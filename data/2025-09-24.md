<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种统一的多任务学习框架，通过动态提示调度机制解决大语言模型在多任务和跨域设置中的泛化限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SPoT依赖固定提示模板，存在泛化能力不足的问题。需要一种能够动态适应不同任务需求的提示调度机制。

Method: 采用动态提示调度机制，包括提示池和任务感知调度策略，通过任务嵌入和门控机制进行提示融合，并引入自动学习策略来优化调度权重。

Result: 实验证明该方法在语言理解和知识推理任务上显著提升性能，有效维持模型稳定性并增强可迁移性。

Conclusion: 所提出的提示调度方法在统一多任务建模和跨域适应方面具有优异的适用性和有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLM数学能力的基准测试，涵盖12个核心技能维度，分为三个领域：知识与理解、问题解决与沟通、元技能与创造力。通过按认知技能分类问题和设计隔离特定能力的任务，GAUSS构建了模型数学能力的全面、细粒度和可解释的配置文件。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够全面评估LLM数学能力多维度的基准测试，需要一种能够揭示模型底层数学智能结构的评估方法。

Method: 设计十二个核心技能维度的分类体系，将问题按认知技能分类，设计能够隔离特定数学能力的任务，构建可解释的数学模型能力配置文件。

Result: 通过GAUSS基准测试，成功揭示了GPT-5-thinking的数学技能分布特征，展示了其相对于o4-mini-high的优势和劣势。

Conclusion: GAUSS基准提供了一种多维度的、基于技能的评估方法，能够更准确地反映LLM的数学智能水平，为模型能力分析提供了有价值的工具。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将第一个事件视为治疗、第二个事件视为结果，利用合成控制方法生成虚拟双胞胎来估计因果效应，在COPES-hard基准测试中表现优于包括GPT-4在内的传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假的图推理而产生错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将时间顺序排列的事件分别视为治疗和结果。通过合成控制方法从相关历史数据中生成虚拟双胞胎，利用文本嵌入合成和反演技术来估计治疗干预对结果可能性的影响。

Result: 该方法在因果关系基准测试COPES-hard上表现出色，识别效果优于包括GPT-4在内的现有方法，能够更稳健地识别事件间的因果关系。

Conclusion: 基于Rubin因果模型的合成控制方法为事件因果关系识别提供了更可靠的框架，通过概念性干预和虚拟对照组的构建，有效解决了文本领域中因果关系识别的挑战。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一个自动提示优化框架，通过联合优化系统提示和用户提示，使用结构化评价标准和最小样本实现快速收敛到高质量提示。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常只关注用户提示，依赖非结构化反馈，需要大量样本和长迭代周期，导致成本高且脆弱。

Method: ZERA使用八个可泛化的评价标准对提示进行评分，并基于这些结构化评价进行提示修订，实现低开销的精炼。

Result: 在五个LLM和九个不同数据集上的实验结果显示，ZERA相比强基线有持续改进，消融研究验证了各组件对更有效提示构建的贡献。

Conclusion: ZERA框架通过联合优化系统提示和用户提示，实现了快速收敛到高质量提示，为自动提示优化提供了更高效和稳健的方法。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 本文研究了辅助信息对具有逐步推理能力的大语言模型的影响，发现思考模式是一把双刃剑：有用信息能提高准确性，但误导信息会导致性能灾难性下降，且思考过程会放大错误。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在现实场景中处理外部信息（可能有用、无关或误导）时的因果影响，特别是在具有逐步推理能力的模型上。

Method: 引入SciAux数据集（基于ScienceQA），系统测试模型对各类信息的鲁棒性，分析思考过程如何影响模型对辅助信息的处理。

Result: 发现关键脆弱性：模型的思考模式会强化错误信息的影响，误导信息导致性能灾难性下降，思考过程反而放大了错误程度。

Conclusion: 挑战不仅在于让模型"思考"，更重要的是赋予它们评估推理所依赖信息的批判能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种过程监督的多智能体框架来优化检索增强生成（RAG）系统中检索器和生成器之间的协调问题，通过决策制定器和知识选择器两个轻量级智能体，结合过程级奖励和树状结构探索策略，实现更准确、稳定和可解释的RAG系统。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统中检索器和生成器独立开发导致交互不理想：检索器可能返回不相关或冗余文档，生成器未能充分利用检索到的证据。需要解决两者之间的协调问题以提高RAG效果。

Method: 1）引入决策制定器决定何时继续检索或停止生成答案；2）知识选择器过滤检索文档保留最有用的证据；3）使用LLM-as-a-Judge提供过程级监督奖励；4）采用树状结构展开策略探索多样化推理路径；5）使用PPO算法端到端训练两个智能体。

Result: 在单跳和多跳问答基准测试中，该方法相比标准RAG基线实现了更高的准确率、更稳定的收敛性，并产生更可解释的推理轨迹。

Conclusion: 该框架是模块化且即插即用的，无需修改检索器或生成器，适用于实际RAG应用，有效解决了RAG系统中组件协调的关键问题。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出了一种新颖的ERFC架构，用于对话中的情感识别和未来情感预测，特别适用于呼叫中心场景，通过多模态分析和上下文理解来提升客户体验。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等场景中，客服人员需要及时识别客户情绪并预测未来情感变化，以便提供合适的解决方案，将不满客户转化为满意客户，提升客户体验。

Method: 提出ERFC架构，考虑多模态信息、情感的不同属性、上下文以及对话中说话者话语之间的相互依赖关系。

Result: 在IEMOCAP数据集上的密集实验证明了所提ERFC方法的可行性。

Conclusion: 该方法在呼叫中心等客户满意度至关重要的应用中具有巨大的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了八个开源LLM检测反犹内容的能力，提出了Guided-CoT提示方法，显著提升了模型性能，并分析了LLM在效用、可解释性和可靠性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是重要但具有挑战性的任务，需要自动化工具来适应社交媒体的快速变化。

Method: 利用上下文定义作为政策指南，探索多种提示技术，设计了新的类似思维链的提示方法Guided-CoT，并引入指标量化模型生成理由的语义差异。

Result: Guided-CoT有效处理上下文政策，在所有评估模型中提高了性能，Llama 3.1 70B甚至优于微调的GPT-3.5。实验揭示了LLM在语义分歧和矛盾行为方面的显著差异。

Conclusion: 研究强调了不同LLM在效用、可解释性和可靠性方面存在明显差异，为仇恨内容检测提供了重要见解。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: TEMPO是一种基于前缀树的无critic强化学习算法，通过树结构计算前缀值，在可验证奖励设置下改进LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中稀疏延迟奖励导致的token级信用分配问题，特别是在数学和医疗QA等可验证答案的任务中

Method: 提出Prefix-to-Tree(P2T)方法将响应组转换为前缀树，计算非参数前缀值；基于此开发TEMPO算法，结合GRPO和分支门控的时序差分修正

Result: 在Qwen3-1.7B/4B模型上，TEMPO在MATH、MedQA等基准测试中优于PPO和GRPO，在相同训练时间内达到更高验证准确率

Conclusion: TEMPO提供了一种简单有效的token级信用分配方法，无需学习价值网络或额外评判者，在推理任务中表现优异

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该论文探索了一种新范式：将LLM作为知识图谱推理路径的奖励模型，让模型学习判断候选路径是否能正确诊断患者输入，而不是直接将KG内容插入提示中。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过检索增强生成或微调来整合知识图谱，但这只是将KG内容插入提示而非实现结构化推理。受奖励训练增强模型推理能力的启发，以及验证解决方案通常比从头生成更容易的计算理论支持，该研究探索了替代方案。

Method: 首先系统评估了5种知识路径判断的任务制定和8种训练范式，然后测试路径判断能力是否能泛化到下游诊断任务（包括诊断总结和医学问答）。使用三个开源指令调优的LLM进行实验。

Result: 实验显示特定奖励优化和蒸馏能带来强大的路径判断性能，但向下游任务的可迁移性仍然较弱。

Conclusion: 这是对临床知识图谱进行"奖励模型风格"推理的首次系统评估，为结构化、基于奖励的监督如何影响医疗GenAI系统中的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无需训练的即插即用方法，通过生成低比特量化替代层来构建高度对齐的草稿模型，加速参数卸载，在有限GPU内存下实现显著推理加速。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型部署在内存有限的消费级GPU上存在挑战，现有压缩方法会降低质量，而参数卸载方法虽然保持质量但推理速度慢。需要一种既能保持质量又能加速推理的解决方案。

Method: SubSpec通过从卸载的目标LLM部分生成低比特量化替代层来构建高度对齐的草稿模型，共享剩余的GPU驻留层和KV-Cache，减少内存开销并增强对齐性。

Result: SubSpec实现了高平均接受长度，在8GB VRAM限制下为Qwen2.5 7B带来9.1倍加速，在24GB VRAM限制下为Qwen2.5 32B平均带来12.5倍加速。

Conclusion: SubSpec是一种无损且无需训练的方法，能够有效加速参数卸载，在有限GPU内存条件下实现显著的推理性能提升。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种并行语音文档对齐方法，通过单调对齐语音段嵌入实现，不依赖文本转录，相比现有方法能产生更长的对齐且噪声更少。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音挖掘方法在语音文档对齐中存在的对齐长度不足和噪声较多的问题，提高语音到语音翻译的质量。

Method: 基于语音段嵌入的单调对齐方法，不依赖文本转录，应用于3000小时的未标注英语-德语平行语音文档。

Result: 产生约1000小时高质量对齐数据，En-De和De-En翻译性能分别比Global Mining提高0.37和0.18 ASR-BLEU，使用8倍少的原始语音文档即可达到或超过SpeechMatrix模型性能。

Conclusion: Speech Vecalign是一种有效的语音文档对齐方法，能显著提升语音到语音翻译性能，且具有更高的数据效率。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种基于LLM的说话人日志校正系统，通过实时用户反馈来修正说话人归属错误，结合流式ASR和说话人日志，使用LLM生成摘要并接受用户语音反馈。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统在"开环"模式下运行，缺乏用户反馈，而人在环的工作流程可以显著提高准确性。

Method: 系统包含流式ASR和说话人日志，使用LLM生成摘要，采用split-when-merged技术检测和分割多说话人段，并基于用户校正进行在线说话人注册。

Result: 在AMI测试集上的LLM驱动模拟显示，该系统显著降低了DER 9.92%和说话人混淆错误44.23%。

Conclusion: 该系统通过实时用户反馈和在线说话人注册，有效提高了说话人日志的准确性，在不同设置下都表现出良好的校正效果。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化框架，用于生成和标注英语、中文和韩语的社会基础对话，通过Violation-to-Resolution对话类型建模规范违反到修复的对话进展，提升对话系统在社会规范遵循方面的能力。


<details>
  <summary>Details</summary>
Motivation: 社会规范在沟通中决定文化适宜行为，使对话系统能产生不仅连贯且社会可接受的回应。当前需要超越静态规范分类，建模社会互动的动态性，并改善在代表性不足语言中的语用一致性。

Method: 提出Violation-to-Resolution对话类型，建模从规范违反到识别和社会适当修复的对话进展；实施基于范例的迭代精炼，在对话合成过程早期引入语言、情感和社会文化期望的对齐；构建包含10,800个多轮对话的数据集，在轮次级别标注规范遵循、说话者意图和情感回应。

Result: 人类和LLM评估显示，NormGenesis在精炼质量、对话自然度和泛化性能上显著优于现有数据集；使用V2R增强数据训练的模型在伦理敏感情境中表现出改进的语用能力。

Conclusion: 本研究为文化自适应对话建模建立了新基准，并为跨语言和文化多样化语言的规范感知生成提供了可扩展的方法论。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在生成富含文化相关表达的波斯文学文本方面的能力，通过构建包含20个主题的数据集，并采用托兰斯创造力测试的四个维度进行自动化评估。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注英语文学创作，缺乏对非英语文学传统的探索，且没有标准化的创造力评估方法。本文旨在填补这一空白，特别针对波斯文学传统。

Method: 构建用户生成的波斯文学数据集，涵盖20个多样化主题；采用托兰斯创造力测试的四个维度（原创性、流畅性、灵活性和精细性）进行评估；使用LLM作为自动化评分工具，并通过组内相关系数验证其与人工评分的一致性；分析模型对四种核心文学手法（明喻、隐喻、夸张和对立）的理解和运用能力。

Result: LLM作为评分工具与人工评分显示出强一致性；模型在波斯文学文本生成方面表现出优势和局限性，特别是在理解和运用文学手法方面。

Conclusion: LLMs在波斯文学文本生成中具有潜力，但仍需进一步改进，特别是在文化相关表达和文学手法的运用方面。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种基于语言模型和对话对齐(CA)分数的自动化方法，用于大规模测量医患共享决策(SDM)。通过深度学习模型和微调的BERT模型计算CA分数，发现CA分数与SDM结果显著相关。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动测量共享决策(SDM)的方法，而SDM对于实现以患者为中心的护理至关重要。需要开发可扩展的自动化方法来评估医患对话中的SDM质量。

Method: 使用157个视频记录的医患对话，转录为42,559个句子。采用上下文-响应对和负采样训练深度学习模型和微调的BERT模型，通过下一句预测任务计算四种类型的CA分数。使用随机效应分析评估CA分数与SDM结果的关系。

Result: 微调的BERTbase模型获得最高召回率(0.640)。DL模型计算的AbsMax和Max CA分数与OPTION12评分显著相关，BERTbase计算的Max CA分数与DCS评分显著相关。模型大小不影响CA分数与SDM的关联。

Conclusion: 本研究首次提出了通过可解释的CA分数自动测量医患对话中SDM的可扩展方法，具有大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个基于认知负荷理论的新型合成基准，通过独立可调参数来精确分析LLM长上下文推理的失败原因，揭示了任务长度是主要约束因素。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文推理基准模糊了关键因素（内在任务复杂度、干扰信息、任务长度），需要更精确的失败分析工具。

Method: 基于认知负荷理论生成自然语言逻辑谜题，通过三个独立可调参数（内在难度d、干扰信号比ρ、任务长度N）分别控制内在负荷、外在负荷和关联负荷。

Result: 评估22个SotA推理LLM发现：任务长度是主导约束，模型对内在复杂度有不同容忍度，对干扰比呈现U型响应。

Conclusion: CogniLoad通过系统控制认知负荷维度，为剖析LLM推理局限性和指导未来模型开发提供了可重现、可扩展且诊断丰富的工具。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种线性注意力框架，可将预训练transformer高效转换为高性能线性注意力架构，显著降低长序列处理的计算复杂度


<details>
  <summary>Details</summary>
Motivation: 解决transformer的二次计算复杂度瓶颈，特别是在长上下文应用中，同时避免从头训练线性复杂度模型的资源消耗

Method: 集成因果Conv1D层增强局部依赖建模，使用归一化门控线性注意力提升不同上下文长度的泛化能力，通过知识蒸馏将预训练transformer能力迁移到线性架构

Result: 仅用1K长度序列蒸馏Mistral-7B，在22K tokens上实现90%+的passkey检索准确率；Llama3.2-1B变体在多个长上下文任务上表现优异，预训练token需求减少99.9%

Conclusion: LAWCAT为高性能长上下文线性模型提供了高效路径，适合边缘部署，减少对大量长序列训练数据和计算资源的依赖

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文通过大规模系统评估，分析了LLM在图数据上的能力，发现代码生成方法表现最佳，特别是在长文本或高密度图上，且所有交互策略在异质图上都有效。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM与图数据交互能力的系统性理解，特别是在欺诈检测、推荐系统等高影响力领域，需要评估不同交互模式在图机器学习任务中的表现。

Method: 采用大规模控制实验，评估多个关键变量轴：LLM-图交互模式（提示、工具使用、代码生成）、数据集领域、结构机制、特征特性和模型配置，并通过截断特征、删除边和移除标签来分析依赖关系。

Result: 代码生成方法整体表现最强，在长文本或高密度图上优势明显；所有交互策略在异质图上保持有效；代码生成能灵活调整对结构、特征或标签的依赖以利用最有效的信息类型。

Conclusion: 研究结果为当前LLM-图交互模式提供了全面的优劣势分析，并为未来方法设计提供了关键原则指导。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种使用ByT5模型在阿拉伯诗歌中插入短语以符合特定韵律的方法，通过基于规则的字符到节拍转换和条件去噪目标训练，实现了高韵律对齐和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自动为阿拉伯诗歌插入符合特定韵律的短语的方法，以支持古典阿拉伯诗歌创作过程中的协同创作应用。

Method: 使用基于规则的字符到节拍转换提取韵律，通过条件去噪目标微调ByT5模型，采用课程学习策略（先在通用阿拉伯数据集上预训练，再在诗歌数据集上微调），并探索从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，所提出的模型在保持语义连贯性的同时，实现了高韵律对齐。

Conclusion: 该模型在古典阿拉伯诗歌创作过程中具有协同创作应用的潜力。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出一种轻量级框架，通过分析文本内部结构来检测原始和修改后的AI生成文本，解决现有词级检测器易受改写攻击、存在偏见等问题


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛使用引发了对AI生成文本滥用的担忧，现有词级检测器存在易受改写攻击、存在ChatGPT词级模式偏见、对修改文本性能下降、需要大模型或在线LLM交互等问题

Method: 使用预训练语言模型编码句子嵌入，通过注意力机制建模句子间关系，采用对比学习减轻自回归生成带来的嵌入偏见，结合因果图和反事实方法从主题相关偏见中分离结构特征

Result: 在两个精选数据集（包括摘要比较和修订的生活FAQ）上的实验验证了该方法的有效性

Conclusion: 提出的基于文本内部结构的轻量级框架能够有效检测原始和修改后的AI生成文本，解决了现有检测方法的局限性

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种针对小型语言模型的新型推理方法，通过循环一致性机制生成问题并评估相似度来选择最佳答案，在数学和常识推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有推理策略在大型语言模型上有效，但在小型模型上效果不佳，需要开发专门针对小型模型的高效推理方法。

Method: 基于循环一致性原理，从推理路径和答案生成问题，评估与原问题的相似度，选择相似度最高的候选解作为最终答案。使用专门的Flan-T5模型支持问题生成。

Result: 在8个模型上的数学和常识推理基准测试中，CCQA一致优于现有最先进方法，为小型语言模型建立了新的高效推理基准。

Conclusion: CCQA为小型语言模型提供了一种有效的推理方法，通过循环一致性机制显著提升了推理性能，具有实际应用价值。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了一种基于先验的数据过滤方法，使用语料库级别的词频统计来估计标记先验，作为困惑度（PPL）过滤的快速替代方案，无需模型推理即可实现高效数据筛选。


<details>
  <summary>Details</summary>
Motivation: 传统基于困惑度的数据过滤方法存在时间成本高、对噪声或分布外样本处理不可靠的问题，需要一种更高效可靠的替代方案。

Method: 利用语料库级别的词频统计估计标记先验，基于标记先验的均值和标准差来过滤文档，该方法受到语言学中词角色和词汇密度见解的启发。

Result: 在20个下游基准测试中取得了最高平均性能，同时将时间成本降低了1000倍以上，适用于代码和数学等符号语言，并能无监督地动态适应多语言语料库。

Conclusion: 基于先验的过滤方法是一种简单而强大的数据选择技术，在保持高性能的同时显著提升了效率，为大规模语言模型预训练提供了实用的数据筛选解决方案。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新颖的参数高效微调方法，通过数据质量驱动选择和敏感性感知的低秩适应来提高微调效率，同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 完全微调所有模型参数计算成本高且内存密集，现有参数高效微调方法忽视了不同模型层的敏感性差异和训练数据的重要性。

Method: TsqLoRA包含两个主要组件：质量感知采样机制选择最具信息量的训练数据，以及动态秩分配模块根据每层对参数更新的敏感性调整其秩。

Result: 实验结果表明TsqLoRA在多种NLP任务上提高了微调效率，同时保持甚至改善了性能。

Conclusion: TsqLoRA通过整合数据质量选择和敏感性感知的低秩适应，为资源受限环境下的模型微调提供了有效的解决方案。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型（如GPT-5）在视觉语言任务上取得了进展，但无法正确理解心电图信号并提供准确的医疗诊断，也不能正确生成心电图信号。

Method: 采用解耦的两阶段训练方法：首先学习基于证据的解释技能（ECG-to-Text），然后通过潜在空间对齐注入心电图生成能力（Text-to-ECG）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: 该模型解决了现有统一模型在心电图理解方面的局限性，为医疗诊断提供了新的工具，代码和检查点将在接受后公开。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 本文通过Planorama实验发现，用户偏好和模型偏好并不能准确预测哪些计划真正对用户有帮助，表明当前的LLM对齐方法存在与帮助性错位的问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLM生成计划的帮助性与用户偏好之间的关系，验证当前基于偏好的对齐方法（如RLHF）是否能真正反映计划对用户的实际帮助效果。

Method: 开发Planorama界面，让126名用户使用LLM计划回答300个多步骤问题，收集4388个计划执行数据和5584个比较数据，测量计划帮助性（QA成功率）和用户偏好。

Result: 1）用户/模型偏好和代理成功率不能准确预测计划对用户的帮助性；2）这种差距不是用户特定偏好造成的；3）表面特征（如简洁性）与偏好强相关但无法预测帮助性。

Conclusion: 需要基于真实用户交互的反馈来对齐有帮助的LLM，而不仅仅是基于看起来有帮助的偏好，并讨论了NLP研究者可以执行的解决方案。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个一致性感知的参数保持知识编辑框架，通过知识图谱在多跳问答任务中确保知识编辑的一致性，解决了现有方法中的知识污染和不稳定更新问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保持知识编辑方法在多跳问答中存在一致性问题，导致知识污染、更新不稳定和检索行为与编辑意图不符，影响了多跳推理的可靠性。

Method: 提出CAPE-KG框架，确保知识图谱的构建、更新和检索过程始终与多跳问答任务要求对齐，在未编辑和已编辑知识上保持一致的推理能力。

Result: 在MQuAKE基准测试上的广泛实验显示，CAPE-KG在多跳问答的参数保持知识编辑性能上取得了准确率提升。

Conclusion: CAPE-KG通过解决一致性问题，有效提升了参数保持知识编辑在多跳问答中的可靠性和性能。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 该论文提出了首个通过保形预测分析LLM作为评判者评估不确定性的框架，为LLM评分提供预测区间，并设计了针对离散评分任务的序数边界调整方法。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者评估自然语言生成的不确定性尚未充分探索，这种可靠性不足可能限制其在许多应用中的部署。

Method: 使用保形预测构建连续预测区间，设计序数边界调整处理离散评分任务，提出区间中点评分作为低偏差替代方案。

Result: 实验表明保形预测能提供具有覆盖保证的有效预测区间，区间中点和重新提示评判者能改善判断质量。

Conclusion: 该框架为LLM评估提供了不确定性量化方法，提高了LLM作为评判者的可靠性，为实际应用部署提供了理论支持。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一种轻量级即插即用的语言强化记忆层，通过将多轮交互提炼为紧凑的策略反思来提升LLM智能体在客户服务中的长期可靠性和一致性


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体在客户服务中存在跨会话遗忘、重复错误和缺乏持续自我改进机制的问题，在需要稳定性和一致性的动态环境中不可靠

Method: 提出MemOrb记忆层，将多轮交互提炼为策略反思存储在共享记忆库中，无需微调即可检索指导决策

Result: MemOrb显著提高了任务成功率和稳定性，在多轮成功率上获得高达63个百分点的提升，并在重复试验中提供更一致的性能

Conclusion: 结构化反思是增强冻结LLM智能体在客户服务场景中长期可靠性的有效机制

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，包含114小时自发对话，专门用于远场对话语音识别研究。该数据集通过多种麦克风在0.12-10米距离录制，包含重叠语音和真实声学效应。实验表明微调Whisper模型能显著提升远场ASR性能。


<details>
  <summary>Details</summary>
Motivation: 解决远场对话语音识别中预训练数据与真实远场语音不匹配的问题，提供专门针对泰语远场场景的训练数据。

Method: 收集114小时自发泰语对话，使用9个独立单通道设备（6种麦克风类型）在0.12-10米距离同时录制，提供标准数据集划分和可复现基线系统。

Result: 零样本Whisper模型在远场条件下性能严重下降（WER 81.6），微调后泰语Whisper基线整体WER从64.3降至38.3，远场WER从81.6降至49.5，最远距离麦克风改进最大。

Conclusion: 距离多样化的训练数据对鲁棒ASR至关重要，LOTUSDIS语料库为远场语音识别研究提供了重要资源。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种针对动态文本属性图（DyTAGs）的新方法，结合LLM和时序GNN，通过近期和全局语义处理解决现有方法在动态图分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，忽略了动态图中近期-全局的时序语义依赖和节点语义演化，且LLM在处理大量动态文本时存在效率问题。

Method: 设计节点中心的隐式推理和滑动窗口机制捕捉近期语义；使用显式推理和RNN链结构捕获全局语义动态；通过更新和合并层整合近期/全局语义与图结构信息。

Result: 在DyTAG基准测试中，DyGRASP在目标节点检索任务的Hit@10指标上提升高达34%，且在不同时序GNN和LLM上表现出强泛化能力。

Conclusion: DyGRASP有效解决了动态文本属性图的语义建模挑战，在效率和性能上均优于现有方法，具有很好的通用性。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本文研究了多语言模型中子词标记重叠对跨语言迁移的影响，通过控制实验发现标记重叠有利于跨语言语义关系的捕捉，并能提升模型在跨语言任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 多语言分词器自然会产生跨语言重叠的标记，但现有研究对标记重叠是促进跨语言迁移还是引入语言间干扰存在争议，部分原因是实验设置和混杂因素（如标记频率、分词粒度）的差异。

Method: 设计了受控实验，在多种语言对上训练双语自回归模型，系统性地改变词汇重叠设置，并探索了一个新维度：跨语言共享标记的语义相似性。分析了模型的隐藏表示，并在XNLI和XQuAD任务上评估性能。

Result: 发现任何类型的标记重叠都能创建捕捉跨语言语义关系的嵌入空间，而在词汇不相交的模型中这种效应较弱。在XNLI和XQuAD上，有重叠的模型优于词汇不相交的模型，且迁移性能通常随着重叠增加而提高。

Conclusion: 标记重叠在多语言模型中具有优势，保持大量共享词汇仍然是多语言分词器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本文研究发现，与长上下文预训练导致短上下文任务性能下降的普遍现象相反，长上下文监督微调（SFT）反而能提升短上下文任务的性能。通过分析多头注意力和前馈网络组件，揭示了长上下文SFT促进上下文知识而短上下文SFT偏好参数知识的偏差，并提出混合训练方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 随着现实应用对长上下文窗口需求的增加，长上下文数据的持续预训练和监督微调成为常见方法。虽然数据长度在持续预训练中的影响已被广泛研究，但其在监督微调中的影响尚不清楚。

Method: 系统研究SFT数据长度如何影响LLM在短上下文任务中的行为，解耦分析多头注意力（MHA）和前馈网络（FFN）两个关键组件，研究它们的相互作用，并揭示知识偏好偏差。

Result: 发现长上下文SFT能独立改善MHA和FFN的性能，但存在知识偏好偏差：长上下文SFT促进上下文知识，短上下文SFT偏好参数知识。混合训练能缓解这种偏差。

Conclusion: 长上下文SFT对短上下文任务有积极影响，但需要平衡长上下文和短上下文训练以避免知识偏好偏差，混合训练为LLM微调提供了可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出一种从10-K文件中提取企业间风险关系的系统方法，通过无监督微调捕获隐含风险连接，优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析企业间风险关系的方法主观性强、劳动密集且难以扩展，需要自动化解决方案

Method: 利用自然语言处理技术，基于10-K文件的时间顺序和词汇模式进行无监督微调，开发领域特定的金融编码器，并引入定量风险关系评分

Result: 大量实验表明该方法在多个评估设置下均优于强基线方法

Conclusion: 该方法为投资组合管理和投资策略等应用提供了可扩展、透明且可解释的企业间风险关系分析工具

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准测试，用于评估大型语言模型在建筑、工程和施工领域的性能表现，涵盖5个认知层次和23个任务，发现模型在复杂推理和领域特定文档生成方面存在显著性能缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在AEC领域的应用日益增多，需要评估这些模型在专业性和安全性要求高的领域中的鲁棒性和可靠性。

Method: 建立包含23个代表性任务的五级认知评估框架（知识记忆、理解、推理、计算、应用），创建4,800个问题的数据集，并采用LLM-as-a-Judge方法进行可扩展评估。

Result: 评估9个LLM显示，模型在知识记忆和理解层面表现良好，但在解释建筑规范表格、执行复杂推理计算和生成领域特定文档方面存在显著性能下降。

Conclusion: 该研究为未来将LLMs可靠集成到安全关键工程实践中的研究奠定了基础，揭示了当前模型在高级认知任务中的局限性。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 该论文使用模型差异分析技术比较Gemma-2-9b-it模型与其SimPO增强版本，发现SimPO主要增强了安全机制、多语言能力和指令跟随能力，同时减少了模型自引用和幻觉管理。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大语言模型的主要方法，传统基准测试往往无法解释模型性能差异的原因，需要更深入的分析方法来理解模型能力的具体变化。

Method: 采用模型差异分析（一种机制可解释性方法），使用crosscoders技术识别和分类两个模型之间的潜在表示差异。

Result: SimPO获得的潜在概念主要增强了安全机制（+32.8%）、多语言能力（+43.8%）和指令跟随（+151.7%），同时减少了模型自引用（-44.1%）和幻觉管理（-68.5%）的强调。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度洞察，将性能差距归因于具体的机制能力，为比较LLMs提供了透明且有针对性框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个基于多智能体协作的关键词提取框架，通过动态适应文档长度的双路径策略，在多个基准数据集上显著优于现有无监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的无监督关键词提取方法通常采用单阶段推理流程和统一提示，无法充分利用LLM的推理能力，特别是在处理不同长度和复杂度的文档时效果有限。

Method: 提出MAPEX框架，通过专家招募、候选提取、主题引导、知识增强和后处理等模块协调LLM智能体，采用知识驱动提取（短文本）和主题引导提取（长文本）的双路径策略。

Result: 在6个基准数据集和3种不同LLM上的实验表明，MAPEX在F1@5指标上平均优于最先进无监督方法2.44%，优于标准LLM基线4.01%。

Conclusion: MAPEX通过多智能体协作和动态适应策略，显著提升了关键词提取的性能和泛化能力，为复杂场景下的关键词提取提供了有效解决方案。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 该研究比较了开源大语言模型与专有模型在生物医学问答任务中的表现，发现开源模型在某些情况下甚至能超越专有模型，特别是在使用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的快速发展，研究者希望验证小型开源模型是否能够有效替代大型闭源模型，特别是在生物医学问答这一专业领域。

Method: 使用嵌入距离检索相关片段、上下文学习、结构化输出等技术增强问答能力，并对精确答案问题采用集成方法整合不同模型的输出。

Result: 开源大语言模型与专有模型表现相当，在某些情况下（特别是应用集成策略时）甚至超越了闭源模型。

Conclusion: 开源大语言模型在生物医学问答领域具有与专有模型相媲美的能力，证明了开源模型的实用价值。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 多特征集成对AI文本检测的性能提升有限（0.4-0.5%），但计算成本显著增加（4.2倍），表明现代神经语言模型可能已高效捕获大部分相关检测信号。


<details>
  <summary>Details</summary>
Motivation: 研究多特征方法是否能显著改进AI文本检测性能，验证结合语义、句法和统计特征是否能提供互补信号，特别是在现代LLM生成文本的背景下。

Method: 实现MHFD（多层次特征检测）方法，通过自适应融合集成基于DeBERTa的语义分析、句法解析和统计概率特征。

Result: MHFD方法在域内检测中达到89.7%准确率，在跨域检测中保持84.2%稳定性能，相比现有方法有0.4-2.6%的适度提升。

Conclusion: 尽管理论预期多特征集成应带来显著改进，但实证结果显示其收益有限且计算成本高昂，表明现代神经网络模型可能已足够高效地捕获检测所需的关键信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个新的AI生成文本检测框架，通过基于惊讶度的特征捕捉文本中不可预测性的波动，在多个基准测试中表现优于现有零样本检测器。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在教育、商业合规、新闻和社交媒体中的滥用增加，检测AI生成文本变得日益重要。现有检测器依赖词级似然或不透明的黑盒分类器，难以应对高质量生成文本且缺乏可解释性。

Method: DivEye利用基于惊讶度的特征来捕捉文本中不可预测性的波动，通过一组可解释的统计特征来识别人类写作与LLM输出在词汇和结构不可预测性上的差异。

Result: DivEye在多个基准测试中比现有零样本检测器性能提升高达33.2%，与微调基线模型性能相当，对改写和对抗攻击具有鲁棒性，跨领域和模型泛化能力强。

Conclusion: DivEye不仅提供有效的AI文本检测，还提供可解释的检测原因，揭示了节奏不可预测性作为LLM检测的强大且未充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅使用编码器的架构，联合执行提取式原子事实分解和可解释推理，无需在推理时使用生成模型，在NLI任务中实现了竞争性的准确性并显著提高了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖资源密集型的生成式大语言模型进行原子事实分解，这影响了可解释性和鲁棒性。JEDI旨在通过仅编码器架构和合成理性来实现可解释性和鲁棒泛化。

Method: 提出JEDI架构，联合执行提取式原子事实分解和可解释推理；使用合成理性的大型语料库进行训练，涵盖多个NLI基准。

Result: JEDI在分布内实现了竞争性准确性，在分布外和对抗性设置中显著提高了鲁棒性，优于仅基于提取式理性监督的模型。

Conclusion: 研究表明，仅使用编码器架构和合成理性可以在NLI中实现可解释性和鲁棒泛化。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态时间规整（DTW）的方法来对齐语音和文本嵌入，以解决端到端语音翻译中的模态差距问题，相比现有方法在准确性和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译需要直接翻译源语音到目标文本，但语音和文本模态之间存在表示差异。现有方法需要依赖对齐工具，但并非所有语言都具备这种工具，且基于最近邻相似性搜索的对齐方法不够准确。

Method: 本文采用动态时间规整（DTW）技术来对齐语音和文本嵌入，在训练过程中实现更精确的模态对齐，无需依赖外部对齐工具。

Result: 实验表明，该方法在端到端语音翻译任务中有效缩小了模态差距，相比先前工作产生了更准确的对齐结果，同时显著提升了训练速度。在低资源设置下，该方法在6个语言方向中的5个都优于先前工作。

Conclusion: 基于DTW的语音-文本嵌入对齐方法是一种高效且准确的解决方案，特别适用于资源受限的语言环境，为端到端语音翻译的模态对齐问题提供了新的思路。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了测试时缩放（TTS）在机器翻译中的应用，通过在推理时生成多个候选翻译并选择最佳方案来提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 传统的模型参数缩放策略计算成本高昂，而测试时缩放提供了一种替代方案，在数学推理等任务中已证明有效，但在机器翻译领域尚未得到系统研究。

Method: 采用简单的best-of-N框架，在WMT24基准上测试，涵盖6个高资源语言对和1个低资源语言对，5种模型规模（3B-72B），以及不同的TTS计算预算（N最大1024）。

Result: 对于高资源语言，TTS能显著提升翻译质量；通过大N值增强小模型可以匹配或超越大模型；但在固定计算预算下，大模型通常更高效，低资源情况下TTS可能因度量盲点而降低质量。

Conclusion: TTS是提升机器翻译质量的有效策略，特别是在高资源语言场景下，但需要根据语言资源和计算预算进行权衡。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文分析了意大利计算语言学和自然语言处理领域过去10年的研究趋势，通过构建CLiC-it会议论文集（2014-2024）并分析其元数据和内容。


<details>
  <summary>Details</summary>
Motivation: 跟踪Transformer大语言模型时代下意大利CL/NLP社区的研究演变，从词汇语义资源向语言建模和多模态的转变。

Method: 收集CLiC-it会议前10届（2014-2024）的论文集，分析元数据（作者来源、性别、机构等）和论文内容主题。

Result: 构建了CLiC-it语料库，提供了意大利CL/NLP研究趋势的全面分析。

Conclusion: 为意大利和国际研究社区提供对新兴趋势和关键发展的宝贵见解，支持该领域的明智决策和未来方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 提出Pathways of Thoughts (PoT)方法，通过建模LLM的推理为迭代决策过程，在推理阶段实现个性化问答，无需任务特定微调


<details>
  <summary>Details</summary>
Motivation: 个性化问答系统对提升准确性和用户满意度至关重要，但面临从长噪声隐式上下文中推断偏好、生成同时正确且符合用户期望的响应的挑战

Method: PoT方法将LLM推理建模为迭代决策过程，动态选择推理、修订、个性化和澄清等认知操作，探索多推理轨迹生成多样化候选响应，然后根据推断的用户偏好聚合重加权

Result: 在LaMP-QA基准测试中，PoT始终优于竞争基线，相对提升达13.1%。人工评估显示66%情况下偏好PoT输出，仅15%为平局

Conclusion: PoT方法有效解决了个性化问答的挑战，通过多推理路径的互补优势生成高质量个性化响应

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 本文通过分析不同语料库中的句子重复率，实证检验了语言学中关于大多数语言表达都是独特的说法。


<details>
  <summary>Details</summary>
Motivation: 语言学中普遍认为大多数语言表达都是独特的，但这一说法缺乏实证支持。随着大型语料库的可用性增加，作者希望对此进行实证检验。

Method: 使用NLTK Python库解析不同体裁的语料库，统计每个语料库中完全相同的字符串匹配数量。

Result: 结果显示，虽然完全独特的句子在语料库中通常占多数，但这高度受体裁限制，重复句子在任何语料库中都不是微不足道的部分。

Conclusion: 语言表达的独特性并非绝对，而是受到语料库体裁的显著影响，重复句子在语言使用中占有重要地位。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzNER，这是首个为吉尔吉斯语手动标注的命名实体识别数据集，包含1,499篇新闻文章、10,900个句子和39,075个实体提及，涵盖27个命名实体类别。


<details>
  <summary>Details</summary>
Motivation: 为资源有限的吉尔吉斯语创建首个高质量的命名实体识别数据集，以支持该语言的NLP研究和发展。

Method: 构建包含27个实体类别的标注方案，收集24.KG新闻门户的1,499篇文章进行手动标注，并评估了基于条件随机场的传统序列标注方法和多语言transformer模型的性能。

Result: 多语言RoBERTa模型表现最佳，在精确率和召回率之间取得了良好平衡，但所有模型在罕见实体类别上都存在困难。其他多语言模型也取得了可比的结果。

Conclusion: 多语言预训练模型在处理资源有限语言方面具有潜力和挑战，未来工作可探索更细粒度的标注方案来提升吉尔吉斯语处理管道的评估效果。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新颖的上下文感知层次化分类法生成框架，通过LLM引导的多方面编码和动态聚类来构建更连贯和细粒度的科学文献分类体系。


<details>
  <summary>Details</summary>
Motivation: 现有基于无监督聚类或直接提示LLM的分类法构建方法缺乏连贯性和细粒度，无法有效应对科学文献快速增长的组织需求。

Method: 利用LLM识别论文的关键方面（如方法、数据集、评估等），生成特定方面的论文摘要，然后对每个方面进行编码和动态聚类，形成连贯的层次结构。

Result: 实验结果表明该方法显著优于先前方法，在分类法连贯性、粒度和可解释性方面达到最先进性能。

Conclusion: 该方法为科学文献组织提供了有效的解决方案，并创建了包含156个专家构建分类法、涵盖11.6k篇论文的新评估基准。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 提出了一种名为"anecdoctoring"的新型红队评估方法，用于自动生成跨语言和跨文化的对抗性提示，以解决生成式AI在虚假信息传播方面的风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的全球采用需要能够适应不同语言和文化的红队评估，但目前的数据集主要集中于美国和英语，存在局限性。

Method: 从三个语言（英语、西班牙语、印地语）和两个地区（美国和印度）的事实核查网站收集虚假信息声明，将其聚类为更广泛的叙事，并用知识图谱表征聚类结果，以此增强攻击者LLM。

Result: 该方法相比少样本提示具有更高的攻击成功率，并提供了可解释性优势。

Conclusion: 结果强调了需要基于真实世界对抗性滥用的、可全球扩展的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文提出了AI "slop"（低质量AI生成文本）的定义和评估框架，通过专家访谈建立了分类体系，并开发了可解释的评估维度。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对AI "slop"的统一定义和测量方法，需要建立系统的评估框架来识别和衡量低质量AI生成文本。

Method: 通过NLP、写作和哲学领域的专家访谈建立分类体系，进行文本片段级标注，分析二元"slop"判断与潜在维度（如连贯性和相关性）的关系。

Result: 发现二元"slop"判断具有一定主观性，但与连贯性、相关性等潜在维度相关。提出的框架可用于AI生成文本的检测和偏好评估任务。

Conclusion: 该框架为评估AI生成文本质量提供了新视角，有助于理解影响质量判断的语言和风格因素。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文提出了首个通过强化学习学习连续思维链的可扩展方法，无需从离散思维链中蒸馏，使用软标记和噪声嵌入进行RL探索，在数学推理基准上表现优于离散标记方法。


<details>
  <summary>Details</summary>
Motivation: 连续标记比离散标记具有更强的表达能力，能同时模拟多个推理路径，但之前的方法存在训练困难、计算成本高、只能处理少量标记等问题。

Method: 使用强化学习方法学习连续思维链，采用"软"标记（标记混合加输入嵌入噪声）进行RL探索，计算开销最小化，可学习包含数百个标记的连续思维链。

Result: 在Llama和Qwen模型上的数学推理基准测试中，连续思维链训练在pass@1上匹配离散标记方法，在pass@32上超越，显示出更大的思维链多样性。最佳方案是训练时使用连续标记，推理时使用离散标记。

Conclusion: 连续思维链RL训练能更好地保持基础模型在域外任务上的预测性能，为基座模型提供了更"温和"的调整方式。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种新的信用分配策略，通过交替优化隐式过程奖励模型和智能体策略，将轨迹偏好转化为隐式步骤奖励，结合结果奖励进行策略更新，解决了稀疏奖励环境中的时序信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为自主智能体在交互环境中进行强化学习时，稀疏且有时不可验证的奖励使得时序信用分配极具挑战性。现有方法存在标注偏差、奖励攻击、方差过大等问题。

Method: 提出在线过程奖励学习（OPRL），通过轨迹DPO目标将轨迹偏好转化为隐式步骤奖励，结合步骤级优势和回合级优势进行策略更新，形成自我强化循环。理论保证学习到的步骤奖励与轨迹偏好一致。

Result: 在WebShop、VisualSokoban和SOTOPIA等基准测试中，OPRL表现优于前沿LLM和强RL基线，实现了最先进的结果，具有更高的样本效率和更低的训练方差。

Conclusion: OPRL通过高效探索和更少的动作使用，展示了在现实世界场景中进行智能体学习的潜力，为稀疏奖励环境中的信用分配提供了有效解决方案。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe是一个轻量级、模型无关的解码框架，通过对比解码和全局感知的token调制策略，动态调整多模态大语言模型的安全决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在安全决策方面存在过度敏感（拒绝良性查询）和敏感不足（错过视觉风险）的平衡问题。

Method: 采用两阶段方法：1）对比解码机制，通过对比真实图像和高斯噪声图像来识别对视觉上下文敏感的token；2）全局感知token调制策略，将场景级推理与token级调整相结合。

Result: 在多种MLLM架构和安全基准测试中，SafeCoDe一致改善了上下文敏感的拒绝行为，同时保持了模型的有用性。

Conclusion: SafeCoDe有效解决了多模态大语言模型在安全对齐方面的持续差距，提供了一种轻量级且模型无关的安全增强解决方案。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 本文比较了多种预训练注意力模型在电子健康记录信息提取任务上的性能，发现临床数据预训练的模型在药物和医疗事件检测方面更有效，而通用领域预训练的Bert Base在药物相关事件上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主要方法，但需要比较不同预训练模型在EHR信息提取任务上的效果，以确定最适合临床应用的模型。

Method: 使用Bert Base、BioBert、Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练模型，在CMED数据集上进行微调，执行药物提取、医疗事件检测和多维药物事件上下文分类任务。

Result: 临床数据预训练的模型在药物和医疗事件检测方面表现更好，而Bert Base在药物相关事件上下文分类方面F1分数最高。

Conclusion: 不同预训练模型在不同临床NLP任务中各有优势，应根据具体任务需求选择合适的模型。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种针对长上下文处理的软压缩技术，通过将上下文分段独立压缩，实现了线性复杂度、可扩展性和可重用性，显著提升处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有软压缩方法将整个上下文作为单一单元压缩，导致二次压缩复杂度且无法在重叠上下文的查询间重用计算，限制了实际应用。

Method: 将上下文划分为多个段，对每个段独立进行压缩，支持压缩段的缓存和跨查询重用。

Result: 在2倍压缩率下，CompLLM在高上下文长度时可将首令牌时间加速4倍，KV缓存减少50%，性能与未压缩上下文相当甚至更好。

Conclusion: CompLLM通过分段压缩设计实现了高效、可扩展和可重用的长上下文处理，具有重要的实用价值。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练时扩展范式，通过强化学习在预训练数据上优化大语言模型，无需人工标注奖励信号，直接从预训练数据中获取奖励，提升模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 计算资源指数级增长与高质量文本数据有限增长之间的差距限制了传统大语言模型的扩展方法，需要新的训练范式来突破这一瓶颈。

Method: 采用下一段推理目标，让策略基于前文准确预测后续文本片段来获得奖励，使强化学习能够在预训练数据上规模化应用，探索更丰富的轨迹。

Result: 在多个模型上的实验验证了RLPT的有效性，Qwen3-4B-Base在MMLU、MMLU-Pro等基准测试上获得显著提升（3.0-8.1个绝对百分点），展现出良好的扩展潜力。

Conclusion: RLPT扩展了大语言模型的推理边界，为强化学习提供了坚实基础，具有持续增益的潜力。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型中提取概念空间的方法，通过使用原型描述来编码特征，并对LLM进行微调以对齐原型嵌入与概念空间维度。


<details>
  <summary>Details</summary>
Motivation: 概念空间使用认知上有意义的维度来表示实体和概念，在认知科学中广泛使用，并有望成为可解释AI的基石。然而，目前缺乏从LLMs中提取概念空间的实用方法。

Method: 提出一种策略，通过嵌入相应原型（如非常甜的食物）的描述来编码特征（如甜度），并对LLM进行微调以使原型嵌入与概念空间维度对齐。

Result: 实证分析发现该方法非常有效。

Conclusion: 该方法为从LLMs中提取概念空间提供了一种实用的解决方案，有助于推动可解释AI的发展。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 本文介绍了SloPalSpeech——一个包含2,806小时斯洛伐克议会语音的大规模ASR数据集，通过微调Whisper模型显著降低了斯洛伐克语的词错误率(WER)，最高降低70%。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语等低资源语言的自动语音识别(ASR)因训练数据稀缺而受到限制，需要构建大规模高质量数据集来提升模型性能。

Method: 开发了稳健的处理流程，将长格式议会录音对齐并分割成30秒的音频-文本对，用于微调多个OpenAI Whisper模型(small、medium、large-v3和large-v3-turbo)。

Result: 在Common Voice和FLEURS等标准斯洛伐克基准测试中，微调后的Whisper-small模型WER最多降低70%，性能接近更大的Whisper-large-v3基线模型。

Conclusion: 公开发布完整的SloPalSpeech数据集、分割后的转录文本(6000万字)和所有微调模型，以促进低资源语音识别的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 该论文发布了沃洛夫语意图分类数据集WolBanking77，填补了低资源语言意图分类研究的空白，包含9,791个银行领域文本句子和超过4小时的语音数据。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究主要关注高资源语言，忽视了像沃洛夫语这样的低资源语言，而沃洛夫语在西非地区有超过1000万使用者，塞内加尔的文盲率高达42%，需要口语优先的解决方案。

Method: 构建了沃洛夫语银行领域数据集WolBanking77，并在文本和语音的最先进模型上进行了基准实验，包括NLP和ASR模型。

Result: 在该数据集上的实验结果非常有前景，报告了基线f1分数和词错误率等指标，并进行了模型间比较。

Conclusion: 该工作为低资源语言的意图分类研究提供了重要资源，计划持续维护和更新数据集，并发布开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是首个专注于印度文化的多模态多语言基准，用于评估生成式AI系统的文化理解能力，涵盖15种语言、所有邦和联邦属地，包含超过64,000个对齐的文本-图像对。


<details>
  <summary>Details</summary>
Motivation: 现有基准多为通用或全球范围，缺乏对特定文化（特别是印度文化）的深度覆盖，需要专门的基准来评估AI系统的文化理解能力。

Method: 构建包含印度文化主题（节日、服饰、美食、艺术形式、历史遗产等）的多模态数据集，评估各种视觉语言模型在零样本和思维链设置下的表现。

Result: 当前模型在处理基于文化的多模态输入方面存在明显局限，特别是在低资源语言和较少记录的传统方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究的重要空白，为推进具有文化意识和多模态能力的语言技术提供了强大的测试平台。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>
