<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [gr-qc](#gr-qc) [Total: 26]
- [quant-ph](#quant-ph) [Total: 46]
- [cs.LG](#cs.LG) [Total: 121]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Effect of cohesion on the gravity-driven evacuation of metal powder through Triply-Periodic Minimal Surface structures](https://arxiv.org/abs/2511.19821)
*Aashish K Gupta,Christopher Ness,Sina Haeri*

Main category: physics.comp-ph

TL;DR: 研究通过离散元方法模拟TPMS结构中粉末的重力驱动排出过程，重点分析了内聚力对排出效率的影响，发现Schwarz-P和Gyroid拓扑结构具有最佳的粉末排出性能。


<details>
  <summary>Details</summary>
Motivation: 解决金属粉末增材制造中TPMS结构复杂空腔内粉末难以排出的问题，为设计有效的脱粉策略提供理论依据。

Method: 使用离散元方法模拟各种TPMS结构单元胞内粉末的重力驱动排出过程，系统研究内聚能密度对排出曲线的影响。

Result: Schwarz-P和Gyroid拓扑结构展现出最高的粉末排出效率，对由内聚力引起的流动阻碍具有较强抵抗力。

Conclusion: Schwarz-P和Gyroid是TPMS结构中最适合粉末排出的拓扑设计，为金属粉末增材制造中的脱粉工艺优化提供了重要指导。

Abstract: Evacuating the powder trapped inside the complex cavities of Triply Periodic Minimal Surface (TPMS) structures remains a major challenge in metal-powder-based additive manufacturing. The Discrete Element Method offers valuable insights into this evacuation process, enabling the design of effective de-powdering strategies. In this study, we simulate gravity-driven evacuation of trapped powders from inside unit cells of various TPMS structures. We systematically investigate the role of cohesive energy density in shaping the discharge profile. Overall, we conclude that the Schwarz-P and Gyroid topologies enable the most efficient powder evacuation, remaining resilient to cohesion-induced flow hindrance. Furthermore, for the two unit cells, we analyse detailed kinematics and interpret the results in relation to particle overlaps and contact force distributions.

</details>


### [2] [An ALE approach to reduce spurious numerical mixing through variational minimizers: application to internal waves](https://arxiv.org/abs/2511.20092)
*Andreas Alexandris-Galanopoulos,George Papadakis*

Main category: physics.comp-ph

TL;DR: 提出了一种减少海洋模型中虚假数值混合的有效方法，通过优化垂直网格运动来降低混合效应。


<details>
  <summary>Details</summary>
Motivation: 海洋模型中经常出现虚假数值混合现象，这会影响模拟结果的准确性。

Method: 通过变分法思想解决优化问题，得到椭圆方程来定义垂直网格运动，适用于任何使用ALE垂直坐标的海洋模型。

Result: 该方法在非线性内波、波浪破碎和翻转等苛刻测试案例中显示出减少虚假混合的能力，同时保持结果的物理相关性。

Conclusion: 该方法能有效减少海洋模型中的虚假数值混合，提高模拟结果的准确性。

Abstract: Spurious numerical mixing is a frequent phenomenon in ocean models. In the present paper, we present an efficient and robust methodology that defines the vertical grid motion so that this mixing is reduced. This motion is defined through the solution of an optimization problem that -- using the ideas of the calculus of variations -- results in an elliptic equation. This framework is generally applicable to any ocean model that uses an ALE vertical coordinate and can be tuned to fit the modeler's specific needs based on the guidelines presented herein. The method is applied to the nonhydrostatic solver presented by the authors in [Alexandris-Galanopoulos et al., 2024] and its applicability in fully nonlinear internal waves is investigated for the demanding test cases of wave breaking and overturning. These numerical benchmarks show the ability of the method to reduce spurious mixing, while attaining the physical relevancy of the results.

</details>


### [3] [Attosecond momentum-resolved resonant inelastic x-ray scattering for imaging coupled electron-hole dynamics](https://arxiv.org/abs/2511.20161)
*Maksim Radionov,Daria Popova-Gorelova*

Main category: physics.comp-ph

TL;DR: 提出阿秒动量分辨共振非弹性X射线散射作为追踪超快动力学的重要技术，证明散射信号包含散射原子瞬时电荷密度分布信息


<details>
  <summary>Details</summary>
Motivation: 理解电子动力学对能量转移、光电子学、光捕获系统和量子计算至关重要，阿秒X射线源为原子尺度观测提供了可能，但时间分辨信号与动力学的关联具有挑战性

Method: 提出阿秒动量分辨共振非弹性X射线散射技术，以α-六噻吩分子为例研究耦合电子-空穴动力学

Result: 散射信号包含散射原子瞬时电荷密度分布信息，能够追踪超快动力学过程

Conclusion: 阿秒动量分辨共振非弹性X射线散射是研究超快电子动力学的有效技术，可提供原子尺度的瞬时电荷密度信息

Abstract: Improving our understanding of electron dynamics is essential for advancing energy transfer, optoelectronics, light harvesting systems and quantum computing. Recent developments in attosecond x-ray sources provide the fundamental possibility of observing these dynamics with atomic-scale resolution. However, connecting a time-resolved signal to dynamics is challenging due to the broad bandwidth of an attosecond probe pulse. This makes exploring the capabilities of different attosecond imaging techniques crucial. Here, we propose attosecond momentum-resolved resonant inelastic x-ray scattering as a prominent technique for tracking ultrafast dynamics. We demonstrate that the scattering signal contains an information about the instantaneous distribution of charge density across the scattering atoms. To illustrate this, we consider scattering from an $α$-sexithiophene molecule, in which coupled electron-hole dynamics are excited.

</details>


### [4] [Active learning with physics-informed neural networks for optimal sensor placement in deep tunneling through transversely isotropic elastic rocks](https://arxiv.org/abs/2511.20574)
*Alec Tristani,Chloé Arson*

Main category: physics.comp-ph

TL;DR: 使用物理信息神经网络(PINN)结合主动学习策略，同时求解深部隧道开挖中的偏微分方程并反演岩体参数，通过蒙特卡洛dropout量化不确定性来优化传感器布置。


<details>
  <summary>Details</summary>
Motivation: 在深部隧道开挖中，现场观测数据获取成本高昂，需要开发能够利用有限测量数据同时求解PDE和反演参数的方法，并优化传感器布置以减少所需现场数据量。

Method: 采用物理信息神经网络(PINN)模型，结合主动学习的顺序训练方法，使用蒙特卡洛dropout量化认知不确定性，在模型最不确定的区域选择新的传感器位置。

Result: 该方法在少量、分散且有噪声的数据集上表现优异，能够高精度确定杨氏模量、剪切模量、水平-垂直远场应力比和层理面方位等岩体参数。

Conclusion: 所提出的框架可为优化地下监测和自适应隧道设计与控制提供决策支持。

Abstract: This paper presents a deep learning strategy to simultaneously solve Partial Differential Equations (PDEs) and back-calculate their parameters in the context of deep tunnel excavation. A Physics-Informed Neural Network (PINN) model is trained with synthetic data that emulates in situ displacement measurements in the host rock and at the cavity wall, obtained from extensometers and convergence monitoring. As acquiring field observations can be costly, a sequential training approach based on active learning is implemented to determine the most informative locations for new sensors. In particular, Monte Carlo dropout is used to quantify epistemic uncertainty and query measurements in regions where the model is least confident. This approach reduces the amount of required field data and optimizes sensor placement. The PINN is tested to reconstruct the displacement field around a deep tunnel of circular section excavated in transversely isotropic elastic rock and to determine rock constitutive and stress-field parameters. Results demonstrate excellent performance on small, scattered, and noisy datasets, achieving high precision for the Young's moduli, shear modulus, horizontal-to-vertical far-field stress ratio, and the orientation of the bedding planes. The proposed framework shall ultimately support decision-making for optimal subsurface monitoring and for adaptive tunnel design and control.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [5] [Hodge-Dirac wave systems and structure-preserving discretizations of the linearized Einstein equations](https://arxiv.org/abs/2511.19441)
*Marien-Lorenzo Hanot,Kaibo Hu*

Main category: gr-qc

TL;DR: 将线性化ADM方程重新表述为具有divdiv复形的Hodge-Dirac波系统，解决了数值相对论中的规范固定、约束传播和张量对称性等挑战。


<details>
  <summary>Details</summary>
Motivation: 解决数值相对论中的关键问题，包括规范固定、约束传播和张量对称性，这些在传统ADM方程中难以处理。

Method: 使用divdiv复形的微分和代数结构重新表述线性化ADM方程为Hodge-Dirac波系统，并开发基于有限元外微积分的结构保持离散化方案。

Result: 建立了Hodge-Dirac波方程的适定性，并开发了适用于共形和非共形离散复形的离散化方案，在最小假设下推导了误差估计。

Conclusion: 该重新表述为数值相对论提供了数学上严格且计算上可行的框架，确保了适定性和结构保持特性。

Abstract: We derive a reformulation of the linearized Arnowitt-Deser-Misner (ADM) equations as a Hodge-Dirac wave system with the divdiv complex, addressing challenges in numerical relativity such as gauge fixing, constraint propagation, and tensor symmetries. The differential and algebraic structures of the divdiv complex ensure the well-posedness of the formulation and facilitate structure-preserving discretization via finite element exterior calculus. We establish the well-posedness of this Hodge-Dirac wave equation and develop a discretization scheme applicable to both conforming and non-conforming discrete complexes, deriving error estimates under minimal assumptions.

</details>


### [6] [GREA and Dark Energy: A holographic dual](https://arxiv.org/abs/2511.19546)
*Juan García-Bellido*

Main category: gr-qc

TL;DR: 该论文探讨了宇宙加速膨胀的起源，提出通过全息原理将宇宙常数Λ的效应与边界热力学性质联系起来，认为观测者无法区分由Λ引起的加速和由边界德西特视界热力学性质引起的加速。


<details>
  <summary>Details</summary>
Motivation: 理解宇宙常数的量子起源是一个未解之谜。作者希望通过全息原理探索宇宙加速膨胀是否可能不是由常数引起的，而是由边界量子自由度的热力学性质导致的，这为理解宇宙加速提供了新视角。

Method: 通过研究空平空间中带宇宙常数Λ的最简单宇宙模型，分析其全息对偶理论，并考虑观测者在电磁和引力观测中的局限性。进一步通过包含物质扩展全息原理到GREA模型，研究因果视界边界的量子自由度如何随时间变化诱导熵加速。

Result: 研究发现，观测者无法区分由宇宙常数Λ引起的加速和由边界德西特视界热力学性质引起的加速。通过全息原理，宇宙加速可以被解释为边界量子自由度的热力学效应。

Conclusion: 宇宙加速膨胀可能不是由常数宇宙常数引起的，而是由因果视界边界的量子自由度产生的熵加速效应。未来的观测将决定我们的宇宙最终是走向德西特空间还是闵可夫斯基空间。

Abstract: The nature of the cosmological constant is a mystery. We don't understand its quantum origin but we associate it with the actual acceleration of the universe because it is the simplest description we had until recently of the present cosmological observations. However, this may change with the next generation of experiments. If we can convince ourselves that the cosmic acceleration is not due to a constant, this would open up new fascinating avenues. By exploring the simplest cosmological model in the bulk, that of an empty and flat space with a cosmological constant $Λ$, we find that its holographic dual makes sense as a theory of fundamental quantum degrees of freedom at the boundary. Moreover, we find that an observer in the bulk, making long-range (electromagnetic and gravitational) observations, cannot distinguish the acceleration induced by the cosmological constant $Λ$ from that induced by the thermodynamic properties of the boundary, the de Sitter horizon. By including matter in the bulk we extend this holographic principle to GREA, where the quantum d.o.f. associated with the evolving boundary of the causal horizon induces an entropic acceleration that varies in time. Future observations will determine whether our causal horizon is responsible for the present acceleration and whether our universe will end in de Sitter or Minkowski.

</details>


### [7] [Quasinormal modes of scalar, electromagnetic, and gravitational perturbations in slowly rotating Kalb-Ramond black holes](https://arxiv.org/abs/2511.19553)
*Weike Deng,Wentao Liu,Kui Xiao,Jiliang Jing*

Main category: gr-qc

TL;DR: 研究了缓慢旋转Kalb-Ramond黑洞中不同扰动的准正则模式，发现洛伦兹对称性破缺会统一改变所有扰动模式的振荡和衰减率。


<details>
  <summary>Details</summary>
Motivation: 通过研究Kalb-Ramond黑洞中的准正则模式，探索洛伦兹对称性破缺在引力波光谱学中的可观测特征。

Method: 在一阶自旋参数近似下推导主方程，使用连分式和矩阵方法计算准正则模式谱。

Result: 洛伦兹破缺参数ℓ增加时，准正则模式频率实部单调增加，虚部变得更负；轴向引力模式响应最强，且存在理论界限ℓ<0.5。

Conclusion: 引力波光谱学有潜力探测Kalb-Ramond引力理论中的洛伦兹破缺特征。

Abstract: We investigate quasinormal modes (QNMs) of scalar, electromagnetic, and axial gravitational perturbations in slowly rotating Kalb-Ramond (KR) black holes, where an antisymmetric tensor field induces spontaneous Lorentz symmetry breaking. Working consistently to first order in the dimensionless spin parameter, we derive the corresponding master equations and compute the QNM spectrum using both the continued-fraction and matrix methods, finding excellent agreement. Lorentz violation modifies the oscillation and damping rates in a unified manner across all perturbative sectors: the real part of the QNM frequency increases monotonically with the Lorentz-violating parameter $\ell$, while the imaginary part becomes more negative. Axial gravitational modes exhibit the strongest response, revealing an intrinsic theoretical bound $\ell< 0.5$, beyond which the spectrum approaches an extremal behavior. Our results highlight the potential of gravitational-wave spectroscopy to probe Lorentz-violating signatures in KR gravity.

</details>


### [8] [On Modelling the Surfaces of Celestial Bodies in Quantum Gravity](https://arxiv.org/abs/2511.19582)
*Xavier Calmet,Marco Sebastianutti*

Main category: gr-qc

TL;DR: 本文研究了如何在量子引力中建模天体表面以确保量子修正在经典广义相对论解的表面保持正则性，使用Vilkovisky-DeWitt有效作用量计算恒星模型外部度规的普适量子修正。


<details>
  <summary>Details</summary>
Motivation: 先前通过Heaviside密度剖面获得的描述在恒星表面是"病态的"，因为度规函数和相关曲率不变量发散，需要找到能产生正则量子修正的密度剖面。

Method: 使用Vilkovisky-DeWitt唯一有效作用量计算量子修正，引入改进的Tolman VII密度剖面，确定该函数在恒星表面产生正则量子修正所需的最小可微性程度。

Result: 确定了密度剖面函数在恒星表面所需的最小可微性条件，以确保量子修正的正则性。

Conclusion: 通过引入适当可微的密度剖面，可以避免先前方法在恒星表面的病态行为，获得正则的量子引力修正。

Abstract: We discuss how to model the surface of celestial bodies (such as stars) in quantum gravity to ensure the regularity of quantum corrections to classical solutions of general relativity at the surface of such bodies. Specifically, we use the Vilkovisky--DeWitt unique effective action to calculate universal quantum corrections to the exterior metric for a class of stellar models. Previous descriptions, obtained via a Heaviside density profile, are ``pathological'' at the surface of the star due to the divergence of the metric functions and associated curvature invariants. Introducing a modified version of the Tolman VII density profile, we determine the minimal degree of differentiability required for this function to generate regular quantum corrections at the star's surface.

</details>


### [9] [Searching Stochastic Gravitational Wave Background Landscape Across Frequency Bands](https://arxiv.org/abs/2511.19590)
*Yunjia Bao,Tore Boybeyi,Vuk Mandic,Lian-Tao Wang*

Main category: gr-qc

TL;DR: 该论文提出了一种分析混合拓扑缺陷模型的新方法，展示了多频段引力波探测在验证或排除新物理模型方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着多频段引力波探测时代的到来，需要开发通用分析工具来研究随机引力波背景，特别是验证可能解释脉冲星计时阵列信号的新物理模型。

Method: 开发了一个通用分析管道来研究实验排除能力，并将其应用于两步相变产生的混合拓扑缺陷模型。

Result: 该模型能够解释低频脉冲星计时阵列信号，未来LISA/Cosmic Explorer/Einstein Telescope等实验将通过高频探测来确认或排除该模型。

Conclusion: 多频段引力波约束具有强大的模型验证能力，能够为混合拓扑缺陷等新物理模型提供关键检验。

Abstract: Gravitational wave (GW) astrophysics is entering a multi-band era with upcoming GW detectors, enabling detailed mapping of the stochastic GW background across vast frequencies. We highlight this potential via a new physics scenario: hybrid topological defects from a two-step phase transition separated by inflation. We develop a general pipeline to analyze experimental exclusions and apply it to this model. The model offers a possible explanation of the pulsar timing array signal at low frequencies, and future experiments (LISA/Cosmic Explorer/Einstein Telescope) will confirm or rule it out via the higher-frequency probes, showcasing the power of multi-band constraints.

</details>


### [10] [A parametrized model for gravitational waves from eccentric, precessing binary black holes: theory-agnostic tests of General Relativity with pTEOBResumS](https://arxiv.org/abs/2511.19593)
*Danilo Chiaramello,Nicolò Cibrario,Jacob Lange,Koustav Chandra,Rossella Gamba,Raffaella Bonino,Alessandro Nagar*

Main category: gr-qc

TL;DR: 提出了pTEOBResumS模型，这是一个包含轨道偏心率和自旋进动的参数化引力波模型，用于测试广义相对论。通过分析LIGO-Virgo-KAGRA观测到的双黑洞合并事件，发现没有显著证据支持偏离广义相对论，但GW200129事件显示出偏心轨道的强烈偏好。


<details>
  <summary>Details</summary>
Motivation: 现有的引力波测试假设信号源为非偏心轨道，限制了其在更一般天体物理场景中的适用性。需要开发能够同时考虑轨道偏心率和自旋进动的模型来更全面地测试广义相对论。

Method: 基于有效单体模型TEOBResumS-Dalí，开发了pTEOBResumS模型，在进动和合并-环降阶段引入了参数化的广义相对论偏离。通过数值相对论模拟的双黑洞和玻色子星双星合成信号进行验证。

Result: 对前三轮LIGO-Virgo-KAGRA观测运行中的双黑洞事件分析显示，没有发现显著偏离广义相对论的统计证据。GW200129事件显示出偏心轨道的强烈偏好，但可能受数据质量问题影响。

Conclusion: 当前观测数据与广义相对论一致，没有发现强烈证据支持偏离广义相对论或轨道偏心率的普遍存在。需要更多高质量数据来进一步检验广义相对论在强场高曲率区域的预测。

Abstract: Gravitational waves from binary black hole (BBH) mergers allow us to test general relativity in the strong-field, high-curvature regime. However, existing gravitational wave-based tests have so far assumed non-eccentric signal sources, limiting their applicability to more general astrophysical scenarios. In this work, we present pTEOBResumS, a new parametrized inspiral-merger-ringdown model for null tests of GR that incorporates both orbital eccentricity and spin precession. Building on the effective-one-body model TEOBResumS-Dalí, we introduce parametrized deviations from GR both in the inspiral and the merger-ringdown regimes. We validate the model via parameter estimation of synthetic signals, including from numerical relativity simulations of BBHs and a boson star binary. These allow us to establish the model's consistency, demonstrate its capability to identify beyond-GR effects, and gauge the impact of eccentricity in tests of GR. We then analyze a set of BBH events from the first three LIGO-Virgo-KAGRA observing runs, testing whether they are best explained by a GR or non-GR waveform, under either the eccentric, spin-aligned or precessing, quasi-circular hypotheses. We find no significant statistical evidence in favor of deviations from GR. Consistent with previous works, we infer a mild preference for longer remnant quasi-normal mode damping times than expected in GR, though the limited sample and potential systematics reduce its significance. In addition, when weighting by signal strength, joint posteriors combining the individual events are still compatible with GR. We find no strong evidence for imprints of orbital eccentricity in the analyzed events, with the exception of GW200129. For this, our analysis finds a strong preference for an eccentric, GR-consistent description, although as previous works have noted this result could be influenced by data quality issues.

</details>


### [11] [Periodic gravitational lensing by oscillating boson stars](https://arxiv.org/abs/2511.19606)
*Xing-Yu Yang,Tan Chen,Rong-Gen Cai*

Main category: gr-qc

TL;DR: 振荡玻色子星可以作为周期性引力透镜，产生与时间同步的光度尖峰和天体测量摆动，为检验弯曲时空中的自引力量子场提供清洁测试。


<details>
  <summary>Details</summary>
Motivation: 研究自引力量子场在弯曲时空中的动力学行为，探索玻色子星作为引力透镜的独特性质，为时间域天文学提供新的观测目标。

Method: 分析振荡（实标量）玻色子星的引力透镜效应，研究其周期性特征和径向焦散现象。

Result: 发现玻色子星附近的光源每半个周期穿过焦散，产生与周期同步的无色差光度尖峰和天体测量摆动，当前天体测量和高频光度巡天具有可测量的发现空间。

Conclusion: 振荡玻色子星提供了检验自引力量子场的清洁测试平台，该框架可自然扩展到自相互作用实标量（包括轴子类粒子）和超轻矢量玻色子。

Abstract: We show that oscillating (real-scalar) boson stars can act as strictly periodic gravitational lenses and generically host an \emph{oscillating radial caustic}. Sources near this caustic cross it every half period, producing achromatic phase-locked photometric spikes synchronized with an astrometric wobble, providing a promising target for time-domain astronomy. Event-number estimation indicates a measurable discovery space with current astrometric and high-cadence photometric surveys. These predictions rely only on the dynamics of long-lived real-scalar condensates, therefore offering a clean test of self-gravitating quantum fields in curved spacetime. The framework extends naturally to self-interacting real scalars (including axion-like particles) and to ultralight vector bosons.

</details>


### [12] [Effective-one-body modelling of eccentric supermassive black hole binaries for Pulsar Timing Array](https://arxiv.org/abs/2511.19611)
*Sara Manzini,Stanislav Babak*

Main category: gr-qc

TL;DR: 提出了基于有效单体(EOB)形式的偏心双星引力波模型，用于脉冲星计时阵列(PTA)中的连续引力波搜索，该模型在2PN精度下考虑保守动力学和辐射反应项。


<details>
  <summary>Details</summary>
Motivation: 当前PTA分析通常假设圆形双星，但环境动力学相互作用可能阻止完全圆化，使超大质量黑洞双星(SMBHBs)保持显著偏心度，需要开发能处理偏心轨道的波形模型。

Method: 基于EOB形式构建偏心双星引力波模型，提供数值精确和计算高效的近似实现，在2PN精度下处理保守动力学和辐射反应项。

Result: 模型在广泛的偏心度和初始轨道频率范围内保持准确性，参数空间中大部分区域显示比圆形情况更强的轨道演化，偏心引力波产生丰富的谐波结构。

Conclusion: 正确表征偏心双星对PTA数据中引力波探测和结果解释至关重要，将增进对本地宇宙中超大质量黑洞种群的理解。

Abstract: Pulsar Timing Arrays (PTAs) observations will detect gravitational waves (GWs) from the early inspiral phase of supermassive black hole binaries (SMBHBs) with orbital periods of weeks to years. Current PTA analyses generally assume circular binaries; however, dynamical interactions with the surrounding environment can prevent complete circularisation, allowing SMBHBs to retain appreciable eccentricities. In this work, we present a gravitational waveform model for eccentric binaries based on the Effective-One-Body (EOB) formalism, designed for continuous GW searches in PTA data. The model is accurate up to the second post-Newtonian (2PN) order for the conservative dynamics and up to post-leading order for the radiation-reaction terms. We provide both a numerically precise and a computationally efficient approximate implementation and evaluate the latter's accuracy against the full model over a broad range of eccentricities and initial orbital frequencies. Our results show that a substantial region of the parameter space exhibits pronounced orbital evolution, much stronger than in the circular case. We demonstrate the rich harmonic structure of timing residuals induced by eccentric GWs. Properly characterising eccentric binaries is an essential step toward detecting GWs in PTA data and interpreting the results, ultimately improving our understanding of the supermassive black hole population in the local Universe.

</details>


### [13] [Universal Relations with Dynamical Tides](https://arxiv.org/abs/2511.19626)
*Jayana A. Saes,Abhishek Hegade K. R.,Nicolás Yunes*

Main category: gr-qc

TL;DR: 本文发现了中子星静态潮汐形变Λ(0)与其动力学修正Λ(2)之间的新准普适关系，以及参数组合√(Λ(0)/Λ(2))≡Mω*的准普适关系，这些关系在63种状态方程下保持高度普适性，为引力波建模中的动力学潮汐效应提供了简化框架。


<details>
  <summary>Details</summary>
Motivation: 中子星观测为极端条件下核物质行为和强场广义相对论测试提供了宝贵见解，而状态方程不敏感的准普适关系在连接不同可观测量、减少状态方程不确定性方面起着关键作用。

Method: 通过相对论潮汐响应的小频率展开，识别静态无量纲潮汐形变Λ(0)与其主导阶动力学修正Λ(2)之间的新准普适关系，并在63种代表性状态方程下测试这些关系。

Result: Λ(0)-Λ(2)关系的状态方程依赖性不超过~5%，Λ(0)-Mω*关系不超过~2.5%，表明高度普适性。泰勒展开模型在大多数参数空间中优于有效单模近似模型。

Conclusion: 新发现的准普适关系具有高度普适性，为引力波建模中的动力学潮汐效应提供了简化框架，泰勒展开模型能更好地捕捉完全动力学潮汐形变的频率依赖行为。

Abstract: Observations of neutron stars and the precise measurement of their macroscopic properties have provided valuable insights into fundamental physics, both by constraining the behavior of nuclear matter under extreme conditions and by enabling tests of general relativity in the strong-field regime. In this context, equation-of-state-insensitive or ``quasi-universal'' relations between key observables, such as the compactness, dimensionless static tidal deformability, and moment of inertia, play a crucial role in connecting different measurable observables while minimizing uncertainties due to the yet unknown equation of state. In this work, we identify new quasi-universal relations between the static, dimensionless tidal deformability ($Λ^{(0)}$) and its leading-order dynamical correction ($Λ^{(2)}$), as well as a combination of these parameters ($\sqrt{Λ^{(0)}/Λ^{(2)}} \equiv Mω_*$), obtained from the small-frequency expansion of the relativistic tidal response. We test these relations across a representative set of 63 equations of state, finding that the equation-of-state dependence does not exceed $\sim 5\%$ for the $Λ^{(0)}$-$Λ^{(2)}$ relation and $\sim 2.5\%$ for the $Λ^{(0)}$-$Mω_*$ relation. This indicates a high degree of universality and offers a simplified framework for incorporating dynamical tidal effects into gravitational-wave modeling. Furthermore, we compare the fully dynamical tidal response against different recent strategies (a Taylor expansion and an effective-one-mode approximation) to model the dynamical tide. We find that both models are capable of capturing the frequency-dependent behavior of the fully dynamical tidal deformability, with the Taylor expansion outperforming the effective-one-mode approximation in most of the parameter space.

</details>


### [14] [Microseismic Noise Mitigation with Machine Learning for Advanced LIGO](https://arxiv.org/abs/2511.19682)
*Christina Reissel,Devin Lai,Shivanshu Dwivedi,Edgard Bonilla,Claudia Geer,Christopher Wipf,Richard Mittleman,Philip Harris,Eyal Schwartz,Dovi Poznanski,Brian Lantz,Erik Katsavounidis*

Main category: gr-qc

TL;DR: 使用机器学习方法抑制引力波探测器中的残余地震运动，相比传统线性滤波方法可降低一个数量级的残余运动


<details>
  <summary>Details</summary>
Motivation: 激光干涉引力波天文台对低频地面运动高度敏感，持续的微震会降低锁模稳定性并导致探测器停机，残余平台运动限制了低频灵敏度和工作周期

Method: 开发数据驱动方法，使用机器学习建模和抑制隔离系统中的残余地震运动，利用地面和平台传感器数据训练神经网络来预测微震活动驱动的平台运动

Result: 在控制方案中集成神经网络预测，相比传统线性滤波方法可实现残余运动降低一个数量级，揭示非线性耦合在当前隔离性能限制中起重要作用

Conclusion: 基于机器学习的控制为增强主动地震隔离、提高锁模鲁棒性和扩展引力波探测器低频观测能力提供了强大新途径

Abstract: The unprecedented sensitivity of the Laser Interferometer Gravitational-Wave Observatory, which enables the detection of distant astrophysical sources, also renders the detectors highly susceptible to low-frequency ground motion. Persistent microseisms in the 0.1-0.3 Hz band couple into the instruments, degrade lock stability, and contribute substantially to detector downtime during observing runs. The multi-stage seismic isolation system has achieved remarkable success in mitigating such disturbances through active feedback control, yet residual platform motion remains a key factor limiting low-frequency sensitivity and duty cycle. Further reduction of this residual motion is therefore critical for improving the long-term stability and overall astrophysical reach of the observatories.
  In this work, we develop a data-driven approach that uses machine learning to model and suppress residual seismic motion within the isolation system. Ground and platform sensor data from the detectors are used to train a neural network that predicts platform motion driven by microseismic activity. When incorporated into the control scheme, the network's predictions yield up to an order-of-magnitude reduction in residual motion compared to conventional linear filtering methods, revealing that nonlinear couplings play a significant role in limiting current isolation performance. These results demonstrate that machine-learning-based control can provide a powerful new pathway for enhancing active seismic isolation, improving lock robustness, and extending the low-frequency observational capabilities of gravitational-wave detectors.

</details>


### [15] [General relativity, early galaxy formation and the JWST observations](https://arxiv.org/abs/2511.19736)
*Christos G. Tsagas*

Main category: gr-qc

TL;DR: JWST观测到早期宇宙存在大质量星系，这与当前宇宙学模型矛盾。本文提出在标准广义相对论框架内，通过考虑宇宙中的特殊速度来解释这一现象。


<details>
  <summary>Details</summary>
Motivation: 解决JWST观测到的早期大质量星系与当前宇宙学模型的矛盾，避免引入新物理或过度调参。

Method: 在标准广义相对论和宇宙学框架内，考虑宇宙中特殊速度的影响。

Result: 提出了一种不依赖新物理的解释方案，能够解释早期大质量星系的存在。

Conclusion: 特殊速度这一被主流宇宙学忽视的特征，可能为解决早期星系形成问题提供关键解释。

Abstract: The James Webb Space Telescope has recently detected massive, fully formed, galaxies at redshifts corresponding to few hundred million years after the Big-Bang. However, our current cosmological model cannot produce such massive systems so early in the lifetime of the universe. A number of theoretical solutions have been proposed, but they all appeal to exotic new physics and introduce rather excessive fine-tuning. In this essay, we outline a theoretical answer to the early galaxy-formation question, which operates within standard general relativity and standard cosmology, without appealing to any new physics. Instead, we account for the effect of a well established feature of our universe. This feature, which has so far been kept in the margins of mainstream cosmology, are the peculiar velocities.

</details>


### [16] [Exact Solutions for the Kemmer Oscillator in 1+1 Rindler Coordinates](https://arxiv.org/abs/2511.19748)
*T. Rouabhia,A. Boumali*

Main category: gr-qc

TL;DR: 本文在(1+1)维Rindler时空中精确求解了自旋1粒子的Kemmer方程，研究了加速度对矢量玻色子的影响，包括Unruh温度和简并消除等效应。


<details>
  <summary>Details</summary>
Motivation: 理解均匀加速度下矢量玻色子的行为，包括非惯性效应和Unruh温度，这些效应使其区别于自旋0和自旋1/2系统。

Method: 从加速参考系中的自由Kemmer场出发，建立类似Rindler坐标下Klein-Gordon方程的特征值方程，通过动量替代引入Dirac振荡器相互作用，推导出Kemmer振荡器的精确闭式能谱。

Result: 发现加速度参数会改变特征长度、移动离散能谱并消除简并，在Minkowski极限a→0时恢复标准Kemmer振荡器能谱。

Conclusion: 这些结果为分析加速度诱导效应提供了一个可处理的理论框架，对弯曲时空量子场论、量子引力和模拟引力平台具有重要意义。

Abstract: This work presents exact solutions of the Kemmer equation for spin-1 particles in $(1+1)$-dimensional Rindler spacetime, motivated by the need to understand vector bosons under uniform acceleration, including non-inertial effects and the Unruh temperature, which distinguish them from spin-0 and spin-1/2 systems. Starting from the free Kemmer field in an accelerated reference frame, we establish eigenvalue equations resembling those of the Klein--Gordon equation in Rindler coordinates. By introducing the Dirac oscillator interaction through a momentum substitution, we derive an exact closed-form spectrum for the Kemmer oscillator, revealing how the acceleration parameter modifies the characteristic length, shifts the discrete energy spectrum, and lifts degeneracies. In the Minkowski limit $a\to 0$, the standard Kemmer oscillator spectrum is recovered, ensuring consistency with flat-spacetime results. These findings provide a tractable framework for analyzing acceleration-induced effects, with implications for quantum field theory in curved spacetime, quantum gravity, and analogue gravity platforms.

</details>


### [17] [Quintessential Inflation in Light of ACT DR6](https://arxiv.org/abs/2511.19898)
*Sayantan Choudhury,Swapnil Kumar Singh,Satish Kumar Sahoo*

Main category: gr-qc

TL;DR: 本文研究了平滑精粹暴胀模型，使用单个标量场统一了宇宙加速的两个阶段。该模型预测了红移的功率谱、极小的张量标量比，并预言了未来引力波探测器可观测的蓝移随机引力波背景。


<details>
  <summary>Details</summary>
Motivation: 探索如何用单个标量场统一描述宇宙暴胀和后期加速膨胀这两个加速阶段，构建一个最小化的精粹暴胀模型。

Method: 使用CMB归一化的指数势能，研究单个正则标量场的动力学，分析暴胀和精粹暗能量阶段的平滑过渡。

Result: 得到了精确的暴胀可观测量：n_s=0.964241，r=7.48×10^-5，所有可观测尺度在极窄的场区间Δφ≈0.03M_Pl内退出视界。预言了未来引力波探测器可探测的蓝移随机引力波背景。

Conclusion: 这个最小化的无特征模型不仅通过了当前观测限制，还提供了跨越20多个数量级引力波频率的具体可证伪预测。

Abstract: We perform a precision investigation of smooth quintessential inflation in which a single canonical scalar field unifies the two known phases of cosmic acceleration. Using a CMB-normalized runaway exponential potential, we obtain sharply predictive inflationary observables: a red-tilted spectrum with $n_s = 0.964241$ and an exceptionally suppressed tensor-to-scalar ratio $r = 7.48 \times 10^{-5}$ at $N=60$, lying near the optimal region of current Planck+ACT constraints. Remarkably, all observable scales exit the horizon within an extremely narrow field interval $Δφ\simeq 0.03\,M_{\rm Pl}$, tightly linking early and late-time dynamics and reducing theoretical ambiguities. While inflationary tensors remain invisible to CMB B-mode surveys, the subsequent stiff epoch-an intrinsic hallmark of quintessential cosmology-imprints a blue-tilted stochastic gravitational-wave background within the discovery reach of future interferometers such as LISA, DECIGO, ALIA, and BBO. Our results demonstrate that this minimal, featureless model not only survives current bounds, but provides concrete, falsifiable predictions across gravitational-wave frequencies spanning over twenty orders of magnitude.

</details>


### [18] [Designing Wormholes in Novel Power-Law $f(R)$: A Mathematical approach with a linear equation of state](https://arxiv.org/abs/2511.19901)
*Subhasis Nalui,Subhra Bhattacharya*

Main category: gr-qc

TL;DR: 本文在f(R)引力理论中研究具有线性状态方程的Morris-Thorne虫洞，构建了四种虫洞模型和对应的f(R)模型，分析了能量条件、标量张量表示，并探讨了光子球与复杂性因子的关系。


<details>
  <summary>Details</summary>
Motivation: 研究f(R)引力理论中具有线性状态方程的虫洞解，探索虫洞在修正引力理论中的存在条件和物理性质。

Method: 使用f(R)引力中的爱因斯坦场方程，构建虫洞解和对应的f(R)模型，通过标量张量对应和混合度规-Palatini形式验证解的鲁棒性。

Result: 获得了四种虫洞模型，其中两个具有立体角亏缺，三个不可渐近延拓，一个渐近平坦且零潮汐力。发现NEC满足的虫洞对应的f(R)模型存在鬼场问题。

Conclusion: 在f(R)引力中成功构建了可行的虫洞解，复杂性因子与光子球存在性的关系在f(R)引力中与爱因斯坦引力保持一致。

Abstract: We consider the inhomogeneous Morris-Thorne wormhole metric with matter tensors characterised by a novel linear equation of state in $f(R)$ gravity. Using the Einstein's field equations in metric $f(R)$ gravity we model solutions for both wormhole as well as $f(R)$ gravity. We obtain four different wormhole models, two wormholes are characterised by solid angle deficit, three are not asymptotically extendible, while one is asymptotically flat with zero tidal force. These are supported by four different power law $f(R)$ models. The parameter space of the models can support both null energy conditions (NEC) satisfying as well as violating wormhole. In case of NEC satisfying matter, the associated $f(R)$ is ghost. The $f(R)$ models obtained have been independently substantiated for cosmological feasibility and valid parameter space was obtained corresponding to cosmologically viable $f(R)$. Suitable scalar-tensor representation of the corresponding $f(R)$ models have been presented using the correspondence of $f(R)$ gravity with Brans-Dicke (BD) theory of gravity. The robustness of the wormhole solutions were further analysed with the BD scalar fields in the hybrid metric-Palatini gravity, which showed excellent results. Lastly as an independent astrophysical probe for the wormhole we have obtained the location of their photon spheres and have connected them with the Herrera Complexity factor in $f(R).$ Our results show that the relation between the complexity factor and existence of photon spheres remains fundamentally unaltered in $f(R)$ as compared to Einstein's gravity.

</details>


### [19] [Search for planetary-mass ultra-compact binaries using data from the first part of the LIGO--Virgo--KAGRA fourth observing run](https://arxiv.org/abs/2511.19911)
*The LIGO Scientific Collaboration,Virgo Collaboration,KAGRA Collaboration*

Main category: gr-qc

TL;DR: 使用LIGO、Virgo和KAGRA第四观测轮数据搜索行星质量超致密双星系统的引力波信号，未发现证据，据此推导了原初黑洞质量分布的约束条件。


<details>
  <summary>Details</summary>
Motivation: 寻找行星质量范围内的超致密双星系统引力波信号，为原初黑洞作为暗物质候选体提供新的观测约束。

Method: 分析LIGO、Virgo和KAGRA第四观测轮第一部分数据，搜索行星质量双星系统的引力波信号，计算最大探测距离和并合率密度。

Result: 未发现此类系统的引力波证据，获得了原初黑洞在质量范围[10^{-6},10^{-3}]太阳质量内的分布约束，与现有微引力透镜结果一致。

Conclusion: 引力波观测为行星质量原初黑洞提供了与微引力透镜互补的探测手段，对暗物质性质研究具有重要意义。

Abstract: We present a search for gravitational waves from inspiraling, planetary-mass ultra-compact binaries using data from the first part of the fourth observing run of LIGO, Virgo and KAGRA. Finding no evidence of such systems, we determine the maximum distance reach for such objects and their merger rate densities, independently of how they could have formed. Then, we identify classes of primordial black-hole mass distributions for which these rate limits can be translated into relevant constraints on the mass distribution of primordial black holes, assuming that they compose all of dark matter, in the mass range $[10^{-6},10^{-3}]M_\odot$. Our constraints are consistent with existing microlensing results in the planetary-mass range, and provide a complementary probe to sub-solar mass objects.

</details>


### [20] [Revisiting black holes and their thermodynamics in Einstein-Kalb-Ramond gravity](https://arxiv.org/abs/2511.19926)
*Zhong-Xi Yu,Hong-Da Lyu,Mandula Huhe,Shoulong Li*

Main category: gr-qc

TL;DR: 本文在爱因斯坦-卡尔布-拉蒙德引力理论中获得了两类精确的静态黑洞解，分析了热力学性质，并讨论了诺特质量对自发洛伦兹对称性破缺的约束作用。


<details>
  <summary>Details</summary>
Motivation: 爱因斯坦-卡尔布-拉蒙德引力理论中，卡尔布-拉蒙德场可以诱导自发洛伦兹对称性破缺，需要研究该框架下的黑洞解及其热力学性质。

Method: 在爱因斯坦-卡尔布-拉蒙德引力框架下，获得了具有一般拓扑视界的精确静态黑洞解，包含有无宇宙学常数的情况，并利用瓦尔德形式计算了诺特质量和熵。

Result: 得到了两类精确的静态黑洞解，建立了相应的黑洞热力学第一定律，并分析了诺特质量对自发洛伦兹对称性破缺的约束。

Conclusion: 爱因斯坦-卡尔布-拉蒙德引力理论支持具有一般拓扑视界的黑洞解，其热力学性质可以通过瓦尔德形式描述，诺特质量为约束自发洛伦兹对称性破缺提供了重要工具。

Abstract: Einstein-Kalb-Ramond gravity is an alternative theory of gravity in which a rank-two antisymmetric tensor field, known as the Kalb-Ramond field, is nonminimally coupled to gravity and can induce spontaneous Lorentz symmetry breaking when it acquires a nonzero vacuum expectation value. In this work, we revisit Einstein-Kalb-Ramond gravity and obtain two classes of exact static black hole solutions with general topological horizons in diverse dimensions within this framework, both with and without a cosmological constant. We further analyze their thermodynamic properties and employ the Wald formalism to compute the Noether mass and entropy, thereby establishing the corresponding first law of black hole thermodynamics. Finally, we discuss the implications of the Noether mass charge for constraining spontaneous Lorentz symmetry breaking within the framework of Einstein-Kalb-Ramond gravity.

</details>


### [21] [Spherically symmetric charged (anti-)de Sitter black hole in $f(R,T)$ gravity coupled with nonlinear electrodynamics](https://arxiv.org/abs/2511.20055)
*Tianyou Ren,Zhenglong Ban,Yaobin Hua,Rong-Jia Yang*

Main category: gr-qc

TL;DR: 在f(R,T)引力与非线性电动力学耦合框架下，推导出包含高阶修正项和有效宇宙学常数项的静态球对称带电解，分析黑洞视界结构、光子传播和阴影特征


<details>
  <summary>Details</summary>
Motivation: 研究非线性电动力学与物质-几何耦合在强场区域对黑洞时空结构的修正效应，探索超越标准广义相对论和麦克斯韦电动力学的引力-电磁相互作用

Method: 推导并求解f(R,T)引力与非线性电动力学耦合的场方程，获得静态球对称带电解，引入有效度规研究光子传播，分析视界结构、有效势、光子球半径和黑洞阴影

Result: 获得包含高阶修正的解，在远场区域退化为AdS/dS度规，强场区域显示显著修正；发现特定参数范围内出现多重视界现象；磁荷和耦合参数对有效势、光子球和阴影有系统性影响

Conclusion: f(R,T)引力与非线性电动力学的耦合在强场区域产生显著的时空修正，导致复杂的视界结构和光子传播特性，为研究超越标准理论的引力-电磁相互作用提供了新视角

Abstract: By deriving and solving the gravitational and electromagnetic field equations in $f(R,T)$ gravity coupled with nonlinear electrodynamics, we obtain a static spherically symmetric charged solution that incorporates higher-order correction terms along with an effective cosmological constant term. This solution reduces to the AdS/dS metric in the far-field region while exhibiting significant modifications in the strong-field regime due to the nonlinear electromagnetic effects and the matter-geometry coupling. We further analyze the black hole's horizon structure, revealing the complex phenomenon of multiple horizons emerging within specific parameter ranges. Additionally, by introducing an effective metric to study photon propagation, we systematically explore the influence of magnetic charge and the coupling parameter on the effective potential, the photon sphere radius, and the black hole shadow.

</details>


### [22] [Quasi-Normal Mode Ringing of Binary Black Hole Mergers in Scalar-Gauss-Bonnet Gravity](https://arxiv.org/abs/2511.20301)
*Zexin Hu,Daniela D. Doneva,Stoytcho S. Yazadjiev,Lijing Shao*

Main category: gr-qc

TL;DR: 通过完全非线性模拟研究标量-高斯-博内引力理论中双黑洞合并的准正则模式激发，发现与广义相对论相比模式激发变化较小，即使使用接近双曲性丧失极限的最大耦合参数。


<details>
  <summary>Details</summary>
Motivation: 双黑洞合并产生的引力波环降阶段包含一系列准正则模式，这些模式的激发幅度和相位依赖于前身系统特性，可用于探索强引力场中的引力理论偏差。

Method: 在位移对称标量-高斯-博内引力理论中执行自洽的完全非线性双黑洞合并模拟，提取准正则模式激发，并进行偏心度减少以验证结果稳健性。

Result: 数值验证模式频率与理论预测一致，提供了模式幅度和相位的拟合结果。发现模式激发变化相对较小，即使使用接近双曲性丧失极限的最大耦合参数。

Conclusion: 这些研究有助于理解标量-高斯-博内引力理论中的环降过程，为黑洞光谱学和并合一致性检验提供重要参考。

Abstract: Observations of gravitational waves (GWs) generated by binary black hole (BBH) mergers provide us with a powerful way to explore the strong and highly dynamical regime of gravity theories. The ringdown of BBH merger, consisting of a series of quasi-normal modes (QNMs), is of particular interest for both the black hole (BH) spectroscopy and the inspiral-merger-ringdown consistency check. Unlike the QNM frequencies that only depend on the properties of the remnant BH, the excitation amplitudes and phases of QNMs depend on the progenitor system, and calculating them is beyond the perturbative approach. In this paper, by performing self-consistent fully non-linear simulations of BBH merger in shift-symmetric scalar-Gauss-Bonnet (sGB) gravity as well as in sGB gravity allowing for scalarization, and extracting the QNM excitation, we explore the possible deviations from GR at the ringdown stage. We numerically verify that the mode frequencies are consistent with the theory prediction, and provide the fitting results of mode amplitudes and phases. We find relatively small changes in the mode excitation, considering that the largest coupling we used in the simulations is close to the limit of loss of hyperbolicity. To demonstrate that our results are robust against the eccentricity caused by the imperfect initial data, we also perform eccentricity reduction and estimate the effect caused by the initial eccentricity. These studies are useful for understanding the ringdown in sGB gravity.

</details>


### [23] [Multiscalar-metric gravity: merging gravity, dark energy and dark matter](https://arxiv.org/abs/2511.20393)
*Yu. F. Pirogov,O. V. Zenin*

Main category: gr-qc

TL;DR: 本文提出了一种修正的广义相对论——自发破缺相对论(SBR)，旨在统一引力、暗能量和暗物质。该理论基于多标量-度规时空概念，包含基本度规和可逆多标量场两种动力学结构。


<details>
  <summary>Details</summary>
Motivation: 寻求超越广义相对论的统一理论框架，将引力、暗能量和暗物质整合到一个自洽的理论中，通过自发对称破缺机制实现相对论的扩展。

Method: 采用多标量-度规时空概念，构建包含基本度规和可逆多标量场的扩展引力有效场理论（元引力理论），通过标量场作为引力希格斯场实现相对论对称性的自发破缺。

Result: SBR理论导致出现有质量的张量引力子和标量引力子，为统一引力与物质提供了新的理论框架，但同时也带来了一些需要进一步研究的问题。

Conclusion: 自发破缺相对论为超越广义相对论、统一引力与物质提供了有前景的理论方向，特别是在相对论和内部对称性破缺的背景下，但仍需深入研究其具体实现和物理后果。

Abstract: The status of a modification of General Relativity (GR) -- Spontaneously Broken Relativity (SBR) -- for merging gravity, dark energy (DE) and dark matter (DM) is presented. The modification is principally grounded on a multiscalar-metric concept of spacetime endowed with two dynamical structures: a basic metric and a set of the reversible multiscalar fields. The latter ones serve geometrically as exceptional dynamical coordinates among arbitrary kinematical/observer's ones and physically as a kind of gravitational Higgs fields producing possible spontaneous breaking of the symmetry (SSB) of relativity. The effective field theory (EFT) of the extended gravity based on the multiscalar-metric spacetime -- the metagravity -- is discussed and some of its particular realizations beyond GR as SBR are explicated. Physically, SBR results in appearance of massive tensor and scalar gravitons. Some of the emerging consequences, problems and prospects for SBR for future deeper unification of gravity with matter in the context of the relativity and internal symmetries breaking are shortly discussed.

</details>


### [24] [Canonical form of a deformed Poisson bracket spacetime](https://arxiv.org/abs/2511.20425)
*Douglas M. Gingrich*

Main category: gr-qc

TL;DR: 本文通过构建一个哈密顿量，将应用广义不确定性原理的重力理论从非正则形式转化为正则且协变的形式，并实现了与标量物质和尘埃的协变耦合。


<details>
  <summary>Details</summary>
Motivation: 应用广义不确定性原理的重力理论在正则形式下表现为修正的泊松括号，导致理论非正则且难以保证协变性。本文旨在解决这一问题，使理论既保持正则性又具有协变性。

Method: 构建一个特定的哈密顿量，应用标准正则形式化方法，确保生成闭合代数，并得到与使用扭曲泊松括号相同的原始度规。

Result: 成功将理论转化为正则且协变的形式，实现了与标量物质和尘埃的协变耦合，为研究动力学提供了基础。

Conclusion: 通过适当的哈密顿量构建，可以解决广义不确定性原理重力理论中的正则性和协变性矛盾，为后续动力学研究铺平道路。

Abstract: The general uncertainty principle applied to gravity can be implemented as a set of modified Poisson brackets in the canonical formalism. As such, the theory is not canonical and the resulting equations of motion, diffeomorphism constraint, and Hamiltonian constraint are unlikely to lead to a covariant metric. We construct a Hamiltonian that when applying the usual canonical formalism gives a closed algebra and equations of motion that result in the original metric obtained by using distorted Poisson brackets. The resulting theory is thus rendered canonical and covariant. We then covariantly couple scalar matter and dust to the modified gravity to allow the study of dynamics.

</details>


### [25] [The Globally Trapped Future: A Fate for Black Holes and Wormholes](https://arxiv.org/abs/2511.20427)
*Yi-bo Liang,Hong-Rong Li*

Main category: gr-qc

TL;DR: 提出了一种新的广义动力学度量，通过推广史瓦西基础，明确了全局因果结构和捕获视界，建立了时空的三种可能命运：无全局捕获未来、无全局捕获但包含有界柯西叶状捕获区域、以及未来完全全局捕获。


<details>
  <summary>Details</summary>
Motivation: 通过推广史瓦西基础来探索时空的全局因果结构和捕获视界的演化，建立新的动力学度量框架，揭示时空演化的不同可能性。

Method: 通过推广史瓦西基础得到新的广义动力学度量，分析全局因果结构和捕获视界，分类时空的三种可能演化命运。

Result: 建立了时空演化的三种可能命运，并通过几何上类似史瓦西的黑洞和无视界虫洞的演化来说明这些可能性，特别是确立了未来完全全局捕获这一新的理论可能性。

Conclusion: 该框架为理解时空演化提供了新的视角，特别是未来完全全局捕获的命运为理论物理学提供了新的可能性。

Abstract: A new general dynamical metric is obtained through a generalization of the Schwarzschild foundations, explicitly providing the global causal structure and trapping horizons and establishing three possible fates of the spacetime: those without a globally trapped future; those without global trapping but containing bounded, Cauchy-foliated trapped regions; and those with a future that becomes completely globally trapped. This framework is illustrated through the evolution of a geometrically Schwarzschild-like black hole and a horizonless wormhole, thereby establishing the final, globally trapped fate as a novel theoretical possibility.

</details>


### [26] [Resolving white dwarf binaries within globular clusters with LISA](https://arxiv.org/abs/2511.20435)
*Wouter G. J. van Zeist,Gijs Nelemans,Shu-Xu Yi,Simon F. Portegies Zwart*

Main category: gr-qc

TL;DR: 研究LISA能否通过天球位置和距离测量分辨银河系球状星团中的白矮星双星，使其能与银河系盘中的双星区分开来。


<details>
  <summary>Details</summary>
Motivation: 银河系球状星团预计包含可被LISA探测到的白矮星双星引力波源，需要确定这些源能否与银河系盘中的双星区分开。

Method: 使用20个最巨大的银河系球状星团样本，通过GWToolbox软件模拟LISA对这些星团中白矮星双星的天球位置和距离测量误差，结合SeBa种群合成代码的银河系可探测双星模型。

Result: 5个星团仅凭天球位置即可区分，另外5个需要结合天球位置和距离测量才能区分，最后10个无法与银河系盘双星区分。结果强烈依赖于星团的天球位置，远离银道面的星团容易分辨，靠近银心的星团与银河系盘双星重叠。最有前景的星团是杜鹃座47。

Conclusion: LISA能够分辨部分球状星团中的白矮星双星，特别是那些远离银道面的星团，而杜鹃座47是最有希望发现可分辨双星的星团。

Abstract: Context: Globular clusters (GCs) around the Milky Way (MW) are expected to host white dwarf (WD) binaries emitting gravitational waves that could be detectable by LISA.
  Aims: Our aim is to investigate whether LISA can resolve WD binaries in GCs well enough in terms of sky location and distance that they can be distinguished from binaries in the MW disc.
  Methods: We used a sample of 20 of the most massive GCs around the MW and simulated LISA's sky location and distance measurement errors for WD binaries in these GCs using the software package GWToolbox. We did this in the context of a model of the LISA-detectable binaries in the MW from the population synthesis code SeBa.
  Results: We find that for five of the GCs in our sample, binaries in the GC could be easily distinguished from MW disc binaries using the sky location alone; for another five, binaries in the GCs could be distinguished using a combination of LISA's sky location and distance measurements; and for the final ten, binaries in the GCs could not be distinguished from overlapping MW disc binaries. The results depend strongly on the sky locations of the GCs, with GCs far away from the Galactic plane being easy to resolve, while GCs close to the Galactic centre overlap with many MW disc binaries. The most promising GC for finding a WD binary that could be resolved to that GC, based on sky location and GC mass, is 47 Tucanae.

</details>


### [27] [The Inflationary Dynamics with the Scalar-Tensor Model](https://arxiv.org/abs/2511.20464)
*Feyzollah Younesizadeh,Davoud Kamani*

Main category: gr-qc

TL;DR: 研究具有标量依赖非最小动能耦合的标量张量模型中的宇宙暴胀，计算关键观测量的理论预测并与Planck数据比较。


<details>
  <summary>Details</summary>
Motivation: 在具有标量依赖非最小动能耦合的标量张量模型框架下研究宇宙暴胀，探索这类模型的理论预测与观测数据的一致性。

Method: 使用慢滚近似计算理论预测，包括谱指数n_s、张标比r和标量谱指数跑动α_s，并与Planck观测数据进行比较分析。

Result: 获得了模型自由参数与关键观测量之间的关系，确定了参数的约束范围，并与最新观测数据进行了对比验证。

Conclusion: 该标量张量模型能够提供与观测一致的暴胀预测，同时分析了观测量对模型参数的敏感性。

Abstract: We investigate the cosmic inflation within a class of the scalar-tensor model with the scalar-dependent non-minimal kinetic couplings. The inflationary dynamical potential will be applied. Using the slow-roll approximation, we compute theoretical predictions for the key observables, like the spectral indexes $n_s$, scalar-to-tensor ratio $r$ and the running of the scalar spectral index $α_s$ in terms of the free parameters of the model. Besides, we find the limitations of these parameters. In addition, these quantities will be compared with the latest observational data from the Planck data. Furthermore, we analyze the sensitivity of $r$, $n_s$ and $α_s$ in terms of the model's free parameters.

</details>


### [28] [Anisotropic Bianchi-I cosmological model in non-conservative unimodular gravity](https://arxiv.org/abs/2511.20486)
*Marcelo H. Alvarenga,Júlio C. Fabris*

Main category: gr-qc

TL;DR: 本文在非保守单模引力框架下提出了各向异性Bianchi-I型宇宙学模型，通过引入对(ρ+p)的额外条件解决了场方程的不确定性，分析了不同物质状态下的宇宙演化行为。


<details>
  <summary>Details</summary>
Motivation: 研究非保守单模引力中各向异性宇宙学模型的可行性，解决场方程的不确定性，探索不同物质状态下的宇宙演化规律。

Method: 使用Bianchi-I型度规，在非保守单模引力框架下引入对(ρ+p)的额外约束条件，分析真空情况、非齐次状态方程以及不同比例关系下的宇宙动力学。

Result: 发现宇宙动力学严格依赖于常数l的值，当l<0时出现超加速的类幽灵宇宙；在(ρ+p)∝a^{-3}和a^{-4}情况下与广义相对论描述的各向异性宇宙模型一致；各向异性参数Ω_A需为10^{-2}量级才能符合宇宙年龄观测。

Conclusion: 非保守单模引力中的各向异性宇宙模型能够描述宇宙演化，各向异性随宇宙膨胀逐渐消失，与广义相对论中的各向异性模型行为相似，但需要进一步从热力学角度分析l<0的情况。

Abstract: In this article, we propose an anisotropic Bianchi-I type cosmological model in non-conservative Unimodular Gravity ($\mathrm{NUG}$). We show that simply using the Bianchi-I type metric does not resolve a striking characteristic of the field equations in $\mathrm{NUG}$: their underdetermination. This fact led us to implement extra conditions on the combination $\left(ρ+p\right)$ and, consequently, obtain a consistent background cosmological analysis. In the vacuum case, we obtain an analogy between the Kasner solutions and the equations in $\mathrm{NUG}$. We also propose a new analysis of a non-homogeneous equation of state, the combination $\left(ρ+p\right)=l$. We identify that the cosmological dynamics are strictly dependent on the value of the constant $l$. The physically interesting case is at the value $l<0$, which seems to indicate a super-accelerated, ghost-like universe. This case still requires a more detailed analysis, for example, from a thermodynamic point of view, keeping in mind that $\left(ρ+p\right)$ may be interpreted as enthalpy of the system. For the cases $\left(ρ+p\right)\propto a^{-3}$ and $\left(ρ+p\right) \propto a^{-4}$, we obtain a description consistent with the anisotropic cosmological model described by $\mathrm{GR}$. In all cases analyzed, a small value for the anisotropic parameter $Ω_{A}$ (on the order of $10^{-2}$) is required in order to have agreement, for example, with the age of the universe to be approximately $12-14\, \mathrm{Gyr}$, agreeing with the age of globular clusters. As the universe expands an isotropization is verified, with the anistropies going to zero asymptotically, similarly with what happens in an anistropic cosmological model based on $\mathrm{GR}$.

</details>


### [29] [Natural inflation in Palatini $F(R)$](https://arxiv.org/abs/2511.20557)
*N. Bostan,R. H. Dejrah,C. Dioguardi,A. Racioppi*

Main category: gr-qc

TL;DR: F(R) Palatini引力框架下，自然暴胀模型在特定参数范围内（7/4 ≲ n ≤ 2）与观测数据一致，而n>2的模型只有在n→2极限下才能部分符合数据。


<details>
  <summary>Details</summary>
Motivation: 研究F(R) Palatini引力如何恢复自然暴胀模型与观测数据的一致性，探索该框架下可行的暴胀势能构造。

Method: 将自然暴胀模型嵌入F(R) Palatini引力框架，具体采用F(R) = R + αR^n形式，分析不同n值下模型与观测数据的匹配程度。

Result: 当7/4 ≲ n ≤ 2时，自然暴胀模型与观测数据完全一致；当n > 2时，模型仅在n→2极限下部分符合数据。

Conclusion: F(R) Palatini引力为自然暴胀模型提供了可行的理论框架，在特定参数范围内能够恢复其与观测数据的一致性。

Abstract: $F(R)$ Palatini gravity provides a robust framework for constructing viable inflationary potentials. In this study, we examine natural inflation and show that its consistency with observational data can be restored when the model is embedded within $F(R)$ Palatini gravity, specifically for $F(R) = R + αR^n$ with $7/4 \lesssim n \leq 2$. For completeness, we also demonstrate that models with $n > 2$ do not yield comparable improvements, achieving partial agreement with the data only in the limit $n \rightarrow 2$.

</details>


### [30] [Gravitational collapse in the vicinity of the extremal black hole critical point](https://arxiv.org/abs/2511.20567)
*William E. East*

Main category: gr-qc

TL;DR: 本文研究了爱因斯坦-麦克斯韦-弗拉索夫方程控制下球对称时空中的引力坍缩阈值，发现了两种不同参数区域中的临界解：亚临界区域的稳态无视界壳层和超临界区域的极端黑洞。


<details>
  <summary>Details</summary>
Motivation: 研究带电物质在引力坍缩过程中的临界行为，探索从坍缩到黑洞形成或最终弥散之间的阈值条件，特别是电荷与质量比接近1时的临界现象。

Method: 通过数值方法构造球对称时空中的带电物质坍缩解，分析参数空间中不同区域的行为，测量近临界解的动力学时间尺度标度律。

Result: 发现参数空间存在两个区域：亚临界区域中临界解为稳态无视界壳层，电荷质量比从下方趋近1；超临界区域中临界解为极端黑洞。临界点处不稳定时间尺度发散。

Conclusion: 这种临界行为模式如果适用于已知的旋转物质稳态解族，可能为形成极端旋转黑洞提供一条途径。

Abstract: We study the threshold of gravitational collapse in spherically symmetric spacetimes governed by the Einstein-Maxwell-Vlasov equations. We numerically construct solutions describing a collapsing distribution of charged matter that either forms a charged black hole or eventually disperses. We first consider a region of parameter space where the solutions at the threshold of black hole formation are stationary, horizonless shells. These solutions terminate at a critical point, with their charge-to-mass ratio approaching unity from below, and the instability timescale diverging. Beyond the critical point, we find a new region of parameter space where the threshold solution is an extremal black hole. We measure the scaling of the dynamical time period of the near threshold solutions and discuss how they are connected in the two regimes. If a similar picture to the one found here holds for known families of stationary solutions of rotating matter that approach the exterior of an extremal Kerr spacetime, they could provide a route to forming an extremal spinning black hole.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [31] [Probabilistic Bounds on the Number of Elements to Generate Finite Nilpotent Groups and Their Applications](https://arxiv.org/abs/2511.19494)
*Ziyuan Dong,Xiang Fan,Tengxun Zhong,Daowen Qiu*

Main category: quant-ph

TL;DR: 本文建立了有限幂零群生成元素数量的新概率界限，基于群秩和群链长度给出了比之前基于群阶更紧的生成概率下界，这些界限被证明是近乎紧的。


<details>
  <summary>Details</summary>
Motivation: 改进有限幂零群生成概率的界限，为概率算法分析提供基础工具，特别是用于优化有限阿贝尔隐藏子群问题量子算法和Regev因式分解算法的迭代次数。

Method: 通过群秩和群链长度两个参数建立生成概率下界，证明当k ≥ rank(G) + ⌈log₂(2/ε)⌉ 或 k ≥ len(G) + ⌈log₂(1/ε)⌉时，φₖ(G) ≥ 1-ε。

Result: 得到了比之前基于群阶的界限更紧的概率下界，这些界限被证明是近乎紧的，能够显著减少量子算法所需的迭代次数和电路重复次数。

Conclusion: 新的概率界限为分析概率算法提供了更好的理论基础，能够优化量子算法的性能，特别是在有限阿贝尔隐藏子群问题和因式分解算法中具有重要应用价值。

Abstract: This work establishes a new probabilistic bound on the number of elements to generate finite nilpotent groups. Let $\varphi_k(G)$ denote the probability that $k$ random elements generate a finite nilpotent group $G$. For any $0 < ε< 1$, we prove that $\varphi_k(G) \ge 1 - ε$ if $k \ge \operatorname{rank}(G) + \lceil \log_2(2/ε) \rceil$ (a bound based on the group rank) or if $k \ge \operatorname{len}(G) + \lceil \log_2(1/ε) \rceil$ (a bound based on the group chain length). Moreover, these bounds are shown to be nearly tight. Both bounds sharpen the previously known requirement of $k \ge \lceil \log_2 |G| + \log_2(1/ε) \rceil + 2$. Our results provide a foundational tool for analyzing probabilistic algorithms, enabling a better estimation of the iteration count for the finite Abelian hidden subgroup problem (AHSP) standard quantum algorithm and a reduction in the circuit repetitions required by Regev's factoring algorithm.

</details>


### [32] [A Quantum-Classical Hybrid Branch & Bound Algorithm](https://arxiv.org/abs/2511.19501)
*András Czégel,Dávid Sipos,Boglárka G. -Tóth*

Main category: quant-ph

TL;DR: 提出了一种完整的量子-经典混合分支定界算法(QCBB)来解决带等式约束的二进制线性规划问题，该算法具有边界计算、收敛度量和最优性保证等特性。


<details>
  <summary>Details</summary>
Motivation: 将量子优化方法封装到经典分支定界框架中，使量子优化算法能够与经典方法直接比较，并利用噪声样本进行问题简化。

Method: 采用量子-经典混合方法，包括量子优化封装、噪声样本利用、经典近似边界计算、基于间隙的停止准则和单调解质量提升等分支定界特性。

Result: 在集合划分问题实例上展示了数值结果，并详细分析了算法不同步骤的特性。

Conclusion: QCBB算法成功将量子优化整合到经典分支定界框架中，为量子优化算法提供了完整的比较基准和性能评估方法。

Abstract: We propose a complete quantum-classical hybrid branch-and-bound algorithm (QCBB) to solve binary linear programs with equality constraints. That includes bound calculation, convergence metrics and optimality guarantee to the quantum optimization based algorithm, which makes our method directly comparable to classical methods. Key aspects of the proposed algorithm are (i) encapsulation of the quantum optimization method, (ii) utilization of noisy samples for problem reduction, (iii) classical approximation based bound calculation, (iv) branch and bound traits like gap-based stopping criterion and monotonic increase in solution quality, (v) integrated composition of many different solutions that can be improved individually. We show numerical results on set partitioning problem instances and provide many details about the characteristics of the different steps of the algorithm.

</details>


### [33] [SPARTA: $χ^2$-calibrated, risk-controlled exploration-exploitation for variational quantum algorithms](https://arxiv.org/abs/2511.19551)
*Mikhail Zubarev*

Main category: quant-ph

TL;DR: 提出了SPARTA算法，首个具有有限样本保证的变分量子优化方法，通过序列测试识别贫瘠高原，结合探索和利用策略实现收敛。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法面临贫瘠高原问题，随着系统规模增大，优化变得指数级困难。现有理论虽然能精确描述高原出现条件，但缺乏具有有限样本保证的实用优化方法。

Method: SPARTA算法包含三个核心组件：(1)基于χ²校准的序列测试，使用似然比超鞅区分贫瘠高原和信息区域；(2)概率信任区域探索策略，具有单边接受机制防止在shot噪声下的虚假改进；(3)理论最优的利用阶段，达到最佳收敛速率。

Result: 证明了高原退出时间的几何界限，在信息盆地中的线性收敛，以及李代数方差代理在不影响统计校准的情况下增强测试能力。

Conclusion: SPARTA是首个提供显式、随时有效风险控制的量子优化调度器，为变分量子算法提供了实用的优化解决方案。

Abstract: Variational quantum algorithms face a fundamental trainability crisis: barren plateaus render optimization exponentially difficult as system size grows. While recent Lie algebraic theory precisely characterizes when and why these plateaus occur, no practical optimization method exists with finite-sample guarantees for navigating them. We present the sequential plateau-adaptive regime-testing algorithm (SPARTA), the first measurement-frugal scheduler that provides explicit, anytime-valid risk control for quantum optimization. Our approach integrates three components with rigorous statistical foundations: (i) a $χ^2$-calibrated sequential test that distinguishes barren plateaus from informative regions using likelihood-ratio supermartingales; (ii) a probabilistic trust-region exploration strategy with one-sided acceptance to prevent false improvements under shot noise; and (iii) a theoretically-optimal exploitation phase that achieves the best attainable convergence rate. We prove geometric bounds on plateau exit times, linear convergence in informative basins, and show how Lie-algebraic variance proxies enhance test power without compromising statistical calibration.

</details>


### [34] [Modelling and experimental verification of photoelectrical response of NV diamond spin centres](https://arxiv.org/abs/2511.19583)
*Josef Soucek,Michael Petrov,Michal Gulka,Emilie Bourgeois,Milos Nesladek*

Main category: quant-ph

TL;DR: 开发了一个用于金刚石中NV色心光电响应的数学模型，该模型包含载流子漂移收集、缺陷动力学和多能级系统，可用于优化NV量子比特的光电读出性能。


<details>
  <summary>Details</summary>
Motivation: 虽然NV缺陷的光致发光读出已被广泛研究，但目前还没有包含载流子漂移收集和缺陷动力学的精确光电读出模型。

Method: 使用多能级系统（包括mS=0、mS=±1基态和激发态、单重态和NV0中性态），结合玻尔兹曼输运方程建模电荷输运和能级占据动力学。

Result: 计算了ODMR和PDMR响应及其量子效率，确定了量子比特操作的最佳参数空间，特别是与替代氮（NS）存在相关的最高自旋对比度。

Conclusion: 该模型经过实验验证，可成为优化NV量子比特光电读出性能的有用工具，且稍作修改即可应用于其他半导体固态量子比特。

Abstract: We report on a mathematical model of the photoelectric response of NV colour centres in diamond, that can be employed for sensing and quantum science information applications. Although the model applies to NV centre in diamond, it can be applied with small modifications to other semiconducting solid state qubits. In our model, we include the drift and collection of charge carriers as well as the presence of other defects via generation and recombination dynamics. Though the photoluminescence readout and the associated dynamics of the NV defect has been extensively studied experimentally and theoretically, so far, there has been no precise model for photocurrent readout, including these effects. In our description, we use a multilevel-level system including mS=0, mS=+-1 ground and excited states, singlet state and the NV0 neutral state. Also, the presence of substitutional nitrogen (NS), which for example determines the spin coherence via the paramagnetic spin bath, is discussed together with presence of acceptor defects. We model the time-dependent occupation of all electronic sublevels and also consider the electronic charge transport from the Boltzmann transport equation, leading to information about the charge state transitions and recombination dynamics. ODMR and PDMR response as well as their quantum efficiencies, are calculated. On this basis, we determine an optimal parameter space for qubit operations, including the highest spin contrast and especially relate those to NS presence. The model is confirmed experimentally and can become a useful tool for optimisation of the performance of NV qubit photoelectric readout.

</details>


### [35] [Monogamy of Mutual Information in Graph States](https://arxiv.org/abs/2511.19585)
*Jesus Fuentes,Cynthia Keeler,William Munizzi,Jason Pollack*

Main category: quant-ph

TL;DR: 该论文研究了图态中互信息单调性(MMI)的违反现象，将其视为禁止子图问题，并证明了对于星形图族，MMI违反的图态在局部Clifford等价下必然包含四星子图。


<details>
  <summary>Details</summary>
Motivation: 研究量子熵不等式MMI在图态中的违反机制，探索其与图结构的关系，特别是作为禁止子图现象来理解。

Method: 构建星形图族分析MMI违反实例，推导邻接矩阵约束条件，通过物理解释和8量子比特稳定子熵向量的穷举搜索进行验证。

Result: 证明了对于星形图族，MMI违反的图态必然包含四星子图，但发现MMI违反不能完全归约到所研究的案例范围内。

Conclusion: MMI违反在图态中表现为禁止子图现象，但存在超出研究范围的违反情况，表明该问题具有更复杂的结构特性。

Abstract: The monogamy of mutual information (MMI) is a quantum entropy inequality that enforces the non-positivity of tripartite information. We investigate the failure of MMI in graph states as a forbidden-subgraph phenomenon, conjecturing that every MMI-violating graph state is local-Clifford equivalent to one whose graph contains a four-star subgraph. We construct a family of star-like graphs whose states fail a specific class of MMI instances, and extend this analysis to general star topologies. Deriving adjacency matrix constraints that fix the MMI evaluation for these instances and interpreting them physically, we prove the forbidden-subgraph conjecture for this family of graphs. Finally, through an exhaustive search over graph representatives for all $8$-qubit stabilizer entropy vectors, we establish that MMI failure is not reducible to the cases within our scope.

</details>


### [36] [Holographic duality between bulk topological order and boundary mixed-state order](https://arxiv.org/abs/2511.19597)
*Tsung-Cheng Lu,Yu-Jie Liu,Sarang Gopalakrishnan,Yizhi You*

Main category: quant-ph

TL;DR: 本文提出了一个全息框架，用于分析具有强对称性的重复量子通道的稳态。通过通道-态对偶，将d维量子通道的稳态映射到(d+1)维波函数的边界约化密度矩阵，揭示了稳态中的强到弱自发对称性破缺源于高维拓扑序的任意子凝聚。


<details>
  <summary>Details</summary>
Motivation: 研究具有强对称性的量子通道的稳态性质，特别是强到弱自发对称性破缺现象，并建立与高维拓扑序的联系。

Method: 使用通道-态对偶将量子通道映射到高维波函数，采用等距张量网络态框架，将通道时间演化识别为高维等距张量网络的转移矩阵。

Result: 建立了稳态中强到弱自发对称性破缺与高维拓扑序边界任意子凝聚的对偶关系，条件互信息继承自体拓扑纠缠熵，并构建了可连续调谐的量子通道展示不同混合态相和相变。

Conclusion: 该全息框架为理解量子通道稳态中的对称性破缺提供了新的几何视角，揭示了低维量子动力学与高维拓扑序之间的深刻联系。

Abstract: We introduce a holographic framework for analyzing the steady states of repeated quantum channels with strong symmetries. Using channel-state duality, we show that the steady state of a $d$-dimensional quantum channel is holographically mapped to the boundary reduced density matrix of a $(d+1)$-dimensional wavefunction generated by a sequential unitary circuit. From this perspective, strong-to-weak spontaneous symmetry breaking (SWSSB) in the steady state arises from the anyon condensation on the boundary of a topological order in one higher dimension. The conditional mutual information (CMI) associated with SWSSB is then inherited from the bulk topological entanglement entropy. We make this duality explicit using isometric tensor network states (isoTNS) by identifying the channel's time evolution with the transfer matrix of a higher-dimensional isoTNS. Built on isoTNS, we further construct continuously tunable quantum channels that exhibit distinct mixed-state phases and transitions in the steady states.

</details>


### [37] [Berry's phase on photonic quantum computers](https://arxiv.org/abs/2511.19598)
*Steven Abel,Iwo Wasek,Simon Williams*

Main category: quant-ph

TL;DR: 提出了一种连续变量量子计算算法，在光子量子计算机上研究贝里相位，使用被动线性光学操作模拟带电粒子在变化磁场中的行为，并在实验平台上成功观测到贝里相位现象。


<details>
  <summary>Details</summary>
Motivation: 研究如何在光子量子计算机上实现贝里相位的模拟，利用连续变量量子计算框架来研究带电粒子在绝热变化磁场中的量子几何相位现象。

Method: 使用连续变量量子计算算法，仅采用被动线性光学操作（分束器和相位移动器），在单光子光子架构中实现贝里相位的模拟，并在Quandella Ascella平台上进行实验验证。

Result: 成功在实验平台上观测到贝里相位现象，并通过干涉测量验证了结果。还将框架推广到更快速的非绝热演化，通过连接反对称磁场的Aharonov-Anandan循环，实现了动态相位和主要非几何误差的对称抵消。

Conclusion: 连续变量量子计算方法能够有效模拟贝里相位，被动线性光学操作在光子量子计算中具有实验可行性，几何相位贡献具有内在鲁棒性，为量子几何相位研究提供了新的实验平台。

Abstract: We formulate a continuous-variable quantum computing (CVQC) algorithm to study Berry's phase on photonic quantum computers. We demonstrate that CVQC allows the simulation of charged particles with orbital angular momentum under the influence of an adiabatically changing $\vec{B}$ field. Although formulated entirely in the CVQC setting, our construction uses only passive linear-optical operations (beam splitters and phase shifts), which act identically in single-photon photonic architectures. This enables experimental realisation on the Quandella Ascella platform, where we observe the Berry's phase phenomenon with interferometric measurement. We also generalise the framework to more rapid non-adiabatic evolution. By concatenating Aharonov-Anandan cycles for opposing magnetic fields we demonstrate that one can engineer a circuit in which dynamical phases and leading non-geometric errors cancel by symmetry, leaving the intrinsically robust geometric phase contribution.

</details>


### [38] [No-go theorems for sequential preparation of two-dimensional chiral states via channel-state correspondence](https://arxiv.org/abs/2511.19612)
*Ruihua Fan,Yantao Wu,Yimu Bao,Zhehao Dai*

Main category: quant-ph

TL;DR: 该论文证明了两类二维手性态无法通过顺序幺正电路制备的不可行定理：高斯费米子系统因平移不变性无法支持代数衰减关联，一般相互作用系统因因果性约束无法容纳手性态的三体纠缠。


<details>
  <summary>Details</summary>
Motivation: 研究顺序幺正电路是否能制备二维手性态，探索手性态与等距张量网络态、量子信道电路之间的对应关系。

Method: 建立顺序制备态、等距张量网络态和一维量子信道电路之间的对应关系，分别针对高斯费米子系统和一般相互作用系统证明不可行定理。

Result: 证明了两个不可行定理：1）高斯费米子系统无法支持代数衰减关联；2）一般相互作用系统无法容纳手性态的三体纠缠。

Conclusion: 二维手性态无法通过顺序幺正电路制备，这对手性拓扑态的制备方案提出了重要限制。

Abstract: We investigate whether sequential unitary circuits can prepare two-dimensional chiral states, using a correspondence between sequentially prepared states, isometric tensor network states, and one-dimensional quantum channel circuits. We establish two no-go theorems, one for Gaussian fermion systems and one for generic interacting systems. In Gaussian fermion systems, the correspondence relates the defining features of chiral wave functions in their entanglement spectrum to the algebraic decaying correlations in the steady state of channel dynamics. We establish the no-go theorem by proving that local channel dynamics with translational invariance cannot support such correlations. As a direct implication, two-dimensional Gaussian fermion isometric tensor network states cannot support algebraically decaying correlations in all directions or represent a chiral state. In generic interacting systems, we establish a no-go theorem by showing that the state prepared by sequential circuits cannot host the tripartite entanglement of a chiral state due to the constraints from causality.

</details>


### [39] [Quantum Hardware-Efficient Selection of Auxiliary Variables for QUBO Formulations](https://arxiv.org/abs/2511.19613)
*Damian Rovara,Lukas Burgholzer,Robert Wille*

Main category: quant-ph

TL;DR: 提出了一种针对有限连接量子架构的辅助变量选择新方法，通过构建具有规则结构和有限顶点最大度的交互图，使QAOA电路能高效映射到各种架构，相比传统方法减少近40%的电路深度。


<details>
  <summary>Details</summary>
Motivation: 传统辅助变量选择算法只关注最小化变量数量，而不考虑量子计算机的连接性约束，导致交互图与目标设备不兼容，产生大量编译开销。

Method: 为有限连接架构量身定制的辅助变量选择方法，专门构建具有规则结构和有限顶点最大度的交互图。

Result: 相比使用传统辅助选择方法构建的QUBO电路，所提方法将电路深度减少了近40%。

Conclusion: 该方法能有效构建可高效映射到多种架构的QAOA电路，显著降低电路深度，提高量子计算效率。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) requires considered optimization problems to be translated into a compatible format. A popular transformation step in this pipeline involves the quadratization of higher-order binary optimization problems, translating them into Quadratic Unconstrained Binary Optimization (QUBO) formulations through the introduction of auxiliary variables. Conventional algorithms for the selection of auxiliary variables often aim to minimize the total number of required variables without taking the constraints of the underlying quantum computer-in particular, the connectivity of its qubits-into consideration. This quickly results in interaction graphs that are incompatible with the target device, resulting in a substantial compilation overhead even with highly optimized compilers. To address this issue, this work presents a novel approach for the selection of auxiliary variables tailored for architectures with limited connectivity. By specifically constructing an interaction graph with a regular structure and a limited maximal degree of vertices, we find a way to construct QAOA circuits that can be mapped efficiently to a variety of architectures. We show that, compared to circuits constructed from a QUBO formulation using conventional auxiliary selection methods, the proposed approach reduces the circuit depth by almost 40%. An implementation of all proposed methods is publicly available at https://github.com/munich-quantum-toolkit/problemsolver.

</details>


### [40] [Shake before use: universal enhancement of quantum thermometry by unitary](https://arxiv.org/abs/2511.19631)
*Emanuele Tumbiolo,Lorenzo Maccone,Chiara Macchiavello,Matteo G. A. Paris,Giacomo Guarnieri*

Main category: quant-ph

TL;DR: 本文证明任何依赖于温度的单幺正驱动都能增强热化探针的量子Fisher信息，提供了一种通用的非平衡温度计量方法。


<details>
  <summary>Details</summary>
Motivation: 标准平衡方法受限于静态能量涨落给出的量子Fisher信息，在固定温度窗口外失去灵敏度。需要开发非平衡策略来克服这些限制。

Method: 通过分析温度依赖的幺正驱动对热化探针的影响，建立了信息流核函数来量化统计可区分性的流动。

Result: 任何温度依赖的幺正驱动都能增强量子Fisher信息，谐振调制能恢复Fisher信息的时间二次标度，并允许在任意温度范围内移动灵敏度峰值。

Conclusion: 外部幺正控制是精密计量学的通用资源，为量子传感的未来实现铺平了道路。

Abstract: Quantum thermometry aims at determining temperature with ultimate precision in the quantum regime. Standard equilibrium approaches, limited by the Quantum Fisher Information given by static energy fluctuations, lose sensitivity outside a fixed temperature window. Non-equilibrium strategies have therefore been recently proposed to overcome these limits, but their advantages are typically model-dependent or tailored for a specific purpose. This Letter establishes a general, model-independent result showing that any temperature-dependent unitary driving applied to a thermalized probe enhances its quantum Fisher information with respect to its equilibrium value. Such information gain is expressed analytically through a positive semi-definite kernel of information currents that quantify the flow of statistical distinguishability. Our results are benchmarked on a driven spin-$1/2$ thermometer, furthermore showing that resonant modulations remarkably restore the quadratic-in-time scaling of the Fisher information and allow to shift the sensitivity peak across arbitrary temperature ranges. Our findings identify external unitary control as a universal resource for precision metrology and pave the way for future implementations in quantum sensing.

</details>


### [41] [High-Order Splitting of Non-Unitary Operators on Quantum Computers](https://arxiv.org/abs/2511.19659)
*Peter Brearley,Philipp Pfeffer*

Main category: quant-ph

TL;DR: 提出一种高阶分裂方法，通过顺序实时间和虚时间哈密顿演化来模拟非幺正动力学，避免了高阶实系数分裂方法中的不稳定负步长问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种在量子电路中稳定模拟非幺正动力学的方法，特别是针对自然分离为幺正和耗散分量的系统，这在科学和工程领域有广泛应用。

Method: 使用具有正实部的复系数分裂方法，在量子电路中实现稳定积分。通过推导高效量子电路来模拟阻尼波方程，达到时间上的六阶精度。

Result: 在三维空间中，单个六阶步长可在350亿个单元上执行，仅需1,562个CNOT门，可在现代量子处理器的相干时间内完成。

Conclusion: 该方法为模拟非幺正动力学提供了一种高效稳定的量子电路实现方案，特别适用于具有紧凑谱表示的分离算子系统。

Abstract: We present a high-order splitting method for simulating non-unitary dynamics by sequential real- and imaginary-time Hamiltonian evolutions. Complex-coefficient splitting methods with positive real parts are chosen for stable integration in a quantum circuit, avoiding the unstable, norm-amplifying negative steps that arise from real-coefficient splitting at high orders. The method is most beneficial for dynamics that naturally separate into unitary and dissipative components, with broad applications across science and engineering. These systems frequently admit compact spectral representations of the split operators, which we demonstrate by deriving efficient quantum circuits for simulating the damped-wave equation with up to sixth-order accuracy in time. A single sixth-order step in three dimensions on 35 trillion cells requires 1,562 CNOT gates, which can be executed within the coherence time of modern quantum processors.

</details>


### [42] [Entropy Flow and Exceptional-Point Structure in Two-Mode Squeezed-Bath Dynamics](https://arxiv.org/abs/2511.19662)
*Eric R. Bittner*

Main category: quant-ph

TL;DR: 本文研究了两个耦合谐振子在独立压缩浴驱动下的动力学，揭示了压缩诱导的熵流和异常点结构，发现压缩仅在二阶异常相关中产生熵，并识别了PT对称性仅在两个浴压缩相反正交分量时存在。


<details>
  <summary>Details</summary>
Motivation: 研究压缩浴如何通过非经典噪声工程控制开放量子系统的不可逆动力学，探索相干驱动的熵流和Lindblad动力学中的异常点结构。

Method: 在高斯形式框架内，推导了协方差矩阵的闭式演化方程，分析了压缩参数对动力学的影响，扫描了压缩参数平面以识别异常点结构。

Result: 发现压缩仅在二阶异常相关中诱导熵生成，识别了异常点扇形结构，将PT对称未破缺的振荡动力学区域与PT对称破缺的过阻尼区域分开。

Conclusion: 压缩浴为信息承载噪声通过相干途径驱动不可逆行为提供了自然设置，为实验探测复杂开放系统中的熵流和临界模式行为奠定了基础。

Abstract: Squeezed reservoirs provide a powerful means of engineering nonclassical noise and controlling irreversible dynamics in open quantum systems. Here we develop a comprehensive analysis of two coupled harmonic oscillators driven by independent squeezed baths, focusing on the emergence of coherence-driven entropy flow and the structure of exceptional points (EPs) in the corresponding Lindblad dynamics. Working entirely within the Gaussian formalism, we derive closed-form evolution equations for the covariance matrix and show that squeezing induces entropy generation only at *second order* in the anomalous correlations, a nonlinear mechanism absent in thermal environments. This entropy flow is accompanied by a rich non-Hermitian structure: by scanning the squeezing parameters we uncover a characteristic "exceptional-point fan" in the (M1, M2) plane, which separates a narrow PT-unbroken region of oscillatory dynamics from broad PT-broken sectors in which one normal mode becomes purely overdamped. This geometric organization of EPs reveals that PT symmetry survives only when the two reservoirs squeeze opposite quadratures, and is generically broken for in-phase squeezing. Our analysis establishes squeezed reservoirs as a natural setting where information-bearing noise drives irreversible behavior through coherent pathways, and lays the groundwork for experimentally accessible probes of entropy flow and critical mode behavior in more complex open systems.

</details>


### [43] [Quantum Coherence of Rare-Earth Ions in Heterogeneous Photonic Interfaces](https://arxiv.org/abs/2511.19668)
*Henry C. Hammer,Hassan A. Bukhari,Yogendra Limdu,Brett M. Wasick,Christopher Rouleau,Michael E. Flatté,Durga Paudyal,Denis R. Candido,Ravitej Uppu*

Main category: quant-ph

TL;DR: 该研究通过理论计算和实验分析，揭示了Er³⁺:TiO₂薄膜中稀土离子光学相干性受限的微观机制，包括界面应变、氧空位和镓扩散等噪声源的影响。


<details>
  <summary>Details</summary>
Motivation: 将氧化物中的稀土离子与III-V半导体中的明亮发射器集成用于量子网络时，局部无序和界面噪声限制了其光学相干性，需要深入理解这些微观噪声机制。

Method: 结合第一性原理计算、噪声哈密顿量建模、蒙特卡洛模拟和光致发光激发光谱，分析Er³⁺:TiO₂外延薄膜在GaAs和GaSb衬底上的微观结构。

Result: 发现距离III-V/氧化物界面越远的Er³⁺离子产生系统性的蓝移，与理论预测的应变弛豫一致；热退火产生补偿性红移和线宽变窄，分离了氧空位和镓扩散噪声的作用。

Conclusion: 这些结果为理解无序驱动退相干提供了微观见解，为精确控制混合量子系统以实现可扩展量子技术提供了途径。

Abstract: Harnessing rare-earth ions in oxides for quantum networks requires integration with bright emitters in III-V semiconductors, but local disorder and interfacial noise limit their optical coherence. Here, we investigate the microscopic origins of the ensemble spectrum in Er$^{3+}$:TiO$_2$ epitaxial thin films on GaAs and GaSb substrates. Ab initio calculations combined with noise-Hamiltonian modeling and Monte Carlo simulations quantify the effects of interfacial and bulk spin noise and local strain on erbium crystal-field energies and inhomogeneous linewidths. Photoluminescence excitation spectroscopy reveals that Er$^{3+}$ ions positioned at increasing distances from the III-V/oxide interface produce a systematic blue shift of the $Y_1\rightarrow Z_1$ transition, consistent with strain relaxation predicted by theory. Thermal annealing produces a compensating redshift and linewidth narrowing, isolating the roles of oxygen-vacancy and gallium-diffusion noise. These results provide microscopic insight into disorder-driven decoherence, offering pathways for precise control of hybrid quantum systems for scalable quantum technologies.

</details>


### [44] [Infrared absorption spectroscopy of a single polyatomic molecular ion](https://arxiv.org/abs/2511.19687)
*Zhenlin Wu,Tim Duka,Mariano Isaza-Monsalve,Miriam Kautzky,Vojtěch Švarc,Andrea Turci,René Nardi,Marcin Gronowski,Michał Tomza,Brandon J. Furey,Philipp Schindler*

Main category: quant-ph

TL;DR: 开发了一种在单个分子离子上进行非破坏性吸收光谱的方法，通过检测吸收单个光子产生的反冲动量，结合双离子晶体放大信号，实现了中红外振动跃迁的测量。


<details>
  <summary>Details</summary>
Motivation: 传统吸收光谱在单个分子水平上信噪比低，难以实现非破坏性测量。需要开发新方法来探测单个分子的振动跃迁。

Method: 将单个分子离子与原子离子共囚禁，通过检测吸收光子产生的反冲动量，利用双离子晶体的非经典运动状态放大信号，并通过原子离子读取信号。

Result: 成功表征了反冲检测方法，研究了飞秒激光脉冲与CaOH+分子离子中O-H伸缩振动的相互作用，获得了振动跃迁的单光子吸收光谱。

Conclusion: 该方法为复杂多原子分子的量子非破坏测量奠定了基础，为多种分子物种的量子态制备和测量提供了高保真度方法。

Abstract: Absorption spectroscopy is a fundamental tool for probing molecular structure. However, performing absorption spectroscopy on individual molecules is challenging due to the low signal-to-noise ratio. Here, we report on a nondestructive absorption spectroscopy on a mid-infrared vibrational transition in a single molecular ion that is co-trapped with an atomic ion. The absorption of a single photon is detected via the momentum transfer from the absorbed photon onto the molecule. This recoil signal is amplified using a non-classical state of motion of the two-ion crystal and subsequently read out via the atomic ion. We characterize the recoil detection method and use it to investigate the interaction between femtosecond laser pulses and the O-H stretching vibration in individual CaOH+ molecular ions. Furthermore, we present the single-photon absorption spectrum obtained for the vibrational transition. This method represents a milestone towards quantum non-demolition measurements of complex polyatomic molecules, providing high-fidelity methods for preparation and measurement of the quantum state of a wide range of molecular species.

</details>


### [45] [Synergistic Effects of Detuning and Auxiliary Qubits on Quantum Synchronization](https://arxiv.org/abs/2511.19697)
*Amir Hossein Houshmand Almani,Ali Mortezapour,Alireza Nourmandipour*

Main category: quant-ph

TL;DR: 本文研究了在非马尔可夫环境中，通过失谐和辅助量子比特协同增强量子同步的机制。


<details>
  <summary>Details</summary>
Motivation: 探索在耗散多量子比特系统中，如何利用失谐和辅助量子比特来增强量子同步，特别是在非马尔可夫环境中利用环境记忆效应。

Method: 使用Husimi Q函数、同步度量指标和Arnold舌结构来分析失谐和辅助量子比特对系统相位锁定的影响。

Result: 在非马尔可夫环境中，失谐成为有效的控制参数，能增强相位锁定；增加辅助量子比特可放大该效应，通过加强集体耦合和增强记忆效应实现鲁棒的相位锁定。

Conclusion: 建立了一种协同控制策略：失谐主动调控相位，而辅助量子比特提供维持同步所需的内存效应。

Abstract: We investigate how detuning and auxiliary qubits collaboratively enhance quantum synchronization in a dissipative multi-qubit system that is coupled to a structured reservoir. Our findings indicate that while detuning is ineffective in Markovian environments, it emerges as a powerful control parameter in the non-Markovian regime, where environmental memory facilitates long-lived phase coherence. It is shown that adding more auxiliary qubits amplifies this effect by strengthening the collective coupling and enhancing memory, resulting in robust phase locking within the system. Analysis using the Husimi Q-function, synchronization measures, and Arnold tongue structures reveals a detuning-induced enhancement of phase locking, which significantly improves stability compared to the resonance case. These results establish a cooperative control strategy where detuning actively engineers phases, while auxiliary qubits provide the necessary memory for sustained synchronization.

</details>


### [46] [Localization and Delocalization of Quantum Trajectories in the Liouvillian Spectrum](https://arxiv.org/abs/2511.19700)
*Josef Richter,Masudul Haque,Lucas Sá*

Main category: quant-ph

TL;DR: 开发了一种通过分析Liouvillian超算符本征基中的量子轨迹来理解开放量子系统动力学的方法，构建了表征轨迹在Liouvillian本征基中局域化程度的准概率分布。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，即晚期动力学仅由稳态和最慢衰减模式主导，探索轨迹在Liouvillian谱深部瞬态本征态中的持续分布现象。

Method: 从轨迹-本征态重叠构建准概率分布，通过数值模拟相互作用自旋链和玻色子系统进行验证。

Result: 发现轨迹在晚期仍能在Liouvillian谱深部的瞬态本征态中保持广泛分布，且轨迹的离域化程度与轨迹平均稳态的纯度强相关。

Conclusion: 建立了轨迹和系综图像之间的进一步联系，揭示了开放量子动力学中轨迹在Liouvillian本征基中的复杂局域化行为。

Abstract: We develop an approach for understanding the dynamics of open quantum systems by analyzing individual quantum trajectories in the eigenbasis of the Liouvillian superoperator. From trajectory-eigenstate overlaps, we construct a quasiprobability distribution that characterizes the degree of localization of the trajectories in the Liouvillian eigenbasis. Contrary to the common wisdom that late-time dynamics are governed solely by the steady state and the slowest-decaying modes, we show that trajectories can remain well spread over transient eigenstates deep within the bulk of the Liouvillian spectrum even at late times. We demonstrate this explicitly using numerical simulations of interacting spin chains and bosonic systems. Moreover, we find that the delocalization of the trajectory strongly correlates with the purity of the trajectory-averaged steady state, establishing a further link between the trajectory and ensemble pictures of open quantum dynamics.

</details>


### [47] [Measurement-Assisted Clifford Synthesis](https://arxiv.org/abs/2511.19732)
*Sowmitra Das*

Main category: quant-ph

TL;DR: 提出了一种从逆Clifford酉算子的稳定子表合成n量子比特Clifford酉算子的新方法，使用辅助量子比特和测量，实现了线性深度的合成。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的Clifford合成范式，通过利用逆算子的稳定子表来优化合成过程，减少两量子比特门的数量。

Method: 使用辅助|+⟩态、受控泡利门、X基测量和基于测量结果的单量子比特泡利校正来合成Clifford酉算子。

Result: 实现了两量子比特门数量恰好等于稳定子表权重的合成，深度与量子比特数n成线性关系。

Conclusion: 该方法为Clifford合成提供了一种新的标准形式，在门数量和深度方面都具有优势。

Abstract: In this letter, we introduce a method to synthesize an $n$-qubit Clifford unitary $C$ from the stabilizer tableau of its inverse $C†$, using ancilla qubits and measurements. The procedure uses ancillary $|+\rangle$ states, controlled-Paulis, $X$-basis measurements and single-qubit Pauli corrections on the data qubits (based on the measurement results). This introduces a new normal form for Clifford synthesis, with the number of two-qubit gates required exactly equal to the weight of the stabilizer tableau, and a depth linear in $n$.

</details>


### [48] [Quantum Framework for Wavelet Shrinkage](https://arxiv.org/abs/2511.19855)
*Brani Vidakovic*

Main category: quant-ph

TL;DR: 提出了量子小波收缩的统一框架，将经典去噪思想扩展到量子领域，通过受控退相干实现系数衰减，将量子退相干机制重新用作可编程的噪声抑制资源。


<details>
  <summary>Details</summary>
Motivation: 建立小波统计推断与量子信息处理之间的概念联系，展示如何将工程化退相干作为经典收缩的操作替代品。

Method: 将收缩解释为完全正定保迹过程，通过相位阻尼和辅助驱动构造实现相干行为，在单一电路模型中结合统计自适应性和量子幺正性。

Result: 使用Qiskit实现了实际演示，展示了电路和通道如何模拟系数衰减，提供了适用于当前NISQ设备的实现方案。

Conclusion: 该工作为量子小波收缩提供了概念和实验基础，展示了工程化退相干可以作为经典收缩的有效量子替代方案。

Abstract: This paper develops a unified framework for quantum wavelet shrinkage, extending classical denoising ideas into the quantum domain. Shrinkage is interpreted as a completely positive trace-preserving process, so attenuation of coefficients is carried out through controlled decoherence rather than nonlinear thresholding. Phase damping and ancilla-driven constructions realize this behavior coherently and show that statistical adaptivity and quantum unitarity can be combined within a single circuit model. The same physical mechanisms that reduce quantum coherence, such as dephasing and amplitude damping, are repurposed as programmable resources for noise suppression. Practical demonstrations implemented with Qiskit illustrate how circuits and channels emulate coefficientwise attenuation, and all examples are provided as Jupyter notebooks in the companion GitHub repository. Encoding schemes for amplitude, phase, and hybrid representations are examined in relation to transform coherence and measurement feasibility, and realizations suited to current noisy intermediate-scale quantum devices are discussed. The work provides a conceptual and experimental link between wavelet-based statistical inference and quantum information processing, and shows how engineered decoherence can act as an operational surrogate for classical shrinkage.

</details>


### [49] [Suboptimality of Parity for Distilling Correlations with Nontrivial Marginals](https://arxiv.org/abs/2511.19977)
*Syed Affan Aslam,Areej Ilyas,Jibran Rashid*

Main category: quant-ph

TL;DR: 本文证明了PARITY协议在基于XOR游戏的所有n玩家非局域盒子（NLB）蒸馏协议中的最优性，并指出当局部边际非平凡时PARITY不再最优，OR协议表现更好。


<details>
  <summary>Details</summary>
Motivation: 研究非局域盒子蒸馏协议的最优性，特别关注局部边际性质对全局行为的影响，以更好地理解非局域系统的特性。

Method: 通过理论证明分析PARITY协议在基于XOR游戏的n玩家NLB蒸馏中的最优性，比较不同协议（PARITY vs OR）在局部边际不同情况下的性能。

Result: 证明了PARITY协议在局部边际平凡时是最优的，但当局部边际非平凡时OR协议表现更好，并扩展了已知的通信复杂度塌缩相关关系。

Conclusion: 理解非局域系统的局部性质对于表征其全局行为至关重要，并展示了自适应蒸馏协议与使用非相同NLB的PARITY协议之间的等价性。

Abstract: We prove that the PARITY protocol is optimal for a general class of non-adaptive distillation protocols of all $n$ player nonlocal boxes (NLBs) based on XOR games. The conditional distributions generated by these NLBs are assumed to have trivial local marginals. We also show that already for $n=2$, PARITY is no longer optimal if the local marginals are non-trivial. The OR protocol is shown to perform better and in the process also slightly extend the known correlations that collapse communication complexity. This emphasizes again the need to understand the local properties of nonlocal systems in order to obtain a better characterization of the global behavior. We conclude by showing an equivalence between adaptive distillation protocols that use identical NLBs and PARITY protocol using nonidentical NLBs.

</details>


### [50] [Error-structure-tailored early fault-tolerant quantum computing](https://arxiv.org/abs/2511.19983)
*Pei Zeng,Guo Zheng,Qian Xu,Liang Jiang*

Main category: quant-ph

TL;DR: 提出了一种基于误差结构定制容错的连续角度旋转门实现方法，避免了传统T门编译和蒸馏过程，显著降低了容错量子计算的时空资源开销。


<details>
  <summary>Details</summary>
Motivation: 传统容错量子计算中，逻辑旋转门由于Eastin-Knill定理无法横向实现，需要通过T门编译结合魔法态蒸馏和注入，导致资源开销巨大。

Method: 结合耗散噪声过程的微扰分析与稳定子码结构特性，设计通过色散耦合哈密顿量实现的1-容错连续角度旋转门，仅需最近邻相互作用。

Result: 对于小旋转角度，门误差可抑制至91|φ|p²，在当前硬件参数(p=10⁻³)下可可靠执行超过10⁷次小角度旋转，相比魔法态蒸馏方法分别降低时空资源成本1337.5倍和43.6倍。

Conclusion: 该方法为容错量子计算提供了一种硬件高效的解决方案，绕过了传统T门编译和蒸馏过程，显著降低了资源需求。

Abstract: Fault tolerance is widely regarded as indispensable for achieving scalable and reliable quantum computing. However, the spacetime overhead required for fault-tolerant quantum computating remains prohibitively large. A critical challenge arises in many quantum algorithms with Clifford + $\varphi$ compiling, where logical rotation gates $R_{Z_L}(\varphi)$ serve as essential components. The Eastin-Knill theorem prevents their transversal implementation in quantum error correction codes and necessitating resource-intensive workarounds through T-gate compilation combined with magic state distillation and injection. In this work, we consider error-structure-tailored fault tolerance, where fault-tolerance conditions are analyzed by combining perturbative analysis of realistic dissipative noise processes with the structural properties of stabilizer codes. Based on this framework, we design 1-fault-tolerant continuous-angle rotation gates in stabilizer codes, implemented via dispersive-coupling Hamiltonians. Our approach could circumvent the need for T-gate compilation and distillation, offering a hardware-efficient solution that maintains simplicity, minimizes physical footprint, and requires only nearest-neighbor interactions. Integrating with recent small-angle-state preparation techniques, we can suppress the gate error to $91|\varphi| p^2$ for small rotation angle (where p denotes the physical error rate). For current achievable hardware parameters ($p=10^{-3}$), this enables reliable execution of over $10^7$ small-angle rotations when $|\varphi|\approx 10^{-3}$, meeting the requirements of many near-term quantum applications. Compared to the 15-to-1 magic state distillation and magic state cultivation approaches, our method reduces spacetime resource costs by factors of 1337.5 and 43.6, respectively, for a Heisenberg Hamiltonian simulation task under realistic hardware assumptions.

</details>


### [51] [Virtual phase-covariant quantum broadcasting for qubits](https://arxiv.org/abs/2511.20014)
*Reiji Okada,Francesco Buscemi*

Main category: quant-ph

TL;DR: 本文研究了虚拟相位协变量子广播，通过放松对称性要求来改进操作性能，但发现即使优化后仍存在样本效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 虚拟映射通过结合物理过程和经典后处理来模拟量子操作，但现有的虚拟酉协变广播在可观测量估计任务中由于样本效率差而不实用。本文旨在探索放松对称性要求是否能改善操作性能。

Method: 研究虚拟相位协变量子广播，施加相位协变性、翻转协变性、置换不变性和经典一致性来完全确定广播映射的结构，并识别出最小化模拟成本的唯一映射。

Result: 发现模拟成本和到最近CPTP映射的距离都比酉协变设置下严格更小，最近的物理映射是最优相位协变克隆通道。

Conclusion: 尽管有所改进，但得到的虚拟广播映射仍然样本效率低下，因此在操作上仍然不实用。

Abstract: Virtual maps allow the simulation of quantum operations by combining physical processes with classical post-processing. Recent work on virtual unitary covariant broadcasting has shown, however, that such maps remain impractical for observable estimation tasks due to poor sample efficiency. Here we investigate whether relaxing the symmetry requirements can improve operational performance, focusing on virtual phase-covariant quantum broadcasting for qubits. We show that imposing phase-covariance, flip covariance, permutation invariance, and classical consistency fully determines the structure of the broadcasting map. Within this family, we identify the unique map that minimizes the simulation cost, and we prove that both the simulation cost and the distance to the closest CPTP map are strictly smaller than in the unitary covariant setting. We also demonstrate that the closest physical map is the optimal phase-covariant cloning channel, mirroring the relation between unitary covariant broadcasting and universal cloning. Despite these improvements, the resulting virtual broadcasting map remains sample-inefficient and is therefore still operationally impractical.

</details>


### [52] [Kernelized Decoded Quantum Interferometry](https://arxiv.org/abs/2511.20016)
*Fumin Wang*

Main category: quant-ph

TL;DR: 提出了Kernelized Decoded Quantum Interferometry (k-DQI)框架，通过引入酉核来重塑能量景观，将解质量集中到低频区域，从而提高在噪声环境下的解码成功率。


<details>
  <summary>Details</summary>
Motivation: 传统解码量子干涉测量(DQI)对硬件噪声和频谱色散非常敏感，限制了其实际应用。需要开发能够主动适应噪声环境的鲁棒量子算法。

Method: 在干涉步骤前插入酉核，主动重塑问题的能量景观；使用Chirp和线性正则变换(LCT)核实现高效电路；提出噪声加权头质量Σ_K作为鲁棒性度量。

Result: 在最优多项式插值和LDPC类问题中，核调谐显著提高了有效信噪比，深度开销可忽略(从~O(n)到~O(n^2))；证明了单调改进定理，最大化Σ_K可保证更高的解码成功率。

Conclusion: k-DQI将DQI从静态算法转变为可调谐、噪声感知的协议，适用于近期纠错环境，为结构化优化提供了实用的超多项式加速方案。

Abstract: Decoded Quantum Interferometry (DQI) promises superpolynomial speedups for structured optimization; however, its practical realization is often hindered by significant sensitivity to hardware noise and spectral dispersion. To bridge this gap, we introduce \textbf{Kernelized Decoded Quantum Interferometry (k-DQI)}, a unified framework that integrates spectral engineering directly into the quantum circuit architecture. By inserting a unitary kernel prior to the interference step, k-DQI actively reshapes the problem's energy landscape, concentrating the solution mass into a ``decoder-friendly'' low-frequency head. We formalize this advantage through a novel robustness metric, the noise-weighted head mass $Σ_K$, and prove a \textbf{Monotonic Improvement Theorem}, which establishes that maximizing $Σ_K$ guarantees higher decoding success rates under local depolarizing noise. We substantiate these theoretical gains in Optimal Polynomial Interpolation (OPI) and LDPC-like problems, demonstrating that kernel tuning functions as a ``spectral lens'' to recover signal otherwise lost to isotropic noise. Crucially, we provide explicit, efficient circuit realizations using Chirp and Linear Canonical Transform (LCT) kernels that achieve significant boosts in effective signal-to-noise ratio with negligible depth overhead ($\tilde{O}(n)$ to $\tilde{O}(n^2)$). Collectively, these results reframe DQI from a static algorithm into a tunable, noise-aware protocol suited for near-term error-corrected environments.

</details>


### [53] [Real and Fourier space readout methods: Comparison of complexity and applications to CFD problems](https://arxiv.org/abs/2511.20017)
*Xinchi Huang,Hirofumi Nishi,Yoshifumi Kawada,Tomofumi Zushi,Yu-ichiro Matsushita*

Main category: quant-ph

TL;DR: 本文提出并比较了量子计算中PDE求解器的几种高效读取方法，包括傅里叶空间读取(FSR)和近似实空间读取(ARSR)，这些方法在计算流体动力学基准测试中相比传统采样方法有显著改进。


<details>
  <summary>Details</summary>
Motivation: 量子计算在求解偏微分方程方面具有潜力，但量子态读取（解的重构）仍然是一个关键问题，需要开发高效的读取方法。

Method: 提出并比较了实空间和傅里叶空间的多种读取方法，包括FSR、ARSR和基于量子振幅估计(QAE)的方法，并在计算流体动力学中进行基准测试。

Result: FSR和ARSR是目前重建连续实值函数最有效和实用的方法，在CFD基准测试中相比传统采样方法有显著改进，能够高效求解2D Burgers方程而无需昂贵的线性化策略。

Conclusion: 配备高效读取方法后，量子计算在中长期量子设备上对某些实际应用具有潜在优势，特别是在无需线性化策略的情况下高效求解非线性PDE方面。

Abstract: Quantum computing is a promising technology that accelerates the partial differential equations solver for practical problems. The reconstruction of solutions (i.e., the readout of quantum states) remains a crucial problem, although numerous efficient quantum algorithms have been proposed. In this paper, we propose and compare several efficient readout methods in the real and the Fourier space. The Fourier space readout (FSR) and the proposed approximate real space readout (ARSR) methods are currently the most efficient and practical ones for the purpose of reconstructing continuous real-valued functions. In contrast, the quantum amplitude estimation (QAE) based methods (especially in the Fourier space) are favorable for mid-term/far-term quantum devices. Besides, we apply the methods for benchmark solutions in computational fluid dynamics (CFD) and demonstrate great improvements compared to the conventional sampling method for large grid numbers. Equipped with efficient readout methods, we further show that a 2D Burgers' equation can be solved efficiently without using the expensive strategy of linearization. It suggests the potential quantum advantages for some practical applications on mid-term quantum devices.

</details>


### [54] [An Adaptable Route to Fast Coherent State Transport via Bang-Bang-Bang Protocols](https://arxiv.org/abs/2511.20026)
*Ya-Tang Yu,Hsin-Lien Lee,Ting Hsu,Guin-Dar Lin,Yin-Cheng Chen,H. H. Jen*

Main category: quant-ph

TL;DR: 提出了一种快速相干态传输的bang-bang-bang协议，使用前后移动的陷阱势组合来加速传输，接近量子速度极限，优于仅前向移动的方法。


<details>
  <summary>Details</summary>
Motivation: 快速相干态传输对量子计算和信息处理至关重要，但绝热传输需要长时间尺度，不利于高效量子操作。

Method: 使用bang-bang-bang协议，结合前后移动的陷阱势来加速传输，并应用压缩相干态演化在更深和更弱的势下传输。

Result: 该协议在谐波陷阱势下接近量子速度极限，优于仅前向移动势的方法，对称压缩势设计可实现更短的时间尺度。

Conclusion: 该协议优于传统方法，为快速态传输和制备提供了新见解，推进了量子控制和操作能力。

Abstract: Fast coherent state transport is essential to quantum computation and quantum information processing. While an adiabatic transport of atomic qubits guarantees a high fidelity of the state preparation, it requires a long timescale that defies efficient quantum operations. Here, we propose an adaptable and fast bang-bang-bang (BBB) protocol, utilizing a combination of forwardand backward-moving trap potentials, to expedite the coherent state transport. This protocol approaches the quantum speed limit under a harmonic trap potential, surpassing the performance by the forward-moving-only potential protocols. We further showcase the advantage of applying squeezed coherent state evolution under a deeper potential followed by a weaker one, where a design of symmetric squeezing potential transports promotes an even shorter timescale for genuine state preparation. Our protocols outperform conventional forward-moving-only methods, providing new insights and opportunities for rapid state transport and preparation, ultimately advancing the capabilities of quantum control and quantum operations.

</details>


### [55] [A Comprehensive Characterization of the Vacuum Beam Guide and Its Applications](https://arxiv.org/abs/2511.20031)
*Yuexun Huang,Delaney Smith,Pei Zeng,Debayan Bandyopadhyay,Junyu Liu,Rana X Adhikari,Liang Jiang*

Main category: quant-ph

TL;DR: 真空光束导引(VBG)作为量子信道技术的创新，具有超低衰减和宽传输线宽特性，但干涉测量稳定性尚未研究。本文开发了相位噪声模型，揭示了VBG在干涉测量中的优势。


<details>
  <summary>Details</summary>
Motivation: VBG技术虽然提供了前所未有的量子容量(超过Tera-qubits/s)，但其在干涉测量方面的稳定性尚未得到验证，这是实现其量子应用潜力的关键障碍。

Method: 开发了全面的误差模型来捕捉VBG的固有相位噪声功率谱密度，通过理论分析评估VBG作为光子量子信道的性能。

Result: 模型揭示了VBG在干涉测量方面优于现有技术的优势，证明了VBG在各种量子应用中的可行性和预期性能。

Conclusion: VBG不仅具有高量子容量，在干涉测量稳定性方面也表现出色，为广泛的量子应用提供了可行的光子量子信道解决方案。

Abstract: The proposed vacuum beam guide (VBG) represents an innovation in the field of quantum channel technology, guaranteeing an ultra-low level of attenuation and a broad transmission linewidth, which offers an unprecedented quantum capacity exceeding Tera-qubits per second on a continental scale. However, its stability in terms of interferometry remains unexamined. To address this gap, we have developed a comprehensive error model that captures the intrinsic phase noise power spectral density associated with VBG, thereby revealing the advantages of VBG for interferometry over existing techniques. This model facilitates a comprehensive characterization of VBG as a photonic quantum channel, thereby facilitating a detailed investigation of its potential. Our theoretical analysis demonstrates the feasibility of VBG and its expected performance in a wide range of quantum applications.

</details>


### [56] [Superconducting Parametric Amplifiers: Resonator Design and Role in Qubit Readout](https://arxiv.org/abs/2511.20097)
*Babak Mohammadian*

Main category: quant-ph

TL;DR: 超导参量放大器(SPAs)是实现量子极限噪声性能的关键量子计算组件，通过参量放大原理放大微弱量子信号，对高保真度量子比特读取至关重要。


<details>
  <summary>Details</summary>
Motivation: 解决量子计算中微弱量子信号放大时引入噪声破坏相干性和计算保真度的关键挑战，实现接近量子极限的噪声性能。

Method: 利用超导材料的固有非线性（动能电感和约瑟夫森效应），通过三波或四波混频实现参量放大，采用集总元件(LC)和分布式元件(共面波导)谐振器设计来优化增益、带宽和噪声特性。

Result: 能够实现或接近标准量子极限(SQL)的噪声性能（半光子添加噪声），通过精确控制谐振器几何参数优化谐振频率、耦合强度和质量因子。

Conclusion: 谐振器设计在决定SPA性能指标中起关键作用，精确的几何参数控制对于实现高保真度量子比特状态分辨至关重要。

Abstract: Superconducting parametric amplifiers (SPAs) are critical components for ultralow-noise qubit readout in quantum computing, addressing the critical challenge of amplifying weak quantum signals without introducing noise that degrades coherence and computational fidelity. Unlike classical amplifiers, SPAs can achieve or closely approach quantum-limited performance, specifically the Standard Quantum Limit (SQL) of half a photon of added noise for phase-preserving amplification. The core principle of SPAs relies on parametric amplification, where energy is transferred from a strong pump tone to a weak input signal through non-dissipative nonlinear mixing processes. This is enabled by intrinsic nonlinearities in superconducting materials, primarily kinetic inductance in thin films (e.g., NbTiN, Al) and, more significantly, the Josephson effect in Josephson junctions. These nonlinear elements facilitate frequency mixing (three-wave or four-wave mixing) and can operate in phase-preserving or phase-sensitive amplification modes, with the latter allowing for noise squeezing below the SQL. This chapter emphasizes the significant role of resonator design in determining critical SPA performance metrics such as gain, bandwidth, and noise characteristics. It details both lumped-element (LC) and distributed-element (coplanar waveguide, CPW) resonators, discussing their unique properties, suitability for different frequency ranges, and the importance of achieving high-quality factors (Q) for efficient energy storage and minimal loss. A practical design and simulation of a meandered quarterwavelength CPW resonator coupled to a feed line is presented, illustrating how precise control over geometric parameters optimizes resonant frequency, coupling strength, and quality factor for high-fidelity qubit state discrimination.

</details>


### [57] [The Cumulants Expansion Approach: The Good, The Bad and The Ugly](https://arxiv.org/abs/2511.20115)
*Johannes Kerber,Helmut Ritsch,Laurin Ostermann*

Main category: quant-ph

TL;DR: 本文研究了累积展开在量子系统中的适用性，通过分析量子电动力学中的集体辐射耗散和量子信息中的双素数分解两个案例，发现累积展开的收敛行为在不同问题中存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 累积展开（包括平均场近似）在量子物理中广泛应用，但缺乏对其适用性和高阶收敛性的一般性判断标准。本文旨在探讨累积展开在不同量子系统中的表现差异。

Method: 使用累积展开方法分析两个具体问题：1）偶极-偶极相互作用原子链的集体辐射耗散；2）绝热量子模拟器中的双素数分解问题。比较不同阶数累积展开的收敛行为。

Result: 在集体辐射耗散问题中，累积展开表现出平滑的收敛行为，高阶近似效果更好；而在双素数分解问题中，超越平均场近似毫无用处，甚至在小系统规模下也会出现数值挑战和非物理解。

Conclusion: 累积展开的适用性高度依赖于具体问题，在某些情况下（如集体辐射耗散）表现良好，而在其他情况下（如双素数分解）可能完全失效，这突显了需要发展更一般的适用性判断标准。

Abstract: The configuration space, i.e. the Hilbert space, of compound quantum systems grows exponentially with the number of its subsystems: its dimensionality is given by the product of the dimensions of its constituents. Therefore a full quantum treatment is rarely possible analytically and can be carried out numerically for fairly small systems only. Fortunately, in order to obtain interesting physics, approximations often very well suffice. One of these approximations is given by the cumulants expansion, where expectation values of products of operators are approximated by products of expectation values of said operators, neglecting higher-order correlations. The lowest order of this approximation is widely known as the mean field approximation and used routinely throughout quantum physics. Despite its ubiquitous presence, a general criterion for applicability and convergence properties of higher order cumulants expansions remains to be found. In this paper, we discuss two problems in quantum electrodynamics and quantum information, namely the collective radiative dissipation of a dipole-dipole interacting chain of atoms and the factorization of a bi-prime by annealing in an adiabatic quantum simulator. In the first case we find smooth, convergence behavior, where the approximation performs increasingly better with higher orders, while in the latter going beyond mean field turns out useless and, even for small system sizes, we are puzzled by numerically challenging and partly non-physical solutions.

</details>


### [58] [All-Optical Brillouin Random number Generator](https://arxiv.org/abs/2511.20133)
*A. R. Mukhamedyanov,E. S. Andrianov,A. A. Zyablovsky*

Main category: quant-ph

TL;DR: 提出基于布里渊光力学系统的二进制随机数发生器模型，利用硬激发模式中的热噪声诱导状态间自发跃迁，通过泵浦波幅值控制跃迁概率分布，通过种子波控制跃迁时间，成功通过NIST SP 800-22测试。


<details>
  <summary>Details</summary>
Motivation: 开发一种全光学集成真随机数发生器，能够生成等概率的随机比特序列。

Method: 利用布里渊光力学系统中的硬激发模式，通过热噪声诱导两个稳定状态间的自发跃迁，通过外部泵浦波幅值控制跃迁概率分布，通过低强度种子波控制状态间跃迁时间。

Result: 提出的随机数发生器成功通过标准测试NIST SP 800-22，能够生成等概率的随机比特序列。

Conclusion: 该结果为开发全光学集成真随机数发生器开辟了新途径，能够生成具有相等概率的随机比特序列。

Abstract: We propose a model of binary random number generator (RNG) based on a Brillouin optomechanical system. The device uses a hard excitation mode in a Brillouin optomechanical system, where thermal noise induces spontaneous transitions between two stable states in the hard excitation mode. We demonstrate the existence of an amplitude criterion for observing these transitions and show that the probability distribution of their occurrence in the non-generating and generating states can be precisely controlled by the amplitude of an external pump wave. At the same time, the use of a low-intensity seed wave allows for the control of the transition times between states. We demonstrate that the proposed random number generator successfully passes the standard tests NIST SP 800-22. The obtained result opens a way for development of an all-optical integrated True RNG, generating a sequence of random bits with equal probability.

</details>


### [59] [Plug-n-Play Three Pulse Twin Field QKD](https://arxiv.org/abs/2511.20140)
*Anagha Gayathri,Aryan Bhardwaj,Nilesh Sharma,Tarun Goel,Y. V. Subba Rao,Anil Prabhakar*

Main category: quant-ph

TL;DR: 实验实现了基于三时间相位编码的双场量子密钥分发协议，采用Sagnac环形星型拓扑即插即用架构，通过三个连续时间箱的相对相位编码每信号2比特，在50公里不对称光纤链路上实现了约1.5e-5比特/脉冲的安全密钥率。


<details>
  <summary>Details</summary>
Motivation: 解决实际部署中由外部振动引起的快速相位波动问题，同时利用Sagnac环形配置实现相位和偏振漂移的自补偿，消除主动稳定需求。

Method: 使用三时间相位编码方法，第一个时间箱用于实时相位波动监测，Sagnac环形星型拓扑架构提供自补偿能力。

Result: 系统在50公里不对称光纤链路上实现了约87%的干涉可见度和约1.5e-5比特/脉冲的安全密钥率。

Conclusion: 所提出的三时间箱双场QKD协议在实际量子通信网络中具有实用性、稳定性和可扩展性。

Abstract: We present the experimental implementation of a three-time-bin phase-encoded Twin-Field Quantum Key Distribution (TF-QKD) protocol using a Sagnac-based star-topology plug-and-play architecture. The proposed encoding method leverages the relative phases of three consecutive time bins to encode two bits per signal. The Sagnac loop configuration enables self-compensation for both phase and polarisation drifts, eliminating the need for active stabilisation. However, field deployments are subject to rapid phase fluctuations caused by external vibrations, which can degrade interference visibility. We used the first time bin for real-time phase-fluctuation monitoring. Although this monitoring reduces the effective key generation rate, the system achieved a secure key rate of approximately 1.5e-5 bits per pulse, with a corresponding visibility of up to 87% over a 50 km asymmetric optical fibre channel. These results demonstrate the practicality, stability, and scalability of the proposed three-time-bin TF-QKD protocol for real-world quantum communication networks.

</details>


### [60] [A Unified Complexity-Algorithm Account of Constant-Round QAOA Expectation Computation](https://arxiv.org/abs/2511.20212)
*Jingheng Wang,Shengminjie Chen,Xiaoming Sun,Jialin Zhang*

Main category: quant-ph

TL;DR: 本文研究了固定轮数QAOA在组合优化中的性能评估问题，证明了对于Max-Cut问题，精确计算固定轮数QAOA的期望值是NP困难的，并提出基于树分解的动态规划算法进行有效评估。


<details>
  <summary>Details</summary>
Motivation: 量子近似优化算法(QAOA)在组合优化中取得重要进展，但对于一般组合优化问题，固定轮数QAOA的预期性能和经典可模拟性仍不清楚，需要系统分析其计算复杂度和评估方法。

Method: 针对Max-Cut问题，首先证明固定轮数QAOA期望值计算的NP困难性；然后提出基于树分解的动态规划算法，当p-局部树宽对数增长时可在多项式时间内精确评估；最后将框架扩展到一般二元无约束组合优化问题。

Result: 证明了对于任意固定轮数p≥2，精确计算QAOA期望值是NP困难的，近似计算在2^{-O(n)}误差内也是NP困难的；提出的动态规划算法在p-局部树宽对数增长时可在多项式时间内精确评估；在代表性结构化图上进行了p=3轮的可重现评估。

Conclusion: 固定轮数QAOA的期望值计算具有内在的计算复杂性，但通过利用图的结构特性（如树宽）可以设计有效的评估算法，为理解QAOA的实际性能提供了理论和方法基础。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is widely studied for combinatorial optimization and has achieved significant advances both in theoretical guarantees and practical performance, yet for general combinatorial optimization problems the expected performance and classical simulability of fixed-round QAOA remain unclear. Focusing on Max-Cut, we first show that for general graphs and any fixed round $p\ge2$, exactly evaluating the expectation of fixed-round QAOA at prescribed angles is $\mathrm{NP}$-hard, and that approximating this expectation within additive error $2^{-O(n)}$ in the number $n$ of vertices is already $\mathrm{NP}$-hard. To evaluate the expected performance of QAOA, we propose a dynamic programming algorithm leveraging tree decomposition. As a byproduct, when the $p$-local treewidth grows at most logarithmically with the number of vertices, this yields a polynomial-time \emph{exact} evaluation algorithm in the graph size $n$. Beyond Max-Cut, we extend the framework to general Binary Unconstrained Combinatorial Optimization (BUCO). Finally, we provide reproducible evaluations for rounds up to $p=3$ on representative structured families, including the generalized Petersen graph $GP(15,2)$, double-layer triangular 2-lifts, and the truncated icosahedron graph $C_{60}$, and report cut ratios while benchmarking against locality-matched classical baselines.

</details>


### [61] [Quantum measurement retrodiction and entropic uncertainty relations](https://arxiv.org/abs/2511.20281)
*Jiaxi Kuang,Kensei Torii,Francesco Buscemi*

Main category: quant-ph

TL;DR: 该论文基于最小变化原理研究量子测量回溯预测，发现所有标准量子散度都选择相同的回溯更新，从而为任意POVM和先验状态提供了唯一且散度无关的量子贝叶斯逆。


<details>
  <summary>Details</summary>
Motivation: 研究量子测量回溯预测，旨在通过最小变化原理建立统一的量子贝叶斯逆理论框架，解决量子测量中的回溯预测问题。

Method: 使用最小变化原理，分析量子到经典测量通道，证明所有标准量子散度选择相同的回溯更新，构造POVM对的对称联合分布，并引入相互回溯可预测性概念。

Result: 推导出仅依赖于先验状态且适用于所有测量的通用上界，建立了两个回溯熵不确定性关系，这些关系在数值基准测试中比现有熵不确定性关系提供更紧的界限。

Conclusion: 该研究为量子测量回溯预测提供了统一的理论框架，提出的回溯熵不确定性关系在广泛测量和状态类别中表现优于现有方法。

Abstract: We study quantum measurement retrodiction using the principle of minimum change. For quantum-to-classical measurement channels, we show that all standard quantum divergences select the same retrodictive update, yielding a unique and divergence-independent quantum Bayesian inverse for any POVM and prior state. Using this update, we construct a symmetric joint distribution for pairs of POVMs and introduce the mutual retrodictability, for which we also derive a general upper bound that depends only on the prior state and holds for all measurements. This structure leads to two retrodictive entropic uncertainty relations, expressed directly in terms of the prior state and the POVMs, but valid independently of the retrodictive framework and fully compatible with the conventional operational interpretation of entropic uncertainty relations. Finally, we benchmark these relations numerically and find that they provide consistently tighter bounds than existing entropic uncertainty relations over broad classes of measurements and states.

</details>


### [62] [Realizing Universal Non-Markovian Noise Suppression](https://arxiv.org/abs/2511.20304)
*Hongfeng Liu,Zizhao Han,Xinfang Nie,Zhenhuan Liu,Dawei Lu*

Main category: quant-ph

TL;DR: 提出并实验验证了一种基于量子纯化协议的非马尔可夫噪声抑制方案，无需噪声校准或特定噪声模型假设，能指数级降低非马尔可夫误差率。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫噪声是量子计算中最具挑战性的噪声形式，通常难以表征和抑制。

Method: 采用受量子纯化协议启发的噪声抑制方案，利用辅助系统尺寸实现指数级误差降低。

Result: 在核自旋系统中成功实现协议，对酉操作和非酉通道的非马尔可夫噪声均实现有效抑制，保真度和过程层析与理论预测高度一致。

Conclusion: 该方案具有实用性和有效性，为非马尔可夫噪声抑制提供了可行方法。

Abstract: Non-Markovian noise, arising from environmental memory effects, is the most general and challenging form of noise in quantum computing, and is typically difficult to characterize and suppress. Here, we analyze and experimentally demonstrate a non-Markovian noise suppression scheme inspired by quantum purification protocols. We theoretically prove that, even without noise calibration and assumptions on specific noise models, the scheme can exponentially reduce non-Markovian error rates with respect to the ancillary system size. We implement the protocol using nuclear spins, demonstrating that non-Markovian noise can be suppressed for both unitary operations and non-unitary channels. The observed fidelities and process tomography show close agreement with theoretical predictions, confirming the practicality and effectiveness of the scheme.

</details>


### [63] [Fault-Tolerant Non-Clifford GKP Gates using Polynomial Phase Gates and On-Demand Noise Biasing](https://arxiv.org/abs/2511.20355)
*Minh T. P. Nguyen,Mackenzie H. Shaw*

Main category: quant-ph

TL;DR: 提出了一种基于标准GKP纠错电路的按需噪声偏置方法，用于在T门操作前后偏置GKP码态，从而消除T门的逻辑错误平台。


<details>
  <summary>Details</summary>
Motivation: GKP码的逻辑Clifford门可以通过高斯幺正门实现，但T门（立方相位门）存在逻辑错误平台问题，除非GKP码态具有偏置噪声特性。

Method: 使用标准GKP纠错电路实现按需噪声偏置，在T门操作前偏置码态，操作后恢复非偏置状态；并开发了基于"多项式相位稳定子"的形式化方法来寻找逻辑对角门的最优幺正表示。

Result: 证明通过按需偏置电路，T门的逻辑错误率可以随GKP码态质量的提高而任意减小；数值模拟显示在12 dB GKP压缩下，T门平均保真度可达99%以上，无需后选择。

Conclusion: 该方法成功解决了GKP码中非Clifford门的逻辑错误平台问题，并扩展了多量子位逻辑门和数相玻色码的分析框架。

Abstract: The Gottesman-Kitaev-Preskill (GKP) error correcting code uses a bosonic mode to encode a logical qubit, and has the attractive property that its logical Clifford gates can be implemented using Gaussian unitary gates. In contrast, a direct unitary implementation of the ${T}$ gate using the cubic phase gate has been shown to have logical error floor unless the GKP codestate has a biased noise profile [1]. In this work, we propose a method for on-demand noise biasing based on a standard GKP error correction circuit. This on-demand biasing circuit can be used to bias the GKP codestate before a $T$ gate and return it to a non-biased state afterwards. With the on-demand biasing circuit, we prove that the logical error rate of the $T$ gate can be made arbitrarily small as the quality of the GKP codestates increases. We complement our proof with a numerical investigation of the cubic phase gate subject to a phenomenological noise model, showing that the ${T}$ gate can achieve average gate fidelities above $99\%$ with 12 dB of GKP squeezing without the use of postselection. Moreover, we develop a formalism for finding optimal unitary representations of logical diagonal gates in higher levels of the Clifford hierarchy that is based on a framework of ``polynomial phase stabilizers'' whose exponents are polynomial functions of one of the quadrature operators. This formalism naturally extends to multi-qubit logical gates and even to number-phase bosonic codes, providing a powerful algebraic tool for analyzing non-Clifford gates in bosonic quantum codes.
  [1] J. Hastrup, M. V. Larsen, J. S. Neergaard-Nielsen, N. C. Menicucci, and U. L. Andersen, Phys. Rev. A 103, 032409 (2021)

</details>


### [64] [Proximity driven photon-tunneling in chiral quantum hybrid systems](https://arxiv.org/abs/2511.20357)
*Aryan Pratap Srivastava,Moulik Deviprasad Ketkar,Kuldeep Kumar Shrivastava,Abhishek Maurya,Biswanath Bhoi,Rajeev Singh*

Main category: quant-ph

TL;DR: 研究了耦合倒置圆形开口环微波谐振器中光子隧穿现象，通过调节谐振器间距观察传输谱的强调制效应，包括模式分裂、干涉效应和暗态形成。


<details>
  <summary>Details</summary>
Motivation: 探索通过结构设计和激发参数控制光子隧穿的能力，为可重构光子器件、量子通信、手性传感和偏振选择性信号处理提供潜在应用。

Method: 使用具有四种离散手性取向的耦合倒置圆形开口环微波谐振器，通过改变谐振器间距进行实验测量，并结合全波电磁模拟和电路量子电动力学模型分析。

Result: 实验测量显示清晰的杂化特征，这些特征依赖于手性和距离，与全波电磁模拟结果一致。系统再现了两个量子化谐振子的预期特征，提供了手性量子混合平台的经典模拟。

Conclusion: 该系统能够通过结构设计和激发参数控制光子隧穿，在可重构光子器件、量子通信、手性传感和偏振选择性信号处理方面具有应用潜力。

Abstract: We investigate photon tunneling in a pair of coupled inverted circular split-ring microwave resonators with four discrete chiral orientations. By varying the spacing between the resonators, we observe strong modulation of the transmission spectra, including mode splitting, interference effects, and the formation of dark states. Measurements on fabricated devices show clear signatures of hybridization that depend on both chirality and proximity, and these results are consistent with full-wave electromagnetic simulations. To describe the observed behavior, we develop a circuit quantum electrodynamics model that captures the dependence of the coupling strength on geometry and the reversal of its sign. Although the experimental excitation is classical, the system reproduces features expected from two quantized harmonic oscillators, providing a classical analogue of a chiral quantum hybrid platform. The ability to control photon tunneling through structural design and excitation parameters suggests potential applications in reconfigurable photonic devices, quantum communication, chiral sensing, and polarization-selective signal processing.

</details>


### [65] [Quantum coherence measures in entangled atomic systems](https://arxiv.org/abs/2511.20371)
*Arnab Mukherjee,Soham Sen,Sunandan Gangopadhyay*

Main category: quant-ph

TL;DR: 研究洛伦兹变换对纠缠原子系统中量子相干性度量的影响，发现在高斯波包宽度增加、boost参数值增大以及受boost影响的粒子数量增多时，相干性普遍衰减。


<details>
  <summary>Details</summary>
Motivation: 探索相对论性boost对纠缠量子系统相干性的影响，特别是在不同boost场景下量子相干性的变化规律。

Method: 考虑两种场景：第一种是boost仅影响一个粒子而另一个不受影响；第二种是两个粒子都受到boost影响。使用各种相干性公式分析波函数相干性随boost参数和高斯波包宽度的变化。

Result: 相干性随高斯波包宽度增加而衰减，随boost参数值增大而衰减，随受boost影响的粒子数量增多而衰减。

Conclusion: 相对论性boost会降低纠缠量子系统的相干性，这种衰减效应与波包宽度、boost强度以及受影响的粒子数量密切相关。

Abstract: In this study, we investigate the effect of the Lorentz transformation on the measures of quantum coherence in an entangled atomic system. Here, we consider the effect of this relativistic boosts on two-particle entangled generalized Gaussian wave packets in two scenarios. In the first scenario, we consider that the relativistic boost affects the one particle and other remains unaffected while in the second scenario, we consider that both the particles are affected by the effect of the relativistic boost. The coherence of the wave function as measured by the boosted observer is studied as a function of the boost parameter and the width of the Gaussian wave packets. Using various formulations of coherence, it is shown that in general the coherence decays with increase in the width of the Gaussian wave packet, higher values of boost parameter, and the number of particles on which boost is applied.

</details>


### [66] [Resource assessment of classical and quantum hardware for post-quench dynamics](https://arxiv.org/abs/2511.20388)
*Joseph Vovrosh,Tiago Mendes-Santos,Hadriel Mamann,Kemal Bidzhiev,Fergus Hayes,Bruno Ximenez,Lucas Béguin,Constantin Dalyac,Alexandre Dauphin*

Main category: quant-ph

TL;DR: 中性原子量子计算机在模拟非平衡动力学方面已经具有竞争力，相比经典方法在性能相当或更优的同时能耗显著降低。


<details>
  <summary>Details</summary>
Motivation: 比较中性原子量子计算机与经典方法（矩阵乘积态和神经量子态）在模拟非平衡动力学时的运行时间和能耗表现，评估量子计算的能效优势。

Method: 收集量子处理器在模拟模式下的实验数据，结合数值基准测试，通过拟合理论标度定律预测大规模模拟的运行时间和能耗。

Result: 中性原子量子设备已在竞争性范围内运行，实现与经典方法相当或更优的性能，同时能耗显著降低。

Conclusion: 模拟中性原子量子计算在能效模拟方面具有潜力，为可持续计算策略提供了可行路径。

Abstract: We estimate the run-time and energy consumption of simulating non-equilibrium dynamics on neutral atom quantum computers in analog mode, directly comparing their performance to state-of-the-art classical methods, namely Matrix Product States and Neural Quantum States. By collecting both experimental data from a quantum processing unit (QPU) in analog mode and numerical benchmarks, we enable accurate predictions of run-time and energy consumption for large-scale simulations on both QPUs and classical systems through fitting of theoretical scaling laws. Our analysis shows that neutral atom devices are already operating in a competitive regime, achieving comparable or superior performance to classical approaches while consuming significantly less energy. These results demonstrate the potential of analog neutral atom quantum computing for energy-efficient simulation and highlight a viable path toward sustainable computational strategies.

</details>


### [67] [Twin Hamiltonians, three types of the Dyson maps, and the probabilistic interpretation problem in quasi-Hermitian quantum mechanics](https://arxiv.org/abs/2511.20404)
*Aritra Ghosh,Adam Miranowicz,Miloslav Znojil*

Main category: quant-ph

TL;DR: 该论文提出通过Dyson映射将准厄米量子力学中的非厄米哈密顿量转换为厄米形式，从而解决物理解释的模糊性问题，并为量子系统的概率解释提供分类框架。


<details>
  <summary>Details</summary>
Motivation: 在准厄米量子力学中，非厄米哈密顿量H ≠ H†导致物理解释模糊，需要通过指定希尔伯特空间中的非平凡内积度量Θ来解决。

Method: 采用Dyson映射Ω将非厄米哈密顿量H转换为厄米形式𝔥，构造H的厄米等谱孪生体𝔥。

Result: 该方法不仅恢复了量子与经典物理之间的传统对应原理，还为准厄米量子力学框架下所有可容许的量子系统概率解释提供了分类框架。

Conclusion: 通过Dyson映射构造厄米等谱孪生体是解决准厄米量子力学中物理解释模糊性的有效替代策略，具有重要的理论意义。

Abstract: In quasi-Hermitian quantum mechanics (QHQM) of unitary systems, an optimal, calculation-friendly form of Hamiltonian is generally non-Hermitian, $H \neq H^\dagger$. This makes its physical interpretation ambiguous. Without altering $H$, this ambiguity is resolved by specifying a nontrivial inner-product metric $Θ$ in Hilbert space. Here, we focus on an alternative strategy: transforming $H$ into a Hermitian form via the Dyson map $Ω: H \to \mathfrak{h}$. This construction of the Hermitian isospectral twin $\mathfrak{h}$ of $H$ does not only restore the conventional correspondence principle between quantum and classical physics, but it also provides a framework for the exhaustive classification of all admissible probabilistic interpretations of quantum systems in QHQM framework.

</details>


### [68] [Fast Quantum Gates for Neutral Atoms Separated by a Few Tens of Micrometers](https://arxiv.org/abs/2511.20437)
*Matteo Bergonzoni,Rosario Roberto Riso,Guido Pupillo*

Main category: quant-ph

TL;DR: 提出了一种基于里德堡态共振偶极-偶极自旋交换相互作用的中性原子iSWAP门方案，可在20微米以上距离实现快速高保真度双量子比特操作


<details>
  <summary>Details</summary>
Motivation: 传统基于里德堡阻塞的量子门受限于阻塞半径，限制了量子处理器的连接性。本工作旨在扩展有效相互作用范围，实现超越阻塞半径的纠缠操作

Method: 利用单个平滑激光脉冲在强偶极-偶极相互作用下实现量子比特与里德堡态之间的相干激发-交换-退激发动力学，采用最优控制方法优化门性能

Result: 理论计算显示该方案可实现与阻塞基门相当的保真度和持续时间，同时将有效相互作用范围扩展了一个数量级

Conclusion: 该协议为实现快速、高连接性的量子处理器提供了一条可行路径，能够实现超越阻塞半径的纠缠操作

Abstract: We present a theoretical scheme for a family of fast and high-fidelity two-qubit iSWAP gates between neutral atoms separated by more than 20 um, enabled by resonant dipole-dipole spin-exchange interactions between Rydberg states. The protocol harnesses coherent excitation-exchange-deexcitation dynamics between the qubit and the Rydberg states within a single and smooth laser pulse, in the presence of strong dipole-dipole interactions. We utilize optimal control methods to achieve theoretical gate fidelities and durations comparable to blockade-based gates in the presence of relevant noise, while extending the effective interaction range by an order of magnitude. This enables entanglement well beyond the blockade radius, offering a route toward fast, high-connectivity quantum processors.

</details>


### [69] [Efficient Estimation of Multiple Temperatures via a Collisional Model](https://arxiv.org/abs/2511.20448)
*Srijon Ghosh,Sagnik Chakraborty,Rosario Lo Franco*

Main category: quant-ph

TL;DR: 提出了一种基于碰撞模型的量子测温协议，用于同时估计多个温度参数。通过引入辅助系统的受控旋转消除参数间依赖关系，实现了多参数温度联合估计的精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统温度测量方法在同时估计多个温度参数时存在精度限制，特别是在参数间存在相互依赖关系时，Fisher信息矩阵可能出现奇异，影响估计精度。需要开发能够消除参数间依赖、提升多参数温度估计精度的量子方法。

Method: 在碰撞模型框架下，采用多参数量子计量学形式体系。通过辅助系统在连续相互作用阶段之间的受控旋转，消除参数间的相互依赖关系，使量子Fisher信息矩阵非奇异。利用辅助系统中的相关性进一步提升Fisher信息。

Result: 证明了即使在辅助系统无相关性的情况下，多温度联合估计的精度也能超越相应的热Fisher信息极限。辅助系统的相关性可带来额外的Fisher信息增强。辅助系统的维度被确定为多参数温度估计效率的关键因素。

Conclusion: 所提出的量子测温协议能够有效消除多温度估计中的参数依赖问题，显著提升估计精度。辅助系统的维度和相关性对估计效率具有重要影响，为多参数量子计量提供了新的实现途径。

Abstract: We present a quantum thermometric protocol for the estimation of multiple temperatures within the collisional model framework. Employing the formalism of multiparameter quantum metrology, we develop a systematic strategy to estimate the temperatures of several thermal reservoirs with minimal estimation error. We prove a necessary and sufficient condition for the singularity of the Fisher information matrix for a bi-parametrized qubit state. By using controlled rotations of ancillary systems between successive interaction stages, we eliminate parameter interdependencies, thereby rendering the quantum Fisher information matrix non-singular. Remarkably, we demonstrate that precision enhancement in the joint estimation of multiple temperatures can be achieved even in the absence of correlations among the ancillas, surpassing the corresponding thermal Fisher information limits. Exploiting correlations within the ancillary system yields additional enhancement of Fisher information. Finally, we identify the dimensionality of the ancillary systems as a key factor governing the efficiency of multiparameter temperature estimation.

</details>


### [70] [Magnetic Control of the Non-Hermitian Skin Effect in Two-Dimensional Lattices](https://arxiv.org/abs/2511.20518)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 本文研究了磁场如何影响二维晶格中的非厄米趋肤效应(NHSE)，发现磁场可以抑制或消除趋肤效应，其机制包括体态局域化或恢复有效互易性。


<details>
  <summary>Details</summary>
Motivation: 探索磁场或合成规范场如何影响非厄米趋肤效应这一边界现象，这是非厄米物理中的一个核心开放问题。

Method: 开发了二维单带晶格中线边界处NHSE磁控制的理论框架，使用非厄米各向异性Harper-Hofstadter模型作为代表性例子进行分析。

Result: 磁场抑制互易模型中的几何趋肤效应，但在非互易系统中趋肤局域化可以持续存在。磁场通过体态局域化或恢复有效互易性等机制缓解或抑制NHSE。

Conclusion: 互易系统中的几何依赖趋肤效应对弱磁场也很脆弱，磁场通过不同物理机制调控NHSE，为磁控制非厄米现象提供了理论框架。

Abstract: The non-Hermitian skin effect (NHSE) -- the anomalous boundary accumulation of an extensive number of bulk modes -- has emerged as a hallmark of non-Hermitian physics, with broad implications for transport, sensing, and topological classification. A central open question is how magnetic or synthetic gauge fields influence this boundary phenomenon. Here, we develop a theoretical framework for magnetic control of the NHSE along line boundaries in two-dimensional single-band lattices. Using a non-Hermitian extension of the anisotropic Harper--Hofstadter model as a representative example, we show that magnetic fields suppress the geometric skin effect in reciprocal models, whereas skin localization can persist in nonreciprocal systems. The analysis disentangles the interplay of flux, nonreciprocity, and boundary geometry, revealing that magnetic fields mitigate or suppress the NHSE through distinct physical mechanisms -- such as bulk localization via Landau or Anderson physics, or the restoration of effective reciprocity. In particular, the geometry-dependent skin effect in reciprocal systems is found to be fragile against even weak magnetic fields.

</details>


### [71] [Reservoir-Engineered Exceptional Points for Quantum Energy Storage](https://arxiv.org/abs/2511.20569)
*Borhan Ahmadi,André H. A. Malavazi,Paweł Mazurek,Paweł Horodecki,Shabir Barzanjeh*

Main category: quant-ph

TL;DR: 提出了一种在完全被动、物理一致的开放量子系统中实现异常点物理的量子能量存储机制，通过耗散干涉增强能量流动，实现快速充电。


<details>
  <summary>Details</summary>
Motivation: 现有基于异常点的能量存储方法依赖增益、精确平衡损耗或显式非厄米哈密顿量，难以在量子系统中实现。需要开发完全被动且物理一致的异常点能量存储机制。

Method: 使用迹保持的储库工程，通过耗散介质在充电模式和存储模式之间创建有效的复杂相互作用，在Heisenberg-Langevin方程的漂移矩阵中直接生成异常点，同时保持完全正定性。

Result: 系统表现出两个动力学区域：稳定相中存储能量饱和，破缺相中能量在有限相干驱动下指数增长。耗散干涉显著增强了模式间的能量流动，无需增益介质或非线性放大。

Conclusion: 该机制与光机械器件、超导电路和磁子系统兼容，为快速、鲁棒和可扩展的量子能量存储技术提供了实用途径，并开辟了量子热力学的新方向。

Abstract: Exceptional points are spectral singularities where both eigenvalues and eigenvectors collapse onto a single mode, causing the system behavior to shift abruptly and making it highly responsive to even small perturbations. Although widely studied in optical and quantum systems, using them for energy storage in quantum systems has been difficult because existing approaches rely on gain, precise balanced loss, or explicitly non-Hermitian Hamiltonians. Here we introduce a quantum energy-storage mechanism that realizes exceptional-point physics in a fully passive, physically consistent open quantum system. Instead of amplification, we use trace-preserving reservoir engineering to create an effective complex interaction between a charging mode and a storage mode through a dissipative mediator, generating an exceptional point directly in the drift matrix of the Heisenberg-Langevin equations while preserving complete positivity. The resulting dynamics exhibit two regimes: a stable phase where the stored energy saturates, and a broken phase where energy grows exponentially under a bounded coherent drive. This rapid charging arises from dissipative interference that greatly boosts energy flow between the modes without gain media or nonlinear amplification. The mechanism is compatible with optomechanical devices, superconducting circuits, and magnonic systems, offering a practical route to fast, robust, and scalable quantum energy-storage technologies and new directions in quantum thermodynamics.

</details>


### [72] [Dynamic local single-shot checks for toric codes](https://arxiv.org/abs/2511.20576)
*Yingjia Lin,Abhinav Anand,Kenneth R. Brown*

Main category: quant-ph

TL;DR: 本文提出局部单次校验方法，通过约束校验权重并使用动态测量方案，减少量子纠错所需的测量轮次，从而降低容错量子计算的时间开销。


<details>
  <summary>Details</summary>
Motivation: 量子纠错通常需要重复进行综合征提取以应对测量噪声，这导致容错计算中存在显著的时间开销。单次纠错旨在仅通过一轮综合征提取来抑制错误，但大多数编码需要高权重校验，这在电路层面会显著降低甚至消除单次性能。

Method: 引入局部单次校验，对校验权重施加约束，并采用动态测量方案。通过数值模拟验证了在电路级噪声模型下，使用滑动窗口解码时该方法相比传统校验能提高解码性能。

Result: 数值模拟表明，该方法可以将所需测量轮次减少一个由约束决定的因子，在环面码的电路级噪声模型下，使用减小窗口大小的滑动窗口解码时，相比传统校验能提高解码性能。

Conclusion: 这项工作为构建能够减少大规模容错量子计算时间开销的校验提供了新方向。

Abstract: Quantum error correction typically requires repeated syndrome extraction due to measurement noise, which results in substantial time overhead in fault-tolerant computation. Single-shot error correction aims to suppress errors using only one round of syndrome extraction. However, for most codes, it requires high-weight checks, which significantly degrade, and often eliminate, single-shot performance at the circuit level. In this work, we introduce local single-shot checks, where we impose constraints on check weights. Using a dynamic measurement scheme, we show that the number of required measurement rounds can be reduced by a factor determined by this constraint. As an example, we show through numerical simulation that our scheme can improve decoding performance compared to conventional checks when using sliding-window decoding with a reduced window size under circuit-level noise models for toric codes. Our work provides a new direction for constructing checks that can reduce time overhead in large-scale fault-tolerant quantum computation.

</details>


### [73] [Quantum Key Distribution: Bridging Theoretical Security Proofs, Practical Attacks, and Error Correction for Quantum-Augmented Networks](https://arxiv.org/abs/2511.20602)
*Nitin Jha,Abhishek Parakh,Mahadevan Subramaniam*

Main category: quant-ph

TL;DR: 本文综述了量子密钥分发(QKD)协议的最新进展、安全漏洞和实验突破，重点分析三类主要QKD方案及其安全证明，并探讨量子增强网络中的应用。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，将理想化的QKD安全模型转化为实用、弹性的系统面临挑战，需要系统梳理最新进展和安全漏洞。

Method: 批判性分析和综合最新QKD协议及安全漏洞，将当代QKD方案分为三类：基于不确定性原理的协议、混合架构协议和连续变量框架，并纳入双场QKD和设备无关QKD等现代协议。

Result: 识别了重要的实验突破和创新缓解策略，包括先进量子纠错码的部署，显著提升了信道保真度和系统鲁棒性。

Conclusion: 通过从复杂量子攻击到最先进纠错方法的全面分析，填补了文献空白，为读者提供了从理论证明到实验验证的QKD安全承诺的全面理解。

Abstract: Quantum Key Distribution (QKD) is revolutionizing cryptography by promising information-theoretic security through the immutable laws of quantum mechanics. Yet, the challenge of transforming these idealized security models into practical, resilient systems remains a pressing issue, especially as quantum computing evolves. In this review, we critically dissect and synthesize the latest advancements in QKD protocols and their security vulnerabilities, with a strong emphasis on rigorous security proofs. We actively categorize contemporary QKD schemes into three key classes: uncertainty principle-based protocols (e.g., BB84), hybrid architectures that enable secure direct communication (eg, three-stage protocol), and continuous-variable frameworks. We further include two modern classes of QKD protocols, namely Twin-field QKD and Device-Independent QKD, both of which were developed to have practical implementations over the last decade. Moreover, we highlight important experimental breakthroughs and innovative mitigation strategies, including the deployment of advanced Quantum Error Correction Codes (QECCs), that significantly enhance channel fidelity and system robustness. By mapping the current landscape, from sophisticated quantum attacks to state-of-the-art error correction methods, this review fills an important gap in the literature. To bring everything together, the relevance of this review concerning quantum augmented networks (QuANets) is also presented. This allows the readers to gain a comprehensive understanding of the security promises of quantum key distribution from theoretical proofs to experimental validations.

</details>


### [74] [Asymptotic yet practical optimization of quantum circuits implementing GF($2^m$) multiplication and division operations](https://arxiv.org/abs/2511.20618)
*Noureldin Yosri,Dmitri Maslov*

Main category: quant-ph

TL;DR: 提出了优化的GF(2^m)乘法和除法量子电路，乘法电路复杂度从O(m²)降至O(m^log₂³)，除法电路从O(m²logm)降至O(m²loglogm/logm)，并展示了在密码学相关参数下的实际优势。


<details>
  <summary>Details</summary>
Motivation: GF(2^m)乘法和除法是量子算法中的基本计算原语，需要优化其量子电路实现以提高效率。

Method: 通过开发高效的常数多项式1+x^⌈m/2⌉乘法电路（复杂度O(m)），改进Van Hoof构造；选择可同时高效实现常数多项式乘法和域平方运算的不可约多项式。

Result: 乘法电路门数复杂度从O(m²)降至O(m^log₂³)，除法电路从O(m²logm)降至O(m²loglogm/logm)，在实用参数下CNOT门数改进超过100倍。

Conclusion: 提出的优化方法显著降低了GF(2^m)运算的量子电路复杂度，在密码学相关参数下具有实际优势，同时证明了线性可逆酉算子的平方根实现可能比原算子需要更深电路。

Abstract: We present optimized quantum circuits for GF$(2^m)$ multiplication and division operations, which are essential computing primitives in various quantum algorithms. Our ancilla-free GF multiplication circuit has the gate count complexity of $O(m^{\log_2{3}})$, an improvement over the previous best bound of $O(m^2)$. This was achieved by developing an efficient $O(m)$ circuit for multiplication by the constant polynomial $1+x^{\lceil{m/2}\rceil}$, a key component of Van Hoof's construction. This asymptotic reduction translates to a factor of 100+ improvement of the $\cnotgate$ gate counts in the implementation of the multiplication by the constant for parameters $m$ of practical importance. For the GF division, we reduce gate count complexity from $O(m^2 \log(m))$ to $O(m^2 \log \log(m)/\log(m))$ by selecting irreducible polynomials that enable efficient implementation of both the constant polynomial multiplication and field squaring operations. We demonstrate practical advantages for cryptographically relevant values of $m$. Additionally, we explore the complexity of implementing square roots of linear reversible unitaries and demonstrate that a root, although itself still a linear reversible transformation, can require asymptotically deeper circuit implementations than the original unitary.

</details>


### [75] [Extracting conserved operators from a projected entangled pair state](https://arxiv.org/abs/2511.20619)
*Wen-Tao Xu,Miguel Frías Pérez,Mingru Yang*

Main category: quant-ph

TL;DR: 提出了一种从张量网络态中提取几何k局域守恒算子的方法，能够找到使给定iPEPS成为（近似）本征态的哈密顿量


<details>
  <summary>Details</summary>
Motivation: 解决如何从给定的张量网络态确定守恒算子（包括哈密顿量）的问题，使得该态成为这些算子的本征态

Method: 通过微分生成函数计算多站点算子的静态结构因子，从精确或变分iPEPS中提取几何k局域守恒算子

Result: 能够高精度提取超出标准构造的无阻挫和非无阻挫父哈密顿量，获得更好的局域性；找到了使短程RVB态近似为基态的4站点局域哈密顿量；发现了在任意弦张力下具有变形环面码态作为相同能量激发本征态的哈密顿量

Conclusion: 该方法能够有效提取张量网络态的守恒算子，为量子多体疤痕等研究提供了潜在候选者

Abstract: Given a tensor network state, how can we determine conserved operators (including Hamiltonians) for which the state is an eigenstate? We answer this question by presenting a method to extract geometrically $k$-local conserved operators that have the given infinite projected entangled pair state (iPEPS) in 2D as an (approximate) eigenstate. The key ingredient is the evaluation of the static structure factors of multi-site operators through differentiating the generating function. Despite the approximation errors, we show that our method is still able to extract from exact or variational iPEPS to good precision both frustration-free and non-frustration-free parent Hamiltonians that are beyond the standard construction and obtain better locality. In particular, we find a 4-site-plaquette local Hamiltonian that approximately has the short-range RVB state as the ground state. Moreover, we find a Hamiltonian that has the deformed toric code state at any string tension as excited eigenstates at the same energy, which might be potential candidates for quantum many-body scars.

</details>


### [76] [Routing in Non-Isotonic Quantum Networks](https://arxiv.org/abs/2511.20628)
*Maxwell Tang,Garrett Hinkley,Kenneth Goodenough,Stefan Krastanov,Guus Avis*

Main category: quant-ph

TL;DR: 提出了改进的量子中继网络路由算法，包括两种最佳优先搜索算法和元启发式算法，解决了传统路由算法不适用于非等距效用函数的问题。


<details>
  <summary>Details</summary>
Motivation: 量子中继网络中的最优路由需要找到连接终端节点的最佳路径。大多数现有工作假设效用函数是等距的，但考虑纠缠生成速率和质量的效用函数（如密钥率）通常是非等距的，这使得Dijkstra等经典算法不再适用，目前最先进的方法是穷举搜索所有可能路径。

Method: 提出了两种改进算法：1）两种使用目标感知优值函数的最佳优先搜索算法，其中一种可证明找到最佳路径，另一种使用启发式方法实现查询次数的有效次线性扩展；2）元启发式算法（模拟退火和遗传算法），可在路径质量和计算开销之间进行权衡。

Result: 新算法能够有效处理非等距效用函数，相比穷举搜索显著提高了计算效率，同时保持找到接近最优的路径。

Conclusion: 这些算法为量子中继网络提供了高效的路由解决方案，可推广到不同的中继方案和模型，解决了传统路由算法在量子网络中的局限性。

Abstract: Optimal routing in quantum-repeater networks requires finding the best path that connects a pair of end nodes. Most previous work on routing in quantum networks assumes utility functions that are isotonic, meaning that the ordering of two paths does not change when extending both with the same edge. However, we show that utility functions that take into account both the rate and quality of the entanglement generation (e.g., the secret-key rate) are often non-isotonic. This makes pathfinding difficult as classical algorithms such as Dijkstra's become unsuitable, with the state of the art for quantum networks being an exhaustive search over all possible paths. In this work we present improved algorithms. First, we present two best-first-search algorithms that use destination-aware merit functions for faster convergence. One of these provably finds the best path, while the other uses heuristics to achieve an effectively sublinear scaling of the query count in the network size while in practice always finding a close-to-optimal path. Second, we present metaheuristic algorithms (simulated annealing and a genetic algorithm) that enable tuning a tradeoff between path quality and computational overhead. While we focus on swap-ASAP quantum repeaters for concreteness, our algorithms are readily generalized to different repeater schemes and models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [77] [Hidden markov model to predict tourists visited place](https://arxiv.org/abs/2511.19465)
*Theo Demessance,Chongke Bi,Sonia Djebali,Guillaume Guerard*

Main category: cs.LG

TL;DR: 基于社交网络数据分析游客移动行为，使用机器学习语法推理算法预测游客未来移动轨迹，特别针对大数据环境进行算法适配，以巴黎为例验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 社交网络中游客留下的数字痕迹为分析旅游行为提供了丰富数据，预测游客移动对旅游营销和决策支持至关重要。

Method: 采用机器学习语法推理算法，构建隐马尔可夫模型来表示游客移动模式，并针对大数据环境进行算法适配。

Result: 成功构建了灵活可编辑的隐马尔可夫模型，能够表示游客群体的移动行为，并以巴黎案例验证了方法的有效性。

Conclusion: 该方法能够有效利用社交网络数据预测游客移动，为旅游营销和决策支持提供有力工具。

Abstract: Nowadays, social networks are becoming a popular way of analyzing tourist behavior, thanks to the digital traces left by travelers during their stays on these networks. The massive amount of data generated; by the propensity of tourists to share comments and photos during their trip; makes it possible to model their journeys and analyze their behavior. Predicting the next movement of tourists plays a key role in tourism marketing to understand demand and improve decision support. In this paper, we propose a method to understand and to learn tourists' movements based on social network data analysis to predict future movements. The method relies on a machine learning grammatical inference algorithm. A major contribution in this paper is to adapt the grammatical inference algorithm to the context of big data. Our method produces a hidden Markov model representing the movements of a group of tourists. The hidden Markov model is flexible and editable with new data. The capital city of France, Paris is selected to demonstrate the efficiency of the proposed methodology.

</details>


### [78] [A Cartesian Encoding Graph Neural Network for Crystal Structures Property Prediction: Application to Thermal Ellipsoid Estimation](https://arxiv.org/abs/2501.18369)
*Àlex Solé,Albert Mosella-Montoro,Joan Cardona,Silvia Gómez-Coca,Daniel Aravena,Eliseo Ruiz,Javier Ruiz-Hidalgo*

Main category: cs.LG

TL;DR: CartNet是一种新颖的图神经网络，通过将原子几何编码为笛卡尔坐标并结合晶体温度，有效预测晶体特性。它采用邻居均衡技术强调共价和接触相互作用，以及基于Cholesky的头部确保有效的ADP预测。在训练期间使用旋转SO(3)数据增强处理未见方向。


<details>
  <summary>Details</summary>
Motivation: 在基于衍射的晶体结构分析中，热椭球体（通过各向异性位移参数ADPs量化）至关重要但难以确定。传统计算方法通常昂贵，需要开发更高效的预测方法。

Method: 提出CartNet图神经网络，将原子几何编码为笛卡尔坐标和晶体温度。集成邻居均衡技术强调相互作用，使用Cholesky-based头部确保有效ADP预测，并在训练中采用旋转SO(3)数据增强。

Result: 在ADP预测方面比现有方法提升10.87%，比理论方法提升34.77%。在Jarvis数据集上提升7.71%，在Materials Project数据集上提升13.16%。显著降低计算成本。

Conclusion: CartNet为各种晶体特性预测建立了最先进的解决方案，在多个数据集上表现出优越性能。

Abstract: In diffraction-based crystal structure analysis, thermal ellipsoids, quantified via Anisotropic Displacement Parameters (ADPs), are critical yet challenging to determine. ADPs capture atomic vibrations, reflecting thermal and structural properties, but traditional computation is often expensive. This paper introduces CartNet, a novel graph neural network (GNN) for efficiently predicting crystal properties by encoding atomic geometry into Cartesian coordinates alongside the crystal temperature. CartNet integrates a neighbour equalization technique to emphasize covalent and contact interactions, and a Cholesky-based head to ensure valid ADP predictions. We also propose a rotational SO(3) data augmentation strategy during training to handle unseen orientations. An ADP dataset with over 200,000 experimental crystal structures from the Cambridge Structural Database (CSD) was curated to validate the approach. CartNet significantly reduces computational costs and outperforms existing methods in ADP prediction by 10.87%, while delivering a 34.77% improvement over theoretical approaches. We further evaluated CartNet on other datasets covering formation energy, band gap, total energy, energy above the convex hull, bulk moduli, and shear moduli, achieving 7.71% better results on the Jarvis Dataset and 13.16% on the Materials Project Dataset. These gains establish CartNet as a state-of-the-art solution for diverse crystal property predictions. Project website and online demo: https://www.ee.ub.edu/cartnet

</details>


### [79] [Quantifying Modality Contributions via Disentangling Multimodal Representations](https://arxiv.org/abs/2511.19470)
*Padegal Amit,Omkar Mahesh Kashyap,Namitha Rayasam,Nidhi Shekhar,Surabhi Narayan*

Main category: cs.LG

TL;DR: 提出了一个基于部分信息分解的框架，通过分解内部嵌入中的预测信息来量化模态贡献，区分独特、冗余和协同组件。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖基于准确性的方法，将移除模态后的性能下降解释为其影响，但这类结果驱动指标无法区分模态是固有信息还是仅通过与其他模态交互产生价值。

Method: 基于部分信息分解框架，开发了基于迭代比例拟合程序的算法，计算层和数据集级别的贡献而无需重新训练。

Result: 提供了一个原则性的、表示级别的多模态行为视图，比基于结果的指标提供更清晰和可解释的见解。

Conclusion: 该框架能够量化模态贡献，区分模态的固有信息和交互价值，为多模态模型提供更深入的洞察。

Abstract: Quantifying modality contributions in multimodal models remains a challenge, as existing approaches conflate the notion of contribution itself. Prior work relies on accuracy-based approaches, interpreting performance drops after removing a modality as indicative of its influence. However, such outcome-driven metrics fail to distinguish whether a modality is inherently informative or whether its value arises only through interaction with other modalities. This distinction is particularly important in cross-attention architectures, where modalities influence each other's representations. In this work, we propose a framework based on Partial Information Decomposition (PID) that quantifies modality contributions by decomposing predictive information in internal embeddings into unique, redundant, and synergistic components. To enable scalable, inference-only analysis, we develop an algorithm based on the Iterative Proportional Fitting Procedure (IPFP) that computes layer and dataset-level contributions without retraining. This provides a principled, representation-level view of multimodal behavior, offering clearer and more interpretable insights than outcome-based metrics.

</details>


### [80] [PrefixGPT: Prefix Adder Optimization by a Generative Pre-trained Transformer](https://arxiv.org/abs/2511.19472)
*Ruogu Ding,Xin Ning,Ulf Schlichtmann,Weikang Qian*

Main category: cs.LG

TL;DR: PrefixGPT是一种基于GPT的生成模型，能够从零开始直接生成优化的前缀加法器，在保持设计合法性的同时显著改善面积-延迟乘积。


<details>
  <summary>Details</summary>
Motivation: 前缀加法器在计算密集型应用中广泛使用，但由于严格的设计规则和指数级大的设计空间，设计优化的前缀加法器具有挑战性。

Method: 将加法器拓扑表示为二维坐标序列，在生成过程中应用合法性掩码确保设计有效，采用定制化的仅解码器Transformer架构，先预训练学习设计规则，再微调优化设计质量。

Result: 发现了一个新的最优设计，面积-延迟乘积改善了7.7%，平均ADP降低了高达79.1%，展现出优越的探索质量。

Conclusion: GPT风格模型有潜力首先掌握复杂的硬件设计原则，然后将其应用于更高效的设计优化。

Abstract: Prefix adders are widely used in compute-intensive applications for their high speed. However, designing optimized prefix adders is challenging due to strict design rules and an exponentially large design space. We introduce PrefixGPT, a generative pre-trained Transformer (GPT) that directly generates optimized prefix adders from scratch. Our approach represents an adder's topology as a two-dimensional coordinate sequence and applies a legality mask during generation, ensuring every design is valid by construction. PrefixGPT features a customized decoder-only Transformer architecture. The model is first pre-trained on a corpus of randomly synthesized valid prefix adders to learn design rules and then fine-tuned to navigate the design space for optimized design quality. Compared with existing works, PrefixGPT not only finds a new optimal design with a 7.7% improved area-delay product (ADP) but exhibits superior exploration quality, lowering the average ADP by up to 79.1%. This demonstrates the potential of GPT-style models to first master complex hardware design principles and then apply them for more efficient design optimization.

</details>


### [81] [WavefrontDiffusion: Dynamic Decoding Schedule or Improved Reasoning](https://arxiv.org/abs/2511.19473)
*Haojin Yang,Rui Hu,Zequn Sun,Rui Zhou,Yujun Cai,Yiwei Wang*

Main category: cs.LG

TL;DR: WavefrontDiffusion是一种动态解码方法，通过从已确定位置向外扩展活动标记波前，在保持与基于块的方法相同计算成本的同时，实现更好的语义连贯性和推理性能。


<details>
  <summary>Details</summary>
Motivation: 主流去噪策略存在缺陷：标准扩散会过早结束序列预测，块扩散的刚性结构会破坏语义单元的连贯性，因此需要一种更自然跟随语义结构的自适应调度方法。

Method: 提出WavefrontDiffusion方法，动态扩展活动标记波前，从已确定位置向外自适应扩散，保持计算效率的同时更好地遵循语义结构。

Result: 在四个推理和代码生成基准测试中达到最先进性能，生成的输出具有更高的语义保真度。

Conclusion: 自适应调度对于实现更连贯和高效的文本生成具有重要价值，WavefrontDiffusion展示了扩散语言模型在文本生成方面的竞争力。

Abstract: Diffusion Language Models (DLMs) have shown strong potential for text generation and are becoming a competitive alternative to autoregressive models. The denoising strategy plays an important role in determining the quality of their outputs. Mainstream denoising strategies include Standard Diffusion and BlockDiffusion. Standard Diffusion performs global denoising without restricting the update range, often finalizing incomplete context and causing premature end-of-sequence predictions. BlockDiffusion updates fixed-size blocks in a preset order, but its rigid structure can break apart coherent semantic units and disrupt reasoning. We present WavefrontDiffusion, a dynamic decoding approach that expands a wavefront of active tokens outward from finalized positions. This adaptive process follows the natural flow of semantic structure while keeping computational cost equal to block-based methods. Across four benchmarks in reasoning and code generation, WavefrontDiffusion achieves state-of-the-art performance while producing outputs with higher semantic fidelity, showing the value of adaptive scheduling for more coherent and efficient generation.

</details>


### [82] [Exploiting the Experts: Unauthorized Compression in MoE-LLMs](https://arxiv.org/abs/2511.19480)
*Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Dheeraj Kulshrestha,Rajiv Ramnath*

Main category: cs.LG

TL;DR: 本文系统研究了MoE-LLMs在任务特定使用下的可剪枝性，揭示了知识损失与恢复的权衡，并提出了防御策略来防止未经授权的模型压缩和微调。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然具有可扩展性和效率优势，但其模块化结构引入了独特的安全漏洞：攻击者可以通过剪枝专家并廉价微调剩余部分来绕过许可和安全约束。

Method: 开发了专家归因框架识别特定任务的关键专家子集，评估剪枝和重新对齐的性能权衡，使用主动学习驱动的微调方法。

Result: 研究发现存在关键的知识损失-恢复权衡：虽然可以隔离某些专家来保持任务准确性，但如果没有针对性的重新对齐，会出现显著性能下降。

Conclusion: 通过将专家剪枝同时定位为威胁向量和防御目标，这项工作突出了MoE模块化的双重用途性质，并为MoE-LLMs的安全专业化提供了首个系统评估框架。

Abstract: Mixture-of-Experts (MoE) architectures are increasingly adopted in large language models (LLMs) for their scalability and efficiency. However, their modular structure introduces a unique vulnerability: adversaries can attempt to compress or repurpose models by pruning experts and cheaply fine-tuning the remainder, effectively bypassing licensing and security constraints. In this paper, we systematically study the prunability of MoE-LLMs under task-specific usage. We first develop an expert attribution framework that identifies the subset of experts most responsible for a given task, then evaluate the performance trade-offs of pruning and re-aligning these experts using active learning-driven fine-tuning. Our findings reveal a critical knowledge loss--recovery trade-off: while certain experts can be isolated to retain task accuracy, significant degradation occurs without targeted re-alignment. Based on this analysis, we propose defense strategies that aim to make MoE models harder to compress and fine-tune without authorization, including entangled expert training and selective fine-tuning protocols that resist unauthorized adaptation. By positioning expert pruning as both a threat vector and a defense target, this work highlights the dual-use nature of MoE modularity and provides the first systematic evaluation framework for secure specialization of MoE-LLMs.

</details>


### [83] [Quality analysis and evaluation prediction of RAG retrieval based on machine learning algorithms](https://arxiv.org/abs/2511.19481)
*Ruoxin Zhang,Zhizhao Wen,Chao Wang,Chenchen Tang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 本文提出基于特征工程和粒子群优化的XGBoost回归模型，用于优化RAG系统中检索模块的质量，通过提高文档相关性来改善生成内容的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统的性能高度依赖检索模块质量，当检索结果与用户需求相关性低或包含噪声信息时，会导致生成内容失真。现有模型在处理表格特征方面存在性能瓶颈。

Method: 采用基于特征工程和粒子群优化的XGBoost机器学习回归模型，通过相关性分析识别关键特征，并与决策树、AdaBoost等模型进行对比实验。

Result: VMD PSO BiLSTM模型在所有评估指标上表现最优，MSE、RMSE、MAE和MAPE显著低于对比模型，R2值更高，表明其预测精度、稳定性和数据解释能力更突出。

Conclusion: 该成果为优化RAG系统检索质量和改善生成效果提供了有效路径，对推动相关技术的实施和应用具有重要价值。

Abstract: With the rapid evolution of large language models, retrieval enhanced generation technology has been widely used due to its ability to integrate external knowledge to improve output accuracy. However, the performance of the system is highly dependent on the quality of the retrieval module. If the retrieval results have low relevance to user needs or contain noisy information, it will directly lead to distortion of the generated content. In response to the performance bottleneck of existing models in processing tabular features, this paper proposes an XGBoost machine learning regression model based on feature engineering and particle swarm optimization. Correlation analysis shows that answer_quality is positively correlated with doc_delevance by 0.66, indicating that document relevance has a significant positive effect on answer quality, and improving document relevance may enhance answer quality; The strong negative correlations between semantic similarity, redundancy, and diversity were -0.89 and -0.88, respectively, indicating a tradeoff between semantic similarity, redundancy, and diversity. In other words, as the former two increased, diversity significantly decreased. The experimental results comparing decision trees, AdaBoost, etc. show that the VMD PSO BiLSTM model is superior in all evaluation indicators, with significantly lower MSE, RMSE, MAE, and MAPE compared to the comparison model. The R2 value is higher, indicating that its prediction accuracy, stability, and data interpretation ability are more outstanding. This achievement provides an effective path for optimizing the retrieval quality and improving the generation effect of RAG system, and has important value in promoting the implementation and application of related technologies.

</details>


### [84] [OmniTFT: Omni Target Forecasting for Vital Signs and Laboratory Result Trajectories in Multi Center ICU Data](https://arxiv.org/abs/2511.19485)
*Wanzhe Xu,Yutong Dai,Yitao Yang,Martin Loza,Weihang Zhang,Yang Cui,Xin Zeng,Sung Joon Park,Kenta Nakai*

Main category: cs.LG

TL;DR: OmniTFT是一个基于Temporal Fusion Transformer的深度学习框架，能够联合预测ICU中的高频生命体征和稀疏采样的实验室结果，通过四种创新策略提升性能，并在多个数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: ICU中生命体征存在噪声和快速波动，实验室检查存在缺失值、测量延迟和设备特定偏差等问题，使得整合预测极具挑战性。

Method: 提出OmniTFT框架，采用滑动窗口均衡采样、频率感知嵌入收缩、分层变量选择和影响对齐注意力校准四种策略来增强性能。

Result: 在MIMIC-III、MIMIC-IV和eICU数据集上，OmniTFT在生命体征和实验室结果的预测任务中都取得了显著的性能提升。

Conclusion: OmniTFT能够统一建模多个异质临床目标，保持跨机构泛化能力，其注意力模式可解释且与已知病理生理学一致，具有临床决策支持的潜在应用价值。

Abstract: Accurate multivariate time-series prediction of vital signs and laboratory results is crucial for early intervention and precision medicine in intensive care units (ICUs). However, vital signs are often noisy and exhibit rapid fluctuations, while laboratory tests suffer from missing values, measurement lags, and device-specific bias, making integrative forecasting highly challenging. To address these issues, we propose OmniTFT, a deep learning framework that jointly learns and forecasts high-frequency vital signs and sparsely sampled laboratory results based on the Temporal Fusion Transformer (TFT). Specifically, OmniTFT implements four novel strategies to enhance performance: sliding window equalized sampling to balance physiological states, frequency-aware embedding shrinkage to stabilize rare-class representations, hierarchical variable selection to guide model attention toward informative feature clusters, and influence-aligned attention calibration to enhance robustness during abrupt physiological changes. By reducing the reliance on target-specific architectures and extensive feature engineering, OmniTFT enables unified modeling of multiple heterogeneous clinical targets while preserving cross-institutional generalizability. Across forecasting tasks, OmniTFT achieves substantial performance improvement for both vital signs and laboratory results on the MIMIC-III, MIMIC-IV, and eICU datasets. Its attention patterns are interpretable and consistent with known pathophysiology, underscoring its potential utility for quantitative decision support in clinical care.

</details>


### [85] [Efficient Inference Using Large Language Models with Limited Human Data: Fine-Tuning then Rectification](https://arxiv.org/abs/2511.19486)
*Lei Wang,Zikun Ye,Jinglong Zhao*

Main category: cs.LG

TL;DR: 提出一个结合微调和修正的框架，通过优化分配有限标注样本来提升LLM在市场研究和社科应用中的表现，使用预测误差方差最小化作为微调目标。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要单独使用微调或修正来提升LLM性能，但缺乏系统性的框架来结合这两种方法并优化有限的标注样本分配。

Method: 开发结合微调和修正的框架，以预测误差方差最小化为微调目标，利用经验缩放定律优化样本在微调和修正阶段的分配。

Result: 实证分析验证了该框架相比单独使用微调或修正方法，在估计和推断性能方面均有提升。

Conclusion: 提出的框架通过优化样本分配和微调目标，有效提升了LLM在市场研究和社科应用中的表现。

Abstract: Driven by recent advances in artificial intelligence (AI), a growing body of work demonstrates the potential of using large language models (LLMs) to generate human-like responses in market research and social science applications. Two primary approaches can be applied to improve the performance of LLMs: fine-tuning, which aligns LLM predictions more closely with human responses, and rectification, which corrects biases in LLM outputs. In this paper, we develop a framework that combines fine-tuning and rectification, and optimally allocates limited labeled samples across the two stages. Unlike the conventional objective that minimizes the mean squared prediction errors, we propose to minimize the variance of the prediction errors as the fine-tuning objective, which is optimal for the downstream rectification stage. Building on this insight, we leverage empirical scaling laws to develop a data-driven method for optimally splitting samples between the fine-tuning and rectification stages. Empirical analysis validates our framework, demonstrating improved estimation and inference performance compared to using either fine-tuning or rectification alone.

</details>


### [86] [The Generalized Proximity Forest](https://arxiv.org/abs/2511.19487)
*Ben Shaw,Adam Rustad,Sofia Pelagalli Maia,Jake S. Rhodes,Kevin R. Moon*

Main category: cs.LG

TL;DR: 本文提出了广义邻近森林模型，将随机森林邻近性扩展到所有基于距离的监督机器学习场景，并引入了回归任务变体和元学习框架。


<details>
  <summary>Details</summary>
Motivation: 随机森林邻近性在监督学习任务中很有用，但其效用依赖于随机森林模型本身，而随机森林并非在所有场景下都是理想模型。需要将邻近性扩展到更广泛的机器学习场景。

Method: 提出了广义邻近森林模型，将随机森林邻近性扩展到所有基于距离的监督学习场景；引入了回归任务变体；提出了使用广义邻近森林作为元学习框架的方法。

Result: 实验证明广义邻近森林模型相比随机森林模型和k近邻模型具有独特优势。

Conclusion: 广义邻近森林模型成功扩展了随机森林邻近性的应用范围，为基于距离的监督学习提供了新的有效工具。

Abstract: Recent work has demonstrated the utility of Random Forest (RF) proximities for various supervised machine learning tasks, including outlier detection, missing data imputation, and visualization. However, the utility of the RF proximities depends upon the success of the RF model, which itself is not the ideal model in all contexts. RF proximities have recently been extended to time series by means of the distance-based Proximity Forest (PF) model, among others, affording time series analysis with the benefits of RF proximities. In this work, we introduce the generalized PF model, thereby extending RF proximities to all contexts in which supervised distance-based machine learning can occur. Additionally, we introduce a variant of the PF model for regression tasks. We also introduce the notion of using the generalized PF model as a meta-learning framework, extending supervised imputation capability to any pre-trained classifier. We experimentally demonstrate the unique advantages of the generalized PF model compared with both the RF model and the $k$-nearest neighbors model.

</details>


### [87] [Generative Model-Aided Continual Learning for CSI Feedback in FDD mMIMO-OFDM Systems](https://arxiv.org/abs/2511.19490)
*Guijun Liu,Yuwen Cao,Tomoaki Ohtsuki,Jiguang He,Shahid Mumtaz*

Main category: cs.LG

TL;DR: 提出基于GAN的持续学习方法解决CSI反馈中的环境动态变化和灾难性遗忘问题，通过GAN生成器作为记忆单元保持历史知识，提升DAE框架的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有CSI反馈模型难以适应由用户移动性引起的动态环境变化，遇到新CSI分布时需要重新训练，且返回先前环境时会出现灾难性遗忘导致的性能下降。

Method: 使用GAN生成器作为记忆单元，通过生成对抗网络保存过去环境的知识，确保在不同场景下保持高性能而不遗忘。

Result: 仿真结果表明，该方法增强了DAE框架的泛化能力，同时保持低内存开销，并能与其他先进CSI反馈模型无缝集成。

Conclusion: 所提出的GAN-based学习方法具有鲁棒性和适应性，能有效解决CSI反馈中的持续学习问题。

Abstract: Deep autoencoder (DAE) frameworks have demonstrated their effectiveness in reducing channel state information (CSI) feedback overhead in massive multiple-input multiple-output (mMIMO) orthogonal frequency division multiplexing (OFDM) systems. However, existing CSI feedback models struggle to adapt to dynamic environments caused by user mobility, requiring retraining when encountering new CSI distributions. Moreover, returning to previously encountered environments often leads to performance degradation due to catastrophic forgetting. Continual learning involves enabling models to incorporate new information while maintaining performance on previously learned tasks. To address these challenges, we propose a generative adversarial network (GAN)-based learning approach for CSI feedback. By using a GAN generator as a memory unit, our method preserves knowledge from past environments and ensures consistently high performance across diverse scenarios without forgetting. Simulation results show that the proposed approach enhances the generalization capability of the DAE framework while maintaining low memory overhead. Furthermore, it can be seamlessly integrated with other advanced CSI feedback models, highlighting its robustness and adaptability.

</details>


### [88] [OpenCML: End-to-End Framework of Open-world Machine Learning to Learn Unknown Classes Incrementally](https://arxiv.org/abs/2511.19491)
*Jitendra Parmar,Praveen Singh Thakur*

Main category: cs.LG

TL;DR: 提出了一种开放世界机器学习模型，通过发现未知类别和增量学习新类别来实现持续学习，在开放世界学习和持续学习任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型遵循封闭世界假设，无法保留先前学到的知识用于未来任务，而自动化智能系统需要学习新类别和已知任务。

Method: 模型包含两个相互连接的任务：首先发现数据中的未知类别并创建新类别，然后对每个新类别进行增量学习，从而实现持续学习。

Result: 在开放世界学习中优于现有方法，在持续学习中四个迭代的平均准确率达到82.54%，最低准确率为65.87%。

Conclusion: 该模型能够在开放和持续学习环境中有效扩展对数据的理解并随时间改进，为开放世界机器学习提供了有效解决方案。

Abstract: Open-world machine learning is an emerging technique in artificial intelligence, where conventional machine learning models often follow closed-world assumptions, which can hinder their ability to retain previously learned knowledge for future tasks. However, automated intelligence systems must learn about novel classes and previously known tasks. The proposed model offers novel learning classes in an open and continuous learning environment. It consists of two different but connected tasks. First, it discovers unknown classes in the data and creates novel classes; next, it learns how to perform class incrementally for each new class. Together, they enable continual learning, allowing the system to expand its understanding of the data and improve over time. The proposed model also outperformed existing approaches in open-world learning. Furthermore, it demonstrated strong performance in continuous learning, achieving a highest average accuracy of 82.54% over four iterations and a minimum accuracy of 65.87%.

</details>


### [89] [RFX: High-Performance Random Forests with GPU Acceleration and QLORA Compression](https://arxiv.org/abs/2511.19493)
*Chris Kuchar*

Main category: cs.LG

TL;DR: RFX v1.0是一个生产就绪的随机森林Python实现，通过QLORA压缩和TriBlock存储等技术解决了邻近矩阵内存瓶颈，使随机森林分析能够处理超过20万样本的大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 传统随机森林分析受限于邻近矩阵的内存瓶颈，最多只能处理约6万个样本，限制了在大规模数据集上的应用。

Method: 提出了四种解决方案：(1) QLORA压缩用于GPU邻近矩阵，实现12,500倍压缩；(2) CPU TriBlock邻近矩阵存储，结合上三角存储和块稀疏阈值；(3) SM感知GPU批处理大小；(4) GPU加速3D MDS可视化。

Result: GPU邻近矩阵内存从80GB减少到6.4MB（100k样本），保持99%几何结构；CPU TriBlock实现2.7倍无损内存减少；GPU比CPU在500+树时提速1.4倍；支持从1,000到200,000+样本的邻近计算。

Conclusion: RFX v1.0消除了邻近矩阵内存瓶颈，使基于邻近的随机森林分析能够处理比以往大几个数量级的数据集，提供了开源的生产就绪分类实现。

Abstract: RFX (Random Forests X), where X stands for compression or quantization, presents a production-ready implementation of Breiman and Cutler's Random Forest classification methodology in Python. RFX v1.0 provides complete classification: out-of-bag error estimation, overall and local importance measures, proximity matrices with QLORA compression, case-wise analysis, and interactive visualization (rfviz)--all with CPU and GPU acceleration. Regression, unsupervised learning, CLIQUE importance, and RF-GAP proximity are planned for v2.0.
  This work introduces four solutions addressing the proximity matrix memory bottleneck limiting Random Forest analysis to ~60,000 samples: (1) QLORA (Quantized Low-Rank Adaptation) compression for GPU proximity matrices, reducing memory from 80GB to 6.4MB for 100k samples (12,500x compression with INT8 quantization) while maintaining 99% geometric structure preservation, (2) CPU TriBlock proximity--combining upper-triangle storage with block-sparse thresholding--achieving 2.7x memory reduction with lossless quality, (3) SM-aware GPU batch sizing achieving 95% GPU utilization, and (4) GPU-accelerated 3D MDS visualization computing embeddings directly from low-rank factors using power iteration.
  Validation across four implementation modes (GPU/CPU x case-wise/non-case-wise) demonstrates correct implementation. GPU achieves 1.4x speedup over CPU for overall importance with 500+ trees. Proximity computation scales from 1,000 to 200,000+ samples (requiring GPU QLORA), with CPU TriBlock filling the gap for medium-scale datasets (10K-50K samples). RFX v1.0 eliminates the proximity memory bottleneck, enabling proximity-based Random Forest analysis on datasets orders of magnitude larger than previously feasible. Open-source production-ready classification following Breiman and Cutler's original methodology.

</details>


### [90] [A Systematic Study of Compression Ordering for Large Language Models](https://arxiv.org/abs/2511.19495)
*Shivansh Chhawri,Rahul Mahadik,Suparna Rooj*

Main category: cs.LG

TL;DR: 本文系统研究了知识蒸馏、结构化剪枝和低位量化三种LLM压缩技术的独立效果和组合顺序，发现在Qwen2.5 3B模型上，P-KD-Q（剪枝-知识蒸馏-量化）序列能实现3.68倍压缩比，同时保持最佳性能。


<details>
  <summary>Details</summary>
Motivation: LLM需要大量计算资源，在受限环境中部署需要模型压缩。虽然各种压缩技术单独效果已有研究，但它们的交互作用和最优顺序仍不清楚。

Method: 在Qwen2.5 3B模型上系统评估多种压缩流水线，包括单技术和三技术组合序列，使用困惑度、G-Eval、清晰度、提示对齐和压缩比作为评估指标。

Result: 量化提供最大的独立压缩，剪枝引入中等质量下降。技术顺序显著影响最终质量：P-KD-Q序列表现最佳，达到3.68倍压缩比，同时保持强指令跟随和语言理解能力。

Conclusion: 压缩技术顺序对最终模型质量至关重要，P-KD-Q序列在资源受限环境中部署LLM时提供了有效的顺序感知压缩流水线设计指导。

Abstract: Large Language Models (LLMs) require substantial computational resources, making model compression essential for efficient deployment in constrained environments. Among the dominant compression techniques: knowledge distillation, structured pruning, and low-bit quantization, their individual effects are well studied, but their interactions and optimal sequencing remain unclear. This work systematically examines how these techniques perform both independently and in combination when applied to the Qwen2.5 3B model. We evaluate multiple compression pipelines, including single, and proposed three-technique sequences, using perplexity, G-Eval, clarity, prompt alignment, and compression ratio as metrics. Our experiments show that quantization provides the greatest standalone compression, while pruning introduces moderate quality degradation. Critically, the ordering of techniques significantly affects the final model quality: the sequence Pruning, Knowledge Distillation, Quantization (P-KD-Q) yields the best balance, achieving a 3.68x compression ratio while preserving strong instruction-following and language understanding capabilities. Conversely, pipelines applying quantization early suffer severe performance degradation due to irreversible information loss that impairs subsequent training. Overall, this study offers practical insight into designing effective, ordering-aware compression pipelines for deploying LLMs in resource-limited settings.

</details>


### [91] [Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM](https://arxiv.org/abs/2511.19496)
*Yang Liu,Xiaolong Zhong,Ling Jiang*

Main category: cs.LG

TL;DR: Xmodel-2.5是一个13亿参数的小型语言模型，采用μP训练方法，在推理任务上表现出色，特别适合边缘计算和成本敏感部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然推理能力强，但计算需求大，不适合边缘或成本敏感部署，需要开发更高效的小型模型。

Method: 使用最大更新参数化(μP)训练，采用1.4T token的Warmup-Stable-Decay课程学习，并在衰减阶段从AdamW切换到Muon优化器，采用FP8混合精度训练。

Result: 在13个推理任务上平均性能提升4.58%，验证了早期AdamW稳定性和后期Muon锐化的组合策略有效。

Conclusion: Xmodel-2.5作为drop-in agent核心，在保持高性能的同时显著降低了计算需求，适合实际部署。

Abstract: Large language models deliver strong reasoning and tool-use skills, yet their computational demands make them impractical for edge or cost-sensitive deployments. We present \textbf{Xmodel-2.5}, a 1.3-billion-parameter small language model designed as a \emph{drop-in agent core}. Training with maximal-update parameterization ($μ$P) allows hyper-parameters tuned on a 20M-parameter proxy to transfer directly to the full model, even under the parameter-tied \emph{tie-word-embedding} architecture. A 1.4T-token Warmup--Stable--Decay curriculum is used, and we further show that \textbf{switching from AdamW to Muon during the decay phase} improves the 13-task reasoning average by 4.58\,\% while keeping every other hyper-parameter fixed, verifying that early AdamW stability can be paired with late Muon sharpening for better downstream performance. FP8-mixed-precision training balances accuracy and throughput. All checkpoints, recipes, and evaluation code are released under the Apache-2.0 license.\footnote{https://huggingface.co/XiaoduoAILab/Xmodel-2.5 and https://huggingface.co/XiaoduoAILab/Xmodel-2.5-history (training checkpoints).} Training code and evaluation harness: https://github.com/XiaoduoAILab/Xmodel-2.5.

</details>


### [92] [PeriodNet: Boosting the Potential of Attention Mechanism for Time Series Forecasting](https://arxiv.org/abs/2511.19497)
*Bowen Zhao,Huanlai Xing,Zhiwen Xiao,Jincheng Peng,Li Feng,Xinhan Wang,Rong Qu,Hui Li*

Main category: cs.LG

TL;DR: PeriodNet提出了一种新的时间序列预测结构，结合周期注意力机制和迭代分组机制，在单变量和多变量时间序列预测中都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 注意力机制在序列建模中表现出巨大潜力，但在时间序列预测中的应用尚未达到预期效果，探索更好的注意力网络结构对时间序列预测具有重要意义。

Method: 提出了PeriodNet，包含周期注意力和稀疏周期注意力机制分析相邻周期，引入迭代分组机制减少跨变量冗余，重新设计Transformer架构并提出了周期扩散器进行精确多周期预测。

Result: 在8个数据集上的实验表明，PeriodNet在单变量和多变量时间序列预测中都优于6个最先进模型，特别是在预测长度为720的时间序列时相比传统编码器-解码器Transformer架构模型有22%的相对改进。

Conclusion: PeriodNet通过创新的周期注意力机制和架构设计，显著提升了时间序列预测的性能，证明了在时间序列领域探索专门注意力结构的重要性。

Abstract: The attention mechanism has demonstrated remarkable potential in sequence modeling, exemplified by its successful application in natural language processing with models such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT). Despite these advancements, its utilization in time series forecasting (TSF) has yet to meet expectations. Exploring a better network structure for attention in TSF holds immense significance across various domains. In this paper, we present PeriodNet with a brand new structure to forecast univariate and multivariate time series. PeriodNet incorporates period attention and sparse period attention mechanism for analyzing adjacent periods. It enhances the mining of local characteristics, periodic patterns, and global dependencies. For efficient cross-variable modeling, we introduce an iterative grouping mechanism which can directly reduce the cross-variable redundancy. To fully leverage the extracted features on the encoder side, we redesign the entire architecture of the vanilla Transformer and propose a period diffuser for precise multi-period prediction. Through comprehensive experiments conducted on eight datasets, we demonstrate that PeriodNet outperforms six state-of-the-art models in both univariate and multivariate TSF scenarios in terms of mean square error and mean absolute error. In particular, PeriodNet achieves a relative improvement of 22% when forecasting time series with a length of 720, in comparison to other models based on the conventional encoder-decoder Transformer architecture.

</details>


### [93] [Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare Intelligence Using Imperfect and Privacy-Sensitive Medical Data](https://arxiv.org/abs/2511.19498)
*Yi Zhang,Tianxiang Xu,Zijian Li,Chao Zhang,Kunyu Zhang,Zhan Gao,Meinuo Li,Xiaohan Zhang,Qichao Qi,Bing Chen*

Main category: cs.LG

TL;DR: 提出分层双策略框架用于选择性知识遗忘，在医疗领域精确移除专业知识同时保留基础医学能力，仅需修改0.1%参数即可实现82.7%遗忘率和88.5%知识保留。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在医疗场景中的隐私风险，特别是训练数据记忆化问题，需要满足监管合规、可审计性和伦理标准。

Method: 分层双策略框架：几何约束梯度更新选择性调节目标参数，概念感知token级干预通过统一四级医学概念层次区分保留关键token和遗忘目标token。

Result: 在MedMCQA（外科）和MHQA（焦虑、抑郁、创伤）数据集上评估，达到82.7%遗忘率和88.5%知识保留率，仅需修改0.1%参数。

Conclusion: 该框架在保持强大隐私保证的同时，满足了临床研究中监管合规、可审计性和伦理标准的关键需求。

Abstract: Large language models (LLMs) exhibit exceptional performance but pose substantial privacy risks due to training data memorization, particularly within healthcare contexts involving imperfect or privacy-sensitive patient information. We present a hierarchical dual-strategy framework for selective knowledge unlearning that precisely removes specialized knowledge while preserving fundamental medical competencies. Our approach synergistically integrates geometric-constrained gradient updates to selectively modulate target parameters with concept-aware token-level interventions that distinguish between preservation-critical and unlearning-targeted tokens via a unified four-level medical concept hierarchy. Comprehensive evaluations on the MedMCQA (surgical) and MHQA (anxiety, depression, trauma) datasets demonstrate superior performance, achieving an 82.7% forgetting rate and 88.5% knowledge preservation. Notably, our framework maintains robust privacy guarantees while requiring modification of only 0.1% of parameters, addressing critical needs for regulatory compliance, auditability, and ethical standards in clinical research.

</details>


### [94] [Beyond Binary Classification: A Semi-supervised Approach to Generalized AI-generated Image Detection](https://arxiv.org/abs/2511.19499)
*Hong-Hanh Nguyen-Le,Van-Tuan Tran,Dinh-Thuc Nguyen,Nhien-An Le-Khac*

Main category: cs.LG

TL;DR: 提出TriDetect检测器，通过半监督方法发现假图像中的潜在架构模式，解决生成器跨架构检测泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前伪造检测器在跨生成器架构（如GAN到扩散模型）时泛化能力差，这源于不同架构产生的伪影差异。

Method: 提出TriDetect检测器，使用Sinkhorn-Knopp算法进行平衡聚类分配和跨视图一致性机制，学习基础架构差异。

Result: 在两个标准基准和三个真实数据集上评估，与13个基线方法相比，展示了在未见生成器上的泛化能力。

Conclusion: TriDetect通过发现假图像中的潜在架构模式，有效提升了跨生成器检测的泛化性能。

Abstract: The rapid advancement of generators (e.g., StyleGAN, Midjourney, DALL-E) has produced highly realistic synthetic images, posing significant challenges to digital media authenticity. These generators are typically based on a few core architectural families, primarily Generative Adversarial Networks (GANs) and Diffusion Models (DMs). A critical vulnerability in current forensics is the failure of detectors to achieve cross-generator generalization, especially when crossing architectural boundaries (e.g., from GANs to DMs). We hypothesize that this gap stems from fundamental differences in the artifacts produced by these \textbf{distinct architectures}. In this work, we provide a theoretical analysis explaining how the distinct optimization objectives of the GAN and DM architectures lead to different manifold coverage behaviors. We demonstrate that GANs permit partial coverage, often leading to boundary artifacts, while DMs enforce complete coverage, resulting in over-smoothing patterns. Motivated by this analysis, we propose the \textbf{Tri}archy \textbf{Detect}or (TriDetect), a semi-supervised approach that enhances binary classification by discovering latent architectural patterns within the "fake" class. TriDetect employs balanced cluster assignment via the Sinkhorn-Knopp algorithm and a cross-view consistency mechanism, encouraging the model to learn fundamental architectural distincts. We evaluate our approach on two standard benchmarks and three in-the-wild datasets against 13 baselines to demonstrate its generalization capability to unseen generators.

</details>


### [95] [Position: The Complexity of Perfect AI Alignment -- Formalizing the RLHF Trilemma](https://arxiv.org/abs/2511.19504)
*Subramanyam Sahoo,Aman Chadha,Vinija Jain,Divya Chaudhary*

Main category: cs.LG

TL;DR: 本文提出了对齐三难困境：RLHF系统无法同时实现代表性、可扩展性和鲁棒性。通过复杂性理论分析证明，实现全球规模的代表性和鲁棒性需要超多项式计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决RLHF实践中存在的安全性与公平性冲突、扩展到多样化人群的计算不可行性，以及鲁棒性导致多数偏见放大的问题。

Method: 通过整合统计学习理论和鲁棒优化的复杂性理论分析，证明实现代表性和鲁棒性的计算复杂度下界。

Result: 证明实现全球规模的代表性和鲁棒性需要Ω(2^{d_context})操作，当前RLHF实现通过牺牲代表性来缓解三难困境。

Conclusion: 提供了统一的框架解释RLHF病理现象，并提出通过战略性地放宽对齐要求来应对这些基本权衡。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is widely used for aligning large language models, yet practitioners face a persistent puzzle: improving safety often reduces fairness, scaling to diverse populations becomes computationally intractable, and making systems robust often amplifies majority biases. We formalize this tension as the Alignment Trilemma: no RLHF system can simultaneously achieve (i) epsilon-representativeness across diverse human values, (ii) polynomial tractability in sample and compute complexity, and (iii) delta-robustness against adversarial perturbations and distribution shift. Through a complexity-theoretic analysis integrating statistical learning theory and robust optimization, we prove that achieving both representativeness (epsilon <= 0.01) and robustness (delta <= 0.001) for global-scale populations requires Omega(2^{d_context}) operations, which is super-polynomial in the context dimensionality. We show that current RLHF implementations resolve this trilemma by sacrificing representativeness: they collect only 10^3--10^4 samples from homogeneous annotator pools while 10^7--10^8 samples are needed for true global representation. Our framework provides a unified explanation for documented RLHF pathologies including preference collapse, sycophancy, and systematic bias amplification. We conclude with concrete directions for navigating these fundamental trade-offs through strategic relaxations of alignment requirements.

</details>


### [96] [Profile Generators: A Link between the Narrative and the Binary Matrix Representation](https://arxiv.org/abs/2511.19506)
*Raoul H. Kutil,Georg Zimmermann,Barbara Strasser-Kirchweger,Christian Borgelt*

Main category: cs.LG

TL;DR: 开发了一种症状组合生成器来替代二元矩阵表示，用于处理DSM-5中复杂认知障碍的诊断路径，解决了大规模症状组合矩阵不可行的问题。


<details>
  <summary>Details</summary>
Motivation: DSM-5中认知障碍的症状组合数量庞大，使用完整的二元矩阵进行相似性计算不可行，需要一种更有效的表示方法。

Method: 开发症状组合生成器，使用列表、集合和数字的严格预定义格式来表示复杂的诊断路径，能够自动生成有效的症状组合。

Result: 生成器格式提供了可读、适应性强且全面的替代方案，能够处理复杂障碍的大量症状组合，并开发了基于生成器操作的MPCS值计算方法。

Conclusion: 症状组合生成器是处理复杂认知障碍诊断的有效工具，解决了大规模矩阵管理的难题，并支持特定MPCS值的计算。

Abstract: Mental health disorders, particularly cognitive disorders defined by deficits in cognitive abilities, are described in detail in the DSM-5, which includes definitions and examples of signs and symptoms. A simplified, machine-actionable representation was developed to assess the similarity and separability of these disorders, but it is not suited for the most complex cases. Generating or applying a full binary matrix for similarity calculations is infeasible due to the vast number of symptom combinations. This research develops an alternative representation that links the narrative form of the DSM-5 with the binary matrix representation and enables automated generation of valid symptom combinations. Using a strict pre-defined format of lists, sets, and numbers with slight variations, complex diagnostic pathways involving numerous symptom combinations can be represented. This format, called the symptom profile generator (or simply generator), provides a readable, adaptable, and comprehensive alternative to a binary matrix while enabling easy generation of symptom combinations (profiles). Cognitive disorders, which typically involve multiple diagnostic criteria with several symptoms, can thus be expressed as lists of generators. Representing several psychotic disorders in generator form and generating all symptom combinations showed that matrix representations of complex disorders become too large to manage. The MPCS (maximum pairwise cosine similarity) algorithm cannot handle matrices of this size, prompting the development of a profile reduction method using targeted generator manipulation to find specific MPCS values between disorders. The generators allow easier creation of binary representations for large matrices and make it possible to calculate specific MPCS cases between complex disorders through conditional generators.

</details>


### [97] [TouchFormer: A Robust Transformer-based Framework for Multimodal Material Perception](https://arxiv.org/abs/2511.19509)
*Kailin Lyu,Long Xiao,Jianing Zeng,Junhao Dong,Xuexin Liu,Zhuojun Zou,Haoyue Yang,Lin Shu,Jie Hao*

Main category: cs.LG

TL;DR: 提出了TouchFormer框架，通过模态自适应门控机制和跨实例嵌入正则化策略，解决了多模态材料感知中的噪声、缺失模态和动态模态重要性问题，在多个基准任务上显著提升了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法在视觉受损条件下性能大幅下降，现有多模态方法简单融合模态输入，忽视了模态特定噪声、缺失模态和模态动态重要性等关键挑战，导致性能不佳。

Method: 使用模态自适应门控(MAG)机制和内外模态注意力机制自适应整合跨模态特征，引入跨实例嵌入正则化(CER)策略提升细粒度子类别材料识别准确率。

Result: 在SSMC和USMC任务上分别实现了2.48%和6.83%的分类准确率提升，真实机器人实验验证了框架在环境感知和解释方面的有效性。

Conclusion: TouchFormer框架为安全关键应用如应急响应和工业自动化中的机器人部署铺平了道路，代码和数据集将开源。

Abstract: Traditional vision-based material perception methods often experience substantial performance degradation under visually impaired conditions, thereby motivating the shift toward non-visual multimodal material perception. Despite this, existing approaches frequently perform naive fusion of multimodal inputs, overlooking key challenges such as modality-specific noise, missing modalities common in real-world scenarios, and the dynamically varying importance of each modality depending on the task. These limitations lead to suboptimal performance across several benchmark tasks. In this paper, we propose a robust multimodal fusion framework, TouchFormer. Specifically, we employ a Modality-Adaptive Gating (MAG) mechanism and intra- and inter-modality attention mechanisms to adaptively integrate cross-modal features, enhancing model robustness. Additionally, we introduce a Cross-Instance Embedding Regularization(CER) strategy, which significantly improves classification accuracy in fine-grained subcategory material recognition tasks. Experimental results demonstrate that, compared to existing non-visual methods, the proposed TouchFormer framework achieves classification accuracy improvements of 2.48% and 6.83% on SSMC and USMC tasks, respectively. Furthermore, real-world robotic experiments validate TouchFormer's effectiveness in enabling robots to better perceive and interpret their environment, paving the way for its deployment in safety-critical applications such as emergency response and industrial automation. The code and datasets will be open-source, and the videos are available in the supplementary materials.

</details>


### [98] [Row-stochastic matrices can provably outperform doubly stochastic matrices in decentralized learning](https://arxiv.org/abs/2511.19513)
*Bing Liu,Boao Kong,Limin Lu,Kun Yuan,Chengcheng Zhao*

Main category: cs.LG

TL;DR: 本文比较了去中心化学习中两种处理节点权重λ的策略：嵌入本地损失和使用λ诱导的行随机矩阵。通过加权希尔伯特空间分析，发现行随机矩阵具有自伴性优势，能提供更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 澄清两种权重处理策略在收敛行为上的根本差异，现有欧几里得空间分析不够紧密，需要更精确的几何框架来理解其收敛特性。

Method: 开发加权希尔伯特空间框架L²(λ;ℝᵈ)，分析两种策略在该几何空间中的收敛行为，使用Rayleigh商和Loewner序特征值比较。

Result: 在加权希尔伯特空间中，行随机矩阵具有自伴性，而双随机矩阵会产生额外的惩罚项放大共识误差，从而减慢收敛。行随机设计即使在谱间隙较小的情况下也可能收敛更快。

Conclusion: 收敛差异不仅来自谱间隙，还来自几何结构产生的惩罚项。行随机策略在特定拓扑条件下具有收敛优势，为实际拓扑设计提供了指导原则。

Abstract: Decentralized learning often involves a weighted global loss with heterogeneous node weights $λ$. We revisit two natural strategies for incorporating these weights: (i) embedding them into the local losses to retain a uniform weight (and thus a doubly stochastic matrix), and (ii) keeping the original losses while employing a $λ$-induced row-stochastic matrix. Although prior work shows that both strategies yield the same expected descent direction for the global loss, it remains unclear whether the Euclidean-space guarantees are tight and what fundamentally differentiates their behaviors. To clarify this, we develop a weighted Hilbert-space framework $L^2(λ;\mathbb{R}^d)$ and obtain convergence rates that are strictly tighter than those from Euclidean analysis. In this geometry, the row-stochastic matrix becomes self-adjoint whereas the doubly stochastic one does not, creating additional penalty terms that amplify consensus error, thereby slowing convergence. Consequently, the difference in convergence arises not only from spectral gaps but also from these penalty terms. We then derive sufficient conditions under which the row-stochastic design converges faster even with a smaller spectral gap. Finally, by using a Rayleigh-quotient and Loewner-order eigenvalue comparison, we further obtain topology conditions that guarantee this advantage and yield practical topology-design guidelines.

</details>


### [99] [Automating Deception: Scalable Multi-Turn LLM Jailbreaks](https://arxiv.org/abs/2511.19517)
*Adarsh Kumarappan,Ananya Mujoo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.

</details>


### [100] [Shortcut Invariance: Targeted Jacobian Regularization in Disentangled Latent Space](https://arxiv.org/abs/2511.19525)
*Shivam Pal,Sakshi Varshney,Piyush Rai*

Main category: cs.LG

TL;DR: 提出一种简单有效的训练方法，通过功能不变性而非表示不变性来解决深度神经网络中的捷径学习问题，在解耦的潜在空间中识别捷径特征并注入各向异性噪声，实现最先进的OOD性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易学习训练数据中的捷径相关性，导致分布外泛化失败。现有方法通过复杂的分区表示学习鲁棒性，但这种方法复杂、脆弱且难以扩展。

Method: 在解耦的潜在空间中，通过捷径特征与标签的强相关性识别候选捷径特征，然后在训练过程中注入有针对性的各向异性潜在噪声，使分类器对这些特征不敏感。

Result: 在已建立的捷径学习基准测试中实现了最先进的分布外性能。

Conclusion: 通过功能不变性而非表示不变性的方法，提供了一种简单有效的解决方案来解决捷径学习问题，在保持性能的同时提高了方法的可扩展性。

Abstract: Deep neural networks are prone to learning shortcuts, spurious and easily learned correlations in training data that cause severe failures in out-of-distribution (OOD) generalization. A dominant line of work seeks robustness by learning a robust representation, often explicitly partitioning the latent space into core and spurious components; this approach can be complex, brittle, and difficult to scale. We take a different approach, instead of a robust representation, we learn a robust function. We present a simple and effective training method that renders the classifier functionally invariant to shortcut signals. Our method operates within a disentangled latent space, which is essential as it isolates spurious and core features into distinct dimensions. This separation enables the identification of candidate shortcut features by their strong correlation with the label, used as a proxy for semantic simplicity. The classifier is then desensitized to these features by injecting targeted, anisotropic latent noise during training. We analyze this as targeted Jacobian regularization, which forces the classifier to ignore spurious features and rely on more complex, core semantic signals. The result is state-of-the-art OOD performance on established shortcut learning benchmarks.

</details>


### [101] [Learning to Solve Weighted Maximum Satisfiability with a Co-Training Architecture](https://arxiv.org/abs/2511.19544)
*Kaidi Wan,Minghao Liu,Yong Lai*

Main category: cs.LG

TL;DR: SplitGNN是一种基于图神经网络的加权最大可满足性问题求解方法，通过协同训练架构和新的图表示方法，在大型加权MaxSAT基准测试中超越传统启发式求解器。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络方法在解决加权最大可满足性问题时存在收敛慢、预测精度不足的问题，特别是在处理大规模和复杂加权实例时表现不佳。

Method: 提出边分裂因子图的图表示方法，结合监督消息传递机制和无监督解增强层的协同训练架构，使用GPU加速层进行高效分数计算和基于松弛的优化。

Result: SplitGNN比其他GNN架构收敛速度快3倍，预测效果更好，在更大更难的加权MaxSAT基准测试中超越现代启发式求解器，并在多样化结构实例上展现出优异的泛化能力。

Conclusion: SplitGNN通过创新的图表示和协同训练架构，显著提升了加权MaxSAT问题的求解性能，证明了图神经网络在组合优化问题中的潜力。

Abstract: Wepropose SplitGNN, a graph neural network (GNN)-based
  approach that learns to solve weighted maximum satisfiabil ity (MaxSAT) problem. SplitGNN incorporates a co-training
  architecture consisting of supervised message passing mech anism and unsupervised solution boosting layer. A new graph
  representation called edge-splitting factor graph is proposed
  to provide more structural information for learning, which is
  based on spanning tree generation and edge classification. To
  improve the solutions on challenging and weighted instances,
  we implement a GPU-accelerated layer applying efficient
  score calculation and relaxation-based optimization. Exper iments show that SplitGNN achieves 3* faster convergence
  and better predictions compared with other GNN-based ar chitectures. More notably, SplitGNN successfully finds solu tions that outperform modern heuristic MaxSAT solvers on
  much larger and harder weighted MaxSAT benchmarks, and
  demonstrates exceptional generalization abilities on diverse
  structural instances.

</details>


### [102] [When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics](https://arxiv.org/abs/2511.19548)
*Yiven,Zhu*

Main category: cs.LG

TL;DR: 本文提出了一个神经经济福利推理框架，分析神经数据在政策福利判断中的合法使用条件，强调需要经过神经-计算映射验证、决策模型识别真实利益、明确福利标准三个关键步骤。


<details>
  <summary>Details</summary>
Motivation: 随着神经数据在政策制定和商业干预中的广泛应用，需要明确神经数据何时能合法地用于福利判断而不仅仅是描述行为，避免神经数据的误用和过度解读。

Method: 开发了一个非经验性的模型框架，将神经信号、计算决策模型和规范福利标准三个层次联系起来，在演员-评论家强化学习模型中形式化从神经活动到潜在价值和预测误差，再到福利主张的推理路径。

Result: 提出了神经经济福利推理检查清单，应用于成瘾、神经营销和环境政策案例，证明神经证据只有在特定条件下才能约束福利判断。

Conclusion: 大脑和人工智能体都应被视为价值学习系统，但内部奖励信号（无论是生物的还是人工的）都是计算量，不能在没有明确规范模型的情况下作为福利衡量标准。

Abstract: Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, "brain-based" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies "true" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.

</details>


### [103] [Online Sparse Feature Selection in Data Streams via Differential Evolution](https://arxiv.org/abs/2511.19555)
*Ruiyang Xu*

Main category: cs.LG

TL;DR: 提出了一种新的在线差分进化稀疏特征选择方法(ODESFS)，用于处理数据流中的缺失值问题，通过潜在因子分析和差分进化来改进特征选择性能。


<details>
  <summary>Details</summary>
Motivation: 现有的在线稀疏流特征选择(OS2FS)方法在特征评估方面存在显著局限性，导致性能下降，需要改进特征选择的有效性。

Method: 使用潜在因子分析模型进行缺失值填补，并通过差分进化算法评估特征重要性。

Result: 在六个真实世界数据集上的实验表明，ODESFS始终优于最先进的OSFS和OS2FS方法，能够选择最优特征子集并获得更高的准确性。

Conclusion: ODESFS方法通过结合潜在因子分析和差分进化，有效解决了数据流中缺失值处理和特征选择的问题，显著提升了性能。

Abstract: The processing of high-dimensional streaming data commonly utilizes online streaming feature selection (OSFS) techniques. However, practical implementations often face challenges with data incompleteness due to equipment failures and technical constraints. Online Sparse Streaming Feature Selection (OS2FS) tackles this issue through latent factor analysis-based missing data imputation. Despite this advancement, existing OS2FS approaches exhibit substantial limitations in feature evaluation, resulting in performance deterioration. To address these shortcomings, this paper introduces a novel Online Differential Evolution for Sparse Feature Selection (ODESFS) in data streams, incorporating two key innovations: (1) missing value imputation using a latent factor analysis model, and (2) feature importance evaluation through differential evolution. Comprehensive experiments conducted on six real-world datasets demonstrate that ODESFS consistently outperforms state-of-the-art OSFS and OS2FS methods by selecting optimal feature subsets and achieving superior accuracy.

</details>


### [104] [Merging without Forgetting: Continual Fusion of Task-Specific Models via Optimal Transport](https://arxiv.org/abs/2511.19561)
*Zecheng Pan,Zhikang Chen,Ding Li,Min Zhang,Sen Cui,Hongshuo Jin,Luqi Tao,Yi Yang,Deheng Ye,Yu Zhang,Tingting Zhu,Tianling Ren*

Main category: cs.LG

TL;DR: OTMF是一种基于最优传输理论的新型模型融合框架，通过发现应用于任务向量的共同掩码来解决参数插值引起的分布偏移问题，实现多任务模型的统一融合。


<details>
  <summary>Details</summary>
Motivation: 现有的模型融合方法主要依赖权重空间的参数插值，这会导致特征空间中的显著分布偏移并削弱任务特定知识。

Method: OTMF通过最优传输计划发现应用于任务向量的共同掩码，选择性地提取可转移和任务无关的组件，同时保留每个任务的独特结构身份。支持持续融合范式，逐步集成新任务向量而无需重新访问之前的任务。

Result: 在多个视觉和语言基准测试上的综合实验表明，OTMF在准确性和效率方面都达到了最先进的性能。

Conclusion: OTMF方法在模型融合方面具有实际和理论价值，能够有效解决分布偏移问题，实现高效的多任务模型统一。

Abstract: Merging models fine-tuned for different tasks into a single unified model has become an increasingly important direction for building versatile, efficient multi-task systems. Existing approaches predominantly rely on parameter interpolation in weight space, which we show introduces significant distribution shift in the feature space and undermines task-specific knowledge. In this paper, we propose OTMF (Optimal Transport-based Masked Fusion), a novel model merging framework rooted in optimal transport theory to address the distribution shift that arises from naive parameter interpolation. Instead of directly aggregating features or weights, OTMF aligns the semantic geometry of task-specific models by discovering common masks applied to task vectors through optimal transport plans. These masks selectively extract transferable and task-agnostic components while preserving the unique structural identities of each task. To ensure scalability in real-world settings, OTMF further supports a continual fusion paradigm that incrementally integrates each new task vector without revisiting previous ones, maintaining a bounded memory footprint and enabling efficient fusion across a growing number of tasks. We conduct comprehensive experiments on multiple vision and language benchmarks, and results show that OTMF achieves state-of-the-art performance in terms of both accuracy and efficiency. These findings highlight the practical and theoretical value of our approach to model merging.

</details>


### [105] [ModHiFi: Identifying High Fidelity predictive components for Model Modification](https://arxiv.org/abs/2511.19566)
*Dhruva Kashyap,Chaitanya Murti,Pranav K Nayak,Tanay Narshana,Chiranjib Bhattacharyya*

Main category: cs.LG

TL;DR: 提出了ModHiFi算法，无需训练数据或损失函数即可进行模型修改，包括剪枝和遗忘任务，在ImageNet和语言模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: 开放权重模型通常不提供训练数据或损失函数，这使得模型修改任务（如剪枝和遗忘）受到限制。现有方法需要梯度或真实标签，在计算资源有限的情况下不可行。

Method: 基于局部重建误差与全局重建误差的线性关系，提出了Subset Fidelity指标来量化组件重要性。开发了ModHiFi算法，包括ModHiFi-P用于结构化剪枝和ModHiFi-U用于类别遗忘。

Result: ModHiFi-P在ImageNet模型上比现有技术快11%，在语言模型上表现具有竞争力。ModHiFi-U在CIFAR-10上无需微调即可实现完全遗忘，在Swin Transformers上表现良好。

Conclusion: 证明了无需训练数据或损失函数即可有效识别模型关键组件，为资源受限环境下的模型修改提供了实用解决方案。

Abstract: Open weight models, which are ubiquitous, rarely provide access to their training data or loss function. This makes modifying such models for tasks such as pruning or unlearning constrained by this unavailability an active area of research. Existing techniques typically require gradients or ground-truth labels, rendering them infeasible in settings with limited computational resources. In this work, we investigate the fundamental question of identifying components that are critical to the model's predictive performance, without access to either gradients or the loss function, and with only distributional access such as synthetic data. We theoretically demonstrate that the global reconstruction error is linearly bounded by local reconstruction errors for Lipschitz-continuous networks such as CNNs and well-trained Transformers (which, contrary to existing literature, we find exhibit Lipschitz continuity). This motivates using the locally reconstructive behavior of component subsets to quantify their global importance, via a metric that we term Subset Fidelity. In the uncorrelated features setting, selecting individual components via their Subset Fidelity scores is optimal, which we use to propose ModHiFi, an algorithm for model modification that requires no training data or loss function access. ModHiFi-P, for structured pruning, achieves an 11% speedup over the current state of the art on ImageNet models and competitive performance on language models. ModHiFi-U, for classwise unlearning, achieves complete unlearning on CIFAR-10 without fine-tuning and demonstrates competitive performance on Swin Transformers.

</details>


### [106] [An Invariant Latent Space Perspective on Language Model Inversion](https://arxiv.org/abs/2511.19569)
*Wentao Ye,Jiaqi Hu,Haobo Wang,Xinpeng Ti,Zhiqing Xiao,Hao Chen,Liyao Li,Lei Feng,Sai Wu,Junbo Zhao*

Main category: cs.LG

TL;DR: 提出Inv^2A方法，利用语言模型的潜在空间不变性假设进行语言模型反演攻击，在保护用户隐私和系统安全方面构成威胁。


<details>
  <summary>Details</summary>
Motivation: 语言模型反演（LMI）作为用户隐私和系统安全的具体威胁，需要研究更有效的攻击方法。作者提出不变潜在空间假设，认为同一源提示的多样化输出应保持一致的语义，且输入-输出循环映射应在共享潜在空间中自洽。

Method: 提出Inv^2A方法，将LLM视为不变解码器，仅学习轻量级逆编码器将输出映射到去噪伪表示。当有多个输出时，在表示层稀疏拼接以增加信息密度。训练分两个阶段：对比对齐（源不变性）和监督强化（循环不变性）。可选的无训练邻域搜索可优化局部性能。

Result: 在9个涵盖用户和系统提示场景的数据集上，Inv^2A平均比基线方法提升4.77% BLEU分数，同时减少了对大型逆语料库的依赖。分析显示现有防御措施保护有限。

Conclusion: Inv^2A方法在语言模型反演攻击中表现出色，突显了需要更强防御策略的必要性。该方法利用了LLM潜在空间的不变性特性，实现了更高效和准确的提示恢复。

Abstract: Language model inversion (LMI), i.e., recovering hidden prompts from outputs, emerges as a concrete threat to user privacy and system security. We recast LMI as reusing the LLM's own latent space and propose the Invariant Latent Space Hypothesis (ILSH): (1) diverse outputs from the same source prompt should preserve consistent semantics (source invariance), and (2) input<->output cyclic mappings should be self-consistent within a shared latent space (cyclic invariance). Accordingly, we present Inv^2A, which treats the LLM as an invariant decoder and learns only a lightweight inverse encoder that maps outputs to a denoised pseudo-representation. When multiple outputs are available, they are sparsely concatenated at the representation layer to increase information density. Training proceeds in two stages: contrastive alignment (source invariance) and supervised reinforcement (cyclic invariance). An optional training-free neighborhood search can refine local performance. Across 9 datasets covering user and system prompt scenarios, Inv^2A outperforms baselines by an average of 4.77% BLEU score while reducing dependence on large inverse corpora. Our analysis further shows that prevalent defenses provide limited protection, underscoring the need for stronger strategies. The source code and data involved in this paper can be found in https://github.com/yyy01/Invariant_Attacker.

</details>


### [107] [Neural Tractability via Structure: Learning-Augmented Algorithms for Graph Combinatorial Optimization](https://arxiv.org/abs/2511.19573)
*Jialiang Li,Weitong Chen,Mingyu Guo*

Main category: cs.LG

TL;DR: 提出结合神经模型和参数化算法的框架，在保持推理效率的同时获得解质量保证，通过神经模型处理结构困难部分，参数化算法搜索简单部分。


<details>
  <summary>Details</summary>
Motivation: 神经模型在组合优化问题上推理快但解质量不如传统搜索算法，传统算法慢但有最优性保证，需要结合两者优势。

Method: 使用参数化分析识别实例结构困难部分，神经模型生成指导信号，参数化算法基于指导信号高效搜索简单部分。

Result: 在多个组合优化任务上实现优于纯神经求解器的解质量，与商业求解器相当，并改善了分布外泛化能力。

Conclusion: 该框架成功结合神经模型和参数化算法优势，在解质量和泛化能力方面均有显著提升，且不依赖特定神经模型选择。

Abstract: Neural models have shown promise in solving NP-hard graph combinatorial optimization (CO) problems. Once trained, they offer fast inference and reasonably high-quality solutions for in-distribution testing instances, but they generally fall short in terms of absolute solution quality compared to classical search-based algorithms that are admittedly slower but offer optimality guarantee once search finishes.
  We propose a novel framework that combines the inference efficiency and exploratory power of neural models with the solution quality guarantee of search-based algorithms. In particular, we use parameterized algorithms (PAs) as the search component. PAs are dedicated to identifying easy instances of generally NP-hard problems, and allow for practically efficient search by exploiting structural simplicity (of the identified easy instances). Under our framework, we use parameterized analysis to identify the structurally hard parts of a CO instance. The neural model handles the hard parts by generating advisory signals based on its data-driven understanding. The PA-based search component then integrates the advisory signals to systematically and efficiently searches through the remaining structurally easy parts. Notably, our framework is agnostic to the choice of neural model and produces strictly better solutions than neural solvers alone.
  We examine our framework on multiple CO tasks. Empirical results show that it achieves superior solution quality, competitive with that of commercial solvers. Furthermore, by using the neural model only for exploratory advisory signals, our framework exhibits improved out-of-distribution generalization, addressing a key limitation of existing neural CO solvers.

</details>


### [108] [Learning Massively Multitask World Models for Continuous Control](https://arxiv.org/abs/2511.19584)
*Nicklas Hansen,Hao Su,Xiaolong Wang*

Main category: cs.LG

TL;DR: 提出了一个包含200个多样化任务的基准测试，并开发了Newt多任务世界模型，通过演示预训练和在线交互联合优化，在多任务性能、数据效率和适应新任务方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习研究主要关注单任务或离线学习，缺乏能够跨多个任务和实体进行在线交互的通用智能体。受基础模型方法的启发，探索是否可以通过在线交互训练单一智能体处理数百个任务。

Method: 首先在演示数据上进行预训练以获取任务感知表示和动作先验，然后通过跨所有任务的在线交互进行联合优化。

Result: Newt在多任务性能和数据效率方面优于强基线方法，表现出强大的开环控制能力，并能快速适应未见过的任务。

Conclusion: 该方法证明了在线强化学习可以扩展到多任务设置，为通用控制智能体的发展提供了新方向。

Abstract: General-purpose control demands agents that act across many tasks and embodiments, yet research on reinforcement learning (RL) for continuous control remains dominated by single-task or offline regimes, reinforcing a view that online RL does not scale. Inspired by the foundation model recipe (large-scale pretraining followed by light RL) we ask whether a single agent can be trained on hundreds of tasks with online interaction. To accelerate research in this direction, we introduce a new benchmark with 200 diverse tasks spanning many domains and embodiments, each with language instructions, demonstrations, and optionally image observations. We then present \emph{Newt}, a language-conditioned multitask world model that is first pretrained on demonstrations to acquire task-aware representations and action priors, and then jointly optimized with online interaction across all tasks. Experiments show that Newt yields better multitask performance and data-efficiency than a set of strong baselines, exhibits strong open-loop control, and enables rapid adaptation to unseen tasks. We release our environments, demonstrations, code for training and evaluation, as well as 200+ checkpoints.

</details>


### [109] [Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks](https://arxiv.org/abs/2511.19636)
*Shihan Feng,Cheng Zhang,Michael Xi,Ethan Hsu,Lesia Semenova,Chudi Zhong*

Main category: cs.LG

TL;DR: 提出Rashomon概念瓶颈模型框架，通过轻量级适配器模块和多样性正则化训练目标，学习多个准确但推理过程不同的神经网络，揭示深度学习模型中的推理多样性。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络存在Rashomon效应——多个模型可以达到相同性能但依赖不同特征或推理模式。然而在深度架构中发现这种多样性很困难，因为连续参数空间包含无数数值不同但行为相似的近最优解。

Method: 结合轻量级适配器模块和多样性正则化训练目标，无需从头训练即可高效构建多个基于概念的不同深度模型。

Result: 生成的网络为相同预测提供根本不同的推理过程，揭示了在同等性能解决方案中概念依赖和决策制定的变化。

Conclusion: 该框架能够系统探索深度模型中的数据驱动推理多样性，为审计、比较和对齐同等准确解决方案提供了新机制。

Abstract: Modern neural networks rarely have a single way to be right. For many tasks, multiple models can achieve identical performance while relying on different features or reasoning patterns, a property known as the Rashomon Effect. However, uncovering this diversity in deep architectures is challenging as their continuous parameter spaces contain countless near-optimal solutions that are numerically distinct but often behaviorally similar. We introduce Rashomon Concept Bottleneck Models, a framework that learns multiple neural networks which are all accurate yet reason through distinct human-understandable concepts. By combining lightweight adapter modules with a diversity-regularized training objective, our method constructs a diverse set of deep concept-based models efficiently without retraining from scratch. The resulting networks provide fundamentally different reasoning processes for the same predictions, revealing how concept reliance and decision making vary across equally performing solutions. Our framework enables systematic exploration of data-driven reasoning diversity in deep models, offering a new mechanism for auditing, comparison, and alignment across equally accurate solutions.

</details>


### [110] [Lower Complexity Bounds for Nonconvex-Strongly-Convex Bilevel Optimization with First-Order Oracles](https://arxiv.org/abs/2511.19656)
*Kaiyi Ji*

Main category: cs.LG

TL;DR: 本文针对双层优化问题，在光滑非凸-强凸设置下，建立了确定性一阶oracle模型下Ω(κ^{3/2}ε^{-2})和随机oracle模型下Ω(κ^{5/2}ε^{-4})的下界复杂度，揭示了当前上下界之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 由于双层结构的复杂性，双层优化的下界研究进展有限，而现有的上界保证已广泛研究。本文旨在填补这一空白，为理解双层优化在标准一阶oracle下的最优复杂度提供理论基础。

Method: 开发新的困难实例，在光滑非凸-强凸设置下，分别针对确定性和随机一阶oracle模型构造下界证明。

Result: 在确定性情况下，任何一阶零尊重算法至少需要Ω(κ^{3/2}ε^{-2})次oracle调用才能找到ε-精确驻点；在随机情况下，至少需要Ω(κ^{5/2}ε^{-4})次随机oracle调用。

Conclusion: 研究结果揭示了当前双层优化上下界之间的显著差距，表明即使是简化的设置（如二次下层目标）也需要进一步研究以理解双层优化在标准一阶oracle下的最优复杂度。

Abstract: Although upper bound guarantees for bilevel optimization have been widely studied, progress on lower bounds has been limited due to the complexity of the bilevel structure. In this work, we focus on the smooth nonconvex-strongly-convex setting and develop new hard instances that yield nontrivial lower bounds under deterministic and stochastic first-order oracle models. In the deterministic case, we prove that any first-order zero-respecting algorithm requires at least $Ω(κ^{3/2}ε^{-2})$ oracle calls to find an $ε$-accurate stationary point, improving the optimal lower bounds known for single-level nonconvex optimization and for nonconvex-strongly-convex min-max problems. In the stochastic case, we show that at least $Ω(κ^{5/2}ε^{-4})$ stochastic oracle calls are necessary, again strengthening the best known bounds in related settings. Our results expose substantial gaps between current upper and lower bounds for bilevel optimization and suggest that even simplified regimes, such as those with quadratic lower-level objectives, warrant further investigation toward understanding the optimal complexity of bilevel optimization under standard first-order oracles.

</details>


### [111] [Structured Noise Modeling for Enhanced Time-Series Forecasting](https://arxiv.org/abs/2511.19657)
*Sepideh Koohfar*

Main category: cs.LG

TL;DR: 提出了一个预测-模糊-去噪框架，通过结构化噪声建模提高时间序列预测的保真度，在多个数据集上实现了多时间尺度预测精度和稳定性的提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的时间序列预测面临多尺度时间模式的挑战，现有神经网络模型难以有效表示这些交互动态，导致预测不稳定和下游应用可靠性降低。

Method: 采用可学习的高斯过程模块生成平滑相关的扰动，鼓励预测主干捕获长程结构，同时使用专门的细化模型恢复高分辨率时间细节，通过联合训练实现自然的能力分工。

Result: 在电力、交通和太阳能数据集上的实验显示，该方法在多时间尺度预测精度和稳定性方面均取得一致提升，模块化设计还支持作为轻量级增强层用于预训练模型。

Conclusion: 该框架通过增强细粒度时间预测的可靠性和可解释性，为能源、基础设施等时间关键领域的AI决策支持系统提供了更可信的解决方案。

Abstract: Time-series forecasting remains difficult in real-world settings because temporal patterns operate at multiple scales, from broad contextual trends to fast, fine-grained fluctuations that drive critical decisions. Existing neural models often struggle to represent these interacting dynamics, leading to unstable predictions and reduced reliability in downstream applications. This work introduces a forecast-blur-denoise framework that improves temporal fidelity through structured noise modeling. The approach incorporates a learnable Gaussian Process module that generates smooth, correlated perturbations, encouraging the forecasting backbone to capture long-range structure while a dedicated refinement model restores high-resolution temporal detail. Training the components jointly enables natural competence division and avoids the artifacts commonly produced by isotropic corruption methods. Experiments across electricity, traffic, and solar datasets show consistent gains in multi-horizon accuracy and stability. The modular design also allows the blur-denoise layer to operate as a lightweight enhancement for pretrained models, supporting efficient adaptation in limited-data scenarios. By strengthening the reliability and interpretability of fine-scale temporal predictions, this framework contributes to more trustworthy AI systems used in forecasting-driven decision support across energy, infrastructure, and other time-critical domains.

</details>


### [112] [Demystifying Diffusion Objectives: Reweighted Losses are Better Variational Bounds](https://arxiv.org/abs/2511.19664)
*Jiaxin Shi,Michalis K. Titsias*

Main category: cs.LG

TL;DR: 本文提出了扩散模型重加权损失的新理论解释，通过构建时间相关的变分下界来改进标准证据下界，从而降低数据-模型KL散度。


<details>
  <summary>Details</summary>
Motivation: 为广泛使用的扩散模型重加权损失提供理论依据，改进标准训练目标以提升模型性能。

Method: 构建时间相关的变分下界级联，推导出适用于连续高斯扩散和掩码扩散的重加权目标函数。

Result: 在掩码扩散中应用该框架，在像素空间图像建模上显著优于先前训练损失，样本质量接近连续扩散模型。

Conclusion: 提出的理论框架为掩码图像模型中广泛使用的简单加权方案提供了理论依据，并展示了其有效性。

Abstract: We derive a new theoretical interpretation of the reweighted losses that are widely used for training diffusion models. Our method is based on constructing a cascade of time-dependent variational lower bounds on the data log-likelihood, that provably improves upon the standard evidence lower bound and results in reduced data-model KL-divergences. Combining such bounds gives rise to reweighted objectives that can be applied to any generative diffusion model including both continuous Gaussian diffusion and masked (discrete) diffusion models. Then, we showcase this framework in masked diffusion and report significant improvements over previous training losses in pixel-space image modeling, approaching sample quality comparable to continuous diffusion models. Our results also provide a theoretical justification for the simple weighting scheme widely used in masked image models.

</details>


### [113] [TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction Understanding](https://arxiv.org/abs/2511.19693)
*Chin-Chia Michael Yeh,Uday Singh Saini,Xin Dai,Xiran Fan,Shubham Jain,Yujie Fan,Jiarui Sun,Junpeng Wang,Menghai Pan,Yingtong Dou,Yuzhong Chen,Vineeth Rakesh,Liang Wang,Yan Zheng,Mahashweta Das*

Main category: cs.LG

TL;DR: TREASURE是一个基于Transformer的交易数据基础模型，能同时捕捉消费者行为和支付网络信号，在异常行为检测和推荐系统方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 支付网络产生大量交易记录，正确建模这些数据可以实现异常行为检测和个性化体验等应用，从而改善人们的生活。

Method: 提出TREASURE模型，包含：1）具有静态和动态属性专用子模块的输入模块；2）高效训练范式用于预测高基数分类属性；3）可作为独立模型或嵌入提供者使用。

Result: 在行业级数据集上验证，TREASURE作为独立模型将异常行为检测性能提升111%，作为嵌入提供者将推荐模型性能提升104%。

Conclusion: TREASURE是一个多用途的交易数据基础模型，通过综合捕捉消费者行为和支付网络信号，在异常检测和推荐系统等应用中表现出色。

Abstract: Payment networks form the backbone of modern commerce, generating high volumes of transaction records from daily activities. Properly modeling this data can enable applications such as abnormal behavior detection and consumer-level insights for hyper-personalized experiences, ultimately improving people's lives. In this paper, we present TREASURE, TRansformer Engine As Scalable Universal transaction Representation Encoder, a multipurpose transformer-based foundation model specifically designed for transaction data. The model simultaneously captures both consumer behavior and payment network signals (such as response codes and system flags), providing comprehensive information necessary for applications like accurate recommendation systems and abnormal behavior detection. Verified with industry-grade datasets, TREASURE features three key capabilities: 1) an input module with dedicated sub-modules for static and dynamic attributes, enabling more efficient training and inference; 2) an efficient and effective training paradigm for predicting high-cardinality categorical attributes; and 3) demonstrated effectiveness as both a standalone model that increases abnormal behavior detection performance by 111% over production systems and an embedding provider that enhances recommendation models by 104%. We present key insights from extensive ablation studies, benchmarks against production models, and case studies, highlighting valuable knowledge gained from developing TREASURE.

</details>


### [114] [TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification](https://arxiv.org/abs/2511.19694)
*Chin-Chia Michael Yeh,Uday Singh Saini,Junpeng Wang,Xin Dai,Xiran Fan,Jiarui Sun,Yujie Fan,Yan Zheng*

Main category: cs.LG

TL;DR: TiCT是一个基于Transformer的时间序列基础模型，专门用于上下文分类，仅使用合成数据进行预训练，无需微调即可在推理时通过少量示例实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据普遍存在，但标注数据成本高昂。现有的时间序列基础模型主要关注预测任务，缺乏无需微调即可进行通用分类的模型。

Method: 提出TiCT模型，采用可扩展的基于比特的标签编码和特殊输出注意力机制来处理任意数量的类别，并通过Mixup启发的过程和数据增强的合成预训练框架来促进泛化和噪声不变性。

Result: 在UCR Archive上的广泛评估显示，TiCT仅使用上下文示例在推理时就能达到与最先进监督方法相竞争的性能，且无需更新任何模型权重。

Conclusion: TiCT证明了仅使用合成数据预训练的模型能够实现有效的上下文学习，为时间序列分类提供了一种无需昂贵标注数据的新方法。

Abstract: The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.

</details>


### [115] [CafeQ: Calibration-free Quantization via Learned Transformations and Adaptive Rounding](https://arxiv.org/abs/2511.19705)
*Ziteng Sun,Adrian Benton,Samuel Kushnir,Asher Trockman,Vikas Singh,Suhas Diggavi,Ananda Theertha Suresh*

Main category: cs.LG

TL;DR: 提出无需校准数据的后训练量化方法，通过优化变换和自适应舍入来减少大语言模型量化误差，在Gemma 2模型上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准后训练量化方法因权重中的异常值而产生大误差，现有缓解机制依赖校准数据，但在实际场景中校准数据可能不可用或受隐私限制。

Method: 设计无校准数据的量化损失代理函数，使用结构化矩阵变换处理单个矩阵，对计算图中直接交互的配对权重使用双矩阵变换和自适应舍入方法。

Result: 在Gemma 2 9B模型上，4位量化平均基准分数从61.9提升到62.4，3位量化从52.0提升到60.6，计算开销增加不到3%。

Conclusion: 该方法在无需校准数据的情况下实现了与需要校准数据的GPTQ方法相当的性能，为实际部署提供了更灵活的量化解决方案。

Abstract: Post-training quantization is an effective method for reducing the serving cost of large language models, where the standard approach is to use a round-to-nearest quantization level scheme. However, this often introduces large errors due to outliers in the weights. Proposed mitigation mechanisms include applying adaptive rounding, random rotation transformations or committing to a post-training target using calibration data. Unfortunately, this reliance on calibration data can be severely limiting in some real-world scenarios as such data may be unavailable or subject to privacy regulations. In this paper, we propose algorithms to optimize transformations and adaptive rounding without access to any calibration data. The optimization is achieved by designing a suitable proxy function for the quantization loss without calibration data. To maintain inference efficiency, we perform structured matrix transformations for single matrices. For paired weights that interact directly in the computation graph, we use dual matrix transformations and adaptive rounding methods. We conduct experiments on Gemma 2 models, and observe consistent improvement over the baselines. For Gemma 2 9B quantization, our method improves the average benchmark score from 61.9 to 62.4 for 4-bit quantization and from 52.0 to 60.6 for 3-bit quantization, while adding less than 3% of computation overhead. Furthermore, our method achieves performance comparable to the commonly used GPTQ method, which requires calibration data.

</details>


### [116] [Training-Free Active Learning Framework in Materials Science with Large Language Models](https://arxiv.org/abs/2511.19730)
*Hongchen Wang,Rafael Espinosa Castañeda,Jay R. Werber,Yao Fehlis,Edward Kim,Jason Hattrick-Simpers*

Main category: cs.LG

TL;DR: LLM-AL框架使用大型语言模型进行主动学习，在材料科学数据集上比传统ML模型减少70%以上的实验次数，实现更高效的实验选择。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在主动学习中存在冷启动问题和领域特定特征工程的限制，限制了其泛化能力。LLMs提供了新的范式，利用预训练知识和通用标记表示直接从文本描述中提出实验。

Method: 引入基于LLM的主动学习框架(LLM-AL)，在迭代少样本设置下运行。探索两种提示策略：简洁数值输入和扩展描述性文本，分别适用于不同特征的数据集。

Result: 在所有数据集上，LLM-AL将找到顶级候选所需的实验次数减少超过70%，始终优于传统ML模型。LLM-AL执行更广泛和探索性搜索，同时以更少迭代达到最优。

Conclusion: LLM-AL可以作为传统主动学习管道的通用替代方案，实现更高效和可解释的实验选择，并具有LLM驱动的自主发现潜力。

Abstract: Active learning (AL) accelerates scientific discovery by prioritizing the most informative experiments, but traditional machine learning (ML) models used in AL suffer from cold-start limitations and domain-specific feature engineering, restricting their generalizability. Large language models (LLMs) offer a new paradigm by leveraging their pretrained knowledge and universal token-based representations to propose experiments directly from text-based descriptions. Here, we introduce an LLM-based active learning framework (LLM-AL) that operates in an iterative few-shot setting and benchmark it against conventional ML models across four diverse materials science datasets. We explored two prompting strategies: one using concise numerical inputs suited for datasets with more compositional and structured features, and another using expanded descriptive text suited for datasets with more experimental and procedural features to provide additional context. Across all datasets, LLM-AL could reduce the number of experiments needed to reach top-performing candidates by over 70% and consistently outperformed traditional ML models. We found that LLM-AL performs broader and more exploratory searches while still reaching the optima with fewer iterations. We further examined the stability boundaries of LLM-AL given the inherent non-determinism of LLMs and found its performance to be broadly consistent across runs, within the variability range typically observed for traditional ML approaches. These results demonstrate that LLM-AL can serve as a generalizable alternative to conventional AL pipelines for more efficient and interpretable experiment selection and potential LLM-driven autonomous discovery.

</details>


### [117] [DISCO: A Browser-Based Privacy-Preserving Framework for Distributed Collaborative Learning](https://arxiv.org/abs/2511.19750)
*Julien T. T. Vignoud,Valérian Rousset,Hugo El Guedj,Ignacio Aleman,Walid Bennaceur,Batuhan Faik Derinbay,Eduard Ďurech,Damien Gengler,Lucas Giordano,Felix Grimberg,Franziska Lippoldt,Christina Kopidaki,Jiafan Liu,Lauris Lopata,Nathan Maire,Paul Mansat,Martin Milenkoski,Emmanuel Omont,Güneş Özgün,Mina Petrović,Francesco Posa,Morgan Ridel,Giorgio Savini,Marcel Torne,Lucas Trognon,Alyssa Unell,Olena Zavertiaieva,Sai Praneeth Karimireddy,Tahseen Rabbani,Mary-Anne Hartley,Martin Jaggi*

Main category: cs.LG

TL;DR: DISCO是一个开源的分布式协作学习平台，允许非技术用户在不共享原始数据的情况下协作构建机器学习模型。该平台在浏览器中本地训练模型，支持联邦学习和去中心化范式，并提供多种隐私保护和权重聚合策略。


<details>
  <summary>Details</summary>
Motivation: 数据共享存在隐私、知识产权和法律限制等问题，这不仅分散了预测模型的统计能力，还造成了可访问性偏见，使得只有具备资源克服这些问题的用户才能获得准确的模型。

Method: DISCO平台在浏览器中本地训练模型，支持联邦学习和去中心化两种范式，提供不同级别的隐私保证和多种权重聚合策略，允许模型个性化和偏见弹性。

Result: 开发了一个开源分布式协作学习平台，代码库位于https://github.com/epfml/disco，展示界面位于https://discolab.ai，支持跨平台使用包括智能手机。

Conclusion: DISCO为非技术用户提供了一个无需编程知识、不共享原始数据的协作机器学习解决方案，解决了数据共享的实践障碍，促进了更公平的模型准确性分布。

Abstract: Data is often impractical to share for a range of well considered reasons, such as concerns over privacy, intellectual property, and legal constraints. This not only fragments the statistical power of predictive models, but creates an accessibility bias, where accuracy becomes inequitably distributed to those who have the resources to overcome these concerns. We present DISCO: an open-source DIStributed COllaborative learning platform accessible to non-technical users, offering a means to collaboratively build machine learning models without sharing any original data or requiring any programming knowledge. DISCO's web application trains models locally directly in the browser, making our tool cross-platform out-of-the-box, including smartphones. The modular design of \disco offers choices between federated and decentralized paradigms, various levels of privacy guarantees and several approaches to weight aggregation strategies that allow for model personalization and bias resilience in the collaborative training. Code repository is available at https://github.com/epfml/disco and a showcase web interface at https://discolab.ai

</details>


### [118] [When +1% Is Not Enough: A Paired Bootstrap Protocol for Evaluating Small Improvements](https://arxiv.org/abs/2511.19794)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 提出一种保守的评估协议，用于判断机器学习中1-2%的性能提升是否真实，避免因随机性导致的虚假结论。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习论文中报告的1-2%性能提升往往缺乏不确定性估计和显著性检验，无法区分真实算法改进与随机噪声。

Method: 基于配对多种子运行、偏差校正加速(BCa)自助法置信区间和符号翻转置换检验的评估协议。

Result: 在CIFAR-10、CIFAR-10N和AG News数据集上测试显示，单次运行和未配对t检验容易错误宣称显著提升，而提出的协议在只有3个种子的情况下不会错误宣称显著性。

Conclusion: 在有限计算预算下，这种保守的评估方法应作为判断小幅度性能提升的安全默认方案。

Abstract: Recent machine learning papers often report 1-2 percentage point improvements from a single run on a benchmark. These gains are highly sensitive to random seeds, data ordering, and implementation details, yet are rarely accompanied by uncertainty estimates or significance tests. It is therefore unclear when a reported +1-2% reflects a real algorithmic advance versus noise.
  We revisit this problem under realistic compute budgets, where only a few runs are affordable. We propose a simple, PC-friendly evaluation protocol based on paired multi-seed runs, bias-corrected and accelerated (BCa) bootstrap confidence intervals, and a sign-flip permutation test on per-seed deltas. The protocol is intentionally conservative and is meant as a guardrail against over-claiming.
  We instantiate it on CIFAR-10, CIFAR-10N, and AG News using synthetic no-improvement, small-gain, and medium-gain scenarios. Single runs and unpaired t-tests often suggest significant gains for 0.6-2.0 point improvements, especially on text. With only three seeds, our paired protocol never declares significance in these settings. We argue that such conservative evaluation is a safer default for small gains under tight budgets.

</details>


### [119] [Terminal Velocity Matching](https://arxiv.org/abs/2511.19797)
*Linqi Zhou,Mathias Parger,Ayaan Haque,Jiaming Song*

Main category: cs.LG

TL;DR: TVM是一种流匹配的泛化方法，支持高保真的一步和少步生成建模，通过终端速度匹配和最小架构修改实现稳定训练，在ImageNet上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统流匹配方法在终端时间行为不稳定，且扩散变换器缺乏Lipschitz连续性，需要改进以实现高效的一步/少步生成。

Method: 提出终端速度匹配(TVM)，建模任意两个扩散时间步之间的转换，在终端时间进行正则化；引入最小架构修改实现稳定训练；开发融合注意力核支持Jacobian-向量积的反向传播。

Result: 在ImageNet-256x256上：1步生成FID=3.29，4步生成FID=1.99；在ImageNet-512x512上：1步生成FID=4.32，4步生成FID=2.94，达到少步生成的SOTA性能。

Conclusion: TVM通过终端正则化和架构优化，成功实现了高效的一步和少步生成建模，在图像生成任务上取得了最先进的性能。

Abstract: We propose Terminal Velocity Matching (TVM), a generalization of flow matching that enables high-fidelity one- and few-step generative modeling. TVM models the transition between any two diffusion timesteps and regularizes its behavior at its terminal time rather than at the initial time. We prove that TVM provides an upper bound on the $2$-Wasserstein distance between data and model distributions when the model is Lipschitz continuous. However, since Diffusion Transformers lack this property, we introduce minimal architectural changes that achieve stable, single-stage training. To make TVM efficient in practice, we develop a fused attention kernel that supports backward passes on Jacobian-Vector Products, which scale well with transformer architectures. On ImageNet-256x256, TVM achieves 3.29 FID with a single function evaluation (NFE) and 1.99 FID with 4 NFEs. It similarly achieves 4.32 1-NFE FID and 2.94 4-NFE FID on ImageNet-512x512, representing state-of-the-art performance for one/few-step models from scratch.

</details>


### [120] [Scalable Data Attribution via Forward-Only Test-Time Inference](https://arxiv.org/abs/2511.19803)
*Sibo Ma,Julian Nyarko*

Main category: cs.LG

TL;DR: 提出了一种高效的数据归因方法，通过训练期间的短时梯度传播模拟训练样本的参数影响，在推理时仅需前向评估即可获得归因结果，大幅降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统影响函数方法需要昂贵的反向传播或Hessian矩阵求逆，在现代网络中不实用。需要一种既能保持影响函数理论基础，又能在实际部署中高效运行的数据归因方法。

Method: 在训练期间通过短时梯度传播模拟每个训练样本的参数影响，推理时仅使用前向评估读取归因结果，将计算从推理阶段转移到模拟阶段。

Result: 在标准MLP基准测试中，该方法在标准归因指标（LOO和LDS）上匹配或超越了TRAK等最先进基线方法，同时推理成本降低了数个数量级。

Conclusion: 该方法结合了影响函数的理论保真度和一阶方法的可扩展性，为大型预训练模型提供了实用、实时的数据归因理论框架。

Abstract: Data attribution seeks to trace model behavior back to the training examples that shaped it, enabling debugging, auditing, and data valuation at scale. Classical influence-function methods offer a principled foundation but remain impractical for modern networks because they require expensive backpropagation or Hessian inversion at inference. We propose a data attribution method that preserves the same first-order counterfactual target while eliminating per-query backward passes. Our approach simulates each training example's parameter influence through short-horizon gradient propagation during training and later reads out attributions for any query using only forward evaluations. This design shifts computation from inference to simulation, reflecting real deployment regimes where a model may serve billions of user queries but originate from a fixed, finite set of data sources (for example, a large language model trained on diverse corpora while compensating a specific publisher such as the New York Times). Empirically, on standard MLP benchmarks, our estimator matches or surpasses state-of-the-art baselines such as TRAK on standard attribution metrics (LOO and LDS) while offering orders-of-magnitude lower inference cost. By combining influence-function fidelity with first-order scalability, our method provides a theoretical framework for practical, real-time data attribution in large pretrained models.

</details>


### [121] [Learning to Clean: Reinforcement Learning for Noisy Label Correction](https://arxiv.org/abs/2511.19808)
*Marzi Heidari,Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: 提出RLNLC框架，将噪声标签校正问题建模为强化学习任务，通过策略网络迭代修正标签并训练预测模型，在多个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 噪声标签会严重降低机器学习模型的预测性能，需要有效的方法来处理标签噪声问题。

Method: 将噪声标签校正定义为强化学习问题，构建包含数据标签状态空间、标签校正动作空间和奖励机制的系统，使用actor-critic方法训练深度特征表示策略网络。

Result: 在多个基准数据集上的实验表明，RLNLC框架持续优于现有的噪声标签学习技术。

Conclusion: RLNLC框架成功地将强化学习应用于噪声标签校正问题，提供了一种有效的解决方案。

Abstract: The challenge of learning with noisy labels is significant in machine learning, as it can severely degrade the performance of prediction models if not addressed properly. This paper introduces a novel framework that conceptualizes noisy label correction as a reinforcement learning (RL) problem. The proposed approach, Reinforcement Learning for Noisy Label Correction (RLNLC), defines a comprehensive state space representing data and their associated labels, an action space that indicates possible label corrections, and a reward mechanism that evaluates the efficacy of label corrections. RLNLC learns a deep feature representation based policy network to perform label correction through reinforcement learning, utilizing an actor-critic method. The learned policy is subsequently deployed to iteratively correct noisy training labels and facilitate the training of the prediction model. The effectiveness of RLNLC is demonstrated through extensive experiments on multiple benchmark datasets, where it consistently outperforms existing state-of-the-art techniques for learning with noisy labels.

</details>


### [122] [Provably Outlier-resistant Semi-parametric Regression for Transferable Calibration of Low-cost Air-quality Sensors](https://arxiv.org/abs/2511.19810)
*Divyansh Chaurasia,Manoj Daram,Roshan Kumar,Nihal Thukarama Rao,Vipul Sangode,Pranjal Srivastava,Avnish Tripathi,Shoubhik Chakraborty,Akanksha,Ambasht Kumar,Davender Sethi,Sachchida Nand Tripathi,Purushottam Kar*

Main category: cs.LG

TL;DR: 提出RESPIRE技术用于校准低成本空气质量CO传感器，在跨站点、跨季节、跨传感器设置中提供改进的预测性能，具有抗异常值和可解释性优势。


<details>
  <summary>Details</summary>
Motivation: 低成本空气质量传感器在大规模部署中校准过程昂贵、耗时且复杂，特别是在地理分布广泛的网络中。

Method: RESPIRE技术提供抗异常值的训练算法和可解释模型，能够检测模型过拟合情况。

Result: 基于四个站点、两个季节和六个传感器包的广泛部署数据，RESPIRE在跨站点、跨季节和跨传感器设置中表现优于基线方法。

Conclusion: RESPIRE为大规模低成本空气质量传感器网络提供了一种有效的校准解决方案，代码已开源。

Abstract: We present a case study for the calibration of Low-cost air-quality (LCAQ) CO sensors from one of the largest multi-site-multi-season-multi-sensor-multi-pollutant mobile air-quality monitoring network deployments in India. LCAQ sensors have been shown to play a critical role in the establishment of dense, expansive air-quality monitoring networks and combating elevated pollution levels. The calibration of LCAQ sensors against regulatory-grade monitors is an expensive, laborious and time-consuming process, especially when a large number of sensors are to be deployed in a geographically diverse layout. In this work, we present the RESPIRE technique to calibrate LCAQ sensors to detect ambient CO (Carbon Monoxide) levels. RESPIRE offers specific advantages over baseline calibration methods popular in literature, such as improved prediction in cross-site, cross-season, and cross-sensor settings. RESPIRE offers a training algorithm that is provably resistant to outliers and an explainable model with the ability to flag instances of model overfitting. Empirical results are presented based on data collected during an extensive deployment spanning four sites, two seasons and six sensor packages. RESPIRE code is available at https://github.com/purushottamkar/respire.

</details>


### [123] [Mosaic Pruning: A Hierarchical Framework for Generalizable Pruning of Mixture-of-Experts Models](https://arxiv.org/abs/2511.19822)
*Wentao Hu,Mingkuan Zhao,Shuangyong Song,Xiaoyan Zhu,Xin Lai,Jiayin Wang*

Main category: cs.LG

TL;DR: 提出了Mosaic Pruning (MoP)方法，通过"聚类-选择"过程构建功能全面的专家集合，解决SMoE模型跨域部署时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有后训练剪枝方法基于单一语料库，导致剪枝模型在其他领域应用时性能严重下降，需要为每个新领域重新剪枝，成本高昂。

Method: 使用跨任务域专家性能相似性度量进行功能聚类，然后基于激活变异性评分从每个聚类中选择最具代表性的专家，形成功能互补的专家集合。

Result: 在各种MoE模型上的实验表明，MoP显著优于先前工作，在通用任务上提升7.24%，在数学推理和代码生成等专业任务上提升8.92%。

Conclusion: Mosaic Pruning能够保留原始模型能力的完整功能图谱，使剪枝模型能够处理多样化的下游任务。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures have enabled a new frontier in scaling Large Language Models (LLMs), offering superior performance by activating only a fraction of their total parameters during inference. However, their practical deployment is severely hampered by substantial static memory overhead, as all experts must be loaded into memory. Existing post-training pruning methods, while reducing model size, often derive their pruning criteria from a single, general-purpose corpus. This leads to a critical limitation: a catastrophic performance degradation when the pruned model is applied to other domains, necessitating a costly re-pruning for each new domain. To address this generalization gap, we introduce Mosaic Pruning (MoP). The core idea of MoP is to construct a functionally comprehensive set of experts through a structured ``cluster-then-select" process. This process leverages a similarity metric that captures expert performance across different task domains to functionally cluster the experts, and subsequently selects the most representative expert from each cluster based on our proposed Activation Variability Score. Unlike methods that optimize for a single corpus, our proposed Mosaic Pruning ensures that the pruned model retains a functionally complementary set of experts, much like the tiles of a mosaic that together form a complete picture of the original model's capabilities, enabling it to handle diverse downstream tasks.Extensive experiments on various MoE models demonstrate the superiority of our approach. MoP significantly outperforms prior work, achieving a 7.24\% gain on general tasks and 8.92\% on specialized tasks like math reasoning and code generation.

</details>


### [124] [GED-Consistent Disentanglement of Aligned and Unaligned Substructures for Graph Similarity Learning](https://arxiv.org/abs/2511.19837)
*Zhentao Zhan,Xiaoliang Xu,Jingjing Wang,Junmei Wang*

Main category: cs.LG

TL;DR: GCGSim是一个基于图编辑距离(GED)的图相似度计算框架，通过图级匹配和子结构级编辑成本解决现有节点中心化方法的局限性，在多个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的GED方法采用节点中心化匹配范式，这与GED的核心原则存在不匹配，导致无法捕捉全局结构对应关系和对编辑成本的错误归因。

Method: 提出GCGSim框架，核心包括图级匹配和子结构级编辑成本计算，通过三个核心技术贡献实现GED一致性的图相似度学习。

Result: 在四个基准数据集上的广泛实验表明，GCGSim实现了最先进的性能，并能有效学习解耦且语义有意义的子结构表示。

Conclusion: GCGSim通过图级匹配和子结构级编辑成本的方法，成功解决了现有节点中心化GED方法的局限性，为图相似度计算提供了更准确和语义有意义的解决方案。

Abstract: Graph Similarity Computation (GSC) is a fundamental graph related task where Graph Edit Distance (GED) serves as a prevalent metric. GED is determined by an optimal alignment between a pair of graphs that partitions each into aligned (zero-cost) and unaligned (cost-incurring) substructures. Due to NP-hard nature of exact GED computation, GED approximations based on Graph Neural Network(GNN) have emerged. Existing GNN-based GED approaches typically learn node embeddings for each graph and then aggregate pairwise node similarities to estimate the final similarity. Despite their effectiveness, we identify a mismatch between this prevalent node-centric matching paradigm and the core principles of GED. This discrepancy leads to two critical limitations: (1) a failure to capture the global structural correspondence for optimal alignment, and (2) a misattribution of edit costs driven by spurious node level signals. To address these limitations, we propose GCGSim, a GED-consistent graph similarity learning framework centering on graph-level matching and substructure-level edit costs. Specifically, we make three core technical contributions. Extensive experiments on four benchmark datasets show that GCGSim achieves state-of-the-art performance. Our comprehensive analyses further validate that the framework effectively learns disentangled and semantically meaningful substructure representations.

</details>


### [125] [Cisco Time Series Model Technical Report](https://arxiv.org/abs/2511.19841)
*Liang Gou,Archit Khare,Praneet Pabolu,Prachi Patel,Joseph Ross,Hercy Shen,Yuhan,Song,Jingze Sun,Kristal Curtis,Vedant Dharnidharka,Abhinav Mathur,Hao Yang*

Main category: cs.LG

TL;DR: Cisco Time Series Model是一个单变量零样本预测器，通过多分辨率输入架构创新，在300B+数据点上训练，在可观测性数据集上表现优异，同时保持通用预测基准的相似性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理多分辨率输入的时间序列基础模型，特别针对可观测性领域，同时保持通用预测能力。

Method: 对TimesFM模型进行架构创新，使其能够接受多分辨率输入，构建多分辨率解码器模型，在300B+数据点（其中一半来自可观测性领域）上进行训练。

Result: 模型在可观测性数据集上实现卓越性能，在通用预测基准（GIFT-Eval）上保持相似性能，多分辨率结构使模型在长上下文输入上预测更准确。

Conclusion: 多分辨率架构创新使时间序列基础模型在特定领域（如可观测性）表现优异，同时不牺牲通用预测能力，长上下文预测精度得到提升。

Abstract: We introduce the Cisco Time Series Model, a univariate zero-shot forecaster. This time series foundation model is the result of a general architectural innovation to a time series model enabling it to accept multiresolution input, applied to a popular decoder-only time series model (TimesFM). The resulting multiresolution decoder-only model is trained on over 300B unique data points, with more than half coming from the observability domain. Quantitative and qualitative evaluations demonstrate that the resulting model achieves superior performance on observability datasets while retaining very similar performance on a standard general-purpose forecasting benchmark (GIFT-Eval), and suggest that the multiresolution structure enables the model to make more accurate predictions on long context input.

</details>


### [126] [SX-GeoTree: Self-eXplaining Geospatial Regression Tree Incorporating the Spatial Similarity of Feature Attributions](https://arxiv.org/abs/2511.19845)
*Chaogui Kang,Lijian Luo,Qingfeng Guan,Yu Liu*

Main category: cs.LG

TL;DR: SX-GeoTree是一种自解释地理空间回归树，通过结合空间残差控制和解释鲁棒性来改进传统决策树的空间依赖性和解释稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统决策树在表格预测中存在两个主要问题：(i)难以捕捉空间依赖性，(ii)无法产生局部稳定的解释。需要开发能够同时处理空间结构和解释鲁棒性的方法。

Method: 提出SX-GeoTree，在递归分裂过程中集成三个耦合目标：不纯度减少(MSE)、空间残差控制(全局Moran's I)、通过模块化最大化实现解释鲁棒性。将局部Lipschitz连续性重新构造为网络社区保持问题。

Result: 在两个任务上的实验显示，SX-GeoTree在保持竞争性预测精度的同时，改善了残差空间均匀性，并将归因共识提高了一倍(模块化度：福建0.19 vs 0.09；西雅图0.10 vs 0.05)。

Conclusion: 该框架展示了如何将空间相似性嵌入可解释模型，推进可信赖的地理空间机器学习，并为领域感知的可解释性提供了可转移的模板。

Abstract: Decision trees remain central for tabular prediction but struggle with (i) capturing spatial dependence and (ii) producing locally stable (robust) explanations. We present SX-GeoTree, a self-explaining geospatial regression tree that integrates three coupled objectives during recursive splitting: impurity reduction (MSE), spatial residual control (global Moran's I), and explanation robustness via modularity maximization on a consensus similarity network formed from (a) geographically weighted regression (GWR) coefficient distances (stimulus-response similarity) and (b) SHAP attribution distances (explanatory similarity). We recast local Lipschitz continuity of feature attributions as a network community preservation problem, enabling scalable enforcement of spatially coherent explanations without per-sample neighborhood searches. Experiments on two exemplar tasks (county-level GDP in Fujian, n=83; point-wise housing prices in Seattle, n=21,613) show SX-GeoTree maintains competitive predictive accuracy (within 0.01 $R^{2}$ of decision trees) while improving residual spatial evenness and doubling attribution consensus (modularity: Fujian 0.19 vs 0.09; Seattle 0.10 vs 0.05). Ablation confirms Moran's I and modularity terms are complementary; removing either degrades both spatial residual structure and explanation stability. The framework demonstrates how spatial similarity - extended beyond geometric proximity through GWR-derived local relationships - can be embedded in interpretable models, advancing trustworthy geospatial machine learning and offering a transferable template for domain-aware explainability.

</details>


### [127] [Accelerating Wireless Distributed Learning via Hybrid Split and Federated Learning Optimization](https://arxiv.org/abs/2511.19851)
*Kun Guo,Xuefei Li,Xijun Wang,Howard H. Yang,Wei Feng,Tony Q. S. Quek*

Main category: cs.LG

TL;DR: 本文提出了一种加速混合分割与联邦学习（HSFL）的方法，通过联合优化学习模式选择、批次大小以及通信计算资源来减少整体学习延迟。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）支持低延迟并行训练但可能收敛到较低精度模型，而分割学习（SL）能获得更高精度但延迟较大。为了结合两者的优势，HSFL允许部分设备在FL模式下运行，其他在SL模式下运行。

Method: 首先分析收敛性，揭示学习模式与批次大小的相互作用；然后制定延迟最小化问题，提出两阶段解决方案：使用块坐标下降法求解松弛问题获得局部最优解，再通过舍入算法恢复整数批次大小。

Result: 实验结果表明，与现有方法相比，该方法能显著加速达到目标精度的收敛过程。

Conclusion: 通过联合优化学习模式选择、批次大小和资源分配，HSFL能够有效平衡精度与延迟，实现更快的收敛性能。

Abstract: Federated learning (FL) and split learning (SL) are two effective distributed learning paradigms in wireless networks, enabling collaborative model training across mobile devices without sharing raw data. While FL supports low-latency parallel training, it may converge to less accurate model. In contrast, SL achieves higher accuracy through sequential training but suffers from increased delay. To leverage the advantages of both, hybrid split and federated learning (HSFL) allows some devices to operate in FL mode and others in SL mode. This paper aims to accelerate HSFL by addressing three key questions: 1) How does learning mode selection affect overall learning performance? 2) How does it interact with batch size? 3) How can these hyperparameters be jointly optimized alongside communication and computational resources to reduce overall learning delay? We first analyze convergence, revealing the interplay between learning mode and batch size. Next, we formulate a delay minimization problem and propose a two-stage solution: a block coordinate descent method for a relaxed problem to obtain a locally optimal solution, followed by a rounding algorithm to recover integer batch sizes with near-optimal performance. Experimental results demonstrate that our approach significantly accelerates convergence to the target accuracy compared to existing methods.

</details>


### [128] [Frailty-Aware Transformer for Recurrent Survival Modeling of Driver Retention in Ride-Hailing Platforms](https://arxiv.org/abs/2511.19893)
*Shuoyan Xu,Yu Zhang,Eric J. Miller*

Main category: cs.LG

TL;DR: 提出基于Transformer的生存分析框架FACT，用于建模网约车司机的空闲行为，在时间依赖性C指数和Brier得分上优于传统和深度学习生存模型。


<details>
  <summary>Details</summary>
Motivation: 网约车平台具有高频、行为驱动的特点，虽然生存分析已在其他领域应用于重复事件，但在建模网约车司机行为方面仍未被充分探索。

Method: 将空闲行为建模为重复生存过程，使用基于Transformer的框架，通过因果掩码捕获长期时间依赖性，并整合司机特定嵌入来建模潜在异质性。

Result: 在多伦多网约车数据上的结果显示，提出的FACT模型在时间依赖性C指数和Brier得分方面表现最佳，超越了经典和深度学习生存模型。

Conclusion: 该方法能够实现更准确的风险估计，支持平台留存策略，并提供政策相关的见解。

Abstract: Ride-hailing platforms are characterized by high-frequency, behavior-driven environments. Although survival analysis has been applied to recurrent events in other domains, its use in modeling ride-hailing driver behavior remains largely unexplored. This study formulates idle behavior as a recurrent survival process using large-scale platform data and proposes a Transformer-based framework that captures long-term temporal dependencies with causal masking and incorporates driver-specific embeddings to model latent heterogeneity. Results on Toronto ride-hailing data demonstrate that the proposed Frailty-Aware Cox Transformer (FACT) achieves the highest time-dependent C-indices and lowest Brier Scores, outperforming classical and deep learning survival models. This approach enables more accurate risk estimation, supports platform retention strategies, and provides policy-relevant insights.

</details>


### [129] [EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning](https://arxiv.org/abs/2511.19935)
*Songlin Zhao,Michael Pitts,Zhuwei Qin*

Main category: cs.LG

TL;DR: EfficientXpert是一个轻量级领域剪枝框架，通过传播感知剪枝准则和高效适配器更新算法，在LoRA微调过程中将通用预训练模型一步转化为稀疏的领域专家模型，在40%稀疏度下保持98%的密集模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域的需求增长，但其大尺寸在资源受限环境中部署困难，现有压缩方法要么跨领域泛化能力差，要么开销过高。

Method: 结合传播感知剪枝准则（Foresight Mask）和高效适配器更新算法（Partial Brain Surgeon），集成到LoRA微调过程中，实现一步式模型转换。

Result: 在医疗和法律任务中，在40%稀疏度下保持高达98%的密集模型性能，优于现有最先进方法。分析显示领域依赖的结构变化会降低通用剪枝掩码的有效性。

Conclusion: 需要针对每个领域采用自适应的、领域感知的剪枝策略。

Abstract: The rapid advancement of large language models (LLMs) has increased the demand for domain-specialized variants in areas such as law, healthcare, and finance. However, their large size remains a barrier to deployment in resource-constrained environments, and existing compression methods either generalize poorly across domains or incur high overhead. In this work, we propose \textbf{EfficientXpert}, a lightweight domain-pruning framework that combines a propagation-aware pruning criterion (Foresight Mask) with an efficient adapter-update algorithm (Partial Brain Surgeon). Integrated into the LoRA fine-tuning process, EfficientXpert enables a one-step transformation of general pretrained models into sparse, domain-adapted experts. Across health and legal tasks, it retains up to 98% of dense-model performance at 40% sparsity, outperforming state-of-the-art methods. Further analysis reveals substantial domain-dependent structural shifts that degrade the effectiveness of general pruning masks, underscoring the need for adaptive, domain-aware pruning strategies tailored to each domain.

</details>


### [130] [Adaptivity and Universality: Problem-dependent Universal Regret for Online Convex Optimization](https://arxiv.org/abs/2511.19937)
*Peng Zhao,Yu-Hu Yan,Hang Yu,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 提出了UniGrad系列算法，实现了同时具备通用性和自适应性的在线学习，能够适应梯度变化并获得最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有通用在线学习方法缺乏问题相关的自适应性，无法获得与梯度变化相关的遗憾界，而梯度变化在随机优化和博弈快速收敛中至关重要。

Method: 提出了UniGrad.Correct和UniGrad.Bregman两种实现，使用元算法结合多个基础学习器；还提出了计算效率更高的UniGrad++，通过代理优化减少梯度查询次数。

Result: UniGrad.Correct对强凸函数获得O(log V_T)遗憾，对指数凹函数获得O(d log V_T)遗憾，对凸函数获得O(√(V_T log V_T))遗憾；UniGrad.Bregman对凸函数获得最优的O(√V_T)遗憾。

Conclusion: UniGrad系列算法首次实现了同时具备通用性和自适应性的在线学习，能够适应梯度变化并获得最优遗憾界，在理论和计算效率方面都有显著改进。

Abstract: Universal online learning aims to achieve optimal regret guarantees without requiring prior knowledge of the curvature of online functions. Existing methods have established minimax-optimal regret bounds for universal online learning, where a single algorithm can simultaneously attain $\mathcal{O}(\sqrt{T})$ regret for convex functions, $\mathcal{O}(d \log T)$ for exp-concave functions, and $\mathcal{O}(\log T)$ for strongly convex functions, where $T$ is the number of rounds and $d$ is the dimension of the feasible domain. However, these methods still lack problem-dependent adaptivity. In particular, no universal method provides regret bounds that scale with the gradient variation $V_T$, a key quantity that plays a crucial role in applications such as stochastic optimization and fast-rate convergence in games. In this work, we introduce UniGrad, a novel approach that achieves both universality and adaptivity, with two distinct realizations: UniGrad.Correct and UniGrad.Bregman. Both methods achieve universal regret guarantees that adapt to gradient variation, simultaneously attaining $\mathcal{O}(\log V_T)$ regret for strongly convex functions and $\mathcal{O}(d \log V_T)$ regret for exp-concave functions. For convex functions, the regret bounds differ: UniGrad.Correct achieves an $\mathcal{O}(\sqrt{V_T \log V_T})$ bound while preserving the RVU property that is crucial for fast convergence in online games, whereas UniGrad.Bregman achieves the optimal $\mathcal{O}(\sqrt{V_T})$ regret bound through a novel design. Both methods employ a meta algorithm with $\mathcal{O}(\log T)$ base learners, which naturally requires $\mathcal{O}(\log T)$ gradient queries per round. To enhance computational efficiency, we introduce UniGrad++, which retains the regret while reducing the gradient query to just $1$ per round via surrogate optimization. We further provide various implications.

</details>


### [131] [Optimize Flip Angle Schedules In MR Fingerprinting Using Reinforcement Learning](https://arxiv.org/abs/2511.19941)
*Shenjun Zhong,Zhifeng Chen,Zhaolin Chen*

Main category: cs.LG

TL;DR: 使用强化学习优化磁共振指纹成像中的翻转角调度，提高指纹可区分性并可能减少重复时间


<details>
  <summary>Details</summary>
Motivation: 磁共振指纹成像依赖于可调采集参数产生的瞬态信号动态，但优化翻转角等关键参数是一个复杂的高维序列决策问题。强化学习为自动化参数选择提供了有前景的方法。

Method: 引入强化学习框架来优化磁共振指纹成像中的翻转角调度，通过RL算法学习非周期性模式的翻转角序列。

Result: RL优化的调度显示出非周期性模式，增强了指纹的可区分性，并可能减少重复时间数量，从而加速磁共振指纹成像采集。

Conclusion: 强化学习框架能够有效优化磁共振指纹成像的翻转角调度，提高指纹分离性能并可能实现采集加速。

Abstract: Magnetic Resonance Fingerprinting (MRF) leverages transient-state signal dynamics generated by the tunable acquisition parameters, making the design of an optimal, robust sequence a complex, high-dimensional sequential decision problem, such as optimizing one of the key parameters, flip angle. Reinforcement learning (RL) offers a promising approach to automate parameter selection, to optimize pulse sequences that maximize the distinguishability of fingerprints across the parameter space. In this work, we introduce an RL framework for optimizing the flip-angle schedule in MRF and demonstrate a learned schedule exhibiting non-periodic patterns that enhances fingerprint separability. Additionally, an interesting observation is that the RL-optimized schedule may enable a reduction in the number of repetition time, potentially accelerate MRF acquisitions.

</details>


### [132] [Differential Smoothing Mitigates Sharpening and Improves LLM Reasoning](https://arxiv.org/abs/2511.19942)
*Jingchu Gai,Guanning Zeng,Huaqing Zhang,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 本文针对强化学习微调大语言模型时出现的多样性崩溃问题，提出了理论分析和解决方案。通过证明RL微调存在选择和强化偏差导致多样性崩溃，作者提出了差分平滑方法，在保证正确性的同时提升多样性，在多个任务和模型规模上都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: RL微调大语言模型会导致多样性崩溃，现有启发式方法存在随意性、效果不稳定且有时相互矛盾的问题，需要建立理论基础和更优解决方案。

Method: 首先理论证明RL微调导致多样性崩溃的机制，然后提出差分平滑方法，该方法只在正确轨迹上应用奖励修改，理论上保证同时提升正确性和多样性。

Result: 在1B到7B参数的模型上，在CountDown和真实世界数学推理等领域的实验表明，差分平滑方法在Pass@1和Pass@k指标上均有提升，在AIME24数据集上最高提升6.7%。

Conclusion: 差分平滑方法在理论和实验上都优于传统RL方法和基于熵的启发式方法，能够有效解决多样性崩溃问题，同时提升正确性和多样性。

Abstract: It is widely recognized that reinforcement learning (RL) fine-tuning of large language models often leads to \textit{diversity collapse}, where outputs lack variety. Prior work has proposed a range of heuristics to counteract this effect, but these methods are ad hoc: they frequently trade off correctness for diversity, their effectiveness varies across tasks, and in some cases they even contradict one another. In this work, we place these observations on a rigorous foundation. We first provide a formal proof of why RL fine-tuning exhibits diversity collapse via a selection and reinforcement bias. Next, we make a key observation that any reward modification to address diversity collapse only needs to be applied on the correct trajectories. Building directly on this analysis, we introduce a principled method -- \textit{differential smoothing} -- that provably improves both correctness and diversity, outperforming vanilla RL as well as widely used entropy-based heuristics. Our theory precisely characterizes when existing heuristics help and why they fail, while showing that differential smoothing is universally superior. Extensive experiments with models from 1B to 7B parameters, across domains including CountDown and real-world mathematical reasoning, demonstrate consistent gains. Differential smoothing improves both Pass@1 and Pass@k, with up to 6.7\% improvements on AIME24 dataset.

</details>


### [133] [Hierarchical Spatio-Temporal Attention Network with Adaptive Risk-Aware Decision for Forward Collision Warning in Complex Scenarios](https://arxiv.org/abs/2511.19952)
*Haoran Hu,Junren Shi,Shuo Jiang,Kun Cheng,Xia Yang,Changhao Piao*

Main category: cs.LG

TL;DR: 提出集成前向碰撞预警框架，结合分层时空注意力网络和动态风险阈值调整算法，解决计算复杂性和建模不足问题，实现高效可靠的碰撞预警。


<details>
  <summary>Details</summary>
Motivation: 现有前向碰撞预警系统难以平衡多智能体交互建模精度与实时决策适应性，存在边缘部署计算成本高、简化交互模型不可靠以及传统静态阈值预警误报率高的问题。

Method: 采用分层时空注意力网络（HSTAN）进行解耦架构设计：图注意力网络处理空间交互，级联GRU与自注意力机制处理时序依赖；结合保形分位数回归生成预测区间，通过动态风险阈值调整算法将预测转换为及时预警。

Result: 在NGSIM数据集上，推理时间仅需12.3ms（比Transformer方法快73%），平均位移误差降至0.73m（比Social_LSTM提升42.2%）；预测区间覆盖率达到91.3%（90%置信度）；系统F1分数0.912，误报率8.2%，预警提前时间2.8秒。

Conclusion: 该框架在多场景数据集测试中表现出高效性和实用性，验证了在复杂环境中优越的性能和实际部署可行性，为车辆安全和自动驾驶提供了可靠的碰撞预警解决方案。

Abstract: Forward Collision Warning systems are crucial for vehicle safety and autonomous driving, yet current methods often fail to balance precise multi-agent interaction modeling with real-time decision adaptability, evidenced by the high computational cost for edge deployment and the unreliability stemming from simplified interaction models.To overcome these dual challenges-computational complexity and modeling insufficiency-along with the high false alarm rates of traditional static-threshold warnings, this paper introduces an integrated FCW framework that pairs a Hierarchical Spatio-Temporal Attention Network with a Dynamic Risk Threshold Adjustment algorithm. HSTAN employs a decoupled architecture (Graph Attention Network for spatial, cascaded GRU with self-attention for temporal) to achieve superior performance and efficiency, requiring only 12.3 ms inference time (73% faster than Transformer methods) and reducing the Average Displacement Error (ADE) to 0.73m (42.2% better than Social_LSTM) on the NGSIM dataset. Furthermore, Conformalized Quantile Regression enhances reliability by generating prediction intervals (91.3% coverage at 90% confidence), which the DTRA module then converts into timely warnings via a physics-informed risk potential function and an adaptive threshold mechanism inspired by statistical process control.Tested across multi-scenario datasets, the complete system demonstrates high efficacy, achieving an F1 score of 0.912, a low false alarm rate of 8.2%, and an ample warning lead time of 2.8 seconds, validating the framework's superior performance and practical deployment feasibility in complex environments.

</details>


### [134] [Prompt Fairness: Sub-group Disparities in LLMs](https://arxiv.org/abs/2511.19956)
*Meiyu Zhong,Noel Teku,Ravi Tandon*

Main category: cs.LG

TL;DR: 该论文研究了LLM中的提示公平性问题，发现不同用户/风格的提示措辞会导致模型响应质量差异，提出了基于信息论的偏差度量方法，并通过多数投票和提示中性化等干预措施改善了公平性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在不同用户/风格的提示措辞下会产生响应质量差异，这种提示公平性问题需要量化和解决，以确保模型对不同用户群体的公平性。

Method: 提出使用信息论指标来量化偏差的两个维度：子组敏感性和跨组一致性；采用多数投票和提示中性化等实际干预措施来缓解差异。

Result: 实验显示，在缓解前跨组分歧值达到0.28，通常在0.14-0.22范围内；应用中性化和多代策略后，分歧值持续下降，最大差距降至0.22，许多距离降至0.17或以下。

Conclusion: 提出的干预措施能够有效改善模型响应稳定性，增强跨用户群体的公平性，使输出在不同子组间更加稳定和一致。

Abstract: Large Language Models (LLMs), though shown to be effective in many applications, can vary significantly in their response quality. In this paper, we investigate this problem of prompt fairness: specifically, the phrasing of a prompt by different users/styles, despite the same question being asked in principle, may elicit different responses from an LLM. To quantify this disparity, we propose to use information-theoretic metrics that can capture two dimensions of bias: subgroup sensitivity, the variability of responses within a subgroup and cross group consistency, the variability of responses across subgroups. Our analysis reveals that certain subgroups exhibit both higher internal variability and greater divergence from others. Our empirical analysis reveals that certain demographic sub groups experience both higher internal variability and greater divergence from others, indicating structural inequities in model behavior. To mitigate these disparities, we propose practical interventions, including majority voting across multiple generations and prompt neutralization, which together improve response stability and enhance fairness across user populations. In the experiments, we observe clear prompt sensitivity disparities across demographic subgroups: before mitigation, cross-group divergence values reach 0.28 and typically fall in the from 0.14 to 0.22 range. After applying our neutralization and multi generation strategy, these divergences consistently decrease, with the largest gap reduced to 0.22 and many distances falling to 0.17 or below, indicating more stable and consistent outputs across subgroups.

</details>


### [135] [ParaBlock: Communication-Computation Parallel Block Coordinate Federated Learning for Large Language Models](https://arxiv.org/abs/2511.19959)
*Yujia Wang,Yuanpu Cao,Jinghui Chen*

Main category: cs.LG

TL;DR: ParaBlock是一种用于联邦学习大语言模型的新方法，通过建立通信和计算的并行线程来提高通信效率，同时保持与标准联邦块坐标下降方法相同的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型时代，即使单个块也包含大量参数，给资源受限的客户端带来显著的通信延迟，这成为联邦训练/微调LLMs的主要挑战。

Method: 提出ParaBlock方法，建立通信和计算两个并行线程来增强通信效率，理论上证明其收敛速度与标准联邦块坐标下降方法相同。

Result: 在通用指令跟随和数学推理任务上对LLMs进行微调的实证评估表明，ParaBlock不仅保持了强大的性能，还显著提高了通信效率。

Conclusion: ParaBlock成功解决了联邦学习大语言模型中的通信效率问题，是一种有效的解决方案。

Abstract: Federated learning (FL) has been extensively studied as a privacy-preserving training paradigm. Recently, federated block coordinate descent scheme has become a popular option in training large-scale models, as it allows clients to train only a subset of the model locally instead of the entire model. However, in the era of large language models (LLMs), even a single block can contain a significant number of parameters, posing substantial communication latency, particularly for resource-constrained clients. To address this challenge in federated training/fine-tuning LLMs, we propose ParaBlock, a novel approach that establishes two parallel threads for communication and computation to enhance communication efficiency. We theoretically prove that the proposed ParaBlock achieves the same convergence rate as the standard federated block coordinate descent methods. Empirical evaluations on fine-tuning LLMs on general instruction following and mathematical reasoning confirm that ParaBlock not only maintains strong performance but also significantly improves communication efficiency.

</details>


### [136] [Stragglers Can Contribute More: Uncertainty-Aware Distillation for Asynchronous Federated Learning](https://arxiv.org/abs/2511.19966)
*Yujia Wang,Fenglong Ma,Jinghui Chen*

Main category: cs.LG

TL;DR: FedEcho是一个新颖的异步联邦学习框架，通过不确定性感知蒸馏技术解决异步延迟和数据异构性带来的挑战，在保持性能的同时不访问私有客户端数据。


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习虽然提高了效率和可扩展性，但面临过时更新和快速客户端主导学习过程的问题，现有方法通常只能解决其中一个问题，造成冲突。

Method: 采用不确定性感知蒸馏技术，服务器评估滞后客户端预测的可靠性，根据估计的不确定性动态调整这些预测的影响，优先考虑更确定的预测同时利用所有客户端的多样化信息。

Result: 通过广泛实验证明，FedEcho在异步联邦学习基准测试中持续优于现有方法，实现了鲁棒性能。

Conclusion: FedEcho有效缓解了过时更新和数据异构性的负面影响，为异步联邦学习提供了有效的解决方案。

Abstract: Asynchronous federated learning (FL) has recently gained attention for its enhanced efficiency and scalability, enabling local clients to send model updates to the server at their own pace without waiting for slower participants. However, such a design encounters significant challenges, such as the risk of outdated updates from straggler clients degrading the overall model performance and the potential bias introduced by faster clients dominating the learning process, especially under heterogeneous data distributions. Existing methods typically address only one of these issues, creating a conflict where mitigating the impact of outdated updates can exacerbate the bias created by faster clients, and vice versa. To address these challenges, we propose FedEcho, a novel framework that incorporates uncertainty-aware distillation to enhance the asynchronous FL performances under large asynchronous delays and data heterogeneity. Specifically, uncertainty-aware distillation enables the server to assess the reliability of predictions made by straggler clients, dynamically adjusting the influence of these predictions based on their estimated uncertainty. By prioritizing more certain predictions while still leveraging the diverse information from all clients, FedEcho effectively mitigates the negative impacts of outdated updates and data heterogeneity. Through extensive experiments, we demonstrate that FedEcho consistently outperforms existing asynchronous federated learning baselines, achieving robust performance without requiring access to private client data.

</details>


### [137] [Rethinking Semi-Supervised Node Classification with Self-Supervised Graph Clustering](https://arxiv.org/abs/2511.19976)
*Songbo Wang,Renchi Yang,Yurui Lai,Xiaoyang Lin,Tsz Nam Chan*

Main category: cs.LG

TL;DR: NCGC框架将自监督图聚类与半监督分类结合，通过软正交GNNs和聚类模块的协同训练，有效利用图结构中的社区信息来提升节点分类性能。


<details>
  <summary>Details</summary>
Motivation: 现实图中的节点往往形成紧密社区，这些社区蕴含丰富信号可以补偿半监督节点分类中的标签稀缺问题，但现有方法未能充分利用这一特性。

Method: 提出NCGC框架：1）理论统一GNN和谱图聚类的优化目标，开发软正交GNNs；2）自监督图聚类模块包含两个聚类目标和Sinkhorn-Knopp归一化；3）多任务目标结合监督分类损失和自监督聚类损失。

Result: 在七个真实图数据集上的广泛实验表明，NCGC框架在不同经典GNN骨干网络上均显著优于流行的GNN模型和近期基线方法。

Conclusion: NCGC通过整合自监督图聚类和半监督分类，有效利用图结构中的社区信息，提升了节点分类性能，证明了该框架的有效性和通用性。

Abstract: The emergence of graph neural networks (GNNs) has offered a powerful tool for semi-supervised node classification tasks. Subsequent studies have achieved further improvements through refining the message passing schemes in GNN models or exploiting various data augmentation techniques to mitigate limited supervision. In real graphs, nodes often tend to form tightly-knit communities/clusters, which embody abundant signals for compensating label scarcity in semi-supervised node classification but are not explored in prior methods.
  Inspired by this, this paper presents NCGC that integrates self-supervised graph clustering and semi-supervised classification into a unified framework. Firstly, we theoretically unify the optimization objectives of GNNs and spectral graph clustering, and based on that, develop soft orthogonal GNNs (SOGNs) that leverage a refined message passing paradigm to generate node representations for both classification and clustering. On top of that, NCGC includes a self-supervised graph clustering module that enables the training of SOGNs for learning representations of unlabeled nodes in a self-supervised manner. Particularly, this component comprises two non-trivial clustering objectives and a Sinkhorn-Knopp normalization that transforms predicted cluster assignments into balanced soft pseudo-labels. Through combining the foregoing clustering module with the classification model using a multi-task objective containing the supervised classification loss on labeled data and self-supervised clustering loss on unlabeled data, NCGC promotes synergy between them and achieves enhanced model capacity. Our extensive experiments showcase that the proposed NCGC framework consistently and considerably outperforms popular GNN models and recent baselines for semi-supervised node classification on seven real graphs, when working with various classic GNN backbones.

</details>


### [138] [Operator Learning at Machine Precision](https://arxiv.org/abs/2511.19980)
*Aras Bacho,Aleksei G. Sorokin,Xianjin Yang,Théo Bourdais,Edoardo Calvello,Matthieu Darcy,Alexander Hsu,Bamdad Hosseini,Houman Owhadi*

Main category: cs.LG

TL;DR: CHONKNORIS是一种能够达到机器精度的算子学习方法，通过回归Tikhonov正则化牛顿-康托罗维奇更新的椭圆算子的Cholesky因子，而不是直接回归解算子本身。


<details>
  <summary>Details</summary>
Motivation: 现有的神经算子学习方法在增加复杂度时往往无法显著提高精度，与更简单的核方法和传统降阶模型表现相当，需要解决这一局限性。

Method: 基于数值分析中的牛顿型方法，回归椭圆算子的Cholesky因子，通过展开迭代构建神经架构，实现压缩映射以达到机器精度。

Result: 在非线性椭圆方程、Burgers方程、非线性达西流问题、Calderón问题、逆波散射问题和地震成像问题等基准测试中表现出色。

Conclusion: CHONKNORIS能够达到机器精度，并提出了基础模型变体FONKNORIS，能够准确求解未见过的非线性PDE如Klein-Gordon和Sine-Gordon方程。

Abstract: Neural operator learning methods have garnered significant attention in scientific computing for their ability to approximate infinite-dimensional operators. However, increasing their complexity often fails to substantially improve their accuracy, leaving them on par with much simpler approaches such as kernel methods and more traditional reduced-order models. In this article, we set out to address this shortcoming and introduce CHONKNORIS (Cholesky Newton--Kantorovich Neural Operator Residual Iterative System), an operator learning paradigm that can achieve machine precision. CHONKNORIS draws on numerical analysis: many nonlinear forward and inverse PDE problems are solvable by Newton-type methods. Rather than regressing the solution operator itself, our method regresses the Cholesky factors of the elliptic operator associated with Tikhonov-regularized Newton--Kantorovich updates. The resulting unrolled iteration yields a neural architecture whose machine-precision behavior follows from achieving a contractive map, requiring far lower accuracy than end-to-end approximation of the solution operator. We benchmark CHONKNORIS on a range of nonlinear forward and inverse problems, including a nonlinear elliptic equation, Burgers' equation, a nonlinear Darcy flow problem, the Calderón problem, an inverse wave scattering problem, and a problem from seismic imaging. We also present theoretical guarantees for the convergence of CHONKNORIS in terms of the accuracy of the emulated Cholesky factors. Additionally, we introduce a foundation model variant, FONKNORIS (Foundation Newton--Kantorovich Neural Operator Residual Iterative System), which aggregates multiple pre-trained CHONKNORIS experts for diverse PDEs to emulate the solution map of a novel nonlinear PDE. Our FONKNORIS model is able to accurately solve unseen nonlinear PDEs such as the Klein--Gordon and Sine--Gordon equations.

</details>


### [139] [Rethinking Message Passing Neural Networks with Diffusion Distance-guided Stress Majorization](https://arxiv.org/abs/2511.19984)
*Haoran Zheng,Renchi Yang,Yubo Zhou,Jianliang Xu*

Main category: cs.LG

TL;DR: 提出DDSM模型，通过应力优化和正交正则化解决MPNN中的过平滑和过相关问题，在异质性和同质性图上均优于15个基线模型


<details>
  <summary>Details</summary>
Motivation: 传统MPNN模型由于最小化Dirichlet能量和邻域聚合操作，存在严重的过平滑和过相关问题

Method: 基于应力优化和正交正则化的优化框架，引入扩散距离指导消息传递，并开发高效的距离近似算法

Result: DDSM在同质性和异质性图上均显著优于15个强基线模型

Conclusion: DDSM通过新的优化框架有效解决了MPNN的过平滑和过相关问题，在多种图上表现出色

Abstract: Message passing neural networks (MPNNs) have emerged as go-to models for learning on graph-structured data in the past decade. Despite their effectiveness, most of such models still incur severe issues such as over-smoothing and -correlation, due to their underlying objective of minimizing the Dirichlet energy and the derived neighborhood aggregation operations. In this paper, we propose the DDSM, a new MPNN model built on an optimization framework that includes the stress majorization and orthogonal regularization for overcoming the above issues. Further, we introduce the diffusion distances for nodes into the framework to guide the new message passing operations and develop efficient algorithms for distance approximations, both backed by rigorous theoretical analyses. Our comprehensive experiments showcase that DDSM consistently and considerably outperforms 15 strong baselines on both homophilic and heterophilic graphs.

</details>


### [140] [On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices](https://arxiv.org/abs/2511.19986)
*Lianming Huang,Haibo Hu,Qiao Li,Nan Guan,Chun Jason Xue*

Main category: cs.LG

TL;DR: 提出了一个按需多任务稀疏框架，通过最大化参数重用来最小化任务切换开销，在自动驾驶平台上实现6.6倍的任务切换加速


<details>
  <summary>Details</summary>
Motivation: 现有稀疏方法在单独优化每个任务时忽略了频繁任务切换带来的显著I/O开销，需要专门设计来最小化切换成本

Method: 将权重分解为可重用的块粒度单元，跨任务对齐稀疏结构以最大化重叠，动态加载下一个任务所需的少量差异块集

Result: 在真实自动驾驶平台上，相比现有稀疏方法平均加速任务切换超过6.6倍

Conclusion: 该框架通过参数重用和动态块加载有效缓解了传统整体方法的冷启动延迟，实现了优越的切换效率

Abstract: Sparsity is essential for deploying large models on resource constrained edge platforms. However, optimizing sparsity patterns for individual tasks in isolation ignores the significant I/O overhead incurred during frequent task switching. We introduce an on-demand multi-task sparsity framework specifically designed to minimize switching costs by maximizing parameter reuse. Unlike monolithic approaches, we decompose weights into reusable block-granular units and align sparse structures across tasks to maximize overlap. By dynamically loading only the small differential set of blocks required for the next task, our method effectively mitigates the cold-start latency inherent in traditional monolithic approaches.Experiments on a real-world autonomous driving platform demonstrate that our framework achieves superior switching efficiency, accelerating task switching by over 6.6X on average compared to existing sparsity methods.

</details>


### [141] [RankOOD -- Class Ranking-based Out-of-Distribution Detection](https://arxiv.org/abs/2511.19996)
*Dishanika Denipitiyage,Naveen Karunanayake,Suranga Seneviratne,Sanjay Chawla*

Main category: cs.LG

TL;DR: RankOOD是一种基于排序的OOD检测方法，使用Plackett-Luce损失训练模型，在TinyImageNet基准上实现SOTA性能，FPR95降低4.3%。


<details>
  <summary>Details</summary>
Motivation: 基于交叉熵损失训练的深度学习模型在ID类预测中会诱导出排序模式，OOD样本虽然可能被高概率分配到ID类，但遵循排序分类的概率较小。

Method: 首先使用初始分类器为每个类提取排序列表，然后使用Plackett-Luce损失进行第二轮训练，其中类排序（每个类的固定排列）是预测变量。

Result: 在近OOD TinyImageNet评估基准上达到最先进性能，FPR95降低4.3%。

Conclusion: RankOOD框架通过利用排序模式有效区分ID和OOD样本，在OOD检测任务中表现出色。

Abstract: We propose RankOOD, a rank-based Out-of-Distribution (OOD) detection approach based on training a model with the Placket-Luce loss, which is now extensively used for preference alignment tasks in foundational models. Our approach is based on the insight that with a deep learning model trained using the Cross Entropy Loss, in-distribution (ID) class prediction induces a ranking pattern for each ID class prediction. The RankOOD framework formalizes the insight by first extracting a rank list for each class using an initial classifier and then uses another round of training with the Plackett-Luce loss, where the class rank, a fixed permutation for each class, is the predicted variable. An OOD example may get assigned with high probability to an ID example, but the probability of it respecting the ranking classification is likely to be small. RankOOD, achieves SOTA performance on the near-ODD TinyImageNet evaluation benchmark, reducing FPR95 by 4.3%.

</details>


### [142] [REWA: Witness-Overlap Theory -- Foundations for Composable Binary Similarity Systems](https://arxiv.org/abs/2511.19998)
*Nikit Phadke*

Main category: cs.LG

TL;DR: REWA提出基于见证集重叠结构的相似性通用理论，可将多种相似性定义（图邻域、因果关系、拓扑特征等）简化为紧凑编码，并保持排序不变性。


<details>
  <summary>Details</summary>
Motivation: 统一各种相似性度量方法，为相似性系统提供理论基础，避免依赖哈希函数工程，实现模块化构建。

Method: 使用有限见证集、半随机比特分配和重叠单调性，在满足重叠间隙条件下，用O(log(|V|/δ))比特保留top-k排序。

Result: 证明了在见证集重叠条件下，相似性排名可被紧凑编码保留，统一了Bloom过滤器、minhash、LSH等多种方法。

Conclusion: REWA为相似性系统提供了原则性基础，支持模块化组合构建，扩展了设计空间，并为未来扩展（如多比特编码、加权见证）奠定了基础。

Abstract: REWA introduces a general theory of similarity based on witness-overlap structures. We show that whenever similarity between concepts can be expressed as monotone witness overlap -- whether arising from graph neighborhoods, causal relations, temporal structure, topological features, symbolic patterns, or embedding-based neighborhoods -- it admits a reduction to compact encodings with provable ranking preservation guarantees. REWA systems consist of: (1) finite witness sets $W(v)$, (2) semi-random bit assignments generated from each witness, and (3) monotonicity of expected similarity in the overlap $Δ(u, v) = |W(u) \cap W(v)|$. We prove that under an overlap-gap condition on the final witness sets -- independent of how they were constructed -- top-$k$ rankings are preserved using $m = O(\log(|V|/δ))$ bits. The witness-set formulation is compositional: any sequence of structural, temporal, causal, topological, information-theoretic, or learned transformations can be combined into pipelines that terminate in discrete witness sets. The theory applies to the final witness overlap, enabling modular construction of similarity systems from reusable primitives. This yields a vast design space: millions of composable similarity definitions inherit logarithmic encoding complexity. REWA subsumes and unifies Bloom filters, minhash, LSH bitmaps, random projections, sketches, and hierarchical filters as special cases. It provides a principled foundation for similarity systems whose behavior is governed by witness overlap rather than hash-function engineering. This manuscript presents the axioms, the main reducibility theorem, complete proofs with explicit constants, and a detailed discussion of compositional design, limitations, and future extensions including multi-bit encodings, weighted witnesses, and non-set representations.

</details>


### [143] [Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting](https://arxiv.org/abs/2511.20004)
*Peining Zhang,Hongchen Qin,Haochen Zhang,Ziqi Guo,Guiling Wang,Jinbo Bi*

Main category: cs.LG

TL;DR: 时间序列基础模型在零样本设置下，当输入上下文窗口足够长时，可以超越专门训练的LSTM模型进行叶面积指数预测


<details>
  <summary>Details</summary>
Motivation: 研究时间序列基础模型在农业监测中的零样本叶面积指数预测能力，探索通用模型是否能在不进行任务特定调优的情况下超越专门监督模型

Method: 使用HiQ数据集（美国，2000-2022），系统比较统计基线、全监督LSTM和Sundial基础模型，采用多种评估协议

Result: Sundial在零样本设置下，当输入上下文窗口覆盖超过1-2个完整季节周期时，能够超越完全训练的LSTM模型

Conclusion: 首次证明通用基础模型可以在不进行任务特定调优的情况下，在遥感时间序列预测中超越专门的监督模型，显示了预训练时间序列基础模型在农业和环境应用中作为即插即用预测器的强大潜力

Abstract: This work investigates the zero-shot forecasting capability of time-series foundation models for Leaf Area Index (LAI) forecasting in agricultural monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare statistical baselines, a fully supervised LSTM, and the Sundial foundation model under multiple evaluation protocols. We find that Sundial, in the zero-shot setting, can outperform a fully trained LSTM provided that the input context window is sufficiently long-specifically, when covering more than one or two full seasonal cycles. This demonstrates, for the first time, that a general-purpose foundation model can surpass specialized supervised models on remote-sensing time series prediction without any task-specific tuning. These results highlight the strong potential of pretrained time-series foundation models to serve as effective plug-and-play forecasters in agricultural and environmental applications.

</details>


### [144] [iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization](https://arxiv.org/abs/2511.20015)
*Xiucheng Wang,Tingwei Yuan,Yang Cao,Nan Cheng,Ruijin Sun,Weihua Zhuang*

Main category: cs.LG

TL;DR: iRadioDiff是一个基于扩散模型的室内无线电地图构建框架，通过物理信息提示和多路径关键先验来生成高保真度的电磁场分布，在室内定位任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统电磁求解器构建高保真室内无线电地图延迟过高，而基于学习的方法通常依赖稀疏测量或假设均匀材料，无法准确建模室内环境的异质性和多路径丰富特性。

Method: 提出采样自由的扩散框架iRadioDiff，通过接入点位置、材料反射/透射系数的物理信息提示，以及衍射点、强透射边界、视距轮廓等多路径关键先验来引导生成过程。

Result: 实验表明iRadioDiff在室内无线电地图构建和基于接收信号强度的室内定位任务中达到最先进性能，并能在不同布局和材料配置下有效泛化。

Conclusion: iRadioDiff能够准确建模非平稳场不连续性，高效构建物理一致的无线电地图，为室内定位提供了有效解决方案。

Abstract: Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at https://github.com/UNIC-Lab/iRadioDiff.

</details>


### [145] [Cross-Contrastive Clustering for Multimodal Attributed Graphs with Dual Graph Filtering](https://arxiv.org/abs/2511.20030)
*Haoran Zheng,Renchi Yang,Hongtao Wang,Jianliang Xu*

Main category: cs.LG

TL;DR: 提出DGF方案用于多模态属性图聚类，通过双图滤波和三元交叉对比学习解决预训练模型输出特征的低相关性和噪声问题


<details>
  <summary>Details</summary>
Motivation: 现有多视图聚类方法假设各视图间高度相关，但忽略了预训练语言和视觉模型输出的多模态属性具有低模态相关性和强特征噪声的特点，导致聚类性能不佳

Method: 提出双图滤波方案，在节点表示学习中加入特征级去噪组件；采用三元交叉对比训练策略，在模态、邻居和社区间进行实例级对比学习

Result: 在8个基准MMAG数据集上的实验表明，DGF在聚类质量上显著优于多种最先进的基线方法

Conclusion: DGF通过有效处理多模态属性的独特特性，在多模态属性图聚类任务中取得了优越性能

Abstract: Multimodal Attributed Graphs (MMAGs) are an expressive data model for representing the complex interconnections among entities that associate attributes from multiple data modalities (text, images, etc.). Clustering over such data finds numerous practical applications in real scenarios, including social community detection, medical data analytics, etc. However, as revealed by our empirical studies, existing multi-view clustering solutions largely rely on the high correlation between attributes across various views and overlook the unique characteristics (e.g., low modality-wise correlation and intense feature-wise noise) of multimodal attributes output by large pre-trained language and vision models in MMAGs, leading to suboptimal clustering performance.
  Inspired by foregoing empirical observations and our theoretical analyses with graph signal processing, we propose the Dual Graph Filtering (DGF) scheme, which innovatively incorporates a feature-wise denoising component into node representation learning, thereby effectively overcoming the limitations of traditional graph filters adopted in the extant multi-view graph clustering approaches. On top of that, DGF includes a tri-cross contrastive training strategy that employs instance-level contrastive learning across modalities, neighborhoods, and communities for learning robust and discriminative node representations. Our comprehensive experiments on eight benchmark MMAG datasets exhibit that DGF is able to outperform a wide range of state-of-the-art baselines consistently and significantly in terms of clustering quality measured against ground-truth labels.

</details>


### [146] [RED-F: Reconstruction-Elimination based Dual-stream Contrastive Forecasting for Multivariate Time Series Anomaly Prediction](https://arxiv.org/abs/2511.20044)
*PengYu Chen,Xiaohou Shi,Yuan Chang,Yan Sun,Sajal K. Das*

Main category: cs.LG

TL;DR: 提出了RED-F框架，通过重构消除和双流对比预测来解决多元时间序列中微弱异常前兆的检测问题，将绝对信号检测转化为相对轨迹比较，显著提升了异常预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在仅使用正常数据训练时，倾向于重构正常模式，导致在面对微弱异常前兆时，预测结果被正常模式主导，无法有效检测异常信号。

Method: RED-F框架包含重构消除模型(REM)和双流对比预测模型(DFM)。REM使用混合时频机制消除前兆，生成纯净的正常模式基线；DFM接收该基线和保留前兆的原始序列，通过对比两个预测流的差异来放大前兆信号，并使用多序列预测目标增强预测敏感性。

Result: 在六个真实世界数据集上的广泛实验表明，RED-F在异常预测任务中表现出卓越的能力。

Conclusion: RED-F通过重构消除和对比预测机制，成功解决了微弱异常前兆检测的挑战，为系统可靠性保障提供了有效解决方案。

Abstract: The proactive prediction of anomalies (AP) in multivariate time series (MTS) is a critical challenge to ensure system dependability. The difficulty lies in identifying subtle anomaly precursors concealed within normal signals. However, existing unsupervised methods, trained exclusively on normal data, demonstrate a fundamental propensity to reconstruct normal patterns. Consequently, when confronted with weak precursors, their predictions are dominated by the normal pattern, submerging the very signal required for prediction. To contend with the limitation, we propose RED-F, a Reconstruction-Elimination based Dual-stream Contrastive Forecasting framework, comprising the Reconstruction-Elimination Model (REM) and the Dual-stream Contrastive Forecasting Model (DFM). The REM utilizes a hybrid time-frequency mechanism to mitigate the precursor, generating a purified, normal-pattern baseline. The DFM then receives this purified baseline and the original sequence which retains the precursor as parallel inputs. At the core of our framework, RED-F employs a contrastive forecast that transforms the difficult task of absolute signal detection into a simpler, more robust task of relative trajectory comparison by computing the divergence between these two predictive streams. This contrastive mechanism serves to amplify the faint precursor signal. Furthermore, the DFM is trained with a novel Multi-Series Prediction (MSP) objective, which leverages distant future context to enhance its predictive sensitivity. Extensive experiments on six real-world datasets demonstrate the superior capability of RED-F in anomaly prediction tasks.

</details>


### [147] [SOMBRL: Scalable and Optimistic Model-Based RL](https://arxiv.org/abs/2511.20066)
*Bhavya Sukhija,Lenart Treven,Carmelo Sferrazza,Florian Dörfler,Pieter Abbeel,Andreas Krause*

Main category: cs.LG

TL;DR: SOMBRL是一种基于模型强化学习方法，通过乐观面对不确定性原则，学习不确定性感知的动态模型，并贪婪地最大化外部奖励与智能体认知不确定性的加权和，在非线性动态系统中实现亚线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决基于模型强化学习中未知系统动态下的高效探索挑战，智能体必须直接从在线交互中学习。

Method: 提出SOMBRL方法，学习不确定性感知的动态模型，贪婪地最大化外部奖励与认知不确定性的加权和，兼容任何策略优化器或规划器。

Result: 在状态和视觉控制环境中表现出色，在动态RC汽车硬件上超越最先进方法，展示了基于原则探索的优势。

Conclusion: SOMBRL为基于模型强化学习提供了灵活、可扩展的原则性探索解决方案，在理论和实践中都表现出色。

Abstract: We address the challenge of efficient exploration in model-based reinforcement learning (MBRL), where the system dynamics are unknown and the RL agent must learn directly from online interactions. We propose Scalable and Optimistic MBRL (SOMBRL), an approach based on the principle of optimism in the face of uncertainty. SOMBRL learns an uncertainty-aware dynamics model and greedily maximizes a weighted sum of the extrinsic reward and the agent's epistemic uncertainty. SOMBRL is compatible with any policy optimizers or planners, and under common regularity assumptions on the system, we show that SOMBRL has sublinear regret for nonlinear dynamics in the (i) finite-horizon, (ii) discounted infinite-horizon, and (iii) non-episodic settings. Additionally, SOMBRL offers a flexible and scalable solution for principled exploration. We evaluate SOMBRL on state-based and visual-control environments, where it displays strong performance across all tasks and baselines. We also evaluate SOMBRL on a dynamic RC car hardware and show SOMBRL outperforms the state-of-the-art, illustrating the benefits of principled exploration for MBRL.

</details>


### [148] [QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression](https://arxiv.org/abs/2511.20099)
*Lei Huang,Rui Zhang,Jiaming Guo,Yang Zhang,Di Huang,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 提出了CRUX结构化中间表示空间，通过两阶段训练框架CRUX-V，在Verilog代码生成任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言描述的硬件代码生成方法存在描述模糊、冗余和非结构化的问题，导致Verilog代码生成面临挑战。

Method: 引入CRUX结构化中间空间，设计包含联合表达建模和双空间优化的两阶段训练框架CRUX-V。

Result: 在多个Verilog生成基准测试中达到最先进性能，特别是在复杂设计任务中表现优异，CRUX空间对其他代码模型也具有可迁移性。

Conclusion: CRUX空间有效缩小了自由形式自然语言描述与精确Verilog生成之间的差距，为硬件代码生成提供了结构化解决方案。

Abstract: Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.

</details>


### [149] [The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs](https://arxiv.org/abs/2511.20104)
*Craig Dickson*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed "emergent misalignment" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit similar resistance to the Qwen-2.5 family and measure misalignment robustness over a range of model architectures and scales.
  We replicate the effect across nine modern open-weights models (Gemma 3 and Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code generation show a 0.68% misalignment rate (compared to 0.07% for base models), matching the lower end of prior open-model results but dramatically lower than GPT-4o's 20%.
  We identify a critical format-dependent vulnerability: requiring JSON output doubles misalignment rates compared to natural language prompts (0.96% vs 0.42%). This suggests that structural constraints may bypass safety training by reducing the model's 'degrees of freedom' to refuse. These findings confirm emergent misalignment as a reproducible phenomenon in modern open-weights models, with rates substantially lower than observed in proprietary systems.

</details>


### [150] [Multivariate Forecasting of Bitcoin Volatility with Gradient Boosting: Deterministic, Probabilistic, and Feature Importance Perspectives](https://arxiv.org/abs/2511.20105)
*Grzegorz Dudek,Mateusz Kasprzyk,Paweł Pełka*

Main category: cs.LG

TL;DR: 本研究应用LGBM模型对比特币实现波动率进行确定性和概率性预测，使用69个预测因子，发现LGBM能有效捕捉加密货币市场的非线性特征，并提供可解释的波动动态洞察。


<details>
  <summary>Details</summary>
Motivation: 研究加密货币市场波动率的预测方法，特别是应用机器学习模型来捕捉其非线性和高方差特性，同时提供对波动驱动因素的可解释性分析。

Method: 使用包含市场、行为和宏观经济指标的69个预测因子，应用LGBM模型进行确定性和概率性预测。概率预测采用两种分位数方法：直接分位数回归和使用弹球损失函数，以及残差模拟方法将点预测转换为预测分布。使用增益基础和置换特征重要性技术识别主要波动驱动因素。

Result: LGBM模型在预测性能上优于计量经济学和机器学习基线模型。特征重要性分析一致显示交易量、滞后波动率指标、投资者关注度和市值是主要波动驱动因素。

Conclusion: LGBM模型能有效捕捉加密货币市场的非线性特征，在提供准确预测的同时，还能提供对波动动态的可解释性见解，为加密货币风险管理提供有力工具。

Abstract: This study investigates the application of the Light Gradient Boosting Machine (LGBM) model for both deterministic and probabilistic forecasting of Bitcoin realized volatility. Utilizing a comprehensive set of 69 predictors -- encompassing market, behavioral, and macroeconomic indicators -- we evaluate the performance of LGBM-based models and compare them with both econometric and machine learning baselines. For probabilistic forecasting, we explore two quantile-based approaches: direct quantile regression using the pinball loss function, and a residual simulation method that transforms point forecasts into predictive distributions. To identify the main drivers of volatility, we employ gain-based and permutation feature importance techniques, consistently highlighting the significance of trading volume, lagged volatility measures, investor attention, and market capitalization. The results demonstrate that LGBM models effectively capture the nonlinear and high-variance characteristics of cryptocurrency markets while providing interpretable insights into the underlying volatility dynamics.

</details>


### [151] [CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows](https://arxiv.org/abs/2511.20109)
*Hyeonjae Kim,Chenyue Li,Wen Deng,Mengxi Jin,Wen Huang,Mengqian Lu,Binhang Yuan*

Main category: cs.LG

TL;DR: ClimateAgent是一个自主多代理框架，用于编排端到端气候数据分析工作流，通过分解用户问题、动态API检查和自校正执行，在85个真实世界气候任务中实现100%完成率和8.32的报告质量得分。


<details>
  <summary>Details</summary>
Motivation: 通用LLM代理和静态脚本管道缺乏气候特定上下文和灵活性，在实际应用中表现不佳，需要专门的气候数据分析自动化解决方案。

Method: 采用多代理框架：Orchestrate-Agent和Plan-Agent协调任务分解；Data-Agents动态检查API合成下载脚本；Coding-Agent生成Python代码、可视化和报告，并具有自校正循环。

Result: 在Climate-Agent-Bench-85基准测试中，实现100%任务完成率，报告质量得分8.32，优于GitHub-Copilot(6.27)和GPT-5基线(3.26)。

Conclusion: 多代理编排、动态API感知和自校正执行显著提高了气候科学分析任务的可靠端到端自动化能力。

Abstract: Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.

</details>


### [152] [IDAP++: Advancing Divergence-Based Pruning via Filter-Level and Layer-Level Optimization](https://arxiv.org/abs/2511.20141)
*Aleksei Samarin,Artem Nazarenko,Egor Kotenko,Valentin Malykh,Alexander Savelev,Aleksei Toropov*

Main category: cs.LG

TL;DR: 提出基于信息流分析的神经网络压缩框架，通过张量流散度量化信息变换，实现滤波器级和架构级的冗余消除


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在滤波器和架构层面的冗余问题，为资源受限环境提供有效的模型压缩方法

Method: 两阶段优化：第一阶段使用迭代散度感知剪枝去除冗余滤波器；第二阶段分析层间信息传播贡献，选择性移除对性能影响最小的整个层

Result: 在多种现代架构和数据集上实现显著模型压缩，同时保持竞争力精度，参数减少效果与最先进方案相当且在多种架构上表现更优

Conclusion: 流散度作为滤波器级和层级优化的有效指导原则，为资源受限环境部署提供实用价值

Abstract: This paper presents a novel approach to neural network compression that addresses redundancy at both the filter and architectural levels through a unified framework grounded in information flow analysis. Building on the concept of tensor flow divergence, which quantifies how information is transformed across network layers, we develop a two-stage optimization process. The first stage employs iterative divergence-aware pruning to identify and remove redundant filters while preserving critical information pathways. The second stage extends this principle to higher-level architecture optimization by analyzing layer-wise contributions to information propagation and selectively eliminating entire layers that demonstrate minimal impact on network performance. The proposed method naturally adapts to diverse architectures, including convolutional networks, transformers, and hybrid designs, providing a consistent metric for comparing the structural importance across different layer types. Experimental validation across multiple modern architectures and datasets reveals that this combined approach achieves substantial model compression while maintaining competitive accuracy. The presented approach achieves parameter reduction results that are globally comparable to those of state-of-the-art solutions and outperforms them across a wide range of modern neural network architectures, from convolutional models to transformers. The results demonstrate how flow divergence serves as an effective guiding principle for both filter-level and layer-level optimization, offering practical benefits for deployment in resource-constrained environments.

</details>


### [153] [On the Limits of Momentum in Decentralized and Federated Optimization](https://arxiv.org/abs/2511.20168)
*Riccardo Zaccone,Sai Praneeth Karimireddy,Carlo Masone*

Main category: cs.LG

TL;DR: 该论文分析了联邦学习中动量方法在统计异质性下的收敛性，证明即使使用动量也无法避免统计异质性的影响，且步长衰减快于Θ(1/t)会导致收敛到依赖初始化和异质性边界的常数值。


<details>
  <summary>Details</summary>
Motivation: 探索动量方法在联邦学习中的潜力，特别是在统计异质性环境下，研究其是否能保证在去中心化场景下的收敛性。

Method: 理论分析动量方法在循环客户端参与模式下的收敛行为，通过数学证明和数值实验验证理论结果。

Result: 动量方法仍然受到统计异质性的影响，与SGD类似，步长衰减快于Θ(1/t)会导致收敛到依赖初始化和异质性边界的常数值。

Conclusion: 动量方法在联邦学习中无法完全解决统计异质性问题，需要更有效的策略来处理客户端数据分布差异。

Abstract: Recent works have explored the use of momentum in local methods to enhance distributed SGD. This is particularly appealing in Federated Learning (FL), where momentum intuitively appears as a solution to mitigate the effects of statistical heterogeneity. Despite recent progress in this direction, it is still unclear if momentum can guarantee convergence under unbounded heterogeneity in decentralized scenarios, where only some workers participate at each round. In this work we analyze momentum under cyclic client participation, and theoretically prove that it remains inevitably affected by statistical heterogeneity. Similarly to SGD, we prove that decreasing step-sizes do not help either: in fact, any schedule decreasing faster than $Θ\left(1/t\right)$ leads to convergence to a constant value that depends on the initialization and the heterogeneity bound. Numerical results corroborate the theory, and deep learning experiments confirm its relevance for realistic settings.

</details>


### [154] [AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks](https://arxiv.org/abs/2511.20170)
*Bruno Belucci,Karim Lounici,Katia Meziani*

Main category: cs.LG

TL;DR: AdaCap是一种结合置换对比损失和Tikhonov闭式输出映射的训练方案，在小样本表格数据上显著提升神经网络性能，特别是在残差模型中效果更佳。


<details>
  <summary>Details</summary>
Motivation: 神经网络在小样本表格数据集上表现不佳，而基于树的模型仍占主导地位。

Method: 引入自适应对比方法(AdaCap)，结合基于置换的对比损失和基于Tikhonov的闭式输出映射。

Result: 在85个真实世界回归数据集和多种架构上，AdaCap在小样本情况下产生一致且统计显著的改进，特别是对残差模型。元预测器能准确预测AdaCap何时有益。

Conclusion: AdaCap作为一种有针对性的正则化机制，在神经网络最脆弱的地方增强了其性能。

Abstract: Neural networks struggle on small tabular datasets, where tree-based models remain dominant. We introduce Adaptive Contrastive Approach (AdaCap), a training scheme that combines a permutation-based contrastive loss with a Tikhonov-based closed-form output mapping. Across 85 real-world regression datasets and multiple architectures, AdaCap yields consistent and statistically significant improvements in the small-sample regime, particularly for residual models. A meta-predictor trained on dataset characteristics (size, skewness, noise) accurately anticipates when AdaCap is beneficial. These results show that AdaCap acts as a targeted regularization mechanism, strengthening neural networks precisely where they are most fragile. All results and code are publicly available at https://github.com/BrunoBelucci/adacap.

</details>


### [155] [Learning Subgroups with Maximum Treatment Effects without Causal Heuristics](https://arxiv.org/abs/2511.20189)
*Lincen Yang,Zhong Li,Matthijs van Leeuwen,Saber Salehkaleybar*

Main category: cs.LG

TL;DR: 本文提出在结构因果模型框架下直接解决最大平均处理效应的亚组发现问题，避免了传统方法中的因果启发式规则，将问题转化为标准监督学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有亚组发现方法存在两个主要问题：一是需要精确估计点条件处理效应，二是使用缺乏严格理论依据的因果启发式规则。本文旨在直接在结构因果模型框架下解决这些问题。

Method: 在基于分区的模型假设下，将最优亚组发现问题转化为数据生成模型的恢复问题，从而可以使用任何基于分区的方法（如CART）来学习具有最大处理效应的亚组。

Result: 在大量合成和半合成数据集上的实验表明，该方法比多种基线方法更准确地识别出具有最大处理效应的亚组。

Conclusion: 直接在结构因果模型框架下进行亚组发现，避免了因果启发式规则，能够更准确地识别最优亚组，为精准决策提供了可靠方法。

Abstract: Discovering subgroups with the maximum average treatment effect is crucial for targeted decision making in domains such as precision medicine, public policy, and education. While most prior work is formulated in the potential outcome framework, the corresponding structural causal model (SCM) for this task has been largely overlooked. In practice, two approaches dominate. The first estimates pointwise conditional treatment effects and then fits a tree on those estimates, effectively turning subgroup estimation into the harder problem of accurate pointwise estimation. The second constructs decision trees or rule sets with ad-hoc 'causal' heuristics, typically without rigorous justification for why a given heuristic may be used or whether such heuristics are necessary at all. We address these issues by studying the problem directly under the SCM framework. Under the assumption of a partition-based model, we show that optimal subgroup discovery reduces to recovering the data-generating models and hence a standard supervised learning problem (regression or classification). This allows us to adopt any partition-based methods to learn the subgroup from data. We instantiate the approach with CART, arguably one of the most widely used tree-based methods, to learn the subgroup with maximum treatment effect. Finally, on a large collection of synthetic and semi-synthetic datasets, we compare our method against a wide range of baselines and find that our approach, which avoids such causal heuristics, more accurately identifies subgroups with maximum treatment effect. Our source code is available at https://github.com/ylincen/causal-subgroup.

</details>


### [156] [In-Context Compositional Learning via Sparse Coding Transformer](https://arxiv.org/abs/2511.20194)
*Wei Chen,Jingxi Yu,Zichen Miao,Qiang Qiu*

Main category: cs.LG

TL;DR: 本文提出了一种基于稀疏编码原理的注意力机制改进方法，用于增强Transformer在组合学习任务中的能力。该方法将注意力块重新解释为通过编码和解码字典原子的投影，并对系数施加稀疏性约束，从而更好地捕捉组合结构。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在语言、视觉和多模态任务中取得了显著成功，但在处理组合学习任务时仍面临挑战。这些任务需要模型从上下文示例中推断组合规则，而Transformer本身并非为处理组合任务而设计，缺乏结构性归纳偏置。

Method: 将注意力块重新解释为输入通过两个学习到的字典原子集合（编码字典和解码字典）的投影。编码字典将输入分解为一组系数，这些系数表示输入的组合结构。为了增强结构化表示，对这些系数施加稀疏性约束。稀疏系数随后用于线性组合解码字典原子以生成输出。

Result: 在S-RAVEN和RAVEN数据集上验证了方法的有效性。对于某些组合泛化任务，该方法在标准Transformer失效时仍能保持性能，这归功于其学习和应用组合规则的能力。

Conclusion: 基于稀疏编码原理的注意力机制改进能够有效增强Transformer在组合学习任务中的能力，特别是在需要组合泛化的场景下表现出色。

Abstract: Transformer architectures have achieved remarkable success across language, vision, and multimodal tasks, and there is growing demand for them to address in-context compositional learning tasks. In these tasks, models solve the target problems by inferring compositional rules from context examples, which are composed of basic components structured by underlying rules. However, some of these tasks remain challenging for Transformers, which are not inherently designed to handle compositional tasks and offer limited structural inductive bias. In this work, inspired by the principle of sparse coding, we propose a reformulation of the attention to enhance its capability for compositional tasks. In sparse coding, data are represented as sparse combinations of dictionary atoms with coefficients that capture their compositional rules. Specifically, we reinterpret the attention block as a mapping of inputs into outputs through projections onto two sets of learned dictionary atoms: an encoding dictionary and a decoding dictionary. The encoding dictionary decomposes the input into a set of coefficients, which represent the compositional structure of the input. To enhance structured representations, we impose sparsity on these coefficients. The sparse coefficients are then used to linearly combine the decoding dictionary atoms to generate the output. Furthermore, to assist compositional generalization tasks, we propose estimating the coefficients of the target problem as a linear combination of the coefficients obtained from the context examples. We demonstrate the effectiveness of our approach on the S-RAVEN and RAVEN datasets. For certain compositional generalization tasks, our method maintains performance even when standard Transformers fail, owing to its ability to learn and apply compositional rules.

</details>


### [157] [Communication-Efficient Learning for Satellite Constellations](https://arxiv.org/abs/2511.20220)
*Ruxandra-Stefania Tudose,Moritz H. W. Grüss,Grace Ra Kim,Karl H. Johansson,Nicola Bastianello*

Main category: cs.LG

TL;DR: 提出了一种用于卫星星座的联邦学习算法，通过本地训练和压缩减少通信开销，并引入误差反馈机制提高准确性。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星星座的普及，需要解决在这些分布式系统中进行机器学习的问题，特别是通信效率问题。

Method: 采用联邦学习方法，卫星本地处理数据，地面站聚合模型；使用本地训练减少通信次数，压缩减少通信量；引入误差反馈机制提升准确性。

Result: 通过仿真验证，在真实空间场景中表现出优于现有技术的性能。

Conclusion: 提出的算法在通信效率和模型准确性方面都取得了良好平衡，误差反馈机制具有更广泛的适用性。

Abstract: Satellite constellations in low-Earth orbit are now widespread, enabling positioning, Earth imaging, and communications. In this paper we address the solution of learning problems using these satellite constellations. In particular, we focus on a federated approach, where satellites collect and locally process data, with the ground station aggregating local models. We focus on designing a novel, communication-efficient algorithm that still yields accurate trained models. To this end, we employ several mechanisms to reduce the number of communications with the ground station (local training) and their size (compression). We then propose an error feedback mechanism that enhances accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback scheme that can be more broadly applied. We analyze the convergence of the resulting algorithm, and compare it with the state of the art through simulations in a realistic space scenario, showcasing superior performance.

</details>


### [158] [Decoupling and Damping: Structurally-Regularized Gradient Matching for Multimodal Graph Condensation](https://arxiv.org/abs/2511.20222)
*Lian Shen,Zhendan Chen,Yinhui jiang,Meijia Song,Ziming Su,Juan Liu,Xiangrong Liu*

Main category: cs.LG

TL;DR: 针对多模态图神经网络训练的计算负担问题，提出结构正则化梯度匹配方法，通过梯度解耦和结构阻尼正则化解决模态间梯度冲突和图结构噪声放大问题。


<details>
  <summary>Details</summary>
Motivation: 多模态图在电商和推荐系统等关键应用中日益重要，但其大规模特性给GNN训练带来巨大计算负担。现有图压缩方法在多模态场景下表现不佳，主要面临模态间语义错配导致的梯度冲突和图结构放大梯度噪声的双重挑战。

Method: 提出SR-GM框架，包含两个协同组件：1）梯度解耦机制，通过正交投影从源头解决模态间梯度冲突；2）结构阻尼正则化器，利用图的Dirichlet能量，在优化过程中将拓扑结构从噪声放大器转变为稳定力。

Result: 大量实验表明，SR-GM相比基线方法显著提高了准确率并加速了收敛。消融研究证实同时解决梯度冲突和结构放大问题对于实现优越性能至关重要。压缩后的多模态图展现出强大的跨架构泛化能力。

Conclusion: 该研究为资源受限环境下的多模态图学习提供了可扩展的方法论，有望加速神经架构搜索等应用。

Abstract: In critical web applications such as e-commerce and recommendation systems, multimodal graphs integrating rich visual and textual attributes are increasingly central, yet their large scale introduces substantial computational burdens for training Graph Neural Networks (GNNs). While Graph Condensation (GC) offers a promising solution by synthesizing smaller datasets, existing methods falter in the multimodal setting. We identify a dual challenge causing this failure: (1) conflicting gradients arising from semantic misalignments between modalities, and (2) the GNN's message-passing architecture pathologically amplifying this gradient noise across the graph structure. To address this, we propose Structurally-Regularized Gradient Matching (SR-GM), a novel condensation framework tailored for multimodal graphs. SR-GM introduces two synergistic components: first, a gradient decoupling mechanism that resolves inter-modality conflicts at their source via orthogonal projection; and second, a structural damping regularizer that acts directly on the gradient field. By leveraging the graph's Dirichlet energy, this regularizer transforms the topology from a noise amplifier into a stabilizing force during optimization. Extensive experiments demonstrate that SR-GM significantly improves accuracy and accelerates convergence compared to baseline methods. Ablation studies confirm that addressing both gradient conflict and structural amplification in tandem is essential for achieving superior performance. Moreover, the condensed multimodal graphs exhibit strong cross-architecture generalization and promise to accelerate applications like Neural Architecture Search. This research provides a scalable methodology for multimodal graph-based learning in resource-constrained environments.

</details>


### [159] [DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label Learning](https://arxiv.org/abs/2511.20225)
*Bo Han,Zhuoming Li,Xiaoyu Wang,Yaxin Hou,Hui Liu,Junhui Hou,Yuheng Jia*

Main category: cs.LG

TL;DR: 提出DiCaP框架，通过估计后验精度来校准伪标签权重，并引入双阈值机制分离置信和模糊区域，在半监督多标签学习中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有半监督多标签学习方法对所有伪标签赋予相同权重，忽略了伪标签质量差异，这会放大噪声或不确定预测的影响并降低性能。

Method: 提出分布校准伪标签(DiCaP)框架：1) 理论验证伪标签最优权重应反映其正确性似然；2) 估计后验精度校准伪标签权重；3) 双阈值机制分离置信样本(伪标记加权)和模糊样本(无监督对比学习)。

Result: 在多个基准数据集上的实验验证，该方法实现了一致改进，比最先进方法提升高达4.27%。

Conclusion: DiCaP通过考虑伪标签正确性似然来校准权重，结合双阈值机制，有效提升了半监督多标签学习的性能。

Abstract: Semi-supervised multi-label learning (SSMLL) aims to address the challenge of limited labeled data in multi-label learning (MLL) by leveraging unlabeled data to improve the model's performance. While pseudo-labeling has become a dominant strategy in SSMLL, most existing methods assign equal weights to all pseudo-labels regardless of their quality, which can amplify the impact of noisy or uncertain predictions and degrade the overall performance. In this paper, we theoretically verify that the optimal weight for a pseudo-label should reflect its correctness likelihood. Empirically, we observe that on the same dataset, the correctness likelihood distribution of unlabeled data remains stable, even as the number of labeled training samples varies. Building on this insight, we propose Distribution-Calibrated Pseudo-labeling (DiCaP), a correctness-aware framework that estimates posterior precision to calibrate pseudo-label weights. We further introduce a dual-thresholding mechanism to separate confident and ambiguous regions: confident samples are pseudo-labeled and weighted accordingly, while ambiguous ones are explored by unsupervised contrastive learning. Experiments conducted on multiple benchmark datasets verify that our method achieves consistent improvements, surpassing state-of-the-art methods by up to 4.27%.

</details>


### [160] [Leveraging weights signals -- Predicting and improving generalizability in reinforcement learning](https://arxiv.org/abs/2511.20234)
*Olivier Moulin,Vincent Francois-lavet,Paul Elbers,Mark Hoogendoorn*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络内部权重预测RL智能体泛化能力的方法，并改进了PPO损失函数来提升智能体的泛化性能


<details>
  <summary>Details</summary>
Motivation: 解决RL智能体在训练环境上过拟合、泛化能力差的问题

Method: 基于智能体神经网络内部权重预测泛化分数，并改进PPO损失函数

Result: 改进后的PPO算法训练出的智能体比原版具有更强的泛化能力

Conclusion: 该方法能有效提升RL智能体的泛化性能

Abstract: Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.

</details>


### [161] [Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling](https://arxiv.org/abs/2511.20257)
*Zhiguo Zhang,Xiaoliang Ma,Daniel Schlesinger*

Main category: cs.LG

TL;DR: 提出了一种物理引导、可解释的时空学习框架，用于空气污染预测，在性能和可解释性之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 准确的空气污染预测对公共健康至关重要，但大多数模型面临性能与可解释性之间的权衡

Method: 将污染物浓度的时空行为分解为两个透明加性模块：物理引导的传输核和可解释的注意力机制

Result: 在斯德哥尔摩地区数据集上评估，模型在多个预测时间范围内始终优于最先进的基线方法

Conclusion: 模型整合了高预测性能和时空可解释性，为实际空气质量管理提供了更可靠的基础

Abstract: Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.

</details>


### [162] [Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits](https://arxiv.org/abs/2511.20273)
*Areeb Ahmad,Abhinav Joshi,Ashutosh Modi*

Main category: cs.LG

TL;DR: 该论文提出了一种细粒度的视角，将Transformer中的注意力头和MLP层分解为正交奇异方向，揭示了单个组件内叠加的独立计算。


<details>
  <summary>Details</summary>
Motivation: 现有的机制可解释性方法通常将注意力头和MLP层视为不可分割的单元，忽略了它们内部可能学习到的功能子结构。

Method: 通过将Transformer组件分解为正交奇异方向，在IOI、GP和GT等标准任务上验证该视角，分析计算图中节点的激活模式。

Result: 发现先前识别的规范功能头（如名称移动器）编码了多个与不同奇异方向对齐的重叠子功能，有意义的计算存在于紧凑子空间中。

Conclusion: Transformer计算比先前假设的更加分布式、结构化和组合化，这为细粒度机制可解释性和模型内部理解开辟了新途径。

Abstract: Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.

</details>


### [163] [HVAdam: A Full-Dimension Adaptive Optimizer](https://arxiv.org/abs/2511.20277)
*Yiheng Zhang,Shaowu Wu,Yuanzhuo Xu,Jiajun Wu,Shang Xu,Steve Drew,Xiaoguang Niu*

Main category: cs.LG

TL;DR: 提出了Anon优化器，通过可调节的自适应机制在SGD和Adam之间插值甚至外推，解决了自适应优化器泛化能力差的问题，并在多种任务上优于现有优化器。


<details>
  <summary>Details</summary>
Motivation: 自适应优化器（如Adam）在大规模模型训练中成功，但在传统架构上泛化能力不如非自适应方法（如SGD）。研究发现自适应预调节器限制了优化器适应不同优化景观的能力。

Method: 提出Anon优化器，具有连续可调的自适应性，引入增量延迟更新（IDU）机制确保收敛，比AMSGrad的最大值跟踪策略更灵活，增强对梯度噪声的鲁棒性。

Result: 在图像分类、扩散模型和语言建模等代表性任务上，Anon持续优于最先进的优化器。

Conclusion: 自适应可以作为有价值的可调设计原则，Anon提供了首个统一可靠的框架，能够弥合经典和现代优化器之间的差距，并超越它们的优势特性。

Abstract: Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity
  , allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.

</details>


### [164] [Geometry of Decision Making in Language Models](https://arxiv.org/abs/2511.20315)
*Abhinav Joshi,Divyanshu Bhatt,Ashutosh Modi*

Main category: cs.LG

TL;DR: 通过内在维度分析LLM隐藏表征的几何结构，发现在多项选择问答任务中，模型在早期层使用低维流形，中间层扩展维度，后期层压缩维度并收敛到决策相关表征。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在各种任务上表现出强大的泛化能力，但其内部决策过程仍然不透明，需要从几何角度理解其隐藏表征结构。

Method: 对28个开源transformer模型进行大规模研究，使用多个估计器估计各层的内在维度，并量化每层在多项选择问答任务上的性能。

Result: 发现一致的ID模式：早期层在低维流形上操作，中间层扩展空间，后期层压缩空间并收敛到决策相关表征。

Conclusion: LLM隐式学习将语言输入投影到结构化的低维流形上，这些流形与任务特定决策对齐，为理解语言模型中泛化和推理的出现提供了新的几何视角。

Abstract: Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.

</details>


### [165] [MXtalTools: A Toolkit for Machine Learning on Molecular Crystals](https://arxiv.org/abs/2511.20327)
*Michael Kilgour,Mark E. Tuckerman,Jutta Rogal*

Main category: cs.LG

TL;DR: MXtalTools是一个用于分子晶体数据驱动建模的灵活Python包，支持机器学习研究分子固态


<details>
  <summary>Details</summary>
Motivation: 为分子晶体的机器学习研究提供灵活的工具包，促进分子固态的数据驱动建模

Method: 包含多个实用工具类：数据集合成整理、集成工作流、晶体参数化表示、结构采样优化、端到端可微分晶体采样构建分析，采用模块化设计和CUDA加速

Result: 开发了MXtalTools Python包，提供开源代码和详细文档

Conclusion: MXtalTools为分子晶体建模提供了灵活的工具，可集成到现有工作流或构建新的建模管道

Abstract: We present MXtalTools, a flexible Python package for the data-driven modelling of molecular crystals, facilitating machine learning studies of the molecular solid state. MXtalTools comprises several classes of utilities: (1) synthesis, collation, and curation of molecule and crystal datasets, (2) integrated workflows for model training and inference, (3) crystal parameterization and representation, (4) crystal structure sampling and optimization, (5) end-to-end differentiable crystal sampling, construction and analysis. Our modular functions can be integrated into existing workflows or combined and used to build novel modelling pipelines. MXtalTools leverages CUDA acceleration to enable high-throughput crystal modelling. The Python code is available open-source on our GitHub page, with detailed documentation on ReadTheDocs.

</details>


### [166] [Soft Adaptive Policy Optimization](https://arxiv.org/abs/2511.20347)
*Chang Gao,Chujie Zheng,Xiong-Hui Chen,Kai Dang,Shixuan Liu,Bowen Yu,An Yang,Shuai Bai,Jingren Zhou,Junyang Lin*

Main category: cs.LG

TL;DR: 提出了Soft Adaptive Policy Optimization (SAPO)方法，通过软门控机制替代硬裁剪，在保持序列级一致性的同时实现token级自适应，解决了强化学习中策略优化的稳定性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于分组的策略优化方法（如GSPO和GRPO）使用硬裁剪来解决token级重要性比率高方差问题，但这难以同时保持稳定性和有效学习。特别是在专家混合模型中，这个问题更加严重。

Method: SAPO使用平滑的温度控制门来替代硬裁剪，自适应地衰减离策略更新，同时保留有用的学习信号。该方法既保持序列级一致性，又实现token级自适应，形成连续的信任区域。

Result: 在数学推理基准测试中，SAPO在相同训练预算下表现出更好的训练稳定性和更高的Pass@1性能。使用SAPO训练的Qwen3-VL模型系列在各种任务和不同模型规模上都获得了持续的性能提升。

Conclusion: SAPO为LLMs的强化学习训练提供了更可靠、可扩展和有效的优化策略，解决了现有方法在稳定性和学习效率之间的权衡问题。

Abstract: Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.

</details>


### [167] [Complexity Reduction Study Based on RD Costs Approximation for VVC Intra Partitioning](https://arxiv.org/abs/2511.20349)
*M. E. A. Kherchouche,F. Galpin,T. Dumas,F. Schnitzler,D. Menard,L. Zhang*

Main category: cs.LG

TL;DR: 本文研究了VVC帧内分区的复杂度问题，提出了两种基于机器学习的加速方法：回归预测RD成本和强化学习决策，通过预定义阈值选择最佳分割方案。


<details>
  <summary>Details</summary>
Motivation: 解决VVC帧内分区在率失真优化过程中穷举搜索带来的高计算复杂度问题，提高编码效率。

Method: 提出两种方法：1）基于回归的技术预测CU的归一化RD成本；2）将分区决策建模为马尔可夫决策过程，使用深度Q网络算法学习强化学习代理。两种方法都利用相邻块的RD成本作为输入特征，并应用预定义阈值选择分割方案。

Result: 所提出的方法具有尺寸无关性，能够有效加速VVC帧内分区的率失真优化过程。

Conclusion: 两种机器学习方法都能有效降低VVC帧内分区的计算复杂度，其中强化学习方法特别适合处理具有马尔可夫性质的分区决策问题。

Abstract: In this paper, a complexity study is conducted for Versatile Video Codec (VVC) intra partitioning to accelerate the exhaustive search involved in Rate-Distortion Optimization (RDO) process. To address this problem, two main machine learning techniques are proposed and compared. Unlike existing methods, the proposed approaches are size independent and incorporate the Rate-Distortion (RD) costs of neighboring blocks as input features. The first method is a regression based technique that predicts normalized RD costs of a given Coding Unit (CU). As partitioning possesses the Markov property, the associated decision-making problem can be modeled as a Markov Decision Process (MDP) and solved by Reinforcement Learning (RL). The second approach is a RL agent learned from trajectories of CU decision across two depths with Deep Q-Network (DQN) algorithm. Then a pre-determined thresholds are applied for both methods to select a suitable split for the current CU.

</details>


### [168] [PRISM: Periodic Representation with multIscale and Similarity graph Modelling for enhanced crystal structure property prediction](https://arxiv.org/abs/2511.20362)
*Àlex Solé,Albert Mosella-Montoro,Joan Cardona,Daniel Aravena,Silvia Gómez-Coca,Eliseo Ruiz,Javier Ruiz-Hidalgo*

Main category: cs.LG

TL;DR: PRISM是一个图神经网络框架，通过集成多尺度表示和周期性特征编码来改进晶体结构预测，显著提升了晶体性质预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前方法往往忽略晶体结构固有的周期性边界条件和多尺度相互作用，这限制了图表示学习在晶体结构分析中的应用效果。

Method: 采用专家模块集合，每个模块专门编码周期性系统的不同结构和化学方面，明确集成多尺度表示和周期性特征编码。

Result: 在多个基于晶体结构的基准测试中，PRISM显著提高了预测精度，超越了现有最先进方法。

Conclusion: PRISM框架通过有效整合周期性边界条件和多尺度相互作用，为晶体性质预测提供了更准确的解决方案。

Abstract: Crystal structures are characterised by repeating atomic patterns within unit cells across three-dimensional space, posing unique challenges for graph-based representation learning. Current methods often overlook essential periodic boundary conditions and multiscale interactions inherent to crystalline structures. In this paper, we introduce PRISM, a graph neural network framework that explicitly integrates multiscale representations and periodic feature encoding by employing a set of expert modules, each specialised in encoding distinct structural and chemical aspects of periodic systems. Extensive experiments across crystal structure-based benchmarks demonstrate that PRISM improves state-of-the-art predictive accuracy, significantly enhancing crystal property prediction.

</details>


### [169] [MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers](https://arxiv.org/abs/2511.20382)
*Audrey Pei-Hsuan Chen*

Main category: cs.LG

TL;DR: MoRE是一个多组学表示学习框架，通过冻结预训练transformer并添加轻量级适配器，实现异构组学数据的对齐和整合。


<details>
  <summary>Details</summary>
Motivation: 多组学数据存在维度极高、模态异质性和批次效应等挑战，现有方法在跨模态整合方面仍有局限，需要开发更有效的表示学习框架。

Method: 采用参数高效微调策略，为冻结的预训练transformer添加模态特定适配器和任务自适应融合层，结合掩码建模、对比学习和批次不变对齐损失进行优化。

Result: MoRE在批次鲁棒性和生物信息保持方面表现优异，同时显著减少了可训练参数数量，在未见细胞类型和平台上具有良好的泛化能力。

Conclusion: MoRE为实现通用组学基础模型提供了实用路径，展示了冻结预训练模型在多组学整合中的潜力。

Abstract: Representation learning on multi-omics data is challenging due to extreme dimensionality, modality heterogeneity, and cohort-specific batch effects. While pre-trained transformer backbones have shown broad generalization capabilities in biological sequence modeling, their application to multi-omics integration remains underexplored. We present MoRE (Multi-Omics Representation Embedding), a framework that repurposes frozen pre-trained transformers to align heterogeneous assays into a shared latent space. Unlike purely generative approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy, prioritizing cross-sample and cross-modality alignment over simple sequence reconstruction. Specifically, MoRE attaches lightweight, modality-specific adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes a masked modeling objective jointly with supervised contrastive and batch-invariant alignment losses, yielding structure-preserving embeddings that generalize across unseen cell types and platforms. We benchmark MoRE against established baselines, including scGPT, scVI, and Harmony with scArches, evaluating integration fidelity, rare population detection, and modality transfer. Our results demonstrate that MoRE achieves competitive batch robustness and biological conservation while significantly reducing trainable parameters compared to fully fine-tuned models. This work positions MoRE as a practical step toward general-purpose omics foundation models.

</details>


### [170] [Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI](https://arxiv.org/abs/2511.20395)
*M. C. Schoppema,B. H. M. van der Velden,A. Hürriyetoğlu,M. D. Klijnstra,E. J. Faassen,A. Gerssen,H. J. van der Fels-Klerx*

Main category: cs.LG

TL;DR: 开发了一个可解释的深度学习模型来预测荷兰Zeeland河口双壳类软体动物中的河豚毒素污染，发现日照时间、全球辐射、水温和氯化物浓度是主要影响因素。


<details>
  <summary>Details</summary>
Motivation: 自2012年以来，欧洲温带水域的双壳类软体动物中发现河豚毒素污染，这带来了食品安全风险和经济损失，因此需要早期预测河豚毒素污染。

Method: 使用气象和水文特征作为输入，开发了一个可解释的深度学习模型来预测河豚毒素污染的存在与否。

Result: 结果显示日出时间、日落时间、全球辐射、水温和氯化物浓度对河豚毒素污染贡献最大，有效日照时数是重要驱动因素。

Conclusion: 该可解释深度学习模型识别出的环境因素（日照时数、全球辐射、水温和水氯化物浓度）与双壳类软体动物中的河豚毒素污染相关，为食品行业和主管部门提供了有价值的风险缓解工具。

Abstract: Since 2012, tetrodotoxin (TTX) has been found in seafoods such as bivalve mollusks in temperate European waters. TTX contamination leads to food safety risks and economic losses, making early prediction of TTX contamination vital to the food industry and competent authorities. Recent studies have pointed to shallow habitats and water temperature as main drivers to TTX contamination in bivalve mollusks. However, the temporal relationships between abiotic factors, biotic factors, and TTX contamination remain unexplored.
  We have developed an explainable, deep learning-based model to predict TTX contamination in the Dutch Zeeland estuary. Inputs for the model were meteorological and hydrological features; output was the presence or absence of TTX contamination.
  Results showed that the time of sunrise, time of sunset, global radiation, water temperature, and chloride concentration contributed most to TTX contamination. Thus, the effective number of sun hours, represented by day length and global radiation, was an important driver for tetrodotoxin contamination in bivalve mollusks.
  To conclude, our explainable deep learning model identified the aforementioned environmental factors (number of sun hours, global radiation, water temperature, and water chloride concentration) to be associated with tetrodotoxin contamination in bivalve mollusks; making our approach a valuable tool to mitigate marine toxin risks for food industry and competent authorities.

</details>


### [171] [Model-Based Learning of Whittle indices](https://arxiv.org/abs/2511.20397)
*Joël Charles-Rebuffé,Nicolas Gast,Bruno Gaujal*

Main category: cs.LG

TL;DR: BLINQ是一种基于模型的新算法，用于学习可索引、可通信且单链马尔可夫决策过程的Whittle指数。该方法通过构建MDP的经验估计并使用现有算法的扩展版本计算Whittle指数，在样本效率和计算成本方面显著优于现有的Q学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Q学习方法在样本效率和计算成本方面存在不足，特别是在需要高精度近似时。BLINQ旨在通过基于模型的方法更有效地学习Whittle指数，克服这些限制。

Method: BLINQ通过构建MDP的经验估计，然后使用现有算法的扩展版本计算Whittle指数。该方法提供了收敛性证明和学习时间边界，并分析了计算复杂度。

Result: 数值实验表明，BLINQ在获得准确近似所需的样本数量方面显著优于现有Q学习方法，且对于任何合理高数量的样本，其总计算成本甚至低于Q学习。即使Q学习算法使用预训练神经网络加速，这些优势仍然存在。

Conclusion: BLINQ是一种高效学习Whittle指数的算法，在样本效率和计算成本方面优于现有方法，为基于Whittle指数的决策问题提供了更实用的解决方案。

Abstract: We present BLINQ, a new model-based algorithm that learns the Whittle indices of an indexable, communicating and unichain Markov Decision Process (MDP). Our approach relies on building an empirical estimate of the MDP and then computing its Whittle indices using an extended version of a state-of-the-art existing algorithm. We provide a proof of convergence to the Whittle indices we want to learn as well as a bound on the time needed to learn them with arbitrary precision. Moreover, we investigate its computational complexity. Our numerical experiments suggest that BLINQ significantly outperforms existing Q-learning approaches in terms of the number of samples needed to get an accurate approximation. In addition, it has a total computational cost even lower than Q-learning for any reasonably high number of samples. These observations persist even when the Q-learning algorithms are speeded up using pre-trained neural networks to predict Q-values.

</details>


### [172] [Short-Range Oversquashing](https://arxiv.org/abs/2511.20406)
*Yaaqov Mishayev,Yonatan Sverdlov,Tal Amir,Nadav Dym*

Main category: cs.LG

TL;DR: 本文发现过压缩现象不仅存在于长距离任务中，也会出现在短距离问题中，揭示了过压缩的两个不同机制：瓶颈现象和梯度消失现象，并表明Transformer比专门的MPNN更能有效解决过压缩问题。


<details>
  <summary>Details</summary>
Motivation: MPNN在图学习中广泛应用，但其处理长距离信息的能力受到过压缩现象的限制。现有研究对Graph Transformers和MPNN框架内的解决方案存在争议，需要更深入理解过压缩的本质机制。

Method: 通过分析短距离任务中的过压缩现象，区分瓶颈现象和梯度消失现象这两种不同的过压缩机制，并比较虚拟节点等技术与Transformer在解决这些问题上的效果。

Result: 发现短距离瓶颈效应不被现有过压缩解释所涵盖，添加虚拟节点无法解决该问题，而Transformer在这些任务中表现成功。

Conclusion: Transformer相比专门的MPNN是解决过压缩问题更有效的方案，过压缩包含两个不同机制：短距离瓶颈现象和长距离梯度消失现象。

Abstract: Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.
  In this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.
  We further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.

</details>


### [173] [Tight Margin-Based Generalization Bounds for Voting Classifiers over Finite Hypothesis Sets](https://arxiv.org/abs/2511.20407)
*Kasper Green Larsen,Natascha Schalburg*

Main category: cs.LG

TL;DR: 本文提出了首个基于间隔的投票分类器泛化界，在假设集大小、间隔、训练点比例、样本数量和失败概率之间的权衡上达到了渐近紧致。


<details>
  <summary>Details</summary>
Motivation: 现有投票分类器的泛化界在关键参数之间的权衡上不够紧致，需要建立更精确的理论边界来指导实践。

Method: 通过理论分析和证明，建立了基于间隔的泛化边界，考虑了假设集大小、间隔参数、训练样本分布等多个因素。

Result: 获得了首个在关键参数权衡上达到渐近紧致的投票分类器泛化界，为理论分析和实际应用提供了更精确的指导。

Conclusion: 该工作填补了投票分类器泛化理论的重要空白，为后续研究和实际应用提供了坚实的理论基础。

Abstract: We prove the first margin-based generalization bound for voting classifiers, that is asymptotically tight in the tradeoff between the size of the hypothesis set, the margin, the fraction of training points with the given margin, the number of training samples and the failure probability.

</details>


### [174] [Diffusion for Fusion: Designing Stellarators with Generative AI](https://arxiv.org/abs/2511.20445)
*Misha Padidar,Teresa Huang,Andrew Giuliani,Marina Spivak*

Main category: cs.LG

TL;DR: 使用条件扩散模型从QUASR数据库中生成具有理想特性的准对称仿星器设计，许多生成的设计表现出良好性能：准对称性偏差小于5%，且达到目标特性。


<details>
  <summary>Details</summary>
Motivation: 仿星器设计传统上是计算密集的PDE约束优化问题，需要数小时在计算集群上求解。利用机器学习方法特别是生成模型，可以快速生成高质量的仿星器设计。

Method: 在QUASR数据库数据上训练条件扩散模型，生成具有特定特性（纵横比和平均旋转变换）的准对称仿星器设计，并应用于训练中未见过的特性组合。

Result: 生成的仿星器设计中，许多表现出小于5%的准对称性偏差，并成功达到了目标特性，显示出达到低于1%偏差目标的潜力。

Conclusion: 生成建模为推进仿星器设计提供了有前景的途径，条件扩散模型能够有效生成具有理想特性的仿星器设计。

Abstract: Stellarators are a prospective class of fusion-based power plants that confine a hot plasma with three-dimensional magnetic fields. Typically framed as a PDE-constrained optimization problem, stellarator design is a time-consuming process that can take hours to solve on a computing cluster. Developing fast methods for designing stellarators is crucial for advancing fusion research. Given the recent development of large datasets of optimized stellarators, machine learning approaches have emerged as a potential candidate. Motivated by this, we present an open inverse problem to the machine learning community: to rapidly generate high-quality stellarator designs which have a set of desirable characteristics. As a case study in the problem space, we train a conditional diffusion model on data from the QUASR database to generate quasisymmetric stellarator designs with desirable characteristics (aspect ratio and mean rotational transform). The diffusion model is applied to design stellarators with characteristics not seen during training. We provide evaluation protocols and show that many of the generated stellarators exhibit solid performance: less than 5% deviation from quasisymmetry and the target characteristics. The modest deviation from quasisymmetry highlights an opportunity to reach the sub 1% target. Beyond the case study, we share multiple promising avenues for generative modeling to advance stellarator design.

</details>


### [175] [Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks](https://arxiv.org/abs/2511.20456)
*Shreevanth Krishnaa Gopalakrishnan,Stephen Hailes*

Main category: cs.LG

TL;DR: 本文系统评估了CSI深度学习模型在不同威胁模型下的鲁棒性，发现小型模型虽然高效但鲁棒性较差，物理可实现扰动比无约束特征空间攻击更难成功，对抗训练能有效缓解漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在基于CSI的人类感知系统中日益重要，这些系统对对抗性扰动的脆弱性引发了安全和可靠性担忧，需要量化理解模型鲁棒性以确保无线感知在真实环境中的安全部署。

Method: 建立了评估框架，比较紧凑时间自编码器模型与大型深度架构在三个公共数据集上的表现，评估模型规模、训练机制和物理约束对鲁棒性的影响，测试了白盒、黑盒/迁移和通用扰动等威胁模型。

Result: 实验表明小型模型在干净数据上性能相当但鲁棒性显著较差；物理可实现信号空间扰动比无约束特征空间攻击成功率低；对抗训练能提高平均鲁棒准确率，仅对干净性能造成适度下降。

Conclusion: 研究结果为鲁棒性估计提供了量化基准，并为设计安全可信的人类中心感知系统提供了指导原则，强调在无线感知向可靠跨域操作发展时需要考虑鲁棒性设计。

Abstract: Machine learning has become integral to Channel State Information (CSI)-based human sensing systems and is expected to power applications such as device-free activity recognition and identity detection in future cellular and Wi-Fi generations. However, these systems rely on models whose decisions can be subtly perturbed, raising concerns for security and reliability in ubiquitous sensing. Quantifying and understanding the robustness of such models, defined as their ability to maintain accurate predictions under adversarial perturbations, is therefore critical before wireless sensing can be safely deployed in real-world environments.
  This work presents a systematic evaluation of the robustness of CSI deep learning models under diverse threat models (white-box, black-box/transfer, and universal perturbations) and varying degrees of attack realism. We establish a framework to compare compact temporal autoencoder models with larger deep architectures across three public datasets, quantifying how model scale, training regime, and physical constraints influence robustness. Our experiments show that smaller models, while efficient and equally performant on clean data, are markedly less robust. We further confirm that physically realizable signal-space perturbations, designed to be feasible in real wireless channels, significantly reduce attack success compared to unconstrained feature-space attacks. Adversarial training mitigates these vulnerabilities, improving mean robust accuracy with only moderate degradation in clean performance across both model classes. As wireless sensing advances towards reliable, cross-domain operation, these findings provide quantitative baselines for robustness estimation and inform design principles for secure and trustworthy human-centered sensing systems.

</details>


### [176] [NVIDIA Nemotron Parse 1.1](https://arxiv.org/abs/2511.20478)
*Kateryna Chumachenko,Amala Sanjay Deshmukh,Jarno Seppanen,Ilia Karmanov,Chia-Chih Chen,Lukas Voegtle,Philipp Fischer,Marek Wawrzos,Saeid Motiian,Roman Ageev,Kedi Wu,Alexandre Milesi,Maryam Moosaei,Krzysztof Pawelec,Padmavathy Subramanian,Mehrzad Samadi,Xin Yu,Celina Dear,Sarah Stoddard,Jenna Diamond,Jesse Oliver,Leanna Chraghchian,Patrick Skelly,Tom Balough,Yao Xu,Jane Polak Scowcroft,Daniel Korzekwa,Darragh Hanley,Sandip Bhaskar,Timo Roman,Karan Sapra,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron-Parse-1.1是一个轻量级文档解析和OCR模型，相比前代在OCR、Markdown格式化、表格解析和图片图表文本提取方面都有改进，支持更长输出序列，采用885M参数的编码器-解码器架构，在公开基准测试中达到竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 提升文档解析和OCR能力，在保持轻量化的同时改进前代模型的功能，为视觉密集文档提供更好的处理能力。

Method: 采用编码器-解码器架构，包含885M参数（其中语言解码器为256M参数），提取文本段的边界框和对应语义类别，支持长输出序列处理。

Result: 在公开基准测试中达到竞争性精度，发布了模型权重、优化的NIM容器和部分训练数据，还提供了速度优化版本Nemotron-Parse-1.1-TC，速度提升20%且质量损失最小。

Conclusion: Nemotron-Parse-1.1是一个强大的轻量级OCR解决方案，在多个文档解析任务上表现出色，并通过发布不同版本满足不同性能需求。

Abstract: We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0. Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown formatting, structured table parsing, and text extraction from pictures, charts, and diagrams. It also supports a longer output sequence length for visually dense documents. As with its predecessor, it extracts bounding boxes of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1 follows an encoder-decoder architecture with 885M parameters, including a compact 256M-parameter language decoder. It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution. We release the model weights publicly on Huggingface, as well as an optimized NIM container, along with a subset of the training data as part of the broader Nemotron-VLM-v2 dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a reduced vision token length, offering a 20% speed improvement with minimal quality degradation.

</details>


### [177] [Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders](https://arxiv.org/abs/2511.20480)
*Sidahmed Benabderrahmane,James Cheney,Talal Rahwan*

Main category: cs.LG

TL;DR: 提出了一种基于自动编码器和主动学习的无监督异常检测方法，用于检测高级持续性威胁(APTs)，在数据极度不平衡的情况下显著提高了检测率。


<details>
  <summary>Details</summary>
Motivation: 解决网络安全中APT检测面临的挑战：传统监督学习方法需要大量标注数据，而真实环境中APT攻击样本极其稀少（仅占0.004%），标注成本高且数据不平衡。

Method: 采用注意力对抗双自动编码器框架进行无监督异常检测，结合主动学习机制，通过选择性查询不确定样本的标签来迭代改进模型，减少标注需求。

Result: 在DARPA透明计算项目的真实溯源跟踪数据集上评估，涵盖Android、Linux、BSD和Windows系统，结果显示主动学习过程中检测率显著提升，性能优于现有方法。

Conclusion: 所提出的框架能够以最小标注成本有效检测APT异常，在数据极度不平衡的现实网络安全环境中具有实用价值。

Abstract: Advanced Persistent Threats (APTs) pose a significant challenge in cybersecurity due to their stealthy and long-term nature. Modern supervised learning methods require extensive labeled data, which is often scarce in real-world cybersecurity environments. In this paper, we propose an innovative approach that leverages AutoEncoders for unsupervised anomaly detection, augmented by active learning to iteratively improve the detection of APT anomalies. By selectively querying an oracle for labels on uncertain or ambiguous samples, we minimize labeling costs while improving detection rates, enabling the model to improve its detection accuracy with minimal data while reducing the need for extensive manual labeling. We provide a detailed formulation of the proposed Attention Adversarial Dual AutoEncoder-based anomaly detection framework and show how the active learning loop iteratively enhances the model. The framework is evaluated on real-world imbalanced provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The results have shown significant improvements in detection rates during active learning and better performance compared to other existing approaches.

</details>


### [178] [MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology](https://arxiv.org/abs/2511.20490)
*Kiril Vasilev,Alexandre Misrahi,Eeshaan Jain,Phil F Cheng,Petros Liakopoulos,Olivier Michielin,Michael Moor,Charlotte Bunne*

Main category: cs.LG

TL;DR: MTBBench是一个模拟分子肿瘤委员会决策的基准测试，评估多模态大语言模型在临床肿瘤学中的多模态、纵向推理能力，发现现有模型存在幻觉、时间推理困难等问题，并提供增强框架提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型评估主要关注单模态、去语境化问答，无法反映真实临床工作流程的复杂性，特别是分子肿瘤委员会中需要整合异质数据和随时间演变的洞察的决策环境。

Method: 开发MTBBench基准测试，模拟分子肿瘤委员会决策过程，包含临床挑战性、多模态和纵向肿瘤学问题，并通过临床医生验证的真实标注。

Result: 基准测试显示，即使在大规模模型下，多模态大语言模型仍缺乏可靠性，经常产生幻觉，难以从时间分辨数据中推理，无法调和冲突证据或不同模态。

Conclusion: MTBBench为推进多模态大语言模型在精准肿瘤学中的推理、可靠性和工具使用提供了具有挑战性和现实性的测试平台，其增强框架可分别提升任务性能9.0%和11.2%。

Abstract: Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.

</details>


### [179] [From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection](https://arxiv.org/abs/2511.20500)
*Sidahmed Benabderrahmane,Talal Rahwan*

Main category: cs.LG

TL;DR: 提出了一种混合迁移框架，结合迁移学习、可解释AI、对比学习和Siamese网络，用于改进APT检测的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习检测器在处理APT时面临类别不平衡、高维特征和真实世界痕迹稀缺的问题，且在跨域场景中泛化能力差。

Method: 使用基于注意力的自编码器支持跨域知识迁移，SHAP选择稳定特征降低维度，Siamese编码器通过对比学习对齐源域和目标域表示。

Result: 在DARPA透明计算项目的真实世界痕迹和合成攻击场景上评估，相比经典和深度基线方法，检测分数显著提升。

Conclusion: 该方法为APT检测提供了可扩展、可解释且可迁移的解决方案。

Abstract: Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to their stealth, persistence, and adaptability. Traditional machine learning detectors struggle with class imbalance, high dimensional features, and scarce real world traces. They often lack transferability-performing well in the training domain but degrading in novel attack scenarios. We propose a hybrid transfer framework that integrates Transfer Learning, Explainable AI (XAI), contrastive learning, and Siamese networks to improve cross-domain generalization. An attention-based autoencoder supports knowledge transfer across domains, while Shapley Additive exPlanations (SHAP) select stable, informative features to reduce dimensionality and computational cost. A Siamese encoder trained with a contrastive objective aligns source and target representations, increasing anomaly separability and mitigating feature drift. We evaluate on real-world traces from the DARPA Transparent Computing (TC) program and augment with synthetic attack scenarios to test robustness. Across source to target transfers, the approach delivers improved detection scores with classical and deep baselines, demonstrating a scalable, explainable, and transferable solution for APT detection.

</details>


### [180] [DP-MicroAdam: Private and Frugal Algorithm for Training and Fine-tuning](https://arxiv.org/abs/2511.20509)
*Mihaela Hudişteanu,Edwige Cyffers,Nikita P. Kalinin*

Main category: cs.LG

TL;DR: 提出了DP-MicroAdam，一种内存高效且支持稀疏性的自适应差分隐私优化器，在多个基准测试中优于现有自适应DP优化器，并与DP-SGD竞争或更优。


<details>
  <summary>Details</summary>
Motivation: 自适应优化器在非隐私训练中是标准选择，能实现更快收敛和更好性能，但差分隐私训练仍主要使用DP-SGD，需要大量计算和超参数调优。

Method: 开发DP-MicroAdam优化器，具有内存效率和稀疏感知特性，在随机非凸优化中证明以最优速率收敛。

Result: 在CIFAR-10、大规模ImageNet训练和预训练transformer的私有微调等基准测试中，DP-MicroAdam优于现有自适应DP优化器，与DP-SGD竞争或更优。

Conclusion: 自适应优化可以在差分隐私下同时提高性能和稳定性。

Abstract: Adaptive optimizers are the de facto standard in non-private training as they often enable faster convergence and improved performance. In contrast, differentially private (DP) training is still predominantly performed with DP-SGD, typically requiring extensive compute and hyperparameter tuning. We propose DP-MicroAdam, a memory-efficient and sparsity-aware adaptive DP optimizer. We prove that DP-MicroAdam converges in stochastic non-convex optimization at the optimal $\mathcal{O}(1/\sqrt{T})$ rate, up to privacy-dependent constants. Empirically, DP-MicroAdam outperforms existing adaptive DP optimizers and achieves competitive or superior accuracy compared to DP-SGD across a range of benchmarks, including CIFAR-10, large-scale ImageNet training, and private fine-tuning of pretrained transformers. These results demonstrate that adaptive optimization can improve both performance and stability under differential privacy.

</details>


### [181] [Adam Simplified: Bias Correction Simplified](https://arxiv.org/abs/2511.20516)
*Sam Laing,Antonio Orvieto*

Main category: cs.LG

TL;DR: 该论文通过系统实验证明Adam优化器中的偏差校正组件在最优超参数配置下对最终测试性能没有改善，有时甚至有害，挑战了该组件必须包含的传统观点。


<details>
  <summary>Details</summary>
Motivation: 研究Adam优化器中偏差校正组件的实际必要性，因为该组件的作用长期以来被误解且缺乏深入理解。

Method: 在视觉和语言建模任务上进行系统消融实验，分析偏差校正在不同超参数配置下的影响，并将其重新解释为一种隐式学习率调度机制。

Result: 在最优超参数配置下，包含偏差校正不会改善最终测试性能；除非实施适当的学习率调度，否则偏差校正有时会损害性能。

Conclusion: 偏差校正不应被普遍包含在Adam优化器中，其效果高度依赖于平滑超参数β₁和β₂的选择，实际上是一种隐式学习率调度形式。

Abstract: The Adam optimizer is a cornerstone of modern deep learning, yet the empirical necessity of each of its individual components is often taken for granted. This paper presents a focused investigation into the role of bias-correction, a feature whose contribution remains poorly understood. Through a series of systematic ablations on vision and language modelling tasks, we demonstrate that the conventional wisdom surrounding bias correction is misleading. In particular, we demonstrate that in the optimal hyper-parameter configuration, the inclusion of bias correction leads to no improvement in final test performance. Moreover, unless appropriate learning rate scheduling is implemented, the inclusion of bias correction can sometimes be detrimental to performance. We further reinterpret bias correction as a form of implicit learning rate scheduling whose behaviour is strongly dependent on the choice of smoothing hyper-parameters $β_1, β_2 \in [0,1)$. Our findings challenge the universal inclusion of this component.

</details>


### [182] [Feature-Modulated UFNO for Improved Prediction of Multiphase Flow in Porous Media](https://arxiv.org/abs/2511.20543)
*Alhasan Abdellatif,Hannah P. Menke,Ahmed H. Elsheikh,Florian Doster,Kamaljit Singh*

Main category: cs.LG

TL;DR: UFNO-FiLM通过引入FiLM层解耦标量输入和空间特征，并使用空间加权损失函数，在保持高精度预测的同时显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: UFNO在处理标量输入时效率低下，将其作为空间分布场处理导致频域中出现冗余常数信号，且标准损失函数未考虑误差敏感性的空间变化。

Method: 1. 使用FiLM层解耦标量输入与空间特征，避免常数信号进入傅里叶变换；2. 采用空间加权损失函数，优先学习关键区域。

Result: 在地下多相流实验中，相比UFNO，气体饱和度平均绝对误差降低了21%。

Conclusion: UFNO-FiLM通过解耦标量输入和空间加权损失，显著提升了预测精度和计算效率。

Abstract: The UNet-enhanced Fourier Neural Operator (UFNO) extends the Fourier Neural Operator (FNO) by incorporating a parallel UNet pathway, enabling the retention of both high- and low-frequency components. While UFNO improves predictive accuracy over FNO, it inefficiently treats scalar inputs (e.g., temperature, injection rate) as spatially distributed fields by duplicating their values across the domain. This forces the model to process redundant constant signals within the frequency domain. Additionally, its standard loss function does not account for spatial variations in error sensitivity, limiting performance in regions of high physical importance. We introduce UFNO-FiLM, an enhanced architecture that incorporates two key innovations. First, we decouple scalar inputs from spatial features using a Feature-wise Linear Modulation (FiLM) layer, allowing the model to modulate spatial feature maps without introducing constant signals into the Fourier transform. Second, we employ a spatially weighted loss function that prioritizes learning in critical regions. Our experiments on subsurface multiphase flow demonstrate a 21\% reduction in gas saturation Mean Absolute Error (MAE) compared to UFNO, highlighting the effectiveness of our approach in improving predictive accuracy.

</details>


### [183] [E2E-GRec: An End-to-End Joint Training Framework for Graph Neural Networks and Recommender Systems](https://arxiv.org/abs/2511.20564)
*Rui Xue,Shichao Zhu,Liang Qin,Guangmou Pan,Yang Song,Tianfu Wu*

Main category: cs.LG

TL;DR: 提出E2E-GRec端到端训练框架，统一GNN训练与推荐系统，解决传统两阶段方法计算开销大和缺乏联合优化的问题。


<details>
  <summary>Details</summary>
Motivation: 传统工业部署采用两阶段流水线：GNN离线预训练生成节点嵌入，然后作为静态特征用于下游推荐系统。这种解耦范式导致两个关键限制：高计算开销和缺乏联合优化。

Method: 包含三个关键组件：(i)从大规模跨域异质图高效子图采样；(ii)图特征自动编码器作为辅助自监督任务；(iii)两级特征融合机制结合基于Gradnorm的动态损失平衡。

Result: 离线评估、在线A/B测试（如停留时长相对提升0.133%，用户跳过视频数量减少0.3171%）和理论分析表明，E2E-GRec在多个推荐指标上显著优于传统方法。

Conclusion: E2E-GRec框架通过端到端训练统一GNN与推荐系统，实现了更好的性能和效率。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for modeling graph-structured data and have been widely used in recommender systems, such as for capturing complex user-item and item-item relations. However, most industrial deployments adopt a two-stage pipeline: GNNs are first pre-trained offline to generate node embeddings, which are then used as static features for downstream recommender systems. This decoupled paradigm leads to two key limitations: (1) high computational overhead, since large-scale GNN inference must be repeatedly executed to refresh embeddings; and (2) lack of joint optimization, as the gradient from the recommender system cannot directly influence the GNN learning process, causing the GNN to be suboptimally informative for the recommendation task. In this paper, we propose E2E-GRec, a novel end-to-end training framework that unifies GNN training with the recommender system. Our framework is characterized by three key components: (i) efficient subgraph sampling from a large-scale cross-domain heterogeneous graph to ensure training scalability and efficiency; (ii) a Graph Feature Auto-Encoder (GFAE) serving as an auxiliary self-supervised task to guide the GNN to learn structurally meaningful embeddings; and (iii) a two-level feature fusion mechanism combined with Gradnorm-based dynamic loss balancing, which stabilizes graph-aware multi-task end-to-end training. Extensive offline evaluations, online A/B tests (e.g., a +0.133% relative improvement in stay duration, a 0.3171% reduction in the average number of videos a user skips) on large-scale production data, together with theoretical analysis, demonstrate that E2E-GRec consistently surpasses traditional approaches, yielding significant gains across multiple recommendation metrics.

</details>


### [184] [MSTN: Fast and Efficient Multivariate Time Series Model](https://arxiv.org/abs/2511.20577)
*Sumit S Shevtekar,Chandresh K Maurya,Gourab Sil*

Main category: cs.LG

TL;DR: MSTN是一种多尺度时序网络，通过分层多尺度架构和序列建模，自适应地建模从毫秒级到长期依赖的完整时序变化谱，在多个时序任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界时序数据具有高度非平稳性和复杂的多尺度动态特性，现有模型依赖固定尺度的结构先验，导致对时序动态的过度正则化，限制了它们对完整时序变化谱的自适应建模能力。

Method: 提出多尺度时序网络(MSTN)，包含：(i)多尺度卷积编码器构建分层特征金字塔；(ii)序列建模组件处理长期时序依赖；(iii)门控融合机制结合SE和多头时序注意力实现动态特征集成。

Result: 在时序长期预测、插值、分类和泛化性研究中，MSTN在32个基准数据集中的24个上建立了新的SOTA性能，优于EMTSF、LLM4TS、HiMTM等当代方法。

Conclusion: MSTN通过统一框架自适应建模多尺度时序模式，在多样化时序任务中展现出持续优异的性能，为未来架构发展奠定了灵活基础。

Abstract: Real-world time-series data is highly non stationary and complex in dynamics that operate across multiple timescales, ranging from fast, short-term changes to slow, long-term trends. Most existing models rely on fixed-scale structural priors, such as patch-based tokenization, fixed frequency transformations, or frozen backbone architectures. This often leads to over-regularization of temporal dynamics, which limits their ability to adaptively model the full spectrum of temporal variations and impairs their performance on unpredictable, Sudden, high-magnitude events. To address this, we introduce the Multi-scale Temporal Network (MSTN), a novel deep learning architecture founded on a hierarchical multi-scale and sequence modeling principle. The MSTN framework integrates: (i) a multi-scale convolutional encoder that constructs a hierarchical feature pyramid for local patterns (ii) a sequence modeling component for long-range temporal dependencies. We empirically validate this with BiLSTM and Transformer variants, establishing a flexible foundation for future architectural advancements. and (iii) a gated fusion mechanism augmented with squeeze-and-excitation (SE) and multi-head temporal attention (MHTA) for dynamic, context-aware feature integration. This design enables MSTN to adaptively model temporal patterns from milliseconds to long-range dependencies within a unified framework. Extensive evaluations across time-series long-horizon forecasting, imputation, classification and generalizability study demonstrate that MSTN achieves competitive state-of-the-art (SOTA) performance, showing improvements over contemporary approaches including EMTSF, LLM4TS, HiMTM, TIME-LLM, MTST, SOFTS, iTransformer, TimesNet, and PatchTST. In total, MSTN establishes new SOTA performance on 24 of 32 benchmark datasets, demonstrating its consistent performance across diverse temporal tasks.

</details>


### [185] [A Tale of Two Geometries: Adaptive Optimizers and Non-Euclidean Descent](https://arxiv.org/abs/2511.20584)
*Shuo Xie,Tianhao Wang,Beining Wu,Zhiyuan Li*

Main category: cs.LG

TL;DR: 该论文揭示了自适应优化器与归一化最速下降(NSD)之间的紧密联系，并建立了自适应平滑性理论来分析自适应优化器的收敛性。在凸和非凸设置下，自适应平滑性都能精确描述自适应优化器的收敛行为，并在某些非欧几何下实现标准平滑性无法达到的加速效果。


<details>
  <summary>Details</summary>
Motivation: 自适应优化器在仅适应当前梯度时会退化为归一化最速下降，这表明两者之间存在密切联系。但现有分析依赖于不同的几何概念（平滑性条件），需要建立统一的理论框架来理解它们的收敛特性。

Method: 将自适应平滑性理论扩展到非凸设置，证明其能精确描述自适应优化器的收敛性。在凸设置下，结合Nesterov动量实现加速。同时引入自适应梯度方差概念，在随机优化中建立类似的分析框架。

Result: 自适应平滑性能够精确刻画自适应优化器的收敛行为，在某些非欧几何下实现标准平滑性无法达到的加速效果。自适应梯度方差为随机优化提供了维度无关的收敛保证。

Conclusion: 自适应平滑性为分析自适应优化器提供了统一的理论框架，揭示了其在非欧几何下的独特优势。该理论不仅适用于凸优化，也扩展到非凸和随机优化设置，为理解自适应优化算法的收敛特性提供了新的视角。

Abstract: Adaptive optimizers can reduce to normalized steepest descent (NSD) when only adapting to the current gradient, suggesting a close connection between the two algorithmic families. A key distinction between their analyses, however, lies in the geometries, e.g., smoothness notions, they rely on. In the convex setting, adaptive optimizers are governed by a stronger adaptive smoothness condition, while NSD relies on the standard notion of smoothness. We extend the theory of adaptive smoothness to the nonconvex setting and show that it precisely characterizes the convergence of adaptive optimizers. Moreover, we establish that adaptive smoothness enables acceleration of adaptive optimizers with Nesterov momentum in the convex setting, a guarantee unattainable under standard smoothness for certain non-Euclidean geometry. We further develop an analogous comparison for stochastic optimization by introducing adaptive gradient variance, which parallels adaptive smoothness and leads to dimension-free convergence guarantees that cannot be achieved under standard gradient variance for certain non-Euclidean geometry.

</details>


### [186] [Anatomica: Localized Control over Geometric and Topological Properties for Anatomical Diffusion Models](https://arxiv.org/abs/2511.20587)
*Karim Kadry,Abdallah Abdelwahed,Shoaib Goraya,Ajay Manicka,Naravich Chutisilp,Farhad Nezami,Elazer Edelman*

Main category: cs.LG

TL;DR: Anatomica是一个推理时框架，用于生成具有局部几何拓扑控制的多类解剖体素图，通过立方体控制域和可微分惩罚函数实现解剖结构的几何和拓扑特征控制。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够灵活控制解剖结构几何和拓扑特征的框架，用于合成数据集的理性设计，支持虚拟试验和机器学习工作流程。

Method: 使用不同维度、位置和形状的立方体控制域切片相关子结构，通过体素矩控制几何特征（大小、形状、位置），通过持久同调控制拓扑特征（连通分量、环、空洞），在潜在扩散模型中实现神经场解码器部分提取子结构。

Result: Anatomica能够灵活应用于各种解剖系统，在任意维度和坐标系下组合约束来控制复杂结构。

Conclusion: 该框架实现了解剖体素图的理性设计，为虚拟试验和机器学习工作流程提供了有效的合成数据生成工具。

Abstract: We present Anatomica: an inference-time framework for generating multi-class anatomical voxel maps with localized geo-topological control. During generation, we use cuboidal control domains of varying dimensionality, location, and shape to slice out relevant substructures. These local substructures are used to compute differentiable penalty functions that steer the sample towards target constraints. We control geometric features such as size, shape, and position through voxel-wise moments, while topological features such as connected components, loops, and voids are enforced through persistent homology. Lastly, we implement Anatomica for latent diffusion models, where neural field decoders partially extract substructures, enabling the efficient control of anatomical properties. Anatomica applies flexibly across diverse anatomical systems, composing constraints to control complex structures over arbitrary dimensions and coordinate systems, thereby enabling the rational design of synthetic datasets for virtual trials or machine learning workflows.

</details>


### [187] [Attention Trajectories as a Diagnostic Axis for Deep Reinforcement Learning](https://arxiv.org/abs/2511.20591)
*Charlotte Beylier,Hannah Selder,Arthur Fleig,Simon M. Hofmann,Nico Scherf*

Main category: cs.LG

TL;DR: 提出了注意力导向指标（ATOMs）来研究强化学习智能体在训练过程中注意力发展，通过三个Pong游戏变体验证了ATOMs能有效区分不同训练条件下的注意力模式和行为差异。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体的学习过程除了数学公式外仍缺乏深入理解，需要工具来研究其注意力发展过程。

Method: 引入ATOMs指标，在三个设计不同的Pong游戏变体上进行控制实验，结合行为评估分析智能体的注意力模式。

Result: ATOMs成功区分了不同游戏变体训练的智能体注意力模式，这些差异转化为行为差异；训练过程中注意力发展呈现阶段性，且各游戏变体间阶段一致。

Conclusion: ATOMs有助于提高对强化学习智能体学习过程的理解，更好地理解注意力与学习之间的关系。

Abstract: The learning process of a reinforcement learning (RL) agent remains poorly understood beyond the mathematical formulation of its learning algorithm. To address this gap, we introduce attention-oriented metrics (ATOMs) to investigate the development of an RL agent's attention during training. In a controlled experiment, we tested ATOMs on three variations of a Pong game, each designed to teach the agent distinct behaviours, complemented by a behavioural assessment. ATOMs successfully delineate the attention patterns of an agent trained on each game variation, and that these differences in attention patterns translate into differences in the agent's behaviour. Through continuous monitoring of ATOMs during training, we observed that the agent's attention developed in phases, and that these phases were consistent across game variations. Overall, we believe that ATOM could help improve our understanding of the learning processes of RL agents and better understand the relationship between attention and learning.

</details>


### [188] [Latent Diffusion Inversion Requires Understanding the Latent Space](https://arxiv.org/abs/2511.20592)
*Mingxing Rao,Bowen Qu,Daniel Moyer*

Main category: cs.LG

TL;DR: 本文研究了潜在扩散模型中的记忆效应，发现扩散模型在潜在代码上表现出不均匀的记忆化，倾向于过拟合解码器回拉度量中高失真区域的样本。作者提出了一种基于维度的记忆化分析方法，通过移除较少记忆化的维度来显著提升成员推理攻击性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型反转技术主要关注数据域的扩散模型，而忽略了潜在空间生成模型（如潜在扩散模型）中的编码器/解码器对和相应潜在代码的作用。本文旨在探索潜在扩散模型中记忆化的非均匀特性及其对隐私风险的影响。

Method: 提出了一种原则性方法来按维度对解码器回拉度量的贡献进行排序，识别对记忆化最负责的维度。在计算基于分数的成员推理攻击统计量时，移除较少记忆化的维度。

Result: 实验表明，该方法在多个数据集（CIFAR-10、CelebA、ImageNet-1K、Pokémon、MS-COCO、Flickr）上显著提升了成员推理攻击性能，平均AUROC增益达2.7%，TPR@1%FPR大幅增加6.42%。

Conclusion: 研究结果强调了自编码器几何结构对潜在扩散模型记忆化的被忽视影响，为分析基于扩散的生成模型的隐私风险提供了新视角。

Abstract: The recovery of training data from generative models (``model inversion'') has been extensively studied for diffusion models in the data domain. The encoder/decoder pair and corresponding latent codes have largely been ignored by inversion techniques applied to latent space generative models, e.g., Latent Diffusion models (LDMs). In this work we describe two key findings: (1) The diffusion model exhibits non-uniform memorization across latent codes, tending to overfit samples located in high-distortion regions of the decoder pullback metric. (2) Even within a single latent code, different dimensions contribute unequally to memorization. We introduce a principled method to rank latent dimensions by their per-dimensional contribution to the decoder pullback metric, identifying those most responsible for memorization. Empirically, removing less-memorizing dimensions when computing attack statistics for score-based membership inference attacker significantly improves performance, with average AUROC gains of 2.7\% and substantial increases in TPR@1\%FPR (6.42\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K, Pokémon, MS-COCO, and Flickr. This indicates stronger confidence in identifying members under extremely low false-positive tolerance. Our results highlight the overlooked influence of the auto-encoder geometry on LDM memorization and provide a new perspective for analyzing privacy risks in diffusion-based generative models.

</details>


### [189] [BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents](https://arxiv.org/abs/2511.20597)
*Kaiyuan Zhang,Mark Tenenholtz,Kyle Polley,Jerry Ma,Denis Yarats,Ninghui Li*

Main category: cs.LG

TL;DR: 本研究分析了AI网络代理中的提示注入攻击，创建了包含真实HTML负载的攻击基准，并评估了现有防御措施的有效性，提出了多层防御策略。


<details>
  <summary>Details</summary>
Motivation: AI代理集成到网络浏览器带来了超越传统网络应用威胁模型的安全挑战，特别是提示注入攻击在真实环境中的影响尚未得到充分理解。

Method: 构建了嵌入在真实HTML负载中的提示注入攻击基准，强调影响实际行为而非仅文本输出的攻击，并对前沿AI模型进行了全面的防御措施实证评估。

Result: 开发了一个复杂度和干扰频率与真实环境相似的攻击基准，评估了现有防御措施的效果，并提出了包含架构和模型防御的多层防御策略。

Conclusion: 通过纵深防御方法为设计实用、安全的网络代理提供了蓝图，能够有效应对不断演变的提示注入攻击。

Abstract: The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.
  In this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes beyond prior work by emphasizing injections that can influence real-world actions rather than mere text outputs, and by presenting attack payloads with complexity and distractor frequency similar to what real-world agents encounter. We leverage this benchmark to conduct a comprehensive empirical evaluation of existing defenses, assessing their effectiveness across a suite of frontier AI models. We propose a multi-layered defense strategy comprising both architectural and model-based defenses to protect against evolving prompt injection attacks. Our work offers a blueprint for designing practical, secure web agents through a defense-in-depth approach.

</details>


### [190] [The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting](https://arxiv.org/abs/2511.20601)
*Heman Shakeri*

Main category: cs.LG

TL;DR: 血糖预测的深度序列模型未能有效利用胰岛素、饮食和活动等临床驱动因素，这种现象被称为"驱动因素盲视"，表现为多变量模型相比单变量基线的性能增益Δ_drivers接近零。


<details>
  <summary>Details</summary>
Motivation: 尽管血糖生理机制已被充分理解，但现有深度序列模型未能有效整合临床驱动因素（胰岛素、饮食、活动），导致模型性能受限。

Method: 提出Δ_drivers指标量化驱动因素盲视问题，分析三个根本原因：架构偏置（C1）、数据保真度差距（C2）和生理异质性（C3），并综合生理特征编码器、因果正则化和个性化等缓解策略。

Result: 文献综述显示Δ_drivers通常接近零，表明当前模型未能有效利用驱动因素信息。

Conclusion: 建议未来研究常规报告Δ_drivers指标，防止驱动因素盲视的模型被视为最先进技术，并推荐采用生理特征编码、因果正则化和个性化等策略来缓解该问题。

Abstract: Deep sequence models for blood glucose forecasting consistently fail to leverage clinically informative drivers--insulin, meals, and activity--despite well-understood physiological mechanisms. We term this Driver-Blindness and formalize it via $Δ_{\text{drivers}}$, the performance gain of multivariate models over matched univariate baselines. Across the literature, $Δ_{\text{drivers}}$ is typically near zero. We attribute this to three interacting factors: architectural biases favoring autocorrelation (C1), data fidelity gaps that render drivers noisy and confounded (C2), and physiological heterogeneity that undermines population-level models (C3). We synthesize strategies that partially mitigate Driver-Blindness--including physiological feature encoders, causal regularization, and personalization--and recommend that future work routinely report $Δ_{\text{drivers}}$ to prevent driver-blind models from being considered state-of-the-art.

</details>


### [191] [How to Purchase Labels? A Cost-Effective Approach Using Active Learning Markets](https://arxiv.org/abs/2511.20605)
*Xiwen Huang,Pierre Pinson*

Main category: cs.LG

TL;DR: 提出主动学习市场来购买标签，通过优化问题整合预算约束和改进阈值，在房地产定价和能源预测领域验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要购买特征和样本，但在模型拟合和预测分析应用中，购买标签能更有效地提升模型性能，特别是在资源受限环境下。

Method: 采用单买家多卖家设置，结合两种主动学习策略（基于方差和查询委员会）与不同定价机制，并与随机采样基准进行比较。

Result: 在真实数据集上验证，相比传统方法，能以更少的标签获得更优的性能表现。

Conclusion: 该方法为资源受限环境下的数据采集优化提供了易于实现的实用解决方案。

Abstract: We introduce and analyse active learning markets as a way to purchase labels, in situations where analysts aim to acquire additional data to improve model fitting, or to better train models for predictive analytics applications. This comes in contrast to the many proposals that already exist to purchase features and examples. By originally formalising the market clearing as an optimisation problem, we integrate budget constraints and improvement thresholds into the label acquisition process. We focus on a single-buyer-multiple-seller setup and propose the use of two active learning strategies (variance based and query-by-committee based), paired with distinct pricing mechanisms. They are compared to a benchmark random sampling approach. The proposed strategies are validated on real-world datasets from two critical application domains: real estate pricing and energy forecasting. Results demonstrate the robustness of our approach, consistently achieving superior performance with fewer labels acquired compared to conventional methods. Our proposal comprises an easy-to-implement practical solution for optimising data acquisition in resource-constrained environments.

</details>


### [192] [Adaptive Hopfield Network: Rethinking Similarities in Associative Memory](https://arxiv.org/abs/2511.20609)
*Shurong Wang,Yuqi Pan,Zhuoyang Shen,Meng Zhang,Hongwei Wang,Guoqi Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的关联记忆模型，通过定义变体分布和自适应相似度机制，解决了现有模型无法保证检索正确性的问题，并在多种任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有关联记忆模型基于邻近度评估检索质量，无法保证检索到的模式与查询具有最强的关联性，存在正确性问题。

Method: 提出变体分布建模查询的生成过程，开发自适应相似度机制来近似存储模式生成查询的可能性，并集成到自适应Hopfield网络(A-Hop)中。

Result: 理论证明在噪声、掩码和偏差三种典型变体类型下实现最优正确检索，实验结果显示在记忆检索、表格分类、图像分类和多实例学习等任务中达到最先进性能。

Conclusion: 通过变体分布和自适应相似度机制，关联记忆模型能够实现正确的检索，为生物智能提供更准确的建模方法。

Abstract: Associative memory models are content-addressable memory systems fundamental to biological intelligence and are notable for their high interpretability. However, existing models evaluate the quality of retrieval based on proximity, which cannot guarantee that the retrieved pattern has the strongest association with the query, failing correctness. We reframe this problem by proposing that a query is a generative variant of a stored memory pattern, and define a variant distribution to model this subtle context-dependent generative process. Consequently, correct retrieval should return the memory pattern with the maximum a posteriori probability of being the query's origin. This perspective reveals that an ideal similarity measure should approximate the likelihood of each stored pattern generating the query in accordance with variant distribution, which is impossible for fixed and pre-defined similarities used by existing associative memories. To this end, we develop adaptive similarity, a novel mechanism that learns to approximate this insightful but unknown likelihood from samples drawn from context, aiming for correct retrieval. We theoretically prove that our proposed adaptive similarity achieves optimal correct retrieval under three canonical and widely applicable types of variants: noisy, masked, and biased. We integrate this mechanism into a novel adaptive Hopfield network (A-Hop), and empirical results show that it achieves state-of-the-art performance across diverse tasks, including memory retrieval, tabular classification, image classification, and multiple instance learning.

</details>


### [193] [Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition](https://arxiv.org/abs/2511.20612)
*Yujin Kim,Sarah Dean*

Main category: cs.LG

TL;DR: 提出了Stochastic NODE-DMD方法，将动态模式分解(DMD)扩展为概率模型，能够处理稀疏/噪声观测、非线性动态并提供不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现实世界动态系统（如风场、洋流）难以建模，传统DMD方法受限于稀疏/噪声观测、线性近似和缺乏不确定性量化。

Method: Stochastic NODE-DMD是DMD的概率扩展，建模连续时间非线性动态，保持可解释性，支持任意坐标的连续时空重建。

Result: 在四个基准测试中，仅使用10%观测密度时重建精度优于基线，恢复动态结构，学习校准的潜在动态分布。

Conclusion: 该方法成功解决了传统DMD的局限性，在稀疏观测下仍能准确重建并量化不确定性。

Abstract: Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: https://github.com/sedan-group/Stochastic-NODE-DMD

</details>


### [194] [Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning](https://arxiv.org/abs/2511.20613)
*Panayiotis Danassis,Naman Goel*

Main category: cs.LG

TL;DR: 本文提出了一个基于真实世界物流优化问题的多智能体推理驱动基准测试，评估LLM在复杂规划、优化和战略交互任务中的代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的代码生成基准测试主要关注单元测试通过率和语法正确性，低估了需要规划、优化和战略交互的真实世界问题的难度。

Method: 引入基于拍卖、取货和配送问题的多智能体推理驱动基准，评估40个LLM编码的智能体与17个人类编码智能体的性能，通过12个双循环锦标赛和约40,000场比赛进行对比。

Result: 人类编码智能体明显优于LLM编码智能体：前5名始终由人类编码智能体占据；33个LLM编码智能体被非常简单的基线击败；即使提供最佳人类解决方案，LLM也无法改进反而使其变差。

Conclusion: LLM在生成能够在真实世界中竞争性工作的代码方面存在能力差距，需要新的评估方法来强调真实世界场景中的推理驱动代码合成。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 human-coded agents developed before the advent of LLMs. Our results over 12 double all-play-all tournaments and $\sim 40$k matches demonstrate (i) a clear superiority of human(graduate students)-coded agents: the top 5 spots are consistently won by human-coded agents, (ii) the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code that works competitively in the real-world, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.

</details>


### [195] [DiFR: Inference Verification Despite Nondeterminism](https://arxiv.org/abs/2511.20621)
*Adam Karvonen,Daniel Reuter,Roy Rinberg,Luke Marks,Adrià Garriga-Alonso,Keri Warr*

Main category: cs.LG

TL;DR: Token-DiFR是一种通过比较生成token与可信参考实现预测来验证LLM推理输出的方法，使用采样种子同步约束有效输出，能以零额外成本检测推理错误。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推理需求增长，需要验证推理过程是否正确执行且未被篡改，但由于数值噪声导致重复推理结果不同，难以区分合法变化与实际问题。

Method: 使用采样种子同步技术，将生成token与可信参考实现在相同随机种子下的预测进行比较；同时提出Activation-DiFR方法，使用随机正交投影压缩激活值为紧凑指纹进行验证。

Result: Token-DiFR能可靠识别采样错误、模拟bug和模型量化，在300个输出token内检测4位量化的AUC>0.999；Activation-DiFR仅用2个输出token就能检测4位量化，通信开销比现有方法减少25-75%。

Conclusion: 提出的方法能有效验证LLM推理正确性，Token-DiFR以零成本提供可审计证据，Activation-DiFR在样本效率验证方面表现优异，已开源集成vLLM以加速可验证推理部署。

Abstract: As demand for LLM inference grows, it is becoming increasingly important that providers and their customers can verify that inference processes are performed correctly, without errors or tampering. However, re-running the same inference process twice often leads to different results due to benign numerical noise, making it difficult to distinguish legitimate variation from actual problems. To address this problem, we introduce Token-DiFR (Token-Divergence-From-Reference), a method for verifying inference outputs by comparing generated tokens against predictions made by a trusted reference implementation conditioned on the same random seed. Sampling seed synchronization tightly constrains valid outputs, leaving providers minimal room to deviate from correct inference, which allows output tokens themselves to serve as auditable evidence of correctness at zero additional cost to the provider. Token-DiFR reliably identifies sampling errors, simulated bugs, and model quantization, detecting 4-bit quantization with AUC $>$ 0.999 within 300 output tokens. For applications requiring sample-efficient forward-pass verification, we additionally introduce Activation-DiFR, a scheme that uses random orthogonal projections to compress activations into compact fingerprints for subsequent verification. Activation-DiFR detects 4-bit quantization with AUC $>$ 0.999 using just 2 output tokens, while reducing communication overhead by 25-75% relative to existing methods. We release an open-source integration with vLLM to accelerate practical deployment of verifiable inference.

</details>


### [196] [ROOT: Robust Orthogonalized Optimizer for Neural Network Training](https://arxiv.org/abs/2511.20626)
*Wei He,Kai Han,Hang Zhou,Hanting Chen,Zhicheng Liu,Xinghao Chen,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出了ROOT优化器，通过维度鲁棒的正交化方案和优化鲁棒的近端优化框架，解决了现有优化器在正交化精度和异常值噪声方面的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型优化面临挑战，模型规模扩大加剧了对算法精度和训练稳定性的敏感性。现有基于动量正交化的优化器存在维度脆弱性和异常值噪声脆弱性两个关键鲁棒性限制。

Method: 1. 维度鲁棒正交化方案：使用自适应牛顿迭代和针对特定矩阵尺寸的细粒度系数；2. 优化鲁棒框架：通过近端优化抑制异常值噪声，同时保留有意义的梯度方向。

Result: ROOT在鲁棒性方面显著改进，相比Muon和Adam优化器收敛更快且最终性能更优，特别是在噪声和非凸场景中表现突出。

Conclusion: 为开发能够处理现代大规模模型训练复杂性的鲁棒且精确的优化器建立了新范式。

Abstract: The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.

</details>


### [197] [Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model](https://arxiv.org/abs/2511.20636)
*Ziyue Wang,Yayati Jadhav,Peter Pak,Amir Barati Farimani*

Main category: cs.LG

TL;DR: Image2Gcode是一个端到端的数据驱动框架，可直接从图像生成3D打印机的G代码，绕过了传统的CAD建模阶段。


<details>
  <summary>Details</summary>
Motivation: 传统机械设计和制造流程依赖CAD建模，这成为快速原型制作的主要瓶颈，因为构建特定对象的3D几何模型耗时且不利于快速迭代。

Method: 使用去噪扩散概率模型(DDPM)在G代码序列上工作，通过迭代去噪将高斯噪声转换为可执行的打印移动轨迹和挤出参数，直接从视觉输入映射到原生工具路径。

Result: 该框架能够从手绘或捕获的2D图像直接生成结构化的G代码，无需CAD或STL中间文件。

Conclusion: Image2Gcode降低了增材制造的门槛，加速了从设计到制造的周期，支持从简单草图或视觉参考进行按需原型制作。

Abstract: Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.

</details>
