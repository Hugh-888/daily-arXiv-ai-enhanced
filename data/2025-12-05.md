<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 63]
- [quant-ph](#quant-ph) [Total: 42]
- [gr-qc](#gr-qc) [Total: 27]
- [physics.comp-ph](#physics.comp-ph) [Total: 9]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [ASCIIBench: Evaluating Language-Model-Based Understanding of Visually-Oriented Text](https://arxiv.org/abs/2512.04125)
*Kerry Luo,Michael Fu,Joshua Peguero,Husnain Malik,Anvay Patil,Joyce Lin,Megan Van Overborg,Ryan Sarmiento,Kevin Zhu*

Main category: cs.LG

TL;DR: ASCIIBench：首个公开的ASCII艺术基准测试，用于评估LLM在空间位置推理上的局限性，包含5,315个分类标注的ASCII图像数据集和微调CLIP模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和长文本生成方面表现出色，但在需要精确空间和位置推理的任务上仍然存在困难。ASCII艺术作为一种用字符编码结构和形式的符号媒介，为探究这一局限性提供了独特的测试工具。

Method: 1. 构建ASCIIBench基准测试，包含5,315个分类标注的ASCII图像数据集；2. 发布微调后的CLIP模型权重，专门捕捉ASCII结构；3. 使用余弦相似度分析CLIP嵌入在ASCII类别间的区分能力。

Result: 1. 基于CLIP嵌入的余弦相似度在大多数ASCII类别上表现不佳，达到随机水平；2. 内部平均相似度高的类别具有明显可区分性；3. 瓶颈在于表示能力而非生成方差。

Conclusion: ASCII艺术可作为多模态表示的压力测试，揭示了当前嵌入方法在符号视觉模态上的局限性，需要开发专门针对符号视觉模态的新嵌入方法或评估指标。

Abstract: Large language models (LLMs) have demonstrated several emergent behaviors with scale, including reasoning and fluency in long-form text generation. However, they continue to struggle with tasks requiring precise spatial and positional reasoning. ASCII art, a symbolic medium where characters encode structure and form, provides a unique probe of this limitation. We introduce ASCIIBench, a novel benchmark for evaluating both the generation and classification of ASCII-text images. ASCIIBench consists of a filtered dataset of 5,315 class-labeled ASCII images and is, to our knowledge, the first publicly available benchmark of its kind. Alongside the dataset, we release weights for a fine-tuned CLIP model adapted to capture ASCII structure, enabling the evaluation of LLM-generated ASCII art. Our analysis shows that cosine similarity over CLIP embeddings fails to separate most ASCII categories, yielding chance-level performance even for low-variance classes. In contrast, classes with high internal mean similarity exhibit clear discriminability, revealing that the bottleneck lies in representation rather than generational variance. These findings position ASCII art as a stress test for multimodal representations and motivate the development of new embedding methods or evaluation metrics tailored to symbolic visual modalities. All resources are available at https://github.com/ASCIIBench/ASCIIBench.

</details>


### [2] [Decoding Large Language Diffusion Models with Foreseeing Movement](https://arxiv.org/abs/2512.04135)
*Yichuan Mo,Quan Chen,Mingjie Li,Zeming Wei,Yisen Wang*

Main category: cs.LG

TL;DR: 本文提出Foreseeing Decoding Method (FDM)，一种结合局部和全局考虑的搜索策略，解决LLDMs解码顺序敏感性问题，并开发加速变体FDM-A，在关键步骤进行深度探索。


<details>
  <summary>Details</summary>
Motivation: 大型语言扩散模型(LLDMs)具有并行推理和可控生成的灵活解码机制，但这种灵活性导致推理性能对解码顺序高度敏感。现有启发式方法主要关注局部效果而忽略了长期影响。

Method: 提出Foreseeing Decoding Method (FDM)，采用基于搜索的策略，在离散空间中整合局部和全局考虑进行有效优化。通过分析完整解码过程中选定token的一致性，开发了加速变体FDM-A，将深度探索限制在关键步骤。

Result: 在多样化基准测试和模型架构上的广泛实验验证了FDM的可扩展性，并证明FDM-A实现了优越的效率-性能权衡。

Conclusion: FDM为LLDMs提供了更强大的解码方法，可能为更强大的解码方法迈出原则性的一步。

Abstract: Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance becomes highly sensitive to the decoding order of tokens. Existing heuristic methods, however, focus mainly on local effects while overlooking long-term impacts. To address this limitation, we propose the Foreseeing Decoding Method (FDM), a novel approach that integrates both local and global considerations to unlock the full potential, employing a search-based strategy to enable effective optimization in discrete spaces. Furthermore, by analyzing the consistency of chosen tokens in the full decoding process, we develop a variant, FDM with Acceleration (FDM-A), which restricts deep exploration to critical steps identified as the exploration and balance circumantences. Extensive experiments across diverse benchmarks and model architectures validate the scalability of FDM and demonstrate the superior efficiency-performance trade-off achieved by FDM-A. Our work might potentially provide a principled step toward more powerful decoding methods for LLDMs.

</details>


### [3] [MechDetect: Detecting Data-Dependent Errors](https://arxiv.org/abs/2512.04138)
*Philipp Jung,Nicholas Chandler,Sebastian Jäger,Felix Biessmann*

Main category: cs.LG

TL;DR: MechDetect算法通过机器学习模型分析错误生成机制，判断错误是否依赖于数据本身，为数据质量监控提供新视角。


<details>
  <summary>Details</summary>
Motivation: 现有数据质量监控方法主要关注错误检测和漂移识别，但很少研究错误生成的机制。了解错误如何生成对于追踪和修复错误至关重要，这是当前研究的重要空白。

Method: 基于统计学中缺失值研究的现有工作，提出MechDetect算法。给定表格数据集和对应的错误掩码，该算法使用机器学习模型估计错误是否依赖于数据本身。该方法可扩展应用于其他错误类型。

Result: 在标准基准数据集上的实验证明了MechDetect的有效性。该算法能够成功检测错误生成机制，为理解数据错误提供了新的分析工具。

Conclusion: MechDetect为数据质量监控提供了新的视角，通过分析错误生成机制帮助更好地理解和修复数据错误。该方法扩展了现有缺失值分析技术，适用于多种错误类型。

Abstract: Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing how errors were generated can be key to tracing and fixing them. In this study, we build on existing work in the statistics literature on missing values and propose MechDetect, a simple algorithm to investigate error generation mechanisms. Given a tabular data set and a corresponding error mask, the algorithm estimates whether or not the errors depend on the data using machine learning models. Our work extends established approaches to detect mechanisms underlying missing values and can be readily applied to other error types, provided that an error mask is available. We demonstrate the effectiveness of MechDetect in experiments on established benchmark datasets.

</details>


### [4] [Mitigating the Curse of Detail: Scaling Arguments for Feature Learning and Sample Complexity](https://arxiv.org/abs/2512.04165)
*Noa Rubin,Orit Davidovich,Zohar Ringel*

Main category: cs.LG

TL;DR: 提出了一种预测特征学习模式出现的数据和宽度尺度的启发式方法，比精确理论更简单，能复现已知结果的缩放指数，并对复杂架构做出新预测。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习理论中，特征学习机制的解释和丰富机制下网络的隐式偏置是两个紧迫问题。现有理论主要局限于单层或双层可训练层网络或深度线性网络，且预测形式多为需要计算密集型数值解的高维非线性方程，分析复杂度高。

Method: 提出了一种强大的启发式路径，用于预测各种特征学习模式出现的数据和宽度尺度。这种尺度分析形式比精确理论简单得多。

Result: 该方法能够复现各种已知结果的缩放指数，并对三层非线性网络和注意力头等复杂玩具架构做出了新颖预测，从而扩展了深度学习第一性原理理论的范围。

Conclusion: 提出的尺度分析方法为预测特征学习模式的出现提供了更简单有效的途径，扩展了深度学习理论的应用范围，特别是在复杂架构上的预测能力。

Abstract: Two pressing topics in the theory of deep learning are the interpretation of feature learning mechanisms and the determination of implicit bias of networks in the rich regime. Current theories of rich feature learning effects revolve around networks with one or two trainable layers or deep linear networks. Furthermore, even under such limiting settings, predictions often appear in the form of high-dimensional non-linear equations, which require computationally intensive numerical solutions. Given the many details that go into defining a deep learning problem, this analytical complexity is a significant and often unavoidable challenge. Here, we propose a powerful heuristic route for predicting the data and width scales at which various patterns of feature learning emerge. This form of scale analysis is considerably simpler than such exact theories and reproduces the scaling exponents of various known results. In addition, we make novel predictions on complex toy architectures, such as three-layer non-linear networks and attention heads, thus extending the scope of first-principle theories of deep learning.

</details>


### [5] [BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training](https://arxiv.org/abs/2512.04189)
*Luca Colombo,Fabrizio Pittorino,Daniele Zambon,Carlo Baldassi,Manuel Roveri,Cesare Alippi*

Main category: cs.LG

TL;DR: 提出Binary Error Propagation (BEP)算法，首次实现完全二进制的端到端训练，包括前向和反向传播都使用位运算，特别适用于循环神经网络。


<details>
  <summary>Details</summary>
Motivation: 二值神经网络(BNNs)在资源受限设备上有显著优势，但现有训练方法需要维护全精度参数和浮点运算，无法充分利用二进制操作的高效性。现有局部学习规则不适合多层架构的全局信用分配。

Method: 提出Binary Error Propagation (BEP)算法，建立离散的反向传播链式法则，使二进制向量形式的误差信号能在多层网络中反向传播。所有计算都使用二进制变量和位运算。

Result: 在多层感知机和循环神经网络上验证BEP有效性，测试准确率分别提升高达+6.89%和+10.57%。首次实现循环神经网络的端到端二进制训练。

Conclusion: BEP是第一个完全二进制的学习算法，实现了离散的反向传播，特别适用于循环神经网络，为资源受限设备上的高效训练提供了新方案。

Abstract: Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for deployment on resource-constrained devices. However, training BNNs via gradient-based optimization remains challenging due to the discrete nature of their variables. The dominant approach, quantization-aware training, circumvents this issue by employing surrogate gradients. Yet, this method requires maintaining latent full-precision parameters and performing the backward pass with floating-point arithmetic, thereby forfeiting the efficiency of binary operations during training. While alternative approaches based on local learning rules exist, they are unsuitable for global credit assignment and for back-propagating errors in multi-layer architectures. This paper introduces Binary Error Propagation (BEP), the first learning algorithm to establish a principled, discrete analog of the backpropagation chain rule. This mechanism enables error signals, represented as binary vectors, to be propagated backward through multiple layers of a neural network. BEP operates entirely on binary variables, with all forward and backward computations performed using only bitwise operations. Crucially, this makes BEP the first solution to enable end-to-end binary training for recurrent neural network architectures. We validate the effectiveness of BEP on both multi-layer perceptrons and recurrent neural networks, demonstrating gains of up to +6.89% and +10.57% in test accuracy, respectively. The proposed algorithm is released as an open-source repository.

</details>


### [6] [Network of Theseus (like the ship)](https://arxiv.org/abs/2512.04198)
*Vighnesh Subramaniam,Colin Conwell,Boris Katz,Andrei Barbu,Brian Cheung*

Main category: cs.LG

TL;DR: NoT方法允许在训练后逐步将网络架构转换为完全不同的目标架构，同时保持性能，解耦了优化与部署


<details>
  <summary>Details</summary>
Motivation: 深度学习通常假设训练和推理时的网络架构必须一致，这限制了选择具有更好效率或设计特性的架构，因为优化困难。NoT挑战这一假设，允许在训练后改变架构

Method: NoT通过逐步替换指南网络中的组件为目标架构模块，并使用表征相似性度量对齐，实现架构转换。即使进行重大架构改变（如CNN转MLP，GPT-2转RNN），也能保持功能

Result: NoT能够在保持指南网络性能的同时，将网络架构转换为完全不同的目标架构，扩展了可行的推理时架构空间

Conclusion: 通过解耦优化与部署，NoT为更好的精度-效率权衡提供了机会，并支持更直接的架构设计空间探索

Abstract: A standard assumption in deep learning is that the inductive bias introduced by a neural network architecture must persist from training through inference. The architecture you train with is the architecture you deploy. This assumption constrains the community from selecting architectures that may have desirable efficiency or design properties due to difficulties with optimization. We challenge this assumption with Network of Theseus (NoT), a method for progressively converting a trained, or even untrained, guide network architecture part-by-part into an entirely different target network architecture while preserving the performance of the guide network. At each stage, components in the guide network architecture are incrementally replaced with target architecture modules and aligned via representational similarity metrics. This procedure largely preserves the functionality of the guide network even under substantial architectural changes-for example, converting a convolutional network into a multilayer perceptron, or GPT-2 into a recurrent neural network. By decoupling optimization from deployment, NoT expands the space of viable inference-time architectures, opening opportunities for better accuracy-efficiency tradeoffs and enabling more directed exploration of the architectural design space.

</details>


### [7] [ActVAE: Modelling human activity schedules with a deep conditional generative approach](https://arxiv.org/abs/2512.04223)
*Fred Shone,Tim Hillel*

Main category: cs.LG

TL;DR: 提出一种基于条件变分自编码器的深度生成模型，用于根据个体特征标签生成多样化、真实的人类活动日程表。


<details>
  <summary>Details</summary>
Motivation: 人类活动日程安排具有复杂性和多样性，传统建模方法难以准确捕捉这种随机性和差异性。需要一种能够根据个体特征（如年龄、就业状态等）生成多样化、真实日程表的方法。

Method: 提出新颖的条件变分自编码器架构，结合结构化潜在生成方法和条件方法，通过深度条件生成机器学习方法建模活动日程安排。

Result: 模型能够快速生成精确且真实的不同标签对应日程表，具有实际数据和计算要求，可部署到现有需求建模框架中。相比纯生成模型和纯条件模型，该组合方法能更好地建模人类行为的随机性。

Conclusion: 深度生成方法能有效建模复杂多样人类行为的随机性，条件变分自编码器架构在活动日程生成任务中表现出色，具有实际应用价值。

Abstract: Modelling the complexity and diversity of human activity scheduling behaviour is inherently challenging. We demonstrate a deep conditional-generative machine learning approach for the modelling of realistic activity schedules depending on input labels such as an individual's age, employment status, or other information relevant to their scheduling. We combine (i) a structured latent generative approach, with (ii) a conditional approach, through a novel Conditional VAE architecture. This allows for the rapid generation of precise and realistic schedules for different input labels. We extensively evaluate model capabilities using a joint density estimation framework and several case studies. We additionally show that our approach has practical data and computational requirements, and can be deployed within new and existing demand modelling frameworks. We evaluate the importance of generative capability more generally, by comparing our combined approach to (i) a purely generative model without conditionality, and (ii) a purely conditional model which outputs the most likely schedule given the input labels. This comparison highlights the usefulness of explicitly modelling the randomness of complex and diverse human behaviours using deep generative approaches.

</details>


### [8] [Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning](https://arxiv.org/abs/2512.04252)
*Baichuan Zeng*

Main category: cs.LG

TL;DR: 使用基于ChemBERTa的深度学习框架，直接从SMILES字符串预测TDP1抑制剂的pIC50值，在严重活性不平衡的数据集上表现优于传统方法，为药物发现提供高效工具。


<details>
  <summary>Details</summary>
Motivation: TDP1是克服癌症化疗耐药性的关键靶点，但预测小分子对其抑制活性仍是早期药物发现的重要挑战。现有方法在严重活性不平衡（仅2.1%活性化合物）的数据集上表现有限。

Method: 提出基于ChemBERTa预训练化学语言模型的深度学习框架，使用两种预训练策略（MLM和MTR），在包含177,092个化合物的大规模共识数据集上进行微调，采用分层数据划分和样本加权处理活性不平衡问题。

Result: 模型在回归准确性和虚拟筛选效用上优于随机预测器，与随机森林相比具有竞争力，在top-ranked预测中达到EF@1% 17.4和Precision@1% 37.4的高富集因子和精度。通过严格的消融和超参数研究验证了模型鲁棒性。

Conclusion: 该工作开发了一个可直接从SMILES字符串进行准确pIC50预测的稳健、可部署工具，无需3D结构信息，展示了化学transformer在加速靶点特异性药物发现中的变革潜力。

Abstract: Predicting the inhibitory potency of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1)-a key target in overcoming cancer chemoresistance-remains a critical challenge in early drug discovery. We present a deep learning framework for the quantitative regression of pIC50 values from molecular Simplified Molecular Input Line Entry System (SMILES) strings using fine-tuned variants of ChemBERTa, a pre-trained chemical language model. Leveraging a large-scale consensus dataset of 177,092 compounds, we systematically evaluate two pre-training strategies-Masked Language Modeling (MLM) and Masked Token Regression (MTR)-under stratified data splits and sample weighting to address severe activity imbalance which only 2.1% are active. Our approach outperforms classical baselines Random Predictor in both regression accuracy and virtual screening utility, and has competitive performance compared to Random Forest, achieving high enrichment factor EF@1% 17.4 and precision Precision@1% 37.4 among top-ranked predictions. The resulting model, validated through rigorous ablation and hyperparameter studies, provides a robust, ready-to-deploy tool for prioritizing TDP1 inhibitors for experimental testing. By enabling accurate, 3D-structure-free pIC50 prediction directly from SMILES, this work demonstrates the transformative potential of chemical transformers in accelerating target-specific drug discovery.

</details>


### [9] [Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness](https://arxiv.org/abs/2512.04264)
*Long Dang,Thushari Hapuarachchi,Kaiqi Xiong,Jing Lin*

Main category: cs.LG

TL;DR: 本文研究了对抗训练中不同激活函数对模型鲁棒性的影响，提出了一种改进的对抗训练方法，并将其扩展到联邦学习环境中，通过数据共享策略提升了非独立同分布数据下的模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练研究通常只考虑ReLU激活函数和集中式训练环境，缺乏对不同激活函数影响的系统研究，以及在联邦学习环境中模型鲁棒性的探索。

Method: 1. 提出改进的集中式对抗训练方法，结合模型架构调整、软标签、简化数据增强和动态学习率；2. 在10种激活函数上进行实验比较；3. 将方法扩展到联邦学习环境，考虑IID和非IID数据设置；4. 针对非IID数据引入数据共享策略。

Result: 1. 集中式训练在CIFAR-10上达到77.08%自然准确率和67.96%鲁棒准确率；2. ReLU在多数情况下表现最佳；3. 联邦学习中鲁棒准确率显著下降，特别是非IID数据；4. 40%数据共享使自然准确率达70.09%，鲁棒准确率达54.79%，优于CalFAT算法。

Conclusion: 激活函数选择对模型鲁棒性有重要影响，ReLU通常表现最佳；联邦学习环境中模型鲁棒性显著下降，但适当的数据共享策略可以显著提升非IID数据下的模型鲁棒性。

Abstract: Adversarial training is an effective method to improve the machine learning (ML) model robustness. Most existing studies typically consider the Rectified linear unit (ReLU) activation function and centralized training environments. In this paper, we study the ML model robustness using ten different activation functions through adversarial training in centralized environments and explore the ML model robustness in federal learning environments. In the centralized environment, we first propose an advanced adversarial training approach to improving the ML model robustness by incorporating model architecture change, soft labeling, simplified data augmentation, and varying learning rates. Then, we conduct extensive experiments on ten well-known activation functions in addition to ReLU to better understand how they impact the ML model robustness. Furthermore, we extend the proposed adversarial training approach to the federal learning environment, where both independent and identically distributed (IID) and non-IID data settings are considered. Our proposed centralized adversarial training approach achieves a natural and robust accuracy of 77.08% and 67.96%, respectively on CIFAR-10 against the fast gradient sign attacks. Experiments on ten activation functions reveal ReLU usually performs best. In the federated learning environment, however, the robust accuracy decreases significantly, especially on non-IID data. To address the significant performance drop in the non-IID data case, we introduce data sharing and achieve the natural and robust accuracy of 70.09% and 54.79%, respectively, surpassing the CalFAT algorithm, when 40% data sharing is used. That is, a proper percentage of data sharing can significantly improve the ML model robustness, which is useful to some real-world applications.

</details>


### [10] [The Initialization Determines Whether In-Context Learning Is Gradient Descent](https://arxiv.org/abs/2512.04268)
*Shifeng Xie,Rui Yuan,Simone Rossi,Thomas Hannagan*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型中上下文学习的机制，特别是多头线性自注意力如何近似梯度下降。通过引入初始猜测并建立理论界限，提出了yq-LSA模型来弥合性能差距，并在语义相似性任务中验证了改进效果。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习是LLMs的显著现象，但其机制尚未完全理解。先前研究在零均值高斯先验和零初始化等简化条件下建立了线性自注意力与梯度下降的联系，但这些假设过于严格。本文旨在研究在更现实条件下（非零高斯先验均值）多头线性自注意力如何近似梯度下降。

Method: 1. 扩展多头线性自注意力嵌入矩阵，引入查询的初始估计（初始猜测）
2. 证明ICL线性回归设置中所需头数的上界
3. 提出yq-LSA：具有可训练初始猜测的单头线性自注意力泛化
4. 在语义相似性任务中测试具有初始猜测能力的LLMs

Result: 1. 实验证实了理论头数界限
2. 观察到一步梯度下降与多头线性自注意力之间存在性能差距
3. yq-LSA在理论上被证明具有强大能力，并在线性回归任务中得到实验验证
4. 具有初始猜测能力的LLMs在语义相似性任务中表现提升

Conclusion: 本文通过引入初始猜测机制，扩展了连接上下文学习与梯度下降的理论框架。yq-LSA模型有效弥合了性能差距，并且在更广泛的LLMs中，初始猜测能力能够提升实际任务的性能，为理解ICL机制提供了新的理论视角。

Abstract: In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primarily been established under simplified conditions with zero-mean Gaussian priors and zero initialization for GD. However, subsequent studies have challenged this simplified view by highlighting its overly restrictive assumptions, demonstrating instead that under conditions such as multi-layer or nonlinear attention, self-attention performs optimization-like inference, akin to but distinct from GD. We investigate how multi-head LSA approximates GD under more realistic conditions specifically when incorporating non-zero Gaussian prior means in linear regression formulations of ICL. We first extend multi-head LSA embedding matrix by introducing an initial estimation of the query, referred to as the initial guess. We prove an upper bound on the number of heads needed for ICL linear regression setup. Our experiments confirm this result and further observe that a performance gap between one-step GD and multi-head LSA persists. To address this gap, we introduce yq-LSA, a simple generalization of single-head LSA with a trainable initial guess yq. We theoretically establish the capabilities of yq-LSA and provide experimental validation on linear regression tasks, thereby extending the theory that bridges ICL and GD. Finally, inspired by our findings in the case of linear regression, we consider widespread LLMs augmented with initial guess capabilities, and show that their performance is improved on a semantic similarity task.

</details>


### [11] [Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows](https://arxiv.org/abs/2512.04954)
*Rajneil Baruah*

Main category: cs.LG

TL;DR: 提出一种基于重要性采样的归一化流摊销后验估计方法，通过高斯混合模型初始化解决多模态后验建模问题


<details>
  <summary>Details</summary>
Motivation: 解决高维逆问题中理论参数的高效推断，避免需要后验训练样本，特别关注多模态后验分布建模

Method: 使用似然加权重要性采样训练归一化流进行摊销后验估计，采用高斯混合模型初始化以匹配目标模态基数

Result: 在2D和3D多模态基准任务上验证方法有效性，高斯混合模型初始化显著改善重构保真度，减少模态间虚假概率桥接

Conclusion: 基分布拓扑对后验建模有重要影响，匹配目标模态基数的高斯混合模型初始化能显著提升多模态后验估计性能

Abstract: We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics.

</details>


### [12] [Bootstrapped Mixed Rewards for RL Post-Training: Injecting Canonical Action Order](https://arxiv.org/abs/2512.04277)
*Prakhar Gupta,Vaibhav Gupta*

Main category: cs.LG

TL;DR: 在强化学习后训练中，通过添加求解器顺序奖励信号（即使监督训练使用随机顺序），可以显著提升模型性能，接近使用求解器顺序监督训练的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习后训练通常只优化单一标量目标，忽略了解决方案生成过程中的结构信息。本研究探索是否可以通过添加求解器顺序的提示信号来提升性能，即使监督训练阶段使用的是随机顺序的解决方案序列。

Method: 在数独问题上，首先使用标准微调方法在随机求解顺序上训练Transformer模型，然后使用Group Relative Policy Optimization (GRPO)进行后训练。后训练使用两种奖励：单元格准确率和顺序奖励（当模型输出顺序与求解器顺序对齐时增加）。通过固定混合比例组合奖励，并使用简单的自举缩放方法在初始化时均衡各组件的大小。

Result: 混合奖励通常优于仅使用单元格准确率优化。最佳混合比例显著提高了测试准确率，不仅优于仅使用随机顺序微调的模型，而且接近使用求解器顺序序列微调的模型的准确率。

Conclusion: 粗粒度的顺序信号可以在不修改监督数据或架构的情况下，引导强化学习后训练朝向求解器顺序轨迹，从而提升模型性能。这表明在强化学习后训练中融入结构信息是有益的。

Abstract: Post-training with reinforcement learning (RL) typically optimizes a single scalar objective and ignores structure in how solutions are produced. We ask whether a scalar hint toward a canonical solver ordering, used only during RL post-training, improves performance even when fine-tuned on randomized solution sequences. On Sudoku, we train a Transformer with standard fine-tuning on randomized solving orders, then post-train it with Group Relative Policy Optimization (GRPO) with two rewards: cell accuracy and an ordering reward that increases when the model's emission order aligns with the solver order. To compare signals cleanly, we combine them via fixed mixtures and use a simple bootstrapped scaling to equalize component magnitudes at initialization. Mixed rewards generally outperform cell-only optimization--the best mixture yields substantially higher test accuracy than the fine-tuned-only model trained on random-order and approaches the fine-tuned-only model trained on solver-order sequences in accuracy. These results suggest that coarse ordering signals can steer RL post-training toward solver-order trajectories without modifying supervised data or architecture.

</details>


### [13] [GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers](https://arxiv.org/abs/2512.04296)
*Malyaban Bal,Abhronil Sengupta*

Main category: cs.LG

TL;DR: GRASP是一种轻量级参数高效微调框架，通过分组激活共享参数化显著减少可训练参数，而StochGRASP引入概率参数化提升噪声鲁棒性，适用于边缘AI硬件部署。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调(PEFT)通过仅更新少量参数来适应大模型，但现有方法在参数效率和硬件部署鲁棒性方面仍有改进空间，特别是在噪声易发的边缘AI硬件上。

Method: GRASP将选定层的D维token表示划分为K<<D个组，为每组学习共享的缩放和偏移向量。StochGRASP进一步学习高斯分布作为预训练权重的扰动，结合噪声感知损失函数来建模硬件级变异性。

Result: 在GLUE(RoBERTa-base/large)和E2E NLG(GPT-2 Medium)任务上，GRASP性能匹配或超越现有PEFT方法，同时相比LoRA和BitFit减少一个数量级的可训练参数。在不同噪声水平下，StochGRASP始终优于确定性变体。

Conclusion: GRASP提供了一种高效且可扩展的PEFT框架，而StochGRASP通过概率参数化显著提升了噪声鲁棒性，特别适合能效受限且噪声易发的边缘AI硬件平台部署。

Abstract: Parameter-efficient fine-tuning (PEFT) provides a scalable alternative to full-model adaptation by updating only a small subset of parameters in large pre-trained models. We introduce GRASP - GRouped Activation Shared Parameterization - a lightweight PEFT framework that partitions the D-dimensional token representations of selected layers into K << D groups and learns a shared scaling and shifting vector for each group. This grouped modulation reduces the number of trainable parameters significantly while preserving the ability of the model to learn task-specific features. Building on this formulation, we further propose StochGRASP, which learns Gaussian distributions as perturbations to the pre-trained weights rather than deterministic values. This probabilistic parameterization along with a noise-aware loss function formulation enables modelling hardware-level variability in programmed weights and significantly improves robustness under non-ideal inference conditions-an important requirement for deployment on edge-based emerging AI hardware. Across GLUE (RoBERTa-base & RoBERTa-large) and E2E NLG (GPT-2 Medium), GRASP matches or exceeds the performance of established PEFT methods while achieving an order of magnitude reduction in trainable parameters compared to LoRA and BitFit. Under varying levels of noise, StochGRASP consistently outperforms deterministic variants, demonstrating its suitability for energy-efficient and noise-prone hardware platforms.

</details>


### [14] [When do spectral gradient updates help in deep learning?](https://arxiv.org/abs/2512.04299)
*Damek Davis,Dmitriy Drusvyatskiy*

Main category: cs.LG

TL;DR: 该论文提出了一个层间条件来预测谱梯度方法（如Muon优化器）何时比欧几里得梯度下降更有效，该条件比较梯度矩阵的核范数与Frobenius范数平方比和输入激活的稳定秩，并在理论和实验中验证了深度网络和Transformer中该条件通常成立。


<details>
  <summary>Details</summary>
Motivation: 谱梯度方法（如Muon优化器）是训练深度神经网络和Transformer的有前景的替代方案，但目前尚不清楚在哪些情况下它们比标准欧几里得梯度下降表现更好。需要理论指导来预测谱更新的优势条件。

Method: 提出了一个简单的层间条件：对于每个参数块，比较梯度矩阵的核范数与Frobenius范数平方比和输入激活的稳定秩。当该比值大于激活的稳定秩时，谱更新能带来更大的损失下降。在随机特征回归、前馈网络和Transformer块中，证明了高斯初始化后激活矩阵具有低稳定秩。在尖峰随机特征模型中，证明了欧几里得梯度的核范数与Frobenius范数平方比随数据维度增长，而激活的稳定秩保持有界。

Result: 理论分析表明，在深度网络和Transformer中，中间激活在整个训练过程中保持低稳定秩，而相应梯度保持较大的核范数与Frobenius范数平方比。在合成回归实验和NanoGPT规模的语言模型训练中验证了这些预测，发现谱梯度方法的优势随维度缩放。

Conclusion: 该研究确定了谱梯度方法（如Muon）在训练深度网络和Transformer中有效的条件：当梯度的核范数与Frobenius范数平方比大于激活的稳定秩时。这些结果为谱梯度方法的应用提供了理论指导和实践验证。

Abstract: Spectral gradient methods, such as the recently popularized Muon optimizer, are a promising alternative to standard Euclidean gradient descent for training deep neural networks and transformers, but it is still unclear in which regimes they are expected to perform better. We propose a simple layerwise condition that predicts when a spectral update yields a larger decrease in the loss than a Euclidean gradient step. This condition compares, for each parameter block, the squared nuclear-to-Frobenius ratio of the gradient to the stable rank of the incoming activations. To understand when this condition may be satisfied, we first prove that post-activation matrices have low stable rank at Gaussian initialization in random feature regression, feedforward networks, and transformer blocks. In spiked random feature models we then show that, after a short burn-in, the Euclidean gradient's nuclear-to-Frobenius ratio grows with the data dimension while the stable rank of the activations remains bounded, so the predicted advantage of spectral updates scales with dimension. We validate these predictions in synthetic regression experiments and in NanoGPT-scale language model training, where we find that intermediate activations have low-stable-rank throughout training and the corresponding gradients maintain large nuclear-to-Frobenius ratios. Together, these results identify conditions for spectral gradient methods, such as Muon, to be effective in training deep networks and transformers.

</details>


### [15] [Evaluating Long-Context Reasoning in LLM-Based WebAgents](https://arxiv.org/abs/2512.04307)
*Andy Chung,Yichi Zhang,Kaixiang Lin,Aditya Rawal,Qiaozi Gao,Joyce Chai*

Main category: cs.LG

TL;DR: 论文提出评估WebAgent长上下文推理能力的基准，发现随着上下文长度增加（2.5万-15万token），主流模型性能急剧下降（从40-50%降至<10%），主要失败原因是循环卡顿和目标丢失。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的智能体在日常数字交互中日益普及，其在长交互历史中的推理能力对提供个性化和上下文感知的辅助至关重要。然而，这些智能体在长上下文场景中的表现，特别是在真实网络环境中执行操作的WebAgent，尚未得到充分研究。

Method: 引入评估WebAgent长上下文推理能力的基准，通过顺序依赖的子任务要求从扩展交互历史中检索和应用信息。开发新颖的评估框架，通过在依赖子任务之间注入无关任务轨迹来模拟多会话用户交互，创建2.5万到15万token的上下文。评估了Claude-3.7、GPT-4.1、Llama 4和o4-mini四个流行模型。

Result: 随着上下文长度增加，观察到性能急剧下降：在基线条件下成功率为40-50%，在长上下文场景中降至不到10%。详细错误分析显示，智能体主要因陷入循环和丢失原始任务目标而失败。提出的隐式RAG方法通过生成任务相关摘要带来适度改进，但长上下文推理的根本限制仍然存在。

Conclusion: 研究结果突显了在真实、长期用户交互场景中部署WebAgent的关键挑战，并为开发能够在扩展上下文中保持连贯任务执行的更鲁棒智能体架构提供了见解。

Abstract: As large language model (LLM)-based agents become increasingly integrated into daily digital interactions, their ability to reason across long interaction histories becomes crucial for providing personalized and contextually aware assistance. However, the performance of these agents in long context scenarios, particularly for action-taking WebAgents operating in realistic web environments, remains largely unexplored. This paper introduces a benchmark for evaluating long context reasoning capabilities of WebAgents through sequentially dependent subtasks that require retrieval and application of information from extended interaction histories. We develop a novel evaluation framework that simulates multi-session user interactions by injecting irrelevant task trajectories between dependent subtasks, creating contexts ranging from 25,000 to 150,000 tokens. Through extensive evaluation of four popular models, Claude-3.7, GPT-4.1, Llama 4, and o4-mini, we observe a dramatic performance degradation as context length increases, with success rates dropping from 40-50\% in baseline conditions to less than 10\% in long context scenarios. Our detailed error analysis reveals that agents primarily fail due to getting stuck in loops and losing track of original task objectives. We further propose an implicit RAG approach that provides modest improvements by generating task-relevant summaries, though fundamental limitations in long context reasoning persist. These findings highlight critical challenges for deploying WebAgents in realistic, long-term user interaction scenarios and provide insights for developing more robust agent architectures capable of maintaining coherent task execution across extended contexts.

</details>


### [16] [RNNs perform task computations by dynamically warping neural representations](https://arxiv.org/abs/2512.04310)
*Arthur Pellegrino,Angus Chadwick*

Main category: cs.LG

TL;DR: RNNs通过动态扭曲其任务变量表示来执行计算，黎曼几何框架揭示了这一机制


<details>
  <summary>Details</summary>
Motivation: 理解神经网络如何通过动力学执行计算，以及计算过程与表示几何之间的联系

Method: 开发黎曼几何框架，从输入流形推导动力学系统的流形拓扑和几何结构

Result: 动态扭曲是RNN计算的基本特征，几何框架能够表征RNN的时间变化几何

Conclusion: RNNs通过动态扭曲表示来执行计算，黎曼几何为理解这一过程提供了数学工具

Abstract: Analysing how neural networks represent data features in their activations can help interpret how they perform tasks. Hence, a long line of work has focused on mathematically characterising the geometry of such "neural representations." In parallel, machine learning has seen a surge of interest in understanding how dynamical systems perform computations on time-varying input data. Yet, the link between computation-through-dynamics and representational geometry remains poorly understood. Here, we hypothesise that recurrent neural networks (RNNs) perform computations by dynamically warping their representations of task variables. To test this hypothesis, we develop a Riemannian geometric framework that enables the derivation of the manifold topology and geometry of a dynamical system from the manifold of its inputs. By characterising the time-varying geometry of RNNs, we show that dynamic warping is a fundamental feature of their computations.

</details>


### [17] [Data-regularized Reinforcement Learning for Diffusion Models at Scale](https://arxiv.org/abs/2512.04332)
*Haotian Ye,Kaiwen Zheng,Jiashu Xu,Puheng Li,Huayu Chen,Jiaqi Han,Sheng Liu,Qinsheng Zhang,Hanzi Mao,Zekun Hao,Prithvijit Chattopadhyay,Dinghao Yang,Liang Feng,Maosheng Liao,Junjie Bai,Ming-Yu Liu,James Zou,Stefano Ermon*

Main category: cs.LG

TL;DR: DDRL是一种新的扩散模型强化学习框架，使用前向KL散度将策略锚定到离策略数据分布，有效解决奖励黑客问题，在视频生成任务中显著提升人类偏好评分。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型强化学习方法容易受到奖励黑客问题的影响，如质量下降、过度风格化或多样性减少，这源于其正则化方法的固有局限性。

Method: 提出数据正则化扩散强化学习（DDRL）框架，使用前向KL散度将策略锚定到离策略数据分布，结合奖励最大化和扩散损失最小化。

Result: 经过超过一百万GPU小时的实验和一万次双盲人类评估，在高分辨率视频生成任务中，DDRL显著提升奖励分数，缓解奖励黑客问题，获得最高人类偏好评分。

Conclusion: DDRL为扩散模型后训练提供了一个稳健且可扩展的范式，能够可靠地将生成扩散模型与人类偏好对齐。

Abstract: Aligning generative diffusion models with human preferences via reinforcement learning (RL) is critical yet challenging. Most existing algorithms are often vulnerable to reward hacking, such as quality degradation, over-stylization, or reduced diversity. Our analysis demonstrates that this can be attributed to the inherent limitations of their regularization, which provides unreliable penalties. We introduce Data-regularized Diffusion Reinforcement Learning (DDRL), a novel framework that uses the forward KL divergence to anchor the policy to an off-policy data distribution. Theoretically, DDRL enables robust, unbiased integration of RL with standard diffusion training. Empirically, this translates into a simple yet effective algorithm that combines reward maximization with diffusion loss minimization. With over a million GPU hours of experiments and ten thousand double-blind human evaluations, we demonstrate on high-resolution video generation tasks that DDRL significantly improves rewards while alleviating the reward hacking seen in baselines, achieving the highest human preference and establishing a robust and scalable paradigm for diffusion post-training.

</details>


### [18] [RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection](https://arxiv.org/abs/2512.04333)
*Shreyas Shende,Varsha Narayanan,Vishal Fenn,Yiran Huang,Dincer Goksuluk,Gaurav Choudhary,Melih Agraz,Mengjia Xu*

Main category: cs.LG

TL;DR: RGE-GCN结合图卷积网络和递归基因消除，从RNA-seq数据中识别癌症生物标志物，在多种癌症数据上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 癌症早期检测需要可靠生物标志物，但RNA-seq数据高维且复杂，传统统计方法难以捕捉基因间的复杂关系。

Method: RGE-GCN框架整合特征选择和分类：基于基因表达谱构建图，使用图卷积网络分类癌症与正常样本，应用积分梯度突出重要基因，递归消除不相关基因得到紧凑生物标志物集。

Result: 在合成数据和真实肺癌、肾癌、宫颈癌RNA-seq数据上，RGE-GCN在准确率和F1分数上均优于DESeq2、edgeR、limma-voom等标准工具，所选基因与已知癌症通路（PI3K-AKT、MAPK、SUMOylation、免疫调节）一致。

Conclusion: RGE-GCN作为可推广的方法，在RNA-seq数据驱动的癌症早期检测和生物标志物发现方面具有潜力。

Abstract: Early detection of cancer plays a key role in improving survival rates, but identifying reliable biomarkers from RNA-seq data is still a major challenge. The data are high-dimensional, and conventional statistical methods often fail to capture the complex relationships between genes. In this study, we introduce RGE-GCN (Recursive Gene Elimination with Graph Convolutional Networks), a framework that combines feature selection and classification in a single pipeline. Our approach builds a graph from gene expression profiles, uses a Graph Convolutional Network to classify cancer versus normal samples, and applies Integrated Gradients to highlight the most informative genes. By recursively removing less relevant genes, the model converges to a compact set of biomarkers that are both interpretable and predictive. We evaluated RGE-GCN on synthetic data as well as real-world RNA-seq cohorts of lung, kidney, and cervical cancers. Across all datasets, the method consistently achieved higher accuracy and F1-scores than standard tools such as DESeq2, edgeR, and limma-voom. Importantly, the selected genes aligned with well-known cancer pathways including PI3K-AKT, MAPK, SUMOylation, and immune regulation. These results suggest that RGE-GCN shows promise as a generalizable approach for RNA-seq based early cancer detection and biomarker discovery (https://rce-gcn.streamlit.app/ ).

</details>


### [19] [Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism](https://arxiv.org/abs/2512.04341)
*Tianwei Ni,Esther Derman,Vineet Jain,Vincent Taboga,Siamak Ravanbakhsh,Pierre-Luc Bacon*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯视角的离线强化学习方法Neubay，挑战了传统保守主义方法的普适性，通过建模后验世界模型分布实现测试时泛化，在低质量数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统离线强化学习方法主要依赖保守主义原则（惩罚数据集外动作或限制规划视野），但作者质疑这一原则的普适性，转而探索贝叶斯视角作为补充方法，以更好地处理离线数据中的认知不确定性。

Method: 提出Neubay算法，基于中性贝叶斯原则：1) 建模后验分布覆盖可能的世界模型；2) 训练历史依赖的智能体最大化期望奖励；3) 采用层归一化和自适应长视野规划等关键技术缓解误差累积和价值高估问题。

Result: 在D4RL和NeoRL基准测试中，Neubay通常匹配或超越领先的保守算法，在7个数据集上达到新的最先进水平。特别值得注意的是，该方法能够成功处理数百步的长规划视野，挑战了传统认知。

Conclusion: 贝叶斯方法在低质量数据集上优于保守主义方法，为离线和基于模型的强化学习提供了新方向。作者还分析了Neubay相对于保守主义方法的适用场景，建立了理论基础。

Abstract: Popular offline reinforcement learning (RL) methods rely on conservatism, either by penalizing out-of-dataset actions or by restricting planning horizons. In this work, we question the universality of this principle and instead revisit a complementary one: a Bayesian perspective. Rather than enforcing conservatism, the Bayesian approach tackles epistemic uncertainty in offline data by modeling a posterior distribution over plausible world models and training a history-dependent agent to maximize expected rewards, enabling test-time generalization. We first illustrate, in a bandit setting, that Bayesianism excels on low-quality datasets where conservatism fails. We then scale the principle to realistic tasks, identifying key design choices, such as layer normalization in the world model and adaptive long-horizon planning, that mitigate compounding error and value overestimation. These yield our practical algorithm, Neubay, grounded in the neutral Bayesian principle. On D4RL and NeoRL benchmarks, Neubay generally matches or surpasses leading conservative algorithms, achieving new state-of-the-art on 7 datasets. Notably, it succeeds with planning horizons of several hundred steps, challenging common belief. Finally, we characterize when Neubay is preferable to conservatism, laying the foundation for a new direction in offline and model-based RL.

</details>


### [20] [Distance Is All You Need: Radial Dispersion for Uncertainty Estimation in Large Language Models](https://arxiv.org/abs/2512.04351)
*Manh Nguyen,Sunil Gupta,Hung Le*

Main category: cs.LG

TL;DR: 提出RDS（径向分散分数），一种简单、参数免费、完全模型无关的不确定性度量方法，通过测量嵌入空间中生成样本的径向分散来评估LLM的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有检测大型语言模型不确定性的方法过于复杂，依赖脆弱的语义聚类或内部状态，需要更简单可靠的解决方案。

Method: 引入径向分散分数（RDS），在嵌入空间中测量生成样本的径向分散；还提出轻量级概率加权变体，结合模型的标记概率信息。

Result: 在四个具有挑战性的自由形式QA数据集和多个LLM上，RDS在幻觉检测和答案选择方面达到最先进性能，优于九个强基线方法。

Conclusion: RDS是一种简单有效的LLM不确定性度量方法，具有模型无关性、可扩展性，并能自然地扩展到逐样本评分，适用于最佳选择、置信度过滤等应用。

Abstract: Detecting when large language models (LLMs) are uncertain is critical for building reliable systems, yet existing methods are overly complicated, relying on brittle semantic clustering or internal states. We introduce \textbf{Radial Dispersion Score (RDS)}, a simple, parameter-free, fully model-agnostic uncertainty metric that measures the radial dispersion of sampled generations in embedding space. A lightweight probability-weighted variant further incorporates the model's own token probabilities when available, outperforming different nine strong baselines. Moroever, RDS naturally extends to per-sample scoring, enabling applications such as best-of-$N$ selection and confidence-based filtering. Across four challenging free-form QA datasets and multiple LLMs, our metrics achieve state-of-the-art hallucination detection and answer selection performance, while remaining robust and scalable with respect to sample size and embedding choice.

</details>


### [21] [SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction](https://arxiv.org/abs/2512.04354)
*April S. Liang,Fatemeh Amrollahi,Yixing Jiang,Conor K. Corbin,Grace Y. E. Kim,David Mui,Trevor Crowell,Aakash Acharya,Sreedevi Mony,Soumya Punnathanam,Jack McKeown,Margaret Smith,Steven Lin,Arnold Milstein,Kevin Schulman,Jason Hom,Michael A. Pfeffer,Tho D. Pham,David Svec,Weihan Chu,Lisa Shieh,Christopher Sharp,Stephen P. Ma,Jonathan H. Chen*

Main category: cs.LG

TL;DR: 机器学习驱动的临床决策支持系统SmartAlert通过预测稳定的实验室结果，成功减少不必要的重复血液检测，在9270例住院患者中实现15%的相对减少，且不影响安全性。


<details>
  <summary>Details</summary>
Motivation: 重复的实验室检测通常不会产生有临床价值的信息，但却是常见做法，增加了患者负担和医疗成本。传统的教育和反馈干预效果有限，而通用的检测限制和电子警报又可能妨碍适当的临床护理。

Method: 开发并评估SmartAlert，这是一个集成到电子健康记录中的机器学习驱动的临床决策支持系统，能够预测稳定的实验室结果以减少不必要的重复检测。研究采用随机对照试验设计，在2024年8月15日至2025年3月15日期间，在两个医院的八个急症护理单元的9270例住院患者中进行试点。

Result: 结果显示，在SmartAlert显示后的52小时内，CBC检测次数显著减少（1.54 vs 1.82，p<0.01），相对减少了15%的重复检测，且对次要安全性结果没有不良影响。

Conclusion: 机器学习驱动的临床决策支持系统结合深思熟虑的实施和治理流程，能够为住院患者实验室检测提供精准指导，安全地减少不必要的重复检测。

Abstract: Repetitive laboratory testing unlikely to yield clinically useful information is a common practice that burdens patients and increases healthcare costs. Education and feedback interventions have limited success, while general test ordering restrictions and electronic alerts impede appropriate clinical care. We introduce and evaluate SmartAlert, a machine learning (ML)-driven clinical decision support (CDS) system integrated into the electronic health record that predicts stable laboratory results to reduce unnecessary repeat testing. This case study describes the implementation process, challenges, and lessons learned from deploying SmartAlert targeting complete blood count (CBC) utilization in a randomized controlled pilot across 9270 admissions in eight acute care units across two hospitals between August 15, 2024, and March 15, 2025. Results show significant decrease in number of CBC results within 52 hours of SmartAlert display (1.54 vs 1.82, p <0.01) without adverse effect on secondary safety outcomes, representing a 15% relative reduction in repetitive testing. Implementation lessons learned include interpretation of probabilistic model predictions in clinical contexts, stakeholder engagement to define acceptable model behavior, governance processes for deploying a complex model in a clinical environment, user interface design considerations, alignment with clinical operational priorities, and the value of qualitative feedback from end users. In conclusion, a machine learning-driven CDS system backed by a deliberate implementation and governance process can provide precision guidance on inpatient laboratory testing to safely reduce unnecessary repetitive testing.

</details>


### [22] [STeP-Diff: Spatio-Temporal Physics-Informed Diffusion Models for Mobile Fine-Grained Pollution Forecasting](https://arxiv.org/abs/2512.04385)
*Nan Zhou,Weijie Hong,Huandong Wang,Jianfeng Zheng,Qiuhua Wang,Yali Song,Xiao-Ping Zhang,Yong Li,Xinlei Chen*

Main category: cs.LG

TL;DR: 提出STeP-Diff模型，利用扩散模型的反向过程结合物理约束，从不完整、时间不一致的移动传感器数据中预测细粒度空气污染时空场。


<details>
  <summary>Details</summary>
Motivation: 细粒度空气污染预测对城市管理和健康建筑发展至关重要。移动平台（如汽车、公交车）部署便携传感器提供了低成本、易维护、广覆盖的数据采集方案，但这些非专用移动平台的随机不可控运动模式导致传感器数据不完整且时间不一致。

Method: 提出时空物理信息扩散模型（STeP-Diff），通过探索扩散模型反向过程中的潜在训练模式，利用DeepONet建模空间测量序列，结合PDE信息扩散模型从不完整、时变数据中预测时空场。通过PDE约束正则化框架，去噪过程渐近收敛于对流-扩散动力学，确保预测既基于真实测量又符合污染扩散的基本物理规律。

Result: 在两个城市部署59个自主设计的便携传感设备，运行14天收集空气污染数据。与次优算法相比，模型在MAE上提升达89.12%，RMSE提升82.30%，MAPE提升25.00%。广泛评估表明STeP-Diff能有效捕捉空气污染场的时空依赖性。

Conclusion: STeP-Diff模型成功解决了移动传感器数据不完整和时间不一致的问题，通过结合扩散模型和物理约束，实现了准确、物理一致的细粒度空气污染时空预测，为城市空气质量管理提供了有效工具。

Abstract: Fine-grained air pollution forecasting is crucial for urban management and the development of healthy buildings. Deploying portable sensors on mobile platforms such as cars and buses offers a low-cost, easy-to-maintain, and wide-coverage data collection solution. However, due to the random and uncontrollable movement patterns of these non-dedicated mobile platforms, the resulting sensor data are often incomplete and temporally inconsistent. By exploring potential training patterns in the reverse process of diffusion models, we propose Spatio-Temporal Physics-Informed Diffusion Models (STeP-Diff). STeP-Diff leverages DeepONet to model the spatial sequence of measurements along with a PDE-informed diffusion model to forecast the spatio-temporal field from incomplete and time-varying data. Through a PDE-constrained regularization framework, the denoising process asymptotically converges to the convection-diffusion dynamics, ensuring that predictions are both grounded in real-world measurements and aligned with the fundamental physics governing pollution dispersion. To assess the performance of the system, we deployed 59 self-designed portable sensing devices in two cities, operating for 14 days to collect air pollution data. Compared to the second-best performing algorithm, our model achieved improvements of up to 89.12% in MAE, 82.30% in RMSE, and 25.00% in MAPE, with extensive evaluations demonstrating that STeP-Diff effectively captures the spatio-temporal dependencies in air pollution fields.

</details>


### [23] [Learning to Orchestrate Agents in Natural Language with the Conductor](https://arxiv.org/abs/2512.04388)
*Stefan Nielsen,Edoardo Cetin,Peter Schwendeman,Qi Sun,Jinglue Xu,Yujin Tang*

Main category: cs.LG

TL;DR: 使用强化学习训练Conductor模型，自动发现LLM间的协调策略，通过设计通信拓扑和提示工程，使7B小模型协调大模型获得超越单个大模型的性能


<details>
  <summary>Details</summary>
Motivation: 不同提供商的大型语言模型在不同领域有专门化能力，但缺乏有效的协调机制。需要一种方法来自动发现LLM间的最优协作策略，最大化利用各模型的专长

Method: 使用强化学习训练Conductor模型，学习设计针对性的通信拓扑和提示工程指令，协调多个LLM工作者。通过随机化代理池训练，使Conductor能适应任意开源和闭源模型。允许Conductor选择自身作为工作者，形成递归拓扑

Result: 7B参数的Conductor模型在协调强大LLM工作者时，性能显著超越任何单个工作者，在LiveCodeBench和GPQA等推理基准上达到SOTA。能有效适应任意代理集合，通过递归拓扑实现动态测试时扩展

Conclusion: 通过纯端到端奖励最大化的强化学习，可以在LLM中自然涌现强大的协调策略。这是早期展示语言模型协调可通过RL解锁的工作之一，为LLM协作提供了新范式

Abstract: Powerful large language models (LLMs) from different providers have been expensively trained and finetuned to specialize across varying domains. In this work, we introduce a new kind of Conductor model trained with reinforcement learning to automatically discover powerful coordination strategies among LLMs. Our Conductor learns not only to design targeted communication topologies for effective agent-to-agent collaboration, but also to prompt engineer focused instructions to the LLMs to maximally leverage their individual capabilities. We show that, by learning optimal coordination strategies over pools of powerful worker LLMs, a 7B Conductor achieves significant performance gains beyond any individual worker, attaining state-of-the-art results in challenging reasoning benchmarks, such as LiveCodeBench and GPQA. By training with randomized agent pools, our conductor effectively adapts to arbitrary sets of open- and closed-source agents, meeting any user requirements. Furthermore, allowing the Conductor to select itself as a worker gives rise to recursive topologies, elevating performance with a new form of dynamic test-time scaling through online iterative adaptation. More broadly, ours is among the early work demonstrating language model coordination can be unlocked through RL, where powerful coordination strategies emerge naturally in LLMs through pure end-to-end reward maximization.

</details>


### [24] [Feature Engineering vs. Deep Learning for Automated Coin Grading: A Comparative Study on Saint-Gaudens Double Eagles](https://arxiv.org/abs/2512.04464)
*Tanmay Dogra,Eric Ngo,Mohammad Alam,Jean-Paul Talavera,Asim Dahal*

Main category: cs.LG

TL;DR: 在圣高登双鹰金币自动分级任务中，特征工程驱动的传统人工神经网络（86%精确匹配）显著优于混合卷积神经网络（31%）和支持向量机（30%），证明在小样本、类别不平衡的特定领域任务中，领域知识比深度学习更有效。


<details>
  <summary>Details</summary>
Motivation: 挑战"深度学习总是优于传统方法"的普遍观念，通过金币自动分级这一具体案例，探讨在数据稀缺、类别不平衡的特定领域任务中，领域知识驱动的特征工程是否比端到端的深度学习更有效。

Method: 构建了三种对比模型：1）基于特征的人工神经网络（ANN），使用192个自定义特征（来自Sobel边缘检测和HSV颜色分析）；2）混合卷积神经网络（CNN），结合EfficientNetV2架构；3）支持向量机（SVM）作为基准对照。使用1,785枚专家分级金币进行测试。

Result: ANN表现最佳：86%精确匹配率，±3级容错率下达到98%。CNN和SVM表现较差：精确匹配率分别为31%和30%，主要猜测最常见等级。CNN在宽泛容错指标上看似不错，但这是回归平均效应掩盖了其无法准确识别具体等级的问题。

Conclusion: 在少于2,000个样本且类别不平衡的特定领域任务中，融入领域专家知识的特征工程方法优于端到端的深度学习方案。这一结论适用于其他数据稀缺、专业知识比计算能力更重要的利基质量检测任务。

Abstract: We challenge the common belief that deep learning always trumps older techniques, using the example of grading Saint-Gaudens Double Eagle gold coins automatically. In our work, we put a feature-based Artificial Neural Network built around 192 custom features pulled from Sobel edge detection and HSV color analysis up against a hybrid Convolutional Neural Network that blends in EfficientNetV2, plus a straightforward Support Vector Machine as the control. Testing 1,785 coins graded by experts, the ANN nailed 86% exact matches and hit 98% when allowing a 3-grade leeway. On the flip side, CNN and SVM mostly just guessed the most common grade, scraping by with 31% and 30% exact hits. Sure, the CNN looked good on broader tolerance metrics, but that is because of some averaging trick in regression that hides how it totally flops at picking out specific grades. All told, when you are stuck with under 2,000 examples and lopsided classes, baking in real coin-expert knowledge through feature design beats out those inscrutable, all-in-one deep learning setups. This rings true for other niche quality checks where data's thin and know-how matters more than raw compute.

</details>


### [25] [GraphBench: Next-generation graph learning benchmarking](https://arxiv.org/abs/2512.04475)
*Timo Stoll,Chendi Qian,Ben Finkelshtein,Ali Parviz,Darius Weber,Fabrizio Frasca,Hadar Shavit,Antoine Siraudin,Arman Mielke,Marie Anastacio,Erik Müller,Maya Bechler-Speicher,Michael Bronstein,Mikhail Galkin,Holger Hoos,Mathias Niepert,Bryan Perozzi,Jan Tönshoff,Christopher Morris*

Main category: cs.LG

TL;DR: GraphBench是一个全面的图机器学习基准测试套件，涵盖多个领域和预测任务，提供标准化评估协议和统一超参数调优框架，旨在解决当前基准测试碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 当前图机器学习基准测试实践碎片化，依赖狭窄的任务特定数据集和不一致的评估协议，这阻碍了可重复性和更广泛的进展。

Method: 引入GraphBench基准测试套件，涵盖多样化的领域和预测任务（节点级、边级、图级和生成式设置），提供标准化评估协议（包括一致的数据集划分和考虑分布外泛化的性能指标）以及统一的超参数调优框架。

Result: 使用消息传递神经网络和图Transformer模型对GraphBench进行基准测试，提供了原则性基线并建立了参考性能标准。

Conclusion: GraphBench通过提供全面的标准化基准测试套件，解决了图机器学习领域的碎片化评估问题，为未来研究建立了可靠的评估基础。

Abstract: Machine learning on graphs has recently achieved impressive progress in various domains, including molecular property prediction and chip design. However, benchmarking practices remain fragmented, often relying on narrow, task-specific datasets and inconsistent evaluation protocols, which hampers reproducibility and broader progress. To address this, we introduce GraphBench, a comprehensive benchmarking suite that spans diverse domains and prediction tasks, including node-level, edge-level, graph-level, and generative settings. GraphBench provides standardized evaluation protocols -- with consistent dataset splits and performance metrics that account for out-of-distribution generalization -- as well as a unified hyperparameter tuning framework. Additionally, we benchmark GraphBench using message-passing neural networks and graph transformer models, providing principled baselines and establishing a reference performance. See www.graphbench.io for further details.

</details>


### [26] [Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems](https://arxiv.org/abs/2512.04476)
*Zehao Fan,Zhenyu Liu,Yunzhen Liu,Yayue Hou,Hadjer Benmeziane,Kaoutar El Maghraoui,Liu Liu*

Main category: cs.LG

TL;DR: 利用CXL近数据处理(CXL-NDP)优化MoE模型推理，通过上下文感知的专家放置和混合精度量化，将冷专家卸载到CXL-NDP执行，减少参数传输，提升解码吞吐量8.7倍


<details>
  <summary>Details</summary>
Motivation: MoE模型通过条件计算扩展大语言模型，但当专家权重超过GPU内存容量时，推理变得内存受限，需要将权重卸载到外部内存，导致昂贵的重复数据传输

Method: 1) 采用CXL-NDP作为卸载层执行冷专家；2) 开发上下文感知MoE系统，使用预填充阶段激活统计指导解码阶段专家放置；3) 动态将热专家固定在GPU HBM中，其余映射到CXL-NDP；4) 引入上下文感知混合精度量化，基于预填充阶段为每个专家分配比特宽度(1-4位)

Result: 在GPU-NDP系统上评估显示，该方法相比最先进方法实现了高达8.7倍的解码吞吐量提升，同时仅带来0.13%的平均准确率下降

Conclusion: 通过上下文感知的专家放置和混合精度量化，结合CXL-NDP执行冷专家，可以有效优化MoE模型推理，显著提升吞吐量同时保持模型准确性

Abstract: Mixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. We address this by adopting CXL-attached near-data processing (CXL-NDP) as the offloading tier to execute cold experts in place, converting expensive parameter movement into cheaper activation movement. Unlike prior GPU-NDP systems that are largely context-agnostic and reactive, we develop a context-aware MoE system that uses prefill-stage activation statistics to guide decoding-stage expert placement, dynamically pins hot experts in GPU-side HBM, and maps the remainder to CXL-NDP. To meet NDP's limited compute throughput, we introduce context-aware mixed-precision quantization that allocates per-expert bitwidths (1-4 bit) based on prefill stage. The resulting MoE inference system overlaps GPU and NDP execution while minimizing cross-device movement. The evaluation on the GPU-NDP system shows that our approach achieves up to an 8.7-fold decoding throughput improvement over the state-of-the-art method, while incurring only a 0.13% average accuracy drop.

</details>


### [27] [Prototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval](https://arxiv.org/abs/2512.04524)
*Tianle Hu,Weijun Lv,Na Han,Xiaozhao Fang,Jie Wen,Jiaxing Li,Guoxu Zhou*

Main category: cs.LG

TL;DR: 提出PSCA框架解决域自适应检索问题，通过原型学习实现类级语义对齐，利用几何邻近性评估伪标签可靠性，在重构特征上进行量化以生成高质量哈希码。


<details>
  <summary>Details</summary>
Motivation: 现有域自适应检索方法存在三个主要问题：1) 忽视类级语义对齐，过度追求样本对对齐；2) 缺乏伪标签可靠性考虑或几何指导；3) 直接量化受域偏移影响的原始特征，损害哈希码质量。需要解决这些根本限制。

Method: 提出两阶段PSCA框架：第一阶段通过正交原型建立类级语义连接，最大化类间分离性和类内聚集性，利用几何邻近性自适应加权伪标签置信度，通过特征重构连接两阶段；第二阶段在重构特征上应用域特定量化函数，在相互近似约束下生成统一的二进制哈希码。

Result: 在多个数据集上的广泛实验验证了PSCA的优越性能，表明该方法能有效解决域自适应检索中的关键问题。

Conclusion: PSCA通过原型驱动的语义一致性对齐和重构特征量化，有效解决了现有域自适应检索方法的局限性，实现了跨域的高质量哈希码生成和检索性能提升。

Abstract: Domain adaptive retrieval aims to transfer knowledge from a labeled source domain to an unlabeled target domain, enabling effective retrieval while mitigating domain discrepancies. However, existing methods encounter several fundamental limitations: 1) neglecting class-level semantic alignment and excessively pursuing pair-wise sample alignment; 2) lacking either pseudo-label reliability consideration or geometric guidance for assessing label correctness; 3) directly quantizing original features affected by domain shift, undermining the quality of learned hash codes. In view of these limitations, we propose Prototype-Based Semantic Consistency Alignment (PSCA), a two-stage framework for effective domain adaptive retrieval. In the first stage, a set of orthogonal prototypes directly establishes class-level semantic connections, maximizing inter-class separability while gathering intra-class samples. During the prototype learning, geometric proximity provides a reliability indicator for semantic consistency alignment through adaptive weighting of pseudo-label confidences. The resulting membership matrix and prototypes facilitate feature reconstruction, ensuring quantization on reconstructed rather than original features, thereby improving subsequent hash coding quality and seamlessly connecting both stages. In the second stage, domain-specific quantization functions process the reconstructed features under mutual approximation constraints, generating unified binary hash codes across domains. Extensive experiments validate PSCA's superior performance across multiple datasets.

</details>


### [28] [Explainable Graph Representation Learning via Graph Pattern Analysis](https://arxiv.org/abs/2512.04530)
*Xudong Wang,Ziheng Sun,Chris Ding,Jicong Fan*

Main category: cs.LG

TL;DR: 提出PXGL-GNN框架，通过图模式分析学习和解释图表示，解决图表示学习可解释性问题


<details>
  <summary>Details</summary>
Motivation: 现有可解释图学习主要关注模型级和实例级，图表示学习的可解释性研究有限。需要回答图表示捕获了图的哪些具体信息这一基本问题。

Method: 受图核启发，采样各种模式的图子结构，学习这些模式的表示，通过加权求和组合，权重表示各图模式的重要性贡献。

Result: 在监督和无监督学习任务中，与多个基线方法比较，展示了方法的有效性，并通过模式分析解释真实世界数据的图表示。

Conclusion: 提出的PXGL-GNN框架能够学习和解释图表示，提供理论分析（鲁棒性和泛化性），为图表示学习提供可解释性解决方案。

Abstract: Explainable artificial intelligence (XAI) is an important area in the AI community, and interpretability is crucial for building robust and trustworthy AI models. While previous work has explored model-level and instance-level explainable graph learning, there has been limited investigation into explainable graph representation learning. In this paper, we focus on representation-level explainable graph learning and ask a fundamental question: What specific information about a graph is captured in graph representations? Our approach is inspired by graph kernels, which evaluate graph similarities by counting substructures within specific graph patterns. Although the pattern counting vector can serve as an explainable representation, it has limitations such as ignoring node features and being high-dimensional. To address these limitations, we introduce a framework (PXGL-GNN) for learning and explaining graph representations through graph pattern analysis. We start by sampling graph substructures of various patterns. Then, we learn the representations of these patterns and combine them using a weighted sum, where the weights indicate the importance of each graph pattern's contribution. We also provide theoretical analyses of our methods, including robustness and generalization. In our experiments, we show how to learn and explain graph representations for real-world data using pattern analysis. Additionally, we compare our method against multiple baselines in both supervised and unsupervised learning tasks to demonstrate its effectiveness.

</details>


### [29] [On the Limits of Test-Time Compute: Sequential Reward Filtering for Better Inference](https://arxiv.org/abs/2512.04558)
*Yue Yu,Qiwei Di,Quanquan Gu,Dongruo Zhou*

Main category: cs.LG

TL;DR: 论文分析了测试时计算（TTC）范式，证明标准的最佳-n采样（BoN）存在固有次优性，提出奖励过滤顺序推理方法，在理论和实证上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管最佳-n采样和顺序修订等方法在增强大语言模型方面取得了经验性成功，但这些方法的基本限制尚不清楚。需要填补这一理论空白，理解测试时计算范式的根本局限性。

Method: 提出奖励过滤顺序推理方法：通过选择性仅将高奖励生成结果纳入上下文，将计算集中在优质策略候选上，抑制劣质候选。分析混合参考策略模型，证明标准BoN的次优性。

Result: 理论证明：奖励过滤顺序推理比标准TTC范式提供更强的保证。实证评估：在多样化基准测试中，该方法相比广泛使用的方法获得一致改进，展示了框架的实际有效性。

Conclusion: 奖励过滤顺序推理是更接近最优前沿的测试时计算方法，在理论和实证上都优于标准的最佳-n采样方法，为增强大语言模型提供了更有效的框架。

Abstract: Test-time compute (TTC) has become an increasingly prominent paradigm for enhancing large language models (LLMs). Despite the empirical success of methods such as best-of-$n$ (BoN) sampling and sequential revision, their fundamental limits remain unclear. We address this gap by analyzing a mixture-of-reference policy model and proving that standard BoN is inherently suboptimal. To move closer to the optimal frontier, we study reward-filtered sequential inference, a simple procedure that selectively incorporates only high-reward generations into the context. This mechanism concentrates computation on superior policy candidates and suppresses inferior ones. On the theoretical side, we show that reward-filtered sequential inference yields strictly stronger guarantees than standard TTC paradigms. On the empirical side, we evaluate such an inference strategy across diverse benchmarks and observe consistent improvements over widely used approaches, demonstrating the practical effectiveness of our framework.

</details>


### [30] [Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function](https://arxiv.org/abs/2512.04559)
*Hyeongyu Kang,Jaewoo Lee,Woocheol Shin,Kiyoung Om,Jinkyoo Park*

Main category: cs.LG

TL;DR: SQDF是一种用于扩散模型对齐的KL正则化强化学习方法，通过软Q函数估计解决奖励过优化问题，在保持多样性的同时提升目标奖励


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型微调方法存在严重的奖励过优化问题，导致生成高奖励但不自然的样本，同时多样性下降。需要一种既能提升目标奖励又能保持样本自然性和多样性的对齐方法。

Method: 提出Soft Q-based Diffusion Finetuning (SQDF)：1）使用训练免费、可微分的软Q函数估计的重参数化策略梯度；2）引入折扣因子用于去噪过程的信用分配；3）集成一致性模型改进Q函数估计；4）使用离策略回放缓冲区管理奖励-多样性权衡

Result: 在文本到图像对齐任务中，SQDF实现了更高的目标奖励同时保持了多样性；在在线黑盒优化中，SQDF获得了高样本效率，同时保持了自然性和多样性

Conclusion: SQDF通过创新的KL正则化RL框架有效解决了扩散模型对齐中的奖励过优化问题，在提升目标奖励的同时保持了样本的自然性和多样性，为扩散模型的下游任务对齐提供了有效解决方案

Abstract: Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.

</details>


### [31] [LeMat-GenBench: A Unified Evaluation Framework for Crystal Generative Models](https://arxiv.org/abs/2512.04562)
*Siddharth Betala,Samuel P. Gleason,Ali Ramlaoui,Andy Xu,Georgia Channing,Daniel Levy,Clémentine Fourrier,Nikita Kazeev,Chaitanya K. Joshi,Sékou-Oumar Kaba,Félix Therrien,Alex Hernandez-Garcia,Rocío Mercado,N. M. Anoop Krishnan,Alexandre Duval*

Main category: cs.LG

TL;DR: LeMat-GenBench是一个用于晶体材料生成模型的统一基准测试框架，包含评估指标、开源评估套件和公开排行榜，旨在解决该领域缺乏标准化评估的问题。


<details>
  <summary>Details</summary>
Motivation: 生成式机器学习模型在加速材料发现方面具有巨大潜力，但缺乏标准化的评估框架，使得难以有意义地评估、比较和进一步发展这些模型。

Method: 开发LeMat-GenBench统一基准测试框架，包含一套评估指标，发布开源评估套件和Hugging Face上的公开排行榜，并对12个最近的生成模型进行基准测试。

Result: 基准测试结果显示，稳定性的提高通常会导致新颖性和多样性的降低，没有模型在所有维度上都表现出色。这揭示了生成模型在晶体材料设计中的权衡关系。

Conclusion: LeMat-GenBench为公平模型比较建立了可重复和可扩展的基础，旨在指导开发更可靠、面向发现的晶体材料生成模型。

Abstract: Generative machine learning (ML) models hold great promise for accelerating materials discovery through the inverse design of inorganic crystals, enabling an unprecedented exploration of chemical space. Yet, the lack of standardized evaluation frameworks makes it challenging to evaluate, compare, and further develop these ML models meaningfully. In this work, we introduce LeMat-GenBench, a unified benchmark for generative models of crystalline materials, supported by a set of evaluation metrics designed to better inform model development and downstream applications. We release both an open-source evaluation suite and a public leaderboard on Hugging Face, and benchmark 12 recent generative models. Results reveal that an increase in stability leads to a decrease in novelty and diversity on average, with no model excelling across all dimensions. Altogether, LeMat-GenBench establishes a reproducible and extensible foundation for fair model comparison and aims to guide the development of more reliable, discovery-oriented generative models for crystalline materials.

</details>


### [32] [Reliable Statistical Guarantees for Conformal Predictors with Small Datasets](https://arxiv.org/abs/2512.04566)
*Miguel Sánchez-Domínguez,Lucas Lacasa,Javier de Vicente,Gonzalo Rubio,Eusebio Valero*

Main category: cs.LG

TL;DR: 提出新的统计保证框架，为单个共形预测器提供覆盖率的概率信息，解决小校准集下传统共形预测覆盖率波动大的问题


<details>
  <summary>Details</summary>
Motivation: 传统共形预测（CP）的统计保证是基于边际覆盖率的边界，当校准集较小时（这在现实代理建模中常见），覆盖率分布可能大幅偏离平均值，导致实际覆盖率低于预期值，降低了不确定性量化框架的可靠性

Method: 提出新的统计保证框架，为单个共形预测器提供覆盖率的概率信息。该方法在大校准集时收敛到传统CP解决方案，但在小数据集时仍能提供可靠的覆盖率信息

Result: 新框架在小数据集下仍能提供可靠的覆盖率信息，解决了传统CP在小校准集时覆盖率波动大的问题。通过一系列示例验证了方法的有效性，并实现了开源软件解决方案

Conclusion: 提出的新统计保证框架填补了传统共形预测在小校准集情况下的不足，为安全关键应用中代理模型的不确定性量化提供了更可靠的解决方案，特别是在数据有限的情况下

Abstract: Surrogate models (including deep neural networks and other machine learning algorithms in supervised learning) are capable of approximating arbitrarily complex, high-dimensional input-output problems in science and engineering, but require a thorough data-agnostic uncertainty quantification analysis before these can be deployed for any safety-critical application. The standard approach for data-agnostic uncertainty quantification is to use conformal prediction (CP), a well-established framework to build uncertainty models with proven statistical guarantees that do not assume any shape for the error distribution of the surrogate model. However, since the classic statistical guarantee offered by CP is given in terms of bounds for the marginal coverage, for small calibration set sizes (which are frequent in realistic surrogate modelling that aims to quantify error at different regions), the potentially strong dispersion of the coverage distribution around its average negatively impacts the reliability of the uncertainty model, often obtaining coverages below the expected value, resulting in a less applicable framework. After providing a gentle presentation of uncertainty quantification for surrogate models for machine learning practitioners, in this paper we bridge the gap by proposing a new statistical guarantee that offers probabilistic information for the coverage of a single conformal predictor. We show that the proposed framework converges to the standard solution offered by CP for large calibration set sizes and, unlike the classic guarantee, still offers reliable information about the coverage of a conformal predictor for small data sizes. We illustrate and validate the methodology in a suite of examples, and implement an open access software solution that can be used alongside common conformal prediction libraries to obtain uncertainty models that fulfil the new guarantee.

</details>


### [33] [Temp-SCONE: A Novel Out-of-Distribution Detection and Domain Generalization Framework for Wild Data with Temporal Shift](https://arxiv.org/abs/2512.04571)
*Aditi Naiknaware,Sanchit Singh,Hajar Homayouni,Salimeh Sekeh*

Main category: cs.LG

TL;DR: Temp-SCONE扩展SCONE以处理动态环境中的时间漂移，通过置信度驱动的正则化损失提升时间一致性，在动态数据上显著改善鲁棒性和OOD检测。


<details>
  <summary>Details</summary>
Motivation: 现有OWL方法（如SCONE）虽然能处理协变量和语义偏移，但假设静态环境，在动态领域性能下降。需要适应动态环境中时间漂移的方法。

Method: 提出Temp-SCONE，基于ATC（平均阈值置信度）的置信度驱动正则化损失，惩罚时间步间预测不稳定性，同时保持SCONE的能量边界分离。

Result: 在动态数据集上，Temp-SCONE显著提升时间漂移下的鲁棒性，获得更高的损坏数据准确率和更可靠的OOD检测。在无时间连续性的数据集上保持可比性能。

Conclusion: Temp-SCONE是向可靠动态环境OWL迈出的一步，理论分析表明其时间稳定性和泛化误差优势，但时间正则化在非连续数据中存在局限性。

Abstract: Open-world learning (OWL) requires models that can adapt to evolving environments while reliably detecting out-of-distribution (OOD) inputs. Existing approaches, such as SCONE, achieve robustness to covariate and semantic shifts but assume static environments, leading to degraded performance in dynamic domains. In this paper, we propose Temp-SCONE, a temporally consistent extension of SCONE designed to handle temporal shifts in dynamic environments. Temp-SCONE introduces a confidence-driven regularization loss based on Average Thresholded Confidence (ATC), penalizing instability in predictions across time steps while preserving SCONE's energy-margin separation. Experiments on dynamic datasets demonstrate that Temp-SCONE significantly improves robustness under temporal drift, yielding higher corrupted-data accuracy and more reliable OOD detection compared to SCONE. On distinct datasets without temporal continuity, Temp-SCONE maintains comparable performance, highlighting the importance and limitations of temporal regularization. Our theoretical insights on temporal stability and generalization error further establish Temp-SCONE as a step toward reliable OWL in evolving dynamic environments.

</details>


### [34] [Exploiting \texttt{ftrace}'s \texttt{function\_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection](https://arxiv.org/abs/2512.04590)
*Kenan Begovic,Abdulaziz Al-Ali,Qutaibah Malluhi*

Main category: cs.LG

TL;DR: 使用Linux内核ftrace框架（特别是函数图追踪器）生成系统级数据用于机器学习应用，在加密检测任务中达到99.28%的准确率


<details>
  <summary>Details</summary>
Motivation: 弥合系统追踪与机器学习之间的鸿沟，为性能监控和安全分析提供创新解决方案。传统方法缺乏有效的系统级数据特征提取方法，需要一种能够从原始追踪数据中提取有意义特征的方法。

Method: 利用Linux内核ftrace框架的函数图追踪器生成系统级追踪数据，提出全面的预处理方法处理原始追踪数据，并提取基于图的特征。将这些特征应用于机器学习算法，包括加密检测和多标签分类任务。

Result: 在真实世界的加密检测任务中取得了99.28%的出色准确率。在额外的多标签分类实验中，能够从追踪数据中准确识别运行的程序，进一步验证了方法的有效性。

Conclusion: 通过将系统追踪与机器学习相结合，为系统行为分析、程序识别和异常检测提供了重要进展。提出的特征提取方法在多个学习算法中都表现出高效性，为性能监控和安全分析开辟了新途径。

Abstract: This paper proposes using the Linux kernel ftrace framework, particularly the function graph tracer, to generate informative system level data for machine learning (ML) applications. Experiments on a real world encryption detection task demonstrate the efficacy of the proposed features across several learning algorithms. The learner faces the problem of detecting encryption activities across a large dataset of files, using function call traces and graph based features. Empirical results highlight an outstanding accuracy of 99.28 on the task at hand, underscoring the efficacy of features derived from the function graph tracer. The results were further validated in an additional experiment targeting a multilabel classification problem, in which running programs were identified from trace data. This work provides comprehensive methodologies for preprocessing raw trace data and extracting graph based features, offering significant advancements in applying ML to system behavior analysis, program identification, and anomaly detection. By bridging the gap between system tracing and ML, this paper paves the way for innovative solutions in performance monitoring and security analytics.

</details>


### [35] [QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction](https://arxiv.org/abs/2512.04596)
*Guanchen Du,Jianlong Xu,Wei Wei*

Main category: cs.LG

TL;DR: QoSDiff：一种基于去噪扩散概率模型的QoS预测框架，无需显式构建用户-服务交互图，通过对抗交互模块捕获高阶关系，在稀疏和噪声数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有QoS预测方法（特别是图神经网络）严重依赖显式用户-服务交互图的构建，这导致可扩展性瓶颈，且在连接稀疏或噪声污染时性能受限。

Method: 提出QoSDiff框架：1）使用去噪扩散概率模型从噪声初始化中恢复潜在结构，避免显式图构建；2）引入对抗交互模块，集成双向混合注意力机制，动态区分信息模式与噪声，实现用户-服务关联的双视角建模。

Result: 在两个大规模真实数据集上的实验表明，QoSDiff显著优于现有最优基线，展现出卓越的跨数据集泛化能力，以及对数据稀疏性和观测噪声的出色鲁棒性。

Conclusion: QoSDiff通过绕过显式图构建需求，利用扩散模型和对抗学习有效解决了QoS预测中的可扩展性和噪声鲁棒性问题，为服务计算提供了更可靠的预测框架。

Abstract: Accurate Quality of Service (QoS) prediction is fundamental to service computing, providing essential data-driven guidance for service selection and ensuring superior user experiences. However, prevalent approaches, particularly Graph Neural Networks (GNNs), heavily rely on constructing explicit user--service interaction graphs. This dependency introduces severe scalability bottlenecks and limits performance when explicit connections are sparse or corrupted by noise. To address these challenges, this paper introduces \emph{QoSDiff}, a novel embedding learning framework that bypasses the prerequisite of explicit graph construction. Specifically, it leverages a denoising diffusion probabilistic model to recover intrinsic latent structures from noisy initializations. To further capture high-order interactions, we propose an adversarial interaction module that integrates a bidirectional hybrid attention mechanism. This adversarial paradigm dynamically distinguishes informative patterns from noise, enabling a dual-perspective modeling of intricate user--service associations. Extensive experiments on two large-scale real-world datasets demonstrate that QoSDiff significantly outperforms state-of-the-art baselines. Notably, the results highlight the framework's superior cross-dataset generalization capability and exceptional robustness against data sparsity and observational noise.

</details>


### [36] [Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space](https://arxiv.org/abs/2512.04601)
*Joey Hong,Kang Liu,Zhan Ling,Jiecao Chen,Sergey Levine*

Main category: cs.LG

TL;DR: NLAC是一种新颖的演员-评论家算法，使用生成式LLM评论家产生自然语言而非标量值来训练LLM智能体，在稀疏奖励的长时程任务中提供更丰富的训练信号。


<details>
  <summary>Details</summary>
Motivation: 传统基于策略梯度的方法在稀疏奖励的长时程任务中存在训练不稳定、样本复杂度高的问题，且自然语言动作空间的探索困难。需要一种更高效、稳定的LLM智能体训练方法。

Method: 提出自然语言演员-评论家算法，使用生成式LLM评论家产生自然语言解释（而非标量奖励）来指导策略改进。该方法可以离策略训练，无需策略梯度，提供更丰富的训练信号。

Result: 在推理、网页浏览和工具使用等混合任务上，NLAC表现出优于现有训练方法的性能，提供了更可扩展和稳定的训练范式。

Conclusion: NLAC通过利用LLM生成自然语言解释而非标量奖励，为LLM智能体训练提供了更丰富、更可操作的训练信号，解决了稀疏奖励长时程任务中的训练挑战，是LLM智能体训练的有前景方向。

Abstract: Large language model (LLM) agents -- LLMs that dynamically interact with an environment over long horizons -- have become an increasingly important area of research, enabling automation in complex tasks involving tool-use, web browsing, and dialogue with people. In the absence of expert demonstrations, training LLM agents has relied on policy gradient methods that optimize LLM policies with respect to an (often sparse) reward function. However, in long-horizon tasks with sparse rewards, learning from trajectory-level rewards can be noisy, leading to training that is unstable and has high sample complexity. Furthermore, policy improvement hinges on discovering better actions through exploration, which can be difficult when actions lie in natural language space. In this paper, we propose Natural Language Actor-Critic (NLAC), a novel actor-critic algorithm that trains LLM policies using a generative LLM critic that produces natural language rather than scalar values. This approach leverages the inherent strengths of LLMs to provide a richer and more actionable training signal; particularly, in tasks with large, open-ended action spaces, natural language explanations for why an action is suboptimal can be immensely useful for LLM policies to reason how to improve their actions, without relying on random exploration. Furthermore, our approach can be trained off-policy without policy gradients, offering a more data-efficient and stable alternative to existing on-policy methods. We present results on a mixture of reasoning, web browsing, and tool-use with dialogue tasks, demonstrating that NLAC shows promise in outperforming existing training approaches and offers a more scalable and stable training paradigm for LLM agents.

</details>


### [37] [Score Matching for Estimating Finite Point Processes](https://arxiv.org/abs/2512.04617)
*Haoqun Cao,Yixuan Zhang,Feng Zhou*

Main category: cs.LG

TL;DR: 提出了一种用于有限点过程的加权分数匹配估计器，解决了现有方法在数学严谨性上的不足，并通过生存分类增强解决了非参数模型的识别问题。


<details>
  <summary>Details</summary>
Motivation: 现有点过程的分数匹配估计器缺乏数学严谨性，特别是在有限点过程上，许多常规假设不再成立。需要建立正式框架来分析分数匹配在有限点过程上的行为。

Method: 通过Janossy测度建立有限点过程的分数匹配框架，提出自回归加权分数匹配估计器。对于非参数模型，提出生存分类增强方法，形成完整的无积分训练目标。

Result: 在合成和真实时空数据集上的实验表明，该方法能准确恢复强度函数，性能与MLE相当但效率更高。

Conclusion: 提出的加权分数匹配框架解决了有限点过程分数匹配的数学严谨性问题，生存分类增强确保了非参数模型的唯一识别，为点过程建模提供了高效替代MLE的方法。

Abstract: Score matching estimators have garnered significant attention in recent years because they eliminate the need to compute normalizing constants, thereby mitigating the computational challenges associated with maximum likelihood estimation (MLE).While several studies have proposed score matching estimators for point processes, this work highlights the limitations of these existing methods, which stem primarily from the lack of a mathematically rigorous analysis of how score matching behaves on finite point processes -- special random configurations on bounded spaces where many of the usual assumptions and properties of score matching no longer hold. To this end, we develop a formal framework for score matching on finite point processes via Janossy measures and, within this framework, introduce an (autoregressive) weighted score-matching estimator, whose statistical properties we analyze in classical parametric settings. For general nonparametric (e.g., deep) point process models, we show that score matching alone does not uniquely identify the ground-truth distribution due to subtle normalization issues, and we propose a simple survival-classification augmentation that yields a complete, integration-free training objective for any intensity-based point process model for spatio-temporal case. Experiments on synthetic and real-world temporal and spatio-temporal datasets, demonstrate that our method accurately recovers intensities and achieves performance comparable to MLE with better efficiency.

</details>


### [38] [Rethinking Decoupled Knowledge Distillation: A Predictive Distribution Perspective](https://arxiv.org/abs/2512.04625)
*Bowen Zheng,Ran Cheng*

Main category: cs.LG

TL;DR: 本文提出广义解耦知识蒸馏(GDKD)，从预测分布角度重新思考DKD，通过改进的解耦策略和关注非顶部logit的蒸馏损失，在各种基准测试中超越了DKD和其他主流知识蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 虽然解耦知识蒸馏(DKD)重新强调了logit知识的重要性并取得了显著进展，但其内在机制值得更深入探索。本文从预测分布的角度重新思考DKD，旨在更好地理解教师模型预测分布对梯度的影响，并改进知识蒸馏效果。

Method: 1. 提出广义解耦知识蒸馏(GDKD)损失，提供更通用的logit解耦方法；2. 分析教师模型预测分布对GDKD损失梯度的影响，发现两个关键见解：顶部logit的分区显著改善非顶部logit的相互关系，以及增强对非顶部logit蒸馏损失的关注能改善它们之间的知识提取；3. 基于这些见解，提出简化的GDKD算法，采用高效的分区策略处理教师模型预测分布的多模态特性。

Result: 在CIFAR-100、ImageNet、Tiny-ImageNet、CUB-200-2011和Cityscapes等多个基准测试上的综合实验表明，GDKD在性能上超越了原始DKD和其他领先的知识蒸馏方法。

Conclusion: 从预测分布角度重新思考DKD能够揭示被忽视的关键机制，提出的GDKD方法通过改进的解耦策略和关注非顶部logit的蒸馏损失，在各种视觉任务中实现了更有效的知识蒸馏，代码已开源。

Abstract: In the history of knowledge distillation, the focus has once shifted over time from logit-based to feature-based approaches. However, this transition has been revisited with the advent of Decoupled Knowledge Distillation (DKD), which re-emphasizes the importance of logit knowledge through advanced decoupling and weighting strategies. While DKD marks a significant advancement, its underlying mechanisms merit deeper exploration. As a response, we rethink DKD from a predictive distribution perspective. First, we introduce an enhanced version, the Generalized Decoupled Knowledge Distillation (GDKD) loss, which offers a more versatile method for decoupling logits. Then we pay particular attention to the teacher model's predictive distribution and its impact on the gradients of GDKD loss, uncovering two critical insights often overlooked: (1) the partitioning by the top logit considerably improves the interrelationship of non-top logits, and (2) amplifying the focus on the distillation loss of non-top logits enhances the knowledge extraction among them. Utilizing these insights, we further propose a streamlined GDKD algorithm with an efficient partition strategy to handle the multimodality of teacher models' predictive distribution. Our comprehensive experiments conducted on a variety of benchmarks, including CIFAR-100, ImageNet, Tiny-ImageNet, CUB-200-2011, and Cityscapes, demonstrate GDKD's superior performance over both the original DKD and other leading knowledge distillation methods. The code is available at https://github.com/ZaberKo/GDKD.

</details>


### [39] [Federated Learning for Anomaly Detection in Maritime Movement Data](https://arxiv.org/abs/2512.04635)
*Anita Graser,Axel Weißenfeld,Clemens Heistracher,Melitta Dragaschnig,Peter Widhalm*

Main category: cs.LG

TL;DR: M3fed是一种用于运动异常检测的联邦学习新方法，旨在提升数据隐私并降低通信成本


<details>
  <summary>Details</summary>
Motivation: 传统集中式机器学习在运动异常检测中存在数据隐私泄露风险和通信成本高的问题，需要一种既能保护隐私又能降低通信开销的解决方案

Method: 提出M3fed框架，采用新颖的联邦学习策略，在分布式设备上训练运动异常检测模型，避免原始数据集中传输

Result: 通过海事AIS数据实验验证，M3fed在保持模型质量的同时显著降低了通信成本，与集中式M3模型相比具有竞争力

Conclusion: M3fed为运动异常检测提供了一种有效的联邦学习解决方案，在保护数据隐私和降低通信成本方面具有实际应用价值

Abstract: This paper introduces M3fed, a novel solution for federated learning of movement anomaly detection models. This innovation has the potential to improve data privacy and reduce communication costs in machine learning for movement anomaly detection. We present the novel federated learning (FL) strategies employed to train M3fed, perform an example experiment with maritime AIS data, and evaluate the results with respect to communication costs and FL model quality by comparing classic centralized M3 and the new federated M3fed.

</details>


### [40] [Contract-Governed Training for Earth Observation: Observed Service Agreement Graphs and Coverage-Accuracy Trade-offs](https://arxiv.org/abs/2512.04644)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 提出OSAG框架，通过契约化采样策略确保地球观测模型训练时各区域/类别获得目标服务份额，平衡全局精度与公平性


<details>
  <summary>Details</summary>
Motivation: 传统EO模型训练采用隐式采样策略，只优化全局精度，无法保证不同区域、类别或关键层级的公平服务覆盖

Method: 引入契约治理训练范式，将样本分组为服务契约，建立OSAG框架监控契约级覆盖率，通过契约归一化采样权重驱动经验覆盖率向目标份额收敛

Result: 在AVIRIS高光谱和Sentinel-2多光谱数据集上，OSAG显著降低优先级覆盖误差，保持全局精度同时提升高优先级精度；精细契约设计可降低治理成本

Conclusion: OSAG为EO模型训练提供可解释的治理框架，通过契约设计和参数调节实现精度与公平性的明确权衡

Abstract: Earth observation (EO) models are frequently trained under implicit sampling policies that optimize global accuracy but provide no explicit guarantees on who (which regions, classes, or mission-critical strata) is being served throughout training. This paper introduces a contract-governed training paradigm for EO in which training samples are grouped into service contracts -- semantically meaningful units such as (dataset, region, rare-crop indicator) -- and each contract is assigned a target service share. We instantiate this paradigm as an Observed Service Agreement Graph (OSAG), a lightweight governance layer that (i) monitors contract-level exposure (coverage) during optimization, (ii) drives empirical coverage toward target shares via contract-normalized sampling weights, and (iii) exposes explicit accuracy-governance trade-offs through two knobs: a sampling mixture coefficient alpha and a contract-regularization weight lambda_C. We provide a compact theory in a toy setting: OSAG sampling concentrates empirical coverage to targets; coverage deviations upper-bound service-risk deviations; and contract design (coarse vs. fine) modulates governance cost. Experiments on AVIRIS hyperspectral scenes (Indian Pines plus Salinas) and multispectral Sentinel-2 EuroSAT demonstrate that OSAG can substantially reduce priority coverage error while maintaining global accuracy and improving high-priority accuracy. A EuroSAT coarse-vs-fine contract ablation further evidences how semantically refined contracts can reduce the accuracy cost per unit of governance improvement.

</details>


### [41] [TimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation](https://arxiv.org/abs/2512.04694)
*Baris Yilmaz,Bevan Deniz Cilgin,Erdem Akagündüz,Salih Tileylioglu*

Main category: cs.LG

TL;DR: 提出TimesNet-Gen时间域条件生成器，用于基于站点特定条件生成强地震动记录，通过HVSR曲线和基频分布评估生成质量


<details>
  <summary>Details</summary>
Motivation: 准确的地震风险评估需要能够反映局部场地条件对地震动特征影响的模型，数据驱动方法通过学习记录中的场地控制特征提供了有前景的方向

Method: 引入TimesNet-Gen时间域条件生成器，使用站点特定的潜在瓶颈，从时域加速度计记录生成强地震动

Result: 通过比较真实和生成记录的HVSR曲线和基频f0分布，TimesNet-Gen实现了强的站点对齐，在站点特定强地震动合成方面优于基于频谱图的VAE基线

Conclusion: TimesNet-Gen在站点特定地震动生成方面表现优异，代码已开源，为地震风险评估提供了有效的数据驱动工具

Abstract: Effective earthquake risk reduction relies on accurate site-specific evaluations. This requires models that can represent the influence of local site conditions on ground motion characteristics. In this context, data driven approaches that learn site controlled signatures from recorded ground motions offer a promising direction. We address strong ground motion generation from time-domain accelerometer records and introduce the TimesNet-Gen, a time-domain conditional generator. The approach uses a station specific latent bottleneck. We evaluate generation by comparing HVSR curves and fundamental site-frequency $f_0$ distributions between real and generated records per station, and summarize station specificity with a score based on the $f_0$ distribution confusion matrices. TimesNet-Gen achieves strong station-wise alignment and compares favorably with a spectrogram-based conditional VAE baseline for site-specific strong motion synthesis. Our codes are available via https://github.com/brsylmz23/TimesNet-Gen.

</details>


### [42] [TRINITY: An Evolved LLM Coordinator](https://arxiv.org/abs/2512.04695)
*Jinglue Xu,Qi Sun,Peter Schwendeman,Stefan Nielsen,Edoardo Cetin,Yujin Tang*

Main category: cs.LG

TL;DR: Trinity提出一个轻量级协调器，通过角色分配机制协调多个大语言模型协作，在多种任务上超越单个模型和现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有权重融合方法受限于架构不匹配和闭源API问题，需要一种能够有效协调多个基础模型协作的新方法。

Method: 使用轻量级协调器（约0.6B参数的小型语言模型+约10K参数的轻量头部），通过进化策略优化，在多轮查询中为选定的LLM分配三种角色（思考者、工作者、验证者）。

Result: 在编码、数学、推理和领域知识任务上持续超越单个模型和现有方法，在标准基准测试中达到最先进水平，LiveCodeBench得分86.2%。

Conclusion: 协调器的隐藏状态表示提供丰富的输入上下文化，在高维度和严格预算约束下，可分离协方差矩阵自适应进化策略相比强化学习等方法具有优势。

Abstract: Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. Trinity addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model (approximately $0.6$B parameters) and a lightweight head (approximately $10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. Trinity processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (Thinker, Worker, or Verifier) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Experiments show that Trinity consistently outperforms individual models and existing methods across coding, math, reasoning, and domain knowledge tasks, and generalizes robustly to out-of-distribution tasks. On standard benchmarks, Trinity achieves state-of-the-art results, including a score of 86.2% on LiveCodeBench. Theoretical and empirical analyses identify two main factors behind this performance: (1) the coordinator's hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy offers advantages over reinforcement learning, imitation learning, and random search by exploiting potential block-epsilon-separability.

</details>


### [43] [Towards Continuous-Time Approximations for Stochastic Gradient Descent without Replacement](https://arxiv.org/abs/2512.04703)
*Stefan Perko*

Main category: cs.LG

TL;DR: 提出基于"epoch Brownian motion"的随机连续时间近似方法，用于分析无放回随机梯度下降(SGDo)，证明了强凸目标下的几乎必然收敛性，并给出了收敛速率上界。


<details>
  <summary>Details</summary>
Motivation: 实际机器学习训练中广泛使用基于epoch的无放回随机梯度下降(SGDo)，但其数学理论相比有放回和单次遍历版本研究不足，需要建立更完善的理论分析框架。

Method: 提出基于Young微分方程的随机连续时间近似方法，使用"epoch Brownian motion"作为驱动过程，学习率调度采用$u_t = \frac{1}{(1+t)^β}, β\in (0,1)$形式。

Result: 证明了强凸目标下连续时间近似的几乎必然收敛性，计算了渐近收敛速率的上界，该上界优于或等于先前SGDo的结果。

Conclusion: 提出的随机连续时间近似方法为分析SGDo提供了有效的理论框架，收敛性结果和速率上界改进了现有理论，有助于更好地理解实际训练算法的数学性质。

Abstract: Gradient optimization algorithms using epochs, that is those based on stochastic gradient descent without replacement (SGDo), are predominantly used to train machine learning models in practice. However, the mathematical theory of SGDo and related algorithms remain underexplored compared to their "with replacement" and "one-pass" counterparts. In this article, we propose a stochastic, continuous-time approximation to SGDo with additive noise based on a Young differential equation driven by a stochastic process we call an "epoched Brownian motion". We show its usefulness by proving the almost sure convergence of the continuous-time approximation for strongly convex objectives and learning rate schedules of the form $u_t = \frac{1}{(1+t)^β}, β\in (0,1)$. Moreover, we compute an upper bound on the asymptotic rate of almost sure convergence, which is as good or better than previous results for SGDo.

</details>


### [44] [A Tutorial on Regression Analysis: From Linear Models to Deep Learning -- Lecture Notes on Artificial Intelligence](https://arxiv.org/abs/2512.04747)
*Jingyuan Wang,Jiahao Ji*

Main category: cs.LG

TL;DR: 这是一份回归分析课程的讲义笔记，系统介绍了从线性回归到神经网络非线性回归的各种回归方法，旨在为具备基础数学知识的学生提供全面的回归分析理解。


<details>
  <summary>Details</summary>
Motivation: 为智能计算课程群（包括人工智能、数据挖掘、机器学习和模式识别课程）的学生提供回归分析的全面教学材料，假设学生只具备基础大学数学知识（微积分、线性代数、概率论），无需额外参考资料即可理解。

Method: 通过系统化的讲义结构，涵盖线性回归、逻辑回归、多项式回归、基函数模型、核方法和神经网络非线性回归等核心内容，包括损失函数设计、参数估计原理、普通最小二乘法、梯度优化算法及其变体，以及Ridge和LASSO正则化技术。

Result: 提供了一套完整的回归分析教学材料，通过详细的数学推导、示例说明和直观的可视化解释，帮助学生理解回归模型的构建、优化以及特征与响应变量之间的潜在关系。

Conclusion: 这些讲义笔记通过连接经典统计建模和现代机器学习实践，为学生进一步学习高级人工智能模型奠定了坚实的概念和技术基础。

Abstract: This article serves as the regression analysis lecture notes in the Intelligent Computing course cluster (including the courses of Artificial Intelligence, Data Mining, Machine Learning, and Pattern Recognition). It aims to provide students -- who are assumed to possess only basic university-level mathematics (i.e., with prerequisite courses in calculus, linear algebra, and probability theory) -- with a comprehensive and self-contained understanding of regression analysis without requiring any additional references. The lecture notes systematically introduce the fundamental concepts, modeling components, and theoretical foundations of regression analysis, covering linear regression, logistic regression, multinomial logistic regression, polynomial regression, basis-function models, kernel-based methods, and neural-network-based nonlinear regression. Core methodological topics include loss-function design, parameter-estimation principles, ordinary least squares, gradient-based optimization algorithms and their variants, as well as regularization techniques such as Ridge and LASSO regression. Through detailed mathematical derivations, illustrative examples, and intuitive visual explanations, the materials help students understand not only how regression models are constructed and optimized, but also how they reveal the underlying relationships between features and response variables. By bridging classical statistical modeling and modern machine-learning practice, these lecture notes aim to equip students with a solid conceptual and technical foundation for further study in advanced artificial intelligence models.

</details>


### [45] [RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting](https://arxiv.org/abs/2512.04752)
*Siqi Wang,Hailong Yang,Junjie Zhu,Xuezhu Wang,Yufan Xu,Depei Qian*

Main category: cs.LG

TL;DR: RLHFSpec：首个将推测解码技术整合到RLHF生成阶段的系统，通过自适应推测解码和样本重分配加速RLHF执行


<details>
  <summary>Details</summary>
Motivation: RLHF包含生成、推理和训练三个阶段，其中生成阶段是整个执行过程的瓶颈，需要优化以提升整体性能

Method: 提出RLHFSpec系统：1) 自适应推测解码，采用工作负载感知的草稿策略选择机制；2) 样本重分配，通过高效样本迁移机制充分利用GPU资源

Result: 实验结果显示，RLHFSpec在生成阶段相比现有工作获得更高吞吐量，并且由于有效缓解了生成瓶颈，在整个RLHF执行中显示出显著的性能加速

Conclusion: RLHFSpec成功将推测解码技术应用于RLHF生成阶段，通过自适应策略和资源优化有效加速了RLHF执行过程

Abstract: Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.

</details>


### [46] [MemLoRA: Distilling Expert Adapters for On-Device Memory Systems](https://arxiv.org/abs/2512.04763)
*Massimo Bini,Ondrej Bohdal,Umberto Michieli,Zeynep Akata,Mete Ozay,Taha Ceritli*

Main category: cs.LG

TL;DR: MemLoRA：为小型语言模型配备专用记忆适配器，实现本地部署的记忆增强系统；MemLoRA-V扩展支持视觉理解，在保持文本任务性能的同时大幅提升视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有记忆增强系统依赖大型语言模型，成本过高无法本地部署；小型模型性能不足；现有系统缺乏原生视觉能力，限制了多模态应用。

Method: 提出MemLoRA系统，为小型语言模型配备专门的记忆适配器，基于知识蒸馏原理分别训练知识提取、记忆更新和记忆增强生成三个适配器；MemLoRA-V扩展集成小型视觉语言模型，支持原生视觉理解。

Result: 在文本任务上，MemLoRA超越10倍大的基线模型（如Gemma2-27B），性能接近60倍大的模型（如GPT-OSS-120B）；在视觉任务上，MemLoRA-V比基于字幕的方法大幅提升（81.3 vs 23.7准确率），同时保持文本任务性能。

Conclusion: MemLoRA系统成功实现了高效、准确的本地记忆操作，无需云端依赖；MemLoRA-V扩展证明了在多模态上下文中的有效性，为设备端智能助手提供了可行解决方案。

Abstract: Memory-augmented Large Language Models (LLMs) have demonstrated remarkable consistency during prolonged dialogues by storing relevant memories and incorporating them as context. Such memory-based personalization is also key in on-device settings that allow users to keep their conversations and data private. However, memory-augmented systems typically rely on LLMs that are too costly for local on-device deployment. Even though Small Language Models (SLMs) are more suitable for on-device inference than LLMs, they cannot achieve sufficient performance. Additionally, these LLM-based systems lack native visual capabilities, limiting their applicability in multimodal contexts. In this paper, we introduce (i) MemLoRA, a novel memory system that enables local deployment by equipping SLMs with specialized memory adapters, and (ii) its vision extension MemLoRA-V, which integrates small Vision-Language Models (SVLMs) to memory systems, enabling native visual understanding. Following knowledge distillation principles, each adapter is trained separately for specific memory operations$\unicode{x2013}$knowledge extraction, memory update, and memory-augmented generation. Equipped with memory adapters, small models enable accurate on-device memory operations without cloud dependency. On text-only operations, MemLoRA outperforms 10$\times$ larger baseline models (e.g., Gemma2-27B) and achieves performance comparable to 60$\times$ larger models (e.g., GPT-OSS-120B) on the LoCoMo benchmark. To evaluate visual understanding operations instead, we extend LoCoMo with challenging Visual Question Answering tasks that require direct visual reasoning. On this, our VLM-integrated MemLoRA-V shows massive improvements over caption-based approaches (81.3 vs. 23.7 accuracy) while keeping strong performance in text-based tasks, demonstrating the efficacy of our method in multimodal contexts.

</details>


### [47] [Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection](https://arxiv.org/abs/2512.05069)
*Mohammad Arif Rasyidi,Omar Alhussein,Sami Muhaidat,Ernesto Damiani*

Main category: cs.LG

TL;DR: 首次大规模评估混合量子-经典自编码器在异常入侵检测中的性能，发现最佳配置下可匹配或超越经典方法，在零日攻击检测中表现出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无监督异常入侵检测需要能够泛化到训练中未观察到的攻击模式的模型。目前缺乏对混合量子-经典自编码器在该任务中的大规模评估。

Method: 构建统一的实验框架，迭代关键量子设计选择：量子层放置、测量方法、变分与非变分公式、潜在空间正则化。在三个基准NIDS数据集上进行实验，包括模拟门噪声实验。

Result: HQC自编码器在最佳配置下可匹配或超越经典性能，但对架构决策更敏感。在零日评估中，配置良好的HQC模型比经典和监督基线提供更强、更稳定的泛化能力。模拟门噪声实验显示早期性能下降。

Conclusion: 首次提供了HQC自编码器在网络入侵检测中的数据驱动特性描述，概述了决定其实用可行性的关键因素，并指出需要噪声感知的HQC设计。

Abstract: Unsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that iterates over key quantum design choices, including quantum-layer placement, measurement approach, variational and non-variational formulations, and latent-space regularization. Experiments across three benchmark NIDS datasets show that HQC autoencoders can match or exceed classical performance in their best configurations, although they exhibit higher sensitivity to architectural decisions. Under zero-day evaluation, well-configured HQC models provide stronger and more stable generalization than classical and supervised baselines. Simulated gate-noise experiments reveal early performance degradation, indicating the need for noise-aware HQC designs. These results provide the first data-driven characterization of HQC autoencoder behavior for network intrusion detection and outline key factors that govern their practical viability. All experiment code and configurations are available at https://github.com/arasyi/hqcae-network-intrusion-detection.

</details>


### [48] [A result relating convex n-widths to covering numbers with some applications to neural networks](https://arxiv.org/abs/2512.04912)
*Jonathan Baxter,Peter Bartlett*

Main category: cs.LG

TL;DR: 本文研究高维函数类的逼近问题，通过分析"凸核"的覆盖数来刻画神经网络等函数类的逼近能力，突破了传统高维逼近的维度诅咒。


<details>
  <summary>Details</summary>
Motivation: 传统高维函数逼近存在维度诅咒问题，但实际中许多高维模式识别问题（如人脸识别）能用少量特征的线性组合很好解决。需要寻找那些能被小特征集有效逼近的高维函数类的特征化方法。

Method: 建立函数类逼近误差与其"凸核"覆盖数的一般关系。针对单隐层神经网络，用单个隐节点函数类的覆盖数来界定凸核的覆盖数，进而应用标准结果得到神经网络类的逼近率上界。

Result: 获得了神经网络类逼近率的上界估计，为理解神经网络在高维空间中的有效逼近能力提供了理论框架。

Conclusion: 通过凸核覆盖数的分析，本文为高维函数类（特别是神经网络）的有效逼近提供了理论解释，解释了为什么某些高维问题能避免维度诅咒。

Abstract: In general, approximating classes of functions defined over high-dimensional input spaces by linear combinations of a fixed set of basis functions or ``features'' is known to be hard. Typically, the worst-case error of the best basis set decays only as fast as $Θ\(n^{-1/d}\)$, where $n$ is the number of basis functions and $d$ is the input dimension. However, there are many examples of high-dimensional pattern recognition problems (such as face recognition) where linear combinations of small sets of features do solve the problem well. Hence these function classes do not suffer from the ``curse of dimensionality'' associated with more general classes. It is natural then, to look for characterizations of high-dimensional function classes that nevertheless are approximated well by linear combinations of small sets of features. In this paper we give a general result relating the error of approximation of a function class to the covering number of its ``convex core''. For one-hidden-layer neural networks, covering numbers of the class of functions computed by a single hidden node upper bound the covering numbers of the convex core. Hence, using standard results we obtain upper bounds on the approximation rate of neural network classes.

</details>


### [49] [Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty](https://arxiv.org/abs/2512.04918)
*Kailiang Liu,Ying Chen,Ralf Borndörfer,Thorsten Koch*

Main category: cs.LG

TL;DR: 提出一个基于多智能体强化学习的实时手术调度框架，通过集中训练分散执行的方式优化手术室资源分配，在模拟实验中优于多种启发式规则。


<details>
  <summary>Details</summary>
Motivation: 解决医院手术室实时调度中的多目标决策问题，包括平衡择期手术吞吐量、紧急需求、延迟、序列依赖的准备时间以及加班时间等不确定性因素。

Method: 将问题建模为合作马尔可夫博弈，采用多智能体强化学习框架（每个手术室为一个智能体），使用PPO算法进行集中训练，通过序列分配协议构建无冲突的联合调度方案，并引入混合整数预调度提供参考起始时间。

Result: 在模拟实验中（6个手术室、8种手术类型、随机紧急到达），学习到的策略在7个指标和3个评估子集上优于6种基于规则的启发式方法，并能量化与事后MIP最优解的差距。策略分析显示可解释的行为模式。

Conclusion: 该方法为实时手术调度提供了一个实用、可解释、可调优的数据驱动补充方案，但存在手术室同质性和未考虑明确人员约束等局限性。

Abstract: Intraday surgical scheduling is a multi-objective decision problem under uncertainty-balancing elective throughput, urgent and emergency demand, delays, sequence-dependent setups, and overtime. We formulate the problem as a cooperative Markov game and propose a multi-agent reinforcement learning (MARL) framework in which each operating room (OR) is an agent trained with centralized training and decentralized execution. All agents share a policy trained via Proximal Policy Optimization (PPO), which maps rich system states to actions, while a within-epoch sequential assignment protocol constructs conflict-free joint schedules across ORs. A mixed-integer pre-schedule provides reference starting times for electives; we impose type-specific quadratic delay penalties relative to these references and a terminal overtime penalty, yielding a single reward that captures throughput, timeliness, and staff workload. In simulations reflecting a realistic hospital mix (six ORs, eight surgery types, random urgent and emergency arrivals), the learned policy outperforms six rule-based heuristics across seven metrics and three evaluation subsets, and, relative to an ex post MIP oracle, quantifies optimality gaps. Policy analytics reveal interpretable behavior-prioritizing emergencies, batching similar cases to reduce setups, and deferring lower-value electives. We also derive a suboptimality bound for the sequential decomposition under simplifying assumptions. We discuss limitations-including OR homogeneity and the omission of explicit staffing constraints-and outline extensions. Overall, the approach offers a practical, interpretable, and tunable data-driven complement to optimization for real-time OR scheduling.

</details>


### [50] [CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent](https://arxiv.org/abs/2512.04949)
*Leyang Shen,Yang Zhang,Chun Kai Ling,Xiaoyan Zhao,Tat-Seng Chua*

Main category: cs.LG

TL;DR: CARL是一种面向多步智能体的关键动作强化学习算法，通过专注于关键动作的训练来提高性能和效率


<details>
  <summary>Details</summary>
Motivation: 传统群体级策略优化算法在多步任务中假设每个动作贡献相等，这与现实不符。分析发现只有少数动作对最终结果起决定性作用，因此需要专注于关键动作的训练方法。

Method: CARL算法通过提供动作级优化信号来聚焦训练：对高关键性动作进行专门优化，同时将低关键性动作排除在模型更新之外。

Result: 大量实验表明，CARL在多种评估设置下，在训练和推理阶段都实现了更强的性能和更高的效率。

Conclusion: 专注于关键动作的强化学习算法CARL能够有效解决多步智能体训练中的优化问题，显著提升性能和效率。

Abstract: Agents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumption that each action holds equal contribution, which deviates significantly from reality. Our analysis reveals that only a small fraction of actions are critical in determining the final outcome. Building on this insight, we propose CARL, a critical-action-focused reinforcement learning algorithm tailored for multi-step agents. CARL achieves focused training through providing action-level optimization signals for high-criticality actions while excluding low-criticality actions from model update. Extensive experiments demonstrate that CARL achieves both stronger performance and higher efficiency during training and inference across diverse evaluation settings.

</details>


### [51] [Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning](https://arxiv.org/abs/2512.04958)
*Roberto Cipollone,Luca Iocchi,Matteo Leonetti*

Main category: cs.LG

TL;DR: 本文提出了一种新的可实现的抽象概念，用于分层强化学习，通过组合选项将高层策略转换为接近最优的低层策略，并提出了具有理论保证的RARL算法。


<details>
  <summary>Details</summary>
Motivation: 分层强化学习旨在通过模块化方式更高效地解决大规模MDP问题，但现有MDP抽象概念表达能力有限或缺乏形式化效率保证。本文旨在解决这些基本问题。

Method: 提出"可实现抽象"的新概念，避免非马尔可夫性问题；证明任何抽象策略可通过选项组合转换为接近最优的低层策略；提出RARL算法，利用输入的可实现抽象返回组合式接近最优的低层策略。

Result: RARL算法具有概率近似正确性保证，在多项式样本数内收敛，且对抽象中的不准确性具有鲁棒性。选项可表示为特定约束MDP的解。

Conclusion: 可实现抽象为分层强化学习提供了具有形式化保证的框架，RARL算法能够有效利用抽象信息生成接近最优的组合式策略，解决了现有方法表达能力和理论保证不足的问题。

Abstract: The main focus of Hierarchical Reinforcement Learning (HRL) is studying how large Markov Decision Processes (MDPs) can be more efficiently solved when addressed in a modular way, by combining partial solutions computed for smaller subtasks. Despite their very intuitive role for learning, most notions of MDP abstractions proposed in the HRL literature have limited expressive power or do not possess formal efficiency guarantees. This work addresses these fundamental issues by defining Realizable Abstractions, a new relation between generic low-level MDPs and their associated high-level decision processes. The notion we propose avoids non-Markovianity issues and has desirable near-optimality guarantees. Indeed, we show that any abstract policy for Realizable Abstractions can be translated into near-optimal policies for the low-level MDP, through a suitable composition of options. As demonstrated in the paper, these options can be expressed as solutions of specific constrained MDPs. Based on these findings, we propose RARL, a new HRL algorithm that returns compositional and near-optimal low-level policies, taking advantage of the Realizable Abstraction given in the input. We show that RARL is Probably Approximately Correct, it converges in a polynomial number of samples, and it is robust to inaccuracies in the abstraction.

</details>


### [52] [Efficient Generative Transformer Operators For Million-Point PDEs](https://arxiv.org/abs/2512.04974)
*Armand Kassaï Koupaï,Lise Le Boudec,Patrick Gallinari*

Main category: cs.LG

TL;DR: ECHO是一个用于生成百万点PDE轨迹的transformer-operator框架，通过层次卷积编码解码架构、稀疏输入高分辨率生成策略和生成式建模范式，解决了现有神经算子在密集网格上的可扩展性、动态展开误差累积和任务特定设计等问题。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在求解偏微分方程时存在三个主要限制：在密集网格上可扩展性差、动态展开过程中误差累积、以及任务特定设计。这些限制阻碍了神经算子在实践中的广泛应用，特别是在需要高分辨率、长期预测的复杂PDE系统中。

Method: ECHO采用三个关键创新：1）层次卷积编码解码架构，实现100倍时空压缩同时保持网格点保真度；2）训练和适应策略，支持从稀疏输入网格生成高分辨率PDE解；3）生成式建模范式，学习完整轨迹段以减轻长期误差漂移。训练策略将表示学习与下游任务监督解耦，支持轨迹生成、正反问题、插值等多种任务。

Result: 在具有复杂几何、高频动态和长期视野的多样化PDE系统上，ECHO在百万点模拟中展示了最先进的性能。模型支持条件生成和无条件生成，能够处理多种任务。

Conclusion: ECHO通过创新的架构设计、训练策略和生成式建模方法，成功解决了现有神经算子的关键限制，为大规模PDE模拟提供了高效、可扩展的解决方案，在复杂PDE系统的百万点模拟中表现出色。

Abstract: We introduce ECHO, a transformer-operator framework for generating million-point PDE trajectories. While existing neural operators (NOs) have shown promise for solving partial differential equations, they remain limited in practice due to poor scalability on dense grids, error accumulation during dynamic unrolling, and task-specific design. ECHO addresses these challenges through three key innovations. (i) It employs a hierarchical convolutional encode-decode architecture that achieves a 100 $\times$ spatio-temporal compression while preserving fidelity on mesh points. (ii) It incorporates a training and adaptation strategy that enables high-resolution PDE solution generation from sparse input grids. (iii) It adopts a generative modeling paradigm that learns complete trajectory segments, mitigating long-horizon error drift. The training strategy decouples representation learning from downstream task supervision, allowing the model to tackle multiple tasks such as trajectory generation, forward and inverse problems, and interpolation. The generative model further supports both conditional and unconditional generation. We demonstrate state-of-the-art performance on million-point simulations across diverse PDE systems featuring complex geometries, high-frequency dynamics, and long-term horizons.

</details>


### [53] [Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression](https://arxiv.org/abs/2512.05030)
*Xuan Li,Samuel Bello*

Main category: cs.LG

TL;DR: 提出一种双路径区域引导注意力网络，用于从鞋垫传感器数据准确估计三维地面反作用力/力矩，在公开数据集上验证了优于CNN和CNN-LSTM的性能。


<details>
  <summary>Details</summary>
Motivation: 三维地面反作用力/力矩的准确估计对生物力学研究和临床康复评估至关重要，本研究专注于基于鞋垫传感器的GRF/GRM估计，并在公开行走数据集上验证方法。

Method: 提出双路径区域引导注意力网络，整合解剖学启发的空间先验和时间先验到区域级注意力机制，同时互补路径捕获完整传感器场的上下文信息，两条路径联合训练，输出结合产生最终预测。

Result: 模型在两个数据集上优于CNN和CNN-LSTM基线，在鞋垫数据集上实现六分量平均NRMSE 5.78%，在公开数据集上垂直地面反作用力NRMSE为1.42%。

Conclusion: 该方法在地面反作用力和力矩估计方面表现出稳健性能，验证了双路径区域引导注意力网络的有效性。

Abstract: Accurate estimation of three-dimensional ground reaction forces and moments (GRFs/GRMs) is crucial for both biomechanics research and clinical rehabilitation evaluation. In this study, we focus on insole-based GRF/GRM estimation and further validate our approach on a public walking dataset. We propose a Dual-Path Region-Guided Attention Network that integrates anatomy-inspired spatial priors and temporal priors into a region-level attention mechanism, while a complementary path captures context from the full sensor field. The two paths are trained jointly and their outputs are combined to produce the final GRF/GRM predictions. Conclusions: Our model outperforms strong baseline models, including CNN and CNN-LSTM architectures on two datasets, achieving the lowest six-component average NRMSE of 5.78% on the insole dataset and 1.42% for the vertical ground reaction force on the public dataset. This demonstrates robust performance for ground reaction force and moment estimation.

</details>


### [54] [SuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals](https://arxiv.org/abs/2512.05038)
*Cassandra Goldberg,Chaehyeon Kim,Adam Stein,Eric Wong*

Main category: cs.LG

TL;DR: 论文提出SuperActivator机制，发现在概念检测中，虽然概念内和概念外的激活分布重叠严重，但概念分布极端高尾部的token激活能可靠指示概念存在，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 概念向量旨在通过将内部表示与人类可理解的语义联系起来增强模型可解释性，但其效用常受噪声和不一致激活的限制。现有方法难以从重叠的激活分布中可靠检测概念。

Method: 提出SuperActivator机制：聚焦于概念分布极端高尾部的token激活作为可靠信号。通过比较标准向量基方法、提示方法和SuperActivator tokens在不同模态、架构、层和概念提取技术下的表现。

Result: SuperActivator tokens在图像和文本模态、不同模型架构、模型层和概念提取技术中一致优于标准方法，F1分数提升高达14%。还能改进概念的特征归因。

Conclusion: SuperActivator机制揭示了概念检测中的关键模式，极端高尾部的激活提供了可靠的概念存在信号，显著提升了概念检测性能，并为改进特征归因提供了新途径。

Abstract: Concept vectors aim to enhance model interpretability by linking internal representations with human-understandable semantics, but their utility is often limited by noisy and inconsistent activations. In this work, we uncover a clear pattern within the noise, which we term the SuperActivator Mechanism: while in-concept and out-of-concept activations overlap considerably, the token activations in the extreme high tail of the in-concept distribution provide a reliable signal of concept presence. We demonstrate the generality of this mechanism by showing that SuperActivator tokens consistently outperform standard vector-based and prompting concept detection approaches, achieving up to a 14% higher F1 score across image and text modalities, model architectures, model layers, and concept extraction techniques. Finally, we leverage SuperActivator tokens to improve feature attributions for concepts.

</details>


### [55] [Multi-LLM Collaboration for Medication Recommendation](https://arxiv.org/abs/2512.05066)
*Huascar Sanchez,Briland Hitaj,Jules Bergmann,Linda Briesemeister*

Main category: cs.LG

TL;DR: 该研究将LLM Chemistry框架应用于临床用药推荐，通过建模多LLM间的协作兼容性来构建更可靠、稳定和校准的AI医疗助手。


<details>
  <summary>Details</summary>
Motivation: 随着医疗领域越来越多地依赖AI进行临床决策支持，确保模型推理的可靠性成为关键挑战。单个大语言模型容易产生幻觉和不一致，而简单的模型集成往往无法提供稳定可信的推荐。

Method: 基于先前提出的LLM Chemistry框架（量化LLM间的协作兼容性），应用于临床用药推荐场景。通过Chemistry启发的交互建模指导多LLM协作，构建有效（利用互补优势）、稳定（产生一致质量）和校准（最小化干扰和错误放大）的集成模型。

Result: 在真实世界临床场景中评估了基于Chemistry的多LLM协作策略，初步结果显示该方法能够生成可信的、针对患者个体的用药推荐，表明LLM Chemistry指导的协作可能为临床实践中可靠可信的AI助手提供有前景的路径。

Conclusion: LLM Chemistry框架指导的多模型协作方法在提高临床用药推荐的可靠性方面显示出潜力，为解决AI医疗助手的可信性问题提供了新思路。

Abstract: As healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fail to deliver stable and credible recommendations. Building on our previous work on LLM Chemistry, which quantifies the collaborative compatibility among LLMs, we apply this framework to improve the reliability in medication recommendation from brief clinical vignettes. Our approach leverages multi-LLM collaboration guided by Chemistry-inspired interaction modeling, enabling ensembles that are effective (exploiting complementary strengths), stable (producing consistent quality), and calibrated (minimizing interference and error amplification). We evaluate our Chemistry-based Multi-LLM collaboration strategy on real-world clinical scenarios to investigate whether such interaction-aware ensembles can generate credible, patient-specific medication recommendations. Preliminary results are encouraging, suggesting that LLM Chemistry-guided collaboration may offer a promising path toward reliable and trustworthy AI assistants in clinical practice.

</details>


### [56] [David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?](https://arxiv.org/abs/2512.05073)
*Shashwat Shankar,Subhranshu Pandey,Innocent Dengkhw Mochahari,Bhabesh Mali,Animesh Basak Chowdhury,Sukanta Bhattacharjee,Chandan Karfa*

Main category: cs.LG

TL;DR: 小型语言模型结合智能代理框架在硬件设计任务中能以极低成本达到接近大语言模型的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理需要大量计算和能源，使得领域特定任务昂贵且不可持续。随着基础模型不断扩展，需要探索是否在硬件设计中"越大越好"。

Method: 评估小型语言模型结合精心设计的智能代理框架，在NVIDIA的综合Verilog设计问题基准上进行测试，通过任务分解、迭代反馈和修正的代理工作流程

Result: 智能代理工作流程不仅能以极低成本实现接近LLM的性能，还能为代理创造学习机会

Conclusion: 智能代理框架为复杂设计任务提供了高效、自适应的解决方案，挑战了"越大越好"的传统观念

Abstract: Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA's Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.

</details>


### [57] [OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design](https://arxiv.org/abs/2512.05080)
*Ian Dunn,Liv Toft,Tyler Katz,Juhi Gupta,Riya Shah,Ramith Hettiarachchi,David R. Koes*

Main category: cs.LG

TL;DR: OMTRA提出了一种统一的多模态流匹配模型，用于结构药物设计中的多种任务，包括口袋条件从头设计、对接等，并构建了5亿个3D分子构象数据集。


<details>
  <summary>Details</summary>
Motivation: 传统结构药物设计方法（如对接、药效团搜索）与生成建模方法各自独立，作者认为这些任务具有共同结构，可以通过统一框架解决，并希望扩展化学多样性。

Method: 提出OMTRA多模态流匹配模型，采用统一框架处理SBDD中的多种任务，包括一些传统工作流中没有的任务。同时构建了包含5亿个3D分子构象的数据集。

Result: OMTRA在口袋条件从头设计和对接任务上达到最先进性能，但大规模预训练和多任务训练的效果相对有限。

Conclusion: 通过统一的多模态流匹配框架可以灵活处理SBDD中的多种任务，虽然大规模预训练效果有限，但该方法为药物设计提供了新的可能性。

Abstract: Structure-based drug design (SBDD) focuses on designing small-molecule ligands that bind to specific protein pockets. Computational methods are integral in modern SBDD workflows and often make use of virtual screening methods via docking or pharmacophore search. Modern generative modeling approaches have focused on improving novel ligand discovery by enabling de novo design. In this work, we recognize that these tasks share a common structure and can therefore be represented as different instantiations of a consistent generative modeling framework. We propose a unified approach in OMTRA, a multi-modal flow matching model that flexibly performs many tasks relevant to SBDD, including some with no analogue in conventional workflows. Additionally, we curate a dataset of 500M 3D molecular conformers, complementing protein-ligand data and expanding the chemical diversity available for training. OMTRA obtains state of the art performance on pocket-conditioned de novo design and docking; however, the effects of large-scale pretraining and multi-task training are modest. All code, trained models, and dataset for reproducing this work are available at https://github.com/gnina/OMTRA

</details>


### [58] [Gradient Descent with Provably Tuned Learning-rate Schedules](https://arxiv.org/abs/2512.05084)
*Dravyansh Sharma*

Main category: cs.LG

TL;DR: 提出一种新的理论框架，用于在非凸非光滑函数上可证明地调整梯度优化算法的超参数，适用于神经网络常用激活函数，并能扩展到学习率调度、动量等多参数调优。


<details>
  <summary>Details</summary>
Motivation: 现有梯度优化方法依赖启发式超参数调优，缺乏理论保证。先前理论工作通常假设函数凸且光滑，这与实际应用（如神经网络）不符。需要开发适用于非凸非光滑函数的超参数调优理论框架。

Method: 开发新的分析工具，用于证明梯度算法超参数调优的样本复杂度界限。框架适用于非凸非光滑函数，特别是神经网络常用激活函数（ReLU、sigmoid、tanh）。扩展框架以同时调优多个超参数，包括学习率调度、动量参数和初始化向量。

Result: 获得了与先前光滑凸函数工作中类似的学习步长样本复杂度界限（相差对数因子），但适用于更广泛的函数类。框架能用于边界验证损失最小化和梯度下降迭代次数的样本复杂度。

Conclusion: 提出了首个适用于非凸非光滑函数的超参数调优理论框架，为实际机器学习应用中的梯度优化算法提供了可证明的超参数调优保证，特别适用于神经网络训练。

Abstract: Gradient-based iterative optimization methods are the workhorse of modern machine learning. They crucially rely on careful tuning of parameters like learning rate and momentum. However, one typically sets them using heuristic approaches without formal near-optimality guarantees. Recent work by Gupta and Roughgarden studies how to learn a good step-size in gradient descent. However, like most of the literature with theoretical guarantees for gradient-based optimization, their results rely on strong assumptions on the function class including convexity and smoothness which do not hold in typical applications. In this work, we develop novel analytical tools for provably tuning hyperparameters in gradient-based algorithms that apply to non-convex and non-smooth functions. We obtain matching sample complexity bounds for learning the step-size in gradient descent shown for smooth, convex functions in prior work (up to logarithmic factors) but for a much broader class of functions. Our analysis applies to gradient descent on neural networks with commonly used activation functions (including ReLU, sigmoid and tanh). We extend our framework to tuning multiple hyperparameters, including tuning the learning rate schedule, simultaneously tuning momentum and step-size, and pre-training the initialization vector. Our approach can be used to bound the sample complexity for minimizing both the validation loss as well as the number of gradient descent iterations.

</details>


### [59] [The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception](https://arxiv.org/abs/2512.05089)
*Eduardo Di Santi*

Main category: cs.LG

TL;DR: 物理过程产生的信号在函数空间中具有紧凑低变异性结构，形成可学习的感知流形，使生物和AI系统能从少量样本快速泛化。


<details>
  <summary>Details</summary>
Motivation: 现实物理过程产生的信号具有特定的几何结构（紧凑低变异性子集），这种结构使生物和人工系统能从少量样本快速泛化。本文旨在建立统一的数学框架来解释这一现象。

Method: 提出确定性函数拓扑框架，将物理现象的有效实现建模为具有稳定不变性和有限Hausdorff半径的紧凑感知流形。通过蒙特卡洛采样自监督发现流形边界，即使系统控制方程未知。

Result: 在三个领域验证：机电铁路道岔机、电化学电池放电曲线、生理ECG信号。提供理论保证、知识边界实用估计器，证明框架能解释有限观测下的泛化能力。

Conclusion: 确定性函数拓扑为感知、表示和世界模型构建提供了统一的数学基础，解释了生物学习者和自监督AI模型为何能从有限观察中泛化。

Abstract: Real-world physical processes do not generate arbitrary variability: their signals concentrate on compact and low-variability subsets of functional space. This geometric structure enables rapid generalization from a few examples in both biological and artificial systems.
  This work develops a deterministic functional-topological framework in which the set of valid realizations of a physical phenomenon forms a compact perceptual manifold with stable invariants and a finite Hausdorff radius. We show that the boundaries of this manifold can be discovered in a fully self-supervised manner through Monte Carlo sampling, even when the governing equations of the system are unknown.
  We provide theoretical guarantees, practical estimators of knowledge boundaries, and empirical validations across three domains: electromechanical railway point machines, electrochemical battery discharge curves, and physiological ECG signals.
  Our results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction, explaining why biological learners and self-supervised AI models can generalize from limited observations.

</details>


### [60] [TV2TV: A Unified Framework for Interleaved Language and Video Generation](https://arxiv.org/abs/2512.05103)
*Xiaochuang Han,Youssef Emad,Melissa Hall,John Nguyen,Karthik Padthe,Liam Robbins,Amir Bar,Delong Chen,Michal Drozdzal,Maha Elbayad,Yushi Hu,Shang-Wen Li,Sreya Dutta Roy,Jakob Verbeek,XuDong Wang,Marjan Ghazvininejad,Luke Zettlemoyer,Emily Dinan*

Main category: cs.LG

TL;DR: TV2TV：一种将视频生成分解为交替文本和视频生成过程的统一生成建模框架，通过"用文字思考，用像素行动"的方式提升视频质量和可控性


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在处理需要复杂语义分支或高层次推理的视频内容时仍存在困难，需要一种能够进行开放式文本推理和控制的视频生成方法

Method: 提出TV2TV框架，采用混合变换器架构联合学习语言建模和视频流匹配，在推理时交替生成文本和视频帧，让模型先用文字思考后续内容再生成像素

Result: 在视频游戏数据实验中，TV2TV在视觉质量和可控性方面均有显著提升；在自然视频（体育视频）上也能生成高质量且与提示对齐的视频，展示了对复杂现实动作序列的推理能力

Conclusion: TV2TV代表了向具有开放式文本推理和控制能力的视频生成迈出的有希望的一步，通过将语言推理与视频生成相结合，实现了更好的视觉质量和细粒度可控性

Abstract: Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow matching (next-frame prediction) using a Mixture-of-Transformers (MoT) architecture. At inference time, TV2TV decides when to alternate between generating text and video frames, allowing the model to "think in words" about subsequent content before ``acting in pixels'' to produce frames. This design offloads much of the responsibility for deciding what should happen next to the language modeling tower, enabling improved visual quality and prompt alignment of generated videos. It also enables fine-grained controllability, allowing users to modify the video generation trajectory through text interventions at any point in the process. In controlled experiments on video game data, TV2TV demonstrates substantial improvements in both visual quality and controllability. TV2TV also scales to natural videos, as we show by augmenting sports videos with interleaved natural language action descriptions using vision-language models (VLMs). Training TV2TV on this corpus yields strong visual quality and prompt alignment, showcasing the model's ability to reason about and generate complex real-world action sequences. Together, these results highlight TV2TV as a promising step toward video generation with open-ended textual reasoning and control.

</details>


### [61] [Deep infant brain segmentation from multi-contrast MRI](https://arxiv.org/abs/2512.05114)
*Malte Hoffmann,Lilla Zöllei,Adrian V. Dalca*

Main category: cs.LG

TL;DR: BabySeg是一个用于婴幼儿脑部MRI分割的深度学习框架，支持多种MRI协议和训练时未见过的图像类型，通过领域随机化和灵活的特征池化实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿脑部MRI分割面临诸多挑战：获取困难、成像模态不一致、视野中包含大量非头部解剖结构、运动伪影频繁。现有方法通常局限于特定图像类型或狭窄年龄组，对临床中更易变的图像不够鲁棒。

Method: 基于领域随机化技术，合成远超现实边界的训练图像以促进数据集偏移不变性；设计了一种机制，使模型能够灵活池化和交互任意数量输入扫描的特征。

Result: 在多个年龄组和输入配置下，单个模型实现了最先进的性能，匹配或超越了多个现有方法的准确性，且运行时间远少于许多现有工具。

Conclusion: BabySeg解决了婴幼儿脑部MRI分割的方法碎片化问题，提供了一个支持多样化MRI协议和训练时未见图像类型的统一框架，在准确性和效率方面均有显著优势。

Abstract: Segmentation of magnetic resonance images (MRI) facilitates analysis of human brain development by delineating anatomical structures. However, in infants and young children, accurate segmentation is challenging due to development and imaging constraints. Pediatric brain MRI is notoriously difficult to acquire, with inconsistent availability of imaging modalities, substantial non-head anatomy in the field of view, and frequent motion artifacts. This has led to specialized segmentation models that are often limited to specific image types or narrow age groups, or that are fragile for more variable images such as those acquired clinically. We address this method fragmentation with BabySeg, a deep learning brain segmentation framework for infants and young children that supports diverse MRI protocols, including repeat scans and image types unavailable during training. Our approach builds on recent domain randomization techniques, which synthesize training images far beyond realistic bounds to promote dataset shift invariance. We also describe a mechanism that enables models to flexibly pool and interact features from any number of input scans. We demonstrate state-of-the-art performance that matches or exceeds the accuracy of several existing methods for various age cohorts and input configurations using a single model, in a fraction of the runtime required by many existing tools.

</details>


### [62] [Value Gradient Guidance for Flow Matching Alignment](https://arxiv.org/abs/2512.05116)
*Zhen Liu,Tim Z. Xiao,Carles Domingo-Enrich,Weiyang Liu,Dinghuai Zhang*

Main category: cs.LG

TL;DR: VGG-Flow：基于梯度匹配的流匹配模型微调方法，利用最优控制理论实现高效适应和概率保真


<details>
  <summary>Details</summary>
Motivation: 现有流匹配模型对齐方法无法同时实现适应效率和概率保真，需要一种既能快速适应又能保持先验分布的方法

Method: 基于最优控制理论，提出VGG-Flow方法，核心思想是将微调后速度场与预训练速度场的最优差异与价值函数的梯度场相匹配，利用奖励模型的一阶信息和价值函数的启发式初始化实现快速适应

Result: 在Stable Diffusion 3等文本到图像流匹配模型上验证，在有限计算预算下能有效微调模型，实现有效且保真的对齐

Conclusion: VGG-Flow方法成功解决了流匹配模型对齐中的适应效率与概率保真权衡问题，为生成模型的对齐提供了新的解决方案

Abstract: While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This method not only incorporates first-order information from the reward model but also benefits from heuristic initialization of the value function to enable fast adaptation. Empirically, we show on a popular text-to-image flow matching model, Stable Diffusion 3, that our method can finetune flow matching models under limited computational budgets while achieving effective and prior-preserving alignment.

</details>


### [63] [The Universal Weight Subspace Hypothesis](https://arxiv.org/abs/2512.05117)
*Prakhar Kaushik,Shravan Chaudhari,Ankit Vaidya,Rama Chellappa,Alan Yuille*

Main category: cs.LG

TL;DR: 深度神经网络在不同任务训练后，会收敛到相似的低维参数子空间，这些通用子空间在少数几个主方向上就能捕捉大部分方差。


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络的内在组织结构，探索是否存在跨任务、跨领域的通用参数子空间，以理解神经网络的信息组织方式。

Method: 对1100多个模型进行模态谱分析，包括500个Mistral-7B LoRA模型、500个Vision Transformers和50个LLaMA-8B模型。应用谱分解技术分析权重矩阵，识别稀疏的联合子空间。

Result: 发现神经网络无论初始化、任务或领域如何，都会系统性地收敛到共享的谱子空间。仅用几个主方向就能捕捉大部分方差，识别出跨架构、任务和数据集一致利用的稀疏联合子空间。

Conclusion: 深度神经网络存在内在的通用子空间结构，这对模型复用、多任务学习、模型融合以及开发训练和推理高效算法有重要影响，可能减少大规模神经模型的碳足迹。

Abstract: We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization, task, or domain. Through mode-wise spectral analysis of over 1100 models - including 500 Mistral-7B LoRAs, 500 Vision Transformers, and 50 LLaMA-8B models - we identify universal subspaces capturing majority variance in just a few principal directions. By applying spectral decomposition techniques to the weight matrices of various architectures trained on a wide range of tasks and datasets, we identify sparse, joint subspaces that are consistently exploited, within shared architectures across diverse tasks and datasets. Our findings offer new insights into the intrinsic organization of information within deep networks and raise important questions about the possibility of discovering these universal subspaces without the need for extensive data and computational resources. Furthermore, this inherent structure has significant implications for model reusability, multi-task learning, model merging, and the development of training and inference-efficient algorithms, potentially reducing the carbon footprint of large-scale neural models.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [64] [Dissipative Yao-Lee Spin-Orbital Model: Exact Solvability and $\mathcal{PT}$ Symmetry Breaking](https://arxiv.org/abs/2512.04155)
*Zihao Qi,Yuan Xue*

Main category: quant-ph

TL;DR: 提出一种基于各向异性Yao-Lee自旋轨道模型的可精确求解耗散模型，通过将Liouvillian动力学映射到双希尔伯特空间中的非厄米哈密顿量，展示了模型的精确可解性，揭示了耗散自旋液体物理与Liouvillian谱奇点的共存。


<details>
  <summary>Details</summary>
Motivation: 可精确求解的耗散模型为研究开放量子系统的弛豫动力学提供了分析工具。作者旨在构建一个物理上可行的耗散自旋液体模型，探索耗散系统中非平衡稳态流形、Liouvillian谱奇点以及PT对称性破缺转变等特性。

Method: 基于各向异性Yao-Lee自旋轨道模型，在自旋部分引入耗散作用。通过将Liouvillian动力学映射到双希尔伯特空间中的费米子跳跃问题，在非厄米哈密顿量框架下证明模型的精确可解性。分析模型的强对称性和弱对称性，研究平移不变性扇区中的瞬态动力学。

Result: 模型具有指数大的非平衡稳态流形，被确认为物理上可行的耗散自旋液体。在动量空间中发现了Liouvillian谱的异常环结构，并绘制出由耗散强度驱动的PT对称性破缺转变，该转变控制着物理观测量从振荡弛豫到衰减弛豫的交叉行为。

Conclusion: 该工作提供了一个物理动机明确、可精确求解的平台，用于探索耗散自旋液体物理与Liouvillian谱奇点的共存现象，为理解开放量子系统中的弛豫动力学和非平衡稳态提供了新的理论框架。

Abstract: Exactly solvable dissipative models provide an analytical tool for studying the relaxation dynamics in open quantum systems. In this work, we study an exactly solvable model based on an anisotropic variant of the Yao-Lee spin-orbital model, with dissipation acting in the spin sector. We map Liouvillian dynamics to fermions hopping in a doubled Hilbert space under a non-Hermitian Hamiltonian and demonstrate the model's exact solvability. We analyze the model's strong and weak symmetries, which protect an exponentially large manifold of non-equilibrium steady states, establishing the system as a physically feasible dissipative spin liquid. Furthermore, we analyze the transient dynamics in a translationally invariant sector and discover that the single-particle Liouvillian spectrum hosts an exceptional ring in momentum space. We map out a characteristic $\mathcal{PT}$ symmetry breaking transition driven by the dissipation strength, which governs the crossover from oscillatory to decaying relaxation of physical observables. Our work provides a physically motivated, solvable setting for exploring the coexistence of dissipative spin liquid physics and Liouvillian spectral singularities.

</details>


### [65] [Exploiting Movable Logical Qubits for Lattice Surgery Compilation](https://arxiv.org/abs/2512.04169)
*Laura S. Herzog,Lucas Berent,Aleksander Kubica,Robert Wille*

Main category: quant-ph

TL;DR: 提出基于可移动逻辑量子比特的晶格手术编译新范式，通过量子隐形传态减少电路深度，适用于超导量子硬件


<details>
  <summary>Details</summary>
Motivation: 传统晶格手术编译方案采用静态布局，逻辑量子比特在计算过程中固定不动。本文旨在利用可移动逻辑量子比特的优势，通过量子隐形传态优化晶格手术CNOT门的实现，降低电路深度

Method: 提出基于颜色码的晶格手术编译新方案，利用量子隐形传态实现逻辑量子比特的移动，在逻辑CNOT门执行过程中动态调整量子比特位置

Result: 数值模拟显示，相比传统静态布局编译技术，新方法能显著减少路由电路深度，证明可移动逻辑量子比特优化不仅适用于中性原子或囚禁离子等物理可移动量子比特架构，也适用于超导量子硬件

Conclusion: 通过引入可移动逻辑量子比特的编译范式，为晶格手术量子计算提供了更高效的编译方案，特别是在超导量子硬件上实现了电路深度优化，相关开源实现已发布

Abstract: Lattice surgery with two-dimensional quantum error correcting codes is among the leading schemes for fault-tolerant quantum computation, motivated by superconducting hardware architectures. In conventional lattice surgery compilation schemes, logical circuits are compiled following a place-and-route paradigm, where logical qubits remain statically fixed in space throughout the computation. In this work, we introduce a paradigm shift by exploiting movable logical qubits via teleportation during the logical lattice surgery CNOT gate. Focusing on lattice surgery with the color code, we propose a proof-of-concept compilation scheme that leverages this capability. Numerical simulations show that the proposed approach can substantially reduce the routed circuit depth compared to standard place-and-route compilation techniques. Our results demonstrate that optimizations based on movable logical qubits are not limited to architectures with physically movable qubits, such as neutral atoms or trapped ions - they are also readily applicable to superconducting quantum hardware. An open-source implementation of our method is available on GitHub https://github.com/munich-quantum-toolkit/qecc.

</details>


### [66] [Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits](https://arxiv.org/abs/2512.04170)
*Erik Weilandt,Tom Peham,Robert Wille*

Main category: quant-ph

TL;DR: 提出多项式时间算法，通过最小割问题优化量子电路中的代码切换次数，减少量子纠错码切换的开销。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码中，单个代码无法支持所有门的容错实现，代码切换虽能解决此问题但代价高昂（增加时间、空间开销和逻辑错误率），因此需要最小化切换操作次数。

Method: 将最小化代码切换次数的问题转化为图上的最小割问题，基于电路构建图，可在多项式时间内求解，并可灵活考虑其他优化因素（如空闲期切换、代码偏好等）。

Result: 首次实现了逻辑层级的代码切换量子计算自动编译与优化方法，能高效减少切换操作。

Conclusion: 该方法为基于代码切换的量子计算提供了有效的自动化优化工具，能显著降低切换开销，提升计算效率。

Abstract: Fault-tolerant quantum computers rely on Quantum Error-Correcting Codes (QECCs) to protect information from noise. However, no single error-correcting code supports a fully transversal and therefore fault-tolerant implementation of all gates required for universal quantum computation. Code switching addresses this limitation by moving quantum information between different codes that, together, support a universal gate set. Unfortunately, each switch is costly-adding time and space overhead and increasing the logical error rate. Minimizing the number of switching operations is, therefore, essential for quantum computations using code switching. In this work, we study the problem of minimizing the number of code switches required to run a given quantum circuit. We show that this problem can be solved efficiently in polynomial time by reducing it to a minimum-cut instance on a graph derived from the circuit. Our formulation is flexible and can incorporate additional considerations, such as reducing depth overhead by preferring switches during idle periods or biasing the compilation to favor one code over another. To the best of our knowledge, this is the first automated approach for compiling and optimizing code-switching-based quantum computations at the logical level.

</details>


### [67] [A Quantum Gate Architecture via Teleportation and Entanglement](https://arxiv.org/abs/2512.04171)
*Samuel J. Sheldon,Pieter Kok,Callum W. Duncan*

Main category: quant-ph

TL;DR: 提出一种结合测量驱动与电路模型优点的通用量子计算架构QGATE，专为确定性光子源的光子量子计算机设计，通过Clifford操作、QGATE辅助比特和任意角度单比特测量实现通用量子计算。


<details>
  <summary>Details</summary>
Motivation: 结合测量驱动量子计算(MBQC)和电路模型的优势，为离散变量光子量子计算机设计一种高效架构，解决传统架构在实现多比特纠缠和通用量子操作方面的挑战。

Method: 使用逻辑数据比特寄存器，通过Clifford操作、QGATE辅助比特和任意角度单比特测量实现通用量子计算。利用多比特Pauli字符串生成逻辑比特与共享辅助比特之间的纠缠，通过辅助比特测量实现所需幺正演化。

Result: QGATE能够直接执行基于多比特Pauli算符的哈密顿演化、任意稀疏哈密顿量的投影子实现，以及多控制门操作。提出了光子实现方案，基于折叠旋转表面码的逻辑比特，光子损耗阈值分别为10.36±0.02%（层内融合）或25.98±0.28%（层间融合）。

Conclusion: QGATE架构成功结合了MBQC和电路模型的优点，为光子量子计算机提供了一种高效的通用计算方案，能够直接实现哈密顿演化和电路模型转换，具有实际应用潜力。

Abstract: We present a universal quantum computing architecture which combines the measurement-driven aspect of MBQC with the circuit model's algorithm dependent generation of qubit entanglement. Our architecture, which we call QGATE, is tailored for discrete-variable photonic quantum computers with deterministic photon sources capable of generating 1D entangled photonic states. QGATE achieves universal quantum computing on a logical data qubit register via the implementation of Clifford operations, QGATE ancilla, and arbitrary angle single-qubit measurements. We realise unitary evolutions defined by multi-qubit Pauli strings via the generation of entanglement between a sub-set of logical qubits and a mutual QGATE ancilla qubit. Measurement of the QGATE ancilla in the appropriate basis then implements a given term of the desired unitary operation. This enables QGATE to both directly perform Hamiltonian evolutions in terms of a series of multi-qubit Pauli operators, in terms of projectors for an arbitrary sparse Hamiltonian, or realise multi-controlled gates enabling direct translation of circuit models to QGATE. We consider examples inspired by quantum chemistry and computational fluid dynamics. We propose an example photonic implementation of QGATE and calculate thresholds of $10.36\pm0.02\%$ or $25.98\pm0.28\%$ on the photonic loss for logical qubits constructed from foliated rotated surface codes, dependent on the deployment of intra-layer or inter-layer fusion respectively.

</details>


### [68] [A contextual advantage for conclusive exclusion: repurposing the Pusey-Barrett-Rudolph construction](https://arxiv.org/abs/2512.04173)
*Yìlè Yīng,David Schmid,Robert W. Spekkens*

Main category: quant-ph

TL;DR: 量子态集合的结论性排除任务中，存在量子相对于经典的优势，通过噪声鲁棒的非上下文不等式证明，并在双局域性场景中构成经典因果兼容性不等式


<details>
  <summary>Details</summary>
Motivation: 研究量子态集合的结论性排除任务，探索量子理论相对于经典理论在排除能力上的优势，特别是在广义非上下文本体模型框架下

Method: 基于Pusey-Barrett-Rudolph定理构造实验场景，推导噪声鲁棒的非上下文不等式来界定排除的结论性，展示量子违反这些不等式

Result: 证明了量子系统在结论性排除任务上存在量子-经典优势，量子理论可以违反非上下文不等式，该界限在双局域性场景中构成经典因果兼容性不等式

Conclusion: 量子理论在结论性排除能力上超越经典理论，这一界限不仅作为非上下文不等式，还在双局域性场景中揭示量子-经典差距的可能性证明

Abstract: The task of conclusive exclusion for a set of quantum states is to find a measurement such that for each state in the set, there is an outcome that allows one to conclude with certainty that the state in question was not prepared. Defining classicality of statistics as realizability by a generalized-noncontextual ontological model, we show that there is a quantum-over-classical advantage for how well one can achieve conclusive exclusion. This is achieved in an experimental scenario motivated by the construction appearing in the Pusey-Barrett-Rudolph theorem. We derive noise-robust noncontextuality inequalities bounding the conclusiveness of exclusion, and describe a quantum violation of these. Finally, we show that this bound also constitutes a classical causal compatibility inequality within the bilocality scenario, and that its violation in quantum theory yields a novel possibilistic proof of a quantum-classical gap in that scenario.

</details>


### [69] [Simulation of a Heterogeneous Quantum Network](https://arxiv.org/abs/2512.04211)
*Hayden Miller,Caitao Zhan,Michael Bishof,Joaquin Chung,Han Xu,Prem Kumar,Rajkumar Kettimuthu*

Main category: quant-ph

TL;DR: 开发了一个基于SeQUeNCe的异构量子网络仿真框架，包含镱原子和超导量子比特的精确设备模型，用于评估异构系统中的纠缠生成和交换协议性能


<details>
  <summary>Details</summary>
Motivation: 量子网络预计将是异构系统，结合不同的量子比特平台、光子波长和设备时间尺度。构建和迭代这样的系统成本高且速度慢，需要硬件保真度高的仿真来探索架构设计空间并验证实现决策

Method: 基于SeQUeNCe离散事件量子网络仿真器开发框架，引入镱原子和超导量子比特的精确设备模型，实现时间编码光子的纠缠生成和交换协议，考虑异构性带来的不同时钟频率、量子频率转换和转换器损耗/噪声

Result: 通过大量仿真，绘制了速率-保真度权衡空间，识别了异构系统特有的主要瓶颈。模型开源且可扩展，支持未来异构设计和协议的可重复评估

Conclusion: 该框架为异构量子网络提供了硬件保真度的仿真工具，能够识别系统瓶颈并指导设计决策，开源特性促进了可重复研究和未来扩展

Abstract: Quantum networks are expected to be heterogeneous systems, combining distinct qubit platforms, photon wavelengths, and device timescales to achieve scalable, multiuser connectivity. Building and iterating on such systems is costly and slow, motivating hardware-faithful simulations to explore architecture design space and justify implementation decisions. This paper presents a framework for simulating heterogeneous quantum networks based on SeQUeNCe, a discrete-event simulator of quantum networks. We introduce faithful device models for two representative platforms - Ytterbium atoms and superconducting qubits. On top of these models, we implement entanglement generation and entanglement swapping protocols for time-bin encoded photons that account for disparate clock rates and quantum frequency conversion and transducer losses/noise brought by the heterogeneity. Using extensive simulations, we map the rate-fidelity trade space and identify the dominant bottlenecks unique to heterogeneous systems. The models are open source and extensible, enabling reproducible evaluation of future heterogeneous designs and protocols.

</details>


### [70] [Maestro: Intelligent Execution for Quantum Circuit Simulation](https://arxiv.org/abs/2512.04216)
*Oriol Bertomeu,Hamzah Ghayas,Adrian Roman,Stephen DiAdamo*

Main category: quant-ph

TL;DR: Maestro是一个量子电路模拟的统一接口，集成了多种模拟范式，通过预测性运行时模型自动选择最优模拟器，并在高性能计算环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 量子电路模拟对于开发和验证量子算法至关重要，但当前模拟方法和软件工具的多样性使得为特定电路选择最合适的后端变得困难，存在较高的选择门槛。

Method: Maestro提供了一个统一接口，集成了状态向量、MPS、张量网络、稳定子、GPU加速和p-block等多种模拟范式。它包含一个预测性运行时模型，能根据电路结构和可用硬件自动选择最优模拟器，并应用后端特定的优化，如多进程、GPU执行和改进的采样。

Result: 在异构工作负载的基准测试中，Maestro在单电路和大批量设置下都优于单个模拟器，特别是在高性能计算环境中表现突出。

Conclusion: Maestro为量子算法研究、混合量子经典工作流和新兴的分布式量子计算架构提供了一个可扩展、可扩展的平台。

Abstract: Quantum circuit simulation remains essential for developing and validating quantum algorithms, especially as current quantum hardware is limited in scale and quality. However, the growing diversity of simulation methods and software tools creates a high barrier to selecting the most suitable backend for a given circuit. We introduce Maestro, a unified interface for quantum circuit simulation that integrates multiple simulation paradigms - state vector, MPS, tensor network, stabilizer, GPU-accelerated, and p-block methods - under a single API. Maestro includes a predictive runtime model that automatically selects the optimal simulator based on circuit structure and available hardware, and applies backend-specific optimizations such as multiprocessing, GPU execution, and improved sampling. Benchmarks across heterogeneous workloads demonstrate that Maestro outperforms individual simulators in both single-circuit and large batched settings, particularly in high-performance computing environments. Maestro provides a scalable, extensible platform for quantum algorithm research, hybrid quantum-classical workflows, and emerging distributed quantum computing architectures.

</details>


### [71] [Unspeakable Coherence Concentration](https://arxiv.org/abs/2512.04255)
*Benjamin Stratton,Chung-Yun Hsieh,Paul Skrzypczyk*

Main category: quant-ph

TL;DR: 该论文研究了量子相干性的增强问题：给定两个低相干性态，能否通过全局相干性非增操作提高子系统相干性？作者解决了量子比特情况，发现了束缚相干性，并构建了多量子比特相干性增强协议，意外发现某些态的输入输出相干性比可以无限放大。


<details>
  <summary>Details</summary>
Motivation: 不可言说相干性是区分量子与经典物理的关键特征，在计量学、参考系对齐和功提取等任务中实现量子优势。一个具有实践和基础价值的问题是：给定一些低相干性态，能否通过相干性非增操作制备更高相干性的态？

Method: 研究最小极限情况：给定两个不相关的相干态，通过全局相干性非增幺正操作能否增加子系统相干性？完全解决了量子比特情况，识别了最优幺正操作，揭示了束缚相干性存在。基于此构建了完全构造性的多量子比特相干性增强协议，仅使用有效量子比特幺正操作。

Result: 1. 完全解决了量子比特的相干性增强问题，识别了最优幺正操作；2. 发现了束缚相干性现象；3. 构建了多量子比特相干性增强协议；4. 意外发现某些态的输入输出相干性比可以无限放大；5. 推导了局部相干性增加量的两个基本上界；6. 证明了某些全局关联不能转换为局部相干性的不可行定理。

Conclusion: 该研究在量子相干性增强方面取得了重要进展：解决了量子比特情况，发现了束缚相干性，构建了有效的多量子比特增强协议，并揭示了相干性可以无限放大的意外现象。这些结果为量子资源理论提供了新见解，对量子信息处理应用具有重要意义。

Abstract: Unspeakable coherence is a key feature separating quantum and classical physics. Modelled as asymmetry with respect to a continuous transformation generated by a physically relevant observable, such as the Hamiltonian or angular moment, unspeakable coherence has been shown to be the relevant notion of coherence for achieving quantum advantage in the tasks of metrology, reference frame alignment and work extraction, among others. A question of both practical and foundational value is: Given some copies of a state with low coherence, can we prepare a more coherent state via coherence non-increasing operations? Here, we study this question in the minimal limiting case: Given two uncorrelated copies of a coherent state, can one, via globally coherence non-increasing unitaries, increase the coherence in a subsystem? We fully solve this problem for qubits, identifying the optimal unitaries and revealing the existence of bound coherence. This is then used to create a completely constructive multi-qubit coherence enhancement protocol, where only effective-qubit unitaries are used. Unexpectedly, in this protocol, we show that there exists states for which the ratio of the input-output coherence can be amplified unboundedly. Extending beyond qubits, we derive two fundamental upper bounds on the amount of local coherence that can be increased and prove a no-go theorem showing that certain global correlations cannot be converted to local coherence.

</details>


### [72] [Limits of Perturbation Theory for Multimode Light Propagation in Dispersive Optical Cavities](https://arxiv.org/abs/2512.04295)
*K. S. Tikhonov,D. M. Malyshev,V. A. Averchenko*

Main category: quant-ph

TL;DR: 本文提出了一种基于微扰理论的方法来分析光学腔中的群速度色散效应，建立了微扰方法的有效区域并评估了其在多模系统中的局限性。


<details>
  <summary>Details</summary>
Motivation: 量子光脉冲的时间模式是现代量子技术的重要资源，但精确控制和操纵这些模式仍然是关键挑战。特别是在非线性多模动力学与色散效应相互作用的系统中，群速度色散在光学腔中的作用传统上被视为有害，但越来越被认为是量子光操纵的多功能工具。

Method: 采用基于微扰理论的方法来分析同步泵浦色散腔中的GVD效应。通过将微扰解与严格的稳态结果进行比较，建立微扰方法的有效区域。

Result: 确定了导致微扰理论失效的关键参数，包括模式阶数、色散强度和腔衰减率。建立了微扰方法的有效区域并评估了其在多模系统中的局限性。

Conclusion: 群速度色散在光学腔中不仅是传统认为的有害效应，更是量子光操纵的有用工具。微扰理论方法为分析GVD效应提供了有效框架，但需要注意其适用范围受模式阶数、色散强度和腔衰减率等参数的影响。

Abstract: Temporal modes of quantum light pulses is a promising resource for modern quantum technologies, driving advancements in quantum computing, communication, and metrology. Precise control and manipulation of these modes remain critical challenges, particularly in systems where nonlinear multimode dynamics interact with dispersion effects. In this work, we focus on the role of group velocity dispersion (GVD) within optical cavities - a phenomenon traditionally viewed as detrimental but increasingly recognized as a versatile tool for quantum light manipulation. We present a perturbation-theory-based approach to analyze GVD effects in a synchronously pumped dispersive cavity. By comparing perturbative solutions to rigorous steady-state results, we establish the validity region of the perturbative approach and assess its limitations in multimode systems. Our study identifies key parameters governing the breakdown of perturbation theory, such as mode order, dispersion strength, and cavity decay rates.

</details>


### [73] [Fermionic neural Gibbs states](https://arxiv.org/abs/2512.04663)
*Jannes Nys,Juan Carrasquilla*

Main category: quant-ph

TL;DR: 提出fermionic neural Gibbs states (fNGS)变分框架，用于模拟强相互作用费米子的有限温度性质，在费米-哈伯德模型中准确再现热力学性质。


<details>
  <summary>Details</summary>
Motivation: 需要开发可扩展的方法来研究强关联费米子系统在有限温度下的性质，特别是在超越精确方法可处理系统尺寸的情况下。

Method: 从参考平均场热场双态出发，结合神经网络变换和虚时演化系统性地构建强关联，形成变分框架fNGS。

Result: 在掺杂费米-哈伯德模型中，fNGS在宽温度范围、相互作用强度和较大掺杂下准确再现热能量，系统尺寸超越精确方法可处理范围。

Conclusion: fNGS为研究一维以上强关联费米子系统的有限温度性质提供了可扩展的途径，展示了神经网络量子态表示的有效性。

Abstract: We introduce fermionic neural Gibbs states (fNGS), a variational framework for modeling finite-temperature properties of strongly interacting fermions. fNGS starts from a reference mean-field thermofield-double state and uses neural-network transformations together with imaginary-time evolution to systematically build strong correlations. Applied to the doped Fermi-Hubbard model, a minimal lattice model capturing essential features of strong electronic correlations, fNGS accurately reproduces thermal energies over a broad range of temperatures, interaction strengths, even at large dopings, for system sizes beyond the reach of exact methods. These results demonstrate a scalable route to studying finite-temperature properties of strongly correlated fermionic systems beyond one dimension with neural-network representations of quantum states.

</details>


### [74] [Experimental Sensitivity Enhancement of a Quantum Rydberg Atom-Based RF Receiver with a Metamaterial GRIN Lens](https://arxiv.org/abs/2512.04298)
*Anton Tishchenko,Demos Serghiou,Ashwin Thelappilly Joy,Paul Marsh,Paul Martin,Tim Brown,Gabriele Gradoni,Mohsen Khalily,Rahim Tafazolli*

Main category: quant-ph

TL;DR: 实验证明集成梯度折射率Luneburg型超材料透镜的里德堡原子射频接收器灵敏度增强


<details>
  <summary>Details</summary>
Motivation: 解决裸里德堡接收器固有的带宽和灵敏度限制，提升量子传感性能

Method: 通过分析铯蒸汽中的电磁诱导透明效应，比较有无GRIN透镜在2.2GHz和3.6GHz远场激励下的接收器性能

Result: 引入透镜后EIT透明窗口显著放大，局部电场增强降低了最小可检测电场，提高了信噪比

Conclusion: 超材料辅助的量子传感有潜力克服裸里德堡接收器的限制，在EMC测试、量子雷达和无线通信等领域有应用前景

Abstract: We experimentally demonstrate enhanced sensitivity of an atom-based Rydberg radio frequency (RF) receiver integrated with a gradient refractive index (GRIN) Luneburg-type metamaterial lens. By analyzing the electromagnetically induced transparency (EIT) effect in Cesium vapor, we compare receiver performance with and without the GRIN lens under a 2.2~GHz and a 3.6~GHz far-field excitation. Our measurements reveal a significant amplification of the EIT transparency window when the lens is introduced, consistent with the theoretical prediction that the local E-field enhancement at the vapor cell reduces the minimum detectable electric field and increases the signal-to-noise ratio (SNR) of the Rydberg RF receiver. This experimental validation highlights the potential of metamaterial-assisted quantum sensing to overcome the inherent bandwidth and sensitivity limitations of bare Rydberg receivers for a variety of applications, such as electromagnetic compatibility (EMC) testing, quantum radar, and wireless communications.

</details>


### [75] [The operator layer cake theorem is equivalent to Frenkel's integral formula](https://arxiv.org/abs/2512.04345)
*Hao-Chung Cheng,Gilad Gour,Ludovico Lami,Po-Chieh Liu*

Main category: quant-ph

TL;DR: 该论文证明了算子分层蛋糕定理与Frenkel的Umegaki相对熵积分公式之间的等价关系。


<details>
  <summary>Details</summary>
Motivation: 先前研究已发现算子分层蛋糕定理可用于证明Frenkel的积分公式，但两者之间的逻辑关系尚未完全明确。本文旨在探究这两个重要数学结果之间的等价性。

Method: 通过数学推导和逻辑分析，证明算子分层蛋糕定理与Frenkel积分公式可以相互推导，从而建立两者之间的等价关系。

Result: 成功证明了算子分层蛋糕定理与Frenkel的Umegaki相对熵积分公式是等价的，即可以从其中一个推导出另一个。

Conclusion: 算子分层蛋糕定理与Frenkel积分公式在数学上是等价的，这一发现深化了我们对这两个重要结果之间关系的理解，并揭示了它们在算子理论和量子信息论中的内在联系。

Abstract: The operator layer cake theorem provides an integral representation for the directional derivative of the operator logarithm in terms of a family of projections [arXiv:2507.06232]. Recently, the related work [arXiv:2507.07065] showed that the theorem gives an alternative proof to Frenkel's integral formula for Umegaki's relative entropy [Quantum, 7:1102 (2023)]. In this short note, we find a converse implication, demonstrating that the operator layer cake theorem is equivalent to Frenkel's integral formula.

</details>


### [76] [Convergence of sample-based quantum diagonalization on a variable-length cuprate chain](https://arxiv.org/abs/2512.04962)
*L. Andrew Wray,Cheng-Ju Lin,Vincent Su,Hrant Gharibyan*

Main category: quant-ph

TL;DR: SQD算法在NISQ设备上用于分子模拟，但收敛性存在问题。研究通过铜氧化物分子测试发现，全连接、高阶展开和非Hartree-Fock基组可改善采样瓶颈，但需权衡硬件能力。有趣的是，真实量子计算机的噪声反而能改善能量收敛。


<details>
  <summary>Details</summary>
Motivation: SQD算法在NISQ设备上用于分子模拟具有广泛兴趣，但算法并不总是在实际时间尺度内收敛，需要探索其可扩展性和改进方法。

Method: 研究使用2-6个铜氧化物plaquettes组成的可变长度分子，采用最小分子轨道基组。测试了全连接性、SQD算法高阶展开和非Hartree-Fock分子轨道基组的影响，并在Quantinuum H2离子阱量子计算机上进行了实验。

Result: 全连接性、高阶展开和非Hartree-Fock基组都能显著克服采样瓶颈，但需要在量子与经典硬件能力之间权衡。意外发现真实量子计算机的噪声比无噪声状态向量模拟能更好地改善能量收敛。

Conclusion: SQD算法的可扩展性可通过多种策略改进，但需考虑硬件限制。量子噪声在某些情况下可能有益于算法收敛，这为NISQ时代的量子计算应用提供了新视角。

Abstract: Sample-based quantum diagonalization (SQD) is an algorithm for hybrid quantum-classical molecular simulation that has been of broad interest for application with noisy intermediate scale quantum (NISQ) devices. However, SQD does not always converge on a practical timescale. Here, we explore scaling of the algorithm for a variable-length molecule made up of 2 to 6 copper oxide plaquettes with a minimal molecular orbital basis. The results demonstrate that enabling all-to-all connectivity, instituting a higher expansion order for the SQD algorithm, and adopting a non-Hartree-Fock molecular orbital basis can all play significant roles in overcoming sampling bottlenecks, though with tradeoffs that need to be weighed against the capabilities of quantum and classical hardware. Additionally, we find that noise on a real quantum computer, the Quantinuum H2 trapped ion device, can improve energy convergence beyond expectations based on noise-free statevector simulations.

</details>


### [77] [Adversarial Limits of Quantum Certification: When Eve Defeats Detection](https://arxiv.org/abs/2512.04391)
*Davut Emre Tasar*

Main category: quant-ph

TL;DR: 量子密钥分发安全认证存在系统性缺陷：攻击者只需在量子数据中混入5%经典相关性即可完全逃避检测，且传统校准方法高估检测性能44个百分点。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发的安全性依赖于认证观测到的相关性确实来自量子纠缠而非窃听者操纵。现有理论安全证明假设理想条件，但实际认证必须应对针对检测系统优化攻击策略的自适应对手。

Method: 使用Eve GAN（生成对抗网络）训练产生与量子相关性无法区分的经典相关性。分析攻击者在量子数据中混入经典相关性时的检测性能，采用交叉分布校准而非传统分布校准，并在IBM Quantum硬件上验证。

Result: 当攻击者以混合参数混入经典相关性时，所有测试检测方法的ROC AUC = 0.50（等同于随机猜测）。传统分布校准高估检测性能44个百分点。Popescu-Rohrlich（PR Box）机制在CHSH S = 2.05处存在尖锐相变：低于此值，任何统计方法都无法区分经典与量子相关性。Eve-GAN在IBM Quantum上实现CHSH = 2.736，超过真实量子硬件性能（CHSH = 2.691）。

Conclusion: 量子密钥分发安全存在严重漏洞：保持95%量子保真度的攻击者可逃避所有测试检测方法。必须采用交叉分布校准方法，并对量子安全声明进行强制性对抗测试。

Abstract: Security of quantum key distribution (QKD) relies on certifying that observed correlations arise from genuine quantum entanglement rather than eavesdropper manipulation. Theoretical security proofs assume idealized conditions, practical certification must contend with adaptive adversaries who optimize their attack strategies against detection systems. Established fundamental adversarial limits for quantum certification using Eve GAN, a generative adversarial network trained to produce classical correlations indistinguishable from quantum. Our central finding: when Eve interpolates her classical correlations with quantum data at mixing parameter, all tested detection methods achieve ROC AUC = 0.50, equivalent to random guessing. This means an eavesdropper needs only 5% classical admixture to completely evade detection. Critically, we discover that same distribution calibration a common practice in prior certification studies inflates detection performance by 44 percentage points compared to proper cross distribution evaluation, revealing a systematic flaw that may have led to overestimated security claims. Analysis of Popescu Rohrlich (PR Box) regime identifies a sharp phase transition at CHSH S = 2.05: below this value, no statistical method distinguishes classical from quantum correlations; above it, detection probability increases monotonically. Hardware validation on IBM Quantum demonstrates that Eve-GAN achieves CHSH = 2.736, remarkably exceeding real quantum hardware performance (CHSH = 2.691), illustrating that classical adversaries can outperform noisy quantum systems on standard certification metrics. These results have immediate implications for QKD security: adversaries maintaining 95% quantum fidelity evade all tested detection methods. We provide corrected methodology using cross-distribution calibration and recommend mandatory adversarial testing for quantum security claims.

</details>


### [78] [Combined Quantum and Post-Quantum Security Performance Under Finite Keys](https://arxiv.org/abs/2512.04429)
*Aman Gupta,Ravi Singh Adhikari,Anju Rani,Xiaoyu Ai,Robert Malaney*

Main category: quant-ph

TL;DR: 该论文提出了一种改进的混合QKD-PQC系统，集成了最严格的有限密钥安全分析，并设计了可扩展的架构，确保即使QKD和PQC原语都被攻破时消息的机密性。


<details>
  <summary>Details</summary>
Motivation: 现有混合量子安全通信方案存在两个主要问题：1) 忽略了QKD密钥率的实际有限密钥效应；2) 未解决QKD和PQC原语通过侧信道泄露信息时的安全性维护。这些缺陷限制了混合系统在实际部署网络中的应用。

Method: 1) 将最严格的有限密钥安全分析集成到BBM92协议中；2) 改进混合系统设计，确保处理时间与秘密指令大小呈线性比例；3) 采用信息论安全的指令序列来确定不同原语的配置，即使QKD和PQC原语都被攻破也能保证消息机密性。

Result: 实现了迄今为止BBM92协议最严格的有限密钥安全性，并设计了具有线性可扩展性的混合系统架构，能够在实际部署环境中提供更强的安全保障。

Conclusion: 该工作通过集成有限密钥安全分析和改进系统设计，显著提升了混合QKD-PQC系统的实用性和安全性，为实际量子安全通信网络的部署提供了更可靠的解决方案。

Abstract: Recent advances in quantum-secure communication have highlighted the value of hybrid schemes that combine Quantum Key Distribution (QKD) with Post-Quantum Cryptography (PQC). Yet most existing hybrid designs omit realistic finite-key effects on QKD key rates and do not specify how to maintain security when both QKD and PQC primitives leak information through side-channels. These gaps limit the applicability of hybrid systems in practical, deployed networks. In this work, we advance a recently proposed hybrid QKD-PQC system by integrating tight finite-key security to the QKD primitive and improving the design for better scalability. This hybrid system employs an information-theoretically secure instruction sequence that determines the configurations of different primitives and thus ensures message confidentiality even when both the QKD and the PQC primitives are compromised. The novelty in our work lies in the implementation of the tightest finite-key security to date for the BBM92 protocol and the design improvements in the primitives of the hybrid system that ensure the processing time scales linearly with the size of secret instructions.

</details>


### [79] [Less is more: subspace reduction for counterdiabatic driving of Rydberg atom arrays](https://arxiv.org/abs/2512.04494)
*Wen Ting Hsieh,Dries Sels*

Main category: quant-ph

TL;DR: 该研究探索在里德堡原子系统中结合子空间方法和反绝热驱动来解决最大独立集问题，通过子空间技术显著降低了计算成本同时保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 精确的反绝热驱动虽然性能优异，但计算成本过高且不可扩展。需要找到一种方法在保持性能的同时降低计算复杂度，使反绝热驱动能在实际量子系统中实用化。

Method: 采用子空间方法改进反绝热驱动：1) 将分析限制在系统的相关子空间，加速直接对角化和Krylov方法获取反绝热矩阵；2) 使用基于子空间的成本函数进一步优化标准Krylov方法中的成本函数。

Result: 子空间技术显著加速了反绝热驱动的计算过程，同时保持了强大的性能表现。基于子空间的成本函数进一步优化了标准Krylov方法。

Conclusion: 这些发现为在各种量子系统中以实用且高效的方式应用反绝热驱动开辟了新的可能性，解决了原有方法计算成本过高的问题。

Abstract: This study explores the use of subspace methods in combination with counterdiabatic driving in a Rydberg atom system to solve the Maximum Independent Set (MIS) problem. Although exact counterdiabatic driving offers excellent performance, it comes at an unscalable computational cost. In this work, we demonstrate that counterdiabatic driving can be significantly improved by restricting the analysis to a relevant subspace of the system. We first show that both direct diagonalization and the Krylov method for obtaining the counterdiabatic matrix can be accelerated through the use of subspace techniques, while still maintaining strong performance. We then demonstrate that the cost function used in the standard Krylov method can be further optimized by employing a subspace-based cost function. These findings open up new possibilities for applying counterdiabatic driving in a practical and efficient manner to a variety of quantum systems.

</details>


### [80] [Universal quantum control over non-Hermitian continuous-variable systems](https://arxiv.org/abs/2512.04495)
*Zhu-yao Jin,Jun Jing*

Main category: quant-ph

TL;DR: 提出非厄米连续变量系统的一般控制理论，利用瞬时框架中的规范势而非能谱，实现任意数量玻色子模式的量子控制，并应用于腔磁子系统中的完美和非互易态转移。


<details>
  <summary>Details</summary>
Motivation: 现有非厄米量子系统控制研究局限于低维系统且严重依赖能谱奇点，需要发展适用于任意数量玻色子模式的一般控制理论。

Method: 在瞬时框架中分析非厄米连续变量系统动力学，利用与时间相关辅助算符的规范势，通过哈密顿量系数矩阵的上三角化条件实现非绝热海森堡通道。

Result: 建立了非厄米连续变量系统的通用量子控制理论，在腔磁子系统中实现了与宇称时间对称性和能谱异常点无关的完美态转移，以及与非互易完美吸收一致的非互易态转移。

Conclusion: 将通用量子控制理论扩展到非厄米连续变量系统，为相干控制提供了有前景的方法，系统波函数概率守恒可在通道末端自然恢复而无需人工归一化。

Abstract: Although the control of non-Hermitian quantum systems has a growing interest for their nonunitary feature in the time evolution, the existing discussions are not more than two or three dimensions and heavily influenced by the singularity of the energy spectrum. We here develop a general theory to control an arbitrary number of bosonic modes governed by the time-dependent non-Hermitian Hamiltonian. It takes advantage of the gauge potential in the instantaneous frame rather than the energy spectrum of Hamiltonian. In particular, the dynamics of a general non-Hermitian continuous-variable system is analyzed in the instantaneous frame associated with time-dependent ancillary operators that are superpositions of the laboratory-frame operators and irrelevant to the original Hamiltonian. The gauge potential is determined by the unitary transformation between the time-dependent and stationary ancillary frames. The upper triangularization condition for the Hamiltonian's coefficient matrix in the stationary ancillary frame enables two of the time-dependent ancillary operators to be nonadiabatic Heisenberg passages of the non-Hermitian system. The probability conservation of the system wavefunction can be restored at the end of these passages without artificial normalization. Our theory is exemplified with the perfect and nonreciprocal state transfers in a cavity magnonic system. The former holds for arbitrary initial states and is irrelevant to the parity-time symmetry of the Hamiltonian and the exceptional point of the spectra; and the latter is consistent with the unidirectional perfect absorbtion. Our work essentially extends the universal quantum control (UQC) theory to the non-Hermitian continuous-variable systems, providing a promising approach for their coherent control.

</details>


### [81] [QReach: A Reachability Analysis Tool for Quantum Markov Chains](https://arxiv.org/abs/2512.04497)
*Aochu Dai,Mingsheng Ying*

Main category: quant-ph

TL;DR: QReach是首个基于CFLOBDD决策图的量子马尔可夫链可达性分析工具，提供可达子空间查找和模型检查子程序，实验证明其在量子电路和算法验证中的实用性。


<details>
  <summary>Details</summary>
Motivation: 量子计算系统需要形式化验证工具来确保正确性，但现有工具缺乏针对量子马尔可夫链的可达性分析能力。QReach旨在填补这一空白，为量子系统验证提供基础框架。

Method: 基于CAV 2023提出的CFLOBDD（决策图）技术，开发了量子马尔可夫链的可达性分析框架，包括可达子空间查找算法和图像计算等模型检查子程序。

Result: 实验结果表明QReach在量子电路和算法验证中具有实际应用价值，能够有效分析量子系统的可达性特性。

Conclusion: QReach是首个量子马尔可夫链可达性分析工具，预计将在未来量子模型检查器中发挥核心作用，推动量子系统形式化验证的发展。

Abstract: We present QReach, the first reachability analysis tool for quantum Markov chains based on decision diagrams CFLOBDD (presented at CAV 2023). QReach provides a novel framework for finding reachable subspaces, as well as a series of model-checking subprocedures like image computation. Experiments indicate its practicality in verification of quantum circuits and algorithms. QReach is expected to play a central role in future quantum model checkers.

</details>


### [82] [Optimal Scaling Quantum Interior Point Method for Linear Optimization](https://arxiv.org/abs/2512.04510)
*Mohammadhossein Mohammadisiahroudi,Zeguan Wu,Pouya Sampourmahani,Jun-Kai You,Tamás Terlaky*

Main category: quant-ph

TL;DR: 提出一种新颖的量子-经典混合内点法，利用量子计算机求解牛顿系统并进行矩阵向量运算，实现O(n²)最坏情况复杂度，显著提升大规模线性优化问题的计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习等应用中大规模数据密集型线性优化问题的出现，传统内点法虽然具有多项式时间收敛性，但在处理稠密大规模问题时每次迭代成本过高。量子线性系统求解器显示出加速内点法中线性系统求解的潜力。

Method: 提出一种几乎精确的量子内点法：在量子计算机上构造和求解牛顿系统，在经典机器上进行解更新；所有矩阵向量乘积都在量子硬件上执行；结合迭代精炼技术处理量子操作的有限精度问题。

Result: 算法实现O(n²)的最坏情况复杂度，量子复杂度为O(n¹.⁵κ_A log(1/ε))次QRAM查询，经典算术操作为O(n² log(1/ε))。在稠密线性优化问题上优于现有经典和量子内点法的最坏情况复杂度。

Conclusion: 该量子-经典混合框架在可扩展性和计算效率方面提供了显著改进，为大规模线性优化问题提供了更高效的解决方案，特别是在处理稠密问题时展现出优越性能。

Abstract: The emergence of huge-scale, data-intensive linear optimization (LO) problems in applications such as machine learning has driven the need for more computationally efficient interior point methods (IPMs). While conventional IPMs are polynomial-time algorithms with rapid convergence, their per-iteration cost can be prohibitively high for dense large-scale LO problems. Quantum linear system solvers have shown potential in accelerating the solution of linear systems arising in IPMs. In this work, we introduce a novel almost-exact quantum IPM, where the Newton system is constructed and solved on a quantum computer, while solution updates occur on a classical machine. Additionally, all matrix-vector products are performed on the quantum hardware. This hybrid quantum-classical framework achieves an optimal worst-case scaling of $\mathcal{O}(n^2)$ for fully dense LO problems. To ensure high precision, despite the limited accuracy of quantum operations, we incorporate iterative refinement techniques both within and outside the proposed IPM iterations. The proposed algorithm has a quantum complexity of $\mathcal{O}(n^{1.5} κ_A \log(\frac{1}ε))$ queries to QRAM and $\mathcal{O}(n^2 \log(\frac{1}ε))$ classical arithmetic operations. Our method outperforms the worst-case complexity of prior classical and quantum IPMs, offering a significant improvement in scalability and computational efficiency.

</details>


### [83] [Efficient Identification the Inequivalence of Mutually Unbiased Bases via Finite Operators](https://arxiv.org/abs/2512.04543)
*Jianxin Song,Zhen-Peng Xu,Changliang Ren*

Main category: quant-ph

TL;DR: 提出一种操作性的方法来识别MUB子集的不等价性，降低了时间复杂度并避免了计算精度问题，获得了更紧的分类上界，成功确定了d≤17维度的精确分类。


<details>
  <summary>Details</summary>
Motivation: 高维相互无偏基(MUBs)的结构表征是一个主要开放问题，现有方法不仅无法得出精确分类，还受到计算资源和数值精度问题的严重限制。

Method: 引入一种操作性的方法来识别MUBs子集的不等价性，该方法具有更低的时间复杂度并完全避免计算精度问题。对于任意素数维度中的k元素MUBs子集，该方法给出了MUBs等价类数量的通用解析上界。通过简单迭代应用该方法，进一步获得了d≤37维度的更紧分类上界。

Result: 该方法的上界与现有下界比较，成功确定了所有d≤17维度的MUBs子集的精确分类。该方法还扩展到维度为素数幂的情况。

Conclusion: 这个通用且可扩展的MUBs子集分类框架为相关应用提供了新的见解。

Abstract: The structural characterization of high-dimensional mutually unbiased bases (MUBs) by classifying MUBs subsets remains a major open problem. The existing methods not only fail to conclude on the exact classification, but also are severely limited by computational resources and suffer from the numerical precision problem. Here we introduce an operational approach to identify the inequivalence of MUBs subsets, which has less time complexity and entirely avoids the computational precision issues. For arbitrary MUBs subsets of $k$ elements in any prime dimension, this method yields a universal analytical upper bound for the amount of MUBs equivalence classes. By applying this method through simple iterations, we further obtain tighter classification upper bounds for any prime dimension $d\leq 37$. Crucially, the comparison of these upper bounds with existing lower bounds successfully determines the exact classification for all MUBs subsets in any dimension $d \leq 17$. We further extend this method to the case that the dimension is a power of prime number. This general and scalable framework for the classification of MUBs subsets sheds new light on related applications.

</details>


### [84] [A Qudit-native Framework for Discrete Time Crystals](https://arxiv.org/abs/2512.04577)
*Wei-Guo Ma,Heng Fan,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: 提出基于qudit的离散时间晶体设计框架，通过限制驱动到特定子空间来抑制加热，实现稳定的多周期时间晶体。


<details>
  <summary>Details</summary>
Motivation: 现有时间晶体设计方法存在加热和不稳定性问题，需要一种系统化的硬件高效方法来设计稳定的Floquet物质相。

Method: 使用qudit原生框架，将周期驱动限制在指定的在位子空间，创建嵌入式kick来防止粒子数泄漏。通过正规形式分析分解有效动力学，包括载波锁定、中性项和带电项。

Result: 在多种qudit平台上验证了框架的预测能力：在spin-1链中通过子空间限制增强DTC稳定性；在spin-3/2系统中证明鲁棒性由子空间划分对称性决定；在spin-2平台上实现并发的2T和3T DTC。

Conclusion: 建立了一种系统化的硬件高效方法，用于在现代qudit量子处理器上设计稳定和多功能的Floquet物质相。

Abstract: We introduce a qudit-native framework for engineering robust discrete time crystals (DTCs) by leveraging their internal multilevel structure. Our approach confines the periodic drive to specified on-site subspaces, creating an embedded kick that suppresses heating by preventing population leakage to inactive levels. We underpin DTC stability with a normal-form analysis that decomposes the effective dynamics into distinct components: the carrier locks the subharmonic frequency, neutral terms govern the slow decay and dephasing of the subharmonic response, and charged terms scatter spectral weight away from the locked modes. This framework's predictive power is demonstrated across various qudit platforms: in spin-1 chains, we enhance the stability of DTC by confining the drive to a subspace; in spin-3/2 systems, we show that robustness is dictated by the symmetry of the subspace partition; and in spin-2 platforms, we realize concurrent 2T and 3T DTCs under a unified drive. These findings establish a systematic, hardware-efficient methodology for designing stable and multifunctional Floquet phases of matter on modern qudit-based quantum processors.

</details>


### [85] [Supramolecular approach-based intermolecular interaction energy calculations using quantum phase estimation algorithm](https://arxiv.org/abs/2512.04587)
*Yuhei Tachi,Akihiko Arakawa,Taisei Osawa,Masayoshi Terabe,Kenji Sugisaki*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子相位估计的完整活性空间构型相互作用（QPE-CASCI）方法，结合MP2活性空间选择和Boys局域轨道，用于高效计算非共价分子间相互作用能，在水二聚体模拟中实现了高精度结果。


<details>
  <summary>Details</summary>
Motivation: 准确计算非共价分子间相互作用能对于理解化学现象至关重要，量子计算机有望加速这一过程。尽管当前量子计算机仍处于噪声中等规模阶段，但开发适用于容错量子计算机的理论框架是紧迫需求。

Method: 采用基于量子相位估计的完整活性空间构型相互作用（QPE-CASCI）方法，结合二阶Møller-Plesset微扰理论（MP2）活性空间选择和Boys局域轨道，使用6个系统量子比特和6个辅助量子比特进行超分子方法的水二聚体分子间相互作用能计算模拟。

Result: 通过算法误差缓解技术，QPE-CASCI模拟实现了与CASCI结果相比仅0.02 kcal mol⁻¹的误差，证明了所提方法的准确性和效率。同时展示了量子电路压缩的初步结果，减少了双量子比特门数量和深度。

Conclusion: 该研究展示了QPE-CASCI方法在计算分子间相互作用能方面的潜力，为在容错量子计算机上实现高效量子化学计算提供了有前景的框架，特别是在结合算法误差缓解和电路压缩技术后表现出良好性能。

Abstract: Accurate computation of non-covalent, intermolecular interaction energies is important to understand various chemical phenomena, and quantum computers are anticipated to accelerate it. Although the state-of-the-art quantum computers are still noisy and intermediate-scale ones, development of theoretical frameworks those are expected to work on a fault-tolerant quantum computer is an urgent issue. In this work, we explore resource-efficient implementation of the quantum phase estimation-based complete active space configuration interaction (QPE-CASCI) calculations, with the aid of the second-order Møller--Plesset perturbation theory (MP2)-based active space selection with Boys localized orbitals. We performed numerical simulations of QPE for the supramolecular approach-based intermolecular interaction energy calculations of the hydrogen-bonded water dimer, using 6 system and 6 ancilla qubits. With the aid of algorithmic error mitigation, the QPE-CASCI simulations achieved interaction energy predictions with an error of 0.02 kcal mol$^{-1}$ relative to the CASCI result, demonstrating the accuracy and efficiency of the proposed methodology. Preliminary results on quantum circuit compression for QPE are also presented to reduce the number of two-qubit gates and depth.

</details>


### [86] [Phase noise characterisation of a 2-km Hollow-Core Nested Antiresonant Nodeless Fibre for Twin-Field Quantum Key Distribution](https://arxiv.org/abs/2512.04605)
*Mariella Minder,Sophie Albosh,Obada Alia,Radan Slavik,Rupesh Kumar,Francesco Poletti,George Kanellos,Marco Lucamarini*

Main category: quant-ph

TL;DR: 空心光纤在相位噪声方面表现出色，适合用于基于相位的量子密钥分发协议


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发性能受信道物理特性影响，传统单模光纤存在传播损耗和相位扰动问题，而空心光纤可能成为更好的替代方案，但其相位噪声特性尚未验证

Method: 进行两个实验：1) 在双不对称马赫-曾德尔干涉仪配置中同时测量2公里空心光纤和单模光纤；2) 使用包含空心光纤和单模光纤信道的TF-QKD干涉仪

Result: 初步结果表明空心光纤在相位噪声方面表现良好，适合用于TF-QKD和其他基于相位的QKD协议

Conclusion: 空心光纤是相位基量子密钥分发协议的可行替代方案，具有相位噪声抗扰性

Abstract: The performance of quantum key distribution (QKD) is heavily dependent on the physical properties of the channel over which it is executed. Propagation losses and perturbations in the encoded photons' degrees of freedom, such as polarisation or phase, limit both the QKD range and key rate. The maintenance of phase coherence over optical fibres has lately received considerable attention as it enables QKD over long distances, e.g., through phase-based protocols like Twin-Field (TF) QKD. While optical single mode fibres (SMFs) are the current standard type of fibre, recent hollow core fibres (HCFs) could become a superior alternative in the future. Whereas the co-existence of quantum and classical signals in HCF has already been demonstrated, the phase noise resilience required for phase-based QKD protocols is yet to be established. This work explores the behaviour of HCF with respect to phase noise for the purpose of TF-QKD-like protocols. To achieve this, two experiments are performed. The first, is a set of concurrent measurements on 2 km of HCF and SMF in a double asymmetric Mach-Zehnder interferometer configuration. The second, uses a TF-QKD interferometer consisting of HCF and SMF channels. These initial results indicate that HCF is suitable for use in TF-QKD and other phase-based QKD protocols.

</details>


### [87] [Ground state energy and phase transitions of Long-range XXZ using VQE](https://arxiv.org/abs/2512.04615)
*Mrinal Dev,Shraddha Sharma*

Main category: quant-ph

TL;DR: 使用VQE探测无限阶相变边界，通过设计对相敏感的ansatz电路，根据基态能量误差变化确定相边界


<details>
  <summary>Details</summary>
Motivation: 传统方法难以解析求解某些哈密顿量的基态能量，VQE已被广泛用于计算这些经典难解问题。本研究旨在利用VQE探测无限阶相变的相边界，特别是针对长程XXZ链模型。

Method: 设计特殊的ansatz电路，使其对相敏感：通过施加净自旋保持恒定的约束，使ansatz在特定相中工作良好（误差小），在其他相中失效（误差大）。通过分析VQE基态能量误差的行为变化来确定相边界。同时使用精确对角化比较能量梯度和能隙在相变边界的行为。

Result: 成功利用VQE确定了无限阶相变的相边界。通过增加优化电路的深度，准确计算了耦合常数J=-1时长程XXZ链的基态能量。误差分析显示ansatz在不同相中的表现差异明显，这为相边界识别提供了可靠依据。

Conclusion: VQE不仅可以用于计算基态能量，还可以通过精心设计的ansatz电路来探测相变边界。该方法为研究无限阶相变提供了一种新的量子计算工具，特别适用于经典难解的量子多体系统。

Abstract: The variational quantum eigen solver (VQE), has been widely used to find the ground state energy of different Hamiltonians with no analytical solutions and are classically difficult to compute. In our work, we have used VQE to identify the phase transition boundary for an infinite order phase transition. We use long-range XXZ (LRXXZ) chain for our study. In order to probe infinite order phase transition, we propose to utilise the ground state energy obtained from VQE. The idea rests on the argument that VQE requires an ansatz circuit; therefore, the accuracy of the VQE will rely on this ansatz circuit. We have designed this circuit such that the estimated ground state energy is sensitive to the phase it is evaluated in. It is achieved by applying the constraint that the net spin remains constant throughout the optimisation process. Consequently, the ansatz works in a certain phase where it gives relatively small random error, as it should, when compared to the error in ground state energy calculations of the other phases, where the ansatz fails. By identifying these changes in the behaviour of the error in ground state energy using VQE, we were able to determine the phase boundaries. Using exact diagonalisation, we also compare the behaviour of the energy gradient and energy gap across both the phase transition boundaries for this model. Further, by increasing the depth of the optimisation circuit, we also accurately evaluate the ground energy of the LRXXZ chain for the value of coupling constant, J equal to -1

</details>


### [88] [Probing false vacuum decay and bubble nucleation in a Rydberg atom array](https://arxiv.org/abs/2512.04637)
*Yu-Xin Chao,Peiyun Ge,Zhen-Xing Hua,Chen Jia,Xiao Wang,Xinhui Liang,Zongpei Yue,Rong Lu,Meng Khoon Tey,Xiao Wang,Li You*

Main category: quant-ph

TL;DR: 利用里德堡原子环模拟量子场论中的假真空衰变和气泡成核过程，观测到衰变率随对称破缺场指数衰减的量子场论预测行为


<details>
  <summary>Details</summary>
Motivation: 量子场论中的假真空衰变是基础物理现象，但难以在真实量子场系统中直接观测。需要利用可控量子模拟平台（如里德堡原子系统）来研究这一过程及其超越标准伊辛模型的物理特性

Method: 使用里德堡原子环作为量子模拟平台，利用长程范德瓦尔斯相互作用和单点寻址能力，研究假真空衰变和气泡成核过程，特别关注对称破缺场对衰变率的影响

Result: 观测到假真空衰变率随对称破缺场倒数指数衰减，与量子场论预测一致；发现即使微小偏离理想亚稳态也会导致普适标度律显著偏离；观察到离散能谱系统特有的共振气泡成核现象

Conclusion: 里德堡原子系统成功模拟了量子场论中的假真空衰变物理，揭示了超越标准模型的特性，为研究高维或复杂几何中的多体隧穿现象开辟了新途径

Abstract: In quantum field theory (QFT), the "vacuum" is not just empty space but the lowest-energy state of a quantum field. If the energy landscape has multiple local minima, the local ground states are the false vacuum (FV) which can tunnel towards the global ground state (true vacuum, TV). This process exhibits signature akin to classical supercooled gas transitions and many-body tunneling in discrete quantum systems. Here, we study the FV decay and bubble nucleation in a Rydberg atom ring. The long-range van-der-Waals interactions and individual-site addressability allow us to explore physics beyond the standard Ising model. We observe that the FV decay rate decreases exponentially with the inverse of the symmetry-breaking field, directly mirroring QFT predictions. Moreover, we demonstrate that even minor deviations from the ideal metastable state can cause a stark departure from this universal scaling law. Extending beyond short-time decay dynamics, we also examine resonant bubble nucleation, a feature distinctive to systems with discrete energy spectra. Our findings and methods open avenues for future studies of many-body tunneling in higher dimensions or more complex geometries.

</details>


### [89] [Probing chiral topological states with permutation defects](https://arxiv.org/abs/2512.04649)
*Yarden Sheffer,Ruihua Fan,Ady Stern,Erez Berg,Shinsei Ryu*

Main category: quant-ph

TL;DR: 提出一种通过多体纠缠测量从体波函数探测手征拓扑相的方法，利用不同排列在相邻区域创建"排列缺陷"，能够提取手征中心荷和霍尔电导。


<details>
  <summary>Details</summary>
Motivation: 二维手征拓扑相在空间边界存在反常无能隙模式，但这些边缘异常在体基态波函数本身的体现仍不完全清楚。需要直接从体波函数探测手征性的方法。

Method: 引入一系列多体纠缠测量，通过在相邻空间区域对基态波函数副本应用不同排列，创建"排列缺陷"。建立场论框架系统计算这些测量，证明排列缺陷的规整化必须引入无能隙边界模式。

Result: 该方法正确识别出手征贡献为高亏格黎曼曲面上的手征共形场论配分函数。数值验证显示与自由费米子和强相互作用手征拓扑态结果一致，能够提取手征中心荷和霍尔电导。

Conclusion: 提出的多体纠缠测量方法能够直接从体波函数探测手征拓扑相，使手征中心荷和霍尔电导可通过有限波函数副本提取，适用于蒙特卡洛数值技术和含噪声中等规模量子设备。

Abstract: The hallmark of two-dimensional chiral topological phases is the existence of anomalous gapless modes at the spatial boundary. Yet, the manifestation of this edge anomaly within the bulk ground-state wavefunction itself remains only partially understood. In this work, we introduce a family of multipartite entanglement measures that probe chirality directly from the bulk wavefunction. Our construction involves applying different permutations between replicas of the ground state wavefunction in neighboring spatial regions, creating "permutation defects" at the boundaries between these regions. We provide general arguments for the robustness of these measures and develop a field-theoretical framework to compute them systematically. While the standard topological field theory prescription misses the chiral contribution, our method correctly identifies it as the chiral conformal field theory partition function on high-genus Riemann surfaces. This feature is a consequence of the bulk-edge correspondence, which dictates that any regularization of the theory at the permutation defects must introduce gapless boundary modes. We numerically verify our results with both free-fermion and strongly-interacting chiral topological states and find excellent agreement. Our results enable the extraction of the chiral central charge and the Hall conductance using a finite number of wavefunction replicas, making these quantities accessible to Monte-Carlo numerical techniques and noisy intermediate-scale quantum devices.

</details>


### [90] [Watt-level coherent microwave emission from dissipation engineered solid-state quantum batteries](https://arxiv.org/abs/2512.04666)
*Yuanjin Wang,Hao Wu,Mark Oxborrow,Qing Zhao*

Main category: quant-ph

TL;DR: 该论文提出通过耗散工程实现高功率相干微波量子电池，通过时间分离能量存储和释放过程，实现瓦级峰值功率的纳秒微波脉冲。


<details>
  <summary>Details</summary>
Motivation: 量子电池在相干微波生成方面有潜力，但面临量子关联、老化、自放电等挑战。对于腔量子电动力学量子电池，还存在强自旋-光子耦合（能量存储）与足够输出耦合（功率传输）之间的权衡问题。

Method: 引入耗散工程作为动态控制策略，时间分离能量存储和释放过程：充电时抑制发射，放电时快速增强输出耦合。优化了三种耗散方案。

Result: 实现了纳秒级微波脉冲，峰值功率达瓦级。将量子电池的工作提取效率提高了两个数量级以上，功率压缩因子优于现有技术。

Conclusion: 耗散工程为实现室温、高功率相干微波源提供了一条有效途径，解决了量子电池在功率输出方面的基本限制。

Abstract: Recently proposed metastability-induced quantum batteries have shown particular promise for coherent microwave generation. However, achieving high-power coherent microwave generation in quantum batteries remains fundamentally challenging due to quantum correlations, aging, and self-discharging processes. For the cavity-quantum-electrodynamics (CQED)-based quantum batteries, a further trade-off arises between strong spin-photon coupling for energy storage and sufficient output coupling for power delivery. To overcome these constraints, we introduce dissipation engineering as a dynamic control strategy that temporally separates energy storage and release. By suppressing emission during charging and rapidly enhancing the output coupling during discharging, we realize nanosecond microwave bursts with watt-level peak power. By optimizing three dissipation schemes, we improve work extraction efficiency of the quantum battery by over two orders of magnitude and achieve high power compression factors outperforming the state-of-the-art techniques, establishing dissipation engineering as a pathway toward room-temperature, high-power coherent microwave sources.

</details>


### [91] [Quantum-Inspired Optimization through Qudit-Based Imaginary Time Evolution](https://arxiv.org/abs/2512.04710)
*Erik M. Åsgrim,Ahsan Javed Awan*

Main category: quant-ph

TL;DR: 提出一种基于量子启发的经典算法，使用多能级量子态（qudits）解决组合优化问题，通过虚时演化框架和自适应梯度方法改进收敛性。


<details>
  <summary>Details</summary>
Motivation: 虚时演化在量子硬件上解决组合优化问题已显示出潜力，但需要开发能在经典计算机上高效模拟的方法。传统二进制编码会导致变量数量增加，而多能级量子态编码可以减少变量数量并自然地处理单关联约束。

Method: 使用qudits（多能级量子态）编码整数决策变量，将系统约束在乘积态以实现经典高效模拟。通过虚时演化的酉算子序列优化qudit态，提出自适应梯度方法选择生成状态演化的厄米算子以改进收敛性。

Result: 在带约束的Min-d-Cut问题上表现出有希望的结果，特别是在较大的d值时，优于Gurobi在惩罚约束公式上的表现。

Conclusion: 提出的量子启发经典算法通过qudit编码和自适应梯度虚时演化，为组合优化问题提供了一种有效的解决方案，在经典模拟效率和求解质量方面都显示出优势。

Abstract: Imaginary-time evolution has been shown to be a promising framework for tackling combinatorial optimization problems on quantum hardware. In this work, we propose a classical quantum-inspired strategy for solving combinatorial optimization problems with integer-valued decision variables by encoding decision variables into multi-level quantum states known as qudits. This method results in a reduced number of decision variables compared to binary formulations while inherently incorporating single-association constraints. Efficient classical simulation is enabled by constraining the system to remain in a product state throughout optimization. The qudit states are optimized by applying a sequence of unitary operators that iteratively approximate the dynamics of imaginary time evolution. Unlike previous studies, we propose a gradient-based method of adaptively choosing the Hermitian operators used to generate the state evolution at each optimization step, as a means to improve the convergence properties of the algorithm. The proposed algorithm demonstrates promising results on Min-d-Cut problem with constraints, outperforming Gurobi on penalized constraint formulation, particularly for larger values of d.

</details>


### [92] [Hybrid VQE-CVQE algorithm using diabatic state preparation](https://arxiv.org/abs/2512.04801)
*John P. T. Stenger,C. Stephen Hellberg,Daniel Gunlycke*

Main category: quant-ph

TL;DR: 提出一种混合变分量子算法，结合量子电路和经典优化的变分参数，适用于误差校正和中等规模量子计算机，在IBM Brisbane上模拟达到化学精度


<details>
  <summary>Details</summary>
Motivation: 开发一种既能利用量子电路变分参数又能结合经典优化参数的混合算法，使其既适用于长期误差校正量子计算机，也适用于短期中等规模量子计算机

Method: 采用绝热态制备生成参数化酉算子，类似VQE应用于量子比特寄存器，量子测量结果用于CVQE的经典优化过程

Result: 在相互作用电子系统上演示算法，IBM Brisbane模拟产生的能量在化学精度范围内

Conclusion: 该混合变分量子算法结合了量子电路和经典优化的优势，为量子计算在化学模拟中的应用提供了有效途径

Abstract: We propose a hybrid variational quantum algorithm that has variational parameters used by both the quantum circuit and the subsequent classical optimization. Similar to the Variational Quantum Eigensolver (VQE), this algorithm applies a parameterized unitary operator to the qubit register. We generate this operator using diabatic state preparation. The quantum measurement results then inform the classical optimization procedure used by the Cascaded Variational Quantum Eigensolver (CVQE). We demonstrate the algorithm on a system of interacting electrons and show how it can be used on long-term error-corrected as well as short-term intermediate-scale quantum computers. Our simulations performed on IBM Brisbane produced energies well within chemical accuracy.

</details>


### [93] [Mitigating Residual Exchange Coupling in Resonant Singlet-Triplet Qubits](https://arxiv.org/abs/2512.04846)
*Jiheng Duan,Fernando Torres-Leal,John M. Nichol*

Main category: quant-ph

TL;DR: 提出缓解交换耦合谐振单重态-三重态量子比特系统中单比特和双比特控制误差的方法，包括使用整数倍驱动周期和单自旋耦合器来降低误差。


<details>
  <summary>Details</summary>
Motivation: 交换耦合谐振单重态-三重态量子比特系统中存在残余交换耦合导致的控制误差，包括单比特和双比特操作中的误差，这限制了量子处理器的可扩展性和容错能力。

Method: 1. 使用整数倍驱动周期（脉冲长度是驱动周期的整数倍）来缓解残余内量子比特交换引起的误差；2. 在两个谐振单重态-三重态量子比特之间使用单自旋耦合器来减少串扰误差。

Result: 整数倍驱动周期能有效缓解残余交换误差；单自旋耦合器可将串扰误差降低一个数量级；在完美耦合器状态准备和实际噪声条件下，双量子比特门误差可低于3×10^-3，门时间短至66纳秒。

Conclusion: 基于耦合器的架构对于构建基于谐振单重态-三重态量子比特的大规模容错自旋量子比特处理器具有潜力，能有效降低控制误差并提高操作保真度。

Abstract: We propose methods to mitigate single- and two-qubit control errors due to residual exchange coupling in systems of exchange-coupled resonant singlet-triplet qubits. Commensurate driving, where the pulse length is an integer multiple of the drive period, can mitigate errors from residual intra-qubit exchange, including effects from counter rotating terms and off-axis rotations, as well as leakage errors during two-qubit operations. Residual inter-qubit exchange creates crosstalk errors that reduce single-qubit control fidelities. We show that using a single-spin coupler between two resonant singlet-triplet qubits can reduce this crosstalk error by an order of magnitude. Assuming perfect coupler state preparation and realistic charge and hyperfine noise, we predict that coupler-assisted two-qubit gate errors can be below $3\times10^{-3}$ for gate times as short as $66~\text{ns}$, even in the presence of residual exchange levels exceeding several hundred kHz. Our results suggest the potential of utilizing coupler-based architectures for large scale fault-tolerant spin qubit processors based on resonant singlet-triplet qubits.

</details>


### [94] [Bayesian stepwise estimation of qubit rotations](https://arxiv.org/abs/2512.04898)
*Mylenne Manrique,Marco Barbieri,Assunta Di Vizio,Miranda Parisi,Gabriele Bizzarri,Ilaria Gianani,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 贝叶斯逐步估计在量子比特旋转参数测量中，虽然渐近分析预测其在奇异Fisher信息矩阵下有优势，但实际有限资源下该优势被削弱，不过逐步策略仍保持实用优势


<details>
  <summary>Details</summary>
Motivation: 研究贝叶斯逐步估计在测量量子比特旋转两个参数时的性能，探索在量子Fisher信息矩阵接近奇异（"松散"模型）时，逐步估计相对于联合估计的理论优势是否能在实际有限资源场景中保持

Method: 采用贝叶斯逐步估计协议，使用偏振量子比特进行实验实现，将总误差与经典Van Trees界限和量子Van Trees界限进行比较，分析先验分布平均对渐近优势的影响

Result: 实验实现了接近经典Van Trees界限的不确定度，但将总误差与联合估计的量子Van Trees界限比较发现，先验分布平均消除了渐近逐步估计优势；然而逐步策略仍保持实用优势，因为它仅需简单固定测量，而饱和联合估计界限通常需要复杂参数相关操作

Conclusion: 在实际有限资源贝叶斯框架中，逐步估计的渐近优势被削弱，但该策略仍具有重要实用价值，因为它仅需简单固定测量即可有效工作，而联合估计通常需要复杂参数相关操作才能达到理论界限

Abstract: This work investigates Bayesian stepwise estimation (Se) for measuring the two parameters of a unitary qubit rotation. While asymptotic analysis predicts a precision advantage for SE over joint estimation (JE) in regimes where the quantum Fisher information matrix is near-singular ("sloppy" models), we demonstrate that this advantage is mitigated within a practical Bayesian framework with limited resources. We experimentally implement a SE protocol using polarisation qubits, achieving uncertainties close to the classical Van Trees bounds. However, comparing the total error to the ultimate quantum Van Trees bound for JE reveals that averaging over prior distributions erases the asymptotic SE advantage. Nevertheless, the stepwise strategy retains a significant practical benefit as it operates effectively with simple, fixed measurements, whereas saturating the JE bound typically requires complex, parameter-dependent operations.

</details>


### [95] [Multiphoton interference outperforms pairwise overlaps for distinguishability characterization](https://arxiv.org/abs/2512.04903)
*S. N. van den Hoven,M. C. Anguita,S. Marzban,J. J. Renema*

Main category: quant-ph

TL;DR: 提出一种利用多光子干涉来更高效表征单光子内部模式重叠的协议，相比传统的成对Hong-Ou-Mandel实验有显著优势


<details>
  <summary>Details</summary>
Motivation: 传统的Hong-Ou-Mandel实验需要成对地测量光子模式重叠，效率较低。需要一种更高效的方法来表征多个光子的内部模式重叠关系

Method: 提出一种利用多光子干涉的新协议，通过实验实现了对三个光子的表征。使用Fisher信息矩阵来量化表征性能

Result: 实验证明该协议在表征三个光子时优于传统的成对Hong-Ou-Mandel方法，即使在Hong-Ou-Mandel实验在无噪声完美条件下也是如此

Conclusion: 多光子干涉协议为高效表征光子模式重叠提供了新方法，在量子信息处理等领域具有应用潜力

Abstract: We propose a protocol that characterizes the pairwise overlaps of the internal modes of single photons more efficiently than pairwise Hong-Ou-Mandel characterization experiments. This protocol exploits multiphoton interference. We experimentally implement this protocol to characterize three photons. We show that our implementation of the characterization protocol outperforms the pairwise Hong-Ou-Mandel characterization, even if the Hong-Ou-Mandel characterization would have been performed in a noiseless, perfect experiment. We demonstrate this via the Fisher information matrix.

</details>


### [96] [PVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers](https://arxiv.org/abs/2512.04909)
*Youla Yang*

Main category: quant-ph

TL;DR: PVLS使用图神经网络为变分量子线性求解器预测高质量初始参数，解决训练中的贫瘠高原问题，在16-1024维矩阵上实现2.6倍加速优化


<details>
  <summary>Details</summary>
Motivation: 变分量子线性求解器在近期量子设备上具有潜力，但受到贫瘠高原和低效参数初始化的限制，随着系统规模增大，可训练性显著下降

Method: 提出PVLS框架，使用图神经网络从系数矩阵中提取结构信息，为VQLS电路生成高质量初始参数，提高收敛性和可扩展性

Result: 在16-1024维矩阵上的实验表明，PVLS能提供高达2.6倍的优化加速，需要更少的迭代次数，同时保持相当的求解精度

Conclusion: 机器学习引导的参数初始化策略有潜力提高混合量子-经典算法在NISQ时代的实用性

Abstract: Variational Quantum Linear Solvers (VQLS) are a promising method for solving linear systems on near-term quantum devices. However, their performance is often limited by barren plateaus and inefficient parameter initialization, which significantly hinder trainability as the system size increases. In this work, we introduce PVLS, a learning-based parameter prediction framework that uses Graph Neural Networks (GNNs) to generate high-quality initial parameters for VQLS circuits. By leveraging structural information from the coefficient matrix, PVLS predicts expressive and scalable initializations that improve convergence and reduce optimization difficulty. Extensive experiments on matrix sizes ranging from 16 to 1024 show that PVLS provides up to a 2.6x speedup in optimization and requires fewer iterations while maintaining comparable solution accuracy. These results demonstrate the potential of machine-learning-guided initialization strategies for improving the practicality of hybrid quantum-classical algorithms in the NISQ era.

</details>


### [97] [Communicating Properties of Quantum States over Classical Noisy Channels](https://arxiv.org/abs/2512.04913)
*Nikhitha Nunavath,Jiechen Chen,Osvaldo Simeone,Riccardo Bassoli,Frank H. P. Fitzek*

Main category: quant-ph

TL;DR: 提出STT-UEP协议，利用经典阴影层析和不等错误保护，实现量子态性质的高效传输，通信复杂度仅对数级于可观测量数量。


<details>
  <summary>Details</summary>
Motivation: 量子态信息通过经典噪声信道传输面临指数级状态空间扩展的根本挑战，需要解决高效传输量子态性质的问题。

Method: 结合经典阴影层析测量效率和不等错误保护技术，对测量基使用更强的信道编码，测量结果使用较弱编码，实现高效通信。

Result: 通信复杂度仅对数级于可观测量数量（依赖于可观测量权重），相比传统方法指数级于量子比特数有显著改进，理论保证估计精度与信道误码率关系。

Conclusion: STT-UEP协议为量子态性质传输提供了高效解决方案，通过数值结果验证了协议相对于多个基准的优越性能。

Abstract: Transmitting information about quantum states over classical noisy channels is an important problem with applications to science, computing, and sensing. This task, however, poses fundamental challenges due to the exponential scaling of state space with system size. We introduce shadow tomography-based transmission with unequal error protection (STT-UEP), a novel communication protocol that enables efficient transmission of properties of quantum states, allowing decoder-side estimation of arbitrary observables. Unlike conventional approaches requiring the transmission of a number of bits that is exponential in the number of qubits, STT-UEP achieves communication complexity that scales logarithmically with the number of observables, depending on the observable weight. The protocol exploits classical shadow tomography for measurement efficiency, and applies unequal error protection by encoding measurement bases with stronger channel codes than measurement outcomes. We provide theoretical guarantees on estimation accuracy as a function of the bit error probability of the classical channel, and validate the approach against several benchmarks via numerical results.

</details>


### [98] [Circuit Quantum Acoustodynamics in a Scalable Phononic Integrated Circuit Architecture](https://arxiv.org/abs/2512.04953)
*Weiting Wang,Lintao Xiao,Bo Zhang,Yu Zeng,Ziyue Hua,Chuanlong Ma,Hongwei Huang,Yifang Xu,Jia-Qi Wang,Guangming Xue,Haifeng Yu,Xin-Biao Xu,Chang-Ling Zou,Luyan Sun*

Main category: quant-ph

TL;DR: 研究人员开发了可扩展的电路量子声动力学架构，通过将超导量子比特与无悬挂声子集成电路集成，实现了量子声学系统的可扩展连接


<details>
  <summary>Details</summary>
Motivation: 现有的量子声学系统局限于孤立器件，缺乏路由声子和互连多端口声学元件的能力，限制了系统的可扩展性

Method: 将可调谐transmon量子比特与波导集成声子腔体耦合，包括通过单片集成的法布里-珀罗腔和通过倒装芯片组装的微环腔

Result: 实现了量子比特与声子腔体之间的相干耦合，产生了显著的声子发射增强，Purcell因子达到约19

Conclusion: 这些器件代表了可扩展声子电路的基本构建模块，为基于声子的量子信息处理器和新型量子声学现象的研究平台奠定了基础

Abstract: Previous demonstrations of quantum acoustic systems have been limited to isolated devices, with limited capability to route phonons and interconnect multi-port acoustic elements for further extension. Here, we demonstrate a scalable architecture for circuit quantum acoustodynamics (cQAD) by integrating superconducting qubits with suspension-free phononic integrated circuits (PnICs). Coherent coupling between tunable transmon qubits and waveguide-integrated phononic cavities, including Fabry-Perot cavities via monolithic integration and microring cavities via flip-chip assembly, has been achieved, producing a pronounced enhancement of phonon emission with a Purcell factor of ~19. These devices represent elementary building blocks for scalable phononic circuits, establishing the foundation for phonon-based quantum information processors and the testbed for novel quantum acoustic phenomena.

</details>


### [99] [Introduction to quantum control: From basic concepts to applications in quantum technologies](https://arxiv.org/abs/2512.04990)
*Christiane P. Koch*

Main category: quant-ph

TL;DR: 量子控制教程章节，介绍利用经典电磁场操控量子系统的基本原理（相干控制和绝热跟随），以及复杂情况下的最优控制理论方法，重点应用于原子和超导量子比特。


<details>
  <summary>Details</summary>
Motivation: 量子控制是操控量子系统的关键技术，本章旨在为读者提供利用经典电磁场实现量子控制的基本原理和方法框架，特别是如何通过干涉效应实现控制目标。

Method: 1. 相干控制：通过频率或时间操纵设计相消和相长干涉；2. 绝热跟随：通过跟踪时间依赖基态实现控制目标；3. 最优控制理论：针对复杂控制目标和系统动力学，通过优化泛函设计控制协议。

Result: 通过作者研究组的最新工作（特别是原子和超导量子比特控制）展示了这些控制概念的实际应用，验证了方法的有效性。

Conclusion: 量子控制领域需要将相干控制与工程化耗散相结合，并解决该领域的开放性问题，为未来研究提供方向。

Abstract: Quantum control refers to our ability to manipulate quantum systems. This tutorial-style chapter focuses on the use of classical electromagnetic fields to steer the system dynamics. In this approach, the quantum nature of the control stems solely from the underlying dynamics, through the exploitation of destructive and constructive interference to reach the control target. We first discuss two basic control principles -- coherent control which uses manipulation in frequency or time to design these interferences, and adiabatic following where access to the control target is enabled by tracking the time-dependent ground state. For complex control targets and system dynamics that exceed the scope of these basic principles, optimal control theory provides a powerful suite of tools to design the necessary protocols. A key consideration for the successful application of optimal control theory is a proper choice of the optimization functional. All concepts are illustrated using recent work from my research group, with a focus on controlling atoms and superconducting qubits. The chapter concludes with an outlook on integrating coherent control with engineered dissipation and a discussion of open questions in the field.

</details>


### [100] [Expanding the Neutral Atom Gate Set: Native iSWAP and Exchange Gates from Dipolar Rydberg Interactions](https://arxiv.org/abs/2512.05037)
*Pedro Ildefonso,Andrew Byun,Aleksei Konovalov,Javad Kazemi,Michael Schuler,Wolfgang Lechner*

Main category: quant-ph

TL;DR: 该论文提出了一种用于中性原子量子处理器的原生iSWAP和参数化交换门实现方法，利用里德堡态间的强偶极-偶极相互作用，通过最优控制设计高效高保真门协议，在锶-88架构下实现了超过99.9%保真度的快速iSWAP门。


<details>
  <summary>Details</summary>
Motivation: 扩展中性原子量子处理器的门集合，超越传统的里德堡阻塞型纠缠门，实现更通用的量子计算能力。

Method: 利用两个偶极耦合里德堡态之间的强偶极-偶极相互作用，采用最优控制技术设计时间高效、高保真的门协议，使用全局驱动项简化实验复杂度，实施噪声感知脉冲选择策略来降低对特定噪声源的敏感性。

Result: 在锶-88架构下，展示了快速iSWAP门协议，在包含原子运动、里德堡衰变、激光相位和强度噪声等实际实验条件下，保真度超过99.9%。

Conclusion: 该方法为扩展中性原子门集合提供了可行途径，超越了典型的里德堡阻塞型纠缠门，推动了中性原子量子计算的发展。

Abstract: We present a native realization of iSWAP and parameterized exchange gates for neutral atom quantum processing units. Our approach leverages strong dipole-dipole interactions between two dipole-coupled Rydberg states, and employs optimal control techniques to design time-efficient, high-fidelity gate protocols. To minimize experimental complexity, we utilize global driving terms acting identically on all atoms. We implement a noise-aware pulse selection strategy to identify candidate protocols with reduced susceptibility to certain noise sources, then analyze their performance under realistic noise sources -- including atomic motion, Rydberg decay, and experimentally motivated laser phase and intensity noise. For a $^{88}$Sr-based architecture, we demonstrate fast iSWAP gate protocols which exceed fidelities of $99.9\%$ under realistic experimental conditions. These results pave the way for expanding the neutral atom gate set beyond typical Rydberg blockade-based entangling gates.

</details>


### [101] [QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory](https://arxiv.org/abs/2512.05049)
*Yu-Chao Hsu,Jiun-Cheng Jiang,Chun-Hua Lin,Kuo-Chung Peng,Nan-Yow Chen,Samuel Yen-Chi Chen,En-Jui Kuo,Hsi-Sheng Goan*

Main category: quant-ph

TL;DR: 提出QKAN-LSTM模型，将量子启发的Kolmogorov-Arnold网络集成到LSTM中，通过数据重上传激活模块增强频率适应性和频谱表示，在减少79%参数的同时提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统LSTM存在参数冗余和非线性表达能力有限的问题，特别是在城市电信预测等时序建模任务中，需要处理时间相关性和非线性依赖关系。

Method: 提出QKAN-LSTM模型，将数据重上传激活模块集成到LSTM的门控结构中，每个模块作为量子变分激活函数，增强频率适应性和频谱表示能力。进一步扩展到JHCG网络和混合QKAN架构。

Result: 在阻尼简谐运动、贝塞尔函数和城市电信三个数据集上，QKAN-LSTM相比传统LSTM减少79%可训练参数的同时，实现了更优的预测精度和泛化能力。

Conclusion: QKAN-LSTM为现实世界数据环境中的量子启发性序贯建模提供了可扩展且可解释的途径，保持了量子级表达能力的同时完全可在经典硬件上执行。

Abstract: Long short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.

</details>


### [102] [Meta-Learning for Quantum Optimization via Quantum Sequence Model](https://arxiv.org/abs/2512.05058)
*Yu-Cheng Lin,Yu-Chao Hsu,Samuel Yen-Chi Chen*

Main category: quant-ph

TL;DR: 提出量子元学习框架，训练量子序列模型生成QAOA参数初始化策略，QK-LSTM在Max-Cut问题上表现最优，实现完美参数可迁移性。


<details>
  <summary>Details</summary>
Motivation: QAOA在近期量子处理器上解决组合优化问题时，由于非凸能量景观导致参数优化困难，收敛慢且解质量差，需要更好的参数初始化方法。

Method: 提出量子元学习框架，训练量子序列模型作为学习优化器，包括量子核长短期记忆(QK-LSTM)等四种经典或量子序列模型，采用"学习学习"范式。

Result: QK-LSTM在Max-Cut问题(n=10-13)上获得最高近似比和最快收敛速度，仅用43个可训练参数，实现完美参数可迁移性，能生成单一固定近优参数集。

Conclusion: QK-LSTM通过量子核架构的紧凑表达能力，为NISQ时代变分量子算法提供了高效参数初始化的稳健途径，显著优于经典LSTM和其他量子模型。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for solving combinatorial optimization problems on near-term quantum processors. However, finding good variational parameters remains a significant challenge due to the non-convex energy landscape, often resulting in slow convergence and poor solution quality. In this work, we propose a quantum meta-learning framework that trains advanced quantum sequence models to generate effective parameter initialization policies. We investigate four classical or quantum sequence models, including the Quantum Kernel-based Long Short-Term Memory (QK-LSTM), as learned optimizers in a "learning to learn" paradigm. Our numerical experiments on the Max-Cut problem demonstrate that the QK-LSTM optimizer achieves superior performance, obtaining the highest approximation ratios and exhibiting the fastest convergence rate across all tested problem sizes (n=10 to 13). Crucially, the QK-LSTM model achieves perfect parameter transferability by synthesizing a single, fixed set of near-optimal parameters, leading to a remarkable sustained acceleration of convergence even when generalizing to larger problems. This capability, enabled by the compact and expressive power of the quantum kernel architecture, underscores its effectiveness. The QK-LSTM, with only 43 trainable parameters, substantially outperforms the classical LSTM (56 parameters) and other quantum sequence models, establishing a robust pathway toward highly efficient parameter initialization for variational quantum algorithms in the NISQ era.

</details>


### [103] [Thermodynamic universality across dissipative quantum phase transitions](https://arxiv.org/abs/2512.05074)
*Laetitia P. Bettmann,Artur M. Lacerda,Mark T. Mitchison,John Goold*

Main category: quant-ph

TL;DR: 研究开放量子系统中二阶耗散量子相变的有限时间驱动，发现非绝热熵产生具有普适的幂律标度行为，类似于封闭系统的Kibble-Zurek机制，揭示了临界开放量子系统中不可逆耗散的普适性。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统在有限时间内驱动通过二阶耗散量子相变时的非平衡响应和热力学不可逆性，探索临界开放量子系统中耗散的普适标度行为。

Method: 采用Lindblad动力学描述耗散量子相变，分析非绝热熵产生的标度行为，特别关注玻色高斯态系统，并在热力学极限下的驱动耗散Dicke模型和有限尺寸标度的开放Kerr模型中验证理论预测。

Result: 发现非绝热熵产生表现出普适的幂律标度行为，类似于封闭系统的Kibble-Zurek机制；在玻色高斯态系统中，非绝热熵产生在主导阶与驱动速度无关；在Dicke模型和Kerr模型中验证了理论预测。

Conclusion: 建立了理解临界开放量子系统中普适非平衡响应和热力学不可逆性的一般框架，揭示了耗散量子相变中不可逆耗散的普适性特征。

Abstract: We study finite-time driving across second-order dissipative quantum phase transitions described by Lindblad dynamics. We show that the nonadiabatic entropy production, which quantifies deviations from the instantaneous nonequilibrium steady state, exhibits universal power-law scaling with the ramp duration in analogy to the Kibble-Zurek mechanism for closed systems. This establishes the universality of irreversible dissipation induced by driving an open quantum system near criticality. Furthermore, in systems described by bosonic Gaussian states, our scaling laws predict that the nonadiabatic entropy production is independent of driving speed to leading order, revealing a distinctive feature of Gaussian dissipative quantum phase transitions. We validate these analytical predictions in the thermodynamic limit of the driven-dissipative Dicke model and via finite-size scaling in the open Kerr model. Our results establish a general framework for understanding universal nonequilibrium response and thermodynamic irreversibility in critical open quantum systems.

</details>


### [104] [Pump Free Microwave-Optical Quantum Transduction](https://arxiv.org/abs/2512.05096)
*Fangxin Li,Jaesung Heo,Zhaoyou Wang,Andrew P. Higginbotham,Alexander A. High,Liang Jiang*

Main category: quant-ph

TL;DR: 提出一种无泵浦的微波-光学贝尔对生成方案，基于色心实现时间编码的微波-光学纠缠，通过自旋-光子纠缠和Purcell增强谐振器实现，模拟显示可实现kHz级生成速率和接近完美的保真度。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算需要微波-光学量子转换，但现有方案受限于光学泵浦导致的器件发热问题。需要开发无泵浦的方案来解决这一瓶颈。

Method: 基于色心的无泵浦方案：首先创建自旋-光子纠缠，然后通过强耦合Purcell增强谐振器将自旋态转换为时间编码的微波光子。微波检索通过三级transmon检测微波信号来宣告。

Result: 通过将最先进的自旋-光学接口与提出的强耦合自旋-微波设计相结合，该无泵浦方案能以超过1kHz的宣告速率生成微波-光学贝尔对，且保真度接近完美。

Conclusion: 该无泵浦方案是生成微波-光学贝尔对的有前景的源，解决了传统方案中的器件发热问题，为分布式量子计算提供了关键组件。

Abstract: Distributed quantum computing involves superconducting computation nodes operating at microwave frequencies, which are connected by long-distance transmission lines that transmit photons at optical frequencies. Quantum transduction, which coherently converts between microwave and optical (M-O) photons, is a critical component of such an architecture. Current approaches are hindered by the unavoidable problem of device heating due to the optical pump. In this work, we propose a pump-free scheme based on color centers that generates time-bin encoded M-O Bell pairs. Our scheme first creates spin-photon entanglement and then converts the spin state into a time-bin-encoded microwave photon using a strongly coupled Purcell-enhanced resonator. In our protocol, the microwave retrieval is heralded by detecting the microwave signal with a three-level transmon. We have analyzed the resulting Bell state fidelity and generation probability of this protocol. Our simulation shows that by combining a state-of-the-art spin-optical interface with our proposed strongly-coupled spin-microwave design, the pump-free scheme can generate M-O Bell pairs at a heralding rate exceeding one kilohertz with near-unity fidelity, which establishes the scheme as a promising source for M-O Bell pairs.

</details>


### [105] [Decoy-state quantum key distribution over 227 km with a frequency-converted telecom single-photon source](https://arxiv.org/abs/2512.05101)
*Frederik Brooke Barnes,Roberto G. Pousa,Christopher L. Morrison,Zhe Xian Koong,Joseph Ho,Francesco Graffitti,John Jeffers,Daniel K. L. Oi,Brian D. Gerardot,Alessandro Fedrizzi*

Main category: quant-ph

TL;DR: 使用电信C波段单发射源实现诱骗态量子密钥分发，通过调制量子发射器激发改变光子数分布，在227公里光纤上实现正密钥率，比非诱骗方案提高一个数量级


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发方案受限于单光子源的纯度不足和传输损耗，需要开发能够克服这些限制的新方案，以实现长距离量子通信

Method: 采用电信C波段单发射源，通过改变量子发射器的光学激发来调制光子数分布，创建诱骗态，并基于现有安全证明分析方案，计算包含有限密钥效应的秘密密钥率

Result: 在227公里光纤上实现了正秘密密钥率，损失容忍度比非诱骗方案提高一个数量级，展示了实际单光子源在长距离量子密钥分发中的可行性

Conclusion: 这项工作通过实现长距离量子密钥分发，扩展了单光子源在未来量子网络中的应用范围，为实际单光子纯度水平下的安全量子通信提供了可行方案

Abstract: We implement a decoy-state quantum key distribution scheme using a telecom C-band single-emitter source. The decoy states are created by varying the optical excitation of the quantum emitter to modulate the photon number distribution. We provide an analysis of our scheme based on existing security proofs, allowing the calculation of secret key rates including finite key effects. This enables us to demonstrate, with a realistic single-photon source, positive secret key rates using our scheme over 227 km of optical fiber, equivalent to a loss tolerance one order of magnitude greater than non-decoy schemes. This work broadens the scope of single-photon sources in future quantum networks by enabling long-distance QKD with realistic levels of single-photon purity.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [106] [Cosmological Implications and Stability of $f\mathbb{(Q,T)}$ Gravity with Pilgrim Dark Energy Model](https://arxiv.org/abs/2512.04127)
*M. Sharif,Iqra Ibrar*

Main category: gr-qc

TL;DR: 在f(Q,T)引力理论中构建朝圣者暗能量框架，采用非相互作用模型和幂律尺度因子，成功复制宇宙演化各阶段。


<details>
  <summary>Details</summary>
Motivation: 在扩展的修正引力理论f(Q,T)中构建朝圣者暗能量模型，以更好地描述宇宙演化历史，并与最新观测数据保持一致。

Method: 在f(Q,T)引力理论中采用对应方法，结合非相互作用模型（包含无压物质和幂律尺度因子），推导状态方程参数、相平面和声速平方。

Result: 重构模型随朝圣者暗能量参数呈现增减趋势；状态方程参数表征幻象区域；声速平方参数提供稳定框架；ω_DE-ω'_DE平面显示冻结区域；r-s相平面显示Chaplygin气体模型。

Conclusion: 在f(Q,T)引力中构建的朝圣者暗能量框架成功复制宇宙演化历史，与最新观测数据一致，为研究宇宙演化提供了稳定分析框架。

Abstract: This manuscript endeavors to construct a pilgrim dark energy framework within the $f\mathbb{(Q,T)}$ gravity theory, employing a correspondence approach aligned with a non-interacting model that incorporates pressureless matter alongside a power-law scale factor. Here $\mathbb{Q}$ and $\mathbb{T}$ represent the non-metricity and trace of the energy-momentum tensor, respectively. This extended modified gravity framework accurately replicates various epochs in the cosmological history. The $f\mathbb{(Q,T)}$ gravity models are utilized to derive the equation of state parameter, phase planes and squared speed of sound. The analysis reveals that the reconstructed model exhibits an increasing or decreasing trend with the pilgrim dark energy parameter. The equation of state parameter characterizes the phantom regime, while the squared speed of sound parameter provides a stable framework for examining the ongoing cosmic evolution. The $ω_{DE}-ω'_{DE}$ plane trajectories reveal the freezing region, while the $r-s$ phase plane shows the Chaplygin gas model. It is important to highlight that our findings align with the most recent observational data.

</details>


### [107] [Proof the Spacetime Penrose Inequality](https://arxiv.org/abs/2512.04137)
*Da Xu*

Main category: gr-qc

TL;DR: 证明了时空Penrose不等式：对于满足主导能量条件的渐近平坦初始数据集，ADM质量下界为陷获面面积的平方根除以16π，仅当为Schwarzschild时空时取等号。


<details>
  <summary>Details</summary>
Motivation: 解决Penrose于1973年提出的猜想，这是数学相对论领域五十多年来的核心开放问题。该猜想将黑洞质量与陷获面面积联系起来，对理解广义相对论中的黑洞物理至关重要。

Method: 结合广义Jang方程与p-调和水平集方法。在加权Sobolev空间中建立Fredholm可解性，验证具有分布曲率的Jang-共形度量满足所有解析假设，证明稳定视界的平均曲率跳跃正性，并通过显式边界证明双极限。

Result: 无条件证明了时空Penrose不等式，适用于任何陷获面（无论稳定性或拓扑结构）。这是该猜想首次被完全证明，之前的成果都是部分结果。

Conclusion: 完全解决了Penrose猜想，为数学相对论领域五十多年的核心问题画上句号。证明方法结合了多种先进技术，建立了黑洞质量与陷获面面积之间的精确关系。

Abstract: We prove the Spacetime Penrose Inequality: for any asymptotically flat initial data set satisfying the Dominant Energy Condition, the ADM mass is bounded below by the square root of the trapped surface area divided by 16 pi, with equality only for Schwarzschild. Unlike previous partial results, our proof is unconditional and holds for any trapped surface regardless of stability or topology.
  The proof combines the generalized Jang equation with the p-harmonic level set method. We establish Fredholm solvability in weighted Sobolev spaces, verify that Jang-conformal metrics with distributional curvature satisfy all required analytic hypotheses, prove mean curvature jump positivity for stable horizons, and justify the double limit with explicit bounds.
  This resolves Penrose's 1973 conjecture, a central open problem in mathematical relativity for over fifty years.

</details>


### [108] [Popcorn EMRIs: Transient Gravitational Wave Signals and Their Analysis in Schwartz Space](https://arxiv.org/abs/2512.04167)
*Pau Amaro Seoane,Kostas Tzanavaris*

Main category: gr-qc

TL;DR: 研究轨道周期超过mHz引力波观测台观测时间尺度的极端质量比旋进系统，这些系统在早期高偏心率阶段产生瞬态引力波爆发，称为"爆米花EMRIs"。


<details>
  <summary>Details</summary>
Motivation: 传统EMRI模型假设轨道周期短于观测时间尺度，但存在轨道周期超过观测时间尺度的EMRIs，这些系统表现为瞬态引力波爆发，需要新的理论框架来描述和分析。

Method: 使用基于相空间连续性方程的稳态解析模型估计银河系类似星系中的种群数量，通过福克-普朗克方程描述恒星弛豫过程进行归一化，并建立严格的数学框架分析瞬态信号的傅里叶变换。

Result: 预测每年可观测到5-44个爆发事件，占空比约10^-4，确认为孤立瞬态信号，来自银河系中心的单个爆发具有高可探测性。

Conclusion: 爆米花EMRIs是重要的引力波瞬态源，需要正确的数学框架分析其傅里叶变换，避免标准加窗技术对爆发形态的扭曲，为未来mHz引力波观测提供理论基础。

Abstract: We investigate extreme-mass ratio inspirals (EMRIs) with orbital periods exceeding the observational timescale of mHz gravitational wave observatories. In their early, highly eccentric phases, these systems generate transient gravitational wave bursts during pericentre passages, separated by long quiescent intervals; we designate these signals ``popcorn EMRIs.'' We utilize a steady-state analytical model based on the continuity equation in phase space to estimate the population in a Milky Way-like galaxy. The normalization of this model is linked to the solution of the Fokker-Planck equation describing stellar relaxation. Adopting a conservative one-year observation baseline ($P>1$ year), we estimate the steady-state population of popcorn EMRIs. We forecast an observable burst rate of 5 to 44 events per year. The low duty cycle ($\sim 10^{-4}$) confirms their manifestation as isolated transients. Individual bursts from the Galactic Centre exhibit high detectability. Analyzing these intrinsically transient signals demands a rigorous mathematical framework, as standard windowing techniques distort burst morphology. We establish an analytical foundation using standard smoothing techniques commonly used in real analysis. This yields the mathematically correct definition for the Fourier transform of transient signals, justifying the use of the direct Fourier transform without ad hoc windowing and ensuring the integrity of spectral analysis.

</details>


### [109] [Asymmetric excitation of left- vs right-handed photons in accelerating waveguides](https://arxiv.org/abs/2512.04188)
*Adrian del Rio*

Main category: gr-qc

TL;DR: 电磁对偶对称性在量子场论中不守恒，非惯性观测者会观测到光子对激发和手征模式不平衡


<details>
  <summary>Details</summary>
Motivation: 研究电磁对偶对称性在量子场论中的守恒性，特别是在非惯性参考系中的表现，探索经典守恒定律在量子理论中的破坏

Method: 在具有对偶保持边界条件的空波导中实现Noether对称性，量化经历线性和旋转加速的长圆柱波导内的无源麦克斯韦理论

Result: 在惯性观测者的真空态中，与波导共动的观测者观测到⟨0|Q̂|0⟩不守恒，帧拖曳效应导致晚期左右手场模式的光谱不对称性

Conclusion: 电磁对偶对称性的经典守恒定律在量子理论中被破坏，即使在平直时空中，只要使用非惯性系统，这为在模拟引力平台上测试该效应提供了概念验证

Abstract: The electromagnetic duality symmetry of Maxwell's equations in vacuum implies that the circular polarization $Q$ of classical electromagnetic waves is conserved. In quantum field theory, the normal-ordered operator $\hat Q$ represents the difference between the number operators of right- and left-handed photons. Previous studies have shown that its expectation value is not conserved for observers propagating in a gravitational field. Here, we show that this Noether symmetry can also be realized in empty waveguides with duality-preserving boundary conditions, and we quantize the source-free Maxwell theory inside a long, cylindrical waveguide undergoing both linear and rotational acceleration from rest. In the vacuum $|0\rangle$ associated to inertial observers, we find that the expectation value $\langle 0| \hat Q |0\rangle $ fails to be conserved for observers co-moving with the waveguide. In particular, frame-dragging effects induce a spectral asymmetry between the right- and left-handed field modes at late times. As a consequence, accelerated detectors co-moving with the rotating waveguide can detect photon-pair excitations from the quantum vacuum, exhibiting an imbalance between opposite helicity modes. This is a relativistic quantum effect, which shows that the classical conservation law associated with duality symmetry is broken in the quantum theory even in flat spacetime, provided we work with non-inertial systems. Our analysis provides a concrete proof of concept for testing this effect in analogue gravity platforms.

</details>


### [110] [Phase mixing and the Vlasov equation in cosmology](https://arxiv.org/abs/2512.04214)
*Martin Taylor,Renato Velozo Ruiz*

Main category: gr-qc

TL;DR: 研究FLRW宇宙时空中Vlasov方程的解在缓慢膨胀各向同性均匀环面上的衰减行为，分析了不同膨胀速率下的相混合效应增强衰减


<details>
  <summary>Details</summary>
Motivation: 研究宇宙膨胀对Vlasov方程解衰减行为的影响，特别是相混合效应在不同膨胀速率下的表现，理解辐射主导宇宙的边界情况

Method: 使用交换向量场集合和相关的微分算子组合性质，对动量支撑大的t值进行向量场分析，采用物理空间二进局部化处理非紧支撑解

Result: 对于膨胀速率t^q(0<q<1/2)，空间密度衰减率为t^{-6q}，去除空间平均后相混合效应增强衰减；对于边界情况t^{1/2}，退化相混合效应产生对数增强

Conclusion: 宇宙膨胀速率显著影响Vlasov方程解的衰减行为，相混合效应在不同膨胀速率下产生多项式或超多项式增强衰减，边界情况呈现特殊对数增强模式

Abstract: We consider the Vlasov equation on slowly expanding isotropic homogeneous tori, described by the Friedmann--Lemaître--Robertson--Walker cosmological spacetimes. For expansion rate $t^q$, with $0< q<\frac{1}{2}$ (excluding certain exceptional values), we show that the spatial density decays at the rate $t^{-6q}$ and that, when the spatial average is removed, the density decays at an enhanced rate due to a phase mixing effect. This enhancement is polynomial for Sobolev initial data and super-polynomial, but sub-exponential, for real analytic initial data. We further show that, when the expansion rate is the borderline $t^{\frac{1}{2}}$ -- the rate which describes a radiation filled universe -- a degenerate phase mixing effect results in a logarithmic enhancement for Sobolev initial data and a super-logarithmic enhancement (in fact, a gain of $\exp(-μ(\log t)^ε)$ for some $μ,ε>0$) for analytic initial data. The proof is based on a collection of commuting vector fields, and certain combinatorial properties of an associated collection of differential operators. The vector fields are not explicit, but are shown to have good properties when $t$ is large with respect to the momentum support of the solution. A physical space dyadic localisation is employed to treat non-compactly supported (in particular, non-trivial real analytic) but suitably decaying solutions.

</details>


### [111] [(Pre)-Inflationary Dynamics with Starobinsky Potential in Noncommutative Effective LQC](https://arxiv.org/abs/2512.04230)
*Luis Rey Díaz-Barrón,Abraham Espinoza-García,Sinuhé Pérez-Payán,José Socorro*

Main category: gr-qc

TL;DR: 该研究在非对易有效圈量子宇宙学框架下，使用Starobinsky势能数值求解场方程，分析了三种初始能量主导状态下的（前）暴胀动力学，并与混沌势能结果进行比较。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在非对易有效圈量子宇宙学框架下，探索Starobinsky势能下的（前）暴胀动力学，理解不同初始条件和非对易参数对宇宙演化的影响，并与先前研究的混沌势能结果进行对比。

Method: 方法包括：1）在非对易有效圈量子宇宙学框架下数值求解场方程；2）分析三种代表性初始状态（极端动能主导、动能主导、势能主导）；3）从动力系统角度进行定性分析；4）与混沌（二次）势能结果进行比较。

Result: 研究获得了Starobinsky势能下不同初始条件和非对易参数值的数值解，揭示了三种能量主导状态下的背景动力学特征，并通过动力系统分析阐明了标量场演化的定性特征。

Conclusion: 结论是系统研究了Starobinsky势能在非对易圈量子宇宙学中的（前）暴胀动力学，提供了与混沌势能不同的演化特征，为理解早期宇宙演化提供了新的视角。

Abstract: In this work, we investigate the (pre)-inflationary dynamics of a flat, homogeneous, and isotropic universe governed by the Starobinsky potential within the framework of noncommutative effective loop quantum cosmology. The field equations are solved numerically for various initial conditions and different values of the noncommutative parameter. We analyze the background dynamics for three representative regimes -- the extreme kinetic-energy domination, kinetic-energy domination, and potential-energy domination. A complementary analysis is performed from the viewpoint of dynamical systems, highlighting the qualitative features of the scalar field evolution. Finally, a discussion comparing our results with previous studies employing the chaotic (quadratic) potential in the same formalism is presented.

</details>


### [112] [Spectral lines of dirty wormholes](https://arxiv.org/abs/2512.04274)
*Leonardo K. S. Furuta,Renan B. Magalhães,Haroldo C. D. Lima Junior,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: 研究物质环境对虫洞吸收质量标量场的影响，发现尽管周围有重物质分布，但吸收谱线位置基本保持不变，表明天体环境无法完全掩盖中心虫洞的特征。


<details>
  <summary>Details</summary>
Motivation: 黑洞通常被吸积盘或喷流等物质环绕，这些天体环境会影响粒子和场的散射现象。虫洞作为奇异致密天体可以模拟黑洞的某些性质，因此需要研究当天体中心是虫洞而非黑洞时，周围天体环境对其物理性质的影响。

Method: 研究被厚物质壳包围的"脏虫洞"对质量标量场的吸收效应。分析这些脏虫洞周围的零测地线，研究新光环对出现的条件。通过研究新稳定光环产生的准束缚态来分析吸收带的变化。

Result: 天体环境可以在虫洞周围引入新的稳定光环，从而产生新的准束缚态（除了虫洞喉部附近的束缚态），导致吸收带出现偏差。但值得注意的是，即使虫洞周围有重而密的物质分布，吸收带中大多数谱线的位置仍然保持不变。

Conclusion: 天体环境虽然会影响虫洞的吸收特性，但无法完全掩盖中心天体的某些特征指纹。吸收谱线位置的稳定性表明，即使存在重物质环境，虫洞的某些本质特征仍然可以被探测到。

Abstract: Astrophysical objects like black holes are usually surrounded by matter in the form of accretion disks or jets of matter. These astrophysical scenarios are expected to introduce novel phenomenology in the scattering of particles and fields. Wormholes are viable candidates for exotic compact objects that can mimic some black hole properties. Hence, it is natural to wonder what would happen if the central astrophysical object were a wormhole, instead of a black hole. We investigate the astrophysical environment effect on the absorption of a massless scalar field by a dirty wormhole surrounded by a thick shell of matter. We study null geodesics around these dirty wormholes and analyze under which conditions new pairs of light rings can appear. The presence of new stable light rings allows new quasibound states in the spacetime, apart from the ones trapped near the throat. Thus, the astrophysical environment can introduce deviations in the absorption bands. Remarkably, although heavy and dense distributions of matter are considered surrounding the wormhole, the position of most of the spectral lines in the absorption bands is preserved, indicating that the astrophysical environment cannot hide some fingerprints of the central object.

</details>


### [113] [Cosmological implications of Bumblebee theory on an FLRW background](https://arxiv.org/abs/2512.04349)
*Manuel Gonzalez-Espinoza,Grigorios Panotopoulos,Francisco Tello-Ortiz*

Main category: gr-qc

TL;DR: 该论文研究了Bumblebee模型在背景层面的宇宙学意义，通过动力学系统分析相空间和临界点，利用超新星数据拟合模型参数，并与Λ-CDM模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 研究Bumblebee模型在宇宙学背景层面的物理意义，探索该模型是否能解释宇宙加速膨胀等观测现象，并与标准宇宙学模型进行比较。

Method: 使用动力学系统技术分析相空间、临界点及其稳定性；利用超新星数据拟合模型唯一自由参数；计算各种宇宙学量随红移的变化；计算状态探测器和宇宙年龄。

Result: 确定了模型唯一自由参数的最佳拟合数值；展示了减速参数、暗能量状态方程参数等宇宙学量随红移的图形；计算了状态探测器和宇宙年龄；与Λ-CDM模型进行了比较。

Conclusion: Bumblebee模型在宇宙学背景下表现出有趣的特性，通过超新星数据约束了模型参数，并与标准宇宙学模型进行了对比分析，为理解宇宙演化提供了新的视角。

Abstract: We investigate some cosmological implications at background level of the Bumblebee model. The phase-space, the critical points and their stability are analyzed in detail applying well-established dynamical system techniques. What is more, upon comparison to available supernovae data, the best fit numerical value of the unique free parameter of the model is determined. We show graphically all the cosmological quantities of interest versus red-shift, such as the deceleration parameter, dark energy equation of state parameter, etc. The statefinders and the age of the Universe are also computed. Finally, a comparison to the $Λ$-CDM model is made as well.

</details>


### [114] [Linear stability of nonrelativistic Proca stars](https://arxiv.org/abs/2512.04376)
*Emmanuel Chávez Nambo,Galo Diaz-Andrade,Alberto Diez-Tejedor,Edgar Preciado-Govea,Armando A. Roque,Olivier Sarbach*

Main category: gr-qc

TL;DR: 研究非相对论性Proca星在线性扰动下的稳定性，发现基态总是模态稳定的，并识别出多个模态稳定的球对称激发态


<details>
  <summary>Details</summary>
Motivation: 研究非相对论性Proca星的稳定性对于理解自旋-1超轻暗物质模型具有重要意义，特别是探索是否存在稳定的激发态

Method: 结合解析方法和数值方法，分析线性稳定性，研究球对称激发态，包括恒定极化和径向极化的稳态，以及自旋-自旋相互作用消失时的多频态

Result: 基态总是模态稳定的，识别出多个模态稳定的球对称激发态，包括恒定极化态、径向极化态以及自旋-自旋相互作用消失时的多频态

Conclusion: 稳定的激发态的存在可能对自旋-1超轻暗物质模型产生影响，为相关理论研究提供了新的可能性

Abstract: We study the linear stability of nonrelativistic Proca stars under generic perturbations. Using a combination of analytic and numerical methods, we demonstrate that, as expected, the ground state is always mode-stable. Additionally, we identify several mode-stable spherically symmetric excited states, including stationary states of constant and radial polarization, as well as multi-frequency states in case that the spin-spin selfinteraction vanishes. The existence of stable excited states may have implications for spin-$1$ ultralight dark matter models.

</details>


### [115] [Hairy black holes via gravitational decoupling: light rings, absorption and spectral lines](https://arxiv.org/abs/2512.04377)
*Gabriel P. Ribeiro,Renan B. Magalhães,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: 研究三种不同毛状黑洞对无质量标量波的吸收，发现满足弱能量条件的黑洞可能出现准束缚态，产生Breit-Wigner型共振吸收谱线，这些谱线与稳定光环相关


<details>
  <summary>Details</summary>
Motivation: 研究引力解耦方法产生的毛状黑洞如何影响无质量标量波的吸收特性，特别是探索黑洞参数如何改变吸收谱并产生类似虫洞等奇特致密天体的物理特征

Method: 使用引力解耦方法构建三种满足不同能量条件（弱、强、主导）的毛状黑洞解，数值计算这些黑洞对无质量标量波的吸收谱，分析准束缚态和共振现象

Result: 满足弱能量条件的毛状黑洞配置中出现了准束缚态，导致吸收谱中出现Breit-Wigner型共振峰；这些共振谱线与时空中的稳定光环结构相关，类似于无视界奇特致密天体的特征；数值结果与已知近似方法高度一致

Conclusion: 引力解耦方法通过变形参数在毛状黑洞中引入了新的光环结构，显著影响了吸收谱特征，使得黑洞在某些条件下表现出类似虫洞等奇特天体的光谱特性，为黑洞物理研究提供了新视角

Abstract: We investigate the absorption of massless scalar waves by three distinct hairy black hole solutions obtained through the gravitational decoupling method, considering the weak, the strong or the dominant energy conditions. Remarkably, in certain configurations of hairy black holes associated with the fulfillment of the weak energy condition, quasibound states may appear, resulting in Breit-Wigner-like resonances in their absorption profile. These quasibound states (and consequently the spectral lines in the absorption spectrum) can be related to stable light rings in the spacetime, a structure often associated with horizonless exotic compact objects, such as wormholes. We investigate how the gravitational decoupling method introduces novel light ring structures in hairy black holes and influences the absorption spectra through its deformation parameters. Our numerical results show excellent agreement with well-known approximations.

</details>


### [116] [On angular dependent response to gravitational-wave signals for time-delay interferometry combinations](https://arxiv.org/abs/2512.04473)
*Pan-Pan Wang,Hao-Kang Chen,Wei-Liang Qian,Rui Luo,Jing Zhou,Wei-Sheng Huang,Yu-Jie Tan,Cheng-Gang Shao*

Main category: gr-qc

TL;DR: 该研究分析了空间引力波探测器中不同TDI组合对引力波信号的角依赖响应特性，为针对特定引力波源优化TDI组合提供理论依据。


<details>
  <summary>Details</summary>
Motivation: 空间引力波探测器针对毫赫兹频段的波源设计，TDI技术能有效抑制激光相位噪声。不同TDI组合具有不同的角依赖灵敏度特性，而引力波源的角位置在探测前未知。一旦实现初始探测并提取源位置信息，就可以为特定引力波源定制优化的TDI组合。

Method: 评估不同TDI组合对引力波信号响应函数的角依赖特性，作为方向角的函数。在低频极限下，根据基础几何TDI组合的特性将响应函数分为七类。通过平均掉探测器平面内的方位角φ_D，分析响应函数的主要特征及其与引力波源天顶角的依赖关系。

Result: 系统分析了探测器对不同TDI组合的响应函数的角依赖特性，在低频极限下将响应函数分为七类。通过平均方位角后，详细研究了响应函数的主要特征及其天顶角依赖关系。

Conclusion: 该研究为正在进行的空间引力波探测器项目提供了重要见解，表明一旦探测到引力波源并确定其位置，可以利用TDI的后处理特性为特定源定制优化的TDI组合，从而提高探测灵敏度。

Abstract: Space-based gravitational wave (GW) detectors are designed for wave sources in the millihertz band with different locations and orientations.
  Time-delay interferometry (TDI) technique is an indispensable ingredient in space-borne GW detection that effectively suppresses the laser phase noise.
  The abundant TDI solutions derived in the literature also feature distinct angular-dependent sensitivities.
  Because a GW source's angular location is unknown prior to the signals' detection, a solid-angle average is often performed when analyzing the sensitivity function of a given TDI combination.
  The present study explores the angular dependence of the detector's sensitivity.
  This detail is relevant, because once the initial detection is achieved, the source's location can be extracted and used to provide information on a refined TDI combination tailored for the specific GW source.
  As the TDI technique is a post-processing algorithm, such a procedure can be implemented in practice.
  We evaluate the angular dependence of the detector's response function to the GW signals for different TDI combinations as a function of the orientation angles.
  Moreover, we classify the response functions into seven categories at the low-frequency limit, leveraging the characteristics of the underlying geometrical TDI combinations.
  By further averaging out the azimuthal angle $φ_D$ in the detector's plane, the main features of the resulting response functions and their zenithal dependence with respect to the GW source are scrutinized.
  The findings presented in this work provide pertinent insights for ongoing space-borne detector programs.

</details>


### [117] [Thermodynamic geometric analysis of D-dimensional RN black hole](https://arxiv.org/abs/2512.04478)
*Wen-Xiang Chen*

Main category: gr-qc

TL;DR: 研究D维RN黑洞的热力学和Ruppeiner几何，发现在固定电荷的系综中Ruppeiner曲率弯曲并在临界点发散，表明D>4时存在相变；而在所有广延变量可涨落的系综中几何可能平坦。热力学几何度规与欧几里得路径积分周期性存在一一对应。


<details>
  <summary>Details</summary>
Motivation: 探索不同热力学系综下D维RN黑洞的Ruppeiner几何性质，理解热力学几何与相变行为之间的关系，建立热力学几何与欧几里得路径积分方法之间的联系。

Method: 分析D维RN黑洞在不同热力学系综（固定电荷的典型系综和所有广延变量可涨落的系综）中的Ruppeiner几何，计算热力学曲率标量R，研究其与临界行为的关系，并建立热力学几何度规与欧几里得路径积分周期性的对应关系。

Result: 在固定电荷的典型系综中，Ruppeiner曲率弯曲并在临界点发散，表明D>4时存在相变；而在所有广延变量可涨落的系综（如巨正则系综或固定压强系综）中，Ruppeiner几何可能平坦。热力学几何度规与欧几里得路径积分周期性存在一一对应，逆温度（欧几里得时间周期）作为连接热力学几何和欧几里得作用量方法的桥梁。

Conclusion: D维RN黑洞的热力学几何性质强烈依赖于所选择的系综，固定电荷系综显示相变特征，而广延变量可涨落系综可能呈现平坦几何。热力学几何与欧几里得路径积分方法之间存在深刻的对应关系，逆温度作为关键连接参数。

Abstract: This paper studies the thermodynamics and Ruppeiner geometry of D-dimensional RN black holes. We analyze the thermodynamic curvature scalar $R$ in various thermodynamic ensembles. It is found that in an ensemble of fixed charge (canonical ensemble), the Ruppeiner curvature is curved and diverges at a critical point, indicating the existence of a phase transition for $D > 4$. In contrast, when all extensive variables are allowed to fluctuate (for example, in a grand-canonical ensemble or with pressure fixed), the Ruppeiner geometry can appear flat. We also demonstrate that the thermodynamic geometric metric has a one-to-one correspondence with the periodicity of the Euclidean path integral method. In particular, the inverse temperature (the Euclidean time period) serves as a bridge connecting the thermodynamic geometry and the Euclidean action approach.

</details>


### [118] [General SIGW source for reheating dynamics](https://arxiv.org/abs/2512.04482)
*M. Laine,S. Procacci*

Main category: gr-qc

TL;DR: 在任意规范下推导了广义再加热时期标量诱导引力波(SIGW)的源项，允许主导能量成分从暴胀场平滑过渡到辐射流体，可能经过物质主导时期，并验证了二阶规范不变性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设再加热过程是瞬时完成的，但实际再加热过程可能包含平滑的能量成分转变，甚至可能存在物质主导时期。本文旨在建立适用于一般再加热时期的标量诱导引力波理论框架。

Method: 在任意规范下工作，推导了标量诱导引力波的源项，允许主导能量成分从暴胀场平滑过渡到辐射流体，可能经过物质主导时期，并验证了二阶规范不变性。

Result: 成功推导出适用于一般再加热时期的标量诱导引力波源项，该源项在任意规范下有效，并验证了二阶规范不变性，为研究非瞬时再加热过程对引力波产生的影响提供了理论基础。

Conclusion: 本文建立了适用于一般再加热时期的标量诱导引力波理论框架，为研究再加热过程对原初引力波谱的影响提供了重要工具，特别是在存在物质主导时期或平滑能量转变的情况下。

Abstract: Working in an arbitrary gauge, we derive the source term for scalar-induced gravitational waves (SIGW) valid during a general reheating epoch. Specifically, the dominant energy component is allowed to transition smoothly from an inflaton field to a radiation fluid, possibly via a period of matter domination. Gauge invariance is verified up to second order.

</details>


### [119] [Searching for binary black hole mergers with deep learning in Advanced LIGO's third observing run](https://arxiv.org/abs/2512.04516)
*Damon Beveridge,Alistair McLeod,Linqing Wen,Weichangfeng Guo,Andreas Wicenec*

Main category: gr-qc

TL;DR: 开发了一种结合匹配滤波和深度学习的混合搜索管道，用于识别恒星质量双黑洞引力波候选体，在LVK第三次观测运行中发现了31个已知候选体和2个新候选体。


<details>
  <summary>Details</summary>
Motivation: 引力波探测为宇宙研究提供了重要见解，但独立搜索发现新的独特引力波候选体仍然是持续的研究领域。需要开发更有效的搜索方法来识别双黑洞合并信号。

Method: 构建了混合搜索管道，结合了匹配滤波（传统方法）和深度学习（机器学习方法）。首先通过目标注入研究来基准测试方法的灵敏度，然后在LVK第三次观测运行中进行离线搜索。

Result: 混合方法对源框架啁啾质量大于25M⊙的注入信号具有可比灵敏度；在LVK第三次观测运行中识别出31个已知候选体（p_astro≥0.5），以及2个新候选体：一个仅在IAS报告中提及，另一个是p_astro为0.63的未报告候选体，具有高啁啾质量和高中等质量黑洞概率。

Conclusion: 混合搜索方法能够识别独特的引力波候选体，包括具有高中等质量黑洞概率的高啁啾质量系统，为引力波天文学提供了新的探测能力。

Abstract: The detection of gravitational waves from compact binary coalescences has provided significant insights into our Universe, and the discovery of new and unique gravitational wave candidates from independent searches remains an ongoing field of research. In this work, we built a hybrid search pipeline that combines matched filtering and deep learning to identify stellar-mass binary black hole candidates from detector strain data. We first present results from a targeted injection study to benchmark the sensitivity of our method and compare it with existing search pipelines. We demonstrate that our hybrid approach has comparable sensitivity for injections with a source-frame chirp mass greater than 25$\,$M$_{\odot}$, and below this threshold our sensitivity drops off for signals with a network SNR less than 15. We also observe that our search method can identify a significant population of unique candidates. Furthermore, we conduct an offline search for gravitational wave candidates in the third observing run of the LIGO-Virgo-KAGRA Collaboration (LVK), yielding 31 candidates previously reported by the LVK with a probability of astrophysical origin $p_{\rm astro}\geq0.5$. We identify two other candidates: one previously reported only in a search conducted by the Institute for Advanced Study, and one previously unreported promising new candidate with a $p_{\rm astro}$ of 0.63. This unique candidate has a high chirp mass and a high probability that the primary black hole is an intermediate-mass black hole.

</details>


### [120] [From Source Properties to Strong-Field Tests: a multipronged analysis of GW250114 with an effective one-body model for generic orbits](https://arxiv.org/abs/2512.04593)
*Koustav Chandra,Rossella Gamba,Danilo Chiaramello*

Main category: gr-qc

TL;DR: GW250114是迄今观测到的最强引力波信号，分析表明它来自两个第一代、近等质量、低自旋黑洞的合并，形成了对不稳定性质量间隙内的残余黑洞。高信噪比使(4,±4)多极子被探测到，且三个独立的广义相对论测试都支持GR预测。


<details>
  <summary>Details</summary>
Motivation: GW250114是目前观测到的最强引力波信号，为精确测试引力理论提供了独特机会。研究旨在利用高信噪比优势，深入分析该信号的物理特性，特别是探测次主导多极子并执行更严格的广义相对论测试。

Method: 使用能够描述偏心进动双黑洞轨道的波形模型进行分析。进行了三个独立的广义相对论测试：1）改进的残差分析验证模型是否完全描述信号；2）次主导模式测试检查(4,±4)多极子振幅是否符合GR预期；3）参数化分析坠并-合并-振铃阶段的物理参数。

Result: 1）源有≥96%概率是两个第一代、近等质量、低自旋黑洞合并，形成对不稳定性质量间隙内的残余黑洞；2）高信噪比（≳75）使(4,±4)多极子被探测到，证据比LVK先前报告更高；3）三个GR测试都支持广义相对论预测，没有发现可探测的偏差。

Conclusion: GW250114是一个里程碑事件，为精确测试引力理论提供了有力证据。所有分析结果都支持广义相对论预测，包括次主导多极子的存在和振幅、残余黑洞参数等，强化了该事件在引力波天文学中的重要性。

Abstract: We present a detailed analysis of GW250114, the loudest gravitational-wave signal observed to date, using a waveform model capable of describing binary black holes in generic (eccentric and precessing) orbits. Our analysis builds on LIGO-Virgo-KAGRA (LVK)'s results, finding that the source is consistent at a probability of $\geq 96\%$ with the merger of two first-generation, nearly equal-mass, low-spin black holes, forming a remnant within the pair-instability mass gap. The signal's high signal-to-noise ratio ($\gtrsim 75$) enables the detection of the subdominant $(4,\pm4)$ multipoles, whose presence we confirm with higher evidence than previously reported by the LVK. Restricting the analysis even to post-peak data yields $\log_{10}B\gtrsim 1$ in favor of models including the $(4,\pm4)$ mode, demonstrating that this contribution remains detectable well into the post-merger phase. We further perform three independent tests of general relativity, complementary to those performed by the LVK: a modified residual analysis confirms that our semi-analytical model fully describes the signal without detectable discrepancies; a subdominant mode test finds that the amplitude of the $(4,\pm4)$ multipoles agrees with general-relativistic expectations; and a parameterised analysis of the plunge-merger-ringdown regime recovers the GR expectation within the 50\% credible region for the remnant mass and spin, and within the 90\% interval for the $(2,\pm2)$ peak amplitude. Collectively, these results reinforce GW250114 as a landmark event for a precision test of gravity.

</details>


### [121] [Charged Regular Black Holes From Quasi-topological Gravities in $D\ge 5$](https://arxiv.org/abs/2512.04604)
*Chen-Hao Hao,Jiliang Jing,Jieci Wang*

Main category: gr-qc

TL;DR: 在D≥5维时空中，构造了包含无限高阶曲率修正的引力理论中的带电球对称黑洞解，展示了高阶修正能渐进消除中心奇点，并在无限阶极限下得到全局正则时空。


<details>
  <summary>Details</summary>
Motivation: 研究高维时空中的引力理论，特别是弦理论和M理论所要求的维度，探索高阶曲率修正对黑洞奇点的影响，寻求消除奇点的可能性。

Method: 在D≥5维时空中，构造包含无限高阶曲率修正的引力理论，求解带电球对称黑洞的精确解，通过适当选择耦合系数α_n，分析高阶修正对奇点的影响。

Result: 对于给定的质量和电荷，模型存在唯一的静态球对称解；随着修正阶数增加，中心奇点逐渐被缓解，在无限阶修正极限下，奇点完全消除，得到全局正则时空；同时确定了极端黑洞存在的判据。

Conclusion: 高阶曲率修正能够有效缓解甚至消除黑洞奇点，为构建正则黑洞解提供了理论框架，在高维引力理论中具有重要意义。

Abstract: The investigation of gravity in higher-dimensional spacetime has transitioned from a mathematical curiosity to a fundamental framework in theoretical physics, catalyzed by the dimensional requirements of String theory and M-theory. In this paper, we explicitly construct a spherically symmetric charged black hole solution in $D \ge 5$ dimensions within a gravity theory featuring an infinite tower of higher-curvature corrections. For a given mass and electric charge, the model admits a unique static spherically symmetric solution. We demonstrate that, with an appropriate choice of coupling coefficients $α_n$, the central singularity is progressively mitigated as the correction order increases, ultimately resolving into a globally regular spacetime in the limit of infinite-order corrections. Furthermore, the criteria for the existence of extremal black holes are determined.

</details>


### [122] [Mode interactions in scalar field cosmology](https://arxiv.org/abs/2512.04607)
*Spiros Cotsakis,Ignatios Antoniadis*

Main category: gr-qc

TL;DR: 论文研究FRW宇宙中质量标量场在质量消失点附近的动力学，发现该点存在一个Hopf-稳态组织中心，其展开参数(r,z)直接对应慢滚参数，为早期加速膨胀提供与势能无关的机制。


<details>
  <summary>Details</summary>
Motivation: 研究质量标量场在质量消失点附近的动力学行为，探索早期宇宙加速膨胀的几何机制，为暴胀模型提供与势能无关的统一解释框架。

Method: 使用中心流形约化技术，将爱因斯坦-标量场系统简化为两个慢几何模(r,z)，通过Hopf-稳态组织中心的展开参数描述所有小扰动，建立展开参数与慢滚参数的对应关系。

Result: 发现慢滚参数ε∼3/2 r²和η∼z，谱倾斜、张标比和标量振幅都成为(r,z)的普适函数，与势能选择无关。展开参数(μ₁,μ₂)分类所有二次模型的扰动，对应势能的倾斜和曲率形变。

Conclusion: 原始扰动的近标度不变性源于组织中心展开的结构性质，为早期加速膨胀提供势能无关的机制，为暴胀模型的解释和分类提供几何框架。

Abstract: We study the dynamics of spatially homogeneous Friedmann--Robertson--Walker universes filled with a massive scalar field in a neighbourhood of the massless transition $s=1$. At this point the Einstein--scalar system exhibits a codimension--two Hopf--steady--state organising centre whose versal unfolding describes all small deformations of the quadratic model. After reduction to the centre manifold, the dynamics is governed by two slow geometric modes $(r,z)$: the Hopf amplitude $r$, measuring the kinetic departure from de Sitter, and the slowly drifting Hubble mode $z$. We show that the standard slow--roll parameters follow directly from these unfolding variables, $ε\sim\tfrac32 r^{2}$ and $η\sim z$, so that the spectral tilt, tensor--to--scalar ratio, and scalar amplitude arise as universal functions of $(r,z)$, independently of the choice of potential. The two unfolding parameters $(μ_{1},μ_{2})$ classify all perturbations of the quadratic model and can be interpreted physically as controlling the tilt and curvature deformations of generic polynomial inflationary potentials. Thus the near scale--invariance of primordial perturbations emerges as a structural property of the unfolding of the organising centre, providing a potential--independent mechanism for an early phase of accelerated expansion. We discuss the implications of this geometric framework for the interpretation and classification of inflationary models.

</details>


### [123] [Inspiraling binary charged black holes in an external magnetic field: Application of post-Newtonian dynamics in Einstein-Maxwell theory](https://arxiv.org/abs/2512.04806)
*RunDong Tang,Lang Liu,Wen-Biao Han*

Main category: gr-qc

TL;DR: 本文提出了一种系统性的后牛顿处理方法，用于研究外部磁场中的带电黑洞双星系统，推导了包含引力与电磁相互作用的全运动方程，发现磁场会显著改变轨道动力学并在引力波信号中留下可探测的特征。


<details>
  <summary>Details</summary>
Motivation: 研究外部磁场中带电黑洞双星系统的动力学行为，探索通过引力波观测探测带电黑洞和磁场环境的可能性。

Method: 在爱因斯坦-麦克斯韦理论框架下，采用后牛顿方法，将均匀外部磁场纳入双星拉格朗日量中，展开至一阶后牛顿阶，推导完整的运动方程，并通过数值积分计算引力波形。

Result: 磁场产生的洛伦兹力会破坏线性动量和角动量守恒，导致轨道从平面运动转变为三维运动，强背景磁场能显著改变轨道演化并在引力波信号中留下可识别的特征。

Conclusion: 外部磁场中的带电黑洞双星系统在引力波信号中会产生独特的特征，这为通过引力波观测探测带电黑洞和磁场环境提供了有前景的途径。

Abstract: We present a systematic post-Newtonian treatment of binary charged black holes immersed in external magnetic fields within the framework of Einstein-Maxwell theory. By incorporating a uniform external magnetic field into the two-body Lagrangian expanded to first post-Newtonian order, we derive the complete equations of motion that capture both gravitational and electromagnetic interactions. The magnetic Lorentz force fundamentally alters the orbital dynamics, breaking the conservation of linear and angular momentum and inducing transitions from planar to three-dimensional trajectories. Through numerical integration of these equations, we compute the resulting gravitational waveforms and quantify the magnetic field imprints using matched filtering techniques. Our results demonstrate that strong background magnetic fields can substantially modify the orbital evolution and leave distinctive signatures in the gravitational wave signals. These findings provide a promising avenue for detecting charged black holes and probing magnetic field environments through gravitational wave observations.

</details>


### [124] [Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo II: Chaotic Imprints in Gravitational Waves](https://arxiv.org/abs/2512.04848)
*Surajit Das,Surojit Dalui,Bum-Hoon Lee,Yi-Fu Cai*

Main category: gr-qc

TL;DR: 该研究分析了极端质量比旋进系统中混沌动力学对引力波信号的印记，发现混沌轨道产生的引力波具有更宽的频谱、增强的振幅和能量发射率，可通过谱分析和递归分析区分混沌与非混沌运动。


<details>
  <summary>Details</summary>
Motivation: 研究极端质量比旋进系统中混沌动力学对引力波信号的物理印记，探索如何通过引力波观测区分混沌与非混沌轨道，并评估未来引力波天文台探测这些信号的可能性。

Method: 采用数值kludge方案计算小质量天体沿混沌和非混沌轨道的引力波形，进行谱分析，通过递归分析研究引力波应变时间序列，评估LISA、天琴和太极等未来观测台的探测潜力。

Result: 混沌状态下的引力波信号具有更宽的频谱宽度、增强的振幅和能量发射率，引力波应变时间序列携带独特的混沌动力学信息，可通过谱特征和递归分析有效区分混沌与非混沌运动。

Conclusion: 引力波信号中的混沌印记可通过谱分析和递归分析检测，这些特征有望被未来引力波天文台观测到，将极大增强我们对黑洞物理和星系核暗物质环境中混沌动力学的理解。

Abstract: We investigate the imprints of chaos in gravitational waves from extreme-mass-ratio inspirals configuration, where a stellar massive object, confined in a harmonic potential, orbits a supermassive Schwarzschild-like black hole embedded in a Dehnen-type dark matter halo. In our first paper [1], we demonstrated the system's transition from non-chaotic to chaotic dynamics by analyzing Poincaré sections, orbital evolution, and Lyapunov exponents across different energies and dark matter halo parameters. In this work, we compute the gravitational waveforms of the small celestial object along different chaotic and non-chaotic orbits by implementing the numerical kludge scheme. We further perform a spectral analysis of the gravitational waveforms from such orbits. In particular, we show that when the system is in a chaotic state, the gravitational wave signals are characterized by broader frequency spectra with finite widths, enhanced amplitude and energy emission rate, distinctly differentiating them from the signals generated during the system's non-chaotic state. Through recurrence analysis we also show that the time series of gravitational waveforms strain carry unique information on the motion of chaotic dynamics, which can be used to distinctly differentiate from non-chaotic to chaotic motion of the source. Furthermore, we discuss the potential detectability of these orbits for upcoming observatories like LISA, TianQin, and Taiji, emphasizing the significant potential for detecting chaotic imprints in gravitational waves to substantially enhance our understanding of chaotic dynamics in black hole physics and the dark matter environments of galactic nuclei.

</details>


### [125] [Detecting relativistic black hole collisions near a massive black hole](https://arxiv.org/abs/2512.04851)
*Yirong Fang,Changfu Shi,Jianwei Mei*

Main category: gr-qc

TL;DR: 研究大质量黑洞背景下相对论性黑洞碰撞及其引力波探测能力


<details>
  <summary>Details</summary>
Motivation: 相对论性黑洞碰撞是探测广义相对论之外新物理的理想条件，但通常罕见且难以发生。三体系统中的黑洞可加速到相对论极限，可能发生相对论性碰撞。

Method: 研究大质量黑洞背景下的相对论性黑洞碰撞，评估多个当前和未来引力波探测器探测此类信号的能力。

Result: 论文未提供具体结果，但研究了此类碰撞事件及其探测可能性。

Conclusion: 三体系统中的黑洞碰撞可能为探测新物理提供机会，需要评估现有和未来引力波探测器的探测能力。

Abstract: Relativistic black hole collisions are one of the most dramatic astrophysical events that can be imagined. They could provide the ideal condition for searching for possible new physics beyond general relativity. However, such events are presumably rare and difficult to occur under normal conditions. Black holes in a triple system can be accelerated to the relativistic limit and may harbor the chance for a relativistic collision. In this paper, we study the relativistic black hole collisions in a massive black hole background and the capabilities of several current and future gravitational wave detectors in detecting such signals.

</details>


### [126] [Constraints on Genesis Cosmology from the Smeared Null Energy Condition](https://arxiv.org/abs/2512.04934)
*Dong-Hui Yu,Mian Zhu,Yong Cai*

Main category: gr-qc

TL;DR: SNEC（涂抹零能量条件）对Genesis宇宙学模型施加了非平凡限制，约束了避免初始奇点的非奇异宇宙学场景的可行性。


<details>
  <summary>Details</summary>
Motivation: 研究SNEC（量子启发的半局域边界）如何影响Genesis宇宙学模型，这些模型需要违反NEC来避免初始奇点，但理论界担心负能量积累问题。

Method: 在广义伽利略理论框架下构建的Genesis模型中检验SNEC猜想，分析SNEC对这些模型施加的约束条件。

Result: SNEC对Genesis模型的可行性施加了非平凡限制，表明SNEC猜想是约束非奇异宇宙学场景的有力工具。

Conclusion: SNEC作为量子启发的能量条件，对违反NEC的Genesis宇宙学模型提出了实质性约束，为评估非奇异宇宙学场景的可行性提供了重要判据。

Abstract: The violation of the null energy condition (NEC) is essential for constructing nonsingular cosmological scenarios, such as Genesis cosmology, which avoids the initial singularity by initiating cosmic evolution from an asymptotically Minkowski state. To address theoretical concerns regarding the accumulation of negative energy, the smeared null energy condition (SNEC) has been proposed as a quantum-motivated, semi-local bound on NEC violation. In this work, we examine the implications of the SNEC conjecture for Genesis models, typically constructed within generalized Galileon theories. Our results demonstrate that SNEC imposes nontrivial restrictions on the viability of Genesis models, highlighting the SNEC conjecture as a powerful tool for constraining nonsingular cosmological scenarios.

</details>


### [127] [Multipole decomposition of the gravitational field of a point mass at the black hole horizon](https://arxiv.org/abs/2512.04976)
*João P. B. Brito,Atsushi Higuchi,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: 黑洞吸收点质量径向坠落的引力能量在微扰理论中发散，这是点粒子模型的缺陷，源于奇点附近无限静态场的能量流入黑洞


<details>
  <summary>Details</summary>
Motivation: 研究黑洞吸收点质量径向坠落的引力能量在微扰理论中发散的问题，揭示这种发散是点粒子模型的人为缺陷，需要理解其物理根源

Method: 对点质量在黑洞视界附近产生的线性化引力场进行多极分解，应用标准场论方法计算粒子场的部分能量，并与常数多极贡献进行匹配

Result: 发现发散能量源于奇点附近无限静态场的能量，当粒子轨迹穿过视界时这些能量也流入黑洞，计算得到的部分能量与常数多极贡献相匹配

Conclusion: 黑洞吸收能量的发散是点粒子模型的数学缺陷，实际物理系统中这种发散会被正则化，揭示了奇点附近静态场能量对吸收过程的贡献机制

Abstract: The portion of the gravitational energy absorbed by the black hole due to the radial infall of a point mass is known to diverge at leading order in perturbation theory. This divergence is an artifact of the point-particle model, where the contribution of each multipole to the total absorbed energy is observed to be roughly constant. We show explicitly that this divergent energy arises from the infinite energy present in the singular static field arbitrarily close to the point mass, which also flows into the black hole when the particle trajectory crosses the horizon. We perform a multipole decomposition of the linearized gravitational field generated by the point mass near its world line at the black hole horizon. By applying the standard field-theoretical approach to the particle field, we compute the corresponding partial energy and find that it matches the constant multipole contribution.

</details>


### [128] [Thermodynamics vs Teleodynamics: A Cosmological Divide?](https://arxiv.org/abs/2512.04977)
*Oem Trivedi,Venkat Venkatasubramanian*

Main category: gr-qc

TL;DR: 黑洞遵循标准贝肯斯坦-霍金热力学，而膨胀宇宙必须遵循具有记忆能力的远距离动力学，两者属于不同热力学体系


<details>
  <summary>Details</summary>
Motivation: 探索黑洞和宇宙在热力学上的根本差异，为量子引力理论提供新视角，避免将黑洞热力学错误地外推到整个宇宙

Method: 通过动力学和半经典方法分析黑洞和宇宙的热力学行为，证明远距离动力学在宇宙膨胀中的必然性

Result: 黑洞遵循标准面积定律，而宇宙膨胀必须包含视界记忆积累，导致偏离面积定律，实现了热力学分裂猜想的动力学实现

Conclusion: 量子引力理论不应将黑洞热力学外推到宇宙，而应将视界记忆作为基本微观成分，构建与之一致的宇宙学模型

Abstract: We show that stationary black holes and the evolving universe belong to fundamentally different thermodynamic regimes: black holes obey ordinary Bekenstein Hawking thermodynamics, whereas cosmology necessarily follows memory-bearing teleodynamics. We show that teleodynamics is not valid for black holes, but is unavoidable in an expanding cosmology. This provides a dynamical, semi-classical realization of the thermodynamic split conjecture and identifies memory accumulation as the natural source of deviations from the area law in cosmology. Our results suggest that quantum gravity should not seek to extrapolate black hole thermodynamics to the universe, but instead must incorporate horizon memory as a fundamental microscopic ingredient and consider cosmological constructions consistent with that.

</details>


### [129] [Schwarzschild Black Hole Turbulence: Scalar Probe](https://arxiv.org/abs/2512.05003)
*Alex Kehagias,Antonio Riotto*

Main category: gr-qc

TL;DR: 研究黑洞微扰如何通过近共振相互作用在标量模式间重新分配能量，驱动类湍流级联，特别关注高多极矩极限下的差频混合主导机制。


<details>
  <summary>Details</summary>
Motivation: 探索黑洞环降过程中能量如何在标量模式间转移，以及线性扰动下如何产生类湍流特征，为黑洞微扰理论提供定量机制。

Method: 采用van der Pol-Krylov-Bogoliubov平均方法，推导描述相邻多极矩间近共振相互作用的耦合模式方程，比较差频混合和自调制两种不稳定路径。

Result: 在高多极矩（几何光学极限）下，差频路径主导并驱动从高频到低频的单向级联，绘制了相应的不稳定区域（"舌头"）并量化了失谐依赖关系。

Conclusion: 该框架为黑洞环降中的能量转移提供了简单定量机制，阐明了在弱扰动背景下线性探测中何时以及如何出现湍流特征。

Abstract: We explore how perturbations of a Schwarzschild black hole can redistribute energy among scalar modes and seed turbulent like cascades. We make use of the van der Pol-Krylov-Bogoliubov averaging method and derive coupled mode equations that describe near-resonant interactions between neighbouring multipoles. We compare two routes to instability, namely the difference-frequency mixing between adjacent modes and the diagonal (Mathieu) self-modulation channel. We show that, at high multipole number (eikonal limit), the difference-frequency route dominates and drives a one-way cascade from higher to lower frequencies. We chart the corresponding instability regions ("tongues") and quantify their detuning dependence. The framework provides a simple, quantitative mechanism for energy transfer in black hole ringdowns and clarifies when and how turbulent signatures can arise within linear probes on a weakly perturbed background.

</details>


### [130] [Emergence of ER=EPR from non-local gravitational energy](https://arxiv.org/abs/2512.05022)
*Kimet Jusufi,Francisco S. N. Lobo,Emmanuel N. Saridakis,Douglas Singleton*

Main category: gr-qc

TL;DR: 该论文构建了一类由非局域引力自能支撑的虫洞几何，展示了两个纠缠粒子（或粒子-黑洞对）自然地产生爱因斯坦-罗森型几何，为ER=EPR猜想提供了具体实现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为ER=EPR猜想（爱因斯坦-罗森桥等于纠缠粒子对）提供具体的几何实现，避免使用特设的奇异物质，而是利用量子引力效应自然地产生虫洞结构。

Method: 方法基于T-对偶启发的框架，构建由非局域引力自能支撑的虫洞几何，分析其视界、喉部结构和嵌入特性，并识别最小表面所需的奇异能量。

Result: 研究发现只有零喉部几何与纠缠诱导的爱因斯坦-罗森桥兼容，为ER=EPR提供了完全正则时空中的具体实现。同时分类了产生的虫洞类型并分析了其几何特性。

Conclusion: 结论表明纠缠粒子对可以自然地产生爱因斯坦-罗森型虫洞几何，为ER=EPR提供了具体实现，并对微观ER网络、霍金辐射的副本虫洞解释以及纠缠驱动的暗能量场景具有潜在意义。

Abstract: We construct a class of wormhole geometries supported by the non-local gravitational self-energy that regularizes the particle and black-hole sectors of spacetime. Using this framework, inspired by T-duality, we show that two entangled particles (or particle-black-hole pairs) naturally source an Einstein-Rosen-type geometry in which the required violation of the strong energy condition arises from intrinsic quantum-gravity effects rather than from ad hoc exotic matter, which is matter that violates the null energy condition. We classify the resulting wormholes, analyze their horizons, throat structure and embedding properties, and we identify the exotic energy needed at the minimal surface. Imposing the ER=EPR requirement of non-traversability and the absence of a macroscopic throat, we find that only the zero-throat geometry is compatible with an entanglement-induced Einstein-Rosen bridge, providing a concrete realization of ER=EPR within a fully regular spacetime. Finally, we briefly discuss possible implications for microscopic ER networks from vacuum fluctuations, replica-wormhole interpretations of Hawking radiation, and possible links to entanglement-driven dark-energy scenarios.

</details>


### [131] [Effective delta sources and Newtonian limit in nonlocal gravity](https://arxiv.org/abs/2512.05061)
*Thomas M. Sangy,Nicolò Burzillà,Breno L. Giacchini,Tibério de Paula Netto*

Main category: gr-qc

TL;DR: 研究具有指数形式因子 f_s(□)=exp[(-□/μ_s^2)^{N_s}] 的非局部引力模型的牛顿极限，分析弱场解的特性，特别是参数 N_s 和 μ_s 对牛顿势的影响。


<details>
  <summary>Details</summary>
Motivation: 研究非局部引力模型中指数形式因子家族的牛顿极限，旨在理解这类模型中弱场解的共性与差异，为探索非局部引力的弱场现象学提供理论基础。

Method: 使用有效源形式主义，比较相关的有效δ源、质量函数和牛顿势，通过级数、积分和特殊函数等多种表示方法进行分析，并建立简单的参数近似。

Result: 发现只有当 N_s>1 时牛顿势才会振荡，但有效质量保持正定；验证了线性化解是正则的（无曲率奇点）；计算了这些模型中牛顿势的领先对数量子修正形式。

Conclusion: 该研究为理解非局部引力模型的弱场行为提供了系统分析框架，特别是揭示了参数 N_s 对牛顿势振荡行为的关键影响，同时证明了即使存在振荡，解仍然是正则的，为量子修正的弱场实现提供了有效途径。

Abstract: We investigate the Newtonian limit of a class of nonlocal gravity models with exponential form factors $f_s (\Box) = \exp [(-\Box/μ_s^2)^{N_s}]$. Our main goal is to identify similarities and differences between models in this family in regard to weak-field solutions. To this end, we use the effective source formalism to compare the related effective delta sources, mass functions, and Newtonian potentials. We obtain a variety of representations for these quantities in terms of series, integrals, and special functions, as well as simple approximations that capture the relevant dependence on the parameters $N_s$ and $μ_s$ - which can be used to explore the weak-field phenomenology of nonlocal gravity. We explain why only for $N_s>1$ the Newtonian potential oscillates and prove that, despite the oscillations, the effective masses are positive. Moreover, we verify that these linearized solutions are regular (without curvature singularities). Finally, we also calculate the form of the leading logarithmic quantum correction to the Newtonian potential in these models. In all our considerations, we assume that $N_s$ is a positive real parameter. The cases of non-integer $N_s$ might be applied beyond nonlocal gravity, in effective approaches to implement quantum corrections in the weak field regime.

</details>


### [132] [On the treatment of thermal effects in the equation of state on neutron star merger remnants](https://arxiv.org/abs/2512.05118)
*Davide Guerra,Milton Ruiz,Michele Pasquali,Pablo Cerdá-Durán,Arnau Rios,José A. Font*

Main category: gr-qc

TL;DR: 该研究通过长时间数值相对论模拟，比较了完全表格化和混合状态方程在双中子星合并中的热效应处理差异，发现热模型显著影响引力波频率演化，并揭示了HMNS中持续的对流模式会激发惯性模式。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估有限温度效应处理对双中子星合并后超质量中子星残骸动力学的影响，特别是对引力波信号谱和热效应建模差异的深入分析。

Method: 采用长时间（达150毫秒）数值相对论模拟，使用完全表格化的有限温度状态方程及其对应的混合表示。通过分析引力波后合并信号谱，并应用Ledoux准则和Solberg-Høiland准则评估HMNS的对流稳定性。

Result: 研究发现：1）热模型处理导致引力波频率演化存在显著差异，特别是在后合并晚期阶段偏离准普适关系；2）HMNS中的差速旋转和热分层产生持续的对流模式；3）这些对流模式激发频率低于基本四极模式的惯性模式，可能被第三代引力波探测器探测到。

Conclusion: 有限温度效应处理对双中子星合并动力学有重要影响，表格化状态方程模拟支持了先前基于混合状态方程研究中观察到的惯性模式激发，为第三代引力波探测器观测提供了理论基础。

Abstract: We present results from long-term, numerical-relativity simulations of binary neutron star mergers modeled using both, fully tabulated, finite-temperature, equations of state and their corresponding hybrid representations. The simulations extend up to 150 ms which allows us to assess the role of the treatment of finite-temperature effects on the dynamics of the hypermassive neutron star remnant. Our study focuses on the analysis of the spectra of the post-merger gravitational-wave signals and on how these are affected by the treatment of thermal effects in the two EOS representations. Our simulations highlight distinct differences in the GW frequency evolution related to the thermal modeling of the EOS, demonstrating that deviations from established quasi-universal relations become significant at late post-merger phases. Furthermore, we investigate the stability of the HMNS against convection. Employing both the Ledoux criterion, necessary condition for the development of convective instabilities, and the Solberg-Høiland criterion, a generalized criterion for axisymmetric perturbations based on a combined analysis of the Brunt-Väisälä frequency and of the epicyclic frequency, we show that differential rotation and thermal stratification in the HMNS give rise to local (yet sustained) convective patterns that persist beyond 100 ms after merger. Those convective patterns, while substantially different between tabulated and hybrid EOS treatments, trigger the the excitation of inertial modes with frequencies smaller than those attained by the fundamental quadrupolar mode, and are potentially within reach of third-generation GW detectors. The late-time excitation of inertial modes, previously reported in studies based on hybrid EOS, is fully supported by the tabulated, finite-temperature EOS simulations presented here, which account for thermal effects in a more consistent way.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [133] [Persistent-variable thermal compositional simulation of multiphase flow with phase separation in porous media](https://arxiv.org/abs/2512.04205)
*Veljko Lipovac,Omar Duran,Eirik Keilegavlen,Inga Berre*

Main category: physics.comp-ph

TL;DR: 提出一种基于焓的持久变量公式，用于热组分多相流模拟，通过嵌入局部求解器处理相变非线性，无需相稳定性测试，适用于高焓应用。


<details>
  <summary>Details</summary>
Motivation: 热组分多相流在孔隙介质中涉及流动、输运和相平衡的复杂非线性相互作用，传统方法在处理相变和高温高焓系统时面临挑战。

Method: 使用焓构建能量平衡和局部平衡问题的持久变量公式，从热力学一致的最小化问题推导平衡条件，将局部热力学求解器嵌入全局牛顿求解器中处理非线性。

Result: 方法能模拟复杂高焓系统（包括窄沸现象），局部求解器可将全局非线性迭代减少达23%，局部残差容差高达1e-3时对全局迭代数无显著影响。

Conclusion: 基于焓的持久变量方法和模块化嵌入局部求解器推进了多相流模拟中平衡计算的应用，特别适用于高焓应用场景。

Abstract: Thermal compositional multiphase flow in porous media with phase transitions involves complex nonlinear interactions among flow, transport, and phase equilibrium. This paper presents a persistent-variable formulation for thermal compositional flow using enthalpy to formulate the energy balance and the local equilibrium problem. Equilibrium conditions are derived from a thermodynamically consistent minimization problem using a persistent set of variables, allowing for seamless integration of equilibrium calculations into a fully coupled flow and transport model. This formulation does not require phase stability tests and provides a continuous and full mathematical description of the multiphysics system, suitable for challenging non-isothermal scenarios. To tackle the nonlinearities arising from phase transitions, we embed a local solver for the thermodynamic subproblem within a global Newton solver for the fully implicit system. The local solver exploits the locality of the subproblem for parallelization and leverages the modularity of the persistent-variable formulation for both isothermal and isenthalpic equilibrium conditions locally. We demonstrate the capability of our approach to simulate complex high-enthalpy systems, including narrow-boiling phenomena. The impact of the embedded local solver is analyzed through numerical experiments, demonstrating a reduction in global nonlinear iterations of up to 23 \% with increased use of the local solver. The number of local iterations is controlled with a local solver tolerance and no significant impact on the global iteration number was observed for local residual tolerances as high as $1e-3$. The persistent-variable approach using enthalpy and the modularity of the embedded local solver advance the usage of equilibrium calculations in multiphase flow simulations and are suitable for high-enthalpy applications.

</details>


### [134] [Bessel Functions and Analysis of Circular Waveguides](https://arxiv.org/abs/2512.04348)
*Jaime Mora-Paz,Leszek Demkowicz,Christina G. Taylor,Jacob Grosek,Stefan Henneking*

Main category: physics.comp-ph

TL;DR: 该论文研究圆形螺旋光学平板波导，通过变量变换和Frobenius方法计算复阶复宗量贝塞尔函数，结合完美匹配层技术求解贝塞尔特征值问题，为三层光学平板波导提供精确损耗因子。


<details>
  <summary>Details</summary>
Motivation: 研究圆形螺旋光学平板波导（也适用于声波导），需要解决相关的贝塞尔特征值问题，为三层光学平板波导问题提供精确的损耗因子计算。

Method: 使用变量变换和经典Frobenius方法计算复阶复宗量贝塞尔函数，结合完美匹配层(PML)技术求解贝塞尔特征值问题。

Result: 获得了三层光学平板波导问题的精确损耗因子，为验证该问题的模型实现提供了基准，并数值验证了Glazman准则。

Conclusion: 该方法为圆形螺旋光学平板波导提供了精确的损耗因子计算，验证了Glazman准则，为具有阻抗边界条件的均匀圆形波导的适定性和稳定性分析奠定了基础。

Abstract: The paper is devoted to the study of circularly coiled optical slab waveguides, which is also applicable to acoustical waveguides. We use a change of variables and the classical Frobenius method to compute Bessel functions of complex order and complex argument, and combine it with a perfectly matched layer technique to solve the relevant Bessel eigenvalue problem and deliver accurate loss factors for eigensolutions to the three-layer optical slab waveguide problem. The solutions provide a benchmark for verifying model implementations of this problem and allow for a numerical verification of the Glazman criterion that provides a foundation for the well-posedness and stability analysis of homogeneous circular waveguides with impedance boundary conditions.

</details>


### [135] [GPU-Portable Real-Space Density Functional Theory Implementation on Unified-Memory Architectures](https://arxiv.org/abs/2512.04447)
*Atsushi M. Ito*

Main category: physics.comp-ph

TL;DR: QUMASUN是一个GPU可移植的实空间密度泛函理论代码，在Intel Xeon CPU、AMD MI300A和NVIDIA GH200 GPU上进行了基准测试，实现了2.0-2.8倍的加速。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在不同GPU架构（包括AMD和NVIDIA）上高效运行的实空间密度泛函理论代码，以利用现代GPU硬件加速等离子体聚变模拟等科学计算应用。

Method: 采用轻量级C++ lambda层实现CPU、CUDA和HIP执行，无需OpenMP/OpenACC预处理器指令。利用MI300A的统一内存和GH200的相干内存互连简化GPU移植。对钻石（216原子）和钨（128原子）系统进行性能测试。

Result: 在MI300A和GH200 GPU上，相比256核Xeon节点，分别实现了2.0-2.8倍和2.3-2.4倍的加速。计算密集型内核（FFT、GEMM、特征值求解器）在两种GPU上都显示出显著加速。

Conclusion: 提出的GPU可移植方法不仅适用于密度泛函理论代码，还能使更广泛的等离子体聚变模拟代码受益，展示了跨不同GPU架构的高性能计算能力。

Abstract: We present a GPU-portable implementation of a real-space density functional theory (DFT) code ``QUMASUN'' and benchmark it on the new Plasma Simulator featuring Intel Xeon 6980P CPUs, and AMD MI300A GPUs. Additional tests were performed on an NVIDIA GH200 GPU. In particular MI300A supports unified memory and GH200 supports coherent memory interconnect, simplifying GPU porting. A lightweight C++ lambda-based layer enables CPU, CUDA, and HIP execution without OpenMP/OpenACC preprocessor directives. For diamond (216 atoms) and tungsten (128 atoms) systems, MI300A and GH200 achieve 2.0-2.8 $\times$ and 2.3-2.4 $\times$ speedups over a 256-core Xeon node. The compute-bound kernels, which are fast Fourier transforms (FFT), dense matrix-matrix multiplications (GEMM) and eigenvalue solver, show substantial acceleration on both GPUs, indicating that the present GPU-portable approach can benefit a wide range of plasma-fusion simulation codes beyond DFT.

</details>


### [136] [On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State](https://arxiv.org/abs/2512.04450)
*Christopher DeGrendele,Nguyen Ly,Francois Cadieux,Michael Barad,Dongwook Lee,Jared Duensing*

Main category: physics.comp-ph

TL;DR: 提出两种完全守恒的压力平衡保持方法，用于消除多组分欧拉方程中的虚假压力振荡


<details>
  <summary>Details</summary>
Motivation: 传统完全守恒的欧拉方程离散化方法在处理真实流体状态方程时，由于压力、密度和内能之间的非线性热力学关系，会产生虚假压力振荡

Method: 提出两种方法：1) 完全守恒的压力平衡保持方法；2) 高阶完全守恒的近似压力平衡保持方法。两种方法都能处理任意状态方程和任意数量的组分，不引入非守恒更新、过定方程或针对特定状态方程设计

Result: 在理想气体、硬化气体和范德瓦尔斯状态方程控制的无粘光滑界面平流问题上，相比现有方案，虚假压力振荡减少了数个数量级

Conclusion: 提出的方法能够有效消除多组分欧拉方程中的虚假压力振荡，具有通用性，适用于任意状态方程和任意数量的组分

Abstract: Typical fully conservative discretizations of the Euler compressible single or multi-component fluid equations governed by a real-fluid equation of state exhibit spurious pressure oscillations due to the nonlinearity of the thermodynamic relation between pressure, density, and internal energy. A fully conservative, pressure-equilibrium preserving method and a high-order, fully conservative, approximate pressure-equilibrium preserving method are presented. Both methods are general and can handle an arbitrary equation of state and arbitrary number of species. Unlike existing approaches to discretize the multi-component Euler equations, we do not introduce non conservative updates, overspecified equations, or design for a specific equation of state. The proposed methods are demonstrated on inviscid smooth interface advection problems governed by three equations of state: ideal-gas, stiffened-gas, and van der Waals where we show orders of magnitude reductions in spurious pressure oscillations compared to existing schemes.

</details>


### [137] [Stochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method](https://arxiv.org/abs/2512.04860)
*Xue Quan,Huajie Chen*

Main category: physics.comp-ph

TL;DR: 本文研究了平面波离散化下的随机密度泛函理论，提出了基于多级蒙特卡洛框架的方差缩减算法，使计算成本与离散化尺寸或温度无关。


<details>
  <summary>Details</summary>
Motivation: 随机密度泛函理论相比传统Kohn-Sham DFT在大规模电子结构计算中具有优势，但需要改进其计算效率。本文旨在通过方差缩减算法提高sDFT的计算性能。

Method: 采用平面波离散化的sDFT方法，通过引入随机轨道和切比雪夫展开近似密度矩阵。提出基于多级蒙特卡洛框架的方差缩减算法，将密度矩阵评估分解为多个层级（通过增加平面波截断或切比雪夫多项式阶数）。

Result: 算法实现了计算成本与离散化尺寸或温度的独立性，通过严格的统计误差分析和材料系统数值实验证明了算法的效率。

Conclusion: 提出的多级蒙特卡洛方差缩减算法显著提高了平面波离散化sDFT的计算效率，为大规模电子结构计算提供了有效的解决方案。

Abstract: The stochastic density functional theory (sDFT) has exhibited advantages over the standard Kohn-Sham DFT method and has become an attractive approach for large-scale electronic structure calculations. The sDFT method avoids the expensive matrix diagonalization by introducing a set of random orbitals and approximating the density matrix via Chebyshev expansion of a matrix-valued function. In this work, we study the sDFT with a plane-wave discretization, and discuss variance reduction algorithms in the framework of multilevel Monte Carlo (MLMC) methods. In particular, we show that the density matrix evaluation in sDFT can be decomposed into many levels by increasing the plane-wave cutoffs or the Chebyshev polynomial orders. This decomposition renders the computational cost independent of the discretization size or temperature. To demonstrate the efficiency of the algorithm, we provide rigorous analysis of the statistical errors and present numerical experiments on some material systems.

</details>


### [138] [PENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling](https://arxiv.org/abs/2512.04863)
*Mostafa Bamdad,Mohammad Sadegh Eshaghi,Cosmin Anitescu,Navid Valizadeh,Timon Rabczuk*

Main category: physics.comp-ph

TL;DR: 提出PENCO混合算子学习框架，结合物理定律与数值结构，通过增强的L²高斯-洛巴托配点残差、傅里叶空间数值一致性项和能量耗散约束，显著提升相场模型等时空PDE求解的精度、稳定性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子（NOs）在求解时空偏微分方程时存在时间误差累积、长时程模拟泛化能力差、需要大量训练数据等问题，需要开发能更好结合物理定律和数值结构的混合框架。

Method: 提出PENCO混合算子学习框架，包含：1）增强的L²高斯-洛巴托配点残差，在时间中点处强制满足控制动力学；2）傅里叶空间数值一致性项，捕捉半隐式离散化的平衡行为；3）能量耗散约束确保热力学一致性；4）低频谱锚定和教师一致性机制稳定学习。

Result: 在三维相场基准测试（相序、结晶、外延生长、复杂图案形成）中，PENCO相比最先进的神经算子（MHNO和FNO-4D）表现出更高的精度、稳定性和数据效率，同时保持物理一致的演化。

Conclusion: PENCO成功整合了物理定律、数值结构和数据驱动学习，为相场模型等时空PDE提供了准确、高效且物理一致的求解框架，显著优于现有神经算子方法。

Abstract: Accurate and efficient solutions of spatio-temporal partial differential equations (PDEs), such as phase-field models, are fundamental for understanding interfacial dynamics and microstructural evolution in materials science and fluid mechanics. Neural Operators (NOs) have recently emerged as powerful data-driven alternatives to traditional solvers; however, existing architectures often accumulate temporal errors, struggle to generalize in long-horizon simulations, and require large training datasets. To overcome these limitations, we propose PENCO (Physics-Energy-Numerical-Consistent Operator), a hybrid operator-learning framework that integrates physical laws and numerical structure within a data-driven architecture. The formulation introduces an enhanced L^2 Gauss-Lobatto collocation residual around the temporal midpoint that robustly enforces the governing dynamics and significantly improves accuracy, a Fourier-space numerical consistency term that captures the balanced behavior of semi-implicit discretizations, and an energy-dissipation constraint that ensures thermodynamic consistency. Additional low-frequency spectral anchoring and teacher-consistency mechanisms further stabilize learning and suppress long-term error growth. This hybrid design enables PENCO to preserve governing physics while mitigating long-term error growth. Through extensive three-dimensional phase-field benchmarks covering phase ordering, crystallization, epitaxial growth, and complex pattern formation, PENCO demonstrates superior accuracy, stability, and data efficiency compared to state-of-the-art neural operators, including Multi-Head Neural Operator (MHNO) and Fourier Neural Operator (FNO-4D), while maintaining physically consistent evolution. The associated dataset and implementation are available at github.com/MBamdad/PENCO.

</details>


### [139] [VNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies](https://arxiv.org/abs/2512.04873)
*Christopher Ehrich,Christian Bachmann,Pavel Pereslavtsev,Christian Reiter*

Main category: physics.comp-ph

TL;DR: 比较Serpent和OpenMC中子学代码对VNS托卡马克的中子-光子耦合模拟结果，发现中子通量和(n,T)反应率高度一致，(n,2n)反应率良好一致，光子通量存在区域差异，Serpent的delta追踪比混合追踪更准确，计算时间方面Serpent在中子-光子耦合模拟中更快但在纯中子模拟中较慢。


<details>
  <summary>Details</summary>
Motivation: VNS托卡马克作为未来聚变反应堆组件测试平台，需要验证其中子学模拟的准确性和可靠性。通过比较两种主流中子学代码Serpent和OpenMC的模拟结果，评估模型一致性并为VNS设计提供参考。

Method: 在Serpent和OpenMC中建立VNS几何模型，进行中子-光子耦合模拟。在真空容器区域计算中子和光子通量分布图，在包层区域计算中子/光子能谱、(n,T)和(n,2n)反应率。比较两种代码的结果，并分析Serpent中混合追踪和delta追踪方法的影响。

Result: 中子通量和(n,T)反应率在两个代码间高度一致，(n,2n)反应率良好一致。光子通量存在区域差异：Serpent混合追踪在包层外侧产生约20%相对差异，而delta追踪差异小于1%。在HPC集群上，Serpent在中子-光子耦合模拟中计算时间更短，但在纯中子模拟中比OpenMC慢。

Conclusion: Serpent和OpenMC对VNS的中子学模拟在关键参数上基本一致，验证了模型的可靠性。Serpent的delta追踪方法比混合追踪更准确。该研究为VNS设计提供了中子学模拟基准，并展示了VNS在放射性同位素生产等附加功能方面的潜力。

Abstract: The Volumetric Neutron Source (VNS) tokamak is a proposed fusion reactor for testing and qualification of reactor components for future use in a fusion power facility, and has potential use for radioisotope production. The VNS geometry is modeled in the Serpent and OpenMC neutronics codes. Analog neutron-photon coupled simulations are carried out to compare the model's vacuum vessel and blanket components across codes. In the vacuum vessel, neutron and photon flux maps are calculated, while in the blanket region, neutron and photon spectra, (n,T), and (n,2n) reaction rates are calculated and compared between models. The detector response comparisons found the following: neutron flux and (n,T) reactions achieved excellent agreement, the (n,2n) detector response had good agreement, and photon flux had regional discrepancies depending on Serpent tracking used. Hybrid tracking lead to a relative difference of about 20% in the outboard side blanket, where as employment of delta tracking resulted in less than 1% relative difference. On an HPC cluster, Serpent was found to have shorter computation time than OpenMC in neutron photon coupled simulations using both hybrid tracking and delta tracking, but longer in neutron only simulations. An exemplary radioisotope production case is presented for the demonstration of additional VNS capabilities.

</details>


### [140] [LEDDS: Portable LBM-DEM simulations on GPUs](https://arxiv.org/abs/2512.04997)
*Raphael Maggio-Aprile,Maxime Rambosson,Christophe Coreixas,Jonas Latt*

Main category: physics.comp-ph

TL;DR: LEDDS是一个基于算法原语的开源框架，使用LBM-DEM方法进行颗粒流和流体-颗粒相互作用的GPU模拟，无需手写CUDA内核，实现了高性能与可移植性。


<details>
  <summary>Details</summary>
Motivation: 传统GPU编程需要编写设备特定的内核代码，而算法原语范式（如map、sort、reduce）提供了更高层次的抽象。本研究旨在将这种范式扩展到计算物理中的复杂问题，特别是颗粒流和流体-颗粒相互作用的模拟。

Method: 开发了LEDDS开源框架，使用算法原语实现完全耦合的Lattice Boltzmann-Discrete Element Method（LBM-DEM）模拟。整个工作流程（包括邻居搜索、碰撞检测和流体-颗粒耦合）都表示为可移植原语的序列。当前实现主要使用C++标准库算法，并选择性使用Thrust原语以获得性能。

Result: 通过多种DEM和LBM-DEM配置的基准测试验证了LEDDS，包括球体和椭球体碰撞、壁面摩擦测试、单颗粒沉降、Jeffery轨道和颗粒剪切流。尽管抽象层次高，LEDDS的性能与手工调优的CUDA求解器相当，同时保持了可移植性和代码清晰度。

Conclusion: 研究表明，高性能的LBM-DEM耦合可以在不牺牲通用性或可读性的情况下实现，LEDDS为基于算法原语的可移植多物理框架提供了蓝图，适用于广泛的现代GPU系统和未来加速器。

Abstract: Algorithmic formulations of GPU programs provide a high-level alternative to device-specific code by expressing computations as compositions of well-defined parallel primitives (e.g., map, sort, reduce), rather than through handcrafted GPU kernels. In this work, we demonstrate that this paradigm can be extended to complex and challenging problems in computational physics: the simulation of granular flows and fluid-particle interactions.
  LEDDS, our open-source framework, performs fully coupled Lattice Boltzmann -- Discrete Element Method (LBM-DEM) simulations using only algorithmic primitives, and runs efficiently on single-GPU platforms. The entire workflow, including neighbor search, collision detection, and fluid-particle coupling, is expressed as a sequence of portable primitives. While the current implementation illustrates these principles primarily through algorithms from the C++ Standard Library, with selective use of Thrust primitives for performance, the underlying concept is compatible with any HPC environment offering a rich set of parallel algorithms and is therefore applicable across a wide range of modern GPU systems and future accelerators.
  LEDDS is validated through benchmarks spanning both DEM and LBM-DEM configurations, including sphere and ellipsoid collisions, wall friction tests, single-particle settling, Jeffery's orbits, and particle-laden shear flows. Despite its high level of abstraction, LEDDS achieves performances comparable to those of hand-tuned CUDA solvers, while maintaining portability and code clarity. These results show that high-performance LBM-DEM coupling can be achieved without sacrificing generality or readability, establishing LEDDS as a blueprint for portable multiphysics frameworks based on algorithmic primitives.

</details>


### [141] [Engineered Inclined Energy Landscapes Enabling Free Flow of Magnetic Microstructures for Artificial Neuron Applications](https://arxiv.org/abs/2512.05020)
*Anmol Sharma,Ranjeet Kumar Brajpuriya,Vivek K. Malik,Vishakha Kaushik,Sachin Pathak*

Main category: physics.comp-ph

TL;DR: 提出一种基于锯齿型能量景观的磁性微结构设计，实现了低能耗（23.66 fJ/脉冲）的神经形态计算，成功模拟生物神经元的积分-发放功能。


<details>
  <summary>Details</summary>
Motivation: 自旋电子神经形态计算具有纳米尺度、高稳定性和低能耗等优势，但实际应用中存在制造工艺复杂、随机效应（如钉扎和热不稳定性）等问题，限制了器件的可靠性和可扩展性。

Method: 通过设计锯齿型能量景观来调控系统各向异性，实现磁性微结构的自由流动，从而模拟生物神经元的积分-发放功能。

Result: 成功实现了低能耗的神经形态计算，每个脉冲仅消耗23.66 fJ能量，为基于斯格明子的未来神经形态计算器件应用铺平了道路。

Conclusion: 提出的设计具有实验可行性和高能效，通过外部刺激调控磁性微结构动态行为，为开发可靠的斯格明子基神经形态计算器件提供了有效途径。

Abstract: Spintronic-based brain-inspired neuromorphic computing has recently attracted significant attention due to the exceptional properties of magnetic microstructures, including nanoscale dimensions, high stability, and low energy consumption. Despite these advantages, the practical integration of such microstructures into functional devices remains challenging. Fabrication processes are often complex and prone to stochastic effects, such as unwanted pinning and thermal-induced instabilities, which limit device reliability and scalability. Addressing these challenges is crucial for advancing spintronic neuromorphic architectures toward real-world applications. Thus, to reduce these effects we have proposed a design which is experimentally feasible and require less energy as compared to existing one. By engineering the system anisotropy into a sawtooth-type energy landscape, we have achieved free flow of these microstructures and successfully emulated integrate and fire (IF) function of biological neuron. Thus, proposed design presents an experimentally reliable and energy efficient external stimuli approach for tailoring magnetic microstructures dynamic behaviours, resulting in low energy consumption of 23.66 fJ per spike paving the way for the development of skyrmion-based futuristic neuromorphic computing device applications.

</details>
