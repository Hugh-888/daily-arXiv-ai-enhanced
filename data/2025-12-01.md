<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 30]
- [quant-ph](#quant-ph) [Total: 93]
- [physics.comp-ph](#physics.comp-ph) [Total: 7]
- [cs.LG](#cs.LG) [Total: 141]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Parity breaking reshapes black hole spectral dynamics](https://arxiv.org/abs/2511.21786)
*Han-Wen Hu,Chen Lan,Zong-Kuan Guo*

Main category: gr-qc

TL;DR: 提出一种通过准正规模式谱不稳定性检测黑洞对称性破缺的动态放大机制，在Chern-Simons引力中通过局域势垒扰动Schwarzschild背景，发现三个GR中不存在的现象：模式分支拓扑重连、反常模式稳定化、中间耦合强度下的标量模式主导。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞对称性破缺的检测问题，特别是如何通过准正规模式的谱不稳定性来放大微弱的静态分裂效应，为通过引力波观测测试修正引力理论提供新途径。

Method: 以动态Chern-Simons引力为宇称破缺范例，在Schwarzschild背景上施加局域势垒扰动，分析准正规模式的谱不稳定性，研究对称性破缺导致的动态放大效应。

Result: 发现三个在广义相对论中不存在的特征现象：1）模式分支的拓扑重连；2）反常的模式稳定化延迟超越转变；3）中间耦合强度下标量模式主导。这些动态特征能将微弱的静态分裂放大为可观测信号。

Conclusion: 该框架建立了引力对称性破缺与非厄米谱物理之间的联系，为通过引力波观测测试修正引力理论提供了新途径，动态放大机制使得原本微弱的对称性破缺效应变得可观测。

Abstract: We propose a dynamical amplification mechanism for detecting symmetry breaking in black holes through environmentally driven spectral instabilities of quasinormal modes. Focusing on dynamical Chern-Simons gravity as a paradigm for parity violation, we perturb the Schwarzschild background with a localized potential bump. Our analysis reveals three distinctive phenomena absent in general relativity: 1) topological reconnections of mode branches, 2) counterintuitive mode stabilization that delays overtaking transitions, and 3) scalar mode dominance emerging at intermediate coupling strengths. These dynamical features amplify weak static splittings into observable signatures, establishing a connection between gravitational symmetry breaking and non-Hermitian spectral physics. Our framework provides new pathways for testing modified gravity theories through gravitational wave observations.

</details>


### [2] [Numerical study of hypershadows in higher-dimensional black holes](https://arxiv.org/abs/2511.21829)
*Jianzhi Yang*

Main category: gr-qc

TL;DR: 开发了计算和可视化五维时空中黑洞阴影三维推广（超阴影）的数值框架，基于反向光线追踪，可灵活控制观测者位置，应用于Schwarzschild-Tangherlini和Myers-Perry几何


<details>
  <summary>Details</summary>
Motivation: 研究五维时空中黑洞阴影的三维推广（超阴影），传统二维阴影分析在更高维度中需要扩展到三维体积结构，需要开发数值方法来计算和可视化这种复杂几何结构

Method: 基于反向光线追踪的完全数值框架，结合离散采样与表面轮廓绘制，引入中心切片上的反射差异图来量化镜像对称性，可灵活控制观测者位置重建完整阴影体积

Result: 验证了Schwarzschild-Tangherlini几何的球对称性，系统讨论了超阴影对观测者位置和黑洞自旋参数的依赖性，提供了尺寸减小和全局位移的紧凑定量度量，揭示了清晰的单调趋势

Conclusion: 该框架可轻松扩展到其他度量，为数值研究更奇特物体（如黑洞环及其预期的环形超阴影）开辟了道路，为高维黑洞阴影分析提供了有力工具

Abstract: We develop a fully numerical framework to compute and visualize the \emph{hypershadow}\cite{Novo:2024wyn}, the three-dimensional generalization of the black hole shadow in five-dimensional spacetimes. Our method is based on backward ray tracing and allows flexible control over observer position, enabling the reconstruction of the full shadow volume. For visualization, we combine discrete sampling with surface contouring and introduce reflection difference maps on central slices to quantify mirror symmetries. Applying this method to the Schwarzschild-Tangherlini and Myers-Perry geometries, we validate the former's spherical symmetry and systematically discuss the hypershadow's dependence on observer position and black hole spin parameters. We also provide compact quantitative measures for size reduction and global displacement, revealing clear monotonic trends.The framework is readily extendible to other metrics and opens the way to numerical studies of more exotic objects, such as black rings and their prospective toroidal hypershadows.

</details>


### [3] [Symmetry and Conserved Quantities in $f(R)$-Gravity: Mei vs. Noether Approaches](https://arxiv.org/abs/2511.21896)
*Tahia F. Dabash,Moataz H. Emam,Lukas Schoppner*

Main category: gr-qc

TL;DR: 该论文使用Noether对称性和Mei对称性两种框架，研究了静态球对称Reissner-Nordström时空在f(R)引力理论中的对称性和守恒量，特别关注了二次模型f(R)=R²的情况。


<details>
  <summary>Details</summary>
Motivation: 研究f(R)引力理论中高阶拉格朗日量的对称性和守恒量，特别是在静态球对称Reissner-Nordström时空中，探索Mei对称性如何扩展标准的Noether框架，为修正引力中的黑洞动力学提供额外的守恒量。

Method: 采用两种互补框架：1) Noether对称性方法（变分和Lie导数形式），推导一般、正则和内部对称性类；2) Mei对称性方法，通过Euler-Lagrange方程在一阶延拓下的不变性条件，建立偏微分方程系统求解生成元。特别研究了二次模型f(R)=R²。

Result: 对于f(R)=R²模型：1) 在Noether方法中识别了包括径向平移和标度对称性在内的生成元；2) 在Mei对称性中找到了8个独立生成元，并构建了相应的守恒流，其中一些没有直接的Noether对应；3) 证明了Mei对称性扩展了高阶拉格朗日量的标准Noether框架。

Conclusion: Mei对称性为高阶拉格朗日量提供了超越标准Noether框架的额外守恒量，对修正引力中的黑洞动力学具有重要意义。研究为更广泛的f(R)模型和旋转时空的应用奠定了基础。

Abstract: We study the symmetries and conserved quantities in $f(R)$ gravity for the static, spherically symmetric Reissner--Nordström spacetime using two complementary frameworks: Noether symmetries and Mei symmetries. Starting from a canonical Lagrangian for radial metric functions and the curvature scalar $R$, we derive the associated Hamiltonian and show that the Legendre map is regular whenever both the first derivative of $f(R)$ with respect to $R$ and the second derivative with respect to $R$ is non-zero. Within Noether's approach (variational and Lie-derivative forms), we obtain general, canonical, and internal symmetry classes and identify explicit generators; for the quadratic model $f(R)=R^{2}$ these include radial translations and scaling symmetries. We then formulate Mei symmetry conditions as invariance of the Euler--Lagrange equations under the first prolongation, which yields an overdetermined partial differential equation (PDE) system for the generator components. Solving this system for $f(R)=R^{2}$, we find eight independent Mei generators and construct the corresponding conserved currents, some without a direct Noether analog. The analysis demonstrates that Mei symmetries extend the standard Noether framework for higher-order Lagrangians and provide additional conserved quantities relevant to black-hole dynamics in modified gravity. We conclude with a comparison of the two symmetry schemes and outline applications to broader $f(R)$ models and to rotating spacetimes.

</details>


### [4] [Gravitational waves from the late inspiral, transition, and plunge of small-mass-ratio eccentric binaries](https://arxiv.org/abs/2511.21897)
*Devin R. Becker,Scott A. Hughes,Gaurav Khanna*

Main category: gr-qc

TL;DR: 研究黑洞双星小质量比系统的引力波信号，特别关注偏心率和轨道异常角如何影响准正规模激发和晚期幂律尾迹。


<details>
  <summary>Details</summary>
Motivation: 小质量比黑洞双星是LISA任务的重要源，研究其动力学和引力波发射有助于理解紧凑双星系统。偏心轨道对晚期波形（准正规模和幂律尾迹）的影响尚不清楚。

Method: 使用先前开发的偏心Ori-Thorne程序构建小质量体在Kerr黑洞偏心轨道上的完整旋进和坠入世界线，用时域Teukolsky方程求解代码计算相应的引力波。

Result: 准正模式的相对激发随偏心率和异常角发生重要变化；某些异常角下的激发与准圆轨道合并几乎无法区分；偏心率倾向于放大晚期幂律尾迹，但放大程度随轨道异常角显著变化。

Conclusion: 偏心率对晚期合并波形有重要影响，但偏心率与轨道异常角的相互作用使这种影响复杂化，需要综合考虑这两个参数来准确描述引力波信号。

Abstract: Black hole binaries with small mass ratios will be important sources for the forthcoming Laser Interferometer Space Antenna (LISA) mission. Models of such binaries also serve as useful tools for understanding the dynamics of compact binary systems and the gravitational waves they emit. Using an eccentric Ori-Thorne procedure developed in previous work, we build worldlines that describe the full inspiral and plunge of a small body on an initially eccentric orbit of a Kerr black hole. We now calculate the gravitational waves associated with these trajectories using a code that solves the Teukolsky equation in the time domain. The final cycles of these waveforms, the ringdown, contains a superposition of Kerr quasinormal modes followed by a power-law tail. In this paper, we study how a binary's eccentricity and orbital anomaly angle affect the excitation of both quasinormal modes and late-time tails. We find that the relative excitation of quasinormal modes varies in an important and interesting way with these parameters. For some anomaly angles, the relative excitations of quasinormal modes are essentially indistinguishable from those excited in quasi-circular coalescences. Consistent with other recent studies, we find that eccentricity tends to amplify the late-time power-law tail, though the amount of this amplification varies significantly with orbital anomaly. We thus find that eccentricity has an important impact on the late-time coalescence waveform, but the interplay of eccentricity and orbit anomaly complicates this impact.

</details>


### [5] [Bayesian analysis of late-time tails in spin-aligned eccentric binary black hole mergers](https://arxiv.org/abs/2511.21898)
*Tousif Islam,Guglielmo Faggioli,Gaurav Khanna*

Main category: gr-qc

TL;DR: 该论文对自旋对齐偏心双黑洞合并引力辐射的晚期尾部进行了全面分析，发现尾部幅度随偏心率和负自旋增加而增强，尾部指数接近理论预测值。


<details>
  <summary>Details</summary>
Motivation: 研究双黑洞合并后引力波的晚期尾部行为，特别是偏心率和自旋对尾部特征的影响，以验证理论预测并理解极端参数下的引力辐射特性。

Method: 使用高精度点粒子黑洞微扰理论模拟，分析了15个质量比q=1000、不同自旋和偏心率的双黑洞合并，追踪了6个球谐模式的尾部幅度和指数，采用了频率主义和贝叶斯两种统计方法。

Result: 发现高偏心率和负自旋使尾部更显著；晚期尾部指数接近理论预测值p=-ℓ-4；相同ℓ值的模式具有相同尾部指数，m值变化不影响尾部行为。

Conclusion: 偏心双黑洞合并的引力辐射晚期尾部行为符合理论预期，验证了尾部指数与球谐指数ℓ的关系，分析框架已通过gwtails Python包公开。

Abstract: We present a comprehensive analysis of late-time tails in gravitational radiation from merging spin-aligned eccentric binary black holes, using high-accuracy point-particle black hole perturbation theory simulations. We simulate the late-time evolution of 15 binary black hole mergers with mass ratio $q = 1000$, dimensionless spins $χ= [-0.9, -0.6, 0.0, 0.6, 0.9]$ and eccentricity at the last stable orbit $e_{\rm LSO} = [0.8, 0.9, 0.95]$. We track the tail amplitudes and exponents up to a retarded time coordinate $t = 9000M$ after merger for the six spin-weighted spherical harmonic modes $(2,1)$, $(2,2)$, $(3,2)$, $(3,3)$, $(4,3)$, and $(4,4)$ employing both frequentist and Bayesian approaches. We note that the tails are increasingly pronounced for binaries with high eccentricity $e_{\rm LSO}$ and large negative spin $χ$. We find that the overall late-time exponents closely approach their predicted asymptotic values ($p=-\ell-4$ for Weyl curvature scalar $ψ_{4,\ell m}$ where $\ell$ is the spin-weighted spherical harmonic index), while estimates restricted to the latest portion of the data exactly recover them. We further verify numerically that modes with the same spherical index $\ell$ share identical tail exponents, while variations in $m$ do not affect the tail behavior. Our analysis framework is publicly available through the gwtails Python package.

</details>


### [6] [Searches for Post-Merger Gravitational Waves with CoCoA: Sensitivity Projections Across Large Template Banks for Current and Next-Generation Detectors](https://arxiv.org/abs/2511.21941)
*Tanazza Khanam,Alessandra Corsi,Robert Coyne,Michael St. Pierre*

Main category: gr-qc

TL;DR: 开发了一个基于Python的框架，用于评估不同引力波探测器网络对中子星合并后长寿命伽马射线暴遗迹产生的引力波的探测灵敏度。


<details>
  <summary>Details</summary>
Motivation: GW170817双中子星合并事件留下了关于其残余物性质（短寿命或长寿命中子星 vs 黑洞）的重要问题，需要理解不同合并残余物的多样性及其作为伽马射线暴中心引擎的可行性。

Method: 开发了一个Python框架，使用交叉相关算法（CoCoA）来有效估计当前和未来地面引力波探测器网络对各种后合并长期棒模式引力波波形的探测距离范围。

Result: 该框架能够识别参数空间中最有希望的区域，帮助设计未来的搜索策略，在搜索灵敏度、参数空间网格划分和计算成本之间实现最优平衡。

Conclusion: 这项工作为评估引力波探测器网络对中子星合并后长寿命伽马射线暴遗迹的探测能力提供了有效工具，有助于指导未来的搜索策略设计。

Abstract: The multi-messenger detection of the binary neutron star (NS) merger GW170817 has revolutionized the field of gravitational wave (GW) astronomy. However, several important questions remain to be answered. One of these is the nature of the compact remnant leftover by GW170817 (short- or long-lived NS versus black hole). A key goal going forward is to understand the diversity of NS-NS merger remnants, and how such diversity maps onto their viability as gamma-ray burst (GRB) central engines. Here, we present a study aimed at assessing the sensitivity of triggered searches for intermediate-duration, post-merger GWs powered by long-lived GRB remnants using networks of current and future ground-based GW detectors and the Cross-Correlation Algorithm (CoCoA). We develop a Python-based framework to efficiently estimate CoCoA distance horizons for a broad range of post merger secular bar-mode waveforms and for different GW detector networks. This framework can be used to identify the most promising regions of parameter space in which to concentrate search efforts, helping design future search strategies to optimally balance search sensitivity and related parameter space gridding schema against computational cost.

</details>


### [7] [Measuring Cosmological Redshift Using Gravitational Waves from Compact Binaries with Mass Transfer](https://arxiv.org/abs/2511.22057)
*Zi-Han Zhang,Tan Liu,Shenghua Yu,Zong-Kuan Guo*

Main category: gr-qc

TL;DR: 该研究探讨了在致密双星系统旋近阶段的质量转移过程如何影响引力波相位，并利用费希尔矩阵预测DECIGO探测器测量含白矮星双星系统红移的能力。


<details>
  <summary>Details</summary>
Motivation: 致密双星系统旋近阶段普遍存在质量转移过程，通过引力波探测可以测量质量转移率。质量转移效应为引力波相位提供额外贡献，能够打破双星质量和红移之间的简并性，从而更准确地确定宇宙学参数。

Method: 基于一阶后牛顿轨道角频率演化的解析质量转移率，使用费希尔矩阵（Fisher matrix）预测DECIGO探测器测量含质量转移的致密双星系统红移的能力。

Result: 对于包含白矮星的致密双星系统，当红移z=0.01且信噪比SNR~30时，红移测量精度可达10%。

Conclusion: 质量转移效应为引力波天文学提供了新的观测窗口，能够打破参数简并性，提高红移测量精度，为宇宙学研究提供重要工具。

Abstract: The mass transfer process is prevalent during the inspiral phase of compact binary systems. Detection of gravitational waves from the inspiral phase of binaries with white dwarfs will allow us to measure the mass transfer rate. Mass transfer effects provide additional contributions to the phase of gravitational waves, which can break the degeneracy between binary masses and redshift. Based on the analytic mass transfer rate to the first order post-Newtonian evolution of orbital angular frequency, we use the Fisher matrix to forecast the ability of DECIGO to measure the redshift of compact binaries with mass transfer. We conclude that for compact binary systems containing white dwarfs, the redshift can be determined to an accuracy of $10\%$ for $z=0.01$ with a $SNR\thicksim 30$.

</details>


### [8] [Abelian and non-Abelian mimetic black holes](https://arxiv.org/abs/2511.22062)
*Mohammad Ali Gorji,Susmita Jana,Pavel Petrov*

Main category: gr-qc

TL;DR: 在mimetic扩展的爱因斯坦-杨-米尔斯系统中研究黑洞解，其中杨-米尔斯项被约束为常数。在U(1)情况下找到了包含史瓦西和Reissner-Nordstrom黑洞的特例解，并发现了具有电毛发的隐身史瓦西解。SU(2)情况可以同时支持电和磁毛发，且允许任意整数磁参数的真正非阿贝尔构型。


<details>
  <summary>Details</summary>
Motivation: 研究mimetic扩展的爱因斯坦-杨-米尔斯系统中的黑洞解，探索在杨-米尔斯项被约束为常数的条件下，黑洞解的性质和特征，特别是比较阿贝尔U(1)和非阿贝尔SU(2)情况下的差异。

Method: 在mimetic扩展的爱因斯坦-杨-米尔斯系统中，将杨-米尔斯项约束为常数，分别研究阿贝尔U(1)和非阿贝尔SU(2)情况下的静态球对称黑洞解。通过解析方法寻找解，并分析其性质。

Result: 在U(1)情况下找到了包含史瓦西和Reissner-Nordstrom黑洞的特例解，发现了具有电毛发的隐身史瓦西解，但证明U(1)情况下不可能有磁毛发。在SU(2)情况下，隐身解可以同时支持电和磁毛发，且允许任意整数磁参数的真正非阿贝尔构型，这与传统SU(2)爱因斯坦-杨-米尔斯黑洞需要单位磁参数才能显示非平凡非阿贝尔贡献不同。

Conclusion: mimetic扩展的爱因斯坦-杨-米尔斯系统产生了有趣的黑洞解，其中SU(2)情况特别丰富，允许具有任意整数磁参数的真正非阿贝尔构型，这扩展了传统爱因斯坦-杨-米尔斯黑洞解的性质。

Abstract: We investigate black hole solutions in the mimetic extension of the Einstein-Yang-Mills system, in which the Yang-Mills term is constrained to be constant. In the Abelian U(1) case, we find a static spherically symmetric solution that includes the Schwarzschild and Reissner-Nordstrom black holes as special cases. Moreover, we identify a stealth Schwarzschild solution with an electric hair. We show that it is impossible to have magnetic hair in the U(1) gauge case, while, in contrast, the non-Abelian SU(2) stealth solutions can sustain both electric and magnetic hair. Unlike the conventional SU(2) Einstein-Yang-Mills black hole, which requires a unit magnetic parameter to exhibit nontrivial non-Abelian contributions, the stealth mimetic SU(2) solution admits genuinely non-Abelian configurations with arbitrary integer magnetic parameter.

</details>


### [9] [Hotspot Image Driven by Magnetic Reconnection in Kerr-anti-de Sitter Black Holes](https://arxiv.org/abs/2511.22077)
*Xiao-Xiong Zeng,Ke Wang*

Main category: gr-qc

TL;DR: 研究基于Comisso-Asenjo机制，在Kerr-AdS黑洞中分析磁重联前后等离子体的运动学图像，发现观测时间内会出现三个耀斑，且宇宙学常数Λ对热点图像有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索在Kerr-AdS黑洞背景下，基于Comisso-Asenjo机制的磁重联过程如何影响等离子体动力学，并研究宇宙学常数对黑洞周围热点成像的影响。

Method: 首先回顾Kerr-AdS黑洞中的Comisso-Asenjo过程，引入热点模型和成像方法，然后计算等离子体轨迹和热点图像的时间演化。

Result: 观测时间内出现三个由Comisso-Asenjo机制驱动的耀斑；热点图像随宇宙学常数Λ绝对值的增大而扩大，表明Λ对热点有显著影响。

Conclusion: Comisso-Asenjo机制在Kerr-AdS黑洞中能产生多个耀斑事件，且宇宙学常数Λ是影响黑洞周围热点成像的重要参数。

Abstract: Based on the Comisso-Asenjo mechanism, we investigate the kinematic images of plasma before and after magnetic reconnection in Kerr-Anti-de Sitter(Kerr-AdS) black holes. Following a brief review of the Comisso-Asenjo process in Kerr-AdS black holes, we introduce the hotspot model and the imaging method. Building upon these foundational theories, we obtain the trajectory of the plasma and the temporal evolution of the hotspot images. It is found that there are three flares within the observing time, which is driven by the Comisso-Asenjo mechanism. We also discuss the influence of the cosmological parameter on the hotspot imaging. The results indicate that the hotspot image enlarges as the absolute value of $Λ$ increases, demonstrating that the cosmological constant significantly affects the hotspot.

</details>


### [10] [Lorentz Violation in Emergent Gravity and Its Cosmological Consequences](https://arxiv.org/abs/2511.22221)
*Raymond Isichei,Joao Magueijo*

Main category: gr-qc

TL;DR: 该论文将广义相对论等几何理论视为涌现引力中的退化奥托循环，仅包含热交换过程。通过加入做功过程，可以产生局域洛伦兹不变性和能量-动量守恒的受控破坏，从而解释晚期宇宙加速膨胀。


<details>
  <summary>Details</summary>
Motivation: 论文旨在从热力学角度重新理解引力理论，特别是通过热力学循环的框架来解释广义相对论等几何引力理论，并探索如何通过扩展这一框架来解决宇宙学常数问题、晚期宇宙加速膨胀等现代宇宙学难题。

Method: 采用涌现引力的视角，将引力理论建模为热力学循环（奥托循环）。首先展示广义相对论等理论对应退化的奥托循环（仅含热交换过程），然后通过引入做功过程来扩展这一框架，从而允许局域洛伦兹不变性和能量-动量守恒的受控破坏。

Result: 研究发现：1）广义相对论等几何引力理论可以视为仅含热交换的退化奥托循环；2）加入做功过程会产生局域洛伦兹不变性和能量-动量守恒的受控破坏；3）这种破坏能够自然地产生晚期宇宙加速膨胀现象。

Conclusion: 该研究为理解引力理论提供了新的热力学视角，表明通过扩展热力学循环框架可以自然地解释宇宙加速膨胀，并对宇宙学常数问题、结构形成和局域观测具有重要启示意义。

Abstract: We show that General Relativity and other geometrical theories can be viewed as a degenerate Otto cycle with only heat-exchange legs in emergent gravity. Including work-producing legs yields controlled violations of local Lorentz invariance and energy-momentum conservation, which produce late-time cosmological acceleration. Implications for the cosmological constant problem, structure formation and local observations are discussed.

</details>


### [11] [Accretion of matter of a new bumblebee black hole](https://arxiv.org/abs/2511.22266)
*Yuxuan Shi,A. A. Araújo Filho*

Main category: gr-qc

TL;DR: 研究Bumblebee引力理论中静态黑洞对吸积物质行为及观测特征的影响，重点关注洛伦兹破坏参数如何改变光子轨迹、阴影大小和辐射强度


<details>
  <summary>Details</summary>
Motivation: 探索洛伦兹破坏引力理论中黑洞的观测特征，了解Bumblebee引力理论中静态黑洞如何影响吸积物质行为及其可观测信号

Method: 使用光线追踪技术分析光子偏折、直接辐射、透镜环和光子环结构，研究三种薄盘辐射模型（从ISCO、光子球、事件视界开始）以及静态和下落球对称吸积

Result: 洛伦兹破坏参数值越大，黑洞阴影越大，所有光学特征向外移动，观测强度因引力红移而减弱，下落物质还会产生多普勒效应导致的额外变暗

Conclusion: Bumblebee引力理论中的洛伦兹破坏参数显著影响黑洞的观测特征，包括阴影大小、辐射结构和强度，为通过观测数据约束洛伦兹破坏引力理论提供了可能

Abstract: We investigate how the newly obtained static black hole in bumblebee gravity affects the behavior of accreting matter and its observable signatures. The Lorentz-violating parameter that characterizes this geometry modifies photon trajectories and shifts the location of the critical curve that defines the shadow. Using ray tracing, we examine light deflection, the structure of direct emission, lensing rings, and photon rings, and we explore three thin-disk emission models--starting at the ISCO, at the photon sphere, and at the event horizon--together with static and infalling spherical accretions. Larger values of this parameter enlarge the shadow, move all optical features outward, and suppress the observed intensity through gravitational redshift, with additional dimming produced by Doppler effects for infalling matter

</details>


### [12] [Kerr black holes as circular polarizers](https://arxiv.org/abs/2511.22276)
*De-Chang Dai*

Main category: gr-qc

TL;DR: 研究极端克尔黑洞的逆行第二焦散，发现不同偏振光束在合适参数下可被外部黑洞分裂达10^-3弧度，导致偏振光在地球尺度上分离，影响回溯透镜观测。


<details>
  <summary>Details</summary>
Motivation: 研究极端克尔黑洞光强无限放大的逆行第二焦散现象，探索偏振光束在黑洞引力透镜效应中的行为，为回溯透镜观测提供新的观测量。

Method: 分析极端克尔黑洞的逆行第二焦散，计算不同偏振光束在黑洞引力场中的分裂角度，考虑观测者位置变化对偏振观测的影响。

Result: 发现不同偏振光束可被外部黑洞分裂达10^-3弧度，在数光年外的透镜黑洞作用下，偏振光束分离距离可达10^12米（超过地球半径），导致地球观测者位置不同会看到不同圆偏振光。

Conclusion: 偏振光束的分裂效应在回溯透镜观测中具有重要意义，偏振可作为重要的观测量，探测器位置变化会观测到偏振变化，为黑洞观测提供新方法。

Abstract: We study the retrograde second caustics of extremal Kerr black holes, where the intensity of the light beam is infinitely magnified. We find that the caustics of different polarized beams are split by as much as $10^{-3}$rad by an external black hole for a suitable range of parameters. A lensing black hole at several lys away separates the polarized beams about $10^{12}$m apart. This splitting is larger than the radius of the Earth. Therefore, an observer on Earth would see different circularly polarized light according to their location. The polarization will change while the detector is wandering around. Thus, the polarization of light beams can be an important quantity in retrolensing observations.

</details>


### [13] [Net Charge Accretion in Magnetized Kerr Black Holes](https://arxiv.org/abs/2511.22356)
*Ethan Berreby,Avner Okun,Shahar Hadar,Amos Ori*

Main category: gr-qc

TL;DR: 重新研究旋转克尔黑洞在磁场中的充电过程，发现Wald的饱和电荷公式Q_w=2B₀J在考虑带电粒子吸收率竞争时并不准确，实际饱和电荷会偏离这个值。


<details>
  <summary>Details</summary>
Motivation: Wald的经典分析假设注入能量为零，预测黑洞会获得饱和电荷Q_w=2B₀J。但实际物理机制应由正负带电粒子的吸收率竞争决定，因此需要重新研究这个充电过程。

Method: 采用简单的吸积模型，从无穷远沿磁力线注入两种符号相反的稀薄带电粒子流。将问题简化为磁化克尔黑洞电磁场中单个粒子的运动问题，结合数值和解析工具确定吸收域，建立吸收截面的上下界。

Result: 在Q=Q_w时，正负电荷的吸收截面存在系统性差异。对于足够强的磁场，"被吸引"电荷的吸收截面下界超过"被排斥"电荷的吸收截面上界。这种电荷吸积不平衡在强磁场极限下变得极端，表明在Q=Q_w时存在持续的净电荷吸积。

Conclusion: 实际的饱和电荷必须偏离Wald的电荷Q_w，因为电荷吸积不平衡表明Q=Q_w时仍存在净电荷吸积，真正的饱和电荷应由正负电荷吸收率的平衡决定。

Abstract: We investigate the charging process of a rotating Kerr black hole of mass $M$ and angular momentum $J$ immersed in a stationary, axisymmetric, asymptotically uniform magnetic field of strength $B_{0}$. In Wald's classic analysis (Wald 1974), which was based on the assumption of vanishing injection energy, the black hole was predicted to acquire a universal "saturation charge" $Q_{\mathrm{w}}=2B_{0}J$. However, the physical mechanism that sets the saturation charge must ultimately be governed by the competition between the absorption rates of positively and negatively charged particles. Motivated by this observation, we revisit the problem in the framework of a simple accretion model, where two dilute, equivalent fluxes of charged particles of opposite signs are injected from infinity along the magnetic field lines. The problem then reduces to that of individual particle motion in the electromagnetic field of the magnetized Kerr black hole. Using a combination of numerical and analytical tools, we determine the domains of absorption and establish both lower and upper bounds on the corresponding absorption cross sections. At $Q=Q_\mathrm{w}$ these bounds reveal a systematic difference between the two charge signs. In particular, for sufficiently strong magnetic fields, the lower bound on the absorption cross section for the "attracted" charge exceeds the upper bound for the "repelled" one. This charge accretion imbalance (which we find to become extreme at the limit of large $B_{0}$) indicates a persistent net charge accretion at $Q=Q_{\mathrm{w}}$, implying that the actual saturation charge must differ from Wald's charge $Q_{\mathrm{w}}$.

</details>


### [14] [Gravitational Spectra and Wave Propagation in Regular Black Holes Supported by a Dehnen Halo](https://arxiv.org/abs/2511.22366)
*Bekir Can Lütfüoğlu,Abubakir Shermatov,Javlon Rayimbaev,Muhammad Matyoqubov,Otaboyev Sirajiddin*

Main category: gr-qc

TL;DR: 研究Dehnen型暗物质晕支持的渐近平坦正则黑洞的引力扰动、准正规模、灰体因子和吸收截面，发现暗物质晕印记会修改引力响应，但不改变Price定律衰减。


<details>
  <summary>Details</summary>
Motivation: 研究嵌入星系环境的超大质量黑洞的引力响应，特别是暗物质晕对黑洞扰动谱的影响。Dehnen型暗物质晕提供了一个简单解析模型来模拟星系环境中的黑洞。

Method: 使用WKB方法计算轴向"上"和"下"扰动的准正规模谱，并通过时域积分验证结果。通过标准散射边界条件和WKB方法提取灰体因子和吸收截面。

Result: 两个扰动扇区不再等谱，偏差随晕尺度参数增大而增加。灰体因子和吸收截面的行为与有效势结构一致。暗物质晕印记会修改引力响应，但Price定律衰减与真空史瓦西黑洞相同。

Conclusion: 暗物质晕印记会诱导引力响应的修改，但采用的近似方案对于定量预测仍然足够准确。在渐近晚期，晕的存在不会改变Price定律衰减。

Abstract: We investigate gravitational perturbations, quasinormal modes, grey-body factors, and absorption cross-sections of the recently proposed regular and asymptotically flat black hole supported by a Dehnen-type dark-matter halo. This geometry provides a remarkably simple analytic model of supermassive black holes embedded in galactic environments, having a lapse function $
f(r)=1-2 M r^{2}/(r+a)^{3}, $
[R. A. Konoplya, A. Zhidenko, 2511.03066]. The regularizing parameter $a$ is the characteristic scale of the halo. We compute the quasinormal spectrum for both axial "up" and "down" perturbations using the WKB method and verify the results through time-domain integration. The two sectors are no longer isospectral, and the deviations grow with the halo scale parameter. The grey-body factors and absorption cross-sections are extracted via standard scattering boundary conditions and the WKB approach, and their behaviour is fully consistent with the structure of the effective potentials. Altogether, our analysis demonstrates that a dark-matter halo imprint induces modifications in the gravitational response, while the employed approximation schemes remain sufficiently accurate for quantitative predictions. At asymptotically late times, the presence of the halo does not alter the Price-law decay, which remains identical to that of a Schwarzschild black hole in vacuum.

</details>


### [15] [Minimum spacetime length and the thermodynamics of spacetime](https://arxiv.org/abs/2511.22403)
*Valeria Rossi,Sergio Luigi Cacciatori,Alessandro Pesci*

Main category: gr-qc

TL;DR: 该综述探讨了涌现引力理论，阐述了熵与时空几何的深刻联系，展示了引力如何从微观时空离散结构及其信息内容中统计性地涌现。


<details>
  <summary>Details</summary>
Motivation: 建立熵与时空几何之间的深层联系，从热力学角度理解引力，展示引力如何从微观时空的离散结构和信息内容中涌现出来。

Method: 首先概述量子引力理论如何暗示时空存在最小长度；然后通过双张量量子度量q_{αβ}(x,x')实现这种结构，该度量在重合极限x→x'时给出有限的测地线距离；最后讨论这些微观自由度的熵如何通过热力学变分原理产生引力场方程。

Result: 建立了从微观时空离散结构到宏观引力现象的完整理论框架，展示了如何通过热力学原理从熵的角度推导引力场方程。

Conclusion: 涌现引力理论成功地将引力解释为从微观时空结构和信息内容中统计涌现的现象，通过热力学原理统一了熵、几何和引力，为理解引力的本质提供了新的视角。

Abstract: Theories of emergent gravity have established a deep connection between entropy and the geometry of spacetime by looking at the latter through a thermodynamic lens. In this framework, the macroscopic properties of gravity arise in a statistical way from an effective small scale discrete structure of spacetime and its information content. In this review we begin by outlining how theories of quantum gravity imply the existence of a minimum length of spacetime as a general feature. We then describe how such a structure can be implemented in a way that is independent from the details of the quantum fluctuations of spacetime via a bi-tensorial quantum metric $q_{αβ}(x, x')$ that yields a finite geodesic distance in the coincidence limit $x\rightarrow x'$. Finally, we discuss how the entropy encoded by these microscopic degrees of freedom can give rise to the field equations for gravity through a thermodynamic variational principle.

</details>


### [16] [Multipole moments do not uniquely characterise spacetimes beyond general relativity](https://arxiv.org/abs/2511.22405)
*Arthur G. Suvorov,George Pappas*

Main category: gr-qc

TL;DR: 在广义相对论中，时空可以唯一分解为一组多极矩，但在超越爱因斯坦的引力理论中，这种唯一性不一定成立——不同理论中的两个不同天体可以具有相同的Geroch-Hansen矩，而两个匹配的度规却可以有不同的矩。


<details>
  <summary>Details</summary>
Motivation: 多极矩在分类辐射模式、潮汐形变等与致密天体相关的现象中非常有用，许多研究探索了在超越爱因斯坦引力理论中构建多极矩的方法。本文旨在检验这种矩分解的唯一性是否在不同理论中仍然成立。

Method: 通过比较不同引力理论中的几个静态球对称解，分析它们的Geroch-Hansen矩特性。具体比较了不同理论中具有相同多极矩的不同天体，以及度规匹配但多极矩不同的情况。

Result: 发现唯一性不一定在不同理论间扩展：两个不同的天体可以具有相同的Geroch-Hansen矩，而两个匹配的度规却可以有不同的矩。这表明多极矩在不同引力理论中可能不是唯一的描述符。

Conclusion: 这一结果对基于矩计算的黑洞阴影和"普适"关系具有重要意义，表明在超越爱因斯坦的引力理论中，多极矩可能无法唯一确定时空几何，需要重新评估依赖矩计算的物理推断。

Abstract: Spacetimes in general relativity can be uniquely decomposed into a set of multipole moments. Given the usefulness of moments in the categorisation of radiation patterns, tidal deformations, and other phenomena associated with compact objects, a number of studies have explored their construction in beyond-Einstein theories of gravity. It is shown here that uniqueness does not necessarily extend across theories: by comparing a few static and spherically-symmetric solutions in different theories, we find that two distinct objects can possess the same Geroch-Hansen moments. Moreover, two metrics can match and yet take different moments. Implications of this result are explored in the context of black-hole shadows and ``universal'' relations hinging on moment computations.

</details>


### [17] [Thermodynamics and Bouncing Cosmology in Rastall-like Gravity](https://arxiv.org/abs/2511.22501)
*José A. C. Nogales,K. Luz-Burgoa,Laysa G. Martins*

Main category: gr-qc

TL;DR: 本文研究了修正版Rastall引力理论的热力学方面及其宇宙学意义，分析了非守恒能量-动量张量方程的作用，并探讨了它们在不可逆热力学框架下对粒子产生的影响。通过引入新拉格朗日量，推导了修正场方程，建立了与物质产生的关系，提出了避免大爆炸奇点的反弹宇宙模型。


<details>
  <summary>Details</summary>
Motivation: 研究修正版Rastall引力理论的热力学特性，探索非守恒能量-动量张量在宇宙学中的作用，特别是粒子产生过程。旨在建立一种能够避免大爆炸奇点的替代宇宙模型，为物质产生提供一致的理论框架。

Method: 引入新的拉格朗日量推导修正场方程，分析非守恒能量-动量张量方程。在不可逆热力学框架下研究粒子产生过程，考虑有熵和无熵生成两种情况。采用理想流体模型，扩展到空间平坦的LFRW宇宙学，建立控制能量密度、压力和曲率动力学的关键方程。

Result: 推导出修正场方程及其与物质产生的关系。提出了一个可行的反弹宇宙模型，宇宙经历收缩和膨胀的循环，避免了大爆炸奇点。发现反弹点附近能量条件的违反支持了该模型的内部一致性。粒子产生过程和稳定性条件为Rastall类引力框架下的反弹场景提供了支持。

Conclusion: 所提出的理论为物质产生提供了连贯的现象学方法，并为非标准宇宙演化提供了新见解。该模型在理论基础上具有内部一致性，反弹宇宙场景在Rastall类引力框架下是可行的。观测意义将在未来研究中探讨。

Abstract: In this study, we explore the thermodynamic aspects of a modified version of Rastall's gravity theory and its implications for cosmological scenarios. We analyze the role of non-conserved energy-momentum tensor equations and investigate their influence on particle production within an irreversible thermodynamic framework. By introducing a novel Lagrangian, we derive modified field equations and establish their relationship with matter production, both with and without entropy generation. Our analysis focuses on ideal fluid models and extends to spatially flat LFRW cosmologies, providing key equations that govern energy density, pressure, and curvature dynamics. Furthermore, we propose a bouncing cosmological model, in which the universe undergoes cycles of contraction and expansion, avoiding the singularity associated with the Big Bang. Our results indicate that this bouncing scenario is feasible within the Rastall-like gravity framework, supported by particle production processes and stability conditions. The violation of energy conditions near the bounce point further confirms the consistency of this alternative cosmological model. The present work is focused on the theoretical foundations and internal consistency of the model; possible observational implications will be addressed in future investigations. We conclude that the proposed theory offers a coherent phenomenological approach to matter production and provides new insights into non-standard cosmological evolution.

</details>


### [18] [A Universal Smarr Formula via Coupling Constants](https://arxiv.org/abs/2511.22558)
*Kamal Hajian,Bayram Tekin,Onur Ucanok*

Main category: gr-qc

TL;DR: 提出一个通用框架，将所有维度耦合参数（如宇宙学常数、高阶导数项系数）提升为黑洞解的自由变化参数，通过引入辅助标量和规范场，使这些参数作为守恒荷出现，从而扩展黑洞热力学第一定律和Smarr公式。


<details>
  <summary>Details</summary>
Motivation: 在包含物质场和高阶导数修正的引力理论中，标准的Smarr公式常常失效，除非所有维度耦合参数被一致地纳入。传统上，宇宙学常数或高阶导数项系数等参数被视为理论的固定特征，因此被排除在热力学相空间之外。

Method: 为每个耦合参数引入辅助标量场和规范场，通过这些场使耦合参数作为与涌现规范对称性的全局部分相关的守恒荷出现。相应的共轭变量自然地作为黑洞视界处评估的电势出现。

Result: 热力学第一定律和Smarr关系获得了额外的、系统确定的贡献，产生了黑洞热力学的一致且普遍的扩展。重新审视文献中即使将宇宙学常数视为热力学变量后Smarr公式仍然不一致的几个黑洞例子，验证了该构造的有效性。

Conclusion: 只有以这种广义方式包含所有维度耦合参数，才能获得内部一致的Smarr关系，从而为黑洞热力学的真正普遍表述奠定基础。

Abstract: In gravitational theories containing matter fields and higher-derivative corrections, the standard Smarr formula often fails unless all dimensionful couplings are incorporated consistently. Traditionally, parameters such as the cosmological constant or the coefficients of higher-derivative terms are regarded as immutable features of the theory and therefore excluded from the thermodynamic phase space. In our recent work, we developed a fully general framework that promotes every such coupling to a dynamical, freely varying parameter of black hole solutions. This is accomplished by introducing, for each coupling, an auxiliary scalar and gauge field, through which the coupling appears as a conserved charge associated with the global sector of an emergent gauge symmetry. The corresponding conjugate variables naturally arise as electric potentials evaluated at the black hole horizon. As a result, the first law and the Smarr relation acquire additional, systematically determined contributions, yielding a consistent and universal extension of black hole thermodynamics. We illustrate the validity of this construction by revisiting several black hole examples in the literature where the Smarr formula remains inconsistent even after treating the cosmological constant as a thermodynamic variable. Our analysis shows that only by including all dimensionful couplings in this generalized manner can one obtain an internally consistent Smarr relation, thereby providing the foundation for a truly universal formulation of black hole thermodynamics.

</details>


### [19] [Electromagnetic radiation from circular orbits in Schwarzschild--de Sitter spacetime](https://arxiv.org/abs/2511.22611)
*João P. B. Brito,Rafael P. Bernar,Luís C. B. Crispino*

Main category: gr-qc

TL;DR: 研究带电粒子在四维Schwarzschild-de Sitter黑洞轨道上运动时发出的电磁辐射，采用半经典方法计算光子发射概率幅，推导辐射功率和频谱分布，并与标量场结果对比。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞背景下带电粒子的电磁辐射特性，特别是Schwarzschild-de Sitter时空中的辐射行为，并与标量场辐射进行对比，探索不同耦合方式对辐射特性的影响。

Method: 采用半经典方法计算带电粒子发射光子的概率幅，推导辐射功率和频谱分布。将结果与标量场（最小耦合和共形耦合）以及Schwarzschild时空中的电磁情况进行比较。

Result: 对于低角速度轨道，总电磁功率约为共形耦合标量场的两倍（与Schwarzschild情况类似）；对于最小耦合，标量功率甚至可能超过电磁功率。电磁情况具有更宽的频谱，且低多极子贡献不可忽略。

Conclusion: Schwarzschild-de Sitter黑洞背景下带电粒子的电磁辐射特性与标量场存在显著差异，特别是在不同耦合方式和轨道参数下。电磁辐射具有更宽的频谱分布，这对理解黑洞附近带电粒子的辐射过程具有重要意义。

Abstract: We investigate the electromagnetic radiation emitted by a charged particle orbiting a four-dimensional Schwarzschild--de Sitter black hole using a semiclassical approach. We calculate the probability amplitude for the charged particle to emit a photon, from which we derive the emitted power and spectral distributions. The results are compared with those obtained for scalar fields, considering both minimal and nonminimal coupling, as well as the corresponding electromagnetic case in the Schwarzschild spacetime. It is found that the total electromagnetic power is approximately twice that of the scalar field with conformal coupling for orbits with low angular velocity, similar to the Schwarzschild case, whereas for minimal coupling, the scalar power can even exceed the electromagnetic power. We also investigate the spectral distributions and possible synchrotron emission by orbits near the photon sphere. The electromagnetic case has a much broader frequency spectrum, with a non-negligible lower multipole contribution.

</details>


### [20] [Echoes of Traversable Wormhole](https://arxiv.org/abs/2511.22671)
*Rajdeep Mondal,Abhishake Sadhukhan*

Main category: gr-qc

TL;DR: 研究Maldacena-Milekhin-Popov虫洞的线性标量扰动，发现虫洞喉部形成共振腔，产生明显的回波信号，且高角动量模式回波更强。


<details>
  <summary>Details</summary>
Motivation: 研究可穿越虫洞的线性标量扰动特性，特别是虫洞几何结构如何影响波动力学和产生可观测的回波信号。

Method: 推导有效标量势能，使用时域积分分析虫洞对初始标量波包的响应，研究不同角动量数l下的回波特性。

Result: 虫洞喉部形成两个尖锐分离的势垒构成共振腔，晚期信号包含明显的回波序列，高角动量模式产生更强的回波。

Conclusion: 虫洞的几何结构导致独特的波动力学行为，产生可观测的回波信号，这为探测虫洞提供了可能的特征信号。

Abstract: We study linear scalar perturbations of the four-dimensional, traversable wormhole solution of Maldacena, Milekhin, and Popov(arXiv:1807.04726). The geometry is constructed by matching an asymptotically flat, near-extremal Reissner--Nordström region to a throat described by $AdS_2 \times S^2$, supported by charged massless fermions. We derive the effective scalar potential governing wave dynamics, which when viewed in the tortoise coordinate, exhibits two extremely sharp and widely separated barriers. These barriers form a resonant cavity and are a direct consequence of the near-horizon geometry of the wormhole mouths. Using time-domain integration, we analyze the wormhole's response to an initial scalar wave packet inside the throat. We find that the late-time signal contains a distinct train of echoes whose amplitude depends on the angular momentum number $l$. We show that higher $l$ modes produce significantly stronger echoes, as the corresponding potential barriers are taller and more reflective, which results in more efficient trapping of the wave within the wormhole throat.

</details>


### [21] [Asymptotics and Universality in Black Holes: from the quasinormal Weyl's law to the binary merger waveform](https://arxiv.org/abs/2511.22722)
*José Luis Jaramillo,Lamis Al Sheikh,Jérémy Besson,Badri Krishnan,Michele Lenzi,Rodrigo Panosso Macedo,Oscar Meneses-Rojas,Bernard Raffaelli,Carlos F. Sopuerta,Corentin Vitel*

Main category: gr-qc

TL;DR: 论文提出采用"渐近推理"方法研究黑洞动力学中的普遍性模式，通过过滤非必要自由度揭示结构稳定性机制，并应用于准正规模计数函数和黑洞并合动力学。


<details>
  <summary>Details</summary>
Motivation: 尽管现有黑洞动力学方法在定量控制方面表现优异，但在理解某些观测现象的机制方面存在盲点，特别是关于黑洞时空中的简单性和普遍性模式。需要新方法来揭示这些现象背后的结构稳定性机制。

Method: 采用"渐近推理"方法，通过过滤非必要自由度来识别关键的结构稳定性机制。具体应用包括：1) 建立黑洞准正规模的Weyl定律，分析计数函数的普遍渐近行为；2) 提出层次化的渐近模型框架来研究黑洞并合动力学，可能与引力可积性理论建立联系。

Result: 通过准正规模Weyl定律识别了光捕获和局部红移效应作为底层机制，为黑洞准正规模谱不稳定性中的普遍模式提供了桥梁。Weyl定律的普遍性形式为观测时空有效维度提供了可能。提出了研究黑洞并合动力学中简单性和普遍性模式的渐近推理框架。

Conclusion: 渐近推理方法能够有效揭示黑洞动力学中的普遍性模式，通过识别关键的结构稳定性机制来理解观测现象。该方法为研究黑洞准正规模和并合动力学提供了新视角，并可能通过可积性理论建立更深入的联系。

Abstract: Current state-of-the-art approaches to black hole (BH) dynamics, encompassing several effective approximation schemes, offer a remarkable control of the quantitative aspects of strong gravity. They also provide key insights into some qualitative aspects of the problem. In spite of this, there remain blind spots that hinder the understanding of the mechanisms underlying some observed phenomena, in particular concerning simplicity and universality in BH spacetimes. Adopting an 'asymptotic reasoning' approach, by filtering non-essential degrees of freedom, can potentially unveil universality patterns by identifying key underlying structural stability mechanisms. We first illustrate such an asymptotic approach by focusing on a BH quasinormal (QNM) Weyl's law, that accounts for the universal asymptotics of the QNM "counting function". This permits to identify light-trapping and the (local) redshift effect as the underlying mechanisms, also offering a bridge to the universal patterns found in BH QNM spectral instability. As a by-product, Weyl's law universality formally opens an observational access to spacetime (effective) dimensionality. More heuristically, we sketch a program recently put forward to apply such 'asymptotic reasoning' to address the observed simplicity and universality patterns in binary BH merger dynamics. This program is built as a hierarchy of asymptotic models, potentially making contact with integrability theory in gravity, namely through the background sector in a "wave-mean flow" approach to BH binary dynamics.

</details>


### [22] [Inflation, black holes with primary hair, and regular planar black holes from an infinite tower of regularized Lovelock-Proca corrections](https://arxiv.org/abs/2511.22798)
*Pedro G. S. Fernandes,Jingqian Gou,Lavinia Heisenberg,Nadine Nussbaumer*

Main category: gr-qc

TL;DR: 无限高阶Proca修正塔取代广义相对论奇点，实现宇宙大爆炸奇点被暴胀时期替代，并允许规则平面黑洞解和带主毛发的球对称黑洞


<details>
  <summary>Details</summary>
Motivation: 解决广义相对论中早期宇宙学和黑洞的奇点问题，通过无限高阶修正塔机制来正则化这些奇点

Method: 采用受Lovelock不变量维度正则化启发的无限高阶Proca修正塔，构建修正的引力理论

Result: 1. 广义相对论中的大爆炸奇点被暴胀时期取代；2. 允许存在规则的平面黑洞解；3. 允许存在带主毛发的球对称黑洞

Conclusion: 无限高阶Proca修正塔是解决引力奇点问题的有效机制，能够正则化宇宙学和黑洞中的奇点，为奇点问题提供了新的解决方案

Abstract: Infinite towers of higher-order corrections to General Relativity have been proposed as a mechanism to resolve singularities in early-universe cosmology and black holes, in a variety of settings. In this work, we consider an infinite tower of higher-order Proca corrections inspired by dimensional regularizations of Lovelock invariants. We find that the Big Bang singularity present in General Relativity is replaced by an inflationary epoch. Furthermore, the Lovelock-Proca tower allows for regular planar black hole solutions and spherically symmetric black holes with primary hair.

</details>


### [23] [A New Approach to the Calculation of Particle Creation from Analog Black Holes](https://arxiv.org/abs/2511.22895)
*Yang-Shuo Hsiung,Pisin Chen*

Main category: gr-qc

TL;DR: 提出惯性替代方法(IRM)计算加速镜面粒子产生的Bogoliubov系数，用于模拟AnaBHEL等霍金辐射实验


<details>
  <summary>Details</summary>
Motivation: 实际实验设置中的加速镜面轨迹使得Bogoliubov积分在解析上难以处理，需要开发混合解析-数值方法来准确预测粒子产生

Method: 惯性替代方法(IRM)：用解析惯性延伸替换轨迹的渐近惯性部分，仅对有限加速段进行数值评估，推导了完美和非完美反射镜的误差界限

Result: 验证了方法在解析可解轨迹上的有效性，应用于AnaBHEL实验相关的等离子体镜面轨迹，发现辐射谱几乎完全由有限加速区域决定

Conclusion: IRM为模拟实际类比引力系统（如AnaBHEL）中的粒子产生提供了可靠且广泛适用的计算工具

Abstract: Accurate prediction of particle creation from accelerating mirrors is crucial for interpreting forthcoming analog Hawking radiation experiments such as AnaBHEL. However, realistic experimental setups render the associated Bogoliubov integrals analytically intractable. To address this challenge, we introduce the Inertial Replacement Method (IRM), a hybrid analytic-numerical framework for computing Bogoliubov coefficients for general moving-mirror trajectories. The IRM replaces the asymptotically inertial portions of a trajectory with analytic inertial extensions, so that numerical evaluation is required only for the finite accelerating segment. We derive perturbative error bounds for both perfectly and imperfectly reflecting mirrors, providing controlled accuracy estimates and guiding the choice of segmentation thresholds. The method is validated against analytically solvable trajectories and then applied to a fully numerical, PIC-based Chen-Mourou plasma-mirror trajectory relevant to the planned AnaBHEL experiment. A key physical insight emerging from this analysis is that the radiation spectrum is determined almost entirely by the finite accelerating region, with negligible sensitivity to the far-past and far-future inertial motion. These results establish the IRM as a reliable and broadly applicable computational tool for modeling particle creation in realistic analog-gravity systems such as AnaBHEL.

</details>


### [24] [Strong-field Gravitational Wave Lensing in the Kerr Background](https://arxiv.org/abs/2511.23110)
*M. V. S. Saketh,Rajes Ghosh,Anuj Mishra*

Main category: gr-qc

TL;DR: 首次系统分析克尔黑洞对引力波的强场波光学透镜效应，发现自旋会特征性改变透镜波形，高频辐射不会被黑洞强烈吸收，与先前研究结论不同。


<details>
  <summary>Details</summary>
Motivation: 现有引力波透镜研究大多局限于小偏折弱场区域，需要填补强场波光学透镜的空白，特别是考虑天体物理中更相关的自旋透镜情况。

Method: 使用Mano-Suzuki-Takasugi形式体系计算强场散射因子，推导一般源-透镜-观测者配置下的观测波形表达式，分析克尔黑洞对引力波的散射效应。

Result: 自旋会产生特征性透镜波形修改，高频入射辐射不会被黑洞强烈吸收；对于GW150914类源被克尔黑洞透镜的情况，在30°散射角附近出现百分比级别的波形偏差；失配在固定散射角下对黑洞自旋依赖较弱。

Conclusion: 该框架为克尔时空中的强场引力波散射提供了统一处理方法，为未来波光学区域高精度观测致密天体透镜提供了分析工具。

Abstract: Gravitational lensing of gravitational waves (GWs) can encode valuable information about the properties of the intervening lens, yet most existing studies remain restricted to the small-deflection, weak-field regime. To bridge this crucial gap, this work presents the first systematic analysis of strong-field, wave-optical GW lensing by a Kerr black hole (BH), extending recent results for non-rotating lenses obtained in Chan et al. to the astrophysically more relevant case of spinning lens. Using the Mano-Suzuki-Takasugi formalism, we compute the strong-field scattering factor (SFSF) and show that the the spin produces characteristic modifications to the lensed waveform, and high-frequency incident radiation is not strongly absorbed by the BH lens, contrary to earlier claims in Chan et al. We further derive an explicit expression for the observed waveform for the general source-lens-observer configuration, showcasing the distortions produced by the scattering and quantifying their departure from the Schwarzschild case. Specializing to on-axis scattering, a mismatch analysis for a \texttt{GW150914}-like source lensed by a Kerr BH of mass $M=10^2M_\odot$ situated $100GM/c^2$ away from the source reveals percentage-level deviations from the direct (unscattered) wave at scattering angles near $30^\circ$, across a range of lens spin values. The mismatch exhibits a sharp decrease at larger scattering angles. For a fixed scattering angle, however, the mismatch shows only a weak dependence on the BH spin in the case of on-axis scattering, which may improve for more general off-axis considerations. The framework developed here offers a unified treatment of strong-field GW scattering in Kerr spacetime and provides tools for interpreting future high-precision observations of compact-object lenses in the wave-optics regime.

</details>


### [25] [Probing Observable Features of Lorentz violation in Low-Energy Hořava Gravity with Accretion Disk Images of Black Hole](https://arxiv.org/abs/2511.23117)
*Meng-Die Zhao,Yu-Yan Wang,Ke-Jian He,Guo-Ping Li*

Main category: gr-qc

TL;DR: 研究低能Horava引力中洛伦兹破坏效应在旋转黑洞图像和偏振特征中的可观测信号，发现洛伦兹破坏参数l显著影响内阴影形状、亮度不对称性和偏振模式。


<details>
  <summary>Details</summary>
Motivation: 探索洛伦兹破坏效应在黑洞观测中的可检测特征，为未来高分辨率事件视界望远镜观测提供理论预测和测试方法。

Method: 采用反向光线追踪方法，在薄盘吸积模型和ZAMO框架下，数值求解光子测地线方程，模拟旋转洛伦兹破坏黑洞的图像和偏振模式。

Result: 洛伦兹破坏参数l强烈影响内阴影形状（l减小导致更椭圆、不倾斜的内阴影，l增大产生明显的左向D形临界曲线）、亮度不对称性、偏振强度和方向分布，且l的正负决定洛伦兹破坏效应的趋势方向。

Conclusion: 未来高分辨率事件视界望远镜观测结合薄盘图像和偏振模式可为洛伦兹破坏效应提供有价值的测试。

Abstract: In this paper, we study the observable signatures of Lorentz violation (LV) in low-energy Horava gravity by simulating the images and polarization features of rotating LV black holes using a backward ray-tracing method. Within a thin-disk accretion model and the ZAMO framework, we numerically solve the geodesics equation of photon and simulate the corresponding thin-disk images and polarization patterns. The results show that the LV parameter l strongly affects the inner shadow, brightness asymmetry, and polarization properties of the thin disk. The decrease of l leads to a more elliptical and untilted inner shadow, while increasing l produces a pronounced leftward D-shaped structure of the critical curve. In addition, the variation of l alters the distribution of polarized intensity and polarization direction, especially near the critical curve. Moreover, it also shows that a positive l enhances the black hole's angular velocity, while a negative one suppresses it, indicating that the sign of l determines the trend direction of the LV effect. These findings suggest that future high-resolution EHT observations combining the thin-disk images and polarization patterns could provide valuable tests of the LV effect.

</details>


### [26] [Internal structure of Hayward black holes](https://arxiv.org/abs/2511.23165)
*Caiying Shao,Jun-Qi Guo,Yu Tian,Hongbao Zhang*

Main category: gr-qc

TL;DR: 研究Hayward时空中标量场塌缩，发现弱扰动下内视界保持稳定，强扰动下内视界收缩至零并形成类奇点，标量场强度控制内视界收缩动力学，存在临界指数γ≈0.5的标度行为。


<details>
  <summary>Details</summary>
Motivation: 正则黑洞（如Hayward黑洞）具有事件视界和柯西视界，但柯西视界的稳定性存在基本问题。本研究旨在探究Hayward时空中标量场塌缩对内视界稳定性的影响。

Method: 在Hayward时空中研究标量场塌缩，分析弱标量扰动和强标量场两种情况，通过初始剖面参数p控制标量场强度，研究内视界半径r-的动力学行为。

Result: 弱标量扰动下内视界保持稳定有限半径；强标量场下内视界收缩至零体积，形成类空间奇点，Hayward几何有效转化为Schwarzschild-like几何。内视界半径r-在参数p接近临界阈值p*时表现出标度行为：r-∝|p-p*|^γ，临界指数γ≈0.5。

Conclusion: 标量场强度决定Hayward黑洞内视界的稳定性：弱扰动下稳定，强扰动下收缩并形成奇点，存在临界相变行为，临界指数约为0.5，揭示了正则黑洞几何结构对物质扰动的响应机制。

Abstract: Regular black holes, free of central singularities, provide an ideal laboratory for probing the geometric structure of spacetime. The global structure of some regular black holes, e.g. Hayward black hole, features an event horizon and a Cauchy horizon, raising fundamental questions about the latter's stability. In this work, we investigate collapse of a scalar field in Hayward spacetime. Under weak scalar perturbations, the inner horizon maintains a stable finite radius. In the circumstance of a strong scalar field, the inner horizon shrinks to zero volume, accompanied by the formation of a spacelike singularity. The Hayward geometry is effectively converted into a Schwarzschild-like geometry. Furthermore, the strength of the scalar field governs the contraction dynamics of the inner horizon. As the parameter $p$ of the initial profile for the scalar field approaches the critical threshold ${p_*}$, the radius of the inner horizon ${r_{-}}$ exhibits a universal scaling behavior: ${r_{-}}\propto{|p - {p_*}|^γ}$, with a critical exponent $γ\approx 0.5$.

</details>


### [27] [Linear and nonlinear late-time tails on dynamical black hole spacetimes via time integrals](https://arxiv.org/abs/2511.23242)
*Dejan Gajic,Lionor Kehrberger*

Main category: gr-qc

TL;DR: 该论文证明了在动态黑洞外部背景上非齐次波动方程的全局主导阶晚期渐近行为，发现非球对称解的时间衰减比Price定律慢一个幂次。


<details>
  <summary>Details</summary>
Motivation: 研究动态黑洞外部背景上波动方程的晚期渐近行为，特别关注当背景趋于Schwarzschild背景时，解的衰减行为如何偏离经典的Price定律。

Method: 采用纯物理空间方法，基于能量估计，将动态波动算子视为Schwarzschild波动算子加上非齐次项。通过观察晚期"尾巴"与空间共形不规则性的关系，构造全局尾函数并分析解与尾函数的差异。

Result: 证明了对于非球对称解，晚期时间衰减比Price定律慢一个幂次。该方法可应用于非线性波动方程，并适用于更一般的动态时空背景。

Conclusion: 动态黑洞背景下的波动方程晚期衰减行为与静态背景不同，非球对称解表现出更慢的衰减速率。该方法具有鲁棒性，可推广到更一般的时空背景。

Abstract: We prove the global leading-order late-time asymptotic behaviour of solutions to inhomogeneous wave equations on dynamical black hole exterior backgrounds that settle down to Schwarzschild backgrounds with arbitrarily small decay rates. In particular, we show that for non-spherically symmetric solutions arising from compactly supported initial data, the late-time decay deviates from Price's law -- governing the decay for stationary black hole backgrounds -- by exhibiting slower time decay by exactly one additional power.
  Our proof is based around the observation that the emergence of late-time "tails", featuring inverse-polynomial decay in time, is intimately connected to conformal irregularity properties in space (towards future null infinity) of time integrals of the solutions. This relationship is exploited through a purely physical-space approach based around energy estimates, in which the dynamical wave operator is treated as a Schwarzschild wave operator with an inhomogeneous term. Going from almost-sharp decay to global asymptotics is achieved by exploiting this relation for the difference between the solution and a carefully chosen global tail function.
  We further apply our method to several examples of nonlinear wave equations and comment on its robustness to more general settings, such as dynamical spacetimes converging to sub-extremal Kerr spacetimes and higher-dimensional wave operators with even or odd spacetime dimensions.

</details>


### [28] [Constructing allowed complex metrics from black holes](https://arxiv.org/abs/2511.23338)
*Oscar Loaiza-Brito,J. L. López-Picón,Octavio Obregón*

Main category: gr-qc

TL;DR: 论文使用微分同胚映射将黑洞度规与Kontsevich-Segal准则允许的复解连接，通过交换径向和时间坐标及复映射，推导出适用于量子场论的动态度规


<details>
  <summary>Details</summary>
Motivation: 探索黑洞度规与Kontsevich-Segal准则允许的复解之间的数学联系，为量子场论提供合适的动态度规框架

Method: 使用微分同胚映射，交换径向和时间坐标，应用复映射技术，将静态和旋转黑洞的内部映射到Kantowski-Sachs和特定Gowdy型宇宙学模型

Result: 成功推导出适用于量子场论的动态度规，展示了黑洞度规与复解之间的数学联系，并提供了Kontsevich-Segal准则适用时期的物理解释

Conclusion: 微分同胚映射为连接黑洞物理与量子场论提供了有效的数学框架，Kontsevich-Segal准则在特定时期成立，这为理解黑洞内部与宇宙学模型的关系提供了新视角

Abstract: We use diffeomorphic mappings to connect black hole metrics with complex solutions allowed by the Kontsevich-Segal criterion. By swapping radial and time-like coordinates and applying complex mappings, we derive dynamic metrics suitable for a Quantum Field Theory. This is shown for static and rotating black holes, mapping their interiors into the Kantowski-Sachs and a specific Gowdy-type cosmological model. We offer interpretations of the period during which the Kontsevich-Segal criterion holds.

</details>


### [29] [Multipartite entanglement features of primordial non-gaussianities](https://arxiv.org/abs/2511.23389)
*Alessio Belfiglio,Roberto Franzosi,Orlando Luongo*

Main category: gr-qc

TL;DR: 该论文研究了单场暴胀场景中立方非高斯扰动相关的纠缠特征，采用动量空间技术分析暴胀扰动模式的多体纠缠，使用纠缠距离量化量子关联，发现立方引力相互作用产生的量子关联远大于标准压缩贡献。


<details>
  <summary>Details</summary>
Motivation: 研究暴胀宇宙学中量子引力相互作用产生的纠缠特征，特别是立方非高斯扰动如何影响暴胀扰动模式的量子关联，探索这些量子关联对暴胀参数的依赖性。

Method: 采用标准动量空间技术分析共动曲率扰动的动力学，使用纠缠距离（基于Fubini-Study度量的几何解释）量化纠缠生成，在相互作用绘景中研究立方引力相互作用。

Result: 在连续极限下，位移变换产生的纠缠距离与量子态中的总激发数成正比，为任何与这些激发兼容的约化态的冯·诺依曼纠缠熵提供了上界；立方引力相互作用产生的量子关联通常远大于标准压缩贡献。

Conclusion: 暴胀参数（特别是暴胀能标和慢滚期间的e-折叠数）显著影响量子关联总量，立方非高斯扰动在暴胀宇宙学中产生重要的多体纠缠特征，这些关联对理解早期宇宙的量子性质具有重要意义。

Abstract: We discuss some entanglement features associated with cubic non-Gaussian perturbations in single-field inflationary scenarios. We adopt standard momentum-space techniques to show how multipartite entanglement arises for inflationary perturbation modes, focusing on the dynamics of the comoving curvature perturbation. In particular, we quantify entanglement generation via the recently proposed Entanglement Distance, which introduces a geometric interpretation of quantum correlations in terms of the Fubini-Study metric. In the continuum limit, we show that the Entanglement Distance arising from displacement transformations is proportional to the total number of excitations in the quantum state for cubic perturbations, thus providing an upper bound on the von Neumann entanglement entropy of any reduced state compatible with such excitations. Within the interaction picture, we further observe that the quantum correlations arising from cubic gravitational interactions are typically much larger than the standard squeezing contribution, in agreement with previous studies focusing on von Neumann entropy generation across the Hubble horizon. We further show how the inflationary parameters affect the total amount of such correlations, highlighting in particular their dependence on the inflationary energy scales and the number of e-foldings during slow-roll.

</details>


### [30] [Cosmology in generalized hybrid metric-Palatini with matter-geometry coupling](https://arxiv.org/abs/2511.23396)
*Reza Jalali,Shahab Shahidi,Mohammad Hossein Zhoolideh Haghighi*

Main category: gr-qc

TL;DR: 该论文研究了一类具有非最小物质-几何耦合的混合度规-Palatini引力理论的宇宙学意义，发现该理论可重写为双标量-张量引力形式，并通过观测数据验证其可作为ΛCDM模型的替代方案。


<details>
  <summary>Details</summary>
Motivation: 研究混合度规-Palatini引力理论在宇宙学中的应用，探索具有非最小物质-几何耦合的引力理论是否能替代标准ΛCDM模型，并解释宇宙加速膨胀现象。

Method: 将混合度规-Palatini引力理论重写为具有非最小耦合的双标量-张量引力形式，然后使用宇宙钟、DESI的BAO数据集和Pantheon+超新星数据集进行观测约束。

Result: 理论能够很好地拟合观测数据，可作为ΛCDM模型的替代方案，但重子物质守恒仅在背景水平成立。状态探测器分析显示暗能量行为在红移z≈0.86处发生从quintessence到phantom的转变。

Conclusion: 具有非最小物质-几何耦合的混合度规-Palatini引力理论是ΛCDM模型的一个有前景的替代方案，能够解释宇宙加速膨胀，但需要在扰动水平进一步研究物质守恒问题。

Abstract: Cosmological implications of a class of hybrid metric-Palatini gravity with a non-minimal matter-geometry coupling is considered. The theory contains a metric curvature tensor, together with a curvature tensor constructed from an independent affine connection. We will show that the model could be written as a bi-scalar-tensor gravity with a non-minimal coupling between matter sector and a scalar field. The theory will then be confronted with observational data from Cosmic Chronometers, BAO dataset from DESI and the Pantheon$^+$ dataset. We will show that the theory could be a good alternative to the $Λ$CDM model with the difference that the conservation of the baryonic matter sector holds only at the background level. The statefinder analysis will also be applied to the theory and it is observed that the DE behavior of the theory exhibits a quintessence to phantom transition occurs at redshifts around $z\approx0.86$.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [31] [Quantum Optimality in the Odd-Cycle game: the topological odd-blocker, marked connected components of the giant, consistency of pearls, vanishing homotopy](https://arxiv.org/abs/2511.21774)
*Pete Rigas*

Main category: quant-ph

TL;DR: 该论文分析了奇数环游戏量子策略的最优性，将并行重复与泡沫问题联系起来，通过表面面积最小化研究获胜概率与标记巨型连通分量的关系。


<details>
  <summary>Details</summary>
Motivation: 研究奇数环游戏中量子策略的最优性特征，探索并行重复与泡沫问题的联系，量化标记巨型连通分量性质与量子策略最大获胜概率之间的关系。

Method: 引入拓扑奇阻塞器、珍珠、一致区域和循环消除问题等新概念，利用表面面积最小化方法，将作者先前为其他量子游戏建立的误差界框架应用于奇数环游戏。

Result: 建立了标记巨型连通分量性质与量子策略最大获胜概率之间的量化关系，为奇数环游戏的并行重复分析提供了新的理论框架。

Conclusion: 奇数环游戏的量子策略最优性分析揭示了与泡沫问题的深刻联系，提出的新概念和方法为量子游戏理论提供了新的分析工具和视角。

Abstract: We characterize optimality of Quantum strategies for the Odd-Cycle game. Separate from other game-theoretic settings, parallel repetition for the Odd-Cycle game is related to the foam problem, which can be formulated through a minimization of the surface area. In comparison to previous works on minimizing the surface area, we quantify how properties of the marked giant connected component can be related to the maximum winning probability using Quantum strategies. Objects that we introduce to formulate such connections include the topological odd-blocker, previous examples of error bounds for other Quantum games that have been formulated by the author, pearls, consistent regions, and the cycle elimination problem.

</details>


### [32] [Higher-order nonclassicality criteria for photon-subtracted and photon-added states via the normalization constant](https://arxiv.org/abs/2511.21801)
*Jhordan Santiago*

Main category: quant-ph

TL;DR: 提出一种基于阶乘矩的非经典性判据计算方法，适用于光子减除和光子增加态，通过算符重排简化计算


<details>
  <summary>Details</summary>
Motivation: 传统上计算光子减除和光子增加态的非经典性判据（如Mandel Q参数、Lee反聚束函数等）较为复杂，需要简化计算方法

Method: 通过算符重排技术处理阶乘矩，使得所有相关量仅依赖于给定态的归一化常数

Result: 成功推导出光子减除和光子增加态的非经典性判据的简化计算公式，大大降低了计算复杂度

Conclusion: 该方法为分析光子操作态的非经典性质提供了高效的计算框架，适用于多种高阶参数的计算

Abstract: We show that any nonclassicality criterion based on factorial moments, including several higher-order parameters such as the Mandel $Q^{(\ell)}$ parameter, the Lee antibunching function $d^{(\ell-1)}_h$, and the Agarwal--Tara parameter $A_3$, can be computed straightforwardly for photon-subtracted and photon-added states by performing operator reordering of the factorial moments. Within this approach, all relevant quantities depend solely on the normalization constant of the given state.

</details>


### [33] [Testing Single Photon Entanglement using Self-Referential Measurements](https://arxiv.org/abs/2511.21819)
*Daniel Kun,Teodor Strömberg,Borivoje Dakić,Philip Walther,Lee A. Rozema*

Main category: quant-ph

TL;DR: 单光子贝尔不等式违反实验的新实现方法，通过同一单光子纠缠态的两个副本进行联合测量，避免了零差测量的复杂性


<details>
  <summary>Details</summary>
Motivation: 三十年前预测单光子通过分束器可违反贝尔不等式，虽然最终通过零差测量得以证实，但该方法复杂且可能存在漏洞。需要寻找更简单、更可靠的替代实现方案

Method: 使用同一单光子纠缠态的两个副本进行联合测量，其中一个光子作为另一个光子的相位参考，形成自参考系统。避免了零差测量的复杂性

Result: 观测到CHSH参数分别为2.71±0.09和2.23±0.07（取决于实施的联合测量类型），明显超过经典极限2，证实了单光子非定域性

Conclusion: 为单光子非定域性提供了新视角和更易实现的实验途径，该方法可推广到不同平台中的一般模式纠缠态

Abstract: Entanglement does not always require one particle per party. It was predicted some thirty years ago that a single photon traversing a beam splitter could violate a Bell inequality. Although initially debated, single-photon nonlocality was eventually demonstrated via homodyne measurements. Here, we present an alternate realisation that avoids the complexity of homodyne measurements and potential loopholes in their implementation. We violate a Bell inequality by performing joint measurements on two copies of the same single-photon entangled state, where one photon acts as a phase reference for the other, making it self-referential. We observe CHSH parameters of $2.71\pm 0.09$ and $2.23\pm 0.07$, depending on the joint measurements implemented. This offers a new perspective on single-photon nonlocality and a more accessible experimental route, potentially applicable to general mode-entangled states in diverse platforms.

</details>


### [34] [No need to calibrate: characterization and compilation for high-fidelity circuit execution using imperfect gates](https://arxiv.org/abs/2511.21831)
*Ashish Kakkar,Samuel Marsh,Yulun Wang,Pranav Mundada,Paul Coote,Gavin Hartnett,Michael J. Biercuk,Yuval Baum*

Main category: quant-ph

TL;DR: 提出一种新的两量子比特门集设计方法，通过快速表征少量门参数并在电路编译中跟踪校正，将传统视为误差的相干贡献作为门定义的一部分，用单量子比特旋转补偿，实现快速生成高保真度纠缠门并扩展门集。


<details>
  <summary>Details</summary>
Motivation: 传统量子计算硬件中两量子比特门的校准过程繁琐耗时，需要迭代精细校准。为了减少低层控制波形的精细调谐负担，提高门集扩展的实用性，需要一种硬件无关的快速表征和编译方法。

Method: 将相干误差贡献视为门定义的一部分，通过快速表征少量门参数，在电路编译中跟踪和校正这些参数。用单量子比特旋转补偿误差，将标准校准门与高保真度纠缠门结合扩展门集，并在量子编译器中合成通用两量子比特电路块为最小持续时间的门序列。

Result: 在127量子比特IBM硬件上，相比仅使用默认CX门的电路编译：量子傅里叶变换电路（最多26量子比特）成功率提高最多7倍；一维横向场伊辛模型的Trotter模拟均方误差降低最多9倍。

Conclusion: 该方法实现了硬件无关的表征和编译，使量子计算架构上扩展表达性门集变得实用，同时最小化低层控制波形精细调谐的需求，显著提升量子电路性能。

Abstract: We propose and validate on real quantum computing hardware a new method for extended two-qubit gate set design, replacing iterative, fine calibration with fast characterization of a small number of gate parameters which are then tracked and corrected in circuit compilation. Coherent contributions to the pulse unitary that would traditionally be considered sources of error are treated as part of the gate definition, and compensated in software via single-qubit rotations. This approach enables rapid device-wide generation of high-fidelity two-qubit entangling gates, which are combined with standard calibrated gates to produce an expanded gate set. We show how these gates are directly usable as part of a quantum compiler, synthesizing generic two-qubit circuit blocks into minimal-duration sequences of the characterized gates interleaved with compensating single-qubit rotations. Benchmarking against circuits compiled using the default $CX$ gate alone on 127-qubit IBM hardware shows up to 7X improvement in success probability for Quantum Fourier Transform circuits up to 26 qubits, and up to 9X lower mean-square error in Trotter simulations of the one-dimensional transverse-field Ising model. Our hardware-agnostic characterization and compilation methodology makes it practical to scale up expressive gate sets on quantum computing architectures while minimizing the need for onerous fine-tuning of low-level control waveforms.

</details>


### [35] [Measure and Forget Dynamics in Random Circuits](https://arxiv.org/abs/2511.21866)
*Yucheng He,Todd A. Brun*

Main category: quant-ph

TL;DR: 研究随机Clifford电路中部分遗忘测量结果时的测量诱导相变，发现局部热化率与系统尺寸无关，熵演化存在阈值现象，净化相变消失


<details>
  <summary>Details</summary>
Motivation: 研究"遗忘"测量（类似于退相干）在容错量子计算中的应用价值，以及探索纠缠和熵如何传播的基本物理问题

Method: 在随机Clifford电路中引入部分遗忘测量结果，研究测量诱导相变，数值计算熵图中的转折点衰减行为

Result: 发现局部热化率与系统尺寸无关；观察到熵达到阈值后停止演化的反直觉现象；识别出净化相变消失；这些发现挑战了先前关于噪声导致系统完全热化的直觉

Conclusion: 部分遗忘测量结果会改变纠缠动力学，影响量子纠错码的性能，为理解测量诱导相变和量子信息处理提供了新视角

Abstract: "Forgetful" measurements-physically similar to dephasing-are of interest both for applications to fault-tolerant quantum computing and fundamentally, in studying how entanglement and entropy spread. This paper investigates measurement-induced phase transitions (MIPT) in random Clifford circuits when measurement outcomes are partially forgotten. Our findings reveal a local thermalization rate that remains constant regardless of system size. We also numerically calculate the decay behavior at the turning points in the entropy diagram. We observe a counterintuitive phenomenon where the entropy reaches a threshold and stops evolving, even as the system size increases. This challenges an intuition, drawn from previous studies of noisy random circuits, that noise will cause the thermalization of the whole system. Additionally, we identify the disappearance of the purification transition and discuss the implications of these entanglement dynamics for quantum error-correction codes.

</details>


### [36] [Accuracy and resource advantages of quantum eigenvalue estimation with non-Hermitian transcorrelated electronic Hamiltonians](https://arxiv.org/abs/2511.21867)
*Alexey Uvarov,Artur F. Izmaylov*

Main category: quant-ph

TL;DR: 量子算法应用于非厄米特transcorrelated哈密顿量，相比传统方法在基组尺寸减小时获得更精确基态能量，T门数量相当但量子比特数减少2.5倍


<details>
  <summary>Details</summary>
Motivation: 电子结构计算中，transcorrelated方法通过将电子-电子关联直接纳入哈密顿量来减小基组尺寸，但产生的非厄米特性使许多传统量子算法不适用，需要研究非厄米哈密顿量量子算法的实际成本

Method: 应用近期提出的针对具有实谱的非厄米哈密顿量的量子本征值估计算法，将其应用于第二行原子的transcorrelated电子哈密顿量，并与应用于非transcorrelated哈密顿量的标准qubitization方法进行成本比较

Result: STO-6G基组中transcorrelated哈密顿量的基态能量比cc-pVQZ基组中标准哈密顿量的结果更精确；两种方法的T门数量相当，但transcorrelated方法的量子比特数减少了2.5倍

Conclusion: transcorrelated方法结合非厄米量子本征值估计算法，在保持计算精度的同时显著减少了量子资源需求，为电子结构计算提供了有前景的量子计算途径

Abstract: In electronic structure calculations, the transcorrelated method enables a reduction of the basis set size by incorporating the electron-electron correlations directly into the Hamiltonian. However, the transcorrelated Hamiltonian is non-Hermitian, which makes many common quantum algorithms inapplicable. Recently, a quantum eigenvalue estimation algorithm was proposed for non-Hermitian Hamiltonians with real spectra [FOCS 65, 1051 (2024)]. Here we investigate the cost of this algorithm applied to transcorrelated electronic Hamiltonians of second-row atoms and compare it to the cost of applying standard qubitization to non-transcorrelated Hamiltonians. We find that the ground state energy of the transcorrelated Hamiltonian in the STO-6G basis is more accurate than that of a standard Hamiltonian in the cc-pVQZ basis. The T gate counts of the two methods are comparable, while the qubit count of the transcorrelated method is 2.5 times smaller.

</details>


### [37] [Lattice Surgery Aware Resource Analysis for the Mapping and Scheduling of Quantum Circuits for Scalable Modular Architectures](https://arxiv.org/abs/2511.21885)
*Batuhan Keskin,Cameron Afradi,Sylvain Lovis,Maurizio Palesi,Pau Escofet,Carmen G. Almudever,Edoardo Charbon*

Main category: quant-ph

TL;DR: 提出一个用于分布式逻辑量子计算架构的框架，通过图分区和映射优化来最小化核心间通信和魔法状态路由开销


<details>
  <summary>Details</summary>
Motivation: 单核心量子计算面临保真度、串扰和功耗等问题，分布式核心架构是更有前景的替代方案，但需要优化核心间状态传输和魔法状态路由

Method: 开发一个框架：1) 将量子电路转换为CNOT、H、T、S和泡利门的通用门集；2) 使用KaHIP图分区器平衡分区量子比特；3) 将映射问题转化为带固定分配的二次分配问题，最小化核心间两量子门路由和魔法状态工厂的总传输距离；4) 使用调度算法安排门时序

Result: 框架报告详细的统计数据，包括经典通信次数、消耗的EPR对和魔法状态数量、核心间状态传输的前后处理时序开销，帮助量化分布式逻辑量子计算架构的经典和量子资源

Conclusion: 该框架为分布式逻辑量子计算架构提供了系统化的资源量化方法，通过优化核心间通信和魔法状态路由，有助于解决单核心架构面临的挑战

Abstract: Quantum computing platforms are evolving to a point where placing high numbers of qubits into a single core comes with certain difficulties such as fidelity, crosstalk, and high power consumption of dense classical electronics. Utilizing distributed cores, each hosting logical data qubits and logical ancillas connected via classical and quantum communication channels, offers a promising alternative. However, building such a system for logical qubits requires additional optimizations, such as minimizing the amount of state transfer between cores for inter-core two-qubit gates and optimizing the routing of magic states distilled in a magic state factory. In this work, we investigate such a system and its statistics in terms of classical and quantum resources. First, we restrict our quantum gate set to a universal gate set consisting of CNOT, H, T, S, and Pauli gates. We then developed a framework that can take any quantum circuit, transpile it to our gate set using Qiskit, and then partition the qubits using the KaHIP graph partitioner to balanced partitions. Afterwards, we built an algorithm to map these graphs onto the 2D mesh of quantum cores by converting the problem into a Quadratic Assignment Problem with Fixed Assignment (QAPFA) to minimize the routing of leftover two-qubit gates between cores and the total travel of magic states from the magic state factory. Following this stage, the gates are scheduled using an algorithm that takes care of the timing of the gate set. As a final stage, our framework reports detailed statistics such as the number of classical communications, the number of EPR pairs and magic states consumed, and timing overheads for pre- and post- processing for inter-core state transfers. These results help to quantify both classical and quantum resources that are used in distributed logical quantum computing architectures.

</details>


### [38] [Optimal Control for Rydberg multi-qubit operations](https://arxiv.org/abs/2511.22202)
*Hossein Abedi,Mohammadsadegh Khazali,Klaus Mølmer*

Main category: quant-ph

TL;DR: 利用量子最优控制技术设计单连续激光脉冲，在里德堡原子量子处理器上实现多量子比特受控相位门、非门和交换门，显著提高门操作速度并减少退相干


<details>
  <summary>Details</summary>
Motivation: 量子计算算法通常分解为基本的一、二量子比特门，但不同物理实现允许单步多量子比特条件动力学。利用量子最优控制技术设计高效多量子比特门，可减少操作时间和退相干，同时提供连续的环境噪声保护

Method: 采用量子最优控制技术设计单连续激光脉冲，在里德堡原子量子处理器上实现多量子比特受控相位门、受控非门和受控交换门（Fredkin门），考虑自发辐射、激光波动和多普勒退相等实际缺陷

Result: 受控交换门（Fredkin门）实现99.74%的保真度，同时考虑了自发辐射、激光波动和多普勒退相等实际缺陷。多量子比特操作减少了操作时间，降低了退相干，控制场提供连续的环境噪声保护

Conclusion: 量子最优控制技术可有效设计鲁棒的多量子比特门操作，显著提高里德堡原子量子处理器的门操作效率和保真度，为实际量子计算应用提供重要技术支撑

Abstract: Quantum computing algorithms can be decomposed into a universal set of elementary one- and two-qubit gates. Different physical implementations of quantum computing, however, employ interactions that permit direct conditional dynamics on multiple qubits in a single step. In this work, we leverage quantum optimal control techniques to design single continuous laser pulses that implement multi-qubit controlled-phase, -NOT and -swap (Fredkin) gates on Rydberg atom quantum processors. The identification of robust multi-qubit operations leads to reduced operation time and less decoherence, and the control field provides continuous protection of the atoms from environmental noise. Notably, we find that the controlled-swap (Fredkin) gate, implemented using this approach achieves 99.74\% fidelity while accounting for imperfections such as spontaneous emission, laser fluctuations, and Doppler dephasing.

</details>


### [39] [A scalable advantage in multi-photon quantum machine learning](https://arxiv.org/abs/2511.21951)
*Yong Wang,Zhenghao Yin,Tobias Haug,Ciro Pentangelo,Simone Piacentini,Andrea Crespi,Francesco Ceccarelli,Roberto Osellame,Philip Walther*

Main category: quant-ph

TL;DR: 光子量子机器学习在光子平台上展现可扩展优势，光子数增加能提升学习能力，实验验证了在线训练可行性。


<details>
  <summary>Details</summary>
Motivation: 光子具有高鲁棒性和室温下长相干时间，是量子信息技术的理想候选。虽然光子拥有适合计算的高维量子特征空间，但如何利用它进行学习任务仍缺乏一般性理解。

Method: 理论证明线性光学电路的学习能力随光子数多项式扩展，实验上在完全可编程光子集成平台上进行在线训练，执行酉学习和度量学习任务。

Result: 理论证明学习能力随光子数多项式扩展，能从更小的训练数据集中泛化并获得更低的测试损失值。实验验证了这些发现，展示了光子量子机器学习的潜力。

Conclusion: 这项工作突出了光子量子机器学习的潜力，为实现实际机器学习应用中的量子增强铺平了道路。

Abstract: Photons are promising candidates for quantum information technology due to their high robustness and long coherence time at room temperature. Inspired by the prosperous development of photonic computing techniques, recent research has turned attention to performing quantum machine learning on photonic platforms. Although photons possess a high-dimensional quantum feature space suitable for computation, a general understanding of how to harness it for learning tasks remains blank. Here, we establish both theoretically and experimentally a scalable advantage in quantum machine learning with multi-photon states. Firstly, we prove that the learning capacity of linear optical circuits scales polynomially with the photon number, enabling generalization from smaller training datasets and yielding lower test loss values. Moreover, we experimentally corroborate these findings through unitary learning and metric learning tasks, by performing online training on a fully programmable photonic integrated platform. Our work highlights the potential of photonic quantum machine learning and paves the way for achieving quantum enhancement in practical machine learning applications.

</details>


### [40] [Superradiant decay in non-Markovian Waveguide Quantum Electrodynamics](https://arxiv.org/abs/2511.22332)
*Rosa Lucia Capurso,Giuseppe Calajó,Simone Montangero,Saverio Pascazio,Francesco V. Pepe,Maria Maffei,Giuseppe Magnifico,Paolo Facchi*

Main category: quant-ph

TL;DR: 研究使用张量网络方法分析一维波导中激发发射体的非马尔可夫动力学，发现超辐射爆发会分解为结构化的相关光子序列，时间延迟可导致衰减速率超过马尔可夫近似预测


<details>
  <summary>Details</summary>
Motivation: 在玻恩-马尔可夫近似下，一维波导中的激发发射体会表现出超辐射衰减，但实际光子交换存在有限时间延迟，这会导致非马尔可夫动力学，需要深入研究其影响

Method: 采用张量网络方法研究由发射体间光子交换的有限时间延迟引起的非马尔可夫动力学，量化发射体-光子和发射体-发射体纠缠

Result: 超辐射爆发分解为结构化的相关光子序列，每个强度峰对应特定光子数；发射体-发射体纠缠在长时间极限下出现，部分激发被捕获在发射体的单重态子空间；时间延迟可导致对称Dicke态的衰减速率超过马尔可夫近似预测

Conclusion: 有限时间延迟显著改变波导量子电动力学系统的超辐射动力学，导致复杂的非马尔可夫效应，包括结构化光子发射和增强的衰减速率，这对量子信息处理和量子光学应用具有重要意义

Abstract: An array of initially excited emitters coupled to a one-dimensional waveguide exhibits superradiant decay under the Born-Markov approximation, manifested as a coherent burst of photons in the output field. In this work, we employ tensor-network methods to investigate its non-Markovian dynamics induced by finite time delays in photon exchange among the emitters. We find that the superradiant burst breaks into a structured train of correlated photons, each intensity peak corresponding to a specific photon number. We quantify the emitter-photon and emitter-emitter entanglement generated during this process and show that the latter emerges in the long-time limit, as part of the excitation becomes trapped within the emitters' singlet subspace. We finally consider the decay of the system's most radiant state, the symmetric Dicke state, and show that time delay can lead to decay rates exceeding those predicted by the Markovian approximation.

</details>


### [41] [Experimental signatures of a $σ_zσ_x$ beam-splitter interaction between a Kerr-cat and transmon qubit](https://arxiv.org/abs/2511.21972)
*Josiah Cochran,Haley M. Cole,Hebah Goderya,Zhuoqun Hao,Yao-Chun Chang,Theo Shaw,Aikaterini Kargioti,Shyam Shankar*

Main category: quant-ph

TL;DR: 实验展示了Kerr-cat qubit与transmon之间的beamsplitter相互作用，实现了σzσx耦合，可用于量子纠错中的奇偶校验测量。


<details>
  <summary>Details</summary>
Motivation: 量子纠错需要辅助量子比特来提取数据量子比特的错误综合征，但辅助量子比特的错误会传播回数据量子比特，引入额外错误并限制容错性。Kerr-cat qubits具有强偏置噪声特性，可作为辅助量子比特来抑制这种反向作用并提升量子纠错性能。

Method: 在超导量子电路中，实验演示了Kerr-cat qubit与transmon之间的beamsplitter相互作用，实现了有效的σzσx耦合，可用于量子纠错协议中的奇偶校验测量。在不同猫态大小和驱动幅度下表征了相互作用的缩放特性。

Result: 实验确认了相互作用速率的预期缩放关系，为将transmon作为数据量子比特与噪声偏置的玻色辅助量子比特相结合的混合架构奠定了基础。

Conclusion: 这项工作为实现硬件高效的综合征提取迈出了一步，推动了容错量子处理器的发展，展示了结合transmon数据量子比特与噪声偏置玻色辅助量子比特的混合架构潜力。

Abstract: Quantum error correction (QEC) requires ancilla qubits to extract error syndromes from data qubits which store quantum information. However, ancilla errors can propagate back to the data qubits, introducing additional errors and limiting fault-tolerance. In superconducting quantum circuits, Kerr-cat qubits (KCQs), which exhibit strongly biased noise, have been proposed as ancillas to suppress this back-action and enhance QEC performance. Here, we experimentally demonstrate a beamsplitter interaction between a KCQ and a transmon, realizing an effective $σ_zσ_x$ coupling that can be employed for parity measurements in QEC protocols. We characterize the interaction across a range of cat sizes and drive amplitudes, confirming the expected scaling of the interaction rate. These results establish a step towards hybrid architectures that combine transmons as data qubits with noise-biased bosonic ancillas, enabling hardware-efficient syndrome extraction and advancing the development of fault-tolerant quantum processors.

</details>


### [42] [Quantum Sensing using Geometrical Phase in Qubit-Oscillator Systems](https://arxiv.org/abs/2511.21983)
*Nishchay Suri,Zhihui Wang,Tanay Roy,Davide Venturelli,Wibe Albert de Jong*

Main category: quant-ph

TL;DR: 该论文提出了一种基于几何相位的量子传感协议，通过压缩放大振子相空间中的面积，突破了标准量子极限，适用于高温或逻辑纠错态，对量子比特马尔可夫噪声具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量子传感受限于标准量子极限，需要开发能够超越该极限、对噪声鲁棒且适用于实际实验条件（如高温或纠错态）的新传感方法。

Method: 利用耦合量子比特-振子系统的几何相位进行传感。信号编码在与振子相空间面积成正比的几何相位中，通过压缩放大该面积实现超标准量子极限的灵敏度。该方法不依赖于振子初始态，适用于高温或逻辑纠错态。

Result: 该方法实现了超越标准量子极限的灵敏度，对量子比特马尔可夫噪声具有鲁棒性，并保持了状态无关性。成功应用于纵向耦合系统的超标准量子极限力传感，以及在色散耦合cQED架构中实现超标准量子极限的耦合测量和脉冲校准。

Conclusion: 该几何相位传感协议为下一代量子计量学提供了实用方案，能够超越标准量子极限，对噪声鲁棒，适用于多种实验条件，在量子传感领域具有重要应用前景。

Abstract: We present a quantum sensing protocol for coupled qubit-oscillator systems that surpasses the standard quantum limit (SQL) by exploiting a geometrical phase. The signal is encoded in the geometrical phase that is proportional to the area enclosed in oscillator phase space. This area is amplified through squeezing, enabling sensitivities beyond the SQL. Our method is independent of oscillator's initial state, amenable to sensing with high-temperature or logical error-corrected states. The protocol shows robustness to qubit Markovian noise and preserves its state-independence, underscoring its practicality for next-generation quantum metrology. We demonstrate application to force sensing beyond the SQL in longitudinally coupled systems, and to high-precision measurements of couplings and pulse calibration surpassing SQL in dispersively coupled circuit quantum electrodynamics (cQED) architectures.

</details>


### [43] [Nonlinear Optical Quantum Communication with a Two-Dimensional Perovskite Light Source](https://arxiv.org/abs/2511.22060)
*Shuyue Feng,Zijian Gan,Camryn J. Gloor,Wei You,Andrew M. Moran*

Main category: quant-ph

TL;DR: 利用二维有机-无机杂化钙钛矿量子阱的非线性光学效应实现量子密钥分发，通过激子自旋动力学和双激子关联进行信息编码，成功传输56位ASCII信息。


<details>
  <summary>Details</summary>
Motivation: 二维有机-无机杂化钙钛矿量子阱因其能产生偏振编码光信号而成为量子通信的潜在光源。本研究旨在探索如何利用非线性光学现象进行量子信息应用，特别是利用激发态之间的共振耦合实现信息编码。

Method: 通过四波混频实验在飞秒时间尺度上追踪信号光子椭圆率变化，建立基于激子自旋动力学和双激子关联的信息编码方法。使用单光子检测实现BB84量子密钥分发协议，将偏振态映射到二进制序列。与传统方法不同，本方法利用2D-OIHP系统的本征电子结构和自旋弛豫过程决定信号光子特性。

Result: 成功通过2D-OIHP量子阱发射的光子偏振态传输了56位ASCII信息。实验表明信息传输效率强烈依赖于双激子态的贡献，证明了自旋依赖非线性光学过程在量子通信中的潜力。

Conclusion: 二维有机-无机杂化钙钛矿量子阱的非线性光学特性可用于量子密钥分发，其自旋依赖过程为量子通信提供了新途径。双激子态在信息传输中起关键作用，展示了这类材料在量子信息处理中的应用前景。

Abstract: Two-dimensional organic-inorganic hybrid perovskite (2D-OIHP) quantum wells are emerging as promising light sources for quantum communication technologies, owing to their ability to generate polarization-encoded optical signals. In this work, we explore how nonlinear optical phenomena can be exploited for quantum information applications, demonstrating the versatility that arises from resonant coupling among excited states. By tracking changes in the ellipticities of signal photons on femtosecond timescales in four-wave-mixing experiments, we first establish a method for information encoding based on exciton spin dynamics and biexciton correlations. Using single-photon detection, we then implement the BB84 quantum key distribution protocol by mapping these polarization states onto binary sequences. While the polarizations of weak coherent pulses are typically manipulated with optical elements in traditional quantum key distribution approaches, the intrinsic electronic structure and spin relaxation processes within the 2D-OIHP system determine the characteristics of the signal photons in our method. As a demonstration, an ASCII message consisting of 56 bits is transmitted through the polarization states of photons emitted by 2D-OIHP quantum wells. These results show that the information transmission efficiency depends strongly on contributions from biexciton states, highlighting the potential of spin-dependent nonlinear optical processes for quantum communication.

</details>


### [44] [Switchable Dissipative Ising coupling Based on Three-Body Coupling in magnon systems](https://arxiv.org/abs/2511.22068)
*Xi-Wen Dou,Zheng-Yang Zhou,Ai-Xi Chen*

Main category: quant-ph

TL;DR: 该论文提出了一种在磁振子系统中实现可切换耗散伊辛耦合的方法，利用光子、声子和磁振子的三体耦合，为构建解决组合优化问题的伊辛机提供关键组件。


<details>
  <summary>Details</summary>
Motivation: 磁振子系统因其通过多种耦合形成混合量子系统的强大能力而成为量子技术的理想平台。为了充分发挥这些系统的潜力，需要在多个磁振子模式之间实现灵活的耦合工程。

Method: 通过光子、声子和磁振子的三体耦合实现可切换耗散伊辛耦合。通过动态调谐非线性机械泵浦的相位，实现了铁磁和反铁磁耗散相互作用。

Result: 数值模拟验证了该方案的有效性，并证明其对强不可控耗散部分具有鲁棒性。实现了可切换的耗散伊辛耦合。

Conclusion: 该工作提供了一个多功能工具，可促进基于磁振子的量子计算实现和探索多体磁振子物理。

Abstract: Magnonic systems present a compelling platform for quantum technology, owing to their strong capacity to form hybrid quantum systems via diverse couplings. To unlock the full potential of these systems, the engineering of flexible coupling between multiple magnon modes is essential. Here, we propose a method to realize switchable dissipative Ising coupling in magnon systems, leveraging the three-body coupling among photon, phonon, and magnon. This type of dissipative coupling is a critical component for constructing Ising machines designed to solve complex combinatorial optimization problems. By dynamically tuning the phase of a nonlinear mechanical pump, we demonstrate the realization of both ferromagnetic and antiferromagnetic dissipative interactions. The validity of the scheme is confirmed by numerical simulations, which also demonstrate its robustness against a strong uncontrollable part of dissipation. Our work provides a versatile tool that can facilitate the implementation of magnon-based quantum computing and the exploration of many-body magnon physics.

</details>


### [45] [Adiabatic pumping of topological corner states by coherent tunneling in a 2D SSH model](https://arxiv.org/abs/2511.22083)
*Yang Peng,Rui-Shan Li,Yan-Jue Lv,Yi Zheng*

Main category: quant-ph

TL;DR: 提出一种基于二维SSH模型的拓扑角态长程传输方案，通过模块化晶格结构和绝热泵浦实现拓扑暗态调控，相比传统Thouless泵浦具有更高保真度和效率。


<details>
  <summary>Details</summary>
Motivation: 拓扑保护态的主动操控是量子技术的关键前沿，结合拓扑鲁棒性和精确量子控制的优势。需要实现拓扑角态的长程传输，克服传统方法的局限性。

Method: 采用二维Su-Schrieffer-Heeger模型，构建由四个拓扑不同子块组成的模块化晶格结构。通过精确调控晶格耦合来调制拓扑暗态，基于拓扑角态和界面态之间的绝热通道相干隧穿。建立了绝热泵浦的多能级模型来描述其机制。

Result: 相比顺序两阶段Thouless泵浦，该协议在传输保真度和效率方面表现出更优越的性能。多能级模型准确描述了底层机制。

Conclusion: 提出的绝热泵浦方案为拓扑角态的长程传输提供了一种有效方法，结合了拓扑鲁棒性和精确量子控制，在量子技术应用中具有潜力。

Abstract: The active manipulation of topologically protected states represents a pivotal frontier for quantum technologies, offering a unique confluence of topological robustness and precise quantum control. We propose an adiabatic pumping scheme for the long-range transfer of topological corner states in a two-dimensional Su-Schrieffer-Heeger model. The protocol utilizes a modular lattice architecture composed of four topologically distinct subblocks, enabling the modulation of a topological dark state by precise tuning of lattice couplings. This approach is based on coherent tunneling by adiabatic passage among topological corner and interface states. We establish a multi-level model for the adiabatic pumping that provides an accurate description of the underlying mechanism. In comparison with a sequential two-stage Thouless pumping, our protocol offers superior performance in both transfer fidelity and efficiency.

</details>


### [46] [Propagation-Distance Limit for a Classical Nonlocal Optical System](https://arxiv.org/abs/2511.22085)
*Salman Sajad Wani,Xiaoping Shi,Saif- Al-Kuwari,Arshid Shabir,Mir Faizal*

Main category: quant-ph

TL;DR: 该论文推导了高度非局域光学光束的闭式量子速度极限(QSL)边界，将纵向传播距离z映射为演化参数，建立了传播距离极限z_PDL，并设计了紧凑的自散焦PDL光束整形器，实现了毫米尺度的强横向模式转换。


<details>
  <summary>Details</summary>
Motivation: 将量子力学中的量子速度极限概念扩展到经典光学领域，建立传播距离域的约束条件，为光子应用提供理论基础。

Method: 将傍轴传播映射到反转谐振子生成元，将纵向坐标z作为演化参数，构建传播子，计算Bures距离，推导Mandelstam-Tamm和Margolus-Levitin边界的解析表达式。

Result: 获得了传播距离极限z_PDL，设计了紧凑的自散焦PDL光束整形器，实现了毫米尺度的强横向模式转换，并展示了折射率、光束功率或温度的微小变化对z_PDL的高灵敏度，实现了10^{-7} RIU的折射率灵敏度和约1 mK的温度分辨率。

Conclusion: 该研究将距离域QSL几何与实用光子应用联系起来，为基于速度极限的计量学提供了新途径。

Abstract: We derive closed-form analog quantum-speed-limit (QSL) bounds for highly nonlocal optical beams whose paraxial propagation is mapped to a reversed (inverted) harmonic-oscillator generator. Treating the longitudinal coordinate $z$ as an evolution parameter (propagation distance), we construct the propagator, evaluate the Bures distance, and obtain analytic Mandelstam--Tamm and Margolus--Levitin bounds that fix a propagation-distance limit $z_{\mathrm{PDL}}$ to reach a prescribed mode distinguishability. This distance-domain constraint is the classical optical analogue of the minimal orthogonality time in quantum mechanics. We then propose a compact self-defocusing PDL beam shaper that achieves strong transverse-mode conversion within millimeter scales. We further show that small variations in refractive index, beam power, or temperature shift $z_{\mathrm{SL}}$ with high leverage, enabling speed-limit-based metrology with index sensitivities down to $10^{-7}$ RIU and temperature resolutions of order $1$ mK. The results bridge distance-domain QSL geometry and practical photonic applications.

</details>


### [47] [Towards Heterogeneous Quantum Federated Learning: Challenges and Solutions](https://arxiv.org/abs/2511.22148)
*Ratun Rahman,Dinh C. Nguyen,Christo Kurisummoottil Thomas,Walid Saad*

Main category: quant-ph

TL;DR: 该论文系统研究了量子联邦学习中的异质性问题，将异质性分为数据和系统两类，分析了其对训练的影响，评估了现有解决方案，并通过案例研究展示了解决量子异质性的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有量子联邦学习框架主要关注同质化场景，忽略了现实世界中量子数据分布、编码技术、硬件噪声水平和计算能力的差异，这些异质性会导致训练不稳定、收敛缓慢和模型性能下降。

Method: 对量子联邦学习中的异质性进行深入分析，将其分类为数据异质性和系统异质性；研究异质性对训练收敛和模型聚合的影响；批判性评估现有缓解方案；通过案例研究展示解决量子异质性的可行性。

Result: 论文系统分析了量子异质性的影响机制，指出了现有解决方案的局限性，并通过案例研究证明了解决量子异质性的可行性，为构建鲁棒和可扩展的异质量子联邦学习框架奠定了基础。

Conclusion: 量子联邦学习中的异质性问题需要系统解决，论文为此提供了分类框架和分析方法，并指出了未来研究方向，包括构建更鲁棒和可扩展的异质量子联邦学习框架。

Abstract: Quantum federated learning (QFL) combines quantum computing and federated learning to enable decentralized model training while maintaining data privacy. QFL can improve computational efficiency and scalability by taking advantage of quantum properties such as superposition and entanglement. However, existing QFL frameworks largely focus on homogeneity among quantum \textcolor{black}{clients, and they do not account} for real-world variances in quantum data distributions, encoding techniques, hardware noise levels, and computational capacity. These differences can create instability during training, slow convergence, and reduce overall model performance. In this paper, we conduct an in-depth examination of heterogeneity in QFL, classifying it into two categories: data or system heterogeneity. Then we investigate the influence of heterogeneity on training convergence and model aggregation. We critically evaluate existing mitigation solutions, highlight their limitations, and give a case study that demonstrates the viability of tackling quantum heterogeneity. Finally, we discuss potential future research areas for constructing robust and scalable heterogeneous QFL frameworks.

</details>


### [48] [Quantum Simulation of Ligand-like Molecules through Sample-based Quantum Diagonalization in Density Matrix Embedding Framework](https://arxiv.org/abs/2511.22158)
*Ashish Kumar Patra,Anurag K. S. V.,Sai Shankar P.,Ruchika Bhat,Raghavendra V.,Rahul Maitra,Jaiganesh G*

Main category: quant-ph

TL;DR: 结合密度矩阵嵌入理论(DMET)与基于采样的量子对角化(SQD)，在量子硬件上计算分子基态能量，达到化学精度


<details>
  <summary>Details</summary>
Motivation: 传统电子结构方法处理扩展分子系统的电子关联计算成本高，量子-经典混合算法有潜力突破这一限制，但需要减少问题规模和缓解硬件噪声的策略

Method: 使用DMET将分子系统分解为嵌入杂质子问题，然后通过SQD构建和经典对角化简化的构型空间，在IBM Eagle R3超导量子硬件上求解嵌入哈密顿量

Result: 所有考虑的天然配体样分子在最小STO-3G基组下的DMET-SQD能量与DMET-FCI基准值在化学精度(1 kcal/mol)内高度一致

Conclusion: 基于采样的量子方法与稳健的嵌入框架结合，能够可靠地将量子计算扩展到化学相关分子系统的模拟，在药物发现领域具有应用潜力

Abstract: The accurate treatment of electron correlation in extended molecular systems remains computationally challenging using classical electronic structure methods. Hybrid quantum-classical algorithms offer a potential route to overcome these limitations; however, their practical deployment on existing quantum computers requires strategies that both reduce problem size and mitigate hardware noise. In this work, we combine Density Matrix Embedding Theory (DMET) with Sample-based Quantum Diagonalization (SQD) to compute ground-state energies of a set of natural ligand-like molecules in the minimal Slater Type Orbital (STO-3G) basis set. DMET provides a systematic fragmentation of a molecule into embedded impurity subproblems, while SQD enables construction and classical diagonalization of reduced configuration spaces through quantum sampling enhanced by iterative configuration recovery. The resulting embedded Hamiltonians are solved on IBM's Eagle R3 superconducting quantum hardware (IBM Sherbrooke). The DMET-SQD energies obtained for all systems considered exhibit strong agreement with DMET-FCI benchmark values within chemical accuracy (1 kcal/mol). These results demonstrate that sample-based quantum methods, when integrated with a robust embedding framework, can reliably extend quantum computation towards simulation of chemically relevant molecular systems, showcasing potential applications in the field of drug discovery.

</details>


### [49] [A Time-Symmetric Formulation of Quantum Measurement: Reinterpreting the Arrow of Time as Information Flow](https://arxiv.org/abs/2511.22191)
*Shin-ichi Inage*

Main category: quant-ph

TL;DR: 提出时间对称的量子测量框架，通过双向信息更新恢复微观可逆性，将测量视为前向态与后向效应的信息交互，而非波函数坍缩。


<details>
  <summary>Details</summary>
Motivation: 量子测量通常被视为时间不对称的过程（波函数坍缩），这破坏了微观可逆性。本研究旨在建立时间对称的测量理论，将测量视为信息更新而非动力学不可逆过程。

Method: 采用基于算符的形式体系，将测量过程建模为前向演化态与后向传播效应之间的双向信息更新，由完全正定生成元及其伴随算符控制。该框架统一处理预选和后选统计。

Result: 框架严格保持完全正定性、归一化和无信号原理，满足Spohn不等式确保非负熵产生。在经典极限下退化为Kalman滤波器和RTS平滑器。适用于弱测量、EPR-Bell测试、零差检测和光子计数等实验场景。

Conclusion: 量子测量的时间不对称性源于信息条件化的单边性，而非基本动力学不可逆性。测量理论中的时间箭头可理解为信息箭头，测量是信息更新而非波函数坍缩。

Abstract: This study proposes a time-symmetric framework for quantum measurement that restores microscopic reversibility at the level of the dynamical description while remaining compatible with causality and thermodynamic consistency. Instead of invoking a stochastic wavefunction collapse, the measurement process is modeled as a bidirectional informational update between a forward-evolving state and a backward-propagating effect, governed by a completely positive generator and its adjoint. Within this operator-based formalism, pre- and post-selected statistics are treated on an equal footing, yielding a unified description of both. The proposed scheme rigorously preserves complete positivity, normalization, and the no-signalling principle, and it is shown to satisfy Spohn's inequality for the associated quantum Markov semigroup, thereby ensuring non-negative entropy production within this setting. The framework admits a direct experimental interpretation across a range of scenarios, including weak measurements, EPR-Bell tests, homodyne detection, and photon counting. Furthermore, in the classical limit, the bidirectional update is demonstrated to reduce to the well-established Kalman filter and Rauch-Tung-Striebel (RTS) smoother used in classical estimation theory. These results support the view that the apparent temporal asymmetry of quantum measurement arises not from fundamental dynamical irreversibility, but from informational conditioning, specifically, the one-sided way in which measurement outcomes are incorporated into our description. In this sense, the arrow of time in measurement theory may be understood as an arrow of information.

</details>


### [50] [Controlled-SWAP gates by tuning of interfering transition pathways in neutral atom arrays](https://arxiv.org/abs/2511.22214)
*Mohammadsadegh Khazali,Klaus Mølmer*

Main category: quant-ph

TL;DR: 在冷原子量子处理器中实现直接受控SWAP（Fredkin）门，通过提升干涉跃迁路径的简并度，用单个里德堡激发原子控制原子对之间的状态交换。


<details>
  <summary>Details</summary>
Motivation: 中性原子量子处理器虽然利用里德堡阻塞实现多量子位相位操作，但缺乏类似的原生交换和条件交换门，而这些门对于状态验证、费米子和XY模型模拟以及大型量子位阵列中的高效路由至关重要。

Method: 通过提升干涉跃迁路径的简并度，使单个里德堡激发原子能够控制原子对之间的状态交换。这种方法在约150μK的多普勒展宽和实际激光强度噪声下稳健工作。

Result: 实现了保真度超过99%的直接受控SWAP（Fredkin）操作，与分解实现相比，电路深度减少了一个数量级，并减少了里德堡态分量的衰减和退相干暴露。

Conclusion: 通过将受控交换操作作为中性原子的原生物理操作，这项工作提供了多量子位门，能够实现高阶状态验证协议、占据依赖模拟和光学晶格中的条件路由。

Abstract: Neutral-atom quantum processors employ Rydberg blockade for multiqubit phase operations but lack similar native exchange and conditional exchange gates, which are essential primitives for state verification, fermionic and XY-model simulation, and efficient routing in large qubit arrays. We demonstrate that by lifting the degeneracy between interfering transition pathways, a single Rydberg-excited atom can control state exchange between pairs of atoms. Using this mechanism, we realize a direct controlled-SWAP (Fredkin) operation with more than 99\% fidelity and an order-of-magnitude reduction in circuit depth and reduced exposure to decay and decoherence of Rydberg state components compared with decomposed implementations. The mechanism operates robustly under Doppler broadening at ~150 $μ$K and realistic laser-intensity noise and extends naturally to an entire family of useful gates, including multi-control conditional exchanges (C$_k$-SWAP) and conditional multiplexed SWAP gates. By incorporating controlled exchange operations as native physical operations on neutral atoms, our work provides multiqubit gates that enable higher-order state-verification protocols, occupation-dependent simulations, and conditional routing across optical lattices.

</details>


### [51] [Enhancing information retrieval in quantum-optical critical systems via quantum measurement backaction](https://arxiv.org/abs/2511.22248)
*Cheng Zhang,Mauro Cirio,Xin-Qi Li,Pengfei Liang*

Main category: quant-ph

TL;DR: 提出一种基于耗散临界性的开放量子光学传感协议，通过连续测量接近量子Cramér-Rao界极限精度


<details>
  <summary>Details</summary>
Motivation: 现有连续测量技术在量子光学中难以达到量子Cramér-Rao界所定义的极限精度，需要新方法来缩小这一差距

Method: 利用耗散临界性开放量子光学传感器，结合量子临界性和连续general-dyne检测中的量子测量反作用，在性能最佳点附近操作

Result: 协议能够显著缩小与极限精度之间的差距，在最佳点附近可以有效接近量子Cramér-Rao界

Conclusion: 为开放量子光学设置中的量子增强精度提供了新途径，并可扩展到具有类似耗散临界性的其他传感器设计

Abstract: Continuous monitoring of open quantum-optical systems offers a promising route towards quantum-enhanced estimation precision. In such continuous-measurement-based sensing protocols, the ultimate precision limit is dictated, through the quantum Cramér-Rao bound, by the global quantum Fisher information associated with the joint system-environment state. Reaching this limit with established continuous measurement techniques in quantum optics remains an outstanding challenge. Here we present a sensing protocol tailored for open quantum-optical sensors that exhibit dissipative criticality, enabling them to significantly narrow the gap to the ultimate precision limit. Our protocol leverages a previously unexplored interplay between the quantum criticality and the quantum measurement backaction inherent in continuous general-dyne detection. We identify a performance sweet spot, near which the ultimate precision limit can be efficiently approached. Our protocol establishes a new pathway towards quantum-enhanced precision in open quantum-optical setups and can be extended to other sensor designs featuring similar dissipative criticality.

</details>


### [52] [Local Equivalences of Graph States](https://arxiv.org/abs/2511.22271)
*Nathan Claudet*

Main category: quant-ph

TL;DR: 该论文提出了局部补图的推广形式来完全描述图态的LU等价性，证明了LC和LU等价性之间存在无限严格层次结构，设计了准多项式算法判断LU等价性，并研究了通用图态的构造。


<details>
  <summary>Details</summary>
Motivation: 图态在量子计算中有重要应用，理解图态之间的纠缠等价性（特别是LU等价性）至关重要。虽然LC等价性已有局部补图规则完全描述，但LU等价性缺乏类似完整刻画，且存在LC不等价但LU等价的图态。

Method: 引入局部补图的推广形式来完全捕捉LU等价性；利用这一特征化证明LC和LU等价性之间的无限严格层次结构；设计准多项式算法判断两个图态是否LU等价；研究通用图态的构造并提供概率构造方法。

Result: 1. 提出了能完全描述LU等价性的局部补图推广形式；2. 证明了LC和LU等价性之间存在无限严格层次结构；3. 设计了判断LU等价性的准多项式算法；4. 证明了在最多19个量子比特时，LU等价性蕴含LC等价性；5. 给出了通用图态的界限和最优概率构造。

Conclusion: 通过推广局部补图操作，论文成功建立了图态LU等价性的完整理论框架，解决了该领域的重要问题，为量子信息处理中的图态应用提供了理论基础和实用工具。

Abstract: Graph states form a large family of quantum states that are in one-to-one correspondence with mathematical graphs. Graph states are used in many applications, such as measurement-based quantum computation, as multipartite entangled resources. It is thus crucial to understand when two such states have the same entanglement, i.e. when they can be transformed into each other using only local operations. In this case, we say that the graph states are LU-equivalent (local unitary). If the local operations are restricted to the so-called Clifford group, we say that the graph states are LC-equivalent (local Clifford). Interestingly, a simple graph rule called local complementation fully captures LC-equivalence, in the sense that two graph states are LC-equivalent if and only if the underlying graphs are related by a sequence of local complementations. While it was once conjectured that two LU-equivalent graph states are always LC-equivalent, counterexamples do exist and local complementation fails to fully capture the entanglement of graph states. We introduce in this thesis a generalization of local complementation that does fully capture LU-equivalence. Using this characterization, we prove the existence of an infinite strict hierarchy of local equivalences between LC- and LU-equivalence. This also leads to the design of a quasi-polynomial algorithm for deciding whether two graph states are LU-equivalent, and to a proof that two LU-equivalent graph states are LC-equivalent if they are defined on at most 19 qubits. Furthermore, we study graph states that are universal in the sense that any smaller graph state, defined on any small enough set of qubits, can be induced using only local operations. We provide bounds and an optimal, probabilistic construction.

</details>


### [53] [Non-commutativity as a Universal Characterization for Enhanced Quantum Metrology](https://arxiv.org/abs/2511.22280)
*Ningxin Kong,Haojie Wang,Mingsheng Tian,Yilun Xu,Geng Chen,Yu Xiang,Qiongyi He*

Main category: quant-ph

TL;DR: 论文提出用幂零指数K量化编码过程中的非对易性深度，发现有限K能实现N^{-(1+K)}的误差缩放，无穷大K可实现指数精度N^{-1}e^{-N}，为量子增强计量提供系统路径。


<details>
  <summary>Details</summary>
Motivation: 量子计量中如何有效利用量子资源超越经典精度极限是核心挑战。虽然近期研究表明不定因果顺序可能实现超海森堡标度，但这种增强的物理起源仍不清楚。

Method: 引入幂零指数K来量化编码过程中算符的非对易性深度，证明K是控制量子增强传感的基本参数。提出实验可行的协议来实现这些机制。

Result: 有限K产生均方根误差的增强标度N^{-(1+K)}；仅当嵌套对易子变为常数时才需要不定因果顺序；当K→∞时，可实现指数精度标度N^{-1}e^{-N}。

Conclusion: 幂零指数K为理解量子增强计量提供了基本框架，揭示了不定因果顺序与精度增强之间的深层联系，并为实用量子增强计量学提供了系统路径。

Abstract: A central challenge in quantum metrology is to effectively harness quantum resources to surpass classical precision bounds. Although recent studies suggest that the indefinite causal order may enable sensitivities to attain the super-Heisenberg scaling, the physical origins of such enhancements remain elusive. Here, we introduce the nilpotency index $\mathcal{K}$, which quantifies the depth of non-commutativity between operators during the encoding process, can act as a fundamental parameter governing quantum-enhanced sensing. We show that a finite $\mathcal{K}$ yields an enhanced scaling of root-mean-square error as $N^{-(1+\mathcal{K})}$. Meanwhile, the requirement for indefinite causal order arises only when the nested commutators become constant. Remarkably, in the limit $\mathcal{K} \to \infty$, exponential precision scaling $N^{-1}e^{-N}$ is achievable. We propose experimentally feasible protocols implementing these mechanisms, providing a systematic pathway towards practical quantum-enhanced metrology.

</details>


### [54] [Programmable generation of arbitrary continuous-variable anharmonicities and nonlinear couplings](https://arxiv.org/abs/2511.22286)
*Teerawat Chalermpusitarak,Kai Schwennicke,Ivan Kassal,Ting Rei Tan*

Main category: quant-ph

TL;DR: 提出一种适用于单模和多模系统的任意非高斯操作实现方法，通过傅里叶分解和玻色量子信号处理，利用离散变量系统在连续变量系统中诱导非线性


<details>
  <summary>Details</summary>
Motivation: 连续变量量子系统因其无限维希尔伯特空间在量子计算和模拟中具有资源效率优势，但现有非高斯操作方案仅限于单模系统，限制了多模非线性耦合的实现

Method: 将目标哈密顿量分解为傅里叶级数，通过玻色量子信号处理技术，利用离散变量系统在连续变量系统中诱导非线性，实现任意非高斯操作

Result: 该方法能够实现单模非谐性和多模非线性耦合，可直接模拟晶格规范理论、化学动力学和量子混沌等连续变量现象，为连续变量电路编译提供更丰富的工具集

Conclusion: 提出的混合连续变量-离散变量协议扩展了连续变量量子系统的能力，使其能够高效实现任意非高斯操作，为量子计算和模拟开辟了新途径

Abstract: Harmonic oscillators are promising continuous-variable (CV) quantum resources because their infinite-dimensional Hilbert spaces allow for resource-efficient quantum computing and simulation. To reach their full potential, CV platforms need to be able to efficiently implement non-Gaussian operations. However, schemes for generating arbitrary non-Gaussian operations are restricted to single modes, i.e., the implementation of anharmonic potentials. Here, we introduce a method for implementing arbitrary non-Gaussian operations applicable to both single- and multi-mode systems, allowing the generation of both anharmonicities and nonlinear multi-mode couplings. Our method synthesizes a target Hamiltonian by decomposing it into a Fourier series whose terms are implemented via bosonic quantum signal processing, which uses a discrete-variable (DV) system to induce a nonlinearity in the CV system. Our hybrid CV-DV protocol allows for the direct simulation of a broad range of CV phenomena (such as those in lattice gauge theory, chemical dynamics, and quantum chaos) and provides a richer toolbox for CV circuit compilation.

</details>


### [55] [Untangling Surface Codes: Bridging Braids and Lattice Surgery](https://arxiv.org/abs/2511.22290)
*Alexandru Paler*

Main category: quant-ph

TL;DR: 提出一种系统方法，使用ZX演算在表面码中实现编织与晶格手术表示之间的双向转换，为拓扑量子计算提供统一形式语言。


<details>
  <summary>Details</summary>
Motivation: 表面码中的容错量子电路存在编织和晶格手术两种表示范式，需要建立它们之间的等价关系以实现自动化验证、编译和基准测试。

Method: 使用ZX演算建立编织和晶格手术的等价性，将两种操作统一表示为多体测量的组合，并利用Raussendorf压缩规则涵盖所有已知的编织和桥接优化。

Result: 实现了任意表面码级电路在编织和晶格手术表示之间的双向转换，并引入了一种新的基于晶格手术的CNOT电路。

Conclusion: 该框架为大规模表面码计算的自动化验证、编译和基准测试奠定了基础，推动了拓扑量子计算统一形式语言的发展。

Abstract: We present a systematic method for translating fault-tolerant quantum circuits between their braiding and lattice surgery (LS) representations within the surface code. Our approach employs the ZX calculus to establish an equivalence between these two paradigms, enabling verified, bidirectional conversion of arbitrary surface-code-level circuits. We show that both braiding and LS operations can be uniformly expressed as compositions of multibody measurements and demonstrate that the Raussendorf compression rule encompasses all known braid and bridge optimizations. We also introduce a novel CNOT circuit with LS. Our framework provides a foundation for the automated verification, compilation, and benchmarking of large-scale surface code computations, advancing toward a unified formal language for topological quantum computation.

</details>


### [56] [RELiQ: Scalable Entanglement Routing via Reinforcement Learning in Quantum Networks](https://arxiv.org/abs/2511.22321)
*Tobias Meuser,Jannis Weil,Aninda Lahiri,Marius Paraschiv*

Main category: quant-ph

TL;DR: RELiQ：基于强化学习和图神经网络的量子纠缠路由方法，仅使用本地信息和迭代消息交换，在随机和真实拓扑中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 量子网络在量子计算和量子传感领域日益重要，但纠缠路由面临量子链路高动态性和量子操作概率性的挑战。手工设计的启发式方法难以优化，尤其是在缺乏全局网络拓扑信息的情况下。

Method: 提出RELiQ方法：基于强化学习，仅依赖本地信息和迭代消息交换，使用图神经网络学习图表示，避免对特定网络拓扑的过拟合。在随机图上训练，适用于各种拓扑。

Result: 在随机和真实拓扑中，RELiQ持续优于现有的本地信息启发式方法和基于学习的方法。与全局信息启发式方法相比，由于对拓扑变化的快速响应，RELiQ实现了相似或更优的性能。

Conclusion: RELiQ展示了强化学习和图神经网络在量子网络路由中的有效性，仅使用本地信息就能实现高性能，并能快速适应网络拓扑变化。

Abstract: Quantum networks are becoming increasingly important because of advancements in quantum computing and quantum sensing, such as recent developments in distributed quantum computing and federated quantum machine learning. Routing entanglement in quantum networks poses several fundamental as well as technical challenges, including the high dynamicity of quantum network links and the probabilistic nature of quantum operations. Consequently, designing hand-crafted heuristics is difficult and often leads to suboptimal performance, especially if global network topology information is unavailable.
  In this paper, we propose RELiQ, a reinforcement learning-based approach to entanglement routing that only relies on local information and iterative message exchange. Utilizing a graph neural network, RELiQ learns graph representations and avoids overfitting to specific network topologies - a prevalent issue for learning-based approaches. Our approach, trained on random graphs, consistently outperforms existing local information heuristics and learning-based approaches when applied to random and real-world topologies. When compared to global information heuristics, our method achieves similar or superior performance because of its rapid response to topology changes.

</details>


### [57] [Excited state preparation on a quantum computer through adiabatic light-matter coupling](https://arxiv.org/abs/2511.22324)
*Hugh G. A. Burton,Maria-Andreea Filip*

Main category: quant-ph

TL;DR: 提出一种基于电子-光子耦合的绝热激发态制备方法，用于量子计算中的电子结构模拟


<details>
  <summary>Details</summary>
Motivation: 量子计算在量子多体问题模拟中具有潜力，但现有方法主要针对基态制备，激发态制备仍是主要挑战，限制了量子算法在光化学和光物理中的应用

Method: 利用电子与光子的显式耦合，通过物理驱动的绝热态制备技术，系统收敛到第一个光学可访问的激发态，并通过改变光子极化来靶向不同的对称性区域

Result: 在Hubbard模型和亚甲基分子的多种关联体系中成功制备了高保真度的激发态，并对模型哈密顿量进行了成功的硬件实现

Conclusion: 该方法为量子计算中的激发态制备提供了有效途径，扩展了量子算法在光化学和光物理领域的应用范围

Abstract: Quantum computing has the potential to transform simulations of quantum many-body problems at the heart of electronic structure theory. Efficient quantum algorithms to compute the eigenstates of fermionic Hamiltonians, such as quantum phase estimation, rely critically on high-accuracy initial state preparation. While several state preparation algorithms have been proposed for fermionic ground states, the preparation of excited states remains a major challenge, limiting the applicability of quantum algorithms to photochemistry and photophysics. In this contribution, we describe a physically motivated adiabatic state preparation technique for low-lying excited states using the explicit coupling between electrons and photons. Our approach systematically converges to the first optically accessible excited state and can target different symmetry sectors by changing the photon polarization. We demonstrate the preparation of high-fidelity excited states for the Hubbard model and methylene molecule across a range of correlation regimes, and perform a successful hardware implementation for a model Hamiltonian.

</details>


### [58] [Entanglement and Minimal Hilbert Space in the Classical Dual States of Quantum Theory](https://arxiv.org/abs/2511.23161)
*Diego J. Cirilo-Lombardo,Norma G. Sanchez*

Main category: quant-ph

TL;DR: 该论文研究量子纠缠与经典化的关系，通过元辛群Mp(n)作用实现真正的经典化，计算了不同相干态在圆和圆柱拓扑上的纠缠概率。


<details>
  <summary>Details</summary>
Motivation: 需要从物理上精确描述和理解量子理论的经典对偶内容，这对量子概念解释、量子技术和计算等领域都至关重要。

Method: 采用APL Quantum 2, 016104 (2025)中的经典化新方法，将纠缠波函数投影到Mp(n)群的偶(+)和奇(-)不可约希尔伯特子空间，计算不同相干态（陪集和非陪集）在圆和圆柱拓扑上的纠缠概率。

Result: 发现真正的经典化仅在元辛群Mp(n)作用下发生，计算了纠缠概率P++、P--、P+-（相同或不同子空间）及其总和，这些结果具有理论和实验价值。

Conclusion: 量子纠缠与经典化之间存在深刻联系，通过Mp(n)群作用实现的经典化方法为理解量子理论的经典对偶内容提供了新视角，结果具有实验和实际应用价值。

Abstract: A precise physical description and understanding of the classical dual content of quantum theory is necessary in many disciplines today: from concepts and interpretation to quantum technologies and computation. In this paper we investigate Quantum Entanglement with the new approach APL Quantum 2, 016104 (2025) on dual Classicalization. Thus, the results of this paper are twofold: Entanglement and Classicalization and the relationship between them. Classicalization truly occurs only under the action of the Metaplectic group Mp(n) (Minimal Representation group, double covering of the Symplectic group). Some of the results of this paper involves the computation and analysis of the entanglement for different types of coherent (coset and non coset) states and topologies: in the circle and the cylinder. We project the entangled wave functions onto the even (+) and odd (-) irreducible Hilbert Mp(n) subspaces, and compute their square norms: Entanglement Probabilities P++, P--, P+-, (eg in the same or in the different subspaces), and the Total sum of them, and more. These theoretical and conceptual results can be of experimental and practical real-world interest.

</details>


### [59] [Unifying Collective Effects in Emission, Absorption, and Transfer](https://arxiv.org/abs/2511.22335)
*Adesh Kushwaha,Erik M. Gauger,Ivan Kassal*

Main category: quant-ph

TL;DR: 该论文提出一个统一的Dicke框架来描述吸收、发射和转移中的集体效应，解决不同领域定义不一致的问题，并推广到谐振子等其他系统，为设计抗干扰量子器件提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 集体效应（超辐射和亚辐射）在量子技术中至关重要，但不同领域（吸收、发射、转移）对这些效应的定义不一致，导致结果难以在不同情境间转移应用。

Method: 使用统一的Dicke框架来描述所有三种类型的集体效应，将之前仅适用于自旋系统的集体效应推广到谐振子聚集体和其他自由度。

Result: 该框架解决了不同方法之间的明显差异，解释了如何设计对无序和噪声具有鲁棒性的集体效应，为更稳健的量子器件铺平道路。

Conclusion: 统一的Dicke框架为理解集体效应提供了通用语言，使不同领域的发现能够相互转化，并为设计抗干扰的量子技术提供了理论基础。

Abstract: Collective effects, such as superradiance and subradiance are central to emerging quantum technologies -- from sensing to energy storage -- and play an important role in light-harvesting. These effects enhance or suppress rates of dynamic processes (absorption, emission, and transfer) due to the formation of symmetric or antisymmetric collective states. However, collective effects in different contexts -- absorption, emission, and transfer -- have often been defined disparately, especially across different communities, leading to results that are not immediately transferable between different contexts. Here, we describe all three types of collective effects using a common Dicke framework that resolves the apparent discrepancies between different approaches. It allows us to generalise previously known collective effects involving spins into new ones involving aggregates of harmonic oscillators or other degrees of freedom. It also explains how collective effects can be engineered to be robust against both disorder and noise, paving the way for more resilient quantum devices.

</details>


### [60] [Sunburst quantum Ising battery under periodic delta-kick charging](https://arxiv.org/abs/2511.22349)
*Ankita Mazumdar,Akash Mitra,Shashi C. L. Srivastava*

Main category: quant-ph

TL;DR: 太阳爆发量子伊辛电池在量子混沌区域可实现量子优势（n_b≤4）并具有优异的能量存储稳定性，而在可积区域则与充电器初始状态无关地实现最优能量存储和提取。


<details>
  <summary>Details</summary>
Motivation: 现有量子电池研究大多基于可积模型，虽然能实现充电功率的超线性缩放和量子优势，但代价是能量存储不稳定。需要探索在量子混沌区域实现量子优势且保持能量存储稳定性的方案。

Method: 研究太阳爆发量子伊辛电池模型，采用周期性δ脉冲驱动，分析其在量子混沌区域和可积区域的不同特性。

Result: 在量子混沌区域，当电池数量n_b≤4时实现了量子优势，同时具有优异的能量存储稳定性；在可积区域，无论充电器初始状态如何都能实现最优能量存储和提取；观察到的优势并非源于电池子系统内的多体纠缠，本质上是经典的。

Conclusion: 太阳爆发量子伊辛电池在量子混沌区域能够实现量子优势与能量存储稳定性的平衡，为量子电池设计提供了新思路，同时揭示了这种优势的经典本质而非量子纠缠驱动。

Abstract: Most quantum batteries studied so far with notable exception of Sachdev-Ye-Kitaev (SYK) batteries are based on integrable models, where superlinear scaling of charging power and hence a quantum advantage can be achieved, but at the cost of unstable stored energy due to integrability. Here, by considering the sunburst quantum Ising battery driven by periodic delta-kicks, we show that in the quantum chaotic regime a quantum advantage is achieved for number of batteries $n_b\leq 4$, together with excellent stability of energy storage. In the integrable regime optimal energy storage and extraction are possible irrespective of the initial state of the charger. Finally, we show that the observed advantage does not originate from multipartite entanglement within the battery subsystem and is therefore classical in nature.

</details>


### [61] [Quantum resource degradation theory within the framework of observational entropy decomposition](https://arxiv.org/abs/2511.22350)
*Xiang Zhou*

Main category: quant-ph

TL;DR: 提出基于观测熵分解的量子资源退化理论，将总不一致性度量分解为块间相干性和块内噪声，揭示了量子相干性在特定自由操作下退化为经典噪声的机制，即使总资源量守恒，其质量也会下降。


<details>
  <summary>Details</summary>
Motivation: 传统标量度量无法捕捉自由操作下资源质量的演化，需要更精细的理论来描述量子资源在操作过程中的退化现象。

Method: 基于观测熵分解，将总不一致性度量 $\mathcal{O}_{\mathcal{C}}$ 分解为两个独立分量：块间相干性 $\mathcal{C}_{\text{rel}}$ 和块内噪声 $\mathcal{D}_{\text{rel}}$，并引入资源纯度度量 $η$ 来量化资源质量。

Result: 揭示了量子相干性在特定自由操作下退化为经典噪声的退化机制，即使总资源量守恒，其质量也会下降。通过变分量子算法的数值实验验证了理论，并成功诊断和解释了贫瘠高原现象。

Conclusion: 该理论提供了比传统单调性方法更详细的资源动态描述，建立了管理资源质量的新范式，有助于优化当前和近期含噪声量子设备上的量子技术。

Abstract: In quantum resource theories, traditional scalar measures often fail to capture the evolution of the quality of a resource under free operations. To address this limitation, we propose a quantum resource degradation theory based on the decomposition of observational entropy. We demonstrate that the total inconsistency measure, $\mathcal{O}_{\mathcal{C}}$, can be decomposed into two independent components: inter-block coherence, $\mathcal{C}_{\text{rel}}$, and intra-block noise, $\mathcal{D}_{\text{rel}}$. This decomposition reveals a significant degradation mechanism: under specific free operations, quantum coherence degrades into classical noise. Consequently, even when the total resource quantity is conserved, its quality decreases. This is quantified by the resource purity metric, $η$. Our theory provides greater detail than conventional approaches that rely solely on monotonicity. It also establishes a new framework for understanding quantum resource dynamics. We validate the theory through numerical experiments on Variational Quantum Algorithms (VQAs), demonstrating its utility in diagnosing and explaining the barren plateau phenomenon (BPP). The proposed framework establishes a new paradigm for managing resource quality, complementing traditional resource quantification. This contributes to the optimization of quantum technologies on current and near-term noisy quantum devices.

</details>


### [62] [Ultrafast Single Qubit Gates through Multi-Photon Transition Removal](https://arxiv.org/abs/2511.22365)
*Y. Gao,A. Galicia,J. D. Da Costa Jesus,Y. Liu,Y. Haddad,D. A. Volkov,J. R. Guimarães,H. Bhardwaj,M. Jerger,M. Neis,B. Li,F. A. Cárdenas-López,F. Motzoi,P. A. Bushev,R. Barends*

Main category: quant-ph

TL;DR: 提出R2D方法实现超快低泄漏量子门，在6.8ns脉冲下泄漏误差低于2.0×10⁻⁵，保真度超过99.98%


<details>
  <summary>Details</summary>
Motivation: 量子计算需要快速精确的量子门控制，但多能级结构导致快速门操作时发生泄漏，传统方法只抑制第一到第二激发态跃迁，忽略了多光子跃迁，难以同时实现快速门和低泄漏

Method: 采用双递归实现的导数移除绝热门方法（R2D方法），消除超越最近邻能级的直接跃迁，并引入放大泄漏误差的方法精确量化低于10⁻⁶的泄漏率

Result: 在6.8ns脉冲下实现单量子比特门，总泄漏误差低于2.0×10⁻⁵，X和X/2门保真度超过99.98%，发现超短门时间和强驱动下主要误差源来自高阶跃迁

Conclusion: R2D方法在超导transmon量子比特中成功实现超快低泄漏量子门，该方法可推广到其他量子比特类型，解决了快速门与低泄漏之间的权衡问题

Abstract: One of the main enablers in quantum computing is having qubit control that is precise and fast. However, qubits typically have multilevel structures making them prone to unwanted transitions from fast gates. This leakage out of the computational subspace is especially detrimental to algorithms as it has been observed to cause long-lived errors, such as in quantum error correction. This forces a choice between either achieving fast gates or having low leakage. Previous works focus on suppressing leakage by mitigating the first to second excited state transition, overlooking multi-photon transitions, and achieving faster gates with further reductions in leakage has remained elusive. Here, we demonstrate single qubit gates with a total leakage error consistently below $2.0\times10^{-5}$, and obtain fidelities above $99.98\%$ for pulse durations down to 6.8 ns for both $X$ and $X/2$ gates. This is achieved by removing direct transitions beyond nearest-neighbor levels using a double recursive implementation of the Derivative Removal by Adiabatic Gate (DRAG) method, which we name the R2D method. Moreover, we find that at such short gate durations and strong driving strengths the main error source is from these higher order transitions. This is all shown in the widely-used superconducting transmon qubit, which has a weakly anharmonic level structure and suffers from higher order transitions significantly. We also introduce an approach for amplifying leakage error that can precisely quantify leakage rates below $10^{-6}$. The presented approach can be readily applied to other qubit types as well.

</details>


### [63] [Quantum-Enhanced Picostrain Sensing with Superconducting Qubits](https://arxiv.org/abs/2511.22407)
*Necati Çelik*

Main category: quant-ph

TL;DR: 提出一种量子增强的皮应变传感器，利用超导量子比特实现海森堡极限的应变传感，灵敏度达到皮应变级别，比经典传感器提高两个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统应变传感器在灵敏度上存在限制，需要开发更高精度的传感技术。量子增强传感可以利用量子纠缠等特性突破经典极限，实现更精确的纳米尺度材料表征和原位诊断。

Method: 将应变敏感的量子比特哈密顿量与微波谐振器的动量正交耦合，将机械应变转换为谐振器相空间位移的放大。通过谐振器场的零差探测和N个量子比特的多体纠缠，实现海森堡极限的应变传感。

Result: 实现了Δε∼pε（皮应变）的应变灵敏度，比经典传感器提高了两个数量级。该方案与超导处理器原生集成，支持原位诊断和纳米尺度材料表征。

Conclusion: 该量子增强皮应变传感器通过量子纠缠和相空间放大技术，成功实现了海森堡极限的应变传感，为超导量子处理器集成的高精度传感应用开辟了新途径。

Abstract: We propose a quantum-enhanced picostrain sensor that achieves Heisenberg-limited strain sensing using superconducting qubits. A strain-sensitive qubit s Hamiltonian is coupled to the momentum quadrature of a microwave resonator, transducing mechanical strain $ε$ into amplified spatial displacements of the resonator s phase space. Using homodyne detection of the resonator field and multipartite entanglement of N qubits, the protocol achieves a strain sensitivity $Δε\sim pε$ (picostrain), two orders of magnitude better than classical sensors. The scheme integrates natively with superconducting processors, enabling in-situ diagnostic and nanoscale material characterization.

</details>


### [64] [Entanglement gain in supercatalytic state transformations](https://arxiv.org/abs/2511.22413)
*Guillermo Díez-Pastor,Julio I. de Vicente*

Main category: quant-ph

TL;DR: 本文研究了超催化现象，其中借用的催化剂在协议结束后以增强形式（更纠缠）返回。作者引入了超催化纠缠增益作为性能指标，研究了最大化增益的策略，并探讨了最小超催化的可能性。


<details>
  <summary>Details</summary>
Motivation: 超催化现象（催化剂在协议结束后以增强形式返回）在量子信息领域研究较少。作者旨在量化超催化性能，探索何时可以获得大于零的纠缠增益，以及哪些策略可以最大化这种增益。

Method: 引入超催化纠缠增益作为量化指标（取值[0,1]），研究不同催化剂选择对增益的影响。证明所有催化转化都可以通过适当选择催化剂实现增益为1的超催化，但某些催化剂选择会使增益小于1甚至为0。同时研究最小超催化（约束借用态的纠缠内容），证明在此情况下无法达到增益为1，但可以无限接近1。

Result: 1. 所有催化转化都可以通过选择高度纠缠的催化剂实现增益为1的超催化；2. 许多催化转化不是完全可超催化的（存在某些催化剂选择使增益为0）；3. 在最小超催化约束下，虽然无法达到增益为1，但可以无限接近1；4. 选择最小纠缠的催化剂通常是最优策略，但并非总是如此。

Conclusion: 超催化现象在量子信息处理中具有重要意义。虽然通过高度纠缠催化剂可以实现最大增益，但在实际约束下（最小超催化），仍然可以获得接近最大值的性能。催化剂的选择策略需要根据具体场景优化，最小纠缠催化剂并非总是最优选择。

Abstract: Catalysis refers to the possibility of performing an otherwise impossible local state transformation by sharing an additional state, i.e. a catalyst, which is returned at the end of the protocol. There is a stronger version, known as supercatalysis, in which the borrowed catalyst is returned in an enhanced form, i.e. more entangled. However, this phenomenon has remained little explored. In this work we introduce the supercatalytic entanglement gain as a figure of merit taking values in [0,1] that quantifies the performance of the protocol (with 0 corresponding to the standard case of catalysis and 1 representing the maximal possible gain) and we study in which cases it can be greater than zero and which strategies can maximize it. While it turns out that every catalytic transformation can be implemented in a supercatalytic fashion with entanglement gain equal to 1 if the state that is borrowed is chosen appropriately, other choices can make the gain strictly less than 1 and even 0. In fact, we prove that a large class of catalytic transformations are not fully supercatalyzable, i.e. there is at least one choice of catalyst for which the entanglement gain vanishes. On the other hand, the construction that shows that supercatalysis is always possible with maximal gain uses artificially highly entangled catalysts. For this reason, we also study minimal supercatalysis, where the entanglement content of the borrowed state is constrained in a precise and natural way. While we consider a scenario where we prove it is impossible to have entanglement gain equal to 1 in this case, we show that there exist minimal supercatalytic transformations with gain as close to 1 as desired. We also explore several examples and observe that, although choosing a catalyst with the least possible entanglement is often an optimal strategy for minimal supercatalysis, this is not necessarily always the case.

</details>


### [65] [Sum rule for non-adiabatic geometric phases](https://arxiv.org/abs/2511.22437)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 该论文证明了非绝热演化中几何相位及其2-形式的求和规则，类似于贝里单极子的抵消现象，这对量子计算中纯几何实现的门操作类型构成了限制。


<details>
  <summary>Details</summary>
Motivation: 研究非绝热演化中几何相位的求和规则，探索量子计算中几何门实现的限制条件。

Method: 通过数学推导证明非绝热演化中几何相位及其基础2-形式存在求和规则，类似于贝里单极子在完整能量本征态集合上的抵消现象。

Result: 发现了非绝热演化中几何相位存在求和规则，这些规则限制了仅通过几何手段实现的量子门类型，对量子比特计算具有重要影响。

Conclusion: 几何相位在非绝热演化中存在求和规则，这限制了纯几何方法在量子计算中实现的门操作类型，为量子门设计提供了理论约束。

Abstract: Berry monopoles always cancel when summing over a complete set of energy eigenstates. We demonstrate that analogous sum rules exist for geometric phases and their underlying 2-forms in non-adiabatic evolution. Our result has implications for qudit computation as it limits the types of gates that can be implemented by purely geometric means.

</details>


### [66] [Effect of Energy Extensivity on the Performance of Open Quantum Interferometers](https://arxiv.org/abs/2511.22439)
*Žan Kokalj,Tommaso Favalli,Andrea Trombettoni*

Main category: quant-ph

TL;DR: 量子干涉仪耦合环境时，Kac重标度对保持海森堡极限灵敏度至关重要


<details>
  <summary>Details</summary>
Motivation: 研究量子干涉仪与环境耦合的性能具有理论和实际重要性。通常认为环境耦合会使灵敏度从海森堡极限退化到散粒噪声极限，但这一结论可能取决于耦合项的Kac重标度。

Method: 使用Lindblad方程分析存在和不存在Kac重标度的情况，考虑线性耦合和谐波环境模型

Result: Kac重标度后，线性耦合和谐波环境模型下，海森堡极限灵敏度可能得以恢复

Conclusion: 需要重视并表征干涉仪环境模型的特性，Kac重标度对保持量子优势至关重要

Abstract: Studying the performance of a quantum interferometer coupled to an external environment is a problem of conceptual and practical importance. If we consider a quantum interferometer featuring Heisenberg-limited sensitivity, then a typical result is that introducing coupling with the environment degrades the sensitivity to the shot-noise limit. Here we argue that this result crucially depends on whether the interferometer-environment coupling term is subject (or not) to the so-called Kac rescaling that restores extensivity, i.e., whether the coupling Hamiltonian is extensive or not. We present results of the Lindblad equation in the presence and absence of Kac rescaling of the coupling constant. Our results show that for a linear coupling and a harmonic model of the environment, often used in modeling of a quantum interferometer coupled with an environment, the Heisenberg-limited sensitivity may be restored after the Kac rescaling. This result points out the need and the importance to characterize the (model of the) environment of the interferometer at hand.

</details>


### [67] [On the possibility of superradiant neutrino emission by atomic condensates](https://arxiv.org/abs/2511.22450)
*Massimo Blasone,Loredana Gastaldo,Francesco Romeo*

Main category: quant-ph

TL;DR: 重新审视原子凝聚体中超辐射中微子发射的可能性，讨论在何种条件下冷原子系统中仍可能出现集体发射现象


<details>
  <summary>Details</summary>
Motivation: Jones和Formaggio最近提出原子凝聚体中可能存在超辐射中微子发射的理论可能性，但后续分析质疑了这一情景，强调了衰变原子费米子性质的限制作用。本研究旨在重新审视这一问题，探讨在冷原子系统中集体发射现象可能出现的条件。

Method: 重新分析原子凝聚体中的超辐射中微子发射问题，考虑费米子性质的限制因素，探讨不同条件下集体发射现象出现的可能性

Result: 研究发现，虽然费米子性质对超辐射中微子发射构成限制，但在特定条件下冷原子系统中仍可能出现集体发射现象

Conclusion: 超辐射中微子发射在原子凝聚体中是可能的，但需要满足特定条件来克服费米子性质的限制，这为冷原子系统中的集体发射现象研究提供了新的理论框架

Abstract: In a recent work [B. J. P. Jones and J. A. Formaggio, Phys. Rev. Lett. 135, 111801 (2025)], the possibility of superradiant neutrino emission from atomic condensates has been theoretically proposed. Subsequent analysis by Y. K. Lu, H. Lin, and W. Ketterle [arXiv:2510.21705] questioned this scenario, emphasizing the limiting role of the fermionic nature of the decayed atoms. In this study, we revisit the problem and discuss under which conditions collective emission phenomena might still emerge in cold-atom systems.

</details>


### [68] [Computation and Verification of Spectra for Non-Hermitian Systems](https://arxiv.org/abs/2511.22469)
*Catherine Drysdale,Matthew Colbrook,Michael T. M. Woodley*

Main category: quant-ph

TL;DR: 论文建立了量子力学与计算之间的联系，揭示了计算谱的基本限制，特别是在非厄米特设置中。通过引入局部平凡伪谱概念，为具有误差控制的谱计算提供了严格框架，并成功应用于虚立方振子等挑战性问题。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的谱计算存在基本限制，特别是在非厄米特系统中。传统方法在计算虚立方振子等挑战性问题的特征值和特征函数时，常常产生虚假模式且缺乏误差控制。需要建立连接量子力学与计算的严格框架来解决这些问题。

Method: 引入局部平凡伪谱概念，该概念动态适应系统能量。利用这一框架，开发了能够避免截断引起的虚假特征值的方法，特别解决了截断导致的PT对称性破坏问题。该方法提供了具有误差控制的谱计算。

Result: 成功计算了虚立方振子$H_{\mathrm{B}} = p^2 + i x^3$的特征值和特征函数，具有误差控制且无虚假模式。例如，确认第100个特征值为$627.6947122484365113526737029011536\ldots$。该方法还应用于一系列物理相关算子的谱计算。

Conclusion: 该研究建立了连接计算理论与量子力学的严格框架，提供了具有误差控制的精确谱计算工具。局部平凡伪谱概念对于谱计算是必要的，该方法能够避免传统截断方法产生的虚假特征值问题，具有广泛的适用性。

Abstract: We establish a connection between quantum mechanics and computation, revealing fundamental limitations for algorithms computing spectra, especially in non-Hermitian settings. Introducing the concept of locally trivial pseudospectra (LTP), we show such assumptions are necessary for spectral computation. LTP adapts dynamically to system energies, enabling spectral analysis across a broad class of challenging non-Hermitian problems. Exploiting this framework, we overcome a longstanding obstacle by computing the eigenvalues and eigenfunctions of the imaginary cubic oscillator $H_{\mathrm{B}} = p^2 + i x^3$ with error bounds and no spurious modes -- yielding, to our knowledge, the first such error-controlled result. We confirm, for instance, the 100th eigenvalue as $627.6947122484365113526737029011536\ldots$. Here, truncation-induced $\mathcal{PT}$-symmetry breaking causes spurious eigenvalues -- a pitfall our method avoids, highlighting the link between truncation and physics. Finally, we illustrate the approach's generality via spectral computations for a range of physically relevant operators. This letter provides a rigorous framework linking computational theory to quantum mechanics and offers a precise tool for spectral calculations with error bounds.

</details>


### [69] [Improved parameter initialization for the (local) unitary cluster Jastrow ansatz](https://arxiv.org/abs/2511.22476)
*Wan-Hsuan Lin,Fangchun Liang,Mario Motta,Haimeng Zhang,Kenneth M. Merz,Kevin J. Sung*

Main category: quant-ph

TL;DR: 提出两种改进量子化学变分算法中UCJ/LUCJ ansatz参数初始化的方法：压缩双因子分解和近似张量网络模拟，显著提升算法性能


<details>
  <summary>Details</summary>
Motivation: UCJ/LUCJ ansatz在量子化学变分算法中具有物理动机和硬件效率优势，但其参数从经典CCSD计算初始化时，由于量子处理器连接性约束需要截断和丢弃相互作用，会降低对CCSD的近似精度和能量准确性

Method: 1. 压缩双因子分解方法：适用于期望值和采样基算法，通过压缩CCSD振幅的双因子分解来改进或恢复CCSD近似；2. 近似张量网络模拟方法：适用于采样基算法，通过近似张量网络模拟改进ansatz电路产生的样本质量

Result: 在最多52个量子比特的精确态矢量模拟和最多65个量子比特的超导量子处理器实验中验证了方法的有效性，两种方法都能显著提升期望值基和采样基量子算法的输出质量

Conclusion: 提出的两种参数初始化改进方法能有效解决UCJ/LUCJ ansatz在量子硬件约束下的性能退化问题，为量子化学变分算法提供了更可靠的参数初始化策略

Abstract: The unitary cluster Jastrow (UCJ) ansatz and its variant known as local UCJ (LUCJ) are promising choices for variational quantum algorithms for chemistry due to their combination of physical motivation and hardware efficiency. The parameters of these ansatzes can be initialized from the output of a coupled cluster, singles and doubles (CCSD) calculation performed on a classical computer. However, truncating the number of repetitions of the ansatz, as well as discarding interactions to accommodate the connectivity constraints of near-term quantum processors, degrade the approximation to CCSD and the resulting energy accuracy. In this work, we propose two methods to improve the parameter initialization. The first method, which is applicable to both expectation value- and sample-based algorithms, uses compressed double factorization of the CCSD amplitudes to improve or recover the CCSD approximation. The second method, which is applicable to sample-based algorithms, uses approximate tensor network simulation to improve the quality of samples produced by the ansatz circuit. We validate our methods using exact state vector simulation on systems of up to 52 qubits, as well as experiments on superconducting quantum processors using up to 65 qubits. Our results indicate that our methods can significantly improve the output of both expectation value- and sample-based quantum algorithms.

</details>


### [70] [Radio-Frequency Hong-Ou-Mandel Interference with Conditionally Built States](https://arxiv.org/abs/2511.22480)
*A. Sheleg,D. Vovchuk,K. Boiko,P. Ginzburg,G. Slepyan,A. Boag,A. Mikhalychev,A. Ulyanenkov,T. Salgals,P. Kuzhir,D. Mogilevtsev*

Main category: quant-ph

TL;DR: 实验演示了在120MHz射频频率下使用经典相位平均相干态的条件构建实现室温Hong-Ou-Mandel干涉，为在缺乏传统单光子技术的频谱区域模拟量子效应提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 在射频等传统量子技术（单光子源和探测器）不可用或需要低温条件的频谱区域，探索实现量子干涉现象的方法。

Method: 使用相位平均相干态构建高保真度的单光子态近似，通过条件状态构建实现Hong-Ou-Mandel干涉，并可通过优化状态表示实现可调噪声抑制。

Result: 观察到归一化二阶强度相关函数显著低于经典极限0.5，成功在120MHz射频频率下实现了室温Hong-Ou-Mandel干涉。

Conclusion: 该方法证明了使用条件制备的经典态在射频域模拟量子干涉现象的可行性，为在标准量子技术不可行的频率范围内实现其他量子协议（如贝尔不等式测试）开辟了道路。

Abstract: We report an experimental demonstration of room-temperature Hong-Ou-Mandel (HOM) interference at a radio-wave frequency of 120 MHz using conditional build-up of quantum states from classical phase-averaged coherent states. This approach enables observation of quantum effects in spectral regimes where conventional single-photon sources and detectors are unavailable or require cryogenic conditions. By constructing a high-fidelity approximation of a single-photon state with phase-averaged coherent states, we observe the normalized second-order intensity correlation dips significantly below the classical limit of 0.5. The method allows for tunable noise suppression via optimization of the state representation. Our results establish the feasibility of using conditionally prepared classical states to simulate quantum interference phenomena in the radio-frequency domain. This technique opens the door to realizing other quantum protocols, such as Bell inequality tests, in frequency ranges where standard quantum technologies are currently infeasible.

</details>


### [71] [Wavelength dependent electrical readout of spin ensembles in thin-film silicon carbide on insulator platform](https://arxiv.org/abs/2511.22485)
*Alexander Zappacosta,Ben Haylock,Paul Fisher,Naoya Morioka,Robert Cernansky*

Main category: quant-ph

TL;DR: 在SiCOI平台上实现了硅空位缺陷的自旋态电学读取和相干控制，首次在V2硅空位零声子线外实现自旋读取，为可扩展量子技术提供新平台


<details>
  <summary>Details</summary>
Motivation: 开发可扩展、CMOS兼容的量子技术平台，将光学自旋读取与可扩展电子设备相结合，实现更实用的量子系统

Method: 在SiCOI平台上使用780-990nm波长激发，采用光电磁共振检测技术，比较体SiC和薄膜SiCOI的光学和电学读取性能

Result: 成功实现<450个硅空位的自旋态电学读取和相干控制，首次在V2硅空位零声子线外实现自旋读取，薄膜处理对T2时间(~7微秒)无显著影响

Conclusion: SiCOI平台不仅适用于集成光子学，还可用于电子和自旋基器件，为宽波长范围内的可扩展量子技术提供多功能平台

Abstract: We report electrical spin state readout and coherent control of a small ensemble (<450) of silicon vacancies in a silicon carbide-on-insulator (SiCOI) platform, with excitation wavelengths from 780 to 990 nm. Demonstrating for the first time spin state readout well beyond the zero phonon line of the V2 silicon vacancies. By implementing photoelectrical detection of magnetic resonance (PDMR) in thin-film SiCOI, we merge a scalable and optics-free spin readout technique together with a promising platform for scalable and CMOS-compatible integrated photonics. Furthermore, we provide a comparison of optical and electrical readout between bulk SiC and thin-film SiCOI, revealing that our thin-film processing has no significant effect on the bulk T2 time of ~ 7 microseconds. These results establish SiCOI as a versatile platform for not only integrated photonics but also electronic and spin-based devices for scalable quantum technologies over a wide range of excitation wavelengths.

</details>


### [72] [Optimal Quantum Measurements with respect to the Fidelity](https://arxiv.org/abs/2511.22487)
*Datong Chen,Huangjun Zhu*

Main category: quant-ph

TL;DR: 该论文研究了当两个量子态密度算符奇异（不可逆）时，保真度最优量子测量的结构，特别是最小最优测量，并给出了存在唯一或无限多个不等价选择的充要条件。


<details>
  <summary>Details</summary>
Motivation: 保真度是衡量两个量子态相似度的标准指标，但三十多年来，当两个密度算符奇异（不可逆）时，保真度最优量子测量的结构仍不清楚。本文旨在填补这一空白。

Method: 聚焦于最小最优测量（即不存在非平凡粗粒化仍保持最优的测量），分析其存在性条件。当其中一个态是纯态时，利用Bloch球表示的几何洞察来完整表征所有最小最优测量。

Result: 证明存在两种情况：要么存在唯一的最小最优测量，要么存在无限多个不等价选择。第一种情况成立当且仅当两个密度算符满足弱交换性条件。当其中一个态是纯态时，给出了所有最小最优测量的完整表征。

Conclusion: 该研究阐明了奇异密度算符下保真度最优测量的结构，建立了与量子不相容性、算子铅笔和几何平均的联系，为量子信息理论中的测量优化问题提供了新的理论框架。

Abstract: Fidelity is the standard measure for quantifying the similarity between two quantum states. It is equal to the square of the minimum Bhattacharyya coefficient between the probability distributions induced by quantum measurements on the two states. Though established for over thirty years, the structure of fidelity-optimal quantum measurements remains unclear when the two density operators are singular (not invertible). Here we address this gap, with a focus on minimal optimal measurements, which admit no nontrivial coarse graining that is still optimal. We show that there exists either a unique minimal optimal measurement or infinitely many inequivalent choices. Moreover, the first case holds if and only if the two density operators satisfy a weak commutativity condition. In addition, we provide a complete characterization of all minimal optimal measurements when one state is pure, leveraging geometric insights from the Bloch-sphere representation. The connections with quantum incompatibility, operator pencils, and geometric means are highlighted.

</details>


### [73] [Replica Field Theory of Quantum Jumps Monitoring: Application to the Ising Chain](https://arxiv.org/abs/2511.22506)
*Youenn Le Gal,Marco Schirò*

Main category: quant-ph

TL;DR: 该论文推导了量子跳跃协议下被监测量子多体系统的副本场论，研究了伊辛链的监测动力学，发现了DIII或D对称类的非线性西格玛模型，并探讨了纠缠相的含义。


<details>
  <summary>Details</summary>
Motivation: 研究被监测量子多体系统的动力学，特别是量子跳跃协议下的演化，理解监测如何影响量子系统的统计性质，并探索伊辛链在不同监测参数下的相行为。

Method: 推导了量子跳跃协议的副本场论，建立了Keldysh作用量，针对监测粒子密度和可调各向异性的伊辛链，推导了有效场论，包括副本对角鞍点和描述副本非对角扇区的非线性西格玛模型。

Result: 发现密度矩阵的演化中非厄米项是副本对角的，而量子跳跃导致副本耦合。伊辛链的有效场论对称类为DIII或D（取决于参数），在特殊对称点恢复自由费米子结果。非线性西格玛模型描述了副本非对角扇区。

Conclusion: 该工作为理解被监测量子系统的统计性质提供了场论框架，揭示了伊辛链在不同监测参数下的对称性结构，对数值观测到的纠缠相有重要启示。

Abstract: In this work we derive the replica field theory for monitored quantum many-body systems evolving under the quantum jumps protocol, corresponding to a non-Hermitian evolution interspersed with random quantum jumps whose distribution is state-dependent. We show that the density matrix of $R$ replicas evolves according to a master equation where the non-Hermitian term is replica-diagonal while coupling among replicas are due to quantum jumps. We write down the associated Keldysh action and study its behavior for the specific case of the Ising Chain with monitoring of particle density and tunable anisotropy, interpolating between free fermions with strong U(1) symmetry and the Ising chain with Z$_2$ symmetry. We derive the effective field theory in terms of slowly varying fields and obtain the replica-diagonal saddle point, which we show to describe the average state. We then go beyond saddle point and derive the effective field theory describing the replica off-diagonal sector, which takes the form of a Non-Linear Sigma Model. The symmetry class is either DIII or D, depending on the parameters of the Ising chain, except at a special symmetric point, where we recover the results for free fermions. We discuss the implications of these findings for the entangling phase observed numerically for the monitored Ising chain.

</details>


### [74] [High-Precision Fidelity Estimation with Common Randomized Measurements](https://arxiv.org/abs/2511.22509)
*Zhongyi Yang,Datong Chen,Zihao Li,Huangjun Zhu*

Main category: quant-ph

TL;DR: 提出一种基于Clifford群和随机测量的高效量子态保真度估计协议，将所需电路数从1/ε²减少到1/ε，在特定噪声下甚至只需常数个电路


<details>
  <summary>Details</summary>
Motivation: 传统量子态保真度估计方法需要1/ε²个不同电路和1/ε²个样本，资源消耗大，限制了高精度保真度估计的实际应用

Method: 结合常见随机测量(CRM)和基于Clifford群的影子估计，构建高效估计协议；分析在退极化噪声和Pauli噪声等实际场景下的性能

Result: 新协议仅需1/ε个电路，比传统方法显著减少；在特定噪声环境下只需常数个电路（通常1个即可），与保真度ε和量子比特数无关

Conclusion: 提出的CRM影子估计协议在效率和资源消耗方面优于标准和节俭影子估计，为大规模量子系统的保真度估计提供了实用解决方案

Abstract: Efficient fidelity estimation of multiqubit quantum states is crucial to many applications in quantum information processing. However, to estimate the infidelity $ε$ with multiplicative precision, conventional estimation protocols require (order) $1/ε^2$ different circuits in addition to $1/ε^2$ samples, which is quite resource-intensive for high-precision fidelity estimation. Here we introduce an efficient estimation protocol by virtue of common randomized measurements (CRM) integrated with shadow estimation based on the Clifford group, which only requires $1/ε$ circuits. Moreover, in many scenarios of practical interest, in the presence of depolarizing or Pauli noise for example, our protocol only requires a constant number of circuits, irrespective of the infidelity $ε$ and the qubit number. For large and intermediate quantum systems, quite often one circuit is already sufficient. In the course of study, we clarify the performance of CRM shadow estimation based on the Clifford group and 4-designs and highlight its advantages over standard and thrifty shadow estimation.

</details>


### [75] [Mixed cat states at low purity of light](https://arxiv.org/abs/2511.22511)
*N. I. Petrov*

Main category: quant-ph

TL;DR: 通过非傍轴演化在光波导中生成空间位移混合猫态的量子叠加，可在特定传播距离观测到高度混合的薛定谔猫态


<details>
  <summary>Details</summary>
Motivation: 通常使用纯态观察量子现象，本研究探索在低纯度光束中生成和观测混合猫态的可能性

Method: 利用光学波导中的非傍轴幺正演化，通过初始低相干性光束生成空间位移混合猫态的量子叠加

Result: 在特定传播距离可观测到高度混合的薛定谔猫态，展示了原始波包的长期退相干和再相干过程的重要性，并评估了混合猫态的海森堡和薛定谔-罗伯逊不确定关系

Conclusion: 通过实际可用光源和光波导参数的精确数值模拟，证明了该方法在实验上的可行性

Abstract: Pure states are usually used to observe quantum phenomena. In this study, we show that a quantum superposition of spatially displaced mixed cat states can be generated within an optical waveguide via nonparaxial unitary evolution of the initial low coherence (low purity) light beam. It is shown that highly mixed Schrodinger cat states can be observed at a well-defined propagation distance. The importance of the long-term decoherence and recoherence of the original wave packet in observing the mixed cat states is demonstrated. The Heisenberg and Schrodinger-Robertson uncertainty relations for mixed cat states are evaluated. We have demonstrated the feasibility of our method using accurate numerical simulations for the parameters of the source and optical waveguide available in practice.

</details>


### [76] [Quantum Circuit Equivalence Checking: A Tractable Bridge From Unitary to Hybrid Circuits](https://arxiv.org/abs/2511.22523)
*Jérome Ricciardi,Sébastien Bardin,Christophe Chareton,Benoît Valiron*

Main category: quant-ph

TL;DR: 提出一种基于延迟测量的量子混合电路等价性检查方法，显著优于现有方法，能处理更大范围的混合电路等价问题


<details>
  <summary>Details</summary>
Motivation: 量子编译器链中普遍存在电路变换，需要自动化检查混合量子电路的等价性。现有方法大多只关注单一酉电路，而实际量子计算需要包含测量算子的混合电路，且现有混合电路方法适用范围有限

Method: 通过延迟测量变换将酉电路验证提升到混合电路验证，并加入分离和投影等酉级技术来处理更大类别的混合电路等价问题

Result: 该方法显著优于先前工作，能处理更大范围的混合电路等价问题，在标准电路变换（如隐形传态、单向测量、IBM Qiskit编译器）上验证了其有效性，并发现了Qiskit编译器的多个意外行为

Conclusion: 提出的基于延迟测量的混合电路等价性检查方法有效解决了现有方法的局限性，为量子编译器验证提供了有力工具

Abstract: Equivalence checking of hybrid quantum circuits is of primary importance, given that quantum circuit transformations are omnipresent along the quantum compiler chain. While some approaches exist for automating this task, most focus on the simple case of unitary circuits. At the same time, real quantum computing requires hybrid circuits equipped with measurement operators. Moreover, the few approaches targeting the hybrid case are limited to a restricted class of problems. We propose tackling the Quantum Hybrid Circuit Equivalence Checking problem through lifting unitary circuit verification using a transformation known as deferred measurement. We show that this approach alone significantly outperforms prior work, and that, with the addition of specific unitary-level techniques we call separation and projection, it can handle much larger classes of hybrid circuit equivalence problems. We have implemented and evaluated our method over standard circuit transformations such as teleportation, one-way measurement, or the IBM Qiskit compiler, demonstrating its promises. As a side finding, we have identified and reported several unexpected behaviours with the Qiskit compiler.

</details>


### [77] [Graphical Tests of Causality](https://arxiv.org/abs/2511.22552)
*Ämin Baumeler,Eleftherios-Ermis Tselentis,Stefan Wolf*

Main category: quant-ph

TL;DR: 论文提出了针对通信参与方的因果不等式，类似于Bell不等式，适用于静态因果序、确定因果序和双因果序，对应有向图中的通信游戏获胜概率上界。


<details>
  <summary>Details</summary>
Motivation: Bell不等式限制了非通信参与方的可能观测结果，但缺乏针对通信参与方的类似理论。本文旨在为不同因果约束下的通信参与方建立类似的不等式理论。

Method: 通过有向图游戏定义不等式：给定特定有向图，参与方需要在随机选择的弧上进行通信。针对确定因果序的情况，所有游戏都由kefalopoda有向图定义，并基于此定义弱因果相关性。

Result: 推导出的不等式非常简单，对应有向图游戏中获胜概率的上界。对于确定因果序，所有游戏都由kefalopoda有向图指定。证明判断相关性是否为弱因果的问题在参与方数量上是多项式时间可解的。

Conclusion: 本文建立了通信参与方的因果不等式理论，类似于Bell不等式，为不同因果约束下的通信系统提供了理论框架，并展示了弱因果相关性的可判定性。

Abstract: Bell inequalities limit the possible observations of non-communicating parties. Here, we present analogous inequalities for any number of communicating parties under the causal constraints of static causal order, definite causal order, and bi-causal order. All derived inequalities are remarkably simple. They correspond to upper bounds on the winning chance in graphical games: Given a specific directed graph over the parties, the parties are challenged to communicate along a randomly chosen arc. In the case of definite causal order, every game that we find is specified by a kefalopoda digraph. Based on this we define weakly causal correlations as those that satisfy all kefalopoda inequalities. We show that the problem of deciding whether some correlations are weakly causal is solvable in polynomial time in the number of parties.

</details>


### [78] [Tunable and nonlinearity-enhanced dispersive-plus-dissipative coupling in photon-pressure circuits](https://arxiv.org/abs/2511.22571)
*Mohamad Kazouini,Janis Peter,Zisu Emily Guo,Benedikt Wilde,Kevin Uhl,Dieter Koelle,Reinhold Kleiner,Daniel Bothner*

Main category: quant-ph

TL;DR: 该论文实现了一个光子压力平台，其中GHz电路通过磁通可调的色散和耗散光子压力与MHz电路相互作用，展示了多光子耦合率增强和Fano-like响应等新特性。


<details>
  <summary>Details</summary>
Motivation: 光子压力电路作为腔光机械哈密顿量的电路实现，在量子比特读取、低频量子光子学和暗物质轴子探测中有重要应用。超导电路的设计灵活性为探索光机械哈密顿量的非常规参数体系提供了可能。

Method: 实现了一个光子压力平台，其中GHz电路通过磁通可调的色散和耗散光子压力与MHz电路相互作用。利用GHz模式的非线性显著增强了两种耦合率，导致多光子耦合率随泵浦光子数的依赖关系强于通常的√n_c。

Result: 展示了两种相互作用路径的干涉导致光子压力诱导透明中出现Fano-like响应，并且动态反作用相比色散情况有显著改变，包括由红失谐泵浦音调引起的参数不稳定性。

Conclusion: 该工作为探索光机械系统的非常规参数体系提供了新的平台，展示了色散和耗散光子压力相互作用的新现象，为量子信息处理和基础物理研究开辟了新途径。

Abstract: Photon-pressure circuits are the circuit implementation of the cavity optomechanical Hamiltonian and discussed for qubit readout, low-frequency quantum photonics and dark matter axion detection. Due to the enormous design flexibility of superconducting circuits, photon-pressure systems provide fascinating possibilities to explore unusual parameter regimes of the optomechanical Hamiltonian. Here, we report the realization of a photon-pressure platform, in which a GHz circuit interacts with a MHz circuit via a magnetic-flux-tunable combination of dispersive and dissipative photon-pressure. In addition, both coupling rates are considerably enhanced by nonlinearities of the GHz-mode, which leads to the multi-photon coupling rates scaling stronger with the pump photon number $n_\mathrm{c}$ than the usual $\sqrt{n_\mathrm{c}}$ dependence. We demonstrate that interference of the two interaction paths leads to a Fano-like response in photon-pressure induced transparency, and that the dynamical backaction is considerably modified compared to the dispersive case, including a parametric instability caused by a red-detuned pump tone.

</details>


### [79] [Superconducting Qubit Gates Robust to Parameter Fluctuations](https://arxiv.org/abs/2511.22580)
*Emily Wright,Leo Van Damme,Niklas J. Glaser,Amit Devra,Federico A. Roy,Julian Englhardt,Niklas Bruckmoser,Leon Koch,Achim Marx,Johannes Schirk,Christian M. F. Schneider,Lasse Södergren,Florian Wallner,Steffen J. Glaser,Max Werninghaus,Stefan Filipp*

Main category: quant-ph

TL;DR: 该论文开发了针对超导transmon量子比特的鲁棒单量子比特门，使用GRAPE算法设计脉冲，能够有效抑制振幅和频率误差，相比传统DRAG方法在抗干扰性能上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 虽然超导transmon量子比特的单量子比特门已达到容错计算所需的保真度，但量子比特不稳定性、环境变化和控制不准确性导致的参数波动使得难以维持这种性能。需要开发能够抵抗参数变化的鲁棒门操作。

Method: 使用梯度上升脉冲工程（GRAPE）算法数值推导对振幅和频率误差具有鲁棒性的门操作。分析量子比特频率、驱动振幅和相干性波动随时间对门性能的影响。

Result: 鲁棒脉冲对驱动振幅漂移引起的相干误差的抑制效果比带DRAG校正的高斯脉冲强15倍以上。此外，这些鲁棒门不仅对静态误差有效，对随机时变噪声也表现出韧性，在退相干时间增加时抑制误差的效果比DRAG强1.7倍。

Conclusion: 通过GRAPE设计的鲁棒脉冲能够显著提高超导transmon量子比特门操作在参数波动和噪声环境下的性能，为实现更可靠的量子计算提供了有效解决方案。

Abstract: State-of-the-art single-qubit gates on superconducting transmon qubits can achieve the fidelities required for error-corrected computations. However, parameter fluctuations due to qubit instabilities, environmental changes, and control inaccuracies make it difficult to maintain this performance. To mitigate the effects of these parameter variations, we numerically derive gates robust to amplitude and frequency errors using gradient ascent pulse engineering (GRAPE). We analyze how fluctuations in qubit frequency, drive amplitude, and coherence affect gate performance over time. The robust pulses suppress coherent errors from drive amplitude drifts over 15 times more than a Gaussian pulse with derivative removal by adiabatic gate (DRAG) corrections. Furthermore, the robust gates, originally designed to compensate for quasi-static errors, also demonstrate resilience to stochastic, time-dependent noise, which is reflected in the dephasing time. They suppress added errors during increases in dephasing by up to 1.7 times more than DRAG.

</details>


### [80] [An Optimal Framework for Constructing Lie-Algebra Generator Pools: Application to Variational Quantum Eigensolvers for Chemistry](https://arxiv.org/abs/2511.22593)
*Yaromir Viswanathan,Olivier Adjoua,César Feniou,Siwar Badreddine,Jean-Philip Piquemal*

Main category: quant-ph

TL;DR: 提出多项式复杂度算法高效构建李代数的最小生成元集(MCPs)，应用于量子化学变分算法，减少量子资源并改进强关联体系收敛


<details>
  <summary>Details</summary>
Motivation: 传统寻找李代数生成元的方法基于贪婪构造步骤，需要处理指数增长的候选算子，计算复杂度高且难以处理。需要一种高效、多项式复杂度的最优策略来构建最小生成元集，特别是在量子化学变分算法中需要高效构建满足费米子代数的用户定义MCPs

Method: 基于李代数的基本性质，提出通用、多项式复杂度且最优的策略，能够高效构建目标李代数的最小生成元集(MCPs)。将该方法应用于量子化学，开发MB-ADAPT-VQE算法，将最优构建的MCPs集成到批处理ADAPT-VQE中

Result: 提出的算法能够多项式复杂度构建MCPs，显著减少量子资源需求，在强关联体系中改进收敛性。这些MCPs还启用了基于李代数结构的固定ansatz方法，如梯度自由的NI-DUCC-VQE，能够超越先前MCP限制进行模拟

Conclusion: 提出的数学框架具有通用性，不仅适用于量子化学，还可应用于量子纠错、量子控制、量子机器学习等领域，以及任何需要紧凑泡利基的场合，为解决李代数生成元构建的计算瓶颈提供了有效方案

Abstract: Lie Algebras are powerful mathematical structures used in physics to describe sets of operators and associated combinations. A central task is to identify a minimal set of generators from which the algebra can be constructed. The classical search for such generators has so far relied on greedy construction steps applied to an exponentially growing number of candidate operators, making it rapidly computationally intractable. We propose a general, polynomial-scaling and optimal strategy, based on Lie-Algebraic basic properties, to overcome this bottleneck. It allows for the efficient construction of these generators, also known as Minimal Complete Pools (MCPs), for a target Lie Algebra. As an immediate application, efficiently constructing user-defined MCPs that respect fermionic algebra is crucial in the context of adaptive Variational Quantum Eigensolver for quantum chemistry. Thus, we introduce MB-ADAPT-VQE, which incorporates optimally constructed MCPs into batched ADAPT-VQE to reduce quantum resources and improve convergence under strong correlation. These MCPs also unlock fixed-ansatz methods based on a Lie-algebraic structure such as the gradient-free NI-DUCC-VQE, enabling simulations surpassing prior MCP limits. The presented mathematical framework is general and applicable well beyond chemistry in fields including quantum error correction, quantum control, quantum machine learning, and more universally wherever compact Pauli basis are required.

</details>


### [81] [High-yield engineering of modified divacancies in 4H-SiC via oxygen-ion implantation](https://arxiv.org/abs/2511.22608)
*Qi-Cheng Hu,Ji-Yang Zhou,Shuo Ren,Zhen-Xuan He,Zhi-He Hao,Rui-Jian Liang,Wu-Xi Lin,Adam Gali,Jin-Shi Xu,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 通过氧离子注入在4H-SiC中高效生成改性双空位色心，实现90%以上的单缺陷占比，展现出优异的光学性质和自旋相干性，为可扩展固态量子技术提供新途径。


<details>
  <summary>Details</summary>
Motivation: 4H-SiC中的改性双空位色心在室温下具有增强的电荷稳定性和自旋可寻址性，但传统方法制备效率低，限制了其在量子应用中的发展。

Method: 采用氧离子注入技术可控高效地生成改性双空位色心，通过系统优化注入剂量和退火温度，利用光学特征和自旋共振特性识别四种不同类型的改性双空位。

Result: 实现了90%以上的单改性双空位占比，光学性质和自旋相干性优于传统碳/氮离子注入方法；表征了零声子线，揭示了自旋读出对比度的温度依赖性；制备了高密度系综并观察到清晰的Rabi振荡拍频模式。

Conclusion: 氧离子注入是工程化高质量自旋活性缺陷的强大方法，为可扩展固态量子技术提供了重要进展，同时为理解4H-SiC中改性双空位的原子构型提供了关键见解。

Abstract: Modified divacancies in the 4H polytype of silicon carbide (SiC) exhibit enhanced charge stability and spin addressability at room temperature, making them highly attractive for quantum applications. However, their low formation yield, both at the single-defect and ensemble levels, has limited further progress. Here, we demonstrate a controllable and efficient method for generating modified divacancy color centers in 4H-SiC via oxygen-ion implantation. Based on their distinct optical signatures and spin-resonance characteristics, we experimentally resolve four types of modified divacancies. Remarkably, single modified divacancies constitute above 90% of the total defect population and exhibit superior optical properties and spin coherence compared with defects created through conventional carbon- or nitrogen-ion implantation. We characterize the zero-phonon lines of these modified divacancies and reveal a distinct temperature-dependent behavior in the spin-readout contrast. By systematically optimizing the implantation dose and annealing temperature, we further achieve high-density ensembles and observe clear Rabi-oscillation beating patterns associated with different orientations of basal-type defects. These results establish oxygen-ion implantation as a powerful and versatile approach to engineering high-quality spin-active defects in SiC, representing a significant advance toward scalable solid-state quantum technologies. Furthermore, our findings provide key insights into the atomic configurations of modified divacancies in 4H-SiC.

</details>


### [82] [Recursive Clifford noise reduction](https://arxiv.org/abs/2511.22624)
*Aharon Brodutch,Gregory Baimetov,Edwin Tham,Nicolas Delfosse*

Main category: quant-ph

TL;DR: 递归版CliNR通过分层纠错方案，以较小门开销显著降低大型Clifford电路的逻辑错误率


<details>
  <summary>Details</summary>
Motivation: 原始CliNR方案在电路规模较大时纠错效果有限，需要开发能处理更大电路且保持较小开销的改进方案

Method: 提出递归版CliNR，采用分层纠错策略，当np→0时逻辑错误率可趋近于零，需要(2⌈log(sp)⌉+3)n+1个量子比特和最多24s⌈(sp)^4⌉个门

Result: 数值模拟显示递归方法在近期实用参数范围内具有优势，当电路规模足够大时，递归CliNR能以相同门开销达到比原始CliNR更低的逻辑错误率

Conclusion: 递归CliNR为以相对较小开销降低大型Clifford电路逻辑错误率提供了有前景的方案

Abstract: Clifford noise reduction (CliNR) is a partial error correction scheme that reduces the logical error rate of Clifford circuits at the cost of a modest qubit and gate overhead. The CliNR implementation of an $n$-qubit Clifford circuit of size $s$ achieves a vanishing logical error rate if $snp^2\rightarrow 0$ where $p$ is the physical error rate. Here, we propose a recursive version of CliNR that can reduce errors on larger circuits with a relatively small gate overhead. When $np \rightarrow 0$, the logical error rate can be vanishingly small. This implementation requires $\left(2\left\lceil \log(sp)\right\rceil+3\right)n+1$ qubits and at most $24 s \left\lceil(sp)^4\right\rceil $ gates. Using numerical simulations, we show that the recursive method can offer an advantage in a realistic near-term parameter regime. When circuit sizes are large enough, recursive CliNR can reach a lower logical error rate than the original CliNR with the same gate overhead. The results offer promise for reducing logical errors in large Clifford circuits with relatively small overheads.

</details>


### [83] [A reconciliation of the Pryce-Ward and Klein-Nishina statistics for semi-classical simulations of annihilation photons correlations](https://arxiv.org/abs/2511.22630)
*Petar Žugec,Eric Andreas Vivoda,Mihael Makek,Ivica Friščić*

Main category: quant-ph

TL;DR: 正电子素湮灭产生的纠缠光子对在康普顿散射中表现出量子关联增强，与经典独立散射模型不同，但通过半经典模拟可以调和两种描述。


<details>
  <summary>Details</summary>
Motivation: 研究纠缠光子对的康普顿散射特性，探索量子纠缠如何影响散射过程，并解决Pryce-Ward量子描述与Klein-Nishina经典描述之间的矛盾。

Method: 使用正电子素湮灭产生的纠缠光子对，分析其康普顿散射的方位角关联，比较量子纠缠描述（Pryce-Ward截面）与经典独立散射描述（Klein-Nishina截面），并通过半经典模拟实现两种描述的调和。

Result: 纠缠光子对的康普顿散射表现出增强的方位角关联，量子描述与经典描述相互排斥，但通过修改的散射截面可以在半经典模拟中调和两种统计结果。

Conclusion: 量子纠缠显著影响光子对的散射行为，虽然量子描述与经典描述在理论上矛盾，但通过适当的半经典处理方法可以实现实验观测与理论预测的一致性。

Abstract: Two photons from the ground state para-positronium annihilation are emitted in a maximally entangled singlet state of orthogonal polarizations. In case of the Compton scattering of both photons the phenomenon of quantum entanglement leads to a measurable increase in the azimuthal correlations of scattered photons, as opposed to a classical description treating the two scattering events as independent. The probability of the scattering of the system of the entangled photons is described by the Pryce-Ward cross section dependent on a difference of the azimuthal scattering angles in the fixed coordinate frame, while the independent scattering of single photons is described by the Klein-Nishina cross section dependent on the azimuthal angle relative to each photon's initial polarization. Since the singlet state of orthogonal polarizations is rotationally invariant, it does not carry any physical information on the initial polarizations of the single annihilation photons. In such bipartite state the angular origin for the Klein-Nishina cross section is undefined, making the Pryce-Ward and Klein-Nishina descriptions mutually exclusive. However, semi-classical simulations of the joint Compton scattering of entangled photons - implementing the Pryce-Ward cross section, but still treating the two photons as separate entities - can reconcile the Pryce-Ward correlations with the Klein-Nishina statistics for single photons by implementing a modified version of a scattering cross section presented in this work.

</details>


### [84] [Out-of-Time-Order Correlator Spectroscopy](https://arxiv.org/abs/2511.22654)
*Keisuke Fujii*

Main category: quant-ph

TL;DR: 该论文将高阶OTOCs与量子信号处理框架统一，揭示了OTOCs测量截断传播子奇异值相位分布的傅里叶分量，并基于此提出OTOC光谱学作为探测量子多体动力学的新工具。


<details>
  <summary>Details</summary>
Motivation: 高阶OTOCs是量子混沌和量子优势基准测试的关键探针，但其行为缺乏统一的算法解释。需要建立OTOCs与现有量子计算框架的理论联系，以更好地理解其对不同动力学机制的敏感性差异。

Method: 将高阶OTOCs纳入量子信号处理框架，证明每个OTOC^(k)测量空间分辨截断传播子奇异值相位分布的2k阶傅里叶分量。通过奇异值的多项式变换推广高阶OTOCs，构建频率选择性滤波器，实现OTOC光谱学。

Result: 建立了OTOCs与量子信号处理的统一理论框架，解释了TOCs和高阶OTOCs对因果锥结构和混沌/可积/局域化动力学的不同敏感性。提出的OTOC光谱学能够作为模式分辨工具探测量子多体动力学的混沌和谱结构。

Conclusion: 该工作为高阶OTOCs提供了统一的算法解释，将其与量子信号处理框架联系起来。提出的OTOC光谱学扩展了传统OTOCs的功能，使其成为探测量子多体动力学谱结构的强大工具，为量子混沌和量子优势研究提供了新方法。

Abstract: Out-of-time-order correlators (OTOCs) are central probes of quantum scrambling, and their generalizations have recently become key primitives for both benchmarking quantum advantage and learning the structure of Hamiltonians. Yet their behavior has lacked a unified algorithmic interpretation. We show that higher-order OTOCs naturally fit within the framework of quantum signal processing (QSP): each $\mathrm{OTOC}^{(k)}$ measures the $2k$-th Fourier component of the phase distribution associated with the singular values of a spatially resolved truncated propagator. This explains the contrasting sensitivities of time-ordered correlators (TOCs) and higher-order OTOCs to causal-cone structure and to chaotic, integrable, or localized dynamics. Based on this understanding, we further generalize higher-order OTOCs by polynomial transformation of the singular values of the spatially resolved truncated propagator. The resultant signal allows us to construct frequency-selective filters, which we call \emph{OTOC spectroscopy}. This extends conventional OTOCs into a mode-resolved tool for probing scrambling and spectral structure of quantum many-body dynamics.

</details>


### [85] [Foundations of Quantum Granular Computing with Effect-Based Granules, Algebraic Properties and Reference Architectures](https://arxiv.org/abs/2511.22679)
*Oscar Montiel Ross*

Main category: quant-ph

TL;DR: 该论文建立了量子粒度计算（QGC）的基础，将经典粒度计算（包括模糊、粗糙和阴影粒度）扩展到量子领域，用量子效应算子建模粒度，为量子信息处理提供统一的数学基础。


<details>
  <summary>Details</summary>
Motivation: 将经典粒度计算扩展到量子领域，为量子信息处理、粒度推理和智能系统提供统一的数学基础，同时保持与近期量子硬件的兼容性。

Method: 用量子效应算子（有限维希尔伯特空间上的效应）建模量子粒度，建立基于效应的量子粒度基础理论，包括归一化、单调性、布尔岛、Lüders更新下的粒度细化等，并引入量子粒度决策系统（QGDS）的三种参考架构。

Result: 建立了量子粒度计算的理论基础，展示了如何用量子效应算子统一表示尖锐（投影）和软（非投影）粒度，连接了量子检测与估计理论，并通过量子比特粒度化、两量子比特奇偶效应和Helstrom风格软决策等案例研究验证了框架的有效性。

Conclusion: 量子粒度计算为量子信息处理中的算子值粒度提供了一个统一且数学基础扎实的框架，能够再现模糊式的分级隶属度和平滑决策边界，同时利用非对易性、上下文性和纠缠等量子特性。

Abstract: This paper develops the foundations of Quantum Granular Computing (QGC), extending classical granular computing including fuzzy, rough, and shadowed granules to the quantum regime. Quantum granules are modeled as effects on a finite dimensional Hilbert space, so granular memberships are given by Born probabilities. This operator theoretic viewpoint provides a common language for sharp (projective) and soft (nonprojective) granules and embeds granulation directly into the standard formalism of quantum information theory. We establish foundational results for effect based quantum granules, including normalization and monotonicity properties, the emergence of Boolean islands from commuting families, granular refinement under Luders updates, and the evolution of granules under quantum channels via the adjoint channel in the Heisenberg picture. We connect QGC with quantum detection and estimation theory by interpreting the effect operators realizing Helstrom minimum error measurement for binary state discrimination as Helstrom type decision granules, i.e., soft quantum counterparts of Bayes optimal decision regions. Building on these results, we introduce Quantum Granular Decision Systems (QGDS) with three reference architectures that specify how quantum granules can be defined, learned, and integrated with classical components while remaining compatible with near term quantum hardware. Case studies on qubit granulation, two qubit parity effects, and Helstrom style soft decisions illustrate how QGC reproduces fuzzy like graded memberships and smooth decision boundaries while exploiting noncommutativity, contextuality, and entanglement. The framework thus provides a unified and mathematically grounded basis for operator valued granules in quantum information processing, granular reasoning, and intelligent systems.

</details>


### [86] [OPI x Soft Decoders](https://arxiv.org/abs/2511.22691)
*André Chailloux*

Main category: quant-ph

TL;DR: 该研究将量子算法中的两种不同方法（Jordan等人的结构化码方法和Chailloux-Tillich的软解码器方法）进行统一，通过码的语言重新表述格基约简，在伯努利噪声模型下恢复Jordan等人的结果，并将更强的软解码器整合到OPI框架中，获得改进的算法。


<details>
  <summary>Details</summary>
Motivation: 近年来量子算法研究关注Regev约简启发的码和格问题算法。现有两种不同方法：Jordan等人利用结构化码展示量子优势，Chailloux和Tillich使用更强的软解码器但限于特定OPI设置。需要统一这两种方法，简化分析并整合优势。

Method: 1. 基于Chailloux和Hermouet在格基设置下的约简公式，用码的语言重新表述；2. 在伯努利噪声模型下恢复Jordan等人的结果，简化分析；3. 将Chailloux和Tillich的更强软解码器整合到OPI框架中。

Result: 成功统一了两种量子算法方法，在伯努利噪声模型下恢复了Jordan等人的结果，并将更强的软解码器整合到OPI框架中，获得了改进的算法。

Conclusion: 该工作通过码的语言重新表述格基约简，统一了量子算法中两种不同方法，简化了分析并整合了各自优势，为量子算法在码和格问题中的应用提供了更强大的框架。

Abstract: In recent years, a particularly interesting line of research has focused on designing quantum algorithms for code and lattice problems inspired by Regev's reduction. The core idea is to use a decoder for a given code to find short codewords in its dual. For example, Jordan et al. demonstrated how structured codes can be used in this framework to exhibit some quantum advantage. In particular, they showed how the classical decodability of Reed-Solomon codes can be leveraged to solve the Optimal Polynomial Intersection (OPI) problem quantumly. This approach was further improved by Chailloux and Tillich using stronger soft decoders, though their analysis was restricted to a specific setting of OPI. In this work, we reconcile these two approaches. We build on a recent formulation of the reduction by Chailloux and Hermouet in the lattice-based setting, which we rewrite in the language of codes. With this reduction, we show that the results of Jordan et al. can be recovered under Bernoulli noise models, simplifying the analysis. This characterization then allows us to integrate the stronger soft decoders of Chailloux and Tillich into the OPI framework, yielding improved algorithms.

</details>


### [87] [Distributed quantum architecture search using multi-agent reinforcement learning](https://arxiv.org/abs/2511.22708)
*Mikhail Sergeev,Georgii Paradezhenko,Daniil Rabinovich,Vladimir V. Palyulin*

Main category: quant-ph

TL;DR: 提出了一种新颖的多智能体强化学习算法用于量子架构搜索，通过将量子电路分解为多个智能体分别控制的模块，显著加速收敛并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的量子架构搜索方法都是单智能体方法，随着量子比特数量增加，动作空间维度和计算成本急剧上升，导致可扩展性差。需要一种更高效、可扩展的方法来设计变分量子电路的架构。

Method: 提出多智能体强化学习算法，每个智能体独立控制量子电路的一个模块（块）。这种分解方法允许并行化处理，减少每个智能体的动作空间维度，从而加速训练过程。

Result: 在3-正则图的MaxCut问题和Schwinger哈密顿量的基态能量估计问题上进行了基准测试，证明该方法能显著加速强化学习量子架构搜索的收敛速度并降低计算成本。

Conclusion: 多智能体方法不仅提高了量子架构搜索的效率，还自然契合分布式量子计算的架构，有利于在现代中等规模量子设备上实现。

Abstract: Quantum architecture search (QAS) automates the design of parameterized quantum circuits for variational quantum algorithms. The framework finds a well-suited problem-specific structure of a variational ansatz. Among possible implementations of QAS the reinforcement learning (RL) stands out as one of the most promising. Current RL approaches are single-agent-based and show poor scalability with a number of qubits due to the increase of the action space dimension and the computational cost. We propose a novel multi-agent RL algorithm for QAS with each agent acting separately on its own block of a quantum circuit. This procedure allows to significantly accelerate the convergence of the RL-based QAS and reduce its computational cost. We benchmark the proposed algorithm on MaxCut problem on 3-regular graphs and on ground energy estimation for the Schwinger Hamiltonian. In addition, the proposed multi-agent approach naturally fits into the set-up of distributed quantum computing, favoring its implementation on modern intermediate scale quantum devices.

</details>


### [88] [Qubit Reuse Beyond Reorder and Reset: Optimizing Quantum Circuits by Fully Utilizing the Potential of Dynamic Circuits](https://arxiv.org/abs/2511.22712)
*Damian Rovara,Lukas Burgholzer,Robert Wille*

Main category: quant-ph

TL;DR: 提出一种通过动态量子电路优化量子比特重用的方法，显著减少量子电路所需的量子比特数量


<details>
  <summary>Details</summary>
Motivation: 现有量子比特重用方法主要局限于重新排序测量和应用量子比特重置，需要更充分利用动态量子电路的潜力来进一步优化量子电路

Method: 通过移动测量位置和引入经典控制门等动态电路原语，创建全新的量子比特重用路径，充分利用动态量子电路的潜力

Result: 显著减少了多种电路的量子比特需求，在现有方法无法优化的量子相位估计、量子傅里叶变换、变分量子本征求解器等流行电路中表现出色，对稀疏随机电路的改进高达95%

Conclusion: 该方法大幅超越了现有方法，为在量子比特数量有限的近期设备上运行复杂电路创造了新机会

Abstract: Qubit reuse offers a promising way to reduce the hardware demands of quantum circuits, but current approaches are largely restricted to reordering measurements and applying qubit resets. In this work, we present an approach to further optimize quantum circuits by fully utilizing the potential of dynamic quantum circuits-more precisely by moving measurements and introducing dynamic circuit primitives such as classically controlled gates in a way that forges entirely new pathways for qubit reuse. This significantly reduces the number of required qubits for a variety of circuits, creating new opportunities for running complex circuits on near-term devices with limited qubit counts. We show that the proposed approach drastically outperforms existing methods, reducing qubit requirements where previous approaches are unable to do so for popular quantum circuits such as Quantum Phase Estimation (QPE), Quantum Fourier Transform~(QFT), and Variational Quantum Eigensolver (VQE) ansätze, as well as leading to improvements of up to 95% for sparse random circuits.

</details>


### [89] [Raising the Cavity Frequency in cQED](https://arxiv.org/abs/2511.22764)
*Raymond A. Mencia,Taketo Imaizumi,Igor A. Golovchanskiy,Andrea Lizzit,Vladimir E. Manucharyan*

Main category: quant-ph

TL;DR: 首次实现腔频率高达21GHz的电路量子电动力学系统，保持5GHz量子比特，展示了大失谐下MHz量级色散位移、8%读取量子效率、超过100μs的相干时间等优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统cQED系统中腔频率通常局限在7GHz附近，限制了系统性能优化。本研究旨在探索高频率腔的潜在优势，同时保持现有量子比特功能不受影响。

Method: 采用常规约5GHz频率的transmon量子比特，但将腔的基本模式频率提升至21GHz，实现大失谐条件下的强耦合系统。

Result: 1) 大失谐下仍保持MHz量级色散位移；2) 量子比特读取量子效率达8%；3) 能量弛豫品质因子超过10^7；4) 相干时间超过100μs，单回波π脉冲校正可达300μs；5) 通过后选择实现2×10^-3的初始化误差和4×10^-3的状态分配误差。

Conclusion: 高频率腔cQED系统在不损害量子比特功能的前提下展现出优异性能，鼓励进一步探索高频率腔的潜在变革性优势。

Abstract: The basic element of circuit quantum electrodynamics (cQED) is a cavity resonator strongly coupled to a superconducting qubit. Since the inception of the field, the choice of the cavity frequency was, with a few exceptions, been limited to a narrow range around 7 GHz due to a variety of fundamental and practical considerations. Here we report the first cQED implementation, where the qubit remains a regular transmon at about 5 GHz frequency, but the cavity's fundamental mode raises to 21 GHz. We demonstrate that (i) the dispersive shift remains in the conventional MHz range despite the large qubit-cavity detuning, (ii) the quantum efficiency of the qubit readout reaches 8%, (iii) the qubit's energy relaxation quality factor exceeds $10^7$, (iv) the qubit coherence time reproducibly exceeds $100~μ\rm{s}$ and can reach above $300~μ\rm{s}$ with a single echoing $π$-pulse correction. The readout error is currently limited by an accidental resonant excitation of a non-computational state, the elimination of which requires minor adjustments to the device parameters. Nevertheless, we were able to initialize the qubit in a repeated measurement by post-selection with $2\times 10^{-3}$ error and achieve $4\times 10^{-3}$ state assignment error. These results encourage in-depth explorations of potentially transformative advantages of high-frequency cavities without compromising existing qubit functionality.

</details>


### [90] [Extensive search of Shannon entropy-based randomness certification protocols](https://arxiv.org/abs/2511.22771)
*Robert Okuła,Piotr Mironowicz*

Main category: quant-ph

TL;DR: 提出一种量化分析贝尔表达式的方法，用于认证量子随机数生成中的随机性，并对超过50万个贝尔表达式进行了全面分析，识别出五个在噪声环境下具有优秀熵分数的例子。


<details>
  <summary>Details</summary>
Motivation: 量子技术在处理和通信领域具有显著优势，特别是在随机数生成方面。利用贝尔不等式可以验证不可信量子RNG设备输出的随机性，但需要更系统的方法来量化分析这些贝尔表达式。

Method: 开发了一种量化分析贝尔表达式的方法，用于认证量子系统中的随机性。分析了超过50万个贝尔表达式，涉及一方4个测量设置、另一方3个测量设置的配置。基于白噪声水平下的熵分数识别出五个显著例子，并进一步结合自测试概念进行更全面的量子关联表征。

Result: 通过对大规模贝尔表达式的系统分析，识别出五个在噪声环境下表现优异的例子。结合自测试框架，能够更全面地评估量子关联特性，为量子随机数生成的认证提供了更强大的工具。

Conclusion: 提出的量化分析方法能够有效评估贝尔表达式在认证量子随机性方面的性能，结合自测试概念进一步增强了量子关联的表征能力，为量子随机数生成的可靠认证提供了系统框架。

Abstract: Quantum technologies offer significant advancements in information processing and communication, notably in the domain of random number generation (RNG). The use of Bell inequalities enables users to certify the randomness of outputs produced by untrusted quantum RNG devices. We present a method for quantitatively analyzing Bell expressions used to certify randomness in quantum systems. Using this method, we conducted a comprehensive analysis on more than half a million Bell expressions involving configurations with four measurement settings for one party and three for the other. We identified five notable examples based on entropy scores under varying levels of white noise. As an extension of these results, we further incorporate the concept of self-testing for boxes (Banacki et al 2022, New J. Phys. 24 083003), enabling a more comprehensive characterization of quantum correlations through the evaluation of $Boxes(α, B)$ and the corresponding measure $Flex(α, B)$.

</details>


### [91] [Delayed Choice Quantum Erasure Experiment Revisited: Causality and Informational Coherence](https://arxiv.org/abs/2511.22827)
*Taku Ohwada*

Main category: quant-ph

TL;DR: 首次实现真正延迟选择的量子擦除实验，利用多模量子存储器确保选择操作严格在观测事件之后，通过单光子干涉测量直接区分因果性和信息性相干假设


<details>
  <summary>Details</summary>
Motivation: 解决传统量子擦除实验中"延迟选择"是否真正延迟的问题，提出操作上明确定义的实验方案，以区分量子相干性的因果解释和信息解释

Method: 使用多模量子存储器提供可控且可验证的延迟，确保选择操作严格在观测事件之后；采用电子单光子干涉检测测量，基于边际检测统计而不需要后选择

Result: 实现了真正的延迟选择，提供了直接统计区分器来区分因果相干假设和信息相干假设；检测统计的泊松结构允许跨重复操作单元积累统计量

Conclusion: 该方案在现有量子光学技术下是实用且实验可行的，首次实现了操作上明确定义的延迟选择量子擦除实验

Abstract: We propose an operationally well-defined delayed-choice quantum-erasure experiment that realizes, for the first time, a genuine delayed choice within presently available quantum-optical technology. A multimode quantum memory supplies a controlled and verifiable delay, ensuring that the choice operation is applied strictly after the observation event. Electronic single-photon interference detection measurements then furnish a direct statistical discriminator between the causal and informational coherence hypotheses, based solely on marginal detection statistics and without any post-selection. The Poissonian structure of the detection statistics allows accumulation of statistics across repeated operational units, rendering the proposal practical and experimentally feasible.

</details>


### [92] [Nonreciprocal transmission in a cavity-magnon system by rotational Sagnac effect](https://arxiv.org/abs/2511.22830)
*Zhe-Qi Yang,Si-Qi Lin,Zhi-Rong Zhong*

Main category: quant-ph

TL;DR: 在腔-磁子系统中实现了超高非互易传输，通过Sagnac效应实现单向光传输，隔离比超过40dB，是目前报道的最高值。


<details>
  <summary>Details</summary>
Motivation: 开发高性能、可调谐、紧凑的光学非互易器件，实现高效的单向光传输，同时抑制反向传播。

Method: 使用包含两个回音壁模式和一个磁子模式的腔-磁子系统，利用Sagnac效应产生的非互易频移实现单向传输，并通过压缩磁子模式增强隔离性能。

Result: 在实验可及参数范围内，光学隔离比超过40dB，是目前报道的最高隔离比；通过压缩磁子模式可进一步增强隔离性能；通过改变回音壁腔的旋转方向可反转光隔离的方向性。

Conclusion: 该研究为开发高性能、可调谐、紧凑的光学非互易器件提供了有前景的途径，实现了超高非互易传输和方向性控制。

Abstract: Ultrahigh nonreciprocal transmission has been achieved in a cavity-magnon system, which consists of two whispering gallery modes (WGMs) and a single magnon mode within a magnetic insulator yttrium iron garnet sphere. The nonreciprocal frequency shift induced by the Sagnac effect enables unidirectional transmission of an input field, while suppressing propagation in the opposite direction, thereby facilitating nonreciprocal optical transmission. Within experimentally accessible parameter regimes, the optical isolation ratio can exceed 40 dB, representing the highest isolation ratio reported to date. Furthermore, applying squeezing to the magnon mode further enhances this isolation performance. Additionally, the directionality of light isolation can be reversed simply by modifying the rotation of the WGM cavity. These findings offer promising prospects for developing high-performance, tunable, and compact optical nonreciprocal devices.

</details>


### [93] [Tunable Single-Photon Transport in a Multi-mode Waveguide via a $Λ$-Type Emitter](https://arxiv.org/abs/2511.22840)
*Yan Liu,Qing-Ao Xiang,Xin-Yuan Yang,Ji-Bing Yuan,Shi-Qing Tang,Xin-Wen Wang,Ya-Ju Song*

Main category: quant-ph

TL;DR: 该研究探索了通过驱动Λ型发射器控制波导中单光子散射，揭示了Fano共振和EIT两种机制分别实现完全反射和完美透射，并在单模和多模体系中展示了动态光谱调控能力。


<details>
  <summary>Details</summary>
Motivation: 精确控制波导量子电动力学中的光子传输对于推进量子信息处理至关重要。研究旨在探索如何通过驱动Λ型发射器来操纵单光子散射，为多模波导中的光子量子控制提供工具箱。

Method: 使用Lippmann-Schwinger形式推导散射矩阵，研究驱动Λ型发射器耦合到矩形波导的系统。分别在单模和多模体系中分析外部驱动参数（失谐和拉比频率）对散射的影响，并探索量子干涉效应。

Result: 发现两种控制机制：Fano共振导致完全反射，电磁感应透明（EIT）实现完美透射。在单模体系中，驱动参数可精确调控反射峰位置和数量；在多模体系中，量子干涉主导散射动力学。特定相干叠加输入可恢复单模行为，实现Fano介导的完全反射。

Conclusion: 该研究为多模波导中的光子量子控制提供了多功能工具箱，为宽带双频滤波器和多模光谱仪等应用铺平了道路，展示了通过驱动Λ型发射器精确调控光子传输的潜力。

Abstract: Precise control of photon transport in waveguide quantum electrodynamics is fundamental to advancing quantum information processing. We investigate the manipulation of single-photon scattering via a driven $Λ$-type emitter coupled to a rectangular waveguide, examining both single- and multi-mode regimes. Using the Lippmann-Schwinger formalism, we derive the scattering matrix and identify two distinct control mechanisms: Fano resonances induce complete reflection, and electromagnetically induce transparency (EIT) induce perfect transmission. In the single-mode regime, the external drive parameters-the detuning and Rabi frequency-precisely tune the positions and number of reflection peaks, allowing dynamic spectral engineering. In the multi-mode regime, quantum interference between modes governs the scattering dynamics. When the input photon is prepared in a specific coherent superposition, multi-mode effects restore single-mode-like behavior, enabling Fano-mediated complete reflection. Conversely, a single-mode input prevents complete reflection even at the Fano resonance, while EIT-driven transmission persists. These results demonstrate a versatile toolbox for photonic quantum control in multi-mode waveguides, paving the way for applications such as broadband dual-frequency filters and multi-mode spectrometers.

</details>


### [94] [Noise-Robustness for Delegated Quantum Computation in the Circuit Model](https://arxiv.org/abs/2511.22844)
*Anne Broadbent,Joshua Nevin*

Main category: quant-ph

TL;DR: 改进可验证量子计算的噪声容忍度阈值，通过交织计算和测试轮次实现


<details>
  <summary>Details</summary>
Motivation: 云量子计算和量子算法快速发展，需要在委托量子计算中解决可验证性问题，同时要考虑当前噪声量子设备的噪声容忍度

Method: 扩展Broadbent的可验证量子计算框架到服务器端噪声场景，通过以不可区分的方式交织计算轮次和测试轮次的协议

Result: 实现了改进的噪声容忍度阈值上限，协议能够抵抗服务器的任意偏差，同时保证对实际噪声的鲁棒性

Conclusion: 提出的协议在保持安全性的同时提高了噪声容忍度，为云量子计算的可验证性提供了更实用的解决方案

Abstract: Cloud-based quantum computing, coupled with the rapid progress in quantum algorithms, brings to the forefront the question of verifiability in delegated quantum computations. In the current landscape of noisy quantum devices, this question must be addressed alongside noise tolerance. In this work, we revisit the circuit-based framework for verifiable quantum computation introduced by Broadbent [Theory of Computing, 2018], and extend it to the setting of server-side noise. Our contribution is an improved upper bound on the noise-tolerance threshold, achieved through a protocol that interleaves computation and test rounds in an indistinguishable manner. This structure enables a concise security proof against arbitrary deviations by the server, while ensuring robustness to realistic noise.

</details>


### [95] [Escaping Barren Plateaus in Variational Quantum Algorithms Using Negative Learning Rate in Quantum Internet of Things](https://arxiv.org/abs/2511.22861)
*Ratun Rahman,Dinh C. Nguyen*

Main category: quant-ph

TL;DR: 提出在量子物联网设备中通过引入负学习率来逃离梯度消失平台的方法，改善变分量子算法在受限设备上的训练效果


<details>
  <summary>Details</summary>
Motivation: 变分量子算法(VQAs)是下一代量子计算机的主要计算原语，但在量子物联网(QIoT)等资源受限设备上执行时，梯度消失平台(barren plateaus)严重限制了学习的可扩展性，导致训练停滞。QIoT端点通常只有少量量子比特、受限的测量次数和严格的延迟要求，这给在QIoT端点上实现VQA智能带来了实际挑战。

Method: 在优化过程中引入负学习率，通过在正负学习阶段之间切换，将受控的不稳定性引入模型训练。这种方法可以恢复显著的梯度并探索损失函数中更平坦的区域。作者从理论上评估了负学习对梯度方差的影响，并提出了有助于逃离梯度消失区域的条件。

Result: 在典型的VQA基准测试中，实验结果显示该方法在收敛性和模拟结果方面相比传统优化器都有持续改进。通过逃离梯度消失平台，该方法为量子-经典混合模型提供了更稳健的优化途径。

Conclusion: 引入负学习率为变分量子算法在量子物联网设备中逃离梯度消失平台提供了一种新颖方法，改善了受限设备上的训练效果，为量子-经典混合模型的稳健优化开辟了新途径。

Abstract: Variational Quantum Algorithms (VQAs) are becoming the primary computational primitive for next-generation quantum computers, particularly those embedded as resource-constrained accelerators in the emerging Quantum Internet of Things (QIoT). However, under such device-constrained execution conditions, the scalability of learning is severely limited by barren plateaus, where gradients collapse to zero and training stalls. This poses a practical challenge to delivering VQA-enabled intelligence on QIoT endpoints, which often have few qubits, constrained shot budgets, and strict latency requirements. In this paper, we present a novel approach for escaping barren plateaus by including negative learning rates into the optimization process in QIoT devices. Our method introduces controlled instability into model training by switching between positive and negative learning phases, allowing recovery of significant gradients and exploring flatter areas in the loss landscape. We theoretically evaluate the effect of negative learning on gradient variance and propose conditions under which it helps escape from barren zones. The experimental findings on typical VQA benchmarks show consistent improvements in both convergence and simulation results over traditional optimizers. By escaping barren plateaus, our approach leads to a novel pathway for robust optimization in quantum-classical hybrid models.

</details>


### [96] [Wave-Particle Complementarity as the Optimal Limit of Unambiguous Quantum-State Discrimination](https://arxiv.org/abs/2511.22871)
*Theerthagiri L*

Main category: quant-ph

TL;DR: 该论文建立了诱导相干干涉中波粒二象性的操作解释，将干涉可见度与最优量子态区分性能联系起来，揭示了区分度受测量最优性限制而非干涉仪几何约束。


<details>
  <summary>Details</summary>
Motivation: 传统上波粒二象性被视为几何约束，本文旨在为诱导相干干涉中的波粒互补性提供操作解释，揭示其本质是测量最优性限制而非几何约束。

Method: 在低增益Zou-Wang-Mandel干涉仪中，将两个SPDC晶体的闲频模作为非正交的晶体标记态，将单光子可见度与最优IDP策略的最小不确定概率联系起来。

Result: 证明单光子可见度等于最优IDP策略的最小不确定概率(V = P_I^{opt})，互补关系D² + V² = 1表达的是测量最优性边界而非几何约束。在热噪声下推导出可见度、保真度和最优区分的层级关系。

Conclusion: 诱导相干中的波粒二象性不受干涉仪几何限制，而是受闲频模零误差区分中测量最优性的限制。区分度本质上是测量受限的，这为区分增强的诱导相干成像和传感提供了理论基础。

Abstract: We establish a direct operational interpretation of wave-particle complementarity in induced-coherence interferometry by linking interference visibility to the optimal performance of unambiguous quantum-state discrimination. In the low-gain Zou-Wang-Mandel interferometer, the idler modes of the two SPDC crystals act as nonorthogonal which-crystal marker states, and we show that the single-photon visibility equals the minimal inconclusive probability of the optimal Ivanovic-Dieks-Peres (IDP) strategy, V = P_I^{opt}, so that the complementarity relation D^{2} + V^{2} = 1 expresses a measurement-optimality boundary rather than a geometric constraint. Our results reveal that wave-particle duality in induced coherence is not limited by interferometer geometry but by measurement optimality in zero-error discrimination on the idler, with experimentally testable consequences predicting distinguishability beyond that inferred from visibility alone. In the presence of thermal noise we derive the hierarchy V <= F(rho_A, rho_B) <= P_I^{opt}, linking visibility, fidelity, and optimal discrimination. These results identify distinguishability as fundamentally measurement-limited and motivate discrimination-enhanced induced-coherence imaging and sensing.

</details>


### [97] [Algorithmic Quantum Simulations of Quantum Thermodynamics](https://arxiv.org/abs/2511.22898)
*Yangsen Ye,Jue Nan,Dong Chen,Torsten V. Zache,Qingling Zhu,Yiming Zhang,Yuan Li,Xiawei Chen,Chong Ying,Chen Zha,Sirui Cao,Shaowei Li,Shaojun Guo,Haoran Qian,Hao Rong,Yulin Wu,Kai Yan,Feifan Su,Hui Deng,Yu Xu,Jin Lin,Ming Gong,Fusheng Chen,Gang Wu,Yong-Heng Huo,Chao-Yang Lu,Cheng-Zhi Peng,Xiaobo Zhu,Xiaopeng Li,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 该论文开发了基于量子核函数展开（QKFE）的量子热力学模拟算法协议，可在量子硬件上计算自由能等热力学量，并在超导量子比特上验证了横向场Ising和XY模型。


<details>
  <summary>Details</summary>
Motivation: 在有限温度下表征量子物相对于理解复杂材料和宏观热力学现象至关重要，需要开发在量子硬件上模拟量子热力学的有效方法。

Method: 开发了量子核函数展开（QKFE）算法协议，将自由能表示为温度的解析函数并保证一致收敛。在超导量子比特上实现了横向场Ising和XY模型的模拟，包括模拟和数字两种实现方式。

Result: QKFE算法的量子模拟实验与精确结果定量一致，验证了方法的有效性。该方法能够计算熵、热容和临界性等关键热力学性质。

Conclusion: 该工作为在可编程量子设备上计算热力学势提供了通用框架，对材料设计和药物开发具有深远意义。

Abstract: Characterizing quantum phases-of-matter at finite-temperature is essential for understanding complex materials and large-scale thermodynamic phenomena. Here, we develop algorithmic protocols for simulating quantum thermodynamics on quantum hardware through quantum kernel function expansion (QKFE), producing the free energy as an analytic function of temperature with uniform convergence. These protocols are demonstrated by simulating transverse field Ising and XY models with superconducting qubits. In both analogue and digital implementations of the QKFE algorithms, we exhibit quantitative agreement of our quantum simulation experiments with the exact results. Our approach provides a general framework for computing thermodynamic potentials on programmable quantum devices, granting access to key thermodynamic properties such as entropy, heat capacity and criticality, with far-reaching implications for material design and drug development.

</details>


### [98] [CO-QLink: Cryogenic Optical Link for Scalable Quantum Computing Systems and High-Performance Cryogenic Computing Systems](https://arxiv.org/abs/2511.22920)
*Zheng Chang,Siqi Zhang,Wenqiang Huang,Tian Tian,Qichun Liu,Tiefu Li,Nan Qi,Yuanjin Zheng,Zhihua Wang,Yanshu Guo,Hanjun Jiang*

Main category: quant-ph

TL;DR: 本文提出了一种4K低温高速低功耗光收发器，实现4K系统与室温设备之间的完整光通信链路，支持56Gbps数据传输和1.6pJ/bit能效，并应用于超导量子计算系统的控制和读出。


<details>
  <summary>Details</summary>
Motivation: 低温系统（如量子计算和低温计算系统）需要在室温与低温环境之间以及低温域内进行大量数据传输。传统有线/微波链路存在局限性，而光通信链路具有高数据速率、高能效、低信号衰减、无热传导和优异可扩展性等优势，是实现大规模低温系统的关键。

Method: 设计并实现了一个4K热隔离高速低功耗收发器：接收端采用PIN光电二极管与基于反相器的模拟前端和模拟半速率时钟数据恢复环路；发送端连接马赫-曾德尔调制器，包含具有电流模式注入的低功耗输出摆幅提升电压模式驱动器和3抽头前馈均衡器。

Result: 实现了56Gbps数据传输速率和1.6pJ/bit的能效，在4K低温系统与室温设备之间建立了完整的光通信链路，并成功应用于完整的超导量子计算系统的控制和读出演示。

Conclusion: 该工作展示了一种高效的光通信解决方案，能够满足大规模低温系统（特别是量子计算系统）对高速、低功耗数据传输的需求，为未来可扩展的低温系统发展提供了关键技术支撑。

Abstract: Cryogenic systems necessitate extensive data transmission between room-temperature and cryogenic environments, as well as within the cryogenic temperature domain. High-speed, low-power data transmission is pivotal to enabling the deployment of larger-scale cryogenic systems, including the scalable quantum computing systems and the high-performance cryogenic computing systems fully immersed in liquid nitrogen. In contrast to wireline and microwave links, optical communication links are emerging as a solution characterized by high data rates, high energy efficiency, low signal attenuation, absence of thermal conduction, and superior scalability. In this work, a 4K heat-insulated high-speed (56Gbps) low-power (1.6pJ/b) transceiver (TRX) that achieves a complete link between 4K systems and room temperature (RT) equipment is presented. Copackaged with a PIN photodiode (PD), the RX uses an inverter-based analog front-end and an analog half-rate clock data recovery loop. Connecting to a Mach-Zehnder modulator (MZM), the TX contains a voltage-mode driver with current-mode injection for low-power output-swing-boosting and 3-tap feed-forward equalization (FFE). This link has been demonstrated in the control and readout of a complete superconducting quantum computing system.

</details>


### [99] [Evidence for unexpectedly low quasiparticle generation rates across Josephson junctions of driven superconducting qubits](https://arxiv.org/abs/2511.22930)
*Byoung-moo Ann,Sang-Jun Choi,Hee Chul Park,Sercan Deve,Robin Dekker,Gary A. Steele,Jaseung Ku,Seung-Bo Shim,Junho Suh*

Main category: quant-ph

TL;DR: 实验发现超导量子比特在强微波驱动下的准粒子生成率远低于理论预期，通过引入高频截止机制可解释这一现象，为超导量子计算的实际操作提供重要指导。


<details>
  <summary>Details</summary>
Motivation: 微波驱动是超导量子比特控制和读取的核心，但即使远低于超导能隙频率的驱动也可能通过约瑟夫森结产生准粒子，这对容错量子计算构成严重威胁。然而，实际准粒子生成率是否如理论预测那么高需要实验验证。

Method: 通过读取谐振器施加强驱动场（有效量子比特驱动幅度达300 GHz），利用谐振器的非线性响应量化超导量子比特向环境的能量损失，包括准粒子生成的贡献。通过比较实验测量值与理想准粒子生成模型的预测值，并引入高频截止机制进行计算分析。

Result: 实验观测到的能量耗散率远低于理想准粒子生成模型的预期。当在准粒子电导中引入17-20 GHz附近的高频截止时，计算得到的准粒子生成率比无截止模型低几个数量级，与实验结果相符。

Conclusion: 超导量子比特在强驱动下的准粒子生成率实际上远低于理论预测，这避免了过高估计驱动引起的准粒子生成问题，为超导量子处理器的操作提供了关键指导。识别这种差异的微观起源为通过材料和器件设计进一步减轻准粒子生成开辟了新机会。

Abstract: Microwave drives applied to superconducting qubits (SCQs) are central to high-fidelity control and fast readout. However, recent studies find that even drives far below the superconducting gap frequency may cause drive-induced quasiparticle generation (QPG) across Josephson junctions (JJs), posing a serious concern for fault-tolerant superconducting quantum computing. Here, we find experimental evidence that the actual QPG rates in strongly driven SCQs are remarkably lower than expected. We apply intense drive fields through readout resonators, reaching effective qubit drive amplitudes up to 300 GHz. The nonlinear response of the resonators enables quantification of the energy loss from SCQs into their environments, including the contribution from QPG. Even when conservatively attributing all measured dissipation to QPG, the observed energy dissipation rates are far lower than expected from the ideal QPG model. Meanwhile, calculations incorporating high-frequency cutoffs (HFCs) near 17-20 GHz in the QPG conductance can explain the experiments. These HFCs yield QPG rates a few orders of magnitude smaller than those without HFCs, providing evidence that the QPG rates are lower than predicted by the ideal model. Our findings prevent overestimation of drive-induced QPG and provide crucial guidance for operating superconducting quantum processors. Identifying the microscopic origin of the discrepancy opens new material and device opportunities to further mitigate QPG.

</details>


### [100] [Benchmarking neutral atom-based quantum processors at scale](https://arxiv.org/abs/2511.22967)
*Andrea B. Rava,Kristel Michielsen,J. A. Montanez-Barrera*

Main category: quant-ph

TL;DR: 该论文提出了两种基于最大独立集问题的可扩展量子处理器基准测试方法，使用量子绝热算法和量子近似优化算法，在102和85量子比特规模上测试了两种中性原子量子处理器。


<details>
  <summary>Details</summary>
Motivation: 随着中性原子量子计算成为容错量子计算的有力竞争者，量子处理器规模不断扩大，需要新的可扩展基准测试方法来评估和比较不同处理器的性能，跟踪技术进展。

Method: 使用量子绝热算法和量子近似优化算法解决随机单位圆图的最大独立集问题，这些基准测试不依赖系统演化的先验知识，而是基于获得的MIS解的质量，具有可扩展性。

Result: 在102和85量子比特规模上分别测试了quera_aquila和pasqal_fresnel处理器，quera_aquila在QAOA和QAA实例上表现更好，并生成了高达1000量子比特的MIS实例作为未来更大处理器的基准测试。

Conclusion: 提出的两种基准测试方法能够有效评估和比较不同中性原子量子处理器的性能，为未来更大规模量子处理器的评估提供了可扩展的基准测试框架。

Abstract: In recent years, neutral atom-based quantum computation has been established as a competing alternative for the realization of fault-tolerant quantum computation. However, as with other quantum technologies, various sources of noise limit their performance. With processors continuing to scale up, new techniques are needed to characterize and compare them in order to track their progress. In this work, we present two systematic benchmarks that evaluate these quantum processors at scale. We use the quantum adiabatic algorithm (QAA) and the quantum approximate optimization algorithm (QAOA) to solve maximal independent set (MIS) instances of random unit-disk graphs. These benchmarks are scalable, relying not on prior knowledge of the system's evolution but on the quality of the MIS solutions obtained. We benchmark quera_aquila and pasqal_fresnel on problem sizes up to 102 and 85 qubits, respectively. Overall, quera_aquila performs better on QAOA and QAA instances. Finally, we generate MIS instances of up to 1000 qubits, providing scalable benchmarks for evaluating future, larger processors as they become available.

</details>


### [101] [Quantum relative entropy for unravelings of master equations](https://arxiv.org/abs/2511.22976)
*Marcos Ruibal Ortigueira,Robert de Keijzer,Luke Visser,Oliver Tse,Servaas Kokkelmans*

Main category: quant-ph

TL;DR: 该论文探索了量子相对熵与经典Kullback-Leibler散度之间的联系，通过纯态分布空间建立量子相对熵概念，并证明最小KL散度由ρ和σ的共同基支撑的测度实现。


<details>
  <summary>Details</summary>
Motivation: 建立纯态分布空间中的量子相对熵概念，这些分布是Lindblad方程（如随机薛定谔方程）解耦过程的结果对象。将量子相对熵与经典KL散度联系起来，为量子信息理论提供新的视角。

Method: 通过研究忠实态ρ,σ的量子相对熵与实现这些态的纯态分布测度μ,ν的KL散度之间的关系。利用经典和量子数据处理不等式，证明最小KL散度由ρ和σ的共同基支撑的测度实现。

Result: 1) 最小KL散度由ρ和σ的共同基（可能非正交）支撑的测度实现；2) 该量子相对熵概念等价于Belavkin-Staszewski熵；3) 共同基为Lindblad流下相对熵收缩提供了新证明；4) 为大偏差理论结果提供了新见解。

Conclusion: 该工作建立了量子相对熵与经典KL散度之间的深刻联系，通过纯态分布空间为量子相对熵提供了新视角，揭示了Belavkin-Staszewski熵的等价性，并为Lindblad动力学和大偏差理论提供了新的数学工具和见解。

Abstract: This work explores connections between the quantum relative entropy of two faithful states $ρ,σ$ (i.e. full-rank density matrices) and the Kullback-Leibler divergences of classical measures $μ,ν$. Here, $μ$ and $ν$ are measures on the space of pure states, realizing $ρ$ and $σ$ respectively. The motivation for this result is to establish a notion of quantum relative entropy in the space of pure state distributions, which are the resulting objects of unravelings of the Lindblad equation, such as the stochastic Schrödinger equation. Our results show that the measures that achieve the minimal KL divergence are those supported on a (possibly non-orthogonal) common basis between $ρ$ and $σ$. Using the classical and quantum data-processing inequalities, our notion of quantum relative entropy is shown to be equivalent to the Belavkin-Staszewski entropy on states, revealing new insights on this quantity. Furthermore, the common basis is used to provide a novel proof of contraction of the relative entropy under Lindblad flow and offers insights into results from large deviation theory.

</details>


### [102] [Secret Entanglement, Public Geometry. Quantum Cryptography from a Geometric Perspective](https://arxiv.org/abs/2511.22984)
*Loris Di Cairano*

Main category: quant-ph

TL;DR: 提出一种基于希尔伯特射影空间的几何量子密码学视角，将秘密隐藏在状态在可能性空间中的运动方式而非状态本身


<details>
  <summary>Details</summary>
Motivation: 探索秘密是否可以隐藏在量子状态在可能性空间中运动的方式，而非状态本身，从而建立几何视角的量子密码学框架

Method: 基于Fubini-Study度量、纠缠度量族和酉操作生成的控制轨迹，构建几何纠缠码，利用隐藏的叶状结构编码信息

Result: 提出几何纠缠码概念，通过两个玩具构造展示不相容叶状结构如何扮演相互无偏基的角色

Conclusion: 量子密码学可以从几何角度重新构想，其中秘密信息可以编码在状态相对于隐藏叶状结构的运动模式中

Abstract: Can a secret be hidden not in which quantum state is prepared, but in the way that state \emph{moves} through its space of possibilities? Motivated by this question, we propose an essential geometric perspective on quantum cryptography in which projective Hilbert space and its entanglement foliations play a central role. The basic ingredients are: (a) the Fubini-Study metric on the manifold of pure states, (b) a family of entanglement measures viewed as scalar functions on this manifold, and (c) controlled trajectories generated by unitary operations.
  The geometric structure -- state manifold, metric, and allowed moves -- is fully public, as is the functional form of the entanglement family. What remains secret is the choice of parameter $θ$ that selects a specific entanglement functional $E_θ$ and the corresponding foliation into constant-entanglement hypersurfaces. In this setting, classical messages are encoded not only in the sequence of states but also in the pattern of upward, downward, or tangential steps with respect to the hidden foliation. We formalize this idea in terms of geometric entanglement codes and illustrate it with two toy constructions in which incompatible foliations play the role of mutually unbiased bases.

</details>


### [103] [No-go theorem for norm-based quantumness-certification with linear functionals](https://arxiv.org/abs/2511.22992)
*Soumyakanti Bose,Yong-Siah Teo,Hyukjoon Kwon,Hyunseok Jeong*

Main category: quant-ph

TL;DR: 提出无需优化的凸资源理论框架，通过量子态线性泛函的范数直接量化光学量子性，证明无优化的普适量子性度量不可能存在，并用高斯和非高斯态验证


<details>
  <summary>Details</summary>
Motivation: 现有表征光量子态的方法大多实用性有限或依赖计算代价高的凸优化过程，需要开发更实用的量子性量化框架

Method: 建立凸资源理论框架，通过量子态线性泛函的范数直接量化光学量子性，避免任何优化过程

Result: 证明了无优化的普适量子性度量不可能存在的"不可行定理"，并通过高斯和非高斯态的具体例子验证了理论结果

Conclusion: 开发了无需优化的量子性量化框架，同时证明了优化在量子性度量中的必要性，为光学量子性表征提供了实用工具

Abstract: Despite several approaches proposed to operationally characterize quantum states of light-those that cannot be sampled with a positive distribution over classical states-most existing formulations suffer from limited practicality or rely on convex optimization procedures that are computationally demanding. In this work, we develop a general convex resource-theoretic framework to quantify optical quantumness directly from the norms of linear functionals of quantum states, thereby avoiding any optimization. We further establish a no-go theorem demonstrating that no universal measure of quantumness can exist in the absence of optimization. Finally, we substantiate our theoretical result through explicit examples involving both Gaussian and non-Gaussian states.

</details>


### [104] [Tunable dual-band atomic mirror based on subwavelength atomic arrays under electromagnetically induced transparency](https://arxiv.org/abs/2511.23032)
*Shiwen Sun,Yi-Xin Wang,Xiao Liu,Yan Zhang*

Main category: quant-ph

TL;DR: 本文提出了一种基于三维三能级原子阵列的可调谐双波段原子镜，利用电磁感应透明和偶极-偶极相互作用实现两个独立可控的反射带。


<details>
  <summary>Details</summary>
Motivation: 亚波长原子阵列为工程化协同光-物质相互作用和实现量子超表面提供了强大平台。需要开发可重构的光子元件，特别是在低能级下工作的可调谐原子镜。

Method: 使用二维三能级原子阵列，在电磁感应透明条件下工作。通过控制场参数、偶极取向、入射几何结构和晶格常数来调节反射特性。分析集体模式结构以确定衍射阶次出现的条件。

Result: 实现了可调谐双波段原子镜，产生两个具有不对称线宽的独立可控反射带。光谱位置和带宽可通过多个参数调节，并确定了衍射阶次出现的条件，界定了原子镜的操作和可调范围。

Conclusion: 该方案提供了一个在宽频率和角度范围内工作的完全可调谐双波段原子镜，为原子阵列平台中低能级下的可重构光子元件提供了实用且实验上可实现的途径。

Abstract: Subwavelength atomic arrays offer a powerful platform for engineering cooperative light-matter interactions and enabling quantum metasurfaces. We demonstrate that a two-dimensional array of three-level atoms operating under electromagnetically induced transparency can function as a tunable dual-band atomic mirror, where two independently controllable reflection bands emerge from the collective optical responses mediated by dipole-dipole interactions. These resonances yield dual reflection bands with asymmetric linewidths, whose spectral positions and bandwidths can be tuned through the control-field parameters, dipole orientation, incident geometry, and lattice constant. We further identify the conditions under which additional diffraction orders emerge, which delineate the operational and tunable range of the atomic mirror via its collective-mode structure. This scheme provides a fully tunable dual-band atomic mirror operating across broad frequency and angular ranges, offering a practical and experimentally accessible pathway toward reconfigurable photonic elements in atomic-array platforms at low energy levels.

</details>


### [105] [Algebraic power scaling in a slowly-quenched bosonic quantum battery](https://arxiv.org/abs/2511.23081)
*Donny Dwiputra,Ahmad R. T. Nugraha,Sasfan A. Wella,Freddy Permana Zen*

Main category: quant-ph

TL;DR: 通过引入慢淬灭相互作用，量子电池的充电功率可以随淬灭时间呈代数增长，实现更慢的淬灭带来更快的充电效果


<details>
  <summary>Details</summary>
Motivation: 玻色模式量子电池虽然具有无界能谱，但传统相干充电过程受限于电池与充电器之间的相干振荡，限制了可存储能量。需要找到突破这一限制的方法。

Method: 在相干驱动的二次振荡器电池与充电器系统中引入慢淬灭相互作用，分析淬灭持续时间对最大充电功率的影响，并研究充电器耗散效应。通过映射到相干驱动的Tavis-Cummings电池模型验证结果的普适性。

Result: 最大电池功率随淬灭持续时间呈代数增长：$P_{B,m} \propto τ_Q^α$，其中$0<α\leq2$取决于淬灭斜坡指数。更慢的淬灭反而导致更快的充电，抑制了能量相干振荡。充电器耗散会限制最大功率。

Conclusion: 慢淬灭相互作用能够突破量子电池相干充电的功率限制，实现功率的代数增长。这一发现为量子电池设计提供了新思路，且结果在更广泛的量子电池模型中具有普适性。

Abstract: Bosonic modes provide a promising platform for quantum batteries as a result of their unbounded energy spectrum. However, the energy that can be stored during a coherent charging process is limited due to coherent oscillations between the charger and battery. In this Letter, we show that by introducing a slow quench in the interaction between a coherently driven quadratic oscillator battery and a charger system, the maximum battery power ($P_{B,m}$) scales algebraically with the quench duration ($τ_Q$), i.e., $P_{B,m} \propto τ_Q^α$, where $0<α\leq2$ is a function of the quench ramp exponent. This finding implies that, counterintuitively, slower quenches lead to faster charging. Such a quench suppresses coherent energy oscillations between the battery and the charger, allowing an unbounded increase in power. Furthermore, we discuss the effect of charger dissipation, which imposes a finite limit on the maximum power. We also show that the temporal extensive scaling occurs in a broader context by mapping the system to a coherently driven Tavis-Cummings battery.

</details>


### [106] [Efficient Identification of Permutation Symmetries in Many-Body Hamiltonians via Graph Theory](https://arxiv.org/abs/2511.23160)
*Saumya Shah,Patrick Rebentrost*

Main category: quant-ph

TL;DR: 提出一种通用算法，通过构建彩色二分图并利用图自同构群来识别任意泡利哈密顿量的完整置换对称群，将对称性发现问题转化为多项式时间可解的计算问题。


<details>
  <summary>Details</summary>
Motivation: 虽然利用物理对称性可以降低量子多体系统模拟的计算成本，但现有方法通常针对特定对称类，缺乏一个通用算法来发现任意泡利哈密顿量的完整置换对称群。

Method: 通过建立哈密顿量置换对称群与从哈密顿量构建的彩色二分图自同构群之间的同构关系，将对称性发现问题转化为图自构群计算问题。对于具有有界局域性和相互作用度的物理哈密顿量，所得图具有有界度，使得自构群计算可在多项式时间内完成。

Result: 算法在各种已知对称性的物理模型上得到经验验证。同时证明，判断两个哈密顿量是否置换等价的问题可以多项式时间归约到图同构问题。

Conclusion: 该工作提供了一个通用、结构精确的算法化对称性发现工具，使得这些对称性能够可扩展地应用于哈密顿量模拟问题。

Abstract: The computational cost of simulating quantum many-body systems can often be reduced by taking advantage of physical symmetries. While methods exist for specific symmetry classes, a general algorithm to find the full permutation symmetry group of an arbitrary Pauli Hamiltonian is notably lacking. This paper introduces a new method that identifies this symmetry group by establishing an isomorphism between the Hamiltonian's permutation symmetry group and the automorphism group of a coloured bipartite graph constructed from the Hamiltonian. We formally prove this isomorphism and show that for physical Hamiltonians with bounded locality and interaction degree, the resulting graph has a bounded degree, reducing the computational problem of finding the automorphism group to polynomial time. The algorithm's validity is empirically confirmed on various physical models with known symmetries. We further show that the problem of deciding whether two Hamiltonians are permutation-equivalent is polynomial-time reducible to the graph isomorphism problem using our graph representation. This work provides a general, structurally exact tool for algorithmic symmetry finding, enabling the scalable application of these symmetries to Hamiltonian simulation problems.

</details>


### [107] [Quantum spectroscopy of topological dynamics via a supersymmetric Hamiltonian](https://arxiv.org/abs/2511.23169)
*Hiroshi Yamauchi,Satoshi Kanno,Yuki Sato,Hiroyuki Tezuka,Yoshi-aki Shimada,Eriko Kaminishi,Naoki Yamamoto*

Main category: quant-ph

TL;DR: 量子硬件作为拓扑数据谱仪：通过超对称哈密顿量特征谱估计拓扑描述符，在量子设备上实现指数级加速


<details>
  <summary>Details</summary>
Motivation: 传统拓扑数据分析在高维数据中计算成本过高，需要开发量子计算方法来突破经典计算限制

Method: 将时域动力学重新解释为超对称哈密顿量的特征谱，通过Takens嵌入Lorenz系统，在IBM量子硬件上实现资源高效的量子相位估计

Result: 超对称拉普拉斯算子的谱隙跟踪同调结构的持久性，谱隙最小值与混沌起始点重合，重新开放反映吸引子的几何成熟

Conclusion: 量子硬件可以作为超越经典计算能力的数据拓扑谱仪，提供从O(N³)到poly(log N)的指数级加速优势

Abstract: Topological data analysis (TDA) characterizes complex dynamics through global invariants, but classical computation becomes prohibitive for high-dimensional data. We reinterpret time-domain dynamics as the eigenvalue spectrum of a supersymmetric (SUSY) Hamiltonian and thereby estimate topological descriptors through quantum spectroscopy. While zero modes correspond to Betti numbers, we show that low-lying excited states quantify the stability of topological features. Using a Takens embedding of the Lorenz system together with a resource-efficient quantum phase estimation implemented on IBM quantum hardware, we observe that the spectral gap of the SUSY Laplacian tracks the persistence of homological structures. Notably, the minimum of this spectral gap coincides with the onset of chaos, whereas its reopening reflects the geometric maturation of the attractor. Validated on small complexes yet offering an exponential advantage over classical diagonalization (from $O(N^3)$ to $\mathrm{poly}(\log N)$), this framework suggests that quantum hardware can function as a spectrometer for data topologies beyond classical reach.

</details>


### [108] [Nonstabilizerness Estimation using Graph Neural Networks](https://arxiv.org/abs/2511.23224)
*Vincenzo Lipardi,Domenica Dibenedetto,Georgios Stamoulis,Evert van Nieuwenburg,Mark H. M. Winands*

Main category: quant-ph

TL;DR: 提出基于图神经网络（GNN）的方法来估计量子电路的非稳定器性，通过监督学习从分类到回归任务，在多种场景下实现鲁棒泛化性能。


<details>
  <summary>Details</summary>
Motivation: 非稳定器性是量子优势的关键资源，但稳定器Rényi熵（SRE）的高效估计在实际应用中非常重要。传统方法在计算上昂贵，需要开发更高效的估计技术。

Method: 使用图神经网络（GNN）从量子电路的图表示中提取特征。通过三种监督学习任务：从简单的分类任务（区分不同SRE级别）到更复杂的回归任务（直接估计SRE值）。电路表示为图结构，节点对应量子比特，边对应量子门操作。

Result: 在分类任务中，GNN在乘积态上训练后，能够泛化到Clifford操作演化的电路、纠缠态和更多量子比特的电路。在回归任务中，相比先前工作，GNN显著提高了在分布外电路（更多量子比特和门数）上的SRE估计精度，包括随机量子电路和横向场伊辛模型的结构化电路。此外，该方法能整合硬件特定信息，在含噪声量子硬件模拟中显示出预测实际设备SRE的潜力。

Conclusion: 提出的GNN方法能够有效捕捉量子电路图表示中的有意义特征，实现鲁棒的泛化性能，为非稳定器性估计提供了一种高效工具，特别适用于实际量子硬件应用。

Abstract: This article proposes a Graph Neural Network (GNN) approach to estimate nonstabilizerness in quantum circuits, measured by the stabilizer Rényi entropy (SRE). Nonstabilizerness is a fundamental resource for quantum advantage, and efficient SRE estimations are highly beneficial in practical applications. We address the nonstabilizerness estimation problem through three supervised learning formulations starting from easier classification tasks to the more challenging regression task. Experimental results show that the proposed GNN manages to capture meaningful features from the graph-based circuit representation, resulting in robust generalization performances achieved across diverse scenarios. In classification tasks, the GNN is trained on product states and generalizes on circuits evolved under Clifford operations, entangled states, and circuits with higher number of qubits. In the regression task, the GNN significantly improves the SRE estimation on out-of-distribution circuits with higher number of qubits and gate counts compared to previous work, for both random quantum circuits and structured circuits derived from the transverse-field Ising model. Moreover, the graph representation of quantum circuits naturally integrates hardware-specific information. Simulations on noisy quantum hardware highlight the potential of the proposed GNN to predict the SRE measured on quantum devices.

</details>


### [109] [Systems that saturate the Margolus-Levitin quantum speed limit](https://arxiv.org/abs/2511.23237)
*Ole Sönnerborn*

Main category: quant-ph

TL;DR: 该论文完整刻画了在任意Uhlmann-Jozsa保真度下饱和Margolus-Levitin量子速度极限的所有有限维量子态，证明了混合态饱和的三个结构判据，并推导了qubit系统的纯度分辨紧致界。


<details>
  <summary>Details</summary>
Motivation: Margolus-Levitin量子速度极限描述了量子态演化的最小时间，但混合态何时能饱和这一极限尚未完全理解。本文旨在完整刻画所有能饱和该极限的量子态结构。

Method: 采用纯化方法，证明混合态饱和需要满足三个结构条件：态的支持限于两个能量本征空间（基态和单个激发态）；每个非零权重的本征矢量是固定叠加态；所有这样的本征矢量在相互正交的二维子空间中演化。

Result: 建立了混合态饱和Margolus-Levitin极限的完整特征，推导了严格的秩界限（排除了任何忠实态的饱和），对qubit系统得到了纯度分辨的紧致界，并通过时间反演论证将对偶Margolus-Levitin极限扩展到混合态。

Conclusion: 该研究完全解决了混合态饱和Margolus-Levitin量子速度极限的问题，揭示了饱和态必须满足的严格结构约束，为量子速度极限理论提供了重要进展。

Abstract: We provide a complete characterization of all finite-dimensional quantum states that saturate the Margolus-Levitin quantum speed limit at arbitrary Uhlmann-Jozsa fidelity. Employing a purification-based approach, we prove that mixed-state saturation occurs precisely when three structural criteria are fulfilled: the state's support is confined to the sum of two energy eigenspaces (the ground level and a single excited level); each eigenvector of the state with nonzero weight is a fixed superposition of one ground- and one excited-state energy eigenvector (determined by the minimizer of the objective function identified by Giovannetti et al.) and all such eigenvectors evolve in mutually orthogonal two-dimensional subspaces. These requirements impose a strict rank bound, ruling out saturation by any faithful state. For qubit systems, we derive a purity-resolved and tight Margolus-Levitin bound that reduces to the pure-state result in the limit of unit purity. Through a time-reversal argument, we further extend the dual Margolus-Levitin quantum speed limit to mixed states and establish the corresponding saturation conditions.

</details>


### [110] [Identifying genuine entanglement of lossy noisy very large scale continuous variable Greenberger-Horne-Zeilinger state](https://arxiv.org/abs/2511.23240)
*Xiao-yu Chen*

Main category: quant-ph

TL;DR: 提出基于不确定关系和符号矩阵技术的连续变量多体系统纠缠检测框架，可应用于多模系统的纠缠深度和k-可分性问题，并在光子损耗和噪声环境中验证了上亿模式GHZ态的真实纠缠条件。


<details>
  <summary>Details</summary>
Motivation: 大规模系统的真实纠缠识别对量子计算、量子通信和量子学习优势至关重要。实验上已开发出可编程光子量子处理器，但理论上连续变量多体系统的真实纠缠检测成果非常有限。

Method: 基于不确定关系和符号矩阵技术，提出通用且高效的连续变量系统多体纠缠检测框架，构建矩阵判据，可应用于多模系统的纠缠深度和k-可分性问题。

Result: 展示了矩阵判据的有效性，并在光子损耗和噪声环境中验证了连续变量Greenberger-Horne-Zeilinger态（超过一亿模式）的真实纠缠条件。

Conclusion: 该框架为连续变量多体系统的纠缠检测提供了通用且高效的理论工具，填补了实验进展与理论成果之间的差距，对大规模量子系统的纠缠识别具有重要意义。

Abstract: Genuine entanglement identification of large scale systems is crucial for quantum computation, quantum communication and quantum learning advantage. In contrast to experiments, where noisy intermediate-scale programmable photonic quantum processors have been developed, theoretically very limited results have been achieved for detecting genuine entanglement of continuous variable multipartite systems. We propose a quite general and efficient entanglement detection framework for all kinds of multipartite entanglement of continuous variable systems based on uncertainty relations and the sign matrix technique. Matrix criteria are demonstrated and can be applied to various entanglement depth and k-separability problems of multimode systems. We illustrate the genuine entanglement conditions of continuous variable Greenberger-Horne-Zeilinger states of more than a hundred million modes in a photon loss and noise environment.

</details>


### [111] [Unrepeated White Rabbit Time Synchronisation over a 300 km Optical Fibre Link](https://arxiv.org/abs/2511.23254)
*Ben Amies-King,Marco Lucamarini*

Main category: quant-ph

TL;DR: 研究人员实现了White Rabbit技术在300公里单跨距光纤链路上的最长无中继部署，实现了皮秒级精度和亚纳秒级精度的时间同步，为大规模量子网络提供了可扩展的标准化定时骨干网。


<details>
  <summary>Details</summary>
Motivation: White Rabbit技术虽然能提供亚纳秒级精度的时间同步，但在长距离无中继部署（特别是海底光纤等无法使用中间放大的场景）方面的演示仍然很少。本研究旨在探索WR技术在超长距离单跨距光纤链路上的可行性。

Method: 通过精心选择和优化链路两端部署的组件，在300公里（51.34 dB）单跨距光纤链路上部署White Rabbit技术，即使在高度不对称配置下也能工作。采用标准电信光纤和商用现成硬件。

Result: 实现了99.86%的正常运行时间，同时保持皮秒级精度和亚纳秒级精度的时间同步。这是迄今为止最长的无中继WR部署，为大规模量子网络提供了可扩展的定时骨干网解决方案。

Conclusion: 该研究证明了White Rabbit技术在超长距离单跨距光纤链路上的可行性，为未来异构量子通信系统中的时间分发提供了实用途径，为大规模量子网络的标准化定时骨干网奠定了基础。

Abstract: White Rabbit (WR) technology provides a commercially-available off-the-shelf solution for time synchronisation with sub-nanosecond accuracy and picosecond-level precision over optical fibre links typically spanning tens of kilometres. Such high-performance time dissemination can support a variety of applications, including position, navigation and timing (PNT), financial transactions, metrology, as well as entanglement and quantum key distribution (QKD). Demonstrations of WR over significantly longer distances remain few and far between, particularly in scenarios where intermediate amplification is unavailable, such as stretches of long-haul underwater fibre. In this work, we report the longest unrepeated deployment of WR to date, achieving time synchronisation over a 300 km (51.34 dB) single-span optical fibre link, even in highly asymmetrical configurations, with 99.86% uptime, whilst maintaining picosecond-level precision and sub-nanosecond accuracy. This was achieved through careful selection and optimisation of the components deployed at the link's end points. By leveraging standard telecom fibre and off-the-shelf hardware, our results pave the way for a scalable and standardised timing backbone for large-scale quantum networks, offering a practical route toward time distribution in future heterogeneous quantum communication systems.

</details>


### [112] [Inhibited radiative decay enhances single-photon emitters](https://arxiv.org/abs/2511.23301)
*Florian Burger,Stephan Rinner,Andreas Gritsch,Kilian Sandholzer,Andreas Reiserer*

Main category: quant-ph

TL;DR: 通过光子晶体波导抑制不需要的自发辐射，实现高效自旋-光子接口，避免传统谐振器方法的限制


<details>
  <summary>Details</summary>
Motivation: 量子网络和量子计算机需要高效的自旋-光子接口。传统方法使用光学谐振器增强特定跃迁的辐射衰变，但需要小模式体积和高品质因子，限制了多路复用能力并需要精确调谐谐振频率。

Method: 采用替代方法：通过定制W1硅光子晶体波导的光子带隙来抑制所有其他辐射衰变通道，而不是强烈增强选定跃迁的发射。这种方法允许在宽光谱范围内解析和单独寻址数十个铒掺杂剂。

Result: 发射被引导到所需跃迁，确保高效收集；寿命在宽光谱范围内得以保持甚至延长；扩展的模式体积允许低掺杂浓度和大的空间分离，避免限制相干性的不需要相互作用。

Conclusion: 抑制不需要的自发辐射的方法可以与Purcell增强结合，并应用于其他主要自旋量子比特平台，为光子量子技术开辟了有趣的前景。

Abstract: Quantum networks and the modular scaling of quantum computers require efficient spin-photon interfaces. This can be achieved with optical resonators that increase the local density of states, thereby enhancing the radiative decay of emitters on a specific transition. However, small mode volumes and high quality factors are required in this approach, which restricts the multiplexing capacity and necessitates precise tuning of the resonator frequency. Here, we demonstrate an alternative method that avoids these bottlenecks for up-scaling. Instead of strongly enhancing the emission on a selected transition, we suppress all other radiative decay channels by tailoring the photonic bandgap of a W1 silicon photonic crystal waveguide. In such a device, we can spectrally resolve and individually address tens of erbium dopants. We find that their emission is channeled to the desired transition, ensuring efficient collection. At the same time, their lifetimes are preserved or even extended compared to the bulk in a broad spectral range. Furthermore, the extended mode volume facilitates a low dopant concentration and thus a large spatial separation between the emitters, avoiding unwanted interactions that would limit their coherence. The demonstrated approach of inhibiting unwanted spontaneous emission can be combined with Purcell enhancement and applied to other leading spin-qubit platforms. It thus opens intriguing perspectives for photonic quantum technologies.

</details>


### [113] [Quantum Cubature Codes](https://arxiv.org/abs/2511.23316)
*Yaoling Yang,Andrew Tanggara,Tobias Haug,Kishor Bharti*

Main category: quant-ph

TL;DR: 论文提出了量子容积码（QCCs）框架，利用相干态叠加构建玻色码，通过多元近似理论中的容积公式连接相空间连续几何与离散加权点集，统一了猫码和量子球面码等现有编码，并发现了性能更优的多壳层非均匀叠加编码。


<details>
  <summary>Details</summary>
Motivation: 玻色码利用谐振子的无限维希尔伯特空间进行量子信息编码，提供硬件高效的量子纠错方案。但设计这些编码需要精确的相空间量子态几何排列，现有方法有限且缺乏统一框架。

Method: 引入量子容积码（QCCs）框架，基于相干态叠加构建玻色码。利用多元近似理论中的容积公式，将相空间的连续几何与离散加权点集连接，确保满足纠错条件。该框架包含非均匀叠加和多壳层配置，从欧几里得设计中发现新的编码家族。

Result: QCC框架统一了猫码和量子球面码等现有编码（对应单能壳均匀权重）。多壳层QCCs通过最大化几何分离度，在固定纯损耗率下优化能量配置，在纯损耗信道数值模拟中表现出比单壳层编码更好的性能。

Conclusion: 量子容积码提供了一个强大的通用框架，不仅统一了现有玻色码，还开辟了包含非均匀叠加和多壳层配置的广阔设计空间，能够通过优化几何分离度提升在光子损耗下的性能。

Abstract: Bosonic codes utilize the infinite-dimensional Hilbert space of harmonic oscillators to encode quantum information, offering a hardware-efficient approach to quantum error correction. Designing these codes requires precise geometric arrangements of quantum states in the phase space. Here, we introduce Quantum Cubature Codes (QCCs), a powerful and generalized framework for constructing bosonic codes based on superpositions of coherent states. This formalism utilizes cubature formulas from multivariate approximation theory, which connect the continuous geometry of the phase space to discrete, weighted point sets, ensuring the conditions for error correction are met. We demonstrate that this framework provides a unifying perspective, revealing that well-established codes, such as cat codes and the recently proposed quantum spherical codes (QSCs), are specific instances of QCCs corresponding to uniform weights on a single energy shell. The QCC formalism unlocks a vast new design space, encompassing non-uniform superpositions and multi-shell configurations. We leverage this framework to discover several new families of codes derived from Euclidean designs, allowing for greater geometric separation between logical states, which correlates with improved performance under photon loss. Numerical simulations under a pure-loss channel show that our multi-shell QCCs can outperform their single-shell counterparts by maximizing geometric separation with optimal energy at fixed pure-loss rate.

</details>


### [114] [Bounded-Error Quantum Simulation via Hamiltonian and Lindbladian Learning](https://arxiv.org/abs/2511.23392)
*Tristan Kraft,Manoj K. Joshi,William Lam,Tobias Olsacher,Florian Kranzl,Johannes Franke,Lata Kh Joshi,Rainer Blatt,Augusto Smerzi,Daniel Stilck França,Benoît Vermersch,Barbara Kraus,Christian F. Roos,Peter Zoller*

Main category: quant-ph

TL;DR: 提出了一个用于有界误差量子模拟的通用框架，通过哈密顿量和Lindbladian学习结合不确定性传播，为多体可观测量提供实验可量化的置信边界。


<details>
  <summary>Details</summary>
Motivation: 模拟量子模拟器虽然能探索经典计算无法处理的强关联多体动力学，但其预测能力因缺乏定量误差估计而受限。建立严格的误差界限对于将这些设备从定性演示提升为定量科学工具至关重要。

Method: 结合哈密顿量和Lindbladian学习（对控制动力学的相干和耗散生成元进行统计严格推断）与不确定性传播到模拟可观测量中，直接从实验数据得出置信边界。在实现长程Ising相互作用的51离子囚禁离子量子模拟器上演示。

Result: 在两种层面上分析误差界限：1）从初始时间窗口的实验数据学习开放系统模型，模拟相应的主方程，定量验证理论预测与长时间测量动力学的一致性；2）直接从实验测量建立误差界限，不依赖经典模拟。学习模型在预测边界内重现实验演化。

Conclusion: 有界误差量子模拟为可信的模拟量子计算提供了可扩展基础，弥合了实验平台与预测性多体物理之间的差距。该技术可直接扩展到数字量子模拟。

Abstract: Analog Quantum Simulators offer a route to exploring strongly correlated many-body dynamics beyond classical computation, but their predictive power remains limited by the absence of quantitative error estimation. Establishing rigorous uncertainty bounds is essential for elevating such devices from qualitative demonstrations to quantitative scientific tools. Here we introduce a general framework for bounded-error quantum simulation, which provides predictions for many-body observables with experimentally quantifiable uncertainties. The approach combines Hamiltonian and Lindbladian Learning--a statistically rigorous inference of the coherent and dissipative generators governing the dynamics--with the propagation of their uncertainties into the simulated observables, yielding confidence bounds directly derived from experimental data. We demonstrate this framework on trapped-ion quantum simulators implementing long-range Ising interactions with up to 51 ions, and validate it where classical comparison is possible. We analyze error bounds on two levels. First, we learn an open-system model from experimental data collected in an initial time window of quench dynamics, simulate the corresponding master equation, and quantitatively verify consistency between theoretical predictions and measured dynamics at long times. Second, we establish error bounds directly from experimental measurements alone, without relying on classical simulation--crucial for entering regimes of quantum advantage. The learned models reproduce the experimental evolution within the predicted bounds, demonstrating quantitative reliability and internal consistency. Bounded-error quantum simulation provides a scalable foundation for trusted analog quantum computation, bridging the gap between experimental platforms and predictive many-body physics. The techniques presented here directly extend to digital quantum simulation.

</details>


### [115] [Hilbert space fragmentation in driven-dephasing Rydberg atom array](https://arxiv.org/abs/2511.23395)
*Tianyi Yan,Chun Hei Leung,Weibin Li*

Main category: quant-ph

TL;DR: 该研究探讨了强相互作用里德堡原子链在局部退相干下希尔伯特空间碎片化的产生机制，发现多个长寿命亚稳态的出现与系统的希尔伯特空间碎片化密切相关，并通过退相干PXP模型揭示了其对称性根源和指数增长的碎片化结构。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在强相互作用里德堡原子链中，局部退相干如何导致希尔伯特空间碎片化的产生机制。里德堡原子系统作为研究多体动力学的重要平台，其希尔伯特空间碎片化现象对理解受限动力学和量子控制具有重要意义。

Method: 采用退相干PXP模型来描述受驱动退相干的里德堡原子系统。该模型支持多个简并零模，这些零模形成由最大混合态组成的块对角子空间。通过分析连续双激发寻址算符定义的守恒量，揭示了希尔伯特空间碎片化的对称性根源。

Result: 研究发现希尔伯特空间碎片化与多个长寿命亚稳态的出现密切相关。碎片化的希尔伯特空间数量随链长呈指数增长，遵循修正的斐波那契数列。每个子空间中的守恒量由连续双激发寻址算符定义，这些子空间包含共享相同对称性的多体自旋态。

Conclusion: 该工作揭示了里德堡原子系统中希尔伯特空间碎片化的对称性机制，为理解动力学约束下的多体动力学提供了新见解，并为控制和操纵里德堡原子系统中的希尔伯特空间碎片化开辟了新途径。

Abstract: We investigate the onset and mechanism of Hilbert space fragmentation (HSF) in a chain of strongly interacting Rydberg atoms subject to local dephasing. It is found that the emergence of multiple long-lived metastable states is fundamentally tied to HSF of the driven-dephasing Rydberg atom system. We demonstrate that the manifesting HSF is captured by a dephasing PXP model that supports multiple degenerate zero modes. These modes form disconnected, block-diagonal subspaces of maximally mixed states, which consist of many-body spin states sharing the same symmetry. A key result is the identification of the underlying symmetry in the HSF, where conserved quantities in each subspace are defined by the consecutive double excitation addressing operator. Moreover, we show explicitly that the number of the fragmented Hilbert space grows exponentially with the chain length, following a modified Fibonacci sequence. Our work provides insights into many-body dynamics under dynamical constraints and opens avenues for controlling and manipulating HSF in Rydberg atom systems.

</details>


### [116] [Renormalisation of Fermionic Cellular Automata](https://arxiv.org/abs/2511.23398)
*Lorenzo Siro Trezzini,Andrea Pizzamiglio,Alessandro Bisio,Paolo Perinotti*

Main category: quant-ph

TL;DR: 提出了一种用于超立方格子上费米子元胞自动机的精确重整化方案，通过将相邻单元分组并选择子空间，将原始系统的多个演化步骤对应到有效自动机的单步演化。


<details>
  <summary>Details</summary>
Motivation: 研究费米子元胞自动机的重整化性质，建立系统性的重整化方案，理解其重整化流和固定点行为。

Method: 通过将相邻单元分组为"瓦片"并在其中选择子空间，将原始系统的多个演化步骤映射到有效自动机的单步演化。推导了重整化的必要充分条件，并完全刻画了链上无自旋模式最近邻费米子自动机的重整化流。

Result: 建立了精确的重整化方案，推导了重整化条件，完全刻画了特定情况（两单元瓦片、两个时间步、链上最近邻费米子自动机）的重整化流，并识别了所有固定点。

Conclusion: 该工作为费米子元胞自动机提供了系统的重整化框架，能够分析其重整化流和固定点行为，为理解这类系统的尺度不变性和临界现象奠定了基础。

Abstract: We present an exact renormalisation scheme for fermionic cellular automata on hypercubic lattices. By grouping neighbouring cells into tiles and selecting subspaces within them, multiple evolution steps on the original system correspond to a single step of an effective automaton acting on the subspaces. We derive a necessary and sufficient condition for renormalisability and fully characterise the renormalisation flow for two-cell tiles and two time steps of nearest-neighbour fermionic automata on a chain of spinless modes, identifying all fixed points.

</details>


### [117] [Persistence of Quantum Triality Relations in Open Qubit and Qutrit Systems](https://arxiv.org/abs/2511.23399)
*Pratidhwani Swain,Ramita Sarkar,Sukanta K. Tripathy,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: 研究量子比特和量子三能级系统在噪声信道下的相干性、可预测性和纠缠之间的互补关系，验证三重性关系在开放量子系统中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索量子系统在噪声环境下（振幅阻尼和相位阻尼）的互补性关系是否仍然成立，为低维系统中的噪声量子干涉提供统一分析框架。

Method: 采用系统-路径纠缠框架，推导双缝和三缝干涉装置中相干性、可预测性和纠缠的解析表达式，分别在理想条件和噪声信道下验证三重性关系。

Result: 振幅阻尼重新分配相干性和布居数不平衡但不违反互补性；相位阻尼降低相干性但保持可预测性不变；互补关系在开放量子系统中仍然保持。

Conclusion: 互补性关系在开放量子系统中具有鲁棒性，能够抵抗退相干效应，为低维系统中的噪声量子干涉提供了统一的分析理解。

Abstract: We examine the complementarity among coherence (visibility), predictability, and entanglement for qubit and qutrit systems subjected to noisy quantum channels. Using the system-path entanglement framework, analytical expressions for all three quantities are derived for two- and three-slit interferometric setups. The study first establishes the validity of the triality relation in ideal conditions and then investigates its behavior under amplitude and phase damping. We find that amplitude damping redistributes coherence and population imbalance without violating complementarity, while phase damping reduces coherence but leaves predictability unchanged. These results demonstrate that the complementarity relation remains preserved even in open quantum systems, highlighting its robustness against decoherence and providing a unified analytical understanding of noisy quantum interferometry in low-dimensional systems.

</details>


### [118] [The Boundary Time Crystal as a light source for quantum enhanced sensing beyond the Heisenberg Limit](https://arxiv.org/abs/2511.23416)
*Malik Jirasek,Igor Lesanovsky,Albert Cabot*

Main category: quant-ph

TL;DR: 利用驱动耗散多体开放量子系统的集体增强输出场作为光源，通过边界时间晶体的时间相关性提升光学相位估计精度，突破海森堡极限


<details>
  <summary>Details</summary>
Motivation: 现代精密测量（如引力波探测干涉仪）依赖于光场中光学相位的估计，需要提高相位估计精度以提升测量灵敏度

Method: 使用边界时间晶体作为光源，利用其输出场的显著时间相关性；提出一种协议，将相移后的光场导入辅助复制系统作为探测器，该探测器对光的非平凡时间相关性敏感

Result: 相位估计的基本精度界限显示系统尺寸缩放超越海森堡极限，在测量时间上服从标准量子极限；该缩放可通过提出的协议部分实现

Conclusion: 利用多体开放量子系统的集体增强输出场作为光源，通过其时间相关性可以显著提高光学相位估计精度，突破传统量子极限

Abstract: Modern precision measurements, such as interferometry for detecting gravitational waves, rely on the estimation of optical phases encoded in light fields. Here, we propose to exploit the collectively enhanced output field of a driven-dissipative many-body open quantum system as a light source in order to improve the precision of estimating optical phases. Pronounced temporal correlations of such output fields benefit the sensitivity of measurement protocols, which we show theoretically by employing a boundary time crystal as a light source. The fundamental bound on the precision of such estimation shows scaling with system size that surpasses the Heisenberg limit and obeys the standard quantum limit in the measurement time. This scaling can be partially harnessed by a protocol, in which the phase shifted light field is guided into an auxiliary replica system, which serves as a detector that is sensitive to non-trivial temporal correlations of the light.

</details>


### [119] [COMPAS: A Distributed Multi-Party SWAP Test for Parallel Quantum Algorithms](https://arxiv.org/abs/2511.23434)
*Brayden Goldstein-Gelb,Kun Liu,John M. Martyn,Hengyun Zhou,Yongshan Ding,Yuan Liu*

Main category: quant-ph

TL;DR: COMPAS是一种分布式量子计算架构，利用预共享的贝尔对作为资源，在多量子处理单元网络中实现多元迹估计，同时实现电路深度和GHZ宽度的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 量子计算中每个芯片的量子比特数量有限是主要瓶颈，需要分布式架构连接多个量子处理单元。执行跨分布式系统的量子算法需要算法原语和硬件架构的协同设计，以管理电路深度和纠缠开销。

Method: 提出COMPAS架构，利用预共享的纠缠贝尔对作为资源，在多模块分布式量子处理单元网络中实现多元迹估计。该架构仅增加常数深度开销，贝尔对消耗率与电路宽度呈线性关系。

Result: COMPAS同时实现了电路深度和GHZ宽度的渐近最优性，而其他方案只能选择其一。该架构适合近期硬件，并分析了网络级错误和电路级噪声的影响。

Conclusion: 多元迹估计是适合分布式的关键子程序，COMPAS架构通过利用预共享贝尔对资源，在分布式量子系统中有效实现了这一功能，为量子计算的可扩展性提供了有前景的解决方案。

Abstract: The limited number of qubits per chip remains a critical bottleneck in quantum computing, motivating the use of distributed architectures that interconnect multiple quantum processing units (QPUs). However, executing quantum algorithms across distributed systems requires careful co-design of algorithmic primitives and hardware architectures to manage circuit depth and entanglement overhead. We identify multivariate trace estimation as a key subroutine that is naturally suited for distribution, and broadly useful in tasks such as estimating Rényi entropies, virtual cooling and distillation, and certain applications of quantum signal processing. In this work, we introduce COMPAS, an architecture that realizes multivariate trace estimation across a multi-party network of interconnected modular and distributed QPUs by leveraging pre-shared entangled Bell pairs as resources. COMPAS adds only a constant depth overhead and consumes Bell pairs at a rate linear in circuit width, making it suitable for near-term hardware. Unlike other schemes, which must choose between asymptotic optimality in circuit depth or GHZ width, COMPAS achieves both at once. Additionally, we analyze network-level errors and simulate the effects of circuit-level noise on the architecture.

</details>


### [120] [A Heuristic for Matrix Product State Simulation of Out-of-Equilibrium Dynamics of Two-Dimensional Transverse-Field Ising Models](https://arxiv.org/abs/2511.23438)
*Salvatore Mandrà,Nikita Astrakhantsev,Sergei Isakov,Benjamin Villalonga,Brayden Ware,Tom Westerhout,Kostyantyn Kechedzhi*

Main category: quant-ph

TL;DR: 提出一种启发式方法，通过缩放低键维度的矩阵乘积态结果来加速热化量子系统模拟的收敛，应用于二维横场伊辛模型并与量子处理器结果比较。


<details>
  <summary>Details</summary>
Motivation: 非可积哈密顿多体量子系统的非平衡动力学具有高度纠缠的波函数，经典模拟需要指数资源。虽然热化系统中计算局部算符期望值不需要存储完整波函数，但在中等能量密度下构建有效算法仍具挑战。

Method: 提出启发式方法加速矩阵乘积态模拟收敛：通过仅依赖于MPS波函数保真度的缩放因子，对低键维度下的MPS结果进行重新缩放来估计目标可观测量。

Result: 在单块A100 GPU上使用最大键维度χ=4096模拟了7×8网格周期性边界条件下的二维横场伊辛模型动力学，并与数字量子处理器上的类似模拟结果进行了比较。

Conclusion: 该方法为广泛能量密度范围内的热化量子系统模拟提供了一种有效的经典算法，能够加速MPS模拟的收敛，并与量子计算模拟结果具有可比性。

Abstract: Out-of-equilibrium dynamics of non-integrable Hamiltonian many-body quantum systems are characterized by highly entangled wave functions. Near-maximal entanglement arises in systems exhibiting thermalization or pre-thermalization, where the system converges to a steady state with a fixed energy density. Classical simulation of the time dependence of such wave functions requires exponential resources. However, typical computations aim to estimate expectation values of local operators and correlation functions to some expected precision. For thermalizing systems at sufficiently high energy densities, such computations do not require storing the full wave function. Nonetheless, constructing classical algorithms for intermediate energy densities has remained a challenge. In this paper, we propose a heuristic approach to accelerate the convergence of Matrix Product State (MPS) simulations of expectation values applicable in a broad range of energy densities. We estimate the desired observables by rescaling the MPS results at low bond dimensions with a factor that depends only on the fidelity of the MPS wave function. Using this technique, we simulated the dynamics of the two-dimensional Transverse-Field Ising Model (TFIM) on a $7\times8$ grid with periodic boundary conditions, using a maximum bond dimension of $χ= 4096$ on a single A100 GPU. We compared our results to similar TFIM simulations on a digital quantum processor.

</details>


### [121] [Quantum Polymorphisms and Commutativity Gadgets](https://arxiv.org/abs/2511.23445)
*Lorenzo Ciardo,Gideo Joubert,Antoine Mottet*

Main category: quant-ph

TL;DR: 引入量子多态概念，完全刻画关系结构的交换性小工具存在性，证明奇圈参数化纠缠CSP不可判定，建立非预言量子同态的量子Galois连接


<details>
  <summary>Details</summary>
Motivation: 将量子多态概念引入非局域博弈的复杂性理论，为Ji提出的实现经典CSP约简量子可靠性的交换性小工具提供完整分类，扩展布尔情形的已知结果

Method: 引入量子多态概念，建立理论框架分析关系结构的交换性小工具存在性，应用该框架证明奇圈参数化纠缠CSP的不可判定性

Result: 完全刻画了关系结构交换性小工具的存在性分类，证明了奇圈参数化纠缠CSP的不可判定性，建立了非预言量子同态情形的量子Galois连接

Conclusion: 量子多态概念为分析非局域博弈复杂性提供了新工具，解决了交换性小工具的分类问题，推进了纠缠CSP的理论研究

Abstract: We introduce the concept of quantum polymorphisms to the complexity theory of non-local games. We use this notion to give a full characterisation of the existence of commutativity gadgets for relational structures, introduced by Ji as a method for achieving quantum soundness of classical CSP reductions. Prior to our work, a classification was only known in the Boolean case [Culf--Mastel, STOC'25]. As an application of our framework, we prove that the entangled CSP parameterised by odd cycles is undecidable. Furthermore, we establish a quantum version of Galois connection for entangled CSPs in the case of non-oracular quantum homomorphisms.

</details>


### [122] [Random purification channel made simple](https://arxiv.org/abs/2511.23451)
*Filippo Girardi,Francesco Anna Mele,Ludovico Lami*

Main category: quant-ph

TL;DR: 提出随机纯化通道的简单构造，证明其能将任意混合态转化为其纯化的均匀凸组合，并应用于量子散度的Uhlmann定理证明


<details>
  <summary>Details</summary>
Motivation: 随机纯化通道在量子学习理论中已被证明是极其有用的工具，但需要更简单的构造来使其性质更加透明，并探索其在非独立同分布情况下的应用

Method: 给出随机纯化通道的简单构造，证明该通道不仅适用于独立同分布的混合态，还能纯化置换对称态，将其转化为置换对称纯化的均匀凸组合

Result: 1. 提供了随机纯化通道的简洁构造；2. 证明了该通道能纯化非独立同分布的置换对称态；3. 给出了量子散度Uhlmann定理的简化证明

Conclusion: 随机纯化通道的简单构造使其性质更加透明，扩展了其在非独立同分布情况下的应用，并为量子信息理论中的重要定理提供了简洁证明

Abstract: The recently introduced random purification channel, which converts $n$ i.i.d. copies of any mixed quantum state into a uniform convex combination of $n$ i.i.d. copies of its purifications, has proved to be an extremely useful tool in quantum learning theory. Here we give a remarkably simple construction of this channel, making its known properties -- and several new ones -- immediately transparent. In particular, we show that the channel also purifies non-i.i.d. states: it transforms any permutationally symmetric state into a uniform convex combination of permutationally symmetric purifications, each differing only by a tensor-product unitary acting on the purifying system. We then apply the channel to give a one-line proof of (a stronger version of) the recently established Uhlmann's theorem for quantum divergences.

</details>


### [123] [Spectral analysis of the Koopman operator recovers Hamiltonian parameters in open quantum systems](https://arxiv.org/abs/2511.23470)
*Jorge E. Pérez-García,Carlos Colchero,Julio C. Gutiérrez-Vega*

Main category: quant-ph

TL;DR: 提出基于Koopman算子的数据驱动方法，从一阶矩动力学推断开放量子系统的哈密顿参数，在强耗散情况下优于傅里叶和矩阵铅笔估计器。


<details>
  <summary>Details</summary>
Motivation: 哈密顿参数的准确识别对于开放量子系统的建模和控制至关重要，需要开发能够从实验数据中可靠提取这些参数的方法。

Method: 使用多通道Hankel替代Koopman视图(mHAVOK)算法获取Koopman算子的离散谱，利用Koopman算子理论从一阶矩动力学中推断哈密顿参数。

Result: 方法成功恢复了振荡频率、阻尼率、非线性Kerr位移、Jaynes-Cummings相互作用的量子比特-光子耦合强度以及时间相关哈密顿量的调制频率，大多数参数误差在5%以内，在强耗散动力学中比傅里叶和矩阵铅笔估计器误差更低。

Conclusion: Koopman算子理论为研究量子动力学系统提供了一个实用框架，能够从实验数据中准确提取哈密顿参数，特别是在强耗散系统中表现出优越性能。

Abstract: An accurate identification of Hamiltonian parameters is essential for modeling and control of open quantum systems. In this work, a novel data-driven method for inferring such parameters from first-moment dynamics is presented using an open 2D quantum harmonic oscillator as an example. The method relies on the discrete spectrum of the Koopman operator to obtain such parameters, which is obtained using the multichannel Hankel Alternative View of Koopman (mHAVOK) algorithm; a theoretical connection of such affirmation is presented. The method is tested on the expected value of noiseless quadratures, retrieving oscillation frequencies, damping rates, nonlinear Kerr shifts, qubit-photon coupling strengths of a Jaynes-Cummings interaction, and a modulated frequency of a time-dependent Hamiltonian. The majority of the recovered parameters remained within 5% of their true values. When compared to Fourier and matrix-pencil estimators, our approach yields lower errors for dynamics with strong dissipation. Overall, these findings suggest that Koopman operator theory provides a practical framework for studying quantum dynamical systems.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [124] [A Self-Adjusting FEM-BEM Coupling Scheme for the Nonlinear Poisson-Boltzmann Equation](https://arxiv.org/abs/2511.21713)
*Mauricio Guerrero-Montero,Michal Bosy,Christopher D. Cooper*

Main category: physics.comp-ph

TL;DR: 提出一种自动寻找最优松弛参数的非线性Poisson-Boltzmann方程求解方法，结合有限元/边界元方案，在高度带电系统（如核酸）中实现快速可靠收敛。


<details>
  <summary>Details</summary>
Motivation: 传统Poisson-Boltzmann方程通常在线性化形式下求解，因为sinh非线性项难以处理，限制了在高度带电系统（如核酸）中的应用。需要开发能够自动处理非线性项且无需人工干预的可靠求解方法。

Method: 采用耦合有限元/边界元方案，自动寻找最优松弛参数。使用Newton-Raphson方法逐步引入非线性，首次迭代采用三次近似。结合其他优化技术自动确定最佳松弛因子。

Result: 验证了求解器在球形腔体上与APBS的一致性。在RNA结构测试中，Newton-Raphson方法最佳，可将迭代次数减少40%。对于电荷最高的1HC8分子，相比手动选择松弛因子获得1.37倍加速，避免了试错过程。

Conclusion: 提出的方法能够自动优化松弛参数，为高度带电系统的非线性Poisson-Boltzmann方程求解提供快速可靠的解决方案，无需用户干预即可获得最佳收敛性能。

Abstract: The Poisson-Boltzmann equation is widely used to model molecular electrostatics; however, it is usually solved in linearised form because the sinh nonlinearity is challenging, limiting its applicability in highly charged systems such as nucleic acids. This work presents a solution method for the nonlinear Poisson-Boltzmann equation based on a coupled finite/boundary element scheme that automatically finds an optimal relaxation parameter, ensuring fast and reliable convergence of the nonlinear solver without user intervention. We validated our solver against APBS for a spherical cavity, and used RNA-based structures to perform a thorough study of the different algorithmic choices, and to test our implementation. We found that the best alternative to solve the Poisson-Boltzmann equation was using a Newton-Raphson method where the nonlinearity was gradually introduced with a cubic approximation in the first iteration. Newton-Raphson was also the best method to find the optimal relaxation factor, reducing the number of iterations by 40%. Including other optimisation techniques, we were able to obtain a 1.37x speed-up with respect to the best hand-picked relaxation factor for 1HC8 (molecule with highest charge in our tests), avoiding any trial-and-error process to find the relaxation factor.

</details>


### [125] [A multi-language auto-differentiation module and its application to a parallel particle-in-cell code on distributed computers](https://arxiv.org/abs/2511.21839)
*Ji Qianga,Yue Hao,Allen Qiang,Jinyu Wan*

Main category: physics.comp-ph

TL;DR: 开发了一个快速透明的自动微分模块，可轻松集成到多种仿真代码中，并成功应用于并行粒子网格代码


<details>
  <summary>Details</summary>
Motivation: 自动微分仿真不仅能输出仿真结果，还能提供结果对输入参数的导数，这对于研究仿真结果的敏感性以及基于梯度的优化设计参数非常有效。然而，需要开发易于集成到现有仿真代码中的自动微分工具。

Method: 开发了一个快速透明的自动微分模块/类，设计为易于集成到众多仿真代码中。将该模块集成到基于消息传递接口（MPI）的分布式内存计算机上的并行粒子网格代码中作为应用示例。

Result: 成功开发了自动微分模块，并实现了其在并行粒子网格代码中的集成，证明了该模块的实用性和可集成性。

Conclusion: 开发的自动微分模块为仿真代码提供了高效的敏感性分析和梯度优化能力，通过粒子网格代码的应用验证了其有效性和实用性，为更广泛的仿真应用提供了便利的自动微分工具。

Abstract: The auto differentiable simulation is a type of simulation that outputs of the simulation include not only the simulation result itself, but also their derivatives with respect to various input parameters. It provides an efficient method to study sensitivity of the simulation results with respect to the input parameters. Furthermore, it can be used in gradient based optimization methods for rapidly optimizing design parameters. In this paper, we present the development of a fast and transparent auto-differentiation module/class designed for easy integration into numerous simulation codes. As an application, this auto-differentiation module is integrated into a parallel particle-in-cell code with message passing interface (MPI) on distributed memory computers.

</details>


### [126] [Single-pixel imaging via data-driven and deep image prior dual networks](https://arxiv.org/abs/2511.22088)
*Jing-yi Shi,Jia-qi Song,Peng-cheng Ji,Zi-qing Zhao,Yuan-jin Yu,Ming-fei Li,Ling-an Wu*

Main category: physics.comp-ph

TL;DR: 提出SPI-DNIO框架，结合数据驱动网络和深度图像先验网络优势，通过梯度信息增强的残差块，在低采样率下实现高质量单像素成像重建


<details>
  <summary>Details</summary>
Motivation: 现有单像素成像方法存在局限性：DIP-Net需要数千次迭代才能获得高质量重建，DD-Net仅在目标特征与训练集相似时表现最佳。需要克服这些限制，特别是在低采样率下输入信息不足的问题。

Method: 提出双网络迭代优化框架SPI-DNIO，结合DD-Net和DIP-Net优势；设计包含梯度信息的残差块，将细节传递到深层网络，增强学习能力；在主动光照室内实验和被动光照室外远距离实验中验证。

Result: SPI-DNIO框架能以更少迭代步骤恢复高质量图像；梯度信息增强的残差块有效提升低采样率下的重建性能；在室内外实验中均表现出卓越的重建能力和泛化性能。

Conclusion: SPI-DNIO框架成功解决了现有单像素成像方法的局限性，通过双网络协同和梯度信息增强，实现了高效高质量的重建，具有良好的实际应用价值。

Abstract: Single-pixel imaging(SPI),especially when integrated with deep neural networks like deep image prior networks (DIP-Net) or data-driven networks (DD-Net), has gained considerable attention for its capability to generate high-quality reconstructed images, even in the presence of sub-sampling conditions. However, DIP-Net often requires thousands of iterations to achieve high-quality image reconstruction, and DD-Net performs optimally only when the target closely resembles the features present in its training set. To overcome these limitations, we propose a dual-network iterative optimization (SPI-DNIO) framework that combines the strengths of both DD-Net and DIP-Net. It has been demonstrated that this approach can recover high-quality images with fewer iteration steps. Furthermore, to address the challenge of SPI inputs having less effective information at low sampling rates, we have designed a residual block enriched with gradient information, which can convey details to deeper layers, thereby enhancing the deep network's learning capabilities. We have applied these techniques to both indoor experiments with active lighting and outdoor long-range experiments with passive lighting. Our experimental results confirm the exceptional reconstruction capabilities and generalization performance of the SPI-DNIO framework.

</details>


### [127] [Efficient Pseudo-spectral Algorithms for Statistical Field Theories](https://arxiv.org/abs/2511.22510)
*Martin Kjøllesdal Johnsrud,Navdeep Rana*

Main category: physics.comp-ph

TL;DR: 提出了随机指数时间差分方案，用于刚性随机微分方程，结合伪谱方法模拟带加性噪声的随机场论，并在多个平衡和非平衡系统中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 针对刚性随机微分方程，需要开发比欧拉-丸山法和米尔斯坦法更稳定的显式数值方案，以有效模拟带加性噪声的随机场论系统。

Method: 提出了三种显式随机指数时间差分方案，结合伪谱方法，构建了模拟随机场论的高效算法，实现了时间步长h的强收敛阶O(h)。

Result: 新方案在稳定性上优于欧拉-丸山法和米尔斯坦法，成功应用于Model A、Model B、KPZ方程和复Ginzburg-Landau方程等平衡与非平衡系统，能够计算临界指数、关联函数和动态线性响应等物理可观测量。

Conclusion: 随机指数时间差分方案为模拟刚性随机微分方程和随机场论提供了有效工具，代码已开源，便于计算物理观测量的应用。

Abstract: We present stochastic variants of the exponential time differencing schemes for stiff stochastic differential equations. We derive three explicit schemes that offer better stability compared to Euler-Maruyama and Milstein's method, and achieve strong convergence up to order O(h) in the time step h. We combine these schemes with a pseudo-spectral approach to outline efficient algorithms for simulating stochastic field theories with additive noise. To illustrate the effectiveness of this approach, we study several systems in and out of equilibrium, including Model A, Model B, the Kardar-Parisi-Zhang equation, and the Complex Ginzburg-Landau equation. We outline procedures for computing physical observables such as the critical exponents, correlation functions, and dynamic linear response, and provide our implementation as open source code.

</details>


### [128] [Robust Indexing for Challenging Serial X-ray Diffraction Patterns](https://arxiv.org/abs/2511.22875)
*Marc M Nasser,Frédéric Poitevin,Kevin M Dalton*

Main category: physics.comp-ph

TL;DR: 提出一种针对小N衍射模式的鲁棒索引算法，通过对称感知晶格解码、异常峰修剪和特殊小N目标模式，在蛋白质晶体数据集上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 串行晶体学实验中，衍射模式可能包含少量可靠峰、受背景污染或来自高度倾斜晶胞的晶体，这些因素在小N情况下导致索引不稳定

Method: 将索引建模为对称感知晶格解码问题，设计包含晶格对称性的损失函数并修剪异常峰；采用倒易空间基重参数化稳定倾斜晶胞的解码；开发专用小N目标模式，结合精细峰评分和从极少反射恢复取向的方法

Result: 在三个XFEL设施收集的蛋白质数据集上，该方法匹配或优于XGANDALF和TORO等现有索引器，在少量索引峰和倾斜晶胞情况下优势尤其明显；内存效率高，支持CPU高并行或GPU大批量处理

Conclusion: 利用晶格结构、对称性和小N感知搜索能显著提高索引鲁棒性，该方法虽然较慢但内存效率高，结构允许在CPU上高并行或在GPU上使用更大批量

Abstract: Serial crystallography experiments routinely produce thousands of diffraction patterns from crystals in random orientations. To turn this stream of images into a usable dataset, each pattern must be indexed before integration and merging can proceed. In practice, diffraction patterns may contain only a small number of reliable peaks, be contaminated by background or spuriously detected reflections, or arise from crystals with highly skewed unit cells. These factors make indexing unstable in the small-N regime. We introduce a robust indexing algorithm tailored to this setting. We formulate indexing as a symmetry-aware lattice decoding problem and design a loss that explicitly incorporates lattice symmetries while trimming outlier peaks that are inconsistent with any plausible orientation. We combine this objective with a reciprocal-space basis reparameterization that stabilizes decoding for skewed or poorly conditioned lattices, and we develop a dedicated small-N objective mode that couples refined peak scoring with a method to recover orientations from very few reflections. The resulting method is memory-efficient and suitable for robust indexing. We evaluate our approach on three protein datasets from the Coherent X-ray Imaging Data Bank collected at XFEL facilities, using identical preprocessing and unit-cell information across methods. Across all datasets, our algorithm matches or outperforms established indexers such as XGANDALF and TORO, with particularly large gains for patterns with few indexed peaks and for crystals with skewed unit cells. While slower, our method is extremely memory-efficient, and its structure allows high-parallelism on CPUs or larger batch sizes on GPUs. These results show that exploiting lattice structure, symmetry, and small-N-aware search yields substantial improvements in indexing robustness.

</details>


### [129] [MDcraft -- a modern molecular dynamics simulation package with machine learning potentials support](https://arxiv.org/abs/2511.22951)
*I. S. Galtsov,R. V. Muratov,G. V. Vyskvarko,S. A. Murzov,S. A. Dyachkov,P. R. Levashov*

Main category: physics.comp-ph

TL;DR: MDcraft是一个现代化的分子动力学平台，集成了机器学习构建精确原子间势能的方法，提供Python API和C++核心算法，支持MPI并行化和多线程计算，适用于高性能计算集群。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟的质量依赖于力场近似，从简单模型到量子直接解算。近年来，机器学习方法在构建精确原子间势能方面受到关注，但需要将这些进展集成到可扩展、物理精确的框架中。

Method: MDcraft采用高级Python API和用户友好的脚本界面，核心模拟算法用C++实现以确保鲁棒性和计算效率。支持MPI动态域分解和负载均衡进行可扩展并行化，并在节点内利用标准C++并行化实现多线程，有效利用异构架构。

Result: 通过多个示例展示了代码能力，包括铝的冲击响应、氩的冲击Hugoniot和铜的冷曲线，证明了平台在复杂分子动力学模拟中的有效性。

Conclusion: MDcraft是一个全面、现代化的分子动力学平台，将机器学习构建精确势能的最新进展集成到可扩展、高性能的计算框架中，为复杂分子动力学模拟提供了强大工具。

Abstract: Molecular dynamics is widely used to study various phenomena, such as diffusion, shock wave propagation, and plasma dynamics. A wide range of software packages supports the expanding scope of molecular dynamics applications. However, the quality of simulations depends on force field approximations, ranging from simple models to direct quantum solutions. Recently, machine learning approaches for constructing accurate interatomic potentials have received significant attention. In MDcraft, we integrate these advances into a scalable, physically accurate framework. MDcraft is a comprehensive, modern molecular dynamics platform. It offers a high-level Python API with a user-friendly, script-based interface. The core simulation algorithms are implemented in C++ to ensure robustness and computational efficiency. MDcraft is built for high-performance computing on modern clusters and supports dynamic domain decomposition and load balancing via the Message Passing Interface (MPI) for scalable parallelization. Additionally, MDcraft leverages multithreading within nodes through standard C++ parallelism, enabling efficient use of heterogeneous architectures. We demonstrate the code's capabilities through several examples, including the shock response in aluminum, the shock Hugoniot in argon, and the cold curve of copper.

</details>


### [130] [Discontinuity-aware physics-informed neural networks for phase-field method in three-phase flows](https://arxiv.org/abs/2511.23102)
*Guoqiang Lei,Zhihua Wang,Lijing Zhou,D. Exposito,Xuerui Mao*

Main category: physics.comp-ph

TL;DR: 提出了一种不连续性感知的物理信息神经网络（DPINN），用于解决三相流相场模型，通过不连续性感知架构和局部人工粘度项来准确捕捉尖锐界面和相变动力学。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在处理多相流时存在梯度方向冲突问题，无法扩展到三相流相变问题，且界面厚度会被人为放大，影响精度。

Method: 提出DPINN方法，包含：1）不连续性感知的残差自适应架构来缓解频谱偏差并自动检测尖锐界面；2）可学习的局部人工粘度项来稳定陡峭梯度区域；3）自适应时间推进和损失平衡策略来减少误差累积和梯度冲突。

Result: 在两相反向单涡和气泡上升问题中，该方法准确解析了传统PINNs无法收敛的尖锐界面动力学；在三相液滴结冰案例中，成功捕捉了相变动力学和尖点形成，粘度比和密度比分别超过7和3个数量级。

Conclusion: DPINN方法成功解决了相场PINNs在梯度冲突和界面厚度放大方面的限制，能够准确模拟三相流相变问题，为多相流建模提供了有效工具。

Abstract: Physics-informed neural networks (PINNs) have proved to be a promising method for modeling multiphase flows. However, due to the gradient-direction conflict during the optimization of the coupled strongly nonlinear Allen-Cahn, Cahn-Hilliard, and Navier-Stokes equations, phase-field-based PINNs have not been extended to three-phase flows with phase change. Furthermore, the interface thickness is known to be artificially magnified, whether in numerical or artificial intelligence-based simulations, reducing accuracy. To mitigate these limitations, this study presents a discontinuity-aware physics-informed neural network (DPINN) that solves an energy-stable phase-field model for three-phase flows. It incorporates a discontinuity-aware residual-adaptive architecture to mitigate spectral bias and to automatically detect and model sharp interfaces, and a learnable local artificial-viscosity term to stabilize the algorithm near steep gradients. During optimization, adaptive time-marching and loss-balancing strategies are introduced to reduce long-term error accumulation and to mitigate gradient conflicts in multi-objective training, respectively. In numerical experiments on the two-phase reversed single-vortex and bubble-rising problems, the proposed method accurately resolves sharp interfacial dynamics that conventional PINNs fail to converge. It also extends to a three-phase droplet-icing case with viscosity and density ratios exceeding 7 and 3 orders of magnitude, accurately capturing the phase-change dynamics and the formation of the pointy tip.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [131] [Artificial intelligence for methane detection: from continuous monitoring to verified mitigation](https://arxiv.org/abs/2511.21777)
*Anna Allen,Gonzalo Mateo-Garcia,Itziar Irakulis-Loitxate,Manuel Montesino-San Martin,Marc Watine,James Requeima,Javier Gorroño,Cynthia Randles,Tharwat Mokalled,Luis Guanter,Richard E. Turner,Claudio Cifarelli,Manfredi Caltagirone*

Main category: cs.LG

TL;DR: MARS-S2L是一个机器学习模型，利用公开的多光谱卫星图像检测甲烷排放，每两天提供高分辨率检测，能够识别78%的排放羽流，误报率8%，已成功应用于实际减排。


<details>
  <summary>Details</summary>
Motivation: 甲烷是强效温室气体，少数大型点源排放占比较大，针对这些点源减排潜力巨大。目前大规模检测和归因大型甲烷排放仍具挑战性，需要通知资产所有者进行减排。

Method: 开发MARS-S2L机器学习模型，基于超过80,000张手动标注图像训练，利用公开可用的多光谱卫星图像检测甲烷排放，每两天提供高分辨率检测，实现设施级归因。

Result: 在697个未见过的站点上，模型检测到78%的排放羽流，误报率8%。已向20个国家的利益相关方发出1,015次通知，成功实现6个持续排放源的永久减排，包括利比亚一个先前未知的排放点。

Conclusion: MARS-S2L展示了从卫星检测到可量化甲烷减排的可扩展路径，为大规模甲烷排放监测和减排提供了有效工具。

Abstract: Methane is a potent greenhouse gas, responsible for roughly 30\% of warming since pre-industrial times. A small number of large point sources account for a disproportionate share of emissions, creating an opportunity for substantial reductions by targeting relatively few sites. Detection and attribution of large emissions at scale for notification to asset owners remains challenging. Here, we introduce MARS-S2L, a machine learning model that detects methane emissions in publicly available multispectral satellite imagery. Trained on a manually curated dataset of over 80,000 images, the model provides high-resolution detections every two days, enabling facility-level attribution and identifying 78\% of plumes with an 8\% false positive rate at 697 previously unseen sites. Deployed operationally, MARS-S2L has issued 1,015 notifications to stakeholders in 20 countries, enabling verified, permanent mitigation of six persistent emitters, including a previously unknown site in Libya. These results demonstrate a scalable pathway from satellite detection to quantifiable methane mitigation.

</details>


### [132] [Physics-Informed Spiking Neural Networks via Conservative Flux Quantization](https://arxiv.org/abs/2511.21784)
*Chi Zhang,Lin Wang*

Main category: cs.LG

TL;DR: 提出PISNN框架，结合物理约束与脉冲神经网络，通过C-LIF神经元和CFQ策略实现严格物理守恒和长期泛化，适用于边缘设备的实时物理预测。


<details>
  <summary>Details</summary>
Motivation: 边缘设备需要实时、物理一致的预测，但传统PINNs能耗高且难以严格保证物理守恒定律。脉冲神经网络(SNNs)适合边缘计算，但简单转换会降低物理保真度。

Method: 提出物理信息脉冲神经网络(PISNN)框架：1) 设计C-LIF神经元，其动力学结构保证局部质量守恒；2) 提出CFQ策略，将神经脉冲重新定义为物理通量的离散包，学习时间不变的物理演化算子。

Result: 在1D热方程和2D拉普拉斯方程等基准测试中表现出色，能准确模拟系统动力学，同时通过设计保持完美的质量守恒，优于传统PINNs。

Conclusion: 建立了将科学计算的严谨性与神经形态工程效率融合的稳健框架，为智能系统的复杂、长期、高效能物理预测铺平道路。

Abstract: Real-time, physically-consistent predictions on low-power edge devices is critical for the next generation embodied AI systems, yet it remains a major challenge. Physics-Informed Neural Networks (PINNs) combine data-driven learning with physics-based constraints to ensure the model's predictions are with underlying physical principles.However, PINNs are energy-intensive and struggle to strictly enforce physical conservation laws. Brain-inspired spiking neural networks (SNNs) have emerged as a promising solution for edge computing and real-time processing. However, naively converting PINNs to SNNs degrades physical fidelity and fails to address long-term generalization issues. To this end, this paper introduce a novel Physics-Informed Spiking Neural Network (PISNN) framework. Importantly, to ensure strict physical conservation, we design the Conservative Leaky Integrate-and-Fire (C-LIF) neuron, whose dynamics structurally guarantee local mass preservation. To achieve robust temporal generalization, we introduce a novel Conservative Flux Quantization (CFQ) strategy, which redefines neural spikes as discrete packets of physical flux. Our CFQ learns a time-invariant physical evolution operator, enabling the PISNN to become a general-purpose solver -- conservative-by-construction. Extensive experiments show that our PISNN excels on diverse benchmarks. For both the canonical 1D heat equation and the more challenging 2D Laplace's Equation, it accurately simulates the system dynamics while maintaining perfect mass conservation by design -- a feat that is challenging for conventional PINNs. This work establishes a robust framework for fusing the rigor of scientific computing with the efficiency of neuromorphic engineering, paving the way for complex, long-term, and energy-efficient physics predictions for intelligent systems.

</details>


### [133] [Dynamical Implicit Neural Representations](https://arxiv.org/abs/2511.21787)
*Yesom Park,Kelvin Kan,Thomas Flynn,Yi Huang,Shinjae Yoo,Stanley Osher,Xihaier Luo*

Main category: cs.LG

TL;DR: DINR将隐式神经表示建模为连续时间动力系统而非离散层堆叠，通过连续特征演化缓解频谱偏差，在表达能力和泛化性上优于传统静态INR。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INR）在建模复杂视觉和几何信号方面具有强大能力，但频谱偏差问题限制了其捕捉高频细节的能力。现有解决方案效果有限，需要新的建模框架来克服这一根本挑战。

Method: 提出动态隐式神经表示（DINR），将特征演化视为连续时间动力系统而非离散层堆叠。通过基于Rademacher复杂度和神经正切核的理论分析，证明DINR能增强表达能力并改善训练动态。通过正则化底层动力学的复杂度来平衡表达能力和泛化性。

Result: 在图像表示、场重建和数据压缩等任务上的大量实验表明，DINR相比传统静态INR具有更稳定的收敛性、更高的信号保真度和更强的泛化能力。

Conclusion: DINR通过将INR建模为连续时间动力系统，有效缓解了频谱偏差问题，在保持良好泛化性的同时显著提升了表达能力，为隐式神经表示提供了新的建模框架。

Abstract: Implicit Neural Representations (INRs) provide a powerful continuous framework for modeling complex visual and geometric signals, but spectral bias remains a fundamental challenge, limiting their ability to capture high-frequency details. Orthogonal to existing remedy strategies, we introduce Dynamical Implicit Neural Representations (DINR), a new INR modeling framework that treats feature evolution as a continuous-time dynamical system rather than a discrete stack of layers. This dynamical formulation mitigates spectral bias by enabling richer, more adaptive frequency representations through continuous feature evolution. Theoretical analysis based on Rademacher complexity and the Neural Tangent Kernel demonstrates that DINR enhances expressivity and improves training dynamics. Moreover, regularizing the complexity of the underlying dynamics provides a principled way to balance expressivity and generalization. Extensive experiments on image representation, field reconstruction, and data compression confirm that DINR delivers more stable convergence, higher signal fidelity, and stronger generalization than conventional static INRs.

</details>


### [134] [Multiclass threshold-based classification and model evaluation](https://arxiv.org/abs/2511.21794)
*Edoardo Legnaro,Sabrina Guastavino,Francesco Marchetti*

Main category: cs.LG

TL;DR: 提出基于阈值的多类分类框架，用多维阈值替代argmax规则，通过阈值调优提升分类性能，并引入ROC云和DFP评分进行多类ROC分析。


<details>
  <summary>Details</summary>
Motivation: 传统多类分类使用softmax输出的argmax规则，缺乏类似二分类中的阈值调优机制。本文旨在将二分类中的阈值优化思想扩展到多类场景，以进一步提升任何已训练网络的预测能力。

Method: 将softmax输出的概率解释转换为多维单纯形上的几何解释，引入多维阈值进行分类决策。提出多维阈值调优方法，并基于ROC云进行多类ROC分析，使用距离点(DFP)评分总结性能。

Result: 实验表明，多维阈值调优能在不同网络和数据集上带来性能提升。提出的ROC云和DFP评分提供了比传统OvR曲线更一致的多类ROC分析方法，与观察到的调优增益一致。

Conclusion: 本文提出的阈值框架为多类分类提供了类似二分类的调优能力，通过后验阈值优化可进一步提升任何网络的预测性能，同时提供了更一致的多类ROC分析工具。

Abstract: In this paper, we introduce a threshold-based framework for multiclass classification that generalizes the standard argmax rule. This is done by replacing the probabilistic interpretation of softmax outputs with a geometric one on the multidimensional simplex, where the classification depends on a multidimensional threshold. This change of perspective enables for any trained classification network an \textit{a posteriori} optimization of the classification score by means of threshold tuning, as usually carried out in the binary setting, thus allowing for a further refinement of the prediction capability of any network. Our experiments show indeed that multidimensional threshold tuning yields performance improvements across various networks and datasets. Moreover, we derive a multiclass ROC analysis based on \emph{ROC clouds} -- the attainable (FPR,TPR) operating points induced by a single multiclass threshold -- and summarize them via a \emph{Distance From Point} (DFP) score to $(0,1)$. This yields a coherent alternative to standard One-vs-Rest (OvR) curves and aligns with the observed tuning gains.

</details>


### [135] [The Double-Edged Nature of the Rashomon Set for Trustworthy Machine Learning](https://arxiv.org/abs/2511.21799)
*Ethan Hsu,Harry Chen,Chudi Zhong,Lesia Semenova*

Main category: cs.LG

TL;DR: Rashomon集合（多个近似最优模型）在可信机器学习中呈现鲁棒性与隐私性的权衡：模型多样性增强对抗攻击的鲁棒性和分布偏移稳定性，但同时也增加了训练数据的信息泄露风险。


<details>
  <summary>Details</summary>
Motivation: 现实机器学习管道通常产生多个近似最优模型（Rashomon集合），而非单一模型。研究这种模型多样性如何影响可信机器学习的关键方面，特别是鲁棒性和隐私性之间的权衡。

Method: 通过理论分析和实证研究，分析稀疏决策树和线性模型构成的Rashomon集合。在个体模型层面分析稀疏可解释模型的特性，在集合层面研究多样性的影响。

Result: 稀疏可解释模型保护隐私但对对抗攻击脆弱；Rashomon集合的多样性实现反应式鲁棒性（攻击破坏一个模型时其他模型仍准确），且在小分布偏移下保持稳定。但多样性也增加信息泄露风险，披露更多近似最优模型为攻击者提供更丰富的训练数据视图。

Conclusion: Rashomon集合在可信机器学习中具有双重角色：既是资源（提供鲁棒性和稳定性），也是风险（增加隐私泄露）。研究揭示了模型多样性带来的鲁棒性与隐私性之间的基本权衡。

Abstract: Real-world machine learning (ML) pipelines rarely produce a single model; instead, they produce a Rashomon set of many near-optimal ones. We show that this multiplicity reshapes key aspects of trustworthiness. At the individual-model level, sparse interpretable models tend to preserve privacy but are fragile to adversarial attacks. In contrast, the diversity within a large Rashomon set enables reactive robustness: even when an attack breaks one model, others often remain accurate. Rashomon sets are also stable under small distribution shifts. However, this same diversity increases information leakage, as disclosing more near-optimal models provides an attacker with progressively richer views of the training data. Through theoretical analysis and empirical studies of sparse decision trees and linear models, we characterize this robustness-privacy trade-off and highlight the dual role of Rashomon sets as both a resource and a risk for trustworthy ML.

</details>


### [136] [Unsupervised Anomaly Detection for Smart IoT Devices: Performance and Resource Comparison](https://arxiv.org/abs/2511.21842)
*Md. Sad Abdullah Sami,Mushfiquzzaman Abid*

Main category: cs.LG

TL;DR: 该研究比较了两种无监督异常检测方法（Isolation Forest和OC-SVM）在IoT环境中的性能，发现Isolation Forest在检测精度和计算效率方面均优于OC-SVM，更适合资源受限的IoT边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 随着IoT设备在各行业的快速部署，虽然提升了运营效率，但也增加了网络安全漏洞。传统基于签名的异常检测系统难以识别新兴和零日威胁，因此需要研究更有效的无监督异常检测技术来保护IoT环境。

Method: 使用TON_IoT恒温器数据集，评估两种无监督异常检测技术：Isolation Forest（IF）和One-Class Support Vector Machine（OC-SVM）。采用标准性能指标（准确率、精确率、召回率、F1分数）和资源利用指标（推理时间、模型大小、峰值RAM使用量）进行综合评估。

Result: Isolation Forest在所有评估指标上均优于OC-SVM：获得更高的检测准确率、更优的精确率和召回率，以及显著更好的F1分数。此外，Isolation Forest展现出明显更优的计算足迹，推理时间更短、模型更小、RAM使用更少。

Conclusion: Isolation Forest在高维和不平衡的IoT环境中表现出更强的鲁棒性，其优越的计算效率使其更适合部署在资源受限的IoT边缘设备上，具有实际实时异常检测的可行性。

Abstract: The rapid expansion of Internet of Things (IoT) deployments across diverse sectors has significantly enhanced operational efficiency, yet concurrently elevated cybersecurity vulnerabilities due to increased exposure to cyber threats. Given the limitations of traditional signature-based Anomaly Detection Systems (ADS) in identifying emerging and zero-day threats, this study investigates the effectiveness of two unsupervised anomaly detection techniques, Isolation Forest (IF) and One-Class Support Vector Machine (OC-SVM), using the TON_IoT thermostat dataset. A comprehensive evaluation was performed based on standard metrics (accuracy, precision, recall, and F1-score) alongside critical resource utilization metrics such as inference time, model size, and peak RAM usage. Experimental results revealed that IF consistently outperformed OC-SVM, achieving higher detection accuracy, superior precision, and recall, along with a significantly better F1-score. Furthermore, Isolation Forest demonstrated a markedly superior computational footprint, making it more suitable for deployment on resource-constrained IoT edge devices. These findings underscore Isolation Forest's robustness in high-dimensional and imbalanced IoT environments and highlight its practical viability for real-time anomaly detection.

</details>


### [137] [Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics](https://arxiv.org/abs/2511.21848)
*Eric Leonardis,Akira Nagamori,Ayesha Thanawalla,Yuanjia Yang,Joshua Park,Hutton Saunders,Eiman Azim,Talmo Pereira*

Main category: cs.LG

TL;DR: 该研究开发了一个行为驱动的仿真平台，用于模拟高保真行为动力学、生物力学和神经回路架构，通过模仿学习框架实现小鼠前肢肌肉骨骼模型的灵巧抓取任务，发现能量和速度的自然约束能更好地预测真实EMG信号。


<details>
  <summary>Details</summary>
Motivation: 大脑进化出有效控制身体的能力，为了理解这种关系，需要建模控制身体的感觉运动转换。研究旨在开发一个通用平台来模拟高保真行为动力学、生物力学和神经回路架构。

Method: 开发了一个从神经科学实验室获取运动学数据并创建管道来在生物力学模型中重现这些自然运动的流程。采用模仿学习框架在模拟物理环境中执行灵巧的前肢抓取任务，使用JAX和Mujoco-MJX进行GPU加速训练。

Result: 小鼠手臂模型训练速度超过每秒100万训练步。研究发现，添加能量和速度的自然约束会导致模拟的肌肉骨骼活动能更好地预测真实的EMG信号。

Conclusion: 这项研究表明能量和控制约束对于建模肌肉骨骼运动控制至关重要，为理解大脑如何控制身体提供了重要证据。

Abstract: The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control.

</details>


### [138] [Lightweight ML-Based Air Quality Prediction for IoT and Embedded Applications](https://arxiv.org/abs/2511.21857)
*Md. Sad Abdullah Sami,Mushfiquzzaman Abid*

Main category: cs.LG

TL;DR: 该研究比较了完整版和轻量版XGBoost回归模型在预测CO和NO2浓度方面的表现，发现完整版精度更高，但轻量版在计算资源消耗方面优势明显，适合物联网等资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估不同复杂度的XGBoost模型在空气质量预测任务中的表现，特别是在资源受限环境（如物联网设备）中部署的可行性，以平衡预测精度和计算效率。

Method: 使用AirQualityUCI数据集（一年城市环境数据），评估完整版和轻量版XGBoost回归模型。采用MAE、RMSE、MBE、R2等预测指标，以及推理时间、模型大小、峰值RAM使用等资源指标进行综合评估。

Result: 完整版XGBoost模型对CO和NO2的预测精度更高，但轻量版模型在推理时间、模型存储和RAM使用方面显著更优，预测精度虽有轻微下降但仍可接受。

Conclusion: 轻量版XGBoost模型在资源受限环境中具有实用价值，可在不显著牺牲预测质量的前提下实现高效部署，适合物联网和嵌入式系统的实时空气质量监测应用。

Abstract: This study investigates the effectiveness and efficiency of two variants of the XGBoost regression model, the full-capacity and lightweight (tiny) versions, for predicting the concentrations of carbon monoxide (CO) and nitrogen dioxide (NO2). Using the AirQualityUCI dataset collected over one year in an urban environment, we conducted a comprehensive evaluation based on widely accepted metrics, including Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Mean Bias Error (MBE), and the coefficient of determination (R2). In addition, we assessed resource-oriented metrics such as inference time, model size, and peak RAM usage. The full XGBoost model achieved superior predictive accuracy for both pollutants, while the tiny model, though slightly less precise, offered substantial computational benefits with significantly reduced inference time and model storage requirements. These results demonstrate the feasibility of deploying simplified models in resource-constrained environments without compromising predictive quality. This makes the tiny XGBoost model suitable for real-time air-quality monitoring in IoT and embedded applications.

</details>


### [139] [Towards a Foundation Model for Partial Differential Equations Across Physics Domains](https://arxiv.org/abs/2511.21861)
*Eduardo Soares,Emilio Vital Brazil,Victor Shirasuna,Breno W. S. R. de Carvalho,Cristiano Malossi*

Main category: cs.LG

TL;DR: PDE-FM是一个用于物理信息机器学习的模块化基础模型，通过统一空间、频谱和时间推理来处理异质偏微分方程系统，在多个物理领域实现了最先进的精度和跨物理泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的任务特定神经算子需要针对不同物理系统进行专门设计和训练，缺乏统一的、可迁移的模型来处理多样化的偏微分方程系统。需要开发一个能够跨不同物理领域进行泛化的基础模型。

Method: PDE-FM结合了空间-频谱标记化、物理感知条件化和基于Mamba的状态空间主干网络，以及算子理论解码器。模型在多样化的PDE数据集上进行一次性预训练，无需架构或数据特定修改即可迁移到新的物理体系。

Result: 在The Well基准测试的12个2D和3D数据集上评估，涵盖流体动力学、辐射、弹性和天体物理现象。PDE-FM在六个领域实现了最先进的精度，相对于先前的算子学习基线，平均VRMSE降低了46%。模型展示了强大的跨物理泛化能力，在湍流和辐射系统中表现出色，同时在线性和稳态体系中保持强劲性能。

Conclusion: 跨多样物理过程的大规模预训练可以产生可迁移的动态表示，这标志着向统一的多物理仿真和科学发现基础级代理迈出了一步。PDE-FM展示了基础模型在物理信息机器学习中的潜力。

Abstract: We present PDE-FM, a modular foundation model for physics-informed machine learning that unifies spatial, spectral, and temporal reasoning across heterogeneous partial differential equation (PDE) systems. PDE-FM combines spatial-spectral tokenization, physics-aware conditioning, and a Mamba-based state-space backbone with an operator-theoretic decoder, enabling scalable and data-efficient modeling of complex physical dynamics. In contrast to task-specific neural operators, PDE-FM is pretrained once on diverse PDE datasets and can be transferred to new physical regimes without architectural or data-specific modifications. Evaluated on twelve 2D and 3D datasets from The Well benchmark - spanning hydrodynamic, radiative, elastic, and astrophysical phenomena - PDE-FM achieves state-of-the-art accuracy in six domains, reducing mean VRMSE by 46% relative to prior operator-learning baselines. The model demonstrates robust cross-physics generalization, excelling in turbulent and radiative systems while maintaining strong performance in linear and steady-state regimes. These results suggest that large-scale pretraining across diverse physical processes can yield transferable representations of dynamics, marking a step toward unified, foundation-level surrogates for multi-physics simulation and scientific discovery.

</details>


### [140] [Closed-Loop Transformers: Autoregressive Modeling as Iterative Latent Equilibrium](https://arxiv.org/abs/2511.21882)
*Akbar Anbar Jafari,Gholamreza Anbarjafari*

Main category: cs.LG

TL;DR: 提出Equilibrium Transformers (EqT)，通过闭环预测原则让模型在生成每个token前迭代优化隐表示，解决传统自回归模型的开环瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前自回归变换器采用开环操作：每个隐藏状态仅通过一次前向传播计算且永不修正，导致错误在序列中传播。这限制了模型在长程推理、事实一致性和多步规划方面的能力。

Method: 引入闭环预测原则，要求模型在生成每个token前迭代优化隐表示直至达到自洽平衡。具体实现为Equilibrium Transformers (EqT)，在标准变换器层中加入Equilibrium Refinement Module，通过梯度下降最小化学习的能量函数来优化隐空间表示。

Result: 在二进制奇偶校验任务上，EqT平均提升3.28%，在标准变换器接近随机性能的困难序列上提升达8.07%。理论证明EqT在隐能量模型中执行近似MAP推断，具有线性收敛保证。

Conclusion: 闭环平衡机制可能解决自回归模型的开环承诺瓶颈，正如注意力机制解决了循环网络的序列瓶颈一样，这代表了向更强大语言模型发展的基础性一步。

Abstract: Contemporary autoregressive transformers operate in open loop: each hidden state is computed in a single forward pass and never revised, causing errors to propagate uncorrected through the sequence. We identify this open-loop bottleneck as a fundamental architectural limitation underlying well-documented failures in long-range reasoning, factual consistency, and multi-step planning. To address this limitation, we introduce the closed-loop prediction principle, which requires that models iteratively refine latent representations until reaching a self-consistent equilibrium before committing to each token. We instantiate this principle as Equilibrium Transformers (EqT), which augment standard transformer layers with an Equilibrium Refinement Module that minimizes a learned energy function via gradient descent in latent space. The energy function enforces bidirectional prediction consistency, episodic memory coherence, and output confidence, all computed without external supervision. Theoretically, we prove that EqT performs approximate MAP inference in a latent energy-based model, establish linear convergence guarantees, and show that refinement improves predictions precisely on hard instances where one-shot inference is suboptimal. The framework unifies deep equilibrium models, diffusion language models, and test-time training as special cases. Preliminary experiments on the binary parity task demonstrate +3.28% average improvement on challenging sequences, with gains reaching +8.07% where standard transformers approach random performance, validating that the benefit of deliberation scales with task difficulty. Just as attention mechanisms resolved the sequential bottleneck of recurrent networks, we propose that closed-loop equilibrium may resolve the commitment bottleneck of open-loop autoregression, representing a foundational step toward language models.

</details>


### [141] [Physically Interpretable Representation Learning with Gaussian Mixture Variational AutoEncoder (GM-VAE)](https://arxiv.org/abs/2511.21883)
*Tiffany Fan,Murray Cutforth,Marta D'Elia,Alexandre Cortiella,Alireza Doostan,Eric Darve*

Main category: cs.LG

TL;DR: 提出GM-VAE框架，结合EM训练方案和谱可解释性度量，从高维科学数据中提取物理可解释的紧凑表示，应用于湍流和反应流系统。


<details>
  <summary>Details</summary>
Motivation: 从高维科学数据中提取紧凑且物理可解释的表示是一个持续挑战，因为物理系统具有复杂的非线性结构。传统VAE在同时优化重建和聚类时存在训练不稳定的问题。

Method: 提出高斯混合变分自编码器(GM-VAE)框架，采用块坐标下降策略，交替执行期望步和最大化步，结合基于图拉普拉斯平滑度的谱可解释性度量来评估学习到的表示。

Result: 在表面反应ODE、Navier-Stokes尾流和实验激光诱导燃烧纹影图像等数据集上验证，GM-VAE能产生平滑的物理一致流形和准确的机制聚类。

Conclusion: GM-VAE框架为解释湍流和反应流系统提供了鲁棒的数据驱动工具，能稳定训练并使潜在聚类与不同物理机制自然对齐。

Abstract: Extracting compact, physically interpretable representations from high-dimensional scientific data is a persistent challenge due to the complex, nonlinear structures inherent in physical systems. We propose a Gaussian Mixture Variational Autoencoder (GM-VAE) framework designed to address this by integrating an Expectation-Maximization (EM)-inspired training scheme with a novel spectral interpretability metric. Unlike conventional VAEs that jointly optimize reconstruction and clustering (often leading to training instability), our method utilizes a block-coordinate descent strategy, alternating between expectation and maximization steps. This approach stabilizes training and naturally aligns latent clusters with distinct physical regimes. To objectively evaluate the learned representations, we introduce a quantitative metric based on graph-Laplacian smoothness, which measures the coherence of physical quantities across the latent manifold. We demonstrate the efficacy of this framework on datasets of increasing complexity: surface reaction ODEs, Navier-Stokes wake flows, and experimental laser-induced combustion Schlieren images. The results show that our GM-VAE yields smooth, physically consistent manifolds and accurate regime clustering, offering a robust data-driven tool for interpreting turbulent and reactive flow systems.

</details>


### [142] [Exploring Fusion Strategies for Multimodal Vision-Language Systems](https://arxiv.org/abs/2511.21889)
*Regan Willis,Jason Bakos*

Main category: cs.LG

TL;DR: 该论文研究了多模态机器学习中不同融合策略对准确性和延迟的权衡，通过BERT与视觉网络（MobileNetV2和ViT）的混合框架，在CMU MOSI数据集上评估了早、中、晚三种融合策略的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在多模态机器学习中，如何融合不同数据流需要在准确性和延迟之间做出权衡。早期或晚期融合会影响模型的性能和推理速度，需要系统研究这种权衡关系。

Method: 使用混合BERT和视觉网络框架（MobileNetV2和ViT）集成图像和文本数据。为每个视觉网络提出了三种模型：晚期融合、中期融合和早期融合。在CMU MOSI数据集上评估准确性，在NVIDIA Jetson Orin AGX上基准测试延迟。

Result: 实验结果表明：晚期融合获得最高准确性，早期融合提供最低推理延迟。具体来说，模型架构中数据融合越早，推理时间越快，但准确性会相应降低。

Conclusion: 多模态融合策略需要在准确性和延迟之间权衡：早期融合提供更快的推理速度但准确性较低，晚期融合准确性更高但延迟更大。实际应用中应根据具体需求选择合适的融合策略。

Abstract: Modern machine learning models often combine multiple input streams of data to more accurately capture the information that informs their decisions. In multimodal machine learning, choosing the strategy for fusing data together requires careful consideration of the application's accuracy and latency requirements, as fusing the data at earlier or later stages in the model architecture can lead to performance changes in accuracy and latency. To demonstrate this tradeoff, we investigate different fusion strategies using a hybrid BERT and vision network framework that integrates image and text data. We explore two different vision networks: MobileNetV2 and ViT. We propose three models for each vision network, which fuse data at late, intermediate, and early stages in the architecture. We evaluate the proposed models on the CMU MOSI dataset and benchmark their latency on an NVIDIA Jetson Orin AGX. Our experimental results demonstrate that while late fusion yields the highest accuracy, early fusion offers the lowest inference latency. We describe the three proposed model architectures and discuss the accuracy and latency tradeoffs, concluding that data fusion earlier in the model architecture results in faster inference times at the cost of accuracy.

</details>


### [143] [Breaking the Illusion: Consensus-Based Generative Mitigation of Adversarial Illusions in Multi-Modal Embeddings](https://arxiv.org/abs/2511.21893)
*Fatemeh Akbarian,Anahita Baninajjar,Yingyi Zhang,Ananth Balashankar,Amir Aminifar*

Main category: cs.LG

TL;DR: 提出一种任务无关的防御机制，通过生成模型重构对抗性扰动输入，结合生成采样和共识聚合策略，有效抵御多模态基础模型中的对抗性幻觉攻击。


<details>
  <summary>Details</summary>
Motivation: 多模态基础模型虽然能在共享嵌入空间中对齐图像、文本等模态，但容易受到对抗性幻觉攻击的影响，这些攻击通过微小扰动破坏跨模态对齐并误导下游任务。

Method: 提出任务无关的缓解机制：1) 使用生成模型（如VAE）从攻击者的扰动输入中重构原始输入以保持自然对齐；2) 采用生成采样策略结合基于共识的聚合方案，对生成样本的结果进行聚合。

Result: 在先进的多模态编码器上实验表明，该方法将幻觉攻击成功率大幅降低至接近零，在未扰动和扰动输入设置下分别将跨模态对齐提高了4%（42到46）和11%（32到43）。

Conclusion: 该方法提供了一种有效且模型无关的防御机制，能够显著抵御多模态基础模型中的对抗性幻觉攻击，提高模型的鲁棒性和跨模态对齐能力。

Abstract: Multi-modal foundation models align images, text, and other modalities in a shared embedding space but remain vulnerable to adversarial illusions (Zhang et al., 2025), where imperceptible perturbations disrupt cross-modal alignment and mislead downstream tasks. To counteract the effects of adversarial illusions, we propose a task-agnostic mitigation mechanism that reconstructs the input from the attacker's perturbed input through generative models, e.g., Variational Autoencoders (VAEs), to maintain natural alignment. To further enhance our proposed defense mechanism, we adopt a generative sampling strategy combined with a consensus-based aggregation scheme over the outcomes of the generated samples. Our experiments on the state-of-the-art multi-modal encoders show that our approach substantially reduces the illusion attack success rates to near-zero and improves cross-modal alignment by 4% (42 to 46) and 11% (32 to 43) in unperturbed and perturbed input settings respectively, providing an effective and model-agnostic defense against adversarial illusions.

</details>


### [144] [Beyond Atoms: Evaluating Electron Density Representation for 3D Molecular Learning](https://arxiv.org/abs/2511.21900)
*Patricia Suriana,Joshua A. Rackers,Ewa M. Nowara,Pedro O. Pinheiro,John M. Nicoloudis,Vishnu Sresht*

Main category: cs.LG

TL;DR: 比较三种体素输入（原子类型、原始电子密度、密度梯度）在3D CNN中的表现，发现电子密度在低数据量下优于原子类型，在量子性质预测中表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统基于原子的3D分子性质预测模型可能忽略细微物理信息，而电子密度作为X射线晶体学和冷冻电镜的直接输出，提供了连续、物理基础的表征方式。

Method: 使用三种体素输入类型（原子类型、原始电子密度、密度梯度大小）训练3D卷积神经网络，在两个任务上测试：蛋白质-配体结合亲和力预测（PDBbind）和量子性质预测（QM9）。

Result: 在PDBbind任务中，全数据量下所有表征表现相似，但在低数据量下，基于密度的输入优于原子类型；在QM9任务中，即使输入密度来自较低级别方法，基于密度的输入在规模上仍优于基于原子的输入。

Conclusion: 电子密度输入具有任务和机制依赖性优势，在亲和力预测中提高数据效率，在量子性质建模中提高准确性，突显了密度编码的丰富结构电子信息。

Abstract: Machine learning models for 3D molecular property prediction typically rely on atom-based representations, which may overlook subtle physical information. Electron density maps -- the direct output of X-ray crystallography and cryo-electron microscopy -- offer a continuous, physically grounded alternative. We compare three voxel-based input types for 3D convolutional neural networks (CNNs): atom types, raw electron density, and density gradient magnitude, across two molecular tasks -- protein-ligand binding affinity prediction (PDBbind) and quantum property prediction (QM9). We focus on voxel-based CNNs because electron density is inherently volumetric, and voxel grids provide the most natural representation for both experimental and computed densities. On PDBbind, all representations perform similarly with full data, but in low-data regimes, density-based inputs outperform atom types, while a shape-based baseline performs comparably -- suggesting that spatial occupancy dominates this task. On QM9, where labels are derived from Density Functional Theory (DFT) but input densities from a lower-level method (XTB), density-based inputs still outperform atom-based ones at scale, reflecting the rich structural and electronic information encoded in density. Overall, these results highlight the task- and regime-dependent strengths of density-derived inputs, improving data efficiency in affinity prediction and accuracy in quantum property modeling.

</details>


### [145] [Multi-Modal Machine Learning for Early Trust Prediction in Human-AI Interaction Using Face Image and GSR Bio Signals](https://arxiv.org/abs/2511.21908)
*Hamid Shamszare,Avishek Choudhury*

Main category: cs.LG

TL;DR: 多模态机器学习框架结合面部表情和皮肤电反应数据，在模拟ADHD移动健康场景中预测用户对AI或人类建议的早期信任度，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 预测人类对AI系统的信任对于AI决策支持工具的安全集成至关重要，特别是在医疗健康领域。在心理健康应用中，信任校准不当会影响诊断和治疗结果，因此需要实时、客观的信任标记来构建自适应AI系统。

Method: 提出多模态机器学习框架，结合图像（面部视频）和皮肤电反应（GSR）数据。面部数据使用OpenCV提取帧并通过预训练transformer模型提取情感特征；GSR信号分解为紧张性和阶段性成分。定义两个时间窗口：早期检测窗口（决策前6-3秒）和近端检测窗口（决策前3-0秒）。分别使用图像、GSR和多模态特征进行信任预测，通过多模态堆叠集成最佳单模态模型。

Result: 多模态堆叠框架在早期检测窗口达到准确率0.83、F1分数0.88、ROC-AUC 0.87；在近端检测窗口达到准确率0.75、F1分数0.82、ROC-AUC 0.66。结合面部和生理线索显著提升了预测性能。

Conclusion: 生物信号可作为实时、客观的用户信任标记，使自适应AI系统能够动态调整响应以维持校准的信任，这在心理健康应用中至关重要，因为信任校准不当会影响诊断和治疗结果。

Abstract: Predicting human trust in AI systems is crucial for safe integration of AI-based decision support tools, especially in healthcare. This study proposes a multi-modal machine learning framework that combines image and galvanic skin response (GSR) data to predict early user trust in AI- or human-generated recommendations in a simulated ADHD mHealth context. Facial video data were processed using OpenCV for frame extraction and transferred learning with a pre-trained transformer model to derive emotional features. Concurrently, GSR signals were decomposed into tonic and phasic components to capture physiological arousal patterns. Two temporal windows were defined for trust prediction: the Early Detection Window (6 to 3 seconds before decision-making) and the Proximal Detection Window (3 to 0 seconds before decision-making). For each window, trust prediction was conducted separately using image-based, GSR-based, and multimodal (image + GSR) features. Each modality was analyzed using machine learning algorithms, and the top-performing unimodal models were integrated through a multimodal stacking ensemble for final prediction. Experimental results showed that combining facial and physiological cues significantly improved prediction performance. The multimodal stacking framework achieved an accuracy of 0.83, F1-score of 0.88, and ROC-AUC of 0.87 in the Early Detection Window, and an accuracy of 0.75, F1-score of 0.82, and ROC-AUC of 0.66 in the Proximal Detection Window. These results demonstrate the potential of bio signals as real-time, objective markers of user trust, enabling adaptive AI systems that dynamically adjust their responses to maintain calibrated trust which is a critical capability in mental health applications where mis-calibrated trust can affect diagnostic and treatment outcomes.

</details>


### [146] [Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck](https://arxiv.org/abs/2511.21923)
*Xinyu Liu,Xu Zhang,Can Chen,Ren Wang*

Main category: cs.LG

TL;DR: 该论文通过信息瓶颈理论分析后门数据对神经网络训练动态的影响，发现后门攻击会创建独特的互信息特征，并揭示了一个反直觉的发现：视觉上明显的攻击在信息论角度可能更隐蔽。


<details>
  <summary>Details</summary>
Motivation: 理解后门数据如何影响神经网络训练动态是一个复杂且未被充分探索的挑战。现有研究缺乏对后门数据在学习过程中影响的深入分析，特别是在目标类别与其他干净类别之间的差异行为。

Method: 利用信息瓶颈原理结合内部表示的聚类分析，研究后门攻击在训练不同阶段创建的互信息特征。基于这些洞察，提出了一种新颖的基于动态的隐蔽性度量标准，用于量化攻击在模型层面的整合程度。

Result: 发现后门攻击会产生独特的互信息特征，这些特征随训练阶段演变且因攻击机制而异。揭示了一个反直觉的权衡：视觉上明显的攻击（如BadNets）从信息论角度可能实现更高的隐蔽性，比许多视觉不可察觉的攻击更无缝地整合到模型中。

Conclusion: 该研究通过信息瓶颈理论为理解后门威胁提供了新的维度，提出的动态隐蔽性度量标准能够有效评估攻击的隐蔽性，为后门攻击的检测和防御提供了新的理论基础。

Abstract: Understanding how backdoor data influences neural network training dynamics remains a complex and underexplored challenge. In this paper, we present a rigorous analysis of the impact of backdoor data on the learning process, with a particular focus on the distinct behaviors between the target class and other clean classes. Leveraging the Information Bottleneck (IB) principle connected with clustering of internal representation, We find that backdoor attacks create unique mutual information (MI) signatures, which evolve across training phases and differ based on the attack mechanism. Our analysis uncovers a surprising trade-off: visually conspicuous attacks like BadNets can achieve high stealthiness from an information-theoretic perspective, integrating more seamlessly into the model than many visually imperceptible attacks. Building on these insights, we propose a novel, dynamics-based stealthiness metric that quantifies an attack's integration at the model level. We validate our findings and the proposed metric across multiple datasets and diverse attack types, offering a new dimension for understanding and evaluating backdoor threats. Our code is available in: https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git.

</details>


### [147] [Prompted Policy Search: Reinforcement Learning through Linguistic and Numerical Reasoning in LLMs](https://arxiv.org/abs/2511.21928)
*Yifan Zhou,Sachin Grover,Mohamed El Mistiri,Kamalesh Kalirathnam,Pratyush Kerhalkar,Swaroop Mishra,Neelesh Kumar,Sanket Gaurav,Oya Aran,Heni Ben Amor*

Main category: cs.LG

TL;DR: ProPS是一种将大语言模型置于策略优化循环核心的新RL方法，通过结合数值奖励和语言输入直接提出策略更新，在15个任务中8个优于传统RL算法。


<details>
  <summary>Details</summary>
Motivation: 传统RL依赖标量奖励信号，无法利用现实任务中丰富的语义知识。人类学习能有效结合数值反馈与语言、先验知识和常识，因此需要统一数值和语言推理的框架。

Method: 提出Prompted Policy Search (ProPS)，将大语言模型置于策略优化循环的核心，直接基于奖励反馈和自然语言输入提出策略更新。LLM能够在上下文中执行数值优化，并整合目标、领域知识和策略提示等语义信号。

Result: 在15个Gymnasium任务（经典控制、Atari游戏、MuJoCo环境）中，ProPS在8个任务上优于7种广泛采用的RL算法（如PPO、SAC、TRPO）。当提供领域知识时，ProPS表现出显著性能提升。

Conclusion: 统一语义和数值推理能够实现更透明、可泛化且与人类对齐的强化学习。LLM在策略优化中的中心作用展示了结合语言和数值反馈的潜力。

Abstract: Reinforcement Learning (RL) traditionally relies on scalar reward signals, limiting its ability to leverage the rich semantic knowledge often available in real-world tasks. In contrast, humans learn efficiently by combining numerical feedback with language, prior knowledge, and common sense. We introduce Prompted Policy Search (ProPS), a novel RL method that unifies numerical and linguistic reasoning within a single framework. Unlike prior work that augment existing RL components with language, ProPS places a large language model (LLM) at the center of the policy optimization loop-directly proposing policy updates based on both reward feedback and natural language input. We show that LLMs can perform numerical optimization in-context, and that incorporating semantic signals, such as goals, domain knowledge, and strategy hints can lead to more informed exploration and sample-efficient learning. ProPS is evaluated across fifteen Gymnasium tasks, spanning classic control, Atari games, and MuJoCo environments, and compared to seven widely-adopted RL algorithms (e.g., PPO, SAC, TRPO). It outperforms all baselines on eight out of fifteen tasks and demonstrates substantial gains when provided with domain knowledge. These results highlight the potential of unifying semantics and numerics for transparent, generalizable, and human-aligned RL.

</details>


### [148] [Does the Model Say What the Data Says? A Simple Heuristic for Model Data Alignment](https://arxiv.org/abs/2511.21931)
*Henry Salgado,Meagan Kendall,Martine Ceberio*

Main category: cs.LG

TL;DR: 提出一个简单高效框架，评估机器学习模型是否与数据结构对齐，即模型是否"说出了数据所说的内容"


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法主要关注解释模型行为，但缺乏直接从数据本身建立基准来评估模型与数据对齐的方法。需要一种模型无关的方法来判断模型是否真实反映了数据的结构。

Method: 借鉴Rubin的潜在结果框架，量化每个特征在二分类任务中分离两个结果组的能力，超越传统描述性统计，估计每个特征对结果的影响。通过比较数据驱动的特征排序与基于模型的解释，评估模型-数据对齐。

Result: 开发了一个可解释且模型无关的方法，使从业者能够评估模型是否与数据结构对齐，为模型验证提供了新的基准。

Conclusion: 该框架为评估机器学习模型与数据对齐提供了一个简单、计算高效且模型无关的方法，有助于确保模型真实反映数据的结构而非引入偏差。

Abstract: In this work, we propose a simple and computationally efficient framework to evaluate whether machine learning models align with the structure of the data they learn from; that is, whether \textit{the model says what the data says}. Unlike existing interpretability methods that focus exclusively on explaining model behavior, our approach establishes a baseline derived directly from the data itself. Drawing inspiration from Rubin's Potential Outcomes Framework, we quantify how strongly each feature separates the two outcome groups in a binary classification task, moving beyond traditional descriptive statistics to estimate each feature's effect on the outcome. By comparing these data-derived feature rankings against model-based explanations, we provide practitioners with an interpretable and model-agnostic method to assess model--data alignment.

</details>


### [149] [Modeling Quantum Autoencoder Trainable Kernel for IoT Anomaly Detection](https://arxiv.org/abs/2511.21932)
*Swathi Chandrasekhar,Shiva Raj Pokhrel,Swati Kumari,Navneet Singh*

Main category: cs.LG

TL;DR: 量子自编码器框架用于物联网入侵检测，在NISQ设备上实现实用量子优势


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法难以应对日益增长的网络安全威胁和高维物联网流量复杂性，深度学习存在计算瓶颈限制实时部署

Method: 提出量子自编码器框架压缩网络流量为判别性潜在表示，结合量子支持向量分类进行入侵检测

Result: 在三个数据集上评估，在理想模拟器和IBM量子硬件上实现更高准确率，证明在当前NISQ设备上的实用量子优势

Conclusion: 中等去极化噪声作为隐式正则化稳定训练并增强泛化，量子机器学习成为解决现实网络安全挑战的可行硬件就绪方案

Abstract: Escalating cyber threats and the high-dimensional complexity of IoT traffic have outpaced classical anomaly detection methods. While deep learning offers improvements, computational bottlenecks limit real-time deployment at scale. We present a quantum autoencoder (QAE) framework that compresses network traffic into discriminative latent representations and employs quantum support vector classification (QSVC) for intrusion detection. Evaluated on three datasets, our approach achieves improved accuracy on ideal simulators and on the IBM Quantum hardware demonstrating practical quantum advantage on current NISQ devices. Crucially, moderate depolarizing noise acts as implicit regularization, stabilizing training and enhancing generalization. This work establishes quantum machine learning as a viable, hardware-ready solution for real-world cybersecurity challenges.

</details>


### [150] [Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation](https://arxiv.org/abs/2511.21934)
*Tao Zhe,Huazhen Fang,Kunpeng Liu,Qian Lou,Tamzidul Hoque,Dongjie Wang*

Main category: cs.LG

TL;DR: 提出了一种异构多智能体强化学习框架，用于实现协作和可扩展的特征转换，解决传统方法中动态特征扩展导致的不稳定性和智能体间协作不足的问题。


<details>
  <summary>Details</summary>
Motivation: 特征转换通过数学特征交叉生成信息丰富的特征，对结构化数据下游任务性能提升至关重要。尽管深度学习有进展，但结构化数据中深度模型难以捕捉复杂特征交互。现有自动化特征转换方法依赖启发式或穷举搜索，效率低下。最近强化学习方法有所改进，但仍存在两个问题：1）转换过程中动态特征扩展导致不稳定并增加RL智能体学习复杂度；2）智能体间协作和通信不足导致次优特征交叉操作和模型性能下降。

Method: 提出异构多智能体RL框架，包含三种异构智能体，分为两种类型，分别负责选择特征和操作进行特征交叉。采用共享评论家机制促进智能体间信息交换。针对动态扩展的特征空间，设计基于多头注意力的特征智能体来选择合适特征。引入状态编码技术来稳定和增强RL智能体学习动态。

Result: 通过大量实验验证了模型在有效性、效率、鲁棒性和可解释性方面的优势。

Conclusion: 提出的异构多智能体RL框架能够实现协作和可扩展的特征转换，解决了传统方法中的关键限制，为自动化特征转换提供了更稳定和高效的解决方案。

Abstract: Feature transformation enhances downstream task performance by generating informative features through mathematical feature crossing. Despite the advancements in deep learning, feature transformation remains essential for structured data, where deep models often struggle to capture complex feature interactions. Prior literature on automated feature transformation has achieved success but often relies on heuristics or exhaustive searches, leading to inefficient and time-consuming processes. Recent works employ reinforcement learning (RL) to enhance traditional approaches through a more effective trial-and-error way. However, two limitations remain: 1) Dynamic feature expansion during the transformation process, which causes instability and increases the learning complexity for RL agents; 2) Insufficient cooperation and communication between agents, which results in suboptimal feature crossing operations and degraded model performance. To address them, we propose a novel heterogeneous multi-agent RL framework to enable cooperative and scalable feature transformation. The framework comprises three heterogeneous agents, grouped into two types, each designed to select essential features and operations for feature crossing. To enhance communication among these agents, we implement a shared critic mechanism that facilitates information exchange during feature transformation. To handle the dynamically expanding feature space, we tailor multi-head attention-based feature agents to select suitable features for feature crossing. Additionally, we introduce a state encoding technique during the optimization process to stabilize and enhance the learning dynamics of the RL agents, resulting in more robust and reliable transformation policies. Finally, we conduct extensive experiments to validate the effectiveness, efficiency, robustness, and interpretability of our model.

</details>


### [151] [Breaking Algorithmic Collusion in Human-AI Ecosystems](https://arxiv.org/abs/2511.21935)
*Natalie Collina,Eshwar Ram Arunachaleswaran,Meena Jagadeesan*

Main category: cs.LG

TL;DR: 研究混合人机生态系统中算法合谋的稳定性，发现人类参与会破坏AI代理之间的价格合谋，使价格趋向竞争水平


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在生态系统中与人类频繁交互，需要理解人类参与如何影响AI代理之间的算法合谋，特别是价格合谋的稳定性

Method: 使用重复定价博弈的理论框架，AI代理采用均衡策略，人类采用无遗憾策略，分析人类"叛逃"行为对价格合谋的影响

Result: 单个人类参与就能破坏AI代理之间的价格合谋，降低价格；多人参与会使价格更接近竞争水平；叛逃感知的AI代理会改变合谋性质

Conclusion: 算法合谋在混合人机生态系统中具有脆弱性，人类参与会显著影响合谋稳定性，这为理解算法合谋何时持续、何时瓦解提供了理论依据

Abstract: AI agents are increasingly deployed in ecosystems where they repeatedly interact not only with each other but also with humans. In this work, we study these human-AI ecosystems from a theoretical perspective, focusing on the classical framework of repeated pricing games. In our stylized model, the AI agents play equilibrium strategies, and one or more humans manually perform the pricing task instead of adopting an AI agent, thereby defecting to a no-regret strategy. Motivated by how populations of AI agents can sustain supracompetitive prices, we investigate whether high prices persist under such defections. Our main finding is that even a single human defection can destabilize collusion and drive down prices, and multiple defections push prices even closer to competitive levels. We further show how the nature of collusion changes under defection-aware AI agents. Taken together, our results characterize when algorithmic collusion is fragile--and when it persists--in mixed ecosystems of AI agents and humans.

</details>


### [152] [Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection](https://arxiv.org/abs/2511.21940)
*Kiran Nair,Hubert Cecotti*

Main category: cs.LG

TL;DR: 该研究提出多种深度学习架构用于C-VEP脑机接口解码，显著优于传统方法，其中多类孪生网络达到96.89%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 基于C-VEP的非侵入式脑机接口需要高度鲁棒的解码方法来应对EEG信号的时间变异性和会话依赖性噪声，传统方法在这方面存在局限性。

Method: 提出并评估多种深度学习架构：用于63位m序列重构和分类的卷积神经网络、基于相似性解码的孪生网络，以及CCA基线方法。使用13名健康成人的单目标闪烁刺激EEG数据，采用基于距离的解码方法（包括地球移动距离和约束EMD），并通过时间数据增强（小位移）提高跨会话泛化能力。

Result: 深度学习模型显著优于传统方法，基于EMD和约束EMD的距离解码对延迟变化具有更好的鲁棒性。多类孪生网络表现最佳，平均准确率达到96.89%，展示了数据驱动深度学习架构在单次试验C-VEP解码中的潜力。

Conclusion: 深度学习架构特别是多类孪生网络，能够实现可靠的单次试验C-VEP解码，为自适应非侵入式脑机接口系统提供了有前景的解决方案。

Abstract: Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.

</details>


### [153] [ABLE: Using Adversarial Pairs to Construct Local Models for Explaining Model Predictions](https://arxiv.org/abs/2511.21952)
*Krishna Khadka,Sunny Shree,Pujan Budhathoki,Yu Lei,Raghu Kacker,D. Richard Kuhn*

Main category: cs.LG

TL;DR: 提出ABEL方法，通过生成对抗点对来界定局部决策边界，提高解释的稳定性和保真度


<details>
  <summary>Details</summary>
Motivation: 现有局部解释方法（如LIME）存在不稳定性和局部保真度差的问题，需要更可靠的解释方法来提高机器学习模型在关键应用中的透明度

Method: ABEL方法：1) 在测试实例附近生成邻域点；2) 对每个邻域点进行两次对抗攻击，生成界定决策边界的对抗点对；3) 在这些对抗点对上训练线性模型来近似局部决策边界

Result: 在6个UCI基准数据集和3种深度神经网络架构上的实验表明，ABEL方法在稳定性和保真度方面优于现有最先进方法

Conclusion: ABEL方法通过利用对抗攻击来界定局部决策边界，显著提高了局部解释的稳定性和保真度，为机器学习模型提供了更可靠的解释

Abstract: Machine learning models are increasingly used in critical applications but are mostly "black boxes" due to their lack of transparency. Local explanation approaches, such as LIME, address this issue by approximating the behavior of complex models near a test instance using simple, interpretable models. However, these approaches often suffer from instability and poor local fidelity. In this paper, we propose a novel approach called Adversarially Bracketed Local Explanation (ABLE) to address these limitations. Our approach first generates a set of neighborhood points near the test instance, x_test, by adding bounded Gaussian noise. For each neighborhood point D, we apply an adversarial attack to generate an adversarial point A with minimal perturbation that results in a different label than D. A second adversarial attack is then performed on A to generate a point A' that has the same label as D (and thus different than A). The points A and A' form an adversarial pair that brackets the local decision boundary for x_test. We then train a linear model on these adversarial pairs to approximate the local decision boundary. Experimental results on six UCI benchmark datasets across three deep neural network architectures demonstrate that our approach achieves higher stability and fidelity than the state-of-the-art.

</details>


### [154] [CTR Prediction on Alibaba's Taobao Advertising Dataset Using Traditional and Deep Learning Models](https://arxiv.org/abs/2511.21963)
*Hongyu Yang,Chunxi Wen,Jiyin Zhang,Nanfei Shen,Shijiao Zhang,Xiyan Han*

Main category: cs.LG

TL;DR: 该研究探索使用大规模淘宝数据集进行CTR预测，从传统机器学习模型（逻辑回归、Light-GBM）发展到深度学习模型（MLP、Transformer），通过结合用户行为序列建模显著提升预测性能，并探讨了将个性化广告技术应用于公共卫生场景的潜力。


<details>
  <summary>Details</summary>
Motivation: 点击率预测在现代广告系统中至关重要，直接影响平台效率和商业价值。传统基于静态特征的模型（如逻辑回归）难以捕捉用户行为模式，需要更有效地建模用户意图和行为动态。

Method: 1. 使用大规模淘宝数据集（22天、数亿次交互）；2. 从监督学习模型（逻辑回归、Light-GBM）开始；3. 提取和编码用户行为序列构建兴趣表示；4. 使用深度学习模型（MLP）融合行为嵌入和静态特征；5. 设计基于Transformer的架构，利用自注意力机制捕捉行为序列的上下文依赖和时间动态；6. 提出A/B测试策略进行实际评估。

Result: Transformer模型相比基线（逻辑回归）AUC提升2.81%，在兴趣多样或随时间变化的用户中表现最佳。MLP也取得了显著性能提升。研究展示了行为序列建模对CTR预测的重要性。

Conclusion: 通过结合用户行为序列建模，深度学习模型（特别是Transformer）能显著提升CTR预测性能。该技术不仅适用于电商广告，还可扩展到公共卫生等场景，实现精准信息投放。研究为CTR预测的进一步发展提供了路线图。

Abstract: Click-through rates prediction is critical in modern advertising systems, where ranking relevance and user engagement directly impact platform efficiency and business value. In this project, we explore how to model CTR more effectively using a large-scale Taobao dataset released by Alibaba. We start with supervised learning models, including logistic regression and Light-GBM, that are trained on static features such as user demographics, ad attributes, and contextual metadata. These models provide fast, interpretable benchmarks, but have limited capabilities to capture patterns of behavior that drive clicks. To better model user intent, we combined behavioral data from hundreds of millions of interactions over a 22-day period. By extracting and encoding user action sequences, we construct representations of user interests over time. We use deep learning models to fuse behavioral embeddings with static features. Among them, multilayer perceptrons (MLPs) have achieved significant performance improvements. To capture temporal dynamics, we designed a Transformer-based architecture that uses a self-attention mechanism to learn contextual dependencies across behavioral sequences, modeling not only what the user interacts with, but also the timing and frequency of interactions. Transformer improves AUC by 2.81 % over the baseline (LR model), with the largest gains observed for users whose interests are diverse or change over time. In addition to modeling, we propose an A/B testing strategy for real-world evaluation. We also think about the broader implications: personalized ad targeting technology can be applied to public health scenarios to achieve precise delivery of health information or behavior guidance. Our research provides a roadmap for advancing click-through rate predictions and extending their value beyond e-commerce.

</details>


### [155] [MOTIF-RF: Multi-template On-chip Transformer Synthesis Incorporating Frequency-domain Self-transfer Learning for RFIC Design Automation](https://arxiv.org/abs/2511.21970)
*Houbo He,Yizhou Xu,Lei Xia,Yaolong Hu,Fan Cai,Taiyun Chi*

Main category: cs.LG

TL;DR: 本文系统研究了用于射频集成电路变压器逆设计的机器学习代理模型，提出频率域自迁移学习技术提升精度30-50%，并基于CMA-ES算法开发了逆设计框架。


<details>
  <summary>Details</summary>
Motivation: 射频集成电路变压器的传统设计方法耗时且依赖专家经验，需要开发AI辅助的specs-to-GDS自动化工具，为RFIC设计师提供可集成到工作流程中的实用工具。

Method: 1. 对四种ML架构进行基准测试；2. 提出频率域自迁移学习技术，利用相邻频段相关性提升S参数预测精度；3. 基于CMA-ES算法开发逆设计框架。

Result: 频率域自迁移学习使S参数预测精度提升30-50%；基于CMA-ES的逆设计框架在多个阻抗匹配任务中表现出快速收敛和可靠性能。

Conclusion: 该研究推进了RFIC的AI辅助specs-to-GDS自动化目标，为RFIC设计师提供了将AI集成到工作流程中的实用工具，展示了机器学习在射频电路逆设计中的有效应用。

Abstract: This paper presents a systematic study on developing multi-template machine learning (ML) surrogate models and applying them to the inverse design of transformers (XFMRs) in radio-frequency integrated circuits (RFICs). Our study starts with benchmarking four widely used ML architectures, including MLP-, CNN-, UNet-, and GT-based models, using the same datasets across different XFMR topologies. To improve modeling accuracy beyond these baselines, we then propose a new frequency-domain self-transfer learning technique that exploits correlations between adjacent frequency bands, leading to around 30%-50% accuracy improvement in the S-parameters prediction. Building on these models, we further develop an inverse design framework based on the covariance matrix adaptation evolutionary strategy (CMA-ES) algorithm. This framework is validated using multiple impedance-matching tasks, all demonstrating fast convergence and trustworthy performance. These results advance the goal of AI-assisted specs-to-GDS automation for RFICs and provide RFIC designers with actionable tools for integrating AI into their workflows.

</details>


### [156] [A Safety and Security Framework for Real-World Agentic Systems](https://arxiv.org/abs/2511.21990)
*Shaona Ghosh,Barnaby Simkin,Kyriacos Shiarlis,Soumili Nandi,Dan Zhao,Matthew Fiedler,Julia Bazinska,Nikki Pope,Roopa Prabhu,Daniel Rohrer,Michael Demoret,Bartley Richardson*

Main category: cs.LG

TL;DR: 提出一个动态可操作的框架，用于保障企业部署中智能体AI系统的安全，将安全和安全视为从模型、编排器、工具和数据动态交互中涌现的属性，并通过AI驱动的红队测试进行风险发现。


<details>
  <summary>Details</summary>
Motivation: 传统上安全和安全在LLM和智能体模型中是分离的，但在智能体系统中它们相互关联。智能体系统引入了新的风险（如工具误用、级联行动链、意外控制放大等），需要新的框架来识别和管理这些动态风险。

Method: 提出动态智能体安全和安全框架，通过辅助AI模型和智能体（在人类监督下）进行上下文风险发现、评估和缓解；采用沙盒化的AI驱动红队测试进行风险发现；定义了统一的智能体风险分类法。

Result: 通过NVIDIA旗舰智能体研究助手AI-Q Research Assistant的详细案例研究，展示了框架在复杂企业级智能体工作流中的端到端安全和安全评估有效性；发现了新的智能体风险并进行上下文缓解；发布了包含10,000多个真实攻击和防御执行轨迹的数据集。

Conclusion: 安全和安全不仅是单个模型的固定属性，更是从系统动态交互中涌现的特性；提出的框架能有效管理智能体系统的上下文风险，特别是通过AI驱动红队测试发现新风险；发布的资源将推动智能体安全研究。

Abstract: This paper introduces a dynamic and actionable framework for securing agentic AI systems in enterprise deployment. We contend that safety and security are not merely fixed attributes of individual models but also emergent properties arising from the dynamic interactions among models, orchestrators, tools, and data within their operating environments. We propose a new way of identification of novel agentic risks through the lens of user safety. Although, for traditional LLMs and agentic models in isolation, safety and security has a clear separation, through the lens of safety in agentic systems, they appear to be connected. Building on this foundation, we define an operational agentic risk taxonomy that unifies traditional safety and security concerns with novel, uniquely agentic risks, including tool misuse, cascading action chains, and unintended control amplification among others. At the core of our approach is a dynamic agentic safety and security framework that operationalizes contextual agentic risk management by using auxiliary AI models and agents, with human oversight, to assist in contextual risk discovery, evaluation, and mitigation. We further address one of the most challenging aspects of safety and security of agentic systems: risk discovery through sandboxed, AI-driven red teaming. We demonstrate the framework effectiveness through a detailed case study of NVIDIA flagship agentic research assistant, AI-Q Research Assistant, showcasing practical, end-to-end safety and security evaluations in complex, enterprise-grade agentic workflows. This risk discovery phase finds novel agentic risks that are then contextually mitigated. We also release the dataset from our case study, containing traces of over 10,000 realistic attack and defense executions of the agentic workflow to help advance research in agentic safety.

</details>


### [157] [Distance-based Learning of Hypertrees](https://arxiv.org/abs/2511.22014)
*Shaun Fallat,Kamyar Khodamoradi,David Kirkpatrick,Valerii Maliuk,S. Ahmad Mojallal,Sandra Zilles*

Main category: cs.LG

TL;DR: 本文提出了首个可证明最优的在线算法，用于学习一类称为有序超树的超图，该算法可转化为最优离线算法。有序超树属于Fagin层次结构中的可学习类，且严格包含该层次中具有亚二次查询复杂度的最广泛类。此外，针对距离测量随距离增加而退化的情况，研究了有界距离查询模型，并给出了学习一般超树的渐近紧复杂度界。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过最短路径查询（SP-queries）学习超图结构。超图学习在数据库理论、进化树重建等领域有重要应用。现有方法在查询复杂度上不够高效，需要开发更优的算法。同时，考虑到实际应用中距离测量可能随距离增加而退化（如进化树重建），需要研究有界距离查询模型。

Method: 1. 提出"有序超树"概念，这是Fagin层次结构中可学习的一类超树
2. 设计首个可证明最优的在线算法用于学习有序超树
3. 将该在线算法转化为可证明最优的离线算法
4. 针对有界距离查询模型，分析学习一般超树的复杂度，给出渐近紧的复杂度界

Result: 1. 提出了首个可证明最优的在线算法用于学习有序超树
2. 证明了有序超树严格包含Fagin层次结构中具有亚二次查询复杂度的最广泛可学习类
3. 在线算法可转化为最优离线算法
4. 在有界距离查询模型中，给出了学习一般超树的渐近紧复杂度界

Conclusion: 本文在超图学习领域取得了重要进展：1）针对有序超树类提出了首个最优算法；2）建立了有序超树在Fagin层次结构中的位置；3）解决了有界距离查询模型下的复杂度问题。这些结果为超图学习提供了理论基础和实用算法，特别适用于数据库理论和进化树重建等应用场景。

Abstract: We study the problem of learning hypergraphs with shortest-path queries (SP-queries), and present the first provably optimal online algorithm for a broad and natural class of hypertrees that we call orderly hypertrees. Our online algorithm can be transformed into a provably optimal offline algorithm. Orderly hypertrees can be positioned within the Fagin hierarchy of acyclic hypergraph (well-studied in database theory), and strictly encompass the broadest class in this hierarchy that is learnable with subquadratic SP-query complexity.
  Recognizing that in some contexts, such as evolutionary tree reconstruction, distance measurements can degrade with increased distance, we also consider a learning model that uses bounded distance queries. In this model, we demonstrate asymptotically tight complexity bounds for learning general hypertrees.

</details>


### [158] [Equilibrium Propagation Without Limits](https://arxiv.org/abs/2511.22024)
*Elon Litman*

Main category: cs.LG

TL;DR: 论文为平衡传播(EP)建立了有限扰动理论基础，通过吉布斯-玻尔兹曼分布建模网络状态，证明了Helmholtz自由能差的梯度等于局部能量导数的期望差，使对比Hebbian学习成为任意有限扰动的精确梯度估计器。


<details>
  <summary>Details</summary>
Motivation: 传统平衡传播(EP)方法依赖于无限小扰动的近似，这限制了其在实际应用中的有效性。作者希望将EP从无限小扰动的限制中解放出来，建立适用于有限扰动的理论基础，从而支持更强的误差信号学习。

Method: 将网络状态建模为吉布斯-玻尔兹曼分布而非确定性点，证明Helmholtz自由能差的梯度等于局部能量导数的期望差。基于损失-能量协方差的路径积分推导出广义EP算法。

Result: 验证了经典对比Hebbian学习更新可作为任意有限扰动的精确梯度估计器，无需无限小近似或凸性假设。推导的广义EP算法能够支持标准无限小近似无法处理的强误差信号学习。

Conclusion: 该研究为平衡传播建立了坚实的有限扰动理论基础，使对比Hebbian学习成为精确的梯度估计方法，扩展了EP算法的适用范围，为使用强误差信号进行学习提供了理论支持。

Abstract: We liberate Equilibrium Propagation (EP) from the limit of infinitesimal perturbations by establishing a finite-nudge foundation for local credit assignment. By modeling network states as Gibbs-Boltzmann distributions rather than deterministic points, we prove that the gradient of the difference in Helmholtz free energy between a nudged and free phase is exactly the difference in expected local energy derivatives. This validates the classic Contrastive Hebbian Learning update as an exact gradient estimator for arbitrary finite nudging, requiring neither infinitesimal approximations nor convexity. Furthermore, we derive a generalized EP algorithm based on the path integral of loss-energy covariances, enabling learning with strong error signals that standard infinitesimal approximations cannot support.

</details>


### [159] [Calibration-Free EEG-based Driver Drowsiness Detection with Online Test-Time Adaptation](https://arxiv.org/abs/2511.22030)
*Geun-Deok Jang,Dong-Kyun Han,Seo-Hyeon Park,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 提出一种基于在线测试时适应的驾驶员疲劳检测框架，通过动态调整批归一化层参数和使用记忆库管理EEG数据流，显著提升模型在未见目标受试者上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: EEG信号存在显著的个体间变异性，导致域偏移问题，使得疲劳检测模型难以泛化到新的受试者。现有方法需要繁琐的校准过程，限制了实际应用。

Method: 提出在线测试时适应(TTA)框架：1) 更新批归一化(BN)层的可学习参数，同时保留预训练的归一化统计量；2) 使用记忆库动态管理流式EEG片段，基于负能量分数和持续时间的可靠性选择样本；3) 引入原型学习以增强对时间分布偏移的鲁棒性。

Result: 在模拟环境中的持续注意力驾驶数据集上验证，平均F1分数达到81.73%，比最佳TTA基线提高了11.73%，显著提升了EEG疲劳检测系统在非独立同分布场景下的适应性。

Conclusion: 提出的在线测试时适应框架有效解决了EEG信号个体间变异性带来的域偏移问题，显著提升了疲劳检测模型对新受试者的泛化能力，为实际应用提供了可行方案。

Abstract: Drowsy driving is a growing cause of traffic accidents, prompting recent exploration of electroencephalography (EEG)-based drowsiness detection systems. However, the inherent variability of EEG signals due to psychological and physical factors necessitates a cumbersome calibration process. In particular, the inter-subject variability of EEG signals leads to a domain shift problem, which makes it challenging to generalize drowsiness detection models to unseen target subjects. To address these issues, we propose a novel driver drowsiness detection framework that leverages online test-time adaptation (TTA) methods to dynamically adjust to target subject distributions. Our proposed method updates the learnable parameters in batch normalization (BN) layers, while preserving pretrained normalization statistics, resulting in a modified configuration that ensures effective adaptation during test time. We incorporate a memory bank that dynamically manages streaming EEG segments, selecting samples based on their reliability determined by negative energy scores and persistence time. In addition, we introduce prototype learning to ensure robust predictions against distribution shifts over time. We validated our method on the sustained-attention driving dataset collected in a simulated environment, where drowsiness was estimated from delayed reaction times during monotonous lane-keeping tasks. Our experiments show that our method outperforms all baselines, achieving an average F1-score of 81.73\%, an improvement of 11.73\% over the best TTA baseline. This demonstrates that our proposed method significantly enhances the adaptability of EEG-based drowsiness detection systems in non-i.i.d. scenarios.

</details>


### [160] [Predicting Public Health Impacts of Electricity Usage](https://arxiv.org/abs/2511.22031)
*Yejia Liu,Zhifeng Wu,Pengfei Li,Shaolei Ren*

Main category: cs.LG

TL;DR: 开发了HealthPredictor AI模型，将电力使用与公共健康结果联系起来，通过优化电力需求管理来减少空气污染对健康的影响。


<details>
  <summary>Details</summary>
Motivation: 电力行业是空气污染的主要来源，虽然监管措施已减少污染物，但化石燃料仍是重要能源组成部分，需要更先进的需求侧方法来减少公共健康影响。

Method: 提出HealthPredictor模型，包含三个组件：燃料组合预测器（估计不同发电来源贡献）、空气质量转换器（建模污染物排放和大气扩散）、健康影响评估器（将污染物变化转化为货币化健康损害）。

Result: 在美国多个地区的健康驱动优化框架中，相比燃料组合驱动的基线方法，在公共健康影响预测方面误差显著降低。电动汽车充电调度的案例研究展示了该方法带来的公共健康收益和可操作指导。

Conclusion: 这项工作展示了AI模型如何被明确设计用于支持健康导向的能源管理，以促进公共健康和更广泛的社会福祉。

Abstract: The electric power sector is a leading source of air pollutant emissions, impacting the public health of nearly every community. Although regulatory measures have reduced air pollutants, fossil fuels remain a significant component of the energy supply, highlighting the need for more advanced demand-side approaches to reduce the public health impacts. To enable health-informed demand-side management, we introduce HealthPredictor, a domain-specific AI model that provides an end-to-end pipeline linking electricity use to public health outcomes. The model comprises three components: a fuel mix predictor that estimates the contribution of different generation sources, an air quality converter that models pollutant emissions and atmospheric dispersion, and a health impact assessor that translates resulting pollutant changes into monetized health damages. Across multiple regions in the United States, our health-driven optimization framework yields substantially lower prediction errors in terms of public health impacts than fuel mix-driven baselines. A case study on electric vehicle charging schedules illustrates the public health gains enabled by our method and the actionable guidance it can offer for health-informed energy management. Overall, this work shows how AI models can be explicitly designed to enable health-informed energy management for advancing public health and broader societal well-being. Our datasets and code are released at: https://github.com/Ren-Research/Health-Impact-Predictor.

</details>


### [161] [Convergence Dynamics of Over-Parameterized Score Matching for a Single Gaussian](https://arxiv.org/abs/2511.22069)
*Yiran Zhang,Weihang Xu,Mo Zhou,Maryam Fazel,Simon Shaolei Du*

Main category: cs.LG

TL;DR: 本文研究了过参数化模型在分数匹配目标下学习单个高斯分布的梯度下降优化行为，分析了不同噪声尺度下的收敛性，证明了在特定初始化条件下的全局收敛保证。


<details>
  <summary>Details</summary>
Motivation: 分数匹配已成为现代生成建模（特别是扩散模型）中的核心训练目标，用于通过估计分数函数来学习高维数据分布。尽管经验上取得了成功，但对分数匹配优化行为（特别是在过参数化机制下）的理论理解仍然有限。

Method: 使用具有n个可学习参数的学生模型，在从单个真实高斯分布生成的数据上训练，使用总体分数匹配目标。分析梯度下降在不同机制下的优化动态：高噪声机制下的全局收敛证明；低噪声机制下识别平稳点存在性；特定初始化条件下的收敛分析；随机初始化下的参数行为分析。

Result: 1) 当噪声尺度足够大时，证明了梯度下降的全局收敛性；2) 在低噪声机制下，识别了平稳点的存在；3) 当参数初始化为指数级小时，所有参数都能收敛到真实值；4) 没有指数级小初始化时，参数可能不收敛到真实值；5) 当参数从远离真实值的高斯分布随机初始化时，高概率下只有一个参数收敛而其他参数发散，但损失仍以1/τ速率收敛到零；6) 建立了该机制下收敛率的近似匹配下界。

Conclusion: 这是首个在分数匹配框架下为至少三个分量的高斯混合建立全局收敛保证的工作，深入理解了过参数化模型在分数匹配目标下的优化动态，为实际训练提供了理论指导。

Abstract: Score matching has become a central training objective in modern generative modeling, particularly in diffusion models, where it is used to learn high-dimensional data distributions through the estimation of score functions. Despite its empirical success, the theoretical understanding of the optimization behavior of score matching, particularly in over-parameterized regimes, remains limited. In this work, we study gradient descent for training over-parameterized models to learn a single Gaussian distribution. Specifically, we use a student model with $n$ learnable parameters and train it on data generated from a single ground-truth Gaussian using the population score matching objective. We analyze the optimization dynamics under multiple regimes. When the noise scale is sufficiently large, we prove a global convergence result for gradient descent. In the low-noise regime, we identify the existence of a stationary point, highlighting the difficulty of proving global convergence in this case. Nevertheless, we show convergence under certain initialization conditions: when the parameters are initialized to be exponentially small, gradient descent ensures convergence of all parameters to the ground truth. We further prove that without the exponentially small initialization, the parameters may not converge to the ground truth. Finally, we consider the case where parameters are randomly initialized from a Gaussian distribution far from the ground truth. We prove that, with high probability, only one parameter converges while the others diverge, yet the loss still converges to zero with a $1/τ$ rate, where $τ$ is the number of iterations. We also establish a nearly matching lower bound on the convergence rate in this regime. This is the first work to establish global convergence guarantees for Gaussian mixtures with at least three components under the score matching framework.

</details>


### [162] [A Multi-View Multi-Timescale Hypergraph-Empowered Spatiotemporal Framework for EV Charging Forecasting](https://arxiv.org/abs/2511.22072)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: HyperCast：基于超图建模高阶时空依赖的电动汽车充电需求预测框架，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的方法通常只能建模充电站之间的成对关系，无法捕捉城市充电网络中复杂的群体动态。准确的电动汽车充电需求预测对电网稳定运行和电动汽车参与电力市场至关重要。

Method: 开发HyperCast框架，利用超图的表达能力建模EV充电模式中的高阶时空依赖。整合多视图超图（捕捉静态地理邻近和动态需求相似性）和多时间尺度输入，采用专门的超时空块和跨注意力机制融合不同视图和时间尺度的信息。

Result: 在四个公共数据集上的广泛实验表明，HyperCast显著优于多种最先进的基线方法，证明了显式建模集体充电行为对提高预测准确性的有效性。

Conclusion: 通过超图建模高阶时空依赖能够更准确地预测电动汽车充电需求，为电网运营和电力市场参与提供更好的支持。

Abstract: Accurate electric vehicle (EV) charging demand forecasting is essential for stable grid operation and proactive EV participation in electricity market. Existing forecasting methods, particularly those based on graph neural networks, are often limited to modeling pairwise relationships between stations, failing to capture the complex, group-wise dynamics inherent in urban charging networks. To address this gap, we develop a novel forecasting framework namely HyperCast, leveraging the expressive power of hypergraphs to model the higher-order spatiotemporal dependencies hidden in EV charging patterns. HyperCast integrates multi-view hypergraphs, which capture both static geographical proximity and dynamic demand-based functional similarities, along with multi-timescale inputs to differentiate between recent trends and weekly periodicities. The framework employs specialized hyper-spatiotemporal blocks and tailored cross-attention mechanisms to effectively fuse information from these diverse sources: views and timescales. Extensive experiments on four public datasets demonstrate that HyperCast significantly outperforms a wide array of state-of-the-art baselines, demonstrating the effectiveness of explicitly modeling collective charging behaviors for more accurate forecasting.

</details>


### [163] [ARES: Anomaly Recognition Model For Edge Streams](https://arxiv.org/abs/2511.22078)
*Simone Mungari,Albert Bifet,Giuseppe Manco,Bernhard Pfahringer*

Main category: cs.LG

TL;DR: ARES是一个用于时序图边流异常检测的无监督框架，结合图神经网络进行特征提取和半空间树进行异常评分，通过监督阈值机制优化检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中许多流式信息场景可以表示为时序图，其中数据通过随时间变化的边进行流动。在时序图中检测边异常对于实时风险缓解至关重要，但由于概念漂移、大数据量和实时响应需求，这一任务比传统异常检测更具挑战性。

Method: ARES框架结合图神经网络（GNNs）进行特征提取和半空间树（HST）进行异常评分。GNNs通过将节点和边属性嵌入到潜在空间中来捕获流中的尖峰和突发异常行为，而HST则高效地划分该空间以隔离异常。此外，还引入了基于统计离散度的监督阈值机制，利用少量标记数据确定最优阈值。

Result: 通过在多个真实世界网络攻击场景中的广泛评估，验证了ARES的性能，并与现有方法进行了比较，同时分析了其空间和时间复杂度。

Conclusion: ARES是一个有效的无监督时序图边流异常检测框架，能够适应不同领域的需求，通过结合GNNs和HST的优势，在实时检测中表现出色。

Abstract: Many real-world scenarios involving streaming information can be represented as temporal graphs, where data flows through dynamic changes in edges over time. Anomaly detection in this context has the objective of identifying unusual temporal connections within the graph structure. Detecting edge anomalies in real time is crucial for mitigating potential risks. Unlike traditional anomaly detection, this task is particularly challenging due to concept drifts, large data volumes, and the need for real-time response. To face these challenges, we introduce ARES, an unsupervised anomaly detection framework for edge streams. ARES combines Graph Neural Networks (GNNs) for feature extraction with Half-Space Trees (HST) for anomaly scoring. GNNs capture both spike and burst anomalous behaviors within streams by embedding node and edge properties in a latent space, while HST partitions this space to isolate anomalies efficiently. ARES operates in an unsupervised way without the need for prior data labeling. To further validate its detection capabilities, we additionally incorporate a simple yet effective supervised thresholding mechanism. This approach leverages statistical dispersion among anomaly scores to determine the optimal threshold using a minimal set of labeled data, ensuring adaptability across different domains. We validate ARES through extensive evaluations across several real-world cyber-attack scenarios, comparing its performance against existing methods while analyzing its space and time complexity.

</details>


### [164] [A Fast and Flat Federated Learning Method via Weighted Momentum and Sharpness-Aware Minimization](https://arxiv.org/abs/2511.22080)
*Tianle Li,Yongzhi Huang,Linshan Jiang,Chang Liu,Qipeng Xie,Wenfeng Du,Lu Wang,Kaishun Wu*

Main category: cs.LG

TL;DR: FedWMSAM：一种解决联邦学习中动量与SAM结合时局部-全局曲率错位和动量回波振荡问题的新方法，通过动量引导的全局扰动和自适应规则实现高效优化。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，模型需要在有限通信预算下快速收敛并在非独立同分布客户端上良好泛化。虽然动量和SAM分别能加速训练和寻找平坦解，但简单结合在非IID FL中会导致局部-全局曲率错位和动量回波振荡两个结构性问题。

Method: 提出FedWMSAM方法：1）使用服务器聚合的动量构建动量引导的全局扰动，使客户端SAM方向与全局下降几何对齐，实现单反向传播SAM近似；2）通过余弦相似度自适应规则耦合动量和SAM，形成早期动量、晚期SAM的两阶段训练计划。

Result: 理论分析提供了非IID收敛边界，明确建模了扰动引起的方差及其对系统参数的依赖。在多个数据集和模型架构上的实验验证了方法的有效性、适应性和鲁棒性，展示了在解决联邦学习优化挑战方面的优越性。

Conclusion: FedWMSAM成功解决了联邦学习中动量与SAM结合时的两个关键失败模式，通过创新的对齐机制和自适应调度策略，在保持效率的同时显著提升了非IID环境下的优化性能。

Abstract: In federated learning (FL), models must \emph{converge quickly} under tight communication budgets while \emph{generalizing} across non-IID client distributions. These twin requirements have naturally led to two widely used techniques: client/server \emph{momentum} to accelerate progress, and \emph{sharpness-aware minimization} (SAM) to prefer flat solutions. However, simply combining momentum and SAM leaves two structural issues unresolved in non-IID FL. We identify and formalize two failure modes: \emph{local-global curvature misalignment} (local SAM directions need not reflect the global loss geometry) and \emph{momentum-echo oscillation} (late-stage instability caused by accumulated momentum). To our knowledge, these failure modes have not been jointly articulated and addressed in the FL literature. We propose \textbf{FedWMSAM} to address both failure modes. First, we construct a momentum-guided global perturbation from server-aggregated momentum to align clients' SAM directions with the global descent geometry, enabling a \emph{single-backprop} SAM approximation that preserves efficiency. Second, we couple momentum and SAM via a cosine-similarity adaptive rule, yielding an early-momentum, late-SAM two-phase training schedule. We provide a non-IID convergence bound that \emph{explicitly models the perturbation-induced variance} $σ_ρ^2=σ^2+(Lρ)^2$ and its dependence on $(S, K, R, N)$ on the theory side. We conduct extensive experiments on multiple datasets and model architectures, and the results validate the effectiveness, adaptability, and robustness of our method, demonstrating its superiority in addressing the optimization challenges of Federated Learning. Our code is available at https://github.com/Huang-Yongzhi/NeurlPS_FedWMSAM.

</details>


### [165] [Quantum Bayesian Optimization for Quality Improvement in Fuselage Assembly](https://arxiv.org/abs/2511.22090)
*Jiayu Liu,Chong Liu,Trevor Rhone,Yinan Wang*

Main category: cs.LG

TL;DR: 提出量子贝叶斯优化框架，用于航空航天机身装配中的形状控制，通过量子算法提高样本效率，减少对制造系统的查询次数


<details>
  <summary>Details</summary>
Motivation: 现有智能制造方法在机身装配中面临样本效率低的问题，传统蒙特卡洛方法在从分布中获取平均响应时存在限制。量子算法能以更少样本达到相同估计精度，这为改进制造实践中的样本效率提供了机会

Method: 提出量子贝叶斯优化框架，利用基于有限元分析或代理模型的量子预言机，以更少查询获得更准确的环境响应估计。采用上置信界作为采集函数，策略性地选择最可能最大化目标函数的输入值

Result: 实验结果表明，与传统方法相比，QBO在相同仿真查询次数下实现了显著更低的尺寸误差和不确定性，特别是在力控执行器调整机身形状以减少间隙的案例中

Conclusion: 量子贝叶斯优化框架在航空航天机身装配中能够显著提高样本效率，减少制造系统查询次数，同时保持可比的优化结果，为智能制造中的精确形状控制提供了有效解决方案

Abstract: Recent efforts in smart manufacturing have enhanced aerospace fuselage assembly processes, particularly by innovating shape adjustment techniques to minimize dimensional gaps between assembled sections. Existing approaches have shown promising results but face the issue of low sample efficiency from the manufacturing systems. It arises from the limitation of the classical Monte Carlo method when uncovering the mean response from a distribution. In contrast, recent work has shown that quantum algorithms can achieve the same level of estimation accuracy with significantly fewer samples than the classical Monte Carlo method from distributions. Therefore, we can adopt the estimation of the quantum algorithm to obtain the estimation from real physical systems (distributions). Motivated by this advantage, we propose a Quantum Bayesian Optimization (QBO) framework for precise shape control during assembly to improve the sample efficiency in manufacturing practice. Specifically, this approach utilizes a quantum oracle, based on finite element analysis (FEA)-based models or surrogate models, to acquire a more accurate estimation of the environment response with fewer queries for a certain input. QBO employs an Upper Confidence Bound (UCB) as the acquisition function to strategically select input values that are most likely to maximize the objective function. It has been theoretically proven to require much fewer samples while maintaining comparable optimization results. In the case study, force-controlled actuators are applied to one fuselage section to adjust its shape and reduce the gap to the adjoining section. Experimental results demonstrate that QBO achieves significantly lower dimensional error and uncertainty compared to classical methods, particularly using the same queries from the simulation.

</details>


### [166] [Decomposed Trust: Exploring Privacy, Adversarial Robustness, Fairness, and Ethics of Low-Rank LLMs](https://arxiv.org/abs/2511.22099)
*Daniel Agyei Asante,Md Mokarram Chowdhury,Yang Li*

Main category: cs.LG

TL;DR: 低秩压缩对LLM可信度影响：提升隐私和对抗鲁棒性，但损害公平性和伦理推理


<details>
  <summary>Details</summary>
Motivation: LLMs规模庞大阻碍资源受限环境部署，低秩压缩虽能减小模型但可信度影响未知，需全面研究压缩对隐私、对抗鲁棒性、公平性和伦理对齐的影响

Method: 评估多种尺寸和变体的LLMs，使用不同低秩算法压缩，分析压缩对隐私、对抗鲁棒性、公平性和伦理对齐的影响，并进行梯度归因分析识别对抗鲁棒性关键层

Result: 1) 低秩压缩保护训练数据隐私但削弱对话中PII保护；2) 对抗鲁棒性保持甚至增强；3) 零样本伦理推理退化但少样本提示可部分恢复；4) 公平性随压缩下降

Conclusion: 低秩压缩对LLM可信度有复杂影响，需权衡不同维度，梯度归因分析可为可信压缩策略提供指导，模型规模和微调也是重要影响因素

Abstract: Large language models (LLMs) have driven major advances across domains, yet their massive size hinders deployment in resource-constrained settings. Model compression addresses this challenge, with low-rank factorization emerging as a particularly effective method for reducing size, memory, and computation while maintaining accuracy. However, while these compressed models boast of benign performance and system-level advantages, their trustworthiness implications remain poorly understood. In this paper, we present the first comprehensive study of how low-rank factorization affects LLM trustworthiness across privacy, adversarial robustness, fairness, and ethical alignment. We evaluate multiple LLMs of different sizes and variants compressed with diverse low-rank algorithms, revealing key insights: (1) low-rank compression preserves or improves training data privacy but weakens PII protection during conversation; (2) adversarial robustness is generally preserved and often enhanced, even under deep compression; (3) ethical reasoning degrades in zero-shot settings but partially recovers with few-shot prompting; (4) fairness declines under compression. Beyond compression, we investigate how model scale and fine-tuning affect trustworthiness, as both are important in low-rank methods. To guide trustworthy compression strategies, we end our paper with a gradient-based attribution analysis to identify which layers in LLMs contribute most to adversarial robustness.

</details>


### [167] [Adaptive Dueling Double Deep Q-networks in Uniswap V3 Replication and Extension with Mamba](https://arxiv.org/abs/2511.22101)
*Zhaofeng Zhang*

Main category: cs.LG

TL;DR: 该报告复制并改进了"Adaptive Liquidity Provision in Uniswap V3 with Deep Reinforcement Learning"论文，提出结合Mamba与DDQN的新架构，在某些测试中表现优于原模型。


<details>
  <summary>Details</summary>
Motivation: 改进Uniswap V3中的自适应流动性提供策略，通过深度强化学习优化流动性提供者的收益，解决原模型可能存在的不足。

Method: 1. 复制原论文：从Uniswap Subgraph获取数据，实现原模型；2. 提出新架构：结合Mamba与DDQN，设计新奖励函数，重新清洗数据，引入两个新基准进行比较。

Result: 新模型虽然尚未应用于所有数据集，但比原模型具有更强的理论支持，并在某些测试中表现更好。

Conclusion: 提出的Mamba+DDQN架构在自适应流动性提供问题上显示出潜力，为Uniswap V3流动性管理提供了改进方案，但需要进一步验证其在所有数据集上的表现。

Abstract: The report goes through the main steps of replicating and improving the article "Adaptive Liquidity Provision in Uniswap V3 with Deep Reinforcement Learning." The replication part includes how to obtain data from the Uniswap Subgraph, details of the implementation, and comments on the results. After the replication, I propose a new structure based on the original model, which combines Mamba with DDQN and a new reward function. In this new structure, I clean the data again and introduce two new baselines for comparison. As a result, although the model has not yet been applied to all datasets, it shows stronger theoretical support than the original model and performs better in some tests.

</details>


### [168] [Representative Action Selection for Large Action Space: From Bandits to MDPs](https://arxiv.org/abs/2511.22104)
*Quan Zhou,Shie Mannor*

Main category: cs.LG

TL;DR: 提出一种从大型动作空间中选择代表性子集的方法，使该子集在每个环境中都包含近似最优动作，从而在MDP中实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 在库存管理和推荐系统等应用中，动作空间极大，直接在整个空间上学习不可行。需要找到固定的小动作子集，使其在每个环境中都包含近似最优动作。

Method: 将先前元多臂赌博机的方法扩展到马尔可夫决策过程（MDPs），在放松的非中心化次高斯过程模型下，证明现有算法能达到与使用完整动作空间相当的性能。

Result: 理论证明该方法在计算和样本效率上都能提供有效解决方案，能够处理更大的环境异质性，适用于大规模组合决策问题。

Conclusion: 该方法为大规模不确定性组合决策问题提供了计算和样本高效的解决方案，扩展了元学习技术在强化学习中的应用范围。

Abstract: We study the problem of selecting a small, representative action subset from an extremely large action space shared across a family of reinforcement learning (RL) environments -- a fundamental challenge in applications like inventory management and recommendation systems, where direct learning over the entire space is intractable. Our goal is to identify a fixed subset of actions that, for every environment in the family, contains a near-optimal action, thereby enabling efficient learning without exhaustively evaluating all actions.
  This work extends our prior results for meta-bandits to the more general setting of Markov Decision Processes (MDPs). We prove that our existing algorithm achieves performance comparable to using the full action space. This theoretical guarantee is established under a relaxed, non-centered sub-Gaussian process model, which accommodates greater environmental heterogeneity. Consequently, our approach provides a computationally and sample-efficient solution for large-scale combinatorial decision-making under uncertainty.

</details>


### [169] [Energy Efficient Sleep Mode Optimization in 5G mmWave Networks via Multi Agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.22105)
*Saad Masrur,Ismail Guvenc,David Lopez Perez*

Main category: cs.LG

TL;DR: 提出基于多智能体深度强化学习（MARL-DDQN）的动态睡眠模式优化方法，用于毫米波网络中的节能管理，在动态3D城市环境中显著提升能量效率并满足服务质量约束。


<details>
  <summary>Details</summary>
Motivation: 现有毫米波网络中的睡眠模式优化方法依赖于静态基站流量模型，无法捕捉非平稳流量动态，且状态-动作空间过大，限制了实际部署。需要一种能适应动态环境、降低信令开销的分布式优化方法。

Method: 提出MARL-DDQN框架，采用双深度Q网络进行多智能体强化学习。在3D城市环境中使用时变、基于社区的用户设备移动模型，集成真实的基站功耗模型和波束赋形技术，以分布式方式自适应调整睡眠模式策略。

Result: MARL-DDQN在动态场景下优于现有方法（All On、IT-QoS-LB、MARL-DDPG、MARL-PPO），达到0.60 Mbit/Joule的能量效率、8.5 Mbps的第10百分位吞吐量，95%的时间满足服务质量约束。

Conclusion: MARL-DDQN框架为毫米波网络提供了一种可扩展、分布式的动态睡眠模式优化解决方案，能有效适应非平稳流量动态，在保证服务质量的同时最大化能量效率。

Abstract: Dynamic sleep mode optimization (SMO) in millimeter-wave (mmWave) networks is essential for maximizing energy efficiency (EE) under stringent quality-of-service (QoS) constraints. However, existing optimization and reinforcement learning (RL) approaches rely on aggregated, static base station (BS) traffic models that fail to capture non-stationary traffic dynamics and suffer from large state-action spaces, limiting real-world deployment. To address these challenges, this paper proposes a multi-agent deep reinforcement learning (MARL) framework using a Double Deep Q-Network (DDQN), referred to as MARL-DDQN, for adaptive SMO in a 3D urban environment with a time-varying and community-based user equipment (UE) mobility model. Unlike conventional single-agent RL, MARL-DDQN enables scalable, distributed decision-making with minimal signaling overhead. A realistic BS power consumption model and beamforming are integrated to accurately quantify EE, while QoS is defined in terms of throughput. The method adapts SMO policies to maximize EE while mitigating inter-cell interference and ensuring throughput fairness. Simulations show that MARL-DDQN outperforms state-of-the-art strategies, including All On, iterative QoS-aware load-based (IT-QoS-LB), MARL-DDPG, and MARL-PPO, achieving up to 0.60 Mbit/Joule EE, 8.5 Mbps 10th-percentile throughput, and meeting QoS constraints 95% of the time under dynamic scenarios.

</details>


### [170] [An energy-efficient spiking neural network with continuous learning for self-adaptive brain-machine interface](https://arxiv.org/abs/2511.22108)
*Zhou Biyan,Arindam Basu*

Main category: cs.LG

TL;DR: 该论文提出将强化学习算法Banditron和AGREL适配到深度脉冲神经网络中，用于植入式脑机接口的连续学习解码器，显著降低了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 植入式脑机接口中同时记录的神经元数量呈指数增长，需要将神经解码器集成到植入设备中以压缩数据。然而系统的非平稳性使解码器性能不可靠，频繁重新训练会影响用户安全舒适，因此需要连续学习方案。深度脉冲神经网络被认为是开发资源高效神经解码器的有前景方法。

Method: 提出将强化学习算法Banditron和AGREL适配到深度脉冲神经网络中，这两种算法计算资源需求有限，能有效处理非平稳问题并满足植入设备的能量限制。通过开环和闭环实验评估方法有效性。

Result: 开环实验中，DSNN Banditron和DSNN AGREL的准确率在长时间内保持稳定。闭环扰动实验中，DSNN Banditron性能与DSNN AGREL相当，同时训练期间内存访问使用减少98%，乘加运算需求减少99%。相比之前的连续学习SNN解码器，DSNN Banditron计算需求减少98%。

Conclusion: DSNN Banditron是未来无线植入式脑机接口系统的理想候选方案，能够在保持性能的同时显著降低计算资源需求，满足植入设备的能量限制。

Abstract: The number of simultaneously recorded neurons follows an exponentially increasing trend in implantable brain-machine interfaces (iBMIs). Integrating the neural decoder in the implant is an effective data compression method for future wireless iBMIs. However, the non-stationarity of the system makes the performance of the decoder unreliable. To avoid frequent retraining of the decoder and to ensure the safety and comfort of the iBMI user, continuous learning is essential for real-life applications. Since Deep Spiking Neural Networks (DSNNs) are being recognized as a promising approach for developing resource-efficient neural decoder, we propose continuous learning approaches with Reinforcement Learning (RL) algorithms adapted for DSNNs. Banditron and AGREL are chosen as the two candidate RL algorithms since they can be trained with limited computational resources, effectively addressing the non-stationary problem and fitting the energy constraints of implantable devices. To assess the effectiveness of the proposed methods, we conducted both open-loop and closed-loop experiments. The accuracy of open-loop experiments conducted with DSNN Banditron and DSNN AGREL remains stable over extended periods. Meanwhile, the time-to-target in the closed-loop experiment with perturbations, DSNN Banditron performed comparably to that of DSNN AGREL while achieving reductions of 98% in memory access usage and 99% in the requirements for multiply- and-accumulate (MAC) operations during training. Compared to previous continuous learning SNN decoders, DSNN Banditron requires 98% less computes making it a prime candidate for future wireless iBMI systems.

</details>


### [171] [Toward Data-Driven Surrogates of the Solar Wind with Spherical Fourier Neural Operator](https://arxiv.org/abs/2511.22112)
*Reza Mansouri,Dustin Kempton,Pete Riley,Rafal Angryk*

Main category: cs.LG

TL;DR: 使用球形傅里叶神经算子(SFNO)作为稳态太阳风建模的替代模型，相比传统数值替代模型HUX在多个指标上表现相当或更好，支持高效实时空间天气预报。


<details>
  <summary>Details</summary>
Motivation: 太阳风变化（如高速流和日冕物质抛射）会破坏卫星、电网和通信系统，需要准确建模进行空间天气预报。传统的3D磁流体动力学模型计算成本高，限制了边界条件不确定性研究，需要开发高效的替代模型。

Method: 开发基于球形傅里叶神经算子(SFNO)的稳态太阳风建模替代模型，这是一种灵活可训练的神经网络方法，能够高效处理球面数据。

Result: SFNO模型在多个评估指标上表现与现有数值替代模型HUX相当或更好，虽然HUX在物理平滑性方面仍有优势，但SFNO展示了神经网络方法的潜力。

Conclusion: SFNO作为一种灵活可训练的方法，能够实现高效实时预报，并能随着数据增加而改进性能，为空间天气预报提供了有前景的替代方案。

Abstract: The solar wind, a continuous stream of charged particles from the Sun's corona, shapes the heliosphere and impacts space systems near Earth. Variations such as high-speed streams and coronal mass ejections can disrupt satellites, power grids, and communications, making accurate modeling essential for space weather forecasting. While 3D magnetohydrodynamic (MHD) models are used to simulate and investigate these variations in the solar wind, they tend to be computationally expensive, limiting their usefulness in investigating the impacts of boundary condition uncertainty. In this work, we develop a surrogate for steady state solar wind modeling, using a Spherical Fourier Neural Operator (SFNO). We compare our model to a previously developed numerical surrogate for this task called HUX, and we show that the SFNO achieves comparable or better performance across several metrics. Though HUX retains advantages in physical smoothness, this underscores the need for improved evaluation criteria rather than a flaw in SFNO. As a flexible and trainable approach, SFNO enables efficient real-time forecasting and can improve with more data. The source code and more visual results are available at https://github.com/rezmansouri/solarwind-sfno-velocity.

</details>


### [172] [IVGAE: Handling Incomplete Heterogeneous Data with a Variational Graph Autoencoder](https://arxiv.org/abs/2511.22116)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal%*

Main category: cs.LG

TL;DR: IVGAE：一种基于变分图自编码器的异构数据缺失值填补框架，通过构建样本-特征二部图和使用双解码器架构，有效处理数值和分类混合数据的缺失问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界表格数据常包含数值和分类特征的异构数据，现有填补方法难以有效捕捉复杂结构依赖和处理异构数据，需要更鲁棒的填补方法。

Method: 构建样本-特征二部图表示关系；采用图表示学习建模结构依赖；设计双解码器架构（一个重构特征嵌入，一个建模缺失模式）；引入基于Transformer的异构嵌入模块处理分类变量。

Result: 在16个真实数据集上的实验表明，IVGAE在MCAR、MAR、MNAR三种缺失机制和30%缺失率下，在RMSE和下游F1指标上均取得一致改进。

Conclusion: IVGAE通过图表示学习和双解码器架构，为异构数据缺失值填补提供了有效解决方案，能捕捉结构依赖并处理不同缺失机制。

Abstract: Handling missing data remains a fundamental challenge in real-world tabular datasets, especially when data are heterogeneous with both numerical and categorical features. Existing imputation methods often fail to capture complex structural dependencies and handle heterogeneous data effectively. We present \textbf{IVGAE}, a Variational Graph Autoencoder framework for robust imputation of incomplete heterogeneous data. IVGAE constructs a bipartite graph to represent sample-feature relationships and applies graph representation learning to model structural dependencies. A key innovation is its \textit{dual-decoder architecture}, where one decoder reconstructs feature embeddings and the other models missingness patterns, providing structural priors aware of missing mechanisms. To better encode categorical variables, we introduce a Transformer-based heterogeneous embedding module that avoids high-dimensional one-hot encoding. Extensive experiments on 16 real-world datasets show that IVGAE achieves consistent improvements in RMSE and downstream F1 across MCAR, MAR, and MNAR missing scenarios under 30\% missing rates. Code and data are available at: https://github.com/echoid/IVGAE.

</details>


### [173] [A Variational Manifold Embedding Framework for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2511.22128)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 提出一个变分框架，将降维算法表述为最优流形嵌入问题的解，该框架允许非线性嵌入，比PCA更灵活，且具有更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有降维算法各有局限：PCA变体简单可解释但不够灵活，无法捕捉非线性流形结构；自编码器难以解释；基于图嵌入的方法可能产生病态几何扭曲。需要一种既灵活又可解释的降维方法。

Method: 提出变分框架，将降维算法表述为最优流形嵌入问题的解。该框架允许非线性嵌入，其解满足一组偏微分方程，并能反映嵌入目标的对称性。

Result: 该框架提供了比PCA更灵活的解决方案，同时保持了可解释性。在某些情况下可以解析表征解，有趣的是，一个特例恰好恢复了PCA。

Conclusion: 提出的变分框架为降维问题提供了统一视角，既保持了PCA的可解释性优点，又通过允许非线性嵌入获得了更大的灵活性，为解决现有降维方法的局限性提供了新途径。

Abstract: Dimensionality reduction algorithms like principal component analysis (PCA) are workhorses of machine learning and neuroscience, but each has well-known limitations. Variants of PCA are simple and interpretable, but not flexible enough to capture nonlinear data manifold structure. More flexible approaches have other problems: autoencoders are generally difficult to interpret, and graph-embedding-based methods can produce pathological distortions in manifold geometry. Motivated by these shortcomings, we propose a variational framework that casts dimensionality reduction algorithms as solutions to an optimal manifold embedding problem. By construction, this framework permits nonlinear embeddings, allowing its solutions to be more flexible than PCA. Moreover, the variational nature of the framework has useful consequences for interpretability: each solution satisfies a set of partial differential equations, and can be shown to reflect symmetries of the embedding objective. We discuss these features in detail and show that solutions can be analytically characterized in some cases. Interestingly, one special case exactly recovers PCA.

</details>


### [174] [Benchmarking In-context Experiential Learning Through Repeated Product Recommendations](https://arxiv.org/abs/2511.22130)
*Gilbert Yang,Yaqin Chen,Thomson Yen,Hongseok Namkoong*

Main category: cs.LG

TL;DR: BELA基准测试评估智能体在动态环境中通过经验学习的能力，当前前沿模型在适应性学习方面表现不佳


<details>
  <summary>Details</summary>
Motivation: 现实世界环境不断变化，智能体需要处理不完全知识并通过经验适应行为，但现有评估主要关注无歧义任务，缺乏对智能体通过积累经验进行适应性学习和推理能力的测量

Method: 创建BELA基准测试，结合：(1)亚马逊真实产品数据，(2)多样化用户角色表示异质潜在偏好，(3)基于角色的LLM用户模拟器生成丰富交互轨迹

Result: 当前前沿模型难以在多个情节中实现有意义的改进，突显了需要具备强大上下文学习能力的智能体系统

Conclusion: 需要开发能够在动态环境中通过经验进行适应性学习和推理的智能体系统，BELA基准为此提供了评估框架

Abstract: To reliably navigate ever-shifting real-world environments, agents must grapple with incomplete knowledge and adapt their behavior through experience. However, current evaluations largely focus on tasks that leave no ambiguity, and do not measure agents' ability to adaptively learn and reason through the experiences they accrued. We exemplify the need for this in-context experiential learning in a product recommendation context, where agents must navigate shifting customer preferences and product landscapes through natural language dialogue. We curate a benchmark for experiential learning and active exploration (BELA) that combines (1) rich real-world products from Amazon, (2) a diverse collection of user personas to represent heterogeneous yet latent preferences, and (3) a LLM user simulator powered by the persona to create rich interactive trajectories. We observe that current frontier models struggle to meaningfully improve across episodes, underscoring the need for agentic systems with strong in-context learning capabilities.

</details>


### [175] [Probabilistic Digital Twin for Misspecified Structural Dynamical Systems via Latent Force Modeling and Bayesian Neural Networks](https://arxiv.org/abs/2511.22133)
*Sahil Kashyap,Rajdip Nayek*

Main category: cs.LG

TL;DR: 提出一个概率数字孪生框架，用于处理物理模型不准确时的动态系统响应预测，结合高斯过程潜在力模型和贝叶斯神经网络实现端到端的不确定性感知推理与预测。


<details>
  <summary>Details</summary>
Motivation: 动态系统通常存在模型形式错误（物理模型不准确），传统方法难以处理这种不确定性。需要开发能够从诊断到预测系统传播不确定性的可信数字孪生框架。

Method: 1. 诊断阶段：将模型形式错误视为线性动态系统的潜在输入力，使用高斯过程潜在力模型（GPLFM）从传感器测量中联合估计系统状态和模型错误。2. 训练贝叶斯神经网络（BNN）学习从系统状态到模型错误的概率非线性映射，捕捉诊断不确定性。3. 预测阶段：使用该映射生成伪测量，通过卡尔曼滤波进行状态预测。

Result: 在四个非线性示例中验证了框架的有效性：单自由度振荡器、多自由度系统、Bouc-Wen迟滞系统和Silverbox实验数据集。展示了预测准确性和对模型不准确的鲁棒性。

Conclusion: 该框架能够系统地从诊断到预测传播不确定性，为可信数字孪生提供了关键能力，在处理物理模型不准确的动态系统响应预测方面表现出良好的准确性和鲁棒性。

Abstract: This work presents a probabilistic digital twin framework for response prediction in dynamical systems governed by misspecified physics. The approach integrates Gaussian Process Latent Force Models (GPLFM) and Bayesian Neural Networks (BNNs) to enable end-to-end uncertainty-aware inference and prediction. In the diagnosis phase, model-form errors (MFEs) are treated as latent input forces to a nominal linear dynamical system and jointly estimated with system states using GPLFM from sensor measurements. A BNN is then trained on posterior samples to learn a probabilistic nonlinear mapping from system states to MFEs, while capturing diagnostic uncertainty. For prognosis, this mapping is used to generate pseudo-measurements, enabling state prediction via Kalman filtering. The framework allows for systematic propagation of uncertainty from diagnosis to prediction, a key capability for trustworthy digital twins. The framework is demonstrated using four nonlinear examples: a single degree of freedom (DOF) oscillator, a multi-DOF system, and two established benchmarks -- the Bouc-Wen hysteretic system and the Silverbox experimental dataset -- highlighting its predictive accuracy and robustness to model misspecification.

</details>


### [176] [TinyLLM: Evaluation and Optimization of Small Language Models for Agentic Tasks on Edge Devices](https://arxiv.org/abs/2511.22138)
*Mohd Ariful Haque,Fahad Rahman,Kishor Datta Gupta,Khalil Shujaee,Roy George*

Main category: cs.LG

TL;DR: 该研究评估了小型语言模型在边缘设备上执行智能体任务（函数/工具/API调用）的有效性，通过多种优化策略使1-3B参数的中型模型在准确率上显著优于<1B的超紧凑模型，最高达到65.74%的整体准确率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是实现无需依赖云基础设施、能在边缘设备上运行的智能体AI，以提供隐私保护、低延迟的自主智能体解决方案，使智能体应用超越云端限制。

Method: 使用Berkeley Function Calling Leaderboard框架评估SLMs，采用参数驱动的优化策略：监督微调、参数高效微调、基于强化学习的优化、通过DPO的偏好对齐以及混合方法。构建了基于AgentBank数据的DPO训练流程，将SFT数据转换为选择-拒绝对。

Result: 中型模型（1-3B参数）在准确率上显著优于超紧凑模型（<1B参数），混合优化达到65.74%整体准确率和55.62%多轮对话准确率。不同模型规模在BFCL各类别（简单、多重、并行等）中表现存在明显差异。

Conclusion: 混合优化策略对于小型语言模型在边缘设备上实现准确、高效、稳定的智能体AI至关重要，使隐私保护、低延迟的自主智能体在云端之外变得实用可行。

Abstract: This paper investigates the effectiveness of small language models (SLMs) for agentic tasks (function/tool/API calling) with a focus on running agents on edge devices without reliance on cloud infrastructure. We evaluate SLMs using the Berkeley Function Calling Leaderboard (BFCL) framework and describe parameter-driven optimization strategies that include supervised fine-tuning (SFT), parameter-efficient fine-tuning (PEFT), reinforcement learning (RL)-based optimization, preference alignment via Direct Preference Optimization (DPO), and hybrid methods. We report results for models including TinyAgent, TinyLlama, Qwen, and xLAM across BFCL categories (simple, multiple, parallel, parallel-multiple, and relevance detection), both in live and non-live settings, and in multi-turn evaluations. We additionally detail a DPO training pipeline constructed from AgentBank data (e.g., ALFRED), including our conversion of SFT data to chosen-rejected pairs using TinyLlama responses as rejected outputs and manual validation. Our results demonstrate clear accuracy differences across model scales where medium-sized models (1-3B parameters) significantly outperform ultra-compact models (<1B parameters), achieving up to 65.74% overall accuracy, and 55.62% multi-turn accuracy with hybrid optimization. This study highlights the importance of hybrid optimization strategies that enable small language models to deliver accurate, efficient, and stable agentic AI on edge devices, making privacy-preserving, low-latency autonomous agents practical beyond the cloud.

</details>


### [177] [From Topology to Retrieval: Decoding Embedding Spaces with Unified Signatures](https://arxiv.org/abs/2511.22150)
*Florian Rottach,William Rudman,Bastain Rieck,Harrisen Scells,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 提出统一拓扑签名(UTS)框架，通过多属性视角分析文本嵌入空间的结构，能预测模型特性、揭示架构相似性，并关联拓扑结构与检索效果。


<details>
  <summary>Details</summary>
Motivation: 研究嵌入在空间中的组织方式不仅能增强模型可解释性，还能揭示驱动下游任务性能的因素。现有拓扑和几何度量存在高度冗余，单个指标往往无法充分区分嵌入空间。

Method: 提出统一拓扑签名(UTS)框架，这是一种用于表征嵌入空间的整体方法。基于对多种文本嵌入模型和数据集的拓扑和几何度量的综合分析。

Result: UTS能够预测模型特定属性，揭示由模型架构驱动的相似性。将拓扑结构与排序效果联系起来，准确预测文档可检索性。发现多属性视角对于理解和利用文本嵌入几何至关重要。

Conclusion: 整体、多属性的视角对于理解和利用文本嵌入的几何结构至关重要。UTS框架为分析嵌入空间提供了有效的工具，能够揭示模型特性和性能驱动因素。

Abstract: Studying how embeddings are organized in space not only enhances model interpretability but also uncovers factors that drive downstream task performance. In this paper, we present a comprehensive analysis of topological and geometric measures across a wide set of text embedding models and datasets. We find a high degree of redundancy among these measures and observe that individual metrics often fail to sufficiently differentiate embedding spaces. Building on these insights, we introduce Unified Topological Signatures (UTS), a holistic framework for characterizing embedding spaces. We show that UTS can predict model-specific properties and reveal similarities driven by model architecture. Further, we demonstrate the utility of our method by linking topological structure to ranking effectiveness and accurately predicting document retrievability. We find that a holistic, multi-attribute perspective is essential to understanding and leveraging the geometry of text embeddings.

</details>


### [178] [Designing Instance-Level Sampling Schedules via REINFORCE with James-Stein Shrinkage](https://arxiv.org/abs/2511.22177)
*Peiyu Yu,Suraj Kothawade,Sirui Xie,Ying Nian Wu,Hongliang Fei*

Main category: cs.LG

TL;DR: 提出一种通过重新调度采样时间线来提升文本到图像生成器性能的方法，而不是修改模型权重。使用基于James-Stein估计器的新奖励基线来学习实例级采样计划。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练方法主要关注模型权重调整（微调对齐或蒸馏加速），但忽略了采样时间线调度的潜力。本文探索通过重新调度冻结采样器的采样时间线来解锁预训练模型的额外生成潜力。

Method: 1. 学习实例级（提示和噪声条件）采样计划，而非固定全局计划；2. 使用单次Dirichlet策略；3. 引入基于James-Stein估计器的新奖励基线，在高维策略学习中提供更准确的梯度估计。

Result: 1. 在Stable Diffusion和Flux模型家族中一致提升文本图像对齐，包括文本渲染和组合控制；2. 5步Flux-Dev采样器配合本文计划可达到与专门蒸馏的Flux-Schnell采样器相当的生成质量。

Conclusion: 本文提出的调度框架作为一种新兴的模型无关后训练杠杆，能够解锁预训练采样器的额外生成潜力，为文本到图像生成提供了新的优化方向。

Abstract: Most post-training methods for text-to-image samplers focus on model weights: either fine-tuning the backbone for alignment or distilling it for few-step efficiency. We take a different route: rescheduling the sampling timeline of a frozen sampler. Instead of a fixed, global schedule, we learn instance-level (prompt- and noise-conditioned) schedules through a single-pass Dirichlet policy. To ensure accurate gradient estimates in high-dimensional policy learning, we introduce a novel reward baseline based on a principled James-Stein estimator; it provably achieves lower estimation errors than commonly used variants and leads to superior performance. Our rescheduled samplers consistently improve text-image alignment including text rendering and compositional control across modern Stable Diffusion and Flux model families. Additionally, a 5-step Flux-Dev sampler with our schedules can attain generation quality comparable to deliberately distilled samplers like Flux-Schnell. We thus position our scheduling framework as an emerging model-agnostic post-training lever that unlocks additional generative potential in pretrained samplers.

</details>


### [179] [PULSE-ICU: A Pretrained Unified Long-Sequence Encoder for Multi-task Prediction in Intensive Care Units](https://arxiv.org/abs/2511.22199)
*Sejeong Jang,Joo Heung Yoon,Hyo Kyung Lee*

Main category: cs.LG

TL;DR: PULSE-ICU是一个自监督基础模型，从大规模EHR序列中学习ICU事件级表示，无需重采样或手动特征工程，在18个预测任务中表现优异，并在外部验证中展示了对领域转移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: ICU数据高度不规则、异质且时间碎片化，这给可泛化的临床预测带来了挑战。现有方法通常需要重采样或手动特征工程，限制了模型的泛化能力和数据效率。

Method: 提出PULSE-ICU自监督基础模型：1）统一嵌入模块编码事件身份、连续值、单位和时间属性；2）基于Longformer的编码器高效建模长轨迹；3）从大规模EHR序列中学习事件级ICU表示，无需重采样或手动特征工程。

Result: 1）在18个预测任务（包括死亡率、干预预测和表型识别）上微调后表现优异；2）在eICU、HiRID和P12数据集上进行外部验证，仅需少量微调即可获得显著改进；3）展示了对领域转移和变量约束的鲁棒性。

Conclusion: 基础模型风格的方法可以提高数据效率和适应性，为不同临床环境中的ICU决策支持提供了一个可扩展的框架，能够应对ICU数据的异质性和时间碎片化挑战。

Abstract: Intensive care unit (ICU) data are highly irregular, heterogeneous, and temporally fragmented, posing challenges for generalizable clinical prediction. We present PULSE-ICU, a self-supervised foundation model that learns event-level ICU representations from large-scale EHR sequences without resampling or manual feature engineering. A unified embedding module encodes event identity, continuous values, units, and temporal attributes, while a Longformer-based encoder enables efficient modeling of long trajectories. PULSE-ICU was fine-tuned across 18 prediction tasks, including mortality, intervention forecasting, and phenotype identification, achieving strong performance across task types. External validation on eICU, HiRID, and P12 showed substantial improvements with minimal fine-tuning, demonstrating robustness to domain shift and variable constraints. These findings suggest that foundation-style modeling can improve data efficiency and adaptability, providing a scalable framework for ICU decision support across diverse clinical environments.

</details>


### [180] [BiCQL-ML: A Bi-Level Conservative Q-Learning Framework for Maximum Likelihood Inverse Reinforcement Learning](https://arxiv.org/abs/2511.22210)
*Junsung Park*

Main category: cs.LG

TL;DR: BiCQL-ML是一种免策略的离线逆强化学习算法，通过双层框架联合优化奖励函数和保守Q函数，无需显式策略学习，在标准离线RL基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 离线逆强化学习仅使用固定演示数据恢复解释专家行为的奖励函数，但现有方法存在局限性。本文旨在开发一种无需在线交互、避免显式策略学习的方法，以更好地恢复奖励函数并提升下游策略性能。

Method: 提出BiCQL-ML算法，采用双层框架：1）在当前奖励下通过保守Q学习（CQL）学习保守Q函数；2）更新奖励参数以最大化专家动作的期望Q值，同时抑制对分布外动作的过度泛化。该方法可视为基于软值匹配原则的最大似然估计。

Result: 理论证明BiCQL-ML收敛到使专家策略达到软最优的奖励函数。在标准离线RL基准测试中，相比现有离线IRL基线，BiCQL-ML在奖励恢复和下游策略性能方面均有提升。

Conclusion: BiCQL-ML是一种有效的免策略离线IRL方法，通过联合优化奖励和保守Q函数，避免了显式策略学习，在理论和实验上都表现出优越性能。

Abstract: Offline inverse reinforcement learning (IRL) aims to recover a reward function that explains expert behavior using only fixed demonstration data, without any additional online interaction. We propose BiCQL-ML, a policy-free offline IRL algorithm that jointly optimizes a reward function and a conservative Q-function in a bi-level framework, thereby avoiding explicit policy learning. The method alternates between (i) learning a conservative Q-function via Conservative Q-Learning (CQL) under the current reward, and (ii) updating the reward parameters to maximize the expected Q-values of expert actions while suppressing over-generalization to out-of-distribution actions. This procedure can be viewed as maximum likelihood estimation under a soft value matching principle. We provide theoretical guarantees that BiCQL-ML converges to a reward function under which the expert policy is soft-optimal. Empirically, we show on standard offline RL benchmarks that BiCQL-ML improves both reward recovery and downstream policy performance compared to existing offline IRL baselines.

</details>


### [181] [FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning](https://arxiv.org/abs/2511.22265)
*Yuan Yao,Lixu Wang,Jiaqi Wu,Jin Song,Simin Chen,Zehua Wang,Zijian Tian,Wei Chen,Huixia Li,Xiaoxiao Li*

Main category: cs.LG

TL;DR: FedRE提出了一种基于纠缠表示的联邦学习框架，通过随机权重聚合本地表示和标签编码，在保护隐私的同时实现异构模型的高效协作训练。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法大多假设同构模型架构，但实际应用中客户端在数据和资源上存在异构性，这使得同构假设不切实际，因此需要模型异构的联邦学习解决方案。

Method: 提出联邦表示纠缠（FedRE）框架：1）客户端使用归一化随机权重将本地表示聚合成单个纠缠表示；2）使用相同权重将one-hot标签编码聚合成纠缠标签编码；3）上传到服务器训练全局分类器；4）每轮重新采样随机权重增加多样性，防止全局分类器过度自信；5）每个客户端只上传单个跨类别纠缠表示和纠缠标签编码。

Result: 大量实验表明，FedRE在模型性能、隐私保护和通信开销之间实现了有效权衡。该方法减少了表示反转攻击的风险，降低了通信开销。

Conclusion: FedRE通过纠缠表示机制，为模型异构联邦学习提供了一个有效的解决方案，在保持隐私保护的同时实现了良好的模型性能和通信效率。

Abstract: Federated learning (FL) enables collaborative training across clients without compromising privacy. While most existing FL methods assume homogeneous model architectures, client heterogeneity in data and resources renders this assumption impractical, motivating model-heterogeneous FL. To address this problem, we propose Federated Representation Entanglement (FedRE), a framework built upon a novel form of client knowledge termed entangled representation. In FedRE, each client aggregates its local representations into a single entangled representation using normalized random weights and applies the same weights to integrate the corresponding one-hot label encodings into the entangled-label encoding. Those are then uploaded to the server to train a global classifier. During training, each entangled representation is supervised across categories via its entangled-label encoding, while random weights are resampled each round to introduce diversity, mitigating the global classifier's overconfidence and promoting smoother decision boundaries. Furthermore, each client uploads a single cross-category entangled representation along with its entangled-label encoding, mitigating the risk of representation inversion attacks and reducing communication overhead. Extensive experiments demonstrate that FedRE achieves an effective trade-off among model performance, privacy protection, and communication overhead. The codes are available at https://github.com/AIResearch-Group/FedRE.

</details>


### [182] [TreeCoder: Systematic Exploration and Optimisation of Decoding and Constraints for LLM Code Generation](https://arxiv.org/abs/2511.22277)
*Henrijs Princis,Arindam Sharma,Cristina David*

Main category: cs.LG

TL;DR: TreeCoder是一个用于代码生成的通用解码框架，通过树搜索和约束函数确保代码正确性，无需依赖提示工程


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成时经常违反语法或语义约束，仅靠自然语言提示难以保证代码正确性

Method: 将解码表示为候选程序的树搜索，将解码策略和约束函数（如风格、语法、执行）作为可优化的组件

Result: 在MBPP（Python）和SQL-Spider基准测试中，TreeCoder显著提高了CodeLlama、Mistral和DeepSeek等开源模型的准确率

Conclusion: TreeCoder提供了一个灵活框架，通过系统探索和自动调优解码配置，有效提升LLM代码生成的质量和正确性

Abstract: Large language models (LLMs) have shown remarkable ability to generate code, yet their outputs often violate syntactic or semantic constraints when guided only through natural language prompts. We introduce TreeCoder, the most general and flexible framework to date for exploring decoding strategies, constraints, and hyperparameters in LLMs, and use it in code generation to enforce correctness and structure during decoding rather than relying on prompt engineering. TreeCoder represents decoding as a tree search over candidate programs, where both decoding strategies and constraint functions - such as style, syntax, execution - are treated as first-class, optimisable components. This design enables systematic exploration and automatic tuning of decoding configurations using standard optimisation techniques. Experiments on the MBPP (Python) and SQL-Spider benchmarks show that TreeCoder consistently improves accuracy across open-source models such as CodeLlama, Mistral and DeepSeek, often outperforming their unconstrained baselines by considerable margins.

</details>


### [183] [The Hidden Cost of Approximation in Online Mirror Descent](https://arxiv.org/abs/2511.22283)
*Ofir Schlisselberg,Uri Sherman,Tomer Koren,Yishay Mansour*

Main category: cs.LG

TL;DR: 本文系统研究了在线镜像下降(OMD)的近似误差影响，发现正则化器的光滑性与误差鲁棒性之间存在复杂关系，揭示了不同正则化器对误差容忍度的显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有OMD分析通常假设理想的无误差设置，而实际应用中子问题往往只能近似求解。这限制了对实际性能保证的理解，因此需要系统研究近似OMD的性能。

Method: 系统研究近似OMD算法，分析不同正则化器（负熵、log-barrier、Tsallis正则化器）在误差存在下的性能表现，建立误差与遗憾的精确界限。

Result: 1. 均匀光滑正则化器下建立了误差导致的超额遗憾的紧界；2. 单纯形上发现尖锐分离：负熵需要指数小误差避免线性遗憾，而log-barrier和Tsallis正则化器对多项式误差保持鲁棒；3. 随机损失下负熵在单纯形上恢复鲁棒性，但子集上仍需指数小误差。

Conclusion: 正则化器的选择对OMD的误差鲁棒性至关重要，不同正则化器对近似误差的容忍度存在显著差异，这为实际算法设计提供了重要指导。

Abstract: Online mirror descent (OMD) is a fundamental algorithmic paradigm that underlies many algorithms in optimization, machine learning and sequential decision-making. The OMD iterates are defined as solutions to optimization subproblems which, oftentimes, can be solved only approximately, leading to an inexact version of the algorithm. Nonetheless, existing OMD analyses typically assume an idealized error free setting, thereby limiting our understanding of performance guarantees that should be expected in practice. In this work we initiate a systematic study into inexact OMD, and uncover an intricate relation between regularizer smoothness and robustness to approximation errors. When the regularizer is uniformly smooth, we establish a tight bound on the excess regret due to errors. Then, for barrier regularizers over the simplex and its subsets, we identify a sharp separation: negative entropy requires exponentially small errors to avoid linear regret, whereas log-barrier and Tsallis regularizers remain robust even when the errors are only polynomial. Finally, we show that when the losses are stochastic and the domain is the simplex, negative entropy regains robustness-but this property does not extend to all subsets, where exponentially small errors are again necessary to avoid suboptimal regret.

</details>


### [184] [Online Dynamic Pricing of Complementary Products](https://arxiv.org/abs/2511.22291)
*Marco Mussi,Marcello Restelli*

Main category: cs.LG

TL;DR: 提出一个针对互补产品的动态定价在线学习算法，通过整数规划识别产品间的互补关系，并利用异方差高斯过程多臂老虎机优化定价策略，相比忽略产品交互的算法能提升收入。


<details>
  <summary>Details</summary>
Motivation: 传统动态定价算法通常独立优化每个产品的价格，忽略了产品间的互补关系。这种忽略可能导致无法充分利用协调定价策略的潜力，从而未能最大化整体收入。

Method: 提出在线学习算法：1) 利用交易数据通过整数规划问题识别产品间的互补关系；2) 基于异方差高斯过程的多臂老虎机解决方案来优化定价策略，该方法数据驱动且计算高效。

Result: 在模拟环境中验证了该解决方案，证明相比忽略产品间交互的可比学习算法，该算法能够提高收入。

Conclusion: 针对互补产品的动态定价算法能够有效利用产品间的联合需求结构，通过识别互补关系和优化协调定价策略来最大化整体收入，为动态定价领域提供了新的研究方向。

Abstract: Traditional pricing paradigms, once dominated by static models and rule-based heuristics, are increasingly being replaced by dynamic, data-driven approaches powered by machine learning algorithms. Despite their growing sophistication, most dynamic pricing algorithms focus on optimizing the price of each product independently, disregarding potential interactions among items. By neglecting these interdependencies in consumer demand across related goods, sellers may fail to capture the full potential of coordinated pricing strategies. In this paper, we address this problem by exploring dynamic pricing mechanisms designed explicitly for complementary products, aiming to exploit their joint demand structure to maximize overall revenue. We present an online learning algorithm considering both positive and negative interactions between products' demands. The algorithm utilizes transaction data to identify advantageous complementary relationships through an integer programming problem between different items, and then optimizes pricing strategies using data-driven and computationally efficient multi-armed bandit solutions based on heteroscedastic Gaussian processes. We validate our solution in a simulated environment, and we demonstrate that our solution improves the revenue w.r.t. a comparable learning algorithm ignoring such interactions.

</details>


### [185] [Adaptive tumor growth forecasting via neural & universal ODEs](https://arxiv.org/abs/2511.22292)
*Kavya Subramanian,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: 使用神经ODE和通用微分方程构建自适应肿瘤生长模型，提高预测精度并指导治疗策略


<details>
  <summary>Details</summary>
Motivation: 传统肿瘤生长模型（如Gompertz和Bertalanffy方程）虽然能捕捉一般肿瘤动态，但难以适应患者特异性变异，特别是在数据有限的情况下。需要更灵活的模型来提高预测准确性，从而优化治疗策略。

Method: 采用科学机器学习方法，使用神经ODE和通用微分方程，以Gompertz模型为基础，用自适应神经网络替换刚性项来捕捉隐藏动态。在Julia编程语言中实现，进行数据约束下的预测和符号恢复，将学习到的动态转化为显式数学表达式。

Result: 该方法能够构建自适应肿瘤生长模型，在数据有限的情况下进行准确预测，并能将学习到的动态转化为可解释的数学表达式，具有提高预测精度的潜力。

Conclusion: 基于神经ODE和通用微分方程的自适应肿瘤生长模型有潜力改善预测准确性，为动态有效的治疗策略提供指导，从而提高临床治疗效果。

Abstract: Forecasting tumor growth is critical for optimizing treatment. Classical growth models such as the Gompertz and Bertalanffy equations capture general tumor dynamics but may fail to adapt to patient-specific variability, particularly with limited data available. In this study, we leverage Neural Ordinary Differential Equations (Neural ODEs) and Universal Differential Equations (UDEs), two pillars of Scientific Machine Learning (SciML), to construct adaptive tumor growth models capable of learning from experimental data. Using the Gompertz model as a baseline, we replace rigid terms with adaptive neural networks to capture hidden dynamics through robust modeling in the Julia programming language. We use our models to perform forecasting under data constraints and symbolic recovery to transform the learned dynamics into explicit mathematical expressions. Our approach has the potential to improve predictive accuracy, guiding dynamic and effective treatment strategies for improved clinical outcomes.

</details>


### [186] [FLUX: Efficient Descriptor-Driven Clustered Federated Learning under Arbitrary Distribution Shifts](https://arxiv.org/abs/2511.22305)
*Dario Fenoglio,Mohan Li,Pietro Barbiero,Nicholas D. Lane,Marc Langheinrich,Martin Gjoreski*

Main category: cs.LG

TL;DR: FLUX是一个基于聚类的联邦学习框架，能够处理训练和测试时的四种常见分布偏移，无需先验知识，支持测试时适应，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习假设客户端数据独立同分布，但在实际场景中这一假设往往不成立，导致全局模型性能显著下降，限制了联邦学习的实际应用。

Method: 提出FLUX框架，采用隐私保护的客户端描述符提取和无监督聚类方法，无需预先知道分布偏移类型或聚类数量，支持测试时适应，使未见过的未标记客户端能够从最合适的聚类特定模型中受益。

Result: 在四个标准基准测试、两个真实世界数据集和十个最先进基线的广泛实验中，FLUX在多样化分布偏移下提高了性能和稳定性，相比最佳基线平均准确率提升高达23个百分点，同时保持与FedAvg相当的计算和通信开销。

Conclusion: FLUX是一个有效的聚类联邦学习框架，能够处理训练和测试时的分布偏移问题，无需先验知识，在实际应用中具有更好的适应性和性能表现。

Abstract: Federated Learning (FL) enables collaborative model training across multiple clients while preserving data privacy. Traditional FL methods often use a global model to fit all clients, assuming that clients' data are independent and identically distributed (IID). However, when this assumption does not hold, the global model accuracy may drop significantly, limiting FL applicability in real-world scenarios. To address this gap, we propose FLUX, a novel clustering-based FL (CFL) framework that addresses the four most common types of distribution shifts during both training and test time. To this end, FLUX leverages privacy-preserving client-side descriptor extraction and unsupervised clustering to ensure robust performance and scalability across varying levels and types of distribution shifts. Unlike existing CFL methods addressing non-IID client distribution shifts, FLUX i) does not require any prior knowledge of the types of distribution shifts or the number of client clusters, and ii) supports test-time adaptation, enabling unseen and unlabeled clients to benefit from the most suitable cluster-specific models. Extensive experiments across four standard benchmarks, two real-world datasets and ten state-of-the-art baselines show that FLUX improves performance and stability under diverse distribution shifts, achieving an average accuracy gain of up to 23 percentage points over the best-performing baselines, while maintaining computational and communication overhead comparable to FedAvg.

</details>


### [187] [DeXposure: A Dataset and Benchmarks for Inter-protocol Credit Exposure in Decentralized Financial Networks](https://arxiv.org/abs/2511.22314)
*Wenbin Wu,Kejiang Qian,Alexis Lui,Christopher Jack,Yue Wu,Peter McBurney,Fengxiang He,Bryan Zhang*

Main category: cs.LG

TL;DR: DeXposure是首个大规模去中心化金融网络跨协议信用风险暴露数据集，包含4370万条记录，涵盖4300个协议、602条区块链和24300种代币，时间跨度为2020-2025年。论文提出了基于TVL变化的价值关联信用风险暴露度量方法，并开发了三个机器学习基准任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、系统性的去中心化金融网络跨协议信用风险暴露数据集，这限制了金融风险监测、政策分析和机器学习研究的发展。需要构建一个全面的数据集来理解DeFi网络中协议间的金融依赖关系。

Method: 1. 构建DeXposure数据集，利用DefiLlama元数据开发代币到协议的模型，从代币存量动态推断跨协议信用风险暴露；2. 定义价值关联信用风险暴露作为基于TVL变化的推断金融依赖关系；3. 开发三个机器学习基准：图聚类用于网络结构演化追踪、向量自回归用于冲击期间部门级风险暴露动态分析、时序图神经网络用于动态链接预测。

Result: 观察到四个主要现象：1. 网络规模快速增长；2. 向关键协议集中的趋势；3. 网络密度下降（实际连接与可能连接的比例）；4. 不同部门（借贷平台、交易交易所、资产管理协议）间冲击传播模式不同。数据集和代码已公开。

Conclusion: DeXposure数据集填补了DeFi跨协议信用风险暴露研究的空白，为机器学习和金融风险监测提供了重要资源。该数据集支持图聚类、向量自回归和时序图分析等基准任务，有助于推动DeFi市场建模、政策分析和风险监控等领域的研究与实践。

Abstract: We curate the DeXposure dataset, the first large-scale dataset for inter-protocol credit exposure in decentralized financial networks, covering global markets of 43.7 million entries across 4.3 thousand protocols, 602 blockchains, and 24.3 thousand tokens, from 2020 to 2025. A new measure, value-linked credit exposure between protocols, is defined as the inferred financial dependency relationships derived from changes in Total Value Locked (TVL). We develop a token-to-protocol model using DefiLlama metadata to infer inter-protocol credit exposure from the token's stock dynamics, as reported by the protocols. Based on the curated dataset, we develop three benchmarks for machine learning research with financial applications: (1) graph clustering for global network measurement, tracking the structural evolution of credit exposure networks, (2) vector autoregression for sector-level credit exposure dynamics during major shocks (Terra and FTX), and (3) temporal graph neural networks for dynamic link prediction on temporal graphs. From the analysis, we observe (1) a rapid growth of network volume, (2) a trend of concentration to key protocols, (3) a decline of network density (the ratio of actual connections to possible connections), and (4) distinct shock propagation across sectors, such as lending platforms, trading exchanges, and asset management protocols. The DeXposure dataset and code have been released publicly. We envision they will help with research and practice in machine learning as well as financial risk monitoring, policy analysis, DeFi market modeling, amongst others. The dataset also contributes to machine learning research by offering benchmarks for graph clustering, vector autoregression, and temporal graph analysis.

</details>


### [188] [SingleQuant: Efficient Quantization of Large Language Models in a Single Pass](https://arxiv.org/abs/2511.22316)
*Jinying Xiao,Bin Ji,Shasha Li,Xiaodong Liu,Ma Jun,Ye Zhong,Wei Li,Xuan Xie,Qingbo Wu,Jie Yu*

Main category: cs.LG

TL;DR: SingleQuant是一种单次量化框架，通过解耦量化截断，消除STE在Stiefel流形上引入的非光滑性和梯度噪声，实现快速高保真LLM量化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM量化方法结合不兼容的梯度优化和量化截断，导致严重的收敛病理问题，延长量化时间并降低任务性能。STE在Stiefel流形上引入非光滑性和梯度噪声，阻碍优化收敛。

Method: 提出SingleQuant单次量化框架，构造对齐旋转变换(ART)和均匀性旋转变换(URT)处理不同激活异常值。ART通过闭式最优旋转平滑异常值，URT通过几何映射重塑分布。两种矩阵均采用严格公式化的Givens旋转。

Result: 在7B-70B LLM上实验显示，SingleQuant优于所选基线。量化LLaMA-2-13B时，实现1400倍量化加速，平均任务性能提升+0.57%。

Conclusion: SingleQuant通过消除非光滑性和梯度噪声因素，能够在短时间内实现高保真LLM量化，显著提升量化效率和模型性能。

Abstract: Large Language Models (LLMs) quantization facilitates deploying LLMs in resource-limited settings, but existing methods that combine incompatible gradient optimization and quantization truncation lead to serious convergence pathology. This prolongs quantization time and degrades LLMs' task performance. Our studies confirm that Straight-Through Estimator (STE) on Stiefel manifolds introduce non-smoothness and gradient noise, obstructing optimization convergence and blocking high-fidelity quantized LLM development despite extensive training. To tackle the above limitations, we propose SingleQuant, a single-pass quantization framework that decouples from quantization truncation, thereby eliminating the above non-smoothness and gradient noise factors. Specifically, SingleQuant constructs Alignment Rotation Transformation (ART) and Uniformity Rotation Transformation (URT) targeting distinct activation outliers, where ART achieves smoothing of outlier values via closed-form optimal rotations, and URT reshapes distributions through geometric mapping. Both matrices comprise strictly formulated Givens rotations with predetermined dimensions and rotation angles, enabling promising LLMs task performance within a short time. Experimental results demonstrate SingleQuant's superiority over the selected baselines across diverse tasks on 7B-70B LLMs. To be more precise, SingleQuant enables quantized LLMs to achieve higher task performance while necessitating less time for quantization. For example, when quantizing LLaMA-2-13B, SingleQuant achieves 1,400$\times$ quantization speedup and increases +0.57\% average task performance compared to the selected best baseline.

</details>


### [189] [Test Time Training for AC Power Flow Surrogates via Physics and Operational Constraint Refinement](https://arxiv.org/abs/2511.22343)
*Panteleimon Dogoulis,Mohammad Iman Alizadeh,Sylvain Kubler,Maxime Cordy*

Main category: cs.LG

TL;DR: 提出PI-TTT框架，通过测试时训练增强机器学习潮流计算的物理一致性，在推理时强制执行交流潮流方程和运行约束。


<details>
  <summary>Details</summary>
Motivation: 基于机器学习的潮流计算相比传统数值方法有计算优势，但往往难以保持完全的物理一致性。需要一种方法在保持计算效率的同时确保物理可行性和准确性。

Method: 提出物理信息测试时训练（PI-TTT）框架，在推理时通过少量梯度更新对代理模型输出进行轻量级自监督精炼，强制执行交流潮流等式和运行约束，无需标注数据即可适应未见运行条件。

Result: 在IEEE 14、118、300总线系统和PEGASE 1354总线网络上实验表明，PI-TTT将潮流残差和运行约束违反减少1-2个数量级，同时保持机器学习模型的计算优势。

Conclusion: PI-TTT提供了快速、准确且物理可靠的预测，代表了电力系统分析中可扩展且物理一致学习的有前景方向。

Abstract: Power Flow (PF) calculation based on machine learning (ML) techniques offer significant computational advantages over traditional numerical methods but often struggle to maintain full physical consistency. This paper introduces a physics-informed test-time training (PI-TTT) framework that enhances the accuracy and feasibility of ML-based PF surrogates by enforcing AC power flow equalities and operational constraints directly at inference time. The proposed method performs a lightweight self-supervised refinement of the surrogate outputs through few gradient-based updates, enabling local adaptation to unseen operating conditions without requiring labeled data. Extensive experiments on the IEEE 14-, 118-, and 300-bus systems and the PEGASE 1354-bus network show that PI-TTT reduces power flow residuals and operational constraint violations by one to two orders of magnitude compared with purely ML-based models, while preserving their computational advantage. The results demonstrate that PI-TTT provides fast, accurate, and physically reliable predictions, representing a promising direction for scalable and physics-consistent learning in power system analysis.

</details>


### [190] [Cleaning the Pool: Progressive Filtering of Unlabeled Pools in Deep Active Learning](https://arxiv.org/abs/2511.22344)
*Denis Huseljic,Marek Herde,Lukas Rauch,Paul Hahn,Bernhard Sick*

Main category: cs.LG

TL;DR: REFINE是一种集成主动学习方法，通过两阶段策略组合多种AL策略，无需预先知道哪种策略最优，从而在各种数据集和模型上实现更稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 现有主动学习策略（如不确定性或代表性）在不同数据集、模型和AL周期中效果差异很大。单一策略在整个AL过程中可能表现不佳，因为没有一种策略始终占优。

Method: REFINE采用两阶段方法：1) 渐进过滤：通过集成多种AL策略迭代筛选未标注池，保留捕获不同数据价值概念的候选样本；2) 基于覆盖的选择：从精炼池中选择最终批次，确保所有已识别的价值概念都被考虑。

Result: 在6个分类数据集和3个基础模型上的实验表明，REFINE始终优于单个策略和现有集成方法。渐进过滤作为强大的预处理步骤，能提升任何应用于精炼池的单个AL策略的性能。

Conclusion: REFINE提供了一种有效的集成主动学习方法，能够自适应地组合多种策略，且易于扩展集成新的先进AL策略，在音频谱图分类等实际应用中表现出色。

Abstract: Existing active learning (AL) strategies capture fundamentally different notions of data value, e.g., uncertainty or representativeness. Consequently, the effectiveness of strategies can vary substantially across datasets, models, and even AL cycles. Committing to a single strategy risks suboptimal performance, as no single strategy dominates throughout the entire AL process. We introduce REFINE, an ensemble AL method that combines multiple strategies without knowing in advance which will perform best. In each AL cycle, REFINE operates in two stages: (1) Progressive filtering iteratively refines the unlabeled pool by considering an ensemble of AL strategies, retaining promising candidates capturing different notions of value. (2) Coverage-based selection then chooses a final batch from this refined pool, ensuring all previously identified notions of value are accounted for. Extensive experiments across 6 classification datasets and 3 foundation models show that REFINE consistently outperforms individual strategies and existing ensemble methods. Notably, progressive filtering serves as a powerful preprocessing step that improves the performance of any individual AL strategy applied to the refined pool, which we demonstrate on an audio spectrogram classification use case. Finally, the ensemble of REFINE can be easily extended with upcoming state-of-the-art AL strategies.

</details>


### [191] [AutoTailor: Automatic and Efficient Adaptive Model Deployment for Diverse Edge Devices](https://arxiv.org/abs/2511.22355)
*Mengyang Liu,Chenyu Lu,Haodong Tian,Fang Dong,Ruiting Zhou,Wei Wang,Dian Shen,Guangtong Li,Ye Wan,Li Li*

Main category: cs.LG

TL;DR: AutoTailor是首个自动化端到端SuperNet自适应模型部署框架，通过计算图引导编译自动将ML模型转换为SuperNet，使用免学习的延迟和精度预测器，显著减少代码量和硬件分析成本，提升精度并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有SuperNet方法需要繁琐的模型感知开发和耗时的硬件感知分析，限制了在实际边缘设备上的应用。需要自动化框架来简化SuperNet构建和性能预测。

Method: 采用计算图引导编译方法自动将用户提供的ML模型转换为SuperNet；集成免学习的延迟和精度预测器，实现低成本而准确的性能预测。

Result: AutoTailor将SuperNet构建代码量减少11-27倍，硬件分析成本降低至少11倍，相比现有方法实现最高15.60%的绝对精度提升和60.03%的延迟降低。

Conclusion: AutoTailor是首个自动化端到端SuperNet自适应模型部署框架，显著简化了边缘设备上的自适应模型部署，提高了效率和性能。

Abstract: On-device machine learning (ML) has become a fundamental component of emerging mobile applications. Adaptive model deployment delivers efficient inference for heterogeneous device capabilities and performance requirements through customizing neural architectures. SuperNet-based approaches offer a promising solution by generating a large number of model variants from a pre-trained ML model. However, applying SuperNet in existing frameworks suffers from tedious model-aware development and time-consuming hardware-aware profiling, which limits their practical adoption.
  We present AutoTailor, the first framework to enable automated, end-to-end SuperNet-based adaptive model deployment for edge devices. Unlike manual SuperNet construction, AutoTailor employs a computation graph-guided compilation approach to automatically transform user-provided ML models into SuperNets. To support efficient specialization, AutoTailor incorporates learning-free latency and accuracy predictors, enabling low-cost yet accurate performance prediction. Our extended evaluations demonstrate that AutoTailor reduces the lines of code for SuperNet construction by 11--27$\times$, decreases hardware-aware profiling costs by at least 11$\times$, and achieves up to 15.60\% absolute accuracy improvement and 60.03\% latency reduction compared to state-of-the-art approaches across diverse models and devices.

</details>


### [192] [Efficient-Husformer: Efficient Multimodal Transformer Hyperparameter Optimization for Stress and Cognitive Loads](https://arxiv.org/abs/2511.22362)
*Merey Orazaly,Fariza Temirkhanova,Jurn-Gyu Park*

Main category: cs.LG

TL;DR: 提出Efficient-Husformer，一种通过超参数优化设计的Transformer架构，用于多模态生理信号的压力检测，在保持高性能的同时大幅减少计算和内存需求。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在生理信号分析中表现出色，但计算强度和内存需求高。需要设计更高效的架构来平衡性能和计算成本。

Method: 开发Efficient-Husformer，通过结构化搜索空间进行超参数优化，针对多模态生理数据集（WESAD和CogLoad）进行压力检测。采用(L+dm)或(L+FFN)模态组合，单层架构，3个注意力头，模型维度18/30，FFN维度120/30。

Result: 在WESAD和CogLoad数据集上分别达到88.41%和92.61%的准确率，相比原始Husformer提升13.83%和6.98%。模型仅需约3万个参数，成为紧凑高效的解决方案。

Conclusion: Efficient-Husformer通过超参数优化实现了性能与效率的良好平衡，为生理信号分析中的Transformer应用提供了更实用的解决方案。

Abstract: Transformer-based models have gained considerable attention in the field of physiological signal analysis. They leverage long-range dependencies and complex patterns in temporal signals, allowing them to achieve performance superior to traditional RNN and CNN models. However, they require high computational intensity and memory demands. In this work, we present Efficient-Husformer, a novel Transformer-based architecture developed with hyperparameter optimization (HPO) for multi-class stress detection across two multimodal physiological datasets (WESAD and CogLoad). The main contributions of this work are: (1) the design of a structured search space, targeting effective hyperparameter optimization; (2) a comprehensive ablation study evaluating the impact of architectural decisions; (3) consistent performance improvements over the original Husformer, with the best configuration achieving an accuracy of 88.41 and 92.61 (improvements of 13.83% and 6.98%) on WESAD and CogLoad datasets, respectively. The best-performing configuration is achieved with the (L + dm) or (L + FFN) modality combinations, using a single layer, 3 attention heads, a model dimension of 18/30, and FFN dimension of 120/30, resulting in a compact model with only about 30k parameters.

</details>


### [193] [SuRe: Surprise-Driven Prioritised Replay for Continual LLM Learning](https://arxiv.org/abs/2511.22367)
*Hugo Hazard,Zafeirios Fountas,Martin A. Benfeghoul,Adnan Oomerjee,Jun Wang,Haitham Bou-Ammar*

Main category: cs.LG

TL;DR: 提出SuRe（基于惊喜的优先级回放）和双学习器设计，通过惊喜值排序和快慢LoRA适配器结合，显著提升大语言模型在持续学习中的性能，减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 持续学习是机器学习和人类智能之间的关键差距。虽然正则化和回放在视觉任务中表现良好，但在大语言模型的多任务学习中效果不佳，特别是在任务数量多的场景下。现有方法存在选择（选择什么来回放）和整合（如何整合新知识）两个失败模式。

Method: 1. SuRe（Surprise-prioritised Replay）：基于惊喜值（负对数似然）对序列进行排序和存储的架构无关规则；2. 双学习器设计：包含快速和慢速LoRA适配器，通过指数移动平均合并，实现快速适应同时稳定长期知识。

Result: 在大量任务（LNT）设置中达到最先进性能，在标准CL和LNT基准测试中总体平均表现最佳。结合SuRe和双学习器带来进一步增益，在LNT上比先前SOTA提升高达+5个准确率点。消融研究证实该方法在减少回放频率和小缓冲区大小下仍保持鲁棒性。

Conclusion: 回放是持续LLM微调的强大基线方法，基于惊喜的选择和慢权重整合是缓解灾难性遗忘的互补组件。该方法展示了有效性和样本效率。

Abstract: Continual learning, one's ability to adapt to a sequence of tasks without forgetting previously acquired knowledge, remains a major challenge in machine learning and a key gap between artificial and human intelligence. While regularisation and replay perform well in vision, they lag behind multi-task learning for large language models (LLMs), especially at scale with many tasks. We revisit replay and argue that two failure modes drive this gap: selection (what to rehearse) and integration (how to consolidate new knowledge). To address selection, we propose Surprise-prioritised Replay (SuRe), a simple, architecture-agnostic rule that ranks and stores the most surprising (high Negative Log-Likelihood) sequences. SuRe achieves state-of-the-art performance in the Large Number of Tasks (LNT) setting and delivers the best overall average across both Standard CL and LNT benchmarks. To address integration, we add a dual-learner design with fast and slow LoRA adapters merged via an exponential moving average (EMA), enabling rapid adaptation while stabilising long-term knowledge. Combining SuRe with the dual learner yields further gains, including improvements of up to +5 accuracy points on LNT over prior SOTA. Ablation studies confirm that our proposed method remains robust under reduced replay frequency and small buffer size, demonstrating both effectiveness and sample efficiency. Taken together, our results establish replay as a strong baseline for continual LLM fine-tuning and demonstrate that surprise-based selection and slow-weight consolidation are complementary components for mitigating catastrophic forgetting.

</details>


### [194] [Predicting and Interpolating Spatiotemporal Environmental Data: A Case Study of Groundwater Storage in Bangladesh](https://arxiv.org/abs/2511.22378)
*Anna Pazola,Mohammad Shamsudduha,Richard G. Taylor,Allan Tucker*

Main category: cs.LG

TL;DR: 该研究比较了两种深度学习策略（网格到网格 vs 网格到点）用于时空预测，发现空间插值比时间预测更困难，地质不确定性对点时间行为有重要影响。


<details>
  <summary>Details</summary>
Motivation: 地理空间观测数据通常仅限于点测量，需要时间预测和空间插值来构建连续场。研究旨在评估两种深度学习策略的有效性，以解决这一挑战。

Method: 使用孟加拉国地下水储量数据作为案例研究，比较两种方法：(1) 网格到网格方法：使用网格化预测变量建模栅格化目标（建模前聚合）；(2) 网格到点方法：使用网格化预测变量建模点目标，然后通过克里金插值填充域（建模后聚合）。

Result: 研究发现空间插值比时间预测困难得多。最近邻点不一定最相似，地质不确定性强烈影响点的时间行为。这些发现为基于时间序列动态聚类位置的高级插值方法提供了动机。

Conclusion: 研究结论适用于其他由间接可观测因素控制的环境变量。未来工作需要开发基于时间序列动态聚类位置的高级插值方法。

Abstract: Geospatial observational datasets are often limited to point measurements, making temporal prediction and spatial interpolation essential for constructing continuous fields. This study evaluates two deep learning strategies for addressing this challenge: (1) a grid-to-grid approach, where gridded predictors are used to model rasterised targets (aggregation before modelling), and (2) a grid-to-point approach, where gridded predictors model point targets, followed by kriging interpolation to fill the domain (aggregation after modelling). Using groundwater storage data from Bangladesh as a case study, we compare the effcacy of these approaches. Our findings indicate that spatial interpolation is substantially more difficult than temporal prediction. In particular, nearest neighbours are not always the most similar, and uncertainties in geology strongly influence point temporal behaviour. These insights motivate future work on advanced interpolation methods informed by clustering locations based on time series dynamics. Demonstrated on groundwater storage, the conclusions are applicable to other environmental variables governed by indirectly observable factors. Code is available at https://github.com/pazolka/interpolation-prediction-gwsa.

</details>


### [195] [TS2Vec-Ensemble: An Enhanced Self-Supervised Framework for Time Series Forecasting](https://arxiv.org/abs/2511.22395)
*Ganeshan Niroshan,Uthayasanker Thayasivam*

Main category: cs.LG

TL;DR: TS2Vec-Ensemble：结合自监督表示学习与显式时间特征的混合框架，通过双模型集成架构提升时间序列预测性能


<details>
  <summary>Details</summary>
Motivation: 现有自监督对比学习方法（如TS2Vec）在预测任务中表现不佳，因为其目标函数侧重于实例判别而非捕捉对预测至关重要的确定性模式（如季节性和趋势）。需要一种能结合学习到的动态特征与显式时间先验的方法。

Method: 提出TS2Vec-Ensemble混合框架：1) 使用预训练的TS2Vec编码器获取隐式学习的时间动态特征；2) 融合显式工程化的时间特征（编码周期性模式）；3) 采用双模型集成架构，两个独立的回归头分别关注学习到的动态特征和季节模式；4) 使用自适应加权方案结合两者，权重针对每个预测时域独立优化。

Result: 在ETT基准数据集上进行单变量和多变量预测的广泛实验表明，TS2Vec-Ensemble在标准TS2Vec基线和其他最先进模型上取得一致且显著的性能提升，验证了混合策略的有效性。

Conclusion: 结合学习到的表示与显式时间先验的混合策略是长期时间序列预测的优越方法，TS2Vec-Ensemble框架成功弥补了自监督表示学习在预测任务中的不足。

Abstract: Self-supervised representation learning, particularly through contrastive methods like TS2Vec, has advanced the analysis of time series data. However, these models often falter in forecasting tasks because their objective functions prioritize instance discrimination over capturing the deterministic patterns, such as seasonality and trend, that are critical for accurate prediction. This paper introduces TS2Vec-Ensemble, a novel hybrid framework designed to bridge this gap. Our approach enhances the powerful, implicitly learned dynamics from a pretrained TS2Vec encoder by fusing them with explicit, engineered time features that encode periodic cycles. This fusion is achieved through a dual-model ensemble architecture, where two distinct regression heads -- one focused on learned dynamics and the other on seasonal patterns -- are combined using an adaptive weighting scheme. The ensemble weights are optimized independently for each forecast horizon, allowing the model to dynamically prioritize short-term dynamics or long-term seasonality as needed. We conduct extensive experiments on the ETT benchmark datasets for both univariate and multivariate forecasting. The results demonstrate that TS2Vec-Ensemble consistently and significantly outperforms the standard TS2Vec baseline and other state-of-the-art models, validating our hypothesis that a hybrid of learned representations and explicit temporal priors is a superior strategy for long-horizon time series forecasting.

</details>


### [196] [Improving Stochastic Action-Constrained Reinforcement Learning via Truncated Distributions](https://arxiv.org/abs/2511.22406)
*Roland Stolz,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 提出高效数值近似方法解决动作约束强化学习中截断正态分布关键特征计算难题，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有动作约束强化学习方法面临有效策略更新、计算效率和可预测运行时间的挑战。虽然近期工作提出使用截断正态分布进行随机策略梯度方法，但在复杂约束下计算熵、对数概率及其梯度等关键特征变得不可行，现有近似方法严重降低性能。

Method: 提出高效数值近似方法来准确估计截断正态分布的关键特征（熵、对数概率及其梯度），并提供截断策略分布的高效采样策略。

Result: 在三个基准环境上验证了该方法，当使用准确估计时展现出显著的性能提升。

Conclusion: 在动作约束强化学习设置中，准确估计截断分布的关键特征至关重要，提出的高效数值近似方法能有效解决现有方法的性能问题。

Abstract: In reinforcement learning (RL), it is often advantageous to consider additional constraints on the action space to ensure safety or action relevance. Existing work on such action-constrained RL faces challenges regarding effective policy updates, computational efficiency, and predictable runtime. Recent work proposes to use truncated normal distributions for stochastic policy gradient methods. However, the computation of key characteristics, such as the entropy, log-probability, and their gradients, becomes intractable under complex constraints. Hence, prior work approximates these using the non-truncated distributions, which severely degrades performance. We argue that accurate estimation of these characteristics is crucial in the action-constrained RL setting, and propose efficient numerical approximations for them. We also provide an efficient sampling strategy for truncated policy distributions and validate our approach on three benchmark environments, which demonstrate significant performance improvements when using accurate estimations.

</details>


### [197] [PISA: Prioritized Invariant Subgraph Aggregation](https://arxiv.org/abs/2511.22435)
*Ali Ghasemi,Farooq Ahmad Wani,Maria Sofia Bucarelli,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: PISA框架通过动态MLP聚合机制改进图数据的OOD泛化，相比之前基于单一不变子图或简单聚合的方法，能更有效地整合多个因果模式，在15个数据集上实现最高5%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有图数据OOD泛化方法存在局限：CIGA只提取单一不变子图可能遗漏多个因果模式，SuGAr虽然学习多个不变子图但使用简单聚合策略。需要更有效的多子图聚合机制来提升鲁棒性。

Method: 提出PISA框架，核心是动态MLP聚合机制，能够优先考虑并有效组合多个不变子图的表示，相比之前的均匀或贪婪聚合策略更加智能和自适应。

Result: 在包括DrugOOD在内的15个数据集上进行实验，PISA在分类准确率上比现有方法提升高达5%，证明了动态聚合机制的有效性。

Conclusion: PISA通过动态MLP聚合机制有效整合多个不变子图表示，显著提升了图数据在分布外场景下的泛化能力，为复杂图结构中的多因果模式学习提供了新思路。

Abstract: Recent work has extended the invariance principle for out-of-distribution (OOD) generalization from Euclidean to graph data, where challenges arise due to complex structures and diverse distribution shifts in node attributes and topology. To handle these, Chen et al. proposed CIGA (Chen et al., 2022b), which uses causal modeling and an information-theoretic objective to extract a single invariant subgraph capturing causal features. However, this single-subgraph focus can miss multiple causal patterns. Liu et al. (2025) addressed this with SuGAr, which learns and aggregates diverse invariant subgraphs via a sampler and diversity regularizer, improving robustness but still relying on simple uniform or greedy aggregation. To overcome this, the proposed PISA framework introduces a dynamic MLP-based aggregation that prioritizes and combines subgraph representations more effectively. Experiments on 15 datasets, including DrugOOD (Ji et al., 2023), show that PISA achieves up to 5% higher classification accuracy than prior methods.

</details>


### [198] [An Efficient Embedding Based Ad Retrieval with GPU-Powered Feature Interaction](https://arxiv.org/abs/2511.22460)
*Yifan Lei,Jiahua Luo,Tingyu Jiang,Bo Zhang,Lifeng Wang,Dapeng Liu,Zhaoren Wu,Haijie Gu,Huan Yu,Jie Jiang*

Main category: cs.LG

TL;DR: 提出基于GPU加速的双塔网络特征交互方法，在广告检索系统中实现Wide & Deep模型，显著提升检索精度并降低计算成本


<details>
  <summary>Details</summary>
Motivation: 现有双塔模型在广告检索中用户和广告嵌入仅在最后内积计算时交互，特征交互能力不足；而支持早期特征交互的DNN模型计算成本过高，不适用于检索阶段

Method: 提出基于GPU加速的特征交互双塔网络，引入新颖的压缩倒排列表设计，支持大规模高效特征交互计算，首次在检索系统中成功实现Wide & Deep模型

Result: 在腾讯广告真实业务场景中，离线评估优于现有方法，已成功部署到腾讯广告推荐系统，带来显著的在线性能提升

Conclusion: 该方法不仅验证了所提方法的有效性，还为优化大规模广告检索系统提供了新的实践指导

Abstract: In large-scale advertising recommendation systems, retrieval serves as a critical component, aiming to efficiently select a subset of candidate ads relevant to user behaviors from a massive ad inventory for subsequent ranking and recommendation. The Embedding-Based Retrieval (EBR) methods modeled by the dual-tower network are widely used in the industry to maintain both retrieval efficiency and accuracy. However, the dual-tower model has significant limitations: the embeddings of users and ads interact only at the final inner product computation, resulting in insufficient feature interaction capabilities. Although DNN-based models with both user and ad as input features, allowing for early-stage interaction between these features, are introduced in the ranking stage to mitigate this issue, they are computationally infeasible for the retrieval stage. To bridge this gap, this paper proposes an efficient GPU-based feature interaction for the dual-tower network to significantly improve retrieval accuracy while substantially reducing computational costs. Specifically, we introduce a novel compressed inverted list designed for GPU acceleration, enabling efficient feature interaction computation at scale. To the best of our knowledge, this is the first framework in the industry to successfully implement Wide and Deep in a retrieval system. We apply this model to the real-world business scenarios in Tencent Advertising, and experimental results demonstrate that our method outperforms existing approaches in offline evaluation and has been successfully deployed to Tencent's advertising recommendation system, delivering significant online performance gains. This improvement not only validates the effectiveness of the proposed method, but also provides new practical guidance for optimizing large-scale ad retrieval systems.

</details>


### [199] [Adversarial Flow Models](https://arxiv.org/abs/2511.22475)
*Shanchuan Lin,Ceyuan Yang,Zhijie Lin,Hao Chen,Haoqi Fan*

Main category: cs.LG

TL;DR: 提出对抗流模型，统一对抗模型和流模型，支持单步或多步生成，通过对抗目标训练，比传统GAN更稳定，比一致性方法更高效


<details>
  <summary>Details</summary>
Motivation: 传统GAN学习任意噪声到数据的传输计划，训练不稳定；一致性方法需要学习概率流中间时间步，模型容量需求大且存在误差累积。需要一种既能稳定训练又能高效单步生成的方法

Method: 提出对抗流模型，生成器学习确定性的噪声到数据映射（与流匹配模型相同的最优传输），使用对抗目标训练，支持原生单步或多步生成，无需学习中间时间步

Result: 在ImageNet-256px上，1NFE设置下，B/2模型接近一致性XL/2模型性能，XL/2模型创下2.38 FID新纪录。通过深度重复端到端训练56层和112层模型，单次前向传播分别达到2.08和1.94 FID，超越2NFE和4NFE对应模型

Conclusion: 对抗流模型成功统一对抗模型和流模型，提供稳定训练和高效生成，在单步生成质量上达到新水平，展示了深度模型端到端训练的潜力

Abstract: We present adversarial flow models, a class of generative models that unifies adversarial models and flow models. Our method supports native one-step or multi-step generation and is trained using the adversarial objective. Unlike traditional GANs, where the generator learns an arbitrary transport plan between the noise and the data distributions, our generator learns a deterministic noise-to-data mapping, which is the same optimal transport as in flow-matching models. This significantly stabilizes adversarial training. Also, unlike consistency-based methods, our model directly learns one-step or few-step generation without needing to learn the intermediate timesteps of the probability flow for propagation. This saves model capacity, reduces training iterations, and avoids error accumulation. Under the same 1NFE setting on ImageNet-256px, our B/2 model approaches the performance of consistency-based XL/2 models, while our XL/2 model creates a new best FID of 2.38. We additionally show the possibility of end-to-end training of 56-layer and 112-layer models through depth repetition without any intermediate supervision, and achieve FIDs of 2.08 and 1.94 using a single forward pass, surpassing their 2NFE and 4NFE counterparts.

</details>


### [200] [Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities, and Challenges](https://arxiv.org/abs/2511.22483)
*Guanxi Lu,Hao Mark Chen,Zhiqiang Que,Wayne Luk,Hongxiang Fan*

Main category: cs.LG

TL;DR: 本文系统研究量化对LLM可信度指标的影响，提出精度集成投票方法提升可信度性能


<details>
  <summary>Details</summary>
Motivation: 现有量化框架主要关注困惑度或分类准确率，忽略了关键的可信度指标，这在金融、医疗等高风险领域应用量化LLM时存在风险

Method: 系统研究量化对四个可信度指标的影响，提出精度集成投票方法，利用同一模型不同精度变体的预测进行集成

Result: 量化在不同压缩比和量化方法上存在不稳定性，精度集成投票方法可将可信度指标性能提升高达5.8%

Conclusion: 开发模型压缩技术时必须考虑可信度因素，压缩与可信度的交叉研究对安全关键应用具有重要意义

Abstract: Large language models (LLMs) have shown promising performance across various tasks. However, their autoregressive decoding process poses significant challenges for efficient deployment on existing AI hardware. Quantization alleviates memory and compute pressure by compressing weights, activations, and KV caches to low precisions while preserving generation quality. However, existing quantization frameworks typically focus on perplexity or classification accuracy, often omitting critical trustworthiness metrics. This gap introduces risks when applying quantized LLMs to downstream high-stakes domains such as finance and healthcare. In this work, we systematically investigate the impact of quantization on four trustworthiness metrics (adversarial robustness, fairness, machine ethics, and out-of-distribution robustness) and identify the instability across compression ratios and quantization methods. Building on these observations, we develop a novel precision-ensemble voting approach that leverages predictions from mixed-precision variants of the same model and consistently improves performance by up to $5.8\%$ on trustworthiness metrics. Our results highlight the importance of considering trustworthiness when developing model compression techniques and point to research opportunities at the intersection of compression and trustworthiness for safety-critical applications.

</details>


### [201] [Space Explanations of Neural Network Classification](https://arxiv.org/abs/2511.22498)
*Faezeh Labbaf,Tomáš Kolárik,Martin Blicha,Grigory Fedyukovich,Michael Wand,Natasha Sharygina*

Main category: cs.LG

TL;DR: 提出基于逻辑的Space Explanations概念，为神经网络在连续输入空间中的行为提供可证明的保证，通过Craig插值和不可满足核心生成自动创建解释


<details>
  <summary>Details</summary>
Motivation: 现有神经网络解释方法缺乏对网络在连续输入区域行为的可证明保证，需要一种能够提供严格理论保证的解释框架

Method: 使用Craig插值算法和不可满足核心生成技术自动生成空间解释，这些逻辑方法能够为神经网络在连续特征空间中的行为提供可证明的保证

Result: 在从小型到大型的实际案例研究中，生成的解释比现有最先进方法更有意义，证明了方法的有效性

Conclusion: Space Explanations为神经网络解释提供了可证明的理论保证，通过逻辑方法自动生成高质量解释，优于现有方法

Abstract: We present a novel logic-based concept called Space Explanations for classifying neural networks that gives provable guarantees of the behavior of the network in continuous areas of the input feature space. To automatically generate space explanations, we leverage a range of flexible Craig interpolation algorithms and unsatisfiable core generation. Based on real-life case studies, ranging from small to medium to large size, we demonstrate that the generated explanations are more meaningful than those computed by state-of-the-art.

</details>


### [202] [Privacy-Utility-Bias Trade-offs for Privacy-Preserving Recommender Systems](https://arxiv.org/abs/2511.22515)
*Shiva Parsarad,Isabel Wagner*

Main category: cs.LG

TL;DR: 该研究系统评估了差分隐私机制（DPSGD和LDP）对四种推荐系统（NCF、BPR、SVD、VAE）在准确性和公平性方面的影响，发现隐私保护强度与性能下降呈正相关，但不同模型受影响程度不同，没有一种DP机制在所有情况下都最优。


<details>
  <summary>Details</summary>
Motivation: 随着推荐系统越来越多地采用差分隐私来保护用户数据，需要了解隐私机制如何影响推荐准确性和公平性。目前缺乏对不同隐私机制和推荐模型的系统性比较研究。

Method: 在MovieLens-1M和Yelp数据集上，对四种推荐系统（NCF、BPR、SVD、VAE）应用两种差分隐私机制（DPSGD和LDP），进行全面的跨模型评估，分析隐私保护对准确性和公平性指标的影响。

Result: 更强的隐私保护会降低推荐效用，但影响程度因模型而异：NCF在DPSGD下准确率损失最小（ε≈1时低于10%），SVD和BPR下降更大，VAE对隐私最敏感。DPSGD通常能缩小热门与冷门物品的推荐差距，而LDP更倾向于保持原有模式。

Conclusion: 没有单一的差分隐私机制在所有情况下都最优，每种机制在不同的隐私保护水平和数据条件下都有各自的权衡。隐私保护对推荐系统的影响具有异质性，需要根据具体模型和数据特征选择合适的隐私机制。

Abstract: Recommender systems (RSs) output ranked lists of items, such as movies or restaurants, that users may find interesting, based on the user's past ratings and ratings from other users. RSs increasingly incorporate differential privacy (DP) to protect user data, raising questions about how privacy mechanisms affect both recommendation accuracy and fairness. We conduct a comprehensive, cross-model evaluation of two DP mechanisms, differentially private stochastic gradient descent (DPSGD) and local differential privacy (LDP), applied to four recommender systems (Neural Collaborative Filtering (NCF), Bayesian Personalized Ranking (BPR), Singular Value Decomposition (SVD), and Variational Autoencoder (VAE)) on the MovieLens-1M and Yelp datasets. We find that stronger privacy consistently reduces utility, but not uniformly. NCF under DPSGD shows the smallest accuracy loss (under 10 percent at epsilon approximately 1), whereas SVD and BPR experience larger drops, especially for users with niche preferences. VAE is the most sensitive to privacy, with sharp declines for sparsely represented groups. The impact on bias metrics is similarly heterogeneous. DPSGD generally reduces the gap between recommendations of popular and less popular items, whereas LDP preserves existing patterns more closely. These results highlight that no single DP mechanism is uniformly superior; instead, each provides trade-offs under different privacy regimes and data conditions.

</details>


### [203] [List-Decodable Regression via Expander Sketching](https://arxiv.org/abs/2511.22524)
*Herbod Pourali,Sajjad Hashemian,Ebrahim Ardeshir-Larijani*

Main category: cs.LG

TL;DR: 提出基于扩展图草图技术的列表可解码线性回归框架，实现接近最优的样本复杂度、列表大小和计算效率


<details>
  <summary>Details</summary>
Motivation: 解决列表可解码线性回归中样本复杂度、列表大小和计算效率之间的权衡问题，避免使用复杂的SoS方法

Method: 使用无损扩展图合成轻度污染的数据批次，结合鲁棒聚合和短谱滤波阶段，避免显式的批次结构

Result: 在标准亚高斯假设下，达到样本复杂度$\tilde{O}((d+\log(1/δ))/α)$，列表大小$O(1/α)$，接近输入稀疏度的运行时间$\tilde{O}(\mathrm{nnz}(X)+d^{3}/α)$

Conclusion: 扩展图草图框架为列表可解码线性回归提供了高效且理论保证强的解决方案，避免了复杂数学工具的使用

Abstract: We introduce an expander-sketching framework for list-decodable linear regression that achieves sample complexity $\tilde{O}((d+\log(1/δ))/α)$, list size $O(1/α)$, and near input-sparsity running time $\tilde{O}(\mathrm{nnz}(X)+d^{3}/α)$ under standard sub-Gaussian assumptions. Our method uses lossless expanders to synthesize lightly contaminated batches, enabling robust aggregation and a short spectral filtering stage that matches the best known efficient guarantees while avoiding SoS machinery and explicit batch structure.

</details>


### [204] [Where to Measure: Epistemic Uncertainty-Based Sensor Placement with ConvCNPs](https://arxiv.org/abs/2511.22567)
*Feyza Eksen,Stefan Oehmcke,Stefan Lüdtke*

Main category: cs.LG

TL;DR: 提出基于认知不确定性的传感器布局新方法，通过扩展ConvCNPs模型和MDN输出头来估计认知不确定性，相比基于总不确定性的方法能更有效降低模型误差


<details>
  <summary>Details</summary>
Motivation: 现有传感器布局方法依赖总预测不确定性，混淆了认知不确定性和偶然不确定性，可能导致在模糊区域选择次优传感器位置

Method: 扩展卷积条件神经过程（ConvCNPs），加入混合密度网络（MDNs）输出头来估计认知不确定性，提出基于认知不确定性减少期望的新采集函数用于传感器布局

Result: 初步结果表明，基于认知不确定性的传感器布局方法比基于总不确定性的方法能更有效地减少模型误差

Conclusion: 认知不确定性驱动的传感器布局优于传统基于总不确定性的方法，为时空系统建模提供了更有效的传感器选择策略

Abstract: Accurate sensor placement is critical for modeling spatio-temporal systems such as environmental and climate processes. Neural Processes (NPs), particularly Convolutional Conditional Neural Processes (ConvCNPs), provide scalable probabilistic models with uncertainty estimates, making them well-suited for data-driven sensor placement. However, existing approaches rely on total predictive uncertainty, which conflates epistemic and aleatoric components, that may lead to suboptimal sensor selection in ambiguous regions. To address this, we propose expected reduction in epistemic uncertainty as a new acquisition function for sensor placement. To enable this, we extend ConvCNPs with a Mixture Density Networks (MDNs) output head for epistemic uncertainty estimation. Preliminary results suggest that epistemic uncertainty driven sensor placement more effectively reduces model error than approaches based on overall uncertainty.

</details>


### [205] [Entropy is all you need for Inter-Seed Cross-Play in Hanabi](https://arxiv.org/abs/2511.22581)
*Johannes Forkel,Jakob Foerster*

Main category: cs.LG

TL;DR: 在Hanabi游戏中，标准独立PPO算法通过提高熵系数到0.05（而非通常的0.01），在跨种子交叉游戏中达到新的最优性能，超越了所有专门为该场景设计的算法。


<details>
  <summary>Details</summary>
Motivation: 研究在零样本协调和临时团队协作中最复杂的基准测试Hanabi中，如何通过简单的超参数调整来提升跨种子交叉游戏性能，探索为什么标准算法在某些情况下能超越专门设计的算法。

Method: 使用标准独立PPO算法，但将熵系数从通常的0.01提高到0.05；同时探索了高GAE λ（约0.9）和使用RNN而非前馈网络对跨种子交叉游戏的影响。

Result: 提高熵系数的PPO在Hanabi的跨种子交叉游戏中达到了新的最优性能，显著超越了所有专门为零样本协调设计的算法；高GAE λ和使用RNN架构也显著提升了跨种子交叉游戏性能。

Conclusion: 超参数（特别是熵正则化）对跨种子交叉游戏性能有巨大影响，但存在简单Dec-POMDPs中，即使增加熵正则化也无法实现完美的跨种子交叉游戏，表明仍需开发新的零样本协调算法。

Abstract: We find that in Hanabi, one of the most complex and popular benchmarks for zero-shot coordination and ad-hoc teamplay, a standard implementation of independent PPO with a slightly higher entropy coefficient 0.05 instead of the typically used 0.01, achieves a new state-of-the-art in cross-play between different seeds, beating by a significant margin all previous specialized algorithms, which were specifically designed for this setting. We provide an intuition for why sufficiently high entropy regularization ensures that different random seed produce joint policies which are mutually compatible. We also empirically find that a high $λ_{\text{GAE}}$ around 0.9, and using RNNs instead of just feed-forward layers in the actor-critic architecture, strongly increase inter-seed cross-play. While these results demonstrate the dramatic effect that hyperparameters can have not just on self-play scores but also on cross-play scores, we show that there are simple Dec-POMDPs though, in which standard policy gradient methods with increased entropy regularization are not able to achieve perfect inter-seed cross-play, thus demonstrating the continuing necessity for new algorithms for zero-shot coordination.

</details>


### [206] [The Multiclass Score-Oriented Loss (MultiSOL) on the Simplex](https://arxiv.org/abs/2511.22587)
*Francesco Marchetti,Edoardo Legnaro,Sabrina Guastavino*

Main category: cs.LG

TL;DR: 该论文将二元分类中的score-oriented损失函数扩展到多分类问题，提出了MultiSOL损失函数，可直接优化目标性能指标，避免后验阈值调整，并在类别不平衡时保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在监督学习中，score-oriented损失函数旨在训练阶段直接优化特定性能指标，避免后验阈值调整。但现有方法主要针对二元分类，需要扩展到多分类场景。

Method: 使用最近提出的多维阈值分类框架，将score-oriented损失函数扩展到多分类，定义了Multiclass Score-Oriented Loss (MultiSOL)函数。该方法将决策阈值视为具有先验分布的随机变量。

Result: 实验表明MultiSOL保持了二元设置中的主要优势：直接优化目标指标、对类别不平衡的鲁棒性，性能与最先进损失函数相当，并提供了单纯形几何与score-oriented学习交互的新见解。

Conclusion: 成功将score-oriented损失函数扩展到多分类问题，提出的MultiSOL函数在保持原有优势的同时，为理解分类器设计与性能指标优化之间的关系提供了新视角。

Abstract: In the supervised binary classification setting, score-oriented losses have been introduced with the aim of optimizing a chosen performance metric directly during the training phase, thus avoiding \textit{a posteriori} threshold tuning. To do this, in their construction, the decision threshold is treated as a random variable provided with a certain \textit{a priori} distribution. In this paper, we use a recently introduced multidimensional threshold-based classification framework to extend such score-oriented losses to multiclass classification, defining the Multiclass Score-Oriented Loss (MultiSOL) functions. As also demonstrated by several classification experiments, this proposed family of losses is designed to preserve the main advantages observed in the binary setting, such as the direct optimization of the target metric and the robustness to class imbalance, achieving performance comparable to other state-of-the-art loss functions and providing new insights into the interaction between simplex geometry and score-oriented learning.

</details>


### [207] [LLM-Cave: A benchmark and light environment for large language models reasoning and decision-making system](https://arxiv.org/abs/2511.22598)
*Huanyu Li,Zongyuan Li,Wei Huang,Xian Guo*

Main category: cs.LG

TL;DR: LLM-Cave是一个轻量级基准测试环境，用于评估大语言模型的序列推理和决策能力，相比现有复杂环境更高效，实验显示结构化多步推理能显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估基准仅限于单步交互，而现有的序列决策环境（如TextStarCraftII和LLM-PySC2）过于复杂，需要数小时才能完成一次游戏，缺乏轻量高效的评估工具。

Method: 提出了LLM-Cave基准测试环境，这是一个经典的符号主义时代实例，AI代理可以在部分可观测状态下探索环境，通过推理附近危险来避免潜在损失。评估了GPT-4o-mini、o1-mini和DeepSeek-R1等主流LLM的序列推理能力、决策性能和计算效率。

Result: DeepSeek-R1在复杂推理任务上取得了最高成功率，而像4o-mini这样的小模型通过采用思维链推测和规划者-批评者策略，在挑战任务上显著缩小了性能差距，但牺牲了计算效率。

Conclusion: 结构化多步推理结合基于LLM的反馈机制能显著增强LLM的决策能力，为改进较弱模型的推理能力提供了有前景的方向，并提出了以推理为中心的LLM评估新基准。

Abstract: Large language models (LLMs) such as ChatGPT o1, ChatGPT o3, and DeepSeek R1 have shown great potential in solving difficult problems. However, current LLM evaluation benchmarks are limited to one-step interactions. Some of the existing sequence decision-making environments, such as TextStarCraftII and LLM-PySC2, are too complicated and require hours of interaction to complete a game. In this paper, we introduce LLM-Cave, a benchmark and light environment for LLM reasoning and decision-making systems. This environment is a classic instance in the era of Symbolism. Artificial intelligence enables the agent to explore the environment and avoid potential losses by reasoning about nearby dangers using partial observable state information. In the experiment, we evaluated the sequential reasoning ability, decision-making performance and computational efficiency of mainstream large language models (LLMs) such as GPT-4o-mini, o1-mini, and DeepSeek-R1. Experiments show that while Deepseek-R1 achieved the highest success rate on complex reasoning tasks, smaller models like 4o-mini significantly narrowed the performance gap on challenges by employing Chain of Speculation and Planner-Critic strategies, at the expense of reduced computational efficiency. This indicates that structured, multi-step reasoning combined with an LLM-based feedback mechanism can substantially enhance an LLM's decision-making capabilities, providing a promising direction for improving reasoning in weaker models and suggesting a new reasoning-centered benchmark for LLM assessment. Our code is open-sourced in https://github.com/puleya1277/CaveEnv.

</details>


### [208] [Federated Learning Survey: A Multi-Level Taxonomy of Aggregation Techniques, Experimental Insights, and Future Frontiers](https://arxiv.org/abs/2511.22616)
*Meriem Arbaoui,Mohamed-el-Amine Brahmia,Abdellatif Rahmoun,Mourad Zghal*

Main category: cs.LG

TL;DR: 这篇论文是关于联邦学习的综述，重点分析了三个研究方向：个性化、优化和鲁棒性，通过混合方法（文献计量分析+系统综述）对现有工作进行分类，并讨论了异构性、效率、安全性和隐私等挑战。


<details>
  <summary>Details</summary>
Motivation: 物联网和人工智能的融合带来了创新，但隐私问题和数据孤岛阻碍了发展。传统的集中式机器学习难以解决这些问题，因此需要联邦学习这种去中心化范式，能够在保护数据隐私的同时进行协作模型训练。

Method: 采用混合方法：结合文献计量分析和系统综述，对联邦学习研究进行结构化分类。重点分析三个研究方向（个性化、优化、鲁棒性），并比较了在IID和非IID数据分布下的聚合方法。

Result: 提供了联邦学习的全面概述，包括聚合策略（架构、同步方法、联邦目标）、实际评估方法，以及不同聚合方法在IID和非IID数据下的实验比较。识别了最具影响力的工作。

Conclusion: 联邦学习是解决数据隐私和隔离问题的有前景方法，但异构性增加了复杂性。论文为未来研究提供了方向，旨在推动这一快速发展的领域创新。

Abstract: The integration of IoT and AI has unlocked innovation across industries, but growing privacy concerns and data isolation hinder progress. Traditional centralized ML struggles to overcome these challenges, which has led to the rise of Federated Learning (FL), a decentralized paradigm that enables collaborative model training without sharing local raw data. FL ensures data privacy, reduces communication overhead, and supports scalability, yet its heterogeneity adds complexity compared to centralized approaches. This survey focuses on three main FL research directions: personalization, optimization, and robustness, offering a structured classification through a hybrid methodology that combines bibliometric analysis with systematic review to identify the most influential works. We examine challenges and techniques related to heterogeneity, efficiency, security, and privacy, and provide a comprehensive overview of aggregation strategies, including architectures, synchronization methods, and diverse federation objectives. To complement this, we discuss practical evaluation approaches and present experiments comparing aggregation methods under IID and non-IID data distributions. Finally, we outline promising research directions to advance FL, aiming to guide future innovation in this rapidly evolving field.

</details>


### [209] [Flow Density Control: Generative Optimization Beyond Entropy-Regularized Fine-Tuning](https://arxiv.org/abs/2511.22640)
*Riccardo De Santi,Marin Vlastelica,Ya-Ping Hsieh,Zebang Shen,Niao He,Andreas Krause*

Main category: cs.LG

TL;DR: Flow Density Control (FDC) 是一种用于微调基础生成模型的新算法，能够优化超越平均奖励的通用目标函数，同时通过多种距离度量保留预训练模型的知识。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法主要关注最大化生成样本的期望奖励，并通过KL散度正则化保留预训练知识。但在实际应用中，需要优化更通用的目标函数（如风险规避、新颖性寻求、多样性度量等），同时考虑更通用的先验信息保留方式（如最优传输距离、Renyi散度等）。

Method: 提出Flow Density Control (FDC)算法，将复杂的微调问题分解为一系列更简单的微调任务序列，每个子任务都可以通过现有的可扩展方法解决。该方法基于镜像流的理论理解，提供了收敛性保证。

Result: 在文本到图像生成和分子设计任务上的实验验证表明，FDC能够引导预训练生成模型优化各种目标函数，解决当前微调方案无法处理的实用相关任务。

Conclusion: FDC为微调基础生成模型提供了一个通用框架，能够处理超越平均奖励的多样化目标函数，同时通过多种距离度量灵活地保留先验知识，扩展了生成模型在实际应用中的能力范围。

Abstract: Adapting large-scale foundation flow and diffusion generative models to optimize task-specific objectives while preserving prior information is crucial for real-world applications such as molecular design, protein docking, and creative image generation. Existing principled fine-tuning methods aim to maximize the expected reward of generated samples, while retaining knowledge from the pre-trained model via KL-divergence regularization. In this work, we tackle the significantly more general problem of optimizing general utilities beyond average rewards, including risk-averse and novelty-seeking reward maximization, diversity measures for exploration, and experiment design objectives among others. Likewise, we consider more general ways to preserve prior information beyond KL-divergence, such as optimal transport distances and Renyi divergences. To this end, we introduce Flow Density Control (FDC), a simple algorithm that reduces this complex problem to a specific sequence of simpler fine-tuning tasks, each solvable via scalable established methods. We derive convergence guarantees for the proposed scheme under realistic assumptions by leveraging recent understanding of mirror flows. Finally, we validate our method on illustrative settings, text-to-image, and molecular design tasks, showing that it can steer pre-trained generative models to optimize objectives and solve practically relevant tasks beyond the reach of current fine-tuning schemes.

</details>


### [210] [Spatially Aware Dictionary-Free Eigenfunction Identification for Modeling and Control of Nonlinear Dynamical Systems](https://arxiv.org/abs/2511.22648)
*David Grasev*

Main category: cs.LG

TL;DR: 提出一种无需预定义基函数的Koopman特征函数数据驱动发现方法，通过参考轨迹识别特征值，利用正则化最小二乘拟合，结合全局优化和PDE约束提升鲁棒性，在多个非线性系统上验证有效。


<details>
  <summary>Details</summary>
Motivation: 传统Koopman算子方法需要预定义基函数，限制了其在复杂非线性系统中的应用。本文旨在开发一种无需预定义基函数的数据驱动方法，直接从数据中发现Koopman特征函数，提高方法的普适性和实用性。

Method: 基于参考轨迹识别Koopman模态振幅，将模态分解转换到包含特征值和时间的基本函数新基上。通过正则化最小二乘拟合将轨迹投影到该基上获得特征函数初值，使用全局优化器优化特征值。通过映射初始状态到特征函数值揭示其空间结构，计算数值梯度，惩罚偏离Koopman偏微分方程的偏差以提高鲁棒性。

Result: 方法在多个基准非线性系统上成功测试，包括带输入的FitzHugh-Nagumo系统、van der Pol和Duffing振荡器，以及带控制的2轴涡轮喷气发动机。结果表明，结合主特征值和空间结构完整性提升显著提高了Koopman预测器的准确性。即使在稀疏状态空间采样下也能有效发现Koopman谱分量，并揭示状态空间的几何特征（如不变分区）。

Conclusion: 该方法为各种动力系统提供了一种实用的Koopman特征函数发现方法，无需预定义基函数。数值近似的特征函数梯度可用于输入动力学建模和控制设计，展示了方法在实际应用中的潜力。

Abstract: A new approach to data-driven discovery of Koopman eigenfunctions without a pre-defined set of basis functions is proposed. The approach is based on a reference trajectory, for which the Koopman mode amplitudes are first identified, and the Koopman mode decomposition is transformed to a new basis, which contains fundamental functions of eigenvalues and time. The initial values of the eigenfunctions are obtained by projecting trajectories onto this basis via a regularized least-squares fit. A global optimizer was employed to optimize the eigenvalues. Mapping initial-state values to eigenfunction values reveals their spatial structure, enabling the numerical computation of their gradients. Thus, deviations from the Koopman partial differential equation are penalized, leading to more robust solutions. The approach was successfully tested on several benchmark nonlinear dynamical systems, including the FitzHugh-Nagumo system with inputs, van der Pol and Duffing oscillators, and a 2-spool turbojet engine with control. The study demonstrates that incorporating principal eigenvalues and spatial structure integrity promotion significantly improves the accuracy of Koopman predictors. The approach effectively discovers Koopman spectral components even with sparse state-space sampling and reveals geometric features of the state space, such as invariant partitions. Finally, the numerical approximation of the eigenfunction gradient can be used for input dynamics modeling and control design. The results support the practicality of the approach for use with various dynamical systems.

</details>


### [211] [Automated Design Optimization via Strategic Search with Large Language Models](https://arxiv.org/abs/2511.22651)
*Anthony Carreon,Vansh Sharma,Venkat Raman*

Main category: cs.LG

TL;DR: AUTO是一个基于大语言模型的代理框架，将设计优化视为梯度自由搜索问题，通过战略推理实现GPU代码优化，性能接近专家实现，搜索效率达贝叶斯优化的50-70%。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在定义良好的搜索空间中表现优异，但在设计参数难以明确定义的设计问题上存在困难。大语言模型能够动态解释设计空间并利用编码的领域知识，为解决这类问题提供了有前景的替代方案。

Method: 提出AUTO框架，将设计优化视为梯度自由搜索问题，采用两个协作代理：战略家（选择探索与开发策略）和执行者（执行详细设计）。应用于GPU代码优化领域，包括化学动力学积分和稠密矩阵乘法。

Result: AUTO生成的解决方案与专家实现相当，搜索效率达到贝叶斯优化方法的50-70%。优化过程约需8小时，每次运行成本估计最高159美元，而中等薪资软件开发者的成本估计最高480美元。

Conclusion: 该框架为在定义不明确、先验信息有限的搜索空间中实现设计优化自动化打开了大门，展示了LLM在复杂设计优化问题中的潜力。

Abstract: Traditional optimization methods excel in well-defined search spaces but struggle with design problems where transformations and design parameters are difficult to define. Large language models (LLMs) offer a promising alternative by dynamically interpreting design spaces and leveraging encoded domain knowledge. To this end, we introduce AUTO, an LLM agent framework that treats design optimization as a gradient-free search problem guided by strategic LLM reasoning. The framework employs two collaborative agents: a Strategist that selects between exploration and exploitation strategies, and an Implementor that executes detailed designs. Applied to GPU code optimization -- a domain critical to fields from machine learning to scientific computing -- AUTO generates solutions competitive with expert implementations for chemical kinetics integration and dense matrix multiplication. The framework achieves 50-70% search efficiency relative to Bayesian optimization methodologies. It completes optimizations in approximately 8 hours at an estimated cost of up to \$159 per run, compared to an estimated cost of up to \$480 with median-wage software developers. These findings open the door to automating design optimization in ill-defined search spaces with limited prior information.

</details>


### [212] [Structure-aware Hybrid-order Similarity Learning for Multi-view Unsupervised Feature Selection](https://arxiv.org/abs/2511.22656)
*Lin Xu,Ke Li,Dongjie Wang,Fengmao Lv,Tianrui Li,Yanyong Huang*

Main category: cs.LG

TL;DR: SHINE-FS是一种新颖的多视图无监督特征选择方法，通过学习混合阶相似性图同时捕获局部和全局数据结构，提升特征选择性能。


<details>
  <summary>Details</summary>
Motivation: 现有多视图无监督特征选择方法主要使用一阶相似性图保留局部结构，忽略了二阶相似性可捕获的全局结构。少数使用预定义二阶相似性图的方法容易受噪声和异常值影响，导致特征选择性能不佳。

Method: SHINE-FS首先学习共识锚点和对应的锚图来捕获锚点与样本间的跨视图关系。基于获得的跨视图共识信息，生成样本的低维表示，通过识别判别性特征重构多视图数据。然后利用锚点-样本关系学习二阶相似性图，最后联合学习一阶和二阶相似性图构建混合阶相似性图，同时捕获局部和全局结构。

Result: 在真实多视图数据集上的综合实验结果表明，SHINE-FS优于最先进的方法。

Conclusion: SHINE-FS通过结构感知的混合阶相似性学习，能够更好地揭示数据的内在结构，从而提升多视图无监督特征选择的性能。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently emerged as an effective dimensionality reduction method for unlabeled multi-view data. However, most existing methods mainly use first-order similarity graphs to preserve local structure, often overlooking the global structure that can be captured by second-order similarity. In addition, a few MUFS methods leverage predefined second-order similarity graphs, making them vulnerable to noise and outliers and resulting in suboptimal feature selection performance. In this paper, we propose a novel MUFS method, termed Structure-aware Hybrid-order sImilarity learNing for multi-viEw unsupervised Feature Selection (SHINE-FS), to address the aforementioned problem. SHINE-FS first learns consensus anchors and the corresponding anchor graph to capture the cross-view relationships between the anchors and the samples. Based on the acquired cross-view consensus information, it generates low-dimensional representations of the samples, which facilitate the reconstruction of multi-view data by identifying discriminative features. Subsequently, it employs the anchor-sample relationships to learn a second-order similarity graph. Furthermore, by jointly learning first-order and second-order similarity graphs, SHINE-FS constructs a hybrid-order similarity graph that captures both local and global structures, thereby revealing the intrinsic data structure to enhance feature selection. Comprehensive experimental results on real multi-view datasets show that SHINE-FS outperforms the state-of-the-art methods.

</details>


### [213] [Difficulties with Evaluating a Deception Detector for AIs](https://arxiv.org/abs/2511.22662)
*Lewis Smith,Bilal Chughtai,Neel Nanda*

Main category: cs.LG

TL;DR: 论文认为当前缺乏可靠评估AI欺骗检测器所需的标记数据，识别了收集这些数据的障碍，并讨论了现有方法的局限性


<details>
  <summary>Details</summary>
Motivation: 构建可靠的AI欺骗检测器对于减轻高级AI系统风险至关重要，但评估这些检测器需要能够明确标记为欺骗或诚实行为的示例数据

Method: 通过概念论证、现有实证研究分析和新颖案例研究分析，识别收集欺骗检测训练数据的障碍，并评估几种实证方法的潜力

Result: 当前缺乏评估欺骗检测器所需的标记数据，存在多个具体障碍，现有实证方法虽然有价值但单独使用不够充分

Conclusion: 欺骗检测的进展需要进一步考虑数据收集问题，当前方法不足以解决评估可靠欺骗检测器所需的标记数据缺乏问题

Abstract: Building reliable deception detectors for AI systems -- methods that could predict when an AI system is being strategically deceptive without necessarily requiring behavioural evidence -- would be valuable in mitigating risks from advanced AI systems. But evaluating the reliability and efficacy of a proposed deception detector requires examples that we can confidently label as either deceptive or honest. We argue that we currently lack the necessary examples and further identify several concrete obstacles in collecting them. We provide evidence from conceptual arguments, analysis of existing empirical works, and analysis of novel illustrative case studies. We also discuss the potential of several proposed empirical workarounds to these problems and argue that while they seem valuable, they also seem insufficient alone. Progress on deception detection likely requires further consideration of these problems.

</details>


### [214] [Modèles de Fondation et Ajustement : Vers une Nouvelle Génération de Modèles pour la Prévision des Séries Temporelles](https://arxiv.org/abs/2511.22674)
*Morad Laglil,Emilie Devijver,Eric Gaussier,Bertrand Pracca*

Main category: cs.LG

TL;DR: 本文综述了用于零样本时间序列预测的基础模型，分析了其架构、预训练策略和优化方法，并研究了微调对特定数据集性能的影响，发现微调能提升零样本预测能力，尤其对长期预测效果显著。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型启发，开发用于零样本时间序列预测的基础模型，旨在通过大规模预训练学习通用表征，减少对任务特定架构和手动调参的依赖。

Method: 综述了主要架构、预训练策略和优化方法，并研究了预训练后微调对特定数据集性能的影响。

Result: 实证结果表明，微调通常能提升零样本预测能力，特别是对长期预测效果更为显著。

Conclusion: 基础模型结合微调策略能有效提升时间序列预测性能，特别是在零样本场景下的长期预测能力。

Abstract: Inspired by recent advances in large language models, foundation models have been developed for zero-shot time series forecasting, enabling prediction on datasets unseen during pretraining. These large-scale models, trained on vast collections of time series, learn generalizable representations for both point and probabilistic forecasting, reducing the need for task-specific architectures and manual tuning.
  In this work, we review the main architectures, pretraining strategies, and optimization methods used in such models, and study the effect of fine-tuning after pretraining to enhance their performance on specific datasets. Our empirical results show that fine-tuning generally improves zero-shot forecasting capabilities, especially for long-term horizons.

</details>


### [215] [Test-time scaling of diffusions with flow maps](https://arxiv.org/abs/2511.22688)
*Amirmojtaba Sabour,Michael S. Albergo,Carles Domingo-Enrich,Nicholas M. Boffi,Sanja Fidler,Karsten Kreis,Eric Vanden-Eijnden*

Main category: cs.LG

TL;DR: 提出FMTT方法，通过流映射直接处理扩散模型测试时优化问题，相比传统基于奖励梯度的方法能更有效地提升样本质量


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型测试时优化方法存在问题：用户指定的奖励函数通常只在生成结束时定义良好，而现有方法使用去噪器估计最终样本存在缺陷

Method: 利用流映射与瞬时传输速度场的关系，构建Flow Map Trajectory Tilting (FMTT)算法，直接处理流映射而非依赖奖励梯度

Result: FMTT在理论上比标准测试时方法能更好地提升奖励，支持精确采样和原则性搜索，能与复杂奖励函数（如视觉语言模型）交互实现新形式的图像编辑

Conclusion: 通过流映射直接处理扩散过程为测试时优化提供了更简单有效的解决方案，特别适用于复杂奖励函数场景，开启了新的图像编辑可能性

Abstract: A common recipe to improve diffusion models at test-time so that samples score highly against a user-specified reward is to introduce the gradient of the reward into the dynamics of the diffusion itself. This procedure is often ill posed, as user-specified rewards are usually only well defined on the data distribution at the end of generation. While common workarounds to this problem are to use a denoiser to estimate what a sample would have been at the end of generation, we propose a simple solution to this problem by working directly with a flow map. By exploiting a relationship between the flow map and velocity field governing the instantaneous transport, we construct an algorithm, Flow Map Trajectory Tilting (FMTT), which provably performs better ascent on the reward than standard test-time methods involving the gradient of the reward. The approach can be used to either perform exact sampling via importance weighting or principled search that identifies local maximizers of the reward-tilted distribution. We demonstrate the efficacy of our approach against other look-ahead techniques, and show how the flow map enables engagement with complicated reward functions that make possible new forms of image editing, e.g. by interfacing with vision language models.

</details>


### [216] [Generative Anchored Fields: Controlled Data Generation via Emergent Velocity Fields and Transport Algebra](https://arxiv.org/abs/2511.22693)
*Deressa Wodajo Deressa,Hannes Mareen,Peter Lambert,Glenn Van Wallendael*

Main category: cs.LG

TL;DR: GAF是一种生成模型，通过分别学习端点预测器J(噪声)和K(数据)而非轨迹预测器，实现可组合控制的生成建模


<details>
  <summary>Details</summary>
Motivation: 传统生成模型缺乏对生成过程的组合性控制能力，无法灵活实现可控插值、混合生成和语义变形等操作

Method: 提出生成锚定场(GAF)，学习独立的端点预测器J(噪声)和K(数据)，通过它们的时变差异产生速度场v=K-J，支持传输代数操作

Result: 在CelebA-HQ 64×64上达到FID 7.5的强样本质量，实现无损循环传输(LPIPS=0.0)，支持可控插值、混合生成和语义变形

Conclusion: GAF将组合生成作为架构原语，通过传输代数实现丰富的可控生成操作，在保持高质量的同时提供强大的组合控制能力

Abstract: We present Generative Anchored Fields (GAF), a generative model that learns independent endpoint predictors $J$ (noise) and $K$ (data) rather than a trajectory predictor. The velocity field $v=K-J$ emerges from their time-conditioned disagreement. This factorization enables \textit{Transport Algebra}: algebraic operation on learned $\{(J_n,K_n)\}_{n=1}^N$ heads for compositional control. With class-specific $K_n$ heads, GAF supports a rich family of directed transport maps between a shared base distribution and multiple modalities, enabling controllable interpolation, hybrid generation, and semantic morphing through vector arithmetic. We achieve strong sample quality (FID 7.5 on CelebA-HQ $64\times 64$) while uniquely providing compositional generation as an architectural primitive. We further demonstrate, GAF has lossless cyclic transport between its initial and final state with LPIPS=$0.0$. Code available at https://github.com/IDLabMedia/GAF

</details>


### [217] [Integrated Transcriptomic-proteomic Biomarker Identification for Radiation Response Prediction in Non-small Cell Lung Cancer Cell Lines](https://arxiv.org/abs/2511.22735)
*Yajun Yu,Guoping Xu,Steve Jiang,Robert Timmerman,John Minna,Yuanyuan Zhang,Hao Peng*

Main category: cs.LG

TL;DR: 开发了一个整合转录组-蛋白质组的框架，用于识别预测非小细胞肺癌细胞系辐射反应（以2Gy生存分数SF2衡量）的并发生物标志物。


<details>
  <summary>Details</summary>
Motivation: 建立首个用于预测NSCLC细胞系辐射反应（SF2）的蛋白质转录组学框架，整合转录组和蛋白质组数据以提高预测准确性并提供机制见解。

Method: 收集73个NSCLC细胞系的RNA-seq数据和46个细胞系的DIA-MS蛋白质组数据，保留1,605个共享基因。使用Lasso回归进行特征选择，采用五折交叉验证重复十次。构建转录组、蛋白质组和整合数据的支持向量回归模型。

Result: RNA-蛋白质表达呈显著正相关（中位Pearson r=0.363）。从三个数据集中识别出20个优先基因特征。单组学模型跨组学泛化能力有限，而整合模型在两个数据集中均表现出平衡的预测准确性（转录组R2=0.461，蛋白质组R2=0.604）。

Conclusion: 该研究提出了首个用于NSCLC SF2预测的蛋白质转录组学框架，强调整合转录组和蛋白质组数据的互补价值。识别的并发生物标志物捕捉了转录调控和功能性蛋白质活性，具有机制见解和转化潜力。

Abstract: To develop an integrated transcriptome-proteome framework for identifying concurrent biomarkers predictive of radiation response, as measured by survival fraction at 2 Gy (SF2), in non-small cell lung cancer (NSCLC) cell lines. RNA sequencing (RNA-seq) and data-independent acquisition mass spectrometry (DIA-MS) proteomic data were collected from 73 and 46 NSCLC cell lines, respectively. Following preprocessing, 1,605 shared genes were retained for analysis. Feature selection was performed using least absolute shrinkage and selection operator (Lasso) regression with a frequency-based ranking criterion under five-fold cross-validation repeated ten times. Support vector regression (SVR) models were constructed using transcriptome-only, proteome-only, and combined transcriptome-proteome feature sets. Model performance was assessed by the coefficient of determination (R2) and root mean square error (RMSE). Correlation analyses evaluated concordance between RNA and protein expression and the relationships of selected biomarkers with SF2. RNA-protein expression exhibited significant positive correlations (median Pearson's r = 0.363). Independent pipelines identified 20 prioritized gene signatures from transcriptomic, proteomic, and combined datasets. Models trained on single-omic features achieved limited cross-omic generalizability, while the combined model demonstrated balanced predictive accuracy in both datasets (R2=0.461, RMSE=0.120 for transcriptome; R2=0.604, RMSE=0.111 for proteome). This study presents the first proteotranscriptomic framework for SF2 prediction in NSCLC, highlighting the complementary value of integrating transcriptomic and proteomic data. The identified concurrent biomarkers capture both transcriptional regulation and functional protein activity, offering mechanistic insights and translational potential.

</details>


### [218] [VeriDispatcher: Multi-Model Dispatching through Pre-Inference Difficulty Prediction for RTL Generation Optimization](https://arxiv.org/abs/2511.22749)
*Zeng Wang,Weihua Xiao,Minghao Shao,Raghu Vamshi Hemadri,Ozgur Sinanoglu,Muhammad Shafique,Ramesh Karri*

Main category: cs.LG

TL;DR: VeriDispatcher是一个多LLM RTL生成框架，通过预推理难度预测将任务分派给合适的LLM，在保持或提高准确性的同时显著降低商业API调用成本。


<details>
  <summary>Details</summary>
Motivation: 不同LLM在RTL生成任务上各有优势，但现有工作主要关注单个模型的提示或微调。如何协调多个不同LLM以共同提高RTL质量并降低成本，而不是运行所有模型并选择最佳输出，这一问题尚未得到充分研究。

Method: 提出VeriDispatcher框架：1）为每个LLM训练紧凑的分类器，基于任务描述的语义嵌入和难度评分；2）难度评分来自结合语法、结构相似性和功能正确性的基准变体；3）在推理时使用这些预测器将任务路由到选定的LLM子集。

Result: 在RTLLM和VerilogEval基准测试中，VeriDispatcher在10个不同LLM上：1）RTLLM上仅使用40%的商业调用实现高达18%的准确率提升；2）VerilogEval上保持准确性的同时减少25%的商业使用。

Conclusion: VeriDispatcher通过智能任务分派实现了成本效益高、高质量的LLM在硬件设计自动化中的部署，解决了多LLM协调问题，在保持性能的同时显著降低计算成本。

Abstract: Large Language Models (LLMs) show strong performance in RTL generation, but different models excel on different tasks because of architecture and training differences. Prior work mainly prompts or finetunes a single model. What remains not well studied is how to coordinate multiple different LLMs so they jointly improve RTL quality while also reducing cost, instead of running all models and choosing the best output. We define this as the multi-LLM RTL generation problem. We propose VeriDispatcher, a multi-LLM RTL generation framework that dispatches each RTL task to suitable LLMs based on pre-inference difficulty prediction. For each model, we train a compact classifier over semantic embeddings of task descriptions, using difficulty scores derived from benchmark variants that combine syntax, structural similarity, and functional correctness. At inference, VeriDispatcher uses these predictors to route tasks to a selected subset of LLMs. Across 10 diverse LLMs on RTLLM and VerilogEval, VeriDispatcher achieves up to 18% accuracy improvement on RTLLM using only 40% of commercial calls, and on VerilogEval maintains accuracy while reducing commercial usage by 25%, enabling cost-effective, high-quality LLM deployment in hardware design automation.

</details>


### [219] [Exact Learning of Arithmetic with Differentiable Agents](https://arxiv.org/abs/2511.22751)
*Hristo Papazov,Francesco D'Angelo,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 提出可微分有限状态转换器（DFSTs），一种图灵完备的模型家族，能够在算术任务上实现强大的长度泛化，通过端到端对数并行可微分训练，在小数据集上训练后能泛化到比训练样本长数千倍的输入。


<details>
  <summary>Details</summary>
Motivation: 探索基于梯度的精确算法学习的可能性，解决现有架构在算术任务长度泛化上的局限性，通过可微分框架实现精确的算法技能学习。

Method: 采用可微分有限状态转换器（DFSTs），利用专家智能体的策略轨迹观察进行训练，支持常数精度、常数时间生成和端到端对数并行可微分训练，应用于二进制和十进制加减乘除运算。

Result: 在极小数据集上训练的模型能够无错误地泛化到比训练样本长数千倍的输入，展示了在算术任务上的强大长度泛化能力。

Conclusion: 在结构化中间监督下训练可微分智能体可能为基于梯度的精确算法技能学习开辟新途径，DFSTs为实现这一目标提供了有前景的框架。

Abstract: We explore the possibility of exact algorithmic learning with gradient-based methods and introduce a differentiable framework capable of strong length generalization on arithmetic tasks. Our approach centers on Differentiable Finite-State Transducers (DFSTs), a Turing-complete model family that avoids the pitfalls of prior architectures by enabling constant-precision, constant-time generation, and end-to-end log-parallel differentiable training. Leveraging policy-trajectory observations from expert agents, we train DFSTs to perform binary and decimal addition and multiplication. Remarkably, models trained on tiny datasets generalize without error to inputs thousands of times longer than the training examples. These results show that training differentiable agents on structured intermediate supervision could pave the way towards exact gradient-based learning of algorithmic skills. Code available at \href{https://github.com/dngfra/differentiable-exact-algorithmic-learner.git}{https://github.com/dngfra/differentiable-exact-algorithmic-learner.git}.

</details>


### [220] [GSpaRC: Gaussian Splatting for Real-time Reconstruction of RF Channels](https://arxiv.org/abs/2511.22793)
*Bhavya Sai Nukapotula,Rishabh Tripathi,Seth Pregler,Dileep Kalathil,Srinivas Shakkottai,Theodore S. Rappaport*

Main category: cs.LG

TL;DR: GSpaRC使用3D高斯基元表示RF环境，通过定制CUDA流水线实现亚毫秒级延迟的实时CSI重建，显著降低训练和推理时间。


<details>
  <summary>Details</summary>
Motivation: 传统CSI获取方法在5G网络中消耗高达25%的频谱资源，且现有重建方法延迟在5-100ms范围，无法满足实时系统需求。

Method: 采用3D高斯基元表示RF环境，每个基元由轻量级神经网络参数化，包含距离衰减等物理特征；使用以接收器为中心的半球面等距柱状投影；定制CUDA流水线实现全并行化处理。

Result: 在多个RF数据集上评估，GSpaRC达到与最新方法相似的CSI重建精度，同时将训练和推理时间降低一个数量级以上，实现亚毫秒级延迟。

Conclusion: GSpaRC通过适度的GPU计算换取显著的导频开销减少，为5G及未来无线系统提供了可扩展、低延迟的信道估计解决方案。

Abstract: Channel state information (CSI) is essential for adaptive beamforming and maintaining robust links in wireless communication systems. However, acquiring CSI incurs significant overhead, consuming up to 25\% of spectrum resources in 5G networks due to frequent pilot transmissions at sub-millisecond intervals. Recent approaches aim to reduce this burden by reconstructing CSI from spatiotemporal RF measurements, such as signal strength and direction-of-arrival. While effective in offline settings, these methods often suffer from inference latencies in the 5--100~ms range, making them impractical for real-time systems. We present GSpaRC: Gaussian Splatting for Real-time Reconstruction of RF Channels, the first algorithm to break the 1 ms latency barrier while maintaining high accuracy. GSpaRC represents the RF environment using a compact set of 3D Gaussian primitives, each parameterized by a lightweight neural model augmented with physics-informed features such as distance-based attenuation. Unlike traditional vision-based splatting pipelines, GSpaRC is tailored for RF reception: it employs an equirectangular projection onto a hemispherical surface centered at the receiver to reflect omnidirectional antenna behavior. A custom CUDA pipeline enables fully parallelized directional sorting, splatting, and rendering across frequency and spatial dimensions. Evaluated on multiple RF datasets, GSpaRC achieves similar CSI reconstruction fidelity to recent state-of-the-art methods while reducing training and inference time by over an order of magnitude. By trading modest GPU computation for a substantial reduction in pilot overhead, GSpaRC enables scalable, low-latency channel estimation suitable for deployment in 5G and future wireless systems. The code is available here: \href{https://github.com/Nbhavyasai/GSpaRC-WirelessGaussianSplatting.git}{GSpaRC}.

</details>


### [221] [Can Synthetic Data Improve Symbolic Regression Extrapolation Performance?](https://arxiv.org/abs/2511.22794)
*Fitria Wulandari Ramlan,Colm O'Riordan,Gabriel Kronberger,James McDermott*

Main category: cs.LG

TL;DR: 该论文研究如何通过添加合成数据来改进符号回归模型在训练数据范围外的外推性能。使用核密度估计识别数据稀疏区域，通过知识蒸馏方法生成合成数据，在六个基准数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 许多机器学习模型在训练数据范围内表现良好，但在需要外推时往往表现不佳。符号回归虽然能生成灵活模型，但在外推时容易出现不可靠行为。研究如何通过合成数据改进外推性能。

Method: 使用核密度估计识别输入空间中训练数据稀疏的区域。采用知识蒸馏方法生成合成数据：教师模型在新输入点上生成预测，然后用这些数据训练学生模型。评估了神经网络、随机森林和遗传编程作为教师和学生模型的效果。

Result: 在六个基准数据集上的实验表明，遗传编程模型在训练合成数据后通常能改进，特别是在外推区域。最显著的改进出现在使用GPe生成的合成数据训练GPp时。插值区域只有轻微变化，观察到模型性能在输入空间不同区域存在异质性误差。

Conclusion: 该方法为改进外推性能提供了实用解决方案，但改进程度取决于数据集和使用的教师模型。合成数据生成策略能有效提升符号回归模型在外推区域的表现。

Abstract: Many machine learning models perform well when making predictions within the training data range, but often struggle when required to extrapolate beyond it. Symbolic regression (SR) using genetic programming (GP) can generate flexible models but is prone to unreliable behaviour in extrapolation. This paper investigates whether adding synthetic data can help improve performance in such cases. We apply Kernel Density Estimation (KDE) to identify regions in the input space where the training data is sparse. Synthetic data is then generated in those regions using a knowledge distillation approach: a teacher model generates predictions on new input points, which are then used to train a student model. We evaluate this method across six benchmark datasets, using neural networks (NN), random forests (RF), and GP both as teacher models (to generate synthetic data) and as student models (trained on the augmented data). Results show that GP models can often improve when trained on synthetic data, especially in extrapolation areas. However, the improvement depends on the dataset and teacher model used. The most important improvements are observed when synthetic data from GPe is used to train GPp in extrapolation regions. Changes in interpolation areas show only slight changes. We also observe heterogeneous errors, where model performance varies across different regions of the input space. Overall, this approach offers a practical solution for better extrapolation. Note: An earlier version of this work appeared in the GECCO 2025 Workshop on Symbolic Regression. This arXiv version corrects several parts of the original submission.

</details>


### [222] [Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence](https://arxiv.org/abs/2511.22813)
*Antoine Salomon*

Main category: cs.LG

TL;DR: INN提出智能神经元网络，每个神经元具有内部状态和选择性通信能力，通过图结构而非层级组织实现计算，在文本建模任务上超越Transformer并匹配LSTM性能。


<details>
  <summary>Details</summary>
Motivation: 受生物神经元智能特性启发：维持内部状态、选择性通信、自组织成复杂图结构而非刚性层级。探索是否能让AI从类似智能计算单元中涌现。

Method: 提出智能神经网络（INN），将神经元作为具有内部记忆和学习通信模式的一等实体，组织成完全图而非顺序层。每个智能神经元结合选择性状态空间动态（知道何时激活）和基于注意力的路由（知道向谁发送信号）。

Result: 在Text8字符建模基准上，INN达到1.705 BPC，显著优于可比较的Transformer（2.055 BPC），匹配高度优化的LSTM基线。参数匹配的堆叠Mamba块基线无法收敛（>3.4 BPC），证明INN的图拓扑提供必要的训练稳定性。消融研究表明移除神经元间通信会降低性能或导致不稳定。

Conclusion: 以神经元为中心的设计与图组织不仅是受生物启发的，而且是计算有效的，为模块化、可解释和可扩展的神经架构开辟了新方向。

Abstract: Biological neurons exhibit remarkable intelligence: they maintain internal states, communicate selectively with other neurons, and self-organize into complex graphs rather than rigid hierarchical layers. What if artificial intelligence could emerge from similarly intelligent computational units? We introduce Intelligent Neural Networks (INN), a paradigm shift where neurons are first-class entities with internal memory and learned communication patterns, organized in complete graphs rather than sequential layers.
  Each Intelligent Neuron combines selective state-space dynamics (knowing when to activate) with attention-based routing (knowing to whom to send signals), enabling emergent computation through graph-structured interactions. On the standard Text8 character modeling benchmark, INN achieves 1.705 Bit-Per-Character (BPC), significantly outperforming a comparable Transformer (2.055 BPC) and matching a highly optimized LSTM baseline. Crucially, a parameter-matched baseline of stacked Mamba blocks fails to converge (>3.4 BPC) under the same training protocol, demonstrating that INN's graph topology provides essential training stability. Ablation studies confirm this: removing inter-neuron communication degrades performance or leads to instability, proving the value of learned neural routing.
  This work demonstrates that neuron-centric design with graph organization is not merely bio-inspired -- it is computationally effective, opening new directions for modular, interpretable, and scalable neural architectures.

</details>


### [223] [A Unified and Stable Risk Minimization Framework for Weakly Supervised Learning with Theoretical Guarantees](https://arxiv.org/abs/2511.22823)
*Miao Zhang,Junpeng Li,Changchun Hua,Yana Yang*

Main category: cs.LG

TL;DR: 提出一个统一的弱监督学习框架，通过直接构建稳定的代理风险来避免后处理调整，涵盖多种监督模式，并建立了理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督学习方法通常针对特定监督模式（如PU、UU、CLL等），依赖后处理校正来缓解间接监督带来的不稳定性，缺乏统一的理论框架。

Method: 提出基于弱监督数据结构的稳定代理风险直接公式化方法，将多种监督设置统一到单一优化目标下，包括PU、UU、CLL、PLL、多类无标签和基于元组的学习。

Result: 建立了基于Rademacher复杂度的非渐近泛化界，分析了类别先验误设的影响，给出了目标风险可恢复性的充分条件，实验显示在类别先验、数据集规模和类别数量方面均有稳定提升。

Conclusion: 该框架为弱监督学习提供了统一的理论基础，避免了启发式稳定化，展示了鲁棒性和泛化性能，为多种弱监督设置提供了系统解决方案。

Abstract: Weakly supervised learning has emerged as a practical alternative to fully supervised learning when complete and accurate labels are costly or infeasible to acquire. However, many existing methods are tailored to specific supervision patterns -- such as positive-unlabeled (PU), unlabeled-unlabeled (UU), complementary-label (CLL), partial-label (PLL), or similarity-unlabeled annotations -- and rely on post-hoc corrections to mitigate instability induced by indirect supervision. We propose a principled, unified framework that bypasses such post-hoc adjustments by directly formulating a stable surrogate risk grounded in the structure of weakly supervised data. The formulation naturally subsumes diverse settings -- including PU, UU, CLL, PLL, multi-class unlabeled, and tuple-based learning -- under a single optimization objective. We further establish a non-asymptotic generalization bound via Rademacher complexity that clarifies how supervision structure, model capacity, and sample size jointly govern performance. Beyond this, we analyze the effect of class-prior misspecification on the bound, deriving explicit terms that quantify its impact, and we study identifiability, giving sufficient conditions -- most notably via supervision stratification across groups -- under which the target risk is recoverable. Extensive experiments show consistent gains across class priors, dataset scales, and class counts -- without heuristic stabilization -- while exhibiting robustness to overfitting.

</details>


### [224] [CausalProfiler: Generating Synthetic Benchmarks for Rigorous and Transparent Evaluation of Causal Machine Learning](https://arxiv.org/abs/2511.22842)
*Panayiotis Panayiotou,Audrey Poinsot,Alessandro Leite,Nicolas Chesneau,Marc Schoenauer,Özgür Şimşek*

Main category: cs.LG

TL;DR: CausalProfiler：首个具有覆盖保证和透明假设的随机因果基准生成器，用于在观察、干预和反事实三个层面评估因果机器学习方法


<details>
  <summary>Details</summary>
Motivation: 当前因果机器学习（Causal ML）的实证评估实践有限，现有基准通常依赖少量手工制作或半合成数据集，导致结论脆弱且不可泛化。需要一种更系统、透明的评估框架。

Method: 提出CausalProfiler，一个因果ML方法的合成基准生成器。基于对因果模型类别、查询和数据集的明确设计选择，随机采样因果模型、数据、查询和真实值，构成合成因果基准。

Result: CausalProfiler是首个在观察、干预和反事实三个因果推理层面运行的随机合成基准生成器，具有覆盖保证和透明假设。通过评估多个最先进方法在不同条件和假设下（包括识别机制内外）展示了其效用。

Conclusion: CausalProfiler为因果ML方法提供了严格、透明的评估框架，能够在多样化条件下生成可重复的基准，填补了现有评估实践的空白，有助于更稳健的因果推理方法开发。

Abstract: Causal machine learning (Causal ML) aims to answer "what if" questions using machine learning algorithms, making it a promising tool for high-stakes decision-making. Yet, empirical evaluation practices in Causal ML remain limited. Existing benchmarks often rely on a handful of hand-crafted or semi-synthetic datasets, leading to brittle, non-generalizable conclusions. To bridge this gap, we introduce CausalProfiler, a synthetic benchmark generator for Causal ML methods. Based on a set of explicit design choices about the class of causal models, queries, and data considered, the CausalProfiler randomly samples causal models, data, queries, and ground truths constituting the synthetic causal benchmarks. In this way, Causal ML methods can be rigorously and transparently evaluated under a variety of conditions. This work offers the first random generator of synthetic causal benchmarks with coverage guarantees and transparent assumptions operating on the three levels of causal reasoning: observation, intervention, and counterfactual. We demonstrate its utility by evaluating several state-of-the-art methods under diverse conditions and assumptions, both in and out of the identification regime, illustrating the types of analyses and insights the CausalProfiler enables.

</details>


### [225] [PerfMamba: Performance Analysis and Pruning of Selective State Space Models](https://arxiv.org/abs/2511.22849)
*Abdullah Al Asif,Mobina Kashaniyan,Sixing Yu,Juan Pablo Muñoz,Ali Jannesari*

Main category: cs.LG

TL;DR: 对Mamba-1和Mamba-2选择性状态空间模型进行系统性能分析，发现SSM组件计算资源消耗大，提出状态剪枝技术实现1.14倍加速和11.50%内存减少。


<details>
  <summary>Details</summary>
Motivation: 选择性状态空间模型（SSMs）作为Transformer的替代方案具有理论计算效率优势，但对其运行时行为、资源利用模式和扩展特性的全面理解仍然不足，阻碍了其优化部署和架构改进。

Method: 对Mamba-1和Mamba-2进行系统性能分析，研究计算模式、内存访问、I/O特性和扩展属性（序列长度64-16384）。基于SSM组件资源消耗大的发现，提出选择性剪除低活动状态的剪枝技术。

Result: SSM组件在Mamba块中消耗大量计算资源；提出的剪枝技术在适度剪枝范围内保持准确性的同时，实现了1.14倍加速和11.50%内存使用减少，在不同序列长度上均获得性能提升。

Conclusion: 该研究为设计更高效的SSM架构提供了有价值的指导，这些架构可广泛应用于实际应用中，通过状态剪枝技术实现了显著的性能改进。

Abstract: Recent advances in sequence modeling have introduced selective SSMs as promising alternatives to Transformer architectures, offering theoretical computational efficiency and sequence processing advantages. A comprehensive understanding of selective SSMs in runtime behavior, resource utilization patterns, and scaling characteristics still remains unexplored, thus obstructing their optimal deployment and further architectural improvements. This paper presents a thorough empirical study of Mamba-1 and Mamba-2, systematically profiled for performance to assess the design principles that contribute to their efficiency in state-space modeling. A detailed analysis of computation patterns, memory access, I/O characteristics, and scaling properties was performed for sequence lengths ranging from 64 to 16384 tokens. Our findings show that the SSM component, a central part of the selective SSM architecture, demands a significant portion of computational resources compared to other components in the Mamba block. Based on these insights, we propose a pruning technique that selectively removes low-activity states within the SSM component, achieving measurable throughput and memory gains while maintaining accuracy within a moderate pruning regime. This approach results in performance improvements across varying sequence lengths, achieving a 1.14x speedup and reducing memory usage by 11.50\%. These results offer valuable guidance for designing more efficient SSM architectures that can be applied to a wide range of real-world applications.

</details>


### [226] [TARFVAE: Efficient One-Step Generative Time Series Forecasting via TARFLOW based VAE](https://arxiv.org/abs/2511.22853)
*Jiawen Wei,Lan Jiang,Pengbo Wei,Ziwen Ye,Teng Song,Chen Chen,Guangrui Ma*

Main category: cs.LG

TL;DR: TARFVAE：结合Transformer自回归流和变分自编码器的高效一步生成式时间序列预测框架，在保持快速预测的同时超越现有确定性方法和生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有生成式时间序列预测方法大多采用循环生成操作或重复去噪步骤，预测过程繁琐，尤其不适合长期预测。这些方法通常只在短期预测上进行实验，与确定性方法在长期预测上的比较有限，实际优势不明确。

Method: 提出TARFVAE框架，结合Transformer自回归流（TARFLOW）和变分自编码器（VAE）。TARFLOW模块增强VAE的后验估计，打破高斯假设，学习对预测有益的潜在变量。仅使用TARFLOW的前向过程，避免自回归逆操作，实现快速生成。采样时从先验潜在空间采样，通过VAE解码器直接生成完整预测序列。

Result: TARFVAE在基准数据集上，在不同预测时间范围内均优于最先进的确定性和生成模型，同时保持高效的预测速度。使用简单的MLP模块即可实现优越性能。

Conclusion: TARFVAE为生成式时间序列预测提供了一个高效且强大的解决方案，通过结合TARFLOW和VAE，实现了快速的一步生成预测，在性能和效率上都表现出色。

Abstract: Time series data is ubiquitous, with forecasting applications spanning from finance to healthcare. Beyond popular deterministic methods, generative models are gaining attention due to advancements in areas like image synthesis and video generation, as well as their inherent ability to provide probabilistic predictions. However, existing generative approaches mostly involve recurrent generative operations or repeated denoising steps, making the prediction laborious, particularly for long-term forecasting. Most of them only conduct experiments for relatively short-term forecasting, with limited comparison to deterministic methods in long-term forecasting, leaving their practical advantages unclear. This paper presents TARFVAE, a novel generative framework that combines the Transformer-based autoregressive flow (TARFLOW) and variational autoencoder (VAE) for efficient one-step generative time series forecasting. Inspired by the rethinking that complex architectures for extracting time series representations might not be necessary, we add a flow module, TARFLOW, to VAE to promote spontaneous learning of latent variables that benefit predictions. TARFLOW enhances VAE's posterior estimation by breaking the Gaussian assumption, thereby enabling a more informative latent space. TARFVAE uses only the forward process of TARFLOW, avoiding autoregressive inverse operations and thus ensuring fast generation. During generation, it samples from the prior latent space and directly generates full-horizon forecasts via the VAE decoder. With simple MLP modules, TARFVAE achieves superior performance over state-of-the-art deterministic and generative models across different forecast horizons on benchmark datasets while maintaining efficient prediction speed, demonstrating its effectiveness as an efficient and powerful solution for generative time series forecasting.

</details>


### [227] [CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate](https://arxiv.org/abs/2511.22854)
*Finn G. Vamosi,Nils D. Forkert*

Main category: cs.LG

TL;DR: 提出双智能体辩论框架，让一个模型进行因果推理，另一个模型批判性审查，通过辩论提升因果推理准确性


<details>
  <summary>Details</summary>
Motivation: 人类因果推理常考虑多种"如果"场景，类似地，语言模型可通过多智能体辩论模拟这种内部对话，提升因果推理的准确性和鲁棒性

Method: 使用双智能体辩论框架：一个模型提供结构化因果推理，另一个模型批判性审查逻辑缺陷；当出现分歧时，智能体尝试说服对方，挑战对方逻辑并修订结论直至达成共识

Result: 在CLadder数据集上，DeepSeek-R1整体准确率从78.03%提升至87.45%，反事实类别从67.94%提升至80.04%；Qwen3整体准确率从84.16%提升至89.41%，反事实问题从71.53%提升至80.35%

Conclusion: 多智能体辩论显著提升因果推理准确性，即使强模型也能从与弱模型的辩论中获益；推理模型可作为因果推理多智能体系统的构建模块，多样视角对因果问题解决至关重要

Abstract: When people reason about cause and effect, they often consider many competing "what if" scenarios before deciding which explanation fits best. Analogously, advanced language models capable of causal inference can consider multiple interventions and counterfactuals to judge the validity of causal claims. Crucially, this type of reasoning is less like a single calculation and more like an internal dialogue between alternative hypotheses. In this paper, we make this dialogue explicit through a dual-agent debate framework where one model provides a structured causal inference, and the other critically examines this reasoning for logical flaws. When disagreements arise, agents attempt to persuade each other, challenging each other's logic and revising their conclusions until they converge on a mutually agreed answer. To take advantage of this deliberative process, we specifically use reasoning language models, whose strengths in both causal inference and adversarial debate remain under-explored relative to standard large language models. We evaluate our approach on the CLadder dataset, a benchmark linking natural language questions to formally defined causal graphs across all three rungs of Pearl's ladder of causation. With Qwen3 and DeepSeek-R1 as debater agents, we demonstrate that multi-agent debate improves DeepSeek-R1's overall accuracy in causal inference from 78.03% to 87.45%, with the counterfactual category specifically improving from 67.94% to 80.04% accuracy. Similarly, Qwen3's overall accuracy improves from 84.16% to 89.41%, and counterfactual questions from 71.53% to 80.35%, showing that strong models can still benefit greatly from debate with weaker agents. Our results highlight the potential of reasoning models as building blocks for multi-agent systems in causal inference, and demonstrate the importance of diverse perspectives in causal problem-solving.

</details>


### [228] [Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation](https://arxiv.org/abs/2511.22862)
*Jiacheng Li,Songhe Feng*

Main category: cs.LG

TL;DR: BriMPR是一个多模态测试时适应框架，通过渐进式重对齐解决多模态分布偏移问题，包含单模态特征对齐和跨模态对比学习两个模块。


<details>
  <summary>Details</summary>
Motivation: 在多模态场景中，不同模态的分布偏移程度不同，导致单模态浅层特征偏移和跨模态高层语义错位的复杂耦合效应，这阻碍了现有TTA方法向多模态领域的扩展。

Method: 提出BriMPR框架，采用分而治之策略：1) 将MMTTA分解为多个单模态特征对齐子问题，利用提示调优校准单模态全局特征分布；2) 为掩码和完整模态组合分配可信伪标签，引入跨模态实例级对比学习增强模态间信息交互。

Result: 在包括基于损坏和真实世界域偏移基准的MMTTA任务上进行广泛实验，证明了该方法的优越性。

Conclusion: BriMPR通过渐进式重对齐有效解决了多模态测试时适应中的复杂耦合效应，为多模态TTA提供了有效解决方案。

Abstract: Test-time adaptation (TTA) enables online model adaptation using only unlabeled test data, aiming to bridge the gap between source and target distributions. However, in multimodal scenarios, varying degrees of distribution shift across different modalities give rise to a complex coupling effect of unimodal shallow feature shift and cross-modal high-level semantic misalignment, posing a major obstacle to extending existing TTA methods to the multimodal field. To address this challenge, we propose a novel multimodal test-time adaptation (MMTTA) framework, termed as Bridging Modalities via Progressive Re-alignment (BriMPR). BriMPR, consisting of two progressively enhanced modules, tackles the coupling effect with a divide-and-conquer strategy. Specifically, we first decompose MMTTA into multiple unimodal feature alignment sub-problems. By leveraging the strong function approximation ability of prompt tuning, we calibrate the unimodal global feature distributions to their respective source distributions, so as to achieve the initial semantic re-alignment across modalities. Subsequently, we assign the credible pseudo-labels to combinations of masked and complete modalities, and introduce inter-modal instance-wise contrastive learning to further enhance the information interaction among modalities and refine the alignment. Extensive experiments on MMTTA tasks, including both corruption-based and real-world domain shift benchmarks, demonstrate the superiority of our method. Our source code is available at [this URL](https://github.com/Luchicken/BriMPR).

</details>


### [229] [ARM-Explainer -- Explaining and improving graph neural network predictions for the maximum clique problem using node features and association rule mining](https://arxiv.org/abs/2511.22866)
*Bharat Sharman,Elkafi Hassini*

Main category: cs.LG

TL;DR: ARM-Explainer是一种基于关联规则挖掘的后处理模型级解释器，用于解释图神经网络在最大团问题上的预测，并能通过识别重要节点特征提升GNN性能。


<details>
  <summary>Details</summary>
Motivation: 尽管已有许多基于图神经网络的组合优化问题求解算法，但这些模型的预测解释方法仍然缺乏开发。需要一种能够解释GNN在组合优化问题中预测的方法。

Method: 提出ARM-Explainer，一种基于关联规则挖掘的后处理模型级解释器。该方法应用于混合几何散射GNN在最大团问题上的预测，从TWITTER和BHOSLIB-DIMACS基准数据集中发现最具解释性的关联规则。

Result: ARM-Explainer发现的八个最具解释性的关联规则在测试实例上获得了中位提升度2.42和置信度0.49。识别了影响GNN预测的最重要节点特征及其值范围。通过增强信息性节点特征，GNN在BHOSLIB-DIMACS数据集上的最大团大小中位数提升了22%（从29.5到36）。

Conclusion: ARM-Explainer能够有效解释GNN在组合优化问题中的预测，并且通过识别重要特征可以显著提升GNN性能，为图神经网络的可解释性提供了实用工具。

Abstract: Numerous graph neural network (GNN)-based algorithms have been proposed to solve graph-based combinatorial optimization problems (COPs), but methods to explain their predictions remain largely undeveloped. We introduce ARM-Explainer, a post-hoc, model-level explainer based on association rule mining, and demonstrate it on the predictions of the hybrid geometric scattering (HGS) GNN for the maximum clique problem (MCP), a canonical NP-hard graph-based COP. The eight most explanatory association rules discovered by ARM-Explainer achieve high median lift and confidence values of 2.42 and 0.49, respectively, on test instances from the TWITTER and BHOSLIB-DIMACS benchmark datasets. ARM-Explainer identifies the most important node features, together with their value ranges, that influence the GNN's predictions on these datasets. Furthermore, augmenting the GNN with informative node features substantially improves its performance on the MCP, increasing the median largest-found clique size by 22% (from 29.5 to 36) on large graphs from the BHOSLIB-DIMACS dataset.

</details>


### [230] [Covering-Space Normalizing Flows: Approximating Pushforwards on Lens Spaces](https://arxiv.org/abs/2511.22882)
*William Ghanem*

Main category: cs.LG

TL;DR: 通过S^3到L(p;q)的通用覆盖映射构造推前分布，并用流来近似这些分布，特别处理对称S^3分布中的冗余问题


<details>
  <summary>Details</summary>
Motivation: 研究如何通过通用覆盖映射在透镜空间L(p;q)上构造推前分布，并开发有效的方法来近似这些分布，特别关注对称分布情况下的冗余消除问题

Method: 使用通用覆盖映射ρ: S^3 → L(p;q)构造推前分布，通过流在L(p;q)上近似这些分布，特别设计了删除对称S^3分布中冗余的方法

Result: 成功近似了von Mises-Fisher诱导的目标密度推前分布，以及为模拟苯分子构建的Z_12对称玻尔兹曼分布在S^3上的推前分布

Conclusion: 该方法能有效构造和近似透镜空间上的推前分布，特别在处理对称分布时能成功删除冗余，为复杂几何空间上的概率分布建模提供了有效工具

Abstract: We construct pushforward distributions via the universal covering map rho: S^3 -> L(p;q) with the goal of approximating these distributions using flows on L(p;q). We highlight that our method deletes redundancies in the case of a symmetric S^3 distribution. Using our model, we approximate the pushforwards of von Mises-Fisher-induced target densities as well as that of a Z_12-symmetric Boltzmann distribution on S^3 constructed to model benzene.

</details>


### [231] [Modeling Chaotic Pedestrian Behavior Using Chaos Indicators and Supervised Learning](https://arxiv.org/abs/2511.22887)
*Md. Muhtashim Shahrier,Nazmul Haque,Md Asif Raihan,Md. Hadiuzzaman*

Main category: cs.LG

TL;DR: 该研究提出一个数据驱动框架，使用监督学习建模行人混沌运动，通过计算机视觉提取轨迹，用混沌指标量化行为，PCA整合为统一混沌分数，CatBoost模型预测效果优异，SHAP分析识别关键特征，可用于城市规划与自动驾驶风险评估。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市致力于提高步行性和安全性，理解行人行为的不规则和不可预测性变得日益重要。当前需要一种能够量化行人混沌运动的方法，以帮助城市规划者和工程师识别高风险区域、改进基础设施，并为自动驾驶系统提供适应性风险评估。

Method: 1) 在白天和夜间条件下录制视频捕捉行人动态；2) 使用计算机视觉技术提取行人轨迹；3) 用四个混沌指标（速度和方向变化的近似熵和李雅普诺夫指数）量化行为混沌；4) 应用主成分分析（PCA）将这些指标整合为统一混沌分数；5) 构建个体、群体和交通环境特征集；6) 训练随机森林和CatBoost回归模型；7) 使用SHAP分析识别关键特征。

Result: CatBoost模型表现最佳：白天PCA-based CatBoost模型的R²达到0.8319，夜间PCA-based CatBoost模型的R²达到0.8574。SHAP分析显示，行程距离、运动持续时间和速度变异性是混沌行为的稳健预测因子。该框架能够有效量化和预测现实环境中的行为不稳定性。

Conclusion: 该研究提出的数据驱动框架能够有效建模行人混沌运动，为城市规划者提供量化工具识别高风险行人区域、指导基础设施改进，并为自动驾驶系统提供基于可观测、可解释特征的短期运动不可预测性评估，支持适应性风险评估。

Abstract: As cities around the world aim to improve walkability and safety, understanding the irregular and unpredictable nature of pedestrian behavior has become increasingly important. This study introduces a data-driven framework for modeling chaotic pedestrian movement using empirically observed trajectory data and supervised learning. Videos were recorded during both daytime and nighttime conditions to capture pedestrian dynamics under varying ambient and traffic contexts. Pedestrian trajectories were extracted through computer vision techniques, and behavioral chaos was quantified using four chaos metrics: Approximate Entropy and Lyapunov Exponent, each computed for both velocity and direction change. A Principal Component Analysis (PCA) was then applied to consolidate these indicators into a unified chaos score. A comprehensive set of individual, group-level, and contextual traffic features was engineered and used to train Random Forest and CatBoost regression models. CatBoost models consistently achieved superior performance. The best daytime PCA-based CatBoost model reached an R^2 of 0.8319, while the nighttime PCA-based CatBoost model attained an R^2 of 0.8574. SHAP analysis highlighted that features such as distance travel, movement duration, and speed variability were robust contributors to chaotic behavior. The proposed framework enables practitioners to quantify and anticipate behavioral instability in real-world settings. Planners and engineers can use chaos scores to identify high-risk pedestrian zones, apprise infrastructure improvements, and calibrate realistic microsimulation models. The approach also supports adaptive risk assessment in automated vehicle systems by capturing short-term motion unpredictability grounded in observable, interpretable features.

</details>


### [232] [Adversarial Training for Process Reward Models](https://arxiv.org/abs/2511.22888)
*Gurusha Juneja,Deepak Nathani,William Yang Wang*

Main category: cs.LG

TL;DR: APRM通过对抗训练提升过程奖励模型的鲁棒性，无需人工标注步骤级标签，在数学推理任务上显著提升求解器准确率


<details>
  <summary>Details</summary>
Motivation: 传统过程奖励模型（PRMs）面临两个主要限制：1）需要昂贵的步骤级人工标注；2）静态训练数据对新错误的泛化能力差。这限制了PRMs的广泛应用。

Method: 提出对抗训练的过程奖励模型（APRM），包含生成器（G）和判别器（R）。G学习生成欺骗R的推理错误，R学习检测这些错误。这种对抗交互为R提供逐步变难的负样本，提升其鲁棒性和对新错误的泛化能力，无需人工步骤级标注。

Result: 在多个数学推理基准测试中，APRM平均比最强的PRM基线提升求解器准确率+3.4个百分点。在分布外任务上获得+5.3个百分点的提升。

Conclusion: 对抗训练是提升过程奖励模型鲁棒性和泛化能力的有效方法，能够在不依赖昂贵人工标注的情况下，显著提高推理任务的性能。

Abstract: Process Reward Models (PRMs) enhance reasoning ability of LLMs by providing step-level supervision. However, their widespread adoption is limited due to expensive manual step-level annotation and poor generalization of static training data to novel errors. We introduce Adversarially Trained PRMs (\texttt{APRM}), where a Generator ($G$) learns to produce reasoning errors to deceive a PRM ($R$), while $R$ concurrently learns to detect them. This interaction yields progressively harder negatives for $R$, improving its robustness and generalization to novel errors without requiring manual step-level labels. Averaged across diverse mathematical reasoning benchmarks, \texttt{APRM} improves solver accuracy by $+3.4$ percentage points (pp) over the strongest PRM baseline. \texttt{APRM} achieves gains of $+5.3$ pp on out-of-distribution tasks.

</details>


### [233] [EnECG: Efficient Ensemble Learning for Electrocardiogram Multi-task Foundation Model](https://arxiv.org/abs/2511.22935)
*Yuhao Xu,Xiaoda Wang,Jiaying Lu,Sirui Ding,Defu Cao,Huaxiu Yao,Yan Liu,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 提出EnECG框架，通过集成多个专业基础模型和轻量级适应策略，高效处理多任务ECG分析，降低计算成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有ECG分析模型未能充分利用各种心脏异常之间的关联性，而开发能提取所有相关特征的多任务模型又很困难。大规模基础模型通常未在ECG数据上预训练，完全重新训练或微调计算成本过高。

Method: 提出EnECG框架：1) 集成多个在ECG解释不同方面表现优异的专业基础模型；2) 采用轻量级适应策略，为每个基础模型附加专用输出层，仅对新参数应用低秩适应(LoRA)；3) 使用混合专家(MoE)机制学习集成权重，有效结合各模型的互补专业知识。

Result: 实验结果表明，通过最小化微调范围，EnECG能帮助降低计算和内存成本，同时保持基础模型的强大表示能力。该框架不仅增强了特征提取和预测性能，还确保了实际临床应用的效率。

Conclusion: EnECG框架通过集成多个专业基础模型和轻量级适应策略，为ECG多任务分析提供了一种高效实用的解决方案，在降低计算成本的同时保持了性能优势，适合实际临床应用。

Abstract: Electrocardiogram (ECG) analysis plays a vital role in the early detection, monitoring, and management of various cardiovascular conditions. While existing models have achieved notable success in ECG interpretation, they fail to leverage the interrelated nature of various cardiac abnormalities. Conversely, developing a specific model capable of extracting all relevant features for multiple ECG tasks remains a significant challenge. Large-scale foundation models, though powerful, are not typically pretrained on ECG data, making full re-training or fine-tuning computationally expensive. To address these challenges, we propose EnECG(Mixture of Experts-based Ensemble Learning for ECG Multi-tasks), an ensemble-based framework that integrates multiple specialized foundation models, each excelling in different aspects of ECG interpretation. Instead of relying on a single model or single task, EnECG leverages the strengths of multiple specialized models to tackle a variety of ECG-based tasks. To mitigate the high computational cost of full re-training or fine-tuning, we introduce a lightweight adaptation strategy: attaching dedicated output layers to each foundation model and applying Low-Rank Adaptation (LoRA) only to these newly added parameters. We then adopt a Mixture of Experts (MoE) mechanism to learn ensemble weights, effectively combining the complementary expertise of individual models. Our experimental results demonstrate that by minimizing the scope of fine-tuning, EnECG can help reduce computational and memory costs while maintaining the strong representational power of foundation models. This framework not only enhances feature extraction and predictive performance but also ensures practical efficiency for real-world clinical applications. The code is available at https://github.com/yuhaoxu99/EnECG.git.

</details>


### [234] [CORGI: GNNs with Convolutional Residual Global Interactions for Lagrangian Simulation](https://arxiv.org/abs/2511.22938)
*Ethan Ji,Yuanzhou Chen,Arush Ramteke,Fang Sun,Tianrun Yu,Jai Parera,Wei Wang,Yizhou Sun*

Main category: cs.LG

TL;DR: CORGI：一种混合架构，通过添加轻量级欧拉组件来增强基于GNN的流体求解器，以捕获全局相互作用，显著提高精度而计算开销很小。


<details>
  <summary>Details</summary>
Motivation: 传统PDE求解器在处理非线性流体动力学问题时计算成本高，而现有的拉格朗日神经网络代理（如GNS和SEGNN）由于感受野有限，难以捕捉流体流动中固有的全局相互作用。

Method: 提出卷积残差全局交互（CORGI）混合架构：将粒子特征投影到网格上，应用卷积更新捕获全局上下文，然后映射回粒子域，从而增强任何基于GNN的求解器。

Result: 在GNS骨干网络上，CORGI将推演精度提高57%，推理时间仅增加13%，训练时间增加31%；相比SEGNN，精度提高49%，推理时间减少48%，训练时间减少30%；在相同运行时约束下，平均比GNS好47%。

Conclusion: CORGI通过轻量级的欧拉组件有效捕获长程依赖关系，显著提升了基于GNN的流体求解器的精度，在不同计算预算下都表现出优异的性能和通用性。

Abstract: Partial differential equations (PDEs) are central to dynamical systems modeling, particularly in hydrodynamics, where traditional solvers often struggle with nonlinearity and computational cost. Lagrangian neural surrogates such as GNS and SEGNN have emerged as strong alternatives by learning from particle-based simulations. However, these models typically operate with limited receptive fields, making them inaccurate for capturing the inherently global interactions in fluid flows. Motivated by this observation, we introduce Convolutional Residual Global Interactions (CORGI), a hybrid architecture that augments any GNN-based solver with a lightweight Eulerian component for global context aggregation. By projecting particle features onto a grid, applying convolutional updates, and mapping them back to the particle domain, CORGI captures long-range dependencies without significant overhead. When applied to a GNS backbone, CORGI achieves a 57% improvement in rollout accuracy with only 13% more inference time and 31% more training time. Compared to SEGNN, CORGI improves accuracy by 49% while reducing inference time by 48% and training time by 30%. Even under identical runtime constraints, CORGI outperforms GNS by 47% on average, highlighting its versatility and performance on varied compute budgets.

</details>


### [235] [Bandit Guided Submodular Curriculum for Adaptive Subset Selection](https://arxiv.org/abs/2511.22944)
*Prateek Chanda,Prayas Agrawal,Saral Sureka,Lokesh Reddy Polu,Atharv Kshirsagar,Ganesh Ramakrishnan*

Main category: cs.LG

TL;DR: 提出ONLINESUBMOD方法，将自适应子集选择重新定义为多臂老虎机问题，每个臂对应引导样本选择的子模函数，通过在线贪心策略优化效用驱动的奖励，在多种采样机制下实现无遗憾性能。


<details>
  <summary>Details</summary>
Motivation: 传统课程学习从简单到困难样本进行，但定义可靠的难度概念仍然困难。先前工作使用子模函数在课程学习中诱导难度分数，但需要更系统的方法来指导课程安排。

Method: 将自适应子集选择重新表述为多臂老虎机问题，每个臂对应一个引导样本选择的子模函数。提出ONLINESUBMOD在线贪心策略，优化效用驱动的奖励，在多种采样机制下实现无遗憾性能。

Result: ONLINESUBMOD在视觉和语言数据集上优于传统课程学习和双层优化方法，显示出更优的准确率-效率权衡。验证驱动的奖励指标为课程安排提供了原则性指导。

Conclusion: 将课程学习重新定义为多臂老虎机问题，并引入ONLINESUBMOD在线贪心策略，为自适应样本选择提供了理论保证和实证优势。验证驱动的奖励指标为课程安排提供了原则性方法。

Abstract: Traditional curriculum learning proceeds from easy to hard samples, yet defining a reliable notion of difficulty remains elusive. Prior work has used submodular functions to induce difficulty scores in curriculum learning. We reinterpret adaptive subset selection and formulate it as a multi-armed bandit problem, where each arm corresponds to a submodular function guiding sample selection. We introduce ONLINESUBMOD, a novel online greedy policy that optimizes a utility-driven reward and provably achieves no-regret performance under various sampling regimes. Empirically, ONLINESUBMOD outperforms both traditional curriculum learning and bi-level optimization approaches across vision and language datasets, showing superior accuracy-efficiency tradeoffs. More broadly, we show that validationdriven reward metrics offer a principled way to guide the curriculum schedule.

</details>


### [236] [Experts are all you need: A Composable Framework for Large Language Model Inference](https://arxiv.org/abs/2511.22955)
*Shrihari Sridharan,Sourjya Roy,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: Comp-LLM提出可组合推理框架，通过子查询依赖图实现专家协作，在保持性能的同时减小模型规模并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：MoE模型需要联合预训练且不支持多步推理，多智能体框架依赖顺序循环导致高延迟。需要一种既能实现专家协作又能降低延迟的推理框架。

Method: Comp-LLM包含三个组件：1) 子查询生成器分解输入查询，基于嵌入相似度分配专家，构建依赖图；2) 查询执行器处理图节点，基于依赖和资源约束识别并行机会；3) 响应聚合器合成专家响应为最终答案。

Result: 在多个基准测试中，Comp-LLM相比相似规模单体LLM准确率提升达11.01%，模型大小减少1.67-3.56倍，相对于最大模型无显著性能下降，延迟比顺序处理提升1.1-1.7倍。

Conclusion: Comp-LLM通过可组合推理框架有效解决了MoE和多智能体框架的局限性，在保持性能的同时实现了模型规模压缩和推理延迟降低。

Abstract: Large Language Models (LLMs) have achieved state-of-the-art accuracies in a variety of natural language processing (NLP) tasks. However, this success comes at the cost of increased model sizes which leads to additional computational burden. Mixture of Experts (MoEs) overcome this bottleneck by decoupling model capacity from computation by only activating a subset of parameters or "experts". However, these models require joint pretraining of these experts along with the router and do not model multi-step reasoning. In contrast, multi-agent frameworks improve reasoning by decomposing complex problems into modular subtasks. However, these frameworks rely on sequential "plan--act--observe" loops, which introduce significant latency. Our work, Comp-LLM, addresses these challenges by introducing a composable inference framework that enables cross-expert collaboration via an explicit sub-query dependency graph. Comp-LLM consists of three components: (1) A Sub-query Generator that decomposes an input query, assigns each sub-query to an appropriate expert using embedding similarity, and constructs a dependency graph; (2) A Query Executor that processes nodes in the graph and identifies opportunities for parallelism based on dependencies and resource constraints; and (3) A Response Aggregator that synthesizes intermediate expert responses into a coherent final answer. Across several benchmarks, Comp-LLM achieves up to 11.01% accuracy improvement over monolithic LLMs of similar size, while offering 1.67x--3.56x reduction in model size with no significant degradation relative to the largest model in its family. Additionally, Comp-LLM provides 1.1x--1.7x latency improvement compared to sequential sub-query processing.

</details>


### [237] [A Trainable Centrality Framework for Modern Data](https://arxiv.org/abs/2511.22959)
*Minh Duc Vu,Mingshuo Liu,Doudou Zhou*

Main category: cs.LG

TL;DR: FUSE是一个神经中心性框架，通过全局和局部头的组合，在任意数据表示上计算中心性分数，实现高效的多尺度几何结构分析


<details>
  <summary>Details</summary>
Motivation: 传统深度概念在高维空间中计算昂贵且不稳定，难以扩展到非欧几里得数据，需要一种能处理任意表示的通用中心性度量方法

Method: FUSE结合全局头（基于成对距离比较学习无锚点中心性分数）和局部头（通过去噪分数匹配近似平滑对数密度势），通过单一参数在0-1之间插值这两种校准信号

Result: 在合成分布、真实图像、时间序列、文本数据和标准异常检测基准上，FUSE恢复了有意义的经典排序，揭示了多尺度几何结构，性能与强经典基线相当，同时保持简单高效

Conclusion: FUSE提供了一个灵活高效的神经框架，用于在各种数据表示上计算中心性，解决了传统深度方法在高维和非欧几里得数据中的局限性

Abstract: Measuring how central or typical a data point is underpins robust estimation, ranking, and outlier detection, but classical depth notions become expensive and unstable in high dimensions and are hard to extend beyond Euclidean data. We introduce Fused Unified centrality Score Estimation (FUSE), a neural centrality framework that operates on top of arbitrary representations. FUSE combines a global head, trained from pairwise distance-based comparisons to learn an anchor-free centrality score, with a local head, trained by denoising score matching to approximate a smoothed log-density potential. A single parameter between 0 and 1 interpolates between these calibrated signals, yielding depth-like centrality from different views via one forward pass. Across synthetic distributions, real images, time series, and text data, and standard outlier detection benchmarks, FUSE recovers meaningful classical ordering, reveals multi-scale geometric structures, and attains competitive performance with strong classical baselines while remaining simple and efficient.

</details>


### [238] [A Modular Framework for Rapidly Building Intrusion Predictors](https://arxiv.org/abs/2511.23000)
*Xiaoxuan Wang,Rolf Stadler*

Main category: cs.LG

TL;DR: 提出模块化框架，通过可复用组件快速组装在线攻击预测器，解决传统单一预测器无法应对多种攻击类型的问题


<details>
  <summary>Details</summary>
Motivation: 现有攻击预测器通常针对特定攻击类型构建单一预测器，而MITRE框架包含数百种攻击类型，为每种类型训练单独的预测器不可行

Method: 提出模块化框架，使用可复用组件快速组装在线攻击预测器，支持动态调整预测及时性和准确性之间的权衡

Result: 使用公开数据集训练和评估，展示了多个模块化预测器示例，证明可以在训练期间从模块化组件网络中动态组装有效预测器

Conclusion: 模块化框架能够高效应对多种攻击类型，通过可复用组件快速构建在线攻击预测器，并灵活控制预测性能指标

Abstract: We study automated intrusion prediction in an IT system using statistical learning methods. The focus is on developing online attack predictors that detect attacks in real time and identify the current stage of the attack. While such predictors have been proposed in the recent literature, these works typically rely on constructing a monolithic predictor tailored to a specific attack type and scenario. Given that hundreds of attack types are cataloged in the MITRE framework, training a separate monolithic predictor for each of them is infeasible. In this paper, we propose a modular framework for rapidly assembling online attack predictors from reusable components. The modular nature of a predictor facilitates controlling key metrics like timeliness and accuracy of prediction, as well as tuning the trade-off between them. Using public datasets for training and evaluation, we provide many examples of modular predictors and show how an effective predictor can be dynamically assembled during training from a network of modular components.

</details>


### [239] [Masked Diffusion for Generative Recommendation](https://arxiv.org/abs/2511.23021)
*Kulin Shah,Bhuvesh Kumar,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 本文提出使用掩码扩散模型替代自回归模型进行生成式推荐，通过并行解码提升推理效率，在数据受限和粗粒度召回场景中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义ID的自回归生成推荐模型存在推理成本高、训练数据利用效率低、偏向学习短上下文关系等问题。受NLP领域突破启发，作者希望用掩码扩散模型解决这些问题。

Method: 提出使用掩码扩散模型来建模用户语义ID序列的概率分布。该方法采用离散掩码噪声学习序列分布，将掩码token的概率建模为在未掩码token条件下的独立分布，从而实现并行解码。

Result: 实验表明，该方法在各项指标上均优于自回归模型，特别是在数据受限场景和粗粒度召回任务中表现优势明显。同时保持了并行预测多个语义ID的灵活性。

Conclusion: 掩码扩散模型为生成式推荐提供了更高效的替代方案，解决了自回归模型的推理效率和数据利用问题，在多种场景下展现出优越性能。

Abstract: Generative recommendation (GR) with semantic IDs (SIDs) has emerged as a promising alternative to traditional recommendation approaches due to its performance gains, capitalization on semantic information provided through language model embeddings, and inference and storage efficiency. Existing GR with SIDs works frame the probability of a sequence of SIDs corresponding to a user's interaction history using autoregressive modeling. While this has led to impressive next item prediction performances in certain settings, these autoregressive GR with SIDs models suffer from expensive inference due to sequential token-wise decoding, potentially inefficient use of training data and bias towards learning short-context relationships among tokens. Inspired by recent breakthroughs in NLP, we propose to instead model and learn the probability of a user's sequence of SIDs using masked diffusion. Masked diffusion employs discrete masking noise to facilitate learning the sequence distribution, and models the probability of masked tokens as conditionally independent given the unmasked tokens, allowing for parallel decoding of the masked tokens. We demonstrate through thorough experiments that our proposed method consistently outperforms autoregressive modeling. This performance gap is especially pronounced in data-constrained settings and in terms of coarse-grained recall, consistent with our intuitions. Moreover, our approach allows the flexibility of predicting multiple SIDs in parallel during inference while maintaining superior performance to autoregressive modeling.

</details>


### [240] [Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring](https://arxiv.org/abs/2511.23036)
*Changhun Kim,Yechan Mun,Hyeongwon Jang,Eunseo Lee,Sangchul Hahn,Eunho Yang*

Main category: cs.LG

TL;DR: Delta-XAI提出了一种在线时间序列监控模型解释框架，通过包装函数适配14种现有XAI方法，并引入系统性评估套件，同时提出了SWING方法以更好地捕捉时间依赖性。


<details>
  <summary>Details</summary>
Motivation: 在医疗和金融等敏感领域，在线时间序列监控模型的解释至关重要。现有XAI方法大多独立分析每个时间步，忽略了时间依赖性，导致解释预测变化困难、无法利用在线动态、评估困难等问题。

Method: 1) 提出Delta-XAI框架，通过包装函数适配14种现有XAI方法；2) 引入原则性的在线设置评估套件，评估忠实性、充分性、连贯性等多个方面；3) 基于实验结果提出SWING方法，通过整合路径中包含过去观测来系统捕捉时间依赖性并缓解分布外效应。

Result: 实验表明，经典梯度方法（如Integrated Gradients）在适配时间分析后可以超越最新方法。SWING方法在各种设置和多种指标下都表现出持续的有效性。

Conclusion: Delta-XAI解决了在线时间序列解释的关键挑战，SWING方法通过有效捕捉时间依赖性显著提升了解释质量，为敏感领域的决策提供了更可靠的时间序列模型解释。

Abstract: Explaining online time series monitoring models is crucial across sensitive domains such as healthcare and finance, where temporal and contextual prediction dynamics underpin critical decisions. While recent XAI methods have improved the explainability of time series models, they mostly analyze each time step independently, overlooking temporal dependencies. This results in further challenges: explaining prediction changes is non-trivial, methods fail to leverage online dynamics, and evaluation remains difficult. To address these challenges, we propose Delta-XAI, which adapts 14 existing XAI methods through a wrapper function and introduces a principled evaluation suite for the online setting, assessing diverse aspects, such as faithfulness, sufficiency, and coherence. Experiments reveal that classical gradient-based methods, such as Integrated Gradients (IG), can outperform recent approaches when adapted for temporal analysis. Building on this, we propose Shifted Window Integrated Gradients (SWING), which incorporates past observations in the integration path to systematically capture temporal dependencies and mitigate out-of-distribution effects. Extensive experiments consistently demonstrate the effectiveness of SWING across diverse settings with respect to diverse metrics. Our code is publicly available at https://anonymous.4open.science/r/Delta-XAI.

</details>


### [241] [Spectral Concentration at the Edge of Stability: Information Geometry of Kernel Associative Memory](https://arxiv.org/abs/2511.23083)
*Akira Tamamori*

Main category: cs.LG

TL;DR: 高容量核Hopfield网络存在"优化脊"现象，表现为极端稳定性。研究发现该脊对应统计流形上的"稳定性边缘"，是Fisher信息矩阵奇异的关键边界，将学习动力学与容量统一于最小描述长度原理。


<details>
  <summary>Details</summary>
Motivation: 高容量核Hopfield网络中观察到的"优化脊"现象具有极端稳定性，虽然之前与"谱集中"相关，但其起源仍不清楚。需要从几何角度理解这一现象的本质。

Method: 在统计流形上分析网络动力学，揭示优化脊对应"稳定性边缘"——Fisher信息矩阵变得奇异的关键边界。通过黎曼空间中的对偶平衡概念解释表观欧几里得力对抗。

Result: 优化脊对应统计流形上的稳定性边缘，表观的欧几里得力对抗是黎曼空间中"对偶平衡"的表现。这通过最小描述长度原理统一了学习动力学和容量。

Conclusion: 该研究提供了自组织临界性的几何理论，将高容量核Hopfield网络的优化脊现象理解为统计流形上的稳定性边缘，为理解网络动力学和容量提供了统一的几何框架。

Abstract: High-capacity kernel Hopfield networks exhibit a "Ridge of Optimization" characterized by extreme stability. While previously linked to "Spectral Concentration," its origin remains elusive. Here, we analyze the network dynamics on a statistical manifold, revealing that the Ridge corresponds to the "Edge of Stability," a critical boundary where the Fisher Information Matrix becomes singular. We demonstrate that the apparent Euclidean force antagonism is a manifestation of \textit{Dual Equilibrium} in the Riemannian space. This unifies learning dynamics and capacity via the Minimum Description Length principle, offering a geometric theory of self-organized criticality.

</details>


### [242] [Freeze, Diffuse, Decode: Geometry-Aware Adaptation of Pretrained Transformer Embeddings for Antimicrobial Peptide Design](https://arxiv.org/abs/2511.23120)
*Pankhil Gawade,Adam Izdebski,Myriam Lizotte,Kevin R. Moon,Jake S. Rhodes,Guy Wolf,Ewa Szczurek*

Main category: cs.LG

TL;DR: 提出FDD框架，通过扩散过程在保持预训练嵌入几何结构的同时适应下游任务，应用于抗菌肽设计


<details>
  <summary>Details</summary>
Motivation: 现有迁移策略（微调和探测）要么扭曲预训练嵌入的几何结构，要么表达能力不足，在监督数据稀缺时问题更严重

Method: FDD框架：冻结预训练嵌入，通过扩散过程沿嵌入流形传播监督信号，实现几何感知的嵌入空间适应

Result: 应用于抗菌肽设计，获得低维、可预测、可解释的表征，支持属性预测、检索和潜在空间插值

Conclusion: FDD框架在保持预训练几何结构的同时有效适应下游任务，特别适用于监督数据稀缺的场景

Abstract: Pretrained transformers provide rich, general-purpose embeddings, which are transferred to downstream tasks. However, current transfer strategies: fine-tuning and probing, either distort the pretrained geometric structure of the embeddings or lack sufficient expressivity to capture task-relevant signals. These issues become even more pronounced when supervised data are scarce. Here, we introduce Freeze, Diffuse, Decode (FDD), a novel diffusion-based framework that adapts pre-trained embeddings to downstream tasks while preserving their underlying geometric structure. FDD propagates supervised signal along the intrinsic manifold of frozen embeddings, enabling a geometry-aware adaptation of the embedding space. Applied to antimicrobial peptide design, FDD yields low-dimensional, predictive, and interpretable representations that support property prediction, retrieval, and latent-space interpolation.

</details>


### [243] [Automated Discovery of Laser Dicing Processes with Bayesian Optimization for Semiconductor Manufacturing](https://arxiv.org/abs/2511.23141)
*David Leeftink,Roman Doll,Heleen Visserman,Marco Post,Faysal Boughorbel,Max Hinne,Marcel van Gerven*

Main category: cs.LG

TL;DR: 首次在工业LASER1205切割系统上实现激光切割半导体晶圆工艺的自动化发现，通过贝叶斯优化和双保真度策略，在硅晶圆和产品晶圆上达到或超越专家基准


<details>
  <summary>Details</summary>
Motivation: 半导体晶圆激光切割是微电子制造的关键步骤，传统上需要数周专家时间调整新材料的工艺参数，过程复杂且耗时，需要自动化解决方案

Method: 将问题建模为高维约束多目标贝叶斯优化任务，采用顺序双保真度策略最小化昂贵的破坏性芯片强度评估，在工业LASER1205系统上实现自动化工艺发现

Result: 在裸硅晶圆和产品晶圆上，方法自主提供可行配置，在生产速度、芯片强度和结构完整性方面匹配或超越专家基准，仅需技术人员操作；后验验证显示可获得多种不同权衡的可行解

Conclusion: 专家对发现工艺的进一步优化可在保持芯片强度和结构完整性的同时提高生产速度，超越纯手动或纯自动化方法，为半导体制造工艺优化提供有效自动化途径

Abstract: Laser dicing of semiconductor wafers is a critical step in microelectronic manufacturing, where multiple sequential laser passes precisely separate individual dies from the wafer. Adapting this complex sequential process to new wafer materials typically requires weeks of expert effort to balance process speed, separation quality, and material integrity. We present the first automated discovery of production-ready laser dicing processes on an industrial LASER1205 dicing system. We formulate the problem as a high-dimensional, constrained multi-objective Bayesian optimization task, and introduce a sequential two-level fidelity strategy to minimize expensive destructive die-strength evaluations. On bare silicon and product wafers, our method autonomously delivers feasible configurations that match or exceed expert baselines in production speed, die strength, and structural integrity, using only technician-level operation. Post-hoc validation of different weight configurations of the utility functions reveals that multiple feasible solutions with qualitatively different trade-offs can be obtained from the final surrogate model. Expert-refinement of the discovered process can further improve production speed while preserving die strength and structural integrity, surpassing purely manual or automated methods.

</details>


### [244] [Adapting Neural Audio Codecs to EEG](https://arxiv.org/abs/2511.23142)
*Ard Kastrati,Luca Lanzendörfer,Riccardo Rigoni,John Staib Matilla,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 使用预训练的神经音频编解码器（DAC）进行EEG压缩，通过数据预处理适配音频编解码器的输入约束，无需修改架构即可获得稳定EEG重建，微调后效果更好


<details>
  <summary>Details</summary>
Motivation: EEG和音频是本质上不同的模态，具有不同的采样率、通道结构和尺度差异，但研究表明预训练的神经音频编解码器可以作为EEG压缩的有效起点

Method: 1. 使用最先进的神经音频编解码器DAC作为基础；2. 将原始EEG数据映射到编解码器的基于步幅的帧结构中；3. 直接重用音频预训练的编码器-解码器；4. 提出DAC-MC多通道扩展，具有基于注意力的跨通道聚合和通道特定解码；5. 系统探索压缩质量权衡：残差码本深度、码本大小、输入采样率

Result: 即使不修改架构也能获得稳定的EEG重建，在EEG数据上微调相比从头训练能进一步提高保真度和泛化能力。在TUH异常和癫痫数据集上的评估显示，适应后的编解码器保留了临床相关信息，体现在基于频谱图的重建损失和下游分类准确性上

Conclusion: 预训练的神经音频编解码器可以作为EEG压缩的有效基础，通过适当的数据预处理和架构适应，能够有效处理EEG数据并保留临床相关信息，为跨模态迁移学习提供了新思路

Abstract: EEG and audio are inherently distinct modalities, differing in sampling rate, channel structure, and scale. Yet, we show that pretrained neural audio codecs can serve as effective starting points for EEG compression, provided that the data are preprocessed to be suitable to the codec's input constraints. Using DAC, a state-of-the-art neural audio codec as our base, we demonstrate that raw EEG can be mapped into the codec's stride-based framing, enabling direct reuse of the audio-pretrained encoder-decoder. Even without modification, this setup yields stable EEG reconstructions, and fine-tuning on EEG data further improves fidelity and generalization compared to training from scratch. We systematically explore compression-quality trade-offs by varying residual codebook depth, codebook (vocabulary) size, and input sampling rate. To capture spatial dependencies across electrodes, we propose DAC-MC, a multi-channel extension with attention-based cross-channel aggregation and channel-specific decoding, while retaining the audio-pretrained initialization. Evaluations on the TUH Abnormal and Epilepsy datasets show that the adapted codecs preserve clinically relevant information, as reflected in spectrogram-based reconstruction loss and downstream classification accuracy.

</details>


### [245] [A Theoretical Framework for Discovering Groups and Unitary Representations via Tensor Factorization](https://arxiv.org/abs/2511.23152)
*Dongsung Huh,Halyun Jeong*

Main category: cs.LG

TL;DR: HyperCube模型通过算子值张量分解发现群结构及其酉表示，理论分析表明其归纳偏置倾向于群结构（直至同构）。


<details>
  <summary>Details</summary>
Motivation: 理解HyperCube模型为何能发现群结构和酉表示的机制，从理论上解释其归纳偏置的来源。

Method: 将目标函数分解为尺度调节项(ℬ)和方向对齐项(ℛ≥0)，分离出共线流形(ℛ=0)，证明该流形仅对群同构可行，且ℬ项产生向酉性的变分压力。

Result: 在共线主导猜想下证明：(1)全局最小值由群的酉正则表示实现；(2)非群操作具有严格更高的目标值，量化了模型对群结合结构的归纳偏置。

Conclusion: HyperCube模型具有发现群结构和酉表示的强归纳偏置，理论框架解释了其优化行为，为理解算子值张量分解的表示学习能力提供了理论基础。

Abstract: We analyze the HyperCube model, an \textit{operator-valued} tensor factorization architecture that discovers group structures and their unitary representations. We provide a rigorous theoretical explanation for this inductive bias by decomposing its objective into a term regulating factor scales ($\mathcal{B}$) and a term enforcing directional alignment ($\mathcal{R} \geq 0$). This decomposition isolates the \textit{collinear manifold} ($\mathcal{R}=0$), to which numerical optimization consistently converges for group isotopes. We prove that this manifold admits feasible solutions exclusively for group isotopes, and that within it, $\mathcal{B}$ exerts a variational pressure toward unitarity. To bridge the gap to the global landscape, we formulate a \textit{Collinearity Dominance Conjecture}, supported by empirical observations. Conditional on this dominance, we prove two key results: (1) the global minimum is achieved by the unitary regular representation for groups, and (2) non-group operations incur a strictly higher objective value, formally quantifying the model's inductive bias toward the associative structure of groups (up to isotopy).

</details>


### [246] [Estimating the Event-Related Potential from Few EEG Trials](https://arxiv.org/abs/2511.23162)
*Anders Vestergaard Nørskov,Kasper Jørgensen,Alexander Neergaard Zahid,Morten Mørup*

Main category: cs.LG

TL;DR: EEG2ERP是一种新颖的不确定性感知自编码器方法，可将任意数量的EEG试次映射到相关的ERP，显著减少传统平均方法所需的试次数


<details>
  <summary>Details</summary>
Motivation: 传统ERP估计需要大量EEG试次的平均来降低噪声和信号变异性，这限制了ERP研究的效率和应用。需要开发能够减少所需试次数的新方法。

Method: 提出EEG2ERP，一种不确定性感知自编码器方法，使用引导训练目标和单独的方差解码器来建模ERP估计的不确定性，支持零样本泛化到新受试者。

Result: 在三个公开数据集（ERP CORE、P300拼写器BCI、面部感知神经影像）上评估，在少试次情况下显著优于传统平均方法和鲁棒平均程序。

Conclusion: EEG2ERP是首个将EEG信号映射到相关ERP的深度学习方法，有望显著减少ERP研究所需的试次数，推动该领域发展。

Abstract: Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP

</details>


### [247] [Energy-Efficient Vision Transformer Inference for Edge-AI Deployment](https://arxiv.org/abs/2511.23166)
*Nursultan Amanzhol,Jurn-Gyu Park*

Main category: cs.LG

TL;DR: 提出两阶段评估流程，结合设备无关模型筛选与设备相关测量，评估Vision Transformers在边缘设备上的能效表现


<details>
  <summary>Details</summary>
Motivation: 随着Vision Transformers在能耗受限设备上的部署增加，需要超越准确率的能效评估方法

Method: 两阶段评估流程：第一阶段使用NetScore指标进行设备无关模型筛选；第二阶段使用可持续准确率指标(SAM)进行设备相关排名

Result: 混合模型如LeViT_Conv_192在TX2上相比ViT基线节能高达53%；蒸馏模型如TinyViT-11M_Distilled在移动GPU上表现优异

Conclusion: 提出的两阶段评估方法能有效识别不同硬件平台上的能效最优模型，为实际部署提供指导

Abstract: The growing deployment of Vision Transformers (ViTs) on energy-constrained devices requires evaluation methods that go beyond accuracy alone. We present a two-stage pipeline for assessing ViT energy efficiency that combines device-agnostic model selection with device-related measurements. We benchmark 13 ViT models on ImageNet-1K and CIFAR-10, running inference on NVIDIA Jetson TX2 (edge device) and an NVIDIA RTX 3050 (mobile GPU). The device-agnostic stage uses the NetScore metric for screening; the device-related stage ranks models with the Sustainable Accuracy Metric (SAM). Results show that hybrid models such as LeViT_Conv_192 reduce energy by up to 53% on TX2 relative to a ViT baseline (e.g., SAM5=1.44 on TX2/CIFAR-10), while distilled models such as TinyViT-11M_Distilled excel on the mobile GPU (e.g., SAM5=1.72 on RTX 3050/CIFAR-10 and SAM5=0.76 on RTX 3050/ImageNet-1K).

</details>


### [248] [SDE-Attention: Latent Attention in SDE-RNNs for Irregularly Sampled Time Series with Missing Data](https://arxiv.org/abs/2511.23238)
*Yuting Fang,Qouc Le Gia,Flora Salim*

Main category: cs.LG

TL;DR: SDE-Attention：一种用于不规则采样时间序列的SDE-RNN模型，通过通道级注意力机制（包括通道重校准、时变特征注意力和金字塔多尺度自注意力）处理高缺失率数据，在单变量和多变量数据集上均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 医疗健康和传感器网络中常见的不规则采样时间序列通常存在大量缺失观测值，现有方法在处理高缺失率数据时效果有限，需要开发更强大的模型来处理这种具有挑战性的时间序列数据。

Method: 提出SDE-Attention模型家族，基于SDE-RNN框架，在潜在RNN状态前引入三种通道级注意力机制：1）通道重校准；2）时变特征注意力；3）金字塔多尺度自注意力。这些机制帮助模型更好地处理缺失数据并提取重要特征。

Result: 在合成周期数据集和真实世界基准测试中，潜在空间注意力机制始终优于普通SDE-RNN。在单变量UCR数据集上，基于LSTM的时变特征模型SDE-TVF-L表现最佳，在30%、60%和90%缺失率下分别比基线平均提升约4%、6%和10%。在多变量UEA基准测试中，注意力增强模型同样优于骨干网络，SDE-TVF-L在高缺失率下可获得高达7%的平均准确率提升。

Conclusion: 时变特征注意力在单变量数据集上表现最稳健，而在多变量数据集上，不同类型的注意力机制在不同任务中各有优势，表明SDE-Attention可以根据每个问题的结构灵活调整。该框架为处理高缺失率的不规则时间序列提供了有效的解决方案。

Abstract: Irregularly sampled time series with substantial missing observations are common in healthcare and sensor networks. We introduce SDE-Attention, a family of SDE-RNNs equipped with channel-level attention on the latent pre-RNN state, including channel recalibration, time-varying feature attention, and pyramidal multi-scale self-attention. We therefore conduct a comparison on a synthetic periodic dataset and real-world benchmarks, under varying missing rate. Latent-space attention consistently improves over a vanilla SDE-RNN. On the univariate UCR datasets, the LSTM-based time-varying feature model SDE-TVF-L achieves the highest average accuracy, raising mean performance by approximately 4, 6, and 10 percentage points over the baseline at 30%, 60% and 90% missingness, respectively (averaged across datasets). On multivariate UEA benchmarks, attention-augmented models again outperform the backbone, with SDE-TVF-L yielding up to a 7% gain in mean accuracy under high missingness. Among the proposed mechanisms, time-varying feature attention is the most robust on univariate datasets. On multivariate datasets, different attention types excel on different tasks, showing that SDE-Attention can be flexibly adapted to the structure of each problem.

</details>


### [249] [Towards Understanding Transformers in Learning Random Walks](https://arxiv.org/abs/2511.23239)
*Wei Shi,Yuan Cao*

Main category: cs.LG

TL;DR: 本文从理论上分析了单层Transformer在随机游走任务上的学习能力和可解释性，证明了梯度下降训练后能达到最优预测精度，并揭示了注意力机制作为令牌选择器、值矩阵执行概率转移的机制。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在序列数据处理中表现出色，但缺乏理论理解和可解释性。本文旨在研究Transformer在经典统计模型（圆周上的随机游走）上的学习能力和可解释性，为理解Transformer的成功提供理论依据。

Method: 采用理论分析方法，研究单层Transformer模型在随机游走任务上的训练过程。使用梯度下降训练，分析模型收敛后的行为，特别关注注意力机制和值矩阵的作用机制。通过理论推导和实验验证相结合的方法。

Result: 理论证明：梯度下降训练后，单层Transformer能达到随机游走预测的最优精度。分析显示模型具有可解释性：训练后的softmax注意力作为令牌选择器，专注于直接父状态；值矩阵基于父状态执行一步概率转移来预测下一个状态的位置。同时识别了理论未覆盖的失败案例。

Conclusion: 本文为Transformer在序列任务上的成功提供了理论解释，揭示了其内部工作机制的可解释性。同时发现小初始化梯度下降在某些简单任务中可能失败或难以收敛，这对理解Transformer的局限性具有重要意义。研究为理解Transformer的理论基础迈出了重要一步。

Abstract: Transformers have proven highly effective across various applications, especially in handling sequential data such as natural languages and time series. However, transformer models often lack clear interpretability, and the success of transformers has not been well understood in theory. In this paper, we study the capability and interpretability of transformers in learning a family of classic statistical models, namely random walks on circles. We theoretically demonstrate that, after training with gradient descent, a one-layer transformer model can achieve optimal accuracy in predicting random walks. Importantly, our analysis reveals that the trained model is interpretable: the trained softmax attention serves as a token selector, focusing on the direct parent state; subsequently, the value matrix executes a one-step probability transition to predict the location of the next state based on this parent state. We also show that certain edge cases not covered by our theory are indeed failure cases, demonstrating that our theoretical conditions are tight. By investigating these success and failure cases, it is revealed that gradient descent with small initialization may fail or struggle to converge to a good solution in certain simple tasks even beyond random walks. Experiments are conducted to support our theoretical findings.

</details>


### [250] [Heteroscedastic Neural Networks for Path Loss Prediction with Link-Specific Uncertainty](https://arxiv.org/abs/2511.23243)
*Jonathan Ethier*

Main category: cs.LG

TL;DR: 提出一种神经网络模型，联合预测路径损耗的均值和链路特定方差，实现异方差不确定性估计，在RF测试数据上表现优于传统恒定方差假设方法。


<details>
  <summary>Details</summary>
Motivation: 传统和现代基于机器学习的路径损耗模型通常假设恒定预测方差，这限制了不确定性估计的准确性。需要能够提供链路特定方差估计的方法来改进RF规划和干扰分析。

Method: 提出一种神经网络，通过最小化高斯负对数似然联合预测均值和链路特定方差。比较了共享参数、部分共享参数和独立参数三种架构，使用准确性、校准度和锐度等指标在大型公共RF路测数据集上进行评估。

Result: 共享参数架构表现最佳，达到RMSE 7.4 dB，95%预测区间的覆盖率为95.1%，平均区间宽度为29.6 dB。这些不确定性估计支持链路特定覆盖余量，改进RF规划和干扰分析，并提供有效的模型弱点自诊断。

Conclusion: 提出的异方差不确定性估计方法优于传统恒定方差假设，为路径损耗预测提供了更准确的不确定性量化，对无线网络规划和优化具有重要实用价值。

Abstract: Traditional and modern machine learning-based path loss models typically assume a constant prediction variance. We propose a neural network that jointly predicts the mean and link-specific variance by minimizing a Gaussian negative log-likelihood, enabling heteroscedastic uncertainty estimates. We compare shared, partially shared, and independent-parameter architectures using accuracy, calibration, and sharpness metrics on blind test sets from large public RF drive-test datasets. The shared-parameter architecture performs best, achieving an RMSE of 7.4 dB, 95.1 percent coverage for 95 percent prediction intervals, and a mean interval width of 29.6 dB. These uncertainty estimates further support link-specific coverage margins, improve RF planning and interference analyses, and provide effective self-diagnostics of model weaknesses.

</details>


### [251] [Time Series Forecasting via Direct Per-Step Probability Distribution Modeling](https://arxiv.org/abs/2511.23260)
*Linghao Kong,Xiaopeng Hong*

Main category: cs.LG

TL;DR: 提出interPDN模型，通过双分支架构直接构建离散概率分布而非标量值，用于时间序列预测并量化不确定性


<details>
  <summary>Details</summary>
Motivation: 现有深度神经网络时间序列预测模型难以处理预测不确定性，因为它们直接输出标量值，无法量化预测的置信度

Method: 提出interleaved dual-branch Probability Distribution Network (interPDN)，在每个时间步直接构建离散概率分布而非标量；使用双分支架构和交错支持集，引入粗时间尺度分支进行长期趋势预测；通过另一分支的输出作为辅助信号，对当前分支预测施加自监督一致性约束

Result: 在多个真实世界数据集上的广泛实验表明interPDN具有优越性能

Conclusion: interPDN通过直接构建概率分布有效解决了时间序列预测中的不确定性量化问题，双分支架构和自监督一致性约束进一步提升了预测性能

Abstract: Deep neural network-based time series prediction models have recently demonstrated superior capabilities in capturing complex temporal dependencies. However, it is challenging for these models to account for uncertainty associated with their predictions, because they directly output scalar values at each time step. To address such a challenge, we propose a novel model named interleaved dual-branch Probability Distribution Network (interPDN), which directly constructs discrete probability distributions per step instead of a scalar. The regression output at each time step is derived by computing the expectation of the predictive distribution on a predefined support set. To mitigate prediction anomalies, a dual-branch architecture is introduced with interleaved support sets, augmented by coarse temporal-scale branches for long-term trend forecasting. Outputs from another branch are treated as auxiliary signals to impose self-supervised consistency constraints on the current branch's prediction. Extensive experiments on multiple real-world datasets demonstrate the superior performance of interPDN.

</details>


### [252] [An Improved and Generalised Analysis for Spectral Clustering](https://arxiv.org/abs/2511.23261)
*George Tyler,Luca Zanetti*

Main category: cs.LG

TL;DR: 论文重新审视谱聚类的理论性能，证明只要最小特征值分组良好且与谱的其余部分分离，谱聚类就能有效工作，适用于多尺度层次聚类和定向图等更一般场景。


<details>
  <summary>Details</summary>
Motivation: 传统谱聚类分析未能涵盖多尺度层次聚类等更一般场景，且主要针对无向图拉普拉斯矩阵。本文旨在建立更通用的理论框架，扩展谱聚类的适用范围，包括有向图表示和更复杂的聚类结构。

Method: 采用理论分析方法，研究谱聚类在最小特征值分组良好且与谱的其余部分分离条件下的性能。将分析扩展到传统图拉普拉斯之外，包括有向图的厄米特表示。通过合成和真实数据集验证理论预测。

Result: 证明谱聚类在最小特征值分组良好条件下表现优异，能处理多尺度层次聚类。对有向图，谱聚类能恢复边主要沿相同方向流动的聚类划分。理论预测与合成和真实数据集的实验结果一致。

Conclusion: 谱聚类的有效性依赖于特征值谱的结构而非具体矩阵表示，这一更通用的理论框架扩展了谱聚类的适用范围，为生态网络营养级分析等应用提供了理论基础。

Abstract: We revisit the theoretical performances of Spectral Clustering, a classical algorithm for graph partitioning that relies on the eigenvectors of a matrix representation of the graph. Informally, we show that Spectral Clustering works well as long as the smallest eigenvalues appear in groups well separated from the rest of the matrix representation's spectrum. This arises, for example, whenever there exists a hierarchy of clusters at different scales, a regime not captured by previous analyses. Our results are very general and can be applied beyond the traditional graph Laplacian. In particular, we study Hermitian representations of digraphs and show Spectral Clustering can recover partitions where edges between clusters are oriented mostly in the same direction. This has applications in, for example, the analysis of trophic levels in ecological networks. We demonstrate that our results accurately predict the performances of Spectral Clustering on synthetic and real-world data sets.

</details>


### [253] [BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning](https://arxiv.org/abs/2511.23264)
*Ariful Islam,Md Rifat Hossen,Tanvir Mahmud*

Main category: cs.LG

TL;DR: BanglaSentNet：一个用于孟加拉语电商评论多维度情感分析的可解释混合深度学习框架，通过集成LSTM、BiLSTM、GRU和BanglaBERT，在8,755条标注数据上达到85%准确率，并提供SHAP可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语情感分析面临标注数据有限、形态复杂、代码混合和领域迁移等挑战，现有方法缺乏可解释性和跨领域泛化能力，影响了3亿孟加拉语用户的实际应用。

Method: 提出BanglaSentNet框架，集成LSTM、BiLSTM、GRU和BanglaBERT通过动态加权集成学习进行多维度情感分类，引入SHAP特征归因和注意力可视化提供可解释性，构建了8,755条手动标注的孟加拉语产品评论数据集。

Result: 模型达到85%准确率和0.88 F1分数，比独立深度学习模型提升3-7%；可解释性套件获得9.4/10可解释性评分和87.6%人工一致性；跨领域迁移学习在零样本设置下保持67-76%效果，少样本学习仅需500-1000样本即可达到90-95%全微调性能。

Conclusion: 该研究为孟加拉语情感分析建立了新的SOTA基准，推进了低资源语言的集成学习方法，为商业应用提供了可行的解决方案，实际部署证明了其在孟加拉电商平台中的实用价值。

Abstract: Multi-aspect sentiment analysis of Bangla e-commerce reviews remains challenging due to limited annotated datasets, morphological complexity, code-mixing phenomena, and domain shift issues, affecting 300 million Bangla-speaking users. Existing approaches lack explainability and cross-domain generalization capabilities crucial for practical deployment. We present BanglaSentNet, an explainable hybrid deep learning framework integrating LSTM, BiLSTM, GRU, and BanglaBERT through dynamic weighted ensemble learning for multi-aspect sentiment classification. We introduce a dataset of 8,755 manually annotated Bangla product reviews across four aspects (Quality, Service, Price, Decoration) from major Bangladeshi e-commerce platforms. Our framework incorporates SHAP-based feature attribution and attention visualization for transparent insights. BanglaSentNet achieves 85% accuracy and 0.88 F1-score, outperforming standalone deep learning models by 3-7% and traditional approaches substantially. The explainability suite achieves 9.4/10 interpretability score with 87.6% human agreement. Cross-domain transfer learning experiments reveal robust generalization: zero-shot performance retains 67-76% effectiveness across diverse domains (BanglaBook reviews, social media, general e-commerce, news headlines); few-shot learning with 500-1000 samples achieves 90-95% of full fine-tuning performance, significantly reducing annotation costs. Real-world deployment demonstrates practical utility for Bangladeshi e-commerce platforms, enabling data-driven decision-making for pricing optimization, service improvement, and customer experience enhancement. This research establishes a new state-of-the-art benchmark for Bangla sentiment analysis, advances ensemble learning methodologies for low-resource languages, and provides actionable solutions for commercial applications.

</details>


### [254] [Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting](https://arxiv.org/abs/2511.23276)
*Joongwon Chae,Runming Wang,Chen Xiong,Gong Yunhan,Lian Zhang,Ji Jiansong,Dongmei Yu,Peiwu Qin*

Main category: cs.LG

TL;DR: 提出一个两智能体框架，将情境解释与概率预测解耦，使用LLM处理学校日程、天气等异质信号，结合神经符号核心进行手足口病预测


<details>
  <summary>Details</summary>
Motivation: 传统模型和基础模型虽然能纳入协变量，但缺乏语义推理能力来解释冲突驱动因素之间的因果关系，需要能结合领域知识和情境理解的预测框架

Method: 两智能体框架：LLM"事件解释器"处理异质信号（学校日程、气象摘要、报告）生成标量传播影响信号；神经符号核心结合历史病例数产生校准的概率预测

Result: 在香港（2023-2024）和丽水（2024）的真实HFMD数据集上评估，相比传统和基础模型基线，在保持竞争性点预测精度的同时，提供稳健的90%预测区间（覆盖率0.85-1.00）和人类可解释的推理

Conclusion: 通过LLM结构化整合领域知识可以达到最先进性能，同时产生与公共卫生工作流程一致的情境感知预测

Abstract: Effective surveillance of hand, foot and mouth disease (HFMD) requires forecasts accounting for epidemiological patterns and contextual drivers like school calendars and weather. While classical models and recent foundation models (e.g., Chronos, TimesFM) incorporate covariates, they often lack the semantic reasoning to interpret the causal interplay between conflicting drivers. In this work, we propose a two-agent framework decoupling contextual interpretation from probabilistic forecasting. An LLM "event interpreter" processes heterogeneous signals-including school schedules, meteorological summaries, and reports-into a scalar transmission-impact signal. A neuro-symbolic core then combines this with historical case counts to produce calibrated probabilistic forecasts. We evaluate the framework on real-world HFMD datasets from Hong Kong (2023-2024) and Lishui, China (2024). Compared to traditional and foundation-model baselines, our approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Our results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art performance while yielding context-aware forecasts that align with public health workflows. Code is available at https://github.com/jw-chae/forecast_MED .

</details>


### [255] [Closing the Generalization Gap in Parameter-efficient Federated Edge Learning](https://arxiv.org/abs/2511.23282)
*Xinnong Du,Zhonghao Lyu,Xiaowen Cao,Chunyang Wen,Shuguang Cui,Jie Xu*

Main category: cs.LG

TL;DR: 提出一个参数高效的联邦边缘学习框架，通过联合模型剪枝和客户端选择来应对数据异构和资源受限的挑战，将泛化分析嵌入收敛分析，并通过交替优化算法解决联合优化问题。


<details>
  <summary>Details</summary>
Motivation: 联邦边缘学习面临本地数据集有限且异构、资源受限部署的问题，这会严重降低模型泛化能力和资源利用率，从而影响学习性能。

Method: 提出参数高效的FEEL框架，联合利用模型剪枝和客户端选择；推导信息论泛化界并嵌入收敛分析；将泛化感知的平均平方梯度范数界最小化问题建模为混合整数优化问题，通过交替优化算法求解。

Result: 实验表明，所提出的设计在多个数据集上优于现有基线方法，验证了将泛化感知分析与系统级优化相结合对高效FEEL的有效性。

Conclusion: 通过联合模型剪枝、客户端选择和资源优化，结合泛化感知分析，能够显著提升联邦边缘学习的性能，为边缘AI提供更高效的解决方案。

Abstract: Federated edge learning (FEEL) provides a promising foundation for edge artificial intelligence (AI) by enabling collaborative model training while preserving data privacy. However, limited and heterogeneous local datasets, as well as resource-constrained deployment, severely degrade both model generalization and resource utilization, leading to a compromised learning performance. Therefore, we propose a parameter-efficient FEEL framework that jointly leverages model pruning and client selection to tackle such challenges. First, we derive an information-theoretic generalization statement that characterizes the discrepancy between training and testing function losses and embed it into the convergence analysis. It reveals that a larger local generalization statement can undermine the global convergence. Then, we formulate a generalization-aware average squared gradient norm bound minimization problem, by jointly optimizing the pruning ratios, client selection, and communication-computation resources under energy and delay constraints. Despite its non-convexity, the resulting mixed-integer problem is efficiently solved via an alternating optimization algorithm. Extensive experiments demonstrate that the proposed design achieves superior learning performance than state-of-the-art baselines, validating the effectiveness of coupling generalization-aware analysis with system-level optimization for efficient FEEL.

</details>


### [256] [Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla](https://arxiv.org/abs/2511.23287)
*Ariful Islam,Tanvir Mahmud,Md Rifat Hossen*

Main category: cs.LG

TL;DR: 本文提出BangACMM框架，通过中间融合策略结合文本和视觉模态，在孟加拉社交媒体帖子作者意图分类任务上取得了84.11%的宏F1分数，比之前方法提升了8.4个百分点。


<details>
  <summary>Details</summary>
Motivation: 互联网和社交网络的扩展导致用户生成内容爆炸式增长，作者意图理解对社交媒体内容解释至关重要。先前单模态方法存在局限性，需要更有效的多模态方法处理孟加拉社交媒体内容。

Method: 系统评估基于Transformer的语言模型（mBERT、DistilBERT、XLM-RoBERTa）和视觉架构（ViT、Swin、SwiftFormer、ResNet、DenseNet、MobileNet），使用包含3,048个帖子、涵盖6个意图类别的Uddessho数据集。提出新颖的中间融合策略，优于早期和晚期融合方法。

Result: 中间融合策略（特别是mBERT和Swin Transformer组合）达到84.11%的宏F1分数，比先前孟加拉多模态方法提升8.4个百分点，建立了新的最先进水平。视觉上下文显著增强了意图分类效果。

Conclusion: 中间层跨模态特征集成在模态特定表示和跨模态学习之间提供了最佳平衡。本研究为孟加拉语和其他低资源语言建立了新的基准和方法标准，提出的BangACMM框架在多模态意图分类任务上表现出色。

Abstract: The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).

</details>


### [257] [Machine Learning for Scientific Visualization: Ensemble Data Analysis](https://arxiv.org/abs/2511.23290)
*Hamid Gadirov*

Main category: cs.LG

TL;DR: 该论文提出深度学习方法来改进时空科学集合数据的分析和可视化，包括基于自动编码器的降维、FLINT模型进行流场估计和时间插值，以及HyperFLINT超网络方法实现参数感知适应。


<details>
  <summary>Details</summary>
Motivation: 科学模拟和实验测量产生大量时空数据，但高维度、复杂结构和缺失信息使得提取有意义的洞察具有挑战性。传统分析方法难以处理这些问题，需要更鲁棒的数据驱动方法。

Method: 1. 基于自动编码器的降维方法，评估部分标记下的投影稳定性，采用帕累托效率选择策略确定最优自动编码器变体；2. FLINT深度学习模型，在流场监督和无监督设置下进行高质量流场估计和时间插值；3. HyperFLINT超网络方法，基于模拟参数进行条件化，实现参数感知的流场估计和标量数据插值。

Result: 提出的方法能够生成表达性强且可靠的低维嵌入，在2D+时间和3D+时间集合中重建缺失速度场并生成高保真时间插值，无需领域特定假设或大量微调。参数感知适应在不同科学领域中产生更准确的重建，即使在数据稀疏或不完整的情况下。

Conclusion: 该论文推进了科学可视化的深度学习技术，为解释复杂时空集合数据提供了可扩展、适应性强且高质量的解决方案，显著改进了科学数据的分析和可视化能力。

Abstract: Scientific simulations and experimental measurements produce vast amounts of spatio-temporal data, yet extracting meaningful insights remains challenging due to high dimensionality, complex structures, and missing information. Traditional analysis methods often struggle with these issues, motivating the need for more robust, data-driven approaches. This dissertation explores deep learning methodologies to improve the analysis and visualization of spatio-temporal scientific ensembles, focusing on dimensionality reduction, flow estimation, and temporal interpolation. First, we address high-dimensional data representation through autoencoder-based dimensionality reduction for scientific ensembles. We evaluate the stability of projection metrics under partial labeling and introduce a Pareto-efficient selection strategy to identify optimal autoencoder variants, ensuring expressive and reliable low-dimensional embeddings. Next, we present FLINT, a deep learning model for high-quality flow estimation and temporal interpolation in both flow-supervised and flow-unsupervised settings. FLINT reconstructs missing velocity fields and generates high-fidelity temporal interpolants for scalar fields across 2D+time and 3D+time ensembles without domain-specific assumptions or extensive finetuning. To further improve adaptability and generalization, we introduce HyperFLINT, a hypernetwork-based approach that conditions on simulation parameters to estimate flow fields and interpolate scalar data. This parameter-aware adaptation yields more accurate reconstructions across diverse scientific domains, even with sparse or incomplete data. Overall, this dissertation advances deep learning techniques for scientific visualization, providing scalable, adaptable, and high-quality solutions for interpreting complex spatio-temporal ensembles.

</details>


### [258] [Hard-Constrained Neural Networks with Physics-Embedded Architecture for Residual Dynamics Learning and Invariant Enforcement in Cyber-Physical Systems](https://arxiv.org/abs/2511.23307)
*Enzo Nicolás Spotorno,Josafat Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 提出HRPINN和PHRPINN框架，通过嵌入已知物理约束和严格强制执行代数不变量，在复杂网络物理系统中实现物理信息学习


<details>
  <summary>Details</summary>
Motivation: 解决具有未知动力学和代数不变量的微分方程所支配的复杂网络物理系统中的物理信息学习问题，需要在保持物理一致性的同时提高数据效率

Method: 1. 提出HRPINN架构，将已知物理作为硬结构约束嵌入循环积分器中学习残差动力学；2. 提出PHRPINN扩展，通过预测-投影机制严格强制执行代数不变量

Result: 在真实世界电池预测DAE上验证HRPINN，在标准约束基准测试中评估PHRPINN，展示了高精度和数据效率，同时揭示了物理一致性、计算成本和数值稳定性之间的权衡

Conclusion: 该框架为复杂网络物理系统中的物理信息学习提供了有效解决方案，通过理论分析和实验验证展示了其潜力，并为实际部署提供了实用指导

Abstract: This paper presents a framework for physics-informed learning in complex cyber-physical systems governed by differential equations with both unknown dynamics and algebraic invariants. First, we formalize the Hybrid Recurrent Physics-Informed Neural Network (HRPINN), a general-purpose architecture that embeds known physics as a hard structural constraint within a recurrent integrator to learn only residual dynamics. Second, we introduce the Projected HRPINN (PHRPINN), a novel extension that integrates a predict-project mechanism to strictly enforce algebraic invariants by design. The framework is supported by a theoretical analysis of its representational capacity. We validate HRPINN on a real-world battery prognostics DAE and evaluate PHRPINN on a suite of standard constrained benchmarks. The results demonstrate the framework's potential for achieving high accuracy and data efficiency, while also highlighting critical trade-offs between physical consistency, computational cost, and numerical stability, providing practical guidance for its deployment.

</details>


### [259] [Emergent Coordination and Phase Structure in Independent Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.23315)
*Azusa Yamaguchi*

Main category: cs.LG

TL;DR: 该论文通过大规模实验揭示了去中心化多智能体强化学习中的三阶段结构：协调稳定相、脆弱过渡区和阻塞无序相，由核漂移和同步竞争驱动。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解去中心化多智能体强化学习中协调何时出现、波动或崩溃的动态特性，需要系统性地研究多智能体学习系统的行为模式。

Method: 使用完全独立Q学习（IQL）作为最小化去中心化测试平台，在环境大小L和智能体密度ρ两个维度上进行大规模实验，构建基于合作成功率（CSR）和TD误差方差稳定性指数的相图。

Result: 发现了三个不同区域：协调稳定相、脆弱过渡区和阻塞无序相，由双不稳定性脊线分隔。核漂移（智能体策略更新引起的有效转移核时变偏移）是关键驱动因素，同步分析显示时间对齐对持续合作至关重要。

Conclusion: 去中心化MARL表现出由规模、密度和核漂移相互作用支配的相干相结构，表明涌现协调是一种分布-相互作用驱动的相现象，智能体间的小不对称性是核漂移的必要驱动因素。

Abstract: A clearer understanding of when coordination emerges, fluctuates, or collapses in decentralized multi-agent reinforcement learning (MARL) is increasingly sought in order to characterize the dynamics of multi-agent learning systems. We revisit fully independent Q-learning (IQL) as a minimal decentralized testbed and run large-scale experiments across environment size L and agent density rho. We construct a phase map using two axes - the cooperative success rate (CSR) and a stability index derived from TD-error variance - revealing three distinct regimes: a coordinated and stable phase, a fragile transition region, and a jammed or disordered phase. A sharp double Instability Ridge separates these regimes and corresponds to persistent kernel drift, the time-varying shift of each agent's effective transition kernel induced by others' policy updates. Synchronization analysis further shows that temporal alignment is required for sustained cooperation, and that competition between drift and synchronization generates the fragile regime. Removing agent identifiers eliminates drift entirely and collapses the three-phase structure, demonstrating that small inter-agent asymmetries are a necessary driver of drift. Overall, the results show that decentralized MARL exhibits a coherent phase structure governed by the interaction between scale, density, and kernel drift, suggesting that emergent coordination behaves as a distribution-interaction-driven phase phenomenon.

</details>


### [260] [ParaGate: Parasitic-Driven Domain Adaptation Transfer Learning for Netlist Performance Prediction](https://arxiv.org/abs/2511.23340)
*Bin Sun,Jingyi Zhou,Jianan Mu,Zhiteng Chao,Tianmeng Yang,Ziyue Xu,Jing Ye,Huawei Li*

Main category: cs.LG

TL;DR: ParaGate是一个三阶段跨阶段预测框架，直接从网表推断布局级时序和功耗，解决了传统EDA流程中布局级性能指标只能在布局布线后获取的问题。


<details>
  <summary>Details</summary>
Motivation: 传统EDA流程中，布局级性能指标只能在布局布线后获取，阻碍了早期阶段的全局优化。现有的神经网络解决方案由于商业布局布线工具的黑盒启发式方法导致数据差异大，面临泛化挑战。

Method: ParaGate采用三步框架：1) 提出两阶段迁移学习方法预测寄生参数，先在中等规模电路上预训练，再在大规模电路上微调以捕捉极端条件；2) 依赖EDA工具进行时序分析，卸载长路径数值推理；3) 使用子图特征进行全局校准。

Result: ParaGate在openE906上实现了强泛化能力，到达时间R2从0.119提升到0.897，仅需少量微调数据。这表明ParaGate可以为综合和布局阶段的全局优化提供指导。

Conclusion: ParaGate框架能够有效预测布局级时序和功耗，解决了传统EDA流程的局限性，为早期设计阶段的全局优化提供了可行方案，具有实际应用价值。

Abstract: In traditional EDA flows, layout-level performance metrics are only obtainable after placement and routing, hindering global optimization at earlier stages. Although some neural-network-based solutions predict layout-level performance directly from netlists, they often face generalization challenges due to the black-box heuristics of commercial placement-and-routing tools, which create disparate data across designs. To this end, we propose ParaGate, a three-step cross-stage prediction framework that infers layout-level timing and power from netlists. First, we propose a two-phase transfer-learning approach to predict parasitic parameters, pre-training on mid-scale circuits and fine-tuning on larger ones to capture extreme conditions. Next, we rely on EDA tools for timing analysis, offloading the long-path numerical reasoning. Finally, ParaGate performs global calibration using subgraph features. Experiments show that ParaGate achieves strong generalization with minimal fine-tuning data: on openE906, its arrival-time R2 from 0.119 to 0.897. These results demonstrate that ParaGate could provide guidance for global optimization in the synthesis and placement stages.

</details>


### [261] [Distributed Dynamic Associative Memory via Online Convex Optimization](https://arxiv.org/abs/2511.23347)
*Bowen Wang,Matteo Zecchin,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 提出分布式动态联想记忆(DDAM)框架，扩展经典联想记忆到多智能体时变数据流场景，并设计基于树的分布式在线梯度下降算法(DDAM-TOGD)，提供理论性能保证和优化路由树设计。


<details>
  <summary>Details</summary>
Motivation: 现代神经架构(如Transformer)中的联想记忆机制在多智能体动态环境中的应用需求。需要解决多智能体在时变数据流中如何协同存储和回忆关联信息的问题。

Method: 提出DDAM框架，每个智能体维护本地联想记忆，通过兴趣矩阵选择性记忆其他智能体信息。设计DDAM-TOGD算法，基于树结构进行分布式在线梯度下降更新，支持动态环境下的实时通信和记忆更新。

Result: 理论证明：在静态环境中获得次线性静态遗憾，在非静态环境中获得路径长度相关的动态遗憾界。实验显示DDAM-TOGD在准确性和鲁棒性上优于共识分布式优化等基线方法。

Conclusion: DDAM框架成功扩展联想记忆到分布式动态环境，DDAM-TOGD算法提供理论保证和实际性能优势，路由树优化策略进一步改善通信延迟和遗憾界，为多智能体协同学习提供有效解决方案。

Abstract: An associative memory (AM) enables cue-response recall, and it has recently been recognized as a key mechanism underlying modern neural architectures such as Transformers. In this work, we introduce the concept of distributed dynamic associative memory (DDAM), which extends classical AM to settings with multiple agents and time-varying data streams. In DDAM, each agent maintains a local AM that must not only store its own associations but also selectively memorize information from other agents based on a specified interest matrix. To address this problem, we propose a novel tree-based distributed online gradient descent algorithm, termed DDAM-TOGD, which enables each agent to update its memory on the fly via inter-agent communication over designated routing trees. We derive rigorous performance guarantees for DDAM-TOGD, proving sublinear static regret in stationary environments and a path-length dependent dynamic regret bound in non-stationary environments. These theoretical results provide insights into how communication delays and network structure impact performance. Building on the regret analysis, we further introduce a combinatorial tree design strategy that optimizes the routing trees to minimize communication delays, thereby improving regret bounds. Numerical experiments demonstrate that the proposed DDAM-TOGD framework achieves superior accuracy and robustness compared to representative online learning baselines such as consensus-based distributed optimization, confirming the benefits of the proposed approach in dynamic, distributed environments.

</details>


### [262] [Learning-Augmented Online Bipartite Matching in the Random Arrival Order Model](https://arxiv.org/abs/2511.23388)
*Kunanon Burathep,Thomas Erlebach,William K. Moses*

Main category: cs.LG

TL;DR: 论文研究学习增强设置下的在线无权二分图匹配问题，在随机到达顺序模型中，算法获得在线顶点类型（邻域）的不信任预测，改进了先前工作对最优匹配大小的限制，实现了接近1的一致性和接近β的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 先前工作（Choo等人，ICML 2024）在在线二分图匹配的学习增强设置中，假设最优匹配大小为n（即每个在线顶点都能匹配）。本文旨在消除这一限制，使算法适用于更一般的场景，仅要求预测匹配大小至少为αn（0<α≤1）。

Method: 使用到达序列的前缀作为样本来评估预测质量，然后决定是遵循预测还是使用忽略预测的基线算法。通过推广Choo等人的方法，移除对最优匹配大小的假设，仅要求预测匹配大小至少为αn。

Result: 提出的学习增强算法实现了(1-o(1))-一致性和(β-o(1))-鲁棒性，并且竞争比随着预测误差的增加在一致性和鲁棒性之间平滑下降。

Conclusion: 成功推广了学习增强在线二分图匹配算法，消除了对最优匹配大小的限制，在更一般的条件下实现了接近最优的一致性和鲁棒性，且竞争比随预测误差平滑变化。

Abstract: We study the online unweighted bipartite matching problem in the random arrival order model, with $n$ offline and $n$ online vertices, in the learning-augmented setting: The algorithm is provided with untrusted predictions of the types (neighborhoods) of the online vertices. We build upon the work of Choo et al. (ICML 2024, pp. 8762-8781) who proposed an approach that uses a prefix of the arrival sequence as a sample to determine whether the predictions are close to the true arrival sequence and then either follows the predictions or uses a known baseline algorithm that ignores the predictions and is $β$-competitive. Their analysis is limited to the case that the optimal matching has size $n$, i.e., every online vertex can be matched. We generalize their approach and analysis by removing any assumptions on the size of the optimal matching while only requiring that the size of the predicted matching is at least $αn$ for any constant $0 < α\le 1$. Our learning-augmented algorithm achieves $(1-o(1))$-consistency and $(β-o(1))$-robustness. Additionally, we show that the competitive ratio degrades smoothly between consistency and robustness with increasing prediction error.

</details>


### [263] [Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning](https://arxiv.org/abs/2511.23402)
*Jiajun Guo,Xin Luo,Jie Liu*

Main category: cs.LG

TL;DR: 提出一种结合学习型数据压缩的多模态分割学习框架，通过将模型嵌入压缩为低比特整数来大幅降低通信成本，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 分割学习虽然能解决数据隐私问题，但高网络通信成本一直是其瓶颈，特别是对于需要传输大量高维数据的大型基础模型。

Method: 提出新的多模态模型结构，结合学习型数据压缩方法，将模型嵌入压缩为低比特整数；基于熵编码理论确定最优离散表示级别数量。

Result: 该方法能大幅降低分割学习中的传输成本，同时保持模型性能。

Conclusion: 通过结合学习型压缩和熵编码理论，有效解决了分割学习中的高通信成本问题，为隐私保护的多模态学习提供了高效解决方案。

Abstract: Split learning is well known as a method for resolving data privacy concerns by training a model on distributed devices, thereby avoiding data sharing that raises privacy issues. However, high network communication costs are always an impediment to split learning, especially for large foundation models that require transmitting large amounts of high-dimensional data. To resolve this issue, we present a new multimodal model structure that incorporates a learning-based data compression method, which compresses model embeddings into low-bit integers while preserving the model's performance, greatly reducing the transmission costs between partitions. We then determine the optimal number of discrete representation levels based on a solid theoretical foundation from entropy coding.

</details>


### [264] [LFM2 Technical Report](https://arxiv.org/abs/2511.23404)
*Alexander Amini,Anna Banaszak,Harold Benoit,Arthur Böök,Tarek Dakhran,Song Duong,Alfred Eng,Fernando Fernandes,Marc Härkönen,Anne Harrington,Ramin Hasani,Saniya Karwa,Yuri Khrustalev,Maxime Labonne,Mathias Lechner,Valentine Lechner,Simon Lee,Zetian Li,Noel Loo,Jacob Marks,Edoardo Mosca,Samuel J. Paech,Paul Pak,Rom N. Parnichkun,Alex Quach,Ryan Rogers,Daniela Rus,Nayan Saxena,Bettina Schlager,Tim Seyde,Jimmy T. H. Smith,Aditya Tadimeti,Neehal Tumma*

Main category: cs.LG

TL;DR: LFM2是一系列专为边缘设备设计的液体基础模型，通过硬件感知架构搜索实现高效部署，支持多模态和检索任务，提供350M-8.3B参数规模，在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决在边缘设备上部署大型语言模型时面临的计算资源限制、内存约束和延迟问题，需要开发既能保持强大任务能力又能在资源受限环境下高效运行的模型。

Method: 采用硬件感知的架构搜索，结合门控短卷积和分组查询注意力块构建混合骨干网络；使用温度调节的解耦Top-K知识蒸馏、课程学习以及三阶段后训练（监督微调、长度归一化偏好优化、模型合并）的训练流程。

Result: LFM2模型在多项基准测试中表现优异，如LFM2-2.6B在IFEval达到79.56%，GSM8K达到82.41%；支持多模态和检索变体，在边缘设备上实现2倍于同类模型的预填充和解码速度。

Conclusion: LFM2系列模型为边缘应用提供了实用基础，通过高效的架构设计和训练方法，在保持强大任务能力的同时实现了快速、内存高效推理，并开源了权重和部署包。

Abstract: We present LFM2, a family of Liquid Foundation Models designed for efficient on-device deployment and strong task capabilities. Using hardware-in-the-loop architecture search under edge latency and memory constraints, we obtain a compact hybrid backbone that combines gated short convolutions with a small number of grouped query attention blocks, delivering up to 2x faster prefill and decode on CPUs compared to similarly sized models. The LFM2 family covers 350M-8.3B parameters, including dense models (350M, 700M, 1.2B, 2.6B) and a mixture-of-experts variant (8.3B total, 1.5B active), all with 32K context length. LFM2's training pipeline includes a tempered, decoupled Top-K knowledge distillation objective that avoids support mismatch; curriculum learning with difficulty-ordered data; and a three-stage post-training recipe of supervised fine-tuning, length-normalized preference optimization, and model merging. Pre-trained on 10-12T tokens, LFM2 models achieve strong results across diverse benchmarks; for example, LFM2-2.6B reaches 79.56% on IFEval and 82.41% on GSM8K. We further build multimodal and retrieval variants: LFM2-VL for vision-language tasks, LFM2-Audio for speech, and LFM2-ColBERT for retrieval. LFM2-VL supports tunable accuracy-latency tradeoffs via token-efficient visual processing, while LFM2-Audio separates audio input and output pathways to enable real-time speech-to-speech interaction competitive with models 3x larger. LFM2-ColBERT provides a low-latency encoder for queries and documents, enabling high-performance retrieval across multiple languages. All models are released with open weights and deployment packages for ExecuTorch, llama.cpp, and vLLM, making LFM2 a practical base for edge applications that need fast, memory-efficient inference and strong task capabilities.

</details>


### [265] [Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation](https://arxiv.org/abs/2511.23440)
*Bernhard Klein,Falk Selker,Hendrik Borras,Sophie Steger,Franz Pernkopf,Holger Fröning*

Main category: cs.LG

TL;DR: 提出PFP方法高效近似贝叶斯神经网络，通过高斯分布假设实现单次前向传播的不确定性估计，结合TVM编译器在ARM CPU上部署，相比传统SVI实现4200倍加速。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在安全关键场景中因不确定性处理能力有限而受限，贝叶斯神经网络能提供概率估计但计算成本过高，需要高效近似方法在资源受限设备上部署。

Method: 提出概率前向传播(PFP)方法，假设权重和激活值服从高斯分布，实现完全解析的不确定性传播，用单次确定性前向传播替代采样；结合TVM深度学习编译器，实现高斯传播算子的专用库，采用手动和自动调优策略。

Result: PFP在计算效率上显著优于SVI，小批量数据上实现高达4200倍的加速；在Dirty-MNIST数据集上，PFP-BNNs在准确率、不确定性估计和OOD检测方面与SVI-BNNs相当，同时大幅降低计算成本。

Conclusion: 将贝叶斯近似与代码生成相结合，能够在资源受限系统上高效部署BNNs，为安全关键应用中的不确定性感知机器学习提供了实用解决方案。

Abstract: Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.

</details>


### [266] [ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts](https://arxiv.org/abs/2511.23442)
*Hang Yu,Di Zhang,Qiwei Du,Yanping Zhao,Hai Zhang,Guang Chen,Eduardo E. Veas,Junqiao Zhao*

Main category: cs.LG

TL;DR: ASTRO是一个用于离线强化学习的数据增强框架，通过生成分布新颖且动态一致的轨迹来解决子优和碎片化数据集中的奖励传播问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习从预收集的数据集中学习最优策略，但包含子优和碎片化轨迹的数据集给奖励传播带来挑战，导致价值估计不准确和策略性能下降。现有的基于生成模型的轨迹拼接方法要么局限于行为策略的支持，要么违反底层动态，限制了策略改进的效果。

Method: ASTRO首先学习时间距离表示来识别不同且可达的拼接目标，然后采用动态引导的拼接规划器，通过Rollout Deviation Feedback（目标状态序列与实际到达状态序列之间的差距）自适应生成连接动作序列，提高轨迹拼接的可行性和可达性。

Result: ASTRO在各种算法上优于先前的离线RL增强方法，在具有挑战性的OGBench套件上实现了显著的性能提升，并在标准离线RL基准测试（如D4RL）上展示了一致的改进。

Conclusion: ASTRO通过生成分布新颖且动态一致的轨迹，有效解决了离线强化学习中子优和碎片化数据集带来的挑战，显著提升了策略学习性能。

Abstract: Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.

</details>


### [267] [Provable Benefits of Sinusoidal Activation for Modular Addition](https://arxiv.org/abs/2511.23443)
*Tianlong Huang,Zhiyuan Li*

Main category: cs.LG

TL;DR: 本文研究激活函数在学习模加法中的作用，发现正弦网络比ReLU网络在表达能力和泛化能力上表现更优，正弦网络只需宽度2即可精确实现模加法，而ReLU网络需要宽度随模数线性增长。


<details>
  <summary>Details</summary>
Motivation: 研究不同激活函数（特别是正弦和ReLU）在模加法学习任务中的表现差异，探索激活函数对神经网络表达能力和泛化能力的影响。

Method: 首先建立表达能力的理论界限，比较正弦MLP和ReLU网络在模加法任务中的宽度需求；然后为正弦网络提供Natarajan维度的泛化界限；最后通过实验验证理论结果。

Result: 正弦网络只需宽度2即可精确实现任意固定长度的模加法，带偏置时甚至能统一处理所有长度；而ReLU网络宽度需随模数线性增长。正弦网络具有近乎最优的样本复杂度，实验显示其在各种情况下都比ReLU网络泛化更好，并表现出强大的长度外推能力。

Conclusion: 正弦激活函数在模加法学习中具有显著优势，不仅表达能力更强，泛化性能也更好，这为神经网络激活函数的选择提供了重要理论依据。

Abstract: This paper studies the role of activation functions in learning modular addition with two-layer neural networks. We first establish a sharp expressivity gap: sine MLPs admit width-$2$ exact realizations for any fixed length $m$ and, with bias, width-$2$ exact realizations uniformly over all lengths. In contrast, the width of ReLU networks must scale linearly with $m$ to interpolate, and they cannot simultaneously fit two lengths with different residues modulo $p$. We then provide a novel Natarajan-dimension generalization bound for sine networks, yielding nearly optimal sample complexity $\widetilde{\mathcal{O}}(p)$ for ERM over constant-width sine networks. We also derive width-independent, margin-based generalization for sine networks in the overparametrized regime and validate it. Empirically, sine networks generalize consistently better than ReLU networks across regimes and exhibit strong length extrapolation.

</details>


### [268] [Physics-Informed Neural Networks for Thermophysical Property Retrieval](https://arxiv.org/abs/2511.23449)
*Ali Waseem,Malcolm Mielle*

Main category: cs.LG

TL;DR: 提出基于物理信息神经网络(PINN)的迭代框架，从热成像图估计墙体热导率k，无需侵入式测量或长时间观测


<details>
  <summary>Details</summary>
Motivation: 现有测量热导率的方法要么是侵入式的，要么需要长时间观测，或者对环境条件敏感。需要一种非侵入、快速、可靠的在位测量方法，特别是用于评估建筑外墙改造后的节能效果

Method: 提出PINN迭代框架：交替进行1)固定k时用PINN求解正向热传导问题，2)通过比较热成像图和PINN预测的表面温度来优化k，重复直到k收敛

Result: 在不同环境条件和数据采集时间下都能准确预测k，前提是黎明时墙体温度分布接近稳态。即使违反稳态假设，最大MAE仅为4.0851

Conclusion: PINN方法为在位材料性能评估提供了可靠途径，无需长时间测量。该工作是机器学习特别是PINN用于解决在位逆问题的起点

Abstract: Inverse heat problems refer to the estimation of material thermophysical properties given observed or known heat diffusion behaviour. Inverse heat problems have wide-ranging uses, but a critical application lies in quantifying how building facade renovation reduces thermal transmittance, a key determinant of building energy efficiency. However, solving inverse heat problems with non-invasive data collected in situ is error-prone due to environmental variability or deviations from theoretically assumed conditions. Hence, current methods for measuring thermal conductivity are either invasive, require lengthy observation periods, or are sensitive to environmental and experimental conditions. Here, we present a PINN-based iterative framework to estimate the thermal conductivity k of a wall from a set of thermographs; our framework alternates between estimating the forward heat problem with a PINN for a fixed k, and optimizing k by comparing the thermographs and surface temperatures predicted by the PINN, repeating until the estimated k's convergence. Using both environmental data captured by a weather station and data generated from Finite-Volume-Method software simulations, we accurately predict k across different environmental conditions and data collection sampling times, given the temperature profile of the wall at dawn is close to steady state. Although violating the steady-state assumption impacts the accuracy of k's estimation, we show that our proposed framework still only exhibits a maximum MAE of 4.0851. Our work demonstrates the potential of PINN-based methods for reliable estimation of material properties in situ and under realistic conditions, without lengthy measurement campaigns. Given the lack of research on using machine learning, and more specifically on PINNs, for solving in-situ inverse problems, we expect our work to be a starting point for more research on the topic.

</details>


### [269] [The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference](https://arxiv.org/abs/2511.23455)
*Hans Gundlach,Jayson Lynch,Matthias Mertens,Neil Thompson*

Main category: cs.LG

TL;DR: 该研究分析了AI模型基准测试的成本变化，发现前沿模型在知识、推理、数学和软件工程基准上的性能成本每年下降5-10倍，其中算法效率提升贡献约3倍的年增长率。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在高级基准测试上取得了巨大进展，但这些进展往往依赖于更昂贵的模型，导致基准测试可能扭曲了实际能力与成本之间的关系。研究者希望了解AI基准测试性能的实际成本变化趋势。

Method: 使用Artificial Analysis和Epoch AI的数据构建了迄今为止最大的当前和历史基准测试价格数据集，分析不同基准测试的性能成本变化，并分离出经济因素、硬件效率改进和算法效率改进的影响。

Result: 研究发现，前沿模型在知识、推理、数学和软件工程基准测试上达到特定性能水平的成本下降速度惊人，约为每年5-10倍。通过控制竞争效应和硬件价格下降，估计算法效率进步约为每年3倍。

Conclusion: AI推理成本正在快速下降，基准测试应考虑价格因素以更准确地衡量AI的实际影响。建议评估者公开并考虑基准测试的价格，作为衡量AI现实世界影响的重要组成部分。

Abstract: Language models have seen enormous progress on advanced benchmarks in recent years, but much of this progress has only been possible by using more costly models. Benchmarks may therefore present a warped picture of progress in practical capabilities per dollar. To remedy this, we use data from Artificial Analysis and Epoch AI to form the largest dataset of current and historical prices to run benchmarks to date. We find that the price for a given level of benchmark performance has decreased remarkably fast, around $5\times$ to $10\times$ per year, for frontier models on knowledge, reasoning, math, and software engineering benchmarks. These reductions in the cost of AI inference are due to economic forces, hardware efficiency improvements, and algorithmic efficiency improvements. Isolating out open models to control for competition effects and dividing by hardware price declines, we estimate that algorithmic efficiency progress is around $3\times$ per year. Finally, we recommend that evaluators both publicize and take into account the price of benchmarking as an essential part of measuring the real-world impact of AI.

</details>


### [270] [SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments](https://arxiv.org/abs/2511.23465)
*Xinyi Li,Zaishuo Xia,Weyl Lu,Chenjie Hao,Yubei Chen*

Main category: cs.LG

TL;DR: 提出SmallWorld Benchmark用于系统评估世界模型在可控环境下的动态建模能力，测试了多种代表性架构在六个领域的表现，揭示了当前模型的优势和局限。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型缺乏统一可控的评估环境，难以判断它们是否真正掌握了环境动态的底层规则。为了解决这一开放挑战，需要建立一个系统性的测试基准。

Method: 引入SmallWorld Benchmark测试平台，在完全可观测状态空间中对代表性架构（包括循环状态空间模型、Transformer、扩散模型和神经ODE）进行综合实验，在六个不同领域中评估其表现。

Result: 实验结果显示这些模型捕捉环境结构的效果，以及它们在长期推演中预测性能的衰减情况，揭示了当前建模范式的优势和局限性。

Conclusion: 该基准为世界模型评估提供了系统框架，指出了当前模型的不足，并为表示学习和动态建模的未来改进方向提供了见解。

Abstract: Current world models lack a unified and controlled setting for systematic evaluation, making it difficult to assess whether they truly capture the underlying rules that govern environment dynamics. In this work, we address this open challenge by introducing the SmallWorld Benchmark, a testbed designed to assess world model capability under isolated and precisely controlled dynamics without relying on handcrafted reward signals. Using this benchmark, we conduct comprehensive experiments in the fully observable state space on representative architectures including Recurrent State Space Model, Transformer, Diffusion model, and Neural ODE, examining their behavior across six distinct domains. The experimental results reveal how effectively these models capture environment structure and how their predictions deteriorate over extended rollouts, highlighting both the strengths and limitations of current modeling paradigms and offering insights into future improvement directions in representation learning and dynamics modeling.

</details>


### [271] [ThetaEvolve: Test-time Learning on Open Problems](https://arxiv.org/abs/2511.23473)
*Yiping Wang,Shao-Rong Su,Zhiyuan Zeng,Eva Xu,Liliang Ren,Xinyu Yang,Zeyi Huang,Xuehai He,Luyao Ma,Baolin Peng,Hao Cheng,Pengcheng He,Weizhu Chen,Shuohang Wang,Simon Shaolei Du,Yelong Shen*

Main category: cs.LG

TL;DR: ThetaEvolve是一个开源框架，通过简化并扩展AlphaEvolve，结合上下文学习和强化学习，使小型开源模型能在开放优化问题上取得新的最佳边界。


<details>
  <summary>Details</summary>
Motivation: AlphaEvolve虽然取得了数学发现突破，但它是闭源系统，依赖前沿LLM集成，且是纯推理系统无法内化演化策略。需要开源框架让小型模型也能在开放问题上取得突破。

Method: ThetaEvolve采用单一LLM、大型程序数据库增强探索、批量采样提高吞吐量、惰性惩罚避免停滞输出、可选奖励塑形提供稳定训练信号，支持测试时上下文学习和强化学习。

Result: ThetaEvolve首次让小型开源模型（如DeepSeek-R1-0528-Qwen3-8B）在AlphaEvolve提到的开放问题（圆填充和自相关不等式）上取得新的最佳边界。在两个模型和四个开放任务中，测试时强化学习始终优于纯推理基线。

Conclusion: ThetaEvolve是一个有效的开源演化框架，使小型模型能够学习演化能力，在训练任务和未见任务上都表现出更快的进展和更好的最终性能，推动了数学发现的民主化。

Abstract: Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve

</details>
