<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 17]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [cs.LG](#cs.LG) [Total: 81]
- [quant-ph](#quant-ph) [Total: 70]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Buchdahl limits in theories with regular black holes](https://arxiv.org/abs/2512.19796)
*Pablo Bueno,Robie A. Hennigar,Ángel J. Murcia,Aitor Vicente-Cano*

Main category: gr-qc

TL;DR: 研究D维爱因斯坦引力耦合高阶曲率修正理论中完美流体星的紧致度极限，发现这些理论中的星体可以比爱因斯坦引力中的星体更紧致，但需要额外条件来避免曲率发散。


<details>
  <summary>Details</summary>
Motivation: 研究高阶曲率修正理论（特别是拟拓扑理论）中星体结构的紧致度极限，探索这些理论是否允许比传统爱因斯坦引力中更紧致的星体存在。

Method: 解析求解常密度星体问题，分析解空间的边界条件；研究更一般的密度随半径递减的完美流体星，推导最大紧致度条件；比较不同理论中的星体紧致度。

Result: 发现解空间由三个边界界定：发散中心压力的最紧致星体、零中心压力的星体、以及尺寸与正则黑洞内视界半径重合的星体；在某些条件下找到了新的Buchdahl极限；这些理论中的星体可以比爱因斯坦引力中更紧致。

Conclusion: 高阶曲率修正理论允许比爱因斯坦引力中更紧致的星体存在，但需要施加额外条件（如主导能量条件）来避免曲率发散问题，否则普通物质星体可能产生任意高的曲率。

Abstract: We study generalizations of Buchdahl's compactness limits for perfect-fluid star solutions of $D$-dimensional Einstein gravity coupled to higher-curvature corrections. We focus on Quasi-topological theories involving infinite towers of terms for which the unique vacuum spherically symmetric solutions correspond to regular black holes. We solve analytically the problem of constant-density stars and find that the space of solutions is bounded by: configurations with divergent central-pressure, corresponding to the most compact stars; configurations which possess zero central-pressure; and configurations for which the sizes of the stars coincide with the inner-horizon radii of the would-be regular black holes. In the more general case of perfect-fluid stars for which the mean density decreases with increasing radius, we show that, for each density profile, maximum compactness is reached when the metric becomes singular at the center. Under certain additional conditions, we find a novel Buchdahl limit for the maximum compactness of stars, attained by a specific constant-density profile. We show, in particular, that stars in these theories may be more compact than in Einstein gravity. While the vacuum solutions of these theories are such that all curvature invariants take mass-independent maximum finite values, we argue that there exist ordinary matter stars with finite central pressures for which such bounds can be violated -- namely, arbitrarily high curvatures can be reached -- unless additional constraints, such as the dominant energy condition, are imposed on the fluid.

</details>


### [2] [Mass and entropy of asymptotically flat eternal quantum black holes in 2D](https://arxiv.org/abs/2512.19812)
*Jean Alexandre,Eleni-Alexandra Kontou,Diego Pardo Santos,Silvia Pla,Andrew Svesko*

Main category: gr-qc

TL;DR: 本文对(1+1)维半经典膨胀引力中的量子黑洞进行了全面分析，研究了质量、热力学性质，并在解析和数值上构建了永恒量子黑洞解。


<details>
  <summary>Details</summary>
Motivation: (1+1)维半经典膨胀引力是少数能够精确构建量子黑洞并完全考虑量子物质反作用的领域之一。研究量子黑洞的质量和热力学性质对于理解量子引力效应至关重要。

Method: 1. 解析研究：分析了一参数族解析可解模型（介于Russo-Susskind-Thorlacius和Bose-Parker-Peleg引力之间）的永恒量子黑洞解
2. 准局域形式：将黑洞限制在有限大小的腔中，推导守恒能量并分析热行为
3. 数值构造：数值构建了半经典Callan-Giddings-Harvey-Strominger引力的永恒黑洞解
4. 解析展开：开发了解析展开方法，在半经典极限下准确近似数值解

Result: 1. 在Boulware态中，量子场可能存在裸奇点
2. 半经典Wald熵精确等于广义熵（包含引力和精细物质熵）
3. 发现量子黑洞在某个范围内是热稳定的
4. 数值构建的CGHS黑洞的热行为与解析模型有质的不同
5. 解析展开在半经典极限下能准确近似完整数值解

Conclusion: 本文提供了(1+1)维半经典膨胀引力中量子黑洞的全面分析框架，建立了解析和数值方法，揭示了量子黑洞的热力学性质，并展示了不同模型间的差异，为量子引力研究提供了重要见解。

Abstract: Semi-classical dilaton gravity in (1+1)-dimensions remains one of the only arenas where quantum black holes can be exactly constructed, fully accounting for backreaction due to quantum matter. Here we provide a comprehensive analysis of the mass and thermodynamic properties of static asymptotically flat quantum black holes both analytically and numerically. First, we analytically investigate eternal quantum black hole solutions to a one-parameter family of analytically solvable models interpolating between Russo-Susskind-Thorlacius and Bose, Parker, and Peleg gravities. Examining these models in a semi-classically allowed parameter space, we find naked singularities may exist for quantum fields in the Boulware state. Using a quasi-local formalism, where we confine the black hole to a finite sized cavity, we derive the conserved energy and analyze the system's thermal behavior. Specifically, we show the semi-classical Wald entropy precisely equals the generalized entropy, accounting for both gravitational and fine grained matter entropies, and we find a range where the quantum black holes are thermally stable. Finally, we numerically construct eternal black hole solutions to semi-classical Callan-Giddings-Harvey-Strominger gravity and find their thermal behavior is qualitatively different from their analytic counterparts. In the process, we develop an analytic expansion of the solutions and find it accurately approximates the full numerical solutions in the semi-classical limit.

</details>


### [3] [On the Stability of Anisotropic Neutron Stars](https://arxiv.org/abs/2512.19825)
*L. M. Becerra,E. A. Becerra-Vergara,F. D. Lora-Clavijo,J. F. Rodriguez*

Main category: gr-qc

TL;DR: 各向异性中子星模型研究：使用三种各向异性压力模型和三种状态方程，通过非线性相对论模拟评估稳定性，发现各向异性可提升最大质量约30%，但标准转折点准则不一定可靠预测不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究各向异性压力对中子星结构和稳定性的影响，探索各向异性如何改变最大质量、稳定性和引力波特征，特别是验证标准转折点准则在各向异性情况下的可靠性。

Method: 采用三种各向异性压力模型（Horvat、Bowers-Liang、Covariant）和三种不同粒子组成的状态方程（分段多方参数化），通过完全非线性相对论代码进行动力学演化，评估稳定性并计算振荡谱。

Result: 各向异性可使稳定构型的最大质量比各向同性情况增加约30%；Bowers-Liang和Covariant模型在较低中心密度下就不稳定，表明标准转折点准则不可靠；确定中性稳定线，右侧构型确实不稳定并坍缩；紧凑星可能初始模拟黑洞引力波环降，但后续回声产生取决于具体内部结构。

Conclusion: 压力各向异性显著影响中子星稳定性和结构，标准转折点准则不适用于各向异性情况；各向异性允许更紧凑的稳定构型，可能产生类似黑洞的引力波特征，但后续回声依赖于具体内部结构而非仅紧凑度。

Abstract: We model anisotropic neutron stars using three distinct prescriptions for pressure anisotropy, the Horvat, Bowers-Liang, and Covariant models, and three equations of state with different particle compositions, each described by a piecewise polytropic parametrization with continuous sound speed. The stability of these configurations is assessed through their dynamical evolution using a fully non-linear relativistic code. For stable configurations, we compute the oscillation spectrum and identify the fundamental mode frequency. We found that, while the isotropic and Horvat models become unstable close to the maximum-mass point, the Bowers-Liang and Covariant models become unstable at lower central densities, indicating that the standard turning-point criterion may not reliably predict the onset of dynamical instability in anisotropic stars. Based on our results, we also determine the neutral-stability line and verify that configurations lying to the right of this line are indeed unstable under radial perturbations and collapse. Overall, given an equation of state, pressure anisotropy can increase the maximum mass of an stable configuration by up to ~30 % compared to the isotropic case. It also allows for more compact stable configurations that may collapse on longer timescales once they become unstable. Finally, we show that these compact stars could initially mimic a black hole's gravitational-wave ringdown. However, the production of subsequent echoes is not guaranteed by high compactness; instead, it depends critically on the star's specific internal structure and equation of state.

</details>


### [4] [Gauge-invariant Bardeen variables for plane waves and their relation to Cartan and Killing invariants](https://arxiv.org/abs/2512.19828)
*R. Radhakrishnan,D. McNutt,D. Mirfendereski,E. Davis,W. Julius,G. Cleaver*

Main category: gr-qc

TL;DR: 本文比较了Bardeen规范不变形式与Cartan-Karlhede不变量在平面引力波分析中的应用，发现Bardeen变量与Killing不变量对应物理引力波自由度，而CK不变量无法区分⊕和×极化模式。


<details>
  <summary>Details</summary>
Motivation: 传统上使用Newman-Penrose形式分析引力波极化，而Bardeen规范不变形式提供了基于度规扰动的标量、矢量和张量分解的互补描述。本文旨在将Bardeen形式应用于Minkowski时空中的平面引力波，并与Cartan-Karlhede不变量进行比较。

Method: 1) 将Bardeen规范不变形式应用于Minkowski时空中的平面引力波，显式计算所有标量、矢量和张量规范不变量；2) 使用线性化Cartan-Karlhede算法构造曲率不变量；3) 比较Bardeen变量与CK不变量，并建立Bardeen变量与Killing不变量的联系。

Result: 1) 对于真空引力波，只有两个横向无迹张量模式存活，符合广义相对论预期；2) CK不变量无法区分⊕和×极化模式；3) Bardeen变量与通过将度规扰动投影到Minkowski背景的平移Killing矢量上得到的Killing不变量一致。

Conclusion: 在平面引力波情况下，物理引力波自由度编码在由Killing矢量场生成的不变量中，而不是Cartan不变量中。Bardeen变量提供了与Killing不变量对应的物理描述，而CK不变量在区分极化模式方面存在局限性。

Abstract: The Newman-Penrose (NP) formalism is traditionally used to analyze the polarization content of gravitational waves, while the gauge-invariant Bardeen formalism provides a complementary, and often simpler, description based on the irreducible scalar, vector, and tensor perturbations of the metric. In this work we apply the Bardeen formalism to plane gravitational waves in Minkowski spacetime, computing all scalar, vector, and tensor gauge-invariant variables explicitly and demonstrating that only the two transverse-traceless tensor modes survive, as expected for vacuum waves in general relativity.
  We then compare these Bardeen variables with curvature-based invariants constructed using the linearized Cartan--Karlhede (CK) algorithm. We show that the CK invariants do not distinguish the $\oplus$ and $\times$ modes. Instead, we show that the Bardeen variables coincide with the Killing invariants obtained by projecting the metric perturbation onto the translational Killing vectors of the Minkowski background. Thus, in the plane-wave case, the physical gravitational-wave degrees of freedom are encoded in invariants generated from the Killing vector fields, rather than Cartan invariants.

</details>


### [5] [A Closer Look at Natário's Zero-Expansion Warp Drive](https://arxiv.org/abs/2512.19837)
*José Rodal*

Main category: gr-qc

TL;DR: Natário曲速驱动时空的详细分析：证明其为Petrov I型，Weyl曲率在曲速泡区域起重要作用，曲率不变量振幅比Alcubierre大35倍，Mattingly等人的分析低估了21个数量级。


<details>
  <summary>Details</summary>
Motivation: 对Natário的"零膨胀"曲速驱动时空进行详细分析，填补文献中Petrov类型分类的空白，评估Weyl曲率的重要性（之前研究被忽视），可视化曲率不变量，并批判性评估Natário曲速驱动比Alcubierre更现实的声称。

Method: 使用3+1形式主义分析标量曲率不变量，确定Natário时空的Petrov类型分类，计算和比较Weyl标量曲率不变量与爱因斯坦标量、Ricci二次和三次不变量的相对大小，可视化曲率不变量和动量密度。

Result: 1. 证明Natário时空是Petrov I型，不属于Class B扭曲积时空；2. Weyl曲率在曲速泡区域起重要作用；3. 动量密度是控制曲速驱动轨迹方向的关键物理量；4. Natário时空的曲率不变量振幅比Alcubierre大35倍；5. Mattingly等人的分析低估了21个数量级。

Conclusion: Natário曲速驱动时空实际上比Alcubierre更不现实，因为其曲率不变量振幅大得多，Weyl曲率在曲速泡区域起重要作用，且动量密度而非空间体积变化主导轨迹方向。

Abstract: We conduct a detailed analysis of Nat'{a}rio's ``zero-expansion'' warp drive spacetime, focusing on scalar curvature invariants within the 3+1 formalism. This paper has four primary objectives: First, we establish the Petrov type classification of Nat'{a}rio's spacetime, which has not been previously determined in the literature. We prove that Nat'{a}rio's spacetime is Petrov type I, not fitting the Class B warped product spacetime definition. Second, we assess the relative magnitude of the Weyl scalar curvature invariant and compare it with the amplitudes of Einstein's scalar and the Ricci quadratic and cubic invariants within the warp-bubble zone. Previous studies have focused on Ricci curvature and the energy-momentum tensor, neglecting the Weyl curvature, which we demonstrate plays a significant role due to the sharp localization of the form function near the warp-bubble radius. Third, we visualize several curvature invariants for Nat'{a}rio's warp drive, as well as momentum density, which we show as the critical physical quantity governing the orientation of the warp drive trajectory, overshadowing space volume changes. Fourth, we critically examine claims that Nat'{a}rio's warp drive is more realistic than Alcubierre's. We demonstrate that Nat'{a}rio's spacetime exhibits curvature invariant amplitudes 35 times greater than Alcubierre's, given identical warp-bubble parameters, making Nat'{a}rio's concept even less viable. Additionally, we address Mattingly et al.'s analysis, highlighting their underestimation of curvature invariant amplitudes by 21 orders of magnitude.

</details>


### [6] [Dissipative cosmology with $Λ$ from the first law of thermodynamics](https://arxiv.org/abs/2512.19911)
*Nobuyoshi Komatsu*

Main category: gr-qc

TL;DR: 论文提出一个包含宇宙学常数Λ和耗散项β(2H²+Ḣ)的宇宙学模型，通过热力学第一定律推导，支持从减速到加速宇宙的转变，与观测数据一致。


<details>
  <summary>Details</summary>
Motivation: 在物质创生宇宙学框架下，通过热力学第一定律推导包含耗散效应的宇宙学模型，解释宇宙加速膨胀现象，并探讨热力学约束条件。

Method: 应用热力学第一定律到物质创生宇宙学，推导出包含Λ/3和耗散项β(2H²+Ḣ)的宇宙学模型。耗散项与Ricci标量曲率成正比，表明动态创生压力具有相同依赖关系。分析模型在晚期宇宙的背景演化、视界热力学，并使用观测哈勃参数数据进行约束。

Result: 当β<0.5时，模型支持从减速宇宙到加速宇宙的转变。视界热力学第二定律始终满足，熵在最终阶段达到最大化。观测约束表明弱耗散宇宙与Λ项的组合与我们的宇宙一致。

Conclusion: 提出的包含宇宙学常数和耗散项的模型能够解释宇宙加速膨胀，满足热力学约束，并与观测数据相符。同时探讨了全息类物质创生宇宙学中的不可逆熵产生。

Abstract: We phenomenologically derive a cosmological model that includes both a cosmological constant term $Λ/3$ and a dissipative driving term $β(2 H^{2} + \dot{H})$ by applying the first law of thermodynamics to matter creation cosmology. Here $H$, $\dot{H}$, and $β$ are the Hubble parameter, the time derivative of $H$, and a non-negative dimensionless coefficient, respectively. The dissipative term is proportional to the Ricci scalar curvature, suggesting that the dynamic creation pressure has the same dependence. We examine the model's background evolution in the late universe and its horizon thermodynamics. The present model supports a transition from a decelerating universe to an accelerating universe when $β<0.5$. The second law of thermodynamics is always satisfied on the horizon, and maximization of entropy is satisfied in the final stage. We examine constraints on the present model using observed Hubble parameter data and the transitional and thermodynamic constraints and find that a weakly dissipative universe with $Λ$ is likely favored and consistent with our Universe. We also discuss irreversible entropy due to adiabatic particle creation, assuming a holographic-like matter creation cosmology.

</details>


### [7] [Measuring Eccentricity and Addressing Waveform Systematics in GW231123](https://arxiv.org/abs/2512.20060)
*Aasim Jan,Sophia Nicolella,Deirdre Shoemaker,Richard O'Shaughnessy*

Main category: gr-qc

TL;DR: 对GW231123_135430引力波事件的重新分析表明，该系统没有明显的偏心轨道证据，参数估计差异主要源于波形模型在强自旋进动下的不一致性。


<details>
  <summary>Details</summary>
Motivation: GW231123_135430是目前观测到的最重双黑洞系统，其黑洞质量可能位于或超过理论上的对不稳定性质量间隙（60-130太阳质量），且具有高自旋。这暗示了超出标准恒星坍缩的形成机制，但不同波形模型给出的参数估计差异很大，可能源于模型中缺失的物理效应。

Method: 使用包含自旋进动和偏心轨道的完整物理模型重新分析GW231123事件。通过零噪声注入恢复研究来评估参数偏差，并进行贝叶斯模型选择来比较不同假设（偏心轨道vs自旋进动）。

Result: 1. GW231123事件没有表现出强烈的偏心轨道证据，排除偏心轨道对参数推断影响很小。2. 即使偏心率达到0.15（在10Hz时），也无法获得置信的非零偏心率测量。3. 参数估计的差异主要源于波形模型在强自旋进动下的不一致性。4. 使用偏心、自旋对齐的波形模型会产生虚假的非零偏心率测量，这是由于偏心率和自旋进动之间的简并性。5. 贝叶斯模型选择支持零偏心率的自旋进动假设。

Conclusion: GW231123事件很可能是一个具有高自旋但接近圆轨道的双黑洞系统。观测到的参数差异主要源于当前波形模型在处理强自旋进动系统时的局限性，而非真实的物理偏心轨道。这强调了在分析类似系统时使用完整物理模型的重要性。

Abstract: The gravitational-wave event GW231123_135430 is the heaviest binary black hole system observed by the LIGO--Virgo--KAGRA Collaboration to date, with the initial analysis indicating the individual black hole masses lie within or above the theorized pair-instability mass gap of roughly $60$--$130\,M_\odot$. The inference further suggests that both black holes possess high spins, measured to be $0.90^{+0.10}_{-0.19}$ and $0.80^{+0.20}_{-0.51}$. Therefore, the observation of this event suggests the formation of black holes from channels beyond the standard stellar collapse. However, different waveform models yield significantly different parameter estimates, possibly due to missing physics in the models used in inference. In this work, we carry out a reanalysis of GW231123 using a physically complete model, accounting for both spin precession and eccentricity. Our analysis shows that this event does not exhibit strong evidence for eccentricity and the exclusion of eccentricity has minimal impact on inference. Furthermore, for GW231123-like systems, even eccentricities as large as $0.15$ at $10$ Hz do not yield a confident nonzero eccentricity measurement. Through a zero-noise injection recovery study, we show that the observed discrepancies in the parameter estimates can be explained by disagreement in the waveform models at strong spin precession, with the degree of parameter bias in the zero-noise runs being comparable to that observed for the real signal. We also show that inference performed with an eccentric, aligned-spin waveform model can yield a confident nonzero eccentricity measurement due to the degeneracy between eccentricity and spin precession. Bayesian model selection, however, rules out this interpretation in favor of the eccentric, spin precessing hypothesis, which supports zero eccentricity -- a conclusion we confirm with additional zero-noise injection-recovery tests.

</details>


### [8] [Entropy of matter on the Carroll geometry](https://arxiv.org/abs/2512.20304)
*Saurav Samanta,Bibhas Ranjan Majhi*

Main category: gr-qc

TL;DR: 本文通过两种构建Carroll几何的方法（近地平线展开和光速c趋于零的度规展开）分析理想气体熵，证明两者在热力学上互补


<details>
  <summary>Details</summary>
Motivation: 探索两种构建Carroll几何方法（近地平线展开和光速c趋于零的度规展开）之间的互补关系，从热力学角度验证这两种方法的等价性

Method: 使用光速c趋于零的度规展开方法构建Carroll几何，分析限制在盒子中且靠近地平线的理想气体熵，研究其与容器横向面积的关系

Result: 理想气体熵依赖于容器的横向面积，这一结果通过Carroll几何分析得到，证实了两种构建Carroll几何方法在热力学上的互补性

Conclusion: 两种构建Carroll几何的方法在热力学上是互补的，从熵的角度验证了这两种方法的等价性，增强了我们对Carroll几何构造的理解

Abstract: Two prescriptions, the expansion of near horizon of geometry and expansion of metric with zero limit of the expansion parameter $c$ (speed of light in vacuum), of constructing Carroll geometries are known to complement each other. The entropy of an ideal gas, confined in a box and kept very near to the horizon, depends on the transverse area of the container. We show this by using the Carroll geometry constructed through the expansion of the metric and then taking zero limit of the expansion parameter $c$. Therefore the present analysis re-assures the complementing nature of two ways of finding the Carroll geometry from the thermodynamical point of view.

</details>


### [9] [Nonsingular hairy black holes by gravitational decoupling](https://arxiv.org/abs/2512.20320)
*Yaobin Hua,Rong-Jia Yang*

Main category: gr-qc

TL;DR: 利用引力解耦构造具有事件视界且满足弱能量条件的无奇点毛状黑洞，连接Minkowski真空与经典Schwarzschild和Kerr解


<details>
  <summary>Details</summary>
Motivation: 传统黑洞解（如Schwarzschild和Kerr）通常假设真空或简单物质分布，缺乏更一般的物质场（"毛"）描述。本文旨在构造满足物理条件（事件视界、弱能量条件）的非奇异毛状黑洞解。

Method: 采用引力解耦方法，从Minkowski真空出发，通过变形构造球对称和轴对称的毛状黑洞解。要求解具有明确定义的事件视界，且源物质满足弱能量条件。

Result: 成功构造了非奇异的球对称和轴对称毛状黑洞解。这些解在最大变形极限下分别退化为经典的Schwarzschild和Kerr黑洞解，建立了新毛状几何与经典黑洞解之间的桥梁。

Conclusion: 引力解耦方法能够构造物理合理的毛状黑洞解，这些解在适当极限下恢复为经典黑洞解，为研究黑洞的"毛"提供了新的理论框架。

Abstract: Using gravitational decoupling under the requirements of a well-defined event horizon and the source matter satisfying the weak energy condition, we construct nonsingular hairy black holes with spherical or axial symmetry. These solutions emerge from a deformation of the Minkowski vacuum, bridging the novel hairy geometries and the classical Schwarzschild and Kerr solutions at the maximum deformation in their respective sectors.

</details>


### [10] [Electromagnetic Sources Teleparallel Robertson--Walker $F(T)$-Gravity Solutions](https://arxiv.org/abs/2512.20337)
*Alexandre Landry*

Main category: gr-qc

TL;DR: 该论文研究了在电磁源存在下的teleparallel Robertson-Walker (TRW) F(T)引力解，针对不同曲率参数k(-1,0,+1)和电磁状态方程，得到了新的F(T)解。


<details>
  <summary>Details</summary>
Motivation: 研究在宇宙学电磁源存在下的teleparallel F(T)引力理论解，为未来宇宙学应用提供新的理论框架，特别是针对宇宙等离子体模型等电磁源过程。

Method: 使用并求解TRW F(T)引力场方程，针对每个k参数值(-1,0,+1)和电磁状态方程，推导新的teleparallel F(T)解。对于k=0情况，找到适用于任何尺度因子n的新解；对于k=±1情况，找到精确解和远未来近似解。

Result: 获得了新的teleparallel F(T)引力解：对于k=0宇宙学情况，得到适用于任何尺度因子n的新解；对于k=±1情况，得到精确解和远未来近似解，涵盖慢速、线性、快速和无限快速宇宙膨胀情况，所有解都以解析函数形式总结。

Conclusion: 所有新解对未来的宇宙学应用都具有重要意义，特别是涉及电磁源过程（如宇宙等离子体模型）的研究，为teleparallel F(T)引力理论在宇宙学中的应用提供了新的解析解。

Abstract: We investigate the teleparallel Robertson--Walker (TRW) $F(T)$-gravity solutions for a cosmological electromagnetic source in the current paper. We use and solve the TRW $F(T)$-gravity field equations (FEs) for each value of the $k$-parameter $(-1,\,0,\,+1)$ and the electromagnetic equivalent of the equation of state (EoS), leading to new teleparallel $F(T)$ solutions. For the $k=0$ cosmological case, we find new teleparallel $F(T)$ solutions for any scale factor $n$. For $k=\pm 1$ cosmological cases, we find exact and far-future approximated new teleparallel $F(T)$ solutions for slow, linear, fast and infinitely fast universe expansion summarized by analytical functions. All the new solutions are relevant for future cosmological applications, implying any electromagnetic source processes, such as the cosmological plasma models.

</details>


### [11] [Effective dynamics of Janis-Newman-Winicour spacetime](https://arxiv.org/abs/2512.20440)
*Faqiang Yuan,Shengzhi Li,Zhen Li,Yongge Ma*

Main category: gr-qc

TL;DR: 研究环量子引力启发的JNW时空有效动力学，比较两种正则化方案：μ₀方案中量子参数为常数，可解析求解运动方程，量子修正时空扩展了先前结果，通过量子反弹解决裸奇点和中心奇点；另一方案中量子参数为狄拉克可观测量，有效理论在时空中不始终有效。


<details>
  <summary>Details</summary>
Motivation: 研究环量子引力如何影响Janis-Newman-Winicour时空的动力学，探索不同正则化方案对时空奇点解析能力的影响，比较量子参数处理方式对有效理论有效性的影响。

Method: 采用两种方案正则化哈密顿约束：1) μ₀方案：量子参数视为常数，解析求解有效哈密顿量生成的运动方程；2) 量子参数作为狄拉克可观测量方案，基于μ₀方案解求解有效动力学。

Result: μ₀方案得到量子修正有效时空，明显扩展了先前文献结果，通过一系列量子反弹解决了经典JNW时空中的裸奇点和中心奇点；另一方案中由于时间重参数化函数零点出现，有效时空仍存在奇点，有效理论不适用于整个时空。

Conclusion: 量子参数处理方式对有效理论的有效性至关重要：μ₀方案能完全解析时空奇点，而量子参数作为狄拉克可观测量的方案无法在整个时空中保持有效，表明正则化方案的选择对环量子引力有效动力学有重要影响。

Abstract: The effective dynamics of the Janis-Newman-Winicour spacetime inspired by loop quantum gravity is studied. Two different schemes are considered to regularize the Hamiltonian constraint for the quantum dynamics. In the $μ_0$ scheme in which the quantum parameters are treated as constants, the equations of motion generated by the effective Hamiltonian are solved analytically. The resulting quantum-corrected effective spacetime obviously extends the effective spacetime previously obtained in the literature. In the new effective spacetime, the naked singularity and the central singularity presented in the classical JNW spacetime are resolved by a series of quantum bounces. In the scheme of choosing the quantum parameters as Dirac observables, the effective dynamics is also solved in the light of the solution in $μ_0$ scheme. It turns out that the resulting effective spacetime has singularities due to the appearance of the zero points of the time reparametrization functions. Hence, the effective theory in this scheme does not remain valid throughout the full spacetime.

</details>


### [12] [Black hole solutions with a linear equation of state in Hořava gravity and Einstein-Aether theory](https://arxiv.org/abs/2512.20445)
*Milko Estrada*

Main category: gr-qc

TL;DR: 本文提出了一种在Hořava引力和爱因斯坦以太理论中获取球对称静态以太黑洞解的方法论，通过指定状态方程形式而非能量密度分布，研究了三种线性状态方程对应的黑洞解，发现HG/AE项导致奇异的物理性质和热力学行为。


<details>
  <summary>Details</summary>
Motivation: 在Hořava引力和爱因斯坦以太理论中，由于HG/AE项的存在，传统的静态球对称情况下的状态方程ρ=-p_r不再成立。需要开发一种新的方法论来获得黑洞解，该方法从指定状态方程形式入手，而非传统的能量密度分布方法。

Method: 提出了一种方法论：首先指定状态方程的形式，而不是规定能量密度分布。研究了三种线性状态方程：(1)类似带电黑洞的状态方程；(2)非平凡极端黑洞的状态方程；(3)超相对论性刚体流体的状态方程。在球对称静态以太的框架下，分析这些状态方程对应的黑洞解。

Result: HG/AE项导致解具有奇异的物理性质和热力学行为。情况I：物质源可解释为奇异的各向异性物质分布，在几何中产生有效的电势项。情况II：获得了一个非平凡极端黑洞解，其事件视界具有n_odd重简并性。情况III：发现了一个具有非平凡排斥势的解，HG/AE项在短尺度上的影响导致形成包含中心奇点的黑洞残余（而非规则黑洞中的de Sitter核心）。

Conclusion: 该方法论成功地获得了Hořava引力和爱因斯坦以太理论中的黑洞解。HG/AE项显著改变了黑洞的物理性质，导致奇异的物质分布、非平凡的极端黑洞结构以及不同于常规黑洞的残余形成机制，这些发现对理解修正引力理论中的黑洞物理具有重要意义。

Abstract: We provide a methodology to obtain black hole (BH) solutions in Hořava gravity (HG) and Einstein Aether (AE) theory for the spherically symmetric (SS) case with a static aether. This methodology consists of first specifying the form of the equation of state (EoS), rather than prescribing an energy density profile. The usual EoS for the static and SS case, $ρ= -p_r$, is no longer satisfied due to the presence of the HG AE terms. We study three linear EoS associated with: an analogue charged BH, a non-trivial extremal BH, and an ultra-relativistic stiff fluid, respectively. The HG AE terms lead to exotic behaviors, both in the physical properties of the solutions and in their thermodynamics. In Case I, the matter sources can be interpreted as an exotic anisotropic matter distribution, giving rise to an effective electric-potential term in the geometry. In Case II, we obtain a non trivial extremal BH solution for which the event horizon is $n_{\text{odd}}$ fold degenerate. In Case III, we find a solution with a non trivial repulsive potential, where the influence of the HG AE terms at short scales leads to the formation of a BH remnant whose horizon encloses a central singularity (instead of a de Sitter core as occurs in regular BHs).

</details>


### [13] [Calibration Method of Spacecraft-Inertial Sensor Center-of-Mass Offset for the Taiji Gravitational Wave Detection Mission under Science Mode](https://arxiv.org/abs/2512.20468)
*Haoyue Zhang,Dong Ye,Peng Xu,Li-E Qiang,Ziren Luo*

Main category: gr-qc

TL;DR: 提出一种无需额外机动操作的质心偏移校准方案，利用标准科学模式测量数据，通过扩展状态自适应卡尔曼滤波器实现高精度连续校准。


<details>
  <summary>Details</summary>
Motivation: 空间引力波探测任务（如LISA和Taiji）中，航天器与惯性传感器测试质量块之间的质心偏移校准至关重要。现有方法需要额外机动操作，这会中断科学数据连续性和卫星间链路，影响引力波信号的相干性。

Method: 提出无机动校准方案，仅使用惯性传感器、干涉仪和差分波前传感器的标准科学模式测量数据。将质心偏移引起的耦合加速度作为扩展状态嵌入模型基自适应卡尔曼滤波器中进行估计。

Result: 在所有轴上实现0.01-1.5毫米的估计精度，最大误差低于1%。该方法可在正常观测运行期间实现连续高精度校准。

Conclusion: 该方法能够在不中断科学数据收集的情况下实现连续精确校准，确保引力波数据的连续性和相干性，同时支持高级DFACS功能，提升LISA类任务的科学产出和可靠性。

Abstract: Accurately calibrating the center-of-mass (CoM) offset between the spacecraft (SC) and the inertial sensor test mass (TM) is crucial for space-based gravitational-wave (GW) antennas, such as LISA and Taiji. Current calibration methods require additional spacecraft maneuvers that disrupt science data continuity and inter-satellite links, compromising the coherence of gravitational wave signals. Here, we present a maneuver-free calibration scheme that directly estimates the CoM offset vector using only standard science-mode measurements from inertial sensors, interferometers, and differential wavefront sensors. By embedding the CoM offset induced coupling acceleration as an extended state in a model-based adaptive Kalman filter, we achieve estimation accuracy of 0.01-1.5 mm across all axes with a maximum error below 1%. This approach enables continuous, high-precision calibration during nominal observation runs, ensuring continuous and coherent gravitational wave data collection while maintaining the required precision, and also facilitating advanced DFACS functions such as performance evaluations and fault diagnosis. For LISA-like missions, where data continuity is paramount for detecting faint gravitational wave signals, this method will enhance scientific output and reliability.

</details>


### [14] [Kerr Isolated Horizon Revisited: Caustic-Free Congruence and Adapted Tetrad](https://arxiv.org/abs/2512.20517)
*Aleš Flandera,David Kofroň,Tomáš Ledvinka*

Main category: gr-qc

TL;DR: 该论文重新审视了孤立视界形式下Kerr时空的近地平线描述，通过采用依赖于极角的Carter常数选择，避免了坐标和测地线奇点，构建了适用于孤立视界的Newman-Penrose标架和地平线适配坐标。


<details>
  <summary>Details</summary>
Motivation: 传统方法中当Carter运动常数全局固定为单一常数时，会出现坐标和测地线奇点问题。论文旨在消除这些病理现象，为Kerr黑洞在孤立视界方法中提供更完整、无奇点的描述。

Method: 采用依赖于极角的Carter常数选择，构建非扭曲零测地线汇，解析构造适应孤立视界的Newman-Penrose标架和地平线适配坐标。开发了两种互补的级数展开和数值方法。

Result: 成功构建了无奇点的解析解，计算了相关曲率标量，提供了孤立视界的特征初始数据。避免了焦散诱导的崩溃和不完整的坐标覆盖。

Conclusion: 该工作为Kerr黑洞在孤立视界方法中提供了详细、无奇点的描述，相对于早期处理具有更好的坐标覆盖和数值实用性。

Abstract: We revisit the near-horizon description of the Kerr space-time in the isolated horizon formalism using a non-twisting null geodesic congruence and eliminate the coordinate and geodesic pathologies that arise when the Carter constant of motion is globally fixed to a single constant. Adopting instead a previously proposed choice of the Carter constant which depends on the polar angle on the horizon, we obtain an analytic construction of the Newman--Penrose tetrad adapted to isolated horizons together with horizon-adapted coordinates in which its defining properties are manifest. We compute the associated curvature scalars and provide initial data on characteristics for the isolated horizon. In addition to an analytical solution, derived by leveraging extensive results on Kerr null geodesics, we develop two complementary series expansions and outline a practical numerical recipe to make the construction readily usable. Relative to earlier treatments, our formulation avoids caustic-induced breakdowns and incomplete coordinate coverage while yielding a detailed description of the Kerr black hole in the isolated horizon approach.

</details>


### [15] [Eckart heat-flux applicability in $F(Φ,X)R$ theories and the existence of temperature gradients](https://arxiv.org/abs/2512.20553)
*David S. Pereira,José Pedro Mimoso*

Main category: gr-qc

TL;DR: 在单标量场理论中，非最小耦合项F(Φ,X)会在标量共动系中产生额外的横向热流项，阻碍标准的Eckart流体解释，只有F_X=0的Jordan类理论才具有全局Eckart流体图像。


<details>
  <summary>Details</summary>
Motivation: 研究单标量场理论中非最小耦合项F(Φ,X)对有效热流的影响，探索何时能获得标准的Eckart流体解释，从而理解标量场理论的流体动力学描述。

Method: 分析形式为L=F(Φ,X)R+G(Φ,X)的单标量场理论，推导标量共动系中的有效热流表达式，特别关注由F(Φ,X)诱导的横向贡献项V_⊥a，并与Eckart热流公式进行比较。

Result: 发现非最小耦合项F(Φ,X)会产生额外的横向热流项(F_X/8πF)V_⊥a，该项通常不能表示为空间温度梯度。只有当F_X(Φ,X)=0时，即F(Φ,X)=F(Φ)的Jordan类理论，才能对所有类时标量构型获得全局Eckart流体图像。

Conclusion: 只有F_X=0的Horndeski子类理论才允许标量场的全局Eckart流体解释，而F_X≠0的理论只能在高度对称背景下恢复Eckart形式，这对标量场理论的流体动力学描述施加了重要限制。

Abstract: We show that in single--scalar theories of the form $\mathcal{L}=F(Φ,X)R+G(Φ,X)$, a generic nonminimal coupling $F(Φ,X)$ induces, in the scalar--comoving frame, an additional transverse contribution to the effective heat flux, proportional to $(F_X/8πF)V_{\perp a}$, where $V_a \equiv h_a{}^c\nabla_c\nabla_d X\,u^d$ and $V_{\perp a}$ denotes the component orthogonal to the 4--acceleration $a_a$. This new term, that is not present in $F(Φ)R$ scalar-tensor theories, cannot in general be written as a spatial temperature gradient, and therefore obstructs a standard Eckart interpretation of the scalar sector for arbitrary timelike scalar configurations. As a result, requiring an Eckart heat flux $q_a = -K\bigl(D_a T_g + T_g\, a_a\bigr)$ for all such configurations is possible if and only if $F_X(Φ,X)\equiv 0$, i.e.\ $F(Φ,X)=F(Φ)$, resulting in a theory that is a subclass of Horndeski. Thus, only Jordan--like theories of the type $F(Φ)R+G(Φ,X)$ admit a global Eckart fluid picture of the scalar sector, while models with $F_X\neq 0$ can recover an Eckart--like form only on highly symmetric backgrounds where the transverse contribution vanishes or collapses to a single gradient direction. We also make a brief comment on the existence of temperature gradients $D_aT_g$.

</details>


### [16] [Spin-induced quadrupole moment based test for eccentric binaries](https://arxiv.org/abs/2512.20579)
*N. V. Krishnendu*

Main category: gr-qc

TL;DR: 将黑洞自旋诱导四极矩检验方法扩展到偏心轨道双星系统，分析忽略轨道偏心率导致的系统误差及其对黑洞性质测试的影响


<details>
  <summary>Details</summary>
Motivation: 传统基于自旋诱导四极矩的黑洞性质检验方法假设圆形轨道，需要扩展到偏心轨道情况以更准确地分析真实双星信号

Method: 使用偏心双星波形模型TaylorF2Ecc，结合半解析Fisher矩阵方法和贝叶斯推断框架，分析当前和未来探测器网络中的系统误差

Result: 忽略初始偏心率e₀=0.1会导致严重的参数推断偏差，偏心轨道中等质量黑洞可能被误判为极端自旋的非黑洞系统

Conclusion: 在进行黑洞性质测试时忽略轨道偏心率会产生关键性偏差，需要将偏心效应纳入考虑以确保测试的准确性

Abstract: The spin-induced quadrupole moment-based test of black hole nature is routinely used to probe the true nature of detected binary signals, assuming a circular orbit. We extend the applicability of the method to binaries in eccentric orbits. Considering simulated signals of varying masses, spins, and signal strengths, we demonstrate how the systematic errors resulting from neglecting orbital eccentricity compare with the statistical errors, using a semi-analytic Fisher matrix-based formalism that accounts for both current and future detectors. Further, we quantify the systematic errors by developing a Bayesian inference framework for the current detector network. The inspiral-only aligned spin gravitational wave waveform model for eccentric binaries, TaylorF2Ecc, is employed. For the current detector network, neglecting an initial eccentricity of $e_0^{\rm inj}=0.1$ defined at $20\,\mathrm {Hz} $ can lead to a serious bias in binary parameter inference. Notably, a nearly equal-mass, moderately spinning binary black hole in an eccentric orbit can be identified as a non-black hole binary with extreme spins and asymmetric masses. We demonstrate the criticality of biased estimates that may arise when neglecting the orbital eccentricity while performing tests of black hole nature and discuss prospects.

</details>


### [17] [Squeezed States in Gravity](https://arxiv.org/abs/2512.20601)
*Arunima Das,Maulik Parikh,Frank Wilczek,Raphaela Wutte*

Main category: gr-qc

TL;DR: 提出了一个在量子引力中产生引力场压缩态的一般框架，通过线性化量子引力中的时间依赖耦合从真空产生压缩态


<details>
  <summary>Details</summary>
Motivation: 研究如何在量子引力中产生压缩量子态，探索引力场量子态的产生机制

Method: 使用线性化量子引力框架，通过二次作用量中的时间依赖耦合产生压缩态，以谐振子为例展示三种获取压缩参数的技术

Result: 时间依赖的经典时空和物质源都能产生引力压缩态，背景曲率和物质源的二次耦合都能导致压缩态的产生

Conclusion: 在量子引力中，时间依赖的经典背景和物质源通常会产生引力场的压缩量子态，为引力量子态的产生提供了理论框架

Abstract: We present a general framework for the production of squeezed quantum states of the gravitational field in linearized quantum gravity. Time-dependent couplings in the quadratic part of the action generically produce squeezed states from the vacuum. Using the harmonic oscillator as an example, we describe three techniques to obtain the squeezing parameter from such quadratic terms. For gravity, the action to quadratic order in metric perturbations contains couplings both to background curvature as well as to matter sources. Thus, both time-dependent classical spacetimes and time-dependent classical matter typically produce squeezed states of gravity.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [18] [URANOS -- a novel voxel engine Neutron Transport Monte-Carlo Simulation](https://arxiv.org/abs/2512.19704)
*Markus Köhli,Martin Schrön,Steffen Zacharias,Ulrich Schmidt*

Main category: physics.comp-ph

TL;DR: URANOS是一款新开发的3D中子输运蒙特卡洛代码，覆盖热中子到快中子能量范围，具有快速计算流程和直观GUI界面，适用于中小型项目。


<details>
  <summary>Details</summary>
Motivation: 开发URANOS的目的是为中小型项目提供一个快速计算流程和直观图形界面的中子输运模拟工具，特别是针对硼衬探测器、实验室小规模装置和宇宙射线诱导环境中子传输研究，降低复杂建模和专业软件学习的门槛。

Method: 采用基于体素引擎的光线投射算法，模拟域按层定义，几何结构从材料像素矩阵挤出。输入文件为图片堆栈，其他设置通过GUI调整。散射核处理弹性和非弹性碰撞、吸收及蒸发等过程，截面数据来自评估数据库。特别建模了硼衬探测器的带电粒子输运和电子径迹在读出单元上的投影。

Result: URANOS能够模拟硼衬或超热中子探测器的响应函数、实验室小规模装置以及宇宙射线诱导环境中子传输研究，提供处理复杂几何的能力，且软件免费可用。

Conclusion: URANOS为理解和模拟仪器周围的中子环境提供了便利工具，否则需要大量建模和专用软件培训，特别适合需要快速、直观中子输运模拟的中小型项目。

Abstract: URANOS is a newly developed 3D neutron transport Monte-Carlo code from thermal to fast energy domains. It was originally developed for the CASCADE detector. The purpose of this simulation program is to provide a fast computational workflow and an intuitive graphical user interface (GUI) for small to medium-sized projects. It features a ray-casting algorithm based on a voxel engine. The simulation domain is defined layerwise, whereas the geometry is extruded from a pixel matrix of materials, identified by specific numbers. Input files are a stack of pictures, all other settings, including the configuration of predefined sources, can be adjusted via the GUI. The scattering kernel features the treatment of elastic and inelastic collisions, absorption and absorption-like processes like evaporation. Cross sections, energy distributions and angular distributions are taken from evaluated data bases. In order to simulate boron-lined detectors it also models the charged particle transport following the conversion by computing the energy loss in the boron and its consecutive layer. The electron track is then projected onto a readout unit by longitudinal and transversal diffusion. URANOS is freely available and can be used to simulate the response function of boron-lined or epithermal neutron detectors, small-scale laboratory setups and especially transport studies of cosmic-ray induced environmental neutrons. It offers an easy accessibility and comparably simple interface capable of handling complex geometries. URANOS therefore offers possibilities to understand and simulate the neutron environment at instruments, which would otherwise require extensive modeling and training on dedicated packages.

</details>


### [19] [Molecular Dynamics Investigation of Mass Transport During Evaporation for the Binary System of n-Dodecane and Nitrogen](https://arxiv.org/abs/2512.19996)
*Suman Chakraborty,Bongseok Kim,Li Qiao*

Main category: physics.comp-ph

TL;DR: 研究使用非平衡分子动力学模拟n-十二烷/氮气二元混合物在近临界温度下的蒸发过程，分析了界面特性并首次估计了此类Type-III二元系统的质量传输系数。


<details>
  <summary>Details</summary>
Motivation: 传统连续介质模型在高温高压条件下无法准确捕捉界面热力学性质变化，特别是对于多组分系统。现有动力学边界条件研究主要针对单原子流体，缺乏对复杂二元混合物的理解。

Method: 采用非平衡分子动力学模拟Type-III二元混合物（n-十二烷/氮气），在近临界温度条件下分析界面厚度、密度梯度、表面张力等特性，并计算蒸发和反射质量通量。

Result: 随着温度升高，蒸发和反射通量均增加，表明界面分子活动增强；但蒸发系数从Tr=0.70时的约0.978降至Tr=0.95时的约0.905，因为反射通量增加降低了净蒸发效率。

Conclusion: 这是少数针对Type-III二元系统质量传输系数的研究，为碳氢化合物/氮气混合物的动力学边界条件建模奠定了基础，揭示了高温下蒸发效率降低的机制。

Abstract: The study of interfacial fluxes under evaporative or condensation processes are ubiquitous in thermal systems, propulsion devices, and many other engineering applications. Most continuum scale models fail to capture the true nature of thermodynamic property variation across the interface, particularly under high-temperature and high-pressure conditions. An improvement over the sharp interface assumption of such continuum scale models is the consideration of a diffused interface and using Kinetic Boundary Conditions (KBCs) to model the mass-transport across the liquid vapor interface. Prior studies on KBCs mainly address monoatomic fluids. Two of the main ingredients required to form KBCs are: density and mass flux. Here, we study a Type-III binary mixture of n-dodecane and nitrogen using non-equilibrium molecular dynamics at near-critical temperatures. Interfacial properties such as thickness, density gradient, and surface tension were analyzed. A key result is the temporal evolution of the evaporation and reflected mass fluxes across the vapor-liquid interface. We observe that both the evaporation and reflection fluxes increase with increasing temperature, indicating enhanced molecular activity and mass transport across the interface at higher Tr. In contrast, the evaporation coefficient alpha_evap decreases from about alpha approximately 0.978 at Tr equals 0.70 to alpha approximately 0.905 at Tr equals 0.95 because the reflected-out flux increases along with the evaporation flux, which reduces the net efficiency of molecular evaporation across the interface. To the authors' knowledge, this is one of the very few studies estimating mass transport coefficients for Type-III binary systems, laying the foundation for KBCs in hydrocarbon and nitrogen mixtures.

</details>


### [20] [An immersed boundary method for the discrete velocity model of the Boltzmann equation](https://arxiv.org/abs/2512.20252)
*Longqing Ge,Qingdong Cai,Yonghao Zhang,Tianbai Xiao*

Main category: physics.comp-ph

TL;DR: 本文提出了一种用于玻尔兹曼方程离散速度模型的浸没边界方法，通过物理空间的上风加权紧致插值策略和速度空间的切割单元校正方法，实现了对非平衡流与结构动态相互作用的精确模拟。


<details>
  <summary>Details</summary>
Motivation: 流体-结构相互作用计算建模是航空航天工程的基础，需要精确预测气动参数。传统方法在处理复杂几何形状和非平衡流动时存在局限性，需要一种统一且物理一致的浸没边界框架。

Method: 1. 将Maxwell气体-表面相互作用模型融入鬼单元粒子分布函数构建中，精确表征速度滑移和温度跳跃效应；2. 提出物理空间的上风加权紧致插值策略，确保数值稳定性；3. 提出速度空间的切割单元校正方法，解决表面不连续性导致的积分精度退化问题。

Result: 方法在物理空间和速度空间均保持二阶精度，数值稳定性强。数值实验表明，该方法能达到设计精度，预测结果与体贴合求解器相当，同时保留了笛卡尔网格方法的简单性、灵活性和可扩展性。

Conclusion: 该方法为模拟非平衡流与结构组件在各种流动状态下的动态相互作用提供了一个统一且物理一致的浸没边界框架，适用于二维和三维问题，无需维度特定修改。

Abstract: Computational modeling and simulation of fluid-structure interactions constitute a fundamental cornerstone for advancing aerospace engineering endeavors. This paper addresses the notion and implementation of the immersed boundary method for the discrete velocity model of the Boltzmann equation. The method incorporates the Maxwell gas-surface interaction model into the construction of ghost-cell particle distribution functions, facilitating meticulous characterization of velocity slip and temperature jump effects within a Cartesian grid framework, which ultimately achieves accurate prediction of aerodynamic parameters. This study presents two principal advancements. First, an upwind-weighted compact interpolation strategy is developed in physical space, which ensures numerical stability and robustness for arbitrary geometries without relying on large stencils or normal-direction projections. Second, a cut-cell correction methodology is proposed in velocity space to address the degradation of quadrature accuracy caused by surface discontinuities. The resulting framework is equally applicable to both two- and three-dimensional problems without requiring any dimension-specific modifications. Rigorous analysis is provided to prove that the approach maintains second-order accuracy across both physical and velocity space, while ensuring robust numerical stability. Comprehensive numerical experiments demonstrate that the solution algorithm achieves the designed accuracy and delivers precise predictions comparable to body-conformal solvers, while retaining the simplicity, flexibility, and scalability of the Cartesian grid method. The proposed approach provides a unified and physically consistent immersed boundary framework for simulating dynamic interactions between non-equilibrium flows and structural components across a wide range of flow regimes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [21] [Large Language Models for EDA Cloud Job Resource and Lifetime Prediction](https://arxiv.org/abs/2512.19701)
*Yuxuan Yin,Shengke Zhou,Yunjie Zhang,Ajay Mohindra,Boxun Xu,Peng Li*

Main category: cs.LG

TL;DR: 提出一个基于大语言模型微调的框架，通过文本到文本回归预测EDA云工作负载的资源需求和作业生命周期，采用科学记数法和前缀填充约束输出格式，全注意力微调提升滑动窗口注意力LLM的预测精度。


<details>
  <summary>Details</summary>
Motivation: EDA行业云计算快速增长，需要资源和工作生命周期预测来实现最优调度。传统机器学习方法难以处理EDA工作负载的复杂性和异构性，需要大量特征工程和领域专业知识。

Method: 提出一个新颖框架，通过文本到文本回归微调大语言模型。引入科学记数法和前缀填充来约束LLM输出格式，提高可靠性。采用全注意力微调和推理来提升滑动窗口注意力LLM的预测准确性。

Result: 在真实世界云数据集上证明了所提框架的有效性，为EDA领域的性能预测设立了新的基准。

Conclusion: 微调LLM的文本到文本回归框架能够有效解决EDA云工作负载的资源和工作生命周期预测问题，通过格式约束和全注意力微调显著提升了预测准确性和可靠性。

Abstract: The rapid growth of cloud computing in the Electronic Design Automation (EDA) industry has created a critical need for resource and job lifetime prediction to achieve optimal scheduling. Traditional machine learning methods often struggle with the complexity and heterogeneity of EDA workloads, requiring extensive feature engineering and domain expertise. We propose a novel framework that fine-tunes Large Language Models (LLMs) to address this challenge through text-to-text regression. We introduce the scientific notation and prefix filling to constrain the LLM, significantly improving output format reliability. Moreover, we found that full-attention finetuning and inference improves the prediction accuracy of sliding-window-attention LLMs. We demonstrate the effectiveness of our proposed framework on real-world cloud datasets, setting a new baseline for performance prediction in the EDA domain.

</details>


### [22] [Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches](https://arxiv.org/abs/2512.19713)
*Taoran Sheng,Manfred Huber*

Main category: cs.LG

TL;DR: 该论文全面研究了可穿戴设备人体活动识别的监督学习谱系，提出了一种新颖的弱自监督学习框架，在仅需10%标注数据的情况下实现接近全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备人体活动识别中，全监督方法需要大量标注数据成本高昂，而无监督方法性能不佳。需要探索在标注需求与性能之间取得更好平衡的学习范式。

Method: 研究并比较了六种方法：1)传统全监督学习；2)基本无监督学习；3)带约束的弱监督学习；4)知识共享的多任务学习；5)基于领域知识的自监督学习；6)新颖的弱自监督学习框架（结合领域知识和少量标注数据）。

Result: 实验表明：弱监督方法性能接近全监督方法但显著减少监督需求；多任务框架通过任务间知识共享提升性能；弱自监督方法仅需10%标注数据即可实现高效识别。

Conclusion: 不同学习范式各有优势，可根据标注数据可用性定制HAR解决方案。提出的弱自监督框架为标注数据有限的实用HAR应用提供了有前景的解决方案。

Abstract: Human activity recognition (HAR) using wearable sensors has advanced through various machine learning paradigms, each with inherent trade-offs between performance and labeling requirements. While fully supervised techniques achieve high accuracy, they demand extensive labeled datasets that are costly to obtain. Conversely, unsupervised methods eliminate labeling needs but often deliver suboptimal performance. This paper presents a comprehensive investigation across the supervision spectrum for wearable-based HAR, with particular focus on novel approaches that minimize labeling requirements while maintaining competitive accuracy. We develop and empirically compare: (1) traditional fully supervised learning, (2) basic unsupervised learning, (3) a weakly supervised learning approach with constraints, (4) a multi-task learning approach with knowledge sharing, (5) a self-supervised approach based on domain expertise, and (6) a novel weakly self-supervised learning framework that leverages domain knowledge and minimal labeled data. Experiments across benchmark datasets demonstrate that: (i) our weakly supervised methods achieve performance comparable to fully supervised approaches while significantly reducing supervision requirements; (ii) the proposed multi-task framework enhances performance through knowledge sharing between related tasks; (iii) our weakly self-supervised approach demonstrates remarkable efficiency with just 10\% of labeled data. These results not only highlight the complementary strengths of different learning paradigms, offering insights into tailoring HAR solutions based on the availability of labeled data, but also establish that our novel weakly self-supervised framework offers a promising solution for practical HAR applications where labeled data are limited.

</details>


### [23] [Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data](https://arxiv.org/abs/2512.19716)
*Behrooz Mamandipoor,Chun-Nan Hsu,Martin Krause,Ulrich H. Schmidt,Rodney A. Gabriel*

Main category: cs.LG

TL;DR: 开发了一个多模态深度学习模型，利用结构化和非结构化临床数据预测危重患者入院24小时后的院内死亡风险，在多个外部数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 早期预测危重患者的院内死亡率可以帮助临床医生优化治疗方案，但目前缺乏能够整合多种临床数据源（包括结构化数据、临床笔记和影像）的预测模型。

Method: 使用MIMIC-III、MIMIC-IV、eICU和HiRID四个数据集，共203,434例ICU入院数据。开发多模态深度学习模型，整合时间不变变量、时间变化变量、临床笔记和胸部X光图像，预测ICU入院后24小时内的院内死亡风险。

Result: 整合结构化数据的模型AUROC为0.92，AUPRC为0.53，Brier分数为0.19。在eICU的8个不同机构外部验证中，AUROC范围为0.84-0.92。加入临床笔记和影像数据后，模型性能进一步提升：AUROC从0.87提高到0.89，AUPRC从0.43提高到0.48，Brier分数从0.37改善到0.17。

Conclusion: 研究表明整合多种患者信息源对死亡率预测的重要性，以及外部验证的必要性。多模态方法能够显著提升预测性能，为临床决策提供更准确的工具。

Abstract: Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.

</details>


### [24] [Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference](https://arxiv.org/abs/2512.19717)
*Zhan Zhang*

Main category: cs.LG

TL;DR: ICFA是一个用于在大搜索空间中寻找稀有但有用解的目标条件重加权框架，通过重用现有采样器和相似度函数形成聚焦采样分布，自适应控制聚焦强度避免退化。


<details>
  <summary>Details</summary>
Motivation: 在语言生成、规划和强化学习等领域，从巨大的候选空间中寻找稀有但有用的解决方案是一个实际挑战。现有方法难以高效地定位这些稀有解。

Method: 提出ICFA框架，将搜索视为目标条件重加权过程：1) 重用现有提议采样器和任务特定相似度函数；2) 形成聚焦采样分布；3) 自适应控制聚焦强度避免退化；4) 提供稳定性诊断（基于有效样本量）和理论分析。

Result: 在两个可复现实验中验证：约束语言生成和稀疏奖励导航。展示了结构化提示如何实现近似语言级ICFA，并描述了结合提示推理和算法重加权的混合架构。

Conclusion: ICFA提供了一个实用的搜索框架，能够减少样本需求，在大空间中有效寻找稀有解，并建立了提示方法与算法重加权之间的联系。

Abstract: Finding rare but useful solutions in very large candidate spaces is a recurring practical challenge across language generation, planning, and reinforcement learning. We present a practical framework, \emph{Inverted Causality Focusing Algorithm} (ICFA), that treats search as a target-conditioned reweighting process. ICFA reuses an available proposal sampler and a task-specific similarity function to form a focused sampling distribution, while adaptively controlling focusing strength to avoid degeneracy. We provide a clear recipe, a stability diagnostic based on effective sample size, a compact theoretical sketch explaining when ICFA can reduce sample needs, and two reproducible experiments: constrained language generation and sparse-reward navigation. We further show how structured prompts instantiate an approximate, language-level form of ICFA and describe a hybrid architecture combining prompted inference with algorithmic reweighting.

</details>


### [25] [Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data](https://arxiv.org/abs/2512.19718)
*Vasileios C. Pezoulas,Nikolaos S. Tachos,Eleni Georga,Kostas Marias,Manolis Tsiknakis,Dimitrios I. Fotiadis*

Main category: cs.LG

TL;DR: Synthetic Data Blueprint (SDB) 是一个模块化的Python库，用于定量和可视化评估合成表格数据的保真度，解决当前合成数据评估碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 当前合成数据的评估存在碎片化问题，使用异构指标、临时脚本和不完整的报告实践，需要统一的评估框架来确保合成数据的质量和可靠性。

Method: 开发了模块化的Python库SDB，支持自动特征类型检测、分布和依赖级保真度指标、基于图和嵌入的结构保留评分，以及丰富的数据可视化方案。

Result: 在三个真实世界用例中验证了SDB的广度、鲁棒性和领域无关适用性：医疗诊断、社会经济金融建模、网络安全和网络流量分析，展示了其处理多样化数据保真度评估挑战的能力。

Conclusion: SDB提供了一个一致、透明和可复现的基准测试框架，能够跨异构领域评估合成数据的保真度，促进合成数据的可靠使用和创新。

Abstract: In the rapidly evolving era of Artificial Intelligence (AI), synthetic data are widely used to accelerate innovation while preserving privacy and enabling broader data accessibility. However, the evaluation of synthetic data remains fragmented across heterogeneous metrics, ad-hoc scripts, and incomplete reporting practices. To address this gap, we introduce Synthetic Data Blueprint (SDB), a modular Pythonic based library to quantitatively and visually assess the fidelity of synthetic tabular data. SDB supports: (i) automated feature-type detection, (ii) distributional and dependency-level fidelity metrics, (iii) graph- and embedding-based structure preservation scores, and (iv) a rich suite of data visualization schemas. To demonstrate the breadth, robustness, and domain-agnostic applicability of the SDB, we evaluated the framework across three real-world use cases that differ substantially in scale, feature composition, statistical complexity, and downstream analytical requirements. These include: (i) healthcare diagnostics, (ii) socioeconomic and financial modelling, and (iii) cybersecurity and network traffic analysis. These use cases reveal how SDB can address diverse data fidelity assessment challenges, varying from mixed-type clinical variables to high-cardinality categorical attributes and high-dimensional telemetry signals, while at the same time offering a consistent, transparent, and reproducible benchmarking across heterogeneous domains.

</details>


### [26] [Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries](https://arxiv.org/abs/2512.19719)
*Zihao Lv,Siqi Ai,Yanbin Zhang*

Main category: cs.LG

TL;DR: 提出MDFA-Net深度学习架构用于电池剩余使用寿命预测，通过双路径网络分别捕捉浅层局部信息和深层全局趋势，在公开数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有电池退化序列建模技术效率低下，难以同时评估局部和全局相关性，无法满足实际应用需求

Method: 提出多尺度双路径特征聚合网络(MDFA-Net)，包含两条路径：多尺度特征网络(MF-Net)保持浅层信息，编码器网络(EC-Net)捕捉序列连续趋势并保留深层细节

Result: 在两个公开锂离子电池数据集上的测试表明，该方法在RUL预测方面超越了现有顶级方法，能准确映射容量退化轨迹

Conclusion: MDFA-Net通过整合深层和浅层属性，有效捕捉局部和全局模式，为电池剩余使用寿命预测提供了更有效的解决方案

Abstract: Targeted maintenance strategies, ensuring the dependability and safety of industrial machinery. However, current modeling techniques for assessing both local and global correlation of battery degradation sequences are inefficient and difficult to meet the needs in real-life applications. For this reason, we propose a novel deep learning architecture, multiscale dual-path feature aggregation network (MDFA-Net), for RUL prediction. MDFA-Net consists of dual-path networks, the first path network, multiscale feature network (MF-Net) that maintains the shallow information and avoids missing information, and the second path network is an encoder network (EC-Net) that captures the continuous trend of the sequences and retains deep details. Integrating both deep and shallow attributes effectively grasps both local and global patterns. Testing conducted with two publicly available Lithium-ion battery datasets reveals our approach surpasses existing top-tier methods in RUL forecasting, accurately mapping the capacity degradation trajectory.

</details>


### [27] [Per-Axis Weight Deltas for Frequent Model Updates](https://arxiv.org/abs/2512.19720)
*Stefan Kuyumdzhiev,Radostin Cholakov*

Main category: cs.LG

TL;DR: 提出一种1-bit权重delta压缩方法，仅存储权重差异的符号和轻量级FP16缩放因子，大幅减少微调模型存储和冷启动延迟


<details>
  <summary>Details</summary>
Motivation: 微调LLM变体面临大尺寸检查点和高冷启动延迟问题，而微调权重与基础模型差异较小，适合用压缩delta表示

Method: 使用1-bit delta方案：仅存储权重差异的符号，配合轻量级per-axis（行/列）FP16缩放因子，通过小校准集学习

Result: 相比标量方案提升重建质量，存储开销比完整FP16检查点小数倍，减少冷启动延迟，保持推理效率

Conclusion: 该方法即插即用，需要最小校准数据，避免密集重建，为频繁模型更新提供高效压缩方案

Abstract: Serving many task-specialized LLM variants is often limited by the large size of fine-tuned checkpoints and the resulting cold-start latency. Since fine-tuned weights differ from their base model by relatively small structured residuals, a natural approach is to represent them as compressed deltas. We propose a simple 1-bit delta scheme that stores only the sign of the weight difference together with lightweight per-axis (row/column) FP16 scaling factors, learned from a small calibration set. This design preserves the compactness of 1-bit deltas while more accurately capturing variation across weight dimensions, leading to improved reconstruction quality over scalar alternatives. From a systems perspective, a streamlined loader that transfers packed deltas in a single operation per module reduces cold-start latency and storage overhead, with artifacts several times smaller than a full FP16 checkpoint. The method is drop-in, requires minimal calibration data, and maintains inference efficiency by avoiding dense reconstruction. Our experimental setup and source code are available at https://github.com/kuiumdjiev/Per-Axis-Weight-Deltas-for-Frequent-Model-Updates.

</details>


### [28] [Reduced Order Modeling for Tsunami Forecasting with Bayesian Hierarchical Pooling](https://arxiv.org/abs/2512.19804)
*Shane X. Coffing,John Tipton,Arvind T. Mohan,Darren Engwirda*

Main category: cs.LG

TL;DR: 提出randPROM方法：结合神经Galerkin投影和统计层次池化，构建能生成统计可解释、物理合理权重的新型降阶模型，应用于海啸预测。


<details>
  <summary>Details</summary>
Motivation: 传统降阶模型（如POD）受限于固定权重，只能模拟特定过程。需要一种能生成新权重、适用于相似问题族、具有统计可解释性和物理合理性的降阶模型。

Method: 1. 使用神经Galerkin投影构建初始值问题，通过神经网络校准以准确建模权重轨迹；2. 采用统计层次池化技术学习时间权重初始值的分布；3. 结合空间特征形成完整的物理代理模型randPROM。

Result: 将randPROM应用于斐济附近合成海啸案例和2011年日本东北部真实海啸灾害，证明该方法能显著减少模拟次数，生成统计校准且物理可辩护的海啸波到达时间和高度预测模型。

Conclusion: randPROM是一种新型降阶模型，能生成与ROM构建所用初始条件邻域分布一致的模拟，为海啸等非线性复杂问题提供统计可解释、物理合理的预测工具。

Abstract: Reduced order models (ROM) can represent spatiotemporal processes in significantly fewer dimensions and can be solved many orders faster than their governing partial differential equations (PDEs). For example, using a proper orthogonal decomposition produces a ROM that is a small linear combination of fixed features and weights, but that is constrained to the given process it models. In this work, we explore a new type of ROM that is not constrained to fixed weights, based on neural Galerkin-Projections, which is an initial value problem that encodes the physics of the governing PDEs, calibrated via neural networks to accurately model the trajectory of these weights. Then using a statistical hierarchical pooling technique to learn a distribution on the initial values of the temporal weights, we can create new, statistically interpretable and physically justified weights that are generalized to many similar problems. When recombined with the spatial features, we form a complete physics surrogate, called a randPROM, for generating simulations that are consistent in distribution to a neighborhood of initial conditions close to those used to construct the ROM. We apply the randPROM technique to the study of tsunamis, which are unpredictable, catastrophic, and highly-detailed non-linear problems, modeling both a synthetic case of tsunamis near Fiji and the real-world Tohoku 2011 disaster. We demonstrate that randPROMs may enable us to significantly reduce the number of simulations needed to generate a statistically calibrated and physically defensible prediction model for arrival time and height of tsunami waves.

</details>


### [29] [Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals](https://arxiv.org/abs/2512.19721)
*Vineet Yadav*

Main category: cs.LG

TL;DR: 提出一个符号感知的多状态Jaccard/Tanimoto框架，将基于重叠的距离从非负向量扩展到任意实值和复值信号，同时保持有界度量结构和正半定核。


<details>
  <summary>Details</summary>
Motivation: 现有Jaccard/Tanimoto相似度方法主要适用于非负向量，无法处理包含正负值的实值信号和复值信号。需要一种统一的框架来处理各种信号类型，同时保持数学上的良好性质。

Method: 将信号表示为带符号状态空间上的原子测度，通过正负分离、笛卡尔和极坐标分解等方法将信号嵌入到非负多状态表示中，然后应用Tanimoto构造得到有界距离。还开发了基于Möbius反演的联盟分析。

Result: 得到一族[0,1]范围内的距离，满足三角不等式并定义正半定核，可直接用于核方法和基于图的学习。框架提供了有界度量结构、正半定核、概率语义和透明的预算核算。

Conclusion: 该框架为实值和复值信号提供了一个统一的、可解释的距离度量，支持相关图、特征工程、相似图等分析工具，在科学和金融应用中具有广泛用途。

Abstract: We introduce a sign-aware, multistate Jaccard/Tanimoto framework that extends overlap-based distances from nonnegative vectors and measures to arbitrary real- and complex-valued signals while retaining bounded metric and positive-semidefinite kernel structure. Formally, the construction is a set- and measure-theoretic geometry: signals are represented as atomic measures on a signed state space, and similarity is given by a generalized Jaccard overlap of these measures. Each signal is embedded into a nonnegative multistate representation, using positive/negative splits for real signals, Cartesian and polar decompositions for complex signals, and user-defined state partitions for refined regime analysis. Applying the Tanimoto construction to these embeddings yields a family of $[0,1]$ distances that satisfy the triangle inequality and define positive-semidefinite kernels usable directly in kernel methods and graph-based learning. Beyond pairwise distances, we develop coalition analysis via Möbius inversion, which decomposes signal magnitude into nonnegative, additive contributions with exact budget closure across coalitions of signals. Normalizing the same embeddings produces probability measures on coordinate -- state configurations, so that the distance becomes a monotone transform of total variation and admits a regime -- intensity decomposition. The resulting construction yields a single, mechanistically interpretable distance that simultaneously provides bounded metric structure, positive-semidefinite kernels, probabilistic semantics, and transparent budget accounting within one sign-aware framework, supporting correlograms, feature engineering, similarity graphs, and other analytical tools in scientific and financial applications.

</details>


### [30] [GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer](https://arxiv.org/abs/2512.20399)
*Corey Adams,Rishikesh Ranade,Ram Cherukuri,Sanjay Choudhry*

Main category: cs.LG

TL;DR: GeoTransolver是一个多尺度几何感知物理注意力Transformer，用于CAE，通过GALE注意力机制结合物理感知自注意力和多尺度几何上下文交叉注意力，在复杂不规则域和非线性物理机制中实现高精度代理建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂几何形状和不同操作机制时存在精度和鲁棒性不足的问题，需要开发能够统一多尺度几何感知上下文与物理基础注意力的可扩展Transformer，以提升CAE中高保真代理建模的性能。

Method: 提出GeoTransolver，采用GALE注意力机制替代标准注意力，将学习状态切片上的物理感知自注意力与多尺度球查询计算的共享几何/全局/边界条件上下文交叉注意力相结合，通过NVIDIA PhysicsNeMo实现，持续将几何、全局和边界条件参数投影到物理状态空间。

Result: 在DrivAerML、Luminary SHIFT-SUV和Luminary SHIFT-Wing基准测试中，GeoTransolver相比Domino、Transolver和AB-UPT具有更好的精度、对几何/机制变化的鲁棒性以及数据效率优势，包括消融研究和定性结果验证。

Conclusion: GeoTransolver通过统一多尺度几何感知上下文与物理基础注意力，为复杂不规则域和非线性物理机制中的高保真代理建模推进了算子学习，在CAE应用中展现出优越性能。

Abstract: We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block. Implemented and released in NVIDIA PhysicsNeMo, GeoTransolver persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes. We benchmark GeoTransolver on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, comparing against Domino, Transolver (as released in PhysicsNeMo), and literature-reported AB-UPT, and evaluate drag/lift R2 and Relative L1 errors for field variables. GeoTransolver delivers better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency; we include ablations on DrivAerML and qualitative results such as contour plots and design trends for the best GeoTransolver models. By unifying multiscale geometry-aware context with physics-based attention in a scalable transformer, GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes.

</details>


### [31] [Node-Level Financial Optimization in Demand Forecasting Through Dynamic Cost Asymmetry and Feedback Mechanism](https://arxiv.org/abs/2512.19722)
*Alessandro Casadei,Clemens Grupp,Sreyoshi Bhaduri,Lu Guo,Wilson Fung,Rohit Malshe,Raj Ratan,Ankush Pole,Arkajit Rakshit*

Main category: cs.LG

TL;DR: 提出一种基于节点特定成本函数不对称性的预测调整方法，通过动态整合成本不对称性到预测误差概率分布中，实现年度510万美元的节约


<details>
  <summary>Details</summary>
Motivation: 传统预测方法通常假设对称成本函数，但实际应用中不同节点的成本不对称性会导致预测偏差，需要一种能够考虑节点特定成本不对称性的预测调整方法

Method: 将成本不对称性动态整合到预测误差概率分布中，使预测偏向成本最低的情景；建立自我调节机制，根据观察到的节约动态调整调整幅度，以适应站点特定条件和未建模因素

Result: 实证结果表明，该方法能够实现年度510万美元的节约，证明了模型的有效性和实用性

Conclusion: 提出的基于节点特定成本不对称性的预测调整方法能够显著提高预测的经济效益，通过动态整合成本不对称性和自我调节机制，使模型能够适应各种实际应用场景

Abstract: This work introduces a methodology to adjust forecasts based on node-specific cost function asymmetry. The proposed model generates savings by dynamically incorporating the cost asymmetry into the forecasting error probability distribution to favor the least expensive scenario. Savings are calculated and a self-regulation mechanism modulates the adjustments magnitude based on the observed savings, enabling the model to adapt to station-specific conditions and unmodeled factors such as calibration errors or shifting macroeconomic dynamics. Finally, empirical results demonstrate the model's ability to achieve \$5.1M annual savings.

</details>


### [32] [End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment](https://arxiv.org/abs/2512.19723)
*Firas Bayram,Bestoun S. Ahmed,Erik Hallin*

Main category: cs.LG

TL;DR: 提出一个端到端框架，将数据质量评估与机器学习模型操作实时集成，在钢铁制造ESR真空泵过程中验证了12%性能提升和4倍延迟降低。


<details>
  <summary>Details</summary>
Motivation: 现有方法将数据质量评估和ML系统作为孤立过程处理，存在理论与实际应用的鸿沟。需要解决动态工业环境中实时、质量驱动的ML决策需求。

Method: 开发了一个轻量级框架，整合动态漂移检测、自适应数据质量指标和MLOps，实现实时数据质量评估与ML模型操作的无缝集成。

Result: 在钢铁制造公司的ESR真空泵过程中验证，模型性能提升12%（R2=94%），预测延迟降低4倍，展示了框架在实际工业应用中的有效性。

Conclusion: 该框架代表了MLOps的重要进展，为动态工业环境中时间敏感的数据驱动决策提供了稳健解决方案，平衡了数据质量标准与预测性能。

Abstract: This paper introduces a novel end-to-end framework that efficiently integrates data quality assessment with machine learning (ML) model operations in real-time production environments. While existing approaches treat data quality assessment and ML systems as isolated processes, our framework addresses the critical gap between theoretical methods and practical implementation by combining dynamic drift detection, adaptive data quality metrics, and MLOps into a cohesive, lightweight system. The key innovation lies in its operational efficiency, enabling real-time, quality-driven ML decision-making with minimal computational overhead. We validate the framework in a steel manufacturing company's Electroslag Remelting (ESR) vacuum pumping process, demonstrating a 12% improvement in model performance (R2 = 94%) and a fourfold reduction in prediction latency. By exploring the impact of data quality acceptability thresholds, we provide actionable insights into balancing data quality standards and predictive performance in industrial applications. This framework represents a significant advancement in MLOps, offering a robust solution for time-sensitive, data-driven decision-making in dynamic industrial environments.

</details>


### [33] [Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking](https://arxiv.org/abs/2512.19725)
*Srishti Gupta,Riccardo Balia,Daniele Angioni,Fabio Brau,Maura Pintor,Ambra Demontis,Alessandro Sebastian,Salvatore Mario Carta,Fabio Roli,Battista Biggio*

Main category: cs.LG

TL;DR: 该论文探讨机器学习模型在现实世界部署中的适应性问题，提出需要结合持续学习和分布外检测来构建鲁棒、高效、自适应的AI系统。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器学习系统面临数据分布随时间变化和出现意外输入的问题，而传统基于i.i.d.假设的模型无法有效应对这些挑战。从头重新训练模型计算成本高且不切实际，因此需要新的解决方案。

Method: 论文提出结合持续学习和分布外检测的方法。持续学习使模型能够从不断变化的数据流中增量学习而不遗忘过去知识；分布外检测使系统能够识别和响应新颖或异常输入。

Result: 通过联合解决持续学习和分布外检测这两个挑战，可以开发出更鲁棒、高效和自适应的AI系统，能够应对现实世界中数据分布变化和意外输入的情况。

Conclusion: 在现实世界部署中，机器学习模型需要具备适应性和鲁棒性。结合持续学习和分布外检测是构建能够应对数据分布变化和意外输入的关键方法，这对于开发实用的AI系统至关重要。

Abstract: Recent years have witnessed significant progress in the development of machine learning models across a wide range of fields, fueled by increased computational resources, large-scale datasets, and the rise of deep learning architectures. From malware detection to enabling autonomous navigation, modern machine learning systems have demonstrated remarkable capabilities. However, as these models are deployed in ever-changing real-world scenarios, their ability to remain reliable and adaptive over time becomes increasingly important. For example, in the real world, new malware families are continuously developed, whereas autonomous driving cars are employed in many different cities and weather conditions. Models trained in fixed settings can not respond effectively to novel conditions encountered post-deployment. In fact, most machine learning models are still developed under the assumption that training and test data are independent and identically distributed (i.i.d.), i.e., sampled from the same underlying (unknown) distribution. While this assumption simplifies model development and evaluation, it does not hold in many real-world applications, where data changes over time and unexpected inputs frequently occur. Retraining models from scratch whenever new data appears is computationally expensive, time-consuming, and impractical in resource-constrained environments. These limitations underscore the need for Continual Learning (CL), which enables models to incrementally learn from evolving data streams without forgetting past knowledge, and Out-of-Distribution (OOD) detection, which allows systems to identify and respond to novel or anomalous inputs. Jointly addressing both challenges is critical to developing robust, efficient, and adaptive AI systems.

</details>


### [34] [Tiny, On-Device Decision Makers with the MiniConv Library](https://arxiv.org/abs/2512.19726)
*Carlos Purves*

Main category: cs.LG

TL;DR: 提出一种分割策略架构，通过设备端小型编码器将高维观测压缩为紧凑特征张量传输到远程策略头，减少数据传输、降低决策延迟和服务器计算开销，在资源受限边缘设备上实现可比较的强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在视觉策略部署到资源受限边缘设备时面临计算成本和通信延迟的挑战。现有方案通常将策略推理卸载到远程服务器，但需要传输高维观测数据并产生网络往返延迟。

Method: 采用分割策略架构：设备端小型编码器（实现为OpenGL片段着色器）将观测转换为紧凑特征张量传输到远程策略头。在带宽限制环境下评估了NVIDIA Jetson Nano、Raspberry Pi 4B和Raspberry Pi Zero 2 W等设备。

Result: 减少了传输数据量，在带宽受限环境中降低了决策延迟，减少了服务器端每请求计算量，在最终100个episode的平均回报上实现了可比较的学习性能，只有适度的平均回报权衡。

Conclusion: 分割策略架构有效解决了边缘设备部署视觉强化学习策略的挑战，在保持性能的同时显著降低了通信开销和延迟，为资源受限环境提供了可行的解决方案。

Abstract: Reinforcement learning (RL) has achieved strong results, but deploying visual policies on resource-constrained edge devices remains challenging due to computational cost and communication latency. Many deployments therefore offload policy inference to a remote server, incurring network round trips and requiring transmission of high-dimensional observations. We introduce a split-policy architecture in which a small on-device encoder, implemented as OpenGL fragment-shader passes for broad embedded GPU support, transforms each observation into a compact feature tensor that is transmitted to a remote policy head. In RL, this communication overhead manifests as closed-loop decision latency rather than only per-request inference latency. The proposed approach reduces transmitted data, lowers decision latency in bandwidth-limited settings, and reduces server-side compute per request, whilst achieving broadly comparable learning performance by final return (mean over the final 100 episodes) in single-run benchmarks, with modest trade-offs in mean return. We evaluate across an NVIDIA Jetson Nano, a Raspberry Pi 4B, and a Raspberry Pi Zero 2 W, reporting learning results, on-device execution behaviour under sustained load, and end-to-end decision latency and scalability measurements under bandwidth shaping. Code for training, deployment, and measurement is released as open source.

</details>


### [35] [Trend Extrapolation for Technology Forecasting: Leveraging LSTM Neural Networks for Trend Analysis of Space Exploration Vessels](https://arxiv.org/abs/2512.19727)
*Peng-Hung Tsai,Daniel Berleant*

Main category: cs.LG

TL;DR: 该研究开发了一种结合LSTM神经网络和摩尔定律增强的预测模型，用于预测航天器寿命，并引入了STETI方法解决右删失偏差问题。


<details>
  <summary>Details</summary>
Motivation: 空间探索等复杂领域的技术预测面临技术、经济、政策等多因素交互的挑战。传统定量趋势外推方法存在局限，而机器学习混合模型成为新趋势。航天器运行寿命是衡量空间技术进步的重要工程特征，但存在右删失偏差问题（较新发射的航天器尚未失效，导致寿命数据被低估）。

Method: 1. 进行了系统文献综述，评估技术预测方法现状；2. 开发了结合LSTM神经网络和摩尔定律增强的预测模型；3. 引入了STETI（启动时间结束时间集成）方法，通过发射时间和失效时间的相互转换来缓解右删失偏差问题。

Result: 研究结果表明，机器学习混合模型在技术预测领域呈现增长趋势。开发的LSTM-摩尔定律混合模型能够有效预测航天器寿命，STETI方法成功缓解了右删失偏差对寿命估计的影响。

Conclusion: 该研究为空间任务规划和政策决策提供了重要见解，展示了机器学习混合模型在复杂技术预测中的潜力，并通过STETI方法解决了寿命分析中的关键统计偏差问题。

Abstract: Forecasting technological advancement in complex domains such as space exploration presents significant challenges due to the intricate interaction of technical, economic, and policy-related factors. The field of technology forecasting has long relied on quantitative trend extrapolation techniques, such as growth curves (e.g., Moore's law) and time series models, to project technological progress. To assess the current state of these methods, we conducted an updated systematic literature review (SLR) that incorporates recent advances. This review highlights a growing trend toward machine learning-based hybrid models.
  Motivated by this review, we developed a forecasting model that combines long short-term memory (LSTM) neural networks with an augmentation of Moore's law to predict spacecraft lifetimes. Operational lifetime is an important engineering characteristic of spacecraft and a potential proxy for technological progress in space exploration. Lifetimes were modeled as depending on launch date and additional predictors.
  Our modeling analysis introduces a novel advance in the recently introduced Start Time End Time Integration (STETI) approach. STETI addresses a critical right censoring problem known to bias lifetime analyses: the more recent the launch dates, the shorter the lifetimes of the spacecraft that have failed and can thus contribute lifetime data. Longer-lived spacecraft are still operating and therefore do not contribute data. This systematically distorts putative lifetime versus launch date curves by biasing lifetime estimates for recent launch dates downward. STETI mitigates this distortion by interconverting between expressing lifetimes as functions of launch time and modeling them as functions of failure time. The results provide insights relevant to space mission planning and policy decision-making.

</details>


### [36] [Hard Negative Sample-Augmented DPO Post-Training for Small Language Models](https://arxiv.org/abs/2512.19728)
*Haocheng Lu,Minjun Zhu,Henry Yu*

Main category: cs.LG

TL;DR: 提出一种轻量级后训练流程，通过数学验证器检测结构化错误，结合加权DPO提升LLM数学推理能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM在数学推理上仍有困难，传统方法将解决方案简化为二元判断（正确/错误）过于局限，而基于RLHF的方法通常昂贵、难以扩展且不稳定。需要一种轻量级方法来处理结构化错误。

Method: 1. 从MetaMathQA风格的CoT数据进行SFT；2. 引入紧凑的MathVerifier，将候选解分解为六维错误配置文件，聚合为可解释的错误和荒谬分数；3. 验证器信号用于：(i)挖掘接近正确但有结构缺陷的困难负样本，(ii)定义强调最信息丰富偏好对的每样本重要性权重；4. 通过验证器引导的加权公式将两者集成到离线DPO目标中。

Result: 在1.5B参数的Qwen2.5模型上的实验表明，验证器引导的加权DPO比普通SFT和非加权DPO产生更有针对性的改进，特别是在解决方案数值接近正确但逻辑不一致的问题上，同时避免了训练大型奖励模型或依赖外部评判的开销。

Conclusion: 提出了一种轻量级、实用的后训练流程，通过数学验证器检测结构化错误并指导加权DPO，有效提升LLM数学推理能力，避免了传统RLHF方法的复杂性和开销。

Abstract: Large language models (LLMs) continue to struggle with mathematical reasoning, and common post-training pipelines often reduce each generated solution to a binary outcome: correct or incorrect. This perspective is limiting in practice, as failures in chain-of-thought (CoT) reasoning are frequently structured; solutions may appear convincing while containing subtle logical, algebraic, or numerical flaws. Meanwhile, reinforcement learning from human feedback (RLHF) variants that rely on large reward models or LLM-as-a-judge signals are often expensive, difficult to scale, and unstable to iterate. We propose a lightweight and pragmatic post-training pipeline that targets such structured errors under realistic compute budgets. Starting from supervised fine-tuning (SFT) on MetaMathQA-style CoT data, we introduce a compact MathVerifier that decomposes a candidate solution into a six-dimensional error profile and aggregates it into interpretable wrongness and absurdity scores. These verifier signals serve two roles: (i) mining hard negatives that are near-correct yet structurally flawed, and (ii) defining per-sample importance weights that emphasize the most informative preference pairs. We integrate both into an offline Direct Preference Optimization (DPO) objective via a verifier-guided weighted formulation. Experiments on a 1.5B-parameter Qwen2.5 model show that verifier-guided, weighted DPO yields more targeted improvements than vanilla SFT and unweighted DPO, particularly on problems where solutions are numerically close to correct but logically inconsistent, while avoiding the overhead of training large reward models or relying on external judges.

</details>


### [37] [High-Performance Self-Supervised Learning by Joint Training of Flow Matching](https://arxiv.org/abs/2512.19729)
*Kosuke Ukita,Tsuyoshi Okita*

Main category: cs.LG

TL;DR: FlowFM：基于流匹配的联合优化基础模型，在可穿戴传感器数据上同时实现高质量生成和高效识别，相比扩散模型训练时间减少50.4%，推理速度提升51倍。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在自监督学习中面临生成质量与判别性能的权衡问题，且迭代采样过程计算成本和能耗高，限制了工业和边缘AI应用。需要一种既能高效学习表征又能快速生成的方法。

Method: 提出FlowFM模型，联合训练表征编码器和条件流匹配生成器。采用解耦设计，通过流匹配学习更简单的速度场，加速并稳定训练过程，提高表征学习效率。

Result: 在可穿戴传感器数据上，FlowFM相比基于扩散的方法减少50.4%训练时间。在五个数据集的下游任务中超越最先进的SSL方法（SSL-Wearables），推理速度提升高达51倍，同时保持高生成质量。

Conclusion: FlowFM通过流匹配技术有效解决了扩散模型在自监督学习中的效率问题，实现了生成与识别的双重优化，为工业和边缘AI应用提供了高效的基础模型解决方案。

Abstract: Diffusion models can learn rich representations during data generation, showing potential for Self-Supervised Learning (SSL), but they face a trade-off between generative quality and discriminative performance. Their iterative sampling also incurs substantial computational and energy costs, hindering industrial and edge AI applications. To address these issues, we propose the Flow Matching-based Foundation Model (FlowFM), which jointly trains a representation encoder and a conditional flow matching generator. This decoupled design achieves both high-fidelity generation and effective recognition. By using flow matching to learn a simpler velocity field, FlowFM accelerates and stabilizes training, improving its efficiency for representation learning. Experiments on wearable sensor data show FlowFM reduces training time by 50.4\% compared to a diffusion-based approach. On downstream tasks, FlowFM surpassed the state-of-the-art SSL method (SSL-Wearables) on all five datasets while achieving up to a 51.0x inference speedup and maintaining high generative quality. The implementation code is available at https://github.com/Okita-Laboratory/jointOptimizationFlowMatching.

</details>


### [38] [ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures](https://arxiv.org/abs/2512.19730)
*Zhonghao Yang,Cheng Luo,Daojing He,Yiming Li,Yu Li*

Main category: cs.LG

TL;DR: 提出ArcGen方法，通过特征对齐层和两种对齐损失函数，解决现有基于学习的神经后门检测方法在未见架构上泛化能力差的问题，实现跨架构的后门检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的神经后门检测方法在训练阶段未见的新模型架构上泛化能力差，这限制了实际应用中的检测效果。

Method: 提出ArcGen方法：1) 在特征提取函数中引入对齐层，减少架构信息对特征的直接影响；2) 设计两种对齐损失函数（分布级和样本级），要求具有相似后门行为但不同架构的模型特征对齐。

Result: 在未见模型架构上检测性能提升高达42.5%（如AUC指标）。基于大规模评估，涉及16,896个模型，涵盖不同数据集、后门攻击类型和模型架构。

Conclusion: ArcGen通过获得架构不变的特征表示，显著提高了后门检测方法在未见模型架构上的泛化能力，为黑盒神经后门检测提供了有效解决方案。

Abstract: Backdoor attacks pose a significant threat to the security and reliability of deep learning models. To mitigate such attacks, one promising approach is to learn to extract features from the target model and use these features for backdoor detection. However, we discover that existing learning-based neural backdoor detection methods do not generalize well to new architectures not seen during the learning phase. In this paper, we analyze the root cause of this issue and propose a novel black-box neural backdoor detection method called ArcGen. Our method aims to obtain architecture-invariant model features, i.e., aligned features, for effective backdoor detection. Specifically, in contrast to existing methods directly using model outputs as model features, we introduce an additional alignment layer in the feature extraction function to further process these features. This reduces the direct influence of architecture information on the features. Then, we design two alignment losses to train the feature extraction function. These losses explicitly require that features from models with similar backdoor behaviors but different architectures are aligned at both the distribution and sample levels. With these techniques, our method demonstrates up to 42.5% improvements in detection performance (e.g., AUC) on unseen model architectures. This is based on a large-scale evaluation involving 16,896 models trained on diverse datasets, subjected to various backdoor attacks, and utilizing different model architectures. Our code is available at https://github.com/SeRAlab/ArcGen.

</details>


### [39] [Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems](https://arxiv.org/abs/2512.19731)
*Xiangzhong Luo,Weichen Liu*

Main category: cs.LG

TL;DR: 提出Double-Win NAS，一种深度到浅层可转换的神经网络架构搜索范式，旨在为资源受限的嵌入式系统同时实现高精度和高硬件效率。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络在嵌入式场景中取得了显著成功，但网络深度增加导致硬件效率下降。浅层网络虽然硬件效率高，但精度往往不足。需要解决这一矛盾。

Method: 提出Double-Win NAS范式：1）自动搜索深度网络以获得高精度；2）将深度网络等价转换为浅层网络以获得高硬件效率。还提出两种增强训练技术：混合可转换训练和任意分辨率弹性训练。

Result: 在两个流行的嵌入式系统（NVIDIA Jetson AGX Xavier和NVIDIA Jetson Nano）和两个大规模数据集（ImageNet和ImageNet-100）上的实验结果表明，Double-Win NAS优于先前最先进的NAS方法。

Conclusion: Double-Win NAS通过深度到浅层的可转换搜索范式，成功解决了深度网络精度与浅层网络硬件效率之间的矛盾，为资源受限的嵌入式智能系统提供了有效的解决方案。

Abstract: Thanks to the evolving network depth, convolutional neural networks (CNNs) have achieved remarkable success across various embedded scenarios, paving the way for ubiquitous embedded intelligence. Despite its promise, the evolving network depth comes at the cost of degraded hardware efficiency. In contrast to deep networks, shallow networks can deliver superior hardware efficiency but often suffer from inferior accuracy. To address this dilemma, we propose Double-Win NAS, a novel deep-to-shallow transformable neural architecture search (NAS) paradigm tailored for resource-constrained intelligent embedded systems. Specifically, Double-Win NAS strives to automatically explore deep networks to first win strong accuracy, which are then equivalently transformed into their shallow counterparts to further win strong hardware efficiency. In addition to search, we also propose two enhanced training techniques, including hybrid transformable training towards better training accuracy and arbitrary-resolution elastic training towards enabling natural network elasticity across arbitrary input resolutions. Extensive experimental results on two popular intelligent embedded systems (i.e., NVIDIA Jetson AGX Xavier and NVIDIA Jetson Nano) and two representative large-scale datasets (i.e., ImageNet and ImageNet-100) clearly demonstrate the superiority of Double-Win NAS over previous state-of-the-art NAS approaches.

</details>


### [40] [Leakage-Aware Bandgap Prediction on the JARVIS-DFT Dataset: A Phase-Wise Feature Analysis](https://arxiv.org/abs/2512.19732)
*Gaurav Kumar Sharma*

Main category: cs.LG

TL;DR: 系统分析JARVIS-DFT带隙数据集，去除可能编码带结构信息的描述符，构建2280个材料的泄漏控制数据集，通过三阶段建模框架评估预测性能


<details>
  <summary>Details</summary>
Motivation: 现有带隙预测研究中，描述符可能无意中编码了带结构信息（如有效质量），导致预测性能被高估。需要构建泄漏控制的数据集来评估真实的预测能力

Method: 1. 系统分析JARVIS-DFT数据集，识别并去除可能编码带结构信息的描述符；2. 构建包含2280个材料的泄漏控制数据集；3. 实施三阶段建模框架：逐步加入基础物理描述符、工程特征和成分属性；4. 使用树模型评估性能，并进行SHAP分析

Result: 树模型在所有三个阶段都达到R²约0.88-0.90，表明在控制泄漏后，扩展描述符空间不会显著提高预测精度。SHAP分析一致显示介电张量分量是主要贡献因素

Conclusion: 提供了泄漏控制的带隙预测数据集和基准性能，为未来泄漏感知的带隙预测研究奠定了基础。控制数据泄漏比增加描述符复杂度更重要

Abstract: In this study, we perform a systematic analysis of the JARVIS-DFT bandgap dataset and identify and remove descriptors that may inadvertently encode band-structure information, such as effective masses. This process yields a curated, leakage-controlled subset of 2280 materials. Using this dataset, a three-phase modeling framework is implemented that incrementally incorporates basic physical descriptors, engineered features, and compositional attributes. The results show that tree-based models achieve R2 values of approximately 0.88 to 0.90 across all phases, indicating that expanding the descriptor space does not substantially improve predictive accuracy when leakage is controlled. SHAP analysis consistently identifies the dielectric tensor components as the dominant contributors. This work provides a curated dataset and baseline performance metrics for future leakage-aware bandgap prediction studies.

</details>


### [41] [The Deleuzian Representation Hypothesis](https://arxiv.org/abs/2512.19734)
*Clément Cornet,Romaric Besançon,Hervé Le Borgne*

Main category: cs.LG

TL;DR: 提出一种替代稀疏自编码器的方法，通过聚类激活差异来提取可解释概念，利用偏度加权增强概念多样性，在多个模型和模态上验证效果优于无监督SAE变体


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器(SAEs)方法在提取神经网络可解释概念方面存在局限性，需要更简单有效的无监督方法来提取多样化的概念

Method: 基于判别分析框架，聚类激活差异，并使用激活偏度进行加权以增强概念多样性，该方法与Deleuze的概念作为差异的现代观点一致

Result: 在五个模型和三种模态（视觉、语言、音频）上评估，概念质量超越先前无监督SAE变体，接近有监督基线，提取的概念能够引导模型内部表示，证明对下游行为的因果影响

Conclusion: 该方法为提取神经网络可解释概念提供了简单有效的无监督替代方案，能够提取高质量、多样化的概念，并展示了对模型行为的因果影响

Abstract: We propose an alternative to sparse autoencoders (SAEs) as a simple and effective unsupervised method for extracting interpretable concepts from neural networks. The core idea is to cluster differences in activations, which we formally justify within a discriminant analysis framework. To enhance the diversity of extracted concepts, we refine the approach by weighting the clustering using the skewness of activations. The method aligns with Deleuze's modern view of concepts as differences. We evaluate the approach across five models and three modalities (vision, language, and audio), measuring concept quality, diversity, and consistency. Our results show that the proposed method achieves concept quality surpassing prior unsupervised SAE variants while approaching supervised baselines, and that the extracted concepts enable steering of a model's inner representations, demonstrating their causal influence on downstream behavior.

</details>


### [42] [Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction](https://arxiv.org/abs/2512.19735)
*Gangxiong Zhang,Yongchao Long*

Main category: cs.LG

TL;DR: 提出CAP框架，通过案例提示改善ICU死亡率预测的公平性和准确性，无需重新训练即可减少人口统计学偏见。


<details>
  <summary>Details</summary>
Motivation: ICU死亡率预测对临床决策至关重要，但现有大型语言模型存在性别、年龄和种族等人口统计学偏见，现有去偏方法常降低预测性能，难以同时优化公平性和准确性。

Method: 提出CAP框架：1）开发多维偏见评估方案进行全面模型诊断；2）结合传统去偏提示与基于案例推理，引导模型从历史误判案例中学习，纠正偏见推理模式。

Result: 在MIMIC-IV数据集上，CAP将AUROC从0.806提升至0.873，AUPRC从0.497提升至0.694，同时将性别和种族相关差异减少90%以上，特征依赖分析显示跨人口群体注意力模式高度一致。

Conclusion: LLMs在ICU死亡率预测中存在可测量的偏见，精心设计的提示框架无需重新训练即可有效协同优化公平性和性能，为公平临床决策支持提供了可转移的范式。

Abstract: Accurate mortality risk prediction for intensive care unit (ICU) patients is essential for clinical decision-making. Although large language models (LLMs) show promise in predicting outcomes from structured medical data, their predictions may exhibit demographic biases related to sex, age, and race, limiting their trustworthy use in clinical practice. Existing debiasing methods often reduce predictive performance, making it difficult to jointly optimize fairness and accuracy. In this study, we systematically examine bias in LLM-based ICU mortality prediction and propose a training-free, clinically adaptive prompting framework to simultaneously improve fairness and performance. We first develop a multi-dimensional bias assessment scheme for comprehensive model diagnosis. Building on this analysis, we introduce CAse Prompting (CAP), a novel prompting framework that integrates conventional debiasing prompts with case-based reasoning. CAP guides the model to learn from similar historical misprediction cases and their correct outcomes, enabling correction of biased reasoning patterns. Experiments on the MIMIC-IV dataset show that CAP substantially improves both predictive accuracy and fairness. CAP increases AUROC from 0.806 to 0.873 and AUPRC from 0.497 to 0.694, while reducing sex- and race-related disparities by over 90%. Feature reliance analysis further indicates highly consistent attention patterns across demographic groups, with similarity scores exceeding 0.98. These results demonstrate that LLMs exhibit measurable bias in ICU mortality prediction, and that a carefully designed prompting framework can effectively co-optimize fairness and performance without retraining, offering a transferable paradigm for equitable clinical decision support.

</details>


### [43] [CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology](https://arxiv.org/abs/2512.19736)
*Gongli Xi,Ye Tian,Mengyu Yang,Zhenyu Zhao,Yuchao Zhang,Xiangyang Gong,Xirong Que,Wendong Wang*

Main category: cs.LG

TL;DR: 提出CoPHo方法，通过预训练图分类器的梯度指导拓扑生成，结合持续同调技术，在保持拓扑结构的同时匹配目标属性


<details>
  <summary>Details</summary>
Motivation: 现有拓扑数据稀缺，需要生成具有特定属性的合成图用于测试或发布。现有扩散方法要么需要为每个属性重新训练模型，要么使用分类器指导但未考虑拓扑尺度和实际约束

Method: 从离散视角出发，将预训练图分类器的梯度整合到离散反向扩散后验中，构建持续同调过滤过程，将特征作为指导信号，在每一步去噪过程中引导生成朝向目标属性

Result: 在四个通用/网络数据集上的实验表明，CoPHo在匹配目标指标方面优于现有方法，并在QM9分子数据集上验证了其可迁移性

Conclusion: CoPHo方法能够有效生成具有指定结构属性的拓扑图，解决了现有方法需要重新训练或未考虑拓扑约束的问题，具有实际应用价值

Abstract: The structure of topology underpins much of the research on performance and robustness, yet available topology data are typically scarce, necessitating the generation of synthetic graphs with desired properties for testing or release. Prior diffusion-based approaches either embed conditions into the diffusion model, requiring retraining for each attribute and hindering real-time applicability, or use classifier-based guidance post-training, which does not account for topology scale and practical constraints. In this paper, we show from a discrete perspective that gradients from a pre-trained graph-level classifier can be incorporated into the discrete reverse diffusion posterior to steer generation toward specified structural properties. Based on this insight, we propose Classifier-guided Conditional Topology Generation with Persistent Homology (CoPHo), which builds a persistent homology filtration over intermediate graphs and interprets features as guidance signals that steer generation toward the desired properties at each denoising step. Experiments on four generic/network datasets demonstrate that CoPHo outperforms existing methods at matching target metrics, and we further validate its transferability on the QM9 molecular dataset.

</details>


### [44] [Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach](https://arxiv.org/abs/2512.19737)
*Clément Elliker,Jesse Read,Sonia Vanier,Albert Bifet*

Main category: cs.LG

TL;DR: 提出Drift-Corrected Imitation Learning (DCIL)算法，通过距离漂移校正改进DAgger，用于列车延误预测，在比利时铁路数据集上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 可靠的列车延误预测对提高铁路运输系统的鲁棒性和效率至关重要。现有方法在捕捉延迟传播的序列性和不确定性方面存在局限。

Method: 将延误预测重构为随机模拟任务，通过模仿学习建模状态转移动态。提出DCIL算法，在DAgger基础上加入基于距离的漂移校正，缓解协变量偏移，无需外部oracle或对抗方案。

Result: 在比利时铁路基础设施管理公司Infrabel的超过300万次列车运行数据集上评估，针对30分钟内的预测，DCIL在预测性能上优于传统回归模型和基于深度学习的行为克隆方法。

Conclusion: DCIL成功结合事件驱动模型的动态保真度和数据驱动方法的表示能力，通过蒙特卡洛模拟实现不确定性感知预测，能有效捕捉大规模网络中延迟传播的序列性和不确定性。

Abstract: Reliable prediction of train delays is essential for enhancing the robustness and efficiency of railway transportation systems. In this work, we reframe delay forecasting as a stochastic simulation task, modeling state-transition dynamics through imitation learning. We introduce Drift-Corrected Imitation Learning (DCIL), a novel self-supervised algorithm that extends DAgger by incorporating distance-based drift correction, thereby mitigating covariate shift during rollouts without requiring access to an external oracle or adversarial schemes. Our approach synthesizes the dynamical fidelity of event-driven models with the representational capacity of data-driven methods, enabling uncertainty-aware forecasting via Monte Carlo simulation. We evaluate DCIL using a comprehensive real-world dataset from \textsc{Infrabel}, the Belgian railway infrastructure manager, which encompasses over three million train movements. Our results, focused on predictions up to 30 minutes ahead, demonstrate superior predictive performance of DCIL over traditional regression models and behavioral cloning on deep learning architectures, highlighting its effectiveness in capturing the sequential and uncertain nature of delay propagation in large-scale networks.

</details>


### [45] [OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting](https://arxiv.org/abs/2512.19738)
*Wilson Fung,Lu Guo,Drake Hilliard,Alessandro Casadei,Raj Ratan,Sreyoshi Bhaduri,Adi Surve,Nikhil Agarwal,Rohit Malshe,Pavan Mullapudi,Hungjen Wang,Saurabh Doodhwala,Ankush Pole,Arkajit Rakshit*

Main category: cs.LG

TL;DR: OpComm是一个结合监督学习、强化学习缓冲控制和生成式AI通信的包裹量预测与决策支持框架，在400多个配送站中降低了21.65%的预测误差，减少了缓冲不足事件。


<details>
  <summary>Details</summary>
Motivation: 最后一公里物流中包裹量预测的准确性至关重要，预测错误会导致资源分配低效、成本增加和配送延迟。需要一种能够平衡预测准确性和实际操作决策的系统。

Method: 使用LightGBM回归模型生成站点级需求预测，作为PPO强化学习代理的上下文，代理从离散动作集中选择缓冲水平。奖励函数对缓冲不足的惩罚比对缓冲过度的惩罚更重。通过蒙特卡洛更新机制持续调整策略，并使用生成式AI层基于SHAP特征归因生成执行级摘要和场景分析。

Result: 在400多个配送站中，OpComm将加权绝对百分比误差(WAPE)降低了21.65%，相比人工预测减少了缓冲不足事件，同时提高了决策者的透明度。

Conclusion: 这项工作展示了上下文强化学习与预测建模相结合，可以解决运营预测挑战，并在高风险物流环境中将统计严谨性与实际决策制定相结合。

Abstract: Accurate forecasting of package volumes at delivery stations is critical for last-mile logistics, where errors lead to inefficient resource allocation, higher costs, and delivery delays. We propose OpComm, a forecasting and decision-support framework that combines supervised learning with reinforcement learning-based buffer control and a generative AI-driven communication module. A LightGBM regression model generates station-level demand forecasts, which serve as context for a Proximal Policy Optimization (PPO) agent that selects buffer levels from a discrete action set. The reward function penalizes under-buffering more heavily than over-buffering, reflecting real-world trade-offs between unmet demand risks and resource inefficiency. Station outcomes are fed back through a Monte Carlo update mechanism, enabling continual policy adaptation. To enhance interpretability, a generative AI layer produces executive-level summaries and scenario analyses grounded in SHAP-based feature attributions. Across 400+ stations, OpComm reduced Weighted Absolute Percentage Error (WAPE) by 21.65% compared to manual forecasts, while lowering under-buffering incidents and improving transparency for decision-makers. This work shows how contextual reinforcement learning, coupled with predictive modeling, can address operational forecasting challenges and bridge statistical rigor with practical decision-making in high-stakes logistics environments.

</details>


### [46] [OASI: Objective-Aware Surrogate Initialization for Multi-Objective Bayesian Optimization in TinyML Keyword Spotting](https://arxiv.org/abs/2512.19739)
*Soumen Garai,Suman Samui*

Main category: cs.LG

TL;DR: 提出OASI初始化策略，使用多目标模拟退火生成高质量种子Pareto集，在TinyML关键词检测任务中超越传统初始化方法


<details>
  <summary>Details</summary>
Motivation: 在超低功耗TinyML设备上实现准确的关键词检测需要平衡精度和资源约束。多目标贝叶斯优化是理想选择，但高度依赖初始化，现有方法使用简单采样策略，未针对Pareto前沿优化且缺乏统计验证。

Method: 提出目标感知代理初始化(OASI)策略，利用多目标模拟退火生成高质量、多样化的种子Pareto配置集，明确平衡精度和模型大小。

Result: 在TinyML关键词检测任务中，OASI优于LHS、Sobol和随机初始化，获得最高超体积(0.0627)和最低代际距离(0.0)，计算时间仅适度增加(1934秒 vs. ~1500秒)。统计分析确认OASI的优越一致性。

Conclusion: OASI为多目标贝叶斯优化提供有效的初始化策略，在资源受限的TinyML应用中显著提升优化性能，为实际部署提供可靠解决方案。

Abstract: Voice assistants utilize Keyword Spotting (KWS) to enable efficient, privacy-friendly activation. However, realizing accurate KWS models on ultra-low-power TinyML devices (often with less than $<2$ MB of flash memory) necessitates a delicate balance between accuracy with strict resource constraints. Multi-objective Bayesian Optimization (MOBO) is an ideal candidate for managing such a trade-off but is highly initialization-dependent, especially under the budgeted black-box setting. Existing methods typically fall back to naive, ad-hoc sampling routines (e.g., Latin Hypercube Sampling (LHS), Sobol sequences, or Random search) that are adapted to neither the Pareto front nor undergo rigorous statistical comparison. To address this, we propose Objective-Aware Surrogate Initialization (OASI), a novel initialization strategy that leverages Multi-Objective Simulated Annealing (MOSA) to generate a seed Pareto set of high-performing and diverse configurations that explicitly balance accuracy and model size. Evaluated in a TinyML KWS setting, OASI outperforms LHS, Sobol, and Random initialization, achieving the highest hypervolume (0.0627) and the lowest generational distance (0.0) across multiple runs, with only a modest increase in computation time (1934 s vs. $\sim$1500 s). A non-parametric statistical analysis using the Kruskal-Wallis test ($H = 5.40$, $p = 0.144$, $η^2 = 0.0007$) and Dunn's post-hoc test confirms OASI's superior consistency despite the non-significant overall difference with respect to the $α=0.05$ threshold.

</details>


### [47] [Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics](https://arxiv.org/abs/2512.19740)
*Kousar Raza,Faizan Ali*

Main category: cs.LG

TL;DR: 构建了2025年亚洲杯T20板球锦标赛的结构化数据集，包含19场比赛的61个变量，支持体育分析研究


<details>
  <summary>Details</summary>
Motivation: 为板球分析研究提供开放、机器可读的基准数据集，支持数据驱动的体育分析、预测建模和战略决策

Method: 收集2025年亚洲杯T20锦标赛所有19场比赛数据，构建包含61个变量的结构化数据集，涵盖球队得分、三柱门、强力回合统计、边界数、投掷决策、场地和球员表现等

Result: 创建了全面的板球数据集，通过探索性数据分析展示了其在团队表现指标、边界分布和得分模式分析中的应用价值，数据已在Zenodo平台以CC-BY 4.0许可证公开

Conclusion: 该工作为板球分析研究提供了有价值的开放数据集，支持可重复性研究和板球分析、预测建模及战略决策的进一步发展

Abstract: This paper presents a structured and comprehensive dataset corresponding to the 2025 Asia Cup T20 cricket tournament, designed to facilitate data-driven research in sports analytics. The dataset comprises records from all 19 matches of the tournament and includes 61 variables covering team scores, wickets, powerplay statistics, boundary counts, toss decisions, venues, and player-specific highlights. To demonstrate its analytical value, we conduct an exploratory data analysis focusing on team performance indicators, boundary distributions, and scoring patterns. The dataset is publicly released through Zenodo under a CC-BY 4.0 license to support reproducibility and further research in cricket analytics, predictive modeling, and strategic decision-making. This work contributes an open, machine-readable benchmark dataset for advancing cricket analytics research.

</details>


### [48] [EdgeFlex-Transformer: Transformer Inference for Edge Devices](https://arxiv.org/abs/2512.19741)
*Shoaib Mohammad,Guanqun Song,Ting Zhu*

Main category: cs.LG

TL;DR: 提出轻量级多阶段优化流程，压缩Vision Transformers用于边缘部署，通过激活分析、剪枝、混合精度和量化，在CIFAR-10上实现76%内存降低和6倍延迟减少。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大规模Transformer模型面临内存、计算和延迟的严格约束，需要有效的压缩和加速方案。

Method: 结合激活分析、内存感知剪枝、选择性混合精度执行和激活感知量化(AWQ)的多阶段优化流程，无需昂贵重训练或任务特定微调。

Result: 从632M参数的ViT-Huge开始，在CIFAR-10上实现76%峰值内存降低和超过6倍延迟减少，同时保持或提高原始FP32基线的准确率。

Conclusion: 该框架为边缘平台上的高效Transformer推理提供了实用路径，并为集成动态稀疏性和MoE架构以进一步提升性能开辟了未来方向。

Abstract: Deploying large-scale transformer models on edge devices presents significant challenges due to strict constraints on memory, compute, and latency. In this work, we propose a lightweight yet effective multi-stage optimization pipeline designed to compress and accelerate Vision Transformers (ViTs) for deployment in resource-constrained environments. Our methodology combines activation profiling, memory-aware pruning, selective mixed-precision execution, and activation-aware quantization (AWQ) to reduce the model's memory footprint without requiring costly retraining or task-specific fine-tuning. Starting from a ViT-Huge backbone with 632 million parameters, we first identify low-importance channels using activation statistics collected via forward hooks, followed by structured pruning to shrink the MLP layers under a target memory budget. We further apply FP16 conversion to selected components and leverage AWQ to quantize the remaining model weights and activations to INT8 with minimal accuracy degradation. Our experiments on CIFAR-10 demonstrate that the fully optimized model achieves a 76% reduction in peak memory usage and over 6x lower latency, while retaining or even improving accuracy compared to the original FP32 baseline. This framework offers a practical path toward efficient transformer inference on edge platforms, and opens future avenues for integrating dynamic sparsity and Mixture-of-Experts (MoE) architectures to further scale performance across diverse tasks.

</details>


### [49] [On-device Large Multi-modal Agent for Human Activity Recognition](https://arxiv.org/abs/2512.19742)
*Md Shakhrul Iman Siam,Ishtiaque Ahmed Showmik,Guanqun Song,Ting Zhu*

Main category: cs.LG

TL;DR: 提出一个基于大语言模型的多模态智能体用于人类活动识别，不仅实现高精度分类，还通过推理和问答能力提升可解释性和用户交互体验。


<details>
  <summary>Details</summary>
Motivation: 人类活动识别在医疗保健和智能环境中有广泛应用，但现有方法缺乏可解释性和用户友好交互。大语言模型的进展为HAR带来了新可能，不仅能分类还能提供解释和交互。

Method: 设计了一个大型多模态智能体框架，整合大语言模型能力，通过多模态数据融合实现活动分类，并具备推理和问答功能来提供用户友好的洞察。

Result: 在HHAR、Shoaib、Motionsense等标准数据集上评估，模型达到与最先进方法相当的高分类精度，同时通过推理和问答能力显著提升了可解释性。

Conclusion: 该多模态智能体框架成功将大语言模型应用于人类活动识别，在保持高性能的同时增强了可解释性和用户交互，为HAR领域提供了新的研究方向。

Abstract: Human Activity Recognition (HAR) has been an active area of research, with applications ranging from healthcare to smart environments. The recent advancements in Large Language Models (LLMs) have opened new possibilities to leverage their capabilities in HAR, enabling not just activity classification but also interpretability and human-like interaction. In this paper, we present a Large Multi-Modal Agent designed for HAR, which integrates the power of LLMs to enhance both performance and user engagement. The proposed framework not only delivers activity classification but also bridges the gap between technical outputs and user-friendly insights through its reasoning and question-answering capabilities. We conduct extensive evaluations using widely adopted HAR datasets, including HHAR, Shoaib, Motionsense to assess the performance of our framework. The results demonstrate that our model achieves high classification accuracy comparable to state-of-the-art methods while significantly improving interpretability through its reasoning and Q&A capabilities.

</details>


### [50] [From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning](https://arxiv.org/abs/2512.19743)
*Sasan Sharifipour,Constantino Álvarez Casado,Manuel Lage Cañellas,Miguel Bordallo López*

Main category: cs.LG

TL;DR: CUDA-APML：一种稀疏GPU实现的点云损失函数，通过阈值化可忽略的分配和自适应softmax，在保持梯度的情况下将峰值GPU内存减少99.9%


<details>
  <summary>Details</summary>
Motivation: 现有点云损失函数存在权衡：Chamfer距离计算高效但允许多对一对应，Earth Mover距离能更好反映一对一传输但计算成本高，APML通过可微Sinkhorn迭代近似传输但内存呈二次方增长

Method: 提出CUDA-APML，稀疏GPU实现，通过阈值化可忽略的分配、运行自适应softmax、双向对称化和直接在COO形式中进行Sinkhorn归一化，实现近线性内存扩展

Result: 在ShapeNet和MM-Fi数据集上，CUDA-APML在微小容差内匹配密集APML性能，同时将峰值GPU内存减少99.9%，保持了存储支持上的梯度

Conclusion: CUDA-APML通过稀疏实现解决了APML内存二次方增长问题，在保持几何保真度的同时大幅降低计算成本，为点云学习提供了高效损失函数

Abstract: Loss functions are fundamental to learning accurate 3D point cloud models, yet common choices trade geometric fidelity for computational cost. Chamfer Distance is efficient but permits many-to-one correspondences, while Earth Mover Distance better reflects one-to-one transport at high computational cost. APML approximates transport with differentiable Sinkhorn iterations and an analytically derived temperature, but its dense formulation scales quadratically in memory. We present CUDA-APML, a sparse GPU implementation that thresholds negligible assignments and runs adaptive softmax, bidirectional symmetrization, and Sinkhorn normalization directly in COO form. This yields near-linear memory scaling and preserves gradients on the stored support, while pairwise distance evaluation remains quadratic in the current implementation. On ShapeNet and MM-Fi, CUDA-APML matches dense APML within a small tolerance while reducing peak GPU memory by 99.9%. Code available at: https://github.com/Multimodal-Sensing-Lab/apml

</details>


### [51] [DeepBridge: A Unified and Production-Ready Framework for Multi-Dimensional Machine Learning Validation](https://arxiv.org/abs/2512.19744)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: DeepBridge是一个8万行Python库，统一了多维验证、自动合规检查、知识蒸馏和合成数据生成，通过6个案例研究证明能减少89%验证时间，自动检测公平性违规，并生成审计就绪报告。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统验证工具分散，缺乏统一的合规检查、公平性评估和知识蒸馏框架，导致验证效率低下且覆盖不全。

Method: 提供5大验证套件（公平性、鲁棒性、不确定性、弹性、超参数敏感性），自动EEOC/ECOA/GDPR验证，多格式报告系统，HPM-KD知识蒸馏框架，以及基于Dask的可扩展合成数据生成。

Result: 验证时间减少89%（17分钟vs150分钟），公平性违规检测覆盖率100%（10/10特征vs现有工具2/10），HPM-KD在CIFAR100上压缩比2.3-7倍时性能提升1.00-2.04pp，可用性研究SUS得分87.5（前10%）。

Conclusion: DeepBridge提供了一个全面、高效的AI系统验证框架，显著提升验证效率和合规性，特别是在知识蒸馏中教师-学生差距较大时效果更佳，已开源并具备优秀可用性。

Abstract: We present DeepBridge, an 80K-line Python library that unifies multi-dimensional validation, automatic compliance verification, knowledge distillation, and synthetic data generation. DeepBridge offers: (i) 5 validation suites (fairness with 15 metrics, robustness with weakness detection, uncertainty via conformal prediction, resilience with 5 drift types, hyperparameter sensitivity), (ii) automatic EEOC/ECOA/GDPR verification, (iii) multi-format reporting system (interactive/static HTML, PDF, JSON), (iv) HPM-KD framework for knowledge distillation with meta-learning, and (v) scalable synthetic data generation via Dask. Through 6 case studies (credit scoring, hiring, healthcare, mortgage, insurance, fraud) we demonstrate that DeepBridge: reduces validation time by 89% (17 min vs. 150 min with fragmented tools), automatically detects fairness violations with complete coverage (10/10 features vs. 2/10 from existing tools), generates audit-ready reports in minutes. HPM-KD demonstrates consistent superiority across compression ratios 2.3--7x (CIFAR100): +1.00--2.04pp vs. Direct Training (p<0.05), confirming that Knowledge Distillation is effective at larger teacher-student gaps. Usability study with 20 participants shows SUS score 87.5 (top 10%, ``excellent''), 95% success rate, and low cognitive load (NASA-TLX 28/100). DeepBridge is open-source under MIT license at https://github.com/deepbridge/deepbridge, with complete documentation at https://deepbridge.readthedocs.io

</details>


### [52] [How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts](https://arxiv.org/abs/2512.19765)
*Sumin Park,Noseong Park*

Main category: cs.LG

TL;DR: MASS是一个语义感知的稀疏混合专家框架，通过梯度语义漂移检测和自适应路由策略，实现专家池的自适应扩展和动态路由，在语言和视觉领域均优于现有MoE基线。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏混合专家框架要么过度依赖超参数调优，要么在调整专家池大小时忽视了专家间语义角色的多样化，无法充分利用MoE架构的潜力。

Method: 提出MASS框架，包含两个关键创新：1) 基于梯度的语义漂移检测器，当现有专家池无法捕捉数据完整语义多样性时触发定向专家扩展；2) 自适应路由策略，基于令牌级路由置信度动态调整专家使用。

Result: 在高度控制的合成设置中，MASS可靠地收敛到成本-性能权衡的最优点，语义专业化显著改善。在语言和视觉领域的真实数据集上，MASS始终优于多种强MoE基线，展示了领域鲁棒性和增强的专家专业化。

Conclusion: MASS通过语义感知的自适应专家扩展和动态路由，有效解决了现有SMoE框架的局限性，在保持成本效益的同时实现了更好的语义专业化，具有跨领域应用的潜力。

Abstract: Finding the optimal configuration of Sparse Mixture-ofExperts (SMoE) that maximizes semantic differentiation among experts is essential for exploiting the full potential of MoE architectures. However, existing SMoE frameworks either heavily rely on hyperparameter tuning or overlook the importance of diversifying semantic roles across experts when adapting the expert pool size. We propose Mixture-of-Experts for Adaptive Semantic Specialization (MASS), a semanticaware MoE framework for adaptive expert expansion and dynamic routing. MASS introduces two key advancements: (i) a gradient-based semantic drift detector that prompts targeted expert expansion when the existing expert pool lacks capacity to capture the full semantic diversity of the data, and (ii) an integration of adaptive routing strategy that dynamically adjusts expert usage based on token-level routing confidence mass. We first demonstrate that MASS reliably converges to the point of optimal balance between cost-performance trade-off with notably improved sematic specialization in a highly controlled synthetic setup. Further empirical results on real-world datasets across language and vision domains show that MASS consistently outperforms a range of strong MoE baselines, demonstrating its domain robustness and enhanced expert specialization.

</details>


### [53] [Learning to Design City-scale Transit Routes](https://arxiv.org/abs/2512.19767)
*Bibek Poudel,Weizi Li*

Main category: cs.LG

TL;DR: 提出基于图注意力网络的端到端强化学习框架，用于序列化公交网络设计，在真实数据集上显著超越人工设计和传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 公交路线网络设计是NP难问题，传统依赖人工规划，搜索空间指数级增长，需要自动化高效解决方案。

Method: 基于图注意力网络的端到端强化学习框架，采用双层奖励结构（增量拓扑反馈+基于仿真的终端奖励），进行序列化公交网络构建。

Result: 在印第安纳州布卢明顿真实数据集上，显著优于现有设计和传统启发式方法：高公交采用率下服务率提升25.6%，等待时间缩短30.9%，公交利用率提高21.0%；混合模式下路线效率比需求覆盖启发式高68.8%，旅行时间比最短路径构建低5.9%。

Conclusion: 端到端强化学习能够设计出在真实城市规模基准上显著优于人工设计系统和手工启发式方法的公交网络。

Abstract: Designing efficient transit route networks is an NP-hard problem with exponentially large solution spaces that traditionally relies on manual planning processes. We present an end-to-end reinforcement learning (RL) framework based on graph attention networks for sequential transit network construction. To address the long-horizon credit assignment challenge, we introduce a two-level reward structure combining incremental topological feedback with simulation-based terminal rewards. We evaluate our approach on a new real-world dataset from Bloomington, Indiana with topologically accurate road networks, census-derived demand, and existing transit routes. Our learned policies substantially outperform existing designs and traditional heuristics across two initialization schemes and two modal-split scenarios. Under high transit adoption with transit center initialization, our approach achieves 25.6% higher service rates, 30.9\% shorter wait times, and 21.0% better bus utilization compared to the real-world network. Under mixed-mode conditions with random initialization, it delivers 68.8% higher route efficiency than demand coverage heuristics and 5.9% lower travel times than shortest path construction. These results demonstrate that end-to-end RL can design transit networks that substantially outperform both human-designed systems and hand-crafted heuristics on realistic city-scale benchmarks.

</details>


### [54] [A K-Means, Ward and DBSCAN repeatability study](https://arxiv.org/abs/2512.19772)
*Anthony Bertrand,Engelbert Mephu Nguifo,Violaine Antoine,David Hill*

Main category: cs.LG

TL;DR: 该论文分析了K-Means、DBSCAN和Ward聚类算法的可重复性，发现K-Means在OpenMP线程数超过2时会产生不一致结果，旨在提高用户和开发者对这一问题的认识。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的可重复性对于确保模型或实验得出相同科学结论至关重要。对于特定算法，具有比特级相同结果的可重复性也是科学完整性的关键，因为它允许调试。

Method: 将K-Means、DBSCAN和Ward聚类算法分解为基本步骤，识别每个阶段实现可重复性所需的条件。使用Python库scikit-learn的实现示例来检查每个方法的可重复性方面。

Result: 研究结果显示，当OpenMP线程数超过两个时，K-Means会产生不一致的结果。DBSCAN和Ward算法的可重复性分析也提供了相应发现。

Conclusion: 这项工作旨在提高用户和开发者对聚类算法可重复性问题的认识，鼓励进一步调查和潜在修复，特别是针对K-Means在并行计算环境中的不一致性问题。

Abstract: Reproducibility is essential in machine learning because it ensures that a model or experiment yields the same scientific conclusion. For specific algorithms repeatability with bitwise identical results is also a key for scientific integrity because it allows debugging. We decomposed several very popular clustering algorithms: K-Means, DBSCAN and Ward into their fundamental steps, and we identify the conditions required to achieve repeatability at each stage. We use an implementation example with the Python library scikit-learn to examine the repeatable aspects of each method. Our results reveal inconsistent results with K-Means when the number of OpenMP threads exceeds two. This work aims to raise awareness of this issue among both users and developers, encouraging further investigation and potential fixes.

</details>


### [55] [Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy](https://arxiv.org/abs/2512.19805)
*Deepit Sapru*

Main category: cs.LG

TL;DR: 提出一个营销决策框架，将异质处理效应转化为受约束的目标策略，在遵守业务护栏的同时最大化收入和留存率。


<details>
  <summary>Details</summary>
Motivation: 传统营销策略往往基于倾向性评分或静态规则，无法考虑个体异质处理效应，且难以在最大化业务指标的同时遵守预算、客户体验等业务约束。

Method: 使用提升学习器估计条件平均处理效应(CATE)，然后通过约束分配优化决定目标受众和优惠方案，在预算、可接受的销售下降等限制条件下进行决策。

Result: 在留存消息、事件奖励和消费阈值分配等应用中，该框架在离线评估中持续优于倾向性和静态基线方法。在线A/B测试进一步验证了在保持客户体验约束的同时，对收入和完成率的战略提升。

Conclusion: 该框架为营销人员提供了一个可重复使用的操作手册，用于规模化实施因果目标定位、设置业务护栏，并使营销活动与战略关键绩效指标保持一致。

Abstract: This paper introduces a marketing decision framework that converts heterogeneous-treatment uplift into constrained targeting strategies to maximize revenue and retention while honoring business guardrails. The approach estimates Conditional Average Treatment Effects (CATE) with uplift learners and then solves a constrained allocation to decide who to target and which offer to deploy under limits such as budget or acceptable sales deterioration. Applied to retention messaging, event rewards, and spend-threshold assignment, the framework consistently outperforms propensity and static baselines in offline evaluations using uplift AUC, Inverse Propensity Scoring (IPS), and Self-Normalized IPS (SNIPS). A production-scale online A/B test further validates strategic lift on revenue and completion while preserving customer-experience constraints. The result is a reusable playbook for marketers to operationalize causal targeting at scale, set guardrails, and align campaigns with strategic KPIs.

</details>


### [56] [Fine-Tuned In-Context Learners for Efficient Adaptation](https://arxiv.org/abs/2512.19879)
*Jorg Bornschein,Clare Lyle,Yazhe Li,Amal Rannen-Triki,Xu Owen He,Razvan Pascanu*

Main category: cs.LG

TL;DR: 提出统一方法，将上下文学习融入微调过程，在少样本和多数据场景下均优于传统提示工程和微调方法


<details>
  <summary>Details</summary>
Motivation: 传统LLM适配方法存在局限：提示工程在数据增多时效果停滞，微调在少样本时表现不佳。需要一种能结合两者优势的统一方法。

Method: 在微调过程中融入上下文学习，使用任务特定数据增强上下文示例，模拟k-shot提示结构。采用预序评估进行超参数选择，避免昂贵交叉验证。

Result: 提出的统一方法在少样本和多数据场景下均优于传统提示工程和微调基线，结合了上下文学习的样本效率和微调的性能增益。

Conclusion: 将上下文学习融入微调过程的统一方法优于传统适配范式，在少样本和多数据场景下均能提供最佳预测性能。

Abstract: When adapting large language models (LLMs) to a specific downstream task, two primary approaches are commonly employed: (1) prompt engineering, often with in-context few-shot learning, leveraging the model's inherent generalization abilities, and (2) fine-tuning on task-specific data, directly optimizing the model's parameters. While prompt-based methods excel in few-shot scenarios, their effectiveness often plateaus as more data becomes available. Conversely, fine-tuning scales well with data but may underperform when training examples are scarce. We investigate a unified approach that bridges these two paradigms by incorporating in-context learning directly into the fine-tuning process. Specifically, we fine-tune the model on task-specific data augmented with in-context examples, mimicking the structure of k-shot prompts. This approach, while requiring per-task fine-tuning, combines the sample efficiency of in-context learning with the performance gains of fine-tuning, leading to a method that consistently matches and often significantly exceeds both these baselines. To perform hyperparameter selection in the low-data regime, we propose to use prequential evaluation, which eliminates the need for expensive cross-validation and leverages all available data for training while simultaneously providing a robust validation signal. We conduct an extensive empirical study to determine which adaptation paradigm - fine-tuning, in-context learning, or our proposed unified approach offers the best predictive performance on a concrete data downstream-tasks.

</details>


### [57] [Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling](https://arxiv.org/abs/2512.19905)
*Indranil Halder,Cengiz Pehlevan*

Main category: cs.LG

TL;DR: 本文提出一个可解析处理的推理时间缩放模型，研究在贝叶斯线性回归框架下，通过奖励加权采样优化推理性能的规律，发现推理时间样本数k与泛化误差的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展将更多计算资源从训练时间转移到推理时间，但推理时间缩放的基本原理尚不明确。本文旨在建立一个可解析处理的模型来理解推理时间缩放规律，特别是在高维情况下的理论特性。

Method: 采用贝叶斯线性回归与奖励加权采样器模型，其中奖励由线性模型决定，模拟LLM作为评判者的场景。在高维体系下，通过确定性等价获得后验预测均值和方差的闭式表达式，分析从教师模型采样的训练数据的泛化误差。

Result: 当奖励与教师模型差异不大时，泛化误差随推理时间样本数k增加单调下降；但最优推理时间选择通常需要与教师不同的奖励。严重奖励错误设定会导致存在有限最优k，超过该值更多采样反而增加泛化误差。对于固定k，存在最优采样温度。实验验证了这些结论。

Conclusion: 本文建立了推理时间缩放的理论框架，揭示了推理时间计算与数据收集之间的权衡关系。在"best-of-k"极限下，泛化误差以Θ(1/k²)衰减，确定了推理时间计算优于收集更多数据的理论边界。任务难度增加会降低推理时间计算的优势。

Abstract: Recent developments in large language models have shown advantages in reallocating a notable share of computational resource from training time to inference time. However, the principles behind inference time scaling are not well understood. In this paper, we introduce an analytically tractable model of inference-time scaling: Bayesian linear regression with a reward-weighted sampler, where the reward is determined from a linear model, modeling LLM-as-a-judge scenario. We study this problem in the high-dimensional regime, where the deterministic equivalents dictate a closed-form expression for the posterior predictive mean and variance. We analyze the generalization error when training data are sampled from a teacher model. We draw $k$ inference-time samples and select via softmax at a temperature applied to a quadratic reward. When the reward is not too different from the teacher, the generalization error decreases monotonically with increasing inference time samples $k$. However, the specific reward that optimizes inference-time selection generally differs from the teacher. In contrast, substantial reward misspecification induces a finite optimal $k$ beyond which more sampling can increase the generalization error. For fixed $k$, there exists an optimal sampling temperature. We experimentally verify these facts in large language model inference with an additional large language model as a judge. In the "best-of-$k$" limit with the teacher as reward, we theoretically show that the generalization error decays as $Θ(1/k^2)$ and determine the leading coefficient via extreme value theory. These formulas delineate domains where scaling inference-time computation is provably preferable to collecting more data. Finally, we demonstrate that when task difficulty increases, the previously mentioned advantage of inference-time compute degrades.

</details>


### [58] [Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra](https://arxiv.org/abs/2512.19909)
*Maxime Lacour,Pu Ren,Rie Nakata,Nori Nakata,Michael Mahoney*

Main category: cs.LG

TL;DR: 提出基于深度学习的CGM-FAS方法替代传统GP方法，用于非遍历性傅里叶振幅谱路径效应建模，具有更好的计算效率和空间模式学习能力


<details>
  <summary>Details</summary>
Motivation: 当前非遍历性地震动模型依赖高斯过程方法，存在计算限制，难以进行大规模预测。需要更高效的方法来建模空间变化和频率相关性

Method: 使用条件变分自编码器架构，以地震和台站的地理坐标为条件变量，直接从数据中学习空间模式和频率间相关性

Result: 在旧金山湾区数据上，CGM-FAS与传统GP方法预测结果一致，但具有更快的计算速度（1万站点×1千频率在10秒内完成），且能学习无预设相关函数的空间模式

Conclusion: CGM-FAS为多频率、大空间域的非遍历性地震动预测提供了高效且有前景的新方向

Abstract: Recent developments in non-ergodic ground-motion models (GMMs) explicitly model systematic spatial variations in source, site, and path effects, reducing standard deviation to 30-40% of ergodic models and enabling more accurate site-specific seismic hazard analysis. Current non-ergodic GMMs rely on Gaussian Process (GP) methods with prescribed correlation functions and thus have computational limitations for large-scale predictions. This study proposes a deep-learning approach called Conditional Generative Modeling for Fourier Amplitude Spectra (CGM-FAS) as an alternative to GP-based methods for modeling non-ergodic path effects in Fourier Amplitude Spectra (FAS). CGM-FAS uses a Conditional Variational Autoencoder architecture to learn spatial patterns and interfrequency correlation directly from data by using geographical coordinates of earthquakes and stations as conditional variables. Using San Francisco Bay Area earthquake data, we compare CGM-FAS against a recent GP-based GMM for the region and demonstrate consistent predictions of non-ergodic path effects. Additionally, CGM-FAS offers advantages compared to GP-based approaches in learning spatial patterns without prescribed correlation functions, capturing interfrequency correlations, and enabling rapid predictions, generating maps for 10,000 sites across 1,000 frequencies within 10 seconds using a few GB of memory. CGM-FAS hyperparameters can be tuned to ensure generated path effects exhibit variability consistent with the GP-based empirical GMM. This work demonstrates a promising direction for efficient non-ergodic ground-motion prediction across multiple frequencies and large spatial domains.

</details>


### [59] [Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning](https://arxiv.org/abs/2512.19920)
*Jiayun Wu,Jiashuo Liu,Zhiyuan Zeng,Tianyang Zhan,Wenhao Huang*

Main category: cs.LG

TL;DR: 该论文提出通过行为校准训练方法，使LLM能够诚实表达不确定性，从而减少幻觉。通过优化严格适当评分规则，让模型输出校准后的正确概率，实现不确定性量化能力的提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在关键领域部署受到幻觉问题的阻碍。现有RLVR范式使用二元奖励信号，无意中鼓励模型成为"优秀应试者"而非诚实沟通者，只要正确概率超过零就会猜测，而不是承认不确定性。

Method: 提出行为校准训练方法，优化严格适当评分规则，使模型输出校准后的正确概率。模型可以在不确定时完全弃权，或在具体声明处标记不确定性。使用Qwen3-4B-Instruct进行实证分析。

Result: 行为校准强化学习使小模型在不确定性量化方面超越前沿模型。在数学推理任务上，模型的Accuracy-to-Hallucination Ratio增益(0.806)超过GPT-5(0.207)。在事实QA任务中，4B模型实现与前沿模型相当的零样本校准误差。

Conclusion: 行为校准训练能够有效提升LLM的不确定性量化能力，使小模型在诚实表达不确定性方面超越前沿大模型，为减少幻觉提供了有前景的解决方案。

Abstract: LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest hallucination is not merely stochastic error but a predictable statistical consequence of training objectives prioritizing mimicking data distribution over epistemic honesty. Standard RLVR paradigms, utilizing binary reward signals, inadvertently incentivize models as good test-takers rather than honest communicators, encouraging guessing whenever correctness probability exceeds zero. This paper presents an exhaustive investigation into behavioral calibration, which incentivizes models to stochastically admit uncertainty by abstaining when not confident, aligning model behavior with accuracy. Synthesizing recent advances, we propose and evaluate training interventions optimizing strictly proper scoring rules for models to output a calibrated probability of correctness. Our methods enable models to either abstain from producing a complete response or flag individual claims where uncertainty remains. Utilizing Qwen3-4B-Instruct, empirical analysis reveals behavior-calibrated reinforcement learning allows smaller models to surpass frontier models in uncertainty quantification--a transferable meta-skill decouplable from raw predictive accuracy. Trained on math reasoning tasks, our model's log-scale Accuracy-to-Hallucination Ratio gain (0.806) exceeds GPT-5's (0.207) in a challenging in-domain evaluation (BeyondAIME). Moreover, in cross-domain factual QA (SimpleQA), our 4B LLM achieves zero-shot calibration error on par with frontier models including Grok-4 and Gemini-2.5-Pro, even though its factual accuracy is much lower.

</details>


### [60] [The Seismic Wavefield Common Task Framework](https://arxiv.org/abs/2512.19927)
*Alexey Yermakov,Yue Zhao,Marine Denolle,Yiyu Ni,Philippe M. Wyder,Judah Goldfeder,Stefano Riva,Jan Williams,David Zoro,Amy Sara Rude,Matteo Tomasetto,Joe Germany,Joseph Bakarji,Georg Maierhofer,Miles Cranmer,J. Nathan Kutz*

Main category: cs.LG

TL;DR: 该论文提出了用于地震波场机器学习的通用任务框架（CTF），包含三个不同尺度的数据集和特定任务指标，旨在通过标准化评估提升科学机器学习的严谨性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 地震学在状态预测和重建（如地震预警和地面运动预测）以及管理源位置、机制和地球模型的参数变异性方面面临根本挑战。现有模拟方法受限于大规模计算，而真实数据方法受限于模型复杂性和稀疏传感器测量。机器学习方法虽有前景，但缺乏适当的特征描述、公平报告和严格比较。

Method: 引入地震波场机器学习的通用任务框架（CTF），包含三个不同尺度的数据集（全球、地壳和局部），以及针对预测、重建和泛化的特定任务指标。框架采用隐藏测试集进行标准化评估，受自然语言处理等领域CTF的启发。

Result: 在两个数据集上展示了各种方法和基础模型的评估结果，CTF评分揭示了不同方法在特定问题类别中的优势、局限性和适用性。框架能够进行算法间的直接比较。

Conclusion: 该CTF框架旨在取代临时性的比较方法，通过标准化评估和隐藏测试集，提高科学机器学习的严谨性和可重复性，为地震波场机器学习研究提供结构化基础。

Abstract: Seismology faces fundamental challenges in state forecasting and reconstruction (e.g., earthquake early warning and ground motion prediction) and managing the parametric variability of source locations, mechanisms, and Earth models (e.g., subsurface structure and topography effects). Addressing these with simulations is hindered by their massive scale, both in synthetic data volumes and numerical complexity, while real-data efforts are constrained by models that inadequately reflect the Earth's complexity and by sparse sensor measurements from the field. Recent machine learning (ML) efforts offer promise, but progress is obscured by a lack of proper characterization, fair reporting, and rigorous comparisons. To address this, we introduce a Common Task Framework (CTF) for ML for seismic wavefields, starting with three distinct wavefield datasets. Our CTF features a curated set of datasets at various scales (global, crustal, and local) and task-specific metrics spanning forecasting, reconstruction, and generalization under realistic constraints such as noise and limited data. Inspired by CTFs in fields like natural language processing, this framework provides a structured and rigorous foundation for head-to-head algorithm evaluation. We illustrate the evaluation procedure with scores reported for two of the datasets, showcasing the performance of various methods and foundation models for reconstructing seismic wavefields from both simulated and real-world sensor measurements. The CTF scores reveal the strengths, limitations, and suitability for specific problem classes. Our vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets, raising the bar for rigor and reproducibility in scientific ML.

</details>


### [61] [Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress](https://arxiv.org/abs/2512.19935)
*Samruddhi Baviskar*

Main category: cs.LG

TL;DR: 金融机器学习模型在宏观经济压力期间对抗性脆弱性会系统性放大，需要基于经济状态的评估框架


<details>
  <summary>Details</summary>
Motivation: 金融决策系统在非平稳经济环境中运行，但对抗性鲁棒性评估通常基于静态假设，忽略了宏观经济压力期间可能出现的系统性脆弱性

Method: 提出基于波动率的制度分割方法，将经济状态分为平静期和压力期，在保持模型架构、攻击方法和评估协议不变的情况下，评估不同制度下的对抗性鲁棒性，并引入基于大语言模型的语义审计解释层

Result: 在压力制度下，模型对抗性扰动表现出显著更大的性能退化，包括预测准确性、操作决策阈值和风险敏感结果，特别是假阴性率增加，导致在不利条件下错过高风险案例的风险升高

Conclusion: 金融机器学习中的对抗性鲁棒性是制度依赖属性，需要在高风险金融部署中采用压力感知的模型风险评估方法

Abstract: Machine learning models used in financial decision systems operate in nonstationary economic environments, yet adversarial robustness is typically evaluated under static assumptions. This work introduces Conditional Adversarial Fragility, a regime dependent phenomenon in which adversarial vulnerability is systematically amplified during periods of macroeconomic stress. We propose a regime aware evaluation framework for time indexed tabular financial classification tasks that conditions robustness assessment on external indicators of economic stress. Using volatility based regime segmentation as a proxy for macroeconomic conditions, we evaluate model behavior across calm and stress periods while holding model architecture, attack methodology, and evaluation protocols constant. Baseline predictive performance remains comparable across regimes, indicating that economic stress alone does not induce inherent performance degradation. Under adversarial perturbations, however, models operating during stress regimes exhibit substantially greater degradation across predictive accuracy, operational decision thresholds, and risk sensitive outcomes. We further demonstrate that this amplification propagates to increased false negative rates, elevating the risk of missed high risk cases during adverse conditions. To complement numerical robustness metrics, we introduce an interpretive governance layer based on semantic auditing of model explanations using large language models. Together, these results demonstrate that adversarial robustness in financial machine learning is a regime dependent property and motivate stress aware approaches to model risk assessment in high stakes financial deployments.

</details>


### [62] [Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis](https://arxiv.org/abs/2512.19970)
*Surya Jayakumar,Kieran Sullivan,John McLaughlin,Christine O'Meara,Indrakshi Dey*

Main category: cs.LG

TL;DR: 首次在县级尺度应用时空图神经网络预测复合可持续性指数，使用VAE增强数据，通过PCA构建四大支柱指数，并预测2026-2030年趋势


<details>
  <summary>Details</summary>
Motivation: 解决畜牧业可持续性评估中数据稀疏性和时空依赖关系建模的挑战，为县级尺度提供数据驱动的可持续性预测框架

Method: 1) 使用变分自编码器增强爱尔兰牛育种联合会数据集；2) 通过主成分分析构建繁殖效率、遗传管理、畜群健康和畜群管理四大支柱的加权复合指数；3) 设计新颖的时空图神经网络架构，显式编码地理依赖性和非线性时间动态

Result: 开发了首个县级尺度的STGNN框架，能够生成2026-2030年的多年预测，为畜牧业可持续性提供前瞻性评估工具

Conclusion: 该研究提出的数据驱动框架成功解决了畜牧业可持续性预测中的时空建模挑战，为政策制定和农场管理提供了创新的预测工具

Abstract: This study introduces a novel data-driven framework and the first-ever county-scale application of Spatio-Temporal Graph Neural Networks (STGNN) to forecast composite sustainability indices from herd-level operational records. The methodology employs a novel, end-to-end pipeline utilizing a Variational Autoencoder (VAE) to augment Irish Cattle Breeding Federation (ICBF) datasets, preserving joint distributions while mitigating sparsity. A first-ever pillar-based scoring formulation is derived via Principal Component Analysis, identifying Reproductive Efficiency, Genetic Management, Herd Health, and Herd Management, to construct weighted composite indices. These indices are modelled using a novel STGNN architecture that explicitly encodes geographic dependencies and non-linear temporal dynamics to generate multi-year forecasts for 2026-2030.

</details>


### [63] [Bloom Filter Encoding for Machine Learning](https://arxiv.org/abs/2512.19991)
*John Cartmell,Mihaela Cardei,Ionut Cardei*

Main category: cs.LG

TL;DR: 使用Bloom过滤器变换预处理机器学习数据，将样本编码为紧凑的隐私保护位数组，在保持分类准确性的同时减少内存使用并增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 机器学习中数据预处理需要平衡内存效率、隐私保护和模型性能。传统方法往往在隐私保护和计算效率之间难以兼顾，需要一种既能保护原始数据隐私，又能保持足够数据结构用于准确分类的预处理方法。

Method: 采用Bloom过滤器变换对数据进行预处理，将每个样本编码为紧凑的位数组。这种方法通过哈希函数将数据特征映射到位数组中，既保护了原始数据的隐私，又保留了足够的数据结构信息。在六个不同数据集上测试了该方法，并使用四种不同的分类器进行评估。

Result: 在六个数据集（SMS垃圾邮件、ECG200、Adult 50K、CDC糖尿病、MNIST、Fashion MNIST）上测试表明，使用Bloom过滤器编码训练的模型能达到与原始数据或其他变换方法相似的准确率。同时，该方法显著减少了内存使用并增强了隐私保护。

Conclusion: Bloom过滤器变换是一种高效的机器学习数据预处理方法，能够在保持模型性能的同时实现内存节省和隐私增强，适用于多样化的机器学习任务。

Abstract: We present a method that uses the Bloom filter transform to preprocess data for machine learning. Each sample is encoded into a compact, privacy-preserving bit array. This reduces memory use and protects the original data while keeping enough structure for accurate classification. We test the method on six datasets: SMS Spam Collection, ECG200, Adult 50K, CDC Diabetes, MNIST, and Fashion MNIST. Four classifiers are used: Extreme Gradient Boosting, Deep Neural Networks, Convolutional Neural Networks, and Logistic Regression. Results show that models trained on Bloom filter encodings achieve accuracy similar to models trained on raw data or other transforms. At the same time, the method provides memory savings while enhancing privacy. These results suggest that the Bloom filter transform is an efficient preprocessing approach for diverse machine learning tasks.

</details>


### [64] [LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2512.20002)
*Jiacheng You,Jingcheng Yang,Yuhang Xie,Zhongxuan Wu,Xiucheng Li,Feng Li,Pengjie Wang,Jian Xu,Bo Zheng,Xinyang Chen*

Main category: cs.LG

TL;DR: LoFT-LLM：一种结合低频学习和LLM语义校准的频率感知时间序列预测方法，在金融和能源数据集上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现实应用中的时间序列预测面临训练数据有限和复杂噪声动态的挑战。现有深度预测模型通常使用包含高频噪声的完整时间窗口进行监督，这掩盖了长期趋势。此外，包含丰富领域信息的辅助变量在少样本设置中往往未得到充分利用。

Method: 提出LoFT-LLM频率感知预测管道：1) 补丁低频预测模块(PLFM)从局部频谱补丁中提取稳定的低频趋势；2) 残差学习器建模高频变化；3) 微调的LLM通过结构化自然语言提示整合辅助上下文和领域知识来精炼预测。

Result: 在金融和能源数据集上的大量实验表明，LoFT-LLM在完整数据和少样本情况下都显著优于强基线方法，提供了更优的准确性、鲁棒性和可解释性。

Conclusion: LoFT-LLM通过结合低频学习和LLM语义校准，有效解决了时间序列预测中的噪声问题和辅助信息利用不足的挑战，在少样本和完整数据场景下都表现出色。

Abstract: Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length temporal windows, which include substantial high-frequency noise and obscure long-term trends. Moreover, auxiliary variables containing rich domain-specific information are often underutilized, especially in few-shot settings. To address these challenges, we propose LoFT-LLM, a frequency-aware forecasting pipeline that integrates low-frequency learning with semantic calibration via a large language model (LLM). Firstly, a Patch Low-Frequency forecasting Module (PLFM) extracts stable low-frequency trends from localized spectral patches. Secondly, a residual learner then models high-frequency variations. Finally, a fine-tuned LLM refines the predictions by incorporating auxiliary context and domain knowledge through structured natural language prompts. Extensive experiments on financial and energy datasets demonstrate that LoFT-LLM significantly outperforms strong baselines under both full-data and few-shot regimes, delivering superior accuracy, robustness, and interpretability.

</details>


### [65] [Control Variate Score Matching for Diffusion Models](https://arxiv.org/abs/2512.20003)
*Khaled Kahouli,Romuald Elie,Klaus-Robert Müller,Quentin Berthet,Oliver T. Unke,Arnaud Doucet*

Main category: cs.LG

TL;DR: 提出Control Variate Score Identity (CVSI)，通过控制变量方法统一DSI和TSI两种分数估计器，实现全噪声谱上的方差最小化，提高采样效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型需要准确估计噪声扰动目标分布的分数。标准Denoising Score Identity (DSI)依赖数据样本，而Target Score Identity (TSI)利用目标能量函数。但两者存在根本的方差权衡：DSI在低噪声区域方差高，TSI在高噪声水平方差高。需要解决这一方差权衡问题。

Method: 提出Control Variate Score Identity (CVSI)，在控制变量的理论框架下统一DSI和TSI两种估计器。推导出最优的时间依赖控制系数，理论上保证在整个噪声谱上的方差最小化。

Result: CVSI作为稳健的低方差插件估计器，显著提高了无数据采样器学习和推理时扩散采样的样本效率。

Conclusion: 通过控制变量方法统一DSI和TSI，提出的CVSI解决了分数估计中的方差权衡问题，为扩散模型提供了更高效的采样方法。

Abstract: Diffusion models offer a robust framework for sampling from unnormalized probability densities, which requires accurately estimating the score of the noise-perturbed target distribution. While the standard Denoising Score Identity (DSI) relies on data samples, access to the target energy function enables an alternative formulation via the Target Score Identity (TSI). However, these estimators face a fundamental variance trade-off: DSI exhibits high variance in low-noise regimes, whereas TSI suffers from high variance at high noise levels. In this work, we reconcile these approaches by unifying both estimators within the principled framework of control variates. We introduce the Control Variate Score Identity (CVSI), deriving an optimal, time-dependent control coefficient that theoretically guarantees variance minimization across the entire noise spectrum. We demonstrate that CVSI serves as a robust, low-variance plug-in estimator that significantly enhances sample efficiency in both data-free sampler learning and inference-time diffusion sampling.

</details>


### [66] [Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance](https://arxiv.org/abs/2512.20006)
*Sukumar Kishanthan,Asela Hevapathige*

Main category: cs.LG

TL;DR: 提出名为OGAB的新型激活函数，通过正交性和分组感知偏置学习来缓解深度学习分类器中的类别不平衡问题，无需显式标签信息。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习和数据挖掘中的常见挑战，会导致分类器性能下降。深度学习虽然在特征提取方面表现出色，但在不平衡数据下性能仍然会恶化。现有方法通常通过预处理数据修改或后处理校正来解决类别不平衡，但本文希望在训练阶段嵌入学习层面直接解决这一问题。

Method: 提出OGAB激活函数，结合正交变换和分组感知偏置学习机制。正交变换通过保持特征独立性来保护少数类信息，防止多数类在嵌入空间中占据主导地位。分组感知偏置机制自动识别数据聚类并调整嵌入以增强类别可分性，无需显式监督。

Result: 在真实世界和合成的类别不平衡数据集上验证了OGAB的有效性，相比传统和可学习激活函数，显示出持续的性能改进。

Conclusion: 激活函数可以引入强归纳偏置来解决复杂数据挑战，超越传统的非线性功能。OGAB在训练阶段嵌入学习层面直接解决类别不平衡问题，无需显式标签信息，为处理类别不平衡提供了新的有效方法。

Abstract: Class imbalance is a common challenge in machine learning and data mining, often leading to suboptimal performance in classifiers. While deep learning excels in feature extraction, its performance still deteriorates under imbalanced data. In this work, we propose a novel activation function, named OGAB, designed to alleviate class imbalance in deep learning classifiers. OGAB incorporates orthogonality and group-aware bias learning to enhance feature distinguishability in imbalanced scenarios without explicitly requiring label information. Our key insight is that activation functions can be used to introduce strong inductive biases that can address complex data challenges beyond traditional non-linearity. Our work demonstrates that orthogonal transformations can preserve information about minority classes by maintaining feature independence, thereby preventing the dominance of majority classes in the embedding space. Further, the proposed group-aware bias mechanism automatically identifies data clusters and adjusts embeddings to enhance class separability without the need for explicit supervision. Unlike existing approaches that address class imbalance through preprocessing data modifications or post-processing corrections, our proposed approach tackles class imbalance during the training phase at the embedding learning level, enabling direct integration with the learning process. We demonstrate the effectiveness of our solution on both real-world and synthetic imbalanced datasets, showing consistent performance improvements over both traditional and learnable activation functions.

</details>


### [67] [DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics](https://arxiv.org/abs/2512.20028)
*Yuan Gao,Zhenguo Dong,Xuelong Wang,Zhiqiang Wang,Yong Zhang,Shaofan Wang*

Main category: cs.LG

TL;DR: DeCoKAN：一个可解释的加密货币预测框架，结合离散小波变换进行信号分解和Kolmogorov-Arnold网络进行透明建模，在保持高预测精度的同时提供符号化解释。


<details>
  <summary>Details</summary>
Motivation: 加密货币数据包含长期社会经济趋势和局部高频投机振荡，现有深度学习"黑盒"模型无法有效解耦这些复合动态，也缺乏金融决策所需的可解释性。

Method: 提出DeCoKAN框架：1) 使用多级离散小波变换(DWT)分解加密货币时间序列为不同频率分量；2) 采用Kolmogorov-Arnold网络(KAN)混频器进行透明可解释的非线性建模；3) 通过稀疏化、剪枝和符号化增强可解释性，生成简洁的解析表达式。

Result: 在BTC、ETH、XMR等真实加密货币数据集上，DeCoKAN实现了最低的平均均方误差，全面优于现有最先进基线模型。

Conclusion: DeCoKAN成功弥合了预测精度和模型透明度之间的差距，为复杂加密货币市场提供了可信的决策支持，推动了可解释AI在金融领域的应用。

Abstract: Accurate and interpretable forecasting of multivariate time series is crucial for understanding the complex dynamics of cryptocurrency markets in digital asset systems. Advanced deep learning methodologies, particularly Transformer-based and MLP-based architectures, have achieved competitive predictive performance in cryptocurrency forecasting tasks. However, cryptocurrency data is inherently composed of long-term socio-economic trends and local high-frequency speculative oscillations. Existing deep learning-based 'black-box' models fail to effectively decouple these composite dynamics or provide the interpretability needed for trustworthy financial decision-making. To overcome these limitations, we propose DecoKAN, an interpretable forecasting framework that integrates multi-level Discrete Wavelet Transform (DWT) for decoupling and hierarchical signal decomposition with Kolmogorov-Arnold Network (KAN) mixers for transparent and interpretable nonlinear modeling. The DWT component decomposes complex cryptocurrency time series into distinct frequency components, enabling frequency-specific analysis, while KAN mixers provide intrinsically interpretable spline-based mappings within each decomposed subseries. Furthermore, interpretability is enhanced through a symbolic analysis pipeline involving sparsification, pruning, and symbolization, which produces concise analytical expressions offering symbolic representations of the learned patterns. Extensive experiments demonstrate that DecoKAN achieves the lowest average Mean Squared Error on all tested real-world cryptocurrency datasets (BTC, ETH, XMR), consistently outperforming a comprehensive suite of competitive state-of-the-art baselines. These results validate DecoKAN's potential to bridge the gap between predictive accuracy and model transparency, advancing trustworthy decision support within complex cryptocurrency markets.

</details>


### [68] [An Optimal Policy for Learning Controllable Dynamics by Exploration](https://arxiv.org/abs/2512.20053)
*Peter N. Loxley*

Main category: cs.LG

TL;DR: 本文提出了一种用于在未知环境中通过有限时间探索学习可控动力学的通用最优策略形式，该策略通过贪婪地最大化信息增益来实现"通过探索学习"，并展示了非平稳策略对于实现最优探索的必要性。


<details>
  <summary>Details</summary>
Motivation: 可控马尔可夫链描述了顺序决策任务的动态，是最优控制和强化学习的核心组件。本文旨在解决在未知环境中通过有限时间探索学习可控动力学的问题，需要找到一种既简单实现又高效计算的最优探索策略。

Method: 提出了一种通用形式的最优策略，该策略通过贪婪地最大化信息增益来选择控制动作，控制集随时间变化。给出了控制集的简单参数化方法，并提出了寻找最优策略的算法。特别关注了限制动力学控制的特殊状态类型（瞬态、吸收态、非回溯态），并展示了这些状态如何使得非平稳策略成为实现最优探索的必要条件。

Result: 提出了一个简单易实现、计算高效的最优探索策略，能够使智能体在有限时间范围内通过探索学习可控动力学。通过六个具体的可控动力学示例详细展示了该方法，并使用计数论证、与次优策略比较以及动态规划的序贯改进特性证明了策略的最优性。

Conclusion: 本文为在未知环境中学习可控动力学提供了一种通用的最优探索策略框架，证明了非平稳策略对于处理特殊状态类型（如瞬态、吸收态、非回溯态）的必要性，并通过多种方法验证了策略的最优性，为顺序决策任务中的探索问题提供了理论支持和实用算法。

Abstract: Controllable Markov chains describe the dynamics of sequential decision making tasks and are the central component in optimal control and reinforcement learning. In this work, we give the general form of an optimal policy for learning controllable dynamics in an unknown environment by exploring over a limited time horizon. This policy is simple to implement and efficient to compute, and allows an agent to ``learn by exploring" as it maximizes its information gain in a greedy fashion by selecting controls from a constraint set that changes over time during exploration. We give a simple parameterization for the set of controls, and present an algorithm for finding an optimal policy. The reason for this policy is due to the existence of certain types of states that restrict control of the dynamics; such as transient states, absorbing states, and non-backtracking states. We show why the occurrence of these states makes a non-stationary policy essential for achieving optimal exploration. Six interesting examples of controllable dynamics are treated in detail. Policy optimality is demonstrated using counting arguments, comparing with suboptimal policies, and by making use of a sequential improvement property from dynamic programming.

</details>


### [69] [PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models](https://arxiv.org/abs/2512.20063)
*Mingue Park,Jisung Hwang,Seungwoo Yoo,Kyeongmin Yeo,Minhyuk Sung*

Main category: cs.LG

TL;DR: PairFlow是一种轻量级预处理方法，用于训练离散流模型（DFMs），实现少步采样而无需预训练教师模型，计算成本极低（仅需完整训练的1.7%）。


<details>
  <summary>Details</summary>
Motivation: 离散流模型在离散数据生成方面表现出色，但因其迭代性质导致采样速度慢。现有加速方法主要依赖微调，带来大量额外训练开销，需要更高效的解决方案。

Method: 受ReFlow启发，通过闭式反演技术高效构建源-目标分布的配对样本，直接从耦合样本训练DFMs，无需预训练教师模型。核心是DFMs的闭式反演公式。

Result: PairFlow在分子数据、二值和RGB图像上表现优异，匹配甚至超越需要微调的两阶段训练性能。同时为后续蒸馏提供更强的基模型，实现进一步加速。

Conclusion: PairFlow是一种高效、通用的DFMs训练预处理方法，以极低成本实现少步采样，为离散数据生成模型提供了实用的加速解决方案。

Abstract: We introduce $\texttt{PairFlow}$, a lightweight preprocessing step for training Discrete Flow Models (DFMs) to achieve few-step sampling without requiring a pretrained teacher. DFMs have recently emerged as a new class of generative models for discrete data, offering strong performance. However, they suffer from slow sampling due to their iterative nature. Existing acceleration methods largely depend on finetuning, which introduces substantial additional training overhead. $\texttt{PairFlow}$ addresses this issue with a lightweight preprocessing step. Inspired by ReFlow and its extension to DFMs, we train DFMs from coupled samples of source and target distributions, without requiring any pretrained teacher. At the core of our approach is a closed-form inversion for DFMs, which allows efficient construction of paired source-target samples. Despite its extremely low cost, taking only up to 1.7% of the compute needed for full model training, $\texttt{PairFlow}$ matches or even surpasses the performance of two-stage training involving finetuning. Furthermore, models trained with our framework provide stronger base models for subsequent distillation, yielding further acceleration after finetuning. Experiments on molecular data as well as binary and RGB images demonstrate the broad applicability and effectiveness of our approach.

</details>


### [70] [QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption](https://arxiv.org/abs/2512.20084)
*Yanjie Li,Jian Xu,Xueqing Chen,Lina Yu,Shiming Xiang,Weijun Li,Cheng-lin Liu*

Main category: cs.LG

TL;DR: QE-Catalytic是一个多模态框架，将大语言模型与E(3)-等变图Transformer结合，用于催化表面吸附构型的性质预测和逆向设计，显著提升了吸附能预测精度。


<details>
  <summary>Details</summary>
Motivation: 吸附能是催化反应性的关键描述符，其准确性直接影响机器学习驱动的催化剂筛选可靠性。现有方法中，E(3)-等变图神经网络在三维坐标预测上表现良好，但语言模型方法在吸附构型能量预测精度和区分不同构型方面仍有不足，即使有图辅助预训练。

Method: 提出QE-Catalytic多模态框架，将大语言模型(Qwen)与E(3)-等变图Transformer(Equiformer-V2)深度耦合。在预测时联合利用三维结构和结构化配置文本，通过图-文本对齐将"三维几何信息"注入语言通道。当精确坐标不可用时，可作为高性能的基于文本的预测器，同时还能自回归生成CIF文件用于目标能量驱动的结构设计和信息补全。

Result: 在OC20数据集上，QE-Catalytic将松弛吸附能的MAE从0.713 eV降低到0.486 eV，在多个评估协议中一致优于CatBERTa和GAP-CATBERTa等基线模型。

Conclusion: QE-Catalytic通过深度耦合语言模型和图神经网络，实现了对复杂催化表面吸附构型的高精度性质预测和逆向设计，显著提升了吸附能预测性能，为催化剂筛选提供了更可靠的工具。

Abstract: Adsorption energy is a key descriptor of catalytic reactivity. It is fundamentally defined as the difference between the relaxed total energy of the adsorbate-surface system and that of an appropriate reference state; therefore, the accuracy of relaxed-energy prediction directly determines the reliability of machine-learning-driven catalyst screening. E(3)-equivariant graph neural networks (GNNs) can natively operate on three-dimensional atomic coordinates under periodic boundary conditions and have demonstrated strong performance on such tasks. In contrast, language-model-based approaches, while enabling human-readable textual descriptions and reducing reliance on explicit graph -- thereby broadening applicability -- remain insufficient in both adsorption-configuration energy prediction accuracy and in distinguishing ``the same system with different configurations,'' even with graph-assisted pretraining in the style of GAP-CATBERTa.
  To this end, we propose QE-Catalytic, a multimodal framework that deeply couples a large language model (\textbf{Q}wen) with an E(3)-equivariant graph Transformer (\textbf{E}quiformer-V2), enabling unified support for adsorption-configuration property prediction and inverse design on complex catalytic surfaces. During prediction, QE-Catalytic jointly leverages three-dimensional structures and structured configuration text, and injects ``3D geometric information'' into the language channel via graph-text alignment, allowing it to function as a high-performance text-based predictor when precise coordinates are unavailable, while also autoregressively generating CIF files for target-energy-driven structure design and information completion. On OC20, QE-Catalytic reduces the MAE of relaxed adsorption energy from 0.713~eV to 0.486~eV, and consistently outperforms baseline models such as CatBERTa and GAP-CATBERTa across multiple evaluation protocols.

</details>


### [71] [Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection](https://arxiv.org/abs/2512.20086)
*Jeehong Kim,Youngseok Hwang,Minchan Kim,Sungho Bae,Hyunwoo Park*

Main category: cs.LG

TL;DR: 提出一个用于海上交通异常检测的新基准数据集，扩展OMTAD数据集，支持节点级、边级和图级异常检测，并计划使用LLM代理生成语义丰富的异常。


<details>
  <summary>Details</summary>
Motivation: 当前时空图神经网络在具有固定节点的结构化领域（如道路交通）表现良好，但许多现实系统（如海上交通）缺乏固定锚点，构建时空图面临根本挑战。这些非网格环境中的异常检测尤其困难，因为缺乏规范参考点、轨迹稀疏不规则，且异常可能出现在多个粒度。

Method: 扩展开放海上交通分析数据集（OMTAD）为图基准数据集，支持节点级、边级和图级异常检测。计划使用两个专门的LLM代理：轨迹合成器和异常注入器，构建更丰富的交互上下文并生成语义有意义的异常。

Result: 提出了一个专门为基于图的异常检测设计的基准数据集，支持系统评估三种不同粒度的异常，旨在促进非网格时空系统中异常检测方法的可重复性和方法进步。

Conclusion: 该基准数据集将推动非网格时空系统异常检测的可重复性研究和方法创新，特别针对海上交通等缺乏固定节点的复杂环境。

Abstract: Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \emph{Trajectory Synthesizer} and \emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.

</details>


### [72] [Jensen-Shannon Divergence Message-Passing for Rich-Text Graph Representation Learning](https://arxiv.org/abs/2512.20094)
*Zuo Wang,Ye Yuan*

Main category: cs.LG

TL;DR: 提出JSDMP学习范式，通过Jensen-Shannon散度同时捕捉文本图的结构与文本相似性和相异性，并基于此开发DMPGCN和DMPPRG两种图神经网络，在富文本图表示学习中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 研究富文本图中广泛存在的上下文和结构差异如何影响表示学习，现有方法通常只考虑相似性而忽略了相异性信息。

Method: 提出Jensen-Shannon散度消息传递（JSDMP）范式，同时考虑结构和文本的相似性与相异性，通过Jensen-Shannon散度计算节点间消息权重。基于JSDMP开发了DMPGCN和DMPPRG两种图神经网络。

Result: 在多个标准富文本数据集上的实验表明，DMPGCN和DMPPRG优于多个最先进的基线方法，验证了JSDMP范式的有效性。

Conclusion: JSDMP通过同时捕捉相似性和相异性，使表示学习能够从真正相关的文本节点中学习上下文和结构信息，为富文本图表示学习提供了新的有效范式。

Abstract: In this paper, we investigate how the widely existing contextual and structural divergence may influence the representation learning in rich-text graphs. To this end, we propose Jensen-Shannon Divergence Message-Passing (JSDMP), a new learning paradigm for rich-text graph representation learning. Besides considering similarity regarding structure and text, JSDMP further captures their corresponding dissimilarity by Jensen-Shannon divergence. Similarity and dissimilarity are then jointly used to compute new message weights among text nodes, thus enabling representations to learn with contextual and structural information from truly correlated text nodes. With JSDMP, we propose two novel graph neural networks, namely Divergent message-passing graph convolutional network (DMPGCN) and Divergent message-passing Page-Rank graph neural networks (DMPPRG), for learning representations in rich-text graphs. DMPGCN and DMPPRG have been extensively texted on well-established rich-text datasets and compared with several state-of-the-art baselines. The experimental results show that DMPGCN and DMPPRG can outperform other baselines, demonstrating the effectiveness of the proposed Jensen-Shannon Divergence Message-Passing paradigm

</details>


### [73] [Information-directed sampling for bandits: a primer](https://arxiv.org/abs/2512.20096)
*Annika Hirling,Giorgio Nicoletti,Antonio Celani*

Main category: cs.LG

TL;DR: 该论文在双状态伯努利多臂老虎机环境中研究信息导向采样策略，通过引入改进的信息度量和调优参数，在对称老虎机和单公平硬币场景中分析其遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究多臂老虎机问题中探索与利用的平衡，特别是在可处理的二状态伯努利老虎机环境中，为启发式策略与最优策略提供严格比较的最小模型。

Method: 扩展信息导向采样框架到折扣无限时域设置，引入改进的信息度量和调优参数来调节决策行为，重点分析对称老虎机和单公平硬币两类问题。

Result: 在对称老虎机情况下，IDS实现有界累积遗憾；在单公平硬币场景中，IDS策略的遗憾随时域对数增长，与经典渐近下界一致。

Conclusion: 该工作作为教学综合，旨在为统计物理学家群体搭建强化学习与信息理论概念之间的桥梁。

Abstract: The Multi-Armed Bandit problem provides a fundamental framework for analyzing the tension between exploration and exploitation in sequential learning. This paper explores Information Directed Sampling (IDS) policies, a class of heuristics that balance immediate regret against information gain. We focus on the tractable environment of two-state Bernoulli bandits as a minimal model to rigorously compare heuristic strategies against the optimal policy. We extend the IDS framework to the discounted infinite-horizon setting by introducing a modified information measure and a tuning parameter to modulate the decision-making behavior. We examine two specific problem classes: symmetric bandits and the scenario involving one fair coin. In the symmetric case we show that IDS achieves bounded cumulative regret, whereas in the one-fair-coin scenario the IDS policy yields a regret that scales logarithmically with the horizon, in agreement with classical asymptotic lower bounds. This work serves as a pedagogical synthesis, aiming to bridge concepts from reinforcement learning and information theory for an audience of statistical physicists.

</details>


### [74] [Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering](https://arxiv.org/abs/2512.20115)
*Yuanhao Chen,Qi Liu,Pengbin Chen,Zhongjian Qiao,Yanjie Li*

Main category: cs.LG

TL;DR: 提出一种简单的样本过滤方法，通过筛选高奖励的transition样本来改进策略约束离线强化学习，解决因数据集包含低质量transition导致学习效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有策略约束离线RL方法使用数据集中的所有transition进行训练，当数据集中包含大量低奖励transition时，学习策略会被次优的行为策略所限制，导致学习速度慢、样本效率低和性能不佳。

Method: 提出两步样本过滤方法：1) 使用episode的平均奖励和平均折扣奖励评估transition的得分；2) 提取高得分的transition样本用于训练离线RL算法。

Result: 在一系列离线RL算法和基准任务上的实验结果表明，所提出的方法优于基线方法，提高了样本效率和最终性能。

Conclusion: 通过简单的样本过滤策略，可以有效改进策略约束离线强化学习的训练效果，解决因低质量数据导致的性能瓶颈问题。

Abstract: Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected return using a given static dataset of transitions. However, offline RL faces the distribution shift problem. The policy constraint offline RL method is proposed to solve the distribution shift problem. During the policy constraint offline RL training, it is important to ensure the difference between the learned policy and behavior policy within a given threshold. Thus, the learned policy heavily relies on the quality of the behavior policy. However, a problem exists in existing policy constraint methods: if the dataset contains many low-reward transitions, the learned will be contained with a suboptimal reference policy, leading to slow learning speed, low sample efficiency, and inferior performances. This paper shows that the sampling method in policy constraint offline RL that uses all the transitions in the dataset can be improved. A simple but efficient sample filtering method is proposed to improve the sample efficiency and the final performance. First, we evaluate the score of the transitions by average reward and average discounted reward of episodes in the dataset and extract the transition samples of high scores. Second, the high-score transition samples are used to train the offline RL algorithms. We verify the proposed method in a series of offline RL algorithms and benchmark tasks. Experimental results show that the proposed method outperforms baselines.

</details>


### [75] [Learning to Reason in LLMs by Expectation Maximization](https://arxiv.org/abs/2512.20169)
*Junghyun Lee,Branislav Kveton,Sunav Choudhary,Subhojyoti Mukherjee,Anup Rao,Ryan A. Rossi,Alexa Siu*

Main category: cs.LG

TL;DR: 论文提出将推理建模为隐变量模型，推导出EM学习目标，比较了多种采样方案，发现Prompt Posterior Sampling（PPS）在多个数据集上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常通过先生成推理过程再给出答案来解决问题。当前基于奖励的优化方法存在挑战，需要设计能够生成支持正确答案的推理过程的采样分布。

Method: 将推理形式化为隐变量模型，推导出EM学习目标。实例化并比较了多种采样方案：带预算的拒绝采样、自教推理器（STaR）和仅保留STaR推理阶段的提示后验采样（PPS）。

Result: 在ARC、MMLU和OpenBookQA数据集上使用Llama和Qwen模型进行实验，发现采样方案显著影响学习推理模型的准确性。尽管简单，PPS优于其他采样方案。

Conclusion: 将推理建模为隐变量模型并采用合适的采样方案（特别是PPS）可以有效提升语言模型的推理能力，为推理学习提供了新的理论框架和实用方法。

Abstract: Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.

</details>


### [76] [NeuralCrop: Combining physics and machine learning for improved crop yield predictions](https://arxiv.org/abs/2512.20177)
*Yunan Lin,Sebastian Bathiany,Maha Badri,Maximilian Gelbrecht,Philipp Hess,Brian Groenke,Jens Heinke,Christoph Müller,Niklas Boers*

Main category: cs.LG

TL;DR: NeuralCrop是一个混合全球网格作物模型，结合了基于过程的GGCM和机器学习组件，在作物产量预测方面优于现有模型，特别是在极端干旱条件下，并能更好地泛化到未见过的气候条件。


<details>
  <summary>Details</summary>
Motivation: 传统GGCM由于过程理解有限存在较大不确定性，而纯机器学习模型在训练分布外泛化能力差，无法适应气候变化。需要结合两者优势来改进作物产量预测。

Method: 开发NeuralCrop混合模型：先训练模拟先进的基于过程GGCM，然后在观测数据上进行微调。结合过程模型的物理机制和机器学习的数据驱动能力。

Result: NeuralCrop在站点和大尺度种植区域均优于最先进的GGCMs，在2000-2019年间能更准确地再现欧洲小麦区和美国玉米带的年际产量异常，在极端干旱条件下改进尤为显著。相比纯机器学习模型，在未见训练条件下仍能保持稳健预测。

Conclusion: 混合作物建模方法提供了整体改进的作物模型和更可靠的气候变化及极端天气条件下的产量预测，为解决农业气候风险评估提供了有前景的途径。

Abstract: Global gridded crop models (GGCMs) simulate daily crop growth by explicitly representing key biophysical processes and project end-of-season yield time series. They are a primary tool to quantify the impacts of climate change on agricultural productivity and assess associated risks for food security. Despite decades of development, state-of-the-art GGCMs still have substantial uncertainties in simulating complex biophysical processes due to limited process understanding. Recently, machine learning approaches trained on observational data have shown great potential in crop yield predictions. However, these models have not demonstrated improved performance over classical GGCMs and are not suitable for simulating crop yields under changing climate conditions due to problems in generalizing outside their training distributions. Here we introduce NeuralCrop, a hybrid GGCM that combines the strengths of an advanced process-based GGCM, resolving important processes explicitly, with data-driven machine learning components. The model is first trained to emulate a competitive GGCM before it is fine-tuned on observational data. We show that NeuralCrop outperforms state-of-the-art GGCMs across site-level and large-scale cropping regions. Across moisture conditions, NeuralCrop reproduces the interannual yield anomalies in European wheat regions and the US Corn Belt more accurately during the period from 2000 to 2019 with particularly strong improvements under drought extremes. When generalizing to conditions unseen during training, NeuralCrop continues to make robust projections, while pure machine learning models exhibit substantial performance degradation. Our results show that our hybrid crop modelling approach offers overall improved crop modeling and more reliable yield projections under climate change and intensifying extreme weather conditions.

</details>


### [77] [Cost-TrustFL: Cost-Aware Hierarchical Federated Learning with Lightweight Reputation Evaluation across Multi-Cloud](https://arxiv.org/abs/2512.20218)
*Jixiao Yang,Jinyu Chen,Zixiao Huang,Chengda Xu,Chi Zhang,Sijia Li*

Main category: cs.LG

TL;DR: Cost-TrustFL：一个分层联邦学习框架，在多云环境中联合优化模型性能和通信成本，同时防御投毒攻击，通过近似Shapley值计算和成本感知聚合策略，在保持高准确率的同时显著降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 多云环境下的联邦学习面临非独立同分布数据分布、恶意参与者检测以及高昂的跨云通信成本（出口费用）等关键挑战。现有拜占庭鲁棒方法主要关注模型准确性，而忽视了跨云提供商数据传输的经济影响。

Method: 提出Cost-TrustFL分层联邦学习框架：1）基于梯度的近似Shapley值计算方法，将复杂度从指数级降低到线性级，实现轻量级信誉评估；2）成本感知聚合策略，优先考虑云内通信以最小化昂贵的跨云数据传输。

Result: 在CIFAR-10和FEMNIST数据集上的实验表明，Cost-TrustFL在30%恶意客户端的情况下达到86.7%的准确率，同时相比基线方法减少32%的通信成本。该框架在不同非独立同分布程度和攻击强度下保持稳定性能。

Conclusion: Cost-TrustFL为实际多云部署提供了一个实用的解决方案，能够同时处理模型性能、通信成本和安全性问题，通过联合优化这些关键因素，实现了经济高效且安全的联邦学习。

Abstract: Federated learning across multi-cloud environments faces critical challenges, including non-IID data distributions, malicious participant detection, and substantial cross-cloud communication costs (egress fees). Existing Byzantine-robust methods focus primarily on model accuracy while overlooking the economic implications of data transfer across cloud providers. This paper presents Cost-TrustFL, a hierarchical federated learning framework that jointly optimizes model performance and communication costs while providing robust defense against poisoning attacks. We propose a gradient-based approximate Shapley value computation method that reduces the complexity from exponential to linear, enabling lightweight reputation evaluation. Our cost-aware aggregation strategy prioritizes intra-cloud communication to minimize expensive cross-cloud data transfers. Experiments on CIFAR-10 and FEMNIST datasets demonstrate that Cost-TrustFL achieves 86.7% accuracy under 30% malicious clients while reducing communication costs by 32% compared to baseline methods. The framework maintains stable performance across varying non-IID degrees and attack intensities, making it practical for real-world multi-cloud deployments.

</details>


### [78] [Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning](https://arxiv.org/abs/2512.20220)
*Kausthubh Manda,Raghuram Bharadwaj Diddigi*

Main category: cs.LG

TL;DR: 该论文研究了离线多任务强化学习，其中多个任务共享其动作价值函数的低秩表示。通过联合学习共享表示和任务特定价值函数，证明了跨任务数据池化能提高统计效率，并分析了在下游任务中重用表示的优势。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，当多个相关任务共享底层表示时，如何利用跨任务数据提高统计效率和泛化能力。传统单任务离线RL面临数据稀缺问题，而多任务设置可以通过共享结构减少样本复杂度。

Method: 提出多任务版本的拟合Q迭代算法，通过贝尔曼误差最小化联合学习共享表示和任务特定价值函数。在标准可实现性和覆盖性假设下，分析该方法的理论性质。

Result: 建立了学习价值函数的有限样本泛化保证，显示样本复杂度依赖总样本数nT的1/√(nT)，同时保持与分布偏移相关的horizon和集中系数依赖。下游任务重用表示能有效降低学习复杂度。

Conclusion: 共享表示在多任务离线Q学习中能显著提高统计效率，跨任务数据池化改善估计精度，下游任务重用表示可减少学习复杂度。为模型无关、基于价值的强化学习中的多任务泛化提供了理论见解。

Abstract: We study offline multitask reinforcement learning in settings where multiple tasks share a low-rank representation of their action-value functions. In this regime, a learner is provided with fixed datasets collected from several related tasks, without access to further online interaction, and seeks to exploit shared structure to improve statistical efficiency and generalization. We analyze a multitask variant of fitted Q-iteration that jointly learns a shared representation and task-specific value functions via Bellman error minimization on offline data. Under standard realizability and coverage assumptions commonly used in offline reinforcement learning, we establish finite-sample generalization guarantees for the learned value functions. Our analysis explicitly characterizes how pooling data across tasks improves estimation accuracy, yielding a $1/\sqrt{nT}$ dependence on the total number of samples across tasks, while retaining the usual dependence on the horizon and concentrability coefficients arising from distribution shift. In addition, we consider a downstream offline setting in which a new task shares the same underlying representation as the upstream tasks. We study how reusing the representation learned during the multitask phase affects value estimation for this new task, and show that it can reduce the effective complexity of downstream learning relative to learning from scratch. Together, our results clarify the role of shared representations in multitask offline Q-learning and provide theoretical insight into when and how multitask structure can improve generalization in model-free, value-based reinforcement learning.

</details>


### [79] [Adaptive Multi-task Learning for Probabilistic Load Forecasting](https://arxiv.org/abs/2512.20232)
*Onintze Zaballa,Verónica Álvarez,Santiago Mazuelas*

Main category: cs.LG

TL;DR: 提出一种基于向量值隐马尔可夫模型的自适应多任务学习方法，用于多实体概率负荷预测，能够动态适应消费模式变化和实体间相关性。


<details>
  <summary>Details</summary>
Motivation: 多实体负荷预测对电力系统高效可靠运行至关重要，但现有方法多为离线学习，无法捕捉消费模式变化，且多任务学习在负荷预测中应用不足。

Method: 基于向量值隐马尔可夫模型，采用递归过程更新模型参数，提供自适应多任务学习框架，实现概率预测和不确定性评估。

Result: 在多实体负荷数据集上的实验表明，该方法在预测性能和不确定性评估方面均优于现有方法。

Conclusion: 提出的自适应多任务学习方法能够有效处理多实体负荷预测中的动态变化和相关性，为电力系统运行提供可靠的概率预测和不确定性评估。

Abstract: Simultaneous load forecasting across multiple entities (e.g., regions, buildings) is crucial for the efficient, reliable, and cost-effective operation of power systems. Accurate load forecasting is a challenging problem due to the inherent uncertainties in load demand, dynamic changes in consumption patterns, and correlations among entities. Multi-task learning has emerged as a powerful machine learning approach that enables the simultaneous learning across multiple related problems. However, its application to load forecasting remains underexplored and is limited to offline learning-based methods, which cannot capture changes in consumption patterns. This paper presents an adaptive multi-task learning method for probabilistic load forecasting. The proposed method can dynamically adapt to changes in consumption patterns and correlations among entities. In addition, the techniques presented provide reliable probabilistic predictions for loads of multiples entities and assess load uncertainties. Specifically, the method is based on vectorvalued hidden Markov models and uses a recursive process to update the model parameters and provide predictions with the most recent parameters. The performance of the proposed method is evaluated using datasets that contain the load demand of multiple entities and exhibit diverse and dynamic consumption patterns. The experimental results show that the presented techniques outperform existing methods both in terms of forecasting performance and uncertainty assessment.

</details>


### [80] [How I Met Your Bias: Investigating Bias Amplification in Diffusion Models](https://arxiv.org/abs/2512.20233)
*Nathan Roos,Ekaterina Iakovleva,Ani Gjergji,Vito Paolo Pastore,Enzo Tartaglione*

Main category: cs.LG

TL;DR: 扩散模型采样算法和超参数对偏见放大的影响分析


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像合成任务中表现出色，但会复制和放大数据集偏见。现有研究将偏见放大视为扩散模型的固有特性，但本文首次分析采样算法及其超参数如何影响偏见放大。

Method: 通过控制实验，使用Biased MNIST、Multi-Color MNIST、BFFHQ数据集训练的模型以及Stable Diffusion，研究不同采样算法和超参数对偏见放大的影响。

Result: 实验表明，扩散模型的采样器（通常为样本质量和速度优化）对偏见放大有显著且可测量的影响。采样超参数可以诱导偏见减少或放大，即使训练好的模型是固定的。

Conclusion: 偏见放大不是扩散模型的固有特性，而是受采样算法和超参数影响的可控因素，这为减少扩散模型中的偏见提供了新途径。

Abstract: Diffusion-based generative models demonstrate state-of-the-art performance across various image synthesis tasks, yet their tendency to replicate and amplify dataset biases remains poorly understood. Although previous research has viewed bias amplification as an inherent characteristic of diffusion models, this work provides the first analysis of how sampling algorithms and their hyperparameters influence bias amplification. We empirically demonstrate that samplers for diffusion models -- commonly optimized for sample quality and speed -- have a significant and measurable effect on bias amplification. Through controlled studies with models trained on Biased MNIST, Multi-Color MNIST and BFFHQ, and with Stable Diffusion, we show that sampling hyperparameters can induce both bias reduction and amplification, even when the trained model is fixed. Source code is available at https://github.com/How-I-met-your-bias/how_i_met_your_bias.

</details>


### [81] [Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion](https://arxiv.org/abs/2512.20249)
*Xuanyu Hu*

Main category: cs.LG

TL;DR: 提出BrainROI模型，通过软功能分区共享空间、体素门控融合机制和可解释提示优化，在多模态脑解码中实现跨被试泛化和可解释性提升


<details>
  <summary>Details</summary>
Motivation: 多模态脑解码面临跨被试泛化和可解释性两大关键挑战。现有方法在功能脑拓扑异质性处理、提示设计稳定性和透明度方面存在局限

Method: 1) 设计新的fMRI编码器：使用多图谱软功能分区作为共享空间，将离散ROI拼接扩展为体素级门控融合机制，通过全局标签对齐确保ROI映射一致性；2) 引入可解释提示优化：在小样本闭环中使用本地部署的Qwen模型迭代生成和选择人类可读提示；3) 推理时施加参数化解码约束

Result: 在NSD数据集上实现领先水平的脑-字幕生成效果。跨被试设置下，相比SOTA方法和代表性基线，BLEU-4和CIDEr等指标有明显提升

Conclusion: BrainROI模型通过创新的fMRI编码器设计、可解释提示优化和参数化解码约束，有效解决了多模态脑解码中的跨被试泛化和可解释性问题

Abstract: Multimodal brain decoding aims to reconstruct semantic information that is consistent with visual stimuli from brain activity signals such as fMRI, and then generate readable natural language descriptions. However, multimodal brain decoding still faces key challenges in cross-subject generalization and interpretability. We propose a BrainROI model and achieve leading-level results in brain-captioning evaluation on the NSD dataset. Under the cross-subject setting, compared with recent state-of-the-art methods and representative baselines, metrics such as BLEU-4 and CIDEr show clear improvements. Firstly, to address the heterogeneity of functional brain topology across subjects, we design a new fMRI encoder. We use multi-atlas soft functional parcellations (soft-ROI) as a shared space. We extend the discrete ROI Concatenation strategy in MINDLLM to a voxel-wise gated fusion mechanism (Voxel-gate). We also ensure consistent ROI mapping through global label alignment, which enhances cross-subject transferability. Secondly, to overcome the limitations of manual and black-box prompting methods in stability and transparency, we introduce an interpretable prompt optimization process. In a small-sample closed loop, we use a locally deployed Qwen model to iteratively generate and select human-readable prompts. This process improves the stability of prompt design and preserves an auditable optimization trajectory. Finally, we impose parameterized decoding constraints during inference to further improve the stability and quality of the generated descriptions.

</details>


### [82] [DeepONet-accelerated Bayesian inversion for moving boundary problems](https://arxiv.org/abs/2512.20268)
*Marco A. Iglesias,Michael. E. Causon,Mikhail Y. Matveev,Andreas Endruweit,Michael . V. Tretyakov*

Main category: cs.LG

TL;DR: 使用DeepONet神经网络算子构建多孔介质中移动边界问题的快速代理模型，结合集成卡尔曼反演算法解决贝叶斯反问题，应用于树脂传递模塑工艺的渗透率和孔隙率估计。


<details>
  <summary>Details</summary>
Motivation: 移动边界系统在工业应用中普遍存在（如树脂传递模塑工艺），但传统数值模拟计算成本高，难以实现实时监测和控制。需要开发快速准确的代理模型来支持数字孪生平台。

Method: 采用Deep Operator Network（DeepONet）架构构建移动边界问题的代理模型，结合Ensemble Kalman Inversion（EKI）算法解决贝叶斯反问题。该方法能跨时空域泛化，可在任意传感器配置下评估而无需重新训练。

Result: DeepONet代理模型相比完整模型EKI加速了几个数量级，实现了实时、准确、高分辨率的渗透率、孔隙率等参数估计。该方法在合成和实验数据上都表现良好，支持RTM工艺的有效监测和控制。

Conclusion: 神经网络算子学习为移动边界系统提供了强大灵活的快速模拟器框架，能够集成到数字孪生平台。该方法相比传统网格依赖方法具有更好的泛化能力，是工业数字孪生实际部署的重要进展。

Abstract: This work demonstrates that neural operator learning provides a powerful and flexible framework for building fast, accurate emulators of moving boundary systems, enabling their integration into digital twin platforms. To this end, a Deep Operator Network (DeepONet) architecture is employed to construct an efficient surrogate model for moving boundary problems in single-phase Darcy flow through porous media. The surrogate enables rapid and accurate approximation of complex flow dynamics and is coupled with an Ensemble Kalman Inversion (EKI) algorithm to solve Bayesian inverse problems.
  The proposed inversion framework is demonstrated by estimating the permeability and porosity of fibre reinforcements for composite materials manufactured via the Resin Transfer Moulding (RTM) process. Using both synthetic and experimental in-process data, the DeepONet surrogate accelerates inversion by several orders of magnitude compared with full-model EKI. This computational efficiency enables real-time, accurate, high-resolution estimation of local variations in permeability, porosity, and other parameters, thereby supporting effective monitoring and control of RTM processes, as well as other applications involving moving boundary flows. Unlike prior approaches for RTM inversion that learn mesh-dependent mappings, the proposed neural operator generalises across spatial and temporal domains, enabling evaluation at arbitrary sensor configurations without retraining, and represents a significant step toward practical industrial deployment of digital twins.

</details>


### [83] [HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training](https://arxiv.org/abs/2512.20272)
*Yuanjian Xu,Yuan Shuai,Jianing Hao,Guang Zhang*

Main category: cs.LG

TL;DR: 提出HGAN-SDEs框架，利用神经Hermite函数构建结构化高效判别器，解决传统神经SDE生成对抗训练中计算成本高和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 神经随机微分方程（Neural SDEs）是建模连续时间随机过程的重要框架，但现有基于GAN的方法在判别器设计上面临挑战：需要准确捕捉时间依赖性同时保持计算效率。先前使用神经控制微分方程（CDEs）作为判别器的方法计算成本高，且加剧了对抗训练的不稳定性。

Method: 提出HGAN-SDEs框架，利用神经Hermite函数构建结构化高效判别器。Hermite函数为路径级动态提供了表达力强且轻量级的近似基础，降低了运行时复杂度并改善了训练稳定性。

Result: 建立了该框架对广泛SDE驱动分布的通用逼近性质，理论上分析了其收敛行为。在合成和真实世界系统上的大量实验表明，HGAN-SDEs相比现有SDE生成模型实现了更优的样本质量和学习效率。

Conclusion: HGAN-SDEs通过神经Hermite函数构建高效判别器，成功解决了神经SDE生成对抗训练中的计算效率和稳定性问题，为连续时间随机过程建模提供了更优的解决方案。

Abstract: Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising solution to learning the complex path distributions induced by SDEs. However, a critical bottleneck lies in designing a discriminator that faithfully captures temporal dependencies while remaining computationally efficient. Prior works have explored Neural Controlled Differential Equations (CDEs) as discriminators due to their ability to model continuous-time dynamics, but such architectures suffer from high computational costs and exacerbate the instability of adversarial training. To address these limitations, we introduce HGAN-SDEs, a novel GAN-based framework that leverages Neural Hermite functions to construct a structured and efficient discriminator. Hermite functions provide an expressive yet lightweight basis for approximating path-level dynamics, enabling both reduced runtime complexity and improved training stability. We establish the universal approximation property of our framework for a broad class of SDE-driven distributions and theoretically characterize its convergence behavior. Extensive empirical evaluations on synthetic and real-world systems demonstrate that HGAN-SDEs achieve superior sample quality and learning efficiency compared to existing generative models for SDEs

</details>


### [84] [Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity](https://arxiv.org/abs/2512.20291)
*Yuxing Gan,Ziyu Lei*

Main category: cs.LG

TL;DR: CDSP-MoE通过冲突驱动的子空间剪枝解决传统MoE架构的两个核心问题：结构参数隔离导致的灾难性遗忘和指令过拟合问题，实现从隔离专家容器到共享物理子空间中动态专家实例化的范式转变。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构存在两个根本性限制：1）结构参数隔离导致灾难性遗忘；2）指令过拟合在无指令场景下性能下降。需要一种新范式来解决这些问题。

Method: 基于通用权重子空间假设，CDSP-MoE维护一个超完备参数骨干，通过可学习的拓扑掩码"雕刻"出逻辑专家。利用梯度冲突作为结构监督信号，通过滞后梯度博弈惩罚共享流形中的干扰连接，使拓扑能够自发剪枝冲突路径并演化出可解释的模块化结构。

Result: CDSP-MoE在严格盲推理协议下（无显式指令）实现了鲁棒的内容驱动路由，保持了语义专业化，无需人工定义的任务标签。

Conclusion: CDSP-MoE通过从隔离专家容器到共享子空间中动态专家实例化的范式转变，解决了传统MoE架构的结构性限制，实现了更鲁棒和可解释的模块化计算。

Abstract: Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruction-free scenarios. We propose CDSP-MoE (Conflict-Driven Subspace Pruning MoE), a framework that addresses these issues through a paradigm shift from isolated expert containers to dynamic expert instantiation within a shared physical subspace. Grounded in the Universal Weight Subspace Hypothesis, CDSP-MoE maintains a super-complete parameter backbone where logical experts are carved out via learnable topology masks. Unlike prior work that uses gradient conflict for token reassignment or optimization surgery, we leverage it as a structural supervisory signal: a Lagged Gradient Game penalizes interfering connections in the shared manifold, enabling the topology to spontaneously prune conflicting pathways and evolve interpretable modular structures. Experimental results demonstrate that CDSP-MoE achieves robust content-driven routing without human-defined task labels, maintaining semantic specialization even under strict blind inference protocols where explicit instructions are absent. Code is available at: https://github.com/konodiodaaaaa1/Conflict-Driven-Subspace-Pruning-Mixture-of-Experts

</details>


### [85] [TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning](https://arxiv.org/abs/2512.20312)
*Saisai Yang,Qingyi Huang,Jing Yuan,Liangyu Zha,Kai Tang,Yuhang Yang,Ning Wang,Yucheng Wei,Liyao Li,Wentao Ye,Hao Chen,Tao Zhang,Junlin Zhou,Haobo Wang,Gang Chen,Junbo Zhao*

Main category: cs.LG

TL;DR: TableGPT-R1：基于强化学习的表格专用模型，通过系统化RL框架解决表格任务中的复杂推理和代码执行问题，在权威基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于SFT的LLM在处理表格数据时存在不足：难以应对复杂的多步推理和鲁棒的代码执行需求。强化学习虽具潜力，但在表格领域面临三大挑战：高质量代理轨迹稀缺、反馈信号极度异质、垂直专业化中的灾难性遗忘风险。

Method: 1) 综合数据工程管道：合成难度分层的代理轨迹用于监督对齐和RL rollout；2) 任务自适应奖励系统：结合基于规则的验证与标准注入的奖励模型，包含过程级步骤奖励塑形和行为正则化；3) 多阶段训练框架：先稳定推理能力，再专门化表格任务。

Result: TableGPT-R1在权威基准测试中达到最先进的性能，显著超越基线模型，同时保持强大的通用能力。

Conclusion: TableGPT-R1通过系统化的强化学习框架成功解决了表格数据处理中的关键挑战，为复杂表格推理任务提供了有效的解决方案，同时平衡了专业化与通用知识保留。

Abstract: Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.

</details>


### [86] [FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning](https://arxiv.org/abs/2512.20329)
*Mrinmay Sen,Subhrajit Nag*

Main category: cs.LG

TL;DR: FedDPC是一种新的联邦学习方法，通过将本地更新投影到先前全局更新上来同时缓解数据异构性和部分客户端参与问题，从而减少方差并加速训练。


<details>
  <summary>Details</summary>
Motivation: 现代联邦学习中，数据异构性导致本地模型更新方差，使全局模型偏离最优解；部分客户端参与进一步加剧了这一问题，使聚合偏向参与客户端的数据分布，导致训练不稳定、性能下降和收敛缓慢。现有研究主要关注数据异构性，对部分客户端参与的影响关注较少。

Method: FedDPC通过将每个本地更新投影到先前的全局更新上来控制本地和全局更新的方差。为了进一步加速训练，FedDPC在聚合前对每个本地更新采用自适应缩放。

Result: 在多个异构划分数据集上的图像分类任务实验验证了FedDPC的有效性。结果显示FedDPC在训练损失减少速度和跨通信轮次的测试准确率方面优于最先进的联邦学习算法。

Conclusion: FedDPC通过同时缓解数据异构性和部分客户端参与问题，提高了联邦学习的训练效率和全局模型性能，在训练损失减少速度和测试准确率方面表现出优越性。

Abstract: Data heterogeneity is a significant challenge in modern federated learning (FL) as it creates variance in local model updates, causing the aggregated global model to shift away from the true global optimum. Partial client participation in FL further exacerbates this issue by skewing the aggregation of local models towards the data distribution of participating clients. This creates additional variance in the global model updates, causing the global model to converge away from the optima of the global objective. These variances lead to instability in FL training, which degrades global model performance and slows down FL training. While existing literature primarily focuses on addressing data heterogeneity, the impact of partial client participation has received less attention. In this paper, we propose FedDPC, a novel FL method, designed to improve FL training and global model performance by mitigating both data heterogeneity and partial client participation. FedDPC addresses these issues by projecting each local update onto the previous global update, thereby controlling variance in both local and global updates. To further accelerate FL training, FedDPC employs adaptive scaling for each local update before aggregation. Extensive experiments on image classification tasks with multiple heterogeneously partitioned datasets validate the effectiveness of FedDPC. The results demonstrate that FedDPC outperforms state-of-the-art FL algorithms by achieving faster reduction in training loss and improved test accuracy across communication rounds.

</details>


### [87] [Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation](https://arxiv.org/abs/2512.20346)
*Emilia Majerz,Witold Dzwinel,Jacek Kitowski*

Main category: cs.LG

TL;DR: 该论文提出了一种基于物理的机器学习方法，通过新颖的损失函数和输出变异性缩放机制，在教师-学生生成框架中使用归一化流，显著加速ALICE实验ZDC的粒子簇射模拟，比现有方法快421倍。


<details>
  <summary>Details</summary>
Motivation: 传统粒子探测器模拟计算成本高昂，需要加速ZDC（零度量热计）的模拟过程。物理机器学习能够结合领域知识与数据驱动方法，提高模型准确性和鲁棒性。

Method: 采用基于物理的机器学习范式，引入新颖的损失函数和基于输出变异性的缩放机制，在教师-学生生成框架中使用归一化流（NFs），增强模型对粒子簇射空间分布和形态的表示能力，减少罕见伪影对训练的影响。

Result: 该方法不仅优于经典的数据驱动模型同化，而且比ZDC模拟文献中现有的NF实现快421倍，显著提高了模拟速度。

Conclusion: 物理机器学习方法成功加速了ALICE实验ZDC的模拟，通过结合领域知识和创新训练机制，实现了既准确又高效的粒子簇射模拟，为高能物理实验模拟提供了有前景的解决方案。

Abstract: Physics-based machine learning blends traditional science with modern data-driven techniques. Rather than relying exclusively on empirical data or predefined equations, this methodology embeds domain knowledge directly into the learning process, resulting in models that are both more accurate and robust. We leverage this paradigm to accelerate simulations of the Zero Degree Calorimeter (ZDC) of the ALICE experiment at CERN. Our method introduces a novel loss function and an output variability-based scaling mechanism, which enhance the model's capability to accurately represent the spatial distribution and morphology of particle showers in detector outputs while mitigating the influence of rare artefacts on the training. Leveraging Normalizing Flows (NFs) in a teacher-student generative framework, we demonstrate that our approach not only outperforms classic data-driven model assimilation but also yields models that are 421 times faster than existing NF implementations in ZDC simulation literature.

</details>


### [88] [Physics-guided Neural Network-based Shaft Power Prediction for Vessels](https://arxiv.org/abs/2512.20348)
*Dogan Altan,Hamza Haruna Mohammed,Glenn Terje Lines,Dusica Marijan,Arnbjørn Maressa*

Main category: cs.LG

TL;DR: 提出一种结合物理模型与神经网络的混合方法，用于船舶轴功率预测，相比传统经验公式和纯神经网络方法，在四艘货船上均取得更低的预测误差。


<details>
  <summary>Details</summary>
Motivation: 船舶燃料消耗占全球贸易重要份额，准确预测轴功率对降低成本和排放至关重要。传统经验公式难以建模动态条件（如海况、船体污损），需要更精确的预测方法。

Method: 提出物理引导的混合神经网络方法，将经验公式嵌入神经网络中，结合神经网络与传统技术的优势。

Result: 在四艘相似尺寸货船数据上测试，物理引导神经网络相比基线神经网络和经验公式方法，在所有船舶上均取得更低的平均绝对误差、均方根误差和平均绝对百分比误差。

Conclusion: 物理引导的混合神经网络方法能更准确地预测船舶轴功率，为优化海上作业、降低燃料消耗和排放提供了有效解决方案。

Abstract: Optimizing maritime operations, particularly fuel consumption for vessels, is crucial, considering its significant share in global trade. As fuel consumption is closely related to the shaft power of a vessel, predicting shaft power accurately is a crucial problem that requires careful consideration to minimize costs and emissions. Traditional approaches, which incorporate empirical formulas, often struggle to model dynamic conditions, such as sea conditions or fouling on vessels. In this paper, we present a hybrid, physics-guided neural network-based approach that utilizes empirical formulas within the network to combine the advantages of both neural networks and traditional techniques. We evaluate the presented method using data obtained from four similar-sized cargo vessels and compare the results with those of a baseline neural network and a traditional approach that employs empirical formulas. The experimental results demonstrate that the physics-guided neural network approach achieves lower mean absolute error, root mean square error, and mean absolute percentage error for all tested vessels compared to both the empirical formula-based method and the base neural network.

</details>


### [89] [Field-Space Attention for Structure-Preserving Earth System Transformers](https://arxiv.org/abs/2512.20350)
*Maximilian Witte,Johannes Meuer,Étienne Plésiat,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出Field-Space Attention机制，在物理域而非潜在空间计算注意力，用于地球系统Transformer，保持连续场表示，实现可解释内部状态和科学约束实施。


<details>
  <summary>Details</summary>
Motivation: 需要能够直接操作连续地球物理场并保持其底层几何结构的机器学习架构，以实现准确且物理一致的地球系统动力学建模。

Method: 引入Field-Space attention机制，在物理域计算注意力；使用固定的非学习多尺度分解；学习输入场的结构保持变形；在HEALPix网格上进行全球温度超分辨率应用。

Result: Field-Space Transformers比传统Vision Transformers和U-Net基线收敛更快更稳定，参数更少；保持场结构允许直接嵌入物理和统计先验，提高数据驱动地球系统建模的保真度和可靠性。

Conclusion: Field-Space Attention作为紧凑、可解释且物理基础构建块，为下一代地球系统预测和生成建模框架提供了有力支持。

Abstract: Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers that computes attention in the physical domain rather than in a learned latent space. By maintaining all intermediate representations as continuous fields on the sphere, the architecture enables interpretable internal states and facilitates the enforcement of scientific constraints. The model employs a fixed, non-learned multiscale decomposition and learns structure-preserving deformations of the input field, allowing coherent integration of coarse and fine-scale information while avoiding the optimization instabilities characteristic of standard single-scale Vision Transformers. Applied to global temperature super-resolution on a HEALPix grid, Field-Space Transformers converge more rapidly and stably than conventional Vision Transformers and U-Net baselines, while requiring substantially fewer parameters. The explicit preservation of field structure throughout the network allows physical and statistical priors to be embedded directly into the architecture, yielding improved fidelity and reliability in data-driven Earth system modeling. These results position Field-Space Attention as a compact, interpretable, and physically grounded building block for next-generation Earth system prediction and generative modeling frameworks.

</details>


### [90] [Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning](https://arxiv.org/abs/2512.20363)
*Daniel M. Jimenez-Gutierrez,Mehrdad Hassanzadeh,Aris Anagnostopoulos,Ioannis Chatzigiannakis,Andrea Vitaletti*

Main category: cs.LG

TL;DR: 提出Clust-PSI-PFL框架，使用PSI指标量化非IID数据程度，通过聚类形成分布相似的用户组，显著提升联邦学习在非IID数据下的性能和公平性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的非独立同分布（non-IID）特性会导致模型更新偏差和性能下降，需要有效方法来量化这种分布差异并缓解其负面影响。

Method: 提出基于聚类的个性化联邦学习框架Clust-PSI-PFL：1) 使用人口稳定性指数（PSI）量化非IID程度，提出加权PSI指标WPSI^L；2) 基于PSI特征使用K-means++对客户端聚类；3) 通过轮廓系数法确定最优聚类数量；4) 在分布相似的客户端组内进行联邦学习。

Result: 在6个数据集（表格、图像、文本）、2种数据划分协议和多种客户端规模下，相比现有方法：1) 全局准确率提升高达18%；2) 在严重非IID数据下，客户端公平性相对提升37%；3) WPSI^L比常用非IID度量指标（Hellinger、Jensen-Shannon、Earth Mover距离）更具信息性。

Conclusion: PSI引导的聚类是一种原理清晰、轻量级的机制，能够在标签偏斜情况下实现鲁棒的个性化联邦学习，有效解决非IID数据带来的挑战。

Abstract: Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.

</details>


### [91] [BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples](https://arxiv.org/abs/2512.20403)
*Xuan-An Le,Minh-Nam Tran,Son Nguyen*

Main category: cs.LG

TL;DR: BRIDGE是一个两阶段知识蒸馏框架，通过引入中等规模的教师助手（TA）来弥合大模型与小模型之间的能力差距，仅用少量API查询就能显著提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 从大型专有模型（如GPT-4）向微小可部署模型（小于10亿参数）蒸馏知识面临容量预算陷阱：1000倍的能力差距阻碍了直接知识转移，而API成本又限制了数据收集。

Method: BRIDGE采用两阶段框架：第一阶段，中等规模的教师助手（约70亿参数）在严格限制的数据子集（3-5%）上从黑盒教师学习，使用零API成本管道平衡熵难度和语义多样性；第二阶段，利用TA推理免费的优势生成完整数据集的合成推理来训练微小学生模型，并采用指令调优课程建立行为对齐。

Result: 在医疗、法律和金融基准测试中，BRIDGE使学生模型性能提升28-41%，将能力差距缩小12-16%，同时使用10倍更少的教师查询。仅用5%的资源就超越了使用100%预算的直接蒸馏基线。

Conclusion: BRIDGE通过战略性的中间层和预算不对称设计，突破了传统的成本-性能边界，为大规模专有模型向微小可部署模型的知识蒸馏提供了高效解决方案。

Abstract: Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.

</details>


### [92] [Simplifying Multi-Task Architectures Through Task-Specific Normalization](https://arxiv.org/abs/2512.20420)
*Mihai Suteu,Ovidiu Serban*

Main category: cs.LG

TL;DR: 论文提出TSσBN，一种轻量级任务特定归一化方法，仅通过归一化层改进多任务学习，无需复杂架构设计


<details>
  <summary>Details</summary>
Motivation: 多任务学习面临资源平衡和任务干扰的挑战，现有复杂架构增加计算开销，需要更简单高效的解决方案

Method: 提出任务特定的Sigmoid批归一化(TSσBN)，通过任务特定的归一化层实现软容量分配，完全共享特征提取器

Result: 在NYUv2、Cityscapes、CelebA和PascalContext等数据集上匹配或超越现有方法，保持高参数效率，提供可解释的任务动态分析

Conclusion: 复杂多任务学习架构可能不必要，任务特定归一化提供简单、可解释且高效的替代方案

Abstract: Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TS$σ$BN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TS$σ$BN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.

</details>


### [93] [Machine Learning to Predict Digital Frustration from Clickstream Data](https://arxiv.org/abs/2512.20438)
*Jibin Joseph*

Main category: cs.LG

TL;DR: 使用电商点击流数据预测用户会话是否受挫，通过规则定义挫折行为（如愤怒点击、来回导航等），构建特征训练XGBoost和LSTM模型，LSTM在91%准确率和0.9705 AUC上表现最佳，且仅需前20-30次交互即可可靠预测。


<details>
  <summary>Details</summary>
Motivation: 移动应用和网站的用户挫折会导致销售损失和投诉，企业需要预测用户挫折来改善用户体验和业务表现。

Method: 基于规则定义挫折会话（愤怒爆发、来回导航、购物车流失、搜索困难、长时间徘徊），从304,881个会话的540万点击流事件中提取特征，训练XGBoost和LSTM分类器。

Result: XGBoost达到约90%准确率和0.9579 ROC AUC，LSTM表现最佳，达到约91%准确率和0.9705 ROC AUC，且仅需前20-30次交互即可可靠预测挫折。

Conclusion: 点击流数据可用于有效预测用户挫折，LSTM模型在序列数据上表现优异，早期预测能力有助于实时干预改善用户体验。

Abstract: Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints. In this research, I use clickstream data from a real e-commerce site to predict whether a session is frustrated or not. Frustration is defined using certain rules based on rage bursts, back and forth navigation (U turns), cart churn, search struggle, and long wandering sessions, and applies these rules to 5.4 million raw clickstream events (304,881 sessions). From each session, I build tabular features and train standard classifier models. I also use the full event sequence to train a discriminative LSTM classifier. XGBoost reaches about 90% accuracy, ROC AUC of 0.9579, while the LSTM performs best with about 91% accuracy and a ROC AUC of 0.9705. Finally, the research shows that with only the first 20 to 30 interactions, the LSTM already predicts frustration reliably.

</details>


### [94] [Recurrent Off-Policy Deep Reinforcement Learning Doesn't Have to be Slow](https://arxiv.org/abs/2512.20513)
*Tyler Clark,Christine Evers,Jonathon Hare*

Main category: cs.LG

TL;DR: RISE是一种新颖的循环网络集成方法，通过可学习和不可学习的编码器层，在图像基础的离策略强化学习中实现循环网络的优势而无需显著计算开销，在Atari基准测试中提升35.6%性能。


<details>
  <summary>Details</summary>
Motivation: 循环离策略深度强化学习模型虽然性能优异，但由于高计算需求而常被忽视。需要一种方法能够在图像基础的离策略RL设置中利用循环网络的优势，同时避免显著的计算开销。

Method: 提出RISE（通过简化编码的循环集成）框架，结合可学习和不可学习的编码器层，将循环网络集成到领先的非循环离策略RL算法中，无需显著增加计算负担。

Result: 将RISE集成到领先的非循环离策略RL算法中，在Atari基准测试中实现了35.6%的人类标准化四分位均值（IQM）性能提升。分析了多种实现策略以展示框架的通用性和潜力。

Conclusion: RISE提供了一种有效的方法，能够在图像基础的离策略强化学习环境中利用循环网络的优势，同时保持计算效率，为循环网络在RL中的广泛应用开辟了新途径。

Abstract: Recurrent off-policy deep reinforcement learning models achieve state-of-the-art performance but are often sidelined due to their high computational demands. In response, we introduce RISE (Recurrent Integration via Simplified Encodings), a novel approach that can leverage recurrent networks in any image-based off-policy RL setting without significant computational overheads via using both learnable and non-learnable encoder layers. When integrating RISE into leading non-recurrent off-policy RL algorithms, we observe a 35.6% human-normalized interquartile mean (IQM) performance improvement across the Atari benchmark. We analyze various implementation strategies to highlight the versatility and potential of our proposed framework.

</details>


### [95] [Explainable time-series forecasting with sampling-free SHAP for Transformers](https://arxiv.org/abs/2512.20514)
*Matthias Hertel,Sebastian Pütz,Ralf Mikut,Veit Hagenmeyer,Benjamin Schäfer*

Main category: cs.LG

TL;DR: SHAPformer：基于Transformer架构的快速、免采样的可解释时间序列预测模型，通过注意力机制操作生成SHAP解释，比传统SHAP方法快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测对规划决策至关重要，可解释性对建立用户信任和满足透明度要求很关键。现有的SHAP框架缺乏针对时间序列的高效实现，且采样反事实时通常假设特征独立。

Method: 基于Transformer架构，通过注意力机制操作使模型能够基于特征子集进行预测，实现免采样的SHAP解释生成。

Result: SHAPformer在1秒内生成解释，比SHAP Permutation Explainer快几个数量级；在合成数据上提供符合真实情况的解释；在真实电力负荷数据上实现竞争性预测性能，并提供有意义的局部和全局洞察。

Conclusion: SHAPformer是一个准确、快速且免采样的可解释时间序列预测模型，能够高效生成SHAP解释，在合成和真实数据上都表现出色，为时间序列预测提供了实用的可解释性解决方案。

Abstract: Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.

</details>


### [96] [Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs](https://arxiv.org/abs/2512.20573)
*Rui Pan,Zhuofu Chen,Ravi Netravali*

Main category: cs.LG

TL;DR: FailFast是一个基于扩散大语言模型的推测解码框架，通过动态调整推测长度实现高效加速，相比传统解码方法最高可达4.9倍速度提升。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)虽然能并行生成token，但在单独使用时存在效率与质量的权衡问题。作者发现，如果巧妙应用，dLLMs的特性可以成为推测解码中草稿生成器的优势，通过并行解码降低拒绝成本，实现更长的草稿生成从而获得更大的加速效果。

Method: 提出FailFast框架，使用dLLM作为草稿生成器，结合自回归验证器进行推测解码。核心创新是动态调整推测长度：在难以推测的区域"快速失败"以减少计算开销，在容易推测的区域"大胆获胜"通过生成更长草稿(可达70个token)来减少验证延迟。

Result: 无需微调即可实现无损加速，相比原始解码最高达4.9倍速度提升，相比最佳朴素dLLM草稿生成器提升1.7倍，相比EAGLE-3提升1.4倍，在不同模型和任务上表现一致。

Conclusion: FailFast成功将dLLMs的并行生成能力转化为推测解码的优势，通过动态调整推测长度的策略实现了显著的速度提升，为LLM推理加速提供了有效解决方案。

Abstract: Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It "fails fast" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and "wins big" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.4$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.

</details>


### [97] [Performative Policy Gradient: Optimality in Performative Reinforcement Learning](https://arxiv.org/abs/2512.20576)
*Debabrota Basu,Udvas Das,Brahim Driss,Uddalak Mukherjee*

Main category: cs.LG

TL;DR: 提出了首个考虑执行性（performative）的强化学习策略梯度算法PePG，解决了RL算法部署后影响环境动态变化的问题，相比现有方法能收敛到执行性最优策略而非仅稳定性。


<details>
  <summary>Details</summary>
Motivation: 部署后的机器学习算法会影响其所处的环境，从而改变底层动态，而标准强化学习方法忽略了这一点。虽然监督学习中的执行性设置已有研究，但强化学习中的对应问题尚未充分探索。

Method: 提出了执行性策略梯度算法（PePG），这是首个考虑执行性的策略梯度算法。证明了执行性性能差异引理和执行性策略梯度定理，在softmax参数化和有无熵正则化情况下，PePG能收敛到执行性最优策略。

Result: PePG在标准执行性RL环境中验证优于标准策略梯度算法和现有追求稳定性的执行性RL算法。算法能收敛到执行性最优策略，即策略在自身引起的分布变化下仍保持最优。

Conclusion: PePG是首个考虑执行性的强化学习策略梯度算法，能收敛到执行性最优策略，显著扩展了现有仅追求执行性稳定的工作，为部署后影响环境的RL算法提供了理论保证和实用方法。

Abstract: Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.

</details>


### [98] [Improving ML Training Data with Gold-Standard Quality Metrics](https://arxiv.org/abs/2512.20577)
*Leslie Barrett,Michael W. Sherman*

Main category: cs.LG

TL;DR: 该论文提出使用统计方法评估和提升人工标注训练数据的质量，通过多轮标注的一致性度量来衡量数据质量，并展示了如何在不要求每个项目多次标注的情况下收集高质量数据。


<details>
  <summary>Details</summary>
Motivation: 人工标注的训练数据对机器学习任务至关重要，但数据质量控制研究较少，而标注质量在不同标注任务中差异很大。需要可靠的方法来评估和提升标注数据的质量。

Method: 提出使用统计方法测量标注一致性和一致性程度。通过多轮标注记录一致性度量，利用一致性度量的方差下降作为数据质量提升的指标。还提出了一种不需要每个工作项多次标注就能收集高质量数据的方法。

Result: 一致性度量在多轮标注中能提供更可靠的结果，一致性度量方差的下降表明数据质量在提升。研究发现标注员熟悉期可能不足以最小化标注错误。

Conclusion: 统计方法能有效评估和提升人工标注数据的质量，多轮标注的一致性度量是可靠的质量指标。需要更系统的方法来确保标注数据质量，而不仅仅是依赖标注员熟悉期。

Abstract: Hand-tagged training data is essential to many machine learning tasks. However, training data quality control has received little attention in the literature, despite data quality varying considerably with the tagging exercise. We propose methods to evaluate and enhance the quality of hand-tagged training data using statistical approaches to measure tagging consistency and agreement. We show that agreement metrics give more reliable results if recorded over multiple iterations of tagging, where declining variance in such recordings is an indicator of increasing data quality. We also show one way a tagging project can collect high-quality training data without requiring multiple tags for every work item, and that a tagger burn-in period may not be sufficient for minimizing tagger errors.

</details>


### [99] [Relu and softplus neural nets as zero-sum turn-based games](https://arxiv.org/abs/2512.20582)
*Stephane Gaubert,Yiannis Vlassopoulos*

Main category: cs.LG

TL;DR: 论文将ReLU神经网络的输出解释为零和回合制停止博弈的值，称为ReLU网络博弈。网络评估等同于博弈值的Shapley-Bellman反向递归计算，由此推导出离散Feynman-Kac型路径积分公式，可用于输出边界分析、鲁棒性验证，并将训练转化为逆博弈问题。


<details>
  <summary>Details</summary>
Motivation: 为ReLU神经网络提供博弈论解释，建立网络输出与博弈值之间的对应关系，从而利用博弈论工具分析神经网络的性质，包括输出边界、鲁棒性验证，并为训练提供新的视角。

Method: 将ReLU神经网络输出解释为零和回合制停止博弈的值，网络评估对应Shapley-Bellman反向递归。推导离散Feynman-Kac型路径积分公式，利用Shapley算子的单调性分析输出边界，使用策略作为鲁棒性证书。将训练转化为逆博弈问题：给定终端奖励和对应值，寻找再现它们的博弈转移概率和奖励。

Result: 建立了ReLU神经网络与博弈论之间的严格对应关系，提供了网络输出的路径积分表示。该方法可推导输出边界、验证鲁棒性，并为训练提供逆博弈视角。类似方法也适用于Softplus激活函数，其中ReLU网络博弈被其熵正则化版本替代。

Conclusion: ReLU神经网络的输出可解释为特定博弈的值，这一博弈论表示为分析神经网络性质提供了新工具，包括边界分析、鲁棒性验证和训练视角。该方法可扩展到其他激活函数如Softplus，展示了博弈论与深度学习之间的深刻联系。

Abstract: We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.

</details>


### [100] [Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning](https://arxiv.org/abs/2512.20605)
*Seijin Kobayashi,Yanick Schimpf,Maximilian Schlegel,Angelika Steger,Maciej Wolczyk,Johannes von Oswald,Nino Scherre,Kaitlin Maile,Guillaume Lajoie,Blake A. Richards,Rif A. Saurous,James Manyika,Blaise Agüera y Arcas,Alexander Meulemans,João Sacramento*

Main category: cs.LG

TL;DR: 本文提出了一种在自回归模型内部表示中进行探索和行动的方法，通过引入高阶非因果序列模型来控制基础模型的残差流激活，实现了时间抽象动作的发现和高效探索。


<details>
  <summary>Details</summary>
Motivation: 传统的基于token-by-token采样的强化学习方法在奖励稀疏时学习效率低下，需要一种能够在自回归模型内部表示层面进行探索的方法，以实现更高效的分层强化学习。

Method: 引入高阶非因果序列模型，其输出控制基础自回归模型的残差流激活；该模型学习将长激活序列块压缩到内部控制器中，每个控制器执行行为上有意义的长时程动作序列，并带有学习到的终止条件。

Result: 在具有分层结构的网格世界和MuJoCo任务中，高阶模型成功学习将长激活序列压缩到内部控制器；内部控制器强化（内部RL）能够在标准RL微调失败的情况下从稀疏奖励中学习，实现高效探索。

Conclusion: 内部RL展示了在自回归模型中潜在动作生成和强化的优势，为实现基础模型中的分层强化学习提供了有前景的途径。

Abstract: Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term "internal RL", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.

</details>


### [101] [Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures](https://arxiv.org/abs/2512.20607)
*Yedi Zhang,Andrew Saxe,Peter E. Latham*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，解释梯度下降训练神经网络时出现的"简单性偏置"现象，即网络会随时间学习越来越复杂的解。该框架适用于全连接、卷积和注意力架构，揭示了鞍点到鞍点的学习动态机制。


<details>
  <summary>Details</summary>
Motivation: 神经网络在梯度下降训练中经常表现出"简单性偏置"现象，即随着时间推移学习越来越复杂的解。尽管这一现象在各种架构中广泛观察到，但现有的理论处理缺乏统一框架来解释这一现象。

Method: 提出了一个理论框架来分析鞍点到鞍点的学习动态，适用于全连接、卷积和注意力网络。通过分析固定点、不变流形和梯度下降动态，展示了网络如何通过迭代地接近不变流形、接近鞍点、然后切换到另一个不变流形来学习。

Result: 理论分析表明：线性网络学习秩逐渐增加的解；ReLU网络学习"扭结"数量逐渐增加的解；卷积网络学习卷积核数量逐渐增加的解；自注意力模型学习注意力头数量逐渐增加的解。该框架还阐明了数据分布和权重初始化对学习平台期持续时间和数量的影响。

Conclusion: 该理论为理解梯度下降何时以及为何会渐进地学习越来越复杂的解提供了一个统一框架，揭示了鞍点到鞍点动态是简单性偏置现象背后的机制，并分离了先前混淆的因素如数据分布和初始化对学习动态的影响。

Abstract: Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explains a simplicity bias arising from saddle-to-saddle learning dynamics for a general class of neural networks, incorporating fully-connected, convolutional, and attention-based architectures. Here, simple means expressible with few hidden units, i.e., hidden neurons, convolutional kernels, or attention heads. Specifically, we show that linear networks learn solutions of increasing rank, ReLU networks learn solutions with an increasing number of kinks, convolutional networks learn solutions with an increasing number of convolutional kernels, and self-attention models learn solutions with an increasing number of attention heads. By analyzing fixed points, invariant manifolds, and dynamics of gradient descent learning, we show that saddle-to-saddle dynamics operates by iteratively evolving near an invariant manifold, approaching a saddle, and switching to another invariant manifold. Our analysis also illuminates the effects of data distribution and weight initialization on the duration and number of plateaus in learning, dissociating previously confounding factors. Overall, our theory offers a framework for understanding when and why gradient descent progressively learns increasingly complex solutions.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [102] [Observation of flat-band skin effect](https://arxiv.org/abs/2512.19745)
*Xulong Wang,Dongyi Wang,Congwei Lu,Ruo-Yang Zhang,Ching Hua Lee,Kun Ding,Guancong Ma*

Main category: quant-ph

TL;DR: 在非厄米系统中发现平带皮肤效应，不同于传统色散带的点隙拓扑保护，平带皮肤效应与色散带的谱拓扑相关，仅在有限非厄米参数范围内出现，并在实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米系统中平带的新现象，研究平带在非厄米环境下的独特行为，特别是平带皮肤效应的出现机制及其与拓扑性质的关系。

Method: 通过理论分析和数值模拟研究一维非厄米晶格中的平带系统，分析平带皮肤效应的出现条件，研究能隙闭合处的异常点行为，并在机械晶格中进行实验验证。

Result: 发现平带皮肤效应与色散带在复能平面上的非平凡谱拓扑相关，该效应仅在有限非厄米参数范围内出现，在强非厄米性下会消失；平带波函数在异常点处量子距离不连续；在机械晶格中成功观测到平带皮肤效应。

Conclusion: 非厄米系统中的平带展现出独特现象，平带皮肤效应揭示了量子几何和局域化控制的新可能性，为理解非厄米系统中的平带行为提供了新视角。

Abstract: Symmetry-protected ideal flat bands in one-dimensional (1D) Hermitian lattices are populated by compact localized states (CLS) - a special class of localization with wavefunctions confined within a small region. In this work, we discover that the non-Hermitian skin effect (NHSE) can appear in a flat band. Unlike conventional NHSEs for dispersive bands that are protected by nontrivial point-gap topology, the flat band remains a point on the complex-energy plane and is therefore always topologically trivial. We found that, intriguingly, the flat-band skin effect (FBSE) is associated with the non-trivial spectral topology of the dispersive bands enclosing the flat band on the complex-energy plane, so it only emerges within a finite range of non-Hermitian parameters and can counterintuitively disappear at large non-Hermiticity. Moreover, the gaps between the flat and the dispersive bands can close at higher-order exceptional points under both periodic and open boundary conditions. The flat-band wavefunctions are discontinuous in quantum distance across these exceptional points, signifying that the gap-closing is singular. The FBSE was experimentally observed in a non-Hermitian mechanical lattice. Our work reveals flat-band phenomena unique to non-Hermitian systems and highlights new possibilities in quantum geometry and localization control.

</details>


### [103] [Composable, unconditional security without a Quantum secret key: public broadcast channels and their conceptualizations, adaptive bit transmission rates, fidelity pruning under wiretaps](https://arxiv.org/abs/2512.19759)
*Pete Rigas*

Main category: quant-ph

TL;DR: 该论文研究无密钥通信协议中的量子信道，探讨如何将QKD相关协议元素融入QKD无关协议，分析量子-经典性能差距，并建立同时实现保密性和认证的条件。


<details>
  <summary>Details</summary>
Motivation: 研究无密钥通信协议中的量子信道，探索如何将量子密钥分发（QKD）相关协议的元素融入QKD无关协议，分析量子优势的可能性，并建立同时实现保密性和认证的理论条件。

Method: 通过分析公共广播、前向概念和后向概念量子信道，使用级联方法增加Eve的错误接受概率，利用Holevo信息和最优解码器分析Eve的错误概率，并通过CPTP映射的后处理结合数据处理和熵连续性边界减少Holevo和量。

Result: 证明了存在合适的协议能使Alice和Bob以高概率映射到认证的比特码字空间，前向概念信道通过级联能显著增加Eve的错误接受概率，并展示了如何通过后处理减少Holevo和量。

Conclusion: 该研究为无密钥量子通信协议提供了理论框架，展示了如何将QKD相关协议元素融入QKD无关协议，并建立了同时实现保密性和认证的条件，为探索无条件安全通信开辟了新方向。

Abstract: We examine public broadcast, forward conceptual, and backward conceptual, Quantum channels in the context of communication protocols that are independent of secret keys. Given research directions of interest previously identified in arXiv: 1804.01797, besides converse upper bounds on the bit transmission rate obtained by the author in recent work (arXiv: 2507.03035), additional possibilities remain, including: (1) determining whether aspects of QKD dependent protocols can be incorporated into steps of QKD independent protocols; (2) whether there would be any amplification to the Quantum-classical performance gap that Alice and Bob can exploit towards prospective Quantum advantage; (3) formulating the conditions under which secrecy and authentication can be simultaneously achieved. To characterize the conditions for which secrecy can be achieved with high probability, we argue that there not only exists suitable protocols which enable Alice and Bob to map into the authenticated space of bit codewords with high probability, but also that forward conceptual channels, through cascading, can significantly increase Eve's probability of false acceptance. Albeit the fact that secrecy, along with conceputalizations of the public broadcast channel, were initially discussed by Maurer for QKD dependent protocols, determining whether aspects of such protocols can be adapted for unconditional security without the use of a secret key is of great interest to explore. We demonstrate that Eve's error probability, through the cascading procedure, can be analyzed with the Holevo information under an optimal decoder. Furthermore, through post-processing of the outputs of a Completely Positive Trace Preserving (CPTP) map, we also demonstrate how to decrease Holevo sum quantities with data-processing and entropy-continuity bounds.

</details>


### [104] [Theory of Scalable Spin Squeezing with Disordered Quantum Dipoles](https://arxiv.org/abs/2512.19781)
*Avi Kaplan-Lipkin,Philip J. D. Crowley,Jonathan N. Hallén,Zilin Wang,Weijie Wu,Sabrina Chern,Chris R. Laumann,Lode Pollet,Norman Y. Yao*

Main category: quant-ph

TL;DR: 研究无序二维偶极自旋系统中的可扩展自旋压缩，发现无序增加时仅在海森堡点附近存在可扩展自旋压缩，并提出通过解耦紧密耦合二聚体实现实验可行的解决方案。


<details>
  <summary>Details</summary>
Motivation: 虽然偶极自旋系统通过淬火动力学能产生自旋压缩，但现有理论主要关注晶格系统，而实际系统（如超冷分子、核自旋系综、固态色心）常存在显著位置无序。需要研究无序对可扩展自旋压缩的影响。

Method: 建立二维随机稀释晶格中量子偶极子的理论模型（偶极XXZ模型），通过大量量子蒙特卡洛模拟绘制有限温度XY序（及可扩展自旋压缩）随无序和各向异性变化的相图。

Result: 无序增加时，可扩展自旋压缩仅在海森堡点附近存在。这是由于罕见的紧密耦合二聚体在淬火后有效加热系统。对于金刚石中的氮空位中心，实验可行的解耦策略足以实现可扩展自旋压缩。

Conclusion: 无序偶极系统中可扩展自旋压缩的可行性受紧密耦合二聚体限制，但通过针对性解耦这些二聚体可在实际实验条件下实现可扩展自旋压缩。

Abstract: Spin squeezed entanglement enables metrological precision beyond the classical limit. Understood through the lens of continuous symmetry breaking, dipolar spin systems exhibit the remarkable ability to generate spin squeezing via their intrinsic quench dynamics. To date, this understanding has primarily focused on lattice spin systems; in practice however, dipolar spin systems$\unicode{x2014}$ranging from ultracold molecules to nuclear spin ensembles and solid-state color centers$\unicode{x2014}$often exhibit significant amounts of positional disorder. Here, we develop a theory for scalable spin squeezing in a two-dimensional randomly diluted lattice of quantum dipoles, which naturally realize a dipolar XXZ model. Via extensive quantum Monte Carlo simulations, we map out the phase diagram for finite-temperature XY order, and by extension scalable spin squeezing, as a function of both disorder and Ising anisotropy. As the disorder increases, we find that scalable spin squeezing survives only near the Heisenberg point. We show that this behavior is due to the presence of rare tightly-coupled dimers, which effectively heat the system post-quench. In the case of strongly-interacting nitrogen-vacancy centers in diamond, we demonstrate that an experimentally feasible strategy to decouple the problematic dimers from the dynamics is sufficient to enable scalable spin squeezing.

</details>


### [105] [Learning transitions of topological surface codes](https://arxiv.org/abs/2512.19786)
*Finn Eckstein,Bo Han,Simon Trebst,Guo-Yi Zhu*

Main category: quant-ph

TL;DR: 研究测量如何影响表面码的拓扑量子序，发现对于大多数测量角度，逻辑信息要么保持稳健，要么通过经典阴影完整传递给观测者，而特定角度下会出现学习相变。


<details>
  <summary>Details</summary>
Motivation: 探索当观测者通过测量底层量子比特来探测拓扑量子态时，测量是否会破坏拓扑序，以及能从测量结果中学习到多少逻辑信息。

Method: 分析在所有量子比特上执行统一基测量的情况，研究不同测量角度下的行为，将测量系综表示为二维张量网络，并通过费米化将其映射到对称类DIII的自由费米子网络模型。

Result: 对于远离Clifford X、Y、Z方向的通用测量角度，逻辑信息要么保持稳健（弱测量），要么通过经典阴影完整传递（投影测量）。在投影测量极限下，系统表现为Majorana金属相。当测量角度偏向X或Z极限时，会出现学习相变，对应网络模型中的金属-绝缘体相变。

Conclusion: 测量不一定破坏拓扑量子序，逻辑信息可以通过测量结果完整获取，但存在学习相变阈值，超过该阈值只能获取部分逻辑信息。

Abstract: For the surface code, topological quantum order allows one to encode logical quantum information in a robust, long-range entangled many-body quantum state. However, if an observer probes this quantum state by performing measurements on the underlying qubits, thereby collecting an ensemble of highly correlated classical snapshots, two closely related questions arise: (i) do measurements decohere the topological order of the quantum state; and (ii) how much of the logical information can one learn from the snapshots? Here we address these questions for measurements in a uniform basis on all qubits. We find that for generic measurement angles, sufficiently far away from the Clifford X, Y, and Z directions (such as the X+Y+Z basis) the logical information is never lost in one of the following two ways: (i) for weak measurement, the topological order is absolutely robust; (ii) for projective measurement, the quantum state inevitably collapses, but the logical quantum information is faithfully transferred from the quantum system to the observer in the form of a tomographically complete classical shadow. At these generic measurement angles and in the projective-measurement limit, the measurement ensemble enforced by Born probabilities can be represented by a 2D tensor network that can be fermionized into a disordered, free-fermion network model in symmetry class DIII, which gives rise to a Majorana "metal" phase. When the measurement angle is biased towards the X or Z limits, a critical angle indicates the threshold of a learning transition beyond which the classical shadow no longer reveals full tomographic information (but reduces to a measurement of the logical X or Z state). This learning transition can be described in the language of the network model as a "metal to insulator" transition...

</details>


### [106] [Passive quantum reference frame transformations cannot create entanglement between physical systems](https://arxiv.org/abs/2512.19790)
*T. Rick Perche,Natália Salomé Móller,Guilherme Franzmann*

Main category: quant-ph

TL;DR: 量子参考系变换中子系统纠缠的必要条件：被动量子参考系变换不会在物理系统间产生纠缠


<details>
  <summary>Details</summary>
Motivation: 研究量子参考系变换如何影响子系统间的纠缠关系，区分参考系系统和物理系统，探索量子参考系框架下的纠缠特性

Method: 定义被动量子参考系，区分适合作为参考系的量子系统和相对于这些参考系描述的物理系统，分析参考系变换对纠缠的影响

Result: 发现被动量子参考系之间的变换不会在物理系统间产生纠缠，为子系统在量子参考系变换后纠缠的必要条件提供了理论依据

Conclusion: 量子参考系变换对纠缠产生有重要限制，被动参考系变换无法创造物理系统间的纠缠，这一结果对量子信息处理和量子基础研究有重要意义

Abstract: We find a necessary condition for subsystems to become entangled after a quantum reference frame transformation. By distinguishing between quantum systems suitable to act as reference frames and physical systems described relative to these frames, we define passive quantum reference frames and show that transformations between these cannot produce entanglement between physical systems. Our results also apply to the study of entanglement between subsystems in the perspectival framework even when there is no distinction between physical and reference systems.

</details>


### [107] [Variational (matrix) product states for combinatorial optimization](https://arxiv.org/abs/2512.20613)
*Guillermo Preisser,Conor Mc Keever,Michael Lubasch*

Main category: quant-ph

TL;DR: 提出基于乘积态和矩阵乘积态的变分方法，结合迭代局部搜索元启发式，用于组合优化问题的近似求解，在最大割问题上表现优于传统方法和量子算法。


<details>
  <summary>Details</summary>
Motivation: 传统量子启发式方法在解决大规模组合优化问题时存在性能限制，需要开发更高效的变分算法来获得更好的近似解。

Method: 使用乘积态和矩阵乘积态作为变分ansatz，结合量子退火哈密顿量进行能量最小化，并嵌入迭代局部搜索元启发式引入随机性。

Result: 在多达50000个变量的最大割问题上进行基准测试，结果显示该方法优于传统(M)PS方法、经典ILS、量子近似优化算法和其他量子启发式求解器。

Conclusion: 量子启发的迭代局部搜索算法为大规模组合优化问题提供了有效的近似求解方案，展示了变分方法与元启发式结合的优势。

Abstract: To compute approximate solutions for combinatorial optimization problems, we describe variational methods based on the product state (PS) and matrix product state (MPS) ansatzes. We perform variational energy minimization with respect to a quantum annealing Hamiltonian and utilize randomness by embedding the approaches in the metaheuristic iterated local search (ILS). The resulting quantum-inspired ILS algorithms are benchmarked on maximum cut problems of up to 50000 variables. We show that they can outperform traditional (M)PS methods, classical ILS, the quantum approximate optimization algorithm and other variational quantum-inspired solvers.

</details>


### [108] [High-efficiency loading of 2,400 Ytterbium atoms in optical tweezer arrays](https://arxiv.org/abs/2512.19795)
*Jiawen Zhu,Changfeng Chen,Li Zhou,Xiangru Xie,Chenyang Jiang,Zhuoli Ding,Fan Wu,Fan Yang,Guoqing Wang,Qihuang Gong,Peng Zhang,Sheng Zhang,Pai Peng*

Main category: quant-ph

TL;DR: 研究人员实现了2400个镱-174原子光镊阵列，单原子装载效率达83.5%，展示了优异的可扩展性，并提出了基于基态-钟态编码的量子计算方案。


<details>
  <summary>Details</summary>
Motivation: 碱土类原子具有长相干时间和高保真度里德堡门等优势，但其可扩展性一直落后于碱金属原子。本研究旨在解决碱土类原子阵列的可扩展性问题。

Method: 采用增强型单原子装载方法，在光镊阵列中捕获2400个镱-174原子，并在不同原子间势能条件下验证方法的鲁棒性。

Result: 实现了83.5(1)%的单原子装载效率，且该效率在从几十到几千个原子的阵列规模下均能保持，展示了优异的可扩展性。增强装载方法在不同原子间势能条件下均有效。

Conclusion: 该工作推进了使用碱土类原子实现大规模量子计算机的前景，提出的基态-钟态编码方案有望实现99.9%的双量子比特门保真度。

Abstract: Neutral atom arrays have emerged as a powerful platform for quantum computation, simulation, and metrology. Among them, alkaline-earth-like atoms exhibit distinct advantages, including long coherence time and high-fidelity Rydberg gates. However, their scalability has lagged behind that of the alkali atoms. Here, we report 2,400 Ytterbium-174 atoms trapped in an optical tweezer array with enhanced single-atom loading efficiency of 83.5(1)%. Notably, the loading efficiency is largely maintained for array sizes ranging from dozens to thousands, exhibiting excellent scalability. We demonstrate the broad applicability of the enhanced loading method by showing that the enhancement exists robustly across a range of interatomic potentials, suggesting its utility for other atomic species. To establish the capability of the 174Yb arrays toward universal quantum computation, we propose to encode the qubit in the ground-clock state manifold and estimate a 99.9% two-qubit gate fidelity with experimentally feasible parameters. Our work advances the prospects for realizing large-scale quantum computers using alkaline-earth-like atoms.

</details>


### [109] [Ergotropy of quantum many-body scars](https://arxiv.org/abs/2512.19801)
*Zhaohui Zhi,Qingyun Qian,Jin-Guo Liu,Guo-Yi Zhu*

Main category: quant-ph

TL;DR: 量子多体疤痕态具有非遍历性，能存储可提取能量（ergotropy），而热态是被动态无ergotropy。本文在PXP模型中揭示了疤痕态与热态之间插值态的广泛ergotropy标度，发现了ergotropy与纠缠的唯象关系，并提出了通过全局相干旋转为量子"电池"充电的动力学协议。


<details>
  <summary>Details</summary>
Motivation: 量子多体疤痕态打破了遍历性并避免了热化，即使在高能量密度下也具有面积律纠缠熵。虽然其量子关联和纠缠已被研究，但其存储可提取能量（ergotropy）的能力仍是一个开放问题。本文旨在探索量子多体疤痕态作为量子"电池"的潜力。

Method: 聚焦于代表性的PXP模型，研究量子多体疤痕态与热态之间插值态的ergotropy标度行为。通过唯象分析揭示ergotropy与纠缠的关系，并设计动力学协议：通过全局均匀相干旋转实现重置，为量子"电池"注入可提取能量。该协议针对里德堡中性原子阵列设计，也可用于其他量子处理器。

Result: 发现量子多体疤痕态与热态之间插值态具有广泛的ergotropy标度，而热态是被动态且ergotropy为零。揭示了ergotropy与纠缠的唯象关系，将现有自由费米子可积结果推广到相互作用情形。动力学协议表明，全局相干旋转可以注入可提取能量，成功为量子"电池"充电。

Conclusion: 量子多体疤痕态尽管只占据希尔伯特空间的微小部分，但能有效存储可提取能量。通过"疤痕化"多体系统是工程化量子多体电池的有前景途径。该研究为利用量子多体疤痕态作为量子能量存储设备奠定了基础。

Abstract: Quantum many-body scars break ergodicity and evade thermalization, resulting in area law entanglement entropy even with high energy density. While their quantum correlations and entanglement have been elaborated previously, their capacity in storing extractable energy, quantified by the notion ergotropy, remains an open question. Here we focus on the representative PXP model, and unveil the extensive ergotropy scaling of a family of states interpolating between quantum many-body scars and thermal states, the latter of which are known to be passive with vanishing ergotropy. A phenomenological relation between ergotropy and entanglement is uncovered, which generalizes the existing free fermion integrable results to an interacting scenario. The ergotropy in a dynamical protocol shows that a reset with a global uniform coherent rotation can inject extractable energy, as a proof of principle way to charge a quantum "battery". Our protocol is tailored for near term Rydberg neutral atoms array, while also being feasible for other quantum processors. Our results establish that quantum many-body scars, despite the tiny fraction of the Hilbert space they occupy, can be efficiently exploited for storing extractable energy, and "scarring" a many-body system as a promising route for engineering quantum many-body battery.

</details>


### [110] [Local Operations and Field Mediated Entanglement without a Local Tensor Product Structure](https://arxiv.org/abs/2512.19806)
*Alberto Spalvieri,Sébastien Christophe Garmier,Flaminia Giacomini*

Main category: quant-ph

TL;DR: 该论文构建了规范理论中的规范不变局部代数，为缺乏局部张量积结构的规范理论提供了操作一致的局域性概念，并证明了离散化电磁学满足LOCC定理的类似物。


<details>
  <summary>Details</summary>
Motivation: 量子信息理论通常假设子系统局域性（希尔伯特空间的因子化分解），但规范约束阻止了总希尔伯特空间分解为时空局部的张量积结构。这使得标准信息论结果（如LOCC定理）无法直接应用于规范理论。需要弥合这一差距。

Method: 针对二维晶格规范模型（捕捉电磁学关键特征），构建规范不变局部代数，推导希尔伯特空间的物理意义分解，在缺乏局部张量积结构的情况下提供操作一致的局域性概念。

Result: 离散化电磁学满足LOCC定理的类似物：即使在没有希尔伯特空间的时空局部张量积分解的情况下，没有真正的量子场相互作用也无法产生纠缠。这为规范理论的子系统结构定义提供了操作途径。

Conclusion: 该工作为规范理论建立了操作一致的局域性框架，弥合了量子信息理论与规范理论之间的差距，可能指向定义规范理论子系统结构的操作方式。

Abstract: Quantum information has become a powerful tool for probing the structure of quantum field theories, yet its application to gauge theories remains subtle. On the one hand, quantum information theory assumes subsystem locality, i.e.~the factorization of the total Hilbert space into subsystems. On the other hand, gauge constraints prevent the total Hilbert space to decompose into a spacetime-local tensor product structure. Because the Hilbert space structure of gauge theories does not accommodate the subsystem decomposition used in quantum information theory, standard information-theoretic results, such as the Local Operations and Classical Communication (LOCC) theorem, cannot be used straightforwardly in the context of gauge theories. In this work, we bridge this gap in the case of a two-dimensional lattice gauge model that captures key features of electromagnetism. In particular, we construct gauge-invariant local algebras and derive a physically meaningful decomposition of the Hilbert space, providing an operationally consistent notion of locality in the absence of a local tensor-product structure. We apply this framework to field-mediated entanglement protocols relevant to proposed tests of the quantum nature of gravity. We show that the discretized version of electromagnetism satisfies an analogue of the LOCC theorem: entanglement cannot be generated without genuine quantum field interactions, even in the absence of a spacetime-local tensor product factorization of the Hilbert space. This may point towards an operational way to define a subsystem structure for gauge theories.

</details>


### [111] [Fundamentals of quantum Boltzmann machine learning with visible and hidden units](https://arxiv.org/abs/2512.19819)
*Mark M. Wilde*

Main category: quant-ph

TL;DR: 该论文推导了量子玻尔兹曼机中量子相对熵梯度的解析表达式，并提出了量子算法进行梯度估计，推动了具有可见和隐藏单元的量子玻尔兹曼机的训练进展。


<details>
  <summary>Details</summary>
Motivation: 经典玻尔兹曼机在生成建模中已有成熟应用，但将其推广到具有可见和隐藏单元的量子玻尔兹曼机进行量子态学习一直存在障碍。需要解决量子相对熵梯度的计算问题。

Method: 推导了量子玻尔兹曼机中量子相对熵梯度的解析表达式，该表达式可通过量子计算机估计，涉及模流生成的幺正旋转。提出了专门的量子算法，并扩展到Petz-Tsallis相对熵目标函数。

Result: 获得了量子相对熵梯度的解析表达式，该表达式适合量子计算机估计。开发了相应的量子算法，并针对量子可见单元/经典隐藏单元等不同设置提供了具体梯度表达式和算法。

Conclusion: 该论文在训练具有可见和隐藏单元的量子玻尔兹曼机方面取得了重要进展，为量子生成建模和量子态学习提供了理论基础和实用算法。

Abstract: One of the primary applications of classical Boltzmann machines is generative modeling, wherein the goal is to tune the parameters of a model distribution so that it closely approximates a target distribution. Training relies on estimating the gradient of the relative entropy between the target and model distributions, a task that is well understood when the classical Boltzmann machine has both visible and hidden units. For some years now, it has been an obstacle to generalize this finding to quantum state learning with quantum Boltzmann machines that have both visible and hidden units. In this paper, I derive an analytical expression for the gradient of the quantum relative entropy between a target quantum state and the reduced state of the visible units of a quantum Boltzmann machine. Crucially, this expression is amenable to estimation on a quantum computer, as it involves modular-flow-generated unitary rotations reminiscent of those appearing in my prior work on rotated Petz recovery maps. This leads to a quantum algorithm for gradient estimation in this setting. I then specialize the setting to quantum visible units and classical hidden units, and vice versa, and provide analytical expressions for the gradients, along with quantum algorithms for estimating them. Finally, I replace the quantum relative entropy objective function with the Petz-Tsallis relative entropy; here I develop an analytical expression for the gradient and sketch a quantum algorithm for estimating it, as an application of a novel formula for the derivative of the matrix power function, which also involves modular-flow-generated unitary rotations. Ultimately, this paper demarcates progress in training quantum Boltzmann machines with visible and hidden units for generative modeling and quantum state learning.

</details>


### [112] [Towards a point-to-point CV-QKD system: Implementation challenges and perspectives](https://arxiv.org/abs/2512.19834)
*Davi Juvêncio Gomes de Sousa,Nelson Alves Ferreira Neto,Christiano M. S. Nascimento,Lucas Q. Galvão,Mauro Queiroz Nooblath Neto,Micael Andrade Dias,Cássio de Castro Silva,Braian Pinheiro da Silva,Alexandre B. Tacla,Valéria Loureiro da Silva*

Main category: quant-ph

TL;DR: 该论文分析了连续变量量子密钥分发(CV-QKD)系统在光纤中的实际挑战和实施前景，重点讨论了物理层设计、数字信号处理、后处理流程以及硬件架构，并为巴西部署CV-QKD系统提供了路线图。


<details>
  <summary>Details</summary>
Motivation: 研究CV-QKD系统在实际光纤部署中的挑战，为巴西建立首个点对点CV-QKD系统奠定基础，并为可扩展、可互操作的量子通信网络提供路线图。

Method: 从物理层（发射器、量子信道、接收器设计）、数字信号处理（DSP桥接量子传输与经典后处理）、后处理流程（有限尺寸参数估计、LDPC码信息协调、通用哈希隐私放大）到硬件架构（模块化数字架构、CV-QKD-ModSim软件框架）进行全面分析。

Result: 建立了CV-QKD系统在光纤中部署的完整技术框架，包括处理衰减、色散、偏振波动等损伤的方法，优化了低信噪比条件下的信息协调，并开发了硬件-软件协同设计工具。

Conclusion: 该研究为巴西首个点对点CV-QKD系统奠定了基础，提供了从城域测试床到混合光纤/FSO和空间基础设施的部署路线图，推动了可扩展量子通信网络的发展。

Abstract: This article presents an analysis of the practical challenges and implementation perspectives of point-to-point continuous-variable quantum key distribution (CV-QKD) systems over optical fiber. The study addresses the physical layer, including the design of transmitters, quantum channels, and receivers, with emphasis on impairments such as attenuation, chromatic dispersion, polarization fluctuations, and coexistence with classical channels. We further examine the role of digital signal processing (DSP) as the bridge between quantum state transmission and classical post-processing, highlighting its impact on excess noise mitigation, covariance matrix estimation, and reconciliation efficiency. The post-processing pipeline is detailed with a focus on parameter estimation in the finite-size regime, information reconciliation using LDPC-based codes optimized for low-SNR conditions, and privacy amplification employing large-block universal hashing. From a hardware perspective, we discuss modular digital architectures that integrate dedicated accelerators with programmable processors, supported by a reference software framework (CV-QKD-ModSim) for algorithm validation and hardware co-design. Finally, we outline perspectives for the deployment of CV-QKD in Brazil, starting from metropolitan testbeds and extending toward hybrid fiber/FSO and space-based infrastructures. The work establishes the foundations for the first point-to-point CV-QKD system in Brazil, while providing a roadmap for scalable and interoperable quantum communication networks.

</details>


### [113] [Quantum Mechanics on Lie Groups: I. Noncommutative Fourier Transforms](https://arxiv.org/abs/2512.19840)
*Mathieu Beauvillain,Blagoje Oblak,Marios Petropoulos*

Main category: quant-ph

TL;DR: 该论文构建了李群上平方可积波函数到其对偶李代数上波函数的可逆傅里叶变换，建立了非对易傅里叶级数理论，并推导了紧李群的非对易泊松求和公式。


<details>
  <summary>Details</summary>
Motivation: 为量子系统在群流形上的Wigner函数和路径积分计算提供理论基础。需要建立从位置空间到动量空间的群论版本变换，其中动量由于群结构而通常非对易。

Method: 从李群上的平方可积波函数出发，构建可逆傅里叶变换映射到对偶李代数上的波函数。处理涉及星积的动量相关函数乘法，建立非对易傅里叶级数理论。

Result: 证明了该形式主义提供了希尔伯特空间的等距映射，并推导出了任意紧李群的非对易泊松求和公式。

Conclusion: 该工作为群流形上量子系统的Wigner函数和路径积分计算奠定了关键基础，建立了非对易傅里叶分析的理论框架。

Abstract: Starting from square-integrable wave functions on a Lie group, we build an invertible Fourier transform mapping them on wave functions on the dual of the Lie algebra. This is a group-theoretic version of the map from position space to momentum space, with generally noncommuting momenta owing to the group structure. As a result, the multiplication of momentum-dependent functions involves star products, which makes the construction of noncommutative Fourier series much more involved than that of their commutative cousin. We show that our formalism provides an isometry of Hilbert spaces, and use it to derive a noncommutative Poisson summation formula for any compact Lie group. This is a key preliminary for the computation of Wigner functions and path integrals for quantum systems on group manifolds.

</details>


### [114] [Complexity and Information in Quantum and Classical Trajectories](https://arxiv.org/abs/2512.19848)
*Hira Ali,Naeem Shahid*

Main category: quant-ph

TL;DR: 量子轨迹与经典电报模型在耦合增强时都会从独立转向同步，但只有量子轨迹在大驱动-衰减比下展现出增强的复杂性和持续的信息共享，其复杂度-信息相关性可作为量子效应的轨迹级特征。


<details>
  <summary>Details</summary>
Motivation: 研究开放系统中量子与经典动力学的区别，探索如何直接从量子跳跃记录中提取有效的区分特征，为量子效应提供轨迹层面的清晰标志。

Method: 分析驱动耗散双量子比特系统和匹配速率的经典电报模型的发射轨迹，使用Lempel-Ziv复杂度、互信息和时间相关性等指标进行比较。

Result: 两种模型在耦合增强时都经历了从独立到同步的转变，但只有量子轨迹在大驱动-衰减比下展现出增强的复杂性和持续的信息共享。经典相关性短暂且被强驱动抑制。量子情况中出现了独特的强复杂度-信息相关性。

Conclusion: 直接从跳跃记录中提取的复杂度和信息测量为区分开放系统中的量子与经典动力学提供了有效方法，复杂度-信息相关性是量子效应的明确轨迹级特征。

Abstract: We analyze emission trajectories from a driven-dissipative two-qubit system and a classical telegraph model with matched rates. Using Lempel-Ziv complexity, mutual information, and temporal correlations, we show that both models undergo a transition from independent to synchronized dynamics as coupling increases, but only the quantum trajectories develop enhanced complexity and sustained information sharing at large drive-to-decay ratio. Classical correlations are short-lived and quickly suppressed by strong drive. A strong complexity-information correlation appears uniquely in the quantum case, providing a clear trajectory-level signature of quantum effects. These results show that complexity and information measures extracted directly from jump records provide an efficient way to distinguish quantum and classical dynamics in open systems.

</details>


### [115] [Quantum information scrambling in strongly disordered Rydberg spin systems](https://arxiv.org/abs/2512.19856)
*Maximilian Müllenbach,Sebastian Geier,Adrian Braemer,Eduard Braun,Titus Franz,Gerhard Zürn,Matthias Weidemüller,Martin Gärttner*

Main category: quant-ph

TL;DR: 研究长程幂律相互作用自旋系统中的信息扰乱现象，发现与最近邻相互作用系统存在显著差异，并提出基于里德堡光镊的实验方案


<details>
  <summary>Details</summary>
Motivation: 尽管幂律相互作用存在于众多物理系统中，但其多体动力学远不如最近邻相互作用系统被理解。需要研究强无序幂律相互作用自旋系统中的信息扰乱现象

Method: 通过数值计算研究无序时间关联函数（OTOCs）在幂律相互作用系统中的传播，并提出基于里德堡光镊的实验方案，该方案可调节各向异性和可编程无序

Result: 数值模拟显示OTOCs在幂律相互作用和最近邻相互作用系统中的传播存在显著差异，即使对于短程相互作用也是如此，这与通常认为短程相互作用等同于最近邻相互作用的观点相悖

Conclusion: 幂律相互作用系统的信息扰乱动力学与最近邻相互作用系统有本质不同，提出的实验方案为研究这类系统提供了可行途径

Abstract: Despite the fact that power-law interactions occur in a plethora of physical systems, their many-body dynamics is far less understood than that of nearest-neighbor interacting systems. Here, we study information scrambling in strongly disordered spin systems with power-law interactions via out-of-time-order correlators (OTOCs). Numerically, we find pronounced differences in the dynamical spreading of OTOCs between nearest-neighbor and power-law interacting systems. This deviation persists even for short-range interactions, opposing the common view that these interactions produce dynamics equivalent to the nearest-neighbor case. In a detailed experimental proposal, tailored but not limited to Rydberg tweezer setups, we present a protocol to extract OTOCs in XXZ Heisenberg spin systems with tunable anisotropy and programmable disorder based on currently available techniques.

</details>


### [116] [Dissipative quantum algorithms for excited-state quantum chemistry](https://arxiv.org/abs/2512.19870)
*Hao-En Li,Lin Lin*

Main category: quant-ph

TL;DR: 提出一种通用的耗散算法，通过设计量子通道将激发态转化为唯一稳态，实现量子设备上电子激发态的选择性制备。


<details>
  <summary>Details</summary>
Motivation: 电子激发态在物理和化学现象中至关重要，但目前量子设备上准确高效制备激发态的方法仍然具有挑战性且相对较少探索。

Method: 通过修改Lindblad动力学，将激发态制备重新构造为有效的基态问题，使目标激发态成为设计量子通道的唯一稳态。开发了三种互补策略，针对不同类型的先验信息（如对称性和近似能量）。

Result: 通过原子和分子光谱的数值模拟验证了方案的有效性和通用性，包括典型平面共轭分子和过渡金属配合物的价电子激发。

Conclusion: 这些结果为推进现实强关联电子系统的量子模拟方法提供了新途径。

Abstract: Electronic excited states are central to a vast array of physical and chemical phenomena, yet accurate and efficient methods for preparing them on quantum devices remain challenging and comparatively underexplored. We introduce a general dissipative algorithm for selectively preparing ab initio electronic excited states. The key idea is to recast excited-state preparation as an effective ground-state problem by suitably modifying the underlying Lindblad dynamics so that the target excited state becomes the unique steady state of a designed quantum channel. We develop three complementary strategies, tailored to different types of prior information about the excited state, such as symmetry and approximate energy. We demonstrate the effectiveness and versatility of these schemes through numerical simulations of atomic and molecular spectra, including valence excitations in prototypical planar conjugated molecules and transition-metal complexes. Taken together, these results provide a new pathway for advancing quantum simulation methods for realistic strongly correlated electronic systems.

</details>


### [117] [Generalized coherent states in thermal field dynamics in the frame of diagonal ordering operator technique](https://arxiv.org/abs/2512.19880)
*Dušan Popov*

Main category: quant-ph

TL;DR: 该论文展示了热场动力学方法可以扩展到变形玻色子系统，构建了温度相关的相干态，并应用了DOOT技术进行计算。


<details>
  <summary>Details</summary>
Motivation: 热场动力学原本是为具有标准阶梯算符的系统设计的，但作者希望将其扩展到变形玻色子系统，这类系统具有变形算符对，从而扩展TFD方法的适用范围。

Method: 采用对角算符排序技术，这是IWOP技术的推广，适用于与一维谐振子相关的正则算符。构建了温度相关的相干态，包括Barut-Girardello型和Klauder-Perelomov型，这两种类型互为对偶。

Result: 成功将热场动力学方法推广到变形玻色子系统，建立了温度相关相干态的构建方法，并展示了DOOT技术在涉及阶梯算符计算中的应用。

Conclusion: 热场动力学方法可以有效地扩展到变形玻色子系统，为这类系统的热力学性质研究提供了新的理论框架和计算工具。

Abstract: Although the thermofield dynamics (TFD) was developed specifically for systems to which the ladder canonical operators and are associated, in the paper we showed that this approach can also be formulated for systems of deformed bosons, associated with a pair of deformed operators and . In this context we built sets of temperature dependent coherent states, both of the Barut-Girardello and of the Klauder-Perelomov type, these two types being dual to each other. In calculations involving ladder operators, both independent and temperature-dependent, we used the Diagonal Operator Ordering Technique (DOOT), which is a generalization of the Integration Within an Ordered Product technique (IWOP) applicable to canonical operators associated with the one-dimensional harmonic oscillator. We also refer to the connection between TFD and thermodynamic quantities.

</details>


### [118] [Gate-Based Microwave Quantum Repeater Via Grid-State Encoding](https://arxiv.org/abs/2512.19896)
*Hany Khalifa,Matti Silveri*

Main category: quant-ph

TL;DR: 提出基于门控微波量子中继器，利用自主量子纠错延长逻辑玻色子量子比特寿命，实现确定性纠缠生成和全玻色子纠缠交换


<details>
  <summary>Details</summary>
Motivation: 传统量子中继器使用线性分束器进行贝尔态测量，成功率受限于1/2，且存在模式失配损耗。需要开发更高效、确定性的量子中继方案，适用于芯片间安全通信和分布式量子计算。

Method: 采用自主量子纠错的编码玻色子网格态，每个中继站包含一个transmon和两个玻色子谐振器：一个作为使用自主纠错的静态量子存储器，另一个作为纠缠生成的信息总线。通过微波光子波包的成功吸收实现确定性纠缠生成，并使用全玻色子纠缠交换贝尔态测量（通过玻色子控制-Z门和两个独立的X基投影零差测量实现）。

Result: 在静态阻尼率κ_damp^-1=40ms条件下，GBMQR可实现纠缠生成成功率约0.75，纠缠交换成功率约0.58，超过理想线性分束器贝尔态测量的1/2基准。该方案可在当前可用的超导微波技术中实现。

Conclusion: 提出的门控微波量子中继器方案克服了传统分束器方法的概率限制和模式失配问题，通过自主纠错和确定性纠缠生成实现了更高的成功率，适用于芯片间安全通信和分布式量子计算的实际应用。

Abstract: In autonomous quantum error correction the lifetime of a logical bosonic qubit can be extended beyond its physical constituents without feedback measurements. Leveraging autonomous error correction, we propose a second-generation gate-based microwave quantum repeater (GBMQR) with encoded bosonic grid states. Each repeater station comprises a transmon and two bosonic resonators: one resonator serving as a stationary quantum memory utilizing autonomous error correction, and the other as an information bus for entanglement generation. Entanglement is generated sequentially through the successful absorption of a microwave photon wavepacket. This method enables deterministic entanglement generation, in contrast to a probabilistic mixing of two heralding signals on a balanced beamsplitter. Furthermore, our GBMQR employs an all-bosonic entanglement swapping Bell-state measurement. This is implemented via a bosonic controlled-Z gate and two separate X-basis projective homodyne measurements on the stationary stored codewords. Our approach circumvents mode-mismatch losses associated with routing and interfering of heralding modes on a beamsplitter, and confines losses to those arising from stationary storage. We evaluate the performance of the proposed quantum repeater by calculating its secret key rate under realistic lab environments. Moreover, we explicitly demonstrate that at stationary damping rate of $κ^{-1}_{\text{damp}}=$~\SI{40}{\milli\second}, GBMQR can achieve entanglement generation and swapping success probabilities approx.~$0.75$, and $0.58$ respectively, surpassing the hallmark success probability of $1/2$ set by ideal linear beamsplitter-based Bell-state measurements. The proposed device can be implemented using currently available superconducting microwave technology and is suited for secure chip-to-chip communication and distributed quantum computing.

</details>


### [119] [DC-powered broadband quantum-limited microwave amplifier](https://arxiv.org/abs/2512.19902)
*N. Nehra,N. Bourlet,A. H. Esmaeili,B. Monge,F. Cyrenne-Bergeron,A. Paquette,M. Arabmohammadi,A. Rogalle,Y. Lapointe,M. Hofheinz*

Main category: quant-ph

TL;DR: 首次展示直流供电的宽带放大器，在量子极限0.2光子内工作，无需传统参量放大所需的泵浦音基础设施


<details>
  <summary>Details</summary>
Motivation: 超导量子处理器需要量子极限放大器来实现快速、高保真的单次读取，但传统参量放大需要强泵浦音，硬件开销大且严重限制可扩展性

Method: 使用阻抗工程化的非弹性库珀对隧穿放大器（ICTA），这是一种电压偏置的SQUID，库珀对通过发射信号-闲频光子对进行非弹性隧穿，工作在反射模式

Result: 实现了在量子极限0.2光子内工作的宽带放大器，单级提供13 dB平均增益，带宽3.5 GHz，半经典模拟准确预测增益和饱和功率

Conclusion: 通过消除泵浦音基础设施，宽带ICTA有望显著降低超导量子处理器中量子极限放大的硬件复杂度

Abstract: Fast, high-fidelity, single-shot readout of superconducting qubits in quantum processors demands quantum-limited amplifiers to preserve the optimal signal-to-noise ratio. Typically, quantum-limited amplification is achieved with parametric down-conversion of a strong pump tone, which imposes significant hardware overhead and severely limits scalability. Here, we demonstrate the first DC-powered broadband amplifier operating within 0.2 photons of the quantum limit. Our impedance-engineered Inelastic Cooper-pair Tunneling Amplifier (ICTA)-a voltage-biased SQUID in which Cooper pairs tunnel inelastically by emitting signal-idler photon pairs-operates in reflection, delivering 13 dB of average gain across a 3.5 GHz bandwidth in a single stage. Semiclassical simulations accurately predict the gain and saturation power, enabling further design improvements. By eliminating the pump-tone infrastructure, the broadband ICTA promises to dramatically reduce the hardware complexity of quantum-limited amplification in superconducting quantum processors.

</details>


### [120] [Analytical blueprint for 99.999% fidelity X-gates on present superconducting hardware under strong driving](https://arxiv.org/abs/2512.19919)
*José Diogo Da Costa Jesus,Boxi Li,Yuan Gao,Rami Barends,Francisco Andrés Cárdenas-López,Felix Motzoi*

Main category: quant-ph

TL;DR: 该论文提出了一种在强驱动极限下抑制超导量子比特中多光子跃迁误差的方法，通过R1D和R2D技术实现7ns π旋转门保真度低于10⁻⁵。


<details>
  <summary>Details</summary>
Motivation: 在强驱动极限下实现超快量子门需要突破退相干设定的自然限制。目前超导等计算平台尚未实现超越半经典时变模型的单量子比特控制，且传统三能级模型在该极限下失效，导致新的量子误差通道随门时间缩短而急剧增长。

Method: 系统计算计算空间外的多光子跃迁效应，推导抑制这些效应以及量子比特空间振幅和相位误差的解析公式：R1D抑制|0⟩-|2⟩跃迁，R2D同时抑制|1⟩-|3⟩泄漏。还确定了考虑时间顺序时DRAG预因子和恒定失谐的最优值，并展示了如何校准其他预因子以进一步提升性能。

Result: 在考虑现有退相干率的情况下，数值模拟显示7ns π旋转门的保真度低于10⁻⁵。解决了关于DRAG预因子和恒定失谐最优值的长期问题，并提供了进一步性能改进的校准方法。

Conclusion: 通过系统抑制强驱动极限下的多光子跃迁误差，实现了超快量子门的高保真度控制，为超导量子计算平台突破传统门速度限制提供了有效方法。

Abstract: Achieving very fast gates that undercut the natural limits set by decoherence requires going into the strong driving limit. Realizing single-qubit control predicted beyond semi-classical, time-dependent modeling has yet to be experimentally realized on superconducting and most other computing platforms. In this regime, the common model of dynamics within a three-level manifold breaks down, and instead, we see new quantum error channels growing abruptly with decreasing time. To identify these error processes we systematically calculate the effect of multi-photon transitions that occur out of the computational space. We then derive analytical formulas to suppress these effects, as well as amplitude and phase errors on the qubit space; we term these R1D for suppressing the $|0\rangle-|2\rangle$ transition and R2D when also suppressing $|1\rangle-|3\rangle$ leakage. We also answer long-standing questions about the optimal values of the DRAG prefactor as well as constant detuning, when accounting for time-ordering, and also show how to calibrate other prefactors for further performance improvement. Upon correcting these varied sources of error, we numerically demonstrate gate infidelities below $10^{-5}$ for a 7ns $π$-rotation when incorporating existing decoherence rates.

</details>


### [121] [Exploring the nature of gravity with quantum information methods](https://arxiv.org/abs/2512.20429)
*Bruna Sahdo,Natália Salomé Móller*

Main category: quant-ph

TL;DR: 本文介绍了使用量子信息方法研究量子理论与引力界面的基本概念，重点讨论引力诱导纠缠和因果结构两大研究方向。


<details>
  <summary>Details</summary>
Motivation: 为探索量子理论与引力的交叉领域，需要引入量子信息方法。传统方法难以直接检验引力场的量子性质，而量子信息工具提供了新的研究途径。

Method: 首先回顾量子信息理论基础（马赫-曾德尔干涉仪、斯特恩-盖拉赫实验、贝尔不等式、量子电路），然后系统介绍两大研究方向：1) 引力诱导纠缠实验，通过检验两个质量体之间的纠缠来推断引力场是否需要量子化；2) 因果结构研究，通过分析量子系统的因果关系来间接证明时空可能具有非经典行为。

Result: 文章提供了量子信息方法在研究量子引力界面中的系统框架，展示了如何通过量子纠缠和因果结构等概念来探索引力的量子性质，为未来实验设计提供了理论基础。

Conclusion: 量子信息方法为研究量子引力提供了有力工具，引力诱导纠缠和因果结构分析是当前两个有前景的研究方向，有望为理解引力的量子本质提供新的实验证据。

Abstract: The aim of this article is to provide an introduction to the use of quantum information methods for investigating the interface between quantum theory and gravity. To this end, we discuss the basic principles of two current research streams that use this approach. The first one explores a phenomenon known as gravitationally induced entanglement, which aims to infer whether the gravitational field responsible for the interaction between two massive bodies must be quantized or not. The second stream investigates causal structures, thereby providing indirect evidence that spacetime may exhibit non-classical behavior. Before presenting these topics, we briefly review some fundamental concepts and experiments from quantum information theory, such as the Mach-Zehnder interferometer, the Stern-Gerlach experiment, Bell inequalities and entanglement, and the language of quantum circuits.

</details>


### [122] [Nonclassicality of Mixed States with Photon Number Coherence](https://arxiv.org/abs/2512.19953)
*Spencer Rogers,Salman Shahid,Wenchao Ge*

Main category: quant-ph

TL;DR: 本文首次计算了具有光子数相干性的混合态的操作资源理论(ORT)度量，给出了秩二混合态的精确公式和更高秩态的数值解，并比较了这些态的非经典性与计量能力。


<details>
  <summary>Details</summary>
Motivation: ORT度量作为玻色子态的非经典性度量具有资源理论性质和计量学联系，但对于混合态难以计算，特别是具有光子数相干性的混合态。本文旨在解决这一计算难题并探索非经典性与计量能力之间的关系。

Method: 针对具有光子数相干性的混合态，推导了秩二混合态的ORT度量精确解析公式，并对更高秩态提供了数值求解方法。通过比较非经典性与计量能力，研究了ORT界限的饱和条件。

Result: 获得了秩二混合态ORT度量的精确公式和更高秩态的数值解。发现非经典性和计量能力在玻色子退相干下从不增加，但可能像纠缠猝死一样达到平台期。降低光子数相干性有时能产生更具非经典性和计量能力的态。

Conclusion: 本文首次实现了具有光子数相干性的混合态ORT度量计算，揭示了非经典性与计量能力之间的关系，并展示了光子数相干性在资源理论中的复杂作用，为量子计量和资源理论提供了新见解。

Abstract: The operational resource theory (ORT) measure is a nonclassicality measure for bosonic states, notable for its resource-theoretic properties and connection to metrology. However, it can be difficult to evaluate, being linked to an optimization problem for mixed states. Here, we present the first ORT measure calculations for mixed states with photon number coherence. We give exact formulas governing the ORT measure of a broad class of rank-two mixed states, and numerical solutions for some higher-rank states. We also compare the nonclassicality of these states to their metrological power, thus showing in what regimes the metrological power manages to saturate the ORT bound. Throughout, we consider the role of coherence. In particular, we show that nonclassicality and metrological power never increase under bosonic dephasing, but may plateau in a manner similar to entanglement sudden death. Nevertheless, lowering photon number coherence more freely can sometimes yield more nonclassical and metrologically useful states.

</details>


### [123] [Solving Segment Display Problems Using Quantum Grover's Search Algorithm](https://arxiv.org/abs/2512.19969)
*Shanyan Chen,Ali Al-Bayaty,Xiaoyu Song,Marek Perkowski*

Main category: quant-ph

TL;DR: 提出基于布尔逻辑的量子段显示问题(SDP)构建方法，使用Grover量子搜索算法求解，并通过火柴棒问题实例验证


<details>
  <summary>Details</summary>
Motivation: 传统SDP问题通常使用人类推理、启发式搜索、SAT和CSP等方法求解，本文旨在探索量子计算在解决这类问题上的潜力，提出量子化的解决方案

Method: 提出新的布尔逻辑方法构建SDP的量子表示，使用二进制可逆电路构建量子oracle，结合之前提出的step-decreasing结构形状算子(Stesso)，通过Grover算法求解

Result: 使用Qiskit实现的噪声模拟量子计算机，成功实验性地解决了火柴棒问题的SDP实例，验证了方法的可行性

Conclusion: 提出的量子方法为SDP问题提供了新的解决方案，展示了量子计算在解决这类组合优化问题上的潜力，通过实验验证了方法的实用性

Abstract: This paper introduces a new Boolean-based methodology for constructing Segment Display Problems (SDPs) in the quantum domain and solving them using Grover's quantum search algorithm. In the classical domain, the SDPs are typically solved using various techniques, such as human deduction, heuristic search, and methods for solving Boolean satisfiability (SAT) and constraint satisfaction problems (CSPs) that are based on different problem design models. In this paper, our newly introduced methodology proposes a quantum-based approach for solving such SDPs, by building their quantum oracle using binary reversible circuits and our previously proposed step-decreasing structures shaped operators (Stesso). To demonstrate the usability of this proposed method, we experimentally solve an SDP instance of the matchstick problem using Grover's algorithm with a noisy simulated quantum computer implemented in Qiskit.

</details>


### [124] [Real Matrix Representations of Quantum Operators: An Introduction to Quantum Index Algebra](https://arxiv.org/abs/2512.19977)
*A. Yu. Volkov,G. A. Koroteev,Yu. S. Volkov*

Main category: quant-ph

TL;DR: 提出量子索引代数(QIA)作为有限维希尔伯特空间上量子算子的索引代数框架，将算子表示为布尔码索引的结构化组合，通过离散索引规则而非稠密矩阵运算进行计算，并应用于Bernstein-Vazirani隐字符串问题的代数重构。


<details>
  <summary>Details</summary>
Motivation: 传统量子计算使用稠密矩阵运算，但许多量子算法具有结构化特性。本文旨在开发一个有限、基于索引的代数框架，能够统一表示和操作量子算子，分离量子资源与代数组合结构，为理解量子加速的根源提供新视角。

Method: 引入量子索引代数(QIA)：将算子表示为布尔码索引的结构化组合，通过离散索引规则计算乘积、对易子和共轭。使用QIA及其关联的块矩阵实现，在实数有限维代数设置中重新表述Bernstein-Vazirani隐字符串问题的相位预言形式。

Result: 在结构化预言访问下，QIA过程精确重现Bernstein-Vazirani算法，达到与标准量子算法相同的渐近查询复杂度和电路深度。隐藏字符串通过预言稀疏代数表示的符号操作恢复，而非量子振幅的数值模拟。

Conclusion: Bernstein-Vazirani设置中的量子加速源于算子结构而非希尔伯特空间维度本身。QIA为分离真正量子资源与代数组合结构提供了精确语言，为结构化量子电路的可经典模拟性提供了新视角。

Abstract: We introduce Quantum Index Algebra (QIA) as a finite, index-based algebraic framework for representing and manipulating quantum operators on Hilbert spaces of dimension $2^m$. In QIA, operators are expressed as structured combinations of basis elements indexed by Boolean codes, allowing products, commutators, and conjugations to be computed through finite rules on discrete indices rather than through dense matrix arithmetic. This representation unifies combinatorial index structure, explicit matrix realization, and transformation properties under Walsh-Hadamard-type transforms within a single formalism. Using QIA and its associated block-matrix realization, we reformulate the Bernstein-Vazirani hidden-string problem in its phase-oracle form entirely within a real, finite-dimensional algebraic setting. We show that, under structured oracle access, the QIA procedure reproduces the Bernstein-Vazirani algorithm exactly and achieves the same asymptotic query complexity and circuit depth as the standard quantum algorithm. In particular, the hidden string is recovered by symbolic manipulation of a sparse algebraic representation of the oracle rather than by numerical simulation of quantum amplitudes. Our results demonstrate that the apparent quantum speed-up in this setting is a consequence of operator structure rather than Hilbert-space dimensionality alone. QIA thus provides a precise language for separating genuinely quantum resources from those arising from algebraic and combinatorial structures and offers a new perspective on the classical simulability of structured quantum circuits.

</details>


### [125] [Regression of Functions by Quantum Neural Networks Circuits](https://arxiv.org/abs/2512.19978)
*Fernando M. de Paula Neto,Lucas dos Reis Silva,Paulo S. G. de Mattos Neto,Felipe F. Fanchini*

Main category: quant-ph

TL;DR: 提出基于遗传算法的量子神经网络架构自动搜索框架，用于回归任务，发现参数更少的量子电路，在多个基准测试中与经典模型竞争，并通过数据集复杂度指标实现量子架构的元学习选择。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络性能高度依赖架构设计（电路深度、参数门配置、数据编码策略），但手动选择有效架构具有挑战性且计算困难，类似于经典神经网络拓扑选择问题。需要自动化方法来构建高效的量子回归器。

Method: 提出遗传算法框架自动搜索量子电路架构，探索电路深度、参数门配置和灵活的数据重上传模式。将量子回归器构建转化为优化问题，并使用12个结构描述符分析数据集复杂度，在5个元学习场景中预测最佳量子架构。

Result: 在22个非线性基准函数和4个解析函数上评估，发现量子模型参数更少但性能与经典模型竞争。复杂度指标能可靠预测最佳量子架构，多个场景中达到完美或接近完美的预测准确率，表明这些指标能有效指导自动化模型选择。

Conclusion: 为元学习驱动的量子架构设计提供理论基础，增进对量子模型在回归任务中行为的理解，推动量子回归向更系统化、理论更扎实的方向发展。数据集复杂度指标能有效表征数据结构并指导量子架构选择。

Abstract: The performance of quantum neural network models depends strongly on architectural decisions, including circuit depth, placement of parametrized operations, and data-encoding strategies. Selecting an effective architecture is challenging and closely related to the classical difficulty of choosing suitable neural-network topologies, which is computationally hard. This work investigates automated quantum-circuit construction for regression tasks and introduces a genetic-algorithm framework that discovers Reduced Regressor QNN architectures. The approach explores depth, parametrized gate configurations, and flexible data re-uploading patterns, formulating the construction of quantum regressors as an optimization process. The discovered circuits are evaluated against seventeen classical regression models on twenty-two nonlinear benchmark functions and four analytical functions. Although classical methods often achieve comparable results, they typically require far more parameters, whereas the evolved quantum models remain compact while providing competitive performance. We further analyze dataset complexity using twelve structural descriptors and show, across five increasingly challenging meta-learning scenarios, that these measures can reliably predict which quantum architecture will perform best. The results demonstrate perfect or near-perfect predictive accuracy in several scenarios, indicating that complexity metrics offer powerful and compact representations of dataset structure and can effectively guide automated model selection. Overall, this study provides a principled basis for meta-learning-driven quantum architecture design and advances the understanding of how quantum models behave in regression settings--a topic that has received limited exploration in prior work. These findings pave the way for more systematic and theoretically grounded approaches to quantum regression.

</details>


### [126] [Experimental Efficient Source-Independent Quantum Conference Key Agreement](https://arxiv.org/abs/2512.20038)
*Wen-Ji Hua,Yi-Ran Xiao,Yu Bao,Hua-Lei Yin,Zeng-Bing Chen*

Main category: quant-ph

TL;DR: 实验演示了可扩展且高效的源无关量子会议密钥协议，使用偏振纠缠光子对在三用户星型网络中实现GHZ关联，达到2.11×10⁴ bits/s的组密钥率。


<details>
  <summary>Details</summary>
Motivation: 多体纠缠可实现安全的组密钥分发，提供对源设备攻击的免疫力，但先前实验面临效率低和可扩展性限制的技术挑战。

Method: 使用偏振纠缠光子对在三用户星型网络中实现源无关量子会议密钥协议，通过后匹配方法实现GHZ关联。

Result: 在对称信道损耗网络中，单用户信道透射率为1.64×10⁻¹时，达到2.11×10⁴ bits/s的安全组密钥率，并研究了不同信道透射率和随机基选择概率对密钥率的影响。

Conclusion: 为源无关量子会议密钥协议建立了高效途径，展示了未来大规模多用户量子网络的可扩展潜力。

Abstract: Multipartite entanglement enables secure group key distribution among multiple users while providing immunity against hacking attacks targeting source devices, thereby realizing source-independent quantum conference key agreement (SI-QCKA). However, previous experimental demonstrations of SI-QCKA have encountered substantial technical challenges, primarily due to the low efficiency and scalability limitations inherent in the generation and distribution of multipartite entanglement. Here, we experimentally demonstrate a scalable and efficient SI-QCKA protocol using polarization-entangled photon pairs in a three-user star network, where Greenberger-Horne-Zeilinger correlations are realized via a post-matching method. We achieve a secure group key rate of $2.11 \times 10^{4}$ bits/s under the single-user channel transmission of 1.64 $\times$ $10^{-1}$ in a symmetric channel loss network. Additionally, we conduct six sets of experiments to investigate the impact of varying channel transmission and random basis selection probabilities on secure key rates. Our work establishes an efficient pathway for SI-QCKA and demonstrates potential scalability for future large-scale multi-user quantum networks.

</details>


### [127] [$\mathscr{H}_2$ Model Reduction for Augmented Model of Linear Non-Markovian Quantum Systems](https://arxiv.org/abs/2512.20040)
*Guangpu Wu,Shibei Xue,Guofeng Zhang,Rebing Wu,Min Jiang,Ian R. Petersen*

Main category: quant-ph

TL;DR: 提出了一种用于线性非马尔可夫量子系统增强模型的H₂模型降阶方法，解决了因大量环境内部模式导致的计算负担问题。


<details>
  <summary>Details</summary>
Motivation: 增强系统模型能有效建模非马尔可夫量子系统，但由于大量代表环境内部模式的量子振荡器直接与主系统相互作用，导致系统维度巨大，给滤波器和控制器设计带来显著计算负担。

Method: 首先建立线性非马尔可夫量子系统增强模型物理可实现性的充要条件；然后推导降阶模型中输入矩阵的必要条件，证明降阶系统辅助系统矩阵设计定理；将非线性等式约束转化为不等式约束，开发半定规划算法求解模型降阶优化问题。

Result: 通过一个由非马尔可夫环境三个内部模式驱动的双模线性量子系统的数值算例，验证了所提方法的有效性。

Conclusion: 该方法成功解决了非马尔可夫量子系统增强模型的模型降阶问题，克服了物理可实现性条件带来的非凸约束挑战，为这类系统的滤波和控制设计提供了计算高效的解决方案。

Abstract: An augmented system model provides an effective way to model non-Markovian quantum systems, which is useful in filtering and control for this class of systems. However, since a large number of ancillary quantum oscillators representing internal modes of a non-Markovian environment directly interact with the principal system in these models, the dimension of the augmented system may be very large causing significant computational burden in designing filters and controllers. In this context, this paper proposes an $\mathscr{H}_2$ model reduction method for the augmented model of linear non-Markovian quantum systems. We first establish necessary and sufficient conditions for the physical realizability of the augmented model of linear non-Markovian quantum systems, which are more stringent than those for Markovian quantum systems. However, these physical realizability conditions of augmented system model pose non-convex constrains in the optimization problem of model reduction, which makes the problem different from the corresponding classical model reduction problem. To solve the problem, we derive necessary conditions for determining the input matrix in the reduced model, with which a theorem for designing the system matrix of the ancillary system in the reduced system is proved. Building on this, we convert the nonlinear equality constraints into inequality constraints so that a semidefinite programming algorithm can be developed to solve the optimization problem for model reduction.
  A numerical example of a two-mode linear quantum system driven by three internal modes of a non-Markovian environment validates the effectiveness of our method.

</details>


### [128] [Markov Chain Model of Entanglement Setup in Noisy Dynamic LEO Satellite Networks](https://arxiv.org/abs/2512.20047)
*Yifan Gao,Alvin Valera,Winston K. G. Seah*

Main category: quant-ph

TL;DR: 该论文提出了一个用于分析动态LEO卫星量子网络中纠缠分布的马尔可夫链模型，考虑了链路存储时间和物理距离，推导了关键性能指标，并揭示了请求率与纠缠保真度之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 动态LEO卫星网络中的量子纠缠路由对于实现可扩展、高保真度的量子通信至关重要，但卫星网络拓扑的动态特性、有限的量子资源以及严格的相干时间约束给可靠的纠缠路由带来了重大挑战。需要建立适合这种独特环境的纠缠分布分析模型来支持纠缠路由研究。

Method: 提出了一个全面的马尔可夫链模型，状态空间由链路存储时间和物理距离定义，用于分析噪声动态LEO卫星量子网络中的纠缠分布。构建了捕捉不同请求到达率下系统动态的转移矩阵，并推导了关键性能指标的分析表达式。

Result: 分析揭示了关键权衡：较高请求率导致更快的链路消耗和更高保真度，但可能降低满意度；较低请求率允许更长的存储时间，但代价是退相干效应导致的保真度降低。此外，证明了在传输距离很短（40-50公里）时忽略偏振旋转是合理的。

Conclusion: 这项工作为设计和优化卫星网络中的量子纠缠分布策略提供了理论基础，可应用于全球规模的量子通信。

Abstract: Quantum entanglement routing in dynamic Low Earth Orbit (LEO) satellite networks is important for achieving scalable and high-fidelity quantum communication. However, the dynamic characteristics of satellite network topology, limited quantum resources, and strict coherence time constraints pose significant challenges to reliable entanglement routing. An entanglement distribution analysis model for this unique environment is critical and helpful for entanglement routing research. We address the fundamental challenge of establishing and maintaining quantum entanglement links between satellites operating in free space, where links are subject to both transmission losses and quantum memory decoherence. This paper presents a comprehensive Markov chain model with a state space defined by link storage age and physical distance for analyzing entanglement distribution in noisy dynamic LEO satellite quantum networks. We construct transition matrices that capture system dynamics under varying request arrival rates, and derive analytical expressions for key performance metrics, including request satisfaction rate, average waiting time, link utilization efficiency, and average consumed link fidelity. Our analysis reveals that the critical trade-offs of higher request rates lead to faster link consumption with higher fidelity but potentially lower satisfaction rates, while lower request rates allow longer storage times at the cost of lower fidelity of increased decoherence effect. Moreover, this paper proves it is reasonable to leave out polarization rotation when the transmission distance is very short (40-50 km). In summary, this work provides theoretical foundations for designing and optimizing quantum entanglement distribution strategies in satellite networks, with applications to global-scale quantum communications.

</details>


### [129] [Fault Injection Attacks on Machine Learning-based Quantum Computer Readout Error Correction](https://arxiv.org/abs/2512.20077)
*Anthony Etim,Jakub Szefer*

Main category: quant-ph

TL;DR: 首次分析量子计算系统中机器学习分类器对物理故障注入的脆弱性，发现通过电压毛刺可导致量子比特读取错误，且故障易感性具有层依赖性。


<details>
  <summary>Details</summary>
Motivation: 机器学习分类器在量子计算系统中被广泛用于多量子比特读取判别和读取错误缓解，但尚未有人研究这些ML模型对物理故障注入的脆弱性。随着ML成为量子计算机控制和读取堆栈的关键组件，了解其安全风险至关重要。

Method: 使用ChipWhisperer Husky进行物理电压毛刺注入，开发自动化算法扫描故障注入参数搜索空间，针对5量子比特（32类）读取错误校正模型，在ML模型的所有层中寻找成功故障。

Result: 故障易感性具有强烈的层依赖性：早期层故障触发时误预测率更高，后期层误预测率较小。单次毛刺可导致结构化读取损坏而非纯随机噪声，通过汉明距离和每比特翻转统计表征读取失败。

Conclusion: 量子计算机中基于ML的读取和读取校正应被视为安全关键组件，需要在量子计算机读取管道中实施轻量级、部署友好的故障检测和冗余机制。

Abstract: Machine-learning (ML) classifiers are increasingly used in quantum computing systems to improve multi-qubit readout discrimination and to mitigate correlated readout errors. These ML classifiers are an integral component of today's quantum computer's control and readout stacks. This paper is the first to analyze the susceptibility of such ML classifiers to physical fault-injection which can result in generation of incorrect readout results from quantum computers. The study targets 5-qubit (thus 32-class) readout error-correction model. Using the ChipWhisperer Husky for physical voltage glitching, this work leverages an automated algorithm for scanning the fault injection parameter search space to find various successful faults in all the layers of the target ML model. Across repeated trials, this work finds that fault susceptibility is strongly layer-dependent: early-layers demonstrate higher rates of misprediction when faults are triggered in them, whereas later layers have smaller misprediction rates. This work further characterizes the resulting readout failures at the bitstring level using Hamming-distance and per-bit flip statistics, showing that single-shot glitches can induce structured readout corruption rather than purely random noise. These results motivate treating ML-based quantum computer readout and readout correction as a security-critical component of quantum systems and highlight the need for lightweight, deployment-friendly fault detection and redundancy mechanisms in the quantum computer readout pipelines.

</details>


### [130] [Force Sensing Beyond the Standard Quantum Limit in a Hybrid Optomechanical Platform](https://arxiv.org/abs/2512.20081)
*Alolika Roy,Amarendra K. Sarma*

Main category: quant-ph

TL;DR: 该理论研究混合光机械系统中的量子测量噪声，通过量子点响应和光学参量放大器实现相干量子噪声消除，突破标准量子极限，提升弱力传感灵敏度。


<details>
  <summary>Details</summary>
Motivation: 研究量子测量噪声对力传感的影响，特别是在光机械系统中辐射压力反作用噪声限制了力测量灵敏度。需要探索如何通过量子效应和系统非线性来消除反作用噪声，突破标准量子极限。

Method: 构建包含可移动镜面、固定半透射镜面、量子点系综和腔内光学参量放大器的混合光机械系统。理论分析量子点诱导响应与系统非线性如何改变噪声谱密度，研究相干量子噪声消除机制和OPA泵浦增益对灵敏度的影响。

Result: 量子点响应与系统非线性能够修改噪声谱密度，提高力测量灵敏度。相干量子噪声消除可以完全移除反作用噪声。增加OPA泵浦增益可以在降低激光功率的情况下实现超越标准量子极限的灵敏度。这些效应共同实现了超越SQL的弱力传感。

Conclusion: 混合光机械系统通过量子点响应、系统非线性和光学参量放大器的协同作用，能够有效消除量子测量噪声，实现超越标准量子极限的弱力传感，为高精度量子测量提供了新途径。

Abstract: We theoretically investigate quantum measurement noise in a hybrid optomechanical system, focusing on radiation pressure back action and its impact on force sensing. The setup consists of an optomechanical cavity with a movable mirror, a fixed semi transparent mirror, an ensemble of quantum dots (QD) coupled to the cavity mode, and an intracavity optical parametric amplifier (OPA). We show how the QD induced response, together with the system nonlinearity, modifies the noise spectral density and thereby improves the force measurement sensitivity. In this setup, coherent quantum noise cancellation (CQNC) can completely remove the back action noise. In addition, increasing the OPA pump gain enables sensitivity beyond the standard quantum limit (SQL) at reduced laser power. These combined effects allow weak force sensing beyond the SQL.

</details>


### [131] [Precision Bounds for Characterising Quantum Measurements](https://arxiv.org/abs/2512.20091)
*Aritra Das,Simon K. Yung,Lorcan O. Conlon,Ozlem Erkilic,Angus Walsh,Yong-Su Kim,Ping K. Lam,Syed M. Assad,Jie Zhao*

Main category: quant-ph

TL;DR: 论文提出了一个用于高效探测器估计的框架，引入了探测器量子费舍尔信息的概念，解决了量子测量表征的难题，完善了量子信息处理中状态、过程和探测器估计的三元体系。


<details>
  <summary>Details</summary>
Motivation: 量子测量与量子状态和过程一样，是量子信息处理的基石，但相比状态和过程，其高效表征方法仍相对未被充分探索。目前存在状态估计与探测器估计之间的不对称性，需要建立一个系统的探测器估计框架。

Method: 引入了一个全面的高效探测器估计框架，提出了"探测器量子费舍尔信息"的概念，该框架消除了优化最佳探针状态的需求，同时突出了探测器分析与量子状态估计的根本差异。

Result: 通过理论证明、实例分析和实验验证，展示了该框架在当前量子探测器技术中的相关性和鲁棒性。该框架形式化了与状态估计对偶的视角，完善了量子信息理论。

Conclusion: 该研究完成了高效状态、过程和探测器层析成像的三元体系，推进了量子信息理论，并对依赖精确校准测量的新兴技术具有更广泛的意义。

Abstract: Quantum measurements, alongside quantum states and processes, form a cornerstone of quantum information processing. However, unlike states and processes, their efficient characterisation remains relatively unexplored. We resolve this asymmetry by introducing a comprehensive framework for efficient detector estimation that reveals the fundamental limits to extractable parameter information and errors arising in detector analysis - the \emph{detector quantum Fisher information}. Our development eliminates the need to optimise for the best probe state, while highlighting aspects of detector analysis that fundamentally differ from quantum state estimation. Through proofs, examples and experimental validation, we demonstrate the relevance and robustness of our proposal for current quantum detector technologies. By formalising a dual perspective to state estimation, our framework completes and connects the triad of efficient state, process, and detector tomography, advancing quantum information theory with broader implications for emerging technologies reliant on precisely calibrated measurements.

</details>


### [132] [Finite-size Effects on The Edge Loss Probability in Non-Hermitian Quantum Walks](https://arxiv.org/abs/2512.20106)
*Shuaixian Liu,Yulan Dong,Bowen Zeng,Mengqiu Long*

Main category: quant-ph

TL;DR: 该论文研究了有限尺寸量子行走中的体-边关系，发现边界散射会抑制边缘爆发，而虚能隙打开与非厄米趋肤效应也能诱导边缘大损耗概率。


<details>
  <summary>Details</summary>
Motivation: 先前研究在无限极限下证明了量子行走中体损耗概率的幂律依赖与边缘概率峰值的关系，源于虚能隙闭合和非厄米趋肤效应。但在有限尺寸系统中，边界效应的影响尚不清楚。

Method: 研究有限尺寸量子行走链，分析边界散射对边缘爆发的影响，并探讨虚能隙打开与非厄米趋肤效应在诱导边缘大损耗概率中的作用。

Result: 发现边界散射会抑制边缘爆发现象，同时虚能隙打开与非厄米趋肤效应也能导致边缘出现大损耗概率，揭示了有限尺寸量子动力学的新特征。

Conclusion: 研究结果为有限尺寸量子动力学提供了新见解，表明边界效应和非厄米特性在量子行走中的重要作用，对理解有限量子系统的动力学行为具有重要意义。

Abstract: A dynamical bulk-edge relation in quantum walks has been theoretically proposed and experimentally observed, in which a power-law dependence of the bulk loss probability is associated with a pronounced peak of loss probability at the edge. This behavior has been proven to arise from imaginary gap closing and the non-Hermitian skin effect in the infinite limit without boundary effects. However, in a finite-size chain, we find that boundary scattering can suppress this edge burst. Meanwhile, imaginary gap opening together with the non-Hermitian skin effect, can also induce a large loss probability at the edge. Our results provide insights into finite-size quantum dynamics.

</details>


### [133] [Optimal control of population transfer in multi-level systems by dynamical quantum geometric tensor](https://arxiv.org/abs/2512.20131)
*Guan-Qiang Li,Yu-Qi Zhang,Hao Guo,You-Jiao Dong,Zhi-Yu Lin,Ping Peng*

Main category: quant-ph

TL;DR: 该研究从量子几何角度优化多能级系统的粒子数转移控制，基于动力学量子几何张量优化STIRAP方案，在三能级和四能级系统中实现高效转移和叠加态制备。


<details>
  <summary>Details</summary>
Motivation: 传统STIRAP方案在粒子数转移效率上有限（约72%），需要更快速高效的量子控制方法。量子几何理论为优化多能级系统的粒子数转移提供了新视角。

Method: 基于动力学量子几何张量优化STIRAP方案，计算三能级Λ型和四能级三脚架型系统的量子几何张量和非绝热跃迁速率，分析系统参数对转移过程的影响。

Result: 优化STIRAP方案在三能级系统中转移效率超过98%（传统为72%），四能级系统可高效制备任意比例的叠加态。在共振窗口选择脉冲参数可使转移保真度低于10^{-3}。

Conclusion: 基于动力学量子几何张量的优化STIRAP方案比传统方案更快速高效，揭示了绝热共振转移现象，为多能级系统的量子控制提供了有效方法。

Abstract: The optimal control of population transfer for multi-level systems is investigated from the perspective of quantum geometry. Firstly, the general theoretical framework of optimizing the stimulated Raman adiabatic passage (STIRAP) scheme based on the dynamical quantum geometric tensor is given, and then the dynamical quantum geometric tensor and the nonadiabatic transition rate are calculated by taking the detuned $Λ$-type three-level system and tripod-type four-level system for example. Secondly, the transfer dynamics of the particle population of the system are investigated in detail. For a three-level system, the optimal STIRAP scheme has an efficiency of over 98\% in transferring the population to the final state, while the transfer efficiency of traditional STIRAP is about 72\%. The superposition states with arbitrary proportions can be efficiently prepared for a four-level system due to the decoupling of the degenerate dark states. Finally, the influences of system parameters, such as the operation time of the Rabi pulses, the amplitude fluctuation and the single-photon detuning, on the transfer process are discussed. Especially, the phenomenon of the adiabatic resonance transfer is revealed. Choosing the pulse parameters in the resonance window can reduce the infidelity of the population transfer to below $10^{-3}$. It is found that the optimal STIRAP scheme by the dynamical quantum geometric tensor provides faster and more efficient transfer than the traditional STIRAP scheme.

</details>


### [134] [On the mixed UDA states and additivity](https://arxiv.org/abs/2512.20133)
*Xinyu Qiu,Lin Chen,Genwei Li,Delin Chu*

Main category: quant-ph

TL;DR: 本文研究了多体混合态被其k-部约化密度矩阵唯一确定(UDA)的条件，特别关注k=2的实用情况，建立了系统判定方法并完全刻画了UDA双体和三量子比特乘积态的可加性。


<details>
  <summary>Details</summary>
Motivation: 量子层析中，能够被局部信息唯一确定的混合态(UDA态)对于高效量子态重构至关重要。研究多体混合态被其k-部约化密度矩阵唯一确定的条件，可以最小化所需局部信息，具有实际应用价值。

Method: 提出了多体混合态被其k-部约化密度矩阵唯一确定(UDA)的充要条件，特别关注k=2的情况。建立了系统判定UDA态的方法，并完全刻画了UDA双体和三量子比特乘积态的可加性。

Result: 获得了多体混合态UDA的充要条件，建立了系统判定方法，完全刻画了UDA双体和三量子比特乘积态的可加性，并展示了混合UDA态在层析和其他任务中的应用。

Conclusion: 本文为多体混合态的UDA特性提供了理论基础和实用工具，特别在k=2时具有最小局部信息需求的优势，为高效量子层析和其他量子信息任务提供了重要资源。

Abstract: Mixed states that are uniquely determined among all (UDA) states are vital in efficient quantum tomography. We show the necessary and sufficient conditions by which some multipartite mixed states are UDA by their $k$-partite reduced density matrices. The case for $k=2$ is mostly studied, which requires minimal local information and shows practical benefits. Based on that, we establish a systematic method for determining UDA states and provide a complete characterization of the additivity of UDA bipartite and three-qubit product states. We show the application of mixed UDA states and their characterization from the perspectives of tomography and other tasks.

</details>


### [135] [Highly Tunable Two-Qubit Interactions in Si/SiGe Quantum Dots by Interchanging the Roles of Qubit-Defining Gates](https://arxiv.org/abs/2512.20142)
*Jaemin Park,Hyeongyu Jang,Hanseo Sohn,Younguk Song,Lucas E. A. Stehouwer,Davide Degli Esposti,Giordano Scappucci,Dohun Kim*

Main category: quant-ph

TL;DR: 硅量子点自旋量子比特通过交换重叠纳米栅极角色，显著提高交换耦合可调性，减少意外单量子位相移，简化多量子位控制


<details>
  <summary>Details</summary>
Motivation: Si/SiGe异质结构中的SiGe间隔层在量子比特与控制电极之间形成间隙，限制了交换耦合的调节能力，导致残余耦合引起意外单量子位相移，使多量子位控制更加困难

Method: 通过交换重叠纳米栅极的角色，重新配置栅极电压，实现原位角色切换，同时保持多量子位控制能力

Result: 该方法将交换耦合的可调性提高了几个数量级，显著减少了意外单量子位相移，并最小化了多量子位控制的复杂性

Conclusion: 这种策略通过最小化实验开销支持可扩展增长，为硅量子点自旋量子比特的实用化提供了有效解决方案

Abstract: Silicon quantum dot spin qubits have become a promising platform for scalable quantum computing because of their small size and compatibility with industrial semiconductor manufacturing processes. Although Si/SiGe heterostructures are commonly used to host spin qubits due to their high mobility and low percolation density, the SiGe spacer creates a gap between the qubits and control electrodes, which limits the ability to tune exchange coupling. As a result, residual coupling leads to unwanted single-qubit phase shifts, making multi-qubit control more difficult. In this work, we explore swapping the roles of overlapping nanogates to overcome this issue. By reconfiguring the gate voltages, we demonstrate in situ role switching while maintaining multi-qubit control. Additionally, this method significantly improves the tunability of exchange coupling by several orders of magnitude over the traditional approach. This strategy reduces unintended single-qubit phase shifts and minimizes the complexity of multi-qubit control, supporting scalable growth with minimal experimental overhead.

</details>


### [136] [Disorder-induced broadening of quantum momentum distribution](https://arxiv.org/abs/2512.20170)
*Vili Heinonen,Jani Lukkarinen*

Main category: quant-ph

TL;DR: 研究二维量子气体在长程关联随机势中的长时间行为，发现初始动量分布会变得各向同性并展宽，推导了动量分布的长时间平均表达式并通过模拟验证。


<details>
  <summary>Details</summary>
Motivation: 研究非相互作用二维量子气体在具有长程关联的弱随机势中的长时间动力学行为，特别是动量分布如何随时间演化。

Method: 理论推导动量分布的长时间平均表达式，并通过计算机模拟进行验证，同时讨论动量各向同性和空间扩散过程。

Result: 任何峰值的初始动量分布最终都会变得各向同性并展宽，理论推导的表达式与计算机模拟结果一致，阐明了动量各向同化机制。

Conclusion: 在长程关联随机势中，二维量子气体的动量分布会经历各向同化和展宽过程，理论模型能够准确描述这一长时间行为。

Abstract: We study the long-time behavior of a non-interacting two-dimensional quantum gas in a weak random potential with long-range correlations. Any peaked initial momentum distribution will eventually become isotropic and broaden due to scattering events with the random potential. We derive an expression for the long-time average of the momentum distribution and test it against computer simulations. We also discuss momentum isotropization and spatial diffusion.

</details>


### [137] [Network-based prediction of drug combinations with quantum annealing](https://arxiv.org/abs/2512.20199)
*Diogo Ramos,Bruno Coutinho,Duarte Magano*

Main category: quant-ph

TL;DR: 提出基于量子退火的算法，利用"互补暴露"原理在疾病模块中寻找有效的药物组合


<details>
  <summary>Details</summary>
Motivation: 药物组合的系统性发现面临组合爆炸的挑战，网络医学为理解疾病机制和药物作用提供了新范式

Method: 将"互补暴露"原理转化为二次无约束二进制优化问题，使用量子退火算法求解

Result: 在糖尿病、类风湿关节炎、哮喘和脑肿瘤等疾病上测试，低能态配置与生物学上合理的组合一致

Conclusion: 量子退火算法能够生成新颖的药物组合预测，为药物发现提供新方法

Abstract: The systematic discovery of effective drug combinations is a challenging problem in modern pharmacology, driven by the combinatorial growth of potential pairings and dosage configurations. Network medicine, modeling diseases and drugs as interconnected modules of the human protein-protein interactome, has emerged as a new paradigm for understanding disease mechanisms and drug action. In this work, we propose a quantum annealing-based algorithm for identifying effective drug combinations. Underlying our approach is the biologically motivated principle of `Complementary Exposure', which posits that therapeutic drug combinations target distinct yet complementary regions of a disease module. We translate this into a quadratic unconstrained binary optimisation problem. We test our method for Diabetes Mellitus, Rheumatoid Arthritis, Asthma, and Brain Neoplasms, relying on experimentally validated drug combinations for these diseases. Our simulated quantum annealing experiments reveal that low-energy configurations align with biologically plausible combinations, demonstrating the algorithm's ability to generate novel predictions for drug combinations.

</details>


### [138] [Waveguide-integrated colour centres in silicon carbide with broadband photonic crystal reflectors for efficient readout](https://arxiv.org/abs/2512.20200)
*Marcel Krumrein,Julian M. Bopp,Timo Steidl,Wolfgang Knolle,Jawad Ul-Hassan,Vadim Vorobyov,Tim Schröder,Jörg Wrachtrup*

Main category: quant-ph

TL;DR: 在4H碳化硅中设计并制造了带有高效恐龙光子晶体反射器的波导结构，用于增强自旋活性色心的光子计数率，实现了宽带反射和约125 kcps的计数率，理论上可实现超过98%保真度的光学单次读出。


<details>
  <summary>Details</summary>
Motivation: 4H碳化硅中的自旋活性色心是量子信息应用的有前景的构建模块，但需要在低温下集成到纳米光子结构中以提高光子计数率。

Method: 设计并制造了带有高效恐龙光子晶体反射器的波导结构，将色心集成到这些结构中，在低温条件下通过锥形波导-锥形光纤接口收集发射，并使用电荷共振检查测量方案提高计数率。

Result: 器件在60 THz范围内显示出宽带反射，峰值反射率超过80%。标准PLE测量的饱和强度约为104 kcps，通过电荷共振检查测量方案可进一步提高到约125 kcps。理论上这些计数率可实现超过98%保真度的光学单次读出。

Conclusion: 研制的带有恐龙光子晶体反射器的波导结构成功增强了4H碳化硅色心的光子计数率，为实现高保真度光学单次读出的量子信息应用奠定了基础，尽管发射器的光谱稳定性在高激发功率下仍需进一步改进。

Abstract: Spin-active colour centres in 4H silicon carbide are promising candidates as building blocks for quantum information applications. To increase the photon count rate of the emitters at low temperatures, the colour centres must be integrated into nanophotonic structures and characterised under cryogenic conditions. Here, we design and fabricate waveguide structures attached with an efficient Dinosaur photonic crystal reflector at one side. The devices show broadband reflection over a range of 60 THz with a peak reflectance above 80 %. Additionally, colour centres were integrated into these structures and characterised at cryogenic conditions. The emission was collected by a tapered-waveguide-tapered-fibre interface. Although the spectral stability of the emitters must be further improved for high excitation powers, the saturation intensity in standard PLE measurements is about 104 kcps. The count rate can be further improved to about 125 kcps with a charge-resonance check measurement scheme. To highlight the relevance of our devices, we theoretically show that these count rates enable optical single-shot readout with a fidelity exceeding 98 %.

</details>


### [139] [Perfect quantum state transfer in a dispersion-engineered waveguide](https://arxiv.org/abs/2512.20212)
*Zeyu Kuang,Oliver Diekmann,Lorenz Fischer,Stefan Rotter,Carlos Gonzalez-Ballestero*

Main category: quant-ph

TL;DR: 通过设计波导的色散关系，使一个量子比特发射的光子脉冲被被动地重塑为其时间反演版本，从而实现完美吸收和高效量子态传输。


<details>
  <summary>Details</summary>
Motivation: 高保真量子态传输受到时间反演对称性的根本限制：一个量子比特以特定时间脉冲形状发射光子，而第二个量子比特需要时间反演的脉冲形状才能有效吸收。传统方法通常需要引入主动元件来克服这一限制。

Method: 通过定制波导的色散关系，使量子比特发射的光子脉冲被动地重塑为其时间反演对应物。解析推导了小和大量子比特间距下的最优色散关系，并通过多参数优化将结果扩展到任意间距。还提出了空间不均匀波导设计，使态传输对量子比特间距变化具有鲁棒性。

Result: 在所有情况下都获得了接近完美的传输保真度（≥98%）。色散工程波导为片上量子网络提供了一种紧凑且被动的解决方案。

Conclusion: 色散工程波导提供了一种紧凑、被动的片上量子网络实现途径，突显了工程化色散作为波导量子电动力学中的强大资源。

Abstract: High-fidelity state transfer is fundamentally limited by time-reversal symmetry: one qubit emits a photon with a certain temporal pulse shape, whereas a second qubit requires the time-reversed pulse shape to efficiently absorb this photon. This limit is often overcome by introducing active elements. Here, we propose an alternative solution: by tailoring the dispersion relation of a waveguide, the photon pulse emitted by one qubit is passively reshaped into its time-reversed counterpart, thus enabling perfect absorption. We analytically derive the optimal dispersion relations in the limit of small and large qubit-qubit separations, and numerically extend our results to arbitrary separations via multiparameter optimization. We further propose a spatially inhomogeneous waveguide that renders the state transfer robust to variations in qubit separations. In all cases, we obtain near-unity transfer fidelity (>= 98%). Our dispersion-engineered waveguide provides a compact and passive route toward on-chip quantum networks, highlighting engineered dispersion as a powerful resource in waveguide quantum electrodynamics.

</details>


### [140] [Tree tensor network states represent low-energy states faithfully](https://arxiv.org/abs/2512.20215)
*Thomas Barthel*

Main category: quant-ph

TL;DR: TTNS近似误差可通过目标态的Schmidt谱或Rényi纠缠熵界定，反之可得实现特定精度所需的键维数。对于树格，若单分支切割的α<1 Rényi纠缠熵满足面积律，则存在高效TTNS近似。


<details>
  <summary>Details</summary>
Motivation: 扩展矩阵乘积态的相关结果，研究树张量网络态的近似误差界限问题，建立近似精度与纠缠熵之间的定量关系。

Method: 利用Schmidt谱或Rényi纠缠熵来界定树张量网络态的近似误差，推导实现特定精度所需的键维数界限。

Result: 建立了TTNS近似误差与目标态纠缠特性之间的数学关系，证明了对于树格，若α<1 Rényi纠缠熵满足面积律，则存在高效的TTNS近似。

Conclusion: 该研究为树张量网络态的近似能力提供了理论保证，特别适用于满足面积律纠缠熵的基态和低能态系统。

Abstract: Extending corresponding results for matrix product states [Verstraete and Cirac, PRB 73, 094423 (2006); Schuch et al. PRL 100, 030504 (2008)], it is shown how the approximation error of tree tensor network states (TTNS) can be bounded using Schmidt spectra or Rényi entanglement entropies of the target quantum state. Conversely, one obtains bounds on TTNS bond dimensions needed to achieve a specific approximation accuracy. For tree lattices, the result implies that efficient TTNS approximations exist if $α<1$ Rényi entanglement entropies for single-branch cuts obey an area law, as in ground and low-energy states of certain gapped systems.

</details>


### [141] [A resource-efficient and noise-robust entanglement witness based on the swap test](https://arxiv.org/abs/2512.20235)
*Sebastiano Guaraldo,Sonia Mazzucchi,Alessio Baldazzi,Stefano Azzini,Lorenzo Pavesi*

Main category: quant-ph

TL;DR: 提出一种基于SWAP测试的纠缠见证方法，适用于任意两量子比特态，能提供concurrence下界，资源高效、抗噪声、平台无关


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子技术的关键资源，需要高效可靠的检测和量化工具。现有方法在资源效率、噪声鲁棒性和平台通用性方面存在局限

Method: 基于受控SWAP测试设计纠缠见证，适用于任意两量子比特态（纯态和混合态）。方法使用线性光学组件在室温光子芯片上实现

Result: 成功在室温光子芯片上验证了该方法，分析了光子硬件噪声下的鲁棒性，建立了简单可靠的纠缠见证工具

Conclusion: 提出的SWAP基纠缠见证方法为量子纠缠检测提供了资源高效、抗噪声、平台无关的实用工具，具有广泛的应用前景

Abstract: Quantum entanglement is an essential resource for quantum technologies, and the controlled swap test provides a versatile tool for its detection and quantification. Here, we propose a SWAP-based entanglement witness that applies to arbitrary two-qubit states - both pure and mixed - and provides a lower bound on the concurrence. The method is resource-efficient, robust to noise, and platform-independent. As an example, we validate the approach on a room-temperature photonic chip, where the swap test is carried out using only linear and well-established integrated optical components. The robustness of the method against photonic-hardware noise is also analysed. Our results establish a simple and reliable tool for entanglement witnessing.

</details>


### [142] [Quantum Geometric Tensor in the Wild: Resolving Stokes Phenomena via Floquet-Monodromy Spectroscopy](https://arxiv.org/abs/2512.20253)
*Prasoon Saurabh*

Main category: quant-ph

TL;DR: 传统拓扑不变量（如陈数、贝里相位）在开放、驱动和非厄米系统中的本质奇点处完全失效，作者提出Floquet-Monodromy Spectroscopy实验协议来提取Stokes现象，将奇点的Stokes乘子映射到时域可观测量，为超越传统拓扑的物质相分类提供新的量子数。


<details>
  <summary>Details</summary>
Motivation: 标准拓扑不变量框架在开放、驱动和非厄米系统（"Wild"区域）中遇到本质奇点时发生灾难性失败，局部几何张量发散导致标准不变量无定义，微扰预测与实际情况偏差达100%。需要新的理论框架和实验方法来处理这些奇点并提取隐藏的几何信息。

Method: 提出Floquet-Monodromy Spectroscopy（FMS）协议，这是一种脉冲级控制序列，通过实验提取Stokes现象——完成拓扑描述所需的"缺失"几何数据。将奇点的Stokes乘子映射到时域可观测量，为Resurgence理论提供严格的实验桥梁，允许从发散渐近级数精确重建非微扰物理。

Result: 在超导qudit模型上验证了该框架，证明"Stokes不变量"可作为下一代量子数，用于分类超出传统拓扑范围的物质相。FMS协议成功提取了隐藏的Stokes现象，为处理本质奇点提供了实验解决方案。

Conclusion: 传统拓扑不变量在本质奇点存在时完全失效，需要新的分类框架。FMS协议通过实验提取Stokes现象，将Resurgence理论与实验观测连接起来，Stokes不变量成为超越传统拓扑的物质相分类的新量子数，为解决开放、驱动和非厄米系统中的拓扑问题提供了新途径。

Abstract: Standard topological invariants, such as the Chern number and Berry phase, form the bedrock of modern quantum matter classification. However, we demonstrate that this framework undergoes a \textbf{catastrophic failure} in the presence of essential singularities -- ubiquitous in open, driven, and non-Hermitian systems ("Wild" regime). In these settings, the local geometric tensor diverges, rendering standard invariants ill-defined and causing perturbative predictions to deviate from reality by order unity ($\sim 100\%$). We resolve this crisis by introducing the \textbf{Floquet-Monodromy Spectroscopy (FMS)} protocol, a pulse-level control sequence, which experimentally extracts the hidden \textit{Stokes Phenomenon} -- the "missing" geometric data that completes the topological description. By mapping the singularity's Stokes multipliers to time-domain observables, FMS provides a rigorous experimental bridge to \textbf{Resurgence Theory}, allowing for the exact reconstruction of non-perturbative physics from divergent asymptotic series. We validate this framework on a superconducting qudit model, demonstrating that the "Stokes Invariant" serves as the next-generation quantum number for classifying phases of matter beyond the reach of conventional topology.

</details>


### [143] [$\mathcal{PT}$-Symmetric Spin--Boson Model with a Continuous Bosonic Spectrum: Exceptional Points and Dynamics](https://arxiv.org/abs/2512.20277)
*Yong-Xin Zhang,Qing-Hu Chen*

Main category: quant-ph

TL;DR: 研究PT对称非厄米自旋-玻色子模型，发现与有限模系统不同，连续玻色浴仅产生单个异常点，且在异常点前仅有一个实特征值。非厄米系统表现出周期性振幅放大的振荡动力学，PT对称未破缺相中相干性增强，破缺相中退相干加速。


<details>
  <summary>Details</summary>
Motivation: 研究PT对称非厄米自旋-玻色子模型在连续玻色浴中的静态和动态特性，探索PT对称如何保护非厄米量子系统中的相干光-物质相互作用。

Method: 采用位移算子推导的投影方法分析系统静态性质，通过Dirac-Frenkel含时变分原理研究可观测量时间演化。

Result: 发现仅出现单个异常点（EP），异常点前仅有一个实特征值，不同于典型非厄米系统。非厄米模型表现出周期性振幅放大的振荡动力学，PT对称未破缺相中振荡持续且退相干受抑制，破缺相中退相干加速并快速收敛到稳定稳态。

Conclusion: PT对称在非厄米量子系统中保护相干光-物质相互作用，连续玻色浴导致与有限模系统不同的异常点行为，为理解非厄米量子系统的相干动力学提供了新见解。

Abstract: This work studies a $\mathcal{PT}$-symmetric non-Hermitian spin--boson model, consisting of a non-Hermitian two-level system coupled to a continuous bosonic bath. The static properties of the system are analyzed through a projection method derived from the displacement operator. We find that only a single exceptional point (EP) emerges, in contrast to non-Hermitian spin--boson models with finite modes, which typically exhibit multiple EPs. Notably, only a single real eigenvalue is found before the EP, which differs markedly from typical non-Hermitian systems where a pair of real eigenvalues precedes the EP. The time evolution of observables is further investigated via the Dirac--Frenkel time-dependent variational principle. Compared to its Hermitian counterpart, the non-Hermitian model exhibits distinct dynamical signatures, most notably the emergence of oscillations with periodic amplified amplitude. In the $\mathcal{PT}$-unbroken phase, the system exhibits sustained oscillatory dynamics with suppressed decoherence, whereas in the $\mathcal{PT}$-broken phase, additional dissipative channels accelerate decoherence and drive rapid convergence toward a stable steady state. These results shed light on how $\mathcal{PT}$ symmetry protects coherent light--matter interactions in non-Hermitian quantum systems.

</details>


### [144] [Localization and coherent control of 25 nuclear spins in Silicon Carbide](https://arxiv.org/abs/2512.20281)
*Pierre Kuna,Erik Hesselmeier-Hüttmann,Phillip Schillinger,Felix Gloistein,István Takács,Viktor Ivády,Wolfgang Knolle,Jawad Ul-Hassan,Jörg Wrachtrup,Vadim Vorobyov*

Main category: quant-ph

TL;DR: 该研究实现了在4H碳化硅中单个V2色心周围25个核自旋的埃级三维定位，利用核自旋作为读出辅助，通过相关光谱技术表征了扩展的核自旋簇。


<details>
  <summary>Details</summary>
Motivation: 光学可寻址的自旋缺陷是量子传感和量子网络的优秀候选平台，核自旋与色心的耦合天然支持长寿命量子存储和局域量子比特寄存器。为充分发挥这一潜力，需要精确表征周围核自旋环境并完善DFT模型。

Method: 利用特殊放置的鲁棒核存储器作为高效读出辅助，应用基于相关的光谱技术，通过选择长度达4的多自旋链，访问和表征扩展的核自旋簇，根据耦合图谱重建它们与中心电子自旋及相邻核自旋的耦合。

Result: 成功实现了单个V2色心周围25个核自旋的埃级三维定位，表征了扩展的核自旋簇，重建了它们与中心电子自旋及相邻核自旋的耦合关系。

Conclusion: 这项工作为在碳化硅平台上实现先进的量子寄存器应用铺平了道路。

Abstract: Optically addressable spin defects are excellent candidate platform for quantum sensing and quantum network. Nuclear spins coupled to color centers naturally enable long lived quantum memories and local qubits registers. To fully leverage this potential precise characterization of the surrounding nuclear-spin environment augmented with refined DFT models is required. In this work, we report angstrom-level 3D localization of 25 nuclear spins around a single V2 center in 4H Silicon Carbide. Utilizing specially placed robust nuclear memory as a highly efficient readout ancilla for readout, we apply correlation based spectroscopy and by selecting multi-spin chains up to length four, we access and characterize extended nuclear spin cluster. Using the coupling map we reconstruct their couplings to the central electron spin and neighboring nuclei. This work paves the way towards advanced quantum register applications on Silicon Carbide platform.

</details>


### [145] [Krylov complexity in ergodically constrained nonintegrable transverse-field Ising model](https://arxiv.org/abs/2512.20285)
*Gaurav Rudra Malik,Jeet Sharma,Rohit Kumar Shukla,S. Aravinda,Sunil Kumar Mishra*

Main category: quant-ph

TL;DR: 在横向场伊辛模型中引入空间不均匀性（将链分成两段，每段具有不同的耦合强度）可以抑制量子混沌行为，提供了一种无需无序性的非遍历性实现途径。


<details>
  <summary>Details</summary>
Motivation: 横向场伊辛模型通常用于研究遍历量子动力学，但研究者希望探索如何通过简单修改来抑制这种遍历行为，特别是寻找无需无序性的方法。

Method: 将自旋链分成两个相等段，每段具有不同的耦合强度，通过改变不均匀性参数（耦合强度比）来研究动力学变化。使用多种诊断工具：长时间饱和的时序无序关联函数、能级间距统计、谱形式因子、Krylov空间中的算子增长以及本征态中的纠缠生成。

Result: 随着不均匀性参数偏离1（均匀情况），系统表现出受限动力学，遍历行为被抑制。多种诊断工具一致显示从混沌到非遍历行为的交叉转变。

Conclusion: 在耦合强度中引入宏观不均匀性为这种特定相互作用自旋模型提供了一种最小化、无需无序性的打破遍历性途径。

Abstract: The nonintegrable transverse-field Ising model is a common platform for studying ergodic quantum dynamics. In this work, we introduce a simple variant of the model in which this ergodic behaviour is suppressed by introducing a spatial inhomogeneity in the interaction strengths. For this we partition the chain into two equal segments within which the spins interact with different coupling strengths. The ratio of these couplings defines an inhomogeneity parameter, whose variation away from unity leads to constrained dynamics. We characterize this crossover using multiple diagnostics, such as the long-time saturation of out-of-time-ordered correlators, level-spacing statistics, and the spectral form factor. We further examine the consequences for operator growth in Krylov space and for entanglement generation in the system's eigenstates. Together, these results demonstrate that introducing a macroscopic inhomogeneity in coupling strengths provides a minimal, disorder-free route to breaking ergodicity in this specific model of interacting spins.

</details>


### [146] [Exact Solution of Schrödinger equation for Complex Mass Quantum System under Complex Morse Potential to study emergent matter types and its phases](https://arxiv.org/abs/2512.20318)
*Partha Sarathi,Bhaskar Singh Rawat*

Main category: quant-ph

TL;DR: 论文研究了具有复质量和复Morse势的量子系统在扩展复相空间中的精确解，推导了归一化本征函数和本征谱，建立了谱为实数的条件，并识别出五种内在物质类型，包括暗物质的理论类比。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米量子框架下具有复质量和复Morse势的量子系统，探索复参数如何影响量子系统的谱特性、稳定性和物理可观测性，为理解复杂量子系统中的物理与非物理区域边界提供统一框架。

Method: 在扩展复相空间中求解具有复质量和复Morse势的薛定谔方程，推导归一化本征函数和本征谱，建立谱为实数的条件，分析参数空间中能量本征谱、归一化条件和概率密度分布。

Result: 识别出五种内在物质类型：实谱厄米类物质、准稳态或共振态、纯复数量子物质、非物理不可归一化态、以及概率密度空间静态的准经典确定区域。其中一种系统表现出非耗散、无碰撞状态，具有长程引力特性，可作为暗物质的理论类比。

Conclusion: 复质量和Morse参数的相互作用导致量子系统出现五种不同的物质类型或相，这一分类阐明了复杂量子系统中物理与非物理区域的边界，为解释复参数引起的稳定性、共振和经典性涌现提供了统一方法。

Abstract: We present exact solutions of the Schrödinger equation for a quantum system with complex mass subjected to a complex Morse potential in the extended complex phase space. The normalized eigenfunctions and corresponding eigenspectra are derived within a non-Hermitian framework, ensuring consistent probability densities. Conditions for the reality of the spectra are established and used to analyze the dependence of eigenvalue behaviour on potential parameters. The study reveals distinct regimes of spectral characteristics arising from the interplay of complex mass, the Morse parameter, and eigenvalues, leading to the emergence of five intrinsic matter types. By analysing the energy eigenspectra, normalization conditions, and probability density profiles across parameter space, we identify regimes corresponding to real-spectrum Hermitian-like matter, quasi-stable or resonant states, purely complex quantum matter, non-physical, non-normalizable states, and a quasi-classical determinate regime in which the probability density becomes spatially static. One of these system exhibits a non-dissipative, collisionless state with long-range gravitational-like characteristics, suggesting a theoretical analogue for dark matter within a non-Hermitian quantum framework. Further, the five identified classes of matter may be interpreted as distinct phases of a single quantum system governed by complex mass and Morse parameters This classification elucidates the boundary between physical and non-physical regimes in complex quantum systems and provides a unified approach for interpreting stability, resonance, and emergent classicality arising from complex parameters.

</details>


### [147] [Macroscopic quantum states, quantum phase transition for $N$ three-level atoms in an optical cavity -- Gauge principle and non-Hermitian Hamiltonian](https://arxiv.org/abs/2512.20321)
*Ni Liu,Xinyu Jia,J. -Q. Liang*

Main category: quant-ph

TL;DR: 该论文研究了N个三能级原子在单模光学腔中从正常相到超辐射相的量子相变，解决了规范选择歧义问题，揭示了不同规范在共振和非共振条件下的差异，并分析了非厄米相互作用下的特殊点行为。


<details>
  <summary>Details</summary>
Motivation: 解决量子光学中长期存在的规范选择歧义问题（库仑规范与偶极规范），建立统一的规范理论框架，研究三能级原子系统的量子相变特性，并探索非厄米相互作用下的物理行为。

Method: 采用自旋相干态变分方法分析量子相变；通过时间相关的规范变换解决薛定谔方程中的规范歧义；构建包含A·p和d·E相互作用的统一规范；研究厄米和非厄米哈密顿量下的系统行为。

Result: 建立了真正规范等价于最小耦合原理的统一规范；发现三种相互作用在共振条件下结果相同，但在红移和蓝移失谐时存在显著差异；揭示了量子相变临界点处能谱、平均光子数和原子布居的突变；发现非厄米相互作用导致特殊点，超辐射态不稳定，非厄米Dicke模型中只存在正常相。

Conclusion: 成功解决了长期存在的规范选择歧义问题，建立了统一的规范理论框架；揭示了初始光相位敏感性可作为实验验证不同规范有效性的关键指标；证明了非厄米相互作用下超辐射态的不稳定性，为理解非厄米量子系统的相变行为提供了新见解。

Abstract: We study in this paper the quantum phase transition (QPT) from normal phase (NP) to superradiant phase (SP) for $N$ three-level atoms in a single-mode optical cavity for both Hermitian and non Hermitian Hamiltonians, where the $Ξ$-type three-level atom is described by spin-$1$ pseudo-spin operators. The long standing gauge-choice ambiguity of $\mathbf{A\cdot p}$ and $\mathbf{d\cdot E}$ called respectively the Coulomb and dipole gauges is resolved by the time-dependent gauge transformation on the Schrödinger equation. Both $\mathbf{A\cdot p}$ and $\mathbf{d\cdot E}$ interactions are included in the unified gauge, which is truly gauge equivalent to the minimum coupling principle. The Coulomb and dipole interactions are just the special cases of unified gauge. Remarkably three interactions lead to the same results under the resonant condition of field-atom frequencies, while significant difference appears in red and blue detunings. The QPT is analyzed in terms of spin coherent-state variational method, which indicates the abrupt changes of energy spectrum, average photon number as well as the atomic population at the critical point of interaction constant. Crucially, we reveal the sensitive dependence on the initial optical-phase, which is particularly useful to test the validity of three gauges experimentally. The non-Hermitian atom-field interaction results in the exceptional point (EP), beyond which the semiclassical energy function becomes complex. However the energy spectrum of variational ground state is real in the absence of EP, and does not become complex. The superradiant state is unstable due to the non-Hermitian interaction induced photon-number loss. Thus only the NP exists in the non-Hermitian Dicke Model Hamiltonian.

</details>


### [148] [A Lovász theta lower bound on Quantum Max Cut](https://arxiv.org/abs/2512.20326)
*Felix Huber*

Main category: quant-ph

TL;DR: 证明了量子最大割的下界：对于有m条边的图G，qmc(G) ≥ (m/4)(1 + (8/3π)/(ϑ(Ḡ)-1))，其中ϑ(Ḡ)是补图的Lovász theta函数，且该下界可由乘积态实现。


<details>
  <summary>Details</summary>
Motivation: 研究量子最大割问题，旨在建立量子版本与经典图论不变量之间的联系，并改进经典最大割的界限。

Method: 扩展了Balla、Janzer和Sudakov关于经典最大割的结果，并受到Gharibian和Parekh的随机舍入方法的启发，通过Lovász theta函数建立量子最大割的下界。

Result: 证明了量子最大割的下界公式，该下界优于经典最大割的对应界限，且可通过乘积态实现。

Conclusion: 成功建立了量子最大割与Lovász theta函数之间的联系，提供了优于经典界限的量子下界，扩展了量子优化问题的理论工具。

Abstract: We prove a lower bound to quantum Max Cut of a graph in terms of the Lovász theta function of its complement. For a graph with $m$ edges, $\text{qmc}(G) \geq \tfrac{m}{4}\big( 1 + \tfrac{8}{3π}\tfrac{1}{\vartheta(\bar{G}) -1} \big)$, with the bound achieved by a product state. The proof extends a result by Balla, Janzer, and Sudakov on classical Max Cut and is also inspired by the randomized rounding method of Gharibian and Parekh. The bound outperforms the classical bound when applied to quantum Max Cut.

</details>


### [149] [Lie algebra-assisted quantum simulation and quantum optimal control via high-order Magnus expansions](https://arxiv.org/abs/2512.20357)
*R. F. dos Santos,S. J. J. M. F. Kokkelmans*

Main category: quant-ph

TL;DR: 提出一种可扩展方法，显著降低计算量子系统时间演化Magnus展开高阶项的计算成本，应用于量子模拟和最优控制


<details>
  <summary>Details</summary>
Motivation: 量子系统在时间依赖驱动下的演化展现出静态系统没有的现象，但量子动力学的高维度和非交换特性使其成为难题。Magnus展开提供了短时间尺度有效动力学的解析框架，但现有方法计算高阶项计算成本高昂

Method: 引入可扩展方法，将计算成本降低到仅依赖于定义时间依赖控制函数的自由度。专注于由常数漂移项和可控项组成的哈密顿量，提供Magnus展开的多项式表达式

Result: 新方法比先前技术快几个数量级，能够广泛用于量子模拟和量子最优控制。展示了在利用里德堡原子的中性原子平台上为5量子位相位门设计控制脉冲的应用

Conclusion: 该方法显著提高了Magnus展开高阶项的计算效率，为量子控制和模拟应用提供了实用工具，特别是在多量子位门设计方面

Abstract: The evolution of a quantum system under time-dependent driving exhibits phenomena that are absent in its stationary counterpart. However, the high dimensionality and non-commutative nature of quantum dynamics make this a challenging problem. The Magnus expansion provides an analytic framework to approximate the effective dynamics on short time-scales, but computing high-order terms with existing methods is computationally expensive. We introduce a scalable approach that reduces the computational effort to depend only on the degrees of freedom defining the time-dependent control function. We focus specifically on Hamiltonians consisting of a constant drift term and a controllable term. Our method provides a polynomial expression for the Magnus expansion which can be evaluated several orders of magnitude faster than previous techniques, enabling broad applications in the realms of quantum simulation and quantum optimal control. We showcase an application of the method by designing control pulses for the 5-qubit phase gate on a neutral-atom platform utilizing Rydberg atoms.

</details>


### [150] [The Exact Uncertainty Relation and Geometric Speed Limits in Krylov Space](https://arxiv.org/abs/2512.20359)
*Mohsen Alishahiha,Souvik Banerjee*

Main category: quant-ph

TL;DR: Hall不确定性关系在Krylov基中呈现简单几何形式，算子振幅向量在单位Krylov球面上以恒定速度演化，速度由第一个Lanczos系数决定，这给出了与高阶系数无关的几何算子演化线性界限。


<details>
  <summary>Details</summary>
Motivation: 为Hall精确不确定性关系提供几何解释，将量子速度极限与算子增长统一起来，识别第一个Lanczos系数作为量子动力学的内在速度尺度。

Method: 在Liouvillian生成的Krylov基中分析Hall不确定性关系，将算子振幅向量表示为在单位Krylov球面上的运动，证明演化速度由第一个Lanczos系数固定。

Result: 得到了与高阶Lanczos系数无关、适用于任意哈密顿量（可积或混沌）的几何算子演化精确线性界限，第一个Lanczos系数被确定为量子动力学的内在速度尺度。

Conclusion: 首次为精确量子速度极限和算子增长提供了统一的几何解释，揭示了第一个Lanczos系数在量子动力学中的基本作用，为理解量子演化速度提供了新视角。

Abstract: We show that Hall's exact uncertainty relation acquires a simple geometric form in the Krylov basis generated by the Liouvillian. In this canonical operator frame, the uncertainty equality implies that the operator amplitude vector evolves on the unit Krylov sphere with constant speed fixed solely by the first Lanczos coefficient. This yields an exact linear bound on geometric operator evolution, independent of higher Lanczos coefficients and valid for arbitrary Hamiltonians, integrable or chaotic. Our results provide the first unified geometric interpretation of exact quantum speed limits and operator growth, identifying the first Lanczos coefficient as the intrinsic speed scale of quantum dynamics.

</details>


### [151] [Storage and retrieval of optical skyrmions with topological characteristics](https://arxiv.org/abs/2512.20378)
*Jinwen Wang,Xin Yang,Yun Chen,Zhujun Ye,Xinji Zeng,Yongkun Zhou,Shuya Zhang,Claire Marie Cisowski,Chengyuan Wang,Katsuya Inoue,Yijie Shen,Sonja Franke-Arnold,Hong Gao*

Main category: quant-ph

TL;DR: 首次实验演示在冷铷原子蒸气中存储和检索光学斯格明子，证明斯格明子数在存储期间保持不变


<details>
  <summary>Details</summary>
Motivation: 光学斯格明子具有拓扑结构，其斯格明子数对扰动具有鲁棒性，适合量子信息存储应用。然而，在相干存储过程中斯格明子的保持特性尚未被探索。

Method: 使用双路径电磁感应透明存储器在冷铷-87原子蒸气中存储和检索光学斯格明子

Result: 斯格明子数在长达数微秒的存储时间内保持不变，即使在两条路径存在不平衡损耗和控制光束功率显著扰动的情况下也保持稳定

Conclusion: 首次展示了非平凡拓扑不变量在量子存储器中的存活，标志着迈向拓扑保护光子技术的重要一步

Abstract: Optical skyrmions are topological structures of light whose defining property, the skyrmion number, is robust against perturbations. This makes them attractive for applications in quantum information storage, where resilience to decoherence is paramount. However, their preservation during coherent storage remains unexplored. We report the first experimental demonstration of storing and retrieving optical skyrmions in a cold $^{87}$Rb vapor using a dual-path electromagnetically induced transparency memory. Crucially, we show that the skyrmion number remains invariant for storage times up to several microseconds, even when subjected to imbalanced loss between the two paths and substantial perturbations in control beam power. Our work demonstrates the survival of a non-trivial topological invariant in a quantum memory, marking a significant step towards topologically protected photonic technologies.

</details>


### [152] [Profusion of Symmetry-Protected Qubits from Stable Ergodicity Breaking](https://arxiv.org/abs/2512.20393)
*Thomas Iadecola,Rahul Nandkishore*

Main category: quant-ph

TL;DR: 结合离散对称性与拓扑希尔伯特空间碎片化，可产生指数多个受单离散对称性保护的拓扑稳定量子比特，显著增强量子存储鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过离散对称性与拓扑希尔伯特空间碎片化的结合，创造更稳定的量子比特，以增强量子存储的鲁棒性，超越基于非拓扑碎片化的现有方案。

Method: 以CZ_p模型为例，展示离散对称性与拓扑希尔伯特空间碎片化的结合机制，分析其产生的指数多个拓扑稳定量子比特的特性。

Result: 该模型产生的量子比特对任意对称性保持的扰动具有参数性长时间稳定性，量子比特成对出现且支持通用横向逻辑门集，但根据Eastin-Knill定理无法用于量子纠错。

Conclusion: 对称性富集与拓扑碎片化的结合为量子存储提供了新途径，但需注意其与量子纠错的不兼容性，为希尔伯特空间碎片化系统的应用提供了重要见解。

Abstract: We show how combining a discrete symmetry with topological Hilbert space fragmentation can give rise to exponentially many topologically stable qubits protected by a single discrete symmetry. We illustrate this explicitly with the example of the $\mathsf{CZ}_p$ model, where the encoded qubits are stable to arbitrary symmetry-respecting perturbations for parametrically long times, substantially enhancing the robustness of a recently proposed construction based on nontopological fragmentation. In this model, the encoded qubits naturally come in pairs for which a universal set of transversal logical gates can be performed, ruling out (by the Eastin-Knill theorem) the possibility of using them for quantum error correction. We also comment on the combination of symmetry enrichment and topological fragmentation more generally, and the implications for use of systems exhibiting Hilbert space fragmentation as quantum memories.

</details>


### [153] [Metrologically advantageous states: long-range entanglement and asymmetric error correction](https://arxiv.org/abs/2512.20426)
*Junjie Chen,Rui Luo,Yuxuan Yan,You Zhou,Xiongfeng Ma*

Main category: quant-ph

TL;DR: 该研究建立了量子计量学性能与长程纠缠、状态制备复杂度及量子纠错特性之间的理论联系，证明了超线性量子Fisher信息缩放需要长程纠缠，并揭示了计量灵敏度与局部噪声保护之间的基本不相容性。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计量学在利用多体量子态突破标准量子极限方面取得进展，但哪些多体量子态能展现超线性参数估计精度缩放的系统性理解仍然缺乏。研究旨在建立计量性能与量子态基本特性之间的理论框架。

Method: 开发了一个连接计量性能与长程纠缠、状态制备复杂度和量子纠错特性的通用理论框架。通过推导复杂度相关的量子Fisher信息严格上界，证明了超线性缩放需要长程纠缠。分析了两类量子纠错码（非退化码和CSS量子LDPC码）在局部哈密顿量下的计量性能限制。

Result: 证明了超线性QFI缩放必然需要长程纠缠。发现对于非退化码和CSS量子LDPC码，非常数码距会阻碍超线性QFI缩放，揭示了计量灵敏度与局部噪声保护之间的基本不相容性。同时发现了通过利用非对称码结构（如经典LDPC码和不对称环面码态）可以规避这一限制，实现海森堡极限缩放。

Conclusion: 该研究确立了长程纠缠和非对称纠错作为量子计量学的基本资源，阐明了状态复杂度、纠错能力和计量能力之间的相互作用关系，为设计高性能量子计量协议提供了理论指导。

Abstract: Quantum metrology aims to exploit many-body quantum states to achieve parameter-estimation precision beyond the standard quantum limit. For unitary parameter encoding generated by local Hamiltonians, such enhancement is characterized by superlinear scaling of the quantum Fisher information (QFI) with system size. Despite extensive progress, a systematic understanding of which many-body quantum states can exhibit this scaling has remained elusive. Here, we develop a general framework that connects metrological performance to long-range entanglement, state-preparation complexity, and quantum error-correction properties. We prove that super-linear QFI scaling necessarily requires long-range entanglement by deriving rigorous complexity-dependent upper bounds on the QFI. We further show that, for two broad classes of quantum error-correcting codes, nondegenerate codes and Calderbank--Shor--Steane quantum low-density parity-check codes, a nonconstant code distance precludes super-linear QFI scaling for a wide class of local Hamiltonians, revealing a fundamental incompatibility between metrological sensitivity and protection against local noise. Finally, we identify constructive routes that evade this obstruction by exploiting asymmetric code structures. In particular, we show that states associated with classical low-density parity-check codes, as well as asymmetric toric code states, both having asymmetric logical distances, can achieve Heisenberg-limited scaling. Together, our results establish long-range entanglement and asymmetric error correction as the essential resource underlying quantum metrology and clarify the interplay among state complexity, error correction, and metrological power.

</details>


### [154] [Scaling roadmap for modular trapped-ion QEC and lattice-surgery teleportation](https://arxiv.org/abs/2512.20435)
*César Benito,Alfredo Ricci Vasquez,Jonathan Home,Karan K. Mehta,Thomas Monz,Markus Müller,Alejandro Bermudez*

Main category: quant-ph

TL;DR: 该研究分析了基于囚禁离子的模块化量子纠错协议，比较了不同架构在三角色码中的性能表现，发现集成光子学连接是最有前景的长期扩展方案。


<details>
  <summary>Details</summary>
Motivation: 研究模块化量子纠错协议在囚禁离子架构中的实际实现，比较不同连接技术（激光束偏转器与集成光子学）对三角色码性能的影响，为近中期量子计算发展提供指导。

Method: 将QEC小工具转译为原生囚禁离子原语，详细考虑激光寻址和离子传输导致的串扰误差、运动激发和空闲比特误差，结合微观噪声模型、高效泡利框架模拟器和可扩展解码器评估性能。

Result: 分析表明模块化色码隐形传态在这些近中期囚禁离子架构中是可实现的，集成光子学连接在长期扩展方面表现最为优越。

Conclusion: 模块化量子纠错在囚禁离子架构中具有可行性，集成光子学连接技术为长期扩展提供了最有前景的技术路线，为量子计算的实际实现提供了重要指导。

Abstract: We present a footprint study for the scaling of modular quantum error correction (QEC) protocols designed for triangular color codes, including a lattice-surgery-based logical teleportation gadget, and compare the performance of various possible architectures based on trapped ions. The differences in these architectures arise from the technology that enables the connectivity between physical qubits and the modularity required for the QEC gadgets, which is either based on laser-beam deflectors focused to independent modules hosting mid-size ion crystals, or integrated photonics guided to segmented modules of the trap and allowing for the manipulation of smaller ion crystals. Our approach integrates the transpilation of the QEC gadgets into native trapped-ion primitives and a detailed account of the specific laser addressing and ion transport leading to different amounts of crosstalk errors, motional excitation and idle qubit errors. Combining a microscopically-informed noise model with an efficient Pauli-frame simulator and different scalable decoders, we assess the near-term performance of the color-code memory and teleportation protocols on these architectures. Our analysis demonstrates that modular color-code teleportation is achievable in these near-term trapped-ion architectures, and identifies the integrated-photonics connectivity as the most promising route for longer-term scaling.

</details>


### [155] [Quantum Bayesian Optimization for the Automatic Tuning of Lorenz-96 as a Surrogate Climate Model](https://arxiv.org/abs/2512.20437)
*Paul J. Christiansen,Daniel Ohl de Mello,Cedric Brügmann,Steffen Hien,Felix Herbort,Martin Kiffner,Lorenzo Pastori,Veronika Eyring,Mierk Schwabe*

Main category: quant-ph

TL;DR: 提出一种混合量子启发式方法，用于自动调优Lorenz-96大气动力学模型，通过量子核替代经典高斯过程模拟器，在数值模拟中显示量子核优于经典RBF核，并讨论了向真实量子硬件的过渡路径。


<details>
  <summary>Details</summary>
Motivation: Lorenz-96模型作为大气动力学的简单代理模型具有混沌行为，需要自动化调优方法。量子计算提供了超越经典方法的潜力，特别是在核方法的表达能力方面。

Method: 基于Lguensat等人（2023）的历史匹配框架，提出完全自动化的调优过程，使用量子核替代经典高斯过程模拟器。研究了三种量子核架构，通过状态向量模拟进行验证，并进行了广泛的超参数优化。

Result: 数值模拟证实了两种研究的量子核优于经典RBF核。量子核在理论上具有更高的表达能力，且方法对NISQ设备友好，仅需少量量子比特和适中的电路深度。

Conclusion: 量子启发式方法在Lorenz-96模型调优中表现出优势，为向真实量子硬件过渡提供了可行路径，包括基于测量的模拟和随机测量评估，能够缓解门错误的影响。

Abstract: In this work, we propose a hybrid quantum-inspired heuristic for automatically tuning the Lorenz-96 model -- a simple proxy to describe atmospheric dynamics, yet exhibiting chaotic behavior. Building on the history matching framework by Lguensat et al. (2023), we fully automate the tuning process with a new convergence criterion and propose replacing classical Gaussian process emulators with quantum counterparts. We benchmark three quantum kernel architectures, distinguished by their quantum feature map circuits. A dimensionality argument implies, in principle, an increased expressivity of the quantum kernels over their classical competitors. For each kernel type, we perform an extensive hyperparameter optimization of our tuning algorithm. We confirm the validity of a quantum-inspired approach based on statevector simulation by numerically demonstrating the superiority of two studied quantum kernels over the canonical classical RBF kernel. Finally, we discuss the pathway towards real quantum hardware, mainly driven by a transition to shot-based simulations and evaluating quantum kernels via randomized measurements, which can mitigate the effect of gate errors. The very low qubit requirements and moderate circuit depths, together with a minimal number of trainable circuit parameters, make our method particularly NISQ-friendly.

</details>


### [156] [Enriching Earth Observation labeled data with Quantum Conditioned Diffusion Models](https://arxiv.org/abs/2512.20448)
*Francesco Mauro,Francesca De Falco,Lorenzo Papa,Andrea Ceschini,Alessandro Sebastianelli,Paolo Gamba,Massimo Panella,Silvia Ullo*

Main category: quant-ph

TL;DR: 提出QCU-Net混合量子-经典架构，首次将类别条件量子扩散模型应用于地球观测领域，显著提升合成图像质量并大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 地球观测领域数据标注成本高、可用性有限，传统扩散模型计算复杂度高（需数百至数千步推理），且难以捕捉EO数据复杂的空间和光谱相关性。量子机器学习为克服这些挑战提供了新途径。

Method: 提出Quanvolutional Conditioned U-Net (QCU-Net)混合量子-经典架构，在条件扩散框架中应用量子操作，采用新颖的量子卷积特征提取方法生成合成EO图像。

Result: 在EuroSAT RGB数据集上，QCU-Net将Fréchet Inception Distance降低64%，Kernel Inception Distance降低76%，并获得更高的语义准确性。消融研究表明量子层战略定位和纠缠变分电路能提升模型性能和收敛性。

Conclusion: 这是EO领域首次成功应用类别条件量子扩散模型，为量子增强的遥感图像合成开辟了新途径，展示了量子操作在提升生成模型性能方面的潜力。

Abstract: The rapid adoption of diffusion models (DMs) in the Earth Observation (EO) domain has unlocked new generative capabilities aimed at producing new samples, whose statistical properties closely match real imagery, for tasks such as synthesizing missing data, augmenting scarce labeled datasets, and improving image reconstruction. This is particularly relevant in EO, where labeled data are often costly to obtain and limited in availability. However, classical DMs still face significant computational limitations, requiring hundreds to thousands of inference steps, as well as difficulties in capturing the intricate spatial and spectral correlations characteristic of EO data. Recent research in Quantum Machine Learning (QML), including initial attempts of Quantum Generative Models, offers a fundamentally different approach to overcome these challenges. Motivated by these considerations, we introduce the Quanvolutional Conditioned U-Net (QCU-Net), a hybrid quantum--classical architecture that applies quantum operations within a conditioned diffusion framework using a novel quanvolutional feature-extraction approach, for generating synthetic labeled EO imagery. Extensive experiments on the EuroSAT RGB dataset demonstrate that our QCU-Net achieves superior results. Notably, it reduces the Fréchet Inception Distance by 64%, lowers the Kernel Inception Distance by 76%, and yields higher semantic accuracy. Ablation studies further reveal that strategically positioning quantum layers and employing entangling variational circuits enhance model performance and convergence. This work represents the first successful adaptation of class-conditioned quantum diffusion modeling in the EO domain, paving the way for quantum-enhanced remote sensing imagery synthesis.

</details>


### [157] [A High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement](https://arxiv.org/abs/2512.20489)
*Aktaş,Arzu,Yılmaz,İhsan*

Main category: quant-ph

TL;DR: 提出一种基于量子力学原理的量子区块链协议，利用高维贝尔态、时间纠缠、纠缠切换和高维超密编码，通过量子测量的因果序列而非哈希函数实现区块验证。


<details>
  <summary>Details</summary>
Motivation: 量子计算和机器学习的快速发展威胁传统区块链的安全性，传统区块链主要依赖计算困难性作为保护机制。需要开发基于量子力学原理的量子安全区块链架构。

Method: 将经典区块信息编码到时间限定的qudit态中，利用高维贝尔态、时间纠缠、纠缠切换和高维超密编码技术。通过量子测量的因果序列实现区块身份和数据验证，每个区块通过连续时间步长的高维贝尔态测量从观测到的量子关联中直接生成公私钥对。

Result: 协议提供了分布式认证、不可否认性和防篡改检测。由于密钥依赖于测量的时间顺序，任何篡改区块数据或破坏协议时序结构的尝试都会影响重建的关联并在验证时被发现。

Conclusion: 该框架可作为未来量子网络环境中量子安全区块链架构的可行且可扩展候选方案，必要的量子资源与新兴量子通信平台兼容。

Abstract: Rapid advancements in quantum computing and machine learning threaten the long-term security of classical blockchain systems, whose protection mechanisms largely rely on computational difficulties. In this study, we propose a quantum blockchain protocol whose protection mechanism is directly derived from quantum mechanical principles. The protocol combines high-dimensional Bell states, time-entanglement, entanglement switching, and high-dimensional superdense coding. Encoding classical block information into time-delimited qudit states allows block identity and data verification to be implemented through the causal sequencing of quantum measurements instead of cryptographic hash functions. High-dimensional coding increases the information capacity per quantum carrier and improves noise resistance. Time-entanglement provides distributed authentication, non-repudiation, and tamper detection across the blockchain. Each block derives its own public-private key pair directly from the observed quantum correlations by performing high-dimensional Bell state measurements in successive time steps. Because these keys are dependent on the time ordering of measurements, attempts to alter block data or disrupt the protocol's timing structure inevitably affect the reconstructed correlations and are revealed during validation. Recent advances in the creation and detection of high-dimensional time-slice entanglement demonstrate that the necessary quantum resources are compatible with emerging quantum communication platforms. Taken together, these considerations suggest that the proposed framework can be evaluated as a viable and scalable candidate for quantum-secure blockchain architectures in future quantum network environments.

</details>


### [158] [End-to-end Optimization of Single-Shot Quantum Machine Learning for Bayesian Inference](https://arxiv.org/abs/2512.20492)
*Theodoros Ilias,Fangjun Hu,Marti Vives,Hakan E. Türeci*

Main category: quant-ph

TL;DR: 提出一种针对有限测量资源的量子机器学习端到端优化策略，直接以任务性能为目标，应用于贝叶斯量子计量学，并在32量子比特系统中实现接近理论极限的性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在有限测量资源下的性能优化是实际应用的关键挑战，需要直接针对任务性能而非中间指标进行优化。

Method: 采用端到端优化策略，定义直接基于任务性能的学习目标，应用于贝叶斯量子计量任务，并扩展到全局函数推断框架。

Result: 在32量子比特系统中，采样感知混合算法实现了单次风险在贝叶斯极限-20 dB的1 dB范围内，并展示了直接函数推断相对于间接重建的计算感知优势。

Conclusion: 该方法在资源有限或实时设备设置中，通过特征任务分析识别噪声鲁棒的特征组合，产生紧凑估计器，提高准确性并降低优化成本。

Abstract: We introduce an end-to-end optimization strategy for quantum machine learning that directly targets performance under finite measurement resources, where learning objectives are defined directly at the level of task performance. The method is applied on a Bayesian quantum metrology task since it provides a natural testbed with known fundamental limits and scaling with system size. The sampling-aware hybrid algorithm achieves a single-shot risk within 1 dB of the -20 dB Bayesian limit using 32 qubits. We extend the Bayesian framework from parameter estimation to global function inference, where the task is to infer a target function of the sensor input drawn from an arbitrary prior, and we demonstrate a clear computational-sensing advantage for direct functional inference over indirect reconstruction. We relate the corresponding Bayesian risk to the Capacity metric and argue that the Resolvable Expressive Capacity provides a natural measure of the space of functions accessible in a single shot. The resulting eigentask analysis identifies noise-robust feature combinations that yield compact estimators with improved accuracy and reduced optimization cost in resource-limited or real-time on-device settings.

</details>


### [159] [Macroscopically distinguishable superposition in infinitely many degrees of freedom](https://arxiv.org/abs/2512.20512)
*J. Fransson,B. C. Sanders,A. P. Sowa*

Main category: quant-ph

TL;DR: 该论文研究了无限玻色子阵列中的宏观可区分叠加态，证明了非局域相干态可以在非局域哈密顿量作用下演化为非局域猫态，且这种动力学无法分解为局域因子。


<details>
  <summary>Details</summary>
Motivation: 研究无限玻色子阵列中宏观可区分叠加态的概念，区分局域和非局域态及其动力学，探索非局域相干态在非局域哈密顿量作用下的演化行为。

Method: 在希尔伯特空间理论框架内进行严格分析，区分仅涉及有限自由度的局域态和固有非局域态，研究非局域相干态在总粒子数算符平方这一非局域哈密顿量作用下的动力学演化。

Result: 证明了非局域相干态可以动态演化为非局域猫态，且这种动力学无法分解为局域因子；发现相干态和非局域猫态的概念并非固有绑定，它们的融合是标准玻色子的独特特征。

Conclusion: 在广义玻色子框架下，如果能在工程量子系统中物理实现，这些现象可能对物理学和材料科学具有重要意义，揭示了非局域量子态演化的新特性。

Abstract: We investigate the concept of macroscopically distinguishable superpositions within an infinite array of boson sites. Our approach is rigorous within the frame of Hilbert space theory. In this context, it is natural to differentiate between states -- and corresponding dynamics -- that involve only finitely many degrees of freedom, referred to as local, and those that are inherently nonlocal. Previous studies have shown that such systems can support nonlocal coherent states (NCS). In this work, we demonstrate that NCS can dynamically evolve into nonlocal cat states under the influence of a nonlocal Hamiltonian -- specifically, the square of the total number operator. Crucially, the resulting dynamics cannot be decomposed into local factors. Furthermore, we explore broader mathematical implications of these phenomena within the framework of generalized bosons. Our findings highlight that the concepts of coherent states and nonlocal cat states are not inherently bound together; rather, their fusion is a distinctive feature of standard bosons. Finally, we propose that if the generalized boson framework can be physically realized in engineered quantum systems, the phenomena described here may hold significant relevance for both physics and materials science.

</details>


### [160] [Small quantum Tanner codes from left--right Cayley complexes](https://arxiv.org/abs/2512.20532)
*Anthony Leverrier,Wouter Rozendaal,Gilles Zémor*

Main category: quant-ph

TL;DR: 量子Tanner码是一类量子低密度奇偶校验码，在渐近极限下具有线性最小距离和恒定编码率。论文研究了基于左右Cayley复形的构造，计算了右度为2时的维度，并通过小群搜索发现了几个具体参数实例。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码是实现容错量子计算的关键。量子Tanner码作为一类有前景的量子LDPC码，理论上具有优良的渐近性能，但需要具体构造方法和实际参数实例来验证其实际应用潜力。

Method: 1. 使用左右Cayley复形构建量子Tanner码，通过提升过程和基码进行描述；2. 计算当复形的右度为2时量子Tanner码的维度；3. 在小群上进行广泛搜索，识别具体的码参数实例。

Result: 1. 描述了基于左右Cayley复形的量子Tanner码构造方法；2. 推导了右度为2时的维度计算公式；3. 发现了三个具体参数实例：[[144,12,11]]、[[432,20,≤22]]和[[576,28,≤24]]，生成元权重为9。

Conclusion: 量子Tanner码通过左右Cayley复形构造具有理论保证的优良渐近性能，论文提供了具体的构造方法和实际参数实例，证明了这类码的实际可行性，为量子纠错码的实际应用提供了有价值的参考。

Abstract: Quantum Tanner codes are a class of quantum low-density parity-check codes that provably display a linear minimum distance and a constant encoding rate in the asymptotic limit. When built from left--right Cayley complexes, they can be described through a lifting procedure and a base code, which we characterize. We also compute the dimension of quantum Tanner codes when the right degree of the complex is 2. Finally, we perform an extensive search over small groups and identify instances of quantum Tanner codes with parameters $[[144,12,11]]$, $[[432,20,\leq 22]]$ and $[[576,28,\leq 24]]$ for generators of weight 9.

</details>


### [161] [On super additivity of Fisher information in fully Gaussian metrology](https://arxiv.org/abs/2512.20534)
*Javier Navarro,Simon Morelli,Mikel Sanz,Mohammad Mehboudi*

Main category: quant-ph

TL;DR: 研究在仅允许高斯测量的约束下，量子费希尔信息是否保持可加性。发现对于位移或协方差矩阵编码的参数，最优高斯测量保持局域性；但对于两者同时编码的参数，存在超可加性的全局高斯测量。


<details>
  <summary>Details</summary>
Motivation: 量子费希尔信息在无约束测量下具有可加性，但实际实验中测量受到限制。本研究旨在探索在仅允许高斯测量的约束下，信息估计的最优测量是否仍保持局域性。

Method: 采用完全高斯场景，仅考虑高斯测量。分析参数编码在位移、协方差矩阵或两者同时的情况，构造具体的全局高斯测量方案。

Result: 当参数仅编码在位移或协方差矩阵时，最优高斯测量保持局域性；当参数同时编码在两者时，存在全局高斯测量使费希尔信息具有超可加性。在量子光学平台中，提出的全局操作仅需被动全局操作和单模高斯测量。

Conclusion: 测量约束改变了量子参数估计的基本特性。全局高斯测量可以提升参数估计性能，在估计压缩和损耗的示例中，联合高斯测量可以缩小与量子费希尔信息的差距，并在多副本渐近极限下闭合该差距。

Abstract: Famously, the quantum Fisher information -- the maximum Fisher information over all physical measurements -- is additive for independent copies of a system and the optimal measurement acts locally. We are left to wonder: does the same hold when the set of accessible measurements is constrained? Such constraints are necessary to account for realistic experimental restrictions. Here, we consider a fully Gaussian scenario focusing on only Gaussian measurements. We prove that the optimal Gaussian measurement protocol remains local, if the information is encoded in either the displacement or the covariance matrix. However, when the information is imprinted on both, this no longer holds true: we construct a simple global Gaussian measurement where the Fisher information becomes super additive. These results can improve parameter estimation tasks via feasible tools. Namely, in quantum optical platforms our proposed global operation requires only passive global operations and single mode Gaussian measurements. We demonstrate this in two examples where we estimate squeezing and losses. While in the former case there is a significant gap between the Fisher information of the optimal Gaussian measurement and the quantum Fisher information for a single copy, this gap can be reduced with joint Gaussian measurements and closed in the asymptotic limit of many copies.

</details>


### [162] [Quantum State Preparation via Schmidt Spectrum Optimisation](https://arxiv.org/abs/2512.20537)
*Josh Green,Joshua Snow,Jingbo B Wang*

Main category: quant-ph

TL;DR: 提出一种基于Schmidt谱优化的高效算法，用于设计浅层量子电路来制备矩阵乘积态表示的多体量子态


<details>
  <summary>Details</summary>
Motivation: 为在近期量子硬件上实现可扩展的量子态制备，需要设计浅层深度的量子电路来高效制备矩阵乘积态表示的多体量子态，同时保持其固有的纠缠结构

Method: 使用Schmidt谱优化方法，通过优化局部幺正操作序列来解纠缠目标MPS，然后反转这个过程获得态制备电路。定义基于中间态Schmidt谱的损失函数，利用自动微分优化每个电路层以系统性地减少纠缠熵

Result: 在局部哈密顿量基态的MPS近似上进行了基准测试，展示了最先进的浅层深度性能，相比现有方法精度提高了一个数量级，并减轻了先前解纠缠方法中观察到的不良时间复杂性缩放

Conclusion: SSO方法为在近期量子硬件上高效制备多体量子态提供了一种有效的浅层电路设计策略，通过优化Schmidt谱来平衡电路深度与态制备精度

Abstract: We introduce an efficient algorithm for the systematic design of shallow-depth quantum circuits capable of preparing many-body quantum states represented as Matrix Product States (MPS). The proposed method leverages Schmidt spectrum optimization (SSO) to minimize circuit depth while preserving the entanglement structure inherent to MPS representations, thereby enabling scalable state preparation on near-term quantum hardware. The core idea is to \textit{disentangle} the target MPS using a sequence of optimised local unitaries, and then reverse this process to obtain a state preparation circuit. Specifically, we define a loss function directly on the Schmidt spectra of intermediate states and use automatic differentiation to optimise each circuit layer so as to systematically reduce entanglement entropy. Once a disentangling sequence has been learned, we take the adjoints of the optimised unitaries to obtain a shallow-depth circuit that approximately reconstructs the target MPS from the computational all-zero state. We benchmark SSO across a range of MPS approximations to the ground states of local Hamiltonians and demonstrate state-of-the-art shallow-depth performance, improving accuracy by up to an order of magnitude over existing methods. Finally, we provide numerical evidence that SSO mitigates the adverse time-complexity scaling observed in previous disentangling-based approaches.

</details>


### [163] [Experimental characterization of the Toffoli gate via channel spectrum benchmarking](https://arxiv.org/abs/2512.20545)
*D. K. Korliakov,B. I. Bantysh,A. S. Borisenko,I. V. Zalivako,E. O. Kiktenko*

Main category: quant-ph

TL;DR: 本文提出了一种扩展的通道谱基准测试（CSB）模型和保真度估计区间（FEI），用于在强噪声环境下更可靠地估计量子门保真度，并在离子阱量子处理器上验证了该协议。


<details>
  <summary>Details</summary>
Motivation: 当前通道谱基准测试（CSB）方法在重建噪声特征值时面临基本挑战，特别是在存在谱简并和目标门特征基中的非对角噪声分量时。这些问题在保真度约90%的强噪声环境下尤为突出。

Method: 引入扩展的CSB模型和保真度估计区间（FEI）——一种区间值的目标门保真度估计。FEI在数值模拟中保持足够窄，其中点可靠地近似真实保真度。

Result: 在离子阱量子处理器上对三量子比特Toffoli门的两种实现进行了基准测试，结果显示基于qutrit的实现明显优于基于qubit的实现。

Conclusion: 提出的扩展CSB模型和FEI方法能够有效解决传统CSB在强噪声环境下的局限性，为量子门保真度评估提供了更可靠的工具。

Abstract: Channel spectrum benchmarking (CSB) provides a robust framework for characterizing quantum gate fidelities while remaining insensitive to state preparation and measurement (SPAM) errors. Yet, current CSB implementations encounter fundamental challenges when reconstructing noisy eigenvalues, particularly in the presence of spectral degeneracies and off-diagonal noise components in the target gate's eigenbasis. These issues become especially pronounced in the strong noise regime for gates with fidelities around $90\%$. To address these limitations, we introduce an extended CSB model together with a fidelity estimate interval (FEI) -- an interval-valued estimate of the target gate fidelity. Numerical simulation demonstrates that FEI remains sufficiently narrow, with its midpoint reliably approximating the true fidelity. We further validate the protocol on a trapped-ion quantum processor by benchmarking two implementations of the three-qubit Toffoli gate. The results reveal a clear advantage of the qutrit-based implementation over its qubit-based counterpart.

</details>


### [164] [Hardware-aware and Resource-efficient Circuit Packing and Scheduling on Trapped-Ion Quantum Computers](https://arxiv.org/abs/2512.20554)
*Miguel Palma,Shuwen Kan,Wenqi Wei,Juntao Chen,Kaixun Hua,Sara Mouradian,Ying Mao*

Main category: quant-ph

TL;DR: CircPack：针对模块化囚禁离子QCCD架构的硬件感知量子电路打包框架，通过二维装箱问题建模实现多电路并行执行，相比超导系统显著提升保真度、利用率和层数优化。


<details>
  <summary>Details</summary>
Motivation: 量子云服务快速增长导致作业队列过长，现有单租户执行模型硬件利用率低。量子多编程（QMP）通过并行执行多个电路来解决此问题，但现有方法主要针对连接有限、串扰高、门保真度低的超导系统，而囚禁离子架构具有全连接、长相干时间、高保真度测量等优势，更适合可扩展的QMP。

Method: CircPack将静态电路调度建模为二维装箱问题，考虑硬件特定的穿梭约束。该框架专为基于量子电荷耦合器件（QCCD）架构的模块化囚禁离子设备设计，能够实现跨独立QCCD模块的可扩展、平衡调度。

Result: 相比基于超导的QMP方法，CircPack实现了：1）保真度提升高达70.72%；2）利用率提高62.67%；3）层数优化改进32.80%。框架还能在QCCD模块集群上实现可扩展的平衡调度。

Conclusion: CircPack展示了囚禁离子系统在提高量子云计算吞吐量方面的潜力，为近未来量子云服务提供了更高效的硬件感知调度解决方案，特别适合具有全连接和高保真度特性的囚禁离子架构。

Abstract: The rapid expansion of quantum cloud services has led to long job queues due to single-tenant execution models that underutilize hardware resources. Quantum multi-programming (QMP) mitigates this by executing multiple circuits in parallel on a single device, but existing methods target superconducting systems with limited connectivity, high crosstalk, and lower gate fidelity. Trapped-ion architectures, with all-to-all connectivity, long coherence times, and high-fidelity mid-circuit measurement properties, presents itself as a more suitable platform for scalable QMP. We present CircPack, a hardware-aware circuit packing framework designed for modular trapped-ion devices based on the Quantum Charge-Coupled Device (QCCD) architecture. CircPack formulates static circuit scheduling as a two-dimensional packing problem with hardware-specific shuttling constraints. Compared to superconducting-based QMP approaches, CircPack achieves up to 70.72% better fidelity, 62.67% higher utilization, and 32.80% improved layer reduction. This framework is also capable of scalable, balanced scheduling across a cluster of independent QCCD modules, highlighting trapped-ion systems' potential in improving the throughput of quantum cloud computing in the near future.

</details>


### [165] [Classification using quantum kernels in a radial basis function network](https://arxiv.org/abs/2512.20567)
*Emily Micklethwaite,Adam Lowe*

Main category: quant-ph

TL;DR: 论文提出了一种结合量子核函数的径向基函数网络，用于多类分类任务，相比传统量子核SVM具有优势。


<details>
  <summary>Details</summary>
Motivation: 量子核函数主要应用于支持向量机，但标准SVM在多类分类方面存在限制。径向基函数网络天然支持多类分类，因此将量子核与RBF网络结合可以克服量子核SVM的局限性。

Method: 将径向基函数网络扩展为包含量子核函数的混合量子-经典机器学习算法。通过合成示例进行概念验证，应用于插值和分类任务。

Result: 提出了量子核RBF网络的概念，证明其在插值和分类应用中的可行性。相比量子核SVM，该网络在多类分类方面具有潜在优势。

Conclusion: 量子核RBF网络为混合量子-经典机器学习提供了新方法，特别是在多类分类任务中比量子核SVM更具优势，为量子机器学习开辟了新方向。

Abstract: Radial basis function (RBF) networks are expanded to incorporate quantum kernel functions enabling a new type of hybrid quantum-classical machine learning algorithm. Using this approach, synthetic examples are introduced which allow for proof of concept on interpolation and classification applications. Quantum kernels have primarily been applied to support vector machines (SVMs), however the quantum kernel RBF network offers potential benefit over quantum kernel based SVMs due to the RBF networks ability to perform multi-class classification natively compared to the standard implementation of the SVM.

</details>


### [166] [Quantum Gates from Wolfram Model Multiway Rewriting Systems](https://arxiv.org/abs/2512.20587)
*Furkan Semih Dündar,Xerxes D. Arsiwalla,Hatem Elshatlawy*

Main category: quant-ph

TL;DR: 该论文展示了如何使用非确定性重写系统构建有限维量子算子的表示，特别是基于莱布尼茨字符串的Wolfram模型多路系统，能够编码量子门（如CNOT、π/8、Hadamard门）和量子电路的表示。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用非确定性重写系统（特别是Wolfram多路系统）来表示量子算子，探索计算模型与量子物理之间的深刻联系，为量子计算提供新的形式化基础。

Method: 采用基于循环字符字符串（莱布尼茨字符串）的特定多路重写系统，这些字符串具有邻域约束。系统实现ℤ-模结构，具有对称ℤ-双线性形式，建立离散路径积分和S矩阵，从而表示量子门和电路。

Result: 莱布尼茨字符串的期望值呈现费米-狄拉克分布，多路系统能够编码量子门的表示，包括CNOT、π/8和Hadamard门，并能表示量子比特和量子dit的量子电路。

Conclusion: 基于莱布尼茨字符串的多路重写系统作为非确定性计算的形式模型，能够编码量子算子的表示，为量子计算提供了新的数学框架，连接了重写系统与量子物理。

Abstract: We show how representations of finite-dimensional quantum operators can be constructed using nondeterministic rewriting systems. In particular, we investigate Wolfram model multiway rewriting systems based on string substitutions. Multiway systems were proposed by S. Wolfram as generic model systems for multicomputational processes, emphasizing their significance as a foundation for modeling complexity, nondeterminism, and branching structures of measurement outcomes. Here, we investigate a specific class of multiway systems based on cyclic character strings with a neighborhood constraint - the latter called Leibnizian strings. We show that such strings exhibit a Fermi-Dirac distribution for expectation values of occupation numbers of character neighborhoods. A Leibnizian string serves as an abstraction of a $N$-fermion system. A multiway system of these strings encodes causal relations between rewriting events in a nondeterministic manner. The collection of character strings realizes a $\mathbb{Z}$-module with a symmetric $\mathbb{Z}$-bilinear form. For discrete spaces, this generalizes the notion of an inner product over a vector field. This admits a discrete analogue of the path integral and a $S$-matrix for multiway systems of Leibnizian strings. The elements of this $S$-matrix yield transition amplitudes between states of the multiway system based on an action defined over a sequence of Leibnizian strings. We then show that these $S$-matrices give explicit representations of quantum gates for qubits and qudits, and also circuits composed of such gates. We find that, as formal models of nondeterministic computation, rewriting systems of Leibnizian strings with causal structure encode representations of the CNOT, $π/8$, and Hadamard gates. Hence, using multiway systems one can represent quantum circuits for qubits.

</details>


### [167] [Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods](https://arxiv.org/abs/2512.20588)
*Demerson N. Gonçalves,Tharso D. Fernandes,Andrias M. M. Cordeiro,Pedro H. G. Lugao,João T. Dias*

Main category: quant-ph

TL;DR: 提出改进的最小准确度启发式方法，用于高效评估量子特征映射，无需完整QSVM训练，提供理论保证和可扩展的蒙特卡洛估计策略。


<details>
  <summary>Details</summary>
Motivation: 原始最小准确度启发式方法存在计算成本高、仅适用于平衡数据集、缺乏理论支持等局限性，需要改进以在近期量子设备上实现可扩展的特征映射预筛选。

Method: 1) 将最小准确度度量推广到任意二元数据集；2) 形式化证明该度量构成相同特征空间中任何线性分类器最优经验准确度的认证下界；3) 引入使用随机泡利方向子集的蒙特卡洛策略来高效估计该下界。

Result: 建立了最小准确度作为可扩展、理论可靠的工具，用于在近期量子设备上预筛选特征映射，提供了严格的概率保证，显著降低了计算复杂度。

Conclusion: 改进的最小准确度启发式方法解决了原始方法的局限性，为量子特征映射评估提供了高效、理论严谨的预筛选工具，特别适合资源受限的近期量子计算设备。

Abstract: The minimum accuracy heuristic evaluates quantum feature maps without requiring full quantum support vector machine (QSVM) training. However, the original formulation is computationally expensive, restricted to balanced datasets, and lacks theoretical backing. This work generalizes the metric to arbitrary binary datasets and formally proves it constitutes a certified lower bound on the optimal empirical accuracy of any linear classifier in the same feature space. Furthermore, we introduce Monte Carlo strategies to efficiently estimate this bound using a random subset of Pauli directions, accompanied by rigorous probabilistic guarantees. These contributions establish minimum accuracy as a scalable, theoretically sound tool for pre-screening feature maps on near-term quantum devices.

</details>


### [168] [Random Stinespring superchannel: converting channel queries into dilation isometry queries](https://arxiv.org/abs/2512.20599)
*Filippo Girardi,Francesco Anna Mele,Haimeng Zhao,Marco Fanizza,Ludovico Lami*

Main category: quant-ph

TL;DR: 论文引入了随机Stinespring超信道，将任意量子信道的n次并行查询转换为相同随机Stinespring等距的n次并行查询，建立了量子信道学习的最优查询复杂度为Θ(d_A d_B r)。


<details>
  <summary>Details</summary>
Motivation: 受随机纯化信道（将任意混合态转换为相同随机纯化）的启发，作者希望构建信道层面的类似工具，将任意量子信道转换为相同随机Stinespring等距，从而简化量子信道学习问题。

Method: 引入随机Stinespring超信道，通过可高效实现的通用编码和解码操作，将任意量子信道的n次并行查询转换为相同随机Stinespring等距的n次并行查询。当信道Choi秩不超过r时，可定制为产生维度为r的Stinespring环境。

Result: 1) 量子信道学习简化为等距学习，基于现有等距学习协议的信道学习算法性能与最近提出的两种信道层析算法相当；2) 完全确定了这些信道学习算法的最优性，证明学习输入维度d_A、输出维度d_B、Choi秩为r的量子信道的最优查询复杂度为Θ(d_A d_B r)。

Conclusion: 随机Stinespring超信道是量子信息理论中的强大工具，它建立了量子信道学习的最优查询复杂度，完全解决了之前算法最优性证明中存在的对数因子差距问题。

Abstract: The recently introduced random purification channel, which converts $n$ copies of an arbitrary mixed quantum state into $n$ copies of the same uniformly random purification, has emerged as a powerful tool in quantum information theory. Motivated by this development, we introduce a channel-level analogue, which we call the random Stinespring superchannel. This consists in a procedure to transform $n$ parallel queries of an arbitrary quantum channel into $n$ parallel queries of the same uniformly random Stinespring isometry, via universal encoding and decoding operations that are efficiently implementable. When the channel is promised to have Choi rank at most $r$, the procedure can be tailored to yield a Stinespring environment of dimension $r$. As a consequence, quantum channel learning reduces to isometry learning, yielding a simple channel learning algorithm, based on existing isometry learning protocols, that matches the performance of the two recently proposed channel tomography algorithms. Complementarily, whereas the optimality of these algorithms had previously been established only up to a logarithmic factor in the dimension, we close this gap by removing this logarithmic factor from the lower bound. Taken together, our results fully establish the optimality of these recently introduced channel learning algorithms, showing that the optimal query complexity of learning a quantum channel with input dimension $d_A$, output dimension $d_B$, and Choi rank $r$ is $Θ(d_A d_B r)$.

</details>


### [169] [Coexistence of distinct Discrete Time-Crystalline orders in the Floquet Lipkin-Meshkov-Glick model](https://arxiv.org/abs/2512.20603)
*Shashank Mishra,Sayan Choudhury*

Main category: quant-ph

TL;DR: 通过空间非均匀周期性驱动，在Lipkin-Meshkov-Glick模型中实现不同空间区域具有不同时间晶体序的共存态


<details>
  <summary>Details</summary>
Motivation: 探索如何通过空间结构化的驱动协议来设计和实现新型时间晶体序，特别是能够在同一系统的不同空间区域实现不同时间晶体序的共存

Method: 使用半经典分析方法研究Lipkin-Meshkov-Glick模型在空间非均匀周期性驱动下的动力学，分析不同空间区域的时间晶体序稳定性

Result: 成功实现了不同空间区域具有不同次谐波响应频率的时间晶体序共存，在热力学极限下证明了这些共存时间晶体序的稳定性，并在量子涨落存在下也保持了稳定性

Conclusion: 空间结构化驱动是设计和实现新型时间晶体序的有效途径，为时间晶体工程提供了新的可能性

Abstract: We examine the distinct discrete time crystals (DTCs) that emerge in the Lipkin-Meshkov-Glick model, subjected to spatially nonuniform periodic driving. Intriguingly, we demonstrate that by appropriately tailoring the drive protocol, distinct DTC orders can be realized in different spatial regions of the system. Consequently, the system exhibits spatially varying sub-harmonic responses with distinct frequencies. We employ a semi-classical analysis to establish the stability of these co-existing DTC orders in the thermodynamic limit. Furthermore, we establish the stability of the stability of these co-existing DTCs in the presence of quantum fluctuations. Our results establish spatially structured driving as a powerful route to engineer novel forms of time-crystalline order.

</details>


### [170] [Single-LED-pumped, room-temperature, solid-state maser](https://arxiv.org/abs/2512.20611)
*Michael Newns,Shirley Xu,Mingyang Liu,Zike Cheng,Zike Cheng,Ziqiu Huang,Max Attwood,Mark Oxborrow*

Main category: quant-ph

TL;DR: 研究人员使用芯片级LED和波导嵌入式光学泵浦，在室温下实现了小型化固态微波激射器振荡


<details>
  <summary>Details</summary>
Motivation: 传统光学泵浦固态微波激射器（OPSS maser）的泵浦源尺寸通常主导整个系统尺寸，限制了其小型化和集成化应用潜力

Method: 采用芯片级LED作为泵浦源，通过波导将光直接嵌入到五苯掺杂对三联苯晶体中，实现侵入式光学泵浦，结合实验测量和光线追踪分析

Result: 成功实现了微波激射器振荡，系统尺寸显著减小，与传统端面泵浦相比，合作性提高了至少2倍

Conclusion: 这种基于芯片级LED和波导嵌入式泵浦的方法为室温固态微波激射器的小型化和集成化开辟了新途径，有望推动其在量子传感器、振荡器和放大器中的应用

Abstract: Through their ability to achieve `cryogenic' levels of noise performance while operating at room temperature, optically-pumped, solid-state (OPSS) masers show great promise as quantum sensors, oscillators, and amplifiers. We here demonstrate maser oscillation in a microwave cavity containing a crystal of pentacene-doped \textit{para}-terphenyl (ptc:ptp) pumped by a single, chip-scale LED. Here, unlike previous work, the size of the pump source no longer dominates the size of the maser system as a whole. This miniaturization is achieved through invasive optical pumping in the form of a waveguide, the tip of which is embedded into the maser crystal. Combining experimental measurements with ray-tracing analysis, we find that our approach offers at least a factor of 2 enhancement in the cooperativity over end-on optical excitation.

</details>


### [171] [Tunably realizing flat-bands and exceptional points in kinetically frustrated systems: An example on the non-Hermitian Creutz ladder](https://arxiv.org/abs/2512.20614)
*Debashish Dutta,Sayan Choudhury*

Main category: quant-ph

TL;DR: 非厄米Creutz梯子的扩展研究，揭示了周期性边界和开放边界条件下不同的谱结构和相图特征


<details>
  <summary>Details</summary>
Motivation: 研究非厄米Creutz梯子模型在非互易跃迁下的谱特性，探索非厄米系统中实-复谱转变、异常点和能带结构的独特行为

Method: 将Creutz梯子映射到两个解耦的非厄米SSH链，在不同边界条件下进行解析和数值分析，包括周期性边界条件的谱分析和开放边界条件的精确对角化

Result: 发现周期性边界条件下存在精细调谐线产生全实谱，偏离时发生实-复谱转变；开放边界条件下存在纯实谱、纯虚谱和复谱区域，由异常线分隔，交点形成三连接点；平带可作为厄米简并点或非厄米异常平带出现

Conclusion: 非厄米Creutz梯子展现出丰富的谱结构和相图特征，边界条件对系统行为有显著影响，非厄米平带比厄米情况具有更严格的动力学约束和独特的谱特征

Abstract: We study a non-Hermitian extension of the Creutz ladder with generic non-reciprocal hopping. By mapping the ladder onto two decoupled non-Hermitian Su--Schrieffer--Heeger (SSH) chains, we uncover a rich structure in parameter space under different boundary conditions. Under periodic boundary conditions, the spectrum admits a fine-tuned line in parameter space with entirely real eigenvalues, while deviations from this line induce a real--complex spectral transition without crossing exceptional points. In contrast, an exact analytical diagonalization under open boundary conditions reveals extended regions in parameter space with purely real or purely imaginary spectra, separated from complex spectral domains by exceptional lines. The intersections of these exceptional lines define triple-junction points where distinct spectral regimes meet, giving rise to a structured phase diagram that is absent under periodic boundary conditions. We further show that flat bands in this system can occur both as Hermitian diabolical points and as non-Hermitian exceptional points, known as exceptional flat bands, where the dynamics is more stringent than in the Hermitian case, leading to distinct spectral and dynamical signatures.

</details>
