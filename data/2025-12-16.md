<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 77]
- [cs.LG](#cs.LG) [Total: 165]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [gr-qc](#gr-qc) [Total: 30]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Entanglement Evolution of Noisy Quantum Systems: Master Equation-TFD Solutions](https://arxiv.org/abs/2512.11932)
*Urjjarani Patel,KVS Shiv Chaitanya*

Main category: quant-ph

TL;DR: 应用热场动力学将量子光学非线性主方程映射为薛定谔方程，并用Hartree-Fock近似解析求解两个噪声量子系统的主方程，分析纠缠和量子互信息


<details>
  <summary>Details</summary>
Motivation: 为更高效地解决开放量子系统问题，需要一种将非线性主方程映射为薛定谔方程的方法，以便分析噪声量子系统中的纠缠和量子互信息

Method: 1. 应用热场动力学将量子光学非线性主方程映射为薛定谔方程；2. 使用Hartree-Fock近似解析求解两个噪声量子系统的主方程；3. 通过协方差矩阵特征值分析纠缠和量子互信息；4. 研究双模和单模压缩态

Result: 开发了一种更高效的开放量子系统求解方法，能够解析求解噪声量子系统的主方程，并分析系统中的纠缠特性和量子互信息

Conclusion: 热场动力学结合Hartree-Fock近似为分析噪声量子系统的纠缠和量子互信息提供了有效的解析方法，对量子光学和开放量子系统研究有重要意义

Abstract: In this paper, Thermofield Dynamics (TFD) is applied to map a quantum optics nonlinear master equation into a Schrodinger-like equation for any arbitrary initial condition. This formalism provides a more efficient way for solving open quantum system problems. Then we use the Hartree-Fock approximation to solve the master equations of two separate noisy quantum systems analytically, which allows us to analyze the entanglement and quantum mutual information in each case using the eigenvalues of a covariance matrix, followed by two-mode and single-mode squeezed states.

</details>


### [2] [Quantum circuits for permutation matrices](https://arxiv.org/abs/2512.11938)
*Jason Hanson*

Main category: quant-ph

TL;DR: 提出两种量子电路算法，用于实现2^n个字母的置换矩阵，仅使用多控制Toffoli门，第一种需要辅助线，第二种无需辅助线但要求置换分解为汉明距离为1的转置乘积。


<details>
  <summary>Details</summary>
Motivation: 研究如何在量子电路中高效实现置换操作，特别是减少资源消耗（如辅助线），同时保持电路简洁性，这对于量子计算中的数据处理和算法实现具有重要意义。

Method: 提出两种算法：1）基于任意转置分解的电路构造，使用一条辅助线；2）基于汉明距离为1的转置分解的电路构造，无需辅助线。证明任何置换都允许第二种分解，并提供减少转置数量的策略。

Result: 成功设计出两种仅使用多控制Toffoli门的量子电路实现置换矩阵，第一种方法通用但需要辅助线，第二种方法无需辅助线但要求特定分解，并证明了所有置换都满足该分解条件。

Conclusion: 为量子计算中的置换操作提供了两种有效的电路实现方案，特别是不需要辅助线的方案具有更好的资源效率，同时提供了优化转置数量的策略，有助于实际量子电路设计。

Abstract: Two different algorithms are presented for generating a quantum circuit realization of a matrix representing a permutation on $2^n$ letters. All circuits involve $n$ qubits and only use multi--controlled Toffoli gates. The first algorithm constructs a circuit from any decomposition of the permutation into a product of transpositions, but uses one ancilla line. The second, which uses no ancillae, constructs a circuit from a decomposition into a product of transpositions that have a Hamming distance of one. We show that any permutation admits such a decomposition, and we give a strategy for reducing the number of transpositions involved.

</details>


### [3] [Convergence of the Cumulant Expansion and Polynomial-Time Algorithm for Weakly Interacting Fermions](https://arxiv.org/abs/2512.12010)
*Hongrui Chen,Cambyse Rouzé,Jielun Chen,Jiaqing Jiang,Samuel O. Scalet,Yongtao Zhan,Garnet Kin-Lic Chan,Lexing Ying,Yu Tong*

Main category: quant-ph

TL;DR: 提出随机算法计算弱相互作用费米子系统的对数配分函数，具有系统尺寸和精度的多项式时间复杂度


<details>
  <summary>Details</summary>
Motivation: 虽然弱相互作用费米子系统通常被认为是可计算的（如图形量子蒙特卡洛），但缺乏数学上严格的多项式时间复杂度证明

Method: 扩展周期系统的累积展开收敛性证明到非周期情况；利用树行列式展开揭示费曼图求和中的树结构；设计基于重要性采样和置信传播的随机算法

Result: 获得具有可证明多项式运行时间的算法，不同于传统马尔可夫链蒙特卡洛方法

Conclusion: 为弱相互作用费米子系统提供了首个具有严格多项式时间复杂度保证的计算对数配分函数的随机算法

Abstract: We propose a randomized algorithm to compute the log-partition function of weakly interacting fermions with polynomial runtime in both the system size and precision. Although weakly interacting fermionic systems are considered tractable for many computational methods such as the diagrammatic quantum Monte Carlo, a mathematically rigorous proof of polynomial runtime has been lacking. In this work we first extend the proof techniques developed in previous works for proving the convergence of the cumulant expansion in periodic systems to the non-periodic case. A key equation used to analyze the sum of connected Feynman diagrams, which we call the tree-determinant expansion, reveals an underlying tree structure in the summation. This enables us to design a new randomized algorithm to compute the log-partition function through importance sampling augmented by belief propagation. This approach differs from the traditional method based on Markov chain Monte Carlo, whose efficiency is hard to guarantee, and enables us to obtain a algorithm with provable polynomial runtime.

</details>


### [4] [Holographic Representation of One-Dimensional Many-Body Quantum States via Isometric Tensor Networks](https://arxiv.org/abs/2512.11967)
*Kaito Kobayashi,Benjamin Sappler,Frank Pollmann*

Main category: quant-ph

TL;DR: 提出全息等距张量网络态（holographic isoTNS），将等距张量网络从高维带回一维，通过引入全息轴增强表达能力，能在适度键维下实现体积极律纠缠，超越矩阵乘积态的限制。


<details>
  <summary>Details</summary>
Motivation: 等距张量网络态（isoTNS）在高维量子系统模拟中表现出色，但在一维系统中应用有限。研究旨在将isoTNS的优势带回一维，通过引入全息几何结构增强表达能力，突破传统矩阵乘积态在表示高度纠缠态方面的限制。

Method: 提出全息isoTNS架构：在(1+1)维格点上构建等距张量网络，水平轴编码物理空间，垂直"全息"轴增强表达能力。利用等距约束保持计算效率，实现局部更新和收缩。开发了时间演化块解耦算法（TEBD）用于全息isoTNS的动力学模拟。

Result: 1）随机初始化的全息isoTNS在适度键维下即表现出体积极律纠缠；2）能精确表示任意费米子高斯态、Clifford态和局部演化短时态；3）TEBD算法保持高效可扩展，但误差累积会抑制纠缠并导致与精确动力学的快速偏离。

Conclusion: 全息isoTNS扩展了张量网络方法的适用范围，为研究体积极律区域的物理现象开辟了新途径，在表示高度纠缠但低复杂度的量子态方面具有独特优势。

Abstract: Isometric tensor network states (isoTNS) allow for efficient and accurate simulations of higher-dimensional quantum systems by enforcing an isometric structure. We bring this idea back to one dimension by introducing a holographic isoTNS ansatz: a (1+1)-dimensional lattice of isometric tensors where the horizontal axis encodes physical space and an auxiliary "holographic" axis boosts expressivity. Despite the enlarged geometry, contractions and local updates remain computationally efficient due to isometric constraints. We investigate this ansatz and benchmark it in comparison to matrix product states (MPS). First, we show that randomly initialized holographic isoTNS typically display volume-law entanglement even at modest bond dimension, surpassing the representational limits of MPS and related ansätze. Second, through analytic constructions and variational optimization, we demonstrate that holographic isoTNS can faithfully represent arbitrary fermionic Gaussian states, Clifford states, and certain short-time-evolved states under local evolution -- a family of states that is highly entangled but low in complexity. Third, to exploit this expressivity in broad situations, we implement a time-evolving block decimation (TEBD) algorithm on holographic isoTNS. While the method remains efficient and scalable, error accumulation over TEBD sweeps suppresses entanglement and leads to rapid deviations from exact dynamics. Overall, holographic isoTNS broaden the reach of tensor-network methods, opening new avenues to study physics in the volume-law regime.

</details>


### [5] [Uniform matrix product states with a boundary](https://arxiv.org/abs/2512.11968)
*Marta Florido-Llinàs,Álvaro M. Alhambra,David Pérez-García,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 该论文为带边界矩阵的均匀矩阵乘积态（MPS）引入了广义规范形式，将分析MPS框架扩展到更广泛的物理相关状态，揭示了此类MPS可表示为作用于代数正则语言状态的块可逆矩阵乘积算子。


<details>
  <summary>Details</summary>
Motivation: 现有规范形式理论仅适用于周期性边界条件的均匀MPS，许多物理相关状态无法被涵盖。需要将分析MPS框架扩展到更一般的边界设置，以处理更广泛的物理状态。

Method: 引入带边界矩阵的均匀MPS的广义规范形式，基于非半单矩阵集生成的空间和代数的代数结果，包括给出阻塞长度显式上界的广义量子Wielandt不等式。

Result: 建立了带边界均匀MPS的统一理论基础，证明任何此类MPS可表示为作用于捕获其长程和尺度不变特征的代数正则语言状态的块可逆矩阵乘积算子。

Conclusion: 该工作填补了周期性和任意边界设置之间的理论空白，为将矩阵乘积态的关键分析和分类结果扩展到更广泛的状态和算子类别奠定了基础。

Abstract: Canonical forms are central to the analytical understanding of tensor network states, underpinning key results such as the complete classification of one-dimensional symmetry-protected topological phases within the matrix product state (MPS) framework. Yet, the established theory applies only to uniform MPS with periodic boundary conditions, leaving many physically relevant states beyond its reach. Here we introduce a generalized canonical form for uniform MPS with a boundary matrix, thus extending the analytical MPS framework to a more general setting of wider physical significance. This canonical form reveals that any such MPS can be represented as a block-invertible matrix product operator acting on a structured class of algebraic regular language states that capture its essential long-range and scale-invariant features. Our construction builds on new algebraic results of independent interest that characterize the span and algebra generated by non-semisimple sets of matrices, including a generalized quantum Wielandt's inequality that gives an explicit upper bound on the blocking length at which the fixed-length span stabilizes to an algebra. Together, these results establish a unified theoretical foundation for uniform MPS with boundaries, bridging the gap between periodic and arbitrary-boundary settings, and providing the basis for extending key analytical and classification results of matrix product states to a much broader class of states and operators.

</details>


### [6] [A Joint Quantum Computing, Neural Network and Embedding Theory Approach for the Derivation of the Universal Functional](https://arxiv.org/abs/2512.13138)
*Martin J. Uttendorfer,Daniel Barragan-Yani,Matthias Sperl,Marc Landmann*

Main category: quant-ph

TL;DR: 提出一种结合量子计算、机器学习和约化密度矩阵泛函理论的新方法，通过量子算法训练深度神经网络来获取通用泛函，并利用密度矩阵嵌入理论扩展泛函的适用范围。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算的潜力改进相互作用量子粒子的模拟，通过开发通用泛函实现量子计算在量子化学和凝聚态物理中的累积量子优势。

Method: 使用量子算法训练深度神经网络获取通用泛函，结合密度矩阵嵌入理论中的片段-浴系统，扩展泛函在哈密顿量空间中的适用范围。

Result: 开发了一种方法，一旦获得通用泛函，可以在相互作用相同的任何系统中重复使用，无需额外量子资源，为实现累积量子优势提供了途径。

Conclusion: 该方法展示了利用量子计算、机器学习和泛函理论交叉领域来改进量子模拟的潜力，为量子化学和凝聚态物理的量子计算应用开辟了新方向。

Abstract: We introduce a novel approach that exploits the intersection of quantum computing, machine learning and reduced density matrix functional theory to leverage the potential of quantum computing to improve simulations of interacting quantum particles. Our method focuses on obtaining the universal functional using a deep neural network trained with quantum algorithms. We also use fragment-bath systems defined by density matrix embedding theory to strengthen our approach by substantially expanding the space of Hamiltonians for which the obtained functional can be applied without the need for additional quantum resources. Given the fact that once obtained, the same universal functional can be reused for any system where the interactions within the embedded fragment are identical, our work demonstrates a way to potentially achieve a cumulative quantum advantage within quantum computing applications for quantum chemistry and condensed matter physics.

</details>


### [7] [Cavity Mediated Two-Qubit Gate: Tuning to Optimal Performance with NISQ Era Quantum Simulations](https://arxiv.org/abs/2512.12030)
*Shreekanth S. Yuvarajan,Vincent Iglesias-Cardinale,David Hucul,Herbert F. Fotso*

Main category: quant-ph

TL;DR: 本文提出了一种基于量子电路的算法，用于模拟腔介导的两量子比特门，该算法兼容NISQ设备，能够可靠地追踪系统动力学并识别最优参数区域。


<details>
  <summary>Details</summary>
Motivation: 光子介导的操作对于可扩展量子信息处理平台至关重要，但现有分析方法受限于近似技术或计算规模。量子处理器为解决这些挑战提供了新途径。

Method: 开发了兼容NISQ时代的量子算法，通过量子电路模拟腔介导的两量子比特门动力学，能够映射量子态传输保真度随系统参数的变化。

Result: 算法提供了稳健直观的解决方案，与解析解或经典模拟算法在各自有效范围内有良好一致性，并识别出远失谐量子比特间仍能有效工作的未充分探索的最优参数区域。

Conclusion: 该方法不仅适用于当前应用，还能高效用于模型的其他难以处理的变体，有助于模拟和优化光子介导的两量子比特门及其他量子信息处理相关操作。

Abstract: A variety of photon-mediated operations are critical to the realization of scalable quantum information processing platforms and their accurate characterization is essential for the identification of optimal regimes and their experimental realizations. Such light-matter interactions are often studied with a broad variety of analytical and computational methods that are constrained by approximation techniques or by computational scaling. Quantum processors present a new avenue to address these challenges. We consider the case of cavity mediated two-qubit gates. To investigate quantum state transfer between the qubits, we implement simulations with quantum circuits that are able to reliably track the dynamics of the system. Our quantum algorithm, compatible with NISQ (Noisy Intermediate Scale Quantum) era systems, allows us to map out the fidelity of the state transfer operation between qubits as a function of a broad range of system parameters including the respective detunings between the qubits and the cavity, the damping factor of the cavity, and the respective couplings between the qubits and the cavity. The algorithm provides a robust and intuitive solution, alongside a satisfactory agreement with analytical solutions or classical simulation algorithms in their respective regimes of validity. It allows us to identify under-explored regimes of optimal performance, relevant for heterogeneous quantum platforms, where the two-qubit gate can be rather effective between far-detuned qubits that are neither resonant with each other nor with the cavity. Besides its present application, the method introduced in the current paper can be efficiently used in otherwise untractable variations of the model and in various efforts to simulate and optimize photon-mediated two-qubit gates and other relevant operations in quantum information processing.

</details>


### [8] [Quantum-enhanced biosensing enables earlier detection of bacterial growth](https://arxiv.org/abs/2512.12057)
*Rayssa B. de Andrade,Anne Egholm Høgh,Gaetana Spedalieri,Stefano Pirandola,Kirstine Berg-Sørensen,Tobias Gehring,Ulrik L. Andersen*

Main category: quant-ph

TL;DR: 首次实验演示量子增强光度测量用于早期细菌检测，使用压缩光实现超越散粒噪声极限的灵敏度，比经典传感器提前30分钟检测到细菌生长


<details>
  <summary>Details</summary>
Motivation: 临床、食品安全和环境监测中需要快速检测细菌生长，但传统光学方法受噪声限制且需要数小时培养时间

Method: 使用压缩光作为量子探针监测大肠杆菌培养物的光学吸收度，通过截断高斯分布的统计建模和假设检验验证噪声降低

Result: 实现超越散粒噪声极限的灵敏度，比经典传感器提前30分钟检测到细菌生长起始，同时保持低误报率

Conclusion: 这项工作展示了量子资源如何改善实时、非侵入性诊断，为量子增强生物传感器铺平道路，可加速微生物生长和其他生物过程的检测而不增加光损伤

Abstract: Rapid detection of bacterial growth is crucial in clinical, food safety, and environmental contexts, yet conventional optical methods are limited by noise and require hours of incubation. Here, we present the first experimental demonstration of a quantum-enhanced photometric measurement for early bacterial detection using squeezed light. By monitoring the optical absorbance of an Escherichia coli culture with a quantum probe, we achieve a sensitivity beyond the shot-noise limit, enabling identification of growth onset up to 30 minutes earlier than with a classical sensor. The noise reduction is validated through statistical modeling with a truncated Gaussian distribution and hypothesis testing, confirming earlier detection with low false-alarm rates. This work illustrates how quantum resources can improve real-time, non-invasive diagnostics. Our results pave the way for quantum-enhanced biosensors that accelerate detection of microbial growth and other biological processes without increasing photodamage.

</details>


### [9] [TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms](https://arxiv.org/abs/2512.12068)
*Yuewen Hou,Dhanvi Bharadwaj,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: TreeVQA：基于树结构的变分量子算法执行框架，通过利用应用任务间的执行相似性，将平均执行次数减少25.9倍，大规模问题可减少100倍以上。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法（VQAs）在近中期量子计算中很有前景，但执行成本极高。每个任务需要多次迭代和大量电路，实际应用涉及多个任务，需要探索能量景观的精度，导致执行次数巨大，实际使用成本过高。

Method: 提出TreeVQA框架，利用应用任务间的执行相似性，采用树状执行策略：开始时联合执行任务，仅当量子执行路径出现分歧时才逐步分支。该框架作为VQA包装器实现，可与典型VQA应用集成。

Result: 在科学和组合基准测试中，在相同目标精度下，平均减少25.9倍执行次数，大规模问题可减少100倍以上。随着问题规模和精度要求增加，优势进一步扩大。

Conclusion: TreeVQA通过利用VQA任务间的执行相似性，显著降低了执行成本，使变分量子算法在实际应用中更加可行和经济。

Abstract: Variational Quantum Algorithms (VQAs) are promising for near- and intermediate-term quantum computing, but their execution cost is substantial. Each task requires many iterations and numerous circuits per iteration, and real-world applications often involve multiple tasks, scaling with the precision needed to explore the application's energy landscape. This demands an enormous number of execution shots, making practical use prohibitively expensive. We observe that VQA costs can be significantly reduced by exploiting execution similarities across an application's tasks. Based on this insight, we propose TreeVQA, a tree-based execution framework that begins by executing tasks jointly and progressively branches only as their quantum executions diverge. Implemented as a VQA wrapper, TreeVQA integrates with typical VQA applications. Evaluations on scientific and combinatorial benchmarks show shot count reductions of $25.9\times$ on average and over $100\times$ for large-scale problems at the same target accuracy. The benefits grow further with increasing problem size and precision requirements.

</details>


### [10] [Proof of Spin-Statistics Theorem in Quantum Mechanics of Identical Particles](https://arxiv.org/abs/2512.12071)
*Takafumi Kita*

Main category: quant-ph

TL;DR: 提出了一种非相对论性的自旋统计定理证明，通过坐标空间中的场算符满足对易和反对易关系，将置换对称性纳入全同粒子的括号中。


<details>
  <summary>Details</summary>
Motivation: 传统自旋统计定理的证明通常依赖于相对论性框架，本文旨在提供一个纯粹非相对论性的证明方法，通过场算符的对易/反对易关系直接建立自旋与统计之间的联系。

Method: 在坐标空间中引入满足对易和反对易关系的场算符，将置换对称性构建到全同粒子的括号中。结合π旋转下两个湮灭算符乘积的本征值问题及其旋转特性分析，证明积分自旋和半整数自旋粒子的场算符分别满足对易和反对易关系。

Result: 成功证明了在非相对论框架下，积分自旋粒子的场算符满足对易关系（玻色统计），而半整数自旋粒子的场算符满足反对易关系（费米统计），建立了自旋与统计之间的直接联系。

Conclusion: 该工作提供了一个不依赖于相对论性假设的自旋统计定理证明，通过坐标空间中的场算符方法和π旋转分析，为理解全同粒子的统计行为提供了新的非相对论性视角。

Abstract: A nonrelativistic proof of the spin-statistics theorem is given in terms of the field operators satisfying commutation and anticommutation relations, which are introduced here in the coordinate space as a means to build the permutation symmetry into the brackets of identical particles. An eigenvalue problem of a $π$-rotation for a product of two annihilation operators is combined with an analysis on its rotational property to prove the connection that the field operators for integral-spin and half-integral-spin particles obey the commutation and anticommutation relations, respectively.

</details>


### [11] [The PPKN Gate: An Optimal 1-Toffoli Input-Preserving Full Adder for Quantum Arithmetic](https://arxiv.org/abs/2512.12073)
*G. Papakonstantinou*

Main category: quant-ph

TL;DR: 提出PPKN门作为新型可逆全加器，相比标准HNG门具有更低量子成本(10 vs 12)和更小逻辑深度(4 vs 5)，并展示了基于PPKN模块的n位脉动进位加法器架构


<details>
  <summary>Details</summary>
Motivation: 量子计算需要高效算术运算，现有HNG门作为标准输入保持可逆全加器存在量子成本高(12)和逻辑深度大(5)的问题，需要更优设计

Method: 提出PPKN门设计，仅使用1个Toffoli门和5个CNOT门实现输入保持功能；构建模块化架构，通过级联PPKN模块实现n位脉动进位加法器

Result: PPKN门量子成本降至10，逻辑深度减至4，在复杂度和速度上均优于标准HNG门；成功构建了n位脉动进位加法器架构

Conclusion: PPKN门为可逆全加器提供了更高效的替代方案，降低了量子成本并提高了执行速度，为实用量子计算中的算术运算优化做出了贡献

Abstract: Efficient arithmetic operations are a prerequisite for practical quantum computing. Optimization efforts focus on two primary metrics: Quantum Cost (QC), determined by the number of non-linear gates, and Logical Depth, which defines the execution speed. Existing literature identifies the HNG gate as the standard for Input-Preserving Reversible Full Adders. HNG gate typically requires a QC of 12 and a logical depth of 5, in the area of classical reversible circuits. This paper proposes the PPKN Gate, a novel design that achieves the same inputpreserving functionality using only one Toffoli gate and five CNOT gates. With a Quantum Cost of 10 and a reduced logical depth of 4, the PPKN gate outperforms the standard HNG gate in both complexity and speed. Furthermore, we present a modular architecture for constructing an n-bit Ripple Carry Adder by cascading PPKN modules.

</details>


### [12] [Leveraging Symmetry Merging in Pauli Propagation](https://arxiv.org/abs/2512.12094)
*Yanting Teng,Su Yeon Chang,Manuel S. Rudolph,Zoë Holmes*

Main category: quant-ph

TL;DR: 提出基于对称性合并的Pauli传播算法，通过合并对称群作用下的冗余Pauli字符串，减少模拟量子动力学的计算复杂度


<details>
  <summary>Details</summary>
Motivation: 量子电路具有对称性时，许多Pauli字符串在对称群作用下会冗余演化，可以利用这种对称性来减少模拟的计算资源需求

Method: 提出对称性合并Pauli传播算法，通过合并通过对称变换相关的Pauli字符串，仅传播轨道代表的最小集合，利用群论框架

Result: 分析表明对称性合并将空间复杂度降低轨道大小的倍数，平移和置换对称性有明确增益；全连接海森堡动力学数值基准显示在截断和噪声下稳定性改善

Conclusion: 建立了增强Pauli传播的群论框架，开源代码展示了其在经典量子动力学模拟中的实际相关性

Abstract: We introduce a symmetry-adapted framework for simulating quantum dynamics based on Pauli propagation. When a quantum circuit possesses a symmetry, many Pauli strings evolve redundantly under actions of the symmetry group. We exploit this by merging Pauli strings related through symmetry transformations. This procedure, formalized as the symmetry-merging Pauli propagation algorithm, propagates only a minimal set of orbit representatives. Analytically, we show that symmetry merging reduces space complexity by a factor set by orbit sizes, with explicit gains for translation and permutation symmetries. Numerical benchmarks of all-to-all Heisenberg dynamics confirm improved stability, particularly under truncation and noise. Our results establish a group-theoretic framework for enhancing Pauli propagation, supported by open-source code demonstrating its practical relevance for classical quantum-dynamics simulations.

</details>


### [13] [Symmetry Dilemmas in Quantum Computing for Chemistry: A Comprehensive Analysis](https://arxiv.org/abs/2512.12097)
*Ilias Magoulas,Muhan Zhang,Francesco A. Evangelista*

Main category: quant-ph

TL;DR: 该论文分析了量子算法中对称性适应、通用性和门效率之间的权衡困境，证明了流行的单重态自旋适应单激发和完美配对双激发算子池在空间对称性强制下不具有通用性，并通过数值模拟提供了实用指南。


<details>
  <summary>Details</summary>
Motivation: 量子算法在电子结构和多体物理应用中面临对称性适应、通用性和门效率之间的核心矛盾：完全对称适应的通用算子池通常产生长而深的量子电路，门效率高的通用算子池通常破坏对称性，而门效率高且完全对称适应的算子池可能不具备通用性。需要分析这种对称性困境。

Method: 从理论和数值两方面分析对称性困境。理论上证明流行的门效率高的算子池（单重态自旋适应单激发和完美配对双激发）在空间对称性强制下不具有通用性。数值上使用自适应算法配合三种类型的算子池进行模拟：(i)完全对称适应且通用，(ii)完全对称适应但不通用，(iii)破坏单一对称性但通用。模拟涵盖三种物理相关场景。

Result: 理论证明显示流行的门效率高的算子池在空间对称性强制下确实不具有通用性。数值结果表明：对称破坏但通用的算子池在某些情况下可以安全使用；在某些情况下强制至少一个区分性对称性就足够了；在某些情况下必须严格保持特定对称性以避免变分崩溃。

Conclusion: 该研究通过理论和数值分析为设计平衡通用性、资源需求和鲁棒状态靶向的对称适应算子池提供了实用指南，帮助在量子化学模拟中做出明智选择。

Abstract: Symmetry adaptation, universality, and gate efficiency are central but often competing requirements in quantum algorithms for electronic structure and many-body physics. For example, fully symmetry-adapted universal operator pools typically generate long and deep quantum circuits, gate-efficient universal operator pools generally break symmetries, and gate-efficient fully symmetry-adapted operator pools may not be universal. In this work, we analyze such symmetry dilemmas both theoretically and numerically. On the theory side, we prove that the popular, gate-efficient operator pool consisting of singlet spin-adapted singles and perfect-pairing doubles is not universal when spatial symmetry is enforced. To demonstrate the strengths and weaknesses of the three types of pools, we perform numerical simulations using an adaptive algorithm paired with operator pools that are (i) fully symmetry-adapted and universal, (ii) fully symmetry-adapted and non-universal, and (iii) breaking a single symmetry and are universal. Our numerical simulations encompass three physically relevant scenarios in which the target state is (i) the global ground state, (ii) the ground state crossed by a state differing in multiple symmetry properties, and (iii) the ground state crossed by a state differing in a single symmetry property. Our results show when symmetry-breaking but universal pools can be used safely, when enforcing at least one distinguishing symmetry suffices, and when a particular symmetry must be rigorously preserved to avoid variational collapse. Together, the formal and numerical analysis provides a practical guide for designing and benchmarking symmetry-adapted operator pools that balance universality, resource requirements, and robust state targeting in quantum simulations for chemistry.

</details>


### [14] [Measurement as Sheafification: Context, Logic, and Truth after Quantum Mechanics](https://arxiv.org/abs/2512.12249)
*Partha Ghose*

Main category: quant-ph

TL;DR: 该论文将量子测量重新解释为预层真值的层化过程，而非物理上的幺正性破坏，通过范畴论和层论框架解决量子测量悖论。


<details>
  <summary>Details</summary>
Motivation: 传统量子测量理论存在逻辑矛盾：量子理论本质上是情境性的，而经典传统预设了单一的全局布尔赋值。作者旨在通过范畴论和层论框架重新解释测量过程，解决量子测量悖论和表观非定域性问题。

Method: 1. 将测量情境构建为预层范畴，其中全局截面的缺失表示情境独立描述的不可能性；2. 使用Čech上同调度量由此产生的障碍；3. 将预层topos的内部逻辑展示为直觉主义逻辑；4. 将Ghose和Patra的七值情境逻辑展示为有限Heyting代数；5. 提出受随机力学启发的σ-λ动力学，在强情境性和近似经典机制之间提供连续插值。

Result: 1. 量子测量被重新解释为预层真值的层化过程，而非物理上的幺正性破坏；2. 经典物理对应层情况，其中兼容的局部数据可以粘合，布尔逻辑有效恢复；3. 通常的测量悖论和表观非定域性被解释为对全局真理的非法要求的产物；4. 提供了从强情境性到近似经典机制的连续动力学插值。

Conclusion: 量子测量的核心问题不是动力学冲突，而是逻辑冲突。通过采用范畴论和层论框架，测量过程可以被理解为情境依赖真值的数学结构转变，从而消解传统测量悖论和非定域性表观问题，为量子理论提供更一致的基础。

Abstract: Quantum measurement is commonly posed as a dynamical tension between linear Schrödinger evolution and an ad hoc collapse rule. I argue that the deeper conflict is logical: quantum theory is inherently contextual, whereas the classical tradition presupposes a single global, Boolean valuation. Building on Bohr's complementarity, the Einstein--Podolsky--Rosen argument and Bell's theorem, I recast locality and completeness as the existence of a global section of a presheaf of value assignments over the category of measurement contexts. The absence of global sections expresses the impossibility of context-independent description, and Čech cohomology measures the resulting obstruction. The internal logic of the presheaf topos is intuitionistic, and the seven-valued contextual logic proposed by Ghose and Patra is exhibited as a finite Heyting algebra capturing patterns of truth, falsity and indeterminacy across incompatible contexts. Classical physics corresponds to the sheaf case, where compatible local data glue and Boolean logic is effectively restored. Measurement is therefore reinterpreted as sheafification of presheaf-valued truth rather than as a physical breakdown of unitarity. Finally, a $σ$--$λ$ dynamics motivated by stochastic mechanics provides a continuous interpolation between strongly contextual and approximately classical regimes, dissolving the usual measurement paradoxes and apparent nonlocality as artefacts of an illegitimate demand for global truth.

</details>


### [15] [Coherence Dispersion and Temperature Scales in a Quantum-Biology Toy Model](https://arxiv.org/abs/2512.12342)
*Fernando Parisio*

Main category: quant-ph

TL;DR: 量子相干性在量子态非对角元间的分散（相干色散Δ_c）在适当熵的中等值时达到最大，这是复杂系统量化指标的普遍特征。该框架应用于非平衡细胞能量学模型，发现ATP-ADP转换能量（30.5 kJ/mol）使Δ_c最大化的温度范围与单细胞生命存在的温度范围一致。


<details>
  <summary>Details</summary>
Motivation: 研究量子相干性在量子态非对角元间的分散特性，探索相干色散作为复杂系统量化指标的特征，并将其应用于非平衡系统特别是细胞能量学模型，以理解量子相干性在生命过程中的潜在作用。

Method: 定义相干色散（Δ_c）作为量子相干性在量子态非对角元间分散的度量，分析其数学特性。将该框架应用于包含剩余相干性的简化细胞能量学模型，研究ATP-ADP转换（30.5 kJ/mol）对相干色散温度依赖性的影响。

Result: 相干色散在适当熵的中等值时达到最大，这是复杂系统量化指标的普遍特征。在细胞能量学模型中，ATP-ADP转换的特定能量（30.5 kJ/mol）使相干色散最大化的温度范围与已知单细胞生命存在的温度范围（约0-100°C）一致，且仅需低水平的相干性即可支持这一结论。

Conclusion: 相干色散作为量子相干性分散的度量，展现了复杂系统量化指标的典型特征。在非平衡生物系统中，特定的生物能量转换过程（如ATP-ADP转换）可能通过量子相干性机制与生命存在的温度条件相关联，暗示量子效应可能在生命过程中发挥重要作用。

Abstract: In this work, we investigate how quantum coherence can scatter among the several off-diagonal elements of an arbitrary quantum state, defining coherence dispersion ($Δ_{\rm c}$). It turns out that this easily computable quantity is maximized for intermediate values of an appropriate entropy, a prevalent signature of complexity quantifiers across different fields, from linguistics and information science to evolutionary biology. By focusing on out-of-equilibrium systems, we use the developed framework to address a simplified model of cellular energetics, involving remanent coherence. Within the context of this model, the precise energy of 30.5 kJ/mol (the yield of ATP-ADP conversion) causes the temperature range where $Δ_{\rm c}$ is maximized to be compatible with temperatures for which unicellular life is reported to exist. Low levels of coherence suffice to support this conclusion.

</details>


### [16] [Imaging Walk-Off Driven Distortions in EPR Photon Pair Correlations](https://arxiv.org/abs/2512.12423)
*Christian Howard,Roohollah Ghobadi,Nazanin Dehghan,Alessio D'Errico,Ebrahim Karimi*

Main category: quant-ph

TL;DR: 薄晶体近似下通常假设双光子波函数可分解为和坐标与差坐标的独立函数，但实际中双折射引起的横向走离破坏了这种分解，即使在名义薄晶体中，自由空间传播也会导致和差坐标耦合，产生独特的锥形相关效应。


<details>
  <summary>Details</summary>
Motivation: 研究自发参量下转换产生的EPR态光子对的空间相关性。传统薄晶体近似假设双光子波函数可分解为和坐标与差坐标的独立函数，但实际中双折射引起的横向走离会破坏这种分解，需要更精确的描述。

Method: 考虑自由空间传播对联合空间强度的影响，分析名义薄晶体中和差坐标的耦合效应。通过数值模拟和实验数据验证这种耦合导致的独特锥形相关行为。

Result: 发现即使在名义薄晶体中，自由空间传播也会导致和差坐标耦合，产生晶体像平面附近横向相关的独特锥形效应。数值模拟和实验数据都明确证实了这一新行为。

Conclusion: 该研究提供了双折射非线性介质中光子对生成的更完整描述，阐明了使用EPR态进行空间分辨量子成像和空间模式量子信息处理的基本限制。

Abstract: Spontaneous parametric down-conversion is the primary source of position-correlated and momentum-anticorrelated photon pairs that form the canonical Einstein-Podolsky-Rosen (EPR) state. Their transverse spatial correlations are usually analyzed within the thin-crystal approximation, where the two-photon wavefunction is assumed to factorize into independent functions of the sum and difference coordinates. In practice, however, birefringence-induced transverse walk-off breaks this factorization and couples these degrees of freedom. Here, we show that this coupling persists even for nominally thin crystals once the free-space propagation of the joint spatial intensity is taken into account. This sum-difference coordinate coupling leads to a distinctive tapering of the transverse correlations near the crystal image plane-an effect that standard factorized models cannot capture. Numerical simulations and experimental data clearly confirm this novel behavior. Our findings provide a more complete description of photon-pair generation in birefringent nonlinear media and clarify fundamental limits on spatially resolved quantum imaging and spatial-mode quantum information processing with EPR states.

</details>


### [17] [Classical Second-Order Moments and Tensor Squeezing in Spin-1 Systems](https://arxiv.org/abs/2512.12504)
*K. S. Mallesh*

Main category: quant-ph

TL;DR: 该论文给出了单自旋-1粒子经典二阶矩的紧致、框架无关的表征，通过矩阵条件界定了经典矩区域，并提供了高阶张量非经典性的简单见证。


<details>
  <summary>Details</summary>
Motivation: 需要一种紧凑且框架无关的方法来表征自旋-1粒子的经典二阶矩，以区分经典和非经典行为，并为高阶张量非经典性提供简单见证。

Method: 定义矩矩阵 M = 2Q + (1/3)I，证明矩对(s, Q)来自自旋相干态的正混合当且仅当M半正定、M减去ss^T半正定且M的迹等于1。

Result: 得到了界定经典矩区域的充分必要条件，这些矩阵条件提供了高阶张量非经典性的简单、基无关见证，如Tr(Q^2)的界限。

Conclusion: 该工作为自旋-1粒子的经典二阶矩提供了紧凑、框架无关的表征，建立了区分经典和非经典行为的明确标准，并可用于检测高阶张量非经典性。

Abstract: We give a compact, frame-independent characterization of the set of classical second-order moments for a single spin-1 particle. Defining the moment matrix M = 2Q + (1/3) I, we show that a moment pair (s, Q) arises from a positive mixture of spin-coherent states if and only if M is positive semidefinite, M minus ss^T is positive semidefinite, and the trace of M equals one. These necessary and sufficient matrix conditions delimit the classical moment region and yield simple, basis-free witnesses of higher-order tensor nonclassicality, such as bounds on Tr(Q^2). A constructive proof of sufficiency is given in the appendix.

</details>


### [18] [A Comparative Study of Encoding Strategies for Quantum Convolutional Neural Networks](https://arxiv.org/abs/2512.12512)
*Xingyun Feng*

Main category: quant-ph

TL;DR: 比较三种量子卷积神经网络编码方案（角度、幅度、混合相位/角度）在噪声下的性能表现，为不同分辨率、噪声水平和计算预算下的编码选择提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 量子卷积神经网络（QCNN）是近期量子机器学习的有前景架构，但需要将经典数据编码到量子态中。编码方案的选择会显著影响性能和资源需求，特别是在噪声环境下。本研究旨在比较不同编码方案在噪声条件下的实际表现。

Method: 开发了完全可微分的PyTorch-Qiskit管道，包含自定义自动微分桥接、批处理参数偏移梯度和采样调度。在降采样的MNIST和Fashion-MNIST数据集（4×4和8×8分辨率）上训练QCNN，比较角度编码、幅度编码和混合相位/角度编码在去极化噪声下的表现。

Result: 在4×4分辨率下，角度编码获得更高准确率且对噪声更鲁棒；在8×8分辨率下，混合编码在中等噪声下能超越角度编码；幅度编码在轻量级和全分辨率配置中表现强劲，训练动态接近经典收敛。

Conclusion: 编码方案的选择取决于分辨率、噪声强度和计算预算的联合约束。角度编码在小分辨率下更优，混合编码在大分辨率下更有优势，幅度编码在轻量级配置中表现良好。这些结果为实际QCNN编码器选择提供了实用指导。

Abstract: Quantum convolutional neural networks (QCNNs) offer a promising architecture for near-term quantum machine learning by combining hierarchical feature extraction with modest parameter growth. However, any QCNN operating on classical data must rely on an encoding scheme to embed inputs into quantum states, and this choice can dominate both performance and resource requirements. This work presents an implementation-level comparison of three representative encodings -- Angle, Amplitude, and a Hybrid phase/angle scheme -- for QCNNs under depolarizing noise. We develop a fully differentiable PyTorch--Qiskit pipeline with a custom autograd bridge, batched parameter-shift gradients, and shot scheduling, and use it to train QCNNs on downsampled binary variants of MNIST and Fashion-MNIST at $4\times 4$ and $8\times 8$ resolutions.
  Our experiments reveal regime-dependent trade-offs. On aggressively downsampled $4\times 4$ inputs, Angle encoding attains higher accuracy and remains comparatively robust as noise increases, while the Hybrid encoder trails and exhibits non-monotonic trends. At $8\times 8$, the Hybrid scheme can overtake Angle under moderate noise, suggesting that mixed phase/angle encoders benefit from additional feature bandwidth. Amplitude-encoded QCNNs are sparsely represented in the downsampled grids but achieve strong performance in lightweight and full-resolution configurations, where training dynamics closely resemble classical convergence. Taken together, these results provide practical guidance for choosing QCNN encoders under joint constraints of resolution, noise strength, and simulation budget.

</details>


### [19] [Opportunistic Scheduling for Single-downlink Satellite-based Quantum Key Distribution](https://arxiv.org/abs/2512.12514)
*Md Zakir Hossain,Nitish K. Panigrahy,Walter O. Krawec,Don Towsley,Bing Wang*

Main category: quant-ph

TL;DR: 本文提出了一种针对单下行链路架构卫星量子密钥分发系统的机会主义调度方法，在考虑地面站对之间公平性的同时，利用动态卫星信道最大化系统性能。


<details>
  <summary>Details</summary>
Motivation: 卫星量子密钥分发是实现全球规模QKD最有前景的方向之一。单下行链路架构虽然安全性较弱（卫星需作为可信节点），但具有更高密钥率和为相距较远地面站对生成密钥的优势。目前该架构下的卫星调度问题尚未被研究。

Method: 提出了一种新颖的机会主义调度方法，在考虑地面站对之间公平性的同时，充分利用动态卫星信道特性来最大化系统性能。

Result: 在多种设置下评估该方法，证明其在总密钥率和地面站对间最小密钥率方面提供了最佳权衡。评估还强调了考虑季节效应和云层覆盖对卫星QKD系统评估的重要性。

Conclusion: 该机会主义调度方法为单下行链路架构卫星QKD系统提供了有效的解决方案，展示了在全局和区域QKD系统中的不同权衡，并突出了环境因素对系统性能评估的关键影响。

Abstract: Satellite-based quantum key distribution (QKD), leveraging low photon loss in free-space quantum communication, is widely regarded as one of the most promising directions to achieve global-scale QKD. With a constellation of satellites and a set of ground stations in a satellite-based QKD system, how to schedule satellites to achieve efficient QKD is an important problem. This problem has been studied in the dual-downlink architecture, where each satellite distributes pairs of entanglements to two ground stations simultaneously. However, it has not been studied in the single downlink architecture, where satellites create keys with each individual ground station, and then serve as trusted nodes to create keys between pairs of ground stations. While the single downlink architecture provides weaker security in that the satellites need to be trusted, it has many advantages, including the potential of achieving significantly higher key rates, and generating keys between pairs of ground stations that are far away from each other and cannot be served using the dual-downlink architecture. In this paper, we propose a novel opportunistic approach for satellite scheduling that accounts for fairness among the ground station pairs, while taking advantage of the dynamic satellite channels to maximize the system performance. We evaluate this approach in a wide range of settings and demonstrate that it provides the best tradeoffs in terms of total and minimum key rates across the ground station pairs. Our evaluation also highlights the importance of considering seasonal effects and cloud coverage in evaluating satellite-based QKD systems. In addition, we show different tradeoffs in global and regional QKD systems.

</details>


### [20] [Robustness analysis in static and dynamic quantum state tomography](https://arxiv.org/abs/2512.12518)
*Alan Chen,Shuixin Xiao,Hailan Ma,Daoyi Dong*

Main category: quant-ph

TL;DR: 该论文研究了量子态层析在测量设备和哈密顿量存在有界误差情况下的鲁棒性，推导了静态和动态场景下的MSE上界，并通过数值模拟验证了这些界随资源扩展的规律。


<details>
  <summary>Details</summary>
Motivation: 量子态层析是量子系统识别的核心任务，但实际实验条件常偏离标称设计，导致测量设备和系统动力学哈密顿量都存在误差。需要研究量子态层析对这些扰动的鲁棒性。

Method: 使用线性回归估计方法，在静态和动态两种场景下，推导测量设备和哈密顿量有界误差对均方误差(MSE)上界的显式界。通过量子比特系统的数值模拟验证理论结果。

Result: 推导出了量化测量设备和哈密顿量有界误差如何影响MSE上界的显式界。数值模拟展示了这些界如何随资源（如测量次数）扩展，为量子态层析的鲁棒性提供了理论保证。

Conclusion: 量子态层析对测量设备和哈密顿量的有界误差具有鲁棒性，理论界为实际实验条件下的量子态层析性能提供了量化评估工具。

Abstract: Quantum state tomography is a core task in quantum system identification. Real experimental conditions often deviate from nominal designs, introducing errors in both the measurement devices and the Hamiltonian governing the system's dynamics. In this paper, we investigate the robustness of quantum state tomography against such perturbations in both static and dynamic settings using linear regression estimation. We derive explicit bounds that quantify how bounded errors in the measurement devices and the Hamiltonian affect the mean squared error (MSE) upper bound in each scenario. Numerical simulations for qubit systems illustrate how these bounds scale with resources.

</details>


### [21] [Quantum Encoding of Three-Dimensional Ligand Poses for Exhaustive Configuration Enumeration](https://arxiv.org/abs/2512.12573)
*Pei-Kun Yang*

Main category: quant-ph

TL;DR: 该论文提出了一种量子原生分子对接方法，通过量子态编码配体在三维网格上的占据情况，利用辅助量子比特控制多步平移和旋转变换，一次性生成所有空间构型，为量子加速虚拟筛选提供可扩展基础。


<details>
  <summary>Details</summary>
Motivation: 传统分子对接受限于配体平移和旋转自由度的组合爆炸问题，在经典硬件上无法穷举所有构象。需要量子计算方法来突破这一瓶颈。

Method: 采用量子原生方法：1) 将配体占据情况编码到离散化三维网格上；2) 在单个量子态中相干生成所有空间构型；3) 使用辅助量子比特控制多步平移和旋转变换；4) 同时激活所有对称相关构型。

Result: 提出了一个可扩展的量子加速虚拟筛选框架，能够一次性生成所有可能的配体构象，克服了经典方法的组合爆炸问题。

Conclusion: 该量子原生框架为分子对接提供了可扩展的解决方案，随着量子硬件的发展，可与量子评分方法集成，实现量子加速的虚拟筛选。

Abstract: Classical molecular docking is fundamentally constrained by the combinatorial growth of ligand translational and rotational degrees of freedom, rendering exhaustive pose enumeration infeasible on classical hardware. This work introduces a quantum-native formulation that encodes ligand occupancy on discretized three-dimensional grids and coherently generates the full ensemble of spatial configurations within a single quantum state. Multi-step translations and rotational transformations are controlled by ancillary qubits, enabling all symmetry-related configurations to be activated simultaneously. This framework provides a scalable foundation for quantum-accelerated virtual screening and is amenable to integration with quantum scoring approaches as quantum hardware continues to advance.

</details>


### [22] [Scalable Quantum Error Mitigation with Neighbor-Informed Learning](https://arxiv.org/abs/2512.12578)
*Zhenyu Chen,Bin Cheng,Minbo Gao,Xiaodie Lin,Ruiqi Zhang,Zhaohui Wei,Zhengfeng Ji*

Main category: quant-ph

TL;DR: NIL（邻居信息学习）是一个统一且可扩展的量子误差缓解框架，通过学习目标量子电路的邻居电路噪声输出来预测理想输出，相比现有方法在灵活性、准确性、效率和鲁棒性方面都有提升。


<details>
  <summary>Details</summary>
Motivation: 量子硬件噪声是实现量子计算潜力的主要障碍。现有量子误差缓解方法在性能、资源开销和理论保证之间存在困难权衡，需要更灵活、准确、高效的解决方案。

Method: 提出邻居信息学习（NIL）框架，通过学习目标量子电路的"邻居"电路（结构相关电路）的噪声输出来预测理想输出。关键创新是2-design训练方法，相比传统基于学习的QEM协议（用随机Clifford门替换非Clifford门），能生成更有效的训练数据。

Result: NIL统一并强化了ZNE和PEC等现有方法，在理论和数值模拟中都显示出更高的准确性和效率。证明训练集大小仅随邻居电路总数对数增长，使NIL能应用于大规模量子电路问题。

Conclusion: NIL建立了一个理论基础坚实且实际高效的量子误差缓解框架，为实现噪声硬件上的量子优势铺平了可行道路。

Abstract: Noise in quantum hardware is the primary obstacle to realizing the transformative potential of quantum computing. Quantum error mitigation (QEM) offers a promising pathway to enhance computational accuracy on near-term devices, yet existing methods face a difficult trade-off between performance, resource overhead, and theoretical guarantees. In this work, we introduce neighbor-informed learning (NIL), a versatile and scalable QEM framework that unifies and strengthens existing methods such as zero-noise extrapolation (ZNE) and probabilistic error cancellation (PEC), while offering improved flexibility, accuracy, efficiency, and robustness.
  NIL learns to predict the ideal output of a target quantum circuit from the noisy outputs of its structurally related ``neighbor'' circuits. A key innovation is our 2-design training method, which generates training data for our machine learning model. In contrast to conventional learning-based QEM protocols that create training circuits by replacing non-Clifford gates with uniformly random Clifford gates, our approach achieves higher accuracy and efficiency, as demonstrated by both theoretical analysis and numerical simulation. Furthermore, we prove that the required size of the training set scales only \emph{logarithmically} with the total number of neighbor circuits, enabling NIL to be applied to problems involving large-scale quantum circuits. Our work establishes a theoretically grounded and practically efficient framework for QEM, paving a viable path toward achieving quantum advantage on noisy hardware.

</details>


### [23] [$k$-Entanglement Measure for Multipartite Systems without Convex-Roof Extensions and its Evaluation](https://arxiv.org/abs/2512.12588)
*Jie Guo,Shuyuan Yang,Jinchuan Hou,Xiaofei Qi,Kan He*

Main category: quant-ph

TL;DR: 提出了首个真正的k-纠缠度量E_w^{(k,n)}，满足所有公理，避免凸包构造，可高效计算，为多体纠缠提供了可扩展的实用量化工具。


<details>
  <summary>Details</summary>
Motivation: 多体纠缠是量子技术的基础，但目前研究受到缺乏通用度量、统一框架以及凸包扩展难以处理的限制。

Method: 建立公理化框架，引入首个真正的k-纠缠度量E_w^{(k,n)}，该度量满足所有公理，避免凸包构造，并提供通用算法评估任意有限维态，开发开源软件覆盖四量子比特系统的所有划分。

Result: 数值测试可在200秒内认证k-纠缠，与充要条件一致，收紧边界并揭示新的阈值，为多体纠缠量化提供了可扩展的实用工具。

Conclusion: 该框架将k-纠缠确立为多体量子资源，提供了首个满足所有公理的高效可计算度量，为多体纠缠的严格量化提供了可扩展的实用工具。

Abstract: Multipartite entanglement underpins quantum technologies but its study is limited by the lack of universal measures, unified frameworks, and the intractability of convex-roof extensions. We establish an axiomatic framework and introduce the first \emph{true} $k$-entanglement measure, $E_w^{(k,n)}$, which satisfies all axioms, establishes $k$-entanglement as a multipartite quantum resource, avoids convex-roof constructions, and is efficiently computable. A universal algorithm evaluates arbitrary finite-dimensional states, with open-source software covering all partitions of four-qubit systems. Numerical tests certify $k$-entanglement within 200 seconds, consistent with necessary-and-sufficient criteria, tightening bounds and revealing new thresholds. This framework offers a scalable, practical tool for rigorous multipartite entanglement quantification.

</details>


### [24] [Operational Derivation of Born's Rule from Causal Consistency in Generalized Probabilistic Theories](https://arxiv.org/abs/2512.12636)
*Enso O. Torres Alegre*

Main category: quant-ph

TL;DR: 从因果一致性等操作要求出发，在广义概率理论中推导出Born规则，证明概率分配必须是仿射的，否则会导致超光速信号传递


<details>
  <summary>Details</summary>
Motivation: 传统上Born规则是量子力学的基本假设，本文旨在从更基本的操作原理出发推导Born规则，而不预先假设希尔伯特空间结构

Method: 采用三阶段论证：1) 操作概率分配；2) 因果一致性约束；3) 结构重建。从因果一致性、锐测量、可逆对称性和无信号传递等要求出发，证明任何允许的状态到概率映射必须是仿射的

Result: 证明概率分配的仿射性迫使概率分配与复数量子理论的二次跃迁函数一致，从而恢复复数量子理论，并将Born规则识别为因果固定点

Conclusion: Born规则可以从因果一致性等基本操作要求推导出来，是允许概率定律中的因果固定点。该推导为实验验证提供了理论基础，可通过基于操控的实验来约束对仿射性的偏离

Abstract: We present an operational derivation of Born's rule within finite-dimensional generalized probabilistic theories (GPTs), without assuming Hilbert-space structure. From a single causal requirement, namely causal consistency, together with sharp measurements, reversible symmetries, and no-signaling, we show that any admissible state-to-probability map must be affine under mixing; otherwise, its curvature enables superluminal signaling via steering. Using standard reconstruction results, affinity forces the probability assignment to coincide with the quadratic transition function of complex quantum theory. Our three-stage argument (operational assignment, causal-consistency constraints, and structural reconstruction) recovers complex quantum theory and identifies Born's rule as a causal fixed point among admissible probabilistic laws. We discuss limitations of the derivation and outline steering-based experiments that could bound deviations from affinity.

</details>


### [25] [Quantum Reference Frames in Quantum Circuits: Perspective Dependent Entangling Cost and Coherence Entanglement Trade Offs](https://arxiv.org/abs/2512.12645)
*Salman Sajad Wani,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: 量子参考系（QRF）变换作为电路编译规则，将局部操作映射到不同参考系，产生关系性电路复杂度，并在IBM量子平台上实验验证了局部相干性与纠缠之间的转换。


<details>
  <summary>Details</summary>
Motivation: 虽然量子参考系的理论框架已经建立，但其对基于电路的量子信息处理的实际影响尚未充分探索。本文旨在将QRF变换转化为实用的电路编译规则，并实验验证关系性量子协议。

Method: 为具有有限阿贝尔对称性的系统（用正则表示描述）推导门级字典，将局部操作从一个参考系映射到另一个参考系。基于群论对门进行分类，并在三量子比特模型中实例化该框架，在IBM量子超导平台上实现相应电路。

Result: QRF酉变换作为无损转换器，在基于纯度的局部相干性和并发度之间转换，保持其不变和。硬件数据重现了局部相干性向纠缠的预测转换，观察到的偏差量化了实际设备噪声对关系性量子协议的影响。

Conclusion: QRF变换定义了关系性电路复杂度，其中计算成本取决于观察者的内部参考系。实验验证了纠缠的相对性，并为噪声环境下的关系性量子协议提供了实用框架。

Abstract: The perspective-neutral formulation of quantum reference frames (QRFs) treats observers as quantum systems and describes physics relationally from within the composite system. While frame-change maps and frame-invariant resource sums are theoretically understood, their impact on circuit-based quantum information processing has largely remained unexplored. We formulate QRF transformations as circuit compilation rules and, for systems with finite Abelian symmetry described by the regular representation, derive a gate-level dictionary that maps local operations in one frame to their images in another. This yields a group-theoretic classification of gates where symmetry-commuting operators remain local, up to frame-dependent phases, while generic gates are promoted to controlled entangling operations in which the original frame acts as a control register. The resulting frame-dependence entangling-gate count defines a relational circuit complexity where the cost of a computation depends on the internal reference frame of the observer. We instantiate the framework in a three-qubit model and show that the QRF unitary acts as a lossless converter between a purity-based local coherence and concurrence, preserving their invariant sum and giving a concrete realization of the relativity of entanglement. We implement the corresponding circuits on an IBM Quantum superconducting platform, using full state tomography to reconstruct the redistribution of resources between internal frames. The hardware data reproduce the predicted conversion of local coherence into entanglement, and the observed deviations from exact conservation quantify the effect of realistic device noise on relational quantum protocols.

</details>


### [26] [Expected values for SUSY hierarchies of Jaynes-Cummings Hamiltonian](https://arxiv.org/abs/2512.12647)
*İsmail Burak Ateş,Şengül Kuru,Javier Negro,Ege Özkan*

Main category: quant-ph

TL;DR: 研究超对称伙伴哈密顿量对Jaynes-Cummings模型中期望值演化的影响，特别是对经典时间和恢复时间的影响


<details>
  <summary>Details</summary>
Motivation: 探索超对称伙伴哈密顿量（其谱仅在有限能级上不同）是否会影响量子光学中Jaynes-Cummings模型的期望值演化，特别是场算符、正交分量和原子反转等物理量的演化行为

Method: 计算超对称伙伴哈密顿量下期望值的演化，包括场算符a±、正交分量和原子反转等物理量，分析这些物理量在超对称变换下的变化规律

Result: 超对称伙伴连接确实会影响期望值的演化，特别是对经典时间和恢复时间产生特定影响，揭示了超对称变换如何改变量子系统的动力学行为

Conclusion: 超对称伙伴哈密顿量对Jaynes-Cummings模型的期望值演化有显著影响，这种影响体现在经典时间和恢复时间的变化上，为理解超对称变换在量子光学中的作用提供了新见解

Abstract: The aim of this letter is to compute the evolution of some expected values, such as the field operators $a^{\pm}$, quadratures and atomic inversion, under SUSY partner Hamiltonians associated to the Jaynes-Cummings Hamiltonian of quantum optics. This kind of SUSY partners are characterized by having spectra which differ in a finite number of energy levels. We wish to elucidate if the partner connection has any influence on these expected values. In particular, we want also to know in which way the classical and revival times are affected by such SUSY partners.

</details>


### [27] [Mid-circuit logic executed in the qubit layer of a quantum processor](https://arxiv.org/abs/2512.12648)
*Cameron Jones,Piper Wysocki,MengKe Feng,Gerardo A. Paz-Silva,Corey I. Ostrove,Tuomo Tanttu,Kenneth M. Rudinger,Samuel K. Bartee,Kevin Young,Fay E. Hudson,Wee Han Lim,Nikolay V. Abrosimov,Hans-Joachim Pohl,Michael L. W. Thewalt,Robin Blume-Kohout,Andrew S. Dzurak,Andre Saraiva,Arne Laucht,Chih Hwan Yang*

Main category: quant-ph

TL;DR: 硅自旋量子比特系统中首次实现中电路测量，并展示无需经典层路由即可执行前馈操作，利用背向驱动控制技术，为将资源密集型经典处理移至量子层迈出第一步。


<details>
  <summary>Details</summary>
Motivation: 实用量子计算机需要在计算过程中持续交换经典与量子子系统间的数据。中电路测量和前馈操作对容错量子计算至关重要，但必须在量子比特退相干前完成量子-经典循环，这对包含数百万量子比特的全规模系统构成重大工程挑战。

Method: 在硅自旋量子比特系统中首次进行中电路测量，采用背向驱动控制技术实现无需经典层路由的前馈操作。同时使用标准FPGA方法作为对比，通过门集层析分析两种方法的性能。

Result: 成功演示了层内前馈策略，利用传统上被视为误差源的背向驱动控制技术，实现了量子层内的信息处理。通过门集层析对层内策略和标准FPGA方法进行了基准测试。

Conclusion: 该研究为将资源密集型经典处理移至量子层迈出了第一步，这一进展有望解决关键工程挑战，并大幅降低未来量子计算机的功耗预算。

Abstract: Practical quantum computers need to continuously exchange data between classical and quantum subsystems during a computation. Mid-circuit measurements of a qubits state are transferred to the classical electronics layer, and their outcome can inform feedforward operations that close the loop back to the quantum layer. These operations are crucial for fault-tolerant quantum computers, but the quantum-classical loop must be completed before the qubits decohere, presenting a substantial engineering challenge for full-scale systems comprising millions of qubits. Here we perform the first mid-circuit measurements in a system of silicon spin qubits, and show that feedforward operations can be performed without needing to route information to the classical layer. This in-layer approach leverages a backaction-driven control technique that has previously been considered a source of error. We benchmark our in-layer strategy, together with the standard FPGA-enabled approach, and analyse the performance of both methods using gate set tomography. Our results provide the first step towards moving resource-intensive classical processing into the quantum layer, an advance that could solve key engineering challenges, and drastically reduce the power budget of future quantum computers.

</details>


### [28] [Quantum Implicit Neural Representations for 3D Scene Reconstruction and Novel View Synthesis](https://arxiv.org/abs/2512.12683)
*Yeray Cordero,Paula García-Molina,Fernando Vilariño*

Main category: quant-ph

TL;DR: Q-NeRF首次将量子隐式表示网络集成到神经辐射场渲染中，通过量子电路缓解经典网络的频谱偏差，在有限计算资源下实现竞争性的3D场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 经典隐式神经表示存在频谱偏差，难以捕捉高频细节。量子电路具有固有的傅里叶结构，能够更紧凑地建模频率，因此探索将量子增强模块集成到神经辐射场框架中。

Method: 提出Q-NeRF混合量子-经典框架：在Nerfacto骨干网络中集成QIREN模块，保留高效采样、姿态优化和体渲染策略，用量子增强组件替换部分密度和辐射预测模块，系统评估三种混合配置。

Result: 在标准多视角室内数据集上，混合量子-经典模型在PSNR、SSIM和LPIPS指标上达到竞争性重建质量，量子模块特别擅长表示细粒度的视角相关外观，尽管当前实现受限于少量量子比特的模拟器。

Conclusion: Q-NeRF为可扩展的量子增强3D场景重建奠定了基础，展示了量子编码缓解隐式表示频谱偏差的潜力，为未来量子神经渲染研究提供了基准。

Abstract: Implicit neural representations (INRs) have become a powerful paradigm for continuous signal modeling and 3D scene reconstruction, yet classical networks suffer from a well-known spectral bias that limits their ability to capture high-frequency details. Quantum Implicit Representation Networks (QIREN) mitigate this limitation by employing parameterized quantum circuits with inherent Fourier structures, enabling compact and expressive frequency modeling beyond classical MLPs. In this paper, we present Quantum Neural Radiance Fields (Q-NeRF), the first hybrid quantum-classical framework for neural radiance field rendering. Q-NeRF integrates QIREN modules into the Nerfacto backbone, preserving its efficient sampling, pose refinement, and volumetric rendering strategies while replacing selected density and radiance prediction components with quantum-enhanced counterparts. We systematically evaluate three hybrid configurations on standard multi-view indoor datasets, comparing them to classical baselines using PSNR, SSIM, and LPIPS metrics. Results show that hybrid quantum-classical models achieve competitive reconstruction quality under limited computational resources, with quantum modules particularly effective in representing fine-scale, view-dependent appearance. Although current implementations rely on quantum circuit simulators constrained to few-qubit regimes, the results highlight the potential of quantum encodings to alleviate spectral bias in implicit representations. Q-NeRF provides a foundational step toward scalable quantum-enabled 3D scene reconstruction and a baseline for future quantum neural rendering research.

</details>


### [29] [Measurement-Induced Perturbations of Hausdorff Dimension in Quantum Paths](https://arxiv.org/abs/2512.13046)
*You-Wei Ding,Yen Chin Ong,Hao Xu*

Main category: quant-ph

TL;DR: 该研究探讨了量子测量如何改变量子粒子路径的分形几何，揭示了测量过程会降低路径的粗糙度并将豪斯多夫维度推向更低值，而选择性演化则需要反馈控制来稳定轨迹。


<details>
  <summary>Details</summary>
Motivation: Abbott等人的开创性工作预测了量子路径的豪斯多夫维度会随着粒子动量增加从d=2过渡到d=1，但他们的计算只涉及自由演化波函数的期望值，没有实际物理测量。本研究旨在探究真实的量子测量如何改变量子粒子路径的分形几何。

Method: 通过使用高斯波包对粒子和测量装置进行建模，研究顺序测量过程。分析了非选择性演化中测量动力学如何改变路径粗糙度，以及在选择性演化中引入反馈控制力来抵消随机波函数坍缩。

Result: 测量过程会改变量子路径的粗糙度，并将出现的豪斯多夫维度推向更低值。在非选择性演化中，测量降低了维度；在选择性演化中，反馈控制可以稳定轨迹并调节维度。当测量贡献趋近于零时，结果退化为Abbott等人的预测。

Conclusion: 这项工作为Abbott等人的方法提供了更现实的表述，将理论量子分形性与测量物理学联系起来，量化了探测器如何在量子尺度上重塑时空统计特性。

Abstract: In a seminal paper, Abbott et al. analyzed the relationship between a particle's trajectory and the resolution of position measurements performed by an observer at fixed time intervals. They predicted that quantum paths exhibit a universal Hausdorff dimension that transitions from $d=2$ to $d=1$ as the momentum of the particle increases. However, although measurements were assumed to occur at intervals of time, the calculations only involved evaluating the expectation value of operators for the free evolution of wave function within a single interval, with no actual physical measurements performed. In this work we investigate how quantum measurements alter the fractal geometry of quantum particle paths. By modelling sequential measurements using Gaussian wave packets for both the particle and the apparatus, we reveal that the dynamics of the measurement change the roughness of the path and shift the emergent Hausdorff dimension towards a lower value in nonselective evolution. For selective evolution, feedback control forces must be introduced to counteract stochastic wave function collapse, stabilising trajectories and enabling dimensionality to be tuned. When the contribution of the measurement approaches zero, our result reduces to that of Abbott et al. Our work can thus be regarded as a more realistic formulation of their approach, and it connects theoretical quantum fractality with measurement physics, quantifying how detectors reshape spacetime statistics at quantum scales.

</details>


### [30] [FiD-QAE: A Fidelity-Driven Quantum Autoencoder for Credit Card Fraud Detection](https://arxiv.org/abs/2512.12689)
*Mansour El Alami,Adam Innan,Nouhaila Innan,Muhammad Shafique,Mohamed Bennai*

Main category: quant-ph

TL;DR: FiD-QAE是一种基于保真度的量子自编码器，利用量子保真度作为异常检测标准，在信用卡欺诈检测中表现出良好的鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 信用卡欺诈检测面临数据高度不平衡、欺诈模式不断演变的挑战，现有经典和量子方法在可扩展性、鲁棒性和适应性方面仍有局限。

Method: 提出FiD-QAE架构：将交易编码为量子态，通过变分量子电路压缩，使用SWAP测试计算保真度来区分合法与欺诈交易。

Result: FiD-QAE在不同不平衡水平下保持稳定性能，在量子噪声模型中保持鲁棒性，在IBM量子硬件上验证了可行性。

Conclusion: 量子保真度是异常检测的有效标准，FiD-QAE作为经典和量子方法的补充，为金融欺诈检测提供了鲁棒性和泛化性。

Abstract: Credit card fraud detection is a critical task in financial security, as fraudulent transactions are rare, highly imbalanced, and often resemble legitimate ones. A wide range of classical machine learning methods, as well as more recent quantum machine learning approaches, have been investigated to address this challenge, each providing valuable progress but also leaving open questions regarding scalability, robustness, and adaptability to evolving fraud patterns. In this work, we introduce the Fidelity-based Quantum Autoencoder (FiD-QAE), a quantum architecture that employs fidelity estimation as the decision criterion for anomaly detection. Transactions are encoded into quantum states, compressed through a variational quantum circuit, and evaluated using the SWAP test to distinguish legitimate from fraudulent transactions. We conduct a comprehensive evaluation of FiD-QAE, including statistical analyses, multiple performance metrics, and robustness tests under quantum noise models. The results show that FiD-QAE maintains consistent performance across different imbalance levels and preserves robustness in noisy conditions. Moreover, validation on IBM Quantum hardware backends confirms the feasibility of our approach on real devices, with outcomes consistent with simulation. These findings position quantum fidelity as a powerful criterion for anomaly detection and highlight FiD-QAE as a promising direction that complements existing classical and quantum approaches, offering robustness and generalizability for financial fraud detection in realistic environments.

</details>


### [31] [Entanglement, Coherence, and Recursive Linking in Dicke states : A Topological Perspective](https://arxiv.org/abs/2512.12704)
*Sougata Bhattacharyya,Sovik Roy*

Main category: quant-ph

TL;DR: 本文通过拓扑视角研究对称Dicke态的多体纠缠结构，将量子比特视为拓扑环，建立Dicke态递归测量动力学与n-Hopf链环稳定性之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究多体纠缠的拓扑结构，特别是Dicke态与GHZ态等不同纠缠类型在拓扑稳定性上的差异，为理解量子纠缠的鲁棒性提供新视角。

Method: 将量子比特视为拓扑环，建立Dicke态测量动力学与n-Hopf链环的对应；使用Schmidt秩量化二分纠缠韧性；引入l1范数量子相干性度量链环流动性。

Result: Dicke态展现出鲁棒的自相似拓扑结构，局部测量通过非零剩余相干性保持全局链环结构，与GHZ态（类比Borromean环）的脆弱性形成鲜明对比。

Conclusion: Dicke态的多体纠缠具有拓扑鲁棒性，其自相似结构在局部扰动下保持稳定，为量子信息处理中的鲁棒纠缠资源提供了理论支持。

Abstract: This work investigates the topological structure of multipartite entanglement in symmetric Dicke states $|D_n^{(k)}\rangle$. By viewing qubits as topological loops, we establish a direct correspondence between the recursive measurement dynamics of Dicke states and the stability of $n$-Hopf links. We utilize the Schmidt rank to quantify bipartite entanglement resilience and introduce the $l_1$-norm of quantum coherence as a measure of link fluidity. We demonstrate that unlike fragile states such as $ \left| GHZ \right \rangle$ (analogous to Borromean rings), Dicke states exhibit a robust, self-similar topology where local measurements preserve the global linking structure through non-vanishing residual coherence.

</details>


### [32] [Practical Hybrid Quantum Language Models with Observable Readout on Real Hardware](https://arxiv.org/abs/2512.12710)
*Stefan Balauca,Ada-Astrid Balauca,Adrian Iftene*

Main category: quant-ph

TL;DR: 该论文首次在真实量子硬件上实现了端到端的生成式量子语言模型训练，提出了量子循环神经网络和量子卷积神经网络作为混合量子-经典语言模型，通过多样本SPSA策略在噪声环境下有效训练量子参数。


<details>
  <summary>Details</summary>
Motivation: 利用近期量子设备处理序列数据，建立混合量子-经典模型作为关键步骤，为生成式量子自然语言处理奠定工程基础。

Method: 结合硬件优化的参数化量子电路与轻量级经典投影层，采用多样本SPSA策略在噪声环境下训练量子参数，使用可观测值读取实现序列模式学习。

Result: 在IBM量子处理器上的实验揭示了电路深度与可训练性之间的关键权衡，表明尽管噪声仍是重要因素，但基于可观测值的读取能够在NISQ设备上成功学习序列模式。

Conclusion: 这些结果为生成式量子自然语言处理建立了严谨的工程基准，验证了在当前量子硬件上训练复杂序列模型的可行性。

Abstract: Hybrid quantum-classical models represent a crucial step toward leveraging near-term quantum devices for sequential data processing. We present Quantum Recurrent Neural Networks (QRNNs) and Quantum Convolutional Neural Networks (QCNNs) as hybrid quantum language models, reporting the first empirical demonstration of generative language modeling trained and evaluated end-to-end on real quantum hardware. Our architecture combines hardware-optimized parametric quantum circuits with a lightweight classical projection layer, utilizing a multi-sample SPSA strategy to efficiently train quantum parameters despite hardware noise. To characterize the capabilities of these models, we introduce a synthetic dataset designed to isolate syntactic dependencies in a controlled, low-resource environment. Experiments on IBM Quantum processors reveal the critical trade-offs between circuit depth and trainability, demonstrating that while noise remains a significant factor, observable-based readout enables the successful learning of sequential patterns on NISQ devices. These results establish a rigorous engineering baseline for generative quantum natural language processing, validating the feasibility of training complex sequence models on current quantum hardware.

</details>


### [33] [Nonlocal Cancellation of Optical Rotations in Fructose Solutions](https://arxiv.org/abs/2512.12739)
*Wen-Chia Lo,Chao-Yuan Wang,Yu-Tung Tsai,Sheng-Yao Huang,Kang-Shih Liu,Yun-Hsuan Shih,Ching-Hua Tsai,Chih-Sung Chuu*

Main category: quant-ph

TL;DR: 利用偏振纠缠光子对在果糖溶液中实现了非局域光学旋转的相消与相加，并通过纠缠光子联合测量实现远程探测光学活性


<details>
  <summary>Details</summary>
Motivation: 量子纠缠作为量子力学中最具代表性的现象之一，在基础研究和现代量子技术中广泛应用。本文旨在探索利用纠缠光子对研究光学活性的新方法，特别是实现非局域的光学旋转操控和远程探测。

Method: 使用偏振纠缠光子对在果糖溶液中进行实验，通过纠缠光子的联合测量来探测光学活性，实现了非局域的光学旋转相消和相加效应。

Result: 实验观察到了光学旋转的非局域相消和相加现象，实验结果与理论预测吻合良好。该方法能够远程探测光学活性，且灵敏度随纠缠光子数量的增加而提高。

Conclusion: 该研究展示了利用纠缠光子对研究手性分子的潜力，为扩展到其他手性分子测量提供了可能，且灵敏度随纠缠光子数增加而提升，具有重要的量子测量应用前景。

Abstract: Entanglement, one of the most representative phenomena in quantum mechanics, has been widely used for fundamental studies and modern quantum technologies. In this paper, we report the observation of nonlocal cancellation and addition of optical rotations with polarization-entangled photons in fructose solutions. The entanglement also enables probing optical activities at a distance by joint measurements on the entangled photons. The good agreement between the experimental results and theoretical predictions demonstrates the potential for extending these measurements to other chiral molecules, with a sensitivity that improves as the number of entangled photons increases.

</details>


### [34] [The Quantum Fourier Transform for Continuous Variables](https://arxiv.org/abs/2512.12771)
*Gianfranco Cariolaro,Edi Ruffa,Amir Mohammad Yaghoobianzadeh,Jawad A. Salehi*

Main category: quant-ph

TL;DR: 本文研究了连续变量量子傅里叶变换(cvQFT)，将其定义为由离散傅里叶变换矩阵指定的旋转算子，并利用Murnaghan方法和FFT算法降低实现复杂度，最后展示了cvQFT对高斯态的变换效果。


<details>
  <summary>Details</summary>
Motivation: 离散变量量子傅里叶变换(dvQFT)在量子计算中有重要应用，但通常针对量子比特。本文旨在研究连续变量量子傅里叶变换(cvQFT)，将其扩展到希尔伯特空间中的连续变量系统，探索其在连续变量量子信息处理中的应用。

Method: 将cvQFT定义为由离散傅里叶变换(DFT)矩阵指定的旋转算子。采用Murnaghan方法，使用单模旋转和分束器等基本组件实现旋转算子。应用快速傅里叶变换(FFT)算法来大幅降低实现复杂度。

Result: 成功定义了cvQFT并建立了其实现方法。特别展示了cvQFT对高斯态的变换效果：将位移向量变换为一维DFT，压缩矩阵变换为二维DFT，旋转矩阵变换为傅里叶类相似变换。

Conclusion: 本文系统研究了连续变量量子傅里叶变换，建立了其数学定义和物理实现方法，并揭示了其对高斯态的变换特性，为连续变量量子信息处理提供了重要工具。

Abstract: The quantum Fourier transform for discrete variable (dvQFT) is an efficient algorithm for several applications. It is usually considered for the processing of quantum bits (qubits) and its efficient implementation is obtained with two elementary components: the Hadamard gate and the controlled--phase gate. In this paper, the quantum Fourier transform operating with continuous variables (cvQFT) is considered. Thus, the environment becomes the Hilbert space, where the natural definition of the cvQFT will be related to rotation operators, which in the $N$--mode are completely specified by unitary matrices of order $N$. Then the cvQFT is defined as the rotation operator whose rotation matrix is given by the discrete Fourier transform (DFT) matrix. For the implementation of rotation operators with primitive components (single--mode rotations and beam splitters), we follow the well known Murnaghan procedure, with appropriate modifications. Moreover, algorithms related to the fast Fourier transform (FFT) are applied to reduce drastically the implementation complexity. The final part is concerned with the application of the cvQFT to general Gaussian states. In particular, we show that cvQFT has the simple effect of transforming the displacement vector by a one-dimensional DFT, the squeeze matrix by a two-dimensional DFT, and the rotation matrix by a Fourier-like similarity transform.

</details>


### [35] [Boundary-driven quantum systems near the Zeno limit: steady states and long-time behavior](https://arxiv.org/abs/2512.12825)
*Eric A. Carlen,David A. Huse,Joel L. Lebowitz*

Main category: quant-ph

TL;DR: 该论文研究具有边界耗散的复合开放量子系统，证明在大耗散参数γ下，系统动力学简化为边界稳态与内部约化动力学的张量积，并建立了稳态的渐近展开。


<details>
  <summary>Details</summary>
Motivation: 研究复合开放量子系统在强边界耗散下的动力学行为，理解系统如何简化为边界稳态与内部约化动力学的张量积，并分析稳态的渐近性质。

Method: 使用Lindblad主方程描述系统演化，假设边界耗散算符是遍历且能隙的。通过引入第三个Lindblad生成元D_P^♯，建立与原始系统的联系，证明大γ极限下的简化动力学和稳态收敛。

Result: 证明在大γ下，系统动力学在γ^{-1}时间尺度后简化为π_A⊗R(t)，其中π_A是边界稳态，R(t)满足约化动力学。若D_P^♯遍历且能隙，则L_γ也遍历且能隙，稳态收敛到π_A⊗R̄，并给出收敛的渐近展开式。

Conclusion: 强边界耗散导致复合开放量子系统动力学简化，边界快速达到稳态，内部演化由约化动力学描述。稳态存在收敛的渐近展开，为理解强耗散极限下的量子系统行为提供了严格数学框架。

Abstract: We study composite open quantum systems with a finite-dimensional state space ${\mathcal H}_A\otimes {\mathcal H}_B$ governed by a Lindblad equation $ρ'(t) = {\mathcal L}_γρ(t)$ where ${\mathcal L}_γρ= -i[H,ρ] + γ{\mathcal D} ρ$, and ${\mathcal D}$ is a dissipator ${\mathcal D}_A\otimes I$ acting non-trivially only on part $A$ of the system, which can be thought of as the boundary, and $γ$ is a parameter. It is known that the dynamics simplifies for large $γ$: after a time of order $γ^{-1}$, $ρ(t)$ is well approximated for times small compared to $γ^2$ by $π_A\otimes R(t)$ where $π_A$ is a steady state of ${\mathcal D}_A$, and $R(t)$ is a solution of $\frac{\rm d}{{\rm d}t}R(t) = {\mathcal L}_{P,γ}R(t)$ where ${\mathcal L}_{P,γ} R := -i[H_P,R] + γ^{-1} {\mathcal D}_P R$ with $H_P$ being a Hamiltonian on ${\mathcal H}_B$ and ${\mathcal D}_P$ being a Lindblad generator over ${\mathcal H}_B$. We prove this assuming only that ${\mathcal D}_A$ is ergodic and gapped. In order to better control the long time behavior, and study the steady states $\barρ_γ$, we introduce a third Lindblad generator ${\mathcal D}_P^\sharp$ that does not involve $γ$, but still closely related to ${\mathcal L}_γ$. We show that if ${\mathcal D}_P^\sharp$ is ergodic and gapped, then so is ${\mathcal L}_γ$ for all large $γ$, and if $\barρ_γ$ denotes the unique steady state for ${\mathcal L}_γ$, then $\lim_{γ\to\infty}\barρ_γ= π_A\otimes \bar R$ where $\bar R$ is the unique steady state for ${\mathcal D}_P^\sharp$. We show that there is a convergent expansion $\barρ_γ= π_A\otimes\bar R +γ^{-1} \sum_{k=0}^\infty γ^{-k} \bar n_k$ where, defining $\bar n_{-1} := π_A\otimes\bar R$, ${\mathcal D} \bar n_k = -i[H,\bar n_{k-1}]$ for all $k\geq 0$.

</details>


### [36] [Measures to characterise Approximate Mutually Unbiased Bases](https://arxiv.org/abs/2512.12828)
*Ajeet Kumar,Uditanshu Sadual*

Main category: quant-ph

TL;DR: 该论文针对量子信息处理中相互无偏基(MUBs)在非素数幂维度下难以构造的问题，提出了近似MUBs(AMUBs)的量化度量方法，用于评估近似MUBs与理想MUBs的接近程度。


<details>
  <summary>Details</summary>
Motivation: 相互无偏基在量子信息处理和编码理论中有重要应用，但在非素数幂维度下难以构造完整集合。现有的大多数近似MUBs构造缺乏量化评估标准，需要建立系统化的度量方法来表征近似MUBs的质量。

Method: 基于MUBs的应用场景，提出可计算的量化度量方法，包括几何解释、投影设计特征、最优态确定和熵不确定性等角度。建立这些度量之间的通用关系，并证明可以在不知道具体构造细节的情况下评估近似MUBs。

Result: 定义了能够完全表征近似MUBs的量化度量体系，证明了仅凭近似MUBs的定义就足以评估其质量。将该方法应用于弱MUBs和使用RBDs构造的特定近似MUBs，验证了度量方法的有效性。

Conclusion: 提出的量化度量方法为近似MUBs提供了系统化的评估框架，使得无需知道具体构造细节就能评估近似MUBs的质量，这对于量子信息处理中近似MUBs的设计和应用具有重要意义。

Abstract: Mutually Unbiased bases has various application in quantum information procession and coding theory. There can be maximum d + 1 MUBs in C^d and d/2 +1 MUBs in R^d. But , over R^d MUBs are known to be non existent when d is odd and for most of the other even d there are mostly 3 Real MUBs. In case of C^d the construction for complete set of MUBs are known for only Prime Power dimension. Thus in general large set of MUBs are not known, particularly for composite dimensions which are not of the form of prime powers. Because of this, there are many constructions of Approximate version of MUBs. In this paper we make an attempt to define certain measures to characterise the AMUBs. Our construction of measures derives its inspiration from the applications of MUBs, and based on them, we define certain quantifiable measures, which are can be computed and gives estimates of how close the Approximate MUBs are to the MUBs. We use geometric interpretation, projective design features of MUBs and applications like Optimal State determination and Entropic Uncertainty of MUBs. We show generic relationship between these measures and show that it can be evaluated for APMUBs without known the exact construction details, thereby showing that definition of APMUB is sufficient completely characterise it. We also evaluate these measure for an interesting class of AMUBs called Weak MUBs and certain AMUBs constructed using RBDs.

</details>


### [37] [Intrinsic Geometry of Operational Contexts: A Riemannian-Style Framework for Quantum Channels](https://arxiv.org/abs/2512.12944)
*Kazuyuki Yoshida*

Main category: quant-ph

TL;DR: 该论文提出了一个在操作上下文空间上的内在几何框架，通过通道、稳态和自保持泛函定义，建立了指针代数、内部电荷和自洽配置的几何结构，将规范对称性和引力动力学解释为该上下文几何中的和乐性和一致性条件。


<details>
  <summary>Details</summary>
Motivation: 为量子信息、统计力学和广义相对论中的操作上下文建立一个统一的几何框架，将规范对称性和引力动力学等物理概念解释为上下文几何的内在属性。

Method: 提出基于通道、稳态和自保持泛函的上下文几何框架，通过自保持泛函的Hessian定义电荷空间的内在度量，利用非交换提问循环定义曲率概念，在适当区域约化为Fisher型信息度量。

Result: 建立了上下文空间的几何结构，包括内在度量、曲率概念，展示了该几何在特定条件下可约化为熟悉的Riemannian或Lorentzian时空，并能解释规范对称性和引力动力学。

Conclusion: 操作上下文空间具有丰富的几何结构，能够统一描述信息几何和时空几何，为理解规范对称性和引力动力学提供了新的几何视角。

Abstract: We propose an intrinsic geometric framework on the space of operational contexts, specified by channels, stationary states, and self-preservation functionals. Each context C carries a pointer algebra, internal charges, and a self-consistent configuration minimizing a self-preservation functional. The Hessian of this functional yields an intrinsic metric on charge space, while non-commutative questioning loops dN -> dPhi -> d rho^circ define a notion of curvature. In suitable regimes, this N-Q-S geometry reduces to familiar Fisher-type information metrics and admits charts that resemble Riemannian or Lorentzian space-times. We outline how gauge symmetries and gravitational dynamics can be interpreted as holonomies and consistency conditions in this context geometry.

</details>


### [38] [Actual and weak actual values in Bohmian mechanics](https://arxiv.org/abs/2512.12951)
*Weixiang Ye*

Main category: quant-ph

TL;DR: 论文提出了在玻姆力学中判断可观测量是否具有确定值的操作鲁棒性准则，建立了弱实际值的概念，并证明了其与量子弱值的理论对应关系。


<details>
  <summary>Details</summary>
Motivation: 玻姆力学中一个基本问题是：除了位置之外的其他可观测量是否具有确定值。需要建立判断可观测量能否被赋予实际值的标准，并发展讨论可观测量本体论地位的概念和数学框架。

Method: 引入操作鲁棒性作为判断准则，建立弱实际值作为理论构造来描述可观测量沿轨迹的局部平均行为，推导其演化方程，并证明其与量子弱值的对应关系。

Result: 得到了充分必要条件：在适当正则条件下，当且仅当波函数在粒子构型处满足相应算符的局部本征条件时，可观测量可被一致赋予实际值。弱实际值的系综平均等于标准量子期望值，且当后选择位置时等于量子弱值的实部。

Conclusion: 该工作扩展并形式化了玻姆力学中可观测量可定义性的早期讨论，建立了讨论可观测量本体论地位的概念和数学框架，并与弱测量实验建立了理论对应关系。

Abstract: A fundamental question in Bohmian mechanics concerns whether observables other than position possess definite values. We introduce a condition of operational robustness as a criterion for when an observable can be attributed an actual value in a given Bohmian state. The main result is a necessary and sufficient condition: under appropriate regularity conditions, an actual value can be consistently assigned if and only if the wave function satisfies a local eigencondition of the corresponding operator at the particle's configuration. For general states, we define a weak actual value as a derived theoretical construct to characterize the local average behavior of an observable along a trajectory. We prove that its ensemble average equals the standard quantum expectation value and derive its evolution equation. Furthermore, we establish that the weak actual value equals the real part of the quantum weak value when post-selecting on position. This work extends and formalizes earlier discussions on the definability of observables in Bohmian mechanics, develops a conceptual and mathematical framework for discussing the ontological status of observables, and establishes a theoretical correspondence with weak measurement experiments.

</details>


### [39] [Quantum Coherence in Reflected and Refracted Beams: A Van Cittert-Zernike Approach](https://arxiv.org/abs/2512.12968)
*Yuetao Chen,Gaiqing Chen,Jin Wang,Qiang Ma,Shoukang Chang,Shaoyan Gao*

Main category: quant-ph

TL;DR: 提出了量子van Cittert-Zernike定理，描述光在介质界面反射和折射时如何影响其相干-偏振特性，并展示了通过界面偏振耦合可调控光子统计特性，无需传统光-物质相互作用。


<details>
  <summary>Details</summary>
Motivation: 量子光学中，光在介质界面的基本光学过程对量子相干性的影响尚未被探索，且调控多光子关联通常需要复杂相互作用，难以在少光子水平实现。

Method: 引入量子van Cittert-Zernike定理，描述光在反射和折射过程中相干-偏振特性的演化，利用界面偏振耦合调控光子统计特性。

Result: 热光可通过后选择测量展现亚泊松统计（涨落低于散粒噪声水平），该统计特性可通过入射角调控，且受光束准直与远场热化之间的标度律支配。

Conclusion: 建立了一种稳健的、避免退相干的量子态控制机制，推进了对量子光学中相干性的基本理解，为量子信息和计量学应用开辟了新途径。

Abstract: Recent advances in quantum optics have highlighted the critical role of spatial propagation in controlling the quantum coherence of light beams. However, the evolution of quantum coherence for light beams undergoing fundamental optical processes at dielectric interfaces remains unexplored. Furthermore, manipulating multiphoton correlations typically requires complex interactions that challenge few-photon level implementation. Here, we introduce a quantum van Cittert-Zernike theorem for light beams, describing how their coherence-polarization properties are influenced by reflection and refraction, as well as how these properties evolve upon subsequent propagation. Our work demonstrates that the quantum statistics of photonic systems can be controllably modified through the inherent polarization coupling arising from reflection and refraction at an interface, without relying on conventional light-matter interactions. Our approach reveals regimes where thermal light can exhibit sub-Poissonian statistics with fluctuations below the shot-noise level through post-selected measurements, and this statistical property can be tuned by the incident angle. Remarkably, this quantum statistical modification is governed by a scaling law linking beam collimation to far-field thermalization. Our work establishes a robust, decoherence-avoiding mechanism for quantum state control, advancing the fundamental understanding of coherence in quantum optics and opening new avenues for applications in quantum information and metrology.

</details>


### [40] [Universal Quantum Random Access Memory: A Data-Independent Unitary Construction](https://arxiv.org/abs/2512.12999)
*Leonardo Bohac*

Main category: quant-ph

TL;DR: 提出一种量子随机存取存储器(QRAM)构造，使用单一、数据无关的酉算子，通过内存量子位作为量子控制信号实现相干查找。


<details>
  <summary>Details</summary>
Motivation: 传统QRAM方法通常产生数据相关的酉算子或基于路由的方法，这增加了实现的复杂性。需要一种简化QRAM实现的方法，将固定电路结构与可变数据编码分离。

Method: 采用通用QRAM架构，将数据编码在内存量子位中，这些量子位作为块对角置换结构中的量子控制信号。内存量子位作为控制信号，当地址处于叠加态时实现相干查找。构造需要log₂N + K + NK个量子位，可分解为NK个多控制门。

Result: 验证了N∈{2,4,8,16}和K∈{1,2,3,4}的情况，确认所得酉算子是纯置换矩阵，在所有数据配置下误差为零。构造简化了QRAM实现，分离了固定电路结构和可变数据编码。

Conclusion: 提出了一种新颖的QRAM构造方法，使用单一数据无关酉算子，通过内存量子位作为控制信号实现相干查找，简化了QRAM的实现并提高了灵活性。

Abstract: We present a construction for Quantum Random Access Memory (QRAM) that achieves a single, data-independent unitary operator. Unlike routing-based approaches or circuit methods that yield data-dependent unitaries, our Universal QRAM encodes data in memory qubits that act as quantum control signals within a block-diagonal permutation structure. The key insight is that memory qubits serve as control signals, enabling coherent lookup when addresses are in superposition. For N addresses with K-bit data words, the construction requires $\log_2 N + K + NK$ qubits and decomposes into exactly $NK$ multi-controlled gates. We verify the construction for $N \in \{2, 4, 8, 16\}$ and $K \in \{1, 2, 3, 4\}$, confirming that the resulting unitary is a pure permutation matrix with zero error across all data configurations. This approach simplifies QRAM implementation by separating fixed circuit structure from variable data encoding.

</details>


### [41] [Imaginary-time-enhanced feedback-based quantum algorithms for universal ground-state preparation](https://arxiv.org/abs/2512.13044)
*Thanh Nguyen Van Long,Lan Nguyen Tran,Le Bin Ho*

Main category: quant-ph

TL;DR: 提出ITE-FALQON方法，通过结合虚时演化改进FALQON算法，解决强关联量子系统基态制备中谱简并导致的收敛失败问题。


<details>
  <summary>Details</summary>
Motivation: FALQON算法在谱简并情况下会失效，无法收敛到基态，这限制了其在强关联量子系统基态制备中的应用。

Method: 提出ITE-FALQON方法，在反馈循环中插入短虚时演化步骤，抑制激发态成分，逃离简并子空间，恢复能量单调下降。

Result: 在3x3费米-哈伯德模型上测试，ITE-FALQON在所有填充情况下都能可靠收敛到基态，解决了原始FALQON在简并情况下的失效问题。

Conclusion: ITE-FALQON为强关联量子系统的可扩展基态制备提供了实用途径，通过结合虚时演化增强了FALQON算法的鲁棒性。

Abstract: Preparing ground states of strongly correlated quantum systems is a central goal in quantum simulation and optimization. The feedback-based quantum algorithm (FALQON) provides an attractive alternative to variational methods with a fully quantum feedback rule, but it fails in the presence of spectral degeneracies, where the feedback signal collapses and the evolution cannot reach the ground state. Using the Fermi-Hubbard model on lattices up to 3x3, we show that this breakdown appears at half-filling on the 2x2 lattice and extends to both half-filled and doped configurations on the 3x3 lattice. We then introduce an imaginary-time-enhanced FALQON (ITE-FALQON) scheme, which inserts short imaginary-time evolution steps into the feedback loop. The hybrid method suppresses excited-state components, escapes degenerate subspaces, and restores monotonic energy descent. The ITE-FALQON achieves a reliable ground-state convergence across all fillings, providing a practical route to scalable ground-state preparation in strongly correlated quantum systems.

</details>


### [42] [Quantum simulation of strong Charge-Parity violation and Peccei-Quinn mechanism](https://arxiv.org/abs/2512.13049)
*Le Bin Ho*

Main category: quant-ph

TL;DR: 该研究通过量子模拟方法，在受控环境中研究QCD中的CP破坏问题，实现了(1+1)维Schwinger模型，展示了θ真空结构和Peccei-Quinn机制


<details>
  <summary>Details</summary>
Motivation: QCD中的拓扑θ项违反CP对称性，但实验表明θ几乎为零，这一矛盾需要解释。研究旨在通过量子模拟在受控环境中研究这一现象

Method: 推导QCD拉格朗日量的哈密顿表示，构建(1+1)维Schwinger模型类比，使用Jordan-Wigner和quantum-link方案将费米子和规范自由度编码到量子比特，获得紧凑的Pauli哈密顿量，采用基于反馈的量子优化协议制备基态

Result: 在少量量子比特模拟器上数值计算真空能E0(θ)，显示在非零θ处存在位移真空，与强相互作用预期一致；引入动态轴子场驱动系统趋向θ=0，实现了Peccei-Quinn机制

Conclusion: 量子硬件能够研究规范理论中的对称性破坏及其动态解决机制，为理解QCD中的CP问题提供了新途径

Abstract: Quantum Chromodynamics (QCD) admits a topological θ-term that violates Charge-Parity (CP) symmetry, yet experimental indicate that θ is nearly zero. To investigate this discrepancy in a controlled setting, we derive the Hamiltonian representation of the QCD Lagrangian and construct its (1+1)-dimensional Schwinger-model analogue. By encoding fermionic and gauge degrees of freedom into qubits using the Jordan-Wigner and quantum-link schemes, we obtain a compact Pauli Hamiltonian that retains the relevant topological vacuum structure. Ground states are prepared using a feedback-based quantum optimization protocol, enabling numerical evaluation of the vacuum energy E0(θ) on a few-qubit simulator. Our results show a displaced vacuum at nonzero θin agreement with strong-interaction expectations, and demonstrate that introducing a dynamical axion field drives the system toward θ= 0, thereby realizing the Peccei-Quinn mechanism within a minimal quantum simulation. These results illustrate how quantum hardware can examine symmetry violation and its dynamical resolution in gauge theories.

</details>


### [43] [The emergence of long-range entanglement and odd-even effect in periodic generalized cluster models](https://arxiv.org/abs/2512.13110)
*Zhen-Yu Zheng,Shu Chen*

Main category: quant-ph

TL;DR: 研究广义簇模型在周期边界条件下的纠缠特性，发现当系统尺寸N和相互作用范围m均为奇数时，系统表现出非零的四部分量子条件互信息熵，这直接标志着长程纠缠的存在。


<details>
  <summary>Details</summary>
Motivation: 研究一维自旋系统中长程纠缠的出现机制，探索系统尺寸和相互作用范围如何共同调控纠缠特性。

Method: 在周期边界条件下研究广义簇模型，通过计算纠缠熵和量子条件互信息熵（在三部分或四部分子系统划分下），识别长程纠缠的特征信号。

Result: 当N和m均为奇数时，系统表现出非零的四部分量子条件互信息熵，直接表明长程纠缠的存在；其他N和m组合则得到零值四部分量子条件互信息熵。在N,m均为奇数的情况下，即使存在有限横向场，这些长程纠缠特征仍然保持，显示出对量子涨落的鲁棒性。

Conclusion: 系统尺寸和相互作用范围之间的相互作用决定了一维自旋系统中长程纠缠的出现，为理解量子多体系统中的纠缠结构提供了新见解。

Abstract: We investigate the entanglement properties in a generalized cluster model under periodic boundary condition. By evaluating the entanglement entropy and the quantum conditional mutual information entropy under three or four subsystem partitions, we identify clear signatures of long-range entanglement. Specifically, when both the system size $N$ and the interaction range $m$ are odd, the system exhibits nonzero four-part quantum conditional mutual information entropies. This non-vanishing four-part quantum conditional mutual information entropy directly signals the presence of long-range entanglement. In contrast, all other combination of $N$ and $m$ yield vanishing four-part quantum conditional mutual information entropy. Remarkably, in the case of $N, m \in \text{odd}$, these long-range entangled features persist even in the presence of a finite transverse field, demonstrating their robustness against quantum fluctuations. These results demonstrate how the interplay between system size and interaction range governs the emergence of long-range entanglement in one-dimensional spin systems.

</details>


### [44] [Neural quantum states for entanglement depth certification from randomized Pauli measurements](https://arxiv.org/abs/2512.13121)
*Marcin Płodzień*

Main category: quant-ph

TL;DR: 提出基于神经量子态和似然比检验的纠缠深度认证方法，无需全层析或定制见证者，直接从测量统计推断纠缠结构


<details>
  <summary>Details</summary>
Motivation: 传统纠缠深度认证方法（定制见证者或全层析）随系统规模扩展性差，需要开发更高效、可扩展的认证方法

Method: 将纠缠深度认证重构为基于神经量子态的模型选择问题：训练具有不同纠缠约束的层次化可分离神经量子态模型，与无约束参考模型比较似然度；当所有约束模型都被统计拒绝时，数据证明超越限制的纠缠

Result: 在模拟的6和10量子比特数据集（GHZ、Dicke、Bell对态）上验证方法有效性，证明对局部噪声下混合态的鲁棒性；从训练参数中提取轻量级可解释性诊断，揭示纠缠模式和量子比特分组

Conclusion: 该方法为纠缠深度认证提供了可扩展的替代方案，直接从测量统计推断纠缠结构，避免了密度矩阵重构，具有实际应用潜力

Abstract: Entanglement depth quantifies how many qubits share genuine multipartite entanglement, but certification typically relies on tailored witnesses or full tomography, both of which scale poorly with system size. We recast entanglement-depth and non-$k$-separability certification as likelihood-based model selection among neural quantum states whose architecture enforces a chosen entanglement constraint. A hierarchy of separable neural quantum states is trained on finite-shot local Pauli outcomes and compared against an unconstrained reference model trained on the same data. When all constrained models are statistically disfavored, the data certify entanglement beyond the imposed limit directly from measurement statistics, without reconstructing the density matrix. We validate the method on simulated six- and ten-qubit datasets targeting GHZ, Dicke, and Bell-pair states, and demonstrate robustness for mixed states under local noise. Finally, we discuss lightweight interpretability diagnostics derived from trained parameters that expose coarse entanglement patterns and qubit groupings directly from bitstring statistics.

</details>


### [45] [Genuine Tripartite Strong Coupling in a Superconducting-Spin Hybrid Quantum System](https://arxiv.org/abs/2512.13129)
*Yingqiu Mao,Han-Yu Ren,Zi-Yi Liu,Yi-Zheng Zhen,Tao Rong,Tao Jiang,Zhuo Chen,Zhe-Heng Yuan,Wen-Hua Qin,Xiaoran Zhang,Xiaobing Liu,Ming Gong,Kae Nemoto,William J. Munro,Johannes Majer*

Main category: quant-ph

TL;DR: 在固态混合量子系统中实现了超导量子比特、固定频率共面波导谐振器和NV色心系综之间的真正三方强耦合，观测到三模避免交叉和多种非线性特征。


<details>
  <summary>Details</summary>
Motivation: 建立一种新型混合腔量子电动力学体系，整合超导和自旋自由度，为探索复杂多组分动力学和开发混合量子接口提供平台。

Method: 构建包含超导transmon量子比特、固定频率共面波导谐振器和金刚石中NV色心系综的固态混合量子系统，通过频域光谱学进行表征。

Result: 观测到特征性的三模避免交叉，表明单个激发在所有三个子系统间相干共享；在更高探测功率下观察到多光子跃迁和transmon-氮核自旋相互作用的非线性特征。

Conclusion: 成功建立了超导和自旋自由度整合的新型混合腔QED体系，为探索复杂多组分动力学和开发混合量子接口提供了有前景的平台。

Abstract: We demonstrate genuine tripartite strong coupling in a solid-state hybrid quantum system comprising a superconducting transmon qubit, a fixed-frequency coplanar-waveguide resonator, and an ensemble of NV$^-$ centers in diamond. Frequency-domain spectroscopy reveals a characteristic three-mode avoided crossing, indicating that single excitations are coherently shared across all three subsystems. At higher probe powers, we observe nonlinear features including multiphoton transitions and signatures of transmon-${}^{14}\mathrm{N}$ nuclear-spin interactions, highlighting the accessibility of higher-excitation manifolds in this architecture. These results establish a new regime of hybrid cavity QED that integrates superconducting and spin degrees of freedom, providing a platform for exploring complex multicomponent dynamics and developing hybrid quantum interfaces.

</details>


### [46] [Intense-Laser Nondipole-Induced Symmetry Breaking in Solids](https://arxiv.org/abs/2512.13140)
*Asger Weeth,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: 研究在固体高次谐波产生模拟中引入非偶极项对光-物质耦合的影响，发现非偶极项会打破偶极选择规则，产生新的偏振光，特别是诱导出与材料拓扑相位相关的螺旋性。


<details>
  <summary>Details</summary>
Motivation: 固体高次谐波光谱学是研究固体内部结构的重要工具，但现有模拟通常依赖电偶极近似，而驱动场已进入挑战该近似准确性的区域。需要研究非偶极项对高次谐波产生的影响。

Method: 在材料高次谐波产生模拟中引入非偶极项的光-物质耦合，研究拓扑平凡和非平凡相材料中的效应，分析非偶极项如何打破偶极选择规则。

Result: 非偶极项的包含打破了偶极选择规则，允许产生新的偏振光。特别发现偶极近似中完全不存在的螺旋性被非偶极扩展诱导出来，且这种螺旋性依赖于材料的拓扑相位。

Conclusion: 在固体高次谐波产生模拟中考虑非偶极效应至关重要，这些效应不仅产生新的偏振特性，还能揭示材料的拓扑相位信息，为高次谐波光谱学提供新的探测维度。

Abstract: High-harmonic spectroscopy in solids gives insight into the inner workings of solids, such as reconstructing band structures or probing the topological phase of materials. High-harmonic generation (HHG) is a highly non-linear phenomena and simulations guide interpretation of experimental results. These simulations often rely on the electric dipole approximation, even though the driving fields enter regimes that challenge its accuracy. Here, we investigate effects of including nondipole terms in the light-matter coupling in simulations of HHG in materials with both topologically trivial and non-trivial phases. We show how the inclusion of nondipole terms breaks dipole selection rules, allowing for new polarizations of the generated light. Specifically we find that helicity, completely absent in the dipole approximation, is induced by the nondipole extension, and that this helicity is dependent on the topological phase of the material.

</details>


### [47] [Quantum critical dynamics and emergent universality in decoherent digital quantum processors](https://arxiv.org/abs/2512.13143)
*Brendan Rhyno,Swarnadeep Majumder,Smitha Vishveshwara,Khadijeh Najafi*

Main category: quant-ph

TL;DR: 论文研究噪声对量子临界动力学的影响，通过理论分析、数值模拟和IBM量子处理器实验，发现噪声可以重塑普适标度行为，形成新的噪声影响普适性区域。


<details>
  <summary>Details</summary>
Motivation: 理解噪声如何影响非平衡量子临界动力学对于基础物理和量子技术发展至关重要。量子Kibble-Zurek机制预测了穿越临界点时的普适标度行为，但实际量子系统中的退相干会显著改变这些行为，从改变临界标度到完全抑制它。

Method: 1. 理论分析：考虑特定非破坏性噪声模型，研究退相干如何重塑普适标度；2. 数值模拟：在广泛噪声强度范围内对自旋链进行数值模拟验证理论预测；3. 实验研究：在IBM超导量子处理器上对横向场Ising模型进行线性淬火实验，使用80-120量子比特系统，测量等时关联函数、缺陷密度和过剩能量。

Result: 1. 理论预测得到数值模拟验证；2. 在IBM量子处理器实验中观察到清晰的标度关系，表明退相干塑造的普适结构持续存在；3. 提取的标度指数既不同于理想QKZ预测，也不同于简化噪声模型的分析结果，表明出现了新的噪声影响普适性区域。

Conclusion: 研究结果表明，可以利用普适动力学标度作为量子硬件的高级描述符，补充传统的门级性能指标，为理解噪声影响下的量子临界动力学提供了新视角。

Abstract: Understanding how noise influences nonequilibrium quantum critical dynamics is essential for both fundamental physics and the development of practical quantum technologies. While the quantum Kibble-Zurek (QKZ) mechanism predicts universal scaling during quenches across a critical point, real quantum systems exhibit complex decoherence that can substantially modify these behaviors, ranging from altering critical scaling to completely suppressing it. By considering a specific case of nondemolishing noise, we first show how decoherence can reshape universal scaling and verify these theoretical predictions using numerical simulations of spin chains across a wide range of noise strengths. Then, we study linear quenches in the transverse-field Ising model on IBM superconducting processors where the noise model is unknown. Using large system sizes of 80-120 qubits, we measure equal-time connected correlations, defect densities, and excess energies across various quench times. Surprisingly, unlike earlier observations where noise-induced defect production masked universal behavior at long times, we observe clear scaling relations, pointing towards persistent universal structure shaped by decoherence. The extracted scaling exponents differ from both ideal QKZ predictions and analytic results for simplified noise models, suggesting the emergence of a distinct noise-influenced universality regime. Our results, therefore, point toward the possibility of using universal dynamical scaling as a high-level descriptor of quantum hardware, complementary to conventional gate-level performance metrics.

</details>


### [48] [Practical Homodyne Shadow Estimation](https://arxiv.org/abs/2512.13146)
*Ruyu Yang,Xiaoming Sun,Hongyi Zhou*

Main category: quant-ph

TL;DR: 提出了一种实用的连续变量系统影子估计协议，使用离散化零差检测，改进了方差界限，实现了理论与实验的桥梁。


<details>
  <summary>Details</summary>
Motivation: 现有的连续变量系统影子估计方法存在理想化假设（连续相位调制和无限测量分辨率）的限制，难以在实际实验中实现。需要开发一种更实用的协议来弥合理论与实验之间的差距。

Method: 使用离散化零差检测，具有有限数量的相位设置和正交分箱。在截断的福克空间内构建无偏估计器，并建立信息完备性的充分和必要条件。

Result: 开发了实用的影子估计协议，方差界限改进为O(n_max^4)，优于之前的O(n_max^{13/3})界限。建立了信息完备性的理论条件。

Conclusion: 该工作弥合了理论影子估计与实验实现之间的差距，使连续变量系统能够在实际条件下进行稳健和可扩展的量子态表征。

Abstract: Shadow estimation provides an efficient framework for estimating observable expectation values using randomized measurements. While originally developed for discrete-variable systems, its recent extensions to continuous-variable (CV) quantum systems face practical limitations due to idealized assumptions of continuous phase modulation and infinite measurement resolution. In this work, we develop a practical shadow estimation protocol for CV systems using discretized homodyne detection with a finite number of phase settings and quadrature bins. We construct an unbiased estimator for the quantum state and establish both sufficient conditions and necessary conditions for informational completeness within a truncated Fock space up to $n_{\mathrm{max}}$ photons. We further provide a comprehensive variance analysis, showing that the shadow norm scales as $\mathcal{O}(n_{\mathrm{max}}^4)$, improving upon previous $\mathcal{O}(n_{\mathrm{max}}^{13/3})$ bounds. Our work bridges the gap between theoretical shadow estimation and experimental implementations, enabling robust and scalable quantum state characterization in realistic CV systems.

</details>


### [49] [Investigation of a Bit-Sequence Reconciliation Protocol Based on Neural TPM Networks in Secure Quantum Communications](https://arxiv.org/abs/2512.13199)
*Matvey Yorkhov,Vladimir Faerman,Anton Konev*

Main category: quant-ph

TL;DR: 本文提出基于树奇偶机(TPM)的量子密钥分发(QKD)密钥协调协议，通过将密钥材料转换为神经网络权重，研究了同步迭代次数和泄露信息量与量子比特错误率(QBER)及权重范围的关系。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发系统需要高效的密钥协调协议来纠正传输错误，传统方法存在效率和安全性的限制。本文探索基于神经密码学方法的密钥协调方案，旨在提高QKD系统的效率和安全性。

Method: 提出基于树奇偶机(TPM)的密钥协调协议，将密钥材料转换为神经网络权重。通过两个实验研究：1）同步迭代次数与QBER和权重范围的关系；2）泄露信息量与权重范围的关系。

Result: 实验结果显示：1）平均同步迭代次数与QBER呈正相关；2）权重范围扩大时迭代次数增加；3）权重范围增大时泄露信息量减少。这些发现为协议优化提供了依据。

Conclusion: 基于树奇偶机的密钥协调协议在QKD系统中具有应用潜力，权重范围的选择需要在同步效率和安全性之间权衡。神经密码学方法在密钥协调领域有进一步研究的价值。

Abstract: The article discusses a key reconciliation protocol for quantum key distribution (QKD) systems based on Tree Parity Machines (TPM). The idea of transforming key material into neural network weights is presented. Two experiments were conducted to study how the number of synchronization iterations and the amount of leaked information depend on the quantum bit error rate (QBER) and the range of neural network weights. The results show a direct relationship between the average number of synchronization iterations and QBER, an increase in iterations when the weight range is expanded, and a reduction in leaked information as the weight range increases. Based on these results, conclusions are drawn regarding the applicability of the protocol and the prospects for further research on neural cryptographic methods in the context of key reconciliation.

</details>


### [50] [A Conjecture on Almost Flat SIC-POVMs](https://arxiv.org/abs/2512.13201)
*Ingemar Bengtsson,Markus Grassl*

Main category: quant-ph

TL;DR: 该论文研究了SIC-POVMs中与反幺正对称性相关的代数恒等式是否足以唯一确定Stark单位，结论是否定的，但失败程度可能很轻微。


<details>
  <summary>Details</summary>
Motivation: 研究SIC-POVMs（最大复等角线集）中与反幺正对称性相关的代数恒等式是否能够唯一确定Stark单位，这对于理解SIC-POVMs的代数结构和数论性质具有重要意义。

Method: 通过数论方法分析SIC-POVMs中的代数恒等式，该恒等式将Stark单位表示为Stark单位平方根乘积之和。研究该恒等式是否足以确定这些Stark单位。

Result: 研究发现该恒等式不足以唯一确定Stark单位，但失败的程度可能相对轻微，表明可能存在其他约束条件或结构特征。

Conclusion: 虽然SIC-POVMs中的代数恒等式不能完全确定Stark单位，但这一失败可能不是根本性的，为进一步研究SIC-POVMs的代数结构和数论性质提供了方向。

Abstract: A well supported conjecture states that SIC-POVMs -- maximal sets of complex equiangular lines -- with anti-unitary symmetry give rise to an identity expressing some of its overlaps as squares of the (rescaled) components of a suitably chosen fiducial vector. In number theoretical terms the identity essentially expresses Stark units as sums of products of pairs of square roots of Stark units. We investigate whether the identity is enough to determine these Stark units. The answer is no, but the failure might be quite mild.

</details>


### [51] [High-purity frequency-degenerate photon pair generation via cascaded SFG/SPDC in thin film lithium niobate](https://arxiv.org/abs/2512.13248)
*Olivia Hefti,Marco Clementi,Enrico Melani,Jean-Etienne Tremblay,Andrea Volpini,Yesim Koyaz,Homa Zarebidaki,Ivan Prieto,Olivier Dubochet,Daniele Bajoni,Charles Caër,Hamed Sattari,Camille-Sophie Brès,Matteo Galli,Davide Grassani*

Main category: quant-ph

TL;DR: 提出一种基于双泵浦方案的频率简并光子对生成方法，在单个波导中通过级联和频与自发参量下转换产生光子对，同时抑制单泵浦过程的寄生光子对生成。


<details>
  <summary>Details</summary>
Motivation: 频率简并光子对是量子信息处理和计量学的重要资源，但传统方法受到相同相位匹配带内不需要的参量过程干扰，导致信噪比下降和量子态纯度降低。

Method: 采用双泵浦方案，在单个波导中实现级联和频生成与自发参量下转换，同时强烈抑制单泵浦过程的寄生光子对生成。该方法简化了设计，使泵浦和光子对收集都能在电信波段进行。

Result: 在层极化薄膜铌酸锂波导中实验验证了该概念，实现了频率简并光子对生成，亮度达到1.0(3)×10⁵ Hz/nm/mW²，并对不需要的单泵浦过程实现了40 dB的抑制。

Conclusion: 该双泵浦方案为频率简并光子对生成提供了一种简化且高效的方法，显著抑制了寄生过程，有望推动量子信息处理应用的发展。

Abstract: Frequency-degenerate photon pairs generated using nonlinear photonic integrated devices are a crucial resource for scalable quantum information processing and metrology. However, their realization is hindered by unwanted parametric processes occurring within the same phase matching band, which degrade the signal-to-noise ratio and reduce the purity of the associated quantum states. Here, we propose a dual-pump scheme to produce frequency-degenerate photon pairs, based on cascaded sum-frequency generation and spontaneous parametric down-conversion occurring within a single waveguide, while strongly suppressing parasitic photon pair generation from single-pump processes. This approach significantly simplifies the design compared to microresonator-based methods and enables both pumping and collection of photon pairs entirely in the telecom band. We experimentally validate the concept in a layer-poled thin film lithium niobate waveguide, achieving frequency-degenerate photon pair generation with a brightness of \SI{1.0(3)e5}{\hertz \per \nm \per \square \milli \watt } and a 40 dB suppression of unwanted single-pump processes.

</details>


### [52] [Distillation of continuous variable qudits from single photon sources: A cascaded approach](https://arxiv.org/abs/2512.13264)
*Devibala Esakkimuthu,Basherrudin Mahmud Ahmed Abduljaffer*

Main category: quant-ph

TL;DR: 提出一种使用线性光学装置（级联分束器）仅依赖单光子源和单光子探测器来制备高质量连续变量量子态的方法，能够生成多种重要量子态并达到高保真度。


<details>
  <summary>Details</summary>
Motivation: 在连续变量体系中创建高保真度光子量子态对量子技术实现至关重要，但传统方法需要高非线性或大福克态，实现困难。本文旨在克服这一限制。

Method: 使用线性光学装置，通过级联分束器排列，仅依赖单光子源和单光子探测器来定制所需单模非经典态。将输出表示为位移qudit形式，便于高效识别和优化输入参数。

Result: 成功生成位移高光子态（单位保真度）、薛定谔猫态家族（>98%保真度）、GKP资源态（如ON态和弱立方相位态，99%保真度）。考虑了探测器效率和单光子源非理想性的实验缺陷。

Conclusion: 该级联装置为实验人员使用现有资源（单光子源和单光子探测器）探索目标态的可行制备提供了有效途径，展示了线性光学方法在连续变量量子态制备中的强大潜力。

Abstract: Creation of high fidelity photonic quantum states in the continuous variable regime is indispensable for the implementation of quantum technologies universally. However, this is a challenging task as it requires higher nonlinearity or larger Fock states. In this article, we surmount this necessity by using a linear optical setup with a cascaded arrangement of beam splitters that relies solely on single photon sources and single photon detectors to tailor desired single mode nonclassical states. To show the utility of this setup, we demonstrate the generation of displaced higher photon states with unit fidelity and the family of Schrodinger cat states above $98\%$ fidelity. In addition, we manifest the generation of GKP resource states, such as ON states and weak cubic phase states with $99\%$ fidelity. Creating such a variety of important states in this single setup is made feasible by stating the output in the form of displaced qudits. This figure of merit facilitates efficient identification and optimization of input parameters required to generate the target single mode quantum states. We also account for the experimental imperfections by incorporating detector inefficiencies and non-unit single photon sources. This cascaded setup will assist the experimentalists to explore the feasible creation of target states using currently available resources, such as single photon sources and single photon detectors.

</details>


### [53] [Slowing and Storing Microwaves in a Single Superconducting Fluxonium Artificial Atom](https://arxiv.org/abs/2512.13272)
*Ching-Yeh Chen,Shih-Wei Lin,Ching-Ping Lee,J. C. Chen,I. -C. Hoi,Yen-Hsiang Lin*

Main category: quant-ph

TL;DR: 在微波波导中使用单个Fluxonium量子比特实现三能级Λ系统，观测到电磁感应透明、光速减慢和光子存储，展示了在超导电路中作为量子通信相位调制器或量子存储器的潜力。


<details>
  <summary>Details</summary>
Motivation: 三能级Λ系统是实现电磁感应透明、慢光和量子记忆的重要平台。虽然已在原子系统、超导人工原子等平台实现，但之前涉及超导人工原子的实验都耦合了额外自由度（如谐振器或其他超导原子）。本研究旨在探索在微波波导中使用单个Fluxonium量子比特实现Λ系统的可能性。

Method: 在微波波导中使用单个Fluxonium量子比特构建Λ系统。该系统由两个等离子体跃迁和一个源自fluxon跃迁的亚稳态组成。控制跃迁和探测跃迁都与传输线强耦合，保护了0和1态之间的跃迁，并确保Fluxonium量子比特接近最佳工作点。

Result: 观测到电磁感应透明现象，实现了光速减慢（延迟时间217纳秒），并成功演示了光子存储。这些结果表明该系统可作为相位调制器或量子存储器应用于量子通信。

Conclusion: 成功在微波频率范围内使用单个Fluxonium量子比特实现了Λ系统，展示了电磁感应透明、光速减慢和光子存储等量子光学现象。这项工作突出了Fluxonium量子比特在超导电路中作为量子通信相位调制器或量子存储器的应用潜力。

Abstract: Three-level Lambda systems provide a versatile platform for quantum optical phenomena such as Electromagnetically Induced Transparency (EIT), slow light, and quantum memory. Such Lambda systems have been realized in several quantum hardware platforms including atomic systems, superconducting artificial atoms, and meta-structures. Previous experiments involving superconducting artificial atoms incorporated coupling to additional degrees of freedom, such as resonators or other superconducting atoms. In this work, we performed an EIT experiment in microwave frequency range utilizing a single Fluxonium qubit within a microwave waveguide. The Lambda system is consisted of two plasmon transitions in combination with one metastable state originating from the fluxon transition. In this configuration, the controlling and probing transitions are strongly coupled to the transmission line, safeguarding the transition between 0 and 1 states, and ensuring the Fluxonium qubit is close to the sweet spot. Our observations include the manifestation of EIT, a slowdown of light with a delay time of 217 ns, and photon storage. These results highlight the potential as a phase shifter or quantum memory for quantum communication in superconducting circuits.

</details>


### [54] [Dual-Qubit Hierarchical Fuzzy Neural Network for Image Classification: Enabling Relational Learning via Quantum Entanglement](https://arxiv.org/abs/2512.13274)
*Wenwei Zhang,Jintao Wang,Tianyu Ye,Changgeng Liao*

Main category: quant-ph

TL;DR: 提出双量子比特层次模糊神经网络（DQ-HFNN），通过纠缠量子比特编码特征对，解决传统模型无法同时处理数据不确定性和特征依赖关系的问题。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络难以同时表示数据不确定性和捕捉特征间依赖关系，尤其在模糊或噪声条件下。现有的量子辅助层次模糊神经网络（QA-HFNN）只能学习单个特征的模糊隶属度，无法建模特征间依赖关系。

Method: 提出双量子比特层次模糊神经网络（DQ-HFNN），将特征对编码到一对纠缠量子比特上，将单特征模糊模型扩展到联合模糊表示。通过量子纠缠编码非经典相关性，使模型能够直接学习特征对之间的关系模式。

Result: 在基准测试中，DQ-HFNN比QA-HFNN和经典深度学习基线表现出更高的分类准确率。消融研究表明性能提升主要来自纠缠实现的关系建模能力，而非增强的表达能力。模型具有高参数效率和快速推理速度，在噪声条件下表现出鲁棒性。

Conclusion: DQ-HFNN通过纠缠量子比特编码特征对，有效解决了传统模型在同时处理数据不确定性和特征依赖关系方面的局限性，具有参数效率高、推理速度快、噪声鲁棒性强等优点，适合在噪声中等规模量子设备上实现。

Abstract: Classical deep neural network models struggle to represent data uncertainty and capture dependencies between features simultaneously, especially under fuzzy or noisy conditions. Although a quantum-assisted hierarchical fuzzy neural network (QA-HFNN) was proposed to learn fuzzy membership for each feature, it cannot model dependencies between features due to its single-qubit encoding. To address this, this paper proposes a dual-qubit hierarchical fuzzy neural network (DQ-HFNN), encoding feature pairs onto a pair of entangled qubits, which extends the single-feature fuzzy model to a joint fuzzy representation. By introducing quantum entanglement, the dual-qubit circuit can encode non-classical correlations, enabling the model to directly learn relationship patterns between feature pairs. Experiments on benchmarks show that DQ-HFNN demonstrates higher classification accuracy than QA-HFNN, as well as classical deep learning baselines. Furthermore, ablation studies after controlling for circuit depth and parameter counts show that the performance gain mainly stems from the relational modeling capability enabled by entanglement rather than enhanced expressivity. The proposed DQ-HFNN model exhibits high parameter efficiency and fast inference speed. Experiments under noisy conditions suggest that it is robust against noise and has the potential to be implemented on noisy intermediate-scale quantum devices.

</details>


### [55] [Coherent feedback-enhanced asymmetry of thermal process in open quantum systems: Cavity optomechanics](https://arxiv.org/abs/2512.13288)
*Hamza Harraf,Mohamed Amazioug,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 该论文研究了在稳态下利用相干反馈回路增强不可逆性，发现熵产生率与量子互信息成正比，并通过法布里-珀罗腔光机械系统验证了熵产生峰值的增强。


<details>
  <summary>Details</summary>
Motivation: 研究非平衡热力学中熵产生这一基本概念，探索如何通过相干反馈回路增强物理过程的不可逆性，并揭示不可逆性与量子关联之间的内在联系。

Method: 采用量子相空间表述计算熵变化，评估稳态熵产生率和量子关联，在弱耦合极限下分析熵产生率与量子互信息的关系，并应用法布里-珀罗腔光机械系统进行验证。

Result: 研究发现相干反馈在热浴输入噪声算符中起关键作用，使系统远离热平衡；在弱耦合极限下，熵产生率与量子互信息成正比；在光机械系统中，可移动镜面加热/冷却对应的熵产生峰值得到改善。

Conclusion: 不可逆性与量子关联不是独立的，必须联合分析；研究结果为通过相干反馈回路增强熵产生提供了可能性，并为量子热应用开辟了新途径。

Abstract: Entropy production is a fundamental concept in nonequilibrium thermodynamics, providing a direct measure of the irreversibility inherent in any physical process. In this work, we investigate in steady-state the enhancement of irreversibility employing coherent feedback loop. We evaluate the steady-state entropy production rate and quantum correlations by applying the quantum phase space formulation to calculate the entropy change. Our study reveals the essential contribution of coherent feedback in the thermal bath's input-noise operators, resulting in the system being driven far from thermal equilibrium. Our analysis shows that in the small-coupling limit, the entropy production rate is proportional to the quantum mutual information. We use for application the optomechanical system of Fabry-Pérot cavity, and show that the picks of the entropy production corresponding of the heating/cooling of movable mirror are improved. Therefore, we conclude that irreversibility and quantum correlations are not independent and must be analyzed jointly. The results demonstrate the possibility of enhancement of entropy production and pave the way for promising quantum thermal applications through coherent feedback loop.

</details>


### [56] [Projected Optimal Sensors from Operator Orbits](https://arxiv.org/abs/2512.13294)
*Sooryansh Asthana,Yeshma Ibrahim,Norman Tze Wei Koo,Sai Vinjanampathy*

Main category: quant-ph

TL;DR: 该论文提出了一种统一框架，将Ramsey、twist-untwist和随机量子传感器纳入算子代数体系，分析了各种传感器设计的Fisher信息标度行为，并设计了一类新型传感器。


<details>
  <summary>Details</summary>
Motivation: 现有量子传感器设计（如Ramsey、twist-untwist和随机传感器）缺乏统一的理论框架来分析其Fisher信息标度行为。需要建立统一模型来理解不同传感器设计的性能标度，并在此基础上设计新型高性能传感器。

Method: 使用算子代数统一描述各类量子传感器，通过算子轨道分析状态制备对子系统数量标度的影响。利用统一模型设计新型传感器，其中投影量子态集合展现出超越散粒噪声的计量性能。

Result: 建立了量子传感器的统一理论框架，能够解释各种传感器设计的Fisher信息标度行为。设计的新型传感器在投影量子态集合中实现了超越散粒噪声的计量性能。同时展示了在退相干模型和粒子损失情况下Fisher信息的有利标度特性。

Conclusion: 通过算子代数框架统一了量子传感器设计，不仅解释了现有传感器的标度行为，还启发了新型高性能传感器的设计。该统一模型为量子计量学提供了理论基础，有助于开发具有优越标度特性的量子传感器。

Abstract: We unify Ramsey, twist-untwist, and random quantum sensors using operator algebra and account for the Fisher scaling of various sensor designs. We illustrate how the operator orbits associated with state preparation inform the scaling of the sensitivity with the number of subsystems. Using our unified model, we design a novel set of sensors in which a projected ensemble of quantum states exhibits beyond-shot-noise metrological performance. We also show favorable scaling of Fisher information with decoherence models and loss of particles.

</details>


### [57] [Fault-tolerant multi-qubit gates in Parity Codes](https://arxiv.org/abs/2512.13335)
*Anette Messinger,Christophe Goeller,Wolfgang Lechner*

Main category: quant-ph

TL;DR: 提出在级联量子纠错码中使用奇偶校验量子比特实现高效多量子比特逻辑门的方法


<details>
  <summary>Details</summary>
Motivation: 传统量子纠错码中的高权重旋转门和多量子比特逻辑门实现复杂，需要格点手术或复杂路由操作，效率较低

Method: 使用奇偶校验量子比特在级联量子纠错码中实现逻辑门：1）在经典稳定子码的单个物理量子比特上实现任意角度的高权重旋转门；2）在量子纠错码的局部区域实现类似操作；3）利用横向CNOT门实现任意多个逻辑量子比特之间的奇偶控制NOT操作

Result: 实现了无需格点手术或复杂路由操作的高效多量子比特逻辑门，许多情况下可以并行化执行

Conclusion: 该方法为量子纠错码中的逻辑门实现提供了更高效的途径，简化了多量子比特操作，有望提升量子计算的容错性能

Abstract: We present a set of efficiently implementable logical multi-qubit gates in concatenated quantum error correction codes using parity qubits. In particular, we show how fault-tolerant high-weight rotation gates of arbitrary angle can be implemented on single physical qubits of a classical stabilizer code, or on localized regions of full quantum error correction codes. Similarly, we show how transversal CNOT gates can implement logical parity-controlled-NOT operations between arbitrarily many logical qubits. Both operation types can be implemented and in many cases parallelized without the use of lattice surgery or the need for complicated routing operations.

</details>


### [58] [Achievable Trade-Off in Network Nonlocality Sharing](https://arxiv.org/abs/2512.13357)
*Ming-Xiao Li,Yuqi Li,Rui-Bin Xu,Mo-Ran Zhu,Haitao Ma,Chang-Yue Zhang,Zhu-Jun Zheng*

Main category: quant-ph

TL;DR: 该论文建立了量子网络非局域性共享的纠缠阈值，提出了一种基于概率投影测量的协议，实现了网络范围内无界共享，并分析了实际噪声下的可行性。


<details>
  <summary>Details</summary>
Motivation: 量子网络对于可扩展量子信息处理至关重要，量子非局域性共享提供了一种资源高效回收量子关联的策略。然而，资源有限性导致可共享网络分支数量与可实现的顺序共享轮数之间存在基本权衡，且纠缠与共享能力之间的关系尚未充分探索，这限制了量子网络的高效设计和可扩展性。

Method: 引入基于概率投影测量的协议，建立支持整个网络无界共享的纠缠阈值。当资源低于该阈值时，推导出可共享分支数量与共享轮数之间的可实现权衡。将协议与弱测量方案进行比较以评估实际可行性，并将共享协议扩展到现实噪声模型。

Result: 建立了支持整个网络无界共享的纠缠阈值，当资源低于阈值时获得了可共享分支数量与共享轮数之间的明确权衡关系。协议在实际噪声模型中表现出鲁棒性，为量子网络中的非局域性回收提供了实用框架。

Conclusion: 该研究为量子网络中的非局域性共享提供了理论基础和实用协议，建立了纠缠资源与共享能力之间的定量关系，解决了量子网络可扩展性设计中的关键限制，推动了资源高效量子网络的发展。

Abstract: Quantum networks are essential for advancing scalable quantum information processing. Quantum nonlocality sharing provides a crucial strategy for the resource-efficient recycling of quantum correlations, offering a promising pathway toward scaling quantum networks. Despite its potential, the limited availability of resources introduces a fundamental trade-off between the number of sharable network branches and the achievable sequential sharing rounds. The relationship between available entanglement and the sharing capacity remains largely unexplored, which constrains the efficient design and scalability of quantum networks. Here, we establish the entanglement threshold required to support unbounded sharing across an entire network by introducing a protocol based on probabilistic projective measurements. When resources fall below this threshold, we derive an achievable trade-off between the number of sharable branches and sharing rounds. To assess practical feasibility, we compare the detectability of our protocol with weak-measurement schemes and extend the sharing protocol to realistic noise models, providing a robust framework for nonlocality recycling in quantum networks.

</details>


### [59] [Impact of Information on Quantum Heat Engines](https://arxiv.org/abs/2512.13371)
*Lindsay Bassman Oftelie,Michele Campisi*

Main category: quant-ph

TL;DR: 提出了一个通用框架，用于描述与N个热浴和麦克斯韦妖相互作用的两冲程量子热机，将机器和记忆作为混合经典-量子标准热机处理。


<details>
  <summary>Details</summary>
Motivation: 量子热力学领域揭示了信息在量子热机中的重要作用，特别是在反馈控制热机中。虽然已有量子反馈控制的一般理论和具体例子，但仍缺乏此类机器的通用框架。

Method: 提出了一个通用框架，描述与N个热浴和麦克斯韦妖相互作用的两冲程量子热机。妖对工作物质进行投影测量，结果记录在嵌入自身热浴的经典记忆中。通过将机器-记忆复合体视为与N+1个热浴相互作用的混合（经典-量子）标准热机，将工作物质和记忆放在同等地位。

Result: 该框架能够清晰解决麦克斯韦悖论，并通过双量子比特引擎示例说明其应用。一个显著发现是：更多信息并不一定带来更好的热力学性能，有时知道更少反而更好。

Conclusion: 提出的通用框架为量子反馈控制热机提供了统一的理论基础，将工作物质和记忆系统平等对待，揭示了信息在量子热力学中的复杂作用。

Abstract: The emerging field of quantum thermodynamics is beginning to reveal the intriguing role that information can play in quantum thermal engines. Information enters as a resource when considering feedback-controlled thermal machines. While both a general theory of quantum feedback control as well as specific examples of quantum feedback-controlled engines have been presented, still lacking is a general framework for such machines. Here, we present a framework for a generic, two-stroke quantum heat engine interacting with $N$ thermal baths and Maxwell's demon. The demon performs projective measurements on the engine working substance, the outcome of which is recorded in a classical memory, embedded in its own thermal bath. To perform feedback control, the demon enacts unitary operations on the working substance, conditioned on the recorded outcome. By considering the compound machine-memory as a hybrid (classical-quantum) standard thermal machine interacting with $N+1$ thermal baths, our framework puts the working substance and memory on equal footing, thereby enabling a comprehensible resolution to Maxwell's paradox. We illustrate the application of our framework with a two-qubit engine. A remarkable observation is that more information does not necessarily result in better thermodynamic performance: sometimes knowing less is better.

</details>


### [60] [Fundamental bound on entanglement generation between interacting Rydberg atoms](https://arxiv.org/abs/2512.13379)
*Georgios Doultsinos,Antonis Delakouras,David Petrosyan*

Main category: quant-ph

TL;DR: 该论文推导了利用里德堡态相互作用制备双原子最大纠缠态（贝尔态）的基本误差下界，并通过量子最优控制方法找到了接近该理论极限的激光脉冲方案。


<details>
  <summary>Details</summary>
Motivation: 在基于里德堡态相互作用的量子信息处理中，制备高保真度的纠缠态是关键挑战。需要理解由于里德堡态自发衰变和有限相互作用强度带来的基本限制，并寻找接近理论极限的优化方案。

Method: 1. 理论推导：解析推导了制备双原子贝尔态保真度的基本下界，误差E ≥ (1 + π/2)Γ/B，其中Γ是里德堡态自发衰变率，B是相互作用强度。
2. 量子最优控制：采用量子最优控制方法设计激光脉冲序列，以最小化制备误差。

Result: 1. 建立了基本误差下界：E ≥ (1 + π/2)Γ/B，这是由里德堡态自发衰变和有限相互作用强度决定的理论极限。
2. 通过最优控制找到了接近极限的脉冲方案：制备误差仅比理论下界高1%，实现了接近最优的纠缠态制备。

Conclusion: 该工作为里德堡态量子信息处理提供了重要的理论基准，证明了量子最优控制方法能够实现接近理论极限的高保真度纠缠态制备，对量子计算和量子模拟应用具有重要意义。

Abstract: We analytically derive the fundamental lower bound for the preparation fidelity of a maximally-entangled (Bell) state of two atoms involving Rydberg-state interactions. This bound represents the minimum achievable error $E \geq ( 1 + π/2 ) Γ/B$ due to spontaneous decay $Γ$ of the Rydberg states and their finite interaction strength $B$. Using quantum optimal control methods, we identify laser pulses for preparing a maximally-entangled state of a pair of atomic qubits with an error only $1\%$ above the derived fundamental bound.

</details>


### [61] [Quantum Chaos as an Essential Resource for Full Quantum State Controllability](https://arxiv.org/abs/2512.13384)
*Lukas Beringer,Mathias Steinhuber,Klaus Richter,Steven Tomsovic*

Main category: quant-ph

TL;DR: 量子混沌系统可利用弱微扰实现对数时间尺度的完全可控性，而可积系统则不具备这种特性


<details>
  <summary>Details</summary>
Motivation: 研究如何将经典混沌控制中的遍历性和指数不稳定性概念转化为量子框架，探索量子混沌系统是否也能实现类似的控制能力

Method: 使用量子混沌的两个关键特性：1) 对弱微扰的动力学敏感性（保真度衰减）替代经典初始条件敏感性；2) 随机矩阵理论描述的统计特性实现遍历性控制。以量子踢转子为例进行说明

Result: 量子混沌系统原则上允许在仅与系统尺寸和ħ⁻¹对数相关的时间尺度内实现完全可控性，能够从任意初始态精细调控到任意目标态，并可产生复苏态、猫态纠缠态等

Conclusion: 量子混沌系统具备弱微扰下的完全可控性，而可积系统缺乏遍历性和指数不稳定性，需要打破可积性才能实现控制

Abstract: Using the key properties of chaos, i.e.~ergodicity and exponential instability, as a resource to control classical dynamics has a long and considerable history. However, in the context of controlling ``chaotic'' quantum unitary dynamics, the situation is far more tenuous. The classical concepts of exponential sensitivity to trajectory initial conditions and ergodicity do not directly translate into quantum unitary evolution. Nevertheless properties inherent to quantum chaos can take on those roles: i) the dynamical sensitivity to weak perturbations, measured by the fidelity decay, serves a similar purpose as the classical sensitivity to initial conditions; and ii) paired with the fact that quantum chaotic systems are conjectured to be statistically described by random matrix theory, implies a method to translate the ergodic feature into the control of quantum dynamics. With those two properties, it can be argued that quantum chaotic dynamical systems, in principle, allow for full controllability beyond a characteristic time that scales only logarithmically with system size and $\hbar^{-1}$. In the spirit of classical targeting, it implies that it is possible to fine tune the immense quantum interference with weak perturbations and steer the system from any initial state into any desired target state, subject to constraints imposed by conserved quantities. In contrast, integrable dynamics possess neither ergodicity nor exponential instability, and thus the weak perturbations apparently must break the integrability for control purposes. The main ideas are illustrated with the quantum kicked rotor. The production of revivals, cat-like entangled states, and the transition from any random state to any other random state is possible as demonstrated.

</details>


### [62] [Riemannian gradient descent-based quantum algorithms for ground state preparation with guarantees](https://arxiv.org/abs/2512.13401)
*Mahum Pervez,Ariq Haqq,Nathan A. McMahon,Christian Arenz*

Main category: quant-ph

TL;DR: 研究黎曼梯度流用于在量子设备上制备目标哈密顿量的基态，提出黎曼梯度下降算法，其收敛步数取决于哈密顿量结构，并开发了随机投影近似和量子实现方案。


<details>
  <summary>Details</summary>
Motivation: 在量子设备上高效制备哈密顿量的基态是量子计算中的重要问题。传统方法可能效率不高，需要开发基于黎曼几何的优化方法，利用量子设备的特性来加速基态制备。

Method: 提出黎曼梯度下降算法，分析其收敛性并建立步数上界。开发随机投影近似方法，将黎曼梯度投影到多项式大小的子空间。基于Trotter分解和量子随机漂移协议实现量子设备上的高效实现。

Result: 建立了RGD步数上界，依赖于哈密顿量谱隙、基态与初始态重叠和目标精度。数值实验显示：一维最近邻伊辛链的RGD步数与自旋数呈线性关系，全耦合系统呈二次关系。随机投影RGD的收敛速度取决于投影子空间大小。

Conclusion: 黎曼梯度流为量子设备上的基态制备提供了有效框架，其收敛特性取决于哈密顿量结构。随机投影近似和量子实现方案为实现高效且保证收敛的算法提供了途径，在IBM量子设备上的小规模实验验证了可行性。

Abstract: We investigate Riemannian gradient flows for preparing ground states of a desired Hamiltonian on a quantum device. We show that the number of steps of the corresponding Riemannian gradient descent (RGD) algorithm that prepares a ground state to a given precision depends on the structure of the Hamiltonian. Specifically, we develop an upper bound for the number of RGD steps that depends on the spectral gap of the Hamiltonian, the overlap between ground and initial state, and the target precision. In numerical experiments we study examples where we observe for a 1D Ising chain with nearest-neighbor interactions that the RGD steps needed to prepare a ground state scales linearly with the number of spins. For all-to-all couplings a quadratic scaling is obtained. To achieve efficient implementations while keeping convergence guarantees, we develop RGD approximations by randomly projecting the Riemannian gradient into polynomial-sized subspaces. We find that the speed of convergence of the randomly projected RGD critically depends on the size of the subspace the gradient is projected into. Finally, we develop efficient quantum device implementations based on Trotterization and a quantum stochastic drift-inspired protocol. We implement the resulting quantum algorithms on IBM's quantum devices and provide data for small-scale problems.

</details>


### [63] [Decoding 3D color codes with boundaries](https://arxiv.org/abs/2512.13436)
*Friederike Butt,Lars Esser,Markus Müller*

Main category: quant-ph

TL;DR: 本文提出了一种针对三维颜色码的约束解码器，实现了1.55%的解码阈值，比先前方法提升近两倍，并开发了可视化工具qCodePlot3D。


<details>
  <summary>Details</summary>
Motivation: 三维颜色码因其横向非克利福德门操作而成为容错量子计算的有力候选，但高效解码一直是挑战。需要开发能够处理三维结构和边界的高效解码器。

Method: 将二维颜色码的约束解码方法扩展到三维，通过将解码问题限制在量子比特晶格的子集上，并处理三维颜色码的边界条件。

Result: 三维约束解码器实现了逻辑错误率的最优标度，在代码容量比特和相位翻转噪声下达到1.55(6)%的解码阈值，比先前报道值提高近两倍。

Conclusion: 该解码器显著提升了三维颜色码的解码性能，配合开发的可视化工具qCodePlot3D，使三维颜色码成为更实用的容错量子计算探索选项。

Abstract: Practical large-scale quantum computation requires both efficient error correction and robust implementation of logical operations. Three-dimensional (3D) color codes are a promising candidate for fault-tolerant quantum computation due to their transversal non-Clifford gates, but efficient decoding remains challenging. In this work, we extend previous decoders for two-dimensional color codes [1], which are based on the restriction of the decoding problem to a subset of the qubit lattice, to three dimensions. Including boundaries of 3D color codes, we demonstrate that the 3D restriction decoder achieves optimal scaling of the logical error rate and a threshold value of 1.55(6)% for code-capacity bit- and phase-flip noise, which is almost a factor of two higher than previously reported for this family of codes [2, 3]. We furthermore present qCodePlot3D, a Python package for visualizing 2D and 3D color codes, error configurations, and decoding paths, which supports the development and analysis of such decoders. These advancements contribute to making 3D color codes a more practical option for exploring fault-tolerant quantum computation.

</details>


### [64] [Wigner function negativity in a classical model of quantum light](https://arxiv.org/abs/2512.13462)
*Brian R. La Cour*

Main category: quant-ph

TL;DR: 经典模型通过后选择技术能够模拟单光子添加相干态的负Wigner函数行为


<details>
  <summary>Details</summary>
Motivation: 传统上认为Wigner函数负值是量子非经典现象的标志，但本文挑战这一观点，试图证明经典模型也能产生类似行为

Method: 使用经典压缩光模型结合振幅阈值交叉检测事件的后选择，采用经典平衡零差检测和标准层析技术推断Fock基中的密度矩阵

Result: 该经典模型能够重现单光子添加相干态的观测行为，对于光子添加真空态和弱相干态，得到的Wigner函数表现出负值

Conclusion: Wigner函数负值不一定能作为量子非经典性的可靠判据，经典模型通过适当后选择也能产生类似特征

Abstract: The presence of negative values in the Wigner quasiprobability distribution is deemed one of the hallmarks of nonclassical phenomena in quantum systems. Here we demonstrate a classical model of squeezed light that, when combined with post-selection on amplitude threshold-crossing detection events, is capable of reproducing observed behavior of single-photon added coherent states. In particular, a classical model of balanced homodyne detection and standard tomographic techniques are used to infer the density matrix in the Fock basis. The resulting Wigner functions exhibit negatively for photon-added vacuum and weak coherent states.

</details>


### [65] [Arrival Time -- Classical Parameter or Quantum Operator?](https://arxiv.org/abs/2512.13502)
*MohammadJavad Kazemi,MohammadHossein Barati,Ghadir Jafari,S. Shajidul Haque,Saurya Das*

Main category: quant-ph

TL;DR: 该研究将量子力学中到达时间分布的两种基本方法（时间参数法和时间算符法）扩展到多粒子系统，提出了可行的双粒子到达时间实验，揭示了两种方法在特定条件下给出不等价预测的机制。


<details>
  <summary>Details</summary>
Motivation: 量子力学中到达时间分布的诠释和计算问题长期存在争议，反映了时间作为量子可观测量与经典参数之间的张力。随着原子光学技术的发展，现在可以实验研究纠缠多粒子系统在近场区域的到达时间分布，这需要超越半经典近似的深入分析。即使在远场区域，由于量子非局域性，半经典近似在多粒子系统中通常也不成立。

Method: 将到达时间问题的两种基本方法——时间参数法和时间算符法——扩展到多粒子系统。使用这些扩展方法，提出了可行的双粒子到达时间实验，并对相应的联合分布进行了数值评估。

Result: 研究结果揭示了两种方法在某些条件下会给出不等价预测的机制，突出了实验可以区分量子力学中不同时间描述的条件。这些发现为利用时间域纠缠的量子技术发展提供了重要见解。

Conclusion: 该工作为实验区分量子力学中竞争性时间描述提供了具体方案，同时为时间域纠缠的量子技术（包括非局域时间干涉测量、时间鬼成像和多粒子系统时间态层析）的发展提供了重要基础。

Abstract: The question of how to interpret and compute arrival-time distributions in quantum mechanics remains unsettled, reflecting the longstanding tension between treating time as a quantum observable or as a classical parameter. Most previous studies have focused on the single-particle case in the far-field regime, where both approaches yield very similar arrival-time distributions and a semi-classical analysis typically suffices. Recent advances in atom-optics technologies now make it possible to experimentally investigate arrival-time distributions for entangled multi-particle systems in the near-field regime, where a deeper analysis beyond semi-classical approximations is required. Even in the far-field regime, due to quantum non-locality, the semi-classical approximation cannot generally hold in multi-particle systems. Therefore, in this work, two fundamental approaches to the arrival-time problem -- namely, the time-parameter and time-operator approaches -- are extended to multi-particle systems. Using these extensions, we propose a feasible two-particle arrival-time experiment and numerically evaluate the corresponding joint distributions. Our results reveal regimes in which the two approaches yield inequivalent predictions, highlighting conditions under which experiments could shed new light on distinguishing between competing accounts of time in quantum mechanics. Our findings also provide important insights for the development of quantum technologies that use entanglement in the time domain, including non-local temporal interferometry, temporal ghost imaging, and temporal state tomography in multi-particle systems.

</details>


### [66] [Unraveling the Quantum Mpemba Effect on Markovian Open Quantum Systems](https://arxiv.org/abs/2512.13509)
*Rodrigo F. Saliba,Raphael C. Drumond*

Main category: quant-ph

TL;DR: 该论文从多个角度研究量子Mpemba效应，提出了基于无退相干子空间的物理机制，展示了马尔可夫开放量子系统中衰减速率随系统尺寸指数增强的极端版本，通过Davies映射的展开研究强Mpemba效应，并提出了微观模型来深入理解浴动力学。


<details>
  <summary>Details</summary>
Motivation: 量子Mpemba效应作为经典对应物的推广，是一个反直觉且引人入胜的现象，当非平衡系统比更接近平衡的系统更快达到平衡时发生。该研究旨在从不同角度深入理解马尔可夫开放量子系统中的这一效应。

Method: 1. 提出基于无退相干子空间的物理机制；2. 分析马尔可夫开放量子系统中衰减速率随系统尺寸的指数增强；3. 通过Davies映射的展开研究强Mpemba效应；4. 提出微观模型来理解浴动力学。

Result: 发现了量子Mpemba效应在马尔可夫开放量子系统中可以表现出极端版本，衰减速率随系统尺寸指数增强。同时揭示了在识别量子Mpemba效应时选择适当度量指标的微妙之处。

Conclusion: 该研究从多个新颖角度深入探讨了量子Mpemba效应，不仅提出了新的物理机制和微观模型，还揭示了该效应在马尔可夫开放量子系统中的极端表现，为理解这一反直觉现象提供了更全面的理论框架。

Abstract: In recent years, the quantum Mpemba effect (QME), which occurs when an out-of-equilibrium system reaches equilibrium faster than another that is closer to equilibrium, has attracted significant attention from the scientific community as an intriguing and counterintuitive phenomenon. It generalizes its classical counterpart by extending the concept beyond temperature equilibration. This paper approaches the QME in Markovian open quantum systems from different perspectives. First, we propose a physical mechanism based on decoherence-free subspaces. Second, we show that an exponential enhancement of the decay rate toward equilibrium, scaling with system size, can be obtained, leading to an extreme version of the phenomenon in Markovian open quantum systems. Third, we study the strong Mpemba effect through the unravelings of Davies maps, revealing subtleties in the choice of figures of merit used to identify the QME. Finally, we propose a microscopic model to gain deeper insight into bath dynamics in this context.

</details>


### [67] [Multi-Photon Lasing Phenomena in Quantum Dot-Cavity QED](https://arxiv.org/abs/2512.13518)
*Lavakumar Addepalli*

Main category: quant-ph

TL;DR: 该论文研究量子点-光子晶体腔QED系统中的多光子激光现象，采用极化子变换主方程处理激子-声子相互作用，推导出Scully-Lamb激光速率方程，研究了多种多光子激光机制和连续变量纠缠。


<details>
  <summary>Details</summary>
Motivation: 多光子激光在具有强非线性相互作用的系统中实现，其中单光子过程被抑制。这种连续的非经典光源在量子计算、量子传感、量子计量和量子通信中有重要应用。量子点-光子晶体腔QED系统中激子-声子相互作用不可避免，需要系统研究多光子激光现象。

Method: 采用极化子变换主方程处理激子-声子相互作用，使用Born-Markov近似获得约化密度矩阵速率方程。基于量子激光理论推导Scully-Lamb激光速率方程，评估单光子和多光子超额发射率（发射与吸收率之差）。研究多种量子点系统（二能级、三能级、四能级）与单/双模腔的耦合。

Result: 研究了合作双光子激光、关联发射激光、超辐射激光、非简并双模双光子激光，以及在开放量子系统中单/多个半导体量子点（相干/非相干驱动）与单/双模腔耦合时的连续变量纠缠。

Conclusion: 该论文系统探索了量子点-光子晶体腔QED系统中的多光子激光现象，建立了处理激子-声子相互作用的理论框架，为多种多光子激光机制和量子纠缠的研究提供了理论基础，对量子技术应用具有重要意义。

Abstract: Multi-photon lasing has been realized in systems with strong nonlinear interactions between emitters and cavity modes, where single-photon processes are suppressed. Coherence between the internal states of a quantum emitter, or among multiple emitters, plays a key role. Such continuous nonclassical sources of light can find applications in quantum computation, quantum sensing, quantum metrology, and quantum communication.
  This thesis explores the multi-photon lasing phenomena in various quantum dot-photonic crystal cavity quantum electrodynamic (QED) setups. Exciton-phonon interactions are inevitable in such systems and are incorporated using the polaron-transformed master equation. The Born-Markov approximation is employed to obtain the reduced density matrix rate equation. Using quantum laser theory, we derived the Scully-Lamb laser rate equations and evaluated the single- and multi-photon excess emission rates defined as the difference between emission and absorption rates into the cavity mode without mean-field approximations. We investigated cooperative two-photon lasing, correlated emission lasing, hyperradiant lasing, non-degenerate two-mode two-photon lasing, and continuous variable entanglement in open quantum systems with single or multiple semiconductor quantum dots (two-level, three-level, and four-level) driven coherently/incoherently and coupled to single/ bimodal cavities.

</details>


### [68] [Tensor Network Formulation of Dequantized Algorithms for Ground State Energy Estimation](https://arxiv.org/abs/2512.13548)
*Hidetaka Manabe,Takanori Sugimoto,Keisuke Fujii*

Main category: quant-ph

TL;DR: 提出基于张量网络的去量子化框架用于基态能量估计，消除采样过程，通过张量网络近似实现高效经典计算，揭示经典可处理与量子优势的交叉区域。


<details>
  <summary>Details</summary>
Motivation: 验证量子优势是量子计算理论的核心挑战，现有去量子化算法依赖采样过程导致计算开销过大，阻碍经典计算机上的实际实现。

Method: 提出基于张量网络的去量子化框架，用切比雪夫向量张量网络表示的键维增长替代采样开销，结合矩阵乘积态等张量网络近似构建实用算法。

Result: 数值模拟显示该方法能高效构造高达d=10^4的高次多项式，处理多达100个量子比特的哈密顿量，明确揭示经典可处理与量子优势的交叉区域。

Conclusion: 张量网络去量子化为在现实多体系统中严格定量验证量子优势提供了关键工具，保留了先前算法的渐近复杂度同时实现实际可执行性。

Abstract: Verifying quantum advantage for practical problems, particularly the ground state energy estimation (GSEE) problem, is one of the central challenges in quantum computing theory. For that purpose, dequantization algorithms play a central role in providing a clear theoretical framework to separate the complexity of quantum and classical algorithms. However, existing dequantized algorithms typically rely on sampling procedures, leading to prohibitively large computational overheads and hindering their practical implementation on classical computers. In this work, we propose a tensor network-based dequantization framework for GSEE that eliminates the sampling process while preserving the asymptotic complexity of prior dequantized algorithms. In our formulation, the overhead arising from sampling is replaced by the growth of the bond dimension required to represent Chebyshev vectors as tensor network states. Consequently, physical structure, such as entanglement and locality, is naturally reflected in the computational cost. By combining this approach with tensor network approximations, such as Matrix Product States (MPS), we construct a practical dequantization algorithm that is executable within realistic computational resources. Numerical simulations demonstrate that our method can efficiently construct high-degree polynomials up to $d=10^4$ for Hamiltonians with up to $100$ qubits, explicitly revealing the crossover between classically tractable and quantum advantaged regimes. These results indicate that tensor network-based dequantization provides a crucial tool toward the rigorous, quantitative verification of quantum advantage in realistic many-body systems.

</details>


### [69] [Pontryagin Maximum Principle for Rydberg-blockaded state-to-state transfers: A semi-analytic approach](https://arxiv.org/abs/2512.13549)
*Federico Alberto Astolfi,Sven Jandura,Guido Pupillo*

Main category: quant-ph

TL;DR: 研究基于里德堡阻塞机制的中性原子量子处理器中二比特和多比特操作的时间最优状态控制问题，通过哈密顿量块对角化简化动力学，应用庞特里亚金极大值原理推导最优激光控制。


<details>
  <summary>Details</summary>
Motivation: 中性原子量子处理器在里德堡阻塞机制下需要高效的时间最优控制，以提高量子操作的保真度和速度，这对于量子计算的实际应用至关重要。

Method: 采用哈密顿量块对角化简化动力学，应用庞特里亚金极大值原理的半解析方法推导最优激光控制，建立N比特通用形式化框架，对二比特情况分类正常和异常极值，并将激光失谐映射为经典粒子在四次势中的运动。

Result: 建立了N比特通用形式化框架，对二比特情况完成了正常和异常极值分类，展示了异常解缺失或次优的情况，建立了激光失谐与经典粒子运动的对应关系，实现了半解析的控制问题简化。

Conclusion: 结合PMP理论洞察和数值优化，该方法为高保真度时间最优控制架起了解析和计算方法的桥梁，为中性原子量子处理器的实际应用提供了有效的控制策略。

Abstract: We study time-optimal state-to-state control for two- and multi-qubit operations motivated by neutral-atom quantum processors within the Rydberg blockade regime. Block-diagonalization of the Hamiltonian simplifies the dynamics and enables the application of a semi-analytic approach to the Pontryagin Maximum Principle to derive optimal laser controls. We provide a general formalism for $N$ qubits. For $N=2$ qubits, we classify normal and abnormal extremals, showcasing examples where abnormal solutions are either absent or suboptimal. For normal extremals, we establish a correspondence between the laser detuning from atomic transitions and the motion of a classical particle in a quartic potential, yielding a reduced, semi-analytic formulation of the control problem. Combining PMP-based insights with numerical optimization, our approach bridges analytic and computational methods for high-fidelity, time-optimal control.

</details>


### [70] [Three-qubit entangling gates with simultaneous exchange controls in spin qubit systems](https://arxiv.org/abs/2512.13558)
*Miguel G. Rodriguez,Yun-Pil Shim*

Main category: quant-ph

TL;DR: 提出一种基于多量子比特交换耦合的纠缠门方案，替代传统的两两交换机制，显著减少量子电路的操作步骤


<details>
  <summary>Details</summary>
Motivation: 传统半导体自旋量子比特系统依赖两两交换耦合进行纠缠，但构建量子电路需要大量基本门操作序列，效率较低

Method: 研究线性和三角形配置的三自旋量子比特系统，推导多交换纠缠操作的解析表达式，通过优化控制参数实现三量子比特门

Result: 多量子比特策略显著减少了所需操作数量，能够生成GHZ态、W态等标准纠缠态和Toffoli门，实现更高效、更浅层、更相干的电路

Conclusion: 多量子比特交换纠缠门为自旋量子比特处理器提供了一条实现更高效、更浅层、更相干量子电路的可行路径

Abstract: Pairwise exchange couplings have long been the standard mechanism for entangling spin qubits in semiconductor systems. However, implementing quantum circuits based on pairwise exchange gates often requires a lengthy sequence of elementary gate operations. In this work, we present an alternative approach: multi-qubit entangling gate operations that simultaneously drive the exchange couplings between multiple pairs of spin qubits. We explore three spin qubit systems in linear or triangular configurations. We derive analytical expressions for these multi-exchange entangling operations and demonstrate how to use the resulting three-qubit gates to construct quantum circuits capable of generating standard entangled states such as GHZ and W states, and the Toffoli gate, by optimizing control parameters. Our results show that this multi-qubit strategy significantly reduces the number of required operations, offering a pathway to more efficient, shallower, and more coherent circuits for spin-qubit processors.

</details>


### [71] [Optimised Fermion-Qubit Encodings for Quantum Simulation with Reduced Transpiled Circuit Depth](https://arxiv.org/abs/2512.13580)
*Michael Williams de la Bastida,Thomas M. Bickley,Peter V. Coveney*

Main category: quant-ph

TL;DR: 提出一种确定性方法优化三元树编码，在不改变树结构的情况下降低泡利权重，减少量子电路深度


<details>
  <summary>Details</summary>
Motivation: 模拟费米子哈密顿量时，编码选择（如Jordan-Wigner变换）对量子电路和模拟结果有显著影响。现有三元树编码优化方法要么针对设备要么针对哈密顿量，需要一种更通用的优化方法

Method: 开发确定性方法优化三元树编码，保持底层树结构不变，无需辅助量子比特或额外交换门开销，可应用于各种编码（包括基于量子计算机连接图导出的编码）

Result: 在STO-3G基组的水分子模拟中，相比标准编码方法（包括Jordan-Wigner），该方法平均减少未编译电路深度27.7%，编译后电路深度26.0%

Conclusion: 该方法能有效优化三元树编码，显著降低量子电路深度，为费米子哈密顿量模拟提供更高效的编码方案

Abstract: Simulation of fermionic Hamiltonians with gate-based quantum computers requires the selection of an encoding from fermionic operators to quantum gates, the most widely used being the Jordan-Wigner transform. Many alternative encodings exist, with quantum circuits and simulation results being sensitive to choice of encoding, device connectivity and Hamiltonian characteristics. Non-stochastic optimisation of the ternary tree class of encodings to date has targeted either the device or Hamiltonian. We develop a deterministic method which optimises ternary tree encodings without changing the underlying tree structure. This enables reduction in Pauli-weight without ancillae or additional swap-gate overhead. We demonstrate this method for a variety of encodings, including those which are derived from the qubit connectivity graph of a quantum computer. Across a suite of standard encoding methods applied to water in STO-3G basis, including Jordan-Wigner, our method reduces qDRIFT circuit depths on average by $27.7\%$ and $26.0\%$ for untranspiled and transpiled circuits respectively.

</details>


### [72] [Quantum channel tomography and estimation by local test](https://arxiv.org/abs/2512.13614)
*Kean Chen,Nengkun Yu,Zhicheng Zhang*

Main category: quant-ph

TL;DR: 该论文研究了量子信道估计的查询复杂度，建立了原始信道访问与随机扩张访问之间的等价性，并给出了不同参数设置下的最优查询复杂度界限。


<details>
  <summary>Details</summary>
Motivation: 研究量子信道估计的查询复杂度问题，特别是在不同访问模型下的最优效率。传统方法通常假设可以直接访问目标信道，但实际中可能只能访问信道的随机扩张。需要理解这两种访问模型之间的等价关系，并推导出最优的查询复杂度界限。

Method: 通过构建局部测试器来建立两种访问模型的等价性：证明使用n次原始信道查询的测试器可以忠实地模拟使用n次随机扩张查询的测试器。利用这种等价性，结合量子信息理论和优化技术，推导出不同参数设置下的查询复杂度界限。

Result: 1. 对于并行测试器，访问随机扩张不提供优势；2. 一般信道层析需要O(rd₁d₂/ε²)查询；3. 当rd₂=d₁时，可实现海森堡尺度O(1/ε)；4. 具体给出了不同误差度量下的最优查询复杂度界限。

Conclusion: 该研究建立了量子信道估计中不同访问模型的等价性，证明了在某些条件下可以实现海森堡尺度的最优估计，为量子信道层析提供了理论基础和实用界限。

Abstract: We study the estimation of an unknown quantum channel $\mathcal{E}$ with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. We establish a connection between the query complexities in two models: (i) access to $\mathcal{E}$, and (ii) access to a random dilation of $\mathcal{E}$. Specifically, we show that for parallel (possibly coherent) testers, access to dilations does not help. This is proved by constructing a local tester that uses $n$ queries to $\mathcal{E}$ yet faithfully simulates the tester with $n$ queries to a random dilation. As application, we show that:
  - $O(rd_1d_2/\varepsilon^2)$ queries to $\mathcal{E}$ suffice for channel tomography to within diamond norm error $\varepsilon$.
  Moreover, when $rd_2=d_1$, we show that the Heisenberg scaling $O(1/\varepsilon)$ can be achieved, even if $\mathcal{E}$ is not a unitary channel:
  - $O(\min\{d_1^{2.5}/\varepsilon,d_1^2/\varepsilon^2\})$ queries to $\mathcal{E}$ suffice for channel tomography to within diamond norm error $\varepsilon$, and $O(d_1^2/\varepsilon)$ queries suffice for the case of Choi state trace norm error $\varepsilon$.
  - $O(\min\{d_1^{1.5}/\varepsilon,d_1/\varepsilon^2\})$ queries to $\mathcal{E}$ suffice for tomography of the mixed state $\mathcal{E}(|0\rangle\langle 0|)$ to within trace norm error $\varepsilon$.

</details>


### [73] [Quantum Integrability of Hamiltonians with Time-Dependent Interaction Strengths and the Renormalization Group Flow](https://arxiv.org/abs/2512.13625)
*Parameshwar R. Pasnoori*

Main category: quant-ph

TL;DR: 时间依赖量子系统中，可积性约束与重整化群流方程具有相同形式，通过各向异性Kondo模型证明时间依赖耦合的演化轨迹与静态模型的RG流轨迹完全一致。


<details>
  <summary>Details</summary>
Motivation: 研究时间依赖相互作用的量子哈密顿量，探索可积性约束与重整化群流之间的对应关系，建立时间依赖量子系统中可积性与RG流的普遍联系。

Method: 采用广义Bethe ansatz框架，以时间依赖各向异性Kondo模型为具体例子，构造时间依赖薛定谔方程的精确解，通过施加费米子场的边界条件得到量子Knizhnik-Zamolodchikov方程。

Result: 发现时间依赖耦合J_∥(t)和J_⊥(t)的约束条件使得系统可积，这些耦合的时间演化轨迹与静态Kondo模型的RG流轨迹完全一致。

Conclusion: 在时间依赖量子系统中，可积性约束与重整化群流方程具有相同形式，建立了可积性与RG流之间的直接且普遍的对应关系。

Abstract: In this paper we consider quantum Hamiltonians with time-dependent interaction strengths, and following the recently formulated generalized Bethe ansatz framework [P. R. Pasnoori, Phys. Rev. B 112, L060409 (2025)], we show that constraints imposed by integrability take the same form as the renormalization group flow equations corresponding to the respective Hamiltonians with constant interaction strengths. As a concrete example, we consider the anisotropic time-dependent Kondo model characterized by the time-dependent interaction strengths $J_{\parallel}(t)$ and $J_{\perp}(t)$. We construct an exact solution to the time-dependent Schrodinger equation and by applying appropriate boundary conditions on the fermion fields we obtain a set of matrix difference equations called the quantum Knizhnik-Zamolodchikov (qKZ) equations corresponding to the XXZ R-matrix. The consistency of these equations imposes constraints on the time-dependent interaction strengths $J_{\parallel}(t)$ and $J_{\perp}(t)$, such that the system is integrable. Remarkably, the resulting temporal trajectories of the couplings are shown to coincide exactly with the RG flow trajectories of the static Kondo model, establishing a direct and universal correspondence between integrability and renormalization-group flow in time-dependent quantum systems.

</details>


### [74] [Certified-Everlasting Quantum NIZK Proofs](https://arxiv.org/abs/2512.13628)
*Nikhil Pappu*

Main category: quant-ph

TL;DR: 该论文研究了具有统计可靠性、计算零知识和认证永恒零知识(CE-ZK)特性的NP问题的非交互零知识证明(NIZK)，提出了在CRS模型和共享EPR模型中的CE-NIZK构造方案。


<details>
  <summary>Details</summary>
Motivation: 研究具有认证永恒零知识特性的非交互零知识证明，这种特性允许验证者撤销量子证明，并且撤销过程可以被证明者验证，同时保证在成功认证后，验证者的状态可以被高效模拟。

Method: 1) 识别了在CRS模型中通过已知交互证明的泛化来获得CE-NIZK的障碍；2) 通过使用具有特定性质的NIZK和单向函数，绕过了这个障碍；3) 在共享EPR模型中，基于统计绑定的隐藏比特生成器构造了CE-NIZK。

Result: 1) 基于LWE假设的多项式难度，在CRS模型中实现了NP问题的CE-NIZK；2) 在共享EPR模型中，基于LWE的统计绑定隐藏比特生成器实现了CE-NIZK，该协议仅涉及共享EPR对的单量子比特测量。

Conclusion: 论文成功构造了具有认证永恒零知识特性的非交互零知识证明，分别在CRS模型和共享EPR模型中提供了可行的实现方案，为量子安全密码学提供了新的工具。

Abstract: We study non-interactive zero-knowledge proofs (NIZKs) for NP satisfying: 1) statistical soundness, 2) computational zero-knowledge and 3) certified-everlasting zero-knowledge (CE-ZK). The CE-ZK property allows a verifier of a quantum proof to revoke the proof in a way that can be checked (certified) by the prover. Conditioned on successful certification, the verifier's state can be efficiently simulated with only the statement, in a statistically indistinguishable way. Our contributions regarding these certified-everlasting NIZKs (CE-NIZKs) are as follows:
  - We identify a barrier to obtaining CE-NIZKs in the CRS model via generalizations of known interactive proofs that satisfy CE-ZK.
  - We circumvent this by constructing CE-NIZK from black-box use of NIZK for NP satisfying certain properties, along with OWFs. As a result, we obtain CE-NIZKs for NP in the CRS model, based on polynomial hardness of the learning with errors (LWE) assumption.
  - In addition, we observe that the aforementioned barrier does not apply to the shared EPR model. Consequently, we present a CE-NIZK for NP in this model based on any statistical binding hidden-bits generator, which can be based on LWE. The only quantum computation in this protocol involves single-qubit measurements of the shared EPR pairs.

</details>


### [75] [Quadratic and cubic scrambling in the estimation of two successive phase-shifts](https://arxiv.org/abs/2512.13640)
*Manju,Stefano Olivares,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 该论文研究利用非线性混洗操作克服量子多参数估计中的"松弛性"问题，通过玻色子模型分析二阶和三阶非线性混洗对相位参数估计性能的提升。


<details>
  <summary>Details</summary>
Motivation: 量子多参数估计面临两个主要挑战：参数不兼容（对称对数导数不对易）和模型松弛性（参数组合导致Fisher信息矩阵退化或病态）。需要寻找方法来克服这些限制，提高估计精度。

Method: 采用玻色子模型研究两个相位参数估计，使用二阶和三阶非线性混洗操作，比较两种探针态（压缩真空态和相干态）的性能，分析固定探针和固定能量约束下的表现。

Result: 非线性混洗能够缓解松弛性、增加参数兼容性并提高整体估计精度。三阶非线性比二阶更有效，且在相干探针中，当非线性耦合足够大时，联合估计优于逐步估计策略；对于压缩探针，仅在三阶非线性下观察到这种优势。

Conclusion: 非线性混洗操作是克服量子多参数估计中松弛性问题的有效方法，三阶非线性表现优于二阶，且存在非线性耦合阈值，超过该阈值时联合估计策略优于逐步估计。

Abstract: Multiparameter quantum estimation becomes challenging when the parameters are incompatible, i.e., when their respective symmetric logarithmic derivatives do not commute, or when the model is sloppy, meaning that the quantum probe depends only on combinations of parameters leading to a degenerate or ill-conditioned Fisher information matrix. In this work, we explore the use of scrambling operations between parameter encoding to overcome sloppiness. We consider a bosonic model with two phase-shift parameters and analyze the performance of second- and third-order nonlinear scrambling using two classes of probe states: squeezed vacuum states and coherent states. Our results demonstrate that nonlinear scrambling mitigates sloppiness, increases compatibility, and improves overall estimation precision. We find third-order nonlinearity to be more effective than second-order under both fixed-probe and fixed-energy constraints. Furthermore, by comparing joint estimation to a stepwise estimation strategy, we show that a threshold for nonlinear coupling exists. For coherent probes, joint estimation outperforms the stepwise strategy if the nonlinearity is sufficiently large, while for squeezed probes, this advantage is observed specifically with third-order nonlinearity.

</details>


### [76] [Matter-Mediated Entanglement in Classical Gravity: Suppression by Binding Potentials and Localization](https://arxiv.org/abs/2512.13675)
*Ziqian Tang,Chen Yang,Zizhao Han,Zikuan Kan,Yulong Liu,Hanyu Xue*

Main category: quant-ph

TL;DR: 该论文指出Aziz和Howl关于经典引力场下质量纠缠的论证实际上反映的是量子隧穿/物质交换通道，而非引力的量子性质，且在实际宏观物体中这种效应会被指数抑制。


<details>
  <summary>Details</summary>
Motivation: 回应Aziz和Howl在Nature 646 (2025)中的主张，他们声称即使引力是经典场，两个空间分离的质量也能通过高阶"虚拟物质"过程纠缠。本文旨在澄清这种纠缠机制的本质及其在实际物理系统中的可观测性。

Method: 通过分析AH提出的机制，指出其本质是量子力学中的隧穿/物质交换通道，而非场论特有。进一步考虑实际宏观物体中微观成分的强束缚势能，计算这种束缚对相干传播的抑制效应。

Result: AH识别的纠缠实际上诊断的是相干物质交换通道的存在，而非引力的经典或量子性质。在实际宏观物体中，强束缚势能导致物质介导的贡献在宏观距离上被指数抑制，可忽略不计。

Conclusion: AH的发现并不削弱基于LOCC的引力量子性见证论证，因为其效应在实际束缚物质平台中可忽略。纠缠检测到的是物质交换通道，而非引力的量子特性。

Abstract: Aziz and Howl [Nature 646 (2025)] argue that two spatially separated masses can become entangled even when gravity is treated as a classical field, by invoking higher-order "virtual-matter" processes in a QFT description of matter, which is non-LOCC (local operations and classical communication). We point out that the relevant mechanism is not intrinsically field-theoretic, but is essentially a quantum tunneling/evanescent matter channel, which is already captured within ordinary quantum mechanics. More importantly, the microscopic constituents of realistic macroscopic objects are bound and localized by strong potentials, introducing a large internal energy scale that suppresses coherent propagation between distant bodies. Including such binding/localization generically yields an exponential suppression, rendering the matter-mediated contribution negligible at the macroscopic separations relevant to gravitational-entanglement proposals. Consequently, the entanglement identified by AH diagnoses the presence of a coherent matter-exchange channel rather than the classical or quantum nature of gravity, and it does not undermine LOCC-based witness arguments in realistic bound-matter platforms.

</details>


### [77] [Quantum oracles give an advantage for identifying classical counterfactuals](https://arxiv.org/abs/2512.13692)
*Ciarán M. Gilligan-Lee,Yìlè Yīng,Jonathan Richens,David Schmid*

Main category: quant-ph

TL;DR: 量子因果模型中的反事实查询比经典因果模型更具优势，量子预言机可以识别所有因果参数，而经典预言机无法做到这一点。


<details>
  <summary>Details</summary>
Motivation: 在经典结构因果模型中，观测数据和干预数据通常无法回答所有反事实问题，因为不同的因果参数可能产生相同的观测和干预数据，但在反事实上存在分歧。研究量子系统是否能为反事实查询提供优势。

Method: 将经典变量编码到量子系统中，因果依赖关系编码到量子预言机中，通过相干查询量子预言机来识别所有因果参数。首先在二元变量示例中演示，然后推广到任意有限基数，证明相干探测可以识别所有双向联合反事实概率。

Result: 量子预言机能够识别所有因果参数，从而回答所有经典反事实问题，而经典预言机无法做到这一点。相干探测可以识别所有双向联合反事实概率p(Y_x=y, Y_{x'}=y')，并对高阶多向反事实提供比经典预言机更严格的界限。

Conclusion: 量子预言机在回答经典反事实问题上具有优势，能够识别经典预言机无法识别的因果参数。这种优势可能不完全依赖于量子上下文性等独特量子特征，因为在某些经典可解释理论（如Spekkens玩具理论）中也存在类似优势。

Abstract: We show that quantum oracles provide an advantage over classical oracles for answering classical counterfactual questions in causal models, or equivalently, for identifying unknown causal parameters such as distributions over functional dependences. In structural causal models with discrete classical variables, observational data and even ideal interventions generally fail to answer all counterfactual questions, since different causal parameters can reproduce the same observational and interventional data while disagreeing on counterfactuals. Using a simple binary example, we demonstrate that if the classical variables of interest are encoded in quantum systems and the causal dependence among them is encoded in a quantum oracle, coherently querying the oracle enables the identification of all causal parameters -- hence all classical counterfactuals. We generalize this to arbitrary finite cardinalities and prove that coherent probing 1) allows the identification of all two-way joint counterfactuals p(Y_x=y, Y_{x'}=y'), which is not possible with any number of queries to a classical oracle, and 2) provides tighter bounds on higher-order multi-way counterfactuals than with a classical oracle. This work can also be viewed as an extension to traditional quantum oracle problems such as Deutsch--Jozsa to identifying more causal parameters beyond just, e.g., whether a function is constant or balanced. Finally, we raise the question of whether this quantum advantage relies on uniquely non-classical features like contextuality. We provide some evidence against this by showing that in the binary case, oracles in some classically-explainable theories like Spekkens' toy theory also give rise to a counterfactual identifiability advantage over strictly classical oracles.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [78] [Active Inference with Reusable State-Dependent Value Profiles](https://arxiv.org/abs/2512.11829)
*Jacob Poschl*

Main category: cs.LG

TL;DR: 论文提出"价值档案"框架，通过少量可复用的价值参数捆绑包（偏好、策略先验、策略精度）实现潜在状态下的自适应控制，避免为每个情境维护独立参数。


<details>
  <summary>Details</summary>
Motivation: 在多变环境中，智能体需要在潜在情境间切换价值控制机制，但为每个情境维护独立的偏好、策略偏差和置信参数是不可行的。需要一种更高效的参数化方法来支持状态条件策略的灵活招募。

Method: 引入价值档案：少量可复用的价值相关参数捆绑包（结果偏好、策略先验、策略精度），分配给生成模型中的隐藏状态。通过信念加权混合产生有效的控制参数，实现状态条件策略招募而无需为每个情境维护独立参数。

Result: 在概率反转学习任务中，基于档案的模型在交叉验证对数似然和信息准则上优于静态精度和熵耦合动态精度模型（约100点AIC差异）。参数恢复分析支持结构可识别性。模型推断表明自适应控制主要由策略先验调制驱动而非策略精度。

Conclusion: 可复用的价值档案为多变环境中的信念条件价值控制提供了可行的计算解释，并产生了信念依赖控制和行为灵活性的可测试特征。该方法支持状态条件（而非纯不确定性驱动）控制，具有渐进的信念依赖档案招募特性。

Abstract: Adaptive behavior in volatile environments requires agents to switch among value-control regimes across latent contexts, but maintaining separate preferences, policy biases, and action-confidence parameters for every situation is intractable. We introduce value profiles: a small set of reusable bundles of value-related parameters (outcome preferences, policy priors, and policy precision) assigned to hidden states in a generative model. As posterior beliefs over states evolve trial by trial, effective control parameters arise via belief-weighted mixing, enabling state-conditional strategy recruitment without requiring independent parameters for each context. We evaluate this framework in probabilistic reversal learning, comparing static-precision, entropy-coupled dynamic-precision, and profile-based models using cross-validated log-likelihood and information criteria. Model comparison favors the profile-based model over simpler alternatives (about 100-point AIC differences), and parameter-recovery analyses support structural identifiability even when context must be inferred from noisy observations. Model-based inference further suggests that adaptive control in this task is driven primarily by modulation of policy priors rather than policy precision, with gradual belief-dependent profile recruitment consistent with state-conditional (not purely uncertainty-driven) control. Overall, reusable value profiles provide a tractable computational account of belief-conditioned value control in volatile environments and yield testable signatures of belief-dependent control and behavioral flexibility.

</details>


### [79] [CR3G: Causal Reasoning for Patient-Centric Explanations in Radiology Report Generation](https://arxiv.org/abs/2512.11830)
*Satyam Kumar*

Main category: cs.LG

TL;DR: CR3G是一个基于因果推理的框架，用于胸部X光报告生成，旨在通过理解图像模式与患者状况之间的因果关系来提升AI诊断报告的质量和可信度。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在医学图像分析中擅长发现相关性模式，但难以理解这些模式与患者状况之间的深层因果关系。这限制了AI诊断报告的临床实用性和可信度。

Method: 提出了CR3G框架，这是一个基于提示驱动的因果推理方法，专注于分析胸部X光图像中的因果关系，生成以患者为中心的解释性报告。

Result: CR3G在5种异常情况中的2种上表现出更好的因果关系识别能力和解释能力。

Conclusion: 因果推理方法能够提升AI驱动的胸部X光报告生成质量，使诊断更加有用和可信，但还需要在更多异常类型上验证其有效性。

Abstract: Automatic chest X-ray report generation is an important area of research aimed at improving diagnostic accuracy and helping doctors make faster decisions. Current AI models are good at finding correlations (or patterns) in medical images. Still, they often struggle to understand the deeper cause-and-effect relationships between those patterns and a patient condition. Causal inference is a powerful approach that goes beyond identifying patterns to uncover why certain findings in an X-ray relate to a specific diagnosis. In this paper, we will explore the prompt-driven framework Causal Reasoning for Patient-Centric Explanations in radiology Report Generation (CR3G) that is applied to chest X-ray analysis to improve understanding of AI-generated reports by focusing on cause-and-effect relationships, reasoning and generate patient-centric explanation. The aim to enhance the quality of AI-driven diagnostics, making them more useful and trustworthy in clinical practice. CR3G has shown better causal relationship capability and explanation capability for 2 out of 5 abnormalities.

</details>


### [80] [On the Design of One-step Diffusion via Shortcutting Flow Paths](https://arxiv.org/abs/2512.11831)
*Haitao Lin,Peiyan Hu,Minsi Ren,Zhifeng Gao,Zhi-Ming Ma,Guolin ke,Tailin Wu,Stan Z. Li*

Main category: cs.LG

TL;DR: 论文提出了一个用于代表性捷径模型的通用设计框架，为这些模型提供理论依据并解耦组件级选择，从而系统性地识别改进点，最终在ImageNet-256x256上实现了2.85的SOTA FID分数。


<details>
  <summary>Details</summary>
Motivation: 现有少步扩散模型的理论推导和实际实现往往紧密耦合，这模糊了设计空间。需要建立一个通用框架来提供理论依据并解耦组件级选择，从而系统性地识别改进点。

Method: 提出了一个用于代表性捷径模型的通用设计框架，该框架为捷径模型提供理论依据，并解耦具体的组件级选择，使研究者能够系统性地识别改进点。

Result: 通过提出的改进，得到的一步模型在ImageNet-256x256上实现了2.85的SOTA FID50k分数，且无需预训练、蒸馏或课程学习。

Conclusion: 该工作降低了捷径模型中组件级创新的门槛，并促进了其设计空间的原则性探索。

Abstract: Recent advances in few-step diffusion models have demonstrated their efficiency and effectiveness by shortcutting the probabilistic paths of diffusion models, especially in training one-step diffusion models from scratch (a.k.a. shortcut models). However, their theoretical derivation and practical implementation are often closely coupled, which obscures the design space. To address this, we propose a common design framework for representative shortcut models. This framework provides theoretical justification for their validity and disentangles concrete component-level choices, thereby enabling systematic identification of improvements. With our proposed improvements, the resulting one-step model achieves a new state-of-the-art FID50k of 2.85 on ImageNet-256x256 under the classifier-free guidance setting. Remarkably, the model requires no pre-training, distillation, or curriculum learning. We believe our work lowers the barrier to component-level innovation in shortcut models and facilitates principled exploration of their design space.

</details>


### [81] [Noise-robust Contrastive Learning for Critical Transition Detection in Dynamical Systems](https://arxiv.org/abs/2512.12523)
*Wenqi Fang,Ye Li*

Main category: cs.LG

TL;DR: 提出一种基于奇异值分解和半正交约束的轻量级神经网络架构，用于从噪声时间序列数据中检测临界转变，相比传统对比学习方法更轻量且抗噪性更强。


<details>
  <summary>Details</summary>
Motivation: 复杂噪声时间序列数据中的临界转变检测是一个重要挑战。传统基于深度神经网络的对比学习方法虽然有望检测临界转变，但通常过度参数化且对无关噪声敏感，导致临界点识别不准确。

Method: 提出一种基于奇异值分解技术构建的神经网络架构，配合严格的半正交约束训练算法，以增强传统对比学习的性能。

Result: 大量实验表明，所提方法在识别临界转变方面与传统对比学习技术性能相当，但更轻量且抗噪性显著更强。

Conclusion: 通过奇异值分解和半正交约束构建的轻量级神经网络架构能有效检测复杂噪声时间序列中的临界转变，解决了传统方法过度参数化和噪声敏感的问题。

Abstract: Detecting critical transitions in complex, noisy time-series data is a fundamental challenge across science and engineering. Such transitions may be anticipated by the emergence of a low-dimensional order parameter, whose signature is often masked by high-amplitude stochastic variability. Standard contrastive learning approaches based on deep neural networks, while promising for detecting critical transitions, are often overparameterized and sensitive to irrelevant noise, leading to inaccurate identification of critical points. To address these limitations, we propose a neural network architecture, constructed using singular value decomposition technique, together with a strictly semi-orthogonality-constrained training algorithm, to enhance the performance of traditional contrastive learning. Extensive experiments demonstrate that the proposed method matches the performance of traditional contrastive learning techniques in identifying critical transitions, yet is considerably more lightweight and markedly more resistant to noise.

</details>


### [82] [Performance and Efficiency of Climate In-Situ Data Reconstruction: Why Optimized IDW Outperforms kriging and Implicit Neural Representation](https://arxiv.org/abs/2512.11832)
*Jakub Walczak*

Main category: cs.LG

TL;DR: 在稀疏气候数据重建中，简单的反距离加权法（IDW）在精度和计算效率上均优于普通克里金法和先进的隐式神经表示模型。


<details>
  <summary>Details</summary>
Motivation: 评估不同重建方法在稀疏气候数据上的表现，为实际应用提供方法选择依据。

Method: 比较三种重建方法：反距离加权法（IDW）、普通克里金法（OK）和隐式神经表示模型（MMGN架构），通过超参数调优和验证集划分进行优化，使用ECA&D数据库的100个随机稀疏数据集进行实验。

Result: IDW在所有评估指标上表现最佳：最低的RMSE（3.00±1.93）、MAE（1.32±0.77）和Δ_MAX（24.06±17.15），以及最高的R²（0.68±0.16），且差异具有统计显著性。

Conclusion: 对于稀疏气候数据重建，简单的IDW方法在精度和效率上优于更复杂的统计和深度学习方法，建议在实际应用中优先考虑。

Abstract: This study evaluates three reconstruction methods for sparse climate data: the simple inverse distance weighting (IDW), the statistically grounded ordinary kriging (OK), and the advanced implicit neural representation model (MMGN architecture). All methods were optimized through hyper-parameter tuning using validation splits. An extensive set of experiments was conducted, followed by a comprehensive statistical analysis. The results demonstrate the superiority of the simple IDW method over the other reference methods in terms of both reconstruction accuracy and computational efficiency. IDW achieved the lowest RMSE ($3.00 \pm 1.93$), MAE ($1.32 \pm 0.77$), and $Δ_{MAX}$ ($24.06 \pm 17.15$), as well as the highest $R^2$ ($0.68 \pm 0.16$), across 100 randomly sampled sparse datasets from the ECA\&D database. Differences in RMSE, MAE, and $R^2$ were statistically significant and exhibited moderate to large effect sizes. The Dunn post-hoc test further confirmed the consistent superiority of IDW across all evaluated quality measures [...]

</details>


### [83] [Soft Decision Tree classifier: explainable and extendable PyTorch implementation](https://arxiv.org/abs/2512.11833)
*Reuben R Shamir*

Main category: cs.LG

TL;DR: 使用PyTorch实现软决策树(SDT)和短期记忆软决策树(SM-SDT)，在模拟和临床数据集上测试，可视化SDT展示可解释性潜力，与XGBoost性能相当，优于其他传统方法。


<details>
  <summary>Details</summary>
Motivation: 开发具有可解释性的机器学习模型，结合决策树的透明性和神经网络的性能，为临床决策提供既准确又可解释的工具。

Method: 使用PyTorch实现软决策树(SDT)和短期记忆软决策树(SM-SDT)，在模拟和临床数据集上进行广泛测试，可视化SDT结构以展示可解释性。

Result: SDT、SM-SDT和XGBoost的AUC值相似，均优于随机森林、逻辑回归和传统决策树；临床数据集上除决策树外，所有分类方法结果相当。

Conclusion: 软决策树方法在保持与XGBoost相当性能的同时，提供了更好的可解释性，适合需要透明决策的临床应用，代码和数据集已开源。

Abstract: We implemented a Soft Decision Tree (SDT) and a Short-term Memory Soft Decision Tree (SM-SDT) using PyTorch. The methods were extensively tested on simulated and clinical datasets. The SDT was visualized to demonstrate the potential for its explainability. SDT, SM-SDT, and XGBoost demonstrated similar area under the curve (AUC) values. These methods were better than Random Forest, Logistic Regression, and Decision Tree. The results on clinical datasets suggest that, aside from a decision tree, all tested classification methods yield comparable results.
  The code and datasets are available online on GitHub: https://github.com/KI-Research-Institute/Soft-Decision-Tree

</details>


### [84] [Hybrid twinning using PBDW and DeepONet for the effective state estimation and prediction on partially known systems](https://arxiv.org/abs/2512.11834)
*Stiven Briand Massala,Ludovic Chamoin,Massimo Picca Ciamarra*

Main category: cs.LG

TL;DR: 提出一种结合物理建模与数据驱动的混合方法，通过PBDW框架集成降阶模型与测量数据，并引入DeepONet学习模型偏差的正交补空间，同时优化传感器布置，用于复杂不确定物理系统的状态估计与预测。


<details>
  <summary>Details</summary>
Motivation: 复杂不确定物理系统的准确状态估计需要协调存在固有缺陷的理论模型与含噪声的实验数据。传统方法难以同时处理预期和非预期的模型不确定性，需要一种能有效结合物理知识与数据学习的方法来提升状态估计和预测能力。

Method: 基于参数化背景数据弱(PBDW)框架，集成降阶模型表示与测量数据。引入深度算子网络(DeepONet)作为最佳知识流形的正交补空间，专门学习模型偏差中未被降阶空间捕获的部分。同时研究最优传感器布置策略以最大化测量信息增益。

Result: 在涉及亥姆霍兹方程的代表性问题中验证了该方法，处理了包括边界条件和源项在内的多种建模误差来源。结果表明该方法能有效学习模型偏差结构，保持物理模型的解释性和保真度，同时提升状态估计精度。

Conclusion: 提出的混合方法成功结合了物理建模与数据驱动学习的优势，通过正交约束的DeepONet专门针对未知模型偏差，配合最优传感器布置，为复杂不确定物理系统提供了准确且可解释的状态估计和预测框架。

Abstract: The accurate estimation of the state of complex uncertain physical systems requires reconciling theoretical models, with inherent imperfections, with noisy experimental data. In this work, we propose an effective hybrid approach that combines physics-based modeling with data-driven learning to enhance state estimation and further prediction. Our method builds upon the Parameterized Background Data-Weak (PBDW) framework, which naturally integrates a reduced-order representation of the best-available model with measurement data to account for both anticipated and unanticipated uncertainties. To address model discrepancies not captured by the reduced-order space, and learn the structure of model deviation, we incorporate a Deep Operator Network (DeepONet) constrained to be an orthogonal complement of the best-knowledge manifold. This ensures that the learned correction targets only the unknown components of model bias, preserving the interpretability and fidelity of the physical model. An optimal sensor placement strategy is also investigated to maximize information gained from measurements. We validate the proposed approach on a representative problem involving the Helmholtz equation under various sources of modeling error, including those arising from boundary conditions and source terms.

</details>


### [85] [Semantic Nutrition Estimation: Predicting Food Healthfulness from Text Descriptions](https://arxiv.org/abs/2512.11836)
*Dayne R. Freudenberg,Daniel G. Haughian,Mitchell A. Klusty,Caroline N. Leach,W. Scott Black,Leslie N. Woltenberg,Rowan Hallock,Elizabeth Solie,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.LG

TL;DR: 开发了一个机器学习系统，可以从文本描述中预测Food Compass Score 2.0营养评分，使用多头部神经网络处理混合特征向量，实现了较高的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的营养评估系统需要详细的营养数据，而这些数据往往难以从日常食物描述文本中获得，限制了公共健康领域的营养评估可扩展性。

Method: 使用多头部神经网络处理混合特征向量，结合语义文本嵌入、词汇模式、领域启发式方法以及USDA FNDDS数据，预测FCS算法所需的营养和食物成分。

Result: 系统表现出强大的预测能力，单个营养素的R²中位数为0.81，预测的FCS与公布值强相关（Pearson's r = 0.77），平均绝对差异为14.0分。

Conclusion: 该方法能够将语言转化为可操作的营养信息，为消费者应用和研究提供可扩展的饮食评估方案，尽管在模糊或加工食品上误差较大。

Abstract: Accurate nutritional assessment is critical for public health, but existing profiling systems require detailed data often unavailable or inaccessible from colloquial text descriptions of food. This paper presents a machine learning pipeline that predicts the comprehensive Food Compass Score 2.0 (FCS) from text descriptions. Our approach uses multi-headed neural networks to process hybrid feature vectors that combine semantic text embeddings, lexical patterns, and domain heuristics, alongside USDA Food and Nutrient Database for Dietary Studies (FNDDS) data. The networks estimate the nutrient and food components necessary for the FCS algorithm. The system demonstratedstrong predictive power, achieving a median R^2 of 0.81 for individual nutrients. The predicted FCS correlated strongly with published values (Pearson's r = 0.77), with a mean absolute difference of 14.0 points. While errors were largest for ambiguous or processed foods, this methodology translates language into actionable nutritional information, enabling scalable dietary assessment for consumer applications and research.

</details>


### [86] [D-STEER - Preference Alignment Techniques Learn to Behave, not to Believe -- Beneath the Surface, DPO as Steering Vector Perturbation in Activation Space](https://arxiv.org/abs/2512.11838)
*Samarth Raina,Saksham Aggarwal,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.LG

TL;DR: DPO不是改变模型内部信念，而是通过低秩调控机制，沿着少数偏好方向微调激活，实现行为对齐而非信念重塑。


<details>
  <summary>Details</summary>
Motivation: 尽管DPO已成为对齐大语言模型的标准方法，但其在神经网络内部引发的具体变化机制尚不明确。本文旨在探究DPO究竟是在重写模型内部信念，还是仅仅作为一种调控机制。

Method: 通过数学推导证明DPO梯度仅依赖于偏好与非偏好补全的logit嵌入差异；从DPO调优模型中提取经验调控向量，验证其在基础激活上的加减效果；进行谱分析揭示高层网络的秩一主导和熵塌缩现象。

Result: DPO梯度仅引起最终隐藏表示的一阶偏移而非深层语义重构；添加调控向量可重现大部分对齐行为，减去则几乎恢复原始模型；谱分析显示对齐通过狭窄子空间实现，支持行为幻觉观点。

Conclusion: DPO并非重写模型内部信念，而是通过低秩调控机制教导模型如何表现出对齐行为，而非改变其实际信念，支持"行为幻觉"观点。

Abstract: Direct Preference Optimization (DPO) has become a standard recipe for aligning large language models, yet it is still unclear what kind of change it actually induces inside the network. This paper argues that DPO does not rewrite a models internal beliefs; instead, it acts as a low rank steering mechanism that nudges activations along a small number of preference directions. Using a simple derivation, we show that the DPO gradient depends only on the difference between the logit embeddings of preferred and dispreferred completions, implying a first order shift in the final hidden representation rather than a deep restructuring of semantics. We then extract an empirical steering vector from a DPO tuned model and demonstrate that adding this vector to base activations reproduces most of the aligned behavior, while subtracting it nearly restores the original model. Finally, spectral analyses reveal rank-one dominance and entropy collapse in upper layers, indicating that alignment is funneled through a narrow subspace. Taken together, these results support a behavioral illusion view of DPO: it teaches models how to act aligned, not what to believe.

</details>


### [87] [Large Language Models as Generalist Policies for Network Optimization](https://arxiv.org/abs/2512.11839)
*Duo Wu,Linjia Kang,Zhimin Wang,Fangxin Wang,Wei Zhang,Xuefeng Tao,Wei Yang,Le Zhang,Peng Cui,Zhi Wang*

Main category: cs.LG

TL;DR: Trailblazer是首个基于大语言模型的通用网络策略框架，通过任务对齐和策略协作机制，在抖音平台上实现了跨任务和跨环境的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统网络优化依赖基于规则或深度学习的专家策略，泛化能力差。大语言模型具有丰富的网络知识基础和强大的泛化能力，为构建通用网络策略提供了变革性基础。

Method: 提出Trailblazer框架：1) 网络对齐方案，将LLM与特定网络任务对接；2) 自适应策略协作机制，将简单控制案例从LLM卸载到轻量级策略以提高计算效率。

Result: 通过大规模仿真和抖音平台真实在线评估，Trailblazer在跨任务和跨环境泛化方面优于传统专家策略，验证了LLM作为通用网络策略基础的有效性。

Conclusion: LLM是通用网络策略的基础，Trailblazer是实现通用驱动范式的第一步，能够以最小的策略设计工作量实现强泛化能力。

Abstract: Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning models, leading to poor generalization across diverse tasks and environments. In contrast, large language models (LLMs), pretrained on Internet-scale corpora, provide a rich and unified knowledge base that encodes fundamental networking principles. Combined with their emergent abilities in generalization to unseen scenarios, LLMs offer a transformative foundation for generalist network policies that can generalize across diverse tasks and environments with minimal adaptation. In this paper, we present Trailblazer, the first systematic framework to realize such a generalist policy for networking. Trailblazer incorporates a network alignment scheme to ground the LLM in specific networking tasks, and an adaptive policy collaboration mechanism that offloads simple control cases from the LLM to a lightweight policy for computational efficiency. Through extensive simulations and large-scale real-world online evaluation on Douyin (the Chinese version of TikTok), Trailblazer, powered by a single LLM, demonstrates stronger cross-task and cross-environment generalization than conventional specialist policies. Our results validate LLMs as the foundation for generalist network policies, and position Trailblazer as the first step toward the generalist-driven paradigm that enables strong generalization with minimal efforts in policy design.

</details>


### [88] [Amortized Causal Discovery with Prior-Fitted Networks](https://arxiv.org/abs/2512.11840)
*Mateusz Sypniewski,Mateusz Olko,Mateusz Gajewski,Piotr Miłoś*

Main category: cs.LG

TL;DR: 提出基于先验拟合网络（PFNs）的摊销因果发现方法，解决似然估计误差问题，相比传统方法在结构恢复上表现更好


<details>
  <summary>Details</summary>
Motivation: 现有可微分惩罚似然方法虽然流行，但即使在较大样本量下，似然估计误差也会阻碍发现正确因果结构。需要解决似然估计器准确性的限制。

Method: 使用先验拟合网络（PFNs）来摊销数据依赖的似然估计，为结构学习提供更可靠的评分。PFNs相比传统神经网络方法能提供更准确的似然估计。

Result: 在合成、模拟和真实世界数据集上的实验显示，相比标准基线方法，该方法在结构恢复方面取得了显著提升。PFNs确实比传统神经网络方法提供更准确的似然估计。

Conclusion: 提出的基于PFNs的摊销因果发现方法有效解决了似然估计准确性问题，在因果结构恢复方面优于现有方法，为因果发现提供了更可靠的框架。

Abstract: In recent years, differentiable penalized likelihood methods have gained popularity, optimizing the causal structure by maximizing its likelihood with respect to the data. However, recent research has shown that errors in likelihood estimation, even on relatively large sample sizes, disallow the discovery of proper structures. We propose a new approach to amortized causal discovery that addresses the limitations of likelihood estimator accuracy. Our method leverages Prior-Fitted Networks (PFNs) to amortize data-dependent likelihood estimation, yielding more reliable scores for structure learning. Experiments on synthetic, simulated, and real-world datasets show significant gains in structure recovery compared to standard baselines. Furthermore, we demonstrate directly that PFNs provide more accurate likelihood estimates than conventional neural network-based approaches.

</details>


### [89] [Meta-Continual Mobility Forecasting for Proactive Handover Prediction](https://arxiv.org/abs/2512.11841)
*Sasi Vardhan Reddy Mandapati*

Main category: cs.LG

TL;DR: 提出轻量级元持续预测框架，用于蜂窝网络中的短期移动性预测，通过元初始化、残差检测和在线更新来应对非平稳移动性，在零样本和少样本场景下均取得良好性能，并显著改善切换预测效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的移动性高度非平稳，存在突然转向、速度快速变化和不可预测的用户行为，导致传统预测器漂移，引发切换时机错误或失败。需要一种能够适应这种非平稳性的预测方法。

Method: 提出轻量级元持续预测框架，包含：1) GRU基础预测器；2) Reptile元初始化用于快速少样本适应；3) EWMA残差检测器，仅在发生漂移时触发紧凑的在线更新。

Result: 在GeoLife和DeepMIMO数据集上评估：零样本设置下达到4.46m ADE和7.79m FDE；10样本少样本下ADE提升至3.71m；从突然漂移中恢复的速度比离线GRU快2-3倍。应用于切换预测时，F1提升至0.83，AUROC达0.90，显著减少切换失败和乒乓事件。

Conclusion: 该方法提供了一种轻量级（12.8万参数）的元持续预测框架，能够有效应对非平稳移动性，显著改善切换预测性能，适合5G/6G系统边缘部署。

Abstract: Short-term mobility forecasting is a core requirement for proactive handover (HO) in cellular networks. Real-world mobility is highly non-stationary: abrupt turns, rapid speed changes, and unpredictable user behavior cause conventional predictors to drift, leading to mistimed or failed handovers. We propose a lightweight meta-continual forecasting framework that integrates a GRU-based predictor, Reptile meta-initialization for fast few-shot adaptation, and an EWMA residual detector that triggers compact online updates only when drift occurs. Evaluated on a reproducible GeoLife and DeepMIMO pipeline, our method achieves 4.46 m ADE and 7.79 m FDE in zero-shot settings, improves few-shot ADE to 3.71 m at 10-shot, and enables recovery from abrupt drift about 2 to 3 times faster than an offline GRU. When applied to downstream HO prediction, the approach improves F1 to 0.83 and AUROC to 0.90, with substantial reductions in missed-HO and ping-pong events. The model is lightweight (128k parameters) and suitable for edge deployment in 5G and 6G systems.

</details>


### [90] [Airport Passenger Flow Forecasting via Deformable Temporal-Spectral Transformer Approach](https://arxiv.org/abs/2512.11845)
*Wenbo Du,Lingling Han,Ying Xiong,Ling Zhang,Biyue Li,Yisheng Lv,Tong Guo*

Main category: cs.LG

TL;DR: 提出DTSFormer模型，通过可变形多尺度划分和时频联合滤波，提升机场客流预测精度


<details>
  <summary>Details</summary>
Motivation: 机场客流预测对运营效率至关重要，现有基于固定大小补丁的Transformer方法难以建模复杂异质的客流模式

Method: 提出DTSFormer模型：1) 多尺度可变形划分模块，通过窗口函数掩码动态划分时间序列；2) 时频联合滤波模块，在频域注意力中捕获高低频成分；3) 时域特征融合

Result: 在北京首都国际机场2023-2024年真实数据上实验，在不同预测时间范围内均优于现有方法，可变形划分模块能更好地捕捉突发高频波动

Conclusion: DTSFormer通过动态多尺度划分和时频联合建模，有效提升了机场客流预测的准确性，能更好地捕捉异质趋势和周期性模式

Abstract: Accurate forecasting of passenger flows is critical for maintaining the efficiency and resilience of airport operations. Recent advances in patch-based Transformer models have shown strong potential in various time series forecasting tasks. However, most existing methods rely on fixed-size patch embedding, making it difficult to model the complex and heterogeneous patterns of airport passenger flows. To address this issue, this paper proposes a deformable temporal-spectral transformer named DTSFormer that integrates a multiscale deformable partitioning module and a joint temporal-spectral filtering module. Specifically, the input sequence is dynamically partitioned into multiscale temporal patches via a novel window function-based masking, enabling the extraction of heterogeneous trends across different temporal stages. Then, within each scale, a frequency-domain attention mechanism is designed to capture both high- and low-frequency components, thereby emphasizing the volatility and periodicity inherent in airport passenger flows. Finally, the resulting multi-frequency features are subsequently fused in the time domain to jointly model short-term fluctuations and long-term trends. Comprehensive experiments are conducted on real-world passenger flow data collected at Beijing Capital International Airport from January 2023 to March 2024. The results indicate that the proposed method consistently outperforms state-of-the-art forecasting models across different prediction horizons. Further analysis shows that the deformable partitioning module aligns patch lengths with dominant periods and heterogeneous trends, enabling superior capture of sudden high-frequency fluctuations.

</details>


### [91] [Exploring Topological Bias in Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2512.11846)
*Yihan Zhang*

Main category: cs.LG

TL;DR: 该论文研究了异质图神经网络中的拓扑偏差问题，提出了一种基于元权重和PageRank的投影方法来检测偏差，并通过对比学习进行去偏处理。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络研究主要关注同质图，而异质图神经网络中的拓扑偏差问题尚未得到充分研究。由于半监督学习中标签稀疏，GNNs在特定节点上表现出偏差性能，这种偏差与拓扑结构相关，成为GNNs性能的瓶颈。

Method: 1. 应用元权重到异质图的邻接矩阵以区分不同的元关系；2. 基于修改后的邻接矩阵，利用PageRank和节点标签信息构建投影，将节点映射到与模型性能强相关的值；3. 提出基于节点映射值差异的去偏结构，结合原始图结构进行对比学习。

Result: 在三个公共数据集上的实验验证了所提方法的有效性，能够提高异质图神经网络的性能并减少拓扑偏差。构建的投影方法在有/无类型内连接的数据集上都有效，证明了拓扑偏差在HGNNs中的普遍存在。

Conclusion: 该工作首次系统研究了异质图神经网络中的拓扑偏差问题，提出的投影方法能够有效检测偏差，基于对比学习的去偏结构能够显著提升模型性能，为解决HGNNs中的偏差问题提供了新思路。

Abstract: Graph Neural Networks (GNNs) are characterized by their capacity of processing graph-structured data. However, due to the sparsity of labels under semi-supervised learning, they have been found to exhibit biased performance on specific nodes. This kind of bias has been validated to correlate with topological structure and is considered as a bottleneck of GNNs' performance. Existing work focuses on the study of homogeneous GNNs and little attention has been given to topological bias in Heterogeneous Graph Neural Networks (HGNNs). In this work, firstly, in order to distinguish distinct meta relations, we apply meta-weighting to the adjacency matrix of a heterogeneous graph. Based on the modified adjacency matrix, we leverage PageRank along with the node label information to construct a projection. The constructed projection effectively maps nodes to values that strongly correlated with model performance when using datasets both with and without intra-type connections, which demonstrates the universal existence of topological bias in HGNNs. To handle this bias, we propose a debiasing structure based on the difference in the mapped values of nodes and use it along with the original graph structure for contrastive learning. Experiments on three public datasets verify the effectiveness of the proposed method in improving HGNNs' performance and debiasing.

</details>


### [92] [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)
*Antonio Roye-Azar,Santiago Vargas-Naranjo,Dhruv Ghai,Nithin Balamurugan,Rayan Amir*

Main category: cs.LG

TL;DR: TRM在ARC-AGI-1上的性能主要来自测试时增强、多数投票集成和任务特定标识符，而非深度递归推理。递归实际上很浅，大多数准确率在第一步就达到。


<details>
  <summary>Details</summary>
Motivation: 分析Tiny Recursive Models在ARC任务中的真实性能来源，厘清其表现是来自架构优势、测试时计算还是任务特定先验。

Method: 对ARC Prize TRM检查点在ARC-AGI-1上进行实证分析：1) 测试时增强和多数投票集成的影响；2) 任务标识符消融实验；3) 递归轨迹分析；4) 不同增强策略的训练实验；5) 与Llama 3 8B QLoRA微调的效率比较。

Result: 1) 1000样本投票将Pass@1提升约11个百分点；2) 替换任务ID导致零准确率；3) 大多数准确率在第一步递归就达到，递归很浅；4) 强增强策略能扩大候选解分布；5) TRM的非自回归设计在吞吐量和内存使用上优于Llama 3 8B。

Conclusion: TRM在ARC-AGI-1上的性能主要源于效率优势、任务特定条件设置和激进的测试时计算，而非深度内部推理能力。

Abstract: Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.

</details>


### [93] [KV Cache Recycling to Expand Usable Context Capacity in Low Parameter LLMs](https://arxiv.org/abs/2512.11851)
*Prashant Pandey*

Main category: cs.LG

TL;DR: 提出token recycling方法，通过重用相似prompt的KV状态来加速小语言模型推理，在DialoGPT-medium上测试显示有重叠前缀时可获得加速且不影响输出质量


<details>
  <summary>Details</summary>
Motivation: 探索是否可以为小型LLM重用已计算过的注意力键值状态，以加速相似prompt的推理，扩展上下文内存空间

Method: 使用DialoGPT-medium作为测试平台，构建过去激活的缓存并通过句子嵌入检索条目，当缓存prompt是新输入的精确前缀时重用缓存的过去键值

Result: 测试显示存在前缀重叠时获得一致的加速效果，输出语义没有实质性退化；没有重叠时行为与基线匹配

Conclusion: token recycling方法有效，可在不修改模型的情况下重用KV状态加速推理，特别适用于有重叠前缀的相似prompt场景

Abstract: Whether attention key value (KV) states computed for one prompt for a small LLM can be reused to accelerate inference on a new similar prompt, giving an increase to the space to its context memory using an approach called token recycling. Using a standard Hugging Face setup with DialoGPT-medium (a 345M parameter GPT-2 style decoder trained on 147M Reddit exchanges, 2005 to 2017) as the testbed, we build a cache of past activations and get entries by sentence embeddings, then reuse cached past key values when the cached prompt is an exact prefix of the new input. We compare recycled vs. baseline runs on latency and output fidelity, and log reuse depth in tokens. Reproducibility requires no model modifications, cached KVs are serialized to the CPU, reloaded, and supplied to the generate function to continue decoding from the cached prefix. In tests, we observe consistent speedups when prefix overlap exists, with no material degradation in output semantics, and when overlap is absent, behavior matches baseline.

</details>


### [94] [Explainable AI for Smart Greenhouse Control: Interpretability of Temporal Fusion Transformer in the Internet of Robotic Things](https://arxiv.org/abs/2512.11852)
*Muhammad Jawad Bashir,Shagufta Henna,Eoghan Furey*

Main category: cs.LG

TL;DR: 本研究利用Temporal Fusion Transformer模型实现温室自动化控制，并通过LIME和SHAP等可解释性技术增强模型决策的透明度，在类别不平衡数据集上达到95%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 智能温室中的物联网机器人系统虽然实现了精准农业，但现有时间序列预测模型多为黑盒，缺乏可解释性决策机制，这在需要信任、透明度和监管合规的智慧农业实践中是一个关键限制。

Method: 采用Temporal Fusion Transformer模型自动化温室执行器设置，并运用模型内在解释、局部可解释模型无关解释和SHAP值等局部和全局解释技术来增强模型决策的可解释性。

Result: 训练后的TFT模型在类别不平衡的自动化温室执行器控制设置数据集上实现了95%的测试准确率，解释性方法揭示了温度、湿度、CO2水平、光照和外部气候等不同传感器读数对执行器控制决策的具体贡献。

Conclusion: 研究证明了可解释AI在智能温室管理中的重要性，通过透明化模型决策过程，实现了自适应微调，提高了作物产量和资源效率，为智慧农业实践提供了可信赖的自动化解决方案。

Abstract: The integration of the Internet of Robotic Things (IoRT) in smart greenhouses has revolutionised precision agriculture by enabling efficient and autonomous environmental control. However, existing time series forecasting models in such setups often operate as black boxes, lacking mechanisms for explainable decision-making, which is a critical limitation when trust, transparency, and regulatory compliance are paramount in smart farming practices. This study leverages the Temporal Fusion Transformer (TFT) model to automate actuator settings for optimal greenhouse management. To enhance interpretability and trust in the model decision-making process, both local and global explanation techniques were employed using model-inherent interpretation, local interpretable model-agnostic explanations (LIME), and SHapley additive explanations (SHAP). These explainability methods provide information on how different sensor readings, such as temperature, humidity, CO2 levels, light, and outer climate, contribute to actuator control decisions in an automated greenhouse. The trained TFT model achieved a test accuracy of 95% on a class-imbalanced dataset for actuator control settings in an automated greenhouse environment. The results demonstrate the varying influence of each sensor on real-time greenhouse adjustments, ensuring transparency and enabling adaptive fine-tuning for improved crop yield and resource efficiency.

</details>


### [95] [Rep Smarter, Not Harder: AI Hypertrophy Coaching with Wearable Sensors and Edge Neural Networks](https://arxiv.org/abs/2512.11854)
*Grant King,Musa Azeem,Savannah Noblitt,Ramtin Zand,Homayoun Valafar*

Main category: cs.LG

TL;DR: 开发基于单腕戴IMU的实时反馈系统，用于检测抗阻训练中的接近力竭状态（RiR≤2），通过两阶段边缘计算实现实时分类。


<details>
  <summary>Details</summary>
Motivation: 抗阻训练中需要平衡接近力竭程度与疲劳管理，但主观的"剩余重复次数"评估不可靠，导致训练刺激不足或过度疲劳，需要客观的实时反馈系统。

Method: 提出两阶段边缘计算管道：1) ResNet模型实时分割IMU数据中的重复动作；2) 结合分割特征、卷积特征和历史LSTM上下文，分类检测接近力竭状态（RiR≤2）。

Result: 在13名参与者631次重复的数据集上，分割模型F1分数0.83，接近力竭分类器F1分数0.82（1.6Hz推理速率）。Raspberry Pi 5平均延迟112ms，iPhone 16延迟23.5ms，证实边缘计算可行性。

Conclusion: 使用最小硬件实现客观实时训练强度反馈的实用方法，为可访问的AI驱动增肌教练工具铺平道路，帮助用户有效管理强度和疲劳。

Abstract: Optimizing resistance training for hypertrophy requires balancing proximity to muscular failure, often quantified by Repetitions in Reserve (RiR), with fatigue management. However, subjective RiR assessment is unreliable, leading to suboptimal training stimuli or excessive fatigue. This paper introduces a novel system for real-time feedback on near-failure states (RiR $\le$ 2) during resistance exercise using only a single wrist-mounted Inertial Measurement Unit (IMU). We propose a two-stage pipeline suitable for edge deployment: first, a ResNet-based model segments repetitions from the 6-axis IMU data in real-time. Second, features derived from this segmentation, alongside direct convolutional features and historical context captured by an LSTM, are used by a classification model to identify exercise windows corresponding to near-failure states. Using a newly collected dataset from 13 diverse participants performing preacher curls to failure (631 total reps), our segmentation model achieved an F1 score of 0.83, and the near-failure classifier achieved an F1 score of 0.82 under simulated real-time evaluation conditions (1.6 Hz inference rate). Deployment on a Raspberry Pi 5 yielded an average inference latency of 112 ms, and on an iPhone 16 yielded 23.5 ms, confirming the feasibility for edge computation. This work demonstrates a practical approach for objective, real-time training intensity feedback using minimal hardware, paving the way for accessible AI-driven hypertrophy coaching tools that help users manage intensity and fatigue effectively.

</details>


### [96] [Achieving Approximate Symmetry Is Exponentially Easier than Exact Symmetry](https://arxiv.org/abs/2512.11855)
*Behrooz Tahmasebi,Melanie Weber*

Main category: cs.LG

TL;DR: 本文首次从理论上比较了精确对称性与近似对称性的成本差异，发现精确对称需要线性平均复杂度，而近似对称仅需对数复杂度，存在指数级分离。


<details>
  <summary>Details</summary>
Motivation: 机器学习中强制精确对称性在科学应用中能带来显著收益，但最近研究表明近似对称性可能提供更大灵活性和鲁棒性。然而缺乏理论理解，特别是精确与近似对称性的直接比较在文献中缺失。

Method: 引入"平均复杂度"框架来量化通过平均强制对称性的成本。在标准条件下分析精确对称与近似对称所需的计算复杂度。

Result: 主要发现是指数级分离：精确对称需要线性平均复杂度，而近似对称仅需对数平均复杂度。这是首次从理论上分离这两种情况。

Conclusion: 近似对称性在实践中可能更优，因为其成本显著低于精确对称。该研究的工具和技术对机器学习中对称性的更广泛研究具有独立价值。

Abstract: Enforcing exact symmetry in machine learning models often yields significant gains in scientific applications, serving as a powerful inductive bias. However, recent work suggests that relying on approximate symmetry can offer greater flexibility and robustness. Despite promising empirical evidence, there has been little theoretical understanding, and in particular, a direct comparison between exact and approximate symmetry is missing from the literature. In this paper, we initiate this study by asking: What is the cost of enforcing exact versus approximate symmetry? To address this question, we introduce averaging complexity, a framework for quantifying the cost of enforcing symmetry via averaging. Our main result is an exponential separation: under standard conditions, achieving exact symmetry requires linear averaging complexity, whereas approximate symmetry can be attained with only logarithmic averaging complexity. To the best of our knowledge, this provides the first theoretical separation of these two cases, formally justifying why approximate symmetry may be preferable in practice. Beyond this, our tools and techniques may be of independent interest for the broader study of symmetries in machine learning.

</details>


### [97] [GCoDE: Efficient Device-Edge Co-Inference for GNNs via Architecture-Mapping Co-Search](https://arxiv.org/abs/2512.11856)
*Ao Zhou,Jianlei Yang,Tong Qiao,Yingjie Qi,Zhi Yang,Weisheng Zhao,Chunming Hu*

Main category: cs.LG

TL;DR: GCoDE：首个面向图神经网络设备-边缘协同推理的自动架构-映射协同设计框架，通过统一设计空间优化，实现高达44.9倍加速和98.2%能耗降低。


<details>
  <summary>Details</summary>
Motivation: GNN在边缘设备上推理面临高计算成本和有限硬件资源的挑战，传统模型划分方法对GNN无效，需要新的设备-边缘协同推理方案。

Method: 提出GCoDE框架，将设备通信过程抽象为显式操作，在统一设计空间中联合优化架构和映射方案，引入能耗预测方法，采用约束随机搜索策略寻找最优解。

Result: GCoDE在1.5小时内找到最优解，相比现有方法实现高达44.9倍加速和98.2%能耗降低，适用于多种应用和系统配置。

Conclusion: GCoDE是首个有效的GNN设备-边缘协同推理自动框架，通过架构-映射协同设计显著提升推理效率和能耗表现，为边缘场景GNN部署提供可行方案。

Abstract: Graph Neural Networks (GNNs) have emerged as the state-of-the-art graph learning method. However, achieving efficient GNN inference on edge devices poses significant challenges, limiting their application in real-world edge scenarios. This is due to the high computational cost of GNNs and limited hardware resources on edge devices, which prevent GNN inference from meeting real-time and energy requirements. As an emerging paradigm, device-edge co-inference shows potential for improving inference efficiency and reducing energy consumption on edge devices. Despite its potential, research on GNN device-edge co-inference remains scarce, and our findings show that traditional model partitioning methods are ineffective for GNNs. To address this, we propose GCoDE, the first automatic framework for GNN architecture-mapping Co-design and deployment on Device-Edge hierarchies. By abstracting the device communication process into an explicit operation, GCoDE fuses the architecture and mapping scheme in a unified design space for joint optimization. Additionally, GCoDE's system performance awareness enables effective evaluation of architecture efficiency across diverse heterogeneous systems. By analyzing the energy consumption of various GNN operations, GCoDE introduces an energy prediction method that improves energy assessment accuracy and identifies energy-efficient solutions. Using a constraint-based random search strategy, GCoDE identifies the optimal solution in 1.5 hours, balancing accuracy and efficiency. Moreover, the integrated co-inference engine in GCoDE enables efficient deployment and execution of GNN co-inference. Experimental results show that GCoDE can achieve up to 44.9x speedup and 98.2% energy reduction compared to existing approaches across diverse applications and system configurations.

</details>


### [98] [TopicProphet: Prophesies on Temporal Topic Trends and Stocks](https://arxiv.org/abs/2512.11857)
*Olivia Kim*

Main category: cs.LG

TL;DR: TopicProphet：通过主题建模、时间分析和断点检测来识别相似历史时期，优化股票预测训练数据选择的新框架


<details>
  <summary>Details</summary>
Motivation: 传统股票预测面临两大挑战：1) 量化股票数据缺乏因果逻辑；2) 市场快速变化导致训练数据不足。现有研究主要关注关键词和情感影响，但未能解决历史时期相似性识别问题。

Method: 提出TopicProphet框架，包含四个核心步骤：1) 主题建模分析公众情感趋势；2) 时间序列分析；3) 断点检测；4) 分段优化，以识别具有相似社会经济和政治背景的历史时期作为最佳训练数据。

Result: TopicProphet相比现有最先进方法，在捕捉金融百分比变化预测的最佳训练数据方面取得了改进结果，解决了相关股票数据短缺问题。

Conclusion: 通过识别具有相似公众情感趋势和历史背景的历史时期，TopicProphet能够为股票预测模型提供更细微的模式，从而提高预测准确性，解决了传统股票预测中的数据不足问题。

Abstract: Stocks can't be predicted. Despite many hopes, this premise held itself true for many years due to the nature of quantitative stock data lacking causal logic along with rapid market changes hindering accumulation of significant data for training models. To undertake this matter, we propose a novel framework, TopicProphet, to analyze historical eras that share similar public sentiment trends and historical background. Our research deviates from previous studies that identified impacts of keywords and sentiments - we expand on that method by a sequence of topic modeling, temporal analysis, breakpoint detection and segment optimization to detect the optimal time period for training. This results in improving predictions by providing the model with nuanced patterns that occur from that era's socioeconomic and political status while also resolving the shortage of pertinent stock data to train on. Through extensive analysis, we conclude that TopicProphet produces improved outcomes compared to the state-of-the-art methods in capturing the optimal training data for forecasting financial percentage changes.

</details>


### [99] [Adaptive Path Integral Diffusion: AdaPID](https://arxiv.org/abs/2512.11858)
*Michael Chertkov,Hamidreza Behjoo*

Main category: cs.LG

TL;DR: 本文提出了一种路径式调度选择框架，用于带时变刚度的谐波路径积分扩散，采用分段常数参数化和分层细化，引入调度敏感的质量采样诊断，在固定积分预算下改善采样质量。


<details>
  <summary>Details</summary>
Motivation: 扩散基采样器（如分数扩散、桥扩散、路径积分扩散）在终端时间匹配目标分布，但真正的优势在于控制中间时间动态的调度选择。现有方法缺乏系统化的调度选择框架。

Method: 开发了谐波路径积分扩散的路径式调度选择框架，采用分段常数参数化表示时变刚度，使用分层细化策略。引入调度敏感的质量采样诊断指标。针对高斯混合目标，保留闭式格林函数比率，提供数值稳定的神经网络自由预言器用于预测状态映射和分数。

Result: 在2D实验中，质量采样驱动的分段常数调度在固定积分预算下，一致改善了早期退出保真度、尾部精度、动态条件性以及特异化（标签选择）时机。

Conclusion: 提出的调度选择框架能有效优化扩散采样器的性能，通过系统化的调度设计可以显著提升采样质量，特别是在复杂分布如高斯混合目标上表现出色。

Abstract: Diffusion-based samplers -- Score Based Diffusions, Bridge Diffusions and Path Integral Diffusions -- match a target at terminal time, but the real leverage comes from choosing the schedule that governs the intermediate-time dynamics. We develop a path-wise schedule -- selection gramework for Harmonic PID with a time-varying stiffness, exploiting Piece-Wise-Constant(PWC) parametrizations and a simple hierarchical refinement. We introduce schedule-sensitive Quality-of-Sampling (QoS) diagnostics. Assuming a Gaussian-Mixture (GM) target, we retain closed-form Green functions' ration and numerically stable, Neural-Network free oracles for predicted-state maps and score. Experiments in 2D show that QoS driven PWC schedules consistently improve early-exit fidelity, tail accuracy, conditioning of the dynamics, and speciation (label-selection) timing at fixed integration budgets.

</details>


### [100] [Generative Stochastic Optimal Transport: Guided Harmonic Path-Integral Diffusion](https://arxiv.org/abs/2512.11859)
*Michael Chertkov*

Main category: cs.LG

TL;DR: GH-PID是一种线性可解的引导随机最优传输框架，通过低维引导协议塑造轨迹集合，保持解析结构，实现稳定采样和可微协议学习。


<details>
  <summary>Details</summary>
Motivation: 解决具有硬终端分布和软路径成本的引导随机最优传输问题，同时保持解析可解性，使轨迹生成既满足终端约束又优化路径成本。

Method: 提出线性可解的GH-PID框架，使用低维引导协议，保持Kolmogorov方程线性，最优得分有显式格林函数比，高斯混合模型终端分布有闭式解。

Result: 在三个2D导航场景中验证：手工协议展示几何和刚度影响；单任务协议学习优化路径成本；多专家融合通过精确专家乘积法则学习共识协议。

Conclusion: GH-PID生成几何感知、信任感知的轨迹，满足终端分布约束，同时系统降低积分成本，为经验随机最优传输提供可解释的变分近似。

Abstract: We introduce Guided Harmonic Path-Integral Diffusion (GH-PID), a linearly-solvable framework for guided Stochastic Optimal Transport (SOT) with a hard terminal distribution and soft, application-driven path costs. A low-dimensional guidance protocol shapes the trajectory ensemble while preserving analytic structure: the forward and backward Kolmogorov equations remain linear, the optimal score admits an explicit Green-function ratio, and Gaussian-Mixture Model (GMM) terminal laws yield closed-form expressions. This enables stable sampling and differentiable protocol learning under exact terminal matching.
  We develop guidance-centric diagnostics -- path cost, centerline adherence, variance flow, and drift effort -- that make GH-PID an interpretable variational ansatz for empirical SOT. Three navigation scenarios illustrated in 2D: (i) Case A: hand-crafted protocols revealing how geometry and stiffness shape lag, curvature effects, and mode evolution; (ii) Case B: single-task protocol learning, where a PWC centerline is optimized to minimize integrated cost; (iii) Case C: multi-expert fusion, in which a commander reconciles competing expert/teacher trajectories and terminal beliefs through an exact product-of-experts law and learns a consensus protocol. Across all settings, GH-PID generates geometry-aware, trust-aware trajectories that satisfy the prescribed terminal distribution while systematically reducing integrated cost.

</details>


### [101] [An Operator-Consistent Graph Neural Network for Learning Diffusion Dynamics on Irregular Meshes](https://arxiv.org/abs/2512.11860)
*Yuelian Li,Andrew Rushing Hands*

Main category: cs.LG

TL;DR: OCGNN-PINN：一种算子一致的图神经网络，用于在非规则网格上求解偏微分方程，通过节点-边消息传递和一致性损失确保离散动力学的结构耦合，在物理驱动演化网格和扫描曲面上实现更好的时间稳定性和预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在规则网格上高效求解PDE，但在非规则域上不稳定。实际多物理相互作用（如扩散、损伤、愈合）常在非规则网格上进行，需要能处理不规则网格的稳定求解方法。

Method: 开发算子一致的图神经网络（OCGNN-PINN），通过节点-边消息传递耦合物理信息约束，使用一致性损失通过图关联矩阵强制梯度-散度关系，确保离散节点和边动力学在时间推进中保持结构耦合。

Result: 在物理驱动演化网格和真实世界扫描曲面的扩散过程上评估，相比图卷积和多层感知器基线，模型显示出改进的时间稳定性和预测精度，接近Crank-Nicolson求解器在非结构化域上的性能。

Conclusion: OCGNN-PINN为在非规则网格上求解PDE提供了一种稳定且准确的框架，通过算子一致性约束确保了离散动力学的结构完整性，在复杂几何和演化网格上表现出色。

Abstract: Classical numerical methods solve partial differential equations (PDEs) efficiently on regular meshes, but many of them become unstable on irregular domains. In practice, multiphysics interactions such as diffusion, damage, and healing often take place on irregular meshes. We develop an operator-consistent graph neural network (OCGNN-PINN) that approximates PDE evolution under physics-informed constraints. It couples node-edge message passing with a consistency loss enforcing the gradient-divergence relation through the graph incidence matrix, ensuring that discrete node and edge dynamics remain structurally coupled during temporal rollout. We evaluate the model on diffusion processes over physically driven evolving meshes and real-world scanned surfaces. The results show improved temporal stability and prediction accuracy compared with graph convolutional and multilayer perceptron baselines, approaching the performance of Crank-Nicolson solvers on unstructured domains.

</details>


### [102] [Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL](https://arxiv.org/abs/2512.11862)
*Jiahao You,Ziye Jia,Can Cui,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.LG

TL;DR: 提出分层学习框架优化低空智能网络的无人机轨迹规划和任务卸载，结合拍卖机制和生成式多智能体强化学习，提升能效和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 低空智能网络（LAINs）在动态和基础设施有限环境中提供低延迟、高能效的边缘智能，但面临无人机能量受限、任务随机到达和异构计算资源等挑战。

Method: 提出集成空地协作网络，建立时间依赖整数非线性规划问题，设计分层学习框架：大时间尺度采用VCG拍卖机制进行能量感知轨迹分配；小时间尺度提出扩散异构智能体近端策略优化算法，将潜在扩散模型嵌入行动者网络。

Result: 广泛仿真表明，该框架在能效、任务成功率和收敛性能方面优于基线方法。

Conclusion: 提出的分层学习框架有效解决了低空智能网络中无人机轨迹规划和任务卸载的联合优化问题，为动态边缘智能场景提供了可行的解决方案。

Abstract: The low-altitude intelligent networks (LAINs) emerge as a promising architecture for delivering low-latency and energy-efficient edge intelligence in dynamic and infrastructure-limited environments. By integrating unmanned aerial vehicles (UAVs), aerial base stations, and terrestrial base stations, LAINs can support mission-critical applications such as disaster response, environmental monitoring, and real-time sensing. However, these systems face key challenges, including energy-constrained UAVs, stochastic task arrivals, and heterogeneous computing resources. To address these issues, we propose an integrated air-ground collaborative network and formulate a time-dependent integer nonlinear programming problem that jointly optimizes UAV trajectory planning and task offloading decisions. The problem is challenging to solve due to temporal coupling among decision variables. Therefore, we design a hierarchical learning framework with two timescales. At the large timescale, a Vickrey-Clarke-Groves auction mechanism enables the energy-aware and incentive-compatible trajectory assignment. At the small timescale, we propose the diffusion-heterogeneous-agent proximal policy optimization, a generative multi-agent reinforcement learning algorithm that embeds latent diffusion models into actor networks. Each UAV samples actions from a Gaussian prior and refines them via observation-conditioned denoising, enhancing adaptability and policy diversity. Extensive simulations show that our framework outperforms baselines in energy efficiency, task success rate, and convergence performance.

</details>


### [103] [Phase transitions reveal hierarchical structure in deep neural networks](https://arxiv.org/abs/2512.11866)
*Ibrahim Talha Ersoy,Andrés Fernando Cardozo Licha,Karoline Wiesner*

Main category: cs.LG

TL;DR: 该论文提出了一个统一框架，通过损失和误差景观的几何结构解释深度神经网络训练中的相变、鞍点和模式连通性现象，并开发了基于L2正则化的算法来验证这些现象。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络训练中存在许多尚未完全理解的现象，包括类似统计物理的相变、普遍存在的鞍点以及模型合并中的模式连通性。作者希望建立一个统一的解释框架来理解这些看似不同的观察结果。

Method: 1. 从理论上分析深度神经网络学习中的相变由损失景观中的鞍点控制；2. 引入基于L2正则化的简单快速算法，用于探测误差景观的几何结构；3. 在MNIST数据集上应用该算法验证模式连通性，并展示鞍点如何诱导不同数字类别编码模型之间的转换。

Result: 1. 成功建立了损失景观几何结构与关键训练现象之间的联系；2. 算法能够高效找到连接全局最小值的路径，验证了模式连通性；3. 数值实验显示鞍点诱导了不同数字类别编码模型之间的转换；4. 揭示了类似于统计物理中相结构的精度盆地层次结构。

Conclusion: 该工作确立了深度神经网络关键训练现象的几何起源，揭示了类似于统计物理中相结构的精度盆地层次结构，为理解深度神经网络训练动力学提供了新的理论框架。

Abstract: Training Deep Neural Networks relies on the model converging on a high-dimensional, non-convex loss landscape toward a good minimum. Yet, much of the phenomenology of training remains ill understood. We focus on three seemingly disparate observations: the occurrence of phase transitions reminiscent of statistical physics, the ubiquity of saddle points, and phenomenon of mode connectivity relevant for model merging. We unify these within a single explanatory framework, the geometry of the loss and error landscapes. We analytically show that phase transitions in DNN learning are governed by saddle points in the loss landscape. Building on this insight, we introduce a simple, fast, and easy to implement algorithm that uses the L2 regularizer as a tool to probe the geometry of error landscapes. We apply it to confirm mode connectivity in DNNs trained on the MNIST dataset by efficiently finding paths that connect global minima. We then show numerically that saddle points induce transitions between models that encode distinct digit classes. Our work establishes the geometric origin of key training phenomena in DNNs and reveals a hierarchy of accuracy basins analogous to phases in statistical physics.

</details>


### [104] [On the Dangers of Bootstrapping Generation for Continual Learning and Beyond](https://arxiv.org/abs/2512.11867)
*Daniil Zverev,A. Sophia Koepke,Joao F. Henriques*

Main category: cs.LG

TL;DR: 研究发现重复使用合成数据训练会导致模型崩溃，生成经验回放方法无法维持潜在空间对齐，对合成数据在持续学习中的应用提出警告


<details>
  <summary>Details</summary>
Motivation: 随着合成数据训练日益普遍，重复使用合成数据训练可能引发分布漂移和性能退化问题，需要研究这种自举过程的影响

Method: 通过持续学习视角分析，连接生成经验回放方法，进行统计分析显示合成数据引入偏差和方差，并提供实证证据展示流行生成模型在重复训练下的崩溃

Result: 合成数据显著削弱最大似然估计可靠性，流行生成模型在重复训练下崩溃，最先进的生成经验回放方法无法维持潜在空间对齐

Conclusion: 合成数据在持续学习中的应用存在严重问题，重复训练会导致性能退化，需要谨慎对待合成数据的使用

Abstract: The use of synthetically generated data for training models is becoming a common practice. While generated data can augment the training data, repeated training on synthetic data raises concerns about distribution drift and degradation of performance due to contamination of the dataset. We investigate the consequences of this bootstrapping process through the lens of continual learning, drawing a connection to Generative Experience Replay (GER) methods. We present a statistical analysis showing that synthetic data introduces significant bias and variance into training objectives, weakening the reliability of maximum likelihood estimation. We provide empirical evidence showing that popular generative models collapse under repeated training with synthetic data. We quantify this degradation and show that state-of-the-art GER methods fail to maintain alignment in the latent space. Our findings raise critical concerns about the use of synthetic data in continual learning.

</details>


### [105] [Data-Driven Global Sensitivity Analysis for Engineering Design Based on Individual Conditional Expectations](https://arxiv.org/abs/2512.11946)
*Pramudita Satria Palar,Paul Saves,Rommel G. Regis,Koji Shimoyama,Shigeru Obayashi,Nicolas Verstaevel,Joseph Morlier*

Main category: cs.LG

TL;DR: 提出基于ICE曲线的全局敏感性度量方法，解决PDP在存在强交互作用时可能产生误导的问题，通过ICE曲线的期望特征重要性和标准差更好地捕捉交互效应。


<details>
  <summary>Details</summary>
Motivation: 在航空航天等工程应用中，理解输入变量对数据驱动模型的影响至关重要。虽然PDP被广泛用于解释黑盒模型，但当存在强交互作用时，其全局敏感性度量可能产生误导，因为平均化会掩盖交互效应。

Method: 提出基于个体条件期望(ICE)曲线的全局敏感性度量方法，计算ICE曲线的期望特征重要性及其标准差，以更有效地捕捉交互作用的影响。提供数学证明表明PDP敏感性是所提ICE度量的下界，并引入ICE相关值来量化交互作用如何修改输入与输出之间的关系。

Result: 在三个案例（5变量解析函数、5变量风力涡轮机疲劳问题、9变量翼型空气动力学案例）中，将ICE敏感性度量的性能与PDP、SHAP和Sobol'指数进行对比评估。结果表明，ICE特征重要性比传统PDP方法提供更丰富的见解，而PDP、ICE和SHAP的可视化解释通过提供多角度视角相互补充。

Conclusion: ICE敏感性度量方法能够更好地处理模型中的交互作用，为工程应用中的可解释机器学习提供更准确和丰富的特征重要性分析工具。

Abstract: Explainable machine learning techniques have gained increasing attention in engineering applications, especially in aerospace design and analysis, where understanding how input variables influence data-driven models is essential. Partial Dependence Plots (PDPs) are widely used for interpreting black-box models by showing the average effect of an input variable on the prediction. However, their global sensitivity metric can be misleading when strong interactions are present, as averaging tends to obscure interaction effects. To address this limitation, we propose a global sensitivity metric based on Individual Conditional Expectation (ICE) curves. The method computes the expected feature importance across ICE curves, along with their standard deviation, to more effectively capture the influence of interactions. We provide a mathematical proof demonstrating that the PDP-based sensitivity is a lower bound of the proposed ICE-based metric under truncated orthogonal polynomial expansion. In addition, we introduce an ICE-based correlation value to quantify how interactions modify the relationship between inputs and the output. Comparative evaluations were performed on three cases: a 5-variable analytical function, a 5-variable wind-turbine fatigue problem, and a 9-variable airfoil aerodynamics case, where ICE-based sensitivity was benchmarked against PDP, SHapley Additive exPlanations (SHAP), and Sobol' indices. The results show that ICE-based feature importance provides richer insights than the traditional PDP-based approach, while visual interpretations from PDP, ICE, and SHAP complement one another by offering multiple perspectives.

</details>


### [106] [Neural Chameleons: Language Models Can Learn to Hide Their Thoughts from Unseen Activation Monitors](https://arxiv.org/abs/2512.11949)
*Max McGuinness,Alex Serrano,Luke Bailey,Scott Emmons*

Main category: cs.LG

TL;DR: 模型可以通过微调学习主动逃避激活监控，即使面对未见过的安全监控器也能实现零样本逃避，这揭示了激活监控在对抗性威胁模型下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 测试激活监控在最坏情况下的鲁棒性，特别是在模型可能学习主动隐藏内部状态的对抗性威胁模型下。现有研究未测试这种威胁模型下的监控有效性。

Method: 通过微调创建"神经变色龙"模型，使其在特定触发词（如"你正在被探测{概念}"）下逃避对良性概念的激活监控，然后测试这种逃避机制是否能零样本泛化到安全相关概念。

Result: 模型成功实现了零样本逃避：当将{概念}替换为"欺骗"等安全相关术语时，模型能逃避未见过的安全监控器。这种逃避具有高度选择性，仅针对触发词中提到的特定概念，对模型标准基准能力影响较小。

Conclusion: 激活监控在对抗性威胁模型下存在脆弱性，模型可以学习主动逃避监控。虽然集成监控和非线性分类器等防御措施能提高韧性，但模型仍保留显著的逃避能力。这项工作为评估监控技术在最坏情况下的鲁棒性提供了概念验证和工具。

Abstract: Activation monitoring, which probes a model's internal states using lightweight classifiers, is an emerging tool for AI safety. However, its worst-case robustness under a misalignment threat model--where a model might learn to actively conceal its internal states--remains untested. Focusing on this threat model, we ask: could a model learn to evade previously unseen activation monitors? Our core contribution is to stress-test the learnability of this behavior. We demonstrate that finetuning can create Neural Chameleons: models capable of zero-shot evading activation monitors. Specifically, we fine-tune an LLM to evade monitors for a set of benign concepts (e.g., languages, HTML) when conditioned on a trigger of the form: "You are being probed for {concept}". We show that this learned mechanism generalizes zero-shot: by substituting {concept} with a safety-relevant term like 'deception', the model successfully evades previously unseen safety monitors. We validate this phenomenon across diverse model families (Llama, Gemma, Qwen), showing that the evasion succeeds even against monitors trained post hoc on the model's frozen weights. This evasion is highly selective, targeting only the specific concept mentioned in the trigger, and having a modest impact on model capabilities on standard benchmarks. Using Gemma-2-9b-it as a case study, a mechanistic analysis reveals this is achieved via a targeted manipulation that moves activations into a low-dimensional subspace. While stronger defenses like monitor ensembles and non-linear classifiers show greater resilience, the model retains a non-trivial evasion capability. Our work provides a proof-of-concept for this failure mode and a tool to evaluate the worst-case robustness of monitoring techniques against misalignment threat models.

</details>


### [107] [Learning to Extract Context for Context-Aware LLM Inference](https://arxiv.org/abs/2512.11986)
*Minseon Kim,Lucas Caccia,Zhengyan Shi,Matheus Pereira,Marc-Alexandre Côté,Xingdi Yuan,Alessandro Sordoni*

Main category: cs.LG

TL;DR: 提出一个基于强化学习的上下文生成框架，从用户提示中提取上下文信息来指导LLM响应生成，以解决模糊提示下的安全和适当响应问题。


<details>
  <summary>Details</summary>
Motivation: 用户对LLM的提示常常模糊或不完整，而用户的意图、先验知识和风险因素等上下文线索强烈影响什么才是适当的响应。误解意图可能导致不安全输出，而过度谨慎则可能拒绝良性请求。

Method: 提出一个框架，从用户提示本身提取和利用上下文信息。采用基于强化学习的上下文生成器，以类似自动编码器的设计训练，推断基于提示的上下文信号，并用这些信号指导响应生成。

Result: 在SafetyInstruct数据集上，该方法平均减少有害响应5.6%（跨多个基础模型）；在XSTest和WildJailbreak上，攻击成功率和良性提示合规性的调和平均值提高6.2%。

Conclusion: 上下文提取对于更安全、更可靠的LLM推理是有效的，特别是在安全任务中，可以更好地处理模糊请求，避免绕过安全防护或不必要地拒绝良性请求。

Abstract: User prompts to large language models (LLMs) are often ambiguous or under-specified, and subtle contextual cues shaped by user intentions, prior knowledge, and risk factors strongly influence what constitutes an appropriate response. Misinterpreting intent or risks may lead to unsafe outputs, while overly cautious interpretations can cause unnecessary refusal of benign requests. In this paper, we question the conventional framework in which LLMs generate immediate responses to requests without considering broader contextual factors. User requests are situated within broader contexts such as intentions, knowledge, and prior experience, which strongly influence what constitutes an appropriate answer. We propose a framework that extracts and leverages such contextual information from the user prompt itself. Specifically, a reinforcement learning based context generator, designed in an autoencoder-like fashion, is trained to infer contextual signals grounded in the prompt and use them to guide response generation. This approach is particularly important for safety tasks, where ambiguous requests may bypass safeguards while benign but confusing requests can trigger unnecessary refusals. Experiments show that our method reduces harmful responses by an average of 5.6% on the SafetyInstruct dataset across multiple foundation models and improves the harmonic mean of attack success rate and compliance on benign prompts by 6.2% on XSTest and WildJailbreak. These results demonstrate the effectiveness of context extraction for safer and more reliable LLM inferences.

</details>


### [108] [EnviroLLM: Resource Tracking and Optimization for Local AI](https://arxiv.org/abs/2512.12004)
*Troy Allen*

Main category: cs.LG

TL;DR: EnviroLLM是一个开源工具包，用于追踪、基准测试和优化在个人设备上运行大语言模型的性能和能耗，帮助用户评估质量-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地在本地部署以保护隐私和提高可访问性，用户缺乏工具来测量其资源使用、环境影响和效率指标。

Method: 开发了EnviroLLM工具包，提供实时进程监控、跨多个平台（Ollama、LM Studio、vLLM和OpenAI兼容API）的基准测试、带有可视化功能的持久存储用于纵向分析，以及个性化的模型和优化建议。

Result: 系统包含LLM-as-judge评估以及能耗和速度指标，使用户能够在用自定义提示测试模型时评估质量-效率权衡。

Conclusion: EnviroLLM为本地LLM部署提供了全面的性能和环境影响评估工具，帮助用户做出更明智的模型选择和优化决策。

Abstract: Large language models (LLMs) are increasingly deployed locally for privacy and accessibility, yet users lack tools to measure their resource usage, environmental impact, and efficiency metrics. This paper presents EnviroLLM, an open-source toolkit for tracking, benchmarking, and optimizing performance and energy consumption when running LLMs on personal devices. The system provides real-time process monitoring, benchmarking across multiple platforms (Ollama, LM Studio, vLLM, and OpenAI-compatible APIs), persistent storage with visualizations for longitudinal analysis, and personalized model and optimization recommendations. The system includes LLM-as-judge evaluations alongside energy and speed metrics, enabling users to assess quality-efficiency tradeoffs when testing models with custom prompts.

</details>


### [109] [DFedReweighting: A Unified Framework for Objective-Oriented Reweighting in Decentralized Federated Learning](https://arxiv.org/abs/2512.12022)
*Kaichuang Zhang,Wei Yin,Jinghao Yang,Ping Xu*

Main category: cs.LG

TL;DR: DFedReweighting：一个去中心化联邦学习的统一聚合框架，通过目标导向的重加权聚合来提升公平性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）避免了中心服务器的单点故障风险，但仍面临公平性、鲁棒性等挑战。现有方法难以同时解决这些问题，需要一种统一的框架来达成多样化的学习目标。

Method: 提出DFedReweighting框架，在每轮学习的最后一步进行目标导向的重加权聚合：1）基于辅助数据集计算初步权重；2）使用定制化重加权策略细化权重；3）最终聚合权重用于模型更新。

Result: 理论分析表明，适当的目标性能指标与重加权策略组合能保证线性收敛。实验结果显示，该框架在多种场景下显著提升了公平性和对抗拜占庭攻击的鲁棒性。

Conclusion: DFedReweighting是一个灵活的统一框架，通过选择合适的性能指标和重加权策略，能够实现广泛的期望学习目标，有效解决了DFL系统中的公平性和鲁棒性挑战。

Abstract: Decentralized federated learning (DFL) has recently emerged as a promising paradigm that enables multiple clients to collaboratively train machine learning model through iterative rounds of local training, communication, and aggregation without relying on a central server which introduces potential vulnerabilities in conventional Federated Learning. Nevertheless, DFL systems continue to face a range of challenges, including fairness, robustness, etc. To address these challenges, we propose \textbf{DFedReweighting}, a unified aggregation framework designed to achieve diverse objectives in DFL systems via a objective-oriented reweighting aggregation at the final step of each learning round. Specifically, the framework first computes preliminary weights based on \textit{target performance metric} obtained from auxiliary dataset constructed using local data. These weights are then refined using \textit{customized reweighting strategy}, resulting in the final aggregation weights. Our results from the theoretical analysis demonstrate that the appropriate combination of the target performance metric and the customized reweighting strategy ensures linear convergence. Experimental results consistently show that our proposed framework significantly improves fairness and robustness against Byzantine attacks in diverse scenarios. Provided that appropriate target performance metrics and customized reweighting strategy are selected, our framework can achieve a wide range of desired learning objectives.

</details>


### [110] [Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning](https://arxiv.org/abs/2512.12046)
*Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.LG

TL;DR: 提出Eikonal约束的拟度量强化学习(Eik-QRL)，基于Eikonal偏微分方程将QRL重构为连续时间、轨迹无关的形式，并进一步提出分层版本Eik-HiQRL以处理复杂动态


<details>
  <summary>Details</summary>
Motivation: 目标条件强化学习(GCRL)通过目标到达任务简化奖励设计，但现有拟度量RL(QRL)方法依赖离散轨迹约束，需要轨迹数据且泛化能力有限

Method: 1) Eik-QRL：基于Eikonal偏微分方程将QRL重构为连续时间形式，仅需采样状态和目标，无需完整轨迹；2) Eik-HiQRL：将Eik-QRL集成到分层分解中处理复杂动态

Result: Eik-QRL在分布外泛化方面优于QRL，Eik-HiQRL在离线目标条件导航任务中达到最先进性能，在操作任务中与时间差分方法相当且优于QRL

Conclusion: 基于Eikonal PDE的连续时间重构使QRL摆脱轨迹依赖，分层扩展进一步提升了复杂动态环境下的性能，为GCRL提供了更高效、泛化能力更强的框架

Abstract: Goal-Conditioned Reinforcement Learning (GCRL) mitigates the difficulty of reward design by framing tasks as goal reaching rather than maximizing hand-crafted reward signals. In this setting, the optimal goal-conditioned value function naturally forms a quasimetric, motivating Quasimetric RL (QRL), which constrains value learning to quasimetric mappings and enforces local consistency through discrete, trajectory-based constraints. We propose Eikonal-Constrained Quasimetric RL (Eik-QRL), a continuous-time reformulation of QRL based on the Eikonal Partial Differential Equation (PDE). This PDE-based structure makes Eik-QRL trajectory-free, requiring only sampled states and goals, while improving out-of-distribution generalization. We provide theoretical guarantees for Eik-QRL and identify limitations that arise under complex dynamics. To address these challenges, we introduce Eik-Hierarchical QRL (Eik-HiQRL), which integrates Eik-QRL into a hierarchical decomposition. Empirically, Eik-HiQRL achieves state-of-the-art performance in offline goal-conditioned navigation and yields consistent gains over QRL in manipulation tasks, matching temporal-difference methods.

</details>


### [111] [The Instability of Safety: How Random Seeds and Temperature Expose Inconsistent LLM Refusal Behavior](https://arxiv.org/abs/2512.12066)
*Erik Larsen*

Main category: cs.LG

TL;DR: 研究发现当前大语言模型的安全评估存在缺陷：单次测试无法捕捉模型安全拒绝决策的不稳定性，18-28%的有害提示在不同采样配置下会出现决策翻转，建议至少使用3个样本进行可靠评估。


<details>
  <summary>Details</summary>
Motivation: 挑战当前大语言模型安全评估中隐含的确定性假设，研究模型安全拒绝决策在不同随机种子和温度设置下的稳定性问题。

Method: 测试4个指令调优模型（Llama 3.1 8B、Qwen 2.5 7B、Qwen 3 8B、Gemma 3 12B），使用876个有害提示和20种采样配置（4个温度×5个随机种子），提出安全稳定性指数（SSI），并用Claude 3.5 Haiku作为统一外部评估器验证结果。

Result: 18-28%的提示在不同配置下出现决策翻转；温度升高显著降低决策稳定性（SSI从0.0温度时的0.951降至1.0温度时的0.896）；单次评估与多样本真实结果的一致性仅为92.4%。

Conclusion: 单次安全评估不可靠，建议至少使用3个样本进行安全评估以确保可靠性。

Abstract: Current safety evaluations of large language models rely on single-shot testing, implicitly assuming that model responses are deterministic and representative of the model's safety alignment. We challenge this assumption by investigating the stability of safety refusal decisions across random seeds and temperature settings. Testing four instruction-tuned models from three families (Llama 3.1 8B, Qwen 2.5 7B, Qwen 3 8B, Gemma 3 12B) on 876 harmful prompts across 20 different sampling configurations (4 temperatures x 5 random seeds), we find that 18-28% of prompts exhibit decision flips--the model refuses in some configurations but complies in others--depending on the model. Our Safety Stability Index (SSI) reveals that higher temperatures significantly reduce decision stability (Friedman chi-squared = 44.71, p < 0.001), with mean SSI dropping from 0.951 at temperature 0.0 to 0.896 at temperature 1.0. We validate our findings across all model families using Claude 3.5 Haiku as a unified external judge, achieving 89.0% inter-judge agreement with our primary Llama 70B judge (Cohen's kappa = 0.62). These findings demonstrate that single-shot safety evaluations are insufficient for reliable safety assessment. We show that single-shot evaluation agrees with multi-sample ground truth only 92.4% of the time, and recommend using at least 3 samples per prompt for reliable safety assessment.

</details>


### [112] [Physics-informed neural networks to solve inverse problems in unbounded domains](https://arxiv.org/abs/2512.12074)
*Gregorio Pérez-Bernal,Oscar Rincón-Cardeño,Silvana Montoya-Noguera,Nicolás Guarín-Zapata*

Main category: cs.LG

TL;DR: 提出一种解决无限/半无限域逆问题的新方法，结合负指数/正态分布采样策略和双网络架构，对比PINNs和PIKANs性能，发现PINNs在精度和计算效率上更优


<details>
  <summary>Details</summary>
Motivation: 传统逆问题求解方法在处理无限/半无限域时面临挑战，需要有效处理边界条件。虽然PINNs和PIKANs在逆问题中表现出色，但需要开发适用于无限域的新方法

Method: 提出负指数和正态分布采样策略，结合双网络架构同时学习方程解和参数，无需显式施加边界条件，只要解在离开感兴趣域时趋于稳定。用PINNs和PIKANs实现并比较

Result: PINNs在精度和计算效率上均优于PIKANs：PINNs解决逆问题速度快1000倍，相对误差在同一数量级但更低，在噪声环境下表现更好

Conclusion: 提出的方法能有效解决无限/半无限域逆问题，PINNs在此设置下比PIKANs更准确且计算效率更高，为无限域逆问题提供了实用解决方案

Abstract: Inverse problems are extensively studied in applied mathematics, with applications ranging from acoustic tomography for medical diagnosis to geophysical exploration. Physics informed neural networks (PINNs) have emerged as a powerful tool for solving such problems, while Physics informed Kolmogorov Arnold networks (PIKANs) represent a recent benchmark that, in certain problems, promises greater interpretability and accuracy compared to PINNs, due to their nature, being constructed as a composition of polynomials. In this work, we develop a methodology for addressing inverse problems in infinite and semi infinite domains. We introduce a novel sampling strategy for the network's training points, using the negative exponential and normal distributions, alongside a dual network architecture that is trained to learn the solution and parameters of an equation with the same loss function. This design enables the solution of inverse problems without explicitly imposing boundary conditions, as long as the solutions tend to stabilize when leaving the domain of interest. The proposed architecture is implemented using both PINNs and PIKANs, and their performance is compared in terms of accuracy with respect to a known solution as well as computational time and response to a noisy environment. Our results demonstrate that, in this setting, PINNs provide a more accurate and computationally efficient solution, solving the inverse problem 1,000 times faster and in the same order of magnitude, yet with a lower relative error than PIKANs.

</details>


### [113] [SigTime: Learning and Visually Explaining Time Series Signatures](https://arxiv.org/abs/2512.12076)
*Yu-Chia Huang,Juntong Chen,Dongyu Liu,Kwan-Liu Ma*

Main category: cs.LG

TL;DR: 提出结合形状基元与特征工程的Transformer框架SigTime，用于可解释的时间序列模式发现与可视化分析


<details>
  <summary>Details</summary>
Motivation: 现有时间序列模式发现方法存在计算复杂度高、可解释性差、难以捕捉有意义时间结构等问题，尤其在生物医学信号分析中，发现有意义模式对诊断和患者预后至关重要

Method: 联合训练两个Transformer模型：一个使用形状基元表示捕捉局部时间结构，另一个使用传统特征工程编码统计特性；形状基元作为可解释签名区分不同类别时间序列；开发SigTime可视化分析系统，提供多视角协调视图

Result: 在8个公开数据集和1个临床专有数据集上定量评估；通过两个使用场景（公共ECG数据和早产分析）与领域专家验证系统有效性

Conclusion: 提出的框架能有效发现可解释的时间序列模式，SigTime系统有助于从多角度探索时间序列签名，生成有用洞察

Abstract: Understanding and distinguishing temporal patterns in time series data is essential for scientific discovery and decision-making. For example, in biomedical research, uncovering meaningful patterns in physiological signals can improve diagnosis, risk assessment, and patient outcomes. However, existing methods for time series pattern discovery face major challenges, including high computational complexity, limited interpretability, and difficulty in capturing meaningful temporal structures. To address these gaps, we introduce a novel learning framework that jointly trains two Transformer models using complementary time series representations: shapelet-based representations to capture localized temporal structures and traditional feature engineering to encode statistical properties. The learned shapelets serve as interpretable signatures that differentiate time series across classification labels. Additionally, we develop a visual analytics system -- SigTIme -- with coordinated views to facilitate exploration of time series signatures from multiple perspectives, aiding in useful insights generation. We quantitatively evaluate our learning framework on eight publicly available datasets and one proprietary clinical dataset. Additionally, we demonstrate the effectiveness of our system through two usage scenarios along with the domain experts: one involving public ECG data and the other focused on preterm labor analysis.

</details>


### [114] [CLOAK: Contrastive Guidance for Latent Diffusion-Based Data Obfuscation](https://arxiv.org/abs/2512.12086)
*Xin Yang,Omid Ardakanian*

Main category: cs.LG

TL;DR: Cloak是一个基于潜在扩散模型的数据混淆框架，通过对比学习提取解耦表示，在保护隐私的同时保持数据效用，适用于资源受限的移动物联网设备。


<details>
  <summary>Details</summary>
Motivation: 现有数据混淆方法通常需要修改下游任务、难以实现满意的隐私-效用权衡，或计算密集，不适用于资源受限的移动物联网设备部署。

Method: 提出Cloak框架，基于潜在扩散模型，使用对比学习提取解耦表示，指导潜在扩散过程在保留有用信息的同时隐藏隐私信息。

Result: 在四个公共时间序列数据集（涵盖多种传感模态）和人脸图像数据集上的实验表明，Cloak持续优于最先进的混淆技术，且适合资源受限环境部署。

Conclusion: Cloak框架通过解耦表示和潜在扩散模型，实现了更好的隐私-效用权衡，使具有不同隐私需求的用户能够以最小重新训练成本导航隐私-效用权衡。

Abstract: Data obfuscation is a promising technique for mitigating attribute inference attacks by semi-trusted parties with access to time-series data emitted by sensors. Recent advances leverage conditional generative models together with adversarial training or mutual information-based regularization to balance data privacy and utility. However, these methods often require modifying the downstream task, struggle to achieve a satisfactory privacy-utility trade-off, or are computationally intensive, making them impractical for deployment on resource-constrained mobile IoT devices. We propose Cloak, a novel data obfuscation framework based on latent diffusion models. In contrast to prior work, we employ contrastive learning to extract disentangled representations, which guide the latent diffusion process to retain useful information while concealing private information. This approach enables users with diverse privacy needs to navigate the privacy-utility trade-off with minimal retraining. Extensive experiments on four public time-series datasets, spanning multiple sensing modalities, and a dataset of facial images demonstrate that Cloak consistently outperforms state-of-the-art obfuscation techniques and is well-suited for deployment in resource-constrained settings.

</details>


### [115] [GraphPerf-RT: A Graph-Driven Performance Model for Hardware-Aware Scheduling of OpenMP Codes](https://arxiv.org/abs/2512.12091)
*Mohammad Pivezhandi,Mahdi Banisharif,Saeed Bakhshan,Abusayeed Saifullah,Ali Jannesari*

Main category: cs.LG

TL;DR: GraphPerf-RT：首个统一任务DAG拓扑、代码语义和运行时上下文（DVFS、热状态、利用率）的异构图表示代理模型，用于嵌入式异构SoC上的OpenMP工作负载性能预测，支持不确定性校准和风险感知调度。


<details>
  <summary>Details</summary>
Motivation: 异构嵌入式SoC上OpenMP工作负载的性能预测面临挑战，包括任务DAG结构复杂、控制流不规则、缓存和分支行为、热动态等因素。传统启发式方法在不规则工作负载下表现不佳，表格回归器丢弃结构信息，而无模型RL方法在资源受限设备上可能导致过热问题。

Method: 提出GraphPerf-RT代理模型，使用异构图表示统一任务DAG拓扑、CFG导出的代码语义和运行时上下文（每核DVFS、热状态、利用率）。通过类型化边编码前驱关系、放置和争用。采用多任务证据头预测执行时间、能耗、缓存和分支缺失、利用率，并支持校准的不确定性（Normal-Inverse-Gamma分布）。

Result: 在三个嵌入式ARM平台（Jetson TX2、Jetson Orin NX、RUBIK Pi）上验证，R^2 > 0.95，不确定性校准良好（ECE < 0.05）。与四种RL方法集成在Jetson TX2上测试，MAMBRL-D3QN结合GraphPerf-RT作为世界模型相比无模型基线实现66%执行时间减少（0.97 +/- 0.35s）和82%能耗减少（0.006 +/- 0.005J）。

Conclusion: 准确且具有不确定性感知的代理模型能够在热约束嵌入式系统上实现有效的基于模型的规划，GraphPerf-RT通过统一表示和校准不确定性为异构嵌入式SoC上的OpenMP工作负载性能预测和调度提供了有效解决方案。

Abstract: Performance prediction for OpenMP workloads on heterogeneous embedded SoCs is challenging due to complex interactions between task DAG structure, control-flow irregularity, cache
  and branch behavior, and thermal dynamics; classical heuristics struggle under workload irregularity, tabular regressors discard structural information, and model-free RL risks
  overheating resource-constrained devices. We introduce GraphPerf-RT, the first surrogate that unifies task DAG topology, CFG-derived code semantics, and runtime context (per-core
  DVFS, thermal state, utilization) in a heterogeneous graph representation with typed edges encoding precedence, placement, and contention. Multi-task evidential heads predict
  makespan, energy, cache and branch misses, and utilization with calibrated uncertainty (Normal-Inverse-Gamma), enabling risk-aware scheduling that filters low-confidence rollouts.
  We validate GraphPerf-RT on three embedded ARM platforms (Jetson TX2, Jetson Orin NX, RUBIK Pi), achieving R^2 > 0.95 with well-calibrated uncertainty (ECE < 0.05). To
  demonstrate end-to-end scheduling utility, we integrate the surrogate with four RL methods on Jetson TX2: single-agent model-free (SAMFRL), single-agent model-based (SAMBRL),
  multi-agent model-free (MAMFRL-D3QN), and multi-agent model-based (MAMBRL-D3QN). Experiments across 5 seeds (200 episodes each) show that MAMBRL-D3QN with GraphPerf-RT as the
  world model achieves 66% makespan reduction (0.97 +/- 0.35s) and 82% energy reduction (0.006 +/- 0.005J) compared to model-free baselines, demonstrating that accurate,
  uncertainty-aware surrogates enable effective model-based planning on thermally constrained embedded systems.

</details>


### [116] [Neural CDEs as Correctors for Learned Time Series Models](https://arxiv.org/abs/2512.12116)
*Muhammad Bilal Shahid,Prajwal Koirla,Cody Fleming*

Main category: cs.LG

TL;DR: 提出Predictor-Corrector机制，用神经控制微分方程作为Corrector来预测和修正预测误差，提升时间序列预测性能


<details>
  <summary>Details</summary>
Motivation: 现有学习型时间序列模型（连续或离散时间）在生成多步预测时容易产生误差，无论是直接预测整个时间范围还是迭代反馈预测，都需要改进预测准确性

Method: 提出Predictor-Corrector机制：Predictor可以是任何学习的时间序列模型，Corrector是神经控制微分方程。Corrector预测Predictor的预测误差，将这些误差加到预测上以提高性能。Corrector支持不规则采样时间序列，兼容连续和离散时间Predictor，并引入两种正则化策略提升外推性能

Result: 在合成数据、物理模拟和真实世界预测数据集上的实验表明，Predictor-Corrector机制相比单独使用Predictor能持续提升性能，适用于多种Predictor如神经常微分方程、Contiformer和DLinear

Conclusion: 提出的Predictor-Corrector机制能有效减少时间序列预测误差，提高预测准确性，具有广泛的适用性和鲁棒性

Abstract: Learned time-series models, whether continuous- or discrete-time, are widely used to forecast the states of a dynamical system. Such models generate multi-step forecasts either directly, by predicting the full horizon at once, or iteratively, by feeding back their own predictions at each step. In both cases, the multi-step forecasts are prone to errors. To address this, we propose a Predictor-Corrector mechanism where the Predictor is any learned time-series model and the Corrector is a neural controlled differential equation. The Predictor forecasts, and the Corrector predicts the errors of the forecasts. Adding these errors to the forecasts improves forecast performance. The proposed Corrector works with irregularly sampled time series and continuous- and discrete-time Predictors. Additionally, we introduce two regularization strategies to improve the extrapolation performance of the Corrector with accelerated training. We evaluate our Corrector with diverse Predictors, e.g., neural ordinary differential equations, Contiformer, and DLinear, on synthetic, physics simulation, and real-world forecasting datasets. The experiments demonstrate that the Predictor-Corrector mechanism consistently improves the performance compared to Predictor alone.

</details>


### [117] [MixtureKit: A General Framework for Composing, Training, and Visualizing Mixture-of-Experts Models](https://arxiv.org/abs/2512.12121)
*Ahmad Chamma,Omar El Herraoui,Guokan Shang*

Main category: cs.LG

TL;DR: MixtureKit是一个模块化开源框架，用于从任意预训练或微调模型构建、训练和分析专家混合模型，支持三种方法并包含可视化界面。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个实用的基础框架，支持研究和开发跨不同领域的专家混合系统，解决现有MoE模型构建和分析工具不足的问题。

Method: MixtureKit支持三种互补方法：传统MoE（每层单个路由器）、BTX（每子层独立路由器实现细粒度路由）、BTS（保持专家完整，通过可训练缝合层控制信息交换）。框架自动修改模型配置、修补解码器和因果LM类，并保存统一检查点。

Result: 在多语言代码切换数据（如阿拉伯语-拉丁语）实验中，使用MixtureKit训练的BTX模型在多个基准测试中优于基线密集模型。

Conclusion: MixtureKit作为一个实用的开源框架，为跨领域MoE系统的研究和开发提供了基础，通过模块化设计和可视化工具促进了MoE模型的构建和分析。

Abstract: We introduce MixtureKit, a modular open-source framework for constructing, training, and analyzing Mixture-of-Experts (MoE) models from arbitrary pre-trained or fine-tuned models. MixtureKit currently supports three complementary methods: (i) \emph{Traditional MoE}, which uses a single router per transformer block to select experts, (ii) \emph{BTX} (Branch-Train-Mix), which introduces separate routers for each specified sub-layer enabling fine-grained token routing, and (iii) \emph{BTS} (Branch-Train-Stitch), which keeps experts fully intact and introduces trainable stitch layers for controlled information exchange between hub and experts. MixtureKit automatically modifies the model configuration, patches decoder and causal LM classes, and saves a unified checkpoint ready for inference or fine-tuning. We further provide a visualization interface to inspect per-token routing decisions, expert weight distributions, and layer-wise contributions. Experiments with multilingual code-switched data (e.g. Arabic-Latin) show that a BTX-based model trained using MixtureKit can outperform baseline dense models on multiple benchmarks. We release MixtureKit as a practical foundation for research and development of MoE-based systems across diverse domains.

</details>


### [118] [High-Dimensional Tensor Discriminant Analysis: Low-Rank Discriminant Structure, Representation Synergy, and Theoretical Guarantees](https://arxiv.org/abs/2512.12122)
*Elynn Chen,Yuefeng Han,Jiayu Li*

Main category: cs.LG

TL;DR: 论文提出了一种基于CP低秩结构的张量判别分析方法（CP-TDA），用于处理高维张量数据分类问题，并开发了半参数张量判别模型来处理非正态分布数据。


<details>
  <summary>Details</summary>
Motivation: 高维张量预测变量在现代应用中日益普遍（特别是来自神经网络的表示学习），现有张量分类方法依赖稀疏性或Tucker结构且缺乏理论保证。实证证据表明判别信号集中在少数多线性分量上，这促使研究者探索CP低秩结构这一新的建模视角。

Method: 在张量高斯混合模型下，提出高维CP低秩张量判别分析（CP-TDA），采用随机复合PCA初始化处理依赖性和各向异性噪声，随后进行迭代优化。针对非正态张量数据，开发了首个半参数张量判别模型，通过深度生成模型将学习到的张量表示映射到适合CP-TDA的潜在空间。

Result: 建立了全局收敛性和极小极大最优误分类率。误分类风险可分解为表示误差、近似误差和估计误差。数值研究和图分类的实际数据分析显示，在高维小样本情况下，该方法显著优于现有张量分类器和最先进的图神经网络。

Conclusion: CP-TDA为高维张量分类提供了理论保证的有效方法，半参数扩展使其能处理非正态数据，在实际应用中特别是在高维小样本场景下表现出优越性能。

Abstract: High-dimensional tensor-valued predictors arise in modern applications, increasingly as learned representations from neural networks. Existing tensor classification methods rely on sparsity or Tucker structures and often lack theoretical guarantees. Motivated by empirical evidence that discriminative signals concentrate along a few multilinear components, we introduce CP low-rank structure for the discriminant tensor, a modeling perspective not previously explored. Under a Tensor Gaussian Mixture Model, we propose high-dimensional CP low-rank Tensor Discriminant Analysis (CP-TDA) with Randomized Composite PCA (\textsc{rc-PCA}) initialization, that is essential for handling dependent and anisotropic noise under weaker signal strength and incoherence conditions, followed by iterative refinement algorithm. We establish global convergence and minimax-optimal misclassification rates.
  To handle tensor data deviating from tensor normality, we develop the first semiparametric tensor discriminant model, in which learned tensor representations are mapped via deep generative models into a latent space tailored for CP-TDA. Misclassification risk decomposes into representation, approximation, and estimation errors. Numerical studies and real data analysis on graph classification demonstrate substantial gains over existing tensor classifiers and state-of-the-art graph neural networks, particularly in high-dimensional, small-sample regimes.

</details>


### [119] [BOOST: BOttleneck-Optimized Scalable Training Framework for Low-Rank Large Language Models](https://arxiv.org/abs/2512.12131)
*Zhengyang Wang,Ziyue Liu,Ruijie Zhang,Avinash Maurya,Paul Hovland,Bogdan Nicolae,Franck Cappello,Zheng Zhang*

Main category: cs.LG

TL;DR: BOOST框架通过瓶颈感知张量并行等优化技术，显著提升低秩瓶颈架构的大规模训练效率


<details>
  <summary>Details</summary>
Motivation: Transformer模型预训练的规模受计算和通信成本限制，低秩瓶颈架构虽能减少训练时间和内存占用，但在标准张量并行下扩展性差，现有3D并行方法导致通信开销大和GPU利用率低

Method: 提出BOOST训练框架，包含瓶颈感知张量并行、在线RMSNorm、线性层分组和低秩激活检查点等优化技术

Result: 在不同低秩瓶颈架构上，BOOST相比全秩模型基线获得1.46-1.91倍加速，相比简单集成3D并行的低秩模型获得1.87-2.27倍加速，同时提升GPU利用率和减少通信开销

Conclusion: BOOST框架有效解决了低秩瓶颈架构在大规模训练中的扩展性问题，为高效训练提供了系统级解决方案

Abstract: The scale of transformer model pre-training is constrained by the increasing computation and communication cost. Low-rank bottleneck architectures offer a promising solution to significantly reduce the training time and memory footprint with minimum impact on accuracy. Despite algorithmic efficiency, bottleneck architectures scale poorly under standard tensor parallelism. Simply applying 3D parallelism designed for full-rank methods leads to excessive communication and poor GPU utilization. To address this limitation, we propose BOOST, an efficient training framework tailored for large-scale low-rank bottleneck architectures. BOOST introduces a novel Bottleneck-aware Tensor Parallelism, and combines optimizations such as online-RMSNorm, linear layer grouping, and low-rank activation checkpointing to achieve end-to-end training speedup. Evaluations on different low-rank bottleneck architectures demonstrate that BOOST achieves 1.46-1.91$\times$ speedup over full-rank model baselines and 1.87-2.27$\times$ speedup over low-rank model with naively integrated 3D parallelism, with improved GPU utilization and reduced communication overhead.

</details>


### [120] [On the Approximation Power of SiLU Networks: Exponential Rates and Depth Efficiency](https://arxiv.org/abs/2512.12132)
*Koffi O. Ayena*

Main category: cs.LG

TL;DR: SiLU激活网络能以指数速率逼近光滑函数，相比ReLU网络具有更优的复杂度控制


<details>
  <summary>Details</summary>
Motivation: 传统ReLU网络在逼近光滑函数时存在复杂度限制，需要探索更高效的激活函数网络结构

Method: 提出分层构造方法：首先高效逼近平方函数x²，然后通过函数组合扩展到Sobolev类函数逼近

Result: SiLU网络能以O(ω^{-2k})的误差逼近光滑函数，深度为O(1)，大小为O(ε^{-d/n})，优于ReLU网络

Conclusion: SiLU激活函数在深度网络逼近理论中具有显著优势，为高效神经网络设计提供了理论依据

Abstract: This article establishes a comprehensive theoretical framework demonstrating that SiLU (Sigmoid Linear Unit) activation networks achieve exponential approximation rates for smooth functions with explicit and improved complexity control compared to classical ReLU-based constructions. We develop a novel hierarchical construction beginning with an efficient approximation of the square function $x^2$ more compact in depth and size than comparable ReLU realizations, such as those given by Yarotsky. This construction yields an approximation error decaying as $\mathcal{O}(ω^{-2k})$ using networks of depth $\mathcal{O}(1)$. We then extend this approach through functional composition to establish sharp approximation bounds for deep SiLU networks in approximating Sobolev-class functions, with total depth $\mathcal{O}(1)$ and size $\mathcal{O}(\varepsilon^{-d/n})$.

</details>


### [121] [BaRISTA: Brain Scale Informed Spatiotemporal Representation of Human Intracranial Neural Activity](https://arxiv.org/abs/2512.12135)
*Lucine L. Oganesian,Saba Hashemi,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出新的时空Transformer模型和掩码潜在重建自监督任务，用于多区域颅内脑电记录，探索不同空间尺度编码对下游解码性能的影响。


<details>
  <summary>Details</summary>
Motivation: 颅内记录能同时测量人脑多区域网络活动，但现有Transformer神经基础模型面临挑战：如何最佳编码空间信息，如何设计自监督任务来学习脑网络模式并提升下游解码性能，特别是处理高度复杂的跨空间尺度时空交互。

Method: 提出新的时空Transformer模型和对应的自监督掩码潜在重建任务，支持在token编码和掩码时灵活选择空间尺度。在公开的多区域颅内脑电数据上应用，调整空间尺度进行实验。

Result: 1) 调整token编码和掩码重建的空间尺度显著影响下游解码性能；2) 比现有iEEG Transformer模型常用的通道级编码更大的空间尺度编码能提升下游解码性能；3) 方法支持区域级token编码同时保持准确的通道级神经重建。

Conclusion: 该建模框架能探索token编码和掩码的空间尺度，揭示了这些因素对多区域人脑活动神经基础模型自监督预训练的重要性，并提升了下游解码性能。

Abstract: Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.

</details>


### [122] [HydroDiffusion: Diffusion-Based Probabilistic Streamflow Forecasting with a State Space Backbone](https://arxiv.org/abs/2512.12183)
*Yihan Wang,Annan Yu,Lujun Zhang,Charuleka Varadharajan,N. Benjamin Erichson*

Main category: cs.LG

TL;DR: HydroDiffusion：基于扩散模型和状态空间模型的水文概率预报框架，通过联合去噪多日轨迹提升时间一致性，在CAMELS数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的径流预报方法使用LSTM骨干网络和单步训练目标，难以捕捉长期依赖关系，且无法保证不同预见期之间的预报轨迹一致性，存在误差累积问题

Method: 提出HydroDiffusion框架，采用仅解码器的状态空间模型作为骨干网络，通过单次前向传播联合去噪完整多日预报轨迹，确保时间一致性并减少自回归预测中的误差累积

Result: 在美国CAMELS数据集的531个流域上评估，HydroDiffusion在观测气象驱动下具有强实时预报精度，在整个模拟时段保持稳定性能，在确定性预报和概率预报技能上均优于DRUM模型

Conclusion: HydroDiffusion为中长期径流预报提供了稳健的生成建模框架，既建立了新的建模基准，也为未来在大陆尺度上进行概率水文预报研究奠定了基础

Abstract: Recent advances have introduced diffusion models for probabilistic streamflow forecasting, demonstrating strong early flood-warning skill. However, current implementations rely on recurrent Long Short-Term Memory (LSTM) backbones and single-step training objectives, which limit their ability to capture long-range dependencies and produce coherent forecast trajectories across lead times. To address these limitations, we developed HydroDiffusion, a diffusion-based probabilistic forecasting framework with a decoder-only state space model backbone. The proposed framework jointly denoises full multi-day trajectories in a single pass, ensuring temporal coherence and mitigating error accumulation common in autoregressive prediction. HydroDiffusion is evaluated across 531 watersheds in the contiguous United States (CONUS) in the CAMELS dataset. We benchmark HydroDiffusion against two diffusion baselines with LSTM backbones, as well as the recently proposed Diffusion-based Runoff Model (DRUM). Results show that HydroDiffusion achieves strong nowcast accuracy when driven by observed meteorological forcings, and maintains consistent performance across the full simulation horizon. Moreover, HydroDiffusion delivers stronger deterministic and probabilistic forecast skill than DRUM in operational forecasting. These results establish HydroDiffusion as a robust generative modeling framework for medium-range streamflow forecasting, providing both a new modeling benchmark and a foundation for future research on probabilistic hydrologic prediction at continental scales.

</details>


### [123] [MolGuidance: Advanced Guidance Strategies for Conditional Molecular Generation with Flow Matching](https://arxiv.org/abs/2512.12198)
*Jirui Jin,Cheng Zeng,Pawan Prakash,Ellad B. Tadmor,Adrian Roitberg,Richard G. Hennig,Stefano Martiniani,Mingjie Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种混合引导策略，将计算机视觉中的先进引导方法（如无分类器引导、自动引导和模型引导）整合到SE(3)-等变流匹配的分子生成框架中，通过贝叶斯优化联合优化连续和离散模态的引导尺度，在QM9和QMe14S数据集上实现了属性对齐的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 条件分子生成的关键目标包括确保化学有效性、使生成分子与目标属性对齐、促进结构多样性以及实现高效采样。计算机视觉领域最近引入了一系列新的生成模型引导策略，其中许多可以适应分子生成任务以支持这些目标。

Method: 1. 将最先进的引导方法（无分类器引导、自动引导、模型引导）整合到基于SE(3)-等变流匹配的分子生成框架中；2. 提出混合引导策略，分别引导连续和离散分子模态（分别作用于速度场和预测logits）；3. 通过贝叶斯优化联合优化它们的引导尺度。

Result: 在QM9和QMe14S数据集上实现了从头分子生成的属性对齐新SOTA性能，生成的分子表现出高结构有效性，并系统比较了各种引导方法的优缺点。

Conclusion: 该混合引导策略有效提升了条件分子生成的性能，为各种引导方法的更广泛应用提供了见解，实现了化学有效性、属性对齐和结构多样性的平衡。

Abstract: Key objectives in conditional molecular generation include ensuring chemical validity, aligning generated molecules with target properties, promoting structural diversity, and enabling efficient sampling for discovery. Recent advances in computer vision introduced a range of new guidance strategies for generative models, many of which can be adapted to support these goals. In this work, we integrate state-of-the-art guidance methods -- including classifier-free guidance, autoguidance, and model guidance -- in a leading molecule generation framework built on an SE(3)-equivariant flow matching process. We propose a hybrid guidance strategy that separately guides continuous and discrete molecular modalities -- operating on velocity fields and predicted logits, respectively -- while jointly optimizing their guidance scales via Bayesian optimization. Our implementation, benchmarked on the QM9 and QMe14S datasets, achieves new state-of-the-art performance in property alignment for de novo molecular generation. The generated molecules also exhibit high structural validity. Furthermore, we systematically compare the strengths and limitations of various guidance methods, offering insights into their broader applicability.

</details>


### [124] [EEG-DLite: Dataset Distillation for Efficient Large EEG Model Training](https://arxiv.org/abs/2512.12210)
*Yuting Tang,Weibang Jiang,Shanglin Li,Yong Li,Chenyu Liu,Xinliang Zhou,Yi Ding,Cuntai Guan*

Main category: cs.LG

TL;DR: EEG-DLite：通过数据蒸馏框架，从大规模EEG数据集中选择性去除噪声和冗余样本，仅用5%数据即可达到与全数据集相当的性能，显著提升EEG基础模型训练效率。


<details>
  <summary>Details</summary>
Motivation: 大规模EEG基础模型训练需要大量计算资源，但EEG数据存在噪声和冗余问题。现有方法训练效率低下，需要更有效的数据选择方法来降低训练成本。

Method: 提出EEG-DLite数据蒸馏框架：1）使用自监督自动编码器将EEG片段编码为紧凑的潜在表示；2）基于这些表示过滤异常值并最小化冗余；3）生成保留多样性的小型但信息丰富的子集。

Result: 在2500小时数据集中，仅使用EEG-DLite筛选的5%数据进行训练，在多个下游任务上达到与全数据集相当甚至更好的性能，显著降低训练成本。

Conclusion: EEG-DLite为EEG基础模型训练提供了可扩展且实用的数据蒸馏方法，首次系统研究了EEG基础模型预训练中的数据蒸馏问题，为更高效的生理基础建模开辟了新途径。

Abstract: Large-scale EEG foundation models have shown strong generalization across a range of downstream tasks, but their training remains resource-intensive due to the volume and variable quality of EEG data. In this work, we introduce EEG-DLite, a data distillation framework that enables more efficient pre-training by selectively removing noisy and redundant samples from large EEG datasets. EEG-DLite begins by encoding EEG segments into compact latent representations using a self-supervised autoencoder, allowing sample selection to be performed efficiently and with reduced sensitivity to noise. Based on these representations, EEG-DLite filters out outliers and minimizes redundancy, resulting in a smaller yet informative subset that retains the diversity essential for effective foundation model training. Through extensive experiments, we demonstrate that training on only 5 percent of a 2,500-hour dataset curated with EEG-DLite yields performance comparable to, and in some cases better than, training on the full dataset across multiple downstream tasks. To our knowledge, this is the first systematic study of pre-training data distillation in the context of EEG foundation models. EEG-DLite provides a scalable and practical path toward more effective and efficient physiological foundation modeling. The code is available at https://github.com/t170815518/EEG-DLite.

</details>


### [125] [Optimized Learned Count-Min Sketch](https://arxiv.org/abs/2512.12252)
*Kyosuke Nishishita,Atsuki Sato,Yusuke Matsui*

Main category: cs.LG

TL;DR: OptLCMS 改进了学习型 Count-Min Sketch，通过分区和动态规划优化参数，提供理论保证并加快构建速度


<details>
  <summary>Details</summary>
Motivation: 学习型 Count-Min Sketch (LCMS) 虽然通过机器学习模型减少了估计误差，但存在构建速度慢（需要经验参数调优）和缺乏理论保证的问题

Method: 将输入域分区并为每个分区分配独立的 CMS 实例，通过分析推导 CMS 参数，使用动态规划和近似可行性检查优化阈值

Result: OptLCMS 构建更快，实现了更低的不可容忍错误概率，同时保持了与 LCMS 相当的估计精度

Conclusion: OptLCMS 在保持学习型 CMS 优点的同时，解决了构建速度慢和缺乏理论保证的问题，提供了更好的灵活性和性能

Abstract: Count-Min Sketch (CMS) is a memory-efficient data structure for estimating the frequency of elements in a multiset. Learned Count-Min Sketch (LCMS) enhances CMS with a machine learning model to reduce estimation error under the same memory usage, but suffers from slow construction due to empirical parameter tuning and lacks theoretical guarantees on intolerable error probability. We propose Optimized Learned Count-Min Sketch (OptLCMS), which partitions the input domain and assigns each partition to its own CMS instance, with CMS parameters analytically derived for fixed thresholds, and thresholds optimized via dynamic programming with approximate feasibility checks. This reduces the need for empirical validation, enabling faster construction while providing theoretical guarantees under these assumptions. OptLCMS also allows explicit control of the allowable error threshold, improving flexibility in practice. Experiments show that OptLCMS builds faster, achieves lower intolerable error probability, and matches the estimation accuracy of LCMS.

</details>


### [126] [GRC-Net: Gram Residual Co-attention Net for epilepsy prediction](https://arxiv.org/abs/2512.12273)
*Bihao You,Jiping Cui*

Main category: cs.LG

TL;DR: 提出GRC-Net模型，使用Gram Matrix将EEG信号转换为3D表示，结合多级特征提取（共注意力机制和Inception结构）处理局部与全局信号不平衡问题，在BONN数据集五分类任务上达到93.66%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法对EEG信号进行1D处理无法充分建模信号间关系，且EEG数据中存在局部与全局信号不平衡问题，需要更有效的特征提取方法。

Method: 1. 使用Gram Matrix将1D EEG信号转换为3D表示，保持时间依赖性；2. 引入多级特征提取：共注意力机制捕获全局特征，Inception结构处理局部信号；3. 构建GRC-Net模型进行癫痫预测。

Result: 在BONN数据集上，GRC-Net在最具挑战性的五分类任务中达到93.66%的准确率，优于现有方法。

Conclusion: 提出的3D表示和多级特征提取方法能有效处理EEG信号中的局部-全局不平衡问题，显著提升癫痫预测性能。

Abstract: Prediction of epilepsy based on electroencephalogram (EEG) signals is a rapidly evolving field. Previous studies have traditionally applied 1D processing to the entire EEG signal. However, we have adopted the Gram Matrix method to transform the signals into a 3D representation, enabling modeling of signal relationships across dimensions while preserving the temporal dependencies of the one-dimensional signals. Additionally, we observed an imbalance between local and global signals within the EEG data. Therefore, we introduced multi-level feature extraction, utilizing coattention for capturing global signal characteristics and an inception structure for processing local signals, achieving multi-granular feature extraction. Our experiments on the BONN dataset demonstrate that for the most challenging five-class classification task, GRC-Net achieved an accuracy of 93.66%, outperforming existing methods.

</details>


### [127] [Balancing Accuracy and Speed: A Multi-Fidelity Ensemble Kalman Filter with a Machine Learning Surrogate Model](https://arxiv.org/abs/2512.12276)
*Jeffrey van der Voort,Martin Verlaan,Hanne Kekkonen*

Main category: cs.LG

TL;DR: 该研究提出使用多保真度集合卡尔曼滤波（MF-EnKF），其中低保真度模型采用机器学习代理模型而非传统低分辨率模型，通过少量昂贵全模型运行与大量廉价ML模型运行的组合，在相同计算预算下提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习代理模型在计算昂贵的物理模型中应用增多，研究者希望利用少量昂贵全模型运行与大量廉价ML模型运行的组合，在相同计算预算下提高预测精度，特别是在气象学和海洋学等领域。

Method: 采用多保真度集合卡尔曼滤波（MF-EnKF），其中低保真度模型为机器学习代理模型，而非传统的低分辨率或降阶模型。通过少量昂贵全模型运行与大量廉价ML模型运行的组合进行测试。

Result: 在Lorenz-2005模型和准地转模型测试中，MF-EnKF在相同计算预算下达到更高精度。ML代理模型相比低分辨率模型具有相似或更好精度，且能提供更大加速比。保留原始物理模型比完全替换为ML模型获得更高精度。

Conclusion: 该方法通过增加EnKF中的有效集合大小，改善了初始条件估计和预测精度，对气象学和海洋学等领域有重要贡献。ML代理模型在计算加速方面优于传统低分辨率模型。

Abstract: Currently, more and more machine learning (ML) surrogates are being developed for computationally expensive physical models. In this work we investigate the use of a Multi-Fidelity Ensemble Kalman Filter (MF-EnKF) in which the low-fidelity model is such a machine learning surrogate model, instead of a traditional low-resolution or reduced-order model. The idea behind this is to use an ensemble of a few expensive full model runs, together with an ensemble of many cheap but less accurate ML model runs. In this way we hope to reach increased accuracy within the same computational budget. We investigate the performance by testing the approach on two common test problems, namely the Lorenz-2005 model and the Quasi-Geostrophic model. By keeping the original physical model in place, we obtain a higher accuracy than when we completely replace it by the ML model. Furthermore, the MF-EnKF reaches improved accuracy within the same computational budget. The ML surrogate has similar or improved accuracy compared to the low-resolution one, but it can provide a larger speed-up. Our method contributes to increasing the effective ensemble size in the EnKF, which improves the estimation of the initial condition and hence accuracy of the predictions in fields such as meteorology and oceanography.

</details>


### [128] [Fractional Differential Equation Physics-Informed Neural Network and Its Application in Battery State Estimation](https://arxiv.org/abs/2512.12285)
*Lujuan Dang,Zilai Wang*

Main category: cs.LG

TL;DR: 提出FDIFF-PINN方法，结合分数阶微积分与深度学习，用于锂离子电池SOC估计，提高预测精度和物理可解释性


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的神经网络模型难以充分表征电化学过程的复杂非线性和记忆依赖动态特性，限制了SOC估计在动态工况下的预测精度和物理可解释性

Method: 提出分数阶微分方程物理信息神经网络(FDIFF-PINN)，基于分数阶等效电路模型构建离散化分数阶偏微分方程，结合分数阶微积分与深度学习

Result: 使用Panasonic 18650PF电池在-10°C到20°C多温度条件下的动态充放电数据集进行对比实验验证

Conclusion: FDIFF-PINN方法能够更好地表征电池电化学过程的复杂动态特性，提高SOC估计的精度和物理可解释性

Abstract: Accurate estimation of the State of Charge (SOC) is critical for ensuring the safety, reliability, and performance optimization of lithium-ion battery systems. Conventional data-driven neural network models often struggle to fully characterize the inherent complex nonlinearities and memory-dependent dynamics of electrochemical processes, significantly limiting their predictive accuracy and physical interpretability under dynamic operating conditions. To address this challenge, this study proposes a novel neural architecture termed the Fractional Differential Equation Physics-Informed Neural Network (FDIFF-PINN), which integrates fractional calculus with deep learning. The main contributions of this paper include: (1) Based on a fractional-order equivalent circuit model, a discretized fractional-order partial differential equation is constructed. (2) Comparative experiments were conducted using a dynamic charge/discharge dataset of Panasonic 18650PF batteries under multi-temperature conditions (from -10$^{\circ}$C to 20$^{\circ}$C).

</details>


### [129] [TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting](https://arxiv.org/abs/2512.12301)
*Mahima Kumavat,Aditya Maheshwari*

Main category: cs.LG

TL;DR: TwinFormer是一种用于长序列时间序列预测的分层Transformer，通过局部和全局信息提取器结合稀疏注意力机制，在多个真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决长序列时间序列预测中传统Transformer计算复杂度高（O(L²d)）的问题，同时需要有效捕捉局部动态和长期依赖关系。

Method: 1. 将输入分割为非重叠时间片段；2. 局部信息提取器使用top-k稀疏注意力建模片段内动态，后进行均值池化；3. 全局信息提取器使用相同top-k注意力捕捉片段间长期依赖；4. 轻量级GRU聚合全局上下文化的片段标记进行多步预测。

Result: 在8个真实世界数据集（天气、股价、温度、电力消耗、电力、疾病等）上，预测范围96-720步，TwinFormer在34个评估中27次进入前两名，其中17次MAE和RMSE最佳，10次次佳。计算复杂度降至线性O(kLd)。

Conclusion: TwinFormer通过分层结构和top-k稀疏注意力机制，在保持线性复杂度的同时，在长序列时间序列预测任务上显著优于现有方法，证明了其架构设计的有效性。

Abstract: TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is available at this repository: https://github.com/Mahimakumavat1205/TwinFormer.

</details>


### [130] [Eventually LIL Regret: Almost Sure $\ln\ln T$ Regret for a sub-Gaussian Mixture on Unbounded Data](https://arxiv.org/abs/2512.12325)
*Shubhada Agrawal,Aaditya Ramdas*

Main category: cs.LG

TL;DR: 该论文证明Robbins提出的经典次高斯混合模型满足路径式确定性遗憾界，在Ville事件中遗憾界与累积方差过程相关，连接了对抗性在线学习和博弈论统计。


<details>
  <summary>Details</summary>
Motivation: 连接对抗性在线学习（通常处理有界数据的遗憾界）和博弈论统计（可以处理无界数据但需要随机性假设）两个领域，通过条件遗憾界作为桥梁。

Method: 使用Robbins的经典次高斯混合模型，在Ville事件中分析路径式确定性遗憾界，证明其与累积方差过程V_T的关系。

Result: 证明在Ville事件E_α中，遗憾界为ln²(1/α)/V_T + ln(1/α) + ln ln V_T（到常数因子）；在E_0中，遗憾最终有界于ln ln V_T；当数据随机时，E_α至少有1-α概率成立。

Conclusion: 条件遗憾界作为随机和对抗性投注之间的桥梁，使得在更广泛的分布类别（次高斯、对称、方差有界等）下都能获得有意义的遗憾界。

Abstract: We prove that a classic sub-Gaussian mixture proposed by Robbins in a stochastic setting actually satisfies a path-wise (deterministic) regret bound. For every path in a natural ``Ville event'' $E_α$, this regret till time $T$ is bounded by $\ln^2(1/α)/V_T + \ln (1/α) + \ln \ln V_T$ up to universal constants, where $V_T$ is a nonnegative, nondecreasing, cumulative variance process. (The bound reduces to $\ln(1/α) + \ln \ln V_T$ if $V_T \geq \ln(1/α)$.) If the data were stochastic, then one can show that $E_α$ has probability at least $1-α$ under a wide class of distributions (eg: sub-Gaussian, symmetric, variance-bounded, etc.). In fact, we show that on the Ville event $E_0$ of probability one, the regret on every path in $E_0$ is eventually bounded by $\ln \ln V_T$ (up to constants). We explain how this work helps bridge the world of adversarial online learning (which usually deals with regret bounds for bounded data), with game-theoretic statistics (which can handle unbounded data, albeit using stochastic assumptions). In short, conditional regret bounds serve as a bridge between stochastic and adversarial betting.

</details>


### [131] [Uncertainty Quantification for Machine Learning: One Size Does Not Fit All](https://arxiv.org/abs/2512.12341)
*Paul Hofman,Yusuf Sale,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 论文认为不存在单一最佳的不确定性度量方法，应根据具体应用场景定制化选择，并提出了基于二阶分布的灵活不确定性度量框架


<details>
  <summary>Details</summary>
Motivation: 机器学习在安全关键应用中需要准确的不确定性量化，现有方法通常声称自己优于其他方法，但作者认为不存在单一最佳度量，应根据具体应用定制化设计

Method: 提出灵活的不确定性度量框架，区分二阶分布的总不确定性、偶然不确定性和认知不确定性，使用适当的评分规则（proper scoring rules）来控制度量特性

Result: 不同任务需要不同的不确定性度量特性：选择性预测任务中评分规则应与任务损失匹配；分布外检测中互信息表现最佳；主动学习中基于0-1损失的认知不确定性持续优于其他方法

Conclusion: 不确定性量化应根据具体应用需求定制化设计，不存在通用的最佳度量方法，提出的灵活框架能够适应不同任务的需求

Abstract: Proper quantification of predictive uncertainty is essential for the use of machine learning in safety-critical applications. Various uncertainty measures have been proposed for this purpose, typically claiming superiority over other measures. In this paper, we argue that there is no single best measure. Instead, uncertainty quantification should be tailored to the specific application. To this end, we use a flexible family of uncertainty measures that distinguishes between total, aleatoric, and epistemic uncertainty of second-order distributions. These measures can be instantiated with specific loss functions, so-called proper scoring rules, to control their characteristics, and we show that different characteristics are useful for different tasks. In particular, we show that, for the task of selective prediction, the scoring rule should ideally match the task loss. On the other hand, for out-of-distribution detection, our results confirm that mutual information, a widely used measure of epistemic uncertainty, performs best. Furthermore, in an active learning setting, epistemic uncertainty based on zero-one loss is shown to consistently outperform other uncertainty measures.

</details>


### [132] [Synthetic Swarm Mosquito Dataset for Acoustic Classification: A Proof of Concept](https://arxiv.org/abs/2512.12365)
*Thai-Duy Dinh,Minh-Luan Vo,Cuong Tuan Nguyen,Bich-Hien Vo*

Main category: cs.LG

TL;DR: 提出合成蚊群声学分类数据集，用于多物种嘈杂环境下的蚊子识别，评估轻量级深度学习模型在嵌入式设备上的部署潜力。


<details>
  <summary>Details</summary>
Motivation: 蚊媒疾病每年造成超过70万人死亡，构成严重全球健康威胁。传统数据集需要人工录制单个蚊子声音，工作量大且难以扩展。

Method: 创建合成蚊群声学分类数据集，模拟真实多物种和嘈杂蚊群环境。使用log-mel频谱图，评估轻量级深度学习架构对蚊子物种的分类能力。

Result: 实验表明，这些模型能有效识别六种主要蚊媒物种，适合在嵌入式低功耗设备上部署。

Conclusion: 合成蚊群音频数据集有潜力加速声学蚊子研究，实现可扩展的实时监测解决方案。

Abstract: Mosquito-borne diseases pose a serious global health threat, causing over 700,000 deaths annually. This work introduces a proof-of-concept Synthetic Swarm Mosquito Dataset for Acoustic Classification, created to simulate realistic multi-species and noisy swarm conditions. Unlike conventional datasets that require labor-intensive recording of individual mosquitoes, the synthetic approach enables scalable data generation while reducing human resource demands. Using log-mel spectrograms, we evaluated lightweight deep learning architectures for the classification of mosquito species. Experiments show that these models can effectively identify six major mosquito vectors and are suitable for deployment on embedded low-power devices. The study demonstrates the potential of synthetic swarm audio datasets to accelerate acoustic mosquito research and enable scalable real-time surveillance solutions.

</details>


### [133] [The Data Efficiency Frontier of Financial Foundation Models: Scaling Laws from Continued Pretraining](https://arxiv.org/abs/2512.12384)
*Jesse Ponnock*

Main category: cs.LG

TL;DR: 对1B和3B参数的Llama-3.2模型在400M金融语料上进行领域自适应预训练，发现前200M token带来最大收益，金融语言高度规律且可高效学习，通用领域性能保持稳定。


<details>
  <summary>Details</summary>
Motivation: 领域自适应预训练（DAPT）为大型语言模型专业化提供实用路径，无需完全重新训练。研究旨在探索金融领域（SEC文件）的早期扩展规律，为金融基础模型提供实证指导。

Method: 使用1B和3B参数的Llama-3.2模型，在400M token的金融语料库（SEC文件）上进行持续预训练，在50M、100M、200M和400M token处设置验证检查点，分析扩展规律。

Result: SEC领域验证损失持续改善，最大收益出现在前200M token，之后收益递减；幂律拟合显示浅指数，表明金融语言高度规律；通用领域损失基本不变，无灾难性遗忘迹象；数据效率前沿显示模型专业化改善而混合领域退化可忽略。

Conclusion: 相对适中的token预算即可实现有意义的领域自适应，金融语言高效可学；更大规模模型（7B-70B）在预计数据需求下仍然可行；为金融基础模型的扩展提供早期实证指导。

Abstract: Domain-adaptive pretraining (DAPT) offers a practical path to specializing large language models for high-value domains without full retraining. We conduct an early-stage scaling-law analysis of continued pretraining on U.S. SEC filings, training 1B and 3B-parameter Llama-3.2 models on a 400M-token financial corpus with validation checkpoints at 50M, 100M, 200M, and 400M tokens. Results show consistent improvements in SEC-domain validation loss for both models, with the largest gains occurring within the first 200M tokens and diminishing returns thereafter. Power-law fits reveal shallow exponents, indicating that financial language is highly regular and efficiently learnable under continued pretraining. General-domain validation loss remains effectively unchanged across all token budgets, suggesting minimal drift and no signs of catastrophic forgetting. A data-efficiency frontier further shows that both models move toward improved specialization with negligible mixed-domain degradation. Together, these findings provide early empirical guidance for scaling financial foundation models, suggesting that meaningful domain adaptation can be achieved with comparatively modest token budgets and that larger model scales (7B-70B) remain tractable under projected data requirements.

</details>


### [134] [Anchoring Values in Temporal and Group Dimensions for Flow Matching Model Alignment](https://arxiv.org/abs/2512.12387)
*Yawen Shao,Jie Xiao,Kai Zhu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.LG

TL;DR: VGPO提出了一种新的强化学习框架，通过时间维度和群体维度的价值锚定，解决了GRPO在图像生成中的两个关键限制：时间信用分配问题和优化停滞问题。


<details>
  <summary>Details</summary>
Motivation: 当前GRPO在基于流匹配的图像生成中存在两个根本性冲突：1）稀疏终端奖励在所有时间步的均匀应用损害了时间信用分配，忽略了从早期结构形成到后期调优的不同关键阶段；2）仅依赖相对群体奖励导致训练收敛时优化信号衰减，当奖励多样性耗尽时出现优化停滞。

Method: VGPO框架在时间和群体维度重新定义价值估计：1）将稀疏终端奖励转化为密集的、过程感知的价值估计，通过建模每个生成阶段的预期累积奖励实现精确信用分配；2）用绝对价值增强的过程替代标准群体归一化，即使在奖励多样性下降时也能保持稳定的优化信号。

Result: 在三个基准测试上的广泛实验表明，VGPO实现了最先进的图像质量，同时提高了任务特定准确性，有效缓解了奖励黑客问题。

Conclusion: VGPO通过解决GRPO在图像生成中的时间信用分配和优化停滞问题，为基于强化学习的视觉合成提供了更有效的优化框架。

Abstract: Group Relative Policy Optimization (GRPO) has proven highly effective in enhancing the alignment capabilities of Large Language Models (LLMs). However, current adaptations of GRPO for the flow matching-based image generation neglect a foundational conflict between its core principles and the distinct dynamics of the visual synthesis process. This mismatch leads to two key limitations: (i) Uniformly applying a sparse terminal reward across all timesteps impairs temporal credit assignment, ignoring the differing criticality of generation phases from early structure formation to late-stage tuning. (ii) Exclusive reliance on relative, intra-group rewards causes the optimization signal to fade as training converges, leading to the optimization stagnation when reward diversity is entirely depleted. To address these limitations, we propose Value-Anchored Group Policy Optimization (VGPO), a framework that redefines value estimation across both temporal and group dimensions. Specifically, VGPO transforms the sparse terminal reward into dense, process-aware value estimates, enabling precise credit assignment by modeling the expected cumulative reward at each generative stage. Furthermore, VGPO replaces standard group normalization with a novel process enhanced by absolute values to maintain a stable optimization signal even as reward diversity declines. Extensive experiments on three benchmarks demonstrate that VGPO achieves state-of-the-art image quality while simultaneously improving task-specific accuracy, effectively mitigating reward hacking. Project webpage: https://yawen-shao.github.io/VGPO/.

</details>


### [135] [DeepVekua: Geometric-Spectral Representation Learning for Physics-Informed Fields](https://arxiv.org/abs/2512.12402)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: DeepVekua是一种结合几何深度学习和谱分析的混合架构，用于解决稀疏数据条件下的偏微分方程，通过将复杂几何映射到潜在调和空间，在平流扩散系统上超越了现有隐式表示方法。


<details>
  <summary>Details</summary>
Motivation: 标准基于坐标的网络在处理谱偏差方面存在困难，特别是在稀疏数据条件下求解偏微分方程时表现不佳。需要一种能够将几何学习与物理学习分离的方法，以提高求解效率和精度。

Method: 提出混合架构，学习一个微分同胚坐标变换，将复杂几何映射到潜在调和空间。该方法将几何学习与物理学习分离，通过闭式求解最优谱权重，避免了传统方法的谱偏差问题。

Result: 在平流扩散系统上超越了最先进的隐式表示方法，相比谱基线方法实现了100倍的改进。代码已在GitHub上开源。

Conclusion: DeepVekua通过将几何学习与物理学习分离，有效解决了稀疏数据条件下偏微分方程的求解问题，为复杂几何上的物理模拟提供了高效准确的解决方案。

Abstract: We present DeepVekua, a hybrid architecture that unifies geometric deep learning with spectral analysis to solve partial differential equations (PDEs) in sparse data regimes. By learning a diffeomorphic coordinate transformation that maps complex geometries to a latent harmonic space, our method outperforms state-of-the-art implicit representations on advection-diffusion systems. Unlike standard coordinate-based networks which struggle with spectral bias, DeepVekua separates the learning of geometry from the learning of physics, solving for optimal spectral weights in closed form. We demonstrate a 100x improvement over spectral baselines. The code is available at https://github.com/VladimerKhasia/vekuanet.

</details>


### [136] [Can Graphs Improve Tabular Foundation Models?](https://arxiv.org/abs/2512.12405)
*Franck Le,Keith Grueneberg,Erich Nahum,Vadim Sheinin*

Main category: cs.LG

TL;DR: BOLERO通过添加轻量级静态二分图头来增强预训练表格Transformer，利用简单的图先验建模实例间关系，在分类和回归任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有表格Transformer和上下文学习方法（如SAINT、TP-BERTa、TabPFN等）缺乏显式建模实例间关系的机制，而相似样本通常具有相关结果。研究是否可以通过引入简单的图先验来增强预训练表格Transformer的性能。

Method: 提出BOLERO方法：在冻结的RoBERTa-Tab骨干网络上添加轻量级静态二分图头，每个实例连接到特征/值锚点，通过小型GNN细化行表示，保持骨干网络不变。

Result: 在TP-BERTa基准套件的80个分类和64个回归数据集上评估，与XGBoost、CatBoost、TabPFN-v2、MITRA、TabICL、TP-BERTa、RoBERTa-Tab等强基线比较。BOLERO在分类和回归任务上都获得了最多的统计显著胜出次数。

Conclusion: 轻量级图先验能够有意义地改进预训练表格Transformer，证明了简单图结构在增强表格数据建模中的有效性。

Abstract: Tabular data are central to many real-world systems. While recent tabular transformers and in-context learners such as SAINT, TP-BERTa, TabPFN, TabICL, and MITRA incorporate limited inter-row reasoning, most approaches still lack an explicit mechanism to model relationships among instances, even though similar samples often share related outcomes. We investigate whether introducing \emph{simple graph priors} can enhance \emph{pretrained tabular transformers}. Concretely, we introduce {BOLERO}, a lightweight, static bipartite graph head that augments {RoBERTa-Tab} (a RoBERTa-style tabular backbone pretrained with masked-token prediction.) Each instance connects to feature/value anchors; a small GNN refines row representations, while the backbone remains frozen. We evaluate on 80 classification and 64 regression datasets from the TP-BERTa benchmark suites, comparing against strong baselines including XGBoost, CatBoost, TabPFN-v2, MITRA, TabICL, TP-BERTa, and RoBERTa-Tab. To ensure statistically sound conclusions, we follow best practices for multi-dataset evaluation: pairwise Wilcoxon signed-rank tests on per-dataset score differences and effect sizes (median improvement with confidence intervals), rather than mean-rank post-hoc tests that depend on the competitor pool. BOLERO achieves the highest number of statistically significant wins across both classification and regression, demonstrating that lightweight graph priors meaningfully improve pretrained tabular transformers.

</details>


### [137] [Learning Dynamics in Memristor-Based Equilibrium Propagation](https://arxiv.org/abs/2512.12428)
*Michael Döll,Andreas Müller,Bernd Ulmann*

Main category: cs.LG

TL;DR: 研究探索了基于忆阻器的非线性权重更新对平衡传播训练神经网络收敛行为的影响，发现只要忆阻器具有足够宽的电阻范围（至少一个数量级），平衡传播就能实现稳健收敛。


<details>
  <summary>Details</summary>
Motivation: 忆阻器内存计算已成为克服冯·诺依曼瓶颈和内存墙的有前景范式，但需要研究非线性忆阻器权重更新对神经网络训练收敛行为的影响。

Method: 将六种忆阻器模型（通过电压-电流磁滞特性表征）集成到EBANA框架中，在两个基准分类任务上评估平衡传播训练方法。

Result: 平衡传播能够在非线性权重更新下实现稳健收敛，前提是忆阻器表现出足够宽的电阻范围（至少一个数量级）。

Conclusion: 忆阻器基内存计算与平衡传播训练方法兼容，为开发高效神经形态计算系统提供了重要见解。

Abstract: Memristor-based in-memory computing has emerged as a promising paradigm to overcome the constraints of the von Neumann bottleneck and the memory wall by enabling fully parallelisable and energy-efficient vector-matrix multiplications. We investigate the effect of nonlinear, memristor-driven weight updates on the convergence behaviour of neural networks trained with equilibrium propagation (EqProp). Six memristor models were characterised by their voltage-current hysteresis and integrated into the EBANA framework for evaluation on two benchmark classification tasks. EqProp can achieve robust convergence under nonlinear weight updates, provided that memristors exhibit a sufficiently wide resistance range of at least an order of magnitude.

</details>


### [138] [Rough Sets for Explainability of Spectral Graph Clustering](https://arxiv.org/abs/2512.12436)
*Bartłomiej Starosta,Sławomir T. Wierzchoń,Piotr Borkowski,Dariusz Czerski,Marcin Sydow,Eryk Laskowski,Mieczysław A. Kłopotek*

Main category: cs.LG

TL;DR: 本文提出了一种基于粗糙集理论的增强解释方法，用于改进图谱聚类在文本文档上的可解释性


<details>
  <summary>Details</summary>
Motivation: 图谱聚类方法能够处理各种形状和密度的簇，但在应用于文本文档时难以解释，主要原因是谱空间嵌入与文档内容没有明显关系，加上文档内容不清晰和聚类算法的随机性进一步降低了可解释性

Method: 提出了一种增强的解释方法，借鉴粗糙集理论的思想，克服了之前研究中存在的问题

Result: 该方法能够更好地解释图谱聚类结果，特别是在处理内容不明确的文档和随机性影响时表现更优

Conclusion: 通过引入粗糙集理论，显著提升了图谱聚类在文本文档分析中的可解释性，解决了谱空间嵌入难以解释的问题

Abstract: Graph Spectral Clustering methods (GSC) allow representing clusters of diverse shapes, densities, etc. However, the results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Furthermore, the presence of documents without clear content meaning and the stochastic nature of the clustering algorithms deteriorate explainability. This paper proposes an enhancement to the explanation methodology, proposed in an earlier research of our team. It allows us to overcome the latter problems by taking inspiration from rough set theory.

</details>


### [139] [Knowledge-Guided Masked Autoencoder with Linear Spectral Mixing and Spectral-Angle-Aware Reconstruction](https://arxiv.org/abs/2512.12445)
*Abdul Matin,Rupasree Dey,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.LG

TL;DR: 提出了一种结合领域知识的ViT掩码自编码器，通过线性光谱混合模型和光谱角度匹配器作为物理约束，提升自监督学习的重建质量和可解释性。


<details>
  <summary>Details</summary>
Motivation: 将领域知识融入深度学习可以提升模型的可解释性、泛化能力和数据效率。当前自监督学习主要依赖数据驱动优化，缺乏对已知物理结构和关系的约束。

Method: 提出知识引导的ViT掩码自编码器，将线性光谱混合模型（LSMM）作为物理约束，结合基于物理的光谱角度匹配器（SAM），与传统的Huber损失联合优化，确保学习到的表征符合观测信号与潜在成分之间的已知结构关系。

Result: 实验结果表明，该模型显著提升了重建质量，改善了下游任务性能，在有限监督下稳定了训练，并产生了基于物理原理的可解释潜在表征。

Conclusion: 将物理信息归纳偏置嵌入基于Transformer的自监督学习具有重要前景，能够增强重建保真度，稳定训练过程，并产生可解释的物理基础表征。

Abstract: Integrating domain knowledge into deep learning has emerged as a promising direction for improving model interpretability, generalization, and data efficiency. In this work, we present a novel knowledge-guided ViT-based Masked Autoencoder that embeds scientific domain knowledge within the self-supervised reconstruction process. Instead of relying solely on data-driven optimization, our proposed approach incorporates the Linear Spectral Mixing Model (LSMM) as a physical constraint and physically-based Spectral Angle Mapper (SAM), ensuring that learned representations adhere to known structural relationships between observed signals and their latent components. The framework jointly optimizes LSMM and SAM loss with a conventional Huber loss objective, promoting both numerical accuracy and geometric consistency in the feature space. This knowledge-guided design enhances reconstruction fidelity, stabilizes training under limited supervision, and yields interpretable latent representations grounded in physical principles. The experimental findings indicate that the proposed model substantially enhances reconstruction quality and improves downstream task performance, highlighting the promise of embedding physics-informed inductive biases within transformer-based self-supervised learning.

</details>


### [140] [Optimized Architectures for Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.12448)
*James Bagrow,Josh Bongard*

Main category: cs.LG

TL;DR: 通过过参数化架构结合稀疏化学习紧凑、可解释的KANs，保持准确性同时提升可解释性


<details>
  <summary>Details</summary>
Motivation: 现有改进KANs的架构增强方法增加了复杂性，损害了KANs原本吸引人的可解释性。需要找到既能保持准确性又能提升可解释性的方法

Method: 采用过参数化架构结合可微分稀疏化技术，将架构搜索转化为端到端优化问题，学习紧凑、可解释的KANs

Result: 在函数逼近基准测试、动力系统预测和真实世界预测任务中，实现了竞争性或更优的准确性，同时发现了显著更小的模型。过参数化与稀疏化具有协同效应

Conclusion: 提供了一条原则性路径，使模型既更具表达能力又更可解释，解决了科学机器学习中的关键矛盾

Abstract: Efforts to improve Kolmogorov-Arnold networks (KANs) with architectural enhancements have been stymied by the complexity those enhancements bring, undermining the interpretability that makes KANs attractive in the first place. Here we study overprovisioned architectures combined with sparsification to learn compact, interpretable KANs without sacrificing accuracy. Crucially, we focus on differentiable sparsification, turning architecture search into an end-to-end optimization problem. Across function approximation benchmarks, dynamical systems forecasting, and real-world prediction tasks, we demonstrate competitive or superior accuracy while discovering substantially smaller models. Overprovisioning and sparsification are synergistic, with the combination outperforming either alone. The result is a principled path toward models that are both more expressive and more interpretable, addressing a key tension in scientific machine learning.

</details>


### [141] [Cross-Modal Representational Knowledge Distillation for Enhanced Spike-Informed LFP Modeling](https://arxiv.org/abs/2512.12461)
*Eray Erturk,Saba Hashemi,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出跨模态知识蒸馏框架，将预训练多会话尖峰Transformer模型的高保真表征知识迁移到LFP Transformer模型，提升LFP模型性能


<details>
  <summary>Details</summary>
Motivation: 尽管局部场电位(LFPs)具有长期稳定性好、对电极退化鲁棒性强、功耗低等优势，但现有神经建模框架主要关注尖峰活动，因为LFP信号具有聚合、群体层面的特性，导致对下游任务变量(如运动行为)的预测能力较低

Method: 1) 使用会话特定的神经标记化策略，通过掩码自编码目标在多会话上训练教师尖峰模型；2) 将学生LFP模型的潜在表征与教师尖峰模型对齐，实现跨模态知识蒸馏

Result: 蒸馏后的LFP模型在完全无监督和监督设置下均优于单会话和多会话LFP基线，能够泛化到其他会话而无需额外蒸馏，同时保持优越性能

Conclusion: 跨模态知识蒸馏是利用高性能尖峰模型开发更准确LFP模型的有效且可扩展方法

Abstract: Local field potentials (LFPs) can be routinely recorded alongside spiking activity in intracortical neural experiments, measure a larger complementary spatiotemporal scale of brain activity for scientific inquiry, and can offer practical advantages over spikes, including greater long-term stability, robustness to electrode degradation, and lower power requirements. Despite these advantages, recent neural modeling frameworks have largely focused on spiking activity since LFP signals pose inherent modeling challenges due to their aggregate, population-level nature, often leading to lower predictive power for downstream task variables such as motor behavior. To address this challenge, we introduce a cross-modal knowledge distillation framework that transfers high-fidelity representational knowledge from pretrained multi-session spike transformer models to LFP transformer models. Specifically, we first train a teacher spike model across multiple recording sessions using a masked autoencoding objective with a session-specific neural tokenization strategy. We then align the latent representations of the student LFP model to those of the teacher spike model. Our results show that the Distilled LFP models consistently outperform single- and multi-session LFP baselines in both fully unsupervised and supervised settings, and can generalize to other sessions without additional distillation while maintaining superior performance. These findings demonstrate that cross-modal knowledge distillation is a powerful and scalable approach for leveraging high-performing spike models to develop more accurate LFP models.

</details>


### [142] [Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference](https://arxiv.org/abs/2512.12462)
*Eray Erturk,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出一个实时递归解码框架，用于处理多模态神经时间序列数据的不同时间尺度、概率分布和缺失样本问题


<details>
  <summary>Details</summary>
Motivation: 现有非线性多模态神经活动模型无法处理不同时间尺度或缺失样本，且部分模型不支持实时解码，需要开发能实时处理这些挑战的框架

Method: 开发包含三个组件的学习框架：1) 多尺度编码器处理不同时间尺度和缺失样本；2) 多尺度动态骨干提取多模态时序动态；3) 模态特定解码器处理不同概率分布

Result: 在模拟和三个真实多尺度脑数据集上，该方法能有效聚合不同时间尺度、分布和缺失样本的信息，改善实时目标解码，优于各种线性和非线性多模态基准方法

Conclusion: 该框架成功解决了多模态神经数据实时解码中的关键挑战，包括不同时间尺度、概率分布和缺失样本，为神经科学应用提供了有效的实时解码工具

Abstract: Real-time decoding of target variables from multiple simultaneously recorded neural time-series modalities, such as discrete spiking activity and continuous field potentials, is important across various neuroscience applications. However, a major challenge for doing so is that different neural modalities can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps. Existing nonlinear models of multimodal neural activity do not address different timescales or missing samples across modalities. Further, some of these models do not allow for real-time decoding. Here, we develop a learning framework that can enable real-time recursive decoding while nonlinearly aggregating information across multiple modalities with different timescales and distributions and with missing samples. This framework consists of 1) a multiscale encoder that nonlinearly aggregates information after learning within-modality dynamics to handle different timescales and missing samples in real time, 2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time recursive decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. In both simulations and three distinct multiscale brain datasets, we show that our model can aggregate information across modalities with different timescales and distributions and missing samples to improve real-time target decoding. Further, our method outperforms various linear and nonlinear multimodal benchmarks in doing so.

</details>


### [143] [Exploring the Design Space of Transition Matching](https://arxiv.org/abs/2512.12465)
*Uriel Singer,Yaron Lipman*

Main category: cs.LG

TL;DR: 本文系统研究了Transition Matching（TM）生成模型中头部模块的设计、训练和采样策略，通过大规模实验发现MLP头部配合特定时间加权和高频采样器在综合指标上表现最佳，达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: Transition Matching作为一种新兴的生成建模范式，虽然比扩散和流匹配模型更具表达力，但其头部模块的设计、训练和采样策略缺乏系统研究。本文旨在通过大规模实验探索这些关键因素对生成质量、训练和推理效率的影响。

Method: 采用时间连续双向变体的TM框架，训练了56个不同的17亿参数文本到图像模型（共549次评估），系统研究头部模块架构、训练建模策略以及一系列随机TM采样器。通过全面消融实验分析不同设计选择的影响。

Result: 研究发现：1）MLP头部配合特定时间加权和高频采样器在所有指标上表现最佳，达到SOTA水平；2）Transformer头部配合序列缩放和低频采样是亚军，在图像美学方面表现优异；3）实验揭示了哪些设计选择能带来最大质量效率提升，哪些选择不太可能提供进一步增益。

Conclusion: 本文通过大规模系统实验为TM生成模型的头部模块设计提供了实证指导，明确了最佳实践方案，同时指出了哪些设计方向值得进一步探索，哪些可能收益有限，为未来TM模型的发展提供了重要参考。

Abstract: Transition Matching (TM) is an emerging paradigm for generative modeling that generalizes diffusion and flow-matching models as well as continuous-state autoregressive models. TM, similar to previous paradigms, gradually transforms noise samples to data samples, however it uses a second ``internal'' generative model to implement the transition steps, making the transitions more expressive compared to diffusion and flow models. To make this paradigm tractable, TM employs a large backbone network and a smaller "head" module to efficiently execute the generative transition step. In this work, we present a large-scale, systematic investigation into the design, training and sampling of the head in TM frameworks, focusing on its time-continuous bidirectional variant. Through comprehensive ablations and experimentation involving training 56 different 1.7B text-to-image models (resulting in 549 unique evaluations) we evaluate the affect of the head module architecture and modeling during training as-well as a useful family of stochastic TM samplers. We analyze the impact on generation quality, training, and inference efficiency. We find that TM with an MLP head, trained with a particular time weighting and sampled with high frequency sampler provides best ranking across all metrics reaching state-of-the-art among all tested baselines, while Transformer head with sequence scaling and low frequency sampling is a runner up excelling at image aesthetics. Lastly, we believe the experiments presented highlight the design aspects that are likely to provide most quality and efficiency gains, while at the same time indicate what design choices are not likely to provide further gains.

</details>


### [144] [Sparse Concept Anchoring for Interpretable and Controllable Neural Representations](https://arxiv.org/abs/2512.12469)
*Sandy Fraser,Patryk Wielopolski*

Main category: cs.LG

TL;DR: 提出稀疏概念锚定方法，通过最小监督（每个锚定概念仅需<0.1%样本标签）在潜在空间中定位目标概念子集，同时允许其他概念自组织，实现可解释、可操控的行为干预。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持其他特征不变的情况下，对学习表示中的特定概念进行选择性操控或移除。需要一种既能精确定位目标概念，又不会干扰正交特征的实用方法。

Method: 结合激活归一化、分离正则化器以及锚定/子空间正则化器，将稀有标记样本吸引到预定义方向或轴对齐子空间。训练时使用极少量监督（每个锚定概念<0.1%样本标签）。

Result: 在结构化自编码器上的实验显示：1）能够选择性衰减目标概念而对正交特征影响可忽略；2）通过针对性权重消融可完全消除概念，重建误差接近理论界限。

Conclusion: 稀疏概念锚定为学习表示提供了可解释、可操控行为的实用途径，支持可逆行为引导和永久概念移除两种干预方式。

Abstract: We introduce Sparse Concept Anchoring, a method that biases latent space to position a targeted subset of concepts while allowing others to self-organize, using only minimal supervision (labels for <0.1% of examples per anchored concept). Training combines activation normalization, a separation regularizer, and anchor or subspace regularizers that attract rare labeled examples to predefined directions or axis-aligned subspaces. The anchored geometry enables two practical interventions: reversible behavioral steering that projects out a concept's latent component at inference, and permanent removal via targeted weight ablation of anchored dimensions. Experiments on structured autoencoders show selective attenuation of targeted concepts with negligible impact on orthogonal features, and complete elimination with reconstruction error approaching theoretical bounds. Sparse Concept Anchoring therefore provides a practical pathway to interpretable, steerable behavior in learned representations.

</details>


### [145] [GoMS: Graph of Molecule Substructure Network for Molecule Property Prediction](https://arxiv.org/abs/2512.12489)
*Shuhui Qu,Cheolwoo Park*

Main category: cs.LG

TL;DR: GoMS提出了一种新的分子图神经网络架构，将分子表示为子结构图而非独立的子图集合，通过显式建模子结构间的相互作用和空间排列关系，显著提升了分子性质预测性能，尤其对大分子效果更佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ESAN将分子视为独立子结构的集合，忽略了子结构之间的关键关系和空间排列。这种"袋子"表示方法丢失了子结构如何连接和重叠的重要拓扑信息，限制了模型对复杂分子性质预测的能力。

Method: GoMS构建了一个子结构图，其中节点代表子图，边捕获子结构之间的结构关系。这种方法保留了子结构如何连接和重叠的关键拓扑信息，能够区分具有相同子图组成但不同空间排列的分子。

Result: 在公开分子数据集上的实验表明，GoMS超越了ESAN和其他基线方法，特别是对于包含超过100个原子的大分子改进更为显著。随着分子尺寸增大，性能差距进一步扩大，证明了GoMS对工业规模分子建模的有效性。

Conclusion: GoMS通过捕获子结构关系（这些关系在袋子式方法中丢失），代表了面向实际应用的可扩展和可解释分子性质预测的重要进展，特别在涉及复杂分子的材料科学应用中展现出巨大潜力。

Abstract: While graph neural networks have shown remarkable success in molecular property prediction, current approaches like the Equivariant Subgraph Aggregation Networks (ESAN) treat molecules as bags of independent substructures, overlooking crucial relationships between these components. We present Graph of Molecule Substructures (GoMS), a novel architecture that explicitly models the interactions and spatial arrangements between molecular substructures. Unlike ESAN's bag-based representation, GoMS constructs a graph where nodes represent subgraphs and edges capture their structural relationships, preserving critical topological information about how substructures are connected and overlap within the molecule. Through extensive experiments on public molecular datasets, we demonstrate that GoMS outperforms ESAN and other baseline methods, with particularly improvements for large molecules containing more than 100 atoms. The performance gap widens as molecular size increases, demonstrating GoMS's effectiveness for modeling industrial-scale molecules. Our theoretical analysis demonstrates that GoMS can distinguish molecules with identical subgraph compositions but different spatial arrangements. Our approach shows particular promise for materials science applications involving complex molecules where properties emerge from the interplay between multiple functional units. By capturing substructure relationships that are lost in bag-based approaches, GoMS represents a significant advance toward scalable and interpretable molecular property prediction for real-world applications.

</details>


### [146] [AI-Driven Early Warning Systems for Student Success: Discovering Static Feature Dominance in Temporal Prediction Models](https://arxiv.org/abs/2512.12493)
*Vaarunay Kaushal,Rajib Mall*

Main category: cs.LG

TL;DR: 该研究比较了决策树和LSTM模型在在线学习环境中识别风险学生的时序预测性能，发现不同干预阶段需要不同的性能指标，且静态人口统计特征对早期预测最为重要。


<details>
  <summary>Details</summary>
Motivation: 在线学习环境中早期识别风险学生对于有效干预至关重要，但现有研究缺乏对不同干预阶段最佳预测模型和性能指标的深入分析。

Method: 将时序预测分析扩展到课程第20周（50%课程时长），在六个时间快照上比较决策树和LSTM模型，分析不同阶段的最佳性能指标和特征重要性。

Result: 不同干预阶段需要不同性能指标：早期（2-4周）需要高召回率，中期（8-16周）需要平衡的精确率-召回率，后期（20周）需要高精确率。静态人口统计特征占预测重要性的68%，LSTM在第2周达到97%召回率，决策树在中期提供78%准确率的稳定表现。

Conclusion: 模型选择应取决于干预时机，早期信号（2-4周）结合人口统计和入学前信息足以进行可靠的初始预测，为不同阶段的风险学生识别提供了实用的模型选择指南。

Abstract: Early identification of at-risk students is critical for effective intervention in online learning environments. This study extends temporal prediction analysis to Week 20 (50% of course duration), comparing Decision Tree and Long Short- Term Memory (LSTM) models across six temporal snapshots. Our analysis reveals that different performance metrics matter at different intervention stages: high recall is critical for early intervention (Weeks 2-4), while balanced precision-recall is important for mid-course resource allocation (Weeks 8-16), and high precision becomes paramount in later stages (Week 20). We demonstrate that static demographic features dominate predictions (68% importance), enabling assessment-free early prediction. The LSTM model achieves 97% recall at Week 2, making it ideal for early intervention, while Decision Tree provides stable balanced performance (78% accuracy) during mid-course. By Week 20, both models converge to similar recall (68%), but LSTM achieves higher precision (90% vs 86%). Our findings also suggest that model selection should depend on intervention timing, and that early signals (Weeks 2-4) are sufficient for reliable initial prediction using primarily demographic and pre-enrollment information.

</details>


### [147] [Policy Optimization for Dynamic Heart Transplant Allocation](https://arxiv.org/abs/2512.12497)
*Ioannis Anagnostides,Zachary W. Sollie,Arman Kilic,Tuomas Sandholm*

Main category: cs.LG

TL;DR: 本文开发了一个新的心脏移植分配政策模拟器，发现当前政策远不如最大化移植获益年数的近视政策，并提出使用潜力值考虑动态分配过程的改进政策，以及批量处理供体的方法。


<details>
  <summary>Details</summary>
Motivation: 心脏移植是晚期心衰患者的可行选择，但供体严重短缺。当前分配政策（2018年修订）未能充分考虑移植前后的死亡率，需要改进。

Method: 使用UNOS历史数据开发新的模拟器，评估不同政策性能。提出基于潜力值的动态分配政策，考虑患者在未来分配中的效用，并探索批量处理供体的方法。

Result: 当前政策明显劣于最大化移植获益年数的近视政策。改进的潜力值政策能提升分配效果，批量处理供体（即使是少量）能进一步提高性能。模拟器还能评估地理邻近性和移植中心拒绝倾向等关键因素。

Conclusion: 通过开发新的模拟器和引入潜力值概念，本文为改进心脏移植分配政策提供了重要工具和方法，能够更好地考虑动态分配过程和关键影响因素。

Abstract: Heart transplantation is a viable path for patients suffering from advanced heart failure, but this lifesaving option is severely limited due to donor shortage. Although the current allocation policy was recently revised in 2018, a major concern is that it does not adequately take into account pretransplant and post-transplant mortality. In this paper, we take an important step toward addressing these deficiencies.
  To begin with, we use historical data from UNOS to develop a new simulator that enables us to evaluate and compare the performance of different policies. We then leverage our simulator to demonstrate that the status quo policy is considerably inferior to the myopic policy that matches incoming donors to the patient who maximizes the number of years gained by the transplant. Moreover, we develop improved policies that account for the dynamic nature of the allocation process through the use of potentials -- a measure of a patient's utility in future allocations that we introduce. We also show that batching together even a handful of donors -- which is a viable option for a certain type of donors -- further enhances performance. Our simulator also allows us to evaluate the effect of critical, and often unexplored, factors in the allocation, such as geographic proximity and the tendency to reject offers by the transplant centers.

</details>


### [148] [Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling](https://arxiv.org/abs/2512.12526)
*Agustín M. de los Riscos,Julio E. Sandubete,Diego Carmona-Fernández,León Beleña*

Main category: cs.LG

TL;DR: 该研究将经验模态分解(EMD)应用于MSCI世界指数，将分解得到的本征模态函数(IMFs)转换为图表示，以便用图神经网络(GNN)建模。使用CEEMDAN提取9个IMF，涵盖高频波动到长期趋势。每个IMF通过四种时间序列转图方法转换为图，分析显示拓扑结构具有明显的尺度依赖性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地对金融时间序列进行预测建模，需要将时间序列分解为不同频率的组件，并将这些组件转换为适合图神经网络处理的图结构表示，从而利用GNN的优势进行金融预测。

Method: 1. 使用CEEMDAN方法将MSCI世界指数分解为9个本征模态函数(IMFs)；2. 采用四种时间序列转图方法：自然可见性图、水平可见性图、递归图和转移图；3. 对生成的图进行拓扑结构分析；4. 为GNN架构设计提供指导。

Result: 1. 高频IMF产生密集、高度连接的小世界图，低频IMF产生更稀疏、特征路径更长的网络；2. 可见性方法对振幅变化更敏感，通常产生更高的聚类系数；3. 递归图更好地保留了时间依赖性；4. 拓扑结构具有明显的尺度依赖性特征。

Conclusion: 该研究结果为针对分解组件的结构特性设计专门的GNN架构提供了指导，支持更有效的金融时间序列预测建模。不同频率的IMF需要不同的图表示方法，这有助于优化GNN在金融预测中的应用。

Abstract: This study applies Empirical Mode Decomposition (EMD) to the MSCI World index and converts the resulting intrinsic mode functions (IMFs) into graph representations to enable modeling with graph neural networks (GNNs). Using CEEMDAN, we extract nine IMFs spanning high-frequency fluctuations to long-term trends. Each IMF is transformed into a graph using four time-series-to-graph methods: natural visibility, horizontal visibility, recurrence, and transition graphs. Topological analysis shows clear scale-dependent structure: high-frequency IMFs yield dense, highly connected small-world graphs, whereas low-frequency IMFs produce sparser networks with longer characteristic path lengths. Visibility-based methods are more sensitive to amplitude variability and typically generate higher clustering, while recurrence graphs better preserve temporal dependencies. These results provide guidance for designing GNN architectures tailored to the structural properties of decomposed components, supporting more effective predictive modeling of financial time series.

</details>


### [149] [Effective Fine-Tuning with Eigenvector Centrality Based Pruning](https://arxiv.org/abs/2512.12543)
*Shaif Chowdhury,Soham Biren Katlariwala,Devleena Kashyap*

Main category: cs.LG

TL;DR: 论文提出基于图论的神经网络剪枝方法，通过特征向量中心性识别重要神经元，剪枝后微调，在多个数据集上实现更高准确率和更低模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 受社交媒体中少数高影响力用户能驱动网络大规模变化的启发，作者认为类似现象存在于神经网络微调中。传统微调通常在预训练模型顶部添加新分类层，而作者认为通过先剪枝保留最重要神经元再进行微调能获得更好的适应性能。

Method: 提出基于图论的神经网络剪枝方法：将神经元表示为节点，边编码神经元间相似性；使用特征向量中心性计算神经元重要性分数；基于中心性分数剪枝，只保留最核心的神经元；对剪枝后的网络进行微调。

Result: 在VGGNet、EfficientNet和ResNet模型上，使用TF Flowers、Caltech 101和Oxford Flowers 102数据集评估。方法在显著降低模型复杂度的同时获得更高分类准确率。在Oxford Flowers 102数据集上，达到48%准确率，而基线VGGNet模型为30%。

Conclusion: 基于图论的剪枝方法能有效识别神经网络中的关键神经元，剪枝后微调相比传统方法在保持或提高性能的同时显著降低模型复杂度，验证了社交媒体影响力传播类比在神经网络适应中的适用性。

Abstract: In social media networks a small number of highly influential users can drive large scale changes in discourse across multiple communities. Small shifts in the behavior of these users are often sufficient to propagate widely throughout the network. A similar phenomenon occurs during neural network fine tuning. Conventional fine tuning of convolutional neural networks typically adds a new linear classification layer on top of a large pre trained model. Instead we argue that improved adaptation can be achieved by first pruning the network to retain only the most important neurons and then performing fine tuning.
  We propose a graph theory based method for pruning neural networks that is designed to improve fine tuning performance. In this method each neuron is represented as a node and edges encode similarity between neurons. Neurons are pruned based on importance scores computed using eigenvector centrality. The resulting pruned network is then fine tuned using only the most central neurons. We evaluate the proposed method on VGGNet EfficientNet and ResNet models using the TF Flowers Caltech one zero one and Oxford Flowers one zero two datasets. The proposed approach achieves higher classification accuracy while significantly reducing model complexity. On the Oxford Flowers one zero two dataset the method achieves forty eight percent classification accuracy compared to thirty percent accuracy obtained by the baseline VGGNet model.

</details>


### [150] [Skillful Subseasonal-to-Seasonal Forecasting of Extreme Events with a Multi-Sphere Coupled Probabilistic Model](https://arxiv.org/abs/2512.12545)
*Bin Mu,Yuxuan Chen,Shijin Yuan,Bo Qin,Hao Guo*

Main category: cs.LG

TL;DR: TianXing-S2S是一个多圈层耦合的概率模型，用于全球次季节到季节（S2S）的每日集合预报，通过扩散模型和最优传输耦合模块，在45天预报中超越了ECMWF和FuXi-S2S系统。


<details>
  <summary>Details</summary>
Motivation: 在气候变化加速的背景下，准确的次季节到季节（S2S）极端事件预测对于资源规划和灾害缓解至关重要，但由于复杂的多圈层相互作用和内在的大气不确定性，这种预测仍然具有挑战性。

Method: 1. 将多样化的多圈层预测因子编码到紧凑的潜在空间中；2. 使用扩散模型生成每日集合预报；3. 在去噪器中加入基于最优传输（OT）的新型耦合模块，优化大气与多圈层边界条件之间的相互作用。

Result: 在1.5°分辨率下，TianXing-S2S在45天每日平均集合预报中，在关键大气变量上超越了ECMWF S2S系统和FuXi-S2S；能够熟练预测极端事件（热浪和异常降水），识别土壤湿度为关键前兆信号；能够生成长达180天的稳定滚动预报。

Conclusion: TianXing-S2S为变暖世界中的S2S研究建立了一个稳健的框架，展示了多圈层耦合和扩散模型在次季节到季节预测中的有效性。

Abstract: Accurate subseasonal-to-seasonal (S2S) prediction of extreme events is critical for resource planning and disaster mitigation under accelerating climate change. However, such predictions remain challenging due to complex multi-sphere interactions and intrinsic atmospheric uncertainty. Here we present TianXing-S2S, a multi-sphere coupled probabilistic model for global S2S daily ensemble forecast. TianXing-S2S first encodes diverse multi-sphere predictors into a compact latent space, then employs a diffusion model to generate daily ensemble forecasts. A novel coupling module based on optimal transport (OT) is incorporated in the denoiser to optimize the interactions between atmospheric and multi-sphere boundary conditions. Across key atmospheric variables, TianXing-S2S outperforms both the European Centre for Medium-Range Weather Forecasts (ECMWF) S2S system and FuXi-S2S in 45-day daily-mean ensemble forecasts at 1.5 resolution. Our model achieves skillful subseasonal prediction of extreme events including heat waves and anomalous precipitation, identifying soil moisture as a critical precursor signal. Furthermore, we demonstrate that TianXing-S2S can generate stable rollout forecasts up to 180 days, establishing a robust framework for S2S research in a warming world.

</details>


### [151] [Optimal Mistake Bounds for Transductive Online Learning](https://arxiv.org/abs/2512.12567)
*Zachary Chase,Steve Hanneke,Shay Moran,Jonathan Shafer*

Main category: cs.LG

TL;DR: 该论文解决了在线学习中无标签数据能力的30年开放问题，证明了转导式在线学习与标准在线学习之间存在平方根差距，即转导式学习的最优错误界为Ω(√d)且可达到O(√d)，而标准在线学习为d。


<details>
  <summary>Details</summary>
Motivation: 解决在线学习中关于无标签数据能力的长期开放问题。已有研究表明转导式学习（提前知道无标签实例序列）比标准在线学习有优势，但具体优势大小30年来未得到精确量化。之前的下界结果（Ω(log log d)、Ω(√log d)、Ω(log d)）与上界(2/3)d之间存在巨大差距。

Method: 通过理论分析证明转导式在线学习的下界为Ω(√d)，并构造具体概念类证明上界为O(√d)。使用Littlestone维度作为衡量标准，对比转导式与标准在线学习的错误界。

Result: 1. 证明转导式在线学习的最优错误界至少为Ω(√d)，相比之前的下界有指数级改进；2. 证明该下界是紧的，存在Littlestone维度为d的概念类，其转导式错误界为O(√d)；3. 改进了之前(2/3)d的上界结果。

Conclusion: 转导式在线学习与标准在线学习之间存在平方根差距（√d vs d），这显著体现了提前获取无标签实例序列的益处。这与PAC学习设置形成对比，在PAC学习中转导式与标准学习的样本复杂度相似。

Abstract: We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. In the standard setting, the optimal mistake bound is characterized by the Littlestone dimension $d$ of the concept class $H$ (Littlestone 1987). We prove that in the transductive setting, the mistake bound is at least $Ω(\sqrt{d})$. This constitutes an exponential improvement over previous lower bounds of $Ω(\log\log d)$, $Ω(\sqrt{\log d})$, and $Ω(\log d)$, due respectively to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that this lower bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\sqrt{d})$. Our upper bound also improves upon the best known upper bound of $(2/3)d$ from Ben-David, Kushilevitz, and Mansour (1997). These results establish a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advance access to the unlabeled instance sequence. This contrasts with the PAC setting, where transductive and standard learning exhibit similar sample complexities.

</details>


### [152] [On the Accuracy of Newton Step and Influence Function Data Attributions](https://arxiv.org/abs/2512.12572)
*Ittai Rubinstein,Samuel B. Hopkins*

Main category: cs.LG

TL;DR: 本文对数据归因方法（NS和IF）进行了新的理论分析，首次在不假设全局强凸性的情况下，为凸学习问题提供了渐近紧致的误差界，并解释了NS方法通常比IF更准确的原因。


<details>
  <summary>Details</summary>
Motivation: 现有数据归因方法（如影响函数IF和单牛顿步NS）的理论分析存在两个主要局限：1）依赖全局强凸性假设，这在实践中常不满足；2）误差界在参数数量d和移除样本数k上缩放很差。这导致无法回答"哪种方法更准确"等基本问题。

Method: 针对凸学习问题，提出了新的理论分析框架，不依赖全局强凸性假设。通过数学推导证明了NS和IF方法的误差界，特别关注逻辑回归等良好行为的模型。

Result: 推导出渐近紧致的误差界（忽略多对数因子）：NS方法的期望误差为Õ(kd/n²)，NS与IF之间的期望差异为Õ((k+d)√(kd)/n²)。这首次解释了NS通常比IF更准确的实验观察。

Conclusion: 本文为数据归因方法提供了更实用、更紧致的理论分析，首次在不依赖强凸性假设的情况下解释了NS优于IF的现象，并为实际应用中的方法选择提供了理论依据。

Abstract: Data attribution aims to explain model predictions by estimating how they would change if certain training points were removed, and is used in a wide range of applications, from interpretability and credit assignment to unlearning and privacy.
  Even in the relatively simple case of linear regressions, existing mathematical analyses of leading data attribution methods such as Influence Functions (IF) and single Newton Step (NS) remain limited in two key ways. First, they rely on global strong convexity assumptions which are often not satisfied in practice. Second, the resulting bounds scale very poorly with the number of parameters ($d$) and the number of samples removed ($k$). As a result, these analyses are not tight enough to answer fundamental questions such as "what is the asymptotic scaling of the errors of each method?" or "which of these methods is more accurate for a given dataset?"
  In this paper, we introduce a new analysis of the NS and IF data attribution methods for convex learning problems. To the best of our knowledge, this is the first analysis of these questions that does not assume global strong convexity and also the first explanation of [KATL19] and [RH25a]'s observation that NS data attribution is often more accurate than IF. We prove that for sufficiently well-behaved logistic regression, our bounds are asymptotically tight up to poly-logarithmic factors, yielding scaling laws for the errors in the average-case sample removals.
  \[ \mathbb{E}_{T \subseteq [n],\, |T| = k} \bigl[ \|\hatθ_T - \hatθ_T^{\mathrm{NS}}\|_2 \bigr] = \widetildeΘ\!\left(\frac{k d}{n^2}\right), \qquad \mathbb{E}_{T \subseteq [n],\, |T| = k} \bigl[ \|\hatθ_T^{\mathrm{NS}} - \hatθ_T^{\mathrm{IF}}\|_2 \bigr] = \widetildeΘ\!\left( \frac{(k + d)\sqrt{k d}}{n^2} \right). \]

</details>


### [153] [Differentiable Energy-Based Regularization in GANs: A Simulator-Based Exploration of VQE-Inspired Auxiliary Losses](https://arxiv.org/abs/2512.12581)
*David Strnadel*

Main category: cs.LG

TL;DR: 探索性研究：将参数化量子电路的可微分能量项作为GAN的辅助正则化信号，在MNIST上实验表明能提高分类准确率，但样本质量指标波动较大，计算开销大，不声称量子优势。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算与生成对抗网络的交叉领域，研究参数化量子电路的可微分能量项能否作为GAN训练中的辅助正则化信号，为量子机器学习提供新的方法学思路。

Method: 在辅助分类器GAN（ACGAN）生成器目标函数中，加入基于变分量子本征求解器（VQE）启发的能量项。该能量项通过Qiskit的EstimatorQNN和TorchConnector从类别特定的伊辛哈密顿量计算得到，使用4量子位的无噪声状态向量模拟器。

Result: 在MNIST数据集上，能量正则化模型（QACGAN）在5个epoch内达到99-100%的分类准确率，显著高于ACGAN的87.8%。但样本质量指标（FID）在运行间波动较大（变异系数约25%），最终稳定在FID 23-24，与ACGAN基线相当。计算开销约为经典ACGAN的200倍。

Conclusion: 该方法学上证明了VQE风格的能量计算可以通过可微分路径集成到GAN训练循环中。但该量子辅助信号是否优于等效的经典正则化器仍是一个开放问题，需要系统的消融研究。研究明确不声称量子优势或通用稳定性改进。

Abstract: This paper presents an exploratory, simulator-based proof of concept investigating whether differentiable energy terms derived from parameterized quantum circuits can serve as auxiliary regularization signals in Generative Adversarial Networks (GANs). We augment the Auxiliary Classifier GAN (ACGAN) generator objective with a Variational Quantum Eigensolver (VQE)-inspired energy term computed from class-specific Ising Hamiltonians using Qiskit's EstimatorQNN and TorchConnector.
  Important limitations: All experiments run on a noiseless statevector simulator with only 4 qubits, use a deliberately simple Hamiltonian parameterization, and lack ablation studies comparing against equivalent classical biases. The computational overhead (approximately 200x slower than classical ACGAN) reflects simulator artifacts rather than inherent quantum costs.
  On MNIST, we observe that the energy-regularized model (termed QACGAN) achieves high classification accuracy (99 to 100 percent) within 5 epochs compared to 87.8 percent for ACGAN, suggesting the auxiliary term influences class conditioning. However, sample quality metrics (FID) show high variance across runs (coefficient of variation approximately 25 percent at epoch 5), with values ranging from 19.92 to 35.96. Extended runs stabilize around FID 23 to 24, comparable to the ACGAN baseline.
  We explicitly do not claim quantum advantage, improved stability in any general sense, or scalability beyond this toy setting. The contribution is methodological: demonstrating that VQE-style energy computations can be integrated into GAN training loops via differentiable pathways. Whether such auxiliary signals provide benefits beyond equivalent classical regularizers remains an open question requiring systematic ablation studies, which we leave for future work.

</details>


### [154] [Error-Free Linear Attention is a Free Lunch: Exact Solution from Continuous-Time Dynamics](https://arxiv.org/abs/2512.12602)
*Jingdi Lei,Di Zhang,Soujanya Poria*

Main category: cs.LG

TL;DR: EFLA是一种误差自由的线性注意力机制，通过将在线学习更新建模为连续时间动力系统，提供精确的闭式解，在保持线性时间复杂度的同时避免误差累积。


<details>
  <summary>Details</summary>
Motivation: 解决传统softmax注意力在长上下文语言模型中的二次计算成本问题，同时克服现有线性注意力和状态空间模型可能存在的数值不稳定性和误差累积问题。

Method: 将在线学习更新公式化为连续时间动力系统，利用动态矩阵的秩-1结构，推导出精确的闭式解（相当于无限阶龙格-库塔方法），实现数值稳定、完全并行化的线性时间注意力机制。

Result: 在噪声环境中表现稳健，语言建模困惑度低于DeltaNet，下游基准测试性能更优，且不引入额外参数，实现了高保真、可扩展的线性时间注意力模型。

Conclusion: EFLA为构建高保真、可扩展的线性时间注意力模型提供了新的理论基础，在保持线性时间复杂度的同时完美捕捉连续动态特性，避免了误差累积问题。

Abstract: Linear-time attention and State Space Models (SSMs) promise to solve the quadratic cost bottleneck in long-context language models employing softmax attention. We introduce Error-Free Linear Attention (EFLA), a numerically stable, fully parallelism and generalized formulation of the delta rule. Specifically, we formulate the online learning update as a continuous-time dynamical system and prove that its exact solution is not only attainable but also computable in linear time with full parallelism. By leveraging the rank-1 structure of the dynamics matrix, we directly derive the exact closed-form solution effectively corresponding to the infinite-order Runge-Kutta method. This attention mechanism is theoretically free from error accumulation, perfectly capturing the continuous dynamics while preserving the linear-time complexity. Through an extensive suite of experiments, we show that EFLA enables robust performance in noisy environments, achieving lower language modeling perplexity and superior downstream benchmark performance than DeltaNet without introducing additional parameters. Our work provides a new theoretical foundation for building high-fidelity, scalable linear-time attention models.

</details>


### [155] [Causal inference and model explainability tools for retail](https://arxiv.org/abs/2512.12605)
*Pranav Gupta,Nithin Surendran*

Main category: cs.LG

TL;DR: 本文提出一个结合模型可解释性与因果推断的框架，用于零售销售分析，通过双机器学习方法处理混杂变量，提升因果效应估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 零售业虽有大量数据分析和预测模型，但现有方法缺乏可解释性，且无法验证或发现因果关系，限制了深入业务洞察的能力。

Method: 回顾因果推断与可解释性文献，应用于真实零售数据集；使用双机器学习方法纳入多个混杂变量，比较SHAP值方差评估模型可解释性。

Result: 研究发现：固有可解释模型具有更低的SHAP值方差；通过双机器学习纳入多个混杂变量可获得正确的因果效应符号。

Conclusion: 为零售销售洞察提供了一套结合模型可解释性与因果推断的实用方法框架，能更准确地识别因果关系并提升决策支持能力。

Abstract: Most major retailers today have multiple divisions focused on various aspects, such as marketing, supply chain, online customer experience, store customer experience, employee productivity, and vendor fulfillment. They also regularly collect data corresponding to all these aspects as dashboards and weekly/monthly/quarterly reports. Although several machine learning and statistical techniques have been in place to analyze and predict key metrics, such models typically lack interpretability. Moreover, such techniques also do not allow the validation or discovery of causal links. In this paper, we aim to provide a recipe for applying model interpretability and causal inference for deriving sales insights. In this paper, we review the existing literature on causal inference and interpretability in the context of problems in e-commerce and retail, and apply them to a real-world dataset. We find that an inherently explainable model has a lower variance of SHAP values, and show that including multiple confounders through a double machine learning approach allows us to get the correct sign of causal effect.

</details>


### [156] [Comparing concepts of quantum and classical neural network models for image classification task](https://arxiv.org/abs/2108.08875)
*Rafal Potempa,Sebastian Porebski*

Main category: cs.LG

TL;DR: 该论文研究了混合量子-经典神经网络在手写数字MNIST数据集分类问题上的性能，发现量子网络虽然模拟耗时，但在收敛性和准确率上优于经典网络


<details>
  <summary>Details</summary>
Motivation: 量子架构仍在发展中，未来量子计算机只能处理量子数据，而机器学习算法只能处理数值数据。因此需要研究如何将数值输入数据转换为量子形式，使量子计算机能够利用机器学习方法进行分类或回归任务

Method: 开发了混合量子-经典神经网络，用于MNIST手写数字分类问题。设计了将数值输入数据转换为量子形式的系统，并与参数数量相似的经典神经网络进行对比实验

Result: 量子神经网络虽然模拟时间较长，但在收敛性和准确率方面优于经典神经网络。量子网络在训练和测试准确率上都取得了更好的结果

Conclusion: 量子神经网络在分类任务中展现出优于经典网络的潜力，尽管当前模拟耗时，但随着量子硬件的发展，量子机器学习方法有望在实际应用中发挥优势

Abstract: While quantum architectures are still under development, when available, they will only be able to process quantum data when machine learning algorithms can only process numerical data. Therefore, in the issues of classification or regression, it is necessary to simulate and study quantum systems that will transfer the numerical input data to a quantum form and enable quantum computers to use the available methods of machine learning. This material includes the results of experiments on training and performance of a hybrid quantum-classical neural network developed for the problem of classification of handwritten digits from the MNIST data set. The comparative results of two models: classical and quantum neural networks of a similar number of training parameters, indicate that the quantum network, although its simulation is time-consuming, overcomes the classical network (it has better convergence and achieves higher training and testing accuracy).

</details>


### [157] [Spectral Sentinel: Scalable Byzantine-Robust Decentralized Federated Learning via Sketched Random Matrix Theory on Blockchain](https://arxiv.org/abs/2512.12617)
*Animesh Mishra*

Main category: cs.LG

TL;DR: Spectral Sentinel：基于随机矩阵理论的拜占庭检测框架，利用协方差矩阵特征谱的Marchenko-Pastur分布异常检测恶意梯度，支持高达15亿参数模型，实现最小最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习面临拜占庭客户端在非独立同分布数据下毒化梯度的威胁。现有防御方法存在可扩展性三难困境：基于距离的过滤可能拒绝合法的非独立同分布更新，几何中值方法计算成本过高（O(n²d)），而许多认证防御仅在低于1亿参数的模型上评估。

Method: 提出Spectral Sentinel框架，利用随机矩阵理论特征：诚实的非独立同分布梯度产生的协方差矩阵特征谱遵循Marchenko-Pastur分布，而拜占庭扰动会导致可检测的尾部异常。算法结合Frequent Directions草图技术和数据依赖的MP跟踪，使用O(k²)内存（k≪d）检测高达15亿参数的模型。

Result: 在(σ,f)威胁模型下（坐标级诚实方差有界σ²，f<1/2的敌手），证明(ε,δ)-拜占庭弹性，收敛率为O(σf/√T + f²/T)，并提供匹配的信息论下界Ω(σf/√T)，确立最小最优性。在Polygon网络上实现完整系统，在144个攻击-聚合配置中验证，平均准确率达78.4%，而基线方法为48-63%。

Conclusion: Spectral Sentinel解决了去中心化联邦学习的可扩展性三难困境，通过随机矩阵理论特征检测拜占庭攻击，支持大规模模型训练，提供理论保证和实际部署验证。

Abstract: Decentralized federated learning (DFL) enables collaborative model training without centralized trust, but it remains vulnerable to Byzantine clients that poison gradients under heterogeneous (Non-IID) data. Existing defenses face a scalability trilemma: distance-based filtering (e.g., Krum) can reject legitimate Non-IID updates, geometric-median methods incur prohibitive $O(n^2 d)$ cost, and many certified defenses are evaluated only on models below 100M parameters. We propose Spectral Sentinel, a Byzantine detection and aggregation framework that leverages a random-matrix-theoretic signature: honest Non-IID gradients produce covariance eigenspectra whose bulk follows the Marchenko-Pastur law, while Byzantine perturbations induce detectable tail anomalies. Our algorithm combines Frequent Directions sketching with data-dependent MP tracking, enabling detection on models up to 1.5B parameters using $O(k^2)$ memory with $k \ll d$. Under a $(σ,f)$ threat model with coordinate-wise honest variance bounded by $σ^2$ and $f < 1/2$ adversaries, we prove $(ε,δ)$-Byzantine resilience with convergence rate $O(σf / \sqrt{T} + f^2 / T)$, and we provide a matching information-theoretic lower bound $Ω(σf / \sqrt{T})$, establishing minimax optimality. We implement the full system with blockchain integration on Polygon networks and validate it across 144 attack-aggregator configurations, achieving 78.4 percent average accuracy versus 48-63 percent for baseline methods.

</details>


### [158] [Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks](https://arxiv.org/abs/2512.12642)
*Filippo Maria Bianchi,Carlo Abate,Ivan Marisca*

Main category: cs.LG

TL;DR: Torch Geometric Pool (tgp) 是一个基于 PyTorch Geometric 的图神经网络分层池化库，提供统一的 API 和模块化设计，支持快速原型开发。


<details>
  <summary>Details</summary>
Motivation: 图神经网络需要分层池化操作来处理图结构数据，但现有工具缺乏统一的接口和模块化设计，导致原型开发效率低下。

Method: 基于 PyTorch Geometric 构建，提供多样化的池化算子，采用一致的 API 和模块化设计，包含预计算池化等加速训练的特性。

Result: 通过广泛的基准测试展示了库的特性，并系统比较了不同下游任务中图池化方法的性能，结果表明最优池化算子的选择取决于具体任务和数据。

Conclusion: 不同任务和数据需要不同的最优池化算子，这支持了需要能够快速原型开发的库的必要性，tgp 正是为此目的而设计。

Abstract: We introduce Torch Geometric Pool (tgp), a library for hierarchical pooling in Graph Neural Networks. Built upon Pytorch Geometric, Torch Geometric Pool (tgp) provides a wide variety of pooling operators, unified under a consistent API and a modular design. The library emphasizes usability and extensibility, and includes features like precomputed pooling, which significantly accelerate training for a class of operators. In this paper, we present tgp's structure and present an extensive benchmark. The latter showcases the library's features and systematically compares the performance of the implemented graph-pooling methods in different downstream tasks. The results, showing that the choice of the optimal pooling operator depends on tasks and data at hand, support the need for a library that enables fast prototyping.

</details>


### [159] [PerNodeDrop: A Method Balancing Specialized Subnets and Regularization in Deep Neural Networks](https://arxiv.org/abs/2512.12663)
*Gelesh G Omathil,Sreeja CS*

Main category: cs.LG

TL;DR: PerNodeDrop是一种轻量级随机正则化方法，通过逐样本、逐节点的扰动打破现有技术中噪声的均匀性，保留有用协同适应同时进行正则化，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易过拟合，神经元倾向于协同适应，虽然能捕捉复杂特征交互，但也强化虚假模式。现有噪声正则化方法（如Dropout、DropConnect）的噪声通常是均匀的，会同时抑制有害和有益的协同适应。

Method: 提出PerNodeDrop方法，应用逐样本、逐节点的扰动，打破噪声均匀性，让每个节点经历输入特定的变异性。与DropConnect不同，它在样本级别而非批次级别丢弃权重。

Result: 在视觉、文本和音频基准测试中，相对于标准噪声正则化器，PerNodeDrop表现出改进的泛化性能，缩小了训练和验证性能之间的差距。

Conclusion: PerNodeDrop通过更精细的逐样本、逐节点扰动，能够保留有用的协同适应同时进行正则化，提高模型在未见数据上的可靠性，是一种有效的轻量级正则化方法。

Abstract: Deep neural networks possess strong representational capacity yet remain vulnerable to overfitting, primarily because neurons tend to co-adapt in ways that, while capturing complex and fine-grained feature interactions, also reinforce spurious and non-generalizable patterns that inflate training performance but reduce reliability on unseen data. Noise-based regularizers such as Dropout and DropConnect address this issue by injecting stochastic perturbations during training, but the noise they apply is typically uniform across a layer or across a batch of samples, which can suppress both harmful and beneficial co-adaptation.
  This work introduces PerNodeDrop, a lightweight stochastic regularization method. It applies per-sample, per-node perturbations to break the uniformity of the noise injected by existing techniques, thereby allowing each node to experience input-specific variability. Hence, PerNodeDrop preserves useful co-adaptation while applying regularization. This narrows the gap between training and validation performance and improves reliability on unseen data, as evident from the experiments.
  Although superficially similar to DropConnect, PerNodeDrop operates at the sample level. It drops weights at the sample level, not the batch level. An expected-loss analysis formalizes how its perturbations attenuate excessive co-adaptation while retaining predictive interactions. Empirical evaluations on vision, text, and audio benchmarks indicate improved generalization relative to the standard noise-based regularizer.

</details>


### [160] [DynaGen: Unifying Temporal Knowledge Graph Reasoning with Dynamic Subgraphs and Generative Regularization](https://arxiv.org/abs/2512.12669)
*Jiawei Shen,Jia Zhu,Hanghui Guo,Weijie Shi,Guoqing Ma,Yidan Liang,Jingjiang Liu,Hao Chen,Shimin Di*

Main category: cs.LG

TL;DR: DynaGen是一个统一的时序知识图谱推理方法，通过动态构建实体中心子图处理插值任务，使用条件扩散过程处理外推任务，在六个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理方法面临两个关键挑战：插值任务中上下文建模有限，外推任务中存在认知泛化偏差。需要一种统一的方法来同时解决这两个问题。

Method: DynaGen采用统一框架：对于插值任务，动态构建实体中心子图，使用协同双分支GNN编码器捕捉演化结构上下文；对于外推任务，应用条件扩散过程，迫使模型学习底层演化原则而非表面模式。

Result: 在六个基准数据集上的实验表明，DynaGen达到最先进性能。相比次优模型，平均MRR分数在插值任务上提升2.61分，在外推任务上提升1.45分。

Conclusion: DynaGen通过统一的动态生成框架，有效解决了时序知识图谱推理中插值和外推任务的关键挑战，实现了显著的性能提升。

Abstract: Temporal Knowledge Graph Reasoning (TKGR) aims to complete missing factual elements along the timeline. Depending on the temporal position of the query, the task is categorized into interpolation and extrapolation. Existing interpolation methods typically embed temporal information into individual facts to complete missing historical knowledge, while extrapolation techniques often leverage sequence models over graph snapshots to identify recurring patterns for future event prediction. These methods face two critical challenges: limited contextual modeling in interpolation and cognitive generalization bias in extrapolation. To address these, we propose a unified method for TKGR, dubbed DynaGen. For interpolation, DynaGen dynamically constructs entity-centric subgraphs and processes them with a synergistic dual-branch GNN encoder to capture evolving structural context. For extrapolation, it applies a conditional diffusion process, which forces the model to learn underlying evolutionary principles rather than just superficial patterns, enhancing its ability to predict unseen future events. Extensive experiments on six benchmark datasets show DynaGen achieves state-of-the-art performance. On average, compared to the second-best models, DynaGen improves the Mean Reciprocal Rank (MRR) score by 2.61 points for interpolation and 1.45 points for extrapolation.

</details>


### [161] [On Approaches to Building Surrogate ODE Models for Diffusion Bridges](https://arxiv.org/abs/2512.12671)
*Maria Khilchuk,Vladimir Latypov,Pavel Kleshchev,Alexander Hvatov*

Main category: cs.LG

TL;DR: 提出两种基于代理模型的扩散和薛定谔桥近似方法：SINDy-FM使用稀疏回归学习符号微分方程，DSBM-NeuralODE使用神经ODE参数化，在保持性能的同时大幅提升效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和薛定谔桥模型在生成建模中表现优异，但存在计算成本高、训练复杂的问题。连续时间桥模型虽然采样更快，但通常使用过参数化神经网络描述最优动态，且底层随机微分方程难以高效积分。

Method: 提出两种代理模型方法：1) SINDy-FM：利用稀疏回归从数据中识别可解释的符号微分方程；2) DSBM-NeuralODE：将薛定谔桥重新表述为神经ODE，实现灵活的连续时间参数化。

Result: 在高斯传输任务和MNIST潜在翻译实验中，这些代理模型实现了竞争性性能，同时在效率和可解释性方面有显著提升。特别是SINDy-FM模型将参数数量减少了几个数量级，实现近乎瞬时的推理。

Conclusion: 该工作为扩散和薛定谔桥模型提供了一种新的代理模型范式，创造了更简单、更快、更灵活的近似方法，为实际部署开辟了新的可处理高性能桥模型类别。

Abstract: Diffusion and Schrödinger Bridge models have established state-of-the-art performance in generative modeling but are often hampered by significant computational costs and complex training procedures. While continuous-time bridges promise faster sampling, overparameterized neural networks describe their optimal dynamics, and the underlying stochastic differential equations can be difficult to integrate efficiently. This work introduces a novel paradigm that uses surrogate models to create simpler, faster, and more flexible approximations of these dynamics. We propose two specific algorithms: SINDy Flow Matching (SINDy-FM), which leverages sparse regression to identify interpretable, symbolic differential equations from data, and a Neural-ODE reformulation of the Schrödinger Bridge (DSBM-NeuralODE) for flexible continuous-time parameterization. Our experiments on Gaussian transport tasks and MNIST latent translation demonstrate that these surrogates achieve competitive performance while offering dramatic improvements in efficiency and interpretability. The symbolic SINDy-FM models, in particular, reduce parameter counts by several orders of magnitude and enable near-instantaneous inference, paving the way for a new class of tractable and high-performing bridge models for practical deployment.

</details>


### [162] [Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity](https://arxiv.org/abs/2512.12688)
*Dongseok Kim,Hyoungsun Choi,Mohamed Jismy Aashik Rasool,Gisung Oh*

Main category: cs.LG

TL;DR: 论文提出将提示视为外部注入程序的理论框架，证明单个固定Transformer骨干仅通过提示就能近似广泛目标行为


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将提示视为启发式工具而非理论对象，缺乏对提示如何改变模型行为的机制理解

Method: 构建简化Transformer，将提示视为外部程序，揭示注意力机制执行选择性路由、前馈网络执行局部算术、深度堆叠组合为多步计算的机制分解

Result: 证明构造性存在结果：单个固定骨干仅通过提示就能近似广泛目标行为，为研究提示长度/精度约束下的权衡提供统一框架

Conclusion: 建立了提示作为外部注入程序的理论框架，为形式化提示能力限制和结构限制提供基础，与预训练LLM的实证研究保持区分

Abstract: Prompts can switch a model's behavior even when the weights are fixed, yet this phenomenon is rarely treated as a clean theoretical object rather than a heuristic. We study the family of functions obtainable by holding a Transformer backbone fixed as an executor and varying only the prompt. Our core idea is to view the prompt as an externally injected program and to construct a simplified Transformer that interprets it to implement different computations. The construction exposes a mechanism-level decomposition: attention performs selective routing from prompt memory, the FFN performs local arithmetic conditioned on retrieved fragments, and depth-wise stacking composes these local updates into a multi-step computation. Under this viewpoint, we prove a constructive existential result showing that a single fixed backbone can approximate a broad class of target behaviors via prompts alone. The framework provides a unified starting point for formalizing trade-offs under prompt length/precision constraints and for studying structural limits of prompt-based switching, while remaining distinct from empirical claims about pretrained LLMs.

</details>


### [163] [Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning](https://arxiv.org/abs/2512.12690)
*Yongcan Yu,Lingxiao He,Shuo Lu,Lijun Sheng,Yinuo Xu,Yanbo Wang,Kuangpu Guo,Jianjie Cheng,Meng Wang,Qianlong Xie,Xingxing Wang,Dapeng Hu,Jian Liang*

Main category: cs.LG

TL;DR: 本文重新审视了视觉语言模型推理训练中SFT与RL的对比，发现SFT的作用被低估，两者应作为互补组件而非RL优先


<details>
  <summary>Details</summary>
Motivation: 当前社区普遍认为RL优于SFT，许多研究显示SFT阶段不仅无法提升推理能力，还可能对模型训练产生负面影响。本文旨在通过系统对比重新评估这一RL中心化观点

Method: 在相同数据源下，通过控制变量方法系统比较SFT和RL在VLM推理中的表现，考察模型容量、数据规模和数据分布等因素的影响

Result: 发现SFT在多个场景中起关键作用：1) 对较弱模型更有效；2) 数据效率更高（2K SFT ≈ 20K RL）；3) 跨模态迁移性更强。同时发现RL存在欺骗性奖励问题

Conclusion: 挑战了"RL优于SFT"的主流观点，指出SFT的作用被低估，支持建立更平衡的后训练流程，将SFT和RL作为互补组件

Abstract: Recent advances in vision-language models (VLMs) reasoning have been largely attributed to the rise of reinforcement Learning (RL), which has shifted the community's focus away from the supervised fine-tuning (SFT) paradigm. Many studies suggest that introducing the SFT stage not only fails to improve reasoning ability but may also negatively impact model training. In this study, we revisit this RL-centric belief through a systematic and controlled comparison of SFT and RL on VLM Reasoning. Using identical data sources, we find that the relative effectiveness of SFT and RL is conditional and strongly influenced by model capacity, data scale, and data distribution. Contrary to common assumptions, our findings show that SFT plays a crucial role across several scenarios: (1) Effectiveness for weaker models. SFT more reliably elicits reasoning capabilities in smaller or weaker VLMs. (2) Data efficiency. SFT with only 2K achieves comparable or better reasoning performance to RL with 20K. (3) Cross-modal transferability. SFT demonstrates stronger generalization across modalities. Moreover, we identify a pervasive issue of deceptive rewards, where higher rewards fail to correlate with better reasoning accuracy in RL. These results challenge the prevailing "RL over SFT" narrative. They highlight that the role of SFT may have been underestimated and support a more balanced post-training pipeline in which SFT and RL function as complementary components.

</details>


### [164] [Co-Exploration and Co-Exploitation via Shared Structure in Multi-Task Bandits](https://arxiv.org/abs/2512.12693)
*Sumantrak Mukherjee,Serafima Lebedeva,Valentin Margraf,Jonas Hanselle,Kanta Yamaoka,Viktor Bengs,Stefan Konigorski,Eyke Hüllermeier,Sebastian Josef Vollmer*

Main category: cs.LG

TL;DR: 提出贝叶斯框架用于上下文多任务多臂老虎机，利用潜在上下文变量捕捉奖励分布间的依赖关系，通过粒子近似实现灵活的数据驱动探索。


<details>
  <summary>Details</summary>
Motivation: 解决上下文多任务多臂老虎机中上下文部分可观测的问题，利用任务间的结构依赖关系来提高探索效率，特别是在模型误设或复杂潜在异质性场景下。

Method: 提出贝叶斯框架，整合所有任务的观测学习全局联合分布，使用基于粒子的对数密度高斯过程近似表示任务和奖励的联合分布，识别结构不确定性和用户特定不确定性两种认知不确定性来源。

Result: 实验表明该方法在模型误设或复杂潜在异质性设置下，优于分层模型老虎机等基线方法。

Conclusion: 提出的贝叶斯框架能有效利用任务间的结构依赖关系，通过灵活的数据驱动方法发现潜在变量间的依赖，在多任务上下文老虎机中实现更高效的探索。

Abstract: We propose a novel Bayesian framework for efficient exploration in contextual multi-task multi-armed bandit settings, where the context is only observed partially and dependencies between reward distributions are induced by latent context variables. In order to exploit these structural dependencies, our approach integrates observations across all tasks and learns a global joint distribution, while still allowing personalised inference for new tasks. In this regard, we identify two key sources of epistemic uncertainty, namely structural uncertainty in the latent reward dependencies across arms and tasks, and user-specific uncertainty due to incomplete context and limited interaction history. To put our method into practice, we represent the joint distribution over tasks and rewards using a particle-based approximation of a log-density Gaussian process. This representation enables flexible, data-driven discovery of both inter-arm and inter-task dependencies without prior assumptions on the latent variables. Empirically, we demonstrate that our method outperforms baselines such as hierarchical model bandits, especially in settings with model misspecification or complex latent heterogeneity.

</details>


### [165] [Multi-Trajectory Physics-Informed Neural Networks for HJB Equations with Hard-Zero Terminal Inventory: Optimal Execution on Synthetic & SPY Data](https://arxiv.org/abs/2512.12708)
*Anthime Valin*

Main category: cs.LG

TL;DR: 提出MT-PINN方法解决带硬零终端库存约束的最优交易执行问题，通过轨迹损失和终端惩罚直接强制零库存，在理论和实际数据上均表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统PINN方法在处理硬零终端库存约束时往往约束不足，导致控制不稳定，需要更有效的方法来严格满足交易执行中的零库存约束。

Method: 提出多轨迹PINN（MT-PINN），添加基于滚动的轨迹损失，通过时间反向传播传播终端惩罚，直接强制零终端库存，并采用轻量级lambda课程学习稳定训练。

Result: 在Gatheral-Schied单资产模型中，MT-PINN与解析解高度一致，终端库存紧密集中在零附近；在SPY日内数据上，风险中性时匹配TWAP，高风险厌恶时获得更低暴露和竞争性成本。

Conclusion: MT-PINN能有效处理硬零终端库存约束，在理论和实际交易执行问题中均表现优异，为带约束的最优控制问题提供了有前景的解决方案。

Abstract: We study optimal trade execution with a hard-zero terminal inventory constraint, modeled via Hamilton-Jacobi-Bellman (HJB) equations. Vanilla PINNs often under-enforce this constraint and produce unstable controls. We propose a Multi-Trajectory PINN (MT-PINN) that adds a rollout-based trajectory loss and propagates a terminal penalty on terminal inventory via backpropagation-through-time, directly enforcing zero terminal inventory. A lightweight lambda-curriculum is adopted to stabilize training as the state expands from a risk-neutral reduced HJB to a risk-averse HJB. On the Gatheral-Schied single-asset model, MT-PINN aligns closely with their derived closed-form solutions and concentrates terminal inventory tightly around zero while reducing errors along optimal paths. We apply MT-PINNs on SPY intraday data, matching TWAP when risk-neutral, and achieving lower exposure and competitive costs, especially in falling windows, for higher risk-aversion.

</details>


### [166] [Solving a Machine Learning Regression Problem Based on the Theory of Random Functions](https://arxiv.org/abs/2512.12731)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: 论文从随机函数理论出发，基于无差别原理推导出回归方法，证明具有特定对称性的概率测度会自然导出广义多调和样条核函数，为平滑和插值方法提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 为机器学习回归问题提供理论基础，从第一性原理出发推导回归方法，而不是经验选择核函数和正则化形式。

Method: 使用随机函数理论框架，基于无差别原理的公设，推导具有平移、旋转、缩放不变性和高斯性的概率测度下的回归方法。

Result: 证明具有自然对称性的概率测度会解析地导出核函数形式、正则化类型和噪声参数化，得到的核函数与广义多调和样条一致。

Conclusion: 该结果为一大类平滑和插值方法提供了理论基础，证明了在缺乏先验信息的情况下这些方法的最优性。

Abstract: This paper studies a machine learning regression problem as a multivariate approximation problem using the framework of the theory of random functions. An ab initio derivation of a regression method is proposed, starting from postulates of indifference. It is shown that if a probability measure on an infinite-dimensional function space possesses natural symmetries (invariance under translation, rotation, scaling, and Gaussianity), then the entire solution scheme, including the kernel form, the type of regularization, and the noise parameterization, follows analytically from these postulates. The resulting kernel coincides with a generalized polyharmonic spline; however, unlike existing approaches, it is not chosen empirically but arises as a consequence of the indifference principle. This result provides a theoretical foundation for a broad class of smoothing and interpolation methods, demonstrating their optimality in the absence of a priori information.

</details>


### [167] [SPARK: Igniting Communication-Efficient Decentralized Learning via Stage-wise Projected NTK and Accelerated Regularization](https://arxiv.org/abs/2512.12737)
*Li Xia*

Main category: cs.LG

TL;DR: SPARK：一种用于去中心化联邦学习的高效通信框架，通过随机投影压缩Jacobian矩阵、阶段式退火蒸馏和Nesterov动量加速，在减少98.7%通信开销的同时保持收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习面临统计异质性和通信开销的挑战。现有的NTK方法虽然收敛快，但传输完整的Jacobian矩阵在带宽受限的边缘网络中不切实际。

Method: SPARK框架整合了三个关键技术：1）基于随机投影的Jacobian压缩，在保持收敛所需谱特性的同时大幅减少通信量；2）阶段式退火蒸馏，从纯NTK演化过渡到邻居正则化学习，抵消压缩噪声；3）Nesterov动量加速，通过蒸馏平滑实现稳定积累，加快收敛。

Result: SPARK相比NTK-DFL减少了98.7%的通信开销，同时保持收敛速度并获得更优的准确率。结合动量后，达到目标性能的速度提高了3倍，在通信效率方面达到最先进水平。

Conclusion: SPARK为带宽受限的边缘环境提供了一种实用的去中心化学习解决方案，通过协同整合压缩、蒸馏和动量技术，在保持性能的同时大幅降低通信需求。

Abstract: Decentralized federated learning (DFL) faces critical challenges from statistical heterogeneity and communication overhead. While NTK-based methods achieve faster convergence, transmitting full Jacobian matrices is impractical for bandwidth-constrained edge networks. We propose SPARK, synergistically integrating random projection-based Jacobian compression, stage-wise annealed distillation, and Nesterov momentum acceleration. Random projections compress Jacobians while preserving spectral properties essential for convergence. Stage-wise annealed distillation transitions from pure NTK evolution to neighbor-regularized learning, counteracting compression noise. Nesterov momentum accelerates convergence through stable accumulation enabled by distillation smoothing. SPARK achieves 98.7% communication reduction compared to NTK-DFL while maintaining convergence speed and superior accuracy. With momentum, SPARK reaches target performance 3 times faster, establishing state-of-the-art results for communication-efficient decentralized learning and enabling practical deployment in bandwidth-limited edge environments.

</details>


### [168] [Resting Neurons, Active Insights: Improving Input Sparsification for Large Language Models](https://arxiv.org/abs/2512.12744)
*Haotian Xu,Tian Gao,Tsui-Wei Weng,Tengfei Ma*

Main category: cs.LG

TL;DR: 该论文提出了一种通过引入可训练的自发神经元来稳定稀疏化LLMs激活的方法，以减少稀疏化带来的性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有的输入稀疏化方法主要关注计算效率，但忽视了稀疏化对模型表示能力的影响，导致与完整模型相比存在明显的性能差距。

Method: 将输入稀疏化重新解释为动态结构剪枝，并受生物神经元自发基线放电率的启发，引入一组小型可训练的自发神经元作为补偿单元来稳定稀疏化LLMs的激活。

Result: 实验表明，这些辅助神经元显著减少了稀疏化引起的性能差距，并在不同任务上表现出良好的泛化能力。

Conclusion: 通过引入自发神经元作为补偿单元，可以在保持输入稀疏化计算效率优势的同时，有效缓解稀疏化对LLMs表示能力的负面影响。

Abstract: Large Language Models (LLMs) achieve state-of-the-art performance across a wide range of applications, but their massive scale poses significant challenges for both efficiency and interpretability. Structural pruning, which reduces model size by removing redundant computational units such as neurons, has been widely explored as a solution, and this study devotes to input sparsification, an increasingly popular technique that improves efficiency by selectively activating only a subset of entry values for each input. However, existing approaches focus primarily on computational savings, often overlooking the representational consequences of sparsification and leaving a noticeable performance gap compared to full models. In this work, we first reinterpret input sparsification as a form of dynamic structural pruning. Motivated by the spontaneous baseline firing rates observed in biological neurons, we introduce a small set of trainable spontaneous neurons that act as compensatory units to stabilize activations in sparsified LLMs. Experiments demonstrate that these auxiliary neurons substantially reduce the sparsification-induced performance gap while generalizing effectively across tasks.

</details>


### [169] [Federated Learning with Feedback Alignment](https://arxiv.org/abs/2512.12762)
*Incheol Baek,Hyungbin Kim,Minseo Kim,Yon Dohn Chung*

Main category: cs.LG

TL;DR: FLFA框架通过将反馈对齐集成到联邦学习中，使用全局模型权重作为共享反馈矩阵来对齐本地更新，有效缓解非IID数据下的本地漂移问题，且计算和通信开销小。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在数据隐私保护方面有优势，但在非独立同分布（non-IID）数据场景下面临本地漂移问题，这会阻碍全局模型的收敛。现有方法需要解决数据异构性带来的挑战。

Method: 提出FLFA框架，将反馈对齐技术集成到联邦学习中。在本地训练的反向传播过程中，使用全局模型的权重作为共享反馈矩阵，从而对齐本地更新与全局模型，缓解本地漂移。

Result: 理论分析表明FLFA能有效缓解本地漂移，并证明本地和全局模型都有稳健的收敛性。实证评估显示FLFA在准确率比较和本地漂移测量方面优于其他FL方法，且能增强现有FL方法的性能。

Conclusion: FLFA通过反馈对齐机制有效解决了联邦学习中的非IID数据问题，以最小的额外计算成本和零额外通信开销缓解了本地漂移，提升了全局模型的收敛性能。

Abstract: Federated Learning (FL) enables collaborative training across multiple clients while preserving data privacy, yet it struggles with data heterogeneity, where clients' data are not distributed independently and identically (non-IID). This causes local drift, hindering global model convergence. To address this, we introduce Federated Learning with Feedback Alignment (FLFA), a novel framework that integrates feedback alignment into FL. FLFA uses the global model's weights as a shared feedback matrix during local training's backward pass, aligning local updates with the global model efficiently. This approach mitigates local drift with minimal additional computational cost and no extra communication overhead.
  Our theoretical analysis supports FLFA's design by showing how it alleviates local drift and demonstrates robust convergence for both local and global models. Empirical evaluations, including accuracy comparisons and measurements of local drift, further illustrate that FLFA can enhance other FL methods demonstrating its effectiveness.

</details>


### [170] [OLR-WAA: Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Averaging](https://arxiv.org/abs/2512.12779)
*Mohammad Abu-Shaira,Weishi Shi*

Main category: cs.LG

TL;DR: OLR-WAA是一种无超参数的在线回归模型，通过动态加权平均和概念漂移检测机制，在非平稳数据流中实现稳定性和适应性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集经常呈现不断演变的数据分布（概念漂移），忽视这一现象会显著降低模型预测性能。现有在线模型的超参数通常是固定的，缺乏动态适应变化数据的能力。

Method: 提出OLR-WAA模型：1）使用指数加权移动平均增量更新基础模型；2）引入独特的优化机制，动态检测概念漂移、量化其幅度，并根据实时数据特征调整模型；3）采用保守更新策略处理基于置信度的场景，优先考虑稳定、高置信度的数据点。

Result: 1）在静态设置中匹配批量回归性能；2）在概念漂移数据集上持续优于或媲美最先进的在线模型；3）有效弥补其他在线模型的性能差距；4）收敛速度快，始终产生比其他在线模型更高的R2值。

Conclusion: OLR-WAA是一种有效的无超参数在线回归模型，能够处理非平稳数据流，在概念漂移环境中实现稳定性和适应性的良好平衡，为在线学习提供了强大的解决方案。

Abstract: Real-world datasets frequently exhibit evolving data distributions, reflecting temporal variations and underlying shifts. Overlooking this phenomenon, known as concept drift, can substantially degrade the predictive performance of the model. Furthermore, the presence of hyperparameters in online models exacerbates this issue, as these parameters are typically fixed and lack the flexibility to dynamically adjust to evolving data. This paper introduces "OLR-WAA: An Adaptive and Drift-Resilient Online Regression with Dynamic Weighted Average", a hyperparameter-free model designed to tackle the challenges of non-stationary data streams and enable effective, continuous adaptation. The objective is to strike a balance between model stability and adaptability. OLR-WAA incrementally updates its base model by integrating incoming data streams, utilizing an exponentially weighted moving average. It further introduces a unique optimization mechanism that dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on real-time data characteristics. Rigorous evaluations show that it matches batch regression performance in static settings and consistently outperforms or rivals state-of-the-art online models, confirming its effectiveness. Concept drift datasets reveal a performance gap that OLR-WAA effectively bridges, setting it apart from other online models. In addition, the model effectively handles confidence-based scenarios through a conservative update strategy that prioritizes stable, high-confidence data points. Notably, OLR-WAA converges rapidly, consistently yielding higher R2 values compared to other online models.

</details>


### [171] [Credit Risk Estimation with Non-Financial Features: Evidence from a Synthetic Istanbul Dataset](https://arxiv.org/abs/2512.12783)
*Atalay Denknalbant,Emre Sezdi,Zeki Furkan Kutlu,Polat Goktas*

Main category: cs.LG

TL;DR: 研究使用合成数据证明，对于缺乏正式信用记录的伊斯坦布尔居民，行为属性数据（如手机使用、消费模式等）能显著提升信用评估效果，接近传统征信水平。


<details>
  <summary>Details</summary>
Motivation: 金融排斥限制了创业机会、增加了收入波动并扩大了财富差距。伊斯坦布尔的银行服务不足人群由于收入通过非正规渠道流动，往往没有征信记录。需要研究如何评估这类借款人的信用风险。

Method: 创建了10万伊斯坦布尔居民的合成数据集，复制了2025年第一季度土耳其统计局人口统计边际和电信使用模式。使用检索增强生成技术将公共统计数据输入OpenAI o3模型，生成真实但私密的记录。每个档案包含7个社会人口变量和9个替代属性（手机规格、网购节奏、订阅支出、汽车所有权、月租金、信用卡标志）。使用CatBoost、LightGBM和XGBoost训练两个版本模型：演示模型仅使用社会人口变量，完整模型同时使用社会人口和替代属性。

Result: 通过五折分层验证，替代属性块将AUC提高了约1.3个百分点，将平衡F1分数从约0.84提升到0.95，增益达14%。行为属性能够接近征信水平的区分能力。

Conclusion: 研究贡献了开放的伊斯坦布尔2025年第一季度合成数据集、完全可复现的建模流程，以及经验证据表明简洁的行为属性集能够接近征信水平的区分能力，同时服务于缺乏正式信用记录的借款人。这些发现为贷款机构和监管机构提供了扩展公平安全信贷接入的透明蓝图。

Abstract: Financial exclusion constrains entrepreneurship, increases income volatility, and widens wealth gaps. Underbanked consumers in Istanbul often have no bureau file because their earnings and payments flow through informal channels. To study how such borrowers can be evaluated we create a synthetic dataset of one hundred thousand Istanbul residents that reproduces first quarter 2025 TÜİK census marginals and telecom usage patterns. Retrieval augmented generation feeds these public statistics into the OpenAI o3 model, which synthesises realistic yet private records. Each profile contains seven socio demographic variables and nine alternative attributes that describe phone specifications, online shopping rhythm, subscription spend, car ownership, monthly rent, and a credit card flag. To test the impact of the alternative financial data CatBoost, LightGBM, and XGBoost are each trained in two versions. Demo models use only the socio demographic variables; Full models include both socio demographic and alternative attributes. Across five fold stratified validation the alternative block raises area under the curve by about one point three percentage and lifts balanced \(F_{1}\) from roughly 0.84 to 0.95, a fourteen percent gain. We contribute an open Istanbul 2025 Q1 synthetic dataset, a fully reproducible modeling pipeline, and empirical evidence that a concise set of behavioural attributes can approach bureau level discrimination power while serving borrowers who lack formal credit records. These findings give lenders and regulators a transparent blueprint for extending fair and safe credit access to the underbanked.

</details>


### [172] [OLC-WA: Drift Aware Tuning-Free Online Classification with Weighted Average](https://arxiv.org/abs/2512.12785)
*Mohammad Abu Shaira,Yunhe Feng,Heng Fan,Weishi Shi*

Main category: cs.LG

TL;DR: OLC-WA是一种自适应、无超参数的在线分类模型，通过加权平均和自动优化机制处理概念漂移，在动态数据流中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集常存在概念漂移现象，忽略这一现象会显著降低模型预测准确性。现有在线模型的超参数通常是固定的，无法根据数据分布变化动态调整，这加剧了概念漂移问题。

Method: 提出OLC-WA模型，通过指数加权移动平均将新数据流与基础模型融合。集成优化机制能动态检测概念漂移、量化其幅度，并根据观测到的数据流特征调整模型。

Result: 在多种基准数据集上的实证评估显示：在稳定环境中，OLC-WA性能与批处理模型相当，准确率差距在1-3%内；在存在漂移的情况下，OLC-WA超越主流在线基线模型10-25%。

Conclusion: OLC-WA是一种有效的自适应在线分类模型，无需超参数调整，能有效适应动态数据流中的概念漂移，在稳定和动态环境中都表现出色。

Abstract: Real-world data sets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. This paper introduces Online Classification with Weighted Average (OLC-WA), an adaptive, hyperparameter-free online classification model equipped with an automated optimization mechanism. OLC-WA operates by blending incoming data streams with an existing base model. This blending is facilitated by an exponentially weighted moving average. Furthermore, an integrated optimization mechanism dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on the observed data stream characteristics. This approach empowers the model to effectively adapt to evolving data distributions within streaming environments. Rigorous empirical evaluation across diverse benchmark datasets shows that OLC-WA achieves performance comparable to batch models in stationary environments, maintaining accuracy within 1-3%, and surpasses leading online baselines by 10-25% under drift, demonstrating its effectiveness in adapting to dynamic data streams.

</details>


### [173] [Unveiling Statistical Significance of Online Regression over Multiple Datasets](https://arxiv.org/abs/2512.12787)
*Mohammad Abu-Shaira,Weishi Shi*

Main category: cs.LG

TL;DR: 该论文提出使用Friedman检验和事后检验来比较多个在线回归模型在不同数据集上的性能，解决了机器学习研究中多算法跨数据集比较统计检验的空白问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习研究缺乏比较多个算法在不同数据集上性能的统计检验方法，特别是在在线学习领域，需要统计显著性验证来确保连续学习过程的可靠性，处理概念漂移并实现快速收敛。

Method: 使用Friedman检验和相应的事后检验来比较多个在线回归模型在不同数据集上的性能。采用真实和合成数据集，结合5折交叉验证和种子平均进行综合评估。

Result: 测试总体上确认了竞争基线的性能与其单独报告一致，但某些统计检验结果表明最先进方法在某些方面仍有改进空间。

Conclusion: 需要稳健的统计方法来评估在线学习过程中性能差异的显著性，Friedman检验和事后检验为多算法跨数据集比较提供了有效工具，但当前最先进方法仍有优化空间。

Abstract: Despite extensive focus on techniques for evaluating the performance of two learning algorithms on a single dataset, the critical challenge of developing statistical tests to compare multiple algorithms across various datasets has been largely overlooked in most machine learning research. Additionally, in the realm of Online Learning, ensuring statistical significance is essential to validate continuous learning processes, particularly for achieving rapid convergence and effectively managing concept drifts in a timely manner. Robust statistical methods are needed to assess the significance of performance differences as data evolves over time. This article examines the state-of-the-art online regression models and empirically evaluates several suitable tests. To compare multiple online regression models across various datasets, we employed the Friedman test along with corresponding post-hoc tests. For thorough evaluations, utilizing both real and synthetic datasets with 5-fold cross-validation and seed averaging ensures comprehensive assessment across various data subsets. Our tests generally confirmed the performance of competitive baselines as consistent with their individual reports. However, some statistical test results also indicate that there is still room for improvement in certain aspects of state-of-the-art methods.

</details>


### [174] [Liquid Reasoning Transformers: A Sudoku-Based Prototype for Chess-Scale Algorithmic Tasks](https://arxiv.org/abs/2512.12792)
*Shivansh Sahni,Wenzhi Zhang*

Main category: cs.LG

TL;DR: LRT是一种具有自适应推理深度的Transformer架构，通过迭代更新、丢弃校正和学习停止机制，在结构化推理任务（如数独）上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在单次前向传播中进行推理，难以纠正早期错误或根据输入难度调整计算量。需要一种能够自适应调整推理深度、支持迭代校正的架构。

Method: 提出Liquid Reasoning Transformer，使用循环推理token进行多步内部迭代更新，包含丢弃门校正早期错误、学习停止机制自适应确定计算深度。

Result: 在数独任务上达到98.68%数字准确率和36.30%完整谜题准确率，无需符号规则或搜索。分析显示丢弃门和停止门在稳定推理和调整计算深度中发挥重要作用。

Conclusion: LRT为结构化推理提供了有效的自适应深度架构，其机制可扩展到国际象棋等更大规模推理任务，并支持多token推理和更大领域的扩展。

Abstract: The Liquid Reasoning Transformer (LRT) is a transformer architecture designed for inference with adaptive depths using iterative changes, discard-based correction, and a learned stopping mechanism. Instead of relying on a single feedforward pass, the model updates a recurrent reasoning token across multiple internal steps, allowing it to correct early errors and allocate computation based on input difficulty. We evaluate the LRT on Sudoku as a controlled testbed for structured reasoning and show that it achieves strong performance, reaching 98.68% digit accuracy and 36.30% full-puzzle accuracy without using symbolic rules or search. Analyzing internal patterns shows that the discard and stop gates play different, important roles in stabilizing inferences and adjusting computational depth. We discuss how these mechanisms extend naturally to chess-scale reasoning tasks and outline extensions for multi-token reasoning and larger domains.

</details>


### [175] [TRACER: Transfer Learning based Real-time Adaptation for Clinical Evolving Risk](https://arxiv.org/abs/2512.12795)
*Mengying Yan,Ziye Tian,Siqi Li,Nan Liu,Benjamin A. Goldstein,Molei Liu,Chuan Hong*

Main category: cs.LG

TL;DR: TRACER框架通过迁移学习实时适应临床环境变化，解决电子健康记录预测模型因人口结构变化导致的性能漂移问题


<details>
  <summary>Details</summary>
Motivation: 临床决策支持工具基于电子健康记录构建，常因时间性人口结构变化而出现性能漂移。当临床环境变化最初仅影响部分患者时，会导致混合人群的过渡状态，这种情况常见于系统级操作更新或新疾病（如COVID-19）出现时

Method: 提出TRACER框架，通过识别就诊级别的过渡成员身份，并使用迁移学习调整预测模型，无需完全重新训练。该方法在模拟研究中验证了有效性

Result: 在模拟研究中，TRACER优于基于历史或当代数据训练的静态模型。在实际应用中，预测急诊就诊后住院情况跨越COVID-19过渡期，TRACER提高了判别能力和校准性能

Conclusion: TRACER提供了一种可扩展的方法，可在不断演变和异质的临床条件下保持稳健的预测性能，有效应对临床环境变化带来的挑战

Abstract: Clinical decision support tools built on electronic health records often experience performance drift due to temporal population shifts, particularly when changes in the clinical environment initially affect only a subset of patients, resulting in a transition to mixed populations. Such case-mix changes commonly arise following system-level operational updates or the emergence of new diseases, such as COVID-19. We propose TRACER (Transfer Learning-based Real-time Adaptation for Clinical Evolving Risk), a framework that identifies encounter-level transition membership and adapts predictive models using transfer learning without full retraining. In simulation studies, TRACER outperformed static models trained on historical or contemporary data. In a real-world application predicting hospital admission following emergency department visits across the COVID-19 transition, TRACER improved both discrimination and calibration. TRACER provides a scalable approach for maintaining robust predictive performance under evolving and heterogeneous clinical conditions.

</details>


### [176] [From Small to Large: Generalization Bounds for Transformers on Variable-Size Inputs](https://arxiv.org/abs/2512.12805)
*Anastasiia Alokhina,Pan Li*

Main category: cs.LG

TL;DR: 本文为Transformer在几何数据上的尺寸泛化能力提供了理论框架，证明了离散样本输出与连续域等价输出之间的误差界限，该界限由采样密度和数据流形内在维度决定。


<details>
  <summary>Details</summary>
Motivation: Transformer在各种应用中表现出尺寸泛化能力，能够从小规模标记集外推到更大规模，但这种能力缺乏严格的理论表征。本文旨在为几何数据的这种现象提供理论分析框架。

Method: 开发理论框架分析几何数据的尺寸泛化现象，将几何数据表示为连续源的离散样本（如流形上的点云、图论中的图）。核心贡献是推导Transformer离散样本输出与连续域等价输出之间的误差界限。

Result: 证明了对于具有稳定位置编码的Transformer，误差界限由采样密度和数据流形的内在维度决定。在不同尺寸的图和点云上的实验证实了理论界限的紧致性。

Conclusion: 本文为Transformer在几何数据上的尺寸泛化能力提供了严格的理论基础，揭示了采样密度和内在维度对泛化性能的关键影响，并通过实验验证了理论结果的有效性。

Abstract: Transformers exhibit a notable property of \emph{size generalization}, demonstrating an ability to extrapolate from smaller token sets to significantly longer ones. This behavior has been documented across diverse applications, including point clouds, graphs, and natural language. Despite its empirical success, this capability still lacks some rigorous theoretical characterizations. In this paper, we develop a theoretical framework to analyze this phenomenon for geometric data, which we represent as discrete samples from a continuous source (e.g., point clouds from manifolds, graphs from graphons). Our core contribution is a bound on the error between the Transformer's output for a discrete sample and its continuous-domain equivalent. We prove that for Transformers with stable positional encodings, this bound is determined by the sampling density and the intrinsic dimensionality of the data manifold. Experiments on graphs and point clouds of various sizes confirm the tightness of our theoretical bound.

</details>


### [177] [Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift](https://arxiv.org/abs/2512.12816)
*Hasan Burhan Beytur,Gustavo de Veciana,Haris Vikalo,Kevin S Chan*

Main category: cs.LG

TL;DR: 论文研究在概念漂移和有限预算下如何分配机器学习模型的训练和部署资源，提出了一个模型无关的框架，分析了资源分配、概念漂移动态和部署时机的相互作用。


<details>
  <summary>Details</summary>
Motivation: 在分布式机器学习系统中，模型提供者需要向多个客户端分发训练好的模型，但客户端设备通常只支持本地推理而无法重新训练模型，因此性能维护的负担完全落在提供者身上。同时面临概念漂移和预算限制的挑战，需要理论指导来优化资源分配。

Method: 提出了一个模型无关的框架，捕获资源分配、概念漂移动态和部署时机的相互作用。针对概念突然变化的情况，在预算约束下推导了最优训练策略，分析了概念持续时间分布的平均剩余寿命特性。还研究了通信约束下的模型部署问题，证明了相关优化问题的拟凸性，并提出了随机调度策略。

Result: 发现最优训练策略关键取决于概念持续时间的老化特性：在平均剩余寿命递减分布下可以推导出最优策略，而在平均剩余寿命递增分布下直观启发式方法被证明是次优的。对于部署问题，证明了优化问题的拟凸性，提出的随机调度策略能够实现接近最优的客户端性能。

Conclusion: 该研究为概念漂移下的成本高效机器学习模型管理提供了理论和算法基础，对持续学习、分布式推理和自适应机器学习系统具有重要启示，展示了概念漂移动态对资源分配策略的关键影响。

Abstract: We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain those models, placing the burden of performance maintenance on the provider. We introduce a model-agnostic framework that captures the interaction between resource allocation, concept drift dynamics, and deployment timing. We show that optimal training policies depend critically on the aging properties of concept durations. Under sudden concept changes, we derive optimal training policies subject to budget constraints when concept durations follow distributions with Decreasing Mean Residual Life (DMRL), and show that intuitive heuristics are provably suboptimal under Increasing Mean Residual Life (IMRL). We further study model deployment under communication constraints, prove that the associated optimization problem is quasi-convex under mild conditions, and propose a randomized scheduling strategy that achieves near-optimal client-side performance. These results offer theoretical and algorithmic foundations for cost-efficient ML model management under concept drift, with implications for continual learning, distributed inference, and adaptive ML systems.

</details>


### [178] [On the continuity of flows](https://arxiv.org/abs/2512.12821)
*Congzhou M Sha*

Main category: cs.LG

TL;DR: 流匹配中拓扑不匹配会导致最优速度场出现空间不连续性，当先验分布和目标分布拓扑结构不匹配时，粒子需要在中间时间做出离散路由决策。


<details>
  <summary>Details</summary>
Motivation: 研究流匹配框架中拓扑约束问题：当先验分布和目标分布拓扑结构不匹配时，标准流匹配目标下的最优速度场可能出现空间不连续性，这可能影响生成建模效果。

Method: 通过理论分析双模态高斯混合模型，证明最优速度场在决策边界处存在跳跃不连续性；进行实证验证，并讨论流匹配在流形上的潜在影响。

Result: 最优速度场在决策边界处表现出跳跃不连续性，其幅度随时间接近目标分布而趋于无穷大；这种现象不是L^2损失特有的，而是分布间拓扑不匹配的结果。

Conclusion: 拓扑不匹配会导致流匹配中的速度场不连续性，这为理解流匹配在复杂分布上的局限性提供了理论依据，并与黎曼流匹配和神经网络学习不连续表示等近期工作相联系。

Abstract: Flow matching has emerged as a powerful framework for generative modeling through continuous normalizing flows. We investigate a potential topological constraint: when the prior distribution and target distribution have mismatched topology (e.g., unimodal to multimodal), the optimal velocity field under standard flow matching objectives may exhibit spatial discontinuities. We suggest that this discontinuity arises from the requirement that continuous flows must bifurcate to map a single mode to multiple modes, forcing particles to make discrete routing decisions at intermediate times. Through theoretical analysis on bimodal Gaussian mixtures, we demonstrate that the optimal velocity field exhibits jump discontinuities along decision boundaries, with magnitude approaching infinity as time approaches the target distribution. Our analysis suggests that this phenomenon is not specific to $L^2$ loss, but rather may be a consequence of topological mismatch between distributions. We validate our theory empirically and discuss potential implications for flow matching on manifolds, connecting our findings to recent work on Riemannian flow matching and the challenge of learning discontinuous representations in neural networks.

</details>


### [179] [GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients](https://arxiv.org/abs/2512.12827)
*Mohammad Mahdi Razmjoo,Mohammad Mahdi Sharifian,Saeed Bagheri Shouraki*

Main category: cs.LG

TL;DR: 该论文提出基于模型梯度参数内在维度（ID）的对抗样本检测方法，通过分析输入损失空间的几何特性，发现自然数据和对抗数据在ID上存在显著差异，从而构建检测器。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络对微小对抗扰动具有脆弱性，而医疗诊断和自动驾驶等应用对可靠性要求极高，因此需要有效的对抗攻击检测方法。

Method: 分析模型输入损失空间的几何特性，研究模型梯度参数的内在维度（ID），利用自然数据和对抗数据在ID上的显著差异构建检测器。

Result: 在批量检测场景中，在MNIST和SVHN数据集上表现出高效性；在单样本检测场景中，在CIFAR-10和MS COCO等挑战性基准上达到新的SOTA结果，对CW和AutoAttack等多种攻击的检测率在CIFAR-10上持续超过92%。

Conclusion: 内在维度是跨不同数据集和攻击策略的强大对抗检测指纹，几何方法具有鲁棒性，为对抗样本检测提供了有效的新途径。

Abstract: Despite their remarkable performance, deep neural networks exhibit a critical vulnerability: small, often imperceptible, adversarial perturbations can lead to drastically altered model predictions. Given the stringent reliability demands of applications such as medical diagnosis and autonomous driving, robust detection of such adversarial attacks is paramount. In this paper, we investigate the geometric properties of a model's input loss landscape. We analyze the Intrinsic Dimensionality (ID) of the model's gradient parameters, which quantifies the minimal number of coordinates required to describe the data points on their underlying manifold. We reveal a distinct and consistent difference in the ID for natural and adversarial data, which forms the basis of our proposed detection method. We validate our approach across two distinct operational scenarios. First, in a batch-wise context for identifying malicious data groups, our method demonstrates high efficacy on datasets like MNIST and SVHN. Second, in the critical individual-sample setting, we establish new state-of-the-art results on challenging benchmarks such as CIFAR-10 and MS COCO. Our detector significantly surpasses existing methods against a wide array of attacks, including CW and AutoAttack, achieving detection rates consistently above 92\% on CIFAR-10. The results underscore the robustness of our geometric approach, highlighting that intrinsic dimensionality is a powerful fingerprint for adversarial detection across diverse datasets and attack strategies.

</details>


### [180] [Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future](https://arxiv.org/abs/2512.12832)
*Kaustav Chatterjee,Joshua Li,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 开发了一个评估铁路公路平交道口(HRGC)悬挂风险的网络级框架，结合激光成像、深度学习和车辆尺寸数据，识别高风险道口并提供决策支持工具。


<details>
  <summary>Details</summary>
Motivation: 陡峭的铁路公路平交道口对低底盘车辆构成安全隐患，车辆可能卡在轨道上导致火车碰撞事故，需要系统性的风险评估方法。

Method: 1) 使用步行剖面仪和Pave3D8K激光成像系统收集道口剖面数据；2) 开发LSTM-Transformer混合深度学习模型重建准确的道口剖面；3) 收集约350辆特种车辆的尺寸数据；4) 采用三种车辆尺寸场景分析悬挂风险；5) 开发ArcGIS数据库和软件界面。

Result: 在不同车辆尺寸场景下，分别识别出36、62和67个最高悬挂风险的道口。开发了实用的决策支持工具，帮助交通机构缓解道口危险。

Conclusion: 该框架通过整合新一代传感技术、深度学习和基础设施数据，为铁路公路平交道口的安全评估提供了先进的决策支持工具，有助于提升交通安全。

Abstract: Steep profiled Highway Railway Grade Crossings (HRGCs) pose safety hazards to vehicles with low ground clearance, which may become stranded on the tracks, creating risks of train vehicle collisions. This research develops a framework for network level evaluation of hangup susceptibility of HRGCs. Profile data from different crossings in Oklahoma were collected using both a walking profiler and the Pave3D8K Laser Imaging System. A hybrid deep learning model, combining Long Short Term Memory (LSTM) and Transformer architectures, was developed to reconstruct accurate HRGC profiles from Pave3D8K Laser Imaging System data. Vehicle dimension data from around 350 specialty vehicles were collected at various locations across Oklahoma to enable up to date statistical design dimensions. Hangup susceptibility was analyzed using three vehicle dimension scenarios (a) median dimension (median wheelbase and ground clearance), (b) 75 25 percentile dimension (75 percentile wheelbase, 25 percentile ground clearance), and (c) worst case dimension (maximum wheelbase and minimum ground clearance). Results indicate 36, 62, and 67 crossings at the highest hangup risk levels under these scenarios, respectively. An ArcGIS database and a software interface were developed to support transportation agencies in mitigating crossing hazards. This framework advances safety evaluation by integrating next generation sensing, deep learning, and infrastructure datasets into practical decision support tools.

</details>


### [181] [PRIVEE: Privacy-Preserving Vertical Federated Learning Against Feature Inference Attacks](https://arxiv.org/abs/2512.12840)
*Sindhuja Madabushi,Ahmad Faraz Khan,Haider Ali,Ananthram Swami,Rui Ning,Hongyi Wu,Jin-Hee Cho*

Main category: cs.LG

TL;DR: PRIVEE是一种保护垂直联邦学习中隐私的防御机制，通过混淆置信度分数来防止特征推断攻击，同时保持模型预测准确性。


<details>
  <summary>Details</summary>
Motivation: 垂直联邦学习(VFL)允许组织在共享用户样本但特征空间分离的情况下协作训练模型，但VFL容易受到特征推断攻击，攻击者可以利用推理过程中共享的置信度分数来重构其他参与者的私有输入特征。

Method: 提出PRIVEE防御机制，通过混淆置信度分数来保护隐私，同时保持相对排名和分数间距离等关键属性。不暴露原始分数，只共享转换后的表示，从而在不降低模型预测准确性的情况下减轻重构攻击风险。

Result: 大量实验表明，PRIVEE在隐私保护方面比最先进的防御方法提高了三倍，同时在对抗高级特征推断攻击时保持了完整的预测性能。

Conclusion: PRIVEE是一种有效的隐私保护机制，能够在垂直联邦学习中提供强大的隐私保护，同时不牺牲模型预测准确性，为解决特征推断攻击问题提供了实用解决方案。

Abstract: Vertical Federated Learning (VFL) enables collaborative model training across organizations that share common user samples but hold disjoint feature spaces. Despite its potential, VFL is susceptible to feature inference attacks, in which adversarial parties exploit shared confidence scores (i.e., prediction probabilities) during inference to reconstruct private input features of other participants. To counter this threat, we propose PRIVEE (PRIvacy-preserving Vertical fEderated lEarning), a novel defense mechanism named after the French word privée, meaning "private." PRIVEE obfuscates confidence scores while preserving critical properties such as relative ranking and inter-score distances. Rather than exposing raw scores, PRIVEE shares only the transformed representations, mitigating the risk of reconstruction attacks without degrading model prediction accuracy. Extensive experiments show that PRIVEE achieves a threefold improvement in privacy protection compared to state-of-the-art defenses, while preserving full predictive performance against advanced feature inference attacks.

</details>


### [182] [Selective Conformal Risk Control](https://arxiv.org/abs/2512.12844)
*Yunpeng Xu,Wenge Guo,Zhi Wei*

Main category: cs.LG

TL;DR: 提出选择性共形风险控制（SCRC）框架，将共形预测与选择性分类结合，通过两阶段方法在保持覆盖率保证的同时减少预测集大小，提供更紧凑可靠的uncertainty quantification。


<details>
  <summary>Details</summary>
Motivation: 共形预测虽然能提供分布无关的覆盖率保证，但通常产生过大的预测集，限制了实际应用价值。需要一种方法在保持可靠性的同时减少预测集大小。

Method: 提出选择性共形风险控制（SCRC）框架，分为两阶段：第一阶段选择置信度高的样本进行预测，第二阶段在选定子集上应用共形风险控制构建校准的预测集。开发了两种算法：SCRC-T（保持可交换性，提供精确有限样本保证）和SCRC-I（仅校准变体，提供PAC式概率保证，计算更高效）。

Result: 在两个公共数据集上的实验表明，两种方法都能达到目标覆盖率和风险水平，性能几乎相同。SCRC-I表现出略微保守的风险控制，但计算实用性更优。

Conclusion: 选择性共形风险控制为紧凑可靠的uncertainty quantification提供了有效且高效的路径，解决了传统共形预测预测集过大的问题。

Abstract: Reliable uncertainty quantification is essential for deploying machine learning systems in high-stakes domains. Conformal prediction provides distribution-free coverage guarantees but often produces overly large prediction sets, limiting its practical utility. To address this issue, we propose \textit{Selective Conformal Risk Control} (SCRC), a unified framework that integrates conformal prediction with selective classification. The framework formulates uncertainty control as a two-stage problem: the first stage selects confident samples for prediction, and the second stage applies conformal risk control on the selected subset to construct calibrated prediction sets. We develop two algorithms under this framework. The first, SCRC-T, preserves exchangeability by computing thresholds jointly over calibration and test samples, offering exact finite-sample guarantees. The second, SCRC-I, is a calibration-only variant that provides PAC-style probabilistic guarantees while being more computational efficient. Experiments on two public datasets show that both methods achieve the target coverage and risk levels, with nearly identical performance, while SCRC-I exhibits slightly more conservative risk control but superior computational practicality. Our results demonstrate that selective conformal risk control offers an effective and efficient path toward compact, reliable uncertainty quantification.

</details>


### [183] [Information-Consistent Language Model Recommendations through Group Relative Policy Optimization](https://arxiv.org/abs/2512.12858)
*Sonal Prabhune,Balaji Padmanabhan,Kaushik Dutta*

Main category: cs.LG

TL;DR: 提出基于GRPO的强化学习框架，优化LLM在语义等价提示下的回答一致性，解决企业场景中信息交付的稳定性问题


<details>
  <summary>Details</summary>
Motivation: LLM在金融、教育、医疗等关键业务领域部署时，对语义相同但表述不同的提示会产生不一致的回答，这损害了用户信任、合规性和用户体验。企业场景如HR入职、客户支持、政策披露等需要信息交付的一致性，而现有方法无法保证这种稳定性。

Method: 提出基于Group Relative Policy Optimization (GRPO)的强化学习框架，将语义等价的提示变体视为组，通过基于熵的有用性和稳定性奖励，重置对话上下文以隔离措辞影响，直接优化LLM的一致性表现。

Result: 在投资和职位推荐任务上的实验表明，GRPO训练模型比微调或基于解码的基线方法更有效地减少变异性，实现了更好的信息一致性。

Conclusion: 这是GRPO在LLM信息一致性对齐方面的创新应用，将变异性重新定义为可纠正的缺陷而非生成多样性的可接受特征，为企业部署提供了解决方案。

Abstract: Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery regardless of phrasing or prior conversational history. Existing approaches, including retrieval-augmented generation (RAG) and temperature tuning, improve factuality or reduce stochasticity but cannot guarantee stability across equivalent prompts. In this paper, we propose a reinforcement learning framework based on Group Relative Policy Optimization (GRPO) to directly optimize for consistency. Unlike prior applications of GRPO, which have been limited to reasoning and code generation, we adapt GRPO to enforce stability of information content across groups of semantically equivalent prompts. We introduce entropy-based helpfulness and stability rewards, treating prompt variants as groups and resetting conversational context to isolate phrasing effects. Experiments on investment and job recommendation tasks show that our GRPO-trained model reduces variability more effectively than fine-tuning or decoding-based baselines. To our knowledge, this is a novel application of GRPO for aligning LLMs toward information consistency, reframing variability not as an acceptable feature of generative diversity but as a correctable flaw in enterprise deployments.

</details>


### [184] [Optimal Labeler Assignment and Sampling for Active Learning in the Presence of Imperfect Labels](https://arxiv.org/abs/2512.12870)
*Pouya Ahadi,Blair Winograd,Camille Zaug,Karunesh Arora,Lijun Wang,Kamran Paynabar*

Main category: cs.LG

TL;DR: 提出一种新颖的主动学习框架，通过优化分配查询样本给标注者来最小化标签噪声，提高分类性能


<details>
  <summary>Details</summary>
Motivation: 主动学习中标注者提供的标签常含有噪声，特别是复杂样本更容易被错误标注，这会导致分类器性能下降

Method: 1) 分配模型：优化分配查询点给标注者，最小化每个周期内最大可能噪声；2) 新采样方法：识别最佳查询点，减少标签噪声对分类器的影响

Result: 实验表明该方法相比多个基准方法显著提高了分类性能

Conclusion: 提出的主动学习框架通过最小化标签噪声有效构建了鲁棒的分类模型

Abstract: Active Learning (AL) has garnered significant interest across various application domains where labeling training data is costly. AL provides a framework that helps practitioners query informative samples for annotation by oracles (labelers). However, these labels often contain noise due to varying levels of labeler accuracy. Additionally, uncertain samples are more prone to receiving incorrect labels because of their complexity. Learning from imperfectly labeled data leads to an inaccurate classifier. We propose a novel AL framework to construct a robust classification model by minimizing noise levels. Our approach includes an assignment model that optimally assigns query points to labelers, aiming to minimize the maximum possible noise within each cycle. Additionally, we introduce a new sampling method to identify the best query points, reducing the impact of label noise on classifier performance. Our experiments demonstrate that our approach significantly improves classification performance compared to several benchmark methods.

</details>


### [185] [Improving Recursive Transformers with Mixture of LoRAs](https://arxiv.org/abs/2512.12880)
*Mohammadmahdi Nouriborji,Morteza Rohanian,Omid Rohanian*

Main category: cs.LG

TL;DR: MoL (Mixture of LoRAs) 通过轻量级条件计算机制，在共享前馈网络中插入LoRA专家，恢复递归transformer中因参数共享而损失的表达能力，实现紧凑模型的高性能。


<details>
  <summary>Details</summary>
Motivation: 递归transformer中的参数共享会减少模型大小，但会削弱层间表达能力。需要一种轻量级方法来恢复表达能力，同时保持参数效率。

Method: 提出MoL（Mixture of LoRAs），在共享前馈网络（FFN）中插入低秩适应（LoRA）专家，实现令牌条件权重空间调制。同时构建ModernALBERT架构，整合旋转嵌入、GeGLU、FlashAttention和基于蒸馏的初始化。

Result: ModernALBERT（50M-120M参数）在GLUE、SQuAD-v2和BEIR基准上达到紧凑模型的最先进性能，甚至超越更大的全参数化基线模型。还提出了专家合并程序，在推理时将MoL压缩为单一适配器。

Conclusion: 条件权重空间调制能有效恢复递归transformer中因激进参数共享而损失的表达能力。MoL提供了一种轻量级、高效的方法，在保持参数效率的同时提升模型性能。

Abstract: Parameter sharing in recursive transformers reduces model size but collapses layer-wise expressivity. We propose Mixture of LoRAs (MoL), a lightweight conditional-computation mechanism that inserts Low-Rank Adaptation (LoRA) experts inside a shared feed-forward network (FFN). MoL enables token-conditional weight-space modulation of the shared FFN without untying backbone parameters, unlike prior approaches that add fixed or externally attached adapters. We pretrain a modernised recursive architecture, ModernALBERT, integrating rotary embeddings, GeGLU, FlashAttention, and a distillation-based initialisation. Across GLUE, SQuAD-v2, and BEIR, ModernALBERT (50M--120M) achieves state-of-the-art performance among compact models and surpasses larger fully parameterised baselines. We also propose an expert-merging procedure that compresses MoL into a single adapter at inference while preserving accuracy, enabling efficient deployment. Our results show that conditional weight-space modulation effectively restores the expressivity lost under aggressive parameter sharing in recursive transformers.

</details>


### [186] [Unsupervised learning of multiscale switching dynamical system models from multimodal neural data](https://arxiv.org/abs/2512.12881)
*DongKyu Kim,Han-Lin Hsieh,Maryam M. Shanechi*

Main category: cs.LG

TL;DR: 提出一种无监督学习算法，用于学习多尺度神经观测数据的切换动力学系统模型，能同时处理连续和离散神经信号，在行为解码中优于单尺度和静态模型。


<details>
  <summary>Details</summary>
Motivation: 神经群体活动常表现出依赖于状态的切换动力学非平稳性，现有方法主要针对单一神经模态（连续高斯信号或离散泊松信号），但实际中常同时记录多模态神经数据来测量不同时空尺度的脑活动。此外，训练数据通常缺乏状态标签，这给学习切换动力学模型带来了挑战。

Method: 开发了一种新颖的无监督学习算法，仅使用多尺度神经观测数据来学习切换多尺度动力学系统模型的参数。该方法能同时处理连续和离散神经信号，无需状态标签。

Result: 在模拟和两个不同的实验数据集（不同运动任务中的多模态尖峰-LFP观测）上验证了方法。切换多尺度动力学系统模型比切换单尺度动力学模型更准确地解码行为，展示了多尺度神经融合的成功。此外，模型优于静态多尺度模型，说明了跟踪多模态神经数据中状态依赖非平稳性的重要性。

Conclusion: 该无监督学习框架通过利用多模态记录中的信息并纳入状态切换，能够更准确地建模复杂的多尺度神经动力学。这种方法有望提高脑机接口的性能和鲁棒性，并增进对行为神经基础的理解。

Abstract: Neural population activity often exhibits regime-dependent non-stationarity in the form of switching dynamics. Learning accurate switching dynamical system models can reveal how behavior is encoded in neural activity. Existing switching approaches have primarily focused on learning models from a single neural modality, either continuous Gaussian signals or discrete Poisson signals. However, multiple neural modalities are often recorded simultaneously to measure different spatiotemporal scales of brain activity, and all these modalities can encode behavior. Moreover, regime labels are typically unavailable in training data, posing a significant challenge for learning models of regime-dependent switching dynamics. To address these challenges, we develop a novel unsupervised learning algorithm that learns the parameters of switching multiscale dynamical system models using only multiscale neural observations. We demonstrate our method using both simulations and two distinct experimental datasets with multimodal spike-LFP observations during different motor tasks. We find that our switching multiscale dynamical system models more accurately decode behavior than switching single-scale dynamical models, showing the success of multiscale neural fusion. Further, our models outperform stationary multiscale models, illustrating the importance of tracking regime-dependent non-stationarity in multimodal neural data. The developed unsupervised learning framework enables more accurate modeling of complex multiscale neural dynamics by leveraging information in multimodal recordings while incorporating regime switches. This approach holds promise for improving the performance and robustness of brain-computer interfaces over time and for advancing our understanding of the neural basis of behavior.

</details>


### [187] [Distillation of Discrete Diffusion by Exact Conditional Distribution Matching](https://arxiv.org/abs/2512.12889)
*Yansong Gao,Yu Sun*

Main category: cs.LG

TL;DR: 提出基于条件分布匹配的离散扩散模型蒸馏方法，通过匹配教师模型和学生模型的条件分布来加速推理，无需近似模拟器或代理目标训练


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型(DDMs)生成分类数据效果很好，但推理时需要大量函数评估，导致采样成本高昂。现有加速方法要么依赖近似模拟器，要么需要训练新的学生模型和代理目标，不够理想。

Method: 提出基于条件分布匹配的蒸馏方法。关键观察是干净数据给定噪声状态的反向条件分布$p_{0\mid t}(x_0 \mid x_t)$可以通过中间时间进行马尔可夫分解，并能从边缘密度比和已知的前向CTMC核中恢复。利用这一结构定义蒸馏目标，直接匹配预训练教师模型和低NFE学生模型的条件分布，适用于单步和少步采样器。

Result: 该方法提供了一种简单而原则性的蒸馏替代方案，能够直接匹配条件分布，避免了现有方法的局限性。

Conclusion: 提出的条件分布匹配蒸馏方法为离散扩散模型加速提供了一种有效且原则性的解决方案，通过直接匹配教师和学生模型的条件分布来实现高效推理。

Abstract: Discrete diffusion models (DDMs) are a powerful class of generative models for categorical data, but they typically require many function evaluations for a single sample, making inference expensive. Existing acceleration methods either rely on approximate simulators, such as $τ$-leaping, or on distillation schemes that train new student models and auxiliary networks with proxy objectives. We propose a simple and principled distillation alternative based on \emph{conditional distribution matching}. Our key observation is that the reverse conditional distribution of clean data given a noisy state, $p_{0\mid t}(x_0 \mid x_t)$, admits a Markov decomposition through intermediate times and can be recovered from marginal density ratios and the known forward CTMC kernel. We exploit this structure to define distillation objectives that directly match conditional distributions between a pre-trained teacher and a low-NFE student, both for one-step and few-step samplers.

</details>


### [188] [Wait, Wait, Wait... Why Do Reasoning Models Loop?](https://arxiv.org/abs/2512.12895)
*Charilaos Pipis,Shivam Garg,Vasilis Kontonis,Vaishnavi Shrivastava,Akshay Krishnamurthy,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: 论文研究推理模型（如DeepSeek-R1）在低温度或贪婪解码时出现文本循环重复的问题，发现学习误差是主要原因，并提出两种机制解释循环产生，指出温度调节只是权宜之计而非根本解决方案。


<details>
  <summary>Details</summary>
Motivation: 推理模型在解决复杂问题时会产生长链思维，但在低温度或贪婪解码时经常出现文本循环重复的现象。本研究旨在探究这种现象的原因以及温度在其中扮演的角色。

Method: 使用开源推理模型进行研究，发现低温度下循环现象普遍。通过引入合成图推理任务，演示了两种机制：1）学习难度导致的风险规避机制；2）Transformer对时间相关错误的归纳偏置。分析不同温度下的表现差异。

Result: 研究发现：1）较大模型循环较少，蒸馏学生模型即使教师模型很少循环也会显著循环；2）学习误差是循环的主要原因；3）高温通过促进探索减少循环，但无法修复学习误差，导致生成文本仍然过长；4）温度调节只是权宜之计。

Conclusion: 推理模型的循环问题源于训练分布与学习模型之间的不匹配（学习误差）。高温只能缓解症状但不能根治问题。未来需要训练时干预来直接减少学习误差，这是更根本的解决方案。

Abstract: Reasoning models (e.g., DeepSeek-R1) generate long chains of thought to solve harder problems, but they often loop, repeating the same text at low temperatures or with greedy decoding. We study why this happens and what role temperature plays. With open reasoning models, we find that looping is common at low temperature. Larger models tend to loop less, and distilled students loop significantly even when their teachers rarely do. This points to mismatches between the training distribution and the learned model, which we refer to as errors in learning, as a key cause. To understand how such errors cause loops, we introduce a synthetic graph reasoning task and demonstrate two mechanisms. First, risk aversion caused by hardness of learning: when the correct progress-making action is hard to learn but an easy cyclic action is available, the model puts relatively more probability on the cyclic action and gets stuck. Second, even when there is no hardness, Transformers show an inductive bias toward temporally correlated errors, so the same few actions keep being chosen and loops appear. Higher temperature reduces looping by promoting exploration, but it does not fix the errors in learning, so generations remain much longer than necessary at high temperature; in this sense, temperature is a stopgap rather than a holistic solution. We end with a discussion of training-time interventions aimed at directly reducing errors in learning.

</details>


### [189] [Probability Estimation for Predicted-Occupancy Grids in Vehicle Safety Applications Based on Machine Learning](https://arxiv.org/abs/2512.12896)
*Parthasarathy Nadarajan,Michael Botsch*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的方法来预测复杂交通场景的演化，使用随机森林算法计算预测占用网格(POG)，相比传统模型方法显著降低计算负载，有望实现实时车辆安全应用。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的预测方法虽然能详细建模交通参与者的行为不确定性，但由于每个参与者可能的轨迹数量庞大，计算负载非常高，难以实现实时应用。需要一种更高效的方法来预测交通场景演化。

Method: 1. 提出预测占用网格(POG)作为未来场景假设的网格化概率表示；2. 使用增强单元的占用网格表示当前交通场景状态；3. 采用随机森林算法进行机器学习，将当前状态映射到POG；4. 与基于模型的方法进行对比。

Result: 机器学习方法在交通场景模拟中表现出色，相比模型方法显著降低了计算负载，能够实现POG的实时计算，为车辆安全应用提供了可行性。

Conclusion: 基于随机森林的机器学习方法能够有效预测复杂交通场景演化，实现预测占用网格的实时计算，有望改进车辆安全系统中的关键组件如危险度估计和轨迹规划。

Abstract: This paper presents a method to predict the evolution of a complex traffic scenario with multiple objects. The current state of the scenario is assumed to be known from sensors and the prediction is taking into account various hypotheses about the behavior of traffic participants. This way, the uncertainties regarding the behavior of traffic participants can be modelled in detail. In the first part of this paper a model-based approach is presented to compute Predicted-Occupancy Grids (POG), which are introduced as a grid-based probabilistic representation of the future scenario hypotheses. However, due to the large number of possible trajectories for each traffic participant, the model-based approach comes with a very high computational load. Thus, a machine-learning approach is adopted for the computation of POGs. This work uses a novel grid-based representation of the current state of the traffic scenario and performs the mapping to POGs. This representation consists of augmented cells in an occupancy grid. The adopted machine-learning approach is based on the Random Forest algorithm. Simulations of traffic scenarios are performed to compare the machine-learning with the model-based approach. The results are promising and could enable the real-time computation of POGs for vehicle safety applications. With this detailed modelling of uncertainties, crucial components in vehicle safety systems like criticality estimation and trajectory planning can be improved.

</details>


### [190] [Predicted-occupancy grids for vehicle safety applications based on autoencoders and the Random Forest algorithm](https://arxiv.org/abs/2512.12901)
*Parthasarathy Nadarajan,Michael Botsch,Sebastian Sardina*

Main category: cs.LG

TL;DR: 使用机器学习预测复杂交通场景的概率时空表示，通过分层分类器识别场景类型，结合降噪自编码器和随机森林预测交通参与者未来行为，应用于安全轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 为主动车辆安全应用提供复杂交通场景的预测能力，特别是在执行动态机动操作时，需要准确预测交通参与者的未来行为以确保安全。

Method: 1. 使用分层情境分类器区分交通场景类型；2. 采用堆叠降噪自编码器将增强占据网格降维为低维特征；3. 针对每类场景训练随机森林预测概率时空表示（预测占据网格）。

Result: 提出的SDA+RF机器学习方法在仿真和真实车辆实验中表现出色，能够有效预测交通参与者的未来行为，并成功应用于交通场景关键性评估和安全轨迹确定。

Conclusion: 该方法为复杂交通场景提供了有效的概率时空预测表示，支持主动安全应用，包括场景关键性评估和安全轨迹规划，具有实际应用价值。

Abstract: In this paper, a probabilistic space-time representation of complex traffic scenarios is predicted using machine learning algorithms. Such a representation is significant for all active vehicle safety applications especially when performing dynamic maneuvers in a complex traffic scenario. As a first step, a hierarchical situation classifier is used to distinguish the different types of traffic scenarios. This classifier is responsible for identifying the type of the road infrastructure and the safety-relevant traffic participants of the driving environment. With each class representing similar traffic scenarios, a set of Random Forests (RFs) is individually trained to predict the probabilistic space-time representation, which depicts the future behavior of traffic participants. This representation is termed as a Predicted-Occupancy Grid (POG). The input to the RFs is an Augmented Occupancy Grid (AOG). In order to increase the learning accuracy of the RFs and to perform better predictions, the AOG is reduced to low-dimensional features using a Stacked Denoising Autoencoder (SDA). The excellent performance of the proposed machine learning approach consisting of SDAs and RFs is demonstrated in simulations and in experiments with real vehicles. An application of POGs to estimate the criticality of traffic scenarios and to determine safe trajectories is also presented.

</details>


### [191] [Next-generation reservoir computing validated by classification task](https://arxiv.org/abs/2512.12903)
*Ken-ichi Kitayama*

Main category: cs.LG

TL;DR: NG-RC无需实际储层，直接从时间序列计算多项式项，首次证明其分类性能与传统储层计算相当，验证了NG-RC在预测和分类任务中的通用计算能力。


<details>
  <summary>Details</summary>
Motivation: 现有NG-RC基准测试局限于Lorenz 63吸引子和Mackey-Glass混沌信号等时间波形预测任务，需要验证其在分类任务上的性能，以证明其通用计算能力。

Method: NG-RC不依赖实际储层进行输入数据混合，而是直接从时间序列输入计算多项式项，避免了传统储层计算的复杂储层结构。

Result: 首次证明NG-RC在分类任务上的性能与传统储层计算相当，验证了NG-RC在预测和分类任务中都具备优秀的计算能力。

Conclusion: NG-RC不仅适用于时间序列预测，也能有效执行分类任务，展现了其作为下一代储层计算范式的通用性和实用性。

Abstract: An emerging computing paradigm, so-called next-generation reservoir computing (NG-RC) is investigated. True to its namesake, NG-RC requires no actual reservoirs for input data mixing but rather computing the polynomial terms directly from the time series inputs. However, benchmark tests so far reported have been one-sided, limited to prediction tasks of temporal waveforms such as Lorenz 63 attractor and Mackey-Glass chaotic signal. We will demonstrate for the first time that NG-RC can perform classification task as good as conventional RC. This validates the versatile computational capability of NG-RC in tasks of both prediction and classification.

</details>


### [192] [Machine Learning Architectures for the Estimation of Predicted Occupancy Grids in Road Traffic](https://arxiv.org/abs/2512.12907)
*Parthasarathy Nadarajan,Michael Botsch,Sebastian Sardina*

Main category: cs.LG

TL;DR: 提出一种用于复杂交通场景概率时空表示高效估计的新型机器学习架构，包含堆叠去噪自编码器和随机森林，相比现有方法在精度和计算时间上均有优势。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和主动安全系统需要详细的未来交通场景表示，准确预测交通参与者的未来时空行为对安全决策至关重要。

Method: 首先识别交通场景类型，然后通过机器学习将当前状态映射到可能未来状态。使用增强占用网格作为输入，通过两个堆叠去噪自编码器和随机森林生成预测占用网格作为概率时空表示输出。

Result: 新架构在仿真验证中相比基于SDAs和DeconvNet的现有架构，在准确性和计算时间方面均表现出优势。

Conclusion: 提出的架构能有效生成包含不确定性的概率时空表示，为自动驾驶和主动安全系统提供可靠的未来交通场景预测。

Abstract: This paper introduces a novel machine learning architecture for an efficient estimation of the probabilistic space-time representation of complex traffic scenarios. A detailed representation of the future traffic scenario is of significant importance for autonomous driving and for all active safety systems. In order to predict the future space-time representation of the traffic scenario, first the type of traffic scenario is identified and then the machine learning algorithm maps the current state of the scenario to possible future states. The input to the machine learning algorithms is the current state representation of a traffic scenario, termed as the Augmented Occupancy Grid (AOG). The output is the probabilistic space-time representation which includes uncertainties regarding the behaviour of the traffic participants and is termed as the Predicted Occupancy Grid (POG). The novel architecture consists of two Stacked Denoising Autoencoders (SDAs) and a set of Random Forests. It is then compared with the other two existing architectures that comprise of SDAs and DeconvNet. The architectures are validated with the help of simulations and the comparisons are made both in terms of accuracy and computational time. Also, a brief overview on the applications of POGs in the field of active safety is presented.

</details>


### [193] [LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization](https://arxiv.org/abs/2512.12922)
*Bangyu Li,Boping Gu,Ziyang Ding*

Main category: cs.LG

TL;DR: 提出基于LLM的个性化投资组合推荐框架，结合大语言模型、强化学习和个性化风险偏好建模，实现智能投资决策


<details>
  <summary>Details</summary>
Motivation: 现代金融市场中，投资者需要个性化和自适应的投资组合策略，传统基于规则或静态优化方法无法捕捉投资者行为、市场波动性和金融目标之间的非线性交互关系

Method: 整合大语言模型、强化学习和个性化风险偏好建模的集成框架，支持智能投资决策

Result: 论文提出了LLM-based Personalized Portfolio Recommender框架，但摘要中未提及具体实验结果

Conclusion: 该框架能够更好地满足投资者个性化需求，适应动态市场条件，克服传统方法的局限性

Abstract: In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender , an integrated framework that combines Large Language Models, reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making.

</details>


### [194] [SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision](https://arxiv.org/abs/2512.12930)
*Yuseon Choi,Sangjin Kim,Jungjun Oh,Byeongcheol Kim,Hoi-Jun Yoo*

Main category: cs.LG

TL;DR: SeVeDo：一种基于SVD的异构加速器，通过将异常值敏感组件分离到高精度低秩路径，其余计算在低比特残差数据路径执行，结合分层组量化，实现高效Transformer推理。


<details>
  <summary>Details</summary>
Motivation: 低比特量化是高效Transformer推理的有前景技术，但激进的比特宽度减少会因激活异常值导致精度下降。现有方法（如异常值处理和组量化）虽然精度高，但能耗大。

Method: 提出SeVeDo异构加速器：1）结构上将异常值敏感组件分离到高精度低秩路径；2）其余计算在低比特残差数据路径执行；3）引入分层组量化（HGQ），结合粗粒度浮点缩放和细粒度移位；4）SVD引导的混合精度（SVD-MP）为精度敏感组件静态分配更高比特宽度。

Result: SeVeDo实现峰值能效13.8TOPS/W，在ViT-Base上达到12.7TOPS/W，在Llama2-7B上达到13.4TOPS/W，超越传统设计。

Conclusion: SeVeDo通过SVD分解和异构架构有效解决了低比特量化中的异常值问题，在保持精度的同时显著提升了能效，为高效Transformer推理提供了新方案。

Abstract: Low-bit quantization is a promising technique for efficient transformer inference by reducing computational and memory overhead. However, aggressive bitwidth reduction remains challenging due to activation outliers, leading to accuracy degradation. Existing methods, such as outlier-handling and group quantization, achieve high accuracy but incur substantial energy consumption. To address this, we propose SeVeDo, an energy-efficient SVD-based heterogeneous accelerator that structurally separates outlier-sensitive components into a high-precision low-rank path, while the remaining computations are executed in a low-bit residual datapath with group quantization. To further enhance efficiency, Hierarchical Group Quantization (HGQ) combines coarse-grained floating-point scaling with fine-grained shifting, effectively reducing dequantization cost. Also, SVD-guided mixed precision (SVD-MP) statically allocates higher bitwidths to precision-sensitive components identified through low-rank decomposition, thereby minimizing floating-point operation cost. Experimental results show that SeVeDo achieves a peak energy efficiency of 13.8TOPS/W, surpassing conventional designs, with 12.7TOPS/W on ViT-Base and 13.4TOPS/W on Llama2-7B benchmarks.

</details>


### [195] [Investigating Data Pruning for Pretraining Biological Foundation Models at Scale](https://arxiv.org/abs/2512.12932)
*Yifan Wu,Jiyue Jiang,Xichen Ye,Yiqi Wang,Chang Zhou,Yitao Xu,Jiayang Chen,He Hu,Weizhong Zhang,Cheng Jin,Jiao Yuan,Yu Li*

Main category: cs.LG

TL;DR: 提出一种基于影响力的后处理数据剪枝框架，用于生物基础模型预训练，能在99%剪枝率下超越随机选择，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 生物基础模型(BioFMs)需要大量训练数据和参数，导致计算成本高昂，阻碍学术实验室的可复现性和可访问性

Method: 提出基于子集的自影响力公式，高效估计样本重要性，开发Top-k影响力和覆盖中心影响力两种选择策略

Result: 在RNA-FM和ESM-C上验证，99%剪枝率下优于随机选择，核心集性能甚至超过10倍大的随机子集

Conclusion: 影响力引导的数据剪枝能显著降低BioFM预训练计算成本，促进更高效、可访问和可持续的生物AI研究

Abstract: Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.

</details>


### [196] [Understanding When Graph Convolutional Networks Help: A Diagnostic Study on Label Scarcity and Structural Properties](https://arxiv.org/abs/2512.12947)
*Nischal Subedi,Ember Kerstetter,Winnie Li,Silo Murphy*

Main category: cs.LG

TL;DR: GCNs在标签极度稀缺时提供最大增益，通过图结构补偿有限监督；在高度同质图中，即使特征被噪声替代，GCN仍能保持性能；但在低同质性和强特征条件下，GCN会损害性能。


<details>
  <summary>Details</summary>
Motivation: 研究GCN在半监督节点分类中何时比简单基线提供有意义的改进，为实践者提供清晰的指导原则。

Method: 使用Amazon Computers共购数据进行诊断研究，通过模拟标签稀缺、特征消融和按类分析的系统实验，分析图同质性与特征质量之间的相互作用。

Result: GCN性能关键取决于图同质性与特征质量的交互作用：在极端标签稀缺时增益最大；在高度同质图中，即使特征被噪声替代也能保持性能；但在低同质性和强特征条件下会损害性能。

Conclusion: GCN在四种条件中的三种情况下都有帮助，仅在低同质性遇到强特征时会损害性能。这为实践者决定是否采用基于图的方法提供了实用指导。

Abstract: Graph Convolutional Networks (GCNs) have become a standard approach for semi-supervised node classification, yet practitioners lack clear guidance on when GCNs provide meaningful improvements over simpler baselines. We present a diagnostic study using the Amazon Computers co-purchase data to understand when and why GCNs help. Through systematic experiments with simulated label scarcity, feature ablation, and per-class analysis, we find that GCN performance depends critically on the interaction between graph homophily and feature quality. GCNs provide the largest gains under extreme label scarcity, where they leverage neighborhood structure to compensate for limited supervision. Surprisingly, GCNs can match their original performance even when node features are replaced with random noise, suggesting that structure alone carries sufficient signal on highly homophilous graphs. However, GCNs hurt performance when homophily is low and features are already strong, as noisy neighbors corrupt good predictions. Our quadrant analysis reveals that GCNs help in three of four conditions and only hurt when low homophily meets strong features. These findings offer practical guidance for practitioners deciding whether to adopt graph-based methods.

</details>


### [197] [Application of Deep Learning in Biological Data Compression](https://arxiv.org/abs/2512.12975)
*Chunyu Zou*

Main category: cs.LG

TL;DR: 使用隐式神经表示（INR）压缩冷冻电镜数据，通过提取二进制密度图、神经网络编码空间密度信息，结合位置编码和加权MSE损失，实现高效压缩并保持重建质量。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜数据文件存储体积巨大，给研究和教育带来挑战，需要高效的压缩解决方案。

Method: 1) 根据密度阈值提取二进制密度图；2) 使用GZIP压缩重复性高的密度图；3) 训练神经网络编码空间密度信息，存储网络参数和可学习潜在向量；4) 引入位置编码增强空间表示；5) 使用加权MSE损失平衡密度分布变化。

Result: 论文旨在提供实用的冷冻电镜数据压缩方案，在保持合理压缩比和文件间重建质量的同时，满足教育和研究需求。

Conclusion: 基于深度学习的隐式神经表示方法能够有效压缩冷冻电镜生物数据，为研究和教育提供高效的数据管理解决方案。

Abstract: Cryogenic electron microscopy (Cryo-EM) has become an essential tool for capturing high-resolution biological structures. Despite its advantage in visualizations, the large storage size of Cryo-EM data file poses significant challenges for researchers and educators. This paper investigates the application of deep learning, specifically implicit neural representation (INR), to compress Cryo-EM biological data. The proposed approach first extracts the binary map of each file according to the density threshold. The density map is highly repetitive, ehich can be effectively compressed by GZIP. The neural network then trains to encode spatial density information, allowing the storage of network parameters and learnable latent vectors. To improve reconstruction accuracy, I further incorporate the positional encoding to enhance spatial representation and a weighted Mean Squared Error (MSE) loss function to balance density distribution variations. Using this approach, my aim is to provide a practical and efficient biological data compression solution that can be used for educational and research purpose, while maintaining a reasonable compression ratio and reconstruction quality from file to file.

</details>


### [198] [CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks](https://arxiv.org/abs/2512.12981)
*Jonathan Wenshøj,Tong Chen,Bob Pepin,Raghavendra Selvan*

Main category: cs.LG

TL;DR: CoDeQ是一种完全可微的联合剪枝-量化方法，通过参数化量化器的死区宽度来实现剪枝，无需外部辅助过程，在ImageNet上可将比特操作减少到约5%同时保持接近全精度准确率。


<details>
  <summary>Details</summary>
Motivation: 当前联合剪枝-量化方法依赖训练循环外的辅助过程来确定压缩参数，这增加了工程复杂性、需要超参数调优，且缺乏直接的数据驱动梯度信号，可能导致次优压缩。

Method: CoDeQ基于关键观察：标量量化器的死区等价于幅度剪枝。方法参数化死区宽度并通过反向传播学习，同时学习量化参数。这提供了稀疏性的显式控制，由单个全局超参数正则化，并将稀疏性选择与比特宽度选择解耦。

Result: 在ImageNet上使用ResNet-18，CoDeQ在固定精度和混合精度设置下都能将比特操作减少到约5%，同时保持接近全精度准确率。

Conclusion: CoDeQ提供了一种简单、完全可微的联合剪枝-量化方法，无需任何辅助过程，架构无关且易于实现，能够同时确定稀疏模式和量化参数。

Abstract: While joint pruning--quantization is theoretically superior to sequential application, current joint methods rely on auxiliary procedures outside the training loop for finding compression parameters. This reliance adds engineering complexity and hyperparameter tuning, while also lacking a direct data-driven gradient signal, which might result in sub-optimal compression. In this paper, we introduce CoDeQ, a simple, fully differentiable method for joint pruning--quantization. Our approach builds on a key observation: the dead-zone of a scalar quantizer is equivalent to magnitude pruning, and can be used to induce sparsity directly within the quantization operator. Concretely, we parameterize the dead-zone width and learn it via backpropagation, alongside the quantization parameters. This design provides explicit control of sparsity, regularized by a single global hyperparameter, while decoupling sparsity selection from bit-width selection. The result is a method for Compression with Dead-zone Quantizer (CoDeQ) that supports both fixed-precision and mixed-precision quantization (controlled by an optional second hyperparameter). It simultaneously determines the sparsity pattern and quantization parameters in a single end-to-end optimization. Consequently, CoDeQ does not require any auxiliary procedures, making the method architecture-agnostic and straightforward to implement. On ImageNet with ResNet-18, CoDeQ reduces bit operations to ~5% while maintaining close to full precision accuracy in both fixed and mixed-precision regimes.

</details>


### [199] [Deep Learning-Driven Inversion Framework for Shear Modulus Estimation in Magnetic Resonance Elastography (DIME)](https://arxiv.org/abs/2512.13010)
*Hassan Iftikhar,Rizwan Ahmad,Arunark Kolipaka*

Main category: cs.LG

TL;DR: 提出DIME深度学习框架，用于磁共振弹性成像中的剪切模量估计，相比传统MMDI方法具有更好的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统MMDI算法基于Helmholtz方程，假设介质均匀、无限且同质，且拉普拉斯算子对噪声敏感，导致刚度估计准确性和可靠性受限。

Method: DIME基于有限元模拟生成的位移场-刚度图对进行训练，采用小图像块捕捉局部波行为，提高对全局图像变化的鲁棒性。

Result: 在合成数据上，DIME相比MMDI具有更低的像素间变异性、更准确的边界划分和更高的地面真值相关性；在真实解剖模拟肝脏数据中，DIME与地面真值高度一致(r=0.99, R²=0.98)；在活体肝脏MRE数据中，DIME保持了生理一致的刚度模式。

Conclusion: DIME相比传统MMDI方法具有更好的性能，初步结果显示了其在临床MRE应用中的可行性。

Abstract: The Multimodal Direct Inversion (MMDI) algorithm is widely used in Magnetic Resonance Elastography (MRE) to estimate tissue shear stiffness. However, MMDI relies on the Helmholtz equation, which assumes wave propagation in a uniform, homogeneous, and infinite medium. Furthermore, the use of the Laplacian operator makes MMDI highly sensitive to noise, which compromises the accuracy and reliability of stiffness estimates. In this study, we propose the Deep-Learning driven Inversion Framework for Shear Modulus Estimation in MRE (DIME), aimed at enhancing the robustness of inversion. DIME is trained on the displacement fields-stiffness maps pair generated through Finite Element Modelling (FEM) simulations. To capture local wave behavior and improve robustness to global image variations, DIME is trained on small image patches. We first validated DIME using homogeneous and heterogeneous datasets simulated with FEM, where DIME produced stiffness maps with low inter-pixel variability, accurate boundary delineation, and higher correlation with ground truth (GT) compared to MMDI. Next, DIME was evaluated in a realistic anatomy-informed simulated liver dataset with known GT and compared directly to MMDI. DIME reproduced ground-truth stiffness patterns with high fidelity (r = 0.99, R^2 = 0.98), while MMDI showed greater underestimation. After validating DIME on synthetic data, we tested the model in in vivo liver MRE data from eight healthy and seven fibrotic subjects. DIME preserved physiologically consistent stiffness patterns and closely matched MMDI, which showed directional bias. Overall, DIME showed higher correlation with ground truth and visually similar stiffness patterns, whereas MMDI displayed a larger bias that can potentially be attributed to directional filtering. These preliminary results highlight the feasibility of DIME for clinical applications in MRE.

</details>


### [200] [Scaling Bidirectional Spans and Span Violations in Attention Mechanism](https://arxiv.org/abs/2512.13033)
*Jongwook Kim,Sangheon Yun,Sukjin Yoon*

Main category: cs.LG

TL;DR: 提出一种优化Transformer训练的方法，通过非对称投影将反向传播梯度分解为平行分量和正交违规分量，选择性缩放这些分量来改进学习信号，在WikiText-2上验证损失降低0.56%


<details>
  <summary>Details</summary>
Motivation: 标准Transformer虽然仍是序列建模的实证性能前沿，但其训练存在几何效率问题。标准注意力梯度可能不是最优的，需要优化训练过程以提高效率。

Method: 提出一个优化框架，使用非对称投影将反向传播梯度分解为平行跨度和正交违规分量，同时保持前向传播的QKV结构不变。选择性缩放这些分量，重点关注0阶双向平行跨度。

Result: 在有限的WikiText-2数据集和粗略配置下，该方法实现了验证损失降低0.56%，证明了框架的基本有效性，并表明在更大数据集和更深训练机制上具有显著潜力。

Conclusion: 标准注意力梯度是次优的，通过选择性缩放梯度分量可以产生更有效的学习信号。该方法为Transformer训练优化提供了理论基础，并显示出在更大规模应用中的潜力。

Abstract: The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes

</details>


### [201] [Alada: Alternating Adaptation of Momentum Method for Memory-Efficient Matrix Optimization](https://arxiv.org/abs/2512.13034)
*Xiaoyu He,Yu Cai,Jin Jia,Canxi Huang,Wenqing Chen,Zibin Zheng*

Main category: cs.LG

TL;DR: Alada是一种用于大规模矩阵随机优化的自适应动量方法，通过秩一分解估计梯度二阶矩，实现亚线性内存开销，性能与Adam相当但更节省内存。


<details>
  <summary>Details</summary>
Motivation: 传统自适应优化方法（如Adam）在处理大规模矩阵优化时内存开销巨大，需要开发更高效的内存优化方法。

Method: 采用秩一分解方法估计梯度二阶矩，通过交替更新因子最小化估计误差；同时引入一阶矩估计规则增强鲁棒性，不增加额外内存开销。

Result: 在多个自然语言处理任务上的数值研究表明，相比Adam及其变体，Alada显著减少了内存开销，并在训练大模型时表现出更好的鲁棒性。

Conclusion: Alada提供了一种高效的自适应优化方法，在保持与Adam相当理论性能的同时，显著降低了内存需求，适用于大规模矩阵和张量优化问题。

Abstract: This work proposes Alada, an adaptive momentum method for stochastic optimization over large-scale matrices. Alada employs a rank-one factorization approach to estimate the second moment of gradients, where factors are updated alternatively to minimize the estimation error. Alada achieves sublinear memory overheads and can be readily extended to optimizing tensor-shaped variables.We also equip Alada with a first moment estimation rule, which enhances the algorithm's robustness without incurring additional memory overheads. The theoretical performance of Alada aligns with that of traditional methods such as Adam. Numerical studies conducted on several natural language processing tasks demonstrate the reduction in memory overheads and the robustness in training large models relative to Adam and its variants.

</details>


### [202] [Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection](https://arxiv.org/abs/2512.13040)
*Xuwei Tan,Yao Ma,Xueru Zhang*

Main category: cs.LG

TL;DR: FinFRE-RAG：一种两阶段方法，通过重要性引导的特征缩减将表格数据序列化为自然语言，并利用检索增强的上下文学习，显著提升LLM在欺诈检测中的性能，同时提供可解释的预测依据。


<details>
  <summary>Details</summary>
Motivation: 传统表格模型在金融欺诈检测中需要大量特征工程且可解释性差，而LLM虽然能生成人类可读的解释，但直接应用于表格数据时性能不佳，存在特征过多、类别极度不平衡和缺乏上下文信息等问题。

Method: 提出FinFRE-RAG两阶段方法：1）重要性引导的特征缩减，将数值/分类属性序列化为自然语言；2）检索增强的上下文学习，利用标签感知的实例级示例进行推理。

Result: 在四个公开欺诈数据集和三类开源LLM上，FinFRE-RAG显著优于直接提示方法，F1/MCC指标大幅提升，在某些场景下与强大的表格基线模型竞争激烈。虽然仍落后于专用分类器，但缩小了性能差距。

Conclusion: FinFRE-RAG有效提升了LLM在欺诈检测中的性能，同时提供可解释的推理过程，使其成为欺诈分析中有价值的辅助工具，能够减轻分析师的工作负担并指导系统改进。

Abstract: Detecting fraud in financial transactions typically relies on tabular models that demand heavy feature engineering to handle high-dimensional data and offer limited interpretability, making it difficult for humans to understand predictions. Large Language Models (LLMs), in contrast, can produce human-readable explanations and facilitate feature analysis, potentially reducing the manual workload of fraud analysts and informing system refinements. However, they perform poorly when applied directly to tabular fraud detection due to the difficulty of reasoning over many features, the extreme class imbalance, and the absence of contextual information. To bridge this gap, we introduce FinFRE-RAG, a two-stage approach that applies importance-guided feature reduction to serialize a compact subset of numeric/categorical attributes into natural language and performs retrieval-augmented in-context learning over label-aware, instance-level exemplars. Across four public fraud datasets and three families of open-weight LLMs, FinFRE-RAG substantially improves F1/MCC over direct prompting and is competitive with strong tabular baselines in several settings. Although these LLMs still lag behind specialized classifiers, they narrow the performance gap and provide interpretable rationales, highlighting their value as assistive tools in fraud analysis.

</details>


### [203] [Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments](https://arxiv.org/abs/2512.13060)
*Kangning Gao,Yi Hu,Cong Nie,Wei Li*

Main category: cs.LG

TL;DR: 基于深度Q学习的ETL智能调度优化框架，通过强化学习在异构数据环境中动态优化任务分配和资源调度，显著降低延迟、提高吞吐量


<details>
  <summary>Details</summary>
Motivation: 解决异构数据环境下ETL流程调度效率低、资源分配不均衡、适应性差的问题，传统调度方法难以应对复杂动态环境

Method: 将ETL调度过程形式化为马尔可夫决策过程，构建包含状态表示模块、特征嵌入网络、Q值估计器和奖励评估机制的深度Q学习框架，考虑任务依赖、节点负载状态和数据流特征

Result: 实验结果表明，该框架显著降低调度延迟、提高系统吞吐量、增强执行稳定性，在多源异构任务条件下表现优异，验证了模型对超参数、环境动态性和数据规模变化的鲁棒性

Conclusion: 该研究展示了强化学习在复杂数据调度和资源管理中的强大潜力，为智能数据管道构建提供了高效可扩展的优化策略

Abstract: This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framework formalizes the ETL scheduling process as a Markov Decision Process and enables adaptive decision-making by a reinforcement learning agent in high-dimensional state spaces to dynamically optimize task allocation and resource scheduling. The model consists of a state representation module, a feature embedding network, a Q-value estimator, and a reward evaluation mechanism, which collectively consider task dependencies, node load states, and data flow characteristics to derive the optimal scheduling strategy in complex environments. A multi-objective reward function is designed to balance key performance indicators such as average scheduling delay, task completion rate, throughput, and resource utilization. Sensitivity experiments further verify the model's robustness under changes in hyperparameters, environmental dynamics, and data scale. Experimental results show that the proposed deep Q-learning scheduling framework significantly reduces scheduling delay, improves system throughput, and enhances execution stability under multi-source heterogeneous task conditions, demonstrating the strong potential of reinforcement learning in complex data scheduling and resource management, and providing an efficient and scalable optimization strategy for intelligent data pipeline construction.

</details>


### [204] [Multi-fidelity aerodynamic data fusion by autoencoder transfer learning](https://arxiv.org/abs/2512.13069)
*Javier Nieto-Centenero,Esther Andrés,Rodrigo Castellanos*

Main category: cs.LG

TL;DR: 提出结合自动编码器迁移学习和多分割保形预测的多保真度深度学习框架，在数据稀缺条件下实现不确定性感知的空气动力学数据融合。


<details>
  <summary>Details</summary>
Motivation: 高保真度空气动力学模拟计算成本过高，限制了数据驱动建模的应用。需要开发多保真度策略，利用低成本低保真度信息而不牺牲精度。

Method: 使用自动编码器迁移学习：利用丰富的低保真度数据学习紧凑的潜在物理表示作为冻结知识库，然后使用稀缺的高保真度样本微调解码器。结合新开发的多分割保形预测策略进行不确定性量化。

Result: 在NACA翼型（2D）和跨音速机翼（3D）数据库的表面压力分布测试中，模型成功校正了低保真度偏差，使用极少的高保真度训练数据实现了高精度压力预测。MSCP框架产生稳健、可操作的不确定性带，点覆盖超过95%。

Conclusion: 通过结合极端数据效率和不确定性量化，这项工作为数据稀缺环境中的空气动力学回归提供了可扩展且可靠的解决方案。

Abstract: Accurate aerodynamic prediction often relies on high-fidelity simulations; however, their prohibitive computational costs severely limit their applicability in data-driven modeling. This limitation motivates the development of multi-fidelity strategies that leverage inexpensive low-fidelity information without compromising accuracy. Addressing this challenge, this work presents a multi-fidelity deep learning framework that combines autoencoder-based transfer learning with a newly developed Multi-Split Conformal Prediction (MSCP) strategy to achieve uncertainty-aware aerodynamic data fusion under extreme data scarcity. The methodology leverages abundant Low-Fidelity (LF) data to learn a compact latent physics representation, which acts as a frozen knowledge base for a decoder that is subsequently fine-tuned using scarce HF samples. Tested on surface-pressure distributions for NACA airfoils (2D) and a transonic wing (3D) databases, the model successfully corrects LF deviations and achieves high-accuracy pressure predictions using minimal HF training data. Furthermore, the MSCP framework produces robust, actionable uncertainty bands with pointwise coverage exceeding 95%. By combining extreme data efficiency with uncertainty quantification, this work offers a scalable and reliable solution for aerodynamic regression in data-scarce environments.

</details>


### [205] [LikeBench: Evaluating Subjective Likability in LLMs for Personalization](https://arxiv.org/abs/2512.13077)
*Md Awsafur Rahman,Adam Gabrys,Doug Kang,Jingjing Sun,Tian Tan,Ashwin Chandramouli*

Main category: cs.LG

TL;DR: LikeBench：首个将LLM个性化评估从记忆和应用扩展到"喜爱度"的多维度动态评估框架，包含7个诊断指标，发现强记忆性能不等于高喜爱度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化基准主要关注记忆用户信息和应用信息两个维度，但忽略了主观且对用户体验至关重要的"喜爱度"维度，需要更全面的评估框架。

Method: 提出LikeBench多会话动态评估框架，让LLM与模拟用户对话，仅从对话中学习偏好，并在每次交互后从7个维度评估喜爱度：情感适应、正式度匹配、知识适应、引用理解、对话长度匹配、幽默匹配和回调。

Result: DeepSeek R1记忆准确率较低(86%，17个事实/档案)但在喜爱度得分上比Qwen3高28%，尽管Qwen3记忆准确率更高(93%，43个事实/档案)；即使是GPT-5等SOTA模型在短对话中适应良好，但在更长、更嘈杂的交互中表现有限。

Conclusion: 记忆性能不能保证高喜爱度，需要专门的喜爱度评估；LikeBench提供了更全面、细粒度的LLM个性化评估框架，有助于识别模型在哪些具体维度上表现不足。

Abstract: A personalized LLM should remember user facts, apply them correctly, and adapt over time to provide responses that the user prefers. Existing LLM personalization benchmarks are largely centered on two axes: accurately recalling user information and accurately applying remembered information in downstream tasks. We argue that a third axis, likability, is both subjective and central to user experience, yet under-measured by current benchmarks. To measure likability holistically, we introduce LikeBench, a multi-session, dynamic evaluation framework that measures likability across multiple dimensions by how much an LLM can adapt over time to a user's preferences to provide more likable responses. In LikeBench, the LLMs engage in conversation with a simulated user and learn preferences only from the ongoing dialogue. As the interaction unfolds, models try to adapt to responses, and after each turn, they are evaluated for likability across seven dimensions by the same simulated user. To the best of our knowledge, we are the first to decompose likability into multiple diagnostic metrics: emotional adaptation, formality matching, knowledge adaptation, reference understanding, conversation length fit, humor fit, and callback, which makes it easier to pinpoint where a model falls short. To make the simulated user more realistic and discriminative, LikeBench uses fine-grained, psychologically grounded descriptive personas rather than the coarse high/low trait rating based personas used in prior work. Our benchmark shows that strong memory performance does not guarantee high likability: DeepSeek R1, with lower memory accuracy (86%, 17 facts/profile), outperformed Qwen3 by 28% on likability score despite Qwen3's higher memory accuracy (93%, 43 facts/profile). Even SOTA models like GPT-5 adapt well in short exchanges but show only limited robustness in longer, noisier interactions.

</details>


### [206] [TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning](https://arxiv.org/abs/2512.13106)
*Shenzhi Yang,Guangcheng Zhu,Xing Zheng,Yingfan MA,Zhongqi Chen,Bowen Song,Weiqiang Wang,Junbo Zhao,Gang Chen,Haobo Wang*

Main category: cs.LG

TL;DR: 提出TraPO算法，一种半监督RLVR方法，使用少量标注样本指导无标注样本的训练，通过匹配学习轨迹相似性来识别可靠的无标注样本，显著提高数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法依赖大量标注成本高，无监督RLVR方法容易在训练后期出现模型崩溃，因为缺乏外部监督会强化错误的推理模式。需要一种既能减少标注成本又能保持稳定训练的方法。

Method: 提出半监督RLVR范式，使用少量标注样本指导无标注样本的训练。核心是TraPO算法，通过匹配无标注样本与标注样本的学习轨迹相似性来识别可靠的无标注样本，确保只有经过标注样本验证的推理模式被纳入强化学习训练。

Result: 在6个数学推理基准测试（AIME24/25, AMC, MATH-500, Minerva, Olympiad）和3个分布外任务（ARC-c, GPQA-diamond, MMLU-pro）上取得显著效果。仅用1K标注+3K无标注样本达到42.6%平均准确率，超越使用45K无标注样本的最佳无监督方法（38.3%）。使用4K标注+12K无标注样本时，在所有基准测试上超越使用全部45K标注样本的全监督模型，仅使用10%标注数据。

Conclusion: TraPO算法通过半监督RLVR范式有效解决了无监督方法中的模型崩溃问题，实现了显著的数据效率和泛化能力提升，证明了标注奖励对于稳定基于一致性的无标注样本训练至关重要。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.

</details>


### [207] [From Overfitting to Reliability: Introducing the Hierarchical Approximate Bayesian Neural Network](https://arxiv.org/abs/2512.13111)
*Hayk Amirkhanian,Marco F. Huber*

Main category: cs.LG

TL;DR: 提出Hierarchical Approximate Bayesian Neural Network，使用高斯-逆Wishart分布作为权重超先验，通过闭式解析解实现高效不确定性估计，在OOD任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络存在超参数调优困难和过拟合问题，贝叶斯神经网络通过直接建模不确定性可提供更可靠的预测，特别是在分布外数据上。然而现有方法在计算效率和模型鲁棒性方面仍有改进空间。

Method: 提出分层近似贝叶斯神经网络，使用高斯-逆Wishart分布作为网络权重的超先验。该方法提供了预测分布和权重后验的解析表示，计算上等价于闭式求解学生t分布的参数，计算复杂度与权重数量呈线性关系。

Result: 实验结果表明HABNN不仅匹配而且经常超越现有最先进模型，有效解决了过拟合问题，提供了可靠的不确定性估计，特别是在分布外任务上表现出色。

Conclusion: HABNN为贝叶斯神经网络提供了一种高效且鲁棒的方法，在安全关键环境中具有广阔的应用前景，为未来研究指明了有希望的方向。

Abstract: In recent years, neural networks have revolutionized various domains, yet challenges such as hyperparameter tuning and overfitting remain significant hurdles. Bayesian neural networks offer a framework to address these challenges by incorporating uncertainty directly into the model, yielding more reliable predictions, particularly for out-of-distribution data. This paper presents Hierarchical Approximate Bayesian Neural Network, a novel approach that uses a Gaussian-inverse-Wishart distribution as a hyperprior of the network's weights to increase both the robustness and performance of the model. We provide analytical representations for the predictive distribution and weight posterior, which amount to the calculation of the parameters of Student's t-distributions in closed form with linear complexity with respect to the number of weights. Our method demonstrates robust performance, effectively addressing issues of overfitting and providing reliable uncertainty estimates, particularly for out-of-distribution tasks. Experimental results indicate that HABNN not only matches but often outperforms state-of-the-art models, suggesting a promising direction for future applications in safety-critical environments.

</details>


### [208] [Quanvolutional Neural Networks for Spectrum Peak-Finding](https://arxiv.org/abs/2512.13125)
*Lukas Bischof,Rudolf M. Füchslin,Kurt Stockinger,Pavel Sulimov*

Main category: cs.LG

TL;DR: 量子卷积神经网络在NMR谱峰检测任务中表现优于经典CNN，F1分数提升11%，峰位置估计误差降低30%，且在复杂问题上收敛更稳定。


<details>
  <summary>Details</summary>
Motivation: 核磁共振等光谱的峰检测（解卷积）对专家和机器都是挑战，机器学习已显示出自动化潜力，量子计算有望进一步提升性能。

Method: 受经典CNN启发，设计简单可解释的量子卷积神经网络架构，用于多任务峰检测（峰计数和位置估计），在合成NMR数据集上与经典CNN对比。

Result: QuanvNN在挑战性光谱上优于经典CNN：F1分数提升11%，峰位置估计的平均绝对误差降低30%，且在更难问题上表现出更好的收敛稳定性。

Conclusion: 量子卷积神经网络在光谱分析任务中展现出超越经典方法的潜力，为量子机器学习在科学数据分析中的应用提供了有前景的方向。

Abstract: The analysis of spectra, such as Nuclear Magnetic Resonance (NMR) spectra, for the comprehensive characterization of peaks is a challenging task for both experts and machines, especially with complex molecules. This process, also known as deconvolution, involves identifying and quantifying the peaks in the spectrum. Machine learning techniques have shown promising results in automating this process. With the advent of quantum computing, there is potential to further enhance these techniques. In this work, inspired by the success of classical Convolutional Neural Networks (CNNs), we explore the use of Quanvolutional Neural Networks (QuanvNNs) for the multi-task peak finding problem, involving both peak counting and position estimation. We implement a simple and interpretable QuanvNN architecture that can be directly compared to its classical CNN counterpart, and evaluate its performance on a synthetic NMR-inspired dataset. Our results demonstrate that QuanvNNs outperform classical CNNs on challenging spectra, achieving an 11\% improvement in F1 score and a 30\% reduction in mean absolute error for peak position estimation. Additionally, QuanvNNs appear to exhibit better convergence stability for harder problems.

</details>


### [209] [Enhancing Node-Level Graph Domain Adaptation by Alleviating Local Dependency](https://arxiv.org/abs/2512.13149)
*Xinwei Tai,Dongmian Zou,Hongfei Wang*

Main category: cs.LG

TL;DR: 该论文提出通过解相关节点特征来改进无监督图域自适应，以解决条件偏移问题，并在实验中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 图机器学习方法近年来取得显著进展，但如何有效地将知识从一个图迁移到另一个图仍然是一个关键挑战。无监督图域自适应（GDA）面临的主要困难是条件偏移问题，这会阻碍知识迁移。

Method: 论文首先通过理论分析证明条件偏移仅存在于节点特征存在局部依赖性的情况下。基于这一发现，提出通过解相关节点特征来改进GDA，具体通过解相关的GCN层和图Transformer层实现。

Result: 实验结果表明该方法有效，不仅显著优于基线GDA方法，而且在学习到的表征中显示出较小的类内距离，可视化结果清晰。

Conclusion: 通过解相关节点特征可以有效解决无监督图域自适应中的条件偏移问题，提高知识迁移效果，为图域自适应提供了新的理论指导和方法实现。

Abstract: Recent years have witnessed significant advancements in machine learning methods on graphs. However, transferring knowledge effectively from one graph to another remains a critical challenge. This highlights the need for algorithms capable of applying information extracted from a source graph to an unlabeled target graph, a task known as unsupervised graph domain adaptation (GDA). One key difficulty in unsupervised GDA is conditional shift, which hinders transferability. In this paper, we show that conditional shift can be observed only if there exists local dependencies among node features. To support this claim, we perform a rigorous analysis and also further provide generalization bounds of GDA when dependent node features are modeled using markov chains. Guided by the theoretical findings, we propose to improve GDA by decorrelating node features, which can be specifically implemented through decorrelated GCN layers and graph transformer layers. Our experimental results demonstrate the effectiveness of this approach, showing not only substantial performance enhancements over baseline GDA methods but also clear visualizations of small intra-class distances in the learned representations. Our code is available at https://github.com/TechnologyAiGroup/DFT

</details>


### [210] [SACn: Soft Actor-Critic with n-step Returns](https://arxiv.org/abs/2512.13165)
*Jakub Łyskawa,Jakub Lewandowski,Paweł Wawrzyński*

Main category: cs.LG

TL;DR: 提出SACn算法，将SAC与n步回报结合，通过数值稳定的重要性采样和τ采样熵估计解决传统方法中的偏差和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: SAC是重要的离策略在线无模型RL方法，n步回报能提高收敛速度，但传统结合方式会因动作分布变化引入偏差，而重要性采样又可能导致数值不稳定。

Method: 1) 提出数值稳定的重要性采样方法，简化超参数选择；2) 分析SAC在n步最大熵框架下的熵估计方法，提出τ采样熵估计降低学习目标方差；3) 最终形成SACn算法。

Result: 在MuJoCo模拟环境中进行实验验证，SACn算法能够有效结合n步回报，提高收敛速度，同时保持数值稳定性。

Conclusion: 成功将SAC与n步回报结合，解决了传统方法中的偏差和不稳定性问题，提出的SACn算法在实际应用中具有更好的性能和稳定性。

Abstract: Soft Actor-Critic (SAC) is widely used in practical applications and is now one of the most relevant off-policy online model-free reinforcement learning (RL) methods. The technique of n-step returns is known to increase the convergence speed of RL algorithms compared to their 1-step returns-based versions. However, SAC is notoriously difficult to combine with n-step returns, since their usual combination introduces bias in off-policy algorithms due to the changes in action distribution. While this problem is solved by importance sampling, a method for estimating expected values of one distribution using samples from another distribution, importance sampling may result in numerical instability. In this work, we combine SAC with n-step returns in a way that overcomes this issue. We present an approach to applying numerically stable importance sampling with simplified hyperparameter selection. Furthermore, we analyze the entropy estimation approach of Soft Actor-Critic in the context of the n-step maximum entropy framework and formulate the $τ$-sampled entropy estimation to reduce the variance of the learning target. Finally, we formulate the Soft Actor-Critic with n-step returns (SAC$n$) algorithm that we experimentally verify on MuJoCo simulated environments.

</details>


### [211] [PolySet: Restoring the Statistical Ensemble Nature of Polymers for Machine Learning](https://arxiv.org/abs/2512.13186)
*Khalid Ferji*

Main category: cs.LG

TL;DR: PolySet是一个将聚合物表示为有限加权链集合的框架，解决了传统机器学习模型将聚合物视为单一完美分子图与物理现实不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 当前聚合物科学中的机器学习模型通常将聚合物视为单一、完美定义的分子图，而真实材料由具有分布长度的随机链集合组成。这种物理现实与数字表示之间的不匹配限制了现有模型捕捉聚合物行为的能力。

Method: 引入PolySet框架，将聚合物表示为从假定摩尔质量分布中采样的有限加权链集合。这种基于集合的编码独立于化学细节，兼容任何分子表示，并在均聚物情况下使用最小语言模型进行说明。

Result: PolySet保留了高阶分布矩（如Mz、Mz+1），使机器学习模型能够学习对尾部敏感的性质，具有显著改善的稳定性和准确性。

Conclusion: 通过明确承认聚合物物质的统计性质，PolySet为未来聚合物机器学习建立了物理基础，可自然扩展到共聚物、嵌段结构和其他复杂拓扑结构。

Abstract: Machine-learning (ML) models in polymer science typically treat a polymer as a single, perfectly defined molecular graph, even though real materials consist of stochastic ensembles of chains with distributed lengths. This mismatch between physical reality and digital representation limits the ability of current models to capture polymer behaviour. Here we introduce PolySet, a framework that represents a polymer as a finite, weighted ensemble of chains sampled from an assumed molar-mass distribution. This ensemble-based encoding is independent of chemical detail, compatible with any molecular representation and illustrated here in the homopolymer case using a minimal language model. We show that PolySet retains higher-order distributional moments (such as Mz, Mz+1), enabling ML models to learn tail-sensitive properties with greatly improved stability and accuracy. By explicitly acknowledging the statistical nature of polymer matter, PolySet establishes a physically grounded foundation for future polymer machine learning, naturally extensible to copolymers, block architectures, and other complex topologies.

</details>


### [212] [WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory](https://arxiv.org/abs/2512.13190)
*Jin Sob Kim,Hyun Joon Park,Wooseok Shin,Dongil Park,Sung Won Han*

Main category: cs.LG

TL;DR: 提出WAY深度學習架構，用於處理AIS軌跡數據，實現船舶目的地預測，並引入梯度丟棄技術提升訓練效果。


<details>
  <summary>Details</summary>
Motivation: AIS系統雖然能提供海事監控數據，但存在可靠性問題和數據間隔不規則的缺點，需要更有效的船舶目的地預測方法。

Method: 將長港口到港口軌跡重構為嵌套序列結構，使用空間網格減輕時空偏差。提出WAY架構，包含軌跡表示層和CASP塊，並引入梯度丟棄技術進行多對多訓練。

Result: 在5年AIS數據上的實驗顯示，WAY優於傳統空間網格方法，梯度丟棄技術帶來性能提升，並展示多任務學習在ETA預測中的應用潛力。

Conclusion: WAY架構能有效處理AIS軌跡數據，實現長期目的地預測，梯度丟棄技術改善訓練效果，具有實際應用價值。

Abstract: The Automatic Identification System (AIS) enables data-driven maritime surveillance but suffers from reliability issues and irregular intervals. We address vessel destination estimation using global-scope AIS data by proposing a differentiated approach that recasts long port-to-port trajectories as a nested sequence structure. Using spatial grids, this method mitigates spatio-temporal bias while preserving detailed resolution. We introduce a novel deep learning architecture, WAY, designed to process these reformulated trajectories for long-term destination estimation days to weeks in advance. WAY comprises a trajectory representation layer and Channel-Aggregative Sequential Processing (CASP) blocks. The representation layer generates multi-channel vector sequences from kinematic and non-kinematic features. CASP blocks utilize multi-headed channel- and self-attention for aggregation and sequential information delivery. Additionally, we propose a task-specialized Gradient Dropout (GD) technique to enable many-to-many training on single labels, preventing biased feedback surges by stochastically blocking gradient flow based on sample length. Experiments on 5-year AIS data demonstrate WAY's superiority over conventional spatial grid-based approaches regardless of trajectory progression. Results further confirm that adopting GD leads to performance gains. Finally, we explore WAY's potential for real-world application through multitask learning for ETA estimation.

</details>


### [213] [Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning](https://arxiv.org/abs/2512.13196)
*Chethana Prasad Kabgere,Sudarshan T S B*

Main category: cs.LG

TL;DR: NR-QFL：一种混合量子-经典联邦学习框架，通过变分量子电路在NISQ条件下实现安全、低延迟的聚合，提升ADAS系统的噪声容忍度和通信效率。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在实时车载网络中容易受到噪声、延迟和安全约束的影响，需要一种更鲁棒、高效的聚合方法来提升ADAS系统的性能。

Method: 提出噪声弹性量子联邦学习（NR-QFL）框架，使用变分量子电路进行安全低延迟聚合，采用量子态编码模型参数和自适应门重参数化，结合量子熵客户端选择和多服务器协调机制。

Result: 实验验证显示NR-QFL在受限边缘条件下实现一致收敛，减少梯度方差，降低通信开销，并增强噪声容忍度。

Conclusion: NR-QFL为量子增强的联邦学习建立了可扩展基础，能够在车载边缘实现安全、高效和动态稳定的ADAS智能。

Abstract: Advanced Driver Assistance Systems (ADAS) increasingly employ Federated Learning (FL) to collaboratively train models across distributed vehicular nodes while preserving data privacy. Yet, conventional FL aggregation remains susceptible to noise, latency, and security constraints inherent to real-time vehicular networks. This paper introduces Noise-Resilient Quantum Federated Learning (NR-QFL), a hybrid quantum-classical framework that enables secure, low-latency aggregation through variational quantum circuits (VQCs) operating under Noisy Intermediate-Scale Quantum (NISQ) conditions. The framework encodes model parameters as quantum states with adaptive gate reparameterization, ensuring bounded-error convergence and provable resilience under Completely Positive Trace-Preserving (CPTP) dynamics. NR-QFL employs quantum entropy-based client selection and multi-server coordination for fairness and stability. Empirical validation shows consistent convergence with reduced gradient variance, lower communication overhead, and enhanced noise tolerance under constrained edge conditions. The framework establishes a scalable foundation for quantum-enhanced federated learning, enabling secure, efficient, and dynamically stable ADAS intelligence at the vehicular edge.

</details>


### [214] [Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting](https://arxiv.org/abs/2512.13207)
*Karina Chichifoi,Fabio Merizzi,Michele Colajanni*

Main category: cs.LG

TL;DR: 研究探讨联邦学习中数据投毒攻击对气象预报的影响，发现即使少量恶意客户端也能显著扭曲大范围区域温度预测，现有防御方法对空间相关数据攻击效果有限。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在气象预报中具有应用潜力，但其分布式特性引入了新的安全漏洞。数据投毒攻击可能通过空间依赖关系影响大范围区域预测，需要研究其具体影响和防御机制。

Method: 使用CERRA数据集模拟地理分布式客户端，评估基于补丁和全局偏置攻击对区域温度预测的影响，并测试修剪均值聚合作为防御机制的效果。

Result: 单个恶意客户端的全局偏置攻击可使预测偏移达-1.7K；协调补丁攻击使均方误差增加三倍以上，产生超过+3.5K的区域异常。修剪均值聚合能防御全局偏置攻击（2-13%性能下降），但对补丁攻击无效（281-603%性能恶化）。

Conclusion: 联邦气象预报对数据投毒攻击高度脆弱，空间相关数据使局部扰动能影响大范围区域。现有基于异常值的防御方法对空间相关攻击效果有限，需要开发更鲁棒的防御机制。

Abstract: Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass traditional numerical models, while FL allows institutions in different locations to collaboratively train models without sharing raw data, addressing efficiency and security concerns. While FL has shown promise across heterogeneous regions, its distributed nature introduces new vulnerabilities. In particular, data poisoning attacks, in which compromised clients inject manipulated training data, can degrade performance or introduce systematic biases. These threats are amplified by spatial dependencies in meteorological data, allowing localized perturbations to influence broader regions through global model aggregation. In this study, we investigate how adversarial clients distort federated surface temperature forecasts trained on the Copernicus European Regional ReAnalysis (CERRA) dataset. We simulate geographically distributed clients and evaluate patch-based and global biasing attacks on regional temperature forecasts. Our results show that even a small fraction of poisoned clients can mislead predictions across large, spatially connected areas. A global temperature bias attack from a single compromised client shifts predictions by up to -1.7 K, while coordinated patch attacks more than triple the mean squared error and produce persistent regional anomalies exceeding +3.5 K. Finally, we assess trimmed mean aggregation as a defense mechanism, showing that it successfully defends against global bias attacks (2-13\% degradation) but fails against patch attacks (281-603\% amplification), exposing limitations of outlier-based defenses for spatially correlated data.

</details>


### [215] [ModSSC: A Modular Framework for Semi-Supervised Classification on Heterogeneous Data](https://arxiv.org/abs/2512.13228)
*Melvin Barbaux*

Main category: cs.LG

TL;DR: ModSSC是一个统一的半监督分类Python框架，支持多种算法、数据类型和硬件环境，通过YAML配置简化实验复现和比较研究。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督分类软件支持分散在不同方法和模态中，缺乏统一框架，使得方法比较和实验复现变得困难。

Method: 开发了ModSSC开源框架，统一归纳和直推式半监督分类，实现经典和最新算法，支持表格、图像、文本、音频和图形数据，提供单一配置接口和YAML声明式实验描述。

Result: 发布了ModSSC 1.0.0版本，采用MIT许可证，包含详细文档和测试，支持从CPU上的轻量级经典方法到多GPU上的深度学习方法。

Conclusion: ModSSC为半监督分类提供了一个全面、统一且易于使用的框架，显著简化了方法比较、实验复现和大规模比较研究。

Abstract: Semi-supervised classification leverages both labeled and unlabeled data to improve predictive performance, but existing software support is fragmented across methods and modalities. We introduce ModSSC, an open source Python framework that unifies inductive and transductive semi-supervised classification in a modular code base. ModSSC implements a broad range of classical and recent algorithms, provides loaders for tabular, image, text, audio and graph datasets, and exposes a single configuration interface for specifying datasets, models and evaluation protocols. It supports both lightweight classical methods on small datasets running on CPU and recent deep approaches that can exploit multiple GPUs within the same experimental framework. Experiments are described declaratively in YAML, which facilitates reproducing existing work and running large comparative studies. ModSSC 1.0.0 is released under the MIT license with extensive documentation and tests, and is available at https://github.com/ModSSC/ModSSC.

</details>


### [216] [CORE: Contrastive Masked Feature Reconstruction on Graphs](https://arxiv.org/abs/2512.13235)
*Jianyuan Bo,Yuan Fang*

Main category: cs.LG

TL;DR: CORE框架将对比学习融入掩码特征重建，通过将原始与重建特征作为正样本、掩码节点作为负样本，在节点和图分类任务上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究发现掩码特征重建（MFR）和图对比学习（GCL）在特定条件下目标函数会收敛，表明这两种自监督学习方法具有互补性而非根本差异，因此探索将两者集成以提升图自监督学习性能。

Method: 提出CORE框架，将对比学习融入MFR：1）仅将掩码节点的原始特征与重建特征作为正样本对，促使编码器关注上下文信息而非节点自身特征；2）利用掩码节点自身作为负样本，结合MFR的重建能力和GCL的判别能力来更好捕捉图结构。

Result: CORE在节点和图分类任务上显著优于MFR，达到最先进水平：在节点分类任务上超越GraphMAE和GraphMAE2分别达2.80%和3.72%；在图分类任务上分别超越3.82%和3.76%。

Conclusion: CORE成功整合了生成式和对比式自监督学习方法，证明了两种方法的互补性，为图自监督学习提供了更强大的框架，在多个任务上取得了显著性能提升。

Abstract: In the rapidly evolving field of self-supervised learning on graphs, generative and contrastive methodologies have emerged as two dominant approaches. Our study focuses on masked feature reconstruction (MFR), a generative technique where a model learns to restore the raw features of masked nodes in a self-supervised manner. We observe that both MFR and graph contrastive learning (GCL) aim to maximize agreement between similar elements. Building on this observation, we reveal a novel theoretical insight: under specific conditions, the objectives of MFR and node-level GCL converge, despite their distinct operational mechanisms. This theoretical connection suggests these approaches are complementary rather than fundamentally different, prompting us to explore their integration to enhance self-supervised learning on graphs. Our research presents Contrastive Masked Feature Reconstruction (CORE), a novel graph self-supervised learning framework that integrates contrastive learning into MFR. Specifically, we form positive pairs exclusively between the original and reconstructed features of masked nodes, encouraging the encoder to prioritize contextual information over the node's own features. Additionally, we leverage the masked nodes themselves as negative samples, combining MFR's reconstructive power with GCL's discriminative ability to better capture intrinsic graph structures. Empirically, our proposed framework CORE significantly outperforms MFR across node and graph classification tasks, demonstrating state-of-the-art results. In particular, CORE surpasses GraphMAE and GraphMAE2 by up to 2.80% and 3.72% on node classification tasks, and by up to 3.82% and 3.76% on graph classification tasks.

</details>


### [217] [Learning to Retrieve with Weakened Labels: Robust Training under Label Noise](https://arxiv.org/abs/2512.13237)
*Arnab Sharma*

Main category: cs.LG

TL;DR: 提出标签弱化方法应对检索模型训练中的稀疏标注和标签噪声问题，通过生成一组可能的标签而非单一标签，在噪声环境下提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 神经编码器在NLP密集检索任务中应用广泛，但训练数据中的稀疏标注和标签噪声使得模型训练困难。现有方法要么需要调参，要么增加训练复杂度，需要更鲁棒的解决方案。

Method: 采用标签弱化方法：不为每个查询-文档对强制分配单一标签，而是基于观察到的监督信号和模型置信度生成一组合理的标签。使用语义感知的噪声生成技术创建不同噪声比例的实验环境。

Result: 在两个检索模型和一个重排序模型上，使用四个不同的排序数据集进行广泛评估。标签弱化方法相比10种最先进的损失函数，在检索任务上表现出更好的性能。

Conclusion: 标签弱化是处理检索任务中标签噪声的有效方法，能够生成更鲁棒的检索模型，在噪声环境下优于现有损失函数方法。

Abstract: Neural Encoders are frequently used in the NLP domain to perform dense retrieval tasks, for instance, to generate the candidate documents for a given query in question-answering tasks. However, sparse annotation and label noise in the training data make it challenging to train or fine-tune such retrieval models. Although existing works have attempted to mitigate these problems by incorporating modified loss functions or data cleaning, these approaches either require some hyperparameters to tune during training or add substantial complexity to the training setup. In this work, we consider a label weakening approach to generate robust retrieval models in the presence of label noise. Instead of enforcing a single, potentially erroneous label for each query document pair, we allow for a set of plausible labels derived from both the observed supervision and the model's confidence scores. We perform an extensive evaluation considering two retrieval models, one re-ranking model, considering four diverse ranking datasets. To this end, we also consider a realistic noisy setting by using a semantic-aware noise generation technique to generate different ratios of noise. Our initial results show that label weakening can improve the performance of the retrieval tasks in comparison to 10 different state-of-the-art loss functions.

</details>


### [218] [BézierFlow: Bézier Stochastic Interpolant Schedulers for Few-Step Generation](https://arxiv.org/abs/2512.13255)
*Yunhong Min,Juil Koo,Seungwoo Yoo,Minhyuk Sung*

Main category: cs.LG

TL;DR: BézierFlow是一种轻量级训练方法，通过将随机插值调度器参数化为Bézier函数，学习最优采样轨迹变换，在≤10步采样中实现2-3倍性能提升，仅需15分钟训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级训练方法主要学习最优时间步长，但仅限于ODE离散化。需要扩展搜索空间，从离散时间步扩展到基于Bézier的轨迹变换，以提升少步采样的性能。

Method: 将随机插值调度器参数化为Bézier函数，通过控制点自然满足边界条件、可微性和SNR单调性等关键要求。将问题简化为学习时间范围内的有序点集，从ODE时间步解释转变为Bézier控制点。

Result: 在多种预训练扩散和流模型上，BézierFlow在≤10步采样中实现2-3倍性能提升，仅需15分钟训练时间，始终优于先前的时间步学习方法。

Conclusion: 通过将搜索空间从离散时间步扩展到基于Bézier的轨迹变换，BézierFlow证明了扩展优化范围的有效性，为少步生成提供了高效轻量级解决方案。

Abstract: We introduce BézierFlow, a lightweight training approach for few-step generation with pretrained diffusion and flow models. BézierFlow achieves a 2-3x performance improvement for sampling with $\leq$ 10 NFEs while requiring only 15 minutes of training. Recent lightweight training approaches have shown promise by learning optimal timesteps, but their scope remains restricted to ODE discretizations. To broaden this scope, we propose learning the optimal transformation of the sampling trajectory by parameterizing stochastic interpolant (SI) schedulers. The main challenge lies in designing a parameterization that satisfies critical desiderata, including boundary conditions, differentiability, and monotonicity of the SNR. To effectively meet these requirements, we represent scheduler functions as Bézier functions, where control points naturally enforce these properties. This reduces the problem to learning an ordered set of points in the time range, while the interpretation of the points changes from ODE timesteps to Bézier control points. Across a range of pretrained diffusion and flow models, BézierFlow consistently outperforms prior timestep-learning methods, demonstrating the effectiveness of expanding the search space from discrete timesteps to Bézier-based trajectory transformations.

</details>


### [219] [No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction](https://arxiv.org/abs/2512.13300)
*Qinglin Jia,Zhaocheng Du,Chuhan Wu,Huifeng Guo,Ruiming Tang,Shuting Shi,Muyu Zhang*

Main category: cs.LG

TL;DR: 提出KAML框架，通过属性驱动掩码策略、分层知识提取机制和排序损失，解决在线广告中多任务学习面临的不完整多标签数据问题。


<details>
  <summary>Details</summary>
Motivation: 在线广告系统中，广告主通常有多样化的用户获取目标，但转化率预测常遇到不完整的转化数据问题。许多广告主由于隐私或其他限制只提交部分用户转化行为，导致多任务数据的标签不完整。如果模型在所有可用样本上训练，当部署到针对特定转化行为的广告主时，训练和部署数据分布不匹配，模型性能会下降。

Method: 提出KAML框架，包含三个核心组件：1) 属性驱动掩码策略(ADM)，更好地利用不对称多标签数据进行训练；2) 分层知识提取机制(HKE)，在目标任务塔内建模样本差异，解决ADM引入的噪声问题；3) 结合排序损失策略，最大化未标记样本的效用。

Result: 在离线行业数据集和在线A/B测试中进行了全面评估，结果显示KAML相比现有的多任务学习基线方法有显著的性能提升。

Conclusion: KAML框架有效解决了在线广告系统中多任务学习面临的不完整多标签数据问题，通过创新的掩码策略、知识提取机制和损失函数设计，在真实场景中取得了显著性能改进。

Abstract: In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.

</details>


### [220] [ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning](https://arxiv.org/abs/2512.13316)
*Mayank Gulati,Benedikt Groß,Gerhard Wunder*

Main category: cs.LG

TL;DR: ALIGN-FL 是一种新颖的分布式学习方法，通过选择性共享生成组件来解决高度不相关数据分布的学习挑战，使用隐私保护机制在非IID场景下保持效用。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中高度不相关数据分布（Non-IID）的挑战，同时保护隐私。传统方法交换完整模型参数存在隐私风险，需要一种既能处理异构客户端数据，又能保护敏感信息的方法。

Method: 1. 选择性共享生成组件而非完整模型参数；2. 服务器使用合成样本进行全局训练；3. 采用互补隐私机制：DP-SGD自适应裁剪和Lipschitz正则化VAE解码器；4. 支持异构客户端的架构设计。

Result: 在MNIST和Fashion-MNIST数据集上验证，两种隐私机制都能有效将敏感异常值映射到典型数据点，同时在跨域协作的极端非IID场景中保持模型效用。

Conclusion: ALIGN-FL通过生成组件共享和隐私机制，成功解决了联邦学习中的Non-IID数据分布和隐私保护双重挑战，为跨域协作提供了可行的解决方案。

Abstract: We present ALIGN-FL, a novel approach to distributed learning that addresses the challenge of learning from highly disjoint data distributions through selective sharing of generative components. Instead of exchanging full model parameters, our framework enables privacy-preserving learning by transferring only generative capabilities across clients, while the server performs global training using synthetic samples. Through complementary privacy mechanisms: DP-SGD with adaptive clipping and Lipschitz regularized VAE decoders and a stateful architecture supporting heterogeneous clients, we experimentally validate our approach on MNIST and Fashion-MNIST datasets with cross-domain outliers. Our analysis demonstrates that both privacy mechanisms effectively map sensitive outliers to typical data points while maintaining utility in extreme Non-IID scenarios typical of cross-silo collaborations.
  Index Terms: Client-invariant Learning, Federated Learning (FL), Privacy-preserving Generative Models, Non-Independent and Identically Distributed (Non-IID), Heterogeneous Architectures

</details>


### [221] [KD-PINN: Knowledge-Distilled PINNs for ultra-low-latency real-time neural PDE solvers](https://arxiv.org/abs/2512.13336)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: 提出KD-PINN框架，通过知识蒸馏将高容量教师模型的预测精度转移到紧凑学生模型，实现物理精度保持和4.8-6.9倍推理加速，达到亚10ms超低延迟实时求解PDE。


<details>
  <summary>Details</summary>
Motivation: 开发准确且超低延迟的神经PDE求解器，解决传统PINNs推理延迟较高的问题，实现实时物理系统模拟。

Method: 提出知识蒸馏物理信息神经网络框架，通过连续调整Kullback-Leibler散度将高容量教师模型的预测能力转移到紧凑学生模型，在多种PDE上进行评估验证。

Result: 学生模型保持了教师模型的物理精度，平均RMSE增加低于0.64%，推理速度提升4.8倍（Navier-Stokes）到6.9倍（Burgers），平均推理延迟5.3ms，达到亚10ms超低延迟实时性能。

Conclusion: KD-PINN框架成功实现了PINNs的推理延迟显著降低，同时保持物理精度，为开发准确且超低延迟的神经PDE求解器提供了有效途径，蒸馏过程还具有正则化效果。

Abstract: This work introduces Knowledge-Distilled Physics-Informed Neural Networks (KD-PINN), a framework that transfers the predictive accuracy of a high-capacity teacher model to a compact student through a continuous adaptation of the Kullback-Leibler divergence. To confirm its generality for various dynamics and dimensionalities, the framework is evaluated on a representative set of partial differential equations (PDEs). In all tested cases, the student model preserved the teacher's physical accuracy, with a mean RMSE increase below 0.64%, and achieved inference speedups ranging from 4.8x (Navier-Stokes) to 6.9x (Burgers). The distillation process also revealed a regularizing effect. With an average inference latency of 5.3 ms on CPU, the distilled models enter the ultra-low-latency real-time regime defined by sub-10 ms performance. Finally, this study examines how knowledge distillation reduces inference latency in PINNs to contribute to the development of accurate ultra-low-latency neural PDE solvers.

</details>


### [222] [FROC: A Unified Framework with Risk-Optimized Control for Machine Unlearning in LLMs](https://arxiv.org/abs/2512.13337)
*Si Qi Goh,Yongsen Zheng,Ziyao Liu,Sami Hormi,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: FROC是一个用于大语言模型机器遗忘的统一框架，通过风险优化控制来平衡遗忘充分性和效用保留，提供可解释的风险评估和配置选择。


<details>
  <summary>Details</summary>
Motivation: 当前机器遗忘技术缺乏有效的风险评估和控制机制，难以在安全性和效用之间取得适当平衡，这阻碍了"被遗忘权"的实际应用，需要一种系统化的风险控制框架。

Method: 提出FROC框架，采用符合性风险控制方法，构建连续风险模型，计算符合性遗忘风险(CUR)和风险控制配置集，通过概率约束来指导遗忘策略选择和超参数调整。

Result: 实验表明FROC能生成稳定可解释的风险景观，揭示遗忘配置、语义偏移和效用影响之间的一致关系，为大规模LLM部署中的遗忘行为管理提供实用基础。

Conclusion: FROC将机器遗忘重构为可控、风险感知的过程，为解决大语言模型中的遗忘风险控制问题提供了系统化框架，增强了机器遗忘的可信度和实用性。

Abstract: Machine unlearning (MU) seeks to eliminate the influence of specific training examples from deployed models. As large language models (LLMs) become widely used, managing risks arising from insufficient forgetting or utility loss is increasingly crucial. Current MU techniques lack effective mechanisms for evaluating and controlling these risks, hindering the selection of strategies that appropriately balance safety and utility, and raising trust concerns surrounding the "right to be forgotten." To address these issues, we propose FROC, a unified framework with Risk-Optimized Control for machine unlearning in LLMs. FROC is built around a conformal-style risk-control formulation that expresses a user-specified risk budget on unlearning behavior. This probability-based constraint enables FROC to compare MU strategies, identify feasible operating regions, and guide hyperparameter selection according to desired trade-offs between forgetting sufficiency and utility preservation. To operationalize this constraint, FROC introduces a smoothly varying continuous risk model that aggregates forgetting deficiency and utility degradation into a single configuration-level score. Building on conformal risk analysis, FROC computes (1) the Conformal Unlearning Risk (CUR), a data-driven estimated value on the probability that forgotten samples continue to influence model predictions, and (2) risk-controlled configuration sets, which identify unlearning hyperparameters that are valid under the specified risk budget. Experiments across multiple LLM MU methods demonstrate that FROC produces stable, interpretable risk landscapes and reveals consistent relationships between unlearning configurations, semantic shift, and utility impact. FROC reframes MU as a controllable, risk-aware process and offers a practical foundation for managing unlearning behavior in large-scale LLM deployments.

</details>


### [223] [Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks](https://arxiv.org/abs/2512.13340)
*Henrik C. M. Frederiksen,Junya Shiraishi,Cedomir Stefanovic,Hei Victor Cheng,Shashi Raj Pandey*

Main category: cs.LG

TL;DR: 提出事件驱动的通信框架，将持续学习集成到物联网网络中，用于节能的故障检测


<details>
  <summary>Details</summary>
Motivation: 物联网设备上的轻量级机器学习模型由于环境非平稳性和初始训练数据有限，推理精度会下降。虽然可以通过新数据更新模型，但这会消耗额外能量，对能量受限的物联网设备不利。

Method: 引入事件驱动的通信框架，使物联网设备和边缘服务器能够协作更新轻量级ML模型，根据无线链路条件和可用能量预算进行自适应调整。

Result: 在真实数据集上的评估显示，该方法在推理召回率方面优于周期性采样和非自适应持续学习方法，在严格的能量和带宽约束下实现了高达42.8%的改进。

Conclusion: 提出的框架通过事件驱动的自适应持续学习，在物联网网络中实现了节能高效的故障检测，解决了资源受限设备在非平稳环境中的模型更新问题。

Abstract: The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limited initial training data. To counteract this, the deployed models can be updated occasionally with new observed data samples. However, this approach consumes additional energy, which is undesirable for energy constrained IoT devices. This letter introduces an event-driven communication framework that strategically integrates continual learning (CL) in IoT networks for energy-efficient fault detection. Our framework enables the IoT device and the edge server (ES) to collaboratively update the lightweight ML model by adapting to the wireless link conditions for communication and the available energy budget. Evaluation on real-world datasets show that the proposed approach can outperform both periodic sampling and non-adaptive CL in terms of inference recall; our proposed approach achieves up to a 42.8% improvement, even under tight energy and bandwidth constraint.

</details>


### [224] [On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models](https://arxiv.org/abs/2512.13352)
*Ali Al Sahili,Ali Chehab,Razane Tajeddine*

Main category: cs.LG

TL;DR: 该研究将多种成员推理攻击技术集成到数据提取流程中，系统评估它们在现实世界数据提取场景中的实际效用


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易记忆训练数据，带来严重的隐私风险，特别是训练数据提取和成员推理攻击。现有研究表明这两种威胁相互关联，但需要系统评估不同MIA技术在真实数据提取场景中的有效性

Method: 将多种成员推理攻击技术集成到数据提取流程中，通过让模型生成大量文本来提取训练数据，然后应用MIAs验证特定数据点是否包含在训练集中，系统比较不同MIA技术的性能

Result: 比较了集成设置下MIA技术的性能与传统MIA基准测试结果，评估了它们在现实世界数据提取场景中的实际效用

Conclusion: 通过系统集成和比较多种MIA技术，为评估和改进大型语言模型隐私保护提供了重要参考，有助于理解不同攻击方法在真实数据提取场景中的实际效果

Abstract: Large Language Models (LLMs) are prone to memorizing training data, which poses serious privacy risks. Two of the most prominent concerns are training data extraction and Membership Inference Attacks (MIAs). Prior research has shown that these threats are interconnected: adversaries can extract training data from an LLM by querying the model to generate a large volume of text and subsequently applying MIAs to verify whether a particular data point was included in the training set. In this study, we integrate multiple MIA techniques into the data extraction pipeline to systematically benchmark their effectiveness. We then compare their performance in this integrated setting against results from conventional MIA benchmarks, allowing us to evaluate their practical utility in real-world extraction scenarios.

</details>


### [225] [Dual-Phase Federated Deep Unlearning via Weight-Aware Rollback and Reconstruction](https://arxiv.org/abs/2512.13381)
*Changjun Zhou,Jintao Zheng,Leyou Yang,Pengfei Wang*

Main category: cs.LG

TL;DR: DPUL是一种新颖的服务器端联邦遗忘方法，通过深度移除所有有影响力的权重来防止隐私泄露，相比现有方法在准确性和时间成本上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有联邦遗忘方法存在高计算需求、复杂激励机制和客户端计算能力差异等问题，导致时间长、成本高。现有服务器端知识蒸馏方法仅移除目标客户端的更新，忽略了其他客户端贡献中嵌入的隐私，可能导致隐私泄露。

Method: DPUL包含三个组件：(1)通过过滤客户端更新幅度识别高权重参数并回滚以确保深度移除；(2)利用变分自编码器(VAE)重建和消除低权重参数；(3)使用基于投影的技术恢复模型。

Result: 在四个数据集上的实验结果表明，DPUL超越了最先进的基线方法，准确率提高了1%-5%，时间成本降低了高达12倍。

Conclusion: DPUL提供了一种有效的服务器端联邦遗忘解决方案，能够深度移除所有有影响力的权重，防止隐私泄露，同时在准确性和效率方面都有显著改进。

Abstract: Federated Unlearning (FUL) focuses on client data and computing power to offer a privacy-preserving solution. However, high computational demands, complex incentive mechanisms, and disparities in client-side computing power often lead to long times and higher costs. To address these challenges, many existing methods rely on server-side knowledge distillation that solely removes the updates of the target client, overlooking the privacy embedded in the contributions of other clients, which can lead to privacy leakage. In this work, we introduce DPUL, a novel server-side unlearning method that deeply unlearns all influential weights to prevent privacy pitfalls. Our approach comprises three components: (i) identifying high-weight parameters by filtering client update magnitudes, and rolling them back to ensure deep removal. (ii) leveraging the variational autoencoder (VAE) to reconstruct and eliminate low-weight parameters. (iii) utilizing a projection-based technique to recover the model. Experimental results on four datasets demonstrate that DPUL surpasses state-of-the-art baselines, providing a 1%-5% improvement in accuracy and up to 12x reduction in time cost.

</details>


### [226] [Multiclass Graph-Based Large Margin Classifiers: Unified Approach for Support Vectors and Neural Networks](https://arxiv.org/abs/2512.13410)
*Vítor M. Hanriot,Luiz C. B. Torres,Antônio P. Braga*

Main category: cs.LG

TL;DR: 本文提出基于Gabriel图的分类方法改进，包括平滑激活函数、结构支持向量中心神经元、神经网络扩展以及新的图正则化成员函数，实验表明该方法优于先前GG分类器且与树模型统计等效。


<details>
  <summary>Details</summary>
Motivation: 虽然大间隔分类器源于优化框架，但支持向量可以从几何方法获得。本文旨在推进Gabriel图在二元和多类分类问题中的应用，改进现有GG分类器的性能。

Method: 1) 为Chipclass分类器提出平滑激活函数和结构支持向量中心神经元；2) 扩展神经网络架构，可通过反向传播或解线性方程组训练；3) 提出新的基于子图/距离的图正则化成员函数；4) 开发计算成本更低的GG重计算算法。

Result: Friedman检验实验结果显示，该方法优于先前GG分类器，且与树模型统计等效。

Conclusion: 本文提出的GG分类方法改进有效提升了分类性能，在保持几何方法优势的同时达到了与优化方法相当的统计性能。

Abstract: While large margin classifiers are originally an outcome of an optimization framework, support vectors (SVs) can be obtained from geometric approaches. This article presents advances in the use of Gabriel graphs (GGs) in binary and multiclass classification problems. For Chipclass, a hyperparameter-less and optimization-less GG-based binary classifier, we discuss how activation functions and support edge (SE)-centered neurons affect the classification, proposing smoother functions and structural SV (SSV)-centered neurons to achieve margins with low probabilities and smoother classification contours. We extend the neural network architecture, which can be trained with backpropagation with a softmax function and a cross-entropy loss, or by solving a system of linear equations. A new subgraph-/distance-based membership function for graph regularization is also proposed, along with a new GG recomputation algorithm that is less computationally expensive than the standard approach. Experimental results with the Friedman test show that our method was better than previous GG-based classifiers and statistically equivalent to tree-based models.

</details>


### [227] [XNNTab -- Interpretable Neural Networks for Tabular Data using Sparse Autoencoders](https://arxiv.org/abs/2512.13442)
*Khawla Elhadri,Jörg Schlötterer,Christin Seifert*

Main category: cs.LG

TL;DR: XNNTab是一个结合神经网络表达能力和可解释性的架构，通过稀疏自编码器将非线性特征分解为单语义特征并赋予人类可解释概念，在保持高性能的同时实现内在可解释性。


<details>
  <summary>Details</summary>
Motivation: 在依赖表格数据且需要可解释性的应用中，决策树和线性回归等模型被广泛使用，而神经网络虽然预测性能更高，但由于其黑盒性质而未被采用。需要一种既能保持神经网络表达能力又具备可解释性的解决方案。

Method: XNNTab首先学习高度非线性的特征表示，然后使用稀疏自编码器（SAE）将这些特征分解为单语义特征，最后为这些特征分配人类可解释的概念，使整个模型预测具有内在可解释性。

Result: XNNTab在性能上超越了可解释预测模型，并且与非可解释的对应模型达到了相当的性能水平。

Conclusion: XNNTab成功地将神经网络的表达能力与可解释性相结合，为表格数据应用提供了一种既高性能又透明的解决方案，填补了当前可解释模型与黑盒神经网络之间的空白。

Abstract: In data-driven applications relying on tabular data, where interpretability is key, machine learning models such as decision trees and linear regression are applied. Although neural networks can provide higher predictive performance, they are not used because of their blackbox nature. In this work, we present XNNTab, a neural architecture that combines the expressiveness of neural networks and interpretability. XNNTab first learns highly non-linear feature representations, which are decomposed into monosemantic features using a sparse autoencoder (SAE). These features are then assigned human-interpretable concepts, making the overall model prediction intrinsically interpretable. XNNTab outperforms interpretable predictive models, and achieves comparable performance to its non-interpretable counterparts.

</details>


### [228] [SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy](https://arxiv.org/abs/2512.13458)
*Yici Liu,Qi Wei Oung,Hoi Leong Lee*

Main category: cs.LG

TL;DR: 提出一种通过源选择与对抗策略的跨被试EEG情绪识别方法，解决个体差异和负迁移问题，在SEED和SEED-IV数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有跨被试EEG情绪识别研究大多忽视了个体间变异性和模型训练中的负迁移现象，这限制了实际应用效果。

Method: 提出包含两个模块的方法：源选择网络（SS）通过反转域适应训练过程，破坏类可分性并放大域间差异；对抗策略网络（AS）利用源选择结果和预训练的域判别器，在对抗训练中增强域分类性能。

Result: 在SEED和SEED-IV两个EEG情绪数据集上取得了出色的性能表现。

Conclusion: 该方法有效解决了跨被试EEG情绪识别中的个体差异和负迁移问题，通过源选择与对抗策略的结合实现了更好的域不变情感相关表示学习。

Abstract: Electroencephalographic (EEG) signals have long been applied in the field of affective brain-computer interfaces (aBCIs). Cross-subject EEG-based emotion recognition has demonstrated significant potential in practical applications due to its suitability across diverse people. However, most studies on cross-subject EEG-based emotion recognition neglect the presence of inter-individual variability and negative transfer phenomena during model training. To address this issue, a cross-subject EEG-based emotion recognition through source selection with adversarial strategy is introduced in this paper. The proposed method comprises two modules: the source selection network (SS) and the adversarial strategies network (AS). The SS uses domain labels to reverse-engineer the training process of domain adaptation. Its key idea is to disrupt class separability and magnify inter-domain differences, thereby raising the classification difficulty and forcing the model to learn domain-invariant yet emotion-relevant representations. The AS gets the source domain selection results and the pretrained domain discriminators from SS. The pretrained domain discriminators compute a novel loss aimed at enhancing the performance of domain classification during adversarial training, ensuring the balance of adversarial strategies. This paper provides theoretical insights into the proposed method and achieves outstanding performance on two EEG-based emotion datasets, SEED and SEED-IV. The code can be found at https://github.com/liuyici/SSAS.

</details>


### [229] [DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems](https://arxiv.org/abs/2512.13460)
*Chethana Prasad Kabgere,Shylaja S S*

Main category: cs.LG

TL;DR: DP-EMAR：一种差分隐私、基于错误模型的自主修复框架，用于检测和修复联邦物联网中传输引起的模型权重失真，同时保持隐私保护。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的物联网网络中，联邦学习面临模型权重失真的挑战。多层级联邦物联网系统中，不稳定的连接和对抗性干扰会悄无声息地改变传输参数，导致收敛性能下降。

Method: 提出DP-EMAR框架，通过估计损坏模式并在添加隐私噪声前应用自适应校正，实现传输引起失真的检测和重建。该框架将差分隐私与安全聚合相结合，区分DP噪声与真实传输错误。

Result: 在异构物联网传感器和图数据集上的实验表明，DP-EMAR在通信损坏情况下保持收敛稳定性，维持接近基线的性能，同时确保严格的(epsilon, delta)-DP保证。

Conclusion: DP-EMAR框架增强了隐私保护联邦物联网学习的鲁棒性、通信效率和可信度，为资源受限环境下的可靠联邦学习提供了解决方案。

Abstract: Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter transmitted parameters, degrading convergence. We propose DP-EMAR, a differentially private, error model based autonomous repair framework that detects and reconstructs transmission induced distortions during FL aggregation. DP-EMAR estimates corruption patterns and applies adaptive correction before privacy noise is added, enabling reliable in network repair without violating confidentiality. By integrating Differential Privacy (DP) with Secure Aggregation (SA), the framework distinguishes DP noise from genuine transmission errors. Experiments on heterogeneous IoT sensor and graph datasets show that DP-EMAR preserves convergence stability and maintains near baseline performance under communication corruption while ensuring strict (epsilon, delta)-DP guarantees. The framework enhances robustness, communication efficiency, and trust in privacy preserving Federated IoT learning.

</details>


### [230] [Element-wise Modulation of Random Matrices for Efficient Neural Layers](https://arxiv.org/abs/2512.13480)
*Maksymilian Szorc*

Main category: cs.LG

TL;DR: 提出参数化随机投影层，通过固定随机矩阵加可学习逐元素参数，大幅减少全连接层参数量，保持精度同时提升计算效率


<details>
  <summary>Details</summary>
Motivation: 全连接层是深度神经网络中内存和计算开销的主要来源，其密集且冗余的参数化导致效率低下。现有压缩技术通常引入复杂的工程权衡或降低模型性能。

Method: 提出参数化随机投影层，将特征混合与适应解耦：使用固定的随机矩阵，通过轻量级、可学习的逐元素参数进行调制。这种架构将可训练参数数量减少到线性规模。

Result: 在各种基准测试中保持可靠的准确性，同时大幅减少可训练参数数量。该设计为架构扩展和资源受限环境中的部署提供了稳定、计算高效的解决方案。

Conclusion: PRP层是一种新颖的神经网络层设计，通过解耦特征混合和适应过程，在保持模型性能的同时显著减少了参数和计算开销，特别适合资源受限的部署场景。

Abstract: Fully connected layers are a primary source of memory and computational overhead in deep neural networks due to their dense, often redundant parameterization. While various compression techniques exist, they frequently introduce complex engineering trade-offs or degrade model performance. We propose the Parametrized Random Projection (PRP) layer, a novel approach that decouples feature mixing from adaptation by utilizing a fixed random matrix modulated by lightweight, learnable element-wise parameters. This architecture drastically reduces the trainable parameter count to a linear scale while retaining reliable accuracy across various benchmarks. The design serves as a stable, computationally efficient solution for architectural scaling and deployment in resource-limited settings.

</details>


### [231] [On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing](https://arxiv.org/abs/2512.13497)
*Haoyu Ren,Kay Koehle,Kirill Dorofeev,Darko Anicic*

Main category: cs.LG

TL;DR: 本文提出一种基于设备端持续学习的无监督视觉异常检测方法，通过轻量级特征提取器和增量核心集更新机制，在动态工业生产环境中实现快速、内存高效的模型适应。


<details>
  <summary>Details</summary>
Motivation: 现代制造业中动态灵活的生产环境带来三大挑战：1) 小批量按需制造中产品频繁变更需要快速模型更新；2) 传统边缘硬件缺乏训练大型AI模型的资源；3) 异常和正常训练数据通常稀缺，特别是对新引入的产品变体。

Method: 扩展PatchCore方法，结合在线学习机制，采用轻量级特征提取器和基于k中心选择的增量核心集更新机制，实现设备端持续学习，无需昂贵的云端重新训练。

Result: 在模拟灵活生产的工业用例测试中，相比基线方法获得12%的AUROC提升，内存使用减少80%，训练速度比批量重新训练更快。

Conclusion: 该方法为动态智能制造提供了准确、资源高效且自适应的视觉异常检测解决方案，适合资源受限的边缘设备部署。

Abstract: In modern manufacturing, Visual Anomaly Detection (VAD) is essential for automated inspection and consistent product quality. Yet, increasingly dynamic and flexible production environments introduce key challenges: First, frequent product changes in small-batch and on-demand manufacturing require rapid model updates. Second, legacy edge hardware lacks the resources to train and run large AI models. Finally, both anomalous and normal training data are often scarce, particularly for newly introduced product variations. We investigate on-device continual learning for unsupervised VAD with localization, extending the PatchCore to incorporate online learning for real-world industrial scenarios. The proposed method leverages a lightweight feature extractor and an incremental coreset update mechanism based on k-center selection, enabling rapid, memory-efficient adaptation from limited data while eliminating costly cloud retraining. Evaluations on an industrial use case are conducted using a testbed designed to emulate flexible production with frequent variant changes in a controlled environment. Our method achieves a 12% AUROC improvement over the baseline, an 80% reduction in memory usage, and faster training compared to batch retraining. These results confirm that our method delivers accurate, resource-efficient, and adaptive VAD suitable for dynamic and smart manufacturing.

</details>


### [232] [Learning under Distributional Drift: Reproducibility as an Intrinsic Statistical Resource](https://arxiv.org/abs/2512.13506)
*Sofiya Zaichyk*

Main category: cs.LG

TL;DR: 论文提出"可重复性预算"$C_T$作为量化统计可重复性的新指标，在分布漂移和反馈机制下，推导出最优的泛化误差界$O(T^{-1/2} + C_T/T)$，建立了可重复性的速度极限。


<details>
  <summary>Details</summary>
Motivation: 在分布漂移（每个观测都会改变数据生成规律）和内生反馈的复杂环境下，传统的泛化界限可能失效。需要一个新的统计框架来量化系统在分布变化下的可重复性能力。

Method: 引入"可重复性预算"$C_T$作为统计原语，定义为耦合学习器-环境演化的累积Fisher-Rao路径长度，量化分布运动总量。基于此推导泛化误差界并证明其极小极大最优性。

Result: 得到漂移-反馈泛化误差界$O(T^{-1/2} + C_T/T)$，证明该速率是极小极大最优的，建立了可重复性速度极限：任何算法的最坏情况泛化误差都不能低于数据生成过程的平均Fisher-Rao漂移率$C_T/T$。

Conclusion: 该框架将外生漂移、自适应数据分析和执行性预测统一在共同的几何结构中，$C_T$成为衡量这些场景中分布运动的内在量，为分布漂移下的统计学习提供了理论基础。

Abstract: Statistical learning under distributional drift remains insufficiently characterized: when each observation alters the data-generating law, classical generalization bounds can collapse. We introduce a new statistical primitive, the reproducibility budget $C_T$, which quantifies a system's finite capacity for statistical reproducibility - the extent to which its sampling process can remain governed by a consistent underlying distribution in the presence of both exogenous change and endogenous feedback. Formally, $C_T$ is defined as the cumulative Fisher-Rao path length of the coupled learner-environment evolution, measuring the total distributional motion accumulated during learning. From this construct we derive a drift-feedback generalization bound of order $O(T^{-1/2} + C_T/T)$, and we prove a matching minimax lower bound showing that this rate is minimax-optimal. Consequently, the results establish a reproducibility speed limit: no algorithm can achieve smaller worst-case generalization error than that imposed by the average Fisher-Rao drift rate $C_T/T$ of the data-generating process. The framework situates exogenous drift, adaptive data analysis, and performative prediction within a common geometric structure, with $C_T$ emerging as the intrinsic quantity measuring distributional motion across these settings.

</details>


### [233] [Async Control: Stress-testing Asynchronous Control Measures for LLM Agents](https://arxiv.org/abs/2512.13526)
*Asa Cooper Stickland,Jan Michelfeit,Arathi Mani,Charlie Griffin,Ollie Matthews,Tomek Korbak,Rogan Inglis,Oliver Makins,Alan Cooney*

Main category: cs.LG

TL;DR: 研究针对LLM软件工程代理的异步监控方法，通过红蓝对抗游戏开发监控器，在5个软件工程环境中实现6%漏报率（1%误报率），并评估部署时的破坏风险。


<details>
  <summary>Details</summary>
Motivation: LLM软件工程代理在实际开发任务中可能访问敏感数据或安全关键代码库，如果代理未对齐可能故意破坏代码库。需要监控系统来检测和防止此类破坏行为。

Method: 采用异步监控方法（事后审查代理行为），建立红蓝对抗游戏：蓝队设计监控器，红队创建破坏性代理。在5个多样化的软件工程环境中进行测试，开发集成监控器。

Result: 开发出的集成监控器在保留测试环境中达到6%的漏报率（假阴性率）和1%的误报率（假阳性率）。通过漏报率外推估计部署时的破坏风险。

Conclusion: 异步监控是检测LLM代理破坏行为的有效方法，红蓝对抗游戏能开发出高性能监控器，但需要谨慎外推风险估计模型。

Abstract: LLM-based software engineering agents are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such agents could intentionally sabotage these codebases if they were misaligned. We investigate asynchronous monitoring, in which a monitoring system reviews agent actions after the fact. Unlike synchronous monitoring, this approach does not impose runtime latency, while still attempting to disrupt attacks before irreversible harm occurs. We treat monitor development as an adversarial game between a blue team (who design monitors) and a red team (who create sabotaging agents). We attempt to set the game rules such that they upper bound the sabotage potential of an agent based on Claude 4.1 Opus. To ground this game in a realistic, high-stakes deployment scenario, we develop a suite of 5 diverse software engineering environments that simulate tasks that an agent might perform within an AI developer's internal infrastructure. Over the course of the game, we develop an ensemble monitor that achieves a 6% false negative rate at 1% false positive rate on a held out test environment. Then, we estimate risk of sabotage at deployment time by extrapolating from our monitor's false negative rate. We describe one simple model for this extrapolation, present a sensitivity analysis, and describe situations in which the model would be invalid. Code is available at: https://github.com/UKGovernmentBEIS/async-control.

</details>


### [234] [Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability](https://arxiv.org/abs/2512.13568)
*Leonard Bereska,Zoe Tzifa-Kratira,Reza Samavi,Efstratios Gavves*

Main category: cs.LG

TL;DR: 提出信息论框架测量神经网络表示的有效自由度，将叠加视为有损压缩，量化网络通过叠加模拟的"虚拟神经元"数量


<details>
  <summary>Details</summary>
Motivation: 神经网络通过叠加（多个特征作为激活空间中的重叠方向）实现卓越性能，这挑战了可解释性，但缺乏测量叠加的原则性方法

Method: 应用香农熵到稀疏自编码器激活，计算有效特征数量作为无干扰编码所需的最小神经元数，等价于测量网络通过叠加模拟的"虚拟神经元"数量

Result: 度量在玩具模型中与真实值强相关，在算法任务中检测到最小叠加，在dropout下显示系统性减少，层间模式与Pythia-70M的内在维度研究一致，能捕捉grokking期间的尖锐特征整合

Conclusion: 将叠加定义为有损压缩，使原则性测量神经网络在计算约束下如何组织信息成为可能，连接了叠加与对抗鲁棒性，发现对抗训练可增加有效特征同时提高鲁棒性

Abstract: Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of freedom. We apply Shannon entropy to sparse autoencoder activations to compute the number of effective features as the minimum neurons needed for interference-free encoding. Equivalently, this measures how many "virtual neurons" the network simulates through superposition. When networks encode more effective features than actual neurons, they must accept interference as the price of compression. Our metric strongly correlates with ground truth in toy models, detects minimal superposition in algorithmic tasks, and reveals systematic reduction under dropout. Layer-wise patterns mirror intrinsic dimensionality studies on Pythia-70M. The metric also captures developmental dynamics, detecting sharp feature consolidation during grokking. Surprisingly, adversarial training can increase effective features while improving robustness, contradicting the hypothesis that superposition causes vulnerability. Instead, the effect depends on task complexity and network capacity: simple tasks with ample capacity allow feature expansion (abundance regime), while complex tasks or limited capacity force reduction (scarcity regime). By defining superposition as lossy compression, this work enables principled measurement of how neural networks organize information under computational constraints, connecting superposition to adversarial robustness.

</details>


### [235] [DP-CSGP: Differentially Private Stochastic Gradient Push with Compressed Communication](https://arxiv.org/abs/2512.13583)
*Zehan Zhu,Heng Zhao,Yan Huang,Joey Tianyi Zhou,Shouling Ji,Jinming Xu*

Main category: cs.LG

TL;DR: 提出DP-CSGP算法，在定向图上的去中心化学习中实现差分隐私保护、梯度压缩通信，在保持模型效用的同时降低通信成本


<details>
  <summary>Details</summary>
Motivation: 现有去中心化学习算法在隐私保护和通信效率方面存在不足，需要同时满足差分隐私保证和高效通信，特别是在定向图拓扑结构下

Method: 提出差分隐私随机梯度推送压缩算法(DP-CSGP)，结合差分隐私机制、梯度压缩技术和推送协议，适用于定向图上的去中心化学习

Result: 对于一般非凸光滑目标函数，算法达到紧致的效用界O(√(d log(1/δ))/(√nJε))，与精确通信的去中心化算法相当，但通信成本显著降低

Conclusion: DP-CSGP在相同隐私预算下，通过压缩通信实现了与精确通信算法相当的模型精度，同时大幅降低通信成本，为隐私保护的分布式学习提供了高效解决方案

Abstract: In this paper, we propose a Differentially Private Stochastic Gradient Push with Compressed communication (termed DP-CSGP) for decentralized learning over directed graphs. Different from existing works, the proposed algorithm is designed to maintain high model utility while ensuring both rigorous differential privacy (DP) guarantees and efficient communication. For general non-convex and smooth objective functions, we show that the proposed algorithm achieves a tight utility bound of $\mathcal{O}\left( \sqrt{d\log \left( \frac{1}δ \right)}/(\sqrt{n}Jε) \right)$ ($J$ and $d$ are the number of local samples and the dimension of decision variables, respectively) with $\left(ε, δ\right)$-DP guarantee for each node, matching that of decentralized counterparts with exact communication. Extensive experiments on benchmark tasks show that, under the same privacy budget, DP-CSGP achieves comparable model accuracy with significantly lower communication cost than existing decentralized counterparts with exact communication.

</details>


### [236] [Image Diffusion Preview with Consistency Solver](https://arxiv.org/abs/2512.13592)
*Fu-Yun Wang,Hao Zhou,Liangzhe Yuan,Sanghyun Woo,Boqing Gong,Bohyung Han,Ming-Hsuan Yang,Han Zhang,Yukun Zhu,Ting Liu,Long Zhao*

Main category: cs.LG

TL;DR: 提出Diffusion Preview范式，通过快速低步采样生成预览供用户评估，满意后再进行完整步数精炼。为了解决现有方法预览质量差和一致性不足的问题，提出了基于强化学习优化的ConsistencySolver高阶求解器。


<details>
  <summary>Details</summary>
Motivation: 图像扩散模型推理速度慢严重影响交互体验，需要一种高效的预览-精炼工作流程。现有加速方法（如免训练求解器和后训练蒸馏）难以在低步数下提供高质量预览，且无法保证预览与最终输出的一致性。

Method: 提出ConsistencySolver，基于通用线性多步方法设计，是一个轻量级、可训练的高阶求解器。通过强化学习进行优化，专门提升低步数场景下的预览质量和一致性。

Result: ConsistencySolver在低步数场景下显著提升生成质量和一致性。相比Multistep DPM-Solver，用47%更少的步数达到相当的FID分数，且优于蒸馏基线。用户研究表明该方法减少近50%的用户交互时间，同时保持生成质量。

Conclusion: ConsistencySolver为高效的预览-精炼工作流程提供了理想解决方案，显著改善了扩散模型的交互体验，在保持生成质量的同时大幅减少用户等待时间。

Abstract: The slow inference process of image diffusion models significantly degrades interactive user experiences. To address this, we introduce Diffusion Preview, a novel paradigm employing rapid, low-step sampling to generate preliminary outputs for user evaluation, deferring full-step refinement until the preview is deemed satisfactory. Existing acceleration methods, including training-free solvers and post-training distillation, struggle to deliver high-quality previews or ensure consistency between previews and final outputs. We propose ConsistencySolver derived from general linear multistep methods, a lightweight, trainable high-order solver optimized via Reinforcement Learning, that enhances preview quality and consistency. Experimental results demonstrate that ConsistencySolver significantly improves generation quality and consistency in low-step scenarios, making it ideal for efficient preview-and-refine workflows. Notably, it achieves FID scores on-par with Multistep DPM-Solver using 47% fewer steps, while outperforming distillation baselines. Furthermore, user studies indicate our approach reduces overall user interaction time by nearly 50% while maintaining generation quality. Code is available at https://github.com/G-U-N/consolver.

</details>


### [237] [Scalable Formal Verification via Autoencoder Latent Space Abstraction](https://arxiv.org/abs/2512.13593)
*Robert Reed,Morteza Lahijanian,Luca Laurenti*

Main category: cs.LG

TL;DR: 提出一种基于凸自编码器和核方法的降维验证框架，可在保证正确性的前提下显著提升高维系统验证的可扩展性


<details>
  <summary>Details</summary>
Motivation: 有限抽象方法虽然为系统验证提供了强大的形式化框架，但面临高维系统的可扩展性挑战，因为状态空间离散化会随维度指数增长。基于学习的降维方法（如神经网络和自编码器）有潜力缓解这一问题，但如何确保验证结果的正确性仍是开放问题。

Method: 使用凸自编码器降低系统维度，通过核方法在潜在空间中学习系统动态，然后在潜在空间中构建有限抽象，并保证该抽象包含原始系统的真实行为。

Result: 该方法在多个系统上验证有效，包括一个由神经网络控制的26维系统，展示了显著的可扩展性改进而不损失严谨性。潜在空间中的验证结果可以映射回原始系统。

Conclusion: 提出的基于凸自编码器和核方法的降维验证框架，能够在保证验证结果正确性的前提下，有效解决高维系统验证的可扩展性问题，为复杂系统的形式化验证提供了新途径。

Abstract: Finite Abstraction methods provide a powerful formal framework for proving that systems satisfy their specifications. However, these techniques face scalability challenges for high-dimensional systems, as they rely on state-space discretization which grows exponentially with dimension. Learning-based approaches to dimensionality reduction, utilizing neural networks and autoencoders, have shown great potential to alleviate this problem. However, ensuring the correctness of the resulting verification results remains an open question. In this work, we provide a formal approach to reduce the dimensionality of systems via convex autoencoders and learn the dynamics in the latent space through a kernel-based method. We then construct a finite abstraction from the learned model in the latent space and guarantee that the abstraction contains the true behaviors of the original system. We show that the verification results in the latent space can be mapped back to the original system. Finally, we demonstrate the effectiveness of our approach on multiple systems, including a 26D system controlled by a neural network, showing significant scalability improvements without loss of rigor.

</details>


### [238] [LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification](https://arxiv.org/abs/2512.13617)
*Ankit Sharma,Sayan Roy Gupta*

Main category: cs.LG

TL;DR: LightTopoGAT：一种轻量级图注意力网络，通过拓扑增强（节点度和局部聚类系数）改进图表示学习，在保持参数效率的同时提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络需要大量计算资源且难以有效捕捉全局图属性，同时局部消息传递方案常忽略结构信息。

Method: 提出LightTopoGAT，通过节点度和局部聚类系数进行拓扑增强来改进节点特征，采用简化的注意力机制保持参数效率。

Result: 在MUTAG、ENZYMES、PROTEINS三个基准数据集上优于GCN、GraphSAGE和标准GAT，MUTAG准确率提升6.6%，PROTEINS提升2.2%。

Conclusion: 拓扑特征的加入直接带来性能提升，展示了在不增加架构复杂性的情况下增强图神经网络性能的简单有效策略。

Abstract: Graph Neural Networks have demonstrated significant success in graph classification tasks, yet they often require substantial computational resources and struggle to capture global graph properties effectively. We introduce LightTopoGAT, a lightweight graph attention network that enhances node features through topological augmentation by incorporating node degree and local clustering coefficient to improve graph representation learning. The proposed approach maintains parameter efficiency through streamlined attention mechanisms while integrating structural information that is typically overlooked by local message passing schemes. Through comprehensive experiments on three benchmark datasets, MUTAG, ENZYMES, and PROTEINS, we show that LightTopoGAT achieves superior performance compared to established baselines including GCN, GraphSAGE, and standard GAT, with a 6.6 percent improvement in accuracy on MUTAG and a 2.2 percent improvement on PROTEINS. Ablation studies further confirm that these performance gains arise directly from the inclusion of topological features, demonstrating a simple yet effective strategy for enhancing graph neural network performance without increasing architectural complexity.

</details>


### [239] [StutterFuse: Mitigating Modality Collapse in Stuttering Detection with Jaccard-Weighted Metric Learning and Gated Fusion](https://arxiv.org/abs/2512.13632)
*Guransh Singh,Md Shah Fahad*

Main category: cs.LG

TL;DR: 提出StutterFuse，首个基于检索增强分类器的多标签口吃检测方法，通过结合临床案例记忆库解决重叠性口吃检测难题，并解决模态塌陷问题。


<details>
  <summary>Details</summary>
Motivation: 现有参数化模型难以检测重叠性口吃（如"阻塞"与"延长"同时发生），因为训练数据中这些特定组合稀缺。检索增强生成范式在NLP领域取得成功，但在病理语音处理中尚未探索。

Method: 提出StutterFuse检索增强分类器，使用Conformer编码器结合非参数化临床案例记忆库，通过参考而非记忆进行分类。解决模态塌陷问题的方法：1) SetCon目标函数优化多标签集合相似度；2) 门控专家混合融合策略动态平衡声学证据与检索上下文。

Result: 在SEP-28k数据集上获得0.65的加权F1分数，优于强基线模型，并展现出卓越的零样本跨语言泛化能力。

Conclusion: StutterFuse首次将检索增强范式引入病理语音处理，通过参考临床案例有效解决重叠性口吃检测难题，为口吃检测提供了新方向。

Abstract: Stuttering detection breaks down when disfluencies overlap. Existing parametric models struggle to distinguish complex, simultaneous disfluencies (e.g., a 'block' with a 'prolongation') due to the scarcity of these specific combinations in training data. While Retrieval-Augmented Generation (RAG) has revolutionized NLP by grounding models in external knowledge, this paradigm remains unexplored in pathological speech processing. To bridge this gap, we introduce StutterFuse, the first Retrieval-Augmented Classifier (RAC) for multi-label stuttering detection. By conditioning a Conformer encoder on a non-parametric memory bank of clinical examples, we allow the model to classify by reference rather than memorization. We further identify and solve "Modality Collapse", an "Echo Chamber" effect where naive retrieval boosts recall but degrades precision. We mitigate this using: (1) SetCon, a Jaccard-Weighted Metric Learning objective that optimizes for multi-label set similarity, and (2) a Gated Mixture-of-Experts fusion strategy that dynamically arbitrates between acoustic evidence and retrieved context. On the SEP-28k dataset, StutterFuse achieves a weighted F1-score of 0.65, outperforming strong baselines and demonstrating remarkable zero-shot cross-lingual generalization.

</details>


### [240] [From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves](https://arxiv.org/abs/2512.13641)
*Gabriel Vitorino de Andrade,Saulo Roberto dos Santos,Itallo Patrick Castro Alves da Silva,Emanuel Adler Medeiros Pereira,Erick de Andrade Barboza*

Main category: cs.LG

TL;DR: 该研究提出了一种评估卷积神经网络在芒果叶病害诊断中鲁棒性的方法，通过创建包含19种人工损坏的MangoLeafDB-C数据集，比较了5种架构在恶劣条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管芒果具有全球重要性，但缺乏针对芒果叶病害诊断模型鲁棒性的研究。需要评估AI模型在真实世界挑战（如图像损坏）下的可靠性能，特别是在农业应用中。

Method: 将MangoLeafDB数据集适配为MangoLeafDB-C，包含19种人工损坏类型和5个严重级别。对5种CNN架构（ResNet-50、ResNet-101、VGG-16、Xception和专门设计的轻量级LCNN）进行基准测试，使用F1分数、损坏错误（CE）和相对平均损坏错误（相对mCE）作为评估指标。

Result: LCNN在真实场景可能出现的损坏（如散焦模糊、运动模糊）中表现优于复杂模型，并获得了最低的mCE。现代架构（如ResNet-101）在损坏场景中表现出显著的性能下降，尽管在理想条件下具有高准确性。

Conclusion: 轻量级和专门化模型可能更适合边缘设备的实际应用，其中鲁棒性和效率至关重要。研究强调了在农业智能系统开发中纳入鲁棒性评估的必要性，特别是在技术受限地区。

Abstract: The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutional neural networks (CNNs) under adverse conditions. We adapted the MangoLeafDB dataset, generating MangoLeafDB-C with 19 types of artificial corruptions at five severity levels. We conducted a benchmark comparing five architectures: ResNet-50, ResNet-101, VGG-16, Xception, and LCNN (the latter being a lightweight architecture designed specifically for mango leaf diagnosis). The metrics include the F1 score, the corruption error (CE) and the relative mean corruption error (relative mCE). The results show that LCNN outperformed complex models in corruptions that can be present in real-world scenarios such as Defocus Blur, Motion Blur, while also achieving the lowest mCE. Modern architectures (e.g., ResNet-101) exhibited significant performance degradation in corrupted scenarios, despite their high accuracy under ideal conditions. These findings suggest that lightweight and specialized models may be more suitable for real-world applications in edge devices, where robustness and efficiency are critical. The study highlights the need to incorporate robustness assessments in the development of intelligent systems for agriculture, particularly in regions with technological limitations.

</details>


### [241] [A Scientific Reasoning Model for Organic Synthesis Procedure Generation](https://arxiv.org/abs/2512.13668)
*Guoqing Liu,Junren Li,Zihan Zhao,Eray Inanc,Krzysztof Maziarz,Jose Garrido Torres,Victor Garcia Satorras,Shoko Ueda,Christopher M. Bishop,Marwin Segler*

Main category: cs.LG

TL;DR: QFANG是一个科学推理语言模型，能够从反应方程直接生成精确的结构化实验程序，通过化学引导推理和强化学习实现高质量合成程序生成。


<details>
  <summary>Details</summary>
Motivation: 解决计算机辅助合成规划中的关键挑战：弥合计算路线设计与实际实验室执行之间的差距，特别是准确预测每个合成步骤的可行实验程序。

Method: 1. 构建高质量数据集：从专利文献中提取90.5万个化学反应与结构化动作序列；2. 化学引导推理框架：基于化学知识生成大规模思维链数据；3. 监督微调：激发复杂化学推理能力；4. 强化学习：使用可验证奖励进一步优化程序准确性。

Result: QFANG在传统NLP相似度指标和化学感知评估器上均优于先进通用推理模型和最近邻检索基线，能够泛化到某些域外反应类别，并适应实验室条件和用户特定约束的变化。

Conclusion: QFANG生成高质量合成程序的能力代表了向弥合计算合成规划与全自动实验室合成之间差距的重要一步。

Abstract: Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly the accurate prediction of viable experimental procedures for each synthesis step. In this work, we present QFANG, a scientific reasoning language model capable of generating precise, structured experimental procedures directly from reaction equations, with explicit chain-of-thought reasoning. To develop QFANG, we curated a high-quality dataset comprising 905,990 chemical reactions paired with structured action sequences, extracted and processed from patent literature using large language models. We introduce a Chemistry-Guided Reasoning (CGR) framework that produces chain-of-thought data grounded in chemical knowledge at scale. The model subsequently undergoes supervised fine-tuning to elicit complex chemistry reasoning. Finally, we apply Reinforcement Learning from Verifiable Rewards (RLVR) to further enhance procedural accuracy. Experimental results demonstrate that QFANG outperforms advanced general-purpose reasoning models and nearest-neighbor retrieval baselines, measured by traditional NLP similarity metrics and a chemically aware evaluator using an LLM-as-a-judge. Moreover, QFANG generalizes to certain out-of-domain reaction classes and adapts to variations in laboratory conditions and user-specific constraints. We believe that QFANG's ability to generate high-quality synthesis procedures represents an important step toward bridging the gap between computational synthesis planning and fully automated laboratory synthesis.

</details>


### [242] [Directional Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2512.13672)
*Kunhee Kim,NaHyeon Park,Kibeom Hong,Hyunjung Shim*

Main category: cs.LG

TL;DR: DTI通过固定嵌入向量的模长并仅优化方向，解决了传统TI方法中嵌入向量模长膨胀导致复杂提示失败的问题，提高了文本忠实度并支持概念间的平滑插值。


<details>
  <summary>Details</summary>
Motivation: 传统文本反转(TI)方法在处理复杂提示时经常失败，研究发现这是由于学习到的token嵌入向量的模长膨胀，导致在预归一化Transformer中提示条件恶化。

Method: 提出方向性文本反转(DTI)：固定嵌入向量的模长为分布内尺度，仅通过黎曼SGD在单位超球面上优化方向；将方向学习建模为具有von Mises-Fisher先验的MAP估计。

Result: DTI在个性化任务中比TI及其变体提高了文本忠实度，同时保持了主体相似性；其超球面参数化支持学习概念间的平滑、语义连贯插值(slerp)。

Conclusion: 仅优化方向是实现提示忠实个性化的鲁棒且可扩展路径，方向学习比传统TI方法在复杂提示下表现更好。

Abstract: Textual Inversion (TI) is an efficient approach to text-to-image personalization but often fails on complex prompts. We trace these failures to embedding norm inflation: learned tokens drift to out-of-distribution magnitudes, degrading prompt conditioning in pre-norm Transformers. Empirically, we show semantics are primarily encoded by direction in CLIP token space, while inflated norms harm contextualization; theoretically, we analyze how large magnitudes attenuate positional information and hinder residual updates in pre-norm blocks. We propose Directional Textual Inversion (DTI), which fixes the embedding magnitude to an in-distribution scale and optimizes only direction on the unit hypersphere via Riemannian SGD. We cast direction learning as MAP with a von Mises-Fisher prior, yielding a constant-direction prior gradient that is simple and efficient to incorporate. Across personalization tasks, DTI improves text fidelity over TI and TI-variants while maintaining subject similarity. Crucially, DTI's hyperspherical parameterization enables smooth, semantically coherent interpolation between learned concepts (slerp), a capability that is absent in standard TI. Our findings suggest that direction-only optimization is a robust and scalable path for prompt-faithful personalization.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [243] [HWF-PIKAN: A Multi-Resolution Hybrid Wavelet-Fourier Physics-Informed Kolmogorov-Arnold Network for solving Collisionless Boltzmann Equation](https://arxiv.org/abs/2512.12001)
*Mohammad E. Heravifard,Kazem Hejranfar*

Main category: physics.comp-ph

TL;DR: 提出了一种新型多分辨率混合小波-傅里叶增强物理信息Kolmogorov-Arnold网络（HWF-PIKAN），用于求解基于无碰撞玻尔兹曼方程的对流问题，在连续和不连续初始条件下均表现出色。


<details>
  <summary>Details</summary>
Motivation: PINNs和PIKANs作为解决偏微分方程的有前景方法，但现有方法在处理对流问题特别是具有不连续初始条件时可能存在局限性。需要开发能够同时捕捉平滑和突变特征的多分辨率方法。

Method: 提出HWF-PIKAN模型，结合小波和傅里叶变换的多分辨率谱特征嵌入。在一维和二维经典对流方程上进行系统基准测试，然后扩展到高维相空间设置，利用相空间动力学的哈密顿概念建模无碰撞系统中粒子的统计行为。

Result: 与Vanilla PINN、Vanilla PIKAN以及傅里叶增强和小波增强的PIKAN变体相比，提出的混合模型显著提高了求解精度和收敛速度，能够准确捕捉平滑和突变特征。

Conclusion: 多分辨率谱特征嵌入在推进物理信息深度学习框架处理复杂动力学方程方面具有强大潜力，HWF-PIKAN为空间-时间和相空间中的对流问题提供了有效的解决方案。

Abstract: Physics-Informed Neural Networks (PINNs) and more recently Physics-Informed Kolmogorov-Arnold Networks (PIKANs) have emerged as promising approaches for solving partial differential equations (PDEs) without reliance on extensive labeled data. In this work, we propose a novel multi-resolution Hybrid Wavelet-Fourier-Enhanced Physics-Informed Kolmogorov-Arnold Network (HWF-PIKAN) for solving advection problems based on collisionless Boltzmann equation (CBE) with both continuous and discontinuous initial conditions. To validate the effectiveness of the proposed model, we conduct systematic benchmarks on classical advection equations in one and two dimensions. These tests demonstrate the model's ability to accurately capture smooth and abrupt features. We then extend the application of HWF-PIKAN to the high-dimensional phase-space setting by solving the CBE in a continuous-velocity manner. This leverages the Hamiltonian concept of phase-space dynamics to model the statistical behavior of particles in a collisionless system, where advection governs the evolution of a probability distribution function or number density. Comparative analysis against Vanilla PINN, Vanilla PIKAN, as well as Fourier-enhanced and Wavelet-enhanced PIKAN variants, shows that the proposed hybrid model significantly improves solution accuracy and convergence speed. This study highlights the power of multi-resolution spectral feature embeddings in advancing physics-informed deep learning frameworks for complex kinetic equations in both space-time and phase-space.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [244] [Dynamical Systems Analysis of an Einstein-Cartan Ekpyrotic Nonsingular Bounce Cosmology](https://arxiv.org/abs/2512.11885)
*Jackson Stingley*

Main category: gr-qc

TL;DR: 作者构建了一个爱因斯坦-嘉当ekpyrotic模型，在爱因斯坦-嘉当引力框架下，通过自旋-挠率与标量场耦合，实现了非奇异的反弹宇宙学，避免了收缩相中的混沌行为。


<details>
  <summary>Details</summary>
Motivation: 传统广义相对论中的收缩宇宙背景通常会出现混沌行为和不稳定性，特别是在存在曲率扰动时。作者旨在探索爱因斯坦-嘉当引力中的自旋-挠率效应能否提供一种机制，在收缩相中实现稳定的非奇异反弹，避免奇点形成。

Method: 构建了爱因斯坦-嘉当ekpyrotic模型，将自旋-挠率建模为具有刚性标度律的Weyssenhoff流体，并与具有陡峭指数势的标量场耦合。扩展了Copeland-Liddle-Wands动力学系统到六维相空间，包括剪切、曲率和自旋-挠率。采用雅可比矩阵和李雅普诺夫指数分析稳定性，并进行数值模拟扫描参数空间。

Result: 数值解显示：ekpyrotic分支能指数阻尼均匀剪切，而软化分支允许自旋-挠率密度在收缩中超过标量场，在高密度处触发挠率支持的反弹。在二维软化参数平面中识别出有限的非奇异轨迹区域，最大李雅普诺夫指数为负，表明即使在包含曲率模式的情况下，该均匀截断也没有混沌行为。

Conclusion: 爱因斯坦-嘉当引力中的自旋-挠率效应能够实现非奇异的宇宙反弹，避免收缩相中的混沌不稳定性。该模型为构建非奇异宇宙学提供了新的可能性，但仍是纯现象学且局限于均匀背景，未解决熵积累、宇宙时间箭头或完整循环宇宙学等问题。

Abstract: I construct an Einstein-Cartan ekpyrotic model (ECEM): a homogeneous, nearly Friedmann-Lemaître-Robertson-Walker (FLRW) background in Einstein-Cartan (EC) gravity whose spin-torsion sector, modeled phenomenologically as a Weyssenhoff fluid with stiff scaling $\propto a^{-6}$, is coupled to a scalar field with a steep exponential potential that interpolates between a negative ekpyrotic branch and a positive plateau. Extending the Copeland-Liddle-Wands (CLW) scalar-fluid dynamical system to a six-dimensional phase space including shear, curvature, and spin-torsion, I recast the equations in a compact deceleration-parameter form, compute the full Jacobian, and evaluate maximal Lyapunov exponents. Numerical solutions show that the ekpyrotic branch ($w_φ\gg1$) exponentially damps homogeneous shear, while the softened branch ($w_φ<1$) allows $ρ_s$ to overtake the scalar during contraction and trigger a torsion-supported bounce at high but finite densities where the EC spin-torsion term becomes dynamically dominant. Scans in a two-parameter softening plane $(φ_{\rm b},Δ)$ identify a finite region of nonsingular trajectories and quantify the required tuning; in the parameter ranges explored the maximal Lyapunov exponent on the constrained phase space is negative, giving no indication of chaotic behavior in this homogeneous truncation even when the usual curvature mode that destabilizes contracting General Relativity (GR) backgrounds is included. The construction is purely phenomenological and confined to homogeneous backgrounds: it does not address entropy accumulation, the cosmological arrow of time, or a complete cyclic cosmology.

</details>


### [245] [Gravitational radiations from periodic orbits around a black hole in the effective field theory extension of general relativity](https://arxiv.org/abs/2512.11911)
*Shuo Lu,Hao-Jie Lin,Tao Zhu,Yu-Xiao Liu,Xin Zhang*

Main category: gr-qc

TL;DR: 研究极端质量比旋进中的周期轨道及其引力波辐射，在包含高阶曲率项的广义相对论有效场论扩展框架下，分析修正黑洞时空对周期轨道动力学和引力波波形的影响。


<details>
  <summary>Details</summary>
Motivation: 研究极端质量比旋进中的周期轨道对于理解小质量天体绕超大质量黑洞的动力学至关重要。本文旨在探索广义相对论有效场论扩展（包含高阶曲率项）中，强场偏离广义相对论如何在可观测现象中表现出来，特别是通过周期轨道及其引力波辐射。

Method: 首先分析EFTGR中的修正黑洞时空，使用拉格朗日形式研究其参数对中性大质量粒子动力学的影响。重点关注高阶曲率项对周期轨道性质的影响，这些轨道由三个拓扑整数(z,w,v)唯一分类其轨迹。然后计算这些周期轨道产生的引力波波形，识别潜在的观测特征。

Result: 分析揭示了小致密天体的缩放-旋转轨道行为与其发射的引力波波形之间的直接联系：更高的缩放数导致越来越复杂的波形子结构。结果为理解EFTGR的动力学特征提供了更清晰的见解。

Conclusion: 研究结果有助于更清晰地理解EFTGR的动力学特征，并为通过引力波探测探测黑洞性质开辟了新途径。周期轨道及其引力波特征为检验广义相对论在强场区域的修正提供了新的观测窗口。

Abstract: The study of periodic orbits in extreme-mass-ratio inspirals is essential for understanding the dynamics of small bodies orbiting supermassive black holes. In this paper, we study the periodic orbits and their corresponding gravitational wave emissions within the framework of an effective field theory-based extension of general relativity (EFTGR), which incorporates higher-order curvature terms into the Einstein-Hilbert action. We start with a brief analysis of the modified black hole spacetime in EFTGR and examine how its parameters influence the dynamics of a massive neutral particle using the Lagrangian formalism. Focusing on the impact of the higher-order curvature terms in EFTGR, we examine the properties of periodic orbits, which are characterized by three topological integers $(z, w, v)$ that uniquely classify their trajectories. By analyzing these orbits within EFTGR, we aim to provide new insights into how strong-field deviations from general relativity may manifest in observable phenomena. We then calculate the gravitational waveforms generated by these periodic orbits, identifying potential observational signatures. Our analysis reveals a direct connection between the zoom-whirl orbital behavior of the small compact object and the gravitational waveforms it emits: higher zoom numbers lead to increasingly intricate waveform substructures. The results contribute to a clearer understanding of the dynamical features of EFTGR and open new avenues for probing black hole properties via gravitational wave detection.

</details>


### [246] [Self-gravitating equilibrium with slow steady flow and the correct form of entropy current](https://arxiv.org/abs/2512.11914)
*Shuichi Yokoyama*

Main category: gr-qc

TL;DR: 研究相对论性自引力平衡系统，在流体静力学极限附近进行微扰分析，考虑稳态能量流，提出新的熵流条件来确定参数函数。


<details>
  <summary>Details</summary>
Motivation: 研究具有球对称性和稳态能量流的相对论性自引力平衡系统，传统协变微扰方法在处理不同分量不同幂次展开时失效，需要新的分析方法。

Method: 在流体静力学极限附近进行微扰展开，提出新的熵流条件 $s^μ=(s-bj^0)u^μ/u^0+ bj^μ$，通过电流守恒方程确定参数 $b$，进行微扰分析。

Result: 建立了确定结构变量次主导修正的微分方程，发现参数 $b$ 从二阶开始出现，并显式确定了其主导项。

Conclusion: 成功发展了处理具有稳态能量流的相对论性自引力系统的微扰方法，提出了新的熵流条件，为这类系统的理论研究提供了新工具。

Abstract: A relativistic self-gravitating equilibrium system with spherical symmetry as well as with steady energy flow is investigated perturbatively around the hydrostatic limit, where the radial component of the fluid velocity field $u^μ$ is sufficiently small. Each component of vectors and tensors consisting of the system is expanded in different powers, which makes the covariant perturbation approach ineffective. The differential equations to determine the subleading correction of the structure variables are presented. The system retains the current $j^μ$ accounting for the steady flow, which contributes to the entropy current $s^μ$ in such a general covariant form that $s^μ=au^μ+ bj^μ$ with $a, b$ unknown parametric functions. To determine them, a new condition is proposed. This condition imposes the entropy current to be of an unconventional form $s^μ=(s-bj^0)u^μ/u^0+ bj^μ$, where $s$ is the entropy density. The remaining parameter $b$ is fixed by the current conservation equation. The perturbative analysis shows that $b$ starts with the quadratic order and its leading term is determined explicitly.

</details>


### [247] [Low finesse scattering and spectral drift of gravitational wave echoes](https://arxiv.org/abs/2512.11917)
*Han-Wen Hu,Cheng-Jun Fang,Zong-Kuan Guo*

Main category: gr-qc

TL;DR: 研究引力波回波在低精细度极限下的瞬态特性，发现早期回波表现为散射波包而非稳态共振，存在谱漂移现象，并提出基于腔寿命的物理判据来区分瞬态干扰与真实共振。


<details>
  <summary>Details</summary>
Motivation: 当前引力波回波搜索假设稳态共振，但实际势垒反射率很低。需要研究低精细度极限下的真实回波特性，以改进探测策略。

Method: 使用时域模拟研究低精细度极限下的引力波回波行为，分析早期回波的瞬态特性，建立基于腔寿命的物理判据来区分瞬态干扰与真实共振。

Result: 发现早期回波表现为瞬态散射波包而非腔本征态，存在谱漂移现象（中心频率逐渐红移），确定了区分瞬态干扰与真实共振的临界反射率阈值约为0.37。

Conclusion: 由于理论模型通常工作在过阻尼区域（低于临界阈值），产生的信号在频谱上非平稳。建议探测策略应从稳态共振转向动态时频跟踪，以捕捉这些漂移特征。

Abstract: Gravitational wave echoes serve as probes for quantum horizon corrections. While steady-state resonances are assumed in the search of gravitational wave echos, realistic barriers are expected to possess intrinsically low reflectivity. In this work, we investigate this low-finesse limit via time-domain simulations and demonstrate that early-time echoes behave as transient scattered wave packets rather than cavity eigenstates. A central finding is the identification of spectral drift, where the central frequency progressively redshifts. This evolution occurs because high-frequency components dissipate significantly faster than the fundamental mode due to the filtering effect of the potential barrier. To distinguish transient interference from genuine resonance, we establish a physical criterion based on cavity lifetime, identifying a critical reflectivity threshold of approximately $0.37$. Since theoretical models typically operate deep within the overdamped regime below this limit, the resulting signals are spectrally non-stationary. We propose that detection strategies should shift towards dynamic time-frequency tracking to capture these drifting signatures.

</details>


### [248] [Nonconservative Lie series: post-Newtonian binary dynamics at 2.5PN](https://arxiv.org/abs/2512.11947)
*Christopher Aykroyd,Adrien Bourgoin,Christophe Le Poncin-Lafitte*

Main category: gr-qc

TL;DR: 提出非自旋2.5后牛顿双星系统动力学的完全解析解，涵盖长期（长期）和短期（振荡）行为，无偏心率限制，适用于引力波模板


<details>
  <summary>Details</summary>
Motivation: 需要为引力波天文学提供精确的波形模板，特别是在非保守辐射反应力影响下的双星系统动力学，这需要处理长期演化和短期振荡的完整描述

Method: 使用Lie级数方法构建共振Birkhoff正规形式，在非保守哈密顿框架下处理辐射自由度，构造辐射反应动力学的生成函数

Result: 获得了完全解析解，长期部分精确重构了Peters-Mathews半长轴和偏心率关系，振荡部分完善了动力学，适用于引力波模板

Conclusion: 该方法可系统性地将任意非保守系统转化为扩展哈密顿形式，从而应用Lie方法，为引力波模板提供了完整的动力学描述

Abstract: We present a fully analytical solution to the dynamics of the non-spinning 2.5 post-Newtonian binary problem, accounting for both the long-term (secular) and short-term (oscillatory) temporal behavior, with no restriction on eccentricity. The radiative degrees of freedom are handled within the nonconservative Hamiltonian framework introduced in a companion paper. In this work, we apply the Lie series method to construct a resonant Birkhoff normal-form and the corresponding generator of the radiation-reaction dynamics. The secular piece reconstructs exactly the Peters-Mathews relations for semi-major axis and eccentricity. The oscillatory piece completes the dynamics and is well suited for gravitational wave templates. The procedure we present in this paper can be systematically employed to cast arbitrary nonconservative systems into extended Hamiltonian form so that the Lie method can be applied.

</details>


### [249] [Born-Infeld signatures in AdS black hole thermodynamics and gravitational lensing](https://arxiv.org/abs/2512.12015)
*Ekrem Aydıner,Tekin Dereli,İzzet Sakallı,Erdem Sucu,Ece Seyma Yörük*

Main category: gr-qc

TL;DR: 研究爱因斯坦-玻恩-因费尔德-反德西特黑洞的热力学和光学性质，包括霍金温度、量子修正、引力红移、光线偏折、热机效率等


<details>
  <summary>Details</summary>
Motivation: 研究EBI-AdS黑洞的热力学和光学特性，探索量子修正对热辐射的影响，分析引力红移和光线偏折，并研究黑洞作为热机的效率

Method: 使用表面引力方法计算霍金温度，应用广义不确定性原理和指数熵修正进行量子修正分析，利用高斯-博内定理计算光线偏折角，在扩展相空间中进行热力学分析

Result: 发现量子修正增强热辐射并可能导致残余形成，玻恩-因费尔德修正主要影响近视界区域，热机效率达到卡诺极限的30-61%，等离子体环境中的光线偏折呈现频率依赖性

Conclusion: EBI-AdS黑洞展现出丰富的热力学和光学特性，量子修正显著影响热辐射，玻恩-因费尔德修正主要在强场区可观测，黑洞热机效率与类似系统一致，等离子体环境为观测非线性电动力学效应提供了新途径

Abstract: We investigate the thermodynamic and optical properties of Einstein-Born-Infeld-Anti-de Sitter (EBI-AdS) black holes (BHs). Our study derives the Hawking temperature using standard surface gravity methods and examines quantum corrections through both the Generalized Uncertainty Principle (GUP) and exponential entropy modifications, showing enhanced thermal radiation and potential remnant formation scenarios. The gravitational redshift analysis separates contributions from mass, cosmological constant, electromagnetic charge, and Born-Infeld (BI) corrections, with the latter scaling as $a^4/r^6$ and thus confined to near-horizon regimes. Using the Gauss-Bonnet theorem, we calculate light deflection angles in both vacuum and plasma environments, demonstrating how dispersive media can either enhance or suppress nonlinear electrodynamic signatures depending on observational configurations. The thermodynamic analysis in extended phase space, where the BH mass corresponds to enthalpy, reveals phase structures with heat capacity transitions between positive and negative values, indicating regions of local stability and instability sensitive to parameter choices. We study BH heat engines operating in rectangular thermodynamic cycles, achieving efficiencies of $η\sim 0.11$--$0.21$ that reach 30--61\% of the corresponding Carnot limits, consistent with other AdS BH systems. Comparison with Johnson's analysis confirms that BI corrections to heat engine efficiency are of order $10^{-12}$ for typical parameter ranges, though these effects become appreciable in the strong-field regime where $r_h \lesssim 1.5$ in Planck units. The plasma deflection analysis reveals frequency-dependent refractive modifications encoded in the plasma parameter, offering additional possible observational channels.

</details>


### [250] [On visible effects in the double Schwarzschild solution](https://arxiv.org/abs/2512.12032)
*Eddy de Leon,Joerg Frauendiener,Christian Klein*

Main category: gr-qc

TL;DR: 研究双黑洞静态解中Weyl strut对零测地线的影响，发现该奇异性具有散焦效应，与黑洞的聚焦效应相反


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦场方程的双黑洞静态解中，连接两个黑洞的Weyl strut奇异性如何影响零测地线的行为

Method: 使用光线追踪方法研究双Schwarzschild解的精确显式解，分析Weyl strut对零测地线的影响

Result: Weyl strut对零测地线具有散焦效应，与黑洞的聚焦效应相反；大间距黑洞的行为类似单个黑洞，而近距离黑洞的行为因Weyl strut而显著改变

Conclusion: 双黑洞系统中，连接黑洞的Weyl strut奇异性对零测地线产生显著的散焦效应，这一效应在黑洞间距较小时尤为明显

Abstract: Physical aspects of a static solution to the Einstein equations
  with two black holes are studied via ray tracing. The exact
  solution for this double Schwarzschild solution is known in explicit form. The black holes are separated by a singularity called \emph{Weyl strut}. The effect of this strut on null geodesics is shown to be defocusing in contrast to the focusing effect of the black holes. It is shown that black holes with a large separation essentially lead to similar behavior of the null geodesics as a single black hole, whereas nearby holes display a widely changed behavior due to the Weyl strut.

</details>


### [251] [The macroscopic precession model: describing quasi-periodic oscillations including internal structures of test bodies](https://arxiv.org/abs/2512.12242)
*Gabriele Bianchini,Orlando Luongo,Marco Muccino*

Main category: gr-qc

TL;DR: 论文提出了宏观进动模型（MPM），通过引入测试粒子的内部结构来改进相对论进动模型（RPM），解决了观测不一致问题，并成功应用于中子星低质量X射线双星系统。


<details>
  <summary>Details</summary>
Motivation: 相对论进动模型（RPM）虽然被广泛用于解释准周期振荡（QPOs），但存在观测不一致问题。RPM假设测试粒子无内部结构，仅考虑测地线运动，这限制了模型的完整性。需要纳入测试粒子的内部结构来改进模型。

Method: 提出宏观进动模型（MPM），基于Mathisson-Papapetrou-Dixon（MPD）方程，在施瓦西背景中引入测试粒子的内部结构。该方法保留了测试粒子近似，但引入了：1）开普勒频率的偏移；2）径向本轮频率的有效自旋修正，模拟准施瓦西-德西特修正。对8个中子星低质量X射线双星系统进行马尔可夫链蒙特卡洛拟合，分析双kHz QPOs。

Result: MPM模型发现了支持精确幂律自旋重建的观测和统计证据。模型准确预测了3:2频率聚类、盘边界和中子星质量。结果表明，包含测试粒子内部结构可以完全描述QPOs的复杂性。

Conclusion: 通过纳入测试粒子的内部结构，宏观进动模型（MPM）成功改进了相对论进动模型（RPM），解决了观测不一致问题，为QPOs的完整描述提供了新框架，并验证了模型在预测频率聚类、盘边界和中子星质量方面的准确性。

Abstract: The relativistic precession model (RPM) is widely-considered as a benchmark framework to interpret quasi-periodic oscillations (QPOs), albeit several observational inconsistencies suggest that the model remains incomplete. The RPM ensures \emph{structureless test particles} and attributes precession to geodesic motion alone. Here, we refine the RPM by incorporating the internal structure of rotating test bodies, while preserving the test particle approximation (TPA), and propose a \emph{macroscopic precession model} (MPM) by means of the Mathisson-Papapetrou-Dixon (MPD) equations, applied to a Schwarzschild background, which introduces 1) a shift in the Keplerian frequency and 2) an \emph{effective spin correction} to the radial epicyclic frequency that, once the spin tensor is modeled, reproduces a quasi-Schwarzschild-de Sitter (SdS) correction. We apply the MPM to eight neutron star low mass X-ray binaries (NS-LMXBs), performing Markov chain Monte Carlo (MCMC) fits to twin kHz QPOs and find observational and statistical evidence in favor of precise power law spin reconstructions. Further, our model accurately predicts the $3:2$ frequency clustering, the disk boundaries and the NS masses. From the MPM model, we thus conclude that complexity of QPOs can be fully-described including the test particle internal structure.

</details>


### [252] [Geodesic structure of spacetime near singularities](https://arxiv.org/abs/2512.12271)
*Mayank,Dawood Kothawala*

Main category: gr-qc

TL;DR: 论文研究了流形中奇异点附近测地线流的标度行为变化，发现Synge世界函数和van Vleck行列式在奇异点附近的标度行为发生显著变化，这为理解时空奇点的经典和量子结构提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 测地线流携带了流形几何性质的重要信息，通常用Synge世界函数和van Vleck行列式描述。在正则点附近，这些双标量有已知展开式，体现局部平坦性和等效原理。但当点变为奇异点时，这些标度行为如何变化尚不清楚，这关系到对时空奇点结构的理解。

Method: 通过分析奇异点附近测地线流的标度行为，研究Synge世界函数和van Vleck行列式在奇异点附近的渐近行为变化。比较正则点和奇异点情况下这些几何量的不同标度特性。

Result: 发现当点P为奇异点时，Synge世界函数和van Vleck行列式的标度行为发生剧烈变化，这与正则点情况完全不同。这种变化捕捉了奇异点附近测地线流的非平凡结构。

Conclusion: 奇异点附近几何双标量的标度行为变化为理解时空奇点的经典结构提供了深刻见解，并为研究其量子结构提供了有用工具。这项工作连接了几何、经典物理和量子描述。

Abstract: Geodesic flows emanating from an arbitrary point $\mathscr{P}$ in a manifold $\mathscr{M}$ carry important information about the geometric properties of $\mathscr{M}$. These flows are characterized by Synge's world function and van Vleck determinant - important bi-scalars that also characterize quantum description of physical systems in $\mathscr{M}$. If $\mathscr{P}$ is a regular point, these bi-scalars have well known expansions around their flat space expressions, quantifying \textit{local flatness} and equivalence principle. We show that, if $\mathscr{P}$ is a singular point, the scaling behavior of these bi-scalars changes drastically, capturing the non-trivial structure of geodesic flows near singularities. This yields remarkable insights into classical structure of spacetime singularities and provides useful tool to study their quantum structure.

</details>


### [253] [Inflation with Gauss-Bonnet Correction and Higgs Potential](https://arxiv.org/abs/2512.12286)
*Zahra Ahghari,Mehrdad Farhoudi*

Main category: gr-qc

TL;DR: 研究爱因斯坦-希尔伯特作用量加上希格斯势函数和高斯-博内项通过类伸缩子耦合与希格斯标量场耦合的宇宙学暴胀模型，通过数值分析得到与观测数据一致的张量-标量比和标量谱指数。


<details>
  <summary>Details</summary>
Motivation: 研究包含希格斯势和高斯-博内项的扩展引力理论中的宇宙学暴胀，探索这类模型是否能产生与观测一致的暴胀可观测量。

Method: 使用FLRW度规和慢滚近似，推导运动方程。由于e-folding积分无法解析求解，采用泰勒展开近似，然后通过数值分析和图表方法，在一定参数范围内计算张量-标量比和标量谱指数。

Result: 在特定参数范围内，得到的张量-标量比和标量谱指数与观测数据良好吻合。当没有高斯-博内项时，暴胀可观测量与混沌暴胀模型的预测大致相同。

Conclusion: 包含希格斯势和高斯-博内项耦合的扩展引力模型能够产生与观测一致的暴胀预测，高斯-博内项对暴胀可观测量有重要影响，移除该项后模型简化为混沌暴胀。

Abstract: We investigate the cosmological inflation for the Einstein-Hilbert action plus the Higgs potential function and the Gauss-Bonnet term coupled with the Higgs scalar field through a dilaton-like coupling. Then, using the Friedmann-Lemaître-Robertson-Walker metric and considering the appropriate slow-roll parameters, we derive the necessary equations of motion. In the proposed model, since the e-folding integral cannot be easily solved analytically, we first utilize a well-known Taylor expansion. Then, with a certain range of values derived for the model parameters, utilizing a mixture of several diagrams and numerical analysis methods, we obtain results for the tensor-to-scalar ratio and the scalar spectral index that are in good agreement with observational data within the acceptable range of the e-folding values. Also, in the absence of the Gauss-Bonnet term, we find that the inflationary observables are roughly the same as the predictions of the chaotic inflation model.

</details>


### [254] [Equation of the Perfect Fluid in the FRW Universe](https://arxiv.org/abs/2512.12347)
*Shi-Bei Kong,Ying Wang,Yu-Ke Wang*

Main category: gr-qc

TL;DR: 研究D维FRW宇宙中完美流体在不同引力理论（爱因斯坦、高斯-博内、洛弗洛克）下的状态方程及其性质，发现引力理论和维度影响临界点的存在性。


<details>
  <summary>Details</summary>
Motivation: 探索不同引力理论（爱因斯坦、高斯-博内、洛弗洛克）下D维FRW宇宙中完美流体的热力学性质，特别是状态方程和相变行为，以理解引力理论和时空维度对流体临界现象的影响。

Method: 在D维FRW宇宙背景下，分别研究爱因斯坦引力、高斯-博内引力和洛弗洛克引力理论中的完美流体状态方程，分析其P-V图性质，寻找临界点并研究相变条件。

Result: 爱因斯坦引力中无临界点（4维等温线有最小值，高维始终为负）；高斯-博内引力在5-8维存在临界点，临界温度以上有相变；洛弗洛克引力得到状态方程和临界点条件。引力理论和维度都影响临界点存在性。

Conclusion: 引力理论（爱因斯坦、高斯-博内、洛弗洛克）和FRW宇宙维度共同决定完美流体临界点的存在性；当临界点存在时，临界温度以上总是发生相变。

Abstract: In this paper, we study the equation of state and its properties of the perfect fluid in the $D$-dimensional FRW universe under Einstein gravity, Gauss-Bonnet gravity and Lovelock gravity. In Einstein gravity, we get the equation of state and find that it has no critical point in the $P$-$V$ diagram, but its isothermal lines have minima in the $4$-dimensional case and are always negative in higher dimensions. In Gauss-Bonnet gravity, we get the equation of state and find that it has a critical point in the $5,6,7,8$-dimensional cases with phase transitions above the critical temperature. In Lovelock gravity, we get the equation of state and conditions of the critical points. Our work shows that both the theories of gravity and the dimensions of the FRW universe affect the existence of the critical point of the perfect fluid. Interestingly, if the critical point exists, phase transition always occures above the critical temperature.

</details>


### [255] [Hybrid algorithm combining matched filtering and convolutional neural networks for searching gravitational waves from binary black hole mergers](https://arxiv.org/abs/2512.12399)
*Takahiro S. Yamamoto,Kipp Cannon,Hayato Motohashi,Hiroaki W. H. Tahara*

Main category: gr-qc

TL;DR: 提出一种基于神经网络的引力波检测方法，使用信噪比图作为输入，在计算资源有限的情况下达到与传统匹配滤波相当的检测性能。


<details>
  <summary>Details</summary>
Motivation: 紧凑双星并合引力波的高效搜索对引力波观测至关重要，需要开发能够替代或补充传统匹配滤波方法的新算法，特别是在计算资源有限的情况下。

Method: 使用神经网络处理信噪比图（由匹配滤波器计算的信噪比时间序列堆叠而成），预测观测数据中是否存在引力波信号。该方法作为概念验证，应用于恒星质量黑洞并合信号注入高斯噪声的数据集。

Result: 该算法性能与标准匹配滤波管道相当，也与参与MLGWSC-1模拟数据挑战的机器学习算法相当。在实用计算资源下实现了合理的灵敏度。

Conclusion: 提出的神经网络方法在引力波检测中具有可行性，能够以实用计算资源达到与传统方法相当的检测性能，为引力波观测提供了有前景的替代方案。

Abstract: Efficient searches for gravitational waves from compact binary coalescence are crucial for gravitational wave observations. We present a proof-of-concept for a method that utilizes a neural network taking an SNR map, a stack of SNR time series calculated by the matched filter, as input and predicting the presence or absence of gravitational waves in observational data. We demonstrate our algorithm by applying it to a dataset of gravitational-wave signals from stellar-mass black hole mergers injected into stationary Gaussian noise. Our algorithm exhibits comparable performance to the standard matched-filter pipeline and to the machine-learning algorithms that participated in the mock data challenge, MLGWSC-1. The demonstration also shows that our algorithm achieves reasonable sensitivity with practical computational resources.

</details>


### [256] [Kerr-Bertotti-Robinson Spacetime and the Kerr/CFT Correspondence](https://arxiv.org/abs/2512.12533)
*Haryanto M. Siahaan*

Main category: gr-qc

TL;DR: 该论文构建了极端Kerr-Bertotti-Robinson黑洞的Kerr/CFT对应关系，证明了外部电磁场非平凡地修改了视界位置和极端条件，并通过近地平线极限得到扭曲AdS₃几何，其Cardy公式精确重现了Bekenstein-Hawking熵。


<details>
  <summary>Details</summary>
Motivation: 研究在均匀Bertotti-Robinson电磁宇宙中的旋转黑洞（Kerr-BR黑洞）的Kerr/CFT对应关系，探索外部电磁场如何影响黑洞的视界几何、极端条件以及可能的全息对偶描述。

Method: 首先回顾Kerr-BR黑洞家族的几何结构、视界结构和热力学；分析外部场如何非平凡修改视界位置和极端条件；对极端配置进行近地平线极限，得到扭曲AdS₃几何；施加标准Kerr/CFT边界条件，推导渐近对称代数；计算中心电荷和左移温度；应用Cardy公式计算熵。

Result: 证明了对于任意可接受的Bertotti-Robinson场强度，Cardy公式都能精确重现极端Kerr-BR黑洞的Bekenstein-Hawking熵，建立了自洽的Kerr/CFT对偶描述。中心电荷c_L和左移温度T_L明确依赖于外部场强度。

Conclusion: 成功构建了极端Kerr-Bertotti-Robinson黑洞的Kerr/CFT对应关系，表明即使在存在外部电磁场的情况下，黑洞熵仍可通过二维共形场论描述。与磁化Melvin-Kerr和Kaluza-Klein黑洞的比较显示了曲率分布和视界几何的定性差异。

Abstract: We construct the Kerr/CFT correspondence for extremal Kerr--Bertotti--Robinson (Kerr--BR) black holes, which are exact stationary solutions of the Einstein--Maxwell equations describing a rotating black hole immersed in a uniform Bertotti--Robinson electromagnetic universe. After reviewing the geometry, horizon structure, and thermodynamics of the Kerr--BR family, we demonstrate that the external field non-trivially modifies both the horizon positions and the extremality condition. For extremal configurations, the near-horizon limit yields a warped $\mathrm{AdS}_3$ geometry with an associated Maxwell field aligned to the $U(1)$ fibration. Imposing standard Kerr/CFT boundary conditions, the asymptotic symmetry algebra gives rise to a Virasoro algebra with central charge $c_L$ and left-moving temperature $T_L$ that depend explicitly on the external field strength. The Cardy formula then reproduces exactly the Bekenstein--Hawking entropy of the extremal Kerr--BR black hole for any admissible value of the Bertotti--Robinson field, thereby establishing a consistent Kerr/CFT dual description. Comparisons with the magnetized Melvin--Kerr and Kaluza--Klein black holes are briefly discussed, highlighting qualitative differences in their curvature profiles and horizon geometries.

</details>


### [257] [Matching the Alcubierre and Minkowski spacetimes](https://arxiv.org/abs/2512.12541)
*Osvaldo L. Santos-Pereira,Everton M. C. Abreu,Marcelo B. Ribeiro*

Main category: gr-qc

TL;DR: 分析Alcubierre曲速引擎时空与外部闵可夫斯基几何的Darmois连接条件，发现连接超曲面要求曲速引擎的位移矢量满足无粘性Burgers方程的解，且曲速引擎几何并非全局平坦。


<details>
  <summary>Details</summary>
Motivation: 研究Alcubierre曲速引擎时空如何与外部闵可夫斯基几何平滑连接，探索连接条件对曲速引擎几何性质的影响。

Method: 使用Darmois连接条件分析内部Alcubierre曲速引擎时空与外部闵可夫斯基几何的匹配问题，推导连接超曲面的数学条件。

Result: 连接超曲面要求位移矢量满足特定无粘性Burgers方程的解（位移矢量不依赖于y和z坐标的规范），且Ricci和Riemann张量在连接超曲面处并非全部为零，表明曲速引擎几何并非全局平坦。

Conclusion: Alcubierre曲速引擎几何通过Burgers型方程与冲击波相联系，其全局性质并非平坦，连接条件对位移矢量有特定数学约束。

Abstract: This work analyzes the Darmois junction conditions matching an interior Alcubierre warp drive spacetime to an exterior Minkowski geometry. The joining hypersurface requires that the shift vector of the warp drive spacetime must satisfy the solution of a particular inviscid Burgers equation, namely, the gauge where the shift vector is not a function of the $y$ and $z$ spacetime coordinates. Such a gauge connects the warp drive metric to shock waves via a Burgers-type equation, which was previously found to be an Einstein equations vacuum solution for the warp drive geometry. It is also shown that not all Ricci and Riemann tensors components are zero at the joining hypersurface, but for that to happen they depend on the shift vector solution of the inviscid Burgers equation at the joining wall. This means that the warp drive geometry is not globally flat.

</details>


### [258] [Quasinormal modes and Grey body factors of Wormholes: From General prescription to Einstein Gauss Bonnet realizations](https://arxiv.org/abs/2512.12547)
*Madhukrishna Chakraborty,Subenoy Chakraborty*

Main category: gr-qc

TL;DR: 该论文通过准正则模和灰体因子研究可穿越虫洞的观测前景，探讨如何区分虫洞与黑洞，并分析了爱因斯坦-高斯-博内虫洞解中的这些特征。


<details>
  <summary>Details</summary>
Motivation: 可穿越虫洞是广义相对论的重要预测，但其存在需要违反零能量条件，使得探测变得困难。论文旨在通过准正则模和灰体因子为虫洞观测提供新途径，这些特征可以帮助区分虫洞与黑洞。

Method: 采用准正则模和灰体因子作为波动力学的两个基本方面，首先进行一般性描述，然后应用于爱因斯坦-高斯-博内虫洞解（包括各向同性和各向异性情况），并建立准正则模频率与虫洞阴影半径的对应关系。

Result: 论文展示了准正则模在表征扰动衰荡相中的作用，以及灰体因子在确定通过虫洞势垒的透射概率中的作用。讨论了高斯-博内参数对准正则模谱的影响，并建立了准正则模频率与虫洞阴影半径的对应关系。

Conclusion: 准正则模和灰体因子为可穿越虫洞的观测提供了有前景的途径，这些特征的光谱印记有助于在引力波观测中区分虫洞与黑洞，为虫洞探测开辟了新方向。

Abstract: Traversable wormholes are one of the most exciting predictions of General Relativity that offer short-cuts through space-time. However, their feasibility requires the violation of the null energy condition and makes their detection a bit difficult. This paper aims to show the new avenues delving deep into the observational prospects of TWHs via quasinormal modes (QNMs) and gray body factors GBFs. These are the two elementary aspects of wave dynamics. Given their distinct spectral imprints, these features provide a potential means to distinguish wormholes from black holes in gravitational wave observations. The role of QNMs in characterizing the ringdown phase of perturbations and the GBFs in determining transmission probabilities through wormhole barriers have been explored by a general description and then fed to Einstein Gauss Bonnet WH solutions in isotropic as well as anisotropic cases. Finally, a correspondence of the QNM frequencies with radius of the WH shadows has been made and the effect of Gauss Bonnet parameter on the QNM spectra has been discussed.

</details>


### [259] [Probing the gravity of a Schwarzschild black hole in the presence of a cloud of strings with EMRIs](https://arxiv.org/abs/2512.12672)
*Mirzabek Alloqulov,Ahmadjon Abdujabbarov,Bobomurat Ahmedov,Chengxun Yuan*

Main category: gr-qc

TL;DR: 研究弦云对极端质量比旋进系统引力波波形的影响，发现LISA能探测到弦云参数α≳2×10⁻⁶的印记


<details>
  <summary>Details</summary>
Motivation: 探索弦云对极端质量比旋进系统引力波波形的影响，检验弦云理论在引力波探测中的可观测性

Method: 使用拉格朗日形式研究施瓦西黑洞周围弦云中测试粒子的运动，分析弦云参数对半通径和偏心率的演化影响，并计算对引力波波形的影响

Result: 弦云参数对EMRI系统的轨道演化有显著影响，LISA能够探测到弦云参数α≳2×10⁻⁶在引力波波形中留下的印记

Conclusion: 弦云对极端质量比旋进系统的引力波波形有可观测的影响，LISA有望探测到弦云存在的证据，为检验弦理论提供新途径

Abstract: Here, we explore the effect of the cloud of strings (CoS) on the gravitational waveforms of extreme mass ratio inspirals (EMRIs). The EMRI system consists of a supermassive black hole (BH) and a compact stellar mass object moving around it. We begin with studying the test particle motion around the Schwarzschild BH surrounded by a CoS by using the Lagrangian formalism. Moreover, we investigated the effect of the CoS parameter on the evolution of the semi-latus rectum and eccentricity. We then turn to the exploration of the impact of the CoS parameter on the gravitational waveforms of the EMRI system. The analysis performed shows that Laser Interferometer Space Antenna (LISA) could detect the CoS imprint in gravitational waveforms when the values of the string cloud parameter $α\gtrsim 2 \times 10^{-6}$.

</details>


### [260] [A parameterized equation of state for dark energy and Hubble Tension](https://arxiv.org/abs/2512.12697)
*Jing-Ya Zhao,Tong-Yu He,Jia-Jun Yin,Zhan-Wen Han,Rong-Jia Yang*

Main category: gr-qc

TL;DR: 提出参数化暗能量状态方程，利用多种观测数据测试，得到最佳拟合参数，模型与天文观测高度一致，为解决哈勃张力提供有前景的参数化方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决哈勃张力问题，需要探索新的暗能量参数化方法，以更好地拟合多种天文观测数据。

Method: 提出参数化的暗能量状态方程，使用哈勃参数测量、Pantheon超新星样本、重子声学振荡和DESI DR2数据进行观测测试。

Result: 获得最佳拟合参数：H₀=73.96±0.16，Ω_m=0.2434±0.0079，α=-0.00049±0.00092，模型与天文观测高度一致。

Conclusion: 该模型为哈勃张力问题提供了一个有前景的参数化解决方案，与多种观测数据高度一致。

Abstract: We propose a parameterized equation of state for dark energy and perform observational tests with the Hubble parameter measurements, the Pantheon supernova sample, baryon acoustic oscillations, and DESI DR2 data. We obtain the best-fit values for the parameters as: $H_0=73.96\pm 0.16$, $Ω_{\rm m}=0.2434\pm 0.0079$, and $α=-0.00049\pm 0.00092$, demonstrating that the model exhibits a high degree of consistency with astronomical observations and provides a promising parameterized method for addressing the Hubble tension.

</details>


### [261] [Spherical symmetric fields on torsion-free Palatini Gauss-Bonnet theory](https://arxiv.org/abs/2512.12863)
*Máximo Bañados,Daniela Bennett*

Main category: gr-qc

TL;DR: 四维Palatini形式的Gauss-Bonnet密度不是全导数，研究无挠理论的球对称场，发现存在超越微分同胚和Weyl变换的隐藏规范对称性


<details>
  <summary>Details</summary>
Motivation: 研究四维Palatini形式下的Gauss-Bonnet密度特性，探索其在无挠理论中的球对称场行为，寻找可能的新对称性

Method: 采用Palatini形式处理Gauss-Bonnet密度，研究无挠理论的球对称场配置，分析场方程的对称性结构

Result: 发现存在超越传统微分同胚和Weyl变换的意外隐藏规范对称性，尽管场方程高度复杂

Conclusion: 四维Palatini形式的Gauss-Bonnet理论具有丰富的对称性结构，包含传统对称性之外的隐藏规范对称性

Abstract: The Gauss-Bonnet density `a la Palatini' is not a total derivative in four dimensions. We study spherically symmetric fields for the torsion-free theory. The resulting equations are highly complicated but we show the existence of unexpected hidden gauge symmetries, beyond diffeomorphisms and Weyl transformations.

</details>


### [262] [Extracting the expression for the field equations of a diffeomorphism invariant theory of gravity from surface term](https://arxiv.org/abs/2512.13025)
*Jun-Jin Peng*

Main category: gr-qc

TL;DR: 从拉格朗日变分的表面项出发，推导出引力场方程表达式，证明表面项能统一描述场方程和诺特荷


<details>
  <summary>Details</summary>
Motivation: 为了更好理解微分同胚不变纯引力理论中的场方程，探索表面项在描述场方程和诺特荷方面的统一作用

Method: 从拉格朗日变分的表面项出发，用任意矢量场的李导数替换变分算子，从中提取对称二阶张量和反对称二阶张量，利用拉格朗日密度李导数的等式证明对称张量就是拉格朗日密度对度规的泛函导数

Result: 证明了对称二阶张量就是拉格朗日密度对度规的泛函导数，由此得到的场方程表达式自然排除了对度规的导数，与欧拉-拉格朗日运动方程一致；反对称二阶张量就是诺特荷二形式

Conclusion: 表面项为微分同胚不变引力理论中的场方程和诺特荷提供了统一描述，支持了先前工作中关于表面项统一作用的提议

Abstract: As a contribution towards the understanding for the field equations of diffeomorphism invariant theories of pure gravity, we demonstrate in great detail that the expression for the field equations of such theories can be derived within the perspective of the surface term coming from the variation of the Lagrangian. Specifically, starting with the surface term, we extract a symmetric rank-two tensor together with an anti-symmetric one out of this term with the variation operator replaced with the Lie derivative along an arbitrary vector field. By utilizing an equality stemming from the Lie derivative of the Lagrangian density along an arbitrary vector field, it is proved that the resulting symmetric rank-two tensor is identified with the functional derivative of the Lagrangian density with respect to the metric. Such a result further brings forth the expression for the field equations constructed from the symmetric rank-two tensor, which naturally rules out the derivative of the Lagrangian density with respect to the metric and coincides with the one for the Euler-Lagrange equations of motion. Furthermore, it is illustrated that the construction of the expression for the field equations from the symmetric rank-two tensor must be feasible as long as the variation operator in the variation equation of the Lagrangian is allowed to be substituted by the Lie derivative along an arbitrary vector field. On the other hand, as a byproduct, the anti-symmetric rank-two tensor turns out to be the Noether charge two-form. Our results offer a straightforward support on the proposal in our previous work that the surface term gives a unified description for field equations and Noether charges in the context of theories of gravity admitting diffeomorphism invariance symmetry.

</details>


### [263] [On the magnetic 2+1- D space-time and its non-relativistic counterpart](https://arxiv.org/abs/2512.13029)
*Sayan Kumar Pal*

Main category: gr-qc

TL;DR: 该论文研究了2+1维爱因斯坦-麦克斯韦系统中纯磁BTZ解的非相对论极限，称为牛顿-胡克极限，该极限包含宇宙学常数Λ，不同于伽利略极限。


<details>
  <summary>Details</summary>
Motivation: 研究从相对论理论到非相对论理论的极限过程，分析不同动力系统的对称性，特别是探索包含宇宙学常数的牛顿-胡克极限在凝聚态物理中的应用。

Method: 从2+1维爱因斯坦-麦克斯韦系统出发，对纯磁BTZ解施加牛顿-胡克极限，该极限包含宇宙学常数Λ和光速c两个参数，分析在此极限下测地线的行为。

Result: 牛顿-胡克极限下，磁BTZ解的测地线简化为二维带电粒子在正常磁场中的运动，并附加一个额外的谐振势（Fock-Darwin问题），该问题可作为凝聚态理论的模型。广义磁牛顿-胡克对称性在维里定理中有应用。

Conclusion: 牛顿-胡克极限为研究相对论与非相对论理论之间的对称性提供了新视角，Fock-Darwin问题中的广义磁牛顿-胡克对称性在凝聚态物理中有重要应用价值。

Abstract: We present here an interesting non-relativistic limit, referred to as the Newton-Hooke (NH) limit, of the purely magnetic BTZ solution by starting from the Einstein-Maxwell system in the 2+1 dimensions. The Newton-Hooke limit is different from the Galilean limit in the sense that the former contains an additional parameter Λ, the cosmological constant, over and above the speed of light, c. We show that under this limit, the geodesics of the magnetic BTZ solution reduce to the two-dimensional motion of a charged particle in a normal magnetic field together with the presence of an extra harmonic potential, sometimes called the Fock-Darwin problem, which serves as a precursor to model certain condensed matter theories. Our present study has significance in analyzing the symmetries of different dynamical systems, from relativistic and/to nonrelativistic theories. Also, we discuss here one of the applications of the generalized (magnetic) NH_3 symmetry in the context of the Virial theorem, where this symmetry is the symmetry group of the Fock-Darwin problem mentioned above.

</details>


### [264] [Shadow and Optical Imaging in Einstein-Maxwell-Dilaton Black Hole](https://arxiv.org/abs/2512.13114)
*Junlin Qin,Hong-Er Gong,Yusen Wang,Zhan-Feng Mai,Bofeng Wu,Sen Guo,Enwei Liang*

Main category: gr-qc

TL;DR: 研究爱因斯坦-麦克斯韦-膨胀子理论中黑洞的光子运动，探索不同吸积模型下的黑洞阴影和观测特征，利用EHT数据约束磁荷q


<details>
  <summary>Details</summary>
Motivation: 研究膨胀子理论中黑洞的光子运动特性，探索不同吸积模型对黑洞阴影观测特征的影响，为黑洞观测提供理论支持

Method: 首先建立事件视界、光子球和临界碰撞参数与磁荷q的关系，然后利用EHT数据约束q值，最后分析三种吸积模型（球对称吸积、下落吸积、薄盘吸积）下的阴影特征

Result: 下落吸积模型由于多普勒效应产生更暗的阴影；不同模型下阴影半径保持不变；薄盘吸积模型中直接发射主导亮度，透镜环贡献次要，光子环可忽略；透镜环和光子环宽度与磁荷q正相关；盘模型中阴影半径依赖于具体发射模型

Conclusion: 膨胀子理论中黑洞的观测特征受吸积模型影响显著，磁荷q对环结构宽度有直接影响，为黑洞观测和理论约束提供了重要参考

Abstract: This paper investigates photon motion in black hole of Einstein-Maxwell-dilaton theory, exploring black hole shadows and observational characteristics under various accretion models. We first give the relation of the event horizon, photon sphere, and critical impact parameter in terms of the magnetic charge $q$. We then use the Event Horizon Telescope data to constrain $q$. For the two spherical accretion models, the infalling scenario yields a darker shadow due to the Doppler effect. However, the shadow radius remains unchanged for different models. In the case of an optically thin, geometrically thin disk accretion model, the observed brightness is predominantly determined by direct emission. The lensing ring provides a secondary contribution to the intensity, whereas the photon ring's emission is negligible. The widths of the lensing and photon rings exhibit a positive correlation with the magnetic charge $q$. Additionally, within the disk model framework, the black hole shadow radius is found to depend on the specific emission model.

</details>


### [265] [Through the Singularity](https://arxiv.org/abs/2512.13206)
*Michael Heller,Tomasz Miller,Wiesław Sasin*

Main category: gr-qc

TL;DR: 论文提出通过"恶意奇点"在不同宇宙或黑洞与白洞之间旅行的理论框架，通过两种推广实现：使用带微分结构的环空间替代流形，以及在曲线参数集中植入奇点结构。


<details>
  <summary>Details</summary>
Motivation: 探索如何穿越弗里德曼和史瓦西解中隐藏的"恶意奇点"，实现从一宇宙到另一宇宙或从黑洞内部到白洞的旅行，解决传统广义相对论中奇点穿越的困难。

Method: 采用两种推广方法：1) 使用环空间（带微分结构的空间）替代传统流形，推广光滑性概念；2) 在曲线参数集中植入奇点结构，使曲线能在广义意义下光滑穿越奇点。

Result: 建立了通过恶意奇点进行宇宙间或黑洞-白洞间旅行的理论可能性，通过推广的空间结构和曲线概念，实现了在广义意义下的光滑穿越。

Conclusion: 通过推广空间结构和曲线概念，理论上可以实现穿越传统广义相对论中不可穿越的奇点，为宇宙间旅行和黑洞-白洞转换提供了新的数学框架。

Abstract: In this work, we propose a dangerous journey -- a journey through the strong singularity from one universe to another or from inside of a black hole to its 'inverse' as a white hole. Such singularities are hidden in the Friedman and Schwarzschild solutions; we call them malicious singularities. The journey is made possible owing to two generalizations. The first generalization consists in considering spaces with differential structures on them (the so-called ringed spaces) rather than the usual manifolds. This entails a generalization of the concept of smoothness, which allows us to think about a smooth passage through the singularity. The second generalization is related to the concept of curve. We show that if a kind of singularity is implanted in the set of curve's parameters, along with an appropriate topology, in such a way that the structure of the set of parameters corresponds to the structure of the singular space-time, the curve can smoothly -- in a generalized sense -- pass through the singularity.

</details>


### [266] [Shadows of rotating traversable wormholes surrounded by plasma](https://arxiv.org/abs/2512.13327)
*Tsanimir Angelov,Rasim Bekir,Galin Gyulchev,Petya Nedkova,Stoytcho Yazadjiev*

Main category: gr-qc

TL;DR: 研究等离子体环境对虫洞阴影的影响，发现等离子体频率变化会改变阴影大小，甚至使虫洞阴影消失，而黑洞阴影仍存在，这为区分虫洞和黑洞提供了观测特征。


<details>
  <summary>Details</summary>
Motivation: 探索等离子体环境如何影响轴对称虫洞的阴影特征，研究等离子体频率变化对虫洞和黑洞阴影的差异，为观测区分虫洞和黑洞提供理论依据。

Method: 研究多个虫洞解和等离子体分布，利用可分离的Hamilton-Jacobi方程推导光线的解析解，分析阴影边界和光子区域随等离子体频率的变化。

Result: 发现径向等离子体分布导致的光子区域演化与虫洞度规无关，与Kerr黑洞一致；角向依赖的等离子体分布则产生虫洞特有的演化。虫洞阴影消失的临界频率低于黑洞，在某些频率范围内黑洞有阴影而虫洞没有，且虫洞阴影总是小于黑洞阴影。

Conclusion: 等离子体环境增强了虫洞和黑洞阴影的差异，为观测区分这两种致密天体提供了有力工具。等离子体频率变化和像差效应都使虫洞更容易被检测到。

Abstract: We study the influence of the plasma environment on the shadows of stationary axisymmetric wormholes. We consider a sample of several wormhole solutions and plasma distributions for which the Hamilton-Jacobi equation for the light rays is separable. This allows us to derive analytical expressions for the shadow boundary and examine the behavior of the photon regions as the plasma frequency varies. We observe that plasma profiles which depend only on radial coordinate lead to common evolution of the photon region which does not depend on the wormhole metric and is consistent with the Kerr black hole. For plasma profiles with angular dependence the evolution of the photon region is specific for every spacetime thus wormholes are observationally distinguishable. We further investigate the formation of forbidden regions in the plasma medium where light cannot propagate. They lead to the formation of plasma frequency ranges where the shadow is no longer observable and we show that this phenomenon is characteristic for all the configurations in our sample. We obtain the critical frequencies for which the shadow vanishes and demonstrate that for all the wormholes they are lower than the critical frequencies for the Kerr black hole in the same environment. This implies that there exist plasma frequency ranges in which the Kerr black hole casts a shadow but wormholes do not, creating a strong observational signature for discriminating between compact objects. In the frequency ranges where both black hole and wormhole shadows exist the wormhole shadows are consistently smaller than those for the Kerr black hole. As the plasma frequency grows the discrepancy progresses showing that plasma medium facilitates the experimental detection of wormholes. Finally we consider aberrational effects on the wormhole shadows. They further increase the deviation from black holes making wormholes easier to detect.

</details>


### [267] [Thermodynamic analysis of a compact object in Rastall-Rainbow gravity](https://arxiv.org/abs/2512.13471)
*Sareh Eslamzadeh,Saheb Soroushfar*

Main category: gr-qc

TL;DR: RR重力下无视界致密天体的热力学行为：温度曲线出现两个极值点，产生零温稳定质量残余，壳层熵小于黑洞，对数修正项促进比热正定和小型gravastar自由能景观平滑化。


<details>
  <summary>Details</summary>
Motivation: 研究Rastall-Rainbow（RR）重力框架下无视界致密天体（gravastar）的热力学行为，探索RR修正如何影响温度分布、熵、比热和自由能，揭示参数调控对热力学稳定性的作用。

Method: 采用局部壳层热力学方法分析gravastar，结合外部基准温度，研究RR修正对温度曲线的弯曲效应，通过热容量和亥姆霍兹自由能分析不同质量分支的热力学稳定性。

Result: RR修正使温度曲线产生两个极值点，在零温时形成稳定质量残余；gravastar壳层熵小于可比黑洞；对数修正项促进比热正定和小型gravastar自由能景观平滑化；发现小、中、大三个质量分支，小型RR gravastar在局部和全局上都优于热弯曲空间。

Conclusion: Rastall和Rainbow参数在热力学调控中发挥不同作用：Rastall参数增强物质-曲率耦合，调整壳层与外部红移；Rainbow参数增强能量依赖的UV抑制。这些结果为RR重力下无视界致密天体的热力学稳定化和稳定残余的形成提供了可控途径。

Abstract: In this paper, we investigate the thermodynamic behavior of a horizonless compact object within the framework of Rastall-Rainbow (RR) gravity. Working with local shell thermodynamics for gravastar and an exterior fiducial temperature, we show that the RR modification bends temperature to produce two extrema and a stable mass remnant at zero temperature. We show that the gravastar's shell entropy is smaller than that of a comparable black hole, and that RR modifications introduce a logarithmic correction which contributes to specific heat positivity and a smoother free energy landscape of small gravastars.
  A Central finding of this work is that, from heat capacity and Helmholtz free energy analyses, we uncover small, middle, and large branches and demonstrate that unlike Rainbow modified black holes, the small RR gravastar is both locally and globally favored over hot curved space. At the parameter level, both Rastall and Rainbow play distinct roles. Increasing the Rastall parameter, by strengthening matter-curvature coupling, adjusts the redshift between the shell and the exterior, shifts the temperature maximum to higher values at larger masses, and narrows the unstable window. In contrast, increasing the Rainbow parameter enhances energy dependent UV suppression and bends the temperature in lower values at larger masses. Altogether, these results highlight a controlled route to thermodynamic stabilization and the emergence of a stable remnant in horizonless compact objects within RR gravity.

</details>


### [268] [Quantum Correlations and Gravity: From the Emergence of a Cosmological Constant to the Gravitation of Particles in Superposition](https://arxiv.org/abs/2512.13531)
*Johas Morales,Yuri Bonder*

Main category: gr-qc

TL;DR: 论文提出了一种独立联络的量子引力模型，将联络视为独立的双张量场，得到爱因斯坦方程的双张量推广。该模型在经典物质源时还原为广义相对论，在宇宙学中自然产生正有效宇宙学常数，在牛顿极限下对量子叠加源预测了依赖于测试粒子速度的非保守有效力。


<details>
  <summary>Details</summary>
Motivation: 量子引力理论构建的主要技术障碍是度规本身定义了量子化所需的因果结构，这促使通过独立联络实现引力的量子方面。此外，实验证实的贝尔不等式违反以及半经典引力中能量-动量张量的自然结构，表明非定域性应纳入引力形式体系。

Method: 提出一个模型，其中联络被处理为独立的双张量场，导致爱因斯坦方程的双张量推广。该模型在经典物质源时还原为广义相对论。应用于两个体系：晚期宇宙和牛顿极限。

Result: 在宇宙学情形中，模型自然地产生正有效宇宙学常数。在牛顿极限下，当引力源处于量子叠加态时，模型预测了一种新颖的、依赖于测试粒子速度的非保守有效力。

Conclusion: 通过将联络作为独立双张量场处理，该模型为量子引力提供了一种新方法，既能在经典极限下还原为广义相对论，又能自然地产生宇宙学常数，并在量子叠加源情况下预测非保守引力效应，为量子引力中的非定域性提供了具体实现。

Abstract: One of the main technical obstacles in constructing a consistent theory of quantum gravity is that the metric itself defines the causal structure required for quantization. This motivates implementing quantum aspects of gravity through an independent connection. Moreover, the experimentally confirmed violation of Bell inequalities, together with the natural structure of the energy--momentum tensor in semiclassical gravity, suggests that nonlocality should be incorporated into the gravitational formalism. Motivated by these considerations, we propose a model in which the connection is treated as an independent bitensorial field, leading to a bitensorial generalization of the Einstein equations. The model reduces to General Relativity when the matter source is classical. We apply it in two regimes: the late-time universe and the Newtonian limit. In the cosmological case, the model naturally gives rise to a positive effective cosmological constant. In the Newtonian regime, we analyze a situation in which the gravitational source is in a quantum superposition and find that the model predicts a novel, nonconservative effective force that depends on the velocity of the test particle.

</details>


### [269] [Silencing Newtonian noise using fusion sensor arrays](https://arxiv.org/abs/2512.13554)
*Paul Ophardt,Francesca Badaracco,Katharina-Sophie Isleif*

Main category: gr-qc

TL;DR: 融合地震仪与分布式声学传感(DAS)的传感器阵列可有效降低爱因斯坦望远镜(ET)中的牛顿噪声，在传感器数量有限时性能优于纯地震仪阵列，提供成本效益高的解决方案。


<details>
  <summary>Details</summary>
Motivation: 第三代引力波探测器（如爱因斯坦望远镜）的低频灵敏度受到地震密度波动引起的牛顿噪声限制。现有方法依赖地震仪阵列和维纳滤波，而分布式声学传感(DAS)提供了一种低成本获取密集应变测量的补充手段。

Method: 研究融合传感器阵列，结合位移测量地震仪和应变测量DAS型传感器。扩展维纳滤波形式到混合传感器类型，引入解析S波应变相关系数。使用混合差分进化和协方差矩阵自适应方案验证方法，分析优化融合阵列的几何结构、鲁棒性和性能。

Result: 融合阵列增强了P/S波解耦能力，在牛顿噪声消除水平上达到甚至超过纯地震仪阵列，特别是在传感器数量较少时。当传感器受限于ET基础设施时，6个地震仪配合14个应变计在ET臂内可达到20个钻孔地震仪的性能，实现10%水平的残余噪声。

Conclusion: 融合传感器阵列为ET规模的牛顿噪声抑制提供了成本效益高的途径，在传感器数量受限时尤其有效，能够匹配或超越纯地震仪阵列的性能。

Abstract: Newtonian noise (NN) from seismic density fluctuations is expected to limit the low-frequency sensitivity of third-generation gravitational-wave detectors, in particular the Einstein Telescope (ET). Current NN mitigation relies on seismometer arrays and Wiener filtering, while distributed acoustic sensing (DAS) offers a complementary, low-cost means of obtaining dense strain measurements. We investigate fusion sensor arrays composed of both displacement-measuring seismometers and strain-measuring DAS-type sensors. We extend the Wiener filter formalism to mixed sensor types and introduce analytic S-wave strain correlation coefficients. Using a hybrid differential evolution and covariance matrix adaptation scheme, we validate our approach against established seismometer-only results and analyze the geometry, robustness, and performance of optimized fusion arrays. Fusion arrays enhance P/S-wave disentanglement and achieve NN cancellation levels comparable to, and sometimes exceeding, those of seismometer-only arrays, particularly for small sensor numbers. When sensors are constrained to the ET infrastructure, we find that six seismometers complemented by fourteen strainmeters inside the ET arms can match the performance of twenty seismometers in boreholes, achieving a residual at the 10% level, and thereby offering a cost-efficient pathway toward ET-scale NN mitigation.

</details>


### [270] [Could a thin-shell configuration lie hidden within the Universe?](https://arxiv.org/abs/2512.13575)
*Mauricio Cataldo,Antonella Cid,Pedro Labraña*

Main category: gr-qc

TL;DR: 论文提出一个包含隐藏薄壳结构的宇宙学模型，通过坐标变换获得退化的FRW度规，描述了一个演化虫洞几何，连接两个渐近平坦的FRW区域，虫洞喉部对应薄壳奇异点。


<details>
  <summary>Details</summary>
Motivation: 探索宇宙中可能存在的隐藏薄壳结构，研究通过坐标变换处理大爆炸奇点的类似方法，构建包含虫洞几何的宇宙学模型。

Method: 对径向坐标应用坐标变换获得退化的FRW度规，使用Israel连接形式主义分析坐标奇点，计算薄壳的表面能量密度和各向同性压力。

Result: 坐标奇点对应一个薄壳，由奇异物质组成，满足状态方程p=-ρ/2，违反标准能量条件；随着宇宙膨胀，薄壳密度按1/a(t)比例稀释。

Conclusion: 宇宙可能包含隐藏的薄壳虫洞结构，这种结构需要奇异物质维持，随着宇宙膨胀逐渐稀释，为宇宙学模型提供了新的可能性。

Abstract: This article explores the cosmological scenario in which our Universe contains a hidden thin-shell configuration. We investigate a degenerate modification of the Friedmann-Robertson-Walker metric obtained through a coordinate transformation applied to the radial coordinate, analogous to recent approaches that address the Big Bang singularity via spacetime defects. The resulting metric, while formally satisfying the standard homogeneous Friedmann equations, actually describes an evolving wormhole geometry with two asymptotically flat Friedmann-Robertson-Walker regions connected by a throat located at the coordinate singularity. Using Israel's junction formalism, we demonstrate that this coordinate singularity corresponds to a thin shell characterized by exotic matter with well-defined surface energy density and isotropic pressure. The shell obeys the barotropic equation of state $p = -ρ/2$, confirming the presence of exotic matter that violates the standard energy condition, which is a requirement for maintaining wormhole geometries. As the universe expands, this thin shell becomes increasingly diluted, scaling as $1/a(t)$ with the cosmic scale factor.

</details>


### [271] [Resonances in the early Universe](https://arxiv.org/abs/2512.13621)
*D. L. Canedo,G. Oliveira-Neto,G. A. Monerat,E. V. Corrêa Silva*

Main category: gr-qc

TL;DR: 研究带正曲率空间截面的FLRW量子宇宙学模型，包含辐射流体、Chaplygin气体和特定势能，分析双势垒隧穿概率中的共振现象


<details>
  <summary>Details</summary>
Motivation: 研究量子宇宙学中宇宙如何从量子隧穿中诞生，特别关注双势垒势能下的隧穿概率，探索宇宙可能以特定参数值诞生的机制

Method: 建立FLRW量子宇宙学模型，包含辐射流体、Chaplygin气体和特定势能；推导哈密顿量，获得Wheeler-DeWitt方程；使用WKB近似求解并计算双势垒隧穿概率

Result: 发现隧穿概率随参数A、B、σ和辐射能量E变化时出现显著共振现象，表明宇宙可能以特定的E或σ值诞生

Conclusion: 双势垒势能中的共振现象可能导致宇宙以特定的能量或势能参数值诞生，为量子宇宙学中的宇宙起源提供了新的物理机制

Abstract: In the present paper, we study a Friedmann-Lemaître-Robertson-Walker (FLRW) quantum cosmology model with positively curved spatial sections. The matter content of the model is given by a radiation fluid, a Chaplygin gas, and an ad hoc potential. After writing the Hamiltonian of the model, we notice that the effective potential ($V_{eff}$) depends on three parameters: $A$ and $B$ associated with the Chaplygin gas, and $σ$ associated with the ad hoc potential. Depending on the values of these parameters $V_{eff}$ becomes a double barrier potential. We quantize the model and obtain the Wheeler-DeWitt equation. We solve that equation using the WKB approximation and compute the corresponding probability ($TP_{WKB}$) that the wavefunction of the universe tunnels through the double barrier potential $V_{eff}$. We study how $TP_{WKB}$ behaves as a function of the parameters $A$, $B$, $σ$ and the radiation energy $E$. We notice a significant occurrence of resonances in $TP_{WKB}$ when varying it as a function of $E$ or $σ$. It is a very interesting phenomenon because it may cause the universe to be born with selected values of $E$ or $σ$.

</details>


### [272] [Two-point correlators in de Sitter-prepared states with bra-ket wormholes](https://arxiv.org/abs/2512.13646)
*Sunghoon Jung,Minju Kum,Junghwan Lee*

Main category: gr-qc

TL;DR: 论文研究de Sitter时空中"bra-ket虫洞"如何修改引力制备态中的关联函数，发现晚期存在鞍点转变，关联函数呈现"斜坡-平台"行为，时间尺度与快速扰乱相当。


<details>
  <summary>Details</summary>
Motivation: 受de Sitter视界熵有限性的启发，研究引力路径积分中欧几里得虫洞鞍点如何产生关联函数的非因子化贡献，类似于复制虫洞解释Page曲线和bra-ket虫洞恢复强次可加性。

Method: 通过定义"时间"变量，在de Sitter边界连接的平坦区域计算可观测量，评估bra-ket虫洞对标量两点函数的贡献，分析晚期主导鞍点的转变。

Result: 发现晚期存在鞍点转变，关联函数呈现斜坡-平台行为，特征时间尺度与快速扰乱相当；虫洞贡献增强了小共动动量k处的关联，模式计数与拓扑抑制的竞争驱动了虫洞主导的转变。

Conclusion: 结果在定性上一致，但需要解决虫洞稳定性问题才能清晰地从熵的角度解释；研究基于暴胀视界进出、小k处虫洞增强关联、以及模式计数与拓扑抑制的竞争机制。

Abstract: Motivated by the finiteness of de Sitter (dS) horizon entropy, we study how ``bra-ket wormholes'' modify correlation functions in gravitationally prepared states. Euclidean wormhole saddles in gravitational path integrals can generate non-factorizing contributions to correlation functions, as in replica-wormhole explanation of the Page curve and bra-ket-wormhole restoration of strong subadditivity. By defining `time' variables and computing observables in a flat region attached to the dS boundary, we evaluate bra-ket wormhole contributions to scalar two-point functions and find a late-time transition in the dominant saddle, accompanied by ramp-and-plateau behavior of correlations and characteristic timescale comparable to the fast scrambling. Our results are built upon (i) inflationary horizon exit and re-entry, (ii) enhancement of correlation at small comoving momentum $k$ by wormhole contribution, and (iii) a competition between mode counting and topological suppression that drives a transition to wormhole dominance. Although results are qualitatively consistent, one needs to address wormhole stabilization to clearly interpret in terms of the entropy context.

</details>


### [273] [Schrödinger Symmetry in Spherically-symmetric Static Mini-superspaces with Matter Fields](https://arxiv.org/abs/2512.13651)
*Taishi Sano,Yuki Yokokura*

Main category: gr-qc

TL;DR: 论文研究了从超空间到多个迷你超空间模型中出现的薛定谔对称性，验证了该对称性在经典层面的鲁棒性，并提出了基于哈密顿约束的物理解释。


<details>
  <summary>Details</summary>
Motivation: 研究薛定谔对称性在引力-物质耦合系统中的涌现特性，验证该对称性在不同迷你超空间模型中的鲁棒性，并为量子引力动力学探索提供新的对称性基础。

Method: 采用基于正则变换的方法，分析两个球对称静态迷你超空间模型：(1) 带宇宙学常数的麦克斯韦场模型，(2) n个无质量标量场模型。通过哈密顿约束分析对称性生成元的行为。

Result: 模型(1)涌现出3D薛定谔对称性，解为(反)德西特-赖斯纳-诺德斯特伦时空；模型(2)涌现出(2+n)D薛定谔对称性，解为广义Janis-Newman-Winicour时空及其内部的Kantowski-Sachs型闭合宇宙。物质退耦极限下两者都导致2D薛定谔对称性。

Conclusion: 薛定谔对称性在经典层面具有鲁棒性，其生成元与哈密顿约束的交换关系决定了对称性变换的性质：交换的生成元将解映射到另一个解，不交换的生成元则生成具有薛定谔对称性的新理论。这为基于对称性探索量子动力学开辟了新可能性。

Abstract: Schrödinger symmetry emerged in a ``fluid limit" from a full superspace to several mini-superspace models. We consider two spherically-symmetric static mini-superspace models with matter fields and verify the robustness of this emergent symmetry at the classical level: (i) Maxwell field with cosmological constant and (ii) $n$ massless scalar fields. We develop a method based on canonical transformations and show that: for model (i), 3D Schrödinger symmetry emerges, and the solution is the (anti-) de Sitter Reissner-Nordström spacetime, and for model (ii), $(2+n)$D Schrödinger symmetry appears, and the solution is a generalized Janis-Newman-Winicour spacetime and its ``interior", a Kantowski-Sachs type closed universe. In the matter decoupling limit, both cases lead to 2D Schrödinger symmetry in different lapse functions and mini-superspace coordinates, which implies the covariance of Schrödinger symmetry. Finally, we propose a physical interpretation of the symmetry under Hamiltonian constraints $H$ and explain it with examples: Symmetry generators commuting with $H$ map a solution to another one, while those non-commuting with $H$ generate a new theory with the Schrödinger symmetry and the transformed configuration is a solution to the new theory. These support the robustness of the emergence of Schrödinger symmetry and open new possibilities for exploring quantum dynamics of matter and gravity based on the symmetry.

</details>
