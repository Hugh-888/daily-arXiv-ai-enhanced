<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 63]
- [quant-ph](#quant-ph) [Total: 34]
- [gr-qc](#gr-qc) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 该论文系统评估了工业异常检测算法在不同类别不平衡程度下的性能，发现最佳检测器取决于训练数据中故障样本的总数，而非健康样本数量。


<details>
  <summary>Details</summary>
Motivation: 机器学习在工业系统（如质量控制和预测性维护）中面临极端类别不平衡的挑战，主要原因是训练过程中故障数据的可用性有限。需要评估异常检测算法在真实工业约束下的性能。

Method: 使用问题无关的模拟数据集（基于超球面异常分布的2D和10D合成数据），在异常率0.05%-20%、训练规模1,000-10,000的数据集上，对14种检测器进行基准测试，评估性能和泛化误差。

Result: 最佳检测器高度依赖于训练数据中故障样本的总数：故障样本少于20个时，无监督方法（kNN/LOF）占优；30-50个故障样本时，半监督（XGBOD）和监督（SVM/CatBoost）方法性能大幅提升。额外健康样本在大多数情况下益处有限。

Conclusion: 研究揭示了异常检测方法在小数据集上的泛化性能下降问题，为工业环境中部署异常检测提供了实用指导：选择检测器时应主要考虑可用故障样本数量，而非数据集总体规模。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [2] [Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games](https://arxiv.org/abs/2601.00007)
*Nicholas A. Pape*

Main category: cs.LG

TL;DR: 该研究将Yahtzee游戏建模为MDP，使用多种策略梯度方法训练自博弈智能体，发现A2C在固定训练预算下表现最稳健，达到接近最优性能的241.78分，但仍存在长期信用分配和探索挑战。


<details>
  <summary>Details</summary>
Motivation: Yahtzee作为具有随机组合结构和延迟奖励的经典骰子游戏，是中等规模RL基准的有趣选择。虽然单人游戏可通过动态规划求解最优策略，但多人游戏难以处理，需要近似方法。

Method: 将Yahtzee建模为马尔可夫决策过程，使用REINFORCE、A2C和PPO等策略梯度方法训练自博弈智能体，采用具有共享主干的多头网络架构，并对特征编码、动作编码、架构、回报估计器和熵正则化进行消融研究。

Result: 在固定训练预算下，REINFORCE和PPO对超参数敏感且未能达到接近最优性能，而A2C在各种设置下都能稳健训练。最佳智能体在10万次评估游戏中获得中位数241.78分，接近最优DP分数254.59的5%以内，上区奖励和Yahtzee达成率分别为24.9%和34.1%。

Conclusion: A2C在Yahtzee游戏中表现出色，但所有模型都难以学习上区奖励策略，过度关注四骰组合，突显了长期信用分配和探索方面的持续挑战。

Abstract: Yahtzee is a classic dice game with a stochastic, combinatorial structure and delayed rewards, making it an interesting mid-scale RL benchmark. While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods. We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods: REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk. We ablate feature and action encodings, architecture, return estimators, and entropy regularization to understand their impact on learning. Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance, whereas A2C trains robustly across a range of settings. Our agent attains a median score of 241.78 points over 100,000 evaluation games, within 5.0\% of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of 24.9\% and 34.1\%, respectively. All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment and exploration challenges.

</details>


### [3] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 论文提出一种针对LLM模型组合技术的攻击方法：通过设计单个"破坏性token"，在捐赠模型中功能惰性，但在移植到基础模型后能可靠重构为高显著性恶意特征，从而破坏基础模型的生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着开源LLM生态系统越来越多地使用模型组合技术（如权重合并、推测解码、词汇扩展），这些方法需要在不同模型家族之间进行tokenizer移植。论文发现这一关键互操作性步骤引入了供应链漏洞，攻击者可以利用该漏洞破坏基础模型。

Method: 1. 形式化为双目标优化问题：既要使token在捐赠模型中功能惰性，又要在移植到基础模型后重构为高显著性恶意特征。2. 利用系数重用的几何特性，创建不对称可实现性差距。3. 使用稀疏求解器实例化攻击，实现训练免费的攻击方法。4. 通过谱模仿规避异常检测。

Result: 攻击成功实现了：1. 在捐赠模型中保持统计上无法区分的正常行为。2. 在基础模型中可靠重构为恶意特征，破坏其生成能力。3. 攻击具有结构持久性，能抵抗微调和权重合并。4. 通过谱模仿有效规避异常检测。

Conclusion: 论文揭示了模块化AI组合流程中的隐藏风险：tokenizer移植这一关键互操作性步骤存在供应链漏洞，攻击者可以设计单个破坏性token来破坏基础模型，同时保持捐赠模型表面正常。这凸显了在模型组合技术中需要更强的安全保证。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [4] [IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business](https://arxiv.org/abs/2601.00075)
*Swetha Varadarajan,Abhishek Ray,Lumina Albert*

Main category: cs.LG

TL;DR: IMBWatch是一个时空图神经网络框架，用于大规模检测伪装成合法按摩店的非法按摩场所，这些场所涉及人口贩卖和性剥削。


<details>
  <summary>Details</summary>
Motivation: 非法按摩场所（IMBs）是隐蔽且持续的有组织剥削形式，伪装成合法健康服务，但实际涉及人口贩卖、性剥削和强迫劳动。传统检测方法（社区举报和监管检查）被动且无效，难以揭示更广泛的运营网络。

Method: IMBWatch是一个时空图神经网络（ST-GNN）框架，从开源情报构建动态图，包括在线广告、营业执照记录和众包评论。节点代表企业、别名、电话号码和位置等异质实体，边捕获时空和关系模式。框架结合图卷积操作和时间注意力机制，建模IMB网络在时间和空间上的演化。

Result: 在美国多个城市的真实数据集上的实验显示，IMBWatch优于基线模型，实现了更高的准确率和F1分数。除了性能提升外，还提供了更好的可解释性，支持主动和有针对性的干预。

Conclusion: IMBWatch是一个可扩展的框架，可适应其他非法领域，并发布了匿名数据和开源代码以支持可重复研究。该框架为打击人口贩卖和性剥削提供了有效的技术工具。

Abstract: Illicit Massage Businesses (IMBs) are a covert and persistent form of organized exploitation that operate under the facade of legitimate wellness services while facilitating human trafficking, sexual exploitation, and coerced labor. Detecting IMBs is difficult due to encoded digital advertisements, frequent changes in personnel and locations, and the reuse of shared infrastructure such as phone numbers and addresses. Traditional approaches, including community tips and regulatory inspections, are largely reactive and ineffective at revealing the broader operational networks traffickers rely on.
  To address these challenges, we introduce IMBWatch, a spatio-temporal graph neural network (ST-GNN) framework for large-scale IMB detection. IMBWatch constructs dynamic graphs from open-source intelligence, including scraped online advertisements, business license records, and crowdsourced reviews. Nodes represent heterogeneous entities such as businesses, aliases, phone numbers, and locations, while edges capture spatio-temporal and relational patterns, including co-location, repeated phone usage, and synchronized advertising. The framework combines graph convolutional operations with temporal attention mechanisms to model the evolution of IMB networks over time and space, capturing patterns such as intercity worker movement, burner phone rotation, and coordinated advertising surges.
  Experiments on real-world datasets from multiple U.S. cities show that IMBWatch outperforms baseline models, achieving higher accuracy and F1 scores. Beyond performance gains, IMBWatch offers improved interpretability, providing actionable insights to support proactive and targeted interventions. The framework is scalable, adaptable to other illicit domains, and released with anonymized data and open-source code to support reproducible research.

</details>


### [5] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 提出一种渐近置信度的最优臂识别新框架，通过放松严格误差控制要求，在非参数设置下实现更紧的最优性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有BAI算法在实际应用中存在局限：严格的精确误差控制需要使用宽松的尾不等式和/或参数限制，导致样本效率低下。现实场景常涉及弱信号、高显著性要求和实验后推断需求，这些都需要较长的实验周期。

Method: 引入渐近误差控制框架，要求随着最小样本量的增加而渐近有效。开发新颖的渐近任意时间有效置信序列，并基于此设计新的BAI算法。灵活整合协变量进行方差缩减，确保在完全非参数设置下的近似误差控制。

Result: 在温和收敛假设下，提供了样本复杂度的渐近界限，并证明在最坏情况下，该方法的样本复杂度与高斯BAI在精确误差保证和已知方差下的最佳情况样本复杂度相匹配。实验表明该方法在保持误差控制的同时减少了平均样本复杂度。

Conclusion: 提出的渐近框架克服了现有BAI方法的局限性，实现了更紧的最优性，更好地处理灵活的非参数结果分布，并充分利用个体层面的上下文信息，为实际应用提供了更实用的解决方案。

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [6] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: NeuroSymBO：通过贝叶斯优化自适应选择指令，解决LLM方程发现中的指令脆弱性问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在方程发现中表现出潜力，但输出对提示词高度敏感（指令脆弱性）。静态提示无法适应多步生成过程的演化状态，导致模型停留在次优解。

Method: 将提示工程重构为序列决策问题：维护离散推理策略库，使用贝叶斯优化根据数值反馈在每一步选择最优指令。

Result: 在PDE发现基准测试中，自适应指令选择显著优于固定提示，获得更高的恢复率和更简约的解。

Conclusion: 自适应指令选择能有效解决LLM方程发现中的指令脆弱性问题，提升模型性能和解的质量。

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [7] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM是一个几何强化学习框架，用于在未知环境中进行同时导航与建图。该方法通过局部能量景观编码可达性，使用哈密顿优化进行动态最短路径搜索，无需构建全局地图。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中的同时导航与建图问题具有挑战性，因为需要在没有先验地图的情况下设计多智能体的分层或联合策略来控制机器人移动。现有方法通常需要构建全局地图，而本文希望仅依赖局部感官观察来实现高效导航。

Method: 将路径导航和建图建模为使用受控哈密顿优化的动态最短路径搜索过程：感官输入转化为编码可达性、障碍物屏障和变形约束的局部能量景观；感知、规划和重新配置策略通过更新哈密顿量逐步演化；简化哈密顿量作为自适应评分函数，更新动能/势能项，嵌入屏障约束，并随着新局部信息的到达持续优化轨迹。

Result: 在两个不同的2D导航任务上评估GRL-SNAM，与局部反应式基线和全局策略学习参考方法相比，在相同的阶段性感知约束下，该方法保持安全距离，泛化到未见过的布局，并通过局部能量优化而非广泛全局建图实现高质量导航。

Conclusion: 通过更新哈密顿量的几何强化学习能够通过局部能量优化实现高质量导航，仅需最小化探索而无需广泛全局建图，为未知环境中的同时导航与建图提供了有效解决方案。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [8] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 研究非马尔可夫状态和成本过程下的线性函数逼近强化学习方法，证明策略评估算法的收敛性，分析Q-learning在特定基函数选择下的收敛条件，并将结果应用于部分可观测马尔可夫决策过程。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法通常假设马尔可夫过程，但在实际应用中，状态和成本过程往往是非马尔可夫的。需要研究在非马尔可夫环境下，使用线性函数逼近的强化学习算法的收敛性和性能。

Method: 1. 研究策略评估方法，证明在非马尔可夫过程的遍历性条件下算法收敛；2. 分析Q-learning与线性函数逼近，证明在基于量化映射选择基函数的特殊情况下收敛；3. 将结果应用于部分可观测马尔可夫决策过程，使用有限记忆变量作为状态表示。

Result: 1. 策略评估算法在适当遍历性条件下收敛，极限对应于正交投影与辅助马尔可夫决策过程Bellman算子的联合算子的不动点；2. Q-learning在基于量化映射选择基函数时，在类似遍历性条件下收敛；3. 为部分可观测马尔可夫决策过程的学习算法推导了明确的误差界。

Conclusion: 该研究为非马尔可夫环境下的线性函数逼近强化学习提供了理论保证，特别是在策略评估和特定基函数选择的Q-learning中证明了收敛性，并将理论结果成功应用于部分可观测马尔可夫决策过程，为实际应用提供了理论基础。

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [9] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 本研究使用XGBoost模型分析美国交通事故严重程度的预测因素，发现时间、地理位置和天气变量是主要预测因子，但模型对极端严重程度案例的预测能力有限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索环境、时间和空间因素对美国交通事故严重程度的预测能力，为基于证据的交通管理提供支持。

Method: 使用2016-2023年美国50万起交通事故数据集，通过随机搜索交叉验证优化XGBoost分类器，并采用类别加权处理类别不平衡问题。

Result: 最终模型整体准确率达78%，对主要类别（严重程度2）的精确率和召回率均达到87%。特征重要性分析显示时间、地理位置和天气变量（能见度、温度、风速）是最强预测因子，但降水和能见度的预测能力有限。

Conclusion: 研究为基于证据的交通管理提供了见解，但指出数据集以中等严重程度事故为主限制了模型对极端案例的学习能力，建议未来采用替代采样策略、增强特征工程和整合外部数据集。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [10] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 提出新算法使决策变换器能够使用纯强化学习梯度进行在线微调，解决了现有方法依赖监督学习目标的问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 决策变换器在离线强化学习中表现出色，但扩展到在线设置时仍主要依赖监督序列建模目标。研究发现后见回报重标注这一标准组件与重要性采样强化学习算法不兼容，导致训练不稳定，阻碍了基于纯强化学习梯度的在线微调。

Method: 将GRPO算法适配到决策变换器，并引入关键修改：子轨迹优化以改进信用分配、序列级似然目标以增强稳定性和效率、主动采样以鼓励在不确定区域的探索。

Result: 新方法在多个基准测试中超越了现有的在线决策变换器基线，实现了最先进的性能，证明了基于纯强化学习的在线微调对决策变换器的有效性。

Conclusion: 通过解决后见回报重标注与重要性采样强化学习算法的不兼容问题，成功实现了决策变换器的纯强化学习在线微调，为序列决策模型提供了更有效的在线学习框架。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [11] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: 提出Sequential Reservoir Computing架构，通过将大储层分解为一系列小型互联储层，降低内存和计算成本，在高维时空系统预测中比传统RNN/LSTM表现更好


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在高维时空系统预测中存在梯度训练和内存瓶颈问题，传统Reservoir Computing虽然缓解了这些问题，但在输入维度扩展时仍然表现不佳

Method: 提出Sequential Reservoir Computing架构，将大型储层分解为一系列小型互联储层，保持固定循环层和凸读出优化，降低内存和计算成本同时保留长期时间依赖性

Result: 在低维混沌系统和高维物理模拟中，Sequential RC比LSTM和标准RNN基线获得15-25%更长的有效预测范围，20-30%更低的误差指标，训练成本降低达三个数量级

Conclusion: Sequential RC保持了传统RC的简单性和效率，同时在高维动力系统中实现了更好的可扩展性，为科学和工程应用中的实时、节能预测提供了实用路径

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [12] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 开发机器学习模型预测肝硬化的发生，在1-3年预测窗口上显著优于传统FIB-4评分


<details>
  <summary>Details</summary>
Motivation: 利用常规电子健康记录数据开发早期肝硬化预测模型，以改进传统FIB-4评分的预测性能，实现更早的风险分层和预防管理

Method: 回顾性队列研究，使用大型学术医疗系统的去标识化EHR数据，识别脂肪肝患者并分为肝硬化与非肝硬化队列，构建1-3年预测场景，使用XGBoost模型训练并评估

Result: 机器学习模型在所有预测窗口上均优于FIB-4：XGBoost模型的AUC分别为1年0.81、2年0.73、3年0.69，而FIB-4分别为0.71、0.63、0.57

Conclusion: 基于常规EHR数据的机器学习模型显著优于传统FIB-4评分，能够实现更早、更准确的风险分层，可作为自动化决策支持工具集成到临床工作流程中

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [13] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应重复编码框架，实现维度级不等错误保护，在有限带宽下显著提升语义通信性能


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限通信系统中语义信息保持的挑战，传统信道编码（如LDPC、Reed-Solomon）无法实现细粒度语义保护

Method: 基于强化学习的自适应重复编码框架，使用复合语义失真度量（全局嵌入相似性与实体级保护平衡），实现上下文感知的保护分配

Result: 在1dB SNR下，相比均匀保护获得6.8%更高的chrF分数和9.3%更好的实体保护，统计显著优于传统方法

Conclusion: 简单但智能分配的重复编码可实现细粒度语义保护，代码结构需与语义粒度对齐，适用于边缘计算和物联网等带宽稀缺但语义保真度关键的场景

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [14] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 提出SSI-GAN半监督深度学习模型，仅需1-3%标注数据即可高精度分类蚊子神经元尖峰信号，检测寨卡病毒、登革热病毒感染，大幅减少人工标注工作量。


<details>
  <summary>Details</summary>
Motivation: 蚊子是虫媒病毒主要传播媒介，人工分类神经元尖峰模式耗时耗力。现有深度学习方案需要完全标注的数据集和高度预处理信号，难以在实际场景大规模应用。需要解决标注数据稀缺问题。

Method: 提出半监督Swin启发式GAN架构（SSI-GAN），包含基于Transformer的生成器和Swin启发的移位窗口判别器。采用多头自注意力模型在平面窗口式Transformer判别器中学习稀疏高频尖峰特征。使用贝叶斯Optuna框架优化超参数，五折蒙特卡洛交叉验证评估鲁棒性。

Result: 仅用3%标注数据，在感染后第三天达到99.93%分类准确率；仅用1%监督在所有感染阶段保持高准确率。相比标准监督方法，在相同性能水平下减少97-99%人工标注工作量。移位窗口Transformer设计大幅超越所有基线方法。

Conclusion: SSI-GAN有效解决了神经元尖峰信号分类中标注数据稀缺问题，显著降低人工标注成本，为实际现场大规模应用提供了可行解决方案，在基于尖峰的神经元感染分类中设立了新的最佳标准。

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [15] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 提出一个资源高效的以数据为中心的心律失常检测框架，通过特征工程使高维数据线性可分，在MIT-BIH和INCART数据集上达到98.44%准确率，模型仅8.54KB，推理延迟0.46μs。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病特别是心律失常是全球主要死因，需要IoMT持续监测。现有深度学习方法计算开销大，不适合资源受限的边缘设备。

Method: 提出资源高效的以数据为中心框架，优先特征工程而非模型复杂度。通过时频小波分解和图论结构描述符（如PageRank中心性）的集成，使复杂高维心律失常数据线性可分。使用互信息和递归消除优化特征空间，采用可解释的超轻量线性分类器。

Result: 在MIT-BIH和INCART数据集上获得98.44%诊断准确率，模型大小仅8.54KB。系统在每搏52ms流水线内实现0.46μs分类推理延迟，确保实时操作。相比压缩模型KD-Light（25KB，96.32%准确率）获得数量级效率提升。

Conclusion: 该框架为资源受限边缘设备提供高效心律失常检测方案，显著优于现有压缩模型，推动了无电池心脏传感器的发展。

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [16] [Unknown Aware AI-Generated Content Attribution](https://arxiv.org/abs/2601.00218)
*Ellie Thieu,Jifan Zhang,Haoyue Bai*

Main category: cs.LG

TL;DR: 提出利用未标注的互联网数据（wild data）来增强生成模型归因的方法，通过约束优化提升对未知生成器的泛化能力


<details>
  <summary>Details</summary>
Motivation: 随着逼真生成模型的快速发展，需要超越简单的真假检测，准确识别特定生成模型产生的图像。现有方法在泛化到未知或新发布的生成器时表现不佳。

Method: 使用CLIP特征和线性分类器建立基线，然后提出约束优化方法：利用未标注的互联网数据（wild data），鼓励这些数据被分类为非目标生成器，同时约束在标注数据上的性能保持高水平。

Result: 实验结果显示，引入wild data显著提升了在挑战性未知生成器上的归因性能，证明未标注数据可以有效增强开放世界场景下的AI生成内容归因能力。

Conclusion: 利用未标注的互联网数据可以有效解决生成模型归因中的泛化问题，为开放世界环境下的AI生成内容溯源提供了有效方法。

Abstract: The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.

</details>


### [17] [Robust Graph Fine-Tuning with Adversarial Graph Prompting](https://arxiv.org/abs/2601.00229)
*Ziyan Zhang,Bo Jiang,Jin Tang*

Main category: cs.LG

TL;DR: 提出对抗性图提示（AGP）框架，首次将对抗学习融入图提示中，通过min-max优化解决图神经网络微调中的噪声和攻击脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法在图拓扑和节点特征面临各种噪声和攻击时表现出显著脆弱性，需要开发更鲁棒的图微调方法。

Method: 提出对抗性图提示（AGP）框架，采用min-max优化：内层最大化使用联合投影梯度下降（JointPGD）生成强对抗噪声；外层最小化学习最优节点提示来对抗噪声。理论证明能处理图拓扑和节点噪声。

Result: 在多个基准任务上的广泛实验验证了AGP相比最先进方法的鲁棒性和有效性，能够增强预训练GNN模型在下游任务中的鲁棒性。

Conclusion: AGP是一个通用框架，可集成到各种预训练GNN模型中，首次将对抗学习融入图提示，有效解决了图微调中的噪声和攻击脆弱性问题。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) method has emerged as a dominant paradigm for adapting pre-trained GNN models to downstream tasks. However, existing PEFT methods usually exhibit significant vulnerability to various noise and attacks on graph topology and node attributes/features. To address this issue, for the first time, we propose integrating adversarial learning into graph prompting and develop a novel Adversarial Graph Prompting (AGP) framework to achieve robust graph fine-tuning. Our AGP has two key aspects. First, we propose the general problem formulation of AGP as a min-max optimization problem and develop an alternating optimization scheme to solve it. For inner maximization, we propose Joint Projected Gradient Descent (JointPGD) algorithm to generate strong adversarial noise. For outer minimization, we employ a simple yet effective module to learn the optimal node prompts to counteract the adversarial noise. Second, we demonstrate that the proposed AGP can theoretically address both graph topology and node noise. This confirms the versatility and robustness of our AGP fine-tuning method across various graph noise. Note that, the proposed AGP is a general method that can be integrated with various pre-trained GNN models to enhance their robustness on the downstream tasks. Extensive experiments on multiple benchmark tasks validate the robustness and effectiveness of AGP method compared to state-of-the-art methods.

</details>


### [18] [GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation](https://arxiv.org/abs/2601.00231)
*Pritish Saha,Chandrav Rajbangshi,Rudra Goyal,Mohit Goyal,Anurag Deo,Biswajit Roy,Ningthoujam Dhanachandra Singh,Raxit Goswami,Amitava Das*

Main category: cs.LG

TL;DR: GRIT是一种动态、曲率感知的LoRA方法，通过K-FAC预条件梯度、定期重投影到Fisher主特征方向、自适应调整有效秩，在减少46%可训练参数的同时达到或超越LoRA/QLoRA性能


<details>
  <summary>Details</summary>
Motivation: 现有LoRA和QLoRA方法在几何上不够敏感：它们在固定的随机低秩子空间中优化，使用一阶下降，主要忽略了局部损失曲率。这可能导致有效更新预算膨胀和沿弱约束方向的漂移放大。

Method: GRIT保持LoRA参数化但：(1)使用K-FAC作为自然梯度代理在秩空间中对梯度进行预条件处理；(2)定期将低秩基重投影到主导Fisher特征方向以抑制漂移；(3)根据谱自适应调整有效秩，使容量集中在信号存在的地方。

Result: 在LLaMA骨干上的指令跟随、理解和推理基准测试中，GRIT匹配或超越了LoRA和QLoRA，同时平均减少了46%的可训练参数（跨任务25-80%），在不同提示风格和数据混合中没有实际质量损失。GRIT显示出更低的漂移和更好的更新与保留边界。

Conclusion: GRIT通过引入曲率感知的动态调整机制，显著提升了参数高效微调的效果，在保持LoRA简洁性的同时解决了现有方法的几何不敏感问题，为PEFT提供了更高效的解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).

</details>


### [19] [Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering](https://arxiv.org/abs/2601.00276)
*Hongxi Li,Chunlin Huang*

Main category: cs.LG

TL;DR: 宽L2正则化网络中监督学习本质上是压缩的，核秩受类别数限制，SGD噪声也是低秩的，与自监督学习的高秩表示形成对比。


<details>
  <summary>Details</summary>
Motivation: 研究宽L2正则化网络中特征学习的本质特性，探索监督学习与自监督学习在表示结构上的根本差异。

Method: 提出理论框架，推导预测"水填充"谱演化的核ODE，证明稳定稳态下核秩受类别数限制，分析SGD噪声的低秩特性。

Result: 监督学习核秩受类别数C限制，SGD噪声也是O(C)低秩，动态被限制在任务相关子空间，与自监督学习的高秩扩展表示形成鲜明对比。

Conclusion: 监督学习本质上是压缩的，核秩和SGD噪声都受类别数限制，这统一了确定性和随机性对齐视角，揭示了监督与自监督学习在表示结构上的根本差异。

Abstract: We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a "water-filling" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classes ($C$). We further demonstrate that SGD noise is similarly low-rank ($O(C)$), confining dynamics to the task-relevant subspace. This framework unifies the deterministic and stochastic views of alignment and contrasts the low-rank nature of supervised learning with the high-rank, expansive representations of self-supervision.

</details>


### [20] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 提出基于最优传输的联邦逆强化学习方法，通过Wasserstein重心融合异构智能体的本地奖励函数，实现通信高效且能跨环境泛化的共享奖励学习。


<details>
  <summary>Details</summary>
Motivation: 在多机器人/多智能体系统中，智能体通常在略有不同的环境中运行，追求共同的高级目标。由于动态差异、隐私约束和有限通信带宽，直接池化数据学习共享奖励函数通常不切实际。

Method: 1) 每个客户端先在本地执行轻量级最大熵逆强化学习，遵守计算和隐私限制；2) 通过Wasserstein重心融合得到的奖励函数，考虑其底层几何结构；3) 证明这种重心融合比传统联邦学习参数平均方法能产生更准确的全局奖励估计。

Result: 该方法提供了一个原则性且通信高效的框架，用于推导能在异构智能体和环境中泛化的共享奖励函数。

Conclusion: 基于最优传输的联邦逆强化学习方法能够有效解决异构智能体环境下的奖励函数学习问题，通过Wasserstein重心融合实现比传统方法更准确的全局奖励估计。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [21] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 该论文提出了基于国际象棋战术的量子基准测试QKRD，用于评估QAOA算法在结构化问题上的表现，发现约束保持混合器、热启动策略等能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有QAOA基准测试主要使用随机合成实例（如MaxCut、TSP、SAT），这些实例缺乏语义结构和人类可解释性，无法反映真实世界问题的约束特性，限制了算法在实际应用中的性能评估。

Method: 提出Quantum King-Ring Domination (QKRD)基准测试，基于国际象棋战术位置构建，包含5,000个结构化实例，具有one-hot约束、空间局部性和10-40量子比特规模。该基准提供人类可解释的覆盖度指标，并通过与经典启发式算法对比实现内在验证。

Result: 1. 约束保持混合器（XY、domain-wall）比标准混合器收敛快约13步（p<10^{-7}, d≈0.5）；2. 热启动策略减少45步收敛（p<10^{-127}, d=3.35），能量改进超过d=8；3. CVaR优化产生负面结果，能量更差（p<10^{-40}, d=1.21）且无覆盖度优势；4. QAOA优于贪婪启发式算法12.6%，优于随机选择80.1%。

Conclusion: 结构化基准测试能揭示在随机实例中被掩盖的问题感知QAOA技术优势，为NISQ算法研究提供了可重复的评估框架。作者发布了所有代码、数据和实验工件。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [22] [Smart Fault Detection in Nanosatellite Electrical Power System](https://arxiv.org/abs/2601.00335)
*Alireza Rezaee,Niloofar Nobahari,Amin Asgarifar,Farshid Hajati*

Main category: cs.LG

TL;DR: 提出一种无需姿态确定控制子系统(ADCS)的纳米卫星电力系统故障检测方法，使用神经网络模拟正常状态，结合多种机器学习方法进行故障分类


<details>
  <summary>Details</summary>
Motivation: 纳米卫星在LEO轨道运行时，其电力系统各部分（光伏子系统、DC-DC转换器、地面电池等）容易因压力耐受性、发射压力和环境因素发生故障，需要有效的故障检测方法

Method: 首先使用神经网络模拟无故障系统（输入为太阳辐射和太阳能板表面温度，输出为电流和负载），然后使用神经网络分类器结合PCA分类、决策树和KNN等机器学习方法进行故障模式识别和分类

Result: 开发了一种能够诊断光伏子系统线间故障和开路、DC-DC转换器IGBT短路和开路、地面电池调节器故障等多种故障的检测系统

Conclusion: 该方法能够在没有ADCS的情况下有效检测纳米卫星电力系统故障，为小型卫星的可靠运行提供了新的故障诊断方案

Abstract: This paper presents a new detection method of faults at Nanosatellites' electrical power without an Attitude Determination Control Subsystem (ADCS) at the LEO orbit. Each part of this system is at risk of fault due to pressure tolerance, launcher pressure, and environmental circumstances. Common faults are line to line fault and open circuit for the photovoltaic subsystem, short circuit and open circuit IGBT at DC to DC converter, and regulator fault of the ground battery. The system is simulated without fault based on a neural network using solar radiation and solar panel's surface temperature as input data and current and load as outputs. Finally, using the neural network classifier, different faults are diagnosed by pattern and type of fault. For fault classification, other machine learning methods are also used, such as PCA classification, decision tree, and KNN.

</details>


### [23] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: 该论文提出结合光流和三种深度学习模型（监督CNN、预训练CNN特征提取器、层次极限学习机）用于无人机非静态相机视频中的人体检测，在UCF-ARG数据集上取得高精度结果。


<details>
  <summary>Details</summary>
Motivation: 传统基于手工特征的方法依赖专家知识，对光照变化、相机抖动等动态事件敏感。需要更自动化的特征学习方法来解决无人机视频中的人体检测问题。

Method: 结合光流和三种深度学习模型：1) 监督卷积神经网络（S-CNN）；2) 预训练CNN特征提取器；3) 层次极限学习机（H-ELM）。在UCF-ARG空中数据集上训练和测试，评估五种人类动作。

Result: 预训练CNN平均准确率98.09%，S-CNN使用softmax为95.6%（SVM为91.7%），H-ELM为95.9%。H-ELM在CPU上训练445秒，S-CNN在GPU上训练770秒。

Conclusion: 提出的自动特征学习方法在无人机视频人体检测任务中表现成功，预训练CNN效果最佳，H-ELM在计算效率上有优势。

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


### [24] [Deep Delta Learning](https://arxiv.org/abs/2601.00417)
*Yifan Zhang,Yifeng Liu,Mengdi Wang,Quanquan Gu*

Main category: cs.LG

TL;DR: DDL提出了一种新的深度残差网络架构，通过可学习的几何变换来调制恒等捷径连接，从而增强网络对复杂状态转换的建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统残差网络的恒等捷径连接虽然缓解了梯度消失问题，但强加了严格加性的归纳偏置，限制了网络建模复杂状态转换的能力。

Method: 提出了深度Delta学习（DDL）架构，通过Delta算子（一个可学习的、数据相关的几何变换）来调制恒等捷径连接。该算子是对单位矩阵的秩-1扰动，由反射方向向量k(X)和门控标量β(X)参数化。

Result: 通过谱分析表明，门控β(X)能够在恒等映射、正交投影和几何反射之间进行动态插值。残差更新被重构为同步秩-1注入，门控作为动态步长控制旧信息的擦除和新特征的写入。

Conclusion: DDL统一了残差更新机制，使网络能够显式控制其层间转移算子的谱，从而在保持门控残差架构稳定训练特性的同时，能够建模复杂的非单调动态。

Abstract: The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\mathbf{k}(\mathbf{X})$ and a gating scalar $β(\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.

</details>


### [25] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: 提出E-GRPO方法，通过熵感知的组相对策略优化增强流匹配模型的人类偏好对齐，通过合并低熵步骤为高熵SDE采样步骤，提高探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多个去噪步骤上优化时面临稀疏和模糊的奖励信号问题。观察到高熵步骤能实现更高效有效的探索，而低熵步骤导致无区别的轨迹。

Method: 提出E-GRPO（熵感知组相对策略优化）：1）合并连续低熵步骤形成一个高熵SDE采样步骤，其他步骤使用ODE采样；2）引入多步组归一化优势，在共享相同合并SDE去噪步骤的样本中计算组相对优势。

Result: 在不同奖励设置下的实验结果证明了该方法的有效性。

Conclusion: 通过熵感知的SDE采样步骤合并和组相对优势计算，E-GRPO能够更有效地对齐人类偏好，提高强化学习在流匹配模型中的性能。

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [26] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 大规模评估16种可解释机器学习方法在216个表格数据集上的表现，发现性能与数据集特征密切相关，EBMs在回归任务中表现最佳，不同方法在不同场景下各有优势。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗、金融等高风险领域的广泛应用，模型可解释性和责任性日益重要，但现有研究对表格数据的可解释模型系统性评估不足，主要关注聚合性能而缺乏对数据集特征的深入分析。

Method: 对16种可解释方法（包括线性模型、决策树、EBMs、符号回归、GOSDT等）进行大规模比较评估，涵盖216个真实表格数据集，按维度、样本量、线性度、类别不平衡等结构特征分层分析，并评估训练时间和分布偏移下的鲁棒性。

Result: 结果显示清晰的性能层次结构，EBMs在回归任务中预测准确性最强；性能高度依赖上下文：SR和IGANNs在非线性场景表现优异，GOSDT对类别不平衡敏感；不同方法在不同数据集特征下表现各异。

Conclusion: 研究为实践者在可解释性和预测性能之间寻求平衡提供实用指导，加深了对表格数据可解释建模的实证理解，强调应根据具体数据集特征选择合适方法。

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [27] [A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection](https://arxiv.org/abs/2601.00446)
*Miseon Park,Kijung Yoon*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFMs）作为通用异常检测骨干网络，通过零样本推理、全模型适应和参数高效微调策略，在多个基准测试中超越任务特定基线，特别是在类别不平衡严重时表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法大多需要大量任务特定训练，本文探索时间序列基础模型（在大规模异构数据上预训练）是否能作为通用异常检测骨干网络，实现更高效和可扩展的检测。

Method: 系统实验比较三种策略：零样本推理、全模型适应、参数高效微调（PEFT，包括LoRA、OFT、HRA等方法），在多个基准测试上评估时间序列基础模型的异常检测性能。

Result: 时间序列基础模型在AUC-PR和VUS-PR指标上显著优于任务特定基线，特别是在类别不平衡严重时表现突出；参数高效微调方法不仅降低计算成本，在大多数情况下匹配或超越全微调性能。

Conclusion: 时间序列基础模型可作为有前景的通用模型，实现可扩展且高效的时间序列异常检测，即使预训练用于预测任务也能有效适应异常检测，参数高效微调提供了计算成本与性能的良好平衡。

Abstract: Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.

</details>


### [28] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 提出可控制概念瓶颈模型(CCBMs)，支持概念标签级、概念级和数据级三种粒度的模型编辑，无需重新训练即可实现动态维护。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型(CBMs)主要关注静态场景，而实际应用中需要持续维护：删除错误或敏感数据(遗忘学习)、纠正错误标注的概念、纳入新样本(增量学习)以适应动态环境。如何在不重新训练的情况下实现高效可编辑的CBMs是重要挑战。

Method: 提出可控制概念瓶颈模型(CCBMs)，基于影响函数推导出数学上严格的闭式近似解，支持三种编辑粒度：概念标签级(concept-label-level)、概念级(concept-level)和数据级(data-level，包括数据删除和添加)。

Result: 实验结果表明CCBMs具有高效性和适应性，验证了其在实现动态可信CBMs方面的实用价值。

Conclusion: CCBMs通过数学严谨的闭式近似解实现了无需重新训练的概念瓶颈模型编辑，支持多种粒度操作，为动态可信AI系统提供了实用解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [29] [Imitation from Observations with Trajectory-Level Generative Embeddings](https://arxiv.org/abs/2601.00452)
*Yongtao Qu,Shangzhe Li,Weitong Zhang*

Main category: cs.LG

TL;DR: TGE：一种用于离线观察模仿学习的轨迹级生成嵌入方法，通过扩散模型在潜在空间估计专家状态密度来构建密集平滑的替代奖励，有效处理专家演示稀缺且离线数据与专家行为差异大的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有分布匹配方法在专家演示稀缺、离线次优数据与专家行为差异大的情况下表现不佳，因为它们施加严格的支持约束并依赖脆弱的单步模型，难以从非完美数据中提取有用信号。

Method: 提出TGE方法，在离线轨迹数据上训练时序扩散模型，利用其潜在空间的平滑几何特性构建轨迹级生成嵌入，通过估计专家状态密度来创建密集平滑的替代奖励函数。

Result: 在D4RL运动和控制基准测试中，TGE方法一致匹配或超越了先前的离线观察模仿学习方法，证明了其在处理分布差异数据时的有效性。

Conclusion: TGE通过扩散嵌入的平滑几何特性捕获长期时序动态，有效桥接不相交的支持集，即使在离线数据与专家分布差异大时也能提供稳健的学习信号。

Abstract: We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.

</details>


### [30] [Deep Networks Learn Deep Hierarchical Models](https://arxiv.org/abs/2601.00455)
*Amit Daniely*

Main category: cs.LG

TL;DR: 该论文研究了残差网络中分层SGD如何高效学习层次化标签模型，这类模型超越了先前可学习模型的深度限制，并提出了教师提供的细粒度标签揭示了大脑内部算法的层次结构，从而促进高效学习。


<details>
  <summary>Details</summary>
Motivation: 研究深度学习中高效学习的理论基础，特别是理解为什么深度学习在某些领域表现出色。作者认为人类"教师"提供的细粒度标签暗示了大脑内部算法的层次结构，这种层次结构可能是深度学习成功的关键。

Method: 采用残差网络中的分层随机梯度下降（layerwise SGD）来学习层次化标签模型。模型假设存在未知的标签层次结构 L₁ ⊆ L₂ ⊆ ... ⊆ Lᵣ = [n]，其中简单标签是输入的函数，而复杂标签是简单标签的函数。通过形式化教师部分了解其内部逻辑的简化模型，展示层次结构的出现。

Result: 证明分层SGD在残差网络上能够高效学习需要多项式深度表达的层次模型，这超越了先前只能由对数深度电路计算的模型。达到了高效可学习性的深度极限，即存在需要多项式深度表达的模型，而先前模型只能由对数深度电路计算。

Conclusion: 层次化模型的学习能力可能最终成为理解深度学习的基础。人类教师提供的细粒度标签揭示了大脑内部算法的层次结构，这种结构促进了高效学习。该研究为深度学习在特定领域表现出色提供了理论解释，并建立了教师指导与层次结构学习之间的形式化联系。

Abstract: We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \subseteq L_2 \subseteq \dots \subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.
  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.
  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.

</details>


### [31] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 正交性损失无法有效提升MoE模型的专家多样性，反而增加权重空间重叠，对性能影响不一致且不可靠。


<details>
  <summary>Details</summary>
Motivation: 研究几何正则化在MoE模型专家专业化中的作用，探索正交性损失是否能有效增强专家多样性。

Method: 在MoE模型中应用正交性损失来强制专家多样性，在7种正则化强度下分析权重空间和激活空间的重叠情况。

Result: 正交性损失在多方面失败：权重空间重叠增加114%，激活空间重叠保持高位(~0.6)，性能影响不一致（WikiText-103略改善，TinyStories略下降，PTB结果高度波动），权重与激活正交性无显著相关性(r=-0.293,p=0.523)。

Conclusion: 权重空间正则化既不能实现其几何目标，也不能可靠提升性能，不适合用于MoE多样性增强。

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [32] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 研究者比较了14种机器学习分类器在自动标记小鼠EEG中棘波放电（SWD）的表现，发现1D UNet效果最佳，并通过数据增强进一步改进，最终AugUNet1D在性能上超越了现有的"Twin Peaks"算法。


<details>
  <summary>Details</summary>
Motivation: 手动标记脑电图（EEG）中的事件（特别是棘波放电SWD）非常耗时，尤其是在连续数周至数月的记录中。需要开发自动标记方法来减少人工工作量，尽管已有一些机器学习方法，但仍有改进空间。

Method: 使用961小时C3H/HeJ小鼠EEG记录（包含22,637个标记的SWD）的数据集，比较了14种机器学习分类器的性能。发现1D UNet最佳，然后通过数据增强（特别是缩放增强）改进为AugUNet1D，并与"Twin Peaks"算法进行比较。

Result: 1D UNet在SWD标记任务中表现最佳，数据增强进一步提升了性能，其中缩放增强效果最显著。AugUNet1D在性能上超越了"Twin Peaks"算法，检测到的事件特征更接近人工标记的SWD。

Conclusion: AugUNet1D是自动标记EEG中SWD的有效工具，性能优于现有方法。研究者公开了预训练和未训练的模型供其他用户使用，有助于减少EEG分析中的人工标记工作量。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [33] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 提出一种融合图拉普拉斯与核的多用户上下文赌博机框架，通过统一的多用户再生核希尔伯特空间实现图同质性建模，设计了基于高斯过程后验的算法并提供了理论遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究多用户上下文赌博机问题，用户通过图结构关联，且奖励函数具有非线性特性和图同质性。现有方法未能有效结合图结构信息与非线性建模。

Method: 提出联合惩罚项，结合基于RKHS距离的图平滑项和个体粗糙度惩罚。证明该惩罚等价于单一多用户RKHS中的平方范数，显式推导其再生核，融合图拉普拉斯与基础臂核。基于此设计LK-GP-UCB和LK-GP-TS算法，利用高斯过程后验进行探索。

Result: 理论分析显示遗憾界与多用户核的有效维度相关，而非用户数或环境维度。实验表明在非线性设置中优于强线性基线和无图感知方法，在线性奖励场景中仍保持竞争力。

Conclusion: 该工作提供了一个统一、理论严谨且实用的框架，将拉普拉斯正则化与核化赌博机相结合，实现了结构化探索，为图结构多用户学习问题提供了新思路。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [34] [Neural Chains and Discrete Dynamical Systems](https://arxiv.org/abs/2601.00473)
*Sauro Succi,Abhisek Ganguly,Santosh Ansumali*

Main category: cs.LG

TL;DR: 论文比较了无自注意力Transformer架构（神经链）与离散动力系统的类比，通过Burgers和Eikonal方程对比标准数值离散化与PINN学习方法，发现两者获得相同动力学知识但路径不同：PINN使用随机矩阵而标准方法使用结构化矩阵，导致PINN参数多、训练成本高且缺乏物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索无自注意力Transformer架构（神经链）与离散动力系统之间的类比关系，比较传统数值离散化方法与物理信息神经网络（PINN）在求解偏微分方程方面的差异，分析两者的优缺点和适用场景。

Method: 通过Burgers方程（粘性和非粘性）和Eikonal方程的数值求解进行对比分析：1）标准数值离散化方法（也表述为神经链形式）；2）PINN学习方法。比较两种方法在矩阵结构、参数数量、训练成本等方面的差异。

Result: 标准数值离散化和PINN学习提供了两种不同路径来获取基本相同的系统动力学知识。PINN使用随机矩阵，而标准方法使用高度结构化的三对角矩阵。可接受的随机矩阵数量远多于唯一的三对角形式，这解释了PINN搜索通常落在随机集合中的原因。代价是参数数量大幅增加，导致物理透明度（可解释性）降低和训练成本高昂。

Conclusion: 对于一维动态问题，PINN相比标准数值方法没有明显优势，参数多、训练成本高且缺乏物理可解释性。但研究结果仅限于一维问题，不排除PINN和机器学习在高维问题中可能提供更好的策略。

Abstract: We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.

</details>


### [35] [When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents](https://arxiv.org/abs/2601.00513)
*Laksh Advani*

Main category: cs.LG

TL;DR: 研究发现小型语言模型（7-9B参数）存在严重的推理可靠性危机：50-69%的正确答案包含根本性错误推理，即"正确但推理错误"现象，标准准确率指标无法检测。


<details>
  <summary>Details</summary>
Motivation: 部署小型语言模型作为自主代理需要信任其推理过程，而不仅仅是输出结果。当前标准准确率指标无法揭示模型推理过程中的根本性缺陷，存在"正确但推理错误"的可靠性危机。

Method: 分析了10,734个推理轨迹，涵盖三个模型和多样化任务。引入了推理完整性评分（RIS），这是一个基于过程的指标，具有较高的评分者间一致性（κ=0.657）。研究了检索增强生成（RAG）和元认知干预（如自我批评）对推理完整性的影响，并进行了机制分析。

Result: RAG显著提高推理完整性（Cohen's d=0.23-0.93），减少7.6%的错误；而元认知干预在小型模型上往往损害性能（d=-0.14到-0.33）。开发了神经分类器用于验证，达到0.86 F1分数和100倍加速。

Conclusion: 仅凭准确率评估模型是危险的，因为模型可能基于完全错误的推理得出正确答案。必须采用基于过程的验证方法来确保可信赖的自主代理部署。

Abstract: Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.

</details>


### [36] [Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI](https://arxiv.org/abs/2601.00516)
*Laksh Advani*

Main category: cs.LG

TL;DR: Trajectory Guard：一种用于检测LLM智能体多步行动计划异常的Siamese循环自编码器，通过对比学习和重建的混合损失函数，能同时检测任务轨迹对齐和序列有效性，在多个基准测试中达到0.88-0.94的F1分数，比LLM Judge基线快17-27倍。


<details>
  <summary>Details</summary>
Motivation: 自主LLM智能体生成的多步行动计划可能因上下文不对齐或结构不连贯而失败。现有的异常检测方法不适用于此挑战：均值池化嵌入会稀释异常步骤，而仅对比方法忽略序列结构。标准的无监督方法在预训练嵌入上F1分数不超过0.69。

Method: 提出Trajectory Guard，一种Siamese循环自编码器，具有混合损失函数，通过对比学习联合学习任务轨迹对齐，通过重建学习序列有效性。这种双重目标能够统一检测"错误的任务计划"和"畸形计划结构"。

Result: 在涵盖合成扰动和真实世界失败的基准测试中（包括安全审计RAS-Eval和多智能体系统Who&When），在平衡集上达到0.88-0.94的F1分数，在不平衡外部基准上达到0.86-0.92的召回率。推理延迟32毫秒，比LLM Judge基线快17-27倍。

Conclusion: Trajectory Guard能够实时检测LLM智能体行动计划的异常，包括任务不对齐和结构无效性，在保持高准确性的同时显著提升推理速度，适用于生产部署中的实时安全验证。

Abstract: Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both "wrong plan for this task" and "malformed plan structure." On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.

</details>


### [37] [A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling](https://arxiv.org/abs/2601.00519)
*Dristi Datta,Tanmoy Debnath,Minh Chau,Manoranjan Paul,Gourab Adhikary,Md Geaur Rahman*

Main category: cs.LG

TL;DR: 提出SAFN模型，通过稀疏注意力融合网络整合多模态数据，用于帕金森病异质性表征，在PPMI数据集上达到98%准确率。


<details>
  <summary>Details</summary>
Motivation: 帕金森病具有异质性表现，需要整合生物和临床标志物。现有多模态模型存在可解释性差、类别不平衡、高维特征融合困难等问题。

Method: 提出SAFN模型：使用模态特定编码器处理MRI皮层厚度、体积测量、临床评估和人口统计学数据；采用对称交叉注意力机制捕捉非线性交互；稀疏约束注意力门控层动态选择信息模态；类别平衡焦点损失处理数据不平衡。

Result: 在PPMI数据集703名参与者上，SAFN达到0.98±0.02准确率和1.00±0.00 PR-AUC，优于现有基准模型。可解释性分析显示约60%预测权重分配给临床评估，符合临床诊断原则。

Conclusion: SAFN为神经退行性疾病计算分析提供了可重复、透明的多模态建模范式，具有临床可解释性。

Abstract: Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.

</details>


### [38] [Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study](https://arxiv.org/abs/2601.00525)
*Ravi Teja Pagidoju*

Main category: cs.LG

TL;DR: 通过逐步减少LSTM隐藏单元数量（128到16）进行模型压缩，发现64单元模型在保持精度的同时显著减小模型大小，为中小型零售业提供高效预测方案。


<details>
  <summary>Details</summary>
Motivation: 标准LSTM神经网络在零售业销售预测中虽然准确，但计算资源需求大，对中小型零售企业构成挑战。需要探索在保持预测精度的同时减少模型复杂性的方法。

Method: 采用渐进式LSTM模型压缩方法，将隐藏单元数量从128逐步减少到16。使用Kaggle商店商品需求预测数据集（91.3万条日销售记录，10家商店，50种商品），分析模型大小与预测精度之间的权衡关系。

Result: 实验显示，将LSTM隐藏单元减少到64个时，模型不仅保持相同精度，甚至有所提升。MAPE从128单元模型的23.6%降至64单元模型的12.4%。优化后的模型大小减少73%（从280KB到76KB），精度提高47%。

Conclusion: 更大的模型并不总是带来更好的结果。通过适当的模型压缩，可以在显著减小模型大小的同时提高预测精度，为中小型零售企业提供可行的销售预测解决方案。

Abstract: Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.

</details>


### [39] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了大型模型在联邦学习框架下的定制化方法，首次尝试将prefix-tuning应用于联邦学习环境，验证了其可行性并展示了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 研究大型模型在联邦学习框架下的定制化挑战，探索如何在保护数据隐私的同时实现模型个性化定制，解决联邦学习中模型定制化的技术难题。

Method: 首先综述了多种大型模型定制技术（全微调、高效微调、提示工程、前缀调优、知识蒸馏、检索增强生成），然后重点研究了联邦前缀调优方法，在联邦学习框架下实现prefix-tuning，并与三种其他联邦定制方法进行比较实验。

Result: 联邦前缀调优实验验证了其在联邦学习环境中的可行性，性能接近集中式方法。与其他三种联邦定制方法相比，展示了竞争性性能、令人满意的效率和一致的鲁棒性。

Conclusion: 联邦前缀调优是大型模型在联邦学习框架下有效的定制化方法，为保护数据隐私的同时实现模型个性化提供了可行的技术路径，具有实际应用价值。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [40] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的云原生架构，用于自动生成商店特定的货架图，将设计时间从30小时减少到0.5小时，同时保持94.4%的约束满足率。


<details>
  <summary>Details</summary>
Motivation: 传统货架图创建过程耗时且昂贵，平均每个复杂布局需要30小时。零售业需要更高效的自动化解决方案来优化空间利用和降低成本。

Method: 采用云原生架构，结合AWS进行云端模型训练和边缘部署进行实时推理。使用扩散模型学习多个零售地点的成功货架布局，并通过修改损失函数集成零售特定约束。

Result: 系统将货架图设计时间减少98.3%（从30小时到0.5小时），达到94.4%的约束满足率。经济分析显示创建费用减少97.5%，投资回收期为4.4个月。架构可线性扩展，支持多达10,000个并发商店请求。

Conclusion: 这项工作证明了生成式AI在自动化零售空间优化中的可行性，为零售业提供了高效、可扩展的货架图生成解决方案。

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [41] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 提出基于熵的再训练框架，将数据漂移建模为概率流，通过熵平衡分解触发再训练，在保持预测性能的同时大幅减少再训练次数


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在非平稳环境中部署时，由于数据漂移导致性能下降。现有的漂移检测方法大多缺乏原理性的动力学解释，且无法指导如何平衡再训练频率与运营成本

Method: 基于非平衡随机动力学，将部署时的数据漂移建模为福克-普朗克方程控制的概率流，使用随时间演化的KL散度量模型-数据不匹配，通过熵平衡分解得到非负的熵产生项，以此触发无标签的再训练策略

Result: 在受控的非平稳分类实验中，基于熵触发的再训练实现了与高频再训练相当的预测性能，同时相对于每日和基于标签的策略，将再训练事件减少了一个数量级

Conclusion: 基于熵的再训练框架为数据漂移提供了原理性的动力学解释，通过响应累积的不匹配而非延迟的性能崩溃，实现了高效的再训练策略，在保持性能的同时显著降低运营成本

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [42] [Adversarial Samples Are Not Created Equal](https://arxiv.org/abs/2601.00577)
*Jennifer Crawford,Amol Khanna,Fred Lu,Amy R. Wagoner,Stella Biderman,Andre T. Nguyen,Edward Raff*

Main category: cs.LG

TL;DR: 论文提出需要区分两种对抗性弱点：利用非鲁棒特征的攻击和不利用这些特征的攻击，并提出了衡量非鲁棒特征操纵的集成度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有非鲁棒特征理论虽然被广泛接受，但忽略了不直接利用这些特征的对抗样本。作者认为这两种样本代表了不同类型的对抗性弱点，需要区分评估对抗鲁棒性。

Method: 提出基于集成的度量方法来衡量对抗扰动对非鲁棒特征的操纵程度，并用该度量分析攻击生成的对抗样本构成。

Result: 通过新度量方法能够区分不同类型的对抗弱点，并重新审视多个现象，包括锐度感知最小化对对抗鲁棒性的影响，以及在鲁棒数据集上对抗训练与标准训练之间的鲁棒性差距。

Conclusion: 需要区分两种对抗性弱点类型，提出的度量方法为更精细地评估对抗鲁棒性提供了新视角，有助于深入理解对抗训练等现象。

Abstract: Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.

</details>


### [43] [Learning to be Reproducible: Custom Loss Design for Robust Neural Networks](https://arxiv.org/abs/2601.00578)
*Waqas Ahmed,Sheeba Samuel,Kevin Coakley,Birgitta Koenig-Ries,Odd Erik Gundersen*

Main category: cs.LG

TL;DR: 提出自定义损失函数(CLF)来减少训练结果对随机因素的敏感性，提高深度学习模型的稳定性和可靠性


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法缺乏确保跨运行一致性和鲁棒性的机制，即使控制初始化和训练条件，模型准确率仍存在显著变异性，影响模型的可复现性和可靠性

Method: 提出自定义损失函数(CLF)，通过调整其参数来平衡预测准确率和训练稳定性，减少对权重初始化和数据洗牌等随机因素的敏感性

Result: 在图像分类和时间序列预测的多种架构上进行广泛实验，证明CLF能显著提高训练鲁棒性而不牺牲预测性能

Conclusion: CLF是开发更稳定、可靠和可信赖神经网络的有效且高效策略

Abstract: To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.

</details>


### [44] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: HFedMoE是一个面向异构设备的MoE联邦学习框架，通过专家重要性评估和自适应选择，在资源受限设备上实现高效的大语言模型微调。


<details>
  <summary>Details</summary>
Motivation: 虽然联邦学习可以保护数据隐私，但大语言模型在资源受限设备上训练不现实。MoE模型通过稀疏激活专家来降低计算负担，但在联邦学习环境中面临三个关键挑战：1) 缺乏可靠指标衡量专家对本地性能的影响；2) 异构计算资源限制；3) 客户端特定专家子集和路由偏好破坏全局聚合。

Method: 提出HFedMoE框架：1) 基于专家对微调性能的贡献评估专家重要性；2) 从信息瓶颈角度自适应选择专家子集以匹配客户端计算预算；3) 设计稀疏感知模型聚合策略，通过重要性加权贡献聚合活跃专家和门控参数。

Result: 大量实验表明，HFedMoE在训练准确率和收敛速度方面优于现有最先进的基准方法。

Conclusion: HFedMoE有效解决了MoE在联邦学习环境中的关键挑战，为资源受限设备上的大语言模型微调提供了高效解决方案。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [45] [Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load](https://arxiv.org/abs/2601.00604)
*Francisco Aguilera Moreno*

Main category: cs.LG

TL;DR: 使用机器学习预测自行车骑行时长，结合路线拓扑特征和运动员当前体能状态，相比传统物理模型更实用


<details>
  <summary>Details</summary>
Motivation: 现有基于物理模型的骑行时长预测方法需要大量参数（如空气阻力系数、实时风速预测），对业余骑手不实用，需要更简单有效的解决方案

Method: 采用机器学习方法，使用路线拓扑特征和运动员当前体能状态（从训练负荷指标推导），通过历史数据学习运动员特定的表现模式，用历史表现代理替代复杂的物理测量

Result: 在单人数据集（N=96次骑行）的N-of-1研究设计中，Lasso回归结合拓扑+体能特征达到MAE=6.60分钟和R2=0.922，整合体能指标（CTL, ATL）比仅使用拓扑特征减少14%误差

Conclusion: 机器学习方法能有效预测骑行时长，生理状态对表现有显著约束作用，渐进检查点预测支持动态比赛规划

Abstract: Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.

</details>


### [46] [Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning](https://arxiv.org/abs/2601.00607)
*Sonia Khetarpaul,P Y Sharan*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图神经网络和强化学习的交通感知出租车热点预测框架，通过整合实时交通数据和历史需求，优化出租车部署，在模拟实验中减少了56%的乘客等待时间和38%的行驶距离。


<details>
  <summary>Details</summary>
Motivation: 传统出租车热点预测模型仅依赖历史需求数据，忽略了交通拥堵、道路事故和公共事件等动态影响因素，无法实现智能城市交通中出租车供需的高效匹配。

Method: 将城市道路网络建模为图结构（节点为交叉口，边为路段），整合历史需求、事件邻近度和实时拥堵评分。使用图神经网络编码时空依赖关系，结合Q-learning智能体推荐最优出租车热点位置，奖励机制联合优化乘客等待时间、司机行驶距离和拥堵避免。

Result: 在基于德里真实地理边界和历史叫车模式生成的模拟数据集上，该模型相比基线随机选择方法减少了约56%的乘客等待时间和38%的行驶距离。

Conclusion: 该交通感知的图强化学习框架能有效优化出租车部署，可适应多模态交通系统，并集成到智能城市平台中实现实时城市移动性优化。

Abstract: In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.

</details>


### [47] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出了一种用于在向下封闭凸体上最大化非负、非单调γ-弱DR-次模函数的近似算法，其保证随γ平滑变化，在γ=1时恢复0.401近似比，在γ<1时性能优雅下降并优于先前结果。


<details>
  <summary>Details</summary>
Motivation: 在机器学习和优化中，约束下的次模目标最大化是一个基本问题。现有研究主要关注DR-次模函数（γ=1），但对于更一般的γ-弱DR-次模函数（γ<1）在向下封闭凸体上的非单调最大化问题，缺乏有效的近似算法。

Method: 结合Frank-Wolfe引导的连续贪婪框架与γ感知的双贪婪步骤，提出了一种简单而有效的处理非单调性的方法。该方法通过γ-aware double-greedy步骤来适应函数的弱次模性程度。

Result: 算法提供了平滑依赖于γ的近似保证：当γ=1时恢复0.401近似比，当γ<1时性能优雅下降，并且在相同约束下改进了先前报告的γ-弱DR-次模最大化边界，达到了该问题的最先进保证。

Conclusion: 该方法为在向下封闭凸体上最大化非单调γ-弱DR-次模函数提供了有效的近似算法，其性能保证随γ平滑变化，在γ=1时达到经典结果，在γ<1时优于现有方法，是该问题的最先进解决方案。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [48] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: YapBench是一个轻量级基准测试，用于量化LLM在需要简洁回答的提示上的过度生成问题，通过测量超出最小必要答案的字符数来评估模型冗余度。


<details>
  <summary>Details</summary>
Motivation: 当前LLM（如ChatGPT、Claude、Gemini）作为通用助手时，经常对简单请求给出不必要的冗长回答，包含冗余解释、模棱两可的表述或模板化内容，这会增加认知负担和推理成本。先前研究表明基于偏好的后训练和LLM评估可能导致系统性长度偏差，即使质量相当，更长的回答也更容易获得奖励。

Method: 提出YapBench基准测试，包含300多个英文提示，涵盖三种需要简洁回答的场景：1) 最小或模糊输入，理想行为是简短澄清；2) 封闭式事实问题，有简短稳定答案；3) 单行编码任务，单个命令或代码片段即可。主要指标YapScore测量响应超出基准答案的字符数，YapIndex是类别级别中位数YapScore的均匀加权平均值。

Result: 评估76个助手LLM，发现中位数超额长度存在数量级差异，并观察到特定类别的失败模式：在模糊输入上填充真空内容，在单行技术请求上添加解释或格式化开销。

Conclusion: YapBench为量化LLM过度生成问题提供了标准化评估框架，揭示了不同模型在简洁性方面的显著差异和特定失败模式，有助于跟踪模型简洁性随时间的变化。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [49] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: IGBO框架通过双目标优化训练可解释模型，利用DAG编码特征重要性层次结构，使用TIG测量特征重要性，并提出最优路径预言机解决OOD问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释模型训练方法缺乏对结构化领域知识的有效整合，且特征重要性测量中的OOD问题影响模型可靠性和解释性。

Method: 1) 将特征重要性层次编码为DAG；2) 使用TIG测量特征重要性；3) 提出最优路径预言机解决TIG计算中的OOD问题；4) 采用双目标优化框架平衡模型准确性和可解释性约束。

Result: 理论分析证明收敛性和对mini-batch噪声的鲁棒性；在时间序列数据上的实验表明，IGBO能有效实施DAG约束且精度损失最小，优于标准正则化基线方法。

Conclusion: IGBO为训练具有结构化领域知识约束的可解释模型提供了有效框架，在保持模型性能的同时增强了可解释性，为解决特征重要性测量中的OOD问题提供了新思路。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [50] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 提出Avatar Forcing框架，通过扩散强迫实现实时交互式头像生成，解决现有模型缺乏情感互动的问题，实现低延迟（约500ms）和表达性反应


<details>
  <summary>Details</summary>
Motivation: 当前说话头生成模型缺乏真正的交互式沟通感，通常生成单向响应而缺乏情感参与。需要解决两个关键挑战：在因果约束下实时生成运动，以及无需额外标注数据学习表达性反应

Method: 提出Avatar Forcing框架，通过扩散强迫建模实时用户-头像交互，处理多模态输入（音频和动作）。引入直接偏好优化方法，利用丢弃用户条件构建的合成负样本，实现无标签的表达性交互学习

Result: 框架实现低延迟实时交互（约500ms），相比基线加速6.8倍，生成的反应性和表达性头像运动在80%的情况下优于基线

Conclusion: Avatar Forcing框架成功解决了交互式头像生成的关键挑战，实现了实时、低延迟、表达性强的虚拟沟通体验，为真正交互式虚拟交流提供了有效解决方案

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [51] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: IRPO是一种新的强化学习框架，通过将Bradley-Terry模型集成到GRPO中，用点式评分替代成对比较，解决了生成奖励模型在RL训练中的计算瓶颈问题，在保持可解释性的同时实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 生成奖励模型(GRMs)因其可解释性、推理时扩展性和通过强化学习进行优化的潜力而受到关注。但广泛使用的成对GRMs在与GRPO等RL算法集成时存在计算瓶颈：1) 获取相对分数的成对比较需要O(n²)时间复杂度；2) 重复采样或额外思维链推理带来的计算开销。

Method: 提出了Intergroup Relative Preference Optimization (IRPO)框架，将Bradley-Terry模型集成到GRPO中。该方法为每个响应生成点式评分，从而在RL训练期间能够高效评估任意数量的候选响应，同时保持可解释性和细粒度奖励信号。

Result: IRPO在多个基准测试中实现了点式GRMs中的最先进性能，性能与当前领先的成对GRMs相当。更重要的是，在后训练评估中，IRPO显著优于成对GRMs。

Conclusion: IRPO通过点式评分方法有效解决了成对GRMs的计算瓶颈问题，在保持可解释性和细粒度奖励信号的同时，实现了高效且高性能的强化学习训练，为生成奖励模型的实用化提供了有前景的解决方案。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [52] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR：面向电信领域票务故障排除的端到端系统，集成分类、检索和生成任务，显著提升故障排除效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 电信领域的票务故障排除高度复杂且耗时，需要专家解读票务内容、查阅文档和搜索历史记录，这种人工密集型方法不仅延迟问题解决，还阻碍整体运营效率。

Method: 提出TeleDoCTR系统，集成领域特定的排序和生成模型，自动化故障排除工作流程的三个关键步骤：票务分类到专家团队、检索上下文和语义相似的历史票务、生成详细的故障分析报告。

Result: 在真实电信基础设施数据集上评估，TeleDoCTR优于现有最先进方法，显著提升了故障排除过程的准确性和效率。

Conclusion: TeleDoCTR为电信领域提供了一种有效的端到端票务故障排除解决方案，通过自动化关键步骤提高了操作效率。

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [53] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE框架通过集成群体探索层增强策略梯度方法，在复杂任务和非平稳奖励下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 强化学习中的有效探索仍然是一个关键挑战，特别是在非平稳奖励或高维策略的情况下。现有方法在复杂任务中探索不足，需要更有效的探索机制。

Method: ARISE是一个轻量级框架，在标准策略梯度方法基础上增加紧凑的群体探索层。它将策略动作与粒子驱动提议相结合，每个粒子代表动作空间中采样的候选策略轨迹，并使用奖励方差线索自适应调节探索。

Result: 在简单基准上只有轻微改进（CartPole-v1 +0.7%），但在挑战性任务上获得显著提升：LunarLander-v3 +46%，Hopper-v4 +22%，同时在Walker2d和Ant上保持稳定。在非平稳奖励变化下，ARISE提供明显鲁棒性优势，在CartPole上比PPO高出75分，LunarLander也有相应改进。消融研究证实群体组件和自适应机制都对性能有贡献。

Conclusion: ARISE提供了一种简单、架构无关的途径，在不改变核心算法结构的情况下，创建更具探索性和鲁棒性的RL智能体。

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [54] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 提出贝叶斯逆博弈框架，通过结构化变分自编码器学习智能体目标的先验和后验分布，相比最大似然估计能量化不确定性并提升下游决策安全性


<details>
  <summary>Details</summary>
Motivation: 现有逆博弈方法仅提供点估计，无法量化估计不确定性，导致下游规划决策可能过度自信地采取不安全行动。需要一种能处理多模态观测数据并实时生成后验分布的方法

Method: 提出贝叶斯逆博弈框架，使用结构化变分自编码器嵌入可微纳什博弈求解器，在交互数据集上训练，无需智能体真实目标的标签。支持多模态推理，当轨迹信息不足时可利用额外观测模态

Result: 框架成功学习先验和后验分布，相比基于最大似然估计的逆博弈方法提升推理质量，实现更安全的下游决策而不牺牲效率。多模态推理在轨迹信息不足时进一步减少不确定性

Conclusion: 贝叶斯逆博弈方法能有效量化不确定性，提升自主决策安全性，特别是在观测信息有限的情况下，多模态推理能显著降低不确定性，为实际部署提供更可靠的逆博弈解决方案

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [55] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 提出BSAT方法，使用B样条自适应分词器解决长时序预测中自注意力二次复杂度和均匀分块不匹配问题，结合混合位置编码L-RoPE，在内存受限场景下实现高压缩率下的强性能。


<details>
  <summary>Details</summary>
Motivation: 传统transformer在长时序预测中存在两个主要问题：1) 自注意力的二次复杂度计算开销大；2) 均匀分块方式可能与数据的语义结构不匹配。需要一种既能降低复杂度又能自适应数据结构的解决方案。

Method: 提出B样条自适应分词器(BSAT)，通过B样条拟合时间序列实现自适应分段：在高曲率区域放置token，将变长基函数表示为固定大小token（包含系数和位置）。同时提出混合位置编码L-RoPE，结合可学习的加性位置编码和层间可学习基数的旋转位置嵌入。

Result: 在多个公开基准测试中，模型表现出色，在高压缩率下仍保持强大性能，特别适合内存受限的应用场景。

Conclusion: BSAT方法有效解决了长时序预测中的计算复杂度和数据结构匹配问题，通过自适应分词和混合位置编码实现了高效且性能优异的时序预测模型。

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [56] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应精度调优框架，用于线性求解器，可扩展到一般算法。通过上下文多臂老虎机问题，使用离散状态空间和增量动作价值估计选择最优精度配置，平衡精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 科学计算中混合精度方法需要平衡计算精度和效率，传统方法缺乏自适应能力。本文旨在开发一个强化学习框架，能够动态选择计算步骤的精度配置，减少计算成本同时保持精度。

Method: 将精度调优建模为上下文多臂老虎机问题，使用离散化状态空间和增量动作价值估计。构建Q表映射离散化特征（如近似条件数和矩阵范数）到动作（特定步骤的精度配置），通过epsilon-greedy策略优化，最大化平衡精度和计算成本的多目标奖励。

Result: 在线性系统迭代求精应用中，该框架能有效选择精度，减少计算成本同时保持与双精度基线相当的精度。框架能泛化到多样化的未见数据集，验证了强化学习精度调优的有效性。

Conclusion: 这是首个使用强化学习进行精度自动调优并验证于未见数据集的工作，为科学计算中的混合精度数值方法提供了新思路，可扩展到其他数值算法。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [57] [Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty](https://arxiv.org/abs/2601.00737)
*Uğurcan Özalp*

Main category: cs.LG

TL;DR: STAC算法通过分布评论家建模时序回报的不确定性，引入悲观偏差缓解价值高估，在随机环境中实现风险规避行为


<details>
  <summary>Details</summary>
Motivation: 离策略演员-评论家方法中评论家网络倾向于系统性地高估价值估计，现有方法使用集成量化认知不确定性来引入悲观偏差，但存在计算效率问题

Method: 提出STAC算法，利用单一分布评论家网络建模时序（一步）偶然不确定性（来自随机转移、奖励和策略引起的贝尔曼目标变异性），在时序差分更新中引入悲观偏差，同时对评论家和演员网络应用dropout进行正则化

Result: 基于分布评论家的悲观偏差足以缓解高估问题，在随机环境中自然产生风险规避行为，dropout进一步提高了训练稳定性和性能，使用单一分布评论家网络提升了计算效率

Conclusion: STAC通过建模时序偶然不确定性而非认知不确定性来引入悲观偏差，在保持计算效率的同时有效缓解价值高估问题，在随机环境中实现更好的性能

Abstract: Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.

</details>


### [58] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文提出Distributional Creative Reasoning (DCR)框架，分析当前LLM推理循环中多样性衰减问题，并提供保持正确性和创造性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理管道依赖自举推理循环，主要优化正确性，但会导致推理路径分布崩溃，降低语义熵并削弱创造性问题解决能力。

Method: 引入Distributional Creative Reasoning (DCR)框架，将训练视为通过解决方案轨迹概率测度的梯度流，统一了STaR、GRPO、DPO等多种方法。

Result: 1) 提出多样性衰减定理，描述基于正确性的目标如何导致不同方法的多样性衰减；2) 设计确保收敛到稳定多样策略的方法；3) 提供简单实用的实现方案。

Conclusion: DCR为LLM提供了首个保持正确性和创造性的原则性方案，解决了当前推理管道中的分布崩溃问题。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [59] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 提出基于协变量依赖隐马尔可夫模型(CDHMM)的足球角球防守评估框架，通过追踪数据推断盯人与区域防守任务，实现无标签的防守贡献评估和反事实分析。


<details>
  <summary>Details</summary>
Motivation: 传统足球防守评估指标难以捕捉无球防守的协调移动，现有价值模型主要评估有球动作，反事实方法缺乏战术上下文。角球作为高度结构化的比赛场景，需要更精确的防守评估方法。

Method: 使用协变量依赖隐马尔可夫模型(CDHMM)从球员追踪数据中推断时间分辨的盯人和区域防守任务分配，无需人工标注。基于此提出防守贡献归因框架和角色条件幽灵模型进行反事实分析。

Result: 模型能够从追踪数据中准确推断防守任务分配，提供可解释的防守贡献评估，相比传统平均行为模拟方法，能更好地结合战术上下文进行反事实分析。

Conclusion: CDHMM框架为足球角球防守提供了有效的无标签评估方法，通过角色条件反事实分析实现了对无球防守表现的更准确评估，为防守战术分析提供了新工具。

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


### [60] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: MBC提出了一种通过码本优化策略压缩记忆库的持续学习方法，结合在线重置机制防止码本崩溃，并使用KV-LoRA高效利用压缩记忆，在保持高准确率的同时将记忆库大小减少到基准方法的0.3%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识容易过时，持续学习需要更新模型而不遗忘旧知识。现有记忆增强方法虽然有效，但记忆库会随着数据流不断增长，导致存储和计算成本过高。

Method: 提出MBC模型：1) 通过码本优化策略压缩记忆库；2) 引入在线重置机制防止码本崩溃；3) 在注意力层使用Key-Value低秩适应(KV-LoRA)来高效利用压缩记忆表示。

Result: 在基准问答数据集上的实验表明，MBC将记忆库大小减少到最竞争基线的0.3%，同时在在线适应学习中保持高保留准确率。

Conclusion: MBC通过记忆库压缩和稳定学习机制，有效解决了持续学习中记忆库无限增长的问题，实现了高效且稳定的在线适应学习。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [61] [Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781)
*Samson Gourevitch,Alain Durmus,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.LG

TL;DR: 提出一种基于扩散的软重参数化方法，用于处理分类变量的梯度优化问题，通过高斯加噪过程的去噪器实现训练自由的扩散采样器。


<details>
  <summary>Details</summary>
Motivation: 传统的分类变量梯度优化方法存在局限性：基于分数函数的估计器虽然无偏但噪声大，而连续松弛方法虽然能获得路径梯度但优化的是有偏的温度依赖目标。需要一种更好的方法来处理分类变量的优化问题。

Method: 提出扩散基软重参数化方法，利用高斯加噪过程对分类分布进行处理，其去噪器具有闭式解且计算高效，从而构建训练自由的扩散采样器，支持反向传播。

Result: 实验表明，所提出的重参数化技巧在各种基准测试中取得了竞争性或改进的优化性能。

Conclusion: 扩散基软重参数化为分类分布的梯度优化提供了一种有效的新方法，通过训练自由的扩散采样器实现了更好的优化性能。

Abstract: Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.

</details>


### [62] [FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing](https://arxiv.org/abs/2601.00785)
*Sunny Gupta,Amit Sethi*

Main category: cs.LG

TL;DR: FedHypeVAE：基于差分隐私和超网络的联邦嵌入级数据合成框架，解决非IID客户端异构性和梯度泄漏问题


<details>
  <summary>Details</summary>
Motivation: 现有联邦数据共享方法在非IID客户端异构性下表现不佳，且对梯度泄漏的正式保护有限。需要一种既能保护隐私又能处理非IID数据分布的嵌入级数据合成方法。

Method: 基于条件VAE架构，用超网络生成客户端感知的解码器和类条件先验，替代单一全局解码器和固定先验。采用差分隐私优化超网络，结合局部MMD对齐和Lipschitz正则化增强稳定性。使用中性元代码实现领域无关合成。

Result: FedHypeVAE在非IID条件下实现了隐私保护的数据合成，通过超网络个性化生成层而非下游模型，将本地数据与通信参数解耦，提供可控的多领域覆盖。

Conclusion: FedHypeVAE在生成器层面统一了个性化、隐私保护和分布对齐，为联邦环境下的隐私保护数据合成建立了理论基础。

Abstract: Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE

</details>


### [63] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需训练的方法，通过注意力矩阵的谱分析检测大语言模型中数学推理的有效性，使用四种谱诊断指标，在多个模型上达到85-95%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要训练数据、微调或学习分类器来检测语言模型中的推理有效性。本文旨在开发一种无需训练的方法，通过分析注意力模式的谱特征来识别数学证明的逻辑一致性。

Method: 将注意力矩阵视为动态图的邻接矩阵，提取四种可解释的谱诊断指标：Fiedler值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵。这些指标在有效和无效数学证明之间表现出统计显著差异。

Result: 在四个独立架构家族的七个Transformer模型上实验，谱特征产生高达Cohen's d=3.30的效应量，实现85.0-95.6%的分类准确率。发现该方法检测逻辑一致性而非编译器接受度，并识别出注意力机制设计影响哪些谱特征捕获推理有效性。

Conclusion: 谱图分析为推理验证提供了一个原则性框架，具有直接应用于幻觉检测和AI安全监控的潜力。该方法无需训练数据、微调或学习分类器，仅需对谱指标设置单一阈值即可实现高准确率。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [64] [On the measurement problem in quantum mechanics: a simple proposal](https://arxiv.org/abs/2601.00010)
*Luigi E. Picasso*

Main category: quant-ph

TL;DR: 该论文探讨量子力学解释中的问题，特别是测量过程和著名悖论，提出"物理实验室假设"作为波函数坍缩假设的替代方案。


<details>
  <summary>Details</summary>
Motivation: 量子力学解释中存在诸多问题，特别是与测量过程相关的悖论和概念困难。传统的波函数坍缩假设存在理论上的问题，需要寻找更合理的替代方案。

Method: 采用"物理实验室假设"，该假设认为只有对应现有测量仪器的自伴算子才能被视为"可观测量"。这种方法避免了引入波函数坍缩的额外假设。

Result: 该假设为量子力学解释问题提供了新的视角，特别是对测量过程和著名悖论的理解，能够替代传统的波函数坍缩假设。

Conclusion: "物理实验室假设"为解决量子力学解释中的核心问题提供了有前景的替代方案，特别是能够避免波函数坍缩假设的理论困难。

Abstract: Some of the problems connected with the interpretation of quantum mechanics are enumerated, in particular those related to some well known paradoxes and, above all, to the measurement process. We then show how the so called "Physics Laboratory Assumption" introduced in [1], which considers as "observables'' only the self-adjoint operators corresponding to existing measuring instruments, can propose a new perspective on the aforementioned problems and can replace the wavefunction collapse postulate.
  [1] Luigi E. Picasso, "On the Concept of State in Quantum Mechanics: Another Way to Decoherence?'' Int. J. Theor. Phys. 62 (2), (2023)

</details>


### [65] [Classical vs quantum dynamics and the onset of chaos in a macrospin system](https://arxiv.org/abs/2601.00062)
*Haowei Fan,Vladimir Fal'ko,Xiao Li*

Main category: quant-ph

TL;DR: 研究具有各向异性长程相互作用和集体耗散的周期性驱动宏观自旋系统，通过最大李雅普诺夫指数分析混沌、准周期和周期相，比较量子与经典动力学在热力学极限下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究周期性驱动宏观自旋系统中量子与经典动力学的对应关系，特别是在热力学极限下，探索混沌行为在量子系统中的表现以及有限尺寸效应的影响。

Method: 使用Lindblad主方程描述系统，在热力学极限下采用平均场处理得到经典运动方程，通过最大李雅普诺夫指数、分岔图和傅里叶谱分析动力学相；同时在Dicke基中进行有限尺寸量子模拟，比较量子与经典动力学。

Result: 识别出混沌、准周期和周期相，包括经典倍周期分岔和吸引子区域的分形边界；量子与经典动力学在Lyapunov时间尺度内收敛，收敛仅当密度矩阵非零元素尖锐局域化时发生；混沌区域中量子演化变得混合并在希尔伯特空间中扩散探索，表现出量子混沌特征。

Conclusion: 量子与经典系统都展现出多样的动力学相，但有限尺寸效应抑制了热力学极限中的某些行为；最大李雅普诺夫指数的符号是量子-经典动力学收敛的关键指标；不收敛并不意味量子与经典动力学存在根本差异，混沌区域中量子演化表现出混合和扩散特征，证实了量子混沌的存在。

Abstract: We study a periodically driven macrospin system with anisotropic long-range interactions and collective dissipation, described by a Lindblad master equation. In the thermodynamic limit ($N\to\infty$), a mean-field treatment yields classical equations of motion, whose dynamics are characterized via the maximal Lyapunov exponent (MLE). Focusing on the thermodynamic limit, we map out chaotic, quasiperiodic, and periodic phases via bifurcation diagrams, MLEs, and Fourier spectra of evolved observables, identifying classic period-doubling bifurcations and fractal boundaries in the regions of attractors. Finite-size quantum simulations in the Dicke basis reveal that while both quantum and classical systems exhibit diverse dynamical phases, finite-size effects suppress some behaviors present in the thermodynamic limit. The sign of $λ_{\mathrm{max}}$ serves as a key indicator of convergence between quantum and classical dynamics, which agree over timescales up to the Lyapunov time. Analysis of the density matrix shows that convergence occurs only when its nonzero elements are sharply localized. However, the nonconvergence does not imply a fundamental difference between quantum and classical dynamics: in chaotic regimes, although the evolution orbits of quantum and classical systems show significant differences, quantum evolution becomes mixed and diffusively explores the Hilbert space, signaling quantum chaos, which can be confirmed by the delocalized nature of the density matrix.

</details>


### [66] [Pauli stabilizer formalism for topological quantum field theories and generalized statistics](https://arxiv.org/abs/2601.00064)
*Yitao Feng,Hanyu Xue,Ryohei Kobayashi,Po-Shen Hsin,Yu-An Chen*

Main category: quant-ph

TL;DR: 本文构建了新的晶格规范理论作为Pauli稳定子模型，实现了多种拓扑量子场论，并系统研究了扩展激发的广义统计性质。


<details>
  <summary>Details</summary>
Motivation: 拓扑量子场论在描述拓扑物态和构建量子纠错码中起核心作用，但如何在晶格上表述拓扑序并从微观哈密顿量提取拓扑激发性质是一个关键挑战。

Method: 构建Pauli稳定子模型作为晶格规范理论，通过凝聚(4+1)D ℤ₄环面码中的e²m²环得到费米子环环面码，并开发基于Pauli的框架来定义任意维度的扩展激发的广义统计。

Result: 实现了(4+1)D中所有扭曲2-形式规范理论（由H⁵(B²G,U(1))分类的高阶形式Dijkgraaf-Witten TQFT），展示了环激发具有费米子环统计性质，并构造了新的ℤ₂拓扑序家族。

Conclusion: 该工作提供了在晶格上系统研究拓扑序和扩展激发统计性质的通用框架，为理解高维拓扑相和开发量子纠错码提供了新工具。

Abstract: Topological quantum field theory (TQFT) provides a unifying framework for describing topological phases of matter and for constructing quantum error-correcting codes, playing a central role across high-energy physics, condensed matter, and quantum information. A central challenge is to formulate topological order on the lattice and to extract the properties of topological excitations from microscopic Hamiltonians. In this work, we construct new classes of lattice gauge theories as Pauli stabilizer models, realizing a wide range of TQFTs in general spacetime dimensions. We develop a lattice description of the resulting extended excitations and systematically determine their generalized statistics.
  Our main example is the $(4+1)$D \emph{fermionic-loop toric code}, obtained by condensing the $e^2 m^2$-loop in the $(4+1)$D $\mathbb{Z}_4$ toric code. We show that the loop excitation exhibits fermionic loop statistics: the 24-step loop-flipping process yields a phase of $-1$. Our Pauli stabilizer models realize all twisted 2-form gauge theories in $(4+1)$D, the higher-form Dijkgraaf-Witten TQFT classified by $H^{5}(B^{2}G, U(1))$. % Beyond $(4+1)$D, the fermionic-loop toric codes form a family of $\mathbb{Z}_2$ topological orders in arbitrary dimensions featuring fermionic loop excitations, realized as explicit Pauli stabilizer codes using $\mathbb{Z}_4$ qudits. % Finally, we develop a Pauli-based framework that defines generalized statistics for extended excitations in any dimension, yielding computable lattice unitary processes to detect nontrivial generalized statistics. For example, we propose anyonic membrane statistics in $(6+1)$D, as well as fermionic membrane and volume statistics in arbitrary dimensions. We construct new families of $\mathbb{Z}_2$ topological orders: the \emph{fermionic-membrane toric code} and the \emph{fermionic-volume toric code}.

</details>


### [67] [Detection Efficiency Bounds in (Semi-)Device-Independent Scenarios](https://arxiv.org/abs/2601.00077)
*Tailan S. Sarubi,Santiago Zamora,Moisés Alves,Vinícius F. Alves,Gandhi Viswanathan,Rafael Chaves*

Main category: quant-ph

TL;DR: 本文全面综述了检测效率在各种设备无关和半设备无关场景中证明非经典性的关键作用，重点分析了检测漏洞问题及其在不同因果结构中的效率要求。


<details>
  <summary>Details</summary>
Motivation: 检测效率在证明量子非经典性中至关重要，因为不完美的探测器可能导致经典隐变量模型模拟量子关联，从而掩盖真正的非经典性。本文旨在系统分析不同场景下的效率要求，帮助理解检测漏洞对量子验证的影响。

Method: 作为综述文章，本文回顾了贝尔场景中的效率要求（如CHSH不等式的2/3对称效率阈值），并扩展到其他因果结构：仪器场景、准备-测量场景和双局域性场景，分析效率要求如何在不同上下文中变化。

Result: 分析表明：1）仪器场景的二元变量与二分贝尔场景有相同的效率界限；2）准备-测量场景中，低效率影响量子系统维度认证并导致QKD安全漏洞；3）双局域性场景中，使用多个独立源可显著放宽认证非经典关联所需的效率要求。

Conclusion: 检测效率是证明量子非经典性的关键因素，不同因果结构对效率要求不同。理解这些要求对于设计可靠的量子验证实验和协议至关重要，特别是在设备无关和半设备无关场景中。

Abstract: This article provides a comprehensive review of the critical role of detection efficiency in demonstrating non-classicality across various device-independent and semi-device-independent scenarios. The central focus is the detection loophole, a challenge in which imperfect detectors can allow classical hidden variable models to mimic quantum correlations, thus masking genuine non-classicality. As a review, the article revisits the paradigmatic Bell scenario, detailing the efficiency requirements for the CHSH inequality, such as the 2/3 threshold for symmetric efficiencies, and traces the historical trajectory toward the first loophole-free tests. The analysis extends to other causal structures to explore how efficiency requirements are affected in different contexts. These include the instrumental scenario, which for binary variables has recently been shown to follow the same inefficiency bounds as the bipartite dichotomic Bell scenario; the prepare-and-measure scenario, where inefficiencies impact the certification of a quantum system's dimension and create security breaches in protocols such as Quantum Key Distribution (QKD); and the bilocality scenario, which exemplifies how employing multiple independent sources can significantly relax the required efficiencies to certify non-classical correlations.

</details>


### [68] [Double-Pumped Kerr Parametric Amplifier Beyond the Gain-Bandwidth Limit](https://arxiv.org/abs/2601.00078)
*Nicolas Zapata,Najmeh Etehadi Abari,Mitchell Field,Patrick Winkel,Simon Geisert,Soeren Ihssen,Anja Metelmann,Ioan M. Pop*

Main category: quant-ph

TL;DR: 提出一种新型超导参量放大器，通过双驱动实现无失稳的参量放大，显著提升带宽性能


<details>
  <summary>Details</summary>
Motivation: 传统超导参量放大器需要在接近失稳点工作，这导致增益增加时瞬时带宽减小，限制了实际应用性能

Method: 采用双驱动方案，同时激活相位保持增益和频率转换，在具有Kerr非线性的铝颗粒二聚体结构中实现

Result: 在20dB增益下带宽提升6倍，在25dB以下增益范围内超越传统增益-带宽缩放关系，且接近量子极限

Conclusion: 双驱动无失稳参量放大方法突破了传统增益-带宽限制，为微波量子器件读出提供了更优解决方案

Abstract: Superconducting standing$-$wave parametric amplifiers are crucial for the readout of microwave quantum devices. Despite significant improvements in recent years, the need to operate near an instability point imposes a fundamental constraint: the instantaneous bandwidth decreases with increasing amplifier gain. Here we show that it is possible to obtain parametric amplification without instability by using two simultaneous drives that activate phase-preserving gain and frequency conversion. Realized in a granular aluminum dimer with Kerr nonlinearity, our method demonstrates a sixfold bandwidth increase at 20 dB gain, surpasses the conventional gain$-$bandwidth scaling up to 25 dB, and remains near the quantum limit.

</details>


### [69] [A compellingly simple proof of the speed of sound for interacting bosons](https://arxiv.org/abs/2601.00111)
*J. Eisert*

Main category: quant-ph

TL;DR: 该论文证明了广义Bose-Hubbard模型中粒子传播存在有限声速的简单界


<details>
  <summary>Details</summary>
Motivation: 长期以来，人们一直不清楚相互作用玻色子系统是否在信息和粒子传播中也具有有限的声速。虽然Lieb-Robinson边界已经为有限维系统的局部相互作用哈密顿量证明了有限群速度的存在，但对于玻色子系统这个问题直到最近才得到解决。

Method: 通过几行基本但非平凡的推导，为定义在一般晶格上的广义Bose-Hubbard模型证明了粒子传播的简单边界。该方法适用于适当局部扰动的稳态。

Result: 证明了广义Bose-Hubbard模型中粒子数传播具有有限声速，即适当局部扰动的稳态在粒子数传播方面表现出有限的声速。

Conclusion: 该工作为玻色子系统中的粒子传播提供了简单而严格的有限声速证明，解决了长期存在的开放性问题，并表明玻色子系统也遵循类似Lieb-Robinson边界的因果性约束。

Abstract: On physical grounds, one expects locally interacting quantum many-body systems to feature a finite group velocity. This intuition is rigorously underpinned by Lieb-Robinson bounds that state that locally interacting Hamiltonians with finite-dimensional constituents on suitably regular lattices always exhibit such a finite group velocity. This also implies that causality is always respected by the dynamics of quantum lattice models. It had been a long-standing open question whether interacting bosonic systems also feature finite speeds of sound in information and particle propagation, which was only recently resolved. This work proves a strikingly simple such bound for particle propagation - shown in literally a few elementary, yet not straightforward, lines - for generalized Bose-Hubbard models defined on general lattices, proving that appropriately locally perturbed stationary states feature a finite speed of sound in particle numbers.

</details>


### [70] [(PhD Thesis) The Information Locally Stored in Quantum Fields: From Entanglement to Gravity](https://arxiv.org/abs/2601.00128)
*T. Rick Perche*

Main category: quant-ph

TL;DR: 这是一篇量子场论博士论文的更新版本，涵盖局部量子场论、局部探针、纠缠、相互作用近似和时空几何信息等五个核心主题，旨在为学生提供研究指南。


<details>
  <summary>Details</summary>
Motivation: 作者希望将博士论文内容传播给更广泛的读者群体，特别是为有兴趣研究量子场论相关主题的学生提供系统的指导框架，并寻求潜在的研究合作机会。

Method: 论文采用五章结构：第一章介绍局部量子场论基础；第二章描述局部探针；第三章讨论纠缠及其探测；第四章分析相互作用近似；第五章探讨量子场中的时空几何信息。

Result: 论文系统性地整合了量子场论的多个前沿研究方向，提供了一个完整的研究框架，可作为学生进入这些领域的入门指南和参考资源。

Conclusion: 这篇论文不仅总结了作者在量子场论领域的研究成果，更重要的是为后续研究者提供了清晰的研究路线图，并开放了合作机会，促进了该领域的知识传播和发展。

Abstract: This is an updated version of my PhD thesis, defended at the University of Waterloo on the 2nd of April 2025, uploaded to the ArXiv with the goal of reaching a wider audience. The thesis is divided into 5 chapters, respectively containing (I) a brief introduction to local quantum field theory (QFT), (II) a description of local probes in QFT, (III) a discussion of entanglement in QFT and how to probe it, (IV) a description of the regimes where QFT interactions can be approximated by direct interactions, and (V) a discussion the information about the geometry of spacetime contained in quantum fields. The partial goal of this thesis is to serve as a guide for students aiming to tackle these different research programs. If the reader is interested in pursuing one or more research projects detailed here, they are encouraged to contact me for collaboration in these topics.

</details>


### [71] [Towards a temperature-insensitive composite diamond clock](https://arxiv.org/abs/2601.00157)
*Sean Lourette,Andrey Jarmola,Jabir Chathanathil,Victor M. Acosta,A. Glen Birdwell,Peter Blümler,Dmitry Budker,Sebastián C. Carrasco,Tony G. Ivanov,Shimon Kolkowitz,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 利用NV中心电子自旋分裂D与核四极分裂Q形成复合频率参考，克服温度敏感性，实现稳定室温金刚石时钟


<details>
  <summary>Details</summary>
Motivation: 基于固态自旋的频率参考具有简单、紧凑、鲁棒、多功能等优点，但NV中心的电子零场分裂对温度高度敏感，限制了其作为稳定时钟跃迁的应用

Method: 1) 形成复合频率参考，结合电子分裂D和核四极分裂Q测量；2) 设计八相控制脉冲序列抑制脉冲缺陷；3) 在高密度NV系综中间插测量D和Q

Result: 室温下10天测试显示：复合时钟在τ=200s时分数不稳定性<5×10⁻⁹，τ=2×10⁵s时<1×10⁻⁸，相比纯D时钟分别提升4倍和200倍；温度不再是主要不稳定源

Conclusion: 金刚石中互补的电子和核自旋跃迁为热鲁棒频率计量提供了可行途径，为紧凑、多功能固态时钟和量子传感器开辟了道路

Abstract: Frequency references based on solid state spins promise simplicity, compactness, robustness, multifunctionality, ease of integration, and high densities of emitters. Nitrogen-vacancy (NV) centers in diamond are a natural candidate, but the electronic zero-field splitting exhibits a large fractional temperature dependence, which has precluded its use as a stable clock transition. Here we show that this limitation can be overcome by forming a composite frequency reference that combines measurements of the electronic splitting D with the nuclear quadrupole splitting of the $^{14}$N nuclear spin intrinsic to the NV center. We further benchmark this composite approach against alternative strategies for mitigating temperature sensitivity. By implementing a specially designed pulse sequence with an eight-phase control scheme that suppresses pulse imperfections, we interleave measurements of D and Q in a high-density NV ensemble and demonstrate a temperature-compensated composite frequency reference. The stability of this composite diamond clock is characterized over a 10-day period at room temperature through a comparison to a Rb vapor-cell clock, yielding a fractional instability below $5 \times 10^{-9}$ for an averaging time of $τ= 200$ s and below $1 \times 10^{-8}$ at $τ= 2 \times 10^5$ s, corresponding to measured improvements by a factor of 4 and 200, respectively, over a clock based purely on the single frequency D for the same periods. By characterizing the residual sensitivity to magnetic fields, optical power, and radio-frequency drive amplitudes, we find that temperature is no longer the dominant source of instability. These results establish complementary electron- and nuclear-spin transitions in diamond as a viable route to thermally robust frequency metrology, providing a pathway toward compact, multifunctional solid-state clocks and quantum sensors.

</details>


### [72] [Reversing Heat Flow by Coherence in a Multipartite Quantum System](https://arxiv.org/abs/2601.00198)
*Keyi Huang,Qi Zhang,Xiangjing Liu,Ruiqing Li,Xinyue Long,Hongfeng Liu,Xiangyu Wang,Yu-ang Fan,Yuxuan Zheng,Yufang Feng,Yu Zhou,Jack Ng,Xinfang Nie,Zhong-Xiao Man,Dawei Lu*

Main category: quant-ph

TL;DR: 实验证明多体自旋系统的内部量子相干性可以逆转热流方向，无需依赖系统与环境间的初始关联


<details>
  <summary>Details</summary>
Motivation: 经典热力学第二定律认为热量自发地从高温流向低温，但量子关联可以逆转热流。本研究探索是否仅靠系统内部的量子相干性（而非系统与环境间的关联）也能实现热流逆转

Method: 采用碰撞模型与级联相互作用，在多体自旋系统中实验研究内部量子相干性对热流方向的影响

Result: 实验验证了相干项的强度和相位共同决定能量转移的方向和大小，能够精确控制热流方向

Conclusion: 仅利用局部量子特性（内部量子相干性）就能实现热流逆转，为量子热力学控制提供了新途径

Abstract: The second law of thermodynamics dictates that heat flows spontaneously from a high-temperature entity to a lower-temperature one. Yet, recent advances have demonstrated that quantum correlations between a system and its thermal environment can induce a reversal of heat flow, challenging classical thermodynamic expectations. Here, we experimentally demonstrate that internal quantum coherence in a multipartite spin system can also reverse heat flow, without relying on initial correlations with the environment. Under the collision model with cascade interaction, we verify that both the strength and the phase of the coherence term determine the direction and magnitude of energy transfer. These results enable precise control of heat flow using only local quantum properties.

</details>


### [73] [DC-MBQC: A Distributed Compilation Framework for Measurement-Based Quantum Computing](https://arxiv.org/abs/2601.00214)
*Yecheng Xue,Rui Yang,Zhiding Liang,Tongyang Li*

Main category: quant-ph

TL;DR: 提出了首个针对测量基量子计算（MBQC）的分布式量子编译框架DC-MBQC，解决了MBQC分布式计算中的任务分配和通信调度两大挑战。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算（DQC）在量子电路模型方面已有显著进展，但针对测量基量子计算（MBQC）的研究较少。MBQC是与电路模型本质不同的通用量子计算模型，特别适合光子量子平台，需要专门的分布式编译框架。

Method: 开发了自适应图分割算法来平衡量子处理单元（QPU）间的工作负载并保持图态结构；提出了层调度问题及其解决算法；针对实际硬件需求，优化了量子程序执行时间和所需光子寿命。

Result: 实验表明，在8个全连接QPU下，所需光子寿命提高了7.46倍，执行速度提升了6.82倍，证实了分布式量子计算在光子系统中的优势。

Conclusion: DC-MBQC是首个针对MBQC的分布式量子编译框架，成功解决了任务分配和通信调度问题，显著提升了光子量子系统的性能和可靠性。

Abstract: Distributed quantum computing (DQC) is a promising technique for scaling up quantum systems. While significant progress has been made in DQC for quantum circuit models, there exists much less research on DQC for measurement-based quantum computing (MBQC), which is a universal quantum computing model that is essentially different from the circuit model and particularly well-suited to photonic quantum platforms. In this paper, we propose DC-MBQC, the first distributed quantum compilation framework tailored for MBQC. We identify and address two key challenges in enabling DQC for MBQC. First, for task allocation among quantum processing units (QPUs), we develop an adaptive graph partitioning algorithm that preserves the structure of the graph state while balancing the workload across QPUs. Second, for inter-QPU communication, we introduce the layer scheduling problem and propose an algorithm to solve it. Regrading realistic hardware requirements, we optimize the execution time of running quantum programs and the corresponding required photon lifetime to avoid fatal failures caused by photon loss. Our experiments demonstrate a $7.46\times$ improvement on required photon lifetime and $6.82\times$ speedup with 8 fully-connected QPUs, which further confirm the advantage of distributed quantum computing in photonic systems. The source code is publicly available at https://github.com/qfcwj/DC-MBQC.

</details>


### [74] [Neural Minimum Weight Perfect Matching for Quantum Error Codes](https://arxiv.org/abs/2601.00242)
*Yotam Peled,David Zenati,Eliya Nachmani*

Main category: quant-ph

TL;DR: 提出NMWPM解码器，结合图神经网络和Transformer预测动态边权重，通过代理损失函数实现端到端优化，显著降低逻辑错误率


<details>
  <summary>Details</summary>
Motivation: 量子纠错是实现量子计算潜力的关键，传统MWPM解码器依赖固定边权重，无法充分利用局部症状特征和长程依赖关系，限制了纠错性能

Method: 提出神经最小权重完美匹配解码器，采用混合架构：GNN提取局部症状特征，Transformer捕获长程全局依赖，预测动态边权重供MWPM使用；设计代理损失函数解决MWPM不可微问题，实现端到端训练

Result: 相比标准基线，NMWPM解码器显著降低了逻辑错误率，展示了神经网络预测能力与经典匹配算法结构结合的混合解码器优势

Conclusion: 结合神经网络预测能力和经典匹配算法结构的混合解码器在量子纠错中具有显著优势，为量子计算的实际应用提供了更有效的纠错方案

Abstract: Realizing the full potential of quantum computation requires Quantum Error Correction (QEC). QEC reduces error rates by encoding logical information across redundant physical qubits, enabling errors to be detected and corrected. A common decoder used for this task is Minimum Weight Perfect Matching (MWPM) a graph-based algorithm that relies on edge weights to identify the most likely error chains. In this work, we propose a data-driven decoder named Neural Minimum Weight Perfect Matching (NMWPM). Our decoder utilizes a hybrid architecture that integrates Graph Neural Networks (GNNs) to extract local syndrome features and Transformers to capture long-range global dependencies, which are then used to predict dynamic edge weights for the MWPM decoder. To facilitate training through the non-differentiable MWPM algorithm, we formulate a novel proxy loss function that enables end-to-end optimization. Our findings demonstrate significant performance reduction in the Logical Error Rate (LER) over standard baselines, highlighting the advantage of hybrid decoders that combine the predictive capabilities of neural networks with the algorithmic structure of classical matching.

</details>


### [75] [Efficient implementation of single particle Hamiltonians in exponentially reduced qubit space](https://arxiv.org/abs/2601.00247)
*Martin Plesch,Martin Friák,Ijaz Ahamed Mohammad*

Main category: quant-ph

TL;DR: 提出对数量子比特编码方法，将N个物理位点映射到⌈log₂N⌉个量子比特，结合格雷码测量策略，将变分量子算法的硬件需求从N²降低到(logN)³


<details>
  <summary>Details</summary>
Motivation: 解决当前量子硬件面临的量子比特数量有限、电路深度受限和重复测量成本高的问题，特别是针对固态哈密顿量的模拟

Method: 1) 对数量子比特编码：将N个物理位点映射到⌈log₂N⌉个量子比特；2) 兼容的变分电路设计；3) 基于格雷码的测量策略，测量设置数量随系统规模对数增长；4) 引入体积效率度量，综合评估量子比特数、电路深度和测量设置

Result: 对于硬件高效的ansatz，变分循环所需的总时空采样体积从N²显著降低到(logN)³，实现了量子硬件时间和尺寸的指数级减少

Conclusion: 该方法使得大型结构化固态哈密顿量可以在显著更小的量子寄存器上模拟，具有可控的采样开销和可管理的电路复杂度，扩展了近期量子设备上变分量子算法的应用范围

Abstract: Current and near-term quantum hardware is constrained by limited qubit counts, circuit depth, and the high cost of repeated measurements. We address these challenges for solid state Hamiltonians by introducing a logarithmic-qubit encoding that maps a system with $N$ physical sites onto only $\lceil \log_2 N \rceil$ qubits while maintaining a clear correspondence with the underlying physical model. Within this reduced register, we construct a compatible variational circuit and a Gray-code-inspired measurement strategy whose number of global settings grows only logarithmically with system size. To quantify the overall hardware load, we introduce a volumetric efficiency metric that combines the number of qubit, circuit depth, and the number of measurement settings into a single measure, expressing the overall computation costs. Using this metric, we show that the total space-time-sampling volume required in a variational loop can be reduced dramatically from $N^2$ to $(logN)^3$ for hardware efficient ansatz, allowing an exponential reduction in time and size of the quantum hardware. These results demonstrate that large, structured solid-state Hamiltonians can be simulated on substantially smaller quantum registers with controlled sampling overhead and manageable circuit complexity, extending the reach of variational quantum algorithms on near-term devices.

</details>


### [76] [First appearance of quasiprobability negativity in quantum many-body dynamics](https://arxiv.org/abs/2601.00259)
*Rohit Kumar Shukla,Amikam Levy*

Main category: quant-ph

TL;DR: 该论文引入"首次负性"作为动力学指标，用于检测相互作用量子系统中局部测量序列何时开始表现出真正的非经典行为，并展示了其在伊辛链中的多种应用。


<details>
  <summary>Details</summary>
Motivation: 准概率分布的负性捕捉了量子动力学中无经典对应物的方面，但在多体系统中其动力学涌现尚未得到充分探索。需要一种指标来检测局部测量序列何时开始表现出真正的非经典行为。

Method: 引入Margenau-Hill准概率的"首次负性"作为动力学指标，使用伊辛链模型进行研究，分析FTN在不同参数区域（相互作用主导与场主导）、温度影响、可积性破坏等方面的表现，并比较负性出现时间与量子速度极限。

Result: FTN能清晰区分相互作用主导和场主导区域，受温度系统性重塑，对可积性破坏敏感。在不同位点测量时，FTN揭示了反映算符不相容性在晶格中有限时间传播的特征时空结构。负性出现时间与量子速度极限一致。

Conclusion: 首次负性是一种实用且实验可访问的探针，可用于探测实时量子相干性和上下文性，直接适用于当前能够进行顺序弱测量和强测量的实验平台。

Abstract: Quasiprobability distributions capture aspects of quantum dynamics that have no classical counterpart, yet the dynamical emergence of their negativity in many-body systems remains largely unexplored. We introduce the \emph{first-time negativity} (FTN) of the Margenau-Hill quasiprobability as a dynamical indicator of when local measurement sequences in an interacting quantum system begin to exhibit genuinely nonclassical behavior. Using the Ising chain, we show that FTN discriminates clearly between interaction-dominated and field-dominated regimes, is systematically reshaped by temperature, and responds sensitively to the breaking of integrability. When measurements are performed on different sites, FTN reveals a characteristic spatio-temporal structure that reflects the finite-time spreading of operator incompatibility across the lattice. We further compare the numerical onset of negativity with a recently proposed quantum speed limit (QSL) for quasiprobabilities, which provides a geometric benchmark for the observed dynamics. Our results identify FTN as a practical and experimentally accessible probe of real-time quantum coherence and contextuality, directly suited to current platforms capable of sequential weak and strong measurements.

</details>


### [77] [Nature is stingy: Universality of Scrooge ensembles in quantum many-body systems](https://arxiv.org/abs/2601.00266)
*Wai-Keong Mok,Tobias Haug,Wen Wei Ho,John Preskill*

Main category: quant-ph

TL;DR: 该论文建立了量子多体系统中Scrooge系综出现的统一理论框架，揭示了三种物理机制，并识别了相干性、纠缠、非稳定性和信息混洗作为关键资源。


<details>
  <summary>Details</summary>
Motivation: 量子模拟器的进展使得能够直接实验访问测量孤立量子多体系统部分产生的纯态系综。这些投影系综编码了超出热期望值的精细信息，为量子热化提供了新窗口。虽然无限温度系统产生Haar随机系综，但实际物理约束（如有限温度或守恒定律）需要更一般的框架，因此需要研究Scrooge系综的出现机制。

Method: 使用Scrooge k-design来表征Scrooge系综，识别了三种物理上不同的出现机制：1）长时间混沌幺正动力学产生全局Scrooge设计；2）高度混洗的全局态在测量互补子系统时诱导局部Scrooge设计；3）任意纠缠态在高度混洗基中测量互补系统时产生局部Scrooge系综。通过多种多体系统的数值模拟验证。

Result: 数值模拟表明，相干性、纠缠、非稳定性和信息混洗是Scrooge类行为出现的关键资源。研究结果为量子多体系统中最大熵、信息吝啬的随机性出现建立了统一的理论框架。

Conclusion: 该研究建立了Scrooge系综出现的统一理论框架，揭示了三种不同的物理机制，并识别了关键量子资源。这些结果为理解量子多体系统中的深度热化和最大熵随机性提供了理论基础。

Abstract: Recent advances in quantum simulators allow direct experimental access to the ensemble of pure states generated by measuring part of an isolated quantum many-body system. These projected ensembles encode fine-grained information beyond thermal expectation values and provide a new window into quantum thermalization. In chaotic dynamics, projected ensembles exhibit universal statistics, a phenomenon known as deep thermalization. While infinite-temperature systems generate Haar-random ensembles, realistic physical constraints such as finite temperature or conservation laws require a more general framework. It has been proposed that deep thermalization is governed in general by the emergence of Scrooge ensembles, maximally entropic distributions of pure states consistent with the underlying constraints. Here we provide rigorous arguments supporting this proposal. To characterize this universal behavior, we invoke Scrooge $k$-designs, which approximate Scrooge ensembles, and identify three physically distinct mechanisms for their emergence. First, global Scrooge designs can arise from long-time chaotic unitary dynamics alone, without the need for measurements. Second, if the global state is highly scrambled, a local Scrooge design is induced when the complementary subsystem is measured. Third, a local Scrooge ensemble arises from an arbitrary entangled state when the complementary system is measured in a highly scrambled basis. Numerical simulations across a range of many-body systems identify coherence, entanglement, non-stabilizerness, and information scrambling as essential resources for the emergence of Scrooge-like behavior. Taken together, our results establish a unified theoretical framework for the emergence of maximally entropic, information-stingy randomness in quantum many-body systems.

</details>


### [78] [When Does Quantum Differential Privacy Compose?](https://arxiv.org/abs/2601.00337)
*Daniel Alabi,Theshani Nuradha*

Main category: quant-ph

TL;DR: 量子差分隐私中，经典组合定理在一般量子测量下失效，但在张量积通道和乘积相邻输入条件下，通过量子矩会计师框架可以恢复类似经典的高级组合保证。


<details>
  <summary>Details</summary>
Motivation: 经典差分隐私的组合定理是其核心优势，但量子差分隐私中隐私定义基于任意测量，经典基于标量隐私损失变量的组合论证不再适用。需要澄清量子差分隐私组合的局限性和可能性。

Method: 首先展示基于POVM的近似量子差分隐私中经典风格组合完全失效。然后针对张量积通道作用于乘积相邻输入的情况，引入基于算子值隐私损失和矩阵矩生成函数的量子矩会计师框架，控制其矩以约束测量的Rényi散度。

Result: 证明即使单个完美私有的量子通道，在相关联合实现中也可能完全失去隐私。但在张量积通道和乘积相邻输入条件下，可以获得与经典理论相同主导阶行为的高级组合风格边界。

Conclusion: 量子差分隐私的有意义组合定理需要仔细阐明通道、输入和对抗测量的结构假设，为理解哪些经典思想能扩展到量子环境提供了原则性框架。

Abstract: Composition is a cornerstone of classical differential privacy, enabling strong end-to-end guarantees for complex algorithms through composition theorems (e.g., basic and advanced). In the quantum setting, however, privacy is defined operationally against arbitrary measurements, and classical composition arguments based on scalar privacy-loss random variables no longer apply. As a result, it has remained unclear when meaningful composition guarantees can be obtained for quantum differential privacy (QDP).
  In this work, we clarify both the limitations and possibilities of composition in the quantum setting. We first show that classical-style composition fails in full generality for POVM-based approximate QDP: even quantum channels that are individually perfectly private can completely lose privacy when combined through correlated joint implementations. We then identify a setting in which clean composition guarantees can be restored. For tensor-product channels acting on product neighboring inputs, we introduce a quantum moments accountant based on an operator-valued notion of privacy loss and a matrix moment-generating function. Although the resulting Rényi-type divergence does not satisfy a data-processing inequality, we prove that controlling its moments suffices to bound measured Rényi divergence, yielding operational privacy guarantees against arbitrary measurements. This leads to advanced-composition-style bounds with the same leading-order behavior as in the classical theory.
  Our results demonstrate that meaningful composition theorems for quantum differential privacy require carefully articulated structural assumptions on channels, inputs, and adversarial measurements, and provide a principled framework for understanding which classical ideas do and do not extend to the quantum setting.

</details>


### [79] [Probabilistic Entanglement Distillation and Cost under Approximately Nonentangling and Dually Nonentangling Instruments](https://arxiv.org/abs/2601.00383)
*Xian Shi*

Main category: quant-ph

TL;DR: 该论文研究了概率性纠缠蒸馏和纠缠稀释，在近似非纠缠和近似对偶非纠缠操作下，建立了与后选择量子假设检验的直接联系，得到了蒸馏误差指数的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 虽然近期在一般资源理论中概率性转换的局限性已得到澄清，但在近似（对偶）非纠缠操作下概率性纠缠蒸馏的误差指数解析公式仍然缺失。该工作旨在填补这一空白。

Method: 基于后选择量子假设检验框架，建立概率性蒸馏与针对可分态集合的后选择假设检验之间的直接联系。研究近似非纠缠和近似对偶非纠缠量子仪器下的操作模型。

Result: 推导出在近似非纠缠操作下蒸馏误差指数的解析表征，建立了与可分测量限制下的后选择假设检验的关系，并研究了概率性纠缠稀释，得到了近似非纠缠和近似对偶非纠缠仪器下概率性纠缠成本的关系及界限。

Conclusion: 该工作通过后选择假设检验框架，为概率性纠缠蒸馏和稀释提供了理论分析工具，建立了不同操作模型下误差指数和成本之间的解析关系，推进了量子纠缠理论的发展。

Abstract: Entanglement distillation and entanglement cost are fundamental tasks in quantum entanglement theory. This work studies both in the probabilistic setting and focuses on the asymptotic error exponent of probabilistic entanglement distillation when the operational model is $δ$-approximately nonentangling(ANE) and $δ$-approximately dually nonentangling(ADNE) quantum instruments. While recent progress has clarified limitations of probabilistic transformations in general resource theories, an analytic formula for the error exponent of probabilistic entanglement distillation under approximately (dually) nonentangling operations has remained unavailable.
  Building on the framework of postselected quantum hypothesis testing, we establish a direct connection between probabilistic distillation and postselected hypothesis testing against the set of separable states. In particular, we derive an analytical characterization of the distillation error exponent under ANE. Besides, we relate the exponent to postselected hypothesis testing with measurements restricted to be separable. We further investigate probabilistic entanglement dilution and establish a relation between probabilistic entanglement costs under approximately nonentangling and approximately dually nonentangling instruments, together with a bound on the probabilistic entanglement cost under nonentangling instruments

</details>


### [80] [The Maximal Entanglement Limit in Statistical and High Energy Physics](https://arxiv.org/abs/2601.00405)
*Dmitri E. Kharzeev*

Main category: quant-ph

TL;DR: 量子纠缠为统计物理和高能相互作用提供了统一基础，系统在长时间或高能量下达到最大纠缠极限，导致量子相位不可观测、密度矩阵呈热形式，概率描述自然涌现。


<details>
  <summary>Details</summary>
Motivation: 本文旨在建立量子纠缠作为统计物理和高能相互作用的统一理论基础，挑战传统上依赖遍历性或经典随机性的解释框架。

Method: 提出最大纠缠极限（MEL）概念，分析量子系统在长时间或高能量极限下的行为，通过纠缠和希尔伯特空间几何来解释物理现象。

Result: 在MEL框架下，量子相位变得不可观测，约化密度矩阵呈现热形式，概率描述自然涌现，成功解释了部分子模型、弦断裂热化、高能碰撞热化以及结构函数的普适小x行为。

Conclusion: 量子纠缠为统计物理和高能相互作用提供了统一的几何基础，最大纠缠极限能够解释多种物理现象，无需引入遍历性或经典随机性假设。

Abstract: These lectures advocate the idea that quantum entanglement provides a unifying foundation for both statistical physics and high-energy interactions. I argue that, at sufficiently long times or high energies, most quantum systems approach a Maximal Entanglement Limit (MEL) in which phases of quantum states become unobservable, reduced density matrices acquire a thermal form, and probabilistic descriptions emerge without invoking ergodicity or classical randomness. Within this framework, the emergence of probabilistic parton model, thermalization in the break-up of confining strings and in high-energy collisions, and the universal small $x$ behavior of structure functions arise as direct consequences of entanglement and geometry of high-dimensional Hilbert space.

</details>


### [81] [Chip scale superconducting quantum gravimeter based on a SQUID transmon mechanical resonator](https://arxiv.org/abs/2601.00425)
*Salman Sajad Wani,Mughees Ahmed Khan,Abrar Ahmed Naqash,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: 芯片级超导重力仪：通过将机械谐振器嵌入量子比特SQUID环中，利用约瑟夫森势的非线性将重力位移映射到量子比特的几何相位，实现高带宽、高精度的重力测量。


<details>
  <summary>Details</summary>
Motivation: 当前重力测量平台难以同时实现绝对精度和高带宽跟踪，限制了地球物理学和惯性导航应用。需要一种既能达到原子传感器精度又能实现千赫兹采样率的新型重力测量技术。

Method: 将高Q值机械谐振器嵌入超导量子比特（transmon）的SQUID环中，利用约瑟夫森势的非线性产生运动相关电感，将重力位移映射到量子比特的几何相位。采用频闪测量协议抑制机械退相干，通过微波光谱实现电可调性和SI可追溯性。

Result: 预测灵敏度达到10² nGal/√Hz，接近原子传感器性能，同时实现千赫兹采样率。该架构提供了实现高速、量子极限片上重力测量的实用途径。

Conclusion: 芯片级超导重力仪结合了超导量子比特和机械谐振器，通过创新的几何相位映射和频闪测量技术，实现了高精度、高带宽的重力测量，为地球物理学和惯性导航提供了新的解决方案。

Abstract: Precise gravitational measurements are vital for geophysics and inertial navigation, but current platforms struggle to combine absolute accuracy with high-bandwidth tracking. We address this challenge with a chip-scale superconducting gravimeter that couples a flux-tunable transmon qubit to a high-$Q$ mechanical resonator. We embed the mechanical element inside the qubit's SQUID loop. This allows us to exploit the Josephson potential's nonlinearity, creating a motion-dependent inductance that maps gravitational displacement onto the qubit's geometric phase. Using a stroboscopic measurement protocol, we suppress mechanical decoherence at revival times. This yields a predicted sensitivity of $10^2\,\mathrm{nGal}/\sqrt{\mathrm{Hz}}$, approaching the performance of atomic sensors but with kilohertz-rate sampling. With electrical {in situ} tunability and SI traceability via microwave spectroscopy, this architecture offers a practical route to high-speed, quantum-limited on-chip gravimetry.

</details>


### [82] [Multistep quantum master equation theory for response functions in four wave mixing electronic spectroscopy of multichromophoric macromolecules](https://arxiv.org/abs/2601.00431)
*Seogjoo J. Jang*

Main category: quant-ph

TL;DR: 本文为多色团大分子系统的四波混频光谱提供了三阶响应函数的替代推导方法，仅考虑单激子态，推导了封闭形式表达式，并为更一般情况开发了量子主方程方法。


<details>
  <summary>Details</summary>
Motivation: 为理解二维电子光谱信号提供更坚实的物理基础，特别是在多色团大分子系统中，需要更系统的方法来处理激子耦合、退相、弛豫和非马尔可夫效应。

Method: 1. 对于谐振子浴对角线性耦合情况，推导了显示所有显式时间依赖性的封闭形式表达式；2. 对于更一般的系统-浴耦合，采用量子主方程方法推导格林函数类算符的多步时间演化方程。

Result: 获得了三阶响应函数的解析表达式，能够一致地处理激子间耦合、退相、弛豫和非马尔可夫效应，为二维电子光谱信号分析提供了更可靠的物理基础。

Conclusion: 该方法为多色团大分子系统的四波混频光谱提供了系统化的理论框架，能够更准确地描述复杂的光谱特征，特别是在非马尔可夫和非对角耦合情况下。

Abstract: This work provides an alternative derivation of third order response functions in four wave mixing spectroscopy of multichromophoric macromolecular systems considering only single exciton states. For the case of harmonic oscillator bath linearly and diagonally coupled to exciton states, closed form expressions showing all the explicit time dependences are derived. These expressions can provide more solid physical basis for understanding 2-dimensional electronic spectroscopy signals. For more general cases of system-bath coupling, the quantum master equation (QME) approach is employed for the derivation of multistep time evolution equations for Green function-like operators. Solution of these equations is feasible at the level of 2nd order non-Markovian QME, and the new approach can account for inter-exciton coupling, dephasing, relaxation, and non-Markovian effects in a consistent manner.

</details>


### [83] [Prediction of a measurable sign change in the Casimir force using a magnetic fluid](https://arxiv.org/abs/2601.00483)
*Long Ma,Larissa Inácio,Dai-Nam Le,Lilia M. Woods,Mathias Boström*

Main category: quant-ph

TL;DR: 该论文展示了通过卡西米尔力控制的量子悬浮，利用聚苯乙烯表面与特氟龙涂层金属基底在甲苯和磁铁矿颗粒混合物中的相互作用，实现了可测量的排斥-吸引转变。


<details>
  <summary>Details</summary>
Motivation: 研究卡西米尔力在复杂材料系统中的可控性，探索通过材料选择和设计实现量子悬浮的可能性，为微纳尺度操控提供新方法。

Method: 使用聚苯乙烯表面和特氟龙涂层金属基底，浸入甲苯和磁铁矿颗粒混合物中，通过改变金属和铁磁流体材料的组合来控制卡西米尔相互作用。

Result: 系统在可测量距离范围内表现出排斥-吸引转变，卡西米尔捕获效应可通过材料选择进行控制，热和量子贡献的分析揭示了铁磁流体光学和磁学性质对捕获效应的影响。

Conclusion: 通过巧妙选择金属和铁磁流体材料，可以实现可控的卡西米尔捕获效应，这为量子悬浮和微尺度操控提供了新的可能性，材料的光学和磁学性质对效应范围和强度有重要影响。

Abstract: We demonstrate quantum levitation controlled by Casimir forces acting between a polystyrene surface and a Teflon-coated metallic substrate immersed in a mixture of Toluene and magnetite particles. This system experiences repulsion-attraction transitions in the Casimir interaction for distances where the effect is measurable. This Casimir trapping can be controlled by clever choices of metallic and ferrofluid materials, which are directly linked to the emergence of the trapping effect. Thermal and quantum contributions are investigated in detail, showing how the optical and magnetic properties of the ferrofluid and other materials affect the magnitude of the trapping and its distance range of observability.

</details>


### [84] [A Geometrical Design Tool for Building Cost-Effective Layout-Aware n-Bit Quantum Gates Using the Bloch Sphere Approach](https://arxiv.org/abs/2601.00484)
*Ali Al-Bayaty,Marek Perkowski*

Main category: quant-ph

TL;DR: 本文提出了一种基于布洛赫球面的几何设计方法（BSA），用于构建成本效益更高的n位量子门，相比传统基于酉矩阵乘法的设计技术，BSA能显著降低量子成本。


<details>
  <summary>Details</summary>
Motivation: 传统n位量子门设计主要依赖酉矩阵乘法，这种方法计算时间长、工作量大，且可能导致量子门成本过高。布洛赫球面通常仅用作验证工具，而本文旨在探索将其作为主动设计工具的可能性。

Method: 提出布洛赫球面方法（BSA），通过布洛赫球面的几何平面交线来视觉选择量子旋转，无需使用酉矩阵乘法。该方法能有效映射n位量子门中的m个目标量子位和n-m个控制量子位，满足量子计算机物理相邻量子位的有限布局连接性。

Result: 实验证明，使用BSA构建的n位量子门始终比使用传统量子设计技术构建的同类门具有更低的量子成本。

Conclusion: BSA作为一种几何设计工具，能够有效构建成本效益更高的n位量子门，为量子门设计提供了新的方法学，突破了传统矩阵乘法设计的局限性。

Abstract: The conventional design technique of any n-bit quantum gate is mainly achieved using unitary matrices multiplication, where n >= 2 and 1 <= m <= n-1 for m target qubits and n-m control qubits. These matrices represent quantum rotations by an n-bit quantum gate. For a quantum designer, such a conventional technique requires extensive computational time and effort, which may generate an n-bit quantum gate with a too high quantum cost. The Bloch sphere is only utilized as a visualization tool to verify the conventional design correctness for quantum rotations by a quantum gate. In contrast, this paper introduces a new concept of using the Bloch sphere as a "geometrical design tool" to build cost-effective n-bit quantum gates with lower quantum costs. This concept is termed the "Bloch sphere approach (BSA)". In BSA, a cost-effective n-bit quantum gate is built without using any unitary matrices multiplication. Instead, the quantum rotations for such a gate are visually selected using the geometrical planar intersections of the Bloch sphere. The BSA can efficiently map m targets among n-m controls for an n-bit quantum gate, to satisfy the limited layout connectivity for the physical neighboring qubits of a quantum computer. Experimentally, n-bit quantum gates built using the BSA always have lower quantum costs than those for such gates built using the conventional quantum design techniques.

</details>


### [85] [Non-Hermitian Band Topology and Edge States in Atomic Lattices](https://arxiv.org/abs/2601.00487)
*Wenxuan Xie,John C Schotland*

Main category: quant-ph

TL;DR: 研究一维和二维二聚体原子晶格在长程耗散辐射耦合下的能带结构和拓扑相，发现低能动力学由具有复费米速度的狄拉克方程描述，验证了非厄米体边对应关系。


<details>
  <summary>Details</summary>
Motivation: 探索长程耗散辐射耦合如何影响原子晶格的拓扑性质，特别是非厄米系统中的拓扑相和边缘态。

Method: 推导单激发子空间的有效非厄米哈密顿量，分析SSH模型和蜂窝模型的拓扑不变量，利用合成规范场打破时间反演对称性，推导域边界局域边缘态的解析解。

Result: 系统低能动力学由具有复费米速度的狄拉克方程描述，验证了非厄米体边对应关系，获得了边缘态的解析解。

Conclusion: 长程耗散辐射耦合在原子晶格中诱导出非厄米拓扑相，为研究非厄米拓扑物理提供了新平台。

Abstract: We investigate the band structure and topological phases of one- and two-dimensional bipartite atomic lattices mediated by long-range dissipative radiative coupling. By deriving an effective non-Hermitian Hamiltonian for the single-excitation sector, we demonstrate that the low-energy dynamics of the system are governed by a Dirac equation with a complex Fermi velocity. We analyze the associated topological invariants for both the SSH and honeycomb models, utilizing synthetic gauge fields to break time-reversal symmetry in the latter. Finally, we explicitly verify the non-Hermitian bulk-edge correspondence by deriving analytical solutions for edge states localized at domain boundaries.

</details>


### [86] [Casimir interactions and drift currents](https://arxiv.org/abs/2601.00489)
*Modi Ke,Dai-Nam Le,Lilia M. Woods*

Main category: quant-ph

TL;DR: 研究带漂移电流的石墨烯片间的卡西米尔相互作用，发现漂移电流引入排斥修正，减少吸引力，并产生与载流子流动方向相反的横向力。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡条件下（存在漂移电流）石墨烯片间的卡西米尔相互作用，研究电流如何影响和控制这种量子涨落诱导的力。

Method: 采用移动费米盘模型描述非平衡光学响应，计算两个平行石墨烯片在稳态漂移电流下的卡西米尔相互作用。

Result: 漂移电流引入垂直于层方向的排斥修正，减少整体吸引力（但未完全抵消）；同时产生与载流子流动方向相反的横向力。两种效应随距离和漂移速度变化。

Conclusion: 漂移电流可调控卡西米尔力，为控制这种量子涨落诱导的相互作用提供了新途径。

Abstract: We investigate the fluctuation-induced Casimir interactions between two parallel graphene sheets carrying steady-state drift currents. The graphene properties are modeled based on the shifted Fermi disk model to capture the non-equilibrium optical response of the system. We find that the drift current introduces a repulsive correction to the perpendicular to the layers Casimir interaction, thereby reducing the overall attractive force. Although the correction is repulsive, it does not overcome the underlying attraction between the layers. It also generates a lateral force that opposes the carrier flow direction. Both contributions are studied in terms of distance and drift velocity functionalities showing pathways for Casimir force control.

</details>


### [87] [Chaos and thermalization in Clifford-Floquet dynamics](https://arxiv.org/abs/2601.00511)
*Anton Kapustin,Daniil Radamovich*

Main category: quant-ph

TL;DR: 研究无限量子比特系统中平移不变Clifford量子元胞自动机的遍历性质，证明非周期性QCA会导致多种初始状态热化到无限温度态


<details>
  <summary>Details</summary>
Motivation: 研究量子元胞自动机（QCA）的遍历性质，特别是当QCA不具有周期性时，系统是否会热化到无限温度态，这对于理解量子多体系统的热化行为具有重要意义

Method: 分析无限d维量子比特系统中平移不变Clifford量子元胞自动机的重复应用，研究其对不同初始状态的演化行为

Result: 证明对于非周期性QCA，多种初始状态（包括纯态和混合态）都会热化到无限温度态，特别是所有短程纠缠且接近平衡态的初始状态都会热化，并指出了弱热化和强热化的微妙区别

Conclusion: 平移不变Clifford量子元胞自动机在非周期性条件下会导致系统热化到无限温度态，这为理解量子多体系统的热化行为提供了理论依据

Abstract: We study the ergodic properties of a unitary Floquet dynamics arising from the repeated application of a translationally-invariant Clifford Quantum Cellular Automata to an infinite system of qubits in d dimensions. One expects that if the QCA does not exhibit any periodicity, a generic initial state of qubits will thermalize, that is, approach the infinite-temperature state. We show that this is true for many classes of states, both pure and mixed. In particular, this is true for all initial states that are short-range entangled and close to the equilibrium state. We also point out a subtle distinction between weak and strong thermalization.

</details>


### [88] [Photonic Reservoir Engineering via 2D $Λ$-Type Atomic Arrays in Waveguide QED](https://arxiv.org/abs/2601.00622)
*Thi Phuong Anh Nguyen,Le Phuong Hoang,Xuan Binh Cao*

Main category: quant-ph

TL;DR: 提出两种二维原子晶格结构（Zigzag和Orthogonal）耦合到光子晶体波导，分别用于增强量子存储保真度和非线性光学过程效率。


<details>
  <summary>Details</summary>
Motivation: 传统Λ型原子系统的电磁感应透明（EIT）存在固有局限性：一维原子链只能提供单个超辐射通道，亚辐射模式难以访问，导致非弹性过程降低存储保真度和非线性光子生成效率。

Method: 设计了两种二维原子晶格结构耦合到光子晶体波导：Zigzag结构通过工程化的集体超辐射和亚辐射模式产生平坦的EIT窗口；Orthogonal结构通过优化四波混频过程增强非线性光学效应。

Result: Zigzag结构展宽了传输带宽并抑制了散射，增强了量子存储保真度；Orthogonal结构将四波混频强度相对于传统一维Λ型EIT链提高了六个数量级，并产生局域化的闲频光子形成明确定义的光谱模式。

Conclusion: 这两种二维原子晶格结构为按需光子生成、高保真量子存储和增强非线性光学过程提供了工程化结构光子储层的通用途径。

Abstract: Electromagnetically induced transparency (EIT) in $Λ$-type atomic systems underpins quantum technologies such as high-fidelity memory and nonlinear optics, but conventional setups face intrinsic limitations. Standard geometries of one-dimensional atomic chains coupled to waveguides allow only a single bright superradiant channel, while subradiant modes remain weakly accessible, limiting control over collective radiative behavior and dark-state pathways. This leads to unwanted inelastic processes, degrading memory fidelity and reducing nonlinear photon generation efficiency. Here, we propose two two-dimensional (2D) atomic lattice geometries coupled to a photonic crystal waveguide, namely Zigzag and Orthogonal structures. In the Zigzag model, engineered collective super- and subradiant modes produce a flattened EIT window, broadening the transmission bandwidth and suppressing unwanted scattering to enhance quantum memory fidelity. In the Orthogonal model, four-wave mixing (FWM) intensity is amplified by up to six orders of magnitude relative to a conventional one-dimensional $Λ$-type EIT chain with identical $Γ_{1D}$, $Ω_c$, and probe intensity, with localized idler photons forming well-defined spectral modes. These results demonstrate a versatile route to engineer structured photonic reservoirs for on-demand photon generation, high-fidelity quantum storage, and enhanced nonlinear optical processes.

</details>


### [89] [Experimental exclusion of a generalized Károlyházy gravity-induced decoherence model](https://arxiv.org/abs/2601.00651)
*Nicola Bortolotti,Kristian Piscicchia,Matthias Laubenstein,Simone Manti,Antonino Marcianò,Federico Nola,Catalina Curceanu*

Main category: quant-ph

TL;DR: 实验数据排除了广义Károlyházy引力退相干模型，将空间关联长度下限提高到4.64米，超过理论上限1.98米，从而否定了该模型。


<details>
  <summary>Details</summary>
Motivation: 检验广义Károlyházy引力退相干模型及其相关非马尔可夫CSL模型，通过实验约束引力相关的量子力学基础修改方案。

Method: 使用VIP合作组在INFN Gran Sasso国家实验室收集的高纯度锗探测器数据，分析广义Károlyházy模型中度量涨落的空间关联长度参数。

Result: 获得改进的下界R_K > 4.64米（95%置信水平），超过先前实验限制一个数量级。结合理论上限R_K < 1.98米，排除了广义Károlyházy模型。

Conclusion: 实验数据排除了广义Károlyházy模型及其相关非马尔可夫CSL模型，显著收紧了对引力相关退相干场景的实验约束，证明地下低背景实验对量子力学基础修改的敏感性。

Abstract: We report new experimental constraints on the generalized version of the gravity-induced decoherence model originally proposed by Károlyházy. Using data collected by the VIP Collaboration at the INFN Gran Sasso National Laboratory with a high-purity germanium detector, we derive an improved lower bound on the spatial correlation length $R_K$ characterizing metric fluctuations in the model. We obtain a bound $R_K > 4.64$ m (95\% C.L.), which exceeds by more than an order of magnitude the previous experimental limit. When combined with the theoretical upper bound $R_K <1.98$ m derived from macroscopic localization requirements, our result excludes the generalized Károlyházy model. The same conclusion applies to an associated non-Markovian formulation of the Continuous Spontaneous Localization (CSL) model. Our findings significantly tighten experimental constraints on gravity-related decoherence scenarios and demonstrate the sensitivity of underground low-background experiments to foundational modifications of quantum mechanics.

</details>


### [90] [Ultracold Quantum Gravimeters: An Introduction for Geophysicists](https://arxiv.org/abs/2601.00676)
*Ivaldevingles Rodrigues De Souza Junior,Andrea Trombettoni,Carla Braitenberg*

Main category: quant-ph

TL;DR: 本文为地球物理学家提供了超冷量子重力仪的入门介绍，重点讲解理解量子重力仪所需的量子力学概念，而非地球物理应用。


<details>
  <summary>Details</summary>
Motivation: 为地球物理学家提供量子重力仪的可访问性介绍，因为地球物理学家已经熟悉地球物理应用，但需要理解量子力学概念来掌握量子重力仪的工作原理。

Method: 基于二能级和三能级原子系统回顾重力仪，重点介绍原子干涉测量的基本原理。通过π/2和π脉冲的作用讨论马赫-曾德尔干涉仪的功能，展示相位差如何编码重力加速度。

Result: 提供了量子重力仪工作原理的数学和概念框架，展示了如何通过原子干涉测量技术测量重力加速度，并简要讨论了噪声影响。

Conclusion: 本文为地球物理学家提供了理解超冷量子重力仪所需的量子力学基础，填补了地球物理应用知识与量子测量技术之间的知识鸿沟。

Abstract: This paper aims at providing an accessible introduction to ultracold quantum gravimeters tailored for geophysicists. We do not focus here on geophysical applications, as these are already well known to geophysicists, but rather provide a pedagogical exposition of the quantum-mechanical concepts needed to understand the operation of quantum gravimeters. We present a review of gravimeters based on two- and three-level atomic systems, focusing on the fundamental mechanisms of atomic interferometry. The functioning of Mach-Zehnder interferometers is discussed through the action of $π/2$ and $π$ pulses, showing how the resulting phase shift encodes gravitational acceleration. The effect of noise is briefly discussed.

</details>


### [91] [Effects of Donor-Acceptor Quantum Coherence and Non-Markovian Bath on the Distance Dependence of Resonance Energy Transfer](https://arxiv.org/abs/2601.00708)
*Seogjoo J. Jang*

Main category: quant-ph

TL;DR: 该研究通过比较相干共振能量转移（CRET）和非平衡Förster共振能量转移（FRET）理论，发现量子相干和非马尔可夫浴效应会改变RET的经典1/r⁶距离依赖性，但这些效应对传统RET效率测量影响较小。


<details>
  <summary>Details</summary>
Motivation: 准确理解共振能量转移（RET）的距离依赖性对于其作为纳米尺度距离光谱尺度的应用至关重要。特别是在短距离下，供体-受体量子相干性和非马尔可夫浴效应变得显著，需要深入研究这些效应对RET距离依赖性的影响。

Method: 通过理论比较相干RET（CRET）和非平衡FRET理论，两者都考虑了非马尔可夫浴效应。研究使用具有跃迁偶极相互作用的供体-受体电子耦合模型，分析RET速率对距离的依赖性。

Result: RET速率通常偏离经典的1/r⁶距离依赖性：量子相干性使距离依赖性比六次方更陡峭，而非马尔可夫浴效应使距离依赖性比六次方更平缓。这些效应在亚皮秒时间尺度的种群动力学中明显，但对传统RET效率测量的影响相对较小。

Conclusion: 量子相干和非马尔可夫浴效应确实会改变RET的经典距离依赖性，但要在传统RET效率测量中检测这些效应，需要高精度测量或使用具有快速自发衰减速率的供体。

Abstract: Accurate information on the distance dependence of resonance energy transfer (RET) is crucial for its utilization as a spectroscopic ruler \re{of} nanometer scale distances. In this regard, understanding the effects of donor-acceptor quantum coherence and non-Markovian bath, which become significant at short distances, has significant implications. The present work investigates this issue theoretically by comparing results from a theory of coherent RET (CRET) with a nonequilibrium version of Förster's RET (FRET) theory, both accounting for non-Markovian bath effects. Even for a model where the donor-acceptor electronic coupling is of transition dipole interaction form, it is shown that the RET rate in general deviates from the inverse sixth power distance dependence as opposed to the prediction of the original FRET. It is shown that the donor-acceptor quantum coherence makes the \re{distance} dependence steeper than the sixth power although detailed manner of enhancement is sensitive to specific values of parameters. On the other hand, the non-Markovian bath effects make the \re{distance} dependence more moderate than the sixth power for both CRET and nonueqilibrium FRET because finite time scale of the bath causes the rate to be smaller than the prediction of original FRET. While these effects are \re{demonstrated clearly} in the population dynamics at sub-picosecond time scales, their contributions to the conventional RET efficiency are relatively minor. This indicates that the actual detection of such effects through conventional RET efficiency measurement requires either high precision or utilization of a donor with fast spontaneous decay rate of excitation.

</details>


### [92] [Assessing Quantum Annealing to Solve the Minimum Vertex Multicut](https://arxiv.org/abs/2601.00711)
*Ali Abbassi,Yann Dujardin,Eric Gourdin,Philippe Lacomme,Caroline Prodhon*

Main category: quant-ph

TL;DR: 量子退火在网络安全优化问题中的应用评估：针对受限顶点最小多割问题，在D-Wave量子退火器上实现，分析量子工作流关键参数，发现硬件约束限制大实例嵌入和扩展性，混合量子经典求解器提供更好可行性。


<details>
  <summary>Details</summary>
Motivation: 电信网络安全中的组合优化问题通常难以用经典方法解决，本研究旨在探索量子退火在解决受限顶点最小多割问题中的实际可行性，为网络安全相关网络问题提供量子优化评估。

Method: 将受限顶点最小多割问题建模为二次无约束二进制优化模型，在D-Wave量子退火器上实现，重点分析量子工作流的关键方面：小图嵌入技术、链长、拓扑约束、链强度选择、解嵌入过程和后处理。

Result: 量子退火面临显著的硬件级约束和限制，特别是在大实例的嵌入和扩展性方面；混合量子经典求解器提供了改进的可行性；研究确定了影响量子优化成功的关键参数。

Conclusion: 本研究对D-Wave系统当前能力进行了现实评估，识别了在网络安全相关网络问题中决定量子优化成功的关键参数，为量子计算在网络安全优化中的应用提供了实用指导。

Abstract: Cybersecurity in telecommunication networks often leads to hard combinatorial optimization problems that are challenging to solve with classical methods. This work investigates the practical feasibility of using quantum annealing to address the Restricted Vertex Minimum Multicut Problem. The problem is formulated as a Quadratic Unconstrained Binary Optimization model and implemented on D-Wave s quantum annealer. Rather than focusing on solution quality alone, we analyze key aspects of the quantum workflow including minor embedding techniques, chain length, topology constraints, chain strength selection, unembedding procedures, and postprocessing. Our results show that quantum annealing faces substantial hardware-level constraints limitations in embedding and scalability, especially for large instances, while hybrid quantum-classical solvers provide improved feasibility. This study offers a realistic assessment of the D-Wave system s current capabilities and identifies crucial parameters that govern the success of quantum optimization in cybersecurity-related network problems.

</details>


### [93] [Quantum Approaches to the Minimum Edge Multiway Cut Problem](https://arxiv.org/abs/2601.00720)
*Ali Abbassi,Yann Dujardin,Eric Gourdin,Philippe Lacomme,Caroline Prodhon*

Main category: quant-ph

TL;DR: 该研究比较了三种量子计算范式（量子退火、光子变分量子电路、门基QAOA）在最小边多路割问题上的表现，发现量子退火在当前最具可扩展性，而其他方法受硬件和模拟深度限制。


<details>
  <summary>Details</summary>
Motivation: 评估电信网络弹性中的最小边多路割问题，比较不同量子计算范式在早期量子优化中的可行性，为电信安全中的组合优化提供量子工作流设计见解。

Method: 在三种量子计算平台上进行基准测试：D-Wave量子处理单元的量子退火、Quandela Perceval平台的光子变分量子电路模拟、IBM的门基量子近似优化算法（QAOA）。

Result: 量子退火在当前对这类问题最具可扩展性；光子和门基方法受硬件和模拟深度限制；不同方法在电路约束、编码开销和可扩展性方面存在权衡。

Conclusion: 量子退火是目前最适合电信网络弹性分析中组合优化问题的量子方法，研究结果为设计量子工作流提供了实用见解。

Abstract: We investigate the minimum edge multiway cut problem, a fundamental task in evaluating the resilience of telecommunication networks. This study benchmarks the problem across three quantum computing paradigms: quantum annealing on a D-Wave quantum processing unit, photonic variational quantum circuits simulated on Quandela s Perceval platform, and IBM s gate-based Quantum Approximate Optimization Algorithm (QAOA). We assess the comparative feasibility of these approaches for early-stage quantum optimization, highlighting trade-offs in circuit constraints, encoding overhead, and scalability. Our findings suggest that quantum annealing currently offers the most scalable performance for this class of problems, while photonic and gate-based approaches remain limited by hardware and simulation depth. These results provide actionable insights for designing quantum workflows targeting combinatorial optimization in telecom security and resilience analysis.

</details>


### [94] [Geometric Complexity of Quantum Channels via Unitary Dilations](https://arxiv.org/abs/2601.00735)
*Alberto Acevedo,Antonio Falcó*

Main category: quant-ph

TL;DR: 论文提出了一种基于酉扩张的量子信道几何复杂度框架，区分实现依赖的复杂度和内在信道复杂度，并引入噪声复杂度来量化相对于理想封闭演化的几何复杂度损失。


<details>
  <summary>Details</summary>
Motivation: 对于开放量子系统，约化演化由量子信道描述，存在许多不等价的Stinespring实现，因此需要明确定义哪些微观资源可访问、哪些变换被视为规范，才能建立有意义的复杂度概念。

Method: 引入基于酉扩张的量子信道族几何复杂度泛函，区分实现依赖复杂度（相对于显式扩张数据）和内在信道复杂度（在物理合理的可容许扩张类上最小化）。泛函采用减法形式：比较总酉实现的几何成本与去除纯环境贡献的规范替代项。

Result: 建立了酉几何复杂度的相干性下界，推导了结构性质（如时间齐次扩张下的线性时间缩放），在马尔可夫（GKSL/Lindblad）体系下通过标准扩张构造获得耗散子控制边界，并在去相位、振幅阻尼和去极化等基准噪声模型上进行了示例说明。

Conclusion: 该框架为开放量子动力学的几何复杂度提供了系统方法，通过减法结构合理分离系统与环境贡献，并引入噪声复杂度来量化相对于理想封闭演化的复杂度损失，为量子信道复杂度研究建立了理论基础。

Abstract: Nielsen's geometric approach to quantum circuit complexity provides a Riemannian framework for quantifying the cost of implementing unitary (closed--system) dynamics. For open dynamics, however, the reduced evolution is described by quantum channels and admits many inequivalent Stinespring realizations, so any meaningful complexity notion must specify which microscopic resources are counted as accessible and which transformations are regarded as gauge. We introduce and analyze a geometric complexity functional for families of quantum channels based on unitary dilations. We distinguish an implementation-dependent complexity, defined relative to explicit dilation data, from an intrinsic channel complexity obtained by minimizing over a physically motivated class of admissible dilations (e.g. bounded environment dimension, energy or norm constraints, and penalty structures). The functional has a subtractive form: it compares the geometric cost of the total unitary realization with a canonical surrogate term that removes purely environmental contributions. We justify this subtraction from concise postulates, including closed-system consistency, environment-only neutrality, and invariance under dilation gauge transformations that leave the channel unchanged. This leads to a companion quantity, noise complexity, quantifying the loss of geometric complexity relative to a prescribed ideal closed evolution. We establish a coherence-based lower bound for unitary geometric complexity, derive structural properties such as linear time scaling under time-homogeneous dilations, and obtain dissipator--controlled bounds in the Markovian (GKSL/Lindblad) regime under a standard dilation construction. Finally, we illustrate the framework on canonical benchmark noise models, including dephasing, amplitude damping, and depolarizing (Pauli) channels.

</details>


### [95] [Training-Free Certified Bounds for Quantum Regression: A Scalable Framework](https://arxiv.org/abs/2601.00745)
*Demerson N. Gonçalves,Tharso D. Fernandes,Pedro H. G. Lugao,João T. Dias*

Main category: quant-ph

TL;DR: 提出一种基于泡利期望值的免训练、可认证的量子回归误差界，通过蒙特卡洛方法高效估计，为量子特征映射选择提供快速评估工具


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中，选择适当的量子特征映射架构需要大量计算资源。现有方法缺乏对回归任务性能的理论保证，难以在部署复杂模型前评估不同特征映射的表达能力。

Method: 将分类中的最小准确率启发式推广到回归任务，在泡利特征空间中评估轴对齐预测器。证明最优轴对齐预测器构成任意线性或核回归器的最小训练MSE的严格上界。引入蒙特卡洛框架，通过可处理测量轴子集高效估计该界，并提供非渐近统计保证。

Result: 建立了量子回归的可认证误差界，实现了对量子特征映射的快速比较和表达能力早期诊断，可在有限测量预算内验证性能。

Conclusion: 该方法为量子特征映射选择提供了理论保证和实用工具，能在部署高复杂度模型前做出明智的架构选择，降低量子机器学习开发成本。

Abstract: We present a training-free, certified error bound for quantum regression derived directly from Pauli expectation values. Generalizing the heuristic of minimum accuracy from classification to regression, we evaluate axis-aligned predictors within the Pauli feature space. We formally prove that the optimal axis-aligned predictor constitutes a rigorous upper bound on the minimum training Mean Squared Error (MSE) attainable by any linear or kernel-based regressor defined on the same quantum feature map. Since computing this exact bound requires an intractable scan of the full Pauli basis, we introduce a Monte Carlo framework to efficiently estimate it using a tractable subset of measurement axes. We further provide non-asymptotic statistical guarantees to certify performance within a practical measurement budget. This method enables rapid comparison of quantum feature maps and early diagnosis of expressivity, allowing for the informed selection of architectures before deploying higher-complexity models.

</details>


### [96] [Exponentially Accelerated Sampling of Pauli Strings for Nonstabilizerness](https://arxiv.org/abs/2601.00761)
*Zhenyu Xiao,Shinsei Ryu*

Main category: quant-ph

TL;DR: 提出一种高效经典算法，精确计算多体波函数的稳定子Rényi熵和稳定子零性，相比直接方法实现指数级加速，并开发蒙特卡洛估计器和方差缩减方案。


<details>
  <summary>Details</summary>
Motivation: 量子魔法（非稳定子性）量化与稳定子结构的偏离，是潜在量子加速的基础。需要高效方法计算稳定子Rényi熵和稳定子零性，以定量分析量子资源。

Method: 结合快速Walsh-Hadamard变换与泡利算符的精确划分，将每个采样泡利字符串的平均成本从O(2^N)降至O(N)。基于此框架开发蒙特卡洛估计器，并采用基于Clifford的方差缩减方案抑制采样波动。

Result: 在随机魔法态集合上验证了准确性和效率，应用于掺杂T门的随机Clifford电路，比较不同掺杂架构。算法适用于任意量子态，可定量分析高度纠缠态和长时间非平衡动力学中的魔法资源。

Conclusion: 该方法实现了指数级加速，为分析量子魔法资源提供了高效计算工具，适用于各种量子态和动力学过程。

Abstract: Quantum magic, quantified by nonstabilizerness, measures departures from stabilizer structure and underlies potential quantum speedups. We introduce an efficient classical algorithm that exactly computes stabilizer Rényi entropies and stabilizer nullity for generic many-body wavefunctions of $N$ qubits. The method combines the fast Walsh-Hadamard transform with an exact partition of Pauli operators. It achieves an exponential speedup over direct approaches, reducing the average cost per sampled Pauli string from $O(2^N)$ to $O(N)$. Building on this framework, we further develop a Monte-Carlo estimator for stabilizer Rényi entropies together with a Clifford-based variance-reduction scheme that suppresses sampling fluctuations. We benchmark the accuracy and efficiency on ensembles of random magic states, and apply the method to random Clifford circuits with doped $T$ gates, comparing different doping architectures. Our approach applies to arbitrary quantum states and provides quantitative access to magic resources both encoded in highly entangled states and generated by long-time nonequilibrium dynamics.

</details>


### [97] [On orthoposets of numerical events in quantum logic](https://arxiv.org/abs/2601.00772)
*Dietmar Dorninger,Helmut Länger*

Main category: quant-ph

TL;DR: 该论文研究一般事件集(GSEs)，这是一种用于量子逻辑的数学框架，将数值事件表示为从状态集到[0,1]的函数，包含0、1和1-p运算。


<details>
  <summary>Details</summary>
Motivation: 为量子逻辑提供一个统一的数学框架，将数值事件、希尔伯特逻辑、具体逻辑和布尔代数等不同概念统一在一般事件集(GSEs)的理论中，研究其结构特性和相互关系。

Method: 定义一般事件集(GSEs)作为偏序集，研究其各种类别，特别是正交偏序集，分析它们与已知逻辑系统的联系，通过状态表征GSEs，并探讨GSEs成为格的条件。

Result: 建立了GSEs作为量子逻辑统一框架的理论基础，表征了GSEs作为偏序集的特性，确定了GSEs成为格的条件，揭示了不同逻辑系统在GSEs框架下的相互关系。

Conclusion: 一般事件集(GSEs)提供了一个强大的数学框架，能够统一表示量子逻辑中的各种代数结构，包括希尔伯特逻辑、具体逻辑和布尔代数，为量子逻辑的进一步研究奠定了理论基础。

Abstract: Let S be a set of states of a physical system and p(s) the probability of the occurrence of an event when the system is in state s in S. Such a function p from S to [0,1] is known as a numerical event or more accurately an S-probability. A set P of numerical events including the constant functions 0 and 1 and 1-p with every p in P becomes a poset when ordered by the order of real functions and can serve as a general setting for quantum logics. We call such a poset P a general set of events (GSE). The thoroughly investigated algebras of S-probabilities (including Hilbert logics), concrete logics and Boolean algebras can all be represented within this setting. In this paper we study various classes of GSEs, in particular those that are orthoposets and their interrelations and connections to known logics. Moreover, we characterize GSEs as posets by means of states and discuss the situation for GSEs to be lattices.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [98] [From Rotating Attractors to Extremal Black Holes with Axionic Hair](https://arxiv.org/abs/2601.00066)
*Etevaldo dos Santos Costa Filho*

Main category: gr-qc

TL;DR: 在四维爱因斯坦-麦克斯韦-轴子理论中，研究极值旋转黑洞，发现仅纯电或纯磁荷配置存在规则旋转吸引子，双荷配置被轴子运动方程排除。


<details>
  <summary>Details</summary>
Motivation: 研究四维爱因斯坦-麦克斯韦-轴子理论中极值旋转黑洞的性质，特别是轴子场对黑洞吸引子机制的影响，探索旋转黑洞在存在轴子场时的特殊约束条件。

Method: 结合近视界分析和整体分析：1) 使用熵函数形式主义研究近视界极值几何，证明规则旋转吸引子的存在条件；2) 构建渐近平坦的旋转极值EMA黑洞族，验证吸引子机制。

Result: 1) 仅纯电或纯磁荷配置存在规则旋转吸引子，双荷配置被轴子运动方程排除；2) 构建了连接电性NHEG分支的渐近平坦旋转极值EMA黑洞族；3) 验证了视界数据由熵函数极值化固定并与渐近模量解耦。

Conclusion: 轴子场对旋转黑洞吸引子机制施加了严格约束：仅允许纯电或纯磁荷配置存在规则旋转吸引子，双荷配置被排除。这为轴子场在黑洞物理中的作用提供了重要见解。

Abstract: We study extremal, rotating black holes in four-dimensional Einstein-Maxwell-axion (EMA) theory through a combined near-horizon and bulk analysis. At the level of the near-horizon extremal geometry (NHEG), using the entropy function formalism, we prove that regular rotating attractors with axionic hair exist only for configurations that are purely electrically or purely magnetically charged; regular rotating dyonic attractors are excluded by the axion equation of motion, a result that we established perturbatively and non-perturbatively within the NHEG system. On the global side, we construct families of asymptotically flat, rotating extremal EMA black holes that interpolate to the electric NHEG branch, confirming that horizon data are fixed by extremization of the entropy function and decoupled from asymptotic moduli in line with the attractor mechanism.

</details>


### [99] [Gravitation and Spacetime: Emergent from Spinor Interactions -- How?](https://arxiv.org/abs/2601.00070)
*Martin Rainer*

Main category: gr-qc

TL;DR: 该论文探讨了从旋量基础出发的不同时空几何方法，提出因果结构和自旋网络都源自因果双锥区域内所有粒子旋量的投影。


<details>
  <summary>Details</summary>
Motivation: 研究时空几何的基本构成，探讨引力是拥有自身基本成分还是从量子物质算符的期望值中涌现的有效理论，比较不同的旋量基础方法。

Method: 比较多种基于旋量的经典和量子时空几何方法，提出通过因果双锥区域内所有粒子旋量（费米子和玻色子）及其自旋交织相互作用事件到该区域空间截面的投影来生成因果结构和离散几何。

Result: 提出了一个统一框架，将因果结构和自旋网络的生成都解释为从旋量基础到空间截面的投影过程，为不同时空几何方法之间的关系提供了新视角。

Conclusion: 时空几何可能从更基本的旋量结构中涌现，因果结构和离散几何都可通过旋量投影机制统一描述，为未来研究不同方法之间的关系指明了方向。

Abstract: Newtonian gravity arises as the nonrelativistic, static, weak-field limit of some Lorentzian spacetime geometry solving the generally covariant Einstein equations for a given matter field configuration. Spacetime geometry has a local description in the spinor basis of Penrose. The breakdown of relativistic quantum (field) theory at small distances suggests that, the Lorentzian geometry is to be modified below some regularization length. The thermodynamic correspondence, e.g. for black holes or other horizons, indicates that, Lorentzian spacetime is an emergent geometric description of an ensemble of more fundamental constituents. The independent derivations of the area law of the Bekenstein-Hawking entropy by string theory and loop quantum gravity show that, (some) properties of spacetime do not depend on the nature of its fundamental constituents (in leading order).
  Whether, on a fundamental scale, spacetime gravity has its own classical or quantum constituents (like e.g. in loop quantum gravity), or it is just an effective theory, deriving from expectation values of quantum matter operators (like in spinor gravity or causal fermion systems), this is still open. We compare some very different classical and quantum approaches to spacetime geometry, all deriving in one way or another from spinors, and comment on questions for future research in order to clarify their relations. We propose that both, the causal structure and the spin networks for generation of discrete geometry arise via projection from all particle spinors (fermionic and bosonic) within a causal double cone region and their spin interwining interaction events onto a spatial section of this double cone region.

</details>


### [100] [Metric Reconstruction and Second Order Perturbation for Generic Spherically Symmetric spacetime](https://arxiv.org/abs/2601.00162)
*Rong-Zhen Guo,Qing-Guo Huang*

Main category: gr-qc

TL;DR: 提出了在一般球对称时空中进行高阶扰动分析的新框架，包括修改的Teukolsky方程和无需Hertz势的度规重构方法，以及适用于二阶扰动的理论。


<details>
  <summary>Details</summary>
Motivation: 为了测试引力理论，需要研究环降阶段的高阶扰动，这要求超越广义相对论的扰动框架和合适的时空度规重构方法。

Method: 1. 为渐近平坦球对称时空引入修改的Teukolsky方程；2. 将无需Hertz势的度规重构方法扩展到tr对称时空；3. 提出适用于一般球对称时空的二阶扰动理论。

Result: 建立了完整的扰动分析框架，能够在特定规范条件下计算度规分量，为高阶扰动研究提供了理论基础。

Conclusion: 该工作解决了球对称时空中高阶扰动分析的关键挑战，为测试引力理论提供了重要的理论工具。

Abstract: Higher-order perturbations during the ringdown phase are essential for testing gravitational theories. This requires a perturbation framework that extends beyond General Relativity, as well as an appropriate method for reconstructing the spacetime metric. In this work, we address these challenges within the context of general spherically symmetric spacetimes. We introduce a modified Teukolsky equation for perturbative calculations in asymptotically flat, spherically symmetric spacetimes. The metric reconstruction method, which does not rely on the Hertz potential, is extended to $tr$-symmetric spacetime, allowing for the calculation of metric components under specific gauge conditions. Additionally, we present a second-order perturbation theory applicable to generic spherically symmetric spacetimes.

</details>


### [101] [Gravitational Wave Tails and Transient Behaviors of Quantum-Corrected Black Holes](https://arxiv.org/abs/2601.00164)
*Rong-Zhen Guo,Qing-Guo Huang*

Main category: gr-qc

TL;DR: 研究有效圈量子引力框架下黑洞引力波尾迹的量子修正效应


<details>
  <summary>Details</summary>
Motivation: 引力波天文学在检验强场引力动力学和探测黑洞本质方面至关重要。受近期关于引力波晚期尾迹研究的启发，本研究旨在探索有效圈量子引力框架下黑洞引力波尾迹的量子修正效应。

Method: 在有效圈量子引力框架下，分析黑洞引力波尾迹，特别关注量子修正对尾迹行为的影响。

Result: 研究发现：1）引力波尾迹的振幅和中间行为都受到量子修正的影响；2）尾迹的振幅和瞬态特性对黑洞动力学的具体细节非常敏感。

Conclusion: 量子引力修正显著影响黑洞引力波尾迹的特征，这为通过引力波观测探测量子引力效应提供了新的可能性。

Abstract: Gravitational wave astronomy plays a pivotal role in testing the dynamics of gravity in strong-field regimes and probing the nature of black holes. Motivated by recent studies on late-time tails in gravitational waves, we examine the gravitational wave tails of black holes incorporating quantum corrections within the framework of effective Loop Quantum Gravity. Our findings indicate that both the amplitudes and the intermediate behavior of these tails are influenced by quantum corrections. We demonstrate that the amplitude and transient characteristics of the tail are sensitive to the specific details of the black hole's dynamics.

</details>


### [102] [Imprints of quantum gravity effects on gravitational waves: a comparative study using extreme mass-ratio inspirals](https://arxiv.org/abs/2601.00185)
*Ruo-Ting Chen,Guoyang Fu,Dan Zhang,Jian-Pin Wu*

Main category: gr-qc

TL;DR: 使用极端质量比旋进(EMRI)作为高精度探测器，研究圈量子引力(LQG)黑洞模型中量子修正参数ζ对时空的影响，通过波形保真度分析评估LISA探测器的可探测性。


<details>
  <summary>Details</summary>
Motivation: 在圈量子引力框架下构建了两个带有量子修正参数ζ的黑洞模型，需要验证这些量子引力效应是否能够通过未来的空间引力波探测器（如LISA）观测到，特别是利用EMRI作为高精度探针。

Method: 使用改进的增强解析近似(AAK)模型，在两种LQG黑洞背景和史瓦西时空中生成波形，通过保真度分析比较波形差异，量化LISA探测器对ζ参数的探测能力。

Result: 第一个LQG黑洞模型在EMRI信号中产生比第二个模型更强的特征信号，使其量子引力效应更容易被未来的空间引力波探测器探测到，并基于探测阈值推导了对ζ参数的约束。

Conclusion: EMRI可以作为探测圈量子引力黑洞模型中量子修正的有效工具，第一个LQG黑洞模型的量子引力效应更易被LISA等空间引力波探测器观测，为量子引力理论的实验验证提供了新途径。

Abstract: Within a generally covariant Hamiltonian framework of loop quantum gravity (LQG), two black hole models parameterized by a quantum correction $ζ$ have recently been constructed. Using extreme mass-ratio inspirals (EMRIs) as high-precision probes, we investigate the imprints of this LQG deformation in the surrounding spacetime. Waveforms generated via an improved augmented analytic kludge (AAK) model in both LQG-BH backgrounds and in Schwarzschild spacetime are compared through a faithfulness analysis. This allows us to quantify the detectability of the deviation with LISA and to derive constraints on $ζ$ based on a detection threshold. We find that the first LQG-BH model produces significantly stronger signatures in EMRI signals than the second, making its quantum gravity effects more accessible to future space-borne gravitational-wave detection.

</details>


### [103] [Dynamical constraints on variable vacuum energy in Brans-Dicke theory](https://arxiv.org/abs/2601.00419)
*Khomesh R. Patle,G. P. Singh,Romanshu Garg*

Main category: gr-qc

TL;DR: 在Brans-Dicke理论框架下研究宇宙晚期加速膨胀，考虑两种动态真空能模型：混合真空定律Λ(t)=αH²+βḢ和幂律真空定律Λ(H)=α₁Hⁿ，推导解析解并分析宇宙学演化


<details>
  <summary>Details</summary>
Motivation: 在Brans-Dicke理论中研究动态真空能模型，以解释宇宙晚期加速膨胀现象。传统宇宙学常数Λ为常数，但观测表明可能需要随时间变化的真空能来解释宇宙演化

Method: 采用两种动态真空能模型：1) 混合真空定律Λ(t)=αH²+βḢ；2) 幂律真空定律Λ(H)=α₁Hⁿ。在Brans-Dicke理论框架下推导Hubble参数和其他相关宇宙学量的解析解

Result: 获得了Hubble参数和其他宇宙学量的解析解，分析了减速参数、有效状态方程、宇宙学参数和当前宇宙年龄的演化行为

Conclusion: Brans-Dicke理论中的动态真空能模型能够描述宇宙晚期加速膨胀，两种模型都提供了可行的理论框架来解释观测到的宇宙演化特征

Abstract: In this research work, we investigate the late-time accelerated expansion of the universe within the framework of Brans-Dicke theory by considering dynamical vacuum energy models with a time-varying cosmological constant. Two vacuum energy models are studied, namely the hybrid vacuum law $Λ(t)=αH^{2}+β\dot{H}$ and the power vacuum law $Λ(H)=α_{1}H^{n}$, where $α$, $β$, $α_{1}$ and $n$ are free parameters. We derive analytical solutions for the Hubble parameter and other relevant cosmological quantities. The evolution of the deceleration parameter, the effective equation of state, the cosmographic parameters and the present age of the universe are also analyzed.

</details>


### [104] [Taxonomy of periodic orbits and gravitational waves in a deformed Schwarzschild black hole spacetime](https://arxiv.org/abs/2601.00550)
*Zhutong Hua,Zhen-Tao He,Jiageng Jiao,Jing-Qi Lai,Yu Tian*

Main category: gr-qc

TL;DR: 研究变形史瓦西黑洞周围测试粒子的周期轨道及其产生的引力波，发现大变形会导致圆形轨道消失，并分析了不同周期轨道的引力波信号特征。


<details>
  <summary>Details</summary>
Motivation: 研究变形史瓦西黑洞周围的轨道动力学和引力波特征，探索黑洞变形对粒子轨道行为和引力波信号的影响，为未来空间引力波探测器提供理论参考。

Method: 首先分析圆形轨道的性质，使用轨道分类法通过三元组描述周期轨道的缩放-旋转行为，然后计算不同周期轨道产生的引力波形信号。

Result: 发现当变形足够大时圆形轨道会消失；通过三元组成功表征了各种周期轨道的缩放-旋转行为；揭示了变形对引力波信号的影响，这些信号可能被未来空间探测器探测到。

Conclusion: 变形史瓦西黑洞的周期轨道特性和引力波信号与标准史瓦西黑洞存在显著差异，这些特征可能成为未来探测黑洞变形的重要观测依据。

Abstract: In this paper, we investigate periodic orbits of test particles around a deformed Schwarzschild black hole and the resulting gravitational waves. Firstly, we examine the properties of circular orbits and find that circular orbits could disappear when the deformation is large enough. Then, using an orbital taxonomy, we characterize various periodic orbits with a set of triples, which describes the zoom-whirl behaviours. We also calculate the gravitational waveform signals generated by different periodic orbits, revealing the influence of the deformation on the gravitational wave, which can be potentially picked up by future space-based detectors.

</details>


### [105] [Uniqueness of electric-magnetic spacetimes with massive particle](https://arxiv.org/abs/2601.00565)
*Marek Rogatko*

Main category: gr-qc

TL;DR: 证明了四维静态渐近平坦的爱因斯坦-麦克斯韦时空在包含非极端大质量粒子球作为内边界时的唯一性，该时空与带有电/磁荷的Reissner-Nordström时空等距


<details>
  <summary>Details</summary>
Motivation: 研究包含非极端大质量粒子球作为内边界的四维静态渐近平坦爱因斯坦-麦克斯韦时空的唯一性问题，与之前的光子球分类结果形成对比

Method: 使用共形正能量定理、正质量定理和适当的共形变换作为主要工具进行证明

Result: 证明了该时空的唯一性，即与带有电/磁荷的Reissner-Nordström时空等距，描述了整个时空叶层集的存在性

Conclusion: 四维静态渐近平坦的爱因斯坦-麦克斯韦时空在包含非极端大质量粒子球作为内边界时具有唯一性，为Reissner-Nordström时空

Abstract: Uniqueness of the four-dimensional static, asymptotically flat, Einstein-Maxwell spacetime with both electric and magnetic charges, containing non-extremal massive particle sphere, being an inner boundary in it, has been proved. It is isometric to Reissner-Nordström spacetime with electric/magnetic charges. In contrast to the previous results concerning the classification of photon spheres, it describes the existence of the entire set of spacetme foliations, a set of massive particle sphere addressed to the various energies of the particles. The conformal positive energy, positive mass theorem and adequate conformal transformations constitute the mail tools in the proof.

</details>


### [106] [Interacting Ghost Dark Energy with Sign-Changeable Coupling in Brans-Dicke Cosmology](https://arxiv.org/abs/2601.00582)
*Kirti Mehta,Pankaj Kumar,N. Myrzakulov,S. H. Shekh*

Main category: gr-qc

TL;DR: 在Brans-Dicke宇宙学框架下，研究具有符号可变相互作用的幽灵暗能量与暗物质模型，分析宇宙学参数演化、相变行为及热力学性质。


<details>
  <summary>Details</summary>
Motivation: 研究幽灵暗能量在Brans-Dicke理论中的行为，特别关注暗能量与暗物质之间的符号可变相互作用，以探索宇宙加速膨胀的动力学机制和未来演化。

Method: 在平坦FLRW宇宙中建立Brans-Dicke-幽灵暗能量模型，采用对数形式的Brans-Dicke标量场，推导宇宙演化方程，分析状态方程参数、减速参数等宇宙学量的演化行为。

Result: 状态方程参数在当前和未来时期呈现quintessence-like行为，但通过调整参数也可实现phantom-like行为；减速参数显示宇宙经历了从减速到加速的平滑相变，并在遥远未来将再次经历减速膨胀；w_D-w_D'平面轨迹从冻结区开始，演化中分离，最终进入解冻区；广义热力学第二定律在该模型中成立。

Conclusion: Brans-Dicke框架下的相互作用幽灵暗能量模型能够解释当前宇宙加速膨胀，预测未来宇宙演化相变，满足热力学基本定律，为理解暗能量本质提供了有价值的理论框架。

Abstract: In this study, we analyze the ghost dark energy model in Brans-Dicke cosmology in the framework of a flat Friedmann-Lemaitre-Robertson-Walker universe. We consider an interaction between ghost dark energy and dark matter with a sign-changeable interaction term. To discuss the cosmological implications of the model, we consider a well-motivated logarithmic form of the Brans-Dicke scalar field. By deriving the cosmological evolution equations, we obtain the cosmological parameters such as the equation of state and deceleration parameters. We analyze the behavior of the cosmological parameters by plotting their graphs against the redshift parameter ($z$). We observe that the equation of state parameter shows quintessence-like behaviour during present and future epochs; however, phantom-like behavior is also possible for suitable values of the model parameters. Analysis of the deceleration parameter shows a smooth recent phase transition of the universe (deceleration to acceleration). An interesting result we observe is the decelerated expansion of the universe in the far future, i.e, the universe experiences another phase transition in the future. The physical significance of the well-known cosmological plane ($w_D-w_D'$ plane) is discussed in our model. We observe that the trajectories start in the freezing region with the same initial behavior, deviate from each other during the evolution and ends in the thawing region. Finally, we perform a detailed thermodynamic analysis and demonstrate that the generalized second law of thermodynamics is satisfied within the present interacting ghost dark energy model.

</details>


### [107] [Massless graviton in de Sitter as second sound in two-fluid hydrodynamics](https://arxiv.org/abs/2601.00639)
*G. E. Volovik*

Main category: gr-qc

TL;DR: 在德西特时空中，引力子的概念和质量存在模糊性。本文通过德西特热力学的双流体方法，发现了一种类似于第二声波的集体模式，该模式以光速传播且无质量，表明它可能是德西特时空中的无质量引力子。


<details>
  <summary>Details</summary>
Motivation: 在闵可夫斯基时空中，引力子及其质量的概念是清晰的，但在德西特时空中这些概念仍然模糊不清。本文旨在通过热力学方法探索德西特时空中的引力子性质。

Method: 采用双流体方法研究德西特热力学，分析德西特状态的双流体动力学，寻找类似于第二声波的集体模式。

Result: 发现了一个集体模式，该模式类似于德西特状态双流体动力学中的第二声波。这个模式是无质量的，并且以光速传播。

Conclusion: 这个第二声波类似物可能是德西特时空中传播的无质量引力子，但该模式具体代表何种类型的引力子仍需进一步研究。

Abstract: The concept of gravitons and their masses, clear in the case of Minkowski spacetime, remains ambiguous for de Sitter spacetime. Here, we used a two-fluid approach to de Sitter thermodynamics and found a collective mode that is analogous to second sound in the two-fluid dynamics of the de Sitter state. This mode is massless and propagates at the speed of light. This suggests that this second-sound analog is a massless graviton propagating in de Sitter spacetime. The type of graviton this mode represents requires further consideration.

</details>


### [108] [Exceptional Lines and Excitation of (Nearly) Double-Pole Quasinormal Modes: A Semi-Analytic Study in the Nariai Black Hole](https://arxiv.org/abs/2601.00704)
*Nao Nakamoto,Naritaka Oshita*

Main category: gr-qc

TL;DR: 该论文发现Kerr-de Sitter和Myers-Perry黑洞中质量标量场的准正规模在参数空间中存在异常线，这是连续异常点的集合，会导致两个准正规模频率及其解重合。在Nariai极限下，扰动方程简化为Pöschl-Teller势的波动方程，使得异常线附近的振幅分析成为可能。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞准正规模在参数空间中的特殊行为，特别是异常点和异常线的出现，这对于理解黑洞扰动和引力波信号中的环降过程具有重要意义。异常点处的模式简并可能导致环降行为的显著变化。

Method: 采用解析方法研究准正规模在异常线附近的行为。在Nariai极限（宇宙视界与黑洞视界接近）下，将扰动方程简化为具有Pöschl-Teller势的波动方程，从而能够解析地分析准正规模的振幅和激发因子。

Result: 发现准正规模在标量质量和黑洞自旋参数空间中存在异常线，在Nariai极限下也出现异常线。解析地研究了异常线附近准正规模的振幅和激发因子，分析了准正规模的破坏性激发和环降稳定性，并研究了异常线附近的瞬态线性增长现象。

Conclusion: 黑洞准正规模在参数空间中存在异常线，这为理解环降过程提供了新的视角。在异常线附近，准正规模表现出特殊的激发模式，包括瞬态线性增长。这些发现适用于涉及（近）双极点准正规模激发的广泛系统。

Abstract: We show that quasinormal modes (QNMs) of a massive scalar field in Kerr-de Sitter and Myers-Perry black holes exhibit an exceptional line (EL), which is a continuous set of exceptional points (EPs) in parameter space, at which two QNM frequencies and their associated solutions coincide. We find that the EL appears in the parameter space spanned by the scalar mass and the black hole spin parameter, and also in the Nariai limit, i.e., $r_{\rm c} - r_{\rm h} \to 0$, where $r_{\rm c}$ and $r_{\rm h}$ denote the radii of the cosmological and black hole horizons, respectively. We analytically study the amplitudes or excitation factors of QNMs near the EL. Such an analytic treatment becomes possible since, in the Nariai limit, the perturbation equation reduces to a wave equation with the Pöschl-Teller (PT) potential. We discuss the destructive excitation of QNMs and the stability of the ringdown near and at the EL. The transient linear growth of QNMs -- a characteristic excitation pattern near an EP or EL -- together with the conditions under which this linear growth dominates the early ringdown, is also studied analytically. Our conditions apply to a broad class of systems that involve the excitation of (nearly) double-pole QNMs.

</details>


### [109] [Extremalization approach to black hole thermodynamics: perturbations around higher-derivative gravities](https://arxiv.org/abs/2601.00771)
*Aonan Zhang,Qiang Wang,Yong Xiao*

Main category: gr-qc

TL;DR: 论文提出了一种基于极值化原理的方法，可以在不求解扰动黑洞解的情况下，计算高阶导数引力理论中黑洞热力学的第一阶修正。


<details>
  <summary>Details</summary>
Motivation: 传统上，在引力作用量中加入高阶导数项时，需要求解修正后的黑洞解才能计算热力学性质。这种方法计算复杂且困难。本文旨在推广已有的极值化方法，使其不仅适用于爱因斯坦引力的小扰动，还能应用于更一般的高阶导数引力理论的扰动。

Method: 采用欧几里得作用量表述的黑洞热力学极值化原理。将已知的高阶导数引力理论（如爱因斯坦-高斯-博内引力）作为零阶背景，将额外的高阶曲率算子视为扰动。通过极值化方法，直接计算第一阶热力学修正，无需显式求解扰动后的黑洞解。

Result: 成功将极值化方法推广到更一般的高阶导数引力理论。以爱因斯坦-高斯-博内引力为零阶理论，计算了额外高阶曲率算子诱导的第一阶热力学修正。该方法在渐近平坦和渐近AdS时空都适用，且无需求解扰动黑洞解。

Conclusion: 极值化方法具有普适性，不仅限于爱因斯坦引力的扰动，可应用于任何已知零阶解的高阶导数引力理论的扰动计算。这大大简化了高阶导数引力理论中黑洞热力学修正的计算过程。

Abstract: When higher-derivative terms are added to a gravitational action, black hole solutions and their thermodynamic properties are generally corrected. Recent progress has shown that, by treating higher-derivative operators as perturbations, the first-order corrections to black hole thermodynamics can be obtained without explicit knowledge of the corresponding perturbed black hole solutions. This result can be understood as a consequence of an extremalization principle underlying the Euclidean action formulation of black hole thermodynamics. In this work, we emphasize that this extremalization approach is not restricted to perturbations around Einstein gravity. Instead, it can be applied to perturbations of more general higher-derivative gravity theories whose black hole solutions are already known and can be taken as the zeroth-order background. As an explicit illustration, we consider Einstein--Gauss--Bonnet gravity as the zeroth-order theory and study the first-order thermodynamic corrections induced by further higher-order curvature operators. We show that these corrections can be derived without solving the perturbed black hole solutions, both in asymptotically flat and asymptotically AdS spacetimes.

</details>


### [110] [A 3+1 Perturbative Approach to the Cosmic Dynamo Equation](https://arxiv.org/abs/2601.00774)
*Juan F. Bravo,Leonardo Castañeda,Héctor J. Hortúa*

Main category: gr-qc

TL;DR: 该研究使用数值相对论方法分析扰动FLRW时空中原初磁场（PMF）的演化，发现标量扰动的速度场可以有效驱动磁场放大，放大程度取决于宇宙介质的电导率。


<details>
  <summary>Details</summary>
Motivation: 研究原初磁场生成机制，解释宇宙中大尺度磁场的普遍存在性。通过分析磁场种子与标量扰动增长模式之间的相互作用，探索磁场放大的物理过程。

Method: 采用数值相对论（NR）形式，对一阶宇宙学扰动进行3+1分解，推导运动学发电机近似下的宇宙发电机方程。使用Einstein Toolkit和FLRWSolver软件数值演化与标量扰动相关的速度场。

Result: 发现标量扰动的速度场能有效驱动原初磁场的放大，这种放大程度依赖于宇宙介质的电导率。速度场与磁场种子的相互作用导致磁场显著增长。

Conclusion: 研究提供了连接原初磁生成与磁场种子演化的计算描述，解释了宇宙中大尺度磁场的普遍存在性，表明宇宙介质电导率在磁场放大过程中起关键作用。

Abstract: In this work, we analyze the evolution of PMFs within a perturbed Friedmann-Lemaître-Robertson-Walker (FLRW) spacetime using the formalisms of Numerical Relativity (NR). We apply the 3+1 decomposition to first-order cosmological perturbations to derive the cosmological dynamo equation under the kinematic-dynamo approximation. Our objective is to study the interaction between the seed magnetic field and the growing modes of scalar perturbations, whose associated velocity fields are evolved numerically using the software \texttt{Einstein Toolkit} and \texttt{FLRWSolver}. We find that these velocity fields effectively drive the amplification of the PMF, demonstrating that the extent of this growth is dependent on the electrical conductivity of the cosmic medium. Our findings provide a computational description linking primordial magnetogenesis to the evolution of magnetic seeds, ultimately explaining the ubiquity of large-scale magnetic fields in the universe

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [111] [New RVE concept in thermoelasticity of periodic composites subjected to compact support loading](https://arxiv.org/abs/2601.00018)
*V. A. Buryachenko*

Main category: physics.comp-ph

TL;DR: 提出基于精确加性通用积分方程(AGIE)的计算分析微力学框架，用于周期性微结构线性热弹性复合材料，通过广义代表体积元概念和机器学习集成实现高效分析。


<details>
  <summary>Details</summary>
Motivation: 传统复合材料分析方法在处理局部加载(如激光加热)时面临边界效应、有限尺寸依赖等问题，需要更精确高效的微力学框架来克服这些限制。

Method: 基于精确的加性通用积分方程(AGIE)，建立机械和热载荷的通用积分方程，采用统一迭代求解方案，引入广义代表体积元概念，并与机器学习架构集成。

Result: 框架能自动过滤非代表性有效参数，消除边界效应和边缘伪影，将无限周期介质分析简化为有限数据驱动域，支持物理信息代理非局部算子开发。

Conclusion: 该AGIE-based CAM框架为周期性复合材料提供了精确高效的微力学分析工具，通过广义RVE和机器学习集成，显著提升了局部加载问题的计算精度和效率。

Abstract: This paper introduces an advanced Computational Analytical Micromechanics (CAM) framework for linear thermoelastic composites (CMs) with periodic microstructures. The approach is based on an exact new Additive General Integral Equation (AGIE), formulated for compactly supported loading conditions, such as body forces and localized thermal effects (for example laser heating). In addition, new general integral equations (GIEs) are established for arbitrary mechanical and thermal loading. A unified iterative scheme is developed for solving the static AGIEs, where the compact support of loading serves as a new fundamental training parameter. At the core of the methodology lies a generalized Representative Volume Element (RVE) concept that extends Hill classical definition of the RVE. Unlike conventional RVEs, this generalized RVE is not fixed geometrically but emerges naturally from the characteristic scale of localized loading, thereby reducing the analysis of an infinite periodic medium to a finite, data-driven domain. This formulation automatically filters out nonrepresentative subsets of effective parameters while eliminating boundary effects, edge artifacts, and finite-size sample dependencies. Furthermore, the AGIE-based CAM framework integrates seamlessly with machine learning (ML) and neural network (NN) architectures, supporting the development of accurate, physics-informed surrogate nonlocal operators.

</details>


### [112] [Additive general integral equations in thermoelastic micromechanics of composites](https://arxiv.org/abs/2601.00019)
*Valeriy A. Buryachenko*

Main category: physics.comp-ph

TL;DR: 提出增强的计算分析微力学框架，用于分析具有随机微观结构的线性热弹性复合材料，基于精确的加性广义积分方程，引入局部化加载作为关键参数，发展广义代表性体积元概念，实现无限随机介质到有限数据驱动域的简化。


<details>
  <summary>Details</summary>
Motivation: 传统复合材料分析方法在处理随机微观结构、局部化加载（如激光加热）和界面缺陷时存在局限性，需要更精确且能消除边界效应的方法来预测有效性能。

Method: 基于精确的加性广义积分方程，提出新的广义积分方程处理任意机械和热载荷，开发统一迭代求解策略，引入广义代表性体积元概念，该RVE由局部化加载的特征尺度决定而非几何预定义。

Result: 该方法能自动排除非代表性有效参数子集，消除边界效应、边缘伪影和有限尺寸限制，将无限随机异质介质分析简化为有限数据驱动域，且天然兼容机器学习和神经网络架构。

Conclusion: 提出的增强CAM框架为线性热弹性复合材料提供了一种精确、高效的分析方法，特别适用于局部化加载场景，通过广义RVE概念和数据驱动方法克服了传统微力学分析的局限性。

Abstract: This work presents an enhanced Computational Analytical Micromechanics (CAM) framework for the analysis of linear thermoelastic composite materials (CMs) with random microstructure. The proposed approach is grounded in an exact Additive General Integral Equation (AGIE), specifically formulated for compactly supported loading, including both body forces and localized thermal changes (such as those from laser heating). New general integral equations (GIEs) for arbitrary mechanical and thermal loading are proposed. A unified iterative solution strategy is developed for the static AGIE, applicable to CMs with both perfectly and imperfectly bonded interfaces, where the compact support of loading is introduced as a new fundamental training parameter. Central to this methodology is a generalized Representative Volume Element (RVE) concept, which extends Hill classical definition. The resulting RVE is not predefined geometrically, but rather emerges from the characteristic scale of the localized loading, effectively reducing the analysis of an infinite, randomly heterogeneous medium to a finite, data-driven domain. This generalized RVE approach enables automatic exclusion of unrepresentative subsets of effective parameters, while inherently eliminating boundary effects, edge artifacts, and finite size limitations. Moreover, the AGIE-based CAM framework is naturally compatible with machine learning (ML) and neural network (NN) architectures, facilitating the construction of accurate and physically informed surrogate nonlocal operators.

</details>


### [113] [Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI](https://arxiv.org/abs/2601.00742)
*Turab Lookman,YuJie Liu,Zhibin Gao*

Main category: physics.comp-ph

TL;DR: 材料信息学从物理和信息论基础发展到AI驱动的成熟阶段，正从预测工具转变为自主研究伙伴，推动"人不在环"的材料发现新时代。


<details>
  <summary>Details</summary>
Motivation: 探索材料信息学的发展轨迹，从早期基础到AI驱动的成熟阶段，特别是大语言模型带来的变革，旨在展示该领域如何从工具演变为自主研究生态系统。

Method: 回顾关键方法论：贝叶斯优化、强化学习、Transformer架构，分析大语言模型集成中的实践挑战，比较专业模型与通用模型，讨论不确定性量化解决方案。

Result: 材料信息学已从预测工具发展为协作研究伙伴，通过主动学习和检索增强生成等技术，正朝着自主材料科学的"人不在环"发现过程新时代迈进。

Conclusion: 材料信息学正在经历从工具到生态系统的转变，AI正成为自主材料发现的核心驱动力，预示着"人不在环"研究范式的到来，将彻底改变材料科学的研究方式。

Abstract: This perspective explores the evolution of materials informatics, from its foundational roots in physics and information theory to its maturation through artificial intelligence (AI). We trace the field's trajectory from early milestones to the transformative impact of the Materials Genome Initiative and the recent advent of large language models (LLMs). Rather than a mere toolkit, we present materials informatics as an evolving ecosystem, reviewing key methodologies such as Bayesian Optimization, Reinforcement Learning, and Transformers that drive inverse design and autonomous self-driving laboratories. We specifically address the practical challenges of LLM integration, comparing specialist versus generalist models and discussing solutions for uncertainty quantification. Looking forward, we assess the transition of AI from a predictive tool to a collaborative research partner. By leveraging active learning and retrieval-augmented generation (RAG), the field is moving toward a new era of autonomous materials science, increasingly characterized by "human-out-of-the-loop" discovery processes.

</details>
