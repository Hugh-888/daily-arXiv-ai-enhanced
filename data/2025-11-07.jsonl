{"id": "2511.03766", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.03766", "abs": "https://arxiv.org/abs/2511.03766", "authors": ["Reggie C. Pantig"], "title": "Ringdown modulation of acceleration radiation in the Schwarzschild background", "comment": "28 pages, 3 figures. Comments are welcome", "summary": "We present an analytic, first-order description of how black hole ringdown\nimprints on the operational signature of near-horizon thermality. Building on a\nstatic Schwarzschild baseline in which a freely falling two-level system\ncoupled to a single outgoing mode exhibits geometric photon statistics and a\ndetailed-balance ratio set by the surface gravity, we introduce an even-parity,\naxisymmetric quadrupolar perturbation and work in an ingoing\nEddington-Finkelstein, horizon-regular framework. The perturbation corrects the\noutgoing eikonal through a gauge-invariant double-null contraction of the\nmetric, yielding a compact redshift map that, when pulled back to the detector\nworldline, produces a universal, decaying-oscillatory modulation of the\nBoltzmann exponent at the quasinormal frequency. We derive a closed boundary\nformula for the response coefficient at the sampling radius, identify the\nprecise adiabatic window in which the result holds, and prove that the\nmodulation vanishes in all stationary limits. Detector specifics (gap,\nswitching wavepacket width) enter only through a smooth prefactor, while the\ngeometric content is captured by the quasinormal pair and the response\ncoefficient. The analysis clarifies that near-horizon \"thermality\" is robust\nbut not rigid: detailed balance persists as the organizing structure and is\ngently driven by ringdown dynamics. The framework is minimal yet extensible to\nother multipoles, parities, and slow rotation, and it suggests direct numerical\nand experimental cross-checks in controlled analog settings."}
{"id": "2511.03788", "categories": ["gr-qc", "astro-ph.CO", "hep-ph"], "pdf": "https://arxiv.org/pdf/2511.03788", "abs": "https://arxiv.org/abs/2511.03788", "authors": ["Amitayus Banik", "Jeong Han Kim", "Xing-Yu Yang"], "title": "Boson Stars Hosting Black Holes", "comment": "18 pages, 12 figures", "summary": "We study a system of a self-gravitating condensate, a boson star, formed from\nscalar ultra-light dark matter (ULDM), with a black hole hosted at its center.\nWe numerically solve the equations of hydrostatic equilibrium in the\nnon-relativistic limit, consistently incorporating the gravitational potential\nof the black hole, to obtain all possible configurations of this BS-BH system\nfor different boson star masses, interaction types, and black hole masses. We\nalso propose an analytic expression for the density profile and compare it with\nthe numerical results, finding good agreement for attractive interactions and\nfor a finite range of mass ratios between the black hole and boson star.\nFinally, considering the inspiral of this BS-BH system with a second, smaller\nblack hole, we study the dephasing of gravitational waves due to the presence\nof the ULDM environment. A Fisher matrix analysis reveals the regions of\nparameter space of the ULDM mass and self-coupling that future\ngravitational-wave observatories such as LISA can probe."}
{"id": "2511.03789", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.03789", "abs": "https://arxiv.org/abs/2511.03789", "authors": ["Akhil Uniyal", "Indu K. Dihingia", "Yosuke Mizuno", "Luciano Rezzolla"], "title": "The future ability to test theories of gravity with black-hole shadows", "comment": "Published in Nature Astronomy", "summary": "The horizon-scale images of supermassive black holes (BHs) by the Event\nHorizon Telescope Collaboration (EHT) have provided new opportunities to test\ngeneral relativity and other theories of gravity. In view of future projects,\nsuch as the next-generation Event Horizon Telescope (ngEHT) and the Black-Hole\nExplorer (BHEX), having the potential of enhancing our ability to probe extreme\ngravity, it is natural to ask: \\textit{how much can two black-hole images\ndiffer?} To address this question and assess the ability of these projects to\ntest theories of gravity with black-hole shadows, we use general-relativistic\nmagnetohydrodynamic and radiative-transfer simulations to investigate the\nimages of a wide class of accreting BHs deviating from the Kerr solution. By\nmeasuring the mismatch between images of different BHs we show that future\nmissions will be able to distinguish a large class of BHs solutions from the\nKerr solution when the mismatch in the images exceeds values between $2\\%$ and\n$5\\%$ depending on the image-comparison metric considered. These results\nindicate future horizon-scale imaging with percent-level image fidelity can\nplace meaningful observational constraints on deviations from the Kerr metric\nand thereby test strong-field predictions of general relativity."}
{"id": "2511.03839", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.03839", "abs": "https://arxiv.org/abs/2511.03839", "authors": ["Corey Sargent", "William Clark", "Antonia Seifert", "Alicia Mand", "Emerson Rogers", "Adam Lane", "Alexandre Deur", "Balša Terzić"], "title": "On the Evidence for Violation of the Equivalence Principle in Disk Galaxies", "comment": "Published in Particles, 8, 65 (2025)", "summary": "We examine the claimed observations of a gravitational external field effect\n(EFE) reported in Chae et al. We show that observations suggestive of the EFE\ncan be interpreted without violating Einstein's equivalence principle, namely\nfrom known correlations between morphology, environment and dynamics of\ngalaxies. While Chae et al's analysis provides a valuable attempt at a clear\ntest of Modified Newtonian Dynamics, an evidently important topic, a\nre-analysis of the observational data does not permit us to confidently assess\nthe presence of an EFE or to distinguish this interpretation from that proposed\nin this article."}
{"id": "2511.03796", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.03796", "abs": "https://arxiv.org/abs/2511.03796", "authors": ["Elijah Pelofske"], "title": "Boltzmann Sampling of Frustrated J1 - J2 Ising Models with Programmable Quantum Annealers", "comment": null, "summary": "One of the surprising, and potentially very useful, capabilities of analog\nquantum computers, such as D-Wave quantum annealers, is sampling from the\nBoltzmann, or Gibbs, distribution defined by a classical Hamiltonian. In this\nstudy, we thoroughly examine the ability of D-Wave quantum annealers to sample\nfrom the Boltzmann distribution defined of a canonical type of competing\nmagnetic frustration $J_1$-$J_2$ model; the ANNNI (axial next-nearest-neighbor\nIsing) model. Boltzmann sampling error rate is quantified for standard\nlinear-ramp anneals ranging from $5$ nanosecond annealing times up to $2000$\nmicroseconds on two different D-Wave quantum annealing processors.\nInterestingly, we find some analog hardware parameters which result in a very\nhigh accuracy (down to a TVD of $0.0003$) and low temperature sampling (down to\n$\\beta=32.2$) in a frustrated region of the ANNNI model magnetic phase diagram.\nThis bolsters the viability of current analog quantum computers for\nthermodynamic sampling applications of highly frustrated magnetic spin systems."}
{"id": "2511.04062", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04062", "abs": "https://arxiv.org/abs/2511.04062", "authors": ["Beichen Zheng", "Ying Chen", "Lili Wen", "Xiaofei Wu"], "title": "Robust Subgroup Method Using DE Algorithm for Resonance Self-Shielding Calculation", "comment": "16 pages,2 figures", "summary": "This paper presents an enhanced version of the subgroup method for resonance\nself-shielding treatment, termed the robust subgroup method, which integrates\nRobust Estimation (RE) with a Differential Evolution (DE) algorithm. The RE\napproach is employed to handle model misspecification and data contamination,\nwhile the DE algorithm serves as an optimization tool within the RE framework\nto obtain constrained solutions. Numerical validation against experimental\nbenchmarks shows that the proposed method removes a systematic absorption bias\nin conventional subgroup fits that would otherwise depress reactivity. This\nbias appears only in benchmarks sensitive to U-238. Mechanistically, it\nreflects a threshold-like conditioning failure: strong self-shielding leverage\ndominates the loss and is magnified by dilution-induced multicollinearity. This\nadverse conditioning appears to be seeded by a narrow, sparse resonance\nstructure at low energies in fertile even-even nuclides, thereby causing rapid\nself-shielding response saturation and a weak Doppler broadening. By bounding\ninfluence and enforcing feasibility within an RE-DE framework, the inferred\nsubgroup parameters track the underlying physics more faithfully, improving the\npredictive fidelity of subsequent transport simulations."}
{"id": "2511.03749", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.03749", "abs": "https://arxiv.org/abs/2511.03749", "authors": ["Oluwadurotimi Onibonoje", "Vuong M. Ngo", "Andrew McCarre", "Elodie Ruelle", "Bernadette O-Briend", "Mark Roantree"], "title": "Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland", "comment": "13 pages (two-columns), 7 figures, 3 tables", "summary": "Grasslands, constituting the world's second-largest terrestrial carbon sink,\nplay a crucial role in biodiversity and the regulation of the carbon cycle.\nCurrently, the Irish dairy sector, a significant economic contributor, grapples\nwith challenges related to profitability and sustainability. Presently, grass\ngrowth forecasting relies on impractical mechanistic models. In response, we\npropose deep learning models tailored for univariate datasets, presenting\ncost-effective alternatives. Notably, a temporal convolutional network designed\nfor forecasting Perennial Ryegrass growth in Cork exhibits high performance,\nleveraging historical grass height data with RMSE of 2.74 and MAE of 3.46.\nValidation across a comprehensive dataset spanning 1,757 weeks over 34 years\nprovides insights into optimal model configurations. This study enhances our\nunderstanding of model behavior, thereby improving reliability in grass growth\nforecasting and contributing to the advancement of sustainable dairy farming\npractices."}
{"id": "2511.03879", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.03879", "abs": "https://arxiv.org/abs/2511.03879", "authors": ["Sergey N. Solodukhin", "Vagif Tagiev"], "title": "Exploring the landscape of black hole mimickers", "comment": "71 pages, 35 figures", "summary": "We identify a general class of spacetime metrics that mimic the properties of\nblack holes without possessing a true event horizon. These metrics are\nconstrained by the requirements of being singularity-free and geodesically\ncomplete. Specifically, we study metrics that do not possess $Z_2$ symmetry and\nmay deviate slightly or significantly from the symmetric case. Focusing on\nscalar perturbations propagating on such backgrounds, we analyze the resulting\neffective radial potentials and their dependence on different corners of the\nmimicker landscape. We further investigate the corresponding quasinormal modes\nand explore their characteristic features. Finally, we survey the landscape for\npotential observational signatures, including shadow properties and the\npossible presence or absence of echo effects."}
{"id": "2511.03846", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.03846", "abs": "https://arxiv.org/abs/2511.03846", "authors": ["Ilya Vilkoviskiy", "Michael Sonner", "Qi Camm Huang", "Wen Wei Ho", "Alessio Lerose", "Dmitry A. Abanin"], "title": "Temporal entanglement transition in chaotic quantum many-body dynamics", "comment": "25 pages, 15 figures", "summary": "Temporal entanglement (TE) of an influence matrix (IM) has been proposed as a\nmeasure of complexity of simulating dynamics of local observables in a\nmany-body system. Foligno et al. [Phys. Rev. X 13, 041008 (2023)] recently\nargued that the TE in chaotic 1d quantum circuits obeys linear (volume-law)\nscaling with evolution time. To reconcile this apparent high complexity of IM\nwith the rapid thermalization of local observables, here we study the relation\nbetween TE, non-Markovianity, and local temporal correlations for chaotic\nquantum baths. By exactly solving a random-unitary bath model, and bounding\ndistillable entanglement between future and past degrees of freedom, we argue\nthat TE is extensive for low enough bath growth rate, and it reflects genuine\nnon-Markovianity. This memory, however, is entirely contained in highly complex\ntemporal correlations, and its effect on few-point temporal correlators is\nnegligible. An IM coarse-graining procedure, reducing the allowed frequency of\nmeasurements of the probe system, results in a transition from volume- to\narea-law TE scaling. We demonstrate the generality of this TE transition in 1d\ncircuits by analyzing the kicked Ising model analytically at dual-unitary\npoints, as well as numerically away from them. This finding indicates that\ndynamics of local observables are fully captured by an area-law IM. We provide\nevidence that the compact IM MPS obtained via standard compression algorithms\naccurately describes local evolution."}
{"id": "2511.04277", "categories": ["physics.comp-ph", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2511.04277", "abs": "https://arxiv.org/abs/2511.04277", "authors": ["Bernat Frangi"], "title": "Novel Numerical Methods for Accurate Space Thermal Analysis: Enforcing View Factors and Modeling Diffuse Reflectivity", "comment": null, "summary": "Accurate thermal analysis is crucial for modern spacecraft, driving demand\nfor reliable modeling tools. This research advances space thermal modeling by\nimproving the simulation accuracy and efficiency of radiative heat transfer,\nthe dominant mode of heat exchange in space. To this end, we incorporate\ndiffuse reflectivity using the Gebhart method, which computes radiative\nexchange factors (REFs) from geometric view factors. The view factors, obtained\nvia Monte Carlo ray tracing (MCRT), require post-processing to mitigate\nstatistical errors. Critically, existing correction schemes cannot\nsimultaneously enforce closure and reciprocity for open systems. This research\naddresses this gap by proposing two novel enforcement methods: (i) a\nleast-squares optimization with non-negativity rectification (NNR) and small\npositive value avoidance (SPVA), and (ii) an iterative enforcement algorithm.\nTo ensure consistency across different discretization levels, this work also\nintroduces the multi-node surface model relations to formalize the connection\nbetween sub-face, face, and node representations of view factors and REFs. A\nsimple case study demonstrates a substantial reduction in mean absolute error\n(MAE): the least-squares method achieves an 81% MAE reduction, while the\niterative method offers the best balance of accuracy (56% MAE reduction) and\ncomputational efficiency. A second case study shows that including diffuse\nreflections decreases the steady-state temperature of a plate by $4^{\\circ}C$,\nreinforcing that reflected radiation reduces net absorption. This work\nintroduces and validates computationally efficient methods for integrating\ndiffuse reflectivity into space thermal analyses and for consistently coupling\nmulti-node surface radiative models. The results enable more accurate and\nrobust thermal predictions for spacecraft systems."}
{"id": "2511.03753", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.03753", "abs": "https://arxiv.org/abs/2511.03753", "authors": ["Youssef Elmir", "Yassine Himeur", "Abbes Amira"], "title": "Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices", "comment": "06 pages, 03 figures, accepted for presentation at the 7th IEEE\n  Computing, Communications and IoT Applications Conference (ComComAp 2025)", "summary": "This study presents a federated learning (FL) framework for\nprivacy-preserving electrocardiogram (ECG) classification in Internet of Things\n(IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian\nAngular Field (GAF) images, the proposed approach enables efficient feature\nextraction through Convolutional Neural Networks (CNNs) while ensuring that\nsensitive medical data remain local to each device. This work is among the\nfirst to experimentally validate GAF-based federated ECG classification across\nheterogeneous IoT devices, quantifying both performance and communication\nefficiency. To evaluate feasibility in realistic IoT settings, we deployed the\nframework across a server, a laptop, and a resource-constrained Raspberry Pi 4,\nreflecting edge-cloud integration in IoT ecosystems. Experimental results\ndemonstrate that the FL-GAF model achieves a high classification accuracy of\n95.18% in a multi-client setup, significantly outperforming a single-client\nbaseline in both accuracy and training time. Despite the added computational\ncomplexity of GAF transformations, the framework maintains efficient resource\nutilization and communication overhead. These findings highlight the potential\nof lightweight, privacy-preserving AI for IoT-based healthcare monitoring,\nsupporting scalable and secure edge deployments in smart health systems."}
{"id": "2511.03886", "categories": ["gr-qc", "astro-ph.HE", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.03886", "abs": "https://arxiv.org/abs/2511.03886", "authors": ["Erdem Sucu", "Kuantay Boshkayev", "Yassine Sekhmani", "İzzet Sakallı", "Mohsen Fathi"], "title": "Astrophysical Constraints on Charged Black Holes in Scalar--Tensor--Vector Gravity", "comment": "27 pages, 25 figures", "summary": "We explore charged black holes in Scalar-Tensor-Vector Gravity (STVG),\nunveiling their distinctive features across multiple physical domains. Our\ntopological analysis reveals that the STVG coupling parameter $\\alpha$ bolsters\nthermal stability while electromagnetic charge $Q$ weakens it. Using the\nGauss-Bonnet theorem, we find that $\\alpha$ amplifies light deflection and\nenlarges shadow silhouettes, with $Q$ generating opposite effects. Our\nquantum-corrected models with exponential entropy terms pinpoint phase\ntransitions in the microscopic regime, modifying conventional thermodynamic\nrelationships. Calculations of strong gravitational lensing, shadow geometry,\nand Hawking emission show clear STVG signatures that diverge from Einstein's\npredictions. Notably, our accretion disk analysis uncovers an intriguing\nphenomenon: specific combinations of $\\alpha$ and $Q$ can produce radiation\npatterns resembling spinning Kerr black holes, creating potential\nidentification challenges for observers. These findings establish concrete\nobservational tests for STVG theory through next generation astronomical\nimaging and lensing campaigns. By connecting theoretical predictions to\nmeasurable quantities, we outline specific pathways to confirm or constrain\nSTVG using data from current and future space telescopes."}
{"id": "2511.03870", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.03870", "abs": "https://arxiv.org/abs/2511.03870", "authors": ["Hokuto Iwakiri", "Keita Kanno"], "title": "On universality of hardware-efficient ansatzes", "comment": "21+10 pages, 21 figures", "summary": "The hardware-efficient ansatz (HEA) is one of the most important class of\nparametrized quantum circuits for near-term applications of quantum computing.\nWe show that the problem of simulating some major classes of the HEA is\nBQP-complete by explicitly demonstrating that any relevant quantum circuit can\nbe efficiently represented as an HEA circuit of those classes."}
{"id": "2511.04483", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04483", "abs": "https://arxiv.org/abs/2511.04483", "authors": ["Chaithanya Purushottam Bhat", "Pranav Suryawanshi", "Aditya Guneja", "Debashis Bandyopadhyay"], "title": "Unveiling the Adsorption and Electronic Interactions of Drugs on 2D Graphsene: Insights from DFT and Machine Learning Approach", "comment": "19 pages, 8 figures", "summary": "Efficient identification of promising drug candidates for nanomaterial-based\ndelivery systems is essential for advancing next-generation therapeutics. In\nthis work, we present a synergistic framework combining density functional\ntheory (DFT) and machine learning (ML) to explore the adsorption behavior and\nelectronic interactions of drugs on a novel 2D graphene allotrope, termed\nGraphsene (GrS). Graphsene, characterized by its porous ring topology and large\nsurface area, offers an excellent platform for efficient adsorption and strong\nelectronic coupling with drug molecules. A dataset comprising 67 drugs adsorbed\non various 2D substrates was employed to train the ML model, which was\nsubsequently applied to predict suitable drug candidates for GrS based on\nmolecular size and adsorption energy criteria (database link provided in a\nlater section). The ML model exhibited robust predictive accuracy, achieving a\nmean absolute error of 0.075 eV upon DFT validation, though its sensitivity to\ninitialization highlighted the need for larger and more diverse datasets.\nDFT-based analyses, including adsorption energetics, projected density of\nstates (PDOS), and Bader charge calculations, revealed pronounced charge\ntransfer and electronic coupling between the drug molecules and the GrS\nsurface, elucidating the fundamental nature of drug-substrate interactions. The\nstudy reveals that the integrated DFT-ML strategy offers a rapid,\ncost-efficient approach for screening and understanding drug-nanomaterial\ninteractions, paving the way for data-driven design of advanced\nnanomaterial-enabled drug delivery systems."}
{"id": "2511.03757", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03757", "abs": "https://arxiv.org/abs/2511.03757", "authors": ["Xuan Ouyang", "Senan Wang", "Bouzhou Wang", "Siyuan Xiahou", "Jinrong Zhou", "Yuekang Li"], "title": "Laugh, Relate, Engage: Stylized Comment Generation for Short Videos", "comment": null, "summary": "Short-video platforms have become a central medium in the modern Internet\nlandscape, where efficient information delivery and strong interactivity are\nreshaping user engagement and cultural dissemination. Among the various forms\nof user interaction, comments play a vital role in fostering community\nparticipation and enabling content re-creation. However, generating comments\nthat are both compliant with platform guidelines and capable of exhibiting\nstylistic diversity and contextual awareness remains a significant challenge.\nWe introduce LOLGORITHM, a modular multi-agent system (MAS) designed for\ncontrollable short-video comment generation. The system integrates video\nsegmentation, contextual and affective analysis, and style-aware prompt\nconstruction. It supports six distinct comment styles: puns (homophones),\nrhyming, meme application, sarcasm (irony), plain humor, and content\nextraction. Powered by a multimodal large language model (MLLM), LOLGORITHM\ndirectly processes video inputs and achieves fine-grained style control through\nexplicit prompt markers and few-shot examples. To support development and\nevaluation, we construct a bilingual dataset using official APIs from Douyin\n(Chinese) and YouTube (English), covering five popular video genres: comedy\nskits, daily life jokes, funny animal clips, humorous commentary, and talk\nshows. Evaluation combines automated metrics originality, relevance, and style\nconformity with a large-scale human preference study involving 40 videos and\n105 participants. Results show that LOLGORITHM significantly outperforms\nbaseline models, achieving preference rates of over 90% on Douyin and 87.55% on\nYouTube. This work presents a scalable and culturally adaptive framework for\nstylized comment generation on short-video platforms, offering a promising path\nto enhance user engagement and creative interaction."}
{"id": "2511.03959", "categories": ["gr-qc", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.03959", "abs": "https://arxiv.org/abs/2511.03959", "authors": ["Daniel R. Terno"], "title": "Apparent horizon as a membrane", "comment": "8+4 pages. Comments welcome!", "summary": "The requirement that a trapped spacetime domain forms in finite time for\ndistant observers is logically possible and sometimes unavoidable, but its\nconsequences are not yet fully understood. In spherical symmetry, the\ncharacterization of the near-horizon geometry of these physical black holes is\ncomplete and shows marked differences from their eternal counterparts. Whether\nthese differences lead to observable signatures remains unclear. We construct\nan approximate near-horizon metric that encapsulates them and is suitable for\nmodeling. The timelike apparent horizon of physical black holes provides a\nnatural surface for a consistent membrane description: we obtain closed-form\nexpressions for the redshift, proper acceleration, and extrinsic curvature, and\nassign a two-dimensional viscous-fluid stress tensor via junction conditions.\nThese results also provide an additional perspective on the relation between\nRindler and near-horizon geometries. Among dynamical generalizations of surface\ngravity, only a subset applies to these models. We complete their analysis and\nrecover the intuitive definition of surface gravity -- the acceleration in the\nframe of a near-horizon observer, redshifted to infinity -- directly from the\nmembrane acceleration."}
{"id": "2511.03874", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.03874", "abs": "https://arxiv.org/abs/2511.03874", "authors": ["Fariba Hosseinynejad", "Pavithran Iyer", "Guillaume Dauphinais", "David L. Feder"], "title": "Realistic GKP stabilizer states enable universal quantum computation", "comment": null, "summary": "Physical Gottesman-Kitaev-Preskill (GKP) states are inherently noisy as ideal\nones would require infinite energy. While this is typically considered as a\ndeficiency to be actively corrected, this work demonstrates that imperfect GKP\nstabilizer states can be leveraged in order to apply non-Clifford gates using\nonly linear optical elements. In particular, Gaussian operations on\nnormalizable GKP states, combined with homodyne measurements, permit two key\nprimitives: clean projection onto Pauli eigenstates in the normalizable GKP\ncodespace, thereby implementing Clifford gates with high fidelity; and\nprobabilistic projection of unmeasured modes onto non-Pauli eigenstates. These\nresults demonstrate that normalizable GKP stabilizer states combined with\nGaussian operations provide a practical framework for computational\nuniversality within the measurement-based model of quantum computation in a\nrealistic continuous-variable setting."}
{"id": "2511.04489", "categories": ["physics.comp-ph", "cs.DC", "cs.PF", "68W10 (Primary), 68W15, 65C05 (Secondary)", "D.1.3; G.3; I.6.8; J.2"], "pdf": "https://arxiv.org/pdf/2511.04489", "abs": "https://arxiv.org/abs/2511.04489", "authors": ["Oskar Lappi", "Huw Leggate", "Yannick Marandet", "Jan Åström", "Keijo Heljanko", "Dmitriy V. Borodin"], "title": "Scalable Domain-decomposed Monte Carlo Neutral Transport for Nuclear Fusion", "comment": "19 pages, 3 figures, submitted to Journal of Computational Physics", "summary": "EIRENE [1] is a Monte Carlo neutral transport solver heavily used in the\nfusion community. EIRENE does not implement domain decomposition, making it\nimpossible to use for simulations where the grid data does not fit on one\ncompute node (see e.g. [2]). This paper presents a domain-decomposed Monte\nCarlo (DDMC) algorithm implemented in a new open source Monte Carlo code,\nEiron. Two parallel algorithms currently used in EIRENE are also implemented in\nEiron, and the three algorithms are compared by running strong scaling tests,\nwith DDMC performing better than the other two algorithms in nearly all cases.\nOn the supercomputer Mahti [3], DDMC strong scaling is superlinear for grids\nthat do not fit into an L3 cache slice (4 MiB). The DDMC algorithm is also\nscaled up to 16384 cores in weak scaling tests, with a weak scaling efficiency\nof 45% in a high-collisional (heavier compute load) case, and 26% in a\nlow-collisional (lighter compute load) case. We conclude that implementing this\ndomain decomposition algorithm in EIRENE would improve performance and enable\nsimulations that are currently impossible due to memory constraints."}
{"id": "2511.03768", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03768", "abs": "https://arxiv.org/abs/2511.03768", "authors": ["Candace Ross", "Florian Bordes", "Adina Williams", "Polina Kirichenko", "Mark Ibrahim"], "title": "What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes", "comment": "10 pages, 6 figures. Accepted to NeurIPS Datasets & Benchmarks 2025", "summary": "Multimodal language models possess a remarkable ability to handle an\nopen-vocabulary's worth of objects. Yet the best models still suffer from\nhallucinations when reasoning about scenes in the real world, revealing a gap\nbetween their seemingly strong performance on existing perception benchmarks\nthat are saturating and their reasoning in the real world. To address this gap,\nwe build a novel benchmark of in-the-wild scenes that we call Common-O. With\nmore than 10.5k examples using exclusively new images not found in web training\ndata to avoid contamination, Common-O goes beyond just perception, inspired by\ncognitive tests for humans, to probe reasoning across scenes by asking \"what's\nin common?\". We evaluate leading multimodal language models, including models\nspecifically trained to perform chain-of-thought reasoning. We find that\nperceiving objects in single images is tractable for most models, yet reasoning\nacross scenes is very challenging even for the best models, including reasoning\nmodels. Despite saturating many leaderboards focusing on perception, the best\nperforming model only achieves 35% on Common-O -- and on Common-O Complex,\nconsisting of more complex scenes, the best model achieves only 1%. Curiously,\nwe find models are more prone to hallucinate when similar objects are present\nin the scene, suggesting models may be relying on object co-occurrence seen\nduring training. Among the models we evaluated, we found scale can provide\nmodest improvements while models explicitly trained with multi-image inputs\nshow bigger improvements, suggesting scaled multi-image training may offer\npromise. We make our benchmark publicly available to spur research into the\nchallenge of hallucination when reasoning across scenes."}
{"id": "2511.04007", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.04007", "abs": "https://arxiv.org/abs/2511.04007", "authors": ["Zhiming Shuai", "Xiangdong Zhang", "Gui-Rong Liang"], "title": "Scalar superradiance in the charged black-bounce spacetimes", "comment": "25 pages, 9 figures", "summary": "We numerically investigate the superradiant amplification effect of a charged\nscalar filed in the scattering experiment and the black hole bomb model in a\ncharged black-bounce spacetime. Due to the shallowing effect on the effective\npotential by the introduced quantum parameter $\\l$, superradiance in both the\nabove cases are verified to be weakened. In a scattering experiment, the\nquantum parameter and the field mass suppress the amplification in all\nfrequency ranges, while the black hole and field charge influence it\ndifferently in high and low frequencies. In a Type I black hole bomb model,\nwhere the reflective mirror is placed outside the ergo-region, we find a new\ndistinct eigen-mode for the scalar field evolution in a high $\\l$ value, which\nis however absent in the case of Type II black bomb where the mirror is set\ninside the ergo-region. Moreover, we investigate the heavy field mass scenario\nin a Type II black hole bomb and find no amplification effect in this confined\nconfiguration."}
{"id": "2511.03918", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.03918", "abs": "https://arxiv.org/abs/2511.03918", "authors": ["Henry C. Hammer", "Caleb Whittier", "Nathan A. Helvy", "Christopher Rouleau", "Nabil D. Bassim", "Ravitej Uppu"], "title": "Controlled growth of rare-earth-doped TiO$_{2}$ thin films on III-V semiconductors for hybrid quantum photonic interfaces", "comment": "30 pages, 10 figures", "summary": "Quantum photonic networks require two distinct functionalities: bright\nsingle-photon sources and long-lived quantum memories. III-V semiconductor\nquantum dots excel as deterministic and coherent photon emitters, while\nrare-earth ions such as erbium (Er$^{3+}$) in crystalline oxides offer\nexceptional spin and optical coherence at telecom wavelengths. Combining these\nsystems and their functionalities via direct epitaxy is challenging due to\nlattice mismatch and incompatible growth conditions. Here we demonstrate\nlow-temperature pulsed laser deposition of Er$^{3+}$-doped TiO$_{2}$ thin films\ndirectly on GaAs and GaSb substrates. Controlled surface preparation with an\narsenic cap and an oxygen-deficient buffer layer enables the growth of\nepitaxial anatase TiO$_{2}$ (001) at 390$^{o}$C with sub-300 pm surface\nroughness, while avoiding interface degradation. In contrast, high-temperature\noxide desorption or growth temperatures drive the transition to rough,\npolycrystalline rutile film, as confirmed by transmission electron microscopy.\nMinimal coincident interface area (MCIA) modeling explains the\norientation-selective growth on GaAs and GaSb. Raman and cryogenic\nphotoluminescence excitation spectroscopy verify the crystal phase and optical\nactivation of Er$^{3+}$ ions. This multi-parameter growth strategy helps\npreserve III-V quantum dot functionality and yields smooth surfaces suitable\nfor low-loss nanophotonic structures. Our results establish a materials\nplatform for monolithically integrating rare-earth quantum memories with\nsemiconductor photon sources, paving the way toward scalable hybrid quantum\nphotonic chips."}
{"id": "2511.04564", "categories": ["physics.comp-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04564", "abs": "https://arxiv.org/abs/2511.04564", "authors": ["Yoh-ichi Mototake", "Makoto Sasaki"], "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI", "comment": "17 pages, 6 figures", "summary": "Physics-informed machine learning (PIML) integrates partial differential\nequations (PDEs) into machine learning models to solve inverse problems, such\nas estimating coefficient functions (e.g., the Hamiltonian function) that\ncharacterize physical systems. This framework enables data-driven understanding\nand prediction of complex physical phenomena. While coefficient functions in\nPIML are typically estimated on the basis of predictive performance, physics as\na discipline does not rely solely on prediction accuracy to evaluate models.\nFor example, Kepler's heliocentric model was favored owing to small\ndiscrepancies in planetary motion, despite its similar predictive accuracy to\nthe geocentric model. This highlights the inherent uncertainties in data-driven\nmodel inference and the scientific importance of selecting physically\nmeaningful solutions. In this paper, we propose a framework to quantify and\nanalyze such uncertainties in the estimation of coefficient functions in PIML.\nWe apply our framework to reduced model of magnetohydrodynamics and our\nframework shows that there are uncertainties, and unique identification is\npossible with geometric constraints. Finally, we confirm that we can estimate\nthe reduced model uniquely by incorporating these constraints."}
{"id": "2511.03774", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03774", "abs": "https://arxiv.org/abs/2511.03774", "authors": ["Jaden Park", "Mu Cai", "Feng Yao", "Jingbo Shang", "Soochahn Lee", "Yong Jae Lee"], "title": "Contamination Detection for VLMs using Multi-Modal Semantic Perturbation", "comment": null, "summary": "Recent advances in Vision-Language Models (VLMs) have achieved\nstate-of-the-art performance on numerous benchmark tasks. However, the use of\ninternet-scale, often proprietary, pretraining corpora raises a critical\nconcern for both practitioners and users: inflated performance due to test-set\nleakage. While prior works have proposed mitigation strategies such as\ndecontamination of pretraining data and benchmark redesign for LLMs, the\ncomplementary direction of developing detection methods for contaminated VLMs\nremains underexplored. To address this gap, we deliberately contaminate\nopen-source VLMs on popular benchmarks and show that existing detection\napproaches either fail outright or exhibit inconsistent behavior. We then\npropose a novel simple yet effective detection method based on multi-modal\nsemantic perturbation, demonstrating that contaminated models fail to\ngeneralize under controlled perturbations. Finally, we validate our approach\nacross multiple realistic contamination strategies, confirming its robustness\nand effectiveness. The code and perturbed dataset will be released publicly."}
{"id": "2511.04010", "categories": ["gr-qc", "astro-ph.GA"], "pdf": "https://arxiv.org/pdf/2511.04010", "abs": "https://arxiv.org/abs/2511.04010", "authors": ["Tian-Yong Cao", "Shu-Xu Yi"], "title": "Probing Gravitational Wave Speed and Dispersion with LISA Observations of Supermassive Black Hole Binary Populations", "comment": "34 pages, 9 figures, accepted for publication in Physical Review D", "summary": "According to General Relativity (GR), gravitational waves (GWs) should travel\nat the speed of light $c$. However, some theories beyond GR predict deviations\nof the velocity of GWs $c_{\\rm gw}$ from $c$, and some of those expect vacuum\ndispersion. Therefore, probing the propagation effects of GWs by comparing the\nwave format detectors against the one at emission excepted from GR. Since such\npropagation effects accumulate through larger distance, it is expected that\nsuper-massive black holes binary (SMBHB) mergers serve as better targets than\ntheir stellarmass equivalent. In this paper, we study with simulations on how\nobservations on a population of SMBHs can help to study this topic. We simulate\nLISA observations on three possible SMBHB merger populations, namely\nPop\\MakeUppercase{\\romannumeral 3}, Q3-nod and Q3-d over a 5-year mission. The\nresulting constraints on the graviton mass are \\(9.50\\), \\(9.33\\), and \\(9.05\n\\times 10^{-27} \\, \\mathrm{eV}/c^2\\), respectively. We also obtain the\ncorresponding constraints on the dispersion coefficients assuming different\ndispersion scenarios. If the electromagnetic wave counterparts of SMBHB merger\ncan be detected simultaneously, the $c_{\\rm gw}$ can be constrained\nwaveform-independently to \\(\\Delta c/c\\) to \\(10^{-13}-10^{-12}\\),\ncorresponding to graviton mass constraints of \\(10^{-26}-10^{-24}\n\\mathrm{eV}/c^2\\)."}
{"id": "2511.03920", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.03920", "abs": "https://arxiv.org/abs/2511.03920", "authors": ["Itai Maimon"], "title": "Novel Encodings of Homology, Cohomology, and Characteristic Classes", "comment": "29 pages, 14 figures", "summary": "Topological quantum error-correcting codes (QECC) encode a variety of\ntopological invariants in their code space. A classic structure that has not\nbeen encoded directly is that of obstruction classes of a fiber bundle, such as\nthe Chern or Euler class. Here, we construct and analyze extensions of toric\ncodes. We then analyze the topological structure of their errors and finally\nconstruct a novel code using these errors to encode the obstruction class to a\nfiber bundle. In so doing, we construct an encoding of characteristic classes\nsuch as the Chern and Pontryagin class in topological QECC. An example of the\nEuler class of $S^2$ is constructed explicitly."}
{"id": "2511.04597", "categories": ["physics.comp-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.04597", "abs": "https://arxiv.org/abs/2511.04597", "authors": ["Sourav Karmakar", "Sutirtha Paul", "Adrian Del Maestro", "Barak Hirshberg"], "title": "Combining Harmonic Sampling with the Worm Algorithm to Improve the Efficiency of Path Integral Monte Carlo", "comment": null, "summary": "We propose an improved Path Integral Monte Carlo (PIMC) algorithm called\nHarmonic PIMC (H-PIMC) and its generalization, Mixed PIMC (M-PIMC). PIMC is a\npowerful tool for studying quantum condensed phases. However, it often suffers\nfrom a low acceptance ratio for solids and dense confined liquids. We develop\ntwo sampling schemes especially suited for such problems by dividing the\npotential into its harmonic and anharmonic contributions. In H-PIMC, we\ngenerate the imaginary time paths for the harmonic part of the potential\nexactly and accept or reject it based on the anharmonic part. In M-PIMC, we\nrestrict the harmonic sampling to the vicinity of local minimum and use\nstandard PIMC otherwise, to optimize efficiency. We benchmark H-PIMC on systems\nwith increasing anharmonicity, improving the acceptance ratio and lowering the\nauto-correlation time. For weakly to moderately anharmonic systems, at $\\beta\n\\hbar \\omega=16$, H-PIMC improves the acceptance ratio by a factor of 6-16 and\nreduces the autocorrelation time by a factor of 7-30. We also find that the\nmethod requires a smaller number of imaginary time slices for convergence,\nwhich leads to another two- to four-fold acceleration. For strongly anharmonic\nsystems, M-PIMC converges with a similar number of imaginary time slices as\nstandard PIMC, but allows the optimization of the auto-correlation time. We\nextend M-PIMC to periodic systems and apply it to a sinusoidal potential.\nFinally, we combine H- and M-PIMC with the worm algorithm, allowing us to\nobtain similar efficiency gains for systems of indistinguishable particles."}
{"id": "2511.03806", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03806", "abs": "https://arxiv.org/abs/2511.03806", "authors": ["Linghui Zeng", "Ruixuan Liu", "Atiquer Rahman Sarkar", "Xiaoqian Jiang", "Joyce C. Ho", "Li Xiong"], "title": "FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features", "comment": null, "summary": "Ensuring the privacy of sensitive training data is crucial in\nprivacy-preserving machine learning. However, in practical scenarios, privacy\nprotection may be required for only a subset of features. For instance, in ICU\ndata, demographic attributes like age and gender pose higher privacy risks due\nto their re-identification potential, whereas raw lab results are generally\nless sensitive. Traditional DP-SGD enforces privacy protection on all features\nin one sample, leading to excessive noise injection and significant utility\ndegradation. We propose FusionDP, a two-step framework that enhances model\nutility under feature-level differential privacy. First, FusionDP leverages\nlarge foundation models to impute sensitive features given non-sensitive\nfeatures, treating them as external priors that provide high-quality estimates\nof sensitive attributes without accessing the true values during model\ntraining. Second, we introduce a modified DP-SGD algorithm that trains models\non both original and imputed features while formally preserving the privacy of\nthe original sensitive features. We evaluate FusionDP on two modalities: a\nsepsis prediction task on tabular data from PhysioNet and a clinical note\nclassification task from MIMIC-III. By comparing against privacy-preserving\nbaselines, our results show that FusionDP significantly improves model\nperformance while maintaining rigorous feature-level privacy, demonstrating the\npotential of foundation model-driven imputation to enhance the privacy-utility\ntrade-off for various modalities."}
{"id": "2511.04163", "categories": ["gr-qc", "astro-ph.GA"], "pdf": "https://arxiv.org/pdf/2511.04163", "abs": "https://arxiv.org/abs/2511.04163", "authors": ["Zhen Li"], "title": "Observational Constrains on the Sgr A$^*$ Black Hole Immersed in a Dark Matter Halo: Shadow and S2 Star Orbit", "comment": "14 pages, 9 figures, 3 tables", "summary": "It is widely believed that Sgr A$^*$, located at the center of our Galaxy, is\na supermassive black hole. Recent observations of its shadow and long-term\nmonitoring of the S2 star have provided compelling evidence supporting this\nhypothesis. These observational advancements also offer valuable opportunities\nto explore the physical properties of the black hole and its surrounding\nenvironment. Since a dark matter halo is expected to exist in the Milky Way and\naround Sgr A$^*$, investigating the behavior of the Galactic Center black hole\nembedded in such a halo provides a crucial means to simultaneously probe both\nblack hole physics and dark matter properties. In this work, We develop a black\nhole metric that incorporates a generalized double power law dark matter halo,\nand analyze the corresponding null and timelike geodesics to investigate how\nthe halo parameters affect the black hole shadow and the motion of the S2 star.\nFurthermore, by comparing our theoretical predictions with observational data\nof the shadow and the S2 orbit, we constrained the dark matter halo parameters.\nThe results of this study provide both theoretical and phenomenological\ninsights into the nature of Sgr A$^*$ and the distribution of dark matter in\nour Galaxy."}
{"id": "2511.03935", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.03935", "abs": "https://arxiv.org/abs/2511.03935", "authors": ["Vahid Salari", "Yingwen Zhang", "Sepideh Ahmadi", "Dilip Paneru", "Duncan England", "Shabir Barzanjeh", "Robert Boyd", "Ebrahim Karimi", "Christoph Simon", "Daniel Oblak"], "title": "Quantum Optical Techniques for Biomedical Imaging", "comment": "20 pages, 8 figures", "summary": "Quantum imaging is emerging as a transformative approach for biomedical\napplications, applying nonclassical properties of light, such as entanglement,\nsqueezing, and quantum correlations, to overcome fundamental limits of\nconventional techniques. These methods promise superior spatial resolution,\nenhanced signal-to-noise ratios, improved phase sensitivity, and reduced\nradiation dose, for potentially safer and more precise imaging for delicate\nbiological samples. Here, we present an overview of quantum optical biomedical\nimaging technologies as well as quantum-inspired imaging methods, including\nquantum optical coherence tomography, quantum optical microscopy, ghost\nimaging, multi-parameter quantum imaging, and imaging with quantum-grade\ncameras. We describe the operating principles, biomedical applications, and\nunique advantages of each approach, along with the specific challenges for\ntheir translation into real-life practice. This review aims to guide future\nresearch toward advancing quantum imaging from experimental demonstrations to\nimpactful biomedical tools."}
{"id": "2511.04402", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04402", "abs": "https://arxiv.org/abs/2511.04402", "authors": ["Yi-Ming Ding", "Zenan Liu", "Xu Tian", "Zhe Wang", "Yanzhang Zhu", "Zheng Yan"], "title": "Mixed-State Measurement-Induced Phase Transitions in Imaginary-Time Dynamics", "comment": "15 pages, 12 figures", "summary": "Mixed-state phase transitions have recently attracted growing attention as a\nnew frontier in nonequilibrium quantum matter and quantum information. In this\nwork, we introduce the measurement-dressed imaginary-time evolution (MDITE) as\na novel framework to explore mixed-state quantum phases and decoherence-driven\ncriticality. In this setup, alternating imaginary-time evolution and projective\nmeasurements generate a competition between coherence-restoring dynamics and\ndecoherence-inducing events. While reminiscent of monitored unitary circuits,\nMDITE fundamentally differs in that the physics is encoded in decoherent mixed\nstates rather than in quantum trajectories. We demonstrate that this interplay\ngives rise to a new class of mixed-state phase transitions, using numerical\nsimulations of the one-dimensional transverse-field Ising model and the\ntwo-dimensional dimerized Heisenberg model. Furthermore, we provide a\ndiagrammatic representation of the evolving state, which naturally enables\nefficient studies of MDITE with quantum Monte Carlo and other many-body\nnumerical methods, thereby extending investigations of mixed-state phase\ntransitions to large-scale and higher-dimensional Hamiltonians. Our results\nhighlight MDITE as a powerful paradigm for investigating non-unitary dynamics\nand the fundamental role of decoherence in many-body quantum systems."}
{"id": "2511.03807", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03807", "abs": "https://arxiv.org/abs/2511.03807", "authors": ["Shivogo John"], "title": "Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations", "comment": "18 pages, 14 figures", "summary": "Evolving borrower behaviors, shifting economic conditions, and changing\nregulatory landscapes continuously reshape the data distributions underlying\nmodern credit-scoring systems. Conventional explainability techniques, such as\nSHAP, assume static data and fixed background distributions, making their\nexplanations unstable and potentially unfair when concept drift occurs. This\nstudy addresses that challenge by developing adaptive explanation frameworks\nthat recalibrate interpretability and fairness in dynamically evolving credit\nmodels. Using a multi-year credit dataset, we integrate predictive modeling via\nXGBoost with three adaptive SHAP variants: (A) per-slice explanation\nreweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP\nrebaselining with sliding-window background samples, and (C) online surrogate\ncalibration using incremental Ridge regression. Each method is benchmarked\nagainst static SHAP explanations using metrics of predictive performance (AUC,\nF1), directional and rank stability (cosine, Kendall tau), and fairness\n(demographic parity and recalibration). Results show that adaptive methods,\nparticularly rebaselined and surrogate-based explanations, substantially\nimprove temporal stability and reduce disparate impact across demographic\ngroups without degrading predictive accuracy. Robustness tests, including\ncounterfactual perturbations, background sensitivity analysis, and\nproxy-variable detection, confirm the resilience of adaptive explanations under\nreal-world drift conditions. These findings establish adaptive explainability\nas a practical mechanism for sustaining transparency, accountability, and\nethical reliability in data-driven credit systems, and more broadly, in any\ndomain where decision models evolve with population change."}
{"id": "2511.04236", "categories": ["gr-qc", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.04236", "abs": "https://arxiv.org/abs/2511.04236", "authors": ["Shi-Hao Zhang", "Zi-Yuan Li", "Jing-Fei Zhang", "Xin Zhang"], "title": "Geometric Unification of Timelike Orbital Chaos and Phase Transitions in Black Holes", "comment": "7 pages, 1 figure", "summary": "The deep connection between black hole thermodynamics and spacetime geometry\nremains a central focus of general relativity. While recent studies have\nrevealed a precise correspondence for null orbits, given by $K = -\\lambda^2$\nbetween the Gaussian curvature $K$ and the Lyapunov exponent $\\lambda$, its\nvalidity for timelike orbits had remained unknown. Our work introduces the\nmassive particle surface (MPS) framework and constructs a new geometric\nquantity $\\mathcal{G}$. We demonstrate that $\\mathcal{G} \\propto -\\lambda^2$ on\nunstable timelike orbits, thus establishing the geometry-dynamics\ncorrespondence for massive particles. Crucially, near the first-order phase\ntransition of a black hole, $\\mathcal{G}$ displays synchronized multivalued\nbehavior with the Lyapunov exponent $\\lambda$ and yields a critical exponent\n$\\delta=1/2$. Our results demonstrate that spacetime geometry encodes\nthermodynamic information, opening a new pathway for studying black hole phase\ntransitions from a geometric perspective."}
{"id": "2511.03947", "categories": ["quant-ph", "cond-mat.str-el", "hep-th", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2511.03947", "abs": "https://arxiv.org/abs/2511.03947", "authors": ["Akash Sinha", "Pramod Padmanabhan", "Vladimir Korepin"], "title": "Non-invertible Kramers-Wannier duality-symmetry in the trotterized critical Ising chain", "comment": "8 pages + Refs + Appendices", "summary": "Integrable trotterization provides a method to evolve a continuous time\nintegrable many-body system in discrete time, such that it retains its\nconserved quantities. Here we explicitly show that the first order\ntrotterization of the critical transverse field Ising model is integrable. The\ndiscrete time conserved quantities are obtained from an inhomogeneous transfer\nmatrix constructed using the quantum inverse scattering method. The\ninhomogeneity parameter determines the discrete time step. We then focus on the\nnon-invertible Kramers-Wannier duality-symmetry for the trotterized evolution.\nWe find that the discretization of both space and time leads to a doubling of\nthese duality operators. They account for discrete translations in both space\nand time. As an interesting application, we find that these operators also\nprovide maps between trotterizations of different orders. This helps us extend\nour results beyond the trotterization scheme and investigate the\nKramers-Wannier duality-symmetry for finite time Floquet evolution of the\ncritical transverse field Ising chain."}
{"id": "2511.04534", "categories": ["cs.LG", "physics.ao-ph", "physics.comp-ph", "I.6.5; I.2.6; G.3; J.2"], "pdf": "https://arxiv.org/pdf/2511.04534", "abs": "https://arxiv.org/abs/2511.04534", "authors": ["Jonas E. Katona", "Emily K. de Jong", "Nipun Gunawardena"], "title": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics", "comment": "Accepted at the NeurIPS 2025 Workshop on Machine Learning and the\n  Physical Sciences (ML4PS). 11 pages, 4 figures, 1 table. LLNL-CONF-2010541", "summary": "Reduced-order models (ROMs) can efficiently simulate high-dimensional\nphysical systems, but lack robust uncertainty quantification methods. Existing\napproaches are frequently architecture- or training-specific, which limits\nflexibility and generalization. We introduce a post hoc, model-agnostic\nframework for predictive uncertainty quantification in latent space ROMs that\nrequires no modification to the underlying architecture or training procedure.\nUsing conformal prediction, our approach estimates statistical prediction\nintervals for multiple components of the ROM pipeline: latent dynamics,\nreconstruction, and end-to-end predictions. We demonstrate the method on a\nlatent space dynamical model for cloud microphysics, where it accurately\npredicts the evolution of droplet-size distributions and quantifies uncertainty\nacross the ROM pipeline."}
{"id": "2511.03808", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03808", "abs": "https://arxiv.org/abs/2511.03808", "authors": ["Bo Zhao", "Berkcan Kapusuzoglu", "Kartik Balasubramaniam", "Sambit Sahu", "Supriyo Chakraborty", "Genta Indra Winata"], "title": "Optimizing Reasoning Efficiency through Prompt Difficulty Prediction", "comment": "NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Reasoning language models perform well on complex tasks but are costly to\ndeploy due to their size and long reasoning traces. We propose a routing\napproach that assigns each problem to the smallest model likely to solve it,\nreducing compute without sacrificing accuracy. Using intermediate\nrepresentations from s1.1-32B, we train lightweight predictors of problem\ndifficulty or model correctness to guide routing across a pool of reasoning\nmodels. On diverse math benchmarks, routing improves efficiency over random\nassignment and matches s1.1-32B's performance while using significantly less\ncompute. Our results demonstrate that difficulty-aware routing is effective for\ncost-efficient deployment of reasoning models."}
{"id": "2511.04467", "categories": ["gr-qc", "astro-ph.CO"], "pdf": "https://arxiv.org/pdf/2511.04467", "abs": "https://arxiv.org/abs/2511.04467", "authors": ["Philipp Neckam", "Christian Käding", "Benjamin Koch", "Cristobal Laporte", "Mario Pitschmann", "Ali Riahinia", "Angel Rincon"], "title": "Equivalence of scalar-tensor theories and scale-dependent gravity", "comment": "39 pages, 2 figures", "summary": "We present a novel equivalence between scale-dependent gravity and\nscalar-tensor theories that have only a single scalar field with a canonical\nkinetic term in the Einstein frame and a conformal coupling to the metric\ntensor. In particular, we show that the set of well-behaved scale-dependent\ngravity theories can be fully embedded into scalar-tensor theories in a unique\nway. Conversely, there are multiple ways to write a scalar-tensor theory as a\nscale-dependent theory. This equivalence is established both on the level of\nthe actions and on the level of field equations. We find that, in the context\nof this equivalence, the scale-setting relation $k(x)$ is naturally promoted to\na dynamical field, which is made manifest by including a corresponding kinetic\nterm in the scale-dependent action. In addition, we demonstrate that the new\nequivalence fits well into the framework of existing equivalences involving the\naforementioned theories and $f(R)$-gravity. Finally, we apply the equivalence\nrelations to explicit examples from both scale-dependent gravity and\nscalar-tensor theories."}
{"id": "2511.03977", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.03977", "abs": "https://arxiv.org/abs/2511.03977", "authors": ["Michael Warnock", "David A. Hague", "Vesna F. Mitrovic"], "title": "Multi-Directional Periodic Driving of a Two-Level System beyond Floquet Formalism", "comment": null, "summary": "In this manuscript, we introduce an exact expression for the response of a\nsemi-classical two-level quantum system subject to arbitrary periodic driving.\nDetermining the transition probabilities of a two-level system driven by an\narbitrary periodic waveform necessitates numerical calculations through methods\nsuch as Floquet theory, requiring the truncation of an infinite matrix.\nHowever, such truncation can lead to a loss of significant interference\ninformation, hindering quantum sensors or introducing artifacts in quantum\ncontrol. To alleviate this issue, we use the $\\star$-resolvent formalism with\nthe path-sum theorem to determine the exact series solution to Schr\\\"odinger's\nequation, therefore providing the exact transition probability. The resulting\nseries solution is generated from a compact kernel expression containing all of\nthe information of the periodic drive and then expanded in a non-harmonic\nFourier series basis given by the divided difference of complex exponentials\nwith coefficients corresponding to products of generalized Bessel functions.\nThe present method provides an analytical formulation for quantum sensors and\ncontrol applications."}
{"id": "2511.04649", "categories": ["gr-qc", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04649", "abs": "https://arxiv.org/abs/2511.04649", "authors": ["Krinio Marouda", "Daniela Cors", "Hannes R. Rüter", "Alex Vaño-Viñuales", "David Hilditch"], "title": "Twist and higher modes of a complex scalar field at the threshold of collapse", "comment": "20 pages, 10 figures", "summary": "We investigate the threshold of collapse of a massless complex scalar field\nin axisymmetric spacetimes under the ansatz of Choptuik et al. 2004, in which a\nsymmetry depending on the azimuthal parameter $m$ is imposed on the scalar\nfield. This allows for both non-vanishing twist and angular momentum. We extend\nearlier work to include higher angular modes. Using the pseudospectral code\nbamps with a new adapted symmetry reduction method, which we call $m$-cartoon,\nand a generalized twist-compatible apparent horizon finder, we evolve\nnear-critical initial data to the verge of black hole formation for the lowest\nnontrivial modes, $m=1$ and $m=2$. For $m=1$ we recover discrete\nself-similarity with echoing period $\\Delta\\simeq0.42$ and power-law scaling\nwith exponent $\\gamma\\simeq0.11$, consistent with earlier work. For $m=2$ we\nfind that universality is maintained within this nonzero fixed-$m$ symmetry\nclass but with smaller period and critical exponents, $\\Delta\\simeq0.09$ and\n$\\gamma\\simeq0.035$, establishing an explicit dependence of the critical\nsolution on the angular mode. Analysis of the relation between the angular\nmomentum and the mass of apparent horizons at the instant of formation,\n$J_{\\mathrm{AH}}{-}M_{\\mathrm{AH}}$, shows that the effect of angular momentum\nis minimal at the threshold, with\n$\\chi_{\\mathrm{AH}}=J_{\\mathrm{AH}}/M_{\\mathrm{AH}}^2\\to0$, and, therefore,\nexcludes extremal black holes for the families under consideration. Our results\ndemonstrate that while universality and DSS hold within each $m$-sector, the\ncritical universal values vary with $m$, and neither extremality nor\nbifurcation occur in the complex scalar field model within the families\nconsidered here."}
{"id": "2511.03809", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.03809", "abs": "https://arxiv.org/abs/2511.03809", "authors": ["François Belias", "Naser Ezzati-Jivan", "Foutse Khomh"], "title": "One Size Does Not Fit All: Architecture-Aware Adaptive Batch Scheduling with DEBA", "comment": "14 pages", "summary": "Adaptive batch size methods aim to accelerate neural network training, but\nexisting approaches apply identical adaptation strategies across all\narchitectures, assuming a one-size-fits-all solution. We introduce DEBA\n(Dynamic Efficient Batch Adaptation), an adaptive batch scheduler that monitors\ngradient variance, gradient norm variation and loss variation to guide batch\nsize adaptations. Through systematic evaluation across six architectures\n(ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V3, ViT-B16) on\nCIFAR-10 and CIFAR-100, with five random seeds per configuration, we\ndemonstrate that the architecture fundamentally determines adaptation efficacy.\nOur findings reveal that: (1) lightweight and medium-depth architectures\n(MobileNet-V3, DenseNet-121, EfficientNet-B0) achieve a 45-62% training speedup\nwith simultaneous accuracy improvements of 1-7%; (2) shallow residual networks\n(ResNet-18) show consistent gains of +2.4 - 4.0% in accuracy, 36 - 43% in\nspeedup, while deep residual networks (ResNet-50) exhibit high variance and\noccasional degradation; (3) already-stable architectures (ViT-B16) show minimal\nspeedup (6%) despite maintaining accuracy, indicating that adaptation benefits\nvary with baseline optimization characteristics. We introduce a baseline\ncharacterization framework using gradient stability metrics (stability score,\ngradient norm variation) that predicts which architectures will benefit from\nadaptive scheduling. Our ablation studies reveal critical design choices often\noverlooked in prior work: sliding window statistics (vs. full history) and\nsufficient cooldown periods (5+ epochs) between adaptations are essential for\nsuccess. This work challenges the prevailing assumption that adaptive methods\ngeneralize across architectures and provides the first systematic evidence that\nbatch size adaptation requires an architecture-aware design."}
{"id": "2511.04591", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.04591", "abs": "https://arxiv.org/abs/2511.04591", "authors": ["Mariia Churilova", "Zdeněk Stuchlík"], "title": "Stability of the rotating string loops in Kerr spacetime", "comment": "11 pages, 7 figures", "summary": "We study stability of the circular string loops rotating in the equatorial\nplane of Kerr spacetime against equatorial and polar perturbations. We consider\nmotion of such string loops for different modes in the case of arbitrary\nequation of state. We also obtain analytical expression for the fundamental\nfrequencies of the string loop oscillations under equatorial and polar\nperturbations."}
{"id": "2511.04018", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04018", "abs": "https://arxiv.org/abs/2511.04018", "authors": ["Mauricio Gutiérrez", "Chiranjib Mukhopadhyay", "Victor Montenegro", "Abolfazl Bayat"], "title": "Quantum error correction for multiparameter metrology", "comment": "6+8 pages, 5+1 figs, comments/suggestions welcome", "summary": "For single-parameter sensing, Greenberger-Horne-Zeilinger (GHZ) probes\nachieve optimal quantum-enhanced precision across the unknown parameter range,\nsolely relying on parameter-independent separable measurement strategies for\nall values of the unknown parameter. However, in the multiparameter setting, a\nsingle GHZ probe not only fails to achieve quantum advantage but also the\ncorresponding optimal measurement becomes complex and dependent on the unknown\nparameters. Here, we provide a recipe for multiparameter sensing with GHZ\nprobes using quantum error correction techniques by treating all but one\nunknown parameters as noise, whose effects can be corrected. This strategy\nrestores the core advantage of single parameter GHZ-based quantum sensing,\nnamely reaching optimally quantum-enhanced precision for all unknown parameter\nvalues while keeping the measurements separable and fixed. Specifically, given\none shielded ancilla qubit per GHZ probe, our protocol extracts optimal\npossible precision for any probe size. While this optimal precision is\nshot-noise limited for a single GHZ probe, we recover the Heisenberg scaling\nthrough use of multiple complementary GHZ probes. We demonstrate the\neffectiveness of the protocol with Bayesian estimation."}
{"id": "2511.03824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03824", "abs": "https://arxiv.org/abs/2511.03824", "authors": ["Ryien Hosseini", "Filippo Simini", "Venkatram Vishwanath", "Rebecca Willett", "Henry Hoffmann"], "title": "Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks", "comment": "To appear at NeurIPS 2025", "summary": "Graph Neural Networks learn on graph-structured data by iteratively\naggregating local neighborhood information. While this local message passing\nparadigm imparts a powerful inductive bias and exploits graph sparsity, it also\nyields three key challenges: (i) oversquashing of long-range information, (ii)\noversmoothing of node representations, and (iii) limited expressive power. In\nthis work we inject randomized global embeddings of node features, which we\nterm \\textit{Sketched Random Features}, into standard GNNs, enabling them to\nefficiently capture long-range dependencies. The embeddings are unique,\ndistance-sensitive, and topology-agnostic -- properties which we analytically\nand empirically show alleviate the aforementioned limitations when injected\ninto GNNs. Experimental results on real-world graph learning tasks confirm that\nthis strategy consistently improves performance over baseline GNNs, offering\nboth a standalone solution and a complementary enhancement to existing\ntechniques such as graph positional encodings. Our source code is available at\n\\href{https://github.com/ryienh/sketched-random-features}{https://github.com/ryienh/sketched-random-features}."}
{"id": "2511.04613", "categories": ["gr-qc", "astro-ph.CO", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.04613", "abs": "https://arxiv.org/abs/2511.04613", "authors": ["Ankit Anand", "Sahil Devdutt", "Kimet Jusufi", "Emmanuel N. Saridakis"], "title": "Effective matter sectors from modified entropies", "comment": "12 pages", "summary": "We present a general formalism linking modified entropy functions directly to\na modified spacetime metric and, subsequently, to an effective matter sector of\nentropic origin. In particular, within the framework of general relativity,\nstarting from the first law of black-hole thermodynamics we establish an\nexplicit correspondence between the entropy derivative and the metric function,\nwhich naturally leads to an emergent stress-energy tensor representing an\nanisotropic effective fluid. This backreaction effect of horizon entropy may\nresolve possible inconsistencies recently identified in black hole physics with\nmodified entropies. As specific examples, we apply this procedure to a wide\nclass of modified entropies, such as Barrow, Tsallis-Cirto, Renyi, Kaniadakis,\nlogarithmic, power-law, loop-quantum-gravity, and exponential modifications,\nand we derive the associated effective matter sectors, analyzing their physical\nproperties and energy conditions."}
{"id": "2511.04028", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04028", "abs": "https://arxiv.org/abs/2511.04028", "authors": ["Qing-Feng Xue", "Qi Zhang", "Xu-Cai Zhuang", "Yun-Jie Xia", "Enrico Russo", "Giulio Chiribella", "Rosario Lo Franco", "Zhong-Xiao Man"], "title": "Anomalous heat flow and quantum Otto cycle with indefinite causal order", "comment": "6 + 7 pages, 6 + 6 figures", "summary": "The principle that heat spontaneously flows from higher temperature to lower\ntemperature is a cornerstone of classical thermodynamics, often assumed to be\nindependent of the sequence of interactions. While this holds true for\nmacroscopic systems at equilibrium, here we show that, when the order of\ninteractions between two identical thermalization channels is indefinite, an\nanomalous heat flow emerges, whereby heat can sometime flow from a colder\nentity to a hotter one. Taking advantage of this anomalous heat flow, we design\na quantum Otto cycle with indefinite causal order, which not only achieves\nrefrigeration but also generates work. The anomalous heat flow and the quantum\nOtto cycle are experimentally simulated in a photonic quantum setup, which\nprovides a proof-of-principle demonstration of the theory."}
{"id": "2511.03828", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03828", "abs": "https://arxiv.org/abs/2511.03828", "authors": ["Lipeng Zu", "Hansong Zhou", "Xiaonan Zhang"], "title": "From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification", "comment": null, "summary": "Transitioning from offline to online reinforcement learning (RL) poses\ncritical challenges due to distributional shifts between the fixed behavior\npolicy in the offline dataset and the evolving policy during online learning.\nAlthough this issue is widely recognized, few methods attempt to explicitly\nassess or utilize the distributional structure of the offline data itself,\nleaving a research gap in adapting learning strategies to different types of\nsamples. To address this challenge, we propose an innovative method,\nEnergy-Guided Diffusion Stratification (StratDiff), which facilitates smoother\ntransitions in offline-to-online RL. StratDiff deploys a diffusion model to\nlearn prior knowledge from the offline dataset. It then refines this knowledge\nthrough energy-based functions to improve policy imitation and generate\noffline-like actions during online fine-tuning. The KL divergence between the\ngenerated action and the corresponding sampled action is computed for each\nsample and used to stratify the training batch into offline-like and\nonline-like subsets. Offline-like samples are updated using offline objectives,\nwhile online-like samples follow online learning strategies. We demonstrate the\neffectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL\nand IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff\nsignificantly outperforms existing methods, achieving enhanced adaptability and\nmore stable performance across diverse RL settings."}
{"id": "2511.04645", "categories": ["gr-qc", "math.DG", "53C50, 53C60 (primary), 83D05, 83C05, 35L05, 58J45 (secondary)"], "pdf": "https://arxiv.org/pdf/2511.04645", "abs": "https://arxiv.org/abs/2511.04645", "authors": ["Miguel Sánchez"], "title": "On the foundations and applications of Lorentz-Finsler Geometry", "comment": "56 pages, 20 figures", "summary": "Finslerian extensions of Special and General Relativity -- commonly referred\nto as Very Special and Very General Relativity -- necessitate the development\nof a unified Lorentz-Finsler geometry. However, the scope of this geometric\nframework extends well beyond relativistic physics. Indeed, it offers powerful\ntools for modeling wave propagation in classical mechanics, discretizing\nspacetimes in classical and relativistic settings, and supporting effective\ntheories in fundamental physics. Moreover, Lorentz-Finsler geometry provides a\nversatile setting that facilitates the resolution of problems within\nRiemannian, Lorentzian, and Finslerian geometries individually. This work\npresents a plain introduction to the subject, reviewing foundational concepts,\nkey applications, and future prospects.\n  The reviewed topics include (i) basics on the setting of cones, Finsler and\nLorentz-Finsler metrics and their (nonlinear, anisotropic and linear)\nconnections, (ii) the global structure of Lorentz-Finsler manifolds and its\nspace of null geodesics, (iii) links among Riemannian, Finsler and Lorentz\ngeometries, (iv) real world applications for wildfires and seisms, and\ndiscretization in classical and relativistic settings with quantum prospects,\nand (v) Finslerian variational approach to Einstein equations. The new results\ninclude the splitting of globally hyperbolic Finsler spacetimes, in addition to\nthe analysis of several extensions as the case of timelike boundaries."}
{"id": "2511.04100", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04100", "abs": "https://arxiv.org/abs/2511.04100", "authors": ["Kieran Flatt", "Joonwoo Bae"], "title": "Unifying contextual advantages in state discrimination", "comment": "9 pages, 4 figures", "summary": "Quantum state discrimination, alongside its other applications, has recently\nfound use as a tool for witnessing generalised contextuality. In this article,\nwe derive noncontextuality inequalities for both conclusive and inconclusive\noutcomes across various guessing strategies. For minimum- error discrimination,\nthe advantage is in terms of the confidences of individual outcomes, while for\nunambiguous state discrimination, it is in terms of the average guessing\nprobability. For maximum- confidence discrimination, we show that contextual\nadvantages occur not only for the confidence but also their average, the\nguessing probability, as well as the inconclusive outcome rate. Our results\nunify the contextual advantages across all state discrimination schemes and\nfigures of merit. We envisage that various quantum information applications\nbased on state discrimination may offer advantages over non-contextual\ntheories."}
{"id": "2511.03831", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.03831", "abs": "https://arxiv.org/abs/2511.03831", "authors": ["James Enouen", "Yujia Zheng", "Ignavier Ng", "Yan Liu", "Kun Zhang"], "title": "Higher-Order Causal Structure Learning with Additive Models", "comment": null, "summary": "Causal structure learning has long been the central task of inferring causal\ninsights from data. Despite the abundance of real-world processes exhibiting\nhigher-order mechanisms, however, an explicit treatment of interactions in\ncausal discovery has received little attention. In this work, we focus on\nextending the causal additive model (CAM) to additive models with higher-order\ninteractions. This second level of modularity we introduce to the structure\nlearning problem is most easily represented by a directed acyclic hypergraph\nwhich extends the DAG. We introduce the necessary definitions and theoretical\ntools to handle the novel structure we introduce and then provide\nidentifiability results for the hyper DAG, extending the typical Markov\nequivalence classes. We next provide insights into why learning the more\ncomplex hypergraph structure may actually lead to better empirical results. In\nparticular, more restrictive assumptions like CAM correspond to easier-to-learn\nhyper DAGs and better finite sample complexity. We finally develop an extension\nof the greedy CAM algorithm which can handle the more complex hyper DAG search\nspace and demonstrate its empirical usefulness in synthetic experiments."}
{"id": "2511.04649", "categories": ["gr-qc", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04649", "abs": "https://arxiv.org/abs/2511.04649", "authors": ["Krinio Marouda", "Daniela Cors", "Hannes R. Rüter", "Alex Vaño-Viñuales", "David Hilditch"], "title": "Twist and higher modes of a complex scalar field at the threshold of collapse", "comment": "20 pages, 10 figures", "summary": "We investigate the threshold of collapse of a massless complex scalar field\nin axisymmetric spacetimes under the ansatz of Choptuik et al. 2004, in which a\nsymmetry depending on the azimuthal parameter $m$ is imposed on the scalar\nfield. This allows for both non-vanishing twist and angular momentum. We extend\nearlier work to include higher angular modes. Using the pseudospectral code\nbamps with a new adapted symmetry reduction method, which we call $m$-cartoon,\nand a generalized twist-compatible apparent horizon finder, we evolve\nnear-critical initial data to the verge of black hole formation for the lowest\nnontrivial modes, $m=1$ and $m=2$. For $m=1$ we recover discrete\nself-similarity with echoing period $\\Delta\\simeq0.42$ and power-law scaling\nwith exponent $\\gamma\\simeq0.11$, consistent with earlier work. For $m=2$ we\nfind that universality is maintained within this nonzero fixed-$m$ symmetry\nclass but with smaller period and critical exponents, $\\Delta\\simeq0.09$ and\n$\\gamma\\simeq0.035$, establishing an explicit dependence of the critical\nsolution on the angular mode. Analysis of the relation between the angular\nmomentum and the mass of apparent horizons at the instant of formation,\n$J_{\\mathrm{AH}}{-}M_{\\mathrm{AH}}$, shows that the effect of angular momentum\nis minimal at the threshold, with\n$\\chi_{\\mathrm{AH}}=J_{\\mathrm{AH}}/M_{\\mathrm{AH}}^2\\to0$, and, therefore,\nexcludes extremal black holes for the families under consideration. Our results\ndemonstrate that while universality and DSS hold within each $m$-sector, the\ncritical universal values vary with $m$, and neither extremality nor\nbifurcation occur in the complex scalar field model within the families\nconsidered here."}
{"id": "2511.04110", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04110", "abs": "https://arxiv.org/abs/2511.04110", "authors": ["Ke-Xiong Yan", "Zhi-Cheng Shi", "Ye-Hong Chen", "Yan Xia"], "title": "Controllable Non-Hermitianity in Continuous-Variable Qubits", "comment": "7 pages, 4 figures, welcome to comments", "summary": "Pure dephasing is the dominant leak mechanism in photonic cat qubits because\nits phase errors disrupt the parity protection, rendering the qubit vulnerable\nto energy relaxation. In this manuscript, we reveal that this dephasing\nmechanism conceals an interesting physical phenomenon: it induces\n\\textit{asymmetric leakage} from the cat-state subspace, where even- and\nodd-parity cat states decay at different rates. This leak asymmetry enables the\ndynamics of the system to be described by a non-Hermitian Hamiltonian, thereby\ntransforming the cat qubit into a platform with controllable gain and loss for\nprobing non-Hermitian physics. Within this platform, we demonstrate the\npossibility to control the parity-time symmetry phase transition in a single\ncat qubit by adjusting its amplitude. Moreover, we couple two cat qubits to\nrealize an entanglement phase transition induced by the exceptional point. Our\nwork constructs a controllable non-Hermitian system simulator, overturning the\nconventional paradigm that treats dephasing as harmful noise."}
{"id": "2511.03836", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03836", "abs": "https://arxiv.org/abs/2511.03836", "authors": ["Lipeng Zu", "Hansong Zhou", "Xiaonan Zhang"], "title": "Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction", "comment": null, "summary": "Deep Q-Networks (DQNs) estimate future returns by learning from transitions\nsampled from a replay buffer. However, the target updates in DQN often rely on\nnext states generated by actions from past, potentially suboptimal, policy. As\na result, these states may not provide informative learning signals, causing\nhigh variance into the update process. This issue is exacerbated when the\nsampled transitions are poorly aligned with the agent's current policy. To\naddress this limitation, we propose the Successor-state Aggregation Deep\nQ-Network (SADQ), which explicitly models environment dynamics using a\nstochastic transition model. SADQ integrates successor-state distributions into\nthe Q-value estimation process, enabling more stable and policy-aligned value\nupdates. Additionally, it explores a more efficient action selection strategy\nwith the modeled transition structure. We provide theoretical guarantees that\nSADQ maintains unbiased value estimates while reducing training variance. Our\nextensive empirical results across standard RL benchmarks and real-world\nvector-based control tasks demonstrate that SADQ consistently outperforms DQN\nvariants in both stability and learning efficiency."}
{"id": "2511.04650", "categories": ["gr-qc", "astro-ph.CO", "astro-ph.HE", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.04650", "abs": "https://arxiv.org/abs/2511.04650", "authors": ["Dražen Glavan", "Alexander Vikman", "Tom Zlosnik"], "title": "On the Bondi accretion of a self-interacting complex scalar field", "comment": "47 pages, 24 figures", "summary": "Scalar fields with a global U(1) symmetry often appear in cosmology and\nastrophysics. We study the spherically-symmetric, stationary accretion of such\na classical field onto a Schwarzschild black hole in the test-field\napproximation. Thus, we consider the relativistic Bondi accretion beyond a\nsimplified perfect-fluid setup. We focus on the complex scalar field with\ncanonical kinetic term and with a generic quartic potential which either\npreserves the U(1) symmetry or exhibits spontaneous symmetry breaking. It is\nwell known that in the lowest order in gradient expansion the dynamics of such\na scalar field is well approximated by a perfect superfluid; we demonstrate\nthat going beyond this approximation systematically reduces the accretion rate\nwith respect to the perfect fluid case. Hence, black holes can provide a way to\ndistinguish a perfect fluid from its ultraviolet completion in form of the\ncomplex scalar field."}
{"id": "2511.04154", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04154", "abs": "https://arxiv.org/abs/2511.04154", "authors": ["Yanting Wang"], "title": "Expectation-Realization Interpretation of Quantum Superposition", "comment": "4 pages and 3 figures", "summary": "By comparing Schr\\\"odinger's cat with its classical counterpart, I show that\na quantum superposition should be understood as an expectation over possible\neigenstates weighted by wave-like probabilities. Upon the occurrence of a\ncertain event, the quantum system is randomly realized into one of the possible\neigenstates due to its intrinsic stochasticity. While the randomness of a\nsingle realization cannot be controlled or predicted, the overall distribution\ncan be regulated via experimental setup and converges as the number of events\nincreases. A measurement is indeed an activity employing a certain event to\nconvert a quantum effect into a macroscopic outcome. Consequently, the puzzling\nconcepts of wavefunction collapse, many worlds, and decoherence become\nunnecessary for understanding quantum superposition. This\nexpectation-realization interpretation, which integrates probability theory\nwith wave mechanics, can also be extended to quantum pathways. Moreover, it\nreframes tests of Bell's inequalities as validating the wave-like probability\nnature of quantum mechanics, with no need to invoke the mysterious notions of\nquantum non-locality and \"spooky action at a distance\"."}
{"id": "2511.03877", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03877", "abs": "https://arxiv.org/abs/2511.03877", "authors": ["Kimia Kazemian", "Zhenzhen Liu", "Yangfanyu Yang", "Katie Z Luo", "Shuhan Gu", "Audrey Du", "Xinyu Yang", "Jack Jansons", "Kilian Q Weinberger", "John Thickstun", "Yian Yin", "Sarah Dean"], "title": "Benchmark Datasets for Lead-Lag Forecasting on Social Platforms", "comment": null, "summary": "Social and collaborative platforms emit multivariate time-series traces in\nwhich early interactions-such as views, likes, or downloads-are followed,\nsometimes months or years later, by higher impact like citations, sales, or\nreviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an\nearly usage channel (the lead), predict a correlated but temporally shifted\noutcome channel (the lag). Despite the ubiquity of such patterns, LLF has not\nbeen treated as a unified forecasting problem within the time-series community,\nlargely due to the absence of standardized datasets. To anchor research in LLF,\nhere we present two high-volume benchmark datasets-arXiv (accesses -> citations\nof 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and\noutline additional domains with analogous lead-lag dynamics, including\nWikipedia (page views -> edits), Spotify (streams -> concert attendance),\ne-commerce (click-throughs -> purchases), and LinkedIn profile (views ->\nmessages). Our datasets provide ideal testbeds for lead-lag forecasting, by\ncapturing long-horizon dynamics across years, spanning the full spectrum of\noutcomes, and avoiding survivorship bias in sampling. We documented all\ntechnical details of data curation and cleaning, verified the presence of\nlead-lag dynamics through statistical and classification tests, and benchmarked\nparametric and non-parametric baselines for regression. Our study establishes\nLLF as a novel forecasting paradigm and lays an empirical foundation for its\nsystematic exploration in social and usage data. Our data portal with downloads\nand documentation is available at https://lead-lag-forecasting.github.io/."}
{"id": "2511.04185", "categories": ["quant-ph", "hep-ph"], "pdf": "https://arxiv.org/pdf/2511.04185", "abs": "https://arxiv.org/abs/2511.04185", "authors": ["Francesco Giacosa", "Anna Kolbus", "Krzysztof Kyziol", "Magdalena Plodowska", "Milena Piotrowska", "Karol Szary", "Arthur Vereijken"], "title": "Two-exponential decay of Acridine Orange", "comment": "Proceedings of the 2nd Symposium on new trends in nuclear and medical\n  physics, September 24-26, 2025, Jagiellonian University, Krakow, Poland. 6\n  pages, 1 figure, 1 table", "summary": "In this work, we experimentally study the fluorescence decay of Acridine\nOrange at late times, in order to test whether a late-time power-law behaviour\nemerges, a feature expected to be very small but consistent with quantum\nmechanical and quantum field theoretical predictions. Using two distinct photon\ndetectors, we find that the data are well described by a sum of two exponential\nfunctions with lifetimes $\\tau_1 = 1.7331 \\pm 0.001$ ns and $\\tau_2 = 5.948 \\pm\n0.012$ ns, in agreement with values reported in the literature. While no\ndeviation from the exponential decay law is observed, this study serves as a\nreliable test for the experimental setup and enables a precise determination of\nthe sample lifetimes."}
{"id": "2511.03911", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03911", "abs": "https://arxiv.org/abs/2511.03911", "authors": ["Sanggeon Yun", "Hyunwoo Oh", "Ryozo Masukawa", "Mohsen Imani"], "title": "DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets", "comment": "Accepted to DATE 2026", "summary": "Decomposition is a proven way to shrink deep networks without changing I/O.\nWe bring this idea to hyperdimensional computing (HDC), where footprint cuts\nusually shrink the feature axis and erode concentration and robustness. Prior\nHDC decompositions decode via fixed atomic hypervectors, which are ill-suited\nfor compressing learned class prototypes. We introduce DecoHD, which learns\ndirectly in a decomposed HDC parameterization: a small, shared set of per-layer\nchannels with multiplicative binding across layers and bundling at the end,\nyielding a large representational space from compact factors. DecoHD compresses\nalong the class axis via a lightweight bundling head while preserving native\nbind-bundle-score; training is end-to-end, and inference remains pure HDC,\naligning with in/near-memory accelerators. In evaluation, DecoHD attains\nextreme memory savings with only minor accuracy degradation under tight\ndeployment budgets. On average it stays within about 0.1-0.15% of a strong\nnon-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip\nnoise, reaches its accuracy plateau with up to ~97% fewer trainable parameters,\nand -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU\n(AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x\nover a baseline HDC ASIC."}
{"id": "2511.04188", "categories": ["quant-ph", "cs.CR", "cs.IT", "math.IT", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.04188", "abs": "https://arxiv.org/abs/2511.04188", "authors": ["Amir Yona", "Yaron Oz"], "title": "Quantum Key Distribution via Charge Teleportation", "comment": null, "summary": "We introduce a quantum key distribution (QKD) primitive based on charge\nteleportation: by Local Operations and Classical Communication (LOCC) on an\nentangled many-body ground state, Alice's one-bit choice steers the sign of a\nlocal charge shift at Bob, which directly encodes the key bit. Relative to\nenergy teleportation schemes, the charge signal is bit-symmetric, measured in a\nsingle basis, and markedly more robust to realistic noise and model\nimperfections. We instantiate the protocol on transverse-field Ising models,\nstar-coupled and one-dimensional chain, obtain closed-form results for two\nqubits, and for larger systems confirm performance via exact diagonalization,\ncircuit-level simulations, and a proof-of-principle hardware run. We quantify\nresilience to classical bit flips and local quantum noise, identifying regimes\nwhere sign integrity, and hence key correctness, is preserved. These results\nposition charge teleportation as a practical, low-rate QKD primitive compatible\nwith near-term platforms."}
{"id": "2511.03924", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03924", "abs": "https://arxiv.org/abs/2511.03924", "authors": ["Ekin Uğurel", "Cynthia Chen", "Brian H. Y. Lee", "Filipe Rodrigues"], "title": "On Predicting Sociodemographics from Mobility Signals", "comment": "22 pages, 8 figures", "summary": "Inferring sociodemographic attributes from mobility data could help\ntransportation planners better leverage passively collected datasets, but this\ntask remains difficult due to weak and inconsistent relationships between\nmobility patterns and sociodemographic traits, as well as limited\ngeneralization across contexts. We address these challenges from three angles.\nFirst, to improve predictive accuracy while retaining interpretability, we\nintroduce a behaviorally grounded set of higher-order mobility descriptors\nbased on directed mobility graphs. These features capture structured patterns\nin trip sequences, travel modes, and social co-travel, and significantly\nimprove prediction of age, gender, income, and household structure over\nbaselines features. Second, we introduce metrics and visual diagnostic tools\nthat encourage evenness between model confidence and accuracy, enabling\nplanners to quantify uncertainty. Third, to improve generalization and sample\nefficiency, we develop a multitask learning framework that jointly predicts\nmultiple sociodemographic attributes from a shared representation. This\napproach outperforms single-task models, particularly when training data are\nlimited or when applying models across different time periods (i.e., when the\ntest set distribution differs from the training set)."}
{"id": "2511.04194", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04194", "abs": "https://arxiv.org/abs/2511.04194", "authors": ["Ahmad Salmanogli", "Hesam Zandi"], "title": "Quantum Chip Co-Design for Fidelity and Entanglement Preservation", "comment": null, "summary": "This study introduces a superconducting quantum chip architecture designed to\nsimultaneously preserve entanglement and readout fidelity, addressing one of\nthe key trade-offs in the development of scalable quantum hardware. In\nconventional quantum circuits, strong qubit qubit coupling enhances\nentanglement but often leads to undesired crosstalk, dephasing, and reduced\nmeasurement fidelity. To mitigate these effects, we propose a hybrid multiqubit\nconfiguration consisting of nine transmon qubits organized into interior and\nexterior groups, interconnected via a flux tunable qubit and a network of\ndistributed resonators. The interior qubits along with tunable qubit form an\nentanglement core, while the exterior qubits operate in the dispersive regime\nunder large detuning to enable readout. The degree of entanglement can be\ndynamically tuned by adjusting the coupling between the central tunable qubit\nand the interior qubits. The total Hamiltonian includes all significant\ncoupling contributions, encompassing effective exchange interactions among\ninterior and exterior qubits, as well as their mediated couplings through\ninterface resonators. By numerically solving the complete Hamiltonian alongside\nthe Lindblad master equation, the system dynamics are characterized, allowing\nevaluation of both spectroscopic features and separation fidelity. Simulation\nresults demonstrate that the proposed design maintains strong entanglement by\ncreating the avoided-crossing region while sustaining measurement fidelity\naround 0.995 under realistic noise conditions. These findings confirm that\nentanglement strength and readout fidelity can be co-optimized within a single,\nreconfigurable architecture, establishing a viable route toward\nhigh-performance and scalable superconducting quantum processors."}
{"id": "2511.03928", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03928", "abs": "https://arxiv.org/abs/2511.03928", "authors": ["Arthur Chen", "Victor Zhong"], "title": "SynQuE: Estimating Synthetic Dataset Quality Without Annotations", "comment": "Under review", "summary": "We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE)\nproblem: ranking synthetic datasets by their expected real-world task\nperformance using only limited unannotated real data. This addresses a critical\nand open challenge where data is scarce due to collection costs or privacy\nconstraints. We establish the first comprehensive benchmarks for this problem\nby introducing and evaluating proxy metrics that choose synthetic data for\ntraining to maximize task performance on real data. We introduce the first\nproxy metrics for SynQuE by adapting distribution and diversity-based distance\nmeasures to our context via embedding models. To address the shortcomings of\nthese metrics on complex planning tasks, we propose LENS, a novel proxy that\nleverages large language model reasoning. Our results show that SynQuE proxies\ncorrelate with real task performance across diverse tasks, including sentiment\nanalysis, Text2SQL, web navigation, and image classification, with LENS\nconsistently outperforming others on complex tasks by capturing nuanced\ncharacteristics. For instance, on text-to-SQL parsing, training on the top-3\nsynthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to\n38.4 (+8.1)% on average compared to selecting data indiscriminately. This work\nestablishes SynQuE as a practical framework for synthetic data selection under\nreal-data scarcity and motivates future research on foundation model-based data\ncharacterization and fine-grained data selection."}
{"id": "2511.04225", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04225", "abs": "https://arxiv.org/abs/2511.04225", "authors": ["Xuan Zhang", "XIao-le Li", "Jingjing Niu", "Tongxing Yan", "Yuanzhen Chen"], "title": "Engineered Robustness for Nonadiabatic Geometric Quantum Gates", "comment": null, "summary": "While geometric quantum gates are often theorized to possess intrinsic\nresilience to control errors by exploiting the global properties of evolution\npaths, this promise has not consistently translated into practical robustness.\nWe present a streamlined framework for nonadiabatic geometric quantum gates\n(NGQGs) that incorporates additional auxiliary constraints to suppress\ndynamical contamination and achieve super-robust performance. Within this\nframework, we also design NGQGs using noncyclic paths, offering enhanced design\nflexibility. Implemented on superconducting transmon qubits, our scheme\nrealizes high-fidelity single-qubit gates that are robust against Rabi\namplitude error $\\epsilon$, with infidelity scaling as\n$\\mathcal{O}(\\epsilon^4)$, in contrast to the $\\mathcal{O}(\\epsilon^2)$\nbehavior of conventional dynamical gates. We further analyze two-qubit NGQGs\nunder parametric driving. Our results identify subtle limitations that\ncompromise performance in two-qubit scenarios, underscoring the importance of\nphase compensation and waveform calibration. The demonstrated simplicity and\ngenerality of our super-robust NGQG scheme make it applicable across diverse\nquantum platforms."}
{"id": "2511.03929", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03929", "abs": "https://arxiv.org/abs/2511.03929", "authors": ["NVIDIA", ":", "Amala Sanjay Deshmukh", "Kateryna Chumachenko", "Tuomas Rintamaki", "Matthieu Le", "Tyler Poon", "Danial Mohseni Taheri", "Ilia Karmanov", "Guilin Liu", "Jarno Seppanen", "Guo Chen", "Karan Sapra", "Zhiding Yu", "Adi Renduchintala", "Charles Wang", "Peter Jin", "Arushi Goel", "Mike Ranzinger", "Lukas Voegtle", "Philipp Fischer", "Timo Roman", "Wei Ping", "Boxin Wang", "Zhuolin Yang", "Nayeon Lee", "Shaokun Zhang", "Fuxiao Liu", "Zhiqi Li", "Di Zhang", "Greg Heinrich", "Hongxu", "Yin", "Song Han", "Pavlo Molchanov", "Parth Mannan", "Yao Xu", "Jane Polak Scowcroft", "Tom Balough", "Subhashree Radhakrishnan", "Paris Zhang", "Sean Cha", "Ratnesh Kumar", "Zaid Pervaiz Bhat", "Jian Zhang", "Darragh Hanley", "Pritam Biswas", "Jesse Oliver", "Kevin Vasques", "Roger Waleffe", "Duncan Riach", "Oluwatobi Olabiyi", "Ameya Sunil Mahabaleshwarkar", "Bilal Kartal", "Pritam Gundecha", "Khanh Nguyen", "Alexandre Milesi", "Eugene Khvedchenia", "Ran Zilberstein", "Ofri Masad", "Natan Bagrov", "Nave Assaf", "Tomer Asida", "Daniel Afrimi", "Amit Zuker", "Netanel Haber", "Zhiyu Cheng", "Jingyu", "Xin", "Di", "Wu", "Nik Spirin", "Maryam Moosaei", "Roman Ageev", "Vanshil Atul Shah", "Yuting Wu", "Daniel Korzekwa", "Unnikrishnan Kizhakkemadam Sreekumar", "Wanli Jiang", "Padmavathy Subramanian", "Alejandra Rico", "Sandip Bhaskar", "Saeid Motiian", "Kedi Wu", "Annie Surla", "Chia-Chih Chen", "Hayden Wolff", "Matthew Feinberg", "Melissa Corpuz", "Marek Wawrzos", "Eileen Long", "Aastha Jhunjhunwala", "Paul Hendricks", "Farzan Memarian", "Benika Hall", "Xin-Yu Wang", "David Mosallanezhad", "Soumye Singhal", "Luis Vega", "Katherine Cheung", "Krzysztof Pawelec", "Michael Evans", "Katherine Luna", "Jie Lou", "Erick Galinkin", "Akshay Hazare", "Kaustubh Purandare", "Ann Guan", "Anna Warno", "Chen Cui", "Yoshi Suhara", "Shibani Likhite", "Seph Mard", "Meredith Price", "Laya Sleiman", "Saori Kaji", "Udi Karpas", "Kari Briski", "Joey Conway", "Michael Lightstone", "Jan Kautz", "Mohammad Shoeybi", "Mostofa Patwary", "Jonathen Cohen", "Oleksii Kuchaiev", "Andrew Tao", "Bryan Catanzaro"], "title": "NVIDIA Nemotron Nano V2 VL", "comment": null, "summary": "We introduce Nemotron Nano V2 VL, the latest model of the Nemotron\nvision-language series designed for strong real-world document understanding,\nlong video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers\nsignificant improvements over our previous model,\nLlama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major\nenhancements in model architecture, datasets, and training recipes. Nemotron\nNano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and\ninnovative token reduction techniques to achieve higher inference throughput in\nlong document and video scenarios. We are releasing model checkpoints in BF16,\nFP8, and FP4 formats and sharing large parts of our datasets, recipes and\ntraining code."}
{"id": "2511.04242", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04242", "abs": "https://arxiv.org/abs/2511.04242", "authors": ["Yehor Hudenko", "Michal Kolář", "Radim Filip", "Artem Ryabov"], "title": "Local quantum coherence with intersource interactions at nonzero temperature", "comment": "28 pages, 3 figures", "summary": "Local quantum coherence in a two-level system (TLS) is typically generated\nvia time-dependent driving. However, it can also emerge autonomously from\nsymmetry-breaking interactions between the TLS and its surrounding environment\nat a low temperature. Although such environments often consist of interacting\natoms or spins, the role of interactions within the environment in generating\nthe autonomous local coherence has remained unexplored. Here, we address this\ngap by analyzing an exactly solvable model, which comprises a target TLS\ncoupled to $N$ interacting source TLSs that represent the environment, with the\nwhole system being in thermal equilibrium. We show that the local coherence not\nonly persists but can be enhanced at finite temperatures of the environment\ncompared to the case of no inter-source interactions. The temperature\ndependence of the coherence bears signatures of a quantum phase transition, and\nour analytical results suggest strategies for its optimization. Our findings\nreveal generic properties of the autonomously generated quantum coherence and\npoint to viable routes for observing the coherence at nonzero temperatures."}
{"id": "2511.03938", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03938", "abs": "https://arxiv.org/abs/2511.03938", "authors": ["Sanggeon Yun", "Hyunwoo Oh", "Ryozo Masukawa", "Pietro Mercati", "Nathaniel D. Bastian", "Mohsen Imani"], "title": "LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction", "comment": "Accepted to DATE 2026", "summary": "Hyperdimensional computing (HDC) suits memory, energy, and\nreliability-constrained systems, yet the standard \"one prototype per class\"\ndesign requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior\ncompaction reduces $D$ (feature axis), improving storage/compute but weakening\nrobustness. We introduce LogHD, a logarithmic class-axis reduction that\nreplaces the $C$ per-class prototypes with $n\\!\\approx\\!\\lceil\\log_k C\\rceil$\nbundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional\nactivation space, cutting memory to $O(D\\log_k C)$ while preserving $D$. LogHD\nuses a capacity-aware codebook and profile-based decoding, and composes with\nfeature-axis sparsification. Across datasets and injected bit flips, LogHD\nattains competitive accuracy with smaller models and higher resilience at\nmatched memory. Under equal memory, it sustains target accuracy at roughly\n$2.5$-$3.0\\times$ higher bit-flip rates than feature-axis compression; an ASIC\ninstantiation delivers $498\\times$ energy efficiency and $62.6\\times$ speedup\nover an AMD Ryzen 9 9950X and $24.3\\times$/$6.58\\times$ over an NVIDIA RTX\n4090, and is $4.06\\times$ more energy-efficient and $2.19\\times$ faster than a\nfeature-axis HDC ASIC baseline."}
{"id": "2511.04243", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04243", "abs": "https://arxiv.org/abs/2511.04243", "authors": ["Valter Uotila", "Väinö Mehtola", "Ilmo Salmenperä", "Bo Zhao"], "title": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes", "comment": "8 pages; 8 figures", "summary": "Leveraging data symmetries has been a key driver of performance gains in\ngeometric deep learning and geometric and equivariant quantum machine learning.\nWhile symmetrization appears to be a promising method, its practical overhead,\nsuch as additional gates, reduced expressibility, and other factors, is not\nwell understood in quantum machine learning. In this work, we develop an\nautomated pipeline to measure various characteristics of quantum machine\nlearning ansatzes with respect to symmetries that can appear in the learning\ntask. We define the degree of symmetry in the learning problem as the size of\nthe subgroup it admits. Subgroups define partial symmetries, which have not\nbeen extensively studied in previous research, which has focused on symmetries\ndefined by whole groups. Symmetrizing the 19 common ansatzes with respect to\nthese varying-sized subgroup representations, we compute three classes of\nmetrics that describe how the common ansatz structures behave under varying\namounts of symmetries. The first metric is based on the norm of the difference\nbetween the original and symmetrized generators, while the second metric counts\ndepth, size, and other characteristics from the symmetrized circuits. The third\nclass of metrics includes expressibility and entangling capability. The results\ndemonstrate varying gate overhead across the studied ansatzes and confirm that\nincreased symmetry reduces expressibility of the circuits. In most cases,\nincreased symmetry increases entanglement capability. These results help select\nsufficiently expressible and computationally efficient ansatze patterns for\ngeometric quantum machine learning applications."}
{"id": "2511.03939", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03939", "abs": "https://arxiv.org/abs/2511.03939", "authors": ["Raghav Sharma", "Manan Mehta", "Sai Tiger Raina"], "title": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is the standard for\naligning Large Language Models (LLMs), yet recent progress has moved beyond\ncanonical text-based methods. This survey synthesizes the new frontier of\nalignment research by addressing critical gaps in multi-modal alignment,\ncultural fairness, and low-latency optimization. To systematically explore\nthese domains, we first review foundational algo- rithms, including PPO, DPO,\nand GRPO, before presenting a detailed analysis of the latest innovations. By\nproviding a comparative synthesis of these techniques and outlining open\nchallenges, this work serves as an essential roadmap for researchers building\nmore robust, efficient, and equitable AI systems."}
{"id": "2511.04250", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04250", "abs": "https://arxiv.org/abs/2511.04250", "authors": ["Longcheng Li", "Xiaoming Sun", "Jialin Zhang", "Jiadong Zhu"], "title": "Space-Bounded Communication Complexity of Unitaries", "comment": null, "summary": "We study space-bounded communication complexity for unitary implementation in\ndistributed quantum processors, where we restrict the number of qubits per\nprocessor to ensure practical relevance and technical non-triviality. We model\ndistributed quantum processors using distributed quantum circuits with nonlocal\ntwo-qubit gates, defining the communication complexity of a unitary as the\nminimum number of such nonlocal gates required for its realization.\n  Our contributions are twofold. First, for general $n$-qubit unitaries, we\nimprove upon the trivial $O(4^n)$ communication bound. Considering $k$\npairwise-connected processors (each with $n/k$ data qubits and $m$ ancillas),\nwe prove the communication complexity satisfies $O\\left(\\max\\{4^{(1-1/k)n - m},\nn\\}\\right)$--for example, $O(2^n)$ when $m=0$ and $k=2$--and establish the\ntightness of this upper bound. We further extend the analysis to approximation\nmodels and general network topologies. Second, for special unitaries, we show\nthat both the Quantum Fourier Transform (QFT) and Clifford circuits admit\nlinear upper bounds on communication complexity in the exact model,\noutperforming the trivial quadratic bounds applicable to these cases. In the\napproximation model, QFT's communication complexity reduces drastically from\nlinear to logarithmic, while Clifford circuits retain a linear lower bound.\nThese results offer fundamental insights for optimizing communication in\ndistributed quantum unitary implementation, advancing the feasibility of\nlarge-scale distributed quantum computing (DQC) systems."}
{"id": "2511.03953", "categories": ["cs.LG", "eess.SP", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.03953", "abs": "https://arxiv.org/abs/2511.03953", "authors": ["Wuxia Chen", "Taposh Banerjee", "Vahid Tarokh"], "title": "Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels", "comment": null, "summary": "We address the problem of quickest change detection in Markov processes with\nunknown transition kernels. The key idea is to learn the conditional score\n$\\nabla_{\\mathbf{y}} \\log p(\\mathbf{y}|\\mathbf{x})$ directly from sample pairs\n$( \\mathbf{x},\\mathbf{y})$, where both $\\mathbf{x}$ and $\\mathbf{y}$ are\nhigh-dimensional data generated by the same transition kernel. In this way, we\navoid explicit likelihood evaluation and provide a practical way to learn the\ntransition dynamics. Based on this estimation, we develop a score-based CUSUM\nprocedure that uses conditional Hyvarinen score differences to detect changes\nin the kernel. To ensure bounded increments, we propose a truncated version of\nthe statistic. With Hoeffding's inequality for uniformly ergodic Markov\nprocesses, we prove exponential lower bounds on the mean time to false alarm.\nWe also prove asymptotic upper bounds on detection delay. These results give\nboth theoretical guarantees and practical feasibility for score-based detection\nin high-dimensional Markov models."}
{"id": "2511.04271", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04271", "abs": "https://arxiv.org/abs/2511.04271", "authors": ["Sergio Bengoechea", "Paul Over", "Thomas Rung"], "title": "Quantum time-marching algorithms for solving linear transport problems including boundary conditions", "comment": null, "summary": "This article presents the first complete application of a quantum\ntime-marching algorithm for simulating multidimensional linear transport\nphenomena with arbitrary boundaries, whereby the success probabilities are\nproblem intrinsic. The method adapts the linear combination of unitaries\nalgorithm to block encode the diffusive dynamics, while arbitrary boundary\nconditions are enforced by the method of images only at the cost of one\nadditional qubit per spatial dimension. As an alternative to the non-periodic\nreflection, the direct encoding of Neumann conditions by the unitary\ndecomposition of the discrete time-marching operator is proposed. All presented\nalgorithms indicate optimal success probabilities while maintaining linear time\ncomplexity, thereby securing the practical applicability of the quantum\nalgorithm on fault-tolerant quantum computers. The proposed time-marching\nmethod is demonstrated through state-vector simulations of the heat equation in\ncombination with Neumann, Dirichlet, and mixed boundary conditions."}
{"id": "2511.03966", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03966", "abs": "https://arxiv.org/abs/2511.03966", "authors": ["Mingliang Hou", "Yinuo Wang", "Teng Guo", "Zitao Liu", "Wenzhou Dou", "Jiaqi Zheng", "Renqiang Luo", "Mi Tian", "Weiqi Luo"], "title": "PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis", "comment": null, "summary": "The need to remove specific student data from cognitive diagnosis (CD) models\nhas become a pressing requirement, driven by users' growing assertion of their\n\"right to be forgotten\". However, existing CD models are largely designed\nwithout privacy considerations and lack effective data unlearning mechanisms.\nDirectly applying general purpose unlearning algorithms is suboptimal, as they\nstruggle to balance unlearning completeness, model utility, and efficiency when\nconfronted with the unique heterogeneous structure of CD models. To address\nthis, our paper presents the first systematic study of the data unlearning\nproblem for CD models, proposing a novel and efficient algorithm: hierarchical\nimportanceguided forgetting (HIF). Our key insight is that parameter importance\nin CD models exhibits distinct layer wise characteristics. HIF leverages this\nvia an innovative smoothing mechanism that combines individual and layer, level\nimportance, enabling a more precise distinction of parameters associated with\nthe data to be unlearned. Experiments on three real world datasets show that\nHIF significantly outperforms baselines on key metrics, offering the first\neffective solution for CD models to respond to user data removal requests and\nfor deploying high-performance, privacy preserving AI systems"}
{"id": "2511.04272", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04272", "abs": "https://arxiv.org/abs/2511.04272", "authors": ["Gaurang Agrawal", "Saptarshi Roy"], "title": "Random access Bell game by sequentially measuring the control of the quantum SWITCH", "comment": "19 pages, 3 figures", "summary": "Preserving quantum correlations such as Bell nonlocality in noisy\nenvironments remains a fundamental challenge for quantum technologies. We\nintroduce the Random Access Bell Game (RABG), a task where an entangled\nparticle propagates through a sequence of identical noisy blocks, and the\nability to violate a Bell inequality is tested at a randomly chosen point\n(access node). We consider a scenario where each noisy block is composed of two\ncomplete erasure channels, an extreme entanglement-breaking channel with\nvanishing quantum and classical capacities. We investigate the performance of\nthe Random Access Bell Game in this configuration and attempt to mitigate the\neffect of noise by coherently controlling the order of each channel in the\nnoise using the quantum {\\tt SWITCH}. However, the quantum {\\tt SWITCH} in its\ncanonical setup with a coherent state in the control fails to provide any\nadvantage in the Random Access Bell Game. Our main contribution is a protocol\nthat leverages initial entanglement between the target and control of the\nquantum {\\tt SWITCH} and employs sequential, unsharp measurements on the\ncontrol system, showing that it is possible to guarantee a Bell violation after\nan arbitrarily large number of channel applications. Furthermore, our protocol\nallows for a near-maximal (Tsirelson bound) Bell violation to be achieved at\nany desired round, while still ensuring violations in all preceding rounds. We\nprove that this advantage is specific to generalized\nGreenberger-Horne-Zeilinger (GHZ) states, as the protocol fails for W-class\nstates, thus providing an operational way to distinguish between these two\nfundamental classes of multipartite entanglement."}
{"id": "2511.03972", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03972", "abs": "https://arxiv.org/abs/2511.03972", "authors": ["Semih Cayci"], "title": "Non-Asymptotic Optimization and Generalization Bounds for Stochastic Gauss-Newton in Overparameterized Models", "comment": null, "summary": "An important question in deep learning is how higher-order optimization\nmethods affect generalization. In this work, we analyze a stochastic\nGauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch\nsampling for training overparameterized deep neural networks with smooth\nactivations in a regression setting. Our theoretical contributions are twofold.\nFirst, we establish finite-time convergence bounds via a variable-metric\nanalysis in parameter space, with explicit dependencies on the batch size,\nnetwork width and depth. Second, we derive non-asymptotic generalization bounds\nfor SGN using uniform stability in the overparameterized regime, characterizing\nthe impact of curvature, batch size, and overparameterization on generalization\nperformance. Our theoretical results identify a favorable generalization regime\nfor SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along\nthe optimization path yields tighter stability bounds."}
{"id": "2511.04274", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04274", "abs": "https://arxiv.org/abs/2511.04274", "authors": ["Jan Sperling", "Laura Ares", "Elizabeth Agudelo"], "title": "Quasiprobabilities from incomplete and overcomplete measurements", "comment": null, "summary": "We discuss the (re-)construction of quasiprobability representations from\ngeneric measurements, including noisy ones. Based on the measurement under\nstudy, quasiprobabilities and the associated concept of nonclassicality are\nintroduced. A practical concern that we address is the treatment of\ninformationally incomplete and overcomplete measurement scenarios, which can\nsignificantly alter the assessment of which states are deemed classical.\nNotions, such as Kirkwood-Dirac quasiprobabilities and s-parametrized\nquasiprobabilities in quantum optics, are generalized by our approach.\nSingle-qubit systems are used to exemplify and to compare different measurement\nschemes, together with the resulting quasiprobabilities and set of nonclassical\nstates."}
{"id": "2511.03976", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2511.03976", "abs": "https://arxiv.org/abs/2511.03976", "authors": ["Xu Zou"], "title": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction", "comment": "preprint", "summary": "Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable\nevolutionary trajectory, characterized by the continual emergence of\nimmune-evasive variants. This poses persistent challenges to public health and\nvaccine development.\n  While large-scale generative pre-trained transformers (GPTs) have\nrevolutionized the modeling of sequential data, their direct applications to\nnoisy viral genomic sequences are limited. In this paper, we introduce\nPETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based\non evolutionary trajectories derived from phylogenetic trees rather than raw\nRNA sequences. This method effectively mitigates sequencing noise and captures\nthe hierarchical structure of viral evolution.\n  With a weighted training framework to address substantial geographical and\ntemporal imbalances in global sequence data, PETRA excels in predicting future\nSARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide\nmutations and 17.10\\% for spike amino-acid mutations, compared to 0.49% and\n6.64% respectively for the best baseline. PETRA also demonstrates its ability\nto aid in the real-time mutation prediction of major clades like 24F(XEC) and\n25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra"}
{"id": "2511.04297", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04297", "abs": "https://arxiv.org/abs/2511.04297", "authors": ["Yehonatan Levin", "Uri Israeli", "Rivka Bekenstein"], "title": "Cluster States Generation with a Quantum Metasurface", "comment": null, "summary": "We investigate the implementation of photonic cluster state generation\nprotocols using quantum metasurfaces comprising sub-wavelength atomic arrays\nwhich enables quantum-controlled reflectivity. These cluster states are\ngenerated using fundamental quantum logic gates and enable wide-ranging\napplications in quantum computation and communication. In the past few years,\ncertain protocols have been developed, but their physical realizations induces\nnatural losses on the system mainly originated from coupling the photonic\nstructures, setting a limit on the efficiency and maximal qubit number. In this\npaper, we examine a physical implementation of two specific protocols for\ngenerating distinct cluster states: a two-dimensional cluster state and a tree\ncluster state. Our approach leverages the unique properties of a quantum\nmetasurface and its free space settings to implement two-qubit quantum-logic\ngates, namely CNOT, CZ, and E gates, with practical fidelities exceeding 0.9,\nand potential speed-up due to parallelism. In addition, we analyze these\nprotocols fidelities for practical conditions of potential implementation\nexperiments, such as thermal fluctuation of trapped atoms."}
{"id": "2511.03981", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03981", "abs": "https://arxiv.org/abs/2511.03981", "authors": ["Yuxiao Wang", "Di Wu", "Feng Liu", "Zhimin Qiu", "Chenrui Hu"], "title": "Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models", "comment": null, "summary": "This paper proposes a composable fine-tuning method that integrates graph\nstructural priors with modular adapters to address the high computational cost\nand structural instability faced by large-scale pre-trained models in\nmulti-task adaptation. The method introduces a relation matrix to model\ndependencies among tasks, explicitly encoding correlations between nodes and\npaths into graph structural priors, which provide unified structural\nconstraints for adapter weight allocation and path selection. Modular adapters\nare embedded into different layers through low-rank mapping and a pluggable\nmechanism, enabling efficient cross-task composition and reuse under prior\nguidance. This mechanism not only improves parameter efficiency and training\nstability but also alleviates path conflicts and redundant computation in\nmulti-task scenarios. Furthermore, experiments on hyperparameter sensitivity,\nenvironmental sensitivity, and data sensitivity are conducted to systematically\nanalyze key factors such as routing temperature, gating thresholds, and\nrelation matrix regularization strength, verifying the consistency and superior\nperformance of the method under structural constraints. The results demonstrate\nthat the proposed framework significantly enhances task prediction accuracy,\nadapter weight allocation precision, and overall computational efficiency while\nmaintaining model lightweight design, highlighting the synergistic advantages\nof graph priors and modular mechanisms in composable fine-tuning."}
{"id": "2511.04300", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.04300", "abs": "https://arxiv.org/abs/2511.04300", "authors": ["Ramy Aboushelbaya", "Annika Moslein", "Hadi Azar", "Hamid Tanhaei", "Marko von der Leyen"], "title": "Self-correcting High-speed Opto-electronic Probabilistic Computer", "comment": null, "summary": "We present a novel self-correcting, high-speed optoelectronic probabilistic\ncomputer architecture that leverages source-device independent (SDI) quantum\nphotonic p-bits integrated with robust electronic control. Our approach\ncombines the intrinsic randomness and high bandwidth of quantum photonics with\nthe programmability and scal- ability of classical electronics, enabling\nefficient and flexible probabilistic computation. We detail the design and\nimplementation of a prototype system based on photonic integrated circuits and\nFPGA-based control, capable of implementing and manipulating 64000 logical\np-bits. Experimental results demonstrate that our architecture achieves a flip\nrate of 2.7 x 10^9 flips/s with an energy consumption of 4.9 nJ/flip,\nrepresenting nearly three orders of magnitude improvement in speed and energy\nefficiency compared to state-of-the-art magnetic tunnel junc- tion (MTJ) based\nsystems. Furthermore, the SDI protocol enables real-time self-certification and\nerror correction, ensuring reliable operation across a wide range of conditions\nand solving the problem of hardware variability as the number of p-bits scale.\nOur results establish quantum photonic p-bits as a promising platform for\nscalable, high-performance probabilistic computing, with significant\nimplications for combinatorial optimization, machine learning, and complex\nsystem modeling."}
{"id": "2511.03983", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.03983", "abs": "https://arxiv.org/abs/2511.03983", "authors": ["Michael Menezes", "Barbara Su", "Xinze Feng", "Yehya Farhat", "Hamza Shili", "Anastasios Kyrillidis"], "title": "TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training", "comment": null, "summary": "We introduce TwIST, a distributed training framework for efficient large\nlanguage model (LLM) sparsification. TwIST trains multiple subnetworks in\nparallel, periodically aggregates their parameters, and resamples new\nsubnetworks during training. This process identifies high-quality subnetworks\n(\"golden tickets\") without requiring post-training procedures such as\ncalibration or Hessian-based recovery. As a result, TwIST enables zero-cost\npruning at deployment time while achieving perplexity competitive with\nstate-of-the-art post-training sparsification methods. The benefits are most\npronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly\noutperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64\nfor the closest prior approach. Unlike unstructured pruning, TwIST produces\nstructured, dense matrices that offer practical inference speedups and memory\nreductions on commodity hardware (e.g., CPUs) that do not support efficient\nsparse computation. TwIST provides an efficient training-time path to\ndeployable sparse LLMs without additional fine-tuning or recovery overhead."}
{"id": "2511.04339", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04339", "abs": "https://arxiv.org/abs/2511.04339", "authors": ["Federico Settimo", "Bassano Vacchini"], "title": "Synchronization effects in a periodically driven two-level system", "comment": "7 pages, 6 figures", "summary": "We study phase-synchronization in a driven two-level system coupled to a\nnon-Markovian bosonic reservoir. The dynamics is described by treating the\nsystem-bath coupling and the coherent drive without invoking the rotating-wave\napproximation, and simulated using the numerically exact hierarchical equations\nof motion. We observe that a robust phase-locking develops and that the\ncorresponding synchronization measure rapidly acquires a finite value when the\nsystem is tuned to what we identify as a resonant-ratio condition, namely when\nthe ratio between the drive amplitude and its frequency coincides with a zero\nof the Bessel function $J_0$. We provide an explanation for this phenomenon by\nmeans of a static approximation derived from a Fourier analysis of the\nperiodically driven Hamiltonian."}
{"id": "2511.03986", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03986", "abs": "https://arxiv.org/abs/2511.03986", "authors": ["Ahmed A. Metwally", "Heyjun Park", "Yue Wu", "Tracey McLaughlin", "Michael P. Snyder"], "title": "Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes", "comment": "18 pages, 8 figures", "summary": "The classification of diabetes and prediabetes by static glucose thresholds\nobscures the pathophysiological dysglycemia heterogeneity, primarily driven by\ninsulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This\nreview demonstrates that continuous glucose monitoring and wearable\ntechnologies enable a paradigm shift towards non-invasive, dynamic metabolic\nphenotyping. We show evidence that machine learning models can leverage\nhigh-resolution glucose data from at-home, CGM-enabled oral glucose tolerance\ntests to accurately predict gold-standard measures of muscle IR and beta-cell\nfunction. This personalized characterization extends to real-world nutrition,\nwhere an individual's unique postprandial glycemic response (PPGR) to\nstandardized meals, such as the relative glucose spike to potatoes versus\ngrapes, could serve as a biomarker for their metabolic subtype. Moreover,\nintegrating wearable data reveals that habitual diet, sleep, and physical\nactivity patterns, particularly their timing, are uniquely associated with\nspecific metabolic dysfunctions, informing precision lifestyle interventions.\nThe efficacy of dietary mitigators in attenuating PPGR is also shown to be\nphenotype-dependent. Collectively, this evidence demonstrates that CGM can\ndeconstruct the complexity of early dysglycemia into distinct, actionable\nsubphenotypes. This approach moves beyond simple glycemic control, paving the\nway for targeted nutritional, behavioral, and pharmacological strategies\ntailored to an individual's core metabolic defects, thereby paving the way for\na new era of precision diabetes prevention."}
{"id": "2511.04354", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.04354", "abs": "https://arxiv.org/abs/2511.04354", "authors": ["Yaru Liu", "Yucheng Wang"], "title": "A General Strategy for Realizing Mpemba Effects in Open Quantum Systems", "comment": "under review", "summary": "The Mpemba effect, where a state farther from equilibrium relaxes faster than\none closer to it, is a striking phenomenon in both classical and quantum\nsystems. In open quantum systems, however, the quantum Mpemba effect (QME)\ntypically occurs only for specifically chosen initial states, which limits its\nuniversality. Here we present a general and experimentally feasible strategy to\nrealize both QME and anti-QME. By applying a temporary bond-dissipation quench,\nwe selectively suppresses or enhances slow relaxation modes, thereby reshaping\nrelaxation pathways independently of both the system and the initial state. We\ndemonstrate this mechanism in systems with dephasing and boundary dissipation,\nand outline feasible cold-atom implementations. Our results establish\ncontrollable dissipation as a versatile tool for quantum control, accelerated\nrelaxation, and efficient nonequilibrium protocols."}
{"id": "2511.03993", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.03993", "abs": "https://arxiv.org/abs/2511.03993", "authors": ["Berk Iskar", "Michael Taynnan Barros"], "title": "Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection", "comment": null, "summary": "Network anomaly detection systems encounter several challenges with\ntraditional detectors trained offline. They become susceptible to concept drift\nand new threats such as zero-day or polymorphic attacks. To address this\nlimitation, we propose a Ca$^{2+}$-modulated learning framework that draws\ninspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid,\ncontext-sensitive adaptation enables robust information processing. Our\napproach couples a multicellular astrocyte dynamics simulator with a deep\nneural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics\nthrough three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump\nuptake, and conductance-aware diffusion through gap junctions between cells.\nEvaluation of our proposed network on CTU-13 (Neris) network traffic data\ndemonstrates the effectiveness of our biologically plausible approach. The\nCa$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to\n$\\sim$98\\% accuracy with reduced false positives and negatives across multiple\ntrain/test splits. Importantly, this improved performance comes with negligible\nruntime overhead once Ca$^{2+}$ trajectories are precomputed. While\ndemonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated\nlearning framework offers a generic solution for streaming detection tasks that\nrequire rapid, biologically grounded adaptation to evolving data patterns."}
{"id": "2511.04359", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04359", "abs": "https://arxiv.org/abs/2511.04359", "authors": ["Sinchan Snigdha Rej", "Bimalendu Deb"], "title": "Neutral-atom quantum computation using multi-qubit geometric gates via adiabatic passage", "comment": null, "summary": "Adiabatic geometric phase gates offer enhanced robustness against\nfluctuations compared to con- ventional Rydberg blockade-based phase gates that\nrely on dynamical phase accumulation. We theoretically demonstrate two- and\nmulti-qubit phase gates in a neutral atom architecture, relying on a double\nstimulated Raman adiabatic passage (double-STIRAP) pulse sequence that imprints\na controllable geometric phase on the qubit systems. The system is designed in\nsuch a way that every atom is individually addressable, and moreover, no extra\nlaser is required to be applied on the target atom while scaling up the system\nfrom two- to multi-qubit quantum gates. The gate fidelity has been numerically\nanalyzed by changing the gate operation time, and we find that 98% to 99%\nfidelity can be achieved for gate time $\\simeq$ 0.6 $\\mu$s. We perform a\nsystematic error analysis, which re- veals that our proposed gates can exhibit\nstrong resilience against fluctuations in Rabi frequencies, finite blockade\nstrength, and atomic position variations. These results establish our approach\nas a physically feasible and scalable pathway toward fault-tolerant quantum\ncomputation with neutral atoms. We simulate Grover's search algorithm for two-,\nthree-, and four-qubit systems with high success probability and thereby\ndemonstrate the utility and scalability of our proposed gates for quantum\ncomputation."}
{"id": "2511.04000", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04000", "abs": "https://arxiv.org/abs/2511.04000", "authors": ["Kyaw Hpone Myint", "Zhe Wu", "Alexandre G. R. Day", "Giri Iyengar"], "title": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations", "comment": "9 pages, 3 figures, Neurips 2025 GenAI in Finance Workshop", "summary": "Decision trees are widely used in high-stakes fields like finance and\nhealthcare due to their interpretability. This work introduces an efficient,\nscalable method for generating synthetic pre-training data to enable\nmeta-learning of decision trees. Our approach samples near-optimal decision\ntrees synthetically, creating large-scale, realistic datasets. Using the\nMetaTree transformer architecture, we demonstrate that this method achieves\nperformance comparable to pre-training on real-world data or with\ncomputationally expensive optimal decision trees. This strategy significantly\nreduces computational costs, enhances data generation flexibility, and paves\nthe way for scalable and efficient meta-learning of interpretable decision tree\nmodels."}
{"id": "2511.04371", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.04371", "abs": "https://arxiv.org/abs/2511.04371", "authors": ["G. M. Delgado", "J. E. G. Silva"], "title": "Non-relativistic Quantum Mechanics on a Twisted Cylindrical Surface", "comment": "8 pages", "summary": "Twisted cylindrical tubes are important model systems for nanostructures,\nheterostructures, and curved quantum devices. In this work, we investigate the\nquantum behavior of an electron confined to a twisted cylindrical surface. By\nfirst calculating the strain tensor to obtain the induced surface metric, we\nemploy da Costa's formalism to derive the geometry-induced quantum potential.\nThis potential modifies the Schr\\\"odinger equation even in the absence of\nexternal forces, allowing us to determine the bound states and energy\neigenvalues. This was made in the linear and non-linear torsion regime.\nFurthermore, we analyze two distinct scattering problems: (i) scattering within\nan infinite cylinder containing a twisted section, and (ii) scattering of a\nfree particle incident upon a finite twisted cylinder. Our goal is to\nunderstand how geometry and strain influence the properties of analogous\nuntwisted systems. It turns out that both the linear and non-linear twists\nyield to a geometric phase into the wave function, while the da Costa potential\nis kept unchanged. Consequently, the system supports bound states whose energie\nspectrum is twist independent. For both scattering problems, we find that the\ntransmission probability is insensitive to torsion, whereas it is significantly\naffected by the particle angular momentum and the cylinder's radius, exhibiting\ndistinct oscillatory behavior. These findings suggest relevant implications for\nengineering quantum devices based on materials with controlled curvature and\ntwist."}
{"id": "2511.04001", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04001", "abs": "https://arxiv.org/abs/2511.04001", "authors": ["J. Nathan Kutz", "Peter Battaglia", "Michael Brenner", "Kevin Carlberg", "Aric Hagberg", "Shirley Ho", "Stephan Hoyer", "Henning Lange", "Hod Lipson", "Michael W. Mahoney", "Frank Noe", "Max Welling", "Laure Zanna", "Francis Zhu", "Steven L. Brunton"], "title": "Accelerating scientific discovery with the common task framework", "comment": "12 pages, 6 figures", "summary": "Machine learning (ML) and artificial intelligence (AI) algorithms are\ntransforming and empowering the characterization and control of dynamic systems\nin the engineering, physical, and biological sciences. These emerging modeling\nparadigms require comparative metrics to evaluate a diverse set of scientific\nobjectives, including forecasting, state reconstruction, generalization, and\ncontrol, while also considering limited data scenarios and noisy measurements.\nWe introduce a common task framework (CTF) for science and engineering, which\nfeatures a growing collection of challenge data sets with a diverse set of\npractical and common objectives. The CTF is a critically enabling technology\nthat has contributed to the rapid advance of ML/AI algorithms in traditional\napplications such as speech recognition, language processing, and computer\nvision. There is a critical need for the objective metrics of a CTF to compare\nthe diverse algorithms being rapidly developed and deployed in practice today\nacross science and engineering."}
{"id": "2511.04389", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04389", "abs": "https://arxiv.org/abs/2511.04389", "authors": ["Michal Krejčí", "Lucie Krejčí", "Ijaz Ahamed Mohammad", "Martin Plesch", "Martin Friák"], "title": "Minimum measurements quantum protocol for band structure calculation", "comment": "9 pages, 6 figures, supplementary file available", "summary": "Protocols for quantum measurement are an essential part of quantum computing.\nMeasurements are no longer confined to the final step of computation but are\nincreasingly embedded within quantum circuits as integral components of\nnoise-resilient algorithms. However, each observable typically requires a\ndistinct measurement basis, often demanding a different circuit configuration.\nAs the number of such configurations typically grows with the number of qubits,\ndifferent measurement configurations constitute a major bottleneck. Focusing on\nelectronic structure calculations in crystalline systems, we propose a\nmeasurement protocol that maximally reduces the number of measurement settings\nto just three, independent of the number of qubits. This makes it one of the\nfew known protocols that do not scale with qubit number. In particular, we\nderive the measurement protocol from the symmetries of tight-binding (TB)\nHamiltonians and implement it within the Variational Quantum Deflation (VQD)\nalgorithm. We demonstrate its performance on two systems, namely a\ntwo-dimensional CuO$_2$ square lattice (3 qubits) and bilayer graphene (4\nqubits). The protocol can be generalized to more complex many-body Hamiltonians\nwith high symmetry, providing a potential path toward future demonstrations of\nquantum advantage."}
{"id": "2511.04002", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04002", "abs": "https://arxiv.org/abs/2511.04002", "authors": ["Mingyu Sung", "Vikas Palakonda", "Suhwan Im", "Sunghwan Moon", "Il-Min Kim", "Sangseok Yun", "Jae-Mo Kang"], "title": "Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing", "comment": null, "summary": "Large language models (LLMs) have achieved near-human performance across\ndiverse reasoning tasks, yet their deployment on resource-constrained\nInternet-of-Things (IoT) devices remains impractical due to massive parameter\nfootprints and memory-intensive autoregressive decoding. While split computing\noffers a promising solution by partitioning model execution between edge\ndevices and cloud servers, existing approaches fail to address the unique\nchallenges of autoregressive inference, particularly the iterative token\ngeneration process and expanding key-value (KV) cache requirements. This work\nintroduces the first autoregressive-aware split computing framework designed\nexplicitly for LLM deployment on edge devices. Our approach makes three key\ncontributions. First, we develop one-point split compression (OPSC), a\nmixed-precision quantization scheme that prevents out-of-memory failures by\nstrategically partitioning models into front-end and back-end segments with\ndifferent precision levels. Second, we propose a two-stage intermediate\ncompression pipeline that combines threshold splitting (TS) and token-wise\nadaptive bit quantization (TAB-Q) to preserve accuracy-critical activations\nwhile dramatically reducing communication overhead. Third, we formulate a\nunified optimization framework that jointly selects optimal split points,\nquantization settings, and sequence lengths to satisfy strict memory and\nlatency constraints. Extensive evaluations across diverse LLMs and hardware\nplatforms demonstrate superior performance compared to state-of-the-art\nquantization methods, including SmoothQuant, OmniQuant, and Atom. The framework\nachieves a 1.49 inference speedup and significant communication overhead\nreduction while maintaining or improving model accuracy."}
{"id": "2511.04397", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04397", "abs": "https://arxiv.org/abs/2511.04397", "authors": ["Yoshinori Kurimoto", "Dongjun Lee", "Koichiro Ban", "Shinichi Morisaka", "Toshi Sumida", "Hidehisa Shiomi", "Yosuke Ito", "Yuuya Sugita", "Makoto Negoro", "Ryutaro Ohira", "Takefumi Miyoshi"], "title": "Microwave Output Stabilization of a Qubit Controller via Device-Level Temperature Control", "comment": null, "summary": "We present the design and performance of QuEL-1 SE, which is a multichannel\nqubit controller developed for superconducting qubits. The system incorporates\nthe active thermal stabilization of critical analog integrated circuits, such\nas phase-locked loops, amplifiers, and mixers, to suppress the long-term\namplitude and phase drift. To evaluate the amplitude and phase stability, we\nsimultaneously monitor 15 microwave output channels over 24 h using a common\nanalog-to-digital converter. Across the channels, the normalized amplitude\nexhibits standard deviations of 0.09\\%--0.22\\% (mean: 0.15\\%), and the phase\ndeviations are 0.35$^\\circ$--0.44$^\\circ$ (mean: 0.39$^\\circ$). We further\nassess the impact of these deviations on quantum gate operations by estimating\nthe average fidelity of an $X_{\\pi/2}$ gate under the coherent errors\ncorresponding to the deviations. The resulting gate infidelities are $2\\times\n10^{-6}$ for amplitude errors and $2\\times 10^{-5}$ for phase errors, which are\nsignificantly lower than typical fault-tolerance thresholds such as those of\nthe surface code. These results demonstrate that the amplitude and phase\nstability of QuEL-1 SE enables reliable long-duration quantum operations, thus\nhighlighting its utility as a scalable control platform for superconducting and\nother qubit modalities."}
{"id": "2511.04040", "categories": ["cs.LG", "cs.NE", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2511.04040", "abs": "https://arxiv.org/abs/2511.04040", "authors": ["Xiaoling Luo", "Peng Chen", "Chengliang Liu", "Xiaopeng Jin", "Jie Wen", "Yumeng Liu", "Junsong Wang"], "title": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch Dynamic Selection with Reconstructive Pre-Training", "comment": null, "summary": "Multimodal protein features play a crucial role in protein function\nprediction. However, these features encompass a wide range of information,\nranging from structural data and sequence features to protein attributes and\ninteraction networks, making it challenging to decipher their complex\ninterconnections. In this work, we propose a multimodal protein function\nprediction method (DSRPGO) by utilizing dynamic selection and reconstructive\npre-training mechanisms. To acquire complex protein information, we introduce\nreconstructive pre-training to mine more fine-grained information with low\nsemantic levels. Moreover, we put forward the Bidirectional Interaction Module\n(BInM) to facilitate interactive learning among multimodal features.\nAdditionally, to address the difficulty of hierarchical multi-label\nclassification in this task, a Dynamic Selection Module (DSM) is designed to\nselect the feature representation that is most conducive to current protein\nfunction prediction. Our proposed DSRPGO model improves significantly in BPO,\nMFO, and CCO on human datasets, thereby outperforming other benchmark models."}
{"id": "2511.04399", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04399", "abs": "https://arxiv.org/abs/2511.04399", "authors": ["Santanu Majhi", "Debajyoti Bera"], "title": "Tight Analysis of a Grover-based Quantum Secret Sharing Scheme", "comment": "11 pages + 1 page Appendix", "summary": "Secret-sharing schemes allow a dealer to split a secret into multiple\n\"shares\" and distribute them individually among many parties while mandating\ncertain constraints on its reconstruction. Such protocols are usually executed\nover a secure communication channel since an eavesdropper, after intercepting\nall the shares, is expected to be able to reconstruct the secret. Leveraging\nthe unique properties of quantum channels, several quantum protocols have been\ndesigned for secret sharing. However, almost all of them detect the presence of\nan eavesdropper by statistical analysis of the outcome of multiple rounds, or\nsimply require a secure channel of communication.\n  We present a complete characterisation of the correctness and security\nproperties of a quantum-search based secret-sharing framework proposed by Hsu\n(2003). The scheme was designed to work over public channels without requiring\nmultiple rounds to detect eavesdropping. Our characterisation allowed us to\nimprove the original protocol to be more resistant towards eavesdropping.\nHowever, we prove that complete security against an eavesdropper is not\npossible in this framework."}
{"id": "2511.04063", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04063", "abs": "https://arxiv.org/abs/2511.04063", "authors": ["Yuantian Shao", "Yuanteng Chen", "Peisong Wang", "Jianlin Yu", "Jing Lin", "Yiwu Yao", "Zhihui Wei", "Jian Cheng"], "title": "DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization", "comment": "NeurIPS 2025, 10 pages, 12 figures", "summary": "Quantization plays a crucial role in accelerating the inference of\nlarge-scale models, and rotational matrices have been shown to effectively\nimprove quantization performance by smoothing outliers. However, end-to-end\nfine-tuning of rotational optimization algorithms incurs high computational\ncosts and is prone to overfitting. To address this challenge, we propose an\nefficient distribution-aware rotational calibration method, DartQuant, which\nreduces the complexity of rotational optimization by constraining the\ndistribution of the activations after rotation. This approach also effectively\nreduces reliance on task-specific losses, thereby mitigating the risk of\noverfitting. Additionally, we introduce the QR-Orth optimization scheme, which\nreplaces expensive alternating optimization with a more efficient solution. In\na variety of model quantization experiments, DartQuant demonstrates superior\nperformance. Compared to existing methods, it achieves 47$\\times$ acceleration\nand 10$\\times$ memory savings for rotational optimization on a 70B model.\nFurthermore, it is the first to successfully complete rotational calibration\nfor a 70B model on a single 3090 GPU, making quantization of large language\nmodels feasible in resource-constrained environments. Code is available at\nhttps://github.com/CAS-CLab/DartQuant.git."}
{"id": "2511.04402", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.04402", "abs": "https://arxiv.org/abs/2511.04402", "authors": ["Yi-Ming Ding", "Zenan Liu", "Xu Tian", "Zhe Wang", "Yanzhang Zhu", "Zheng Yan"], "title": "Mixed-State Measurement-Induced Phase Transitions in Imaginary-Time Dynamics", "comment": "15 pages, 12 figures", "summary": "Mixed-state phase transitions have recently attracted growing attention as a\nnew frontier in nonequilibrium quantum matter and quantum information. In this\nwork, we introduce the measurement-dressed imaginary-time evolution (MDITE) as\na novel framework to explore mixed-state quantum phases and decoherence-driven\ncriticality. In this setup, alternating imaginary-time evolution and projective\nmeasurements generate a competition between coherence-restoring dynamics and\ndecoherence-inducing events. While reminiscent of monitored unitary circuits,\nMDITE fundamentally differs in that the physics is encoded in decoherent mixed\nstates rather than in quantum trajectories. We demonstrate that this interplay\ngives rise to a new class of mixed-state phase transitions, using numerical\nsimulations of the one-dimensional transverse-field Ising model and the\ntwo-dimensional dimerized Heisenberg model. Furthermore, we provide a\ndiagrammatic representation of the evolving state, which naturally enables\nefficient studies of MDITE with quantum Monte Carlo and other many-body\nnumerical methods, thereby extending investigations of mixed-state phase\ntransitions to large-scale and higher-dimensional Hamiltonians. Our results\nhighlight MDITE as a powerful paradigm for investigating non-unitary dynamics\nand the fundamental role of decoherence in many-body quantum systems."}
{"id": "2511.04069", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04069", "abs": "https://arxiv.org/abs/2511.04069", "authors": ["Fatemeh Hosseinabadi", "Seyedhassan Sharifi"], "title": "Pediatric Appendicitis Detection from Ultrasound Images", "comment": null, "summary": "Pediatric appendicitis remains one of the most common causes of acute\nabdominal pain in children, and its diagnosis continues to challenge clinicians\ndue to overlapping symptoms and variable imaging quality. This study aims to\ndevelop and evaluate a deep learning model based on a pretrained ResNet\narchitecture for automated detection of appendicitis from ultrasound images. We\nused the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound\nscans, laboratory data, and clinical scores from pediatric patients admitted\nwith abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each\nsubject had 1 to 15 ultrasound views covering the right lower quadrant,\nappendix, lymph nodes, and related structures. For the image based\nclassification task, ResNet was fine tuned to distinguish appendicitis from\nnon-appendicitis cases. Images were preprocessed by normalization, resizing,\nand augmentation to enhance generalization. The proposed ResNet model achieved\nan overall accuracy of 93.44, precision of 91.53, and recall of 89.8,\ndemonstrating strong performance in identifying appendicitis across\nheterogeneous ultrasound views. The model effectively learned discriminative\nspatial features, overcoming challenges posed by low contrast, speckle noise,\nand anatomical variability in pediatric imaging."}
{"id": "2511.04408", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04408", "abs": "https://arxiv.org/abs/2511.04408", "authors": ["Aby Philip", "Alexander Streltsov"], "title": "Robustness of quantum data hiding against entangled catalysts and memory", "comment": "10 pages, 1 figure", "summary": "Quantum data hiding stores classical information in bipartite quantum states\nthat are, in principle, perfectly distinguishable, yet remain almost\nindistinguishable without access to a quantum communication channel. Here, we\ninvestigate whether this limitation can be overcome when the communicating\nparties are assisted by additional quantum resources. We develop a general\nframework for state discrimination that unifies catalytic and memory-assisted\nlocal discrimination protocols and analyze their power to reveal hidden\ninformation. We prove that when the hiding states are separable, neither\nentangled catalysts nor quantum memory can increase the optimal discrimination\nprobability, establishing the robustness of separable data-hiding schemes. In\ncontrast, for some entangled states, a reusable quantum memory turns locally\nindistinguishable states into ones that can be discriminated almost perfectly.\nOur results delineate the fundamental limits of catalytic and memory-assisted\nstate discrimination and identify separable encodings as a robust strategy for\nquantum data hiding."}
{"id": "2511.04071", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04071", "abs": "https://arxiv.org/abs/2511.04071", "authors": ["Fatemeh Hosseinabadi", "Seyedhassan Sharifi"], "title": "Left Atrial Segmentation with nnU-Net Using MRI", "comment": null, "summary": "Accurate segmentation of the left atrium (LA) from cardiac MRI is critical\nfor guiding atrial fibrillation (AF) ablation and constructing biophysical\ncardiac models. Manual delineation is time-consuming, observer-dependent, and\nimpractical for large-scale or time-sensitive clinical workflows. Deep learning\nmethods, particularly convolutional architectures, have recently demonstrated\nsuperior performance in medical image segmentation tasks. In this study, we\napplied the nnU-Net framework, an automated, self-configuring deep learning\nsegmentation architecture, to the Left Atrial Segmentation Challenge 2013\ndataset. The dataset consists of thirty MRI scans with corresponding\nexpert-annotated masks. The nnU-Net model automatically adapted its\npreprocessing, network configuration, and training pipeline to the\ncharacteristics of the MRI data. Model performance was quantitatively evaluated\nusing the Dice similarity coefficient (DSC), and qualitative results were\ncompared against expert segmentations. The proposed nnUNet model achieved a\nmean Dice score of 93.5, demonstrating high overlap with expert annotations and\noutperforming several traditional segmentation approaches reported in previous\nstudies. The network exhibited robust generalization across variations in left\natrial shape, contrast, and image quality, accurately delineating both the\natrial body and proximal pulmonary veins."}
{"id": "2511.04414", "categories": ["quant-ph", "cond-mat.quant-gas", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2511.04414", "abs": "https://arxiv.org/abs/2511.04414", "authors": ["Hans Peter Büchler", "Tobias F. Maier", "Simon Fell", "Nicolai Lang"], "title": "Quantum doubles in symmetric blockade structures", "comment": "39 pages, 12 figures", "summary": "Exactly solvable models of topologically ordered phases with non-abelian\nanyons typically require complicated many-body interactions which do not\nnaturally appear in nature. This motivates the \"inverse problem\" of quantum\nmany-body physics: given microscopic systems with experimentally realistic\ntwo-body interactions, how to design a Hamiltonian that realizes a desired\ntopological phase? Here we solve this problem on a platform motivated by\nRydberg atoms, where elementary two-level systems couple via simple blockade\ninteractions. Within this framework, we construct Hamiltonians that realize\ntopological orders described by non-abelian quantum double models. We\nanalytically prove the existence of topological order in the ground state, and\npresent efficient schemes to prepare these states. We also introduce protocols\nfor the controlled adiabatic braiding of anyonic excitations to probe their\nnon-abelian statistics. Our construction is generic and applies to quantum\ndoubles $\\mathcal{D}(G)$ for arbitrary finite groups $G$. We illustrate\nbraiding for the simplest non-abelian quantum double $\\mathcal{D}(S_3)$."}
{"id": "2511.04073", "categories": ["cs.LG", "cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.04073", "abs": "https://arxiv.org/abs/2511.04073", "authors": ["Ananya Sutradhar", "Suryansh Gupta", "Ravishankar Krishnaswamy", "Haiyang Xu", "Aseem Rastogi", "Gopal Srinivasa"], "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters", "comment": "1st Workshop on Vector Databases at International Conference on\n  Machine Learning, 2025", "summary": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest\nvectors for a query vector from a dataset. It enforces that a specified set of\ndiscrete labels $S$ for the query must be included in the labels of each\nretrieved vector. Existing graph-based methods typically incorporate filter\nawareness by assigning fixed penalties or prioritizing nodes based on filter\nsatisfaction. However, since these methods use fixed, data in- dependent\npenalties, they often fail to generalize across datasets with diverse label and\nvector distributions. In this work, we propose a principled alternative that\nlearns the optimal trade-off between vector distance and filter match directly\nfrom the data, rather than relying on fixed penalties. We formulate this as a\nconstrained linear optimization problem, deriving weights that better reflect\nthe underlying filter distribution and more effectively address the filtered\nANN search problem. These learned weights guide both the search process and\nindex construction, leading to graph structures that more effectively capture\nthe underlying filter distribution and filter semantics. Our experiments\ndemonstrate that adapting the distance function to the data significantly im-\nproves accuracy by 5-10% over fixed-penalty methods, providing a more flexible\nand generalizable framework for the filtered ANN search problem."}
{"id": "2511.04434", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.04434", "abs": "https://arxiv.org/abs/2511.04434", "authors": ["Cristian Tabares", "Dominik S. Wild", "J. Ignacio Cirac", "Peter Zoller", "Alejandro González-Tudela", "Daniel González-Cuadra"], "title": "Estimating ground-state properties in quantum simulators with global control", "comment": "12+10 pages, 5+5 figures", "summary": "Accurately determining ground-state properties of quantum many-body systems\nremains one of the major challenges of quantum simulation. In this work, we\npresent a protocol for estimating the ground-state energy using only global\ntime evolution under a target Hamiltonian. This avoids the need for controlled\noperations that are typically required in conventional quantum phase estimation\nand extends the algorithm applicability to analog simulators. Our method\nextracts energy differences from measurements of the Loschmidt echo over an\ninitial ground-state approximation, combines them with direct energy\nmeasurements, and solves a set of equations to infer the individual\neigenenergies. We benchmark this protocol on free-fermion systems, showing\norders-of-magnitude precision gains over direct energy measurements on the\ninitial state, with accuracy improving rapidly with initial-state fidelity and\npersisting for hundreds of modes. We further demonstrate applicability to the\n2D Ising and Fermi-Hubbard models and show that the approach extends naturally\nto other observables such as order parameters. Finally, we analyze the effect\nof experimental imperfections and propose error-mitigation strategies. These\nresults establish a practical route to compute physically relevant quantities\nwith high precision using globally controlled quantum simulators."}
{"id": "2511.04086", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04086", "abs": "https://arxiv.org/abs/2511.04086", "authors": ["Qingfeng Chen", "Haojin Zeng", "Jingyi Jie", "Shichao Zhang", "Debo Cheng"], "title": "DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection", "comment": null, "summary": "With the rapid growth of graph-structured data in critical domains,\nunsupervised graph-level anomaly detection (UGAD) has become a pivotal task.\nUGAD seeks to identify entire graphs that deviate from normal behavioral\npatterns. However, most Graph Neural Network (GNN) approaches implicitly assume\nthat the training set is clean, containing only normal graphs, which is rarely\ntrue in practice. Even modest contamination by anomalous graphs can distort\nlearned representations and sharply degrade performance. To address this\nchallenge, we propose DeNoise, a robust UGAD framework explicitly designed for\ncontaminated training data. It jointly optimizes a graph-level encoder, an\nattribute decoder, and a structure decoder via an adversarial objective to\nlearn noise-resistant embeddings. Further, DeNoise introduces an encoder\nanchor-alignment denoising mechanism that fuses high-information node\nembeddings from normal graphs into all graph embeddings, improving\nrepresentation quality while suppressing anomaly interference. A contrastive\nlearning component then compacts normal graph embeddings and repels anomalous\nones in the latent space. Extensive experiments on eight real-world datasets\ndemonstrate that DeNoise consistently learns reliable graph-level\nrepresentations under varying noise intensities and significantly outperforms\nstate-of-the-art UGAD baselines."}
{"id": "2511.04438", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04438", "abs": "https://arxiv.org/abs/2511.04438", "authors": ["Vishal Singh", "Karol Horodecki", "Aby Philip", "Mark M. Wilde"], "title": "Limiting one-way distillable secret key via privacy testing of extendible states", "comment": "31+10 pages, 4 figures", "summary": "The notions of privacy tests and $k$-extendible states have both been\ninstrumental in quantum information theory, particularly in understanding the\nlimits of secure communication. In this paper, we determine the maximum\nprobability with which an arbitrary $k$-extendible state can pass a privacy\ntest, and we prove that it is equal to the maximum fidelity between an\narbitrary $k$-extendible state and the standard maximally entangled state. Our\nfindings, coupled with the resource theory of $k$-unextendibility, lead to an\nefficiently computable upper bound on the one-shot, one-way distillable key of\na bipartite state, and we prove that it is equal to the best-known efficiently\ncomputable upper bound on the one-shot, one-way distillable entanglement. We\nalso establish efficiently computable upper bounds on the one-shot,\nforward-assisted private capacity of channels. Extending our formalism to the\nindependent and identically distributed setting, we obtain single-letter\nefficiently computable bounds on the $n$-shot, one-way distillable key of a\nstate and the $n$-shot, forward-assisted private capacity of a channel. For\nsome key examples of interest, our bounds are significantly tighter than other\nknown efficiently computable bounds."}
{"id": "2511.04094", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04094", "abs": "https://arxiv.org/abs/2511.04094", "authors": ["Hyungjong Na", "Wonho Song", "Seungyong Han", "Donghyeon Jo", "Sejin Myung", "Hyungjoon Kim"], "title": "KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea", "comment": "18 pages, 3 figures, 8 tables. Submitted to Scientific Data;\n  currently under review. Data and codebook available at Zenodo (DOI:\n  10.5281/zenodo.17149808)", "summary": "This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term\npanel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011\nand 2024. After excluding financial firms, firms with non-December fiscal year\nends, capital impairment, and negative pre-tax income, the final dataset\nconsists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed\nto treat corporate tax avoidance as a predictor variable and link it to\nmultiple domains, including earnings management (accrual- and activity-based),\nprofitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,\nINVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance\nitself is measured using complementary indicators cash effective tax rate\n(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,\nTSDA) with adjustments to ensure interpretability. A key strength of KoTaP is\nits balanced panel structure with standardized variables and its consistency\nwith international literature on the distribution and correlation of core\nindicators. At the same time, it reflects distinctive institutional features of\nKorean firms, such as concentrated ownership, high foreign shareholding, and\nelevated liquidity ratios, providing both international comparability and\ncontextual uniqueness. KoTaP enables applications in benchmarking econometric\nand deep learning models, external validity checks, and explainable AI\nanalyses. It further supports policy evaluation, audit planning, and investment\nanalysis, making it a critical open resource for accounting, finance, and\ninterdisciplinary research."}
{"id": "2511.04446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04446", "abs": "https://arxiv.org/abs/2511.04446", "authors": ["Raphael Brinster", "Peter Tirler", "Shishir Khandelwal", "Michael Meth", "Hermann Kampermann", "Dagmar Bruß", "Rainer Blatt", "Martin Ringbauer", "Armin Tavakoli", "Nikolai Wyderka"], "title": "Robust certification of non-projective measurements: theory and experiment", "comment": "10+6 pages, 5+1 figures, 2+2 tables", "summary": "Determining the conditions under which positive operator-valued measures\n(POVMs), the most general class of quantum measurements, outperform projective\nmeasurements remains a challenging and largely unresolved problem. Of\nparticular interest are projectively simulable POVMs, which can be realized\nthrough probabilistic mixtures of projective measurements, and therefore offer\nno advantage over projective schemes. Characterizing the boundary between\nsimulable and non-simulable POVMs is, however, a difficult task, and existing\ntools either fail to scale efficiently, provide limited experimental\nfeasibility or work only for specific POVMs. Here, we introduce and demonstrate\na general method to certify non-simulability of a POVM by introducing a\nhierarchy of semidefinite programs. It provides upper bounds on the\nnon-simulability measure of critical visibility of arbitrary POVMs which are\ntight in many cases and outperform previously known criteria. We experimentally\ncertify the non-simulability of two- and three-dimensional POVMs using a\ntrapped-ion qudit quantum processor by constructing non-simulability witnesses\nand introduce a modification of our framework that makes them robust against\nstate preparation errors. Finally, we extend our results to the setting where\nan additional ancilla system is available."}
{"id": "2511.04124", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04124", "abs": "https://arxiv.org/abs/2511.04124", "authors": ["Giorgio Morales", "John W. Sheppard"], "title": "Decomposable Neuro Symbolic Regression", "comment": null, "summary": "Symbolic regression (SR) models complex systems by discovering mathematical\nexpressions that capture underlying relationships in observed data. However,\nmost SR methods prioritize minimizing prediction error over identifying the\ngoverning equations, often producing overly complex or inaccurate expressions.\nTo address this, we present a decomposable SR method that generates\ninterpretable multivariate expressions leveraging transformer models, genetic\nalgorithms (GAs), and genetic programming (GP). In particular, our explainable\nSR method distills a trained ``opaque'' regression model into mathematical\nexpressions that serve as explanations of its computed function. Our method\nemploys a Multi-Set Transformer to generate multiple univariate symbolic\nskeletons that characterize how each variable influences the opaque model's\nresponse. We then evaluate the generated skeletons' performance using a\nGA-based approach to select a subset of high-quality candidates before\nincrementally merging them via a GP-based cascade procedure that preserves\ntheir original skeleton structure. The final multivariate skeletons undergo\ncoefficient optimization via a GA. We evaluated our method on problems with\ncontrolled and varying degrees of noise, demonstrating lower or comparable\ninterpolation and extrapolation errors compared to two GP-based methods, three\nneural SR methods, and a hybrid approach. Unlike them, our approach\nconsistently learned expressions that matched the original mathematical\nstructure."}
{"id": "2511.04488", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04488", "abs": "https://arxiv.org/abs/2511.04488", "authors": ["Benedikt Tissot", "Soubhadra Maiti", "Emil R. Hellebek", "Anders Søndberg Sørensen"], "title": "Hybrid Single-Ion Atomic-Ensemble Node for High-Rate Remote Entanglement Generation", "comment": "10 pages, 4 figures", "summary": "Different quantum systems possess different favorable qualities. On the one\nhand, ensemble-based quantum memories are suited for fast multiplexed\nlong-range entanglement generation. On the other hand, single-atomic systems\nprovide access to gates for processing of information. Both of those can\nprovide advantages for high-rate entanglement generation within quantum\nnetworks. We develop a hybrid architecture that takes advantage of these\nproperties by combining trapped-ion nodes and nodes comprised of spontaneous\nparametric down conversion photon pair sources and absorptive memories based on\nrare-earth ion ensembles. To this end, we solve the central challenge of\nmatching the different bandwidths of photons emitted by those systems in an\ninitial entanglement-generation step. This enables the parallel execution of\nmultiple probabilistic tasks in the initial stage. We show that our approach\ncan lead to a significant speed-up for the fundamental task of creating ion-ion\nentanglement over hundreds of kilometers in a quantum network."}
{"id": "2511.04132", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04132", "abs": "https://arxiv.org/abs/2511.04132", "authors": ["Hongbin Zhang", "Shihao Gao", "Yang Liu", "Mingjie Xing", "Yanjun Wu", "Chen Zhao"], "title": "Exploring the Feasibility of End-to-End Large Language Model as a Compiler", "comment": "This work has been accepted by IJCNN 2025 and submitted to the IEEE\n  for publication", "summary": "In recent years, end-to-end Large Language Model (LLM) technology has shown\nsubstantial advantages across various domains. As critical system software and\ninfrastructure, compilers are responsible for transforming source code into\ntarget code. While LLMs have been leveraged to assist in compiler development\nand maintenance, their potential as an end-to-end compiler remains largely\nunexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and\nits future directions. We designed the CompilerEval dataset and framework\nspecifically to evaluate the capabilities of mainstream LLMs in source code\ncomprehension and assembly code generation. In the evaluation, we analyzed\nvarious errors, explored multiple methods to improve LLM-generated code, and\nevaluated cross-platform compilation capabilities. Experimental results\ndemonstrate that LLMs exhibit basic capabilities as compilers but currently\nachieve low compilation success rates. By optimizing prompts, scaling up the\nmodel, and incorporating reasoning methods, the quality of assembly code\ngenerated by LLMs can be significantly enhanced. Based on these findings, we\nmaintain an optimistic outlook for LaaC and propose practical architectural\ndesigns and future research directions. We believe that with targeted training,\nknowledge-rich prompts, and specialized infrastructure, LaaC has the potential\nto generate high-quality assembly code and drive a paradigm shift in the field\nof compilation."}
{"id": "2511.04545", "categories": ["quant-ph", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.04545", "abs": "https://arxiv.org/abs/2511.04545", "authors": ["Erickson Tjoa", "J. Ignacio Cirac"], "title": "Continuous matrix product operators for quantum fields", "comment": "4+1+10 pages, no figures", "summary": "In this work we introduce an ansatz for continuous matrix product operators\nfor quantum field theory. We show that (i) they admit a closed-form expression\nin terms of finite number of matrix-valued functions without reference to any\nlattice parameter; (ii) they are obtained as a suitable continuum limit of\nmatrix product operators; (iii) they preserve the entanglement area law\ndirectly in the continuum, and in particular they map continuous matrix product\nstates (cMPS) to another cMPS. As an application, we use this ansatz to\nconstruct several families of continuous matrix product unitaries beyond\nquantum cellular automata."}
{"id": "2511.04147", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04147", "abs": "https://arxiv.org/abs/2511.04147", "authors": ["Jiaming Zhang", "Yujie Yang", "Haoning Wang", "Liping Zhang", "Shengbo Eben Li"], "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning", "comment": "Submitted to the Journal of Machine Learning Research (JMLR), under\n  review", "summary": "Safe reinforcement learning (safe RL) aims to respect safety requirements\nwhile optimizing long-term performance. In many practical applications,\nhowever, the problem involves an infinite number of constraints, known as\nsemi-infinite safe RL (SI-safe RL). Such constraints typically appear when\nsafety conditions must be enforced across an entire continuous parameter space,\nsuch as ensuring adequate resource distribution at every spatial location. In\nthis paper, we propose exchange policy optimization (EPO), an algorithmic\nframework that achieves optimal policy performance and deterministic bounded\nsafety. EPO works by iteratively solving safe RL subproblems with finite\nconstraint sets and adaptively adjusting the active set through constraint\nexpansion and deletion. At each iteration, constraints with violations\nexceeding the predefined tolerance are added to refine the policy, while those\nwith zero Lagrange multipliers are removed after the policy update. This\nexchange rule prevents uncontrolled growth of the working set and supports\neffective policy training. Our theoretical analysis demonstrates that, under\nmild assumptions, strategies trained via EPO achieve performance comparable to\noptimal solutions with global constraint violations strictly remaining within a\nprescribed bound."}
{"id": "2511.04553", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.04553", "abs": "https://arxiv.org/abs/2511.04553", "authors": ["Alejandro Gomez Cadavid", "Pranav Chandarana", "Sebastián V. Romero", "Jan Trautmann", "Enrique Solano", "Taylor Lee Patti", "Narendra N. Hegade"], "title": "Scaling advantage with quantum-enhanced memetic tabu search for LABS", "comment": "9 pages, 7 figures", "summary": "We introduce quantum-enhanced memetic tabu search (QE-MTS), a non-variational\nhybrid algorithm that achieves state-of-the-art scaling for the\nlow-autocorrelation binary sequence (LABS) problem. By seeding the classical\nMTS with high-quality initial states from digitized counterdiabatic quantum\noptimization (DCQO), our method suppresses the empirical time-to-solution\nscaling to $\\mathcal{O}(1.24^N)$ for sequence length $N \\in [27,37]$. This\nscaling surpasses the best-known classical heuristic $\\mathcal{O}(1.34^N)$ and\nimproves upon the $\\mathcal{O}(1.46^N)$ of the quantum approximate optimization\nalgorithm, achieving superior performance with a $6\\times$ reduction in circuit\ndepth. A two-stage bootstrap analysis confirms the scaling advantage and\nprojects a crossover point at $N \\gtrsim 47$, beyond which QE-MTS outperforms\nits classical counterpart. These results provide evidence that quantum\nenhancement can directly improve the scaling of classical optimization\nalgorithms for the paradigmatic LABS problem."}
{"id": "2511.04155", "categories": ["cs.LG", "I.2.6; I.5.1"], "pdf": "https://arxiv.org/pdf/2511.04155", "abs": "https://arxiv.org/abs/2511.04155", "authors": ["Olav Finne Praesteng Larsen", "Massimiliano Ruocco", "Michail Spitieris", "Abdulmajid Murad", "Martina Ragosta"], "title": "Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories", "comment": null, "summary": "Access to trajectory data is a key requirement for developing and validating\nAir Traffic Management (ATM) solutions, yet many secondary and regional\nairports face severe data scarcity. This limits the applicability of machine\nlearning methods and the ability to perform large-scale simulations or\n\"what-if\" analyses. In this paper, we investigate whether generative models\ntrained on data-rich airports can be efficiently adapted to data-scarce\nairports using transfer learning. We adapt state-of-the-art diffusion- and\nflow-matching-based architectures to the aviation domain and evaluate their\ntransferability between Zurich (source) and Dublin (target) landing trajectory\ndatasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying\namounts of local data, ranging from 0% to 100%. Results show that\ndiffusion-based models achieve competitive performance with as little as 5% of\nthe Dublin data and reach baseline-level performance around 20%, consistently\noutperforming models trained from scratch across metrics and visual\ninspections. Latent flow matching and latent diffusion models also benefit from\npretraining, though with more variable gains, while flow matching models show\nweaker generalization. Despite challenges in capturing rare trajectory\npatterns, these findings demonstrate the potential of transfer learning to\nsubstantially reduce data requirements for trajectory generation in ATM,\nenabling realistic synthetic data generation even in environments with limited\nhistorical records."}
{"id": "2511.04559", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.04559", "abs": "https://arxiv.org/abs/2511.04559", "authors": ["Junhyeok Bang"], "title": "Preferred Basis in Coupled Electron-Nuclear Dynamics", "comment": "31 pages, 3 figures", "summary": "Beyond the adiabatic regime, our understanding of quantum dynamics in coupled\nsystems remains limited, and the choice of representation continues to obscure\nphysical interpretation and simulation accuracy. Here we propose a natural and\nefficient basis for electron nuclear dynamics by drawing on the concepts of\npointer and preferred states from decoherence theory, adapted to systems where\nelectrons and nuclei interact strongly. Within this framework, we show that 1)\nthe independent dynamics exploited by mixed quantum classical (MQC) methods is\nbest understood as a manifestation of entanglement viewed in a preferred basis,\nrather than a consequence of decoherence, and 2) the adiabatic Born Oppenheimer\nstates satisfy the conditions of an approximate preferred basis. This\nperspective reconciles widely used approximations with a more fundamental\nstructure of the theory and provides a systematic route to more reliable MQC\nstrategies. In effect, we revisit MQC methods through the lens of preferred\nstates, clarifying when they succeed and how they can be improved."}
{"id": "2511.04158", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04158", "abs": "https://arxiv.org/abs/2511.04158", "authors": ["Anzhuo Xie", "Wei-Chen Chang"], "title": "Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data", "comment": null, "summary": "This study proposes a Transformer-based longitudinal modeling method to\naddress challenges in clinical risk classification with heterogeneous\nElectronic Health Record (EHR) data, including irregular temporal patterns,\nlarge modality differences, and complex semantic structures. The method takes\nmulti-source medical features as input and employs a feature embedding layer to\nachieve a unified representation of structured and unstructured data. A\nlearnable temporal encoding mechanism is introduced to capture dynamic\nevolution under uneven sampling intervals. The core model adopts a multi-head\nself-attention structure to perform global dependency modeling on longitudinal\nsequences, enabling the aggregation of long-term trends and short-term\nfluctuations across different temporal scales. To enhance semantic\nrepresentation, a semantic-weighted pooling module is designed to assign\nadaptive importance to key medical events, improving the discriminative ability\nof risk-related features. Finally, a linear mapping layer generates\nindividual-level risk scores. Experimental results show that the proposed model\noutperforms traditional machine learning and temporal deep learning models in\naccuracy, recall, precision, and F1-Score, achieving stable and precise risk\nidentification in multi-source heterogeneous EHR environments and providing an\nefficient and reliable framework for clinical intelligent decision-making."}
{"id": "2511.04563", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04563", "abs": "https://arxiv.org/abs/2511.04563", "authors": ["Vincent Gierisch", "Wolfgang Mauerer"], "title": "QEF: Reproducible and Exploratory Quantum Software Experiments", "comment": "to appear as a workshop paper at ICSOC 2025 (SQS 2025)", "summary": "Commercially available Noisy Intermediate-Scale Quantum (NISQ) devices now\nmake small hybrid quantum-classical experiments practical, but many tools hide\nconfiguration or demand ad-hoc scripting.\n  We introduce the Quantum Experiment Framework (QEF): A lightweight framework\ndesigned to support the systematic, hypothesis-driven study of quantum\nalgorithms. Unlike many existing approaches, QEF emphasises iterative,\nexploratory analysis of evolving experimental strategies rather than exhaustive\nempirical evaluation of fixed algorithms using predefined quality metrics. The\nframework's design is informed by a comprehensive review of the literature,\nidentifying principal parameters and measurement practices currently reported\nin the field.\n  QEF captures all key aspects of quantum software and algorithm experiments\nthrough a concise specification that expands into a Cartesian product of\nvariants for controlled large-scale parameter sweeps. This design enables\nrigorous and systematic evaluation, as well as precise reproducibility. Large\nsweeps are automatically partitioned into asynchronous jobs across simulators\nor cloud hardware, and ascertain full hyper-parameter traceability. QEF\nsupports parameter reuse to improve overall experiment runtimes, and collects\nall metrics and metadata into a form that can be conveniently explored with\nstandard statistical and visualisation software.\n  By combining reproducibility and scalability while avoiding the complexities\nof full workflow engines, QEF seeks to lower the practical barriers to\nempirical research on quantum algorithms, whether these are designed for\ncurrent NISQ devices or future error-corrected quantum systems."}
{"id": "2511.04160", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04160", "abs": "https://arxiv.org/abs/2511.04160", "authors": ["Laurits Fredsgaard", "Mikkel N. Schmidt"], "title": "On Joint Regularization and Calibration in Deep Ensembles", "comment": "39 pages, 8 figures, 11 tables", "summary": "Deep ensembles are a powerful tool in machine learning, improving both model\nperformance and uncertainty calibration. While ensembles are typically formed\nby training and tuning models individually, evidence suggests that jointly\ntuning the ensemble can lead to better performance. This paper investigates the\nimpact of jointly tuning weight decay, temperature scaling, and early stopping\non both predictive performance and uncertainty quantification. Additionally, we\npropose a partially overlapping holdout strategy as a practical compromise\nbetween enabling joint evaluation and maximizing the use of data for training.\nOur results demonstrate that jointly tuning the ensemble generally matches or\nimproves performance, with significant variation in effect size across\ndifferent tasks and metrics. We highlight the trade-offs between individual and\njoint optimization in deep ensemble training, with the overlapping holdout\nstrategy offering an attractive practical solution. We believe our findings\nprovide valuable insights and guidance for practitioners looking to optimize\ndeep ensemble models. Code is available at:\nhttps://github.com/lauritsf/ensemble-optimality-gap"}
{"id": "2511.04578", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04578", "abs": "https://arxiv.org/abs/2511.04578", "authors": ["Tiphaine Kouadou", "Elie Gozlan", "Loïc Garcia", "David Polizzi", "David Fainsin", "Iris Paparelle", "R. L. Rincón Celis", "Bastien Oriot", "Anthony Abi Aad", "Peter Namdar", "Ganaël Roland", "Nicolas Treps", "Bérengère Argence", "Valentina Parigi"], "title": "Homodyne detection for pulse-by-pulse squeezing measurements", "comment": "9 pages, 10 figures", "summary": "Homodyne detection is a phase-sensitive measurement technique, essential for\nthe characterization of continuous-variable (CV)-encoded quantum states of\nlight. It is a key component to the implementation of CV quantum-information\nprotocols and benefits from operating, by design, at room temperature. However,\nperforming high-speed quantum information processing remains a major challenge,\nas conventional homodyne detectors often fail to sustain pulsed operation at\nhigh repetition rates due to electronic limitations. We present wideband\nhomodyne detectors operating at near-infrared (NIR) and telecom wavelengths,\nwith optimized performance at repetition rates up to 150 MHz. We demonstrate\ntheir performance by resolving the pulse-by-pulse structure of squeezed states\nof light at telecom wavelengths while preserving their spectral multimode\nproperties."}
{"id": "2511.04162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04162", "abs": "https://arxiv.org/abs/2511.04162", "authors": ["Xiaokai Wang", "Shaoyuan Huang", "Yuting Li", "Xiaofei Wang"], "title": "ScaleDL: Towards Scalable and Efficient Runtime Prediction for Distributed Deep Learning Workloads", "comment": null, "summary": "Deep neural networks (DNNs) form the cornerstone of modern AI services,\nsupporting a wide range of applications, including autonomous driving,\nchatbots, and recommendation systems. As models increase in size and\ncomplexity, DNN workloads like training and inference tasks impose\nunprecedented demands on distributed computing resources, making the accurate\nprediction of runtime essential for optimizing development and resource\nallocation. Traditional methods rely on additive computational unit models,\nlimiting their accuracy and generalizability. In contrast, graph-enhanced\nmodeling improves performance but significantly increases data collection\ncosts. Therefore, there is a critical need for a method that strikes a balance\nbetween accuracy, generalizability, and the costs of data collection. To\naddress these challenges, we propose ScaleDL, a novel runtime prediction\nframework that combines nonlinear layer-wise modeling with graph neural network\n(GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime\nprediction and hierarchical generalizability across different network\narchitectures. Additionally, we employ the D-optimal method to reduce data\ncollection costs. Experiments on the workloads of five popular DNN models prove\nthat ScaleDL enhances runtime prediction accuracy and generalizability,\nachieving 6$\\times$ lower MRE and 5$\\times$ lower RMSE compared to baseline\nmodels."}
{"id": "2511.04604", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04604", "abs": "https://arxiv.org/abs/2511.04604", "authors": ["Mikhail Guselnikov", "Alexei D. Kiselev", "Andrei Gaidash", "George Miroshnichenko", "Anton Kozubov"], "title": "Controlling Hong-Ou-Mandel antibunching via parity governed spectral shaping of biphoton states", "comment": "16 pages, 7 figures", "summary": "We investigate into experimentally detectable effects such as the\nHong-Ou-Mandel (HOM) bunching and antibunching. These regimes can be\ncharacterized using the symmetry degree parameter $D_S$ that enters the\ntwo-photon coincidence probability $P_{2c}=(1-D_S)/2$. In the case of HOM\nbunching (antibunching), $D_S$ is positive (negative). Though the symmetry\ndegree can generally be expressed in terms of the difference between the\ncontributions coming from the symmetric and antisymmetric parts of the biphoton\njoint spectral amplitude (JSA), $\\psi(\\omega_1,\\omega_2)$, for a certain\nphysically realizable class of the JSA, where $\\psi(\\omega_1,\\omega_2)$ is\nproportional to the product of amplitudes\n$\\varphi_1(\\omega_1)\\varphi_2(\\omega_2)$ multiplied by a Gaussian shaped\nentangling factor, we find the sign of $D_S$ is primarily governed by the\nparity properties of the spectral function,\n$\\varphi_{12}(\\omega)=\\varphi_1(\\omega)\\varphi_2^*(\\omega)$. It is the even\n(odd) part of $\\varphi_{12}=\\varphi_{12}^{(+)}+\\varphi_{12}^{(-)}$ that meets\nthe parity condition\n$\\varphi_{12}^{(+)}(\\omega-\\Omega)=\\varphi_{12}^{(+)}(\\Omega-\\omega)$\n($\\varphi_{12}^{(-)}(\\omega-\\Omega)=- \\varphi_{12}^{(-)}(\\Omega-\\omega)$) to\nyield the positive (negative) contribution, $D_S^{(+)}$ ($-D_S^{(-)}$), to the\nsymmetry degree parameter: $D_S=D_S^{(+)}-D_S^{(-)}$. We have shown that\nswitching between the bunching and antibunching regimes can be realized using\nthe experimentally accessible family of modulated biphoton states produced\nusing the spectral phase modulation fine-tuned via the sub-nanometer scale\nvariation of the path length. For this class of modulated states, the Schmidt\nnumber has been computed as a function of the modulation parameter. This\ndependence reveals the structure of narrow resonance peaks strongly correlated\nwith the corresponding narrow dips of the symmetry degree where the HOM\nantibunching occurs."}
{"id": "2511.04214", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04214", "abs": "https://arxiv.org/abs/2511.04214", "authors": ["Yuantian Shao", "Peisong Wang", "Yuanteng Chen", "Chang Xu", "Zhihui Wei", "Jian Cheng"], "title": "Block Rotation is All You Need for MXFP4 Quantization", "comment": "9 pages, 10 figures", "summary": "Large language models (LLMs) have achieved remarkable success, but their\nrapidly growing scale imposes prohibitive costs in memory, computation, and\nenergy. Post-training quantization (PTQ) is a promising solution for efficient\ndeployment, yet achieving accurate W4A4 quantization remains an open challenge.\nWhile most existing methods are designed for INT4 formats, the emergence of\nMXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--\nraises questions about the applicability of current techniques. In this work,\nwe establish a comprehensive benchmark of PTQ methods under the MXFP4 format.\nThrough systematic evaluation, we find that methods like GPTQ consistently\ndeliver strong performance, whereas rotation-based approaches, which are almost\nused by all state-of-the-art approaches, suffer from severe incompatibility\nwith MXFP4. We further provide the first in-depth analysis of this conflict,\ntracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)\nblock scaling and the redistribution of outlier energy via global rotation.\nBuilding on this insight, we propose a simple yet effective block rotation\nstrategy that adapts rotation-based methods to MXFP4, leading to substantial\naccuracy improvements across diverse LLMs. Our findings not only offer clear\nguidance for practitioners but also set a foundation for advancing PTQ research\nunder emerging low-precision formats."}
{"id": "2511.04608", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04608", "abs": "https://arxiv.org/abs/2511.04608", "authors": ["Zhaohui Yang", "Kai Zhang", "Xinyang Tian", "Xiangyu Ren", "Yingjian Liu", "Yunfeng Li", "Jianxin Chen", "Dawei Ding", "Yuanx Xie"], "title": "Qubit Mapping and Routing tailored to Advanced Quantum ISAs: Not as Costly as You Think", "comment": "12 pages, 11 figures, with appendices", "summary": "Qubit mapping/routing is a critical stage in compilation for both near-term\nand fault-tolerant quantum computers, yet existing scalable methods typically\nimpose several times the routing overhead in terms of circuit depth or\nduration. This inefficiency stems from a fundamental disconnect: compilers rely\non an abstract routing model (e.g., three-$ \\mathrm{CX} $-unrolled SWAP\ninsertion) that completely ignores the idiosyncrasies of native gates supported\nby physical devices.\n  Recent hardware breakthroughs have enabled high-precision implementations of\ndiverse instruction set architectures (ISAs) beyond standard\n$\\mathrm{CX}$-based gates. Advanced ISAs involving gates such as\n$\\mathrm{\\sqrt{iSWAP}}$ and $\\mathrm{ZZ}(\\theta)$ gates offer superior circuit\nsynthesis capabilities and can be realized with higher fidelities. However,\nsystematic compiler optimization strategies tailored to these advanced ISAs are\nlacking.\n  To address this, we propose Canopus, a unified qubit mapping/routing\nframework applicable to diverse quantum ISAs. Built upon the canonical\nrepresentation of two-qubit gates, Canopus centers on qubit routing to perform\ndeep co-optimization in an ISA-aware approach. Canopus leverages the two-qubit\ncanonical representation and the monodromy polytope to model the synthesis cost\nfor more intelligent $ \\mathrm{SWAP} $ insertion during the routing stage. We\nalso formalize the commutation relations between two-qubit gates through the\ncanonical form, providing a generalized approach to commutativity-based\noptimizations. Experiments show that Canopus consistently reduces routing\noverhead by 15\\%-35\\% compared to state-of-the-art methods across different\nISAs and topologies. Our work also presents a coherent method for\nco-exploration of program patterns, quantum ISAs, and hardware topologies."}
{"id": "2511.04217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04217", "abs": "https://arxiv.org/abs/2511.04217", "authors": ["Hikari Otsuka", "Daiki Chijiwa", "Yasuyuki Okoshi", "Daichi Fujiki", "Susumu Takeuchi", "Masato Motomura"], "title": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms", "comment": "22 pages, 8 figures", "summary": "The strong lottery ticket hypothesis (SLTH) conjectures that high-performing\nsubnetworks, called strong lottery tickets (SLTs), are hidden in randomly\ninitialized neural networks. Although recent theoretical studies have\nestablished the SLTH across various neural architectures, the SLTH for\ntransformer architectures still lacks theoretical understanding. In particular,\nthe current theory of the SLTH does not yet account for the multi-head\nattention (MHA) mechanism, a core component of transformers. To address this\ngap, we introduce a theoretical analysis of the existence of SLTs within MHAs.\nWe prove that, if a randomly initialized MHA of $H$ heads and input dimension\n$d$ has the hidden dimension $O(d\\log(Hd^{3/2}))$ for the key and value, it\ncontains an SLT that approximates an arbitrary MHA with the same input\ndimension with high probability. Furthermore, by leveraging this theory for\nMHAs, we extend the SLTH to transformers without normalization layers. We\nempirically validate our theoretical findings, demonstrating that the\napproximation error between the SLT within a source model (MHA and transformer)\nand an approximate target counterpart decreases exponentially by increasing the\nhidden dimension of the source model."}
{"id": "2511.04633", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04633", "abs": "https://arxiv.org/abs/2511.04633", "authors": ["Omri Shmueli", "Mark Zhandry"], "title": "Unclonable Cryptography in Linear Quantum Memory", "comment": null, "summary": "Quantum cryptography is a rapidly-developing area which leverages quantum\ninformation to accomplish classically-impossible tasks. In many of these\nprotocols, quantum states are used as long-term cryptographic keys. Typically,\nthis is to ensure the keys cannot be copied by an adversary, owing to the\nquantum no-cloning theorem. Unfortunately, due to quantum state's tendency to\ndecohere, persistent quantum memory will likely be one of the most challenging\nresources for quantum computers. As such, it will be important to minimize\npersistent memory in quantum protocols.\n  In this work, we consider the case of one-shot signatures (OSS), and more\ngeneral quantum signing tokens. These are important unclonable primitives,\nwhere quantum signing keys allow for signing a single message but not two.\nNaturally, these quantum signing keys would require storage in long-term\nquantum memory. Very recently, the first OSS was constructed in a classical\noracle model and also in the standard model, but we observe that the quantum\nmemory required for these protocols is quite large. In this work, we\nsignificantly decrease the quantum secret key size, in some cases achieving\nasymptotically optimal size. To do so, we develop novel techniques for proving\nthe security of cryptosystems using coset states, which are one of the main\ntools used in unclonable cryptography."}
{"id": "2511.04239", "categories": ["cs.LG", "cs.AI", "68T01"], "pdf": "https://arxiv.org/pdf/2511.04239", "abs": "https://arxiv.org/abs/2511.04239", "authors": ["Rasmus Møller-Larsen", "Adam Izdebski", "Jan Olszewski", "Pankhil Gawade", "Michal Kmicikiewicz", "Wojciech Zarzecki", "Ewa Szczurek"], "title": "seqme: a Python library for evaluating biological sequence design", "comment": "13 pages", "summary": "Recent advances in computational methods for designing biological sequences\nhave sparked the development of metrics to evaluate these methods performance\nin terms of the fidelity of the designed sequences to a target distribution and\ntheir attainment of desired properties. However, a single software library\nimplementing these metrics was lacking. In this work we introduce seqme, a\nmodular and highly extendable open-source Python library, containing\nmodel-agnostic metrics for evaluating computational methods for biological\nsequence design. seqme considers three groups of metrics: sequence-based,\nembedding-based, and property-based, and is applicable to a wide range of\nbiological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.\nThe library offers a number of embedding and property models for biological\nsequences, as well as diagnostics and visualization functions to inspect the\nresults. seqme can be used to evaluate both one-shot and iterative\ncomputational design methods."}
{"id": "2511.04634", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04634", "abs": "https://arxiv.org/abs/2511.04634", "authors": ["Koki Okada", "Kenta Kasai"], "title": "Random Construction of Quantum LDPC Codes", "comment": null, "summary": "We propose a method for modifying orthogonal sparse matrix pairs used in CSS\ncodes while preserving their matrix row and column weight distributions, which\nplay a crucial role in determining the performance of belief-propagation\ndecoding. Unlike simple row or column permutations that merely reorder existing\nelements, the proposed local modification introduces genuine structural\nrandomness through small $2\\times2$ cross-swap operations followed by\ninteger-linear-program-based local repairs that restore orthogonality. By\napplying this procedure repeatedly in a random manner, ensembles of randomized\nquantum LDPC codes can be constructed. The computational complexity of each\nrepair depends only on the maximum row and column weights and is independent of\nthe overall matrix size, ensuring scalability to large code blocks."}
{"id": "2511.04244", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04244", "abs": "https://arxiv.org/abs/2511.04244", "authors": ["Irene Ferfoglia", "Simone Silvetti", "Gaia Saveri", "Laura Nenzi", "Luca Bortolussi"], "title": "Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics", "comment": "submitted to Journal of Artificial Intelligence Research (JAIR), 2025", "summary": "Time series classification is a task of paramount importance, as this kind of\ndata often arises in safety-critical applications. However, it is typically\ntackled with black-box deep learning methods, making it hard for humans to\nunderstand the rationale behind their output. To take on this challenge, we\npropose a novel approach, STELLE (Signal Temporal logic Embedding for\nLogically-grounded Learning and Explanation), a neuro-symbolic framework that\nunifies classification and explanation through direct embedding of trajectories\ninto a space of temporal logic concepts. By introducing a novel STL-inspired\nkernel that maps raw time series to their alignment with predefined STL\nformulae, our model jointly optimises accuracy and interpretability, as each\nprediction is accompanied by the most relevant logical concepts that\ncharacterise it. This yields (i) local explanations as human-readable STL\nconditions justifying individual predictions, and (ii) global explanations as\nclass-characterising formulae. Experiments demonstrate that STELLE achieves\ncompetitive accuracy while providing logically faithful explanations, validated\non diverse real-world benchmarks."}
{"id": "2511.04648", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04648", "abs": "https://arxiv.org/abs/2511.04648", "authors": ["Sören Arlt", "Mario Krenn", "Xuemei Gu"], "title": "Automated Discovery of Non-local Photonic Gates", "comment": "10 pages, 4 figures", "summary": "Interactions between quantum systems enable quantum gates, the building\nblocks of quantum information processing. In photonics, direct photon-photon\ninteractions are too weak to be practically useful, so effective interactions\nare engineered with linear optics and measurement. A central challenge is to\nrealize such interactions non-locally, i.e., between photons that remain\nspatially separated. We present experimental proposals for several essential\nnon-local multiphoton quantum gates that act on spatially separated photons, in\nboth qubit and high-dimensional qudit systems. All solutions were discovered by\nthe AI-driven discovery system called PyTheus. Rather than using pre-shared\nentanglement or Bell state measurements, our gates use as a resource quantum\nindistinguishability by path identity - a technique that exploits coherent\nsuperpositions of the photon pair origins. While analyzing these solutions, we\nuncovered a new mechanism that mimics much of the properties of quantum\nteleportation, without shared entanglement or Bell state measurements.\nTechnically, our results establish path indistinguishability as a practical\nresource for distributed quantum information processing; conceptually, they\ndemonstrate how automated discovery systems can contribute new ideas and\ntechniques in physics."}
{"id": "2511.04286", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04286", "abs": "https://arxiv.org/abs/2511.04286", "authors": ["Matteo Cercola", "Valeria Capretti", "Simone Formentin"], "title": "Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference", "comment": null, "summary": "Learning from human preferences is a cornerstone of aligning machine learning\nmodels with subjective human judgments. Yet, collecting such preference data is\noften costly and time-consuming, motivating the need for more efficient\nlearning paradigms. Two established approaches offer complementary advantages:\nRLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,\nwhile PBO achieves greater sample efficiency through active querying. We\npropose a hybrid framework that unifies RLHF's scalability with PBO's query\nefficiency by integrating an acquisition-driven module into the RLHF pipeline,\nthereby enabling active and sample-efficient preference gathering. We validate\nthe proposed approach on two representative domains: (i) high-dimensional\npreference optimization and (ii) LLM fine-tuning. Experimental results\ndemonstrate consistent improvements in both sample efficiency and overall\nperformance across these tasks."}
{"id": "2511.04657", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04657", "abs": "https://arxiv.org/abs/2511.04657", "authors": ["Jasper Kranias", "Christian Drago", "Colin Vendromin", "J. E. Sipe"], "title": "Photodetection of Squeezed Light: a Whittaker-Shannon Analysis", "comment": "27 pages, 12 figures", "summary": "The Whittaker-Shannon decomposition provides a temporally localized\ndescription of squeezed light, making it applicable in the CW limit and leading\nto a definition of squeezing strength based on the number of photon pairs at a\ntime. We show examples of its usefulness by calculating quadrature variance in\na homodyne detection scheme, coincidence detection probabilities in the\ncontinuous-wave limit, and analyzing the Hong-Ou-Mandel effect for strongly\nsqueezed light. Quadrature uncertainty falls farther below the shot noise limit\nwhen squeezing is strong, but effects due to correlations between photon pairs\nare most significant with weak squeezing. Our analysis extends previous results\nto more general scenarios, and we leverage the Whittaker-Shannon formalism to\ninterpret them based on the temporal properties of photon pairs."}
{"id": "2511.04332", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04332", "abs": "https://arxiv.org/abs/2511.04332", "authors": ["Antti Koskela", "Tejas Kulkarni", "Laith Zumot"], "title": "Differentially Private In-Context Learning with Nearest Neighbor Search", "comment": "NeurIPS Lock-LLM Workshop 2025", "summary": "Differentially private in-context learning (DP-ICL) has recently become an\nactive research topic due to the inherent privacy risks of in-context learning.\nHowever, existing approaches overlook a critical component of modern large\nlanguage model (LLM) pipelines: the similarity search used to retrieve relevant\ncontext data. In this work, we introduce a DP framework for in-context learning\nthat integrates nearest neighbor search of relevant examples in a privacy-aware\nmanner. Our method outperforms existing baselines by a substantial margin\nacross all evaluated benchmarks, achieving more favorable privacy-utility\ntrade-offs. To achieve this, we employ nearest neighbor retrieval from a\ndatabase of context data, combined with a privacy filter that tracks the\ncumulative privacy cost of selected samples to ensure adherence to a central\ndifferential privacy budget. Experimental results on text classification and\ndocument question answering show a clear advantage of the proposed method over\nexisting baselines."}
{"id": "2511.04669", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.04669", "abs": "https://arxiv.org/abs/2511.04669", "authors": ["Arjan Cornelissen", "Nikhil S. Mande", "Subhasree Patro", "Nithish Raja", "Swagato Sanyal"], "title": "Quantum Search With Generalized Wildcards", "comment": null, "summary": "In the search with wildcards problem [Ambainis, Montanaro, Quantum\nInf.~Comput.'14], one's goal is to learn an unknown bit-string $x \\in\n\\{-1,1\\}^n$. An algorithm may, at unit cost, test equality of any subset of the\nhidden string with a string of its choice. Ambainis and Montanaro showed a\nquantum algorithm of cost $O(\\sqrt{n} \\log n)$ and a near-matching lower bound\nof $\\Omega(\\sqrt{n})$. Belovs [Comput.~Comp.'15] subsequently showed a tight\n$O(\\sqrt{n})$ upper bound.\n  We consider a natural generalization of this problem, parametrized by a\nsubset $\\cal{Q} \\subseteq 2^{[n]}$, where an algorithm may test whether $x_S =\nb$ for an arbitrary $S \\in \\cal{Q}$ and $b \\in \\{-1,1\\}^S$ of its choice, at\nunit cost. We show near-tight bounds when $\\cal{Q}$ is any of the following\ncollections: bounded-size sets, contiguous blocks, prefixes, and only the full\nset.\n  All of these results are derived using a framework that we develop. Using\nsymmetries of the task at hand we show that the quantum query complexity of\nlearning $x$ is characterized, up to a constant factor, by an optimization\nprogram, which is succinctly described as follows: `maximize over all odd\nfunctions $f : \\{-1,1\\}^n \\to \\mathbb{R}$ the ratio of the maximum value of $f$\nto the maximum (over $T \\in \\cal{Q}$) standard deviation of $f$ on a subcube\nwhose free variables are exactly $T$.'\n  To the best of our knowledge, ours is the first work to use the primal\nversion of the negative-weight adversary bound (which is a maximization program\ntypically used to show lower bounds) to show new quantum query upper bounds\nwithout explicitly resorting to SDP duality."}
{"id": "2511.04333", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04333", "abs": "https://arxiv.org/abs/2511.04333", "authors": ["Federico Pirola", "Fabio Stella", "Marco Grzegorczyk"], "title": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care", "comment": "27 pages, 8 figures, 3 tables, presented at HC@AIxIA + HYDRA 2025\n  Workshop located at ECAI 2025 Conference", "summary": "Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to\ntheir ability to model complex temporal relationships in patient data while\nmaintaining interpretability, an essential feature for clinical\ndecision-making. However, existing approaches to handling missing data in\nlongitudinal clinical datasets are largely derived from static Bayesian\nnetworks literature, failing to properly account for the temporal nature of the\ndata. This gap limits the ability to quantify uncertainty over time, which is\nparticularly critical in settings such as intensive care, where understanding\nthe temporal dynamics is fundamental for model trustworthiness and\napplicability across diverse patient groups. Despite the potential of DBNs, a\nfull Bayesian framework that integrates missing data handling remains\nunderdeveloped. In this work, we propose a novel Gibbs sampling-based method\nfor learning DBNs from incomplete data. Our method treats each missing value as\nan unknown parameter following a Gaussian distribution. At each iteration, the\nunobserved values are sampled from their full conditional distributions,\nallowing for principled imputation and uncertainty estimation. We evaluate our\nmethod on both simulated datasets and real-world intensive care data from\ncritically ill patients. Compared to standard model-agnostic techniques such as\nMICE, our Bayesian approach demonstrates superior reconstruction accuracy and\nconvergence properties. These results highlight the clinical relevance of\nincorporating full Bayesian inference in temporal models, providing more\nreliable imputations and offering deeper insight into model behavior. Our\napproach supports safer and more informed clinical decision-making,\nparticularly in settings where missing data are frequent and potentially\nimpactful."}
{"id": "2511.04401", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04401", "abs": "https://arxiv.org/abs/2511.04401", "authors": ["Subeen Park", "Joowang Kim", "Hakyung Lee", "Sunjae Yoo", "Kyungwoo Song"], "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness", "comment": null, "summary": "Deep learning models achieve strong performance across various domains but\noften rely on spurious correlations, making them vulnerable to distribution\nshifts. This issue is particularly severe in subpopulation shift scenarios,\nwhere models struggle in underrepresented groups. While existing methods have\nmade progress in mitigating this issue, their performance gains are still\nconstrained. They lack a rigorous theoretical framework connecting the\nembedding space representations with worst-group error. To address this\nlimitation, we propose Spurious Correlation-Aware Embedding Regularization for\nWorst-Group Robustness (SCER), a novel approach that directly regularizes\nfeature representations to suppress spurious cues. We show theoretically that\nworst-group error is influenced by how strongly the classifier relies on\nspurious versus core directions, identified from differences in group-wise mean\nembeddings across domains and classes. By imposing theoretical constraints at\nthe embedding level, SCER encourages models to focus on core features while\nreducing sensitivity to spurious patterns. Through systematic evaluation on\nmultiple vision and language, we show that SCER outperforms prior\nstate-of-the-art studies in worst-group accuracy. Our code is available at\n\\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}."}
{"id": "2511.04418", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04418", "abs": "https://arxiv.org/abs/2511.04418", "authors": ["Tim Tomov", "Dominik Fuchsgruber", "Tom Wollschläger", "Stephan Günnemann"], "title": "The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity", "comment": null, "summary": "Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is\ncritical for trustworthy deployment. While real-world language is inherently\nambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically\nbenchmarked against tasks with no ambiguity. In this work, we demonstrate that\nwhile current uncertainty estimators perform well under the restrictive\nassumption of no ambiguity, they degrade to close-to-random performance on\nambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first\nambiguous question-answering (QA) datasets equipped with ground-truth answer\ndistributions estimated from factual co-occurrence. We find this performance\ndeterioration to be consistent across different estimation paradigms: using the\npredictive distribution itself, internal representations throughout the model,\nand an ensemble of models. We show that this phenomenon can be theoretically\nexplained, revealing that predictive-distribution and ensemble-based estimators\nare fundamentally limited under ambiguity. Overall, our study reveals a key\nshortcoming of current UQ methods for LLMs and motivates a rethinking of\ncurrent modeling paradigms."}
{"id": "2511.04422", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T05, 68T10, 68Q32", "I.2.6; I.5.1; I.5.2"], "pdf": "https://arxiv.org/pdf/2511.04422", "abs": "https://arxiv.org/abs/2511.04422", "authors": ["Jayadeva", "Naman Dwivedi", "Hari Krishnan", "N. M. Anoop Krishnan"], "title": "On the Equivalence of Regression and Classification", "comment": "19 pages", "summary": "A formal link between regression and classification has been tenuous. Even\nthough the margin maximization term $\\|w\\|$ is used in support vector\nregression, it has at best been justified as a regularizer. We show that a\nregression problem with $M$ samples lying on a hyperplane has a one-to-one\nequivalence with a linearly separable classification task with $2M$ samples. We\nshow that margin maximization on the equivalent classification task leads to a\ndifferent regression formulation than traditionally used. Using the\nequivalence, we demonstrate a ``regressability'' measure, that can be used to\nestimate the difficulty of regressing a dataset, without needing to first learn\na model for it. We use the equivalence to train neural networks to learn a\nlinearizing map, that transforms input variables into a space where a linear\nregressor is adequate."}
{"id": "2511.04445", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04445", "abs": "https://arxiv.org/abs/2511.04445", "authors": ["Syeda Sitara Wishal Fatima", "Afshin Rahimi"], "title": "ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting", "comment": "Portions of this work were previously published in the author's\n  Master's thesis at University of Windsor (2024)", "summary": "Time series forecasting is essential across domains from finance to supply\nchain management. This paper introduces ForecastGAN, a novel decomposition\nbased adversarial framework addressing limitations in existing approaches for\nmulti-horizon predictions. Although transformer models excel in long-term\nforecasting, they often underperform in short-term scenarios and typically\nignore categorical features. ForecastGAN operates through three integrated\nmodules: a Decomposition Module that extracts seasonality and trend components;\na Model Selection Module that identifies optimal neural network configurations\nbased on forecasting horizon; and an Adversarial Training Module that enhances\nprediction robustness through Conditional Generative Adversarial Network\ntraining. Unlike conventional approaches, ForecastGAN effectively integrates\nboth numerical and categorical features. We validate our framework on eleven\nbenchmark multivariate time series datasets that span various forecasting\nhorizons. The results show that ForecastGAN consistently outperforms\nstate-of-the-art transformer models for short-term forecasting while remaining\ncompetitive for long-term horizons. This research establishes a more\ngeneralizable approach to time series forecasting that adapts to specific\ncontexts while maintaining strong performance across diverse data\ncharacteristics without extensive hyperparameter tuning."}
{"id": "2511.04456", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04456", "abs": "https://arxiv.org/abs/2511.04456", "authors": ["Xinwen Zhang", "Hongchang Gao"], "title": "Federated Stochastic Minimax Optimization under Heavy-Tailed Noises", "comment": null, "summary": "Heavy-tailed noise has attracted growing attention in nonconvex stochastic\noptimization, as numerous empirical studies suggest it offers a more realistic\nassumption than standard bounded variance assumption. In this work, we\ninvestigate nonconvex-PL minimax optimization under heavy-tailed gradient noise\nin federated learning. We propose two novel algorithms: Fed-NSGDA-M, which\nintegrates normalized gradients, and FedMuon-DA, which leverages the Muon\noptimizer for local updates. Both algorithms are designed to effectively\naddress heavy-tailed noise in federated minimax optimization, under a milder\ncondition. We theoretically establish that both algorithms achieve a\nconvergence rate of $O({1}/{(TNp)^{\\frac{s-1}{2s}}})$. To the best of our\nknowledge, these are the first federated minimax optimization algorithms with\nrigorous theoretical guarantees under heavy-tailed noise. Extensive experiments\nfurther validate their effectiveness."}
{"id": "2511.04469", "categories": ["cs.LG", "q-fin.CP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.04469", "abs": "https://arxiv.org/abs/2511.04469", "authors": ["Dennis Thumm", "Luis Ontaneda Mijares"], "title": "Towards Causal Market Simulators", "comment": "ICAIF 2025 Workshop on Rethinking Financial Time-Series", "summary": "Market generators using deep generative models have shown promise for\nsynthetic financial data generation, but existing approaches lack causal\nreasoning capabilities essential for counterfactual analysis and risk\nassessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that\ncombines variational autoencoders with structural causal models to generate\ncounterfactual financial time series while preserving both temporal\ndependencies and causal relationships. Our approach enforces causal constraints\nthrough directed acyclic graphs in the decoder architecture and employs the\ncausal Wasserstein distance for training. We validate our method on synthetic\nautoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating\nsuperior performance in counterfactual probability estimation with L1 distances\nas low as 0.03-0.10 compared to ground truth. The model enables financial\nstress testing, scenario analysis, and enhanced backtesting by generating\nplausible counterfactual market trajectories that respect underlying causal\nmechanisms."}
{"id": "2511.04473", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.04473", "abs": "https://arxiv.org/abs/2511.04473", "authors": ["Alberto Cattaneo", "Carlo Luschi", "Daniel Justus"], "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs", "comment": null, "summary": "Retrieval of information from graph-structured knowledge bases represents a\npromising direction for improving the factuality of LLMs. While various\nsolutions have been proposed, a comparison of methods is difficult due to the\nlack of challenging QA datasets with ground-truth targets for graph retrieval.\nWe present SynthKGQA, a framework for generating high-quality synthetic\nKnowledge Graph Question Answering datasets from any Knowledge Graph, providing\nthe full set of ground-truth facts in the KG to reason over each question. We\nshow how, in addition to enabling more informative benchmarking of KG\nretrievers, the data produced with SynthKGQA also allows us to train better\nmodels. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset\ndesigned to test zero-shot generalization abilities of KG retrievers with\nrespect to unseen graph structures and relation types, and benchmark popular\nsolutions for KG-augmented LLMs on it."}
{"id": "2511.04485", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.04485", "abs": "https://arxiv.org/abs/2511.04485", "authors": ["Ipsita Ghosh", "Ethan Nguyen", "Christian Kümmerle"], "title": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training", "comment": null, "summary": "Parameter-efficient training, based on low-rank optimization, has become a\nhighly successful tool for fine-tuning large deep-learning models. However,\nthese methods fail at low-rank pre-training tasks where maintaining the\nlow-rank structure and the objective remains a challenging task. We propose the\nQuadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel\nlow-rank inducing training strategy inspired by the iteratively reweighted\nleast squares (IRLS) framework. Q3R is based on a quadratic regularizer term\nwhich majorizes a smoothed log determinant serving as rank surrogate objective.\nUnlike other low-rank training techniques, Q3R is able to train weight matrices\nwith prescribed, low target ranks of models that achieve comparable predictive\nperformance as dense models, with small computational overhead, while remaining\nfully compatible with existing architectures. For example, we demonstrated one\nexperiment where we are able to truncate $60\\%$ and $80\\%$ of the parameters of\na ViT-Tiny model with $~1.3\\%$ and $~4\\%$ accuracy drop in CIFAR-10 performance\nrespectively. The efficacy of Q3R is confirmed on Transformers across both\nimage and language tasks, including for low-rank fine-tuning."}
{"id": "2511.04494", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04494", "abs": "https://arxiv.org/abs/2511.04494", "authors": ["Alper Kalle", "Theo Rudkiewicz", "Mohamed-Oumar Ouerfelli", "Mohamed Tamaazousti"], "title": "Distribution-Aware Tensor Decomposition for Compression of Convolutional Neural Networks", "comment": null, "summary": "Neural networks are widely used for image-related tasks but typically demand\nconsiderable computing power. Once a network has been trained, however, its\nmemory- and compute-footprint can be reduced by compression. In this work, we\nfocus on compression through tensorization and low-rank representations.\nWhereas classical approaches search for a low-rank approximation by minimizing\nan isotropic norm such as the Frobenius norm in weight-space, we use\ndata-informed norms that measure the error in function space. Concretely, we\nminimize the change in the layer's output distribution, which can be expressed\nas $\\lVert (W - \\widetilde{W}) \\Sigma^{1/2}\\rVert_F$ where $\\Sigma^{1/2}$ is\nthe square root of the covariance matrix of the layer's input and $W$,\n$\\widetilde{W}$ are the original and compressed weights. We propose new\nalternating least square algorithms for the two most common tensor\ndecompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike\nconventional compression pipelines, which almost always require\npost-compression fine-tuning, our data-informed approach often achieves\ncompetitive accuracy without any fine-tuning. We further show that the same\ncovariance-based norm can be transferred from one dataset to another with only\na minor accuracy drop, enabling compression even when the original training\ndataset is unavailable. Experiments on several CNN architectures (ResNet-18/50,\nand GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100)\nconfirm the advantages of the proposed method."}
{"id": "2511.04505", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.04505", "abs": "https://arxiv.org/abs/2511.04505", "authors": ["Shaolong Wu", "James Blume", "Geshi Yeung"], "title": "Alternative Fairness and Accuracy Optimization in Criminal Justice", "comment": "Accepted for presentation at the AAAI 2026 AI Governance Workshop\n  (AIGOV). 24 pages", "summary": "Algorithmic fairness has grown rapidly as a research area, yet key concepts\nremain unsettled, especially in criminal justice. We review group, individual,\nand process fairness and map the conditions under which they conflict. We then\ndevelop a simple modification to standard group fairness. Rather than exact\nparity across protected groups, we minimize a weighted error loss while keeping\ndifferences in false negative rates within a small tolerance. This makes\nsolutions easier to find, can raise predictive accuracy, and surfaces the\nethical choice of error costs. We situate this proposal within three classes of\ncritique: biased and incomplete data, latent affirmative action, and the\nexplosion of subgroup constraints. Finally, we offer a practical framework for\ndeployment in public decision systems built on three pillars: need-based\ndecisions, Transparency and accountability, and narrowly tailored definitions\nand solutions. Together, these elements link technical design to legitimacy and\nprovide actionable guidance for agencies that use risk assessment and related\ntools."}
{"id": "2511.04514", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04514", "abs": "https://arxiv.org/abs/2511.04514", "authors": ["C. Hepburn", "T. Zielke", "A. P. Raulf"], "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers", "comment": "16 pages, 22 figures", "summary": "The phenomenon of linear mode connectivity (LMC) links several aspects of\ndeep learning, including training stability under noisy stochastic gradients,\nthe smoothness and generalization of local minima (basins), the similarity and\nfunctional diversity of sampled models, and architectural effects on data\nprocessing. In this work, we experimentally study LMC under data shifts and\nidentify conditions that mitigate their impact. We interpret data shifts as an\nadditional source of stochastic gradient noise, which can be reduced through\nsmall learning rates and large batch sizes. These parameters influence whether\nmodels converge to the same local minimum or to regions of the loss landscape\nwith varying smoothness and generalization. Although models sampled via LMC\ntend to make similar errors more frequently than those converging to different\nbasins, the benefit of LMC lies in balancing training efficiency against the\ngains achieved from larger, more diverse ensembles. Code and supplementary\nmaterials will be made publicly available at https://github.com/DLR-KI/LMC in\ndue course."}
{"id": "2511.04518", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML", "68T05, 62J07, 65M20, 65M60", "I.2.6; G.1.2; G.1.8"], "pdf": "https://arxiv.org/pdf/2511.04518", "abs": "https://arxiv.org/abs/2511.04518", "authors": ["Obed Amo", "Samit Ghosh", "Markus Lange-Hegermann", "Bogdan Raiţă", "Michael Pokojovy"], "title": "Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity", "comment": "14 pages, 2 figures", "summary": "We present a new benchmarking study comparing a boundary-constrained\nEhrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical\nfinite element method combined with Crank--Nicolson time stepping (CN-FEM) for\nsolving the two-dimensional wave equation with homogeneous Dirichlet boundary\nconditions. The B-EPGP construction leverages exponential-polynomial bases\nderived from the characteristic variety to enforce the PDE and boundary\nconditions exactly and employs penalized least squares to estimate the\ncoefficients. To ensure fairness across paradigms, we introduce a\ndegrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP\nconsistently attains lower space-time $L^2$-error and maximum-in-time\n$L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of\nmagnitude."}
{"id": "2511.04522", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.04522", "abs": "https://arxiv.org/abs/2511.04522", "authors": ["Daniel Mayfrank", "Kayra Dernek", "Laura Lang", "Alexander Mitsos", "Manuel Dahmen"], "title": "End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air Separation Unit", "comment": "manuscript (8 pages, 5 figures, 1 table), supplementary materials (5\n  pages, 1 figure, 1 table)", "summary": "With our recently proposed method based on reinforcement learning (Mayfrank\net al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained\nfor optimal performance in specific (economic) nonlinear model predictive\ncontrol ((e)NMPC) applications. So far, our method has exclusively been\ndemonstrated on a small-scale case study. Herein, we show that our method\nscales well to a more challenging demand response case study built on a\nlarge-scale model of a single-product (nitrogen) air separation unit. Across\nall numerical experiments, we assume observability of only a few realistically\nmeasurable plant variables. Compared to a purely system identification-based\nKoopman eNMPC, which generates small economic savings but frequently violates\nconstraints, our method delivers similar economic performance while avoiding\nconstraint violations."}
{"id": "2511.04534", "categories": ["cs.LG", "physics.ao-ph", "physics.comp-ph", "I.6.5; I.2.6; G.3; J.2"], "pdf": "https://arxiv.org/pdf/2511.04534", "abs": "https://arxiv.org/abs/2511.04534", "authors": ["Jonas E. Katona", "Emily K. de Jong", "Nipun Gunawardena"], "title": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics", "comment": "Accepted at the NeurIPS 2025 Workshop on Machine Learning and the\n  Physical Sciences (ML4PS). 11 pages, 4 figures, 1 table. LLNL-CONF-2010541", "summary": "Reduced-order models (ROMs) can efficiently simulate high-dimensional\nphysical systems, but lack robust uncertainty quantification methods. Existing\napproaches are frequently architecture- or training-specific, which limits\nflexibility and generalization. We introduce a post hoc, model-agnostic\nframework for predictive uncertainty quantification in latent space ROMs that\nrequires no modification to the underlying architecture or training procedure.\nUsing conformal prediction, our approach estimates statistical prediction\nintervals for multiple components of the ROM pipeline: latent dynamics,\nreconstruction, and end-to-end predictions. We demonstrate the method on a\nlatent space dynamical model for cloud microphysics, where it accurately\npredicts the evolution of droplet-size distributions and quantifies uncertainty\nacross the ROM pipeline."}
{"id": "2511.04557", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04557", "abs": "https://arxiv.org/abs/2511.04557", "authors": ["Divyansha Lachi", "Mahmoud Mohammadi", "Joe Meyer", "Vinam Arora", "Tom Palczewski", "Eva L. Dyer"], "title": "Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning", "comment": null, "summary": "In domains such as healthcare, finance, and e-commerce, the temporal dynamics\nof relational data emerge from complex interactions-such as those between\npatients and providers, or users and products across diverse categories. To be\nbroadly useful, models operating on these data must integrate long-range\nspatial and temporal dependencies across diverse types of entities, while also\nsupporting multiple predictive tasks. However, existing graph models for\nrelational data primarily focus on spatial structure, treating temporal\ninformation merely as a filtering constraint to exclude future events rather\nthan a modeling signal, and are typically designed for single-task prediction.\nTo address these gaps, we introduce a temporal subgraph sampler that enhances\nglobal context by retrieving nodes beyond the immediate neighborhood to capture\ntemporally relevant relationships. In addition, we propose the Relational Graph\nPerceiver (RGP), a graph transformer architecture for relational deep learning\nthat leverages a cross-attention-based latent bottleneck to efficiently\nintegrate information from both structural and temporal contexts. This latent\nbottleneck integrates signals from different node and edge types into a common\nlatent space, enabling the model to build global context across the entire\nrelational system. RGP also incorporates a flexible cross-attention decoder\nthat supports joint learning across tasks with disjoint label spaces within a\nsingle model. Experiments on RelBench, SALT, and CTU show that RGP delivers\nstate-of-the-art performance, offering a general and scalable solution for\nrelational deep learning with support for diverse predictive tasks."}
{"id": "2511.04573", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04573", "abs": "https://arxiv.org/abs/2511.04573", "authors": ["Vasco V. Branco", "Jandó Benedek", "Lidia Pivovarova", "Luís Correia", "Pedro Cardoso"], "title": "ARETE: an R package for Automated REtrieval from TExt with large language models", "comment": null, "summary": "1. A hard stop for the implementation of rigorous conservation initiatives is\nour lack of key species data, especially occurrence data. Furthermore,\nresearchers have to contend with an accelerated speed at which new information\nmust be collected and processed due to anthropogenic activity. Publications\nranging from scientific papers to gray literature contain this crucial\ninformation but their data are often not machine-readable, requiring extensive\nhuman work to be retrieved. 2. We present the ARETE R package, an open-source\nsoftware aiming to automate data extraction of species occurrences powered by\nlarge language models, namely using the chatGPT Application Programming\nInterface. This R package integrates all steps of the data extraction and\nvalidation process, from Optical Character Recognition to detection of outliers\nand output in tabular format. Furthermore, we validate ARETE through systematic\ncomparison between what is modelled and the work of human annotators. 3. We\ndemonstrate the usefulness of the approach by comparing range maps produced\nusing GBIF data and with those automatically extracted for 100 species of\nspiders. Newly extracted data allowed to expand the known Extent of Occurrence\nby a mean three orders of magnitude, revealing new areas where the species were\nfound in the past, which mayhave important implications for spatial\nconservation planning and extinction risk assessments. 4. ARETE allows faster\naccess to hitherto untapped occurrence data, a potential game changer in\nprojects requiring such data. Researchers will be able to better prioritize\nresources, manually verifying selected species while maintaining automated\nextraction for the majority. This workflow also allows predicting available\nbibliographic data during project planning."}
{"id": "2511.04590", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04590", "abs": "https://arxiv.org/abs/2511.04590", "authors": ["Oshri Naparstek"], "title": "Complexity as Advantage: A Regret-Based Perspective on Emergent Structure", "comment": "15 pages. Under preparation for submission to ICML 2026. Feedback\n  welcome", "summary": "We introduce Complexity as Advantage (CAA), a framework that defines the\ncomplexity of a system relative to a family of observers. Instead of measuring\ncomplexity as an intrinsic property, we evaluate how much predictive regret a\nsystem induces for different observers attempting to model it. A system is\ncomplex when it is easy for some observers and hard for others, creating an\ninformation advantage. We show that this formulation unifies several notions of\nemergent behavior, including multiscale entropy, predictive information, and\nobserver-dependent structure. The framework suggests that \"interesting\" systems\nare those positioned to create differentiated regret across observers,\nproviding a quantitative grounding for why complexity can be functionally\nvaluable. We demonstrate the idea through simple dynamical models and discuss\nimplications for learning, evolution, and artificial agents."}
{"id": "2511.04594", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04594", "abs": "https://arxiv.org/abs/2511.04594", "authors": ["Utkarsh U. Chavan", "Prashant Trivedi", "Nandyala Hemachandra"], "title": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems", "comment": "To appear in 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "summary": "Multi-agent systems (MAS) are central to applications such as swarm robotics\nand traffic routing, where agents must coordinate in a decentralized manner to\nachieve a common objective. Stochastic Shortest Path (SSP) problems provide a\nnatural framework for modeling decentralized control in such settings. While\nthe problem of learning in SSP has been extensively studied in single-agent\nsettings, the decentralized multi-agent variant remains largely unexplored. In\nthis work, we take a step towards addressing that gap. We study decentralized\nmulti-agent SSPs (Dec-MASSPs) under linear function approximation, where the\ntransition dynamics and costs are represented using linear models. Applying\nnovel symmetry-based arguments, we identify the structure of optimal policies.\nOur main contribution is the first regret lower bound for this setting based on\nthe construction of hard-to-learn instances for any number of agents, $n$. Our\nregret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the\ninherent learning difficulty in Dec-MASSPs. These insights clarify the learning\ncomplexity of decentralized control and can further guide the design of\nefficient learning algorithms in multi-agent systems."}
{"id": "2511.04598", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04598", "abs": "https://arxiv.org/abs/2511.04598", "authors": ["Hampus Åström", "Elin Anna Topp", "Jacek Malec"], "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning", "comment": "8 pages without cover, references and supplementary materials, 11\n  with. Submitted to RLC 2025's workshop RLBrew and IMOL 2025", "summary": "In this paper we study how transforming regular reinforcement learning\nenvironments into goal-conditioned environments can let agents learn to solve\ntasks autonomously and reward-free. We show that an agent can learn to solve\ntasks by selecting its own goals in an environment-agnostic way, at training\ntimes comparable to externally guided reinforcement learning. Our method is\nindependent of the underlying off-policy learning algorithm. Since our method\nis environment-agnostic, the agent does not value any goals higher than others,\nleading to instability in performance for individual goals. However, in our\nexperiments, we show that the average goal success rate improves and\nstabilizes. An agent trained with this method can be instructed to seek any\nobservations made in the environment, enabling generic training of agents prior\nto specific use cases."}
{"id": "2511.04638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04638", "abs": "https://arxiv.org/abs/2511.04638", "authors": ["Satchel Grant", "Simon Jerome Han", "Alexa Tartaglini", "Christopher Potts"], "title": "Addressing divergent representations from causal interventions on neural networks", "comment": null, "summary": "A common approach to mechanistic interpretability is to causally manipulate\nmodel representations via targeted interventions in order to understand what\nthose representations encode. Here we ask whether such interventions create\nout-of-distribution (divergent) representations, and whether this raises\nconcerns about how faithful their resulting explanations are to the target\nmodel in its natural state. First, we demonstrate empirically that common\ncausal intervention techniques often do shift internal representations away\nfrom the natural distribution of the target model. Then, we provide a\ntheoretical analysis of two classes of such divergences: `harmless' divergences\nthat occur in the null-space of the weights and from covariance within\nbehavioral decision boundaries, and `pernicious' divergences that activate\nhidden network pathways and cause dormant behavioral changes. Finally, in an\neffort to mitigate the pernicious cases, we modify the Counterfactual Latent\n(CL) loss from Grant (2025) that regularizes interventions to remain closer to\nthe natural distributions, reducing the likelihood of harmful divergences while\npreserving the interpretive power of interventions. Together, these results\nhighlight a path towards more reliable interpretability methods."}
{"id": "2511.04641", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04641", "abs": "https://arxiv.org/abs/2511.04641", "authors": ["Hans Harder", "Abhijeet Vishwasrao", "Luca Guastoni", "Ricardo Vinuesa", "Sebastian Peitz"], "title": "Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems", "comment": null, "summary": "This paper is concerned with probabilistic techniques for forecasting\ndynamical systems described by partial differential equations (such as, for\nexample, the Navier-Stokes equations). In particular, it is investigating and\ncomparing various extensions to the flow matching paradigm that reduce the\nnumber of sampling steps. In this regard, it compares direct distillation,\nprogressive distillation, adversarial diffusion distillation, Wasserstein GANs\nand rectified flows. Moreover, experiments are conducted on a set of\nchallenging systems. In particular, we also address the challenge of directly\npredicting 2D slices of large-scale 3D simulations, paving the way for\nefficient inflow generation for solvers."}
{"id": "2511.04647", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04647", "abs": "https://arxiv.org/abs/2511.04647", "authors": ["Sitan Chen", "Kevin Cong", "Jerry Li"], "title": "Optimal Inference Schedules for Masked Diffusion Models", "comment": "33 pages, 1 figure", "summary": "A major bottleneck of standard auto-regressive large language models is that\ntheir inference process is inherently sequential, resulting in very long and\ncostly inference times. To circumvent this, practitioners proposed a class of\nlanguage models called diffusion language models, of which the masked diffusion\nmodel (MDM) is the most successful. The MDM is able to sample tokens\nout-of-order and, ostensibly, many tokens at once and in parallel. However,\nthere is very limited rigorous understanding of how much parallel sampling\nthese models can perform without noticeable degradation in their sampling\nperformance. Prior work of Li and Cai obtained some preliminary bounds, but\nthese are not tight for many natural classes of distributions. In this work, we\ngive a new, exact characterization of the expected divergence between the true\ndistribution and the sampled distribution, for any distribution and any\nunmasking schedule for the sampler, showing an elegant connection to the theory\nof univariate function approximation.\n  By leveraging this connection, we then attain a number of novel lower and\nupper bounds for this problem. While the connection to function approximation\nin principle gives the optimal unmasking schedule for any distribution, we show\nthat it is in general impossible to compete with it without strong a priori\nknowledge of the distribution, even in seemingly benign settings. However, we\nalso demonstrate new upper bounds and new sampling schedules in terms of\nwell-studied information-theoretic properties of the base distribution, namely,\nits total correlation and dual total correlation, which show that in some\nnatural settings, one can sample in $O(log n)$ steps without any visible loss\nin performance, where $n$ is the total sequence length."}
{"id": "2511.04653", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04653", "abs": "https://arxiv.org/abs/2511.04653", "authors": ["Xinlu Zhang", "Yansha Deng", "Toktam Mahmoodi"], "title": "TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning", "comment": null, "summary": "Federated learning (FL) offers new opportunities in machine learning,\nparticularly in addressing data privacy concerns. In contrast to conventional\nevent-based federated learning, time-triggered federated learning (TT-Fed), as\na general form of both asynchronous and synchronous FL, clusters users into\ndifferent tiers based on fixed time intervals. However, the FL network consists\nof a growing number of user devices with limited wireless bandwidth,\nconsequently magnifying issues such as stragglers and communication overhead.\nIn this paper, we introduce adaptive model pruning to wireless TT-Fed systems\nand study the problem of jointly optimizing the pruning ratio and bandwidth\nallocation to minimize the training loss while ensuring minimal learning\nlatency. To answer this question, we perform convergence analysis on the\ngradient l_2 norm of the TT-Fed model based on model pruning. Based on the\nobtained convergence upper bound, a joint optimization problem of pruning ratio\nand wireless bandwidth is formulated to minimize the model training loss under\na given delay threshold. Then, we derive closed-form solutions for wireless\nbandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The\nsimulation results show that model pruning could reduce the communication cost\nby 40% while maintaining the model performance at the same level."}
{"id": "2511.04659", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.04659", "abs": "https://arxiv.org/abs/2511.04659", "authors": ["Huaguan Chen", "Wei Han", "Haofei Sun", "Ning Lin", "Xingtao Song", "Yunfan Yang", "Jie Tian", "Yang Liu", "Ji-Rong Wen", "Xiaoye Zhang", "Xueshun Shen", "Hao Sun"], "title": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning", "comment": null, "summary": "Extreme precipitation nowcasting demands high spatiotemporal fidelity and\nextended lead times, yet existing approaches remain limited. Numerical Weather\nPrediction (NWP) and its deep-learning emulations are too slow and coarse for\nrapidly evolving convection, while extrapolation and purely data-driven models\nsuffer from error accumulation and excessive smoothing. Hybrid 2D radar-based\nmethods discard crucial vertical information, preventing accurate\nreconstruction of height-dependent dynamics. We introduce a gray-box, fully\nthree-dimensional nowcasting framework that directly processes volumetric radar\nreflectivity and couples physically constrained neural operators with\ndatadriven learning. The model learns vertically varying 3D advection fields\nunder a conservative advection operator, parameterizes spatially varying\ndiffusion, and introduces a Brownian-motion--inspired stochastic term to\nrepresent unresolved motions. A residual branch captures small-scale convective\ninitiation and microphysical variability, while a diffusion-based stochastic\nmodule estimates uncertainty. The framework achieves more accurate forecasts up\nto three-hour lead time across precipitation regimes and ranked first in 57\\%\nof cases in a blind evaluation by 160 meteorologists. By restoring full 3D\ndynamics with physical consistency, it offers a scalable and robust pathway for\nskillful and reliable nowcasting of extreme precipitation."}
{"id": "2511.04666", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04666", "abs": "https://arxiv.org/abs/2511.04666", "authors": ["Ben Sanati", "Thomas L. Lee", "Trevor McInroe", "Aidan Scannell", "Nikolay Malkin", "David Abel", "Amos Storkey"], "title": "Forgetting is Everywhere", "comment": "Project page:\n  https://ben-sanati.github.io/forgetting-is-everywhere-project/", "summary": "A fundamental challenge in developing general learning algorithms is their\ntendency to forget past knowledge when adapting to new data. Addressing this\nproblem requires a principled understanding of forgetting; yet, despite decades\nof study, no unified definition has emerged that provides insights into the\nunderlying dynamics of learning. We propose an algorithm- and task-agnostic\ntheory that characterises forgetting as a lack of self-consistency in a\nlearner's predictive distribution over future experiences, manifesting as a\nloss of predictive information. Our theory naturally yields a general measure\nof an algorithm's propensity to forget. To validate the theory, we design a\ncomprehensive set of experiments that span classification, regression,\ngenerative modelling, and reinforcement learning. We empirically demonstrate\nhow forgetting is present across all learning settings and plays a significant\nrole in determining learning efficiency. Together, these results establish a\nprincipled understanding of forgetting and lay the foundation for analysing and\nimproving the information retention capabilities of general learning\nalgorithms."}
{"id": "2511.04667", "categories": ["cs.LG", "97C70, 62P25, 62H30, 68T05"], "pdf": "https://arxiv.org/pdf/2511.04667", "abs": "https://arxiv.org/abs/2511.04667", "authors": ["Julian D. Allagan", "Dasia A. Singleton", "Shanae N. Perry", "Gabrielle C. Morgan", "Essence A. Morgan"], "title": "Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches", "comment": "28 pages, 8 table, 4figures, NAM conference", "summary": "This study evaluates a 40-item mathematics placement examination administered\nto 198 students using a multi-method framework combining Classical Test Theory,\nmachine learning, and unsupervised clustering. Classical Test Theory analysis\nreveals that 55\\% of items achieve excellent discrimination ($D \\geq 0.40$)\nwhile 30\\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.\nQuestion 6 (Graph Interpretation) emerges as the examination's most powerful\ndiscriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA\nF-statistic ($F = 4609.1$), and maximum Random Forest feature importance\n(0.206), accounting for 20.6\\% of predictive power. Machine learning algorithms\ndemonstrate exceptional performance, with Random Forest and Gradient Boosting\nachieving 97.5\\% and 96.0\\% cross-validation accuracy. K-means clustering\nidentifies a natural binary competency structure with a boundary at 42.5\\%,\ndiverging from the institutional threshold of 55\\% and suggesting potential\noverclassification into remedial categories. The two-cluster solution exhibits\nexceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster\npurity. Convergent evidence across methods supports specific refinements:\nreplace poorly discriminating items, implement a two-stage assessment, and\nintegrate Random Forest predictions with transparency mechanisms. These\nfindings demonstrate that multi-method integration provides a robust empirical\nfoundation for evidence-based mathematics placement optimization."}
{"id": "2511.04243", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04243", "abs": "https://arxiv.org/abs/2511.04243", "authors": ["Valter Uotila", "Väinö Mehtola", "Ilmo Salmenperä", "Bo Zhao"], "title": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes", "comment": "8 pages; 8 figures", "summary": "Leveraging data symmetries has been a key driver of performance gains in\ngeometric deep learning and geometric and equivariant quantum machine learning.\nWhile symmetrization appears to be a promising method, its practical overhead,\nsuch as additional gates, reduced expressibility, and other factors, is not\nwell understood in quantum machine learning. In this work, we develop an\nautomated pipeline to measure various characteristics of quantum machine\nlearning ansatzes with respect to symmetries that can appear in the learning\ntask. We define the degree of symmetry in the learning problem as the size of\nthe subgroup it admits. Subgroups define partial symmetries, which have not\nbeen extensively studied in previous research, which has focused on symmetries\ndefined by whole groups. Symmetrizing the 19 common ansatzes with respect to\nthese varying-sized subgroup representations, we compute three classes of\nmetrics that describe how the common ansatz structures behave under varying\namounts of symmetries. The first metric is based on the norm of the difference\nbetween the original and symmetrized generators, while the second metric counts\ndepth, size, and other characteristics from the symmetrized circuits. The third\nclass of metrics includes expressibility and entangling capability. The results\ndemonstrate varying gate overhead across the studied ansatzes and confirm that\nincreased symmetry reduces expressibility of the circuits. In most cases,\nincreased symmetry increases entanglement capability. These results help select\nsufficiently expressible and computationally efficient ansatze patterns for\ngeometric quantum machine learning applications."}
{"id": "2511.04564", "categories": ["physics.comp-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04564", "abs": "https://arxiv.org/abs/2511.04564", "authors": ["Yoh-ichi Mototake", "Makoto Sasaki"], "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI", "comment": "17 pages, 6 figures", "summary": "Physics-informed machine learning (PIML) integrates partial differential\nequations (PDEs) into machine learning models to solve inverse problems, such\nas estimating coefficient functions (e.g., the Hamiltonian function) that\ncharacterize physical systems. This framework enables data-driven understanding\nand prediction of complex physical phenomena. While coefficient functions in\nPIML are typically estimated on the basis of predictive performance, physics as\na discipline does not rely solely on prediction accuracy to evaluate models.\nFor example, Kepler's heliocentric model was favored owing to small\ndiscrepancies in planetary motion, despite its similar predictive accuracy to\nthe geocentric model. This highlights the inherent uncertainties in data-driven\nmodel inference and the scientific importance of selecting physically\nmeaningful solutions. In this paper, we propose a framework to quantify and\nanalyze such uncertainties in the estimation of coefficient functions in PIML.\nWe apply our framework to reduced model of magnetohydrodynamics and our\nframework shows that there are uncertainties, and unique identification is\npossible with geometric constraints. Finally, we confirm that we can estimate\nthe reduced model uniquely by incorporating these constraints."}
