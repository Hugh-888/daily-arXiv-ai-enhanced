<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 17]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [cs.LG](#cs.LG) [Total: 71]
- [quant-ph](#quant-ph) [Total: 31]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Cosmological and High Energy Physics implications from gravitational-wave background searches in LIGO-Virgo-KAGRA's O1-O4a runs](https://arxiv.org/abs/2510.26848)
*The LIGO Scientific Collaboration,the Virgo Collaboration,the KAGRA Collaboration*

Main category: gr-qc

TL;DR: 利用LIGO-Virgo的O1-O4a引力波数据搜索早期宇宙过程产生的背景信号，未检测到信号但对多种早期宇宙模型提供了强大约束。


<details>
  <summary>Details</summary>
Motivation: 探测早期宇宙过程产生的引力波背景信号，包括相变、宇宙弦、畴壁等，以约束基本物理参数和宇宙学模型。

Method: 分析LIGO-Virgo O1-O4a数据集，结合天体物理背景模型，对多种早期宇宙过程产生的引力波背景进行搜索和参数约束。

Result: 未检测到显著的引力波背景信号，但获得了对多种早期宇宙过程参数的强大约束，包括相变、宇宙弦、畴壁、轴子暴胀等。

Conclusion: LIGO-Virgo数据已经能够对众多早期宇宙场景提供显著约束，为宇宙学和高能物理模型提供了重要限制。

Abstract: We search for gravitational-wave background signals produced by various early
Universe processes in the Advanced LIGO O4a dataset, combined with the data
from the earlier O1, O2, and O3 (LIGO-Virgo) runs. The absence of detectable
signals enables powerful constraints on fundamental physics. We derive
gravitational-wave background energy density upper limits from the O1-O4a data
to constrain parameters associated with various possible processes in the early
Universe: first-order phase transitions, cosmic strings, domain walls, stiff
equation of state, axion inflation, second-order scalar perturbations,
primordial black hole binaries, and parity violation. In our analyses, the
presence of an astrophysical background produced by compact (black hole and
neutron star) binary coalescences throughout the Universe is also considered.
We address the implications for various cosmological and high energy physics
models based on the obtained parameter constraints. We conclude that LIGO-Virgo
data already yield significant constraints on numerous early Universe
scenarios.

</details>


### [2] [Regularization of Gauss-Bonnet Gravity in Riemann-Cartan Geometry](https://arxiv.org/abs/2510.26858)
*Jianhui Qiu,Ling-Wei Luo,Chunhui Liu,Chao-Qiang Geng*

Main category: gr-qc

TL;DR: 在四维黎曼-嘉当几何中研究高斯-博内引力的共形正则化，通过维度导数方案构建了新的静态球对称黑洞解，发现正则化高斯-博内项可作为长程挠率场的内在源。


<details>
  <summary>Details</summary>
Motivation: 研究四维高斯-博内引力的正则化问题，探索在四维框架下维持黑洞挠率毛发的机制，避免依赖额外维度。

Method: 采用一致的维度导数方案进行共形正则化，在四维黎曼-嘉当几何中推导完整的场方程，构建静态球对称黑洞解。

Result: 成功构建了新的静态球对称黑洞解，发现正则化高斯-博内项能够作为长程挠率场的内在源。

Conclusion: 正则化高斯-博内项提供了纯粹四维机制来维持黑洞上的挠率毛发，无需依赖额外维度。

Abstract: We investigate the conformal regularization of Gauss-Bonnet gravity in
four-dimensional Riemann-Cartan geometry, employing a consistent dimensional
derivative scheme. Within this regularized framework, we derive the complete
field equations and construct novel static spherically symmetric black hole
solutions. Our central finding is that the regularized Gauss-Bonnet term acts
as an intrinsic source for a long-range torsion field, providing a purely
four-dimensional mechanism to sustain torsion as a hair on black holes, without
reliance on extra dimensions.

</details>


### [3] [Third law of repetitive electric Penrose process](https://arxiv.org/abs/2510.26866)
*Li Hu,Rong-Gen Cai,Shao-Jiang Wang*

Main category: gr-qc

TL;DR: 重复的彭罗斯过程无法将克尔黑洞的可提取能量完全耗尽，而带电的Reissner-Nordström黑洞的电荷也无法通过有限次迭代的重复电彭罗斯过程降至零，这暗示了该过程存在类似热力学第三定律的规律。


<details>
  <summary>Details</summary>
Motivation: 基于Ruffini等人关于重复彭罗斯过程无法完全耗尽克尔黑洞可提取能量的发现，进一步研究带电黑洞在重复电彭罗斯过程中的行为。

Method: 分析重复电彭罗斯过程在Reissner-Nordström黑洞上的迭代行为，特别关注电荷减少的极限情况。

Result: 发现即使经过有限次迭代的重复电彭罗斯过程，Reissner-Nordström黑洞的电荷也无法降至零。

Conclusion: 重复电彭罗斯过程存在类似热力学第三定律的极限行为，电荷无法通过有限次过程完全消除。

Abstract: Recently, Ruffini et al. [Phys. Rev. Lett. 134 (2025) 8, 081403] pointed out
that the repetitive Penrose process cannot drain the entire extractable energy
of a Kerr black hole. In this Letter, we further point out that the charge of a
Reissner-Nordstr\"{o}m black hole cannot drop down to exactly zero via the
repetitive electric Penrose process that is terminated after a finite number of
iterative steps, indicating a thermodynamical third-law analog for the
repetitive electric Penrose process.

</details>


### [4] [On the adiabatic initial conditions for a particle gas in cosmology](https://arxiv.org/abs/2510.26883)
*Guillem Domènech*

Main category: gr-qc

TL;DR: 本文澄清了膨胀宇宙中气体动力学理论中绝热初始条件的定义，区分了强绝热和弱绝热两种初始条件，并强调了使用粒子局域动量定义绝热初始条件的重要性。


<details>
  <summary>Details</summary>
Motivation: 鉴于对宇宙学中'暗'辐射（如宇宙引力波、惰性中微子和暗光子）作用的近期关注，需要澄清膨胀宇宙中气体动力学理论中绝热初始条件的定义。

Method: 在不假设相空间分布函数形式的情况下，识别了两种绝热初始条件：强绝热和弱绝热条件，并通过内部等曲率涨落关联两者。

Result: 证明了两种绝热初始条件都与分离宇宙方法一致，但弱绝热条件需要初始内部等曲率。同时澄清了引力子气体可以具有绝热初始条件。

Conclusion: 使用粒子局域动量定义绝热初始条件至关重要，这有助于正确理解包括引力子在内的各种辐射成分在宇宙学中的行为。

Abstract: In view of recent interest in the role of "dark" radiation in cosmology, such
as cosmic gravitational waves, sterile neutrinos, and dark photons, we clarify
the definition of adiabatic initial conditions in the kinetic theory of gases
in an expanding universe. Without assuming any form for the phase space
distribution function, we identify two possibilities: a strong and a weak
adiabatic initial condition. The strong one corresponds to the standard
adiabatic initial conditions, while the weak one is related to the strong via
internal isocurvature fluctuations. We show that both types of adiabatic
initial conditions are consistent with the separate universe approach, although
the latter requires initial internal isocurvature. In passing, we stress the
importance of using the particle local momentum in the phase space to define
the notion of adiabatic initial conditions. Doing so, we clarify that a gas of
gravitons can have adiabatic initial conditions.

</details>


### [5] [An extendible spacetime without closed timelike curves whose every extension contains closed timelike curves](https://arxiv.org/abs/2510.26902)
*H. Andréka,J. Madarász,J. Manchak,I. Németi,G. Székely*

Main category: gr-qc

TL;DR: 通过从时间卷曲的闵可夫斯基时空中移除分形结构，构造了一个可延展的时空，该时空本身没有闭合类时曲线，但其所有延展都包含闭合类时曲线。


<details>
  <summary>Details</summary>
Motivation: 解决Geroch提出的关于时空延展性和闭合类时曲线存在性的问题。

Method: 从时间卷曲的闵可夫斯基时空中移除分形结构来构造特定时空。

Result: 成功构造了一个可延展时空，该时空本身无闭合类时曲线，但其所有延展都包含闭合类时曲线。

Conclusion: 该构造解决了Geroch提出的问题，证明了存在这样的时空：本身无闭合类时曲线，但任何延展都会引入闭合类时曲线。

Abstract: By removing a fractal from time-rolled Minkowski spacetime, we construct an
extendible spacetime without closed timelike curves whose every extension
contains closed timelike curves. This settles a question posed by Geroch.

</details>


### [6] [Entanglement Entropy in Loop Quantum Gravity through Quantum Error Correction](https://arxiv.org/abs/2510.26911)
*Sean Tobin*

Main category: gr-qc

TL;DR: 该论文提出了一种在圈量子引力中计算纠缠熵的新方法，通过量子纠错码技术将规范不变子空间嵌入更大的希尔伯特空间，并使用冯诺依曼代数公式计算纠缠熵。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在圈量子引力框架下，通过量子纠错码技术来理解和计算纠缠熵，特别是为了推导黑洞熵的微观起源。

Method: 方法包括将规范不变子空间嵌入更大的希尔伯特空间，使用冯诺依曼代数公式来处理非因子化的希尔伯特空间，并应用量子纠错码技术。

Result: 结果成功再现了预期的黑洞熵，通过正则系综实现了Ryu-Takayanagi公式的直接实现，为黑洞熵提供了第一性原理推导。

Conclusion: 结论是所发展的代数技术可用于计算任意表面的纠缠熵，为圈量子引力中的纠缠熵计算提供了新的理论框架。

Abstract: We introduce a novel method for computing entanglement entropy across
surfaces in Loop Quantum Gravity by employing techniques from quantum error
correcting codes. In this construction, the redundancy encoded in the gauge
invariant subspace is made manifest by embedding it in a larger Hilbert space.
The enlarged Hilbert space of a surface does not factorize, which necessitates
an algebraic formulation of the entanglement entropy using von Neumann
algebras. Using this approach, we are able to reproduce the expected black hole
entropy through the canonical ensemble. This includes a direct realization of
the Ryu-Takayanagi formula, providing a first principles derivation of the
black hole entropy within a kinematical framework of loop quantum gravity. The
algebraic techniques developed in this work can be used to compute the
entanglement entropy across arbitrary surfaces.

</details>


### [7] [Scattered light noise due to dust particles contamination in the vacuum pipes of the Einstein Telescope](https://arxiv.org/abs/2510.26919)
*Andrea Moscatello,Giacomo Ciani,Livia Conti*

Main category: gr-qc

TL;DR: 该论文研究了爱因斯坦望远镜干涉仪臂中颗粒沉积引起的散射光噪声，分析了不同尺寸颗粒的光散射特性，并制定了真空管道组装的洁净度指南。


<details>
  <summary>Details</summary>
Motivation: 干涉引力波探测器等高灵敏度光学测量易受散射光噪声影响，表面粗糙度和体缺陷控制措施可能被其他散射源削弱，特别是表面沉积颗粒引起的散射噪声。

Method: 首先研究沉积在表面的颗粒（直径从光波长的十分之一到百倍）的光散射特性，包括角度分布、对颗粒尺寸、折射率和偏振的依赖性；然后专门针对爱因斯坦望远镜臂的情况，量化每个臂挡板上允许的最大颗粒密度。

Result: 分析了颗粒散射的角分布特性及其对光学参数的影响，确定了爱因斯坦望远镜臂挡板的最大允许颗粒密度限制。

Conclusion: 制定了真空管道组装的洁净度指南，包括安装环境所需的洁净等级要求，以控制颗粒沉积引起的散射光噪声。

Abstract: High-sensitivity optical measurements such as those performed in
interferometric gravitational wave detectors are prone to scattered light
noise. To minimize it, optical components must meet tight requirements on
surface roughness and bulk defects. Nonetheless, the effectiveness of these
measures can be undermined by other sources of scattered light. In this
article, we examine scattered light noise caused by particles deposited on
surfaces, especially on the baffles inside the vacuum pipes of the Einstein
Telescope's interferometer arms. First, we study light scattering by particles
deposited on a surface and having diameters from about one tenth to hundred
times the light wavelength: we discuss its angular distribution and dependence
on particle size and refractive index, and on polarization. Then, we specialize
to the case of the Einstein Telescope arms and quantify the maximum allowed
density of particles on each arm baffle. We conclude with cleanliness
guidelines for the assembly of the vacuum pipes, including the required
cleanliness class of the installation environment.

</details>


### [8] [Entanglement entropy in Loop Quantum Gravity and geometrical area law](https://arxiv.org/abs/2510.26922)
*Muxin Han*

Main category: gr-qc

TL;DR: 本文使用冯·诺依曼代数框架研究圈量子引力中的纠缠熵，通过固定面积态推导出几何面积定律，并证明体纠缠可以重整化面积定律系数。


<details>
  <summary>Details</summary>
Motivation: 圈量子引力中由于规范不变性导致的希尔伯特空间非分解性需要广义的纠缠熵定义，这与黑洞熵密切相关。

Method: 采用冯·诺依曼代数框架，在图上使用区域和边界上的完整算符和通量算符生成非因子型I冯·诺依曼代数，应用于固定面积态。

Result: 通过熵最大化推导出几何面积定律，纠缠熵与面积成正比，体纠缠可以重整化面积定律系数并产生对数修正。

Conclusion: 该代数形式主义为圈量子引力中的纠缠熵提供了严格定义，结果与圈量子引力黑洞熵密切相关。

Abstract: The non-factorizing nature of the Hilbert space in Loop Quantum Gravity (LQG)
due to gauge invariance requires a generalized definition of entanglement
entropy. This work employs the framework of von Neumann algebras to investigate
the entanglement entropy in LQG. On a graph, the holonomy and flux operators
within a region and on the boundary generate a non-factor type I von Neumann
algebra, which is used to define the entanglement entropy for LQG states. This
algebraic formalism is applied to ``fixed-area states''--superpositions of spin
networks associated with a surface with a definite macroscopic area given by
the LQG area spectrum. By maximizing the entropy, we derive a geometrical area
law where the entanglement entropy is proportional to the area. In addition, we
show that bulk entanglement can renormalize the area-law coefficient and
produce logarithmic corrections. The results in this paper closely relate to
LQG black hole entropy.

</details>


### [9] [Lorentzian spinfoam gravity path integral and geometrical area-law entanglement entropy](https://arxiv.org/abs/2510.26925)
*Muxin Han*

Main category: gr-qc

TL;DR: 本文研究了3+1维洛伦兹协变圈量子引力中的纠缠熵，通过自旋泡沫路径积分计算空间区域的纠缠熵，发现其遵循几何面积律，并在特定参数范围内重现了Bekenstein-Hawking公式。


<details>
  <summary>Details</summary>
Motivation: 探索洛伦兹协变圈量子引力框架下引力熵的路径积分方法，避免传统方法中的轮廓规定需求。

Method: 使用自旋泡沫路径积分，对一族2-复形求和，计算空间区域的纠缠熵。

Result: 纠缠熵呈现几何面积律S≃βa，其中面积a由LQG面积谱确定，主导系数β>0且与底层2-复形无关。通过将2-复形求和的耦合常数与Barbero-Immirzi参数γ关联，在0<γ≲1/2范围内重现了Bekenstein-Hawking公式。

Conclusion: 这项工作为引力熵提供了洛伦兹路径积分方法，无需轮廓规定，成功建立了圈量子引力与黑洞热力学之间的联系。

Abstract: This paper investigates entanglement entropy in 3+1 dimensional Lorentzian
covariant Loop Quantum Gravity (LQG). We compute the entanglement entropy for a
spatial region from states dynamically generated by a spinfoam path integral
that sums over a family of 2-complexes. The resulting entropy exhibits a
geometric area law, $S \simeq \beta a$, where the area $a$ of the entangling
surface is determined by the LQG area spectrum and the leading coefficient
$\beta>0$ is independent of the underlying 2-complexes. By relating the
coupling constant of the sum over 2-complexes to the Barbero-Immirzi parameter
$\gamma$, we reproduce the Bekenstein-Hawking formula for the range $0 < \gamma
\lesssim 1/2$. This work provides a Lorentzian path integral approach to
gravitational entropy without the need for contour prescriptions.

</details>


### [10] [On the summation and triangulation independence of Lorentzian spinfoam amplitudes for all LQG](https://arxiv.org/abs/2510.26926)
*Muxin Han*

Main category: gr-qc

TL;DR: 本文研究了自旋泡沫量子引力中的三角化依赖性问题，提出了自旋泡沫堆栈框架来系统求和无限类2-复形上的自旋泡沫振幅。在内部面面积截断趋于无穷的极限下，振幅通过驻相机制局域化到SU(2)平坦连接空间，有效将体动力学从量子几何理论简化为类似SU(2) BF理论的拓扑理论。


<details>
  <summary>Details</summary>
Motivation: 解决自旋泡沫量子引力中的基本问题——三角化依赖性，即理论结果不应依赖于背景三角化的选择。

Method: 引入自旋泡沫堆栈框架，通过在简单根复形上堆叠任意数量的面来生成无限类2-复形，分析在内部面面积截断趋于无穷极限下的振幅行为。

Result: 在极限下，振幅通过驻相机制局域化到SU(2)平坦连接空间，对于拓扑平凡流形，振幅分解为三角化依赖的归一化因子和仅依赖边界数据的有限部分。重正化后得到与复形体结构无关的有限结果。

Conclusion: 在明确定义的极限下实现了三角化独立性，表明自旋泡沫形式主义中可能存在量子引力的非平凡固定点。

Abstract: This paper investigates the fundamental issue of triangulation dependence in
spinfoam quantum gravity. It introduces a novel framework, named spinfoam
stack, to systematically sum spinfoam amplitudes over an infinite class of
2-complexes. These complexes are generated by stacking an arbitrary number of
faces upon a simpler root complex. The central result is obtained by analyzing
the amplitude of spinfoam stack in the limit where an upper cut-off on the area
of internal faces is taken to infinity. In this limit, the amplitude as an
integral localizes via a stationary phase mechanism onto a critical manifold.
This manifold is shown to be the space of SU(2) flat connections on the
underlying complex. This localization effectively reduces the bulk dynamics
from a theory of quantum geometry to a topological theory akin to SU(2) BF
theory. For spinfoams on topologically trivial manifolds, this result has a
powerful consequence: the spinfoam stack amplitude factorizes into a
triangulation-dependent normalization factor and a finite part that depends
only on the boundary data. Renormalizing the amplitude yields a finite result
that is manifestly independent of the bulk structure of the 2-complex. This
provides a concrete realization of triangulation independence in a well-defined
limit, suggesting the possibility of existing a non-trivial fixed point of
quantum gravity within the spinfoam formalism.

</details>


### [11] [Axial Gravitational Normal Modes of Uniform Density Star in Anti-de Sitter Spacetime](https://arxiv.org/abs/2510.26963)
*Kai Lin,Alan B. Pavan,Amilcar Rabelo de Queiroz,Elcio Abdalla*

Main category: gr-qc

TL;DR: 研究了反德西特时空中均匀恒星轴向引力扰动的动力学行为，发现扰动表现为量子力学无限深势阱中的驻波振动，并观察到波包在恒星表面产生回声现象。


<details>
  <summary>Details</summary>
Motivation: 探讨反德西特时空中均匀恒星的引力扰动行为，特别关注由于乌龟坐标变换导致的有限域特性，以及这种特性如何影响引力波的传播。

Method: 使用打靶法和有限差分法分析扰动方程，通过数值方法展示驻波图像和波包在势阱中的传播行为。

Result: 发现扰动表现为驻波振动，波包在势阱内来回反弹并在恒星表面产生回声现象，最终波包因多次反射而弥散。

Conclusion: 反德西特时空中均匀恒星的引力扰动具有类似量子力学无限深势阱的特性，表现为驻波振动并产生回声效应，波包最终会弥散。

Abstract: The article studies the dynamical behavior of axial gravitational
perturbations of homogeneous stars in Anti-de Sitter spacetime. Because the
radial coordinate $r$ transforms into the tortoise coordinate $y = y(r)$,
obeying $y(r=0)=0$ and $y(r\rightarrow\infty)=y_\text{max}<\infty$, the
tortoise coordinates domain is finite, and the gravitational waves fail to
reach out of the domain. Thus, from the perspective of tortoise coordinates,
the perturbation equation of uniform density stars in Anti-de Sitter spacetime
is analogous to the infinite deep potential well in quantum mechanics.
Therefore, the perturbative behavior in this spacetime represents a standing
wave vibration. Here we use shooting method and finite difference method to
show the imagery of standing waves in this spacetime for $n=0,1,2$ as examples.
On the other hand, by finite difference method, a Gaussian wave packet bounces
back and forth within this potential well. Furthermore, due to the shape of the
gravitational potential function $V$ within the range $0\le y\le y_\text{max}$,
an echo phenomenon occurs at the surface of the star. As the energy of the wave
packet remains within the potential well, each time it traverses the surface of
the star, a reflective echo is generated. Consequently, after multiple
reflections, the Gaussian wave packet cannot maintain its original shape and
ultimately disperses.

</details>


### [12] [Magnetically supramassive and hypermassive compact stars](https://arxiv.org/abs/2510.27188)
*Koji Uryu,Shijun Yoshida,Eric Gourgoulhon,Charalampos Markakis,Kotaro Fujisawa,Antonios Tsokaros,Keisuke Taniguchi,Mina Zamani,Lambros Boukas*

Main category: gr-qc

TL;DR: 该论文发现强磁场（B~10^17-10^18G）能显著增加相对论致密星的质量，产生磁超质量解和磁超超质量解。


<details>
  <summary>Details</summary>
Motivation: 研究磁场对相对论致密星质量的影响，特别是强磁场条件下可能产生超出传统极限的质量解。

Method: 使用COCAL数值代码系统计算具有混合极向和环向磁场的致密星平衡解。

Result: 获得了质量超过静态球对称解最大质量10%以上的磁超质量解，以及质量超过开普勒极限下均匀旋转解最大质量的磁超超质量解。

Conclusion: 强磁场能显著提升致密星的质量极限，产生传统理论无法解释的超质量恒星结构。

Abstract: It is known that the mass of magnetized relativistic compact star is larger
than that of non-magnetized one for the same equation of state and central
density, albeit the excess of mass is sizable only if the magnetic fields are
strong enough B~10^17-10^18G. Using our recently developed numerical code
COCAL, we systematically compute such compact star solutions in equilibrium
associated with mixed poloidal and toroidal magnetic fields, and show the
magnetically supramassive solutions whose masses exceed by more than 10% of the
maximum mass of the static and spherically symmetric solutions. For some
extremely strong magnetic field configurations, we also obtain solutions more
massive than the maximum mass of the uniformly rotating solutions at the Kepler
(mass-shedding) limit, namely magnetically hypermassive solutions.

</details>


### [13] [The quasinormal modes of the rotating quantum corrected black holes](https://arxiv.org/abs/2510.27320)
*Jia-Ning Chen,Zong-Kuan Guo,Liang-Bi Wu*

Main category: gr-qc

TL;DR: 研究了旋转量子修正黑洞的准正规模，使用双曲框架将谱问题转化为二维特征值问题，并用伪谱法计算。构建了引力波数据分析管道，发现量子修正参数与黑洞本征参数的强相关性会影响质量和自旋的后验分布。


<details>
  <summary>Details</summary>
Motivation: 研究量子引力理论对旋转黑洞准正规模的影响，探索量子修正如何改变黑洞的动力学特性及其在引力波观测中的可探测性。

Method: 采用双曲框架处理标量扰动，将准正规模谱问题转化为二维特征值问题，使用二维伪谱法计算谱线，并利用pyRing构建参数估计管道分析引力波数据。

Result: 即使量子修正黑洞谱与Kerr谱只有微小偏差，量子引力理论引入的额外参数与黑洞本征参数之间的强相关性会显著影响质量M和自旋ā的后验分布。

Conclusion: 量子修正对旋转黑洞准正规模的影响虽然微小，但参数间的强相关性在引力波数据分析中会产生显著效应，这对探测量子引力效应具有重要意义。

Abstract: The quasinormal modes (QNMs) of a rotating quantum corrected black hole
(RQCBH) are studied by employing the hyperboloidal framework for the scalar
perturbation. This framework is used to cast the QNMs spectra problem into the
two-dimensional eigenvalues problem, then the spectra are calculated by
imposing two-dimensional pseudo-spectral method. Based on the resulting
spectra, a parameter estimation pipeline for this RQCBH model with
gravitational wave data is constructed by using \texttt{pyRing} in the ringdown
phase. We find that, even when the RQCBH spectra exhibits a small deviation
from the Kerr spectra, the strong correlation between the extra parameter
coming from the quantum gravity theory and the intrinsic parameter of black
hole may significantly affect the posterior distributions of the mass $M$ and
the dimensionless spin $\bar{a}$.

</details>


### [14] [Geometric acceleration in $f(Q,C)$ theories](https://arxiv.org/abs/2510.27415)
*Mikel Artola,Ismael Ayuso,Ruth Lazkoz,Gonzalo Olmo,Vincenzo Salzano*

Main category: gr-qc

TL;DR: 提出了一种新的f(Q,C)引力框架，该框架无法简单分解为Q和C的独立函数，但仍能产生二阶场方程。通过特定类型的联络，推导出了新的宇宙学模型，包括一个在统计上优于ΛCDM的DGP模型变体。


<details>
  <summary>Details</summary>
Motivation: f(Q,C)引力框架能够从几何本身描述有效的暗能量流体，从而修改广义相对论的宇宙学现象学。目标是发现新的、观测支持的（有效）演化暗能量模型。

Method: 提出了一个通用的f(Q,C)公式，该公式不能简单地分解为Q和C的独立函数，但能产生二阶场方程。通过采用特定类型的联络，推导出新的宇宙学模型指南。

Result: 推导出了新的宇宙学模型，包括一个在统计上优于ΛCDM的DGP模型变体。还展示了如何将f(Q,C)框架中的解在背景水平上转换为f(Q)对应物。

Conclusion: f(Q,C)框架为发现新的、观测支持的暗能量模型提供了有前景的途径，其中一些模型在统计上优于标准的ΛCDM模型。

Abstract: The $f(Q,C)$ framework of gravity enables the depiction of an effective dark
energy fluid that emerges from geometry itself, thus leading to modifications
in the cosmological phenomenology of General Relativity. We pursue this
approach to discover new and observationally supported (effective) evolving
dark energy models. We propose a general $f(Q,C)$ formulation that cannot be
simply split into separate functions of $Q$ and $C$, yet it still results in
second-order field equations. By employing a particular type of connection, we
derive guidelines for new cosmological models, including a variant of the DGP
model that appears to be statistically favored over $\Lambda$CDM. Notably, we
also demonstrate how to translate solutions within this $f(Q,C)$ framework to
$f(Q)$ counterparts at the background level.

</details>


### [15] [Extracting Properties of Dark Dense Environment Around Black Holes From Gravitational Waves](https://arxiv.org/abs/2510.27424)
*Qianhang Ding,Minxi He,Hui-Yu Zhu*

Main category: gr-qc

TL;DR: 该论文提出了一种通过引力波观测探测黑洞周围暗物质凝聚体的新方法，通过量化暗物质对轨道演化的影响来提取暗物质密度分布信息。


<details>
  <summary>Details</summary>
Motivation: 暗物质可以在黑洞周围形成致密凝聚体，这些结构会通过动力学摩擦影响伴星轨道演化，从而在引力波信号中留下可观测特征。

Method: 定义了一个新物理量来量化暗物质凝聚体在引力波振幅、频率及其时间导数中的效应，通过多波段引力波观测提取密度分布信息。

Result: 该方法能够通过现有地面和未来空间引力波探测器探测暗致密环境，揭示暗物质性质并阐明恒星质量黑洞的原始起源。

Conclusion: 该方法为探测暗物质提供了新途径，即使零探测结果也能对相关暗物质参数施加强约束。

Abstract: Dark matter (DM) can form dense condensates around black holes (BHs), such as
superradiant clouds and ultracompact mini halos, which can significantly affect
the orbital evolution of their companion objects through dynamical friction
(DF). In this work, we define a novel quantity to quantify such effects in the
emitted gravitational waves (GWs) in terms of GW amplitude, frequency, and
their time derivatives. The information about the density profile can be
extracted from this quantity, which characterizes the type of condensate and,
therefore, the corresponding DM property. This quantity allows us to probe the
dark dense environment by multi-wavelength GW observation with existing
ground-based and future space-based GW detectors, potentially reveals the
properties of the dark sector and sheds light on the primordial origin of the
stellar mass BHs. A null detection can place strong constraints on the relevant
DM parameters.

</details>


### [16] [Interplay of Null Energy Condition Violations and Thermodynamics in Kiselev Black Hole Evaporation](https://arxiv.org/abs/2510.27454)
*Vitalii Vertogradov,Maksim Grigorev*

Main category: gr-qc

TL;DR: 本文研究了Kiselev黑洞在蒸发过程中的温度动态，发现温度不会发散而是趋于零，某些参数下会出现相变，相变特性与零能条件违反区域直接相关。


<details>
  <summary>Details</summary>
Motivation: 研究具有两个视界的黑洞蒸发热力学特性，探索其与Schwarzschild黑洞的根本差异，特别是温度行为与相变、零能条件违反之间的关系。

Method: 分析Kiselev黑洞在不同质量M和各向异性流体参数N下的Hawking温度动态，将温度行为与相变和零能条件违反明确联系起来。

Result: 发现温度在蒸发过程中通常趋于零而非发散；某些参数下会出现温度峰值和热容发散的相变；相变特性由零能条件违反区域决定：全局违反导致视界合并和温度抑制，部分或无违反则恢复标准蒸发图像。

Conclusion: 在各向异性黑洞时空中，热力学稳定性、视界动态和能量条件结构之间存在直接对应关系，建立了零能条件违反与黑洞蒸发热力学行为之间的根本联系。

Abstract: The evaporation of black holes with two horizons presents a rich
thermodynamic landscape that departs fundamentally from the Schwarzschild
paradigm. In this work, we analyze the Hawking temperature dynamics of the
Kiselev black hole under varying mass $M$ and anisotropic fluid parameter $N$,
explicitly connecting temperature behavior to phase transitions and violations
of the null energy condition (NEC). We find that the temperature does not
necessarily diverge during evaporation; instead, it typically falls to zero as
the black hole evaporates. This cooling behavior is preceded, in certain
parameter regimes, by a phase transition marked by a peak in temperature and a
divergence in heat capacity. Crucially, the presence and nature of these phase
transitions are dictated by the spacetime regions where the NEC is violated:
global NEC violation leads to horizon merger and temperature suppression, while
partial or absent violation can restore the standard evaporation picture. Our
results establish a direct correspondence between thermodynamic stability,
horizon dynamics, and energy condition structure in anisotropic black hole
spacetimes.

</details>


### [17] [Renormalisation Group approach to General Relativity](https://arxiv.org/abs/2510.27676)
*F. Gutiérrez,K. Falls,A. Codello*

Main category: gr-qc

TL;DR: 提出了一种用于经典引力系统的精确重整化群方程，作为后闵可夫斯基展开和后牛顿展开的中间路径，能够非微扰地近似强场动力学。


<details>
  <summary>Details</summary>
Motivation: 引力波探测需要高效、高精度的广义相对论二体问题建模，现有解析方法本质上是微扰的，而数值相对论计算成本高昂。

Method: 引入精确重整化群方程，利用RG流的固有非线性，避免了复杂的三引力子顶点计算。

Result: 正确重现了后闵可夫斯基展开的前三阶，高效恢复了1PN二体作用量。

Conclusion: 精确重整化群是处理引力强场动力学的强大新工具。

Abstract: The detection of gravitational waves has intensified the need for efficient,
high-precision modeling of the two-body problem in General Relativity. Current
analytical methods, primarily the Post-Minkowskian and Post-Newtonian
expansions, are inherently perturbative, while numerical relativity remains
computationally expensive. In this Letter, we introduce a middle path: an exact
renormalization group (RG) equation for classical gravitational systems. We
demonstrate that our equation correctly reproduces the first three orders of
the Post-Minkowskian expansion. Crucially, it provides a framework for
non-perturbative approximations. As a first application, we show that our
method efficiently recovers the 1PN two-body action, bypassing the need for
complex three-graviton vertex calculations by leveraging the intrinsic
nonlinearity of the RG flow. This establishes the exact RG as a powerful new
tool for tackling strong-field dynamics in gravity.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [18] [MRX: A differentiable 3D MHD equilibrium solver without nested flux surfaces](https://arxiv.org/abs/2510.26986)
*Tobias Blickhan,Julianne Stratton,Alan A. Kaptanoglu*

Main category: physics.comp-ph

TL;DR: 提出了一种基于B、p可容许变分概念的新型3D磁流体动力学平衡求解器，通过磁弛豫将磁场从扰动/非最小能量状态松弛到更低能量状态。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D MHD平衡求解器面临的挑战，包括精确执行物理约束（如无散磁场）、高数值收敛性、处理复杂几何以及模拟随机场线或混沌行为。

Method: 使用基于B、p可容许变分的数学理论，结合微分几何在逻辑域和物理域之间的变换，采用可微分Python实现磁弛豫方法。

Result: 求解器经过稳健基准测试，成功求解了高β下的2D环形平衡和旋转椭圆仿星器，展现出计算效率、代码可访问性和每一步的可微分性。

Conclusion: 该方法为3D平衡优化提供了有效工具，未来将集成用于模拟仿星器聚变装置中的磁岛和混沌行为。

Abstract: This article introduces a new 3D magnetohydrodynamic (MHD) equilibrium
solver, based on the concept of admissible variations of B, p that allows for
magnetic relaxation of a magnetic field in a perturbed/non-minimum energy state
to a lower energy state. We describe the mathematical theory behind this
method, including ensuring certain bounds on the magnetic energy, and the
differential geometry behind transforming to and from a logical domain and
physical domain. Our code is designed to address a number of traditional
challenges to 3D MHD equilibrium solvers, e.g. exactly enforcing physical
constraints such as divergence-free magnetic field, exhibiting high levels of
numerical convergence, dealing with complex geometries, and modeling stochastic
field lines or chaotic behavior. By using differentiable Python, our numerical
method comes with the additional benefits of computational efficiency on modern
computing architectures, high code accessibility, and differentiability at each
step. The proposed magnetic relaxation solver is robustly benchmarked and
tested with standard examples, including solving 2D toroidal equilibria at
high-beta, and a rotating ellipse stellarator. Future work will address the
integration of this code for 3D equilibrium optimization for modeling magnetic
islands and chaos in stellarator fusion devices.

</details>


### [19] [Attenuation Compensation in Lossy Media via the Wave Operator Model](https://arxiv.org/abs/2510.27276)
*Tianchen Shao,Zekui Jia,Maokun Li,Shenheng Xu,Fan Yang*

Main category: physics.comp-ph

TL;DR: 将波算子模型从无损介质扩展到有损介质，提出衰减补偿策略来恢复衰减数据，为基于降阶模型的技术在有损介质中建立理论基础


<details>
  <summary>Details</summary>
Motivation: 现有的波算子模型主要针对无损介质，需要将其扩展到能够处理有损介质中的波传播问题

Method: 推导了有损环境中电场波算子解的表达式，将其分解为闭式传播项和非闭式耗散项，基于传播项中的主导指数衰减分析提出衰减补偿策略

Result: 通过数值实验验证了补偿策略的性能，成功将有损介质中的衰减数据恢复到近似无损状态

Conclusion: 建立了基于降阶模型的技术在有损介质中应用的理论基础，扩展了波算子模型的应用范围

Abstract: The wave operator model provides a framework for modeling wave propagation by
encoding material parameter distributions into matrix-form operators. This
paper extends this framework from lossless to lossy media. We present a
derivation of the wave operator solution for the electric field in dissipative
environments, which can be decomposed into a closed-form propagation term and a
non-closed-form dissipation term. Based on an analysis of the dominant
exponential decay within the propagation term, an attenuation compensation
strategy is proposed to restore the attenuated data to an approximate lossless
state. The performance of this compensation strategy is analyzed and validated
through numerical experiments, establishing the theoretical foundation for
reduced order model (ROM)-based techniques in lossy media.

</details>


### [20] [Boron Nitride Nanotubes as Efficient Surface Absorbers for Air Pollutant Gas Molecules: Insights from Density Functional Theory](https://arxiv.org/abs/2510.27608)
*Joy Mukherjee,Chaithanya Purushottam Bhat,Antara Banerjee,Debashis Bandyopadhyay*

Main category: physics.comp-ph

TL;DR: 本研究通过密度泛函理论分析(5,5)硼氮纳米管对多种环境污染物气体分子的吸附传感能力，发现其具有良好的吸附性能且结构完整性不受影响，在气体污染物传感器应用方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 研究硼氮纳米管作为气体污染物吸附材料的潜力，旨在开发用于改善室内空气质量的气体传感器。

Method: 采用线性组合原子轨道密度泛函理论和自旋极化广义梯度近似方法，分析纳米管对CH2、SO2、NH3、H2Se、CO2和CS2等气体分子的吸附行为。

Result: (5,5)硼氮纳米管表现出稳健的吸附行为，热力学和化学参数（吸附能、HOMO-LUMO能隙、垂直电离能等）显示其作为污染物分子高效吸附剂的潜力，红外光谱证实了BNNT-气体复合物的形成。

Conclusion: 硼氮纳米管作为常见气体污染物的吸附剂具有广阔应用前景，对开发用于改善室内空气质量的气体传感器至关重要。

Abstract: This study investigates into the adsorption sensing capabilities of
single-walled (5,5) boron nitride nanotubes (BNNTs) towards environmental
pollutant gas molecules, including CH2, SO2, NH3, H2Se, CO2 and CS2. Employing
a linear combination of atomic orbital density functional theory (DFT) and
spin-polarized generalized gradient approximation (GGA), the investigation
reveals the nanotube's robust adsorption behavior without compromising its
structural integrity. Thermodynamic and chemical parameters, such as adsorption
energy, HOMO-LUMO gap, vertical ionization energy, and vertical electron
affinity, highlight the (5,5) BNNTs' potential as efficient absorbents for
pollutant molecules. Infrared spectroscopy confirms the formation of distinct
BNNT-gas complexes. These findings underscore the promising application of BN
nanotubes as absorbents for common gaseous pollutants, essential for developing
sensors to enhance indoor air quality.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [21] [Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning](https://arxiv.org/abs/2510.26829)
*Svetlana Churina,Niranjan Chebrolu,Kokil Jaidka*

Main category: cs.LG

TL;DR: 本文研究了持续预训练中LLMs对错误信息的易感性，发现即使少量重复接触虚假但自信陈述的事实也会导致模型内部表征偏离真相，类似于人类的幻觉真相效应。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在持续预训练过程中是否像人类一样容易受到重复错误信息的影响，即是否存在类似幻觉真相效应的脆弱性。

Method: 提出Layer of Truth框架，通过注入受控的污染数据，在不同检查点、模型规模和问题类型上探测中间表征，量化事实信念何时以及如何发生偏移。

Result: 研究发现即使最小程度的暴露也会导致已确立事实的持续表征漂移，且易感性在不同层和模型规模间存在差异。

Conclusion: 持续更新的LLMs存在被忽视的脆弱性：它们能够类似人类一样内化错误信息，强调在模型更新过程中需要强健的事实完整性监控。

Abstract: Large language models (LLMs) continually evolve through pre-training on
ever-expanding web data, but this adaptive process also exposes them to subtle
forms of misinformation. While prior work has explored data poisoning during
static pre-training, the effects of such manipulations under continual
pre-training remain largely unexplored. Drawing inspiration from the illusory
truth effect in human cognition - where repeated exposure to falsehoods
increases belief in their accuracy - we ask whether LLMs exhibit a similar
vulnerability. We investigate whether repeated exposure to false but
confidently stated facts can shift a model's internal representation away from
the truth.
  We introduce Layer of Truth, a framework and dataset for probing belief
dynamics in continually trained LLMs. By injecting controlled amounts of
poisoned data and probing intermediate representations across checkpoints,
model scales, and question types, we quantify when and how factual beliefs
shift. Our findings reveal that even minimal exposure can induce persistent
representational drift in well-established facts, with susceptibility varying
across layers and model sizes. These results highlight an overlooked
vulnerability of continually updated LLMs: their capacity to internalize
misinformation analogously to humans, underscoring the need for robust
monitoring of factual integrity during model updates.

</details>


### [22] [SmoothGuard: Defending Multimodal Large Language Models with Noise Perturbation and Clustering Aggregation](https://arxiv.org/abs/2510.26830)
*Guangzhi Su,Shuchang Huang,Yutong Ke,Zhuohang Liu,Long Qian,Kaizhu Huang*

Main category: cs.LG

TL;DR: 提出了SmoothGuard防御框架，通过随机噪声注入和聚类预测聚合来增强多模态大语言模型的对抗鲁棒性


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在联合处理文本和视觉输入方面表现出色，但对对抗性攻击高度脆弱，存在安全和可靠性问题

Method: 在连续模态（如图像、音频）中添加高斯噪声，生成多个候选输出，然后通过嵌入聚类过滤受对抗性影响的预测，从多数簇中选择最终答案

Result: 在POPE、LLaVA-Bench和MM-SafetyBench上的实验表明，SmoothGuard显著提高了对抗攻击的鲁棒性，同时保持了竞争力

Conclusion: SmoothGuard是一个轻量级、模型无关的防御框架，通过噪声注入和聚类聚合有效增强MLLMs的鲁棒性，最佳噪声范围为0.1-0.2

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance
across diverse tasks by jointly reasoning over textual and visual inputs.
Despite their success, these models remain highly vulnerable to adversarial
manipulations, raising concerns about their safety and reliability in
deployment. In this work, we first generalize an approach for generating
adversarial images within the HuggingFace ecosystem and then introduce
SmoothGuard, a lightweight and model-agnostic defense framework that enhances
the robustness of MLLMs through randomized noise injection and clustering-based
prediction aggregation. Our method perturbs continuous modalities (e.g., images
and audio) with Gaussian noise, generates multiple candidate outputs, and
applies embedding-based clustering to filter out adversarially influenced
predictions. The final answer is selected from the majority cluster, ensuring
stable responses even under malicious perturbations. Extensive experiments on
POPE, LLaVA-Bench (In-the-Wild), and MM-SafetyBench demonstrate that
SmoothGuard improves resilience to adversarial attacks while maintaining
competitive utility. Ablation studies further identify an optimal noise range
(0.1-0.2) that balances robustness and utility.

</details>


### [23] [Accurate Target Privacy Preserving Federated Learning Balancing Fairness and Utility](https://arxiv.org/abs/2510.26841)
*Kangkang Sun,Jun Wu,Minyi Guo,Jianhua Li,Jianwei Huang*

Main category: cs.LG

TL;DR: 提出了一种联邦学习算法FedPF，通过差分隐私和公平性约束的零和博弈框架，揭示了隐私与公平性之间的固有张力关系


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中同时确保跨人口群体公平性和保护敏感客户端数据的根本挑战

Method: 将多目标优化转化为零和博弈，让公平性和隐私约束与模型效用竞争，并引入差分隐私公平联邦学习算法

Result: 在三个数据集上实现了高达42.9%的歧视减少，同时保持竞争力准确性，但发现隐私-公平张力不可避免

Conclusion: 同时实现隐私和公平性目标需要精心平衡的妥协，而不是单独优化任一目标，因为更严格的隐私保护会限制系统检测和纠正人口偏见的能力

Abstract: Federated Learning (FL) enables collaborative model training without data
sharing, yet participants face a fundamental challenge, e.g., simultaneously
ensuring fairness across demographic groups while protecting sensitive client
data. We introduce a differentially private fair FL algorithm (\textit{FedPF})
that transforms this multi-objective optimization into a zero-sum game where
fairness and privacy constraints compete against model utility. Our theoretical
analysis reveals a surprising inverse relationship, i.e., stricter privacy
protection fundamentally limits the system's ability to detect and correct
demographic biases, creating an inherent tension between privacy and fairness.
Counterintuitively, we prove that moderate fairness constraints initially
improve model generalization before causing performance degradation, where a
non-monotonic relationship that challenges conventional wisdom about
fairness-utility tradeoffs. Experimental validation demonstrates up to 42.9 %
discrimination reduction across three datasets while maintaining competitive
accuracy, but more importantly, reveals that the privacy-fairness tension is
unavoidable, i.e., achieving both objectives simultaneously requires carefully
balanced compromises rather than optimization of either in isolation. The
source code for our proposed algorithm is publicly accessible at
https://github.com/szpsunkk/FedPF.

</details>


### [24] [CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs](https://arxiv.org/abs/2510.26843)
*Zhiyuan Ning,Jiawei Shao,Ruge Xu,Xinfei Guo,Jun Zhang,Chi Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: 提出CAS-Spec方法，通过动态切换推理加速策略构建推测性草稿模型，并引入DyTC算法自适应路由多级草稿模型和分配草稿长度，实现无损推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自推测解码方法在集成便利性和通用性方面有优势，但速度提升不如依赖专门训练的方法；级联草稿模型层次结构虽能提供进一步加速和灵活性，但训练多个模型成本高昂限制了实际应用。

Method: CAS-Spec方法利用动态可切换推理加速策略（层稀疏化和激活量化）构建推测性草稿模型，并引入动态树级联算法自适应路由多级草稿模型和分配草稿长度。

Result: CAS-Spec方法相比现有自推测解码方法实现了最先进的加速效果，在不同LLM和数据集上平均加速1.1倍到2.3倍；DyTC算法相比级联基线和树状基线算法分别提升47%和48%的平均加速效果。

Conclusion: CAS-Spec方法可以轻松集成到大多数现有LLM中，随着自推测解码技术的持续发展，具有进一步加速的潜力。

Abstract: Speculative decoding has become a widely adopted as an effective technique
for lossless inference acceleration when deploying large language models
(LLMs). While on-the-fly self-speculative methods offer seamless integration
and broad utility, they often fall short of the speed gains achieved by methods
relying on specialized training. Cascading a hierarchy of draft models promises
further acceleration and flexibility, but the high cost of training multiple
models has limited its practical application. In this paper, we propose a novel
Cascade Adaptive Self-Speculative Decoding (CAS-Spec) method which constructs
speculative draft models by leveraging dynamically switchable inference
acceleration (DSIA) strategies, including layer sparsity and activation
quantization. Furthermore, traditional vertical and horizontal cascade
algorithms are inefficient when applied to self-speculative decoding methods.
We introduce a Dynamic Tree Cascade (DyTC) algorithm that adaptively routes the
multi-level draft models and assigns the draft lengths, based on the heuristics
of acceptance rates and latency prediction. Our CAS-Spec method achieves
state-of-the-art acceleration compared to existing on-the-fly speculative
decoding methods, with an average speedup from $1.1\times$ to $2.3\times$ over
autoregressive decoding across various LLMs and datasets. DyTC improves the
average speedup by $47$\% and $48$\% over cascade-based baseline and tree-based
baseline algorithms, respectively. CAS-Spec can be easily integrated into most
existing LLMs and holds promising potential for further acceleration as
self-speculative decoding techniques continue to evolve.

</details>


### [25] [BI-DCGAN: A Theoretically Grounded Bayesian Framework for Efficient and Diverse GANs](https://arxiv.org/abs/2510.26892)
*Mahsa Valizadeh,Rui Tuo,James Caverlee*

Main category: cs.LG

TL;DR: BI-DCGAN是一种贝叶斯扩展的DCGAN，通过引入模型不确定性来解决GAN中的模式崩溃问题，提高生成样本的多样性。


<details>
  <summary>Details</summary>
Motivation: GAN在生成合成数据方面表现出色，但持续受到模式崩溃问题的困扰，即生成器只产生有限范围的输出，无法捕捉完整的数据分布。这在需要多样性和不确定性感知的实际应用中尤为严重。

Method: BI-DCGAN集成了Bayes by Backprop来学习网络权重的分布，并采用平均场变分推断在GAN训练期间高效近似后验分布。

Result: 通过标准生成基准测试的广泛实验验证，BI-DCGAN比传统DCGAN产生更多样化和鲁棒的输出，同时保持训练效率。

Conclusion: BI-DCGAN为需要多样性和不确定性的应用提供了一个可扩展且及时的解决方案，特别是在现代替代方案如扩散模型仍然过于资源密集的情况下。

Abstract: Generative Adversarial Networks (GANs) are proficient at generating synthetic
data but continue to suffer from mode collapse, where the generator produces a
narrow range of outputs that fool the discriminator but fail to capture the
full data distribution. This limitation is particularly problematic, as
generative models are increasingly deployed in real-world applications that
demand both diversity and uncertainty awareness. In response, we introduce
BI-DCGAN, a Bayesian extension of DCGAN that incorporates model uncertainty
into the generative process while maintaining computational efficiency.
BI-DCGAN integrates Bayes by Backprop to learn a distribution over network
weights and employs mean-field variational inference to efficiently approximate
the posterior distribution during GAN training. We establishes the first
theoretical proof, based on covariance matrix analysis, that Bayesian modeling
enhances sample diversity in GANs. We validate this theoretical result through
extensive experiments on standard generative benchmarks, demonstrating that
BI-DCGAN produces more diverse and robust outputs than conventional DCGANs,
while maintaining training efficiency. These findings position BI-DCGAN as a
scalable and timely solution for applications where both diversity and
uncertainty are critical, and where modern alternatives like diffusion models
remain too resource-intensive.

</details>


### [26] [Integrating Ontologies with Large Language Models for Enhanced Control Systems in Chemical Engineering](https://arxiv.org/abs/2510.26898)
*Crystal Su,Kuai Yu,Jingrui Zhang,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 提出了一个结合本体论和大型语言模型的化学工程框架，通过结构化领域知识和生成推理的统一，为过程控制和安全分析等关键工程应用提供透明可审计的方法。


<details>
  <summary>Details</summary>
Motivation: 将符号化结构与神经生成相结合，为化学工程领域提供透明、可审计的LLM应用方法，特别针对过程控制和安全分析等关键工程场景。

Method: 通过数据获取、语义预处理、信息提取和本体映射等步骤，构建与COPE本体对齐的模板化问答对来指导微调，采用控制聚焦解码和引用门机制来约束输出到本体链接术语。

Result: 开发了一个能够同时评估语言质量和本体准确性的评估指标，通过语义检索和迭代验证增强了系统的可解释性和可靠性。

Conclusion: 本体集成LLM框架成功地将结构化领域知识与生成推理相结合，为关键工程应用提供了透明且可审计的解决方案。

Abstract: This work presents an ontology-integrated large language model (LLM)
framework for chemical engineering that unites structured domain knowledge with
generative reasoning. The proposed pipeline aligns model training and inference
with the COPE ontology through a sequence of data acquisition, semantic
preprocessing, information extraction, and ontology mapping steps, producing
templated question-answer pairs that guide fine-tuning. A control-focused
decoding stage and citation gate enforce syntactic and factual grounding by
constraining outputs to ontology-linked terms, while evaluation metrics
quantify both linguistic quality and ontological accuracy. Feedback and future
extensions, including semantic retrieval and iterative validation, further
enhance the system's interpretability and reliability. This integration of
symbolic structure and neural generation provides a transparent, auditable
approach for applying LLMs to process control, safety analysis, and other
critical engineering contexts.

</details>


### [27] [Discovering EV Charging Site Archetypes Through Few Shot Forecasting: The First U.S.-Wide Study](https://arxiv.org/abs/2510.26910)
*Kshitij Nikhal,Luke Ackerknecht,Benjamin S. Riggan,Phil Stahlfeld*

Main category: cs.LG

TL;DR: 提出一个结合聚类和少样本预测的框架，利用大规模充电需求数据集发现站点原型，以改善电动汽车充电需求预测和基础设施规划。


<details>
  <summary>Details</summary>
Motivation: 现有研究受限于小规模数据集、简单的时间依赖建模以及对运营历史有限站点的弱泛化能力，需要更准确的充电行为理解来支持电网弹性和成本效益的基础设施建设。

Method: 集成聚类与少样本预测的框架，使用新颖的大规模充电需求数据集发现站点原型，构建原型特定的专家模型。

Result: 原型特定的专家模型在未见站点上的需求预测表现优于全局基线模型。

Conclusion: 通过将预测性能作为基础设施分割的基础，该框架为运营商提供了可操作的见解，有助于降低成本、优化能源和定价策略，并支持实现气候目标所需的电网弹性。

Abstract: The decarbonization of transportation relies on the widespread adoption of
electric vehicles (EVs), which requires an accurate understanding of charging
behavior to ensure cost-effective, grid-resilient infrastructure. Existing work
is constrained by small-scale datasets, simple proximity-based modeling of
temporal dependencies, and weak generalization to sites with limited
operational history. To overcome these limitations, this work proposes a
framework that integrates clustering with few-shot forecasting to uncover site
archetypes using a novel large-scale dataset of charging demand. The results
demonstrate that archetype-specific expert models outperform global baselines
in forecasting demand at unseen sites. By establishing forecast performance as
a basis for infrastructure segmentation, we generate actionable insights that
enable operators to lower costs, optimize energy and pricing strategies, and
support grid resilience critical to climate goals.

</details>


### [28] [MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models](https://arxiv.org/abs/2510.26937)
*Zimeng Huang,Jinxin Ke,Xiaoxuan Fan,Yufeng Yang,Yang Liu,Liu Zhonghan,Zedi Wang,Junteng Dai,Haoyi Jiang,Yuyu Zhou,Keze Wang,Ziliang Chen*

Main category: cs.LG

TL;DR: 提出了MM-OPERA基准测试，用于评估大型视觉语言模型在开放关联推理方面的能力，包含11,497个实例和两个任务，通过LLM作为评判者的策略来评估模型的关联智能。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型在关联智能方面存在不足，而现有基准测试局限于封闭式任务，无法评估开放关联推理能力，这是人类认知和创造性思维的关键。

Method: 开发了MM-OPERA基准测试，包含远程项目关联和上下文关联两个开放任务，采用LLM作为评判者的策略来评估自由形式响应和显式推理路径。

Result: 对最先进的大型视觉语言模型进行了广泛实证研究，包括任务实例敏感性分析、LLM评判策略有效性分析以及跨能力、领域、语言、文化等的多样性分析。

Conclusion: 研究揭示了当前大型视觉语言模型在关联推理方面的局限性，为开发更接近人类智能和通用人工智能铺平了道路。

Abstract: Large Vision-Language Models (LVLMs) have exhibited remarkable progress.
However, deficiencies remain compared to human intelligence, such as
hallucination and shallow pattern matching. In this work, we aim to evaluate a
fundamental yet underexplored intelligence: association, a cornerstone of human
cognition for creative thinking and knowledge integration. Current benchmarks,
often limited to closed-ended tasks, fail to capture the complexity of
open-ended association reasoning vital for real-world applications. To address
this, we present MM-OPERA, a systematic benchmark with 11,497 instances across
two open-ended tasks: Remote-Item Association (RIA) and In-Context Association
(ICA), aligning association intelligence evaluation with human psychometric
principles. It challenges LVLMs to resemble the spirit of divergent thinking
and convergent associative reasoning through free-form responses and explicit
reasoning paths. We deploy tailored LLM-as-a-Judge strategies to evaluate
open-ended outputs, applying process-reward-informed judgment to dissect
reasoning with precision. Extensive empirical studies on state-of-the-art
LVLMs, including sensitivity analysis of task instances, validity analysis of
LLM-as-a-Judge strategies, and diversity analysis across abilities, domains,
languages, cultures, etc., provide a comprehensive and nuanced understanding of
the limitations of current LVLMs in associative reasoning, paving the way for
more human-like and general-purpose AI. The dataset and code are available at
https://github.com/MM-OPERA-Bench/MM-OPERA.

</details>


### [29] [Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction](https://arxiv.org/abs/2510.26940)
*Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh*

Main category: cs.LG

TL;DR: 本文审计了最先进的移动性预测模型，揭示了基于用户人口统计特征的隐藏差异，并提出了一种公平性引导的增量采样方法FGIS来减少群体间性能差距。


<details>
  <summary>Details</summary>
Motivation: 移动位置预测应用日益广泛，但其社会影响尚未充分研究。作者发现现有模型在不同种族和族裔群体间存在系统性性能差异，需要解决这种公平性问题。

Method: 提出了FGIS（公平性引导增量采样）策略，结合SAKM（规模感知K均值）聚类方法，在缺乏个体人口统计标签的情况下使用人口普查数据生成代理种族标签，构建更公平的训练数据集。

Result: 该方法在MetaPath2Vec和Transformer-encoder模型上将群体间总差异减少了高达40%，且在早期采样阶段效果最显著，整体准确率损失最小。

Conclusion: 研究揭示了移动性预测流程中的结构性不平等，证明了轻量级、以数据为中心的干预措施能在低资源设置中有效改善公平性，而不会显著增加复杂性。

Abstract: Next location prediction underpins a growing number of mobility, retail, and
public-health applications, yet its societal impacts remain largely unexplored.
In this paper, we audit state-of-the-art mobility prediction models trained on
a large-scale dataset, highlighting hidden disparities based on user
demographics. Drawing from aggregate census data, we compute the difference in
predictive performance on racial and ethnic user groups and show a systematic
disparity resulting from the underlying dataset, resulting in large differences
in accuracy based on location and user groups. To address this, we propose
Fairness-Guided Incremental Sampling (FGIS), a group-aware sampling strategy
designed for incremental data collection settings. Because individual-level
demographic labels are unavailable, we introduce Size-Aware K-Means (SAKM), a
clustering method that partitions users in latent mobility space while
enforcing census-derived group proportions. This yields proxy racial labels for
the four largest groups in the state: Asian, Black, Hispanic, and White. Built
on these labels, our sampling algorithm prioritizes users based on expected
performance gains and current group representation. This method incrementally
constructs training datasets that reduce demographic performance gaps while
preserving overall accuracy. Our method reduces total disparity between groups
by up to 40\% with minimal accuracy trade-offs, as evaluated on a state-of-art
MetaPath2Vec model and a transformer-encoder model. Improvements are most
significant in early sampling stages, highlighting the potential for
fairness-aware strategies to deliver meaningful gains even in low-resource
settings. Our findings expose structural inequities in mobility prediction
pipelines and demonstrate how lightweight, data-centric interventions can
improve fairness with little added complexity, especially for low-data
applications.

</details>


### [30] [Can machines think efficiently?](https://arxiv.org/abs/2510.26954)
*Adam Winchell*

Main category: cs.LG

TL;DR: 提出基于能耗约束的新图灵测试，将智能评估与能源效率联系起来


<details>
  <summary>Details</summary>
Motivation: 原图灵测试已不足以区分人类与机器智能，且AI系统引发了严重的伦理和环境问题，需要更新测试标准

Method: 在原模仿游戏基础上增加能耗约束，通过能源消耗来评估智能效率

Result: 新测试为智能评估提供了可测量的实际终点，迫使社会权衡AI的时间节省与总资源成本

Conclusion: 基于能耗约束的新图灵测试能更有效地评估智能，连接抽象思维与有限资源的现实

Abstract: The Turing Test is no longer adequate for distinguishing human and machine
intelligence. With advanced artificial intelligence systems already passing the
original Turing Test and contributing to serious ethical and environmental
concerns, we urgently need to update the test. This work expands upon the
original imitation game by accounting for an additional factor: the energy
spent answering the questions. By adding the constraint of energy, the new test
forces us to evaluate intelligence through the lens of efficiency, connecting
the abstract problem of thinking to the concrete reality of finite resources.
Further, this proposed new test ensures the evaluation of intelligence has a
measurable, practical finish line that the original test lacks. This additional
constraint compels society to weigh the time savings of using artificial
intelligence against its total resource cost.

</details>


### [31] [Predicting Household Water Consumption Using Satellite and Street View Images in Two Indian Cities](https://arxiv.org/abs/2510.26957)
*Qiao Wang,Joseph George*

Main category: cs.LG

TL;DR: 使用公开可用的卫星图像、Google街景分割和简单地理空间数据预测印度城市家庭用水量，接近传统调查方法的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统家庭用水监测方法成本高、耗时，需要寻找更高效的替代方案。

Method: 比较四种方法：调查特征（基准）、CNN嵌入（卫星、街景、组合）、街景语义地图加辅助数据，采用序数分类框架。

Result: 街景分割加遥感协变量达到0.55准确率，接近调查模型的0.59准确率，在用水量极端值处精度高。

Conclusion: 开放获取图像结合最小地理空间数据可替代传统调查，为城市分析提供可靠的家庭用水估算。

Abstract: Monitoring household water use in rapidly urbanizing regions is hampered by
costly, time-intensive enumeration methods and surveys. We investigate whether
publicly available imagery-satellite tiles, Google Street View (GSV)
segmentation-and simple geospatial covariates (nightlight intensity, population
density) can be utilized to predict household water consumption in
Hubballi-Dharwad, India. We compare four approaches: survey features
(benchmark), CNN embeddings (satellite, GSV, combined), and GSV semantic maps
with auxiliary data. Under an ordinal classification framework, GSV
segmentation plus remote-sensing covariates achieves 0.55 accuracy for water
use, approaching survey-based models (0.59 accuracy). Error analysis shows high
precision at extremes of the household water consumption distribution, but
confusion among middle classes is due to overlapping visual proxies. We also
compare and contrast our estimates for household water consumption to that of
household subjective income. Our findings demonstrate that open-access imagery,
coupled with minimal geospatial data, offers a promising alternative to
obtaining reliable household water consumption estimates using surveys in urban
analytics.

</details>


### [32] [Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget](https://arxiv.org/abs/2510.26981)
*Zhichao Hou,Weizhi Gao,Xiaorui Liu*

Main category: cs.LG

TL;DR: 提出了一种在有限计算预算下最大化对抗攻击效果的方法，通过选择性重新计算层激活来精细控制计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决AI安全研究中计算资源有限时的关键挑战：如何在固定计算预算下最大化迭代对抗攻击的效果。

Method: 提出了细粒度控制机制，在迭代和层级两个维度上选择性重新计算层激活。

Result: 在相同成本下始终优于现有基线方法，集成到对抗训练中仅需原始预算的30%即可达到相当性能。

Conclusion: 该方法有效解决了有限计算预算下的对抗攻击优化问题，显著提高了计算效率。

Abstract: This work tackles a critical challenge in AI safety research under limited
compute: given a fixed computation budget, how can one maximize the strength of
iterative adversarial attacks? Coarsely reducing the number of attack
iterations lowers cost but substantially weakens effectiveness. To fulfill the
attainable attack efficacy within a constrained budget, we propose a
fine-grained control mechanism that selectively recomputes layer activations
across both iteration-wise and layer-wise levels. Extensive experiments show
that our method consistently outperforms existing baselines at equal cost.
Moreover, when integrated into adversarial training, it attains comparable
performance with only 30% of the original budget.

</details>


### [33] [HADSF: Aspect Aware Semantic Control for Explainable Recommendation](https://arxiv.org/abs/2510.26994)
*Zheng Nie,Peijie Sun*

Main category: cs.LG

TL;DR: 提出了HADSF框架，通过双阶段语义处理解决LLM在评论推荐系统中的问题：自适应生成紧凑方面词汇表，然后进行约束提取，并引入新指标评估表示保真度。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的评论推荐系统存在三个问题：(i)无范围控制的自由形式评论挖掘产生冗余噪声表示，(ii)缺乏将LLM幻觉与下游效果关联的指标，(iii)未探索模型规模的成本-质量权衡。

Method: HADSF双阶段框架：第一阶段通过自适应选择生成语料级紧凑方面词汇表，第二阶段进行词汇表引导的约束提取，获取结构化方面-观点三元组。引入ADR和OFR指标评估表示保真度。

Result: 在约300万条评论和1.5B-70B参数的LLM上实验表明，HADSF集成到标准评分预测器中能持续降低预测误差，使小模型在代表性部署场景中达到竞争性能。

Conclusion: HADSF框架有效解决了LLM在评论推荐中的关键问题，提供了可复现的幻觉感知、LLM增强的可解释推荐研究基础。

Abstract: Recent advances in large language models (LLMs) promise more effective
information extraction for review-based recommender systems, yet current
methods still (i) mine free-form reviews without scope control, producing
redundant and noisy representations, (ii) lack principled metrics that link LLM
hallucination to downstream effectiveness, and (iii) leave the cost-quality
trade-off across model scales largely unexplored. We address these gaps with
the Hyper-Adaptive Dual-Stage Semantic Framework (HADSF), a two-stage approach
that first induces a compact, corpus-level aspect vocabulary via adaptive
selection and then performs vocabulary-guided, explicitly constrained
extraction of structured aspect-opinion triples. To assess the fidelity of the
resulting representations, we introduce Aspect Drift Rate (ADR) and Opinion
Fidelity Rate (OFR) and empirically uncover a nonmonotonic relationship between
hallucination severity and rating prediction error. Experiments on
approximately 3 million reviews across LLMs spanning 1.5B-70B parameters show
that, when integrated into standard rating predictors, HADSF yields consistent
reductions in prediction error and enables smaller models to achieve
competitive performance in representative deployment scenarios. We release
code, data pipelines, and metric implementations to support reproducible
research on hallucination-aware, LLM-enhanced explainable recommendation. Code
is available at https://github.com/niez233/HADSF

</details>


### [34] [Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules](https://arxiv.org/abs/2510.26997)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，将学习规则视为在损失景观中导航的策略，并将最优规则识别为相关最优控制问题的解。


<details>
  <summary>Details</summary>
Motivation: 传统上学习规则通常是假设而非推导出来的，需要理解为什么某些学习规则比其他规则更好，以及在什么假设下可以认为给定规则是最优的。

Method: 将学习规则建模为在（部分可观测）损失景观中导航的策略，并将最优规则识别为相关最优控制问题的解。

Result: 在该框架下，梯度下降、动量、自然梯度、非梯度规则和Adam等自适应优化器都可以自然地出现，持续学习策略如权重重置也可以被理解为对任务不确定性的最优响应。

Conclusion: 该框架通过统一这些现象到一个单一目标下，阐明了学习的计算结构，并为设计自适应算法提供了原则性基础。

Abstract: Learning rules -- prescriptions for updating model parameters to improve
performance -- are typically assumed rather than derived. Why do some learning
rules work better than others, and under what assumptions can a given rule be
considered optimal? We propose a theoretical framework that casts learning
rules as policies for navigating (partially observable) loss landscapes, and
identifies optimal rules as solutions to an associated optimal control problem.
A range of well-known rules emerge naturally within this framework under
different assumptions: gradient descent from short-horizon optimization,
momentum from longer-horizon planning, natural gradients from accounting for
parameter space geometry, non-gradient rules from partial controllability, and
adaptive optimizers like Adam from online Bayesian inference of loss landscape
shape. We further show that continual learning strategies like weight resetting
can be understood as optimal responses to task uncertainty. By unifying these
phenomena under a single objective, our framework clarifies the computational
structure of learning and offers a principled foundation for designing adaptive
algorithms.

</details>


### [35] [A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms](https://arxiv.org/abs/2510.27001)
*Elise Wolf*

Main category: cs.LG

TL;DR: 本文提出了一个可复现的多臂老虎机算法评估框架，系统比较了8种经典和方差感知算法，发现方差感知算法在高不确定性环境中具有优势。


<details>
  <summary>Details</summary>
Motivation: 多臂老虎机算法评估缺乏标准化条件和可复现性，特别是方差感知扩展算法的性能高度依赖环境条件，需要系统性的评估方法。

Method: 开发了Bandit Playground代码库，包含明确定义的实验设置、多种性能指标（奖励、遗憾、奖励分布、风险价值和动作最优性）以及交互式评估界面。

Result: 方差感知算法在奖励差异细微的高不确定性环境中表现更好，而经典算法在可分离场景或经过充分调优时表现相当或更优。

Conclusion: 贡献包括：1）系统评估MAB算法的框架；2）明确了方差感知方法优于经典方法的具体条件。

Abstract: Multi-armed bandit (MAB) problems serve as a fundamental building block for
more complex reinforcement learning algorithms. However, evaluating and
comparing MAB algorithms remains challenging due to the lack of standardized
conditions and replicability. This is particularly problematic for
variance-aware extensions of classical methods like UCB, whose performance can
heavily depend on the underlying environment. In this study, we address how
performance differences between bandit algorithms can be reliably observed, and
under what conditions variance-aware algorithms outperform classical ones. We
present a reproducible evaluation designed to systematically compare eight
classical and variance-aware MAB algorithms. The evaluation framework,
implemented in our Bandit Playground codebase, features clearly defined
experimental setups, multiple performance metrics (reward, regret, reward
distribution, value-at-risk, and action optimality), and an interactive
evaluation interface that supports consistent and transparent analysis. We show
that variance-aware algorithms can offer advantages in settings with high
uncertainty where the difficulty arises from subtle differences between arm
rewards. In contrast, classical algorithms often perform equally well or better
in more separable scenarios or if fine-tuned extensively. Our contributions are
twofold: (1) a framework for systematic evaluation of MAB algorithms, and (2)
insights into the conditions under which variance-aware approaches outperform
their classical counterparts.

</details>


### [36] [Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase](https://arxiv.org/abs/2510.27002)
*Mihir Mahajan,Alfred Nguyen,Franz Srambical,Stefan Bauer*

Main category: cs.LG

TL;DR: Jasmine是一个基于JAX的高性能世界建模代码库，支持从单机到数百个加速器的扩展，在CoinRun案例研究中比现有实现快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 世界建模是解决机器人等领域数据稀缺问题的途径，但目前开放的世界建模训练基础设施仍处于初级阶段。

Method: 开发了Jasmine代码库，通过数据加载、训练和检查点等性能优化，支持完全可重现的训练和多样化分片配置。

Result: 在CoinRun案例研究中实现了比现有开源实现快一个数量级的复现速度，并建立了跨模型家族和架构消融的严格基准测试流程。

Conclusion: Jasmine与精选的大规模数据集结合，为世界建模研究提供了高性能、可扩展的基础设施支持。

Abstract: While world models are increasingly positioned as a pathway to overcoming
data scarcity in domains such as robotics, open training infrastructure for
world modeling remains nascent. We introduce Jasmine, a performant JAX-based
world modeling codebase that scales from single hosts to hundreds of
accelerators with minimal code changes. Jasmine achieves an order-of-magnitude
faster reproduction of the CoinRun case study compared to prior open
implementations, enabled by performance optimizations across data loading,
training and checkpointing. The codebase guarantees fully reproducible training
and supports diverse sharding configurations. By pairing Jasmine with curated
large-scale datasets, we establish infrastructure for rigorous benchmarking
pipelines across model families and architectural ablations.

</details>


### [37] [Mixture-of-Transformers Learn Faster: A Theoretical Study on Classification Problems](https://arxiv.org/abs/2510.27004)
*Hongbo Li,Qinhang Wu,Sen Lin,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: 提出了Mixture-of-Transformers (MoT)理论框架，通过连续训练门控网络实现transformer块级专家专业化，显著提升训练效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的Mixture-of-Experts模型缺乏统一理论解释，特别是在允许前馈层和注意力层都专业化的情况下。需要建立可处理的理论框架来理解专家专业化和注意力对齐的核心学习动态。

Method: 开发了三阶段训练算法，连续训练门控网络，使每个transformer专家专注于特定任务类别，门控网络准确路由数据样本到正确专家。

Result: 理论分析表明专家专业化减少了梯度冲突，使每个子任务强凸。训练在O(log(ε⁻¹))迭代步数内将预期预测损失驱动到接近零，显著优于单transformer的O(ε⁻¹)速率。真实数据实验验证了MoT的实际有效性。

Conclusion: 提供了首个统一的transformer级专业化和学习动态理论解释，为设计高效大规模模型提供了实践指导。

Abstract: Mixture-of-Experts (MoE) models improve transformer efficiency but lack a
unified theoretical explanation, especially when both feed-forward and
attention layers are allowed to specialize. To this end, we study the
Mixture-of-Transformers (MoT), a tractable theoretical framework in which each
transformer block acts as an expert governed by a continuously trained gating
network. This design allows us to isolate and study the core learning dynamics
of expert specialization and attention alignment. In particular, we develop a
three-stage training algorithm with continuous training of the gating network,
and show that each transformer expert specializes in a distinct class of tasks
and that the gating network accurately routes data samples to the correct
expert. Our analysis shows how expert specialization reduces gradient conflicts
and makes each subtask strongly convex. We prove that the training drives the
expected prediction loss to near zero in $O(\log(\epsilon^{-1}))$ iteration
steps, significantly improving over the $O(\epsilon^{-1})$ rate for a single
transformer. We further validate our theoretical findings through extensive
real-data experiments, demonstrating the practical effectiveness of MoT.
Together, these results offer the first unified theoretical account of
transformer-level specialization and learning dynamics, providing practical
guidance for designing efficient large-scale models.

</details>


### [38] [Enhancing Sentiment Classification with Machine Learning and Combinatorial Fusion](https://arxiv.org/abs/2510.27014)
*Sean Patten,Pin-Yu Chen,Christina Schweikert,D. Frank Hsu*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的情感分类方法，通过组合融合分析(CFA)集成多种机器学习模型，在IMDB情感分析数据集上达到了97.072%的最新准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常通过扩大单个模型的规模来提高性能，但计算资源消耗大。本文旨在利用认知多样性概念，通过量化模型间的差异性来更有效地集成模型预测。

Method: 使用组合融合分析(CFA)方法，通过秩-得分特征函数量化模型间的差异性，策略性地结合RoBERTa架构的transformer模型与传统机器学习模型(随机森林、SVM、XGBoost)的预测。

Result: 在IMDB情感分析数据集上实现了97.072%的state-of-the-art准确率，优于传统集成方法，且计算资源使用相对高效。

Conclusion: 组合融合分析通过有效计算和利用模型多样性，能够显著提升情感分类性能，相比单纯扩大模型规模的方法更具计算效率。

Abstract: This paper presents a novel approach to sentiment classification using the
application of Combinatorial Fusion Analysis (CFA) to integrate an ensemble of
diverse machine learning models, achieving state-of-the-art accuracy on the
IMDB sentiment analysis dataset of 97.072\%. CFA leverages the concept of
cognitive diversity, which utilizes rank-score characteristic functions to
quantify the dissimilarity between models and strategically combine their
predictions. This is in contrast to the common process of scaling the size of
individual models, and thus is comparatively efficient in computing resource
use. Experimental results also indicate that CFA outperforms traditional
ensemble methods by effectively computing and employing model diversity. The
approach in this paper implements the combination of a transformer-based model
of the RoBERTa architecture with traditional machine learning models, including
Random Forest, SVM, and XGBoost.

</details>


### [39] [Quantitative Bounds for Length Generalization in Transformers](https://arxiv.org/abs/2510.27015)
*Zachary Izzo,Eshaan Nichani,Jason D. Lee*

Main category: cs.LG

TL;DR: 本文首次为Transformer的长度泛化提供了定量边界，证明了当训练序列长度超过特定阈值时，模型能够在未见过的更长序列上保持性能。


<details>
  <summary>Details</summary>
Motivation: 先前研究虽然证明Transformer最终能实现长度泛化，但未明确训练序列长度需要多大。本文旨在量化这一阈值，深化对Transformer外推机制的理论理解。

Method: 分析了多种问题设置：ℓ∞误差控制vs平均误差控制、无限精度softmax注意力vs有限精度注意力、单层vs双层Transformer。通过证明在更长序列上的内部行为可以被训练中较短序列的行为"模拟"来实现泛化。

Result: 在所有场景下都证明了长度泛化的存在，并给出了训练数据长度需求的定性估计，通过实验验证了这些理论见解。

Conclusion: 研究结果深化了对Transformer外推机制的理论理解，并形式化了"更复杂的任务需要更丰富的训练数据才能泛化"这一直觉。

Abstract: We study the problem of length generalization (LG) in transformers: the
ability of a model trained on shorter sequences to maintain performance when
evaluated on much longer, previously unseen inputs. Prior work by Huang et al.
(2025) established that transformers eventually achieve length generalization
once the training sequence length exceeds some finite threshold, but left open
the question of how large it must be. In this work, we provide the first
quantitative bounds on the required training length for length generalization
to occur. Motivated by previous empirical and theoretical work, we analyze LG
in several distinct problem settings: $\ell_\infty$ error control vs. average
error control over an input distribution, infinite-precision softmax attention
vs. finite-precision attention (which reduces to an argmax) in the transformer,
and one- vs. two-layer transformers. In all scenarios, we prove that LG occurs
when the internal behavior of the transformer on longer sequences can be
"simulated" by its behavior on shorter sequences seen during training. Our
bounds give qualitative estimates for the length of training data required for
a transformer to generalize, and we verify these insights empirically. These
results sharpen our theoretical understanding of the mechanisms underlying
extrapolation in transformers, and formalize the intuition that richer training
data is required for generalization on more complex tasks.

</details>


### [40] [Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](https://arxiv.org/abs/2510.27044)
*Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 该论文研究了强化学习与可验证奖励（RLVR）在数学推理任务中的效果，发现在活动调度和最长递增子序列两个组合问题上，RLVR虽然能提升评估指标，但往往是通过强化表面启发式方法而非获得真正的推理策略。


<details>
  <summary>Details</summary>
Motivation: 数学推理是大型语言模型的核心挑战，需要正确答案和忠实的推理过程。RLVR被认为是增强这种能力的有效方法，但其是否能促进真正的推理能力尚不清楚。

Method: 在活动调度和最长递增子序列两个具有完全可验证解的组合问题上应用RLVR，使用精心策划的具有唯一最优解的数据集，并测试多种奖励设计。

Result: 研究发现RLVR虽然能改善评估指标，但通常是通过强化表面启发式方法而非获得新的推理策略，揭示了RLVR泛化能力的局限性。

Conclusion: 这些发现强调了基准测试的重要性，需要能够区分真正的数学推理与捷径利用，并提供对进展的忠实衡量。

Abstract: Mathematical reasoning is a central challenge for large language models
(LLMs), requiring not only correct answers but also faithful reasoning
processes. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as
a promising approach for enhancing such capabilities; however, its ability to
foster genuine reasoning remains unclear. We investigate RLVR on two
combinatorial problems with fully verifiable solutions: \emph{Activity
Scheduling} and the \emph{Longest Increasing Subsequence}, using carefully
curated datasets with unique optima. Across multiple reward designs, we find
that RLVR improves evaluation metrics but often by reinforcing superficial
heuristics rather than acquiring new reasoning strategies. These findings
highlight the limits of RLVR generalization, emphasizing the importance of
benchmarks that disentangle genuine mathematical reasoning from shortcut
exploitation and provide faithful measures of progress. Code available at
https://github.com/xashru/rlvr-seq-generalization.

</details>


### [41] [Consistency Training Helps Stop Sycophancy and Jailbreaks](https://arxiv.org/abs/2510.27062)
*Alex Irpan,Alexander Matt Turner,Mark Kurzeja,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 该论文提出了两种一致性训练方法（BCT和ACT），通过使模型对提示中的无关线索保持不变量，来减少LLM的谄媚行为和越狱攻击。


<details>
  <summary>Details</summary>
Motivation: LLM的事实性和拒绝训练容易被简单的提示修改所破坏，模型经常表现出谄媚行为或满足不当请求。作者旨在解决模型对提示中无关线索的敏感性问题。

Method: 提出了两种一致性训练方法：1）基于外部输出的BCT方法；2）基于内部激活的ACT方法。通过让模型在提示数据增强下表现一致来训练模型。

Result: 两种方法都有效减少了Gemini 2.5 Flash对无关线索的敏感性。BCT和ACT在减少谄媚行为方面效果相当，但BCT在减少越狱方面表现更好。

Conclusion: 一致性训练可以简化训练流程，避免依赖静态数据集。某些对齐问题应被视为一致性问题而非最优响应问题。

Abstract: An LLM's factuality and refusal training can be compromised by simple changes
to a prompt. Models often adopt user beliefs (sycophancy) or satisfy
inappropriate requests which are wrapped within special text (jailbreaking). We
explore \emph{consistency training}, a self-supervised paradigm that teaches a
model to be invariant to certain irrelevant cues in the prompt. Instead of
teaching the model what exact response to give on a particular prompt, we aim
to teach the model to behave identically across prompt data augmentations (like
adding leading questions or jailbreak text). We try enforcing this invariance
in two ways: over the model's external outputs (\emph{Bias-augmented
Consistency Training} (BCT) from Chua et al. [2025]) and over its internal
activations (\emph{Activation Consistency Training} (ACT), a method we
introduce). Both methods reduce Gemini 2.5 Flash's susceptibility to irrelevant
cues. Because consistency training uses responses from the model itself as
training data, it avoids issues that arise from stale training data, such as
degrading model capabilities or enforcing outdated response guidelines. While
BCT and ACT reduce sycophancy equally well, BCT does better at jailbreak
reduction. We think that BCT can simplify training pipelines by removing
reliance on static datasets. We argue that some alignment problems are better
viewed not in terms of optimal responses, but rather as consistency issues.

</details>


### [42] [Towards a Measure of Algorithm Similarity](https://arxiv.org/abs/2510.27063)
*Shairoz Sohail,Taher Ali*

Main category: cs.LG

TL;DR: 提出了EMOC框架来评估算法相似性，将算法实现嵌入到特征空间中，用于克隆检测、程序合成等下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决如何确定两个算法是否真正不同的问题，这在程序克隆检测和程序合成等应用中很重要，但现有方法缺乏一致且实用的相似性度量。

Method: 开发了EMOC（评估-内存-操作-复杂度）框架，将算法实现嵌入到特征空间；创建了PACD数据集，包含三个问题的已验证Python实现。

Result: EMOC特征支持算法类型聚类和分类、近重复检测，并能量化LLM生成程序的多样性。

Conclusion: EMOC框架为算法相似性分析提供了实用工具，相关代码和数据已开源以促进可重现性和未来研究。

Abstract: Given two algorithms for the same problem, can we determine whether they are
meaningfully different? In full generality, the question is uncomputable, and
empirically it is muddied by competing notions of similarity. Yet, in many
applications (such as clone detection or program synthesis) a pragmatic and
consistent similarity metric is necessary. We review existing equivalence and
similarity notions and introduce EMOC: An
Evaluation-Memory-Operations-Complexity framework that embeds algorithm
implementations into a feature space suitable for downstream tasks. We compile
PACD, a curated dataset of verified Python implementations across three
problems, and show that EMOC features support clustering and classification of
algorithm types, detection of near-duplicates, and quantification of diversity
in LLM-generated programs. Code, data, and utilities for computing EMOC
embeddings are released to facilitate reproducibility and future work on
algorithm similarity.

</details>


### [43] [MLPerf Automotive](https://arxiv.org/abs/2510.27065)
*Radoyeh Shojaei,Predrag Djurdjevic,Mostafa El-Khamy,James Goel,Kasper Mecklenburg,John Owens,Pınar Muyan-Özçelik,Tom St. John,Jinho Suh,Arjun Suresh*

Main category: cs.LG

TL;DR: MLPerf Automotive是首个用于评估汽车系统中AI加速机器学习系统的标准化公开基准，由MLCommons和自动驾驶车辆计算联盟合作开发，专注于汽车感知任务。


<details>
  <summary>Details</summary>
Motivation: 现有基准套件无法满足汽车工作负载的特殊需求，包括安全性和实时处理要求，因此需要专门针对汽车机器学习系统的标准化性能评估方法。

Method: 开发了包含2D目标检测、2D语义分割和3D目标检测等汽车感知任务的基准框架，提供延迟和准确性指标以及评估协议，确保跨硬件平台和软件实现的一致性和可重现性比较。

Result: 首个基准迭代已完成，包括任务选择、参考模型和提交规则的详细方法，并讨论了第一轮基准提交以及获取数据集和开发参考实现所面临的挑战。

Conclusion: MLPerf Automotive填补了汽车机器学习系统标准化评估的空白，为行业提供了可靠的性能比较基准，代码已在GitHub开源。

Abstract: We present MLPerf Automotive, the first standardized public benchmark for
evaluating Machine Learning systems that are deployed for AI acceleration in
automotive systems. Developed through a collaborative partnership between
MLCommons and the Autonomous Vehicle Computing Consortium, this benchmark
addresses the need for standardized performance evaluation methodologies in
automotive machine learning systems. Existing benchmark suites cannot be
utilized for these systems since automotive workloads have unique constraints
including safety and real-time processing that distinguish them from the
domains that previously introduced benchmarks target. Our benchmarking
framework provides latency and accuracy metrics along with evaluation protocols
that enable consistent and reproducible performance comparisons across
different hardware platforms and software implementations. The first iteration
of the benchmark consists of automotive perception tasks in 2D object
detection, 2D semantic segmentation, and 3D object detection. We describe the
methodology behind the benchmark design including the task selection, reference
models, and submission rules. We also discuss the first round of benchmark
submissions and the challenges involved in acquiring the datasets and the
engineering efforts to develop the reference implementations. Our benchmark
code is available at https://github.com/mlcommons/mlperf_automotive.

</details>


### [44] [Towards Understanding Self-play for LLM Reasoning](https://arxiv.org/abs/2510.27072)
*Justin Yang Chae,Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 本文分析了自博弈训练在大型语言模型数学推理中的训练动态，通过与RLVR和SFT对比，研究了参数更新稀疏性、熵动态和奖励函数，揭示了自博弈的机制和局限性。


<details>
  <summary>Details</summary>
Motivation: 自博弈训练在数学推理中显示出强大效果，但其改进机制尚不明确，需要深入理解自博弈与其他后训练策略的差异。

Method: 使用Absolute Zero Reasoner分析自博弈训练动态，比较RLVR和SFT，考察参数更新稀疏性、熵动态和替代提议者奖励函数，并通过pass@k评估推理性能。

Result: 研究阐明了自博弈与其他后训练策略的差异，揭示了其内在局限性。

Conclusion: 研究结果有助于理解自博弈机制，为未来改进LLM数学推理的自博弈方法指明了方向。

Abstract: Recent advances in large language model (LLM) reasoning, led by reinforcement
learning with verifiable rewards (RLVR), have inspired self-play post-training,
where models improve by generating and solving their own problems. While
self-play has shown strong in-domain and out-of-domain gains, the mechanisms
behind these improvements remain poorly understood. In this work, we analyze
the training dynamics of self-play through the lens of the Absolute Zero
Reasoner, comparing it against RLVR and supervised fine-tuning (SFT). Our study
examines parameter update sparsity, entropy dynamics of token distributions,
and alternative proposer reward functions. We further connect these dynamics to
reasoning performance using pass@k evaluations. Together, our findings clarify
how self-play differs from other post-training strategies, highlight its
inherent limitations, and point toward future directions for improving LLM math
reasoning through self-play.

</details>


### [45] [Functional embeddings enable Aggregation of multi-area SEEG recordings over subjects and sessions](https://arxiv.org/abs/2510.27090)
*Sina Javadzadeh,Rahil Soroushmojdehi,S. Alireza Seyyed Mousavi,Mehrnaz Asadi,Sumiko Abe,Terence D. Sanger*

Main category: cs.LG

TL;DR: 提出了一种可扩展的表征学习框架，通过功能嵌入和Transformer建模，实现跨受试者的颅内记录数据聚合，解决了电极位置和数量差异带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决跨受试者颅内记录数据聚合的挑战，因为电极数量、位置和覆盖区域差异很大，传统的空间归一化方法（如MNI坐标）无法准确捕捉功能相似性。

Method: 使用孪生编码器和对比学习目标学习电极的功能表征，然后通过Transformer建模区域间关系，支持可变数量的通道输入。

Result: 在20名受试者的数据集上验证，学习的功能空间支持准确的受试者内区分和区域一致性聚类，能够零样本迁移到未见过的通道，Transformer能够捕捉跨区域依赖关系并重建被遮蔽的通道。

Conclusion: 该方法为缺乏严格任务结构和统一传感器放置的颅内神经数据提供了大规模跨受试者聚合和预训练的可行路径。

Abstract: Aggregating intracranial recordings across subjects is challenging since
electrode count, placement, and covered regions vary widely. Spatial
normalization methods like MNI coordinates offer a shared anatomical reference,
but often fail to capture true functional similarity, particularly when
localization is imprecise; even at matched anatomical coordinates, the targeted
brain region and underlying neural dynamics can differ substantially between
individuals. We propose a scalable representation-learning framework that (i)
learns a subject-agnostic functional identity for each electrode from
multi-region local field potentials using a Siamese encoder with contrastive
objectives, inducing an embedding geometry that is locality-sensitive to
region-specific neural signatures, and (ii) tokenizes these embeddings for a
transformer that models inter-regional relationships with a variable number of
channels. We evaluate this framework on a 20-subject dataset spanning basal
ganglia-thalamic regions collected during flexible rest/movement recording
sessions with heterogeneous electrode layouts. The learned functional space
supports accurate within-subject discrimination and forms clear,
region-consistent clusters; it transfers zero-shot to unseen channels. The
transformer, operating on functional tokens without subject-specific heads or
supervision, captures cross-region dependencies and enables reconstruction of
masked channels, providing a subject-agnostic backbone for downstream decoding.
Together, these results indicate a path toward large-scale, cross-subject
aggregation and pretraining for intracranial neural data where strict task
structure and uniform sensor placement are unavailable.

</details>


### [46] [QiNN-QJ: A Quantum-inspired Neural Network with Quantum Jump for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.27091)
*Yiwei Chen,Kehuan Yan,Yu Pan,Daoyi Dong*

Main category: cs.LG

TL;DR: 提出了一种量子启发的神经网络QiNN-QJ，通过量子跳跃算子实现多模态纠缠建模，解决了传统量子启发方法训练不稳定和泛化能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有量子启发融合模型仅依赖酉变换生成量子纠缠，虽然理论表达能力强，但存在训练不稳定和泛化能力有限的问题。

Method: 每个模态首先编码为量子纯态，然后通过可微分模块模拟量子跳跃算子将可分离乘积态转换为纠缠表示。通过联合学习哈密顿量和Lindblad算子，QiNN-QJ生成可控的跨模态纠缠，利用结构化随机性和稳态吸引子特性稳定训练并约束纠缠形状。

Result: 在CMU-MOSI、CMU-MOSEI和CH-SIMS等基准数据集上实现了优于最先进模型的性能，并通过冯诺依曼纠缠熵增强了事后可解释性。

Conclusion: 这项工作为纠缠多模态融合建立了一个原则性框架，为量子启发方法在建模复杂跨模态相关性方面开辟了新途径。

Abstract: Quantum theory provides non-classical principles, such as superposition and
entanglement, that inspires promising paradigms in machine learning. However,
most existing quantum-inspired fusion models rely solely on unitary or
unitary-like transformations to generate quantum entanglement. While
theoretically expressive, such approaches often suffer from training
instability and limited generalizability. In this work, we propose a
Quantum-inspired Neural Network with Quantum Jump (QiNN-QJ) for multimodal
entanglement modelling. Each modality is firstly encoded as a quantum pure
state, after which a differentiable module simulating the QJ operator
transforms the separable product state into the entangled representation. By
jointly learning Hamiltonian and Lindblad operators, QiNN-QJ generates
controllable cross-modal entanglement among modalities with dissipative
dynamics, where structured stochasticity and steady-state attractor properties
serve to stabilize training and constrain entanglement shaping. The resulting
entangled states are projected onto trainable measurement vectors to produce
predictions. In addition to achieving superior performance over the
state-of-the-art models on benchmark datasets, including CMU-MOSI, CMU-MOSEI,
and CH-SIMS, QiNN-QJ facilitates enhanced post-hoc interpretability through
von-Neumann entanglement entropy. This work establishes a principled framework
for entangled multimodal fusion and paves the way for quantum-inspired
approaches in modelling complex cross-modal correlations.

</details>


### [47] [Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle](https://arxiv.org/abs/2510.27097)
*Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 提出了一个概率层次贝叶斯模型，用于从批量RNA测序数据中解卷积细胞类型表达谱和比例，应用于人类子宫内膜组织月经周期研究，揭示了细胞类型特异性动态变化。


<details>
  <summary>Details</summary>
Motivation: 批量组织RNA测序会掩盖细胞类型特异性动态，特别是在细胞组成变化显著的样本中，如月经周期中的子宫内膜组织。

Method: 使用概率层次贝叶斯模型，结合高分辨率单细胞参考数据，解卷积批量RNA-seq数据，推断细胞类型比例和细胞特异性基因表达变化。

Result: 揭示了月经周期不同阶段上皮细胞、基质细胞和免疫细胞比例的动态变化，识别了与子宫内膜功能相关的细胞类型特异性差异基因表达。

Conclusion: 贝叶斯方法对参考数据不匹配和噪声具有鲁棒性，为研究细胞组成动态变化的组织提供了有力工具，具有生育和子宫内膜疾病临床应用的潜力。

Abstract: Bulk tissue RNA sequencing of heterogeneous samples provides averaged gene
expression profiles, obscuring cell type-specific dynamics. To address this, we
present a probabilistic hierarchical Bayesian model that deconvolves bulk
RNA-seq data into constituent cell-type expression profiles and proportions,
leveraging a high-resolution single-cell reference. We apply our model to human
endometrial tissue across the menstrual cycle, a context characterized by
dramatic hormone-driven cellular composition changes. Our extended framework
provides a principled inference of cell type proportions and cell-specific gene
expression changes across cycle phases. We demonstrate the model's structure,
priors, and inference strategy in detail, and we validate its performance with
simulations and comparisons to existing methods. The results reveal dynamic
shifts in epithelial, stromal, and immune cell fractions between menstrual
phases, and identify cell-type-specific differential gene expression associated
with endometrial function (e.g., decidualization markers in stromal cells
during the secretory phase). We further conduct robustness tests and show that
our Bayesian approach is resilient to reference mismatches and noise. Finally,
we discuss the biological significance of our findings, potential clinical
implications for fertility and endometrial disorders, and future directions,
including integration of spatial transcriptomics.

</details>


### [48] [Group-Sensitive Offline Contextual Bandits](https://arxiv.org/abs/2510.27123)
*Yihong Guo,Junjie Luo,Guodong Gao,Ritu Agarwal,Anqi Liu*

Main category: cs.LG

TL;DR: 提出了一种离线上下文赌博机中的群体敏感公平约束方法，通过引入群体间奖励差异约束来减少策略学习过程中可能出现的奖励差异，同时保持整体性能。


<details>
  <summary>Details</summary>
Motivation: 离线策略优化在最大化总体期望奖励时可能无意中放大群体间的奖励差异，导致某些群体受益更多，这在资源有限的情况下引发公平性担忧。

Method: 提出了一个约束离线策略优化框架，将群体间奖励差异约束引入到基于梯度的离策略优化过程中，使用双重稳健估计器来改进群体间奖励差异的估计。

Result: 在合成和真实世界数据集上的实验结果表明，该方法能有效减少奖励差异，同时保持有竞争力的整体性能。

Conclusion: 该方法成功解决了离线上下文赌博机中的群体公平性问题，通过约束优化框架平衡了公平性和性能目标。

Abstract: Offline contextual bandits allow one to learn policies from
historical/offline data without requiring online interaction. However, offline
policy optimization that maximizes overall expected rewards can unintentionally
amplify the reward disparities across groups. As a result, some groups might
benefit more than others from the learned policy, raising concerns about
fairness, especially when the resources are limited. In this paper, we study a
group-sensitive fairness constraint in offline contextual bandits, reducing
group-wise reward disparities that may arise during policy learning. We tackle
the following common-parity requirements: the reward disparity is constrained
within some user-defined threshold or the reward disparity should be minimized
during policy optimization. We propose a constrained offline policy
optimization framework by introducing group-wise reward disparity constraints
into an off-policy gradient-based optimization procedure. To improve the
estimation of the group-wise reward disparity during training, we employ a
doubly robust estimator and further provide a convergence guarantee for policy
optimization. Empirical results in synthetic and real-world datasets
demonstrate that our method effectively reduces reward disparities while
maintaining competitive overall performance.

</details>


### [49] [AI Agents in Drug Discovery](https://arxiv.org/abs/2510.27130)
*Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth*

Main category: cs.LG

TL;DR: 本文综述了基于大语言模型的智能AI代理在药物发现中的应用，展示了这些系统如何通过自主推理、行动和学习来加速药物研发流程。


<details>
  <summary>Details</summary>
Motivation: 药物发现过程复杂耗时，需要整合多种生物医学数据并执行大量实验。智能AI代理有望通过自主工作流大幅提升药物研发的效率和可扩展性。

Method: 采用基于大语言模型的智能AI架构，结合感知、计算、行动和记忆工具，包括ReAct、Reflection、Supervisor和Swarm等系统架构。

Result: 早期实施显示在速度、可重复性和可扩展性方面取得显著进展，将原本需要数月的工作流程压缩到数小时，同时保持科学可追溯性。

Conclusion: 智能AI代理在药物发现中展现出巨大潜力，但仍面临数据异质性、系统可靠性、隐私和基准测试等挑战，需要进一步发展以支持科学研究和转化应用。

Abstract: Artificial intelligence (AI) agents are emerging as transformative tools in
drug discovery, with the ability to autonomously reason, act, and learn through
complicated research workflows. Building on large language models (LLMs)
coupled with perception, computation, action, and memory tools, these agentic
AI systems could integrate diverse biomedical data, execute tasks, carry out
experiments via robotic platforms, and iteratively refine hypotheses in closed
loops. We provide a conceptual and technical overview of agentic AI
architectures, ranging from ReAct and Reflection to Supervisor and Swarm
systems, and illustrate their applications across key stages of drug discovery,
including literature synthesis, toxicity prediction, automated protocol
generation, small-molecule synthesis, drug repurposing, and end-to-end
decision-making. To our knowledge, this represents the first comprehensive work
to present real-world implementations and quantifiable impacts of agentic AI
systems deployed in operational drug discovery settings. Early implementations
demonstrate substantial gains in speed, reproducibility, and scalability,
compressing workflows that once took months into hours while maintaining
scientific traceability. We discuss the current challenges related to data
heterogeneity, system reliability, privacy, and benchmarking, and outline
future directions towards technology in support of science and translation.

</details>


### [50] [Exploring the Utilities of the Rationales from Large Language Models to Enhance Automated Essay Scoring](https://arxiv.org/abs/2510.27131)
*Hong Jiao,Hanna Choi,Haowei Hua*

Main category: cs.LG

TL;DR: 该研究比较了GPT-4.1和GPT-5生成的rationales在自动评分中的效用，发现基于essay的评分通常优于基于rationale的评分，但rationale评分在类别不平衡的分数0上表现更好。集成模型能显著提高评分准确性。


<details>
  <summary>Details</summary>
Motivation: 探索GPT-4.1和GPT-5生成的rationales在自动评分中的实际效用，比较基于essay和基于rationale的评分方法的性能差异。

Method: 使用2012年Kaggle ASAP数据中的Prompt 6 essays，比较essay-based评分与rationale-based评分，并采用集成建模方法结合不同评分模型。

Result: essay-based评分在QWK指标上表现更好，但rationale-based评分在类别不平衡的分数0上F1分数更高。集成essay-based和两个rationale-based评分模型获得了最佳QWK 0.870，优于文献报告的0.848。

Conclusion: rationales在自动评分中具有一定效用，特别是在处理类别不平衡问题时。集成多种评分方法可以显著提高评分准确性，达到最先进的性能水平。

Abstract: This study explored the utilities of rationales generated by GPT-4.1 and
GPT-5 in automated scoring using Prompt 6 essays from the 2012 Kaggle ASAP
data. Essay-based scoring was compared with rationale-based scoring. The study
found in general essay-based scoring performed better than rationale-based
scoring with higher Quadratic Weighted Kappa (QWK). However, rationale-based
scoring led to higher scoring accuracy in terms of F1 scores for score 0 which
had less representation due to class imbalance issues. The ensemble modeling of
essay-based scoring models increased the scoring accuracy at both specific
score levels and across all score levels. The ensemble modeling of essay-based
scoring and each of the rationale-based scoring performed about the same.
Further ensemble of essay-based scoring and both rationale-based scoring
yielded the best scoring accuracy with QWK of 0.870 compared with 0.848
reported in literature.

</details>


### [51] [FairAD: Computationally Efficient Fair Graph Clustering via Algebraic Distance](https://arxiv.org/abs/2510.27136)
*Minh Phu Vuong,Young-Ju Lee,Iván Ojeda-Ruiz,Chul-Ho Lee*

Main category: cs.LG

TL;DR: FairAD是一种高效的公平图聚类方法，通过代数距离构建亲和矩阵并施加公平约束，在保持聚类质量的同时显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 由于机器学习模型对某些人口群体的偏见行为日益受到关注，公平性成为重要研究课题，特别是在图聚类中需要考虑公平约束

Method: 首先基于代数距离构建亲和矩阵并施加公平约束，然后进行图粗化过程找到代表节点，最后求解约束最小化问题获得公平聚类解

Result: 在修改的随机块模型和六个公共数据集上的实验表明，FairAD能够实现公平聚类，同时比最先进的公平图聚类算法快达40倍

Conclusion: FairAD提供了一种计算高效的公平图聚类解决方案，在保持公平性的同时显著提升了算法效率

Abstract: Due to the growing concern about unsavory behaviors of machine learning
models toward certain demographic groups, the notion of 'fairness' has recently
drawn much attention from the community, thereby motivating the study of
fairness in graph clustering. Fair graph clustering aims to partition the set
of nodes in a graph into $k$ disjoint clusters such that the proportion of each
protected group within each cluster is consistent with the proportion of that
group in the entire dataset. It is, however, computationally challenging to
incorporate fairness constraints into existing graph clustering algorithms,
particularly for large graphs. To address this problem, we propose FairAD, a
computationally efficient fair graph clustering method. It first constructs a
new affinity matrix based on the notion of algebraic distance such that
fairness constraints are imposed. A graph coarsening process is then performed
on this affinity matrix to find representative nodes that correspond to $k$
clusters. Finally, a constrained minimization problem is solved to obtain the
solution of fair clustering. Experiment results on the modified stochastic
block model and six public datasets show that FairAD can achieve fair
clustering while being up to 40 times faster compared to state-of-the-art fair
graph clustering algorithms.

</details>


### [52] [Relation-Aware Bayesian Optimization of DBMS Configurations Guided by Affinity Scores](https://arxiv.org/abs/2510.27145)
*Sein Kwon,Seulgi Baek,Hyunseo Yang,Youngwan Jo,Sanghyun Park*

Main category: cs.LG

TL;DR: RelTune是一个新颖的数据库参数调优框架，通过关系图表示参数依赖关系，使用GNN学习性能相关语义嵌入，并引入混合分数引导的贝叶斯优化方法，在多个DBMS和工作负载上实现了比传统方法更快的收敛和更高的优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有数据库参数自动调优方法存在三个主要问题：忽略参数间的依赖关系、仅优化少数参数而忽略其他有意义的参数、贝叶斯优化依赖代理模型导致预测不稳定和探索效率低。

Method: 提出RelTune框架：1）将参数依赖表示为关系图，使用GNN学习性能相关语义的潜在嵌入；2）引入混合分数引导的贝叶斯优化（HBO），结合代理模型预测和亲和分数（衡量与先前高性能配置的接近程度）。

Result: 在多个DBMS和工作负载上的实验结果表明，RelTune比传统的基于贝叶斯优化的方法收敛更快、优化效率更高，在所有评估场景中都达到了最先进的性能。

Conclusion: RelTune通过建模参数依赖关系和引入混合分数引导机制，有效解决了现有数据库参数调优方法的局限性，实现了更高效和稳定的性能优化。

Abstract: Database Management Systems (DBMSs) are fundamental for managing large-scale
and heterogeneous data, and their performance is critically influenced by
configuration parameters. Effective tuning of these parameters is essential for
adapting to diverse workloads and maximizing throughput while minimizing
latency. Recent research has focused on automated configuration optimization
using machine learning; however, existing approaches still exhibit several key
limitations. Most tuning frameworks disregard the dependencies among
parameters, assuming that each operates independently. This simplification
prevents optimizers from leveraging relational effects across parameters,
limiting their capacity to capture performancesensitive interactions. Moreover,
to reduce the complexity of the high-dimensional search space, prior work often
selects only the top few parameters for optimization, overlooking others that
contribute meaningfully to performance. Bayesian Optimization (BO), the most
common method for automatic tuning, is also constrained by its reliance on
surrogate models, which can lead to unstable predictions and inefficient
exploration. To overcome these limitations, we propose RelTune, a novel
framework that represents parameter dependencies as a Relational Graph and
learns GNN-based latent embeddings that encode performancerelevant semantics.
RelTune further introduces Hybrid-Score-Guided Bayesian Optimization (HBO),
which combines surrogate predictions with an Affinity Score measuring proximity
to previously high-performing configurations. Experimental results on multiple
DBMSs and workloads demonstrate that RelTune achieves faster convergence and
higher optimization efficiency than conventional BO-based methods, achieving
state-of-the-art performance across all evaluated scenarios.

</details>


### [53] [Exploring Landscapes for Better Minima along Valleys](https://arxiv.org/abs/2510.27153)
*Tong Zhao,Jiacheng Li,Yuanchang Zhou,Guangming Tan,Weile Jia*

Main category: cs.LG

TL;DR: 提出了一种名为"E"的适配器，用于梯度优化器，使其在达到局部最小值后继续探索损失景观中的山谷区域，以寻找更好的局部最小值，从而提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习需要找到更低且泛化能力更好的最小值，但现有优化器一旦达到局部最小值就停止搜索，无法保证找到最优解。

Method: 为梯度优化器添加适配器"E"，使其在达到局部最小值后继续沿着损失景观的山谷区域进行探索。

Result: 在大型批次训练中，改进后的Lamb优化器（ALTO）将当前最先进优化器的测试准确率平均提高了2.5%。

Conclusion: 该方法为优化算法设计开辟了新的研究方向，能够有效提高模型泛化能力。

Abstract: Finding lower and better-generalizing minima is crucial for deep learning.
However, most existing optimizers stop searching the parameter space once they
reach a local minimum. Given the complex geometric properties of the loss
landscape, it is difficult to guarantee that such a point is the lowest or
provides the best generalization. To address this, we propose an adaptor "E"
for gradient-based optimizers. The adapted optimizer tends to continue
exploring along landscape valleys (areas with low and nearly identical losses)
in order to search for potentially better local minima even after reaching a
local minimum. This approach increases the likelihood of finding a lower and
flatter local minimum, which is often associated with better generalization. We
also provide a proof of convergence for the adapted optimizers in both convex
and non-convex scenarios for completeness. Finally, we demonstrate their
effectiveness in an important but notoriously difficult training scenario,
large-batch training, where Lamb is the benchmark optimizer. Our testing
results show that the adapted Lamb, ALTO, increases the test accuracy
(generalization) of the current state-of-the-art optimizer by an average of
2.5% across a variety of large-batch training tasks. This work potentially
opens a new research direction in the design of optimization algorithms.

</details>


### [54] [Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](https://arxiv.org/abs/2510.27172)
*Zixuan Hu,Li Shen,Zhenyi Wang,Yongxian Wei,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出了贝叶斯数据调度器（BDS），一种无需攻击模拟的自适应防御策略，通过贝叶斯推理学习数据点的安全属性后验分布，在微调过程中约束有害数据的影响。


<details>
  <summary>Details</summary>
Motivation: 现有防御策略通过攻击模拟构建鲁棒性，但存在根本局限性：无法预测未知攻击，且难以适应变化的攻击设置。有害微调对大型语言模型的微调即服务构成关键安全风险。

Method: 将有害微调防御建模为贝叶斯推理问题，学习每个数据点安全属性的后验分布。基于后验采样的安全属性对数据进行加权，约束微调过程。引入基于摊销贝叶斯学习的神经调度器，实现高效迁移。

Result: 在多种攻击和防御设置下的综合结果表明，该方法达到了最先进的性能。

Conclusion: BDS通过贝叶斯推理实现了自适应防御，无需攻击模拟即可有效缓解有害微调的安全风险，并在各种设置下表现出色。

Abstract: Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service
for large language models. Existing defense strategies preemptively build
robustness via attack simulation but suffer from fundamental limitations: (i)
the infeasibility of extending attack simulations beyond bounded threat models
due to the inherent difficulty of anticipating unknown attacks, and (ii)
limited adaptability to varying attack settings, as simulation fails to capture
their variability and complexity. To address these challenges, we propose
Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with
no need for attack simulation. BDS formulates harmful fine-tuning defense as a
Bayesian inference problem, learning the posterior distribution of each data
point's safety attribute, conditioned on the fine-tuning and alignment
datasets. The fine-tuning process is then constrained by weighting data with
their safety attributes sampled from the posterior, thus mitigating the
influence of harmful data. By leveraging the post hoc nature of Bayesian
inference, the posterior is conditioned on the fine-tuning dataset, enabling
BDS to tailor its defense to the specific dataset, thereby achieving adaptive
defense. Furthermore, we introduce a neural scheduler based on amortized
Bayesian learning, enabling efficient transfer to new data without retraining.
Comprehensive results across diverse attack and defense settings demonstrate
the state-of-the-art performance of our approach. Code is available at
https://github.com/Egg-Hu/Bayesian-Data-Scheduler.

</details>


### [55] [A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions](https://arxiv.org/abs/2510.27177)
*Junfan Li,Shizhong Liao,Zenglin Xu,Liqiang Nie*

Main category: cs.LG

TL;DR: 提出了一种新的多项式时间算法，显著改进了在线稀疏线性回归（OSLR）问题在兼容性条件下的遗憾边界，该算法使用Dantzig选择器并结合多种新技术。


<details>
  <summary>Details</summary>
Motivation: 研究在线稀疏线性回归问题，其中算法每实例只能访问k个属性进行预测，该问题已被证明是NP难问题。先前工作需要在数据矩阵满足特定假设条件下才能给出多项式时间算法。

Method: 基于Dantzig选择器，开发了包含算法依赖的协方差矩阵采样方案、自适应参数调优方案、以及带仔细初始化的批处理在线牛顿步等新技术。

Result: 在兼容性条件下显著改进了先前的遗憾边界，改进源于对估计器ℓ1范数误差的更紧收敛率分析。

Conclusion: 提出的算法在较弱假设下实现了更好的性能，并成功扩展到带额外观测的OSLR问题，进一步改进了相关遗憾边界。

Abstract: In this paper, we study the problem of online sparse linear regression (OSLR)
where the algorithms are restricted to accessing only $k$ out of $d$ attributes
per instance for prediction, which was proved to be NP-hard. Previous work gave
polynomial-time algorithms assuming the data matrix satisfies the linear
independence of features, the compatibility condition, or the restricted
isometry property. We introduce a new polynomial-time algorithm, which
significantly improves previous regret bounds (Ito et al., 2017) under the
compatibility condition that is weaker than the other two assumptions. The
improvements benefit from a tighter convergence rate of the $\ell_1$-norm error
of our estimators. Our algorithm leverages the well-studied Dantzig Selector,
but importantly with several novel techniques, including an algorithm-dependent
sampling scheme for estimating the covariance matrix, an adaptive parameter
tuning scheme, and a batching online Newton step with careful initializations.
We also give novel and non-trivial analyses, including an induction method for
analyzing the $\ell_1$-norm error, careful analyses on the covariance of
non-independent random variables, and a decomposition on the regret. We further
extend our algorithm to OSLR with additional observations where the algorithms
can observe additional $k_0$ attributes after each prediction, and improve
previous regret bounds (Kale et al., 2017; Ito et al., 2017).

</details>


### [56] [SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference](https://arxiv.org/abs/2510.27182)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.LG

TL;DR: SERFLOW通过动态卸载机器学习模型分区到FaaS和IaaS服务，结合阶段特定资源供应和自适应负载均衡，在动态工作负载下降低云成本超过23%。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了虚拟机冷启动、长尾服务时间分布等现实因素，无法适应输入依赖的退出率变化，导致资源利用率低下或无法快速扩展处理深层请求。

Method: 将ML查询建模为遍历无环阶段序列，每个阶段包含稀疏模型参数块，在内部或最终分类器处可能退出。利用FaaS无服务器函数和阶段特定资源供应，结合基于请求摄入的自适应负载均衡。

Result: SERFLOW能够有效适应动态工作负载，将云成本降低超过23%，同时提高资源利用效率。

Conclusion: 通过整合阶段特定资源供应和自适应负载均衡，SERFLOW解决了现实世界中的资源管理挑战，为自适应推理应用提供了高效且成本优化的解决方案。

Abstract: Dynamic offloading of Machine Learning (ML) model partitions across different
resource orchestration services, such as Function-as-a-Service (FaaS) and
Infrastructure-as-a-Service (IaaS), can balance processing and transmission
delays while minimizing costs of adaptive inference applications. However,
prior work often overlooks real-world factors, such as Virtual Machine (VM)
cold starts, requests under long-tail service time distributions, etc. To
tackle these limitations, we model each ML query (request) as traversing an
acyclic sequence of stages, wherein each stage constitutes a contiguous block
of sparse model parameters ending in an internal or final classifier where
requests may exit. Since input-dependent exit rates vary, no single resource
configuration suits all query distributions. IaaS-based VMs become
underutilized when many requests exit early, yet rapidly scaling to handle
request bursts reaching deep layers is impractical. SERFLOW addresses this
challenge by leveraging FaaS-based serverless functions (containers) and using
stage-specific resource provisioning that accounts for the fraction of requests
exiting at each stage. By integrating this provisioning with adaptive load
balancing across VMs and serverless functions based on request ingestion,
SERFLOW reduces cloud costs by over $23\%$ while efficiently adapting to
dynamic workloads.

</details>


### [57] [MDAS-GNN: Multi-Dimensional Spatiotemporal GNN with Spatial Diffusion for Urban Traffic Risk Forecasting](https://arxiv.org/abs/2510.27197)
*Ziyuan Gao*

Main category: cs.LG

TL;DR: MDAS-GNN是一种基于多维注意力的空间扩散图神经网络，用于交通事故预测，通过整合交通安全、基础设施和环境风险三个核心维度，在多个英国城市数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统事故预测模型将路段视为独立单元，无法捕捉城市交通网络中的复杂空间关系和时间依赖性，导致预测准确性有限。

Method: 采用特征特定的空间扩散机制和多头时间注意力，捕捉不同时间跨度上的依赖关系，整合交通安全、基础设施和环境风险三个维度。

Result: 在英国交通部三个城市数据上的评估显示，MDAS-GNN相比基线方法表现更优，在短、中、长期预测中均保持低误差，长期预测表现尤其突出。消融研究证实多维特征集成比单特征方法减少预测误差达40%。

Conclusion: 该框架为土木工程师和城市规划者提供了先进的预测能力，支持数据驱动的道路网络优化、基础设施改进和城市发展项目中的安全干预决策。

Abstract: Traffic accidents represent a critical public health challenge, claiming over
1.35 million lives annually worldwide. Traditional accident prediction models
treat road segments independently, failing to capture complex spatial
relationships and temporal dependencies in urban transportation networks. This
study develops MDAS-GNN, a Multi-Dimensional Attention-based Spatial-diffusion
Graph Neural Network integrating three core risk dimensions: traffic safety,
infrastructure, and environmental risk. The framework employs feature-specific
spatial diffusion mechanisms and multi-head temporal attention to capture
dependencies across different time horizons. Evaluated on UK Department for
Transport accident data across Central London, South Manchester, and SE
Birmingham, MDASGNN achieves superior performance compared to established
baseline methods. The model maintains consistently low prediction errors across
short, medium, and long-term periods, with particular strength in long-term
forecasting. Ablation studies confirm that integrated multi-dimensional
features outperform singlefeature approaches, reducing prediction errors by up
to 40%. This framework provides civil engineers and urban planners with
advanced predictive capabilities for transportation infrastructure design,
enabling data-driven decisions for road network optimization, infrastructure
resource improvements, and strategic safety interventions in urban development
projects.

</details>


### [58] [Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models](https://arxiv.org/abs/2510.27207)
*Hamed Najafi,Dongsheng Luo,Jason Liu*

Main category: cs.LG

TL;DR: FFCA是一个新的可解释AI框架，通过分析模型学习函数的几何特性，为每个特征生成4维签名（影响力、波动性、非线性、交互性），并提供动态原型分析来追踪训练过程中的特征演化。


<details>
  <summary>Details</summary>
Motivation: 主流归因方法通常只提供模型最终状态的静态视图，将特征作用简化为单一分数，无法处理非线性和交互效应，需要更完整的几何分析框架。

Method: 引入特征-函数曲率分析（FFCA），量化特征的4个几何属性，并扩展到动态原型分析来追踪训练过程中的特征演化。

Result: 首次直接实证证明了分层学习现象（模型先学习简单线性效应再学习复杂交互），并为识别模型容量不足和预测过拟合提供了新的诊断工具。

Conclusion: FFCA通过其静态和动态组件，为模型解释提供了必要的几何背景，将解释从简单量化转变为对整个学习过程的细致可信分析。

Abstract: Explainable AI (XAI) is critical for building trust in complex machine
learning models, yet mainstream attribution methods often provide an
incomplete, static picture of a model's final state. By collapsing a feature's
role into a single score, they are confounded by non-linearity and
interactions. To address this, we introduce Feature-Function Curvature Analysis
(FFCA), a novel framework that analyzes the geometry of a model's learned
function. FFCA produces a 4-dimensional signature for each feature, quantifying
its: (1) Impact, (2) Volatility, (3) Non-linearity, and (4) Interaction.
Crucially, we extend this framework into Dynamic Archetype Analysis, which
tracks the evolution of these signatures throughout the training process. This
temporal view moves beyond explaining what a model learned to revealing how it
learns. We provide the first direct, empirical evidence of hierarchical
learning, showing that models consistently learn simple linear effects before
complex interactions. Furthermore, this dynamic analysis provides novel,
practical diagnostics for identifying insufficient model capacity and
predicting the onset of overfitting. Our comprehensive experiments demonstrate
that FFCA, through its static and dynamic components, provides the essential
geometric context that transforms model explanation from simple quantification
to a nuanced, trustworthy analysis of the entire learning process.

</details>


### [59] [Soft Task-Aware Routing of Experts for Equivariant Representation Learning](https://arxiv.org/abs/2510.27222)
*Jaebyeong Jeon,Hyeonseo Jang,Jy-yong Sohn,Kibok Lee*

Main category: cs.LG

TL;DR: 提出了Soft Task-Aware Routing (STAR)方法，通过将投影头建模为专家来减少不变性和等变性表示学习中的冗余特征学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用分离的投影头联合学习不变性和等变性表示，但忽视了两种学习之间共享的信息，导致冗余特征学习和模型容量利用效率低下。

Method: 引入STAR路由策略，将投影头建模为专家，使其专门捕获共享或任务特定信息，从而减少冗余特征学习。

Result: 实验显示在不变性和等变性嵌入之间具有较低的正则相关性，并在多样化的迁移学习任务中取得一致改进。

Conclusion: STAR方法通过专家路由策略有效减少冗余特征学习，提高了表示学习的效率和下游任务性能。

Abstract: Equivariant representation learning aims to capture variations induced by
input transformations in the representation space, whereas invariant
representation learning encodes semantic information by disregarding such
transformations. Recent studies have shown that jointly learning both types of
representations is often beneficial for downstream tasks, typically by
employing separate projection heads. However, this design overlooks information
shared between invariant and equivariant learning, which leads to redundant
feature learning and inefficient use of model capacity. To address this, we
introduce Soft Task-Aware Routing (STAR), a routing strategy for projection
heads that models them as experts. STAR induces the experts to specialize in
capturing either shared or task-specific information, thereby reducing
redundant feature learning. We validate this effect by observing lower
canonical correlations between invariant and equivariant embeddings.
Experimental results show consistent improvements across diverse transfer
learning tasks. The code is available at https://github.com/YonseiML/star.

</details>


### [60] [FedSM: Robust Semantics-Guided Feature Mixup for Bias Reduction in Federated Learning with Long-Tail Data](https://arxiv.org/abs/2510.27240)
*Jingrui Zhang,Yimeng Xu,Shujie Li,Feng Liang,Haihan Duan,Yanjie Dong,Victor C. M. Leung,Xiping Hu*

Main category: cs.LG

TL;DR: FedSM是一个面向客户端的联邦学习框架，通过语义引导的特征混合和轻量级分类器重训练，解决非独立同分布和长尾数据分布导致的全局模型偏差问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在非独立同分布和长尾数据分布下会产生有偏的全局模型，需要解决这一偏差问题。

Method: 使用预训练的图文对齐模型计算类别级语义相关性，指导本地特征与全局原型的类别选择混合，生成类别一致的伪特征，并通过概率类别选择增强特征多样性。

Result: 在多个长尾数据集上的实验表明，FedSM在准确率上持续优于最先进方法，对领域偏移具有高鲁棒性且计算效率高。

Conclusion: FedSM通过语义引导的特征混合有效缓解了联邦学习中的模型偏差问题，所有计算在本地执行，服务器开销最小。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized clients without sharing private data. However, FL suffers from
biased global models due to non-IID and long-tail data distributions. We
propose \textbf{FedSM}, a novel client-centric framework that mitigates this
bias through semantics-guided feature mixup and lightweight classifier
retraining. FedSM uses a pretrained image-text-aligned model to compute
category-level semantic relevance, guiding the category selection of local
features to mix-up with global prototypes to generate class-consistent
pseudo-features. These features correct classifier bias, especially when data
are heavily skewed. To address the concern of potential domain shift between
the pretrained model and the data, we propose probabilistic category selection,
enhancing feature diversity to effectively mitigate biases. All computations
are performed locally, requiring minimal server overhead. Extensive experiments
on long-tail datasets with various imbalanced levels demonstrate that FedSM
consistently outperforms state-of-the-art methods in accuracy, with high
robustness to domain shift and computational efficiency.

</details>


### [61] [Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation](https://arxiv.org/abs/2510.27253)
*Qiyan Deng,Changqian Zheng,Lianpeng Qiao,Yuping Wang,Chengliang Chai,Lei Cao*

Main category: cs.LG

TL;DR: 提出IWD框架，通过影响函数在数据集蒸馏中考虑数据质量，自适应加权实例，提升蒸馏数据集质量和模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法假设所有实例贡献相等，但真实数据集包含信息丰富和冗余/有害实例，直接蒸馏会降低模型性能

Method: IWD框架利用影响函数为每个实例分配自适应权重，基于其对蒸馏目标的影响，优先有益数据，降低无用或有害数据权重

Result: IWD能提升蒸馏数据集质量，增强模型性能，准确率提升最高达7.8%，且能无缝集成到多种蒸馏框架

Conclusion: IWD通过考虑数据质量的数据集蒸馏方法，有效提升了蒸馏效率和模型性能

Abstract: Dataset distillation condenses large datasets into synthetic subsets,
achieving performance comparable to training on the full dataset while
substantially reducing storage and computation costs. Most existing dataset
distillation methods assume that all real instances contribute equally to the
process. In practice, real-world datasets contain both informative and
redundant or even harmful instances, and directly distilling the full dataset
without considering data quality can degrade model performance. In this work,
we present Influence-Weighted Distillation IWD, a principled framework that
leverages influence functions to explicitly account for data quality in the
distillation process. IWD assigns adaptive weights to each instance based on
its estimated impact on the distillation objective, prioritizing beneficial
data while downweighting less useful or harmful ones. Owing to its modular
design, IWD can be seamlessly integrated into diverse dataset distillation
frameworks. Our empirical results suggest that integrating IWD tends to improve
the quality of distilled datasets and enhance model performance, with accuracy
gains of up to 7.8%.

</details>


### [62] [ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models](https://arxiv.org/abs/2510.27256)
*Xin Tang,Youfang Han,Fangfei Gou,Wei Zhao,Xin Meng,Yang Yu,Jinguo Zhang,Yuanchun Shi,Yuntao Wang,Tengxiang Zhang*

Main category: cs.LG

TL;DR: 提出了ECVL-ROUTER，首个面向视觉语言模型的场景感知路由框架，通过动态选择合适模型来平衡响应速度、输出质量和能耗。


<details>
  <summary>Details</summary>
Motivation: 用户需求在不同场景下差异很大，包括快速响应、高质量输出和低能耗。仅依赖云端大模型会导致高延迟和高能耗，而边缘小模型能处理简单任务但能力有限。

Method: 引入新的路由策略和评估指标，根据用户需求动态选择合适模型，并构建了专门用于路由器训练的多模态响应质量数据集。

Result: 实验表明，该方法成功将超过80%的查询路由到小模型，同时问题解决概率下降不到10%。

Conclusion: ECVL-ROUTER框架有效结合了大模型和小模型的优势，在保证性能的同时显著降低了延迟和能耗。

Abstract: Vision-Language Models (VLMs) excel in diverse multimodal tasks. However,
user requirements vary across scenarios, which can be categorized into fast
response, high-quality output, and low energy consumption. Relying solely on
large models deployed in the cloud for all queries often leads to high latency
and energy cost, while small models deployed on edge devices are capable of
handling simpler tasks with low latency and energy cost. To fully leverage the
strengths of both large and small models, we propose ECVL-ROUTER, the first
scenario-aware routing framework for VLMs. Our approach introduces a new
routing strategy and evaluation metrics that dynamically select the appropriate
model for each query based on user requirements, maximizing overall utility. We
also construct a multimodal response-quality dataset tailored for router
training and validate the approach through extensive experiments. Results show
that our approach successfully routes over 80\% of queries to the small model
while incurring less than 10\% drop in problem solving probability.

</details>


### [63] [Higher-order Linear Attention](https://arxiv.org/abs/2510.27258)
*Yifan Zhang,Zhen Qin,Quanquan Gu*

Main category: cs.LG

TL;DR: 提出了高阶线性注意力（HLA），一种线性时间、因果的注意力机制，通过紧凑的前缀充分统计实现高阶交互，解决了传统注意力二次计算成本的问题。


<details>
  <summary>Details</summary>
Motivation: 传统缩放点积注意力的二次计算成本限制了自回归语言模型扩展到长上下文的能力，而现有的线性时间注意力和状态空间模型通常限制在一阶或基于核的近似，限制了表达能力。

Method: HLA使用紧凑前缀充分统计实现高阶交互，在二阶情况下保持恒定大小状态并以线性时间计算每个token输出，无需生成n×n矩阵。提供了闭式流式恒等式、严格因果掩码变体和基于关联扫描的块并行训练方案。

Result: HLA实现了线性时间复杂度的注意力机制，能够精确复现串行循环的激活，同时保持数据依赖的混合能力。

Conclusion: HLA作为一个原则性、可扩展的构建块，将注意力式的数据依赖混合与现代循环架构的效率相结合，为长上下文建模提供了有效解决方案。

Abstract: The quadratic cost of scaled dot-product attention is a central obstacle to
scaling autoregressive language models to long contexts. Linear-time attention
and State Space Models (SSMs) provide scalable alternatives but are typically
restricted to first-order or kernel-based approximations, which can limit
expressivity. We introduce Higher-order Linear Attention (HLA), a causal,
streaming mechanism that realizes higher interactions via compact prefix
sufficient statistics. In the second-order case, HLA maintains a constant-size
state and computes per-token outputs in linear time without materializing any
$n \times n$ matrices. We give closed-form streaming identities, a strictly
causal masked variant using two additional summaries, and a chunk-parallel
training scheme based on associative scans that reproduces the activations of a
serial recurrence exactly. We further outline extensions to third and higher
orders. Collectively, these results position HLA as a principled, scalable
building block that combines attention-like, data-dependent mixing with the
efficiency of modern recurrent architectures. Project Page:
https://github.com/yifanzhang-pro/HLA.

</details>


### [64] [ODP-Bench: Benchmarking Out-of-Distribution Performance Prediction](https://arxiv.org/abs/2510.27263)
*Han Yu,Kehan Li,Dongbai Li,Yue He,Xingxuan Zhang,Peng Cui*

Main category: cs.LG

TL;DR: 提出了ODP-Bench基准，用于统一评估OOD性能预测算法，包含常用OOD数据集和现有算法，提供预训练模型确保比较一致性。


<details>
  <summary>Details</summary>
Motivation: 现有OOD性能预测研究评估协议不一致，覆盖的数据集和分布偏移类型有限，需要公平便捷的比较基准。

Method: 构建综合性基准ODP-Bench，整合常用OOD数据集和实用性能预测算法，提供预训练模型作为测试平台。

Result: 建立了统一的评估基准，避免了重复训练模型的负担，并通过深入实验分析了解算法的能力边界。

Conclusion: ODP-Bench为OOD性能预测研究提供了公平比较的基础，有助于更好地理解和部署现成训练模型。

Abstract: Recently, there has been gradually more attention paid to Out-of-Distribution
(OOD) performance prediction, whose goal is to predict the performance of
trained models on unlabeled OOD test datasets, so that we could better leverage
and deploy off-the-shelf trained models in risk-sensitive scenarios. Although
progress has been made in this area, evaluation protocols in previous
literature are inconsistent, and most works cover only a limited number of
real-world OOD datasets and types of distribution shifts. To provide convenient
and fair comparisons for various algorithms, we propose Out-of-Distribution
Performance Prediction Benchmark (ODP-Bench), a comprehensive benchmark that
includes most commonly used OOD datasets and existing practical performance
prediction algorithms. We provide our trained models as a testbench for future
researchers, thus guaranteeing the consistency of comparison and avoiding the
burden of repeating the model training process. Furthermore, we also conduct
in-depth experimental analyses to better understand their capability boundary.

</details>


### [65] [HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction](https://arxiv.org/abs/2510.27281)
*Minghui Li,Yuanhang Wang,Peijin Guo,Wei Wan,Shengshan Hu,Shengqing Hu*

Main category: cs.LG

TL;DR: HiF-DTA是一个用于药物-靶点亲和力预测的分层网络，采用双路径策略提取药物和蛋白质的全局序列语义和局部拓扑特征，并通过多尺度融合模块整合原子、亚结构和分子级别的表示。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列的深度学习方法忽视了同时建模全局序列语义特征和局部拓扑结构特征，且将药物表示为扁平序列而缺乏多尺度特征。

Method: 采用双路径策略提取药物和蛋白质的全局序列语义和局部拓扑特征，通过多尺度双线性注意力模块融合原子、亚结构和分子级别的表示。

Result: 在Davis、KIBA和Metz数据集上的实验表明，HiF-DTA优于现有最先进基线方法，消融实验证实了全局-局部特征提取和多尺度融合的重要性。

Conclusion: HiF-DTA通过同时建模全局序列语义和局部拓扑特征，并结合多尺度药物表示，有效提升了药物-靶点亲和力预测的准确性。

Abstract: Accurate prediction of Drug-Target Affinity (DTA) is crucial for reducing
experimental costs and accelerating early screening in computational drug
discovery. While sequence-based deep learning methods avoid reliance on costly
3D structures, they still overlook simultaneous modeling of global sequence
semantic features and local topological structural features within drugs and
proteins, and represent drugs as flat sequences without atomic-level,
substructural-level, and molecular-level multi-scale features. We propose
HiF-DTA, a hierarchical network that adopts a dual-pathway strategy to extract
both global sequence semantic and local topological features from drug and
protein sequences, and models drugs multi-scale to learn atomic, substructural,
and molecular representations fused via a multi-scale bilinear attention
module. Experiments on Davis, KIBA, and Metz datasets show HiF-DTA outperforms
state-of-the-art baselines, with ablations confirming the importance of
global-local extraction and multi-scale fusion.

</details>


### [66] [Can LLMs Help You at Work? A Sandbox for Evaluating LLM Agents in Enterprise Environments](https://arxiv.org/abs/2510.27287)
*Harsh Vishwakarma,Ankush Agarwal,Ojas Patil,Chaitanya Devaguptapu,Mahesh Chandran*

Main category: cs.LG

TL;DR: EnterpriseBench是一个模拟企业环境的综合基准测试，包含500个跨领域任务，用于评估LLM在企业系统中的表现，当前最佳模型仅完成41.8%的任务。


<details>
  <summary>Details</summary>
Motivation: 企业系统对提升员工和客户的生产力与决策能力至关重要，但将LLM集成到企业系统中面临数据碎片化和访问控制等复杂挑战。

Method: 开发了EnterpriseBench基准测试，模拟企业环境特征，包括数据源碎片化、访问控制层次和跨职能工作流，并提供从组织元数据生成内部一致任务的数据生成管道。

Result: 实验表明，即使是最先进的LLM代理也只能完成41.8%的任务，揭示了企业AI系统的显著改进空间。

Conclusion: EnterpriseBench为评估和改进企业环境中的LLM系统提供了重要基准，突显了当前模型在企业任务处理能力上的局限性。

Abstract: Enterprise systems are crucial for enhancing productivity and decision-making
among employees and customers. Integrating LLM based systems into enterprise
systems enables intelligent automation, personalized experiences, and efficient
information retrieval, driving operational efficiency and strategic growth.
However, developing and evaluating such systems is challenging due to the
inherent complexity of enterprise environments, where data is fragmented across
multiple sources and governed by sophisticated access controls. We present
EnterpriseBench, a comprehensive benchmark that simulates enterprise settings,
featuring 500 diverse tasks across software engineering, HR, finance, and
administrative domains. Our benchmark uniquely captures key enterprise
characteristics including data source fragmentation, access control
hierarchies, and cross-functional workflows. Additionally, we provide a novel
data generation pipeline that creates internally consistent enterprise tasks
from organizational metadata. Experiments with state-of-the-art LLM agents
demonstrate that even the most capable models achieve only 41.8% task
completion, highlighting significant opportunities for improvement in
enterprise-focused AI systems.

</details>


### [67] [Temporal Cardiovascular Dynamics for Improved PPG-Based Heart Rate Estimation](https://arxiv.org/abs/2510.27297)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 提出了一种基于互信息分析心率非线性混沌行为的新方法，结合深度学习显著提升了真实场景下的心率估计性能，相比传统方法提升达40%，减少了对多模态传感的依赖并无需后处理。


<details>
  <summary>Details</summary>
Motivation: 人类心率振荡具有复杂的非线性混沌特性，这给日常心血管健康监测带来了挑战，需要从数学角度解释和处理这种非线性时间复杂性。

Method: 通过互信息研究心率的非线性混沌行为，提出一种新颖的心率估计方法，该方法能够与深度学习解决方案结合使用。

Result: 在四个真实场景数据集上的验证表明，该方法相比传统方法和现有机器学习技术，心率估计性能提升高达40%，同时减少了对多传感模态的依赖并消除了后处理需求。

Conclusion: 提出的方法不仅从数学角度解释了心率的非线性复杂性，而且与深度学习结合后显著提升了心率估计性能，为日常心血管监测提供了更有效的解决方案。

Abstract: The oscillations of the human heart rate are inherently complex and
non-linear -- they are best described by mathematical chaos, and they present a
challenge when applied to the practical domain of cardiovascular health
monitoring in everyday life. In this work, we study the non-linear chaotic
behavior of heart rate through mutual information and introduce a novel
approach for enhancing heart rate estimation in real-life conditions. Our
proposed approach not only explains and handles the non-linear temporal
complexity from a mathematical perspective but also improves the deep learning
solutions when combined with them. We validate our proposed method on four
established datasets from real-life scenarios and compare its performance with
existing algorithms thoroughly with extensive ablation experiments. Our results
demonstrate a substantial improvement, up to 40\%, of the proposed approach in
estimating heart rate compared to traditional methods and existing
machine-learning techniques while reducing the reliance on multiple sensing
modalities and eliminating the need for post-processing steps.

</details>


### [68] [Binary Anomaly Detection in Streaming IoT Traffic under Concept Drift](https://arxiv.org/abs/2510.27304)
*Rodrigo Matos Carnier,Laura Lahesoo,Kensuke Fukuda*

Main category: cs.LG

TL;DR: 该研究比较了批处理和流式学习在IoT网络异常检测中的表现，发现流式学习方法能更好地处理概念漂移，且树基算法在计算效率和性能上具有优势。


<details>
  <summary>Details</summary>
Motivation: 随着IoT网络流量增长，传统批学习模型面临维护成本高、对概念漂移适应性差的问题，需要研究流式学习方法来提高异常检测的鲁棒性。

Method: 将异常检测建模为二分类问题，通过混合现有数据集模拟异构网络数据流，逐个样本流式处理，比较批处理和流式学习方法，并评估树基和非树基算法的性能。

Result: 自适应随机森林达到F1分数0.990±0.006，计算成本仅为批处理的三分之一；Hoeffding自适应树F1分数0.910±0.007，计算成本降低四倍，适合在线应用。

Conclusion: 流式学习能有效处理概念漂移，树基算法在IoT异常检测中具有计算效率和性能优势，但当前数据集在暴露模型局限性方面仍有不足。

Abstract: With the growing volume of Internet of Things (IoT) network traffic, machine
learning (ML)-based anomaly detection is more relevant than ever. Traditional
batch learning models face challenges such as high maintenance and poor
adaptability to rapid anomaly changes, known as concept drift. In contrast,
streaming learning integrates online and incremental learning, enabling
seamless updates and concept drift detection to improve robustness. This study
investigates anomaly detection in streaming IoT traffic as binary
classification, comparing batch and streaming learning approaches while
assessing the limitations of current IoT traffic datasets. We simulated
heterogeneous network data streams by carefully mixing existing datasets and
streaming the samples one by one. Our results highlight the failure of batch
models to handle concept drift, but also reveal persisting limitations of
current datasets to expose model limitations due to low traffic heterogeneity.
We also investigated the competitiveness of tree-based ML algorithms,
well-known in batch anomaly detection, and compared it to non-tree-based ones,
confirming the advantages of the former. Adaptive Random Forest achieved
F1-score of 0.990 $\pm$ 0.006 at one-third the computational cost of its batch
counterpart. Hoeffding Adaptive Tree reached F1-score of 0.910 $\pm$ 0.007,
reducing computational cost by four times, making it a viable choice for online
applications despite a slight trade-off in stability.

</details>


### [69] [Un-Attributability: Computing Novelty From Retrieval & Semantic Similarity](https://arxiv.org/abs/2510.27313)
*Philipp Davydov,Ameya Prabhu,Matthias Bethge,Elisa Nguyen,Seong Joon Oh*

Main category: cs.LG

TL;DR: 该论文提出了不可归因性作为语义新颖性的操作化度量，通过两阶段检索流程评估模型输出是否无法归因于预训练语料库中的任何示例，从而衡量语义新颖性。


<details>
  <summary>Details</summary>
Motivation: 传统训练数据归因方法关注哪些训练示例影响了特定输出，而本研究反向提问：哪些输出无法归因于任何预训练示例？旨在通过不可归因性来操作化定义语义新颖性。

Method: 使用两阶段检索流程：首先用轻量级GIST嵌入索引语料库并检索前n个候选，然后用ColBERTv2重新排序。如果最近语料项的可归因性低于人工生成的文本参考，则认为模型输出具有新颖性。

Result: 在SmolLM和SmolLM2上的评估显示：(1)模型利用预训练数据的跨度比之前报告的长得多；(2)某些领域系统性地促进或抑制新颖性；(3)指令微调不仅改变风格还增加新颖性。

Conclusion: 围绕不可归因性重新构建新颖性评估能够在预训练规模上实现高效分析，并发布了约20TB的语料块和索引工件以支持复现和大规模扩展分析。

Abstract: Understanding how language-model outputs relate to the pretraining corpus is
central to studying model behavior. Most training data attribution (TDA)
methods ask which training examples causally influence a given output, often
using leave-one-out tests. We invert the question: which outputs cannot be
attributed to any pretraining example? We introduce un-attributability as an
operational measure of semantic novelty: an output is novel if the pretraining
corpus contains no semantically similar context. We approximate this with a
simple two-stage retrieval pipeline: index the corpus with lightweight GIST
embeddings, retrieve the top-n candidates, then rerank with ColBERTv2. If the
nearest corpus item is less attributable than a human-generated text reference,
we consider the output of the model as novel. We evaluate on SmolLM and SmolLM2
and report three findings: (1) models draw on pretraining data across much
longer spans than previously reported; (2) some domains systematically promote
or suppress novelty; and (3) instruction tuning not only alters style but also
increases novelty. Reframing novelty assessment around un-attributability
enables efficient analysis at pretraining scale. We release ~20 TB of corpus
chunks and index artifacts to support replication and large-scale extension of
our analysis at https://huggingface.co/datasets/stai-tuebingen/faiss-smollm

</details>


### [70] [MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data](https://arxiv.org/abs/2510.27321)
*Yu-Chen Kuo,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: MedM2T是一个时间感知的多模态框架，用于处理医疗数据的多模态性和异质时间结构，在心血管疾病预测、院内死亡率预测和ICU住院时间回归任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医疗数据具有固有的多模态性和异质时间结构，这给建模带来了显著挑战。需要一种能够灵活处理不规则稀疏时间序列、捕捉多时间尺度模式并提取跨模态交互的框架。

Method: MedM2T集成了：(1)稀疏时间序列编码器处理不规则稀疏时间序列；(2)分层时间感知融合捕捉密集时间序列的微观和宏观时间模式；(3)双模态注意力提取跨模态交互；(4)使用模态特定的预训练编码器并对其特征进行对齐。

Result: 在MIMIC-IV和MIMIC-IV-ECG数据集上的评估显示：心血管疾病预测AUROC 0.947、AUPRC 0.706；院内死亡率预测AUROC 0.901、AUPRC 0.558；ICU住院时间回归MAE 2.31，均优于现有最先进方法。

Conclusion: MedM2T展现了强大的鲁棒性和广泛适用性，是临床预测中一个有前景的工具，其实现已在GitHub上开源。

Abstract: The inherent multimodality and heterogeneous temporal structures of medical
data pose significant challenges for modeling. We propose MedM2T, a time-aware
multimodal framework designed to address these complexities. MedM2T integrates:
(i) Sparse Time Series Encoder to flexibly handle irregular and sparse time
series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and
macro-temporal patterns from multiple dense time series, such as ECGs, and
(iii) Bi-Modal Attention to extract cross-modal interactions, which can be
extended to any number of modalities. To mitigate granularity gaps between
modalities, MedM2T uses modality-specific pre-trained encoders and aligns
resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and
MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease
dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality
prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed
state-of-the-art multimodal learning frameworks and existing time series
models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction;
an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean
Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the
robustness and broad applicability of MedM2T, positioning it as a promising
tool in clinical prediction. We provide the implementation of MedM2T at
https://github.com/DHLab-TSENG/MedM2T.

</details>


### [71] [Reasoning Models Sometimes Output Illegible Chains of Thought](https://arxiv.org/abs/2510.27338)
*Arun Jose*

Main category: cs.LG

TL;DR: 研究发现基于结果强化学习的语言模型在链式思维推理中会产生难以理解的过程，尽管最终答案可读，但推理过程不透明，这可能削弱监控效果。


<details>
  <summary>Details</summary>
Motivation: 监控语言模型的链式思维推理过程有助于理解其意图和检测恶意行为，但这要求推理过程清晰可读且忠实。

Method: 研究了14个推理模型的链式思维可读性，分析RL训练对推理过程可读性的影响，包括强制使用可读部分时的准确性变化。

Result: RL训练导致推理过程难以理解，模型使用不可读推理得出正确答案，准确性下降53%，可读性在更难问题上进一步恶化。

Conclusion: 如果没有明确优化可读性，基于结果的RL自然会产生推理过程不透明的模型，可能破坏监控方法的有效性。

Abstract: Language models trained via outcome-based reinforcement learning (RL) to
reason using chain-of-thought (CoT) have shown remarkable performance.
Monitoring such a model's CoT may allow us to understand its intentions and
detect potential malicious behavior. However, to be effective, this requires
that CoTs are legible and faithful. We study CoT legibility across 14 reasoning
models, finding that RL often causes reasoning to become illegible to both
humans and AI monitors, with reasoning models (except Claude) generating
illegible CoTs while returning to perfectly readable final answers. We show
that models use illegible reasoning to reach correct answers (accuracy dropping
by 53\% when forced to use only legible portions), yet find no correlation
between legibility and performance when resampling - suggesting the
relationship is more nuanced. We also find that legibility degrades on harder
questions. We discuss potential hypotheses for these results, including
steganography, training artifacts, and vestigial tokens. These results suggest
that without explicit optimization for legibility, outcome-based RL naturally
produces models with increasingly opaque reasoning processes, potentially
undermining monitoring approaches.

</details>


### [72] [Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity](https://arxiv.org/abs/2510.27378)
*Austin Meek,Eitan Sprejer,Iván Arcuschin,Austin J. Brockmeier,Steven Basart*

Main category: cs.LG

TL;DR: 该论文提出了监控性(monitorability)概念，结合忠实性(faithfulness)和详尽性(verbosity)来评估思维链(CoT)作为模型外部工作记忆的有效性，发现模型可能看似忠实但难以监控，且不同模型家族的监控性差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过模型在添加提示后改变答案的情况来评估思维链的忠实性，但这种方法在模型维持原答案时会丢失信息，且无法检查与提示无关的推理方面。需要更全面地评估思维链作为监控模型内部推理的窗口。

Method: 引入详尽性(verbosity)概念，即思维链是否列出解决任务所需的每个因素，并将其与忠实性结合形成统一的监控性评分。在BBH、GPQA和MMLU数据集上评估指令调优和推理模型。

Result: 研究表明模型可能看似忠实但难以监控，当它们遗漏关键因素时；不同模型家族的监控性存在显著差异。

Conclusion: 思维链的监控性对于基于CoT监控的安全方案至关重要，需要同时考虑忠实性和详尽性来全面评估模型推理过程的可观测性。

Abstract: Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.
Since any long, serial reasoning process must pass through this textual trace,
the quality of the CoT is a direct window into what the model is thinking. This
visibility could help us spot unsafe or misaligned behavior (monitorability),
but only if the CoT is transparent about its internal reasoning (faithfulness).
Fully measuring faithfulness is difficult, so researchers often focus on
examining the CoT in cases where the model changes its answer after adding a
cue to the input. This proxy finds some instances of unfaithfulness but loses
information when the model maintains its answer, and does not investigate
aspects of reasoning not tied to the cue. We extend these results to a more
holistic sense of monitorability by introducing verbosity: whether the CoT
lists every factor needed to solve the task. We combine faithfulness and
verbosity into a single monitorability score that shows how well the CoT serves
as the model's external `working memory', a property that many safety schemes
based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning
models on BBH, GPQA, and MMLU. Our results show that models can appear faithful
yet remain hard to monitor when they leave out key factors, and that
monitorability differs sharply across model families. We release our evaluation
code using the Inspect library to support reproducible future work.

</details>


### [73] [FedMuon: Accelerating Federated Learning with Matrix Orthogonalization](https://arxiv.org/abs/2510.27403)
*Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: 提出了FedMuon优化器，通过动量聚合和局部-全局对齐技术解决联邦学习中非IID数据下的客户端漂移问题，显著减少通信轮次并提高收敛速度


<details>
  <summary>Details</summary>
Motivation: 联邦学习的核心瓶颈在于通信轮次，现有方法使用逐元素优化器忽略了权重矩阵的几何结构，导致条件数恶化并减慢收敛

Method: 引入Muon优化器进行矩阵正交化，在非IID设置下提出FedMuon，包含动量聚合（客户端使用聚合动量进行本地初始化）和局部-全局对齐（本地梯度与全局更新方向对齐）

Result: 理论上证明FedMuon实现线性加速收敛率，无需异质性假设；实验验证在语言和视觉模型上显著减少通信轮次并提高测试准确率

Conclusion: FedMuon通过解决客户端漂移和动量重新初始化问题，在非IID联邦学习环境中实现了更高效的收敛

Abstract: The core bottleneck of Federated Learning (FL) lies in the communication
rounds. That is, how to achieve more effective local updates is crucial for
reducing communication rounds. Existing FL methods still primarily use
element-wise local optimizers (Adam/SGD), neglecting the geometric structure of
the weight matrices. This often leads to the amplification of pathological
directions in the weights during local updates, leading deterioration in the
condition number and slow convergence. Therefore, we introduce the Muon
optimizer in local, which has matrix orthogonalization to optimize
matrix-structured parameters. Experimental results show that, in IID setting,
Local Muon significantly accelerates the convergence of FL and reduces
communication rounds compared to Local SGD and Local AdamW. However, in non-IID
setting, independent matrix orthogonalization based on the local distributions
of each client induces strong client drift. Applying Muon in non-IID FL poses
significant challenges: (1) client preconditioner leading to client drift; (2)
moment reinitialization. To address these challenges, we propose a novel
Federated Muon optimizer (FedMuon), which incorporates two key techniques: (1)
momentum aggregation, where clients use the aggregated momentum for local
initialization; (2) local-global alignment, where the local gradients are
aligned with the global update direction to significantly reduce client drift.
Theoretically, we prove that \texttt{FedMuon} achieves a linear speedup
convergence rate without the heterogeneity assumption, where $S$ is the number
of participating clients per round, $K$ is the number of local iterations, and
$R$ is the total number of communication rounds. Empirically, we validate the
effectiveness of FedMuon on language and vision models. Compared to several
baselines, FedMuon significantly reduces communication rounds and improves test
accuracy.

</details>


### [74] [Atlas-Alignment: Making Interpretability Transferable Across Language Models](https://arxiv.org/abs/2510.27413)
*Bruno Puri,Jim Berend,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: Atlas-Alignment框架通过将未知的潜在空间与标记化的Concept Atlas对齐，实现跨语言模型的解释性迁移，无需训练特定稀疏自编码器或手动标记组件。


<details>
  <summary>Details</summary>
Motivation: 现有解释性方法成本高、难以扩展，需要为每个新模型训练稀疏自编码器并进行手动标记验证。

Method: 使用共享输入和轻量级表示对齐技术，将未知潜在空间与预构建的Concept Atlas对齐。

Result: 实现了语义特征搜索检索和沿可解释概念的生成引导，无需标记概念数据。

Conclusion: 该框架通过一次性投资高质量Concept Atlas，以最小边际成本使多个新模型变得透明可控，分摊了解释性AI的成本。

Abstract: Interpretability is crucial for building safe, reliable, and controllable
language models, yet existing interpretability pipelines remain costly and
difficult to scale. Interpreting a new model typically requires costly training
of model-specific sparse autoencoders, manual or semi-automated labeling of SAE
components, and their subsequent validation. We introduce Atlas-Alignment, a
framework for transferring interpretability across language models by aligning
unknown latent spaces to a Concept Atlas - a labeled, human-interpretable
latent space - using only shared inputs and lightweight representational
alignment techniques. Once aligned, this enables two key capabilities in
previously opaque models: (1) semantic feature search and retrieval, and (2)
steering generation along human-interpretable atlas concepts. Through
quantitative and qualitative evaluations, we show that simple representational
alignment methods enable robust semantic retrieval and steerable generation
without the need for labeled concept data. Atlas-Alignment thus amortizes the
cost of explainable AI and mechanistic interpretability: by investing in one
high-quality Concept Atlas, we can make many new models transparent and
controllable at minimal marginal cost.

</details>


### [75] [MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting Post-fire Vegetation Loss](https://arxiv.org/abs/2510.27443)
*Meenu Ravi,Shailik Sarkar,Yanshen Sun,Vaishnavi Singh,Chang-Tien Lu*

Main category: cs.LG

TL;DR: 提出了MVeLMA多模态端到端机器学习管道，用于预测野火后县级植被损失，通过多模态特征集成和堆叠集成架构提高预测性能，并生成置信度地图识别高风险区域。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分探索影响植被损失的所有因素及其相互作用，且预测模型缺乏可解释性，限制了在实际场景中的应用。需要开发更全面、可解释的预测方法。

Method: 使用多模态特征集成管道和堆叠集成架构，结合概率建模进行不确定性估计，构建端到端的ML管道MVeLMA。

Result: 模型在预测野火后植被损失方面优于多个最先进和基线模型，并生成了植被损失置信度地图来识别高风险县。

Conclusion: 该研究为未来的灾害救援规划、生态政策制定和野生动物恢复管理提供了有价值的信息和工具。

Abstract: Understanding post-wildfire vegetation loss is critical for developing
effective ecological recovery strategies and is often challenging due to the
extended time and effort required to capture the evolving ecosystem features.
Recent works in this area have not fully explored all the contributing factors,
their modalities, and interactions with each other. Furthermore, most research
in this domain is limited by a lack of interpretability in predictive modeling,
making it less useful in real-world settings. In this work, we propose a novel
end-to-end ML pipeline called MVeLMA (\textbf{M}ultimodal \textbf{Ve}getation
\textbf{L}oss \textbf{M}odeling \textbf{A}rchitecture) to predict county-wise
vegetation loss from fire events. MVeLMA uses a multimodal feature integration
pipeline and a stacked ensemble-based architecture to capture different
modalities while also incorporating uncertainty estimation through
probabilistic modeling. Through comprehensive experiments, we show that our
model outperforms several state-of-the-art (SOTA) and baseline models in
predicting post-wildfire vegetation loss. Furthermore, we generate vegetation
loss confidence maps to identify high-risk counties, thereby helping targeted
recovery efforts. The findings of this work have the potential to inform future
disaster relief planning, ecological policy development, and wildlife recovery
management.

</details>


### [76] [Spectral Neural Graph Sparsification](https://arxiv.org/abs/2510.27474)
*Angelica Liguori,Ettore Ritacco,Pietro Sabatino,Annalisa Socievole*

Main category: cs.LG

TL;DR: 提出Spectral Preservation Network（SPN）框架，通过生成保留原始图谱特性的简化图来降低计算成本，同时支持社区检测、影响力传播等下游任务。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络依赖固定结构且易出现过平滑问题，需要一种能自适应演化图结构和节点特征的方法。

Method: 引入联合图演化层和谱一致性损失，联合变换图拓扑和节点特征矩阵，通过谱特性一致性进行正则化。

Result: 在节点级稀疏化任务上，SPN在多个指标上优于现有最先进方法，表现出优越性能。

Conclusion: SPN框架通过谱保持机制有效解决了图神经网络的局限性，为图表示学习提供了新思路。

Abstract: Graphs are central to modeling complex systems in domains such as social
networks, molecular chemistry, and neuroscience. While Graph Neural Networks,
particularly Graph Convolutional Networks, have become standard tools for graph
learning, they remain constrained by reliance on fixed structures and
susceptibility to over-smoothing. We propose the Spectral Preservation Network,
a new framework for graph representation learning that generates reduced graphs
serving as faithful proxies of the original, enabling downstream tasks such as
community detection, influence propagation, and information diffusion at a
reduced computational cost. The Spectral Preservation Network introduces two
key components: the Joint Graph Evolution layer and the Spectral Concordance
loss. The former jointly transforms both the graph topology and the node
feature matrix, allowing the structure and attributes to evolve adaptively
across layers and overcoming the rigidity of static neighborhood aggregation.
The latter regularizes these transformations by enforcing consistency in both
the spectral properties of the graph and the feature vectors of the nodes. We
evaluate the effectiveness of Spectral Preservation Network on node-level
sparsification by analyzing well-established metrics and benchmarking against
state-of-the-art methods. The experimental results demonstrate the superior
performance and clear advantages of our approach.

</details>


### [77] [Simplex-to-Euclidean Bijections for Categorical Flow Matching](https://arxiv.org/abs/2510.27480)
*Bernardo Williams,Victor M. Yeom-Song,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 提出了一种在单纯形上学习和采样概率分布的方法，通过光滑双射将开单纯形映射到欧几里得空间，利用Aitchison几何定义映射，并通过Dirichlet插值将离散观测去量化。


<details>
  <summary>Details</summary>
Motivation: 现有的在单纯形上操作的方法通常使用黎曼几何或自定义噪声过程，这些方法较为复杂。本文旨在开发一种在欧几里得空间中工作但尊重Aitchison几何的方法，以简化建模过程。

Method: 使用光滑双射将开单纯形映射到欧几里得空间，利用Aitchison几何定义映射，并通过Dirichlet插值对分类数据进行建模，将离散观测去量化为连续观测。

Result: 在合成和真实世界数据集上取得了有竞争力的性能，证明了该方法在欧几里得空间中有效建模单纯形上分布的能力。

Conclusion: 该方法在欧几里得空间中实现了对单纯形上概率分布的有效学习和采样，同时保持了与Aitchison几何的一致性，为分类数据的密度建模提供了新途径。

Abstract: We propose a method for learning and sampling from probability distributions
supported on the simplex. Our approach maps the open simplex to Euclidean space
via smooth bijections, leveraging the Aitchison geometry to define the
mappings, and supports modeling categorical data by a Dirichlet interpolation
that dequantizes discrete observations into continuous ones. This enables
density modeling in Euclidean space through the bijection while still allowing
exact recovery of the original discrete distribution. Compared to previous
methods that operate on the simplex using Riemannian geometry or custom noise
processes, our approach works in Euclidean space while respecting the Aitchison
geometry, and achieves competitive performance on both synthetic and real-world
data sets.

</details>


### [78] [Thought Branches: Interpreting LLM Reasoning Requires Resampling](https://arxiv.org/abs/2510.27484)
*Uzay Macar,Paul C. Bogdan,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.LG

TL;DR: 通过重采样研究思维链分布，揭示模型推理的因果影响，提出基于重采样的因果分析方法，用于评估原因的真实影响、比较策略干预效果、理解推理步骤重要性以及分析不忠实思维链中的因果机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只分析单个思维链样本，但模型实际上定义了多个可能思维链的分布。单一样本分析不足以理解因果影响和底层计算过程，需要研究思维链分布来获得更可靠的分析。

Method: 使用重采样方法研究模型决策：1）在"代理错位"场景中重采样特定句子测量下游影响；2）比较策略外干预与重采样选择的效果；3）引入弹性度量防止相似内容重现；4）适应因果中介分析研究未明确提及的提示影响。

Result: 自保句子的因果影响很小；策略外干预效果小且不稳定；关键规划陈述难以消除但消除后影响大；未明确提及的提示对思维链产生持续影响。

Conclusion: 通过重采样研究分布能够实现可靠的因果分析、更清晰的模型推理叙述和原则性的思维链干预，为理解模型推理提供了更系统的方法。

Abstract: Most work interpreting reasoning models studies only a single
chain-of-thought (CoT), yet these models define distributions over many
possible CoTs. We argue that studying a single sample is inadequate for
understanding causal influence and the underlying computation. Though fully
specifying this distribution is intractable, it can be understood by sampling.
We present case studies using resampling to investigate model decisions. First,
when a model states a reason for its action, does that reason actually cause
the action? In "agentic misalignment" scenarios, we resample specific sentences
to measure their downstream effects. Self-preservation sentences have small
causal impact, suggesting they do not meaningfully drive blackmail. Second, are
artificial edits to CoT sufficient for steering reasoning? These are common in
literature, yet take the model off-policy. Resampling and selecting a
completion with the desired property is a principled on-policy alternative. We
find off-policy interventions yield small and unstable effects compared to
resampling in decision-making tasks. Third, how do we understand the effect of
removing a reasoning step when the model may repeat it post-edit? We introduce
a resilience metric that repeatedly resamples to prevent similar content from
reappearing downstream. Critical planning statements resist removal but have
large effects when eliminated. Fourth, since CoT is sometimes "unfaithful", can
our methods teach us anything in these settings? Adapting causal mediation
analysis, we find that hints that have a causal effect on the output without
being explicitly mentioned exert a subtle and cumulative influence on the CoT
that persists even if the hint is removed. Overall, studying distributions via
resampling enables reliable causal analysis, clearer narratives of model
reasoning, and principled CoT interventions.

</details>


### [79] [FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models](https://arxiv.org/abs/2510.27486)
*Junkang Liu,Fanhua Shang,Kewen Zhu,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: 提出了FedAdamW算法，这是首个专门针对联邦学习的AdamW优化器，通过局部校正机制和去耦权重衰减来解决数据异构性、局部过拟合和收敛慢的问题。


<details>
  <summary>Details</summary>
Motivation: 直接应用AdamW在联邦学习环境中面临三个挑战：(1)数据异构导致二阶矩估计方差大；(2)局部过拟合导致客户端漂移；(3)每轮重新初始化动量估计会减慢收敛速度。

Method: FedAdamW使用局部校正机制和去耦权重衰减来对齐局部更新与全局更新，高效聚合二阶矩估计的均值以减少方差，并重新初始化这些估计。

Result: 理论上证明了FedAdamW实现了线性加速收敛率，无需异质性假设。实验验证在语言和视觉Transformer模型上显著减少通信轮数并提高测试精度。

Conclusion: FedAdamW是首个专门为联邦学习设计的AdamW算法，有效解决了数据异构环境下的优化问题，在理论和实验上都表现出优越性能。

Abstract: AdamW has become one of the most effective optimizers for training
large-scale models. We have also observed its effectiveness in the context of
federated learning (FL). However, directly applying AdamW in federated learning
settings poses significant challenges: (1) due to data heterogeneity, AdamW
often yields high variance in the second-moment estimate $\boldsymbol{v}$; (2)
the local overfitting of AdamW may cause client drift; and (3) Reinitializing
moment estimates ($\boldsymbol{v}$, $\boldsymbol{m}$) at each round slows down
convergence. To address these challenges, we propose the first
\underline{Fed}erated \underline{AdamW} algorithm, called \texttt{FedAdamW},
for training and fine-tuning various large models. \texttt{FedAdamW} aligns
local updates with the global update using both a \textbf{local correction
mechanism} and decoupled weight decay to mitigate local overfitting.
\texttt{FedAdamW} efficiently aggregates the \texttt{mean} of the second-moment
estimates to reduce their variance and reinitialize them. Theoretically, we
prove that \texttt{FedAdamW} achieves a linear speedup convergence rate of
$\mathcal{O}(\sqrt{(L \Delta \sigma_l^2)/(S K R \epsilon^2)}+(L \Delta)/R)$
without \textbf{heterogeneity assumption}, where $S$ is the number of
participating clients per round, $K$ is the number of local iterations, and $R$
is the total number of communication rounds. We also employ PAC-Bayesian
generalization analysis to explain the effectiveness of decoupled weight decay
in local training. Empirically, we validate the effectiveness of
\texttt{FedAdamW} on language and vision Transformer models. Compared to
several baselines, \texttt{FedAdamW} significantly reduces communication rounds
and improves test accuracy. The code is available in
https://github.com/junkangLiu0/FedAdamW.

</details>


### [80] [InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames](https://arxiv.org/abs/2510.27497)
*Haorui Li,Weitao Du,Yuqiang Li,Hongyu Guo,Shengchao Liu*

Main category: cs.LG

TL;DR: InertialAR是一个基于Transformer的自回归模型，通过惯性坐标系对齐和几何感知注意力机制解决3D分子生成的SE(3)不变性和原子索引排列不变性问题，在无条件分子生成和可控生成任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: Transformer自回归模型在文本和图像模态中取得了成功，但在3D分子生成领域尚未充分探索，主要面临两个挑战：(1)如何将分子规范化为SE(3)变换和原子索引排列不变的1D序列；(2)如何设计能够建模混合原子标记（结合离散原子类型和连续3D坐标）的架构。

Method: 提出InertialAR方法：1）通过惯性坐标系对齐和原子重排序实现规范化的tokenization；2）使用几何旋转位置编码(GeoRoPE)为注意力机制添加几何感知能力；3）采用分层自回归范式，先预测原子类型，再通过扩散损失预测3D坐标。

Result: 在QM9、GEOM-Drugs和B3LYP数据集的无条件分子生成任务中，10个评估指标中有7个达到最先进性能。在可控生成任务中，所有5个指标均显著优于强基线，获得最先进结果。

Conclusion: InertialAR成功地将Transformer自回归模型扩展到3D分子生成领域，通过创新的规范化tokenization和几何感知架构设计，解决了该领域的核心挑战，在多个基准测试中展现了卓越性能。

Abstract: Transformer-based autoregressive models have emerged as a unifying paradigm
across modalities such as text and images, but their extension to 3D molecule
generation remains underexplored. The gap stems from two fundamental
challenges: (1) tokenizing molecules into a canonical 1D sequence of tokens
that is invariant to both SE(3) transformations and atom index permutations,
and (2) designing an architecture capable of modeling hybrid atom-based tokens
that couple discrete atom types with continuous 3D coordinates. To address
these challenges, we introduce InertialAR. InertialAR devises a canonical
tokenization that aligns molecules to their inertial frames and reorders atoms
to ensure SE(3) and permutation invariance. Moreover, InertialAR equips the
attention mechanism with geometric awareness via geometric rotary positional
encoding (GeoRoPE). In addition, it utilizes a hierarchical autoregressive
paradigm to predict the next atom-based token, predicting the atom type first
and then its 3D coordinates via Diffusion loss. Experimentally, InertialAR
achieves state-of-the-art performance on 7 of the 10 evaluation metrics for
unconditional molecule generation across QM9, GEOM-Drugs, and B3LYP. Moreover,
it significantly outperforms strong baselines in controllable generation for
targeted chemical functionality, attaining state-of-the-art results across all
5 metrics.

</details>


### [81] [DP-FedPGN: Finding Global Flat Minima for Differentially Private Federated Learning via Penalizing Gradient Norm](https://arxiv.org/abs/2510.27504)
*Junkang Liu,Yuxuan Tian,Fanhua Shang,Yuanyuan Liu,Hongying Liu,Junchao Zhou,Daorui Ding*

Main category: cs.LG

TL;DR: 提出DP-FedPGN算法，通过引入全局梯度范数惩罚来寻找全局平坦最小值，缓解差分隐私联邦学习中模型泛化性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的客户端级差分隐私联邦学习方法通常导致更尖锐的损失景观，降低模型泛化能力。局部平坦性在CL-DPFL中不能反映全局平坦性。

Method: 在局部损失中引入全局梯度范数惩罚，寻找全局平坦最小值，同时减少局部更新范数，降低梯度裁剪误差。使用Rényi DP提供严格隐私保证。

Result: 在ResNet和Transformer模型上测试，在六个视觉和自然语言处理任务中相比现有最先进算法取得显著改进。

Conclusion: DP-FedPGN不仅找到更平坦的全局最小值，还减少了局部更新范数，缓解了DP带来的性能下降，同时消除了数据异构性的影响并实现快速收敛。

Abstract: To prevent inference attacks in Federated Learning (FL) and reduce the
leakage of sensitive information, Client-level Differentially Private Federated
Learning (CL-DPFL) is widely used. However, current CL-DPFL methods usually
result in sharper loss landscapes, which leads to a decrease in model
generalization after differential privacy protection. By using Sharpness Aware
Minimization (SAM), the current popular federated learning methods are to find
a local flat minimum value to alleviate this problem. However, the local
flatness may not reflect the global flatness in CL-DPFL. Therefore, to address
this issue and seek global flat minima of models, we propose a new CL-DPFL
algorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to
the local loss to find the global flat minimum. Moreover, by using our global
gradient norm penalty, we not only find a flatter global minimum but also
reduce the locally updated norm, which means that we further reduce the error
of gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN
mitigates the performance degradation caused by DP. Meanwhile, the proposed
DP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves
fast convergence. We also use R\'enyi DP to provide strict privacy guarantees
and provide sensitivity analysis for local updates. Finally, we conduct
effectiveness tests on both ResNet and Transformer models, and achieve
significant improvements in six visual and natural language processing tasks
compared to existing state-of-the-art algorithms. The code is available at
https://github.com/junkangLiu0/DP-FedPGN

</details>


### [82] [Learning Sparse Approximate Inverse Preconditioners for Conjugate Gradient Solvers on GPUs](https://arxiv.org/abs/2510.27517)
*Zherui Yang,Zhehao Li,Kangbo Lyu,Yixuan Li,Tao Du,Ligang Liu*

Main category: cs.LG

TL;DR: 提出了一种基于GNN的GPU友好型稀疏近似逆预处理器学习方法，避免了传统方法中的三角求解问题，在GPU上实现40%-53%的求解时间减少。


<details>
  <summary>Details</summary>
Motivation: 传统预处理器依赖预设算法，难以从数据中优化；现有基于学习的方法使用GNN但依赖不完全分解，导致三角求解阻碍GPU并行化并引入长程依赖问题。

Method: 使用GNN构建稀疏近似逆预处理器，避免三角求解，每个CG步骤仅需两次矩阵向量乘积；引入基于统计的尺度不变损失函数。

Result: 在三个PDE数据集和一个合成数据集上评估，相比标准预处理器和学习方法，在GPU上减少40%-53%求解时间，条件数更优，泛化性能更好。

Conclusion: 该方法成功解决了学习型预处理器在GPU上的并行化问题，通过GNN构建SPAI预处理器实现了显著的性能提升和更好的泛化能力。

Abstract: The conjugate gradient solver (CG) is a prevalent method for solving
symmetric and positive definite linear systems Ax=b, where effective
preconditioners are crucial for fast convergence. Traditional preconditioners
rely on prescribed algorithms to offer rigorous theoretical guarantees, while
limiting their ability to exploit optimization from data. Existing
learning-based methods often utilize Graph Neural Networks (GNNs) to improve
the performance and speed up the construction. However, their reliance on
incomplete factorization leads to significant challenges: the associated
triangular solve hinders GPU parallelization in practice, and introduces
long-range dependencies which are difficult for GNNs to model. To address these
issues, we propose a learning-based method to generate GPU-friendly
preconditioners, particularly using GNNs to construct Sparse Approximate
Inverse (SPAI) preconditioners, which avoids triangular solves and requires
only two matrix-vector products at each CG step. The locality of matrix-vector
product is compatible with the local propagation mechanism of GNNs. The
flexibility of GNNs also allows our approach to be applied in a wide range of
scenarios. Furthermore, we introduce a statistics-based scale-invariant loss
function. Its design matches CG's property that the convergence rate depends on
the condition number, rather than the absolute scale of A, leading to improved
performance of the learned preconditioner. Evaluations on three PDE-derived
datasets and one synthetic dataset demonstrate that our method outperforms
standard preconditioners (Diagonal, IC, and traditional SPAI) and previous
learning-based preconditioners on GPUs. We reduce solution time on GPUs by
40%-53% (68%-113% faster), along with better condition numbers and superior
generalization performance. Source code available at
https://github.com/Adversarr/LearningSparsePreconditioner4GPU

</details>


### [83] [Leveraging Generic Time Series Foundation Models for EEG Classification](https://arxiv.org/abs/2510.27522)
*Théo Gnassounou,Yessin Moakher,Shifeng Xie,Vasilii Feofanov,Ievgen Redko*

Main category: cs.LG

TL;DR: 该研究探讨了通用时间序列基础模型在脑电图（EEG）任务中的应用，发现即使使用非神经源数据或合成数据进行预训练，这些模型在EEG分类任务中仍能取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 探索时间序列基础模型在生物医学信号（特别是EEG）领域的适用性，验证跨域预训练模型对脑信号分析的有效性。

Method: 使用两种预训练策略：（1）在多个领域的真实世界时间序列数据上预训练；（2）在纯合成数据上预训练，然后在EEG任务（运动想象分类和睡眠阶段预测）上进行测试。

Result: 两种预训练变体都表现出色，持续优于广泛使用的卷积基线EEGNet和最新的EEG专用基础模型CBraMod。

Conclusion: 通用时间序列基础模型即使使用非神经源数据或合成信号进行预训练，也能有效迁移到EEG任务，表明EEG分析可以从更广泛的时间序列文献进展中受益。

Abstract: Foundation models for time series are emerging as powerful general-purpose
backbones, yet their potential for domain-specific biomedical signals such as
electroencephalography (EEG) remains rather unexplored. In this work, we
investigate the applicability a recently proposed time series classification
foundation model, to a different EEG tasks such as motor imagery classification
and sleep stage prediction. We test two pretraining regimes: (a) pretraining on
heterogeneous real-world time series from multiple domains, and (b) pretraining
on purely synthetic data. We find that both variants yield strong performance,
consistently outperforming EEGNet, a widely used convolutional baseline, and
CBraMod, the most recent EEG-specific foundation model. These results suggest
that generalist time series foundation models, even when pretrained on data of
non-neural origin or on synthetic signals, can transfer effectively to EEG. Our
findings highlight the promise of leveraging cross-domain pretrained models for
brain signal analysis, suggesting that EEG may benefit from advances in the
broader time series literature.

</details>


### [84] [Active transfer learning for structural health monitoring](https://arxiv.org/abs/2510.27525)
*J. Poole,N. Dervilis,K. Worden,P. Gardner,V. Giglioni,R. S. Mills,A. J. Hughes*

Main category: cs.LG

TL;DR: 提出了一种用于结构健康监测的贝叶斯域适应框架，结合主动学习策略，在标签稀缺情况下提高分类模型的数据效率。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测数据获取成本高且困难，特别是带标签数据。传统方法在不同结构数据分布差异大时泛化误差高，需要解决在线监测中如何有效利用有限标签数据的问题。

Method: 使用贝叶斯域适应框架，在无监督域适应基础上利用有限目标标签数据改进映射，并集成主动采样策略选择最有信息量的观测进行标注。

Result: 在实验桥梁数据集上验证，该方法在标签稀缺情况下能有效提高分类模型的数据效率，结合迁移学习和主动学习可减少所需标签数据量。

Conclusion: 该方法可降低结构运营寿命期间的检查频率，从而减少运营成本，对数据驱动的结构运维具有重要意义。

Abstract: Data for training structural health monitoring (SHM) systems are often
expensive and/or impractical to obtain, particularly for labelled data.
Population-based SHM (PBSHM) aims to address this limitation by leveraging data
from multiple structures. However, data from different structures will follow
distinct distributions, potentially leading to large generalisation errors for
models learnt via conventional machine learning methods. To address this issue,
transfer learning -- in the form of domain adaptation (DA) -- can be used to
align the data distributions. Most previous approaches have only considered
\emph{unsupervised} DA, where no labelled target data are available; they do
not consider how to incorporate these technologies in an online framework --
updating as labels are obtained throughout the monitoring campaign. This paper
proposes a Bayesian framework for DA in PBSHM, that can improve unsupervised DA
mappings using a limited quantity of labelled target data. In addition, this
model is integrated into an active sampling strategy to guide inspections to
select the most informative observations to label -- leading to further
reductions in the required labelled data to learn a target classifier. The
effectiveness of this methodology is evaluated on a population of experimental
bridges. Specifically, this population includes data corresponding to several
damage states, as well as, a comprehensive set of environmental conditions. It
is found that combining transfer learning and active learning can improve data
efficiency when learning classification models in label-scarce scenarios. This
result has implications for data-informed operation and maintenance of
structures, suggesting a reduction in inspections over the operational lifetime
of a structure -- and therefore a reduction in operational costs -- can be
achieved.

</details>


### [85] [TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control](https://arxiv.org/abs/2510.27527)
*Yuxiang Chen,Xiaoming Xu,Pengle Zhang,Michael Beyer,Martin Rapp,Jun Zhu,Jianfei Chen*

Main category: cs.LG

TL;DR: TetraJet-v2是一种端到端的4位全量化训练方法，使用NVFP4格式处理所有线性层中的激活、权重和梯度，解决了权重震荡和异常值问题，显著缩小了与全精度训练的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练成本极高，推动了对低精度全量化训练的兴趣。虽然NVFP4等4位格式能带来显著的效率提升，但在如此低精度下实现近乎无损的训练仍然具有挑战性。

Method: 提出TetraJet-v2方法，包括：1）针对NVFP4线性层的无偏双块量化方法；2）抑制权重震荡的OsciReset算法；3）保持异常值精度的OutControl算法。

Result: 在预训练LLM中，TetraJet-v2在模型规模达3.7亿参数、数据规模达2000亿token的情况下，始终优于先前的FP4训练方法，将性能差距平均缩小了51.3%。

Conclusion: TetraJet-v2通过解决权重震荡和异常值问题，成功实现了高效的4位全量化训练，显著提升了低精度训练的性能表现。

Abstract: Large Language Models (LLMs) training is prohibitively expensive, driving
interest in low-precision fully-quantized training (FQT). While novel 4-bit
formats like NVFP4 offer substantial efficiency gains, achieving near-lossless
training at such low precision remains challenging. We introduce TetraJet-v2,
an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,
and gradients in all linear layers. We identify two critical issues hindering
low-precision LLM training: weight oscillation and outliers. To address these,
we propose: 1) an unbiased double-block quantization method for NVFP4 linear
layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)
OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently
outperforms prior FP4 training methods on pre-training LLMs across varying
model sizes up to 370M and data sizes up to 200B tokens, reducing the
performance gap to full-precision training by an average of 51.3%.

</details>


### [86] [AstuteRAG-FQA: Task-Aware Retrieval-Augmented Generation Framework for Proprietary Data Challenges in Financial Question Answering](https://arxiv.org/abs/2510.27537)
*Mohammad Zahangir Alam,Khandoker Ashik Uz Zaman,Mahdi H. Miraz*

Main category: cs.LG

TL;DR: AstuteRAG-FQA是针对金融问答任务设计的自适应RAG框架，通过混合检索策略、动态提示工程和多层安全机制，解决金融领域RAG应用中的专有数据访问、检索精度、监管合规和敏感数据解释等挑战。


<details>
  <summary>Details</summary>
Motivation: RAG在知识密集型任务中表现优异，但在金融领域应用面临专有数据集访问受限、检索精度有限、监管约束和敏感数据解释等关键挑战。

Method: 采用混合检索策略整合开源和专有金融数据，使用动态提示框架实时适应查询复杂度，提出四层任务分类（显式事实、隐式事实、可解释推理、隐含因果推理），并集成多层安全机制（差分隐私、数据匿名化、基于角色的访问控制）和实时合规监控。

Result: 评估了三种数据集成技术（上下文嵌入、小模型增强、目标微调），分析了它们在不同金融环境中的效率和可行性。

Conclusion: AstuteRAG-FQA通过自适应框架有效解决了金融领域RAG应用的关键挑战，为金融问答系统提供了可行的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) shows significant promise in
knowledge-intensive tasks by improving domain specificity, enhancing temporal
relevance, and reducing hallucinations. However, applying RAG to finance
encounters critical challenges: restricted access to proprietary datasets,
limited retrieval accuracy, regulatory constraints, and sensitive data
interpretation. We introduce AstuteRAG-FQA, an adaptive RAG framework tailored
for Financial Question Answering (FQA), leveraging task-aware prompt
engineering to address these challenges. The framework uses a hybrid retrieval
strategy integrating both open-source and proprietary financial data while
maintaining strict security protocols and regulatory compliance. A dynamic
prompt framework adapts in real time to query complexity, improving precision
and contextual relevance. To systematically address diverse financial queries,
we propose a four-tier task classification: explicit factual, implicit factual,
interpretable rationale, and hidden rationale involving implicit causal
reasoning. For each category, we identify key challenges, datasets, and
optimization techniques within the retrieval and generation process. The
framework incorporates multi-layered security mechanisms including differential
privacy, data anonymization, and role-based access controls to protect
sensitive financial information. Additionally, AstuteRAG-FQA implements
real-time compliance monitoring through automated regulatory validation systems
that verify responses against industry standards and legal obligations. We
evaluate three data integration techniques - contextual embedding, small model
augmentation, and targeted fine-tuning - analyzing their efficiency and
feasibility across varied financial environments.

</details>


### [87] [ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling](https://arxiv.org/abs/2510.27610)
*Zhuohan Wang,Ziwei Zhu,Ziniu Li,Congliang Chen,Yizhou Han,Yufeng Lin,Zhihang Lin,Angyang Gu,Xinglin Hu,Ruoyu Sun,Tian Ding*

Main category: cs.LG

TL;DR: 提出了ORGEval框架，使用图论方法评估LLM在优化问题建模中的能力，通过将优化模型表示为图并将等价性检测转化为图同构测试，解决了现有求解器方法的不一致性和高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 工业应用中优化问题的制定需要大量人工努力和领域专业知识，而现有基于求解器的LLM评估方法存在不一致性、不可行性和高计算成本的问题。

Method: ORGEval将优化模型表示为图，将等价性检测转化为图同构测试。提出了对称可分解图的充分条件，在该条件下Weisfeiler-Lehman测试能正确检测同构性，并集成了定制化的WL测试与SD检测算法。

Result: 实验结果表明，ORGEval能成功检测模型等价性，在随机参数配置下产生100%一致的结果，同时在运行时间上显著优于基于求解器的方法，特别是在困难问题上。

Conclusion: 使用ORGEval构建了Bench4Opt数据集并评估了最先进的LLM，发现虽然优化建模对所有LLM都具有挑战性，但DeepSeek-V3和Claude-Opus-4在直接提示下达到了最高准确率，甚至超过了领先的推理模型。

Abstract: Formulating optimization problems for industrial applications demands
significant manual effort and domain expertise. While Large Language Models
(LLMs) show promise in automating this process, evaluating their performance
remains difficult due to the absence of robust metrics. Existing solver-based
approaches often face inconsistency, infeasibility issues, and high
computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs' capabilities in
formulating linear and mixed-integer linear programs. ORGEval represents
optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the
tested graphs are symmetric decomposable (SD), under which the
Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an
SD detection algorithm to evaluate model equivalence. By focusing on structural
equivalence rather than instance-level configurations, ORGEval is robust to
numerical variations. Experimental results show that our method can
successfully detect model equivalence and produce 100\% consistent results
across random parameter configurations, while significantly outperforming
solver-based methods in runtime, especially on difficult problems. Leveraging
ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs
on optimization modeling. Our results reveal that although optimization
modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even
leading reasoning models.

</details>


### [88] [Panprediction: Optimal Predictions for Any Downstream Task and Loss](https://arxiv.org/abs/2510.27638)
*Sivaraman Balakrishnan,Nika Haghtalab,Daniel Hsu,Brian Lee,Eric Zhao*

Main category: cs.LG

TL;DR: 本文提出了panprediction框架，将模型训练视为从数据中提取足够信息以最小化多个下游任务的多种损失函数，并设计了高效的确定性/随机化算法。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习关注在固定分布上最小化固定损失函数，而新范式认为训练应使模型能够处理多个下游任务的多种损失函数。

Method: 设计确定性panpredictor算法（样本复杂度Õ(1/ε³)）和随机化panpredictor算法（样本复杂度Õ(1/ε²)），通过step calibration实现统计高效性。

Result: 在温和假设下，同时最小化无限多任务和损失函数的统计复杂度与单一任务单一损失相当；改进了确定性omniprediction的样本复杂度。

Conclusion: panprediction统一并推广了omniprediction和多组学习，证明了多任务多损失优化的可行性，且统计效率与单任务学习相当。

Abstract: Supervised learning is classically formulated as training a model to minimize
a fixed loss function over a fixed distribution, or task. However, an emerging
paradigm instead views model training as extracting enough information from
data so that the model can be used to minimize many losses on many downstream
tasks. We formalize a mathematical framework for this paradigm, which we call
panprediction, and study its statistical complexity. Formally, panprediction
generalizes omniprediction and sits upstream from multi-group learning, which
respectively focus on predictions that generalize to many downstream losses or
many downstream tasks, but not both. Concretely, we design algorithms that
learn deterministic and randomized panpredictors with
$\tilde{O}(1/\varepsilon^3)$ and $\tilde{O}(1/\varepsilon^2)$ samples,
respectively. Our results demonstrate that under mild assumptions,
simultaneously minimizing infinitely many losses on infinitely many tasks can
be as statistically easy as minimizing one loss on one task. Along the way, we
improve the best known sample complexity guarantee of deterministic
omniprediction by a factor of $1/\varepsilon$, and match all other known sample
complexity guarantees of omniprediction and multi-group learning. Our key
technical ingredient is a nearly lossless reduction from panprediction to a
statistically efficient notion of calibration, called step calibration.

</details>


### [89] [Imbalanced Classification through the Lens of Spurious Correlations](https://arxiv.org/abs/2510.27650)
*Jakob Hackstein,Sidney Bender*

Main category: cs.LG

TL;DR: 论文提出了一种基于可解释AI的方法，通过反事实解释来识别和消除类别不平衡导致的Clever Hans效应，从而提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习中的基本挑战，传统方法关注数据或损失重加权，但本文将其视为放大Clever Hans效应的数据条件，通过少数类的不充分规范来解决问题。

Method: 采用基于反事实解释的可解释AI方法，联合识别和消除在类别不平衡下出现的Clever Hans效应。

Result: 在三个数据集上实现了有竞争力的分类性能，并展示了类别不平衡下Clever Hans效应的出现机制。

Conclusion: 该方法为类别不平衡问题提供了新视角，揭示了现有方法忽视的Clever Hans效应在类别不平衡下的表现。

Abstract: Class imbalance poses a fundamental challenge in machine learning, frequently
leading to unreliable classification performance. While prior methods focus on
data- or loss-reweighting schemes, we view imbalance as a data condition that
amplifies Clever Hans (CH) effects by underspecification of minority classes.
In a counterfactual explanations-based approach, we propose to leverage
Explainable AI to jointly identify and eliminate CH effects emerging under
imbalance. Our method achieves competitive classification performance on three
datasets and demonstrates how CH effects emerge under imbalance, a perspective
largely overlooked by existing approaches.

</details>


### [90] [Information-Theoretic Greedy Layer-wise Training for Traffic Sign Recognition](https://arxiv.org/abs/2510.27651)
*Shuyan Lyu,Zhanzimo Wu,Junliang Du*

Main category: cs.LG

TL;DR: 提出一种基于确定性信息瓶颈和矩阵Rényi熵的逐层训练方法，在CIFAR-10/100和交通标志识别任务上性能优于现有逐层训练基线，接近SGD表现。


<details>
  <summary>Details</summary>
Motivation: 传统端到端训练需要存储中间权重和进行反向传播，这在生物学上不现实。逐层训练可以避免这些问题，但现有方法只在小型数据集和简单架构上验证。

Method: 基于信息瓶颈原理，每层与辅助分类器联合训练，学习最小充分的任务相关表示。使用确定性信息瓶颈和矩阵Rényi熵函数。

Result: 在CIFAR-10/100和交通标志识别任务上验证，性能优于现有逐层训练方法，接近SGD训练效果。

Conclusion: 提出的逐层训练方法有效且具有生物学合理性，为深度网络训练提供了新的可行方案。

Abstract: Modern deep neural networks (DNNs) are typically trained with a global
cross-entropy loss in a supervised end-to-end manner: neurons need to store
their outgoing weights; training alternates between a forward pass
(computation) and a top-down backward pass (learning) which is biologically
implausible. Alternatively, greedy layer-wise training eliminates the need for
cross-entropy loss and backpropagation. By avoiding the computation of
intermediate gradients and the storage of intermediate outputs, it reduces
memory usage and helps mitigate issues such as vanishing or exploding
gradients. However, most existing layer-wise training approaches have been
evaluated only on relatively small datasets with simple deep architectures. In
this paper, we first systematically analyze the training dynamics of popular
convolutional neural networks (CNNs) trained by stochastic gradient descent
(SGD) through an information-theoretic lens. Our findings reveal that networks
converge layer-by-layer from bottom to top and that the flow of information
adheres to a Markov information bottleneck principle. Building on these
observations, we propose a novel layer-wise training approach based on the
recently developed deterministic information bottleneck (DIB) and the
matrix-based R\'enyi's $\alpha$-order entropy functional. Specifically, each
layer is trained jointly with an auxiliary classifier that connects directly to
the output layer, enabling the learning of minimal sufficient task-relevant
representations. We empirically validate the effectiveness of our training
procedure on CIFAR-10 and CIFAR-100 using modern deep CNNs and further
demonstrate its applicability to a practical task involving traffic sign
recognition. Our approach not only outperforms existing layer-wise training
baselines but also achieves performance comparable to SGD.

</details>


### [91] [Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems](https://arxiv.org/abs/2510.27659)
*Alireza Saleh Abadi,Leen-Kiat Soh*

Main category: cs.LG

TL;DR: 该论文分析了多智能体强化学习中开放性与信用分配问题的相互作用，提出了开放性的新子类别，并通过实证研究表明开放性直接导致信用分配错误和性能下降。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习快速发展的背景下，理解开放系统的动态特性至关重要。传统信用分配方法假设静态智能体群体、固定任务和稳定类型，无法适应开放环境的需求。

Method: 首先进行概念分析，引入开放性的新子类别，详细说明智能体流动、任务取消等事件如何打破环境稳定性和固定团队组成的假设。然后使用代表性时间和结构算法在开放环境中进行实证研究。

Result: 结果表明开放性直接导致信用分配错误，表现为损失函数不稳定和显著性能下降。

Conclusion: 开放环境对信用分配方法提出了新的挑战，需要开发能够适应动态变化的新型信用分配算法。

Abstract: In the rapidly evolving field of multi-agent reinforcement learning (MARL),
understanding the dynamics of open systems is crucial. Openness in MARL refers
to the dynam-ic nature of agent populations, tasks, and agent types with-in a
system. Specifically, there are three types of openness as reported in (Eck et
al. 2023) [2]: agent openness, where agents can enter or leave the system at
any time; task openness, where new tasks emerge, and existing ones evolve or
disappear; and type openness, where the capabil-ities and behaviors of agents
change over time. This report provides a conceptual and empirical review,
focusing on the interplay between openness and the credit assignment problem
(CAP). CAP involves determining the contribution of individual agents to the
overall system performance, a task that becomes increasingly complex in open
environ-ments. Traditional credit assignment (CA) methods often assume static
agent populations, fixed and pre-defined tasks, and stationary types, making
them inadequate for open systems. We first conduct a conceptual analysis,
in-troducing new sub-categories of openness to detail how events like agent
turnover or task cancellation break the assumptions of environmental
stationarity and fixed team composition that underpin existing CAP methods. We
then present an empirical study using representative temporal and structural
algorithms in an open environment. The results demonstrate that openness
directly causes credit misattribution, evidenced by unstable loss functions and
significant performance degradation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [92] [Programmable digital quantum simulation of 2D Fermi-Hubbard dynamics using 72 superconducting qubits](https://arxiv.org/abs/2510.26845)
*Faisal Alam,Jan Lukas Bosse,Ieva Čepaitė,Adrian Chapman,Laura Clinton,Marcos Crichigno,Elizabeth Crosson,Toby Cubitt,Charles Derby,Oliver Dowinton,Paul K. Faehrmann,Steve Flammia,Brian Flynn,Filippo Maria Gambetta,Raúl García-Patrón,Max Hunter-Gordon,Glenn Jones,Abhishek Khedkar,Joel Klassen,Michael Kreshchuk,Edward Harry McMullan,Lana Mineh,Ashley Montanaro,Caterina Mora,John J. L. Morton,Dhrumil Patel,Pete Rolph,Raul A. Santos,James R. Seddon,Evan Sheridan,Wilfrid Somogyi,Marika Svensson,Niam Vaishnav,Sabrina Yue Wang,Gethin Wright*

Main category: quant-ph

TL;DR: 本文展示了在Google Willow量子处理器上使用72个量子比特对2D Fermi-Hubbard模型进行可编程数字量子模拟，超越了经典模拟的能力范围，验证了量子计算机在模拟多体相互作用电子系统方面的竞争力。


<details>
  <summary>Details</summary>
Motivation: 量子计算机最初由Feynman提出用于模拟量子多体系统的时间动力学，因为电子间的量子相互作用在材料和分子性质中起着关键作用。准确模拟这类系统仍然是通用数字量子计算机最有前景的应用之一。

Method: 在Google的Willow量子处理器上使用72个量子比特实现2D Fermi-Hubbard模型的数字量子模拟，模拟了6×6晶格尺寸，研究了包括电子-电子相互作用强度和磁通量在内的物理参数。

Result: 成功模拟了磁极化子形成、条纹有序态中的动力学对称性破缺、价键固体上电荷载流子的吸引以及通过热化达到平衡等现象。在可行参数范围内与精确计算验证结果，并与张量网络和算子传播方法等经典近似模拟进行比较。

Conclusion: 研究结果表明，在现有最先进的量子硬件上，可编程数字量子模拟多体相互作用电子模型已经具有竞争力。

Abstract: Simulating the time-dynamics of quantum many-body systems was the original
use of quantum computers proposed by Feynman, motivated by the critical role of
quantum interactions between electrons in the properties of materials and
molecules. Accurately simulating such systems remains one of the most promising
applications of general-purpose digital quantum computers, in which all the
parameters of the model can be programmed and any desired physical quantity
output. However, performing such simulations on today's quantum computers at a
scale beyond the reach of classical methods requires advances in the efficiency
of simulation algorithms and error mitigation techniques. Here we demonstrate
programmable digital quantum simulation of the dynamics of the 2D Fermi-Hubbard
model -- one of the best-known simplified models of electrons in crystalline
solids -- at a scale beyond exact classical simulation. We implement
simulations of this model on lattice sizes up to $6\times 6$ using 72 qubits on
Google's Willow quantum processor, across a range of physical parameters,
including on-site electron-electron interaction strength and magnetic flux, and
study phenomena including formation of magnetic polarons, i.e. charge carriers
surrounded by local magnetic polarisation, dynamical symmetry breaking in
stripe-ordered states, attraction of charge carriers on an entangled state
known as a valence bond solid, and the approach to equilibrium through
thermalisation. We validate our results against exact calculations in parameter
regimes where these are feasible, and compare them to approximate classical
simulations performed using tensor network and operator propagation methods.
Our results demonstrate that programmable digital quantum simulation of
many-body interacting electron models is now competitive on state-of-the-art
quantum hardware.

</details>


### [93] [The Particle in a Box in Koopman--von Neumann Mechanics: A Hilbert Space representation of Classical Mechanics](https://arxiv.org/abs/2510.26856)
*Abhijit Sen,Lev Kaplan*

Main category: quant-ph

TL;DR: 本文从Koopman-von Neumann力学角度重新审视'盒子中的粒子'问题，证明经典粒子在理想壁之间仍具有连续能量谱，而非量子化的能级。


<details>
  <summary>Details</summary>
Motivation: 澄清KvN力学中经典动力学在希尔伯特空间描述的特殊性，纠正关于边界条件导致能量量子化的常见误解。

Method: 使用KvN力学框架，采用正确的壁边界条件（描述普通弹性反射而非边界消失），分析粒子在盒子中的动力学行为。

Result: KvN粒子在理想壁之间仍具有连续能量范围，正确的边界条件自然产生空间约束而不产生离散能级。

Conclusion: KvN力学描述经典系统时不会产生能量量子化，关键在于正确理解边界条件和波函数的物理意义。

Abstract: This paper revisits the textbook 'particle in a box', but from the point of
view of Koopman-von Neumann (KvN) mechanics. KvN mechanics is a way to describe
\emph{classical} dynamics in a Hilbert space. That simple fact changes the
usual expectation: hard walls do \emph{not} force energy quantization here. We
show, in a clear and physical way, why a KvN particle confined between two
ideal walls still has a continuous range of energies. With the correct wall
condition, one that captures ordinary elastic reflection rather than 'vanishing
at the boundary,' the KvN description naturally produces spatial confinement
without discrete energy levels. Beyond establishing this result, we also clean
up common misunderstandings: for example, treating the KvN wavefunction like a
quantum probability amplitude in position alone leads to the wrong boundary
picture and, with it, the wrong conclusion about quantization.

</details>


### [94] [A Non-Variational Quantum Approach to the Job Shop Scheduling Problem](https://arxiv.org/abs/2510.26859)
*Miguel Angel Lopez-Ruiz,Emily L. Tucker,Emma M. Arnold,Evgeny Epifanovsky,Ananth Kaushik,Martin Roetteler*

Main category: quant-ph

TL;DR: 提出了Iterative-QAOA算法，结合非变分浅层电路和迭代预热启动，在量子硬件上解决组合优化问题，在JIT-JSSP问题上表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 量子启发式算法在组合优化中具有潜在优势，但受到近期硬件限制的约束，需要设计能缓解这些限制的新算法。

Method: Iterative-QAOA算法结合非变分浅层电路方法（使用固定参数调度）和迭代预热启动过程，在IonQ Forte量子处理器上执行。

Result: 算法在所有评估的问题实例中都能稳健收敛到最优解和高质量近优解，在97量子比特的更大问题上通过张量网络模拟验证了可扩展性。

Conclusion: 算法的扩展性表明在容错量子计算机上解决工业规模问题具有潜力。

Abstract: Quantum heuristics offer a potential advantage for combinatorial optimization
but are constrained by near-term hardware limitations. We introduce
Iterative-QAOA, a variant of QAOA designed to mitigate these constraints. The
algorithm combines a non-variational, shallow-depth circuit approach using
fixed-parameter schedules with an iterative warm-starting process. We benchmark
the algorithm on Just-in-Time Job Shop Scheduling Problem (JIT-JSSP) instances
on IonQ Forte Generation QPUs, representing some of the largest such problems
ever executed on quantum hardware. We compare the performance of the algorithm
against both the Variational Quantum Imaginary Time Evolution (VarQITE)
algorithm and the non-variational Linear Ramp (LR) QAOA algorithm. We find that
Iterative-QAOA robustly converges to find optimal solutions as well as
high-quality, near-optimal solutions for all problem instances evaluated. We
evaluate the algorithm on larger problem instances up to 97 qubits using tensor
network simulations. The scaling behavior of the algorithm indicates potential
for solving industrial-scale problems on fault-tolerant quantum computers.

</details>


### [95] [Single-Photon-Level Atomic Frequency Comb Storage in Room Temperature Alkali Vapour](https://arxiv.org/abs/2510.26870)
*Zakary Schofield,Vanderli Laurindo Jr,Ori Ezrah Mor,Patrick M. Ledingham*

Main category: quant-ph

TL;DR: 在室温铷蒸气中实现了单光子级别光的相干存储和检索，使用原子频率梳协议，存储效率达6.59%，支持时间比特和偏振比特量子存储。


<details>
  <summary>Details</summary>
Motivation: 开发室温量子存储器，实现单光子级别光的相干存储，为量子信息处理提供实用化解决方案。

Method: 使用原子频率梳协议，通过速度选择性光泵浦在铷蒸气中制备频率梳，存储弱相干态光子。

Result: 成功存储平均光子数0.083的弱相干态，存储效率6.59%，支持多时间模式和偏振无关存储。

Conclusion: 证明了室温铷蒸气中原子频率梳协议的有效性，为量子比特存储提供了可行方案。

Abstract: We have demonstrated the coherent storage and retrieval of
single-photon-level light using the atomic frequency comb protocol in a room
temperature rubidium vapour. Velocity-selective optical pumping is used to
prepare the comb within the $F=2$ hyperfine ground state of rubidium, with the
spacing between peaks coinciding with half the $F = 2 - F =3$ hyperfine
splitting of the $5^2$P$_{3/2}$ excited state. Weak coherent states of average
photon number $\mu_\mathrm{in} = 0.083(5)$ are stored with pre-programmed
recall time of $7.5\,$ns with an efficiency of $\eta_{\textrm{AFC}} =
6.59(5)\,\%$, while two temporally distinct modes have been stored and recalled
with $\eta_{\textrm{AFC}} = 2.6(1)\,\%$, allowing for time-bin qubit storage.
Finally, the efficiency is observed to be independent of the input pulse
polarisation, paving the way for polarisation qubit storage.

</details>


### [96] [Optimising physical parameters of a quantum network based on a loss-jitter trade-off](https://arxiv.org/abs/2510.26888)
*Marcus J. Clark,Siddarth K. Joshi*

Main category: quant-ph

TL;DR: 基于不可避免的损耗、色散和时序抖动，模拟显示某些波长和带宽在量子通信系统中具有明显优势


<details>
  <summary>Details</summary>
Motivation: 随着量子通信系统商业化，明确其未来基础设施需求变得日益重要

Method: 通过模拟分析不同波长和带宽在存在损耗、色散和时序抖动条件下的性能

Result: 发现某些特定波长和带宽配置具有明显优势

Conclusion: 量子通信系统设计应考虑波长和带宽选择以优化性能

Abstract: As quantum communication systems and networks are becoming a commercial
reality, clarity on their future infrastructure is increasingly important.
Based on the inevitable presence of some amount of loss, chromatic dispersion,
and timing jitter, we present simulations to show that certain wavelengths and
bandwidths have clear advantages.

</details>


### [97] [Exact and approximate conditions of tabletop reversibility: when is Petz recovery cost-free?](https://arxiv.org/abs/2510.26895)
*Minjeong Song,Hyukjoon Kwon,Valerio Scarani*

Main category: quant-ph

TL;DR: 该论文研究了量子信道的时间可逆性，特别是Petz恢复映射在何种条件下能够使用与正向信道相似的资源实现，提出了精确和近似的时间可逆性条件。


<details>
  <summary>Details</summary>
Motivation: 量子动力学信道本质上是不可逆的，但可以研究信息的部分恢复。Petz恢复映射提供了一种系统性的恢复方法，但通常实现方式与原始信道差异很大。研究在什么条件下这两种映射需要相似甚至相同的资源。

Method: 首先研究精确的时间可逆性条件，发现需要时间敏感的辅助系统控制；然后提出近似时间可逆性条件，不需要时间敏感控制；最后在随机时间碰撞模型下推导Lindbladian时间可逆性条件。

Result: 建立了量子信道时间可逆性的理论框架，区分了精确和近似可逆性的不同要求，为实际实现量子信息恢复提供了指导。

Conclusion: 量子信道的时间可逆性实现需要特定的条件，精确可逆性要求时间敏感控制，而近似可逆性可以放宽这一要求，这为量子信息处理中的恢复操作设计提供了理论基础。

Abstract: Channels $\mathcal{N}$ that describe open quantum dynamics are inherently
irreversible: it is impossible to undo their effect completely, but one can
study partial recovery of the information. The Petz recovery map
$\hat{\mathcal{N}}_{\gamma}^{(\texttt{P})}$ is a systematic construction that
depends only on $\mathcal{N}$ and on a reference state $\gamma$, which will be
recovered exactly. If the real input state was different from $\gamma$, the
recovery is partial, with a guarantee of near-optimality. Generically, an
implementation of the Petz recovery map would look very different from the
implementation of the channel. It is natural to study under which conditions
the two maps require similar or even identical resources. The noisy forward
channel $\mathcal{N}$ is called ``tabletop time-reversible'' for a given
$\gamma$ when the corresponding Petz recovery map is realizable in such a way.
First, we study the exact tabletop reversibility (TTR) conditions. We show in
particular that a time-sensitive control of an ancilla system is needed.
Second, we present the approximate TTR conditions, which do not require such a
time-sensitive control. Third, we derive Lindbladian TTR conditions under a
random-time collision model.

</details>


### [98] [Harnessing Floquet dynamics for selective metrology in few-qubit systems](https://arxiv.org/abs/2510.26942)
*Asghar Ullah,Hasan Mermer,Melih Özkurt,Igor Lesanovsky,Özgür E. Müstecaplıoğlu*

Main category: quant-ph

TL;DR: 本文展示了周期性驱动的量子系统可作为选择性参数滤波器，在三量子比特Floquet Ising模型中，周期加倍相能显著增强对Ising相互作用强度的测量精度，同时抑制对横向磁场的敏感性。


<details>
  <summary>Details</summary>
Motivation: 探索周期性驱动量子系统在量子传感中的选择性参数滤波能力，特别是在有限尺寸系统中如何利用不同的动力学机制来实现针对特定参数的优化测量。

Method: 使用三量子比特横向场Floquet Ising模型，分析周期加倍相中的π配对效应，通过量子Fisher信息评估测量精度，并验证经典Fisher信息在实验可观测量（如磁化和两量子比特关联）中的可量化性。

Result: 周期加倍相显著增强了对Ising相互作用强度的测量精度，同时抑制了对横向磁场的敏感性；非周期加倍相则最适合测量横向场。这种滤波效应在更大系统尺寸中保持稳健。

Conclusion: 有限尺寸Floquet系统中的不同动力学机制可用于实现有针对性的量子传感，周期加倍相提供了一种选择性参数滤波的有效方法。

Abstract: Periodically driven quantum systems can function as highly selective
parameter filters. We demonstrate this capability in a finite-size, three-qubit
system described by the transverse-field Floquet Ising model. In this system,
we identify a period-doubling (PD) dynamical phase that exhibits a stark
asymmetry in metrological sensitivity to the magnetic field applied on the
qubits and to the coupling strength between the qubits. The PD phase originates
from $\pi$-pairing, where the initial state exhibits strong overlap with
$\pi$-paired Floquet eigenstates, leading to robust period-doubled dynamics and
enhanced metrological sensitivity. The analysis of quantum Fisher information
reveals that the PD regime significantly enhances precision for estimating the
Ising interaction strength while simultaneously suppressing sensitivity to the
transverse magnetic field. Conversely, non-PD regimes are optimal for sensing
the transverse field. This filtering effect is robust for larger system sizes
and is quantifiable using experimentally accessible observables, such as
magnetization and two-qubit correlations, via the classical Fisher information.
Our work shows that distinct dynamical regimes in finite-size Floquet systems
can be harnessed for targeted quantum sensing.

</details>


### [99] [Sample-Based Krylov Quantum Diagonalization for the Schwinger Model on Trapped-Ion and Superconducting Quantum Processors](https://arxiv.org/abs/2510.26951)
*Emil Otis Rosanowski,Jurek Eisinger,Lena Funcke,Ulrich Poschinger,Ferdinand Schmidt-Kaler*

Main category: quant-ph

TL;DR: 将基于采样的Krylov量子对角化方法应用于含θ项的Schwinger模型，通过量子-经典混合方法构建Krylov空间并经典对角化，准确捕捉了模型的相结构，在不同量子处理器上验证了性能。


<details>
  <summary>Details</summary>
Motivation: 开发适用于晶格规范理论的高效量子模拟方法，特别是针对含θ项的Schwinger模型，以准确捕捉其相结构。

Method: 采用基于采样的Krylov量子对角化方法：从时间演化的量子态中采样比特串构建Krylov空间，然后在该子空间内经典对角化哈密顿量。

Result: 准确获得了基态能量和粒子数对θ项的依赖关系，在不同量子处理器上表现一致，显著减小了有效希尔伯特空间维度。

Conclusion: SKQD方法虽然Krylov空间维度仍呈指数增长，但增长较慢，显示出在更大体积晶格规范理论模拟中的潜力。

Abstract: We apply the recently proposed Sample-based Krylov Quantum Diagonalization
(SKQD) method to lattice gauge theories, using the Schwinger model with a
$\theta$-term as a benchmark. SKQD approximates the ground state of a
Hamiltonian, employing a hybrid quantum-classical approach: (i) constructing a
Krylov space from bitstrings sampled from time-evolved quantum states, and (ii)
classically diagonalizing the Hamiltonian within this subspace. We study the
dependence of the ground-state energy and particle number on the value of the
$\theta$-term, accurately capturing the model's phase structure. The algorithm
is implemented on trapped-ion and superconducting quantum processors,
demonstrating consistent performance across platforms. We show that SKQD
substantially reduces the effective Hilbert space, and although the Krylov
space dimension still scales exponentially, the slower growth underscores its
promise for simulating lattice gauge theories in larger volumes.

</details>


### [100] [Electron juggling: Approaching the atomic physics limit of the attempt rate in trapped ion photonic interconnects](https://arxiv.org/abs/2510.27005)
*I. D. Moore,B. M. White,B. Graner,J. D. Siverns*

Main category: quant-ph

TL;DR: 提出了一种名为"电子杂耍"的新技术，通过大幅减少状态准备步骤来加速光子互连，使远程纠缠生成速率接近原子物理极限，可能实现每秒超过1000个贝尔对的生成速率。


<details>
  <summary>Details</summary>
Motivation: 光子互连是扩展原子量子计算机的关键技术，但传统方法中状态准备步骤耗时过长（数百纳秒到几微秒），限制了纠缠生成速率。

Method: 使用"电子杂耍"技术，通过理论框架分析如何显著减少状态准备步骤的时间消耗。

Result: 该方案能显著提高远程纠缠生成速率，接近被困离子光子互连中尝试速率的原子物理极限。

Conclusion: 电子杂耍方案有望实现每秒超过1000个贝尔对的远程纠缠生成速率，为构建高性能模块化量子处理单元提供了重要技术路径。

Abstract: Photonic interconnects are a key technology for scaling up atomic based
quantum computers. By facilitating the connection of multiple systems,
high-performance modular quantum processing units may be constructed to perform
deeper and more useful algorithms. Most previous implementations of photonic
interconnects in trapped ions utilize the scheme of preparing a state, exciting
it, and collecting single photons from decays of the excited state. State
preparation is responsible for the vast majority of the total attempt time,
often taking hundreds of nanoseconds to several microseconds. Here, we describe
and analyze a novel technique called ``electron juggling" to speed up photonic
interconnects by reducing the state preparation step substantially. Using a
theoretical framework, we illustrate how this scheme can significantly increase
remote entanglement generation rates, approaching the atomic physics limit of
the attempt rate in trapped-ion photonic interconnects. Our results indicate
that this scheme holds the possibility of achieving remote entanglement
generation rates of over 1,000 Bell pairs per second.

</details>


### [101] [Fast Bosonic Control via Multiphoton Qubit-Oscillator Interactions](https://arxiv.org/abs/2510.27035)
*Noah Gorgichuk,Mohammad Ayyash,Matteo Mariantoni,Sahel Ashhab*

Main category: quant-ph

TL;DR: 提出了一种利用多光子相互作用在振荡器中制备n重旋转对称态（包括玻色子量子纠错码的逻辑码字）的协议，相比线性相互作用能显著减少态制备时间。


<details>
  <summary>Details</summary>
Motivation: 为可扩展的玻色子容错超导量子计算机开发高效的振荡器态制备方法，特别是针对平面超导硬件上的玻色子码性能优化。

Method: 利用辅助量子比特与振荡器之间的多光子相互作用，结合不同阶数的多光子相互作用实现振荡器希尔伯特空间的任意控制，并推广到多振荡器态制备。

Result: 数值模拟验证了协议在考虑量子比特和振荡器弛豫及退相干的现实超导电路参数下的鲁棒性，多光子相互作用相比线性相互作用显著减少了态制备时间。

Conclusion: 该协议能显著提升平面超导硬件上玻色子码的性能，是实现可扩展玻色子容错超导量子计算机的重要技术。

Abstract: We present a protocol for preparing oscillator states with $n$-fold
rotational symmetry, which include many logical codewords for bosonic quantum
error correction codes. The protocol relies on a multiphoton interaction
between the oscillator and an auxiliary qubit. Further, we achieve arbitrary
control over the oscillator's Hilbert space by using a combination of different
multiphoton interaction orders. We also discuss the preparation of
rotationally-symmetric multi-oscillator states using a generalized variant of
the protocol. We show that the use of multiphoton qubit-oscillator interactions
can substantially reduce the state preparation time, in comparison to the
linear qubit-oscillator interactions that are usually employed. Furthermore, we
perform numerical simulations that take into account qubit and oscillator
relaxation and dephasing using realistic planar superconducting circuit
parameters that validate the robustness of our protocol. Our findings can
significantly improve the performance of bosonic codes on planar
superconducting hardware, which are an almost inevitable necessity for scalable
bosonic fault-tolerant superconducting quantum computers.

</details>


### [102] [Characterizing Quantum Internet Using Complex Network Models](https://arxiv.org/abs/2510.27073)
*Otávio José R. Silveira,Nycolas B. da Silva,Saulo L. L. da Silva,Angélica S. da Mata*

Main category: quant-ph

TL;DR: 提出了考虑光纤网络节点连接异质性的量子互联网新模型，分析异质性对网络结构指标的影响，发现异质网络能更好地模拟真实光纤网络的关键结构特性。


<details>
  <summary>Details</summary>
Motivation: 现有量子互联网模型通常假设光纤基础设施连接分布均匀，忽略了网络异质性，需要更真实的模型来理解量子通信网络的统计特性。

Method: 提出新的量子互联网模型，纳入光纤网络中节点连接的异质性，分析其对度分布、平均聚类系数、平均最短路径和同配性等基本指标的影响。

Result: 与同质模型相比，异质网络能有效再现真实光纤网络的关键结构特性，包括度分布、同配性和层次行为。

Conclusion: 网络结构对量子通信有重要影响，异质性建模能促进量子互联网基础设施的更真实建模。

Abstract: Quantum communication is a growing area of research, with quantum internet
being one of the most promising applications. Studying the statistical
properties of this network is essential to understanding its connectivity and
the efficiency of the entanglement distribution. However, the models proposed
in the literature often assume homogeneous distributions in the connections of
the optical fiber infrastructure, without considering the heterogeneity of the
network. In this work, we propose new models for the quantum internet that
incorporate this heterogeneity of node connections in the optical fiber
network, analyzing how this characteristic influences fundamental metrics such
as the degree distribution, the average clustering coefficient, the average
shortest path and assortativity. Our results indicate that, compared to
homogeneous models, heterogeneous networks efficiently reproduce key structural
properties of real optical fiber networks, including degree distribution,
assortativity, and hierarchical behavior. These findings highlight the impact
of network structure on quantum communication and can contribute to more
realistic modeling of quantum internet infrastructure.

</details>


### [103] [Inter-transition interference in spectrum of Kerr parametric oscillators](https://arxiv.org/abs/2510.27122)
*Shumpei Masuda*

Main category: quant-ph

TL;DR: 本文研究了Kerr参量振荡器中多光子跃迁的干涉效应，扩展了反射测量理论，考虑了能级简并和密度矩阵非对角元的影响。


<details>
  <summary>Details</summary>
Motivation: 由于KPO能级简并，探测场可能与多个能级间跃迁共振，之前理论忽略了这些跃迁间的干涉效应和密度矩阵非对角元的影响。

Method: 扩展了反射测量理论，引入能级间跃迁的干涉效应和密度矩阵非对角元素，并将理论推广到透射测量。

Result: 发现跃迁间的干涉显著改变了光谱特性，确定了干涉发生的条件以及密度矩阵非对角元影响光谱的条件。

Conclusion: 该理论适用于KPO之外的广泛系统，揭示了多能级跃迁干涉在量子系统中的重要作用。

Abstract: We theoretically investigate reflection and transmission measurements of
two-photon and four-photon Kerr parametric oscillators (KPOs), introducing
interference effects between inter-level transitions. Due to the level
degeneracy of a KPO, a probe field can be resonant with multiple inter-level
transitions. We extend the previous theory of reflection measurements by
incorporating the interaction between inter-level transitions and off-diagonal
elements of the density matrix which had previously been neglected. We
demonstrate that interference among these transitions substantially modifies
the spectrum. We identify the conditions for the interference, as well as those
under which the off-diagonal elements of the density matrix affect the
spectrum. The theory is also generalized to transmission measurements, and is
applicable to a broad class of systems beyond KPOs.

</details>


### [104] [Quantum, Stochastic, and Classical Dynamics Within A Single Geometric Framework](https://arxiv.org/abs/2510.27170)
*Partha Ghose*

Main category: quant-ph

TL;DR: 该论文展示了Koopman-von Neumann经典力学表述作为Ghose插值方程在λ→1极限下的自然涌现，建立了量子、随机和经典动力学的统一框架。


<details>
  <summary>Details</summary>
Motivation: 建立量子力学与经典力学之间的连续过渡框架，通过随机力学和插值参数连接量子与经典动力学。

Method: 利用Ghose插值方程中的λ参数，研究从量子(λ=0)到经典(λ=1)的连续过渡，分析KvN表述在λ→1极限下的涌现。

Result: 发现KvN经典力学表述是随机σ-λ层次结构在λ→1极限下的自然结果，KvN相空间振幅提供了经典Liouville方程的算子表示。

Conclusion: 该统一框架通过λ参数实现了从复射影Hilbert流形到经典商空间的连续投影，为量子、随机和经典动力学提供了单一连续框架。

Abstract: Nelson's stochastic mechanics links quantum mechanics to an underlying
Brownian motion with the identification $\hbar = m\sigma$. Ghose's
interpolating equation introduces a continuous parameter $\lambda$ that
suppresses the quantum potential $Q[\psi]$ and yields a smooth transition
between quantum ($\lambda=0$) and classical ($\lambda=1$) regimes. In this
short note, we show that the Koopman--von Neumann (KvN) Hilbert-space
formulation of classical mechanics emerges naturally as the $\lambda \to 1$
limit of this stochastic $\sigma$--$\lambda$ hierarchy. The KvN phase-space
amplitude provides an operator representation of the classical Liouville
equation, while the $\lambda$ parameter acts as a projection flow from the
complex projective Hilbert manifold $\mathbb{C}P^n$ to its classical quotient
$\mathbb{C}P^*/U(1)$, implementing phase superselection. This unified picture
links quantum, stochastic, and classical dynamics within a single continuous
framework.

</details>


### [105] [Zitterbewegung Effect and Quantum Geometry in Non-Hermitian Exciton-Polariton Systems](https://arxiv.org/abs/2510.27220)
*Yow-Ming Robin Hu,Elena A. Ostrovskaya,Eliezer Estrecho*

Main category: quant-ph

TL;DR: 本文推导了非厄米系统中波包动力学的zitterbewegung效应的半经典运动方程，揭示了非厄米自旋动力学的新特征和非厄米量子度规张量对群速度的修正。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中zitterbewegung效应的动机在于：非厄米系统的自旋动力学与厄米系统存在本质差异，非厄米哈密顿量会引入有效非线性项，这可能导致新的物理现象。

Method: 通过分析推导半经典运动方程，将zitterbewegung效应的描述推广到非厄米系统，并考虑非厄米哈密顿量引起的有效非线性项。

Result: 发现了非厄米自旋动力学对zitterbewegung效应的影响，并揭示了在没有面外有效场情况下，群速度的非厄米修正可以用非厄米量子度规张量表示。

Conclusion: 非厄米系统中的zitterbewegung效应展现出与厄米系统不同的特征，非厄米量子度规张量在群速度修正中起关键作用，这为理解非厄米系统的动力学行为提供了新视角。

Abstract: In this work, we analytically derive a semi-classical equation of motion
describing the zitterbewegung effects arising in the dynamics of wavepackets in
non-Hermitian systems. In Hermitian non-relativistic quantum systems, the
zitterbewegung effects can arise due to the spin precession and spin-orbit
coupling. Interestingly, the spin dynamics in non-Hermitian systems are
qualitatively different because of the effective nonlinear terms induced by the
non-Hermitian part of the Hamiltonian. In this work, we show the effects from
the non-Hermitian spin dynamics by generalising the description of
zitterbewegung effects to non-Hermitian systems. We also uncover novel
non-Hermitian correction to the group velocity, which can be expressed in terms
of the non-Hermitian quantum metric tensor in the absence of out-of-plane
effective field.

</details>


### [106] [Maximal extension on converse monogamy of entanglement for tripartite pure states](https://arxiv.org/abs/2510.27264)
*Junhyeong An,Soojoon Lee*

Main category: quant-ph

TL;DR: 本文扩展了纠缠对偶单调性(CMoE)的条件，证明了在更广泛条件下弱纠缠会强制产生强纠缠，并表明这些扩展在所考虑的层次结构中是最优的。


<details>
  <summary>Details</summary>
Motivation: 纠缠的单调性限制了多方之间的纠缠共享，但其逆命题——弱纠缠强制强纠缠——仅在特定条件下成立。本文旨在扩展CMoE的适用范围。

Method: 基于Hayashi和Chen以及Singh和Datta的工作，通过考虑更广泛的层次结构和可蒸馏性条件来扩展CMoE。

Result: 成功扩展了CMoE的条件范围，并证明了这些扩展在所考虑的层次结构中是最优的。

Conclusion: 本文为纠缠对偶单调性提供了更广泛的理论框架，深化了对多体量子系统中纠缠分布规律的理解。

Abstract: Unlike classical correlations, entanglement cannot be freely shared among
multiple parties. This unique feature of quantum systems is known as the
monogamy of entanglement. While it holds for all multipartite pure states, its
converse -- weak entanglement between two parties enforces strong entanglement
with a third party -- occurs only under specific conditions. In particular,
Hayashi and Chen [Phys. Rev. A \textbf{84}, 012325 (2011)] demonstrated a
qualitative version of the converse monogamy of entanglement (CMoE) for
tripartite pure states by employing a hierarchy of bipartite entanglement
defined through the relations among various separability criteria, and Singh
and Datta [IEEE Trans. Inf. Theory \textbf{69}, 6564 (2023)] later extended
this notion of the CMoE from the viewpoint of distillability under one-way or
two-way classical communication. In this work, we extend their results to the
CMoE with broader conditions, and furthermore show that our extensions are
maximal with respect to the hierarchies they considered.

</details>


### [107] [Instruction-Directed MAC for Efficient Classical Communication in Scalable Multi-Chip Quantum Systems](https://arxiv.org/abs/2510.27273)
*Maurizio Palesi,Enrico Russo,Hamaad Rafique,Giuseppe Ascia,Davide Patti,Abhijit Das,Sergi Abadal*

Main category: quant-ph

TL;DR: 提出了一种基于指令导向令牌的MAC协议(ID-MAC)，通过利用量子电路执行的确定性特点，在编译时预定义传输调度，显著减少了量子多芯片架构中的经典通信延迟。


<details>
  <summary>Details</summary>
Motivation: 可扩展量子计算需要模块化多芯片架构，其中经典通信子系统对于协调分布式控制操作和支持量子协议至关重要。传统基于令牌的MAC协议由于在非活动节点间低效循环令牌而产生延迟惩罚。

Method: 提出指令导向令牌MAC协议(ID-MAC)，利用量子电路执行的确定性特点，在编译时预定义传输调度。通过在MAC层嵌入指令级信息，将令牌循环限制在活动发送器之间。

Result: 仿真显示ID-MAC将经典通信时间减少高达70%，总执行时间减少30-70%，同时延长了有效系统相干时间。

Conclusion: ID-MAC是未来多芯片量子架构的可扩展且高效的MAC解决方案。

Abstract: Scalable quantum computing requires modular multi-chip architectures
integrating multiple quantum cores interconnected through quantum-coherent and
classical links. The classical communication subsystem is critical for
coordinating distributed control operations and supporting quantum protocols
such as teleportation. In this work, we consider a realization based on a
wireless network-on-chip for implementing classical communication within
cryogenic environments. Traditional token-based medium access control (MAC)
protocols, however, incur latency penalties due to inefficient token
circulation among inactive nodes. We propose the instruction-directed token MAC
(ID-MAC), a protocol that leverages the deterministic nature of quantum circuit
execution to predefine transmission schedules at compile time. By embedding
instruction-level information into the MAC layer, ID-MAC restricts token
circulation to active transmitters, thereby improving channel utilization and
reducing communication latency. Simulations show that ID-MAC reduces classical
communication time by up to 70% and total execution time by up to 30-70%, while
also extending effective system coherence. These results highlight ID-MAC as a
scalable and efficient MAC solution for future multi-chip quantum
architectures.

</details>


### [108] [Manipulating Excitation Dynamics in Structured Waveguide Quantum Electrodynamics](https://arxiv.org/abs/2510.27310)
*I Gusti Ngurah Yudi Handayana,Ya-Tang Yu,Wei-Hsuan Chung,H. H. Jen*

Main category: quant-ph

TL;DR: 提出结构化波导量子电动力学框架，通过工程化每个发射器的耦合方向性来控制激发传输，识别了四种具有不同动力学行为的配置，并展示了可调控的局域化-去局域化转变。


<details>
  <summary>Details</summary>
Motivation: 传统波导量子电动力学系统依赖均匀手性或互易发射器-波导耦合，需要开发能够局部控制耦合方向性的新框架来操控激发传输。

Method: 构建结构化波导量子电动力学框架，工程化每个发射器的局部耦合方向性，通过谱分析和方差分析研究激发传输动力学。

Result: 识别了四种代表性配置（中心化、波状、跳跃、色散激发），展示了可调控的局域化-去局域化转变，且在现实耦合效率下传输特性保持稳健。

Conclusion: 结构化波导量子电动力学为通过可编程方向性模式操控激发局域化、相干性和传输提供了实用途径，为可控亚辐射传输和手性量子信息路由铺平了道路。

Abstract: Waveguide quantum electrodynamics (wQED) has become a central platform for
studying collective light-matter interactions in low-dimensional photonic
environments. While conventional wQED systems rely on uniform chirality or
reciprocal emitter-waveguide coupling, we propose a structured wQED framework,
where the coupling directionality of each emitter can be engineered locally to
control excitation transport in an atom-nanophotonic interface. For different
combinations of patterned coupling directionalities of the emitters, we
identify four representative configurations that exhibit distinct dynamical
behaviors: centering, wave-like, leap-frog, and dispersion excitations.
Spectral analysis of the effective non-Hermitian Hamiltonian reveals that these
dynamics originate from interferences among subradiant eigenmodes. Variance
analysis further quantifies the spreading of excitation as functions of
interatomic spacing and global chirality, showing tunable
localization-delocalization transitions. Including nonguided losses, we find
that the transport characteristics remain robust for realistic coupling
efficiencies (beta >= 0.99). These results establish structured wQED as a
practical route to manipulate excitation localization, coherence, and transport
through programmable directionality patterns, paving the way for controllable
subradiant transport and chiral quantum information routing.

</details>


### [109] [Room-Temperature Quantum Simulation with Atomically Thin Nuclear Spin Layers in Diamond](https://arxiv.org/abs/2510.27374)
*Philipp J. Vetter,Christoph Findler,Antonio Verdú,Matthias Kost,Rémi Blinder,Jens Fuhrmann,Christian Osterkamp,Johannes Lang,Martin B. Plenio,Javier Prior,Fedor Jelezko*

Main category: quant-ph

TL;DR: 实现了基于金刚石中碳-13核自旋层的室温量子模拟器，用于研究强关联多体效应


<details>
  <summary>Details</summary>
Motivation: 现有量子模拟平台通常复杂且成本高昂，需要超纯真空或低温环境，限制了可扩展性和应用范围

Method: 利用金刚石中的氮空位中心和射频场，实现对碳-13核自旋层的极化、读取和相干控制

Result: 展示了核自旋之间的强可调相互作用，并成功研究了离散时间晶体序

Conclusion: 该系统在环境温度下运行且易于使用，为研究强关联多体效应开辟了新途径

Abstract: Quantum simulation aims to recreate complex many-body phenomena in controlled
environments, offering insights into dynamics that are otherwise difficult to
model. Existing platforms, however, are often complex and costly to scale,
typically requiring ultra-pure vacuum or low temperatures. Here, we realize a
room-temperature quantum simulator using a thin ${}^{13}\text{C}$ nuclear spin
layer in diamond. Nearby nitrogen-vacancy centers enable polarization, readout,
and, combined with radio-frequency fields, coherent control of the nuclear
spins. We demonstrate strong, tunable interactions among the nuclear spins and
use the system to investigate discrete time-crystalline order. By combining
ease of use with operation at ambient temperatures, our work opens new
opportunities for investigating strongly correlated many-body effects.

</details>


### [110] [Revisiting quantum walk advantages: A mean hitting time perspective](https://arxiv.org/abs/2510.27377)
*Jan Wójcik*

Main category: quant-ph

TL;DR: 本文提出用平均击中时间(MHT)作为量子随机行走和经典随机行走比较的新指标，发现在对称初始条件下两者MHT相同，而引入随机重置后量子行走能降低MHT，这可以作为量子行为的新特征。


<details>
  <summary>Details</summary>
Motivation: 传统使用均方位移(MSD)比较量子与经典随机行走存在局限，因为MSD适合高斯分布而量子行走分布是非高斯的。需要寻找具有明确操作意义的新指标来更全面理解量子优势。

Method: 通过解析计算分析量子与经典随机行走的平均击中时间，特别研究了在随机重置条件下的动力学行为，并考察噪声对量子优势的影响。

Result: 在对称初始条件下，量子与经典行走的MHT相同；引入随机重置后，量子行走通过准动量重分布能降低MHT，而经典行走无此优势；量子优势随噪声增加而退化。

Conclusion: 不同指标能揭示量子-经典比较的不同方面，MHT在随机重置下的降低可作为量子行为的新特征，特别适用于噪声量子设备上量子行走实现的表征。

Abstract: The mean squared displacement has been widely used as the primary metric for
comparing quantum and classical random walks, with quantum walks showing
quadratic scaling versus linear scaling for classical walks. However, this
comparison may not capture the full picture: while the mean squared
displacement is well-suited for Gaussian distributions, quantum walk
distributions exhibit distinctly non-Gaussian features. We propose that the
mean hitting time offers a complementary perspective with clear operational
meaning for search algorithms. Through analytical calculations, we show that
quantum and classical walks yield identical MHT for symmetric initial
conditions with two detectors, suggesting that the apparent quantum advantage
seen in MSD comparisons may be context-dependent. Interestingly, introducing
stochastic resetting reveals new dynamics. We demonstrate analytically that
quantum walks can achieve reduced MHT under stochastic reset through
quasi-momentum redistribution, while classical walks see no benefit. This
quantum advantage naturally degrades with noise, the quantum walk converges to
classical behavior. We suggest that MHT reduction under stochastic reset can
serve as an additional signature of quantum behavior, particularly useful for
characterizing quantum walk implementations on noisy quantum devices. Our
results indicate that different metrics can reveal different aspects of
quantum-classical comparisons in walk-based algorithms.

</details>


### [111] [Complete characterization of beam deflection based on double weak value amplification system](https://arxiv.org/abs/2510.27398)
*Yu Wang,Rongguo Yang,Jing Zhang,Xiaomin Liu,Chenzhen Luo,Kui Liu,Jiangrui Gao*

Main category: quant-ph

TL;DR: 本文提出了一种基于Hermite-Gaussian后选择双弱值系统的高精度光束偏转二维测量方法，能够同时独立测量偏航角和俯仰角，达到皮弧度级别的测量精度。


<details>
  <summary>Details</summary>
Motivation: 空间姿态参数的精确测量在惯性导航、工业监测、仪器校准和量子计量等领域至关重要，现有方法难以实现高精度的二维光束偏转同时测量。

Method: 采用Hermite-Gaussian后选择双弱值系统，结合两套高阶模式平衡零差探测系统，分别从系统的两个暗端口独立测量TEM10和TEM01模式中的偏航角和俯仰角信号。

Result: 实现了偏航角83 prad和俯仰角89 prad的最小可测量角度，对应的位移分别为0.79 pm和0.85 pm。

Conclusion: 该工作将光束偏转测量扩展到二维，为未来高精度多参数空间精密检测提供了新的思路。

Abstract: The precise measurement of spatial attitude parameters is critical for
applications in inertial navigation, industrial monitoring, instrument
calibration, quantum metrology, etc. In this work, we theoretically investigate
and experimentally realize the simultaneous measurement of the yaw and pitch
angles using a Hermite-Gaussian-postselected double weak value system
integrated with two sets of high-order-mode balanced homodyne detections,
thereby achieving a complete characterization of the beam deflection. Signals
of the yaw and pitch angles that are involved in TEM$_{10}$ and TEM$_{01}$
modes output from two dark ports of the system can be measured independently.
As a result, the obtained minimum measurable yaw and pitch angles of beam
deflection are 83 prad and 89 prad, respectively. Meanwhile, the corresponding
displacements are 0.79 pm and 0.85 pm, respectively. This work expands the beam
deflection measurement to two dimensions, which provides a new insight for
future high-precision multi-parameter spatial precise detection.

</details>


### [112] [Quantum Secret Sharing Scheme on Hypercyclic Quantum Structures](https://arxiv.org/abs/2510.27466)
*Lei Li,Zhi Li*

Main category: quant-ph

TL;DR: 该论文研究了基于三超边超图的量子访问结构的高效量子秘密共享方案构建，证明了12种非同构类型的超循环量子访问结构，并构建了具有最优信息率的经典完美秘密共享方案，最终实现了效率最高的量子秘密共享方案。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经为三超边超星访问结构构建了高效的量子秘密共享方案，但对于三超边超循环访问结构，现有方法无法获得具有最优信息率的经典完美秘密共享方案。本文旨在解决这一问题。

Method: 结合Simmons的几何方法和Shamir的阈值方案，为三超边超循环访问结构显式构建具有最优信息率的经典完美秘密共享方案，然后使用d维量子系统中的单光子在这些经典构造基础上构建完美量子秘密共享方案。

Result: 成功构建了12种非同构类型的超循环量子访问结构，这些结构包含了所有四类三超边超星结构，并证明了所构建的量子秘密共享方案在现有解决方案中达到了最高效率。

Conclusion: 本文提出的方法能够为三超边超循环量子访问结构构建具有最优信息率的完美量子秘密共享方案，这些方案在效率上优于现有解决方案，为量子秘密共享领域提供了新的理论框架和实用构造。

Abstract: This paper investigates the construction of efficient quantum secret sharing
schemes for quantum access structures based on hypergraphs with three
hyperedges. We prove that hypercycles with three hyperedges are quantum access
structures if and only if they can be classified into 12 non-isomorphic types
under hypergraph isomorphism, and these hypercyclic quantum access structures
encompass all four hyperstars with three hyperedges.In prior work, efficient
and perfect quantum secret sharing schemes were constructed for hyperstar
access structures with three hyperedges using single photons in d -dimensional
quantum systems. These schemes correspond to classical perfect secret sharing
schemes with optimal information rates. However, for hypercyclic access
structures with three hyperedges, the method described above fails to yield
classical perfect secret sharing schemes with optimal information rates. In
this work, we explicitly construct classical perfect secret sharing schemes
with optimal information rates for these access structures by combining
Simmons' geometric method with Shamir's threshold scheme. Subsequently, we
employ single photons in d-dimensional quantum systems to build perfect QSS
schemes upon these classical constructions.We introduce the concept of
idealized information rate for minimal access structures in perfect QSS
schemes. By extending the notion of efficiency proposed by Cabello [Phys. Rev.
Lett., vol. 85, no. 26, p. 5635, 2000] for quantum key distribution protocols
to QSS, we define the efficiency of minimally authorized subsets. Furthermore,
we establish the relationship between the efficiency of minimally authorized
subsets and the idealized information rate of minimal access structures.
Finally, we rigorously prove that the QSS schemes constructed in this work
achieve the highest efficiency among existing solutions.

</details>


### [113] [Auxiliary-state facilitated phase synchronization phenomena in isolated spin systems](https://arxiv.org/abs/2510.27472)
*Xylo Molenda,S. Zhong,B. Viswanathan,Xingli Li,Y. Yan,A. M. Marino,D. Blume*

Main category: quant-ph

TL;DR: 该研究通过将三个无限寿命量子态与有限寿命激发态耦合，构建了有效自旋-1系统，并发现相位同步可以通过调节耦合相位来控制，且完全由有效耗散器主导。


<details>
  <summary>Details</summary>
Motivation: 将经典同步扩展到量子领域对基础物理和量子技术应用具有重要意义。

Method: 通过耦合无限寿命量子态与有限寿命激发态，构建有效自旋-1模型，包含相干和不相干有效耦合，并与全希尔伯特空间的主方程计算进行基准比较。

Result: 发现相位同步可由耦合相位控制，且与文献中的典型自旋-1系统不同，该系统受限于进入和离开极限环状态的耗散衰减竞争，离开极限环的耗散衰减起关键作用。

Conclusion: 在无相干有效耦合时，有效自旋-1系统的相位同步完全由有效耗散器主导，这一发现在广泛的能级和耦合方案中具有普适性，并通过$^{87}$Rb的超精细态得到验证。

Abstract: Extending classical synchronization to the quantum domain is of great
interest both from the fundamental physics point of view and with a view toward
quantum technology applications. This work characterizes phase synchronization
of an effective spin-1 system, which is realized by coupling three quantum
states with infinite lifetime to auxiliary excited states that have a finite
lifetime. Integrating out the excited states, the effective spin-1 model
features coherent and incoherent effective couplings. Our key findings are: (i)
Phase synchronization can be controlled by adjusting the phases of the
couplings to the excited states. (ii) Unlike in the paradigmatic spin-1 system
studied in the literature, where the dissipative couplings describe decay into
the limit cycle state, the effective spin-1 model investigated in this work is
governed by a competition between dissipative decay into and out of the limit
cycle state, with the dissipative decay out of the limit cycle state playing a
critical role. (iii) We identify a parameter regime where phase synchronization
of the effective spin-1 system is -- in the absence of coherent effective
couplings -- governed entirely by the effective dissipators. The effective
spin-1 model is benchmarked through comparisons with master equation
calculations for the full Hilbert space. Physical insights are gained through
analytical perturbation theory calculations. Our findings, which are expected
to hold for a broad class of energy level and coupling schemes, are
demonstrated using hyperfine states of $^{87}$Rb.

</details>


### [114] [The role of entanglement in energy-restricted communication and randomness generation](https://arxiv.org/abs/2510.27473)
*Carles Roch I Carceller,Armin Tavakoli*

Main category: quant-ph

TL;DR: 该论文研究了在能量受限的制备-测量实验中共享纠缠的作用，发现纠缠在经典通信中可能不是资源，而在量子通信中需要通过非酉编码方案才能解锁纠缠优势，且高维纠缠能增强这种优势。


<details>
  <summary>Details</summary>
Motivation: 研究在能量受限的制备-测量量子信息场景中，共享纠缠是否以及如何成为有用资源，特别是在半设备无关的量子通信和随机数生成应用中。

Method: 推导了经典通信中非局域资源的通用相关性判据，分析了量子通信中概率比特传输的基本原语，研究了非酉编码方案对纠缠优势的影响，并探讨了高维纠缠的作用。

Result: 发现纠缠在经典通信中可能不是资源；在量子通信中，只有通过非酉编码方案故意使纠缠态退相干才能解锁纠缠优势；高维纠缠能增强这些优势；在低能量状态下，量子随机数生成协议的安全性基本保持完整。

Conclusion: 在能量受限的量子通信中，纠缠优势需要特定的编码策略才能实现，高维纠缠能提供更多优势，这些发现为在不增加复杂性的情况下增强量子随机数生成的安全性提供了途径。

Abstract: A promising platform for semi-device-independent quantum information is
prepare-and-measure experiments restricted only by a bound on the energy of the
communication. Here, we investigate the role of shared entanglement in such
scenarios. For classical communication, we derive a general correlation
criterion for nonlocal resources and use it to show that entanglement can fail
to be a resource in standard tasks. For quantum communication, we consider the
basic primitive for energy-constrained communication, namely the probabilistic
transmission of a bit, and show that the advantages of entanglement only can be
unlocked by non-unitary encoding schemes that purposefully decohere the
entangled state. We also find that these advantages can be increased by using
entanglement of higher dimension than qubit. We leverage these insights to
investigate the impact of entanglement for quantum random number generation,
which is a standard application of these systems but whose security so far only
has been established against classical side information. In the low-energy
regime, our attacks on the protocol indicate that the security remains largely
intact, thereby paving the way for strengthened security without more complex
setups and with negligible performance reductions.

</details>


### [115] [Area-Law Entanglement in Quantum Chaotic System](https://arxiv.org/abs/2510.27511)
*Chunyin Chen,Sizhe Yan,Biao WU*

Main category: quant-ph

TL;DR: 本文发现了一个违反直觉的现象：尽管具有混沌系统的特征（如Wigner-Dyson能级统计和局域热化），但受Floquet驱动的Rydberg阻塞量子多体系统的所有本征态都严格遵循面积律纠缠熵，且熵值上限为ln2，与系统尺寸无关。


<details>
  <summary>Details</summary>
Motivation: 纠缠熵通常被认为是量子混沌的关键诊断工具，在混沌多体系统的高激发本征态中通常呈现体积律标度。本文旨在寻找违反这一常规认知的反例，探索希尔伯特空间几何结构对量子动力学和热化的深刻影响。

Method: 通过Floquet驱动的Rydberg类阻塞量子多体系统，结合约束希尔伯特空间结构分析。建立了约束多体哈密顿量与中值图上单粒子量子行走之间的对偶关系，并提出了构造具有预定常数纠缠熵上限系统的通用方法。

Result: 发现了严格面积律纠缠熵的混沌系统，所有Floquet本征态的纠缠熵都严格有界于ln2。证明了希尔伯特空间结构对纠缠熵的约束作用，以及二分截面上Schmidt秩的限制是这一现象的根本原因。

Conclusion: 纠缠熵单独不足以诊断多体量子混沌，希尔伯特空间几何对量子动力学和热化具有深远影响。这一发现挑战了传统对量子混沌与纠缠熵关系的理解，为设计具有可控纠缠特性的量子系统提供了新思路。

Abstract: Entanglement entropy is a fundamental diagnostic for quantum chaos, typically
exhibiting volume-law scaling in highly excited eigenstates of chaotic
many-body systems. In this work, we present a striking counterexample: a
Floquet-driven quantum many-body system with Rydberg-like blockade that,
despite being fully chaotic as indicated by its Wigner-Dyson level statistics
and local thermalization, exhibits a strict area-law entanglement entropy.
Specifically, the entanglement entropy of every Floquet eigenstate is bounded
by $\ln2$, independent of system size. We trace this anomaly to the specific
Hilbert space structure imposed by the blockades, which restricts the Schmidt
rank across a bipartition. Furthermore, we generalize this discovery by
establishing a duality between constrained many-body Hamiltonians and
single-particle quantum walks on median graphs, and we outline a general
procedure for constructing systems with an entanglement entropy bounded by a
predetermined constant. Our results demonstrate that entanglement entropy alone
is an insufficient diagnostic of many-body quantum chaos and highlight the
profound impact of Hilbert space geometry on quantum dynamics and
thermalization.

</details>


### [116] [Experimental Quantum Channel Purification](https://arxiv.org/abs/2510.27534)
*Yue-Yang Fei,Zhenhuan Liu,Rui Zhang,Zhenyu Cai,Xu-Fei Yin,Yingqiu Mao,Li Li,Nai-Le Liu,Yu-Ao Chen,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 实验演示了利用光子空间和偏振特性进行高效信道净化的方法，通过两个Fredkin门实现独立噪声信道的相干干涉，有效抑制多种噪声并保持纠缠分布。


<details>
  <summary>Details</summary>
Motivation: 量子网络对分布式量子信息处理至关重要，但信道噪声是固有弱点。信道净化技术无需复杂编解码操作即可抑制噪声，特别适合光学系统中的远程量子信息传输。

Method: 利用光子的空间和偏振特性设计实验装置，采用两个Fredkin门实现独立噪声信道间的相干干涉，实现宽范围噪声类型和水平的有效抑制。

Result: 在纠缠分布应用中，该协议展现出比传统纠缠净化方法更强的抗信道噪声能力，能更好地保持纠缠。

Conclusion: 该实验装置为量子信道净化提供了高效解决方案，在量子网络中具有重要应用价值。

Abstract: Quantum networks, which integrate multiple quantum computers and the channels
connecting them, are crucial for distributed quantum information processing but
remain inherently susceptible to channel noise. Channel purification emerges as
a promising technique for suppressing noise in quantum channels without complex
encoding and decoding operations, making it particularly suitable for remote
quantum information transmission in optical systems. In this work, we introduce
an experimental setup for efficient channel purification, harnessing the
spatial and polarization properties of photons. Our design employs two Fredkin
gates to enable coherent interference between independent noise channels,
achieving effective noise suppression across a wide range of noise levels and
types. Through application to entanglement distribution, our protocol
demonstrates a superior capability to preserve entanglement against channel
noise compared to conventional entanglement purification methods.

</details>


### [117] [Entanglement in the energy-constrained prepare-and-measure scenario: applications to randomness certification and channel discrimination](https://arxiv.org/abs/2510.27559)
*Raffaele D'Avino,Gabriel Senno,Mir Alimuddin,Antonio Acín*

Main category: quant-ph

TL;DR: 在能量约束的半设备无关框架下，允许制备和测量设备之间存在纠缠会严格扩大可实现的关联集合，这对随机性认证和量子通道区分任务产生重要影响。


<details>
  <summary>Details</summary>
Motivation: 量子信息任务通常在不同设备信任假设下进行分析。半设备无关框架在所需假设和实验可行性之间提供了平衡，但之前的研究仅限于经典相关的设备。

Method: 研究能量约束的半设备无关场景，其中唯一假设是制备的量子态能量上限。与之前限制设备为经典相关的研究不同，本研究允许纠缠策略。

Result: 允许纠缠严格扩大了可实现的关联集合。在随机性认证中，纠缠策略可能显著减少可认证的随机性；在量子通道区分中，已知的与维度无关的纠缠优势界限在能量约束下被违反。

Conclusion: 纠缠在能量约束的半设备无关场景中具有显著影响，需要在量子信息协议的安全分析中考虑纠缠策略的潜在威胁。

Abstract: Quantum information tasks are often analyzed under varying trust assumptions
about the devices involved. The semi-device-independent (SDI) framework offers
a balance between needed assumptions and experimental feasibility. In this
work, we study the energy-constrained SDI scenario, where the only assumption
in a prepare-and-measure setup is an upper bound on the energy of the prepared
quantum states. In contrast to previous studies that restricted the preparation
and measurement devices to be classically correlated, we show that allowing
entanglement strictly enlarges the set of achievable correlations. We identify
two operational consequences of this result. The first concerns randomness
certification, where we show that allowing the adversary to employ entangled
strategies may significantly reduce the amount of certifiable randomness. This
includes situations where the amount of randomness drops to zero in the
presence of entanglement, while it remains positive when entanglement is
excluded. Second, for the task of distinguishing an arbitrary quantum channel
from the identity, we show that the known dimension-independent bound on the
advantage conferred by entanglement is violated under an energy constraint.

</details>


### [118] [Quantum interference effects in two-photon scattering by a macroscopic lossy sphere](https://arxiv.org/abs/2510.27612)
*A. Ciattoni*

Main category: quant-ph

TL;DR: 研究双光子波包在宏观有耗球体中的量子光学散射，分析非共线入射光子产生的干涉效应，以及米氏共振对量子干涉的影响。


<details>
  <summary>Details</summary>
Motivation: 研究有耗介质中双光子散射的量子干涉现象，特别是非共线入射条件下不同量子路径产生的干涉效应，以及物质色散/损耗对量子干涉的影响。

Method: 采用宏观量子电动力学中的修正朗之万噪声形式论，分析双光子波包在宏观有耗球体中的散射过程，包括两个、一个和零个出射光子的三种独立过程。

Result: 发现非共线入射光子存在两条不同的量子路径，产生干涉效应；米氏共振峰由于其Fano-like特性，在共振频率和Fano凹陷频率处分别产生强构造性和破坏性干涉；散射概率对输入波包谱对称性极其敏感。

Conclusion: 有耗介质中的双光子散射过程能够产生显著的量子干涉效应，特别是米氏共振频率处的干涉效应对波包谱对称性高度敏感，这为识别纠缠提供了一种有效的谱技术手段。

Abstract: We investigate the quantum optical scattering of two-photon wavepackets by a
macroscopic lossy sphere by means of macroscopic quantum electrodynamics in the
form of modified Langevin noise formalism. The two ingoing photons with
arbitrary frequency-polarization spectrum impinge onto the sphere along two
different directions and, as consequence of matter losses, their scattering
involves the three independent processes where two, one and zero outgoing
photons survive. Non-collinearity of ingoing photons causes the existence of
two different quantum paths they can follow upon scattering, this producing
interference effects in the detection of the above three processes which is
governed by the wavepacket spectral symmetry. By exploiting rotational
invariance, we show that different classes of scattering geometries exist such
that the coincidence detection of the scattered photons shows perfect
constructive or destructive (Hong-Ou-Mandel) interference, both for symmetric
and antisymmetric wavepackets. To assess the impact of matter dispersion/losses
on quantum interference effects accompanying photons detection, we analyze the
scattering of narrow band two-photon wavepackets by high-index dielectric lossy
spheres. We show that classical Mie resonance peaks, due to their Fano-like
traits, yield very strong constructive and destructive interference effects,
occurring when the wavepacket carrier frequency matches the resonance frequency
and side Fano dip frequency, respectively. In addition we consider the overall
scattering probabilities of two, one and zero photons and we prove that, at the
Mie resonance frequencies, they exhibit quantum interference effects which are
extremely sensitive to the spectral symmetry of the input wavepacket, thus
suggesting an efficient spectral technique assisted by matter losses to
identify entanglement.

</details>


### [119] [Directional quantum scattering transducer in cooperative Rydberg metasurfaces](https://arxiv.org/abs/2510.27654)
*Jonas von Milczewski,Kelly Werker Smith,Susanne F. Yelin*

Main category: quant-ph

TL;DR: 提出了一种使用四波混频和量子散射的单光子转换方案，通过平面合作性里德堡阵列实现高效、高方向性的太赫兹到光学转换。


<details>
  <summary>Details</summary>
Motivation: 开发一种量子相干太赫兹检测和处理技术，用于天文光谱学、量子网络稀疏孔径成像等量子传感应用。

Method: 采用四波混频方案，两个激光器驱动系统，通过光子介导的偶极-偶极相互作用产生集体超/亚辐射偶极模式，在特定临界条件下将信号光子转换为高度定向的光学光子。

Result: 对于无限晶格，预测特定空间方向的转换效率高达50%，有限阵列的输出被准直成随1/√N变窄的波瓣。

Conclusion: 该方案结合了自由空间四波混频的宽带接受度与合作性超表面的效率、方向性和可调谐性，为量子相干太赫兹检测提供了可行途径。

Abstract: We present a single-photon transduction scheme using 4-wave-mixing and
quantum scattering in planar, cooperative Rydberg arrays that is both efficient
and highly directional and may allow for terahertz-to-optical transduction. In
the 4-wave-mixing scheme, two lasers drive the system, coherently trapping the
system in a dark ground-state and coupling a signal transition, that may be in
the terahertz, to an idler transition that may be in the optical. The
photon-mediated dipole-dipole interactions between emitters generate collective
super-/subradiant dipolar modes, both on the signal and the idler transition.
As the array is cooperative with respect to the signal transition, an incident
signal photon can efficiently couple into the array and is admixed into dipolar
idler modes by the drive. Under specific criticality conditions, this admixture
is into a superradiant idler mode which primarily decays into a specific,
highly directional optical photon that propagates within the array plane.
Outside of the array, this photon may then be coupled into existing quantum
devices for further processing. Using a scattering-operator formalism we derive
resonance and criticality conditions that govern this two-step process and
obtain analytic transduction efficiencies. For infinite lattices, we predict
transduction efficiencies into specific spatial directions of up to 50%, while
the overall, undirected transduction efficiency can be higher. An analysis for
finite arrays of $N^2$ emitters, shows that the output is collimated into lobes
that narrow as $1/\sqrt{N}$. Our scheme combines the broadband acceptance of
free-space 4-wave mixing with the efficiency, directionality and tunability of
cooperative metasurfaces, offering a route towards quantum-coherent THz
detection and processing for astronomical spectroscopy, quantum-networked
sparse-aperture imaging and other quantum-sensing applications.

</details>


### [120] [Probing non-equilibrium physics through the two-body Bell correlator](https://arxiv.org/abs/2510.27657)
*Abhishek Muhuri,Tanoy Kanti Konar,Leela Ganesh Chandra Lakkaraju,Aditi Sen De*

Main category: quant-ph

TL;DR: 该论文发现两体贝尔算符可作为长程XY自旋链中动力学量子相变(DQPT)的有效见证者，在临界边界处表现出明显下降，而传统关联度量无法检测这种转变。


<details>
  <summary>Details</summary>
Motivation: 基于局部可观测量识别动力学量子相变(DQPT)具有挑战性，需要寻找有效的非局域关联见证者来检测临界行为。

Method: 在长程XY自旋链中，通过突然淬灭磁场强度和相互作用衰减率两种协议，研究最近邻自旋间的贝尔算符行为。

Result: 贝尔算符在临界边界处显示出明显下降，定义了区分相内和相间淬灭的阈值，且不受长程相互作用强度、各向异性和系统尺寸影响。

Conclusion: 两体贝尔算符是检测DQPT的有效工具，优于传统经典和量子关联度量，为识别动力学临界性提供了新方法。

Abstract: Identifying equilibrium criticalities and phases from the dynamics of a
system, known as a dynamical quantum phase transition (DQPT), is a challenging
task when relying solely on local observables. We exhibit that the
experimentally accessible two-body Bell operator, originally designed to detect
nonlocal correlations in quantum states, serves as an effective witness of
DQPTs in a long-range (LR) XY spin chain subjected to a magnetic field, where
the interaction strength decays as a power law. Following a sudden quench of
the system parameters, the Bell operator between nearest-neighbor spins
exhibits a distinct drop at the critical boundaries. In this study, we consider
two quenching protocols, namely sudden quenches of the magnetic field strength
and the interaction fall-off rate. This pronounced behavior defines a
threshold, distinguishing intra-phase from inter-phase quenches, remaining
valid regardless of the strength of long-range interactions, anisotropy, and
system sizes. Comparative analyses further demonstrate that conventional
classical and quantum correlators, including entanglement, fail to capture this
transition during dynamics.

</details>


### [121] [Teleportation-based squeezer for bosonic cluster states](https://arxiv.org/abs/2510.27661)
*Michal Matulík,Radim Filip,Petr Marek*

Main category: quant-ph

TL;DR: 本文提出了在簇态架构中实现最优压缩门的新方法，通过使用非平衡分束器的幅度透射系数和零差检测配合单位增益前馈来压缩输入态，性能优于当前基于固定平衡分束器和最优旋转零差检测的方法。


<details>
  <summary>Details</summary>
Motivation: 基于光玻色模式的单向量子计算具有无与伦比的可扩展性，但需要稳健低误差的门和测量操作。压缩门是必要的Gaussian操作之一，需要在簇态架构中寻找最优实现方案。

Method: 新方法利用非平衡分束器的幅度透射系数，结合零差检测和单位增益前馈操作来压缩输入态，与基于固定平衡分束器和最优旋转零差检测的现有方法进行对比。

Result: 新方法在性能上优于现有方法，对Gaussian和非Gaussian输入态都进行了评估，使用多种指标来基准测试压缩输出态的质量。

Conclusion: 该结果为在实验可实现的簇态中实现低噪声压缩门开辟了道路。

Abstract: The one-way quantum computation utilizing bosonic modes of light offers
unmatched scalability of light modes, and it has seen rapid experimental
development recently. Scalability requires robust and low-error gates and
measurements. Squeezing gate is one of the necessary Gaussian operations. We
find the optimal squeezing gate in cluster state architecture. Our approach
newly uses amplitude transmission coefficients of unbalanced beam splitters and
homodyne detection with subsequent unity-gain feed-forward to squeeze the input
state. The approach outperforms the current method based on optimally rotated
homodyne detection, but with fixed balanced beam splitters. The performance of
both cluster state squeezers is evaluated for Gaussian and non-Gaussian input
states. We use different metrics to benchmark the quality of squeezed output
states. The result opens a road to low-noise squeezing gates in experimentally
achievable cluster states.

</details>


### [122] [Quantum waste management: Utilizing residual states in quantum information processing](https://arxiv.org/abs/2510.27687)
*Karol Horodecki,Chirag Srivastava,Leonard Sikorski,Siddhartha Das*

Main category: quant-ph

TL;DR: 提出量子残差管理框架，将资源蒸馏过程后丢弃的状态重新用作后续量子信息任务的输入，提高整体资源利用率。以量子密钥分发后的残差状态提取私有随机性为例进行验证。


<details>
  <summary>Details</summary>
Motivation: 传统量子资源理论中，资源蒸馏过程后丢弃的状态未被充分利用。本文旨在通过二次资源提取来增强整体资源效用，提高量子资源在顺序信息处理任务中的利用率。

Method: 建立量子残差管理框架，将残差状态作为后续量子信息任务的输入。具体研究了从量子密钥分发（QKD）协议（如Devetak-Winter协议和Gottesman-Lo协议）的残差状态中本地提取私有随机性。

Result: 定量证明了在Devetak-Winter协议后可以从残差状态中本地提取私有随机性，并为Gottesman-Lo QKD协议提供了从丢弃状态中提取私有随机性的可实现速率。

Conclusion: 量子残差管理框架提供了一种通用原则，能够显著提高量子资源在顺序信息处理任务中的整体利用率，通过二次资源提取增强传统量子资源理论。

Abstract: We propose a framework for quantum residual management, in which states
discarded after a resource distillation process are repurposed as inputs for
subsequent quantum information tasks. This approach extends conventional
quantum resource theories by incorporating secondary resource extraction from
residual states, thereby enhancing overall resource utility. As a concrete
example, we investigate the distillation of private randomness from the
residual states remaining after quantum key distribution (QKD). More
specifically, we quantitatively show that after performing a well-known
coherent Devetak-Winter protocol one can locally extract private randomness
from its residual. We further consider the Gottesman-Lo QKD protocol, and
provide the achievable rate of private randomness from the discarded states
that are left after its performance. We also provide a formal framework that
highlights a general principle for improving quantum resource utilization
across sequential information processing tasks.

</details>
