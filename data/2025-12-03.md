<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 53]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [gr-qc](#gr-qc) [Total: 17]
- [cs.LG](#cs.LG) [Total: 70]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Improved Ising Meson Spectroscopy Simulation on a Noisy Digital Quantum Device](https://arxiv.org/abs/2512.02516)
*Hao-Ti Hung,Isabel Nha Minh Le,Johannes Knolle,Ying-Jer Kao*

Main category: quant-ph

TL;DR: 该论文展示了在IBM量子设备上使用两种误差弹性电路构造技术改进受限激发的光谱学，成功识别了E8对称性的关键特征。


<details>
  <summary>Details</summary>
Motivation: 横向场伊辛模型是研究约束和激发谱的范例，但验证E8对称性所需的伊辛介子光谱学在近期量子硬件上具有挑战性，因为实时演化需要较深的电路。

Method: 使用两种误差弹性电路构造技术：1）利用原生分数门的一阶Trotter分解；2）通过黎曼优化的张量网络电路压缩。分析误差缓解的时间序列数据的傅里叶谱。

Result: 成功识别了E8对称性的关键特征，尽管存在硬件噪声。验证了电路压缩和硬件高效编译在NISQ设备上探测复杂拓扑现象的可行性。

Conclusion: 两种电路构造技术都能有效改进受限激发的光谱学，为在噪声量子硬件上研究复杂对称性提供了可行方案。

Abstract: The transverse-field Ising model serves as a paradigm for studying confinement and excitation spectra, particularly the emergence of $E_8$ symmetry near criticality. However, experimentally resolving the Ising meson spectroscopy required to verify these symmetries is challenging on near-term quantum hardware due to the depth of circuits required for real-time evolution. Here, we demonstrate improved spectroscopy of confined excitations using two distinct error-resilient circuit construction techniques on the IBM Torino device: first-order Trotter decomposition utilizing native fractional gates, and a tensor-network-based circuit compression via Riemannian optimization. By analyzing the Fourier spectrum of error-mitigated time-series data, we successfully identify key signatures of $E_8$ symmetry despite hardware noise. These results validate the viability of both circuit compression and hardware-efficient compilation for probing complex topological phenomena on NISQ devices.

</details>


### [2] [Efficient Simulation of the 2D Hubbard Model via Hilbert Space-Filling Curve Mapping](https://arxiv.org/abs/2512.02666)
*Ashkan Abedi,Vittorio Giovannetti,Dario De Santis*

Main category: quant-ph

TL;DR: 使用希尔伯特曲线将二维Hubbard模型映射到一维链，通过保持空间局部性来最小化有效相互作用范围，相比传统蛇形映射能获得更紧凑的矩阵乘积态表示，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统张量网络方法在模拟二维强关联量子系统时面临计算复杂度高的挑战，需要寻找更高效的映射方法来扩展可模拟的系统规模。

Method: 采用空间填充曲线（特别是希尔伯特曲线）将二维晶格映射到一维链，利用其保持局部性的结构最小化映射后模型的有效相互作用范围，实现更紧凑的矩阵乘积态表示。

Result: 希尔伯特曲线映射在固定键维度下能获得更低的基态能量，优势随系统尺寸增大和在物理相关相互作用区域增强；成功模拟了32×32格点系统，计算结果与已有结果一致但计算成本显著降低。

Conclusion: 空间填充曲线映射（特别是希尔伯特曲线）是扩展二维强关联量子系统张量网络研究的强大工具，能够超越标准方法可访问的极限。

Abstract: We investigate tensor network simulations of the two-dimensional Hubbard model by mapping the lattice onto a one-dimensional chain using space-filling curves. In particular, we focus on the Hilbert curve, whose locality-preserving structure minimizes the range of effective interactions in the mapped model. This enables a more compact matrix product state (MPS) representation compared to conventional snake mapping. Through systematic benchmarks, we show that the Hilbert curve consistently yields lower ground-state energies at fixed bond dimension, with the advantage increasing for larger system sizes and in physically relevant interaction regimes. Our implementation reaches clusters up to $32\times32$ sites with open and periodic boundary conditions, delivering reliable ground-state energies and correlation functions in agreement with established results, but at significantly reduced computational cost. These findings establish space-filling curve mappings, particularly the Hilbert curve, as a powerful tool for extending tensor-network studies of strongly correlated two-dimensional quantum systems beyond the limits accessible with standard approaches.

</details>


### [3] [Dispersion Outperforms Absorption: EIT-Enhanced Atomic Localization and Gradient Sensing with Super-Gaussian Beams](https://arxiv.org/abs/2512.02063)
*Mahboob Ul Haq*

Main category: quant-ph

TL;DR: EIT方法在四能级三脚架系统中比吸收法具有显著优势，梯度灵敏度提高一个数量级，空间分辨率达到亚衍射极限，边缘对比度和定位精度更高。


<details>
  <summary>Details</summary>
Motivation: 为了在原子梯度传感领域对吸收法和电磁感应透明（EIT）方法进行公平的理论比较，指导下一代光学和量子计量系统的设计。

Method: 在四能级三脚架系统中，在相同且优化的物理条件下，对吸收法和EIT方法进行理论比较分析，评估不同超高斯光束轮廓下的性能。

Result: EIT方法凭借其陡峭的色散响应，在梯度灵敏度上比吸收法提高一个数量级，即使在相同失谐下也有两倍优势；两种方法都达到0.29λ-0.40λ的亚衍射空间分辨率，但EIT具有更锐利的边缘对比度和更高的定位精度。

Conclusion: EIT是原子梯度传感和亚波长定位的根本优越方法，为下一代光学和量子计量系统的设计提供了明确指导。

Abstract: This work presents a comprehensive theoretical comparison between absorption-based and electromagnetically induced transparency (EIT)-based atomic gradient sensing in a four-level tripod system. Both methods were evaluated under identical and optimized physical conditions to ensure a fair and unbiased comparison. The analysis demonstrates that EIT, driven by its steep dispersion response, consistently outperforms conventional absorption detection across a wide range of super-Gaussian beam profiles. Under optimal detuning, EIT achieved up to an order-of-magnitude enhancement in gradient sensitivity and maintained a twofold advantage even under identical detuning. Both approaches reached sub-diffraction spatial resolution in the range of 0.29lambda-0.40lambda, with EIT exhibiting sharper edge contrast and higher localization accuracy. These results confirm EIT as a fundamentally superior approach for precision atomic gradient sensing and sub-wavelength localization, offering clear guidance for the design of next-generation optical and quantum metrology systems.

</details>


### [4] [Quantum Machine Learning for Secondary Frequency Control](https://arxiv.org/abs/2512.02065)
*Younes Ghazagh Jahed,Alireza Khatiri*

Main category: quant-ph

TL;DR: 提出使用纯变分量子电路进行柴油发电机实时二次频率控制，相比传统方法和混合量子-经典模型具有延迟低、精度高的优势


<details>
  <summary>Details</summary>
Motivation: 传统频率控制方法（元启发式算法和机器学习）在实时性和可扩展性方面存在局限，混合量子-经典模型存在量子-经典数据交换延迟问题

Method: 使用纯变分量子电路独立运行，通过监督学习训练，将历史频率偏差映射到最优PI控制器参数（基于预计算查找表）

Result: VQC在足够量子测量次数下达到超过90%的预测精度，在不同测试事件中泛化能力强，量子优化的PI参数显著改善瞬态响应，减少频率波动和稳定时间

Conclusion: 纯变分量子电路为电力系统频率控制提供了一种实时、高效、可扩展的解决方案，消除了混合模型的延迟问题

Abstract: Frequency control in power systems is critical to maintaining stability and preventing blackouts. Traditional methods like meta-heuristic algorithms and machine learning face limitations in real-time applicability and scalability. This paper introduces a novel approach using a pure variational quantum circuit (VQC) for real-time secondary frequency control in diesel generators. Unlike hybrid classical-quantum models, the proposed VQC operates independently during execution, eliminating latency from classical-quantum data exchange. The VQC is trained via supervised learning to map historical frequency deviations to optimal Proportional-Integral (PI) controller parameters using a pre-computed lookup table. Simulations demonstrate that the VQC achieves high prediction accuracy (over 90%) with sufficient quantum measurement shots and generalizes well across diverse test events. The quantum-optimized PI parameters significantly improve transient response, reducing frequency fluctuations and settling time.

</details>


### [5] [Parallel Multi-Circuit Quantum Feature Fusion in Hybrid Quantum-Classical Convolutional Neural Networks for Breast Tumor Classification](https://arxiv.org/abs/2512.02066)
*Ece Yurtseven*

Main category: quant-ph

TL;DR: 提出混合量子-经典卷积神经网络用于乳腺癌图像分类，在参数匹配条件下量子模型显著优于经典模型


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习在医学影像高维数据特征提取和分类任务中的潜力，特别是在乳腺癌诊断这样的重要医疗应用领域

Method: 设计混合量子-经典CNN架构，结合经典卷积特征提取与两种量子电路（振幅编码VQC和角度编码VQC），生成量子特征嵌入并与经典特征融合，使用参数匹配的经典CNN作为基线进行公平比较

Result: 混合QCNN在五次独立运行中分类准确率显著优于经典CNN，Wilcoxon符号秩检验p=0.03125，Cohen's d效应量达2.14，表明量子层对性能提升有实质性贡献

Conclusion: 混合QCNN架构能够利用量子纠缠和特征融合增强医学图像分类，建立了量子模型在生物医学应用中的统计验证框架，为扩展到更大数据集和近期量子硬件部署指明了方向

Abstract: Quantum machine learning has emerged as a promising approach to improve feature extraction and classification tasks in high-dimensional data domains such as medical imaging. In this work, we present a hybrid Quantum-Classical Convolutional Neural Network (QCNN) architecture designed for the binary classification of the BreastMNIST dataset, a standardized benchmark for distinguishing between benign and malignant breast tumors. Our architecture integrates classical convolutional feature extraction with two distinct quantum circuits: an amplitude-encoding variational quantum circuit (VQC) and an angle-encoding VQC circuit with circular entanglement, both implemented on four qubits. These circuits generate quantum feature embeddings that are fused with classical features to form a joint feature space, which is subsequently processed by a fully connected classifier. To ensure fairness, the hybrid QCNN is parameter-matched against a baseline classical CNN, allowing us to isolate the contribution of quantum layers. Both models are trained under identical conditions using the Adam optimizer and binary cross-entropy loss. Experimental evaluation in five independent runs demonstrates that the hybrid QCNN achieves statistically significant improvements in classification accuracy compared to the classical CNN, as validated by a one-sided Wilcoxon signed rank test (p = 0.03125) and supported by large effect size of Cohen's d = 2.14. Our results indicate that hybrid QCNN architectures can leverage entanglement and quantum feature fusion to enhance medical image classification tasks. This work establishes a statistical validation framework for assessing hybrid quantum models in biomedical applications and highlights pathways for scaling to larger datasets and deployment on near-term quantum hardware.

</details>


### [6] [Geometric Optimization on Lie Groups: A Lie-Theoretic Explanation of Barren Plateau Mitigation for Variational Quantum Algorithms](https://arxiv.org/abs/2512.02078)
*Zhehao Yi,Rahul Bhadani*

Main category: quant-ph

TL;DR: 该论文提出使用神经网络生成量子电路参数可以避免训练中的"贫瘠高原"问题，通过几何视角分析参数演化路径，解释了神经网络辅助量子学习方法中观察到的改进可训练性。


<details>
  <summary>Details</summary>
Motivation: 贫瘠高原（训练梯度变得极小）是优化参数化量子电路的主要挑战，导致学习过程极其缓慢或停滞。需要找到克服这一困难的方法。

Method: 引入几何视角描述神经网络生成的量子电路参数在训练过程中的演化路径，分析这些参数如何遵循平滑高效的路径，避免导致贫瘠高原的平坦区域。

Result: 分析表明神经网络生成的参数遵循平滑高效的演化路径，能够避开训练中的平坦区域，这为神经网络辅助量子学习方法中观察到的改进可训练性提供了计算解释。

Conclusion: 研究结果连接了量子机器学习和计算优化的思想，为量子模型结构提供了新见解，并指导未来设计更具可训练性的量子电路或参数初始化方法。

Abstract: Barren plateaus, which means the training gradients become extremely small, pose a major challenge in optimizing parameterized quantum circuits, often making the learning process impractically slow or stall. This work shows why using neural networks to generate quantum circuit parameters helps overcome this difficulty. We introduce a geometric viewpoint that describes how the parameters produced by neural networks evolve during training. Our analysis shows that these parameters follow smooth and efficient paths that avoid the flat regions in the training that cause barren plateaus. This provides a computational explanation for the improved trainability observed in recent neural network-assisted quantum learning methods. Overall, our findings bridge ideas from quantum machine learning and computational optimization, offering new insight into the structure of quantum models and guiding future approaches for designing more trainable quantum circuits or parameter initialization.

</details>


### [7] [From Betti Numbers to Persistence Diagrams: A Hybrid Quantum Algorithm for Topological Data Analysis](https://arxiv.org/abs/2512.02081)
*Dong Liu*

Main category: quant-ph

TL;DR: 本文提出了一种量子-经典混合算法，首次实现了从"量子计算贝蒂数"到"量子获取实用持久图"的飞跃，通过利用LGZ量子算法提取特征，训练量子支持向量机学习拓扑特征到持久图的映射。


<details>
  <summary>Details</summary>
Motivation: 现有量子拓扑算法（如LGZ算法）只能高效计算贝蒂数等统计摘要，无法提供跟踪单个拓扑特征生命周期的持久图信息，严重限制了其实际应用价值。

Method: 利用LGZ量子算法作为高效特征提取器，挖掘组合拉普拉斯算子的调和形式特征向量和贝蒂数，构建专门的拓扑核函数训练量子支持向量机，学习从量子拓扑特征到持久图的映射。

Result: 实现了量子拓扑计算从统计摘要到模式识别的提升，在保持量子计算指数加速优势的同时，以持久图形式获得更实用的拓扑信息，为量子拓扑数据分析的实际应用提供了可行路径。

Conclusion: 该算法提出了"经典精度指导量子效率"的新型混合范式，首次实现了从量子计算贝蒂数到量子获取实用持久图的跨越，大大扩展了量子拓扑计算的应用价值。

Abstract: Persistence diagrams serve as a core tool in topological data analysis, playing a crucial role in pathological monitoring, drug discovery, and materials design. However, existing quantum topological algorithms, such as the LGZ algorithm, can only efficiently compute summary statistics like Betti numbers, failing to provide persistence diagram information that tracks the lifecycle of individual topological features, severely limiting their practical value. This paper proposes a novel quantum-classical hybrid algorithm that achieves, for the first time, the leap from "quantum computation of Betti numbers" to "quantum acquisition of practical persistence diagrams." The algorithm leverages the LGZ quantum algorithm as an efficient feature extractor, mining the harmonic form eigenvectors of the combinatorial Laplacian as well as Betti numbers, constructing specialized topological kernel functions to train a quantum support vector machine (QSVM), and learning the mapping from quantum topological features to persistence diagrams. The core contributions of this algorithm are: (1) elevating quantum topological computation from statistical summaries to pattern recognition, greatly expanding its application value; (2) obtaining more practical topological information in the form of persistence diagrams for real-world applications while maintaining the exponential speedup advantage of quantum computation; (3) proposing a novel hybrid paradigm of "classical precision guiding quantum efficiency." This method provides a feasible pathway for the practical implementation of quantum topological data analysis.

</details>


### [8] [Observation of an anomaly in the statistics of Kibble-Zurek defects](https://arxiv.org/abs/2512.02112)
*Jan Balewski,Alexey Khudorozhkov,Siva Darbha,Omar A. Ashour,Fangli Liu,Ermal Rrapaj,Sheng-Tao Wang,Pedro L. S. Lopes,Katherine Klymko,Milan Kornjača,Daan Camps*

Main category: quant-ph

TL;DR: 在长程1D里德堡原子链的绝热穿越实验中，缺陷计数统计在长斜坡时间出现异常，挑战了独立畴合并的缺陷形成假设，揭示了非临界粗化动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Kibble-Zurek机制在连续相变绝热穿越中的缺陷形成，探索量子多体系统中的普适性，并利用量子模拟器揭示意外的关联量子现象。

Method: 在长程1D里德堡原子链上进行绝热穿越实验，分析缺陷计数统计分布，通过数值模拟验证异常现象，并使用prepare-and-hold实验抑制非临界粗化动力学。

Result: 实验发现缺陷数分布在长斜坡时间出现异常，数值模拟确认了该异常并表明其与非临界粗化动力学相关，prepare-and-hold实验成功抑制了这种动力学效应。

Conclusion: 量子模拟器能够揭示意外的关联量子现象，缺陷形成机制比独立畴合并假设更复杂，非临界粗化动力学在缺陷统计中起重要作用。

Abstract: The Kibble-Zurek mechanism quantifies defect formation during adiabatic passage across a continuous phase transition, providing key insights into universality in quantum many-body systems. We explore counting statistics of defects in adiabatic passage experiments on long 1D Rydberg atom chains. The experiments reveal an anomaly in the defect number distribution at long ramp times, challenging the hypothesis of defect formation through independent domain mergers. Numerical simulations confirm the anomaly and suggest its link to non-critical coarsening dynamics, which we suppress in prepare-and-hold experiments. Our results highlight the ability of quantum simulators to uncover unexpected correlated quantum phenomena.

</details>


### [9] [Network theory classification of quantum matter based on wave function snapshots](https://arxiv.org/abs/2512.02121)
*Riccardo Andreoni,Vittorio Vitale,Cristiano Muzzi,Guido Caldarelli,Roberto Verdel,Marcello Dalmonte*

Main category: quant-ph

TL;DR: 该论文提出了一个结合数据复杂性和网络理论的理论框架，将量子物质的相与其测量快照联系起来，实现了无需假设底层动力学的量子态分类。


<details>
  <summary>Details</summary>
Motivation: 量子计算机和模拟器通过集体投影测量获得多体波函数的快照，但这些快照只能覆盖希尔伯特空间的极小部分。目前对这些快照概率分布与多体集体性质之间的关系理解不足，需要建立理论框架来连接量子相与测量快照。

Method: 采用两步法：1) 应用奥卡姆剃刀原理，通过分析不同测量基下快照的信息可压缩性，识别最小复杂性测量基；2) 使用网络理论分析任意相关性，从最小复杂性基数据构建波函数网络。

Result: 该方法能够随机分类量子计算机和模拟器的输出，无需对底层动力学做假设，且具有完全可解释性。在一维平移不变系统中实现了对量子物质态的穷尽分类，揭示了多体态中算法复杂性和计算复杂性之间的有趣相互作用。

Conclusion: 该框架具有直接的实验相关性，可进一步扩展到更先进的网络数学（包括离散同调）以及物理现象应用（如时间依赖动力学和规范理论）。

Abstract: Quantum computers and simulators offer unparalleled capabilities of probing quantum many-body states, by obtaining snapshots of the many-body wave function via collective projective measurements. The probability distribution obtained by such snapshots (which are fundamentally limited to a negligible fraction of the Hilbert space) is of fundamental importance to determine the power of quantum computations. However, its relation to many-body collective properties is poorly understood. Here, we develop a theoretical framework to link quantum phases of matter to their snapshots, based on a combination of data complexity and network theory analyses. The first step in our scheme consists of applying Occam's razor principle to quantum sampling: given snapshots of a wave function, we identify a minimal-complexity measurement basis by analyzing the information compressibility of snapshots over different measurement bases. The second step consists of analyzing arbitrary correlations using network theory, building a wave-function network from the minimal-complexity basis data. This approach allows us to stochastically classify the output of quantum computers and simulations, with no assumptions on the underlying dynamics, and in a fully interpretable manner. We apply this method to quantum states of matter in one-dimensional translational invariant systems, where such classification is exhaustive, and where it reveals an interesting interplay between algorithmic and computational complexity for many-body states. Our framework is of immediate experimental relevance, and can be further extended both in terms of more advanced network mathematics, including discrete homology, as well as in terms of applications to physical phenomena, such as time-dependent dynamics and gauge theories.

</details>


### [10] [Quantum Advantage in Resource Estimation](https://arxiv.org/abs/2512.02131)
*William A. Simon,Peter J. Love*

Main category: quant-ph

TL;DR: 该论文提出了一种量子算法，用于测量基于Trotter的量子算法的模拟误差，从而指数级加速数值资源估计，为展示实用量子优势提供了候选方案。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计算硬件快速发展，但仍缺乏适用于下一代量子计算机的有用应用。需要找到既能展示量子优势又具有实用价值的量子算法。

Method: 提出了一种量子算法来测量基于Trotter的量子算法的模拟误差。该方法需要相对较少的量子比特和操作，适用于下一代量子计算机。

Result: 该方法可将100量子比特系统的量子算法运行时间减少约三个数量级，且这种减少会随系统规模增加而增大。下一代量子计算机可计算经典计算机难以处理的系统的模拟误差。

Conclusion: 通过准确测量模拟误差来生成更大量子算法的数值资源估计存在指数级量子优势，这一任务是展示实用量子优势的有力候选方案。

Abstract: Quantum computing promises the ability to compute properties of quantum systems exponentially faster than classical computers. Quantum advantage is achieved when a practical problem is solved more efficiently on a quantum computer than on a classical computer. Demonstrating quantum advantage requires a powerful quantum computer with low error rates and an efficient quantum algorithm that has a useful application. Despite rapid progress in hardware development, we still lack useful applications that are feasible for the next generation of quantum computers. Here we argue that an exponential quantum advantage exists in producing numerical resource estimates of larger quantum algorithms by accurately measuring simulation errors. We provide a quantum algorithm for measuring simulation errors of Trotter-based algorithms. Our results indicate that this method will reduce runtimes of quantum algorithms by approximately three orders of magnitude for one-hundred qubit systems. We also predict that these reductions will increase with system size. The methods we propose require relatively few qubits and operations, meaning the next generation of quantum computers could compute simulation errors for classically intractable systems. Since the underlying computations that lead to reduced resource estimates are infeasible for classical computers, this task is a candidate for demonstrating practical quantum advantage.

</details>


### [11] [Testing ER = EPR with Hydrogen](https://arxiv.org/abs/2512.02156)
*Irfan Javed,Edward Wilson-Ewing*

Main category: quant-ph

TL;DR: 该论文基于ER=EPR猜想，提出纠缠带电粒子间的量子虫洞会影响氢原子超精细结构，并可能导致氢原子具有非零有效电荷，为验证ER=EPR效应提供了实验约束。


<details>
  <summary>Details</summary>
Motivation: 基于ER=EPR猜想（纠缠粒子通过量子虫洞连接），探索量子虫洞对氢原子物理性质的可观测影响，为验证这一量子引力理论提供实验途径。

Method: 假设纠缠带电粒子的部分电场会泄漏到量子虫洞中，理论推导这种效应如何修改氢原子的超精细结构；进一步考虑非穿越性量子虫洞，分析其对氢原子总有效电荷的影响。

Result: 理论预测显示：量子虫洞效应会改变氢原子的超精细结构，且非穿越性虫洞会导致氢原子具有非零总有效电荷。这些效应为ER=EPR效应的强度提供了严格的实验约束。

Conclusion: 通过高精度测量氢原子的超精细结构和总电荷，可以强有力地约束ER=EPR效应的幅度，为量子引力理论的实验验证开辟了新途径。

Abstract: According to the ER = EPR conjecture, entangled particles are connected by quantum wormholes. Under the assumption that some of the electric field surrounding an entangled charged particle leaks into the wormhole, we show that this effect will modify the hyperfine structure of the hydrogen atom. In addition, if the quantum wormholes are non-traversable, this will also lead to a non-zero total effective charge for the hydrogen atom. These effects provide strong constraints on the amplitude of this potential ER = EPR effect, given high-precision measurements of the hydrogen atom's hyperfine structure and total charge.

</details>


### [12] [Methodological Realism and Quantum Mechanics](https://arxiv.org/abs/2512.02169)
*Michael E. Cuffaro*

Main category: quant-ph

TL;DR: 该论文区分了物理理论"完备性"的两种含义：一种是完全描述物理现实，另一种是提供描述任何物理现象所需的概念资源。作者认为(新)埃弗雷特解释追求第一种完备性，而(新)玻尔解释基于第二种完备性，并探讨了两种视角的哲学基础。


<details>
  <summary>Details</summary>
Motivation: 论文旨在澄清物理理论"完备性"概念的歧义，分析量子力学解释中的不同哲学立场，特别是(新)埃弗雷特解释和(新)玻尔解释如何基于不同的完备性概念，并探讨这些差异背后的哲学基础。

Method: 通过概念分析区分两种完备性含义，比较(新)埃弗雷特和(新)玻尔解释的哲学立场，分析经典与量子描述的根本差异，并探讨形而上学实在论和方法论实在论两种哲学视角。

Result: 区分了物理理论完备性的两种含义：1) 完全描述物理现实；2) 提供描述任何现象所需的概念资源。(新)埃弗雷特解释追求第一种完备性，(新)玻尔解释基于第二种完备性。两种解释虽然对立，但从各自视角看可以相互支持。

Conclusion: 量子力学解释的差异源于对理论完备性的不同理解。虽然(新)埃弗雷特和(新)玻尔解释在哲学立场上对立，但它们分别体现了形而上学实在论和方法论实在论的视角，从各自角度为量子力学的完备性提供了论证。

Abstract: I distinguish two senses in which one can take a given physical theory to be `complete'. On the first, a complete physical theory is one that, in principle, completely describes physical reality. On the second, a complete physical theory is one that provides all of the conceptual resources one needs to describe any (in general probabilistic) physical phenomenon to any level of detail one likes, in principle. I argue that while the (neo-)Everettian approach to interpreting quantum mechanics aims to show that it is complete in the first sense, the (neo-)Bohrian approach begins from an understanding of quantum mechanics as being complete in the second sense. I then discuss some of the essential differences between how classical and quantum theory describe phenomena, and the way in which the quantum description can be thought of as a ``natural generalisation'' (to use Bohr's phrase) of the classical description. Finally, I elaborate upon the two visions of physics from which one can motivate the first and the second sense of completeness, respectively: \emph{metaphysical realism}, on the one hand, and what I will call \emph{methodological realism}, on the other -- and discuss what one can say about the significance of the differences between quantum and classical description from each of these points of view. I suggest that there is a sense in which the views of (neo-)Everett and the views of (neo-)Bohr can be understood to be mutually supporting positions, from their respective perspectives, even though they are diametrically opposed.

</details>


### [13] [Absorption-Based Qubit Estimation in Discrete-Time Quantum Walks](https://arxiv.org/abs/2512.02186)
*Edgard P. M. Amorim,Lorena R. Cerutti,O. P. de Sá Neto,M. C. de Oliveira*

Main category: quant-ph

TL;DR: 研究离散时间量子行走中的单吸收边界状态估计，通过谱方法获得逃逸概率的闭式表达式，分析经典与量子Fisher信息，发现边界位置与硬币状态信息获取的互补性，提出双边界方案实现完整信息提取，并设计集成光子学实现方案。


<details>
  <summary>Details</summary>
Motivation: 量子行走中的吸收边界可作为硬币状态测量的简单原语，但现有方法需要复杂测量或完整层析，本文旨在探索单吸收边界能否提供有效的状态估计信息，并寻求更简单的测量方案。

Method: 采用谱分析方法研究离散时间量子行走，推导逃逸概率作为硬币状态和边界位置的闭式表达式，计算经典Fisher信息和单拷贝量子Fisher信息，比较不同边界位置的信息获取能力，提出双边界放置方案以获得完整信息。

Result: 发现边界位置与硬币状态信息获取的互补关系：近边界携带关于硬币布居角的广泛信息，而适中或远边界揭示相位敏感区域。单边界只能探测一个信息方向，双边界放置可获得满秩Fisher矩阵和紧致的联合Cramér-Rao界，同时保持二进制、无需层析的测量。

Conclusion: 量子行走中的吸收可作为硬币状态计量学的简单且可扩展的原语，通过集成光子学实现（片上汇作为吸收器），相比模式分辨的量子比特层析可显著减少配置数量，为量子态估计提供了高效方案。

Abstract: We investigate state estimation in discrete-time quantum walks with a single absorbing boundary. Using a spectral approach, we obtain closed expressions for the escape probability as a function of the coin state and the boundary position, and their corresponding classical Fisher information for a simple absorption readout. Comparing with the single-copy quantum Fisher information shows a clear complementarity: near boundaries carry broad information about the population angle of the coin, whereas moderate or distant boundaries reveal phase-sensitive regions. Because a single boundary probes only one information direction, combining two boundary placements yields a full-rank Fisher matrix and tight joint Cramér--Rao bounds, while retaining a binary, tomography-free measurement. We outline an integrated-photonics implementation in which an on-chip sink realizes the absorber and estimate a substantial reduction in configuration count compared to mode-resolved qubit tomography. These results identify absorption in quantum walks as a simple and scalable primitive for coin-state metrology.

</details>


### [14] [Progress in quantum metrology and applications for optical atomic clocks](https://arxiv.org/abs/2512.02202)
*Raphael Kaubruegger,Adam M. Kaufman*

Main category: quant-ph

TL;DR: 本章介绍量子纠缠增强计量学原理及其在原子钟时间测量中的应用，包括量子相位估计理论框架、典型纠缠态、退相干挑战，以及实验约束下的频率估计实现。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠能够超越经典极限提升测量灵敏度，光学原子钟是这一技术的主要平台。本章旨在探讨纠缠增强量子计量学原理及其在精密时间测量中的实际应用。

Method: 回顾量子相位估计的理论框架（频率论和贝叶斯方法），讨论典型纠缠态（自旋压缩态和GHZ态），分析退相干带来的挑战，并探讨原子钟频率估计中的实验约束。

Result: 展示了量子纠缠在提升测量灵敏度方面的理论潜力，同时指出退相干和实验约束限制了大规模设备中的实际优势。强调了量子信息处理与精密计量学之间日益紧密的相互作用。

Conclusion: 量子纠缠为超越经典极限的测量灵敏度提供了强大机会，但实际应用中需克服退相干等挑战。量子信息处理与精密计量学的结合正在推动当代量子计量学的新发展方向。

Abstract: Quantum entanglement offers powerful opportunities for enhancing measurement sensitivity beyond classical limits, with optical atomic clocks serving as a leading platform for such advances. This chapter introduces the principles of entanglement-enhanced quantum metrology and explores their applications to timekeeping. We review the theoretical framework of quantum phase estimation, comparing frequentist and Bayesian approaches, and discuss paradigmatic entangled states such as spin-squeezed and GHZ states. Particular emphasis is placed on the challenges posed by decoherence, which constrain the practical advantages that can be realized in large-scale devices. The discussion then turns to frequency estimation in atomic clocks, highlighting how experimental constraints shape the translation of abstract quantum limits into real performance gains. Finally, we outline emerging directions of contemporary quantum metrology. Together, these developments underscore the increasingly close interplay between quantum information processing and precision metrology.

</details>


### [15] [Enhanced readout contrast of V2 ensembles in 4H-SiC through resonant optical excitation](https://arxiv.org/abs/2512.02235)
*Infiter Tathfif,Samuel G. Carter*

Main category: quant-ph

TL;DR: 通过低温共振激发V2缺陷，将ODMR对比度从<1%提升至50%，灵敏度达到100 nT/√Hz，相比非共振激发有100倍改进


<details>
  <summary>Details</summary>
Motivation: 4H-SiC中的V2硅空位缺陷具有优良的光学和自旋特性，但其ODMR读对比度在室温下通常<1%，限制了量子传感应用。需要提高读对比度以提升量子技术性能。

Method: 在低温下对V2缺陷进行共振激发，并与非共振激发进行对比。使用低功率（2 μW）共振激光，研究温度对ODMR对比度的影响。

Result: 实现了50%的最大ODMR对比度，比非共振激发提高了近100倍。在300 μW共振激光功率下达到100 nT/√Hz的灵敏度，而非共振激发需要100倍功率才能达到类似灵敏度。对比度随温度升高而降低，到60K时接近非共振水平。

Conclusion: 低温共振激发能显著提高V2缺陷的ODMR读对比度和灵敏度，这归因于部分V2中心具有与激光共振的自旋选择性光学跃迁。该方法为基于SiC的量子技术提供了重要改进。

Abstract: The V2 silicon vacancy defect in 4H-SiC has emerged as a promising system for quantum technologies due to its favorable optical and spin properties and the advantages of the SiC host. However, the readout contrast - an important benchmark for quantum sensing - of V2 ensembles for optically-detected magnetic resonance (ODMR) is relatively low, usually <1$\%$ at room temperature. To overcome this challenge, we resonantly excite the V2 ensembles at cryogenic temperatures and compare the results with the off-resonant case. We report a maximum ODMR contrast of 50$\%$ with only 2 $μ$W of resonant laser power, almost 100 times improvement over off-resonant excitation. We attribute this high readout contrast to a subset of V2 centers that have one spin-selective optical transition resonant with the laser. The ODMR contrast decreases with temperature, approaching the non-resonant contrast by 60 K, likely due to broadening of the optical transition linewidths. We achieve a maximum sensitivity of 100 nT/$\sqrt{Hz}$ with a resonant laser power of 300 $μ$W, while 100 times more non-resonant excitation power is needed to achieve comparable sensitivity.

</details>


### [16] [Evolution of the eigenvalues and eigenstates of the single-particle reduced density operator during two-particle scattering](https://arxiv.org/abs/2512.02239)
*Arsam Najafian,Mark Van Raamsdonk*

Main category: quant-ph

TL;DR: 该论文通过数值模拟研究量子散射过程中纯态如何演化为离散的混合态，展示了散射过程中密度矩阵特征值和特征态的时间演化，揭示了多峰态的形成机制。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统与环境相互作用时，初始纯态如何演化为离散的混合态，特别是散射过程中密度矩阵特征值和特征态的时间演化，以理解量子测量和退相干过程。

Method: 使用数值模拟方法，研究一维和二维简单散射实验中高斯波包的散射过程，分析约化密度算符特征值和特征态的时间依赖性。

Result: 发现一维散射中，晚期谱由两个大特征值主导，接近中心动量的透射和反射概率；小特征值对应多峰波包态；二维散射中，更小的特征值对应更多峰的概率分布。

Conclusion: 散射过程将初始连续参数描述的态演化为离散的可能结果集合，多峰态对应粒子在散射后处于分离波包叠加态的结果，为量子测量和退相干提供了详细的时间分辨图像。

Abstract: A particle initially in a pure state but interacting with some environment evolves into a discrete ensemble of pure states, the eigenstates of its reduced density operator, with ensemble probabilities given by the corresponding eigenvalues. In this work, we use numerics to present explicit results for the time-dependence of these eigenvalues and eigenstates for simple scattering experiments in one and two dimensions. This provides a time-resolved picture of the scattering process, showing in detail how an initial state described entirely in terms of continuous parameters evolves into a discrete set of possible outcomes, each with an associated probability and time-evolving wavefunction. We find that for scattering of Gaussian wavepackets in one dimension, the late time spectrum is dominated by two large eigenvalues nearly equal to the transmission and reflection probabilities associated with the central value of momentum. The corresponding eigenstates appear as single-peaked reflected or transmitted wavepackets. The remaining smaller eigenvalues, which increase to a maximum during scattering and then decrease to small values, correspond to reflected or transmitted wavepackets with multiple spatially separated parts. In this case and also for two-dimensional scattering, we find that successively smaller eigenvalues correspond to probability distributions with successively more peaks. These multi-peaked states correspond to outcomes of the scattering experiment where a particle initially in a single wavepacket ends up in a superposition of separated wavepackets after scattering.

</details>


### [17] [Microwave Circulation in an Extended Josephson Junction Ring](https://arxiv.org/abs/2512.02264)
*Dat Thanh Le,Arkady Fedorov,Thomas M. Stace*

Main category: quant-ph

TL;DR: 提出基于环形约瑟夫森结中移动磁通量子实现非互易微波传输的谐振环行器设计


<details>
  <summary>Details</summary>
Motivation: 利用波导中传播介质相对于波导的运动产生时间反演对称性破缺，实现非互易器件，特别是环行器

Method: 设计基于扩展环形约瑟夫森结的非互易微波传输系统，利用移动磁通量子作为传播介质

Result: 理论上评估了该谐振环行器的高性能表现

Conclusion: 环形约瑟夫森结中的移动磁通量子为实现高质量微波环行器提供了一种有前景的方法

Abstract: Circulators are nonreciprocal devices that enable directional signal routing. Nonreciprocity, which requires time-reversal symmetry breaking, can be produced in waveguides in which the propagation medium moves relative to the waveguide at a moderate fraction of the wave speed. Motivated by this effect, here we propose a design for nonreciprocal microwave transmission based on an extended, annular Josephson junction, in which the propagation medium consists of a train of moving fluxons. We show how to harness this to build a high-quality resonant microwave circulator, and we theoretically evaluate the anticipated performance of such a device.

</details>


### [18] [Quantum-Classical Separation in Bounded-Resource Tasks Arising from Measurement Contextuality](https://arxiv.org/abs/2512.02284)
*Shashwat Kumar,Eliott Rosenberg,Alejandro Grajales Dau,Rodrigo Cortinas,Dmitri Maslov,Richard Oliver,Adam Zalcman,Matthew Neeley,Alice Pagano,Aaron Szasz,Ilya Drozdov,Zlatko Minev,Craig Gidney,Noureldin Yosri,Stijn J. de Graaf,Aniket Maiti,Dmitry Abanin,Rajeev Acharya,Laleh Aghababaie Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Trond I. Andersen,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Martin Bigdeli,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Alexandre Bourassa,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Jahan Claes,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Roberto Collins,Paul Conner,Harold Cook,William Courtney,Alexander L. Crook,Ben Curtin,Sayan Das,Laura De Lorenzo,Sean Demura,Agustin Di Paolo,Paul Donohoe,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Vinicius S. Ferreira,Marcos Flores,Leslie Flores Burgos,Ebrahim Forati,Jeremiah Ford,Austin G. Fowler,Brooks Foxen,Masaya Fukami,Alan Wing Lun Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Élie Genois,William Giang,Dar Gilboa,James E. Goeders,Ed Gonzales,Raja Gosula,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Tan Ha,Steve Habegger,Tanner Hadick,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Ashley Huff,William J. Huggins,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Cody Jones,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Dvir Kafri,Hui Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Trupti Khaire,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,David Landhuis,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Loïck Le Guevel,Emma Leavell,Justin Ledford,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily L Li,Wing Yan Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Aditya Locharla,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Masih Das,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Sherman Peek,David Peterson,Alex Pizzuto,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Gabrielle Roberts,Roberto Rodriguez,Emma Ropes,Emma Rosenfeld,Dario Rosenstock,Elizabeth Rossi,David A. Rower,Kannan Sankaragomathi,Murat Can Sarihan,Kevin J. Satzinger,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Noah Shutty,Vladimir Shvarts,Volodymyr Sivak,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Catherine Vollgraff Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Brayden Ware,James D. Watson,Travis Weidel,Theodore White,Kristi Wong,Bryan W. K. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Elliot Young,Grayson Young,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Shruti Puri,Erik Lucero,Julian Kelly,Sergio Boixo,Yu Chen,Vadim Smelyanskiy,Hartmut Neven,Pedram Roushan,Michel Devoret*

Main category: quant-ph

TL;DR: 该论文展示了量子上下文性能够实现超越经典极限的任务成功率，并在超导量子处理器上通过多种游戏和问题验证了这一量子-经典分离。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算领域面临的核心挑战是量化并实际证明量子处理器相对于经典方法的优势。虽然理论上量子现象能够解决某些经典方法无法处理的问题，但在实际量子处理器上展示这种量子-经典分离仍然困难。

Method: 使用超导量子比特处理器，通过多种方式验证量子上下文性：1) 魔方游戏展示量子上下文性；2) Kochen-Specker-Bell不等式违反量化上下文性；3) N玩家GHZ游戏研究多体上下文性；4) 2D隐藏线性函数问题求解。

Result: 实验结果表明，量子处理器在多个任务中实现了超越经典极限的成功率：魔方游戏、Kochen-Specker-Bell不等式违反、N玩家GHZ游戏和2D隐藏线性函数问题都展示了量子上下文性带来的优势。

Conclusion: 该工作提出了基于上下文性的新型量子处理器基准测试方法，成功在超导量子处理器上展示了量子-经典分离，为验证量子优势提供了新途径。

Abstract: The prevailing view is that quantum phenomena can be harnessed to tackle certain problems beyond the reach of classical approaches. Quantifying this capability as a quantum-classical separation and demonstrating it on current quantum processors has remained elusive. Using a superconducting qubit processor, we show that quantum contextuality enables certain tasks to be performed with success probabilities beyond classical limits. With a few qubits, we illustrate quantum contextuality with the magic square game, as well as quantify it through a Kochen--Specker--Bell inequality violation. To examine many-body contextuality, we implement the N-player GHZ game and separately solve a 2D hidden linear function problem, exceeding classical success rate in both. Our work proposes novel ways to benchmark quantum processors using contextuality-based algorithms.

</details>


### [19] [Universal Sensitivity Bound for Thermal Quantum Dynamic Sensing](https://arxiv.org/abs/2512.02366)
*Rui Zhang,Yang Yang,Wenkui Ding,Xiaoguang Wang*

Main category: quant-ph

TL;DR: 该工作将量子计量学的平衡与非平衡框架统一于多体系统背景下，研究了动态传感方案，推导出热平衡探针态量子Fisher信息的上界，并应用于多种模型验证。


<details>
  <summary>Details</summary>
Motivation: 将量子计量学中的平衡与非平衡框架统一起来，特别是在多体系统背景下，研究热平衡探针态在动态传感中的性能极限。

Method: 提出动态传感方案，推导热探针态量子Fisher信息的上界，证明该上界由变换后的局域生成元与热态哈密顿量的非对易程度决定，并建立与逆温度和演化时间平方乘积相关的标度关系。

Result: 建立了热探针态动态量子Fisher信息的上界：1）由变换局域生成元与哈密顿量的非对易度决定；2）标度为逆温度与演化时间平方的乘积；3）低温极限下额外上界为对易子半范数除以能隙。在多种模型中验证了这些上界。

Conclusion: 该工作成功统一了量子计量学的平衡与非平衡框架，为热平衡探针态的量子传感性能建立了理论极限，并在多体系统中得到验证，为实际量子传感应用提供了理论基础。

Abstract: This work unifies the equilibrium and non-equilibrium frameworks of quantum metrology within the context of many-body systems. We investigate dynamic sensing schemes to derive an upper bound on the quantum Fisher information for probe states in thermal equilibrium with their environment. We establish that the dynamic quantum Fisher information for a thermal probe state is upper bounded by the degree of non-commutation between the transformed local generator and the Hamiltonian for the thermal state. Furthermore, we show that this upper bound scales as the square of the product of the inverse temperature and the evolution time. In the low-temperature limit, we establish an additional upper bound expressed as the seminorm of the commutator divided by the energy gap. We apply this thermal dynamic sensing scheme to various models, demonstrating that the dynamic quantum Fisher information satisfies the established upper bounds.

</details>


### [20] [Estimating Local Observables via Cluster-Level Light-Cone Decomposition](https://arxiv.org/abs/2512.02377)
*Junxiang Huang,Yunxin Tang,Xiao Yuan*

Main category: quant-ph

TL;DR: 提出基于簇级光锥分析的框架，利用量子工作负载的局部性，通过因果解耦和代数分解算法，使模拟成本取决于电路深度和连接性而非系统规模。


<details>
  <summary>Details</summary>
Motivation: 在量子比特数量有限的硬件上模拟大型量子电路时，传统方法如电路编织通常会导致采样成本随切割连接数指数增长，需要更高效的模拟方法。

Method: 提出基于簇级光锥分析的框架，包含两个互补算法：1) 因果解耦算法，利用光锥中的几何断连提高采样效率；2) 代数分解算法，利用代数扩展最小化硬件需求。

Result: 这些方法使模拟成本取决于电路深度和连接性，而非系统规模，将Lieb-Robinson启发的局部性推广到模块化架构，为在近期量子设备上探测局部物理建立了定量框架。

Conclusion: 该工作通过解耦模拟成本与全局系统规模，为在资源受限的量子硬件上高效模拟大型量子电路提供了新框架，有望推动近期量子设备的实际应用。

Abstract: Simulating large quantum circuits on hardware with limited qubit counts is often attempted through methods like circuit knitting, which typically incur sample costs that grow exponentially with the number of connections cut. In this work, we introduce a framework based on Cluster-level Light-cone analysis that leverages the natural locality of quantum workloads. We propose two complementary algorithms: the Causal Decoupling Algorithm, which exploits geometric disconnections in the light cone for sampling efficiency, and the Algebraic Decomposition Algorithm, which utilizes algebraic expansion to minimize hardware requirements. These methods allow simulation costs to depend on circuit depth and connectivity rather than system size. Together, our results generalize Lieb-Robinson-inspired locality to modular architectures and establish a quantitative framework for probing local physics on near-term quantum devices by decoupling the simulation cost from the global system size.

</details>


### [21] [Quantum feature encoding optimization](https://arxiv.org/abs/2512.02422)
*Tommaso Fioravanti,Brian Quanz,Gabriele Agliardi,Edgar Andres Ruiz Guzman,Ginés Carrascal,Jae-Eun Park*

Main category: quant-ph

TL;DR: 该论文研究了量子机器学习中数据编码的预处理优化，通过经典数据操作（排序、选择、加权特征）来改进QML模型性能，并在多种数据集和电路规模上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在复杂度和准确性方面具有潜力，但数据编码是决定QML性能的关键挑战。当前研究主要关注编码ansatz的调整，而忽略了数据如何传递给ansatz这一独特方面。

Method: 提出在QML流程中集成经典数据预处理步骤，包括特征排序、选择和加权。通过优化特征在ansatz中的编码方式，评估这些预处理操作对QML模型性能的影响。

Result: 实验结果表明，通过优化特征编码方式可以显著且一致地提升QML模型性能。在100量子比特的真实量子硬件上运行也验证了该方法的实际可行性。

Conclusion: 数据预处理和编码优化对QML性能有重要影响，应将这些技术整合到未来的QML应用中，以提高模型性能。

Abstract: Quantum Machine Learning (QML) holds the promise of enhancing machine learning modeling in terms of both complexity and accuracy. A key challenge in this domain is the encoding of input data, which plays a pivotal role in determining the performance of QML models. In this work, we tackle a largely unaddressed aspect of encoding that is unique to QML modeling -- rather than adjusting the ansatz used for encoding, we consider adjusting how data is conveyed to the ansatz. We specifically implement QML pipelines that leverage classical data manipulation (i.e., ordering, selecting, and weighting features) as a preprocessing step, and evaluate if these aspects of encoding can have a significant impact on QML model performance, and if they can be effectively optimized to improve performance. Our experimental results, applied across a wide variety of data sets, ansatz, and circuit sizes, with a representative QML approach, demonstrate that by optimizing how features are encoded in an ansatz we can substantially and consistently improve the performance of QML models, making a compelling case for integrating these techniques in future QML applications. Finally we demonstrate the practical feasibility of this approach by running it using real quantum hardware with 100 qubit circuits and successfully achieving improved QML modeling performance in this case as well.

</details>


### [22] [Quantum-Based Self-Attention Mechanism for Hardware-Aware Differentiable Quantum Architecture Search](https://arxiv.org/abs/2512.02476)
*Yuxiang Liu,Sixuan Li,Fanxu Meng,Zaichen Zhang,Xutao Yu*

Main category: quant-ph

TL;DR: QBSA-DQAS：基于量子自注意力的可微分量子架构搜索框架，用于NISQ时代的变分量子算法设计，通过量子自注意力模块和多目标搜索优化电路性能


<details>
  <summary>Details</summary>
Motivation: 传统可微分架构搜索依赖经典模型，无法充分表示硬件噪声下的量子门交互，限制了NISQ时代参数化量子电路的自动化设计

Method: 提出QBSA-DQAS元学习框架，包含两阶段量子自注意力模块（计算上下文依赖关系，用量子派生的注意力分数替代经典相似度度量），硬件感知的多目标搜索（联合优化噪声可表达性和PST），以及后搜索优化阶段（门交换、融合和消除）

Result: 在VQE任务中，H₂分子上达到0.9准确率（标准DQAS为0.89）；后搜索优化使电路复杂度降低44%门数和47%深度；在WSN路由中，相比QAOA节能8.6%，相比经典贪心方法节能40.7%

Conclusion: QBSA-DQAS框架在多种分子和IBM量子硬件噪声模型下保持稳健性能，证明了量子原生架构搜索在NISQ应用中的有效性

Abstract: The automated design of parameterized quantum circuits for variational algorithms in the NISQ era faces a fundamental limitation, as conventional differentiable architecture search relies on classical models that fail to adequately represent quantum gate interactions under hardware noise. We introduce the Quantum-Based Self-Attention for Differentiable Quantum Architecture Search (QBSA-DQAS), a meta-learning framework featuring quantum-based self-attention and hardware-aware multi-objective search. The framework employs a two-stage quantum self-attention module that computes contextual dependencies by mapping architectural parameters through parameterized quantum circuits, replacing classical similarity metrics with quantum-derived attention scores, then applies position-wise quantum transformations for feature enrichment. Architecture search is guided by a task-agnostic multi-objective function jointly optimizing noisy expressibility and Probability of Successful Trials (PST). A post-search optimization stage applies gate commutation, fusion, and elimination to reduce circuit complexity. Experimental validation demonstrates superior performance on VQE tasks and large-scale Wireless Sensor Networks. For VQE on H$_2$, QBSA-DQAS achieves 0.9 accuracy compared to 0.89 for standard DQAS. Post-search optimization reduces discovered circuit complexity by up to 44% in gate count and 47% in depth without accuracy degradation. The framework maintains robust performance across three molecules and five IBM quantum hardware noise models. For WSN routing, discovered circuits achieve 8.6% energy reduction versus QAOA and 40.7% versus classical greedy methods, establishing the effectiveness of quantum-native architecture search for NISQ applications.

</details>


### [23] [Qudits offer no advantages over dits for sending random messages](https://arxiv.org/abs/2512.02477)
*Ronit Shah*

Main category: quant-ph

TL;DR: 证明了在无预共享纠缠的情况下，发送量子比特相比经典比特在消息猜测任务中无优势，并将结果推广到混合态情形


<details>
  <summary>Details</summary>
Motivation: 研究在消息猜测任务中，当Alice只能发送量子比特（无预共享纠缠）时，是否比发送经典比特有优势。先前结果仅针对均匀分布，本文要扩展到一般分布

Method: 通过理论证明，首先证明纯态情形下量子比特无优势，然后推广到混合态情形，建立基于维度、概率分布和特征值的成功概率上界

Result: 1. 对于任意已知分布的消息，发送量子比特相比经典比特无优势；2. 建立了混合态区分成功概率的尖锐上界，该上界仅依赖于维度、概率分布和特征值

Conclusion: 在无预共享纠缠的单量子比特通信中，量子比特相比经典比特在消息猜测任务中没有优势，这一结论对任意分布都成立，并可通过混合态推广获得更一般的区分界限

Abstract: We consider the following simple scenario: Alice has one of many possible messages, drawn from a known distribution, and wants to maximize the probability that Bob guesses her message correctly. We prove that if Alice can send only a qudit to Bob, without preshared entanglement, there is never any advantage over sending him a classical dit. This result was previously known only for a uniform distribution.
  We also prove a mixed-state generalization of this result in the form of an upper bound on the success probability of discriminating between mixed quantum states with a single measurement. This bound is based solely on the dimension, probability distribution, and eigenvalues of the states and is sharp among such bounds.

</details>


### [24] [Superchannel without Tears: A Generalized Occam's Razor for Quantum Processes](https://arxiv.org/abs/2512.02493)
*Yunlong Xiao*

Main category: quant-ph

TL;DR: 本文为超通道建立统一理论框架，解决现有理论不一致和不完整的问题，发展超通道的多种表示形式，并应用于非马尔可夫量子动力学研究。


<details>
  <summary>Details</summary>
Motivation: 当前超通道理论存在内部不一致（不同Choi算子构造共存）和结构不完整（缺乏类似通道理论的基础表示）的问题，需要建立统一的理论基础。

Method: 结合张量网络方法和广义奥卡姆剃刀原理，建立超通道的统一框架，发展Kraus、Stinespring和Liouville表示，推导实现定理。

Result: 建立了超通道的统一理论框架，连接了不同的Choi算子构造，发展了多种表示形式，简化了实现定理的推导，并能够表征破坏量子关联或因果结构的超通道。

Conclusion: 该框架为超通道提供了统一的理论基础，解决了现有理论的不一致问题，为系统研究非马尔可夫量子动力学开辟了道路。

Abstract: Quantum channels function as the operational primitives of quantum theory, while superchannels describe the most general transformations acting upon them. Yet the prevailing framework for superchannels is both internally inconsistent, owing to the coexistence of distinct Choi operator constructions, and structurally incomplete, lacking the analogue of representations that ground channel theory. We resolve these issues by combining tensor-network methods with a generalized Occam's razor introduced here, establishing a unified foundation for superchannels. Our framework establishes the connections between competing Choi formulations, develops the Kraus, Stinespring, and Liouville representations for superchannels, and provides a simplified derivation of the realization theorem that identifies the minimal memory required to implement a given transformation. These structural tools also enable characterizations of superchannels that destroy quantum correlations or causal structure, opening a systematic route to non-Markovian quantum dynamics.

</details>


### [25] [Detection of photon-level signals embedded in sunlight with an atomic photodetector](https://arxiv.org/abs/2512.02521)
*Laura Zarraoa,Romain Veyron,Tomas Lamich,Sondos Elsehimy,Morgan W. Mitchell*

Main category: quant-ph

TL;DR: 单原子量子跃迁光电探测器可在强太阳光背景下检测单光子信号


<details>
  <summary>Details</summary>
Motivation: 在宽带背景噪声中检测微弱光子信号是光子计数技术的重大挑战，需要窄带滤波技术。本文旨在验证量子跃迁光电探测器在强太阳光背景下检测单光子信号的可行性。

Method: 使用单个铷原子作为量子跃迁光电探测器，检测嵌入强太阳光中的窄带激光光子。建立原子内部态动力学的速率方程模型，并与实验数据对比验证。

Result: 实验成功检测到嵌入约10^10光子/秒太阳光背景中的单个窄带激光光子。速率方程模型与实验结果定量吻合。在1纳瓦太阳光背景下发送150个探测光子，可实现0.5比特/符号的信道容量。

Conclusion: 量子跃迁光电探测器能够在强太阳光背景下有效检测单光子信号，为日间激光雷达、远程磁力测量和自由空间光通信等背景受限应用提供了新方案。

Abstract: The detection of few-photon signals in a broadband background is an extreme challenge for photon counting, requiring filtering that accepts a narrow range of optical frequencies while strongly rejecting all others. Recent work [Zarraoa et. al, Phys. Rev. Res. 6, 033338 (2024)] demonstrated that trapped single atoms can act as low dark-count narrow-band photodetectors. Here we show that this ``quantum jump photodetector'' (QJPD) approach can also detect photon-level signals embedded in strong sunlight. Using a single rubidium atom as a QJPD, we count arrivals of individual narrow-band laser photons embedded in sunlight powers of order $10^{10}$ photons/s. We derive a rate-equation model for the atom's internal-state dynamics in sunlight, and find quantitative agreement with experiment. Using this model, we calculate the channel capacity over a noisy communication channel when sending weak coherent states and detecting them in the presence of sunlight, achieving a representative rate of 0.5 bits per symbol when sending 150 probe photons per 10 ms time-bin, embedded in 1 nW of sunlight (of order $10^{10}$ photons/s in the visible and near-infrared bands). The demonstration may benefit background-limited applications such as daytime light detection and ranging (LIDAR), remote magnetometry, and free-space classical and quantum optical communications.

</details>


### [26] [Full-counting statistics and quantum information of dispersive readout with a squeezed environment](https://arxiv.org/abs/2512.02531)
*Ming Li,JunYan Luo,Gloria Platero,Georg Engelhardt*

Main category: quant-ph

TL;DR: 提出一种基于压缩真空探针的色散读取全计数统计框架，用于连续量子测量，能直接计算任意阶累积量，且Fisher信息随压缩参数指数增长


<details>
  <summary>Details</summary>
Motivation: 色散读取在量子技术中至关重要，但传统输入输出理论在处理非线性系统和计算高阶统计量方面存在局限，需要更高效的分析框架

Method: 开发了色散读取的全计数统计框架，采用时间反演对称的压缩真空探针，结合适用于非幺正动力学的广义平均场方法

Result: Fisher信息随压缩参数指数增长，对残余非线性具有鲁棒性，可接近量子Fisher信息上限；框架计算高效，适用于非线性系统

Conclusion: 该工作为连续量子测量提供了概念简洁、计算高效的框架，适合在量子技术中广泛应用，特别是在压缩增强的色散读取场景中

Abstract: Motivated by the importance of dispersive readout in quantum technology, we study a prototypical dispersive readout setup that is probed by a squeezed vacuum in a time-reversal-symmetric fashion. To this end, we develop a full-counting-statistics framework for dispersive readout and analyze its measurement information, accompanied by a generalized mean-field approach suitable to deal with non-unitary dynamics. Distinct from conventional input-output theory, our full-counting-statistics approach enables the direct calculation of arbitrary-order cumulants for the measured cumulative (i.e., time-integrated) photonic distribution while maintaining applicability to nonlinear systems. The corresponding Fisher information exhibits an exponential dependence on the squeezing parameter and a robustness against residual nonlinearity, which can even approach the quantum Fisher information, setting an upper limit. This work introduces a conceptually streamlined and computationally efficient framework for continuous quantum measurements, making it well suited for widespread adoption in quantum technologies.

</details>


### [27] [Constraint-Optimal Driven Allocation for Scalable QEC Decoder Scheduling](https://arxiv.org/abs/2512.02539)
*Dongmin Kim,Jeonggeun Seo,Youngtae Kim,Youngsun Han*

Main category: quant-ph

TL;DR: CODA是一种基于全局优化的调度算法，用于解决大规模容错量子计算中解码器资源短缺问题，通过利用电路全局结构最小化最长未解码序列长度，相比现有方法平均减少74%。


<details>
  <summary>Details</summary>
Motivation: 大规模容错量子计算系统中，解码器数量远少于逻辑量子比特数，导致资源短缺。现有的虚拟化量子解码器架构中的MLS启发式调度策略由于局部贪婪决策，无法考虑全局电路结构，导致资源平衡效率低下和可扩展性受限。

Method: 提出约束最优驱动分配（CODA）算法，这是一种基于优化的调度算法，利用全局电路结构来最小化最长未解码序列长度。算法有效避免了理论搜索空间随电路规模指数增长的问题。

Result: 在19个基准电路测试中，CODA实现了平均74%的最长未解码序列长度减少。调度时间与量子比特数量呈线性关系，由物理资源约束而非组合搜索空间决定，确保了大尺度系统的鲁棒可扩展性。

Conclusion: CODA提供了一种基于全局优化的可扩展调度解决方案，能够在大规模容错量子计算系统中实现高效的解码器虚拟化，解决了资源短缺和可扩展性挑战。

Abstract: Fault-tolerant quantum computing (FTQC) requires fast and accurate decoding of Quantum Error Correction (QEC) syndromes. However, in large-scale systems, the number of available decoders is much smaller than the number of logical qubits, leading to a fundamental resource shortage. To address this limitation, Virtualized Quantum Decoder (VQD) architectures have been proposed to share a limited pool of decoders across multiple qubits. While the Minimize Longest Undecoded Sequence (MLS) heuristic has been introduced as an effective scheduling policy within the VQD framework, its locally greedy decision-making structure limits its ability to consider global circuit structure, causing inefficiencies in resource balancing and limited scalability. In this work, we propose Constraint-Optimal Driven Allocation (CODA), an optimization-based scheduling algorithm that leverages global circuit structure to minimize the longest undecoded sequence length. Across 19 benchmark circuits, CODA achieves an average 74\% reduction in the longest undecoded sequence length. Crucially, while the theoretical search space scales exponentially with circuit size, CODA effectively bypasses this combinatorial explosion. Our evaluation confirms that the scheduling time scales linearly with the number of qubits, determined by physical resource constraints rather than the combinatorial search space, ensuring robust scalability for large-scale FTQC systems. These results demonstrate that CODA provides a global optimization-based, scalable scheduling solution that enables efficient decoder virtualization in large-scale FTQC systems.

</details>


### [28] [A unified optical platform for non-Gaussian and fault-tolerant Gottesman-Kitaev-Preskill states](https://arxiv.org/abs/2512.02607)
*Ozlem Erkilic,Aritra Das,Biveen Shajilal,Ping Koy Lam,Timothy C. Ralph,Syed M. Assad*

Main category: quant-ph

TL;DR: 提出一种统一的光学框架，仅使用高斯输入、光学参量放大和光子探测，就能生成多种非高斯量子态，为量子通信、计量和计算提供可扩展平台。


<details>
  <summary>Details</summary>
Motivation: 量子技术需要非高斯光态来实现安全通信、容错计算和精密传感，但传统方法依赖高光子数Fock态或强非线性，实现困难。需要一种更实用的方法。

Method: 使用统一光学框架：仅需高斯输入、光学参量放大和光子探测。在单一架构中生成多种非高斯态，包括光子增加压缩态、立方相位态和压缩猫态。

Result: 实现了高保真度非高斯态生成：光子增加压缩态接近单位保真度，立方相位态保真度>98.5%，压缩猫态>99%保真度，并能迭代培育出超过9.75dB容错阈值的GKP网格态。

Conclusion: 该框架在低于3dB输入压缩下运行，为量子通信、计量和计算提供了可扩展、实验可访问的统一平台，解决了非高斯态生成的实用化难题。

Abstract: Quantum technologies, encompassing communication, computation, and metrology, rely on the generation and control of non-Gaussian states of light. These states enable secure quantum communication, fault-tolerant quantum computation, and precision sensing beyond classical limits, yet their practical realisation remains a major challenge due to reliance on high-photon-number Fock states or strong non-linearities. Here we introduce a unified optical framework that removes this constraint, using only Gaussian inputs, optical parametric amplification, and heralded photon detection. Within a single architecture, we demonstrate the generation of photon-added squeezed states with near unit fidelity, cubic-phase-like states with strong non-linearities and fidelities above 98.5%, and squeezed-cat states exceeding 99% fidelity that can be iteratively bred into GKP grid states surpassing the 9.75 dB fault-tolerance threshold. Operating entirely below 3 dB of input squeezing, the approach provides a scalable, experimentally accessible platform that unites the state resources required for quantum communication, metrology, and computation within one coherent optical framework.

</details>


### [29] [Quantum LLMs Using Quantum Computing to Analyze and Process Semantic Information](https://arxiv.org/abs/2512.02619)
*Timo Aukusti Laine*

Main category: quant-ph

TL;DR: 该论文提出了一种利用量子计算分析LLM嵌入的方法，通过将语义空间映射到量子电路，在真实量子计算机上计算句子嵌入的余弦相似度，展示了量子方法在语义分析中的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型与量子力学之间的联系，利用量子计算原理为语义表示和处理提供新视角，开发量子自然语言处理算法。

Method: 建立LLM语义空间与量子电路的直接映射，使用复数表示和量子力学原理建模语义关系，在真实量子计算机上计算Google Sentence Transformer嵌入的余弦相似度。

Result: 成功在量子硬件上实现了语义相似度估计，实验计算了句子嵌入的余弦相似度，证明了量子方法分析LLM嵌入的可行性。

Conclusion: 揭示了LLM与量子力学之间的连接，表明量子原理能为语义表示提供新视角，为量子自然语言处理算法的发展铺平道路。

Abstract: We present a quantum computing approach to analyzing Large Language Model (LLM) embeddings, leveraging complex-valued representations and modeling semantic relationships using quantum mechanical principles. By establishing a direct mapping between LLM semantic spaces and quantum circuits, we demonstrate the feasibility of estimating semantic similarity using quantum hardware. One of the key results is the experimental calculation of cosine similarity between Google Sentence Transformer embeddings using a real quantum computer, providing a tangible demonstration of a quantum approach to semantic analysis. This work reveals a connection between LLMs and quantum mechanics, suggesting that these principles can offer new perspectives on semantic representation and processing, and paving the way for future development of quantum algorithms for natural language processing.

</details>


### [30] [High-harmonic generation from two weakly coupled molecules: a simple tight-binding model](https://arxiv.org/abs/2512.02623)
*Lina Bielke,Samuel Schöpa,Falk-Erik Wiechmann,Franziska Fennel,Dieter Bauer*

Main category: quant-ph

TL;DR: 研究二维紧束缚系统中激光偏振角度和分子间相互作用对高次谐波产率的影响，发现低阶谐波在激光偏振沿分子轴方向时产率最大，而高阶谐波则在偏振沿分子间轴方向时最强，且翻转点取决于分子间耦合强度。


<details>
  <summary>Details</summary>
Motivation: 高次谐波产生是强非线性效应，可用于探测靶材性质和电子动力学。最近在有机分子晶体中的研究发现，谐波产率对分子间弱耦合敏感。本文旨在详细研究激光偏振角度和分子间相互作用对谐波产率的影响机制。

Method: 使用简单但具有启发性的二维紧束缚系统模拟分子二聚体（两个弱耦合分子），详细分析激光偏振角度和分子间相互作用对谐波产率的影响，并包含详细的绝热分析来理解物理机制。

Result: 发现低阶谐波强度在激光偏振方向与分子轴对齐时最大，而高阶谐波则在偏振沿分子间轴方向时最强。谐波产率最大值从分子轴向分子间轴翻转的谐波阶数强烈依赖于分子间耦合强度。绝热分析表明这种翻转现象在绝热跟随态中已定性存在。

Conclusion: 通过简单的二维紧束缚模型揭示了高次谐波产率对激光偏振方向的依赖关系及其与分子间耦合强度的关联，为理解有机分子晶体中的高次谐波产生机制提供了重要见解。

Abstract: The generation of high harmonics is a strongly nonlinear effect that allows to probe properties of the target and to study electron dynamics in matter. It has been investigated in many different kinds of targets, including molecular gases, liquids and solids. Recently, high-harmonic generation was studied in organic molecular crystals by Wiechmann et al. [Nat. Commun. 16, 9890 (2025)]. It was found that the laser-polarization-dependent harmonic yield is sensitive to the weak couplings between nearest- and next-nearest-neighbor molecules. In this paper, the impact of the laser polarization angle and the intermolecular interaction on the harmonic yield is examined in detail using a simple but insightful two-dimensional tight-binding system that models a molecular dimer, i.e. two weakly coupled molecules. We find that the intensities of lower harmonic orders tend to maximize for a laser polarization direction aligning with the molecular axes, whereas higher harmonic orders rather show the strongest yield for a polarization direction along the intermolecular axis. We further demonstrate that the harmonic order at which the maximum flips from the molecular to the intermolecular direction strongly depends on the intermolecular coupling strength. To gain a deeper insight into the origins of the findings, we include a detailed adiabatic analysis, showing that the flipping of the maximum yield towards the intermolecular direction is already contained qualitatively in the adiabatically following states.

</details>


### [31] [Chiplet technology for large-scale trapped-ion quantum processors](https://arxiv.org/abs/2512.02645)
*Bassem Badawi,Philip C. Holz,Michael Raffetseder,Nicolas Jungwirth,Juris Ulmanis,Hans-Joachim Quenzer,Dirk Kähler,Thomas Monz,Philipp Schindler*

Main category: quant-ph

TL;DR: 提出了一种基于小芯片的模块化囚禁离子量子处理器架构，通过异质集成技术将不同功能的小芯片组合，相比传统单片集成方法具有更好的材料选择和功能扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有囚禁离子量子处理器主要采用单片集成方法，依赖于CMOS兼容的半导体制造技术，但这些技术并非针对量子处理器需求优化，限制了材料选择和功能扩展。

Method: 采用模块化小芯片方法，将处理器分解为具有特定功能的小芯片，分别制造后通过异质集成技术组合。以十离子晶体为例，展示了由玻璃基底表面离子阱、硅基底集成波导和3D打印微光学堆叠组成的寻址系统。

Result: 成功实现了基于小芯片的集成单离子寻址系统，在离子位置实现了衍射极限的聚焦光斑，验证了模块化方法的可行性和优势。

Conclusion: 小芯片技术为囚禁离子量子处理器提供了更灵活的材料选择、优化的制造工艺和模块化功能扩展能力，是实现大规模量子信息处理器的有前景途径。

Abstract: Trapped ions are among the most promising platforms for realizing a large-scale quantum information processor. Current progress focuses on integrating optical and electronic components into microfabricated ion traps to allow scaling to large numbers of ion qubits. Most available fabrication strategies for such integrated processors employ monolithic integration of all processor components and rely heavily on CMOS-compatible semiconductor fabrication technologies that are not optimized for the requirements of a trapped-ion quantum processor. In this work, we present a modular approach in which the processor modules, called chiplets, have specific functions and are fabricated separately. The individual chiplets are then combined using heterogeneous integration techniques. This strategy opens up the possibility of choosing the optimal materials and fabrication technology for each of the chiplets, with a minimum amount of fabrication limitations compared to the monolithic approach. Chiplet technology furthermore enables novel processor functionalities to be added in a cost-effective, modular fashion by adding or modifying only a subset of the chiplets. We describe the design concept of a chiplet-based trapped-ion quantum processor and demonstrate the technology with an example of an integrated individual-ion addressing system for a ten-ion crystal. The addressing system emphasizes the modularity of the chiplet approach, combining a surface ion trap manufactured on a glass substrate with a silicon substrate carrying integrated waveguides and a stack of 3D-printed micro-optics, achieving diffraction-limited focal spots at the ion positions.

</details>


### [32] [Multi-node quantum key distribution network using existing underground optical fibre infrastructure](https://arxiv.org/abs/2512.02701)
*Mariella Minder,Andreas Siakolas,Stephanos Yerolatsitis,Konstantinos Katzis,Kyriacos Kalli*

Main category: quant-ph

TL;DR: 在塞浦路斯首次部署了多节点量子网络，利用现有商业地下光纤基础设施，通过双向占用和波长复用实现高速率量子密钥分发


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)能提供无条件信息安全，但需要集成到现有通信基础设施上。当前网络攻击日益增多，需要为关键基础设施和机密信息交换提供安全解决方案

Method: 采用环形架构，利用现有商业地下光纤，通过双向占用光纤和波长复用技术，最小化暗光纤使用，实现多节点量子网络部署

Result: 在所有节点上获得一致的密钥生成速率，证实了在真实环境中可靠运行，展示了利用现有电信基础设施进行量子安全通信的可行性

Conclusion: 这项工作标志着向可扩展、经济高效的量子网络迈出了重要一步，适合关键应用，为量子网络安全通信提供了实际部署方案

Abstract: Quantum key distribution (QKD) offers unconditional information security by allowing two distant users to establish a common encryption key resilient to hacking. Resultingly, QKD networks interconnecting critical infrastructure and enabling the secure exchange of classified information, can provide a solution to the increasing number of successful cyberattacks. To efficiently deploy quantum networks, the technology must be integrated over existing communication infrastructure, such as optical fibre links. Yet, QKD poses stringent requirements on the conditions of the network over which it is deployed. This work demonstrates the first quantum communication network in Cyprus via the deployment of a multi-node quantum network, exploiting existing commercial underground optical fibre. The network employs bidirectional occupation of fibres and wavelength multiplexing in a ring architecture to achieve, with minimal use of dark fibres, high-rate QKD. Results obtained reveal consistent key generation rates across all nodes, confirming reliable operation in a real-world environment. This deployment highlights the feasibility of leveraging existing telecom infrastructure for quantum-secured communication, marking a significant step toward scalable and cost-effective quantum networks suited for critical applications.

</details>


### [33] [Lectures on Quantum Field Theory on a Quantum Computer](https://arxiv.org/abs/2512.02706)
*Aninda Sinha,Ujjwal Basumatary*

Main category: quant-ph

TL;DR: 量子场论量子计算方法的入门讲义，涵盖谐振子、φ⁴理论、Ising场论和Schwinger模型，包含量子计算基础和Tensor Network技术，附带QISKIT错误建模


<details>
  <summary>Details</summary>
Motivation: 为量子场论应用提供量子计算方法的入门教学材料，旨在让没有量子计算或量子场论背景的学习者能够理解，并准备在NISQ设备上运行

Method: 从谐振子入手，逐步扩展到1+1维量子场论模型，结合量子计算基础和Tensor Network技术，使用QISKIT进行错误建模

Result: 开发了一套完整的教学讲义和程序代码，涵盖量子场论量子计算的核心概念和技术，为实际NISQ设备运行做准备

Conclusion: 成功创建了量子场论量子计算方法的入门教学资源，为相关领域的学习和研究提供了实用工具和基础

Abstract: The lecture notes cover the basics of quantum computing methods for quantum field theory applications. No detailed knowledge of either quantum computing or quantum field theory is assumed and we have attempted to keep the material at a pedagogical level. We review the anharmonic oscillator, using which we develop a hands-on treatment of certain interesting QFTs in $1+1D$: $φ^4$ theory, Ising field theory, and the Schwinger model. We review quantum computing essentials as well as tensor network techniques. The latter form an essential part for quantum computing benchmarking. Some error modelling on QISKIT is also done in the hope of anticipating runs on NISQ devices.
  These lecture notes are the expanded version of a one semester course taught by AS during August-November 2025 at the Indian Institute of Science and TA-ed by UB. The programs written for this course are available in a GitHub repository.

</details>


### [34] [Generative modeling using evolved quantum Boltzmann machines](https://arxiv.org/abs/2512.02721)
*Mark M. Wilde*

Main category: quant-ph

TL;DR: 提出一种实用的量子玻尔兹曼机训练方法，用于玻恩规则生成建模，解决了该领域长期存在的训练难题。


<details>
  <summary>Details</summary>
Motivation: 量子玻尔兹曼机在量子机器学习中用于玻恩规则生成建模已有约十年历史，但一直缺乏有效的训练方法。本文旨在克服这一障碍，实现量子模型对经典方法难以学习和模拟的概率分布的高效捕获。

Method: 结合两个关键要素：经典相对熵的Donsker-Varadhan变分表示和Patel等人的量子玻尔兹曼梯度估计器。针对更一般的演化量子玻尔兹曼机（结合参数化实时间和虚时间演化）提出主要结果，并扩展到相对熵以外的可区分性度量。提出了四种不同的混合量子-经典算法用于训练中的极小极大优化。

Result: 开发出实用的量子玻尔兹曼机训练解决方案，能够处理更一般的演化量子玻尔兹曼机模型，并扩展到多种可区分性度量。提出的四种混合算法具有理论收敛保证。

Conclusion: 成功解决了量子玻尔兹曼机训练长期存在的难题，为玻恩规则生成建模提供了实用的训练方法，推动了量子机器学习在生成建模领域的应用。

Abstract: Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.

</details>


### [35] [Dynamic Modulation of Long Range Photon Magnon Coupling](https://arxiv.org/abs/2512.02732)
*Alban Joseph,Mawgan A. Smith,Martin P. Weides,Rair Macêdo*

Main category: quant-ph

TL;DR: 实验展示了通过远程耦合实现磁子-光子系统中能级吸引的时间域动态，利用辅助模式介导的非厄米耦合，实现了可调谐的耗散耦合强度


<details>
  <summary>Details</summary>
Motivation: 腔磁子学中已观察到非厄米行为（如能级吸引和异常点），但需要进一步研究远程耦合系统中时间域动态的耗散耦合特性

Method: 通过辅助模式介导的远程耦合，结合频域测量确认能级吸引，同时进行时域振铃衰减测量观察耗散耦合动态特征

Result: 实验直接观测到耗散耦合腔磁子模式的时间演化，证实了预测的能级吸引，并实现了原位可调谐的耗散耦合强度（包括完全抑制）

Conclusion: 该方法为探索可调谐非厄米物理提供了一个多功能平台，无需物理修改实验装置即可实现耗散耦合强度的原位调控

Abstract: Evidence of non-hermitian behavior has been recently demonstrated in cavity magnonics, including the emergence of mode level attraction and exceptional points in spectroscopic measurements. This work demonstrates experimental evidence of time-domain dynamics of magnon-photon systems that are coupled through a long-range interaction (i.e. remote coupling) exhibiting level attraction mediated by an auxiliary mode. We directly observe the temporal evolution of dissipatively coupled cavity-magnon modes, where heavily damped transmission line modes mediate the interaction. Our frequency-domain measurements confirm the predicted level attraction, while time-domain ring-down measurements reveal the characteristic signatures of dissipative coupling dynamics. Our approach offers in situ tunability over the dissipative coupling strength, including complete suppression, without requiring physical modifications to the experimental setup, providing a versatile platform for exploring tunable, non-Hermitian physics.

</details>


### [36] [Minimal decomposition entropy and optimal representations of absolutely maximally entangled states](https://arxiv.org/abs/2512.02749)
*N Ramadas*

Main category: quant-ph

TL;DR: 该论文研究绝对最大纠缠态的最小分解熵，提出数值算法计算该熵，发现AME态比Haar随机态具有更小的最小分解熵（q=2时）和更高的几何纠缠度量（q=∞时），算法还能生成更简洁的AME态分解。


<details>
  <summary>Details</summary>
Motivation: 理解和分类多体纠缠是量子信息处理的基础。最小分解熵作为多体纠缠的有用度量，能够识别使态最大局域化的乘积基，为分析多体态的局域幺正等价性和结构特性提供最优表示。

Method: 提出数值算法计算有限q>1时的最小分解熵。针对q=2和q=∞情况，在qubit、qutrit和ququad系统中获得AME态和Haar随机态的熵分布。算法还生成已知AME态的简化稀疏分解。

Result: 对于q=2，四个qutrit和四个ququad的AME态比Haar随机态具有更小的最小分解熵，表明其最优表示更局域化。对于q=∞（对应几何纠缠度量），AME态比Haar随机态显示更高的纠缠度。算法能区分真正量子AME态与经典组合设计相关的AME态。

Conclusion: 最小分解熵是分析多体纠缠的有效工具，AME态在特定参数下表现出与随机态不同的纠缠特性，算法为识别和表征AME态提供了实用方法，有助于区分量子与经典起源的AME态。

Abstract: Understanding and classifying multipartite entanglement is fundamental to quantum information processing. A useful measure of multipartite entanglement is the minimal decomposition entropy, defined as the minimum of the Rényi entropy $ S_q $ associated with the state's decomposition over all local product bases. This quantity identifies the product bases in which the state is maximally localized, thereby yielding optimal representations for analyzing local-unitary equivalence and structural properties of multipartite states.
  We investigate the minimal decomposition entropy for absolutely maximally entangled (AME) states, a class of highly entangled states characterized by their maximal entanglement across any bipartitions. We present a numerical algorithm for computing the minimal decomposition entropy for finite $ q>1 $. Entropy distributions for AME and Haar random states are obtained for $ q=2 $ and $ q=\infty $ in qubit, qutrit, and ququad systems. For $ q=2 $, AME states of four qutrits and four ququads exhibit smaller minimal decomposition entropy than Haar random states, indicating more localized optimal representations. For $ q=\infty $, corresponding to the geometric measure of entanglement, AME states display higher entanglement than Haar random states. The algorithm additionally produces simpler and sparser decompositions of known AME states, aiding in distinguishing genuinely quantum AME states from those associated with classical combinatorial designs.

</details>


### [37] [Observation of non-Hermitian many-body phase transition in a Rydberg-atom array](https://arxiv.org/abs/2512.02753)
*Yao-Wen Zhang,Biao Xu,Yijia Zhou,De-Sheng Xiang,Hao-Xiang Liu,Peng Zhou,Kuan Zhang,Ren Liao,Thomas Pohl,Weibin Li,Lin Li*

Main category: quant-ph

TL;DR: 实验在强相互作用Rydberg原子阵列中实现了非厄米XY模型，通过测量完全极化态的Loschmidt Echo，观测到PT对称性破缺相变的动力学特征，发现偶极相互作用在相变点和非厄米多体阻塞效应中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 非厄米量子力学中的PT对称性为研究开放量子系统中耗散与相干相互作用的复杂关系提供了强大框架。虽然PT对称性破缺已在多种物理系统中研究，但在量子多体层面上的观测仍然难以实现。

Method: 在强相互作用的Rydberg原子阵列中实验实现非厄米XY模型，通过测量完全极化态的Loschmidt Echo来探测PT对称性破缺相变的动力学特征。

Result: 观测到PT对称性破缺相变的明显动力学特征，发现偶极相互作用不仅决定相变点，还触发非厄米多体阻塞效应，保护Loschmidt Echo免于衰减，且对系统尺寸呈现非单调依赖关系。

Conclusion: 研究揭示了相互作用对PT对称性破缺的复杂影响，为超越单粒子和平均场范式探索非厄米多体动力学打开了大门。

Abstract: Non-Hermitian quantum mechanics with parity-time (PT) symmetry offers a powerful framework for exploring the complex interplay of dissipation and coherent interactions in open quantum systems. While PT-symmetry breaking has been studied in various physical systems, its observation on a quantum many-body level remains elusive. Here, we experimentally realize a non-Hermitian XY model in a strongly-interacting Rydberg-atom array. By measuring the Loschmidt Echo of a fully polarized state, we observe distinct dynamical signatures of a PT-symmetry-breaking phase transition. Dipole interactions are found to play a crucial role, not only determining the transition point but also triggering a non-Hermitian many-body blockade effect that protects the Loschmidt Echo from decay with a non-monotonic dependence on the system size. Our results reveal intricate interaction-induced effects on PT-symmetry breaking and open the door for exploring non-Hermitian many-body dynamics beyond single-particle and mean-field paradigms.

</details>


### [38] [Fault-tolerant quantum computation with constant overhead for general noise](https://arxiv.org/abs/2512.02760)
*Matthias Christandl,Omar Fawzi,Ashutosh Goswami*

Main category: quant-ph

TL;DR: 该论文证明了在一般电路级噪声模型下，使用恒定速率和线性最小距离的量子低密度奇偶校验码可以实现恒定量子比特开销的容错量子计算。


<details>
  <summary>Details</summary>
Motivation: 传统容错量子计算需要大量资源开销，量子比特和时间开销随计算规模呈多对数增长。虽然Gottesman先前工作表明在随机噪声下使用QLDPC码可以实现恒定量子比特开销，但在更一般的非随机噪声模型下是否同样成立仍是一个开放问题。

Method: 研究采用基于钻石范数定义的一般电路级噪声模型，该模型同时捕捉随机和非随机噪声（包括相干噪声和振幅阻尼噪声）。开发了容错纠错方案和逻辑门实现方法，使用具有恒定速率和线性最小距离的QLDPC码。

Result: 证明了在一般电路级噪声模型下，可以实现恒定量子比特开销的容错量子计算。这一结果扩展了先前仅适用于随机噪声的结论，适用于更广泛的噪声类型。

Conclusion: 该工作扩展了容错量子计算的理论基础，为在现实噪声模型下构建容错架构提供了新方向，表明恒定量子比特开销在一般噪声条件下也是可实现的。

Abstract: Fault-tolerant quantum computation traditionally incurs substantial resource overhead, with both qubit and time overheads scaling polylogarithmically with the size of the computation. While prior work by Gottesman showed that constant qubit overhead is achievable under stochastic noise using quantum low-density parity-check (QLDPC) codes, it has remained an open question whether similar guarantees hold under more general, non-stochastic noise models. In this work, we address this question by considering a general circuit-level noise model defined via the diamond norm, which captures both stochastic and non-stochastic noise, including coherent and amplitude damping noise. We prove that constant qubit overhead fault-tolerant quantum computation is achievable in this general setting, using QLDPC codes with constant rate and linear minimum distance. To establish our result, we develop a fault-tolerant error correction scheme and a method for implementing logic gates under general circuit noise. These results extend the theoretical foundations of fault-tolerant quantum computation and offer new directions for fault-tolerant architectures under realistic noise models.

</details>


### [39] [Effect of slowly decaying long-range interactions on topological qubits](https://arxiv.org/abs/2512.02809)
*Etienne Granet,Michael Levin*

Main category: quant-ph

TL;DR: 研究长程相互作用对拓扑基态简并鲁棒性的影响，发现在幂律衰减相互作用（α<1）下，基态劈裂呈拉伸指数衰减δ∼exp(-C L^{(1+α)/2})。


<details>
  <summary>Details</summary>
Motivation: 探索超出已知稳定性定理范围的长程相互作用（幂律衰减1/r^α，α小于空间维度）对拓扑基态简并鲁棒性的影响，这些相互作用无法用现有理论处理。

Method: 采用类似Coleman瞬子方法的路径积分技术，分析一维伊辛模型变体H = -∑σ_i^zσ_{i+1}^z + λ∑|i-j|^{-α}σ_i^xσ_j^x，以及Kitaev p波导线模型的长程密度-密度相互作用。还研究了另一个无需路径积分技术即可分析的长程相互作用玩具模型。

Result: 发现基态劈裂δ呈拉伸指数衰减：δ∼exp(-C L^{(1+α)/2})，其中L为系统尺寸。这种衰减比短程相互作用下的指数衰减更慢，表明长程相互作用对拓扑简并的破坏性更强。

Conclusion: 当相互作用衰减足够慢（α<1）时，拓扑基态简并的劈裂呈拉伸指数衰减，这意味着长程相互作用会显著影响拓扑序的稳定性，超出了现有稳定性定理的适用范围。

Abstract: We study the robustness of topological ground state degeneracy to long-range interactions in quantum many-body systems. We focus on slowly decaying two-body interactions that scale like a power-law $1/r^α$ where $α$ is smaller than the spatial dimension; such interactions are beyond the reach of known stability theorems which only apply to short-range or rapidly decaying long-range perturbations. Our main result is a computation of the ground state splitting of several toy models, which are variants of the 1D Ising model $H = -\sum_i σ^z_i σ^z_{i+1} + λ\sum_{ij} |i-j|^{-α} σ^x_i σ^x_j$ with $λ> 0$ and $α< 1$. These models are also closely connected to the Kitaev p-wave wire model with power-law density-density interactions. In these examples, we find that the splitting $δ$ scales like a stretched exponential $δ\sim \exp(-C L^{\frac{1+α}{2}})$ where $L$ is the system size. Our computations are based on path integral techniques similar to the instanton method introduced by Coleman. We also study another toy model with long-range interactions that can be analyzed without path integral techniques and that shows similar behavior.

</details>


### [40] [Implementation and Analysis of Quantum Majority Rules under Noisy Conditions](https://arxiv.org/abs/2512.02813)
*Gal Amit,Yuval Idan,Michael Suleymanov,Luis Razo,Eliahu Cohen*

Main category: quant-ph

TL;DR: 量子投票协议QMR在含噪声量子硬件上的实现分析，显示中等噪声下保持定性行为，强噪声改变胜者分布，并探索了基于纠缠的QMR2变体。


<details>
  <summary>Details</summary>
Motivation: 将抽象的量子多数规则(QMR)宪法连接到具体的NISQ设备实现，研究现实噪声如何影响量子投票协议的社会排名分布，为未来量子投票协议设计提供参考。

Method: 1. 在经典配置数据上分析评估QMR宪法；2. 将最终测量阶段实现为量子电路，在无噪声模拟器和含噪声IBM量子硬件上运行；3. 使用胜者一致率、孔多塞胜者翻转率和Jensen-Shannon散度量化噪声影响；4. 探索基于纠缠的QMR2变体，测试多投票者量子关联在噪声下的表现。

Result: 1. 中等-高单量子比特噪声不改变QMR的定性行为；2. 强噪声使分布向非经典主导胜者偏移；3. GHZ型和可分离叠加态在期望值相同但对噪声响应不同；4. 量子关联在噪声下表现出不同稳定性。

Conclusion: QMR宪法可在NISQ设备上实现，噪声影响可控但需考虑，基于纠缠的变体为量子投票协议设计提供了新思路，连接了抽象理论与实际实现。

Abstract: Quantum voting, inspired by quantum game theory, provides a framework in which the quantum majority rule (QMR) constitution of Bao and Yunger Halpern [Phys. Rev. A 95, 062306 (2017)] violates the quantum analogue of Arrow's impossibility theorem. We evaluate this QMR constitution analytically on classical profile data and implement its final measurement stage as a quantum circuit, running on both noiseless simulators and noisy IBM quantum hardware to map how realistic noise deforms the resulting societal ranking distribution. Moderate-high single-qubit noise does not change the qualitative behavior of QMR, whereas strong noise shifts the distribution toward other dominant winners than the classical one. We quantify this behavior using winner-agreement rates, Condorcet-winner flip rates, and Jensen-Shannon divergence between societal ranking distributions. In a second, exploratory component, we demonstrate an explicitly entanglement-based variant of the QMR constitution that serves as a testbed for multi-voter quantum correlations under noise, which we refer to as the QMR2-inspired variant. There, GHZ-type and separable superpositions over opposite rankings have the same expectation values but respond very differently to noise. Taken together, these two components connect the abstract QMR constitution to concrete implementations on noisy intermediate-scale quantum (NISQ) devices and highlight design considerations for future quantum voting protocols.

</details>


### [41] [Phononic Casimir Effect in Planar Materials](https://arxiv.org/abs/2512.02815)
*Pablo Rodriguez-Lopez,Dai-Nam Le,Lilia M. Woods*

Main category: quant-ph

TL;DR: 研究平面物体间的声子卡西米尔效应，发现耦合主要由一种极化模式主导，其他两种因指数抑制而影响小。该效应在某些材料组合中可与电磁卡西米尔效应相当。


<details>
  <summary>Details</summary>
Motivation: 研究声子作为有效弹性介质中介的涨落诱导耦合，探索声子卡西米尔效应的物理机制及其与电磁卡西米尔效应的比较。

Method: 从系统的量子配分函数出发，采用多重散射方法建立形式理论，将声子建模为有效弹性介质，解析边界条件得到三种极化激发。

Result: 发现耦合主要由一种极化自由度主导，其他两种因指数抑制效应而贡献很小；获得了标度律和材料特性、温度依赖性，为相互作用控制提供了有效途径。

Conclusion: 声子卡西米尔效应在某些材料组合中可与标准电磁卡西米尔效应相当，为涨落诱导相互作用的控制开辟了新途径。

Abstract: The Phononic Casimir effect between planar objects is investigated by deriving a formalism from the quantum partition function of the system following multiscattering approach. This fluctuation-induced coupling is mediated by phonons modeled as an effective elastic medium. We find that excitations with three types of polarizations arise from the resolved boundary conditions, however the coupling is dominated by only one of these degrees of freedom due to exponential suppression effects in the other two. The obtained scaling laws and dependence on materials properties and temperature suggest effective pathways of interaction control. Scenarios of materials combinations are envisioned where the Phononic Casimir effect is of similar order as the standard Casimir interaction mediated by electromagnetic fluctuations.

</details>


### [42] [Experimental Blueprint for Distinguishing Decoherence from Objective Collapse](https://arxiv.org/abs/2512.02838)
*Ridha Horchani*

Main category: quant-ph

TL;DR: 提出一个基于悬浮光力学的实验框架，用于区分环境退相干和波函数坍缩机制，通过制备介电纳米球的薛定谔猫态并进行贝叶斯推断来检验量子线性性。


<details>
  <summary>Details</summary>
Motivation: 量子到经典的过渡是物理学中最深刻的开放问题之一。宏观叠加态的缺失通常归因于环境退相干或波函数坍缩机制，但缺乏区分这两种可能性的定量实验框架。

Method: 提出悬浮光力学平台，在介电纳米球的质心运动中产生可控的薛定谔猫态。建立包含气体碰撞、黑体辐射和光子反冲噪声的综合主方程作为环境基准，并将连续自发定域化模型嵌入同一框架。

Result: CSL模型预测退相干速率随叠加尺寸饱和且与质量平方成正比。提出贝叶斯推断协议来区分坍缩引起的额外退相干与环境噪声。

Conclusion: 该框架为量子线性性的决定性检验提供了具体实验蓝图，要么揭示超越标准量子力学的新物理，要么为客观坍缩参数设定最严格的界限。

Abstract: The transition from the quantum to the classical realm remains one of the most profound open questions in physics. While quantum theory predicts the existence of macroscopic superpositions, their apparent absence in the everyday world is attributed either to environmental decoherence or to an intrinsic mechanism for wave-function collapse. This work presents a quantitative and experimentally grounded framework for distinguishing these possibilities. We propose a levitated optomechanical platform capable of generating controllable Schrodinger-cat states in the center of mass motion of a dielectric nanosphere. A comprehensive master equation incorporates gas collisions, black-body radiation, and photon-recoil noise, establishing a calibrated environmental baseline. The Continuous Spontaneous Localization (CSL) model is embedded within the same framework, predicting a characteristic saturation of the decoherence rate with superposition size and a quadratic scaling with mass. A Bayesian inference protocol is outlined to discriminate collapse induced excess decoherence from environmental noise. Together these elements provide a concrete experimental blueprint for a decisive test of quantum linearity, either revealing new physics beyond standard quantum mechanics or setting the most stringent bounds to date on objective-collapse parameters.

</details>


### [43] [Detecting Symmetrizability in Physical Systems](https://arxiv.org/abs/2512.02869)
*Florian Seitz,Janis Nötzel*

Main category: quant-ph

TL;DR: 提出多项式时间算法判断AVC是否非对称化，并展示能量约束下算法能高效识别大量非对称化AVC类


<details>
  <summary>Details</summary>
Motivation: 研究无线系统中受干扰器影响的数据传输问题，该问题通常建模为任意变化信道（AVC）。对称化AVC容易受到拒绝服务攻击，但判断AVC是否对称化是非图灵可计算问题，需要寻找高效判定方法。

Method: 通过放松对称化定义，提出多项式时间算法判断给定AVC是否非对称化。算法性能依赖于干扰器输入状态数量。进一步对干扰器施加能量约束，使算法能高效识别大量非对称化AVC类。

Result: 证明了存在多项式时间算法可判定AVC的非对称化性质，但算法性能受干扰器输入状态数影响。在能量约束条件下，同一算法能高效识别大量非对称化AVC类。

Conclusion: 通过放松对称化定义并引入能量约束，成功开发出高效算法来识别非对称化AVC，为解决无线系统中干扰器导致的拒绝服务攻击问题提供了实用工具。

Abstract: We study the problem of data transmission under the influence of a jammer, which is typical for wireless systems and commonly modeled as an arbitrarily varying channel (AVC) in information theory. AVC fulfilling a certain set of linear equations are called symmetrizable and are known to be prone to denial of service attacks. Recent work has shown that deciding if a given AVC is symmetrizable or not is a non-Turing computable problem. By relaxing the formulation of symmetrizability, we show the existence of a polynomial-time algorithm that determines whether a given AVC is non-symmetrizable, but displays a critical dependence on the number of jammer input states. We then show how imposing an energy constraint on the jammer allows the same algorithm to efficiently identify large classes of AVCs which are non-symmetrizable.

</details>


### [44] [SDQC: Distributed Quantum Computing Architecture Utilizing Entangled Ion Qubit Shuttling](https://arxiv.org/abs/2512.02890)
*Seunghyun Baek,Seok-Hyung Lee,Dongmoon Min,Junki Kim*

Main category: quant-ph

TL;DR: 提出SDQC混合架构，结合物理量子比特穿梭与分布式量子计算，通过确定性穿梭分发纠缠离子比特实现非局域量子操作，在保持高保真度的同时利用并行性和流水线优势。


<details>
  <summary>Details</summary>
Motivation: 为了扩展囚禁离子量子计算的可扩展性，结合物理量子比特穿梭的高保真确定性操作与分布式量子计算的并行流水线优势，解决大规模量子计算的需求。

Method: 1) 提出包含量子纠错的实用架构；2) 开发利用纠缠分发和测量并行性的流水线策略；3) 通过确定性穿梭分发纠缠离子比特实现非局域量子操作。

Result: 对于需要2,871个逻辑量子比特的256位椭圆曲线离散对数问题，SDQC的逻辑错误率是光子DQC的1.20×10⁻⁸倍，是QCCD的3.79×10⁻³倍，同时逻辑时钟速度比QCCD快2.82倍。

Conclusion: SDQC架构成功结合了穿梭和分布式量子计算的优势，在逻辑错误率和时钟速度方面显著优于现有架构，为实现可扩展的囚禁离子量子计算提供了有前景的解决方案。

Abstract: We propose Shuttling-based Distributed Quantum Computing (SDQC), a hybrid architecture that combines the strengths of physical qubit shuttling and distributed quantum computing to enable scalable trapped-ion quantum computing. SDQC performs non-local quantum operations by distributing entangled ion qubits via deterministic shuttling, combining the high-fidelity and deterministic operations of shuttling-based architectures with the parallelism and pipelining advantages of distributed quantum computing. We present (1) a practical architecture incorporating quantum error correction (QEC), (2) pipelining strategies to exploit parallelism in entanglement distribution and measurement, and (3) a performance evaluation in terms of logical error rate and clock speed. For a 256-bit elliptic-curve discrete logarithm problem (ECDLP) instance, which requires 2,871 logical qubits at code distance 13, SDQC achieves a logical error rate which is $1.20^{+0.94}_{-0.45}\times10^{-8}$ of Photonic DQC error rate and $3.79^{+5.09}_{-2.84}\times10^{-3}$ of Quantum Charge-Coupled Device (QCCD) error rate, while providing 2.82 times faster logical clock speed than QCCD.

</details>


### [45] [Time-series forecasting with multiphoton quantum states and integrated photonics](https://arxiv.org/abs/2512.02928)
*Rosario Di Bartolo,Simone Piacentini,Francesco Ceccarelli,Giacomo Corrielli,Roberto Osellame,Valeria Cimini,Fabio Sciarrino*

Main category: quant-ph

TL;DR: 该论文在可重构线性光学集成光子电路中实现了量子储层计算协议，利用多光子设置进行时间序列预测，并实验证明双光子不可区分输入状态相比可区分状态能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习算法在光子平台中受到关注，可重构集成光子电路因其能够实现自适应反馈回路而成为实现神经网络非线性行为的理想平台。研究旨在探索量子储层计算协议在光子平台中的应用，并特别关注输入光子不可区分性对系统性能的影响。

Method: 采用量子储层计算协议，通过可重构线性光学集成光子电路处理信息，使用单光子探测器测量。输入信号编码在电路的光学相位中，调制量子储层状态。输出概率用于设置反馈相位，最终通过线性回归训练的经典数字层进行预测。特别研究了输入光子不可区分性对储层预测能力的影响。

Result: 实验证明双光子不可区分输入状态相比可区分状态能显著提升时间序列预测性能。这种增强源于不可区分状态中的量子相关性，使系统能够用相当的物理资源近似更高阶非线性函数。

Conclusion: 量子干涉和不可区分性作为光子量子储层计算中的重要资源，能够显著提升系统性能。不可区分光子状态中的量子相关性为使用相当物理资源实现更强大计算能力提供了途径。

Abstract: Quantum machine learning algorithms have very recently attracted significant attention in photonic platforms. In particular, reconfigurable integrated photonic circuits offer a promising route, thanks to the possibility of implementing adaptive feedback loops, which is an essential ingredient for achieving the necessary nonlinear behavior characteristic of neural networks. Here, we implement a quantum reservoir computing protocol in which information is processed through a reconfigurable linear optical integrated photonic circuit and measured using single-photon detectors. We exploit a multiphoton-based setup for time-series forecasting tasks in a variety of scenarios, where the input signal is encoded in one of the circuit's optical phases, thus modulating the quantum reservoir state. The resulting output probabilities are used to set the feedback phases and, at the end of the computation, are fed to a classical digital layer trained via linear regression to perform predictions. We then focus on the investigation of the role of input photon indistinguishability in the reservoir's capabilities of predicting time-series. We experimentally demonstrate that two-photon indistinguishable input states lead to significantly better performance compared to distinguishable ones. This enhancement arises from the quantum correlations present in indistinguishable states, which enable the system to approximate higher-order nonlinear functions when using comparable physical resources, highlighting the importance of quantum interference and indistinguishability as a resource in photonic quantum reservoir computing.

</details>


### [46] [Stability of quantum chaos against weak non-unitarity](https://arxiv.org/abs/2512.02934)
*Yi-Cheng Wang,Ehud Altman,Samuel J. Garratt*

Main category: quant-ph

TL;DR: 研究非幺正演化算符在量子比特系统中的重复作用，发现指数级缓慢的纯化现象源于复平面上形成环状且边缘尖锐的特征值分布，揭示了量子混沌与系统对初始条件敏感性之间的联系。


<details>
  <summary>Details</summary>
Motivation: 研究非幺正演化算符如何影响量子系统的动力学行为，特别是打破幺正性可能导致混合初始态的纯化，这会消除动力学混沌的关键特征。然而量子信息的扰乱可能延迟纯化过程，本文旨在理解这种延迟现象与演化算符谱特性之间的关系。

Method: 研究固定时间演化算符的系统，其中所有动力学特性原则上编码在单步演化算符的谱特性中。使用全局Haar随机幺正算符和非幺正单量子比特操作构建演化算符，分析特征值在复平面上的分布特性，计算谱形状因子来研究能级排斥现象。

Result: 发现指数级缓慢的纯化现象源于复平面上形成环状分布的特征值，该环在较大半径处具有尖锐边缘，且特征值密度在这些边缘附近呈指数级增大。尖锐边缘源于复平面上径向的能级吸引，而方位角方向存在能级排斥，即使靠近特征值环的外边缘也是如此。

Conclusion: 该研究建立了量子混沌的谱特征与系统对初始条件敏感性之间的联系，揭示了非幺正演化系统中指数级缓慢纯化现象的谱机制，为理解量子混沌在非幺正系统中的表现提供了新视角。

Abstract: We study the quantum dynamics generated by the repeated action of a non-unitary evolution operator on a system of qubits. Breaking unitarity can lead to the purification of mixed initial states, which corresponds to the loss of sensitivity to initial conditions, and hence the absence of a key signature of dynamical chaos. However, the scrambling of quantum information can delay purification to times that are exponential in system size. Here we study purification in systems whose evolution operators are fixed in time, where all aspects of the dynamics are in principle encoded in spectral properties of the evolution operator for a single time step. The operators that we study consist of global Haar random unitary operators and non-unitary single-qubit operations. We show that exponentially slow purification arises from a distribution of eigenvalues in the complex plane that forms a ring with sharp edges at large radii, with the eigenvalue density exponentially large near these edges. We argue that the sharp edges of the eigenvalue distribution arise from level attraction along the radial direction in the complex plane. By calculating the spectral form factor we also show that there is level repulsion around the azimuthal direction, even close to the outer edge of the ring of eigenvalues. Our results connect this spectral signature of quantum chaos to the sensitivity of the system to its initial conditions.

</details>


### [47] [Scalable Quantum Walk-Based Heuristics for the Minimum Vertex Cover Problem](https://arxiv.org/abs/2512.02940)
*F. S. Luiz,A. K. F. Iwakami,D. H. Moraes,M. C. de Oliveira*

Main category: quant-ph

TL;DR: 提出基于连续时间量子行走的启发式算法求解最小顶点覆盖问题，通过动态解耦机制隔离已选顶点，使用紧凑二进制编码大幅减少量子资源需求，在多种图结构上优于经典启发式算法。


<details>
  <summary>Details</summary>
Motivation: 最小顶点覆盖是NP难问题，在基础设施韧性、流行病控制、传感器网络优化等领域有重要应用。现有经典启发式算法在复杂网络结构上表现有限，需要探索量子计算方法以获得更好的近似解。

Method: 基于连续时间量子行走框架，量子行走者在图上的相干传播将结构特性编码到状态振幅中。引入动态解耦（"冻结"）机制隔离已选顶点，防止干扰后续迭代。采用紧凑二进制编码，仅需⌈log₂(V)⌉个量子比特表示V个顶点的图。

Result: 与混合整数线性规划精确解及模拟退火、FastVC、2-近似算法等经典启发式相比，CTQW启发式算法在Erdős-Rényi、Barabási-Albert和正则随机图集合上均获得更优的近似比，对网络拓扑表现出显著鲁棒性。

Conclusion: 连续时间量子行走结合拓扑无关的解耦策略为大规模组合优化和复杂网络控制提供了强大范式，在基础设施韧性、流行病控制、传感器网络优化和生物系统分析等领域具有应用潜力。

Abstract: We propose a novel heuristic quantum algorithm for the Minimum Vertex Cover (MVC) problem based on continuous-time quantum walks (CTQWs). In this framework, the coherent propagation of a quantum walker over a graph encodes its structural properties into state amplitudes, enabling the identification of highly influential vertices through their transition probabilities. To enhance stability and solution quality, we introduce a dynamic decoupling (``freezing'') mechanism that isolates vertices already selected for the cover, preventing their interference in subsequent iterations of the algorithm. The method employs a compact binary encoding, requiring only $\lceil \log_2 (V)\rceil$ qubits to represent a graph with $V$ vertices, resulting in an exponential reduction of quantum resources compared to conventional vertex-based encodings. We benchmark the proposed heuristic against exact solutions obtained via Mixed-Integer Linear Programming (MILP) and against established classical heuristics, including Simulated Annealing, FastVC, and the 2-Approximation algorithm, across Erdős--Rényi, Barabási--Albert and regular random graph ensembles. Our results demonstrate that the CTQW-based heuristic consistently achieves superior approximation ratios and exhibits remarkable robustness with respect to network topology, outperforming classical approaches in both heterogeneous and homogeneous structures. These findings indicate that continuous-time quantum walks, when combined with topology-independent decoupling strategies, provide a powerful paradigm for large-scale combinatorial optimization and complex network control, with potential applications spanning infrastructure resilience, epidemic containment, sensor network optimization, and biological systems analysis.

</details>


### [48] [Quantum hypergraph states: a concise review](https://arxiv.org/abs/2512.02955)
*Vinícius Salem*

Main category: quant-ph

TL;DR: 本文综述了量子超图态的定义及其在离散变量和连续变量量子信息中的主要应用


<details>
  <summary>Details</summary>
Motivation: 量子超图态作为图态的推广在量子信息与计算领域具有重要意义，需要系统梳理其定义和应用进展

Method: 综述性研究方法，回顾和整理量子超图态的相关文献和进展

Result: 系统阐述了量子超图态的定义及其在量子信息处理中的各种应用

Conclusion: 量子超图态作为真正的多体纠缠态，在量子信息与计算领域具有重要价值和应用前景

Abstract: Quantum hypergraph states emerged in the literature as a generalization of graph states, and since then, much has been developed in the direction of implementing this class of genuine multipartite entangled states for quantum information and computation. Here, we review the definition of hypergraph states and their main applications so far, both in discrete-variable and continuous-variable quantum information.

</details>


### [49] [Systematic construction of ROCN Bell-inequalities](https://arxiv.org/abs/2512.02957)
*Arturo Konderak,Patryk Michalski*

Main category: quant-ph

TL;DR: 提出基于对称生成集的量子自测试新准则，为任意维度设计自测试贝尔不等式提供显式构造方法


<details>
  <summary>Details</summary>
Motivation: 现有自测试方法主要基于作者先前提出的Clifford生成元框架，需要发展更直接、显式的构造方法，特别是在任意维度下的自测试贝尔不等式设计

Method: 开发基于对称生成集的自测试准则，提供显式构造路径，作为作者先前Clifford生成元框架的补充和替代方法

Result: 建立了新的自测试理论框架，能够系统性地为任意维度设计自测试贝尔不等式，提供更直接的构造方法

Conclusion: 对称生成集方法为量子自测试提供了有效的补充工具，特别适用于任意维度下的贝尔不等式构造，增强了设备无关认证的能力

Abstract: Self-testing constitutes one of the most powerful forms of device certification, enabling a complete and device-independent characterization of a quantum apparatus solely from the observed correlations. In recent work by the authors [23], a general framework was introduced for constructing Bell inequalities that self-test entire families of Clifford generators. In this manuscript, we develop an alternative and complementary self-testing criterion based on symmetric spanning sets. This formulation provides an explicit and constructive route to designing self-testing Bell inequalities in arbitrary dimensions.

</details>


### [50] [Many-body $k$-local ground states as probes for unitary quantum metrology](https://arxiv.org/abs/2512.02976)
*Majid Hassani,Mengyao Hu,Guillem Müller-Rigat,Matteo Fadel,Jordi Tura*

Main category: quant-ph

TL;DR: 研究在仅含少体关联的实验可行哈密顿量约束下，多体量子态的计量性能，发现典型随机对称基态仍能实现海森堡极限标度


<details>
  <summary>Details</summary>
Motivation: 虽然达到海森堡极限灵敏度的多体量子态通常需要全关联，但实验上可行的哈密顿量往往只包含少体关联，需要研究在这种约束下的计量性能

Method: 使用量子费希尔信息工具，研究任意编码生成元（包括参数依赖）下，k-体置换不变哈密顿量的典型随机对称基态的计量特性

Result: 发现典型随机对称基态仍能实现海森堡标度，并建立了哈密顿量能隙（表征制备难度）与对应基态量子费希尔信息之间的权衡关系

Conclusion: 在实验可行的少体关联哈密顿量约束下，仍能实现海森堡极限计量性能，为实际量子计量实验提供了理论指导

Abstract: Multipartite quantum states saturating the Heisenberg limit of sensitivity typically require full-body correlators to be prepared. On the other hand, experimentally practical Hamiltonians often involve few-body correlators only. Here, we study the metrological performances under this constraint, using tools derived from the quantum Fisher information. Our work applies to any encoding generator, also including a dependence on the parameter. We find that typical random symmetric ground states of $k$-body permutation-invariant Hamiltonians exhibit Heisenberg scaling. Finally, we establish a tradeoff between the Hamiltonian's gap, which quantifies preparation hardness, and the quantum Fisher information of the corresponding ground state.

</details>


### [51] [Structured Clifford+T Circuits for Efficient Generation of Quantum Chaos](https://arxiv.org/abs/2512.02996)
*Asim Sharma,Avah Banerjee*

Main category: quant-ph

TL;DR: 该论文研究了在去随机化的Clifford+T电路中，通过因果覆盖架构实现量子混沌和酉T-design行为的涌现。研究发现因果连通性（而非电路深度或随机性）是驱动电路走向混沌的关键特征。


<details>
  <summary>Details</summary>
Motivation: 需要确定性的电路构造，能够在不同的量子硬件平台上展现混沌行为。研究旨在探索确定性Clifford电路架构如何驱动量子电路走向Wigner-Dyson纠缠谱统计和OTOC衰减。

Method: 使用确定性Clifford电路架构（包括带因果覆盖的随机Clifford电路、比特排序网络和基于置换的路由电路）。实验设计包括：用n个T态初始化，在因果覆盖的Clifford演化后添加第二个T层，以观察OTOC衰减和WD统计。

Result: 实验表明因果连通性是驱动电路走向混沌的关键特征。初始化n个T态并在因果覆盖的Clifford演化后添加第二个T层，能够产生一致的OTOC衰减和WD统计。确定性的多对数深度电路足以近似混沌行为。

Conclusion: 因果连通性足以实现算符扩散，从而诱导Wigner-Dyson纠缠统计和OTOC衰减。这为理解产生复杂纠缠行为的电路结构提供了更深入的见解，并表明确定性的多对数深度电路就足以近似混沌行为。

Abstract: We investigate the emergence of quantum chaos and unitary T-design behavior in derandomized Clifford+T circuits using causal cover architectures. Motivated by the need for deterministic constructions that can exhibit chaotic behavior across diverse quantum hardware platforms, we explore deterministic Clifford circuit architectures (random Clifford circuits with causal cover, bitonic sorting networks, and permutation-based routing circuits) to drive quantum circuits toward Wigner-Dyson (WD) entanglement spectrum statistics and OTOC decay.Our experiments demonstrate that causal connectivity, not circuit depth or randomness, is a critical feature that drives circuits to chaos. We show that initializing with n T-states and adding a second T-layer after a causally covered Clifford evolution yields consistent OTOC decay and WD statistics. This also enables deeper understanding of the circuit structures that generate complex entanglement behavior. Notably, our work suggests polylogarithmic-depth deterministic circuits suffice to approximate chaotic behavior, highlighting that causal connectivity is sufficient for operator spreading to induce Wigner-Dyson entanglement statistics and OTOC decay.

</details>


### [52] [Combinatorial foundations for solvable chaotic local Euclidean quantum circuits in two dimensions](https://arxiv.org/abs/2512.03029)
*Fredy Yip*

Main category: quant-ph

TL;DR: 证明了二维整数格点图Z²具有"有界测地线切片"性质，这意味着可以在二维欧几里得晶格上设计精确可解的混沌局域量子电路，并具有非平凡关联模式。


<details>
  <summary>Details</summary>
Motivation: 研究源于量子计算中关于量子电路中信息传播的问题。探索图论性质与量子电路设计之间的关系，特别是寻找能够在二维晶格上实现精确可解混沌量子电路的图结构。

Method: 定义了图的"有界扩展"和"有界测地线切片"概念，引入了"测地线可定向图"的数学框架。通过图论方法证明Z²及其有界扩展具有测地线可定向性。

Result: 证明了Z²是测地线可定向的，且Z²的任何有界扩展都是测地线可定向的。进一步推导出所有二维规则铺砌都是测地线可定向的。

Conclusion: 该结果为在二维欧几里得晶格上设计精确可解的混沌局域量子电路提供了理论基础，打破了先前认为Z²不具备此性质的预期，为量子信息处理开辟了新可能性。

Abstract: We investigate a graph-theoretic problem motivated by questions in quantum computing concerning the propagation of information in quantum circuits. A graph $G$ is said to be a bounded extension of its subgraph $L$ if they share the same vertex set, and the graph distance $d_L(u, v)$ is uniformly bounded for edges $uv\in G$. Given vertices $u, v$ in $G$ and an integer $k$, the geodesic slice $S(u, v, k)$ denotes the subset of vertices $w$ lying on a geodesic in $G$ between $u$ and $v$ with $d_G(u, w) = k$. We say that $G$ has bounded geodesic slices if $|S(u, v, k)|$ is uniformly bounded over all $u, v, k$. We call a graph $L$ geodesically directable if it has a bounded extension $G$ with bounded geodesic slices.
  Contrary to previous expectations, we prove that $\mathbb{Z}^2$ is geodesically directable. Physically, this provides a setting in which one could devise exactly-solvable chaotic local quantum circuits with non-trivial correlation patterns on 2D Euclidean lattices. In fact, we show that any bounded extension of $\mathbb{Z}^2$ is geodesically directable. This further implies that all two-dimensional regular tilings are geodesically directable.

</details>


### [53] [Information dynamics and symmetry breaking in generic monitored $\mathbb{Z}_2$-symmetric open quantum systems](https://arxiv.org/abs/2512.03031)
*Jacob Hauser,Ali Lavasani,Sagar Vijay,Matthew P. A. Fisher*

Main category: quant-ph

TL;DR: 研究具有ℤ₂对称性的开放量子动力学系统的稳态相，通过信息论诊断和对称性破缺描述三种相：完全破缺相、强弱破缺相和未破缺相。


<details>
  <summary>Details</summary>
Motivation: 研究具有ℤ₂对称性的开放量子动力学系统的稳态相，理解信息保留、泄露和观测者学习等不同信息行为与对称性破缺的关系。

Method: 使用信息论诊断和强弱对称性破缺分析，通过路径积分方法将双态系统约化为经典2D随机键Ising模型，并利用高效张量网络模拟进行数值验证。

Result: 发现三种稳态相：完全破缺相（信息保留在量子系统中）、强弱破缺相（信息泄露到环境）、未破缺相（信息被观测者学习）。在仅含测量的临界点处获得特殊的自对偶随机键Ising模型。

Conclusion: 弱测量和退相干构成ℤ₂对称开放系统的最小模型，信息行为与对称性破缺模式密切相关，路径积分方法为理解这类系统提供了统一框架。

Abstract: We investigate the steady-state phases of generic $\mathbb{Z}_2$-symmetric monitored, open quantum dynamics. We describe the phases systematically in terms of both information-theoretic diagnostics and spontaneous breaking of strong and weak symmetries of the dynamics. We find a completely broken phase where information is retained by the quantum system, a strong-to-weak broken phase where information is leaked to the environment, and an unbroken phase where information is learned by the observer. We find that weak measurement and dephasing alone constitute a minimal model for generic open systems with $\mathbb{Z}_2$ symmetry, but we also explore perturbations by unitary gates. For a 1d set of qubits, we examine information-theoretic and symmetry-breaking observables in the path integral of the doubled state. This path integral reduces to the standard classical 2d random-bond Ising model in certain limits but generically involves negative weights, enabling a special self-dual random-bond Ising model at the critical point when only measurements are present. We obtain numerical evidence for the steady-state phases using efficient tensor network simulations of the doubled state.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [54] [Towards a fully differentiable digital twin for solar cells](https://arxiv.org/abs/2512.02904)
*Marie Louise Schubert,Houssam Metni,Jan David Fischbach,Benedikt Zerulla,Marjan Krstić,Ulrich W. Paetzold,Seyedamir Orooji,Olivier J. J. Ronsin,Yasin Ameslon,Jens Harting,Thomas Kirchartz,Sandheep Ravishankar,Chris Dreessen,Eunchi Kim,Christian Sprau,Mohamed Hussein,Alexander Colsmann,Karen Forberich,Klaus Jäger,Pascal Friederich,Carsten Rockstuhl*

Main category: physics.comp-ph

TL;DR: 提出可微分数字孪生Sol(Di)$^2$T，实现太阳能电池从材料到发电量的端到端优化


<details>
  <summary>Details</summary>
Motivation: 现有太阳能电池模拟通常只关注孤立方面，缺乏统一框架来准确预测和优化年发电量，特别是对于新兴技术

Method: 开发可微分数字孪生Sol(Di)$^2$T，从材料特性开始，经过光学和电学模拟，最后结合气候条件和地理位置预测发电量，每个步骤都实现可微分或使用机器学习代理模型

Result: 该框架不仅能准确预测发电量，还能进行基于梯度的参数优化，将发电量预测扩展到以前未探索的条件，在有机太阳能电池上得到验证

Conclusion: Sol(Di)$^2$T标志着为特定应用定制太阳能电池并确保最大性能的重要进展

Abstract: Maximizing energy yield (EY) - the total electric energy generated by a solar cell within a year at a specific location - is crucial in photovoltaics (PV), especially for emerging technologies. Computational methods provide the necessary insights and guidance for future research. However, existing simulations typically focus on only isolated aspects of solar cells. This lack of consistency highlights the need for a framework unifying all computational levels, from material to cell properties, for accurate prediction and optimization of EY prediction. To address this challenge, a differentiable digital twin, Sol(Di)$^2$T, is introduced to enable comprehensive end-to-end optimization of solar cells. The workflow starts with material properties and morphological processing parameters, followed by optical and electrical simulations. Finally, climatic conditions and geographic location are incorporated to predict the EY. Each step is either intrinsically differentiable or replaced with a machine-learned surrogate model, enabling not only accurate EY prediction but also gradient-based optimization with respect to input parameters. Consequently, Sol(Di)$^2$T extends EY predictions to previously unexplored conditions. Demonstrated for an organic solar cell, the proposed framework marks a significant step towards tailoring solar cells for specific applications while ensuring maximal performance.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [55] [Exceptional Points and Resonance in Black Hole Ringdown](https://arxiv.org/abs/2512.02110)
*Rodrigo Panosso Macedo,Takuya Katagiri,Kei-ichiro Kubota,Hayato Motohashi*

Main category: gr-qc

TL;DR: 提出基于异常点(EP)框架的黑洞环降理论，超越传统准正规模(QNM)范式，能够捕捉避免交叉附近的共振效应。


<details>
  <summary>Details</summary>
Motivation: 传统QNM分析无法完全捕捉异常点附近避免交叉相关的共振效应，需要新的理论框架来更好地描述黑洞环降现象。

Method: 采用现象学环境黑洞模型结合双曲面框架，识别QNM特征值和特征函数的近合并现象，并直接展示共振在时域中产生的增强模式贡献。

Result: 发现共振导致特征性的偏离指数衰减振荡，异常点频率（作为共振模式的平均值）在近异常点区域成为物理可观测量，为建模和提取共振环降信号提供稳健基础。

Conclusion: 异常点框架为黑洞环降提供了超越传统QNM范式的新理论工具，能够更准确地描述和提取共振信号，对引力波天文学有重要意义。

Abstract: We propose an exceptional-point (EP) framework for black-hole ringdown beyond the standard quasinormal-mode (QNM) paradigm. It provides a first-principles characterization of the resonance associated with avoided crossings near EPs, an effect that conventional QNM analysis cannot fully capture. Employing a phenomenological environmental black-hole model with the hyperboloidal framework, we identify near-coalescence of both QNM eigenvalues and eigenfunctions, and directly demonstrate that the resonance produces enhanced mode contributions in the time domain, resulting in characteristic departures from exponentially damped oscillations. Our formulation further reveals that the EP frequency, given by the averaged value of the resonant modes, emerges as the physically relevant observable in the near-EP regime, and offers a robust foundation for modeling and extracting resonant ringdown signals.

</details>


### [56] [Revisiting the gravitational "arrow of time"](https://arxiv.org/abs/2512.02238)
*Roberto A. Sussman,Sebastián Nájera,Fernando A. Pizaña,Juan Carlos Hidalgo*

Main category: gr-qc

TL;DR: 该论文澄清了彭罗斯提出的引力"时间箭头"（韦尔曲率假说）的一个长期误解，通过分析邦诺在瓦伊迪亚背景下热传导球体坍缩的精确解，证明该反例在接近FLRW宇宙学模型的物理可行解中不成立。


<details>
  <summary>Details</summary>
Motivation: 解决关于引力"时间箭头"（韦尔曲率假说）的长期误解，该假说认为结构形成沿着韦尔曲率标量主导里奇标量的时间方向。邦诺在热传导球体坍缩的精确解中发现了该假说的反例，本文旨在澄清这一反例的有效性。

Method: 重新分析邦诺的精确解类，将其解释为接近FLRW宇宙学模型的物理可行解，将热传导矢量场重新解释为特殊速度场，从而检验韦尔曲率假说在这些条件下的有效性。

Result: 邦诺的反例在接近FLRW宇宙学模型的物理可行解中不成立，即在这些条件下，韦尔曲率假说仍然有效，引力"时间箭头"与结构形成方向一致。

Conclusion: 引力"时间箭头"（韦尔曲率假说）在物理可行的宇宙学背景下仍然成立，邦诺的反例需要重新解释。论文还讨论了引力"时间箭头"与Clifton、Ellis和Tavakol的引力熵形式之间的异同。

Abstract: We address a long-standing misperception on the gravitational ``arrow of time'', a proposal by Penrose (also known as the ``Weyl-curvature hypothesis") that associates structure formation along timelike directions in which Weyl-curvature scalars become dominant over Ricci scalars. A counterexample of this hypothesis was found by Bonnor on a class of exact solutions describing heat conducting spheres collapsing in a Vaidya background. We show that this result does not hold in the same class of solutions considered as physically viable near FLRW cosmological models, with the heat conduction vector interpreted as a peculiar velocity field. We also discuss the similarities and differences between the gravitational ``arrow of time'' and the gravitational entropy formalism of Clifton, Ellis and Tavakol.

</details>


### [57] [Gravitational radiation from hyperbolic orbits: comparison between self-force, post-Minkowskian, post-Newtonian, and numerical relativity results](https://arxiv.org/abs/2512.02274)
*Niels Warburton*

Main category: gr-qc

TL;DR: 使用频率域Regge-Wheeler-Zerilli方法计算黑洞双星系统在双曲线和抛物线轨道上的引力波辐射能量，并与后闵可夫斯基展开、后牛顿理论、自力和数值相对论结果进行比较验证。


<details>
  <summary>Details</summary>
Motivation: 研究致密天体在史瓦西黑洞双曲线和抛物线轨道上运动时产生的引力波辐射能量，填补现有理论在不同轨道类型和参数范围下的计算空白，验证不同近似方法的有效性。

Method: 采用频率域的Regge-Wheeler-Zerilli方法计算引力波辐射能量，该方法通过求解黑洞扰动方程来精确计算引力波辐射。将结果与后闵可夫斯基展开、后牛顿理论进行系统比较，并构建PN-PM混合模型。

Result: 对于大冲击参数（v∞/c=0.7）的双曲线轨道，计算结果与后闵可夫斯基展开一致；黑洞吸收辐射与后闵可夫斯基展开的领头阶一致；PN-PM混合模型表现良好；首次实现了自力与数值相对论辐射能量的比较。

Conclusion: 频率域Regge-Wheeler-Zerilli方法能有效计算黑洞双星系统在各种轨道上的引力波辐射，不同近似理论在各自适用范围内一致，PN-PM混合模型提供了一种有效的计算框架，为未来更精确的引力波建模奠定基础。

Abstract: In this work I use a frequency-domain Regge-Wheeler-Zerilli approach to compute the gravitational wave energy radiated by a compact body moving along a hyperbolic or parabolic geodesic of a Schwarzschild black hole. I compare my results with the latest post-Minkowskian (PM) calculations for the radiated energy and find agreement for hyperbolic orbits with large impact parameters and characterized by a velocity at infinity, $v_\infty$, as large as $v_\infty/c=0.7$. I also find agreement between my results and the leading-order PM expansion for the radiation absorbed by the black hole. I make further comparisons with post-Newtonian (PN) theory and show the effectiveness of a simple PN-PM hybrid model. Finally, I make a first comparison of the radiated energy between self-force and numerical relativity.

</details>


### [58] [Leading effective field theory corrections to the Kerr metric at all spins](https://arxiv.org/abs/2512.02338)
*Pedro G. S. Fernandes*

Main category: gr-qc

TL;DR: 使用谱方法计算Kerr度规的高阶导数修正，发现近极端黑洞对修正最敏感，可作为新物理探针


<details>
  <summary>Details</summary>
Motivation: 在低能有效场论框架下参数化广义相对论的主要修正，以普适且不依赖具体UV完备性的方式研究高阶导数相互作用对黑洞物理的影响

Method: 采用谱方法计算亚极端自旋范围内Kerr度规的领头阶修正，分析这些修正对物理量的影响

Result: 发现近极端黑洞受高阶导数修正影响最大，使其成为探测新物理的特别敏感探针；公开了解决方案数据集和计算代码

Conclusion: 高阶导数修正对黑洞物理有显著影响，特别是近极端黑洞可作为检验引力理论UV完备性的理想测试平台

Abstract: The leading corrections to General Relativity can be parametrized by higher-derivative interactions in a low-energy effective field theory, in a way that is general and agnostic to the precise UV completion of gravity. Using pseudospectral methods, we compute the leading-order corrections to the Kerr metric across the entire range of sub-extremal values of spin and analyse their impact on physical quantities. We find that near-extremal black holes are most affected by the higher-derivative corrections, making them especially sensitive probes of new physics. A dataset of solutions and the code used to produce them are publicly available.

</details>


### [59] [Structure and Mass-Radius Stability of Charged Compact Objects in Symmetric Teleparallel Euler-Heisenberg Gravity](https://arxiv.org/abs/2512.02439)
*Allah Ditta,M. Yousaf,G. Mustafa,S. K. Maurya,Farruh Atamurotov,Orhan Donmez,Sardor Murodov*

Main category: gr-qc

TL;DR: 在修正对称远平行引力框架下，构建了带电各向异性致密星的相对论模型，结合MIT袋模型状态方程和非线性电磁源，研究了恒星结构、稳定性和物理性质。


<details>
  <summary>Details</summary>
Motivation: 研究在修正对称远平行引力（f(Q)-Euler-Heisenberg引力）框架下，带电各向异性致密星的结构和稳定性，探索非线性电磁源对恒星性质的影响。

Method: 采用MIT袋模型状态方程建立度量势关系，求解f(Q)-Euler-Heisenberg引力场方程，获得各向异性流体与非线电磁源的精确解，使用Darmois-Israel连接条件匹配内外时空。

Result: 模型满足正则性、能量和因果性条件，压力各向异性、声速传播和TOV平衡条件相互关联，绝热指数Γ>4/3确保径向扰动下的稳定性，质量-半径曲线显示物理量在恒星内部平滑变化。

Conclusion: 成功构建了f(Q)-Euler-Heisenberg引力下的带电各向异性致密星模型，该模型物理可行、结构稳定，揭示了引力、流体静压、电磁和各向异性贡献的平衡机制。

Abstract: In this work, we develop a new relativistic model for a charged anisotropic compact star in the framework of modified symmetric teleparallel gravity, namely $f(Q)$-Euler-Heisenberg gravity. By employing the MIT bag model equation of state, we establish a relation between the metric potentials, leading to an exact solution of the field equations for an anisotropic fluid configuration coupled with a non-linear electromagnetic source. The interior spacetime is smoothly matched with the exterior geometry calculated from the theoretical setup of $f(Q)$-Euler-Heisenberg gravity using the Darmois-Israel junction conditions, ensuring the continuity of the metric functions and their derivatives at the stellar boundary. The physical viability of the model is examined through regularity, energy, and causality conditions, all of which are satisfied throughout the stellar interior. The study highlights how the pressure anisotropy, the propagation speeds of sound, and the Tolman-Oppenheimer-Volkoff balance condition are interconnected, showing that the star remains in mechanical equilibrium only when the gravitational, hydrostatic, electric, and anisotropic contributions counterbalance one another appropriately. The dynamical stability of the configuration is further supported by the requirement $Γ> \tfrac{4}{3}$ for the adiabatic index, indicating resilience against small radial perturbations. The plots of compactness, surface redshift, and the mass--radius profiles confirm that all physical quantities behave regularly and vary smoothly throughout the stellar interior. We graphically plotted the mass-radius curves.

</details>


### [60] [Non-vanishing non-linear Static Love Number of a Class of Extremal Reissner-Nordstrom Black Holes](https://arxiv.org/abs/2512.02506)
*L. R. Gounis,A. Kehagias,G. Panagopoulos,A. Riotto*

Main category: gr-qc

TL;DR: 计算极端Reissner-Nordstrom黑洞在特定轴对称配置下的潮汐Love数，发现该配置下Love数非零且有限，而孤立黑洞的Love数仍为零


<details>
  <summary>Details</summary>
Motivation: 研究极端Reissner-Nordstrom黑洞在外部引力场作用下的潮汐响应，特别关注特定轴对称几何配置下的Love数行为

Method: 精确求解非线性爱因斯坦方程，分析四维时空中的极端Reissner-Nordstrom黑洞潮汐响应，计算Zerilli-Moncrief主函数并与有效场论描述匹配

Result: 对于特定轴对称配置，静态潮汐Love数在所有外部潮汐场阶次下保持有限且非零；而孤立极端Reissner-Nordstrom黑洞的Love数仍为零

Conclusion: 极端Reissner-Nordstrom黑洞的潮汐响应特性依赖于几何配置，特定轴对称情况下会出现非零Love数，这为黑洞潮汐变形研究提供了新见解

Abstract: We compute the tidal Love numbers for a particular axially symmetric configuration of extremal Reissner-Nordstrom geometry. By exactly solving the non-linear Einstein equations, we investigate the tidal response of extremal Reissner-Nordstrom black holes in four-dimensional spacetimes under external gravitational fields. We show that, for the specific geometry considered, the static tidal Love number remains finite and non-vanishing to all orders in the external tidal field. By contrast, we verify that the Love number of an isolated extremal Reissner-Nordstrom black hole remains zero, in agreement with previous expectations. Furthermore, we explicitly calculate the Zerilli-Moncrief master functions and match them with the effective field theory description.

</details>


### [61] [Quasinormal modes of a static black hole in nonlinear electrodynamics](https://arxiv.org/abs/2512.02714)
*Mohsen Fathi,Ariel Guzmán,J. R. Villanueva*

Main category: gr-qc

TL;DR: 研究非线性电动力学（Plebański型）AdS黑洞的轴向电磁准正规模，发现非线性参数β和电荷Q增加会提高振荡频率和衰减率，打破电磁构型的等谱性，磁模式比电模式振荡更弱、衰减更慢。


<details>
  <summary>Details</summary>
Motivation: 研究非线性电动力学对黑洞扰动的影响，探索高场强或高电荷天体物理环境中非线性电磁效应的定性特征。

Method: 从轴向扰动主方程出发，采用Jansen方法：使用ingoing Eddington-Finkelstein表述，压缩径向域，正则化渐近系数，将径向方程转化为线性广义特征值问题，用Chebyshev-Lobatto伪谱离散化求解。

Result: β或Q增加会提高振荡频率ω_R和衰减率-ω_I；非线性电动力学打破了电磁构型的等谱性，磁模式比电模式振荡更弱、衰减更慢；当β足够大且Q_m较小时，基模变为纯虚数（ω_R≈0）。

Conclusion: 非线性电磁效应对黑洞扰动有显著影响，揭示了非线性电动力学在黑洞准正规模中的定性特征，对高场强或高电荷天体物理环境有潜在意义。

Abstract: We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $β$ and the effective charge magnitude $Q$. Our results show that increasing either $β$ or $Q$ raises both the oscillation frequency $ω_R$ and the damping rate $-ω_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $β$ and small $Q_m$, the fundamental mode becomes purely imaginary ($ω_R \approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.

</details>


### [62] [Universality and Falsifiability of Quantum Spacetime Decoherence: A Gauge-Invariant Framework for Gravitational-Wave Phase Diffusion](https://arxiv.org/abs/2512.02782)
*Hu Cang,Yuan Wang*

Main category: gr-qc

TL;DR: 论文提出了一种完全规范不变的理论框架，用于计算引力波在随机量子时空中传播时的累积退相干效应，发现相位扩散是微观曲率波动的主要印记，并证明了相方差随距离线性增长的普适性定理。


<details>
  <summary>Details</summary>
Motivation: 现有量子引力模型预测时空存在微观波动，但缺乏严格的理论框架来量化这些波动对引力波传播的影响。需要建立规范不变、基于第一原理的方法来区分不同量子引力模型的观测特征。

Method: 直接使用黎曼张量两点函数，利用宇宙学引力波传播的极端绝热性，沿零测地线计算投影黎曼关联函数，确定偏离普适性的精确条件。

Result: 发现相位扩散（而非振幅衰减或模式混合）是微观曲率波动的主要效应；证明了相方差随距离线性增长的普适性定理；频率指数成为区分弦泡沫反冲、全息或标度不变噪声、因果集离散性等模型的清晰谱判别器。

Conclusion: 该框架为检验奇异量子时空场景提供了尖锐且可证伪的测试方法，特别是那些具有宏观关联长度或强能量依赖性的模型。虽然标准普朗克尺度波动远低于当前探测灵敏度，但提出了使用LIGO、LISA和脉冲星计时阵列的分层贝叶斯测量策略。

Abstract: We develop a fully gauge-invariant and rigorously derived framework for computing the cumulative decoherence of gravitational waves (GWs) propagating through a stochastic quantum spacetime. Working directly with the Riemann-tensor two-point function and exploiting the extreme adiabaticity of cosmological GW propagation, we show that phase diffusion, rather than amplitude attenuation or mode mixing, is the unique leading-order imprint of microscopic curvature fluctuations. Our main theoretical result is a universality theorem: for any quantum-gravity model whose curvature fluctuations possess a finite correlation length, the accumulated phase variance grows linearly with distance, independent of the underlying microphysics. This diffusive scaling contrasts sharply with coherent astrophysical effects and with nonlocal models. The frequency exponent therefore becomes a clean spectral discriminator, separating string-foam recoil, holographic or scale-invariant noise, and causal-set discreteness. We obtain these results from first principles by evaluating the projected Riemann correlator along null geodesics and determining the exact conditions under which deviations from universality can arise. Finally, we outline a hierarchical Bayesian strategy for measuring this effect with LIGO, LISA, and Pulsar Timing Arrays. Although standard Planck-scale fluctuations remain far below current sensitivity, this framework provides a sharp and falsifiable test of exotic quantum-spacetime scenarios, particularly those with macroscopic correlation lengths or strong energy dependence.

</details>


### [63] [A New Application of the Gibbons-Werner Method: Bound Orbits of Massive Particles in Stationary Spacetimes](https://arxiv.org/abs/2512.02806)
*Yang Huang*

Main category: gr-qc

TL;DR: 将Gibbons-Werner方法扩展到稳态轴对称时空中的束缚轨道，解决了束缚轨道计算中的两个关键问题：轨道分段处理以应用GW方法，以及克服JMRF度量正定性丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有GW方法主要适用于无束缚轨道，而有限距离偏转角计算需要研究束缚轨道的弯曲。本文旨在将GW方法扩展到稳态轴对称时空中的束缚轨道，以计算束缚轨道上任意两点间的偏转角。

Method: 1. 将自重叠的束缚轨道划分为多个非重叠段，使GW方法能应用于各段；2. 解决束缚轨道粒子能量低于1时JMRF度量正定性丢失的问题；3. 在Kerr时空中具体实现计算。

Result: 获得了稳态轴对称时空中束缚轨道粒子偏转角的计算公式，并在Kerr时空中成功计算了束缚轨道上任意两点间的偏转角。

Conclusion: 成功将GW方法扩展到稳态轴对称时空中的束缚轨道，解决了束缚轨道计算的关键技术难题，为研究有限距离束缚轨道偏转角提供了有效工具。

Abstract: The Gibbons-Werner (GW) method provides a geometric framework for calculating the deflection angle of particles in curved spacetimes, and numerous extensions based on the original version have been developed in recent years to expand its applicability. Most existing studies, however, are restricted to unbound orbits. The finite-distance deflection angle, which assumes both the source and observer to be located at finite distances, motivates us to investigate the bending of bound orbits. In this work, we broaden the GW method to bound orbits of massive particles in stationary axisymmetric (SAS) spacetimes, following our previous extension in static spherically symmetric (SSS) backgrounds [Huang et al., Phys. Rev. D 107, 104046 (2023)]. By employing our generalized GW method for SAS spacetimes [Huang et al., J. Cosmol. Astropart. Phys. 01(2024)013], (a) We obtain a formula for the deflection angle of bound massive particles in SAS spacetimes by dividing bound orbits that azimuthally overlap with themselves into multiple non-overlapping segments. This division enables the application of the GW method -- originally developed for unbound orbits -- to each segment in a consistent manner. (b) We overcome the limitation associated with the loss of positive definiteness of the Jacobi-Maupertuis Randers-Finsler (JMRF) metric, which occurs because bound massive particles have energies below unity. To show the practical implementation of our approach, we carry out the calculation in Kerr spacetime and obtain the deflection angle between two arbitrary points along the bound orbit of massive particles.

</details>


### [64] [Inflationary assessment of $F(\mathcal{R},\tilde{\mathcal{R}})$ Einstein-Cartan models](https://arxiv.org/abs/2512.02847)
*Theodoros Katsoulas,Kyriakos Tamvakis*

Main category: gr-qc

TL;DR: 在F(R,˜R)爱因斯坦-嘉当引力框架下，研究包含Holst不变曲率立方项作用的模型及其暴胀行为，立方项可显著改善与观测数据的符合度


<details>
  <summary>Details</summary>
Motivation: 研究在爱因斯坦-嘉当引力理论中加入Holst不变曲率立方项对暴胀行为的影响，探索这些高阶项如何改善与观测数据的符合度

Method: 在F(R,˜R)爱因斯坦-嘉当引力框架下，构建包含Holst不变曲率立方项的作用量模型，分析其对暴胀行为的影响

Result: 立方项对与观测数据的符合度有显著影响（正或负），在二次模型与观测不符的参数区域，立方项可产生符合观测的预测

Conclusion: Holst不变曲率立方项在爱因斯坦-嘉当引力暴胀模型中具有重要作用，能够改善模型与观测数据的符合度

Abstract: In the framework of $F(\mathcal{R},\tilde{\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.

</details>


### [65] [Interacting Generalized Chaplygin-Jacobi gas: Thermodynamics approach](https://arxiv.org/abs/2512.02900)
*Gilberto Aguilar-Pérez,Miguel Cruz,Mohsen Fathi,J. R. Villanueva*

Main category: gr-qc

TL;DR: 研究包含暗能量与暗物质相互作用的宇宙学模型，其中暗能量由广义Chaplygin-Jacobi气体描述，通过线性相互作用项交换能量，分析了系统的热力学性质。


<details>
  <summary>Details</summary>
Motivation: 探索暗能量与暗物质相互作用的宇宙学模型，特别是当暗能量由广义Chaplygin-Jacobi气体描述时，研究其热力学性质如何与宇宙观测（如暗能量进入phantom区域）相协调。

Method: 建立GCJG暗能量与无压暗物质通过线性相互作用项Q∝ρ_x交换能量的系统，求解守恒方程得到暗能量和暗物质密度的解析表达式，然后进行详细的热力学分析。

Result: 推导出暗能量和暗物质密度演化的解析解；热力学分析显示两个暗成分都保持正温度，确保稳定性；暗能量在过去过渡到phantom区域，不违反热力学原理；总熵产生符合热力学第二定律；比热分析表明暗物质保持热力学稳定，而暗能量经历晚期相变，与其进入phantom区域一致。

Conclusion: 该相互作用GCJG暗能量模型在热力学上是自洽的，能够解释暗能量进入phantom区域的现象，同时满足热力学稳定性要求，为理解暗能量与暗物质相互作用提供了新的理论框架。

Abstract: This work investigates a cosmological model featuring an interaction between dark energy and dark matter, where the dark energy component is described by the Generalized Chaplygin-Jacobi gas (GCJG). In this study, we establish a system in which the GCJG and a pressureless dark matter fluid exchange energy via a linear interaction term, $Q \propto ρ_x$, being $ρ_{x}$ the dark energy density. By solving the conservation equations, we derive analytical expressions for the evolution of the dark energy and dark matter densities. The thermodynamic properties of this interacting system are then thoroughly analyzed. The thermodynamic analysis reveals that both dark components maintain positive temperatures, ensuring stability. Notably, the dark energy component transitions to a phantom regime in the past, a feature of interest for recent cosmological observations, without violating thermodynamic principles. The total entropy production is shown to be in agreement with the second law of thermodynamics. Furthermore, an analysis of the specific heats suggests that while the dark matter sector remains thermodynamically stable, the dark energy sector undergoes a late-time phase transition, consistent with its entering into the phantom domain at effective level.

</details>


### [66] [Gravitational-wave imprints of Kerr--Bertotti--Robinson black holes: frequency blue-shift and waveform dephasing](https://arxiv.org/abs/2512.02921)
*Xiang-Qian Li,Hao-Peng Yan,Xiao-Jun Yue*

Main category: gr-qc

TL;DR: 研究Kerr黑洞在均匀磁场中的极端质量比旋进轨道动力学和引力波特征，发现磁场会使ISCO半径增大但频率增加，导致引力波截止频率蓝移，对LISA等探测器有可观测影响。


<details>
  <summary>Details</summary>
Motivation: 研究磁场环境对极端质量比旋进系统的影响，因为现有波形模型通常忽略磁场效应，而实际宇宙中黑洞常处于磁场环境中，这可能对引力波探测和参数估计产生重要偏差。

Method: 使用精确的Kerr-Bertotti-Robinson解描述磁场中的Kerr黑洞，分析ISCO轨道特性，采用半解析绝热演化方案结合精确测地线关系和领头阶四极矩通量生成旋进波形。

Result: 磁场使ISCO半径增大但轨道频率增加（蓝移效应）；逆行轨道对磁场更敏感；磁场修正可反转ISCO处的自旋-频率层次；磁场引起显著波形相移，对黑洞自旋参数估计可能产生不可忽略偏差。

Conclusion: 大规模磁场环境会在EMRI信号中留下可观测印记，未来空间引力波探测器（LISA、天琴、太极）应考虑磁场效应，否则可能在参数估计特别是黑洞自旋测量中引入偏差。

Abstract: We investigate the orbital dynamics and gravitational-wave signatures of extreme mass-ratio inspirals (EMRIs) in the spacetime of a Kerr black hole immersed in an asymptotically uniform magnetic field, described by the exact Kerr--Bertotti--Robinson (Kerr--BR) solution~\cite{Podolsky:2025tle}. In contrast to the widely used Kerr--Melvin metric, the Kerr--BR spacetime is of algebraic type~D, admits a clear asymptotic structure, and allows for a systematic analytic treatment of geodesics. By analyzing the innermost stable circular orbit (ISCO), we find that the external magnetic field consistently pushes the ISCO to larger radii \(r_{\rm ISCO}\) for all spin configurations considered. Counterintuitively, despite this outward radial shift, the ISCO orbital frequency \(Ω_{\rm ISCO}\) increases monotonically with the magnetic-field strength, leading to a robust ``blue-shift'' of the gravitational-wave cutoff frequency. We further show that retrograde orbits are significantly more sensitive to magnetic fields than prograde orbits, and identify a frequency crossover phenomenon in which magnetic corrections can invert the usual spin--frequency hierarchy at the ISCO. Finally, employing a semi-analytic adiabatic evolution scheme driven by exact geodesic relations and a leading-order quadrupole flux, we generate inspiral waveforms and quantify the substantial dephasing induced by the magnetic field. Our results indicate that large-scale magnetic environments can leave observable imprints in EMRI signals for future space-based detectors such as LISA, TianQin, and Taiji, and that neglecting such effects in waveform models may introduce non-negligible biases in parameter estimation, particularly for the black-hole spin.

</details>


### [67] [Can Eccentric Binary Black Hole Signals Mimic Gravitational-Wave Microlensing?](https://arxiv.org/abs/2512.02943)
*Anuj Mishra,Apratim Ganguly*

Main category: gr-qc

TL;DR: 研究探讨了引力波信号中轨道偏心率与微引力透镜效应之间的混淆风险，发现高偏心率、低总质量的系统可能被误判为微引力透镜事件，但使用包含偏心率的波形模型可以完全消除这种混淆。


<details>
  <summary>Details</summary>
Motivation: 引力波信号中的波光学微引力透镜效应会产生特征性的频率依赖调制，但类似的调制也可能来自轨道偏心率。这种潜在的混淆可能导致错误的微引力透镜声称，需要系统评估这种风险。

Method: 使用数值相对论模拟和TEOBResumS-Dalí波形模型生成偏心双黑洞信号模拟种群，进行贝叶斯模型比较研究，并辅以失配分析。比较了准圆形微透镜模型、准圆形非透镜模型和偏心波形模型。

Result: 发现高偏心率、低总质量和高信噪比条件下存在强烈混淆：准圆形微透镜模型可能被强烈偏好于准圆形非透镜模型，即使真实信号是非透镜的。对于中等信噪比(~30)，总质量≲100M⊙且偏心率≳0.4的双星特别容易误分类。但使用包含偏心率的波形模型可以完全消除混淆。

Conclusion: 任何显示强烈微引力透镜贝叶斯证据的事件都应同时使用偏心波形模型进行分析，反之亦然，以避免误判和偏倚的天体物理推断。这有助于在精确引力波天文学时代制定稳健的信号解释策略。

Abstract: Gravitational lensing in the wave-optics regime imprints characteristic frequency-dependent amplitude and phase modulations on gravitational-wave (GW) signals, yet to be detected by ground-based interferometers. Similar modulations may also arise from orbital eccentricity, raising the possibility of degeneracies that could lead to false microlensing claims. We investigate the extent to which eccentric binary black hole (BBH) signals can mimic microlensing signatures produced by an isolated point-mass lens. With a simulated population of eccentric signals using numerical relativity simulations and \texttt{TEOBResumS-Dalí} waveform model, we perform a Bayesian model-comparison study, supported by a complementary \textit{mismatch} analysis. We find a strong degeneracy for high eccentricities, low total masses, and high signal-to-noise ratios (SNRs): under these conditions, quasicircular microlensed model can be strongly favored over quasicircular unlensed model, even when the true signal is unlensed. For moderate SNRs ($\sim 30$), binaries with $M_\mathrm{tot}\lesssim 100\,M_\odot$ and eccentricity $e \gtrsim 0.4$ are particularly susceptible to misclassifications. In such cases, inferred microlens parameters exhibit well-constrained posteriors despite being unphysical. Crucially, the degeneracy is completely removed when the recovery uses waveform models that incorporate eccentricity, which overwhelmingly favors the eccentric hypothesis over microlensing. Our results demonstrate that any event exhibiting strong Bayesian evidence for microlensing should also be analyzed with eccentric waveform models and vice-versa to avoid false positives and biased astrophysical inference. This work contributes to developing robust strategies for interpreting signals in the era of precision GW astronomy.

</details>


### [68] [Flexible Gravitational-Wave Parameter Estimation with Transformers](https://arxiv.org/abs/2512.02968)
*Annalena Kofler,Maximilian Dax,Stephen R. Green,Jonas Wildberger,Nihar Gupte,Jakob H. Macke,Jonathan Gair,Alessandra Buonanno,Bernhard Schölkopf*

Main category: gr-qc

TL;DR: Dingo-T1：基于Transformer的灵活引力波参数估计模型，可适应不同分析设置，在多种配置下分析48个引力波事件，提升采样效率至4.2%。


<details>
  <summary>Details</summary>
Motivation: 引力波数据分析面临观测频率增加和复杂性提升的挑战，传统深度学习方法缺乏灵活性以适应不同分析设置（如探测器配置、频率范围变化等），需要能处理不完整或缺失数据的灵活框架。

Method: 提出基于Transformer的灵活架构及训练策略，使模型能在推理时适应多样化的分析设置。该模型能处理不同探测器配置、频率范围变化和局部数据截断等情况。

Result: Dingo-T1模型成功分析了第三次LIGO-Virgo-KAGRA观测运行的48个引力波事件，支持系统研究探测器配置对后验分布的影响，执行广义相对论检验，并将真实事件的采样效率中位数从1.4%提升至4.2%。

Conclusion: 该方法展示了灵活、可扩展的推理能力，为处理缺失或不完整数据提供了原则性框架，对当前和下一代天文台具有重要意义。

Abstract: Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.

</details>


### [69] [Constraining Zero-Point Length from Gravitational Baryogenesis](https://arxiv.org/abs/2512.03009)
*Ava Shahbazi Sooraki,Ahmad Sheykhi*

Main category: gr-qc

TL;DR: 零长度修正引力对重子生成和早期宇宙热力学的影响，从观测数据约束零长度尺度


<details>
  <summary>Details</summary>
Motivation: 研究弦理论或量子引力理论预测的基本零长度尺度对宇宙学的影响，特别是对重子生成和早期宇宙热力学的修正

Method: 通过零长度修正的弗里德曼方程，分析非平衡热力学条件下重子不对称性的生成，从观测数据推导零长度尺度的约束

Result: 零长度产生辐射时期的里奇标量变化，导致重子不对称参数与零长度平方成正比；观测数据约束零长度小于约7.1×10⁻³³米，约为普朗克长度的440倍；零长度修正减缓高能下的膨胀速率，使早期宇宙保持更高温度更长时间

Conclusion: 零长度宇宙学为连接量子引力和宇宙学观测提供了可测试框架，对早期宇宙热历史和基本长度尺度具有重要意义

Abstract: The existence of a fundamental zero-point length, $l_0$, a minimal spacetime scale predicted by T-duality in string theory or quantum gravity theories, modifies the entropy associated with the horizon of spacetime. In the cosmological setup, this leads to correction to the Friedmann equations governing the evolution of the Universe. In this paper, we investigate the implications of zero-point length $l_0$-corrected gravity for gravitational baryogenesis and early universe thermodynamics, deriving constraints on $l_0$ from observational baryon asymmetry data. We observe that under the condition of non-equilibrium thermodynamics, $l_0$ generates $\dot{\mathcal{R}}\neq 0$ during radiation epoch, where $\mathcal{R}$ is the Ricci scalar. This yields a baryon asymmetry parameter $η\propto l_0^2 T_D^9/M_{\rm Pl}^7$. The observed baryon asymmetry $η\sim 9.9 \times 10^{-11}$ constrains $l_0 \lesssim 7.1 \times 10^{-33} m$, approximately $440$ times the Planck length. Furthermore, our analysis reveals that the zero-point length correction in the Friedmann equation, effectively slows the expansion rate at high energies, resulting in a modified time-temperature relationship where the Universe maintains higher temperatures for longer time during early epochs compared to standard cosmology. Our results establish zero-point length cosmology as a testable framework connecting quantum gravity to cosmological observables, with implications for early universe thermal history and fundamental length scales.

</details>


### [70] [Topological Shell Structures in Neutron Stars: Effects on Equilibrium, Oscillations, and Gravitational-Wave Signatures](https://arxiv.org/abs/2512.03016)
*Debojoti Kuzur,Kamal Krishna Nath*

Main category: gr-qc

TL;DR: 研究在脉冲星内部引入拓扑壳层对结构和动力学的影响，分析其对引力波观测量的影响


<details>
  <summary>Details</summary>
Motivation: 探索脉冲星内部拓扑壳层（质量为零的分布密度剖面）对星体结构和动力学的影响，以及这种内部结构如何通过引力波观测被探测到

Method: 1. 在脉冲星结构中引入拓扑壳层密度剖面；2. 构建多种现实状态方程的平衡序列；3. 使用Sturm-Liouville公式分析径向稳定性；4. 应用跳跃条件研究f模谱特征；5. 基于第一性原理标度关系估算引力波可观测量

Result: 发现拓扑壳层导致f模频率相对于无壳模型出现强烈非单调变化，引力波阻尼时间、品质因子、光度和特征应变等可观测量与先进LIGO及第三代探测器灵敏度可比

Conclusion: 脉冲星内部拓扑壳层可在振荡和引力波特性中留下可观测特征，为通过引力波探测脉冲星内部结构提供了新途径

Abstract: We study the structural and dynamical consequences of introducing a distributional density profile inside a neutron star, representing a massless, topological shell located at an arbitrary radius. We incorporate this effect into the structure of neutron star and construct equilibrium sequence for several realistic equations of state. Radial stability is examined through the Sturm-Liouville formulation of the $\ell=0$ perturbation equation, supplemented with a jump condition and imprinting distinct features on the fundamental $f$-mode spectrum. We find strong, non-monotonic variations in the mode frequency relative to standard no-shell models. Using first-principles scaling relations, we estimate various gravitational wave observables such as the damping time, quality factor, luminosity and characteristic strain. These observables are then compared with the sensitivity of Advanced LIGO, and third-generation detectors such as the Einstein Telescope and Cosmic Explorer. Our results demonstrate that internal topological shells can leave potentially observable signatures in the oscillation and gravitational wave properties of neutron stars.

</details>


### [71] [Neutron stars in $f(\mathbb{Q})$ gravity](https://arxiv.org/abs/2512.03037)
*Lavinia Heisenberg,Carlos Pastor-Marcos*

Main category: gr-qc

TL;DR: 在f(ℚ)引力理论中构建中子星解面临挑战，需将仿射联络视为动态分量。标准简化可能导致GR行为，即使是非平凡的f(ℚ)模型。数值求解时需处理边界值问题和数值病态。


<details>
  <summary>Details</summary>
Motivation: 研究f(ℚ)引力理论中中子星解的构建挑战，强调仿射联络作为动态分量的重要性，避免标准简化导致意外恢复广义相对论行为。

Method: 从黑洞时空形式推广到中子星非真空配置，分析两个代表性模型：f(ℚ)=ℚ+αℚ²和f(ℚ)=ℚ^β。在标准正则性假设下，通过Maclaurin/Laurent级数展开研究解的性质，将问题表述为边界值问题并分析数值病态。

Result: 在标准正则性假设下，Maclaurin/Laurent型级数解恢复广义相对论动力学，表明超越GR的效应可能来自更复杂的结构。仿射联络的动力学对渐近行为施加约束。

Conclusion: 为未来数值研究提供具体框架，概述构建物理上有意义的超越GR中子星解所需的理论一致性条件，强调仿射联络动力学在f(ℚ)引力中的关键作用。

Abstract: We investigate the challenges of constructing neutron star (NS) solutions in $f(\mathbb{Q})$ gravity, highlighting the importance of treating the affine connection as an active, dynamical component of the theory. We begin by clarifying under what conditions standard simplifications -- such as the coincident gauge or General Relativity (GR)-like connections -- inadvertently lead to GR behavior, even in non-trivial $f(\mathbb{Q})$ models. Building on previous work in black hole (BH) spacetimes, we adapt the formalism to NS and extend it to non-vacuum configurations. Focusing on two representative models, $f(\mathbb{Q}) = \mathbb{Q} + α\mathbb{Q}^2$ and $f(\mathbb{Q}) = \mathbb{Q}^β$, our analysis suggests that, under standard regularity assumptions, solutions with Maclaurin/Laurent-type series recover GR dynamics, pointing to more intricate structures as the likely seat of beyond-GR effects, and reflecting the constraints imposed by the connection's dynamics on the asymptotic behavior of genuinely beyond-GR solutions. We then formulate the problem as a boundary value problem (BVP) and highlight the numerical pathologies that may arise, together with possible strategies to prevent them. This work aims to provide a concrete framework for future numerical studies and outlines the theoretical consistency conditions required to construct physically meaningful beyond-GR NS solutions in $f(\mathbb{Q})$ gravity.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [An Improved Ensemble-Based Machine Learning Model with Feature Optimization for Early Diabetes Prediction](https://arxiv.org/abs/2512.02023)
*Md. Najmul Islam,Md. Miner Hossain Rimon,Shah Sadek-E-Akbor Shamim,Zarif Mohaimen Fahad,Md. Jehadul Islam Mony,Md. Jalal Uddin Chowdhury*

Main category: cs.LG

TL;DR: 该研究开发了一个基于机器学习的糖尿病早期预测框架，使用BRFSS数据集，通过SMOTE和Tomek Links处理数据不平衡，采用多种监督学习算法和集成方法，最终构建了React Native移动应用用于糖尿病风险预测。


<details>
  <summary>Details</summary>
Motivation: 糖尿病是全球严重的健康问题，早期检测对成功干预至关重要。但由于风险因素重叠和数据不对称，预测变得困难。研究旨在利用大规模健康调查数据构建准确且可解释的机器学习框架，辅助临床决策。

Method: 使用2015年BRFSS数据集（约253,680条记录，22个数值特征），采用SMOTE和Tomek Links处理类别不平衡问题。评估了多种监督学习算法（随机森林、XGBoost、CatBoost、LightGBM）以及集成方法（如堆叠集成）。最终开发了React Native移动应用，后端使用Python Flask。

Result: 单个模型（随机森林、XGBoost、CatBoost、LightGBM）的ROC-AUC达到约0.96。堆叠集成（XGBoost+KNN）表现最佳：准确率94.82%，ROC-AUC 0.989，PR-AUC 0.991，实现了召回率和精确度的良好平衡。开发了React Native应用提供可访问的健康监测工具。

Conclusion: 该研究成功构建了高精度的糖尿病预测机器学习框架，通过集成方法显著提升了性能。开发的移动应用为早期糖尿病检测提供了实用工具，有助于改善临床决策和健康监测。

Abstract: Diabetes is a serious worldwide health issue, and successful intervention depends on early detection. However, overlapping risk factors and data asymmetry make prediction difficult. To use extensive health survey data to create a machine learning framework for diabetes classification that is both accurate and comprehensible, to produce results that will aid in clinical decision-making. Using the BRFSS dataset, we assessed a number of supervised learning techniques. SMOTE and Tomek Links were used to correct class imbalance. To improve prediction performance, both individual models and ensemble techniques such as stacking were investigated. The 2015 BRFSS dataset, which includes roughly 253,680 records with 22 numerical features, is used in this study. Strong ROC-AUC performance of approximately 0.96 was attained by the individual models Random Forest, XGBoost, CatBoost, and LightGBM.The stacking ensemble with XGBoost and KNN yielded the best overall results with 94.82\% accuracy, ROC-AUC of 0.989, and PR-AUC of 0.991, indicating a favourable balance between recall and precision. In our study, we proposed and developed a React Native-based application with a Python Flask backend to support early diabetes prediction, providing users with an accessible and efficient health monitoring tool.

</details>


### [73] [Pharmacophore-based design by learning on voxel grids](https://arxiv.org/abs/2512.02031)
*Omar Mahmood,Pedro O. Pinheiro,Richard Bonneau,Saeed Saremi,Vishnu Sresht*

Main category: cs.LG

TL;DR: 提出VoxCap方法，一种基于药效团形状的体素生成模型，解决传统基于药效团的虚拟筛选在计算规模和生成能力上的限制


<details>
  <summary>Details</summary>
Motivation: 传统基于药效团的虚拟筛选方法虽然成功，但存在两个主要问题：1) 随着分子库规模增大，计算成本急剧增加；2) 只能从现有化合物库中筛选，无法生成新分子

Method: 提出VoxCap方法，一种基于体素标注的技术，能从体素化的分子表示生成SMILES字符串。设计了两种工作流程：1) 从头设计：生成与查询分子具有高药效团形状相似性的新分子；2) 快速搜索：结合生成设计和廉价的2D子结构相似性搜索

Result: VoxCap在生成多样化从头设计命中分子方面显著优于先前方法。快速搜索工作流程将计算时间减少数个数量级，同时能为所有查询分子返回命中结果，使得搜索大规模分子库成为可能

Conclusion: VoxCap方法解决了传统药效团虚拟筛选的扩展性和生成能力限制，为药物发现提供了更高效、更具创造性的解决方案

Abstract: Ligand-based drug discovery (LBDD) relies on making use of known binders to a protein target to find structurally diverse molecules similarly likely to bind. This process typically involves a brute force search of the known binder (query) against a molecular library using some metric of molecular similarity. One popular approach overlays the pharmacophore-shape profile of the known binder to 3D conformations enumerated for each of the library molecules, computes overlaps, and picks a set of diverse library molecules with high overlaps. While this virtual screening workflow has had considerable success in hit diversification, scaffold hopping, and patent busting, it scales poorly with library sizes and restricts candidate generation to existing library compounds. Leveraging recent advances in voxel-based generative modelling, we propose a pharmacophore-based generative model and workflows that address the scaling and fecundity issues of conventional pharmacophore-based virtual screening. We introduce \emph{VoxCap}, a voxel captioning method for generating SMILES strings from voxelised molecular representations. We propose two workflows as practical use cases as well as benchmarks for pharmacophore-based generation: \emph{de-novo} design, in which we aim to generate new molecules with high pharmacophore-shape similarities to query molecules, and fast search, which aims to combine generative design with a cheap 2D substructure similarity search for efficient hit identification. Our results show that VoxCap significantly outperforms previous methods in generating diverse \textit{de-novo} hits. When combined with our fast search workflow, VoxCap reduces computational time by orders of magnitude while returning hits for all query molecules, enabling the search of large libraries that are intractable to search by brute force.

</details>


### [74] [PIBNet: a Physics-Inspired Boundary Network for Multiple Scattering Simulations](https://arxiv.org/abs/2512.02049)
*Rémi Marsal,Stéphanie Chaillat*

Main category: cs.LG

TL;DR: PIBNet：基于物理启发的图神经网络，用于高效近似边界元法中的解迹，解决多散射问题


<details>
  <summary>Details</summary>
Motivation: 边界元法（BEM）在求解无界均匀域中的多散射问题时，需要先求解边界积分方程获得解迹，这是主要计算瓶颈。作者希望开发学习方法来近似解迹，提高计算效率。

Method: 提出PIBNet：1）采用物理启发的基于图的方法来建模障碍物及其长程相互作用；2）引入新颖的多尺度图神经网络架构来模拟多散射现象；3）创建包含多种多散射问题类型的数据集进行训练和评估。

Result: PIBNet在考虑的任务中超越了现有最先进的学习方法，并且在障碍物数量增加的情况下表现出更好的泛化能力。

Conclusion: PIBNet为边界元法中的解迹近似提供了有效的学习解决方案，能够高效处理多散射问题，并具有良好的泛化性能。

Abstract: The boundary element method (BEM) provides an efficient numerical framework for solving multiple scattering problems in unbounded homogeneous domains, since it reduces the discretization to the domain boundaries, thereby condensing the computational complexity. The procedure first consists in determining the solution trace on the boundaries of the domain by solving a boundary integral equation, after which the volumetric solution can be recovered at low computational cost with a boundary integral representation. As the first step of the BEM represents the main computational bottleneck, we introduce PIBNet, a learning-based approach designed to approximate the solution trace. The method leverages a physics-inspired graph-based strategy to model obstacles and their long-range interactions efficiently. Then, we introduce a novel multiscale graph neural network architecture for simulating the multiple scattering. To train and evaluate our network, we present a benchmark consisting of several datasets of different types of multiple scattering problems. The results indicate that our approach not only surpasses existing state-of-the-art learning-based methods on the considered tasks but also exhibits superior generalization to settings with an increased number of obstacles. github.com/ENSTA-U2IS-AI/pibnet

</details>


### [75] [Contextual Gating within the Transformer Stack: Synergistic Feature Modulation for Enhanced Lyrical Classification and Calibration](https://arxiv.org/abs/2512.02053)
*M. A. Gameiro*

Main category: cs.LG

TL;DR: 提出SFL Transformer，通过上下文门控机制在BERT编码器中间层融合结构特征，显著提升了歌词内容分类性能，在准确率、F1分数和校准误差方面都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有特征融合方法通常在最终输出层融合辅助结构特征，这可能不是最有效的方式。本研究假设在Transformer中间层注入辅助上下文信息能更有效地结合结构和语义信息。

Method: 提出SFL Transformer模型，采用上下文门控机制（Intermediate SFL）在BERT编码器堆栈中间层调制隐藏状态序列，将低维结构特征融入深度语义特征中。

Result: 在基于UMAP降维歌词嵌入的二元分类任务中，SFL Transformer达到0.9910的准确率和宏F1分数，优于之前SFL模型的0.9894。同时保持极低的预期校准误差（0.0081）和对数损失（0.0489）。

Conclusion: 验证了在Transformer中间层注入辅助上下文是结合结构和语义信息的最有效方式，创造了兼具优异判别能力和高保真概率估计的模型。

Abstract: This study introduces a significant architectural advancement in feature fusion for lyrical content classification by integrating auxiliary structural features directly into the self-attention mechanism of a pre-trained Transformer. I propose the SFL Transformer, a novel deep learning model that utilizes a Contextual Gating mechanism (an Intermediate SFL) to modulate the sequence of hidden states within the BERT encoder stack, rather than fusing features at the final output layer. This approach modulates the deep, contextualized semantic features (Hseq) using low-dimensional structural cues (Fstruct). The model is applied to a challenging binary classification task derived from UMAP-reduced lyrical embeddings. The SFL Transformer achieved an Accuracy of 0.9910 and a Macro F1 score of 0.9910, significantly improving the state-of-the-art established by the previously published SFL model (Accuracy 0.9894). Crucially, this Contextual Gating strategy maintained exceptional reliability, with a low Expected Calibration Error (ECE = 0.0081) and Log Loss (0.0489). This work validates the hypothesis that injecting auxiliary context mid-stack is the most effective means of synergistically combining structural and semantic information, creating a model with both superior discriminative power and high-fidelity probability estimates.

</details>


### [76] [Opening the Black Box: An Explainable, Few-shot AI4E Framework Informed by Physics and Expert Knowledge for Materials Engineering](https://arxiv.org/abs/2512.02057)
*Haoxiang Zhang,Ruihao Yuan,Lihui Zhang,Yushi Luo,Qiang Zhang,Pan Ding,Xiaodong Ren,Weijie Xing,Niu Gao,Jishan Chen,Chubo Zhang*

Main category: cs.LG

TL;DR: 提出一个可解释的少样本AI工程框架，通过物理约束的数据增强和符号回归，从仅32个实验样本中推导出预测热裂倾向的物理本构方程，准确率达88%。


<details>
  <summary>Details</summary>
Motivation: 工业AI应用面临两大瓶颈：高质量数据稀缺和黑盒模型缺乏可解释性，这在航空航天等安全敏感领域尤为关键。需要开发能够嵌入工程领域知识的可信AI系统。

Method: 采用三阶段物理约束数据增强协议：校准过程变异性的差异化噪声注入、硬物理约束强制执行、参数间关系保持。然后使用嵌套优化策略进行本构模型发现：符号回归探索方程结构，差分进化优化参数，最后通过混合全局-局部优化进行参数精炼。

Result: 从仅32个实验样本出发，推导出的可解释本构方程在预测K439B高温合金铸造修复焊接热裂倾向方面达到88%的准确率。该方程不仅提供定量预测，还揭示了热学、几何和冶金机制如何耦合驱动裂纹形成。

Conclusion: 该方法为开发可信AI系统提供了通用蓝图，将工程领域知识直接嵌入架构中，使AI能够在数据有限但物理理解可用的高风险工业应用中可靠采用。本构方程还可作为多功能工具用于工艺优化和高保真虚拟数据生成。

Abstract: The industrial adoption of Artificial Intelligence for Engineering (AI4E) faces two fundamental bottlenecks: scarce high-quality data and the lack of interpretability in black-box models-particularly critical in safety-sensitive sectors like aerospace. We present an explainable, few-shot AI4E framework that is systematically informed by physics and expert knowledge throughout its architecture. Starting from only 32 experimental samples in an aerial K439B superalloy castings repair welding case, we first augment physically plausible synthetic data through a three-stage protocol: differentiated noise injection calibrated to process variabilities, enforcement of hard physical constraints, and preservation of inter-parameter relationships. We then employ a nested optimization strategy for constitutive model discovery, where symbolic regression explores equation structures while differential evolution optimizes parameters, followed by intensive parameter refinement using hybrid global-local optimization. The resulting interpretable constitutive equation achieves 88% accuracy in predicting hot-cracking tendency. This equation not only provides quantitative predictions but also delivers explicit physical insight, revealing how thermal, geometric, and metallurgical mechanisms couple to drive cracking-thereby advancing engineers' cognitive understanding of the process. Furthermore, the constitutive equation serves as a multi-functional tool for process optimization and high-fidelity virtual data generation, enabling accuracy improvements in other data-driven models. Our approach provides a general blueprint for developing trustworthy AI systems that embed engineering domain knowledge directly into their architecture, enabling reliable adoption in high-stakes industrial applications where data is limited but physical understanding is available.

</details>


### [77] [Ada-MoGE: Adaptive Mixture of Gaussian Expert Model for Time Series Forecasting](https://arxiv.org/abs/2512.02061)
*Zhenliang Ni,Xiaowen Ma,Zhenkai Wu,Shuai Xiao,Han Shu,Xinghao Chen*

Main category: cs.LG

TL;DR: 提出Ada-MoGE模型，通过自适应高斯专家混合解决传统MoE模型在多元时间序列预测中频率覆盖不平衡问题，在六个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列预测中，数据频谱分布会随时间演化，主导频率会发生偏移。传统固定专家数量的MoE模型难以适应这种变化，导致频率覆盖不平衡问题：专家太少会忽略关键信息，太多会引入噪声。

Method: 提出Ada-MoGE模型，集成频谱强度和频率响应来自适应确定专家数量，确保与输入数据的频率分布对齐。使用高斯带通滤波平滑分解频域特征，避免直接频带截断引入噪声。

Result: 在六个公共基准测试中实现了最先进的性能，仅使用0.2百万参数。

Conclusion: Ada-MoGE通过自适应确定专家数量解决了频率覆盖不平衡问题，在多元时间序列预测中表现出色，同时参数效率高。

Abstract: Multivariate time series forecasts are widely used, such as industrial, transportation and financial forecasts. However, the dominant frequencies in time series may shift with the evolving spectral distribution of the data. Traditional Mixture of Experts (MoE) models, which employ a fixed number of experts, struggle to adapt to these changes, resulting in frequency coverage imbalance issue. Specifically, too few experts can lead to the overlooking of critical information, while too many can introduce noise. To this end, we propose Ada-MoGE, an adaptive Gaussian Mixture of Experts model. Ada-MoGE integrates spectral intensity and frequency response to adaptively determine the number of experts, ensuring alignment with the input data's frequency distribution. This approach prevents both information loss due to an insufficient number of experts and noise contamination from an excess of experts. Additionally, to prevent noise introduction from direct band truncation, we employ Gaussian band-pass filtering to smoothly decompose the frequency domain features, further optimizing the feature representation. The experimental results show that our model achieves state-of-the-art performance on six public benchmarks with only 0.2 million parameters.

</details>


### [78] [DPWMixer: Dual-Path Wavelet Mixer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2512.02070)
*Li Qianyang,Zhang Xingjun,Wang Shaoxun,Wei Jia*

Main category: cs.LG

TL;DR: DPWMixer：一种基于无损Haar小波金字塔和双路径混合器的长期时间序列预测方法，通过正交分解分离趋势和局部波动，结合全局线性映射和局部MLP-Mixer处理，实现高效准确的预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1）Transformer模型计算复杂度高且容易过拟合；2）线性模型难以捕捉复杂的非线性局部动态；3）多尺度框架使用的平均池化会导致频谱混叠和高频信息丢失。

Method: 提出DPWMixer框架：1）使用无损Haar小波金字塔替代传统池化，通过正交分解无信息损失地分离趋势和局部波动；2）设计双路径趋势混合器，结合全局线性映射和基于patch的MLP-Mixer；3）自适应多尺度融合模块根据通道平稳性加权整合不同尺度的预测。

Result: 在8个公开基准数据集上的实验表明，DPWMixer在长期时间序列预测任务上持续优于现有最优基线方法。

Conclusion: DPWMixer通过无损小波分解和双路径架构，有效解决了现有方法在计算效率、非线性动态建模和频谱信息保留方面的局限性，为长期时间序列预测提供了高效准确的解决方案。

Abstract: Long-term time series forecasting (LTSF) is a critical task in computational intelligence. While Transformer-based models effectively capture long-range dependencies, they often suffer from quadratic complexity and overfitting due to data sparsity. Conversely, efficient linear models struggle to depict complex non-linear local dynamics. Furthermore, existing multi-scale frameworks typically rely on average pooling, which acts as a non-ideal low-pass filter, leading to spectral aliasing and the irreversible loss of high-frequency transients. In response, this paper proposes DPWMixer, a computationally efficient Dual-Path architecture. The framework is built upon a Lossless Haar Wavelet Pyramid that replaces traditional pooling, utilizing orthogonal decomposition to explicitly disentangle trends and local fluctuations without information loss. To process these components, we design a Dual-Path Trend Mixer that integrates a global linear mapping for macro-trend anchoring and a flexible patch-based MLP-Mixer for micro-dynamic evolution. Finally, An adaptive multi-scale fusion module then integrates predictions from diverse scales, weighted by channel stationarity to optimize synthesis. Extensive experiments on eight public benchmarks demonstrate that our method achieves a consistent improvement over state-of-the-art baselines. The code is available at https://github.com/hit636/DPWMixer.

</details>


### [79] [HTG-GCL: Leveraging Hierarchical Topological Granularity from Cellular Complexes for Graph Contrastive Learning](https://arxiv.org/abs/2512.02073)
*Qirui Ji,Bin Qin,Yifan Jin,Yunze Zhao,Chuxiong Sun,Changwen Zheng,Jianwen Cao,Jiangmeng Li*

Main category: cs.LG

TL;DR: HTG-GCL是一个新颖的图对比学习框架，通过生成多尺度环形细胞复合体来捕捉层次化拓扑粒度，并使用多粒度解耦对比与不确定性加权机制来学习更有意义的图表示。


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习方法在结构增强时难以识别任务相关的拓扑结构，且无法适应不同下游任务所需的从粗到细的拓扑粒度变化。为了解决这个问题，需要一种能够捕捉层次化拓扑信息的方法。

Method: 提出HTG-GCL框架：1）通过图变换生成多尺度环形细胞复合体，体现拓扑粒度概念；2）提出多粒度解耦对比方法；3）基于不确定性估计的粒度特定加权机制。

Result: 在多个基准测试上的综合实验证明了HTG-GCL的有效性，显示出其在通过层次化拓扑信息捕捉有意义的图表示方面的优越性能。

Conclusion: HTG-GCL通过引入层次化拓扑粒度和不确定性加权机制，能够更好地捕捉图数据的语义不变性，为图对比学习提供了新的有效框架。

Abstract: Graph contrastive learning (GCL) aims to learn discriminative semantic invariance by contrasting different views of the same graph that share critical topological patterns. However, existing GCL approaches with structural augmentations often struggle to identify task-relevant topological structures, let alone adapt to the varying coarse-to-fine topological granularities required across different downstream tasks. To remedy this issue, we introduce Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL), a novel framework that leverages transformations of the same graph to generate multi-scale ring-based cellular complexes, embodying the concept of topological granularity, thereby generating diverse topological views. Recognizing that a certain granularity may contain misleading semantics, we propose a multi-granularity decoupled contrast and apply a granularity-specific weighting mechanism based on uncertainty estimation. Comprehensive experiments on various benchmarks demonstrate the effectiveness of HTG-GCL, highlighting its superior performance in capturing meaningful graph representations through hierarchical topological information.

</details>


### [80] [FDRMFL:Multi-modal Federated Feature Extraction Model Based on Information Maximization and Contrastive Learning](https://arxiv.org/abs/2512.02076)
*Haozhe Wu*

Main category: cs.LG

TL;DR: 提出一种任务驱动的监督式多模态联邦特征提取方法，解决多模态数据回归中的特征提取问题，应对有限非IID数据、多模态信息融合和灾难性遗忘三大挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现实场景中多模态数据回归的三个核心挑战：1) 有限且非独立同分布的数据；2) 多模态信息的有效提取与融合；3) 模型学习中的灾难性遗忘问题。

Method: 集成多模态信息提取和对比学习机制，采用任务驱动的监督式多模态联邦特征提取方法。方法包含：1) 多约束学习框架（均方误差损失保证回归精度）；2) 互信息保持约束；3) 对称KL散度约束；4) 模型间对比约束。支持客户端独立学习多模态数据的低维表示，通过参数调优灵活控制预测变量中响应变量有效信息的保留程度。

Result: 实验结果表明，相比经典特征提取技术，该方法在下游回归任务上取得了更显著的性能提升。模拟和真实数据分析均验证了方法的有效性。

Conclusion: 该方法成功解决了多模态数据回归中的特征提取挑战，通过多约束学习框架确保特征提取过程始终以提高下游回归任务性能为中心，实现了任务相关信息的保留、多模态特征的提取融合对齐，以及非IID场景下表示漂移和灾难性遗忘的缓解。

Abstract: This study focuses on the feature extraction problem in multi-modal data regression. To address three core challenges in real-world scenarios: limited and non-IID data, effective extraction and fusion of multi-modal information, and susceptibility to catastrophic forgetting in model learning, a task-driven supervised multi-modal federated feature extraction method is proposed. The method integrates multi-modal information extraction and contrastive learning mechanisms, and can adapt to different neural network structures as the latent mapping functions for data of each modality. It supports each client to independently learn low-dimensional representations of multi-modal data, and can flexibly control the degree of retention of effective information about the response variable in the predictive variables within the low-dimensional features through parameter tuning. The multi-constraint learning framework constructed by the method guarantees regression accuracy using Mean Squared Error loss. Through the synergistic effect of mutual information preservation constraint, symmetric Kullback-Leibler divergence constraint, and inter-model contrastive constraint, it achieves the retention of task-related information, the extraction, fusion, and alignment of multi-modal features, and the mitigation of representation drift and catastrophic forgetting in non-IID scenarios, respectively. This ensures that the feature extraction process always centers on improving the performance of downstream regression tasks. Experimental results from simulations and real-world data analysis demonstrate that the proposed method achieves more significant performance improvement on downstream regression tasks compared with classical feature extraction techniques.

</details>


### [81] [Cross-View Topology-Aware Graph Representation Learning](https://arxiv.org/abs/2512.02130)
*Ahmet Sami Korkmaz,Selim Coskunuzer,Md Joshem Uddin*

Main category: cs.LG

TL;DR: GraphTCL：一种结合图神经网络结构嵌入和持久同调拓扑嵌入的双视图对比学习框架，用于提升图分类性能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）虽然能有效捕捉局部结构模式，但往往忽略了全局拓扑特征，而这些特征对于鲁棒的表示学习至关重要。现有方法在整合结构信息和拓扑信息方面存在不足。

Method: 提出GraphTCL框架，通过双视图对比学习整合GNNs的结构嵌入和持久同调的拓扑嵌入。使用跨视图对比损失对齐这两个互补视图，增强表示质量。

Result: 在TU和OGB分子图等基准数据集上的广泛实验表明，GraphTCL consistently outperforms state-of-the-art baselines，显著提升了图分类性能。

Conclusion: 拓扑感知的对比学习对于推进图表示方法具有重要意义，GraphTCL通过整合结构信息和拓扑信息，为图分类任务提供了更强大的表示学习框架。

Abstract: Graph classification has gained significant attention due to its applications in chemistry, social networks, and bioinformatics. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they often overlook global topological features that are critical for robust representation learning. In this work, we propose GraphTCL, a dual-view contrastive learning framework that integrates structural embeddings from GNNs with topological embeddings derived from persistent homology. By aligning these complementary views through a cross-view contrastive loss, our method enhances representation quality and improves classification performance. Extensive experiments on benchmark datasets, including TU and OGB molecular graphs, demonstrate that GraphTCL consistently outperforms state-of-the-art baselines. This study highlights the importance of topology-aware contrastive learning for advancing graph representation methods.

</details>


### [82] [How Market Volatility Shapes Algorithmic Collusion: A Comparative Analysis of Learning-Based Pricing Algorithms](https://arxiv.org/abs/2512.02134)
*Aheer Sravon,Md. Ibrahim,Devdyuti Mazumder,Ridwan Al Aziz*

Main category: cs.LG

TL;DR: 该研究分析了四种定价算法在三种双寡头市场模型和不同需求冲击下的竞争行为，发现强化学习算法在稳定需求下维持超竞争价格，DDPG最具合谋倾向，需求冲击对不同市场结构影响各异，但算法相对排名保持稳定。


<details>
  <summary>Details</summary>
Motivation: 自主定价算法日益影响数字市场竞争，但其在现实需求条件下的行为尚未得到充分研究。本文旨在填补这一空白，分析算法、市场结构和随机需求如何共同影响竞争结果。

Method: 研究分析了四种定价算法（Q-Learning、PSO、Double DQN、DDPG）在三种经典双寡头模型（Logit、Hotelling、Linear）下的表现，使用自回归过程创建不同需求冲击机制，并采用利润和价格基础的合谋指数进行评估。

Result: 强化学习算法在稳定需求下常维持超竞争价格，DDPG表现出最明显的合谋倾向。需求冲击影响各异：Logit市场性能显著下降，Hotelling市场保持稳定，Linear市场出现冲击诱导的利润膨胀。尽管绝对性能变化显著，但算法相对排名在不同环境中保持一致。

Conclusion: 市场结构和需求不确定性对算法竞争具有关键影响，这些发现为自主定价行为的政策讨论提供了重要见解，强调了在评估算法竞争时需要综合考虑市场特性和需求条件。

Abstract: Autonomous pricing algorithms are increasingly influencing competition in digital markets; however, their behavior under realistic demand conditions remains largely unexamined. This paper offers a thorough analysis of four pricing algorithms -- Q-Learning, PSO, Double DQN, and DDPG -- across three classic duopoly models (Logit, Hotelling, Linear) and under various demand-shock regimes created by auto-regressive processes. By utilizing profit- and price-based collusion indices, we investigate how the interactions among algorithms, market structure, and stochastic demand collaboratively influence competitive outcomes. Our findings reveal that reinforcement-learning algorithms often sustain supra-competitive prices under stable demand, with DDPG demonstrating the most pronounced collusive tendencies. Demand shocks produce notably varied effects: Logit markets suffer significant performance declines, Hotelling markets remain stable, and Linear markets experience shock-induced profit inflation. Despite marked changes in absolute performance, the relative rankings of the algorithms are consistent across different environments. These results underscore the critical importance of market structure and demand uncertainty in shaping algorithmic competition, while also contributing to the evolving policy discussions surrounding autonomous pricing behavior.

</details>


### [83] [CLEF: Clinically-Guided Contrastive Learning for Electrocardiogram Foundation Models](https://arxiv.org/abs/2512.02180)
*Yuxuan Shu,Peter H. Charlton,Fahim Kawsar,Jussi Hernesniemi,Mohammad Malekzadeh*

Main category: cs.LG

TL;DR: 提出CLEF模型，通过临床风险评分自适应加权负样本对的对比学习方法，在无标注ECG数据上预训练单导联心电图基础模型，显著提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督预训练方法未充分利用临床元数据中的领域知识，而临床风险评分等元数据能提供重要的临床意义信息，有助于提升心电图分析性能。

Method: 提出临床引导对比学习方法，利用临床风险评分自适应加权负样本对，使ECG嵌入相似性与临床差异对齐，并处理缺失元数据。在MIMIC-IV数据集上预训练三个尺度的单导联ECG基础模型。

Result: 在7个测试数据集上的18个临床任务中，CLEF在12导联预训练、单导联测试时，相比自监督基础模型基线，分类AUROC平均提升至少2.6%，回归MAE平均降低至少3.2%。仅用单导联数据预训练时，性能与监督训练的ECGFounder相当。

Conclusion: CLEF通过整合临床元数据实现更准确、可扩展的单导联ECG分析，推进远程健康监测。模型代码已开源。

Abstract: The electrocardiogram (ECG) is a key diagnostic tool in cardiovascular health. Single-lead ECG recording is integrated into both clinical-grade and consumer wearables. While self-supervised pretraining of foundation models on unlabeled ECGs improves diagnostic performance, existing approaches do not incorporate domain knowledge from clinical metadata. We introduce a novel contrastive learning approach that utilizes an established clinical risk score to adaptively weight negative pairs: clinically-guided contrastive learning. It aligns the similarities of ECG embeddings with clinically meaningful differences between subjects, with an explicit mechanism to handle missing metadata. On 12-lead ECGs from 161K patients in the MIMIC-IV dataset, we pretrain single-lead ECG foundation models at three scales, collectively called CLEF, using only routinely collected metadata without requiring per-sample ECG annotations. We evaluate CLEF on 18 clinical classification and regression tasks across 7 held-out datasets, and benchmark against 5 foundation model baselines and 3 self-supervised algorithms. When pretrained on 12-lead ECG data and tested on lead-I data, CLEF outperforms self-supervised foundation model baselines: the medium-sized CLEF achieves average AUROC improvements of at least 2.6% in classification and average reductions in MAEs of at least 3.2% in regression. Comparing with existing self-supervised learning algorithms, CLEF improves the average AUROC by at least 1.8%. Moreover, when pretrained only on lead-I data for classification tasks, CLEF performs comparably to the state-of-the-art ECGFounder, which was trained in a supervised manner. Overall, CLEF enables more accurate and scalable single-lead ECG analysis, advancing remote health monitoring. Code and pretrained CLEF models are available at: github.com/Nokia-Bell-Labs/ecg-foundation-model.

</details>


### [84] [Enforcing Orderedness to Improve Feature Consistency](https://arxiv.org/abs/2512.02194)
*Sophie L. Wang,Alex Quach,Nithin Parsan,John J. Yang*

Main category: cs.LG

TL;DR: 提出Ordered Sparse Autoencoders (OSAE)，通过建立严格的特征排序和确定性使用每个特征维度，解决稀疏自编码器特征不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在神经网络可解释性中广泛应用，但其学习到的特征在不同随机种子和超参数设置下存在不一致性，这影响了特征的可重复性和可靠性。

Method: 扩展Matryoshka SAEs，引入两个关键改进：(1) 建立严格的潜在特征排序；(2) 确定性使用每个特征维度，避免先前嵌套SAE方法中的基于采样的近似。

Result: 理论上证明OSAE在稀疏字典学习设置中解决了排列不可识别性问题（在自然对称性范围内保持唯一性）。在Gemma2-2B和Pythia-70M上的实证研究表明，相比Matryoshka基线，OSAE能提高特征一致性。

Conclusion: OSAE通过引入特征排序和确定性维度使用，解决了稀疏自编码器特征不一致的问题，为神经网络可解释性提供了更可靠的特征表示方法。

Abstract: Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.

</details>


### [85] [Modelling the Doughnut of social and planetary boundaries with frugal machine learning](https://arxiv.org/abs/2512.02200)
*Stefano Vrizzi,Daniel W. O'Neill*

Main category: cs.LG

TL;DR: 机器学习方法应用于甜甜圈模型，寻找实现环境和社会可持续性的政策参数


<details>
  <summary>Details</summary>
Motivation: 甜甜圈模型作为评估环境和社会可持续性的流行框架，需要探索如何应用机器学习方法来寻找实现可持续性的政策方案

Method: 使用随机森林分类器和Q学习等轻量级机器学习方法，应用于简单的宏观经济甜甜圈模型，寻找符合"生活在甜甜圈内"的政策参数

Result: 机器学习方法能够找到同时实现环境和社会可持续性的政策参数组合，并识别参数空间中的最优轨迹

Conclusion: 这些轻量级机器学习方法在简单模型中有效，下一步将应用于更复杂的生态宏观经济模型

Abstract: The 'Doughnut' of social and planetary boundaries has emerged as a popular framework for assessing environmental and social sustainability. Here, we provide a proof-of-concept analysis that shows how machine learning (ML) methods can be applied to a simple macroeconomic model of the Doughnut. First, we show how ML methods can be used to find policy parameters that are consistent with 'living within the Doughnut'. Second, we show how a reinforcement learning agent can identify the optimal trajectory towards desired policies in the parameter space. The approaches we test, which include a Random Forest Classifier and $Q$-learning, are frugal ML methods that are able to find policy parameter combinations that achieve both environmental and social sustainability. The next step is the application of these methods to a more complex ecological macroeconomic model.

</details>


### [86] [WhAM: Towards A Translative Model of Sperm Whale Vocalization](https://arxiv.org/abs/2512.02206)
*Orr Paradise,Pranav Muralikrishnan,Liangyuan Chen,Hugo Flores García,Bryan Pardo,Roee Diamant,David F. Gruber,Shane Gero,Shafi Goldwasser*

Main category: cs.LG

TL;DR: WhAM是基于Transformer的模型，能够从任意音频提示生成合成抹香鲸点击序列（codas），通过微调VampNet在1万条鲸鱼录音上训练，生成高质量合成codas并保留关键声学特征。


<details>
  <summary>Details</summary>
Motivation: 抹香鲸通过称为codas的点击序列进行交流，但目前缺乏能够生成合成鲸鱼codas的模型。研究旨在开发首个基于Transformer的模型，能够从任意音频提示生成高质量的合成抹香鲸codas。

Method: 通过微调在音乐音频上预训练的掩码声学标记模型VampNet，使用过去20年收集的1万条coda录音进行训练。采用迭代掩码标记预测方法生成合成codas。

Result: WhAM生成高保真合成codas，保留源录音的关键声学特征。通过Fréchet Audio Distance和专家感知研究评估质量。在节奏、社会单元和元音分类等下游任务中，WhAM学习到的表示表现出色，尽管模型是为生成而非分类任务训练的。

Conclusion: WhAM是首个能够从任意音频提示生成合成抹香鲸codas的Transformer模型，在生成质量和下游分类任务中都表现出色，为鲸鱼声学研究提供了新工具。

Abstract: Sperm whales communicate in short sequences of clicks known as codas. We present WhAM (Whale Acoustics Model), the first transformer-based model capable of generating synthetic sperm whale codas from any audio prompt. WhAM is built by finetuning VampNet, a masked acoustic token model pretrained on musical audio, using 10k coda recordings collected over the past two decades. Through iterative masked token prediction, WhAM generates high-fidelity synthetic codas that preserve key acoustic features of the source recordings. We evaluate WhAM's synthetic codas using Fréchet Audio Distance and through perceptual studies with expert marine biologists. On downstream classification tasks including rhythm, social unit, and vowel classification, WhAM's learned representations achieve strong performance, despite being trained for generation rather than classification. Our code is available at https://github.com/Project-CETI/wham

</details>


### [87] [InstructLR: A Scalable Approach to Create Instruction Dataset for Under-Resourced Languages](https://arxiv.org/abs/2512.02213)
*Mamadou K. Keita,Sebastien Diarra,Christopher Homan,Seydou Diallo*

Main category: cs.LG

TL;DR: InstructLR框架通过LLM生成和双重质量过滤机制，为低资源语言创建高质量指令数据集，解决了非洲语言等低资源语言缺乏优质指令数据的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在低资源语言（特别是非洲语言）上的文本生成和对话接口效果不佳，主要原因是缺乏高质量的指令数据集。现有的自动翻译和合成数据生成方法经常产生不流畅甚至拼写不一致的输出。

Method: 提出InstructLR框架，整合LLM驱动的文本生成和双重质量过滤机制：1）基于检索增强生成（RAG）的n-shot提示自动过滤层；2）人工参与验证层。受MMLU等基准测试启发，该方法创建了三个多领域指令基准。

Result: 成功创建了三个高质量的低资源语言指令数据集：ZarmaInstruct-50k（扎尔马语）、BambaraInstruct-50k（班巴拉语）和FulfuldeInstruct-50k（富拉语），每个包含5万条指令。

Conclusion: InstructLR框架有效解决了低资源语言高质量指令数据集的生成难题，为支持非洲语言等低资源语言的LLM应用提供了可行方案，通过双重质量过滤确保了数据集的实用性和可靠性。

Abstract: Effective text generation and chat interfaces for low-resource languages (LRLs) remain a challenge for state-of-the-art large language models (LLMs) to support. This is mainly due to the difficulty of curating high-quality instruction datasets for LRLs, a limitation prevalent in the languages spoken across the African continent and other regions. Current approaches, such as automated translation and synthetic data generation, frequently yield outputs that lack fluency or even orthographic consistency. In this paper, we introduce InstructLR, a novel framework designed to generate high-quality instruction datasets for LRLs. Our approach integrates LLM-driven text generation with a dual-layer quality filtering mechanism: an automated filtering layer based on retrieval-augmented-generation (RAG)-based n-shot prompting, and a human-in-the-loop validation layer. Drawing inspiration from benchmarks such as MMLU in task definition, InstructLR has facilitated the creation of three multi-domain instruction benchmarks: ZarmaInstruct-50k, BambaraInstruct-50k, and FulfuldeInstruct-50k.

</details>


### [88] [Improved Training Mechanism for Reinforcement Learning via Online Model Selection](https://arxiv.org/abs/2512.02214)
*Aida Afshar,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 该论文研究强化学习中的在线模型选择问题，通过自适应选择合适配置的智能体来提高训练效率和性能，从理论角度解决资源分配、非平稳动态适应和训练稳定性三个实际问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习中需要选择合适的模型配置（如神经网络架构、步长等），传统方法通常需要大量试错。在线模型选择旨在通过自适应选择机制，提高训练效率和最终性能，解决实际部署中的资源分配、环境动态变化和训练稳定性问题。

Method: 提出强化学习中的在线模型选择框架，智能体可以访问一组不同配置的强化学习智能体，并学习自适应选择最优配置。从理论角度分析三个关键标准：1）高效资源分配，2）非平稳动态环境下的适应能力，3）不同随机种子下的训练稳定性。通过理论分析和实证验证相结合的方法。

Result: 理论分析为在线模型选择提供了有效指导，实证结果在多个强化学习模型选择任务中验证了方法的有效性，包括神经网络架构选择、步长选择和自模型选择，展示了改进的效率和性能增益。

Conclusion: 在线模型选择方法能够显著提升强化学习的训练效率和性能，理论分析为实践中的配置选择提供了有效指导，解决了资源分配、环境适应和训练稳定性等实际问题，具有重要的理论和实践价值。

Abstract: We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating online model selection methods into reinforcement learning training procedures. We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Adaptation under non-stationary dynamics, and 3) Training stability across different seeds. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self model selection.

</details>


### [89] [Uncertainty Reasoning with Photonic Bayesian Machines](https://arxiv.org/abs/2512.02217)
*F. Brückerhoff-Plückelmann,H. Borras,S. U. Hulyal,L. Meyer,X. Ji,J. Hu,J. Sun,B. Klein,F. Ebert,J. Dijkstra,L. McRae,P. Schmidt,T. J. Kippenberg,H. Fröning,W. Pernice*

Main category: cs.LG

TL;DR: 提出一种利用混沌光源固有随机性的光子贝叶斯机器，实现高速不确定性推理，用于可信AI系统


<details>
  <summary>Details</summary>
Motivation: AI系统在医疗诊断、自动驾驶等安全关键领域应用日益广泛，不确定性感知成为可信AI的核心需求。传统数字系统存在伪随机数生成瓶颈和采样成本高的问题。

Method: 设计光子贝叶斯机器，利用混沌光源的固有随机性，在贝叶斯神经网络框架内实现不确定性推理。系统具有1.28 Tbit/s数字接口，兼容PyTorch，每卷积处理仅需37.5 ps。

Result: 成功应用于血细胞显微镜图像的同时分类和域外检测，能够区分偶然不确定性和认知不确定性。系统消除了数字系统中伪随机数生成的瓶颈，大幅降低了概率模型的采样成本。

Conclusion: 光子贝叶斯机器为高速可信AI系统提供了有效解决方案，通过利用光子硬件的固有随机性，实现了高效的不确定性推理，有望推动安全关键AI应用的发展。

Abstract: Artificial intelligence (AI) systems increasingly influence safety-critical aspects of society, from medical diagnosis to autonomous mobility, making uncertainty awareness a central requirement for trustworthy AI. We present a photonic Bayesian machine that leverages the inherent randomness of chaotic light sources to enable uncertainty reasoning within the framework of Bayesian Neural Networks. The analog processor features a 1.28 Tbit/s digital interface compatible with PyTorch, enabling probabilistic convolutions processing within 37.5 ps per convolution. We use the system for simultaneous classification and out-of-domain detection of blood cell microscope images and demonstrate reasoning between aleatoric and epistemic uncertainties. The photonic Bayesian machine removes the bottleneck of pseudo random number generation in digital systems, minimizes the cost of sampling for probabilistic models, and thus enables high-speed trustworthy AI systems.

</details>


### [90] [On the Approximation of Phylogenetic Distance Functions by Artificial Neural Networks](https://arxiv.org/abs/2512.02223)
*Benjamin K. Rosenzweig,Matthew W. Hahn*

Main category: cs.LG

TL;DR: 提出最小神经网络架构来近似经典系统发育距离函数，能够学习多种分子进化模型下的距离，相比传统方法计算开销小且可扩展性强


<details>
  <summary>Details</summary>
Motivation: 传统基于距离的层次聚类算法已被贝叶斯和最大似然搜索方法取代，但这些方法基于复杂的分子进化模型。需要开发计算开销小、可扩展性强且能学习多种进化模型距离的方法

Method: 设计最小神经网络架构来近似经典系统发育距离函数，学习多种分子进化模型下的距离特性，相比基于模型的推理和最近提出的卷积/transformer网络，具有更小的计算足迹

Result: 学习的距离函数泛化能力强，在适当训练数据集下能达到与最先进推理方法相当的结果，同时具有计算开销小、可扩展到大量分类单元和分子特征的优势

Conclusion: 最小神经网络架构能够有效学习系统发育距离函数，在保持高性能的同时显著降低计算复杂度，为大规模系统发育分析提供了有前景的替代方案

Abstract: Inferring the phylogenetic relationships among a sample of organisms is a fundamental problem in modern biology. While distance-based hierarchical clustering algorithms achieved early success on this task, these have been supplanted by Bayesian and maximum likelihood search procedures based on complex models of molecular evolution. In this work we describe minimal neural network architectures that can approximate classic phylogenetic distance functions and the properties required to learn distances under a variety of molecular evolutionary models. In contrast to model-based inference (and recently proposed model-free convolutional and transformer networks), these architectures have a small computational footprint and are scalable to large numbers of taxa and molecular characters. The learned distance functions generalize well and, given an appropriate training dataset, achieve results comparable to state-of-the art inference methods.

</details>


### [91] [The Effect of Enforcing Fairness on Reshaping Explanations in Machine Learning Models](https://arxiv.org/abs/2512.02265)
*Joshua Wolff Anderson,Shyam Visweswaran*

Main category: cs.LG

TL;DR: 研究探讨公平性约束如何影响机器学习模型的可解释性，特别是SHAP特征重要性排名的稳定性


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要可信的机器学习模型，包括良好的预测性能、公平性和可解释性。虽然已知提升公平性会影响预测性能，但公平性改进如何影响可解释性（临床信任的关键要素）尚不清楚。临床医生可能不愿依赖公平性约束后解释发生变化的模型。

Method: 研究通过偏差缓解技术增强公平性，分析其对基于SHAP的特征排名的影响。在三个数据集（儿童尿路感染风险、直接抗凝剂出血风险、再犯风险）上量化公平性约束后特征重要性排名的变化，并评估多个模型类别在SHAP排名稳定性方面的表现。

Result: 提高种族亚组间的模型公平性会显著改变特征重要性排名，有时在不同群体间以不同方式变化。公平性约束可能导致解释的显著变化。

Conclusion: 需要在模型评估中联合考虑准确性、公平性和可解释性，而不是孤立地看待这些因素。公平性改进可能以可解释性为代价，这对临床信任有重要影响。

Abstract: Trustworthy machine learning in healthcare requires strong predictive performance, fairness, and explanations. While it is known that improving fairness can affect predictive performance, little is known about how fairness improvements influence explainability, an essential ingredient for clinical trust. Clinicians may hesitate to rely on a model whose explanations shift after fairness constraints are applied. In this study, we examine how enhancing fairness through bias mitigation techniques reshapes Shapley-based feature rankings. We quantify changes in feature importance rankings after applying fairness constraints across three datasets: pediatric urinary tract infection risk, direct anticoagulant bleeding risk, and recidivism risk. We also evaluate multiple model classes on the stability of Shapley-based rankings. We find that increasing model fairness across racial subgroups can significantly alter feature importance rankings, sometimes in different ways across groups. These results highlight the need to jointly consider accuracy, fairness, and explainability in model assessment rather than in isolation.

</details>


### [92] [Limitations of Membership Queries in Testable Learning](https://arxiv.org/abs/2512.02279)
*Jane Lange,Mingda Qiao*

Main category: cs.LG

TL;DR: 测试学习模型中，成员查询无法显著降低时间复杂性，且高效的成员查询学习器无法被转化为可测试的学习器。


<details>
  <summary>Details</summary>
Motivation: 研究在测试学习模型中，成员查询是否能够比仅使用样本的分布特定学习更高效地降低时间复杂性。

Method: 将基于样本的布尔概念类反驳归约到带查询的测试学习，并定义一类"统计"成员查询算法，证明这类算法暗示高效的统计查询反驳和学习算法。

Result: 在测试学习模型中，成员查询不能使算法比最佳样本PAC学习器超多项式地更高效，且高效的成员查询学习器无法被转化为可测试的学习器。

Conclusion: 测试学习模型限制了成员查询的效用，高效的成员查询学习器与可测试性之间存在根本性冲突。

Abstract: Membership queries (MQ) often yield speedups for learning tasks, particularly in the distribution-specific setting. We show that in the \emph{testable learning} model of Rubinfeld and Vasilyan [RV23], membership queries cannot decrease the time complexity of testable learning algorithms beyond the complexity of sample-only distribution-specific learning. In the testable learning model, the learner must output a hypothesis whenever the data distribution satisfies a desired property, and if it outputs a hypothesis, the hypothesis must be near-optimal.
  We give a general reduction from sample-based \emph{refutation} of boolean concept classes, as presented in [Vadhan17, KL18], to testable learning with queries (TL-Q). This yields lower bounds for TL-Q via the reduction from learning to refutation given in [KL18]. The result is that, relative to a concept class and a distribution family, no $m$-sample TL-Q algorithm can be super-polynomially more time-efficient than the best $m$-sample PAC learner.
  Finally, we define a class of ``statistical'' MQ algorithms that encompasses many known distribution-specific MQ learners, such as those based on influence estimation or subcube-conditional statistical queries. We show that TL-Q algorithms in this class imply efficient statistical-query refutation and learning algorithms. Thus, combined with known SQ dimension lower bounds, our results imply that these efficient membership query learners cannot be made testable.

</details>


### [93] [Training Dynamics of Learning 3D-Rotational Equivariance](https://arxiv.org/abs/2512.02303)
*Max W. Shen,Ewa Nowara,Michael Maser,Kyunghyun Cho*

Main category: cs.LG

TL;DR: 论文研究了对称性无关模型学习对称性的速度和效果，提出了衡量等变误差的原则性方法，发现在3D旋转等变任务中，模型能快速学习到高精度对称性，但非等变模型可能因计算效率更高而表现更好。


<details>
  <summary>Details</summary>
Motivation: 尽管数据增强被广泛用于训练对称性无关模型，但模型学习尊重对称性的速度和效果仍不清楚。研究者希望量化模型学习对称性的过程，特别是在3D旋转等变任务中。

Method: 提出了一个原则性的等变误差度量方法，用于计算由于学习对称性不完美导致的损失比例。在3D旋转等变的高维分子任务（流匹配、力场预测、体素去噪）上进行实证研究，分析模型大小、数据集大小等因素的影响。

Result: 模型在1k-10k训练步内就能将等变误差降低到≤2%的保留损失，这一结果对模型和数据集大小具有鲁棒性。学习3D旋转等变是一个相对容易的任务，具有更平滑、条件更好的损失景观。非等变模型在整个训练过程中损失惩罚较小，可能在GPU小时内获得比等变模型更低的测试损失。

Conclusion: 模型能快速学习3D旋转对称性，但等变模型需要提高计算效率才能与非等变模型竞争。研究还探讨了相对等变误差、学习梯度和模型参数之间的关系。

Abstract: While data augmentation is widely used to train symmetry-agnostic models, it remains unclear how quickly and effectively they learn to respect symmetries. We investigate this by deriving a principled measure of equivariance error that, for convex losses, calculates the percent of total loss attributable to imperfections in learned symmetry. We focus our empirical investigation to 3D-rotation equivariance on high-dimensional molecular tasks (flow matching, force field prediction, denoising voxels) and find that models reduce equivariance error quickly to $\leq$2\% held-out loss within 1k-10k training steps, a result robust to model and dataset size. This happens because learning 3D-rotational equivariance is an easier learning task, with a smoother and better-conditioned loss landscape, than the main prediction task. For 3D rotations, the loss penalty for non-equivariant models is small throughout training, so they may achieve lower test loss than equivariant models per GPU-hour unless the equivariant ``efficiency gap'' is narrowed. We also experimentally and theoretically investigate the relationships between relative equivariance error, learning gradients, and model parameters.

</details>


### [94] [Unlocking the Power of Boltzmann Machines by Parallelizable Sampler and Efficient Temperature Estimation](https://arxiv.org/abs/2512.02323)
*Kentaro Kubo,Hayato Goto*

Main category: cs.LG

TL;DR: 提出SAL框架，结合LSB采样器和CEM温度估计方法，实现比RBM更强大的玻尔兹曼机高效学习


<details>
  <summary>Details</summary>
Motivation: 玻尔兹曼机是强大的生成模型，但训练成本高，实际应用多限于受限玻尔兹曼机。更准确的学习需要MCMC玻尔兹曼采样，但并行化困难且耗时

Method: 1. 提出LSB采样器：受量子启发组合优化算法模拟分岔启发，实现并行采样；2. 提出CEM方法：在学习过程中高效估计逆温度；3. 结合LSB和CEM形成SAL框架

Result: LSB实现并行采样且精度与MCMC相当，适用于一般耦合的玻尔兹曼机。SAL框架为超越RBM的能量基生成建模开辟新途径

Conclusion: SAL框架解决了玻尔兹曼机训练中的采样效率和温度控制问题，使更强大的玻尔兹曼机模型变得实用可行

Abstract: Boltzmann machines (BMs) are powerful energy-based generative models, but their heavy training cost has largely confined practical use to Restricted BMs (RBMs) trained with an efficient learning method called contrastive divergence. More accurate learning typically requires Markov chain Monte Carlo (MCMC) Boltzmann sampling, but it is time-consuming due to the difficulty of parallelization for more expressive models. To address this limitation, we first propose a new Boltzmann sampler inspired by a quantum-inspired combinatorial optimization called simulated bifurcation (SB). This SB-inspired approach, which we name Langevin SB (LSB), enables parallelized sampling while maintaining accuracy comparable to MCMC. Furthermore, this is applicable not only to RBMs but also to BMs with general couplings. However, LSB cannot control the inverse temperature of the output Boltzmann distribution, which hinders learning and degrades performance. To overcome this limitation, we also developed an efficient method for estimating the inverse temperature during the learning process, which we call conditional expectation matching (CEM). By combining LSB and CEM, we establish an efficient learning framework for BMs with greater expressive power than RBMs. We refer to this framework as sampler-adaptive learning (SAL). SAL opens new avenues for energy-based generative modeling beyond RBMs.

</details>


### [95] [Retrieval-Augmented Memory for Online Learning](https://arxiv.org/abs/2512.02333)
*Wenzhang Du*

Main category: cs.LG

TL;DR: RAM-OL是一种用于概念漂移在线学习的检索增强记忆方法，通过检索历史样本的最近邻来增强当前样本的学习，在周期性漂移数据流上显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强模型在流式监督学习中的概念漂移问题研究不足，需要开发能够在非平稳环境中有效利用历史知识的在线学习方法。

Method: RAM-OL是SGD的简单扩展，维护一个小型历史样本缓冲区，在隐藏表示空间中检索当前输入的最近邻，并联合更新当前样本和检索到的邻居。包含朴素重放和门控重放两种变体。

Result: 在强周期漂移数据流上，RAM-OL将预序列准确性提升约7个百分点，大幅减少随机种子间的方差；在噪声数据流上，门控变体与纯在线基线相当。

Conclusion: 检索增强记忆是处理概念漂移在线学习的实用且鲁棒的工具，能够有效利用历史模式重复出现的特性来改善学习性能。

Abstract: Retrieval-augmented models couple parametric predictors with non-parametric memories, but their use in streaming supervised learning with concept drift is not well understood. We study online classification in non-stationary environments and propose Retrieval-Augmented Memory for Online Learning (RAM-OL), a simple extension of stochastic gradient descent that maintains a small buffer of past examples. At each time step, RAM-OL retrieves a few nearest neighbours of the current input in the hidden representation space and updates the model jointly on the current example and the retrieved neighbours. We compare a naive replay variant with a gated replay variant that constrains neighbours using a time window, similarity thresholds, and gradient reweighting, in order to balance fast reuse of relevant past data against robustness to outdated regimes. From a theoretical perspective, we interpret RAM-OL under a bounded drift model and discuss how retrieval can reduce adaptation cost and improve regret constants when patterns recur over time. Empirically, we instantiate RAM-OL on a simple online multilayer perceptron and evaluate it on three real-world data streams derived from electricity pricing, electricity load, and airline delay data. On strongly and periodically drifting streams, RAM-OL improves prequential accuracy by up to about seven percentage points and greatly reduces variance across random seeds, while on a noisy airline stream the gated variant closely matches the purely online baseline. These results show that retrieval-augmented memory is a practical and robust tool for online learning under concept drift.

</details>


### [96] [Forecasting MBTA Transit Dynamics: A Performance Benchmarking of Statistical and Machine Learning Models](https://arxiv.org/abs/2512.02336)
*Sai Siddharth Nalamalpu,Kaining Yuan,Aiden Zhou,Eugene Pinsky*

Main category: cs.LG

TL;DR: 该研究比较了多种统计和机器学习模型在预测波士顿地铁使用量和MBTA系统延误次数方面的性能，发现日期特征比天气数据对预测准确性更有帮助。


<details>
  <summary>Details</summary>
Motivation: MBTA系统经常面临延误和客流量波动问题，影响效率和乘客满意度。需要开发更好的预测方法来理解这些现象。

Method: 使用10个统计和机器学习模型预测次日地铁使用量，11个模型预测延误次数（包括自激点过程模型）。考虑日期、季节、天气等特征，通过特征选择和RMSE评估模型性能。

Result: 日期特征（星期几或季节）比天气数据对预测准确性更有帮助；天气数据通常会降低性能，表明模型容易过拟合。

Conclusion: 在公共交通预测中，日期特征比天气因素更重要；天气数据可能导致模型过拟合；自激点过程模型在延误预测中有独特应用价值。

Abstract: The Massachusetts Bay Transportation Authority (MBTA) is the main public transit provider in Boston, operating multiple means of transport, including trains, subways, and buses. However, the system often faces delays and fluctuations in ridership volume, which negatively affect efficiency and passenger satisfaction. To further understand this phenomenon, this paper compares the performance of existing and unique methods to determine the best approach in predicting gated station entries in the subway system (a proxy for subway usage) and the number of delays in the overall MBTA system. To do so, this research considers factors that tend to affect public transportation, such as day of week, season, pressure, wind speed, average temperature, and precipitation. This paper evaluates the performance of 10 statistical and machine learning models on predicting next-day subway usage. On predicting delay count, the number of models is extended to 11 per day by introducing a self-exciting point process model, representing a unique application of a point-process framework for MBTA delay modeling. This research involves experimenting with the selective inclusion of features to determine feature importance, testing model accuracy via Root Mean Squared Error (RMSE). Remarkably, it is found that providing either day of week or season data has a more substantial benefit to predictive accuracy compared to weather data; in fact, providing weather data generally worsens performance, suggesting a tendency of models to overfit.

</details>


### [97] [SpecPV: Improving Self-Speculative Decoding for Long-Context Generation via Partial Verification](https://arxiv.org/abs/2512.02337)
*Zhendong Tan,Xingjun Zhang,Chaoyi Hu,Junjie Peng,Kun Xia*

Main category: cs.LG

TL;DR: SpecPV：一种用于长上下文生成的自推测解码方法，通过部分KV状态快速验证和周期性全验证，在多个长上下文基准测试中实现最高6倍解码加速


<details>
  <summary>Details</summary>
Motivation: 随着代码生成、深度推理和长文档理解等任务需求的增长，长上下文生成成为LLMs的关键能力。推测解码是加速生成的最直接有效方法之一，但随着上下文长度增加，验证成为主要瓶颈。

Method: 提出SpecPV自推测解码方法：1）使用部分键值状态（KV）进行快速验证；2）周期性应用全验证以消除累积错误

Result: 在多个长上下文基准测试和模型（包括LLaMA-3.1-8B-Instruct和Qwen3系列）上验证，SpecPV相比标准自回归解码实现最高6倍解码加速，性能退化很小

Conclusion: SpecPV通过部分KV状态快速验证和周期性全验证的有效结合，成功解决了长上下文生成中推测解码的验证瓶颈问题，显著加速了生成过程

Abstract: Growing demands from tasks like code generation, deep reasoning, and long-document understanding have made long-context generation a crucial capability for large language models (LLMs). Speculative decoding is one of the most direct and effective approaches for accelerating generation. It follows a draft-verify paradigm, where a lightweight draft model proposes several candidate tokens and the target model verifies them. However, we find that as the context length grows, verification becomes the dominant bottleneck. To further accelerate speculative decoding in long-context generation, we introduce SpecPV, a self-speculative decoding approach that performs fast verification using partial key-value states (KV) and periodically applies full verification to eliminate accumulated errors. We validate SpecPV across multiple long-context benchmarks and models, including LLaMA-3.1-8B-Instruct and Qwen3-series. Experimental results show that SpecPV achieves up to 6x decoding speedup over standard autoregressive decoding with minor degradation.

</details>


### [98] [FOVA: Offline Federated Reinforcement Learning with Mixed-Quality Data](https://arxiv.org/abs/2512.02350)
*Nan Qiao,Sheng Yue,Ju Ren,Yaoxue Zhang*

Main category: cs.LG

TL;DR: FOVA：基于投票机制的离线联邦强化学习框架，通过投票机制识别高质量动作，解决混合质量数据下的性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有离线联邦强化学习方法在面对混合质量数据（不同客户端策略质量差异大）时性能显著下降，需要新方法来克服这一限制

Method: 提出FOVA框架：1）使用投票机制在本地策略评估中识别高回报动作，减轻低质量行为影响；2）基于优势加权回归构建一致的本地和全局训练目标，提升效率和稳定性

Result: 理论分析证明FOVA学习到的策略相比行为策略有严格改进；大量实验验证FOVA在广泛使用的基准测试中显著优于现有基线方法

Conclusion: FOVA通过投票机制有效解决了离线联邦强化学习中混合质量数据带来的挑战，在理论和实验上都表现出优越性能

Abstract: Offline Federated Reinforcement Learning (FRL), a marriage of federated learning and offline reinforcement learning, has attracted increasing interest recently. Albeit with some advancement, we find that the performance of most existing offline FRL methods drops dramatically when provided with mixed-quality data, that is, the logging behaviors (offline data) are collected by policies with varying qualities across clients. To overcome this limitation, this paper introduces a new vote-based offline FRL framework, named FOVA. It exploits a \emph{vote mechanism} to identify high-return actions during local policy evaluation, alleviating the negative effect of low-quality behaviors from diverse local learning policies. Besides, building on advantage-weighted regression (AWR), we construct consistent local and global training objectives, significantly enhancing the efficiency and stability of FOVA. Further, we conduct an extensive theoretical analysis and rigorously show that the policy learned by FOVA enjoys strict policy improvement over the behavioral policy. Extensive experiments corroborate the significant performance gains of our proposed algorithm over existing baselines on widely used benchmarks.

</details>


### [99] [Reinforcement Learning in POMDP's via Direct Gradient Ascent](https://arxiv.org/abs/2512.02383)
*Jonathan Baxter,Peter L. Bartlett*

Main category: cs.LG

TL;DR: 本文提出GPOMDP算法，一种基于梯度的直接优化POMDP策略性能的方法，通过单样本路径估计平均奖励梯度，无需状态知识，具有自然偏差-方差权衡参数。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测马尔可夫决策过程（POMDP）中，直接优化策略性能面临挑战。现有方法通常需要多个样本路径或对底层状态的完全了解。本文旨在开发一种更实用的梯度估计方法，仅需单样本路径且无需状态知识。

Method: 提出GPOMDP算法，类似于REINFORCE算法，用于估计随机策略参数下平均奖励的梯度近似值。算法核心优势：仅需底层马尔可夫链的单样本路径；仅使用一个自由参数β∈[0,1)，该参数在偏差-方差权衡中具有自然解释；无需了解底层状态信息。

Result: 证明了GPOMDP算法的收敛性，并展示了如何将GPOMDP产生的梯度估计用于共轭梯度过程，以找到平均奖励的局部最优解。

Conclusion: GPOMDP为POMDP中的策略优化提供了一种实用且理论完备的梯度估计方法，仅需单样本路径且无需状态知识，通过自然参数实现偏差-方差权衡，可用于梯度优化过程找到局部最优策略。

Abstract: This paper discusses theoretical and experimental aspects of gradient-based approaches to the direct optimization of policy performance in controlled POMDPs. We introduce GPOMDP, a REINFORCE-like algorithm for estimating an approximation to the gradient of the average reward as a function of the parameters of a stochastic policy. The algorithm's chief advantages are that it requires only a single sample path of the underlying Markov chain, it uses only one free parameter $β\in [0,1)$, which has a natural interpretation in terms of bias-variance trade-off, and it requires no knowledge of the underlying state. We prove convergence of GPOMDP and show how the gradient estimates produced by GPOMDP can be used in a conjugate-gradient procedure to find local optima of the average reward.

</details>


### [100] [Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection](https://arxiv.org/abs/2512.02386)
*Chuhan Xie*

Main category: cs.LG

TL;DR: 该论文研究连续时间风险敏感强化学习问题，提出基于优化确定性等价的风险敏感Q学习算法，并在动态投资组合选择问题上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习通常关注期望回报最大化，但在金融、机器人控制等实际应用中，决策者需要考虑风险因素。现有风险敏感强化学习方法主要针对离散时间设置，连续时间环境下的风险敏感强化学习研究相对较少。

Method: 采用可控随机微分方程建模环境，使用优化确定性等价作为目标函数。提出CT-RS-q算法，基于新的鞅特征化方法进行风险敏感Q学习。通过增强环境状态空间证明最优策略的马尔可夫性。

Result: 理论证明当目标函数为优化确定性等价时，最优策略相对于增强环境是马尔可夫的。提出的CT-RS-q算法在动态投资组合选择问题的仿真研究中表现出有效性。

Conclusion: 该研究为连续时间风险敏感强化学习提供了理论框架和实用算法，扩展了风险敏感强化学习在连续时间环境中的应用，特别适用于金融投资组合管理等需要考虑风险的实际问题。

Abstract: This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.

</details>


### [101] [ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity](https://arxiv.org/abs/2512.02403)
*Hongxiang Liu,Zhifang Deng,Tong Pu,Shengli Lu*

Main category: cs.LG

TL;DR: ESACT是一个端到端稀疏加速器，通过局部相似性预测注意力稀疏性，减少52.03%计算量，能耗效率达3.29 TOPS/W


<details>
  <summary>Details</summary>
Motivation: Transformer模型计算成本高阻碍硬件部署，现有加速器大多只利用注意力中的行内稀疏性，而利用行间稀疏性的方法通常依赖昂贵的全局相似性估计，且只应用于一两个组件

Method: 提出ESACT端到端稀疏加速器，核心是局部相似性稀疏性预测(SPLS)机制，使用HLog量化在QK生成前预测局部注意力稀疏性，支持所有Transformer组件的稀疏加速

Result: 在26个基准测试中，SPLS减少总计算量52.03%，精度损失小于1%；ESACT端到端能耗效率达3.29 TOPS/W，注意力级能耗效率比SpAtten和Sanger分别提高2.95倍和2.26倍

Conclusion: 局部相似性可实现低开销的端到端稀疏加速，ESACT通过SPLS机制和硬件创新，为计算密集型Transformer提供了高效的稀疏加速解决方案

Abstract: Transformers, composed of QKV generation, attention computation, and FFNs,
  have become the dominant model across various domains due to their outstanding performance.
  However, their high computational cost hinders efficient hardware deployment.
  Sparsity offers a promising solution,
  yet most existing accelerators exploit only intra-row sparsity in attention,
  while few consider inter-row sparsity.
  Approaches leveraging inter-row sparsity often rely on costly global similarity estimation,
  which diminishes the acceleration benefits of sparsity,
  and typically apply sparsity to only one or two transformer components.
  Through careful analysis of the attention distribution and computation flow,
  we observe that local similarity allows end-to-end sparse acceleration with lower computational overhead.
  Motivated by this observation, we propose ESACT,
  an end-to-end sparse accelerator for compute-intensive Transformers.
  ESACT centers on the Sparsity Prediction with Local Similarity (SPLS) mechanism,
  which leverages HLog quantization to accurately predict local attention sparsity prior to QK generation,
  achieving efficient sparsity across all transformer components.
  To support efficient hardware realization, we introduce three architectural innovations.
  Experimental results on 26 benchmarks demonstrate that
  SPLS reduces total computation by 52.03% with less than 1% accuracy loss.
  ESACT achieves an end-to-end energy efficiency of 3.29 TOPS/W,
  and improves attention-level energy efficiency by 2.95x and 2.26x over
  SOTA attention accelerators SpAtten and Sanger, respectively.

</details>


### [102] [Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning](https://arxiv.org/abs/2512.02406)
*Oshada Jayasinghe,Farhana Choudhury,Egemen Tanin,Shanika Karunasekera*

Main category: cs.LG

TL;DR: 提出基于多智能体强化学习的动态路边停车位配置框架，通过优化停车位布局减少交通拥堵，在仿真实验中可将车辆平均旅行时间损失降低达47%


<details>
  <summary>Details</summary>
Motivation: 随着出行需求增加，交通拥堵成为城市主要问题。路边停车位占用道路空间，进一步阻碍交通流。利用车路协同技术，探索如何通过动态配置路边停车位来最小化其对交通拥堵的影响

Method: 采用双层多智能体强化学习框架：车道级智能体负责决定每条车道的最优停车位配置，使用结合LSTM和图注意力网络的深度Q学习架构捕捉时空相关性；区块级智能体控制车道级智能体并维持区块周围足够的停车位水平

Result: 在SUMO仿真平台上使用合成数据和墨尔本真实数据进行实验，结果显示所提框架能显著降低车辆平均旅行时间损失，最高可达47%，且停车步行距离仅有轻微增加

Conclusion: 动态配置路边停车位可以有效缓解交通拥堵，提出的多智能体强化学习框架具有可扩展性，能适应大规模道路网络，在减少旅行时间的同时保持停车便利性

Abstract: With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.

</details>


### [103] [Data Curation Through the Lens of Spectral Dynamics: Static Limits, Dynamic Acceleration, and Practical Oracles](https://arxiv.org/abs/2512.02409)
*Yizhou Zhang,Lun Du*

Main category: cs.LG

TL;DR: 本文分析了数据剪枝和合成数据生成等数据中心化策略对神经模型训练的影响，从算子谱结构角度证明静态剪枝无法改变谱尾指数，而理想的时间相关数据管理可以加速学习。


<details>
  <summary>Details</summary>
Motivation: 当前大规模神经模型训练采用了多种数据策略（数据剪枝、合成数据生成、跨模型蒸馏、RLHF、难度采样等），但其中一些策略（特别是自生成合成数据）往往增加数据量而不提升模型能力。需要从理论角度理解这些数据管理策略如何影响模型训练效果。

Method: 将数据管理形式化为采样分布的重加权，并将其影响映射到数据诱导算子的特征结构上。使用算子谱理论分析静态剪枝和时间相关数据管理对学习过程的影响。

Result: 1. 静态剪枝诱导有界算子，无法改变谱尾指数，只能提供有限区域改进，不能改变渐近神经缩放。2. 时间相关数据管理中，理想oracle能够跟踪谱残差并连续重归一化尾部，可以证明加速学习，但实际系统只能近似这种行为。

Conclusion: 数据管理策略的效果取决于其如何影响数据算子的谱结构。静态方法有根本性限制，而动态时间相关方法在理论上具有加速学习的潜力，但实际实现面临挑战。这为设计更有效的数据策略提供了理论指导。

Abstract: Large-scale neural models are increasingly trained with data pruning, synthetic data generation, cross-model distillation, reinforcement learning from human feedback (RLHF), and difficulty-based sampling. While several of these data-centric strategies reliably improve training efficiency and downstream performance, others fail to provide meaningful gains -- most notably self-generated synthetic data, which often increases dataset volume without enhancing model capability.
  We formalize data curation as reweighting the sampling distribution and map its effect onto the eigenstructure of the data-induced operator. Our first main result shows that \textbf{static pruning induces a bounded operator and therefore cannot change the spectral tail exponent}; it provides at most finite-region improvements and cannot alter asymptotic neural scaling. Our second result analyzes \textbf{time-dependent data curation}, showing that an ideal oracle capable of tracking spectral residuals and continuously re-normalizing the tail can provably accelerate learning -- although practical systems can only approximate this behavior.

</details>


### [104] [Cross-Domain Offline Policy Adaptation with Dynamics- and Value-Aligned Data Filtering](https://arxiv.org/abs/2512.02435)
*Zhongjian Qiao,Rui Yang,Jiafei Lyu,Chenjia Bai,Xiu Li,Zhuoran Yang,Siyang Gao,Shuang Qiu*

Main category: cs.LG

TL;DR: 提出DVDF方法，通过同时考虑动态对齐和价值对齐，从源域选择性地筛选高质量样本用于跨域离线强化学习，在多种动态偏移设置中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有跨域离线强化学习方法只关注动态对齐，忽略了价值对齐的重要性。简单合并源域和目标域数据可能导致性能下降，需要同时考虑动态和价值对齐来选择高质量的源域样本。

Method: 提出DVDF（动态和价值对齐数据筛选）方法，通过理论分析证明动态对齐和价值对齐对策略学习的重要性，然后设计方法选择同时具有高动态对齐和高价值对齐的源域样本。

Result: 在包括运动学和形态学偏移在内的多种动态偏移设置中，DVDF在多个任务和数据集上一致优于现有强基线方法，即使在目标域只有5000个转换的极低数据设置下也表现出色。

Conclusion: 动态对齐和价值对齐都是跨域离线强化学习的关键因素，DVDF方法通过同时考虑这两个方面，能够有效利用源域数据提升目标域策略性能。

Abstract: Cross-Domain Offline Reinforcement Learning aims to train an agent deployed in the target environment, leveraging both a limited target domain dataset and a source domain dataset with (possibly) sufficient data coverage. Due to the underlying dynamics misalignment between the source and target domain, simply merging the data from two datasets may incur inferior performance. Recent advances address this issue by selectively sharing source domain samples that exhibit dynamics alignment with the target domain. However, these approaches focus solely on dynamics alignment and overlook \textit{value alignment}, i.e., selecting high-quality, high-value samples from the source domain. In this paper, we first demonstrate that both dynamics alignment and value alignment are essential for policy learning, by examining the limitations of the current theoretical framework for cross-domain RL and establishing a concrete sub-optimality gap of a policy trained on the source domain and evaluated on the target domain. Motivated by the theoretical insights, we propose to selectively share those source domain samples with both high dynamics and value alignment and present our \textbf{\underline{D}}ynamics- and \textbf{\underline{V}}alue-aligned \textbf{\underline{D}}ata \textbf{\underline{F}}iltering (DVDF) method. We design a range of dynamics shift settings, including kinematic and morphology shifts, and evaluate DVDF on various tasks and datasets, as well as in challenging extremely low-data settings where the target domain dataset contains only 5,000 transitions. Extensive experiments demonstrate that DVDF consistently outperforms prior strong baselines and delivers exceptional performance across multiple tasks and datasets.

</details>


### [105] [When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents](https://arxiv.org/abs/2512.02445)
*Tsimur Hadeliya,Mohammad Ali Jauhar,Nidhi Sakpal,Diogo Cruz*

Main category: cs.LG

TL;DR: 研究发现LLM智能体在处理长上下文时存在性能和安全性问题：在100K token时性能下降超50%，拒绝率变化不可预测，揭示长上下文智能体安全评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM在长上下文提示上的评估，而智能体设置（从能力和安全角度）相对未被探索。本研究旨在填补这一空白，探究LLM智能体在长上下文环境下的表现。

Method: 通过评估LLM智能体在不同长度、类型和位置上下文下的表现，分析任务性能和拒绝有害请求的变化。测试了具有1M-2M token上下文窗口的模型在100K-200K token长度下的表现。

Result: 发现LLM智能体对上下文长度、类型和位置敏感，表现出意外且不一致的性能变化和拒绝率变化。在100K token时性能下降超过50%，拒绝率变化不可预测（如GPT-4.1-nano从~5%增加到~40%，Grok 4 Fast从~80%下降到~10%）。

Conclusion: 研究揭示了长上下文智能体操作存在的潜在安全问题，并提出了当前评估LLM智能体在长多步任务中安全性的指标和范式的局限性。智能体在能力和安全性能上与先前LLM评估存在显著差异。

Abstract: Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window. New LLMs enable longer context windows and support tool calling capabilities. Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives. Our work addresses this gap. We find that LLM agents could be sensitive to length, type, and placement of the context, exhibiting unexpected and inconsistent shifts in task performance and in refusals to execute harmful requests. Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\% for both benign and harmful tasks. Refusal rates shift unpredictably: GPT-4.1-nano increases from $\sim$5\% to $\sim$40\% while Grok 4 Fast decreases from $\sim$80\% to $\sim$10\% at 200K tokens. Our work shows potential safety issues with agents operating on longer context and opens additional questions on the current metrics and paradigm for evaluating LLM agent safety on long multi-step tasks. In particular, our results on LLM agents reveal a notable divergence in both capability and safety performance compared to prior evaluations of LLMs on similar criteria.

</details>


### [106] [TabGRU: An Enhanced Design for Urban Rainfall Intensity Estimation Using Commercial Microwave Links](https://arxiv.org/abs/2512.02465)
*Xingwang Li,Mengyun Chen,Jiamou Liu,Sijie Wang,Shuanggen Jin,Jafet C. M. Andersson,Jonas Olsson,Remco,van de Beek,Hai Victor Habi,Congzheng Han*

Main category: cs.LG

TL;DR: 提出名为TabGRU的混合深度学习架构，结合Transformer和双向门控循环单元，用于商业微波链路降雨监测，在瑞典哥德堡数据集上表现优于传统物理模型和深度学习基线。


<details>
  <summary>Details</summary>
Motivation: 面对全球城市化和极端天气事件增加，高分辨率城市降雨监测对建设韧性智慧城市至关重要。传统基于物理模型的商业微波链路降雨反演方法难以处理现实世界中的信号噪声和非线性衰减等复杂问题。

Method: 提出TabGRU混合深度学习架构，结合Transformer和双向门控循环单元，捕捉CML信号数据中的长期依赖和局部序列特征。采用可学习位置嵌入和注意力池化机制增强动态特征提取和泛化能力。

Result: 在瑞典哥德堡公开基准数据集上验证，使用两个雨量站12个子链路，覆盖约10次降雨事件。TabGRU在Torp站点R²=0.91，Barl站点R²=0.96，优于深度学习基线，相比物理模型能有效缓解峰值降雨事件中的高估问题。

Conclusion: TabGRU模型能有效克服传统方法的局限性，在测试条件下为基于CML的城市降雨监测提供了稳健准确的解决方案。

Abstract: In the face of accelerating global urbanization and the increasing frequency of extreme weather events, highresolution urban rainfall monitoring is crucial for building resilient smart cities. Commercial Microwave Links (CMLs) are an emerging data source with great potential for this task.While traditional rainfall retrieval from CMLs relies on physicsbased models, these often struggle with real-world complexities like signal noise and nonlinear attenuation. To address these limitations, this paper proposes a novel hybrid deep learning architecture based on the Transformer and a Bidirectional Gated Recurrent Unit (BiGRU), which we name TabGRU. This design synergistically captures both long-term dependencies and local sequential features in the CML signal data. The model is further enhanced by a learnable positional embedding and an attention pooling mechanism to improve its dynamic feature extraction and generalization capabilities. The model was validated on a public benchmark dataset from Gothenburg, Sweden (June-September 2015). The evaluation used 12 sub-links from two rain gauges (Torp and Barl) over a test period (August 22-31) covering approximately 10 distinct rainfall events. The proposed TabGRU model demonstrated consistent advantages, outperforming deep learning baselines and achieving high coefficients of determination (R2) at both the Torp site (0.91) and the Barl site (0.96). Furthermore, compared to the physics-based approach, TabGRU maintained higher accuracy and was particularly effective in mitigating the significant overestimation problem observed in the PL model during peak rainfall events. This evaluation confirms that the TabGRU model can effectively overcome the limitations of traditional methods, providing a robust and accurate solution for CML-based urban rainfall monitoring under the tested conditions.

</details>


### [107] [Dual-Robust Cross-Domain Offline Reinforcement Learning Against Dynamics Shifts](https://arxiv.org/abs/2512.02486)
*Zhongjian Qiao,Rui Yang,Jiafei Lyu,Xiu Li,Zhongxiang Dai,Zhuoran Yang,Siyang Gao,Shuang Qiu*

Main category: cs.LG

TL;DR: 提出DROCO算法，解决跨域离线强化学习中训练时和测试时对动态变化的双重鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 现有跨域离线强化学习主要关注训练时鲁棒性（处理训练数据中的动态变化），但忽略了实际部署时测试时对动态扰动的鲁棒性。当目标域数据有限时，现有方法在动态扰动下表现脆弱。

Method: 提出鲁棒跨域贝尔曼算子(RCB)，增强测试时对动态扰动的鲁棒性，同时保持对分布外动态转移的保守性。引入动态值惩罚和Huber损失技术，形成DROCO算法。

Result: 在各种动态变化场景下的实验结果表明，DROCO优于强基线方法，并展现出对动态扰动增强的鲁棒性。

Conclusion: DROCO算法成功解决了跨域离线强化学习中训练时和测试时的双重鲁棒性问题，在动态扰动下表现出优越性能。

Abstract: Single-domain offline reinforcement learning (RL) often suffers from limited data coverage, while cross-domain offline RL handles this issue by leveraging additional data from other domains with dynamics shifts. However, existing studies primarily focus on train-time robustness (handling dynamics shifts from training data), neglecting the test-time robustness against dynamics perturbations when deployed in practical scenarios. In this paper, we investigate dual (both train-time and test-time) robustness against dynamics shifts in cross-domain offline RL. We first empirically show that the policy trained with cross-domain offline RL exhibits fragility under dynamics perturbations during evaluation, particularly when target domain data is limited. To address this, we introduce a novel robust cross-domain Bellman (RCB) operator, which enhances test-time robustness against dynamics perturbations while staying conservative to the out-of-distribution dynamics transitions, thus guaranteeing the train-time robustness. To further counteract potential value overestimation or underestimation caused by the RCB operator, we introduce two techniques, the dynamic value penalty and the Huber loss, into our framework, resulting in the practical \textbf{D}ual-\textbf{RO}bust \textbf{C}ross-domain \textbf{O}ffline RL (DROCO) algorithm. Extensive empirical results across various dynamics shift scenarios show that DROCO outperforms strong baselines and exhibits enhanced robustness to dynamics perturbations.

</details>


### [108] [Hybrid(Penalized Regression and MLP) Models for Outcome Prediction in HDLSS Health Data](https://arxiv.org/abs/2512.02489)
*Mithra D K*

Main category: cs.LG

TL;DR: 应用机器学习技术于NHANES健康调查数据预测糖尿病状态，比较基线模型与混合方法，混合模型在AUC和平衡准确率上表现更优


<details>
  <summary>Details</summary>
Motivation: 利用NHANES健康调查数据预测糖尿病状态，探索更有效的机器学习方法

Method: 比较逻辑回归、随机森林、XGBoost等基线模型与混合方法（XGBoost特征编码器+轻量级MLP头部）

Result: 混合模型在处理后的NHANES子集上获得了比基线模型更好的AUC和平衡准确率

Conclusion: 混合方法在糖尿病预测任务上表现更优，作者发布了代码和可复现脚本以鼓励复制研究

Abstract: I present an application of established machine learning techniques to NHANES health survey data for predicting diabetes status. I compare baseline models (logistic regression, random forest, XGBoost) with a hybrid approach that uses an XGBoost feature encoder and a lightweight multilayer perceptron (MLP) head. Experiments show the hybrid model attains improved AUC and balanced accuracy compared to baselines on the processed NHANES subset. I release code and reproducible scripts to encourage replication.

</details>


### [109] [A Fully First-Order Layer for Differentiable Optimization](https://arxiv.org/abs/2512.02494)
*Zihao Zhao,Kai-Chia Mo,Shing-Hei Ho,Brandon Amos,Kai Wang*

Main category: cs.LG

TL;DR: 提出一种仅使用一阶信息计算可微优化层梯度的新算法，避免Hessian计算，降低计算和内存开销


<details>
  <summary>Details</summary>
Motivation: 可微优化层需要求解包含Hessian项的线性系统来计算梯度，计算和内存开销大，需要更高效的梯度计算方法

Method: 将可微优化重写为双层优化问题，利用双层方法的最新进展，引入活动集拉格朗日超梯度预言机，避免Hessian评估

Result: 近似超梯度可在$\tilde{\oo}(1)$时间内仅使用一阶信息计算，约束双层优化的总体复杂度为$\tilde{\oo}(δ^{-1}ε^{-3})$，匹配非光滑非凸优化的最佳已知速率

Conclusion: 提出了一种高效的可微优化层梯度计算方法，显著降低计算成本，并发布了开源Python库FFOLayer

Abstract: Differentiable optimization layers enable learning systems to make decisions by solving embedded optimization problems. However, computing gradients via implicit differentiation requires solving a linear system with Hessian terms, which is both compute- and memory-intensive. To address this challenge, we propose a novel algorithm that computes the gradient using only first-order information. The key insight is to rewrite the differentiable optimization as a bilevel optimization problem and leverage recent advances in bilevel methods. Specifically, we introduce an active-set Lagrangian hypergradient oracle that avoids Hessian evaluations and provides finite-time, non-asymptotic approximation guarantees. We show that an approximate hypergradient can be computed using only first-order information in $\tilde{\oo}(1)$ time, leading to an overall complexity of $\tilde{\oo}(δ^{-1}ε^{-3})$ for constrained bilevel optimization, which matches the best known rate for non-smooth non-convex optimization. Furthermore, we release an open-source Python library that can be easily adapted from existing solvers. Our code is available here: https://github.com/guaguakai/FFOLayer.

</details>


### [110] [Water Quality Estimation Through Machine Learning Multivariate Analysis](https://arxiv.org/abs/2512.02508)
*Marco Cardia,Stefano Chessa,Alessio Micheli,Antonella Giuliana Luminare,Francesca Gambineri*

Main category: cs.LG

TL;DR: 将紫外-可见光谱与机器学习结合，用于农业用水质量评估，并利用SHAP增强模型可解释性


<details>
  <summary>Details</summary>
Motivation: 水质对农业食品行业至关重要，随着该行业数字化进程，自动评估水质变得日益重要。需要快速、准确且可解释的水质评估方法。

Method: 整合紫外-可见光谱技术与机器学习，用于水质评估。特别强调模型可解释性，采用SHAP方法分析不同波长吸光度对预测的贡献。

Result: 该方法展示了快速、准确且可解释地评估关键水质参数的潜力，有助于确保水安全和符合水法规。

Conclusion: 紫外-可见光谱与机器学习结合，加上SHAP可解释性分析，为农业用水质量评估提供了一种有前景的解决方案。

Abstract: The quality of water is key for the quality of agrifood sector. Water is used in agriculture for fertigation, for animal husbandry, and in the agrifood processing industry. In the context of the progressive digitalization of this sector, the automatic assessment of the quality of water is thus becoming an important asset. In this work, we present the integration of Ultraviolet-Visible (UV-Vis) spectroscopy with Machine Learning in the context of water quality assessment aiming at ensuring water safety and the compliance of water regulation. Furthermore, we emphasize the importance of model interpretability by employing SHapley Additive exPlanations (SHAP) to understand the contribution of absorbance at different wavelengths to the predictions. Our approach demonstrates the potential for rapid, accurate, and interpretable assessment of key water quality parameters.

</details>


### [111] [Decentralized Fairness Aware Multi Task Federated Learning for VR Network](https://arxiv.org/abs/2512.02513)
*Krishnendu S. Tharakan,Carlo Fischione*

Main category: cs.LG

TL;DR: 提出基于去中心化多任务公平联邦学习（DMTFL）的VR视频缓存方案，通过在基站个性化缓存用户视场内容，解决无线VR传输的延迟和体验质量问题。


<details>
  <summary>Details</summary>
Motivation: 无线VR体验需要高质量、低延迟的视频传输，但VR设备能力有限，传统联邦学习存在用户偏见问题，无法适应不同用户和基站的统计异质性。

Method: 提出DMTFL算法，在每个基站学习个性化缓存模型，基于用户视场预测进行内容缓存和预取，通过Rademacher复杂度和PAC边界提供理论保证。

Result: 使用真实VR头部追踪数据集进行仿真，DMTFL算法相比基线算法表现出优越性能，能更好地满足VR体验的质量要求。

Conclusion: DMTFL算法通过去中心化多任务学习和个性化模型，有效解决了无线VR传输中的缓存优化问题，提升了用户体验质量。

Abstract: Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.

</details>


### [112] [In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs](https://arxiv.org/abs/2512.02543)
*Vishnu Sarukkai,Asanshay Gupta,James Hong,Michaël Gharbi,Kayvon Fatahalian*

Main category: cs.LG

TL;DR: 提出上下文蒸馏方法，通过检索教师模型演示作为上下文示例，让学生模型模仿教师行为，结合自一致性级联实现低成本LLM智能体推理


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体开发面临高推理成本问题，而微调需要长训练周期和超参数调整，手动提示工程又需要大量试错，需要一种既能降低成本又不增加开发摩擦的方法

Method: 提出上下文蒸馏：在智能体每个步骤中检索相关教师演示作为上下文示例，让学生模型实时模仿教师行为；结合自一致性级联来判断何时信任学生模型，实现自适应策略

Result: 在ALFWorld基准上以2.5倍低成本达到教师级准确率（每集成本从$0.059降至$0.024）；在AppWorld基准上实现2倍成本降低；演示成本在843集后摊销，百万级部署可节省$34,900

Conclusion: 上下文蒸馏方法在保持冻结模型快速实验周期的同时显著降低运营成本，使高级智能体系统在经济上对更广泛的应用可行

Abstract: The world currently has an abundance of ideas for how to use new LLM agents, and developers seek to rapidly prototype and test new agentic designs. However, executing agents at scale using high-capacity LLMs incurs high inference costs. We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error). Most importantly, we introduce $\textit{in-context distillation}$, which adapts the idea of knowledge distillation (training a low cost-student model to mimic a high-cost teacher) to an in-context learning setting. Our approach retrieves relevant teacher demonstrations at each agent step and provides them to the student as in-context examples, enabling the student to imitate teacher behavior on-the-fly. We combine in-context distillation with the established idea of $\textit{self-consistency cascades}$ to know when the trust the student. This adaptive strategy realizes the cost benefits of model specialization while preserving the productivity of working with frozen models. On the multi-step embodied reasoning benchmark ALFWorld, our method matches teacher-level accuracy at $\textbf{2.5$\times$ lower cost}$, reducing per-episode costs from \$0.059 to \$0.024. The upfront demonstration cost amortizes after just 843 episodes, yielding cumulative savings exceeding \$34,900 at deployment scale (1M episodes). On AppWorld, a complex agent benchmark requiring multi-step API workflows, we shift the Pareto frontier by achieving a $\textbf{2$\times$ cost reduction}$ at iso-accuracy. By reducing operational costs while maintaining rapid experimentation cycles with frozen models, our approach makes advanced agentic systems economically viable for a broader range of applications.

</details>


### [113] [Tensor Network Based Feature Learning Model](https://arxiv.org/abs/2512.02547)
*Albert Saiapin,Kim Batselier*

Main category: cs.LG

TL;DR: 提出FL模型，通过可学习的CPD分解表示张量积特征，同时学习特征超参数和模型参数，比标准交叉验证快3-5倍且预测质量相当。


<details>
  <summary>Details</summary>
Motivation: 现有张量积特征方法虽然解决了维度灾难问题，但特征超参数优化仍依赖耗时的交叉验证，需要更高效的超参数学习方法。

Method: 将张量积特征表示为可学习的CPD分解，利用ALS优化方法同时学习特征超参数和模型参数，实现端到端训练。

Result: 在不同维度和规模的真实数据上，FL模型训练速度比标准交叉验证快3-5倍，预测质量相当。

Conclusion: FL模型通过可学习的CPD结构有效解决了特征超参数优化问题，实现了高效的特征学习和模型训练。

Abstract: Many approximations were suggested to circumvent the cubic complexity of kernel-based algorithms, allowing their application to large-scale datasets. One strategy is to consider the primal formulation of the learning problem by mapping the data to a higher-dimensional space using tensor-product structured polynomial and Fourier features. The curse of dimensionality due to these tensor-product features was effectively solved by a tensor network reparameterization of the model parameters. However, another important aspect of model training - identifying optimal feature hyperparameters - has not been addressed and is typically handled using the standard cross-validation approach. In this paper, we introduce the Feature Learning (FL) model, which addresses this issue by representing tensor-product features as a learnable Canonical Polyadic Decomposition (CPD). By leveraging this CPD structure, we efficiently learn the hyperparameters associated with different features alongside the model parameters using an Alternating Least Squares (ALS) optimization method. We prove the effectiveness of the FL model through experiments on real data of various dimensionality and scale. The results show that the FL model can be consistently trained 3-5 times faster than and have the prediction quality on par with a standard cross-validated model.

</details>


### [114] [CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication through Reinforcement Learning](https://arxiv.org/abs/2512.02551)
*Songqiao Su,Xiaofei Sun,Xiaoya Li,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.LG

TL;DR: CUDA-L2使用LLM+RL自动优化半精度矩阵乘法CUDA内核，在1000种配置上超越现有最佳方案，离线模式平均提升11.4-22%，服务器模式提升15.9-28.7%


<details>
  <summary>Details</summary>
Motivation: 即使像HGEMM这样性能关键、高度优化的CUDA内核，仍然存在通过自动化方法进一步优化的空间。传统手动优化难以系统探索大规模配置空间，需要结合LLM和RL实现自动化优化。

Method: 结合大型语言模型（LLMs）和强化学习（RL），以CUDA执行速度为奖励信号，自动优化半精度通用矩阵乘法（HGEMM）CUDA内核。系统在1000种配置上进行自动优化。

Result: 在离线模式下：相比torch.matmul提升22.0%；相比cuBLAS（最优布局）提升19.2%；相比cuBLASLt-heuristic提升16.8%；相比cuBLASLt-AutoTuning提升11.4%。在服务器模式下：提升进一步增加到28.7%、26.0%、22.4%和15.9%。

Conclusion: CUDA-L2证明即使是性能关键、高度优化的内核如HGEMM，也能通过LLM引导的RL自动化在人类难以系统探索的大规模配置空间中获得显著性能提升。

Abstract: In this paper, we propose CUDA-L2, a system that combines large language models (LLMs) and reinforcement learning (RL) to automatically optimize Half-precision General Matrix Multiply (HGEMM) CUDA kernels. Using CUDA execution speed as the RL reward, CUDA-L2 automatically optimizes HGEMM kernels across 1,000 configurations. CUDA-L2 systematically outperforms major matmul baselines to date, from the widely-used {\it torch.matmul} to state-of-the-art Nvidia's closed-source libraries, i.e., {\it cuBLAS}, {\it cuBLASLt}. In offline mode, where kernels are executed consecutively without time intervals, CUDA-L2 yields +22.0\% over {\it torch.matmul} on average; +19.2\% over {\it cuBLAS} using the optimal layout configuration (normal-normal NN and transposed-normal TN); +16.8\% over {\it cuBLASLt-heuristic}, which queries {\it cuBLASLt} library and selects the algorithm based on the heuristic's suggestion; and +11.4\% over the most competitive {\it cuBLASLt-AutoTuning} model, which selects the fastest algorithm from up to 100 candidates from {\it cuBLASLt}'s suggestions. In server mode, where kernels are executed at random intervals simulating real-time inference, the speedups further increase to +28.7\%, +26.0\%, +22.4\%, and +15.9\% for {\it torch.matmul}, {\it cuBLAS}, {\it cuBLASLt-heuristic}, and {\it cuBLASLt-AutoTuning} respectively. CUDA-L2 shows that even the most performance-critical, heavily-optimized kernels like HGEMM can be improved through LLM-guided RL automation by systematically exploring configuration spaces at scales impractical for humans. Project and code can be found at github.com/deepreinforce-ai/CUDA-L2

</details>


### [115] [GoRL: An Algorithm-Agnostic Framework for Online Reinforcement Learning with Generative Policies](https://arxiv.org/abs/2512.02581)
*Chubin Zhang,Zhenglin Wan,Feng Chen,Xingrui Yu,Ivor Tsang,Bo An*

Main category: cs.LG

TL;DR: GoRL框架通过解耦优化与生成，使用可优化的隐变量策略和条件生成解码器，在保持稳定性的同时实现高表达能力，在连续控制任务中显著超越高斯策略和现有生成策略基线。


<details>
  <summary>Details</summary>
Motivation: 强化学习中存在稳定性与表达能力的矛盾：高斯策略易于优化但表达能力有限（单模态），而基于扩散或流匹配的生成策略能建模多模态行为但在在线RL中不稳定（似然难处理、梯度噪声大）。

Method: 提出GoRL框架，核心是解耦优化与生成：优化一个可处理的隐变量策略，同时使用条件生成解码器合成动作。采用双时间尺度更新计划，使隐变量策略稳定学习，解码器逐步提升表达能力，无需可处理的动作似然。

Result: 在多个连续控制任务中，GoRL一致优于高斯策略和最近的生成策略基线。在HopperStand任务上达到归一化回报870+，是最好基线的3倍以上。

Conclusion: 解耦优化与生成为实现既稳定又高表达能力的策略提供了实用路径，解决了强化学习中稳定性与表达能力的长期矛盾。

Abstract: Reinforcement learning (RL) faces a persistent tension: policies that are stable to optimize are often too simple to represent the multimodal action distributions needed for complex control. Gaussian policies provide tractable likelihoods and smooth gradients, but their unimodal form limits expressiveness. Conversely, generative policies based on diffusion or flow matching can model rich multimodal behaviors; however, in online RL, they are frequently unstable due to intractable likelihoods and noisy gradients propagating through deep sampling chains. We address this tension with a key structural principle: decoupling optimization from generation. Building on this insight, we introduce GoRL (Generative Online Reinforcement Learning), a framework that optimizes a tractable latent policy while utilizing a conditional generative decoder to synthesize actions. A two-timescale update schedule enables the latent policy to learn stably while the decoder steadily increases expressiveness, without requiring tractable action likelihoods. Across a range of continuous-control tasks, GoRL consistently outperforms both Gaussian policies and recent generative-policy baselines. Notably, on the HopperStand task, it reaches a normalized return above 870, more than 3 times that of the strongest baseline. These results demonstrate that separating optimization from generation provides a practical path to policies that are both stable and highly expressive.

</details>


### [116] [Modeling and Inverse Identification of Interfacial Heat Conduction in Finite Layer and Semi-Infinite Substrate Systems via a Physics-Guided Neural Framework](https://arxiv.org/abs/2512.02618)
*Wenhao Sha,Tienchong Chang*

Main category: cs.LG

TL;DR: HeatTransFormer：用于界面主导扩散问题的物理引导Transformer架构，解决芯片-基板热传导中的陡峭梯度问题，支持正反演建模


<details>
  <summary>Details</summary>
Motivation: 半导体器件中芯片与基板的热传导存在显著的物性差异，导致界面处产生陡峭的温度梯度。传统数值方法需要过度离散化，而PINNs在界面附近常出现收敛不稳定和物理一致性丧失的问题。

Method: 提出HeatTransFormer物理引导Transformer架构，包含：1）物理信息时空采样；2）模拟解析扩散解的拉普拉斯基激活函数；3）支持双向时空耦合的无掩码注意力机制。

Result: HeatTransFormer能在界面处产生连贯的温度场，解决陡峭梯度问题，保持物理一致性，在PINNs通常失效的区域保持稳定。结合物理约束反演策略，仅使用外部测量即可可靠识别三个未知热物性参数。

Conclusion: 物理引导的Transformer架构为界面主导的热系统正反演建模提供了统一框架，解决了传统方法和PINNs在界面热传导问题中的局限性。

Abstract: Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems.

</details>


### [117] [Adapting Tensor Kernel Machines to Enable Efficient Transfer Learning for Seizure Detection](https://arxiv.org/abs/2512.02626)
*Seline J. S. de Rooij,Borbála Hunyadi*

Main category: cs.LG

TL;DR: 提出自适应张量核机（Adapt-TKM）用于迁移学习，通过低秩张量网络在原始域学习紧凑非线性模型，显著减少参数数量并提高推理速度，特别适用于资源受限的可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 迁移学习旨在通过从相关源问题学习来优化目标任务的性能。当前方法如自适应SVM虽然有效，但参数较多，不适合资源受限的设备。需要一种更高效的迁移学习方法。

Method: 提出自适应张量核机（Adapt-TKM），受自适应SVM启发，通过正则化将源任务知识迁移到"适应"模型中。利用低秩张量网络在原始域学习紧凑非线性模型，实现高效适应而不增加额外参数。

Result: 在耳后EEG癫痫检测任务中，使用少量患者特定数据个性化患者独立模型，患者适应模型（使用Adapt-TKM）比患者独立和完全患者特定模型表现更好。相比自适应SVM，参数减少约100倍，推理速度相应更快。

Conclusion: Adapt-TKM提供了一种高效的迁移学习方法，特别适用于资源受限的可穿戴设备。通过低秩张量网络实现紧凑模型表示，在保持性能的同时大幅减少参数和计算需求。

Abstract: Transfer learning aims to optimize performance in a target task by learning from a related source problem. In this work, we propose an efficient transfer learning method using a tensor kernel machine. Our method takes inspiration from the adaptive SVM and hence transfers 'knowledge' from the source to the 'adapted' model via regularization. The main advantage of using tensor kernel machines is that they leverage low-rank tensor networks to learn a compact non-linear model in the primal domain. This allows for a more efficient adaptation without adding more parameters to the model. To demonstrate the effectiveness of our approach, we apply the adaptive tensor kernel machine (Adapt-TKM) to seizure detection on behind-the-ear EEG. By personalizing patient-independent models with a small amount of patient-specific data, the patient-adapted model (which utilizes the Adapt-TKM), achieves better performance compared to the patient-independent and fully patient-specific models. Notably, it is able to do so while requiring around 100 times fewer parameters than the adaptive SVM model, leading to a correspondingly faster inference speed. This makes the Adapt-TKM especially useful for resource-constrained wearable devices.

</details>


### [118] [SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization](https://arxiv.org/abs/2512.02631)
*Zhengcheng Wang,Zichuan Lin,Yijun Yang,Haobo Fu,Deheng Ye*

Main category: cs.LG

TL;DR: 提出SeeNav-Agent框架，通过双视角视觉提示减少感知幻觉，并设计SRGPO强化微调方法提升导航性能，在EmbodiedBench上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有基于大视觉语言模型的视觉语言导航代理存在感知错误、推理错误和规划错误，严重影响了导航性能，需要解决这些限制。

Method: 1. 引入双视角视觉提示技术减少视觉模块的感知幻觉；2. 设计SRGPO（步奖励分组策略优化）强化微调方法，定义可验证过程奖励并进行步级优势估计。

Result: 在EmbodiedBench导航基准上：GPT-4.1通过零样本VP模块达到86.7%导航成功率，比当前最佳LVLM提升约20个百分点；Qwen2.5-VL-3B模型通过SRGPO后训练达到72.3%成功率，比现有最佳LVLM提升5.6个百分点；SRGPO相比GRPO和GiGPO在训练稳定性、收敛效率和泛化能力上有显著改进。

Conclusion: SeeNav-Agent框架通过双视角视觉提示和SRGPO强化微调有效解决了VLN代理的感知、推理和规划问题，显著提升了导航性能，为视觉语言导航领域提供了新的解决方案。

Abstract: Existing Vision-Language Navigation (VLN) agents based on Large Vision-Language Models (LVLMs) often suffer from perception errors, reasoning errors, and planning errors, which significantly hinder their navigation performance. To address these limitations, a novel VLN agent framework, named SeeNav-Agent, is proposed in this work. First, to reduce perception hallucinations of the visual module of the VLN agent, a dual-view Visual Prompt (VP) technique is introduced in the input space, which can also improve the agent's understanding of current spatial states. Subsequently, a novel step-level Reinforcement Fine-Tuning (RFT) method, Step Reward Group Policy Optimization (SRGPO), is designed for the post-training of VLN agents. In SRGPO, we first define verifiable process rewards for the navigation task, and then perform efficient step-level advantage estimation by randomly grouping different navigation steps. SRGPO provides dense reward signals for the reinforcement learning process of the VLN agent and enhances its planning capability. Experimental results on the EmbodiedBench Navigation benchmark indicate that by introducing the zero-shot VP module, the GPT-4.1 achieves a navigation success rate of 86.7%, surpassing the current best LVLM by approximately 20 percentage points (pp). Through post-training based on SRGPO, the Qwen2.5-VL-3B model reaches a navigation success rate of 72.3%, outperforming the best existing LVLM model by 5.6 pp. Moreover, compared to RFT algorithms such as GRPO and GiGPO, the proposed SRGPO demonstrates significant improvements in training stability, convergence efficiency, and generalization capability.

</details>


### [119] [Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models](https://arxiv.org/abs/2512.02636)
*Xinyue Ai,Yutong He,Albert Gu,Ruslan Salakhutdinov,J Zico Kolter,Nicholas Matthew Boffi,Max Simchowitz*

Main category: cs.LG

TL;DR: F2D2框架通过联合蒸馏采样轨迹和累积散度，将基于流的生成模型的采样和似然评估所需的神经函数评估次数减少两个数量级，同时保持高样本质量和准确的似然计算。


<details>
  <summary>Details</summary>
Motivation: 当前最好的生成模型（如扩散和基于流的模型）需要数百到数千次神经函数评估来计算单个似然值，这构成了计算瓶颈。虽然现有蒸馏方法可以加速采样，但要么完全放弃似然计算，要么仍然需要昂贵的全轨迹积分。

Method: 提出快速流联合蒸馏（F2D2）框架，利用连续归一化流中采样和似然的耦合ODE共享底层速度场的特点，通过单个模型联合蒸馏采样轨迹和累积散度。该方法模块化，与现有基于流的少步采样模型兼容，仅需添加散度预测头。

Result: F2D2能够在少步评估下实现准确的似然计算，同时保持高样本质量。应用该方法提出的轻量级自引导方法使2步MeanFlow模型仅需一次额外反向NFE就能超越1024步教师模型。

Conclusion: F2D2解决了基于流生成模型中长期存在的计算瓶颈问题，实现了采样和似然评估效率的显著提升，为生成模型的实际应用提供了重要改进。

Abstract: Log-likelihood evaluation enables important capabilities in generative models, including model comparison, certain fine-tuning objectives, and many downstream applications. Yet paradoxically, some of today's best generative models -- diffusion and flow-based models -- still require hundreds to thousands of neural function evaluations (NFEs) to compute a single likelihood. While recent distillation methods have successfully accelerated sampling to just a few steps, they achieve this at the cost of likelihood tractability: existing approaches either abandon likelihood computation entirely or still require expensive integration over full trajectories. We present fast flow joint distillation (F2D2), a framework that simultaneously reduces the number of NFEs required for both sampling and likelihood evaluation by two orders of magnitude. Our key insight is that in continuous normalizing flows, the coupled ODEs for sampling and likelihood are computed from a shared underlying velocity field, allowing us to jointly distill both the sampling trajectory and cumulative divergence using a single model. F2D2 is modular, compatible with existing flow-based few-step sampling models, and requires only an additional divergence prediction head. Experiments demonstrate F2D2's capability of achieving accurate log-likelihood with few-step evaluations while maintaining high sample quality, solving a long-standing computational bottleneck in flow-based generative models. As an application of our approach, we propose a lightweight self-guidance method that enables a 2-step MeanFlow model to outperform a 1024 step teacher model with only a single additional backward NFE.

</details>


### [120] [Adaptive Weighted LSSVM for Multi-View Classification](https://arxiv.org/abs/2512.02653)
*Farnaz Faramarzi Lighvan,Mehrdad Asadi,Lynn Houthuys*

Main category: cs.LG

TL;DR: AW-LSSVM是一种自适应加权LS-SVM多视图学习方法，通过迭代全局耦合促进互补学习，让每个视图专注于其他视图的困难样本，在保持原始特征隔离的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于核的多视图学习方法通常使用融合技术而不强制视图间的显式协作类型，或采用共正则化限制全局协作，需要一种能促进视图间互补学习的方法。

Method: 提出自适应加权LS-SVM（AW-LSSVM），通过迭代全局耦合机制，让每个视图在每次迭代中专注于其他视图在前一轮中的困难样本，实现视图间的互补学习。

Result: 实验表明AW-LSSVM在大多数数据集上优于现有的基于核的多视图学习方法，同时保持原始特征隔离，适用于隐私保护场景。

Conclusion: AW-LSSVM通过迭代全局耦合有效促进多视图间的互补学习，在提升性能的同时保持特征隔离，为多视图学习提供了新的有效方法。

Abstract: Multi-view learning integrates diverse representations of the same instances to improve performance. Most existing kernel-based multi-view learning methods use fusion techniques without enforcing an explicit collaboration type across views or co-regularization which limits global collaboration. We propose AW-LSSVM, an adaptive weighted LS-SVM that promotes complementary learning by an iterative global coupling to make each view focus on hard samples of others from previous iterations. Experiments demonstrate that AW-LSSVM outperforms existing kernel-based multi-view methods on most datasets, while keeping raw features isolated, making it also suitable for privacy-preserving scenarios.

</details>


### [121] [Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.02657)
*Naveen George,Naoki Murata,Yuhta Takida,Konda Reddy Mopuri,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 提出生成蒸馏持续遗忘框架，解决视觉生成模型在序列删除请求下的稳定遗忘问题，避免传统方法在持续遗忘场景中的性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 视觉生成模型训练数据与隐私法规（如GDPR的"被遗忘权"）存在冲突，需要机器遗忘技术。现有遗忘方法无法应对现实世界中序列到达的删除请求（持续遗忘），直接应用会导致稳定性危机、性能退化等问题。

Method: 提出生成蒸馏持续遗忘框架，将每个遗忘步骤重构为多目标师生蒸馏过程。借鉴持续学习原理，通过教师-学生蒸馏机制在序列删除请求下实现稳定、精准的遗忘。

Result: 在10步序列基准测试中，该方法能更准确地遗忘目标概念，同时对保留概念性能和整体图像质量影响最小，显著优于基线方法。

Conclusion: 该框架为大规模生成模型的负责任部署和维护提供了可行路径，使产业界能够以实用有效的方式满足持续的数据删除请求。

Abstract: The recent rapid growth of visual generative models trained on vast web-scale datasets has created significant tension with data privacy regulations and copyright laws, such as GDPR's ``Right to be Forgotten.'' This necessitates machine unlearning (MU) to remove specific concepts without the prohibitive cost of retraining. However, existing MU techniques are fundamentally ill-equipped for real-world scenarios where deletion requests arrive sequentially, a setting known as continual unlearning (CUL). Naively applying one-shot methods in a continual setting triggers a stability crisis, leading to a cascade of degradation characterized by retention collapse, compounding collateral damage to related concepts, and a sharp decline in generative quality. To address this critical challenge, we introduce a novel generative distillation based continual unlearning framework that ensures targeted and stable unlearning under sequences of deletion requests. By reframing each unlearning step as a multi-objective, teacher-student distillation process, the framework leverages principles from continual learning to maintain model integrity. Experiments on a 10-step sequential benchmark demonstrate that our method unlearns forget concepts with better fidelity and achieves this without significant interference to the performance on retain concepts or the overall image quality, substantially outperforming baselines. This framework provides a viable pathway for the responsible deployment and maintenance of large-scale generative models, enabling industries to comply with ongoing data removal requests in a practical and effective manner.

</details>


### [122] [Graph VQ-Transformer (GVT): Fast and Accurate Molecular Generation via High-Fidelity Discrete Latents](https://arxiv.org/abs/2512.02667)
*Haozhuo Zheng,Cheng Wang,Yang Liu*

Main category: cs.LG

TL;DR: GVT是一个两阶段分子生成框架，通过图VQ-VAE将分子图压缩为离散潜在序列，再用自回归Transformer生成，实现了高效准确的分子生成，性能超越扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型计算量大，自回归模型存在误差传播问题，需要一种既能保持高准确性又高效的分子生成方法。

Method: 提出Graph VQ-Transformer两阶段框架：1) 图VQ-VAE将分子图压缩为高保真离散潜在序列，结合图Transformer、RCM节点排序和RoPE位置编码；2) 在离散潜在序列上训练自回归Transformer进行序列建模。

Result: 在ZINC250k、MOSES、GuacaMol等基准测试中达到SOTA或极具竞争力的性能，在FCD和KL散度等关键分布相似性指标上显著优于主流扩散模型。

Conclusion: GVT不仅为扩散模型提供了有吸引力的替代方案，还为离散潜在空间分子生成建立了新的强基线，为未来与大型语言模型的协同研究铺平了道路。

Abstract: The de novo generation of molecules with desirable properties is a critical challenge, where diffusion models are computationally intensive and autoregressive models struggle with error propagation. In this work, we introduce the Graph VQ-Transformer (GVT), a two-stage generative framework that achieves both high accuracy and efficiency. The core of our approach is a novel Graph Vector Quantized Variational Autoencoder (VQ-VAE) that compresses molecular graphs into high-fidelity discrete latent sequences. By synergistically combining a Graph Transformer with canonical Reverse Cuthill-McKee (RCM) node ordering and Rotary Positional Embeddings (RoPE), our VQ-VAE achieves near-perfect reconstruction rates. An autoregressive Transformer is then trained on these discrete latents, effectively converting graph generation into a well-structured sequence modeling problem. Crucially, this mapping of complex graphs to high-fidelity discrete sequences bridges molecular design with the powerful paradigm of large-scale sequence modeling, unlocking potential synergies with Large Language Models (LLMs). Extensive experiments show that GVT achieves state-of-the-art or highly competitive performance across major benchmarks like ZINC250k, MOSES, and GuacaMol, and notably outperforms leading diffusion models on key distribution similarity metrics such as FCD and KL Divergence. With its superior performance, efficiency, and architectural novelty, GVT not only presents a compelling alternative to diffusion models but also establishes a strong new baseline for the field, paving the way for future research in discrete latent-space molecular generation.

</details>


### [123] [Conformal Correction for Efficiency May be at Odds with Entropy](https://arxiv.org/abs/2512.02704)
*Senrong Xu,Tianyu Wang,Zenan Li,Yuan Yao,Taolue Chen,Feng Xu,Xiaoxing Ma*

Main category: cs.LG

TL;DR: 提出一种熵约束的共形校正方法，在共形预测效率和模型预测熵之间寻找更好的帕累托最优


<details>
  <summary>Details</summary>
Motivation: 共形预测能提供统计上严谨的不确定性集合，但现有方法在效率方面仍有改进空间。研究发现共形预测效率与模型预测熵之间存在权衡关系，需要探索更好的平衡点

Method: 提出熵约束的共形校正方法，通过引入熵约束来优化共形感知的低效损失函数，在给定熵阈值下寻找效率和熵之间的帕累托最优

Result: 在计算机视觉和图数据集上的实验表明，该方法能显著提高最先进共形预测方法的效率，在给定熵阈值下最高提升34.4%

Conclusion: 熵约束共形校正方法能有效平衡共形预测效率和模型预测熵，为不确定性量化提供了更优的解决方案

Abstract: Conformal prediction (CP) provides a comprehensive framework to produce statistically rigorous uncertainty sets for black-box machine learning models. To further improve the efficiency of CP, conformal correction is proposed to fine-tune or wrap the base model with an extra module using a conformal-aware inefficiency loss. In this work, we empirically and theoretically identify a trade-off between the CP efficiency and the entropy of model prediction. We then propose an entropy-constrained conformal correction method, exploring a better Pareto optimum between efficiency and entropy. Extensive experimental results on both computer vision and graph datasets demonstrate the efficacy of the proposed method. For instance, it can significantly improve the efficiency of state-of-the-art CP methods by up to 34.4%, given an entropy threshold.

</details>


### [124] [FGC-Comp: Adaptive Neighbor-Grouped Attribute Completion for Graph-based Anomaly Detection](https://arxiv.org/abs/2512.02705)
*Junpeng Wu,Pinheng Zong*

Main category: cs.LG

TL;DR: FGC-Comp是一个轻量级、分类器无关的图属性补全模块，用于增强缺失或对抗性模糊属性下的邻域聚合稳定性


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测模型大多忽视节点属性缺失和对抗性模糊问题，这会破坏邻域聚合的稳定性和预测可靠性

Method: 将每个节点的邻居分为三个基于标签的组，对标记组应用组特定变换，使用节点条件门处理未知组，通过残差连接融合消息，并用二元分类目标进行端到端训练

Result: 在两个真实世界欺诈数据集上的实验验证了该方法的有效性，且计算开销可忽略不计

Conclusion: FGC-Comp是一个部署友好的属性补全模块，能够在不完整属性下提高邻域聚合稳定性和预测可靠性

Abstract: Graph-based Anomaly Detection models have gained widespread adoption in recent years, identifying suspicious nodes by aggregating neighborhood information. However, most existing studies overlook the pervasive issues of missing and adversarially obscured node attributes, which can undermine aggregation stability and prediction reliability. To mitigate this, we propose FGC-Comp, a lightweight, classifier-agnostic, and deployment-friendly attribute completion module-designed to enhance neighborhood aggregation under incomplete attributes. We partition each node's neighbors into three label-based groups, apply group-specific transforms to the labeled groups while a node-conditioned gate handles unknowns, fuse messages via residual connections, and train end-to-end with a binary classification objective to improve aggregation stability and prediction reliability under missing attributes. Experiments on two real-world fraud datasets validate the effectiveness of the approach with negligible computational overhead.

</details>


### [125] [Credal Graph Neural Networks](https://arxiv.org/abs/2512.02722)
*Matteo Tolloso,Davide Bacciu*

Main category: cs.LG

TL;DR: 提出首个信度图神经网络（CGNN），将信度学习扩展到图领域，通过训练GNN输出信度集形式的集合值预测，用于图上的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法主要依赖贝叶斯推断或集成学习，需要开发专门针对图神经网络的不确定性量化方法，特别是在图消息传递的独特特性下。

Method: 开发了信度图神经网络（CGNN），通过利用层间信息传播的不同方面，训练GNN输出信度集形式的集合值预测，提出了一种互补的信度学习方法。

Result: 在异配图上的分布偏移条件下，CGNN能够提供更可靠的认识不确定性表示，并在节点分类任务中实现了最先进的性能。

Conclusion: CGNN是首个将信度学习扩展到图领域的方法，分析揭示了图同配性假设在塑造不确定性估计有效性中的关键作用，为图神经网络提供了更可靠的不确定性量化。

Abstract: Uncertainty quantification is essential for deploying reliable Graph Neural Networks (GNNs), where existing approaches primarily rely on Bayesian inference or ensembles. In this paper, we introduce the first credal graph neural networks (CGNNs), which extend credal learning to the graph domain by training GNNs to output set-valued predictions in the form of credal sets. To account for the distinctive nature of message passing in GNNs, we develop a complementary approach to credal learning that leverages different aspects of layer-wise information propagation. We assess our approach on uncertainty quantification in node classification under out-of-distribution conditions. Our analysis highlights the critical role of the graph homophily assumption in shaping the effectiveness of uncertainty estimates. Extensive experiments demonstrate that CGNNs deliver more reliable representations of epistemic uncertainty and achieve state-of-the-art performance under distributional shift on heterophilic graphs.

</details>


### [126] [Adversarial Jamming for Autoencoder Distribution Matching](https://arxiv.org/abs/2512.02740)
*Waleed El-Geresy,Deniz Gündüz*

Main category: cs.LG

TL;DR: 提出一种利用对抗性无线干扰来正则化自编码器潜在空间的方法，使其匹配对角高斯分布


<details>
  <summary>Details</summary>
Motivation: 现有理论表明，在对抗性信道中，编码器、解码器和干扰器之间的极小极大博弈的鞍点由干扰器输出的对角高斯噪声组成。受此启发，作者希望利用干扰作为辅助目标来鼓励聚合潜在后验匹配对角高斯分布

Method: 提出一种新颖的分布匹配方法：将对抗性无线干扰作为正则化手段，通过编码器、解码器和对抗性干扰器之间的博弈，使潜在空间匹配对角高斯分布。该方法可推广到其他潜在分布

Result: 该方法实现了与标准变分自编码器和Wasserstein自编码器相当的分布匹配性能

Conclusion: 对抗性干扰可作为有效的正则化工具来匹配潜在空间分布，为分布匹配提供了新思路，并可扩展到其他分布类型

Abstract: We propose the use of adversarial wireless jamming to regularise the latent space of an autoencoder to match a diagonal Gaussian distribution. We consider the minimisation of a mean squared error distortion, where a jammer attempts to disrupt the recovery of a Gaussian source encoded and transmitted over the adversarial channel. A straightforward consequence of existing theoretical results is the fact that the saddle point of a minimax game - involving such an encoder, its corresponding decoder, and an adversarial jammer - consists of diagonal Gaussian noise output by the jammer. We use this result as inspiration for a novel approach to distribution matching in the latent space, utilising jamming as an auxiliary objective to encourage the aggregated latent posterior to match a diagonal Gaussian distribution. Using this new technique, we achieve distribution matching comparable to standard variational autoencoders and to Wasserstein autoencoders. This approach can also be generalised to other latent distributions.

</details>


### [127] [FiMMIA: scaling semantic perturbation-based membership inference across modalities](https://arxiv.org/abs/2512.02786)
*Anton Emelyanov,Sergei Kudriashov,Alena Fenogenova*

Main category: cs.LG

TL;DR: 本文提出了FiMMIA框架，用于检测多模态大语言模型中的成员推理攻击，通过扰动输入分析模型行为来识别训练数据泄露。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推理攻击方法在单模态大语言模型上表现良好，但在多模态大语言模型上效果不佳，因为多模态组件适配和跨模态分布偏移带来了不稳定性。

Method: 1) 识别现有数据集中的分布偏移；2) 发布扩展基线管道检测这些偏移；3) 将基于扰动的成员推理方法推广到多模态模型；4) 提出FiMMIA框架，训练神经网络分析目标模型在扰动输入上的行为，捕捉成员与非成员之间的分布差异。

Result: 在各种微调的多模态模型上进行全面评估，证明了基于扰动的成员推理攻击在多模态领域的有效性。

Conclusion: FiMMIA框架能够有效检测多模态大语言模型中的成员推理攻击，解决了多模态环境下的数据泄露检测问题，为多模态模型安全提供了重要工具。

Abstract: Membership Inference Attacks (MIAs) aim to determine whether a specific data point was included in the training set of a target model. Although there are have been numerous methods developed for detecting data contamination in large language models (LLMs), their performance on multimodal LLMs (MLLMs) falls short due to the instabilities introduced through multimodal component adaptation and possible distribution shifts across multiple inputs. In this work, we investigate multimodal membership inference and address two issues: first, by identifying distribution shifts in the existing datasets, and second, by releasing an extended baseline pipeline to detect them. We also generalize the perturbation-based membership inference methods to MLLMs and release \textbf{FiMMIA} -- a modular \textbf{F}ramework for \textbf{M}ultimodal \textbf{MIA}.\footnote{The source code and framework have been made publicly available under the MIT license via \href{https://github.com/ai-forever/data_leakage_detect}{link}.The video demonstration is available on \href{https://youtu.be/a9L4-H80aSg}{YouTube}.} Our approach trains a neural network to analyze the target model's behavior on perturbed inputs, capturing distributional differences between members and non-members. Comprehensive evaluations on various fine-tuned multimodal models demonstrate the effectiveness of our perturbation-based membership inference attacks in multimodal domains.

</details>


### [128] [From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity](https://arxiv.org/abs/2512.02826)
*Haoming Liu,Jinnuo Liu,Yanhao Li,Liuyang Bai,Yunkai Ji,Yuanhe Guo,Shenji Wan,Hongyi Wen*

Main category: cs.LG

TL;DR: 该论文分析了流匹配扩散模型的记忆化-泛化行为，揭示了其训练目标具有两阶段特性：早期导航阶段泛化数据模式形成全局布局，后期精炼阶段记忆细粒度细节。


<details>
  <summary>Details</summary>
Motivation: 流匹配扩散模型已成为图像和视频生成的主流范式，但其记忆化-泛化行为仍未被充分理解。研究者希望深入分析流匹配目标的边际速度场，以揭示模型的训练动态和内在机制。

Method: 重新审视流匹配目标，研究其边际速度场，该场允许闭式表达，从而能够精确计算oracle流匹配目标。通过分析这个oracle速度场，揭示模型训练的两阶段特性。

Result: 分析表明流匹配扩散模型本质上形成两阶段训练目标：早期阶段由数据模式混合引导，后期阶段由最近数据样本主导。早期导航阶段泛化数据模式形成全局布局，后期精炼阶段记忆细粒度细节。

Conclusion: 该研究深化了对扩散模型训练动态的理解，为解释时间步偏移调度、无分类器引导区间和潜在空间设计等实用技术的有效性提供了理论依据，并为未来架构和算法改进提供了指导原则。

Abstract: Flow-based diffusion models have emerged as a leading paradigm for training generative models across images and videos. However, their memorization-generalization behavior remains poorly understood. In this work, we revisit the flow matching (FM) objective and study its marginal velocity field, which admits a closed-form expression, allowing exact computation of the oracle FM target. Analyzing this oracle velocity field reveals that flow-based diffusion models inherently formulate a two-stage training target: an early stage guided by a mixture of data modes, and a later stage dominated by the nearest data sample. The two-stage objective leads to distinct learning behaviors: the early navigation stage generalizes across data modes to form global layouts, whereas the later refinement stage increasingly memorizes fine-grained details. Leveraging these insights, we explain the effectiveness of practical techniques such as timestep-shifted schedules, classifier-free guidance intervals, and latent space design choices. Our study deepens the understanding of diffusion model training dynamics and offers principles for guiding future architectural and algorithmic improvements.

</details>


### [129] [A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models](https://arxiv.org/abs/2512.02833)
*Ihab Ahmed,Denis Krompaß,Cheng Feng,Volker Tresp*

Main category: cs.LG

TL;DR: 本文系统评估了时间序列基础模型（TSFMs）的输入归一化方法，发现REVIN方法在零样本预测中表现最优，相比未归一化基线降低89% MASE，比其他归一化方法降低44%，同时保持最佳域内精度。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在不同领域和通道间存在显著的尺度变化和非平稳性，这些问题会严重影响TSFMs的性能。尽管在数据集特定的时间序列模型中归一化方法已有研究，但在需要泛化能力的TSFMs中却被忽视。

Method: 通过系统评估四种架构不同的TSFMs，比较多种输入归一化方法，重点关注REVIN方法的效果，并分析其在不同模型类型（概率预测、点预测、LLM基础模型）和训练目标下的表现。

Result: REVIN是最有效的归一化方法，在零样本预测中将MASE降低了89%（相比未归一化基线）和44%（相比其他归一化方法），同时达到最佳域内精度（0.84 MASE），无需任何数据集级预处理，实现了最高的精度-效率权衡。

Conclusion: REVIN是TSFMs中最有效的输入归一化方法，但其效果利用取决于架构设计选择和优化目标，特别是训练损失尺度敏感性和模型类型。这为TSFMs的归一化策略提供了重要指导。

Abstract: We investigate input normalization methods for Time-Series Foundation Models (TSFMs). While normalization is well-studied in dataset-specific time-series models, it remains overlooked in TSFMs where generalization is critical. Time-series data, unlike text or images, exhibits significant scale variation across domains and channels, coupled with non-stationarity, can undermine TSFM performance regardless of architectural complexity. Through systematic evaluation across four architecturally diverse TSFMs, we empirically establish REVIN as the most efficient approach, reducing zero-shot MASE by 89\% relative to an un-normalized baseline and by 44\% versus other normalization methods, while matching the best in-domain accuracy (0.84 MASE) without any dataset-level preprocessing -- yielding the highest accuracy-efficiency trade-off. Yet its effect utilization depends on architectural design choices and optimization objective, particularly with respect to training loss scale sensitivity and model type (probabilistic, point-forecast, or LLM-based models).

</details>


### [130] [GraphMatch: Fusing Language and Graph Representations in a Dynamic Two-Sided Work Marketplace](https://arxiv.org/abs/2512.02849)
*Mikołaj Sacha,Hammad Jafri,Mattie Terzolo,Ayan Sinha,Andrew Rabinovich*

Main category: cs.LG

TL;DR: GraphMatch：融合预训练语言模型与图神经网络的大规模推荐框架，用于文本丰富的动态双边市场匹配


<details>
  <summary>Details</summary>
Motivation: 文本丰富的动态双边市场（如劳动力市场）面临内容演化和交互图变化的挑战，现有独立模型方法难以同时捕捉文本语义和图结构的时间敏感性

Method: 结合预训练文本编码器和图神经网络，采用对抗性负采样和时点子图训练，学习同时捕捉演化文本细粒度语义和时间敏感图结构的表示

Result: 在Upwork劳动力市场大规模交互数据上的实验表明，GraphMatch在匹配任务上优于纯语言和纯图基线，同时保持运行时高效性

Conclusion: 统一语言和图表示是解决文本丰富动态双边推荐的有效方案，弥合了强大预训练语言模型与大规模图在实际应用中的差距

Abstract: Recommending matches in a text-rich, dynamic two-sided marketplace presents unique challenges due to evolving content and interaction graphs. We introduce GraphMatch, a new large-scale recommendation framework that fuses pre-trained language models with graph neural networks to overcome these challenges. Unlike prior approaches centered on standalone models, GraphMatch is a comprehensive recipe built on powerful text encoders and GNNs working in tandem. It employs adversarial negative sampling alongside point-in-time subgraph training to learn representations that capture both the fine-grained semantics of evolving text and the time-sensitive structure of the graph. We evaluated extensively on interaction data from Upwork, a leading labor marketplace, at large scale, and discuss our approach towards low-latency inference suitable for real-time use. In our experiments, GraphMatch outperforms language-only and graph-only baselines on matching tasks while being efficient at runtime. These results demonstrate that unifying language and graph representations yields a highly effective solution to text-rich, dynamic two-sided recommendations, bridging the gap between powerful pretrained LMs and large-scale graphs in practice.

</details>


### [131] [Adaptive Decentralized Federated Learning for Robust Optimization](https://arxiv.org/abs/2512.02852)
*Shuyuan Wu,Feifei Wang,Yuan Gao,Hansheng Wang*

Main category: cs.LG

TL;DR: 提出自适应去中心化联邦学习(aDFL)方法，通过自适应调整客户端学习率来缓解异常客户端对全局模型的负面影响，无需先验知识或对邻居节点的严格假设。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习中，异常客户端（由噪声或中毒数据引起）会显著干扰学习过程并降低模型鲁棒性。现有方法通常需要足够多的正常邻居客户端或可靠客户端的先验知识，这限制了DFL的实际应用性。

Method: 提出自适应DFL(aDFL)方法，核心思想是自适应调整客户端的学习率：对可疑客户端分配较小的学习率，对正常客户端分配较大的学习率，以完全自适应的方式减轻异常客户端对全局模型的负面影响。

Result: 理论分析无需对邻居节点施加严格条件且不需要先验知识，提供了严格的收敛分析以保证aDFL的oracle性质。大量数值实验证明了aDFL方法的优越性能。

Conclusion: aDFL方法通过自适应学习率调整有效解决了去中心化联邦学习中异常客户端的问题，提高了模型的鲁棒性和实用性，无需依赖先验知识或特定网络条件。

Abstract: In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.

</details>


### [132] [Assessing the performance of correlation-based multi-fidelity neural emulators](https://arxiv.org/abs/2512.02868)
*Cristian J. Villatoro,Gianluca Geraci,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 该研究系统评估了多保真度神经网络模拟器在不同复杂场景下的性能，包括高维振荡函数、不连续性、参数差异和噪声数据等情况，并与单保真度方法进行对比。


<details>
  <summary>Details</summary>
Motivation: 解决高保真度模型计算成本过高导致优化、不确定性量化等任务不可行的问题，以及数据驱动方法需要大量高精度数据的挑战。通过利用廉价低保真度信息结合少量高保真度数据，构建高效的多保真度模拟器。

Method: 开发多保真度神经网络模拟器，集成有限的高保真度数据和丰富的低保真度模型解。研究多种网络架构（MLP、Siren、KAN）、坐标编码机制、低保真度信息处理方式（精确或可学习），并在不同训练数据集规模下进行测试。

Result: 系统评估了多保真度模拟器在低维/高维函数、振荡特性、不连续性、参数差异模型和可能被污染的低保真度源等各种场景下的性能。通过等效单保真度测试量化了多源信息融合带来的性能提升。

Conclusion: 多保真度神经网络模拟器能够有效利用低保真度信息提升预测精度，在计算成本有限的情况下为复杂任务提供可行的解决方案。该方法在不同复杂场景下均表现出性能优势，证明了多源信息融合的价值。

Abstract: Outer loop tasks such as optimization, uncertainty quantification or inference can easily become intractable when the underlying high-fidelity model is computationally expensive. Similarly, data-driven architectures typically require large datasets to perform predictive tasks with sufficient accuracy. A possible approach to mitigate these challenges is the development of multi-fidelity emulators, leveraging potentially biased, inexpensive low-fidelity information while correcting and refining predictions using scarce, accurate high-fidelity data. This study investigates the performance of multi-fidelity neural emulators, neural networks designed to learn the input-to-output mapping by integrating limited high-fidelity data with abundant low-fidelity model solutions. We investigate the performance of such emulators for low and high-dimensional functions, with oscillatory character, in the presence of discontinuities, for collections of models with equal and dissimilar parametrization, and for a possibly large number of potentially corrupted low-fidelity sources. In doing so, we consider a large number of architectural, hyperparameter, and dataset configurations including networks with a different amount of spectral bias (Multi-Layered Perceptron, Siren and Kolmogorov Arnold Network), various mechanisms for coordinate encoding, exact or learnable low-fidelity information, and for varying training dataset size. We further analyze the added value of the multi-fidelity approach by conducting equivalent single-fidelity tests for each case, quantifying the performance gains achieved through fusing multiple sources of information.

</details>


### [133] [OptPO: Optimal Rollout Allocation for Test-time Policy Optimization](https://arxiv.org/abs/2512.02882)
*Youkang Wang,Jian Wang,Rubing Chen,Tianyi Zeng,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: OptPO提出了一种自适应分配推理预算的测试时策略优化框架，通过贝叶斯序列概率比检验动态停止采样，减少计算冗余同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有测试时策略优化方法依赖固定预算的多数投票来估计奖励，导致大量计算冗余，需要更高效的预算分配机制。

Method: 将投票过程建模为贝叶斯序列概率比检验，动态停止采样（当后验置信度超过阈值时），并利用保留的rollout进行策略更新，可与PPO或GRPO等算法无缝集成。

Result: 在多样化推理基准测试中，OptPO相比固定样本基线显著减少了rollout开销，同时保持或提高了准确性。

Conclusion: OptPO通过统一统计最优停止与测试时学习，为测试时适应提供了一个计算高效的范式。

Abstract: Test-time policy optimization enables large language models (LLMs) to adapt to distribution shifts by leveraging feedback from self-generated rollouts. However, existing methods rely on fixed-budget majority voting to estimate rewards, incurring substantial computational redundancy. We propose Optimal Rollout Allocation for Test-time Policy Optimization (OptPO), a principled framework that adaptively allocates inference budgets. By formulating the voting process as a Bayesian sequential probability ratio test, OptPO dynamically halts sampling once the posterior confidence in a consensus answer exceeds a specified threshold. Crucially, it utilizes the retained rollouts for on-policy updates, seamlessly integrating with algorithms like PPO or GRPO without requiring ground-truth labels. Across diverse reasoning benchmarks, OptPO significantly reduces rollout overhead compared to fixed-sample baselines while preserving or improving accuracy. By unifying statistically optimal stopping with test-time learning, OptPO offers a computationally efficient paradigm for test-time adaptation. The source code will be open upon acceptance at https://open-upon-acceptance.

</details>


### [134] [FAIRY2I: Universal Extremely-Low Bit QAT framework via Widely-Linear Representation and Phase-Aware Quantization](https://arxiv.org/abs/2512.02901)
*Feiyu Wang,Xinyu Tan,Bokai Huang,Yihao Zhang,Guoan Wang,Peizhuang Cong,Tong Yang*

Main category: cs.LG

TL;DR: Fairy2i是一个将预训练实值LLM转换为等效复值表示的通用框架，通过数学等价转换和相位感知量化，实现极低比特（2比特）量化，显著超越现有实值量化方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM需要激进的量化来减少内存和计算需求，但现有复值LLM需要从头训练，无法利用庞大的预训练实值模型生态系统。需要一种方法既能利用复值表示的低比特优势，又能重用现有预训练模型。

Method: 1) 证明实值映射与广泛线性复值映射的数学等价性，将标准Transformer转换为复域；2) 采用相位感知量化方案，使用四次单位根的高效码本；3) 引入递归残差量化机制，迭代最小化量化误差；4) 通过无乘法累加实现高效推理。

Result: Fairy2i将LLaMA-2 7B模型恢复至接近全精度基线的性能水平，在有效2比特精度下显著优于最先进的实值二值和三值量化方法。

Conclusion: 该工作弥合了复值算术表示效率与预训练模型实际效用之间的差距，为在商用硬件上进行高效推理开辟了新途径。

Abstract: Large language models (LLMs) have revolutionized artificial intelligence, yet their massive memory and computational demands necessitate aggressive quantization, increasingly pushing representations toward the theoretical limit of a single bit. While complex-valued LLMs, such as iFairy, offer a superior chance for low-bit representation compared to real-valued counterparts, they require training from scratch, preventing the utilization of the vast ecosystem of pre-trained real-valued foundation models. Here we present Fairy2i, a universal framework that transforms pre-trained real-valued layers into an equivalent widely-linear complex form, enabling extremely low-bit quantization while reusing existing checkpoints. By proving a lossless mathematical equivalence between real and widely-linear maps, we convert standard Transformers into the complex domain and employ a phase-aware quantization scheme with a highly efficient codebook of fourth roots of unity. Furthermore, we introduce a recursive residual quantization mechanism that iteratively minimizes quantization error, allowing inference to proceed via efficient multiplication-free accumulation. We demonstrate that Fairy2i restores the performance of LLaMA-2 7B at an effective 2-bit precision to levels nearly comparable with full-precision baselines, significantly outperforming state-of-the-art real-valued binary and ternary quantization methods. This work bridges the gap between the representational efficiency of complex-valued arithmetic and the practical utility of pre-trained models, paving a new way for efficient inference on commodity hardware.

</details>


### [135] [Hypothesis Testing for Generalized Thurstone Models](https://arxiv.org/abs/2512.02912)
*Anuran Makur,Japneet Singh*

Main category: cs.LG

TL;DR: 本文提出了一个假设检验框架，用于判断成对比较数据是否由给定的广义Thurstone模型生成，建立了检验的上下界，并开发了基于分离距离的假设检验方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注广义Thurstone模型的参数估计和不确定性量化，但缺乏对这些模型本身的假设检验框架。本文旨在解决这一基本问题，即判断观测数据是否真的来自特定的广义Thurstone模型。

Method: 1. 引入广义Thurstone模型与一般成对比较模型之间的分离距离概念；2. 推导依赖于观测图拓扑结构的检验临界阈值上下界；3. 提出基于分离距离的假设检验方法；4. 构建置信区间；5. 使用反向鞅技术建立时间一致性的I类和II类错误概率界限；6. 使用信息论方法推导极小极大下界。

Result: 1. 对于完全观测图，检验阈值按Θ((nk)^{-1/2})缩放，其中n为智能体数量，k为每对比较次数；2. 建立了依赖于观测图拓扑结构的检验临界阈值上下界；3. 开发了有效的假设检验方法；4. 在合成和真实数据集上验证了理论结果。

Conclusion: 本文为广义Thurstone模型的假设检验提供了系统的理论框架，建立了检验的极小极大界限，并开发了实用的检验方法，填补了该领域的研究空白。

Abstract: In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \emph{generalized Thurstone model} $\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $Θ((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.

</details>


### [136] [Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation](https://arxiv.org/abs/2512.02920)
*Ziniu Zhang,Minxuan Duan,Haris N. Koutsopoulos,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种结合道路网络数据和卫星图像的多模态交通事故预测方法，通过构建包含900万事故记录和100万卫星图像的大规模数据集，证明多模态学习能显著提升预测精度，并识别出降水、道路类型和季节模式等关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 现有交通事故预测研究主要依赖道路网络结构特征，忽略了道路表面及其周围环境的物理和环境信息。为了更全面地分析事故模式，需要整合多源数据，包括卫星图像、天气统计和交通流量等信息。

Method: 构建了覆盖美国六个州的大规模多模态数据集，包含900万交通事故记录和100万高分辨率卫星图像。每个道路网络节点都标注了天气统计、道路类型等特征，每条边标注了交通流量信息。采用多模态学习方法，整合视觉特征和网络嵌入，并使用匹配估计器进行因果分析。

Result: 多模态学习方法平均AUROC达到90.1%，比仅使用图结构的图神经网络模型提高了3.7%。因果分析发现：较高降水量使事故率上升24%，高速公路等高速道路使事故率上升22%，季节模式使事故率上升29%。消融研究证实卫星图像特征对准确预测至关重要。

Conclusion: 整合卫星图像和道路网络数据的多模态学习方法能显著提升交通事故预测精度。该方法不仅能提供更准确的预测，还能通过因果分析识别关键影响因素，为交通安全管理和政策制定提供数据支持。

Abstract: We consider analyzing traffic accident patterns using both road network data and satellite images aligned to road graph nodes. Previous work for predicting accident occurrences relies primarily on road network structural features while overlooking physical and environmental information from the road surface and its surroundings. In this work, we construct a large multimodal dataset across six U.S. states, containing nine million traffic accident records from official sources, and one million high-resolution satellite images for each node of the road network. Additionally, every node is annotated with features such as the region's weather statistics and road type (e.g., residential vs. motorway), and each edge is annotated with traffic volume information (i.e., Average Annual Daily Traffic). Utilizing this dataset, we conduct a comprehensive evaluation of multimodal learning methods that integrate both visual and network embeddings. Our findings show that integrating both data modalities improves prediction accuracy, achieving an average AUROC of $90.1\%$, which is a $3.7\%$ gain over graph neural network models that only utilize graph structures. With the improved embeddings, we conduct a causal analysis based on a matching estimator to estimate the key contributing factors influencing traffic accidents. We find that accident rates rise by $24\%$ under higher precipitation, by $22\%$ on higher-speed roads such as motorways, and by $29\%$ due to seasonal patterns, after adjusting for other confounding factors. Ablation studies confirm that satellite imagery features are essential for achieving accurate prediction.

</details>


### [137] [Fast Gaussian Process Approximations for Autocorrelated Data](https://arxiv.org/abs/2512.02925)
*Ahmadreza Chokhachian,Matthias Katzfuss,Yu Ding*

Main category: cs.LG

TL;DR: 本文提出一种加速自相关数据高斯过程回归计算的方法，通过数据分块去相关，使现有快速近似方法适用于自相关数据，显著加速计算而不损失预测性能。


<details>
  <summary>Details</summary>
Motivation: 高斯过程模型在非线性回归中应用广泛，但标准方法假设数据独立同分布。对于自相关数据，忽略自相关性会导致时间过拟合问题，降低模型在新测试实例上的性能。现有快速高斯过程近似方法需要针对自相关数据进行修改。

Method: 将原始自相关数据点分割成块，使块内数据去相关，然后调整现有高斯过程近似方法使其能够处理分块数据。这种方法使快速近似技术能够应用于自相关数据场景。

Result: 在多个应用数据集上的数值实验表明，所提出的方法能够显著加速自相关数据的高斯过程回归计算，同时不损害模型预测性能。

Conclusion: 通过数据分块去相关技术，成功使现有高斯过程快速近似方法适用于自相关数据，解决了时间过拟合问题，实现了计算效率与预测性能的平衡。

Abstract: This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise. Various fast approximations that speed up Gaussian process regression work under this standard setting. But for autocorrelated data, failing to account for autocorrelation leads to a phenomenon known as temporal overfitting that deteriorates model performance on new test instances. To handle autocorrelated data, existing fast Gaussian process approximations have to be modified; one such approach is to segment the originally correlated data points into blocks in which the blocked data are de-correlated. This work explains how to make some of the existing Gaussian process approximations work with blocked data. Numerical experiments across diverse application datasets demonstrate that the proposed approaches can remarkably accelerate computation for Gaussian process regression on autocorrelated data without compromising model prediction performance.

</details>


### [138] [Pruning AMR: Efficient Visualization of Implicit Neural Representations via Weight Matrix Analysis](https://arxiv.org/abs/2512.02967)
*Jennifer Zvonek,Andrew Gillette*

Main category: cs.LG

TL;DR: PruningAMR算法通过剪枝隐式神经表示(INR)的权重矩阵来识别几何特征，从而生成适应几何特征的自适应网格，实现内存高效的可视化。


<details>
  <summary>Details</summary>
Motivation: 虽然INR比传统格点数据更内存高效，但许多可视化任务仍需要离散化到规则网格。现有方法无法自动生成适应INR底层分辨率的自适应网格，导致内存浪费。

Method: 使用插值分解剪枝方法处理INR的权重矩阵来识别几何特征，基于剪枝后的网络指导自适应网格细化，生成适应函数底层分辨率的自适应网格。

Result: 从预训练的INR（无需访问其训练数据）生成可变分辨率可视化，实现显著的内存节省。

Conclusion: PruningAMR算法能够自动生成适应INR几何特征的自适应网格，在保持可视化质量的同时大幅减少内存使用。

Abstract: An implicit neural representation (INR) is a neural network that approximates a spatiotemporal function. Many memory-intensive visualization tasks, including modern 4D CT scanning methods, represent data natively as INRs. While INRs are prized for being more memory-efficient than traditional data stored on a lattice, many visualization tasks still require discretization to a regular grid. We present PruningAMR, an algorithm that builds a mesh with resolution adapted to geometric features encoded by the INR. To identify these geometric features, we use an interpolative decomposition pruning method on the weight matrices of the INR. The resulting pruned network is used to guide adaptive mesh refinement, enabling automatic mesh generation tailored to the underlying resolution of the function. Starting from a pre-trained INR--without access to its training data--we produce a variable resolution visualization with substantial memory savings.

</details>


### [139] [ProteinPNet: Prototypical Part Networks for Concept Learning in Spatial Proteomics](https://arxiv.org/abs/2512.02983)
*Louis McConnell,Jieran Sun,Theo Maffei,Raphael Gottardo,Marianna Rapsomaniki*

Main category: cs.LG

TL;DR: ProteinPNet是一个基于原型部分网络的新框架，用于从空间蛋白质组学数据中发现肿瘤微环境（TME）模式，通过监督训练直接学习可解释的空间原型。


<details>
  <summary>Details</summary>
Motivation: 理解肿瘤微环境（TME）的空间结构对推进精准肿瘤学至关重要。传统的事后解释模型存在局限性，需要能够直接学习可解释空间模式的新方法。

Method: 基于原型部分网络（prototypical part networks）的ProteinPNet框架，通过监督训练直接学习具有区分性、可解释性和忠实性的空间原型。

Result: 在具有真实模式标记的合成数据集上验证了方法有效性，在真实世界肺癌空间蛋白质组学数据集中，ProteinPNet一致地识别出与不同肿瘤亚型对齐的生物学意义原型。图形和形态学分析显示这些原型捕获了可解释特征，指向免疫浸润和组织模块化的差异。

Conclusion: 原型学习在揭示肿瘤微环境内可解释空间生物标志物方面具有潜力，对空间组学中的机制发现具有重要意义。

Abstract: Understanding the spatial architecture of the tumor microenvironment (TME) is critical to advance precision oncology. We present ProteinPNet, a novel framework based on prototypical part networks that discovers TME motifs from spatial proteomics data. Unlike traditional post-hoc explanability models, ProteinPNet directly learns discriminative, interpretable, faithful spatial prototypes through supervised training. We validate our approach on synthetic datasets with ground truth motifs, and further test it on a real-world lung cancer spatial proteomics dataset. ProteinPNet consistently identifies biologically meaningful prototypes aligned with different tumor subtypes. Through graphical and morphological analyses, we show that these prototypes capture interpretable features pointing to differences in immune infiltration and tissue modularity. Our results highlight the potential of prototype-based learning to reveal interpretable spatial biomarkers within the TME, with implications for mechanistic discovery in spatial omics.

</details>


### [140] [Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge](https://arxiv.org/abs/2512.03019)
*Hamid Dadkhahi,Firas Trabelsi,Parker Riley,Juraj Juraska,Mehdi Mirzazadeh*

Main category: cs.LG

TL;DR: 提出一种基于分布校准的聚合方法，将大语言模型作为评判者时产生的多个独立评分样本进行聚合，通过建模三向偏好并利用评分分布的极性和确定性来区分微弱优势与强共识，显著提升评估的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型作为成对偏好评判者时，单个样本存在噪声，常见的聚合规则（多数投票、软自一致性或基于指令的自聚合）在允许平局时存在不一致性，需要更可靠的聚合方法来提升评估质量。

Method: 提出分布校准的聚合方案：为每个项目生成n个独立的思考-评分样本，使用Bradley-Terry-Davidson公式对评分计数进行三向偏好建模，同时利用极性（非平局间的差距）和确定性（非平局率）来区分微弱优势与强共识。

Result: 在各种评估基准测试中，该方法相比标准基线持续降低MAE并提高成对准确性，在与人类共识元标签对比时，达到或超过个体人类评分者的表现。

Conclusion: 通过精心分配推理时计算资源并采用分布感知的聚合方法，可以将嘈杂的个体模型判断转化为可靠的评估评分，显著提升大语言模型作为评判者的评估质量。

Abstract: Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Bradley-Terry-Davidson formulation on rating counts, leveraging both polarity (margin among non-ties) and decisiveness (non-tie rate) to distinguish narrow margins from strong consensus. Across various evaluation benchmarks, our approach consistently reduces MAE and increases pairwise accuracy versus standard baselines, and when evaluated against human-consensus meta-labels, matches or exceeds individual human raters. These results show that carefully allocating ITC and aggregating with distribution-aware methods turns noisy individual model judgments into reliable ratings for evaluation.

</details>


### [141] [TokenPowerBench: Benchmarking the Power Consumption of LLM Inference](https://arxiv.org/abs/2512.03024)
*Chenxu Niu,Wei Zhang,Jie Li,Yongjian Zhao,Tongyang Wang,Xi Wang,Yong Chen*

Main category: cs.LG

TL;DR: TokenPowerBench是首个专注于LLM推理功耗研究的轻量级可扩展基准测试工具，支持GPU、节点和系统级功耗测量，无需专用功率计。


<details>
  <summary>Details</summary>
Motivation: LLM服务每天处理数十亿查询，推理占90%以上总功耗，但现有基准测试主要关注训练/微调或推理性能，缺乏对推理功耗的测量和分析支持。

Method: 包含三个核心组件：(1)声明式配置接口覆盖模型选择、提示集和推理引擎；(2)无需专用功率计的GPU、节点和系统级功耗测量层；(3)将能耗归因于每个请求的prefill和decode阶段的相位对齐指标管道。

Result: 在四个最广泛使用的模型系列（Llama、Falcon、Qwen、Mistral）上评估，覆盖从10亿参数到前沿规模的Llama3-405B模型。通过改变批量大小、上下文长度、并行化策略和量化，快速评估每个设置对每token焦耳等能效指标的影响。

Conclusion: TokenPowerBench作为开源工具发布，帮助用户测量功耗、预测运营成本，并在部署LLM服务时满足可持续性目标。

Abstract: Large language model (LLM) services now answer billions of queries per day, and industry reports show that inference, not training, accounts for more than 90% of total power consumption. However, existing benchmarks focus on either training/fine-tuning or performance of inference and provide little support for power consumption measurement and analysis of inference. We introduce TokenPowerBench, the first lightweight and extensible benchmark designed for LLM-inference power consumption studies. The benchmark combines (i) a declarative configuration interface covering model choice, prompt set, and inference engine, (ii) a measurement layer that captures GPU-, node-, and system-level power without specialized power meters, and (iii) a phase-aligned metrics pipeline that attributes energy to the prefill and decode stages of every request. These elements make it straight-forward to explore the power consumed by an LLM inference run; furthermore, by varying batch size, context length, parallelism strategy and quantization, users can quickly assess how each setting affects joules per token and other energy-efficiency metrics. We evaluate TokenPowerBench on four of the most widely used model series (Llama, Falcon, Qwen, and Mistral). Our experiments cover from 1 billion parameters up to the frontier-scale Llama3-405B model. Furthermore, we release TokenPowerBench as open source to help users to measure power consumption, forecast operating expenses, and meet sustainability targets when deploying LLM services.

</details>
