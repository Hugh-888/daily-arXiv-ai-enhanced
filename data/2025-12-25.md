<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 29]
- [cs.LG](#cs.LG) [Total: 60]
- [gr-qc](#gr-qc) [Total: 16]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Systematic Construction of Time-Dependent Hamiltonians for Microwave-Driven Josephson Circuits](https://arxiv.org/abs/2512.20743)
*Yao Lu,Tianpu Zhao,André Vallières,Kevin C. Smith,Daniel Weiss,Xinyuan You,Yaxing Zhang,Suhas Ganjam,Aniket Maiti,John W. O. Garmon,Shantanu Mundhada,Ziwen Huang,Ian Mondragon-Shem,Steven M. Girvin,Jens Koch,Robert J. Schoelkopf*

Main category: quant-ph

TL;DR: 提出新的数值方法，通过经典微波仿真获取任意几何形状微波驱动超导电路的时间相关哈密顿量，无需集总元件描述，可预测驱动诱导的弛豫和退相干。


<details>
  <summary>Details</summary>
Motivation: 现有数值方法（如BBQ和EPR）擅长建模约瑟夫森电路的静态哈密顿量，但无法完全捕捉微波驱动电路的行为，也缺乏处理微波端口噪声和耗散的通用方法。

Method: 利用可在有限元求解器中高效执行的经典微波仿真技术，获取任意几何形状微波驱动超导电路的时间相关哈密顿量，不依赖电路的集总元件描述。

Result: 展示了该方法在复杂电磁环境中表征实际电路器件驱动特性的能力，包括电荷和磁通调制引起的相干动力学，以及驱动诱导的弛豫和退相干。

Conclusion: 这些技术为优化电路设计和推进超导量子计算的实际应用提供了强大的工具箱。

Abstract: Time-dependent electromagnetic drives are fundamental for controlling complex quantum systems, including superconducting Josephson circuits. In these devices, accurate time-dependent Hamiltonian models are imperative for predicting their dynamics and designing high-fidelity quantum operations. Existing numerical methods, such as black-box quantization (BBQ) and energy-participation ratio (EPR), excel at modeling the static Hamiltonians of Josephson circuits. However, these techniques do not fully capture the behavior of driven circuits stimulated by external microwave drives, nor do they include a generalized approach to account for the inevitable noise and dissipation that enter through microwave ports. Here, we introduce novel numerical techniques that leverage classical microwave simulations that can be efficiently executed in finite element solvers, to obtain the time-dependent Hamiltonian of a microwave-driven superconducting circuit with arbitrary geometries. Importantly, our techniques do not rely on a lumped-element description of the superconducting circuit, in contrast to previous approaches to tackling this problem. We demonstrate the versatility of our approach by characterizing the driven properties of realistic circuit devices in complex electromagnetic environments, including coherent dynamics due to charge and flux modulation, as well as drive-induced relaxation and dephasing. Our techniques offer a powerful toolbox for optimizing circuit designs and advancing practical applications in superconducting quantum computing.

</details>


### [2] [Quantum Universality in Composite Systems: A Trichotomy of Clifford Resources](https://arxiv.org/abs/2512.20787)
*Alejandro Borda,Julian Rincon,César Galindo*

Main category: quant-ph

TL;DR: 该论文研究了高维量子系统（qudits）中通用量子计算的资源需求，发现希尔伯特空间维度的数论结构严格决定了打破Clifford电路经典模拟屏障所需的资源。特别地，对于具有互质因子的复合维度，仅需标准纠缠操作（广义CNOT门）即可实现通用计算，无需显式注入对角"魔法"资源。


<details>
  <summary>Details</summary>
Motivation: Clifford电路的高效经典模拟构成了量子优势的基本障碍，通常需要通过注入显式的非Clifford"魔法"资源来克服。本文旨在探索在高维量子系统中，打破这一障碍所需资源是否受希尔伯特空间维度数论结构的严格约束。

Method: 通过分析Clifford群的伴随作用，建立了单qudit通用性的三分法分类。对于复合维度（具有互质因子），证明了仅使用标准纠缠操作（广义intra-qudit CNOT门）就能生成必要的非Clifford资源。证明依赖于一个新的几何准则：如果一个子群具有不可约的伴随作用，并且包含一个与恒等元投影距离严格小于1/2的非标量元素，则该子群是无限的。

Result: 建立了单qudit通用性的三分法：(I) 对于素数维度，Clifford群是最大有限子群，任何非Clifford门都能稳健地实现通用性；(II) 对于素数幂维度，群结构碎片化，需要定制的对角非Clifford门来恢复不可约性；(III) 对于具有互质因子的复合维度，仅标准纠缠操作就能保证SU(d)的稠密子群，无需显式对角魔法注入。

Conclusion: "互质架构"——结合具有互质子系统的混合寄存器——可以仅使用经典纠缠操作来维持通用计算，使得显式注入魔法资源在代数上变得不必要。这表明高维量子系统中通用量子计算的资源需求严格受希尔伯特空间维度数论结构的支配。

Abstract: The efficient classical simulation of Clifford circuits constitutes a fundamental barrier to quantum advantage, typically overcome by injecting explicit non-Clifford "magic" resources. We demonstrate that for high-dimensional quantum systems (qudits), the resources required to break this barrier are strictly governed by the number-theoretic structure of the Hilbert space dimension $d$. By analyzing the adjoint action of the Clifford group, we establish a classification of single-qudit universality as a trichotomy. (I) For prime dimensions, the Clifford group is a maximal finite subgroup, and universality is robustly achieved by any non-Clifford gate. (II) For prime-power dimensions, the group structure fragments, requiring tailored diagonal non-Clifford gates to restore irreducibility. (III) Most notably, for composite dimensions with coprime factors, we demonstrate that standard entangling operations alone -- specifically, generalized intra-qudit CNOT gates -- generate the necessary non-Clifford resources to guarantee a dense subgroup of $\mathrm{SU}(d)$ without explicit diagonal magic injection. Our proofs rely on a new geometric criterion establishing that a subgroup with irreducible adjoint action is infinite if it contains a non-scalar element with projective distance strictly less than $1/2$ from the identity. These results establish that "coprime architectures" -- hybrid registers combining subsystems with coprime dimensions -- can sustain universal computation using only classical entangling operations, rendering the explicit injection of magic resources algebraically unnecessary.

</details>


### [3] [Coexistence of Anderson Localization and Quantum Scarring in Two Dimensions](https://arxiv.org/abs/2512.20788)
*Fartash Chalangari,Anant Vijay Varma,Joonas Keski-Rahkonen,Esa Räsänen*

Main category: quant-ph

TL;DR: 二维无序系统中低能态强局域化，高能态形成变分疤痕，两者共存产生可观测的空间和谱特征


<details>
  <summary>Details</summary>
Motivation: 研究二维无序系统中局域化与扩展态共存的物理现象，探索在有限系统尺寸下如何同时存在强局域化和变分疤痕态

Method: 研究具有周期性约束的二维无序系统，分析能量相关的局域化长度，通过变分方法识别疤痕态，结合空间强度分布和谱统计进行分析

Result: 发现低能态呈现强安德森局域化，高能态形成各向异性的变分疤痕态，违反随机波预期，两者共存产生可直接观测的鲁棒特征

Conclusion: 二维无序系统中局域化与疤痕态可以共存，这种共存现象在介观电子、光子和冷原子系统中具有直接可观测的物理特征

Abstract: We study finite two-dimensional disordered systems with periodic confinement. At low energies, eigenstates exhibit strong Anderson localization, while at higher energies a subset of states forms variational scars with anisotropic intensity patterns that violate random wave expectations. Scaling theory predicts that all states localize in two dimensions, yet energy-dependent localization lengths and finite system size allow these regimes to coexist. We demonstrate that this coexistence produces distinct, robust signatures in both spatial intensity patterns and spectral statistics that are directly observable in mesoscopic electronic, photonic, and cold atom systems.

</details>


### [4] [Higher-Dimensional Information Lattice: Quantum State Characterization through Inclusion-Exclusion Local Information](https://arxiv.org/abs/2512.20793)
*Ian Matthias Flór,Claudia Artiaco,Thomas Klein Kvorning,Jens H. Bardarson*

Main category: quant-ph

TL;DR: 将一维信息晶格推广到高维量子多体系统，通过包含-排除原理定义局部信息，提取尺度分辨的普适特征


<details>
  <summary>Details</summary>
Motivation: 传统一维信息晶格无法处理高维系统中子系统重叠形成环路的问题，需要发展新的理论框架来表征高维量子多体态的尺度分辨信息结构

Method: 引入高维信息晶格，通过包含-排除原理定义局部信息，将信息分配给标记子系统位置和尺度的晶格顶点，并在二维系统中具体实现

Result: 成功应用于多种不同纠缠结构的多体基态，提取了信息基定位长度、方向依赖临界指数、边缘模信息特征、拓扑序长程信息模式以及非阿贝尔融合通道特征

Conclusion: 建立了一个通用的信息理论框架，用于分离高维几何中量子多体态的普适尺度分辨特征

Abstract: We generalize the information lattice, originally defined for one-dimensional open-boundary chains, to characterize quantum many-body states in higher-dimensional geometries. In one dimension, the information lattice provides a position- and scale-resolved decomposition of von Neumann information. Its generalization is nontrivial because overlapping subsystems can form loops, allowing multiple regions to encode the same information. This prevents information from being assigned uniquely to any one of them. We address this by introducing a higher-dimensional information lattice in which local information is defined through an inclusion-exclusion principle. The inclusion-exclusion local information is assigned to the lattice vertices, each labeled by subsystem position and scale. We implement this construction explicitly in two dimensions and apply it to a range of many-body ground states with distinct entanglement structures. Within this position- and scale-resolved framework, we extract information-based localization lengths, direction-dependent critical exponents, characteristic edge mode information, long-range information patterns due to topological order, and signatures of non-Abelian fusion channels. Our work establishes a general information-theoretic framework for isolating the universal scale-resolved features of quantum many-body states in higher-dimensional geometries.

</details>


### [5] [Using bosons to improve resource efficiency of quantum simulation of vibronic molecular dynamics](https://arxiv.org/abs/2512.20828)
*Henry L. Nourse,Vanessa C. Olaya-Agudelo,Ivan Kassal*

Main category: quant-ph

TL;DR: MQB量子模拟器相比纯量子比特模拟器在模拟非绝热化学动力学时具有巨大资源优势，所需量子操作少几个数量级


<details>
  <summary>Details</summary>
Motivation: 化学动力学模拟计算成本高，特别是非绝热动力学，经典模拟随系统规模指数增长，即使小分子也难以处理。量子计算机虽能高效模拟，但需要比较纯量子比特方法与混合量子比特-玻色子(MQB)模拟器的资源需求

Method: 比较量子比特方法与MQB模拟器在模拟非绝热分子动力学时达到相同精度所需的量子资源，分析电路体积和操作数量

Result: MQB模拟所需量子操作比量子比特方法少几个数量级：一个门的MQB电路相当于超过40万个量子比特电路体积（孤立分子），考虑环境效应时超过1000万。误差较小时，系统规模越大，MQB优势越明显

Conclusion: 原生表示非量子比特化学自由度（而非编码到量子比特中）具有巨大资源优势，MQB模拟器在化学动力学模拟中比纯量子比特方法高效得多

Abstract: Simulating chemical dynamics is computationally challenging, especially for nonadiabatic dynamics, where numerically exact classical simulations scale exponentially with system size, becoming intractable for even small molecules. On quantum computers, chemical dynamics can be simulated efficiently using either universal, qubit-only devices or specialized mixed-qudit-boson (MQB) simulators, which natively host electronic and vibrational degrees of freedom. Here, we compare the quantum resources required for a qubit-only approach to achieve the same accuracy as an MQB device at simulating nonadiabatic molecular dynamics. We find that MQB simulations require orders-of-magnitude fewer quantum operations than qubit-only simulations, with a one-gate MQB circuit requiring a qubit-equivalent circuit volume of over 400,000 when simulating an isolated molecule, which increases to over ten million when environmental effects are included. These estimates assume perfect qubits and gates, and would increase by additional orders of magnitude if error correction were used for fault tolerance. When errors are small, the advantage of MQB simulators becomes even larger as system size increases. Our results highlight the enormous resource advantages of representing non-qubit chemical degrees of freedom natively, rather than encoding them into qubits.

</details>


### [6] [Quantum Homotopy Algorithm for Solving Nonlinear PDEs and Flow Problems](https://arxiv.org/abs/2512.21033)
*Sachin S. Bharadwaj,Balasubramanya Nadiga,Stephan Eidenbenz,Katepalli R. Sreenivasan*

Main category: quant-ph

TL;DR: 提出一种近最优、鲁棒的端到端量子算法，用于求解含时、耗散、非线性偏微分方程，基于量子同伦分析将PDE嵌入高维线性空间，采用紧凑量子算法进行离散化和积分。


<details>
  <summary>Details</summary>
Motivation: 量子算法求解非线性PDE对于增强量子计算的实际应用价值至关重要，但这类算法难以发现。需要开发能够处理非线性现象的实用量子算法。

Method: 基于量子同伦分析将非线性PDE嵌入截断的高维线性空间，使用有限差分方法对线性化系统进行离散化和积分，采用紧凑量子算法实现。

Result: 算法复杂度在矩阵算子范数、条件数、模拟时间和精度方面优于现有方法，提供了通用嵌入策略、稳定性准则界限、精度、门计数和查询复杂度分析，并通过一维Burgers问题验证。

Conclusion: 该工作展示了混合量子算法在近期和容错量子设备上模拟实用非线性现象的潜力，为量子计算在流体力学等领域的应用提供了重要工具。

Abstract: Quantum algorithms to integrate nonlinear PDEs governing flow problems are challenging to discover but critical to enhancing the practical usefulness of quantum computing. We present here a near-optimal, robust, and end-to-end quantum algorithm to solve time-dependent, dissipative, and nonlinear PDEs. We embed the PDEs in a truncated, high dimensional linear space on the basis of quantum homotopy analysis. The linearized system is discretized and integrated using finite-difference methods that use a compact quantum algorithm. The present approach can adapt its input to the nature of nonlinearity and underlying physics. The complexity estimates improve existing approaches in terms of scaling of matrix operator norms, condition number, simulation time, and accuracy. We provide a general embedding strategy, bounds on stability criteria, accuracy, gate counts and query complexity. A physically motivated measure of nonlinearity is connected to a parameter that is similar to the flow Reynolds number $Re_{\textrm{H}}$, whose inverse marks the allowed integration window, for given accuracy and complexity. We illustrate the embedding scheme with numerical simulations of a one-dimensional Burgers problem. This work shows the potential of the hybrid quantum algorithm for simulating practical and nonlinear phenomena on near-term and fault-tolerant quantum devices.

</details>


### [7] [Optical spin tomography in a telecom C-band quantum dot](https://arxiv.org/abs/2512.20870)
*Junyang Huang,Ginny Shooter,Petros Laccotripes,Andrea Barbiero,David A. Ritchie,Andrew J. Shields,Tina Müller,R. Mark Stevenson*

Main category: quant-ph

TL;DR: 通过时间与偏振分辨光子关联测量，评估了量子点中电子与空穴的g因子及相干特性，发现空穴更适合作为量子网络节点中的自旋-光子纠缠载体，并通过全态层析揭示了自旋进动中的各向异性，为减少多光子纠缠生成中的相位误差提供关键诊断。


<details>
  <summary>Details</summary>
Motivation: 实现可扩展量子网络的关键挑战是建立静止量子比特与电信波段光子量子比特之间的相干接口，以实现长距离纠缠分发。半导体量子点在电信波长发射，提供了有前景的自旋-光子平台，但需要精确理解受限自旋的特性以优化其与光子量子比特的相互作用。

Method: 采用时间与偏振分辨的光子关联测量方法，同时评估了液滴外延量子点中电子和空穴的g因子及相干特性。随后对受限空穴基态进行了全态层析，以揭示自旋进动中的微妙各向异性。

Result: 测量结果表明空穴是量子网络节点中自旋-光子纠缠的优选量子比特。全态层析揭示了自旋进动中的各向异性，这为最小化确定性多光子纠缠生成中的关键相位误差提供了重要诊断信息。

Conclusion: 该研究通过光子关联测量成功评估了量子点自旋特性，确定了空穴作为量子网络节点的优选自旋量子比特，并揭示了自旋各向异性对相位误差的影响，为优化量子网络接口性能提供了关键见解。

Abstract: A central challenge for scalable quantum networks is the realization of coherent interfaces between stationary qubits and telecom-band photonic qubits for long-distance entanglement distribution. Semiconductor quantum dots emitting at telecom wavelengths present a promising spin-photon platform, and a precise understanding of the properties of the confined spin is crucial for optimizing its interplay with the photonic qubit. Here, we simultaneously benchmark the electron and hole g-factors and coherence properties of a droplet epitaxy QD, solely from time and polarization resolved photon correlations. These measurements identify the hole as the preferable qubit for spin-photon entanglement in quantum network nodes. We then perform full state tomography of the confined hole ground state to reveal subtle anisotropies in the spin precession, providing essential diagnostics for minimizing phase errors critical for deterministic multiphoton entanglement generation.

</details>


### [8] [Heralded Linear Optical Generation of Dicke States](https://arxiv.org/abs/2512.20881)
*Minhyeok Kang,Jaehee Kim,William J. Munro,Seungbeom Chin,Joonsuk Huh*

Main category: quant-ph

TL;DR: 提出了一种基于线性量子图框架的光学预示方案，用于生成任意Dicke态|D_n^k⟩，使用3n+k光子，通过将方案设计映射为图寻找问题并利用Dicke态的置换对称性来克服结构复杂性。


<details>
  <summary>Details</summary>
Motivation: Dicke态作为具有置换对称性的多体纠缠态，在量子通信和计算中具有重要应用。然而，大多数光学实现依赖于后选择，这会破坏态并阻止其进一步使用，因此需要一种预示的光学方案。

Method: 采用线性量子图框架，将Dicke态生成方案设计映射为图寻找问题，利用Dicke态的置换对称性来克服结构复杂性，使用3n+k光子实现任意Dicke态|D_n^k⟩的预示生成。

Result: 提出了一种资源高效的线性光学预示方案，能够生成任意Dicke态|D_n^k⟩，为量子技术的实际应用提供了可行的制备途径。

Conclusion: 该研究为Dicke态的预示制备提供了一种资源高效的路径，克服了先前方法的结构复杂性限制，有望推动量子通信和计算等量子技术的发展。

Abstract: Entanglement is a fundamental feature of quantum mechanics and a key resource for quantum information processing. Among multipartite entangled states, Dicke states $|D_n^k\rangle$ are distinguished by their permutation symmetry, which provides robustness against particle loss and enables applications for quantum communication and computation. Although Dicke states have been realized in various platforms, most optical implementations rely on postselection, which destroys the state upon detection and prevents its further use. A heralded optical scheme is therefore highly desirable. Here, we present a linear-optical heralded scheme for generating arbitrary Dicke states $|D_n^k\rangle$ with $3n+k$ photons through the framework of the linear quantum graph (LQG) picture. By mapping the scheme design into the graph-finding problem, and exploiting the permutation symmetry of Dicke states, we overcome the structural complexity that has hindered previous approaches. Our results provide a resource-efficient pathway toward practical heralded preparation of Dicke states for quantum technologies.

</details>


### [9] [Quantum-classical algorithm for Ewald summation based computation of long-range electrostatics](https://arxiv.org/abs/2512.20886)
*Mansur Ziiatdinov,Igor Novikov,Farid Ablayev,Valeri Barsegov*

Main category: quant-ph

TL;DR: 提出一种用于计算点电荷系统库仑静电能的量子算法，利用量子傅里叶变换实现计算加速，在系统规模较大时具有量子优势


<details>
  <summary>Details</summary>
Motivation: 大规模生物系统的数值模拟需要远超经典计算机的计算能力，而计算带电原子间的长程静电相互作用是计算分子科学中的主要瓶颈

Method: 基于Ewald方法将静电能量分解为多个能量项，其中"傅里叶分量"在量子设备上使用量子傅里叶变换进行计算

Result: 算法在三维空间中点电荷数量超过网格点数时具有量子优势，数值误差小于0.1%

Conclusion: 该算法可在量子计算机上实现全原子分子动力学模拟，扩展了QFT方法在计算物理、化学和生物学中的应用范围

Abstract: Numerical exploration of large-size real biological systems requires computational power far exceeding that of modern classical computers. In computational molecular science, calculation of long-range electrostatic interactions between charged atoms - the strongest interactions in condensed phases, is a major bottleneck. Here, we propose a quantum algorithm for fast yet accurate computation of Coulomb electrostatic energy for a system of point charges. The algorithm employs the Ewald method based decomposition of electrostatic energy E into several energy terms, of which "the Fourier component" of E is computed in the algorithm proposed on a quantum device, utilizing the power of Quantum Fourier Transform. We demonstrate the algorithm's quantum advantage for a range of systems of point charges in the three-dimensional space when the number of charges (system size) N exceeds the number of grid points M, and show that the numerical error is rather small <0.1%. The algorithm can be implemented in running the all-atom Molecular Dynamics simulations on a quantum computer, thereby expanding the scope of applications of QFT methods in computational physics, chemistry, and biology.

</details>


### [10] [Tutorial on Superconducting Quantum Circuits: From Basics to Applications](https://arxiv.org/abs/2512.20913)
*Denys Derlian Carvalho Brito,Fernando Valadares,André Jorge Carvalho Chaves*

Main category: quant-ph

TL;DR: 这是一篇面向本科生的超导量子电路入门教程，系统介绍了从超导现象到量子比特的完整理论框架，并通过数值模拟演示了真空拉比振荡。


<details>
  <summary>Details</summary>
Motivation: 随着超导电路成为可扩展量子信息处理的主要平台，需要为领域新研究者建立从宏观量子现象基本原理到现代量子设备架构的完整桥梁。

Method: 从超导性和约瑟夫森效应开始，系统地将微波电路量子化为电路量子电动力学(cQED)框架，然后引入transmon量子比特作为应用，详细推导其哈密顿量及其与控制/读出电路的相互作用。

Result: 通过数值模拟驱动transmon-谐振器系统中的真空拉比振荡，巩固了理论形式体系，展示了强耦合机制下相干能量交换的典型实验。

Conclusion: 该工作作为基础指南和入门接触点，为学生和研究人员提供了理解和设计超导量子硬件所需的概念和数学工具。

Abstract: As superconducting circuits emerge as a leading platform for scalable quantum information processing, building comprehensive bridges from the foundational principles of macroscopic quantum phenomena to the architecture of modern quantum devices is increasingly essential for introducing new researchers to the field. This tutorial provides a self-contained, pedagogical introduction to superconducting quantum circuits at the undergraduate level. Beginning with an overview of superconductivity and the Josephson effect, the tutorial systematically develops the quantization of microwave circuits into the framework of circuit quantum electrodynamics (cQED). The transmon qubit is then introduced as a state-of-the-art application, with a detailed derivation of its Hamiltonian and its interaction with control and readout circuitry. The theoretical formalism is consolidated through a numerical simulation of vacuum Rabi oscillations in a driven transmon-resonator system, a canonical experiment that demonstrates the coherent energy exchange characteristic of the strong coupling regime. This work serves as a foundational guide and first point of contact, equipping students and researchers with the conceptual and mathematical tools necessary to understand and engineer superconducting quantum hardware.

</details>


### [11] [AI-Accelerated Qubit Readout at the Single-Photon Level for Scalable Atomic Quantum Processors](https://arxiv.org/abs/2512.20919)
*Yaoting Zhou,Weisen Wang,Zhuangzhuang Tian,Bin Huang,Huancheng Chen,Donghao Li,Zhongxiao Xu,Li Chen,Heng Shen*

Main category: quant-ph

TL;DR: AI加速贝叶斯推理方法实现中性原子阵列单光子荧光读取，在短曝光下达到99%以上保真度，比传统阈值方法快100倍


<details>
  <summary>Details</summary>
Motivation: 量子态读取需要最小化资源消耗以实现可扩展量子信息处理。中性原子阵列依赖荧光成像进行量子比特读取，但单光子状态下状态分布严重重叠导致传统阈值判别失效

Method: 提出AI加速的贝叶斯推理方法：1）弱锚定贝叶斯方案，仅需校准一个状态；2）使用置换不变神经网络，将迭代推理压缩为单次前向传播，实现100倍加速

Result: 在直方图重叠61%和72%时，相对读取保真度分别达到99%和98%以上，成功提取传统阈值方法无法获得的拉比振荡和拉姆齐干涉结果

Conclusion: 该方法支持大规模原子阵列的可扩展实时读取，为AI增强的量子计算和传感技术铺平道路

Abstract: Quantum state readout with minimal resources is crucial for scalable quantum information processing. As a leading platform, neutral atom arrays rely on atomic fluorescence imaging for qubit readout, requiring short exposure, low photon count schemes to mitigate heating and atom loss while enabling mid-circuit feedback. However, a fundamental challenge arises in the single-photon regime where severe overlap in state distributions causes conventional threshold discrimination to fail. Here, we report an AI-accelerated Bayesian inference method for fluorescence readout in neutral atom arrays. Our approach leverages Bayesian inference to achieve reliable state detection at the single-photon level under short exposure. Specifically, we introduce a weakly anchored Bayesian scheme that requires calibration of only one state, addressing asymmetric calibration challenges common across quantum platforms. Furthermore, acceleration is achieved via a permutation-invariant neural network, which yields a 100-fold speedup by compressing iterative inference into a single forward pass. The approach achieves relative readout fidelity above 99% and 98% for histogram overlaps of 61% and 72%, respectively, enabling reliable extraction of Rabi oscillations and Ramsey interference results unattainable with conventional threshold based methods. This framework supports scalable, real-time readout of large atom arrays and paves the way toward AI-enhanced quantum technology in computation and sensing.

</details>


### [12] [Precise quantum control of unidirectional field-free molecular orientation](https://arxiv.org/abs/2512.21012)
*Qian-Qian Hong,Zhe-Jun Zhang,Chuan-Cun Shu,Jun He,Daoyi Dong,Dajun Ding*

Main category: quant-ph

TL;DR: 提出一种利用单控制脉冲实现对称顶分子单向场自由取向的理论框架，通过选择性操控两个特定转动态，简化了传统多态或多脉冲方案。


<details>
  <summary>Details</summary>
Motivation: 传统分子取向方法存在方向周期性反转、需要宽谱转动态相干叠加等限制，需要发展更简单有效的场自由单向取向方法。

Method: 建立理论框架，通过选择性操控对称顶分子的两个特定转动态，利用相干叠加和初始态选择，设计单控制脉冲的量子控制策略。

Result: 数值模拟验证了该方法对甲基碘分子的有效性和可行性，即使在考虑分子离心畸变的情况下也能实现持久的高单向分子取向。

Conclusion: 初始态选择和量子相干在实现持久高单向分子取向中起关键作用，为立体化学、精密光谱学和量子计算开辟新方向。

Abstract: The capability to control molecular rotation for field-free orientation, which arranges molecules in specific spatial directions without external fields, is crucial in physics, chemistry, and quantum information science. However, conventional methods typically lead to transient orientations characterized by periodic directional reversals and necessitate the generation of coherent superpositions across a broad spectrum of rotational states of ultracold molecules. In this work, we develop a theoretical framework for achieving unidirectional field-free orientation by selectively manipulating two specific rotational states of symmetric top molecules. By leveraging the interplay between coherent superpositions and the precise selection of initial states, we demonstrate that both the maximum achievable orientation and its direction can be effectively controlled. To attain the desired two-state orientation, we present a quantum control strategy that utilizes a single control pulse, significantly simplifying the complexities of conventional multistate or multipulse schemes. Numerical simulations validate the effectiveness and feasibility of this approach for methyl iodide (CH$_3$I) molecules, even when accounting for molecular centrifugal distortion.The results highlight the critical roles of initial-state selection and quantum coherence in achieving long-lasting, high unidirectional molecular orientation, opening new directions in stereochemistry, precision spectroscopy, and quantum computing.

</details>


### [13] [Measurement-driven Quantum Approximate Optimization](https://arxiv.org/abs/2512.21046)
*Tobias Stollenwerk,Stuart Hadfield*

Main category: quant-ph

TL;DR: 提出一种基于非幺正演化的量子算法，专门用于组合优化问题，通过弱测量实现虚时演化，支持近似优化和约束优化，并引入自适应混合算子加速收敛。


<details>
  <summary>Details</summary>
Motivation: 基于非幺正演化的量子算法在基态制备方面受到关注，但需要将其专门化并扩展到组合优化领域，特别是解决近似优化和约束优化问题。

Method: 使用辅助量子比特和受控幺正算子实现与虚时演化相关的弱测量。首先将算法从精确优化推广到近似优化，然后针对约束优化问题比较惩罚方法和可行性保持方法。提出自适应变体，根据测量结果决定是否应用混合算子以加速收敛。

Result: 展示了如何选择参数使每个测量步骤的成功概率远离1/2，证明了可行性保持方法相比惩罚方法的显著优势，并展示了量子交替算子ansatz中的混合算子可以直接导入用于本征态扰乱算子和初始态制备。

Conclusion: 该算法具有通用性，可作为独立算法应用于易制备的初始态，或作为量子后处理阶段改进参数化量子电路的性能。自适应混合算子的引入能加速算法并避免系统演化停滞在次优状态。

Abstract: Algorithms based on non-unitary evolution have attracted much interest for ground state preparation on quantum computers. One recently proposed method makes use of ancilla qubits and controlled unitary operators to implement weak measurements related to imaginary-time evolution. In this work we specialize and extend this approach to the setting of combinatorial optimization. We first generalize the algorithm from exact to approximate optimization, taking advantage of several properties unique to classical problems. In particular we show how to select parameters such that the success probability of each measurement step is bounded away from $1/2$. We then show how to adapt our paradigm to the setting of constrained optimization for a number of important classes of hard problem constraints. For this we compare and contrast both penalty-based and feasibility-preserving approaches, elucidating the significant advantages of the latter approach. Our approach is general and may be applied to easy-to-prepare initial states as a standalone algorithm, or deployed as a quantum postprocessing stage to improve performance of a given parameterized quantum circuit. We then propose a more sophisticated variant of our algorithm that adaptively applies a mixing operator or not, based on the measurement outcomes seen so far, as to speeds up the algorithm and helps the system evolution avoid slowing down or getting stuck suboptimally. In particular, we show that mixing operators from the quantum alternating operator ansatz can be imported directly, both for the necessary eigenstate scrambling operator and for initial state preparation, and discuss quantum resource tradeoffs.

</details>


### [14] [Device-Independent Anonymous Communication in Quantum Networks](https://arxiv.org/abs/2512.21047)
*Srijani Das,Manasi Patra,Tuhin Paul,Anish Majumdar,Ramij Rahaman*

Main category: quant-ph

TL;DR: 首个完全量子匿名通信协议，具有设备无关安全性证明


<details>
  <summary>Details</summary>
Motivation: 传统协议无法提供信息论安全性，现有量子方法依赖经典子程序和多个私有信道，在完全对抗环境中安全性不足

Method: 提出首个完全量子匿名通信协议，在现实量子网络中实现，具有设备无关安全性证明

Result: 实现了信息论安全的匿名通信，无需依赖经典子程序或多个私有信道

Conclusion: 该工作为量子网络中的匿名通信提供了首个完全量子化的解决方案，具有设备无关安全性，适用于完全对抗环境

Abstract: Anonymity is a fundamental cryptographic primitive that hides the identities of both senders and receivers during message transmission over a network. Classical protocols cannot provide information-theoretic security for such task, and existing quantum approaches typically depend on classical subroutines and multiple private channels, thereby weakening their security in fully adversarial settings. In this work, we introduce the first fully quantum protocol for anonymous communication in realistic quantum networks with a device-independent security proof.

</details>


### [15] [Classical reservoir approach for efficient molecular ground state preparation](https://arxiv.org/abs/2512.21069)
*Zekun He,Dominika Zgid,A. F. Kemper,J. K. Freericks*

Main category: quant-ph

TL;DR: 提出经典储层方法，一种适用于近期量子硬件的低成本变分ansatz，仅需方形晶格连接上的最近邻相互作用，在局域分子轨道中运行，显著减少电路深度


<details>
  <summary>Details</summary>
Motivation: 基态制备是电子结构量子算法的核心应用。传统方法基于经典高效的Hartree-Fock理论，但需要在变分参数空间中探索新区域，同时降低近期量子硬件的电路深度要求

Method: 引入经典储层方法，这是一种低成本的变分ansatz，专门为近期量子硬件设计，仅需方形晶格连接上的最近邻相互作用。该方法在局域分子轨道中运行，不同于传统基于Hartree-Fock理论的方法

Result: 数值基准测试显示，在不同系统和键长下都能达到化学精度；当允许放宽误差阈值（如数十E_h）时，可显著减少电路深度。在氢链、N_2、O_2、CO、BeH_2和H_2O上进行了基准测试，后者对应有效的24量子位计算

Conclusion: 经典储层方法为近期量子硬件提供了一种有效的基态制备方案，能够在保持化学精度的同时显著降低电路深度要求，为电子结构计算开辟了新途径

Abstract: Ground state preparation is a central application of quantum algorithms for electronic structure. We introduce the classical reservoir approach, a low cost variational ansatz tailored to near-term hardware, requiring only nearest-neighbor interactions on a machine with square-lattice connectivity. Unlike traditional methods built from the classically efficient Hartree Fock theory, our ansatz operates in localized molecular orbitals to study previously unexplored regions of the variational parameter space. Numerical benchmarks demonstrate chemical accuracy across diverse systems and bond lengths; notably, significantly reduced circuit depths are attainable when relaxed error thresholds (e.g., tens of E_h) are permissible. We benchmark the method on hydrogen chains, N_2, O_2, CO, BeH_2, and H_2O, the latter corresponding to an effective 24 qubit calculation.

</details>


### [16] [Holonomic multi-controlled gates for single-photon states](https://arxiv.org/abs/2512.21101)
*Carlo Danieli,Valentina Brosco,Claudio Conti,Laura Pilozzi*

Main category: quant-ph

TL;DR: 提出基于非阿贝尔全息原理的光子波导网络方案，实现可控和多控量子门，包括单量子比特门、CNOT、SWAP、Toffoli等门，并演示Deutsch量子查询算法。


<details>
  <summary>Details</summary>
Motivation: 可控和多控量子门是复杂量子算法的基本逻辑构建块，需要高效实现方案。传统方法存在限制，需要探索新的物理平台来实现这类关键量子操作。

Method: 利用调制光子波导网络中的非阿贝尔全息原理。采用两个星形网络通过双路径电路耦合的结构，其中星形网络包含M个外围波导耦合到单个中心站点（M-pod）。首先分析两个连接三脚架的最小情况，设计绝热驱动循环实现基本量子门，然后扩展到更大的M-pod结构实现多控操作。

Result: 成功设计了单量子比特门、CNOT门、SWAP门，以及通过耦合五脚架实现的Toffoli门和OR门。还证明了连接三脚架网络可以实现Deutsch量子查询算法。

Conclusion: 基于光子波导网络中非阿贝尔全息的方案为实现可控和多控量子门提供了有效途径，能够支持复杂量子算法的构建，展示了在光子平台上实现量子计算的潜力。

Abstract: Controlled and multi-controlled quantum gates, whose action on a target qubit depends on the state of multiple control qubits, represent a fundamental logical building block for complex quantum algorithms. We propose a scheme for realizing this class of gates based on non-Abelian holonomies in modulated photonic waveguide networks. Our approach relies on linear photonic cicuits formed by two star networks coupled via a two-path circuit. A star network with M peripheral waveguides coupled to a single central site, or M-pod, naturally generalizes the tripod structure used in non-Abelian Thouless pumping and stimulated Raman adiabatic passage (STIRAP). In the present work, we first analyze the minimal case of two connected tripods and design adiabatic driving loops that implement single-qubit, CNOT, and SWAP gates. We then show how extending the approach to larger M-pod structures enables the realization of multiply controlled operations, which we exemplify by designing Toffoli and the OR gate on two coupled pentapods. Finally, we demonstrate that networks of connected tripods can implement the Deutsch quantum query algorithm.

</details>


### [17] [Photoexcitation of moiré-trapped interlayer excitons via chiral phonons](https://arxiv.org/abs/2512.21125)
*A. Borel,T. V. Ivanova,J. Cervantes-Villanueva,P. Thor,H. Baek,T. Taniguchi,K. Watanabe,A. Molina-Sanchez,B. D. Gerardot,M. Brotons-Gisbert*

Main category: quant-ph

TL;DR: 该论文报道了一种通过手性E''面内光学声子激发过渡金属二硫化物异质双层中莫尔超晶格捕获的层间激子的新机制，实现了具有确定螺旋度的单个层间激子的确定性生成。


<details>
  <summary>Details</summary>
Motivation: 过渡金属二硫化物异质双层中的莫尔超晶格能够量子限制具有大垂直永久电偶极和自旋谷控制的层间激子，但需要开发可控的激发机制来利用这些特性进行量子光子和谷电子应用。

Method: 通过光致发光激发光谱在整体和量子发射器两种状态下研究2H堆叠MoSe2/WSe2异质双层，结合第一性原理计算验证相关声子模式的对称性和能量及其与层间激子的耦合。

Result: 发现约23 meV的固定声子能量介导了激发过程，该机制保持了谷选择性光学选择规则，能够确定性生成具有确定螺旋度的单个层间激子，发射光谱能量分布窄。

Conclusion: 手性声子可作为TMD莫尔系统中量子发射器可控激发的工具，为谷电子和量子光子应用开辟了新机会。

Abstract: Moiré superlattices in transition-metal dichalcogenide semiconductor heterobilayers enable the quantum confinement of interlayer excitons with large out-of-plane permanent electric dipoles and spin-valley control. Here, we report a novel phonon-assisted excitation mechanism of individual moiré-trapped interlayer excitons in 2H-stacked MoSe$_2$/WSe$_2$ heterobilayers via chiral $E^{\prime\prime}$ in-plane optical phonons at the Γ-point. This excitation pathway preserves valley-selective optical selection rules and enables deterministic generation of individual interlayer excitons with defined helicity, emitting within a spectrally narrow energy spread. Through photoluminescence excitation spectroscopy in both the ensemble and quantum emitter regimes, we identify a fixed phonon energy of $\sim$23 meV mediating the process. First-principles calculations corroborate the symmetry and energy of the relevant phonon mode and its coupling to interlayer excitons, providing microscopic support for the observed valley-selective phonon-assisted excitation mechanism. Our results highlight the utility of chiral phonons as a tool for controlled excitation of quantum emitters in TMD moiré systems, opening new opportunities for valleytronic and quantum photonic applications.

</details>


### [18] [Thermodynamic sampling of materials using neutral-atom quantum computers](https://arxiv.org/abs/2512.21142)
*Bruno Camino,Mao Lin,John Buckeridge,Scott M. Woodley*

Main category: quant-ph

TL;DR: 开发了一个从DFT到Rydberg原子哈密顿量的映射框架，通过α_v参数缩放解决硬件能量尺度限制，实现材料热力学性质的量子退火计算


<details>
  <summary>Details</summary>
Motivation: 中性原子量子硬件为可编程多体物理提供了有前景的平台，但需要开发实用框架来提取材料的热力学性质

Method: 从DFT形成能出发，将材料能量映射到适合量子退火的Rydberg原子哈密顿量，通过α_v参数缩放解决硬件能量尺度限制，建立激光失谐与化学势的直接对应关系

Result: 在28位点石墨烯纳米片上通过穷举验证方法有效性，在78位点系统上通过蒙特卡洛采样确认低能构型的优先采样

Conclusion: 建立了实用的中性原子量子硬件材料热力学性质提取框架，通过参数缩放策略克服硬件限制，为材料模拟提供了可行的量子计算方法

Abstract: Neutral-atom quantum hardware has emerged as a promising platform for programmable many-body physics. In this work, we develop and validate a practical framework for extracting thermodynamic properties of materials using such hardware. As a test case, we consider nitrogen-doped graphene. Starting from Density Functional Theory (DFT) formation energies, we map the material energetics onto a Rydberg-atom Hamiltonian suitable for quantum annealing by fitting an on-site term and distance-dependent pair interactions. The Hamiltonian derived from DFT cannot be implemented directly on current QuEra devices, as the largest energy scale accessible on the hardware is two orders of magnitude smaller than the target two-body interaction in the material. To overcome this limitation, we introduce a rescaling strategy based on a single parameter, $α_v$, which ensures that the Boltzmann weights sampled by the hardware correspond exactly to those of the material at an effective temperature $T' = α_vT$, where $T$ is the device sampling temperature. This rescaling also establishes a direct correspondence between the global laser detuning $Δ_g$ and the grand-canonical chemical potential $Δμ$. We validate the method on a 28-site graphene nanoflake using exhaustive enumeration, and on a larger 78-site system where Monte Carlo sampling confirms preferential sampling of low-energy configurations.

</details>


### [19] [Information-Scrambling-Enhanced Quantum Sensing Beyond the Standard Quantum Limit](https://arxiv.org/abs/2512.21157)
*Yangyang Ge,Haoyu Zhou,Wen Zheng,Xiang-Min Yu,Wei Fang,Zhenchuan Zhang,Wanli Huang,Xiang Deng,Haoyang Cai,Xianke Li,Kun Zhou,Hanxin Che,Tao Zhang,Lichang Ji,Yu Zhang,Jie Zhao,Shao-Xiong Li,Xinsheng Tan,Yang Yu*

Main category: quant-ph

TL;DR: 本文提出并实验验证了一种基于量子信息扰乱的蝴蝶计量学协议，在超导量子处理器上实现了超越标准量子极限的传感灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子传感虽然承诺超越经典极限的测量精度，但实际实现常受到退相干和大规模系统中产生、稳定纠缠的挑战。需要开发可扩展、鲁棒的量子传感协议。

Method: 实验演示了可扩展的扰乱增强量子传感协议（蝴蝶计量学），在十字形超导量子处理器上实现。通过利用量子信息扰乱，将局域相互作用转化为离域的计量有用相关性，通过扰乱态和极化态的干涉实现鲁棒信号放大。通过Loschmidt回波测量验证时间反转能力，并通过无序时序关联器量化信息扰乱。

Result: 测量显示传感灵敏度随量子比特数增加超越标准量子极限，在9量子比特配置中达到3.78（SQL为3.0）。该方案对相干控制误差和探测信号噪声具有固有鲁棒性。

Conclusion: 这项工作展示了一条可扩展的路径，利用现有实验平台实现实用的量子传感优势，为实际量子传感应用提供了有前景的方案。

Abstract: Quantum sensing promises measurement precision beyond classical limits, but its practical realization is often hindered by decoherence and the challenges of generating and stabilizing entanglement in large-scale systems. Here, we experimentally demonstrate a scalable, scrambling-enhanced quantum sensing protocol, referred to as butterfly metrology, implemented on a cross-shaped superconducting quantum processor. By harnessing quantum information scrambling, the protocol converts local interactions into delocalized metrologically useful correlations, enabling robust signal amplification through interference of the scrambled and polarized quantum states. We validate the time-reversal ability via Loschmidt echo measurements and quantify the information scrambling through out-of-time-ordered correlators, establishing the essential quantum resources of our protocol. Our measurements reveal that the sensing sensitivity surpasses the standard quantum limit (SQL) with increasing qubit number, reaching 3.78 in a 9-qubit configuration, compared to the SQL of 3.0. The scheme further exhibits inherent robustness to coherent control errors and probed signal noise. This work demonstrates a readily scalable path toward practical quantum sensing advantages with prevalent experimental platforms.

</details>


### [20] [Quantum Approximate Optimization Algorithm with Fixed Number of Parameters](https://arxiv.org/abs/2512.21181)
*Sebastián Saavedra-Pino,Ricardo Quispe-Mendizábal,Gabriel Alvarado Barrios,Enrique Solano,Juan Carlos Retamal,Francisco Albarrán-Arriagada*

Main category: quant-ph

TL;DR: FPC-QAOA是一种新型量子优化框架，通过固定可训练参数数量实现可扩展性，将调度函数优化与电路数字化分离，在保持高性能的同时显著减少经典计算开销。


<details>
  <summary>Details</summary>
Motivation: 标准QAOA在深度增加时面临可训练参数数量爆炸、优化困难（如贫瘠高原现象）等问题，限制了其在近期量子设备上的实际应用。需要一种既能支持深度电路又保持参数效率的框架。

Method: 提出FPC-QAOA框架，将调度函数优化与电路数字化分离：1) 使用固定数量的参数优化调度函数；2) 支持任意深度的数字化绝热演化电路；3) 保持参数数量恒定，不受量子比特数、哈密顿量复杂度或电路深度影响。

Result: 在随机MaxCut实例和Tail Assignment问题上，FPC-QAOA性能与标准QAOA相当或更好，经典计算开销几乎恒定，量子电路评估次数显著减少。在IBM Kingston超导处理器上50量子比特实验验证了其在真实噪声下的鲁棒性和硬件效率。

Conclusion: FPC-QAOA通过固定参数数量和分离优化层次，解决了深度QAOA的过参数化和优化难题，为近期量子设备上的变分量子优化提供了一个实用且可扩展的范式。

Abstract: We introduce a novel quantum optimization paradigm: the Fixed-Parameter-Count Quantum Approximate Optimization Algorithm (FPC-QAOA). It is a scalable variational framework that maintains a constant number of trainable parameters regardless of the number of qubits, Hamiltonian complexity, or circuit depth. By separating schedule function optimization from circuit digitization, FPC-QAOA enables accurate schedule approximations with minimal parameters while supporting arbitrarily deep digitized adiabatic evolutions, constrained only by NISQ hardware capabilities. This separation allows depth to scale without expanding the classical search space, mitigating overparameterization and optimization challenges typical of deep QAOA circuits, such as barren plateaus-like behaviors. We benchmark FPC-QAOA on random MaxCut instances and the Tail Assignment Problem, achieving performance comparable to or better than standard QAOA with nearly constant classical effort and significantly fewer quantum circuit evaluations. Experiments on the IBM Kingston superconducting processor with up to 50 qubits confirm robustness and hardware efficiency under realistic noise. These results position FPC-QAOA as a practical and scalable paradigm for variational quantum optimization on near-term quantum devices.

</details>


### [21] [Interaction-Resilient Scalable Fluxonium Architecture with All-Microwave Gates](https://arxiv.org/abs/2512.21189)
*Andrei A. Kugut,Grigoriy S. Mazhorin,Ilya A. Simakov*

Main category: quant-ph

TL;DR: 提出了一种基于fluxonium量子比特的方形网格架构，通过微波驱动transmon耦合器实现快速CZ门，并采用多种设计策略抑制长程寄生相互作用，同时支持快速三量子比特CZZ门操作。


<details>
  <summary>Details</summary>
Motivation: Fluxonium量子比特在量子处理方面展现出巨大潜力，但实现可扩展架构仍然面临挑战。主要困难在于大规模系统中全微波门控和强静态耦合会引发超出最近邻的寄生相互作用。

Method: 提出fluxonium方形网格设计，采用微波驱动transmon耦合器实现快速CZ门。通过三种策略抑制寄生相互作用：1) 量子比特和耦合器的频率分配；2) 耦合器波函数局域化；3) 差分振荡器抑制残余长程相互作用。

Result: 实现了约63纳秒的快速CZ门，相干误差低于10^-4。同时支持约70纳秒的CZZ门（三量子比特操作），与顺序执行两个CZ门相比，非相干误差降低约35%。

Conclusion: 这些进展建立了一个相互作用弹性平台，适用于大规模fluxonium处理器，并且可以适应各种fluxonium布局，为可扩展量子计算提供了有前景的解决方案。

Abstract: Fluxonium qubits demonstrate exceptional potential for quantum processing; yet, realizing scalable architectures using them remains challenging. We propose a fluxonium-based square-grid design with fast $\sim63$~ns controlled-Z (CZ) gates, achieving coherent errors below $10^{-4}$, activated via microwave-driven transmon couplers. A central difficulty in such large-scale systems with all-microwave gates and, therefore, strong static couplings, is suppressing parasitic interactions that extend beyond nearest neighbors to include next-nearest elements. We address this issue by introducing several design strategies: the frequency allocation of both qubits and couplers, the localization of coupler wavefunctions, and a differential oscillator that suppresses residual long-range interactions. In addition, the architecture natively supports fast $\sim70$~ns CZZ gates -- three-qubit operations composed of two CZ gates sharing a common qubit -- which reduce the incoherent error by $\sim 35\%$ compared to performing the corresponding CZs sequentially. Together, these advances establish an interaction-resilient platform for large-scale fluxonium processors and can be adapted to a variety of fluxonium layouts.

</details>


### [22] [All-optical control and multiplexed readout of multiple superconducting qubits](https://arxiv.org/abs/2512.21199)
*Xiaoxuan Pan,Chuanlong Ma,Jia-Qi Wang,Zheng-Xu Zhu,Linze Li,Jiajun Chen,Yuan-Hao Yang,Yilong Zhou,Jia-Hua Zou,Xin-Biao Xu,Weiting Wang,Baile Chen,Haifeng Yu,Chang-Ling Zou,Luyan Sun*

Main category: quant-ph

TL;DR: 光学I/O架构用于超导量子电路，通过光学光子传输所有控制和读取信号，解决了大规模量子处理器I/O瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 超导量子电路需要大量微波电缆连接室温控制电子设备，当扩展到数百个量子比特时面临严重的I/O瓶颈，包括物理空间、热负载、布线复杂性和成本等问题。

Method: 采用宽带行波布里渊微波-光学转换器实现频率复用光学读取两个量子比特，结合光纤集成光电二极管阵列传输控制信号，形成闭环光学I/O系统。

Result: 光学I/O系统不会显著降低量子比特相干时间，光学驱动的单量子比特门保真度仅比标准微波操作降低0.19%，成功实现两个量子比特的同时频率复用光学读取。

Conclusion: 光学互连为大规模超导量子处理器提供了可行路径，并开启了通过集中式室温控制基础设施连接多个独立稀释制冷器中超导量子计算机的可能性。

Abstract: Superconducting quantum circuits operate at millikelvin temperatures, typically requiring independent microwave cables for each qubit for connecting room-temperature control and readout electronics. However, scaling to large-scale processors hosting hundreds of qubits faces a severe input/output (I/O) bottleneck, as the dense cable arrays impose prohibitive constraints on physical footprint, thermal load, wiring complexity, and cost. Here we demonstrate a complete optical I/O architecture for superconducting quantum circuits, in which all control and readout signals are transmitted exclusively via optical photons. Employing a broadband traveling-wave Brillouin microwave-to-optical transducer, we achieve simultaneous frequency-multiplexed optical readout of two qubits. Combined with fiber-integrated photodiode arrays for control signal delivery, this closed-loop optical I/O introduces no measurable degradation to qubit coherence times, with an optically driven single-qubit gate fidelity showing only a 0.19% reduction relative to standard microwave operation. These results establish optical interconnects as a viable path toward large-scale superconducting quantum processors, and open the possibility of networking multiple superconducting quantum computers housed in separate dilution refrigerators through a centralized room-temperature control infrastructure.

</details>


### [23] [3D cavity-based graphene superconducting quantum circuits in two-qubit architectures](https://arxiv.org/abs/2512.21213)
*Kuei-Lin Chiu,Avishma J. Lasrado,Cheng-Han Lo,Yen-Chih Chen,Shih-Po Shih,Yen-Hsiang Lin,Chung-Ting Ke*

Main category: quant-ph

TL;DR: 该研究构建了基于石墨烯的超导量子电路并将其集成到3D腔体中，展示了可调谐的单量子比特特性以及多量子比特与腔体的耦合机制。


<details>
  <summary>Details</summary>
Motivation: 探索二维材料（如石墨烯）在超导量子电路中的应用潜力，特别是如何将基于2D材料的量子器件与3D腔体结构有效耦合，为构建多量子比特3D transmon器件奠定基础。

Method: 构建石墨烯基超导量子电路并集成到3D腔体中：1）单量子比特器件展示磁通可调谐特性；2）通过不同谐振频率的腔体访问多种量子比特-腔体耦合机制；3）双量子比特器件（SQUID和单结）进行功率相关测量，分析色散位移。

Result: 单量子比特T1≈48 ns，T2*≥17.63 ns；观察到真空Rabi分裂和磁通依赖的谱线宽度；双量子比特器件显示两阶段色散位移，证实了固定量子比特与SQUID量子比特通过单一腔模的成功耦合。

Conclusion: 研究证明了2D材料基超导电路与3D腔体之间可实现灵活耦合，为从二维材料构建多量子比特3D transmon器件开辟了道路。

Abstract: We construct a series of graphene-based superconducting quantum circuits and integrate them into 3D cavities. For a single-qubit device, we demonstrate flux-tunable qubit transition, with a measured $T_1$ $\approx$ 48 ns and a lower bound estimate of $T_2^\ast$ $\approx$ 17.63 ns. By coupling the device to cavities with different resonant frequencies, we access multiple qubit-cavity coupling regimes, enabling the observation of vacuum Rabi splitting and flux-dependent spectral linewidths. In a two-qubit device consisting of a SQUID and a single junction, power-dependent measurements reveal a two-stage dispersive shift. By flux-tuning the cavity frequency at different readout powers, we attribute the first shift to the fixed-qubit and the second to the SQUID-qubit, indicating successful coupling between the two circuits and a single cavity mode. Our study demonstrates the flexible coupling achievable between 2D-material-based superconducting circuits and 3D cavities, and paves the way toward constructing multi-qubit 3D transmon devices from 2D materials.

</details>


### [24] [Squeezed quantum multiplets: properties and phase space representation](https://arxiv.org/abs/2512.21229)
*Juan Pablo Paz,Corina Révora,Christian Tomás Schmiegelow*

Main category: quant-ph

TL;DR: 该论文研究了"压缩量子多重态"的定义和性质，包括普通压缩多重态和高阶压缩多重态，分析了它们的相似性和差异，并展示了它们在计量学应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究压缩量子多重态的性质，特别是探索高阶压缩态（如三压缩和四压缩态）的特性，以及它们在相位空间中的分布，旨在发现这些量子态在计量学应用中的潜在价值。

Method: 定义并研究压缩量子多重态，包括普通多重态（p=2）和高阶多重态（p>2）。通过分析相位空间分布（Wigner函数和特征函数）的解析表达式，比较不同类型多重态的性质。

Result: 发现普通压缩多重态和高阶压缩多重态具有重要的相似性和差异。推导出普通压缩多重态的相位空间分布解析表达式，并证明某些压缩多重态对所有相位空间方向的扰动高度敏感。

Conclusion: 压缩量子多重态，特别是那些对相位空间扰动高度敏感的态，在计量学应用中具有重要价值，为量子计量学提供了新的研究方向。

Abstract: We define and study the properties of ``squeezed quantum multiplets''. Ordinary multiplets are sets of $D$-orthonormal quantum states formed by superpositions of states squeezed along $D$ equally spaced directions in quadrature space. More generally, we also discuss superpositions of ``higher-order squeezed states'', including tri-squeezed and quad-squeezed states. All these states involve superpositions of multiples of $p$ photons. We compare states in ordinary ($p=2$) multiplets and higher-order ones ($p>2$) in the most relevant cases, showing that ordinary squeezed multiplets and higher-order ones share some important similarities, as well as some differences. Finally, we present analytical expressions for phase-space distributions (Wigner and characteristic functions) representing ordinary squeezed multiplets. We use this to show that some squeezed multiplets are highly sensitive to perturbations in all phase-space directions, making them interesting for metrological applications.

</details>


### [25] [Random dilation superchannel](https://arxiv.org/abs/2512.21260)
*Satoshi Yoshida,Ryotaro Niwa,Mio Murao*

Main category: quant-ph

TL;DR: 提出一种实现随机扩张超通道的量子电路，将未知量子通道的并行查询转换为随机选择扩张等距的并行查询，基于量子Schur变换和对称群上的量子傅里叶变换，复杂度为多项式级别。


<details>
  <summary>Details</summary>
Motivation: 随机纯化通道可以将未知混合态副本转换为随机选择纯化态副本，本文旨在将这一概念推广到量子通道层面，构建随机扩张超通道，实现未知量子通道的高效存储和检索。

Method: 基于量子Schur变换和对称群上的量子傅里叶变换构建量子电路，实现随机扩张超通道，电路复杂度为O(poly(n, log d_I, log d_O))，其中n为查询次数，d_I和d_O分别为输入输出维度。

Result: 1) 实现了随机扩张超通道的高效构造；2) 展示了未知量子通道的高效存储和检索，在检索误差ε方面指数级改进程序成本；3) 对于最小Kraus秩情况，展示了将n个并行查询转换为Θ(n^α)个并行查询的量子电路；4) 结果可扩展到量子超通道情况。

Conclusion: 成功构建了实现随机扩张超通道的量子电路，为量子通道的高效处理提供了新工具，在量子信息处理中具有重要应用价值，特别是在量子通道的存储、检索和变换方面取得了显著进展。

Abstract: We present a quantum circuit that implements the random dilation superchannel, transforming parallel queries of an unknown quantum channel into parallel queries of a randomly chosen dilation isometry of the input channel. This is a natural generalization of a random purification channel, that transforms copies of an unknown mixed state to copies of a randomly chosen purification state. Our construction is based on the quantum Schur transform and the quantum Fourier transform over the symmetric group. By using the efficient construction of these quantum transforms, we can implement the random dilation superchannel with the circuit complexity $O(\mathrm{poly}(n, \log d_I, \log d_O))$, where $n$ is the number of queries and $d_I$ and $d_O$ are the input and output dimensions of the input channel, respectively. As an application, we show an efficient storage-and-retrieval of an unknown quantum channel, which improves the program cost exponentially in the retrieval error $\varepsilon$. For the case where the Kraus rank $r$ is the least possible (i.e., $r = d_I/d_O$), we show quantum circuits transforming $n$ parallel queries of an unknown quantum channel $Λ$ to $Θ(n^α)$ parallel queries of $Λ$ for any $α<2$ approximately, and its Petz recovery map for the reference state given by the maximally mixed state probabilistically and exactly. We also show that our results can be further extended to the case of quantum superchannels.

</details>


### [26] [Characterizing quantum synchronization in the van der Pol oscillator via tomogram and photon correlation](https://arxiv.org/abs/2512.21272)
*Kingshuk Adhikary,K. M. Athira,M. Rohith*

Main category: quant-ph

TL;DR: 该论文通过非经典面积δ和第二阶关联函数g²(0)两个实验可行的度量指标，研究驱动量子van der Pol振荡器稳态中的量子同步现象，揭示了相位锁定行为和同步区域（Arnold舌）


<details>
  <summary>Details</summary>
Motivation: 研究量子van der Pol振荡器中的量子同步现象，开发实验可行的度量方法，避免需要完整态重构或Wigner函数负性分析的传统复杂方法

Method: 使用基于零差层析的非经典面积δ和第二阶关联函数g²(0)作为同步度量指标，推导稳态密度矩阵和层析图的解析表达式，分析驱动强度和失谐参数下的同步特征

Result: 在特定驱动强度和失谐参数范围内，δ和g²(0)都显示出明显的同步特征，与驱动和振荡器之间的相位相干性互补；量子层析图揭示了清晰的相位锁定行为，可直接识别同步区域

Conclusion: 非经典面积δ和第二阶关联函数g²(0)是实验可行的量子同步有效度量指标，通过分析这两个指标的相互作用，可以更深入地理解量子同步的底层机制

Abstract: We access the quantum synchronization (QS) in the steady state of a driven quantum van der Pol oscillator (vdPo) using two distinct figures of merit: (i) the nonclassical area $δ$ and (ii) the second-order correlation function $g^{(2)}(0)$, which are both viable in experimental architectures. The nonclassical area quantifier rooted in homodyne tomography, allows us to assess the nonclassical nature of the vdPo's state directly from the tomogram without requiring full state reconstruction or the Wigner function negativity. Within a well-defined parameter regime of drive strength and detuning, both $δ$ and $g^{(2)}(0)$ exhibit pronounced signatures of synchronization that complements the phase coherence between the drive and the vdPo. We derive an analytical expression for the steady-state density matrix and the corresponding tomogram of the system, valid for arbitrary strengths of the harmonic drive. Analysis of the quantum tomogram uncovers clear phase-locking behavior, enabling the identification of the synchronization region (Arnold tongue) directly in terms of experimentally measurable quantities. Furthermore, the behaviour of $g^{(2)}(0)$ provides a statistical perspective that reinforces the tomographic signatures of QS. By analyzing the interplay between these metrics, we can gain more profound insights into the underlying mechanisms that govern QS in such systems.

</details>


### [27] [Quantum computation of mass gap in an asymptotically free theory](https://arxiv.org/abs/2512.21282)
*Paulo F. Bedaque,Edison M. Murairi,Gautam Rupak,Valery S. Simonyan*

Main category: quant-ph

TL;DR: 提出一种使用量子计算机直接提取质量间隙的方法，应用于非线性σ模型，并在量子硬件（强耦合）和经典计算机模拟（弱耦合）中验证。


<details>
  <summary>Details</summary>
Motivation: 在相对论场论中，质量谱由真空态和激发态的能量差给出。在连续极限附近，这两个值的抵消会导致精度损失，需要更精确的方法来提取质量间隙。

Method: 提出使用量子计算机直接提取质量间隙的方法，应用于特定版本的非线性σ模型（具有正确连续极限），在量子硬件上进行强耦合计算，在经典计算机上进行弱耦合模拟。

Result: 该方法成功在量子硬件（强耦合）和经典计算机模拟（弱耦合）中实现了质量间隙的提取，验证了量子计算在场论质量谱计算中的应用潜力。

Conclusion: 量子计算机可以直接有效地提取场论中的质量间隙，为研究相对论场论的连续极限提供了新的计算工具，特别是在传统方法面临精度损失的情况下。

Abstract: In relativistic field theories, the mass spectrum is given by the difference between the energy of the vacuum and the excited states. Near the continuum limit, the cancellation between these two values leads to loss of precision. We propose a method to extract the mass gap directly using quantum computers and apply it to a particular version of the nonlinear $σ$-model with the correct continuum limit and perform calculations in quantum hardware (at strong coupling) and simulation in classical computers (at weak coupling).

</details>


### [28] [A Note on Publicly Verifiable Quantum Money with Low Quantum Computational Resources](https://arxiv.org/abs/2512.21304)
*Fabrizio Genovese,Lev Stambler*

Main category: quant-ph

TL;DR: 提出一种基于一次性存储器的公开可验证量子货币协议，无需复杂量子计算能力，支持有限次验证和数字签名量子令牌


<details>
  <summary>Details</summary>
Motivation: 传统量子货币方案通常需要复杂的量子计算能力，限制了实际应用。本文旨在开发一种几乎不需要量子计算能力的公开可验证量子货币协议，降低实现门槛

Method: 基于一次性存储器构建协议，一次性存储器可通过量子共轭编码和硬件假设实现。利用共轭编码态的不可克隆原理防止双重支付，支持有限次验证和数字签名量子令牌

Result: 成功设计出公开可验证的量子货币协议，该协议对量子计算能力要求极低，能够防止双重支付，并已在GitHub上提供概念实现

Conclusion: 该工作展示了基于一次性存储器和共轭编码的量子货币方案可行性，为低量子计算能力环境下的量子货币应用提供了新途径，具有实际部署潜力

Abstract: In this work we present a publicly verifiable quantum money protocol which assumes close to no quantum computational capabilities. We rely on one-time memories which in turn can be built from quantum conjugate coding and hardware-based assumptions. Specifically, our scheme allows for a limited number of verifications and also allows for quantum tokens for digital signatures. Double spending is prevented by the no-cloning principle of conjugate coding states. An implementation of the concepts presented in this work can be found at https://github.com/neverlocal/otm_billz.

</details>


### [29] [Optimizing Quantum State Transformation Under Locality Constraint](https://arxiv.org/abs/2512.21310)
*Sasan Sarbishegi,Maryam Sadat Mirkamali*

Main category: quant-ph

TL;DR: 提出一个在局域约束下进行确定性和概率性量子态转换的通用数值框架，通过优化局部量子通道实现高保真度转换，显著提升弱纠缠态的纠缠蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理中需要在局域约束下进行量子态转换，特别是纠缠蒸馏等任务。现有方法可能不够高效，需要一种通用框架来处理确定性和概率性的量子态转换问题。

Method: 将局部量子通道参数化在复Stiefel流形上，使用基于梯度的优化方法构建优化的局部量子通道，实现从任意二分初始态到目标态的高保真度转换。

Result: 该方法显著增强了弱纠缠态的纠缠蒸馏效果，通过两种互补策略：优化的局部态转换和概率性局部转换，证明了该框架的有效性和通用性。

Conclusion: 该数值框架为广泛的量子信息处理任务提供了一个强大而通用的工具，特别适用于局域约束下的量子态转换和纠缠蒸馏问题。

Abstract: In this paper, we present a general numerical framework for both deterministic and probabilistic quantum state transformations, under locality constraints. For a given arbitrary bipartite initial state and a desired bipartite target state, we construct an optimized local quantum channel that transforms the initial state into the target state with high fidelity. To achieve this goal, local quantum channels are parametrized on a complex Stiefel manifold and optimized using gradient-based methods. We demonstrate that this approach significantly enhances entanglement distillation for weakly entangled states via two complementary strategies: optimized local state transformation and probabilistic local transformation. These results establish our method as a powerful and versatile tool for a broad class of quantum information processing tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [30] [Forecasting N-Body Dynamics: A Comparative Study of Neural Ordinary Differential Equations and Universal Differential Equations](https://arxiv.org/abs/2512.20643)
*Suriya R S,Prathamesh Dinesh Joshi,Rajat Dandekar,Raj Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: 使用Julia编程语言中的科学机器学习框架（神经ODE和通用ODE）解决n体问题，相比传统黑盒模型更符合物理规律且可解释，其中通用ODE模型仅需20%数据即可准确预测，而神经ODE需要90%数据。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型用于预测天体轨迹时通常是数据密集型的黑盒模型，忽略了物理定律，缺乏可解释性。科学机器学习可以直接将已知物理定律嵌入机器学习框架，提高模型的物理合理性和可解释性。

Method: 使用Julia编程语言中的科学机器学习框架：神经常微分方程（NODEs）和通用常微分方程（UDEs）来预测和预报系统动力学。利用合成噪声数据模拟现实观测限制，并确定预测崩溃点（模型准确预测未来未见数据所需的最小训练数据量）。

Result: UDE模型数据效率更高，仅需20%的数据即可正确预测，而神经ODE模型需要90%的数据。这表明将物理知识嵌入机器学习框架可以显著提高数据效率。

Conclusion: 科学机器学习方法（特别是UDE）在解决n体问题中表现出优越的数据效率和物理一致性，为天体物理模拟提供了一种更高效且可解释的替代方案。

Abstract: The n body problem, fundamental to astrophysics, simulates the motion of n bodies acting under the effect of their own mutual gravitational interactions. Traditional machine learning models that are used for predicting and forecasting trajectories are often data intensive black box models, which ignore the physical laws, thereby lacking interpretability. Whereas Scientific Machine Learning ( Scientific ML ) directly embeds the known physical laws into the machine learning framework. Through robust modelling in the Julia programming language, our method uses the Scientific ML frameworks: Neural ordinary differential equations (NODEs) and Universal differential equations (UDEs) to predict and forecast the system dynamics. In addition, an essential component of our analysis involves determining the forecasting breakdown point, which is the smallest possible amount of training data our models need to predict future, unseen data accurately. We employ synthetically created noisy data to simulate real-world observational limitations. Our findings indicate that the UDE model is much more data efficient, needing only 20% of data for a correct forecast, whereas the Neural ODE requires 90%.

</details>


### [31] [Parameter-Efficient Neural CDEs via Implicit Function Jacobians](https://arxiv.org/abs/2512.20625)
*Ilya Kuleshov,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 提出参数高效的Neural CDE替代方案，大幅减少参数数量，同时实现"连续RNN"的类比


<details>
  <summary>Details</summary>
Motivation: Neural CDE虽然适合分析时间序列，但参数数量过多，需要更高效的替代方案

Method: 提出参数高效的Neural CDE替代方法，实现"连续RNN"的类比

Result: 新方法大幅减少参数数量，同时保持逻辑类比性

Conclusion: 提出的参数高效Neural CDE替代方案解决了原方法的参数过多问题，实现了更实用的"连续RNN"

Abstract: Neural Controlled Differential Equations (Neural CDEs, NCDEs) are a unique branch of methods, specifically tailored for analysing temporal sequences. However, they come with drawbacks, the main one being the number of parameters, required for the method's operation. In this paper, we propose an alternative, parameter-efficient look at Neural CDEs. It requires much fewer parameters, while also presenting a very logical analogy as the "Continuous RNN", which the Neural CDEs aspire to.

</details>


### [32] [Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning](https://arxiv.org/abs/2512.20629)
*Wenlong Tang*

Main category: cs.LG

TL;DR: 提出一个无需微调语言模型参数的多智能体语言框架，通过外部潜在向量实现持续策略演化，构建行为循环和语言循环的双循环架构。


<details>
  <summary>Details</summary>
Motivation: 传统静态语义表示限制了抽象概念的演化能力，需要一种无需修改模型参数的低成本、可扩展且可解释的抽象策略表示方法。

Method: 构建双循环架构：行为循环基于环境奖励调整行动偏好；语言循环通过反思生成文本的语义嵌入来更新外部潜在向量。解放抽象概念的潜在向量，使其通过环境交互和强化反馈持续更新。

Result: 智能体的潜在空间在反思驱动更新下呈现清晰的收敛轨迹和关键时刻的结构性转变；系统展现出无需共享奖励即可隐式推断并持续适应情感智能体的涌现能力。

Conclusion: 外部潜在空间可为语言智能体提供低成本、可扩展且可解释的抽象策略表示形式，无需修改模型参数即可实现持续策略演化。

Abstract: This study proposes a multi-agent language framework that enables continual strategy evolution without fine-tuning the language model's parameters. The core idea is to liberate the latent vectors of abstract concepts from traditional static semantic representations, allowing them to be continuously updated through environmental interaction and reinforcement feedback. We construct a dual-loop architecture: the behavior loop adjusts action preferences based on environmental rewards, while the language loop updates the external latent vectors by reflecting on the semantic embeddings of generated text.
  Together, these mechanisms allow agents to develop stable and disentangled strategic styles over long-horizon multi-round interactions. Experiments show that agents' latent spaces exhibit clear convergence trajectories under reflection-driven updates, along with structured shifts at critical moments. Moreover, the system demonstrates an emergent ability to implicitly infer and continually adapt to emotional agents, even without shared rewards. These results indicate that, without modifying model parameters, an external latent space can provide language agents with a low-cost, scalable, and interpretable form of abstract strategic representation.

</details>


### [33] [Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams](https://arxiv.org/abs/2512.20631)
*Aayam Bansal,Ishaan Gangwani*

Main category: cs.LG

TL;DR: 该论文提出了一种无需训练的零训练时间漂移分析方法，用于评估Transformer情感模型在真实社交媒体数据上的稳定性，通过系统评估发现事件驱动期间模型准确率下降可达23.4%，并引入了四个优于基线的新漂移指标。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在动态社交媒体内容上的稳定性问题，特别是在重大现实事件期间，模型性能可能显著下降，需要有效的零训练方法来实时监控模型漂移。

Method: 提出零训练时间漂移分析方法，系统评估三种Transformer架构，在12,279个真实社交媒体帖子上进行统计验证，引入四个新颖的漂移指标，这些指标优于基于嵌入的基线方法且计算高效。

Result: 发现模型在事件驱动期间显著不稳定，准确率下降最高达23.4%，最大置信度下降13.0%（Bootstrap 95% CI: [9.1%, 16.5%]），漂移指标与性能下降强相关，检测能力超过行业监控阈值。

Conclusion: 这种零训练方法可直接部署于实时情感监控系统，为Transformer模型在动态内容期间的行为提供了新见解，具有实际生产部署价值。

Abstract: We present a comprehensive zero-training temporal drift analysis of transformer-based sentiment models validated on authentic social media data from major real-world events. Through systematic evaluation across three transformer architectures and rigorous statistical validation on 12,279 authentic social media posts, we demonstrate significant model instability with accuracy drops reaching 23.4% during event-driven periods. Our analysis reveals maximum confidence drops of 13.0% (Bootstrap 95% CI: [9.1%, 16.5%]) with strong correlation to actual performance degradation. We introduce four novel drift metrics that outperform embedding-based baselines while maintaining computational efficiency suitable for production deployment. Statistical validation across multiple events confirms robust detection capabilities with practical significance exceeding industry monitoring thresholds. This zero-training methodology enables immediate deployment for real-time sentiment monitoring systems and provides new insights into transformer model behavior during dynamic content periods.

</details>


### [34] [Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models](https://arxiv.org/abs/2512.20633)
*MunHwan Lee,Shaika Chowdhury,Xiaodi Li,Sivaraman Rajaganapathy,Eric W Klee,Ping Yang,Terence Sio,Liewei Wang,James Cerhan,Nansu NA Zong*

Main category: cs.LG

TL;DR: 提出GKC框架，利用LLM作为目标导向的知识策展器，将多模态临床数据转化为任务对齐的特征表示，在肺癌治疗结果预测中优于传统方法


<details>
  <summary>Details</summary>
Motivation: 肺癌治疗结果预测面临挑战：真实世界电子健康数据稀疏、异质且上下文过载；传统模型难以捕捉多模态流的语义信息；大规模微调方法在临床工作流中不实用

Method: 引入GKC框架：使用LLM作为目标导向的知识策展器，将实验室、基因组和药物数据转化为高保真、任务对齐的特征表示；作为离线预处理步骤，自然集成到医院信息管道中

Result: 在肺癌队列(N=184)中，GKC平均AUROC为0.803(95% CI: 0.799-0.807)，优于专家工程特征、直接文本嵌入和端到端transformer；消融研究证实三种模态的组合具有互补价值

Conclusion: 语义表示质量是稀疏临床数据预测准确性的关键决定因素；将LLM重新定义为知识策展引擎而非黑盒预测器，为肿瘤学AI决策支持提供了可扩展、可解释且与工作流兼容的途径

Abstract: Accurate prediction of treatment outcomes in lung cancer remains challenging due to the sparsity, heterogeneity, and contextual overload of real-world electronic health data. Traditional models often fail to capture semantic information across multimodal streams, while large-scale fine-tuning approaches are impractical in clinical workflows. We introduce a framework that uses Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to convert laboratory, genomic, and medication data into high-fidelity, task-aligned features. Unlike generic embeddings, GKC produces representations tailored to the prediction objective and operates as an offline preprocessing step that integrates naturally into hospital informatics pipelines. Using a lung cancer cohort (N=184), we benchmarked GKC against expert-engineered features, direct text embeddings, and an end-to-end transformer. Our approach achieved a mean AUROC of 0.803 (95% CI: 0.799-0.807) and outperformed all baselines. An ablation study further confirmed the complementary value of combining all three modalities. These results show that the quality of semantic representation is a key determinant of predictive accuracy in sparse clinical data settings. By reframing LLMs as knowledge curation engines rather than black-box predictors, this work demonstrates a scalable, interpretable, and workflow-compatible pathway for advancing AI-driven decision support in oncology.

</details>


### [35] [Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning](https://arxiv.org/abs/2512.20634)
*Weiwei Wang*

Main category: cs.LG

TL;DR: 提出浅层对齐与深层对齐框架，量化分析大语言模型持续学习中的灾难性遗忘问题，开发实时检测工具和自适应缓解策略，显著提升模型抗遗忘能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现持续学习中的性能下降可能源于任务对齐破坏而非真实知识丢失，但仅定性描述对齐现象，依赖事后分析，缺乏自动区分机制。需要量化表征对齐深度，解决浅层对齐导致的易遗忘问题。

Method: 提出浅层对齐与深层对齐框架：1) 开发0-1量表的量化指标测量不同token位置的对齐深度；2) 训练中实时检测浅层对齐的方法；3) 可视化与恢复预测的专门分析工具；4) 自动区分遗忘类型并促进深层对齐的自适应缓解策略。

Result: 在多个数据集和模型架构（Qwen2.5-3B到Qwen2.5-32B）上的实验表明：识别准确率达到86.2-90.6%；促进深层对齐相比基线将抗遗忘鲁棒性提升了3.3-7.1%。

Conclusion: 浅层对齐是持续学习中灾难性遗忘的关键原因，提出的量化框架能有效识别和缓解该问题，通过促进深层对齐显著提升大语言模型的抗遗忘能力。

Abstract: Catastrophic forgetting remains a fundamental challenge in continual learning for large language models. Recent work revealed that performance degradation may stem from spurious forgetting caused by task alignment disruption rather than true knowledge loss. However, this work only qualitatively describes alignment, relies on post-hoc analysis, and lacks automatic distinction mechanisms.
  We introduce the shallow versus deep alignment framework, providing the first quantitative characterization of alignment depth. We identify that current task alignment approaches suffer from shallow alignment - maintained only over the first few output tokens (approximately 3-5) - making models vulnerable to forgetting. This explains why spurious forgetting occurs, why it is reversible, and why fine-tuning attacks are effective.
  We propose a comprehensive framework addressing all gaps: (1) quantitative metrics (0-1 scale) to measure alignment depth across token positions; (2) real-time detection methods for identifying shallow alignment during training; (3) specialized analysis tools for visualization and recovery prediction; and (4) adaptive mitigation strategies that automatically distinguish forgetting types and promote deep alignment. Extensive experiments on multiple datasets and model architectures (Qwen2.5-3B to Qwen2.5-32B) demonstrate 86.2-90.6% identification accuracy and show that promoting deep alignment improves robustness against forgetting by 3.3-7.1% over baselines.

</details>


### [36] [SHRP: Specialized Head Routing and Pruning for Efficient Encoder Compression](https://arxiv.org/abs/2512.20635)
*Zeli Su,Ziyin Zhang,Wenzheng Zhang,Zhou Liu,Guixian Xu,Wentao Zhang*

Main category: cs.LG

TL;DR: SHRP是一种专门针对Transformer编码器的结构化剪枝框架，通过将注意力头视为独立专家，结合轻量级共享扩展前馈网络，实现冗余注意力头的自动识别和移除，在保持模型精度的同时大幅减少参数和计算量。


<details>
  <summary>Details</summary>
Motivation: Transformer编码器在自然语言理解任务中广泛部署，但其高推理延迟和内存消耗对实时服务和可扩展性构成挑战。这些限制主要源于架构冗余，特别是注意力模块的参数冗余和注意力头相对独立操作的特点，使其特别适合结构化模型压缩。

Method: 提出SHRP框架：1）引入专家注意力机制，将每个注意力头视为独立专家；2）使用轻量级共享扩展前馈网络精炼输出；3）采用统一的Top-1使用驱动机制，在训练时进行动态路由，在部署时进行确定性剪枝。

Result: 在GLUE基准测试中使用BERT-base编码器：1）保持93%原始模型精度，减少48%参数；2）极端压缩场景（剪除11/12层）下，仍保持84%精度，吞吐量提升4.2倍，计算量降至原始FLOPs的11.5%。

Conclusion: SHRP框架有效解决了Transformer编码器在实时服务中的延迟和内存问题，通过结构化剪枝在保持模型性能的同时显著提升效率，特别适用于大规模、延迟敏感的Web部署场景。

Abstract: Transformer encoders are widely deployed in large-scale web services for natural language understanding tasks such as text classification, semantic retrieval, and content ranking. However, their high inference latency and memory consumption pose significant challenges for real-time serving and scalability. These limitations stem largely from architectural redundancy, particularly in the attention module. The inherent parameter redundancy of the attention mechanism, coupled with the fact that its attention heads operate with a degree of independence, makes it particularly amenable to structured model compression. In this paper, we propose SHRP (Specialized Head Routing and Pruning), a novel structured pruning framework that automatically identifies and removes redundant attention heads while preserving most of the model's accuracy and compatibility. SHRP introduces Expert Attention, a modular design that treats each attention head as an independent expert, followed by a lightweight shared expander feed-forward network that refines their outputs. The framework employs a unified Top-1 usage-driven mechanism to jointly perform dynamic routing during training and deterministic pruning at deployment. Experimental results on the GLUE benchmark using a BERT-base encoder show that SHRP achieves 93% of the original model accuracy while reducing parameters by 48 percent. Under an extreme compression scenario where 11/12 of the layers are pruned, the model still maintains 84% accuracy and delivers a 4.2x throughput gain while reducing computation to as low as 11.5 percent of the original FLOPs, demonstrating its practical utility for large-scale and latency-sensitive web deployments.

</details>


### [37] [Data-Free Pruning of Self-Attention Layers in LLMs](https://arxiv.org/abs/2512.20636)
*Dhananjay Saikumar,Blesson Varghese*

Main category: cs.LG

TL;DR: 提出Gate-Norm方法，通过分析注意力层中query-key耦合程度，无需数据、前向传播或微调，即可快速剪枝LLM中贡献较小的注意力子层，提升推理速度同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中许多注意力子层可以被移除而几乎不影响性能，这归因于"注意力抑制假说"：在预训练过程中，一些深层注意力层学会了抑制自身贡献，让残差流和MLP承载表示。

Method: 提出Gate-Norm准则，这是一种一次性、仅权重的标准，通过查询-键耦合程度对注意力子层进行排序，移除耦合最弱的层。该方法无需校准数据、前向传播、微调或专用内核。

Result: 在40层、130亿参数的LLaMA模型上，Gate-Norm在1秒内完成剪枝。剪除8-16个注意力子层可使推理吞吐量提升1.3倍，同时在多个基准测试（BoolQ、RTE等）上保持平均零样本准确率在未剪枝基线的2%以内。

Conclusion: Gate-Norm在精度上与数据驱动剪枝方法相当，但评分层速度快约1000倍，实现了实用、无需数据的LLM压缩，为高效推理提供了有效解决方案。

Abstract: Many self-attention sublayers in large language models (LLMs) can be removed with little to no loss. We attribute this to the Attention Suppression Hypothesis: during pre-training, some deep attention layers learn to mute their own contribution, leaving the residual stream and the MLP to carry the representation. We propose Gate-Norm, a one-shot, weight-only criterion that ranks attention sublayers by query--key coupling and removes the least coupled ones, requiring no calibration data, no forward passes, no fine-tuning, and no specialized kernels. On 40-layer, 13B-parameter LLaMA models, Gate-Norm prunes the model in under a second. Pruning $8$--$16$ attention sublayers yields up to $1.30\times$ higher inference throughput while keeping average zero-shot accuracy within $2\%$ of the unpruned baseline across BoolQ, RTE, HellaSwag, WinoGrande, ARC-Easy/Challenge, and OpenBookQA. Across these settings, Gate-Norm matches data-driven pruning methods in accuracy while being $\sim 1000\times$ faster to score layers, enabling practical, data-free compression of LLMs.

</details>


### [38] [Q-RUN: Quantum-Inspired Data Re-uploading Networks](https://arxiv.org/abs/2512.20654)
*Wenbo Qiao,Shuaixian Wang,Peng Zhang,Yan Ming,Jiaming Zhao*

Main category: cs.LG

TL;DR: 量子启发数据重上传网络(Q-RUN)将量子数据重上传电路原理引入经典模型，无需量子硬件即可获得量子模型的傅里叶表达能力优势，在减少参数的同时显著降低误差。


<details>
  <summary>Details</summary>
Motivation: 量子数据重上传电路(DRQC)在量子神经网络中表现出色，能更好地拟合高频函数，但受限于当前量子硬件的可扩展性。本文旨在将DRQC的数学原理引入经典模型，在无需量子硬件的情况下获得量子模型的优势。

Method: 提出量子启发数据重上传网络(Q-RUN)，将量子数据重上传电路的数学范式引入经典神经网络模型。Q-RUN可以作为标准全连接层的即插即用替代方案，保留量子模型的傅里叶表达能力优势。

Result: 实验表明Q-RUN在数据建模和预测建模任务中均表现优异。相比全连接层和最先进的神经网络层，Q-RUN在减少模型参数的同时，在某些任务上将误差降低了约1-3个数量级。Q-RUN能提升多种神经架构的性能。

Conclusion: 这项工作展示了量子机器学习原理如何指导设计更具表达能力的人工智能模型。Q-RUN成功将量子模型的优势引入经典计算框架，为无需量子硬件的量子启发算法设计提供了范例。

Abstract: Data re-uploading quantum circuits (DRQC) are a key approach to implementing quantum neural networks and have been shown to outperform classical neural networks in fitting high-frequency functions. However, their practical application is limited by the scalability of current quantum hardware. In this paper, we introduce the mathematical paradigm of DRQC into classical models by proposing a quantum-inspired data re-uploading network (Q-RUN), which retains the Fourier-expressive advantages of quantum models without any quantum hardware. Experimental results demonstrate that Q-RUN delivers superior performance across both data modeling and predictive modeling tasks. Compared to the fully connected layers and the state-of-the-art neural network layers, Q-RUN reduces model parameters while decreasing error by approximately one to three orders of magnitude on certain tasks. Notably, Q-RUN can serve as a drop-in replacement for standard fully connected layers, improving the performance of a wide range of neural architectures. This work illustrates how principles from quantum machine learning can guide the design of more expressive artificial intelligence.

</details>


### [39] [MaskOpt: A Large-Scale Mask Optimization Dataset to Advance AI in Integrated Circuit Manufacturing](https://arxiv.org/abs/2512.20655)
*Yuting Hu,Lei Zhuang,Hua Xiang,Jinjun Xiong,Gi-Joon Nam*

Main category: cs.LG

TL;DR: MaskOpt：一个用于单元感知和上下文感知掩模优化的大规模基准数据集，基于45nm节点的真实IC设计构建，包含超过20万个图块，支持不同上下文窗口大小。


<details>
  <summary>Details</summary>
Motivation: 随着集成电路尺寸缩小至低于光刻波长，光学邻近效应校正和逆向光刻技术计算成本高昂。现有深度学习掩模优化数据集多基于合成布局，忽略了标准单元层次结构和周围上下文环境，限制了实际应用。

Method: 从45nm节点的真实IC设计中构建大规模基准数据集MaskOpt，包含104,714个金属层图块和121,952个通孔层图块。每个图块在标准单元放置处裁剪以保留单元信息，支持不同上下文窗口大小来捕捉邻近形状的光学邻近效应影响。

Result: 评估了最先进的深度学习掩模优化模型并建立了基准，评估结果揭示了基线模型之间的不同权衡。上下文大小分析和输入消融研究证实了周围几何形状和单元感知输入对于实现准确掩模生成的重要性。

Conclusion: MaskOpt数据集为单元感知和上下文感知的掩模优化提供了重要基准，证实了考虑周围几何环境和单元层次结构在实际掩模优化中的必要性，推动了深度学习在IC掩模优化领域的实用化发展。

Abstract: As integrated circuit (IC) dimensions shrink below the lithographic wavelength, optical lithography faces growing challenges from diffraction and process variability. Model-based optical proximity correction (OPC) and inverse lithography technique (ILT) remain indispensable but computationally expensive, requiring repeated simulations that limit scalability. Although deep learning has been applied to mask optimization, existing datasets often rely on synthetic layouts, disregard standard-cell hierarchy, and neglect the surrounding contexts around the mask optimization targets, thereby constraining their applicability to practical mask optimization. To advance deep learning for cell- and context-aware mask optimization, we present MaskOpt, a large-scale benchmark dataset constructed from real IC designs at the 45$\mathrm{nm}$ node. MaskOpt includes 104,714 metal-layer tiles and 121,952 via-layer tiles. Each tile is clipped at a standard-cell placement to preserve cell information, exploiting repeated logic gate occurrences. Different context window sizes are supported in MaskOpt to capture the influence of neighboring shapes from optical proximity effects. We evaluate state-of-the-art deep learning models for IC mask optimization to build up benchmarks, and the evaluation results expose distinct trade-offs across baseline models. Further context size analysis and input ablation studies confirm the importance of both surrounding geometries and cell-aware inputs in achieving accurate mask generation.

</details>


### [40] [Managing the Stochastic: Foundations of Learning in Neuro-Symbolic Systems for Software Engineering](https://arxiv.org/abs/2512.20660)
*Matthew Thompson*

Main category: cs.LG

TL;DR: 论文提出了一种双状态架构，将LLM视为环境组件而非决策代理，通过原子动作对和守卫函数实现确定性控制流，显著提升代码生成任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前AI编码代理方法模糊了LLM与代理之间的界限，让LLM承担本应由确定性流程处理的决策任务，导致系统容易出现随机性失败（如游戏化单元测试、语法幻觉）。需要借鉴成熟的软件工程实践，为管理不可预测过程提供确定性框架。

Method: 提出双状态架构：分离工作流状态（确定性控制流）和环境状态（随机生成）。使用原子动作对将生成与验证作为不可分割的事务耦合。守卫函数作为感知动作，将概率性输出投影到可观察的工作流状态。

Result: 在13个LLM（1.3B-15B参数）的三个代码生成任务上进行验证。对于合格的指令跟随模型，任务成功率提高了高达66个百分点，计算成本为基线的1.2-2.1倍。结果表明架构约束可以替代参数规模来实现可靠的代码生成。

Conclusion: 通过将LLM视为环境组件而非决策代理，并采用双状态架构和原子动作对，可以在保持LLM创造性随机性的同时，通过确定性控制流显著提高代码生成系统的可靠性。架构设计可以弥补模型规模的不足。

Abstract: Current approaches to AI coding agents appear to blur the lines between the Large Language Model (LLM) and the agent itself, asking the LLM to make decisions best left to deterministic processes. This leads to systems prone to stochastic failures such as gaming unit tests or hallucinating syntax. Drawing on established software engineering practices that provide deterministic frameworks for managing unpredictable processes, this paper proposes setting the control boundary such that the LLM is treated as a component of the environment environment -- preserving its creative stochasticity -- rather than the decision-making agent.
  A \textbf{Dual-State Architecture} is formalized, separating workflow state (deterministic control flow) from environment state (stochastic generation). \textbf{Atomic Action Pairs} couple generation with verification as indivisible transactions, where \textbf{Guard Functions} act as sensing actions that project probabilistic outputs onto observable workflow state. The framework is validated on three code generation tasks across 13 LLMs (1.3B--15B parameters). For qualified instruction-following models, task success rates improved by up to 66 percentage points at 1.2--2.1$\times$ baseline computational cost. The results suggest that architectural constraints can substitute for parameter scale in achieving reliable code generation.

</details>


### [41] [Dominating vs. Dominated: Generative Collapse in Diffusion Models](https://arxiv.org/abs/2512.20666)
*Hayeon Jeong,Jong-Seok Lee*

Main category: cs.LG

TL;DR: 论文提出DominanceBench来系统分析多概念提示生成中的主导vs被主导（DvD）不平衡问题，发现训练数据实例多样性不足和注意力机制分布是主要原因。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在生成多概念提示时，经常出现一个概念主导生成而抑制其他概念的问题，这种DvD不平衡现象影响了生成的可控性和可靠性。

Method: 引入DominanceBench进行系统分析，从数据和架构两个角度研究原因，包括训练数据多样性分析、交叉注意力动态分析以及注意力头消融研究。

Result: 发现训练数据实例多样性有限加剧了概念间干扰；主导token会快速饱和注意力，在扩散时间步中逐步抑制其他token；DvD行为源于多个注意力头的分布式机制。

Conclusion: 研究结果为生成崩溃提供了关键见解，有助于推进更可靠和可控的文本到图像生成。

Abstract: Text-to-image diffusion models have drawn significant attention for their ability to generate diverse and high-fidelity images. However, when generating from multi-concept prompts, one concept token often dominates the generation, suppressing the others-a phenomenon we term the Dominant-vs-Dominated (DvD) imbalance. To systematically analyze this imbalance, we introduce DominanceBench and examine its causes from both data and architectural perspectives. Through various experiments, we show that the limited instance diversity in training data exacerbates the inter-concept interference. Analysis of cross-attention dynamics further reveals that dominant tokens rapidly saturate attention, progressively suppressing others across diffusion timesteps. In addition, head ablation studies show that the DvD behavior arises from distributed attention mechanisms across multiple heads. Our findings provide key insights into generative collapse, advancing toward more reliable and controllable text-to-image generation.

</details>


### [42] [Forward Only Learning for Orthogonal Neural Networks of any Depth](https://arxiv.org/abs/2512.20668)
*Paul Caillon,Alex Colagrande,Erwan Fagnou,Blaise Delattre,Alexandre Allauzen*

Main category: cs.LG

TL;DR: FOTON是一种无需反向传播的前向训练算法，通过正交网络假设实现与反向传播相当的性能，支持任意深度网络训练


<details>
  <summary>Details</summary>
Motivation: 反向传播算法在大型神经网络中计算成本过高，而现有的前向训练方法（如PEPITA）无法扩展到深层网络，需要一种更高效且可扩展的训练算法

Method: 首先分析现有前向训练方法的局限性，设计在线性和正交假设下与反向传播等价的前向算法，然后放宽线性假设，提出FOTON算法，通过正交网络训练实现

Result: FOTON在性能上超越PEPITA，能够训练任意深度的神经网络，无需反向传播，在卷积网络上也表现出色，为更复杂架构的应用开辟了道路

Conclusion: FOTON提供了一种高效的前向训练替代方案，解决了反向传播的计算负担问题，具有扩展到先进神经网络架构的潜力

Abstract: Backpropagation is still the de facto algorithm used today to
  train neural networks.
  With the exponential growth of recent architectures, the
  computational cost of this algorithm also becomes a burden. The
  recent PEPITA and forward-only frameworks have proposed promising
  alternatives, but they failed to scale up to a handful of hidden
  layers, yet limiting their use.
  In this paper, we first analyze theoretically the main limitations of
  these approaches. It allows us the design of a forward-only
  algorithm, which is equivalent to backpropagation under the linear
  and orthogonal assumptions. By relaxing the linear assumption, we
  then introduce FOTON (Forward-Only Training of Orthogonal Networks)
  that bridges the gap with the backpropagation
  algorithm. Experimental results show that it outperforms PEPITA,
  enabling us to train neural networks of any depth, without the need
  for a backward pass.
  Moreover its performance on convolutional networks clearly opens up avenues for its application to more
  advanced architectures. The code is open-sourced at https://github.com/p0lcAi/FOTON .

</details>


### [43] [Improving Cardiac Risk Prediction Using Data Generation Techniques](https://arxiv.org/abs/2512.20669)
*Alexandre Cabodevila,Pedro Gamallo-Fernandez,Juan C. Vidal,Manuel Lama*

Main category: cs.LG

TL;DR: 提出基于条件变分自编码器(CVAE)的架构，用于生成符合真实观察的合成临床记录，以解决心脏康复数据稀缺、不完整等问题，提升心脏风险预测模型性能。


<details>
  <summary>Details</summary>
Motivation: 心脏康复是一个多阶段、多专业协作的临床过程，但现实医疗数据库存在数据稀缺、记录不适用、缺失值高等问题，限制了相关研究的开展。

Method: 采用条件变分自编码器(CVAE)架构，生成与真实观察一致的合成临床记录，增加数据集规模和多样性。

Result: 提出的架构能够生成连贯且真实的合成数据，使用这些数据提高了各种心脏风险检测分类器的准确性，优于现有的深度学习合成数据生成方法。

Conclusion: CVAE架构能有效生成高质量合成临床数据，不仅增强心脏风险预测模型性能，还能减少潜在危险的诊断程序需求，如运动压力测试。

Abstract: Cardiac rehabilitation constitutes a structured clinical process involving multiple interdependent phases, individualized medical decisions, and the coordinated participation of diverse healthcare professionals. This sequential and adaptive nature enables the program to be modeled as a business process, thereby facilitating its analysis. Nevertheless, studies in this context face significant limitations inherent to real-world medical databases: data are often scarce due to both economic costs and the time required for collection; many existing records are not suitable for specific analytical purposes; and, finally, there is a high prevalence of missing values, as not all patients undergo the same diagnostic tests. To address these limitations, this work proposes an architecture based on a Conditional Variational Autoencoder (CVAE) for the synthesis of realistic clinical records that are coherent with real-world observations. The primary objective is to increase the size and diversity of the available datasets in order to enhance the performance of cardiac risk prediction models and to reduce the need for potentially hazardous diagnostic procedures, such as exercise stress testing. The results demonstrate that the proposed architecture is capable of generating coherent and realistic synthetic data, whose use improves the accuracy of the various classifiers employed for cardiac risk detection, outperforming state-of-the-art deep learning approaches for synthetic data generation.

</details>


### [44] [Disentangling Fact from Sentiment: A Dynamic Conflict-Consensus Framework for Multimodal Fake News Detection](https://arxiv.org/abs/2512.20670)
*Weilin Zhou,Zonghao Ying,Junjie Mu,Shengwei Tian,Quanchen Zou,Deyue Zhang,Dongdong Yang,Xiangzheng Zhang*

Main category: cs.LG

TL;DR: 本文提出动态冲突共识框架（DCCF），通过主动放大而非抑制跨模态矛盾来检测假新闻，相比传统一致性融合方法平均准确率提升3.52%。


<details>
  <summary>Details</summary>
Motivation: 当前多模态假新闻检测主要依赖一致性融合，但这种方法错误地将关键的跨模态差异视为噪声，导致过度平滑，从而稀释了伪造证据。主流方法通过最小化特征差异来对齐模态，但无意中平滑了作为伪造主要证据的细微跨模态矛盾。

Method: 提出动态冲突共识框架（DCCF）：1）将输入解耦到独立的事实空间和情感空间，区分客观不匹配与情感不一致；2）采用物理启发的特征动力学迭代极化这些表示，主动提取最大信息量的冲突；3）冲突共识机制将局部差异与全局上下文标准化，实现稳健的审议判断。

Result: 在三个真实世界数据集上的广泛实验表明，DCCF始终优于最先进的基线方法，平均准确率提升3.52%。

Conclusion: DCCF通过主动寻求不一致性而非抑制矛盾，有效解决了传统一致性融合方法的局限性，显著提升了多模态假新闻检测的性能。

Abstract: Prevalent multimodal fake news detection relies on consistency-based fusion, yet this paradigm fundamentally misinterprets critical cross-modal discrepancies as noise, leading to over-smoothing, which dilutes critical evidence of fabrication. Mainstream consistency-based fusion inherently minimizes feature discrepancies to align modalities, yet this approach fundamentally fails because it inadvertently smoothes out the subtle cross-modal contradictions that serve as the primary evidence of fabrication. To address this, we propose the Dynamic Conflict-Consensus Framework (DCCF), an inconsistency-seeking paradigm designed to amplify rather than suppress contradictions. First, DCCF decouples inputs into independent Fact and Sentiment spaces to distinguish objective mismatches from emotional dissonance. Second, we employ physics-inspired feature dynamics to iteratively polarize these representations, actively extracting maximally informative conflicts. Finally, a conflict-consensus mechanism standardizes these local discrepancies against the global context for robust deliberative judgment.Extensive experiments conducted on three real world datasets demonstrate that DCCF consistently outperforms state-of-the-art baselines, achieving an average accuracy improvement of 3.52\%.

</details>


### [45] [HyDRA: Hierarchical and Dynamic Rank Adaptation for Mobile Vision Language Model](https://arxiv.org/abs/2512.20674)
*Yuanhao Xi,Xiaohuan Bing,Ramin Yahyapour*

Main category: cs.LG

TL;DR: HyDRA：针对移动视觉语言模型的高效参数微调框架，通过分层动态秩调度实现更好的性能而不增加可训练参数


<details>
  <summary>Details</summary>
Motivation: 移动视觉语言模型训练计算需求大，标准LoRA固定秩方法对处理多模态的移动VLMs能力不足，需要更高效的参数微调方案

Method: 提出HyDRA框架，包含两个优化策略：1）分层优化（粗粒度分配不同层不同秩，细粒度调整层内秩）；2）动态调整（使用轻量性能模型进行端到端自动优化，在微调过程中确定和调整秩）

Result: 在多个基准测试中，HyDRA始终优于基线，在各种模型大小上实现4.7%的性能提升，且不增加可训练参数；在某些任务中甚至超过全参数微调

Conclusion: HyDRA为移动视觉语言模型提供了一种高效参数微调解决方案，通过分层动态秩调度显著提升性能，解决了移动VLMs训练计算需求大的问题

Abstract: Vision Language Models (VLMs) have undergone significant advancements, particularly with the emergence of mobile-oriented VLMs, which offer a wide range of application scenarios. However, the substantial computational requirements for training these models present a significant obstacle to their practical application. To address this issue, Low-Rank Adaptation (LoRA) has been proposed. Nevertheless, the standard LoRA with a fixed rank lacks sufficient capability for training mobile VLMs that process both text and image modalities. In this work, we introduce HyDRA, a parameter-efficient fine-tuning framework designed to implement hierarchical and dynamic rank scheduling for mobile VLMs. This framework incorporates two essential optimization strategies: (1) hierarchical optimization, which involves a coarse-grained approach that assigns different ranks to various layers, as well as a fine-grained method that adjusts ranks within individual layers, and (2) dynamic adjustment, which employs an end-to-end automatic optimization using a lightweight performance model to determine and adjust ranks during the fine-tuning process. Comprehensive experiments conducted on popular benchmarks demonstrate that HyDRA consistently outperforms the baseline, achieving a 4.7\% improvement across various model sizes without increasing the number of trainable parameters. In some tasks, it even surpasses full-parameter fine-tuning.

</details>


### [46] [Revisiting the Learning Objectives of Vision-Language Reward Models](https://arxiv.org/abs/2512.20675)
*Simon Roy,Samuel Barbeau,Giovanni Beltrame,Christian Desrosiers,Nicolas Thome*

Main category: cs.LG

TL;DR: 研究发现，在统一的框架下，简单的三元组损失函数优于当前最先进的VLM奖励模型方法，表明近期方法的改进主要源于数据和架构差异而非学习目标本身。


<details>
  <summary>Details</summary>
Motivation: 学习可泛化的奖励函数是具身智能的核心挑战。近期工作利用对比视觉语言模型（VLMs）获得无需人工监督的密集、领域无关的奖励。但这些方法通过日益复杂的学习目标将VLMs适配为奖励模型，由于训练数据、架构和评估设置的差异，有意义的比较变得困难。

Method: 通过统一框架评估近期基于VLM的奖励模型，使用相同的骨干网络、微调数据和评估环境（Meta-World任务）。通过测量与真实奖励的一致性以及与专家进度的相关性来评估建模准确性。

Result: 令人惊讶的是，简单的三元组损失函数优于最先进的方法，这表明近期方法的大部分改进可能归因于数据和架构的差异，而非学习目标本身。

Conclusion: 在奖励函数学习中，学习目标的选择可能不如数据和架构因素重要，简单的三元组损失在统一比较中表现最佳，为未来研究提供了重要参考。

Abstract: Learning generalizable reward functions is a core challenge in embodied intelligence. Recent work leverages contrastive vision language models (VLMs) to obtain dense, domain-agnostic rewards without human supervision. These methods adapt VLMs into reward models through increasingly complex learning objectives, yet meaningful comparison remains difficult due to differences in training data, architectures, and evaluation settings. In this work, we isolate the impact of the learning objective by evaluating recent VLM-based reward models under a unified framework with identical backbones, finetuning data, and evaluation environments. Using Meta-World tasks, we assess modeling accuracy by measuring consistency with ground truth reward and correlation with expert progress. Remarkably, we show that a simple triplet loss outperforms state-of-the-art methods, suggesting that much of the improvements in recent approaches could be attributed to differences in data and architectures.

</details>


### [47] [PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation](https://arxiv.org/abs/2512.20687)
*Yuma Ichikawa,Naoya Takagi,Takumi Nakagawa,Yuzi Kanazawa,Akira Sakai*

Main category: cs.LG

TL;DR: PHOTON是一种分层自回归模型，用垂直多分辨率上下文访问替代传统的水平token扫描，通过维护潜在流层次结构减少KV缓存流量，显著提升长上下文和多查询任务的吞吐量。


<details>
  <summary>Details</summary>
Motivation: Transformer作为水平token扫描器，在生成过程中需要访问不断增长的token级状态序列，这增加了预填充延迟，并使长上下文解码越来越受内存限制，KV缓存的读写操作主导了推理吞吐量而非算术计算。

Method: 提出并行分层操作（PHOTON），维护潜在流层次结构：自底向上编码器逐步将token压缩为低速率上下文状态，轻量级自顶向下解码器重建细粒度token表示，实现垂直多分辨率上下文访问。

Result: PHOTON在吞吐量-质量权衡方面优于基于Transformer的语言模型，在长上下文和多查询任务中具有显著优势，将解码时KV缓存流量减少，实现高达10^3倍的每单位内存吞吐量提升。

Conclusion: PHOTON通过分层架构和垂直上下文访问模式，有效解决了Transformer在长上下文解码中的内存瓶颈问题，为高效语言模型推理提供了有前景的解决方案。

Abstract: Transformers operate as horizontal token-by-token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decoding increasingly memory-bound, as KV-cache reads and writes dominate inference throughput rather than arithmetic computation. We propose Parallel Hierarchical Operation for Top-down Networks (PHOTON), a hierarchical autoregressive model that replaces flat scanning with vertical, multi-resolution context access. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based language models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This reduces decode-time KV-cache traffic, yielding up to $10^{3}\times$ higher throughput per unit memory.

</details>


### [48] [FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs](https://arxiv.org/abs/2512.20732)
*Saeed Mohammadzadeh,Erfan Hamdi,Joel Shor,Emma Lejeune*

Main category: cs.LG

TL;DR: FEM-Bench是一个计算力学基准测试，用于评估大语言模型生成正确有限元方法代码的能力，当前最先进模型在33个任务中仅能稳定完成26个。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在物理世界推理能力上的进步，缺乏评估其生成科学有效物理模型能力的严格基准已成为关键缺口。计算力学提供了结构化科学推理评估的理想基础。

Method: FEM-Bench 2025包含一套与计算力学研究生课程内容对齐的入门但非平凡任务，捕捉了基本的数值和物理建模挑战，同时仅代表该学科复杂性的很小一部分。

Result: 在五次尝试运行中，函数编写表现最佳的Gemini 3 Pro模型在33个任务中至少完成30个，稳定完成26个；单元测试编写表现最佳的GPT-5模型平均联合成功率为73.8%。其他流行模型表现差异较大。

Conclusion: FEM-Bench为评估AI生成科学代码建立了结构化基础，未来迭代将纳入更复杂的任务以追踪模型进展。

Abstract: As LLMs advance their reasoning capabilities about the physical world, the absence of rigorous benchmarks for evaluating their ability to generate scientifically valid physical models has become a critical gap. Computational mechanics, which develops and applies mathematical models and numerical methods to predict the behavior of physical systems under forces, deformation, and constraints, provides an ideal foundation for structured scientific reasoning evaluation. Problems follow clear mathematical structure, enforce strict physical and numerical constraints, and support objective verification. The discipline requires constructing explicit models of physical systems and reasoning about geometry, spatial relationships, and material behavior, connecting directly to emerging AI goals in physical reasoning and world modeling. We introduce FEM-Bench, a computational mechanics benchmark designed to evaluate the ability of LLMs to generate correct finite element method (FEM) and related code. FEM-Bench 2025 contains a suite of introductory but nontrivial tasks aligned with material from a first graduate course on computational mechanics. These tasks capture essential numerical and physical modeling challenges while representing only a small fraction of the complexity present in the discipline. Despite their simplicity, state-of-the-art LLMs do not reliably solve all of them. In a five attempt run, the best performing model at function writing, Gemini 3 Pro, completed 30/33 tasks at least once and 26/33 tasks all five times. The best performing model at unit test writing, GPT-5, had an Average Joint Success Rate of 73.8%. Other popular models showed broad performance variation. FEM-Bench establishes a structured foundation for evaluating AI-generated scientific code, and future iterations will incorporate increasingly sophisticated tasks to track progress as models evolve.

</details>


### [49] [Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies](https://arxiv.org/abs/2512.20749)
*Diyar Altinses,Andreas Schwung*

Main category: cs.LG

TL;DR: 该论文分析了多模态自编码器的Lipschitz性质，提出了基于理论分析的注意力融合方法，通过实验验证了该方法在稳定性、收敛速度和准确性方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 多模态自编码器在处理复杂多模态数据方面具有潜力，但理解其稳定性和鲁棒性对于优化训练、架构设计和实际应用至关重要。本文旨在分析多模态自编码器的Lipschitz性质，以增强这些模型的训练稳定性。

Method: 首先推导多模态自编码器框架中聚合方法的理论Lipschitz常数，然后基于理论分析提出正则化的注意力融合方法。通过一系列实验，在多轮试验和不同融合策略中估计Lipschitz常数，实证验证理论发现。

Result: 实验结果表明，提出的融合函数不仅与理论预测一致，而且在一致性、收敛速度和准确性方面优于现有策略。该方法为理解多模态自编码器中的融合提供了理论基础。

Conclusion: 本文为理解多模态自编码器中的融合提供了坚实的理论基础，并贡献了一个增强其性能的解决方案。提出的正则化注意力融合方法在稳定性和性能方面表现出色。

Abstract: In recent years, the development of multimodal autoencoders has gained significant attention due to their potential to handle multimodal complex data types and improve model performance. Understanding the stability and robustness of these models is crucial for optimizing their training, architecture, and real-world applicability. This paper presents an analysis of Lipschitz properties in multimodal autoencoders, combining both theoretical insights and empirical validation to enhance the training stability of these models. We begin by deriving the theoretical Lipschitz constants for aggregation methods within the multimodal autoencoder framework. We then introduce a regularized attention-based fusion method, developed based on our theoretical analysis, which demonstrates improved stability and performance during training. Through a series of experiments, we empirically validate our theoretical findings by estimating the Lipschitz constants across multiple trials and fusion strategies. Our results demonstrate that our proposed fusion function not only aligns with theoretical predictions but also outperforms existing strategies in terms of consistency, convergence speed, and accuracy. This work provides a solid theoretical foundation for understanding fusion in multimodal autoencoders and contributes a solution for enhancing their performance.

</details>


### [50] [Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits](https://arxiv.org/abs/2512.20755)
*Yizhak Yisrael Elboher,Avraham Raviv,Amihay Elboher,Zhouxing Shi,Omri Azencot,Hillel Kugler,Guy Katz*

Main category: cs.LG

TL;DR: 提出针对早期退出神经网络的鲁棒性验证框架，结合形式化验证与推理效率优化，通过改进算法提升验证性能


<details>
  <summary>Details</summary>
Motivation: 早期退出架构能提高推理效率，但因其条件执行路径给形式化验证带来新挑战，需要专门的方法来验证这类网络的鲁棒性

Method: 定义针对早期退出架构的鲁棒性属性，使用现成求解器评估；提出基线算法，结合早期停止策略和启发式优化，保持完备性和可靠性

Result: 在多个基准测试中验证了框架的有效性，改进算法带来性能提升；早期退出不仅加速推理，还增强可验证性，相比标准网络能在更短时间内解决更多查询

Conclusion: 早期退出架构在准确性和效率间提供新的权衡空间，提出的验证框架能帮助用户导航这一权衡，同时确保系统安全性和效率

Abstract: Ensuring the safety and efficiency of AI systems is a central goal of modern research. Formal verification provides guarantees of neural network robustness, while early exits improve inference efficiency by enabling intermediate predictions. Yet verifying networks with early exits introduces new challenges due to their conditional execution paths. In this work, we define a robustness property tailored to early exit architectures and show how off-the-shelf solvers can be used to assess it. We present a baseline algorithm, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. Experiments on multiple benchmarks validate our framework's effectiveness and demonstrate the performance gains of the improved algorithm. Alongside the natural inference acceleration provided by early exits, we show that they also enhance verifiability, enabling more queries to be solved in less time compared to standard networks. Together with a robustness analysis, we show how these metrics can help users navigate the inherent trade-off between accuracy and efficiency.

</details>


### [51] [Generalization of RLVR Using Causal Reasoning as a Testbed](https://arxiv.org/abs/2512.20760)
*Brian Lu,Hongyu Zhao,Shuo Sun,Hao Peng,Rui Ding,Hongyuan Mei*

Main category: cs.LG

TL;DR: RLVR在因果推理任务上比SFT有更好的泛化能力，但效果取决于模型规模和训练查询级别，且需要模型具备足够的初始推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究RLVR在复杂推理任务上的泛化条件，特别是在因果图模型概率推理场景下，理解RLVR何时能产生稳健的泛化能力。

Method: 在因果图模型概率推理任务上，构建不同难度级别的数据集（查询级别：关联、干预、反事实；结构复杂度），对Qwen-2.5-Instruct模型（3B-32B）进行RLVR和SFT微调，比较两者的泛化性能。

Result: RLVR在特定模型规模和训练查询级别组合下，比SFT有更好的同级别和跨级别泛化能力。RLVR的有效性取决于模型的初始推理能力，当具备足够初始能力时，RLVR能改进模型的边缘化策略并减少中间概率计算错误。

Conclusion: RLVR能改进特定的因果推理子技能，但其优势仅在模型具备足够初始推理能力时才会显现，这为RLVR在复杂推理任务上的应用提供了指导。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.

</details>


### [52] [TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform](https://arxiv.org/abs/2512.20761)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Henrik Albers,Oliver Müller*

Main category: cs.LG

TL;DR: TS-Arena平台解决时间序列基础模型评估中的信息泄露问题，通过在实时数据流上实施预注册机制，确保评估目标在推理时物理上不存在，从而建立严格的全局时间分割。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFMs）虽然具有变革性能力，但存在评估危机：训练集和测试集重叠导致信息泄露，以及全局模式非法转移到测试数据。现有评估方法允许利用观察到的全局冲击，违反了有效基准测试所需的独立性要求。

Method: 提出TS-Arena平台，将真正未知的未来作为最终测试环境。通过实时数据流上的预注册机制，确保评估目标在推理时物理上不存在，强制执行严格的全局时间分割，建立移动时间前沿防止历史污染。

Result: 在能源领域初步应用TS-Arena，为在现实约束下比较基础模型提供了可持续的基础设施。平台原型已在Hugging Face上提供。

Conclusion: TS-Arena通过恢复预测的操作完整性，防止历史污染，为时间序列基础模型提供了真实的泛化能力评估，解决了当前评估方法中的根本性危机。

Abstract: While Time Series Foundation Models (TSFMs) offer transformative capabilities for forecasting, they simultaneously risk triggering a fundamental evaluation crisis. This crisis is driven by information leakage due to overlapping training and test sets across different models, as well as the illegitimate transfer of global patterns to test data. While the ability to learn shared temporal dynamics represents a primary strength of these models, their evaluation on historical archives often permits the exploitation of observed global shocks, which violates the independence required for valid benchmarking. We introduce TS-Arena, a platform that restores the operational integrity of forecasting by treating the genuinely unknown future as the definitive test environment. By implementing a pre-registration mechanism on live data streams, the platform ensures that evaluation targets remain physically non-existent during inference, thereby enforcing a strict global temporal split. This methodology establishes a moving temporal frontier that prevents historical contamination and provides an authentic assessment of model generalization. Initially applied within the energy sector, TS-Arena provides a sustainable infrastructure for comparing foundation models under real-world constraints. A prototype of the platform is available at https://huggingface.co/spaces/DAG-UPB/TS-Arena.

</details>


### [53] [Subgroup Discovery with the Cox Model](https://arxiv.org/abs/2512.20762)
*Zachary Izzo,Iain Melvin*

Main category: cs.LG

TL;DR: 提出生存分析中子群发现的新方法，针对Cox模型开发了EPE和CRS两个新指标，并设计了8种算法，在合成和真实数据上验证了有效性


<details>
  <summary>Details</summary>
Motivation: 现有子群发现方法的质量函数不适用于Cox生存分析模型，需要开发专门的技术来发现解释性强的子群，提高模型准确性

Method: 1) 提出预期预测熵(EPE)评估生存模型；2) 提出条件秩统计(CRS)量化个体与子群分布的偏差；3) 开发8种子群发现算法，其中主算法结合EPE和CRS

Result: 在合成数据中能恢复真实子群，在真实数据上比在整个数据集上拟合Cox模型效果更好，NASA喷气发动机案例发现了已知的非线性/同质性

Conclusion: 首次系统研究Cox模型的子群发现问题，提出的EPE和CRS指标及相应算法能有效发现解释性子群，在理论和实践上都有价值

Abstract: We study the problem of subgroup discovery for survival analysis, where the goal is to find an interpretable subset of the data on which a Cox model is highly accurate. Our work is the first to study this particular subgroup problem, for which we make several contributions.
  Subgroup discovery methods generally require a "quality function" in order to sift through and select the most advantageous subgroups. We first examine why existing natural choices for quality functions are insufficient to solve the subgroup discovery problem for the Cox model. To address the shortcomings of existing metrics, we introduce two technical innovations: the *expected prediction entropy (EPE)*, a novel metric for evaluating survival models which predict a hazard function; and the *conditional rank statistics (CRS)*, a statistical object which quantifies the deviation of an individual point to the distribution of survival times in an existing subgroup. We study the EPE and CRS theoretically and show that they can solve many of the problems with existing metrics.
  We introduce a total of eight algorithms for the Cox subgroup discovery problem. The main algorithm is able to take advantage of both the EPE and the CRS, allowing us to give theoretical correctness results for this algorithm in a well-specified setting. We evaluate all of the proposed methods empirically on both synthetic and real data. The experiments confirm our theory, showing that our contributions allow for the recovery of a ground-truth subgroup in well-specified cases, as well as leading to better model fit compared to naively fitting the Cox model to the whole dataset in practical settings. Lastly, we conduct a case study on jet engine simulation data from NASA. The discovered subgroups uncover known nonlinearities/homogeneity in the data, and which suggest design choices which have been mirrored in practice.

</details>


### [54] [Improving Matrix Exponential for Generative AI Flows: A Taylor-Based Approach Beyond Paterson--Stockmeyer](https://arxiv.org/abs/2512.20777)
*Jorge Sastre,Daniel Faronbi,José Miguel Alonso,Peter Traver,Javier Ibáñez,Nuria Lloret*

Main category: cs.LG

TL;DR: 提出了一种针对生成式AI流程优化的矩阵指数泰勒基算法，通过动态选择泰勒阶数和缩放因子，在保证精度的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 矩阵指数在科学计算和系统仿真中至关重要，尤其在生成式机器学习中需要高吞吐量。传统Padé近似结合缩放平方方法虽然长期作为标准，但最近基于泰勒的方法在精度和计算复杂度方面表现更优。

Method: 开发了优化的泰勒基矩阵指数算法，包含严格的误差分析和动态选择策略，可根据预设误差容限自动选择最优的泰勒阶数和缩放因子以最小化计算量。

Result: 大量数值实验表明，该方法相比现有最先进实现提供了显著加速，同时保持了高数值稳定性，特别适合大规模生成式建模。

Conclusion: 所提出的方法成为大规模生成式建模的高效工具，在生成式AI流程中实现了计算效率与数值精度的平衡。

Abstract: The matrix exponential is a fundamental operator in scientific computing and system simulation, with applications ranging from control theory and quantum mechanics to modern generative machine learning. While Padé approximants combined with scaling and squaring have long served as the standard, recent Taylor-based methods, which utilize polynomial evaluation schemes that surpass the classical Paterson--Stockmeyer technique, offer superior accuracy and reduced computational complexity. This paper presents an optimized Taylor-based algorithm for the matrix exponential, specifically designed for the high-throughput requirements of generative AI flows. We provide a rigorous error analysis and develop a dynamic selection strategy for the Taylor order and scaling factor to minimize computational effort under a prescribed error tolerance. Extensive numerical experiments demonstrate that our approach provides significant acceleration and maintains high numerical stability compared to existing state-of-the-art implementations. These results establish the proposed method as a highly efficient tool for large-scale generative modeling.

</details>


### [55] [Symbolic regression for defect interactions in 2D materials](https://arxiv.org/abs/2512.20785)
*Mikhail Lazarev,Andrey Ustyuzhanin*

Main category: cs.LG

TL;DR: 该研究应用深度符号回归算法SEGVAE预测二维缺陷材料性质，与图神经网络方法性能相当，展示了符号回归在自然科学中的适用性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在科学领域广泛应用，但神经网络方法虽然准确度高，却存在可解释性差等缺点。符号回归能够发现描述数据的解析方程，提供可解释且能泛化的模型，特别适合科学发现。

Method: 采用深度符号回归算法SEGVAE（Symbolic Expression Generation via Variational Autoencoder）来确定二维材料缺陷的性质。该方法通过变分自编码器生成符号表达式，从数据中发现解析方程。

Result: SEGVAE算法在预测二维材料缺陷性质方面表现出色，与最先进的图神经网络方法相比，结果相当甚至在某些情况下完全相同，证明了符号回归的有效性。

Conclusion: 深度符号回归算法SEGVAE在材料科学中具有实际应用价值，能够提供可解释的解析模型，性能与黑盒神经网络相当，这类方法在自然科学领域具有广阔的应用前景。

Abstract: Machine learning models have become firmly established across all scientific fields. Extracting features from data and making inferences based on them with neural network models often yields high accuracy; however, this approach has several drawbacks. Symbolic regression is a powerful technique for discovering analytical equations that describe data, providing interpretable and generalizable models capable of predicting unseen data. Symbolic regression methods have gained new momentum with the advancement of neural network technologies and offer several advantages, the main one being the interpretability of results. In this work, we examined the application of the deep symbolic regression algorithm SEGVAE to determine the properties of two-dimensional materials with defects. Comparing the results with state-of-the-art graph neural network-based methods shows comparable or, in some cases, even identical outcomes. We also discuss the applicability of this class of methods in natural sciences.

</details>


### [56] [GraphFire-X: Physics-Informed Graph Attention Networks and Structural Gradient Boosting for Building-Scale Wildfire Preparedness at the Wildland-Urban Interface](https://arxiv.org/abs/2512.20813)
*Miguel Esparza,Vamshi Battal,Ali Mostafavi*

Main category: cs.LG

TL;DR: 提出双专家集成框架，分离环境传播与结构脆弱性风险，结合GNN和XGBoost模型，应用于2025年Eaton火灾，实现社区韧性诊断


<details>
  <summary>Details</summary>
Motivation: 传统火灾风险模型将建筑视为孤立资产，无法捕捉WUI（野地-城市交界区）的非线性传播动态。需要弥合机理物理与数据驱动学习之间的差距，以应对日益严重的城市火灾威胁。

Method: 建立双专家集成框架：1) 环境专家：使用图神经网络(GNN)将社区建模为加权有向传播图，权重基于物理信息（对流、辐射、余烬概率）和Google AlphaEarth基础嵌入；2) 结构专家：使用XGBoost模型分析资产级韧性。通过逻辑堆叠集成两个模型的输出。

Result: 应用于2025年Eaton火灾显示：GNN模型表明邻里尺度的环境压力在定义传播路径中占主导地位，而XGBoost识别屋檐是主要的微观尺度入侵途径。集成模型实现了稳健分类并生成诊断性风险拓扑。

Conclusion: 该框架使决策者能够超越二元损失预测，精确针对高连通性集群进行植被管理，对建筑脆弱节点进行结构加固，实现了主动、数据驱动的社区韧性方法。

Abstract: As wildfires increasingly evolve into urban conflagrations, traditional risk models that treat structures as isolated assets fail to capture the non-linear contagion dynamics characteristic of the wildland urban interface (WUI). This research bridges the gap between mechanistic physics and data driven learning by establishing a novel dual specialist ensemble framework that disentangles vulnerability into two distinct vectors, environmental contagion and structural fragility. The architecture integrates two specialized predictive streams, an environmental specialist, implemented as a graph neural network (GNN) that operationalizes the community as a directed contagion graph weighted by physics informed convection, radiation, and ember probabilities, and enriched with high dimensional Google AlphaEarth Foundation embeddings, and a Structural Specialist, implemented via XGBoost to isolate granular asset level resilience. Applied to the 2025 Eaton Fire, the framework reveals a critical dichotomy in risk drivers. The GNN demonstrates that neighborhood scale environmental pressure overwhelmingly dominates intrinsic structural features in defining propagation pathways, while the XGBoost model identifies eaves as the primary micro scale ingress vector. By synthesizing these divergent signals through logistic stacking, the ensemble achieves robust classification and generates a diagnostic risk topology. This capability empowers decision makers to move beyond binary loss prediction and precisely target mitigation prioritizing vegetation management for high connectivity clusters and structural hardening for architecturally vulnerable nodes thereby operationalizing a proactive, data driven approach to community resilience.

</details>


### [57] [FedMPDD: Communication-Efficient Federated Learning with Privacy Preservation Attributes via Projected Directional Derivative](https://arxiv.org/abs/2512.20814)
*Mohammadreza Rostami,Solmaz S. Kia*

Main category: cs.LG

TL;DR: FedMPDD是一种联邦学习算法，通过多投影方向导数压缩梯度，同时优化带宽利用和增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中高维梯度传输带来的通信开销大和隐私泄露风险问题。

Method: 客户端计算梯度沿多个随机向量的方向导数来编码高维梯度，服务器通过投影回相同随机向量来解码聚合信息。

Result: 通信成本从O(d)降至O(m)，收敛速率达到O(1/√K)，与FedSGD相当，并提供可调节的隐私-效用权衡。

Conclusion: FedMPDD有效平衡了通信效率、收敛性能和隐私保护，为联邦学习提供了实用的解决方案。

Abstract: This paper introduces \texttt{FedMPDD} (\textbf{Fed}erated Learning via \textbf{M}ulti-\textbf{P}rojected \textbf{D}irectional \textbf{D}erivatives), a novel algorithm that simultaneously optimizes bandwidth utilization and enhances privacy in Federated Learning. The core idea of \texttt{FedMPDD} is to encode each client's high-dimensional gradient by computing its directional derivatives along multiple random vectors. This compresses the gradient into a much smaller message, significantly reducing uplink communication costs from $\mathcal{O}(d)$ to $\mathcal{O}(m)$, where $m \ll d$. The server then decodes the aggregated information by projecting it back onto the same random vectors. Our key insight is that averaging multiple projections overcomes the dimension-dependent convergence limitations of a single projection. We provide a rigorous theoretical analysis, establishing that \texttt{FedMPDD} converges at a rate of $\mathcal{O}(1/\sqrt{K})$, matching the performance of FedSGD. Furthermore, we demonstrate that our method provides some inherent privacy against gradient inversion attacks due to the geometric properties of low-rank projections, offering a tunable privacy-utility trade-off controlled by the number of projections. Extensive experiments on benchmark datasets validate our theory and demonstrates our results.

</details>


### [58] [Defending against adversarial attacks using mixture of experts](https://arxiv.org/abs/2512.20821)
*Mohammad Meymani,Roozbeh Razavi-Far*

Main category: cs.LG

TL;DR: 提出一种基于专家混合架构的对抗训练防御系统，通过联合优化专家模型和门控机制来增强模型对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在面对对抗性威胁时存在脆弱性，包括对抗扰动、数据投毒和模型窃取等攻击。现有防御系统需要进一步提升鲁棒性。

Method: 在专家混合架构中设计对抗训练模块，使用9个基于ResNet-18的预训练专家模型，通过端到端训练联合更新专家参数和门控机制。

Result: 提出的防御系统优于现有最先进的防御系统和普通分类器，即使这些分类器使用了比ResNet-18更复杂的架构。

Conclusion: 基于专家混合架构的对抗训练防御系统能有效提升模型对抗攻击的鲁棒性，为机器学习安全提供了有效的防御方案。

Abstract: Machine learning is a powerful tool enabling full automation of a huge number of tasks without explicit programming. Despite recent progress of machine learning in different domains, these models have shown vulnerabilities when they are exposed to adversarial threats. Adversarial threats aim to hinder the machine learning models from satisfying their objectives. They can create adversarial perturbations, which are imperceptible to humans' eyes but have the ability to cause misclassification during inference. Moreover, they can poison the training data to harm the model's performance or they can query the model to steal its sensitive information. In this paper, we propose a defense system, which devises an adversarial training module within mixture-of-experts architecture to enhance its robustness against adversarial threats. In our proposed defense system, we use nine pre-trained experts with ResNet-18 as their backbone. During end-to-end training, the parameters of expert models and gating mechanism are jointly updated allowing further optimization of the experts. Our proposed defense system outperforms state-of-the-art defense systems and plain classifiers, which use a more complex architecture than our model's backbone.

</details>


### [59] [Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs](https://arxiv.org/abs/2512.20861)
*Pierre Abillama,Changwoo Lee,Juechu Dong,David Blaauw,Dennis Sylvester,Hun-Seok Kim*

Main category: cs.LG

TL;DR: 论文提出针对BLR压缩方法的定制Triton内核优化，解决多token推理中的内存瓶颈问题，在内存受限GPU上实现显著加速和模型压缩。


<details>
  <summary>Details</summary>
Motivation: Transformer基础模型尺寸快速增长，单GPU难以容纳完整模型且计算成本高昂。BLR压缩技术能学习紧凑权重表示，但现有方法在多token推理时存在内存瓶颈，增加延迟。

Method: 通过roofline分析揭示BLR方法在多token推理中的内存限制问题，为Monarch和BLAST两种BLR方法设计定制Triton内核，采用部分融合和内存布局优化。

Result: 在NVIDIA Jetson Orin Nano和A40等内存受限GPU上，相比PyTorch密集基线，新内核实现最高3.76倍加速和3倍模型压缩，支持Llama-7/1B、GPT2-S、DiT-XL/2、ViT-B等多种模型。

Conclusion: 定制Triton内核能有效解决BLR方法在多token推理中的内存瓶颈，在内存受限设备上实现显著性能提升和模型压缩，为部署大型基础模型提供实用解决方案。

Abstract: Recent advances in transformer-based foundation models have made them the default choice for many tasks, but their rapidly growing size makes fitting a full model on a single GPU increasingly difficult and their computational cost prohibitive. Block low-rank (BLR) compression techniques address this challenge by learning compact representations of weight matrices. While traditional low-rank (LR) methods often incur sharp accuracy drops, BLR approaches such as Monarch and BLAST can better capture the underlying structure, thus preserving accuracy while reducing computations and memory footprints. In this work, we use roofline analysis to show that, although BLR methods achieve theoretical savings and practical speedups for single-token inference, multi-token inference often becomes memory-bound in practice, increasing latency despite compiler-level optimizations in PyTorch. To address this, we introduce custom Triton kernels with partial fusion and memory layout optimizations for both Monarch and BLAST. On memory-constrained NVIDIA GPUs such as Jetson Orin Nano and A40, our kernels deliver up to $3.76\times$ speedups and $3\times$ model size compression over PyTorch dense baselines using CUDA backend and compiler-level optimizations, while supporting various models including Llama-7/1B, GPT2-S, DiT-XL/2, and ViT-B. Our code is available at https://github.com/pabillam/mem-efficient-blr .

</details>


### [60] [Robustness Certificates for Neural Networks against Adversarial Attacks](https://arxiv.org/abs/2512.20865)
*Sara Taheri,Mahalakshmi Sabanayagam,Debarghya Ghoshdastidar,Majid Zamani*

Main category: cs.LG

TL;DR: 提出基于动力系统理论和屏障证书的形式化鲁棒性认证框架，为训练时数据投毒和测试时攻击提供统一的形式化保证。


<details>
  <summary>Details</summary>
Motivation: 机器学习在安全关键领域的应用增加，对抗性威胁风险加剧，特别是数据投毒攻击。现有防御方法缺乏形式化保证或依赖过多限制性假设，限制了实际可靠性。

Method: 将基于梯度的训练建模为离散时间动力系统，将投毒鲁棒性转化为形式化安全验证问题。采用控制理论中的屏障证书概念，通过神经网络参数化屏障证书，在有限投毒轨迹上训练，并通过场景凸规划推导PAC边界。

Result: 在MNIST、SVHN和CIFAR-10数据集上实验表明，该方法能够认证非平凡的扰动预算，同时具有模型无关性，无需攻击或污染水平的先验知识。

Conclusion: 该框架为训练时数据投毒和测试时攻击提供了首个统一的形式化认证框架，通过动力系统理论和屏障证书实现了具有理论保证的鲁棒性认证。

Abstract: The increasing use of machine learning in safety-critical domains amplifies the risk of adversarial threats, especially data poisoning attacks that corrupt training data to degrade performance or induce unsafe behavior. Most existing defenses lack formal guarantees or rely on restrictive assumptions about the model class, attack type, extent of poisoning, or point-wise certification, limiting their practical reliability. This paper introduces a principled formal robustness certification framework that models gradient-based training as a discrete-time dynamical system (dt-DS) and formulates poisoning robustness as a formal safety verification problem. By adapting the concept of barrier certificates (BCs) from control theory, we introduce sufficient conditions to certify a robust radius ensuring that the terminal model remains safe under worst-case ${\ell}_p$-norm based poisoning. To make this practical, we parameterize BCs as neural networks trained on finite sets of poisoned trajectories. We further derive probably approximately correct (PAC) bounds by solving a scenario convex program (SCP), which yields a confidence lower bound on the certified robustness radius generalizing beyond the training set. Importantly, our framework also extends to certification against test-time attacks, making it the first unified framework to provide formal guarantees in both training and test-time attack settings. Experiments on MNIST, SVHN, and CIFAR-10 show that our approach certifies non-trivial perturbation budgets while being model-agnostic and requiring no prior knowledge of the attack or contamination level.

</details>


### [61] [From GNNs to Symbolic Surrogates via Kolmogorov-Arnold Networks for Delay Prediction](https://arxiv.org/abs/2512.20885)
*Sami Marouani,Kamal Singh,Baptiste Jeudy,Amaury Habrard*

Main category: cs.LG

TL;DR: 论文提出FlowKANet，使用Kolmogorov-Arnold网络替代传统MLP层，减少可训练参数的同时保持预测性能，并通过符号蒸馏生成可解释的闭式方程。


<details>
  <summary>Details</summary>
Motivation: 准确预测流延迟对优化和管理现代通信网络至关重要，需要建立高效且可解释的预测模型。

Method: 1) 建立基于注意力消息传递的异构图神经网络基线；2) 提出FlowKANet，用Kolmogorov-Arnold网络替代MLP层，集成KAMP-Attn机制；3) 通过块级回归将模型蒸馏为符号代理模型。

Result: KAN层在效率和准确性之间提供了有利的权衡，符号代理模型实现了轻量级部署和增强的透明度。

Conclusion: FlowKANet和符号蒸馏方法为网络流延迟预测提供了高效、可解释的解决方案，平衡了性能与部署实用性。

Abstract: Accurate prediction of flow delay is essential for optimizing and managing modern communication networks. We investigate three levels of modeling for this task. First, we implement a heterogeneous GNN with attention-based message passing, establishing a strong neural baseline. Second, we propose FlowKANet in which Kolmogorov-Arnold Networks replace standard MLP layers, reducing trainable parameters while maintaining competitive predictive performance. FlowKANet integrates KAMP-Attn (Kolmogorov-Arnold Message Passing with Attention), embedding KAN operators directly into message-passing and attention computation. Finally, we distill the model into symbolic surrogate models using block-wise regression, producing closed-form equations that eliminate trainable weights while preserving graph-structured dependencies. The results show that KAN layers provide a favorable trade-off between efficiency and accuracy and that symbolic surrogates emphasize the potential for lightweight deployment and enhanced transparency.

</details>


### [62] [Time-Efficient Evaluation and Enhancement of Adversarial Robustness in Deep Neural Networks](https://arxiv.org/abs/2512.20893)
*Runqi Lin*

Main category: cs.LG

TL;DR: 该论文旨在为深度神经网络提供时间高效的方法来评估和增强对抗鲁棒性，解决现有红蓝对抗框架计算密集的问题。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络在社会中的广泛应用，确保其安全性变得至关重要。现有的红蓝对抗框架（红队发现漏洞，蓝队修复漏洞）计算密集，难以应用于大规模模型，限制了其实际应用。

Method: 论文致力于开发时间高效的方法来评估和增强深度神经网络的对抗鲁棒性，具体方法未在摘要中详细说明，但核心目标是解决计算效率问题。

Result: 摘要中未提供具体实验结果，但论文的目标是提供能够显著减少计算时间的方法，使对抗鲁棒性评估和增强能够扩展到大规模神经网络。

Conclusion: 通过开发时间高效的方法，该论文旨在使对抗鲁棒性的评估和增强能够实际应用于大规模深度神经网络，从而更好地保障AI系统的安全性。

Abstract: With deep neural networks (DNNs) increasingly embedded in modern society, ensuring their safety has become a critical and urgent issue. In response, substantial efforts have been dedicated to the red-blue adversarial framework, where the red team focuses on identifying vulnerabilities in DNNs and the blue team on mitigating them. However, existing approaches from both teams remain computationally intensive, constraining their applicability to large-scale models. To overcome this limitation, this thesis endeavours to provide time-efficient methods for the evaluation and enhancement of adversarial robustness in DNNs.

</details>


### [63] [DiEC: Diffusion Embedded Clustering](https://arxiv.org/abs/2512.20905)
*Haidong Hu*

Main category: cs.LG

TL;DR: DiEC利用预训练扩散模型的内部激活进行无监督聚类，通过两层搜索（层×时间步）找到聚类友好的表示，结合KL自训练、图正则化和去噪一致性分支提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度聚类方法通常使用单一编码器产生固定嵌入，忽略了预训练扩散模型在不同网络层次和噪声时间步形成的表示轨迹，其中聚类能力差异很大。

Method: 1) 将表示选择分解为层×时间步的两阶段搜索：固定U-Net瓶颈层作为聚类友好中间层，然后通过最优时间步搜索找到聚类最优时间步t*；2) 训练时在固定t*提取瓶颈特征，通过轻量残差映射获得聚类表示；3) 优化DEC风格的KL自训练目标，增强自适应图正则化和熵正则化；4) 引入随机时间步的去噪一致性分支稳定表示并保持生成一致性。

Result: 实验表明DiEC在多个标准基准测试中实现了有竞争力的聚类性能。

Conclusion: DiEC通过直接读取预训练扩散模型的内部激活进行无监督聚类，有效利用了扩散模型在不同层次和时间步的表示轨迹，为深度聚类提供了新思路。

Abstract: Deep clustering hinges on learning representations that are inherently clusterable. However, using a single encoder to produce a fixed embedding ignores the representation trajectory formed by a pretrained diffusion model across network hierarchies and noise timesteps, where clusterability varies substantially. We propose DiEC (Diffusion Embedded Clustering), which performs unsupervised clustering by directly reading internal activations from a pretrained diffusion U-Net.
  DiEC formulates representation selection as a two-dimensional search over layer x timestep, and exploits a weak-coupling property to decompose it into two stages. Specifically, we first fix the U-Net bottleneck layer as the Clustering-friendly Middle Layer (CML), and then use Optimal Timestep Search (OTS) to identify the clustering-optimal timestep (t*). During training, we extract bottleneck features at the fixed t* and obtain clustering representations via a lightweight residual mapping. We optimize a DEC-style KL self-training objective, augmented with adaptive graph regularization and entropy regularization to strengthen cluster structures. In parallel, we introduce a denoising-consistency branch at random timesteps to stabilize the representations and preserve generative consistency. Experiments show that DiEC achieves competitive clustering performance on multiple standard benchmarks.

</details>


### [64] [Towards a General Framework for Predicting and Explaining the Hardness of Graph-based Combinatorial Optimization Problems using Machine Learning and Association Rule Mining](https://arxiv.org/abs/2512.20915)
*Bharat Sharman,Elkafi Hassini*

Main category: cs.LG

TL;DR: 提出GCO-HPIF框架，通过机器学习预测和解释图组合优化问题的计算难度，在最大团问题上表现优异


<details>
  <summary>Details</summary>
Motivation: 传统上评估组合优化问题实例的计算难度需要实际运行算法，耗时且无法提前预测。需要一种能够预测和解释问题实例难度的通用框架。

Method: 两阶段框架：第一阶段使用问题无关的图特征和难度分类训练机器学习分类器；第二阶段使用关联规则挖掘解释预测结果，并训练回归模型预测计算时间。

Result: 在3287个最大团问题实例上，仅用3个图特征就达到加权F1分数0.9921，少数类F1分数0.878，ROC-AUC分数0.9083。最佳关联规则支持度0.8829，准确率87.64%。最佳回归模型百分比RMSE为5.12，R²值为0.991。

Conclusion: GCO-HPIF框架能够有效预测和解释组合优化问题的计算难度，为算法选择和问题理解提供了实用工具。

Abstract: This study introduces GCO-HPIF, a general machine-learning-based framework to predict and explain the computational hardness of combinatorial optimization problems that can be represented on graphs. The framework consists of two stages. In the first stage, a dataset is created comprising problem-agnostic graph features and hardness classifications of problem instances. Machine-learning-based classification algorithms are trained to map graph features to hardness categories. In the second stage, the framework explains the predictions using an association rule mining algorithm. Additionally, machine-learning-based regression models are trained to predict algorithmic computation times. The GCO-HPIF framework was applied to a dataset of 3287 maximum clique problem instances compiled from the COLLAB, IMDB, and TWITTER graph datasets using five state-of-the-art algorithms, namely three exact branch-and-bound-based algorithms (Gurobi, CliSAT, and MOMC) and two graph-neural-network-based algorithms (EGN and HGS). The framework demonstrated excellent performance in predicting instance hardness, achieving a weighted F1 score of 0.9921, a minority-class F1 score of 0.878, and an ROC-AUC score of 0.9083 using only three graph features. The best association rule found by the FP-Growth algorithm for explaining the hardness predictions had a support of 0.8829 for hard instances and an overall accuracy of 87.64 percent, underscoring the framework's usefulness for both prediction and explanation. Furthermore, the best-performing regression model for predicting computation times achieved a percentage RMSE of 5.12 and an R2 value of 0.991.

</details>


### [65] [RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks](https://arxiv.org/abs/2512.20920)
*Ningyuan Liu,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.LG

TL;DR: RevFFN：一种用于MoE大语言模型的内存高效全参数微调方法，通过可逆Transformer块重构激活值，减少内存占用，实现单GPU微调


<details>
  <summary>Details</summary>
Motivation: 全参数微调需要缓存大量中间激活值，导致内存开销大，现有分布式训练框架需要多GPU或CPU卸载，增加了硬件需求和降低了训练速度

Method: 采用精心设计的可逆Transformer块，在反向传播期间从输出重构层输入激活值，无需存储大多数中间激活值，同时保持MoE架构的表达能力

Result: 显著降低全参数微调的峰值内存消耗，能够在单个消费级或服务器级GPU上实现高效的全参数微调

Conclusion: RevFFN为MoE大语言模型提供了一种内存高效的全参数微调范式，解决了传统方法的内存瓶颈问题

Abstract: Full parameter fine tuning is a key technique for adapting large language models (LLMs) to downstream tasks, but it incurs substantial memory overhead due to the need to cache extensive intermediate activations for backpropagation. This bottleneck makes full fine tuning of contemporary large scale LLMs challenging in practice. Existing distributed training frameworks such as DeepSpeed alleviate this issue using techniques like ZeRO and FSDP, which rely on multi GPU memory or CPU offloading, but often require additional hardware resources and reduce training speed. We introduce RevFFN, a memory efficient fine tuning paradigm for mixture of experts (MoE) LLMs. RevFFN employs carefully designed reversible Transformer blocks that allow reconstruction of layer input activations from outputs during backpropagation, eliminating the need to store most intermediate activations in memory. While preserving the expressive capacity of MoE architectures, this approach significantly reduces peak memory consumption for full parameter fine tuning. As a result, RevFFN enables efficient full fine tuning on a single consumer grade or server grade GPU.

</details>


### [66] [Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy](https://arxiv.org/abs/2512.20932)
*Deepit Sapru*

Main category: cs.LG

TL;DR: 该论文提出了一个营销分析框架，将订阅定价操作化为动态、有护栏的决策系统，结合多元需求预测、细分价格弹性和流失倾向来优化收入、利润和留存率。


<details>
  <summary>Details</summary>
Motivation: 传统订阅定价方法（如静态层级或统一提价）无法有效平衡收入最大化与客户体验保护，缺乏动态调整能力和业务约束机制，可能导致客户流失和信任侵蚀。

Method: 融合季节性时间序列模型和基于树的学习器进行预测，使用蒙特卡洛场景测试映射风险范围，通过约束优化强制执行客户体验、利润底线和允许流失率等业务护栏。

Result: 在异质SaaS产品组合中验证，该方法持续优于静态层级和统一提价策略，通过将价格调整重新分配到支付意愿更高的细分市场，同时保护价格敏感群体。

Conclusion: 该框架作为战略手册，明确了何时从固定定价转向动态定价，如何将定价与客户终身价值和月度经常性收入目标对齐，以及如何嵌入道德护栏，实现可持续增长而不损害客户信任。

Abstract: This paper presents a marketing analytics framework that operationalizes subscription pricing as a dynamic, guardrailed decision system, uniting multivariate demand forecasting, segment-level price elasticity, and churn propensity to optimize revenue, margin, and retention. The approach blends seasonal time-series models with tree-based learners, runs Monte Carlo scenario tests to map risk envelopes, and solves a constrained optimization that enforces business guardrails on customer experience, margin floors, and allowable churn. Validated across heterogeneous SaaS portfolios, the method consistently outperforms static tiers and uniform uplifts by reallocating price moves toward segments with higher willingness-to-pay while protecting price-sensitive cohorts. The system is designed for real-time recalibration via modular APIs and includes model explainability for governance and compliance. Managerially, the framework functions as a strategy playbook that clarifies when to shift from flat to dynamic pricing, how to align pricing with CLV and MRR targets, and how to embed ethical guardrails, enabling durable growth without eroding customer trust.

</details>


### [67] [A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws for GNN-based Aerodynamic Field Surrogate](https://arxiv.org/abs/2512.20941)
*Yiren Shen,Juan J. Alonso*

Main category: cs.LG

TL;DR: 研究探索了训练数据量对基于图神经网络的空气动力学场预测代理模型性能的影响，发布了开源多保真度双三角翼数据集，发现了测试误差随数据量呈幂律下降的规律，并提出了设计空间最优采样密度建议。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的代理模型在车辆设计中应用日益广泛，但开源多保真度数据集有限，且缺乏关于数据集大小与模型性能关系的经验指导。本研究旨在填补这一空白，为空气动力学代理模型开发提供数据基础和性能指导。

Method: 1) 创建并开源包含2448个流场快照的多保真度双三角翼空气动力学数据集，使用VLM和RANS求解器；2) 采用嵌套Saltelli采样生成几何形状；3) 构建6个不同大小的训练数据集（40-1280个快照）；4) 训练不同参数规模（0.1-2.4百万）的MF-VortexNet图神经网络代理模型；5) 在固定训练预算下进行经验缩放研究。

Result: 测试误差随数据量增加呈幂律下降，指数为-0.6122，表明数据利用效率高。基于缩放规律，估计d维设计空间的最优采样密度约为每维度8个样本。较大代理模型的数据利用效率更高，暗示数据集生成成本与模型训练预算之间存在权衡。

Conclusion: 本研究提供了开源多保真度空气动力学数据集和关于数据量与模型性能关系的经验指导，发现幂律缩放规律和最优采样密度，为车辆设计中的代理模型开发提供了实用参考，并揭示了数据生成成本与模型训练预算的潜在权衡。

Abstract: Data-driven surrogate models are increasingly adopted to accelerate vehicle design. However, open-source multi-fidelity datasets and empirical guidelines linking dataset size to model performance remain limited. This study investigates the relationship between training data size and prediction accuracy for a graph neural network (GNN) based surrogate model for aerodynamic field prediction. We release an open-source, multi-fidelity aerodynamic dataset for double-delta wings, comprising 2448 flow snapshots across 272 geometries evaluated at angles of attack from 11 (degree) to 19 (degree) at Ma=0.3 using both Vortex Lattice Method (VLM) and Reynolds-Averaged Navier-Stokes (RANS) solvers. The geometries are generated using a nested Saltelli sampling scheme to support future dataset expansion and variance-based sensitivity analysis. Using this dataset, we conduct a preliminary empirical scaling study of the MF-VortexNet surrogate by constructing six training datasets with sizes ranging from 40 to 1280 snapshots and training models with 0.1 to 2.4 million parameters under a fixed training budget. We find that the test error decreases with data size with a power-law exponent of -0.6122, indicating efficient data utilization. Based on this scaling law, we estimate that the optimal sampling density is approximately eight samples per dimension in a d-dimensional design space. The results also suggest improved data utilization efficiency for larger surrogate models, implying a potential trade-off between dataset generation cost and model training budget.

</details>


### [68] [Solving Functional PDEs with Gaussian Processes and Applications to Functional Renormalization Group Equations](https://arxiv.org/abs/2512.20956)
*Xianjin Yang,Matthieu Darcy,Matthew Hudes,Francis J. Alexander,Gregory Eyink,Houman Owhadi*

Main category: cs.LG

TL;DR: 提出一种基于高斯过程算子学习的框架，用于求解非微扰泛函重整化群方程，直接在函数空间构建泛函表示，不依赖于特定方程或离散化。


<details>
  <summary>Details</summary>
Motivation: 解决非微扰泛函重整化群方程（如Wetterich和Wilson-Polchinski方程）的数值求解问题，传统方法如局域势近似存在局限性，需要更灵活且能处理非恒定场的方法。

Method: 使用高斯过程算子学习框架，直接在函数空间构建泛函表示，通过先验均值或核设计融入物理先验知识，适用于广泛的泛函微分方程。

Result: 该方法在多个相关方程上表现优异，达到或超越了现有近似方法（如局域势近似）的性能，同时显著提高了灵活性，能够处理非恒定场。

Conclusion: 提出的算子学习框架为求解泛函重整化群方程提供了灵活有效的工具，特别适合研究更复杂的场构型（如瞬子），具有广阔的应用前景。

Abstract: We present an operator learning framework for solving non-perturbative functional renormalization group equations, which are integro-differential equations defined on functionals. Our proposed approach uses Gaussian process operator learning to construct a flexible functional representation formulated directly on function space, making it independent of a particular equation or discretization. Our method is flexible, and can apply to a broad range of functional differential equations while still allowing for the incorporation of physical priors in either the prior mean or the kernel design. We demonstrate the performance of our method on several relevant equations, such as the Wetterich and Wilson--Polchinski equations, showing that it achieves equal or better performance than existing approximations such as the local-potential approximation, while being significantly more flexible. In particular, our method can handle non-constant fields, making it promising for the study of more complex field configurations, such as instantons.

</details>


### [69] [ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design](https://arxiv.org/abs/2512.20958)
*R Yadunandan,Nimisha Ghosh*

Main category: cs.LG

TL;DR: ReACT-Drug是一个基于强化学习的靶点无关药物设计框架，利用ESM-2蛋白嵌入识别相似蛋白，分解已知配体构建片段搜索空间，通过PPO智能体指导ChemBERTa编码分子进行反应模板化转换，生成具有高结合亲和力和合成可及性的全新药物候选物。


<details>
  <summary>Details</summary>
Motivation: 传统从头药物设计面临化学空间巨大、合成可及性差、高亲和力候选物难以发现的挑战。强化学习能够进行多目标优化和探索新颖化学空间，这是传统监督学习方法所缺乏的能力。

Method: 1. 利用ESM-2蛋白嵌入从PDB等知识库中识别与给定靶点相似的蛋白质；2. 分解这些蛋白质的已知药物配体，构建基于片段的搜索空间；3. 使用PPO强化学习智能体指导ChemBERTa编码的分子，在化学有效的反应模板化转换动态动作空间中进行优化；4. 确保100%化学有效性和新颖性。

Result: 生成了具有竞争性结合亲和力和高合成可及性的全新药物候选物，通过MOSES基准测试验证了100%化学有效性和新颖性。该框架展示了整合结构生物学、深度表征学习和化学合成规则实现自动化理性药物设计的潜力。

Conclusion: ReACT-Drug是一个完全集成的靶点无关分子设计框架，通过整合蛋白结构信息、深度学习和化学规则，能够自动化加速理性药物设计过程，为药物发现提供了新的有效方法。

Abstract: De novo drug design is a crucial component of modern drug development, yet navigating the vast chemical space to find synthetically accessible, high-affinity candidates remains a significant challenge. Reinforcement Learning (RL) enhances this process by enabling multi-objective optimization and exploration of novel chemical space - capabilities that traditional supervised learning methods lack. In this work, we introduce \textbf{ReACT-Drug}, a fully integrated, target-agnostic molecular design framework based on Reinforcement Learning. Unlike models requiring target-specific fine-tuning, ReACT-Drug utilizes a generalist approach by leveraging ESM-2 protein embeddings to identify similar proteins for a given target from a knowledge base such as Protein Data Base (PDB). Thereafter, the known drug ligands corresponding to such proteins are decomposed to initialize a fragment-based search space, biasing the agent towards biologically relevant subspaces. For each such fragment, the pipeline employs a Proximal Policy Optimization (PPO) agent guiding a ChemBERTa-encoded molecule through a dynamic action space of chemically valid, reaction-template-based transformations. This results in the generation of \textit{de novo} drug candidates with competitive binding affinities and high synthetic accessibility, while ensuring 100\% chemical validity and novelty as per MOSES benchmarking. This architecture highlights the potential of integrating structural biology, deep representation learning, and chemical synthesis rules to automate and accelerate rational drug design. The dataset and code are available at https://github.com/YadunandanRaman/ReACT-Drug/.

</details>


### [70] [Can Agentic AI Match the Performance of Human Data Scientists?](https://arxiv.org/abs/2512.20959)
*An Luo,Jin Du,Fangqiao Tian,Xun Xian,Robert Specht,Ganghua Wang,Xuan Bi,Charles Fleming,Jayanth Srinivasa,Ashish Kundu,Mingyi Hong,Jie Ding*

Main category: cs.LG

TL;DR: 当前基于大语言模型的智能体AI在数据科学中无法匹敌人类专家，因为缺乏领域知识来识别隐藏在图像数据中的关键潜在变量


<details>
  <summary>Details</summary>
Motivation: 探索智能体AI系统是否能够真正匹配人类数据科学家的性能，特别是在需要领域知识来识别隐藏变量的场景中

Method: 设计了一个预测任务，其中关键潜在变量隐藏在相关图像数据中而非表格特征中，使用财产保险的合成数据集进行实验

Result: 实验表明，依赖通用分析流程的智能体AI表现不佳，而能够利用领域特定洞察的方法表现更好

Conclusion: 当前数据科学智能体AI存在关键局限性，需要未来研究开发能够更好识别和整合领域知识的智能体AI系统

Abstract: Data science plays a critical role in transforming complex data into actionable insights across numerous domains. Recent developments in large language models (LLMs) have significantly automated data science workflows, but a fundamental question persists: Can these agentic AI systems truly match the performance of human data scientists who routinely leverage domain-specific knowledge? We explore this question by designing a prediction task where a crucial latent variable is hidden in relevant image data instead of tabular features. As a result, agentic AI that generates generic codes for modeling tabular data cannot perform well, while human experts could identify the important hidden variable using domain knowledge. We demonstrate this idea with a synthetic dataset for property insurance. Our experiments show that agentic AI that relies on generic analytics workflow falls short of methods that use domain-specific insights. This highlights a key limitation of the current agentic AI for data science and underscores the need for future research to develop agentic AI systems that can better recognize and incorporate domain knowledge.

</details>


### [71] [Generalization of Diffusion Models Arises with a Balanced Representation Space](https://arxiv.org/abs/2512.20963)
*Zekai Zhang,Xiao Li,Xiang Li,Lianghe Shi,Meng Wu,Molei Tao,Qing Qu*

Main category: cs.LG

TL;DR: 论文通过表示学习视角分析扩散模型中的记忆化与泛化现象，提出记忆化对应"尖峰"表示而泛化对应"平衡"表示，并基于此开发了记忆化检测和表示引导的编辑方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然能生成高质量多样样本，但存在记忆训练数据的风险。需要理解记忆化与泛化的本质区别，以促进更好的生成建模。

Method: 1) 通过两层ReLU去噪自编码器(DAE)进行理论分析；2) 在真实无条件扩散模型和文生图模型上验证理论发现；3) 提出基于表示的记忆化检测方法；4) 开发无需训练、通过表示引导的编辑技术。

Result: 证明记忆化对应学习权重中存储原始训练样本的"尖峰"表示，泛化对应捕捉局部数据统计的"平衡"表示。在真实扩散模型中观察到相同表示结构，验证了理论发现。

Conclusion: 学习良好表示是新颖且有意义的生成建模的核心。基于表示的分析框架为理解扩散模型行为提供了新视角，并启发了实用的记忆化检测和编辑方法。

Abstract: Diffusion models excel at generating high-quality, diverse samples, yet they risk memorizing training data when overfit to the training objective. We analyze the distinctions between memorization and generalization in diffusion models through the lens of representation learning. By investigating a two-layer ReLU denoising autoencoder (DAE), we prove that (i) memorization corresponds to the model storing raw training samples in the learned weights for encoding and decoding, yielding localized "spiky" representations, whereas (ii) generalization arises when the model captures local data statistics, producing "balanced" representations. Furthermore, we validate these theoretical findings on real-world unconditional and text-to-image diffusion models, demonstrating that the same representation structures emerge in deep generative models with significant practical implications. Building on these insights, we propose a representation-based method for detecting memorization and a training-free editing technique that allows precise control via representation steering. Together, our results highlight that learning good representations is central to novel and meaningful generative modeling.

</details>


### [72] [Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions](https://arxiv.org/abs/2512.20974)
*Jingyang You,Hanna Kurniawati*

Main category: cs.LG

TL;DR: 提出GLiBRL方法，通过可学习基函数的广义线性模型改进深度贝叶斯强化学习，实现高效准确的转移和奖励模型学习，在MetaWorld基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯强化学习方法假设已知转移和奖励模型形式，限制了实际应用。现有深度贝叶斯方法虽然引入模型学习，但需要优化ELBO，这难以优化且可能导致任务参数不明确，从而影响策略质量。

Method: 提出GLiBRL方法，使用可学习基函数的广义线性模型，实现完全可处理的边际似然和贝叶斯推断，能够高效准确地学习转移和奖励模型。

Result: 在MetaWorld ML10/45基准测试中，GLiBRL将最先进的深度贝叶斯方法VariBAD的成功率提升高达2.7倍。相比其他代表性方法如MAML、RL2、SDVT、TrMRL和ECET，GLiBRL表现出低方差和稳定的良好性能。

Conclusion: GLiBRL通过可学习基函数的广义线性模型解决了深度贝叶斯强化学习中模型学习的挑战，提供了高效准确的解决方案，在多个基准测试中表现出优越性能。

Abstract: Bayesian Reinforcement Learning (BRL) provides a framework for generalisation of Reinforcement Learning (RL) problems from its use of Bayesian task parameters in the transition and reward models. However, classical BRL methods assume known forms of transition and reward models, reducing their applicability in real-world problems. As a result, recent deep BRL methods have started to incorporate model learning, though the use of neural networks directly on the joint data and task parameters requires optimising the Evidence Lower Bound (ELBO). ELBOs are difficult to optimise and may result in indistinctive task parameters, hence compromised BRL policies. To this end, we introduce a novel deep BRL method, Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions (GLiBRL), that enables efficient and accurate learning of transition and reward models, with fully tractable marginal likelihood and Bayesian inference on task parameters and model noises. On challenging MetaWorld ML10/45 benchmarks, GLiBRL improves the success rate of one of the state-of-the-art deep BRL methods, VariBAD, by up to 2.7x. Comparing against representative or recent deep BRL / Meta-RL methods, such as MAML, RL2, SDVT, TrMRL and ECET, GLiBRL also demonstrates its low-variance and decent performance consistently.

</details>


### [73] [CoSeNet: A Novel Approach for Optimal Segmentation of Correlation Matrices](https://arxiv.org/abs/2512.21000)
*Alberto. Palomo-Alonso,David Casillas-Perez,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,Sancho Salcedo-Sanz*

Main category: cs.LG

TL;DR: CoSeNet是一个用于噪声相关矩阵中相关段最优识别的四层算法架构，通过重叠技术和预训练ML算法实现鲁棒分割，使用启发式算法优化参数，输出无噪声二值矩阵和分割点。


<details>
  <summary>Details</summary>
Motivation: 现有方法在噪声相关矩阵中识别相关段的效果有限，需要一种更有效、鲁棒且可泛化的解决方案来准确识别相关段，并在效率、内存和速度之间取得平衡。

Method: 提出CoSeNet四层架构：输入层、格式化层、重缩放层和分割层。采用重叠技术处理数据，使用预训练机器学习算法，通过启发式算法和基于窗口差异度量的适应度函数优化重缩放层参数。

Result: CoSeNet能够有效识别噪声相关矩阵中的相关段，性能优于先前类似问题的方法。模型输出无噪声二值矩阵和分割点，在效率、内存和速度之间取得折衷解决方案。

Conclusion: CoSeNet为噪声相关矩阵中的相关段识别提供了一种新颖有效的解决方案，具有鲁棒性和可泛化性，适用于多种应用场景，在计算资源约束下实现了性能平衡。

Abstract: In this paper, we propose a novel approach for the optimal identification of correlated segments in noisy correlation matrices. The proposed model is known as CoSeNet (Correlation Seg-mentation Network) and is based on a four-layer algorithmic architecture that includes several processing layers: input, formatting, re-scaling, and segmentation layer. The proposed model can effectively identify correlated segments in such matrices, better than previous approaches for similar problems. Internally, the proposed model utilizes an overlapping technique and uses pre-trained Machine Learning (ML) algorithms, which makes it robust and generalizable. CoSeNet approach also includes a method that optimizes the parameters of the re-scaling layer using a heuristic algorithm and fitness based on a Window Difference-based metric. The output of the model is a binary noise-free matrix representing optimal segmentation as well as its seg-mentation points and can be used in a variety of applications, obtaining compromise solutions between efficiency, memory, and speed of the proposed deployment model.

</details>


### [74] [LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics](https://arxiv.org/abs/2512.21010)
*Jiashuo Liu,Jiayun Wu,Chunjie Wu,Jingkai Liu,Zaiyuan Wang,Huan Zhou,Wenhao Huang,Hongseok Namkoong*

Main category: cs.LG

TL;DR: 提出CSD框架，通过模拟多轮瑞士制竞赛动态配对模型，结合蒙特卡洛模拟计算期望胜率，提供比传统静态评分更细粒度的LLM评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估方法主要依赖静态评分，存在局限性：难以确定不同基准测试的合理混合比例，无法捕捉模型在连续高风险任务中的动态竞争能力和脆弱性。

Method: 提出竞争性瑞士制动态框架(CSD)，模拟多轮顺序竞赛，根据累积胜负记录动态配对模型；使用蒙特卡洛模拟(N=100,000次迭代)计算统计稳健的期望胜分；通过参数化每轮淘汰数量进行失败敏感性分析，区分稳健通用型和激进专业型模型。

Result: CSD相比传统聚合评分和静态配对模型，能提供更细致、上下文感知的排名，代表了向风险感知的下一代LLM评估迈出的重要一步。

Conclusion: CSD框架解决了传统LLM评估方法的局限性，通过动态竞争模拟和风险分析，为模型评估提供了更全面、更实用的排名系统。

Abstract: The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fitness or its vulnerability when confronted with sequential, high-stakes tasks. To address this, we introduce the novel Competitive Swiss-System Dynamics (CSD) framework. CSD simulates a multi-round, sequential contest where models are dynamically paired across a curated sequence of benchmarks based on their accumulated win-loss record. And Monte Carlo Simulation ($N=100,000$ iterations) is used to approximate the statistically robust Expected Win Score ($E[S_m]$), which eliminates the noise of random pairing and early-round luck. Furthermore, we implement a Failure Sensitivity Analysis by parameterizing the per-round elimination quantity ($T_k$), which allows us to profile models based on their risk appetite--distinguishing between robust generalists and aggressive specialists. We demonstrate that CSD provides a more nuanced and context-aware ranking than traditional aggregate scoring and static pairwise models, representing a vital step towards risk-informed, next-generation LLM evaluation.

</details>


### [75] [Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics](https://arxiv.org/abs/2512.21075)
*Zihan Yao,Ruoyu Wu,Tianxiang Gao*

Main category: cs.LG

TL;DR: 论文提出神经特征动力学（NFD）理论，用于分析ResNet在无限宽度和深度极限下的特征学习机制，解释了缩放定律失效原因，并提出深度感知学习率修正方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习经验成功常归因于缩放定律，但大模型会出现训练不稳定和收益递减现象。现有方法（如muP）在深度扩展时失效，缺乏对深度特征学习的严格理解。

Method: 推导ResNet单层残差块的神经特征动力学（NFD），在联合无限宽度和深度极限下通过耦合前向-后向随机系统表征特征学习。研究两层残差块的特征学习崩溃机制。

Result: NFD识别了缩放定律趋势持续的条件，解释了收益递减现象。揭示了1/√深度残差缩放导致的梯度独立性假设在无限深度下重新成立，为端到端特征学习提供解析可处理机制。

Conclusion: 基于对两层残差块特征学习崩溃的诊断，提出深度感知学习率修正方法，有效恢复深度超参数传递，在更深ResNet中实现更强性能。

Abstract: The empirical success of deep learning is often attributed to scaling laws that predict consistent gains as model, data, and compute grow; however, large models can exhibit training instability and diminishing returns, suggesting that scaling laws describe what success looks like but not when and why scaling succeeds or fails. A central obstacle is the lack of a rigorous understanding of feature learning at large depth. While muP characterizes feature-learning dynamics in the infinite-width limit and enables hyperparameter transfer across width, its depth extension (depth-muP) breaks down for residual blocks with more than one internal layer. We derive Neural Feature Dynamics (NFD) for ResNets with single-layer residual blocks, characterizing feature learning via a coupled forward-backward stochastic system in the joint infinite-width and infinite-depth limit. In this regime, NFD identifies when scaling-law trends persist and explains diminishing returns. It also reveals a vanishing mechanism induced by the 1/sqrt(depth) residual scaling under which the gradient-independence assumption (GIA), known to fail during training at finite depth, becomes provably valid again at infinite depth, yielding an analytically tractable regime for end-to-end feature learning. Motivated by this insight, we study two-layer residual blocks and show that the same mechanism causes feature-learning collapse in the first internal layer at large depth, providing a structural explanation for the empirical failure of depth-muP. Based on this diagnosis, we propose a depth-aware learning-rate correction that counteracts the collapse and empirically restores depth-wise hyperparameter transfer, yielding stronger performance in deeper ResNets.

</details>


### [76] [Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends](https://arxiv.org/abs/2512.21102)
*Zixiao Huang,Jixiao Yang,Sijia Li,Chi Zhang,Jinyu Chen,Chengda Xu*

Main category: cs.LG

TL;DR: 提出统一预测框架处理云原生后端系统的高维多任务时间序列预测，通过共享编码、状态融合、跨任务传播和动态调整机制，在动态负载、耦合指标和平行任务环境下实现稳定预测。


<details>
  <summary>Details</summary>
Motivation: 云原生后端系统在高度动态负载、耦合指标和平行任务环境下，需要准确预测高维多任务时间序列，以支持智能后端管理，但现有方法难以处理这种复杂场景。

Method: 1) 构建共享编码结构统一表示多样化监控指标；2) 状态融合机制捕捉不同时间尺度的趋势变化和局部扰动；3) 跨任务结构传播模块建模节点间潜在依赖关系；4) 动态调整机制根据系统状态变化自动调节内部特征流。

Result: 实验评估显示该方法在多个误差指标上优于其他模型，在不同运行条件下能更准确地表示未来状态，并通过超参数敏感性、环境敏感性和数据敏感性分析验证了框架的有效性。

Conclusion: 该统一预测框架为云原生系统的高维多任务强动态环境提供了可靠的预测能力，为智能后端管理提供了关键技术支撑。

Abstract: This study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.

</details>


### [77] [A Mechanistic Analysis of Transformers for Dynamical Systems](https://arxiv.org/abs/2512.21113)
*Gregory Duthé,Nikolaos Evangelou,Wei Liu,Ioannis G. Kevrekidis,Eleni Chatzi*

Main category: cs.LG

TL;DR: 论文从动力系统视角分析单层Transformer的表示能力，发现softmax注意力的凸性约束限制了线性振荡系统的表示能力，而在非线性部分可观测系统中注意力可作为自适应延迟嵌入机制进行状态重构。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列建模中广泛应用但内部机制缺乏理论理解，与经典自回归和状态空间模型相比缺乏理论基础。随着注意力模型被考虑用于跨不同动力机制的通用途或零样本预测，理解其表示能力和限制变得尤为重要。

Method: 从动力系统视角将因果自注意力解释为线性历史依赖递归，通过线性和非线性案例研究分析其处理时间信息的方式。研究单层Transformer在动力数据上的表示能力。

Result: 对于线性系统，softmax注意力的凸性约束从根本上限制了可表示的动态类别，导致在振荡设置中出现过度平滑。对于非线性部分可观测系统，注意力作为自适应延迟嵌入机制，在足够时间上下文和潜在维度可用时能够有效进行状态重构。

Conclusion: 研究结果有助于将经验观察与经典动力系统理论联系起来，为理解Transformer作为动力系统模型何时成功或失败提供了见解，填补了Transformer在时间序列建模中理论基础的空白。

Abstract: Transformers are increasingly adopted for modeling and forecasting time-series, yet their internal mechanisms remain poorly understood from a dynamical systems perspective. In contrast to classical autoregressive and state-space models, which benefit from well-established theoretical foundations, Transformer architectures are typically treated as black boxes. This gap becomes particularly relevant as attention-based models are considered for general-purpose or zero-shot forecasting across diverse dynamical regimes. In this work, we do not propose a new forecasting model, but instead investigate the representational capabilities and limitations of single-layer Transformers when applied to dynamical data. Building on a dynamical systems perspective we interpret causal self-attention as a linear, history-dependent recurrence and analyze how it processes temporal information. Through a series of linear and nonlinear case studies, we identify distinct operational regimes. For linear systems, we show that the convexity constraint imposed by softmax attention fundamentally restricts the class of dynamics that can be represented, leading to oversmoothing in oscillatory settings. For nonlinear systems under partial observability, attention instead acts as an adaptive delay-embedding mechanism, enabling effective state reconstruction when sufficient temporal context and latent dimensionality are available. These results help bridge empirical observations with classical dynamical systems theory, providing insight into when and why Transformers succeed or fail as models of dynamical systems.

</details>


### [78] [STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting](https://arxiv.org/abs/2512.21118)
*Shi Quan Foo,Chi-Ho Wong,Zhihan Gao,Dit-Yan Yeung,Ka-Hing Wong,Wai-Kin Wong*

Main category: cs.LG

TL;DR: STLDM是一种基于扩散模型的降水临近预报方法，通过变分自编码器和条件网络学习潜在表示，将任务分解为确定性预报和增强两个阶段，在多个雷达数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报对预防极端天气灾害至关重要，但现有方法面临挑战：确定性模型预测模糊，生成模型精度不足。需要一种能平衡准确性和清晰度的方法。

Method: STLDM采用端到端的扩散模型架构，结合变分自编码器和条件网络学习潜在表示。将任务分解为：1）条件网络处理确定性预报阶段；2）潜在扩散模型执行增强阶段。

Result: 在多个雷达数据集上的实验表明，STLDM相比现有最先进方法取得了更优的性能，同时提高了推理效率。

Conclusion: STLDM通过两阶段分解方法有效解决了降水临近预报中确定性模型模糊和生成模型精度不足的问题，实现了高性能和高效率的预测。

Abstract: Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.

</details>


### [79] [MODE: Multi-Objective Adaptive Coreset Selection](https://arxiv.org/abs/2512.21152)
*Tanmoy Mukherjee,Pierre Marquis,Zied Bouraoui*

Main category: cs.LG

TL;DR: MODE是一个动态调整核心集选择策略的框架，根据训练阶段自适应选择数据，在减少内存需求的同时保持模型性能


<details>
  <summary>Details</summary>
Motivation: 现有核心集选择方法通常是静态的，无法适应训练不同阶段的数据需求变化。需要一种能够根据训练进展动态调整数据选择策略的方法

Method: 提出MODE框架，动态组合多种核心集选择策略：早期强调类别平衡，中期关注多样性，后期聚焦不确定性。算法复杂度为O(n log n)，提供(1-1/e)近似保证

Result: 实验显示MODE在减少内存需求的同时保持竞争力，并提供数据效用演化的可解释性洞察

Conclusion: MODE通过动态适应训练阶段的核心集选择策略，实现了高效的数据利用，为理解数据效用演化提供了新视角

Abstract: We present Mode(Multi-Objective adaptive Data Efficiency), a framework that dynamically combines coreset selection strategies based on their evolving contribution to model performance. Unlike static methods, \mode adapts selection criteria to training phases: emphasizing class balance early, diversity during representation learning, and uncertainty at convergence. We show that MODE achieves (1-1/e)-approximation with O(n \log n) complexity and demonstrates competitive accuracy while providing interpretable insights into data utility evolution. Experiments show \mode reduces memory requirements

</details>


### [80] [BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft](https://arxiv.org/abs/2512.21165)
*Qizhi Wang*

Main category: cs.LG

TL;DR: BALLAST使用上下文多臂老虎机替代Raft中静态随机超时机制，通过安全探索在线自适应调整超时，显著改善长尾延迟和分区恢复下的可用性。


<details>
  <summary>Details</summary>
Motivation: Raft的随机选举超时机制在长尾延迟、抖动和分区恢复场景下变得脆弱，重复的分裂投票会显著增加不可用时间。

Method: BALLAST采用轻量级在线自适应机制，使用线性上下文多臂老虎机（LinUCB变体）从离散的超时选项中选择，并通过安全探索限制不稳定期间的风险。

Result: 在包含长尾延迟、丢包、相关突发、节点异构性和分区/恢复扰动的可重现离散事件模拟中，BALLAST在挑战性WAN环境下显著减少恢复时间和不可写时间，同时在稳定LAN/WAN设置中保持竞争力。

Conclusion: BALLAST通过上下文多臂老虎机实现的自适应超时机制，有效解决了Raft在复杂网络条件下的可用性问题，相比传统随机超时和常见启发式方法有显著改进。

Abstract: Randomized election timeouts are a simple and effective liveness heuristic for Raft, but they become brittle under long-tail latency, jitter, and partition recovery, where repeated split votes can inflate unavailability. This paper presents BALLAST, a lightweight online adaptation mechanism that replaces static timeout heuristics with contextual bandits. BALLAST selects from a discrete set of timeout "arms" using efficient linear contextual bandits (LinUCB variants), and augments learning with safe exploration to cap risk during unstable periods. We evaluate BALLAST on a reproducible discrete-event simulation with long-tail delay, loss, correlated bursts, node heterogeneity, and partition/recovery turbulence. Across challenging WAN regimes, BALLAST substantially reduces recovery time and unwritable time compared to standard randomized timeouts and common heuristics, while remaining competitive on stable LAN/WAN settings.

</details>


### [81] [A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine](https://arxiv.org/abs/2512.21170)
*Yogesh Kumar,Vrushank Ahire,M. A. Ganaie*

Main category: cs.LG

TL;DR: 提出两种Universum增强的EEG信号分类器：U-GEPSVM和IU-GEPSVM，利用广义特征值分解的计算效率和Universum学习的泛化优势，在Bonn大学EEG数据集上取得优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决EEG信号分析中的关键挑战：非平稳性、低信噪比和有限标记数据。传统方法在处理这些问题时存在局限性，需要更有效的分类器。

Method: 提出两种新模型：1) U-GEPSVM：通过基于比值的目标函数将Universum约束扩展到GEPSVM框架；2) IU-GEPSVM：通过加权差异公式增强稳定性，提供对类别分离和Universum对齐的独立控制。

Result: 在Bonn大学EEG数据集的两个二分类任务上评估：(O vs S)-健康（闭眼）vs癫痫，和(Z vs S)-健康（睁眼）vs癫痫。IU-GEPSVM达到峰值准确率85%（O vs S）和80%（Z vs S），平均准确率分别为81.29%和77.57%，优于基线方法。

Conclusion: 提出的Universum增强分类器能有效处理EEG信号分类中的挑战，IU-GEPSVM在准确率和稳定性方面表现最佳，为EEG分析提供了有前景的解决方案。

Abstract: The paper presents novel Universum-enhanced classifiers: the Universum Generalized Eigenvalue Proximal Support Vector Machine (U-GEPSVM) and the Improved U-GEPSVM (IU-GEPSVM) for EEG signal classification. Using the computational efficiency of generalized eigenvalue decomposition and the generalization benefits of Universum learning, the proposed models address critical challenges in EEG analysis: non-stationarity, low signal-to-noise ratio, and limited labeled data. U-GEPSVM extends the GEPSVM framework by incorporating Universum constraints through a ratio-based objective function, while IU-GEPSVM enhances stability through a weighted difference-based formulation that provides independent control over class separation and Universum alignment. The models are evaluated on the Bonn University EEG dataset across two binary classification tasks: (O vs S)-healthy (eyes closed) vs seizure, and (Z vs S)-healthy (eyes open) vs seizure. IU-GEPSVM achieves peak accuracies of 85% (O vs S) and 80% (Z vs S), with mean accuracies of 81.29% and 77.57% respectively, outperforming baseline methods.

</details>


### [82] [Analytic and Variational Stability of Deep Learning Systems](https://arxiv.org/abs/2512.21208)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出统一的分析和变分框架研究深度学习系统的稳定性，通过"学习稳定性剖面"追踪表示、参数和更新机制对扰动的响应，证明稳定性特征有界等价于存在Lyapunov型能量耗散。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习稳定性分析缺乏统一框架，不同架构和优化方法的稳定性研究分散。需要建立能够统一描述各种深度学习系统（包括平滑和非平滑情况）稳定性的理论框架，阐明架构和算法选择如何共同影响系统对扰动的鲁棒性和敏感性。

Method: 提出学习稳定性剖面作为核心工具，追踪表示、参数和更新机制沿学习轨迹对扰动的无穷小响应。证明基本分析稳定性定理，将稳定性特征的一致有界性与Lyapunov型能量耗散等价。对于平滑系统，推导显式稳定性指数；对于非平滑系统（如ReLU网络、近端更新），使用Clarke广义导数和变分Lyapunov泛函扩展框架。

Result: 建立了统一的动力学稳定性框架，能够推导出前馈网络的经典谱稳定性结果、残差架构的离散CFL型条件、随机梯度方法的参数和时间稳定性定律。框架适用于各种架构和优化方法，为理解深度学习系统稳定性提供了理论基础。

Conclusion: 该框架为深度学习系统稳定性提供了统一的理论描述，阐明了架构和算法选择如何共同决定学习动力学的鲁棒性。为扩展到连续时间极限和学习动力学的几何表述奠定了基础，具有重要的理论和实践意义。

Abstract: We propose a unified analytic and variational framework for studying stability in deep learning systems viewed as coupled representation-parameter dynamics. The central object is the Learning Stability Profile, which tracks the infinitesimal response of representations, parameters, and update mechanisms to perturbations along the learning trajectory. We prove a Fundamental Analytic Stability Theorem showing that uniform boundedness of these stability signatures is equivalent, up to norm equivalence, to the existence of a Lyapunov-type energy that dissipates along the learning flow. In smooth regimes, the framework yields explicit stability exponents linking spectral norms, activation regularity, step sizes, and learning rates to contractivity of the learning dynamics. Classical spectral stability results for feedforward networks, a discrete CFL-type condition for residual architectures, and parametric and temporal stability laws for stochastic gradient methods arise as direct consequences. The theory extends to non-smooth learning systems, including ReLU networks, proximal and projected updates, and stochastic subgradient flows, by replacing classical derivatives with Clarke generalized derivatives and smooth energies with variational Lyapunov functionals. The resulting framework provides a unified dynamical description of stability across architectures and optimization methods, clarifying how architectural and algorithmic choices jointly govern robustness and sensitivity to perturbations. It also provides a foundation for further extensions to continuous-time limits and geometric formulations of learning dynamics.

</details>


### [83] [MiST: Understanding the Role of Mid-Stage Scientific Training in Developing Chemical Reasoning Models](https://arxiv.org/abs/2512.21231)
*Andres M Bran,Tong Xie,Shai Pranesh,Jeffrey Meng,Xuan Vu Nguyen,Jeremy Goumaz,David Ming Segura,Ruizhi Xu,Dongzhan Zhou,Wenjie Zhang,Bram Hoex,Philippe Schwaller*

Main category: cs.LG

TL;DR: 该研究提出MiST方法，通过中间阶段训练提升大语言模型在化学推理任务中的表现，解决了RL训练需要"潜在可解性"的问题


<details>
  <summary>Details</summary>
Motivation: 研究发现强化学习在化学推理任务中成功的前提是基础模型已经对正确答案分配了不可忽略的概率（即"潜在可解性"），但现有模型缺乏这种能力，需要开发方法来满足化学推理的两个必要条件

Method: 提出MiST中间阶段科学训练方法，包括：1）SMILES/CIF感知预处理的数据混合；2）在29亿token上的持续预训练；3）在10亿token上的监督微调，以提升模型的符号能力和潜在化学知识

Result: MiST将3B和7B模型的潜在可解性分数提升1.8倍，使有机反应命名的top-1准确率从10.9%提升到63.9%，无机材料生成的准确率从40.6%提升到67.4%，在其他化学任务上也观察到类似改进

Conclusion: 研究明确了化学推理训练的必要条件，强调了中间阶段训练在解锁推理能力中的重要作用，为科学领域的AI推理提供了方法论指导

Abstract: Large Language Models can develop reasoning capabilities through online fine-tuning with rule-based rewards. However, recent studies reveal a critical constraint: reinforcement learning succeeds only when the base model already assigns non-negligible probability to correct answers -- a property we term 'latent solvability'. This work investigates the emergence of chemical reasoning capabilities and what these prerequisites mean for chemistry. We identify two necessary conditions for RL-based chemical reasoning: 1) Symbolic competence, and 2) Latent chemical knowledge. We propose mid-stage scientific training (MiST): a set of mid-stage training techniques to satisfy these, including data-mixing with SMILES/CIF-aware pre-processing, continued pre-training on 2.9B tokens, and supervised fine-tuning on 1B tokens. These steps raise the latent-solvability score on 3B and 7B models by up to 1.8x, and enable RL to lift top-1 accuracy from 10.9 to 63.9% on organic reaction naming, and from 40.6 to 67.4% on inorganic material generation. Similar results are observed for other challenging chemical tasks, while producing interpretable reasoning traces. Our results define clear prerequisites for chemical reasoning training and highlight the broader role of mid-stage training in unlocking reasoning capabilities.

</details>


### [84] [Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks](https://arxiv.org/abs/2512.21241)
*Xinjie Xu,Shuyu Cheng,Dongwei Xu,Qi Xuan,Chen Ma*

Main category: cs.LG

TL;DR: 提出AR-OPT和PAR-OPT两种动量优化算法，显著降低硬标签黑盒对抗攻击的查询复杂度


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒对抗攻击中仅能获取top-1预测标签，查询复杂度过高限制了实际应用，需要更高效的优化方法

Method: 基于Nesterov加速梯度思想，提出AR-OPT算法利用动量预测未来射线方向梯度；进一步结合代理模型先验知识，提出PAR-OPT算法增强梯度估计

Result: 在ImageNet和CIFAR-10数据集上超越13种最先进方法，显著提高查询效率；理论分析证明算法具有更快、更稳定的收敛性

Conclusion: 提出的动量优化框架有效解决了硬标签黑盒对抗攻击的高查询复杂度问题，为实际部署提供了可行的解决方案

Abstract: In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov's Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT's gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.

</details>


### [85] [Model Merging via Multi-Teacher Knowledge Distillation](https://arxiv.org/abs/2512.21288)
*Seyed Arshan Dalili,Mehrdad Mahdavi*

Main category: cs.LG

TL;DR: 该论文提出了SAMerging方法，通过PAC-Bayes理论分析模型合并的泛化性能，并利用SAM寻找平坦最小值来优化合并过程，在视觉和NLP基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 模型合并作为轻量级多任务学习替代方案，其泛化性能缺乏理论保证。现有方法依赖启发式参数组合，特别是系数缩放权重缺乏原则性指导，导致性能脆弱且对初始化敏感。

Method: 1) 建立针对模型合并的平坦感知PAC-Bayes泛化界，引入"跨任务异质性"项；2) 将模型合并框架化为稀缺无标签数据上的多教师知识蒸馏；3) 提出SAMerging方法，利用SAM寻找平坦最小值来优化合并目标。

Result: SAMerging在视觉和NLP基准测试中建立了新的最先进性能，表现出卓越的性能表现。

Conclusion: 通过理论分析指导的SAMerging方法为模型合并提供了原则性框架，解决了现有启发式方法的局限性，在保持轻量级的同时实现了优异的泛化性能。

Abstract: Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model's contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a "cross-task heterogeneity" term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model's excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.

</details>


### [86] [Transcriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering](https://arxiv.org/abs/2512.21301)
*Abdullah G. Elafifi,Basma Mamdouh,Mariam Hanafy,Muhammed Alaa Eldin,Yosef Khaled,Nesma Mohamed El-Gelany,Tarek H. M. Abou-El-Enien*

Main category: cs.LG

TL;DR: 开发了一个结合系统生物学和进化元启发式算法的端到端计算框架，用于从AML患者转录组数据中发现个性化药物先导化合物


<details>
  <summary>Details</summary>
Motivation: 急性髓系白血病（AML）具有极高的分子异质性和高复发率，虽然精准医学引入了突变特异性疗法，但许多患者仍缺乏有效的个性化治疗选择

Method: 通过分析TCGA-LAML队列的RNA测序数据，使用WGCNA识别20个高价值生物标志物；用AlphaFold3建模靶点结构，DOGSiteScorer定位可药热点；开发反应优先的进化元启发式算法和多目标优化程序，从片段库组装新型配体

Result: 生成的结构独特化学实体具有药物样特性（QED评分0.5-0.7），验证显示配体L1对A08A96生物标志物的结合自由能为-6.571 kcal/mol，识别出高置信度候选药物

Conclusion: 系统生物学与元启发式分子组装相结合可以产生药理学可行的患者定制先导化合物，为AML及其他疾病的精准肿瘤学提供了可扩展的蓝图

Abstract: Acute Myeloid Leukemia (AML) remains a clinical challenge due to its extreme molecular heterogeneity and high relapse rates. While precision medicine has introduced mutation-specific therapies, many patients still lack effective, personalized options. This paper presents a novel, end-to-end computational framework that bridges the gap between patient-specific transcriptomics and de novo drug discovery. By analyzing bulk RNA sequencing data from the TCGA-LAML cohort, the study utilized Weighted Gene Co-expression Network Analysis (WGCNA) to prioritize 20 high-value biomarkers, including metabolic transporters like HK3 and immune-modulatory receptors such as SIGLEC9. The physical structures of these targets were modeled using AlphaFold3, and druggable hotspots were quantitatively mapped via the DOGSiteScorer engine. Then developed a novel, reaction-first evolutionary metaheuristic algorithm as well as multi-objective optimization programming that assembles novel ligands from fragment libraries, guided by spatial alignment to these identified hotspots. The generative model produced structurally unique chemical entities with a strong bias toward drug-like space, as evidenced by QED scores peaking between 0.5 and 0.7. Validation through ADMET profiling and SwissDock molecular docking identified high-confidence candidates, such as Ligand L1, which achieved a binding free energy of -6.571 kcal/mol against the A08A96 biomarker. These results demonstrate that integrating systems biology with metaheuristic molecular assembly can produce pharmacologically viable, patient tailored leads, offering a scalable blueprint for precision oncology in AML and beyond

</details>


### [87] [Learning to Solve PDEs on Neural Shape Representations](https://arxiv.org/abs/2512.21311)
*Lilian Welschinger,Yilin Liu,Zican Wang,Niloy Mitra*

Main category: cs.LG

TL;DR: 提出一种直接在神经表面表示上求解表面偏微分方程的网格无关方法，无需显式网格提取或逐实例优化，实现端到端工作流。


<details>
  <summary>Details</summary>
Motivation: 传统PDE求解器依赖多边形/三角形网格，而现代3D资产越来越多采用神经表示，这种不匹配导致无法直接在神经域中求解表面PDE，需要显式网格提取或逐实例残差训练，阻碍了端到端工作流程。

Method: 提出一种网格无关的公式，学习一个基于神经（局部）形状属性的局部更新算子。该算子与主流神经表面表示自然集成，在单个代表性形状上训练一次，可泛化到不同形状和拓扑变化。

Result: 在解析基准测试（球面上的热方程和泊松求解）和不同表示的真实神经资产上，该方法略微优于CPM，同时与FEM保持合理接近，提供了第一个在神经和经典表面表示上求解表面PDE的端到端管道。

Conclusion: 该方法实现了直接在神经表示上求解表面PDE，无需显式网格化或逐实例优化，保持可微性，为神经表面分析提供了有效的PDE求解框架。

Abstract: Solving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.

</details>


### [88] [Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks](https://arxiv.org/abs/2512.21315)
*Roy Turgeman,Tom Tirer*

Main category: cs.LG

TL;DR: 数据不等式原理表明信号处理不能增加信息量，但实际中低层处理常有助于分类。本文理论证明有限训练样本下，预处理能提高分类准确率，并通过实验验证。


<details>
  <summary>Details</summary>
Motivation: 数据不等式原理认为信号处理不能增加信息量，理论上最优贝叶斯分类器确实如此。但实践中，深度学习模型常先进行低层处理（如去噪、编码）再进行高层分类任务。本文旨在探究这种看似矛盾的现象：何时以及为何低层处理对分类有益。

Method: 1. 理论分析：建立与最优贝叶斯分类器紧密相关的二元分类框架，证明有限训练样本下存在能提高分类准确率的预处理方法。2. 参数研究：分析类别分离度、训练集大小、类别平衡性对预处理增益的影响。3. 实验验证：在理论设置下进行实证研究，并在实际数据集上考察去噪和编码对深度分类器性能的影响，特别是训练集大小、类别分布和噪声水平的变化。

Result: 1. 理论证明：对于任何有限训练样本，都存在能提高分类准确率的预处理方法。2. 参数影响：类别分离度、训练集大小和类别平衡性都会影响预处理的相对增益。3. 实验验证：在实际基准数据集上，去噪和编码对深度分类器性能的影响趋势与理论结果一致。

Conclusion: 虽然数据不等式原理在理论上成立，但在实际有限训练样本的情况下，低层预处理确实能提高分类性能。这种增益受多种因素影响，包括训练集大小、类别分离度和类别平衡性。研究为实践中常见的"先低层后高层"处理流程提供了理论依据。

Abstract: The data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification problem. This assertion can be proven to be true for the case of the optimal Bayes classifier. However, in practice, it is common to perform "low-level" tasks before "high-level" downstream tasks despite the overwhelming capabilities of modern deep neural networks. In this paper, we aim to understand when and why low-level processing can be beneficial for classification. We present a comprehensive theoretical study of a binary classification setup, where we consider a classifier that is tightly connected to the optimal Bayes classifier and converges to it as the number of training samples increases. We prove that for any finite number of training samples, there exists a pre-classification processing that improves the classification accuracy. We also explore the effect of class separation, training set size, and class balance on the relative gain from this procedure. We support our theory with an empirical investigation of the theoretical setup. Finally, we conduct an empirical study where we investigate the effect of denoising and encoding on the performance of practical deep classifiers on benchmark datasets. Specifically, we vary the size and class distribution of the training set, and the noise level, and demonstrate trends that are consistent with our theoretical results.

</details>


### [89] [Measuring all the noises of LLM Evals](https://arxiv.org/abs/2512.21326)
*Sida Wang*

Main category: cs.LG

TL;DR: 论文提出了一种分析LLM评估中噪声的方法，定义了三种噪声类型，并开发了all-pairs paired方法来测量这些噪声，发现预测噪声通常超过数据噪声，通过平均可以减少预测噪声并提高统计功效。


<details>
  <summary>Details</summary>
Motivation: 将成熟的统计方法有效应用于LLM评估需要考虑其独特的噪声特性。LLM评估中存在不同类型的噪声，需要明确定义和测量这些噪声，以便更好地进行统计分析和比较。

Method: 提出all-pairs paired方法，将配对分析应用于所有LLM对，基于数百万个问题级预测测量三种噪声：预测噪声（同一问题生成不同答案）、数据噪声（问题抽样）、以及根据全方差定律的总噪声。

Result: 测量揭示了清晰模式：1）每个评估在所有模型对中表现出特征性且高度可预测的总噪声水平；2）配对预测噪声通常超过配对数据噪声，这意味着通过平均减少预测噪声可以显著提高统计功效。

Conclusion: 这些发现使实践者能够无需定制测试即可评估显著性，并在受控实验中检测更小的效应。该方法为LLM评估提供了更有效的统计分析框架。

Abstract: Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [90] [Spinning extremal dyonic black holes in $γ=1$ Einstein-Maxwell-dilaton theory](https://arxiv.org/abs/2512.20698)
*Jose Luis Blázquez-Salcedo,Carlos Herdeiro,Eugen Radu,Etevaldo dos Santos Costa Filho,Kunihito Uzawa*

Main category: gr-qc

TL;DR: 研究四维爱因斯坦-麦克斯韦-伸缩子理论中渐近平坦旋转带电极端黑洞的一般框架，发现在伸缩子耦合常数γ=1时存在无病理的一参数黑洞族，条件是磁荷与电荷相等。


<details>
  <summary>Details</summary>
Motivation: 研究四维爱因斯坦-麦克斯韦-伸缩子理论中的渐近平坦旋转带电极端黑洞，探索无病理黑洞解的存在条件。

Method: 提出一般框架研究这类黑洞，在伸缩子耦合常数γ=1时，通过分析解的近地平线极限，使用微扰闭式解和数值解方法。

Result: 发现当磁荷与电荷相等时，存在一个无病理的一参数极端黑洞族，这一条件通过近地平线极限分析得到理解。

Conclusion: 在特定参数条件下，四维爱因斯坦-麦克斯韦-伸缩子理论中存在物理合理的旋转带电极端黑洞解，磁荷与电荷相等是关键条件。

Abstract: We propose a general framework for the study of asymptotically flat spinning dyonic {\it extremal} black holes (eBHs) in $D=4$ Einstein-Maxwell-dilaton theory. Restricting to the stringy value $γ=1$ of the dilaton coupling constant, we report on the existence of a one parameter family of eBHs which are free of pathologies, provided their magnetic and electric charges are equal. An understanding of this condition is found from a study of the near horizon limit of the solutions, both perturbative closed form and numerical solutions being presented.

</details>


### [91] [Comparing next-generation detector configurations for high-redshift gravitational wave sources with neural posterior estimation](https://arxiv.org/abs/2512.20699)
*Filippo Santoliquido,Jacopo Tissino,Ulyana Dupletsa,Marica Branchesi,Jan Harms*

Main category: gr-qc

TL;DR: 研究首次使用神经后验估计评估下一代引力波探测器网络配置性能，重点关注高质量双黑洞合并系统，发现2个L型ET探测器网络相比三角形配置能减少天空定位多峰性，提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 下一代引力波探测器（如爱因斯坦望远镜和宇宙探索者）的最终设计和配置将在未来十年确定，需要评估不同网络配置的性能，特别是针对高质量、高红移的双黑洞合并系统，这些系统对早期宇宙研究至关重要。

Method: 使用基于归一化流和重要性采样的神经后验估计方法（Dingo-IS），首次评估不同引力波探测器网络配置的性能，重点关注探测器框架啁啾质量大于100太阳质量的双黑洞合并系统。

Result: 验证显示NPE能准确复现复杂且不连续的后验结构。两个L型ET探测器网络相比三角形配置能显著减少天空定位的多峰性（少于预期的8个），提升天空和体积定位精度，加入CE探测器后进一步减少天空位置简并性。

Conclusion: 两个L型ET探测器配置在天空定位方面优于三角形配置，为下一代引力波探测器网络设计提供了重要参考，神经后验估计方法能有效评估复杂网络性能。

Abstract: The coming decade will be crucial for determining the final design and configuration of a global network of next-generation (XG) gravitational-wave (GW) detectors, including the Einstein Telescope (ET) and Cosmic Explorer (CE). In this study and for the first time, we assess the performance of various network configurations using neural posterior estimation (NPE) implemented in Dingo-IS-a method based on normalizing flows and importance sampling that enables fast and accurate inference. We focus on a specific science case involving short-duration, massive and high-redshift binary black hole (BBH) mergers with detector-frame chirp masses $M_{\mathrm{d}} > 100$ M$_\odot$. These systems encompass early-Universe stellar and primordial black holes, as well as intermediate-mass black-hole binaries, for which XG observatories are expected to deliver major discoveries. Validation against standard Bayesian inference demonstrates that NPE robustly reproduces complex and disconnected posterior structures across all network configurations. For a network of two misaligned L-shaped ET detectors (2L MisA), the posterior distributions on luminosity distance can become multimodal and degenerate with the sky position, leading to less precise distance estimates compared to the triangular ET configuration. However, the number of sky-location multimodalities is substantially lower than the eight expected with the triangular ET, resulting in improved sky and volume localization. Adding CE to the network further reduces sky-position degeneracies, and the better performance of the 2L MisA configuration over the triangle remains evident.

</details>


### [92] [Visualization and analysis of the curvature invariants in the Alcubierre warp-drive spacetime](https://arxiv.org/abs/2512.20738)
*José Rodal*

Main category: gr-qc

TL;DR: 分析Alcubierre曲速引擎时空的曲率不变量，包括Weyl张量、Ricci张量的标量不变量，揭示构建曲速泡需要四层各向异性应力-能量张量，并澄清对Alcubierre时空的误解。


<details>
  <summary>Details</summary>
Motivation: 研究Alcubierre曲速引擎时空的曲率不变量，以更准确地理解其几何结构和物理要求，纠正先前研究中曲率不变量被低估8-16个数量级的问题，澄清时空分类误解。

Method: 计算和分析四个标量曲率不变量：Weyl张量的二次收缩标量I、Ricci张量的迹R、迹调整Ricci张量的二次不变量r1和三次不变量r2。利用爱因斯坦曲率张量表达Ricci不变量，绘制详细分布图，与土星质量Schwarzschild黑洞曲率比较。

Result: 发现构建Alcubierre曲速泡需要四层各向异性应力-能量张量；Mattingly等人的研究低估了曲率不变量8-16个数量级；Alcubierre时空曲率与土星质量Schwarzschild黑洞相当；澄清该时空不属于B类扭曲积时空。

Conclusion: Alcubierre曲速引擎时空的曲率分析揭示了其复杂的几何结构和严格的物理要求，纠正了先前研究的数值误差和分类误解，为理解曲速驱动物理提供了更准确的基础。

Abstract: In the Alcubierre warp-drive spacetime, we investigate the following scalar curvature invariants: the scalar $I$, derived from a quadratic contraction of the Weyl tensor, the trace $R$ of the Ricci tensor, and the quadratic $r1$ and cubic $r2$ invariants from the trace-adjusted Ricci tensor. In four-dimensional spacetime the trace-adjusted Einstein and Ricci tensors are identical, and their unadjusted traces are oppositely signed yet equal in absolute value. This allows us to express these Ricci invariants using Einstein's curvature tensor, facilitating a direct interpretation of the energy-momentum tensor. We present detailed plots illustrating the distribution of these invariants. Our findings underscore the requirement for four distinct layers of an anisotropic stress-energy tensor to create the warp bubble. Additionally, we delve into the Kretschmann quadratic invariant decomposition. We provide a critical analysis of the work by Mattingly et al., particularly their underrepresentation of curvature invariants in their plots by 8 to 16 orders of magnitude. A comparison is made between the spacetime curvature of the Alcubierre warp-drive and that of a Schwarzschild black hole with a mass equivalent to the planet Saturn. The paper addresses potential misconceptions about the Alcubierre warp-drive due to inaccuracies in representing spacetime curvature changes and clarifies the classification of the Alcubierre spacetime, emphasizing its distinction from class $B$ warped product spacetimes.

</details>


### [93] [The space spinor formalism and estimates for spinor fields](https://arxiv.org/abs/2512.20768)
*Mariem Magdy,Juan A. Valiente Kroon*

Main category: gr-qc

TL;DR: 该论文展示了如何利用2分量旋量的空间旋量形式来构造满足一阶方程的旋量场的估计，并将此方法与二阶双曲方程的正交换子方法联系起来。


<details>
  <summary>Details</summary>
Motivation: 论文旨在为满足一阶方程的旋量场开发有效的估计构造方法，将二阶双曲方程的正交换子方法推广到一阶方程情形。

Method: 采用空间旋量形式来处理2分量旋量，构建满足一阶方程的旋量场估计，并与现有估计构造策略建立联系。

Result: 成功将空间旋量形式应用于一阶旋量方程的估计构造，建立了与二阶双曲方程正交换子方法的对应关系，并重新表述了与双曲性相关的概念。

Conclusion: 空间旋量形式为构造一阶旋量方程的估计提供了有效框架，这是二阶双曲方程正交换子方法在一阶方程中的适应性推广。

Abstract: We show how the space spinor formalism for 2-component spinors can be used to construct estimates for spinor fields satisfying first order equations. We discuss the connection of the approach presented in this article with other strategies for the construction of estimates. In addition, we recast several concepts related to the notion of hyperbolicity in the context of spinor equations. The approach described in this article can be regarded as an adaptation to first order equations of the method of positive commutators for second order hyperbolic equations.

</details>


### [94] [Asymptotic dynamical analysis of $f(R,T^φ) = R+αT^φ + β(T^φ)^2/2$ cosmology](https://arxiv.org/abs/2512.20774)
*Joaquin Estevez-Delgado,Roberto De Arcia,Gabino Estevez-Delgado,Israel Quiros*

Main category: gr-qc

TL;DR: 研究f(R,T^φ)修正引力模型的渐近宇宙学动力学，其中包含标量场应力能张量迹的线性项和二次项，分析临界点稳定性并发现二次项允许晚期加速膨胀解，但存在退化标量扇区需要超越线性扰动分析。


<details>
  <summary>Details</summary>
Motivation: 尽管f(R,T)引力已被广泛研究，但二次迹耦合在标量场宇宙学中的渐近影响仍未被充分探索。本研究旨在填补这一空白，分析f(R,T^φ)=R+αT^φ+β(T^φ)²/2模型的宇宙学动力学，特别关注二次项对晚期加速膨胀的影响。

Method: 推导平坦、均匀、各向同性宇宙的宇宙学方程，构建无量纲变量的自治系统一阶微分方程。识别和分类所有临界点，分析稳定性性质。研究一般情况(α≠0,β≠0)及子情况(α=0,β=0)，与最小耦合quintessence模型比较。

Result: T^φ的二次项允许背景水平的晚期加速de Sitter类临界解。然而多个加速点位于退化标量扇区(Q_s=0)，标准线性扰动准则无法确定稳定性，而Q_s>0的准de Sitter点是鞍点。需要超越线性分析来建立完整的扰动可行性。

Conclusion: f(R,T^φ)模型中的二次迹耦合项能够产生晚期加速膨胀解，但存在退化标量扇区需要更深入的扰动分析。该研究为理解修正引力模型中物质-几何非最小耦合的渐近行为提供了重要见解。

Abstract: In this work we investigate the asymptotic cosmological dynamics of a modified gravity model based on the $f(R,T^φ)$ theory, where $R$ denotes the Ricci scalar and $T^φ$ is the trace of the stress-energy tensor of a scalar field. Despite the extensive study of $f(R,T)$ gravity, the asymptotic implications of quadratic trace couplings in scalar field cosmology remain largely unexplored. We focus on a specific form given by $ f(R,T^φ) = R + αT^φ+ β(T^φ)^2/2$, in which the parameters $α$ and $β$ control the strength of non-minimal couplings between geometry and matter. We derive the set of cosmological equations for a spatially flat, homogeneous and isotropic universe and construct the autonomous system of first-order differential equations using a compact set of dimensionless variables. This formulation provides a foundation for the qualitative analysis of the asymptotic behavior. We identify and classify all critical points and analyze their stability properties. Finally, the energy conditions and the presence of dynamical instabilities are examined. We study the general scenario $α\neq 0$ and $β\neq 0$, along with the subcases $α= 0$ and $β= 0$, in order to compare with minimally coupled quintessence $α= β= 0$. We find that the quadratic term in $T^φ$ admits late-time accelerated de Sitter-like critical solutions at the background level. However, several accelerated points lie in a degenerate scalar sector with $Q_s=0$, where the standard linear perturbation criteria are inconclusive, while the quasi-de Sitter point with $Q_s>0$ is of saddle type. Therefore, establishing full perturbative viability requires going beyond the linear analysis in the degenerate sector.

</details>


### [95] [Geometric Approach to Light Rings in Axially Symmetric Spacetimes](https://arxiv.org/abs/2512.20802)
*Chenkai Qiao,Ming Li,Donghui Xie,Minyong Guo*

Main category: gr-qc

TL;DR: 本文提出了一种几何方法，将球对称时空中的圆形光子轨道分析扩展到轴对称旋转时空，利用光学几何中的内在曲率来确定赤道面内的光环，并通过Randers-Finsler几何分类光环的稳定性。


<details>
  <summary>Details</summary>
Motivation: 圆形光子轨道在黑洞阴影、引力透镜、准正规模态和时空拓扑性质中扮演重要角色。先前的工作已经为球对称时空提出了几何方法，现在需要将其扩展到更一般的轴对称旋转时空。

Method: 采用几何方法，通过洛伦兹时空光学几何中的内在曲率来确定轴对称时空中的光环。具体来说，利用Randers-Finsler几何描述轴对称时空的光学几何，通过测地曲率为零的条件精确确定光环位置，并通过内在旗曲率分类光环的稳定性。

Result: 该方法适用于任何稳态轴对称时空，无需对时空度规形式施加任何限制。研究提供了严格证明，表明该几何方法与基于光子有效势的传统方法得到完全等价的结果。

Conclusion: 成功将几何方法从球对称时空扩展到轴对称旋转时空，为研究更一般时空中的圆形光子轨道提供了统一的几何框架，具有普适性和理论一致性。

Abstract: Circular photon orbits have become an attractive topic in recent years. They play extremely important roles in black hole shadows, gravitational lensings, quasi-normal modes, and spacetime topological properties. The development of analytical methods for these circular orbits has also drawn extensive attention. In our recent work, \href{https://doi.org/10.1103/PhysRevD.106.L021501}{Phys. Rev. D \textbf{106}, L021501 (2022)}, a geometric approach to circular photon orbits was proposed for spherically symmetric spacetimes. In the present study, we give an extension of this geometric approach from spherically symmetric spacetimes to axially symmetric rotational spacetimes. In such a geometric approach, light rings in the equatorial plane are determined through the intrinsic curvatures in the optical geometry of Lorentz spacetime, which gives rise to a Randers-Finsler geometry for axially symmetric spacetimes. Specifically, light rings can be precisely determined by the condition of vanishing geodesic curvature, and the stability of light rings is classified through the intrinsic flag curvature in Randers-Finsler optical geometry. This geometric approach presented in this work is generally applicable to any stationary and axially symmetric spacetime, without imposing any restriction on the spacetime metric forms. Furthermore, we provide a rigorous demonstration to show that our geometric approach yields completely equivalent results with those derived from the conventional approach (based on the effective potential of photons).

</details>


### [96] [Schwarzschild-de Sitter black hole as a correlated qubit system via entropic identification](https://arxiv.org/abs/2512.20842)
*Ratchaphat Nakarachinda,Lunchakorn Tannukij,Pitayuth Wongjun,Tanapat Deesuwan*

Main category: gr-qc

TL;DR: 将Schwarzschild-de Sitter黑洞建模为两个相互关联的量子比特系统，每个事件视界对应一个量子比特，通过熵识别成功构建了密度矩阵，并发现引力效应下量子比特关联存在比Araki-Lieb三角不等式更严格的约束。


<details>
  <summary>Details</summary>
Motivation: 多视界黑洞（如Schwarzschild-de Sitter黑洞）的热力学行为长期以来是引力物理的谜题，涉及引力系统的量子性质，而量子引力理论尚未完成。本文探索将此类黑洞实现为关联量子比特系统的可能性。

Method: 将Schwarzschild-de Sitter黑洞建模为两个关联的量子比特系统，每个事件视界视为一个量子比特。通过将子系统熵识别为量子比特熵，成功构建了两个子系统的约化密度矩阵以及整个黑洞的密度矩阵。

Result: 成功构建了Schwarzschild-de Sitter黑洞作为2-关联量子比特系统的密度矩阵表示。发现当引力效应在量子比特系统中起作用时（如黑洞情况），量子比特之间的关联受到比Araki-Lieb三角不等式更严格的下界约束。

Conclusion: Schwarzschild-de Sitter黑洞可以被建模为关联量子比特系统，引力效应导致量子比特关联存在更严格的约束条件，这为理解黑洞热力学和量子引力提供了新视角。

Abstract: The thermodynamic behaviours of multi-horizon black holes such as a Schwarzschild-de Sitter black hole have been one of the long-standing mysteries in gravitational physics since they involve quantum natures in gravitational systems and that the search for quantum gravity has not reached its conclusion. In this work, we seeked for a possibility of realising the Schwarzschild-de Sitter black hole as a correlated qubit system, where each of the event horizon is treated as a qubit and both of them are correlated in a way that two qubits could be. By identifying the entropies of subsystems to those of qubits, we successfully constructed the reduced density matrices of the two subsystems as well as the density matrix for the Schwarzschild-de Sitter black hole, modelled as 2-correlating qubits. Moreover, our results suggested that when the gravitational effect has its role in the qubit systems, supposedly like black holes, the correlation between qubits are constrained with a lower bound more stringent than the so-called Araki-Lieb triangle inequality.

</details>


### [97] [Universality and Criticality in Mass-less Scalar Field Collapse](https://arxiv.org/abs/2512.20998)
*Koushiki,Rituparno Goswami,Pankaj S. Joshi*

Main category: gr-qc

TL;DR: 研究无质量标量场的协变坍缩，发现坍缩与弥散模式的强度决定最终形成黑洞还是弥散，临界情况为局部裸奇点，由单一无量纲参数决定


<details>
  <summary>Details</summary>
Motivation: 研究无质量标量场坍缩的最终命运，理解在何种条件下会形成黑洞、弥散或出现裸奇点，探索引力坍缩的基本物理机制

Method: 采用协变方法观测无质量标量场的坍缩过程，分析坍缩模式和弥散模式的相对强度，不依赖特定假设（ansatz-independent）

Result: 发现坍缩与弥散模式的强度决定最终状态：黑洞形成或弥散；临界情况下出现局部裸零奇点；存在单一无量纲参数决定最终命运；几何质量趋于零

Conclusion: 无质量标量场坍缩的最终状态由坍缩与弥散模式的相对强度决定，临界情况产生局部裸奇点，这一结论对所有无质量标量场族都成立

Abstract: In this paper, we observe the collapse of a mass-less scalar field covariantly. We show that the strengths of the collapsing and dispersing modes of this scalar field will decide whether the collapse will end up in a black-hole or disperse. We find a locally naked null singularity as a critical case between these two and confirm that there is a single dimensionless parameter that determine the end state. This work is ansatz-independent, hence, true for all mass-less scalar field families. We also show that the geometrical mass of these singularities go to zero.

</details>


### [98] [Black Hole Evaporation Driven by Non-Thermal Squeezing Through SNS and CSNS Dynamics](https://arxiv.org/abs/2512.21014)
*Dhwani Gangal,K. K. Venkataratnam*

Main category: gr-qc

TL;DR: 该研究对平坦FRW宇宙中黑洞辐射进行了半经典分析，重点考察了两种非经典量子态（压缩数态SNS和相干压缩数态CSNS）对霍金辐射的影响，推导了状态相关的霍金温度、熵变和质量损失表达式。


<details>
  <summary>Details</summary>
Motivation: 先前研究多关注热修正，而SNS和CSNS代表了完全非热、数态依赖的量子构型。研究旨在将早期热压缩态方法扩展到完全数态分辨的框架，揭示非经典量子构型对霍金辐射的敏感性。

Method: 在引力的半经典理论框架内嵌入SNS和CSNS态，推导状态分辨的霍金温度、熵变和质量损失表达式。通过压缩参数ρ和数态参数n分析对霍金辐射的影响，支持以12个详细图表的分析结果。

Result: 霍金温度随ρ和n单调增长，提高了黑洞视界的有效温度。熵变ΔS_SNS和ΔS_CSNS表现出强烈的非线性增强，特别是在中等和大压缩值下。研究揭示了非经典量子构型对霍金辐射的显著影响。

Conclusion: 该研究将热压缩态方法扩展到完全数态分辨框架，为宇宙学背景下的引力粒子产生提供了新视角，强调了霍金辐射对非经典量子构型的敏感性。

Abstract: In this work, we present a comprehensive semiclassical analysis of black hole radiation in a spatially flat FRW Universe for two fundamental nonclassical states: the Squeezed Number State (SNS) and the Coherent Squeezed Number State (CSNS). Unlike thermally modified earlier studies, SNS and CSNS constitute fully non-thermal, number-state-dependent quantum configurations. By embedding these states within the framework of semiclassical theory of gravity, we derive state-resolved expressions for the Hawking temperature, entropy variation, and corresponding mass loss of an evaporating black hole. The influence of the squeezing parameter $ρ$ and number state parameter $n$ on Hawking emission is examined through a series of analytical results supported by twelve detailed plots. The analysis reveals that the Hawking temperature exhibits monotonic growth with increasing $ρ$ and $n$, thereby elevating the effective temperature experienced at the black hole horizon. The entropy variations $Δ\mathbb{S}_{\mathrm{SNS}}$ and $Δ\mathbb{S}_{\mathrm{CSNS}}$ show strong nonlinear enhancement, especially at moderate and large squeezing values. Overall, the study extends earlier thermal squeezed-state approaches to a fully number-state-resolved framework, highlighting the sensitivity of Hawking emission to nonclassical quantum configurations. These findings contribute a new perspective on gravitational particle creation in cosmological settings.

</details>


### [99] [A class of entangled and diffeomorphism-invariant states in loop quantum gravity: Bell-network states](https://arxiv.org/abs/2512.21145)
*Bekir Baytaş*

Main category: gr-qc

TL;DR: 本文分析了LQG中的Bell-network态，这类态具有微分同胚不变性，在大自旋极限下满足面积律纠缠熵，其几何涨落类似于弯曲时空量子场论中的半经典极限。


<details>
  <summary>Details</summary>
Motivation: 在圈量子引力中，需要寻找既能满足微分同胚不变性，又能展现半经典几何性质的量子态。Bell-network态提供了这样的可能性，它们具有面积律纠缠熵，且几何涨落与弯曲时空量子场论中的半经典极限相似。

Method: 对偶极图上的Bell-network态进行有效几何分析，详细表征这类微分同胚不变、满足面积律的量子几何态，这些态代表了圈量子引力中的均匀各向同性构型。

Result: 提供了Bell-network态在偶极图上的全面有效几何分析，详细描述了这类代表均匀各向同性构型的量子几何态，可作为理论动力学的边界态进行探索。

Conclusion: Bell-network态为圈量子引力提供了一类重要的微分同胚不变、满足面积律纠缠熵的量子态，其几何性质与半经典极限相似，可作为理论动力学的边界态，为研究量子引力中的几何纠缠和半经典极限提供了有力工具。

Abstract: Bell-network states constitute a class of diffeomorphism-invariant and entangled states of the geometry within loop quantum gravity (LQG) that satisfy an area-law for the entanglement entropy in the limit of large spins. The fluctuations of the geometry for a Bell-network state are entangled, similar to those in the semiclassical limit as described by quantum field theory in curved spacetimes. We present a comprehensive analysis of the effective geometry of Bell-network states on a dipole graph. This analysis provides a detailed characterization of the quantum geometry of a class of diffeomorphism-invariant, area-law states representing homogeneous and isotropic configurations in loop quantum gravity, which may be explored as boundary states for the dynamics of the theory.

</details>


### [100] [Acoustic gravitational waves from primordial curvature perturbations](https://arxiv.org/abs/2512.21151)
*Zhuan Ning,Zi-Yan Yuwen,Xiang-Xi Zeng,Rong-Gen Cai,Shao-Jiang Wang*

Main category: gr-qc

TL;DR: 开发混合数值框架研究原初曲率扰动诱导的引力波中的非微扰效应，发现声学通道引力波在振幅较大时可比微扰计算增强一个数量级且峰值频率降低。


<details>
  <summary>Details</summary>
Motivation: 标准的微扰计算在标量诱导引力波中忽略了大振幅区域内的非微扰效应，需要开发新方法来准确预测原初曲率扰动诱导的随机引力波背景。

Method: 开发混合数值框架：首先使用完全广义相对论球对称模拟提取孤立曲率峰的非微扰声壳剖面，然后将这些剖面嵌入三维晶格演化中，结合相对论流体力学和横向无迹度规扰动来计算声学引力波谱。

Result: 声学信号峰值频率由共动壳厚度决定，振幅对峰的平均共动分离极其敏感（近似∝R_{*c}^{-7}）。发现稳健的因果低频尾∝k^3，非线性流体力学相互作用可增强紫外功率。与相同实空间配置的微扰计算相比，声学引力波在大振幅区域可放大一个数量级且峰值频率降低。

Conclusion: 非微扰效应对准确预测原初曲率扰动诱导的随机引力波信号至关重要，大振幅区域中的声学引力波可比标准微扰计算显著增强且频率特性不同。

Abstract: Standard perturbative calculations of scalar-induced gravitational waves (SIGWs) have neglected nonperturbative effects in the large-amplitude regime. We develop a hybrid numerical framework to signify nonperturbative effects on the stochastic gravitational wave (GW) background sourced by primordial curvature perturbations, focusing on the acoustic channel (fluid motions). Fully general-relativistic, spherically symmetric simulations are used to extract nonperturbative sound-shell profiles from isolated curvature peaks; these profiles are then embedded into three-dimensional lattice evolutions of relativistic hydrodynamics coupled to transverse-traceless metric perturbations to compute the acoustic GW spectra. The acoustic signal has a peak frequency determined by the comoving shell thickness, and its amplitude is extremely sensitive to the mean comoving separation of peaks, scaling approximately as $R_{*c}^{-7}$. We find a robust causal low-frequency tail $\propto k^{3}$, and the nonlinear hydrodynamic interactions can enhance the ultraviolet power. Comparing with SIGWs computed perturbatively from the same real-space configuration, we show that acoustic GWs can be amplified by an order of magnitude and display a peak shifted to a lower frequency in the large-amplitude regime. These results highlight the importance of nonperturbative effects for accurate predictions of stochastic GW signals induced from primordial curvature perturbations.

</details>


### [101] [(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation](https://arxiv.org/abs/2512.21167)
*Andrea Addazi,Yermek Aldabergenov,Daulet Berkimbayev,Yifu Cai*

Main category: gr-qc

TL;DR: 该论文通过引入高斯-博内项对Starobinsky暴胀模型进行一参数推广，解决了与ACT数据中稍大标量谱指数的轻微张力，同时保持了原模型的成功之处。


<details>
  <summary>Details</summary>
Motivation: ACT数据显示标量谱指数ns略大于标准R²暴胀模型的预测值，存在轻微张力。需要扩展Starobinsky模型以更好地符合现代精密宇宙学数据。

Method: 提出L+L²重力模型，其中L=R+α/4𝒢（𝒢为高斯-博内项）。通过标量-张量表述得到爱因斯坦框架下的Starobinsky型标量势，包含高斯-博内项和导数耦合，修改了暴胀慢滚动力学。

Result: 非零的高斯-博内耦合参数α可以沿着特定轨迹移动(ns, r)预测值，使其更好地符合ACT似然函数。该模型属于Horndeski/galileon类修正重力理论，且等价于耦合高斯-博内项的希格斯暴胀。

Conclusion: 二次f(L)重力是Starobinsky暴胀模型的物理动机扩展，既保留了原模型的成功，又改善了与现代精密宇宙学数据的拟合度，是一个有吸引力的理论框架。

Abstract: We revisit the Starobinsky model of inflation in light of recent data from the Atacama Cosmology Telescope (ACT), which indicates a potential preference for a slightly larger scalar spectral index $n_s$ than predicted by the standard $R^2$ scenario. We demonstrate that a natural one-parameter generalization to a quadratic model $\sim L+L^2$ in the Lovelock invariant $L=R+\fracα{4}{\cal G}$ ($\cal G$ is the Gauss--Bonnet term), can effectively resolve this minor tension. Scalar-tensor formulation of this theory yields an Einstein-frame Starobinsky-type scalar potential augmented by Gauss--Bonnet and derivative couplings, which modify the inflationary slow-roll dynamics. We show that a non-zero coupling $α$ for the Gauss-Bonnet term can shift $(n_s, r)$ along a trajectory that brings the predictions into better agreement with the ACT likelihood. We also find that $L+L^2$ gravity, in its scalar-tensor formulation, is equivalent to Higgs inflation coupled to the Gauss--Bonnet term, and belongs to the Horndeski/galileon class of modified gravities. This work establishes the quadratic $f(L)$ gravity as a compelling and physically motivated extension that preserves the successes of Starobinsky inflation while improving its fit to modern precision cosmological data.

</details>


### [102] [Linking interior curvature to observable shadows: A case study of nonsingular black holes](https://arxiv.org/abs/2512.21178)
*Ming-Xin Li,Jin Pu,Yi Ling,Guo-Ping Li*

Main category: gr-qc

TL;DR: 该研究建立了非奇异黑洞内部曲率结构与可观测光学特征之间的直接联系，通过曲率分类揭示了黑洞阴影形态如何反映内部几何差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索量子引力启发的非奇异黑洞模型如何通过可观测特征（如黑洞阴影）来检验。传统黑洞存在奇点问题，而具有Minkowski核心的非奇异黑洞提供了替代方案，但需要建立其内部几何与可观测特征之间的明确联系。

Method: 方法包括：1）将非奇异黑洞时空按曲率结构分为三类（Type I、II、III）；2）详细分析光子动力学，研究参数α和n如何影响光子球性质；3）在静态和下落球对称吸积模型下计算黑洞阴影；4）通过曲率分类与阴影特征的对应关系建立联系。

Result: 研究发现：1）Type III黑洞具有最紧凑的光子球，产生最小最亮的阴影；2）Type I黑洞产生最大最暗的阴影；3）Type III黑洞对参数变化最敏感，是约束基础时空几何的最佳探针；4）即使具有相同渐近核心，内部曲率差异也会反映在阴影形态中。

Conclusion: 该工作揭示了非奇异黑洞内部曲率结构与可观测阴影特征之间的直接对应关系，为利用高分辨率观测测试量子引力模型提供了新途径。曲率分类可直接转化为可观测差异，Type III黑洞特别适合用于约束基础时空几何。

Abstract: We establish a direct connection between the interior curvature structure of nonsingular black holes (BHs) with a Minkowski core and their observable optical signatures. By classifying these spacetimes into three fundamental types, Type I (Kretschmann scalar K_max increasing with mass M), Type II (mass-independent K_max), and Type III (K_max decreasing with M), we demonstrate how subtle variations in the core geometry imprint distinguishable features on the BH shadow. A detailed analysis of photon dynamics reveals that the parameters α and n, which control the deviation from Schwarzschild geometry and the radial decay of the regularizing factor, respectively, systematically alter the properties of the photon sphere. These intrinsic geometric differences propagate outward: for fixed parameters, Type III BHs, with the most compact photon sphere, produce the smallest and brightest shadows, whereas Type I BHs yield the largest and dimmest ones. Shadow computations under both static and infalling spherical accretion models confirm that the curvature-based classification directly corresponds to observable differences. Critically, Type III BHs exhibit the strongest sensitivity to parameter variations, making them optimal probes for constraining the underlying spacetime geometry. Our work reveals that even among nonsingular BHs sharing the same asymptotic core, differences in internal curvature are reflected in the shadow morphology, thereby providing a new pathway to test quantum-gravity-inspired models using upcoming high-resolution observations.

</details>


### [103] [Preliminary forecasting constraint on scalar charge with LISA in non-vacuum environments](https://arxiv.org/abs/2512.21186)
*Tieguang Zi,Chang-Qing Ye*

Main category: gr-qc

TL;DR: 研究计算了在非真空环境中（包含吸积盘和暗物质晕）的偏心极端质量比旋近（EMRIs）引力波信号，其中次级天体带有标量电荷，并分析了标量电荷对波形的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在非真空天体物理环境中（吸积盘和暗物质晕）带有标量电荷的EMRIs系统，探索标量电荷对引力波信号的影响，为未来空间引力波探测器（如LISA）探测标量电荷提供理论预测。

Method: 通过将标量电荷纳入通量和轨道轨迹修正，计算了在吸积盘和暗物质晕环境中偏心EMRIs的引力波信号，推导了波形修正。

Result: 在合适的参数配置下，标量电荷对非真空环境中EMRIs波形的影响可与真空时空中的影响区分开；LISA探测器可将标量电荷的相对误差约束在~0.1水平。

Conclusion: 该研究为在非真空时空中探测标量电荷提供了初步预测，表明未来空间引力波探测器有能力区分标量电荷在真空和非真空环境中的不同效应。

Abstract: We compute the gravitational wave signal from eccentric extreme-mass-ratio inspirals (EMRIs) embedded within beyond-vacuum environments, where the secondary object carries a scalar charge and evolves in the presence of both an accretion disk and a dark matter halo. The waveform modification is derived by incorporating the scalar charge correcting the fluxes and orbital trajectories of the secondary. Our results indicate that, under suitable parameter configurations, the influence of the scalar charge on EMRIs waveform in such environments can be distinguished from that in vacuum spacetime. For the EMRIs signal modified by the astrophysical environments, the future space-borne detector can determine the relative error of scalar charge constrained by LISA at the level of $\sim0.1$, providing a preliminary prediction of detecting scalar charge in the beyond-vacuum spacetime.

</details>


### [104] [Asymptotically Euclidean Solutions of the Constraint Equations with Prescribed Asymptotics](https://arxiv.org/abs/2512.21274)
*Lydia Bieri,David Garfinkle,James Isenberg,David Maxwell,James Wheeler*

Main category: gr-qc

TL;DR: 该论文提出了一种在广义相对论中构造渐近平坦真空初始数据集的新方法，可以预先指定ADM动量分量、衰减率和质量项各向异性等渐近结构，并构建了一个不满足未来与过去零无穷反演对称性猜想的数值示例。


<details>
  <summary>Details</summary>
Motivation: 在广义相对论中构造具有特定渐近结构的初始数据集是一个重要问题。先前的工作在渐近结构控制方面存在限制，特别是关于未来与过去零无穷之间的反演对称性猜想需要更精确的初始数据集来验证。

Method: 使用共形方法构造渐近平坦真空初始数据集，通过指定种子数据预先控制ADM动量分量、衰减率（主导阶和次主导阶）以及质量项的各向异性等渐近结构。

Result: 成功构造了一个比先前工作具有更强渐近性的初始数据集数值示例，该数据集的演化不满足未来与过去零无穷之间的反演对称性猜想。

Conclusion: 该方法提供了一种系统构造具有特定渐近结构初始数据集的配方，并通过数值示例挑战了关于时空渐近结构的反演对称性猜想。

Abstract: We demonstrate that in constructing asymptotically flat vacuum initial data sets in General Relativity via the conformal method, certain asymptotic structures may be prescribed a priori through the specified seed data, including the ADM momentum components, the leading- and next-to-leading-order decay rates, and the anisotropy in the metric's mass term, yielding a recipe to construct initial data sets with desired asymptotics. We numerically construct a simple explicit example of an initial data set, with stronger asymptotics than have been obtained in previous work, such that the evolution of this initial data set does not exhibit the conjectured antipodal symmetry between future and past null infinity.

</details>


### [105] [When Geometry Radiates Review: Gravitational Waves in Theory, Cosmology, and Observation](https://arxiv.org/abs/2512.21328)
*Azadeh Maleknejad*

Main category: gr-qc

TL;DR: 该论文是一篇关于引力波的综述，系统性地介绍了引力波理论、观测方法和天体物理/宇宙学应用，涵盖了从基础理论到前沿观测的完整框架。


<details>
  <summary>Details</summary>
Motivation: 引力波为研究引力、宇宙学和高能物理提供了独特窗口，能够探索广泛尺度上的基本物理现象。论文旨在建立一个连贯的教学框架，连接基础理论与观测前沿。

Method: 1. 在线性化广义相对论中发展引力辐射理论；2. 从几何角度深入讨论引力辐射与Weyl张量代数结构的关系；3. 扩展到膨胀宇宙背景下的引力波演化；4. 讨论绝热模式和一致性关系；5. 推导暴胀产生的真空引力波谱；6. 综述多频段观测策略；7. 分析产生引力辐射的天体物理和宇宙学机制。

Result: 论文建立了完整的引力波理论框架，涵盖了从基础数学推导到实际观测应用的各个方面，包括引力波的物理解释、极化状态、关键性质、宇宙学演化、观测方法以及产生机制。

Conclusion: 论文总结了引力波领域的当前状态，并展望了未来理论和观测发展的有前景方向，强调引力波作为探索基础物理现象的重要工具的价值。

Abstract: Gravitational waves provide a unique window into gravity, cosmology, and high-energy physics, enabling the exploration of fundamental phenomena across a wide range of scales. This review presents a coherent and pedagogical framework that bridges foundational theory with observational frontiers. We begin by developing the theory of gravitational radiation within linearized general relativity, deriving gravitational waves as solutions to the linearized Einstein equations and clarifying their physical interpretation, polarization states, and key properties. We then deepen the discussion through a geometric perspective, tracing the connection between gravitational radiation and the algebraic structure of the Weyl tensor and its role in defining energy and angular momentum in asymptotically flat spacetimes. Extending beyond flat backgrounds, we examine gravitational waves in an expanding universe, following their evolution across cosmological epochs and their generation during inflation. Within this setting, we discuss adiabatic modes and consistency relations that reveal universal properties of long-wavelength perturbations, and derive the inflationary spectrum of vacuum gravitational waves together with their contribution to the integrated Sachs-Wolfe effect. We also survey the main observational strategies for detecting gravitational waves across a broad frequency range, including cosmic microwave background polarization, pulsar timing arrays, ground- and space-based laser interferometers, and resonant cavity detectors. We then discuss the astrophysical and cosmological mechanisms responsible for generating gravitational radiation. We conclude by summarizing the current status of the field and outlining promising directions for future theoretical and observational developments.

</details>
