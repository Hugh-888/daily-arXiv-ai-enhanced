<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [gr-qc](#gr-qc) [Total: 10]
- [quant-ph](#quant-ph) [Total: 34]
- [cs.LG](#cs.LG) [Total: 73]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Differentiable quantum-trajectory simulation of Lindblad dynamics for QGP transport-coefficient inference](https://arxiv.org/abs/2601.14399)
*Lukas Heinrich,Tom Magorsch*

Main category: physics.comp-ph

TL;DR: 提出一种基于梯度优化的方法，用于估计夸克-胶子等离子体的输运系数，通过微分开放量子系统蒙特卡洛模拟实现


<details>
  <summary>Details</summary>
Motivation: 传统方法中，通过求解大希尔伯特空间中的Lindblad方程来估计夸克-胶子等离子体的输运系数计算成本高昂，需要更高效的参数估计方法

Method: 使用基于梯度的优化方法，应用得分函数梯度估计器对蒙特卡洛波函数算法中的离散跳跃采样进行微分，实现低方差随机梯度估计

Result: 开发出的随机梯度估计器方差足够低，可并行计算，并在现有开源代码QTraj中实现，成功通过梯度优化推断出输运系数$\hatκ$和$\hatγ$

Conclusion: 该方法为夸克-胶子等离子体输运系数的参数估计提供了一种计算高效、可扩展的解决方案，显著降低了计算成本

Abstract: We study parameter estimation for the transport coefficients of the quark-gluon plasma by differentiating open-quantum-system-based Monte Carlo simulations of quarkonium suppression. The underlying simulator requires solving a Lindblad equation in a large Hilbert space, which makes parameter estimation computationally expensive. We approach the problem using gradient-based optimization. Specifically, we apply the score-function gradient estimator to differentiate through discrete jump sampling in the Monte Carlo wave-function algorithm used to solve the Lindblad equation. The resulting stochastic gradient estimator exhibits sufficiently low variance and can still be estimated in an embarrassingly parallel manner, enabling efficient scaling of the simulations. We implement this gradient estimator in the existing open-source quarkonium suppression code QTraj. To demonstrate its utility for parameter estimation, we infer the two transport coefficients $\hatκ$ and $\hatγ$ using gradient-based optimization on synthetic nuclear modification factor data.

</details>


### [2] [FEcMD: A multi-physics and multi-scale computational program for dynamic coupling molecular dynamics simulations with transient electric field and heat conduction in metal nanostructures](https://arxiv.org/abs/2601.14712)
*Bing Xiao,Nan Li,Wenqian Kong,Rui Chu,Hongyu Zhang,Guodong Meng,Kai Wu,Yonghong Cheng*

Main category: physics.comp-ph

TL;DR: FEcMD是一个结合分子动力学与多尺度电动力学、热传导的软件包，用于研究金属纳米结构的原子演化、相变及场发射特性


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时研究金属纳米结构在电场和热场作用下的原子结构演化、相变、再结晶以及电子发射特性的多物理场多尺度计算工具

Method: 将分子动力学与多尺度电动力学和热传导耦合，在电动力学中引入空间电荷相互作用，使用自洽求解的Poisson-Schrödinger方程和WKBJ近似计算场发射电流密度；实现双温度热传导模型描述电子-声子双通道热传导机制

Result: 开发了FEcMD软件包，能够更可靠地评估纳米线或纳米突起（特别是金属电极间纳米间隙）的场发射电流密度和相关电阻加热过程，并提供了对电子和声子系统温度演化的专门描述

Conclusion: FEcMD软件包通过基准测试验证了其数值结果的可靠性，并展示了其在研究金属纳米结构在电场和加热过程中的原子结构演化方面的应用潜力

Abstract: Field emission coupled with molecular dynamics simulation (FEcMD) software package is a computational tool for studying atomic structure evolution, structural deformation, phase transitions, recrystallization as well as electron emission characteristics of micro- and nano-protrusions and nanowires consisting of elemental metals or multi-component alloys by means of multi-physics and multi-scale methodology. Current implementations of molecular dynamics simulation coupled with multi-scale electrodynamics (ED) and heat conduction (HC) in FEcMD program are advanced mainly in the two aspects as follows. In electrodynamics, the FEcMD program incorporates the space charge interactions (space charge potential and exchange-correlation effects) in the self-consistent solved Poisson-Schrödinger equation with Wentzel-Kramers-Brillouin-Jeffreys (WKBJ) approximation to evaluate the field emission current density and the related resistive heating process more reliably for nanowires or nano-protrusions especially for nano-gaps between two metal electrodes. Meanwhile, the two-temperature heat conduction model is implemented in electrodynamics coupled with molecular dynamics simulations (ED-MD), providing more dedicated descriptions for the hierarchical electron-phonon two-channel heat conduction mechanism and the temperature evolutions of electron and phonon subsystems under the radiofrequency (RF) or pulse electric fields. Benchmark tests are performed for some key implementations in FEcMD software to validate the numerical results, and also to demonstrate the use of program to study the atomic structure evolution of metal nano-structures under electric field and heating processes.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [3] [Gauge gravitation theory in Riemann-Cartan space-time and the nonsingular Universe](https://arxiv.org/abs/2601.14293)
*A. V. Minkevich*

Main category: gr-qc

TL;DR: 该论文研究黎曼-嘉当时空中的规范引力理论，旨在解决广义相对论的基本问题，给出了描述无奇点加速宇宙的各向同性宇宙学解的参数约束条件。


<details>
  <summary>Details</summary>
Motivation: 为了解决广义相对论的基本问题，特别是宇宙奇点和加速膨胀问题，作者在黎曼-嘉当时空中研究规范引力理论，期望获得更完善的宇宙学描述。

Method: 在黎曼-嘉当时空中构建规范引力理论，对各向同性宇宙学解施加参数约束，数值求解宇宙学方程，分析在极限能量密度附近从引力压缩到膨胀的转变过程。

Result: 获得了描述无奇点加速宇宙的参数约束条件，得到了平坦、闭合和开放模型中从压缩到膨胀转变的数值解，并讨论了该理论在天体物理学中的物理后果。

Conclusion: 黎曼-嘉当时空中的规范引力理论能够解决广义相对论的奇点问题，描述无奇点的加速膨胀宇宙，为宇宙学提供更完整的理论框架。

Abstract: The gauge gravitation theory in the Riemann-Cartan space-time is investigated in order to solve the fundamental problems of the general relativity theory. The constraints for indefinite parameters of the theory under which solutions of isotropic cosmology describe a nonsingular accelerating Universe are given. Numerical solutions of cosmological equations near the limiting energy density by transition from gravitational compression to expansion in dependence on energy density in the case of flat, closed and open models are obtained. Some physical consequences of gauge gravitational theory in the Riemann-Cartan space-time in astrophysics are discussed.

</details>


### [4] [Scalar Quasi-Normal Modes in Black Hole Gravitational Lensing](https://arxiv.org/abs/2601.14303)
*Chengjiang Yin,Zihao Lin,Jian-hua He*

Main category: gr-qc

TL;DR: 研究史瓦西黑洞引力透镜中准正规模的激发，发现入射波能非共振激发大量高l模，透镜波形成高度定向的高斯光束，振幅在近场区几乎不变，且振荡模式相互抵消。


<details>
  <summary>Details</summary>
Motivation: 研究史瓦西黑洞引力透镜中准正规模的激发机制，探索入射波与黑洞时空的复杂相互作用，特别是高角动量模的激发特性。

Method: 采用标量场模型，使用时域模和方法分析入射脉冲信号与黑洞时空的相互作用，并通过准正规模模板拟合验证激发模式。

Result: 发现入射波能非共振激发大量高l模（高达l=20），透镜波形成高度定向的相干高斯光束，其横截面强度呈高斯分布，振幅在近场区几乎不变，且多模叠加导致振荡模式相互抵消。

Conclusion: 史瓦西黑洞引力透镜能有效激发高角动量准正规模，形成定向高斯光束，这一发现对理解黑洞引力透镜现象和引力波探测具有重要意义。

Abstract: We investigate the excitation of quasi-normal modes (QNMs) in gravitational lensing by a Schwarzschild black hole using a scalar field model. By employing a time-domain mode-sum method, we analyze the complex interplay between an incident burst signal and the black hole spacetime. We find that the incident waves can non-resonantly excite a substantial number of high-$l$ modes, with amplitudes for modes as high as l=20 remaining significant compared to the fundamental l=0 mode. We confirm through QNM template fitting that the late-time behaviors of these excited modes are indeed QNMs. After passing through the black hole, we find that the lensed waves form a highly directional and coherent Gaussian beam whose cross-sectional intensity profile is well-described by a Gaussian profile. Unlike spherical waves, this beam's amplitude does not decrease with distance from the black hole but remains nearly constant in the near-field region. Moreover, due to the superposition of numerous QNMs, oscillations largely cancel each other out. The lensed temporal waves do not exhibit typical oscillatory patterns.

</details>


### [5] [From MOND entropy to extended uncertainty principles: A unified framework](https://arxiv.org/abs/2601.14353)
*Özgür Sevinç,Özgür Ökcü,Ekrem Aydiner*

Main category: gr-qc

TL;DR: 该研究探索广义熵与扩展不确定性原理(EUP)模型之间的关系，从高阶扩展不确定性原理(HOEUP)出发得到修正的熵-面积关系，推导修正的弗里德曼方程，并建立MOND熵与EUP的统一框架。


<details>
  <summary>Details</summary>
Motivation: 探索广义熵与扩展不确定性原理之间的深层联系，建立统一的框架来桥接广义熵、截断机制和EUP模型，特别是为那些没有显式截断机制的熵形式寻找有效的截断机制。

Method: 1. 从HOEUP推导修正的熵-面积关系；2. 通过三种方法推导修正的弗里德曼方程：表观视界的热力学第一定律、熵引力情形、宇宙空间涌现；3. 检验广义第二定律(GSL)的有效性；4. 提出从MOND熵反向构造统一EUP的逆向方法。

Result: 1. HOEUP修正的弗里德曼方程是最近提出的MOND熵推导结果的极限情况；2. 从MOND熵反向推导出新的MOND EUP；3. 该MOND EUP在极限情况下可还原为与Rényi熵和双Kaniadakis熵相关的EUP关系；4. HOEUP对应MOND熵的微扰极限。

Conclusion: 论文的主要新成果是从MOND熵出发通过逆向方法构造统一的EUP，该方法可推广到其他广义熵形式，建立了连接广义熵、截断机制和EUP模型的统一框架，为没有显式截断机制的熵形式提供了可能的截断机制。

Abstract: In this study, we explore the relation between generalised entropies and the extended uncertainty principle (EUP) models. Starting from the higher-order extended uncertainty principle (HOEUP), we obtain the modified entropy-area relation. Then, we derive the modified Friedmann equations through three different approaches: the first law of thermodynamics at the apparent horizon, the entropic gravity case, and the emergence of cosmic space. Furthermore, we check the validity of the generalised second law (GSL). Notably, HOEUP modified Friedmann equations are the limiting cases of those obtained from a recently proposed novel entropy, which is derived from Modified Newtonian Dynamics (MOND) [{\it Phys. Dark Universe} {\bf 49} (2025) 101967]. Motivated by this connection, we derive a novel EUP, referred to as MOND EUP, from a reverse procedure. This novel EUP reproduces to EUP relations associated with Rényi and dual Kaniadakis entropies in the limiting cases. Moreover, we show that HOEUP corresponds to perturbative limit of MOND entropy. The main new result of this paper is a reverse procedure beginning from a recently proposed novel MOND entropy to construct a unified EUP. This reverse procedure is not limited with the present case. In principle, the method can be applied to other generalised entropy formalisms, suggesting that our findings may establish a unified framework that bridges the generalised entropies, cutoff mechanisms, and EUP models. In particular, the corresponding modified uncertainty principles may have effective cutoff mechanisms for the entropy forms, which do not explicitly display cutoff mechanisms. Thus, these entropies may have cutoff mechanism due to their corresponding modified uncertainty principles.

</details>


### [6] [Analytic discrete self-similar solutions of Einstein-Klein-Gordon at large D](https://arxiv.org/abs/2601.14358)
*Christian Ecker,Florian Ecker,Daniel Grumiller*

Main category: gr-qc

TL;DR: 在爱因斯坦-无质量克莱因-戈登系统中，首次以封闭解析形式构造了无限族离散自相似解，使用大D展开方法，并与有限D数值临界解进行比较。


<details>
  <summary>Details</summary>
Motivation: 自Choptuik开创性工作以来，临界引力坍缩中的离散自相似解一直只能通过数值方法获得。本文旨在寻找这些解的解析形式，以更好地理解其结构和特性。

Method: 使用大维数（large-D）展开方法，在爱因斯坦-无质量克莱因-戈登系统中构造离散自相似解，并以封闭解析形式表示。

Result: 成功构造了无限族离散自相似解的封闭解析形式，表征了其结构，并与有限维数的数值临界解进行比较，识别了普适性特征和大维数特有行为。

Conclusion: 首次提供了临界引力坍缩中离散自相似解的解析构造，为大维数展开方法在引力物理中的应用提供了新范例，并揭示了数值解与解析解之间的关系。

Abstract: Discretely self-similar solutions govern critical gravitational collapse and have been known only numerically since Choptuik's pioneering work. We construct, in closed analytic form, an infinite family of such solutions of the Einstein-massless-Klein-Gordon system using the large-D expansion. We characterize their structure and compare them with numerical critical solutions at finite D, identifying both universal features and distinctly large-D behavior.

</details>


### [7] [Higher Harmonics of Double White Dwarfs in the Centihertz Band: Linking LISA and DECIGO](https://arxiv.org/abs/2601.14578)
*Naoki Seto*

Main category: gr-qc

TL;DR: 研究银河系双白矮星在厘赫兹波段（~0.01 Hz）的后牛顿高阶谐波可探测性，发现LISA只能探测四极矩模式而无法探测高阶谐波，但未来的分赫兹探测器（DECIGO/BBO）能探测约10%双星系统的三阶谐波，为质量比提供统计约束。


<details>
  <summary>Details</summary>
Motivation: 探索空间引力波天文学中不同频段观测器的互补作用，特别是研究后牛顿高阶谐波在银河系双白矮星系统中的可探测性，以建立连贯的空间引力波观测策略。

Method: 使用合成种群模拟银河系双白矮星系统，分析LISA和计划中的分赫兹观测器（DECIGO、BBO）对不同谐波模式的探测能力，重点关注四极矩模式和高阶谐波的可探测性对比。

Result: LISA只能探测四极矩模式，高阶谐波除极少数邻近系统外基本不可探测；而DECIGO和BBO等分赫兹观测器能探测约10%频率高于5 mHz的旋近双星系统的三阶谐波，从而为质量比提供统计约束。

Conclusion: LISA和未来的分赫兹任务在空间引力波天文学中扮演连续互补的角色：LISA主要探测四极矩模式，而分赫兹观测器能探测高阶谐波，共同建立完整的观测策略。

Abstract: We investigate the detectability of post-Newtonian higher harmonics from Galactic double white dwarfs in the centihertz band ($\sim 0.01$ Hz). Using a synthetic population, we show that, unlike the quadrupole mode, higher harmonics remain undetectable with LISA except for rare nearby systems. In contrast, planned mid-band (decihertz) observatories such as DECIGO and BBO will be able to detect the third harmonic for about 10\% of inspiral binaries above $\sim 5$ mHz, enabling statistical constraints on mass ratios. These results highlight the successive roles of LISA and future decihertz missions in establishing a coherent strategy for space-based gravitational-wave astronomy.

</details>


### [8] [The role of angular momentum in general relativity: heuristic and covariant interpretations](https://arxiv.org/abs/2601.14664)
*Erick Pasten,Claudia Alvarez,Norman Cruz*

Main category: gr-qc

TL;DR: 该论文研究了广义相对论中角动量对引力坍缩的影响，通过比较施瓦西和克尔黑洞时空中测试粒子的自由落体动力学，揭示了黑洞旋转如何通过改变切变来增强或减弱引力聚焦效应。


<details>
  <summary>Details</summary>
Motivation: 研究动机是澄清当牛顿直觉外推到相对论领域时出现的概念模糊性，特别是角动量在广义相对论中的作用。作者希望理解黑洞旋转如何影响引力坍缩过程，以及角动量如何改变自由落体动力学。

Method: 采用两种方法：1）有效势启发式方法分析施瓦西和克尔时空中测试粒子的自由落体动力学，分离特定能量E、特定角动量L和黑洞自旋a的作用；2）协变1+3描述分析类时测地线汇的膨胀、切变和Raychaudhuri演化。

Result: 研究发现：1）克尔时空在某些参数区域导致比施瓦西情况更强或更弱的局部径向下落；2）黑洞旋转系统地改变了无旋下落流的切变，即使局部膨胀幅度减小；3）切变调制控制着整体聚焦速率。

Conclusion: 黑洞旋转通过修改切变来增强或减弱引力坍缩，这为角动量在相对论引力坍缩中的作用提供了统一的能量和几何解释，补充了先前关于相对论下落的研究。

Abstract: We examine the role of angular momentum in general relativity from both heuristic and fully covariant perspectives, with the aim of clarifying conceptual ambiguities that arise when Newtonian intuition is extrapolated into the relativistic regime. Focusing on free--fall dynamics in the Schwarzschild and Kerr spacetimes in the test--particle limit, we employ an effective--potential heuristic approach to isolate the roles of the specific energy $E$, specific angular momentum $L$, and black--hole spin $a$. Within this framework, we identify well--defined regions of parameter space in which the Kerr spacetime leads to stronger or weaker local radial infall than the Schwarzschild case at the same radius. By analysing the kinematics of infalling geodesic congruences, we show how these local regimes combine along complete trajectories to either enhance or reduce gravitational focusing. We then interpret these results within a covariant 1+3 description of general relativity, in terms of the expansion, shear and Raychaudhuri evolution of timelike congruences. We demonstrate that black--hole rotation systematically modifies the shear of infalling irrotational flows, even when the magnitude of the local expansion is reduced, and that this shear modulation governs the overall rate of focusing. Our work complements previous studies of relativistic infall by providing a unified energetic and geometric interpretation of how angular momentum and rotation can strengthen or weaken gravitational collapse relative to the non--rotating case.

</details>


### [9] [Polarized Radiative Transfer of Kerr-Newman Black Hole](https://arxiv.org/abs/2601.14785)
*Xin Li,Guo Sen,Pei Wang,En-Wei Liang,Xiao-Xiong Zeng,Kai Lin*

Main category: gr-qc

TL;DR: 该研究通过构建ODE数值框架，分析了Kerr-Newman黑洞的偏振辐射成像，特别关注电荷对光子传播和偏振特性的影响，发现电荷会显著改变偏振模式。


<details>
  <summary>Details</summary>
Motivation: 传统Walker-Penrose方法依赖于特定的对称结构和Killing张量，限制了其在一般时空背景下的应用。需要开发一种不依赖特定对称性的方法，来研究黑洞电荷对光子传播和偏振特性的影响。

Method: 扩展传统Walker-Penrose方法，构建ODE数值框架，将光子轨道方程与偏振平行输运方程相结合，实现光子轨迹和偏振态在任意时空背景下的自洽演化。

Result: 黑洞电荷能显著改变光子轨迹和偏振模式：增加电荷会压缩和扭曲光子环尺度上的EVPA结构，引起局部旋转和不对称性，这可能为非零黑洞电荷提供潜在诊断依据。

Conclusion: 构建的ODE数值框架克服了传统方法的对称性限制，成功揭示了黑洞电荷对偏振辐射成像的重要影响，为探测黑洞电荷提供了新的可能性。

Abstract: In this analysis, we investigate the polarization radiation imaging of Kerr-Newman black holes, with a particular focus on the impact of black hole charge on photon propagation and polarization characteristics. By extending the traditional Walker-Penrose method, which is limited by its reliance on specific symmetric structures and Killing tensors, we overcome these limitations by constructing an ordinary differential equations (ODEs) numerical framework that combines the photon orbit equation with the polarization parallel transport equation. This allows for the self-consistent evolution of photon trajectories and polarization states in any spacetime backgrounds without relying on specific symmetries. Using this framework, we analyze the effects of black hole spin and charge on the polarization characteristics of radiation from both prograde and retrograde accretion disks. Our results show that black hole charge can significantly modify photon trajectories and polarization patterns: increasing charge compresses and distorts the EVPA structure on photon-ring scales, inducing localized rotations and asymmetries that may provide a potential diagnostic of a nonzero black hole charge.

</details>


### [10] [The relativistic restricted three-body problem: geometry and motion around tidally perturbed black holes](https://arxiv.org/abs/2601.14979)
*Takuya Katagiri,Vitor Cardoso*

Main category: gr-qc

TL;DR: 研究潮汐形变旋转黑洞附近的类时测地线几何，揭示受限三体问题在演化双星系统中的结构变化，发现随着潮汐场增强，束缚轨道经历四个阶段的演化，对引力波探测和吸积黑洞X射线光变曲线有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究潮汐形变黑洞附近的轨道动力学，为理解吸积盘动力学、极端质量比旋进等天体物理过程提供理论基础，探索潮汐场对黑洞周围物质流动和引力波信号的影响。

Method: 采用局部几何框架分析潮汐形变旋转黑洞附近的类时测地线，研究受限三体问题在绝热演化双星系统中的结构变化，通过半解析方法估计各阶段转变的临界潮汐振幅。

Result: 发现束缚轨道随潮汐场增强经历四个阶段：弱混沌出现、部分轨道坠入黑洞、部分轨道变为非束缚、最终无束缚轨道存在。地面引力波探测器频段内物质流可能已耗尽，而LISA和(B-)DECIGO可探测早期阶段。潮汐扰动可在宽分离范围内维持共振，对引力波相位产生累积影响，并可能通过非线性耦合激发准周期振荡。

Conclusion: 潮汐形变对黑洞周围轨道动力学有显著影响，导致复杂的相空间演化，对引力波探测和吸积黑洞观测有重要启示，为理解双星系统中黑洞周围物质行为提供了新视角。

Abstract: We investigate the geometry of a tidally deformed, rotating black hole and timelike geodesics in its vicinity. Our framework provides a local picture of the structural evolution of a relativistic restricted three-body problem around a deformed black hole in an adiabatically evolving binary, motivated by various astrophysical settings including disk dynamics and extreme mass-ratio inspirals. As the tidal-field strength is increased, initially regular, bound geodesics undergo four stages: (i) weak chaos emerges within the bound motion; (ii) a subset of trajectories plunges into the black hole; (iii) a fraction of the remaining trajectories becomes unbound; and (iv) no bound trajectories persist. We provide semi-analytic estimates for the critical tidal amplitudes associated with each transition. Our estimates indicate that, within the frequency band of ground-based gravitational-wave detectors, the matter flow around black holes may already be depleted, whereas LISA and (B-)DECIGO could probe the earlier stages. Our results suggest that an object orbiting a tidally deformed massive BH may remain near resonances over a wide range of separations, indicating an accumulated, non-negligible impact on the gravitational-wave phase. Tidal perturbations can also introduce nonlinear couplings among epicyclic oscillations of geodesics, offering a potential avenue to resonant excitation of quasi-periodic oscillations in X-ray light curves from accreting black holes.

</details>


### [11] [Effects of massive spin-2 fields on gravitational wave propagation](https://arxiv.org/abs/2601.15201)
*Jose A. R. Cembranos,Álvaro Cendal,Hector Villarrubia-Rojo*

Main category: gr-qc

TL;DR: 论文研究了广义相对论扩展中出现的额外大质量自旋-2场对引力波传播的观测特征，建立了可探测性界限，并预测了当前和未来引力波探测器可访问的参数空间。


<details>
  <summary>Details</summary>
Motivation: 在广义相对论的扩展理论（如大质量双引力理论或额外维度模型）中，除了标准无质量引力子外，自然会出现大质量自旋-2场。这些额外场对引力波传播的影响尚未得到充分观测研究，需要探索其可能的观测特征。

Method: 采用与这类理论一致的现象学框架，在超相对论极限下推导解析传递函数，并建立可探测性界限。使用当前和未来的引力波探测器进行参数空间预测。

Result: 推导出了超相对论极限下的解析传递函数，建立了大质量自旋-2场对引力波传播影响的观测界限。提供了使用当前和未来引力波探测器可访问参数空间的预测。

Conclusion: 大质量自旋-2场在引力波传播中会产生可观测的特征，通过建立的分析框架和预测，当前和未来的引力波探测器能够探测这些额外场的存在，为检验广义相对论的扩展理论提供了新的观测途径。

Abstract: Massive spin-2 fields in addition to the standard massless graviton arise naturally in extensions of General Relativity, such as massive bigravity or models with extra dimensions. This work explores the observational signatures of these fields on the propagation of gravitational waves. Adopting a phenomenological framework consistent with such theories, we derive an analytical transfer function in the ultrarelativistic limit and establish detectability bounds. Finally, we provide forecasts for the accessible parameter space using current and future gravitational wave detectors.

</details>


### [12] [Exact general solutions for cosmological scalar field evolution in a vacuum-energy dominated expansion](https://arxiv.org/abs/2601.15226)
*Patrick Hu,Robert J. Scherrer*

Main category: gr-qc

TL;DR: 该论文推导了在w_B=-1背景流体主导宇宙中，标量场演化的精确通解，扩展了之前w_B>-1的研究。对于线性微分方程情况（常数、线性、二次势）有直接解，对于非线性势（对数、平方根、倒数势）也得到精确解，但形式复杂。研究发现慢滚近似适用于真空主导膨胀中的所有足够平坦势，但不适用于w_B>-1的背景流体主导情况。


<details>
  <summary>Details</summary>
Motivation: 扩展先前关于标量场在w_B>-1背景流体主导宇宙中精确解的研究，探索在w_B=-1（真空主导）情况下的标量场演化精确解，并比较不同宇宙背景下的慢滚近似适用性。

Method: 推导标量场演化的精确解析解：对于线性微分方程情况（对应常数、线性、二次势）得到直接解；对于非线性情况（V=V_0 ln φ, V=V_0 φ^{1/2}, V=V_0/φ）推导精确参数解；推广慢滚近似并分析其在不同宇宙背景下的适用条件。

Result: 得到了w_B=-1宇宙中多种势函数的精确解，包括线性情况的直接解和非线性情况的参数解。发现对数势还能得到精确的第一积分。与w_B>-1情况相比，这些解形式更复杂且实用性较低。慢滚近似在真空主导膨胀中适用于所有足够平坦的势，但在w_B>-1的背景流体主导宇宙中完全不适用。

Conclusion: 成功推导了w_B=-1宇宙中标量场演化的精确通解，填补了先前研究的空白。虽然非线性情况的解形式复杂，但理论上有重要意义。慢滚近似适用性的发现揭示了不同宇宙背景对标量场演化的关键影响，为宇宙学模型提供了重要理论依据。

Abstract: We derive exact general solutions (as opposed to attractor particular solutions) for the evolution of a scalar field $φ$ in a universe dominated by a background fluid with equation of state parameter $w_B = -1$, extending earlier work on exact solutions with $w_B > -1$. Straightfoward exact solutions exist when the evolution is described by a linear differential equation, corresponding to constant, linear, and quadratic potentials. In the nonlinear case, exact solutions are derived for $V = V_0\ln φ$, $V = V_0 φ^{1/2}$ and $V = V_0/φ$, and the logarithmic potential also yields an exact first integral. These complicated parametric solutions are considerably less useful than those derived previously for a universe dominated by a barotropic fluid such as matter or radiation with $w_B > -1$. However, we generalize the slow-roll approximation and show that it applies to all sufficiently flat potentials in the case of a vacuum-dominated expansion, while it never applies when the universe is dominated by a background fluid with $w_B > -1$.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [13] [QDK/Chemistry: A Modular Toolkit for Quantum Chemistry Applications](https://arxiv.org/abs/2601.15253)
*Nathan A. Baker,Brian Bilodeau,Chi Chen,Yingrong Chen,Marco Eckhoff,Alexandra Efimovskaya,Piero Gasparotto,Puck van Gerwen,Rushi Gong,Kevin Hoang,Zahra Hooshmand,Andrew J. Jenkins,Conrad S. N. Johnston,Run R. Li,Jiashu Liang,Hongbin Liu,Alexis Mills,Maximilian Mörchen,George Nishibuchi,Chong Sun,Bill Ticehurst,Matthias Troyer,Jan P. Unsleber,Stefan Wernli,David B. Williams-Young,Boqin Zhang*

Main category: quant-ph

TL;DR: QDK/Chemistry是一个用于量子化学工作流的软件工具包，通过模块化架构连接经典电子结构计算与量子电路执行，解决该领域基础设施碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 量子化学算法已相当成熟，但连接经典电子结构计算与量子电路执行的基础设施仍然碎片化，缺乏统一的工作流工具。

Method: 采用模块化架构，将数据表示与计算方法分离，通过插件系统集成广泛使用的开源量子化学包和量子计算框架，允许用户组合不同来源的方法。

Result: 开发了QDK/Chemistry工具包，提供了量子-经典管道中目标算法的原生实现，并建立了可复现量子化学实验的基础。

Conclusion: QDK/Chemistry作为连接经典量子化学与量子计算的关键基础设施，为可复现的量子化学实验提供了基础，解决了该领域工作流碎片化的问题。

Abstract: We present QDK/Chemistry, a software toolkit for quantum chemistry workflows targeting quantum computers. The toolkit addresses a key challenge in the field: while quantum algorithms for chemistry have matured considerably, the infrastructure connecting classical electronic structure calculations to quantum circuit execution remains fragmented. QDK/Chemistry provides this infrastructure through a modular architecture that separates data representations from computational methods, enabling researchers to compose workflows from interchangeable components. In addition to providing native implementations of targeted algorithms in the quantum-classical pipeline, the toolkit builds upon and integrates with widely used open-source quantum chemistry packages and quantum computing frameworks through a plugin system, allowing users to combine methods from different sources without modifying workflow logic. This paper describes the design philosophy, current capabilities, and role of QDK/Chemistry as a foundation for reproducible quantum chemistry experiments.

</details>


### [14] [Advances in non-Hermitian dynamics of quadratic bosonic systems](https://arxiv.org/abs/2601.14329)
*Huawei Zhao,Xinlei Liu,Xinyao Huang,Guofeng Zhang*

Main category: quant-ph

TL;DR: 该论文提出利用二次玻色子系统（QBS）的压缩相互作用实现非厄米特性，包括正交非互易传输和非厄米拓扑现象，为探索非厄米性质对量子效应的影响提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 传统非厄米系统通常通过不对称耦合或引入耗散/增益实现，而二次玻色子系统（QBS）本质上是厄米的，但其动力学演化矩阵在实空间和动量空间都是非厄米的。这为研究非厄米性质对量子效应的影响提供了新途径，而此前非厄米物理研究主要集中在经典系统。

Method: 利用QBS的压缩相互作用，通过对动力学演化矩阵应用场算符变换xp，实现x和p算符之间的正交非互易传输。在Bogoliubov-de Gennes框架下，在动量空间中观察非厄米拓扑现象，如点隙拓扑和非厄米趋肤效应，这些现象由具有非零绕数的谱诱导产生。

Result: QBS可以实现正交非互易传输，可用于信号放大器；同时可以观察到非厄米拓扑现象，包括点隙拓扑和非厄米趋肤效应；还能实现非厄米Aharonov-Bohm笼并扩展非布洛赫能带理论。

Conclusion: 二次玻色子系统为探索非厄米物理与量子物理交叉领域提供了新平台，特别是研究非厄米性质对量子效应的影响这一关键问题，扩展了非厄米物理的研究范围。

Abstract: Non-Hermitian physics has emerged as a rapidly advancing field of research, revealing a range of novel phenomena and potential applications. Traditional non-Hermitian Hamiltonians are typically simulated by constructing asymmetric couplings or by introducing dissipation and gain to realize non-Hermitian systems. The quadratic bosonic system (QBS) with squeezing interaction is intrinsically Hermitian; however, its dynamical evolution matrix in both real and momentum spaces is non-Hermitian. Based on this, applying a field-operator transformation xp to the dynamical evolution matrix yields quadrature nonreciprocal transmission between the x and p operators. This nonreciprocal characteristic can be utilized in signal amplifiers. On the other hand, within the Bogoliubov-de Gennes framework in momentum space, one can observe non-Hermitian topological phenomena such as point-gap topology and the non-Hermitian skin effect, both induced by spectra with nonzero winding numbers. Additionally, QBS can be employed to realize non-Hermitian Aharonov-Bohm cages and to extend non-Bloch band theory. Previous studies in non-Hermitian physics have largely concentrated on classical systems. The influence of non-Hermitian properties on quantum effects remains a key issue awaiting exploration and has evolved into a research direction at the interface of non-Hermitian and quantum physics.

</details>


### [15] [Towards Device-Independent Quantum Key Distribution with Photonic Devices](https://arxiv.org/abs/2601.14373)
*Corentin Lanore,Xavier Valcarce,Jean Etesse,Anthony Martin,Jean-Daniel Bancal*

Main category: quant-ph

TL;DR: 本文提出了一种基于光子电路的设备无关量子密钥分发方案，通过机器学习识别合适的光子电路，并开发了高效的半定规划层次结构和有限统计分析方法，证明了该方案在噪声环境下的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统QKD协议存在物理建模与实现之间的不匹配问题，容易受到侧信道攻击。设备无关QKD通过黑盒设置减少设备建模需求，提供更强安全性，但现有实验主要基于囚禁离子系统，光子平台虽然具有光纤传输、高重复率、硬件成熟等优势，但在DIQKD中的噪声容忍度较低，实验实现困难。

Method: 1. 使用机器学习技术识别适合DIQKD的光子电路；2. 开发了收敛的半定规划层次结构来约束条件冯·诺依曼熵；3. 建立了考虑完整结果统计的有限统计分析方法；4. 评估了所提光学电路在噪声环境下的性能。

Result: 分析表明，所提出的光学电路具有足够的噪声抵抗能力，使得实验实现变得现实可行。这为在光子平台上实现DIQKD提供了理论基础和技术支持。

Conclusion: 本研究证明了在光子平台上实现设备无关量子密钥分发的可行性，通过机器学习识别合适的光子电路，结合高效的熵约束方法和有限统计分析，克服了传统光子平台DIQKD噪声容忍度低的问题，为实际应用奠定了基础。

Abstract: Quantum Key Distribution (QKD) protocols enable two distant parties to communicate with information-theoretically proven secrecy. However, these protocols are generally vulnerable to potential mismatches between the physical modeling and the implementation of their quantum operations, thereby opening opportunities for side channel attacks. Device-Independent (DI) QKD addresses this problem by reducing the degree of device modeling to a black-box setting. The stronger security obtained in this way comes at the cost of a reduced noise tolerance, rendering experimental demonstrations more challenging: so far, only one experiment based on trapped ions was able to successfully generate a secret key. Photonic platforms have however long been preferred for QKD thanks to their suitability to optical fiber transmission, high repetition rates, readily available hardware, and potential for circuit integration. In this work, we assess the feasibility of DIQKD on a photonic circuit recently identified by machine learning techniques. For this, we introduce an efficient converging hierarchy of semi-definite programs (SDP) to bound the conditional von Neumann entropy and develop a finite-statistics analysis that takes into account full outcome statistics. Our analysis shows that the proposed optical circuit is sufficiently resistant to noise to make an experimental realization realistic.

</details>


### [16] [Vanishing correlations in (bi)stochastic controlled circuits](https://arxiv.org/abs/2601.14379)
*Pavel Kos,Bruno Bertini,Tomaž Prosen*

Main category: quant-ph

TL;DR: 随机和双随机受控门电路具有特殊的时空关联结构：两点关联仅当两算符作用在同一位置时才非零，多点关联中右边两个算符必须作用在同一位置


<details>
  <summary>Details</summary>
Motivation: 研究由随机和双随机受控门组成的电路动力学，这类动力学出现在量子电路、随机电路和确定性经典元胞自动机中，旨在揭示这类系统尽管微观动力学复杂却表现出简单关联结构的特性

Method: 通过数学证明分析随机和双随机受控门电路的动力学行为，研究其时空关联函数的结构特性，并讨论自关联函数的衰减行为

Result: 证明了两点时空关联函数仅当两算符作用在同一位置时才非零，多点关联中右边两个算符必须作用在同一位置；自关联函数通常呈指数衰减，其渐近值随系统尺寸指数减小

Conclusion: 随机和双随机受控门电路代表了一类量子系统，尽管微观动力学复杂，却展现出惊人的简单关联结构，这为理解复杂量子系统的简化行为提供了新视角

Abstract: We study the dynamics of circuits composed of stochastic and bistochastic controlled gates. This type of dynamics arises from quantum circuits with random controlled gates, as well as in stochastic circuits and deterministic classical cellular automata. We prove that stochastic and bistochastic controlled gates lead to two-point spatio-temporal correlation functions that vanish everywhere except when the two operators act on the same site. More generally, for multi-point correlations the two rightmost operators must act on the same site. We argue that autocorrelation, while hard to compute, typically decays exponentially towards a value that is exponentially small in the system size. Our results reveal a broad class of quantum systems that exhibit surprisingly simple correlation structures despite their complex microscopic dynamics.

</details>


### [17] [Vacuum Torque Without Anisotropy: Switchable Casimir Torque Between Altermagnets](https://arxiv.org/abs/2601.14381)
*Zixuan Dai,Qing-Dong Jiang*

Main category: quant-ph

TL;DR: 磁场可在保持旋转对称性的情况下通过破坏时间反演对称性产生卡西米尔扭矩，这是与传统机制不同的新机制


<details>
  <summary>Details</summary>
Motivation: 传统卡西米尔扭矩通常与旋转对称性的显式破坏相关（如材料介电各向异性、几何不对称性或外部场破坏旋转不变性）。本文探索一种根本不同的机制：轴向对称磁场如何通过诱导轴向不对称的卡西米尔能量产生扭矩，甚至能反转扭矩符号。

Method: 聚焦于二维交变磁体，研究垂直于平面施加的磁场（保持面内旋转对称性）如何通过交变磁序固有的晶体对称性C_n T激活取向依赖的真空相互作用。分析扭矩随磁场强度的连续产生和二次标度关系，并研究其温度和距离依赖性。

Result: 发现磁场诱导的卡西米尔扭矩连续产生，且与磁场强度平方成正比。其温度和距离依赖的标度行为与单轴块体材料有本质不同。时间反演对称性破坏成为调控卡西米尔扭矩符号和强度的有效途径。

Conclusion: 时间反演对称性破坏是设计卡西米尔扭矩符号和强度的有力途径，交变磁体为探索真空量子涨落驱动现象提供了令人兴奋的平台。

Abstract: Casimir torque is conventionally associated with explicit breaking of rotational symmetry, arising from material dielectric anisotropy, geometric asymmetry, or externally applied fields that themselves break rotational invariance. Here we demonstrate a fundamentally different mechanism: an axially symmetric magnetic field can generate a Casimir torque by inducing an axially asymmetric Casimir energy - and can even reverse the torque's sign. Focusing on two-dimensional altermagnets, we show that a magnetic field applied perpendicular to the plane - while preserving in-plane rotational symmetry - activates an orientation-dependent vacuum interaction through the combined crystalline symmetry $\mathrm{C_n T}$ inherent to altermagnetic order. The resulting torque emerges continuously and scales quadratically with the magnetic field strength. We further analyze its temperature and distance dependence, revealing scaling behaviors that are qualitatively different from those found in uniaxial bulk materials. Our results identify time-reversal symmetry breaking as a powerful route for engineering both the sign and strength of Casimir torque and establish altermagnets as an exciting platform for exploring phenomena driven by vacuum quantum fluctuations.

</details>


### [18] [Pauli Propagation for Imaginary Time Evolution](https://arxiv.org/abs/2601.14400)
*Rafael Gómez-Lurbe,Armando Pérez*

Main category: quant-ph

TL;DR: 将Pauli传播框架扩展到模拟虚时间演化，提出虚时间Pauli传播算法，用于计算热态和基态性质，并展示了在横向场Ising模型上的基准测试结果。


<details>
  <summary>Details</summary>
Motivation: 扩展Pauli传播框架以处理虚时间演化，从而能够计算热态和基态性质，同时保留Pauli传播的计算优势，并为模拟开放量子系统动力学提供统一框架。

Method: 推导Pauli算符在虚时间演化下的显式更新规则，提出虚时间Pauli传播算法，直接在Pauli基中近似虚时间动力学，通过截断在精度和计算成本之间提供可控权衡。

Result: 在一维横向场Ising模型上的基准测试表明，截断方法在精度和计算成本之间提供了可控权衡，同时揭示了虚时间演化下算符增长带来的挑战。

Conclusion: 虚时间Pauli传播算法成功扩展了Pauli传播框架，为计算热态和基态性质提供了有效方法，结合实时间和虚时间Pauli传播为模拟开放量子系统动力学提供了统一框架。

Abstract: We extend the Pauli Propagation framework to simulate imaginary time evolution. By deriving explicit update rules for the propagation of Pauli operators under imaginary time evolution generated by Pauli strings, we introduce an imaginary time Pauli Propagation (ITPP) algorithm for approximating imaginary time dynamics directly in the Pauli basis. This approach enables the computation of thermal and ground-state properties while retaining the key computational advantages of Pauli Propagation. Benchmarking ITPP on the one-dimensional transverse-field Ising model demonstrates that truncation provides a controlled trade-off between accuracy and computational cost, while also revealing challenges associated with operator growth under imaginary time evolution. Finally, combining imaginary time and real-time Pauli Propagation naturally suggests a pathway toward simulating open quantum system dynamics within a unified framework.

</details>


### [19] [Quantum state exclusion with many copies](https://arxiv.org/abs/2601.14410)
*Debanjan Roy,Tathagata Gupta,Pratik Ghosal,Samrat Sen,Somshubhro Bandyopadhyay*

Main category: quant-ph

TL;DR: 多副本量子态排除：对于三个或更多纯态，有限副本可实现态排除，但所需副本数可能任意大


<details>
  <summary>Details</summary>
Motivation: 量子态排除任务旨在从已知集合中识别至少一个未用于系统制备的量子态。单副本设置下态排除并非总是可行，因此研究多副本访问是否能实现态排除。

Method: 研究多副本量子态排除问题，证明对于三个或更多纯态，有限副本可实现态排除。构造示例表明所需副本数可能任意大。

Result: 1. 对于任意三个或更多纯态集合，存在有限副本数可实现态排除。2. 所需副本数可能任意大：对于每个自然数N，可构造态集合使得N个或更少副本无法实现排除。

Conclusion: 多副本访问确实能实现量子态排除，但所需副本数可能非常大，揭示了量子态排除问题的复杂性。

Abstract: Quantum state exclusion is the task of identifying at least one state from a known set that was not used in the preparation of a quantum system. In particular, a given set of quantum states is said to admit state exclusion if there exists a measurement such that, for each state in the set, some measurement outcome rules it out with certainty. However, state exclusion is not always possible in the single-copy setting. In this paper, we investigate whether access to multiple identical copies enables state exclusion. We prove that for any set of three or more pure states, state exclusion becomes possible with a finite number of copies. We further show that the required number of copies may be arbitrarily large -- in particular, for every natural number $N$, we construct sets of states for which exclusion remains impossible with $N$ or fewer copies.

</details>


### [20] [Quantum Super-resolution by Adaptive Non-local Observables](https://arxiv.org/abs/2601.14433)
*Hsin-Yi Lin,Huan-Hsin Tseng,Samuel Yen-Chi Chen,Shinjae Yoo*

Main category: quant-ph

TL;DR: 首次研究量子电路用于超分辨率，提出基于变分量子电路和自适应非局域可观测量的框架，相比传统深度学习方法，能以较小模型实现5倍分辨率提升。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法需要更深的网络、更大的数据集和更重的计算来捕捉细粒度相关性，而量子系统的高维希尔伯特空间、纠缠和叠加特性为超分辨率提供了新的可能性。

Method: 提出基于变分量子电路（VQC）的框架，引入自适应非局域可观测（ANO）测量。与传统VQC使用固定泡利读出不同，ANO引入可训练的多量子比特厄米可观测，允许测量过程在训练中自适应调整。

Result: ANO-VQCs能够实现高达5倍的分辨率提升，且模型规模相对较小，展示了量子机器学习在超分辨率任务中的潜力。

Conclusion: 这是量子电路在超分辨率领域的首次研究，为量子机器学习与超分辨率的交叉领域开辟了有前景的新方向，展示了量子系统在高维表示学习中的优势。

Abstract: Super-resolution (SR) seeks to reconstruct high-resolution (HR) data from low-resolution (LR) observations. Classical deep learning methods have advanced SR substantially, but require increasingly deeper networks, large datasets, and heavy computation to capture fine-grained correlations. In this work, we present the \emph{first study} to investigate quantum circuits for SR. We propose a framework based on Variational Quantum Circuits (VQCs) with \emph{Adaptive Non-Local Observable} (ANO) measurements. Unlike conventional VQCs with fixed Pauli readouts, ANO introduces trainable multi-qubit Hermitian observables, allowing the measurement process to adapt during training. This design leverages the high-dimensional Hilbert space of quantum systems and the representational structure provided by entanglement and superposition. Experiments demonstrate that ANO-VQCs achieve up to five-fold higher resolution with a relatively small model size, suggesting a promising new direction at the intersection of quantum machine learning and super-resolution.

</details>


### [21] [Spin-$s$ $U(1)$-eigenstate preparation](https://arxiv.org/abs/2601.14513)
*Nabi Zare Harofteh,Rafael I. Nepomechie*

Main category: quant-ph

TL;DR: 提出一种确定性算法，用于制备自旋链的U(1)本征态，利用有界整数组合的格雷码和相应的"格雷门"实现量子态制备


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的方法来制备自旋链的U(1)本征态，这些态是计算基态的线性组合，具有固定的数字和，可用于研究可积自旋系统的精确本征态

Method: 利用有界整数组合的格雷码，其连续比特串满足格雷性质，通过应用相应的"格雷门"来制备量子态，该算法适用于任意自旋s和链长n

Result: 开发了一种确定性算法，能够制备一般自旋链的U(1)本征态，并成功应用于制备可积自旋-s XXX哈密顿量的精确本征态

Conclusion: 该算法提供了一种系统的方法来制备自旋链的对称本征态，为研究可积自旋系统的量子态制备和量子模拟提供了有效工具

Abstract: We formulate a deterministic algorithm for preparing a general $U(1)$-eigenstate of a spin-$s$ chain of length $n$. These states consist of linear combinations of computational basis states $|\vec{m}\rangle$ of $n$ qudits, each with $(2s+1)$ levels and $s= 1/2, 1, 3/2, \ldots$, whose ditstrings $\vec{m}$ have a fixed digit sum. Exploiting a Gray code for bounded integer compositions, whose consecutive ditstrings obey the Gray property, the quantum state is prepared by applying corresponding ``Gray gates.'' We use this algorithm to prepare exact eigenstates of integrable spin-$s$ XXX Hamiltonians.

</details>


### [22] [Active interference suppression in frequency-division-multiplexed quantum gates via off-resonant microwave tones](https://arxiv.org/abs/2601.14547)
*Haruki Mitarai,Yukihiro Tadokoro,Hiroya Tanaka*

Main category: quant-ph

TL;DR: 提出一种主动干扰抑制方法，用于频率分复用同时门操作，通过故意加入非共振微波音调提高单量子比特门精度


<details>
  <summary>Details</summary>
Motivation: 量子处理器与外部电子设备之间控制线数量的增加是实现大规模量子计算机的主要瓶颈。频率分复用技术有望通过单根微波电缆控制多个量子比特，但非共振微波音调的干扰阻碍了精确的量子比特控制。

Method: 提出主动干扰抑制方法，通过故意加入非共振微波音调来改善频率分复用同时门操作的精度。具体包括：1）引入非共振正交或准正交微波音调；2）考虑旋转波近似下被忽略的快速振荡；3）通过优化频率分配来减轻门保真度下降。

Result: 发现通过加入非共振正交或准正交微波音调，门不保真度与微波音调数量的平方成反比下降。同时发现旋转波近似下被忽略的快速振荡会降低门保真度，但可以通过优化频率分配来减轻这种退化。

Conclusion: 该方法简单而有效，能够提高频率分复用量子门的性能，为解决大规模量子计算机控制线瓶颈问题提供了有前景的解决方案。

Abstract: An increase in the number of control lines between the quantum processors and the external electronics constitutes a major bottleneck in the realization of large-scale quantum computers. Frequency-division multiplexing is expected to enable multiple qubits to be controlled through a single microwave cable; however, interference from off-resonant microwave tones hinders precise qubit control. Here, we propose an active interference suppression method for frequency-division-multiplexed simultaneous gate operations. We demonstrate that deliberate incorporation of off-resonant microwave tones improves the accuracy of single-qubit gates. Specifically, we find that by incorporating off-resonant orthogonal or quasi-orthogonal microwave tones, the gate infidelity decreases proportionally to the inverse square of the number of microwave tones. Furthermore, we show that fast oscillations neglected under the rotating wave approximation degrade gate fidelity, and that this degradation can be mitigated through optimized frequency allocation. Our approach is simple yet effective for improving the performance of frequency-division-multiplexed quantum gates.

</details>


### [23] [Programming Quantum Measurements of Time inside a Complex Medium](https://arxiv.org/abs/2601.14565)
*Dylan Danese,Vatshal Srivastav,Will McCutcheon,Saroch Leedumrongwatthanakun,Mehul Malik*

Main category: quant-ph

TL;DR: 利用多模光纤中空间模式与色散的耦合，实现可编程的高维时间比特量子态测量，替代传统级联干涉仪方案。


<details>
  <summary>Details</summary>
Motivation: 光子到达时间的高维量子叠加态测量对量子技术至关重要，但传统Franson型干涉仪存在维度扩展性差、需要主动相位稳定、只能测量相位叠加等限制。

Method: 利用多模光纤的多光谱传输矩阵，找到经历不同色散延迟的空间模式集，通过激发这些空间模式的相干叠加，在单根光纤内构建等效的大型非平衡多模干涉仪。

Result: 实现了高达11维的光子时间比特任意叠加态的高质量测量，单根光纤作为可扩展的共路干涉仪，显著降低了传统方法的实验复杂度。

Conclusion: 该方法为利用光的时间特性的量子技术提供了关键工具，通过空间-时间耦合在单光纤内实现可编程的广义测量，解决了传统干涉仪的可扩展性问题。

Abstract: The temporal degree-of-freedom of light is incredibly powerful for modern quantum technologies, enabling large-scale quantum computing architectures and record key-rates in quantum key distribution. However, the generalized measurement of large and complex quantum superpositions of the time-of-arrival of a photon remains a unique experimental challenge. Conventional methods based on unbalanced Franson-type interferometers scale poorly with dimension, requiring multiple cascaded devices and active phase stabilization. In addition, these are limited by construction to a restricted set of phase-only superposition measurements. Here we show how the coupling of spatial and temporal information inside a single multi-mode fiber can be harnessed to program completely generalized measurements for high-dimensional superpositions of photonic time-bin. Using the multi-spectral transmission matrix of the fiber, we find special sets of spatial modes that experience distinct dispersive delays through the fiber. By exciting coherent superpositions of these spatial modes, we engineer the equivalent of large, unbalanced multi-mode interferometers inside the fiber and use them to perform high-quality measurements of arbitrary time-bin superpositions in up to dimension 11. The single fiber functions as a scalable, common-path interferometer for time-bin qudits that significantly eases the experimental overheads of standard approaches based on unbalanced Franson-type interferometers, serving as an essential tool for quantum technologies that harness the temporal properties of light.

</details>


### [24] [Multipartite entanglement in the quantum tetrahedron](https://arxiv.org/abs/2601.14964)
*Robert Amelung,Hanno Sahlmann*

Main category: quant-ph

TL;DR: 该论文研究了SU(2)不变四价张量（即交织子）的多体纠缠特性，使用熵填充度量，发现交织子的纠缠分布与一般张量非常不同，且纠缠与几何数据存在复杂关系。


<details>
  <summary>Details</summary>
Motivation: 交织子在环量子引力中对应具有固定面积的四面体量子态，是最小的"空间原子"态。同时它们也是全局旋转不变的四方张量积态。研究这些特殊态的多体纠缠特性对于理解量子引力中的纠缠结构具有重要意义。

Method: 使用最近提出的熵填充度量来量化多体纠缠。数值计算了自旋从1/2到11的等自旋情况下交织子的熵填充，比较了交织子与一般张量、相干交织子与一般交织子的纠缠分布。

Result: 发现交织子的纠缠分布与一般张量非常不同：对于一般交织子，分布峰值出现在最高纠缠处；对于一般张量，峰值出现在最低纠缠处。但在平均纠缠方面，角色互换：大自旋情况下，一般张量的平均纠缠最高，交织子的较低。相干交织子的纠缠与其几何数据存在复杂关系。

Conclusion: 交织子作为环量子引力中的基本空间量子态，展现出独特的纠缠特性，与一般量子态显著不同。这种差异反映了量子引力态的特殊几何约束，为理解量子几何与纠缠的关系提供了新视角。

Abstract: The space $\mathrm{Inv}(j_1,j_2,j_3,j_4)$ of SU(2)-invariant four-valent tensors, also known as intertwiners, can be understood as the quantum states of a tetrahedron in Euclidean space with fixed areas. In loop quantum gravity, they are states of the smallest "atom of space" with non-zero volume. At the same time they correspond to four-party tensor product states invariant under global rotations. We consider the multipartite entanglement of states in $\mathrm{Inv}(j_1,j_2,j_3,j_4)$ using the recently proposed entropic fill.
  Numerically evaluating entropic fill in the case of equal spins between $1/2$ and $11$, we find that the distributions of entanglement are very different for intertwiners as compared to generic tensors, and for coherent intertwiners as compared to generic ones. The peak in the distribution seems to be at the highest entanglement for generic intertwiners and at the lowest for generic tensors, but in terms of average entanglement, the roles are switched: average entanglement is highest in arbitrary tensors and lower in intertwiners, at least in the regime of large $j$. We also find that entanglement depends on the geometric data of coherent intertwiners in a complicated way.

</details>


### [25] [Quantum Interference Needs Convention: Overlap-Determinability and Unified No-Superposition Principle](https://arxiv.org/abs/2601.14638)
*Jeongho Bang,Kyoungho Cho,Ki Hyuk Yee*

Main category: quant-ph

TL;DR: 论文证明：量子叠加操作的可行性等价于"重叠可确定性"，该条件统一了现有的"不可叠加"结果，并揭示了当允许固定相位约定时，会破坏量子计算的基本限制。


<details>
  <summary>Details</summary>
Motivation: 量子叠加通常被描述为态矢量的相加能力，但实际上物理量是射线（秩一投影算子），每个输入只指定投影算子而留下相位规范自由。这成为实际操作障碍：当需要设备对两个独立制备的未知纯态输出规定线性组合的相干态时，缺乏相位信息成为关键限制。

Method: 通过引入"相位约定"和"重叠可确定性"概念，建立主要定理：存在非零完全正迹非增映射概率性地在域上产生叠加，当且仅当该域是重叠可确定的。这统一了现代不可叠加结果，并刻画了例外可行协议。

Result: 证明了叠加操作的可行性与重叠可确定性的精确等价关系。当允许固定相位约定的重叠时，会破坏量子基础限制：实现类似量子克隆的禁止变换、产生超光速信号、允许对未知态的反射操作，导致指数级重叠放大和Grover搜索下界崩溃到对数查询复杂度。

Conclusion: 量子叠加操作的根本限制源于相位信息的缺失，通过"重叠可确定性"条件可以精确刻画叠加操作的可行性。当允许固定相位约定时，会破坏量子计算和量子基础的基本约束，这揭示了相位信息在量子信息处理中的核心作用。

Abstract: Quantum superposition is often phrased as the ability to add state vectors. In practice, however, the physical quantity is a ray (a rank-one projector), so each input specifies only a projector and leaves a gauge freedom in the phases of its vector representatives. This becomes a real operational barrier when one asks for a device that, given two independently prepared unknown pure states, outputs a coherent state proportional to a prescribed linear combination. We identify the missing ingredient as not probabilistic but phase-like. One needs a physical scenario that fixes a single phase convention on the relevant set of rays, so that the overlaps become well defined complex numbers. Thus, we formalize this through phase conventions and a single notion -- dubbed as "overlap-determinability." Our main theorem gives an exact equivalence: A nonzero completely positive trace-nonincreasing map that probabilistically produces superposition on a domain exists if and only if that domain is overlap-determinable. This unifies modern no-superposition results and characterizes the exceptional yes-go protocols, which succeed precisely when side information supplies the required missing resource. We then show that granting universal access to such convention-fixed overlaps destabilizes the familiar foundational and computational constraints. It enables forbidden transformations akin to quantum cloning and yields super-luminal signaling. It would also permit reflections about unknown states, leading to exponentially fast overlap amplification and a collapse of Grover's search lower bound to a logarithmic query complexity.

</details>


### [26] [Superluminal Transformations and Indeterminism](https://arxiv.org/abs/2601.15263)
*Amrapali Sen,Flavio Del Santo*

Main category: quant-ph

TL;DR: 论文证明了一个"禁止定理"：超光速变换与有限信息无法共存。任何包含超光速变换的理论都必须允许无限信息，导致确定性本体论，这与量子力学的客观概率本质不同。


<details>
  <summary>Details</summary>
Motivation: 量子理论被认为是根本上非确定性的，而经典框架在放弃无限信息后也能表现出非确定性。同时，相对论通常禁止超光速信号，但洛伦兹对称性形式上允许超光速变换。Dragan和Ekert认为超光速变换会导致类似量子的非确定性。本文旨在澄清这种非确定性是否真正类似于量子非确定性。

Method: 从自然假设出发推导出一个"禁止定理"，证明超光速变换与有限信息无法共存。通过逻辑推理和理论分析，探讨超光速变换对信息内容和确定性的影响。

Result: 任何包含超光速变换的理论都必须允许无限信息内容，导致确定性本体论，类似于在实数上表述的经典理论。从超光速变换产生的表面非确定性仅反映主观无知产生的概率，与量子理论中概率的客观性质不同。

Conclusion: 超光速变换产生的非确定性不是量子非确定性。任何容纳超光速变换的理论都需要无限信息，从而产生确定性本体论，这与量子力学的客观概率本质有根本区别。

Abstract: Quantum theory is widely regarded as fundamentally indeterministic, yet classical frameworks can also exhibit indeterminism once infinite information is abandoned. At the same time, relativity is usually taken to forbid superluminal signalling, yet Lorentz symmetry formally admits superluminal transformations (SpTs). Dragan and Ekert have argued that SpTs entail indeterminism analogous to the quantum one. Here, we derive a no-go theorem from natural assumptions, which can be interpreted as: superluminal transformations (SpTs) and finite information cannot coexist. Any theory accommodating SpTs must therefore allow unbounded information content, leading to a deterministic ontology akin to that of classical theories formulated over the real numbers. Thus, any apparent indeterminism arising from superluminal transformations reflects only probabilities arising from subjective ignorance, unlike the objective nature of probabilities in quantum theory, indicating that the claimed indeterminacy from superluminal extensions is not quantum.

</details>


### [27] [Scaling Enhancement in Distributed Quantum Sensing via Causal Order Switching](https://arxiv.org/abs/2601.14708)
*Binke Xia,Zhaotong Cui,Jingzheng Huang,Yuxiang Yang,Guihua Zeng*

Main category: quant-ph

TL;DR: 提出一种基于因果序切换的分布式量子传感协议，无需纠缠探针即可实现1/N²精度的超海森堡标度


<details>
  <summary>Details</summary>
Motivation: 传统分布式量子传感依赖纠缠探针，但纠缠态对噪声敏感且难以扩展，需要更稳健可扩展的方案

Method: 将因果序开关融入循环网络，让单个探针在相反因果序的相干叠加或概率混合中顺序查询N个独立传感器，利用传播与传感过程的非对易性

Result: 实验实现9个传感器的分布式光束倾斜传感，达到皮弧度级精度，超越传统1/N海森堡标度

Conclusion: 该协议提供了一种稳健且可扩展的分布式量子传感方案，推进量子传感网络的实际部署

Abstract: Sensing networks underpin applications from fundamental physics to real-world engineering. Recently, distributed quantum sensing (DQS) has been investigated to boost the sensing performance, yet current schemes typically rely on entangled probes that are fragile to noise and difficult to scale. Here, we propose a DQS protocol that incorporates a causal-order switch into a cyclic network, enabling a single probe to sequentially query N independent sensors in a coherent superposition or a probabilistic mixture of opposite causal orders. By exploiting the noncommutativity between propagation and sensing processes, our scheme achieves a 1/N^2-scaling precision limit without involving entangled probes. Importantly, our approach utilizes a classical mixture of causal orders rather than a quantum switch, making it more feasible for practical realization. We experimentally implement this scheme for distributed beam tilts sensing in a free-space quantum optical network comprising up to 9 sensors, achieving picoradian-scale precision in estimating tilt angle. Our results demonstrate a robust and scalable DQS protocol that surpasses the conventional 1/N Heisenberg scaling in precision, advancing the practical deployment of quantum sensing networks.

</details>


### [28] [Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness](https://arxiv.org/abs/2601.14713)
*Tingting Li,Ziming Zhao,Jianwei Yin*

Main category: quant-ph

TL;DR: QuFid是一个自适应、噪声感知的量子程序保真度估计框架，通过电路结构和运行时统计反馈在线确定测量预算，显著降低测量成本


<details>
  <summary>Details</summary>
Motivation: 在NISQ设备上测试量子程序时，保真度估计是关键但资源密集的步骤。由于硬件噪声、设备异构性和编译引起的电路变换，难以预先定义所需的测量次数

Method: 将量子程序建模为有向无环图，采用控制流感知的随机游走来表征沿门依赖关系的噪声传播。通过编译引起的结构变形度量捕获后端特定效应，并集成到随机游走公式中以诱导噪声传播算子。通过该算子的谱特性量化电路复杂度，为自适应测量规划提供理论基础

Result: 在IBM Quantum后端执行的18个量子基准测试表明，QuFid相比固定测量次数和学习基线显著降低了测量成本，同时保持可接受的保真度偏差

Conclusion: QuFid提供了一个原则性且轻量级的自适应保真度估计框架，能够有效应对NISQ设备的噪声和异构性挑战，为量子程序测试提供实用的解决方案

Abstract: Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias.

</details>


### [29] [On Distributed Quantum Computing with Distributed Fan-Out Operations](https://arxiv.org/abs/2601.14734)
*Seng W. Loke*

Main category: quant-ph

TL;DR: 比较仅使用纠缠对和使用分布式扇出操作（GHZ态）实现分布式量子计算的电路，发现分布式扇出操作能减少电路深度和可能的纠缠资源


<details>
  <summary>Details</summary>
Motivation: 探索分布式量子计算中不同电路实现方法的优劣，特别是比较仅使用纠缠对与使用分布式扇出操作（GHZ态）的效率差异

Method: 比较分析不同电路实现分布式量子计算的方法：1）仅使用纠缠对；2）使用分布式扇出操作（GHZ态）

Result: 分布式扇出操作（GHZ态）在减少电路深度和可能减少纠缠资源方面具有优势，如果分布式GHZ态能高效实现，它可能成为分布式量子操作的基本构建块

Conclusion: 分布式扇出操作（特别是分布式GHZ态）有望成为分布式量子计算的基本构建块，类似于纠缠对的作用，前提是能实现高效的分布式GHZ态生成

Abstract: We compare different circuits implementing distributed versions of quantum computations, using entangled pairs only, and using distributed fan-out operations (using GHZ states). We highlight the advantages of using distributed fan-out operations in terms of reductions in circuit depth and (possibly) entanglement resources. We note that distributed fan-out operations (or notably, distributed GHZ states) could be a ``primitive'' building block for distributed quantum operations in the same way as entangled pairs are, if distributed GHZ states could be realized efficiently.

</details>


### [30] [Blended Dynamics and Emergence in Open Quantum Networks](https://arxiv.org/abs/2601.14763)
*Qinghao Wen,Zihao Ren,Lei Wang,Hyungbo Shim,Guodong Shi*

Main category: quant-ph

TL;DR: 本文开发了开放量子网络中扩散耦合的混合动力学框架，揭示了量子网络中的经典类聚类现象和量子相干动力学


<details>
  <summary>Details</summary>
Motivation: 开放量子网络在自发辐射过程和非厄米量子计算中常见，其演化遵循Lindblad主方程。经典混合动力学理论已成熟用于分析异质网络中的涌现行为，但需要扩展到量子领域以揭示量子网络中的聚类现象和相干动力学

Method: 首先将经典混合动力学理论扩展到量子网络的约化态动力学，然后使用量子拉普拉斯算子和诱导图分析量子比特相干态，证明网络密度算子向量子混合相干动力学的轨道吸引

Result: 理论分析表明，在足够强的耦合下，量子比特会收敛到共享平衡态或由量子混合约化态动力学确定的共同轨迹，网络密度算子被吸引到量子混合相干动力学，揭示了内在量子动态聚类行为

Conclusion: 混合动力学框架成功扩展到开放量子网络，揭示了量子网络中的经典类聚类现象和量子相干动力学，数值验证支持理论结果，为分析量子网络涌现行为提供了新工具

Abstract: In this paper, we develop a blended dynamics framework for open quantum networks with diffusive couplings. The network consists of qubits interconnected through Hamiltonian couplings, environmental dissipation, and consensus-like diffusive interactions. Such networks commonly arise in spontaneous emission processes and non-Hermitian quantum computing, and their evolution follows a Lindblad master equation. Blended dynamics theory is well established in the classical setting as a tool for analyzing emergent behaviors in heterogeneous networks with diffusive couplings. Its key insight is to blend the local dynamics rather than the trajectories of individual nodes. Perturbation analysis then shows that, under sufficiently strong coupling, all node trajectories tend to stay close to those of the blended system over time. We first show that this theory extends naturally to the reduced-state dynamics of quantum networks, revealing classical-like clustering phenomena in which qubits converge to a shared equilibrium or a common trajectory determined by the quantum blended reduced-state dynamics. We then extend the analysis to qubit coherent states using quantum Laplacians and induced graphs, proving orbit attraction of the network density operator toward the quantum blended coherent dynamics, establishing the emergence of intrinsically quantum and dynamically clustering behaviors. Finally, numerical examples validate the theoretical results.

</details>


### [31] [Testing the equivalence to thermal states via extractable work under LOCC](https://arxiv.org/abs/2601.14789)
*Toshihiro Yada,Nobuyuki Yoshioka,Takahiro Sagawa*

Main category: quant-ph

TL;DR: 该论文研究了在LOCC操作下量子多体纯态是否仍与热态等效的问题，发现热等效性由多体量子关联结构决定，最大多体纠缠态无法提取大量功，而有限多体纠缠态可以。


<details>
  <summary>Details</summary>
Motivation: 传统上已知典型纯态在局域操作下与热态一样无法提取功，但LOCC操作可以利用经典可访问的关联，因此需要研究在LOCC下这种热等效性是否仍然成立。

Method: 建立了判断多体纯态在LOCC下是否与热态等效的判据，分析了不同多体量子关联结构（如最大多体纠缠态和有限度图态）在LOCC下的功提取能力。

Result: 发现热等效性由多体量子关联结构决定：渐近最大多体纠缠态（如Haar随机态）在LOCC下无法提取大量功，而有限多体纠缠态（如常数度图态）尽管局域不可区分于热态，却可以提取大量功。

Conclusion: 提出了超越传统局域操作的热等效性操作定义，这对于理解实验可访问操作扩展背景下的量子热力学行为具有重要意义。

Abstract: Understanding the thermal behavior of quantum many-body pure states is one of the most fundamental issues in quantum thermodynamics. It is widely known that typical pure states yield vanishing work, just as thermal states do, when one restricts to local operations that cannot access correlations among subsystems. However, it remains unclear whether this equivalence to thermal states persists under LOCC (local operations and classical communication), where classically accessible correlations can be exploited for work extraction. In this work, we establish criteria for determining whether many-body pure states remain equivalent to thermal states even under LOCC, and show that this thermal equivalence is governed by their multipartite quantum correlation structure. We show that states with asymptotically maximal multipartite entanglement, such as Haar-random states, cannot yield extensive work under LOCC, whereas some states with limited multipartite entanglement, such as constant-degree graph states, allow extensive work extraction despite being locally indistinguishable from thermal states. Thus, our work provides a refined operational notion of thermal equivalence beyond the traditional local regime, which is becoming increasingly important due to the recent expansion of experimentally accessible operations.

</details>


### [32] [Routing Qubits on Noisy Networks](https://arxiv.org/abs/2601.14824)
*Claudia Benedetti,Giovanni Ragazzi,Simone Cavazzoni,Paolo Bordone,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 研究量子路由协议在理想条件下的鲁棒性，通过量子行走在图上编码信息，评估静态和动态噪声下的路由性能


<details>
  <summary>Details</summary>
Motivation: 量子路由的鲁棒性对于可扩展量子技术至关重要，需要研究在理想条件下设计的高保真信息传输网络架构在实际噪声环境中的表现

Method: 将信息编码在量子行走者在图上的位置，模拟从单个输入到多个正交输出的通用量子比特状态路由，分析不同机制下的路由性能

Result: 评估了各种机制下路由协议对静态和动态噪声的鲁棒性表现

Conclusion: 量子路由协议的鲁棒性分析为可扩展量子网络设计提供了重要参考，有助于开发在实际噪声环境下可靠工作的量子路由方案

Abstract: Robust quantum routing is essential for scalable quantum technologies. This paper investigates the resilience of routing protocols in network architectures designed for perfect, high-fidelity transfer of both classical and quantum information under ideal conditions. We encode information in the position of a quantum walker on a graph, modelling the routing of a generic qubit state from a single input to multiple (orthogonal) outputs. We analyse and assess routing performance in various regimes, evaluating their robustness against static and dynamical noise.

</details>


### [33] [Combatting noise in near-term quantum data centres](https://arxiv.org/abs/2601.14845)
*Kenny Campbell,Ahmed Lawey,Mohsen Razavi*

Main category: quant-ph

TL;DR: 分析量子数据中心中不同错误处理方法对分布式量子计算性能的影响，比较量子错误检测与传统纠缠蒸馏技术


<details>
  <summary>Details</summary>
Motivation: 研究在分布式量子计算中，如何有效处理量子错误以提高远程门操作的性能，特别是在量子数据中心范式下

Method: 使用经典模拟方法，比较三量子比特重复码和[[4,1,2]] Leung-Nielsen-Chuang-Yamamoto码的量子错误检测技术，与传统纠缠蒸馏技术进行对比

Result: 通过详细经典模拟获得了适用于近期实际硬件的性能结果

Conclusion: 为量子数据中心范式中的错误处理提供了性能比较分析，有助于选择适合分布式量子计算的错误处理方法

Abstract: We analyse the performance of different error handling methods in the quantum data centre paradigm of distributed quantum computing. We compare the impact of quantum error detection, using the three-qubit repetition code and the [[4, 1, 2]] Leung-Nielsen-Chuang-Yamamoto code, on remote gates with that of conventional entanglement distillation techniques. Detailed classical simulation is used to obtain results for realistic near-term hardware.

</details>


### [34] [Exotic collective behaviors of giant quantum emitters in two-dimensional baths](https://arxiv.org/abs/2601.14867)
*Qing-Yang Qiu,Wen Huang,Lei Du,Xin-You Lü*

Main category: quant-ph

TL;DR: 该论文研究多个巨型原子在二维光学浴中的非局域光-物质相互作用，展示了通过精确原子排列可实现非常规量子动力学，包括非马尔可夫性诱导的拍频和连续谱中的长寿命束缚态，为二维量子存储器提供了平台。


<details>
  <summary>Details</summary>
Motivation: 研究巨型原子在高维环境中的非局域光-物质相互作用，不仅对测试超越偶极近似的量子电动力学具有基础意义，而且对构建高维量子网络和工程多体纠缠态至关重要。特别是多个巨型原子在二维光学浴中表现出的神秘且未被充分探索的集体特征。

Method: 在单激发子空间中研究多个巨型原子与共同二维光子库耦合的非微扰集体动力学，采用解析算符方法。研究精确设计的原子排列如何影响量子动力学，并推广到三维浴的情况。

Result: 1. 精确设计的原子排列导致非常规量子动力学，包括非马尔可夫性诱导的拍频和连续谱中的长寿命束缚态，为二维量子存储器提供了平台。
2. 在二维和三维浴中观察到奇异的光子发射模式，发射方向可通过耦合参数的精确相位工程按需精确控制，实现高效的手性光-物质界面。
3. 在三维浴中，相干偶极-偶极相互作用可以在耦合到连续模式谱的情况下存活，这一发现挑战了关于退相干的传统认知。

Conclusion: 该研究揭示了巨型原子在高维光学浴中的丰富集体动力学，为量子信息处理提供了新的可能性，包括量子存储器、手性界面和相干相互作用保护，挑战了传统退相干理论，为高维量子网络的发展奠定了基础。

Abstract: Nonlocal light-matter interactions with giant atoms in high-dimensional environments are not only fundamentally intriguing for testing quantum electrodynamics beyond the dipole approximation but also crucial for building high-dimensional quantum networks and engineering multipartite entangled states. Given the enigmatic and largely uncharted collective signatures exhibited by multiple giant atoms within two-dimensional optical baths, we delve into their nonperturbative collective dynamics within the single-excitation subspace, focusing on the case where they are coupled to a common two-dimensional photonic reservoir and employing a resolvent operator approach. We demonstrate that precisely engineered atomic arrangements lead to unconventional quantum dynamics, featuring non-Markovianity-induced beats and long-lived bound states in the continuum, thereby providing a versatile platform for implementing two-dimensional quantum memory. Phenomenologically, we observe the emergence of exotic photon emission patterns in both two- and three-dimensional (3D) baths. The emission directions are shown to be precisely controllable on demand through exact phase engineering of the coupling parameters, enabling a highly efficient chiral light-matter interface. Moreover, our generalization to a 3D bath reveals that coherent dipole-dipole interactions can survive despite the coupling to a continuum of modes, a finding that challenges conventional wisdom regarding decoherence.

</details>


### [35] [Multiparameter estimation for the superresolution of two incoherent sources](https://arxiv.org/abs/2601.14876)
*Antonin Grateau,Alexander Boeschoten,Tanguy Favin-Lévêque,Isael Herrera,Nicolas Treps*

Main category: quant-ph

TL;DR: 利用空间模式解复用技术实现亚瑞利极限下双光源三参数的同时超分辨估计


<details>
  <summary>Details</summary>
Motivation: 传统光学成像受衍射极限限制，无法分辨亚瑞利距离的光源。需要开发能够同时估计多个光源参数的超分辨技术。

Method: 采用空间模式解复用(SPADE)技术，使用两个解复用器（其中一个故意偏移），在单次实验设置中同时估计光源的分离距离、质心位置和相对亮度。

Result: 成功实现了远低于衍射极限的光源分离距离测量，并在宽范围场景配置下实现了三个参数的敏感联合估计。通过Fisher信息Cramér-Rao界限评估性能，并讨论了相应的量子极限。

Conclusion: 该方法能够实现亚瑞利极限下双光源三参数的同时超分辨估计，为超分辨场景表征提供了有效方案，并探讨了非相同光源和理想不可区分光源两种场景。

Abstract: We experimentally demonstrate the simultaneous estimation of the three parameters characterizing a pair of incoherent optical sources in the sub-Rayleigh regime, enabling super-resolved scene characterization. Using spatial-mode demultiplexing (SPADE) with two demultiplexers--one deliberately shifted--we determine separations well below the diffraction limit and achieve sensitive joint estimation of separation, centroid, and relative brightness over a broad range of scene configurations in a single experimental setting. We benchmark our performance using Fisher-information-based Cramér-Rao bounds, and discuss the corresponding quantum limits. We investigate two complementary scenarios: a realistic case with slightly non-identical sources, and an idealized case of indistinguishable sources.

</details>


### [36] [Impossible Counterfactuals, Discrete Hilbert Space and Bell's Theorem](https://arxiv.org/abs/2601.14941)
*Tim Palmer*

Main category: quant-ph

TL;DR: 该论文提出了一种违反测量独立性假设的局部实在论模型（RaQM），通过希尔伯特空间的引力离散化，在不否定自由意志的情况下解释贝尔不等式违反。


<details>
  <summary>Details</summary>
Motivation: 传统上，违反测量独立性假设（MI）被认为是解释贝尔不等式实验违反的"第三条路"，但通常被认为过于牵强，暗示着某种不合理的阴谋论。本文旨在开发一种不否定自由意志的局部实在论模型来解释量子现象。

Method: 提出了理性力学（RaQM）模型，基于希尔伯特空间的引力离散化。该模型区分了实验者选择测量设置的"名义精度"自由与选择"精确设置"的不可能性。在RaQM中，希尔伯特态在平方振幅和/或复相位为无理数的基中必然未定义。

Result: RaQM模型表明，违反贝尔不等式可以在不涉及传统上与之相关的奇怪过程（如超距作用）的情况下理解。通过p进数理论，将RaQM与Bohm和Hiley的整体性马赫式未分割宇宙概念联系起来。

Conclusion: 如果对贝尔定理的这种解释是正确的，那么通过建造更高能量的粒子加速器来探索更小尺度以寻找量子与引力物理的统一理论（万物理论）可能是徒劳的。RaQM提供了一种理解量子现象的新框架，避免了传统解释中的奇异特性。

Abstract: Negating the Measurement Independence assumption (MI) is often referred to as the `third way' to account for the experimental violation of Bell's inequality. However, this route is generally viewed as ludicrously contrived, implying some implausible conspiracy where experimenters are denied the freedom to choose measurement settings as they like. Here, a locally realistic model of quantum physics is developed (Rational Mechanics - RaQM - based on a gravitational discretisation of Hilbert Space) which violates MI without denying free will. Crucially, RaQM distinguishes experimenters' ability to freely choose measurement settings to some nominal accuracy, from an inability to choose exact settings, which were never under their control anyway. In RaQM, Hilbert states are necessarily undefined in bases where squared amplitudes and/or complex phases are irrational numbers. Such `irrational' bases correspond to conceivable but necessarily impossible counterfactual measurements, and are shown to play a ubiquitous role in the analysis of both single- and entangled-particle quantum physics. It is concluded that violation of Bell inequalities can be understood with none of the strange processes historically associated with it. Instead, using concepts from (non-classical) $p$-adic number theory, we relate RaQM to Bohm and Hiley's concept of a holistic Machian-like Undivided Universe. If this interpretation of Bell's Theorem is correct, building more and more energetic particle accelerators to probe smaller and smaller scales, in the search for a theory which synthesises quantum and gravitational physics and hence a Theory of Everything, may be a fruitless exercise.

</details>


### [37] [Resonant Excitation Induced Vibronic Mollow Triplets](https://arxiv.org/abs/2601.14963)
*Devashish Pandey,Corne Koks,Martijn Wubs,Nicolas Stenger,Jake Iles-Smith*

Main category: quant-ph

TL;DR: 在强共振驱动下，耦合局域声子的量子发射体不仅零声子线会出现Mollow三重态，其声子边带也会出现Mollow三重态，揭示了电子-光子-声子混合的相干动力学。


<details>
  <summary>Details</summary>
Motivation: 传统上认为声子边带是典型的非相干、非弹性散射通道，但本文预测在强共振驱动下，声子边带也会出现Mollow三重态，这为理解振动耦合系统中的相干性提供了新视角。

Method: 开发了一个可扩展的解析形式体系来模拟这种效应，适用于复杂的多模式分子系统（如二苯并并四苯），并确定了观测这些新光谱特征的精确驱动条件。

Result: 预测了在强共振驱动下，耦合局域声子的发射体会在声子边带上出现Mollow三重态，这些振动Mollow三重态是动态生成的混合态的直接指纹，揭示了电子、光子和振动自由度之间的相干混合。

Conclusion: 这项工作建立了振动耦合系统中相干性的新特征，表明Mollow三重态不仅限于零声子线，还能扩展到声子边带，为研究复杂分子系统中的相干现象提供了新工具。

Abstract: The Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter's electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems.

</details>


### [38] [Low-frequency fiber-optic vibration sensing with a Floquet-engineered optical lattice clock](https://arxiv.org/abs/2601.14995)
*Mojuan Yin,Ruohui Wang,Rui Zhou,Xueguang Qiao,Shougang Zhang*

Main category: quant-ph

TL;DR: 提出基于Floquet工程光学晶格钟的解调方案，提升缠绕光纤振动传感器的低频性能


<details>
  <summary>Details</summary>
Motivation: 传统光纤振动传感器在低频段性能受限，需要提升0.5-200Hz低频振动检测能力

Method: 利用Floquet工程Rabi光谱对传感光纤中的振动诱导相位变化进行解调，模拟不同光纤长度和振动频率下的晶格深度和Rabi光谱

Result: 在4km光纤长度、2dB/km传输损耗下，200Hz和0.5Hz振动频率均实现高于6×10³ rad/g的相位变化灵敏度

Conclusion: Floquet工程光学晶格钟解调方案能有效提升光纤振动传感器的低频性能，在长距离传感中保持高灵敏度

Abstract: We propose a Floquet-engineered optical lattice clock based demodulation scheme to enhance the low-frequency performance of wound fiber-optic vibration sensors. Vibration-induced phase variations in the sensing fiber are demodulated by the Floquet-engineered Rabi spectra of the clock transition. The lattice depth with the fiber length and the Floquet-engineered Rabi spectra under the vibration from 200 Hz down to 0.5 Hz are simulated. With a fiber length of 4 km and transmission loss of 2 dB/km, a phase change sensitivity higher than 6 * 10^3 rad per g is achieved at both vibration frequencies of 200 Hz and 0.5 Hz.

</details>


### [39] [Cavity-QED tools for MBQC with optical binomial-codes](https://arxiv.org/abs/2601.15019)
*G. P. Teja,Radim Filip*

Main category: quant-ph

TL;DR: 提出了使用光学二项式编码进行基于测量的量子计算（MBQC）的工具包，包括腔-QED协议用于条件生成簇态和泡利测量实现


<details>
  <summary>Details</summary>
Motivation: 基于测量的量子计算（MBQC）为光量子计算提供了有前景的范式，但需要生成特定的非高斯资源态。虽然连续变量编码（如GKP态）已被广泛研究，但更简单的二项式编码提供了实验上更易实现的替代方案，尽管需要不同的操作工具。

Method: 提出了使用光学二项式编码的MBQC工具包，详细描述了腔-QED协议用于条件生成簇态，并实现了泡利测量。

Result: 为现有光学原子-腔架构提出了首个步骤，为它们在量子计算中的应用奠定了基础。

Conclusion: 这项工作为使用光学二项式编码进行基于测量的量子计算提供了完整的工具包，使现有实验平台能够向实现量子计算迈出第一步。

Abstract: Measurement-based quantum computation (MBQC) offers a promising paradigm for photonic quantum computing, but its implementation requires the generation of specific non-Gaussian resource states. While continuous-variable encodings such as the highly complex (GKP) states have been widely studied, the much simpler binomial codes offer an experimentally accessible alternative, though they demand a distinct set of operational tools. Here, we present a toolkit for MBQC using optical binomial codes, detailing a cavity-QED protocol for conditional generation of cluster states and the implementation of Pauli measurements. Our work proposes the first steps for existing optical atom-cavity architectures to lay the groundwork for their use in quantum computation.

</details>


### [40] [Two-Qubit Spin-Boson Model in the Strong Coupling Regime: Coherence, Non-Markovianity, and Quantum Thermodynamics](https://arxiv.org/abs/2601.15026)
*Hasan Mehdi Rizvi,Devvrat Tiwari,Subhashish Banerjee*

Main category: quant-ph

TL;DR: 研究强耦合非马尔可夫非平衡条件下双量子比特开放系统的动力学，采用HEOM和RCM方法分析不同耦合机制，探究隧穿幅值对量子相干性的影响，并计算强耦合下的熵产生，研究量子热器件应用。


<details>
  <summary>Details</summary>
Motivation: 研究强耦合非马尔可夫非平衡条件下双量子比特开放量子系统的动力学行为，特别是为了理解量子相干性在强耦合环境中的演化，以及探索在强耦合条件下实现量子热器件的可能性。

Method: 采用两种互补方法：层次运动方程（HEOM）和反应坐标映射（RCM），分析双量子比特与各自热浴在不同耦合机制下的相互作用。使用相干性的l1范数来量化量子相干性，利用HEOM中的辅助密度算符计算强耦合下的熵产生。

Result: 模型表现出非马尔可夫演化，隧穿幅值对量子相干性有显著影响。成功计算了强耦合条件下的熵产生，并研究了系统的非平衡稳态行为，探索了热流和自旋流与隧穿幅值之间的关系。

Conclusion: 该研究为理解强耦合非马尔可夫非平衡条件下双量子比特系统的动力学提供了深入见解，展示了量子相干性在强耦合环境中的演化特性，并为强耦合条件下量子热器件的实现提供了理论基础。

Abstract: We investigate the dynamics of a two-qubit open quantum system, in particular the two-qubit spin-boson model in the strong coupling regime, coupled to two thermal bosonic baths under non-Markovian and non-equilibrium conditions. Two complementary approaches, the Hierarchical Equations of Motion (HEOM) and Reaction Coordinate Mapping (RCM), are employed to examine various coupling regimes between the qubits and their respective baths. The dynamical features of the model and the impact of the tunneling amplitude on quantum coherence of the system are probed using the $l_1$-norm of coherence. The model is further shown to have non-Markovian evolution. The nontrivial task of calculating entropy production in the strong-coupling regime is performed using auxiliary density operators in HEOM. Motivated by the realization of a quantum thermal device in the strong-coupling regime, the non-equilibrium steady-state behavior of the system is investigated. Furthermore, the relationship between the heat and spin currents and the tunneling amplitude is probed.

</details>


### [41] [Explaining the advantage of quantum-enhanced physics-informed neural networks](https://arxiv.org/abs/2601.15046)
*Nils Klement,Veronika Eyring,Mierk Schwabe*

Main category: quant-ph

TL;DR: 量子计算增强物理信息神经网络（PINNs）求解偏微分方程，量子-经典混合网络相比纯经典网络能显著减少训练轮次，特别是在复杂问题上。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程（PDEs）在气候建模、材料科学、金融市场等许多自然现象模拟中至关重要。物理信息神经网络（PINNs）在加速PDE求解方面有潜力，但目前仍无法与数值求解器竞争。研究量子计算如何提升PINNs求解PDE的能力。

Method: 开发量子-经典混合网络，将量子电路与经典层结合。系统地在各种非线性PDE和边界条件下测试这些混合网络，并与纯经典网络进行比较。

Result: 量子网络的优势在于能够以显著更少的训练轮次获得精确的近似解，特别是在更复杂的问题上。量子-经典混合网络在训练效率上优于纯经典网络。

Conclusion: 这些发现为有针对性地开发混合量子神经网络奠定了基础，目标是显著加速数值建模。量子计算有潜力提升PINNs在PDE求解中的性能。

Abstract: Partial differential equations (PDEs) form the backbone of simulations of many natural phenomena, for example in climate modeling, material science, and even financial markets. The application of physics-informed neural networks to accelerate the solution of PDEs is promising, but not competitive with numerical solvers yet. Here, we show how quantum computing can improve the ability of physics-informed neural networks to solve partial differential equations. For this, we develop hybrid networks consisting of quantum circuits combined with classical layers and systematically test them on various non linear PDEs and boundary conditions in comparison with purely classical networks. We demonstrate that the advantage of using quantum networks lies in their ability to achieve an accurate approximation of the solution in substantially fewer training epochs, particularly for more complex problems. These findings provide the basis for targeted developments of hybrid quantum neural networks with the goal to significantly accelerate numerical modeling.

</details>


### [42] [Bose condensation and Bogoliubov excitation in resonator-embedded superconducting qubit network](https://arxiv.org/abs/2601.15101)
*Patrick Navez,Valentina Di Meo,Berardo Ruggiero,Claudio Gatti,Fabio Chiarello,Alessandro D'Elia,Alessio Rettaroli,Emanuele Enrico,Luca Fasolo,Mikhail Fistul,Ilya Eremin,Alexandre Zagoskin,Paolo Vanacore,Paolo Silvestrini,Mikhail Lisitskiy*

Main category: quant-ph

TL;DR: 超导量子比特网络与微波谐振器耦合，通过量子交流斯塔克效应实现强非线性光子相互作用，在泵浦功率超过临界值时观察到光子数双稳态的尖锐频率偏移。


<details>
  <summary>Details</summary>
Motivation: 研究超导量子比特网络与低耗散谐振器的耦合系统，旨在建立宏观尺度的集体量子动力学，并增强微波光子探测器的灵敏度。量子交流斯塔克效应导致光子间的强非线性相互作用，为探索光子凝聚和双稳态现象提供了平台。

Method: 采用双音光谱实验，将10个超导磁通量子比特耦合到输入谐振器和输出传输线。使用接近共振频率的外部微波泵浦场宏观填充谐振器模式（类似玻色-爱因斯坦凝聚），同时用第二束探测光束扫描共振（类似Bogoliubov激发）。通过测量传输系数|S21(f)|分析激发频率。

Result: 当泵浦场功率超过临界值Pcr时，传输系数测量的共振吸收峰位置出现急剧变化。这种尖锐偏移发生在泵浦频率的狭窄区域内，并且可以通过外加磁场进行调谐。这标志着谐振器内光子数的双稳态行为，与理论预测一致。

Conclusion: 实验成功观测到超导量子比特网络-谐振器耦合系统中的光子双稳态现象，验证了量子交流斯塔克效应导致的强非线性相互作用。这种双稳态行为为量子信息处理和微波光子探测提供了新的可能性。

Abstract: Superconducting qubit networks (SQNs) embedded in a low-dissipative resonator is a promising device allowing one not only to establish the collective quantum dynamics on a macroscopic scale but also to greatly enhance the sensitivity of detectors of microwave photons. A quantum ac Stark effect provided by coupling between an SQN and microwave photons of a resonator, leads to a strong nonlinear interaction between photons. Here, we present a two-tone spectroscopy experiment in which a set of 10 superconducting flux qubits is coupled to the input R- resonator and the output T- transmission line. An external microwave pump field close to the resonance frequency populates macroscopically the resonator mode as a Bose-Einstein condensate, while a second probe beam scans the resonances referred also as Bogoliubov-like excitations. The corresponding excitation frequency measured from the transmission coefficient, |S21(f)| displays an abrupt change of the resonant dip position once the power of the pump field overcomes a critical value Pcr. This sharp shift occurs in a narrow region of pump frequencies, and can be tuned by an applied magnetic field. It is a signature of bistability of the photon number inside the resonator, in agreement with theory.

</details>


### [43] [Entanglement summoning from entanglement sharing](https://arxiv.org/abs/2601.15112)
*Lana Bozanic,Alex May,Stanley Miao*

Main category: quant-ph

TL;DR: 该论文研究了纠缠召唤任务，给出了双向因果连接情况下的充要条件，并为包含定向和双向因果连接的一般情况提供了一组充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究在分布式量子网络中，当通信资源受限（包括时间约束和网络连接限制）时，如何在不同位置之间准备纠缠态的问题。

Method: 基于早期工作，利用最近发展的纠缠共享方案，对纠缠召唤任务进行特征化分析。

Result: 为仅包含双向因果连接的纠缠召唤任务提供了充要条件，并为包含定向和双向因果连接的一般情况提供了一组充分条件。

Conclusion: 该研究推进了对纠缠召唤任务的理解，为在受限通信条件下实现分布式量子纠缠提供了理论框架和实用条件。

Abstract: In an entanglement summoning task, a set of distributed, co-operating parties attempt to fulfill requests to prepare entanglement between distant locations. The parties share limited communication resources: timing constraints may require the entangled state be prepared before some pairs of distant parties can communicate, and a restricted set of links in a quantum network may further constrain communication. Building on earlier work, we continue the characterization of entanglement summoning. We give an if and only if condition on entanglement summoning tasks with only bidirected causal connections, and provide a set of sufficient conditions addressing the most general case containing both oriented and bidirected causal connections. Our results rely on the recent development of entanglement sharing schemes.

</details>


### [44] [A nearly linear-time Decoded Quantum Interferometry algorithm for the Optimal Polynomial Intersection problem](https://arxiv.org/abs/2601.15171)
*Ansis Rosmanis*

Main category: quant-ph

TL;DR: 本文改进了DQI算法，通过绕过二次时间Dicke态制备，实现了针对OPI问题的近线性时间量子算法。


<details>
  <summary>Details</summary>
Motivation: Jordan等人提出的DQI算法虽然能在多项式时间内解决OPI问题并优于经典算法，但其Dicke态制备需要二次时间，限制了算法效率。本文旨在改进DQI算法的时间复杂度。

Method: 提出多项DQI算法改进，特别是绕过二次时间的Dicke态制备步骤。在随机访问输入的前提下，构建了近线性时间的DQI算法。

Result: 成功实现了针对OPI问题的近线性时间DQI算法。同时，Khattar等人也独立使用不同技术构建了类似的近线性时间DQI算法。

Conclusion: 通过改进DQI算法的时间复杂度，使其在处理OPI问题时达到近线性时间，显著提升了量子算法在组合优化问题上的效率。

Abstract: Recently, Jordan et al. (Nature, 2025) introduced a novel quantum-algorithmic technique called Decoded Quantum Interferometry (DQI) for solving specific combinatorial optimization problems associated with classical codes. They presented a constraint-satisfaction problem called Optimal Polynomial Intersection (OPI) and showed that, for this problem, a DQI algorithm running in polynomial time can satisfy a larger fraction of constraints than any known polynomial-time classical algorithm.
  In this work, we propose several improvements to the DQI algorithm, including sidestepping the quadratic-time Dicke state preparation. Given random access to the input, we show how these improvements result in a nearly linear-time DQI algorithm for the OPI problem. Concurrently and independently with this work, Khattar et al. (arXiv:2510:10967) also construct a nearly linear-time DQI algorithm for OPI using slightly different techniques.

</details>


### [45] [Purcell enhanced electroluminescence of a unipolar light emitting quantum device at 10 micron](https://arxiv.org/abs/2601.15193)
*Marta Mastrangelo,Djamal Gacemi,Axel Evirgen,Salvatore Pes,Alexandre Larrue,Pascal Filloux,Isabelle Sagnes,Abdelmounaim Harouri,Angela Vasanelli,Carlo Sirtori*

Main category: quant-ph

TL;DR: 该论文展示了一种通过工程化超材料和微腔结构来增强中远红外自发辐射的方法，实现了比标准器件高100倍的收集功率和良好空间特性的准直光束发射。


<details>
  <summary>Details</summary>
Motivation: 中远红外波段缺乏高效的发光器件，因为自发辐射速率远低于非辐射能量弛豫过程，传统上只能依赖激光或非线性光学增益产生的受激辐射。自发辐射并非发射器的固有属性，可以通过调控光子环境来增强。

Method: 通过将纳米发射器阵列组成的超材料集成到与贴片天线耦合的微腔中，重塑发射偶极子周围的光子环境，利用Purcell效应增强自发辐射。

Result: 实现了中红外电致发光器件，发射出具有优异空间特性的准直光束，收集功率比标准器件提高了100倍。

Conclusion: 通过调控光子环境增强自发辐射，可以设计出接近热力学平衡条件下工作的高效光电器件，类似于可见光波段的LED，为中远红外发光器件提供了新途径。

Abstract: Efficient generation of radiation in the mid- and far- infrared relies primarily on lasers and coherent nonlinear optical phenomena driven by lasers. This wavelength range lacks of luminescent devices because the spontaneous emission rate becomes much longer than the nonradiative energy relaxation processes and therefore emitters have to count on stimulated emission produced by linear or non-linear optical gain. However, spontaneous emission is not a fundamental property of the emitter. By engineering metamaterials composed of arrays of nano-emitters into microcavities coupled to patch antennas, we have demonstrated mid-infrared electroluminescent devices emitting a collimated beam with excellent spatial properties and a factor 100 increase in the collected power, compared to standard devices. Our results illustrate that by reshaping the photonic environment around emitting dipoles, as in the Purcell effect, it is possible to enhance the spontaneous emission and conceive efficient optoelectronic light emitting devices that operate close to the thermodynamical equilibrium as LEDs in the visible range.

</details>


### [46] [Precision Enhancement in Transient Quantum Thermometry:Cold-Probe Bias and Its Removal](https://arxiv.org/abs/2601.15237)
*Debarupa Saha,Ujjwal Sen*

Main category: quant-ph

TL;DR: 量子温度计在马尔可夫动力学下存在温度偏差：只有初始温度低于待测浴温的探针才能获得超越稳态极限的精度提升，而非马尔可夫动力学可以消除这种偏差，让冷热探针都能达到相同的瞬态最大精度。


<details>
  <summary>Details</summary>
Motivation: 研究瞬态量子测温中探针的温度偏差问题，探索马尔可夫和非马尔可夫动力学对测温精度的影响差异。

Method: 分析量子比特温度计在不同动力学（马尔可夫vs非马尔可夫）下的演化，研究探针初始温度与浴温的关系对瞬态测温精度的影响。

Result: 在马尔可夫动力学下，只有初始温度低于浴温的探针才能实现超越稳态极限的精度提升；而在非马尔可夫动力学下，无论初始温度高于或低于浴温，探针都能达到相同的瞬态最大精度，且远高于稳态值。

Conclusion: 量子测温存在动力学依赖的温度偏差：马尔可夫动力学导致冷探针优势，而非马尔可夫动力学可以消除这种偏差，为优化量子测温提供了新视角。

Abstract: We unveil a temperature bias of the probe in transient quantum thermometry under Markovian dynamics. Specifically, for qubit thermometers evolving under Markovian dynamics, we show that enhanced precision beyond the steady state limit can be achieved if and only if the probe is initially colder than the thermal state corresponding to the bath temperature to be estimated. In contrast, this temperature bias can be lifted when the probe dynamics is non-Markovian. In the non-Markovian regime, both hot and cold probes can simultaneously attain the same transient maximum precision, well above the steady-state value.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning](https://arxiv.org/abs/2601.14263)
*Alex Echeverria,Sávio Salvarino Teles de Oliveira,Fernando Marques Federson*

Main category: cs.LG

TL;DR: 本文提出一个端到端自动化流程，从客服通话录音生成问答格式的指令微调数据集，用于大语言模型的领域适应。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在特定领域的适应需要高质量的指令微调数据集，但从未经整理的客服通话录音等非结构化数据生成此类数据集面临巨大挑战，因为数据嘈杂且无组织。

Method: 开发了端到端自动化流程：音频处理（说话人分离、降噪、自动转录）、文本处理（清洗、规范化、匿名化）、使用向量嵌入进行客户需求和客服响应的语义提取，以及通过语义搜索匹配形成最终问答对。

Result: 成功实现了完整流程，生成了专门用于指令微调的数据集。通过成功微调基于Llama 2 7B的LLM模型，验证了生成数据集的实际价值和可行性。

Conclusion: 提出的方法可行，能将客服通话的非结构化对话数据转化为训练大语言模型的宝贵资源，为客服领域问答任务创建更有效的AI系统开辟了新途径。代码已公开以促进可重复性和未来研究。

Abstract: The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&A). However, generating these datasets, particularly from unstructured sources such as call center audio recordings, poses a significant challenge due to the noisy and disorganized nature of the data. This paper presents a solution to this challenge by offering an end-to-end automated pipeline for generating Q&A instructional datasets from such recordings. The methodology developed comprises sequential steps of audio processing (including diarization, noise removal and automatic transcription), textual processing (cleaning, normalization, and anonymization), semantic extraction of customer demands and attendant responses using vector embeddings, and matching via semantic search to form the final Q&A pairs. As a result, the complete pipeline was successfully implemented, generating a dataset specifically formatted for Instruct Fine Tuning. The practical value and feasibility of the generated dataset were substantiated and functionally demonstrated through the successful fine-tuning of an LLM model (based on Llama 2 7B). The conclusion of the paper states that the proposed approach is viable for converting unstructured conversational data from call centers into valuable resources for training LLMs. This development has the potential to open up avenues for creating more effective AI systems for Q&A tasks in the customer service domain. The developed codes have been made publicly available to promote reproducibility and future research.

</details>


### [48] [GCG Attack On A Diffusion LLM](https://arxiv.org/abs/2601.14266)
*Ruben Neyroud,Sam Corley*

Main category: cs.LG

TL;DR: 对扩散语言模型LLaDA进行GCG风格对抗攻击的探索性研究，评估了多种攻击变体在有害提示上的效果


<details>
  <summary>Details</summary>
Motivation: 虽然大多数LLM是自回归的，但基于扩散的LLM最近成为替代生成方法。GCG攻击对自回归模型有效，但其在扩散语言模型上的适用性尚未充分探索

Method: 对开源扩散LLM LLaDA进行GCG风格对抗提示攻击，评估多种攻击变体（包括前缀扰动和后缀对抗生成），使用AdvBench数据集中的有害提示进行评估

Result: 研究提供了关于扩散语言模型鲁棒性和攻击面的初步见解，表明需要为这种设置开发替代的优化和评估策略

Conclusion: 扩散语言模型需要专门的对抗分析策略，本研究为理解其安全性和开发相应防御方法奠定了基础

Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.

</details>


### [49] [Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation](https://arxiv.org/abs/2601.14274)
*Anh-Tuan Mai,Cam-Van Thi Nguyen,Duc-Trong Le*

Main category: cs.LG

TL;DR: 提出DnR框架，通过显式分解模态为独特性、冗余性和协同性三个信息理论成分，并分别优化，提升多模态对话情感识别性能


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感识别方法难以平衡模态独有信息、跨模态冗余信息和协同信息。现有对比学习和增强方法在数据准备阶段容易模糊这些成分的边界，需要更精细的处理策略

Method: 提出两阶段DnR框架：1) Divide阶段：将每个模态显式分解为独特性、成对冗余性和协同性三个信息理论成分；2) Refine阶段：设计针对性目标函数增强各成分的信息量，同时保持其区分性。最终表示可即插即用地用于各种多模态管道

Result: 在IEMOCAP和MELD数据集上的广泛实验表明，DnR框架在多种MERC骨干网络上均取得一致性能提升，验证了显式分解、优化和重组多模态表示的有效性

Conclusion: 通过信息理论视角显式分解多模态信号为独特性、冗余性和协同性成分，并针对性优化，是提升对话情感识别性能的有效策略。DnR框架具有普适性和可扩展性

Abstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerge only when modalities are combined. In information-theoretic terms, these correspond to \emph{unique}, \emph{redundant}, and \emph{synergistic} contributions. An ideal representation should leverage all three, yet achieving such balance remains challenging. Recent advances in contrastive learning and augmentation-based methods have made progress, but they often overlook the role of data preparation in preserving these components. In particular, applying augmentations directly to raw inputs or fused embeddings can blur the boundaries between modality-unique and cross-modal signals. To address this challenge, we propose a two-phase framework \emph{\textbf{D}ivide and \textbf{R}efine} (\textbf{DnR}). In the \textbf{Divide} phase, each modality is explicitly decomposed into uniqueness, pairwise redundancy, and synergy. In the \textbf{Refine} phase, tailored objectives enhance the informativeness of these components while maintaining their distinct roles. The refined representations are plug-and-play compatible with diverse multimodal pipelines. Extensive experiments on IEMOCAP and MELD demonstrate consistent improvements across multiple MERC backbones. These results highlight the effectiveness of explicitly dividing, refining, and recombining multimodal representations as a principled strategy for advancing emotion recognition. Our implementation is available at https://github.com/mattam301/DnR-WACV2026

</details>


### [50] [Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version](https://arxiv.org/abs/2601.14275)
*Zewen Yang,Xiaobing Dai,Jiajun Cheng,Yulong Huang,Peng Shi*

Main category: cs.LG

TL;DR: 提出首个选择性在线学习框架EIGP，用于分布式高斯过程回归，通过选择函数筛选高质量模型，优先质量而非数量，提升合作学习效果。


<details>
  <summary>Details</summary>
Motivation: 在多智能体分布式学习中，盲目包含所有模型进行联合预测是不合理的，需要优先考虑模型质量而非数量，以提高合作学习效率。

Method: 提出分布式误差感知高斯过程(EIGP)框架，每个智能体评估邻居模型，使用选择函数筛选预测误差较小的高质量GP模型。包含贪心算法(gEIGP)加速预测和自适应算法(aEIGP)提升精度，结合误差感知量化项迭代和数据删除策略实现实时学习。

Result: 数值模拟验证了所提方法的有效性，展示了其优于现有分布式GP方法，在不同基准测试中表现优越。

Conclusion: 通过选择性在线学习框架EIGP，实现了分布式GP回归中质量优先于数量的合作学习，提高了预测效率和准确性，为多智能体系统提供了有效的合作学习方案。

Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.

</details>


### [51] [Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct](https://arxiv.org/abs/2601.14277)
*Uygar Kurt*

Main category: cs.LG

TL;DR: 对llama.cpp量化格式的统一实证研究，评估Llama-3.1-8B-Instruct模型在3-8位K-quant和传统格式下的性能，为实际部署提供选择指南


<details>
  <summary>Details</summary>
Motivation: 量化技术能降低大语言模型的部署门槛，但现有量化格式评估不一致，难以选择合适的方案。llama.cpp虽然能让大模型在普通硬件上运行，但缺乏统一的量化方案比较指南。

Method: 对Llama-3.1-8B-Instruct模型进行统一的实证研究，覆盖3-8位K-quant和传统量化格式。评估下游任务性能（推理、知识、指令遵循、真实性）、困惑度、CPU吞吐量（预填充/解码）、模型大小、压缩率和量化时间。

Result: 提供了llama.cpp量化方案的全面性能评估，量化了不同位宽格式在精度损失、推理速度、内存占用等方面的权衡关系，为不同应用场景提供具体选择建议。

Conclusion: 本工作为选择llama.cpp量化方案提供了实用的决策指南，帮助用户根据具体使用场景和资源预算做出明智的、上下文感知的选择。

Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.

</details>


### [52] [On the Limits of Learned Importance Scoring for KV Cache Compression](https://arxiv.org/abs/2601.14279)
*Brady Steele*

Main category: cs.LG

TL;DR: 研究通过推测重要性预测（SIP）进行KV缓存压缩学习，发现1.7M参数的复杂模型未能超越简单基线方法，包括随机选择和位置启发式方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索通过学习方法来压缩KV缓存，以提高大型语言模型的推理效率。传统方法依赖手动设计的启发式规则，研究者希望验证通过学习KV表示来预测token重要性的可行性。

Method: 采用Speculative Importance Prediction（SIP）方法，这是一个1.7M参数的非查询感知评分器，仅从KV表示预测token重要性。方法包含多视野前瞻和交叉注意力等复杂架构。实验在5个随机种子、4个保留水平和3个任务上进行评估。

Result: 关键发现：1）基于位置的启发式方法（保留前4个+最后N个token）匹配或优于学习方法；2）预填充注意力提供与复杂学习评分器等效的信号；3）KV表示中除位置和预填充注意力之外的边际信息对重要性预测有限。SIP在所有评估中未能超越简单基线，包括随机选择。

Conclusion: KV表示中用于重要性预测的信息主要限于位置和预填充注意力，复杂学习方法未能提供额外价值。研究者假设未来查询与生成轨迹之间的循环依赖关系导致了这一困难，表明当前KV缓存压缩可能更适合基于简单启发式的方法。

Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.

</details>


### [53] [Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design](https://arxiv.org/abs/2601.14283)
*Kangyu Zheng,Kai Zhang,Jiale Tan,Xuehan Chen,Yingzhou Lu,Zaixi Zhang,Lichao Sun,Marinka Zitnik,Tianfan Fu,Zhiding Liang*

Main category: cs.LG

TL;DR: 该研究建立了首个跨算法类别的SBDD基准测试，评估了15种不同算法基础的模型，发现3D模型在结合亲和力上表现最佳但化学有效性不足，1D模型化学指标可靠但结合力有限，2D模型则提供平衡性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于结构的药物设计领域主要有搜索算法、深度生成模型和强化学习三类算法，但现有研究多局限于同类算法比较，缺乏跨算法类别的系统性评估。为填补这一空白，本研究建立了一个基准测试来全面评估不同算法基础模型的性能。

Method: 建立了一个基准测试框架，评估了15种不同算法基础的模型，通过分析生成分子的药物特性、与指定靶蛋白的对接亲和力和构象来比较性能。特别强调了将对接函数作为黑盒oracle，将1D/2D配体中心方法应用于SBDD的可能性。

Result: 评估揭示了不同模型类别的明显模式：3D结构模型在结合亲和力方面表现优异，但在化学有效性和构象质量方面存在不一致性；1D模型在标准分子指标上表现可靠，但很少达到最佳结合亲和力；2D模型提供平衡性能，保持高化学有效性同时获得中等结合分数。

Conclusion: 研究为未来SBDD模型设计提供了具体建议，强调需要结合不同方法的优势并解决其局限性。特别指出1D/2D配体中心方法通过将对接函数作为黑盒oracle可以应用于SBDD，这一途径常被忽视。所有基准测试代码已开源。

Abstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark

</details>


### [54] [A Comparison of Polynomial-Based Tree Clustering Methods](https://arxiv.org/abs/2601.14285)
*Pengyu Liu,Mariel Vázquez,Nataša Jonoska*

Main category: cs.LG

TL;DR: 比较基于树多项式的不同距离度量在树聚类中的性能，发现基于条目级归一化距离的方法具有最高聚类准确率


<details>
  <summary>Details</summary>
Motivation: 生命科学中树结构数据日益增多（如系统发育、RNA二级结构），需要新的树结构数据分析方法。树多项式提供了一种计算高效、可解释且全面的树结构编码方式，但需要评估不同距离度量在树聚类中的性能。

Method: 1. 使用树区分多项式编码树结构；2. 比较不同距离度量（包括Canberra距离）在树聚类方法中的性能；3. 实现两种基本的自编码器模型用于树聚类

Result: 基于条目级归一化距离的方法在所有比较方法中具有最高的聚类准确率

Conclusion: 树多项式结合适当的距离度量（特别是条目级归一化距离）能够有效用于树结构数据的聚类分析，为生命科学中的树结构数据分析提供了实用工具

Abstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.

</details>


### [55] [Chain-of-Memory: Lightweight Memory Construction with Dynamic Evolution for LLM Agents](https://arxiv.org/abs/2601.14287)
*Xiucheng Xu,Bingbing Xu,Xueyun Tian,Zihe Huang,Rongxin Chen,Yunfan Li,Huawei Shen*

Main category: cs.LG

TL;DR: CoM框架提出轻量级内存构建与复杂利用的新范式，通过链式记忆机制组织检索片段为连贯推理路径，显著提升性能同时大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有外部内存系统存在两个根本限制：复杂的内存构建成本高但性能提升有限，简单的上下文拼接无法弥合检索召回与推理准确性之间的差距。

Method: 提出CoM（Chain-of-Memory）框架，采用轻量级构建与复杂利用相结合的新范式，引入链式记忆机制，通过动态演化将检索片段组织成连贯推理路径，并使用自适应截断来修剪无关噪声。

Result: 在LongMemEval和LoCoMo基准测试中，CoM比强基线准确率提升7.5%-10.4%，同时将计算开销大幅降低至复杂内存架构的约2.7%令牌消耗和6.0%延迟。

Conclusion: CoM通过轻量级构建与复杂利用的新范式，有效解决了现有内存系统的局限性，在保持高性能的同时显著降低了计算成本，为LLM代理的外部内存系统提供了更优的解决方案。

Abstract: External memory systems are pivotal for enabling Large Language Model (LLM) agents to maintain persistent knowledge and perform long-horizon decision-making. Existing paradigms typically follow a two-stage process: computationally expensive memory construction (e.g., structuring data into graphs) followed by naive retrieval-augmented generation. However, our empirical analysis reveals two fundamental limitations: complex construction incurs high costs with marginal performance gains, and simple context concatenation fails to bridge the gap between retrieval recall and reasoning accuracy. To address these challenges, we propose CoM (Chain-of-Memory), a novel framework that advocates for a paradigm shift toward lightweight construction paired with sophisticated utilization. CoM introduces a Chain-of-Memory mechanism that organizes retrieved fragments into coherent inference paths through dynamic evolution, utilizing adaptive truncation to prune irrelevant noise. Extensive experiments on the LongMemEval and LoCoMo benchmarks demonstrate that CoM outperforms strong baselines with accuracy gains of 7.5%-10.4%, while drastically reducing computational overhead to approximately 2.7% of token consumption and 6.0% of latency compared to complex memory architectures.

</details>


### [56] [Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity](https://arxiv.org/abs/2601.14300)
*Jun Liu,Leo Yu Zhang,Fengpeng Li,Isao Echizen,Jiantao Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种新的硬标签黑盒攻击框架，通过零查询频域初始化和模式驱动优化策略，在仅能观察到top-1预测标签的受限设置下，实现了比现有方法更高的攻击成功率和查询效率。


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒设置（仅能观察到top-1预测标签）是理解模型行为的重要反馈模型，但面临核心挑战：能否从这种离散响应中恢复有意义的梯度信息。现有硬标签攻击方法缺乏统一的理论理解。

Method: 提出统一理论视角，将现有符号翻转硬标签攻击解释为隐式近似真实损失梯度的符号。基于此提出新攻击框架：结合零查询频域初始化和模式驱动优化策略，前者提高与真实梯度符号的余弦相似度，后者降低查询复杂度。

Result: 在CIFAR-10、ImageNet、ObjectNet等数据集上，方法在攻击成功率和查询效率上均超越现有SOTA硬标签攻击，特别是在低查询机制下。还能有效泛化到损坏数据、生物医学数据集和密集预测任务，并能完全规避Blacklight防御（0%检测率）。

Conclusion: 该工作为硬标签黑盒攻击提供了统一的理论理解，提出的新框架在理论和实验上都表现出优越性能，能够有效应对各种实际场景和防御机制。

Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.

</details>


### [57] [Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2601.14327)
*YuanLab. ai,Shawn Wu,Jiangang Luo,Tong Yu,Darcy Chen,Sean Wang,Xudong Zhao,Louie Li,Claire Wang,Hunter He,Carol Wang,Allen Wang*

Main category: cs.LG

TL;DR: LAEP算法在MoE LLM预训练阶段通过层自适应专家剪枝和重组，显著提升训练效率并减少模型参数，同时保持优异性能


<details>
  <summary>Details</summary>
Motivation: MoE大语言模型虽然能减少活跃参数并提升精度，但其预训练阶段存在专家利用率不足和训练效率低下的计算瓶颈问题

Method: 提出层自适应专家剪枝算法，在预训练阶段根据token分布统计选择性剪枝未充分利用的专家，并跨计算设备重组专家

Result: 在从头预训练1010B基础模型时，训练效率提升48.3%，参数减少33.3%，同时在多个领域保持优异性能

Conclusion: LAEP算法能有效解决MoE LLM预训练的计算瓶颈问题，在显著提升训练效率的同时保持模型性能，为大规模MoE模型训练提供了实用解决方案

Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.

</details>


### [58] [Hierarchical Contextual Uplift Bandits for Catalog Personalization](https://arxiv.org/abs/2601.14333)
*Anupam Agrawal,Rajesh Mohanty,Shamik Bhattacharjee,Abhimanyu Mittal*

Main category: cs.LG

TL;DR: 提出分层上下文提升赌博机框架，通过动态调整上下文粒度解决幻想体育动态环境中的个性化推荐问题，显著提升收入和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 传统上下文赌博机算法在幻想体育等动态环境中表现不佳，用户行为快速变化，奖励分布因外部影响剧烈波动，需要频繁重新训练。需要解决冷启动问题和有效策略迁移。

Method: 提出分层上下文提升赌博机框架：1) 动态调整上下文粒度，从系统级洞察到用户特定上下文；2) 利用上下文相似性促进有效策略迁移；3) 集成提升建模原则。

Result: 在Dream11幻想体育平台的大规模A/B测试中，方法显著提升推荐质量：实现0.4%收入提升，同时改善用户满意度指标。2025年5月部署到生产环境后，进一步观察到0.5%收入提升。

Conclusion: 分层上下文提升赌博机框架有效解决了动态环境中的个性化推荐挑战，通过动态上下文粒度调整和提升建模集成，显著提升了推荐系统的性能和商业价值。

Abstract: Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.

</details>


### [59] [Log anomaly detection via Meta Learning and Prototypical Networks for Cross domain generalization](https://arxiv.org/abs/2601.14336)
*Krishna Sharma,Vivek Yelleti*

Main category: cs.LG

TL;DR: 提出基于元学习的日志异常检测框架，通过动态漂移标注、BERT语义嵌入和MAML/原型网络实现跨域适应，使用SMOTE处理类别不平衡，在跨域场景下获得最高平均F1分数。


<details>
  <summary>Details</summary>
Motivation: 日志异常检测面临类别不平衡和跨域适应难题。传统模型由于数据漂移和目标域缺乏标注异常而难以泛化，需要解决从源域到目标域的知识迁移问题。

Method: 1) 使用Drain3日志解析和基于动态漂移的标注技术进行数据准备；2) 获取BERT语义嵌入并进行特征选择降维；3) 训练MAML和原型网络模型实现快速适应；4) 使用SMOTE处理数据不平衡；5) 采用留一源方法评估。

Result: 提出的元学习驱动方法在跨域设置下获得了最高的平均F1分数，验证了该方法在跨域日志异常检测中的有效性。

Conclusion: 基于元学习的框架成功解决了日志异常检测中的跨域适应和类别不平衡问题，为系统可靠性提供了有效的解决方案。

Abstract: Log anomaly detection is essential for system reliability, but it is extremely challenging to do considering it involves class imbalance. Additionally, the models trained in one domain are not applicable to other domains, necessitating the need for cross-domain adaptation (such as HDFS and Linux). Traditional detection models often fail to generalize due to significant data drift and the inherent absence of labeled anomalies in new target domains. To handle the above challenges, we proposed a new end-to-end framework based on a meta-learning approach. Our methodology first gets the data ready by combining a Drain3 log parsing mechanism with a dynamic drift-based labeling technique that uses semantic and fuzzy matching to move existing anomaly knowledge from one source to another. BERT-based semantic embeddings are obtained, and the feature selection is invoked to reduce the dimensionality. Later, Model Agnostic Meta-Learning (MAML) and Prototypical Networks models are trained to adapt quickly and effectively. The SMOTE oversampling method is employed to handle imbalances in the data. All the results are obtained by employing the leave-one-out source method, and the corresponding mean F1 scores are reported. Our empirical findings validate that the proposed meta-learning-driven approach yielded the highest mean F1 score and proved to be effective for cross-domain settings.

</details>


### [60] [DiSPA: Differential Substructure-Pathway Attention for Drug Response Prediction](https://arxiv.org/abs/2601.14346)
*Yewon Han,Sunghyun Kim,Eunyi Jeong,Sungkyung Lee,Seokwoo Yun,Sangsoo Lim*

Main category: cs.LG

TL;DR: DiSPA是一个通过双向条件化化学亚结构与通路级基因表达来解耦结构驱动和上下文驱动药物反应机制的表征学习框架，在GDSC基准测试中实现了最先进的性能，并具有零样本迁移到空间转录组学的能力。


<details>
  <summary>Details</summary>
Motivation: 精准医学中药物反应的准确预测需要能够捕捉特定化学亚结构与细胞通路状态相互作用的模型。现有深度学习方法通常独立处理化学和转录组学模态或在后期才结合它们，限制了模拟药物作用的细粒度、上下文依赖机制的能力。此外，标准注意力机制对高维生物网络中的噪声和稀疏性敏感，阻碍了泛化性和可解释性。

Method: DiSPA通过化学亚结构与通路级基因表达之间的双向条件化，明确解耦结构驱动和上下文驱动的药物反应机制。引入差分交叉注意力模块，抑制虚假的通路-亚结构关联，同时放大上下文相关的相互作用。

Result: 在GDSC基准测试的多个评估设置中，DiSPA实现了最先进的性能，特别是在评估未见药物-细胞组合泛化性的不相交集设置中表现出显著改进。学习到的注意力模式恢复了已知的药效团，区分了结构驱动和上下文依赖的化合物，并在生物通路中表现出连贯的组织结构。此外，仅使用批量RNA-seq数据训练的DiSPA能够零样本迁移到空间转录组学，无需重新训练即可揭示区域特异性药物敏感性模式。

Conclusion: DiSPA作为一个稳健且可解释的整合药物基因组学建模框架，能够超越事后解释，对药物反应机制进行原则性分析，为精准医学中的药物反应预测提供了新的方法。

Abstract: Accurate prediction of drug response in precision medicine requires models that capture how specific chemical substructures interact with cellular pathway states. However, most existing deep learning approaches treat chemical and transcriptomic modalities independently or combine them only at late stages, limiting their ability to model fine-grained, context-dependent mechanisms of drug action. In addition, standard attention mechanisms are often sensitive to noise and sparsity in high-dimensional biological networks, hindering both generalization and interpretability. We present DiSPA, a representation learning framework that explicitly disentangles structure-driven and context-driven mechanisms of drug response through bidirectional conditioning between chemical substructures and pathway-level gene expression. DiSPA introduces a differential cross-attention module that suppresses spurious pathway-substructure associations while amplifying contextually relevant interactions. Across multiple evaluation settings on the GDSC benchmark, DiSPA achieves state-of-the-art performance, with particularly strong improvements in the disjoint-set setting, which assesses generalization to unseen drug-cell combinations. Beyond predictive accuracy, DiSPA yields mechanistically informative representations: learned attention patterns recover known pharmacophores, distinguish structure-driven from context-dependent compounds, and exhibit coherent organization across biological pathways. Furthermore, we demonstrate that DiSPA trained solely on bulk RNA-seq data enables zero-shot transfer to spatial transcriptomics, revealing region-specific drug sensitivity patterns without retraining. Together, these results establish DiSPA as a robust and interpretable framework for integrative pharmacogenomic modeling, enabling principled analysis of drug response mechanisms beyond post hoc interpretation.

</details>


### [61] [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
*Yongchao Huang*

Main category: cs.LG

TL;DR: VJEPA是JEPA的概率化扩展，通过变分目标学习未来潜在状态的预测分布，统一了表示学习与PSR/贝叶斯滤波，无需自回归观测似然，为高维噪声环境中的不确定性感知规划提供基础框架。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA使用确定性回归目标，掩盖了概率语义，限制了其在随机控制中的应用。需要一种概率化扩展来支持不确定性估计和鲁棒规划。

Method: 提出Variational JEPA (VJEPA)，通过变分目标学习未来潜在状态的预测分布；进一步提出Bayesian JEPA (BJEPA)，将预测信念分解为学习到的动态专家和模块化先验专家，通过专家乘积实现零样本任务迁移和约束满足。

Result: 理论证明VJEPA表示可作为最优控制的充分信息状态，无需像素重建，并提供避免坍塌的正式保证。实验显示VJEPA/BJEPA能成功过滤高方差干扰，而生成基线会坍塌。

Conclusion: VJEPA为高维噪声环境中的可扩展、鲁棒、不确定性感知规划提供了基础框架，支持原则性不确定性估计，同时保持对观测的似然无关性。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.

</details>


### [62] [Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation](https://arxiv.org/abs/2601.14473)
*Danny Butvinik,Nana Boateng,Achi Hackmon*

Main category: cs.LG

TL;DR: 提出一种在线自适应核密度估计方法，将风险评分流转换为审查队列，无需标签即可满足容量约束并减少阈值抖动


<details>
  <summary>Details</summary>
Motivation: 传统方法如top-K或手动调整阈值难以在动态评分流中稳定满足容量约束，需要一种标签无关、实时适应且能减少阈值抖动的队列分配方法

Method: 在线拟合自适应核密度估计，将密度转换为尾部质量曲线以满足容量约束，并通过检测跨带宽的持久密度谷值来"固定"切割点，支持多队列路由和实时滑动窗口或指数遗忘

Result: 在合成、漂移、多模态数据流上，该方法实现了竞争性的容量遵守能力，同时显著减少了阈值抖动

Conclusion: 该方法提供了一种标签无关、实时适应、内存效率高的解决方案，能够稳定地将风险评分流转换为审查队列，满足容量约束并减少阈值波动

Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity

</details>


### [63] [GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling](https://arxiv.org/abs/2601.14476)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.LG

TL;DR: 该研究揭示了一个反直觉发现：在基于磁性隧道结的概率计算中，器件变异性不仅能降低性能，还能通过时序变异性增强算法表现。研究开发了GPU加速的开源模拟退火框架，在MAX-CUT问题上实现了两个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为器件变异性会降低概率计算的性能，但本研究旨在探索变异性对算法性能的实际影响，特别是时序变异性可能带来的意外好处。

Method: 开发了基于CUDA的GPU加速开源模拟退火框架，模拟三种关键器件变异性因素：时序、强度和偏移，以反映真实器件行为。在MAX-CUT基准测试上验证，问题规模从800到20,000个节点。

Result: 发现器件变异性（特别是时序变异性）不仅能降低性能，还能增强算法表现。GPU实现相比CPU实现了两个数量级的加速，为大规模优化问题提供了高效解决方案。

Conclusion: 器件变异性在概率计算中具有双重作用，不应简单视为负面因素。开发的GPU加速框架为概率计算研究提供了可扩展工具，有望推动优化算法在多个领域的应用。

Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -- timing, intensity, and offset -- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.

</details>


### [64] [Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence](https://arxiv.org/abs/2601.14487)
*Mrigank Dhingra,Omer San*

Main category: cs.LG

TL;DR: MSR-HINE：一种用于混沌动力系统长期预测的分层隐式预测器，通过多尺度潜在先验和多速率循环模块减少误差累积，显著提升预测精度和可预测性范围。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统的长期自回归预测面临误差快速放大和分布偏移的挑战：微小的一步不准确性会累积成物理上不一致的滚动预测和大尺度统计特性的崩溃。

Method: 提出MSR-HINE分层隐式预测器，结合多尺度潜在先验和多速率循环模块。在每个时间步，粗到细的循环状态生成潜在先验，隐式一步预测器通过多尺度潜在注入细化状态，门控融合与后验潜在变量确保尺度一致性更新，轻量级隐藏状态校正进一步对齐循环记忆与融合潜在变量。

Result: 在两个基准测试中表现优异：在Kuramoto-Sivashinsky系统中，将端到端RMSE降低62.8%（H=400），ACC从-0.155提升到0.828；在Lorenz-96系统中，RMSE降低27.0%（H=100），ACC从0.144提升到0.545。两个系统的ACC≥0.5可预测性范围分别从241步扩展到400步和从58步扩展到100步。

Conclusion: MSR-HINE通过维持慢流形上的长期上下文同时保留快尺度变异性，有效缓解混沌滚动预测中的误差累积问题，显著提升了混沌动力系统的长期预测能力。

Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.

</details>


### [65] [Learning PDE Solvers with Physics and Data: A Unifying View of Physics-Informed Neural Networks and Neural Operators](https://arxiv.org/abs/2601.14517)
*Yilong Dai,Shengyu Chen,Ziyi Wang,Xiaowei Jia,Yiqun Xie,Vipin Kumar,Runlong Yu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一框架来分析物理信息神经网络(PINNs)和神经算子(NOs)等学习型PDE求解方法，从三个维度组织现有方法：学习内容、物理结构集成方式、计算负载分摊机制。


<details>
  <summary>Details</summary>
Motivation: 当前科学建模中PDE求解器越来越依赖学习组件，但缺乏统一视角来理解各种物理感知数据驱动方法之间的关系、局限性和在科学工作流中的适当角色。

Method: 提出一个统一设计空间，从三个基本维度组织现有方法：1) 学习内容(模型、解、算子等)；2) 物理结构如何集成到学习过程中；3) 计算负载如何在问题实例间分摊。

Result: 通过这个统一视角，许多挑战可以被理解为学习PDE的结构特性后果，有助于理解PINNs和NOs等方法的本质差异和适用场景。

Conclusion: 该统一框架有助于开发可靠的学习型PDE求解器，促进物理与数据的融合，为领域提供系统化的分析工具。

Abstract: Partial differential equations (PDEs) are central to scientific modeling. Modern workflows increasingly rely on learning-based components to support model reuse, inference, and integration across large computational processes. Despite the emergence of various physics-aware data-driven approaches, the field still lacks a unified perspective to uncover their relationships, limitations, and appropriate roles in scientific workflows. To this end, we propose a unifying perspective to place two dominant paradigms: Physics-Informed Neural Networks (PINNs) and Neural Operators (NOs), within a shared design space. We organize existing methods from three fundamental dimensions: what is learned, how physical structures are integrated into the learning process, and how the computational load is amortized across problem instances. In this way, many challenges can be best understood as consequences of these structural properties of learning PDEs. By analyzing advances through this unifying view, our survey aims to facilitate the development of reliable learning-based PDE solvers and catalyze a synthesis of physics and data.

</details>


### [66] [How Worst-Case Are Adversarial Attacks? Linking Adversarial and Statistical Robustness](https://arxiv.org/abs/2601.14519)
*Giulio Rossolini*

Main category: cs.LG

TL;DR: 本文质疑对抗性攻击作为模型鲁棒性评估指标的有效性，提出了一种概率框架来量化方向性偏置扰动下的噪声风险，通过实验揭示对抗性攻击何时能有效反映噪声风险、何时会失效。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击被广泛用于评估模型鲁棒性，但其作为随机扰动鲁棒性代理指标的有效性一直存在争议。作者质疑对抗性扰动是否真的能代表相同幅度随机噪声下的鲁棒性，还是仅仅反映了非典型的极端情况。

Method: 引入了一个概率度量框架，通过浓度因子κ参数化方向性偏置扰动分布，在从各向同性噪声到对抗性方向之间进行插值。提出了一种在统计上更接近均匀噪声的对抗攻击策略，并在ImageNet和CIFAR-10上系统性地评估了广泛使用的攻击方法。

Result: 实验系统地评估了广泛使用的对抗攻击方法，揭示了对抗性攻击成功何时能有效反映噪声风险、何时会失效。这为安全导向的评估提供了指导，明确了对抗性攻击作为鲁棒性代理指标的适用范围和局限性。

Conclusion: 对抗性攻击作为模型鲁棒性评估指标的有效性是有条件的。作者提出的框架能够量化方向性偏置扰动下的风险，帮助理解对抗性扰动何时能作为噪声风险的有意义估计，从而为安全评估提供更可靠的指导。

Abstract: Adversarial attacks are widely used to evaluate model robustness, yet their validity as proxies for robustness to random perturbations remains debated. We ask whether an adversarial perturbation provides a representative estimate of robustness under random noise of the same magnitude, or instead reflects an atypical worst-case event. To this end, we introduce a probabilistic metric that quantifies noisy risk with respect to directionally biased perturbation distributions, parameterized by a concentration factor $κ$ that interpolates between isotropic noise and adversarial direction. Using this framework, we study the limits of adversarial perturbations as estimators of noisy risk by proposing an attack strategy designed to operate in regimes statistically closer to uniform noise. Experiments on ImageNet and CIFAR-10 systematically benchmark widely used attacks, highlighting when adversarial success meaningfully reflects noisy risk and when it fails, thereby informing their use in safety-oriented evaluation.

</details>


### [67] [On the Runway Cascade of Transformers for Language Modeling](https://arxiv.org/abs/2601.14522)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 本文提出了一种"跑道感知重连"机制，通过将间接信息传播路径（跑道）的上下文直接整合到注意力模式中，解决因果Transformer中直接路径和间接路径信息传播不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 因果Transformer中，因果掩码创建的计算图通过直接路径注意力和由中间令牌形成的间接路径传播信息。最近研究发现，因果Transformer的某些故障模式可能源于这两种信息传播模式之间的不匹配，导致冗余和无关信息在令牌表示中传播，尽管注意力模式已经充分学习。

Method: 提出跑道感知重连机制，根据每个令牌的跑道景观（间接路径）摘要重新连接注意力模式。该方法将跑道上下文直接整合到每个令牌的直接路径注意力中，使模型能够感知累积的表征影响，实现更平衡的信息传播。该方法不引入额外参数，可无缝集成到标准注意力机制中。

Result: 经验结果表明，重连Transformer在通用语言建模方面持续改进，同时在信息检索和外推能力方面明显优于标准Transformer。

Conclusion: 跑道感知重连机制通过更明确地整合间接信息传播路径的上下文，有效解决了因果Transformer中信息传播不匹配的问题，提高了模型性能，特别是在信息检索和外推任务上表现更优。

Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.

</details>


### [68] [Search over Self-Edit Strategies for LLM Adaptation](https://arxiv.org/abs/2601.14532)
*Alistair Cheong,Haolin Cong,Tyler Yang,Dustin Miao*

Main category: cs.LG

TL;DR: LLM能否利用任务反馈自主决定权重更新策略？研究在SEAL框架中让模型生成自编辑模板，探索了有无历史模板存档的两种变体，发现存档变体表现接近但未超越最优人工基线。


<details>
  <summary>Details</summary>
Motivation: 现有LLM开放搜索系统通常冻结基础模型，可能限制长期进展。虽然已有研究探索在测试时更新提议模型，但更新策略仍需人工指定。因此，本研究旨在探索LLM能否利用任务反馈自主决定权重更新方式。

Method: 在SEAL框架基础上，放宽固定人工模板限制，允许模型生成自编辑模板，从而让模型能控制训练数据和关键超参数。研究了两种变体：无存档版本和有存档版本（使用轻量级历史模板存档）。在Qwen3-8B模型和SQuAD数据集上进行实验。

Result: 无存档变体表现与较弱的"Implications"基线相当，而有存档变体优于"Implications"基线，接近但未超越最强人工设计的"Rewrite"基线。分析发现朴素存档虽能提供短期鲁棒性，但也会加速同质化。

Conclusion: LLM能够利用任务反馈自主决定权重更新策略，但需要显式的新颖性压力才能持续超越精心优化的人工策略。朴素存档可能加速同质化，未来需要更好的探索机制。

Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .

</details>


### [69] [engGNN: A Dual-Graph Neural Network for Omics-Based Disease Classification and Feature Selection](https://arxiv.org/abs/2601.14536)
*Tiantian Yang,Yuxuan Wang,Zhenwei Zhou,Ching-Ti Liu*

Main category: cs.LG

TL;DR: engGNN提出了一种双图神经网络框架，结合外部生物网络和数据驱动生成图，用于高维组学数据的疾病分类和生物标志物发现。


<details>
  <summary>Details</summary>
Motivation: 组学数据（转录组、蛋白质组、代谢组等）具有高维度、小样本和复杂生物网络的特点，现有方法通常只使用外部知识图谱或数据驱动生成的图谱，无法充分利用互补信息。

Method: engGNN采用双图框架：1）从已知生物网络数据库构建生物学信息无向特征图；2）从树集成模型构建数据驱动的有向特征图。通过联合利用这两种图结构生成更全面的嵌入表示。

Result: 在模拟实验和真实基因表达数据应用中，engGNN持续优于现有最先进方法，不仅提高了预测性能，还提供了可解释的特征重要性评分，支持通路富集分析等生物学发现。

Conclusion: engGNN是一个稳健、灵活且可解释的框架，适用于高维组学数据的疾病分类和生物标志物发现，能够整合外部生物知识和数据驱动信息。

Abstract: Omics data, such as transcriptomics, proteomics, and metabolomics, provide critical insights into disease mechanisms and clinical outcomes. However, their high dimensionality, small sample sizes, and intricate biological networks pose major challenges for reliable prediction and meaningful interpretation. Graph Neural Networks (GNNs) offer a promising way to integrate prior knowledge by encoding feature relationships as graphs. Yet, existing methods typically rely solely on either an externally curated feature graph or a data-driven generated one, which limits their ability to capture complementary information. To address this, we propose the external and generated Graph Neural Network (engGNN), a dual-graph framework that jointly leverages both external known biological networks and data-driven generated graphs. Specifically, engGNN constructs a biologically informed undirected feature graph from established network databases and complements it with a directed feature graph derived from tree-ensemble models. This dual-graph design produces more comprehensive embeddings, thereby improving predictive performance and interpretability. Through extensive simulations and real-world applications to gene expression data, engGNN consistently outperforms state-of-the-art baselines. Beyond classification, engGNN provides interpretable feature importance scores that facilitate biologically meaningful discoveries, such as pathway enrichment analysis. Taken together, these results highlight engGNN as a robust, flexible, and interpretable framework for disease classification and biomarker discovery in high-dimensional omics contexts.

</details>


### [70] [Report for NSF Workshop on AI for Electronic Design Automation](https://arxiv.org/abs/2601.14541)
*Deming Chen,Vijay Ganesh,Weikai Li,Yingyan,Lin,Yong Liu,Subhasish Mitra,David Z. Pan,Ruchir Puri,Jason Cong,Yizhou Sun*

Main category: cs.LG

TL;DR: NSF AI for EDA研讨会报告总结了AI在电子设计自动化中的应用前景与挑战，涵盖物理设计、高层综合、优化工具和测试验证四大主题，并提出促进AI/EDA合作、投资基础研究、建设数据基础设施等建议。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，特别是大语言模型、图神经网络等技术的成熟，AI在电子设计自动化领域具有巨大应用潜力。然而，AI与EDA的交叉研究仍面临挑战，需要学术界和工业界的深入合作。NSF举办此研讨会旨在探索AI如何加速EDA流程、缩短设计周期，并制定相关研究路线图。

Method: 通过举办NSF研讨会，汇集机器学习与EDA领域的专家，围绕四个主题展开讨论：1) AI在物理综合与制造设计中的应用；2) AI在高层与逻辑级综合中的应用；3) AI优化与设计工具箱；4) AI在测试与验证中的应用。基于讨论形成具体建议。

Result: 研讨会识别了AI在EDA各环节的具体应用场景，包括LLM辅助验证工具、ML增强SAT求解、GNN在物理设计中的应用等。提出了五项关键建议：促进AI/EDA合作、投资基础AI研究、建设健壮数据基础设施、发展可扩展计算基础设施、投资人才培养以民主化硬件设计。

Conclusion: AI技术有望革命性地改变电子设计自动化流程，但需要系统性投资和跨学科合作。通过实施研讨会提出的建议，可以加速AI在EDA中的应用，实现下一代硬件系统的创新设计，最终缩短设计周期并降低硬件开发门槛。

Abstract: This report distills the discussions and recommendations from the NSF Workshop on AI for Electronic Design Automation (EDA), held on December 10, 2024 in Vancouver alongside NeurIPS 2024. Bringing together experts across machine learning and EDA, the workshop examined how AI-spanning large language models (LLMs), graph neural networks (GNNs), reinforcement learning (RL), neurosymbolic methods, etc.-can facilitate EDA and shorten design turnaround. The workshop includes four themes: (1) AI for physical synthesis and design for manufacturing (DFM), discussing challenges in physical manufacturing process and potential AI applications; (2) AI for high-level and logic-level synthesis (HLS/LLS), covering pragma insertion, program transformation, RTL code generation, etc.; (3) AI toolbox for optimization and design, discussing frontier AI developments that could potentially be applied to EDA tasks; and (4) AI for test and verification, including LLM-assisted verification tools, ML-augmented SAT solving, security/reliability challenges, etc. The report recommends NSF to foster AI/EDA collaboration, invest in foundational AI for EDA, develop robust data infrastructures, promote scalable compute infrastructure, and invest in workforce development to democratize hardware design and enable next-generation hardware systems. The workshop information can be found on the website https://ai4eda-workshop.github.io/.

</details>


### [71] [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549)
*Nilesh Prasad Pandey,Jangseon Park,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: 提出QMC方法，通过异常值感知量化和异构内存架构，在边缘设备上高效部署小型语言模型，显著降低内存、能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 边缘设备部署小型语言模型面临内存、延迟和能耗限制。现有量化方法受设备噪声影响，传统内存层次结构效率有限，需要针对LLM推理的混合内存组织方案。

Method: 提出QMC方法：1) 识别SLM中的正常值和异常值权重；2) 将正常值存储在紧凑的多级ReRAM中；3) 将关键异常值保存在高精度片上MRAM中；4) 无需重新训练的量化和内存协同设计。

Result: 在语言建模和推理基准测试中，QMC优于或匹配最先进的量化方法。相比FP16，内存使用减少6.3-7.3倍，外部数据传输减少7.6倍，能耗降低11.7倍，延迟降低12.5倍。

Conclusion: QMC是一种可扩展、可部署的协同设计方法，为高效的设备端推理提供了解决方案，在最新边缘AI平台上表现出色。

Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.

</details>


### [72] [Constructing Multi-label Hierarchical Classification Models for MITRE ATT&CK Text Tagging](https://arxiv.org/abs/2601.14556)
*Andrew Crossman,Jonah Dodd,Viralam Ramamurthy Chaithanya Kumar,Riyaz Mohammed,Andrew R. Plummer,Chandra Sekharudu,Deepak Warrier,Mohammad Yekrangian*

Main category: cs.LG

TL;DR: 提出分层任务空间框架，用于自动化MITRE ATT&CK文本标注，并构建了基于经典机器学习的多标签分层分类模型，在战术和技术层面分别达到94%和82%的准确率，优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: MITRE ATT&CK作为网络安全知识库，目前标注过程主要依赖人工，效率低下。需要自动化方法来提高网络安全情报报告、漏洞描述和威胁场景的标注效率。

Method: 提出分层的"任务空间"框架来组织自动化标注任务，采用多标签分层分类模型，仅使用经典机器学习方法（而非LLMs、RAG或复杂分层方法），在通用网络威胁情报文本上进行实验。

Result: 模型在战术层面准确率达到约94%，技术层面约82%，超越现有最佳方法。GPT-4o在战术层面的准确率仅为60%左右，显著低于该方法。模型已开源并扩展到金融应用威胁场景。

Conclusion: 提出的分层任务空间框架和基于经典机器学习的多标签分层分类模型能够有效自动化MITRE ATT&CK文本标注任务，性能优于现有方法且不依赖复杂技术，具有实际应用价值。

Abstract: MITRE ATT&CK is a cybersecurity knowledge base that organizes threat actor and cyber-attack information into a set of tactics describing the reasons and goals threat actors have for carrying out attacks, with each tactic having a set of techniques that describe the potential methods used in these attacks. One major application of ATT&CK is the use of its tactic and technique hierarchy by security specialists as a framework for annotating cyber-threat intelligence reports, vulnerability descriptions, threat scenarios, inter alia, to facilitate downstream analyses. To date, the tagging process is still largely done manually. In this technical note, we provide a stratified "task space" characterization of the MITRE ATT&CK text tagging task for organizing previous efforts toward automation using AIML methods, while also clarifying pathways for constructing new methods. To illustrate one of the pathways, we use the task space strata to stage-wise construct our own multi-label hierarchical classification models for the text tagging task via experimentation over general cyber-threat intelligence text -- using shareable computational tools and publicly releasing the models to the security community (via https://github.com/jpmorganchase/MITRE_models). Our multi-label hierarchical approach yields accuracy scores of roughly 94% at the tactic level, as well as accuracy scores of roughly 82% at the technique level. The models also meet or surpass state-of-the-art performance while relying only on classical machine learning methods -- removing any dependence on LLMs, RAG, agents, or more complex hierarchical approaches. Moreover, we show that GPT-4o model performance at the tactic level is significantly lower (roughly 60% accuracy) than our own approach. We also extend our baseline model to a corpus of threat scenarios for financial applications produced by subject matter experts.

</details>


### [73] [Place with Intention: An Empirical Attendance Predictive Study of Expo 2025 Osaka, Kansai, Japan](https://arxiv.org/abs/2601.14570)
*Xiaojie Yang,Dizhi Huang,Hangli Ge,Masahiro Sano,Takeaki Ohdake,Kazuma Hatano,Noboru Koshizuka*

Main category: cs.LG

TL;DR: 提出基于Transformer的框架，利用票务预订动态作为参观者意图的代理，预测大型国际活动（如2025大阪世博会）的每日出席人数，避免多源外部数据的复杂性。


<details>
  <summary>Details</summary>
Motivation: 大型国际活动（如世博会）的准确出席预测对交通、人流和服务管理至关重要。现有方法依赖多源外部数据（天气、交通、社交媒体），但在历史数据不足时结果不可靠。

Method: 提出Transformer框架，利用票务预订动态（预订及后续更新）作为参观者意图的代理，捕捉隐含的外部影响。构建包含入场记录和预订动态的数据集，在单通道（总出席）和双通道（东/西门分开）设置下评估模型。

Result: 结果显示，分开建模东门和西门能持续提高预测准确性，特别是对短期和中期预测。消融研究证实了编码器-解码器结构、逆风格嵌入和自适应融合模块的重要性。

Conclusion: 预订动态为大型国际活动的出席预测提供了实用且信息丰富的基础，避免了多源数据整合的复杂性，同时能隐含捕捉外部影响因素。

Abstract: Accurate forecasting of daily attendance is vital for managing transportation, crowd flows, and services at large-scale international events such as Expo 2025 Osaka, Kansai, Japan. However, existing approaches often rely on multi-source external data (such as weather, traffic, and social media) to improve accuracy, which can lead to unreliable results when historical data are insufficient. To address these challenges, we propose a Transformer-based framework that leverages reservation dynamics, i.e., ticket bookings and subsequent updates within a time window, as a proxy for visitors' attendance intentions, under the assumption that such intentions are eventually reflected in reservation patterns. This design avoids the complexity of multi-source integration while still capturing external influences like weather and promotions implicitly embedded in reservation dynamics. We construct a dataset combining entrance records and reservation dynamics and evaluate the model under both single-channel (total attendance) and two-channel (separated by East and West gates) settings. Results show that separately modeling East and West gates consistently improves accuracy, particularly for short- and medium-term horizons. Ablation studies further confirm the importance of the encoder-decoder structure, inverse-style embedding, and adaptive fusion module. Overall, our findings indicate that reservation dynamics offer a practical and informative foundation for attendance forecasting in large-scale international events.

</details>


### [74] [Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation](https://arxiv.org/abs/2601.14590)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 本文评估了使用大语言模型（LLMs）生成反事实解释（CFEs）的方法，在临床数据集上验证了LLMs在干预质量、特征多样性和数据增强效果方面的优势，特别是微调后的LLaMA-3.1-8B表现最佳。


<details>
  <summary>Details</summary>
Motivation: 反事实解释通过识别最小、可操作的改变来改变机器学习模型的预测，可用于异常预防干预和训练鲁棒模型的数据增强。传统优化方法存在局限性，需要探索LLMs在生成临床可操作反事实方面的潜力。

Method: 使用GPT-4（零样本和少样本）以及两个开源模型BioMistral-7B和LLaMA-3.1-8B（预训练和微调配置），在多模态AI-READI临床数据集上评估反事实生成。从干预质量、特征多样性和增强效果三个维度进行评估，并与DiCE、CFNOW、NICE等优化基线方法比较。

Result: 微调后的LLMs，特别是LLaMA-3.1-8B，生成的反事实具有高合理性（高达99%）、强有效性（高达0.99）和现实可修改的特征调整。在标签稀缺设置下，LLM生成的反事实作为数据增强能显著恢复分类器性能，在三种稀缺场景下平均F1恢复20%。相比优化基线，LLMs提供更灵活、模型无关的方法，生成更具临床可操作性和语义连贯性的反事实。

Conclusion: 这项工作展示了LLM驱动的反事实在传感器数字健康领域中，对于可解释干预设计和数据高效模型训练的前景。SenseCF方法通过微调LLM生成有效的反事实解释，并补充不平衡数据集中的少数类，提高了模型训练效果、鲁棒性和预测性能。

Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance

</details>


### [75] [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599)
*Xiao Hu,Hong Xie,Tao Tan,Defu Lian,Jianyu Han*

Main category: cs.LG

TL;DR: 该论文通过自下而上的实验流程，系统分析了强化学习微调LLM中各种优化选择的作用和瓶颈，揭示了设计选择的新理解


<details>
  <summary>Details</summary>
Motivation: 当前LLM强化微调领域存在大量启发式方法但缺乏统一理解，需要回答两个基本问题：1) 每个优化选择的作用是什么？2) 哪些是瓶颈？

Method: 提出自下而上的实验流程：底层是最简配置（单一训练数据、每轮单次rollout、直接使用奖励作为学习信号），然后逐层扩展，检验每个设计选择的作用

Result: 在三个LLM和两个推理数据集上的实验不仅揭示了设计选择的新理解，还为该领域提供了重要见解

Conclusion: 通过系统分析强化微调中的设计选择，为理解优化方法的作用和瓶颈提供了理论基础和实验证据

Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.

</details>


### [76] [Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum](https://arxiv.org/abs/2601.14603)
*Jingru Li,Yibo Fan,Huan Li*

Main category: cs.LG

TL;DR: Muon通过正交动量更新加速LLM预训练，提出Muon-NSR和Muon-VS两种变体，在GPT-2和LLaMA预训练中比AdamW和Muon基线收敛更快、验证损失更低。


<details>
  <summary>Details</summary>
Motivation: LLM预训练计算成本高昂，优化器效率成为重要实际问题。虽然Adam是方差自适应符号更新算法，但仍有改进空间，需要更高效的优化方法加速LLM预训练。

Method: 提出Muon优化器，使用正交动量更新作为元素级符号算子的矩阵模拟。进一步提出两个变体：Muon-NSR应用信噪比调制，Muon-VS执行基于方差的缩放，两者都在正交化前对动量应用方差自适应归一化。

Result: 在GPT-2和LLaMA预训练实验中，Muon-NSR和Muon-VS加速收敛，始终获得比AdamW和Muon基线更低的验证损失。在LLaMA-1.2B模型上，达到目标验证损失所需的迭代次数减少1.36倍。

Conclusion: Muon-NSR和Muon-VS通过方差自适应归一化改进了Muon优化器，显著加速LLM预训练收敛，为高效LLM训练提供了有效的优化方法。

Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.

</details>


### [77] [Relational Graph Modeling for Credit Default Prediction: Heterogeneous GNNs and Hybrid Ensemble Learning](https://arxiv.org/abs/2601.14633)
*Yvonne Yang,Eranki Vasistha*

Main category: cs.LG

TL;DR: 论文构建了一个大规模异构图（3100万节点，5000万边）来建模信用违约风险，发现纯异构图神经网络提升有限，但将GNN生成的客户嵌入与表格特征结合的混合集成方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 信用违约风险涉及借款人、金融机构和交易行为之间的复杂交互。虽然表格模型在信用评分中表现良好，但可能无法显式捕捉多表金融历史中嵌入的跨实体依赖关系。

Method: 构建大规模异构图（3100万节点，5000万边），整合借款人属性和细粒度交易级实体（分期付款、POS余额、信用卡历史）。评估异构图神经网络（异构图SAGE和关系感知注意力异构图GNN），并与表格基线对比。采用混合集成方法，将GNN生成的客户嵌入与表格特征结合。

Result: 纯GNN相比竞争性梯度提升树基线提升有限，但混合集成方法（表格特征+GNN嵌入）在ROC-AUC和PR-AUC上表现最佳。对比预训练能改善优化稳定性，但在通用图增强下下游收益有限。通过可解释性和公平性分析揭示了关系信号如何影响子群行为。

Conclusion: 异构图神经网络能够捕捉信用风险中的关系模式，但单独使用时提升有限。最佳实践是将GNN生成的关系嵌入与传统表格特征结合，形成混合集成模型。同时需要关注模型的可解释性和公平性影响。

Abstract: Credit default risk arises from complex interactions among borrowers, financial institutions, and transaction-level behaviors. While strong tabular models remain highly competitive in credit scoring, they may fail to explicitly capture cross-entity dependencies embedded in multi-table financial histories. In this work, we construct a massive-scale heterogeneous graph containing over 31 million nodes and more than 50 million edges, integrating borrower attributes with granular transaction-level entities such as installment payments, POS cash balances, and credit card histories.
  We evaluate heterogeneous graph neural networks (GNNs), including heterogeneous GraphSAGE and a relation-aware attentive heterogeneous GNN, against strong tabular baselines. We find that standalone GNNs provide limited lift over a competitive gradient-boosted tree baseline, while a hybrid ensemble that augments tabular features with GNN-derived customer embeddings achieves the best overall performance, improving both ROC-AUC and PR-AUC. We further observe that contrastive pretraining can improve optimization stability but yields limited downstream gains under generic graph augmentations. Finally, we conduct structured explainability and fairness analyses to characterize how relational signals affect subgroup behavior and screening-oriented outcomes.

</details>


### [78] [Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport](https://arxiv.org/abs/2601.14653)
*Yuyu Liu,Jiannan Yang,Ziyang Yu,Weishen Pan,Fei Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: CROT是一种基于最优传输的插补算法，专门处理表格数据中的块状缺失数据，在保持高精度的同时显著减少运行时间。


<details>
  <summary>Details</summary>
Motivation: 单细胞测序数据中的缺失值给生物信息分析带来挑战，现有插补方法通常假设数据均匀完整，难以处理大规模块状缺失数据。

Method: 提出CROT算法，基于最优传输理论处理表格格式的块状缺失数据，有效捕捉数据底层结构，即使在大量缺失情况下也能保持性能。

Result: CROT在插补精度上表现优异，同时显著减少运行时间，证明其在大规模数据集上的可扩展性和效率。

Conclusion: 该工作为异质性高维数据集中的结构化缺失数据提供了稳健的插补解决方案，解决了生物和临床数据分析中的关键挑战。

Abstract: Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.

</details>


### [79] [Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning](https://arxiv.org/abs/2601.14687)
*Zhihao Chen,Zirui Gong,Jianting Ning,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.LG

TL;DR: FRL通过离散排名更新机制增强联邦学习安全性，但本文提出首个针对排名式FL的细粒度控制攻击ECA，能精确控制目标模型精度而避免检测。


<details>
  <summary>Details</summary>
Motivation: 联邦排名学习(FRL)因其离散排名更新机制被认为对模型投毒攻击具有强鲁棒性，但本文发现FRL仍存在安全漏洞，需要研究针对排名式FL框架的新型细粒度控制攻击。

Method: 提出边缘控制攻击(ECA)：1)识别并操纵上升和下降边缘使全局模型与目标模型对齐；2)扩大选择边界间隙以稳定全局模型在目标精度。攻击分为两个阶段，避免传统DoS攻击的明显异常。

Result: 在7个基准数据集和9种拜占庭鲁棒聚合规则上的实验表明，ECA能实现细粒度精度控制，平均误差仅0.224%，比基线方法提升达17倍。

Conclusion: FRL虽然减少了攻击面，但仍易受细粒度控制攻击。ECA作为首个针对排名式FL的此类攻击，揭示了需要更强的防御机制来应对高级投毒攻击。

Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA

</details>


### [80] [Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning](https://arxiv.org/abs/2601.14693)
*Jianwen Sun,Xinrui Li,Fuqing Li,Xiaoxuan Shen*

Main category: cs.LG

TL;DR: EGRL-SR：基于经验驱动目标条件强化学习的符号回归框架，通过历史轨迹和动作价值网络主动引导搜索，而非传统误差驱动方法


<details>
  <summary>Details</summary>
Motivation: 传统基于误差的符号回归方法在庞大表达式空间中面临搜索方向模糊问题，许多结构不同但误差相似的候选表达式阻碍收敛到真实函数

Method: 将符号回归建模为目标条件强化学习问题，结合后见经验回放；设计全点满足二元奖励函数关注结构模式而非低误差表达式；提出结构引导启发式探索策略增强搜索多样性

Result: 在公共基准测试中，EGRL-SR在恢复率和鲁棒性上持续优于最先进方法，相同搜索预算下能恢复更复杂表达式；消融实验验证动作价值网络有效引导搜索

Conclusion: EGRL-SR通过强化学习框架和结构关注机制，解决了传统误差驱动方法的模糊性问题，实现了更鲁棒的符号回归搜索

Abstract: Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.

</details>


### [81] [Re-understanding Graph Unlearning through Memorization](https://arxiv.org/abs/2601.14694)
*Pengfei Ding,Yan Wang,Guanfeng Liu*

Main category: cs.LG

TL;DR: 提出基于记忆化视角的图神经网络遗忘框架MGU，解决现有图遗忘方法在难度评估、困难任务处理和评估协议方面的三大局限性


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络遗忘方法缺乏对遗忘效果关键因素的理解，存在三大问题：1）难度评估不切实际且不准确，需要测试访问且假设无效；2）对难以遗忘的任务效果不佳；3）评估协议错位，过度强调简单任务而未能捕捉真实遗忘能力

Method: 提出记忆化引导的图遗忘框架MGU，从图神经网络记忆化新视角理解图遗忘，实现三个关键进展：提供准确实用的难度评估、开发基于难度动态调整遗忘目标的自适应策略、建立符合实际需求的全面评估协议

Result: 在十个真实世界图数据上的广泛实验表明，MGU在遗忘质量、计算效率和效用保持方面始终优于最先进的基线方法

Conclusion: 通过建立图神经网络记忆化作为理解图遗忘的新视角，MGU框架有效解决了现有方法的局限性，在实用性、准确性和全面性方面取得了显著进展

Abstract: Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation.

</details>


### [82] [CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation](https://arxiv.org/abs/2601.14695)
*Yutong Chen,Jiandong Gao,Ji Wu*

Main category: cs.LG

TL;DR: 提出CoScale-RL方法，通过扩展解决方案和rollout计算来提升大型推理模型的训练稳定性和效率，相比传统后训练缩放策略有显著改进


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRM）训练不稳定且难以预测，特别是在处理难题或基础模型较弱的情况下。传统后训练缩放策略在这些情况下仍有改进空间，需要更高效的数据和计算利用方法。

Method: CoScale-RL包含三个核心组件：1）扩展解决方案：为每个问题收集多个解决方案而非简单扩大数据集；2）扩展rollout计算：稳定强化学习训练；3）重新蒸馏（Re-distillation）：通过模型合并技术维持或提升计算效率。

Result: 在四个基准测试上平均获得3.76倍的准确率提升，显著改善了数据和计算效率。该方法能够在不需要大量监督微调数据集的情况下提升LRM的能力边界。

Conclusion: CoScale-RL为提升大型推理模型的推理能力提供了新的缩放方向，通过更智能的数据和计算资源利用，有效解决了训练不稳定和效率低下的问题。

Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.

</details>


### [83] [Case-Guided Sequential Assay Planning in Drug Discovery](https://arxiv.org/abs/2601.14710)
*Tianchi Chen,Jan Bima,Sean L. Wu,Otto Ritter,Bingjia Yang,Xiang Yu*

Main category: cs.LG

TL;DR: IBMDP是一个用于无模拟器环境下的模型强化学习框架，通过构建隐式贝叶斯马尔可夫决策过程，利用历史数据形成非参数信念分布，实现资源高效的实验序列规划。


<details>
  <summary>Details</summary>
Motivation: 药物发现中的实验序列规划面临严重不确定性和资源约束，标准强化学习缺乏环境模拟器或转移数据，需要仅依赖静态历史数据库进行规划。

Method: 引入隐式贝叶斯马尔可夫决策过程（IBMDP），构建基于案例引导的隐式转移动态模型，使用相似历史结果形成非参数信念分布，通过贝叶斯信念更新和集成MCTS规划生成稳定策略。

Result: 在真实世界CNS药物发现任务中，IBMDP相比现有启发式方法减少高达92%的资源消耗；在合成环境中，与确定性值迭代相比，IBMDP与最优策略对齐度显著更高。

Conclusion: IBMDP为数据丰富但模拟器匮乏领域的顺序实验设计提供了实用解决方案，通过集成规划器在资源效率和决策质量方面表现出优越性。

Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.

</details>


### [84] [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716)
*Yao Lu,Dengdong Fan,Jianzheng Nie,Fan Xu,Jie Chen,Bin Zhou,Yonghong Tian*

Main category: cs.LG

TL;DR: PCL-Reasoner-V1.5是一个基于Qwen2.5-32B构建的320亿参数数学推理大语言模型，采用监督微调和强化学习训练，在AIME竞赛中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 探索更稳定高效的强化学习方法用于提升大语言模型的数学推理能力，特别是解决标准在线强化学习方法（如GRPO）存在的训练不稳定和效率问题。

Method: 基于Qwen2.5-32B模型，采用监督微调（SFT）后接强化学习（RL）的两阶段训练方法。核心创新是提出的离线强化学习方法，相比标准在线RL方法（如GRPO）提供更好的训练稳定性和效率。

Result: 模型在基于Qwen2.5-32B后训练的模型中达到最先进性能：AIME 2024平均准确率90.9%，AIME 2025平均准确率85.6%。所有实验在华为昇腾910C NPU上进行。

Conclusion: 离线强化学习是推进大语言模型推理能力的稳定高效范式，PCL-Reasoner-V1.5展示了该方法在数学推理任务上的有效性。

Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.

</details>


### [85] [FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks](https://arxiv.org/abs/2601.14730)
*Bizu Feng,Zhimu Yang,Shaode Yu,Zixin Hu*

Main category: cs.LG

TL;DR: FSX是一个新颖的GNN可解释性框架，通过结合内部消息流分析和合作博弈方法，高效生成高保真度的结构解释。


<details>
  <summary>Details</summary>
Motivation: 现有GNN可解释性方法存在权衡：基于梯度的方法计算高效但忽略结构交互，而博弈论方法能捕捉交互但计算开销大且可能偏离模型真实推理路径。需要一种能兼顾效率和准确性的方法。

Method: FSX采用混合框架：1) 通过流敏感性分析识别关键消息流（单次前向传播中模拟局部节点扰动）；2) 将敏感度排名的流投影到输入图定义语义子图；3) 在每个子图中进行流感知合作博弈，使用类Shapley值评估节点贡献（结合节点特征重要性和在维持/破坏关键流中的作用）。

Result: 在多个数据集和GNN架构上的广泛评估表明，FSX实现了优越的解释保真度，同时显著减少运行时间，并能揭示模型预测背后的结构逻辑——重要子结构如何通过控制关键内部计算路径的稳定性来施加影响。

Conclusion: FSX通过协同结合模型内部消息流和外部图数据的合作博弈方法，有效解决了现有GNN可解释性方法的局限性，提供了高效且高保真的结构解释框架。

Abstract: Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.

</details>


### [86] [RefProtoFL: Communication-Efficient Federated Learning via External-Referenced Prototype Alignment](https://arxiv.org/abs/2601.14746)
*Hongyue Wu,Hangyu Li,Guodong Fan,Haoran Zhu,Shizhan Chen,Zhiyong Feng*

Main category: cs.LG

TL;DR: RefProtoFL：一种通信高效的联邦学习框架，通过外部参考原型对齐和自适应概率更新丢弃，在有限带宽下提升异构客户端的学习效果。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在边缘环境中面临通信带宽有限和客户端数据分布异构的挑战。现有的原型联邦学习方法虽然通过交换类别特征原型而非完整模型参数来缓解通信压力，但在严重通信约束下仍存在泛化性能不足的问题。

Method: 提出RefProtoFL框架：1）将模型分解为私有骨干网络和轻量级共享适配器，仅通信适配器参数；2）自适应概率更新丢弃（APUD）通过幅度感知Top-K稀疏化，仅传输最重要的适配器更新；3）外部参考原型对齐（ERPA）利用服务器持有的少量公共数据集构建外部参考原型作为共享语义锚点，对齐异构客户端的表示。

Result: 在标准基准测试上的大量实验表明，RefProtoFL比现有的原型联邦学习方法获得了更高的分类准确率。

Conclusion: RefProtoFL通过结合通信高效的适配器更新和基于公共数据的表示对齐，有效解决了联邦学习中的通信约束和客户端异构性问题，实现了更好的模型泛化性能。

Abstract: Federated learning (FL) enables collaborative model training without sharing raw data in edge environments, but is constrained by limited communication bandwidth and heterogeneous client data distributions. Prototype-based FL mitigates this issue by exchanging class-wise feature prototypes instead of full model parameters; however, existing methods still suffer from suboptimal generalization under severe communication constraints. In this paper, we propose RefProtoFL, a communication-efficient FL framework that integrates External-Referenced Prototype Alignment (ERPA) for representation consistency with Adaptive Probabilistic Update Dropping (APUD) for communication efficiency. Specifically, we decompose the model into a private backbone and a lightweight shared adapter, and restrict federated communication to the adapter parameters only. To further reduce uplink cost, APUD performs magnitude-aware Top-K sparsification, transmitting only the most significant adapter updates for server-side aggregation. To address representation inconsistency across heterogeneous clients, ERPA leverages a small server-held public dataset to construct external reference prototypes that serve as shared semantic anchors. For classes covered by public data, clients directly align local representations to public-induced prototypes, whereas for uncovered classes, alignment relies on server-aggregated global reference prototypes via weighted averaging. Extensive experiments on standard benchmarks demonstrate that RefProtoFL attains higher classification accuracy than state-of-the-art prototype-based FL baselines.

</details>


### [87] [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758)
*Injin Kong,Hyoungjoon Lee,Yohan Jo*

Main category: cs.LG

TL;DR: 论文通过对比分析发现，将自回归模型后训练为掩码扩散模型会引发"机制转变"：对于局部因果依赖任务保留自回归电路，但对于全局规划任务则重构网络连接，实现分布式集成计算。


<details>
  <summary>Details</summary>
Motivation: 研究后训练自回归模型为掩码扩散模型时，模型内部是否真正获得了双向推理能力，还是仅仅重新包装了自回归启发式方法。探索这种范式转变引发的内部算法变化。

Method: 采用对比电路分析方法，比较自回归模型及其对应的掩码扩散模型，从结构和语义两个维度分析机制转变。

Result: 发现系统性的"机制转变"：结构上，对于局部因果依赖任务，MDMs基本保留自回归电路；对于全局规划任务，MDMs放弃初始路径，表现出早期层处理增强的重新连接特征。语义上，从ARMs的尖锐局部专业化转变为MDMs的分布式集成。

Conclusion: 扩散后训练不仅仅是调整模型参数，而是从根本上重新组织内部计算以支持非顺序的全局规划，实现了真正的计算机制转变。

Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.

</details>


### [88] [Anytime Optimal Decision Tree Learning with Continuous Features](https://arxiv.org/abs/2601.14765)
*Harold Kiossou,Pierre Schaus,Siegfried Nijssen*

Main category: cs.LG

TL;DR: 提出了一种基于有限差异搜索的任意时间最优决策树学习方法，解决了现有方法在早期中断时产生不平衡次优树的问题。


<details>
  <summary>Details</summary>
Motivation: 现有连续特征最优决策树学习方法采用深度优先搜索策略，虽然能找到最优解但任意时间性能差：早期中断时找到的树通常高度不平衡且次优，而纯贪心方法如C4.5反而可能得到更好结果。

Method: 采用有限差异搜索策略，将计算努力更均匀地分布在整个树结构中，确保在任何中断点都能获得高质量的决策树。

Result: 实验结果表明，该方法在任意时间性能方面优于现有方法。

Conclusion: 提出的基于有限差异搜索的任意时间方法能够有效解决现有最优决策树学习方法的早期中断问题，提供更好的任意时间性能。

Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.

</details>


### [89] [Robustness of Mixtures of Experts to Feature Noise](https://arxiv.org/abs/2601.14792)
*Dong Sun,Rahul Nittala,Rebekka Burkholz*

Main category: cs.LG

TL;DR: MoE模型通过稀疏专家激活作为噪声过滤器，在特征噪声下比密集网络具有更好的泛化性能、鲁棒性和收敛速度


<details>
  <summary>Details</summary>
Motivation: 尽管MoE模型在实践中很成功，但除了参数规模扩展外，为什么它们能超越密集网络仍不清楚。本文研究在输入具有潜在模块化结构但受到特征噪声污染的情况下，MoE的性能优势机制。

Method: 在等参数设定下，研究输入具有潜在模块化结构但受特征噪声污染的情况。通过理论分析稀疏专家激活作为噪声过滤器的作用，并在合成数据和真实语言任务上进行实证验证。

Result: 与密集估计器相比，MoE在特征噪声下获得更低的泛化误差、更好的扰动鲁棒性和更快的收敛速度。合成数据和真实语言任务的实证结果支持理论见解。

Conclusion: 稀疏模块化计算通过专家激活作为噪声过滤器，为MoE模型提供了超越密集网络的鲁棒性和效率优势，特别是在输入具有模块化结构但受噪声污染的情况下。

Abstract: Despite their practical success, it remains unclear why Mixture of Experts (MoE) models can outperform dense networks beyond sheer parameter scaling. We study an iso-parameter regime where inputs exhibit latent modular structure but are corrupted by feature noise, a proxy for noisy internal activations. We show that sparse expert activation acts as a noise filter: compared to a dense estimator, MoEs achieve lower generalization error under feature noise, improved robustness to perturbations, and faster convergence speed. Empirical results on synthetic data and real-world language tasks corroborate the theoretical insights, demonstrating consistent robustness and efficiency gains from sparse modular computation.

</details>


### [90] [Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation](https://arxiv.org/abs/2601.14798)
*Ondřej Holub,Essi Ryymin,Rodrigo Alves*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型的反思问题自动生成框架，通过两个角色专业化代理（学生-教师和教师-教育者）进行苏格拉底式多轮对话，迭代优化反思问题。


<details>
  <summary>Details</summary>
Motivation: 设计高质量的反思问题对教学很重要，但传统方法耗时且教师支持不均衡。需要一种自动化方法来生成有效的反思问题，减轻教师负担并提高教学质量。

Method: 采用反思中的反思框架，协调两个角色专业化代理：学生-教师提出候选问题并给出简要理由，教师-教育者从清晰度、深度、相关性、参与度和概念关联性五个维度评估，通过苏格拉底式多轮对话迭代优化问题。使用GPT-4o-mini作为骨干模型，GPT-4级模型作为外部评估器。

Result: 1) 动态停止机制结合上下文信息（学生水平和教学材料）比固定5或10步迭代效果更好；2) 双代理协议生成的问题在相关性、深度和整体质量上显著优于单次生成基线；3) 过长对话容易导致问题偏离或过度复杂化。

Conclusion: 反思中的反思框架能有效生成高质量的反思问题，动态停止机制和上下文信息对提升问题质量至关重要，双代理对话方法优于单次生成方法。

Abstract: Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.

</details>


### [91] [Statistical Learning Theory for Distributional Classification](https://arxiv.org/abs/2601.14818)
*Christian Fiedler*

Main category: cs.LG

TL;DR: 本文分析了两阶段采样设置中分布输入的监督学习问题，特别关注使用支持向量机（SVM）和核均值嵌入（KME）的分类方法，建立了新的理论结果包括oracle不等式、一致性、学习率，并针对高斯核提出了新的噪声假设。


<details>
  <summary>Details</summary>
Motivation: 在基于学习的医学筛查或因果学习等应用中，输入是概率分布但在学习阶段只能获得其样本（两阶段采样设置）。现有方法使用核均值嵌入将分布嵌入希尔伯特空间，然后应用标准核方法如SVM，但缺乏充分的理论分析。

Method: 采用核均值嵌入（KME）将分布或样本嵌入希尔伯特空间，然后应用支持向量机（SVM）进行分类。特别针对高斯核和铰链损失，提出了新的噪声假设变体，并建立了新的特征空间技术工具。

Result: 建立了新的oracle不等式，推导了一致性和学习率结果。针对使用铰链损失和高斯核的SVM，提出了新的噪声假设，在该假设下能够建立学习率。为高斯核在希尔伯特空间上构建的新特征空间技术工具具有独立价值。

Conclusion: 本文为两阶段采样设置中分布输入的SVM分类提供了系统的理论分析框架，建立了重要的理论保证，提出的技术工具特别是高斯核在希尔伯特空间上的新特征空间构造具有更广泛的应用价值。

Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.

</details>


### [92] [From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps](https://arxiv.org/abs/2601.14848)
*Mohamed Abouras,Catherine M. Elias*

Main category: cs.LG

TL;DR: 本文研究高速公路匝道区域车辆行为预测，使用多层LSTM架构训练模型，在4秒预测范围内取得良好效果


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道区域车辆交互变化大且研究不足，预测这些区域的车辆行为可以减少不确定性并提高道路安全

Method: 使用多层LSTM架构训练匝道区域模型，基于ExiD无人机数据集，测试不同预测时间范围和模型工作流程

Result: 在4秒预测范围内表现良好，匝道区域最大预测准确率约76%，普通高速公路场景约94%

Conclusion: 研究表明多层LSTM架构能有效预测匝道区域车辆行为，为智能交通系统提供重要支持

Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.

</details>


### [93] [Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference](https://arxiv.org/abs/2601.14855)
*Baojun Che,Yifan Chen,Daniel Zhengyu Huang,Xinying Mao,Weijie Wang*

Main category: cs.LG

TL;DR: 提出一种稳定高效的BBVI框架，结合自然梯度、指数积分器和自适应步长，用于高斯混合变分推断


<details>
  <summary>Details</summary>
Motivation: 传统黑盒变分推断（BBVI）使用高斯混合分布近似复杂后验分布时，标准数值优化方法存在不稳定和效率低的问题

Method: 结合三个关键组件：1）通过自然梯度公式实现仿射不变预处理；2）无条件保持协方差矩阵正定性的指数积分器；3）确保稳定性并适应不同阶段的自适应步长

Result: 对于高斯后验，在无噪声设置下证明指数收敛，在蒙特卡洛估计下证明几乎必然收敛；在多模态分布、Neal多尺度漏斗和PDE贝叶斯反问题中验证了方法的有效性

Conclusion: 提出的框架为BBVI提供了一种稳定高效的优化方法，与流形优化和镜像下降有自然联系，自适应步长对收敛至关重要

Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.

</details>


### [94] [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Derya Umut Kulali*

Main category: cs.LG

TL;DR: sdLM框架通过多文档注意力、时间编码和教义一致性层，提升战略推理的长期预测能力和计划合理性，减少教义违规


<details>
  <summary>Details</summary>
Motivation: 现有通用大语言模型在多文档战略推理中缺乏教义一致性约束和校准的不确定性，难以保证长期预测的准确性和计划的可信度

Method: 结合多文档注意力机制、时间编码和教义一致性层，构建战略教义语言模型框架，确保推理过程符合教义约束

Result: 在战略场景专家评分、336份教义出版物一致性评估、127个历史反事实地缘政治预测三个基准测试中，sdLM均优于通用LLM基线，在长期判断上与人类专家竞争力相当

Conclusion: sdLM框架显著提升了战略推理的质量和校准性，通过消融实验和扩展趋势分析明确了各组件的作用，为实际部署提供了性能/延迟特性指导

Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.

</details>


### [95] [What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study](https://arxiv.org/abs/2601.14888)
*Keyu Lv,Manyi Zhang,Xiaobo Xia,Jingchen Ni,Shannan Yan,Xianzhi Yu,Lu Hou,Chun Yuan,Haoli Bai*

Main category: cs.LG

TL;DR: 论文提出Reasoning-QAT工作流，通过量化感知训练提升推理模型效率，在低比特设置下显著优于现有PTQ方法


<details>
  <summary>Details</summary>
Motivation: 推理模型在复杂任务上表现出色但推理速度慢且token效率低，传统后训练量化在低比特设置下会导致推理任务准确率大幅下降

Method: 系统研究推理模型的量化感知训练，发现知识蒸馏是鲁棒目标、PTQ提供QAT强初始化、强化学习在量化模型中可行、对齐PTQ校准域与QAT训练域加速收敛，整合为Reasoning-QAT工作流

Result: Reasoning-QAT在多个LLM骨干和推理数据集上一致优于最先进的PTQ方法，如在Qwen3-0.6B上比GPTQ在MATH-500上提升44.53%，在2比特设置下恢复性能

Conclusion: 量化感知训练是提升推理模型效率的有效方法，通过系统优化的工作流可以在低比特设置下保持高性能，为高效推理模型部署提供解决方案

Abstract: Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.

</details>


### [96] [Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models](https://arxiv.org/abs/2601.14917)
*Giorgia Rigamonti,Mirko Paolo Barbato,Davide Marelli,Paolo Napoletano*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度学习的个性化血糖预测方法，通过患者特定数据提高预测准确性，相比传统通用模型能更好地处理个体差异，显著改善不良事件预测能力。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病管理需要连续血糖监测和精确胰岛素调整，随着可穿戴血糖监测设备和移动健康应用的普及，准确的血糖预测对于增强自动化胰岛素输送和决策支持系统至关重要。传统通用模型难以处理个体差异，需要更有效的个性化预测方法。

Method: 1. 提出基于深度学习的个性化血糖预测方法，利用患者特定数据提高预测准确性；2. 比较留一受试者交叉验证与微调策略，评估其对患者特定动态的建模能力；3. 进行多模态患者特定方法与仅使用连续血糖监测的传统方法的对比实验；4. 通过消融研究分析模型在不同规模训练集下的性能，确定有效个性化所需的最小数据量。

Result: 1. 个性化模型显著改善不良事件预测能力，实现更精确及时的干预；2. 多模态患者特定方法优于传统仅使用连续血糖监测的方法；3. 确定了有效个性化所需的最小数据量，这对实际应用中数据收集受限的情况至关重要。

Conclusion: 自适应个性化血糖预测模型在下一代糖尿病管理中具有重要潜力，特别是在可穿戴和移动健康平台中，能够增强面向消费者的糖尿病护理解决方案，为实际应用提供了可行的个性化方法。

Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.

</details>


### [97] [Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning](https://arxiv.org/abs/2601.14942)
*Hang Zhao,Hongru Li,Dongfang Xu,Shenghui Song,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出三阶段通信感知分布式学习框架，用于多模态边缘推理，通过自监督学习、分布式微调和不确定性反馈机制，在减少通信开销的同时保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 语义通信是实现分布式边缘智能的关键，但多模态边缘推理面临两大挑战：1) 带宽有限无线链路上的通信开销过大；2) 信道变化和噪声多模态输入下的鲁棒性不足。

Method: 三阶段框架：1) 本地多模态自监督学习获取共享和模态特定编码器，无需设备-服务器交换；2) 分布式微调与集中证据融合，校准模态不确定性并聚合噪声/信道失真特征；3) 不确定性引导反馈机制，为不确定样本选择性请求额外特征。

Result: 在RGB-深度室内场景分类实验中，该框架以更少的训练通信轮次获得更高准确率，对模态退化或信道变化保持鲁棒性，优于现有自监督和全监督基线方法。

Conclusion: 提出的三阶段通信感知分布式学习框架有效解决了多模态边缘推理的通信效率和鲁棒性问题，为无线环境下的分布式边缘智能提供了实用解决方案。

Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.

</details>


### [98] [Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features](https://arxiv.org/abs/2601.14954)
*Han Li,Hua Sun*

Main category: cs.LG

TL;DR: 提出一种结合外部证据和伪造特征的多模态谣言检测模型，通过双对比学习检测图文语义不一致，在微博和Twitter数据集上优于主流基线方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中图文混合帖子的谣言常利用细微不一致和伪造内容，深度语义不匹配谣言尤其具有挑战性。现有多模态谣言检测方法存在特征提取有限、噪声对齐、融合策略不灵活等问题，且忽略验证复杂谣言所需的外部事实证据。

Method: 使用ResNet34视觉编码器和BERT文本编码器，通过傅里叶变换提取频域痕迹和压缩伪影的伪造特征模块。BLIP生成图像描述桥接图文语义空间。双对比学习模块计算文本-图像和文本-描述对的对比损失，检测语义不一致。门控自适应特征缩放融合机制动态调整多模态融合并减少冗余。

Result: 在微博和Twitter数据集上的实验表明，该模型在宏观准确率、召回率和F1分数上优于主流基线方法。

Conclusion: 提出的结合外部证据和伪造特征的多模态谣言检测模型能有效检测深度语义不匹配谣言，通过双对比学习和自适应融合机制提升了检测性能。

Abstract: Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.

</details>


### [99] [Improving Regret Approximation for Unsupervised Dynamic Environment Generation](https://arxiv.org/abs/2601.14957)
*Harry Mead,Bruno Lacerda,Jakob Foerster,Nick Hawes*

Main category: cs.LG

TL;DR: DEGen通过动态环境生成提供更密集的奖励信号，结合MNA遗憾近似方法，显著提升UED在大型环境中的性能


<details>
  <summary>Details</summary>
Motivation: 当前UED方法在环境参数子集导致策略复杂度显著增加时存在困难，面临信用分配问题和遗憾近似失效的挑战，特别是在环境规模增大时

Method: 提出DEGen（动态环境生成）提供更密集的生成器奖励信号，改善信用分配；引入MNA（最大化负优势）作为新的遗憾近似指标，更好识别挑战性环境

Result: 实验表明MNA优于现有遗憾近似方法，DEGen与MNA结合后显著超越现有方法，特别是在环境规模增大时表现更突出

Conclusion: DEGen和MNA的组合有效解决了UED在大型环境中的扩展性问题，为强化学习代理的泛化能力提供了更好的训练课程

Abstract: Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.

</details>


### [100] [InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement](https://arxiv.org/abs/2601.14968)
*Mingyue Cheng,Xiaoyu Tao,Huajian Zhang,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: InstructTime++：将时间序列分类重构为多模态生成任务，通过离散化时间序列、跨模态对齐和隐式特征建模，利用语言模型生成类别标签。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法采用判别式范式，直接将输入序列映射到one-hot编码的类别标签。这种方法难以融入上下文特征，也无法捕捉类别间的语义关系。

Method: 1. 将时间序列分类重构为多模态生成任务：连续数值序列、上下文文本特征和任务指令作为多模态输入，类别标签作为语言模型生成的文本输出。2. 引入时间序列离散化模块，将连续序列转换为离散时间标记。3. 使用对齐投影层和生成式自监督预训练策略增强跨模态表示对齐。4. InstructTime++进一步加入隐式特征建模：使用统计特征提取和视觉语言图像描述等工具包挖掘原始时间序列和上下文输入中的信息模式，并将其转换为文本描述进行集成。

Result: 在多个基准数据集上的广泛实验表明，InstructTime++具有优越的性能。

Conclusion: 将时间序列分类重构为生成式多模态任务，通过离散化、对齐和隐式特征建模，能够有效利用语言模型的能力，克服传统判别式方法的局限性。

Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.

</details>


### [101] [Fine-Grained Traceability for Transparent ML Pipelines](https://arxiv.org/abs/2601.14971)
*Liping Chen,Mujie Liu,Haytham Fayek*

Main category: cs.LG

TL;DR: FG-Trac是一个模型无关的框架，为机器学习流水线建立可验证的细粒度样本级可追溯性，通过加密承诺锚定样本生命周期事件，不改变模型架构即可实现完整的数据使用历史审计。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统通常是多阶段流水线，但现有透明度机制仅停留在模型层面，无法追踪单个样本在流水线中的使用情况。缺乏可验证的样本级可追溯性使得实践者和用户无法确定特定样本是否被使用、何时被处理，以及相应记录是否随时间保持完整。

Method: FG-Trac定义了一个显式机制来捕获和验证预处理和训练过程中的样本生命周期事件，基于训练检查点计算贡献分数，并将这些追踪锚定到防篡改的加密承诺中。该框架无需修改模型架构或训练目标，通过实用的计算开销重建完整可审计的数据使用历史。

Result: 在经典卷积神经网络和多模态图学习流水线上的实验表明，FG-Trac在保持预测性能的同时，使机器学习系统能够提供关于单个样本在模型执行过程中如何被使用和传播的可验证证据。

Conclusion: FG-Trac填补了机器学习流水线中样本级可追溯性的空白，通过加密锚定的生命周期追踪机制，为系统提供了可验证的数据使用历史记录，增强了机器学习系统的透明度和可信度。

Abstract: Modern machine learning systems are increasingly realised as multistage pipelines, yet existing transparency mechanisms typically operate at a model level: they describe what a system is and why it behaves as it does, but not how individual data samples are operationally recorded, tracked, and verified as they traverse the pipeline. This absence of verifiable, sample-level traceability leaves practitioners and users unable to determine whether a specific sample was used, when it was processed, or whether the corresponding records remain intact over time. We introduce FG-Trac, a model-agnostic framework that establishes verifiable, fine-grained sample-level traceability throughout machine learning pipelines. FG-Trac defines an explicit mechanism for capturing and verifying sample lifecycle events across preprocessing and training, computes contribution scores explicitly grounded in training checkpoints, and anchors these traces to tamper-evident cryptographic commitments. The framework integrates without modifying model architectures or training objectives, reconstructing complete and auditable data-usage histories with practical computational overhead. Experiments on a canonical convolutional neural network and a multimodal graph learning pipeline demonstrate that FG-Trac preserves predictive performance while enabling machine learning systems to furnish verifiable evidence of how individual samples were used and propagated during model execution.

</details>


### [102] [Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors](https://arxiv.org/abs/2601.15000)
*Christos Petridis,Konstantinos Pelechrinis*

Main category: cs.LG

TL;DR: 提出L-RAPM回归方法，通过控制对手阵容和利用球员信息，解决篮球阵容评估中数据稀疏和噪声问题，提高预测能力。


<details>
  <summary>Details</summary>
Motivation: 篮球运动中评估阵容组合表现是重要任务，但由于频繁换人导致数据高度稀疏（NBA赛季超过600种阵容，平均仅25-30回合），现有统计数据噪声大、预测价值低，且缺乏公开解决方案。

Method: 提出基于回归的方法L-RAPM，控制每个阵容面对的对手因素，同时利用组成阵容的球员信息。

Result: 实验显示L-RAPM比当前基线方法具有更好的预测能力，且随着阵容样本量减小，改进效果更加明显。

Conclusion: L-RAPM方法能有效解决篮球阵容评估中的数据稀疏问题，提供更可靠的阵容表现预测，特别适用于小样本情况。

Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.

</details>


### [103] [RadixMLP -- Intra-batch Deduplication for Causal Transformers](https://arxiv.org/abs/2601.15013)
*Michael Feil,Julius Lipp*

Main category: cs.LG

TL;DR: RadixMLP通过前缀树压缩共享前缀，消除因果Transformer批量推理中的冗余计算，提升推理速度


<details>
  <summary>Details</summary>
Motivation: 因果Transformer模型的批量推理工作负载经常处理具有共享前缀的序列（如系统提示、少样本示例等），但标准推理引擎独立处理每个序列，冗余计算相同的MLP激活

Method: RadixMLP利用MLP、LayerNorm、线性投影和嵌入的位置特性，将批次动态映射到前缀树中，将共享段压缩为表示进行位置计算，仅在注意力边界处散射结果

Result: 在MS MARCO v1.1的Qwen3模型（0.6B到8B参数）上，RadixMLP在实际重排序工作负载中实现1.44-1.59倍加速，在具有更长共享前缀的合成基准测试中达到5倍加速

Conclusion: RadixMLP是一种无状态、单前向传递的技术，能有效消除因果Transformer批量推理中的冗余计算，显著提升推理效率

Abstract: Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\times$ speedups in realistic reranking workloads, with up to $5\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.

</details>


### [104] [Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control](https://arxiv.org/abs/2601.15015)
*Jannis Becktepe,Aleksandra Franz,Nils Thuerey,Sebastian Peitz*

Main category: cs.LG

TL;DR: FluidGym：首个独立、完全可微的强化学习主动流控制基准套件，基于PyTorch和GPU加速PICT求解器，无需外部CFD软件，提供标准化评估协议。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在主动流控制领域的研究进展难以评估，因为现有研究依赖异构的观测与执行方案、数值设置和评估协议。现有基准依赖外部CFD求解器、不完全可微、且3D和多智能体支持有限。

Method: 基于GPU加速的PICT求解器在PyTorch上构建完全独立的基准套件，提供标准化评估协议，无需外部CFD软件，支持3D和多智能体场景。

Result: 提供了PPO和SAC的基线结果，发布了所有环境、数据集和训练模型作为公共资源，建立了可扩展的学习型流控制研究基础。

Conclusion: FluidGym实现了控制方法的系统比较，为基于学习的流控制研究建立了可扩展的基础，所有资源已开源。

Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.

</details>


### [105] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 研究比较了图像分类中密集、SoftMoE和SparseMoE架构的性能，发现MoE变体在CIFAR10上略优于密集基线，但条件计算在小型模型上未能实现推理加速。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构在图像分类中的行为，而非传统的大语言模型缩放应用。关注预测性能、专家利用率和泛化特性，特别是在小规模模型上的实际效率表现。

Method: 在CIFAR10数据集上比较密集、SoftMoE和SparseMoE分类头，保持可比模型容量。使用正则化防止专家崩溃，通过Hessian矩阵特征值和迹等锐度指标分析泛化，并进行损失曲面扰动分析。

Result: MoE变体验证准确率略高于密集基线，专家利用率保持平衡。SoftMoE显示更高的锐度，而密集和SparseMoE处于相似的曲率区域。条件路由在当前硬件和小规模下未能实现推理加速。

Conclusion: MoE在图像分类中能提供轻微性能提升，但稀疏条件计算的理论效率优势在小规模模型中难以实现。曲率分析揭示了架构间的差异，但未能直接解释泛化性能。

Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.

</details>


### [106] [Factorizable joint shift revisited](https://arxiv.org/abs/2601.15036)
*Dirk Tasche*

Main category: cs.LG

TL;DR: 论文提出一个分析一般标签空间分布偏移的框架，将因子化联合偏移(FJS)扩展到分类和回归模型，并推广了相关算法。


<details>
  <summary>Details</summary>
Motivation: 现有因子化联合偏移(FJS)研究仅限于分类标签空间，需要扩展到一般标签空间以覆盖分类和回归模型。

Method: 提出一个分析一般标签空间分布偏移的框架，将FJS扩展到一般标签空间，并推广了期望最大化(EM)算法用于类别先验概率估计。

Result: 建立了适用于分类和回归的分布偏移分析框架，将FJS理论推广到一般标签空间，并重新审视了一般标签空间下的广义标签偏移(GLS)。

Conclusion: 该框架为一般标签空间的分布偏移分析提供了理论基础，扩展了现有方法的应用范围，对机器学习的实际应用具有重要意义。

Abstract: Factorizable joint shift (FJS) was proposed as a type of distribution shift (or dataset shift) that comprises both covariate and label shift. Recently, it has been observed that FJS actually arises from consecutive label and covariate (or vice versa) shifts. Research into FJS so far has been confined to the case of categorical label spaces. We propose a framework for analysing distribution shift in the case of general label spaces, thus covering both classification and regression models. Based on the framework, we generalise existing results on FJS to general label spaces and propose a related extension of the expectation maximisation (EM) algorithm for class prior probabilities. We also take a fresh look at generalized label shift (GLS) in the case of general label spaces.

</details>


### [107] [A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2601.15038)
*Mertcan Daysalilar,Fuat Uyguroglu,Gabriel Nicolosi,Adam Meyers*

Main category: cs.LG

TL;DR: 提出基于课程学习的深度强化学习框架(CB-DRL)解决电动车路径规划问题(EVRPTW)的训练不稳定问题，通过三阶段渐进式学习实现从简单到复杂的稳定训练，在小规模训练下实现大规模泛化。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习模型在处理具有密集约束的电动车路径规划问题时存在训练不稳定问题，难以收敛或泛化，需要一种更稳定的训练框架。

Method: 采用三阶段课程学习：阶段A学习距离和车队优化，阶段B学习电池管理，阶段C学习完整EVRPTW问题。使用改进的近端策略优化算法，结合异构图注意力编码器、全局-局部注意力机制和特征线性调制。

Result: 仅使用N=10的小规模实例训练，模型能泛化到N=5到N=100的未见实例，在中规模问题上显著优于基准方法，在分布外实例上实现高可行性和竞争性解质量。

Conclusion: 课程学习引导的方法有效解决了深度强化学习在复杂约束优化问题中的训练不稳定问题，在神经网络的快速求解和操作可靠性之间架起了桥梁。

Abstract: The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.

</details>


### [108] [HyperNet-Adaptation for Diffusion-Based Test Case Generation](https://arxiv.org/abs/2601.15041)
*Oliver Weißl,Vincenzo Riccio,Severin Kacianka,Andrea Stocco*

Main category: cs.LG

TL;DR: HyNeA是一种基于扩散模型的生成式测试方法，通过超网络实现无数据集的精确控制，能够高效生成真实的失败测试用例，相比传统方法具有更好的可控性和测试多样性。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统在真实场景中的可靠性评估需求日益增长。传统梯度对抗攻击引入的小扰动很少对应真实故障，主要评估鲁棒性而非功能行为。现有生成式测试方法通常局限于简单数据集或受限输入域，而扩散模型虽然能合成高保真图像，但计算成本高且可控性有限，难以应用于大规模测试。

Method: HyNeA采用基于超网络的扩散模型生成方法，实现无数据集的可控性。通过超网络直接控制生成过程，无需依赖架构特定的条件机制或数据集驱动的微调。采用独特的训练策略，支持实例级调优以识别引发失败的测试用例，无需包含类似失败示例的数据集。

Result: 实验结果表明，HyNeA相比现有生成式测试生成器提高了可控性和测试多样性，能够泛化到缺乏失败标签训练数据的领域。该方法能够以比基于搜索的方法低得多的计算成本，有针对性地生成真实的失败案例。

Conclusion: HyNeA提供了一种高效、可控的生成式测试方法，能够直接控制扩散模型的生成过程，为深度学习系统的可靠性评估提供了新的解决方案，特别适用于缺乏失败标签数据的领域。

Abstract: The increasing deployment of deep learning systems requires systematic evaluation of their reliability in real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative test generation methods offer an alternative but are often limited to simple datasets or constrained input domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing method that enables direct and efficient control over diffusion-based generation. HyNeA provides dataset-free controllability through hypernetworks, allowing targeted manipulation of the generative process without relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning. HyNeA employs a distinct training strategy that supports instance-level tuning to identify failure-inducing test cases without requiring datasets that explicitly contain examples of similar failures. This approach enables the targeted generation of realistic failure cases at substantially lower computational cost than search-based methods. Experimental results show that HyNeA improves controllability and test diversity compared to existing generative test generators and generalizes to domains where failure-labeled training data is unavailable.

</details>


### [109] [LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training](https://arxiv.org/abs/2601.15079)
*Chenyu Liu,Haige Li,Luca Rossi*

Main category: cs.LG

TL;DR: 提出LoRAP方法，通过低秩聚合提示优化GNN量化训练，在低比特量化下提升性能且计算开销小


<details>
  <summary>Details</summary>
Motivation: GNN量化能减小模型尺寸、加速推理，但现有方法主要关注节点特征量化，而聚合操作的量化效果不理想。需要一种方法来优化量化聚合结果，提升低比特量化GNN的性能。

Method: 提出低秩聚合提示（LoRAP）方法，在量化感知训练中为每个聚合特征注入轻量级、输入相关的提示，优化量化聚合结果。相比仅提示节点特征，LoRAP能更全面地优化量化过程。

Result: 在4个主流QAT框架和9个图数据集上的实验表明，LoRAP能持续提升低比特量化GNN的性能，同时引入的计算开销极小。

Conclusion: LoRAP是一种有效的GNN量化优化方法，通过提示学习机制改善了量化聚合操作，为资源受限环境下的高效GNN部署提供了实用解决方案。

Abstract: Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.

</details>


### [110] [Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning](https://arxiv.org/abs/2601.15086)
*Oleg Shchendrigin,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 论文提出了一个评估强化学习智能体记忆重写能力的新基准，发现传统循环模型在现代结构化记忆和Transformer智能体失败的任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 现实世界决策需要记忆既稳定又适应性强，但现有RL基准和记忆增强智能体主要关注记忆保留，忽视了记忆重写这一同等重要的能力。

Method: 引入了一个在部分可观测性下测试持续记忆更新的基准，用于比较循环模型、基于Transformer的结构化记忆架构。

Result: 经典循环模型在记忆重写任务中表现出更大的灵活性和鲁棒性，而结构化记忆只在狭窄条件下成功，Transformer智能体在非平凡保留任务中经常失败。

Conclusion: 当前方法存在根本性局限，需要设计平衡稳定保留与适应更新的记忆机制，强调开发具有明确可训练遗忘机制的未来RL智能体的必要性。

Abstract: Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/

</details>


### [111] [Field-Space Autoencoder for Scalable Climate Emulators](https://arxiv.org/abs/2601.15102)
*Johannes Meuer,Maximilian Witte,Étiénne Plésiat,Thomas Ludwig,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出Field-Space Autoencoder框架，通过球面压缩模型解决公里级地球系统模型计算昂贵、输出庞大的问题，支持零样本超分辨率和生成扩散模型训练。


<details>
  <summary>Details</summary>
Motivation: 公里级地球系统模型计算成本高、输出数据庞大（PB级），限制了其在概率风险评估等应用中的实用性，需要一种可扩展的气候模拟框架。

Method: 提出Field-Space Autoencoder，基于球面压缩模型，使用Field-Space Attention直接在原生气候模型输出上操作，避免将球面数据强制到欧几里得网格造成的几何失真。该方法生成结构化压缩场，作为下游生成模拟的良好基线，并能进行零样本超分辨率。

Result: 该方法比卷积基线更好地保留了物理结构，通过生成扩散模型在压缩场上训练，能够同时从丰富的低分辨率数据中学习内部变异性，并从稀疏的高分辨率数据中学习精细尺度物理。

Conclusion: 该工作填补了低分辨率集合统计量丰富与高分辨率物理细节稀缺之间的差距，为可扩展的气候模拟提供了有效框架。

Abstract: Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.

</details>


### [112] [Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111)
*Anmol Goel,Alan Ritter,Iryna Gurevych*

Main category: cs.LG

TL;DR: 当前机器学习遗忘方法存在关键局限：尽管遗忘算法看似成功，但被遗忘数据的信息仍可从模型内部表示中线性解码。论文引入基于部分信息分解的信息论框架来审计遗忘效果，发现冗余信息在遗忘后持续存在，并提出基于表示的风险评分来缓解隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型遗忘方法存在关键问题：虽然遗忘算法表面成功，但被遗忘数据的信息仍能从模型内部表示中线性解码。这种不一致性需要系统评估，以理解遗忘效果的真实程度和潜在隐私风险。

Method: 引入基于部分信息分解（PID）的可解释信息论框架来审计遗忘效果。通过比较遗忘前后的模型表示，将与被遗忘数据的互信息分解为不同组件，形式化定义已遗忘知识和残留知识的概念。分析发现冗余信息（两个模型共享）构成遗忘后持续存在的残留知识。

Result: 分析揭示冗余信息在遗忘后持续存在，且与已知对抗重建攻击的易感性相关。基于这些发现，提出基于表示的风险评分，可在推理时指导对敏感输入的弃权，提供缓解隐私泄露的实际机制。

Conclusion: 本文提出了原则性的表示层审计方法用于评估遗忘效果，为语言模型的安全部署提供理论洞见和实用工具。该框架能识别残留知识并指导风险缓解策略，提升模型隐私保护能力。

Abstract: We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.

</details>


### [113] [Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.15124)
*Haonan Yuan,Qingyun Sun,Jiacheng Tao,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: RAG-GFM提出了一种检索增强的图基础模型，通过将知识从参数中卸载到外部存储，解决了传统图基础模型的内存瓶颈和知识压缩问题，在跨域节点和图分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前图基础模型(GFMs)存在内存瓶颈问题：它们试图将所有知识编码到模型参数中，这限制了语义容量，引入了严重的损失性压缩和冲突，并且将图表示与知识纠缠在一起，阻碍了高效适应，影响了可扩展性和可解释性。

Method: 提出RAG-GFM框架：1) 构建双模态统一检索模块，包括基于前缀结构文本的语义存储和基于中心性基序的结构存储；2) 设计双视图对齐目标，通过对比两种模态来捕捉内容和关系模式；3) 进行上下文增强，用检索到的文本和基序作为上下文证据来丰富支持实例。

Result: 在五个基准图数据集上的实验表明，RAG-GFM在跨域节点和图分类任务中始终优于13个最先进的基线方法，实现了卓越的有效性和效率。

Conclusion: RAG-GFM通过检索增强生成的方法，成功地将知识从模型参数中卸载，解决了传统图基础模型的内存瓶颈问题，同时保持了高效的下游适应能力，为图基础模型的发展提供了新的方向。

Abstract: Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.

</details>


### [114] [DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search](https://arxiv.org/abs/2601.15127)
*Bostan Khan,Masoud Daneshtalab*

Main category: cs.LG

TL;DR: DeepFedNAS是一个两阶段联邦神经架构搜索框架，通过帕累托最优超网训练和预测器免费搜索方法，显著提升联邦学习中的模型设计效率与性能。


<details>
  <summary>Details</summary>
Motivation: 当前联邦神经架构搜索面临两个关键瓶颈：无指导的超网训练导致次优模型，以及后训练子网发现需要耗时数小时的多阶段流程。这限制了联邦学习在实际部署中的实用性。

Method: 提出两阶段框架：1) 联邦帕累托最优超网训练，使用预计算的帕累托最优架构缓存作为智能课程来优化共享超网权重；2) 预测器免费搜索方法，利用多目标适应度函数作为零成本精度代理，实现秒级子网发现。

Result: 在CIFAR-100上实现最高1.21%的绝对精度提升，具有优越的参数和通信效率，后训练搜索流程时间加速约61倍（从20多小时减少到约20分钟），单个子网搜索仅需20秒。

Conclusion: DeepFedNAS通过创新的两阶段框架解决了联邦神经架构搜索的效率瓶颈，使硬件感知的联邦学习部署变得即时实用，为隐私保护的自动化模型设计提供了高效解决方案。

Abstract: Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS

</details>


### [115] [CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning](https://arxiv.org/abs/2601.15141)
*Tianshi Xu,Yuteng Chen,Meng Li*

Main category: cs.LG

TL;DR: CLEANER提出了一种利用LLM内在自校正能力来净化强化学习轨迹的方法，通过相似性感知自适应回滚机制替换失败步骤，显著提升小参数模型在工具使用任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 小参数LLM（4B-7B）在工具使用强化学习中面临探索阶段频繁执行失败的问题，导致噪声轨迹阻碍策略优化。传统方法面临奖励黑客攻击和计算成本高昂的困境。

Method: 提出CLEANER框架，核心是相似性感知自适应回滚机制（SAAR），利用模型自校正能力在数据收集阶段直接净化轨迹，根据语义相似度自适应调整替换粒度，从浅层执行修复到深层推理替换。

Result: 在AIME24/25、GPQA和LiveCodeBench基准测试中，平均准确率分别提升6%、3%和5%，仅用三分之一训练步数就能达到SOTA性能。

Conclusion: 轨迹净化是高效智能体强化学习的可扩展解决方案，通过训练自净化路径使模型内化正确推理模式而非错误恢复循环。

Abstract: Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub

</details>


### [116] [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158)
*Yuval Ran-Milo,Yotam Alexander,Shahar Mendel,Nadav Cohen*

Main category: cs.LG

TL;DR: 论文分析了Transformer在稀疏奖励下如何自发发展出链式推理能力，通过图遍历任务的理论分析揭示了简单示例在梯度流动态中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 理解基于结果的强化学习训练的Transformer如何自发发展出中间推理步骤（链式思维）的机制，目前对这一过程的理解还很有限。

Method: 通过分析单层Transformer在合成图遍历任务上的梯度流动态，该任务无法在没有链式思维的情况下解决，但允许简单的迭代解决方案。理论证明仅基于最终答案正确性训练时，梯度流会驱动模型收敛到结构化、可解释的迭代算法。

Result: 识别了"简单示例"（需要较少推理步骤的实例）在分布特性中的关键作用。当训练分布包含足够多的简单示例时，模型学习到可泛化的遍历策略并能外推到更长的链；当这些示例消失时，基于梯度的学习变得不可行。理论结果在合成数据和真实世界语言模型的数学推理任务上得到了验证。

Conclusion: 稀疏奖励驱动的梯度下降能够自发发现系统性的推理算法，关键在于训练分布中简单示例的存在，这为理解Transformer如何发展链式推理能力提供了理论解释。

Abstract: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of "simple examples": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.

</details>


### [117] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH优化器通过梯度范数的时间演化自适应调整学习率，在图像分类、目标检测等任务中取得更高精度且计算开销更低。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器存在计算内存开销大、与正则化不兼容、学习率选择次优等问题，需要手动调整学习率计划。

Method: 提出ZENITH优化器，利用梯度范数的时间演化来自适应调整学习率，实现零开销的自动学习率调度。

Result: 在6个CNN架构和6个基准测试中，ZENITH在更短的时间内达到更高的测试精度；在MS COCO的目标检测、关键点检测和实例分割任务中取得更优的mAP。

Conclusion: ZENITH优化器能够有效自适应学习率，减少计算开销，与正则化兼容，在多种计算机视觉任务中表现优异。

Abstract: Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

</details>


### [118] [Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism](https://arxiv.org/abs/2601.15249)
*Garrett G. Wen,Buxin Su,Natalie Collina,Zhun Deng,Weijie Su*

Main category: cs.LG

TL;DR: 提出一种作者辅助的最佳论文评选机制，通过等渗机制让作者对自己的论文进行排名，结合评审分数优化估计论文真实质量，激励作者诚实报告。


<details>
  <summary>Details</summary>
Motivation: NeurIPS、ICML等AI顶会每年收到数万投稿，最佳论文评选面临质量和一致性的挑战，且近年来争议不断。需要改进评选机制以提升质量。

Method: 采用等渗机制让作者对自己的投稿进行排名评估，结合原始评审分数调整，优化估计论文的真实质量。机制激励作者诚实报告，特别是当作者只有单一配额时，即使效用函数只是非递减可加也成立。

Result: 使用ICLR 2019-2023和NeurIPS 2021-2023的公开评审数据验证了凸性假设。模拟结果显示该机制显著提升了获奖论文的质量。

Conclusion: 作者辅助的最佳论文评选机制能有效改进评选质量，激励诚实报告，且假设条件比先前工作更宽松，具有实际应用价值。

Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.

</details>


### [119] [MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs](https://arxiv.org/abs/2601.15279)
*Christoph Bartmann,Johannes Schimunek,Mykyta Ielanskyi,Philipp Seidl,Günter Klambauer,Sohvi Luukkonen*

Main category: cs.LG

TL;DR: MolecularIQ是一个专门评估大语言模型在分子结构推理能力的基准测试，专注于符号可验证任务，揭示模型在特定分子结构和任务上的能力模式。


<details>
  <summary>Details</summary>
Motivation: 现有化学基准测试大多侧重于一般化学知识，依赖文献或代理标签，存在数据泄露或偏见风险，或简化为多项选择题，缺乏对分子图推理能力的细粒度评估。

Method: 开发MolecularIQ基准测试，专注于符号可验证的分子结构推理任务，能够对分子图推理进行细粒度评估，将模型失败定位到特定任务和分子结构。

Result: MolecularIQ揭示了当前化学大语言模型的能力模式，能够将模型失败定位到特定任务和分子结构，为模型开发提供可操作的见解。

Conclusion: MolecularIQ提供了对当前化学大语言模型优势和局限性的深入理解，指导开发能够忠实推理分子结构的模型。

Abstract: A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.

</details>
