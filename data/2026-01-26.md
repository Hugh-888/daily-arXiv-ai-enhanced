<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 50]
- [quant-ph](#quant-ph) [Total: 38]
- [gr-qc](#gr-qc) [Total: 11]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 本文提出了一种基于离散评分函数的叶节点判别准则，将评分匹配框架扩展到离散数据的因果发现中，通过叶节点检测识别拓扑顺序，再通过边剪枝恢复图结构。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据中学习DAG结构是跨科学领域的长期挑战。现有基于评分匹配的因果发现方法主要针对连续数据，需要扩展到离散数据场景。

Method: 扩展评分匹配框架到离散数据，提出基于离散评分函数的新型叶节点判别准则，通过叶节点检测识别拓扑顺序，然后进行边剪枝来恢复图结构。

Result: 通过模拟和真实世界实验证明，该方法能够从观测的离散数据中准确推断真实因果顺序，并且识别的顺序能显著提升现有因果发现基线的准确性。

Conclusion: 提出的基于离散评分函数的叶节点判别准则有效扩展了评分匹配框架到离散数据因果发现，能够准确推断因果顺序并提升现有方法的性能。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [2] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 利用Fitbit可穿戴设备数据，通过机器学习模型筛查大学生抑郁、焦虑和压力，探索不同生理模态的最佳数据聚合水平。


<details>
  <summary>Details</summary>
Motivation: 大学生面临高压力导致焦虑抑郁，现有研究在心理测量工具多样性、生理模态和时间序列参数方面有限，需要探索可穿戴设备在心理健康监测中的潜力。

Method: 收集疫情期间大学生心理健康与环境健康数据集，使用不同Fitbit模态（心率、睡眠等），构建预测性机器学习模型进行抑郁、焦虑和压力筛查。

Result: 心率模态在压力筛查中F1分数达0.77，睡眠模态在抑郁筛查中达0.78，焦虑筛查最高F1分数为0.79，显示可穿戴设备在心理健康筛查中的潜力。

Conclusion: 可穿戴设备支持持续心理健康监测具有潜力，识别最佳数据聚合水平和适当模态对于不同心理健康问题筛查至关重要。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [3] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出一种基于数据低维线性投影的高斯过程训练新目标函数——投影似然(PL)，相比精确GP训练和变分稀疏GP方法，在中等规模数据集上具有更好的精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程训练在大规模数据集上面临计算复杂度高的问题，需要开发更高效且保持精度的训练方法。

Method: 使用数据低维线性投影构建高斯过程，提出投影似然(PL)训练目标函数，推导了PL信息损失的闭式表达式，并采用单位球面上的随机投影来减少信息损失。

Result: 实验表明，在不同优化器、核函数和中等规模数据集上，投影似然方法在精度和计算效率上均优于精确GP训练和变分稀疏GP方法。

Conclusion: 投影似然为高斯过程训练提供了一种高效且准确的替代方案，特别适用于中等规模数据集，通过低维投影平衡了计算复杂度和模型性能。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [4] [Analyzing Neural Network Information Flow Using Differential Geometry](https://arxiv.org/abs/2601.16366)
*Shuhang Tan,Jayson Sia,Paul Bogdan,Radoslav Ivanov*

Main category: cs.LG

TL;DR: 该论文从图论视角重新审视神经网络数据流问题，提出基于Ollivier-Ricci曲率的神经曲率概念，用于识别神经网络中重要的连接边。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络数据流分析基于信息论，本文希望通过图论中的曲率概念提供新的分析工具，用于符号神经网络分析如鲁棒性分析和模型修复。

Method: 1) 基于神经网络结构构建图并引入基于ORC的神经曲率概念；2) 根据输入示例的激活模式计算曲率；3) 使用神经曲率对边的重要性进行排序。

Result: 剪枝实验表明，移除负ORC边会快速降低神经网络性能，而正ORC边影响很小。在MNIST、CIFAR-10和CIFAR-100数据集上的评估显示，该方法比现有剪枝方法能识别更多不重要边。

Conclusion: 图曲率为神经网络数据流分析提供了有效的新视角，神经曲率能够可靠地识别对模型性能至关重要的连接边，为模型分析和优化提供了新工具。

Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.

</details>


### [5] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出单循环一阶actor-critic算法，通过惩罚重构解决双层优化问题，上层目标依赖下层MDP的最优策略，引入衰减熵正则实现无偏梯度估计。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和RL方法需要二阶信息、强正则化或低效嵌套循环，需要更高效的单循环一阶方法处理上层目标依赖下层MDP最优策略的问题。

Method: 提出单循环一阶actor-critic算法，通过惩罚重构将双层问题转化为单层，在下层RL目标中引入衰减熵正则，实现渐进无偏的上层超梯度估计。

Result: 在特殊Polyak-Lojasiewicz条件下，通过新颖的下层残差分析，证明了算法对原始无正则双层优化问题平稳点的有限时间和有限样本收敛性。

Conclusion: 方法在GridWorld目标位置问题和基于人类反馈的RLHF快乐推文生成任务中验证有效，为双层RL优化提供了高效的单循环一阶解决方案。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [6] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 该论文为RLHF对齐大语言模型建立了泛化理论，证明在特征覆盖条件下，策略模型的泛化误差为O(n^{-1/2})，为RLHF的实证泛化提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: RLHF及其变体已成为对齐大语言模型的主要方法，虽然实证有效，但其在高维设置下的理论泛化性质尚未充分探索。现有工作主要基于奖励模型的最大似然估计一致性，而本文旨在建立更符合实践端到端学习框架的理论基础。

Method: 在线性奖励模型假设下，通过算法稳定性框架分析RLHF的泛化性质。在特征覆盖条件下，证明策略模型经验最优解的泛化误差界，并将结果推广到梯度上升和随机梯度上升等梯度学习算法。

Result: 证明在特征覆盖条件下，策略模型的泛化误差为O(n^{-1/2})。该结果可推广到梯度上升和随机梯度上升算法获得的参数，为RLHF后大语言模型观察到的泛化现象提供了新的理论证据。

Conclusion: 本文建立了RLHF对齐大语言模型的泛化理论框架，在特征覆盖条件下证明了O(n^{-1/2})的泛化误差界，为实践中观察到的RLHF泛化效果提供了理论支持，填补了现有理论研究的空白。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [7] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，通过推理增强预测和基于置信度的结果校正来解决罕见事件预测中的类别不平衡问题，显著提升精度并降低相关成本。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程、客户支持、航空安全等领域，罕见事件预测至关重要，但极端的类别不平衡会使传统模型偏向多数类预测，限制召回率、校准性和实际应用价值。

Method: LPCORP采用两阶段框架：首先使用推理模型从叙事输入中生成增强预测，然后通过轻量级逻辑回归分类器评估并选择性校正这些输出，以减轻流行度驱动的偏差。

Result: 该方法将高度不平衡的设置转化为平衡设置，同时保留原始样本数量且无需任何重采样策略。测试集评估显示性能显著提升，特别是在低流行度数据中通常较弱的精度指标方面。成本降低分析显示在某些情况下可减少超过50%的费用。

Conclusion: LPCORP有效解决了罕见事件预测中的类别不平衡问题，通过推理增强和选择性校正显著提升预测性能，并在实际应用中展示了显著的成本节约潜力。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [8] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 本文改进了经典的Vapnik-Chervonenkis定理，通过使用带有显式Berry-Esseen误差控制的正态逼近代替Hoeffding不等式，得到了更精确的中等偏差估计，在ε√n较大时，主要指数项中增加了(ε√n)^{-1}因子。


<details>
  <summary>Details</summary>
Motivation: 经典VC定理使用Hoeffding不等式作为最后一步，作者希望改进这一概率论证部分，通过更精确的正态逼近方法来获得更尖锐的估计结果。

Method: 重新审视经典VC定理的概率论证部分，使用带有显式Berry-Esseen误差控制的正态逼近方法替代传统的Hoeffding不等式。

Result: 得到了VC估计的中等偏差锐化结果，当ε√n较大时，在主要指数项中增加了(ε√n)^{-1}因子，提供了更精确的收敛速率估计。

Conclusion: 通过改进概率论证方法，获得了比经典VC定理更精确的均匀收敛速率估计，特别是在中等偏差区域，为机器学习理论提供了更精细的分析工具。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [9] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强的临床深度学习工具包，旨在通过简化代码、统一框架和社区支持来降低临床AI研究的门槛。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基准难以复现、计算成本高、需要领域专业知识等持续障碍，阻碍了研究进展和应用。

Method: 开发PyHealth 2.0工具包，提供统一框架整合多种数据集、任务、模型和解释方法，支持多模态临床数据，优化计算效率，并建立活跃的开源社区。

Result: 工具包实现7行代码完成预测建模，处理速度提升39倍，内存使用降低20倍，支持从16GB笔记本到生产系统的计算环境，拥有400+成员的活跃社区。

Conclusion: PyHealth 2.0为可访问、可复现的医疗AI建立了开源基础和社区，降低了临床AI研究的门槛。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [10] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 本文比较了贝叶斯实验设计中KL散度和Wasserstein距离两种效用函数准则，指出Wasserstein距离存在位置依赖性问题，而KL散度在无模型误差时收敛更快，Wasserstein距离在存在模型误差时更稳健。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计(BED)为科学发现提供了原则性的信息框架，但效用函数的选择一直是一个活跃的研究课题。虽然KL散度是最常见的选择，但最近的研究提出了Wasserstein距离作为替代。本文旨在系统比较这两种准则，揭示它们在不同情况下的优缺点。

Method: 首先使用一个简单示例说明Wasserstein距离的问题：固定形状的后验分布中，Wasserstein距离的值取决于其主要质量在支撑集中的相对位置，可能产生与信息增益无关的虚假奖励。然后通过BED文献中的经典源反演问题，系统比较这两种准则在不同条件下的表现。

Result: 研究发现：1) Wasserstein距离存在位置依赖性问题，特别是在使用非信息先验（如均匀分布）时；2) 在没有模型误差的情况下，KL散度倾向于导致更快的收敛；3) 如果模型误差不可忽略，Wasserstein度量提供更稳健的顺序BED结果。

Conclusion: 这些发现阐明了KL散度和Wasserstein度量作为效用函数的权衡，为实际BED应用中选择合适的准则提供了指导。选择应基于具体应用场景中是否存在模型误差等因素。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [11] [Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction](https://arxiv.org/abs/2601.16426)
*Shuang Wu,Meijie Wang,Lun Yu*

Main category: cs.LG

TL;DR: 该论文研究了气味相关性质建模中的蒸汽压(VP)和气味阈值(OP)两个任务，采用Bemis-Murcko骨架分割评估模型OOD能力，比较了GINE和PNA架构，并提出"安全多任务"学习方法。


<details>
  <summary>Details</summary>
Motivation: 研究气味相关性质建模中的两个重要任务：蒸汽压(VP)和气味阈值(OP)，评估模型在分布外(OOD)场景下的能力，并解决多任务学习中辅助任务可能损害主要任务性能的问题。

Method: 采用Bemis-Murcko骨架分割评估OOD能力；引入A20/E17分子图特征(20维原子特征+17维键特征)；系统比较GINE和PNA架构；提出"安全多任务"方法：以VP为主要任务，OP为辅助任务，采用延迟激活+梯度裁剪+小权重策略。

Result: VP任务：PNA架构在验证集上MSE≈0.21(归一化空间)；OP单任务：使用A20/E17特征和鲁棒训练达到Val MSE≈0.60-0.61；多任务：安全多任务方法在避免损害主要任务的同时，获得了最佳的VP泛化性能。

Conclusion: 论文提供了完整的可重复实验、消融研究和误差相似性分析，讨论了数据噪声的影响和方法局限性，提出的安全多任务方法在多任务学习中有效平衡了主要任务和辅助任务的关系。

Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.

</details>


### [12] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: Endless Terminals是一个完全自主的管道，能够程序化生成终端使用任务，无需人工标注。使用简单的PPO训练代理，在多个模型上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前终端基准测试主要用于评估而非训练，强化学习需要一个可扩展的管道而不仅仅是数据集。环境是自改进代理的瓶颈。

Method: 提出Endless Terminals管道，包含四个阶段：生成多样化任务描述、构建和验证容器化环境、生成完成测试、筛选可解任务。使用简单的PPO训练，仅使用二元回合级奖励，没有检索、多代理协调或专门工具。

Result: 生成了3255个任务，涵盖文件操作、日志管理、数据处理、脚本编写和数据库操作。训练后模型性能显著提升：在开发集上，Llama-3.2-3B从4.0%提升到18.2%，Qwen2.5-7B从10.7%提升到53.3%，Qwen3-8B-openthinker-sft从42.6%提升到59.0%。在TerminalBench 2.0上也有显著改进。

Conclusion: 当环境能够规模化时，简单的强化学习就能成功。Endless Terminals展示了通过程序化生成训练环境可以显著提升终端代理的性能，即使使用简单的训练方法。

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [13] [Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network](https://arxiv.org/abs/2601.16446)
*George Awiakye-Marfo,Elijah Agbosu,Victoria Mawuena Barns,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 该论文提出了BrownianReLU激活函数，通过布朗运动机制改善LSTM网络在金融时间序列中的梯度传播和学习稳定性，相比传统ReLU类激活函数有更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数如ReLU、LeakyReLU和PReLU在处理噪声大、非平稳的金融时间序列时存在梯度不稳定问题，特别是"dying ReLU"问题，需要更稳定的激活函数来提升深度学习模型在金融预测中的性能。

Method: 提出BrownianReLU激活函数，基于布朗运动机制设计，使用蒙特卡洛模拟实现平滑、自适应的负输入响应。在LSTM网络中应用该激活函数，并在苹果、GCB、标普500等金融时间序列数据以及LendingClub贷款分类数据上进行评估。

Result: BrownianReLU在金融时间序列预测中表现出更低的均方误差和更高的R²值，表明预测准确性和泛化能力得到改善。在分类任务中，虽然ROC-AUC指标有限，但激活函数选择显著影响准确性和敏感性的权衡，BrownianReLU取得了实际有意义的性能。

Conclusion: BrownianReLU激活函数通过布朗运动机制有效缓解了传统ReLU类激活函数在金融时间序列中的梯度不稳定问题，提升了LSTM网络的预测性能和稳定性，为金融时间序列建模提供了更有效的激活函数选择。

Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.

</details>


### [14] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 浮点Transformer在有限精度计算下具有与传统理论不同的表达能力：无需位置编码即可表示非置换等变函数，在序列长度有限时可表示所有置换等变函数，但长序列时无法实现。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer表达能力研究基于实数参数和精确运算，但实际计算机实现使用有限精度浮点数和含舍入误差的机器运算。需要研究浮点Transformer在真实计算环境下的表达能力。

Method: 分析使用浮点参数和浮点运算的Transformer模型，研究其在有限精度计算条件下的数学性质，包括置换等变性、位置编码影响等。

Result: 1) 浮点Transformer无需位置编码即可表示非置换等变函数；2) 序列长度有限时可表示所有置换等变函数，但长序列时无法实现；3) 发现浮点Transformer的最小等变结构；4) 所有非平凡加法位置编码都会损害浮点Transformer的表达能力。

Conclusion: 浮点Transformer在有限精度计算下表现出与传统理论不同的表达能力特性，位置编码在浮点运算环境下可能损害模型表达能力，这对实际Transformer实现有重要启示。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [15] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 该论文分析了对抗鲁棒性和分布鲁棒性之间的权衡关系，发现ℓ∞扰动在适度偏置数据上能提升分布鲁棒性，特征可分性在此过程中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 尽管对抗鲁棒性和分布鲁棒性都旨在确保模型性能的可靠性，但先前研究发现两者存在权衡关系。对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，特别是在某些代表性不足的子群体上。本文旨在深入理解这种权衡关系及其背后的机制。

Method: 通过理论分析研究在扰动数据上训练的模型，为每步对抗训练提供了一个可处理的替代方案。分析了ℓ∞扰动在不同偏置程度数据上的影响，特别关注特征可分性在权衡关系中的作用。

Result: 研究发现：1）对抗鲁棒性和分布鲁棒性之间存在权衡关系；2）ℓ∞扰动在适度偏置数据上能提高分布鲁棒性；3）在高度偏斜数据上，当简单性偏置诱导模型依赖核心特征（特征可分性较高）时，分布鲁棒性的增益仍然存在。

Conclusion: 理论分析扩展了对权衡关系的理解，强调了特征可分性在对抗鲁棒性和分布鲁棒性权衡中的关键作用。尽管权衡关系在许多情况下仍然存在，但忽视特征可分性的作用可能导致对鲁棒性的误导性结论。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [16] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE自监督学习框架整合FreeSurfer特征，在阿尔茨海默病预测任务中超越传统方法和现有SSL方法，其脑年龄差指标显示高遗传性和与神经退行性及脑血管过程相关的生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 当前阿尔茨海默病（AD）的早期检测和监测需要更敏感且具有生物学基础的生物标志物。结构MRI虽然广泛可用，但通常依赖手工特征（如皮层厚度或体积）。现有自监督学习方法在疾病分类、转化预测和淀粉样蛋白状态预测方面表现不如FreeSurfer衍生特征。

Method: 提出残差噪声对比估计（R-NCE）自监督学习框架，整合辅助FreeSurfer特征，同时最大化增强不变性信息。该方法利用结构MRI数据，通过对比学习提取更有信息量的特征表示。

Result: R-NCE在多个基准测试中超越传统FreeSurfer特征和现有SSL方法，包括AD转化预测。R-NCE衍生的脑年龄差（BAG）指标显示高遗传性，并与MAPT和IRAG1基因相关，在星形胶质细胞和少突胶质细胞中富集，表明对神经退行性和脑血管过程敏感。

Conclusion: R-NCE能够从结构MRI中发现更强大的AD生物标志物，不仅提升预测性能，而且具有生物学相关性，为AD早期检测和监测提供了有前景的新方法。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [17] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MCDC方法，通过多粒度竞争惩罚学习(MGCPL)和基于编码的聚类聚合(CAME)来解决分类数据聚类中的嵌套粒度簇效应问题，实现自动探索多粒度簇分布。


<details>
  <summary>Details</summary>
Motivation: 分类数据在聚类分析中面临挑战：由于分类特征值是定性的，无法明确定义距离空间，而分类数据中普遍存在嵌套粒度簇效应（小簇形成大簇），需要有效方法处理这种多粒度聚类结构。

Method: 提出MCDC方法：1) MGCPL算法让潜在簇通过竞争惩罚学习在不同粒度上交互调整和收敛；2) CAME策略基于MGCPL编码将数据对象编码为嵌入表示，然后在嵌入空间进行最终聚类。

Result: MCDC能够自动探索多粒度簇的嵌套分布，对各种领域的分类数据集具有高度鲁棒性，线性时间复杂度使其可扩展到大规模数据集，实验证明其在多个真实公共数据集上优于现有方法。

Conclusion: MCDC方法有效解决了分类数据聚类中的嵌套粒度簇问题，通过多粒度竞争学习和编码聚合策略实现了高效、可扩展的聚类，适用于大规模数据集的预处理和分布式计算加速。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [18] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: BoostFGL是一个公平感知的联邦图学习框架，通过客户端节点增强、拓扑增强和服务器端模型增强三个机制，解决联邦图学习中弱势节点群体性能下降的问题，在保持整体性能的同时显著提升公平性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽然整体准确率高，但会掩盖弱势节点群体的严重性能下降问题。这种不公平性源于三个耦合因素：标签偏向多数模式、消息传播中的拓扑混淆，以及困难客户端更新的聚合稀释。

Method: BoostFGL采用提升式框架，包含三个协调机制：1) 客户端节点增强：重塑本地训练信号，强调系统性服务不足的节点；2) 客户端拓扑增强：重新分配传播重点，偏向可靠但未充分利用的结构，减弱误导性邻域；3) 服务器端模型增强：执行难度和可靠性感知的聚合，保留困难客户端的有效更新同时稳定全局模型。

Result: 在9个数据集上的广泛实验表明，BoostFGL带来显著的公平性提升，将Overall-F1提高了8.43%，同时在整体性能上保持与强大联邦图学习基线的竞争力。

Conclusion: BoostFGL通过协调的客户端和服务器端增强机制，有效解决了联邦图学习中的公平性问题，在保持整体性能的同时显著改善了弱势节点群体的表现，为公平感知的联邦图学习提供了有效解决方案。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [19] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出自适应图模型，通过HNSW图与预计算投票机制，将邻居选择和权重计算完全转移到训练阶段，实现推理速度与精度的解耦。


<details>
  <summary>Details</summary>
Motivation: kNN算法在大规模应用中面临推理速度与精度的计算权衡问题，现有近似最近邻解决方案虽然加速检索但会降低分类精度，且缺乏自适应选择最优邻居数量(k)的能力。

Method: 集成分层可导航小世界(HNSW)图与预计算投票机制，构建自适应图模型。高层图实现快速导航，低层图编码精确的节点特定决策边界和自适应邻居数量，将邻居选择和权重计算完全转移到训练阶段。

Result: 在六个不同数据集上对八个最先进基线进行基准测试，该架构显著加速推理速度，实现实时性能，同时不损害分类精度。

Conclusion: 为解决kNN长期存在的推理瓶颈提供了可扩展、鲁棒的解决方案，建立了基于图的非参数学习的新结构范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [20] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: 浅层Transformer在核机制下训练，宽度仅需对数级样本量，优化误差与序列长度无关，但内存需求随序列长度增长


<details>
  <summary>Details</summary>
Motivation: 理解Transformer为何表现优异仍然具有挑战性，因为其优化景观是非凸的。本研究旨在分析浅层Transformer在核机制下的训练行为，以揭示其优化特性。

Method: 分析具有m个独立头的浅层Transformer，使用投影梯度下降在核机制下训练。理论分析关注宽度与样本量的关系以及优化误差与序列长度的关系。

Result: 发现两个主要结果：(1) 非渐近保证所需的宽度仅随样本量n对数增长；(2) 优化误差与序列长度T无关。这与循环架构形成鲜明对比，后者的优化误差可能随T指数增长。代价是内存需求随序列长度增长。

Conclusion: Transformer在核机制下训练具有优越的优化特性：宽度需求低，优化误差与序列长度无关，但需要更多内存来保持完整上下文。这些理论结果在师生设置中得到数值验证。

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [21] [Rethinking Large Language Models For Irregular Time Series Classification In Critical Care](https://arxiv.org/abs/2601.16516)
*Feixiang Zheng,Yu Wu,Cecilia Mascolo,Ting Dang*

Main category: cs.LG

TL;DR: 本文系统评估了LLM在ICU不规则时间序列数据上的应用，发现编码器设计比对齐策略更重要，但LLM方法训练时间更长且在小样本场景下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在时间序列建模中展现出潜力，但其在ICU不规则数据（高缺失率）上的有效性尚未充分探索。本文旨在研究LLM在ICU时间序列中成功的关键组件：时间序列编码器和多模态对齐策略。

Method: 建立系统测试平台，评估不同最先进的基于LLM的方法在ICU基准数据集上的表现，与强监督和自监督基线进行比较。重点分析时间序列编码器设计（特别是显式建模不规则性的编码器）和多模态对齐策略的影响。

Result: 编码器设计比对齐策略更关键：显式建模不规则性的编码器比普通Transformer平均AUPRC提升12.8%。对齐策略影响较小：最佳融合策略比交叉注意力提升2.9%。但LLM方法训练时间至少比最佳不规则监督模型长10倍，性能仅相当，且在数据稀缺的小样本学习中表现不佳。

Conclusion: LLM在ICU不规则时间序列中既有潜力也有当前局限性。编码器设计是关键因素，但LLM方法在计算效率和少样本学习方面仍需改进。研究为未来LLM在医疗时间序列分析中的应用提供了重要见解。

Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.

</details>


### [22] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: DANCE提出了一种新的TAG-FGL范式，通过轮次式、模型在环的图压缩刷新机制提升性能，同时保留可解释的证据包来追踪预测来源，在8个数据集上实现了2.33%的准确率提升和33.42%的token减少。


<details>
  <summary>Details</summary>
Motivation: 当前TAG-FGL方法面临三个主要挑战：1) LLM处理长文本的高计算开销；2) 一次性图压缩导致非客户端自适应和次优性能；3) LLM压缩引入黑盒瓶颈，缺乏可解释性和可追溯性。

Method: DANCE采用轮次式、模型在环的图压缩刷新机制，使用最新的全局模型动态更新压缩核心。同时保留可本地检查的证据包，追踪预测到特定邻居和源文本片段，增强可解释性。

Result: 在8个TAG数据集上，DANCE在8%压缩比下实现了2.33%的准确率提升，同时比基线方法减少了33.42%的token使用量。

Conclusion: DANCE通过动态压缩刷新和可解释性证据包，有效解决了TAG-FGL中的性能次优和黑盒问题，为实用的文本属性图联邦学习提供了新范式。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [23] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: SARE：通过几何稳定化解决多模态LLM对象幻觉的结构脆弱性问题


<details>
  <summary>Details</summary>
Motivation: 多模态LLM存在对象幻觉问题，现有遗忘方法存在结构脆弱性缺陷，仅实现表面抑制，在轻微重新学习后幻觉会灾难性复发

Method: 提出SARE框架，将遗忘建模为目标最小-最大优化问题，使用Targeted-SAM机制在幻觉概念周围显式平坦化损失景观，通过模拟最坏情况参数扰动抑制幻觉

Result: SARE在遗忘效果上显著优于基线方法，同时保持一般生成质量，对重新学习和参数更新保持持久的幻觉抑制

Conclusion: 几何稳定化是解决多模态LLM对象幻觉问题的有效方法，SARE框架通过结构稳定性确保幻觉的持久消除

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [24] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键冲突不是Engram式条件记忆的主要瓶颈，消除冲突的碰撞自由设计并未持续改善验证损失，碰撞反而提供有益的隐式正则化


<details>
  <summary>Details</summary>
Motivation: 研究高频键冲突是否是Engram式条件记忆的主要瓶颈，探索消除冲突是否能改善模型性能

Method: 引入Engram-Nine碰撞自由热层扩展，通过最小完美哈希函数映射最频繁n-gram，保留原始多头哈希查找作为冷层，在严格等参数设置下比较性能，使用路由分层评估分解每个token损失为热/冷层贡献

Result: 碰撞自由设计未持续改善验证损失；发现训练中一致的"热到冷优势翻转"现象：热层位置初始损失较低，但冷层位置最终超越；碰撞自由配置比碰撞基线更早翻转，表明碰撞提供隐式正则化；门控机制存在不匹配：早期学习偏好热层位置，但翻转后仍保持此偏好

Conclusion: 仅提高查找精度不能保证更好的训练结果，主要限制可能在于门控信用分配而非索引准确性，碰撞引起的噪声可能提供有益的正则化效果，不应简单消除

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [25] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: JORC-UMAP：通过引入Ollivier-Ricci曲率几何先验和Jaccard相似性拓扑先验，改进UMAP在非线性降维中的表现，减少拓扑撕裂和结构坍塌问题。


<details>
  <summary>Details</summary>
Motivation: UMAP等非线性降维方法在可视化高维数据时，由于局部欧氏距离假设无法捕捉内在流形几何结构，导致拓扑撕裂和结构坍塌。研究发现UMAP对k近邻图的敏感性是主要原因。

Method: 提出JORC-UMAP方法：1）引入Ollivier-Ricci曲率作为几何先验，增强几何瓶颈处的边连接并减少冗余链接；2）由于曲率估计对噪声敏感，引入Jaccard相似性作为拓扑先验，确保邻域一致性；3）结合两种先验更好地区分真实流形结构与虚假连接。

Result: 在合成和真实数据集上的实验表明，JORC-UMAP比标准UMAP和其他降维方法更有效地减少撕裂和坍塌，通过SVM准确率和三元组保留分数衡量，同时保持计算效率。

Conclusion: JORC-UMAP为UMAP提供了几何感知的增强，能够实现更忠实的数据可视化，通过几何和拓扑先验的结合改进了非线性降维的质量。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [26] [Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability](https://arxiv.org/abs/2601.16563)
*Vasileios Sevetlidis,George Pavlidis*

Main category: cs.LG

TL;DR: 该论文提出将神经训练视为过程张量，引入基于可区分性回流的训练记忆见证方法，证明实际SGD偏离马尔可夫理想化，并提供测量框架比较优化器、课程和调度策略。


<details>
  <summary>Details</summary>
Motivation: 传统上神经网络训练常被理想化为马尔可夫过程，但实际训练中存在记忆效应。论文旨在开发一种原则性的诊断方法来量化训练记忆，证明实际SGD训练偏离马尔可夫假设，并提供测量框架来比较不同训练策略。

Method: 将神经训练建模为过程张量，引入基于可区分性回流的训练记忆见证方法。通过控制两步协议比较一次干预与两次干预后的结果分布，使用TV、JS、Hellinger距离测量softmax预测差异，通过ΔBF = D2 - D1 > 0来认证非马尔可夫性。

Result: 观察到一致的正向回流效应，具有紧密的自举置信区间；在高动量、更大批次重叠和更多微步时效应增强；在因果中断（重置优化器状态）时效应消失，证明效应源于优化器/数据状态记忆。该方法对TV/JS/Hellinger距离均稳健，计算成本低且无需架构修改。

Conclusion: 该工作提供了原则性的诊断方法和经验证据，证明实际SGD训练偏离马尔可夫理想化。框架为比较优化器、课程安排和调度策略提供了通用平台，将"数据顺序重要"转化为可测试的操作符，并展示了微观信号如何指导课程排序。

Abstract: This work proposes neural training as a \emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $Δ_{\mathrm{BF}} = D_2 - D_1>0$ (with $D\in\{\mathrm{TV}, \mathrm{JS}, \mathrm{H}\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. "Data order matters" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.

</details>


### [27] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出kNN-ICL框架，利用大语言模型进行初创公司成功预测，无需模型训练，仅需少量标注数据作为示例


<details>
  <summary>Details</summary>
Motivation: 早期初创公司成功预测面临数据稀缺挑战，风投公司通常只有几十个早期初创公司的信息，传统机器学习方法需要大量标注数据，在数据稀缺环境下效果有限

Method: 提出kNN-ICL框架，基于k近邻选择最相关的过往初创公司作为示例，利用大语言模型进行上下文学习，无需模型训练，仅使用少量标注数据作为演示示例

Result: 使用Crunchbase真实数据，kNN-ICL方法比监督机器学习基线和普通上下文学习获得更高的预测准确率；仅需50个示例即可达到较高的平衡准确率

Conclusion: 上下文学习可以作为风投公司在数据稀缺环境下的决策工具，kNN-ICL框架为早期初创公司成功预测提供了有效的解决方案

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [28] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 首个公开的芬兰铁路运营与气象观测融合数据集（2018-2024），包含3850万条观测记录，涵盖5915公里铁路网，可用于列车延误预测和天气影响分析。


<details>
  <summary>Details</summary>
Motivation: 现有数据集很少将气象信息与铁路运营数据整合，特别是在天气对铁路可靠性影响显著的北欧地区，缺乏公开可用的综合数据集。

Method: 整合芬兰Digitraffic铁路交通服务的运营指标和209个环境监测站的气象观测数据，通过Haversine距离进行时空对齐，包含28个工程特征，采用空间回退算法处理缺失数据、时间特征循环编码和稳健缩放。

Result: 冬季月份延误率超过25%，中北部芬兰存在高延误走廊的地理聚类；XGBoost回归基线实验在预测站点特定延误时达到2.73分钟的平均绝对误差。

Conclusion: 该数据集为机器学习应用提供了灵活资源，支持列车延误预测、天气影响评估和基础设施脆弱性映射等多种应用，填补了铁路运营研究中综合数据集的空白。

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [29] [E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory](https://arxiv.org/abs/2601.16622)
*Lin Huang,Chengxiang Huang,Ziang Wang,Yiyue Du,Chu Wang,Haocheng Lu,Yunyang Li,Xiaoli Liu,Arthur Jiang,Jia Zhang*

Main category: cs.LG

TL;DR: E2Former-V2是一个可扩展的等变图神经网络架构，通过代数稀疏化和硬件感知执行解决了主流EGNNs的可扩展性瓶颈，在保持预测性能的同时显著加速推理。


<details>
  <summary>Details</summary>
Motivation: 主流等变图神经网络（EGNNs）在建模3D原子系统时面临可扩展性瓶颈，因为需要在每条边上显式构建几何特征或进行密集张量积运算，这限制了模型的训练效率。

Method: 提出等变轴对齐稀疏化（EAAS），利用SO(3)→SO(2)基变换将计算密集的张量收缩转化为高效的稀疏奇偶重索引操作；在此基础上引入基于定制Triton内核的即时等变注意力机制，消除边张量物化并最大化SRAM利用率。

Result: 定制内核相比标准实现实现了20倍的TFLOPS提升；在SPICE和OMol25数据集上的实验表明，E2Former-V2在保持可比预测性能的同时显著加速推理；证明大型等变变压器可以在广泛可用的GPU平台上高效训练。

Conclusion: 通过结合代数稀疏化和硬件感知执行，E2Former-V2成功解决了EGNNs的可扩展性瓶颈，为高效训练大型等变变压器提供了可行的解决方案，代码已开源。

Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.

</details>


### [30] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一个模型无关的辅助框架，通过双原型自适应解耦机制，为时间序列预测模型提供模式解耦和上下文感知能力，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法通常通过修改架构或引入增强策略来提升预测性能，但往往无法动态解耦和利用时间序列中复杂交织的时序模式，导致学习到静态的、平均化的表示，缺乏上下文感知能力。

Method: 提出双原型自适应解耦框架（DPAD），包含：1）动态双原型库（DDP），包括具有强时序先验的通用模式库和动态记忆关键罕见事件的罕见模式库；2）双路径上下文感知路由（DPC）机制，从DDP中选择性检索上下文特定模式表示来增强输出；3）解耦引导损失（DGLoss），确保每个原型库专注于其指定角色同时保持全面覆盖。

Result: 综合实验表明，DPAD在各种真实世界基准测试中，能够一致地提升最先进模型的预测性能和可靠性。

Conclusion: DPAD作为一个模型无关的辅助方法，通过模式解耦和上下文感知适应，有效解决了现有方法在处理复杂交织时序模式时的局限性，显著提升了时间序列预测的性能和可靠性。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [31] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出PSCE方法，生成具有概率安全保证的反事实解释，确保在高模型更新频率的现实场景中保持有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，机器学习模型经常更新，现有的反事实解释会很快失效或不可靠，需要一种能够适应模型变化的反事实解释方法。

Method: 基于贝叶斯原理，提出概率安全反事实解释(PSCE)方法，生成δ-安全（确保高预测置信度）和ε-鲁棒（确保低预测方差）的反事实解释，并集成不确定性感知约束到优化框架中。

Result: 在多个数据集上验证，与最先进的贝叶斯反事实解释方法相比，PSCE生成的反事实解释不仅更合理、更具区分性，而且在模型变化下具有可证明的鲁棒性。

Conclusion: PSCE方法为反事实解释提供了正式的概率保证，确保其在模型更新时保持有效性，解决了现实场景中反事实解释失效的问题。

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [32] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种结合动态专家知识和模型平均的因果发现集成方法，利用LLM作为专家处理现实医疗数据中的假设违反问题


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要准确的因果模型来增强预测模型的可解释性，支持反事实推理和治疗效果估计。但现有因果发现算法众多且没有明确最佳选择，同时现实数据经常违反算法假设，过度依赖专家知识

Method: 提出灵活的模型平均方法，利用动态请求的专家知识（包括LLM作为专家）来集成多种因果发现算法。通过动态专家知识指导集成过程

Result: 实验证明该方法在使用不完美专家（如LLM）的情况下，在干净和噪声数据上都有效。分析了不同专家正确度的影响，并评估了LLM在临床因果发现中的能力

Conclusion: 该方法为实践者提供了有价值的见解，通过结合动态专家知识和算法集成，解决了现实医疗因果发现中的挑战，特别是当数据违反传统算法假设时

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [33] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种基于序列惩罚方法的学习算法，能够在深度学习中处理严格约束而非任意惩罚


<details>
  <summary>Details</summary>
Motivation: 许多学习任务中，对单个数据样本的处理要求应该被形式化为优化问题中的严格约束，而不是任意的惩罚项。需要一种能够正确处理约束的学习方法

Method: 采用序列惩罚方法进行学习，该方法允许适当处理约束条件

Result: 该算法在深度学习场景的合理假设下具有收敛保证，图像处理任务的实验结果表明该方法在实践中确实可行

Conclusion: 序列惩罚方法能够有效处理深度学习中的约束优化问题，具有理论保证和实践可行性

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [34] [Uncertainty propagation through trained multi-layer perceptrons: Exact analytical results](https://arxiv.org/abs/2601.16830)
*Andrew Thompson,Miles McCrory*

Main category: cs.LG

TL;DR: 本文推导了单隐藏层ReLU MLP在多元高斯输入下输出均值和方差的精确解析表达式，无需级数展开。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常使用级数展开近似处理不确定性在神经网络中的传播，缺乏精确解析解。本文旨在为单隐藏层ReLU MLP提供输入为多元高斯分布时输出统计量的精确表达式。

Method: 针对单隐藏层ReLU激活的多层感知机，在输入服从多元高斯分布的条件下，推导输出均值和方差的精确解析表达式，避免了传统的级数展开近似方法。

Result: 获得了输出均值和方差的精确解析表达式，相比基于级数展开的近似方法，提供了更准确的不确定性传播分析。

Conclusion: 本文为单隐藏层ReLU MLP在多元高斯输入下的不确定性传播提供了精确解析解，为神经网络的不确定性量化提供了理论基础。

Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.

</details>


### [35] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: ANPs替代传统机器学习方法，通过概率元学习框架结合局部观测和地理空间基础模型嵌入，实现更可靠的GEDI生物量制图不确定性校准


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林、XGBoost）在GEDI稀疏LiDAR观测插值中，将空间预测视为独立处理，无法适应异质景观的难度变化，导致预测区间校准失败。问题源于将集成方差与偶然不确定性混淆，并忽略局部空间上下文。

Method: 提出Attentive Neural Processes（ANPs）概率元学习框架，明确将预测条件化于局部观测集和地理空间基础模型嵌入。与静态集成不同，ANPs学习灵活的空间协方差函数，使不确定性估计在复杂景观中扩展，在均质区域收缩。

Result: 在从热带亚马逊森林到北方和高山生态系统的五个不同生物群落中验证，ANPs实现竞争性精度，同时保持接近理想的不确定性校准。通过少样本适应展示操作实用性，模型使用最少本地数据即可恢复跨区域转移的大部分性能差距。

Conclusion: ANPs为大陆尺度地球观测提供了可扩展、理论严谨的集成方差替代方案，解决了传统方法在异质景观中不确定性校准失败的问题。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [36] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 研究人员通过人类专家与LLM协作，改进了FunSearch算法的输出，在组合优化问题上取得了突破性进展，打破了多个问题长达十年的停滞状态。


<details>
  <summary>Details</summary>
Motivation: 探索人类专家与大型语言模型（LLM）协作在理论计算机科学开放问题中的潜力，特别是在组合优化领域，旨在突破长期停滞的研究瓶颈。

Method: 采用FunSearch算法生成初始解，然后通过人类专家对输出进行迭代精炼，针对分层k-中值聚类、装箱问题、背包问题和Lovász汽油问题推广等组合优化问题，生成使标准启发式算法表现不佳的对抗性实例。

Result: 在多个组合优化问题上获得了最先进的性能下界，其中一些问题已经十多年没有显著改进，打破了长期的研究停滞状态。

Conclusion: LLM能够提供关键初始模式，但人类专家对于将这些模式转化为数学严谨且有洞察力的构造至关重要，证明了LLM是数学和计算机科学研究中的强大协作工具。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [37] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 研究通过黑盒查询学习Transformer序列模型参数的问题，针对单头注意力提出多项式查询算法，证明多头注意力参数不可识别


<details>
  <summary>Details</summary>
Motivation: 研究如何仅通过黑盒访问Transformer模型的输出来学习其参数，这对于理解模型内部机制、模型压缩和逆向工程具有重要意义

Method: 1. 针对单头注意力提出O(d²)查询的简单算法；2. 利用压缩感知技术提出O(rd)查询的随机算法（r≪d时）；3. 研究噪声鲁棒性；4. 证明多头注意力参数不可识别

Result: 1. 单头注意力参数可通过O(d²)查询精确学习；2. 在r≪d时可通过O(rd)查询学习；3. 在温和条件下可容忍噪声；4. 多头注意力参数一般不可识别

Conclusion: 单头注意力模型参数可通过多项式查询学习，但多头注意力需要额外结构假设才能保证可识别性，为黑盒学习Transformer提供了理论基础

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [38] [Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks](https://arxiv.org/abs/2601.16880)
*Bethan Evans,Jared Tanner*

Main category: cs.LG

TL;DR: 论文推导了深度神经网络实现指定输出变化所需的最小范数权重扰动，分析了影响因素，并应用于后门攻击的压缩阈值证明


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络对权重扰动的敏感性，为模型鲁棒性提供理论保证，特别关注后门攻击场景下的压缩激活机制

Method: 推导单层精确公式计算最小范数权重扰动，对比多层Lipschitz常数鲁棒性保证，应用于精度修改激活的后门攻击分析

Result: 单层精确公式与多层Lipschitz保证具有相同量级，建立了后门攻击无法成功的可证明压缩阈值，低秩压缩能可靠激活潜在后门同时保持全精度准确率

Conclusion: 反向传播的边界控制层间敏感性，为与期望输出变化一致的最小参数更新提供可证明保证，揭示了模型压缩与安全性的重要关系

Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.

</details>


### [39] [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)
*Shijun Zhang,Zuowei Shen,Yuesheng Xu*

Main category: cs.LG

TL;DR: 多级深度学习（MGDL）通过逐级训练深度网络来结构化地减少近似误差，为深度网络训练提供了理论保证和稳定方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络训练面临高度非凸和病态优化问题，而浅层网络（特别是单隐藏层ReLU模型）可以通过凸优化获得全局保证。这促使研究者探索既能保持稳定性又能扩展到深层架构的学习范式。

Method: MGDL采用逐级训练策略：冻结已学习的层级，每个新的残差块专门训练以减少剩余近似误差，形成可解释的层次化精炼过程。该方法基于算子理论框架，证明了对于任意连续目标函数，存在固定宽度的多级ReLU方案，其残差在各级间严格递减并一致收敛到零。

Result: 该研究首次为逐级训练在深度网络中提供严格的理论保证，证明其能产生可证明的消失近似误差。数值实验进一步验证了理论结果。

Conclusion: MGDL为深度神经网络训练提供了一个原则性的结构化误差精炼框架，通过逐级训练实现了稳定、可解释的深度网络学习，并为该方法的有效性提供了严格的理论保证。

Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.

</details>


### [40] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的四大挑战：函数约束、通信瓶颈、本地更新和部分客户端参与，通过投影自由、仅需原始更新的方法实现高效优化。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中存在四大挑战：1）函数约束难以处理；2）通信瓶颈限制效率；3）多步本地更新带来复杂性；4）部分客户端参与导致采样噪声。现有方法通常单独处理这些问题，缺乏统一的理论框架。

Method: 基于切换梯度方法，FedSGM采用投影自由、仅需原始更新的设计。引入双向误差反馈来纠正压缩引入的偏差，并明确理解压缩噪声与多步本地更新之间的相互作用。还提出了软切换版本以在可行性边界附近稳定更新。

Result: 理论分析表明平均迭代达到经典的$\mathcal{O}(1/\sqrt{T})$收敛速率，并提供了高概率界限，将优化进展与部分参与带来的采样噪声解耦。在Neyman-Pearson分类和约束马尔可夫决策过程任务上的实验验证了理论保证。

Conclusion: FedSGM是首个统一处理函数约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础，并通过实验验证了其有效性。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [41] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 该研究评估了基于地理空间基础模型嵌入的方法在小农地区作物类型制图中的应用，发现TESSERA方法在性能、合理性、可迁移性和可访问性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前大多数基于卫星的作物类型制图方法不适合小农条件，需要开发适合小农地区的方法来支持粮食安全、生计和气候变化缓解。

Method: 建立了包含性能、合理性、可迁移性和可访问性四个标准的评估框架，比较了TESSERA和AlphaEarth两种地理空间基础模型嵌入方法与现有基线方法在塞内加尔花生盆地的应用。

Result: TESSERA方法在所有评估标准中表现最佳，在一个时间迁移示例中比次优方法的准确率高28%，表明其是塞内加尔作物类型分类和制图的有效方法。

Conclusion: 基于TESSERA嵌入的方法满足小农地区作物类型制图的需求标准，为粮食安全、生计支持和气候变化缓解提供了有效的遥感工具。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [42] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束保护MoE模型的路由稳定性，防止传统遗忘方法利用路由漏洞进行表面遗忘，强制从专家参数中真正擦除知识。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法无法有效应用于混合专家（MoE）架构，传统方法会利用MoE的路由漏洞，通过操纵路由将查询从知识专家处重定向，而不是真正擦除知识，导致模型效用损失和表面遗忘。

Method: 提出几何路由不变性保护（GRIP）框架，核心是几何约束：通过将路由梯度更新投影到专家特定的零空间中实现。这解耦了路由稳定性与参数刚性，保持离散专家选择稳定，同时允许连续路由参数在零空间内保持可塑性，强制遗忘优化直接从专家参数中擦除知识。

Result: 大规模MoE模型实验表明，GRIP适配器消除了专家选择偏移（实现超过95%的路由稳定性），同时保留了所有测试遗忘方法的效用。通过防止现有算法利用MoE模型的路由漏洞，GRIP将密集架构的遗忘研究适配到MoE架构。

Conclusion: GRIP作为一个算法无关的适配器框架，通过几何约束保护MoE模型的路由稳定性，强制遗忘过程真正从专家参数中擦除知识，而不是利用路由操纵的捷径，从而将现有遗忘研究成功扩展到MoE架构。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [43] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 本文提出TAC（轨迹对齐系数）作为评估奖励函数与专家偏好匹配程度的指标，并开发了Soft-TAC作为可微近似用于直接从人类偏好数据学习奖励模型。


<details>
  <summary>Details</summary>
Motivation: 强化学习的成功依赖于准确反映任务目标的奖励函数，但设计奖励函数耗时且容易出错。需要支持RL从业者指定合适的奖励权重，并减少手动奖励设计的劳动强度。

Method: 1）使用TAC指标评估奖励函数与专家偏好的对齐程度；2）进行人因研究，让RL从业者在Lunar Lander环境中使用TAC调整奖励权重；3）提出Soft-TAC作为TAC的可微近似，用作损失函数从人类偏好数据训练奖励模型；4）在Gran Turismo 7赛车模拟器中验证Soft-TAC。

Result: 1）提供TAC进行奖励调整的参与者产生了性能更好的奖励函数，并报告了更低的认知负荷；2）Soft-TAC训练的奖励模型成功捕捉了偏好特定的目标，产生了比标准交叉熵损失训练的模型具有更明显不同行为的策略。

Conclusion: TAC既可以作为指导奖励调整的实用工具，也可以作为复杂领域中奖励学习的目标。这项工作展示了TAC在支持RL从业者和自动化奖励学习方面的双重价值。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [44] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 提出一种基于等渗回归的单调校准方法，解决预训练嵌入空间中余弦相似度的各向异性问题，恢复绝对值的可解释性，同时保持排序相关性不变。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的余弦相似度虽然与人类判断有强排序相关性，但由于各向异性导致绝对值系统性误校准：无论实际语义相关性如何，分数都集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。

Method: 使用基于人类相似性判断训练的等渗回归，构建单调变换实现近乎完美的校准，同时保持排序相关性和局部稳定性（在七种扰动类型中达到98%）。该方法不改变余弦相似度本身，而是通过单调校准恢复其绝对值的可解释性。

Result: 等渗校准被证明是一种保序重参数化，所有基于排序的构造（角度排序、最近邻、阈值图和基于分位数的决策）在该变换下都是不变的。该方法在保持98%局部稳定性的同时实现了近乎完美的校准。

Conclusion: 通过单调校准可以恢复余弦相似度绝对值的可解释性，而不改变其排序特性，避免了修改嵌入空间几何结构或重新计算所有嵌入的需要，为预训练嵌入相似度提供了更实用的定量度量。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [45] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多群体学习在群体可实现设定下的样本复杂度优于不可知设定，即使群体族是无限的（只要VC维有限）。通过经验风险最小化实现改进，但计算上不可行，建议使用非适定学习替代。


<details>
  <summary>Details</summary>
Motivation: 研究多群体学习在不同设定下的样本复杂度差异，探索如何在群体族无限但VC维有限的情况下获得更好的学习效率。

Method: 使用群体可实现概念类的经验风险最小化方法，但发现该方法计算上不可行，因此提出基于非适定学习的替代方案。

Result: 在群体可实现设定下，即使群体族无限（只要VC维有限），样本复杂度也比不可知设定更好。但实现该方法的计算复杂度高。

Conclusion: 多群体学习在群体可实现设定下具有样本复杂度优势，但需要采用非适定学习等替代方法来解决计算可行性问题。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [46] [Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles](https://arxiv.org/abs/2601.16936)
*Anton Zamyatin,Patrick Indri,Sagar Malhotra,Thomas Gärtner*

Main category: cs.LG

TL;DR: BatchEnsemble声称能以低成本提供类似Deep Ensembles的不确定性估计，但研究发现其表现接近单模型基线，而非真正的集成方法


<details>
  <summary>Details</summary>
Motivation: 在资源受限和低延迟场景中，需要高效获取不确定性估计。Deep Ensembles能提供稳健的认知不确定性，但需要训练多个完整模型，成本高昂

Method: BatchEnsemble通过对共享基础网络应用学习的秩-1扰动，旨在以更低的参数和内存成本提供类似集成的认知不确定性

Result: BatchEnsemble不仅在性能上不如Deep Ensembles，而且在CIFAR10/10C/SVHN上的准确性、校准性和分布外检测方面与单模型基线接近。在MNIST上的控制研究发现成员在函数和参数空间上几乎相同

Conclusion: BatchEnsemble的行为更像单模型而非真正的集成方法，其成员缺乏实现不同预测模式的能力

Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.

</details>


### [47] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 将分子视为刚性基元集合，采用SE(3)等变生成模型进行3D分子生成，相比原子级方法减少生成步骤2-10倍，压缩表示3.5倍


<details>
  <summary>Details</summary>
Motivation: 传统3D分子生成在原子级别进行，但分子图生成常使用片段作为结构单元。受蛋白质结构生成中框架方法的启发，将片段化思想扩展到3D分子生成，将分子视为刚性基元集合

Method: 使用刚性基元表示分子，采用SE(3)-等变生成模型进行从头3D分子生成。该方法将分子分解为刚性结构单元，在等变框架下生成这些基元的空间排列

Result: 在多个基准测试中达到或超越现有最佳方法，在GEOM-Drugs上原子稳定性表现更优，生成步骤减少2-10倍，分子表示压缩3.5倍

Conclusion: 基于刚性基元的3D分子生成方法在保持性能的同时显著提高了效率，为分子设计提供了更高效的框架

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [48] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散过程重构为块级因果模型，统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型在语言建模中存在性能差距，需要更多训练迭代。作者希望结合自回归模型的训练效率和扩散模型的并行生成优势，缩小这一差距。

Method: 将掩码扩散过程重构为块级因果模型，设计严格因果、置换等变架构，在单个前向传播中计算所有条件概率。采用渐进置换训练方案，支持跨步并行生成策略。

Result: ARMD在标准语言建模基准上取得SOTA性能，优于现有扩散基线，且需要更少训练步骤。在并行文本生成方面建立新基准，有效缩小并行与顺序解码的性能差距。

Conclusion: ARMD成功统一了自回归训练效率和扩散并行生成，为语言建模提供了高性能且高效的解决方案，特别是在并行生成方面表现出色。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [49] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 该论文提出使用潜在扩散模型（LDM）进行物联网攻击数据增强，以解决基于机器学习的入侵检测系统中类别不平衡问题，相比现有方法在样本质量、多样性和计算效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 物联网入侵检测系统中，基于机器学习的方法面临良性流量与攻击流量类别严重不平衡的问题，导致性能下降。现有数据增强方法（如简单过采样或生成模型）难以同时实现高样本保真度、多样性和计算效率。

Method: 采用潜在扩散模型（LDM）进行物联网攻击数据增强，与最先进的基线方法进行全面比较。实验针对三种代表性物联网攻击类型（DDoS、Mirai、中间人攻击），评估下游IDS性能和内在生成质量，使用分布、依赖性和多样性指标。

Result: 使用LDM生成的样本平衡训练数据显著提高了IDS性能，DDoS和Mirai攻击的F1分数达到0.99，始终优于竞争方法。LDM能有效保持特征依赖性，生成多样化样本，采样时间比直接在数据空间运行的扩散模型减少约25%。

Conclusion: 潜在扩散模型是合成物联网攻击数据生成的有效且可扩展解决方案，能显著减轻物联网场景中基于机器学习的入侵检测系统的类别不平衡影响。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


### [50] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: 提出一种计算高效的临界锐度(λ_c)来替代计算昂贵的Hessian锐度，首次在大规模语言模型(7B参数)中展示了渐进锐化和稳定性边缘现象，并引入相对临界锐度来指导数据混合策略。


<details>
  <summary>Details</summary>
Motivation: Hessian锐度(λ_max^H)对于分析神经网络训练动态至关重要，但直接测量对于大型语言模型计算成本过高。需要一种计算高效的替代方法来在大规模训练中分析损失曲面的曲率演化。

Method: 提出临界锐度(λ_c)，仅需少于10次前向传播即可计算，基于参数更新方向Δθ。进一步引入相对临界锐度(λ_c^{1→2})来量化优化一个损失曲面时的另一个损失曲面的曲率。

Result: 首次在7B参数的OLMo-2模型上展示了渐进锐化和稳定性边缘现象，覆盖预训练和中训练阶段。相对临界锐度成功分析了从预训练到微调的过渡，并指导了数据混合策略。

Conclusion: 临界锐度为实践者提供了诊断曲率动态和指导大规模训练中数据组合选择的实用工具，证明了可扩展的曲率测量方法可以为大规模训练提供可操作的见解。

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [51] [LiDMaS: Architecture-Level Modeling of Fault-Tolerant Magic-State Injection in GKP Photonic Qubits](https://arxiv.org/abs/2601.16244)
*Dennis Delali Kwesi Wayo*

Main category: quant-ph

TL;DR: 研究光量子架构中GKP编码逻辑T门魔法态的制备，结合重复直到成功注入协议和表面码保护，开发轻量级密度矩阵模拟框架，分析压缩、光子损耗等参数对逻辑态保真度的影响。


<details>
  <summary>Details</summary>
Motivation: 在有限压缩和光子损耗的现实约束下，实现高保真度逻辑魔法态的制备对于光量子架构的容错量子计算至关重要。

Method: 开发基于标准数值线性代数的轻量级密度矩阵模拟框架，将有限压缩映射为有效逻辑退相，在逻辑层面包含退极化噪声，将光子损耗视为可探测擦除过程，避免显式连续变量波函数模拟。

Result: 在8-16dB压缩范围内，成功概率超过0.94，平均开销接近1；经过外部码保护后，逻辑保真度达到约0.77-0.80，对中等光子损耗敏感度弱但对压缩依赖性强；相边界分析确定了同时实现高成功概率和高逻辑保真度的最小压缩要求。

Conclusion: 该研究为可扩展光量子容错架构提供了定量设计指导，表明通过适当的压缩水平和表面码保护，可以在现实约束下实现有效的逻辑魔法态制备。

Abstract: Fault-tolerant quantum computation in photonic architectures relies on the efficient preparation of high-fidelity logical magic states under realistic constraints imposed by finite squeezing and photon loss. In this work, we study logical T-gate magic-state preparation in GKP-encoded photonic qubits using a repeat-until-success injection protocol combined with outer surface-code protection. We develop an architecture-level modeling framework based on a lightweight density-matrix simulator implemented with standard numerical linear algebra. Finite squeezing is mapped to effective logical dephasing, depolarizing noise is included at the logical level, and photon loss is treated as a heralded erasure process. This approach avoids explicit continuous-variable wavefunction simulation, hardware-specific photonic models, and quantum software frameworks, enabling transparent and computationally efficient exploration of architectural trade-offs. We perform systematic parameter sweeps over squeezing values from 8 to 16 dB, baseline loss probabilities between 0.01 and 0.03, and surface-code distances d = 1, 3, 5, and 7. Across this regime, we evaluate repeat-until-success probability, average injection overhead, and logical magic-state fidelity. We find that success probabilities exceed 0.94 across all studied parameters, with an average overhead close to unity. After outer-code protection, logical fidelities reach approximately 0.77 to 0.80 and show weak sensitivity to moderate photon loss but a strong dependence on squeezing. Phase-boundary analysis identifies minimum squeezing requirements needed to simultaneously achieve high success probability and logical fidelity. These results provide quantitative design guidance for scalable photonic fault-tolerant quantum architectures.

</details>


### [52] [Quantum Cellular Automata on a Dual-Species Rydberg Processor](https://arxiv.org/abs/2601.16257)
*Ryan White,Vikram Ramesh,Alexander Impertro,Shraddha Anand,Francesco Cesa,Giuliano Giudici,Thomas Iadecola,Hannes Pichler,Hannes Bernien*

Main category: quant-ph

TL;DR: 在双物种里德堡原子阵列上实现量子元胞自动机，利用全局控制实现多种量子协议，包括生成高保真度纠缠态


<details>
  <summary>Details</summary>
Motivation: 随着量子设备规模扩大，相干控制面临巨大挑战。量子元胞自动机框架可以绕过这个控制问题，仅使用静态量子比特阵列和全局控制操作就能实现通用动力学。

Method: 在铷和铯原子的双物种里德堡阵列上实现量子元胞自动机，利用每个物种的独立全局控制来执行多种量子协议。通过简单的脉冲序列探索多体动力学。

Result: 实现了多种纠缠态的生成：GHZ态、96.7(1.7)%保真度的贝尔态、17量子比特簇态和高连通性图态。展示了量子元胞自动机的多功能性和可扩展性。

Conclusion: 量子元胞自动机为通过全局控制扩展量子信息系统提供了有前景的途径，并为量子多体动力学提供了新的视角。

Abstract: As quantum devices scale to larger and larger sizes, a significant challenge emerges in scaling their coherent controls accordingly. Quantum cellular automata (QCAs) constitute a promising framework that bypasses this control problem: universal dynamics can be achieved using only a static qubit array and global control operations. We realize QCAs on a dual-species Rydberg array of rubidium and cesium atoms, leveraging independent global control of each species to perform a myriad of quantum protocols. With simple pulse sequences, we explore many-body dynamics and generate a variety of entangled states, including GHZ states, 96.7(1.7)%-fidelity Bell states, 17-qubit cluster states, and high-connectivity graph states. The versatility and scalability of QCAs offers compelling routes for scaling quantum information systems with global controls, as well as new perspectives on quantum many-body dynamics.

</details>


### [53] [Multi-invariants in stabilizer states](https://arxiv.org/abs/2601.16258)
*Sriram Akella,Abhijit Gadde,Jay Pandey*

Main category: quant-ph

TL;DR: 本文开发了计算稳定子态多部分纠缠度量（多不变量）的工具，包括高效数值算法、三部分态的显式公式、q部分态的计数论证，并揭示了与拓扑的有趣联系。


<details>
  <summary>Details</summary>
Motivation: 多部分纠缠是二分纠缠的自然推广，但相对理解不足。本文旨在开发计算稳定子态多部分纠缠度量的工具，特别是多不变量这一类别。

Method: 1. 开发了计算稳定子态多不变量的高效数值算法；2. 对于三部分稳定子态，利用GHZ提取定理得到了任意多不变量的显式公式；3. 提出了计算q部分稳定子态任意Coxeter多不变量的计数论证；4. 对受限类稳定子态（如环面码和X立方模型的基态）进一步简化公式。

Result: 1. 实现了稳定子态多不变量的高效计算；2. 获得了三部分稳定子态多不变量的显式公式；3. 提出了q部分稳定子态Coxeter多不变量的计数方法并推测了闭式表达式；4. 揭示了多不变量、稳定子态与拓扑之间的有趣联系。

Conclusion: 本文系统发展了计算稳定子态多部分纠缠度量的工具，为理解多部分纠缠提供了新方法，并揭示了与拓扑物理的有趣联系，对环面码、X立方模型等拓扑有序系统的研究具有重要意义。

Abstract: Multipartite entanglement is a natural generalization of bipartite entanglement, but is relatively poorly understood. In this paper, we develop tools to calculate a class of multipartite entanglement measures - known as multi-invariants - for stabilizer states. We give an efficient numerical algorithm that computes multi-invariants for stabilizer states. For tripartite stabilizer states, we also obtain an explicit formula for any multi-invariant using the GHZ-extraction theorem. We then present a counting argument that calculates any Coxeter multi-invariant of a q-partite stabilizer state. We conjecture a closed form expression for the same. We uncover hints of an interesting connection between multi-invariants, stabilizer states and topology. We show how our formulas are further simplified for a restricted class of stabilizer states that appear as ground states of interesting models like the toric code and the X-cube model.

</details>


### [54] [Quantum algorithm for simulating non-adiabatic dynamics at metallic surfaces](https://arxiv.org/abs/2601.16264)
*Robert A. Lang,Paarth Jain,Juan Miguel Arrazola,Danial Motlagh*

Main category: quant-ph

TL;DR: 该论文提出了一种用于模拟分子-金属界面非绝热动力学的量子算法，通过推广Anderson-Newns哈密顿量，实现了对包含大量电子态和核自由度的复杂系统的高效量子模拟。


<details>
  <summary>Details</summary>
Motivation: 分子-金属界面的非绝热动力学在异相催化、染料敏化太阳能转换和分子结电荷传输等众多技术应用中至关重要。传统经典计算方法在处理核运动与大量电子态耦合时计算成本过高，需要开发新的高效模拟方法。

Method: 作者推广了Anderson-Newns哈密顿量，开发了高度优化的量子算法，利用PennyLane软件平台进行资源估算，评估了算法在包含金属轨道、分子轨道和核自由度的模型系统中的实现成本。

Result: 资源估算显示，对于包含100个金属轨道、8个分子轨道和20个核自由度的模型系统，进行1000个Trotter步骤的时间演化仅需要271个量子比特和7.9×10^7个Toffoli门，表明该算法在首代容错量子计算机上具有可行性。

Conclusion: 该研究开发的量子算法为模拟分子-金属界面的非绝热动力学提供了高效解决方案，展示了量子计算在复杂化学系统模拟中的巨大潜力，特别是在首代容错量子计算机上的实际应用前景。

Abstract: Non-adiabatic dynamics at molecule-metal interfaces govern diverse and technologically important phenomena, from heterogeneous catalysis to dye-sensitized solar energy conversion and charge transport across molecular junctions. Realistic modeling of such dynamics necessitates taking into account various charge and energy transfer channels involving the coupling of nuclear motion with a very large number of electronic states, leading to prohibitive cost using classical computational methods. In this work we introduce a generalization of the Anderson-Newns Hamiltonian and develop a highly optimized quantum algorithm for simulating the non-adiabatic dynamics of realistic molecule-metal interfaces. Using the PennyLane software platform, we perform resource estimations of our algorithm, showing its remarkably low implementation cost for model systems representative of various scientifically and industrially relevant molecule-metal systems. Specifically, we find that time evolution for models including $100$ metal orbitals, $8$ molecular orbitals, and $20$ nuclear degrees of freedom, requires only $271$ qubits and $7.9 \times 10^7$ Toffoli gates for $1000$ Trotter steps, suggesting non-adiabatic molecule-metal dynamics as a fruitful application of first-generation fault-tolerant quantum computers.

</details>


### [55] [Post-processing optimization and optimal bounds for non-adaptive shadow tomography](https://arxiv.org/abs/2601.16266)
*Andrea Caprotti,Joshua Morris,Borivoje Dakić*

Main category: quant-ph

TL;DR: 提出一种优化POVM测量后处理的方法，通过凸优化找到最小化方差的重构系数，显著降低量子态估计的采样复杂度。


<details>
  <summary>Details</summary>
Motivation: 信息过完备的POVM测量在量子态层析和估计任务中优于最小完备测量，但存在经典自由度：相同可观测量可以从相同测量数据中获得无限多种无偏线性重构。如何选择最优重构系数以最小化方差是一个重要问题。

Method: 将重构系数选择问题形式化为凸极小极大问题，提出保证收敛的算法，返回固定POVM和可观测量下通过后处理可实现的最紧状态无关方差界。

Result: 数值实验显示，所得估计器相对于标准（规范）重构能显著降低采样复杂度，对于结构化的非对易目标，甚至能改善与系统尺寸相关的定性标度行为。

Conclusion: 通过优化POVM测量的后处理重构系数，可以大幅提升量子态估计的效率，特别是在处理大规模系统和非对易可观测量时表现出优越性能。

Abstract: Informationally overcomplete POVMs are known to outperform minimally complete measurements in many tomography and estimation tasks, and they also leave a purely classical freedom in shadow tomography: the same observable admits infinitely many unbiased linear reconstructions from identical measurement data. We formulate the choice of reconstruction coefficients as a convex minimax problem and give an algorithm with guaranteed convergence that returns the tightest state-independent variance bound achievable by post-processing for a fixed POVM and observable. Numerical examples show that the resulting estimators can dramatically reduce sampling complexity relative to standard (canonical) reconstructions, and can even improve the qualitative scaling with system size for structured noncommuting targets.

</details>


### [56] [Engineering Near-Infrared Two-Level Systems in Confined Alkali Vapors](https://arxiv.org/abs/2601.16269)
*Gilad Orr,Golan Ben-Ari,Eliran Talker*

Main category: quant-ph

TL;DR: 该研究在近红外通信波段实现了基于热铷蒸汽的紧凑型二能级原子系统，利用亚微米厚气室中的壁诱导弛豫效应，实现了可控的光-物质相互作用。


<details>
  <summary>Details</summary>
Motivation: 开发紧凑型原子平台，在通信波段实现可控的二能级原子系统，为集成量子光子技术（如片上量子存储器、通信波段频率基准和可扩展量子信息处理）提供实用途径。

Method: 采用实验与理论相结合的方法，使用亚微米厚气室限制热铷蒸汽，通过分析吸收和荧光光谱，研究壁诱导弛豫对原子相干性的影响，并利用封闭循环跃迁实现有效的二能级配置。

Result: 成功在通信波段实现了二能级原子系统，壁诱导弛豫抑制了光学泵浦到非耦合态，实现了稳健可控的光-物质相互作用，为紧凑型原子器件提供了实用方案。

Conclusion: 该研究为在紧凑型蒸汽池器件中实现近红外原子二能级系统建立了实用途径，为集成量子光子技术开辟了新机遇。

Abstract: We combined experimental and theoretical investigations of an effective two-level atomic system operating in the near-infrared telecom wavelength regime, realized using hot rubidium vapor confined within a sub-micron-thick cell. In this strongly confined geometry, atomic coherence is profoundly influenced by wall-induced relaxation arising from frequent atom-surface collisions. By analyzing both absorption and fluorescence spectra, we demonstrate that the optical response is dominated by a closed cycling transition, which effectively isolates the atomic dynamics to a two-level configuration despite the presence of multiple hyperfine states. This confinement-induced selection suppresses optical pumping into uncoupled states and enables robust, controllable light-matter interaction at telecom wavelengths within a miniature atomic platform. Our results establish a practical route to realizing near-infrared atomic two-level systems in compact vapor-cell devices, opening new opportunities for integrated quantum photonic technologies, including on-chip quantum memories, telecom-band frequency references, and scalable quantum information processing.

</details>


### [57] [Experimental observation of conformal field theory spectra](https://arxiv.org/abs/2601.16275)
*Xiangkai Sun,Yuan Le,Stephen Naus,Richard Bing-Shiun Tsai,Lewis R. B. Picard,Sara Murciano,Michael Knap,Jason Alicea,Manuel Endres*

Main category: quant-ph

TL;DR: 实验直接观测量子相变中涌现共形场论的能量激发谱，验证了Ising和tricritical Ising CFT的普适性能量比


<details>
  <summary>Details</summary>
Motivation: 共形场论在多个物理领域有重要应用，但许多理论预测的特征在实验中难以直接观测。需要开发新方法来验证量子相变中涌现的CFT特征。

Method: 开发调制技术解析里德堡链的有限尺寸谱；利用局域控制区分反射宇称；在tricritical Ising链中诱导不同边界条件对应的CFT谱转变；使用调制技术变体研究临界系统的动力学结构因子。

Result: 成功观测到Ising和tricritical Ising CFT的普适性能量比；区分了不同宇称的激发；实现了边界条件相关的CFT谱转变；测量了与Ising共形场关联相关的动力学结构因子。

Conclusion: 该工作不仅验证了量子模拟器中CFT特征的涌现，还为未来实验中诊断未知普适性类提供了技术手段。

Abstract: Conformal field theories (CFTs) feature prominently in high-energy physics, statistical mechanics, and condensed matter. For example, CFTs govern emergent universal properties of systems tuned to quantum phase transitions, including their entanglement, correlations, and low-energy excitation spectra. Much of the rich structure predicted by CFTs nevertheless remains unobserved in experiment. Here we directly observe the energy excitation spectra of emergent CFTs at quantum phase transitions -- recovering universal energy ratios characteristic of the underlying field theories. Specifically, we develop and implement a modulation technique to resolve a Rydberg chain's finite-size spectra, variably tuned to quantum phase transitions described by either Ising or tricritical Ising CFTs. We also employ local control to distinguish parities of excitations under reflection and, in the tricritical Ising chain, to induce transitions between distinct CFT spectra associated with changing boundary conditions. By utilizing a variant of the modulation technique, we furthermore study the dynamical structure factor of the critical system, which is closely related to the correlation of an underlying Ising conformal field. Our work not only probes the emergence of CFT features in a quantum simulator, but also provides a technique for diagnosing a priori unknown universality classes in future experiments.

</details>


### [58] [Exploring Noisy Quantum Thermodynamical Processes via the Depolarizing-Channel Approximation](https://arxiv.org/abs/2601.16317)
*Jian Li,Xiaoyang Wang,Marcus Huber,Nicolai Friis,Pharnam Bakhshinezhad*

Main category: quant-ph

TL;DR: 本文提出一个通用框架，用全局退极化通道近似门相关噪声的累积效应，并将其应用于热力学两排序算法冷却协议，推导出噪声下的渐近冷却极限。


<details>
  <summary>Details</summary>
Motivation: 量子热力学冷却协议会受到噪声和误差的显著影响，改变其性能和效率。随着系统规模增大，特别是在深度量子电路中，噪声会以复杂方式累积，使得分析表征这些影响变得极具挑战性。

Method: 引入一个通用框架，使用全局退极化通道来近似门相关噪声的累积效应，并指定该近似能够可靠描述噪声动力学的条件范围。

Result: 将该框架应用于热力学两排序算法冷却协议，解析推导出噪声存在下的渐近冷却极限。结果表明，最优冷却性能通过有限数量的量子比特实现（与传统无噪声TSAC协议需要无限量子比特不同），并推导出可达到的基态布居的基本界限。

Conclusion: 该方法为探索噪声量子热力学过程开辟了新途径，提供了一种处理复杂噪声累积效应的分析工具。

Abstract: Noise and errors are unavoidable in any realistic quantum process, including processes designed to reduce noise and errors in the first place. In particular, quantum thermodynamical protocols for cooling can be significantly affected, potentially altering both their performance and efficiency. Analytically characterizing the impact of such errors becomes increasingly challenging as the system size grows, particularly in deep quantum circuits where noise can accumulate in complex ways. To address this, we introduce a general framework for approximating the cumulative effect of gate-dependent noise using a global depolarizing channel. We specify the regime in which this approximation provides a reliable description of the noisy dynamics. Applying our framework to the thermodynamical two-sort algorithmic cooling (TSAC) protocol, we analytically derive its asymptotic cooling limit in the presence of noise. Using the cooling limit, the optimal cooling performance is achieved by a finite number of qubits--distinguished from the conventional noiseless TSAC protocol by an infinite number of qubits--and fundamental bounds on the achievable ground-state population are derived. This approach opens new avenues for exploring noisy quantum thermodynamical processes.

</details>


### [59] [Unambiguous randomness from a quantum state](https://arxiv.org/abs/2601.16343)
*Fionnuala Curran*

Main category: quant-ph

TL;DR: 论文研究了量子测量中内在随机性的量化问题，特别考虑了窃听者可能返回不确定结果的情况，提出了"明确随机性"的概念，并解决了二维系统和各向同性噪声情况下的具体计算问题。


<details>
  <summary>Details</summary>
Motivation: 传统量子随机性分析假设窃听者要么完全正确猜测测量结果，要么完全错误。但实际中窃听者可能有时返回不确定结果，类似于量子态区分中的"明确区分"概念。论文旨在量化这种更现实的窃听场景下的量子随机性。

Method: 引入"明确随机性"概念，量化窃听者可能返回不确定结果时的随机性。针对二维量子系统和任意维度的各向同性噪声态，在无偏基下进行测量，分析两种窃听场景：仅与噪声态相关的窃听者，以及与噪声态和噪声测量都相关的联合窃听者。

Result: 解决了二维系统和各向同性噪声情况下的明确随机性计算问题。发现给定相同总噪声量时，与噪声态和噪声测量都相关的联合窃听者总是优于仅与噪声态相关的窃听者。识别出一个临界误差参数，超过该参数时联合窃听者能达到完美猜测概率，完全消除私密随机性。

Conclusion: 论文扩展了量子随机性分析框架，考虑了窃听者可能返回不确定结果的更现实场景。结果表明，测量设备的噪声对私密随机性的影响比量子态本身的噪声更为关键，联合窃听模型能更有效地提取信息，这对量子随机数生成的安全性分析具有重要意义。

Abstract: Intrinsic randomness is generated when a quantum state is measured in any basis in which it is not diagonal. In an adversarial scenario, we quantify this randomness by the probability that a correlated eavesdropper could correctly guess the measurement outcomes. What if the eavesdropper is never wrong, but can sometimes return an inconclusive outcome? Inspired by analogous concepts in quantum state discrimination, we introduce the unambiguous randomness of a quantum state and measurement, and, relaxing the assumption of perfect accuracy, randomness with a fixed rate of inconclusive outcomes. We solve these problems for any state and projective measurement in dimension two, as well as for an isotropically noisy state measured in an unbiased basis of any dimension. In the latter case, we find that, given a fixed amount of total noise, an eavesdropper correlated only to the noisy state is always outperformed by an eavesdropper with joint correlations to both a noisy state and a noisy measurement. In fact, we identify a critical error parameter beyond which the joint eavesdropper achieves perfect guessing probability, ruling out any possibility of private randomness.

</details>


### [60] [Reducing TLS loss in tantalum CPW resonators using titanium sacrificial layers](https://arxiv.org/abs/2601.16369)
*Zachary Degnan,Chun-Ching Chiu,Yi-Hsun Chen,David Sommers,Leonid Abdurakhimov,Lihuang Zhu,Arkady Fedorov,Peter Jacobson*

Main category: quant-ph

TL;DR: 使用超薄钛牺牲层作为固态氧吸收剂，化学改性钽氧化物界面，显著降低超导谐振器的两级系统损耗，品质因子提升3倍以上


<details>
  <summary>Details</summary>
Motivation: 解决钽基超导量子电路中界面氧化物化学导致的相干性损失问题，特别是两级系统损耗对量子比特寿命的限制

Method: 在预溅射的α-钽上沉积0.2nm钛牺牲层作为固态氧吸收剂，化学改性金属-空气界面的原生钽氧化物，然后用缓冲氧化物蚀刻剂去除钛层，最后进行高真空退火

Result: 处理后的谐振器在单光子区域平均内部品质因子Qi超过150万（10个器件），比未使用钛层的相同器件提高3倍以上

Conclusion: 界面氧化物化学在超导损耗中起关键作用，原子尺度表面工程是提高钽基量子电路相干性的有效方法，该工艺与现有钽薄膜制造流程兼容

Abstract: We demonstrate a substantial reduction in two-level system loss in tantalum coplanar waveguide resonators fabricated on high-resistivity silicon substrates through the use of an ultrathin titanium sacrificial layer. A 0.2nm titanium film, deposited atop pre-sputtered α-tantalum, acts as a solid-state oxygen getter that chemically modifies the native Ta oxide at the metal-air interface. After device fabrication, the titanium layer is removed using buffered oxide etchant, leaving behind a chemically reduced Ta oxide surface. Subsequent high-vacuum annealing further suppresses two-level system loss. Resonators treated with this process exhibit internal quality factors Qi exceeding an average of 1.5 million in the single-photon regime across ten devices, over three times higher than otherwise identical devices lacking the titanium layer. These results highlight the critical role of interfacial oxide chemistry in superconducting loss and reinforce atomic-scale surface engineering as an effective approach to improving coherence in tantalum-based quantum circuits. The method is compatible with existing fabrication workflows applicable to tantalum films, offering a practical route to further extending T1 lifetimes in superconducting qubits.

</details>


### [61] [Subspace-Confined QAOA with Generalized Dicke States for Multi-Channel Allocation in 5G CBRS Networks](https://arxiv.org/abs/2601.16396)
*Gunsik Min,Youngjin Seo,Jun Heo*

Main category: quant-ph

TL;DR: 提出一种针对CBRS多信道分配的量子优化算法，通过子空间约束的QAOA变体，将搜索空间从2^24大幅压缩到2916个可行配置，在保持高可行性的同时快速收敛到低冲突分配。


<details>
  <summary>Details</summary>
Motivation: CBRS频段的高效频谱共享对最大化5G网络容量至关重要。传统QAOA使用惩罚项处理多信道约束，导致大部分希尔伯特空间对应无效分配，搜索效率低下。

Method: 提出子空间约束的QAOA变体：每个节点信道寄存器初始化为广义Dicke态，在XY混合器下演化，将动力学限制在Johnson图的张量积中，精确编码每个节点的汉明权重约束。

Result: 在8节点CBRS干扰图（24量子比特）上，搜索空间从2^24压缩到2916个可行配置。算法快速收敛到低冲突分配，无需大惩罚系数。在最多8节点的实例中，该方案达到接近最优的冲突水平，在可行性方面始终优于标准惩罚基QAOA和贪婪经典启发式算法。

Conclusion: 子空间约束的QAOA变体能有效处理CBRS多信道分配问题，在保持高可行性的同时显著提高搜索效率。噪声模拟表明，即使在NISQ相关的错误机制下，约束保持结构仍能维持高可行性比率。

Abstract: Efficient spectrum sharing in the Citizens Broadband Radio Service (CBRS) band is essential for maximizing 5G network capacity, particularly when high-traffic base stations require simultaneous access to multiple channels. Standard formulations of the Quantum Approximate Optimization Algorithm (QAOA) impose such multi-channel constraints using penalty terms, so most of the explored Hilbert space corresponds to invalid assignments. We propose a subspace-confined QAOA tailored to CBRS multi-channel allocation, in which each node-wise channel register is initialized in a Generalized Dicke state and evolved under an intra-register XY mixer. This ansatz confines the dynamics to a tensor product of Johnson graphs that exactly encode per-node Hamming-weight constraints. For an 8-node CBRS interference graph with 24 qubits, the effective search space is reduced from the full Hilbert space of size $2^{24}$ to 2916 feasible configurations. Within this subspace, the algorithm converges rapidly to low-conflict assignments without large penalty coefficients. Simulations on instances with up to eight nodes show that the proposed ansatz achieves near-optimal conflict levels and consistently outperforms standard penalty-based QAOA and a greedy classical heuristic in terms of feasibility. Noise simulations with depolarizing channels further indicate that the constraint-preserving structure maintains a high feasibility ratio in NISQ-relevant error regimes.

</details>


### [62] [Low-Loss, High-Coherence Airbridge Interconnects Fabricated by Single-Step Lithography](https://arxiv.org/abs/2601.16416)
*Jibang Fu,Bo Ren,Jiandong Ouyang,Cong Li,Kechengqi Zhu,Yonggang Che,Xiang Fu,Shichuan Xue,Zhaohua Yang,Mingtang Deng,Junjie Wu*

Main category: quant-ph

TL;DR: 单步电子束光刻制备纳米级空气桥，用于量子器件三维互连，显著提升超导量子比特性能


<details>
  <summary>Details</summary>
Motivation: 传统多步制备方法阻碍微型化并引入工艺缺陷，需要简化纳米级空气桥制造流程以实现高性能三维互连

Method: 采用单步电子束光刻，优化多层抗蚀剂堆叠和三层曝光剂量方案，结合热回流步骤，实现亚200纳米特征尺寸的平滑悬浮金属桥

Result: 在超导transmon量子比特的梯度SQUID设计中，空气桥不引入可测量的额外弛豫时间T1损耗，同时使退相干时间T2*提高2.5倍

Conclusion: 这种高效方法为先进量子和纳米电子器件中集成高性能三维互连提供了实用途径

Abstract: Airbridges are essential for creating high-performance, low-parasitic interconnects in integrated circuits and quantum devices. Conventional multi-step fabrication methods hinder miniaturization and introduce process-related defects. We report a simplified process for fabricating nanoscale airbridges using only a single electron-beam lithography step. By optimizing a multilayer resist stack with a triple-exposure-dose scheme and a thermal reflow step, we achieve smooth, suspended metallic bridges with sub-200-nm features that exhibit robust mechanical stability. Fabricated within a gradiometric SQUID design for superconducting transmon qubits, these airbridges introduce no measurable additional loss in the relaxation time $T_1$, while enabling a 2.5-fold enhancement of the dephasing time $T_2^*$. This efficient method offers a practical route toward integrating high-performance three-dimensional interconnects in advanced quantum and nano-electronic devices.

</details>


### [63] [Circulant quantum channels and its applications](https://arxiv.org/abs/2601.16435)
*Bing Xie,Lin Zhang*

Main category: quant-ph

TL;DR: 本文介绍了一类循环量子信道，证明其像集恰好是循环矩阵集合，该信道是纠缠破坏的，可用于分析Bargmann不变量和相干性下界。


<details>
  <summary>Details</summary>
Motivation: 研究循环量子信道这一混合置换信道的子类，旨在分析其结构特性和操作性质，特别是其在简化量子关联擦除成本和量子信息处理中的应用潜力。

Method: 引入循环量子信道家族，证明其像集恰好是循环矩阵集合，分析该信道的纠缠破坏性质，并研究其在Bargmann不变量、ℓp-范数相干性下界和双粒子系统中的作用。

Result: 1. 循环量子信道的像集精确对应循环矩阵集合；2. 该信道是纠缠破坏的，相比一般混合置换信道显著降低量子关联擦除的资源成本；3. 可用于推导ℓp-范数相干性的更紧下界；4. 在双粒子系统中具有特定作用特征。

Conclusion: 循环量子信道作为混合置换信道的特殊子类，具有明确的结构特征和纠缠破坏性质，在量子信息处理中具有应用价值，特别是在简化量子关联擦除和相干性分析方面。

Abstract: This note introduces a family of circulant quantum channels -- a subclass of the mixed-permutation channels -- and investigates its key structural and operational properties. We show that the image of the circulant quantum channel is precisely the set of circulant matrices. This characterization facilitates the analysis of arbitrary $n$-th order Bargmann invariants. Furthermore, we prove that the channel is entanglement-breaking, implying a substantially reduced resource cost for erasing quantum correlations compared to a general mixed-permutation channel. Applications of this channel are also discussed, including the derivation of tighter lower bounds for $\ell_p$-norm coherence and a characterization of its action in bipartite systems.

</details>


### [64] [Gluing Randomness via Entanglement: Tight Bound from Second Rényi Entropy](https://arxiv.org/abs/2601.16454)
*Wonjun Lee,Hyukjoon Kwon,Gil Young Cho*

Main category: quant-ph

TL;DR: 通过局部随机酉操作，利用纠缠态生成近似随机量子态，误差由初始态的纠缠熵决定


<details>
  <summary>Details</summary>
Motivation: 随机量子态在量子信息处理中有广泛应用，但高效生成随机态是一个长期挑战。本研究旨在探索如何利用纠缠作为关键资源，通过局部操作生成全局随机态。

Method: 从纠缠态|ψ⟩出发，应用局部随机酉操作生成量子态集合。分析该集合形成近似态设计的误差，证明误差与初始态的第二Rényi纠缠熵相关。进一步扩展到相干自由操作和伪随机态生成。

Result: 证明生成的集合形成近似态设计，误差为Θ(e^{-𝒩₂(ψ)})，其中𝒩₂(ψ)是初始态的第二Rényi纠缠熵。该紧界也适用于相干自由操作时的第二Rényi相干熵。第二Rényi熵在所有α-Rényi熵中给出最紧的界。

Conclusion: 纠缠是局部随机酉操作生成全局随机态的关键资源。当限制在资源自由门时，生成随机态的质量完全由初始态的资源含量决定。第二Rényi熵可解释为使用资源自由操作生成随机性的最大容量。

Abstract: The efficient generation of random quantum states is a long-standing challenge, motivated by their diverse applications in quantum information processing tasks. In this work, we identify entanglement as the key resource that enables local random unitaries to generate global random states by effectively gluing randomness across the system. Specifically, we demonstrate that approximate random states can be produced from an entangled state $|ψ\rangle$ through the application of local random unitaries. We show that the resulting ensemble forms an approximate state design with an error saturating as $Θ(e^{-\mathcal{N}_2(ψ)})$, where $\mathcal{N}_2(ψ)$ is the second Rényi entanglement entropy of $|ψ\rangle$. Furthermore, we prove that this tight bound also applies to the second Rényi entropy of coherence when the ensemble is constructed using coherence-free operations. These results imply that, when restricted to resource-free gates, the quality of the generated random states is determined entirely by the resource content of the initial state. Notably, we find that among all $α$-Rényi entropeis, the second Rényi entropy yields the tightest bounds. Consequently, these second Rényi entropies can be interpreted as the maximal capacities for generating randomness using resource-free operations. Finally, moving beyond approximate state designs, we utilize this entanglement-assisted gluing mechanism to present a novel method for generating pseudorandom states in multipartite systems from a locally entangled state via pseudorandom unitaries in each of parties.

</details>


### [65] [Quantum phase estimation with optimal confidence interval using three control qubits](https://arxiv.org/abs/2601.16474)
*Kaur Kristjuhan,Dominic W. Berry*

Main category: quant-ph

TL;DR: 本文提出了一种更高效的方法来制备量子相位估计中使用的离散扁球序列态，通过矩阵乘积态表示和简单三量子比特操作实现，显著减少了控制寄存器的量子比特需求。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计是量子化学模拟中估计基态能量的重要算法，传统方法需要大量量子比特资源。随着早期容错量子计算机的出现，需要开发适用于有限逻辑量子比特资源的高效相位估计方法。

Method: 使用矩阵乘积态表示离散扁球序列态，发现键维度为4的MPS即可提供高精度近似。通过一系列简单的三量子比特操作高效制备该MPS态。当维度为2的幂次时，相位估计仅需3个量子比特的控制寄存器。

Result: 该方法在测试的所有维度（高达2^24）上都能提供高精度近似。相比先前工作，制备效率显著提高，特别适合早期容错量子计算机的有限量子比特资源。

Conclusion: 提出的方法大幅降低了量子相位估计的量子比特需求，使该算法更适合早期容错量子计算机的实现，为量子化学模拟等应用提供了更实用的解决方案。

Abstract: Quantum phase estimation is an important routine in many quantum algorithms, particularly for estimating the ground state energy in quantum chemistry simulations. This estimation involves applying powers of a unitary to the ground state, controlled by an auxiliary state prepared on a control register. In many applications the goal is to provide a confidence interval for the phase estimate, and optimal performance is provided by a discrete prolate spheroidal sequence. We show how to prepare the corresponding state in a far more efficient way than prior work. We find that a matrix product state representation with a bond dimension of 4 is sufficient to give a highly accurate approximation for all dimensions tested, up to $2^{24}$. This matrix product state can be efficiently prepared using a sequence of simple three-qubit operations. When the dimension is a power of 2, the phase estimation can be performed with only three qubits for the control register, making it suitable for early-generation fault-tolerant quantum computers with a limited number of logical qubits.

</details>


### [66] [Indefinite Causal Order from Failure-to-Glue: Contextual Semantics and Parametric Time](https://arxiv.org/abs/2601.16494)
*Partha Ghose*

Main category: quant-ph

TL;DR: 论文通过范畴论方法重新定义因果顺序的不确定性，提出七值上下文分类器，并将框架应用于量子引力背景，区分参数时间与几何时间，为因果顺序不确定性提供统一语言。


<details>
  <summary>Details</summary>
Motivation: 现有关于不确定因果顺序（ICO）的研究（如量子开关、过程矩阵、量子引力提案）对"不确定性"的含义及其与确定顺序解释的关系仍不清晰。论文旨在澄清这些概念，为比较不同ICO标准提供共同语言。

Method: 第一部分：使用范畴论方法，将确定顺序可解释性表述为粘合问题，将每个确定因果顺序视为上下文，引入紧凑的七值上下文分类器。第二部分：将该框架应用于量子引力背景，采用参数时间τ与几何时间分离的视角，从随机量子化角度解释自旋网络动力学。

Result: 建立了统一的ICO分析框架，能够明确区分上下文变化与真正的不确定性。在量子引力背景下，将ICO解释为粗粒度关系干预的参数顺序不确定性，即使微观更新过程在τ上有全局顺序。

Conclusion: 论文为比较不同ICO标准提供了共同语言，并精确阐明了"无隐藏确定顺序"的含义。通过区分参数时间与几何时间，为量子引力中的因果顺序不确定性提供了新的解释框架。

Abstract: Indefinite causal order (ICO) has been studied via higher-order quantum processes (e.g.\ the quantum switch), process matrices, and quantum-gravity proposals involving superposed causal structure, yet the meaning of ``indefiniteness'' and its relation to definite-order explanations often remain opaque.
  Part~I develops a category-theoretic formulation of definite-order explainability as a gluing problem: each definite causal ordering (a partial order/DAG type) is treated as a context, and causal separability amounts to a consistent global section (possibly after convex mixing), whereas causal nonseparability is a failure-to-glue. We also introduce a compact seven-valued contextual classifier -- an intuitionistic elaboration -- that separates variation across contexts from genuine indeterminacy.
  Part~II applies this framework to a quantum-gravity motivated setting where the fundamental time is a parametric ordering variable $τ$, distinct from geometric (spacetime) time. Adopting a stochastic-quantization perspective on spin-network dynamics (Hilbert space not assumed fundamental) and reading the Wheeler--DeWitt condition as an equilibrium/stationarity constraint, we interpret ICO as indeterminacy of the parametric order of coarse-grained relational interventions, even when the microscopic update process is globally ordered by $τ$. Together, the two parts provide a common language for comparing ICO criteria and for stating precisely what ``no hidden definite order'' means.

</details>


### [67] [The optimal strategy of two-photon interferometric sensing in diverse noise environments](https://arxiv.org/abs/2601.16517)
*Teng-fei Yan,Zhuo-zhuo Wang,Qi-qi Li,Peng-long Wang,Bai-hong Li,Rui-Bo Jin*

Main category: quant-ph

TL;DR: 该论文分析了两种双光子干涉测量技术（HOM和N00N态干涉）在不同噪声环境下的灵敏度，发现HOM干涉对相位噪声不敏感，而N00N态干涉敏感，为不同噪声场景下的量子传感应用提供了优化策略。


<details>
  <summary>Details</summary>
Motivation: 双光子干涉测量虽然具有超越经典极限的量子优势，但实际应用中噪声通常会削弱这种优势。需要分析不同双光子干涉方案对噪声的敏感性，为实际量子传感应用提供指导。

Method: 分析了两种典型的双光子干涉测量技术：Hong-Ou-Mandel（HOM）干涉和N00N态干涉。研究了它们在频谱分辨和非分辨检测模式下对相位噪声的敏感性，特别关注双光子频率差（HOM）和频率和（N00N态）的依赖关系。

Result: 发现HOM干涉对相位噪声不敏感，而N00N态干涉对相位噪声敏感。频谱分辨检测在两种干涉测量中都优于非分辨检测，特别是在超过双光子相干时间的范围内。这为不同噪声环境下的量子传感应用提供了优化选择。

Conclusion: 研究结果为实际噪声环境中双光子干涉测量的应用提供了优化策略：HOM干涉适用于噪声较大的环境，N00N态干涉适用于低噪声环境，且频谱分辨检测通常能获得更好的性能。

Abstract: Quantum sensing based on two-photon interferometry manifests quantum superiority beyond the classical precision limit. However, this superiority is usually diminished inevitably by the noise. Here, we analyze the sensitivity of two typical two-photon interferometries to the noise, that is, Hong-Ou-Mandel (HOM) and N00N state interferometry. It is found that HOM (N00N state) interference, which depends on the biphoton frequency difference (sum), is insensitive (sensitive) to the phase noise in both the manners of spectrally non-resolved and resolved detections in practice, suggesting their potential applications of sensing for different noise scenarios. Furthermore, spectrally resolved detection outperforms spectrally non-resolved one for the two interferometries, especially for the scope that exceeds the coherence time of biphotons. The findings provide an optimal strategy for the practical applications of two-photon interferometric sensing in diverse noise environments.

</details>


### [68] [Drive-Through Quantum Gate: Non-Stop Entangling a Mobile Ion Qubit with a Stationary One](https://arxiv.org/abs/2601.16537)
*Ting Hsu,Wen-Han Png,Kuan-Ting Lin,Ming-Shien Chang,Guin-Dar Lin*

Main category: quant-ph

TL;DR: 提出一种新型纠缠方案，在静止离子量子比特和连续传输的移动离子之间实现纠缠，避免传统离子穿梭中的加热问题，实现0.01%量级的门误差


<details>
  <summary>Details</summary>
Motivation: 传统量子电荷耦合器件(QCCD)中离子穿梭过程会产生严重加热，需要大量时间和激光功率进行重新冷却和稳定化，限制了可扩展性

Method: 提出静止离子量子比特与连续均匀运动的移动离子之间的纠缠方案，移动离子保持匀速运动以最小化运动加热，理论上分析门误差

Result: 理论上证明可以实现0.01%量级的门误差，在当前技术可达范围内，支持资源高效的量子操作和长距离纠缠分布

Conclusion: 该方案为超越QCCD范式的替代性囚禁离子架构铺平道路，静止离子阵列作为存储单元，移动离子作为通信量子比特

Abstract: Towards the scalable realization of a quantum computer, a quantum charge-coupled device (QCCD) based on ion shuttling has been considered a promising approach. However, the processes of detaching an ion from an array, reintegrating it, and driving non-uniform motion introduce severe heating, requiring significant time and laser power for re-cooling and stabilization. To mitigate these challenges, we propose a novel entangling scheme between a stationary ion qubit and a continuously transported mobile ion, which remains in uniform motion and minimizes motional heating. We theoretically demonstrate a gate error on the order of 0.01%, within reach of current technology. This approach enables resource-efficient quantum operations and facilitates long-distance entanglement distribution, where stationary trapped-ion arrays serve as memory units and mobile ions act as communication qubits passing beside them. Our results pave the way for an alternative trapped-ion architecture beyond the QCCD paradigm.

</details>


### [69] [Quantum graph resonances by cut-off technique](https://arxiv.org/abs/2601.16545)
*Pavel Exner,Jiří Lipovský,Jan Pekař*

Main category: quant-ph

TL;DR: 通过截断系统的本征值行为识别量子图中共振态


<details>
  <summary>Details</summary>
Motivation: 量子图由紧致核心和半无限引线组成，其共振态在散射理论中很重要，但直接计算困难。需要发展通过截断系统本征值来识别共振的方法。

Method: 将半无限引线截断为有限长度，研究截断系统的本征值行为。当截断长度增加时，本征值会趋近于共振位置，通过分析本征值的收敛模式来识别共振。

Result: 证明了截断系统的本征值行为可以可靠地识别量子图中的共振态。本征值在适当条件下收敛到共振位置，提供了计算共振的有效数值方法。

Conclusion: 通过截断系统的本征值分析是识别量子图共振态的有效方法，为研究开放量子系统的散射特性提供了实用工具。

Abstract: We demonstrate how resonances in a quantum graph consisting of a compact core and semi-infinite leads can be identified from the eigenvalue behavior of the cut-off system.

</details>


### [70] [Certification of quantum properties with imperfect measurements](https://arxiv.org/abs/2601.16570)
*Leonardo Zambrano,Teodor Parella-Dilmé,Antonio Acín,Donato Farina*

Main category: quant-ph

TL;DR: 提出一种考虑测量噪声和有限统计误差的量子态凸函数认证方法


<details>
  <summary>Details</summary>
Motivation: 量子技术的进步需要精确表征量子系统，特别是量子态凸函数的认证在许多应用中至关重要。现有方法通常假设完美测量控制，但实际实验中存在测量缺陷和统计噪声。

Method: 扩展置信区域方法以容纳测量不完美性，结合凸优化技术对函数值进行边界估计，提供量化有限统计噪声和测量缺陷影响的明确方案。

Result: 开发出同时考虑统计误差和系统误差的鲁棒认证框架，能够处理实际实验中的测量不完美性和有限数据统计问题。

Conclusion: 该方法为量子实验提供了更现实的认证框架，通过联合处理统计和系统误差，提高了量子态凸函数认证的鲁棒性和实用性。

Abstract: The accurate characterization of quantum systems is essential for the advancement of quantum technologies. In particular, certifying convex functions of quantum states plays a central role in many applications. We present a certification method for experimentally prepared quantum states that accounts for both shot noise and measurement imperfections in the data-acquisition stage. Building upon previous work, our method extends confidence regions to accommodate imperfect control over measurements. The values of the functions can then be bounded using convex optimization techniques. We provide explicit prescriptions for quantifying the noise contribution from finite statistics and for estimating the effect of measurement imperfections. By jointly incorporating statistical and systematic errors, the method yields a robust certification framework for quantum experiments.

</details>


### [71] [Efficient quantum machine learning with inverse-probability algebraic corrections](https://arxiv.org/abs/2601.16665)
*Jaemin Seo*

Main category: quant-ph

TL;DR: 提出一种用于量子神经网络训练的反概率代数学习框架，通过概率空间的局部逆问题直接映射预测与目标概率差异到参数修正，无需梯度下降，收敛更快且对噪声鲁棒。


<details>
  <summary>Details</summary>
Motivation: 传统量子神经网络训练依赖基于梯度的过程优化，存在收敛慢、对超参数敏感、在尖锐最小值附近不稳定等问题，特别是在含噪声的近量子设备上训练困难。

Method: 提出反概率代数学习框架：将学习视为概率空间的局部逆问题，通过雅可比矩阵的伪逆直接映射预测与目标Born规则概率的差异到参数修正，无需学习率调优，单步即可接近损失最小值。

Result: 在回归和分类任务的师生量子神经网络基准测试中，代数学习比梯度下降和Adam优化收敛显著更快，能逃离损失平台，达到更低的最终误差。在有限采样下具有接近最优的误差缩放，对退相等硬件噪声保持鲁棒。

Conclusion: 反概率代数学习为量子神经网络训练提供了原理性和实用的替代方案，特别适用于资源受限的近量子设备，避免了过程优化的许多缺点。

Abstract: Quantum neural networks (QNNs) provide expressive probabilistic models by leveraging quantum superposition and entanglement, yet their practical training remains challenging due to highly oscillatory loss landscapes and noise inherent to near-term quantum devices. Existing training approaches largely rely on gradient-based procedural optimization, which often suffers from slow convergence, sensitivity to hyperparameters, and instability near sharp minima. In this work, we propose an alternative inverse-probability algebraic learning framework for QNNs. Instead of updating parameters through incremental gradient descent, our method treats learning as a local inverse problem in probability space, directly mapping discrepancies between predicted and target Born-rule probabilities to parameter corrections via a pseudo-inverse of the Jacobian. This algebraic update is covariant, does not require learning-rate tuning, and enables rapid movement toward the vicinity of a loss minimum in a single step. We systematically compare the proposed method with gradient descent and Adam optimization in both regression and classification tasks using a teacher-student QNN benchmark. Our results show that algebraic learning converges significantly faster, escapes loss plateaus, and achieves lower final errors. Under finite-shot sampling, the method exhibits near-optimal error scaling, while remaining robust against intrinsic hardware noise such as dephasing. These findings suggest that inverse-probability algebraic learning offers a principled and practical alternative to procedural optimization for QNN training, particularly in resource-constrained near-term quantum devices.

</details>


### [72] [Charging of a Quantum Battery by a Single-Photon Quantum Pulse](https://arxiv.org/abs/2601.16671)
*Elnaz Darsheshdar,Seyed Mostafa Moniri*

Main category: quant-ph

TL;DR: 研究量子电池充电的最小模型：使用二能级系统作为充电器，耦合到作为量子电池的谐振子，通过单光子量子脉冲激发二能级系统，然后将其激发转移到隔离的电池中。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池充电的基本物理机制，探索如何通过量子脉冲优化能量存储，理解量子系统中的能量转移效率和速度极限。

Method: 构建由二能级系统（充电器）和谐振子（电池）组成的最小模型，使用单光子量子脉冲激发二能级系统，分析系统动力学，推导最优脉冲形状和充电时间。

Result: 获得了电池动力学的解析解，确定了最大化存储能量的最优脉冲形状，该脉冲达到了由二能级系统向脉冲和环境衰减率决定的普适上界。在异常点处推导了最小充电时间和量子速度极限。

Conclusion: 该研究建立了量子电池充电的基本理论框架，揭示了量子脉冲优化和速度极限的物理机制，为量子能量存储系统的设计和优化提供了理论基础。

Abstract: We study a minimal model for charging a quantum battery consisting of a two-level system (TLS) acting as a charger, coupled to a harmonic oscillator that serves as the quantum battery. A single-photon quantum pulse of light excites the TLS, which subsequently transfers its excitation to the isolated battery. The TLS may also decay into the electromagnetic environment. We obtain analytical solutions for the dynamics of the battery and determine the optimal pulse shape that maximizes the stored energy. The optimal pulse saturates a universal bound for the stored energy, determined by the TLS decay rates into the pulse and the environment. Furthermore, we derive the minimum charging time and establish a quantum speed limit at the exceptional point, where a critical transition occurs in the system's dynamics. We also present analytical expressions for the charging power and investigate the pulse duration that maximizes it.

</details>


### [73] [Classical Regularization in Variational Quantum Eigensolvers](https://arxiv.org/abs/2601.16679)
*Yury Chernyak,Ijaz Ahamed Mohammad,Martin Plesch*

Main category: quant-ph

TL;DR: 该论文研究了在变分量子算法（VQA）中使用经典L2正则化来缓解优化不稳定性和贫瘠高原问题，通过在VQE目标函数中添加参数平方范数惩罚项，无需修改量子电路即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算机在规模和精度上仍有限制，变分量子算法（VQA）结合经典优化和量子计算评估成本函数，但面临贫瘠高原和病态优化景观问题，导致收敛不稳定和对初始化敏感。作者旨在探索经典L2正则化是否能系统性地稳定混合量子-经典优化。

Method: 在变分量子本征求解器（VQE）目标函数中增加与参数平方范数成正比的二次惩罚项（L2正则化），不修改量子电路或测量过程。在H2、LiH和随机场伊辛模型（RFIM）等多种哈密顿量上进行大规模数值测试。

Result: 在所有测试的哈密顿量中，在正则化强度的广泛窗口内观察到性能提升。经典正则化提供了稳健、系统无关的机制来缓解VQE不稳定性，增强了变分量子优化的可靠性和可重复性。

Conclusion: 经典L2正则化是稳定变分量子算法优化的有效方法，无需修改量子电路即可显著改善性能，为解决VQA中的优化挑战提供了简单而强大的工具。

Abstract: While quantum computers are a very promising tool for the far future, in their current state of the art they remain limited both in size and quality. This has given rise to hybrid quantum-classical algorithms, where the quantum device performs only a small but vital part of the overall computation. Among these, variational quantum algorithms (VQAs), which combine a classical optimization procedure with quantum evaluation of a cost function, have emerged as particularly promising. However, barren plateaus and ill-conditioned optimization landscapes remain among the primary obstacles faced by VQAs, often leading to unstable convergence and high sensitivity to initialization. Motivated by this challenge, we investigate whether a purely classical remedy, standard L2 squared-norm regularization, can systematically stabilize hybrid quantum-classical optimization. Specifically, we augment the Variational Quantum Eigensolver (VQE) objective with a quadratic penalty proportional to the squared norm of the parameters, without modifying the quantum circuit or measurement process. Across all tested Hamiltonians, H2, LiH, and the Random Field Ising Model (RFIM), we observe improved performance over a broad window of the regularization strength. Our large-scale numerical results demonstrate that classical regularization provides a robust, system-independent mechanism for mitigating VQE instability, enhancing the reliability and reproducibility of variational quantum optimization without altering the underlying quantum circuit.

</details>


### [74] [Sparsity-dependent Complexity Lower Bound of Quantum Linear System Solvers](https://arxiv.org/abs/2601.16697)
*Hitomi Mori,Yuta Kikuchi,Marcello Benedetti,Matthias Rosenkranz*

Main category: quant-ph

TL;DR: 该论文建立了量子线性系统求解器查询复杂度的严格下界Ω(κ√s)，填补了包含稀疏度s依赖性的理论空白。


<details>
  <summary>Details</summary>
Motivation: 量子线性系统求解器是量子计算中的基础算法，其性能通常用查询复杂度衡量。现有下界Ω(κlog(1/ε))未包含稀疏度s的依赖关系，而学界普遍认为应有Ω(κ√s log(1/ε))的下界，但缺乏严格证明。作者旨在填补这一理论空白。

Method: 作者通过理论分析建立了量子线性系统求解器查询复杂度的严格下界证明。他们证明了对于任何能以常数误差求解量子线性系统的量子算法，其查询复杂度下界为Ω(κ√s)。

Result: 论文证明了量子线性系统求解器查询复杂度的下界为Ω(κ√s)，其中κ是条件数，s是稀疏度。这一结果首次严格建立了包含稀疏度依赖性的下界，为完全表征QLS复杂度提供了关键基础。

Conclusion: 该工作填补了量子线性系统求解器复杂度理论的重要空白，建立了包含稀疏度依赖性的严格下界Ω(κ√s)。虽然包含所有参数κ,s,ε的完全表征仍是开放问题，但这一结果为理解QLS算法的基本限制提供了关键进展。

Abstract: Quantum linear system (QLS) solvers are a fundamental class of quantum algorithms used in many potential quantum computing applications, including machine learning and solving differential equations. The performance of quantum algorithms is often measured by their query complexity, which quantifies the number of oracle calls required to access the input. The main parameters determining the complexity of QLS solvers are the condition number $κ$ and sparsity $s$ of the linear system, and the target error $ε$. To date, the best known query-complexity lower bound is $Ω(κ\log(1/ε))$, which establishes the optimality of the most recent QLS solvers. The original proof of this lower bound is attributed to Harrow and Kothari, but their result is unpublished. Furthermore, when discussing a more general lower bound including the sparsity $s$ of the linear system, it has become folklore that it should read as $Ω( κ\sqrt{s}\log(1/ε))$. In this work, we establish the rigorous lower bound capturing the sparsity dependence of QLS. We prove the lower bound of $Ω(κ\sqrt{s})$ for any quantum algorithm that solves QLS with constant error. While the dependence on all parameters $κ,s,ε$ remains an open problem, our result provides a crucial stepping stone toward the complete characterization of QLS complexity.

</details>


### [75] [Entanglement harvesting in the presence of cavities](https://arxiv.org/abs/2601.16698)
*Jannik Ströhle,Nikolija Momcilovic*

Main category: quant-ph

TL;DR: 研究腔体中纠缠收获，分析圆柱形腔体中两个高斯探测器通过电磁场耦合的纠缠特性，发现纠缠对腔长敏感但对半径不敏感，揭示光锥内外不同参数标度规律，以及腔诱导宇称对纠缠的强影响。


<details>
  <summary>Details</summary>
Motivation: 目前纠缠收获研究主要集中在自由空间，缺乏对腔体环境下的系统分析。腔体结构可能显著改变纠缠收获特性，需要深入研究腔体几何参数和场宇称对称性对纠缠收获的影响。

Method: 采用绝热耦合方法，将量子化电磁场与位于圆柱形腔体对称轴上的两个相同高斯探测器耦合。结合解析分析和数值模拟，研究腔长、半径等几何参数对纠缠收获的影响，分析光锥内外参数标度规律。

Result: 数值研究发现：1）纠缠收获对腔长有强依赖性，但在最大纠缠状态下对腔半径变化不敏感；2）光锥内外探测器系统参数呈现不同的标度规律；3）腔诱导的电磁场宇称对称性对收获的相关性有强烈影响。

Conclusion: 腔体环境显著改变纠缠收获特性，腔长和场宇称对称性是关键影响因素。这些发现为腔量子电动力学中的纠缠操作提供了重要见解，并可能应用于量子信息处理中的腔增强纠缠生成。

Abstract: So far, entanglement harvesting has been extensively studied in free space setups. Here, we provide a detailed analytical and numerical analysis of entanglement harvesting in cavities. Specifically, we adiabatically couple the quantized electromagnetic field to two identical Gaussian detectors located on the symmetry axis of a cylindrical cavity. Our numerical investigations reveal a strong dependence on the cavity length, while showing invariance under changes in the cavity radius in regimes of maximal entanglement. Moreover, we identify different scalings of the detector system parameters for entanglement inside and outside the light cone. Finally, we uncover a strong dependence of the harvested correlations on the cavity induced parity of the electromagnetic field.

</details>


### [76] [SeeMPS: A Python-based Matrix Product State and Tensor Train Library](https://arxiv.org/abs/2601.16734)
*Paula García-Molina,Juan José Rodríguez-Aldavero,Jorge Gidi,Juan José García-Ripoll*

Main category: quant-ph

TL;DR: SeeMPS是一个基于矩阵乘积态（MPS）和量化张量列（QTT）的Python张量网络算法库，用于处理指数级大向量空间的压缩计算。


<details>
  <summary>Details</summary>
Motivation: 传统量子多体物理应用和量子启发数值分析问题（如求解PDE、多维函数插值与积分、多元概率分布采样等）需要处理指数级大向量空间，需要高效的压缩计算工具。

Method: 基于MPS/TT形式构建完整的有限精度线性代数包，通过张量网络压缩指数级大向量空间，支持从低级别操作（向量加法、线性变换、Hadamard积）到高级算法（线性方程近似、特征值计算、指数高效傅里叶变换）。

Result: 开发了SeeMPS库，实现了基于MPS/QTT的张量网络算法，能够处理传统量子多体物理和量子启发数值分析问题。

Conclusion: SeeMPS为处理指数级大向量空间的压缩计算提供了有效的Python工具，适用于量子物理和数值分析领域。

Abstract: We introduce SeeMPS, a Python library dedicated to implementing tensor network algorithms based on the well-known Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms. SeeMPS is implemented as a complete finite precision linear algebra package where exponentially large vector spaces are compressed using the MPS/TT formalism. It enables both low-level operations, such as vector addition, linear transformations, and Hadamard products, as well as high-level algorithms, including the approximation of linear equations, eigenvalue computations, and exponentially efficient Fourier transforms. This library can be used for traditional quantum many-body physics applications and also for quantum-inspired numerical analysis problems, such as solving PDEs, interpolating and integrating multidimensional functions, sampling multivariate probability distributions, etc.

</details>


### [77] [Noise Resilience and Robust Convergence Guarantees for the Variational Quantum Eigensolver](https://arxiv.org/abs/2601.16758)
*Mirko Legnini,Julian Berberich*

Main category: quant-ph

TL;DR: 该论文研究了噪声对变分量子本征求解器（VQE）收敛性的影响，分析了相干和非相干噪声对最优参数和成本的影响，并提供了理论分析和数值模拟。


<details>
  <summary>Details</summary>
Motivation: 虽然已有工作为VQE在理想条件下提供了全局收敛保证，但实际量子电路总会受到噪声影响。目前对噪声环境下VQE收敛特性的研究还很缺乏，需要系统分析噪声对算法收敛性的影响。

Method: 通过理论分析不同相干和非相干噪声过程对VQE最优参数和最优成本的影响，研究这些噪声对算法收敛保证的影响。同时使用Pennylane进行数值模拟来验证理论结果。

Result: 研究揭示了噪声如何影响VQE的最优参数和收敛特性，提供了对参数化量子电路在噪声环境下行为的理论洞察。数值模拟进一步验证了理论分析。

Conclusion: 该工作填补了噪声环境下VQE收敛性研究的空白，为理解参数化量子电路在实际噪声条件下的行为提供了重要理论依据，对变分量子算法的实际应用具有重要意义。

Abstract: Variational Quantum Algorithms (VQAs) are a class of hybrid quantum-classical algorithms that leverage on classical optimization tools to find the optimal parameters for a parameterized quantum circuit. One relevant application of VQAs is the Variational Quantum Eigensolver (VQE), which aims at steering the output of the quantum circuit to the ground state of a certain Hamiltonian. Recent works have provided global convergence guarantees for VQEs under suitable local surjectivity and smoothness hypotheses, but little has been done in characterizing convergence of these algorithms when the underlying quantum circuit is affected by noise. In this work, we characterize the effect of different coherent and incoherent noise processes on the optimal parameters and the optimal cost of the VQE, and we study their influence on the convergence guarantees of the algorithm. Our work provides novel theoretical insight into the behavior of parameterized quantum circuits. Furthermore, we accompany our results with numerical simulations implemented via Pennylane.

</details>


### [78] [Investigating Retargetability Claims for Quantum Compilers](https://arxiv.org/abs/2601.16779)
*Luke Southall,Joshua Ammermann,Rinor Kelmendi,Domenik Eichhorn,Ina Schaefer*

Main category: quant-ph

TL;DR: 本文提出并应用了一种评估量子编译器可重定向性的指标，对Tket、Qiskit和ProjectQ三个编译器进行了分析比较，发现Tket具有最高的可重定向性。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，不同硬件制造商采用不同的量子计算机架构，导致量子程序在不同硬件平台间的可移植性成为重要挑战。虽然已有多种可重定向量子编译器被提出，但缺乏评估这些编译器可重定向性的标准方法。

Method: 开发了一种评估量子编译器可重定向性的指标，并设计并运行了一项研究，分析Tket、Qiskit和ProjectQ三个编译器在可重定向性方面的关键特性。

Result: Tket表现出最高的可重定向性水平，Qiskit紧随其后，而ProjectQ相对落后。研究结果为量子软件开发者选择适合其用例的编译器提供了参考。

Conclusion: 该研究为评估量子编译器的可重定向性提供了实用指标，揭示了当前量子编译器在跨平台兼容性方面的现状，并指出了量子编译器需要改进的领域。

Abstract: In the NISQ-era, there is a wide variety of hardware manufacturers building quantum computers. Each of these companies may choose different approaches and hardware architectures for their machines. This poses a problem for quantum software engineering, as the retargetability of quantum programs across different hardware platforms becomes a non-trivial challenge. In response to this problem, various retargetable quantum compilers have been presented in the scientific literature. These promise the ability to compile software for different hardware platforms, enabling retargetability for quantum software. In this paper, we develop and apply a metric by which the retargetability of the quantum compilers can be assessed. We develop and run a study to analyze key aspects regarding the retargetability of the compilers Tket, Qiskit, and ProjectQ. Our findings indicate that Tket demonstrates the highest level of retargetability, closely followed by Qiskit, while ProjectQ lags behind. These results provide insights for quantum software developers in selecting appropriate compilers for their use-cases, and highlight areas for improvement in quantum compilers.

</details>


### [79] [Harnessing Quantum Computing for Energy Materials: Opportunities and Challenges](https://arxiv.org/abs/2601.16816)
*Seongmin Kim,In-Saeng Suh,Travis S. Humble,Thomas Beck,Eungkyu Lee,Tengfei Luo*

Main category: quant-ph

TL;DR: 量子计算在能源材料研发中的应用前景与挑战


<details>
  <summary>Details</summary>
Motivation: 传统计算方法在能源材料开发中面临扩展性和时间复杂性限制，特别是对于高维或强关联材料系统。量子计算利用量子比特的叠加和纠缠特性，有望解决经典方法难以处理的复杂问题。

Method: 结合量子计算与经典计算方法，用于实际能源材料的设计和模拟。展望了能够实现预测精度和量子优势的容错量子计算。

Result: 量子计算为能源材料研究提供了新的机遇，但面临解决复杂高维问题的挑战。量子-经典混合方法可以用于实际能源材料的设计和模拟。

Conclusion: 量子计算有望在能源材料领域带来范式转变，但要实现预测精度和量子优势，需要发展容错量子计算技术。量子-经典混合方法为当前阶段提供了实用路径。

Abstract: Developing high-performance materials is critical for diverse energy applications to increase efficiency, improve sustainability and reduce costs. Classical computational methods have enabled important breakthroughs in energy materials development, but they face scaling and time-complexity limitations, particularly for high-dimensional or strongly correlated material systems. Quantum computing (QC) promises to offer a paradigm shift by exploiting quantum bits with their superposition and entanglement to address challenging problems intractable for classical approaches. This perspective discusses the opportunities in leveraging QC to advance energy materials research and the challenges QC faces in solving complex and high-dimensional problems. We present cases on how QC, when combined with classical computing methods, can be used for the design and simulation of practical energy materials. We also outline the outlook for error-corrected, fault-tolerant QC capable of achieving predictive accuracy and quantum advantage for complex material systems.

</details>


### [80] [Protocols to share genuine multipartite entanglement employing copies of biseparable states](https://arxiv.org/abs/2601.16840)
*Swati Choudhary,Ujjwal Sen,Saronath Halder*

Main category: quant-ph

TL;DR: 三量子比特系统中，两个副本的二分可分但跨所有二分都纠缠的态，可以非零概率生成真多体纠缠态，这比三量子比特情况更高效，且能激活真非局域关联。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过集体使用二分可分态的副本（这些态在单副本层面缺乏真多体纠缠，但在所有二分上都纠缠）来共享真多体纠缠，这在量子信息处理协议中具有重要作用，被称为真多体纠缠激活。

Method: 提出一个针对三量子比特系统的协议，使用两个副本的秩为2的二分可分态（在所有二分上都纠缠），通过不依赖联合测量的方式，以非零概率生成真多体纠缠态，并将协议推广到任意数量的参与方。

Result: 与三量子比特场景需要多个副本不同，三量子比特系统中仅需两个副本的二分可分态就能生成真多体纠缠态。该构造还能自然地激活真非局域关联，这比单纯的真多体纠缠激活更强。

Conclusion: 展示了通过集体使用二分可分态副本激活真多体纠缠的可行性，特别是在三量子比特系统中仅需两个副本，且该方法还能激活更强的真非局域关联，为量子信息处理提供了新工具。

Abstract: Sharing genuine multipartite entanglement by considering collective use of copies of biseparable states, which are entangled across all bipartitions but lack genuine multipartite entanglement at the single-copy level, plays a central role in several quantum information processing protocols, and has been referred as genuine multipartite entanglement activation. We present a protocol for three-qutrit systems showing that two copies of rank-two biseparable states, entangled across every bipartition, are sufficient to generate a genuinely multipartite entangled state with nonzero probability. This contrasts with the three-qubit scenario where many copies of biseparable states might be required for sharing genuine multipartite entanglement. We subsequently generalize our protocols to the case of an arbitrary number of parties. Our protocol does not rely on the implementation of joint measurements on the copies of states. Interestingly, the proposed construction naturally leads to the activation of genuinely nonlocal correlations, yielding a result that is stronger than genuine multipartite entanglement activation alone.

</details>


### [81] [Generation of fully phase controlled two-photon entangled states](https://arxiv.org/abs/2601.16875)
*Ian Ford,Adrien Amour,Matthias Keller*

Main category: quant-ph

TL;DR: 利用单个钙离子与光学腔耦合，实现了对相位完全可控的双光子纠缠态生成，保真度达82%


<details>
  <summary>Details</summary>
Motivation: 利用囚禁离子作为理想系统生成单光子和双光子态，通过离子与光学腔耦合实现高效的单模光子发射和对其时间形状、相位、频率的控制

Method: 采用单个⁴⁰Ca⁺离子与光学腔耦合，利用离子内部态的长相干时间，通过保护离子-腔相互作用的相干性方案，先生成离子-光子纠缠，再生成第二个光子将离子态映射到第二个光子上，通过调整驱动场实现纠缠态相位的完全控制

Result: 成功生成了相位完全可控的双光子纠缠态，保真度最高达到82%

Conclusion: 该方案以最资源高效的方式实现了对双光子纠缠态相位的完全控制，为量子信息处理提供了重要工具

Abstract: Control over the internal states of trapped ions makes them the ideal system to generate single and two-photon states. Coupling a single ion to an optical cavity enables efficient emission of single photons into a single spatial mode and grants control over their temporal shape, phase and frequency. Using the long coherence time of the ion's internal states and employing a scheme to protect the coherence of the ion-cavity interaction, we demonstrate the generation of a two-photon entangled state with full control over the phase. Initially, ion-photon entanglement is generated. A second photon is subsequently generated, mapping the ion's state onto the second photon. By adjusting the drive field the phase of the entangled state can be fully controlled. We implement this scheme in the most resource efficient way by utilizing a single $^{40}$Ca$^+$ ion coupled to an optical cavity and demonstrate the generation of a two-photon entangled stated with full phase control with a fidelity of up to 82\%.

</details>


### [82] [Quantum Position Verification with Remote Untrusted Devices](https://arxiv.org/abs/2601.16892)
*Gautam A. Kavuri,Yanbao Zhang,Abigail R. Gookin,Soumyadip Patra,Joshua C. Bienfang,Honghao Fu,Yusuf Alnawakhtha,Dileep V. Reddy,Michael D. Mazurek,Carlos Abellán,Waldimar Amaya,Morgan W. Mitchell,Sae Woo Nam,Carl A. Miller,Richard P. Mirin,Martin J. Stevens,Scott Glancy,Emanuel Knill,Lynden K. Shalm*

Main category: quant-ph

TL;DR: 该论文提出并实验演示了一种设备无关的量子位置验证协议，通过量子网络中的无漏洞贝尔测试实现安全定位，相比经典协议有显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统物理中，对手可能完全了解远程方的设备，使得安全定位在根本上不可能。现有量子技术方案需要信任易受攻击的硬件，存在安全漏洞。

Method: 开发并实验演示设备无关的量子位置验证协议，仅通过量子网络中的无漏洞贝尔测试观察到的相关性来保证安全性，无需信任硬件。

Result: 实验实现了一维定位，比最佳非远程经典定位协议精确2.47(2)倍；在相同延迟条件下，比经典协议精确4.53(5)倍。

Conclusion: 该工作将数字安全锚定在物理世界中，实现了对抗具有无限量子计算和通信能力的对手的安全位置验证。

Abstract: Many applications require or benefit from being able to securely localize remote parties. In classical physics, adversaries can in principle have complete knowledge of such a party's devices, and secure localization is fundamentally impossible. This limitation can be overcome with quantum technologies, but proposals to date require trusting vulnerable hardware. Here we develop and experimentally demonstrate a protocol for device-independent quantum position verification that guarantees security with only observed correlations from a loophole-free Bell test across a quantum network. The protocol certifies the position of a remote party against adversaries who, before each instance of the test, are weakly entangled, but otherwise have unlimited quantum computation and communication capabilities. Our demonstration achieves a one-dimensional localization that is 2.47(2) times smaller than the best, necessarily non-remote, classical localization protocol. Compared to such a classical protocol having identical latencies, the localization is 4.53(5) times smaller. This work anchors digital security in the physical world.

</details>


### [83] [Upper bounds on the purity of Wigner positive quantum states that verify the Wigner entropy conjecture](https://arxiv.org/abs/2601.16898)
*Qipeng Qian,Christos Gagatsos*

Main category: quant-ph

TL;DR: 该论文证明了Wigner熵猜想的部分结果，建立了Wigner熵的显式下界层次结构，并给出了基于纯度的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究Wigner熵猜想，该猜想认为在所有物理Wigner非负态中，纯高斯态的Wigner熵最小，其值为1+lnπ。目标是建立系统性的下界方法，为验证该猜想提供充分条件。

Method: 在Wigner函数的非负性、归一化和点界πW≤1三个基本约束下，结合截断级数下界和Wigner函数的矩恒等式，构造了Wigner熵S[W]的显式下界层次结构B_n。进一步开发了基于纯度的系统松弛方法。

Result: 1. 证明了所有Wigner非负态在μ≤4-2√3时满足Wigner熵猜想；2. 得到了简单的充分条件μ≤2/e；3. 阐明了为什么需要额外的物理约束来接近极值情况μ≤1。

Conclusion: 该研究为Wigner熵猜想提供了系统的下界方法，建立了基于纯度的充分条件，并揭示了接近极值情况需要额外物理约束的原因，推进了对量子相空间中熵最小化问题的理解。

Abstract: We present analytical results toward the Wigner entropy conjecture, which posits that among all physical Wigner non-negative states the Wigner entropy is minimized by pure Gaussian states for which it attains the value $1+\lnπ$.Working under a minimal set of constraints on the Wigner function, namely, non-negativity, normalization, and the pointwise bound $πW\le 1$, we construct an explicit hierarchy of lower bounds $B_n$ on $S[W]$ by combining a truncated series lower bound for $-\ln x$ with moment identities of the Wigner function.This yields closed-form purity-based sufficient conditions ensuring $S[W]\ge 1+\lnπ$.In particular, we first prove that all Wigner non-negative states with $μ\le 4-2\sqrt3$ satisfy the Wigner entropy conjecture. We further obtain a systematic purity-only relaxation of the hierarchy, yielding the simple sufficient condition $μ\le 2/e$. On top of aforesaid results, our analysis clarifies why additional physicality constraints are necessary for purity-based approaches that aim to approach the extremal case $μ\leq1$.

</details>


### [84] [Quantum Fisher information analysis for absorption measurements with undetected photons](https://arxiv.org/abs/2601.16941)
*Martin Houde,Franz Roeder,Christine Silberhorn,Benjamin Brecht,Nicolás Quesada*

Main category: quant-ph

TL;DR: 该论文理论比较了三种基于未探测闲频光子的吸收光谱配置的量子费舍尔信息：SU(1,1)干涉仪、诱导相干配置和分布式损耗方案，确定了不同损耗和增益条件下各架构的最优测量区域。


<details>
  <summary>Details</summary>
Motivation: 研究不同吸收光谱配置在量子信息理论上的性能比较，确定在何种损耗和增益条件下哪种架构能提供最大的量子费舍尔信息，从而为实验设计提供理论指导。

Method: 理论计算三种配置的量子费舍尔信息：SU(1,1)干涉仪（含源间闲频损耗）、诱导相干配置（闲频部分种子化第二压缩器加真空辅助）、分布式损耗方案（介质内衰减）。分析QFI随参数增益的变化，考虑完全探测和仅信号探测两种情况。

Result: 损耗低于99%且增益中低时，SU(1,1)配置提供最大QFI；高增益中等损耗时，诱导相干方案最优；极端衰减（透射率<1%）时，分布式损耗模型成为最佳。这些结果划定了各架构在信息理论上最优的测量区域。

Conclusion: 不同吸收光谱架构在不同损耗和增益条件下各有优势，为基于未探测闲频光子的量子增强吸收光谱实验设计提供了明确的理论指导，可根据具体实验条件选择最优配置。

Abstract: We theoretically compare the quantum Fisher information (QFI) for three configurations of absorption spectroscopy with undetected idler photons: an SU(1,1) interferometer with inter-source idler loss, an induced-coherence (IC) setup in which the idler partially seeds a second squeezer together with a vacuum ancilla, and a distributed-loss (DL) scheme with in-medium attenuation. We calculate the QFI as a function of parametric gain for both full and signal-only detection access. For losses below 99% and low to moderate gain, the SU(1,1) configuration provides the largest QFI. At high gain and intermediate loss, the IC scheme performs best, while under extreme attenuation (transmission $<$ 1%) the DL model becomes optimal. These results delineate the measurement regimes in which each architecture is optimal in terms of information theory.

</details>


### [85] [Experimental investigation of nonclassicality in the simplest scenario via the degrees of freedom of light](https://arxiv.org/abs/2601.16952)
*João M. M. Gama,Guilherme T. C. Cruz,Massy Khoshbin,Lorenzo Catani,José A. O. Huguenin,Wagner F. Balthazar*

Main category: quant-ph

TL;DR: 使用经典光模拟量子非经典性概念，通过偏振和横向模式两种实验设置，在四态制备和二元测量场景中验证了噪声鲁棒不等式的违反，表明与制备非上下文性和有界本体论区分度不一致。


<details>
  <summary>Details</summary>
Motivation: 研究经典光是否能够模拟量子非经典性概念，特别是在最简单的四态制备和二元测量场景中。该场景是量子随机访问码等计算优势的基础，也是半设备无关非经典性认证的最简单通信原语。

Method: 采用两种不同的实验设置：偏振自由度和一阶Hermite-Gaussian横向模式自由度。实现四态制备和二元测量的准备-测量场景，并通过全光学设置模拟实验噪声（去极化通道的效应）。

Result: 实验结果与Khoshbin等人的发现一致：在假设两个测量构成层析完备集的前提下，观测到的统计量违反了噪声鲁棒不等式，表明与制备非上下文性和有界本体论区分度不一致。虽然使用经典光，但重现了该场景的预测统计量。

Conclusion: 经典光可以模拟量子非经典性统计特征，这一实现直接适用于量子随机访问码等应用，为半设备无关认证提供了实验基础，展示了经典系统模拟量子优势的可能性。

Abstract: In this work, we experimentally investigate the classical-light emulation of different notions of nonclassicality in the simplest scenario. We implement this prepare-and-measure scenario involving four preparations and two binary-outcome measurements using two distinct experimental setups that exploit different degrees of freedom of light: polarization and first-order Hermite-Gaussian transverse modes. We additionally model experimental noise through an all-optical setup that reproduces the operational effect of a depolarizing channel. Our experimental results are consistent with the findings of Khoshbin et al. [Phys. Rev. A 109, 032212 (2024)]: under the assumption that the two measurements performed form a tomographically complete set, the observed statistics violate their noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations. Although our implementation uses classical light, it reproduces the statistics predicted for the simplest scenario. Since the states and measurements of this scenario underpin computational advantages in tasks such as two-bit quantum random access codes -- among the simplest communication primitives enabling semi-device-independent certification of nonclassicality -- our implementation is directly relevant for such applications.

</details>


### [86] [Engineering discrete local dynamics in globally driven dual-species atom arrays](https://arxiv.org/abs/2601.16961)
*Francesco Cesa,Andrea Di Fini,David Aram Korbany,Roberto Tricarico,Hannes Bernien,Hannes Pichler,Lorenzo Piroli*

Main category: quant-ph

TL;DR: 提出一种在全局驱动的双物种中性原子实验中设计离散局域动力学的方法，通过统一的模拟控制研究涌现的数字模型


<details>
  <summary>Details</summary>
Motivation: 利用双物种系统的新机会（如物种交替驱动），在静态原子排列上实现简单的Floquet协议，并利用广义阻塞机制（不同种间和种内相互作用）的优势

Method: 基于Floquet协议在静态原子排列上构建离散动力学模型，特别关注量子元胞自动机的具体实例，包括kicked-Ising模型、Floquet Kitaev蜂窝模型以及通用平移不变最近邻哈密顿量的数字化

Result: 该方法能够研究离散化多体动力学的混沌特征，这些特征可以通过全局驱动实验的已证明能力来检测，并能够对区分混沌演化的能力进行基准测试

Conclusion: 为在双物种中性原子平台上实现和研究量子元胞自动机等离散动力学模型提供了新方法，特别适用于研究多体系统的混沌行为

Abstract: We introduce a method for engineering discrete local dynamics in globally-driven dual-species neutral atom experiments, allowing us to study emergent digital models through uniform analog controls. Leveraging the new opportunities offered by dual-species systems, such as species-alternated driving, our construction exploits simple Floquet protocols on static atom arrangements, and benefits of generalized blockade regimes (different inter- and intra-species interactions). We focus on discrete dynamical models that are special examples of Quantum Cellular Automata (QCA), and explicitly consider a number of relevant examples, including the kicked-Ising model, the Floquet Kitaev honeycomb model, and the digitization of generic translation-invariant nearest-neighbor Hamiltonians (e.g., for Trotterized evolution). As an application, we study chaotic features of discretized many-body dynamics that can be detected by leveraging only demonstrated capabilities of globally-driven experiments, and benchmark their ability to discriminate chaotic evolution.

</details>


### [87] [Autonomous Optical Alignment of Satellite-Based Entanglement Sources using Reinforcement Learning](https://arxiv.org/abs/2601.16968)
*Andrzej Gajewski,Robert Okuła,Marcin Pawłowski,Akshata Shenoy H*

Main category: quant-ph

TL;DR: 论文提出了两种卫星上量子纠缠源自动校准方法：启发式算法和强化学习，后者性能显著优于前者，可在10分钟内完成完美校准。


<details>
  <summary>Details</summary>
Motivation: 卫星量子通信面临轨道动态变化导致的光源失准问题，需要自动化校准方案以减少人工干预并提高效率。

Method: 针对PPLN-SPDC纠缠源，开发了两种校准方法：1）模拟实验室手动校准过程的启发式算法；2）基于强化学习的智能校准方法。

Result: 强化学习方法在修改的ROC分析中AUC=0.9119，优于启发式算法的0.7042；RL仅需10分钟完成完美校准，而HA需要30分钟。

Conclusion: 两种方法都满足卫星约束条件，强化学习在性能和时间效率上显著优于启发式算法，为复杂量子通信场景提供了可扩展的自动化解决方案。

Abstract: Quantum entanglement distributed via satellites enable global-scale quantum communication. However, onboard sources are susceptible to misalignment due to dynamical orbital conditions. Here, we present two recalibration techniques for efficient generation of high quality entanglement using a periodically poled lithium niobate (PPLN)-based spontaneous parametric down-conversion (SPDC) source with minimum intervention. The first is a heuristic algorithm (HA) which mimics the manual alignment process in a laboratory. The second is based on reinforcement learning (RL). Our simulation demonstrates superior performance of RL with AUC=0.9119 compared to HA's 0.7042 in the modified ROC analysis (60 min threshold). RL achieves perfect alignment in 10 min as opposed to HA's 30 min. Both the methods operate within feasible satellite constraints, offering scalable automation for complex quantum communication scenarios.

</details>


### [88] [Formalising an operational continuum limit of quantum combs](https://arxiv.org/abs/2601.16974)
*Clara Wassner,Jonáš Fuksa,Jens Eisert,Gregory A. L. White*

Main category: quant-ph

TL;DR: 将离散量子梳框架扩展到连续时间，建立完全连续的process tensor框架，解决量子信息理论中多时间过程与连续时间之间的概念鸿沟。


<details>
  <summary>Details</summary>
Motivation: 量子梳虽然能描述多时间量子过程，但缺乏与连续时间的物理连接；process tensor框架虽然考虑了底层动力学，但数学上难以扩展到连续过程，存在概念上的不完整。

Method: 将离散多部分Choi态转化为玻色子Fock空间中的场论态，建立内在且严格定义的连续框架，利用连续矩阵乘积态表示来分析多时间关联。

Result: 成功构建了完全连续的process tensor框架，实现了量子信息理论中多时间过程与连续时间的数学连接，为分析连续时间中的多时间关联提供了工具。

Conclusion: 填补了量子信息文献中的空白，为将多体物理的见解应用于理解连续量子随机过程开辟了机会，建立了量子信息理论与连续时间过程之间的桥梁。

Abstract: Quantum combs are powerful conceptual tools for capturing multi-time processes in quantum information theory, constituting the most general quantum mechanical process. But, despite their causal nature, they lack a meaningful physical connection to time -- and are, by and large, arguably incompatible with it without extra structure. The subclass of quantum combs which assumes an underlying process is described by the so-called process tensor framework, which has been successfully used to study and characterise non-Markovian open quantum systems. But, although process tensors are motivated by an underlying dynamics, it is not a priori clear how to connect to a continuous process tensor object mathematically -- leaving an uncomfortable conceptual gap. In this work, we take a decisive step toward remedying this situation. We introduce a fully continuous process tensor framework by showing how the discrete multi-partite Choi state becomes a field-theoretic state in bosonic Fock space, which is intrinsically and rigorously defined in the continuum. With this equipped, we lay out the core structural elements of this framework and its properties. This translation allows for an information-theoretic treatment of multi-time correlations in the continuum via the analysis of their continuous matrix product state representatives. Our work closes a gap in the quantum information literature, and opens up the opportunity for the application of many-body physics insights to our understanding of quantum stochastic processes in the continuum.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [89] [Bayesian Inference of Neutron Star Properties in $f(Q)$ Gravity Using NICER Observations](https://arxiv.org/abs/2601.16227)
*Sneha Pradhan,N. K. Patra,Kai Zhou,P. K. Sahoo*

Main category: gr-qc

TL;DR: 该研究在对称远平行f(Q)引力框架下，通过贝叶斯推断分析中子星结构，发现指数模型在统计上优于线性和对数模型，并给出了与观测一致的半径和潮汐形变参数。


<details>
  <summary>Details</summary>
Motivation: 虽然中子星观测的贝叶斯研究在广义相对论和曲率修正引力理论中已成熟，但在f(Q)引力框架下此类分析仍基本空白。研究旨在利用中子星作为强场区对称远平行引力的探针。

Method: 在对称远平行f(Q)引力框架下，考虑线性、对数和指数三种模型。通过贝叶斯推断分析，将理论中子星质量-半径预测与NICER观测的四个脉冲星数据进行对比。致密物质状态方程固定为DDME2以隔离修正引力效应。

Result: 指数f(Q)模型在统计上优于线性和对数模型（贝叶斯因子比较证实）。对于该模型，得到1.4倍太阳质量中子星的半径R₁.₄=11.27⁺⁰.⁵³₋₀.₃₆ km和潮汐形变参数Λ₁.₄=156.95⁺⁸⁴.⁰²₋₄₁.₇₃，与当前观测约束一致。

Conclusion: 研究结果表明中子星可作为强场区对称远平行引力的有效探针，指数f(Q)模型在统计上更优，其预测与观测相符，为探索修正引力理论提供了新途径。

Abstract: In this work, we investigate neutron stars (NSs) in the strong field regime within the framework of symmetric teleparallel $f(Q)$ gravity, considering three representative models: linear, logarithmic, and exponential. While Bayesian studies of NS observations are well established in General Relativity and curvature based modified gravity theories, such analyses in $f(Q)$ gravity remain largely unexplored. We perform a Bayesian inference analysis by confronting theoretical NS mass-radius predictions with NICER observations of PSR J0030+0451, PSR J0740+6620, PSR J0437+4715, and PSR J0614+3329. The dense matter equation of state is fixed to DDME2 in order to isolate the effects of modified gravity on NS structure. Our results show that the exponential $f(Q)$ model is statistically preferred over the linear and logarithmic cases, as confirmed by Bayes factor comparisons, and exhibits well-constrained. For this model, we obtain a radius and tidal deformability at $1.4\,M_\odot$ of $R_{1.4} = 11.27^{+0.53}_{-0.36}\,\mathrm{km}$ and $Λ_{1.4} = 156.95^{+84.02}_{-41.73}$, respectively, consistent with current observational constraints. These results highlight the potential of NSs as powerful probes of symmetric teleparallel gravity in the strong field regime.

</details>


### [90] [Static hairy black hole in 4D General Relativity](https://arxiv.org/abs/2601.16254)
*Marco Astorino*

Main category: gr-qc

TL;DR: 本文提出了一种四维真空广义相对论中的新型静态黑洞解，通过添加一个新的积分常数（"毛发"）将史瓦西时空推广为Petrov类型I，该参数代表外部引力场的强度，可视为Witten无物泡的hyperbolic推广。


<details>
  <summary>Details</summary>
Motivation: 在四维真空广义相对论中，已知的静态、精确解析黑洞解只有史瓦西时空。本文旨在通过添加新的积分常数来推广这一著名解，探索非渐近平坦、非球对称的黑洞解。

Method: 通过添加一个代表外部引力场强度的积分常数（"毛发"），将史瓦西度规推广为Petrov类型I。该解在事件视界外没有曲率或锥形奇点，且不满足渐近平坦条件。

Result: 新参数连续变形史瓦西几何：视界变得扁长，面积减小。该解规避了无毛定理，因为度规既非渐近平坦，黑洞也非球对称。研究了黑洞的守恒荷和热力学性质。

Conclusion: 成功构造了一个具有引力"毛发"的新型静态黑洞解，扩展了四维真空广义相对论中已知的精确解析解集合，为研究非渐近平坦黑洞提供了新范例。

Abstract: In four-dimensional vacuum general relativity the only known static, exact and analytical black hole solution is given by the Schwarzschild spacetime. In this paper this renowned metric is generalised by adding another integrating constant, a hair that switches the metric from the Petrov type D to the type I. This new parameter represents the intensity of an external gravitational field, which can be considered the hyperbolic generalisation of the Witten's bubble of nothing. No curvature or conical singularities are present outside the event horizon. The no hair arguments are circumvented because the metric is not asymptotically flat, and neither the black hole is spherical. The gravitational hair continuously deforms the Schwarzschild geometry: the horizon becomes oblate, while its area is reduced. Conserved charges and thermodynamic properties of the black hole are studied.

</details>


### [91] [Light propagation and quasinormal modes of a topologically charged Schwarzschild-Klinkhamer wormhole](https://arxiv.org/abs/2601.16305)
*C. F. S. Pereira,H. Belich,A. R. Soares,Marcos V. de S. Silva,R. L. L. Vitória,A. A. Araújo Filho*

Main category: gr-qc

TL;DR: 该论文理论分析了由几何缺陷产生的虫洞的零测地线、临界光子轨道和阴影形成，研究了弱场和强场区域的光偏折角，推导了引力透镜可观测量，并计算了标量扰动的准正规模和时间域解。


<details>
  <summary>Details</summary>
Motivation: 研究由几何缺陷产生的虫洞的光学特性，特别是通过分析光传播、引力透镜效应和阴影形成来探索这类虫洞的可观测特征，为当前和未来的天文观测提供理论参考。

Method: 采用理论分析方法，研究虫洞时空中的零测地线和临界光子轨道；推导弱场和强场区域的光偏折角解析展开；分析引力透镜可观测量；计算标量扰动的准正规模和时间域解。

Result: 建立了虫洞光学特性的完整理论框架，得到了光偏折角的解析表达式，确定了全局单极子电荷对观测量的影响范围，并提供了可能被当前或未来观测设备探测到的参数区间。

Conclusion: 该研究为几何缺陷产生的虫洞提供了系统的光学特性分析框架，建立了连接理论模型与天文观测的桥梁，为通过引力透镜和阴影观测探测这类虫洞奠定了理论基础。

Abstract: In this work, we present a theoretical analysis of null geodesics, critical photon orbits, and shadow formation associated with a wormhole generated by a geometric defect. The propagation of light in this spacetime is examined through the deflection angle in both weak- and strong-field regimes. Analytical expansions are derived in each regime and employed to characterize gravitational lensing observables. By varying the global monopole charge, we evaluate its impact on these observables and determine parameter ranges that may be accessible to current or future observational probes. Finally, we calculate the quasinormal modes as well as the time-domain solution for scalar perturbations as well.

</details>


### [92] [Does Gravity Care About Electric Charge? A Minimalist Model and Experimental Test](https://arxiv.org/abs/2601.16325)
*Renato Vieira dos Santos*

Main category: gr-qc

TL;DR: 论文提出一个理论框架，将电磁学与线性化引力通过复电荷-质量流守恒耦合，预测引力加速度与电荷质量比相关，并建议用改进的扭秤实验验证这一预测。


<details>
  <summary>Details</summary>
Motivation: 当前精密弱等效原理测试刻意最小化测试质量的电荷，导致"引力是否关心电荷"这一基本问题在实验上悬而未决。论文旨在填补这一实验空白。

Method: 构建一个简约的理论框架，通过复电荷-质量流守恒将电磁学与线性化引力耦合，预测引力加速度与电荷质量比的关系：Δa/g = κ(q/m)。

Result: 理论预测显示电荷依赖的弱等效原理违反，这一预测恰好位于现有精密引力实验未探索的参数空间，因为传统实验刻意避免电荷变化。

Conclusion: 提出改进的扭秤实验，将电荷质量比作为控制变量，可以测试引力加速度是否依赖电荷，探索全新的物理参数空间，展示了理论简约主义如何揭示基础物理中被忽视的机会。

Abstract: Does gravity care about electric charge? Precision tests of the weak equivalence principle achieve remarkable sensitivity but deliberately minimize electric charge on test masses, leaving this fundamental question experimentally open. We present a minimalist framework coupling electromagnetism to linearized gravity through conservation of a complex charge-mass current, predicting charge-dependent violations $Δa/g = κ(q/m)$. Remarkably, this prediction occupies unexplored experimental territory precisely because precision gravity tests avoid charge variation. We identify this as a significant gap and propose a modified torsion balance experiment where $q/m$ is treated as a controlled variable. Such an experiment could test whether gravitational acceleration depends on electric charge, probing physics in genuinely new parameter space. This work exemplifies how theoretical minimalism can reveal overlooked opportunities in fundamental physics.

</details>


### [93] [Thick Lunar Crust Amplifies Gravitational-Wave Signal](https://arxiv.org/abs/2601.16567)
*Lei Zhang,Han Yan,Xian Chen,Jinhai Zhang*

Main category: gr-qc

TL;DR: 月球可作为引力波谐振探测器，其粗糙表面和异质内部会放大信号10-20%，特定位置可达10倍放大，为探测器选址提供指导。


<details>
  <summary>Details</summary>
Motivation: 0.001-0.1 Hz频段的引力波包含早期宇宙和致密天体合并的独特信息，但现有天文台无法探测。月球可作为谐振探测器，但其粗糙表面和异质内部的影响未知，阻碍了这一应用。

Method: 结合高精度谱元模拟和正规微扰理论，构建首个高分辨率、结构真实的月球引力波响应模型，分辨率达3.7 km网格间距，同时能识别全球自由振荡模式。

Result: 不仅恢复了预期的四极(l=2)振荡模式，还发现厚地壳区域信号系统放大10-20%。正规模式分析表明这是模式耦合过程：引力波诱导的四极振荡将能量分配到高阶模式。特定本征频率和位置观测到10倍放大。

Conclusion: 月球可作为精确校准的引力波谐振探测器，放大图为最优着陆点选择提供定量指导，数值模拟能解析这些结构微调特征。

Abstract: Gravitational waves (GWs) in the $10^{-3}-0.1$ Hz band encode unique signatures of the early universe and merging compact objects, but they are beyond the reach of existing observatories. Theoretical models suggest that the Moon could act as a resonant detector, but the unknown influence of its rugged surface and heterogeneous interior has cast doubt on this prospect. Here, we resolve this long-standing uncertainty by constructing the first high-resolution, structurally realistic model of the lunar GW response. We achieve this by combining high-fidelity spectral-element simulations with the analytical power of normal-mode perturbation theory, thereby resolving topographical effects down to $3.7$ km grid spacing while maintaining the capacity to discern global free-oscillation patterns. This dual-methodology approach not only recovers the expected predominant quadrupole ($l=2$) oscillation mode, but also exposes a systematic signal amplification of $(10-20)\%$ in thick-crust regions. This enhancement is traced by our normal-mode analysis to a mode-coupling process, in which the original quadrupolar oscillation induced by the passing GWs distributes energy into a series of higher-order modes, the hybridized eigenmodes of the laterally heterogeneous Moon. Near certain eigen-frequencies and at specific locations, we observe up to tenfold amplification, highlighting the power of numerical simulations in resolving these structurally fine-tuned features. Our work establishes the Moon as an accurately calibrated resonant GW detector, and the resulting amplification maps provide quantitative guide for the optimal landing site selection.

</details>


### [94] [Gravitational Lensing Effect from The Revised Deser-Woodard Nonlocal Gravity](https://arxiv.org/abs/2601.16572)
*Haida Li,Xiangdong Zhang*

Main category: gr-qc

TL;DR: 在修正的Deser-Woodard非局部引力框架下，研究静态球对称黑洞的引力透镜效应，发现弱场和强场极限下的偏转角修正特征。


<details>
  <summary>Details</summary>
Motivation: 探索修正的Deser-Woodard非局部引力理论中黑洞的引力透镜效应，以区分该理论与广义相对论及其他替代理论。

Method: 分析静态球对称黑洞在弱场和强场极限下的偏转角，推导理论参数对透镜效应的影响。

Result: 弱场极限下发现由理论非局部性质引起的一阶修正；强场极限下透镜修正几乎线性依赖于耦合参数ζ，同时被指数参数n指数抑制；该模型在给定时间下表现出与广义相对论和共形引力相似的尺度不变行为。

Conclusion: 修正的D-W模型的引力透镜效应具有独特特征，为通过天文观测区分该理论与其他替代理论提供了潜在途径。

Abstract: We investigate the gravitational lensing effects of a static spherically symmetric black hole (BH) within the framework of the revised Deser-Woodard (D-W) nonlocal gravity. By analyzing the deflection angle in both the weak and strong field limits, we derive several distinguishing features of the model. In the weak field limit, we report a leading-order correction to the deflection angle directly attributed to the non-local nature of the theory. In the strong field limit, we find that the lensing corrections are almost linearly dependent on the coupling parameter $ζ$ while being exponentially suppressed by the exponent parameter $n$. Furthermore, the gravitational lensing effect in the revised D-W model at a given time shares similar scale-invariant behavior to General Relativity and conformal gravity, offering a potential pathway to distinguish it from other alternatives using astronomical observations.

</details>


### [95] [Dirac-Bergmann algorithm and canonical quantization of $k$-essence cosmology](https://arxiv.org/abs/2601.16703)
*Andrés Lueiza,Andronikos Paliathanasis,Nikolaos Dimakis*

Main category: gr-qc

TL;DR: 提出了标量张量理论中k-essence宇宙学的通用正则量子化方案，通过狄拉克-伯格曼算法构建哈密顿量，引入正则共轭变量，将哈密顿约束简化为无势项的二次函数，得到类似无质量克莱因-戈尔登方程的惠勒-德维特方程。


<details>
  <summary>Details</summary>
Motivation: 为标量张量理论中的k-essence宇宙学模型建立系统的正则量子化框架，解决这类模型的量子化问题，为研究宇宙学中的量子效应（如幻影穿越作为量子隧穿效应）提供理论基础。

Method: 使用狄拉克-伯格曼算法构建宇宙学场方程的哈密顿量，识别第一类和第二类约束，引入适当的正则共轭变量（相对于狄拉克括号），将哈密顿约束简化为无势项的二次函数，实现模型的规范量子化。

Result: 成功建立了k-essence宇宙学的正则量子化方案，哈密顿约束简化为类似无质量克莱因-戈尔登方程的形式。以快子场为例，研究了幻影穿越作为量子隧穿效应的条件，在恒定势能简化情况下，分析了不同边界条件对奇点避免和平均膨胀率的影响。

Conclusion: 该研究为标量张量理论中的k-essence宇宙学提供了系统的正则量子化框架，将哈密顿约束简化为可处理的二次形式，为研究宇宙学量子效应（如幻影穿越）奠定了基础，并展示了边界条件对量子宇宙学结果的重要影响。

Abstract: We develop a general canonical quantization scheme for $k$-essence cosmology in scalar-tensor theory. Utilizing the Dirac-Bergmann algorithm, we construct the Hamiltonian associated with the cosmological field equations and identify the first- and second-class constraints. The introduction of appropriate canonically conjugate variables with respect to Dirac brackets, allows for the canonical quantization of the model. In these new variables, the Hamiltonian constraint reduces to a quadratic function with no potential term. Its quantum realization leads to a Wheeler-DeWitt equation reminiscent of the massless Klein-Gordon case. As an illustrative example, we consider the action of a tachyonic field and investigate the conditions under which a phantom crossing can occur as a quantum tunneling effect. For the simplified constant potential case, we investigate the consequences of different boundary conditions on the singularity avoidance and to the mean expansion rate.

</details>


### [96] [Ricci-Weyl curvature balance in viscous dissipative collapse: A covariant analysis of singularity censorship](https://arxiv.org/abs/2601.16706)
*Samarjit Chakraborty,Rituparno Goswami,Sunil D. Maharaj,Gareth Amery*

Main category: gr-qc

TL;DR: 研究球对称塌缩中的宇宙监督猜想，考虑剪切和体粘性、热流、压力各向异性，通过半标架协变形式推导塌缩流体动力学，发现视界上Ricci与Weyl曲率平衡机制决定奇点可见性，得到中心奇点局部裸露的充要条件，支持较弱形式的宇宙监督。


<details>
  <summary>Details</summary>
Motivation: 研究宇宙监督猜想在更现实的物理条件下的有效性，特别是考虑粘性、热流和各向异性压力等耗散效应的球对称塌缩，这些因素在真实天体物理塌缩中很重要但常被忽略。

Method: 采用半标架协变形式，推导包含粘性效应的塌缩流体动力学方程，包括Weyl曲率演化的主方程，分析零测地线几何，研究视界上Ricci曲率（物质）与Weyl曲率（自由引力场）的平衡机制。

Result: 发现视界上存在新的曲率平衡机制，Ricci与Weyl曲率的平衡决定视界的因果性质，从而控制奇点的可见性；推导出中心奇点局部裸露的充要协变条件；结果支持较弱形式的宇宙监督。

Conclusion: 将协变监督分析扩展到现实的耗散粘性塌缩，发现曲率平衡机制决定奇点可见性，支持较弱形式的宇宙监督猜想，为理解真实物理条件下的引力塌缩提供了新见解。

Abstract: We investigate the cosmic censorship conjecture in a spherically symmetric collapse with shear and bulk viscosity, heat flux, and pressure anisotropy, imposing physically reasonable energy conditions. Using the semi-tetrad covariant formalism, we derive the dynamics of the collapsing fluid, including a master equation for the evolution of the Weyl curvature, to examine the role of viscosity. The analysis of null geodesic geometry uncovers a novel curvature-balance mechanism between Ricci (matter) and Weyl (free gravitational field) curvature on the apparent horizon; this balance determines the causal nature of the horizon and thereby governs the visibility of the singularity. We then derive necessary and sufficient covariant conditions for the central singularity to be locally naked. Our findings support a weaker form of cosmic censorship and extend the covariant censorship analysis to realistic dissipative, viscous collapse.

</details>


### [97] [General orbital perturbation theory in Schwarzschild space-time](https://arxiv.org/abs/2601.16887)
*Oleksii Yanchyshen,Eva Hackmann,Claus Lämmerzahl*

Main category: gr-qc

TL;DR: 该论文推导了在无限制的史瓦西时空背景下，受扰动力的轨道振动的广义相对论高斯方程，为强引力相对论环境中的轨道参数演化提供了描述方法。


<details>
  <summary>Details</summary>
Motivation: 在强引力相对论环境中，需要一种能够描述受扰动力影响的轨道参数演化的数学框架。现有的方法可能存在限制，该研究旨在提供一种无限制的广义相对论高斯方程，以更好地理解在强引力场中的轨道动力学。

Method: 推导了在史瓦西时空背景下受扰动力的轨道振动的广义相对论高斯方程。该方法没有对底层时空施加任何限制。作为外部力的示例，考虑了克尔度规和q-度规生成的力，并在线性近似下求解了振动元素方程。

Result: 成功推导出无限制的广义相对论高斯方程，能够描述强引力相对论环境中的轨道参数演化。在线性近似下求解了克尔度规和q-度规生成的力的振动元素方程。在牛顿后极限下，克尔时空的结果重现了著名的Lense-Thirring进动（升交点经度的进动）。

Conclusion: 该研究提供了一种在强引力相对论环境中描述受扰动力影响的轨道参数演化的通用数学框架。推导的方程能够准确描述轨道振动，并在特定情况下重现已知的相对论效应，验证了方法的有效性。

Abstract: We derive general relativistic Gaussian equations for osculating elements for orbits under the influence of a perturbing force without any restrictions in an underlying Schwarzschild space-time. Such a formulation provides a way to describe the evolution of orbital parameters in strong gravity relativistic settings. As examples of external forces we considered Kerr and $q$-metric space-times generated forces, for which we solve equations for osculating elements in linear approximation. For the Kerr space-time in the post-Newtonian limit, our result reproduces the well-known Lense--Thirring precession of the longitude of the ascending node.

</details>


### [98] [Anisotropy Strikes Back: Modified Gravity and Dark Matter Halos](https://arxiv.org/abs/2601.16958)
*Paolo M Bassani*

Main category: gr-qc

TL;DR: 论文探索了在LTB迷你超空间中暗物质类流体的性质，分析了哈密顿约束的对称性如何控制广义相对论和Horava-Lifshitz引力中有效暗源的出现。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质类流体在引力理论中的表现，特别是哈密顿约束的对称性如何影响有效暗源的出现，以及不同引力理论（GR和HL）中暗物质行为的差异。

Method: 1. 在GR中通过添加额外权重+1密度来变形哈密顿量；2. 分析变形对Dirac代数的影响；3. 在HL引力中研究变形Dirac代数如何诱导出受控的非守恒定律；4. 识别特定LTB背景类别。

Result: 1. GR中的变形保持Dirac代数不变，可重新解释为有效各向异性应力能量贡献；2. 流体产生类等温质量标度，但压力各向异性阻止平坦旋转曲线的形成；3. 在HL引力中，识别出能产生正标度暗物质密度的受限LTB背景类别，与无鬼条件和红外GR恢复一致。

Conclusion: 哈密顿约束的对称性对暗物质类流体的表现有重要影响，不同引力理论产生不同的有效暗源行为。HL引力在特定背景下能产生符合物理要求的暗物质密度，但完全自洽的解决方案需要进一步研究。

Abstract: We explore dark matter like fluids in a spherically symmetric Lemaitre Tolman Bondi (LTB) minisuperspace, tracking how symmetry properties of the Hamiltonian constraint control the emergence of effective dark sources in General Relativity (GR) and Horava Lifshitz (HL) gravity. We first deform the GR Hamiltonian by adding an extra weight $+1$ density to the potential. We show that potential deformations of this type leave the (reduced) Dirac algebra unchanged and the modification is naturally reinterpreted as an effective anisotropic stress energy contribution. While the fluid reproduces an isothermal-like mass scaling, its pressure anisotropy prevents it from giving flat rotation curves. We then turn to HL gravity, where the deformed Dirac algebra induces a controlled nonconservation law for an emergent dust component. Generalizing earlier results, we identify a restricted class of LTB backgrounds for which the HL source term yields a positive scaling dark matter density, consistent with ghost-freedom, and recovery of GR in the infrared. The analysis is conditional on a prescribed background: obtaining a fully backreacted areal radius solution consistent with the HL field equations is left as a natural direction for future work.

</details>


### [99] [Embedding Wormholes and Dyonic Black Strings in Warped Braneworlds via Local Sum Rules](https://arxiv.org/abs/2601.16969)
*G. Alencar,T. M. Crispim,Francisco S. N. Lobo*

Main category: gr-qc

TL;DR: 在Randall-Sundrum膜世界中构建由局域化物质场支持的紧致天体，包括Ellis-Bronnikov虫洞和两种新型黑洞弦解


<details>
  <summary>Details</summary>
Motivation: 基于先前建立的局域求和规则，研究如何在Randall-Sundrum膜世界中构建动力学一致且可局域化的紧致天体，连接高维物理与已知的四维解

Method: 首先回顾Chamblin等人的黑洞弦作为基础高维解，然后通过局域化自由标量场嵌入Ellis-Bronnikov虫洞，最后推导由局域化非线性电动力学理论（拉格朗日密度为$\mathcal{L}(\mathcal{F}) = -β\sqrt{\mathcal{F}}$）支持的两种新型黑洞弦解

Result: 成功构建了三种紧致天体解：1) Ellis-Bronnikov虫洞在膜世界框架中的一致嵌入；2) 纯磁配置黑洞弦，在膜上重现Letelier弦云；3) 双荷配置黑洞弦，推广到包含电荷，类似于Letelier-Alencar构造。两种非线性电动力学解在β→0时平滑过渡到Chamblin黑洞弦

Conclusion: 局域化高维物质场可以一致地支持膜世界紧致天体，并有效连接高维物理与已知的四维解，为膜世界中构建物理上合理的紧致天体提供了具体范例

Abstract: Building on our previous work [1], where the Local Sum Rules (LSR) were established, we investigate the construction of compact objects in Randall-Sundrum braneworlds supported by matter fields that are dynamically consistent and localizable. We begin by revisiting the Chamblin et al. black string, highlighting its role as a foundational higher-dimensional solution. We then show that the Ellis-Bronnikov wormhole can be consistently embedded in this framework via a localized free scalar field, providing a simple yet nontrivial example of a braneworld compact object. Finally, we derive two novel black string solutions sourced by a localized nonlinear electrodynamics (NED) theory with Lagrangian $\mathcal{L}(\mathcal{F}) = -β\sqrt{\mathcal{F}}$, corresponding to purely magnetic and dyonic configurations. The purely magnetic solution reproduces the classical Letelier string cloud on the brane, while the dyonic solution generalizes it to include electric charge, closely paralleling the Letelier-Alencar construction. Both NED solutions reduce smoothly to the Chamblin et al. black string in the limit $β\to 0$, illustrating how localized higher-dimensional matter fields can consistently support braneworld compact objects and connect higher-dimensional physics with well-known four-dimensional solutions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [100] [Collective Rabi-driven vibrational activation in molecular polaritons](https://arxiv.org/abs/2601.16299)
*Carlos M. Bustamante,Franco P. Bonafé,Richard Richardson,Michael Ruggenthaler,Wenxiang Ying,Abraham Nitzan,Maxim Sukharev,Angel Rubio*

Main category: physics.comp-ph

TL;DR: 在驱动光学腔中，集体电子强耦合通过电子Rabi振荡相干驱动核运动，实现了一种新的振动激活机制


<details>
  <summary>Details</summary>
Motivation: 虽然分子极化子（电子或振动强耦合）已被广泛研究，但在驱动腔中电子-核动力学的影响仍然未知，需要探索集体电子强耦合下的新机制

Method: 使用半经典模拟，自洽地结合麦克斯韦方程与量子分子动力学，包括最小二能级模型中的振动波包动力学和基于含时密度泛函紧束缚与Ehrenfest动力学的原子模拟

Result: 发现集体电子Rabi振荡相干驱动核运动，振动激活对Rabi频率呈非单调依赖，当集体极化子分裂与分子振动模式共振时达到最大，机制表现出类似受激Raman弛豫的特征

Conclusion: 建立了一个自洽的框架用于研究真实腔-电子-核动力学，揭示了驱动光学腔中集体电子强耦合下振动激活的新机制

Abstract: Hybrid light-matter states, known as molecular polaritons, arise from electronic or vibrational strong coupling (ESC and VSC) with confined electromagnetic fields. While these have been widely studied, the influence of electron-nuclear dynamics in driven cavities remains largely unknown. Here, we report a previously unrecognized mechanism of vibrational activation that emerges under collective ESC in driven optical cavities. Using semiclassical simulations that self-consistently combine Maxwell's equations with quantum molecular dynamics, we show that collective electronic Rabi oscillations coherently drive nuclear motion. This effect is captured using both vibrational wave-packet dynamics in a minimal two-level model and atomistic simulations based on time-dependent density-functional tight-binding with Ehrenfest dynamics. Vibrational activation depends non-monotonically on the Rabi frequency and is maximized when the collective polaritonic splitting resonates with a molecular vibrational mode. The mechanism exhibits features consistent with a stimulated Raman-like relaxation mechanism. Our results establish a self-consistent framework for realistic cavity-electron-nuclear dynamics.

</details>


### [101] [Physics Informed Differentiable Solvers for Learning Parametric Solution Manifolds in Heterogeneous Physical Systems](https://arxiv.org/abs/2601.16350)
*Milad Panahi,Giovanni Michele Porta,Monica Riva,Alberto Guadagnini*

Main category: physics.comp-ph

TL;DR: 提出一种基于可微分PINN的框架，单次训练即可学习达西流稳态解流形，支持复杂空间异质性参数场的直接解析和数据驱动表示，实现高效不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 参数化偏微分方程（PDEs）全解族的建模对异质系统分析至关重要，尤其在系统性质存在显著空间异质性（如水文地质学）且具有不确定性的领域。传统方法需要为每个新参数实例重新训练，计算成本高昂。

Method: 将物理信息神经网络（PINN）重构为可微分求解器，学习稳态达西流的连续解流形。提出两种空间异质水力传导率场表示：直接解析形式和基于自编码器的数据驱动形式。关键创新是将可微分解码器集成到物理信息损失函数中，通过自动微分实时重建复杂传导率场。

Result: 该方法仅需单次训练，避免了为每个新参数实例重新训练的成本。能够生成准确、质量守恒的流动解，支持高效的不确定性量化，为异质系统的物理约束数据驱动建模提供了通用方法。

Conclusion: 该框架成功实现了参数化PDEs解流形的连续学习，通过可微分PINN和数据驱动表示的创新结合，为异质系统建模提供了高效、通用的解决方案，特别适用于水文地质等空间异质性显著的领域。

Abstract: Learning the full family of solutions to parameterized partial differential equations (PDEs) is a central challenge to our ability to model the behavior of heterogeneous systems, with a variety of fundamental and application-oriented implications in fields such as hydrogeology where system properties exhibit significant (and often uncertain) spatial heterogeneity. We address this by reformulating a Physics-Informed Neural Network (PINN) as a differentiable solver that learns the continuous solution manifold for steady-state Darcy flow. Our framework requires only a single training run, circumventing the need for costly re-training for each new parameter instance. Its versatility is demonstrated through two representations of spatially heterogeneous hydraulic conductivity fields: a direct analytical form and a novel data-driven formulation resting on an autoencoder to create a low-dimensional latent encoding. A key innovation is the integration of the differentiable decoder into the physics-informed loss function, enabling on-the-fly reconstruction of complex conductivity fields via automatic differentiation. The approach yields accurate, mass-conserving flow solutions and supports efficient uncertainty quantification, providing a general methodology for physics-constrained data-driven modeling of heterogeneous systems.

</details>
