{"id": "2511.00743", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.00743", "abs": "https://arxiv.org/abs/2511.00743", "authors": ["Ali Entezari", "Vahid Badali", "Sara Checa"], "title": "Biomechanical and Mechanobiological Modelling of Functionally Graded Scaffolds for Large Bone Defects", "comment": null, "summary": "Critical sized bone defects remain a major clinical challenge, requiring\nscaffolds that combine mechanical stability with regenerative capacity.\nFunctionally graded (FG) scaffolds, inspired by the graded architecture of\nnative bone, offer a promising solution by spatially varying porosity to\noptimise both load transfer and tissue ingrowth. Here, we present an integrated\nfinite element agent based modelling (FEA ABM) framework to simultaneously\nevaluate the biomechanics and regenerative potential of FG scaffolds under\nphysiologically relevant conditions. Cylindrical scaffolds with axial or radial\npore size gradients were compared with uniform controls. The finite element\nmodel incorporated poroelastic tissue mechanics and gait related loading to\ncompute local shear strain and fluid velocity, which guided cellular behaviours\nin the agent based model, including progenitor migration, proliferation,\ndifferentiation, and apoptosis. Simulations over 150 days revealed that axial\ngradients with larger pores at the host bone interface promoted greater bone\ningrowth, while radial gradients with denser peripheral struts substantially\nreduced peak von Mises stresses. These findings highlight a fundamental design\ntrade off between maximising regenerative performance and enhancing structural\ncompetence. The coupled FEA ABM framework establishes a mechanistic platform\nfor the rational design of next-generation FG scaffolds, offering a pathway\ntoward preclinical optimisation of implants tailored to defect location and\nloading environment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6709\u9650\u5143\u5206\u6790\u548c\u57fa\u4e8e\u4ee3\u7406\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u529f\u80fd\u68af\u5ea6\u652f\u67b6\u5728\u9aa8\u7f3a\u635f\u4fee\u590d\u4e2d\u7684\u751f\u7269\u529b\u5b66\u548c\u518d\u751f\u6f5c\u529b\uff0c\u53d1\u73b0\u8f74\u5411\u68af\u5ea6\u4fc3\u8fdb\u9aa8\u957f\u5165\uff0c\u5f84\u5411\u68af\u5ea6\u589e\u5f3a\u7ed3\u6784\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e34\u754c\u5c3a\u5bf8\u9aa8\u7f3a\u635f\u662f\u4e34\u5e8a\u4e3b\u8981\u6311\u6218\uff0c\u9700\u8981\u517c\u5177\u673a\u68b0\u7a33\u5b9a\u6027\u548c\u518d\u751f\u80fd\u529b\u7684\u652f\u67b6\u3002\u529f\u80fd\u68af\u5ea6\u652f\u67b6\u901a\u8fc7\u7a7a\u95f4\u53d8\u5316\u5b54\u9699\u7387\u6765\u4f18\u5316\u8f7d\u8377\u4f20\u9012\u548c\u7ec4\u7ec7\u957f\u5165\u3002", "method": "\u5f00\u53d1\u4e86\u96c6\u6210\u6709\u9650\u5143-\u57fa\u4e8e\u4ee3\u7406\u5efa\u6a21\u6846\u67b6\uff0c\u6a21\u62df\u5706\u67f1\u5f62\u652f\u67b6\u5728\u751f\u7406\u76f8\u5173\u6761\u4ef6\u4e0b\u7684\u751f\u7269\u529b\u5b66\u548c\u7ec6\u80de\u884c\u4e3a\u3002\u6709\u9650\u5143\u6a21\u578b\u5305\u542b\u591a\u5b54\u5f39\u6027\u7ec4\u7ec7\u529b\u5b66\u548c\u6b65\u6001\u76f8\u5173\u8f7d\u8377\uff0c\u57fa\u4e8e\u4ee3\u7406\u6a21\u578b\u6a21\u62df\u7ec6\u80de\u8fc1\u79fb\u3001\u589e\u6b96\u3001\u5206\u5316\u548c\u51cb\u4ea1\u3002", "result": "150\u5929\u6a21\u62df\u663e\u793a\uff1a\u8f74\u5411\u68af\u5ea6\uff08\u9aa8\u754c\u9762\u5904\u8f83\u5927\u5b54\u9699\uff09\u4fc3\u8fdb\u66f4\u591a\u9aa8\u957f\u5165\uff0c\u5f84\u5411\u68af\u5ea6\uff08\u8f83\u5bc6\u5916\u5468\u652f\u67f1\uff09\u663e\u8457\u964d\u4f4e\u5cf0\u503c\u51af\u00b7\u7c73\u585e\u65af\u5e94\u529b\uff0c\u63ed\u793a\u4e86\u518d\u751f\u6027\u80fd\u4e0e\u7ed3\u6784\u80fd\u529b\u4e4b\u95f4\u7684\u8bbe\u8ba1\u6743\u8861\u3002", "conclusion": "\u8026\u5408FEA-ABM\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u529f\u80fd\u68af\u5ea6\u652f\u67b6\u7684\u7406\u6027\u8bbe\u8ba1\u5efa\u7acb\u4e86\u673a\u5236\u5e73\u53f0\uff0c\u4e3a\u9488\u5bf9\u7f3a\u635f\u4f4d\u7f6e\u548c\u8f7d\u8377\u73af\u5883\u7684\u690d\u5165\u7269\u4e34\u5e8a\u524d\u4f18\u5316\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.01005", "categories": ["physics.comp-ph", "hep-lat", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.01005", "abs": "https://arxiv.org/abs/2511.01005", "authors": ["Timoteo Lee", "Frank Br\u00fcckerhoff-Pl\u00fcckelmann", "Jelle Dijkstra", "Jan M. Pawlowski", "Wolfram Pernice"], "title": "Integrated photonic multigrid solver for partial differential equations", "comment": "19 pages, 4 figures", "summary": "Solving partial differential equations is crucial to analysing and predicting\ncomplex, large-scale physical systems but pushes conventional high-performance\ncomputers to their limits. Application specific photonic processors are an\nexciting computing paradigm for building efficient, ultrafast hardware\naccelerators. Here, we investigate the synergy between multigrid based partial\ndifferential equations solvers and low latency photonic matrix vector\nmultipliers. We propose a mixed-precision photonic multigrid solver, that\noffloads the computationally demanding smoothening procedure to the optical\ndomain. We test our approach on an integrated photonic accelerator operating at\n2 GSPS solving a Poisson and Schr\\\"odinger equation. By offloading the\nsmoothening operation to the photonic system, we can reduce the digital\noperation by more than 80%. Finally, we show that the photonic multigrid solver\npotentially reduces digital operations by up to 97 % in lattice quantum\nchromodynamics (LQCD) calculations, enabling an order-of-magnitude gain in\ncomputational speed and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7cbe\u5ea6\u7684\u5149\u5b50\u591a\u91cd\u7f51\u683c\u6c42\u89e3\u5668\uff0c\u5c06\u8ba1\u7b97\u5bc6\u96c6\u7684\u5e73\u6ed1\u8fc7\u7a0b\u5378\u8f7d\u5230\u5149\u5b66\u57df\uff0c\u5728\u5149\u5b50\u52a0\u901f\u5668\u4e0a\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u53ef\u51cf\u5c1180%\u4ee5\u4e0a\u7684\u6570\u5b57\u8fd0\u7b97\u3002", "motivation": "\u4f20\u7edf\u9ad8\u6027\u80fd\u8ba1\u7b97\u673a\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u9762\u4e34\u6781\u9650\uff0c\u9700\u8981\u6784\u5efa\u9ad8\u6548\u3001\u8d85\u5feb\u7684\u5149\u5b50\u786c\u4ef6\u52a0\u901f\u5668\u6765\u5206\u6790\u548c\u9884\u6d4b\u590d\u6742\u7684\u5927\u89c4\u6a21\u7269\u7406\u7cfb\u7edf\u3002", "method": "\u5229\u7528\u4f4e\u5ef6\u8fdf\u5149\u5b50\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u5668\u4e0e\u591a\u91cd\u7f51\u683c\u504f\u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u5668\u7684\u534f\u540c\u4f5c\u7528\uff0c\u63d0\u51fa\u6df7\u5408\u7cbe\u5ea6\u5149\u5b50\u591a\u91cd\u7f51\u683c\u6c42\u89e3\u5668\uff0c\u5c06\u5e73\u6ed1\u8fc7\u7a0b\u5378\u8f7d\u5230\u5149\u5b66\u57df\u3002", "result": "\u57282 GSPS\u7684\u96c6\u6210\u5149\u5b50\u52a0\u901f\u5668\u4e0a\u6d4b\u8bd5\u4e86\u6cca\u677e\u65b9\u7a0b\u548c\u859b\u5b9a\u8c14\u65b9\u7a0b\u6c42\u89e3\uff0c\u901a\u8fc7\u5c06\u5e73\u6ed1\u64cd\u4f5c\u5378\u8f7d\u5230\u5149\u5b50\u7cfb\u7edf\uff0c\u53ef\u51cf\u5c1180%\u4ee5\u4e0a\u7684\u6570\u5b57\u8fd0\u7b97\u3002\u5728\u6676\u683c\u91cf\u5b50\u8272\u52a8\u529b\u5b66\u8ba1\u7b97\u4e2d\uff0c\u5149\u5b50\u591a\u91cd\u7f51\u683c\u6c42\u89e3\u5668\u53ef\u80fd\u51cf\u5c11\u9ad8\u8fbe97%\u7684\u6570\u5b57\u8fd0\u7b97\u3002", "conclusion": "\u5149\u5b50\u591a\u91cd\u7f51\u683c\u6c42\u89e3\u5668\u5b9e\u73b0\u4e86\u8ba1\u7b97\u901f\u5ea6\u548c\u6548\u7387\u7684\u6570\u91cf\u7ea7\u63d0\u5347\uff0c\u4e3a\u5927\u89c4\u6a21\u7269\u7406\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5149\u5b50\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01178", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.01178", "abs": "https://arxiv.org/abs/2511.01178", "authors": ["Ming Tang", "Zi-Yi Pan", "Ni Yang", "Xiao-Xiao Cai"], "title": "BzScope: an absolute cross section calculator for neutron-phonon scattering", "comment": null, "summary": "BzScope is a Python package designed for efficiently calculating absolute\ncross sections of neutron-phonon inelastic scattering for crystalline powders\nin large phase spaces, addressing the limitations of traditional histogramming\ntechniques in reproducing sharp structures and ensuring convergence. The\npackage employs an adapted integral method and supports calculations of single-\nand two-phonon scattering functions in ideal crystalline powders, with\nnumerical robustness up to a momentum transfer of 100 Ang^-1. Higher order\nscatterings up to several hundred orders are calculated by incoherent\napproximation in a well-established thermal neutron scattering physics package,\nNCrystal. In addition, a NCrystal plugin is made available for NCrystal-enabled\nMonte Carlo packages, facilitating direct comparison between the new physics\nand experimental data.\n  Validation against NCrystal demonstrates good agreement in incoherent\nscattering for cubic systems Ni. In addition, it shows improved accuracy for\nlow-symmetry materials $NiP_2$ by avoiding the isotropic atomic displacement\napproximations in NCrystal. Benchmarks the experimental differential cross\nsection of LiH and total cross section of Be confirm its reliability.\n  BzScope integrates with NCrystal via a plugin and therefore can be directly\nused in any NCrystal-enabled Monte Carlo package. This tool enhances the\nefficiency and accuracy of neutron scattering simulations, advancing the study\nof condensed matter dynamics.", "AI": {"tldr": "BzScope\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u6676\u4f53\u7c89\u672b\u4e2d\u4e2d\u5b50-\u58f0\u5b50\u975e\u5f39\u6027\u6563\u5c04\u7edd\u5bf9\u622a\u9762\u7684Python\u8f6f\u4ef6\u5305\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u76f4\u65b9\u56fe\u65b9\u6cd5\u5728\u518d\u73b0\u5c16\u9510\u7ed3\u6784\u548c\u786e\u4fdd\u6536\u655b\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4e2d\u5b50\u6563\u5c04\u6a21\u62df\u65b9\u6cd5\u5728\u5904\u7406\u5927\u76f8\u7a7a\u95f4\u65f6\u96be\u4ee5\u51c6\u786e\u518d\u73b0\u5c16\u9510\u7ed3\u6784\u5e76\u786e\u4fdd\u6536\u655b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u548c\u7cbe\u786e\u7684\u8ba1\u7b97\u5de5\u5177\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684\u79ef\u5206\u65b9\u6cd5\uff0c\u652f\u6301\u7406\u60f3\u6676\u4f53\u7c89\u672b\u4e2d\u5355\u58f0\u5b50\u548c\u53cc\u58f0\u5b50\u6563\u5c04\u51fd\u6570\u7684\u8ba1\u7b97\uff0c\u6570\u503c\u7a33\u5b9a\u6027\u53ef\u8fbe100 \u00c5^-1\u52a8\u91cf\u8f6c\u79fb\u3002\u9ad8\u9636\u6563\u5c04\u901a\u8fc7NCrystal\u5305\u4e2d\u7684\u975e\u76f8\u5e72\u8fd1\u4f3c\u8ba1\u7b97\u3002", "result": "\u9a8c\u8bc1\u663e\u793a\u4e0eNCrystal\u5728\u7acb\u65b9\u7cfb\u7edfNi\u7684\u975e\u76f8\u5e72\u6563\u5c04\u4e2d\u5177\u6709\u826f\u597d\u4e00\u81f4\u6027\uff0c\u5bf9\u4f4e\u5bf9\u79f0\u6027\u6750\u6599NiP2\u907f\u514d\u4e86\u5404\u5411\u540c\u6027\u539f\u5b50\u4f4d\u79fb\u8fd1\u4f3c\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002LiH\u548cBe\u7684\u5b9e\u9a8c\u6570\u636e\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u5b9e\u4e86\u53ef\u9760\u6027\u3002", "conclusion": "BzScope\u901a\u8fc7NCrystal\u63d2\u4ef6\u4e0e\u8499\u7279\u5361\u7f57\u8f6f\u4ef6\u5305\u96c6\u6210\uff0c\u63d0\u9ad8\u4e86\u4e2d\u5b50\u6563\u5c04\u6a21\u62df\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u63a8\u52a8\u4e86\u51dd\u805a\u6001\u52a8\u529b\u5b66\u7814\u7a76\u3002"}}
{"id": "2511.01442", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.01442", "abs": "https://arxiv.org/abs/2511.01442", "authors": ["Benedikt M. Reible", "Nils Liebreich", "Carsten Hartmann", "Luigi Delle Site"], "title": "A fast and rigorous numerical tool to measure length-scale artifacts in molecular simulations", "comment": "28 pages, 6 figures", "summary": "The two-sided Bogoliubov inequality for classical and quantum many-body\nsystems is a theorem that provides rigorous bounds on the free-energy cost of\npartitioning a given system into two or more independent subsystems. This\ntheorem motivates the definition of a quality factor which directly quantifies\nthe degree of statistical-mechanical consistency achieved by a given simulation\nbox size. A major technical merit of the theorem is that, for systems with\ntwo-body interactions and a known radial distribution function, the quality\nfactor can be computed by evaluating just two six-dimensional integrals. In\nthis work, we present a numerical algorithm for computing the quality factor\nand demonstrate its consistency with respect to results in the literature\nobtained from simulations performed at different box sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u503c\u7b97\u6cd5\u6765\u8ba1\u7b97\u8d28\u91cf\u56e0\u5b50\uff0c\u7528\u4e8e\u91cf\u5316\u7ed9\u5b9a\u6a21\u62df\u76d2\u5b50\u5c3a\u5bf8\u4e0b\u7edf\u8ba1\u529b\u5b66\u7684\u4e00\u81f4\u6027\u7a0b\u5ea6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4e0e\u6587\u732e\u4e2d\u4e0d\u540c\u76d2\u5b50\u5c3a\u5bf8\u6a21\u62df\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u57fa\u4e8e\u53cc\u9762Bogoliubov\u4e0d\u7b49\u5f0f\u5b9a\u7406\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u5b9a\u4e49\u4e00\u4e2a\u8d28\u91cf\u56e0\u5b50\u6765\u76f4\u63a5\u91cf\u5316\u7ed9\u5b9a\u6a21\u62df\u76d2\u5b50\u5c3a\u5bf8\u4e0b\u7edf\u8ba1\u529b\u5b66\u7684\u4e00\u81f4\u6027\u7a0b\u5ea6\uff0c\u4ece\u800c\u4e3a\u591a\u4f53\u7cfb\u7edf\u7684\u81ea\u7531\u80fd\u6210\u672c\u63d0\u4f9b\u4e25\u683c\u754c\u9650\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u503c\u7b97\u6cd5\u6765\u8ba1\u7b97\u8d28\u91cf\u56e0\u5b50\uff0c\u8be5\u7b97\u6cd5\u5bf9\u4e8e\u5177\u6709\u4e8c\u4f53\u76f8\u4e92\u4f5c\u7528\u548c\u5df2\u77e5\u5f84\u5411\u5206\u5e03\u51fd\u6570\u7684\u7cfb\u7edf\uff0c\u53ea\u9700\u8ba1\u7b97\u4e24\u4e2a\u516d\u7ef4\u79ef\u5206\u5373\u53ef\u3002", "result": "\u7b97\u6cd5\u8ba1\u7b97\u7ed3\u679c\u4e0e\u6587\u732e\u4e2d\u4e0d\u540c\u76d2\u5b50\u5c3a\u5bf8\u6a21\u62df\u7ed3\u679c\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u503c\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u8ba1\u7b97\u8d28\u91cf\u56e0\u5b50\uff0c\u4e3a\u8bc4\u4f30\u6a21\u62df\u76d2\u5b50\u5c3a\u5bf8\u7684\u7edf\u8ba1\u529b\u5b66\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2511.00002", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00002", "abs": "https://arxiv.org/abs/2511.00002", "authors": ["Yurun Wu", "Yousong Sun", "Burkhard Wunsche", "Jia Wang", "Elliott Wen"], "title": "VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games", "comment": null, "summary": "Virtual Reality (VR) has rapidly become a mainstream platform for gaming and\ninteractive experiences, yet ensuring the quality, safety, and appropriateness\nof VR content remains a pressing challenge. Traditional human-based quality\nassurance is labor-intensive and cannot scale with the industry's rapid growth.\nWhile automated testing has been applied to traditional 2D and 3D games,\nextending it to VR introduces unique difficulties due to high-dimensional\nsensory inputs and strict real-time performance requirements. We present\nVRScout, a deep learning-based agent capable of autonomously navigating VR\nenvironments and interacting with virtual objects in a human-like and real-time\nmanner. VRScout learns from human demonstrations using an enhanced Action\nChunking Transformer that predicts multi-step action sequences. This enables\nour agent to capture higher-level strategies and generalize across diverse\nenvironments. To balance responsiveness and precision, we introduce a\ndynamically adjustable sliding horizon that adapts the agent's temporal context\nat runtime. We evaluate VRScout on commercial VR titles and show that it\nachieves expert-level performance with only limited training data, while\nmaintaining real-time inference at 60 FPS on consumer-grade hardware. These\nresults position VRScout as a practical and scalable framework for automated VR\ngame testing, with direct applications in both quality assurance and safety\nauditing.", "AI": {"tldr": "VRScout\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u81ea\u4e3bVR\u6d4b\u8bd5\u4ee3\u7406\uff0c\u80fd\u591f\u4ee5\u4eba\u7c7b\u65b9\u5f0f\u5b9e\u65f6\u5bfc\u822aVR\u73af\u5883\u5e76\u4ea4\u4e92\uff0c\u7528\u4e8e\u81ea\u52a8\u5316VR\u6e38\u620f\u6d4b\u8bd5\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5VR\u5185\u5bb9\u8d28\u91cf\u4fdd\u8bc1\u52b3\u52a8\u5bc6\u96c6\u4e14\u65e0\u6cd5\u9002\u5e94\u884c\u4e1a\u5feb\u901f\u589e\u957f\uff0c\u800c\u73b0\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9VR\u7684\u9ad8\u7ef4\u611f\u5b98\u8f93\u5165\u548c\u5b9e\u65f6\u6027\u80fd\u8981\u6c42\u3002", "method": "\u4f7f\u7528\u589e\u5f3a\u578bAction Chunking Transformer\u4ece\u4eba\u7c7b\u6f14\u793a\u4e2d\u5b66\u4e60\uff0c\u9884\u6d4b\u591a\u6b65\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u53ef\u8c03\u6ed1\u52a8\u89c6\u754c\u6765\u5e73\u8861\u54cd\u5e94\u6027\u548c\u7cbe\u5ea6\u3002", "result": "\u5728\u5546\u4e1aVR\u6e38\u620f\u4e2d\u8fbe\u5230\u4e13\u5bb6\u7ea7\u6027\u80fd\uff0c\u4ec5\u9700\u6709\u9650\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u4fdd\u630160 FPS\u7684\u5b9e\u65f6\u63a8\u7406\u3002", "conclusion": "VRScout\u4e3a\u81ea\u52a8\u5316VR\u6e38\u620f\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u8d28\u91cf\u4fdd\u8bc1\u548c\u5b89\u5168\u5ba1\u8ba1\u3002"}}
{"id": "2511.00238", "categories": ["gr-qc", "astro-ph.CO"], "pdf": "https://arxiv.org/pdf/2511.00238", "abs": "https://arxiv.org/abs/2511.00238", "authors": ["Alexander Leithes"], "title": "Conserved Quantities in Expanding G\u00f6del Cosmology", "comment": "11 pages, 0 figures", "summary": "At linear order we study perturbations to a G\\\"odel background spacetime\nwhich includes expansion in addition to rotation. We investigate the\ntransformation behaviour of these perturbations under gauge transformations and\nconstruct gauge invariant quantities. Using the perturbed energy conservation\nequation we find that there are conserved quantities in Expanding G\\\"odel (EG)\nCosmology, in particular a spatial metric trace perturbation, {\\zeta} SMTP ,\nwhich is conserved on large scales for pressureless dust. We intend to extend\nour discussion to a perfect fluid matter content with a view to also obtaining\nconserved quantities in this context.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5305\u542b\u81a8\u80c0\u548c\u65cb\u8f6c\u7684G\u00f6del\u80cc\u666f\u65f6\u7a7a\u4e2d\u7684\u7ebf\u6027\u6270\u52a8\uff0c\u6784\u5efa\u4e86\u89c4\u8303\u4e0d\u53d8\u91cf\uff0c\u53d1\u73b0\u5728\u81a8\u80c0G\u00f6del\u5b87\u5b99\u5b66\u4e2d\u5b58\u5728\u5b88\u6052\u91cf\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65e0\u538b\u5c18\u57c3\u5728\u5927\u5c3a\u5ea6\u4e0a\u5b88\u6052\u7684\u7a7a\u95f4\u5ea6\u89c4\u8ff9\u6270\u52a8\u03b6_SMTP\u3002", "motivation": "\u7814\u7a76\u81a8\u80c0G\u00f6del\u5b87\u5b99\u5b66\u4e2d\u7684\u6270\u52a8\u884c\u4e3a\uff0c\u63a2\u7d22\u5728\u5305\u542b\u65cb\u8f6c\u548c\u81a8\u80c0\u7684\u80cc\u666f\u4e0b\u662f\u5426\u5b58\u5728\u5b88\u6052\u91cf\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u8fd9\u7c7b\u5b87\u5b99\u6a21\u578b\u7684\u6027\u8d28\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u7ebf\u6027\u9636\u7814\u7a76G\u00f6del\u80cc\u666f\u65f6\u7a7a\u7684\u6270\u52a8\uff0c\u5206\u6790\u5b83\u4eec\u5728\u89c4\u8303\u53d8\u6362\u4e0b\u7684\u884c\u4e3a\uff0c\u6784\u5efa\u89c4\u8303\u4e0d\u53d8\u91cf\uff0c\u5229\u7528\u6270\u52a8\u80fd\u91cf\u5b88\u6052\u65b9\u7a0b\u5bfb\u627e\u5b88\u6052\u91cf\u3002", "result": "\u53d1\u73b0\u5728\u81a8\u80c0G\u00f6del\u5b87\u5b99\u5b66\u4e2d\u5b58\u5728\u5b88\u6052\u91cf\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65e0\u538b\u5c18\u57c3\uff0c\u7a7a\u95f4\u5ea6\u89c4\u8ff9\u6270\u52a8\u03b6_SMTP\u5728\u5927\u5c3a\u5ea6\u4e0a\u662f\u5b88\u6052\u7684\u3002", "conclusion": "\u81a8\u80c0G\u00f6del\u5b87\u5b99\u5b66\u4e2d\u5b58\u5728\u5b88\u6052\u91cf\uff0c\u4f5c\u8005\u8ba1\u5212\u5c06\u7814\u7a76\u6269\u5c55\u5230\u5b8c\u7f8e\u6d41\u4f53\u7269\u8d28\u5185\u5bb9\uff0c\u4ee5\u5728\u8be5\u80cc\u666f\u4e0b\u4e5f\u83b7\u5f97\u5b88\u6052\u91cf\u3002"}}
{"id": "2511.00150", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.00150", "abs": "https://arxiv.org/abs/2511.00150", "authors": ["Christopher L. Baldwin"], "title": "Simulated outperforms quantum reverse annealing in mean-field models", "comment": "20 pages, 9 figures. Comments welcome!", "summary": "Adiabatic reverse annealing (ARA) has been proposed as an improvement to\nconventional quantum annealing for solving optimization problems, in which one\ntakes advantage of an initial guess at the solution to suppress problematic\nphase transitions. Here we interpret the performance of ARA through its effects\non the free energy landscape, and use the intuition gained to introduce a\nclassical analogue to ARA termed ``simulated reverse annealing'' (SRA). This\nmakes it more difficult to claim that ARA provides a quantum advantage in\nsolving a given problem, as not only must ARA succeed but the corresponding SRA\nmust fail. As a solvable example, we analyze how both protocols behave in the\ninfinite-range (non-disordered) $p$-spin model. Through both the thermodynamic\nphase diagrams and explicit dynamical behavior, we establish that the quantum\nalgorithm has no advantage over its classical counterpart: SRA succeeds not\nonly in every case where ARA does but even in a narrow range of parameters\nwhere ARA fails.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7edd\u70ed\u53cd\u5411\u9000\u706b(ARA)\u53ca\u5176\u7ecf\u5178\u5bf9\u5e94\u65b9\u6cd5\u6a21\u62df\u53cd\u5411\u9000\u706b(SRA)\u5728\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5728\u65e0\u9650\u8303\u56f4p-\u81ea\u65cb\u6a21\u578b\u4e2d\uff0cSRA\u4e0d\u4ec5\u5728\u6240\u6709ARA\u6210\u529f\u7684\u60c5\u51b5\u4e0b\u90fd\u80fd\u6210\u529f\uff0c\u751a\u81f3\u5728\u67d0\u4e9bARA\u5931\u8d25\u7684\u53c2\u6570\u8303\u56f4\u5185\u4e5f\u80fd\u6210\u529f\uff0c\u8868\u660eARA\u76f8\u5bf9\u4e8eSRA\u6ca1\u6709\u91cf\u5b50\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u7edd\u70ed\u53cd\u5411\u9000\u706b(ARA)\u76f8\u5bf9\u4e8e\u4f20\u7edf\u91cf\u5b50\u9000\u706b\u7684\u6539\u8fdb\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5229\u7528\u521d\u59cb\u89e3\u731c\u6d4b\u6765\u6291\u5236\u95ee\u9898\u76f8\u53d8\u7684\u80fd\u529b\uff0c\u5e76\u63a2\u8ba8ARA\u662f\u5426\u771f\u6b63\u63d0\u4f9b\u91cf\u5b50\u4f18\u52bf\u3002", "method": "\u901a\u8fc7\u81ea\u7531\u80fd\u666f\u89c2\u5206\u6790ARA\u6027\u80fd\uff0c\u5f15\u5165\u7ecf\u5178\u5bf9\u5e94\u65b9\u6cd5\u6a21\u62df\u53cd\u5411\u9000\u706b(SRA)\uff0c\u5728\u65e0\u9650\u8303\u56f4p-\u81ea\u65cb\u6a21\u578b\u4e2d\u5bf9\u4e24\u79cd\u534f\u8bae\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u52a8\u529b\u5b66\u884c\u4e3a\u6bd4\u8f83\u3002", "result": "\u5728\u65e0\u9650\u8303\u56f4p-\u81ea\u65cb\u6a21\u578b\u4e2d\uff0c\u6a21\u62df\u53cd\u5411\u9000\u706b(SRA)\u4e0d\u4ec5\u5728\u6240\u6709\u7edd\u70ed\u53cd\u5411\u9000\u706b(ARA)\u6210\u529f\u7684\u60c5\u51b5\u4e0b\u90fd\u80fd\u6210\u529f\uff0c\u751a\u81f3\u5728\u67d0\u4e9bARA\u5931\u8d25\u7684\u53c2\u6570\u8303\u56f4\u5185\u4e5f\u80fd\u6210\u529f\u3002", "conclusion": "\u91cf\u5b50\u7b97\u6cd5\u76f8\u5bf9\u4e8e\u5176\u7ecf\u5178\u5bf9\u5e94\u65b9\u6cd5\u6ca1\u6709\u4f18\u52bf\uff0c\u8981\u58f0\u79f0ARA\u63d0\u4f9b\u91cf\u5b50\u4f18\u52bf\uff0c\u4e0d\u4ec5\u9700\u8981ARA\u6210\u529f\uff0c\u8fd8\u9700\u8981\u76f8\u5e94\u7684SRA\u5931\u8d25\uff0c\u4f46\u5728\u7814\u7a76\u7684\u6a21\u578b\u4e2d\u8fd9\u79cd\u60c5\u51b5\u5e76\u672a\u51fa\u73b0\u3002"}}
{"id": "2511.01596", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.01596", "abs": "https://arxiv.org/abs/2511.01596", "authors": ["Hadis Ghodrati Saeini", "Kevin Preis", "Thi Ngoc Ha", "Christoph Tegenkamp", "Sibylle Gemming", "Jeffrey Kelling", "Florian G\u00fcnther"], "title": "Simulation of Self-Assembled Monolayers of Polyalanine $\u03b1$-Helix Using an Effective Potential", "comment": null, "summary": "Self-assembled monolayers of $\\alpha$-polyalanine helices exhibit distinct\nstructural phases with implications for chiral-induced spin selectivity. We\ncombine scanning tunneling microscopy and theoretical modeling to reveal how\nchiral composition governs supramolecular organization. Enantiopure systems\nform hexagonal lattices, while racemic mixtures organize into rectangular\nphases with stripe-like features. Our SCC-DFTB derived interaction potentials\nshow that opposite-handed helix pairs exhibit stronger binding and closer\npacking, explaining the denser racemic structures. Crucially, we demonstrate\nthat the observed STM contrast arises from anti-parallel alignment of\nopposite-handed helices rather than physical height variations. These findings\nestablish fundamental structure-property relationships for designing\npeptide-based spintronic materials.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u03b1-\u805a\u4e19\u6c28\u9178\u87ba\u65cb\u81ea\u7ec4\u88c5\u5355\u5c42\u819c\u7684\u7ed3\u6784\u76f8\u53ca\u5176\u5bf9\u624b\u6027\u8bf1\u5bfc\u81ea\u65cb\u9009\u62e9\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bf9\u6620\u7eaf\u4f53\u7cfb\u5f62\u6210\u516d\u65b9\u6676\u683c\uff0c\u5916\u6d88\u65cb\u6df7\u5408\u7269\u5f62\u6210\u77e9\u5f62\u76f8\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u6a21\u578b\u63ed\u793a\u4e86\u7ed3\u6784\u5dee\u5f02\u7684\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u624b\u6027\u7ec4\u6210\u5982\u4f55\u63a7\u5236\u8d85\u5206\u5b50\u7ec4\u7ec7\uff0c\u5efa\u7acb\u80bd\u57fa\u81ea\u65cb\u7535\u5b50\u6750\u6599\u7684\u57fa\u672c\u7ed3\u6784-\u6027\u8d28\u5173\u7cfb\u3002", "method": "\u7ed3\u5408\u626b\u63cf\u96a7\u9053\u663e\u5fae\u955c\u548cSCC-DFTB\u7406\u8bba\u5efa\u6a21\uff0c\u5206\u6790\u4e0d\u540c\u624b\u6027\u7ec4\u6210\u7684\u81ea\u7ec4\u88c5\u7ed3\u6784\u3002", "result": "\u5bf9\u6620\u7eaf\u4f53\u7cfb\u5f62\u6210\u516d\u65b9\u6676\u683c\uff0c\u5916\u6d88\u65cb\u6df7\u5408\u7269\u5f62\u6210\u66f4\u7d27\u5bc6\u7684\u77e9\u5f62\u76f8\uff1bSTM\u5bf9\u6bd4\u5ea6\u6e90\u4e8e\u76f8\u53cd\u624b\u6027\u87ba\u65cb\u7684\u53cd\u5e73\u884c\u6392\u5217\u800c\u975e\u7269\u7406\u9ad8\u5ea6\u53d8\u5316\u3002", "conclusion": "\u5efa\u7acb\u4e86\u80bd\u57fa\u81ea\u65cb\u7535\u5b50\u6750\u6599\u8bbe\u8ba1\u7684\u57fa\u672c\u7ed3\u6784-\u6027\u8d28\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u624b\u6027\u7ec4\u6210\u5bf9\u8d85\u5206\u5b50\u7ec4\u7ec7\u7684\u8c03\u63a7\u673a\u5236\u3002"}}
{"id": "2511.00029", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00029", "abs": "https://arxiv.org/abs/2511.00029", "authors": ["Samaksh Bhargav", "Zining Zhu"], "title": "Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts", "comment": "12 pages, 6 figures", "summary": "Large Language Model (LLM) deployment requires guiding the LLM to recognize\nand not answer unsafe prompts while complying with safe prompts. Previous\nmethods for achieving this require adjusting model weights along with other\nexpensive procedures. While recent advances in Sparse Autoencoders (SAEs) have\nenabled interpretable feature extraction from LLMs, existing approaches lack\nsystematic feature selection methods and principled evaluation of\nsafety-utility tradeoffs. We explored using different steering features and\nsteering strengths using Sparse Auto Encoders (SAEs) to provide a solution.\nUsing an accurate and innovative contrasting prompt method with the\nAI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air\nBench eu-dataset to efficiently choose the best features in the model to steer,\nwe tested this method on Llama-3 8B. We conclude that using this method, our\napproach achieves an 18.9% improvement in safety performance while\nsimultaneously increasing utility by 11.1%, demonstrating that targeted SAE\nsteering can overcome traditional safety-utility tradeoffs when optimal\nfeatures are identified through principled selection methods.", "AI": {"tldr": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAE)\u7279\u5f81\u9009\u62e9\u548c\u5bf9\u6bd4\u63d0\u793a\u65b9\u6cd5\uff0c\u5728Llama-3 8B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u90e8\u7f72\u65b9\u6cd5\u9700\u8981\u8c03\u6574\u6a21\u578b\u6743\u91cd\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u800c\u73b0\u6709\u7684SAE\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7279\u5f81\u9009\u62e9\u548c\u539f\u5219\u6027\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5bf9\u6bd4\u63d0\u793a\u65b9\u6cd5\u4eceAI-Generated Prompts Dataset\u548cAir Bench eu-dataset\u4e2d\u9ad8\u6548\u9009\u62e9\u6700\u4f73\u7279\u5f81\u8fdb\u884c\u5f15\u5bfc\u3002", "result": "\u5728Llama-3 8B\u6a21\u578b\u4e0a\uff0c\u5b89\u5168\u6027\u6027\u80fd\u63d0\u534718.9%\uff0c\u540c\u65f6\u5b9e\u7528\u6027\u589e\u52a011.1%\u3002", "conclusion": "\u901a\u8fc7\u539f\u5219\u6027\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u8bc6\u522b\u6700\u4f18\u7279\u5f81\uff0c\u5b9a\u5411SAE\u5f15\u5bfc\u53ef\u4ee5\u514b\u670d\u4f20\u7edf\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u3002"}}
{"id": "2511.00307", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2511.00307", "abs": "https://arxiv.org/abs/2511.00307", "authors": ["Healey Kogan", "Frederick C. L. Pardoe", "Helvi Witek"], "title": "Spin-up and mass-gain in hyperbolic encounters of spinning black holes", "comment": "23 pages, 23 figures", "summary": "Scattering black holes spin up and gain mass through the re-absorption of\norbital angular momentum and energy radiated in gravitational waves during\ntheir encounter. In this work, we perform a series of numerical relativity\nsimulations to investigate the spin-up and mass-gain for equal-mass black holes\nwith a wide range of equal initial spins, $\\chi_{\\rm i}\\in[-0.7,0.7]$, aligned\n(or anti-aligned) to the orbital angular momentum. We also consider a variety\nof initial momenta. Furthermore, we explore a range of incident angles and\nidentify the threshold between scattering and merging configurations. The\nspin-up and mass-gain are typically largest in systems with incident angles\nclose to the threshold value, large momenta, and negative (i.e. anti-aligned)\ninitial spins. When evaluated at the threshold angle, we find that the spin-up\ndecreases linearly with initial spin. Intriguingly, systems with initial spin\n$\\chi_{\\rm i}=0.7$ sometimes experience a spin-down, in spite of an increase in\nthe black-hole angular momentum, due to a corresponding gain in the black-hole\nmass. Across the simulation suite, we find a maximum spin-up of $0.3$ and a\nmaximum increase in the black-hole mass of $15\\%$.", "AI": {"tldr": "\u901a\u8fc7\u6570\u503c\u76f8\u5bf9\u8bba\u6a21\u62df\u7814\u7a76\u7b49\u8d28\u91cf\u9ed1\u6d1e\u6563\u5c04\u8fc7\u7a0b\u4e2d\u7684\u81ea\u65cb\u589e\u957f\u548c\u8d28\u91cf\u589e\u52a0\uff0c\u53d1\u73b0\u6700\u5927\u81ea\u65cb\u589e\u957f\u4e3a0.3\uff0c\u6700\u5927\u8d28\u91cf\u589e\u52a0\u4e3a15%\u3002", "motivation": "\u7814\u7a76\u9ed1\u6d1e\u5728\u6563\u5c04\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u5438\u6536\u5f15\u529b\u6ce2\u8f90\u5c04\u7684\u8f68\u9053\u89d2\u52a8\u91cf\u548c\u80fd\u91cf\u800c\u83b7\u5f97\u81ea\u65cb\u589e\u957f\u548c\u8d28\u91cf\u589e\u52a0\u7684\u7269\u7406\u673a\u5236\u3002", "method": "\u8fdb\u884c\u4e00\u7cfb\u5217\u6570\u503c\u76f8\u5bf9\u8bba\u6a21\u62df\uff0c\u6db5\u76d6\u7b49\u8d28\u91cf\u9ed1\u6d1e\u7684\u5e7f\u6cdb\u521d\u59cb\u81ea\u65cb\u8303\u56f4\uff08\u03c7i\u2208[-0.7,0.7]\uff09\uff0c\u8003\u8651\u4e0d\u540c\u7684\u521d\u59cb\u52a8\u91cf\u3001\u5165\u5c04\u89d2\u5ea6\uff0c\u5e76\u8bc6\u522b\u6563\u5c04\u4e0e\u5408\u5e76\u914d\u7f6e\u7684\u9608\u503c\u3002", "result": "\u5728\u63a5\u8fd1\u9608\u503c\u89d2\u5ea6\u3001\u5927\u52a8\u91cf\u548c\u8d1f\u521d\u59cb\u81ea\u65cb\u7684\u7cfb\u7edf\u4e2d\uff0c\u81ea\u65cb\u589e\u957f\u548c\u8d28\u91cf\u589e\u52a0\u6700\u4e3a\u663e\u8457\u3002\u521d\u59cb\u81ea\u65cb\u4e3a0.7\u7684\u7cfb\u7edf\u6709\u65f6\u4f1a\u51fa\u73b0\u81ea\u65cb\u4e0b\u964d\uff0c\u5c3d\u7ba1\u9ed1\u6d1e\u89d2\u52a8\u91cf\u589e\u52a0\uff0c\u4f46\u7531\u4e8e\u8d28\u91cf\u76f8\u5e94\u589e\u52a0\u3002", "conclusion": "\u9ed1\u6d1e\u6563\u5c04\u8fc7\u7a0b\u4e2d\u7684\u81ea\u65cb\u589e\u957f\u548c\u8d28\u91cf\u589e\u52a0\u53d7\u5230\u521d\u59cb\u81ea\u65cb\u3001\u52a8\u91cf\u548c\u5165\u5c04\u89d2\u5ea6\u7684\u663e\u8457\u5f71\u54cd\uff0c\u6700\u5927\u81ea\u65cb\u589e\u957f\u4e3a0.3\uff0c\u6700\u5927\u8d28\u91cf\u589e\u52a0\u4e3a15%\u3002"}}
{"id": "2511.00224", "categories": ["quant-ph", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.00224", "abs": "https://arxiv.org/abs/2511.00224", "authors": ["Tomonori Shirakawa", "Javier Robledo-Moreno", "Toshinari Itoko", "Vinay Tripathi", "Kento Ueda", "Yukio Kawashima", "Lukas Broers", "William Kirby", "Himadri Pathak", "Hanhee Paik", "Miwako Tsuji", "Yuetsu Kodama", "Mitsuhisa Sato", "Constantinos Evangelinos", "Seetharami Seelam", "Robert Walkup", "Seiji Yunoki", "Mario Motta", "Petar Jurcevic", "Hiroshi Horii", "Antonio Mezzacapo"], "title": "Closed-loop calculations of electronic structure on a quantum processor and a classical supercomputer at full scale", "comment": null, "summary": "Quantum computers must operate in concert with classical computers to deliver\non the promise of quantum advantage for practical problems. To achieve that, it\nis important to understand how quantum and classical computing can interact\ntogether, and how one can characterize the scalability and efficiency of hybrid\nquantum-classical workflows. So far, early experiments with quantum-centric\nsupercomputing workflows have been limited in scale and complexity. Here, we\nuse a Heron quantum processor deployed on premises with the entire\nsupercomputer Fugaku to perform the largest computation of electronic structure\ninvolving quantum and classical high-performance computing. We design a\nclosed-loop workflow between the quantum processors and 152,064 classical nodes\nof Fugaku, to approximate the electronic structure of chemistry models beyond\nthe reach of exact diagonalization, with accuracy comparable to some\nall-classical approximation methods. Our work pushes the limits of the\nintegration of quantum and classical high-performance computing, showcasing\ncomputational resource orchestration at the largest scale possible for current\nclassical supercomputers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728Fugaku\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u96c6\u6210\u4e86Heron\u91cf\u5b50\u5904\u7406\u5668\uff0c\u6784\u5efa\u4e86\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u7cbe\u786e\u5bf9\u89d2\u5316\u80fd\u529b\u7684\u6700\u5927\u89c4\u6a21\u7535\u5b50\u7ed3\u6784\u8ba1\u7b97\u3002", "motivation": "\u7406\u89e3\u91cf\u5b50\u4e0e\u7ecf\u5178\u8ba1\u7b97\u5982\u4f55\u534f\u540c\u5de5\u4f5c\uff0c\u4ee5\u53ca\u5982\u4f55\u8868\u5f81\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5de5\u4f5c\u6d41\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\uff0c\u5b9e\u73b0\u91cf\u5b50\u4f18\u52bf\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u91cf\u5b50\u5904\u7406\u5668\u4e0e152,064\u4e2a\u7ecf\u5178\u8ba1\u7b97\u8282\u70b9\u4e4b\u95f4\u7684\u95ed\u73af\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u7ecf\u5178\u9ad8\u6027\u80fd\u8ba1\u7b97\u6765\u8fd1\u4f3c\u7535\u5b50\u7ed3\u6784\u3002", "result": "\u6210\u529f\u8ba1\u7b97\u4e86\u8d85\u51fa\u7cbe\u786e\u5bf9\u89d2\u5316\u8303\u56f4\u7684\u5316\u5b66\u6a21\u578b\u7535\u5b50\u7ed3\u6784\uff0c\u7cbe\u5ea6\u4e0e\u67d0\u4e9b\u5168\u7ecf\u5178\u8fd1\u4f3c\u65b9\u6cd5\u76f8\u5f53\uff0c\u5c55\u793a\u4e86\u5f53\u524d\u6700\u5927\u89c4\u6a21\u7684\u91cf\u5b50-\u7ecf\u5178\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u6210\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u91cf\u5b50\u4e0e\u7ecf\u5178\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u6210\u7684\u6781\u9650\uff0c\u5c55\u793a\u4e86\u5728\u5f53\u524d\u7ecf\u5178\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u6700\u5927\u89c4\u6a21\u7684\u8d44\u6e90\u7f16\u6392\u80fd\u529b\u3002"}}
{"id": "2511.00030", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00030", "abs": "https://arxiv.org/abs/2511.00030", "authors": ["Myeongseob Ko", "Hoang Anh Just", "Charles Fleming", "Ming Jin", "Ruoxi Jia"], "title": "Probing Knowledge Holes in Unlearned LLMs", "comment": "The Thirty-ninth Annual Conference on Neural Information Processing\n  Systems", "summary": "Machine unlearning has emerged as a prevalent technical solution for\nselectively removing unwanted knowledge absorbed during pre-training, without\nrequiring full retraining. While recent unlearning techniques can effectively\nremove undesirable content without severely compromising performance on\nstandard benchmarks, we find that they may inadvertently create ``knowledge\nholes'' -- unintended losses of benign knowledge that standard benchmarks fail\nto capture. To probe where unlearned models reveal knowledge holes, we propose\na test case generation framework that explores both immediate neighbors of\nunlearned content and broader areas of potential failures. Our evaluation\ndemonstrates significant hidden costs of unlearning: up to 98.7\\% of the test\ncases yield irrelevant or nonsensical responses from unlearned models, despite\nbeing answerable by the pretrained model. These findings necessitate rethinking\nthe conventional approach to evaluating knowledge preservation in unlearning,\nmoving beyond standard, static benchmarks.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u673a\u5668\u9057\u5fd8\u6280\u672f\u867d\u7136\u80fd\u6709\u6548\u79fb\u9664\u4e0d\u826f\u77e5\u8bc6\uff0c\u4f46\u4f1a\u610f\u5916\u9020\u6210\"\u77e5\u8bc6\u7a7a\u6d1e\"\u2014\u2014\u826f\u6027\u77e5\u8bc6\u7684\u975e\u9884\u671f\u635f\u5931\uff0c\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u68c0\u6d4b\u5230\u8fd9\u4e9b\u9690\u85cf\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u6280\u672f\u867d\u7136\u80fd\u6709\u6548\u79fb\u9664\u4e0d\u826f\u5185\u5bb9\u4e14\u4e0d\u5f71\u54cd\u6807\u51c6\u57fa\u51c6\u6027\u80fd\uff0c\u4f46\u53ef\u80fd\u5b58\u5728\u672a\u88ab\u53d1\u73b0\u7684\"\u77e5\u8bc6\u7a7a\u6d1e\"\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6846\u67b6\uff0c\u63a2\u7d22\u9057\u5fd8\u5185\u5bb9\u90bb\u8fd1\u533a\u57df\u548c\u66f4\u5e7f\u6cdb\u7684\u6f5c\u5728\u5931\u6548\u533a\u57df\uff0c\u8bc4\u4f30\u9057\u5fd8\u6a21\u578b\u7684\u77e5\u8bc6\u4fdd\u7559\u60c5\u51b5\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u9057\u5fd8\u5b58\u5728\u663e\u8457\u9690\u85cf\u6210\u672c\uff1a\u9ad8\u8fbe98.7%\u7684\u6d4b\u8bd5\u7528\u4f8b\u5728\u9057\u5fd8\u6a21\u578b\u4e2d\u4ea7\u751f\u65e0\u5173\u6216\u8352\u8c2c\u56de\u7b54\uff0c\u800c\u8fd9\u4e9b\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u662f\u53ef\u56de\u7b54\u7684\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003\u8bc4\u4f30\u673a\u5668\u9057\u5fd8\u4e2d\u77e5\u8bc6\u4fdd\u7559\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u8d85\u8d8a\u6807\u51c6\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u53d1\u73b0\u548c\u89e3\u51b3\u77e5\u8bc6\u7a7a\u6d1e\u95ee\u9898\u3002"}}
{"id": "2511.00347", "categories": ["gr-qc", "astro-ph.CO", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.00347", "abs": "https://arxiv.org/abs/2511.00347", "authors": ["Valerio Faraoni", "Santiago Novoa Cattivelli"], "title": "The thermal view of $f(R)$ cosmology", "comment": "15 pages, 3 figures", "summary": "A new thermal view of scalar-tensor gravity, in which general relativity is\nthe zero-temperature state of gravity, is applied to the specific subclass of\n$f(R)$ gravity theories and, specifically, to spatially homogeneous and\nisotropic universes. Within the limits of application of the new thermal\nformalism, results on the convergence to Einstein cosmology (or lack thereof)\nare first obtained for general $f(R)$ theories, and then illustrated with\npower-law and Starobinsky $f(R)$ gravity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u6807\u91cf-\u5f20\u91cf\u5f15\u529b\u7406\u8bba\u7684\u70ed\u529b\u5b66\u89c2\u70b9\u5e94\u7528\u4e8ef(R)\u5f15\u529b\u7406\u8bba\uff0c\u7279\u522b\u662f\u5747\u5300\u5404\u5411\u540c\u6027\u5b87\u5b99\uff0c\u7814\u7a76\u5176\u5411\u7231\u56e0\u65af\u5766\u5b87\u5b99\u5b66\u7684\u6536\u655b\u6027\u3002", "motivation": "\u5c06\u5e7f\u4e49\u76f8\u5bf9\u8bba\u89c6\u4e3a\u5f15\u529b\u96f6\u6e29\u72b6\u6001\u7684\u65b0\u70ed\u529b\u5b66\u89c2\u70b9\u5e94\u7528\u4e8ef(R)\u5f15\u529b\u7406\u8bba\uff0c\u63a2\u7d22\u8fd9\u7c7b\u7406\u8bba\u5982\u4f55\u6536\u655b\u5230\u7231\u56e0\u65af\u5766\u5b87\u5b99\u5b66\u3002", "method": "\u5728\u70ed\u529b\u5b66\u5f62\u5f0f\u9002\u7528\u7684\u8303\u56f4\u5185\uff0c\u9996\u5148\u5bf9\u4e00\u822cf(R)\u7406\u8bba\u8fdb\u884c\u5206\u6790\uff0c\u7136\u540e\u901a\u8fc7\u5e42\u5f8b\u548cStarobinsky f(R)\u5f15\u529b\u6a21\u578b\u8fdb\u884c\u5177\u4f53\u8bf4\u660e\u3002", "result": "\u83b7\u5f97\u4e86\u5173\u4e8ef(R)\u7406\u8bba\u5411\u7231\u56e0\u65af\u5766\u5b87\u5b99\u5b66\u6536\u655b\uff08\u6216\u4e0d\u6536\u655b\uff09\u7684\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u6a21\u578b\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3f(R)\u5f15\u529b\u7406\u8bba\u5728\u70ed\u529b\u5b66\u6846\u67b6\u4e0b\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u5176\u5411\u6807\u51c6\u5b87\u5b99\u5b66\u6f14\u5316\u7684\u7279\u6027\u3002"}}
{"id": "2511.00243", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00243", "abs": "https://arxiv.org/abs/2511.00243", "authors": ["Gavin Crowder", "Lora Ramunno", "Stephen Hughes"], "title": "Quantum-dot single photon source performance with off-resonant pulse preparation schemes", "comment": "12 pages, 7 figures", "summary": "The preparation of photonic qubits in the excited state is an integral part\nof the performance of an on-demand single photon source (SPS). Conventional\nresonant excitation, an excellent approach to maximize the coherence and\nindistinguishability of the SPS, often requires polarization filtering to\nremove the pump signal and isolate the qubit emission, but this results in an\ninherent 50\\% hit to the efficiency. Recent excitation schemes strategically\ntry to exploit pulses that excite the qubit while avoiding spectral overlap to\nbypass this required filtering. In this work, we compare three such pumping\nschemes to quantify the important SPS figures-of-merit for off-resonant quantum\ndot schemes, using: (i) a symmetrically detuned dichromatic pulse, (ii) a\nnotch-filtered adiabatic rapid passage (NARP) pulse, and (iii) a swing up of\nthe quantum emitter population (SUPER) pulse. Due to large instantaneous pulse\nstrengths, the dichromatic pulse suffers from phonon-induced dephasing which\ncan lower the SPS performance by up to 50\\%. In contrast, the NARP and SUPER\npulses are shielded from phonon coupling to differing degrees but both maintain\nexcellent SPS performance. The SUPER pulse can lose significant efficiency if\nthere is variance in its constituent pulses' amplitude, pulse width, or\nfrequency, while the NARP pulse, though potentially more difficult to realize\nin experiments, is robust against variance in the pulse preparation.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u975e\u5171\u632f\u91cf\u5b50\u70b9\u6cf5\u6d66\u65b9\u6848\uff1a\u5bf9\u79f0\u5931\u8c10\u53cc\u8272\u8109\u51b2\u3001\u9677\u6ce2\u6ee4\u6ce2\u7edd\u70ed\u5feb\u901f\u901a\u9053\u8109\u51b2\u548c\u91cf\u5b50\u53d1\u5c04\u5668\u5e03\u5c45\u6570\u6446\u52a8\u8109\u51b2\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u5355\u5149\u5b50\u6e90\u6027\u80fd\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u5171\u632f\u6fc0\u53d1\u9700\u8981\u504f\u632f\u6ee4\u6ce2\u6765\u53bb\u9664\u6cf5\u6d66\u4fe1\u53f7\uff0c\u5bfc\u81f450%\u7684\u6548\u7387\u635f\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4e09\u79cd\u907f\u514d\u5149\u8c31\u91cd\u53e0\u7684\u6cf5\u6d66\u65b9\u6848\uff0c\u4ee5\u7ed5\u8fc7\u8fd9\u4e00\u6ee4\u6ce2\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u6cf5\u6d66\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\uff1a(i) \u5bf9\u79f0\u5931\u8c10\u53cc\u8272\u8109\u51b2\uff0c(ii) \u9677\u6ce2\u6ee4\u6ce2\u7edd\u70ed\u5feb\u901f\u901a\u9053\u8109\u51b2\uff0c(iii) \u91cf\u5b50\u53d1\u5c04\u5668\u5e03\u5c45\u6570\u6446\u52a8\u8109\u51b2\uff0c\u91cf\u5316\u5355\u5149\u5b50\u6e90\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u3002", "result": "\u53cc\u8272\u8109\u51b2\u56e0\u77ac\u65f6\u8109\u51b2\u5f3a\u5ea6\u5927\u800c\u53d7\u58f0\u5b50\u8bf1\u5bfc\u9000\u76f8\u5e72\u5f71\u54cd\uff0c\u6027\u80fd\u964d\u4f4e\u8fbe50%\u3002NARP\u548cSUPER\u8109\u51b2\u5728\u4e0d\u540c\u7a0b\u5ea6\u4e0a\u514d\u53d7\u58f0\u5b50\u8026\u5408\u5f71\u54cd\uff0c\u5747\u4fdd\u6301\u4f18\u5f02\u7684\u5355\u5149\u5b50\u6e90\u6027\u80fd\u3002SUPER\u8109\u51b2\u5bf9\u8109\u51b2\u53c2\u6570\u53d8\u5316\u654f\u611f\uff0c\u800cNARP\u8109\u51b2\u867d\u7136\u5b9e\u9a8c\u5b9e\u73b0\u8f83\u96be\uff0c\u4f46\u5bf9\u8109\u51b2\u5236\u5907\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "NARP\u548cSUPER\u8109\u51b2\u662f\u907f\u514d\u4f20\u7edf\u5171\u632f\u6fc0\u53d1\u6ee4\u6ce2\u9700\u6c42\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u5176\u4e2dNARP\u8109\u51b2\u5728\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u800cSUPER\u8109\u51b2\u5bf9\u53c2\u6570\u53d8\u5316\u8f83\u4e3a\u654f\u611f\u3002"}}
{"id": "2511.00032", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00032", "abs": "https://arxiv.org/abs/2511.00032", "authors": ["Lei Liu", "Zhongyi Yu", "Hong Wang", "Huanshuo Dong", "Haiyang Xin", "Hongwei Zhao", "Bin Li"], "title": "From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators", "comment": null, "summary": "In recent years, Neural Operators(NO) have gradually emerged as a popular\napproach for solving Partial Differential Equations (PDEs). However, their\napplication to large-scale engineering tasks suffers from significant\ncomputational overhead. And the fact that current models impose a uniform\ncomputational cost while physical fields exhibit vastly different complexities\nconstitutes a fundamental mismatch, which is the root of this inefficiency. For\ninstance, in turbulence flows, intricate vortex regions require deeper network\nprocessing compared to stable flows. To address this, we introduce a framework:\nSkip-Block Routing (SBR), a general framework designed for Transformer-based\nneural operators, capable of being integrated into their multi-layer\narchitectures. First, SBR uses a routing mechanism to learn the complexity and\nranking of tokens, which is then applied during inference. Then, in later\nlayers, it decides how many tokens are passed forward based on this ranking.\nThis way, the model focuses more processing capacity on the tokens that are\nmore complex. Experiments demonstrate that SBR is a general framework that\nseamlessly integrates into various neural operators. Our method reduces\ncomputational cost by approximately 50% in terms of Floating Point Operations\n(FLOPs), while still delivering up to 2x faster inference without sacrificing\naccuracy.", "AI": {"tldr": "\u63d0\u51faSkip-Block Routing (SBR)\u6846\u67b6\uff0c\u901a\u8fc7\u8def\u7531\u673a\u5236\u5b66\u4e60token\u590d\u6742\u5ea6\u5e76\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u663e\u8457\u964d\u4f4eTransformer\u795e\u7ecf\u7b97\u5b50\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7b97\u5b50\u5728\u5904\u7406\u5927\u89c4\u6a21\u5de5\u7a0b\u95ee\u9898\u65f6\u5b58\u5728\u663e\u8457\u8ba1\u7b97\u5f00\u9500\uff0c\u4e14\u7edf\u4e00\u8ba1\u7b97\u6210\u672c\u4e0e\u7269\u7406\u573a\u590d\u6742\u5ea6\u5dee\u5f02\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "SBR\u6846\u67b6\u96c6\u6210\u5230Transformer\u795e\u7ecf\u7b97\u5b50\u4e2d\uff0c\u901a\u8fc7\u5b66\u4e60token\u590d\u6742\u5ea6\u548c\u6392\u5e8f\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u6392\u540d\u51b3\u5b9a\u540e\u7eed\u5c42\u4f20\u9012\u7684token\u6570\u91cf\uff0c\u5c06\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u7ed9\u590d\u6742\u533a\u57df\u3002", "result": "SBR\u53ef\u96c6\u6210\u5230\u591a\u79cd\u795e\u7ecf\u7b97\u5b50\u4e2d\uff0c\u51cf\u5c11\u7ea650%\u7684FLOPs\u8ba1\u7b97\u6210\u672c\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe2\u500d\uff0c\u4e14\u4e0d\u727a\u7272\u7cbe\u5ea6\u3002", "conclusion": "SBR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b97\u5b50\u5728\u5904\u7406\u590d\u6742\u7269\u7406\u573a\u65f6\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00353", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00353", "abs": "https://arxiv.org/abs/2511.00353", "authors": ["Lucas T. de Paula", "Caio C. Holanda Ribeiro", "Vitorio A. De Lorenci"], "title": "Effective spacetime description of light propagation in linear magnetoelectric media", "comment": null, "summary": "Formal analogies between gravitational and optical phenomena have been\nexplored for over a century, providing valuable insights into kinematic aspects\nof general relativity. Here, this analogy is employed to study light\npropagation in linear magnetoelectric media from an effective spacetime\nperspective. Starting from Maxwell's equations in covariant form, it is shown\nthat an effective metric can always be identified for linear, non-dispersive\nmagnetoelectric materials. The effective metric is then used to construct\nanalog models in the limit of geometric optics. Among the optical effects\nanalyzed, it is shown that under reasonable assumptions on the magnitude of the\nmagnetoelectric response, a one-way propagation region can be established,\nwhich behaves analogously to an event horizon.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u5f15\u529b\u4e0e\u5149\u5b66\u7684\u5f62\u5f0f\u7c7b\u6bd4\uff0c\u7814\u7a76\u7ebf\u6027\u78c1\u7535\u4ecb\u8d28\u4e2d\u7684\u5149\u4f20\u64ad\uff0c\u4ece\u6709\u6548\u65f6\u7a7a\u89d2\u5ea6\u6784\u5efa\u4e86\u7c7b\u6bd4\u6a21\u578b\uff0c\u5e76\u53d1\u73b0\u53ef\u4ee5\u5efa\u7acb\u7c7b\u4f3c\u4e8b\u4ef6\u89c6\u754c\u7684\u5355\u5411\u4f20\u64ad\u533a\u57df\u3002", "motivation": "\u63a2\u7d22\u5f15\u529b\u4e0e\u5149\u5b66\u73b0\u8c61\u4e4b\u95f4\u7684\u5f62\u5f0f\u7c7b\u6bd4\uff0c\u4e3a\u7406\u89e3\u5e7f\u4e49\u76f8\u5bf9\u8bba\u7684\u52a8\u529b\u5b66\u65b9\u9762\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u5e76\u5c06\u8fd9\u79cd\u7c7b\u6bd4\u5e94\u7528\u4e8e\u7ebf\u6027\u78c1\u7535\u4ecb\u8d28\u4e2d\u7684\u5149\u4f20\u64ad\u7814\u7a76\u3002", "method": "\u4ece\u534f\u53d8\u5f62\u5f0f\u7684\u9ea6\u514b\u65af\u97e6\u65b9\u7a0b\u51fa\u53d1\uff0c\u8bc6\u522b\u7ebf\u6027\u975e\u8272\u6563\u78c1\u7535\u6750\u6599\u7684\u6709\u6548\u5ea6\u91cf\uff0c\u5e76\u5728\u51e0\u4f55\u5149\u5b66\u6781\u9650\u4e0b\u6784\u5efa\u7c7b\u6bd4\u6a21\u578b\u3002", "result": "\u5728\u7ebf\u6027\u78c1\u7535\u6750\u6599\u4e2d\u603b\u80fd\u8bc6\u522b\u51fa\u6709\u6548\u5ea6\u91cf\uff0c\u5728\u5408\u7406\u5047\u8bbe\u78c1\u7535\u54cd\u5e94\u5f3a\u5ea6\u4e0b\uff0c\u53ef\u4ee5\u5efa\u7acb\u7c7b\u4f3c\u4e8b\u4ef6\u89c6\u754c\u7684\u5355\u5411\u4f20\u64ad\u533a\u57df\u3002", "conclusion": "\u5f15\u529b-\u5149\u5b66\u7c7b\u6bd4\u53ef\u6210\u529f\u5e94\u7528\u4e8e\u78c1\u7535\u4ecb\u8d28\u7814\u7a76\uff0c\u4e3a\u6a21\u62df\u5f15\u529b\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u5149\u5b66\u5e73\u53f0\uff0c\u7279\u522b\u662f\u5728\u4e8b\u4ef6\u89c6\u754c\u7b49\u5f15\u529b\u6548\u5e94\u65b9\u9762\u3002"}}
{"id": "2511.00314", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00314", "abs": "https://arxiv.org/abs/2511.00314", "authors": ["Rohit Kishan Ray"], "title": "Local perception operators and classicality: new tools for old tests", "comment": "10 pages, 4 figures", "summary": "Quantum nonlocality is often judged by violations of Bell-type inequalities\nfor a given state. The computation of such violations is a global task,\nrequiring evaluation of global correlations and subsequent testing against a\nBell functional. We ask instead: when is a given state local (classical)? We\nformalize this question via local perception operators (LPOs) that compress\nglobal observables into locally accessible statistics, and we derive two\ncomplementary witnesses -- one implementable by a single party with classical\nside information, one intrinsically two-sided. These tools revisit familiar\nBell scenarios from a new operational angle. We show how the witness leads to\nstate-aware constraints that depend on local marginals and measurement\ngeometry, with natural specializations to canonical scenarios. The resulting\ncriteria are built from first moments and standard projective measurements and\nprovide a way to certify compatibility with local hidden variable explanations\nfor the LPO-processed data in regimes where conventional Bell violations may be\ninconclusive.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5224\u65ad\u91cf\u5b50\u6001\u662f\u5426\u5177\u6709\u5c40\u57df\u6027\uff0c\u901a\u8fc7\u5c40\u90e8\u611f\u77e5\u7b97\u5b50\u538b\u7f29\u5168\u5c40\u53ef\u89c2\u6d4b\u91cf\u4e3a\u5c40\u90e8\u53ef\u8bbf\u95ee\u7684\u7edf\u8ba1\u91cf\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e24\u79cd\u4e92\u8865\u7684\u89c1\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4e0a\u901a\u8fc7\u8fdd\u53cd\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u6765\u5224\u65ad\u91cf\u5b50\u975e\u5c40\u57df\u6027\uff0c\u4f46\u8fd9\u662f\u5168\u5c40\u4efb\u52a1\u3002\u4f5c\u8005\u5e0c\u671b\u4ece\u76f8\u53cd\u89d2\u5ea6\u56de\u7b54\uff1a\u4f55\u65f6\u4e00\u4e2a\u7ed9\u5b9a\u6001\u662f\u5c40\u57df\u7684\uff1f", "method": "\u4f7f\u7528\u5c40\u90e8\u611f\u77e5\u7b97\u5b50\u538b\u7f29\u5168\u5c40\u53ef\u89c2\u6d4b\u91cf\uff0c\u63a8\u5bfc\u51fa\u4e24\u79cd\u89c1\u8bc1\u65b9\u6cd5\uff1a\u4e00\u79cd\u53ef\u7531\u5355\u65b9\u5b9e\u73b0\uff08\u5e26\u6709\u7ecf\u5178\u8fb9\u4fe1\u606f\uff09\uff0c\u53e6\u4e00\u79cd\u672c\u8d28\u4e0a\u662f\u53cc\u8fb9\u7684\u3002", "result": "\u5f00\u53d1\u4e86\u4f9d\u8d56\u4e8e\u5c40\u90e8\u8fb9\u7f18\u5206\u5e03\u548c\u6d4b\u91cf\u51e0\u4f55\u7684\u72b6\u6001\u611f\u77e5\u7ea6\u675f\uff0c\u5728\u4f20\u7edf\u8d1d\u5c14\u8fdd\u53cd\u53ef\u80fd\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba4\u8bc1\u4e0e\u5c40\u57df\u9690\u53d8\u91cf\u89e3\u91ca\u517c\u5bb9\u6027\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ece\u65b0\u7684\u64cd\u4f5c\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u719f\u6089\u7684\u8d1d\u5c14\u573a\u666f\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u4e00\u9636\u77e9\u548c\u6807\u51c6\u6295\u5f71\u6d4b\u91cf\u7684\u5224\u636e\uff0c\u80fd\u591f\u5728\u4f20\u7edf\u8d1d\u5c14\u6d4b\u8bd5\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5224\u65ad\u91cf\u5b50\u6001\u7684\u5c40\u57df\u6027\u3002"}}
{"id": "2511.00035", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00035", "abs": "https://arxiv.org/abs/2511.00035", "authors": ["Georg Velev", "Stefan Lessmann"], "title": "Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series", "comment": null, "summary": "The dynamic energy sector requires both predictive accuracy and runtime\nefficiency for short-term forecasting of energy generation under operational\nconstraints, where timely and precise predictions are crucial. The manual\nconfiguration of complex methods, which can generate accurate global multi-step\npredictions without suffering from a computational bottleneck, represents a\nprocedure with significant time requirements and high risk for human-made\nerrors. A further intricacy arises from the temporal dynamics present in\nenergy-related data. Additionally, the generalization to unseen data is\nimperative for continuously deploying forecasting techniques over time. To\novercome these challenges, in this research, we design a neural architecture\nsearch (NAS)-based framework for the automated discovery of time series models\nthat strike a balance between computational efficiency, predictive performance,\nand generalization power for the global, multi-step short-term forecasting of\nenergy production time series. In particular, we introduce a search space\nconsisting only of efficient components, which can capture distinctive patterns\nof energy time series. Furthermore, we formulate a novel objective function\nthat accounts for performance generalization in temporal context and the\nmaximal exploration of different regions of our high-dimensional search space.\nThe results obtained on energy production time series show that an ensemble of\nlightweight architectures discovered with NAS outperforms state-of-the-art\ntechniques, such as Transformers, as well as pre-trained forecasting models, in\nterms of both efficiency and accuracy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u67b6\u6784\u641c\u7d22(NAS)\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u3001\u9884\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u7684\u65f6\u5e8f\u6a21\u578b\uff0c\u7528\u4e8e\u80fd\u6e90\u751f\u4ea7\u7684\u5168\u5c40\u591a\u6b65\u77ed\u671f\u9884\u6d4b\u3002", "motivation": "\u80fd\u6e90\u9886\u57df\u9700\u8981\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u6548\u7387\uff0c\u4f46\u624b\u52a8\u914d\u7f6e\u590d\u6742\u65b9\u6cd5\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u540c\u65f6\u9700\u8981\u8003\u8651\u65f6\u5e8f\u52a8\u6001\u7279\u6027\u548c\u5bf9\u672a\u89c1\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u9ad8\u6548\u7ec4\u4ef6\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u51fa\u8003\u8651\u65f6\u5e8f\u4e0a\u4e0b\u6587\u6027\u80fd\u6cdb\u5316\u548c\u9ad8\u7ef4\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u7684\u65b0\u76ee\u6807\u51fd\u6570\uff0c\u901a\u8fc7NAS\u81ea\u52a8\u53d1\u73b0\u8f7b\u91cf\u7ea7\u67b6\u6784\u3002", "result": "\u5728\u80fd\u6e90\u751f\u4ea7\u65f6\u5e8f\u6570\u636e\u4e0a\uff0cNAS\u53d1\u73b0\u7684\u8f7b\u91cf\u7ea7\u67b6\u6784\u96c6\u6210\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8eTransformer\u7b49\u6700\u5148\u8fdb\u6280\u672f\u53ca\u9884\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u3002", "conclusion": "NAS\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u80fd\u6e90\u9884\u6d4b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u3001\u9884\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2511.00425", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2511.00425", "abs": "https://arxiv.org/abs/2511.00425", "authors": ["Charul Rathod", "M. Mishra", "Prasanta Kumar Das"], "title": "Structural Properties of Magnetized Neutron Stars under f (R, T ) Gravity Framework", "comment": null, "summary": "The current work investigates the structural properties of neutron stars in\nthe presence of a strong magnetic field within the framework of f(R,T) modified\ngravity, where the matter-geometry coupling leads to deviations from general\nrelativity at high matter densities. We present here the mass-radius sequences,\nas well as the mass and pressure distributions for various values of the\nmodified gravity parameter and the central magnetic field. The modified\nTolman-Oppenheimer- Volkoff equations are numerically solved using isotropic\nequations of state, specifically the APR, FPS, and SLy models. Comparing the\ncorresponding results in the context of general relativity suggests that more\nnegative values of the modified gravity parameter result in higher maximum\ngravitational masses. In contrast, strong central magnetic fields of up to 1018\nGauss cause only a slight decrease in maximum mass without disrupting spherical\nsymmetry. Our findings are in agreement with the observed data from GW170817,\nPSR and NICER.", "AI": {"tldr": "\u7814\u7a76\u5728\u5f3a\u78c1\u573a\u548cf(R,T)\u4fee\u6b63\u5f15\u529b\u6846\u67b6\u4e0b\u4e2d\u5b50\u661f\u7684\u7ed3\u6784\u7279\u6027\uff0c\u53d1\u73b0\u4fee\u6b63\u5f15\u529b\u53c2\u6570\u8d1f\u503c\u8d8a\u5927\uff0c\u6700\u5927\u5f15\u529b\u8d28\u91cf\u8d8a\u9ad8\uff1b\u5f3a\u78c1\u573a\u4ec5\u8f7b\u5fae\u964d\u4f4e\u6700\u5927\u8d28\u91cf\u800c\u4e0d\u7834\u574f\u7403\u5bf9\u79f0\u6027\u3002", "motivation": "\u5728f(R,T)\u4fee\u6b63\u5f15\u529b\u6846\u67b6\u4e0b\u7814\u7a76\u5f3a\u78c1\u573a\u5bf9\u4e2d\u5b50\u661f\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u7269\u8d28-\u51e0\u4f55\u8026\u5408\u5728\u9ad8\u5bc6\u5ea6\u7269\u8d28\u6761\u4ef6\u4e0b\u5982\u4f55\u504f\u79bb\u5e7f\u4e49\u76f8\u5bf9\u8bba\u3002", "method": "\u6570\u503c\u6c42\u89e3\u4fee\u6b63\u7684Tolman-Oppenheimer-Volkoff\u65b9\u7a0b\uff0c\u4f7f\u7528\u5404\u5411\u540c\u6027\u72b6\u6001\u65b9\u7a0b\uff08APR\u3001FPS\u3001SLy\u6a21\u578b\uff09\uff0c\u5206\u6790\u4e0d\u540c\u4fee\u6b63\u5f15\u529b\u53c2\u6570\u548c\u4e2d\u5fc3\u78c1\u573a\u503c\u4e0b\u7684\u8d28\u91cf-\u534a\u5f84\u5e8f\u5217\u3001\u8d28\u91cf\u5206\u5e03\u548c\u538b\u529b\u5206\u5e03\u3002", "result": "\u4fee\u6b63\u5f15\u529b\u53c2\u6570\u8d1f\u503c\u8d8a\u5927\uff0c\u6700\u5927\u5f15\u529b\u8d28\u91cf\u8d8a\u9ad8\uff1b\u5f3a\u78c1\u573a\uff08\u9ad8\u8fbe10^18\u9ad8\u65af\uff09\u4ec5\u8f7b\u5fae\u964d\u4f4e\u6700\u5927\u8d28\u91cf\u800c\u4e0d\u7834\u574f\u7403\u5bf9\u79f0\u6027\uff1b\u7ed3\u679c\u4e0eGW170817\u3001PSR\u548cNICER\u89c2\u6d4b\u6570\u636e\u4e00\u81f4\u3002", "conclusion": "f(R,T)\u4fee\u6b63\u5f15\u529b\u6846\u67b6\u4e0b\uff0c\u7269\u8d28-\u51e0\u4f55\u8026\u5408\u663e\u8457\u5f71\u54cd\u4e2d\u5b50\u661f\u7ed3\u6784\uff0c\u800c\u5f3a\u78c1\u573a\u5f71\u54cd\u76f8\u5bf9\u8f83\u5c0f\uff1b\u7814\u7a76\u7ed3\u679c\u4e0e\u73b0\u6709\u89c2\u6d4b\u6570\u636e\u76f8\u7b26\u3002"}}
{"id": "2511.00323", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00323", "abs": "https://arxiv.org/abs/2511.00323", "authors": ["Da-Wei Luo", "Edward Yu", "Ting Yu"], "title": "Optimal transfer of entanglement in oscillator chains in non-Markovian open systems", "comment": "18 pages, 9 figures", "summary": "We considered the transfer of continuous-variable entangled states in coupled\noscillator chains embedded in a generic environment. We demonstrate\nhigh-fidelity transfer via optimal control in two configurations - a linear\nchain and an X-shaped chain. More specifically, we use the Krotov optimization\nalgorithm to design control fields that achieve the desired state transfer.\nUnder the environmental memory effects, the Krotov algorithm needs to be\nmodified, since the dissipative terms in non-Markovian dynamics are generally\ngoverned by the time-dependent system Hamiltonian. Remarkably, we can achieve\nhigh-fidelity transfer by simply tuning the frequencies of the oscillators\nwhile keeping the coupling strength constant, even in the presence of\nopen-system effects. For the system under consideration, we find that quantum\nmemory effects can aid in the transfer of entanglement and show improvement\nover the memoryless case. In addition, it is possible to target a range of\nentangled states, making it unnecessary to know the parameters of the initial\nstate beforehand.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u73af\u5883\u4e2d\u901a\u8fc7\u6700\u4f18\u63a7\u5236\u5b9e\u73b0\u8fde\u7eed\u53d8\u91cf\u7ea0\u7f20\u6001\u7684\u9ad8\u4fdd\u771f\u5ea6\u4f20\u8f93\uff0c\u4f7f\u7528Krotov\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63a7\u5236\u573a\uff0c\u53d1\u73b0\u91cf\u5b50\u8bb0\u5fc6\u6548\u5e94\u6709\u52a9\u4e8e\u7ea0\u7f20\u4f20\u8f93\u3002", "motivation": "\u7814\u7a76\u5728\u4e00\u822c\u73af\u5883\u4e2d\u8026\u5408\u632f\u8361\u5668\u94fe\u4e2d\u8fde\u7eed\u53d8\u91cf\u7ea0\u7f20\u6001\u7684\u4f20\u8f93\u95ee\u9898\uff0c\u63a2\u7d22\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\u4e0b\u7684\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Krotov\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63a7\u5236\u573a\uff0c\u5728\u7ebf\u6027\u94fe\u548cX\u5f62\u94fe\u4e24\u79cd\u914d\u7f6e\u4e2d\u5b9e\u73b0\u72b6\u6001\u4f20\u8f93\uff0c\u901a\u8fc7\u8c03\u8282\u632f\u8361\u5668\u9891\u7387\u4fdd\u6301\u8026\u5408\u5f3a\u5ea6\u6052\u5b9a\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684\u7ea0\u7f20\u6001\u4f20\u8f93\uff0c\u91cf\u5b50\u8bb0\u5fc6\u6548\u5e94\u6bd4\u65e0\u8bb0\u5fc6\u60c5\u51b5\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u65e0\u9700\u9884\u5148\u77e5\u9053\u521d\u59cb\u6001\u53c2\u6570\u5373\u53ef\u9488\u5bf9\u591a\u79cd\u7ea0\u7f20\u6001\u3002", "conclusion": "\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u6700\u4f18\u63a7\u5236\u53ef\u4ee5\u9ad8\u6548\u4f20\u8f93\u7ea0\u7f20\u6001\uff0c\u91cf\u5b50\u8bb0\u5fc6\u6548\u5e94\u6709\u52a9\u4e8e\u63d0\u9ad8\u4f20\u8f93\u6027\u80fd\uff0c\u65b9\u6cd5\u5177\u6709\u5bf9\u521d\u59cb\u6001\u53c2\u6570\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00040", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00040", "abs": "https://arxiv.org/abs/2511.00040", "authors": ["Seonggyun Lee", "Sungjun Lim", "Seojin Park", "Soeun Cheon", "Kyungwoo Song"], "title": "Semi-Supervised Preference Optimization with Limited Feedback", "comment": null, "summary": "The field of preference optimization has made outstanding contributions to\nthe alignment of language models with human preferences. Despite these\nadvancements, recent methods still rely heavily on substantial paired (labeled)\nfeedback data, leading to substantial resource expenditures. To address these\nchallenges, we study the problem of Semi-Supervised Preference Optimization\n(SSPO) in which the idea is to learn from both a small number of pairwise\npreference labels and a large pool of unpaired samples simultaneously. Our key\ntheoretical contribution proves the existence of an optimal reward threshold\ncapable of separating winning and losing responses with high probability, which\nenables a principled pseudo-labeling of unpaired data. By leveraging these\npseudo-labels, SSPO effectively distills latent preferences from large-scale\nunpaired data, thus maintaining human alignment while drastically reducing\nacquisition costs. Extensive experiments across datasets validate this\nremarkable data efficiency; for instance, SSPO trained with Llama3-8B-Instruct\non just 1% of UltraFeedback consistently surpasses strong baselines trained on\n10% of UltraFeedback.", "AI": {"tldr": "\u63d0\u51fa\u534a\u76d1\u7763\u504f\u597d\u4f18\u5316(SSPO)\u65b9\u6cd5\uff0c\u5229\u7528\u5c11\u91cf\u914d\u5bf9\u504f\u597d\u6807\u7b7e\u548c\u5927\u91cf\u672a\u914d\u5bf9\u6837\u672c\u540c\u65f6\u5b66\u4e60\uff0c\u663e\u8457\u964d\u4f4e\u6570\u636e\u83b7\u53d6\u6210\u672c", "motivation": "\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u5927\u91cf\u914d\u5bf9\u53cd\u9988\u6570\u636e\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u5de8\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u6cd5", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5b58\u5728\u6700\u4f18\u5956\u52b1\u9608\u503c\u80fd\u9ad8\u6982\u7387\u533a\u5206\u80dc\u8d1f\u54cd\u5e94\uff0c\u57fa\u4e8e\u6b64\u5bf9\u672a\u914d\u5bf9\u6570\u636e\u8fdb\u884c\u539f\u5219\u6027\u4f2a\u6807\u6ce8\uff0c\u5229\u7528\u4f2a\u6807\u7b7e\u4ece\u5927\u89c4\u6a21\u672a\u914d\u5bf9\u6570\u636e\u4e2d\u63d0\u53d6\u6f5c\u5728\u504f\u597d", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u663e\u8457\u7684\u6570\u636e\u6548\u7387\uff0c\u4f8b\u5982\u4f7f\u7528Llama3-8B-Instruct\u5728\u4ec51% UltraFeedback\u6570\u636e\u4e0a\u8bad\u7ec3\u7684SSPO\u6301\u7eed\u8d85\u8d8a\u572810%\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5f3a\u57fa\u7ebf", "conclusion": "SSPO\u80fd\u6709\u6548\u7ef4\u6301\u4eba\u7c7b\u5bf9\u9f50\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u83b7\u53d6\u6210\u672c\uff0c\u4e3a\u504f\u597d\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u6848"}}
{"id": "2511.00464", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00464", "abs": "https://arxiv.org/abs/2511.00464", "authors": ["Suraj Kumar Behera", "Pratik P. Ray", "B. Mishra"], "title": "Reconstructing $f(T)$ Gravity From Hubble Parameterization Constraints", "comment": "10 pages, 9 figures, 1 table", "summary": "In this paper, we have presented the cosmological model of the Universe that\nrepresents late time cosmic acceleration in torsion based gravitational theory,\nthe $f(T)$ gravity. A well motivated parametrization for the Hubble parameter\nhas been introduced and the free parameters involved are constrained using the\ncosmological datasets. With the constrained values of the free parameters,\nother geometrical parameters such as deceleration parameter, jerk parameter,\nand snap parameter are analyzed and confronted with the prescribed value of the\ncosmological observations. In addition, the dynamical parameters are analyzed\nin some non-linear form of $f(T)$ and the energy conditions are also studied\nand confirmed with the violation of the strong energy condition. The obtained\ncosmological model provides late time phantom behavior of the Universe.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6320\u7387\u5f15\u529b\u7406\u8bbaf(T)\u91cd\u529b\u7684\u5b87\u5b99\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u54c8\u52c3\u53c2\u6570\u5e76\u5229\u7528\u5b87\u5b99\u5b66\u6570\u636e\u96c6\u7ea6\u675f\u81ea\u7531\u53c2\u6570\uff0c\u5206\u6790\u4e86\u5b87\u5b99\u7684\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u7279\u6027\uff0c\u53d1\u73b0\u5b87\u5b99\u5448\u73b0\u665a\u671f\u5e7b\u8c61\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76f(T)\u91cd\u529b\u7406\u8bba\u4e0b\u7684\u5b87\u5b99\u5b66\u6a21\u578b\uff0c\u89e3\u91ca\u5b87\u5b99\u665a\u671f\u52a0\u901f\u81a8\u80c0\u73b0\u8c61\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u65b9\u6cd5\u5206\u6790\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u53c2\u6570\u3002", "method": "\u5f15\u5165\u54c8\u52c3\u53c2\u6570\u7684\u53c2\u6570\u5316\u5f62\u5f0f\uff0c\u4f7f\u7528\u5b87\u5b99\u5b66\u6570\u636e\u96c6\u7ea6\u675f\u81ea\u7531\u53c2\u6570\uff0c\u5206\u6790\u51cf\u901f\u53c2\u6570\u3001\u6025\u52a8\u53c2\u6570\u548csnap\u53c2\u6570\u7b49\u51e0\u4f55\u53c2\u6570\uff0c\u7814\u7a76\u975e\u7ebf\u6027f(T)\u5f62\u5f0f\u7684\u52a8\u529b\u5b66\u53c2\u6570\u548c\u80fd\u91cf\u6761\u4ef6\u3002", "result": "\u6a21\u578b\u663e\u793a\u5b87\u5b99\u5448\u73b0\u665a\u671f\u5e7b\u8c61\u884c\u4e3a\uff0c\u5f3a\u80fd\u91cf\u6761\u4ef6\u88ab\u8fdd\u53cd\uff0c\u51e0\u4f55\u53c2\u6570\u4e0e\u5b87\u5b99\u5b66\u89c2\u6d4b\u503c\u4e00\u81f4\u3002", "conclusion": "f(T)\u91cd\u529b\u7406\u8bba\u80fd\u591f\u6210\u529f\u63cf\u8ff0\u5b87\u5b99\u665a\u671f\u52a0\u901f\u81a8\u80c0\uff0c\u6a21\u578b\u4e0e\u89c2\u6d4b\u6570\u636e\u76f8\u7b26\uff0c\u9a8c\u8bc1\u4e86\u5f3a\u80fd\u91cf\u6761\u4ef6\u7684\u8fdd\u53cd\u548c\u5e7b\u8c61\u884c\u4e3a\u7684\u5b58\u5728\u3002"}}
{"id": "2511.00406", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00406", "abs": "https://arxiv.org/abs/2511.00406", "authors": ["Thanveer Shaik", "Xiaohui Tao", "Haoran Xie", "Robert Sang"], "title": "Quantum Machine Unlearning: Foundations, Mechanisms, and Taxonomy", "comment": null, "summary": "Quantum Machine Unlearning has emerged as a foundational challenge at the\nintersection of quantum information theory privacypreserving computation and\ntrustworthy artificial intelligence This paper advances QMU by establishing a\nformal framework that unifies physical constraints algorithmic mechanisms and\nethical governance within a verifiable paradigm We define forgetting as a\ncontraction of distinguishability between pre and postunlearning models under\ncompletely positive trace-preserving dynamics grounding data removal in the\nphysics of quantum irreversibility Building on this foundation we present a\nfiveaxis taxonomy spanning scope guarantees mechanisms system context and\nhardware realization linking theoretical constructs to implementable strategies\nWithin this structure we incorporate influence and quantum Fisher information\nweighted updates parameter reinitialization and kernel alignment as practical\nmechanisms compatible with noisy intermediatescale quantum NISQ devices The\nframework extends naturally to federated and privacyaware settings via quantum\ndifferential privacy homomorphic encryption and verifiable delegation enabling\nscalable auditable deletion across distributed quantum systems Beyond technical\ndesign we outline a forwardlooking research roadmap emphasizing formal proofs\nof forgetting scalable and secure architectures postunlearning interpretability\nand ethically auditable governance Together these contributions elevate QMU\nfrom a conceptual notion to a rigorously defined and ethically aligned\ndiscipline bridging physical feasibility algorithmic verifiability and societal\naccountability in the emerging era of quantum intelligence.", "AI": {"tldr": "\u672c\u6587\u4e3a\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7269\u7406\u7ea6\u675f\u3001\u7b97\u6cd5\u673a\u5236\u548c\u4f26\u7406\u6cbb\u7406\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5c06\u9057\u5fd8\u5b9a\u4e49\u4e3aCPTP\u52a8\u529b\u5b66\u4e0b\u524d\u540e\u6a21\u578b\u53ef\u533a\u5206\u6027\u7684\u6536\u7f29\uff0c\u5e76\u63d0\u51fa\u4e86\u4e94\u8f74\u5206\u7c7b\u6cd5\u8fde\u63a5\u7406\u8bba\u6982\u5ff5\u4e0e\u53ef\u5b9e\u65bd\u7b56\u7565\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u662f\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u3001\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u548c\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u4ea4\u53c9\u9886\u57df\u7684\u57fa\u7840\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u8fde\u63a5\u7269\u7406\u53ef\u884c\u6027\u3001\u7b97\u6cd5\u53ef\u9a8c\u8bc1\u6027\u548c\u793e\u4f1a\u95ee\u8d23\u6027\u3002", "method": "\u5b9a\u4e49\u4e86\u57fa\u4e8eCPTP\u52a8\u529b\u5b66\u7684\u9057\u5fd8\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u63d0\u51fa\u4e94\u8f74\u5206\u7c7b\u6cd5\uff08\u8303\u56f4\u3001\u4fdd\u8bc1\u3001\u673a\u5236\u3001\u7cfb\u7edf\u4e0a\u4e0b\u6587\u3001\u786c\u4ef6\u5b9e\u73b0\uff09\uff0c\u6574\u5408\u4e86\u5f71\u54cd\u51fd\u6570\u3001\u91cf\u5b50Fisher\u4fe1\u606f\u52a0\u6743\u66f4\u65b0\u3001\u53c2\u6570\u91cd\u521d\u59cb\u5316\u7b49\u5b9e\u7528\u673a\u5236\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u9a8c\u8bc1\u7684\u91cf\u5b50\u9057\u5fd8\u8303\u5f0f\uff0c\u5c06\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u4ece\u6982\u5ff5\u6027\u6982\u5ff5\u63d0\u5347\u4e3a\u4e25\u683c\u5b9a\u4e49\u7684\u5b66\u79d1\uff0c\u652f\u6301\u5728NISQ\u8bbe\u5907\u4e0a\u5b9e\u73b0\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u8054\u90a6\u5b66\u4e60\u548c\u9690\u79c1\u4fdd\u62a4\u8bbe\u7f6e\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u8fde\u63a5\u7269\u7406\u7ea6\u675f\u3001\u7b97\u6cd5\u673a\u5236\u548c\u4f26\u7406\u6cbb\u7406\uff0c\u4f7f\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u6210\u4e3a\u5728\u91cf\u5b50\u667a\u80fd\u65b0\u5174\u65f6\u4ee3\u5177\u6709\u7269\u7406\u53ef\u884c\u6027\u3001\u7b97\u6cd5\u53ef\u9a8c\u8bc1\u6027\u548c\u793e\u4f1a\u95ee\u8d23\u6027\u7684\u4e25\u8c28\u5b66\u79d1\u3002"}}
{"id": "2511.00043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00043", "abs": "https://arxiv.org/abs/2511.00043", "authors": ["Tyrus Whitman", "Andrew Particka", "Christopher Diers", "Ian Griffin", "Charuka Wickramasinghe", "Pradeep Ranaweera"], "title": "Physics-Informed Neural Network Frameworks for the Analysis of Engineering and Biological Dynamical Systems Governed by Ordinary Differential Equations", "comment": "21 pages, 10 figures, 5 tables", "summary": "In this study, we present and validate the predictive capability of the\nPhysics-Informed Neural Networks (PINNs) methodology for solving a variety of\nengineering and biological dynamical systems governed by ordinary differential\nequations (ODEs). While traditional numerical methods a re effective for many\nODEs, they often struggle to achieve convergence in problems involving high\nstiffness, shocks, irregular domains, singular perturbations, high dimensions,\nor boundary discontinuities. Alternatively, PINNs offer a powerful approach for\nhandling challenging numerical scenarios. In this study, classical ODE problems\nare employed as controlled testbeds to systematically evaluate the accuracy,\ntraining efficiency, and generalization capability under controlled conditions\nof the PINNs framework. Although not a universal solution, PINNs can achieve\nsuperior results by embedding physical laws directly into the learning process.\nWe first analyze the existence and uniqueness properties of several benchmark\nproblems and subsequently validate the PINNs methodology on these model\nsystems. Our results demonstrate that for complex problems to converge to\ncorrect solutions, the loss function components data loss, initial condition\nloss, and residual loss must be appropriately balanced through careful\nweighting. We further establish that systematic tuning of hyperparameters,\nincluding network depth, layer width, activation functions, learning rate,\noptimization algorithms, w eight initialization schemes, and collocation point\nsampling, plays a crucial role in achieving accurate solutions. Additionally,\nembedding prior knowledge and imposing hard constraints on the network\narchitecture, without loss the generality of the ODE system, significantly\nenhances the predictive capability of PINNs.", "AI": {"tldr": "PINNs\u65b9\u6cd5\u5728\u89e3\u51b3\u5de5\u7a0b\u548c\u751f\u7269\u52a8\u529b\u5b66\u7cfb\u7edfODE\u95ee\u9898\u65f6\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u901a\u8fc7\u5d4c\u5165\u7269\u7406\u5b9a\u5f8b\u548c\u7cbe\u5fc3\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u96be\u4ee5\u6536\u655b\u7684\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u521a\u5ea6\u3001\u51b2\u51fb\u3001\u4e0d\u89c4\u5219\u57df\u3001\u5947\u5f02\u6270\u52a8\u3001\u9ad8\u7ef4\u6216\u8fb9\u754c\u4e0d\u8fde\u7eed\u7b49\u590d\u6742ODE\u95ee\u9898\u65f6\u5f80\u5f80\u96be\u4ee5\u6536\u655b\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u5f3a\u5927\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528PINNs\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7269\u7406\u5b9a\u5f8b\u76f4\u63a5\u5d4c\u5165\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u7cfb\u7edf\u8c03\u6574\u7f51\u7edc\u6df1\u5ea6\u3001\u5c42\u5bbd\u3001\u6fc0\u6d3b\u51fd\u6570\u3001\u5b66\u4e60\u7387\u3001\u4f18\u5316\u7b97\u6cd5\u3001\u6743\u91cd\u521d\u59cb\u5316\u65b9\u6848\u548c\u914d\u70b9\u91c7\u6837\u7b49\u8d85\u53c2\u6570\u3002", "result": "PINNs\u5728\u590d\u6742\u95ee\u9898\u4e2d\u80fd\u591f\u6536\u655b\u5230\u6b63\u786e\u89e3\uff0c\u4f46\u9700\u8981\u9002\u5f53\u5e73\u8861\u6570\u636e\u635f\u5931\u3001\u521d\u59cb\u6761\u4ef6\u635f\u5931\u548c\u6b8b\u5dee\u635f\u5931\uff0c\u5e76\u901a\u8fc7\u786c\u7ea6\u675f\u548c\u5148\u9a8c\u77e5\u8bc6\u589e\u5f3a\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "PINNs\u867d\u7136\u4e0d\u662f\u4e07\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u635f\u5931\u51fd\u6570\u5e73\u8861\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u80fd\u591f\u4e3a\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u590d\u6742ODE\u95ee\u9898\u63d0\u4f9b\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.00497", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00497", "abs": "https://arxiv.org/abs/2511.00497", "authors": ["Tomasz Baka", "Bal\u00e1zs Cirok", "K. Haris", "Johannes Noller", "N. V. Krishnendu"], "title": "Testing general relativity with gravitational waves -- improving and extending Modified Dispersion Relation tests", "comment": null, "summary": "Searching for a modified dispersion relation is one of the general relativity\ntests performed by the LIGO-Virgo-KAGRA collaboration with each new cumulative\nGravitational Wave Transient Catalog (GWTC). It considers classes of theories\nthat modify the dispersion of gravitational waves by introducing a massive\ngraviton or breaking Lorentz invariance. The symmetry breaking is parameterized\nphenomenologically by a momentum power law term $p^\\alpha$ added to the\ndispersion relation, with the test placing constraints on the amplitude\n$A_\\alpha$ of the introduced deviation. In this work, we implement improvements\nto the test, chief among them group velocity parametrization, a better sampling\nprocedure, and extension to negative exponents $\\alpha$ of $p$. We then\nreanalyze the events from the third catalog, GWTC-3, with our improved method.\nCompared with GWTC-3 results, we find significant improvement, mostly from the\nimproved sampling method, in the posteriors obtained by analyzing individual\nevent and more modest improvements in the combined bounds on amplitude\nparameters $A_\\alpha$ -- on average, we observe 19% shrinking of posterior\nwidth. The 90% upper bound on the graviton mass changes from $2.42 \\times\n10^{-11}$ peV to $2.21 \\times 10^{-11}$ peV. For the extension of our test to\n$\\alpha \\in \\{-1, -2, -3\\}$, we find no evidence in favor of general relativity\nviolation.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86LIGO-Virgo-KAGRA\u5408\u4f5c\u7ec4\u6d4b\u8bd5\u4fee\u6b63\u8272\u6563\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5f15\u5165\u7fa4\u901f\u5ea6\u53c2\u6570\u5316\u3001\u6539\u8fdb\u91c7\u6837\u7a0b\u5e8f\u4ee5\u53ca\u6269\u5c55\u5230\u8d1f\u6307\u6570\u03b1\uff0c\u5e76\u91cd\u65b0\u5206\u6790\u4e86GWTC-3\u6570\u636e\u3002", "motivation": "\u6539\u8fdb\u5bf9\u4fee\u6b63\u8272\u6563\u5173\u7cfb\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4ee5\u66f4\u7cbe\u786e\u5730\u68c0\u9a8c\u5e7f\u4e49\u76f8\u5bf9\u8bba\u5e76\u7ea6\u675f\u53ef\u80fd\u7684\u4fee\u6b63\u9879\u5e45\u5ea6\u3002", "method": "\u91c7\u7528\u7fa4\u901f\u5ea6\u53c2\u6570\u5316\u3001\u6539\u8fdb\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u5e76\u5c06\u6d4b\u8bd5\u6269\u5c55\u5230\u8d1f\u6307\u6570\u03b1 \u2208 {-1, -2, -3}\uff0c\u7136\u540e\u91cd\u65b0\u5206\u6790GWTC-3\u76ee\u5f55\u4e2d\u7684\u5f15\u529b\u6ce2\u4e8b\u4ef6\u3002", "result": "\u4e0eGWTC-3\u7ed3\u679c\u76f8\u6bd4\uff0c\u6539\u8fdb\u65b9\u6cd5\u4f7f\u540e\u9a8c\u5206\u5e03\u5bbd\u5ea6\u5e73\u5747\u7f29\u5c0f19%\uff0c\u5f15\u529b\u5b50\u8d28\u91cf\u768490%\u4e0a\u9650\u4ece2.42\u00d710\u207b\u00b9\u00b9 peV\u6539\u8fdb\u52302.21\u00d710\u207b\u00b9\u00b9 peV\u3002\u5bf9\u4e8e\u8d1f\u6307\u6570\u6269\u5c55\u6d4b\u8bd5\uff0c\u672a\u53d1\u73b0\u652f\u6301\u5e7f\u4e49\u76f8\u5bf9\u8bba\u7834\u574f\u7684\u8bc1\u636e\u3002", "conclusion": "\u6539\u8fdb\u7684\u6d4b\u8bd5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u4fee\u6b63\u8272\u6563\u5173\u7cfb\u7ea6\u675f\u7684\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u901a\u8fc7\u6539\u8fdb\u91c7\u6837\u65b9\u6cd5\uff0c\u4f46\u5bf9\u8d1f\u6307\u6570\u03b1\u7684\u6d4b\u8bd5\u672a\u53d1\u73b0\u504f\u79bb\u5e7f\u4e49\u76f8\u5bf9\u8bba\u7684\u8bc1\u636e\u3002"}}
{"id": "2511.00454", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00454", "abs": "https://arxiv.org/abs/2511.00454", "authors": ["Jeongrak Son"], "title": "Quantum Qomrades: Catalysts in Resource Theories and Memories in Dynamic Programming", "comment": "189 pages; PhD thesis", "summary": "Quantum information theory explores the limits of manipulating quantum\nstates. While auxiliary systems often enhance information processing, a\nsystematic explanation for their power has been lacking. This thesis addresses\nthis gap by investigating the underlying sources of strength in using auxiliary\nsystems. We then apply these insights to practical problems in quantum\ncomputing and devise an algorithmic paradigm leveraging auxiliary systems. The\nfirst part examines catalysts -- auxiliary systems that remain unaltered -- and\nidentifies three advantages: a memory effect, the ability to fine-tune catalyst\nstates, and their role as seed states for resource distribution. The second\npart presents a strategy for solving recursive problems in quantum algorithms\nby employing auxiliary states as memories, achieving an exponential reduction\nin circuit depth at the cost of increased width. The findings in this thesis\nwould facilitate future research into fundamental problems like resource\ninterconversion and practical ones like optimal quantum circuit synthesis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u8f85\u52a9\u7cfb\u7edf\u5728\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u4f18\u52bf\uff0c\u8bc6\u522b\u4e86\u50ac\u5316\u5242\u7684\u4e09\u5927\u4f18\u52bf\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8f85\u52a9\u72b6\u6001\u4f5c\u4e3a\u8bb0\u5fc6\u7684\u91cf\u5b50\u7b97\u6cd5\u7b56\u7565\uff0c\u80fd\u5728\u7535\u8def\u6df1\u5ea6\u4e0a\u5b9e\u73b0\u6307\u6570\u7ea7\u51cf\u5c11\u3002", "motivation": "\u867d\u7136\u8f85\u52a9\u7cfb\u7edf\u7ecf\u5e38\u589e\u5f3a\u4fe1\u606f\u5904\u7406\u80fd\u529b\uff0c\u4f46\u5bf9\u5176\u529b\u91cf\u6765\u6e90\u7684\u7cfb\u7edf\u6027\u89e3\u91ca\u4e00\u76f4\u7f3a\u4e4f\uff0c\u672c\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7b2c\u4e00\u90e8\u5206\u7814\u7a76\u50ac\u5316\u5242\uff08\u4fdd\u6301\u4e0d\u53d8\u7684\u8f85\u52a9\u7cfb\u7edf\uff09\uff0c\u8bc6\u522b\u5176\u4e09\u5927\u4f18\u52bf\uff1b\u7b2c\u4e8c\u90e8\u5206\u63d0\u51fa\u5229\u7528\u8f85\u52a9\u72b6\u6001\u4f5c\u4e3a\u8bb0\u5fc6\u6765\u89e3\u51b3\u91cf\u5b50\u7b97\u6cd5\u4e2d\u7684\u9012\u5f52\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u4e86\u50ac\u5316\u5242\u7684\u4e09\u4e2a\u5173\u952e\u4f18\u52bf\uff1a\u8bb0\u5fc6\u6548\u5e94\u3001\u72b6\u6001\u5fae\u8c03\u80fd\u529b\u548c\u8d44\u6e90\u5206\u914d\u79cd\u5b50\u4f5c\u7528\uff1b\u63d0\u51fa\u7684\u7b97\u6cd5\u7b56\u7565\u5728\u7535\u8def\u6df1\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u51cf\u5c11\uff0c\u4f46\u589e\u52a0\u4e86\u7535\u8def\u5bbd\u5ea6\u3002", "conclusion": "\u672c\u8bba\u6587\u7684\u7814\u7a76\u53d1\u73b0\u5c06\u4fc3\u8fdb\u672a\u6765\u5728\u8d44\u6e90\u8f6c\u6362\u7b49\u57fa\u7840\u95ee\u9898\u548c\u6700\u4f18\u91cf\u5b50\u7535\u8def\u5408\u6210\u7b49\u5b9e\u9645\u95ee\u9898\u4e0a\u7684\u7814\u7a76\u3002"}}
{"id": "2511.00044", "categories": ["cs.LG", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.00044", "abs": "https://arxiv.org/abs/2511.00044", "authors": ["Kohei Tsuchiyama", "Andre Roehm", "Takatomo Mihana", "Ryoichi Horisaki"], "title": "ReLaX-Net: Reusing Layers for Parameter-Efficient Physical Neural Networks", "comment": null, "summary": "Physical Neural Networks (PNN) are promising platforms for next-generation\ncomputing systems. However, recent advances in digital neural network\nperformance are largely driven by the rapid growth in the number of trainable\nparameters and, so far, demonstrated PNNs are lagging behind by several orders\nof magnitude in terms of scale. This mirrors size and performance constraints\nfound in early digital neural networks. In that period, efficient reuse of\nparameters contributed to the development of parameter-efficient architectures\nsuch as convolutional neural networks.\n  In this work, we numerically investigate hardware-friendly weight-tying for\nPNNs. Crucially, with many PNN systems, there is a time-scale separation\nbetween the fast dynamic active elements of the forward pass and the only\nslowly trainable elements implementing weights and biases. With this in mind,we\npropose the Reuse of Layers for eXpanding a Neural Network (ReLaX-Net)\narchitecture, which employs a simple layer-by-layer time-multiplexing scheme to\nincrease the effective network depth and efficiently use the number of\nparameters. We only require the addition of fast switches for existing PNNs. We\nvalidate ReLaX-Nets via numerical experiments on image classification and\nnatural language processing tasks. Our results show that ReLaX-Net improves\ncomputational performance with only minor modifications to a conventional PNN.\nWe observe a favorable scaling, where ReLaX-Nets exceed the performance of\nequivalent traditional RNNs or DNNs with the same number of parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReLaX-Net\u67b6\u6784\uff0c\u901a\u8fc7\u65f6\u95f4\u590d\u7528\u5c42\u6765\u6269\u5c55\u7269\u7406\u795e\u7ecf\u7f51\u7edc\u7684\u6709\u6548\u6df1\u5ea6\uff0c\u63d0\u9ad8\u53c2\u6570\u5229\u7528\u6548\u7387", "motivation": "\u7269\u7406\u795e\u7ecf\u7f51\u7edc\u5728\u89c4\u6a21\u4e0a\u843d\u540e\u6570\u5b57\u795e\u7ecf\u7f51\u7edc\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u9700\u8981\u53c2\u6570\u9ad8\u6548\u7684\u91cd\u7528\u65b9\u6cd5\uff0c\u7c7b\u4f3c\u4e8e\u65e9\u671f\u6570\u5b57\u795e\u7ecf\u7f51\u7edc\u4e2d\u5377\u79ef\u7f51\u7edc\u7684\u53d1\u5c55", "method": "\u91c7\u7528\u5c42\u95f4\u65f6\u95f4\u590d\u7528\u65b9\u6848\uff0c\u5728\u73b0\u6709PNN\u57fa\u7840\u4e0a\u4ec5\u9700\u6dfb\u52a0\u5feb\u901f\u5f00\u5173\uff0c\u901a\u8fc7\u91cd\u7528\u5c42\u6765\u6269\u5c55\u7f51\u7edc\u6df1\u5ea6", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0cReLaX-Net\u5728\u76f8\u540c\u53c2\u6570\u6570\u91cf\u4e0b\u6027\u80fd\u4f18\u4e8e\u4f20\u7edfRNN\u6216DNN", "conclusion": "ReLaX-Net\u901a\u8fc7\u7b80\u5355\u4fee\u6539\u663e\u8457\u63d0\u5347PNN\u8ba1\u7b97\u6027\u80fd\uff0c\u5c55\u73b0\u51fa\u6709\u5229\u7684\u7f29\u653e\u7279\u6027"}}
{"id": "2511.00565", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00565", "abs": "https://arxiv.org/abs/2511.00565", "authors": ["Wei-Liang Qian", "Qiyuan Pan", "Ramin G. Daghigh", "Bean Wang", "Rui-Hong Yue"], "title": "Reflectionless and echo modes in asymmetric Damour-Solodukhin wormholes", "comment": "39 pages, 6 figures", "summary": "It is understood that the echo waveforms in ultracompact objects can be\nregarded as composed mainly of the asymptotic high-overtone quasinormal modes,\ndubbed echo modes, which predominantly lie parallel to the real frequency axis.\nAlternatively, Rosato {\\it et al.} recently suggested that high-frequency\nquasi-reflectionless scattering modes are primarily responsible for the echo\nphenomenon. This identification relies on greybody factors as stable\nobservables, despite the apparent spectral instability of quasinormal modes. In\nthis work, by extending the definition of quasi-reflectionless modes to\nreflectionless ones and generalizing symmetric Damour-Solodukhin wormholes to\nasymmetric cases, we examine the underlying similarity between the\nreflectionless and echo mode spectra in the complex frequency plane. Through a\nprimarily analytical treatment, we demonstrate that the asymptotic properties\nof these two spectra exhibit a strong resemblance, featuring an approximately\nuniform distribution parallel to the real frequency axis with the same spacing\nbetween successive modes. Specifically, the real parts of echo modes coincide\nwith those of reflectionless modes at the limit $|\\mathrm{Re}\\omega| \\gg\n|\\mathrm{Im}\\omega|$. While echo modes typically possess non-vanishing\nimaginary parts, the reflectionless modes of symmetric Damour-Solodukhin\nwormholes lie precisely on the real frequency axis, with any deviation serving\nas a measure of the degree of asymmetry of the wormhole. We support our\nderivations by employing two complementary approaches, based on the scattering\nmatrix and the Green's function, and argue that both perspectives provide\neffective tools for describing the echo phenomenon.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8d85\u81f4\u5bc6\u5929\u4f53\u56de\u6ce2\u73b0\u8c61\u4e2d\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u548c\u56de\u6ce2\u6a21\u5f0f\u5728\u590d\u9891\u7387\u5e73\u9762\u4e0a\u7684\u76f8\u4f3c\u6027\uff0c\u53d1\u73b0\u4e24\u79cd\u8c31\u7684\u6e10\u8fd1\u7279\u6027\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u5728\u5b9e\u8f74\u9644\u8fd1\u5177\u6709\u5747\u5300\u5206\u5e03\u4e14\u6a21\u5f0f\u95f4\u8ddd\u76f8\u540c\u3002", "motivation": "\u7406\u89e3\u8d85\u81f4\u5bc6\u5929\u4f53\u56de\u6ce2\u73b0\u8c61\u7684\u7269\u7406\u673a\u5236\uff0c\u6f84\u6e05\u56de\u6ce2\u6a21\u5f0f\u4e0e\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u63cf\u8ff0\u56de\u6ce2\u73b0\u8c61\u7684\u6709\u6548\u7406\u8bba\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u5c06\u51c6\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u6269\u5c55\u5230\u5b8c\u5168\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\uff0c\u5e76\u5c06\u5bf9\u79f0Damour-Solodukhin\u866b\u6d1e\u63a8\u5e7f\u5230\u975e\u5bf9\u79f0\u60c5\u51b5\uff0c\u4f7f\u7528\u6563\u5c04\u77e9\u9635\u548c\u683c\u6797\u51fd\u6570\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\u8fdb\u884c\u4e3b\u8981\u89e3\u6790\u5904\u7406\u3002", "result": "\u53d1\u73b0\u56de\u6ce2\u6a21\u5f0f\u548c\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u7684\u6e10\u8fd1\u8c31\u5728\u590d\u9891\u7387\u5e73\u9762\u4e0a\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u90fd\u5177\u6709\u5e73\u884c\u4e8e\u5b9e\u8f74\u7684\u8fd1\u4f3c\u5747\u5300\u5206\u5e03\uff0c\u4e14\u6a21\u5f0f\u95f4\u8ddd\u76f8\u540c\u3002\u5bf9\u79f0\u866b\u6d1e\u7684\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u7cbe\u786e\u4f4d\u4e8e\u5b9e\u9891\u7387\u8f74\u4e0a\u3002", "conclusion": "\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u548c\u56de\u6ce2\u6a21\u5f0f\u90fd\u63d0\u4f9b\u4e86\u63cf\u8ff0\u56de\u6ce2\u73b0\u8c61\u7684\u6709\u6548\u5de5\u5177\uff0c\u4e24\u79cd\u89c6\u89d2\u5728\u590d\u9891\u7387\u5e73\u9762\u4e0a\u5c55\u73b0\u51fa\u5f3a\u76f8\u4f3c\u6027\uff0c\u53cd\u5c04\u65e0\u53cd\u5c04\u6a21\u5f0f\u7684\u504f\u79bb\u53ef\u4f5c\u4e3a\u866b\u6d1e\u4e0d\u5bf9\u79f0\u7a0b\u5ea6\u7684\u5ea6\u91cf\u3002"}}
{"id": "2511.00466", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.00466", "abs": "https://arxiv.org/abs/2511.00466", "authors": ["Ayan Kumar Nai", "G. K. Samanta"], "title": "Free-space multi-user quantum network with high key rate", "comment": null, "summary": "Emergent quantum networks are the essential ingredient for securely\nconnecting multiple users worldwide, extensively deployed in both fibre and\nfree-space. An essential element is the multiplexing of entanglement to\nmultiple users, overcoming the peer-to-peer restriction of quantum key\ndistribution (QKD), so far successfully shown in fibre-based architectures.\nHere, we demonstrate a free-space quantum space division multiplexing\narchitecture using just one entanglement source to realise a fully connected\ntwelve-channel quantum network for seamless QKD connections between six users.\nThe network achieves record coincidence rates exceeding $3 \\times 10^{4}$\ns$^{-1}$ between any pair of nodes on the network, for sifted key rate of over\n400 kbps. Our approach overcomes the active switching hurdle that has hindered\nthe free-space deployment of quantum multiplexing, is fully passive, easily\nscalable to more nodes and compatible with fibre-based integration, thus\nopening a new path to scalable and resource-efficient quantum networks that\nutilise free-space links.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u81ea\u7531\u7a7a\u95f4\u91cf\u5b50\u7a7a\u5206\u590d\u7528\u67b6\u6784\uff0c\u4f7f\u7528\u5355\u4e2a\u7ea0\u7f20\u6e90\u5b9e\u73b0\u516d\u7528\u6237\u5168\u8fde\u63a5\u5341\u4e8c\u901a\u9053\u91cf\u5b50\u7f51\u7edc\uff0c\u514b\u670d\u4e86\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u4e2d\u7684\u70b9\u5bf9\u70b9\u9650\u5236\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u4e2d\u7684\u70b9\u5bf9\u70b9\u9650\u5236\uff0c\u5b9e\u73b0\u591a\u7528\u6237\u5b89\u5168\u8fde\u63a5\uff0c\u7279\u522b\u662f\u5728\u81ea\u7531\u7a7a\u95f4\u73af\u5883\u4e2d\u514b\u670d\u4e3b\u52a8\u5207\u6362\u969c\u788d\u3002", "method": "\u91c7\u7528\u81ea\u7531\u7a7a\u95f4\u91cf\u5b50\u7a7a\u5206\u590d\u7528\u67b6\u6784\uff0c\u4f7f\u7528\u5355\u4e2a\u7ea0\u7f20\u6e90\u6784\u5efa\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u5b9e\u73b0\u5b8c\u5168\u88ab\u52a8\u64cd\u4f5c\u3002", "result": "\u7f51\u7edc\u5b9e\u73b0\u4e86\u8d85\u8fc73\u00d710^4 s^-1\u7684\u7b26\u5408\u8ba1\u6570\u7387\uff0c\u4efb\u610f\u8282\u70b9\u95f4\u7684\u7b5b\u9009\u5bc6\u94a5\u7387\u8d85\u8fc7400 kbps\uff0c\u521b\u4e0b\u8bb0\u5f55\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u81ea\u7531\u7a7a\u95f4\u91cf\u5b50\u590d\u7528\u7684\u4e3b\u52a8\u5207\u6362\u969c\u788d\uff0c\u5177\u6709\u5b8c\u5168\u88ab\u52a8\u3001\u6613\u4e8e\u6269\u5c55\u548c\u4e0e\u5149\u7ea4\u96c6\u6210\u517c\u5bb9\u7684\u7279\u70b9\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u91cf\u5b50\u7f51\u7edc\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.00047", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.00047", "abs": "https://arxiv.org/abs/2511.00047", "authors": ["Omkar Kulkarni", "Rohitash Chandra"], "title": "DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection", "comment": null, "summary": "Financial fraud detection is critical for maintaining the integrity of\nfinancial systems, particularly in decentralised environments such as\ncryptocurrency networks. Although Graph Convolutional Networks (GCNs) are\nwidely used for financial fraud detection, graph Transformer models such as\nGraph-BERT are gaining prominence due to their Transformer-based architecture,\nwhich mitigates issues such as over-smoothing. Graph-BERT is designed for\nstatic graphs and primarily evaluated on citation networks with undirected\nedges. However, financial transaction networks are inherently dynamic, with\nevolving structures and directed edges representing the flow of money. To\naddress these challenges, we introduce DynBERG, a novel architecture that\nintegrates Graph-BERT with a Gated Recurrent Unit (GRU) layer to capture\ntemporal evolution over multiple time steps. Additionally, we modify the\nunderlying algorithm to support directed edges, making DynBERG well-suited for\ndynamic financial transaction analysis. We evaluate our model on the Elliptic\ndataset, which includes Bitcoin transactions, including all transactions during\na major cryptocurrency market event, the Dark Market Shutdown. By assessing\nDynBERG's resilience before and after this event, we analyse its ability to\nadapt to significant market shifts that impact transaction behaviours. Our\nmodel is benchmarked against state-of-the-art dynamic graph classification\napproaches, such as EvolveGCN and GCN, demonstrating superior performance,\noutperforming EvolveGCN before the market shutdown and surpassing GCN after the\nevent. Additionally, an ablation study highlights the critical role of\nincorporating a time-series deep learning component, showcasing the\neffectiveness of GRU in modelling the temporal dynamics of financial\ntransactions.", "AI": {"tldr": "\u63d0\u51faDynBERG\u6a21\u578b\uff0c\u5c06Graph-BERT\u4e0eGRU\u7ed3\u5408\uff0c\u7528\u4e8e\u52a8\u6001\u91d1\u878d\u4ea4\u6613\u7f51\u7edc\u7684\u6b3a\u8bc8\u68c0\u6d4b\uff0c\u5728\u6bd4\u7279\u5e01\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709Graph-BERT\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u65e0\u5411\u56fe\u8bbe\u8ba1\uff0c\u800c\u91d1\u878d\u4ea4\u6613\u7f51\u7edc\u5177\u6709\u52a8\u6001\u6f14\u5316\u548c\u6709\u5411\u8fb9\u7279\u6027\uff0c\u9700\u8981\u4e13\u95e8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408Graph-BERT\u4e0eGRU\u5c42\u6355\u6349\u65f6\u5e8f\u6f14\u5316\uff0c\u4fee\u6539\u7b97\u6cd5\u652f\u6301\u6709\u5411\u8fb9\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u91d1\u878d\u4ea4\u6613\u5206\u6790\u3002", "result": "\u5728Elliptic\u6bd4\u7279\u5e01\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\uff0cDynBERG\u5728\u5e02\u573a\u5173\u95ed\u4e8b\u4ef6\u524d\u540e\u5747\u4f18\u4e8eEvolveGCN\u548cGCN\uff0cGRU\u7ec4\u4ef6\u5bf9\u65f6\u5e8f\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "DynBERG\u80fd\u6709\u6548\u9002\u5e94\u91d1\u878d\u5e02\u573a\u91cd\u5927\u53d8\u5316\uff0c\u4e3a\u52a8\u6001\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00585", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00585", "abs": "https://arxiv.org/abs/2511.00585", "authors": ["Jiale Gu", "Leonardo Modesto", "Cosimo Bambi"], "title": "Taming singularities and chaos in conformal gravity", "comment": "11 pages, no figures", "summary": "We hereby address the cosmological singularity problem in a general\ngravitational theory invariant under Weyl conformal transformations. In\nparticular, we focus on the Bianchi IX spacetime and we show that both the\ninitial (big bang) and final (big crunch) singularities disappear in an\ninfinite class of conformal frames naturally selected according to analyticity.\nIt turns out that the past and future singularities are both unattainable\nwithin a finite affine parameter (for massless particles) or within a finite\nproper time (for massive and conformally coupled particles). In order to prove\nsuch a statement, we show the geodesic completion of the spacetime when probed\nby massless, massive, and conformally coupled particles. Finally, the chaotic\nbehavior of the spacetime near the singularity is tamed by a conformal\nrescaling that turns the Bianchi IX metric into a quasi-FLRW spacetime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7Weyl\u5171\u5f62\u53d8\u6362\u89e3\u51b3\u4e86Bianchi IX\u65f6\u7a7a\u4e2d\u7684\u5b87\u5b99\u5b66\u5947\u70b9\u95ee\u9898\uff0c\u8bc1\u660e\u5728\u65e0\u9650\u7c7b\u5171\u5f62\u6846\u67b6\u4e0b\uff0c\u521d\u59cb\uff08\u5927\u7206\u70b8\uff09\u548c\u6700\u7ec8\uff08\u5927\u6324\u538b\uff09\u5947\u70b9\u90fd\u6d88\u5931\u4e86\u3002", "motivation": "\u89e3\u51b3\u5e7f\u4e49\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u5b87\u5b99\u5b66\u5947\u70b9\u95ee\u9898\uff0c\u7279\u522b\u662fBianchi IX\u65f6\u7a7a\u4e2d\u7684\u521d\u59cb\u548c\u6700\u7ec8\u5947\u70b9\u95ee\u9898\u3002", "method": "\u91c7\u7528Weyl\u5171\u5f62\u4e0d\u53d8\u6027\u7406\u8bba\uff0c\u5728\u65e0\u9650\u7c7b\u5171\u5f62\u6846\u67b6\u4e0b\u5206\u6790\u65f6\u7a7a\u7684\u6d4b\u5730\u5b8c\u5907\u6027\uff0c\u5206\u522b\u7814\u7a76\u65e0\u8d28\u91cf\u7c92\u5b50\u3001\u6709\u8d28\u91cf\u7c92\u5b50\u548c\u5171\u5f62\u8026\u5408\u7c92\u5b50\u7684\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u8fc7\u53bb\u548c\u672a\u6765\u5947\u70b9\u5728\u6709\u9650\u4eff\u5c04\u53c2\u6570\uff08\u65e0\u8d28\u91cf\u7c92\u5b50\uff09\u6216\u6709\u9650\u56fa\u6709\u65f6\u95f4\uff08\u6709\u8d28\u91cf\u548c\u5171\u5f62\u8026\u5408\u7c92\u5b50\uff09\u5185\u90fd\u65e0\u6cd5\u8fbe\u5230\uff0c\u65f6\u7a7a\u5728\u5171\u5f62\u53d8\u6362\u4e0b\u53d8\u5f97\u6d4b\u5730\u5b8c\u5907\u3002", "conclusion": "\u901a\u8fc7\u5171\u5f62\u91cd\u65b0\u6807\u5ea6\uff0cBianchi IX\u5ea6\u91cf\u53ef\u4ee5\u8f6c\u5316\u4e3a\u51c6FLRW\u65f6\u7a7a\uff0c\u4ece\u800c\u9a6f\u670d\u4e86\u5947\u70b9\u9644\u8fd1\u7684\u6df7\u6c8c\u884c\u4e3a\uff0c\u89e3\u51b3\u4e86\u5947\u70b9\u95ee\u9898\u3002"}}
{"id": "2511.00483", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00483", "abs": "https://arxiv.org/abs/2511.00483", "authors": ["Debanjan Dey Sarkar", "Mallika Mondal", "Preeti Parashar", "Tamal Guha"], "title": "Lost and found charge in quantum batteries", "comment": "4.5+5 pages, 1 figure. Comments are welcome", "summary": "Quantum batteries are prone to loosing their stored charge, when interacting\nwith a thermal environment. However, getting a limited assistance from the\nthermal environment, is it possible to recover the charge back, in a reusable\nform? Here we answer this question affirmatively, leveraging a non-trivial\nusage of the seemingly useless thermal environment to recycle the quantum\nbatteries. The framework involves two different kind of assistance from thermal\nenvironment - one by accessing only the thermal particle, actively\nparticipating in the interaction; and the other, involving assistance from an\nadditional purifying subsystem for the thermal environment, bearing a passive\nrole to the interaction. Interestingly, we report that the difference between\nthe retrieved charge between these two degrees of assistance characterizes the\namount of entanglement generated by the thermal operation between the quantum\nbattery and the purifying subsystem for the thermal environment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u70ed\u73af\u5883\u56de\u6536\u91cf\u5b50\u7535\u6c60\u7535\u8377\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u79cd\u4e0d\u540c\u7684\u70ed\u73af\u5883\u8f85\u52a9\u65b9\u5f0f\uff08\u4e3b\u52a8\u53c2\u4e0e\u548c\u88ab\u52a8\u51c0\u5316\uff09\u6765\u6062\u590d\u91cf\u5b50\u7535\u6c60\u7684\u5b58\u50a8\u7535\u8377\u3002", "motivation": "\u91cf\u5b50\u7535\u6c60\u5728\u4e0e\u70ed\u73af\u5883\u76f8\u4e92\u4f5c\u7528\u65f6\u4f1a\u635f\u5931\u5b58\u50a8\u7684\u7535\u8377\uff0c\u7814\u7a76\u5982\u4f55\u5229\u7528\u70ed\u73af\u5883\u672c\u8eab\u6765\u56de\u6536\u8fd9\u4e9b\u7535\u8377\uff0c\u4f7f\u5176\u53ef\u91cd\u590d\u4f7f\u7528\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u70ed\u73af\u5883\u8f85\u52a9\u6846\u67b6\uff1a\u4e00\u79cd\u662f\u4ec5\u8bbf\u95ee\u70ed\u7c92\u5b50\u5e76\u4e3b\u52a8\u53c2\u4e0e\u76f8\u4e92\u4f5c\u7528\uff1b\u53e6\u4e00\u79cd\u662f\u6d89\u53ca\u70ed\u73af\u5883\u989d\u5916\u51c0\u5316\u5b50\u7cfb\u7edf\u7684\u88ab\u52a8\u8f85\u52a9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e24\u79cd\u8f85\u52a9\u65b9\u5f0f\u56de\u6536\u7684\u7535\u8377\u91cf\u4e4b\u5dee\u8868\u5f81\u4e86\u70ed\u64cd\u4f5c\u5728\u91cf\u5b50\u7535\u6c60\u4e0e\u70ed\u73af\u5883\u51c0\u5316\u5b50\u7cfb\u7edf\u4e4b\u95f4\u4ea7\u751f\u7684\u7ea0\u7f20\u91cf\u3002", "conclusion": "\u786e\u8ba4\u4e86\u5229\u7528\u70ed\u73af\u5883\u56de\u6536\u91cf\u5b50\u7535\u6c60\u7535\u8377\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u56de\u6536\u7535\u8377\u5dee\u4e0e\u7cfb\u7edf\u95f4\u7ea0\u7f20\u7684\u91cf\u5316\u5173\u7cfb\u3002"}}
{"id": "2511.00049", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00049", "abs": "https://arxiv.org/abs/2511.00049", "authors": ["Yao Liu"], "title": "Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting", "comment": null, "summary": "Accurate and robust weather forecasting remains a fundamental challenge due\nto the inherent spatio-temporal complexity of atmospheric systems. In this\npaper, we propose a novel self-supervised learning framework that leverages\nspatio-temporal structures to improve multi-variable weather prediction. The\nmodel integrates a graph neural network (GNN) for spatial reasoning, a\nself-supervised pretraining scheme for representation learning, and a\nspatio-temporal adaptation mechanism to enhance generalization across varying\nforecasting horizons. Extensive experiments on both ERA5 and MERRA-2 reanalysis\ndatasets demonstrate that our approach achieves superior performance compared\nto traditional numerical weather prediction (NWP) models and recent deep\nlearning methods. Quantitative evaluations and visual analyses in Beijing and\nShanghai confirm the model's capability to capture fine-grained meteorological\npatterns. The proposed framework provides a scalable and label-efficient\nsolution for future data-driven weather forecasting systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u591a\u53d8\u91cf\u5929\u6c14\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u65f6\u7a7a\u9002\u5e94\u673a\u5236\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u7531\u4e8e\u5927\u6c14\u7cfb\u7edf\u56fa\u6709\u7684\u65f6\u7a7a\u590d\u6742\u6027\uff0c\u51c6\u786e\u7a33\u5065\u7684\u5929\u6c14\u9884\u62a5\u4ecd\u7136\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002", "method": "\u6574\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\uff0c\u91c7\u7528\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6848\u8fdb\u884c\u8868\u793a\u5b66\u4e60\uff0c\u5e76\u5229\u7528\u65f6\u7a7a\u9002\u5e94\u673a\u5236\u589e\u5f3a\u4e0d\u540c\u9884\u6d4b\u65f6\u957f\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728ERA5\u548cMERRA-2\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u6a21\u578b\u548c\u8fd1\u671f\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u6027\u80fd\u3002\u5728\u5317\u4eac\u548c\u4e0a\u6d77\u7684\u5b9a\u91cf\u8bc4\u4f30\u548c\u89c6\u89c9\u5206\u6790\u8bc1\u5b9e\u4e86\u6a21\u578b\u6355\u6349\u7ec6\u7c92\u5ea6\u6c14\u8c61\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u6570\u636e\u9a71\u52a8\u7684\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6807\u7b7e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00586", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00586", "abs": "https://arxiv.org/abs/2511.00586", "authors": ["Xiao-Xiong Zeng", "Chen-Yu Yang", "Muhammad Israr Aslam", "Rabia Saleem"], "title": "Probing Non-rotating Black Hole in Kalb-Ramond Gravity: Imaging and Polarized Signatures Surrounded by Different Thick Accretion Flows", "comment": "36 pages, 13 figures", "summary": "In this work, we consider a spherically symmetric static black hole metric in\nKalb-Ramond (KR) gravity, and investigate the impact of relevant parameters on\nthe black hole shadow and polarization images. For black hole shadow images, we\nconsider two geometrically thick accretion disk models such as a\nphenomenological RIAF-like model and an analytical HOU disk model. In each\ncase, we observe a bright ring-like structure corresponding to the higher-order\nimages with a surrounding region of non-zero intensity that represents the\nprimary image. The increasing values of $\\hat{\\lambda}$ or $\\hat{\\gamma}$\nresults in decrease the size of the higher-order image, while increasing values\nof observer inclination $\\theta_{o}$ alter its shape and cause the horizons\noutline to be obscured. On the other hand, in HOU disk model, at high observer\ninclinations, the obscuration of the horizons outline by radiation from outside\nthe equatorial plane is weakened. Consequently, the brightness of the primary\nimage in the phenomenological model is significantly greater than that in the\nHOU disk model, indicating the strong gravitational lensing effect. For the\npolarized images, we use only the HOU disk model with anisotropic radiation,\nassuming an infalling accretion flow matter. The obtained results illustrate\nthat the polarization intensity $P_{o}$ in the higher-order image region is\nsignificantly stronger than as compare to other regions, and it is rapidly\ndecreases away from this region. The variation in $\\hat{\\lambda}$ and\n$\\hat{\\gamma}$ depicts the intrinsic structure of the space-time and $\\theta_o$\ndepends on the observers orientation, together they shape the polarization\nfeatures.", "AI": {"tldr": "\u7814\u7a76Kalb-Ramond\u5f15\u529b\u4e2d\u7403\u5f62\u5bf9\u79f0\u9759\u6001\u9ed1\u6d1e\u7684\u9634\u5f71\u548c\u504f\u632f\u56fe\u50cf\uff0c\u5206\u6790\u53c2\u6570\u5bf9\u9ad8\u9636\u56fe\u50cf\u548c\u521d\u7ea7\u56fe\u50cf\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8KR\u5f15\u529b\u4e2d\u9ed1\u6d1e\u53c2\u6570\u5bf9\u9634\u5f71\u548c\u504f\u632f\u56fe\u50cf\u7684\u5f71\u54cd\uff0c\u7406\u89e3\u4e0d\u540c\u5438\u79ef\u76d8\u6a21\u578b\u4e0b\u7684\u6210\u50cf\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u51e0\u4f55\u539a\u5438\u79ef\u76d8\u6a21\u578b\uff08RIAF-like\u6a21\u578b\u548cHOU\u76d8\u6a21\u578b\uff09\u5206\u6790\u9ed1\u6d1e\u9634\u5f71\uff0c\u5728HOU\u76d8\u6a21\u578b\u4e0b\u7814\u7a76\u5404\u5411\u5f02\u6027\u8f90\u5c04\u7684\u504f\u632f\u56fe\u50cf\u3002", "result": "\u53c2\u6570\u589e\u52a0\u4f1a\u51cf\u5c0f\u9ad8\u9636\u56fe\u50cf\u5c3a\u5bf8\uff0c\u89c2\u6d4b\u8005\u503e\u89d2\u6539\u53d8\u56fe\u50cf\u5f62\u72b6\u3002HOU\u6a21\u578b\u4e2d\u9ad8\u503e\u89d2\u65f6\u89c6\u754c\u8f6e\u5ed3\u906e\u853d\u51cf\u5f31\u3002\u504f\u632f\u5f3a\u5ea6\u5728\u9ad8\u9636\u56fe\u50cf\u533a\u57df\u6700\u5f3a\uff0c\u8fdc\u79bb\u65f6\u5feb\u901f\u8870\u51cf\u3002", "conclusion": "\u53c2\u6570\u53d8\u5316\u63ed\u793a\u4e86\u65f6\u7a7a\u5185\u5728\u7ed3\u6784\uff0c\u89c2\u6d4b\u8005\u53d6\u5411\u4e0e\u53c2\u6570\u5171\u540c\u5851\u9020\u504f\u632f\u7279\u5f81\uff0c\u4e0d\u540c\u5438\u79ef\u76d8\u6a21\u578b\u663e\u793a\u663e\u8457\u4eae\u5ea6\u5dee\u5f02\u3002"}}
{"id": "2511.00506", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00506", "abs": "https://arxiv.org/abs/2511.00506", "authors": ["Shreetam Dash", "Shreya Banerjee", "Prasanta K. Panigrahi"], "title": "Hierarchical Quantum Optimization for Large-Scale Vehicle Routing: A Multi-Angle QAOA Approach with Clustered Decomposition", "comment": null, "summary": "We present a quantum optimization methodology for solving large-scale Vehicle\nRouting Problem (VRP) using a combination of standard and Multi-Angle Quantum\nApproximate Optimization Algorithms (MA-QAOA). The approach decomposes\n13-locations based VRP problems through clustering into three balanced clusters\nof 4 nodes each, then applies standard QAOA for intra-cluster Open Loop\nTraveling Salesman Problem (OTSP) and MA-QAOA for inter-cluster VRP routing.\nValidation across 10 distinct datasets demonstrates that standard QAOA\nconsistently identifies optimal solutions for intra-cluster routing, which is\nmatching classical Gurobi optimizer results exactly. More significantly,\nMA-QAOA with Simultaneous Perturbation Stochastic Approximation(SPSA) optimizer\ndemonstrates competitive performance against classical optimization methods,\nultimately converging towards a solution that closely approximates the\nclassical Gurobi optimizer result.The clustered decomposition enables quantum\noptimization of problem sizes generally larger than previous quantum VRP\nimplementations, advancing from 4-6 location limits to 13-location problems\nwhile maintaining solution quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6807\u51c6QAOA\u548cMA-QAOA\u7684\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u7c7b\u5206\u89e3\u89e3\u51b313\u4e2a\u4f4d\u7f6e\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u5e73\u8861\u76844\u8282\u70b9\u96c6\u7fa4\uff0c\u5206\u522b\u5904\u7406\u96c6\u7fa4\u5185\u548c\u96c6\u7fa4\u95f4\u8def\u7531\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u91cf\u5b50VRP\u5b9e\u73b0\u53ea\u80fd\u5904\u74064-6\u4e2a\u4f4d\u7f6e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u805a\u7c7b\u5206\u89e3\u65b9\u6cd5\u5c06\u95ee\u9898\u89c4\u6a21\u6269\u5c55\u523013\u4e2a\u4f4d\u7f6e\uff0c\u540c\u65f6\u4fdd\u6301\u89e3\u7684\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u805a\u7c7b\u65b9\u6cd5\u5c0613\u4e2a\u4f4d\u7f6e\u7684VRP\u5206\u89e3\u4e3a\u4e09\u4e2a\u5e73\u8861\u76844\u8282\u70b9\u96c6\u7fa4\uff0c\u5bf9\u96c6\u7fa4\u5185\u8def\u7531\u4f7f\u7528\u6807\u51c6QAOA\u89e3\u51b3\u5f00\u653e\u56de\u8def\u65c5\u884c\u5546\u95ee\u9898\uff0c\u5bf9\u96c6\u7fa4\u95f4\u8def\u7531\u4f7f\u7528\u5e26SPSA\u4f18\u5316\u5668\u7684MA-QAOA\u3002", "result": "\u572810\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\uff0c\u6807\u51c6QAOA\u5728\u96c6\u7fa4\u5185\u8def\u7531\u4e2d\u59cb\u7ec8\u627e\u5230\u6700\u4f18\u89e3\uff0c\u4e0e\u7ecf\u5178Gurobi\u4f18\u5316\u5668\u7ed3\u679c\u5b8c\u5168\u5339\u914d\uff1bMA-QAOA\u5728\u96c6\u7fa4\u95f4\u8def\u7531\u4e2d\u8868\u73b0\u51fa\u4e0e\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u6700\u7ec8\u6536\u655b\u5230\u63a5\u8fd1Gurobi\u4f18\u5316\u5668\u7684\u89e3\u3002", "conclusion": "\u805a\u7c7b\u5206\u89e3\u65b9\u6cd5\u4f7f\u91cf\u5b50\u4f18\u5316\u80fd\u591f\u5904\u7406\u6bd4\u4ee5\u5f80\u66f4\u5927\u7684\u95ee\u9898\u89c4\u6a21\uff0c\u4ece4-6\u4e2a\u4f4d\u7f6e\u6269\u5c55\u523013\u4e2a\u4f4d\u7f6e\uff0c\u540c\u65f6\u4fdd\u6301\u89e3\u7684\u8d28\u91cf\uff0c\u4e3a\u5927\u89c4\u6a21\u91cf\u5b50\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.00050", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00050", "abs": "https://arxiv.org/abs/2511.00050", "authors": ["Dhananjaya Gowda", "Seoha Song", "Junhyun Lee", "Harshith Goka"], "title": "FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs", "comment": null, "summary": "As the large language models (LLMs) grow in size each day, efficient training\nand fine-tuning has never been as important as nowadays. This resulted in the\ngreat interest in parameter efficient fine-tuning (PEFT), and effective methods\nincluding low-rank adapters (LoRA) has emerged. Although the various PEFT\nmethods have been studied extensively in the recent years, the greater part of\nthe subject remains unexplored with the huge degree of freedom. In this paper,\nwe propose FLoRA, a family of fused forward-backward adapters (FFBA) for\nparameter-efficient fine-tuning of LLMs on downstream tasks. The FFBA combine\nideas from the popular LoRA and parallel adapters to improve the overall\nfine-tuning accuracies. At the same time, latencies are minimized by fusing the\nforward and backward adapters into existing projection layers of the base\nmodel. Experimental results show that the proposed FFB adapters perform\nsignificantly better than the popularly used LoRA in both accuracy and latency\nfor a similar parameter budget.", "AI": {"tldr": "\u63d0\u51fa\u4e86FLoRA\u65b9\u6cd5\uff0c\u4e00\u79cd\u878d\u5408\u524d\u5411-\u540e\u5411\u9002\u914d\u5668\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff0c\u7ed3\u5408\u4e86LoRA\u548c\u5e76\u884c\u9002\u914d\u5668\u7684\u4f18\u52bf\uff0c\u5728\u4fdd\u6301\u76f8\u4f3c\u53c2\u6570\u9884\u7b97\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u65e5\u76ca\u589e\u957f\uff0c\u9ad8\u6548\u8bad\u7ec3\u548c\u5fae\u8c03\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u4ecd\u6709\u5927\u91cf\u81ea\u7531\u5ea6\u672a\u88ab\u63a2\u7d22\u3002", "method": "FLoRA\u878d\u5408\u4e86\u6d41\u884c\u7684LoRA\u548c\u5e76\u884c\u9002\u914d\u5668\u7684\u601d\u60f3\uff0c\u901a\u8fc7\u5c06\u524d\u5411\u548c\u540e\u5411\u9002\u914d\u5668\u878d\u5408\u5230\u57fa\u7840\u6a21\u578b\u7684\u73b0\u6709\u6295\u5f71\u5c42\u4e2d\u6765\u6700\u5c0f\u5316\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u76f8\u4f3c\u53c2\u6570\u9884\u7b97\u4e0b\uff0cFLoRA\u5728\u51c6\u786e\u6027\u548c\u5ef6\u8fdf\u65b9\u9762\u90fd\u663e\u8457\u4f18\u4e8e\u5e38\u7528\u7684LoRA\u65b9\u6cd5\u3002", "conclusion": "FLoRA\u4e3aLLM\u7684\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6848\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.00621", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.00621", "abs": "https://arxiv.org/abs/2511.00621", "authors": ["Meet Khatri", "Ankur Renduchintala", "Sayak Datta", "Sajal Mukherjee"], "title": "Impact of a third body on binary neutron star tidal interactions", "comment": "9 pages, 4 figures", "summary": "For waveform modelling of compact binary coalescence, it is conventionally\nassumed that the binary is in isolation. In this work, we break that assumption\nand introduce a third body at a distance. The primary goal is to understand how\nthe distant third body would affect the binary dynamics. However, in the\npresent work, we treat the three-body problem perturbatively and study tidal\ninteraction in the binary due to the third body's presence. We introduce\nappropriate modifications to the equations governing the orbital motions and\nthe evolution equations of the binary component's quadrupole moment. Further,\nwe obtain the radiated energy and accumulated dephasing for the binary. We show\nthat for b-EMRI, the effect is weak in the tidal sector, while for systems such\nas b-IMRIs, it would be most relevant to study these effects.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7d27\u51d1\u53cc\u661f\u5e76\u5408\u6ce2\u5f62\u5efa\u6a21\u4e2d\u5f15\u5165\u7b2c\u4e09\u4f53\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u7b2c\u4e09\u4f53\u5bf9\u53cc\u661f\u52a8\u529b\u5b66\u548c\u6f6e\u6c50\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u7684\u7d27\u51d1\u53cc\u661f\u5e76\u5408\u6ce2\u5f62\u5efa\u6a21\u5047\u8bbe\u53cc\u661f\u5904\u4e8e\u5b64\u7acb\u72b6\u6001\uff0c\u4f46\u73b0\u5b9e\u4e2d\u53ef\u80fd\u5b58\u5728\u7b2c\u4e09\u4f53\u6270\u52a8\u3002\u672c\u7814\u7a76\u65e8\u5728\u6253\u7834\u8fd9\u4e00\u5047\u8bbe\uff0c\u63a2\u8ba8\u9065\u8fdc\u7b2c\u4e09\u4f53\u5bf9\u53cc\u661f\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5fae\u6270\u65b9\u6cd5\u5904\u7406\u4e09\u4f53\u95ee\u9898\uff0c\u7814\u7a76\u7b2c\u4e09\u4f53\u5b58\u5728\u5f15\u8d77\u7684\u6f6e\u6c50\u76f8\u4e92\u4f5c\u7528\u3002\u4fee\u6539\u4e86\u8f68\u9053\u8fd0\u52a8\u65b9\u7a0b\u548c\u53cc\u661f\u7ec4\u5206\u56db\u6781\u77e9\u6f14\u5316\u65b9\u7a0b\uff0c\u8ba1\u7b97\u4e86\u8f90\u5c04\u80fd\u91cf\u548c\u7d2f\u79ef\u76f8\u4f4d\u5dee\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5bf9\u4e8eb-EMRI\u7cfb\u7edf\uff0c\u6f6e\u6c50\u6548\u5e94\u8f83\u5f31\uff1b\u800c\u5bf9\u4e8eb-IMRI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u6548\u5e94\u6700\u4e3a\u663e\u8457\uff0c\u503c\u5f97\u6df1\u5165\u7814\u7a76\u3002", "conclusion": "\u7b2c\u4e09\u4f53\u6270\u52a8\u5bf9\u7d27\u51d1\u53cc\u661f\u5e76\u5408\u7cfb\u7edf\u7684\u5f71\u54cd\u56e0\u7cfb\u7edf\u7c7b\u578b\u800c\u5f02\uff0cb-IMRI\u7cfb\u7edf\u662f\u7814\u7a76\u8fd9\u4e9b\u6548\u5e94\u7684\u6700\u76f8\u5173\u5bf9\u8c61\u3002"}}
{"id": "2511.00538", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00538", "abs": "https://arxiv.org/abs/2511.00538", "authors": ["Avi Levy", "Meir Hemmo"], "title": "Quantum Field Theory and the Measurement Problem in Quantum Mechanics", "comment": "41 pages", "summary": "We propose a novel solution to the measurement problem based on quantum field\ntheory and Haag's theorem. According to our proposal in elementary interactions\nwhere the particles content is changed, the temporal evolution is non unitary.\nThese interactions which are almost instantaneous lead to a genuine stochastic\nselection of an outcome subspace that has a distinct particles content but can\nbe a superposition of momentum states, spin states, etc.", "AI": {"tldr": "\u57fa\u4e8e\u91cf\u5b50\u573a\u8bba\u548cHaag\u5b9a\u7406\u63d0\u51fa\u6d4b\u91cf\u95ee\u9898\u7684\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u8ba4\u4e3a\u5728\u6539\u53d8\u7c92\u5b50\u5185\u5bb9\u7684\u57fa\u672c\u76f8\u4e92\u4f5c\u7528\u4e2d\uff0c\u65f6\u95f4\u6f14\u5316\u662f\u975e\u5e7a\u6b63\u7684\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u529b\u5b66\u4e2d\u7684\u6d4b\u91cf\u95ee\u9898\uff0c\u4e3a\u6ce2\u51fd\u6570\u574d\u7f29\u63d0\u4f9b\u7269\u7406\u673a\u5236\u89e3\u91ca\u3002", "method": "\u5229\u7528\u91cf\u5b50\u573a\u8bba\u6846\u67b6\u548cHaag\u5b9a\u7406\uff0c\u5206\u6790\u57fa\u672c\u76f8\u4e92\u4f5c\u7528\u4e2d\u7c92\u5b50\u5185\u5bb9\u6539\u53d8\u65f6\u7684\u975e\u5e7a\u6b63\u65f6\u95f4\u6f14\u5316\u8fc7\u7a0b\u3002", "result": "\u53d1\u73b0\u77ac\u65f6\u76f8\u4e92\u4f5c\u7528\u4f1a\u5bfc\u81f4\u5bf9\u5177\u6709\u4e0d\u540c\u7c92\u5b50\u5185\u5bb9\u4f46\u53ef\u4ee5\u662f\u52a8\u91cf\u6001\u3001\u81ea\u65cb\u6001\u7b49\u53e0\u52a0\u7684\u7ed3\u679c\u5b50\u7a7a\u95f4\u7684\u771f\u6b63\u968f\u673a\u9009\u62e9\u3002", "conclusion": "\u6d4b\u91cf\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u57fa\u672c\u76f8\u4e92\u4f5c\u7528\u4e2d\u7684\u975e\u5e7a\u6b63\u6f14\u5316\u5f97\u5230\u89e3\u51b3\uff0c\u6ce2\u51fd\u6570\u574d\u7f29\u662f\u8fd9\u4e9b\u77ac\u65f6\u76f8\u4e92\u4f5c\u7528\u7684\u7ed3\u679c\u3002"}}
{"id": "2511.00051", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00051", "abs": "https://arxiv.org/abs/2511.00051", "authors": ["Da Chang", "Peng Xue", "Yu Li", "Yongxiang Liu", "Pengxiang Xu", "Shixun Zhang"], "title": "Calibrating and Rotating: A Unified Framework for Weight Conditioning in PEFT", "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods are crucial for adapting large\npre-trained models. Among these, LoRA is considered a foundational approach.\nBuilding on this, the influential DoRA method enhances performance by\ndecomposing weight updates into magnitude and direction. However, its\nunderlying mechanism remains unclear, and it introduces significant\ncomputational overhead. In this work, we first identify that DoRA's success\nstems from its capacity to increase the singular value entropy of the weight\nupdate matrix, which promotes a more uniform update distribution akin to full\nfine-tuning. We then reformulate DoRA into a mathematically equivalent and more\nefficient matrix form, revealing it as a learnable weight conditioning method.\nBased on this insight, we propose a unified framework for designing advanced\nPEFT methods by exploring two orthogonal dimensions: the architectural\nplacement and the transformation type of the conditioning matrix. Within this\nframework, we introduce two novel methods: (1) \\textbf{Pre-Diag}, which applies\na diagonal conditioning matrix before the LoRA update to efficiently calibrate\nthe pre-trained weights, thereby enhancing performance while reducing training\ntime; and (2) \\textbf{S}kewed \\textbf{O}rthogonal \\textbf{R}otation\n\\textbf{A}daptation (\\textbf{SORA}), which employs a parameter-efficient\northogonal rotation to perform a more powerful, norm-preserving transformation\nof the feature space. Extensive experiments on natural language understanding\nand generation tasks demonstrate that our proposed methods achieve superior\nperformance and efficiency compared to both LoRA and DoRA. The code is\navailable at https://github.com/MaeChd/SORA.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86DoRA\u65b9\u6cd5\u7684\u6210\u529f\u673a\u5236\uff0c\u53d1\u73b0\u5176\u901a\u8fc7\u589e\u52a0\u6743\u91cd\u66f4\u65b0\u77e9\u9635\u7684\u5947\u5f02\u503c\u71b5\u6765\u63d0\u5347\u6027\u80fd\u3002\u4f5c\u8005\u5c06DoRA\u91cd\u65b0\u8868\u8ff0\u4e3a\u66f4\u9ad8\u6548\u7684\u77e9\u9635\u5f62\u5f0f\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684PEFT\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86Pre-Diag\u548cSORA\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8eLoRA\u548cDoRA\u3002", "motivation": "DoRA\u65b9\u6cd5\u867d\u7136\u6027\u80fd\u4f18\u8d8a\u4f46\u673a\u5236\u4e0d\u660e\u786e\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u63ed\u793a\u5176\u6210\u529f\u539f\u7406\u5e76\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u3002", "method": "1) \u5206\u6790DoRA\u673a\u5236\uff0c\u53d1\u73b0\u5176\u901a\u8fc7\u589e\u52a0\u5947\u5f02\u503c\u71b5\u5b9e\u73b0\u66f4\u5747\u5300\u7684\u66f4\u65b0\u5206\u5e03\uff1b2) \u5c06DoRA\u91cd\u65b0\u8868\u8ff0\u4e3a\u53ef\u5b66\u4e60\u7684\u6743\u91cd\u6761\u4ef6\u5316\u65b9\u6cd5\uff1b3) \u63d0\u51fa\u7edf\u4e00PEFT\u6846\u67b6\uff0c\u63a2\u7d22\u67b6\u6784\u653e\u7f6e\u548c\u53d8\u6362\u7c7b\u578b\u4e24\u4e2a\u7ef4\u5ea6\uff1b4) \u5f15\u5165Pre-Diag\u548cSORA\u4e24\u79cd\u65b0\u65b9\u6cd5\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u4f18\u4e8eLoRA\u548cDoRA\u3002", "conclusion": "\u901a\u8fc7\u63ed\u793aDoRA\u7684\u673a\u5236\u5e76\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\uff0c\u6210\u529f\u5f00\u53d1\u51fa\u66f4\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684PEFT\u65b9\u6cd5\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u601d\u8def\u3002"}}
{"id": "2511.00778", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00778", "abs": "https://arxiv.org/abs/2511.00778", "authors": ["Alexey Dubinsky"], "title": "Long-lived modes and grey-body factors of massive fields in quantum-corrected (Hayward) black holes", "comment": null, "summary": "We study the dynamics of a massive scalar field in the background of the\nHayward black hole, which can be interpreted both as a regular spacetime and as\nan effective geometry arising from Asymptotically Safe gravity. The quasinormal\nspectrum and grey-body factors are computed using the WKB method with Pad\\'e\nimprovements and confirmed through time-domain integration followed by Prony\nanalysis. We find that the mass of the field significantly suppresses the\ndamping rate of quasinormal oscillations, giving rise to long-lived modes that\ncontinuously approach arbitrarily long-lived states (quasi-resonances) at\ncertain critical field masses. In the time domain, the standard exponentially\ndecaying ringdown is replaced by oscillatory tails with a power-law envelope.\nThe corresponding grey-body factors reveal a pronounced shift of the\ntransmission peak toward higher frequencies and a suppression of the\nlow-frequency part of the spectrum. Finally, we show that the correspondence\nbetween quasinormal modes and grey-body factors remains valid for massive\nfields, being highly accurate for large multipole numbers and gradually losing\nprecision as either the field mass increases or the multipole number decreases.", "AI": {"tldr": "\u7814\u7a76\u6d77\u6c83\u5fb7\u9ed1\u6d1e\u80cc\u666f\u4e0b\u5927\u8d28\u91cf\u6807\u91cf\u573a\u7684\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u573a\u8d28\u91cf\u663e\u8457\u6291\u5236\u51c6\u6b63\u89c4\u632f\u8361\u7684\u8870\u51cf\u7387\uff0c\u4ea7\u751f\u957f\u5bff\u547d\u6a21\u5f0f\uff0c\u5e76\u5728\u7279\u5b9a\u4e34\u754c\u8d28\u91cf\u4e0b\u63a5\u8fd1\u51c6\u5171\u632f\u6001\u3002", "motivation": "\u63a2\u7d22\u6d77\u6c83\u5fb7\u9ed1\u6d1e\uff08\u65e2\u53ef\u89e3\u91ca\u4e3a\u89c4\u5219\u65f6\u7a7a\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u6e10\u8fd1\u5b89\u5168\u5f15\u529b\u7684\u6709\u6548\u51e0\u4f55\uff09\u4e2d\u5927\u8d28\u91cf\u6807\u91cf\u573a\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u7279\u522b\u662f\u51c6\u6b63\u89c4\u6a21\u548c\u7070\u4f53\u56e0\u5b50\u7684\u7279\u6027\u3002", "method": "\u4f7f\u7528\u5e26Pad\u00e9\u6539\u8fdb\u7684WKB\u65b9\u6cd5\u8ba1\u7b97\u51c6\u6b63\u89c4\u8c31\u548c\u7070\u4f53\u56e0\u5b50\uff0c\u5e76\u901a\u8fc7\u65f6\u57df\u79ef\u5206\u548cProny\u5206\u6790\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u573a\u8d28\u91cf\u663e\u8457\u6291\u5236\u51c6\u6b63\u89c4\u632f\u8361\u7684\u8870\u51cf\u7387\uff0c\u4ea7\u751f\u957f\u5bff\u547d\u6a21\u5f0f\uff1b\u65f6\u57df\u4e2d\u6807\u51c6\u6307\u6570\u8870\u51cf\u88ab\u5177\u6709\u5e42\u5f8b\u5305\u7edc\u7684\u632f\u8361\u5c3e\u90e8\u53d6\u4ee3\uff1b\u7070\u4f53\u56e0\u5b50\u663e\u793a\u4f20\u8f93\u5cf0\u5411\u9ad8\u9891\u79fb\u52a8\u4e14\u4f4e\u9891\u90e8\u5206\u88ab\u6291\u5236\u3002", "conclusion": "\u51c6\u6b63\u89c4\u6a21\u4e0e\u7070\u4f53\u56e0\u5b50\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u5bf9\u5927\u8d28\u91cf\u573a\u4ecd\u7136\u6709\u6548\uff0c\u5bf9\u4e8e\u5927\u591a\u6781\u6570\u5177\u6709\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u968f\u7740\u573a\u8d28\u91cf\u589e\u52a0\u6216\u591a\u6781\u6570\u51cf\u5c11\u800c\u9010\u6e10\u5931\u53bb\u7cbe\u5ea6\u3002"}}
{"id": "2511.00577", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.00577", "abs": "https://arxiv.org/abs/2511.00577", "authors": ["Tamoghna Ray", "Katha Ganguly", "Dario Poletti", "Manas Kulkarni", "Bijay Kumar Agarwalla"], "title": "Quantum dynamics in lattices in presence of bulk dephasing and a localized source", "comment": "11 pages, 5 figures", "summary": "The aim of this work is to study the dynamics of quantum systems subjected to\na localized fermionic source in the presence of bulk dephasing. We consider two\nclasses of one-dimensional lattice systems: (i) a non-interacting lattice with\nnearest-neighbor and beyond, i.e., long-ranged (power-law) hopping, and (ii) a\nlattice that is interacting via short-range interactions modeled by a fermionic\nquartic Hamiltonian. We study the evolution of the local density profile\n$n_i(t)$ within the system and the growth of the total particle number $N(t)$\nin it. For case (i), we provide analytical insights into the dynamics of the\nnearest-neighbor model using an adiabatic approximation, which relies on\nassuming faster relaxation of coherences of the single particle density matrix.\nFor case (ii), we perform numerical computations using the time-evolving block\ndecimation (TEBD) algorithm and analyze the density profile and the growth\nexponent in $N(t)$. Our detailed study reveals an interesting interplay between\nHamiltonian dynamics and various environmentally induced mechanisms in open\nquantum systems, such as local source and bulk dephasing. It brings out rich\ndynamics, including universal dynamical scaling and anomalous behavior across\nvarious time scales and is of relevance to various quantum simulation\nplatforms.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u5c40\u57df\u8d39\u7c73\u5b50\u6e90\u548c\u4f53\u76f8\u9000\u76f8\u5e72\u7684\u91cf\u5b50\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u5206\u6790\u975e\u76f8\u4e92\u4f5c\u7528\u548c\u76f8\u4e92\u4f5c\u7528\u4e24\u79cd\u4e00\u7ef4\u6676\u683c\u7cfb\u7edf\u4e2d\u7684\u5bc6\u5ea6\u5206\u5e03\u548c\u7c92\u5b50\u6570\u589e\u957f\u3002", "motivation": "\u63a2\u7d22\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e0e\u73af\u5883\u8bf1\u5bfc\u673a\u5236\uff08\u5c40\u57df\u6e90\u548c\u4f53\u76f8\u9000\u76f8\u5e72\uff09\u5728\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63ed\u793a\u4e30\u5bcc\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u5bf9\u975e\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4f7f\u7528\u7edd\u70ed\u8fd1\u4f3c\u5206\u6790\uff0c\u5bf9\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4f7f\u7528TEBD\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\uff0c\u7814\u7a76\u5bc6\u5ea6\u5206\u5e03\u548c\u589e\u957f\u6307\u6570\u3002", "result": "\u53d1\u73b0\u666e\u9002\u52a8\u529b\u5b66\u6807\u5ea6\u548c\u5f02\u5e38\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u4e30\u5bcc\u52a8\u529b\u5b66\u7279\u5f81\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5404\u79cd\u91cf\u5b50\u6a21\u62df\u5e73\u53f0\u63d0\u4f9b\u4e86\u76f8\u5173\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e0e\u73af\u5883\u673a\u5236\u4e4b\u95f4\u6709\u8da3\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2511.00052", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00052", "abs": "https://arxiv.org/abs/2511.00052", "authors": ["Federico Formica", "Stefano Gregis", "Aurora Francesca Zanenga", "Andrea Rota", "Mark Lawford", "Claudio Menghi"], "title": "Feature-Guided Analysis of Neural Networks: A Replication Study", "comment": null, "summary": "Understanding why neural networks make certain decisions is pivotal for their\nuse in safety-critical applications. Feature-Guided Analysis (FGA) extracts\nslices of neural networks relevant to their tasks. Existing feature-guided\napproaches typically monitor the activation of the neural network neurons to\nextract the relevant rules. Preliminary results are encouraging and demonstrate\nthe feasibility of this solution by assessing the precision and recall of\nFeature-Guided Analysis on two pilot case studies. However, the applicability\nin industrial contexts needs additional empirical evidence.\n  To mitigate this need, this paper assesses the applicability of FGA on a\nbenchmark made by the MNIST and LSC datasets. We assessed the effectiveness of\nFGA in computing rules that explain the behavior of the neural network. Our\nresults show that FGA has a higher precision on our benchmark than the results\nfrom the literature. We also evaluated how the selection of the neural network\narchitecture, training, and feature selection affect the effectiveness of FGA.\nOur results show that the selection significantly affects the recall of FGA,\nwhile it has a negligible impact on its precision.", "AI": {"tldr": "\u8bc4\u4f30\u7279\u5f81\u5f15\u5bfc\u5206\u6790\uff08FGA\uff09\u5728MNIST\u548cLSC\u6570\u636e\u96c6\u57fa\u51c6\u4e0a\u7684\u9002\u7528\u6027\uff0c\u7ed3\u679c\u663e\u793aFGA\u5728\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u6587\u732e\u7ed3\u679c\uff0c\u7f51\u7edc\u67b6\u6784\u548c\u7279\u5f81\u9009\u62e9\u5bf9\u53ec\u56de\u7387\u6709\u663e\u8457\u5f71\u54cd\u4f46\u5bf9\u7cbe\u5ea6\u5f71\u54cd\u53ef\u5ffd\u7565", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u539f\u56e0\u5bf9\u5176\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u4f7f\u7528\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u7279\u5f81\u5f15\u5bfc\u65b9\u6cd5\u9700\u8981\u66f4\u591a\u5de5\u4e1a\u73af\u5883\u4e0b\u7684\u5b9e\u8bc1\u8bc1\u636e", "method": "\u5728MNIST\u548cLSC\u6570\u636e\u96c6\u57fa\u51c6\u4e0a\u8bc4\u4f30FGA\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3001\u8bad\u7ec3\u548c\u7279\u5f81\u9009\u62e9\u5bf9FGA\u6548\u679c\u7684\u5f71\u54cd", "result": "FGA\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u7cbe\u5ea6\u9ad8\u4e8e\u6587\u732e\u7ed3\u679c\uff0c\u7f51\u7edc\u67b6\u6784\u548c\u7279\u5f81\u9009\u62e9\u5bf9FGA\u53ec\u56de\u7387\u6709\u663e\u8457\u5f71\u54cd\u4f46\u5bf9\u7cbe\u5ea6\u5f71\u54cd\u5f88\u5c0f", "conclusion": "FGA\u5728\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u884c\u4e3a\u65b9\u9762\u5177\u6709\u5b9e\u7528\u6027\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u9009\u62e9\u7f51\u7edc\u67b6\u6784\u548c\u7279\u5f81\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u53ec\u56de\u7387"}}
{"id": "2511.00784", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.00784", "abs": "https://arxiv.org/abs/2511.00784", "authors": ["Zhong-Wu Xia", "Sheng Long", "Huajie Gong", "Qiyuan Pan", "Jiliang Jing"], "title": "Scalar perturbation around a rotating Kalb-Ramond BTZ black hole", "comment": "13 pages, 4 figures", "summary": "We investigate the scalar perturbation of a newly proposed Kalb-Ramond (KR)\nBTZ-like black hole. After the separation of variables for the Klein-Gordon\nequation, we find that the radial part reduces to the general Heun equation.\nUsing the Heun function, we compute quasinormal modes (QNMs) subject to generic\nRobin boundary conditions, which shows that the KR parameter substantially\nmodifies the QNM spectrum and only the fundamental mode on the left branch has\nan instability. To ascertain whether the instability is superradiant, we\nfurther analyze how the KR field changes the energy and angular momentum\nfluxes. Our results show that the KR parameter shifts the threshold and the\nrange of the Robin coupling parameter where the superradiance occurs,\nunderscoring the importance of the KR field in modeling black hole\nperturbations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Kalb-Ramond BTZ\u7c7b\u9ed1\u6d1e\u7684\u6807\u91cf\u6270\u52a8\uff0c\u53d1\u73b0KR\u53c2\u6570\u663e\u8457\u6539\u53d8\u51c6\u6b63\u89c4\u6a21\u8c31\uff0c\u5e76\u8bc6\u522b\u51fa\u5de6\u5206\u652f\u57fa\u6a21\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76KR\u573a\u5982\u4f55\u5f71\u54cd\u9ed1\u6d1e\u6270\u52a8\uff0c\u7279\u522b\u662f\u5bf9QNM\u8c31\u548c\u8d85\u8f90\u5c04\u73b0\u8c61\u7684\u4fee\u6539\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u5206\u79bb\u53d8\u91cf\u6cd5\u5c06Klein-Gordon\u65b9\u7a0b\u5f84\u5411\u90e8\u5206\u5316\u4e3a\u5e7f\u4e49Heun\u65b9\u7a0b\uff0c\u4f7f\u7528Heun\u51fd\u6570\u8ba1\u7b97\u51c6\u6b63\u89c4\u6a21\uff0c\u5e76\u5206\u6790\u80fd\u91cf\u548c\u89d2\u52a8\u91cf\u901a\u91cf\u3002", "result": "KR\u53c2\u6570\u663e\u8457\u4fee\u6539QNM\u8c31\uff0c\u5de6\u5206\u652f\u57fa\u6a21\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e14KR\u573a\u6539\u53d8\u4e86\u8d85\u8f90\u5c04\u53d1\u751f\u7684\u9608\u503c\u548cRobin\u8026\u5408\u53c2\u6570\u8303\u56f4\u3002", "conclusion": "KR\u573a\u5728\u9ed1\u6d1e\u6270\u52a8\u5efa\u6a21\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u80fd\u591f\u663e\u8457\u5f71\u54cdQNM\u8c31\u548c\u8d85\u8f90\u5c04\u7279\u6027\u3002"}}
{"id": "2511.00644", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00644", "abs": "https://arxiv.org/abs/2511.00644", "authors": ["Nicol\u00f2 Piccione"], "title": "Principle of Minimal Heating for Collapse and Hybrid Gravitational Models", "comment": "4 pages plus appendices, no figures", "summary": "Energy nonconservation is a prominent, testable prediction of collapse and\nhybrid classical-quantum gravitational models. Without smearing of certain\noperators, the associated heating (or energy increase) rate diverges, yet the\nsmearing distribution is arbitrary and, on scales much larger than the smearing\nlength $r_C$, much of the phenomenology is expected to be independent of this\nchoice. We propose to resolve this arbitrariness by a simple principle: for a\nfixed $r_C$, select the distribution that minimizes the heating rate.\nConceptually, this should identify the minimal deviation from standard quantum\nmechanics and provide models that, once experimentally refuted, would strongly\ndisfavor all variants with different distributions. We apply this approach to\nthe most investigated collapse models: GRW, CSL, and DP. Notably, the Gaussian\nis optimal only for the GRW case. Finally, we apply it to the Tilloy-Di\\'osi\nhybrid classical-quantum model of Newtonian gravity, leading to the minimally\ndeviating variant of it. This version of the model is entirely determined by\nonly one free parameter (the smearing length $r_C$) and, if experimentally\nrefuted, would strongly disfavor any other version of it.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u6700\u5c0f\u5316\u52a0\u70ed\u7387\u6765\u9009\u62e9\u584c\u7f29\u6a21\u578b\u4e2d\u7684\u5e73\u6ed1\u5206\u5e03\uff0c\u4ee5\u6d88\u9664\u5206\u5e03\u9009\u62e9\u7684\u4efb\u610f\u6027\uff0c\u5e76\u5e94\u7528\u4e8eGRW\u3001CSL\u3001DP\u7b49\u584c\u7f29\u6a21\u578b\u53caTilloy-Di\u00f3si\u7ecf\u5178-\u91cf\u5b50\u6df7\u5408\u5f15\u529b\u6a21\u578b\u3002", "motivation": "\u80fd\u91cf\u4e0d\u5b88\u6052\u662f\u584c\u7f29\u548c\u7ecf\u5178-\u91cf\u5b50\u6df7\u5408\u5f15\u529b\u6a21\u578b\u7684\u53ef\u6d4b\u8bd5\u9884\u6d4b\uff0c\u4f46\u76f8\u5173\u7684\u52a0\u70ed\u7387\u5728\u672a\u5e73\u6ed1\u67d0\u4e9b\u7b97\u5b50\u65f6\u4f1a\u53d1\u6563\uff0c\u800c\u5e73\u6ed1\u5206\u5e03\u7684\u9009\u62e9\u662f\u4efb\u610f\u7684\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6700\u5c0f\u5316\u52a0\u70ed\u7387\u6765\u6d88\u9664\u8fd9\u79cd\u4efb\u610f\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u539f\u5219\uff1a\u5bf9\u4e8e\u56fa\u5b9a\u7684\u5e73\u6ed1\u957f\u5ea6r_C\uff0c\u9009\u62e9\u4f7f\u52a0\u70ed\u7387\u6700\u5c0f\u5316\u7684\u5206\u5e03\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u8bc6\u522b\u4e0e\u6807\u51c6\u91cf\u5b50\u529b\u5b66\u7684\u6700\u5c0f\u504f\u5dee\uff0c\u5e76\u4e3a\u5b9e\u9a8c\u9a8c\u8bc1\u63d0\u4f9b\u57fa\u7840\u3002", "result": "\u5e94\u7528\u8be5\u65b9\u6cd5\u53d1\u73b0\u9ad8\u65af\u5206\u5e03\u4ec5\u5728GRW\u60c5\u51b5\u4e0b\u662f\u6700\u4f18\u7684\u3002\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eTilloy-Di\u00f3si\u725b\u987f\u5f15\u529b\u6df7\u5408\u6a21\u578b\uff0c\u5f97\u5230\u4e86\u8be5\u6a21\u578b\u7684\u6700\u5c0f\u504f\u5dee\u7248\u672c\u3002", "conclusion": "\u8be5\u6700\u5c0f\u504f\u5dee\u7248\u672c\u7684\u6a21\u578b\u5b8c\u5168\u7531\u5355\u4e00\u81ea\u7531\u53c2\u6570\uff08\u5e73\u6ed1\u957f\u5ea6r_C\uff09\u786e\u5b9a\uff0c\u5982\u679c\u88ab\u5b9e\u9a8c\u8bc1\u4f2a\uff0c\u5c06\u5f3a\u70c8\u4e0d\u5229\u4e8e\u8be5\u6a21\u578b\u7684\u5176\u4ed6\u7248\u672c\u3002"}}
{"id": "2511.00053", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00053", "abs": "https://arxiv.org/abs/2511.00053", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhichao Chen", "Tianqiao Liu", "Shuting He", "Zhixuan Chu", "Qingsong Wen", "Haoxuan Li", "Zhouchen Lin"], "title": "Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models", "comment": null, "summary": "The design of training objective is central to training time-series\nforecasting models. Existing training objectives such as mean squared error\nmostly treat each future step as an independent, equally weighted task, which\nwe found leading to the following two issues: (1) overlook the label\nautocorrelation effect among future steps, leading to biased training\nobjective; (2) fail to set heterogeneous task weights for different forecasting\ntasks corresponding to varying future steps, limiting the forecasting\nperformance. To fill this gap, we propose a novel quadratic-form weighted\ntraining objective, addressing both of the issues simultaneously. Specifically,\nthe off-diagonal elements of the weighting matrix account for the label\nautocorrelation effect, whereas the non-uniform diagonals are expected to match\nthe most preferable weights of the forecasting tasks with varying future steps.\nTo achieve this, we propose a Quadratic Direct Forecast (QDF) learning\nalgorithm, which trains the forecast model using the adaptively updated\nquadratic-form weighting matrix. Experiments show that our QDF effectively\nimproves performance of various forecast models, achieving state-of-the-art\nresults. Code is available at https://anonymous.4open.science/r/QDF-8937.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8c\u6b21\u5f62\u5f0f\u52a0\u6743\u8bad\u7ec3\u76ee\u6807\uff0c\u901a\u8fc7\u8003\u8651\u6807\u7b7e\u81ea\u76f8\u5173\u6548\u5e94\u548c\u8bbe\u7f6e\u5f02\u8d28\u4efb\u52a1\u6743\u91cd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u8bad\u7ec3\u76ee\u6807\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u76ee\u6807\uff08\u5982\u5747\u65b9\u8bef\u5dee\uff09\u5c06\u6bcf\u4e2a\u672a\u6765\u6b65\u9aa4\u89c6\u4e3a\u72ec\u7acb\u3001\u7b49\u6743\u91cd\u7684\u4efb\u52a1\uff0c\u8fd9\u5bfc\u81f4\u4e24\u4e2a\u95ee\u9898\uff1a(1) \u5ffd\u7565\u672a\u6765\u6b65\u9aa4\u95f4\u7684\u6807\u7b7e\u81ea\u76f8\u5173\u6548\u5e94\uff0c\u9020\u6210\u8bad\u7ec3\u76ee\u6807\u504f\u5dee\uff1b(2) \u65e0\u6cd5\u4e3a\u4e0d\u540c\u9884\u6d4b\u6b65\u9aa4\u8bbe\u7f6e\u5f02\u8d28\u4efb\u52a1\u6743\u91cd\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e8c\u6b21\u76f4\u63a5\u9884\u6d4b(QDF)\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u66f4\u65b0\u7684\u4e8c\u6b21\u5f62\u5f0f\u52a0\u6743\u77e9\u9635\u8fdb\u884c\u8bad\u7ec3\u3002\u52a0\u6743\u77e9\u9635\u7684\u975e\u5bf9\u89d2\u7ebf\u5143\u7d20\u8003\u8651\u6807\u7b7e\u81ea\u76f8\u5173\u6548\u5e94\uff0c\u975e\u5747\u5300\u5bf9\u89d2\u7ebf\u5339\u914d\u4e0d\u540c\u9884\u6d4b\u6b65\u9aa4\u7684\u6700\u4f18\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eQDF\u6709\u6548\u63d0\u5347\u4e86\u5404\u79cd\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e8c\u6b21\u5f62\u5f0f\u52a0\u6743\u8bad\u7ec3\u76ee\u6807\u80fd\u591f\u540c\u65f6\u89e3\u51b3\u6807\u7b7e\u81ea\u76f8\u5173\u6548\u5e94\u548c\u5f02\u8d28\u4efb\u52a1\u6743\u91cd\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.00825", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.00825", "abs": "https://arxiv.org/abs/2511.00825", "authors": ["Hanif Golchin", "Hamid R. Bakhtiarizadeh", "Mohammad Reza Mehdizadeh"], "title": "Wormhole geometries in Einstein-aether theory", "comment": "25 pages", "summary": "We perform the first study of traversable wormhole solutions in the\nbackground of Einstein-Aether theory. We show that the field equations admit\nsome wormhole geometries, for several combinations of values of the aether\ncoupling constants. We investigating the null and weak energy conditions for\nwormhole solutions with three types of the worm hole shape function. In\ncontrast to Einstein gravity, we find that by choosing adequate values for the\nparameters of the models, wormhole geometries respect the energy conditions at\nthe wormhole throat and also throughout the whole space. Satisfaction of these\nenergy conditions led to some constraints on the value of the Einstein-Aether\ntheory. Comparing these constraints with those previously obtained from\ntheoretical and observational considerations, we find that the satisfaction of\nenergy condition put more limitations on the values of the Einstein-Aether\ncouplings.", "AI": {"tldr": "\u9996\u6b21\u5728\u7231\u56e0\u65af\u5766-\u4ee5\u592a\u7406\u8bba\u80cc\u666f\u4e0b\u7814\u7a76\u53ef\u7a7f\u8d8a\u866b\u6d1e\u89e3\uff0c\u53d1\u73b0\u67d0\u4e9b\u53c2\u6570\u7ec4\u5408\u4e0b\u5b58\u5728\u866b\u6d1e\u51e0\u4f55\u7ed3\u6784\uff0c\u4e14\u80fd\u540c\u65f6\u6ee1\u8db3\u96f6\u80fd\u91cf\u6761\u4ef6\u548c\u5f31\u80fd\u91cf\u6761\u4ef6\u3002", "motivation": "\u63a2\u7d22\u7231\u56e0\u65af\u5766-\u4ee5\u592a\u7406\u8bba\u4e2d\u662f\u5426\u5b58\u5728\u53ef\u7a7f\u8d8a\u866b\u6d1e\u89e3\uff0c\u5e76\u7814\u7a76\u8fd9\u4e9b\u89e3\u662f\u5426\u80fd\u591f\u6ee1\u8db3\u80fd\u91cf\u6761\u4ef6\uff0c\u8fd9\u662f\u4f20\u7edf\u7231\u56e0\u65af\u5766\u5f15\u529b\u7406\u8bba\u4e2d\u96be\u4ee5\u5b9e\u73b0\u7684\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u6c42\u89e3\u7231\u56e0\u65af\u5766-\u4ee5\u592a\u7406\u8bba\u7684\u573a\u65b9\u7a0b\uff0c\u5206\u6790\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u866b\u6d1e\u5f62\u72b6\u51fd\u6570\u4e0b\u7684\u96f6\u80fd\u91cf\u6761\u4ef6\u548c\u5f31\u80fd\u91cf\u6761\u4ef6\u3002", "result": "\u53d1\u73b0\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u53c2\u6570\uff0c\u866b\u6d1e\u51e0\u4f55\u7ed3\u6784\u80fd\u591f\u5728\u866b\u6d1e\u5589\u90e8\u53ca\u6574\u4e2a\u7a7a\u95f4\u90fd\u6ee1\u8db3\u80fd\u91cf\u6761\u4ef6\uff0c\u8fd9\u4e3a\u7231\u56e0\u65af\u5766-\u4ee5\u592a\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "\u80fd\u91cf\u6761\u4ef6\u7684\u6ee1\u8db3\u5bf9\u7231\u56e0\u65af\u5766-\u4ee5\u592a\u8026\u5408\u53c2\u6570\u65bd\u52a0\u4e86\u6bd4\u5148\u524d\u7406\u8bba\u548c\u89c2\u6d4b\u8003\u8651\u66f4\u4e25\u683c\u7684\u9650\u5236\uff0c\u8868\u660e\u8be5\u7406\u8bba\u5728\u63cf\u8ff0\u866b\u6d1e\u51e0\u4f55\u65b9\u9762\u5177\u6709\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2511.00842", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00842", "abs": "https://arxiv.org/abs/2511.00842", "authors": ["David Amaro-Alcal\u00e1"], "title": "Kostant relation in filtered randomized benchmarking for passive bosonic devices", "comment": "10 pages, 0 figures, 2 tables", "summary": "We reduce the cost of the current bosonic randomized benchmarking proposal.\nFirst, we introduce a filter function using immanants. With this filter, we\navoid the need to compute Clebsch-Gordan coefficients. Our filter uses the same\ndata as the original, although we propose a distinct data collection process\nthat requires a single type of measurement. Furthermore, we argue that weak\ncoherent states and intensity measurements are sufficient to proceed with the\ncharacterization. Our work could then allow simpler platforms to be\ncharacterized and simplify the data analysis process.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528immanants\u7684\u6ee4\u6ce2\u5668\u51fd\u6570\uff0c\u964d\u4f4e\u4e86\u73bb\u8272\u5b50\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u7684\u6210\u672c\uff0c\u907f\u514d\u4e86Clebsch-Gordan\u7cfb\u6570\u7684\u8ba1\u7b97\uff0c\u5e76\u7b80\u5316\u4e86\u6570\u636e\u6536\u96c6\u548c\u5206\u6790\u8fc7\u7a0b\u3002", "motivation": "\u964d\u4f4e\u5f53\u524d\u73bb\u8272\u5b50\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6848\u7684\u6210\u672c\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u66f4\u7b80\u5355\u7684\u5e73\u53f0\u4e0a\u5b9e\u73b0\uff0c\u5e76\u7b80\u5316\u6570\u636e\u5206\u6790\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u57fa\u4e8eimmanants\u7684\u6ee4\u6ce2\u5668\u51fd\u6570\uff0c\u63d0\u51fa\u4ec5\u9700\u5355\u4e00\u7c7b\u578b\u6d4b\u91cf\u7684\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5f31\u76f8\u5e72\u6001\u548c\u5f3a\u5ea6\u6d4b\u91cf\u8fdb\u884c\u8868\u5f81\u3002", "result": "\u65b0\u65b9\u6cd5\u907f\u514d\u4e86Clebsch-Gordan\u7cfb\u6570\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u4f7f\u7528\u4e0e\u539f\u59cb\u65b9\u6cd5\u76f8\u540c\u7684\u6570\u636e\u4f46\u7b80\u5316\u4e86\u6570\u636e\u6536\u96c6\uff0c\u80fd\u591f\u4f7f\u7528\u66f4\u7b80\u5355\u7684\u6d4b\u91cf\u8bbe\u5907\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4f7f\u5f97\u66f4\u7b80\u5355\u7684\u5e73\u53f0\u80fd\u591f\u8fdb\u884c\u8868\u5f81\uff0c\u5e76\u7b80\u5316\u4e86\u6570\u636e\u5206\u6790\u8fc7\u7a0b\uff0c\u4e3a\u73bb\u8272\u5b50\u7cfb\u7edf\u7684\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00054", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00054", "abs": "https://arxiv.org/abs/2511.00054", "authors": ["Gio Huh", "Dhruv Sheth", "Rayhan Zirvi", "Frank Xiao"], "title": "SpatialTraceGen: High-Fidelity Traces for Efficient VLM Spatial Reasoning Distillation", "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop on Efficient Reasoning", "summary": "While Vision-Language Models (VLMs) excel in many areas, they struggle with\ncomplex spatial reasoning, which requires problem decomposition and strategic\ntool use. Fine-tuning smaller, more deployable models offers an efficient path\nto strong performance, but this is hampered by a major bottleneck: the absence\nof high-quality, step-by-step reasoning data. To address this data-efficiency\ngap, we introduce SpatialTraceGen, a framework to distill the reasoning\nprocesses of a large teacher model into a high-quality dataset of multi-hop,\nmulti-tool reasoning traces. A key innovation is our automated Verifier, which\nscalably ensures the fidelity of each reasoning step, providing a\ncost-effective alternative to manual human annotation. On the CLEVR-Humans\nbenchmark, this verifier-guided process improves the average quality score of\ntraces by 17\\% while reducing quality variance by over 40\\%. SpatialTraceGen\ndelivers a dataset of expert traces, providing the structured, step-by-step\nexamples of tool use necessary for effective fine-tuning and sample-efficient\noffline reinforcement learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86SpatialTraceGen\u6846\u67b6\uff0c\u901a\u8fc7\u84b8\u998f\u5927\u578b\u6559\u5e08\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u591a\u6b65\u9aa4\u3001\u591a\u5de5\u5177\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u95ee\u9898\u5206\u89e3\u548c\u7b56\u7565\u6027\u5de5\u5177\u4f7f\u7528\u3002\u5fae\u8c03\u5c0f\u578b\u53ef\u90e8\u7f72\u6a21\u578b\u662f\u9ad8\u6548\u8def\u5f84\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u5206\u6b65\u63a8\u7406\u6570\u636e\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002", "method": "\u5f00\u53d1SpatialTraceGen\u6846\u67b6\uff0c\u4ece\u5927\u578b\u6559\u5e08\u6a21\u578b\u84b8\u998f\u63a8\u7406\u8fc7\u7a0b\u751f\u6210\u591a\u8df3\u3001\u591a\u5de5\u5177\u63a8\u7406\u8f68\u8ff9\u3002\u5173\u952e\u521b\u65b0\u662f\u81ea\u52a8\u5316\u9a8c\u8bc1\u5668\uff0c\u53ef\u6269\u5c55\u5730\u786e\u4fdd\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u7684\u4fdd\u771f\u5ea6\uff0c\u66ff\u4ee3\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u3002", "result": "\u5728CLEVR-Humans\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u8fc7\u7a0b\u4f7f\u8f68\u8ff9\u5e73\u5747\u8d28\u91cf\u5f97\u5206\u63d0\u9ad817%\uff0c\u8d28\u91cf\u65b9\u5dee\u964d\u4f4e\u8d85\u8fc740%\u3002", "conclusion": "SpatialTraceGen\u63d0\u4f9b\u4e86\u4e13\u5bb6\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u4e3a\u6709\u6548\u5fae\u8c03\u548c\u6837\u672c\u9ad8\u6548\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u5206\u6b65\u5de5\u5177\u4f7f\u7528\u793a\u4f8b\u3002"}}
{"id": "2511.00834", "categories": ["gr-qc", "astro-ph.IM", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.00834", "abs": "https://arxiv.org/abs/2511.00834", "authors": ["Jing-Qi Lai", "Jia-Geng Jiao", "Cai-Ying Shao", "Jun-Xi Shi", "Yu Tian"], "title": "Reconstruction of Black Hole Ringdown Signals with Data Gaps using a Deep-Learning Framework", "comment": "15 pages, 12 figures. Code (research prototype) available at:\n  https://github.com/ljq2088/RingdownGapFilling/tree/master", "summary": "We introduce DenoiseGapFiller (DGF), a deep-learning framework specifically\ndesigned to reconstruct gravitational-wave ringdown signals corrupted by data\ngaps and instrumental noise. DGF employs a dual-branch encoder-decoder\narchitecture, which is fused via mixing layers and Transformer-style blocks.\nTrained end-to-end on synthetic ringdown waveforms with gaps up to 20% of the\nsegment length, DGF can achieve a mean waveform mismatch of 0.002. The residual\namplitudes of the Time-domain shrink by roughly an order of magnitude and the\npower spectral density in the 0.01-1 Hz band is suppressed by 1-2 orders of\nmagnitude, restoring the peak of quasi-normal mode(QNM) in the time-frequency\nrepresentation around 0.01-0.1 Hz. The ability of the model to faithfully\nreconstruct the original signals, which implies milder penalties in the\ndetection evidence and tighter credible regions for parameter estimation, lay a\nfoundation for the following scientific work.", "AI": {"tldr": "\u63d0\u51fa\u4e86DenoiseGapFiller (DGF)\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u91cd\u5efa\u88ab\u6570\u636e\u95f4\u9699\u548c\u4eea\u5668\u566a\u58f0\u7834\u574f\u7684\u5f15\u529b\u6ce2\u73af\u964d\u4fe1\u53f7\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4fe1\u53f7\u91cd\u5efa\u3002", "motivation": "\u5f15\u529b\u6ce2\u73af\u964d\u4fe1\u53f7\u7ecf\u5e38\u53d7\u5230\u6570\u636e\u95f4\u9699\u548c\u4eea\u5668\u566a\u58f0\u7684\u5e72\u6270\uff0c\u5f71\u54cd\u4fe1\u53f7\u68c0\u6d4b\u548c\u53c2\u6570\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u6062\u590d\u8fd9\u4e9b\u88ab\u7834\u574f\u7684\u4fe1\u53f7\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u6df7\u5408\u5c42\u548cTransformer\u98ce\u683c\u5757\u8fdb\u884c\u878d\u5408\uff0c\u5728\u5305\u542b\u9ad8\u8fbe20%\u6570\u636e\u95f4\u9699\u7684\u5408\u6210\u73af\u964d\u6ce2\u5f62\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5b9e\u73b0\u4e86\u5e73\u5747\u6ce2\u5f62\u5931\u914d\u4e3a0.002\uff0c\u65f6\u57df\u6b8b\u5dee\u5e45\u5ea6\u964d\u4f4e\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c0.01-1 Hz\u9891\u6bb5\u7684\u529f\u7387\u8c31\u5bc6\u5ea6\u88ab\u6291\u52361-2\u4e2a\u6570\u91cf\u7ea7\uff0c\u6062\u590d\u4e860.01-0.1 Hz\u9644\u8fd1\u7684\u51c6\u6b63\u5219\u6a21\u5f0f\u5cf0\u503c\u3002", "conclusion": "DGF\u80fd\u591f\u5fe0\u5b9e\u5730\u91cd\u5efa\u539f\u59cb\u4fe1\u53f7\uff0c\u4e3a\u540e\u7eed\u79d1\u5b66\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8fd9\u610f\u5473\u7740\u5728\u68c0\u6d4b\u8bc1\u636e\u4e2d\u60e9\u7f5a\u66f4\u8f7b\uff0c\u53c2\u6570\u4f30\u8ba1\u7684\u53ef\u4fe1\u533a\u57df\u66f4\u7d27\u3002"}}
{"id": "2511.00852", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00852", "abs": "https://arxiv.org/abs/2511.00852", "authors": ["Lajos Di\u00f3si"], "title": "No, classical gravity does not entangle quantized matter fields", "comment": "1.5 pp; comment on arXiv:2510.19714", "summary": "In their recent work [Nature,646,813(2025)], Aziz and Howl claim that\nclassical (unquantized) gravity produces entanglement of quantized matter if\nmatter is treated within quantum field theory which is, no doubt, our ultimate\ntheory to use. However, an elementary quantum field re-calculation of the\nauthors' example shows that there is no entangling effect.", "AI": {"tldr": "\u4f5c\u8005\u53cd\u9a73\u4e86Aziz\u548cHowl\u5173\u4e8e\u7ecf\u5178\u5f15\u529b\u80fd\u4ea7\u751f\u91cf\u5b50\u7ea0\u7f20\u7684\u7ed3\u8bba\uff0c\u901a\u8fc7\u91cf\u5b50\u573a\u8bba\u91cd\u65b0\u8ba1\u7b97\u8868\u660e\u4e0d\u5b58\u5728\u7ea0\u7f20\u6548\u5e94", "motivation": "\u8d28\u7591Aziz\u548cHowl\u5728Nature\u8bba\u6587\u4e2d\u58f0\u79f0\u7ecf\u5178\u5f15\u529b\u80fd\u4ea7\u751f\u91cf\u5b50\u7ea0\u7f20\u7684\u7ed3\u8bba\uff0c\u8ba4\u4e3a\u4ed6\u4eec\u7684\u8ba1\u7b97\u5b58\u5728\u95ee\u9898", "method": "\u4f7f\u7528\u91cf\u5b50\u573a\u8bba\u5bf9\u4f5c\u8005\u793a\u4f8b\u8fdb\u884c\u91cd\u65b0\u8ba1\u7b97\u548c\u5206\u6790", "result": "\u91cd\u65b0\u8ba1\u7b97\u8868\u660e\u4e0d\u5b58\u5728\u7ea0\u7f20\u6548\u5e94\uff0c\u4e0eAziz\u548cHowl\u7684\u7ed3\u8bba\u76f8\u53cd", "conclusion": "\u7ecf\u5178\u5f15\u529b\u4e0d\u4f1a\u4ea7\u751f\u91cf\u5b50\u7ea0\u7f20\uff0cAziz\u548cHowl\u7684\u7ed3\u8bba\u662f\u9519\u8bef\u7684"}}
{"id": "2511.00055", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00055", "abs": "https://arxiv.org/abs/2511.00055", "authors": ["Leonhard Duda", "Khadijeh Alibabaei", "Elena Vollmer", "Leon Klug", "Valentin Kozlov", "Lisana Berberi", "Mishal Benz", "Rebekka Volk", "Juan Pedro Guti\u00e9rrez Hermosillo Muriedas", "Markus G\u00f6tz", "Judith S\u00e1\u00ednz-Pardo D\u00edaz", "\u00c1lvaro L\u00f3pez Garc\u00eda", "Frank Schultmann", "Achim Streit"], "title": "Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches", "comment": null, "summary": "Federated Learning (FL) is an approach for training a shared Machine Learning\n(ML) model with distributed training data and multiple participants. FL allows\nbypassing limitations of the traditional Centralized Machine Learning CL if\ndata cannot be shared or stored centrally due to privacy or technical\nrestrictions -- the participants train the model locally with their training\ndata and do not need to share it among the other participants. This paper\ninvestigates the practical implementation and effectiveness of FL in a\nreal-world scenario, specifically focusing on unmanned aerial vehicle\n(UAV)-based thermal images for common thermal feature detection in urban\nenvironments. The distributed nature of the data arises naturally and makes it\nsuitable for FL applications, as images captured in two German cities are\navailable. This application presents unique challenges due to non-identical\ndistribution and feature characteristics of data captured at both locations.\nThe study makes several key contributions by evaluating FL algorithms in real\ndeployment scenarios rather than simulation. We compare several FL approaches\nwith a centralized learning baseline across key performance metrics such as\nmodel accuracy, training time, communication overhead, and energy usage. This\npaper also explores various FL workflows, comparing client-controlled workflows\nand server-controlled workflows. The findings of this work serve as a valuable\nreference for understanding the practical application and limitations of the FL\nmethods in segmentation tasks in UAV-based imaging.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u4eba\u673a\u70ed\u6210\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\uff0c\u6bd4\u8f83\u4e86\u591a\u79cdFL\u65b9\u6cd5\u4e0e\u96c6\u4e2d\u5f0f\u5b66\u4e60\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u548c\u6280\u672f\u9650\u5236\uff0c\u5206\u5e03\u5f0f\u6570\u636e\u65e0\u6cd5\u96c6\u4e2d\u5b58\u50a8\u548c\u5171\u4eab\uff0c\u8054\u90a6\u5b66\u4e60\u80fd\u591f\u7ed5\u8fc7\u4f20\u7edf\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60\u7684\u9650\u5236\uff0c\u8ba9\u53c2\u4e0e\u8005\u5728\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u800c\u65e0\u9700\u5171\u4eab\u6570\u636e\u3002", "method": "\u5728\u771f\u5b9e\u90e8\u7f72\u573a\u666f\u4e2d\u8bc4\u4f30\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f7f\u7528\u6765\u81ea\u4e24\u4e2a\u5fb7\u56fd\u57ce\u5e02\u7684\u65e0\u4eba\u673a\u70ed\u6210\u50cf\u6570\u636e\uff0c\u6bd4\u8f83\u591a\u79cdFL\u65b9\u6cd5\u4e0e\u96c6\u4e2d\u5f0f\u5b66\u4e60\u57fa\u7ebf\uff0c\u8bc4\u4f30\u6a21\u578b\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u65f6\u95f4\u3001\u901a\u4fe1\u5f00\u9500\u548c\u80fd\u8017\u7b49\u6307\u6807\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u4eba\u673a\u70ed\u6210\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u9762\u4e34\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u548c\u7279\u5f81\u7279\u6027\u5dee\u5f02\u7684\u6311\u6218\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u65e0\u4eba\u673a\u6210\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2511.00890", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.00890", "abs": "https://arxiv.org/abs/2511.00890", "authors": ["Kanabar Jay"], "title": "The final fate of anisotropic-dissipative gravitational collapse", "comment": "10 pages,0 figures", "summary": "The final fate of a collapsing star depends not only on how much matter it\ncontains but also on how that matter resists gravity in different directions.\nIn this work, we investigate the final fate of highly magnetized\nradiation-dominated spherically symmetric dissipative stellar configurations.\nWe study the dynamics of collapse by introducing a dimensionless geometric\nfactor $f(\\theta, \\phi)$ defined by the angular dependence of the radiative\nopacity. Using the field equations, we derive direction-sensitive threshold\nconditions that determine whether collapse initiates, halts, or reverses. The\nresulting inequalities unify black hole formation, bounce behavior, and delayed\ntrapping of geodesics into a single geometrically controlled framework. This\ntheoretical analysis would help analyze the collapse through pre-computed\nopacity tables for different magnetic field, temperature, and density profiles,\nalong with other data available for such considered profiles.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u5ea6\u78c1\u5316\u8f90\u5c04\u4e3b\u5bfc\u7684\u7403\u5bf9\u79f0\u8017\u6563\u6052\u661f\u6784\u578b\u7684\u6700\u7ec8\u547d\u8fd0\uff0c\u901a\u8fc7\u5f15\u5165\u8f90\u5c04\u4e0d\u900f\u660e\u5ea6\u7684\u89d2\u5ea6\u4f9d\u8d56\u6027\u51e0\u4f55\u56e0\u5b50\uff0c\u63a8\u5bfc\u51fa\u51b3\u5b9a\u574d\u7f29\u542f\u52a8\u3001\u505c\u6b62\u6216\u9006\u8f6c\u7684\u65b9\u5411\u654f\u611f\u9608\u503c\u6761\u4ef6\u3002", "motivation": "\u63a2\u7d22\u6052\u661f\u6700\u7ec8\u547d\u8fd0\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u7269\u8d28\u603b\u91cf\uff0c\u8fd8\u53d6\u51b3\u4e8e\u7269\u8d28\u5728\u4e0d\u540c\u65b9\u5411\u4e0a\u62b5\u6297\u5f15\u529b\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9ad8\u5ea6\u78c1\u5316\u8f90\u5c04\u4e3b\u5bfc\u6052\u661f\u6784\u578b\u7684\u574d\u7f29\u52a8\u529b\u5b66\u3002", "method": "\u5f15\u5165\u7531\u8f90\u5c04\u4e0d\u900f\u660e\u5ea6\u89d2\u5ea6\u4f9d\u8d56\u6027\u5b9a\u4e49\u7684\u51e0\u4f55\u56e0\u5b50f(\u03b8,\u03c6)\uff0c\u5229\u7528\u573a\u65b9\u7a0b\u63a8\u5bfc\u65b9\u5411\u654f\u611f\u7684\u9608\u503c\u6761\u4ef6\uff0c\u5efa\u7acb\u51e0\u4f55\u63a7\u5236\u6846\u67b6\u7edf\u4e00\u5206\u6790\u9ed1\u6d1e\u5f62\u6210\u3001\u53cd\u5f39\u884c\u4e3a\u548c\u6d4b\u5730\u7ebf\u5ef6\u8fdf\u6355\u83b7\u3002", "result": "\u83b7\u5f97\u4e86\u51b3\u5b9a\u574d\u7f29\u542f\u52a8\u3001\u505c\u6b62\u6216\u9006\u8f6c\u7684\u65b9\u5411\u654f\u611f\u9608\u503c\u6761\u4ef6\uff0c\u5c06\u9ed1\u6d1e\u5f62\u6210\u3001\u53cd\u5f39\u884c\u4e3a\u548c\u6d4b\u5730\u7ebf\u5ef6\u8fdf\u6355\u83b7\u7edf\u4e00\u5230\u5355\u4e00\u51e0\u4f55\u63a7\u5236\u6846\u67b6\u4e2d\u3002", "conclusion": "\u8be5\u7406\u8bba\u5206\u6790\u6709\u52a9\u4e8e\u901a\u8fc7\u9884\u5148\u8ba1\u7b97\u7684\u4e0d\u540c\u78c1\u573a\u3001\u6e29\u5ea6\u548c\u5bc6\u5ea6\u5256\u9762\u7684\u4e0d\u900f\u660e\u5ea6\u8868\uff0c\u4ee5\u53ca\u5176\u4ed6\u53ef\u7528\u6570\u636e\u6765\u5206\u6790\u574d\u7f29\u8fc7\u7a0b\u3002"}}
{"id": "2511.00857", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2511.00857", "abs": "https://arxiv.org/abs/2511.00857", "authors": ["Marcos Rub\u00edn-Osanz", "Marina C. de Ory", "Ignacio Gimeno", "Wenzel Kersten", "Marta Mas-Torrent", "Mar\u00eda C. Pallar\u00e9s", "Sebasti\u00e1n Roca-Jerat", "David Rodriguez", "Nerea Gonz\u00e1lez-Prato", "J. Alejandro de Sousa", "Lorenzo Tesi", "Daniel Granados", "Jaume Veciana", "David Zueco", "Anabel Lostao", "Joerg Schmiedmayer", "Inma Ratera", "Joris van Slageren", "N\u00faria Crivillers", "Alicia Gomez", "Fernando Luis"], "title": "Optimizing magnetic coupling in lumped element superconducting resonators for molecular spin qubits", "comment": null, "summary": "We engineer lumped-element superconducting resonators that maximize magnetic\ncoupling to molecular spin qubits, achieving record single-spin couplings up to\n100 kHz and collective couplings exceeding 10 MHz. The resonators were made\ninteract with PTMr organic free radicals, model spin systems with $S=1/2$ and a\nquasi-isotropic $g \\simeq 2$, dispersed in polymer matrices. The highest\ncollective spin-photon coupling strengths are attained with resonators having\nlarge inductors, which therefore interact with most spins in the molecular\nensemble. By contrast, the coupling of each individual spin $G_{1}$ is\nmaximized in resonators having a minimum size inductor, made of a single\nmicrowire. The same platform has been used to study spin relaxation and spin\ncoherent dynamics in the dispersive regime, when spins are energetically\ndetuned from the resonator. We find evidences for the Purcell effect, i.e. the\nphoton induced relaxation of those spins that are most strongly coupled to the\ncircuit. The rate of this process has been used to infer the distribution of\nsingle spin photon couplings in a given device. For resonators with a 50 nm\nwide constriction fabricated at the center of its single maximum $G_{1}$ values\nreach $\\sim 100$ kHz. Pumping the spins with strong pulses fed through an\nindependent transmission line induces coherent Rabi oscillations. The spin\nexcitation then proceeds via either direct resonant processes induced by the\nmain pulse frequency or, in the case of square-shaped pulses, via the\nexcitation of the cavity by side frequency components. The latter process\nmeasures the cavity mode hybridization with the spins and can be eliminated by\nusing Gaussian shaped pulses. These results establish a scalable route toward\nintegrated molecular-spin quantum processors.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u8d85\u5bfc\u8c10\u632f\u5668\u4e0e\u5206\u5b50\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u7684\u5f3a\u78c1\u8026\u5408\uff0c\u5b9e\u73b0\u4e86100 kHz\u7684\u5355\u81ea\u65cb\u8026\u5408\u548c10 MHz\u7684\u96c6\u4f53\u8026\u5408\uff0c\u7814\u7a76\u4e86\u81ea\u65cb\u5f1b\u8c6b\u548c\u76f8\u5e72\u52a8\u529b\u5b66\uff0c\u4e3a\u96c6\u6210\u5206\u5b50\u81ea\u65cb\u91cf\u5b50\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84\u3002", "motivation": "\u6700\u5927\u5316\u5206\u5b50\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u4e0e\u8d85\u5bfc\u7535\u8def\u7684\u78c1\u8026\u5408\uff0c\u63a2\u7d22\u81ea\u65cb-\u5149\u5b50\u76f8\u4e92\u4f5c\u7528\u673a\u5236\uff0c\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5206\u5b50\u81ea\u65cb\u91cf\u5b50\u5904\u7406\u5668\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u8bbe\u8ba1\u5177\u6709\u4e0d\u540c\u7535\u611f\u7ed3\u6784\u7684\u8d85\u5bfc\u8c10\u632f\u5668\uff0c\u4e0ePTMr\u6709\u673a\u81ea\u7531\u57fa\u5206\u5b50\u81ea\u65cb\u7cfb\u7edf\u76f8\u4e92\u4f5c\u7528\uff0c\u7814\u7a76\u81ea\u65cb\u5f1b\u8c6b\u3001Purcell\u6548\u5e94\u548c\u76f8\u5e72Rabi\u632f\u8361\u3002", "result": "\u5b9e\u73b0\u4e86\u521b\u7eaa\u5f55\u7684\u5355\u81ea\u65cb\u8026\u5408100 kHz\u548c\u96c6\u4f53\u8026\u540810 MHz\uff0c\u89c2\u5bdf\u5230Purcell\u6548\u5e94\u548c\u76f8\u5e72Rabi\u632f\u8361\uff0c\u53d1\u73b0\u8109\u51b2\u5f62\u72b6\u5bf9\u6fc0\u53d1\u673a\u5236\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u5e73\u53f0\u4e3a\u96c6\u6210\u5206\u5b50\u81ea\u65cb\u91cf\u5b50\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u7ebf\uff0c\u8bc1\u660e\u4e86\u8d85\u5bfc\u8c10\u632f\u5668\u4e0e\u5206\u5b50\u81ea\u65cb\u7cfb\u7edf\u5f3a\u8026\u5408\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.00056", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00056", "abs": "https://arxiv.org/abs/2511.00056", "authors": ["Yuxi Liu", "Renjia Deng", "Yutong He", "Xue Wang", "Tao Yao", "Kun Yuan"], "title": "MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling", "comment": null, "summary": "The substantial memory demands of pre-training and fine-tuning large language\nmodels (LLMs) require memory-efficient optimization algorithms. One promising\napproach is layer-wise optimization, which treats each transformer block as a\nsingle layer and optimizes it sequentially, while freezing the other layers to\nsave optimizer states and activations. Although effective, these methods ignore\nthe varying importance of the modules within each layer, leading to suboptimal\nperformance. Moreover, layer-wise sampling provides only limited memory\nsavings, as at least one full layer must remain active during optimization. To\novercome these limitations, we propose Module-wise Importance SAmpling (MISA),\na novel method that divides each layer into smaller modules and assigns\nimportance scores to each module. MISA uses a weighted random sampling\nmechanism to activate modules, provably reducing gradient variance compared to\nlayer-wise sampling. Additionally, we establish an \\(\\mathcal{O}(1/\\sqrt{K})\\)\nconvergence rate under non-convex and stochastic conditions, where $K$ is the\ntotal number of block updates, and provide a detailed memory analysis\nshowcasing MISA's superiority over existing baseline methods. Experiments on\ndiverse learning tasks validate the effectiveness of MISA. Source code is\navailable at https://github.com/pkumelon/MISA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6a21\u5757\u91cd\u8981\u6027\u91c7\u6837\u65b9\u6cd5MISA\uff0c\u901a\u8fc7\u5c06\u6bcf\u4e2a\u5c42\u5212\u5206\u4e3a\u66f4\u5c0f\u7684\u6a21\u5757\u5e76\u5206\u914d\u91cd\u8981\u6027\u5206\u6570\uff0c\u4f7f\u7528\u52a0\u6743\u968f\u673a\u91c7\u6837\u673a\u5236\u6fc0\u6d3b\u6a21\u5757\uff0c\u76f8\u6bd4\u5c42\u95f4\u91c7\u6837\u80fd\u6709\u6548\u51cf\u5c11\u68af\u5ea6\u65b9\u5dee\uff0c\u5728\u5185\u5b58\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7684\u5185\u5b58\u9700\u6c42\u5de8\u5927\uff0c\u9700\u8981\u5185\u5b58\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\u3002\u73b0\u6709\u7684\u5c42\u95f4\u4f18\u5316\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u5ffd\u7565\u4e86\u5c42\u5185\u6a21\u5757\u7684\u91cd\u8981\u6027\u5dee\u5f02\uff0c\u4e14\u5185\u5b58\u8282\u7701\u6709\u9650\u3002", "method": "\u5c06\u6bcf\u4e2a\u5c42\u5212\u5206\u4e3a\u66f4\u5c0f\u7684\u6a21\u5757\uff0c\u4e3a\u6bcf\u4e2a\u6a21\u5757\u5206\u914d\u91cd\u8981\u6027\u5206\u6570\uff0c\u4f7f\u7528\u52a0\u6743\u968f\u673a\u91c7\u6837\u673a\u5236\u9009\u62e9\u6fc0\u6d3b\u7684\u6a21\u5757\uff0c\u5728\u975e\u51f8\u548c\u968f\u673a\u6761\u4ef6\u4e0b\u5efa\u7acb\u4e86\u6536\u655b\u7387\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MISA\u5728\u5404\u79cd\u5b66\u4e60\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5185\u5b58\u5206\u6790\uff0c\u5c55\u793a\u4e86\u5176\u76f8\u5bf9\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "MISA\u901a\u8fc7\u6a21\u5757\u7ea7\u7684\u91cd\u8981\u6027\u91c7\u6837\uff0c\u5728\u4fdd\u8bc1\u6536\u655b\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5b58\u6548\u7387\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01004", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01004", "abs": "https://arxiv.org/abs/2511.01004", "authors": ["Zonghai Li"], "title": "From Spray to Metric: The Geometric Construction of the Jacobi Metric", "comment": null, "summary": "This paper develops a systematic approach to the geometrization of dynamics\nfrom the viewpoint of the geodesic equation. The method promotes a semispray to\na spray through the imposition of suitable dynamical constraints, and the\nassociated metric structure is extracted via reparameterization. When applied\nto static spacetimes, this spray-to-metric framework recovers the optical\nmetric, the Jacobi metric for massive particles, and its generalization for\ncharged particles in electromagnetic fields. We further show that a\nRanders-type Finsler metric arises naturally in the planar circular restricted\nthree-body problem. By establishing a direct pathway from equations of motion\nto metric structures, this work offers a geometric perspective, independent of\nthe traditional variational framework, may provide a basis for further studies\non dynamical systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u6d4b\u5730\u7ebf\u65b9\u7a0b\u89c6\u89d2\u7cfb\u7edf\u5316\u51e0\u4f55\u5316\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u65bd\u52a0\u52a8\u529b\u5b66\u7ea6\u675f\u5c06\u534a\u55b7\u5c04\u63d0\u5347\u4e3a\u55b7\u5c04\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u63d0\u53d6\u76f8\u5173\u5ea6\u91cf\u7ed3\u6784\u3002", "motivation": "\u4e3a\u52a8\u529b\u5b66\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u72ec\u7acb\u4e8e\u4f20\u7edf\u53d8\u5206\u6846\u67b6\u7684\u51e0\u4f55\u89c6\u89d2\uff0c\u5efa\u7acb\u4ece\u8fd0\u52a8\u65b9\u7a0b\u5230\u5ea6\u91cf\u7ed3\u6784\u7684\u76f4\u63a5\u8def\u5f84\u3002", "method": "\u901a\u8fc7\u65bd\u52a0\u5408\u9002\u7684\u52a8\u529b\u5b66\u7ea6\u675f\u5c06\u534a\u55b7\u5c04\u63d0\u5347\u4e3a\u55b7\u5c04\uff0c\u7136\u540e\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u63d0\u53d6\u76f8\u5173\u7684\u5ea6\u91cf\u7ed3\u6784\u3002", "result": "\u5728\u9759\u6001\u65f6\u7a7a\u4e0b\u6062\u590d\u4e86\u5149\u5b66\u5ea6\u91cf\u3001\u5927\u8d28\u91cf\u7c92\u5b50\u7684\u96c5\u53ef\u6bd4\u5ea6\u91cf\u53ca\u5176\u5728\u7535\u78c1\u573a\u4e2d\u5e26\u7535\u7c92\u5b50\u7684\u63a8\u5e7f\uff1b\u5728\u5e73\u9762\u5706\u5f62\u9650\u5236\u4e09\u4f53\u95ee\u9898\u4e2d\u81ea\u7136\u4ea7\u751f\u4e86Randers\u578bFinsler\u5ea6\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u51e0\u4f55\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u53ef\u80fd\u6210\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u57fa\u7840\u3002"}}
{"id": "2511.00910", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.00910", "abs": "https://arxiv.org/abs/2511.00910", "authors": ["Tristan Benoist", "No\u00e9 Cuneo", "Vojkan Jak\u0161i\u0107", "Claude-Alain Pillet"], "title": "On entropy production of repeated quantum measurements III. Quantum detailed balance", "comment": null, "summary": "In light of the dynamical-systems approach to entropy production in repeated\nquantum measurements, proposed and illustrated in Commun. Math. Phys. 357,\n77-123 (2018) [arXiv:1607.00162] and J. Stat. Phys. 182, 44 (2021)\n[arXiv:2012.03885], we characterize the KMS quantum detailed balance condition\nfor quantum channels via time-reversal invariance and the vanishing of the\nentropy production for the associated informationally complete quantum\ninstruments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8e\u52a8\u6001\u7cfb\u7edf\u65b9\u6cd5\u7814\u7a76\u91cf\u5b50\u6d4b\u91cf\u4e2d\u7684\u71b5\u4ea7\u751f\uff0c\u901a\u8fc7\u65f6\u95f4\u53cd\u6f14\u4e0d\u53d8\u6027\u548c\u4fe1\u606f\u5b8c\u5907\u91cf\u5b50\u4eea\u5668\u7684\u71b5\u4ea7\u751f\u4e3a\u96f6\u6765\u8868\u5f81\u91cf\u5b50\u901a\u9053\u7684KMS\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u6d4b\u91cf\u4e2d\u7684\u71b5\u4ea7\u751f\u52a8\u6001\uff0c\u5e76\u5efa\u7acb\u91cf\u5b50\u901a\u9053\u7684\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u4e0e\u71b5\u4ea7\u751f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u52a8\u6001\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7ed3\u5408\u65f6\u95f4\u53cd\u6f14\u4e0d\u53d8\u6027\u5206\u6790\u548c\u4fe1\u606f\u5b8c\u5907\u91cf\u5b50\u4eea\u5668\u7684\u71b5\u4ea7\u751f\u7279\u6027\u3002", "result": "\u6210\u529f\u8868\u5f81\u4e86KMS\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\uff0c\u8868\u660e\u5f53\u5173\u8054\u7684\u4fe1\u606f\u5b8c\u5907\u91cf\u5b50\u4eea\u5668\u71b5\u4ea7\u751f\u4e3a\u96f6\u65f6\uff0c\u91cf\u5b50\u901a\u9053\u6ee1\u8db3\u8be5\u5e73\u8861\u6761\u4ef6\u3002", "conclusion": "\u91cf\u5b50\u901a\u9053\u7684KMS\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u53ef\u4ee5\u901a\u8fc7\u65f6\u95f4\u53cd\u6f14\u4e0d\u53d8\u6027\u548c\u4fe1\u606f\u5b8c\u5907\u91cf\u5b50\u4eea\u5668\u7684\u96f6\u71b5\u4ea7\u751f\u6765\u5b8c\u5168\u8868\u5f81\u3002"}}
{"id": "2511.00059", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00059", "abs": "https://arxiv.org/abs/2511.00059", "authors": ["Aditya Singh", "Zihang Wen", "Srujananjali Medicherla", "Adam Karvonen", "Can Rager"], "title": "Automatically Finding Rule-Based Neurons in OthelloGPT", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop Mechanistic interpretability", "summary": "OthelloGPT, a transformer trained to predict valid moves in Othello, provides\nan ideal testbed for interpretability research. The model is complex enough to\nexhibit rich computational patterns, yet grounded in rule-based game logic that\nenables meaningful reverse-engineering. We present an automated approach based\non decision trees to identify and interpret MLP neurons that encode rule-based\ngame logic. Our method trains regression decision trees to map board states to\nneuron activations, then extracts decision paths where neurons are highly\nactive to convert them into human-readable logical forms. These descriptions\nreveal highly interpretable patterns; for instance, neurons that specifically\ndetect when diagonal moves become legal. Our findings suggest that roughly half\nof the neurons in layer 5 can be accurately described by compact, rule-based\ndecision trees ($R^2 > 0.7$ for 913 of 2,048 neurons), while the remainder\nlikely participate in more distributed or non-rule-based computations. We\nverify the causal relevance of patterns identified by our decision trees\nthrough targeted interventions. For a specific square, for specific game\npatterns, we ablate neurons corresponding to those patterns and find an\napproximately 5-10 fold stronger degradation in the model's ability to predict\nlegal moves along those patterns compared to control patterns. To facilitate\nfuture work, we provide a Python tool that maps rule-based game behaviors to\ntheir implementing neurons, serving as a resource for researchers to test\nwhether their interpretability methods recover meaningful computational\nstructures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u89e3\u91caOthelloGPT\u6a21\u578b\u4e2d\u7f16\u7801\u6e38\u620f\u89c4\u5219\u7684MLP\u795e\u7ecf\u5143\uff0c\u53d1\u73b0\u7ea6\u4e00\u534a\u7684\u795e\u7ecf\u5143\u53ef\u4ee5\u7528\u7d27\u51d1\u7684\u89c4\u5219\u63cf\u8ff0\uff0c\u5e76\u901a\u8fc7\u5e72\u9884\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6a21\u5f0f\u7684\u91cd\u8981\u6027\u3002", "motivation": "OthelloGPT\u6a21\u578b\u4e3a\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\u2014\u2014\u65e2\u8db3\u591f\u590d\u6742\u5c55\u73b0\u4e30\u5bcc\u8ba1\u7b97\u6a21\u5f0f\uff0c\u53c8\u57fa\u4e8e\u89c4\u5219\u6e38\u620f\u903b\u8f91\u4fbf\u4e8e\u9006\u5411\u5de5\u7a0b\u3002", "method": "\u4f7f\u7528\u56de\u5f52\u51b3\u7b56\u6811\u5c06\u68cb\u76d8\u72b6\u6001\u6620\u5c04\u5230\u795e\u7ecf\u5143\u6fc0\u6d3b\uff0c\u63d0\u53d6\u9ad8\u6fc0\u6d3b\u51b3\u7b56\u8def\u5f84\u5e76\u8f6c\u6362\u4e3a\u4eba\u7c7b\u53ef\u8bfb\u7684\u903b\u8f91\u5f62\u5f0f\uff0c\u540c\u65f6\u901a\u8fc7\u9488\u5bf9\u6027\u5e72\u9884\u9a8c\u8bc1\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u5728\u7b2c\u4e94\u5c422048\u4e2a\u795e\u7ecf\u5143\u4e2d\uff0c913\u4e2a\uff08\u7ea6\u4e00\u534a\uff09\u53ef\u4ee5\u7528\u7d27\u51d1\u7684\u89c4\u5219\u51b3\u7b56\u6811\u51c6\u786e\u63cf\u8ff0\uff08R\u00b2 > 0.7\uff09\uff0c\u5176\u4f59\u53ef\u80fd\u53c2\u4e0e\u5206\u5e03\u5f0f\u6216\u975e\u89c4\u5219\u8ba1\u7b97\u3002\u5e72\u9884\u5b9e\u9a8c\u663e\u793a\u7279\u5b9a\u6a21\u5f0f\u5bf9\u5e94\u7684\u795e\u7ecf\u5143\u88ab\u6d88\u878d\u540e\uff0c\u6a21\u578b\u9884\u6d4b\u5408\u6cd5\u79fb\u52a8\u7684\u80fd\u529b\u4e0b\u964d5-10\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u8bc6\u522b\u4e86\u6a21\u578b\u4e2d\u7684\u89c4\u5219\u7f16\u7801\u795e\u7ecf\u5143\uff0c\u9a8c\u8bc1\u4e86\u5176\u56e0\u679c\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5de5\u5177\u652f\u6301\u672a\u6765\u7814\u7a76\uff0c\u8868\u660e\u795e\u7ecf\u7f51\u7edc\u786e\u5b9e\u5b66\u4e60\u5230\u4e86\u53ef\u89e3\u91ca\u7684\u6e38\u620f\u89c4\u5219\u8868\u793a\u3002"}}
{"id": "2511.01020", "categories": ["gr-qc", "hep-th", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.01020", "abs": "https://arxiv.org/abs/2511.01020", "authors": ["Ana Bokuli\u0107", "Filip Po\u017ear"], "title": "Noncommutative dyonic black holes sourced by nonlinear electromagnetic fields", "comment": "12 pages", "summary": "We introduce the first-order noncommutative (NC) corrections to the general\nnonlinear electrodynamics (NLE) Lagrangian depending on two electromagnetic\ninvariants. The NC deformation of Einstein-NLE theory is implemented using the\n$\\partial_t\\wedge\\partial_\\varphi$ Drinfel'd twist and the NC effects are\nencoded in the matter sector through the Seiberg-Witten map. The resulting\nequations of motion reflect two distinct sources of nonlinearity in this\nframework; one arising from replacing Maxwell's electrodynamics with its\nnonlinear modifications and another from the NC deformations. Assuming a\ngeneral form of static, spherically symmetric dyonic black hole as a seed\nsolution in the commutative limit, we solve the equations of motion\nperturbatively to the first order in the NC parameter $a$. Finally, we evaluate\nthe obtained corrections to the metric tensor and gauge potential for several\nprominent NLE theories.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u975e\u4ea4\u6362(NC)\u4fee\u6b63\u5bf9\u975e\u7ebf\u6027\u7535\u52a8\u529b\u5b66(NLE)\u62c9\u683c\u6717\u65e5\u91cf\u7684\u5f71\u54cd\uff0c\u901a\u8fc7Drinfel'd\u626d\u66f2\u548cSeiberg-Witten\u6620\u5c04\u5b9e\u73b0\u7231\u56e0\u65af\u5766-NLE\u7406\u8bba\u7684NC\u53d8\u5f62\uff0c\u5e76\u6c42\u89e3\u4e86\u9759\u6001\u7403\u5bf9\u79f0\u53cc\u8377\u9ed1\u6d1e\u7684\u5fae\u6270\u89e3\u3002", "motivation": "\u63a2\u7d22\u975e\u4ea4\u6362\u51e0\u4f55\u5bf9\u975e\u7ebf\u6027\u7535\u52a8\u529b\u5b66\u7684\u4fee\u6b63\u6548\u5e94\uff0c\u5c06NC\u53d8\u5f62\u5f15\u5165\u7231\u56e0\u65af\u5766-NLE\u7406\u8bba\u6846\u67b6\uff0c\u7814\u7a76\u4e24\u79cd\u975e\u7ebf\u6027\u6765\u6e90\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u2202t\u2227\u2202\u03c6 Drinfel'd\u626d\u66f2\u548cSeiberg-Witten\u6620\u5c04\u5b9e\u73b0NC\u53d8\u5f62\uff0c\u5728\u4ea4\u6362\u6781\u9650\u4e0b\u5047\u8bbe\u9759\u6001\u7403\u5bf9\u79f0\u53cc\u8377\u9ed1\u6d1e\u4f5c\u4e3a\u79cd\u5b50\u89e3\uff0c\u5bf9NC\u53c2\u6570a\u8fdb\u884c\u4e00\u9636\u5fae\u6270\u6c42\u89e3\u8fd0\u52a8\u65b9\u7a0b\u3002", "result": "\u83b7\u5f97\u4e86\u5bf9\u5ea6\u91cf\u5f20\u91cf\u548c\u89c4\u8303\u52bf\u7684\u4e00\u9636NC\u4fee\u6b63\uff0c\u5e76\u5728\u591a\u4e2a\u8457\u540dNLE\u7406\u8bba\u4e2d\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u4fee\u6b63\u7684\u5177\u4f53\u5f62\u5f0f\u3002", "conclusion": "NC\u53d8\u5f62\u5728\u7269\u8d28\u90e8\u5206\u5f15\u5165\u4e86\u989d\u5916\u7684\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u4e0eNLE\u672c\u8eab\u975e\u7ebf\u6027\u5171\u540c\u6784\u6210\u4e86\u8be5\u6846\u67b6\u4e2d\u7684\u53cc\u91cd\u975e\u7ebf\u6027\u6765\u6e90\uff0c\u4e3a\u7406\u89e3NC\u51e0\u4f55\u5bf9\u5f15\u529b-\u7535\u78c1\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.00968", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.00968", "abs": "https://arxiv.org/abs/2511.00968", "authors": ["Minyi Huang", "Ray-Kuang Lee"], "title": "Adiabatic theorem for non-Hermitian quantum systems with non-degenerate real eigenvalues: A proof following Kato's approach", "comment": "5 pages", "summary": "The adiabatic theorem is one of the most interesting and significant theorem\nin quantum mechanics. In 1950, T. Kato gave an elegant proof of this result\n[1]. However, the validation of adiabatic theorem for non-Hermitian quantum\nsystems is unrevealed. In this paper, by following Kato' approach, we prove\nrigorously that the adiabatic theorem is still valid for non-Hermitian systems\nwith non-degenerate real eigenvalues. Moreover, our proof utilizes the complex\nBerry phase, instead of the orthogonal projections used in Kato's work.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9075\u5faaKato\u7684\u65b9\u6cd5\uff0c\u4e25\u683c\u8bc1\u660e\u4e86\u5177\u6709\u975e\u7b80\u5e76\u5b9e\u7279\u5f81\u503c\u7684\u975e\u5384\u7c73\u91cf\u5b50\u7cfb\u7edf\u7684\u7edd\u70ed\u5b9a\u7406\u4ecd\u7136\u6210\u7acb\u3002", "motivation": "\u9a8c\u8bc1\u7edd\u70ed\u5b9a\u7406\u5728\u975e\u5384\u7c73\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u56e0\u4e3a\u4e4b\u524d\u8be5\u5b9a\u7406\u5728\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u5c1a\u672a\u63ed\u793a\u3002", "method": "\u91c7\u7528Kato\u7684\u65b9\u6cd5\uff0c\u4f46\u4f7f\u7528\u590dBerry\u76f8\u4f4d\u4ee3\u66ffKato\u5de5\u4f5c\u4e2d\u4f7f\u7528\u7684\u6b63\u4ea4\u6295\u5f71\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u5177\u6709\u975e\u7b80\u5e76\u5b9e\u7279\u5f81\u503c\u7684\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u7edd\u70ed\u5b9a\u7406\u4ecd\u7136\u6709\u6548\u3002", "conclusion": "\u7edd\u70ed\u5b9a\u7406\u53ef\u4ee5\u6269\u5c55\u5230\u975e\u5384\u7c73\u91cf\u5b50\u7cfb\u7edf\uff0c\u524d\u63d0\u662f\u7cfb\u7edf\u5177\u6709\u975e\u7b80\u5e76\u7684\u5b9e\u7279\u5f81\u503c\u3002"}}
{"id": "2511.00064", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00064", "abs": "https://arxiv.org/abs/2511.00064", "authors": ["Randolph Wiredu-Aidoo"], "title": "EVINGCA: Adaptive Graph Clustering with Evolving Neighborhood Statistics", "comment": null, "summary": "Clustering algorithms often rely on restrictive assumptions: K-Means and\nGaussian Mixtures presuppose convex, Gaussian-like clusters, while DBSCAN and\nHDBSCAN capture non-convexity but can be highly sensitive. I introduce EVINGCA\n(Evolving Variance-Informed Nonparametric Graph Construction Algorithm), a\ndensity-variance based clustering algorithm that treats cluster formation as an\nadaptive, evolving process on a nearest-neighbor graph. EVINGCA expands rooted\ngraphs via breadth-first search, guided by continuously updated local distance\nand shape statistics, replacing fixed density thresholds with local statistical\nfeedback. With spatial indexing, EVINGCA features log-linear complexity in the\naverage case and exhibits competitive performance against baselines across a\nvariety of synthetic, real-world, low-d, and high-d datasets.", "AI": {"tldr": "EVINGCA\u662f\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6-\u65b9\u5dee\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u5c06\u805a\u7c7b\u5f62\u6210\u89c6\u4e3a\u6700\u8fd1\u90bb\u56fe\u4e0a\u7684\u81ea\u9002\u5e94\u6f14\u5316\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5c40\u90e8\u7edf\u8ba1\u53cd\u9988\u66ff\u4ee3\u56fa\u5b9a\u5bc6\u5ea6\u9608\u503c\uff0c\u5177\u6709\u5bf9\u6570\u7ebf\u6027\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u7b97\u6cd5\u5b58\u5728\u9650\u5236\u6027\u5047\u8bbe\uff1aK-Means\u548c\u9ad8\u65af\u6df7\u5408\u5047\u8bbe\u51f8\u7684\u7c7b\u9ad8\u65af\u7c07\uff0cDBSCAN\u548cHDBSCAN\u80fd\u6355\u83b7\u975e\u51f8\u6027\u4f46\u5bf9\u53c2\u6570\u9ad8\u5ea6\u654f\u611f\u3002", "method": "\u5728\u6700\u8fd1\u90bb\u56fe\u4e0a\u901a\u8fc7\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6269\u5c55\u6839\u56fe\uff0c\u4f7f\u7528\u6301\u7eed\u66f4\u65b0\u7684\u5c40\u90e8\u8ddd\u79bb\u548c\u5f62\u72b6\u7edf\u8ba1\u4f5c\u4e3a\u6307\u5bfc\uff0c\u7528\u5c40\u90e8\u7edf\u8ba1\u53cd\u9988\u66ff\u4ee3\u56fa\u5b9a\u5bc6\u5ea6\u9608\u503c\u3002", "result": "\u901a\u8fc7\u7a7a\u95f4\u7d22\u5f15\uff0cEVINGCA\u5728\u5e73\u5747\u60c5\u51b5\u4e0b\u5177\u6709\u5bf9\u6570\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u5728\u5404\u79cd\u5408\u6210\u3001\u771f\u5b9e\u4e16\u754c\u3001\u4f4e\u7ef4\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "EVINGCA\u901a\u8fc7\u5c06\u805a\u7c7b\u89c6\u4e3a\u81ea\u9002\u5e94\u6f14\u5316\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u5bf9\u53c2\u6570\u4e0d\u654f\u611f\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.01029", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01029", "abs": "https://arxiv.org/abs/2511.01029", "authors": ["Jiri Podolsky"], "title": "Various metric forms of all type D black holes and their application", "comment": "5 pages, 1 figure; contribution to the proceedings of GR24 / Amaldi16\n  (International Conference on General Relativity and Gravitation / Edoardo\n  Amaldi Conference on Gravitational Waves) to be published in Journal of\n  Physics: Conference Series", "summary": "Several recent results concerning the complete class of exact solutions to\nthe Einstein-Maxwell-$\\Lambda$ equations of type D with a double-aligned\nelectromagnetic field are summarized. This large class of spacetimes includes\ncharged black holes with rotation, NUT parameter, and acceleration. In\nparticular, we present their Plebanski-Demianski, Griffiths-Podolsky-Vratny,\nand Astorino metric representations, we discuss mutual relations between them,\nand demonstrate their usefulness for investigation of physical and geometrical\nproperties (singularities, horizons, conformal diagrams, ergoregions, rotating\nstrings causing the acceleration, thermodynamics). It includes the proof that\nsuch black holes emit gravitational radiation if, and only if, they accelerate.\nVery recent extension to type D black holes with non-aligned Maxwell field is\nalso mentioned.", "AI": {"tldr": "\u603b\u7ed3\u4e86\u7231\u56e0\u65af\u5766-\u9ea6\u514b\u65af\u97e6-\u039b\u65b9\u7a0bD\u578b\u53cc\u5bf9\u9f50\u7535\u78c1\u573a\u7cbe\u786e\u89e3\u7684\u5168\u7c7b\uff0c\u5305\u62ec\u5e26\u65cb\u8f6c\u3001NUT\u53c2\u6570\u548c\u52a0\u901f\u7684\u5e26\u7535\u9ed1\u6d1e\uff0c\u8ba8\u8bba\u4e86\u4e0d\u540c\u5ea6\u91cf\u8868\u793a\u53ca\u5176\u7269\u7406\u51e0\u4f55\u6027\u8d28\u3002", "motivation": "\u7cfb\u7edf\u6574\u7406\u548c\u7814\u7a76\u7231\u56e0\u65af\u5766-\u9ea6\u514b\u65af\u97e6-\u039b\u65b9\u7a0bD\u578b\u53cc\u5bf9\u9f50\u7535\u78c1\u573a\u7684\u7cbe\u786e\u89e3\u5168\u7c7b\uff0c\u7279\u522b\u662f\u5305\u542b\u65cb\u8f6c\u3001NUT\u53c2\u6570\u548c\u52a0\u901f\u7684\u5e26\u7535\u9ed1\u6d1e\u89e3\u3002", "method": "\u603b\u7ed3Plebanski-Demianski\u3001Griffiths-Podolsky-Vratny\u548cAstorino\u4e09\u79cd\u5ea6\u91cf\u8868\u793a\uff0c\u5206\u6790\u5b83\u4eec\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\uff0c\u5e76\u7528\u4e8e\u7814\u7a76\u7269\u7406\u548c\u51e0\u4f55\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u7c7b\u9ed1\u6d1e\u5f53\u4e14\u4ec5\u5f53\u52a0\u901f\u65f6\u624d\u4f1a\u53d1\u5c04\u5f15\u529b\u8f90\u5c04\uff0c\u5e76\u6269\u5c55\u5230\u975e\u5bf9\u9f50\u9ea6\u514b\u65af\u97e6\u573a\u7684D\u578b\u9ed1\u6d1e\u3002", "conclusion": "\u5efa\u7acb\u4e86D\u578b\u53cc\u5bf9\u9f50\u7535\u78c1\u573a\u7cbe\u786e\u89e3\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u52a0\u901f\u4e0e\u5f15\u529b\u8f90\u5c04\u53d1\u5c04\u7684\u5173\u8054\uff0c\u4e3a\u7814\u7a76\u9ed1\u6d1e\u7269\u7406\u6027\u8d28\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2511.01027", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01027", "abs": "https://arxiv.org/abs/2511.01027", "authors": ["Francesco Adinolfi", "Daniel Z. Haxell", "Alessandro Bruno", "Laurent Michaud", "Venus Hasanuzzaman Kamrul", "Preeti Pandey", "Alexander Grimm"], "title": "Enhancing Kerr-Cat Qubit Coherence with Controlled Dissipation", "comment": null, "summary": "Quantum computing crucially relies on maintaining quantum coherence for the\nduration of a calculation. Bosonic quantum error correction protects this\ncoherence by encoding qubits into superpositions of noise-resilient oscillator\nstates. In the case of the Kerr-cat qubit (KCQ), these states derive their\nstability from being the quasi-degenerate ground states of an engineered\nHamiltonian in a driven nonlinear oscillator. KCQs are experimentally\ncompatible with on-chip architectures and high-fidelity operations, making them\npromising candidates for a scalable bosonic quantum processor. However, their\nbit-flip time must increase further to fully leverage these advantages. Here,\nwe present direct evidence that the bit-flip time in a KCQ is limited by\nleakage out of the qubit manifold and experimentally mitigate this process. We\ncoherently control the leakage population and measure it to be > 9%, twelve\ntimes higher than in the undriven system. We then cool this population back\ninto the KCQ manifold with engineered dissipation, identify conditions under\nwhich this suppresses bit-flips, and demonstrate increased bit-flip times up to\n3.6 milliseconds. By employing both Hamiltonian confinement and engineered\ndissipation, our experiment combines two paradigms for Schr\\\"odinger-cat qubit\nstabilization. Our results elucidate the interplay between these stabilization\nprocesses and indicate a path towards fully realizing the potential of these\nqubits for quantum error correction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Kerr-cat\u91cf\u5b50\u6bd4\u7279\u7684\u6bd4\u7279\u7ffb\u8f6c\u65f6\u95f4\u9650\u5236\u95ee\u9898\uff0c\u53d1\u73b0\u6cc4\u6f0f\u51fa\u91cf\u5b50\u6bd4\u7279\u6d41\u5f62\u662f\u4e3b\u8981\u9650\u5236\u56e0\u7d20\uff0c\u5e76\u901a\u8fc7\u5de5\u7a0b\u8017\u6563\u51b7\u5374\u6cc4\u6f0f\u6001\u6765\u5ef6\u957f\u6bd4\u7279\u7ffb\u8f6c\u65f6\u95f4\u3002", "motivation": "Kerr-cat\u91cf\u5b50\u6bd4\u7279\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u6bd4\u7279\u7ffb\u8f6c\u65f6\u95f4\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u9ad8\u624d\u80fd\u5145\u5206\u53d1\u6325\u5176\u4f18\u52bf\u3002", "method": "\u901a\u8fc7\u76f8\u5e72\u63a7\u5236\u6cc4\u6f0f\u6001\u5e76\u6d4b\u91cf\u5176\u5360\u6bd4\uff0c\u7136\u540e\u4f7f\u7528\u5de5\u7a0b\u8017\u6563\u5c06\u6cc4\u6f0f\u6001\u51b7\u5374\u56de\u91cf\u5b50\u6bd4\u7279\u6d41\u5f62\uff0c\u7ed3\u5408\u54c8\u5bc6\u987f\u7ea6\u675f\u548c\u5de5\u7a0b\u8017\u6563\u4e24\u79cd\u7a33\u5b9a\u5316\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6cc4\u6f0f\u6001\u5360\u6bd4\u9ad8\u8fbe9%\uff0c\u662f\u672a\u9a71\u52a8\u7cfb\u7edf\u768412\u500d\uff1b\u901a\u8fc7\u5de5\u7a0b\u8017\u6563\u51b7\u5374\u540e\uff0c\u6bd4\u7279\u7ffb\u8f6c\u65f6\u95f4\u5ef6\u957f\u81f33.6\u6beb\u79d2\u3002", "conclusion": "\u7ed3\u5408\u54c8\u5bc6\u987f\u7ea6\u675f\u548c\u5de5\u7a0b\u8017\u6563\u53ef\u4ee5\u6709\u6548\u6291\u5236\u6bd4\u7279\u7ffb\u8f6c\uff0c\u4e3a\u5b9e\u73b0Kerr-cat\u91cf\u5b50\u6bd4\u7279\u5728\u91cf\u5b50\u7ea0\u9519\u4e2d\u7684\u6f5c\u529b\u6307\u660e\u4e86\u8def\u5f84\u3002"}}
{"id": "2511.00065", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00065", "abs": "https://arxiv.org/abs/2511.00065", "authors": ["Kateryna Shapovalenko", "Quentin Auster"], "title": "Aligning Brain Signals with Multimodal Speech and Vision Embeddings", "comment": null, "summary": "When we hear the word \"house\", we don't just process sound, we imagine walls,\ndoors, memories. The brain builds meaning through layers, moving from raw\nacoustics to rich, multimodal associations. Inspired by this, we build on\nrecent work from Meta that aligned EEG signals with averaged wav2vec2 speech\nembeddings, and ask a deeper question: which layers of pre-trained models best\nreflect this layered processing in the brain? We compare embeddings from two\nmodels: wav2vec2, which encodes sound into language, and CLIP, which maps words\nto images. Using EEG recorded during natural speech perception, we evaluate how\nthese embeddings align with brain activity using ridge regression and\ncontrastive decoding. We test three strategies: individual layers, progressive\nconcatenation, and progressive summation. The findings suggest that combining\nmultimodal, layer-aware representations may bring us closer to decoding how the\nbrain understands language, not just as sound, but as experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4e0d\u540c\u5c42\u5982\u4f55\u53cd\u6620\u5927\u8111\u5bf9\u8bed\u8a00\u7684\u5206\u5c42\u5904\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6bd4\u8f83wav2vec2\u548cCLIP\u6a21\u578b\u7684\u5d4c\u5165\u4e0e\u8111\u7535\u56fe\u4fe1\u53f7\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "motivation": "\u53d7\u5927\u8111\u4ece\u539f\u59cb\u58f0\u5b66\u5230\u4e30\u5bcc\u591a\u6a21\u6001\u5173\u8054\u7684\u5206\u5c42\u610f\u4e49\u6784\u5efa\u8fc7\u7a0b\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u786e\u5b9a\u54ea\u4e9b\u9884\u8bad\u7ec3\u6a21\u578b\u5c42\u6700\u80fd\u53cd\u6620\u5927\u8111\u7684\u8fd9\u79cd\u5206\u5c42\u5904\u7406\u673a\u5236\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u97f3\u611f\u77e5\u671f\u95f4\u8bb0\u5f55\u7684EEG\u6570\u636e\uff0c\u901a\u8fc7\u5cad\u56de\u5f52\u548c\u5bf9\u6bd4\u89e3\u7801\u8bc4\u4f30wav2vec2\u548cCLIP\u6a21\u578b\u5d4c\u5165\u4e0e\u5927\u8111\u6d3b\u52a8\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u7b56\u7565\uff1a\u5355\u5c42\u3001\u6e10\u8fdb\u62fc\u63a5\u548c\u6e10\u8fdb\u6c42\u548c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7ed3\u5408\u591a\u6a21\u6001\u3001\u5206\u5c42\u611f\u77e5\u7684\u8868\u5f81\u53ef\u80fd\u66f4\u63a5\u8fd1\u89e3\u7801\u5927\u8111\u5982\u4f55\u7406\u89e3\u8bed\u8a00\u2014\u2014\u4e0d\u4ec5\u662f\u58f0\u97f3\uff0c\u66f4\u662f\u4f53\u9a8c\u3002", "conclusion": "\u591a\u6a21\u6001\u3001\u5206\u5c42\u611f\u77e5\u7684\u8868\u5f81\u7ec4\u5408\u4e3a\u7406\u89e3\u5927\u8111\u8bed\u8a00\u5904\u7406\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u58f0\u97f3\u5904\u7406\u5c42\u9762\u3002"}}
{"id": "2511.01051", "categories": ["gr-qc", "astro-ph.HE", "hep-ph"], "pdf": "https://arxiv.org/pdf/2511.01051", "abs": "https://arxiv.org/abs/2511.01051", "authors": ["Francesco Crescimbeni"], "title": "Can we identify primordial black holes? The role of subsolar gravitational wave events", "comment": "Note: Contribution to: 24th International Conference on General\n  Relativity and Gravitation (GR24) and 16th Edoardo Amaldi Conference on\n  Gravitational Waves (Amaldi16)", "summary": "The detection of a subsolar object in a compact binary merger is regarded as\none of the most compelling signatures of a population of primordial black holes\n(PBHs). We critically examine whether such systems can be distinguished from\nstellar binaries, such as those composed of neutron stars (NSs), which could\nalso populate the subsolar mass range. Unlike PBHs, the gravitational-wave\nsignal from stellar binaries is affected by tidal effects, which increase by\nseveral orders of magnitude as the mass decreases. We forecast the capability\nof current and future gravitational-wave (GW) detectors to constrain tidal\neffects in putative subsolar binaries. We also discuss the broader implications\nthat the detection of a subsolar merger would have for both cosmology and\nnuclear physics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u6027\u5730\u5206\u6790\u4e86\u5982\u4f55\u533a\u5206\u4e9a\u592a\u9633\u8d28\u91cf\u81f4\u5bc6\u53cc\u661f\u7cfb\u7edf\u4e2d\u7684\u539f\u521d\u9ed1\u6d1e\u4e0e\u4e2d\u5b50\u661f\uff0c\u901a\u8fc7\u7814\u7a76\u6f6e\u6c50\u6548\u5e94\u5728\u5f15\u529b\u6ce2\u4fe1\u53f7\u4e2d\u7684\u5dee\u5f02\u6765\u8bc6\u522b\u539f\u521d\u9ed1\u6d1e\u3002", "motivation": "\u4e9a\u592a\u9633\u8d28\u91cf\u81f4\u5bc6\u53cc\u661f\u5408\u5e76\u7684\u63a2\u6d4b\u88ab\u8ba4\u4e3a\u662f\u539f\u521d\u9ed1\u6d1e\u5b58\u5728\u7684\u6700\u6709\u529b\u8bc1\u636e\u4e4b\u4e00\uff0c\u4f46\u9700\u8981\u4e0e\u53ef\u80fd\u5b58\u5728\u4e8e\u4e9a\u592a\u9633\u8d28\u91cf\u8303\u56f4\u5185\u7684\u4e2d\u5b50\u661f\u7b49\u6052\u661f\u53cc\u661f\u7cfb\u7edf\u8fdb\u884c\u533a\u5206\u3002", "method": "\u901a\u8fc7\u9884\u6d4b\u5f53\u524d\u548c\u672a\u6765\u5f15\u529b\u6ce2\u63a2\u6d4b\u5668\u5bf9\u4e9a\u592a\u9633\u8d28\u91cf\u53cc\u661f\u4e2d\u6f6e\u6c50\u6548\u5e94\u7684\u7ea6\u675f\u80fd\u529b\uff0c\u5206\u6790\u5f15\u529b\u6ce2\u4fe1\u53f7\u4e2d\u6f6e\u6c50\u6548\u5e94\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0ePBHs\u4e0d\u540c\uff0c\u6052\u661f\u53cc\u661f\u7684\u5f15\u529b\u6ce2\u4fe1\u53f7\u4f1a\u53d7\u5230\u6f6e\u6c50\u6548\u5e94\u7684\u5f71\u54cd\uff0c\u4e14\u968f\u7740\u8d28\u91cf\u51cf\u5c0f\uff0c\u8fd9\u79cd\u6548\u5e94\u4f1a\u589e\u5f3a\u6570\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u4e9a\u592a\u9633\u8d28\u91cf\u5408\u5e76\u7684\u63a2\u6d4b\u5bf9\u5b87\u5b99\u5b66\u548c\u6838\u7269\u7406\u90fd\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u901a\u8fc7\u6f6e\u6c50\u6548\u5e94\u5206\u6790\u53ef\u4ee5\u6709\u6548\u533a\u5206\u539f\u521d\u9ed1\u6d1e\u548c\u6052\u661f\u53cc\u661f\u7cfb\u7edf\u3002"}}
{"id": "2511.01028", "categories": ["quant-ph", "math-ph", "math.MP", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.01028", "abs": "https://arxiv.org/abs/2511.01028", "authors": ["Fabio Benatti", "Masoud Gharahi", "Giovanni Gramegna", "Stefano Mancini", "Vincenzo Parisi"], "title": "Pseudo quantum advantages in perceptron storage capacity", "comment": "23 pages, 2 figures", "summary": "We investigate a generalized quantum perceptron architecture characterized by\nan oscillating activation function with a tunable frequency ranging from zero\nto infinity. Employing analytical techniques from statistical mechanics, we\nderive the optimal storage capacity and demonstrate that the classical result\nis recovered in the limit of vanishing frequency. As the frequency increases,\nhowever, the architecture exhibits enhanced quantum storage capabilities.\nNotably, this improvement stems solely from the specific form of the activation\nfunction and, in principle, could be emulated within a classical framework.\nAccordingly, we refer to this enhancement as a pseudo quantum advantage.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5177\u6709\u632f\u8361\u6fc0\u6d3b\u51fd\u6570\u7684\u5e7f\u4e49\u91cf\u5b50\u611f\u77e5\u5668\u67b6\u6784\uff0c\u53d1\u73b0\u968f\u7740\u9891\u7387\u589e\u52a0\uff0c\u91cf\u5b50\u5b58\u50a8\u80fd\u529b\u589e\u5f3a\uff0c\u4f46\u8fd9\u79cd\u4f18\u52bf\u672c\u8d28\u4e0a\u662f\u4f2a\u91cf\u5b50\u4f18\u52bf\uff0c\u53ef\u4ee5\u5728\u7ecf\u5178\u6846\u67b6\u4e2d\u6a21\u62df\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u611f\u77e5\u5668\u67b6\u6784\u7684\u5b58\u50a8\u80fd\u529b\uff0c\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u4f18\u52bf\uff0c\u7279\u522b\u662f\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u5f62\u5f0f\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u3002", "method": "\u4f7f\u7528\u7edf\u8ba1\u529b\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u5177\u6709\u53ef\u8c03\u9891\u7387\u632f\u8361\u6fc0\u6d3b\u51fd\u6570\u7684\u5e7f\u4e49\u91cf\u5b50\u611f\u77e5\u5668\u67b6\u6784\uff0c\u5206\u6790\u5176\u5b58\u50a8\u5bb9\u91cf\u968f\u9891\u7387\u53d8\u5316\u7684\u5173\u7cfb\u3002", "result": "\u5f53\u9891\u7387\u4e3a\u96f6\u65f6\u6062\u590d\u7ecf\u5178\u7ed3\u679c\uff0c\u968f\u7740\u9891\u7387\u589e\u52a0\uff0c\u67b6\u6784\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u91cf\u5b50\u5b58\u50a8\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u589e\u5f3a\u4ec5\u6e90\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u5f62\u5f0f\u3002", "conclusion": "\u91cf\u5b50\u611f\u77e5\u5668\u67b6\u6784\u7684\u5b58\u50a8\u80fd\u529b\u63d0\u5347\u662f\u4f2a\u91cf\u5b50\u4f18\u52bf\uff0c\u56e0\u4e3a\u8fd9\u79cd\u6539\u8fdb\u53ef\u4ee5\u5728\u7ecf\u5178\u6846\u67b6\u4e2d\u6a21\u62df\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u91cf\u5b50\u529b\u5b66\u7684\u672c\u8d28\u7279\u6027\u3002"}}
{"id": "2511.00066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00066", "abs": "https://arxiv.org/abs/2511.00066", "authors": ["Tue Le", "Nghi D. Q. Bui", "Linh Ngo Van", "Trung Le"], "title": "Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npowerful approach for strengthening the reasoning capabilities of large\nlanguage models (LLMs). Among existing algorithms, Group Relative Policy\nOptimization (GRPO) has demonstrated strong performance, yet it suffers from a\ncritical issue: low-probability tokens disproportionately dominate gradient\nupdates due to their inherently large gradient magnitudes. This imbalance leads\nto unstable training and suppresses the contribution of high-probability tokens\nthat are more reliable for learning. In this work, we introduce Token-Regulated\nGroup Relative Policy Optimization (TR-GRPO), a simple yet effective extension\nof GRPO that assigns token-level weights positively correlated with the model's\npredicted probability. By downweighting low-probability tokens and emphasizing\nhigh-probability ones, TR-GRPO mitigates gradient over-amplification while\npreserving informative learning signals. Extensive experiments demonstrate that\nTR-GRPO consistently outperforms GRPO across RLVR tasks, including logic, math,\nand agentic reasoning, highlighting the importance of regulating token\ncontributions during RL training and establishing TR-GRPO as a robust framework\nfor enhancing LLM reasoning.", "AI": {"tldr": "TR-GRPO\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8etoken\u6982\u7387\u7684\u6743\u91cd\u8c03\u8282\u6765\u89e3\u51b3GRPO\u4e2d\u4f4e\u6982\u7387token\u68af\u5ea6\u8fc7\u5ea6\u653e\u5927\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709GRPO\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u95ee\u9898\uff1a\u4f4e\u6982\u7387token\u7531\u4e8e\u5176\u56fa\u6709\u7684\u68af\u5ea6\u5e45\u5ea6\u8f83\u5927\uff0c\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u5730\u4e3b\u5bfc\u68af\u5ea6\u66f4\u65b0\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u5e76\u6291\u5236\u9ad8\u6982\u7387token\u7684\u5b66\u4e60\u8d21\u732e\u3002", "method": "\u63d0\u51faToken-Regulated Group Relative Policy Optimization (TR-GRPO)\uff0c\u901a\u8fc7\u5206\u914d\u4e0e\u6a21\u578b\u9884\u6d4b\u6982\u7387\u6b63\u76f8\u5173\u7684token\u7ea7\u6743\u91cd\uff0c\u964d\u4f4e\u4f4e\u6982\u7387token\u7684\u6743\u91cd\u5e76\u5f3a\u8c03\u9ad8\u6982\u7387token\uff0c\u4ece\u800c\u7f13\u89e3\u68af\u5ea6\u8fc7\u5ea6\u653e\u5927\u540c\u65f6\u4fdd\u7559\u4fe1\u606f\u5b66\u4e60\u4fe1\u53f7\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eTR-GRPO\u5728RLVR\u4efb\u52a1\uff08\u5305\u62ec\u903b\u8f91\u3001\u6570\u5b66\u548c\u667a\u80fd\u4f53\u63a8\u7406\uff09\u4e2d\u6301\u7eed\u4f18\u4e8eGRPO\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728RL\u8bad\u7ec3\u671f\u95f4\u8c03\u8282token\u8d21\u732e\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c06TR-GRPO\u786e\u7acb\u4e3a\u589e\u5f3aLLM\u63a8\u7406\u7684\u7a33\u5065\u6846\u67b6\u3002"}}
{"id": "2511.01128", "categories": ["gr-qc", "83C05"], "pdf": "https://arxiv.org/pdf/2511.01128", "abs": "https://arxiv.org/abs/2511.01128", "authors": ["Miguel S\u00e1nchez"], "title": "Cosmological spacetimes with spatially constant sign-changing curvature", "comment": "Presented at the 24th International Conference on General Relativity\n  and Gravitation (Glasgow, July'25), provisionally accepted by the Conference\n  Editors, 4 pages", "summary": "Globally hyperbolic spacetimes endowed with a time function $t$ whose\nspacelike slices $t=t_0$ have constant curvature $k(t_0)$ and where the sign of\n$k(t_0)$ (as well as the topology of the slice) varies with $t_0$, can be\nconstructed despite some common claims about the implications of the classical\nCosmological Principle. Here, we stress the possibilities of these cosmologies\nand announce the development of new models obtained in collaboration with G.\nGarc\\'{\\i}a-Moreno, B. Janssen, A. Jim\\'enez-Cano, M. Mars and R. Vera", "AI": {"tldr": "\u8be5\u8bba\u6587\u6784\u5efa\u4e86\u5168\u5c40\u53cc\u66f2\u65f6\u7a7a\u6a21\u578b\uff0c\u5176\u4e2d\u65f6\u95f4\u51fd\u6570\u7684\u7a7a\u95f4\u5207\u7247\u5177\u6709\u53d8\u5316\u7684\u66f2\u7387\u7b26\u53f7\u548c\u62d3\u6251\u7ed3\u6784\uff0c\u7a81\u7834\u4e86\u7ecf\u5178\u5b87\u5b99\u5b66\u539f\u7406\u7684\u9650\u5236\u3002", "motivation": "\u6311\u6218\u7ecf\u5178\u5b87\u5b99\u5b66\u539f\u7406\u5173\u4e8e\u7a7a\u95f4\u5207\u7247\u66f2\u7387\u7b26\u53f7\u548c\u62d3\u6251\u7ed3\u6784\u5fc5\u987b\u4fdd\u6301\u4e0d\u53d8\u7684\u5047\u8bbe\uff0c\u63a2\u7d22\u66f4\u4e30\u5bcc\u7684\u5b87\u5b99\u5b66\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u65f6\u95f4\u51fd\u6570\u6784\u9020\u5168\u5c40\u53cc\u66f2\u65f6\u7a7a\uff0c\u4f7f\u5f97\u7a7a\u95f4\u5207\u7247\u7684\u66f2\u7387k(t\u2080)\u548c\u62d3\u6251\u7ed3\u6784\u968ft\u2080\u53d8\u5316\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u7a7a\u95f4\u5207\u7247\u66f2\u7387\u7b26\u53f7\u548c\u62d3\u6251\u7ed3\u6784\u53ef\u53d8\u7684\u5b87\u5b99\u5b66\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u5c55\u793a\u4e86\u5b87\u5b99\u5b66\u4e2d\u8d85\u8d8a\u7ecf\u5178\u5b87\u5b99\u5b66\u539f\u7406\u9650\u5236\u7684\u65b0\u53ef\u80fd\u6027\uff0c\u4e3a\u5b87\u5b99\u6f14\u5316\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2511.01062", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01062", "abs": "https://arxiv.org/abs/2511.01062", "authors": ["Aleksandra \u015awierkowska", "Jannik Pflieger", "Emmanouil Giortamis", "Pramod Bhatotia"], "title": "ECCentric: An Empirical Analysis of Quantum Error Correction Codes", "comment": null, "summary": "Quantum error correction (QEC) is essential for building scalable quantum\ncomputers, but a lack of systematic, end-to-end evaluation methods makes it\ndifficult to assess how different QEC codes perform under realistic conditions.\nThe vast diversity of codes, an expansive experimental search space, and the\nabsence of a standardized framework prevent a thorough, holistic analysis. To\naddress this, we introduce ECCentric, an end-to-end benchmarking framework\ndesigned to systematically evaluate QEC codes across the full quantum computing\nstack. ECCentric is designed to be modular, extensible, and general, allowing\nfor a comprehensive analysis of QEC code families under varying hardware\ntopologies, noise models, and compilation strategies.\n  Using ECCentric, we conduct the first systematic benchmarking of major QEC\ncode families against realistic, mid-term quantum device parameters. Our\nempirical analysis reveals that intra-QPU execution significantly outperforms\ndistributed methods, that qubit connectivity is a far more critical factor for\nreducing logical errors than increasing code distance, and that compiler\noverhead remains a major source of error. Furthermore, our findings suggest\nthat trapped-ion architectures with qubit shuttling are the most promising\nnear-term platforms and that on noisy devices, a strategic and selective\napplication of QEC is necessary to avoid introducing more errors than are\ncorrected. This study provides crucial, actionable insights for both hardware\ndesigners and practitioners, guiding the development of fault-tolerant quantum\nsystems.", "AI": {"tldr": "ECCentric\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u91cf\u5b50\u7ea0\u9519\u7801\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540cQEC\u4ee3\u7801\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff1aQPU\u5185\u90e8\u6267\u884c\u4f18\u4e8e\u5206\u5e03\u5f0f\u65b9\u6cd5\uff0c\u91cf\u5b50\u6bd4\u7279\u8fde\u63a5\u6027\u6bd4\u589e\u52a0\u4ee3\u7801\u8ddd\u79bb\u66f4\u91cd\u8981\uff0c\u7f16\u8bd1\u5668\u5f00\u9500\u662f\u4e3b\u8981\u9519\u8bef\u6e90\uff0c\u79bb\u5b50\u9631\u67b6\u6784\u6700\u6709\u524d\u666f\u3002", "motivation": "\u91cf\u5b50\u7ea0\u9519\u5bf9\u4e8e\u6784\u5efa\u53ef\u6269\u5c55\u91cf\u5b50\u8ba1\u7b97\u673a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u65b9\u6cd5\uff0c\u96be\u4ee5\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u8bc4\u4f30\u4e0d\u540cQEC\u4ee3\u7801\u7684\u6027\u80fd\u3002\u4ee3\u7801\u591a\u6837\u6027\u5927\u3001\u5b9e\u9a8c\u641c\u7d22\u7a7a\u95f4\u5e7f\u9614\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u963b\u788d\u4e86\u5168\u9762\u5206\u6790\u3002", "method": "\u5f15\u5165ECCentric\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u7aef\u5230\u7aef\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5141\u8bb8\u5728\u4e0d\u540c\u786c\u4ef6\u62d3\u6251\u3001\u566a\u58f0\u6a21\u578b\u548c\u7f16\u8bd1\u7b56\u7565\u4e0b\u5bf9QEC\u4ee3\u7801\u5bb6\u65cf\u8fdb\u884c\u5168\u9762\u5206\u6790\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff1aQPU\u5185\u90e8\u6267\u884c\u663e\u8457\u4f18\u4e8e\u5206\u5e03\u5f0f\u65b9\u6cd5\uff1b\u91cf\u5b50\u6bd4\u7279\u8fde\u63a5\u6027\u6bd4\u589e\u52a0\u4ee3\u7801\u8ddd\u79bb\u5bf9\u51cf\u5c11\u903b\u8f91\u9519\u8bef\u66f4\u4e3a\u5173\u952e\uff1b\u7f16\u8bd1\u5668\u5f00\u9500\u4ecd\u7136\u662f\u4e3b\u8981\u9519\u8bef\u6e90\uff1b\u79bb\u5b50\u9631\u67b6\u6784\u7ed3\u5408\u91cf\u5b50\u6bd4\u7279\u7a7f\u68ad\u662f\u6700\u6709\u524d\u666f\u7684\u8fd1\u5e73\u53f0\uff1b\u5728\u566a\u58f0\u8bbe\u5907\u4e0a\u9700\u8981\u7b56\u7565\u6027\u5730\u9009\u62e9\u6027\u5e94\u7528QEC\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5173\u952e\u4e14\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u6307\u5bfc\u5bb9\u9519\u91cf\u5b50\u7cfb\u7edf\u7684\u5f00\u53d1\uff0c\u5f3a\u8c03\u9700\u8981\u6218\u7565\u6027\u5e94\u7528QEC\u4ee5\u907f\u514d\u5f15\u5165\u6bd4\u7ea0\u6b63\u66f4\u591a\u7684\u9519\u8bef\u3002"}}
{"id": "2511.00067", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00067", "abs": "https://arxiv.org/abs/2511.00067", "authors": ["Zhixing Li", "Arsham Gholamzadeh Khoee", "Yinan Yu"], "title": "Latent Domain Prompt Learning for Vision-Language Models", "comment": null, "summary": "The objective of domain generalization (DG) is to enable models to be robust\nagainst domain shift. DG is crucial for deploying vision-language models (VLMs)\nin real-world applications, yet most existing methods rely on domain labels\nthat may not be available and often ambiguous. We instead study the DG setting\nwhere models must generalize well without access to explicit domain labels. Our\nkey idea is to represent an unseen target domain as a combination of latent\ndomains automatically discovered from training data, enabling the model to\nadaptively transfer knowledge across domains. To realize this, we perform\nlatent domain clustering on image features and fuse domain-specific text\nfeatures based on the similarity between the input image and each latent\ndomain. Experiments on four benchmarks show that this strategy yields\nconsistent gains over VLM-based baselines and provides new insights into\nimproving robustness under domain shift.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u663e\u5f0f\u57df\u6807\u7b7e\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u57df\uff0c\u5e76\u5c06\u672a\u89c1\u76ee\u6807\u57df\u8868\u793a\u4e3a\u8fd9\u4e9b\u6f5c\u5728\u57df\u7684\u7ec4\u5408\uff0c\u4ece\u800c\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u57df\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u57df\u6807\u7b7e\uff0c\u4f46\u8fd9\u4e9b\u6807\u7b7e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u4e0d\u53ef\u5f97\u6216\u6a21\u7cca\u4e0d\u6e05\u3002\u672c\u6587\u7814\u7a76\u65e0\u9700\u663e\u5f0f\u57df\u6807\u7b7e\u7684DG\u8bbe\u7f6e\uff0c\u65e8\u5728\u63d0\u5347\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u80fd\u529b\u3002", "method": "\u5728\u56fe\u50cf\u7279\u5f81\u4e0a\u6267\u884c\u6f5c\u5728\u57df\u805a\u7c7b\uff0c\u5e76\u6839\u636e\u8f93\u5165\u56fe\u50cf\u4e0e\u6bcf\u4e2a\u6f5c\u5728\u57df\u7684\u76f8\u4f3c\u5ea6\u878d\u5408\u57df\u7279\u5b9a\u7684\u6587\u672c\u7279\u5f81\uff0c\u5b9e\u73b0\u8de8\u57df\u77e5\u8bc6\u7684\u81ea\u9002\u5e94\u8fc1\u79fb\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u4e8eVLM\u7684\u57fa\u7ebf\u6a21\u578b\u53d6\u5f97\u4e86\u7a33\u5b9a\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u57df\u504f\u79fb\u4e0b\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u81ea\u52a8\u53d1\u73b0\u6f5c\u5728\u57df\u6765\u5b9e\u73b0\u9886\u57df\u6cdb\u5316\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.01326", "categories": ["gr-qc", "astro-ph.CO", "astro-ph.HE", "hep-ph"], "pdf": "https://arxiv.org/pdf/2511.01326", "abs": "https://arxiv.org/abs/2511.01326", "authors": ["Aur\u00e9lien Barrau", "Killian Martineau", "Hanane Zelgoum"], "title": "Black holes in a dense infinite medium: a toy-model regularizing the Schwarzschild metric", "comment": null, "summary": "We revisit the dynamics of a black hole accreting energy from a surrounding\nhomogeneous and infinite space. We argue for a simple heuristic modification of\nthe Schwarzschild approximation when the density of the medium is not\nnegligible anymore. The resulting behavior is drastically modified: the mass\ndivergence at finite time is cured and the thermodynamical properties are\ndeeply changed. Some potential consequences for quantum gravity and bouncing\nmodels are also pointed out. Those conclusions being mostly obtained from a\nNewtonian approach, they only aim at guiding toward a more rigorous treatment.\nStill, interestingly, the behavior is far more convincing that the one usually\nobtained.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u7814\u7a76\u4e86\u9ed1\u6d1e\u4ece\u5468\u56f4\u5747\u5300\u65e0\u9650\u7a7a\u95f4\u5438\u79ef\u80fd\u91cf\u7684\u52a8\u529b\u5b66\uff0c\u63d0\u51fa\u4e86\u5f53\u4ecb\u8d28\u5bc6\u5ea6\u4e0d\u53ef\u5ffd\u7565\u65f6\u5bf9\u53f2\u74e6\u897f\u8fd1\u4f3c\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u4fee\u6b63\uff0c\u89e3\u51b3\u4e86\u8d28\u91cf\u5728\u6709\u9650\u65f6\u95f4\u5185\u53d1\u6563\u7684\u95ee\u9898\uff0c\u5e76\u663e\u8457\u6539\u53d8\u4e86\u70ed\u529b\u5b66\u6027\u8d28\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u9ed1\u6d1e\u5438\u79ef\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662f\u5f53\u5468\u56f4\u4ecb\u8d28\u5bc6\u5ea6\u4e0d\u53ef\u5ffd\u7565\u65f6\uff0c\u4f20\u7edf\u53f2\u74e6\u897f\u8fd1\u4f3c\u9700\u8981\u4fee\u6b63\uff0c\u4ee5\u89e3\u51b3\u8d28\u91cf\u53d1\u6563\u7b49\u4e0d\u5408\u7406\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u725b\u987f\u529b\u5b66\u65b9\u6cd5\uff0c\u5bf9\u53f2\u74e6\u897f\u8fd1\u4f3c\u8fdb\u884c\u7b80\u5355\u7684\u542f\u53d1\u5f0f\u4fee\u6b63\uff0c\u4e3b\u8981\u662f\u4e00\u79cd\u6307\u5bfc\u6027\u65b9\u6cd5\u800c\u975e\u4e25\u683c\u5904\u7406\u3002", "result": "\u4fee\u6b63\u540e\u7684\u884c\u4e3a\u663e\u8457\u6539\u5584\uff1a\u8d28\u91cf\u5728\u6709\u9650\u65f6\u95f4\u5185\u53d1\u6563\u7684\u95ee\u9898\u5f97\u5230\u89e3\u51b3\uff0c\u70ed\u529b\u5b66\u6027\u8d28\u53d1\u751f\u6df1\u523b\u53d8\u5316\uff0c\u7ed3\u679c\u6bd4\u901a\u5e38\u83b7\u5f97\u7684\u884c\u4e3a\u66f4\u4ee4\u4eba\u4fe1\u670d\u3002", "conclusion": "\u8fd9\u79cd\u4fee\u6b63\u65b9\u6cd5\u4e3a\u91cf\u5b50\u5f15\u529b\u548c\u53cd\u5f39\u6a21\u578b\u63d0\u4f9b\u4e86\u6f5c\u5728\u542f\u793a\uff0c\u867d\u7136\u57fa\u4e8e\u725b\u987f\u65b9\u6cd5\uff0c\u4f46\u4e3a\u66f4\u4e25\u683c\u5904\u7406\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2511.01080", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01080", "abs": "https://arxiv.org/abs/2511.01080", "authors": ["Jonathan Kunjummen", "Jacob M. Taylor"], "title": "In situ calibration of unitary operations during quantum error correction", "comment": null, "summary": "Quantum error correction uses the measurement of syndromes and classical\ndecoding algorithms to estimate the location and type of errors while\nprotecting the encoded quantum bits. Here we consider how prior information and\nBayesian updates can play a critical role in improving the performance of QEC\nin the scenario of a particularly noisy qubit. This allows for leveraging even\ndistance codes, which typically are less valued in QEC, to handle the noisy\nqubit, changing the power-law scaling of the logical error rate with the\nbaseline physical error rate. A crucial component of this is updating the prior\nby real time feeding of decoder outputs into a approximate Kalman filter. Thus\nour approach provides a bootstrap to the actual error rates. We show this via\nsimulation of the full closed-loop system: starting from uniform priors, the\nupdate procedure gradually learns site-specific error rates, enabling the\ndecoder to outperform a fixed-prior baseline. In turn, we show that this\nenables in situ calibration of unitary operations via injection of gate set\ntomography operations with only moderate overhead in the more typical scenario\nof low noise qubits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u66f4\u65b0\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u91cf\u5b50\u7ea0\u9519\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u89e3\u7801\u5668\u8f93\u51fa\u4fe1\u606f\u6765\u5b66\u4e60\u7279\u5b9a\u6bd4\u7279\u7684\u9519\u8bef\u7387\uff0c\u4ece\u800c\u63d0\u5347\u7ea0\u9519\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u91cf\u5b50\u7ea0\u9519\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u5148\u9a8c\u4fe1\u606f\uff0c\u65e0\u6cd5\u9002\u5e94\u7279\u5b9a\u566a\u58f0\u6bd4\u7279\u7684\u60c5\u51b5\u3002\u672c\u6587\u65e8\u5728\u5229\u7528\u5148\u9a8c\u4fe1\u606f\u548c\u8d1d\u53f6\u65af\u66f4\u65b0\u6765\u6539\u8fdb\u91cf\u5b50\u7ea0\u9519\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7279\u522b\u566a\u58f0\u6bd4\u7279\u7684\u573a\u666f\u4e0b\u3002", "method": "\u4f7f\u7528\u8fd1\u4f3c\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5b9e\u65f6\u53cd\u9988\u89e3\u7801\u5668\u8f93\u51fa\uff0c\u66f4\u65b0\u5148\u9a8c\u4fe1\u606f\uff0c\u5b66\u4e60\u7ad9\u70b9\u7279\u5b9a\u7684\u9519\u8bef\u7387\u3002\u901a\u8fc7\u6a21\u62df\u5b8c\u6574\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u4ece\u5747\u5300\u5148\u9a8c\u5f00\u59cb\uff0c\u9010\u6b65\u5b66\u4e60\u7279\u5b9a\u6bd4\u7279\u7684\u9519\u8bef\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4f7f\u89e3\u7801\u5668\u6027\u80fd\u8d85\u8fc7\u56fa\u5b9a\u5148\u9a8c\u57fa\u7ebf\uff0c\u6539\u53d8\u903b\u8f91\u9519\u8bef\u7387\u4e0e\u7269\u7406\u9519\u8bef\u7387\u7684\u5e42\u5f8b\u7f29\u653e\u5173\u7cfb\u3002\u5373\u4f7f\u5728\u4f4e\u566a\u58f0\u6bd4\u7279\u7684\u5178\u578b\u573a\u666f\u4e0b\uff0c\u4e5f\u80fd\u4ee5\u4e2d\u7b49\u5f00\u9500\u5b9e\u73b0\u95e8\u96c6\u5c42\u6790\u64cd\u4f5c\u7684\u73b0\u573a\u6821\u51c6\u3002", "conclusion": "\u8d1d\u53f6\u65af\u66f4\u65b0\u548c\u5b9e\u65f6\u53cd\u9988\u673a\u5236\u4e3a\u91cf\u5b50\u7ea0\u9519\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u4e3e\u65b9\u6cd5\uff0c\u80fd\u591f\u9002\u5e94\u7279\u5b9a\u566a\u58f0\u73af\u5883\uff0c\u63d0\u5347\u7ea0\u9519\u6027\u80fd\u5e76\u5b9e\u73b0\u73b0\u573a\u6821\u51c6\u3002"}}
{"id": "2511.00070", "categories": ["cs.LG", "cs.AI", "90C29 (Primary), 68T07, 65K05 (Secondary)", "G.1.6; I.2.6; J.6"], "pdf": "https://arxiv.org/pdf/2511.00070", "abs": "https://arxiv.org/abs/2511.00070", "authors": ["Muhammad Bilal Awan", "Abdul Razzaq", "Abdul Shahid"], "title": "Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design", "comment": "17 pages, 2 Figures", "summary": "This paper investigates the performance of Large Language Models (LLMs) as\ngenerative optimizers for solving constrained multi-objective regression tasks,\nspecifically within the challenging domain of inverse design\n(property-to-structure mapping). This problem, critical to materials\ninformatics, demands finding complex, feasible input vectors that lie on the\nPareto optimal front. While LLMs have demonstrated universal effectiveness\nacross generative and reasoning tasks, their utility in constrained,\ncontinuous, high-dimensional numerical spaces tasks they weren't explicitly\narchitected for remains an open research question. We conducted a rigorous\ncomparative study between established Bayesian Optimization (BO) frameworks and\na suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the\nfoundational BoTorch Ax implementation against the state-of-the-art q-Expected\nHypervolume Improvement (qEHVI, BoTorchM). The generative approach involved\nfine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the\nchallenge as a regression problem with a custom output head. Our results show\nthat BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the\nperformance ceiling. Crucially, the best-performing LLM (WizardMath-7B)\nachieved a Generational Distance (GD) of 1.21, significantly outperforming the\ntraditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO\nframeworks remain the performance leader for guaranteed convergence, but\nfine-tuned LLMs are validated as a promising, computationally fast alternative,\ncontributing essential comparative metrics to the field of AI-driven\noptimization. The findings have direct industrial applications in optimizing\nformulation design for resins, polymers, and paints, where multi-objective\ntrade-offs between mechanical, rheological, and chemical properties are\ncritical to innovation and production efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u4f18\u5316\u5668\u5728\u7ea6\u675f\u591a\u76ee\u6807\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u9006\u5411\u8bbe\u8ba1\u9886\u57df\u3002\u901a\u8fc7\u4e0e\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u7684\u5bf9\u6bd4\uff0c\u53d1\u73b0\u5fae\u8c03\u7684LLM\u5728\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4e13\u7528BO\u6846\u67b6\u5728\u6536\u655b\u4fdd\u8bc1\u65b9\u9762\u4ecd\u9886\u5148\u3002", "motivation": "\u7814\u7a76LLM\u5728\u7ea6\u675f\u3001\u8fde\u7eed\u3001\u9ad8\u7ef4\u6570\u503c\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u6548\u7528\uff0c\u8fd9\u4e9b\u4efb\u52a1\u5e76\u975eLLM\u7684\u539f\u59cb\u8bbe\u8ba1\u76ee\u6807\uff0c\u4f46\u5728\u6750\u6599\u4fe1\u606f\u5b66\u4e2d\u7684\u9006\u5411\u8bbe\u8ba1\u95ee\u9898\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8fdb\u884c\u4e86\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u4e0e\u5fae\u8c03LLM/BERT\u6a21\u578b\u7684\u6bd4\u8f83\u7814\u7a76\u3002BO\u65b9\u9762\u6d4b\u8bd5\u4e86BoTorch Ax\u548cqEHVI\uff0c\u751f\u6210\u65b9\u6cd5\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u5e26\u81ea\u5b9a\u4e49\u8f93\u51fa\u5934\u7684\u56de\u5f52\u95ee\u9898\u3002", "result": "BoTorch qEHVI\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u6536\u655b(GD=0.0)\uff0c\u800c\u8868\u73b0\u6700\u4f73\u7684LLM(WizardMath-7B)\u8fbe\u5230GD=1.21\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfBoTorch Ax\u57fa\u7ebf(GD=15.03)\u3002", "conclusion": "\u4e13\u7528BO\u6846\u67b6\u5728\u4fdd\u8bc1\u6536\u655b\u65b9\u9762\u4ecd\u662f\u6027\u80fd\u9886\u5148\u8005\uff0c\u4f46\u5fae\u8c03LLM\u88ab\u9a8c\u8bc1\u4e3a\u6709\u524d\u666f\u3001\u8ba1\u7b97\u5feb\u901f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3aAI\u9a71\u52a8\u4f18\u5316\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u6bd4\u8f83\u6307\u6807\u3002"}}
{"id": "2511.01330", "categories": ["gr-qc", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2511.01330", "abs": "https://arxiv.org/abs/2511.01330", "authors": ["Chunyu Zhang"], "title": "Analytical sensitivity curves of the second-generation time-delay interferometry", "comment": "Comments are welcome!", "summary": "Forthcoming space-based gravitational-wave (GW) detectors will employ\nsecond-generation time-delay interferometry (TDI) to suppress laser frequency\nnoise and achieve the sensitivity required for GW detection. We introduce an\ninverse light-path operator $\\mathcal{P}_{i_{1}i_{2}i_{3}\\ldots i_{n-1}i_{n}}$,\nwhich enables simple representation of second-generation TDI combinations and a\nconcise description of light propagation. Analytical expressions and\nhigh-accuracy approximate formulas are derived for the sky- and\npolarization-averaged response functions, noise power spectral densities\n(PSDs), and sensitivity curves of TDI Michelson, ($\\alpha,\\beta,\\gamma$),\nMonitor, Beacon, Relay, and Sagnac combinations, as well as their orthogonal\n$A, E, T$ channels. Our results show that: (i) second-generation TDIs have the\nsame sensitivities as their first-generation counterparts; (ii) the $A, E, T$\nsensitivities and the optimal sensitivity are independent of the TDI generation\nand specific combination; (iii) the $A$ and $E$ channels have equal averaged\nresponses, noise PSDs, and sensitivities, while the $T$ channel has much weaker\nresponse and sensitivity at low frequencies ($2\\pi fL/c\\lesssim3$); (iv) except\nfor the $(\\alpha,\\beta,\\gamma)$ and $\\zeta$ combinations and the $T$ channel,\nall sensitivity curves exhibit a flat section in the range $f_{n}<f\\lesssim\n1.5/(2\\pi L/c)$, where the noise-balance frequency $f_{n}$ separates the\nproof-mass- and optical-path-dominated regimes, while the response-transition\nfrequency $\\sim 1.5/(2\\pi L/c)$ separates the response function's low- and\nhigh-frequency behaviors; (v) the averaged response, noise PSD, and sensitivity\nof $\\zeta$ scales with those of the $T$ channel. These analytical and\napproximate formulations provide useful benchmarks for instrument optimization\nand data-analysis studies for future space-based GW detectors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f15\u5165\u9006\u5149\u7a0b\u7b97\u5b50\u7b80\u5316\u7b2c\u4e8c\u4ee3\u65f6\u95f4\u5ef6\u8fdf\u5e72\u6d89\u6d4b\u91cf(TDI)\u7ec4\u5408\u7684\u8868\u793a\uff0c\u63a8\u5bfc\u4e86\u5404\u79cdTDI\u7ec4\u5408\u7684\u54cd\u5e94\u51fd\u6570\u3001\u566a\u58f0\u529f\u7387\u8c31\u5bc6\u5ea6\u548c\u7075\u654f\u5ea6\u66f2\u7ebf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u8bc1\u660e\u4e86\u7b2c\u4e8c\u4ee3TDI\u4e0e\u7b2c\u4e00\u4ee3\u5177\u6709\u76f8\u540c\u7684\u7075\u654f\u5ea6\u3002", "motivation": "\u4e3a\u672a\u6765\u5929\u57fa\u5f15\u529b\u6ce2\u63a2\u6d4b\u5668\u5f00\u53d1\u7b80\u5316\u7684\u6570\u5b66\u5de5\u5177\u6765\u63cf\u8ff0\u7b2c\u4e8c\u4ee3\u65f6\u95f4\u5ef6\u8fdf\u5e72\u6d89\u6d4b\u91cf(TDI)\u7ec4\u5408\uff0c\u63d0\u4f9b\u5206\u6790\u8868\u8fbe\u5f0f\u548c\u8fd1\u4f3c\u516c\u5f0f\u7528\u4e8e\u4eea\u5668\u4f18\u5316\u548c\u6570\u636e\u5206\u6790\u7814\u7a76\u3002", "method": "\u5f15\u5165\u9006\u5149\u7a0b\u7b97\u5b50\u6765\u7b80\u5316\u7b2c\u4e8c\u4ee3TDI\u7ec4\u5408\u7684\u8868\u793a\uff0c\u63a8\u5bfc\u4e86TDI Michelson\u3001(\u03b1,\u03b2,\u03b3)\u3001Monitor\u3001Beacon\u3001Relay\u548cSagnac\u7ec4\u5408\u53ca\u5176\u6b63\u4ea4A\u3001E\u3001T\u901a\u9053\u7684\u54cd\u5e94\u51fd\u6570\u3001\u566a\u58f0\u529f\u7387\u8c31\u5bc6\u5ea6\u548c\u7075\u654f\u5ea6\u66f2\u7ebf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u9ad8\u7cbe\u5ea6\u8fd1\u4f3c\u516c\u5f0f\u3002", "result": "\u53d1\u73b0\u7b2c\u4e8c\u4ee3TDI\u4e0e\u7b2c\u4e00\u4ee3\u5177\u6709\u76f8\u540c\u7075\u654f\u5ea6\uff1bA\u3001E\u3001T\u901a\u9053\u7684\u7075\u654f\u5ea6\u548c\u6700\u4f18\u7075\u654f\u5ea6\u4e0eTDI\u4ee3\u6570\u548c\u5177\u4f53\u7ec4\u5408\u65e0\u5173\uff1bA\u548cE\u901a\u9053\u5177\u6709\u76f8\u7b49\u7684\u5e73\u5747\u54cd\u5e94\u3001\u566a\u58f0PSD\u548c\u7075\u654f\u5ea6\uff1bT\u901a\u9053\u5728\u4f4e\u9891\u54cd\u5e94\u8f83\u5f31\uff1b\u9664(\u03b1,\u03b2,\u03b3)\u548c\u03b6\u7ec4\u5408\u53caT\u901a\u9053\u5916\uff0c\u6240\u6709\u7075\u654f\u5ea6\u66f2\u7ebf\u5728\u7279\u5b9a\u9891\u7387\u8303\u56f4\u5185\u5448\u73b0\u5e73\u5766\u6bb5\u3002", "conclusion": "\u8fd9\u4e9b\u5206\u6790\u548c\u8fd1\u4f3c\u516c\u5f0f\u4e3a\u672a\u6765\u5929\u57fa\u5f15\u529b\u6ce2\u63a2\u6d4b\u5668\u7684\u4eea\u5668\u4f18\u5316\u548c\u6570\u636e\u5206\u6790\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u7b2c\u4e8c\u4ee3TDI\u7ec4\u5408\u7684\u6709\u6548\u6027\u548c\u6027\u80fd\u7279\u5f81\u3002"}}
{"id": "2511.01085", "categories": ["quant-ph", "math-ph", "math.MP", "81Q93"], "pdf": "https://arxiv.org/pdf/2511.01085", "abs": "https://arxiv.org/abs/2511.01085", "authors": ["Andre Luiz P. de Lima", "Luke S. Baker", "Anatoly Zlotnik", "Andrew K. Harter", "Michael J. Martin", "Jr-Shin Li"], "title": "Robust Quantum State Generation in Symmetric Spin Networks", "comment": "9 pages, 4 figures, 1 table", "summary": "In this work, we consider a parameterized Ising model with long-range\nsymmetric pairwise interactions on a network of spin $\\frac{1}{2}$ particles.\nThe system is designed with symmetric dynamics, allowing for the reduction of\nthe state space to a subspace defined by the set of Dicke states. We propose a\nmethod for designing robust electromagnetic amplitude pulses based on a moment\nquantization approach. The introduced parameter accounts for uncertainties in\nthe electromagnetic field, resulting in a family of distinct Hamiltonians. By\nemploying a discretized moment-based quantization technique, we design a\ncontrol pulse capable of simultaneously steering an infinite collection of\ndynamical systems to compensate for parameter variations. This approach\nbenefits from the duality between the infinite-dimensional parameterized system\nand its finite-dimensional trucnated moment dynamics. Simulation results\ndemonstrate the efficacy of this method in achieving states of significant\ninterest in quantum sensing, including the GHZ and W states.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e9\u91cf\u5316\u65b9\u6cd5\u7684\u9c81\u68d2\u7535\u78c1\u5e45\u5ea6\u8109\u51b2\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u53c2\u6570\u5316\u4f0a\u8f9b\u6a21\u578b\u4e2d\u7684\u91cf\u5b50\u6001\u63a7\u5236\uff0c\u80fd\u591f\u540c\u65f6\u8865\u507f\u53c2\u6570\u53d8\u5316\u5e76\u5b9e\u73b0GHZ\u548cW\u6001\u7b49\u91cf\u5b50\u4f20\u611f\u4e2d\u7684\u91cd\u8981\u72b6\u6001\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u957f\u7a0b\u5bf9\u79f0\u76f8\u4e92\u4f5c\u7528\u7684\u53c2\u6570\u5316\u4f0a\u8f9b\u6a21\u578b\uff0c\u8003\u8651\u7535\u78c1\u573a\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u53c2\u6570\u53d8\u5316\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u540c\u65f6\u63a7\u5236\u65e0\u9650\u591a\u4e2a\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u9c81\u68d2\u63a7\u5236\u8109\u51b2\u3002", "method": "\u91c7\u7528\u79bb\u6563\u5316\u77e9\u57fa\u91cf\u5316\u6280\u672f\uff0c\u5229\u7528\u53c2\u6570\u5316\u7cfb\u7edf\u4e0e\u5176\u6709\u9650\u7ef4\u622a\u65ad\u77e9\u52a8\u529b\u5b66\u4e4b\u95f4\u7684\u5bf9\u5076\u6027\uff0c\u8bbe\u8ba1\u63a7\u5236\u8109\u51b2\u6765\u540c\u65f6\u8865\u507f\u53c2\u6570\u53d8\u5316\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u91cf\u5b50\u4f20\u611f\u4e2d\u91cd\u8981\u7684GHZ\u6001\u548cW\u6001\u7b49\u91cf\u5b50\u6001\u3002", "conclusion": "\u57fa\u4e8e\u77e9\u91cf\u5316\u7684\u9c81\u68d2\u63a7\u5236\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u7cbe\u786e\u7684\u6001\u63a7\u5236\u3002"}}
{"id": "2511.00071", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00071", "abs": "https://arxiv.org/abs/2511.00071", "authors": ["Ertugrul Mutlu"], "title": "Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective", "comment": "8 pages, 2 figures. Code:\n  github.com/Ertugrulmutlu/Using-Wavelets-and-Clustering-to-Predict-Odd-or-Even-Numbers", "summary": "This paper explores a deliberately over-engineered approach to the classical\nproblem of parity detection -- determining whether a number is odd or even --\nby combining wavelet-based feature extraction with unsupervised clustering.\nInstead of relying on modular arithmetic, integers are transformed into\nwavelet-domain representations, from which multi-scale statistical features are\nextracted and clustered using the k-means algorithm. The resulting feature\nspace reveals meaningful structural differences between odd and even numbers,\nachieving a classification accuracy of approximately 69.67% without any label\nsupervision. These results suggest that classical signal-processing techniques,\noriginally designed for continuous data, can uncover latent structure even in\npurely discrete symbolic domains. Beyond parity detection, the study provides\nan illustrative perspective on how feature engineering and clustering may be\nrepurposed for unconventional machine learning problems, potentially bridging\nsymbolic reasoning and feature-based learning.", "AI": {"tldr": "\u4f7f\u7528\u5c0f\u6ce2\u53d8\u6362\u548ck-means\u805a\u7c7b\u68c0\u6d4b\u6570\u5b57\u5947\u5076\u6027\u7684\u8fc7\u5ea6\u5de5\u7a0b\u65b9\u6cd5\uff0c\u65e0\u9700\u76d1\u7763\u6807\u7b7e\u8fbe\u523069.67%\u51c6\u786e\u7387", "motivation": "\u63a2\u7d22\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u6280\u672f\u5982\u4f55\u63ed\u793a\u79bb\u6563\u7b26\u53f7\u57df\u4e2d\u7684\u6f5c\u5728\u7ed3\u6784\uff0c\u6865\u63a5\u7b26\u53f7\u63a8\u7406\u548c\u57fa\u4e8e\u7279\u5f81\u7684\u5b66\u4e60", "method": "\u5c06\u6574\u6570\u8f6c\u6362\u4e3a\u5c0f\u6ce2\u57df\u8868\u793a\uff0c\u63d0\u53d6\u591a\u5c3a\u5ea6\u7edf\u8ba1\u7279\u5f81\uff0c\u4f7f\u7528k-means\u7b97\u6cd5\u8fdb\u884c\u65e0\u76d1\u7763\u805a\u7c7b", "result": "\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u63ed\u793a\u4e86\u5947\u5076\u6570\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u5dee\u5f02\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523069.67%", "conclusion": "\u4fe1\u53f7\u5904\u7406\u6280\u672f\u53ef\u4ee5\u5e94\u7528\u4e8e\u79bb\u6563\u7b26\u53f7\u57df\uff0c\u7279\u5f81\u5de5\u7a0b\u548c\u805a\u7c7b\u53ef\u91cd\u65b0\u7528\u4e8e\u975e\u5e38\u89c4\u673a\u5668\u5b66\u4e60\u95ee\u9898"}}
{"id": "2511.01342", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01342", "abs": "https://arxiv.org/abs/2511.01342", "authors": ["Ke Wang", "Xiao-Xiong Zeng"], "title": "Hotspot Images Driven by Magnetic Reconnection in Kerr-Sen black hole", "comment": "19 pages, 7 figures", "summary": "In the Kerr-Sen black hole, this study investigates the changes in hotspot\nimages before and after the occurrence of magnetic reconnection. After\nreviewing the Comisso-Asenjo magnetic reconnection process and introducing the\nhotspot imaging method, we examine the temporal evolution of hotspot intensity,\nincluding when energy extraction occurs, when it does not occur, and when the\nobserver's azimuthal angle is altered. We also discuss the influence of the\nblack hole's expansion parameter and spin on hotspot imaging. The results\nindicate that the first flare may serve as a potential signature of ongoing\nenergy extraction: changing the observer's azimuthal angle may alter the time\ninterval between the first and second flares: a larger expansion parameter\nmakes it more difficult to identify the energy extraction signal, and a higher\nspin also makes it more challenging to detect the energy extraction signal.", "AI": {"tldr": "\u7814\u7a76Kerr-Sen\u9ed1\u6d1e\u4e2d\u78c1\u91cd\u8054\u524d\u540e\u70ed\u70b9\u56fe\u50cf\u7684\u53d8\u5316\uff0c\u53d1\u73b0\u7b2c\u4e00\u8000\u6591\u53ef\u4f5c\u4e3a\u80fd\u91cf\u63d0\u53d6\u7684\u6f5c\u5728\u7279\u5f81\uff0c\u89c2\u6d4b\u8005\u65b9\u4f4d\u89d2\u3001\u9ed1\u6d1e\u81a8\u80c0\u53c2\u6570\u548c\u81ea\u65cb\u90fd\u4f1a\u5f71\u54cd\u80fd\u91cf\u63d0\u53d6\u4fe1\u53f7\u7684\u68c0\u6d4b\u3002", "motivation": "\u7814\u7a76Kerr-Sen\u9ed1\u6d1e\u4e2d\u78c1\u91cd\u8054\u8fc7\u7a0b\u5bf9\u70ed\u70b9\u56fe\u50cf\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u80fd\u91cf\u63d0\u53d6\u7684\u89c2\u6d4b\u7279\u5f81\u3002", "method": "\u56de\u987eComisso-Asenjo\u78c1\u91cd\u8054\u8fc7\u7a0b\uff0c\u5f15\u5165\u70ed\u70b9\u6210\u50cf\u65b9\u6cd5\uff0c\u5206\u6790\u70ed\u70b9\u5f3a\u5ea6\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u5305\u62ec\u80fd\u91cf\u63d0\u53d6\u53d1\u751f\u4e0e\u4e0d\u53d1\u751f\u7684\u60c5\u51b5\uff0c\u4ee5\u53ca\u89c2\u6d4b\u8005\u65b9\u4f4d\u89d2\u53d8\u5316\u7684\u5f71\u54cd\u3002", "result": "\u7b2c\u4e00\u8000\u6591\u53ef\u80fd\u4f5c\u4e3a\u80fd\u91cf\u63d0\u53d6\u7684\u6f5c\u5728\u7279\u5f81\uff1b\u6539\u53d8\u89c2\u6d4b\u8005\u65b9\u4f4d\u89d2\u53ef\u80fd\u6539\u53d8\u7b2c\u4e00\u548c\u7b2c\u4e8c\u8000\u6591\u4e4b\u95f4\u7684\u65f6\u95f4\u95f4\u9694\uff1b\u8f83\u5927\u7684\u81a8\u80c0\u53c2\u6570\u548c\u8f83\u9ad8\u7684\u81ea\u65cb\u90fd\u4f7f\u80fd\u91cf\u63d0\u53d6\u4fe1\u53f7\u66f4\u96be\u8bc6\u522b\u3002", "conclusion": "\u78c1\u91cd\u8054\u8fc7\u7a0b\u5728Kerr-Sen\u9ed1\u6d1e\u4e2d\u4f1a\u4ea7\u751f\u53ef\u89c2\u6d4b\u7684\u70ed\u70b9\u56fe\u50cf\u53d8\u5316\uff0c\u7b2c\u4e00\u8000\u6591\u53ef\u4f5c\u4e3a\u80fd\u91cf\u63d0\u53d6\u7684\u6307\u793a\u5668\uff0c\u4f46\u9ed1\u6d1e\u53c2\u6570\u4f1a\u5f71\u54cd\u4fe1\u53f7\u7684\u53ef\u68c0\u6d4b\u6027\u3002"}}
{"id": "2511.01097", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01097", "abs": "https://arxiv.org/abs/2511.01097", "authors": ["Javier Rivera-Dean", "Lidija Petrovic", "Maciej Lewenstein", "Philipp Stammer"], "title": "Attosecond quantum optical interferometry", "comment": "14 pages (7 main text + 7 Supplementary Material), 9 figures (4 main\n  text + 5 Supplementary Material). Comments are welcome", "summary": "In this work, we explore the scheme of attosecond quantum interferometry\n(AQI), the quantum optical version of classical attosecond interferometry,\nwhich allows to measure quantum optical properties on the attosecond\ntime-scale. We develop how the scheme of AQI can be used for quantum state\nengineering of the emitted harmonics, by varying the relative phase of a\ntwo-color driving field, and further enables one to manipulate the field\ncorrelations as well as their entanglement characteristics. In addition, this\nscheme allows us to learn properties of the phase-space distribution of the\nharmonic quantum state, by means of measuring an attosecond quantum tomography\ntrace. This serves as a new type of protocol for in situ attosecond\nmeasurements of quantum optical observables. With this, we achieve to further\nconnect all-optical attosecond measurement schemes with quantum optics,\nallowing for a rich manifold of observations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u963f\u79d2\u91cf\u5b50\u5e72\u6d89\u6d4b\u91cf\u65b9\u6848\uff0c\u5c06\u7ecf\u5178\u963f\u79d2\u5e72\u6d89\u6d4b\u91cf\u6269\u5c55\u5230\u91cf\u5b50\u5149\u5b66\u9886\u57df\uff0c\u80fd\u591f\u5728\u963f\u79d2\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u6d4b\u91cf\u91cf\u5b50\u5149\u5b66\u7279\u6027\uff0c\u5e76\u7528\u4e8e\u91cf\u5b50\u6001\u5de5\u7a0b\u548c\u573a\u5173\u8054\u64cd\u63a7\u3002", "motivation": "\u5c06\u5168\u5149\u5b66\u963f\u79d2\u6d4b\u91cf\u65b9\u6848\u4e0e\u91cf\u5b50\u5149\u5b66\u8fde\u63a5\u8d77\u6765\uff0c\u5b9e\u73b0\u5728\u963f\u79d2\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u6d4b\u91cf\u91cf\u5b50\u5149\u5b66\u53ef\u89c2\u6d4b\u91cf\uff0c\u5e76\u64cd\u63a7\u8c10\u6ce2\u7684\u91cf\u5b50\u6001\u7279\u6027\u3002", "method": "\u5f00\u53d1\u963f\u79d2\u91cf\u5b50\u5e72\u6d89\u6d4b\u91cf\u65b9\u6848\uff0c\u901a\u8fc7\u6539\u53d8\u53cc\u8272\u9a71\u52a8\u573a\u7684\u76f8\u5bf9\u76f8\u4f4d\u6765\u8fdb\u884c\u91cf\u5b50\u6001\u5de5\u7a0b\uff0c\u6d4b\u91cf\u963f\u79d2\u91cf\u5b50\u5c42\u6790\u8ff9\u6765\u83b7\u53d6\u8c10\u6ce2\u91cf\u5b50\u6001\u7684\u76f8\u7a7a\u95f4\u5206\u5e03\u7279\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u8c10\u6ce2\u53d1\u5c04\u7684\u91cf\u5b50\u6001\u5de5\u7a0b\uff0c\u80fd\u591f\u64cd\u63a7\u573a\u5173\u8054\u53ca\u5176\u7ea0\u7f20\u7279\u6027\uff0c\u5efa\u7acb\u4e86\u7528\u4e8e\u539f\u4f4d\u963f\u79d2\u6d4b\u91cf\u91cf\u5b50\u5149\u5b66\u53ef\u89c2\u6d4b\u91cf\u7684\u65b0\u578b\u534f\u8bae\u3002", "conclusion": "\u8be5\u65b9\u6848\u6210\u529f\u8fde\u63a5\u4e86\u5168\u5149\u5b66\u963f\u79d2\u6d4b\u91cf\u4e0e\u91cf\u5b50\u5149\u5b66\uff0c\u4e3a\u5b9e\u73b0\u4e30\u5bcc\u7684\u89c2\u6d4b\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4e3a\u963f\u79d2\u65f6\u95f4\u5c3a\u5ea6\u7684\u91cf\u5b50\u5149\u5b66\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.00076", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00076", "abs": "https://arxiv.org/abs/2511.00076", "authors": ["Zihao Wan", "Pau Tong Lin Xu", "Fuwen Luo", "Ziyue Wang", "Peng Li", "Yang Liu"], "title": "Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with B\u00e9zier Curves", "comment": null, "summary": "While Vision-language Models (VLMs) have demonstrated strong semantic\ncapabilities, their ability to interpret the underlying geometric structure of\nvisual information is less explored. Pictographic characters, which combine\nvisual form with symbolic structure, provide an ideal test case for this\ncapability. We formulate this visual recognition challenge in the mathematical\ndomain, where each character is represented by an executable program of\ngeometric primitives. This is framed as a program synthesis task, training a\nVLM to decompile raster images into programs composed of B\\'ezier curves. Our\nmodel, acting as a \"visual decompiler\", demonstrates performance superior to\nstrong zero-shot baselines, including GPT-4o. The most significant finding is\nthat when trained solely on modern Chinese characters, the model is able to\nreconstruct ancient Oracle Bone Script in a zero-shot context. This\ngeneralization provides strong evidence that the model acquires an abstract and\ntransferable geometric grammar, moving beyond pixel-level pattern recognition\nto a more structured form of visual understanding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u89c6\u89c9\u51e0\u4f55\u7ed3\u6784\u65b9\u9762\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u5c06\u8c61\u5f62\u6587\u5b57\u8bc6\u522b\u6784\u5efa\u4e3a\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\uff0c\u8bad\u7ec3VLM\u5c06\u6805\u683c\u56fe\u50cf\u53cd\u7f16\u8bd1\u4e3a\u7531\u8d1d\u585e\u5c14\u66f2\u7ebf\u7ec4\u6210\u7684\u51e0\u4f55\u7a0b\u5e8f\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u89c6\u89c9\u4fe1\u606f\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u8c61\u5f62\u6587\u5b57\u7ed3\u5408\u4e86\u89c6\u89c9\u5f62\u5f0f\u548c\u7b26\u53f7\u7ed3\u6784\uff0c\u4e3a\u6b64\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u6848\u4f8b\u3002", "method": "\u5c06\u89c6\u89c9\u8bc6\u522b\u6311\u6218\u6784\u5efa\u4e3a\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\uff0c\u8bad\u7ec3VLM\u5c06\u6805\u683c\u56fe\u50cf\u53cd\u7f16\u8bd1\u4e3a\u7531\u8d1d\u585e\u5c14\u66f2\u7ebf\u7ec4\u6210\u7684\u51e0\u4f55\u7a0b\u5e8f\uff0c\u6a21\u578b\u4f5c\u4e3a\"\u89c6\u89c9\u53cd\u7f16\u8bd1\u5668\"\u5de5\u4f5c\u3002", "result": "\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5f3a\u5927\u7684\u96f6\u6837\u672c\u57fa\u7ebf\uff08\u5305\u62ecGPT-4o\uff09\uff0c\u6700\u663e\u8457\u7684\u53d1\u73b0\u662f\u4ec5\u5728\u73b0\u4ee3\u6c49\u5b57\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u91cd\u5efa\u53e4\u4ee3\u7532\u9aa8\u6587\u3002", "conclusion": "\u8fd9\u79cd\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u8bc1\u636e\uff0c\u8868\u660e\u6a21\u578b\u83b7\u5f97\u4e86\u62bd\u8c61\u4e14\u53ef\u8f6c\u79fb\u7684\u51e0\u4f55\u8bed\u6cd5\uff0c\u8d85\u8d8a\u4e86\u50cf\u7d20\u7ea7\u6a21\u5f0f\u8bc6\u522b\uff0c\u8fbe\u5230\u4e86\u66f4\u7ed3\u6784\u5316\u7684\u89c6\u89c9\u7406\u89e3\u5f62\u5f0f\u3002"}}
{"id": "2511.01367", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01367", "abs": "https://arxiv.org/abs/2511.01367", "authors": ["Hao Chen", "Meng-Yao Zhang", "Hassan Hassanabadi", "Qihong Huang", "Zheng-Wen Long"], "title": "Novel topological subclass in Hourava-Lifshitz black holes", "comment": "9pages, 7 figures", "summary": "This work explores the universal classification of thermodynamic topology for\ncharged static black holes within the $z=3$ Ho\\u{r}ava-Lifshitz gravity theory,\nconsidering both canonical and grand canonical ensembles. We introduce a new\ntopological subclass, denoted as $\\ddot{W}^{1-}$. This finding expands the\nexisting topological classification, going beyond the five previously defined\nclasses and their respective subclasses. The $\\ddot{W}^{1-}$ subclass presents\na distinct and previously unobserved stability profile: In the low-temperature\nregime, an unstable small black hole appears in the phase space, whereas, while\nin the high temperature regime, two unstable small black holes exist together\nwith a stable large black hole. Our study underscores the dependence of charged\nblack hole stability on the selection of the ensemble. These results contribute\nto refining and expanding the topological framework in black hole\nthermodynamics, providing key perspectives on the underlying nature of black\nholes and gravity.", "AI": {"tldr": "\u672c\u6587\u5728z=3 Ho\u0159ava-Lifshitz\u5f15\u529b\u7406\u8bba\u4e2d\uff0c\u5bf9\u5e26\u7535\u9759\u6001\u9ed1\u6d1e\u7684\u70ed\u529b\u5b66\u62d3\u6251\u8fdb\u884c\u4e86\u666e\u904d\u5206\u7c7b\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u62d3\u6251\u5b50\u7c7b$\\ddot{W}^{1-}$\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u63a2\u7d22\u5e26\u7535\u9ed1\u6d1e\u5728Ho\u0159ava-Lifshitz\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u70ed\u529b\u5b66\u62d3\u6251\u6027\u8d28\uff0c\u5b8c\u5584\u73b0\u6709\u7684\u62d3\u6251\u5206\u7c7b\u6846\u67b6\u3002", "method": "\u5728\u6b63\u5219\u7cfb\u7efc\u548c\u5927\u6b63\u5219\u7cfb\u7efc\u4e0b\uff0c\u5206\u6790z=3 Ho\u0159ava-Lifshitz\u5f15\u529b\u4e2d\u5e26\u7535\u9759\u6001\u9ed1\u6d1e\u7684\u70ed\u529b\u5b66\u62d3\u6251\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u62d3\u6251\u5b50\u7c7b$\\ddot{W}^{1-}$\uff0c\u8be5\u5b50\u7c7b\u8868\u73b0\u51fa\u72ec\u7279\u7684\u7a33\u5b9a\u6027\u7279\u5f81\uff1a\u4f4e\u6e29\u4e0b\u76f8\u7a7a\u95f4\u4e2d\u5b58\u5728\u4e00\u4e2a\u4e0d\u7a33\u5b9a\u7684\u5c0f\u9ed1\u6d1e\uff0c\u9ad8\u6e29\u4e0b\u5219\u6709\u4e24\u4e2a\u4e0d\u7a33\u5b9a\u7684\u5c0f\u9ed1\u6d1e\u548c\u4e00\u4e2a\u7a33\u5b9a\u7684\u5927\u9ed1\u6d1e\u5171\u5b58\u3002", "conclusion": "\u5e26\u7535\u9ed1\u6d1e\u7684\u7a33\u5b9a\u6027\u4f9d\u8d56\u4e8e\u7cfb\u7efc\u7684\u9009\u62e9\uff0c\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u5b8c\u5584\u9ed1\u6d1e\u70ed\u529b\u5b66\u7684\u62d3\u6251\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u9ed1\u6d1e\u548c\u5f15\u529b\u7684\u672c\u8d28\u63d0\u4f9b\u4e86\u91cd\u8981\u89c6\u89d2\u3002"}}
{"id": "2511.01108", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.01108", "abs": "https://arxiv.org/abs/2511.01108", "authors": ["Adrian Harkness", "Hamidreza Validi", "Ramin Fakhimi", "Illya V. Hicks", "Tam\u00e1s Terlaky", "Luis F. Zuluaga"], "title": "Characterizing QUBO Reformulations of the Max-k-Cut Problem for Quantum Computing", "comment": "21 pages, 8 figures", "summary": "Quantum computing offers significant potential for solving NP-hard\ncombinatorial (optimization) problems that are beyond the reach of classical\ncomputers. One way to tap into this potential is by reformulating combinatorial\nproblems as a quadratic unconstrained binary optimization (QUBO) problem. The\nsolution of the QUBO reformulation can then be addressed using adiabatic\nquantum computing devices or appropriate quantum computing algorithms on\ngate-based quantum computing devices. In general, QUBO reformulations of\ncombinatorial problems can be readily obtained by properly penalizing the\nviolation of the problem's constraints in the original problem's objective.\nHowever, characterizing tight (i.e., minimal but sufficient) penalty\ncoefficients for this purpose is critical for enabling the solution of the\nresulting QUBO in current and near-term quantum computing devices. Along these\nlines, we here focus on the (weighted) max $k$-cut problem, a fundamental\ncombinatorial problem with wide-ranging applications that generalizes the\nwell-known max cut problem. We present closed-form characterizations of tight\npenalty coefficients for two distinct QUBO reformulations of the max $k$-cut\nproblem whose values depend on the (weighted) degree of the vertices of the\ngraph defining the problem. These findings contribute to the ongoing effort to\nmake quantum computing a viable tool for solving combinatorial problems at\nscale. We support our theoretical results with illustrative examples. Further,\nwe benchmark the proposed QUBO reformulations to solve the max $k$-cut problem\non a quantum computer simulator.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u6700\u5927k\u5272\u95ee\u9898\u7684\u4e24\u79cdQUBO\u91cd\u6784\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u7d27\u81f4\u60e9\u7f5a\u7cfb\u6570\u7684\u95ed\u5f0f\u8868\u5f81\uff0c\u8fd9\u4e9b\u7cfb\u6570\u4f9d\u8d56\u4e8e\u56fe\u7684\u9876\u70b9\u52a0\u6743\u5ea6\u6570\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5728\u89e3\u51b3NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5c06\u95ee\u9898\u91cd\u6784\u4e3aQUBO\u5f62\u5f0f\u3002\u786e\u5b9a\u7d27\u81f4\u7684\u60e9\u7f5a\u7cfb\u6570\u5bf9\u4e8e\u5728\u73b0\u6709\u548c\u8fd1\u671f\u91cf\u5b50\u8ba1\u7b97\u8bbe\u5907\u4e0a\u6c42\u89e3\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6700\u5927k\u5272\u95ee\u9898\u7684QUBO\u91cd\u6784\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ed\u5f0f\u8868\u5f81\u786e\u5b9a\u4e86\u4f9d\u8d56\u4e8e\u56fe\u9876\u70b9\u52a0\u6743\u5ea6\u6570\u7684\u7d27\u81f4\u60e9\u7f5a\u7cfb\u6570\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u901a\u8fc7\u793a\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u5728\u91cf\u5b50\u8ba1\u7b97\u673a\u6a21\u62df\u5668\u4e0a\u5bf9\u63d0\u51fa\u7684QUBO\u91cd\u6784\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u63a8\u52a8\u91cf\u5b50\u8ba1\u7b97\u6210\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u7ec4\u5408\u95ee\u9898\u7684\u53ef\u884c\u5de5\u5177\u3002"}}
{"id": "2511.00079", "categories": ["cs.LG", "cs.CY", "stat.ME", "62-04, 62-07", "D.2.11; G.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.00079", "abs": "https://arxiv.org/abs/2511.00079", "authors": ["Maximilian Willer", "Peter Ruckdeschel"], "title": "flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R", "comment": "27 pages, 7 figures, 1 table", "summary": "flowengineR is an R package designed to provide a modular and extensible\nframework for building reproducible algorithmic workflows for general-purpose\nmachine learning pipelines. It is motivated by the rapidly evolving field of\nalgorithmic fairness where new metrics, mitigation strategies, and machine\nlearning methods continuously emerge. A central challenge in fairness, but also\nfar beyond, is that existing toolkits either focus narrowly on single\ninterventions or treat reproducibility and extensibility as secondary\nconsiderations rather than core design principles. flowengineR addresses this\nby introducing a unified architecture of standardized engines for data\nsplitting, execution, preprocessing, training, inprocessing, postprocessing,\nevaluation, and reporting. Each engine encapsulates one methodological task yet\ncommunicates via a lightweight interface, ensuring workflows remain\ntransparent, auditable, and easily extensible. Although implemented in R,\nflowengineR builds on ideas from workflow languages (CWL, YAWL), graph-oriented\nvisual programming languages (KNIME), and R frameworks (BatchJobs, batchtools).\nIts emphasis, however, is less on orchestrating engines for resilient parallel\nexecution but rather on the straightforward setup and management of distinct\nengines as data structures. This orthogonalization enables distributed\nresponsibilities, independent development, and streamlined integration. In\nfairness context, by structuring fairness methods as interchangeable engines,\nflowengineR lets researchers integrate, compare, and evaluate interventions\nacross the modeling pipeline. At the same time, the architecture generalizes to\nexplainability, robustness, and compliance metrics without core modifications.\nWhile motivated by fairness, it ultimately provides a general infrastructure\nfor any workflow context where reproducibility, transparency, and extensibility\nare essential.", "AI": {"tldr": "flowengineR\u662f\u4e00\u4e2aR\u5305\uff0c\u4e3a\u6784\u5efa\u53ef\u590d\u73b0\u7684\u901a\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5de5\u4f5c\u6d41\u63d0\u4f9b\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u7279\u522b\u5173\u6ce8\u7b97\u6cd5\u516c\u5e73\u6027\u9886\u57df\u3002", "motivation": "\u7b97\u6cd5\u516c\u5e73\u6027\u9886\u57df\u5feb\u901f\u53d1\u5c55\uff0c\u65b0\u6307\u6807\u3001\u7f13\u89e3\u7b56\u7565\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e0d\u65ad\u6d8c\u73b0\uff0c\u73b0\u6709\u5de5\u5177\u5305\u8981\u4e48\u4e13\u6ce8\u4e8e\u5355\u4e00\u5e72\u9884\uff0c\u8981\u4e48\u5c06\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u4f5c\u4e3a\u6b21\u8981\u8003\u8651\u800c\u975e\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u6807\u51c6\u5316\u5f15\u64ce\u67b6\u6784\uff0c\u5305\u62ec\u6570\u636e\u5206\u5272\u3001\u6267\u884c\u3001\u9884\u5904\u7406\u3001\u8bad\u7ec3\u3001\u5904\u7406\u4e2d\u3001\u540e\u5904\u7406\u3001\u8bc4\u4f30\u548c\u62a5\u544a\u7b49\u6a21\u5757\u3002\u6bcf\u4e2a\u5f15\u64ce\u5c01\u88c5\u4e00\u4e2a\u65b9\u6cd5\u4efb\u52a1\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a5\u53e3\u901a\u4fe1\uff0c\u786e\u4fdd\u5de5\u4f5c\u6d41\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u4e14\u6613\u4e8e\u6269\u5c55\u3002", "result": "\u901a\u8fc7\u5c06\u516c\u5e73\u6027\u65b9\u6cd5\u6784\u5efa\u4e3a\u53ef\u4e92\u6362\u7684\u5f15\u64ce\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u5728\u5efa\u6a21\u6d41\u7a0b\u4e2d\u96c6\u6210\u3001\u6bd4\u8f83\u548c\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\u3002\u8be5\u67b6\u6784\u8fd8\u53ef\u63a8\u5e7f\u5230\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u548c\u5408\u89c4\u6027\u6307\u6807\uff0c\u65e0\u9700\u6838\u5fc3\u4fee\u6539\u3002", "conclusion": "\u867d\u7136\u53d7\u516c\u5e73\u6027\u7814\u7a76\u542f\u53d1\uff0c\u4f46flowengineR\u6700\u7ec8\u4e3a\u4efb\u4f55\u9700\u8981\u53ef\u590d\u73b0\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u7684\u5de5\u4f5c\u6d41\u573a\u666f\u63d0\u4f9b\u901a\u7528\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2511.01402", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01402", "abs": "https://arxiv.org/abs/2511.01402", "authors": ["Massimo Bianchi", "Donato Bini", "Giorgio Di Russo"], "title": "Scalar self-force effects in neutral $W$-soliton backgrounds", "comment": "23 pages, 3 figures", "summary": "We investigate several geometrical and physical properties of the recently\nfound $W$-soliton solution (neutral case). We discuss both the genuine 5d\nsolution and its reduction to 4d and highlight similarities and differences. In\nboth cases, we study scattering processes of massless and massive particles in\nthe background, reconstructing the gauge-invariant scattering angle, either\nwith exact expressions or with large-angular momentum expansion expressions,\nwhich we show how to resum in a useful form. Finally, we analyze the\npropagation of a test scalar field in the $W$-soliton background and compute\nthe spectrum of Quasi Normal Modes in the case of (non-)minimal coupling and\nthe radiated energy in the case of minimal coupling. Our result for the energy\nloss is fully analytic and presented in a Post-Newtonian expansion, following\nthe approach termed gravitational self force.", "AI": {"tldr": "\u7814\u7a76W-\u5b64\u5b50\u89e3\u7684\u51e0\u4f55\u548c\u7269\u7406\u6027\u8d28\uff0c\u5305\u62ec5\u7ef4\u89e3\u53ca\u51764\u7ef4\u7ea6\u5316\uff0c\u5206\u6790\u7c92\u5b50\u6563\u5c04\u8fc7\u7a0b\u548c\u51c6\u6b63\u89c4\u6a21\u8c31\u3002", "motivation": "\u63a2\u7d22\u65b0\u53d1\u73b0\u7684W-\u5b64\u5b50\u89e3\u57285\u7ef4\u548c4\u7ef4\u60c5\u51b5\u4e0b\u7684\u51e0\u4f55\u4e0e\u7269\u7406\u7279\u6027\uff0c\u7279\u522b\u662f\u6563\u5c04\u8fc7\u7a0b\u548c\u51c6\u6b63\u89c4\u6a21\u884c\u4e3a\u3002", "method": "\u7814\u7a765\u7ef4W-\u5b64\u5b50\u89e3\u53ca\u51764\u7ef4\u7ea6\u5316\uff0c\u5206\u6790\u8d28\u91cf/\u65e0\u8d28\u91cf\u7c92\u5b50\u6563\u5c04\uff0c\u8ba1\u7b97\u89c4\u8303\u4e0d\u53d8\u6563\u5c04\u89d2\uff0c\u7814\u7a76\u6807\u91cf\u573a\u4f20\u64ad\u548c\u51c6\u6b63\u89c4\u6a21\u8c31\u3002", "result": "\u83b7\u5f97\u4e86\u6563\u5c04\u89d2\u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\u548c\u5927\u89d2\u52a8\u91cf\u5c55\u5f00\u5f0f\uff0c\u8ba1\u7b97\u4e86\u51c6\u6b63\u89c4\u6a21\u8c31\u548c\u8f90\u5c04\u80fd\u91cf\u635f\u5931\uff0c\u540e\u8005\u4ee5\u5168\u89e3\u6790\u7684\u540e\u725b\u987f\u5c55\u5f00\u5f62\u5f0f\u7ed9\u51fa\u3002", "conclusion": "W-\u5b64\u5b50\u89e3\u57285\u7ef4\u548c4\u7ef4\u60c5\u51b5\u4e0b\u5c55\u73b0\u51fa\u76f8\u4f3c\u7684\u7269\u7406\u7279\u6027\uff0c\u4f46\u5b58\u5728\u91cd\u8981\u5dee\u5f02\uff0c\u6563\u5c04\u8fc7\u7a0b\u548c\u51c6\u6b63\u89c4\u6a21\u5206\u6790\u4e3a\u7406\u89e3\u8be5\u89e3\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.01179", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01179", "abs": "https://arxiv.org/abs/2511.01179", "authors": ["Xiangjing Liu", "Harshit Verma", "Yunlong Xiao", "Oscar Dahlsten", "Mile Gu"], "title": "Spatial Incompatibility Witnesses for Quantum Temporal Correlations", "comment": "18 pages, 2 figures, Comments are welcome!", "summary": "We introduce a witness-based framework for certifying quantum temporal\ncorrelations via the pseudo-density matrix (PDM) formalism, which is a\nspatiotemporal generalization of the density matrix. We define spatial\nincompatibility (SI) as the minimum distance between a PDM and valid density\nmatrices. For trace-norm distance, we show that this reduces to the PDM's\nnegativity, enabling the construction of experimentally accessible SI\nwitnesses. We derive a tight bound on SI for quantum channels and analyze the\nrespective roles of state and channel coherence in witnessing SI. Crucially, SI\nwitnesses certify temporal correlations across a strictly broader class of\nchannels than Leggett-Garg (LG) tests. Our approach, unlike the LG framework,\nexploits incompatible measurements that generate coherence through state\ndisturbance. We further show that channels satisfying the LG inequality for\nincoherent states can still exhibit detectable SI, demonstrating that\nmeasurement disturbance enhances the certification of temporal correlations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4f2a\u5bc6\u5ea6\u77e9\u9635\u7684\u89c1\u8bc1\u6846\u67b6\u6765\u8ba4\u8bc1\u91cf\u5b50\u65f6\u95f4\u5173\u8054\uff0c\u5b9a\u4e49\u4e86\u7a7a\u95f4\u4e0d\u517c\u5bb9\u6027\u4f5c\u4e3a\u4f2a\u5bc6\u5ea6\u77e9\u9635\u4e0e\u6709\u6548\u5bc6\u5ea6\u77e9\u9635\u7684\u6700\u5c0f\u8ddd\u79bb\uff0c\u5e76\u6784\u5efa\u4e86\u5b9e\u9a8c\u53ef\u8bbf\u95ee\u7684SI\u89c1\u8bc1\u3002", "motivation": "\u73b0\u6709Leggett-Garg\u6846\u67b6\u5728\u8ba4\u8bc1\u65f6\u95f4\u5173\u8054\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u6765\u5229\u7528\u6d4b\u91cf\u6270\u52a8\u589e\u5f3a\u65f6\u95f4\u5173\u8054\u7684\u8ba4\u8bc1\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u4f2a\u5bc6\u5ea6\u77e9\u9635\u5f62\u5f0f\u4f53\u7cfb\uff0c\u5b9a\u4e49\u7a7a\u95f4\u4e0d\u517c\u5bb9\u6027\u4e3a\u4f2a\u5bc6\u5ea6\u77e9\u9635\u4e0e\u6709\u6548\u5bc6\u5ea6\u77e9\u9635\u7684\u6700\u5c0f\u8ddd\u79bb\uff0c\u5bf9\u4e8e\u8ff9\u8303\u6570\u8ddd\u79bb\uff0c\u8fd9\u7b80\u5316\u4e3aPDM\u7684\u8d1f\u6027\uff0c\u4ece\u800c\u6784\u5efaSI\u89c1\u8bc1\u3002", "result": "SI\u89c1\u8bc1\u6bd4Leggett-Garg\u6d4b\u8bd5\u80fd\u8ba4\u8bc1\u66f4\u5e7f\u6cdb\u901a\u9053\u7c7b\u522b\u7684\u65f6\u95f4\u5173\u8054\uff0c\u6d4b\u91cf\u6270\u52a8\u589e\u5f3a\u4e86\u65f6\u95f4\u5173\u8054\u7684\u8ba4\u8bc1\u80fd\u529b\uff0c\u6ee1\u8db3LG\u4e0d\u7b49\u5f0f\u7684\u901a\u9053\u4ecd\u53ef\u68c0\u6d4b\u5230SI\u3002", "conclusion": "\u57fa\u4e8e\u4f2a\u5bc6\u5ea6\u77e9\u9635\u7684\u7a7a\u95f4\u4e0d\u517c\u5bb9\u6027\u6846\u67b6\u63d0\u4f9b\u4e86\u6bd4Leggett-Garg\u6d4b\u8bd5\u66f4\u5f3a\u5927\u7684\u65f6\u95f4\u5173\u8054\u8ba4\u8bc1\u5de5\u5177\uff0c\u6d4b\u91cf\u6270\u52a8\u5728\u8ba4\u8bc1\u65f6\u95f4\u5173\u8054\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.00083", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00083", "abs": "https://arxiv.org/abs/2511.00083", "authors": ["Shakib Khan", "A. Ben Hamza", "Amr Youssef"], "title": "Fixed-point graph convolutional networks against adversarial attacks", "comment": null, "summary": "Adversarial attacks present a significant risk to the integrity and\nperformance of graph neural networks, particularly in tasks where graph\nstructure and node features are vulnerable to manipulation. In this paper, we\npresent a novel model, called fixed-point iterative graph convolutional network\n(Fix-GCN), which achieves robustness against adversarial perturbations by\neffectively capturing higher-order node neighborhood information in the graph\nwithout additional memory or computational complexity. Specifically, we\nintroduce a versatile spectral modulation filter and derive the feature\npropagation rule of our model using fixed-point iteration. Unlike traditional\ndefense mechanisms that rely on additional design elements to counteract\nattacks, the proposed graph filter provides a flexible-pass filtering approach,\nallowing it to selectively attenuate high-frequency components while preserving\nlow-frequency structural information in the graph signal. By iteratively\nupdating node representations, our model offers a flexible and efficient\nframework for preserving essential graph information while mitigating the\nimpact of adversarial manipulation. We demonstrate the effectiveness of the\nproposed model through extensive experiments on various benchmark graph\ndatasets, showcasing its resilience against adversarial attacks.", "AI": {"tldr": "\u63d0\u51faFix-GCN\u6a21\u578b\uff0c\u901a\u8fc7\u56fa\u5b9a\u70b9\u8fed\u4ee3\u56fe\u5377\u79ef\u7f51\u7edc\u5b9e\u73b0\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\uff0c\u5229\u7528\u8c31\u8c03\u5236\u6ee4\u6ce2\u5668\u9009\u62e9\u6027\u8870\u51cf\u9ad8\u9891\u6210\u5206\uff0c\u4fdd\u62a4\u56fe\u7ed3\u6784\u4fe1\u606f\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5728\u56fe\u7ed3\u6784\u548c\u8282\u70b9\u7279\u5f81\u6613\u53d7\u64cd\u7eb5\u7684\u4efb\u52a1\u4e2d\uff0c\u9700\u8981\u5f00\u53d1\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u5f15\u5165\u901a\u7528\u8c31\u8c03\u5236\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u56fa\u5b9a\u70b9\u8fed\u4ee3\u63a8\u5bfc\u7279\u5f81\u4f20\u64ad\u89c4\u5219\uff0c\u63d0\u4f9b\u7075\u6d3b\u901a\u5e26\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u8870\u51cf\u9ad8\u9891\u6210\u5206\u540c\u65f6\u4fdd\u7559\u4f4e\u9891\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u6709\u6548\u62b5\u6297\u5bf9\u6297\u653b\u51fb\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "Fix-GCN\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u57fa\u672c\u56fe\u4fe1\u606f\u7684\u540c\u65f6\u51cf\u8f7b\u5bf9\u6297\u64cd\u7eb5\u7684\u5f71\u54cd\uff0c\u65e0\u9700\u989d\u5916\u5185\u5b58\u6216\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.01447", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01447", "abs": "https://arxiv.org/abs/2511.01447", "authors": ["Yong Song", "Jiaqi Fu", "Yiting Cen"], "title": "Robustness of timelike circular orbit topology against particle spin", "comment": "15 pages, 15 figures", "summary": "Based on a detailed study of the motion of spinning test particles within the\nMathisson-Papapetrou-Dixon formalism under the Tulczyjew spin-supplementary\ncondition in static, spherically symmetric spacetimes, we investigate the\ntopological properties of timelike circular orbits (TCOs) for such particles.\nBy constructing an auxiliary potential and an associated vector field on the\nequatorial plane, we compute the topological winding number W for regions\nbetween horizons and outside the outermost horizon in asymptotically flat,\nanti-de Sitter (AdS), and de Sitter (dS) black hole spacetimes. Our results\nshow that between two neighboring horizons (including the cosmological horizon\nin the dS case), the topological number is W=-1, indicating the presence of at\nleast one unstable TCO. Outside the outermost horizon, we find W=0 for both\nasymptotically flat and AdS black holes, implying that any TCOs must appear in\nstable-unstable pairs or be absent. These conclusions are independent of the\nspin orientation (co-rotating or counter-rotating) of the test particle. The\nanalysis is supported by explicit examples in Schwarzschild, Schwarzschild-AdS,\nand Schwarzschild-dS spacetimes, confirming the general topological\npredictions. While the effective potential for spinning particles has been\npreviously studied, the topological approach employed here reveals invariant\nproperties that remain robust even when spin is included, thereby highlighting\nthe fundamental influence of the spacetime structure itself.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u62d3\u6251\u65b9\u6cd5\u7814\u7a76\u4e86\u9759\u6001\u7403\u5bf9\u79f0\u65f6\u7a7a\u4e2d\u65cb\u8f6c\u6d4b\u8bd5\u7c92\u5b50\u7684\u7c7b\u65f6\u5706\u8f68\u9053\u7684\u62d3\u6251\u6027\u8d28\uff0c\u53d1\u73b0\u5728\u76f8\u90bb\u89c6\u754c\u4e4b\u95f4\u62d3\u6251\u6570\u4e3aW=-1\uff08\u5b58\u5728\u4e0d\u7a33\u5b9a\u8f68\u9053\uff09\uff0c\u5728\u6700\u5916\u5c42\u89c6\u754c\u5916W=0\uff08\u7a33\u5b9a-\u4e0d\u7a33\u5b9a\u8f68\u9053\u6210\u5bf9\u51fa\u73b0\u6216\u4e0d\u5b58\u5728\uff09\uff0c\u8fd9\u4e9b\u7ed3\u679c\u4e0e\u7c92\u5b50\u81ea\u65cb\u65b9\u5411\u65e0\u5173\u3002", "motivation": "\u7814\u7a76\u65cb\u8f6c\u6d4b\u8bd5\u7c92\u5b50\u5728\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u7684\u8fd0\u52a8\u7279\u6027\uff0c\u7279\u522b\u662f\u7c7b\u65f6\u5706\u8f68\u9053\u7684\u62d3\u6251\u6027\u8d28\uff0c\u4ee5\u63ed\u793a\u65f6\u7a7a\u7ed3\u6784\u5bf9\u7c92\u5b50\u8f68\u9053\u7684\u57fa\u672c\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Mathisson-Papapetrou-Dixon\u5f62\u5f0f\u4f53\u7cfb\u548cTulczyjew\u81ea\u65cb\u8865\u5145\u6761\u4ef6\uff0c\u5728\u9759\u6001\u7403\u5bf9\u79f0\u65f6\u7a7a\u4e2d\u6784\u9020\u8f85\u52a9\u52bf\u573a\u548c\u77e2\u91cf\u573a\uff0c\u8ba1\u7b97\u62d3\u6251\u7ed5\u6570W\u3002", "result": "\u5728\u76f8\u90bb\u89c6\u754c\u4e4b\u95f4W=-1\uff08\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u4e0d\u7a33\u5b9a\u8f68\u9053\uff09\uff0c\u5728\u6700\u5916\u5c42\u89c6\u754c\u5916W=0\uff08\u8f68\u9053\u6210\u5bf9\u51fa\u73b0\u6216\u4e0d\u5b58\u5728\uff09\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5728Schwarzschild\u3001Schwarzschild-AdS\u548cSchwarzschild-dS\u65f6\u7a7a\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u62d3\u6251\u65b9\u6cd5\u63ed\u793a\u4e86\u5373\u4f7f\u5305\u542b\u81ea\u65cb\u6548\u5e94\uff0c\u8f68\u9053\u62d3\u6251\u6027\u8d28\u4ecd\u4fdd\u6301\u4e0d\u53d8\u7684\u7279\u6027\uff0c\u7a81\u51fa\u4e86\u65f6\u7a7a\u7ed3\u6784\u672c\u8eab\u5bf9\u7c92\u5b50\u8f68\u9053\u7684\u57fa\u672c\u5f71\u54cd\u3002"}}
{"id": "2511.01217", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01217", "abs": "https://arxiv.org/abs/2511.01217", "authors": ["Michael H. Goerz", "Sebasti\u00e1n C. Carrasco", "Alastair Marshall", "Vladimir S. Malinovsky"], "title": "GRAPE.jl: Gradient Ascent Pulse Engineering in Julia", "comment": null, "summary": "The GRAPE$.$jl package (https://github.com/JuliaQuantumControl/GRAPE.jl)\nimplements Gradient Ascent Pulse Engineering, a widely used method of quantum\noptimal control. Its purpose is to find controls that steer a quantum system in\na particular way. This is a prerequisite for next-generation quantum\ntechnology, such as quantum computing or quantum sensing. GRAPE$.$jl exploits\nthe unique strengths of the Julia programming language to achieve both\nflexibility and numerical performance. It builds on the QuantumControl$.$jl\nframework.", "AI": {"tldr": "GRAPE.jl \u662f\u4e00\u4e2a\u57fa\u4e8e Julia \u8bed\u8a00\u7684\u91cf\u5b50\u6700\u4f18\u63a7\u5236\u5305\uff0c\u5b9e\u73b0\u4e86\u68af\u5ea6\u4e0a\u5347\u8109\u51b2\u5de5\u7a0b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bfb\u627e\u63a7\u5236\u91cf\u5b50\u7cfb\u7edf\u7684\u4f18\u5316\u8109\u51b2\u3002", "motivation": "\u4e3a\u4e0b\u4e00\u4ee3\u91cf\u5b50\u6280\u672f\uff08\u5982\u91cf\u5b50\u8ba1\u7b97\u548c\u91cf\u5b50\u4f20\u611f\uff09\u63d0\u4f9b\u9ad8\u6548\u7075\u6d3b\u7684\u91cf\u5b50\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528 Julia \u8bed\u8a00\u7684\u4f18\u52bf\u5b9e\u73b0\u6570\u503c\u6027\u80fd\u3002", "method": "\u57fa\u4e8e QuantumControl.jl \u6846\u67b6\uff0c\u5b9e\u73b0\u68af\u5ea6\u4e0a\u5347\u8109\u51b2\u5de5\u7a0b\uff08GRAPE\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u63a7\u5236\u8109\u51b2\u6765\u5f15\u5bfc\u91cf\u5b50\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u517c\u5177\u7075\u6d3b\u6027\u548c\u6570\u503c\u6027\u80fd\u7684\u91cf\u5b50\u6700\u4f18\u63a7\u5236\u8f6f\u4ef6\u5305\uff0c\u80fd\u591f\u6709\u6548\u5bfb\u627e\u63a7\u5236\u91cf\u5b50\u7cfb\u7edf\u7684\u4f18\u5316\u8109\u51b2\u3002", "conclusion": "GRAPE.jl \u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e Julia \u7684\u9ad8\u6548\u91cf\u5b50\u6700\u4f18\u63a7\u5236\uff0c\u4e3a\u91cf\u5b50\u6280\u672f\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.00084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00084", "abs": "https://arxiv.org/abs/2511.00084", "authors": ["Jolanta \u015aliwa"], "title": "Application of predictive machine learning in pen & paper RPG game design", "comment": "Master's thesis submitted at AGH University of Science and Technology", "summary": "In recent years, the pen and paper RPG market has experienced significant\ngrowth. As a result, companies are increasingly exploring the integration of AI\ntechnologies to enhance player experience and gain a competitive edge.\n  One of the key challenges faced by publishers is designing new opponents and\nestimating their challenge level. Currently, there are no automated methods for\ndetermining a monster's level; the only approaches used are based on manual\ntesting and expert evaluation. Although these manual methods can provide\nreasonably accurate estimates, they are time-consuming and resource-intensive.\n  Level prediction can be approached using ordinal regression techniques. This\nthesis presents an overview and evaluation of state-of-the-art methods for this\ntask. It also details the construction of a dedicated dataset for level\nestimation. Furthermore, a human-inspired model was developed to serve as a\nbenchmark, allowing comparison between machine learning algorithms and the\napproach typically employed by pen and paper RPG publishers. In addition, a\nspecialized evaluation procedure, grounded in domain knowledge, was designed to\nassess model performance and facilitate meaningful comparisons.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5e8f\u6570\u56de\u5f52\u6280\u672f\u6765\u81ea\u52a8\u9884\u6d4b\u7eb8\u7b14RPG\u4e2d\u602a\u7269\u7684\u6311\u6218\u7b49\u7ea7\uff0c\u4ee5\u66ff\u4ee3\u5f53\u524d\u8017\u65f6\u7684\u624b\u52a8\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u7eb8\u7b14RPG\u5e02\u573a\u7684\u589e\u957f\uff0c\u51fa\u7248\u5546\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1\u65b0\u5bf9\u624b\u5e76\u8bc4\u4f30\u5176\u6311\u6218\u7b49\u7ea7\u3002\u76ee\u524d\u4ec5\u6709\u7684\u624b\u52a8\u6d4b\u8bd5\u548c\u4e13\u5bb6\u8bc4\u4f30\u65b9\u6cd5\u867d\u7136\u51c6\u786e\u4f46\u8017\u65f6\u8017\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e13\u95e8\u7684\u7b49\u7ea7\u4f30\u8ba1\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u4e86\u4eba\u7c7b\u542f\u53d1\u5f0f\u6a21\u578b\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u4e13\u95e8\u8bc4\u4f30\u7a0b\u5e8f\u6765\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0e\u4f20\u7edf\u65b9\u6cd5\u3002", "result": "\u8bba\u6587\u5bf9\u6700\u5148\u8fdb\u7684\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\u8fdb\u884c\u4e86\u6982\u8ff0\u548c\u8bc4\u4f30\uff0c\u5e76\u5efa\u7acb\u4e86\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u548c\u4eba\u7c7b\u65b9\u6cd5\u7684\u57fa\u51c6\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7eb8\u7b14RPG\u51fa\u7248\u5546\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684\u602a\u7269\u7b49\u7ea7\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u663e\u8457\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\u5e76\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2511.01478", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01478", "abs": "https://arxiv.org/abs/2511.01478", "authors": ["Fen Long", "Weike Deng", "Xin Qin", "Songbai Chen", "Jiliang Jing"], "title": "The images of Brans-Dicke-Kerr type naked singularities", "comment": null, "summary": "We have studied the images of the Brans-Dicke-Kerr spacetime with a\ndimensionless Brans-Dicke parameter $\\omega$, which belongs to axisymmetric\nrotating solutions in the Brans-Dicke theory. Our results show that the\nBrans-Dicke-Kerr spacetime with the parameter $\\omega>-3/2$ represents naked\nsingularities with distinct structures. For the case with $a \\leq M$, the\nshadow in the Brans-Dicke-Kerr spacetime persists, gradually becomes flatter\nand smaller as $\\omega$ decreases. Especially when $\\omega<1/2$, the shadow in\nthe image exhibit a very special ``jellyfish\" shape and possesses a\nself-similar fractal structure. For the case with $a > M$, a distinct gray\nregion consisting of two separate patches appears in the image observed by\nequatorial observers. This indicating that the Brans-Dicke-Kerr spacetime can\nbe distinguished from the Kerr and Kerr-de Sitter cases based on its image.\nThese effects of the Brans-Dicke parameter could help us to reveal the\nintrinsic structure of the Brans-Dicke-Kerr spacetimes and provide a foundation\nfor testing Brans-Dicke theory through future high-precision observations.", "AI": {"tldr": "\u7814\u7a76\u4e86Brans-Dicke-Kerr\u65f6\u7a7a\u7684\u56fe\u50cf\uff0c\u53d1\u73b0\u5f53\u03c9>-3/2\u65f6\u8868\u73b0\u4e3a\u88f8\u5947\u70b9\uff0c\u9634\u5f71\u968f\u03c9\u51cf\u5c0f\u800c\u53d8\u5e73\u53d8\u5c0f\uff0c\u03c9<1/2\u65f6\u5448\u73b0\u7279\u6b8a\u7684\u6c34\u6bcd\u5f62\u72b6\u548c\u5206\u5f62\u7ed3\u6784\uff0ca>M\u65f6\u51fa\u73b0\u72ec\u7279\u7684\u7070\u8272\u533a\u57df\uff0c\u53ef\u7528\u4e8e\u533a\u5206Kerr\u65f6\u7a7a\u548c\u6d4b\u8bd5Brans-Dicke\u7406\u8bba\u3002", "motivation": "\u7814\u7a76Brans-Dicke-Kerr\u65f6\u7a7a\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u63a2\u7d22Brans-Dicke\u53c2\u6570\u03c9\u5bf9\u65f6\u7a7a\u7ed3\u6784\u548c\u89c2\u6d4b\u56fe\u50cf\u7684\u5f71\u54cd\uff0c\u4e3a\u901a\u8fc7\u9ad8\u7cbe\u5ea6\u89c2\u6d4b\u6d4b\u8bd5Brans-Dicke\u7406\u8bba\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u5206\u6790Brans-Dicke-Kerr\u65f6\u7a7a\u7684\u56fe\u50cf\uff0c\u7814\u7a76\u4e0d\u540c\u03c9\u53c2\u6570\u503c\u4e0b\u65f6\u7a7a\u7684\u9634\u5f71\u5f62\u72b6\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u7279\u522b\u5173\u6ce8a\u2264M\u548ca>M\u4e24\u79cd\u60c5\u51b5\u3002", "result": "\u5f53\u03c9>-3/2\u65f6\u8868\u73b0\u4e3a\u88f8\u5947\u70b9\uff1b\u03c9\u51cf\u5c0f\u5bfc\u81f4\u9634\u5f71\u53d8\u5e73\u53d8\u5c0f\uff1b\u03c9<1/2\u65f6\u51fa\u73b0\u7279\u6b8a\u7684\u6c34\u6bcd\u5f62\u72b6\u548c\u5206\u5f62\u7ed3\u6784\uff1ba>M\u65f6\u56fe\u50cf\u4e2d\u51fa\u73b0\u7531\u4e24\u4e2a\u5206\u79bb\u6591\u5757\u7ec4\u6210\u7684\u72ec\u7279\u7070\u8272\u533a\u57df\u3002", "conclusion": "Brans-Dicke-Kerr\u65f6\u7a7a\u7684\u56fe\u50cf\u7279\u5f81\u660e\u663e\u533a\u522b\u4e8eKerr\u548cKerr-de Sitter\u60c5\u51b5\uff0cBrans-Dicke\u53c2\u6570\u7684\u5f71\u54cd\u6709\u52a9\u4e8e\u63ed\u793a\u65f6\u7a7a\u5185\u5728\u7ed3\u6784\uff0c\u4e3a\u901a\u8fc7\u89c2\u6d4b\u6d4b\u8bd5\u8be5\u7406\u8bba\u63d0\u4f9b\u53ef\u80fd\u3002"}}
{"id": "2511.01220", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01220", "abs": "https://arxiv.org/abs/2511.01220", "authors": ["David Sommers", "Prasanna Pakkiam", "Zach Degnan", "Chun-Ching Chiu", "Divita Gautam", "Yi-Hsun Chen", "Arkady Fedorov"], "title": "Open-Source Highly Parallel Electromagnetic Simulations for Superconducting Circuits", "comment": null, "summary": "Electromagnetic simulations form an indispensable part of the design and\noptimization process for superconducting quantum devices. Although several\ncommercial platforms exist, open-source alternatives optimized for\nhigh-performance computing remain limited. To address this gap, we introduce\nSQDMetal, a Python-based API that integrates Qiskit Metal (IBM), Gmsh, Palace\n(AWS), and Paraview (Kitware) into an open-source, highly parallel simulation\nworkflow for superconducting quantum circuits. SQDMetal enables accurate,\nefficient, and scalable simulations while remaining community-driven and free\nfrom commercial constraints. In this work, we validate SQDMetal through mesh\nconvergence studies which benchmark SQDMetal against COMSOL Multiphysics and\nAnsys, demonstrating excellent agreement for both eigenmode and electrostatic\n(capacitance) simulations. Furthermore, we simulate superconducting resonators\nand transmon qubits, showing reasonable agreement with experimental\nmeasurements. SQDMetal also supports advanced capabilities, including\nHamiltonian extraction via the energy participation ratio (EPR) method,\nincorporation of kinetic inductance effects, and full 3D modelling of device\ngeometry for improved predictive accuracy. By unifying open-source tools into a\nsingle framework, SQDMetal lowers the barriers to entry for community members\nseeking to access high-performance simulations to assist in the design and\noptimization of their devices.", "AI": {"tldr": "SQDMetal\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5f00\u6e90API\uff0c\u96c6\u6210\u4e86Qiskit Metal\u3001Gmsh\u3001Palace\u548cParaview\u7b49\u5de5\u5177\uff0c\u4e3a\u8d85\u5bfc\u91cf\u5b50\u7535\u8def\u63d0\u4f9b\u9ad8\u5ea6\u5e76\u884c\u7684\u4eff\u771f\u5de5\u4f5c\u6d41\u3002", "motivation": "\u89e3\u51b3\u5546\u4e1a\u4eff\u771f\u5e73\u53f0\u9650\u5236\u548c\u5f00\u6e90\u9ad8\u6027\u80fd\u8ba1\u7b97\u66ff\u4ee3\u65b9\u6848\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u8d85\u5bfc\u91cf\u5b50\u8bbe\u5907\u8bbe\u8ba1\u63d0\u4f9b\u793e\u533a\u9a71\u52a8\u3001\u65e0\u5546\u4e1a\u7ea6\u675f\u7684\u4eff\u771f\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u5f00\u6e90\u5de5\u5177\u6784\u5efa\u7edf\u4e00\u6846\u67b6\uff0c\u652f\u6301\u7f51\u683c\u6536\u655b\u7814\u7a76\u3001\u672c\u5f81\u6a21\u548c\u9759\u7535\u4eff\u771f\u3001\u54c8\u5bc6\u987f\u91cf\u63d0\u53d6\u3001\u52a8\u611f\u6548\u5e94\u5efa\u6a21\u548c\u5b8c\u65743D\u51e0\u4f55\u5efa\u6a21\u3002", "result": "\u9a8c\u8bc1\u663e\u793aSQDMetal\u4e0eCOMSOL Multiphysics\u548cAnsys\u5728\u4eff\u771f\u7ed3\u679c\u4e0a\u5177\u6709\u826f\u597d\u4e00\u81f4\u6027\uff0c\u8d85\u5bfc\u8c10\u632f\u5668\u548ctransmon\u91cf\u5b50\u6bd4\u7279\u4eff\u771f\u4e0e\u5b9e\u9a8c\u6d4b\u91cf\u7ed3\u679c\u5408\u7406\u543b\u5408\u3002", "conclusion": "SQDMetal\u901a\u8fc7\u7edf\u4e00\u5f00\u6e90\u5de5\u5177\u964d\u4f4e\u4e86\u9ad8\u6027\u80fd\u4eff\u771f\u95e8\u69db\uff0c\u4e3a\u8d85\u5bfc\u91cf\u5b50\u8bbe\u5907\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00085", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00085", "abs": "https://arxiv.org/abs/2511.00085", "authors": ["Peilin Tan", "Chuanqi Shi", "Dian Tu", "Liang Xie"], "title": "MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning", "comment": null, "summary": "Stock trend prediction is crucial for profitable trading strategies and\nportfolio management yet remains challenging due to market volatility, complex\ntemporal dynamics and multifaceted inter-stock relationships. Existing methods\nstruggle to effectively capture temporal dependencies and dynamic inter-stock\ninteractions, often neglecting cross-sectional market influences, relying on\nstatic correlations, employing uniform treatments of nodes and edges, and\nconflating diverse relationships. This work introduces MaGNet, a novel Mamba\ndual-hyperGraph Network for stock prediction, integrating three key\ninnovations: (1) a MAGE block, which leverages bidirectional Mamba with\nadaptive gating mechanisms for contextual temporal modeling and integrates a\nsparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market\nconditions, alongside multi-head attention for capturing global dependencies;\n(2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable\nprecise fusion of multivariate features and cross-stock dependencies,\neffectively enhancing informativeness while preserving intrinsic data\nstructures, bridging temporal modeling with relational reasoning; and (3) a\ndual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH)\nthat captures fine-grained causal dependencies with temporal constraints, and\nGlobal Probabilistic Hypergraph (GPH) that models market-wide patterns through\nsoft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism,\njointly disentangling localized temporal influences from instantaneous global\nstructures for multi-scale relational learning. Extensive experiments on six\nmajor stock indices demonstrate MaGNet outperforms state-of-the-art methods in\nboth superior predictive performance and exceptional investment returns with\nrobust risk management capabilities. Codes available at:\nhttps://github.com/PeilinTime/MaGNet.", "AI": {"tldr": "\u63d0\u51fa\u4e86MaGNet\u6a21\u578b\uff0c\u4e00\u79cd\u57fa\u4e8eMamba\u53cc\u8d85\u56fe\u7f51\u7edc\u7684\u80a1\u7968\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1aMAGE\u5757\u30012D\u65f6\u7a7a\u6ce8\u610f\u529b\u6a21\u5757\u548c\u53cc\u8d85\u56fe\u6846\u67b6\uff0c\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u80a1\u7968\u95f4\u52a8\u6001\u5173\u7cfb\uff0c\u5728\u516d\u4e2a\u4e3b\u8981\u80a1\u7968\u6307\u6570\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9884\u6d4b\u6027\u80fd\u548c\u6295\u8d44\u56de\u62a5\u3002", "motivation": "\u80a1\u7968\u8d8b\u52bf\u9884\u6d4b\u5bf9\u4ea4\u6613\u7b56\u7565\u548c\u6295\u8d44\u7ec4\u5408\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5e02\u573a\u6ce2\u52a8\u6027\u3001\u590d\u6742\u7684\u65f6\u95f4\u52a8\u6001\u548c\u591a\u65b9\u9762\u7684\u80a1\u7968\u95f4\u5173\u7cfb\u800c\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u52a8\u6001\u80a1\u7968\u95f4\u4ea4\u4e92\uff0c\u5f80\u5f80\u5ffd\u7565\u6a2a\u622a\u9762\u5e02\u573a\u5f71\u54cd\u3002", "method": "MaGNet\u6a21\u578b\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) MAGE\u5757\uff0c\u4f7f\u7528\u53cc\u5411Mamba\u548c\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u8fdb\u884c\u4e0a\u4e0b\u6587\u65f6\u95f4\u5efa\u6a21\uff0c\u96c6\u6210\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u5c42\u4ee5\u9002\u5e94\u4e0d\u540c\u5e02\u573a\u6761\u4ef6\uff1b(2) \u7279\u5f81\u548c\u80a1\u7968\u7ef4\u5ea6\u76842D\u65f6\u7a7a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u7cbe\u786e\u878d\u5408\u591a\u53d8\u91cf\u7279\u5f81\u548c\u8de8\u80a1\u7968\u4f9d\u8d56\u5173\u7cfb\uff1b(3) \u53cc\u8d85\u56fe\u6846\u67b6\uff0c\u5305\u62ec\u65f6\u95f4\u56e0\u679c\u8d85\u56fe\u6355\u6349\u7ec6\u7c92\u5ea6\u56e0\u679c\u4f9d\u8d56\uff0c\u548c\u5168\u5c40\u6982\u7387\u8d85\u56fe\u5efa\u6a21\u5e02\u573a\u8303\u56f4\u6a21\u5f0f\u3002", "result": "\u5728\u516d\u4e2a\u4e3b\u8981\u80a1\u7968\u6307\u6570\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMaGNet\u5728\u9884\u6d4b\u6027\u80fd\u548c\u6295\u8d44\u56de\u62a5\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5177\u6709\u7a33\u5065\u7684\u98ce\u9669\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "MaGNet\u901a\u8fc7\u521b\u65b0\u7684Mamba\u53cc\u8d85\u56fe\u7f51\u7edc\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u80a1\u7968\u9884\u6d4b\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u52a8\u6001\u5173\u7cfb\u5efa\u6a21\u95ee\u9898\uff0c\u4e3a\u80a1\u7968\u8d8b\u52bf\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01533", "categories": ["gr-qc", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.01533", "abs": "https://arxiv.org/abs/2511.01533", "authors": ["Sara Saghafi", "Kourosh Nozari", "Maryam Kaveh"], "title": "Shadow of Extreme Compact Charged Objects in Consistent 4-Dimensional Einstein-Gauss-Bonnet Gravity", "comment": "20 pages, 7 figures, 1 table", "summary": "In order to better describe gravitational phenomena on both very small and\ncosmological scales, there have been constant attempts to generalize and expand\nthe theory of General Relativity (GR) since its inception. The Einstein Gauss\nBonnet (EGB) theory is one such extension that adds spacetime corrections\nrelated to curvature. Since the standard Gauss Bonnet term is purely\ntopological, it does not contribute to the field equations in four dimensions.\nTo get around this restriction, however, an invariant four dimensional limit\nhas been developed. In this work, we study Extreme Compact Charged Objects\n(ECCOs), which can resemble black holes, in a gravity framework that is\ncompatible with Einstein Gauss Bonnet in four dimensions. Our main goal is to\ncompare theoretical predictions with Event Horizon Telescope (EHT)\nobservational data in order to constrain the Gauss Bonnet coupling constant\n{\\alpha}. In order to achieve this, we investigate important optical\ncharacteristics like the shadow, light bending angle, and other associated\nobservables, as well as the geodesic structure of ECCO spacetimes in EGB\ngravity. Finally, we apply these findings to constrain the Gauss Bonnet\nconstant.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56db\u7ef4\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u6846\u67b6\u4e0b\u7684\u6781\u7aef\u81f4\u5bc6\u5e26\u7535\u5929\u4f53\uff0c\u901a\u8fc7\u5206\u6790\u5176\u9634\u5f71\u3001\u5149\u7ebf\u504f\u6298\u89d2\u7b49\u5149\u5b66\u7279\u6027\uff0c\u4e0e\u4e8b\u4ef6\u89c6\u754c\u671b\u8fdc\u955c\u89c2\u6d4b\u6570\u636e\u5bf9\u6bd4\uff0c\u6765\u7ea6\u675f\u9ad8\u65af-\u535a\u5185\u8026\u5408\u5e38\u6570\u03b1\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u63cf\u8ff0\u5c0f\u5c3a\u5ea6\u548c\u5b87\u5b99\u5c3a\u5ea6\u7684\u5f15\u529b\u73b0\u8c61\uff0c\u9700\u8981\u6269\u5c55\u5e7f\u4e49\u76f8\u5bf9\u8bba\u3002\u56db\u7ef4\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u7406\u8bba\u901a\u8fc7\u5f15\u5165\u66f2\u7387\u76f8\u5173\u7684\u65f6\u7a7a\u4fee\u6b63\u9879\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u5728\u56db\u7ef4\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u6846\u67b6\u4e0b\u7814\u7a76\u6781\u7aef\u81f4\u5bc6\u5e26\u7535\u5929\u4f53\uff0c\u5206\u6790\u5176\u6d4b\u5730\u7ebf\u7ed3\u6784\u548c\u5149\u5b66\u7279\u6027\uff08\u5305\u62ec\u9634\u5f71\u3001\u5149\u7ebf\u504f\u6298\u89d2\u7b49\u53ef\u89c2\u6d4b\u53c2\u6570\uff09\uff0c\u5e76\u4e0e\u4e8b\u4ef6\u89c6\u754c\u671b\u8fdc\u955c\u7684\u89c2\u6d4b\u6570\u636e\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u9884\u6d4b\u4e0e\u89c2\u6d4b\u6570\u636e\u7684\u5bf9\u6bd4\u5206\u6790\uff0c\u83b7\u5f97\u4e86\u5bf9\u9ad8\u65af-\u535a\u5185\u8026\u5408\u5e38\u6570\u03b1\u7684\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "\u56db\u7ef4\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u7406\u8bba\u80fd\u591f\u901a\u8fc7\u6781\u7aef\u81f4\u5bc6\u5e26\u7535\u5929\u4f53\u7684\u5149\u5b66\u89c2\u6d4b\u7279\u6027\u6765\u7ea6\u675f\u5176\u8026\u5408\u53c2\u6570\uff0c\u4e3a\u6d4b\u8bd5\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.01247", "categories": ["quant-ph", "cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.01247", "abs": "https://arxiv.org/abs/2511.01247", "authors": ["Md. Shariful Islam", "Joaquin Chung", "Ely Marcus Eastman", "Robert J. Hayek", "Prem Kumar", "Rajkumar Kettimuthu"], "title": "Experimental Demonstration of Software-Orchestrated Quantum Network Applications over a Campus-Scale Testbed", "comment": "11 pages, 8 figures, journal", "summary": "To fulfill their promise, quantum networks must transform from isolated\ntestbeds into scalable infrastructures for distributed quantum applications. In\nthis paper, we present a prototype orchestrator for the Argonne Quantum Network\n(ArQNet) testbed that leverages design principles of software-defined\nnetworking (SDN) to automate typical quantum communication experiments across\nbuildings in the Argonne campus connected over deployed, telecom fiber. Our\nimplementation validates a scalable architecture supporting service-level\nabstraction of quantum networking tasks, distributed time synchronization, and\nentanglement verification across remote nodes. We present a prototype service\nof continuous, stable entanglement distribution between remote sites that ran\nfor 12 hours, which defines a promising path towards scalable quantum networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5b50\u7f51\u7edc\u7f16\u6392\u5668\u539f\u578b\uff0c\u5229\u7528SDN\u8bbe\u8ba1\u539f\u5219\u5728Argonne\u91cf\u5b50\u7f51\u7edc\u6d4b\u8bd5\u5e8a\u4e0a\u81ea\u52a8\u5316\u91cf\u5b50\u901a\u4fe1\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u53ef\u6269\u5c55\u67b6\u6784\u5e76\u5b9e\u73b0\u4e8612\u5c0f\u65f6\u8fde\u7eed\u7a33\u5b9a\u7684\u8fdc\u7a0b\u7ea0\u7f20\u5206\u53d1\u670d\u52a1\u3002", "motivation": "\u91cf\u5b50\u7f51\u7edc\u9700\u8981\u4ece\u5b64\u7acb\u7684\u6d4b\u8bd5\u5e8a\u8f6c\u53d8\u4e3a\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4ee5\u652f\u6301\u5206\u5e03\u5f0f\u91cf\u5b50\u5e94\u7528\u3002", "method": "\u91c7\u7528\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc(SDN)\u8bbe\u8ba1\u539f\u5219\uff0c\u5728Argonne\u6821\u56ed\u5185\u901a\u8fc7\u90e8\u7f72\u7684\u7535\u4fe1\u5149\u7ea4\u8fde\u63a5\u5efa\u7b51\u7269\uff0c\u81ea\u52a8\u5316\u91cf\u5b50\u901a\u4fe1\u5b9e\u9a8c\u3002", "result": "\u9a8c\u8bc1\u4e86\u652f\u6301\u91cf\u5b50\u7f51\u7edc\u4efb\u52a1\u670d\u52a1\u7ea7\u62bd\u8c61\u3001\u5206\u5e03\u5f0f\u65f6\u95f4\u540c\u6b65\u548c\u8fdc\u7a0b\u8282\u70b9\u7ea0\u7f20\u9a8c\u8bc1\u7684\u53ef\u6269\u5c55\u67b6\u6784\uff0c\u5b9e\u73b0\u4e8612\u5c0f\u65f6\u8fde\u7eed\u7a33\u5b9a\u7684\u8fdc\u7a0b\u7ea0\u7f20\u5206\u53d1\u670d\u52a1\u3002", "conclusion": "\u8fd9\u4e3a\u53ef\u6269\u5c55\u91cf\u5b50\u7f51\u7edc\u7684\u53d1\u5c55\u5b9a\u4e49\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u9053\u8def\u3002"}}
{"id": "2511.00086", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2511.00086", "abs": "https://arxiv.org/abs/2511.00086", "authors": ["Fali Wang", "Jihai Chen", "Shuhua Yang", "Runxue Bao", "Tianxiang Zhao", "Zhiwei Zhang", "Xianfeng Tang", "Hui Liu", "Qi He", "Suhang Wang"], "title": "Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph", "comment": "Under review", "summary": "Test-Time Scaling (TTS) improves large language models (LLMs) by allocating\nadditional computation during inference, typically through parallel,\nsequential, or hybrid scaling. However, prior studies often assume fixed\ncollaboration architectures (e.g., topologies) and single-model usage,\noverlooking that optimal architectures and model combinations can vary across\ntasks. Therefore, we study the novel problem of searching for compute-optimal\nmodel combinations and architectures in TTS under a fixed budget. We formalize\nit as a multi-LLM collaboration graph, where nodes encode roles and LLM model\nassignments, and edges capture information flow. This problem is challenging\nbecause (i) the combinatorial search space is prohibitively large, and (ii)\ntask-specific requirements demand tailored designs. To address these, we\nreformulate the problem as probabilistic graph optimization and, through pilot\nexperiments, derive three empirical insights into TTS collaboration graphs.\nGuided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented\nframework that mirrors the REINFORCE pipeline by mapping\nsampling-gradient-update to sampling-feedback-update, where feedback serves as\na textual gradient to update the probabilistic graph and efficiently search for\noptimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE\noutperforms both traditional and LLM-based baselines in sample efficiency and\nsearch performance, and effectively identifies optimal graphs under joint\nobjectives of accuracy and inference latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgent-REINFORCE\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u641c\u7d22\u6d4b\u8bd5\u65f6\u6269\u5c55(TTS)\u4e2d\u7684\u6700\u4f18\u591aLLM\u534f\u4f5c\u56fe\u548c\u6a21\u578b\u7ec4\u5408\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5ffd\u89c6\u4efb\u52a1\u7279\u5b9a\u67b6\u6784\u9700\u6c42\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u56fa\u5b9a\u7684\u534f\u4f5c\u67b6\u6784\u548c\u5355\u4e00\u6a21\u578b\u4f7f\u7528\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u4efb\u52a1\u9700\u8981\u4e0d\u540c\u6700\u4f18\u67b6\u6784\u548c\u6a21\u578b\u7ec4\u5408\u7684\u4e8b\u5b9e\u3002", "method": "\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6982\u7387\u56fe\u4f18\u5316\uff0c\u63d0\u51faAgent-REINFORCE\u6846\u67b6\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u589e\u5f3a\u7684REINFORCE\u6d41\u7a0b\uff0c\u5c06\u91c7\u6837-\u68af\u5ea6-\u66f4\u65b0\u6620\u5c04\u4e3a\u91c7\u6837-\u53cd\u9988-\u66f4\u65b0\uff0c\u4f7f\u7528\u6587\u672c\u53cd\u9988\u4f5c\u4e3a\u68af\u5ea6\u6765\u66f4\u65b0\u6982\u7387\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAgent-REINFORCE\u5728\u6837\u672c\u6548\u7387\u548c\u641c\u7d22\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u548c\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u5728\u51c6\u786e\u6027\u548c\u63a8\u7406\u5ef6\u8fdf\u8054\u5408\u76ee\u6807\u4e0b\u7684\u6700\u4f18\u56fe\u3002", "conclusion": "Agent-REINFORCE\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86TTS\u4e2d\u591aLLM\u534f\u4f5c\u56fe\u641c\u7d22\u7684\u6311\u6218\uff0c\u4e3a\u4e0d\u540c\u4efb\u52a1\u627e\u5230\u8ba1\u7b97\u6700\u4f18\u7684\u6a21\u578b\u7ec4\u5408\u548c\u67b6\u6784\u3002"}}
{"id": "2511.01544", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2511.01544", "abs": "https://arxiv.org/abs/2511.01544", "authors": ["Ernesto Contreras", "Mikaela Carrasco-Hidalgo", "Pedro Bargue\u00f1o", "Arthur G. Suvorov"], "title": "A General Framework for the Spontaneous Scalarization of Regular Black Holes", "comment": "10 pages, 5 figures. Comments welcome", "summary": "We investigate the spontaneous scalarization of generic, static, and\nspherically symmetric regular black holes supported by nonlinear\nelectrodynamics. Starting from an arbitrary seed metric, we employ the P-dual\nformalism to reconstruct the electromagnetic sector and subsequently couple a\nreal scalar field nonminimally. As a worked example, we apply the framework to\nthe regular Balart-Vagenas black hole, showing that scalarized and scalar-free\nbranches can coexist in a region where the scalarized configurations are\nentropically preferred. We further assess possible observational imprints,\nfinding percent-level deviations in both the shadow size and the fundamental\nscalar quasi-normal modes ($< 10\\%$ for small charge-to-mass ratios),\nindicating that current electromagnetic and gravitational-wave observations do\nnot rule out these solutions. Our construction thus provides a general route to\nexplore scalarization on top of nonlinear-electrodynamics-supported spacetimes,\nextending beyond specific Reissner-Nordstr\\\"om-like cases.", "AI": {"tldr": "\u7814\u7a76\u975e\u7ebf\u6027\u7535\u52a8\u529b\u5b66\u652f\u6301\u7684\u89c4\u5219\u9ed1\u6d1e\u7684\u81ea\u53d1\u6807\u91cf\u5316\uff0c\u901a\u8fc7P-\u5bf9\u5076\u5f62\u5f0f\u91cd\u6784\u7535\u78c1\u573a\u90e8\u5206\u5e76\u8026\u5408\u6807\u91cf\u573a\uff0c\u53d1\u73b0\u6807\u91cf\u5316\u5206\u652f\u5728\u71b5\u65b9\u9762\u66f4\u4f18\uff0c\u89c2\u6d4b\u504f\u5dee\u572810%\u4ee5\u5185\u3002", "motivation": "\u63a2\u7d22\u8d85\u8d8aReissner-Nordstr\u00f6m\u60c5\u51b5\u7684\u66f4\u4e00\u822c\u975e\u7ebf\u6027\u7535\u52a8\u529b\u5b66\u65f6\u7a7a\u4e2d\u7684\u6807\u91cf\u5316\u73b0\u8c61\uff0c\u6784\u5efa\u901a\u7528\u6846\u67b6\u6765\u7814\u7a76\u89c4\u5219\u9ed1\u6d1e\u7684\u6807\u91cf\u5316\u884c\u4e3a\u3002", "method": "\u4ece\u4efb\u610f\u79cd\u5b50\u5ea6\u91cf\u51fa\u53d1\uff0c\u4f7f\u7528P-\u5bf9\u5076\u5f62\u5f0f\u91cd\u6784\u7535\u78c1\u573a\u90e8\u5206\uff0c\u7136\u540e\u975e\u6700\u5c0f\u8026\u5408\u5b9e\u6807\u91cf\u573a\uff0c\u4ee5Balart-Vagenas\u89c4\u5219\u9ed1\u6d1e\u4e3a\u4f8b\u8fdb\u884c\u5177\u4f53\u5206\u6790\u3002", "result": "\u53d1\u73b0\u6807\u91cf\u5316\u548c\u65e0\u6807\u91cf\u5206\u652f\u53ef\u4ee5\u5171\u5b58\uff0c\u6807\u91cf\u5316\u6784\u578b\u5728\u71b5\u65b9\u9762\u66f4\u4f18\uff1b\u89c2\u6d4b\u504f\u5dee\u5728\u9634\u5f71\u5c3a\u5bf8\u548c\u51c6\u6b63\u89c4\u6a21\u65b9\u9762\u5747\u5c0f\u4e8e10%\uff0c\u5f53\u524d\u89c2\u6d4b\u65e0\u6cd5\u6392\u9664\u8fd9\u4e9b\u89e3\u3002", "conclusion": "\u8be5\u6784\u9020\u4e3a\u63a2\u7d22\u975e\u7ebf\u6027\u7535\u52a8\u529b\u5b66\u652f\u6301\u7684\u65f6\u7a7a\u6807\u91cf\u5316\u63d0\u4f9b\u4e86\u901a\u7528\u8def\u5f84\uff0c\u6269\u5c55\u4e86\u8d85\u51fa\u7279\u5b9aReissner-Nordstr\u00f6m\u7c7b\u60c5\u51b5\u7684\u7814\u7a76\u8303\u56f4\u3002"}}
{"id": "2511.01253", "categories": ["quant-ph", "cs.AI", "cs.LG", "81P68, 68T07, 68Q12, 68Q25, 65F10", "F.1.2; F.2.1; I.2.6; I.2.8; G.1.3"], "pdf": "https://arxiv.org/pdf/2511.01253", "abs": "https://arxiv.org/abs/2511.01253", "authors": ["Hans Gundlach", "Hrvoje Kukina", "Jayson Lynch", "Neil Thompson"], "title": "Quantum Deep Learning Still Needs a Quantum Leap", "comment": null, "summary": "Quantum computing technology is advancing rapidly. Yet, even accounting for\nthese trends, a quantum leap would be needed for quantum computers to mean-\ningfully impact deep learning over the coming decade or two. We arrive at this\nconclusion based on a first-of-its-kind survey of quantum algorithms and how\nthey match potential deep learning applications. This survey reveals three\nimportant areas where quantum computing could potentially accelerate deep\nlearning, each of which faces a challenging roadblock to realizing its\npotential. First, quantum algorithms for matrix multiplication and other\nalgorithms central to deep learning offer small theoretical improvements in the\nnumber of operations needed, but this advantage is overwhelmed on practical\nproblem sizes by how slowly quantum computers do each operation. Second, some\npromising quantum algorithms depend on practical Quantum Random Access Memory\n(QRAM), which is underdeveloped. Finally, there are quantum algorithms that\noffer large theoretical advantages, but which are only applicable to special\ncases, limiting their practical benefits. In each of these areas, we support\nour arguments using quantitative forecasts of quantum advantage that build on\nthe work by Choi et al. [2023] as well as new research on limitations and\nquantum hardware trends. Our analysis outlines the current scope of quantum\ndeep learning and points to research directions that could lead to greater\npractical advances in the field.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.00097", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00097", "abs": "https://arxiv.org/abs/2511.00097", "authors": ["Zihao Guo", "Qingyun Sun", "Ziwei Zhang", "Haonan Yuan", "Huiping Zhuang", "Xingcheng Fu", "Jianxin Li"], "title": "GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation", "comment": "Accepted by the Main Track of NeurIPS-2025", "summary": "Graph incremental learning (GIL), which continuously updates graph models by\nsequential knowledge acquisition, has garnered significant interest recently.\nHowever, existing GIL approaches focus on task-incremental and\nclass-incremental scenarios within a single domain. Graph domain-incremental\nlearning (Domain-IL), aiming at updating models across multiple graph domains,\nhas become critical with the development of graph foundation models (GFMs), but\nremains unexplored in the literature. In this paper, we propose Graph\nDomain-Incremental Learning via Knowledge Dientanglement and Preservation\n(GraphKeeper), to address catastrophic forgetting in Domain-IL scenario from\nthe perspectives of embedding shifts and decision boundary deviations.\nSpecifically, to prevent embedding shifts and confusion across incremental\ngraph domains, we first propose the domain-specific parameter-efficient\nfine-tuning together with intra- and inter-domain disentanglement objectives.\nConsequently, to maintain a stable decision boundary, we introduce\ndeviation-free knowledge preservation to continuously fit incremental domains.\nAdditionally, for graphs with unobservable domains, we perform domain-aware\ndistribution discrimination to obtain precise embeddings. Extensive experiments\ndemonstrate the proposed GraphKeeper achieves state-of-the-art results with\n6.5%~16.6% improvement over the runner-up with negligible forgetting. Moreover,\nwe show GraphKeeper can be seamlessly integrated with various representative\nGFMs, highlighting its broad applicative potential.", "AI": {"tldr": "\u63d0\u51fa\u4e86GraphKeeper\u65b9\u6cd5\u6765\u89e3\u51b3\u56fe\u57df\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u77e5\u8bc6\u89e3\u7f20\u548c\u4fdd\u6301\u6765\u5e94\u5bf9\u5d4c\u5165\u6f02\u79fb\u548c\u51b3\u7b56\u8fb9\u754c\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u57df\u5185\u7684\u4efb\u52a1\u589e\u91cf\u548c\u7c7b\u522b\u589e\u91cf\u573a\u666f\uff0c\u800c\u56fe\u57df\u589e\u91cf\u5b66\u4e60\uff08\u8de8\u591a\u4e2a\u56fe\u57df\u66f4\u65b0\u6a21\u578b\uff09\u5728\u56fe\u5f62\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u4e2d\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u6587\u732e\u4e2d\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "GraphKeeper\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u57df\u7279\u5b9a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u53ca\u57df\u5185\u548c\u57df\u95f4\u89e3\u7f20\u76ee\u6807\uff0c\u9632\u6b62\u8de8\u589e\u91cf\u56fe\u57df\u7684\u5d4c\u5165\u6f02\u79fb\u548c\u6df7\u6dc6\uff1b2\uff09\u65e0\u504f\u5dee\u77e5\u8bc6\u4fdd\u6301\u4ee5\u7ef4\u6301\u7a33\u5b9a\u51b3\u7b56\u8fb9\u754c\uff1b3\uff09\u5bf9\u4e8e\u4e0d\u53ef\u89c2\u6d4b\u57df\u7684\u56fe\uff0c\u6267\u884c\u57df\u611f\u77e5\u5206\u5e03\u5224\u522b\u4ee5\u83b7\u5f97\u7cbe\u786e\u5d4c\u5165\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGraphKeeper\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u76f8\u6bd4\u7b2c\u4e8c\u540d\u67096.5%~16.6%\u7684\u63d0\u5347\uff0c\u4e14\u9057\u5fd8\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002\u8be5\u65b9\u6cd5\u53ef\u4e0e\u5404\u79cd\u4ee3\u8868\u6027\u56fe\u5f62\u57fa\u7840\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "GraphKeeper\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u57df\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u9002\u7528\u6f5c\u529b\uff0c\u4e3a\u56fe\u5f62\u57fa\u7840\u6a21\u578b\u5728\u591a\u57df\u73af\u5883\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.01561", "categories": ["gr-qc", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01561", "abs": "https://arxiv.org/abs/2511.01561", "authors": ["Xiaobao Liu", "Wentao Liu", "Si-Han Shang", "Shu-Min Wu"], "title": "Does the survival and sudden death of quadripartite steering in curved spacetime truly depend on multi-directionality?", "comment": "23 pages, 3 figures", "summary": "We systematically investigate the directional dependence of Gaussian\nquadripartite quantum steering and its redistribution among different modes in\nthe background of a Schwarzschild black hole. For physically accessible\nsectors, we identify three distinct behaviors: (i) steering from\nnon-gravitational to gravitational observers undergoes sudden death at maximal\nasymmetry with the Hawking temperature, marking the crossover from two-way to\none-way steerability; (ii) steering in the opposite direction decays\nmonotonically and vanishes only in the extreme black hole limit, highlighting\nits directional sensitivity to spacetime curvature; (iii) steering from hybrid\ngravitational-non-gravitational partitions to non-gravitational mode persists\nat a finite asymptotic value set by the initial squeezing parameter. Moreover,\nall inaccessible steerings generated by the Hawking effect exhibit an intrinsic\nasymmetry, with their specific behavior being strongly dependent on the\nsteering direction.", "AI": {"tldr": "\u7814\u7a76\u4e86\u53f2\u74e6\u897f\u9ed1\u6d1e\u80cc\u666f\u4e0b\u9ad8\u65af\u56db\u4f53\u91cf\u5b50\u5bfc\u5f15\u7684\u65b9\u5411\u4f9d\u8d56\u6027\u53ca\u5176\u5728\u4e0d\u540c\u6a21\u5f0f\u95f4\u7684\u91cd\u65b0\u5206\u5e03\uff0c\u53d1\u73b0\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u91cf\u5b50\u5bfc\u5f15\u5bf9\u65f6\u7a7a\u66f2\u7387\u7684\u65b9\u5411\u654f\u611f\u6027\u3002", "motivation": "\u63a2\u7d22\u9ed1\u6d1e\u5f15\u529b\u573a\u5bf9\u91cf\u5b50\u5bfc\u5f15\u8fd9\u4e00\u975e\u7ecf\u5178\u91cf\u5b50\u5173\u8054\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5176\u65b9\u5411\u4f9d\u8d56\u6027\u5728\u5f15\u529b\u80cc\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5728\u53f2\u74e6\u897f\u9ed1\u6d1e\u80cc\u666f\u4e0b\u7cfb\u7edf\u7814\u7a76\u9ad8\u65af\u56db\u4f53\u91cf\u5b50\u5bfc\u5f15\uff0c\u5206\u6790\u53ef\u8bbf\u95ee\u548c\u4e0d\u53ef\u8bbf\u95ee\u533a\u57df\u4e2d\u7684\u5bfc\u5f15\u884c\u4e3a\uff0c\u8003\u8651\u970d\u91d1\u6e29\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u4e0d\u540c\u7684\u5bfc\u5f15\u884c\u4e3a\uff1a(1)\u4ece\u975e\u5f15\u529b\u89c2\u6d4b\u8005\u5230\u5f15\u529b\u89c2\u6d4b\u8005\u7684\u5bfc\u5f15\u5728\u6700\u5927\u4e0d\u5bf9\u79f0\u6027\u65f6\u7a81\u7136\u6b7b\u4ea1\uff1b(2)\u53cd\u5411\u5bfc\u5f15\u5355\u8c03\u8870\u51cf\uff1b(3)\u6df7\u5408\u5206\u533a\u5230\u975e\u5f15\u529b\u6a21\u5f0f\u7684\u5bfc\u5f15\u4fdd\u6301\u6709\u9650\u6e10\u8fd1\u503c\u3002", "conclusion": "\u91cf\u5b50\u5bfc\u5f15\u5728\u9ed1\u6d1e\u80cc\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u65b9\u5411\u654f\u611f\u6027\uff0c\u970d\u91d1\u6548\u5e94\u4ea7\u751f\u7684\u4e0d\u53ef\u8bbf\u95ee\u5bfc\u5f15\u5177\u6709\u5185\u5728\u4e0d\u5bf9\u79f0\u6027\uff0c\u5bfc\u5f15\u884c\u4e3a\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u65b9\u5411\u3002"}}
{"id": "2511.01260", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01260", "abs": "https://arxiv.org/abs/2511.01260", "authors": ["Shotaro Shirai", "Shinichi Inoue", "Shuhei Tamate", "Rui Li", "Yasunobu Nakamura", "Atsushi Noguchi"], "title": "High-fidelity all-microwave CZ gate with partial erasure-error detection via a transmon coupler", "comment": null, "summary": "Entangling gates between neighboring physical qubits are essential for\nquantum error correction. Implementing them in an all-microwave manner\nsimplifies signal routing and control apparatus of superconducting quantum\nprocessors. We propose and experimentally demonstrate an all-microwave\ncontrolled-Z (CZ) gate that achieves high fidelity while suppressing residual\nZZ interactions. Our approach utilizes a fixed-frequency transmon coupler and\nmulti-path coupling, thereby sufficiently reducing the net transverse\ninteraction between data transmons to suppress residual ZZ interactions. The\ncontrolled phase arises from the dispersive frequency shift of the $\\fggetxt$\ntransition between the coupler and one of the data transmons conditioned on the\nstate of the other data transmon. Driving the transitions at the midpoint of\ntwo dispersively shifted resonance frequencies induces state-dependent\ngeometric phases to achieve the CZ gate. Crucially, with this scheme, we can\nmaintain a small net transverse interaction between two data transmons while\nincreasing the coupling between the data and coupler transmons to accelerate\nthe CZ-gate speed. Additionally, we measure the coupler state after the gate to\ndetect a subset of decoherence-induced failures that occur during the gate\noperation. These events constitute erasure errors with known locations,\nenabling erasure-aware quantum error-correcting codes to improve future logical\nqubit performance.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e00\u79cd\u5168\u5fae\u6ce2\u63a7\u5236\u7684CZ\u95e8\uff0c\u901a\u8fc7\u56fa\u5b9a\u9891\u7387\u4f20\u8f93\u5b50\u8026\u5408\u5668\u548c\u591a\u8def\u5f84\u8026\u5408\u6765\u6291\u5236\u6b8b\u4f59ZZ\u76f8\u4e92\u4f5c\u7528\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5728\u8d85\u5bfc\u91cf\u5b50\u5904\u7406\u5668\u4e2d\uff0c\u5b9e\u73b0\u5168\u5fae\u6ce2\u63a7\u5236\u7684\u91cf\u5b50\u95e8\u53ef\u4ee5\u7b80\u5316\u4fe1\u53f7\u8def\u7531\u548c\u63a7\u5236\u88c5\u7f6e\uff0c\u540c\u65f6\u9700\u8981\u6291\u5236\u6b8b\u4f59ZZ\u76f8\u4e92\u4f5c\u7528\u4ee5\u63d0\u9ad8\u95e8\u4fdd\u771f\u5ea6\u3002", "method": "\u4f7f\u7528\u56fa\u5b9a\u9891\u7387\u4f20\u8f93\u5b50\u8026\u5408\u5668\u548c\u591a\u8def\u5f84\u8026\u5408\u65b9\u6848\uff0c\u901a\u8fc7\u9a71\u52a8\u4e24\u4e2a\u8272\u6563\u504f\u79fb\u5171\u632f\u9891\u7387\u4e2d\u70b9\u5904\u7684\u8dc3\u8fc1\u6765\u4ea7\u751f\u72b6\u6001\u76f8\u5173\u7684\u51e0\u4f55\u76f8\u4f4d\uff0c\u5b9e\u73b0CZ\u95e8\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684CZ\u95e8\uff0c\u540c\u65f6\u6709\u6548\u6291\u5236\u4e86\u6b8b\u4f59ZZ\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u80fd\u901a\u8fc7\u6d4b\u91cf\u8026\u5408\u5668\u72b6\u6001\u6765\u68c0\u6d4b\u9000\u76f8\u5e72\u5f15\u8d77\u7684\u6545\u969c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u6570\u636e\u4f20\u8f93\u5b50\u95f4\u5c0f\u51c0\u6a2a\u5411\u76f8\u4e92\u4f5c\u7528\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u589e\u52a0\u6570\u636e\u4e0e\u8026\u5408\u5668\u4f20\u8f93\u5b50\u95f4\u7684\u8026\u5408\u6765\u52a0\u901fCZ\u95e8\u901f\u5ea6\uff0c\u4e3a\u91cf\u5b50\u7ea0\u9519\u63d0\u4f9b\u4e86\u6709\u5229\u6761\u4ef6\u3002"}}
{"id": "2511.00099", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00099", "abs": "https://arxiv.org/abs/2511.00099", "authors": ["Marios Impraimakis", "Evangelia Nektaria Palkanoglou"], "title": "A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation", "comment": "21 pages, 23 figures, published in Structural and Multidisciplinary\n  Optimization", "summary": "The optimization-based damage detection and damage state digital twinning\ncapabilities are examined here of a novel conditional-labeled generative\nadversarial network methodology. The framework outperforms current approaches\nfor fault anomaly detection as no prior information is required for the health\nstate of the system: a topic of high significance for real-world applications.\nSpecifically, current artificial intelligence-based digital twinning approaches\nsuffer from the uncertainty related to obtaining poor predictions when a low\nnumber of measurements is available, physics knowledge is missing, or when the\ndamage state is unknown. To this end, an unsupervised framework is examined and\nvalidated rigorously on the benchmark structural health monitoring measurements\nof Z24 Bridge: a post-tensioned concrete highway bridge in Switzerland. In\nimplementing the approach, firstly, different same damage-level measurements\nare used as inputs, while the model is forced to converge conditionally to two\ndifferent damage states. Secondly, the process is repeated for a different\ngroup of measurements. Finally, the convergence scores are compared to identify\nwhich one belongs to a different damage state. The process for both\nhealthy-to-healthy and damage-to-healthy input data creates, simultaneously,\nmeasurements for digital twinning purposes at different damage states, capable\nof pattern recognition and machine learning data generation. Further to this\nprocess, a support vector machine classifier and a principal component analysis\nprocedure is developed to assess the generated and real measurements of each\ndamage category, serving as a secondary new dynamics learning indicator in\ndamage scenarios. Importantly, the approach is shown to capture accurately\ndamage over healthy measurements, providing a powerful tool for vibration-based\nsystem-level monitoring and scalable infrastructure resilience.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6807\u7b7e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u7684\u65e0\u76d1\u7763\u635f\u4f24\u68c0\u6d4b\u548c\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\uff0c\u65e0\u9700\u7cfb\u7edf\u5065\u5eb7\u72b6\u6001\u7684\u5148\u9a8c\u4fe1\u606f\uff0c\u5728Z24\u6865\u6881\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eAI\u7684\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u5728\u6d4b\u91cf\u6570\u636e\u5c11\u3001\u7269\u7406\u77e5\u8bc6\u7f3a\u5931\u6216\u635f\u4f24\u72b6\u6001\u672a\u77e5\u65f6\u9884\u6d4b\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u4e0d\u4f9d\u8d56\u5148\u9a8c\u4fe1\u606f\u7684\u65e0\u76d1\u7763\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u6807\u7b7e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u5c06\u4e0d\u540c\u635f\u4f24\u7ea7\u522b\u7684\u6d4b\u91cf\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u5f3a\u5236\u6a21\u578b\u6536\u655b\u5230\u4e24\u4e2a\u4e0d\u540c\u7684\u635f\u4f24\u72b6\u6001\uff0c\u901a\u8fc7\u6bd4\u8f83\u6536\u655b\u5f97\u5206\u6765\u8bc6\u522b\u4e0d\u540c\u635f\u4f24\u72b6\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u6355\u6349\u5065\u5eb7\u6d4b\u91cf\u6570\u636e\u4e2d\u7684\u635f\u4f24\uff0c\u4e3a\u57fa\u4e8e\u632f\u52a8\u7684\u7cfb\u7edf\u7ea7\u76d1\u6d4b\u548c\u53ef\u6269\u5c55\u57fa\u7840\u8bbe\u65bd\u97e7\u6027\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u76d1\u7763\u6846\u67b6\u5728\u635f\u4f24\u68c0\u6d4b\u548c\u6570\u5b57\u5b6a\u751f\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7cfb\u7edf\u5065\u5eb7\u72b6\u6001\u672a\u77e5\u7684\u60c5\u51b5\u3002"}}
{"id": "2511.01677", "categories": ["gr-qc", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.01677", "abs": "https://arxiv.org/abs/2511.01677", "authors": ["Kourosh Nozari", "Sara Saghafi", "Zeynab Ramezanpasandi"], "title": "Accretion Process as a Probe of Extra Dimensions in MOG Compact Object Spacetimes", "comment": "23 pages, 9 figures, 2 tables", "summary": "The idea of extra spatial dimensions arises from attempts to unify gravity\nwith other fundamental interactions, develop a consistent theory of quantum\ngravity, and address open problems in particle physics and cosmology.\nConsiderable attention has been devoted to understanding how such dimensions\nmodify gravitational theories. One way to probe their impact is through the\nanalytical study of astrophysical processes such as black hole accretion. Since\naccretion efficiently converts gravitational energy into radiation, this makes\nit a powerful tool to test modified gravity (MOG) theories and\nhigher-dimensional frameworks via the behavior of dark compact objects like\nblack holes, neutron stars, and white dwarfs. In this work, we investigate the\ndynamics of neutral particles around a higher-dimensional, regular, spherically\nsymmetric MOG compact object, focusing on the innermost stable circular orbit\n(ISCO), energy flux, temperature, and differential luminosity. We further\nanalyze the accretion of a perfect fluid onto the same object, deriving\nanalytical expressions for the four-velocity and proper energy density of the\ninflowing matter. Our findings show that extra dimensions reduce the ISCO\nradius while enhancing the corresponding flux and temperature. Finally, by\ncomparing the effective disk temperature $T_{\\text{eff}}$ with Event Horizon\nTelescope (EHT) observations of Sgr A*, we argue that MOG and\nhigher-dimensional corrections to the accretion disk properties could be close\nto the current threshold of detectability.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u7ef4\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u4e2d\u89c4\u5219\u7403\u5bf9\u79f0\u81f4\u5bc6\u5929\u4f53\u7684\u7c92\u5b50\u52a8\u529b\u5b66\u548c\u5438\u79ef\u8fc7\u7a0b\uff0c\u53d1\u73b0\u989d\u5916\u7ef4\u5ea6\u51cf\u5c0f\u6700\u5185\u7a33\u5b9a\u5706\u8f68\u9053\u534a\u5f84\uff0c\u589e\u5f3a\u80fd\u91cf\u901a\u91cf\u548c\u6e29\u5ea6\uff0c\u4e14\u8fd9\u4e9b\u4fee\u6b63\u53ef\u80fd\u63a5\u8fd1\u5f53\u524d\u89c2\u6d4b\u63a2\u6d4b\u9608\u503c\u3002", "motivation": "\u901a\u8fc7\u7814\u7a76\u9ad8\u7ef4\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u5929\u4f53\u7269\u7406\u8fc7\u7a0b\uff08\u5982\u9ed1\u6d1e\u5438\u79ef\uff09\uff0c\u6765\u63a2\u7d22\u989d\u5916\u7ef4\u5ea6\u5982\u4f55\u4fee\u6539\u5f15\u529b\u7406\u8bba\uff0c\u5e76\u68c0\u9a8c\u4fee\u6539\u5f15\u529b\u7406\u8bba\u548c\u66f4\u9ad8\u7ef4\u6846\u67b6\u3002", "method": "\u5206\u6790\u9ad8\u7ef4\u89c4\u5219\u7403\u5bf9\u79f0MOG\u81f4\u5bc6\u5929\u4f53\u5468\u56f4\u4e2d\u6027\u7c92\u5b50\u7684\u52a8\u529b\u5b66\uff0c\u7814\u7a76\u6700\u5185\u7a33\u5b9a\u5706\u8f68\u9053\u3001\u80fd\u91cf\u901a\u91cf\u3001\u6e29\u5ea6\u548c\u5fae\u5206\u5149\u5ea6\uff0c\u5e76\u5206\u6790\u5b8c\u7f8e\u6d41\u4f53\u5728\u8be5\u5929\u4f53\u4e0a\u7684\u5438\u79ef\u8fc7\u7a0b\u3002", "result": "\u989d\u5916\u7ef4\u5ea6\u51cf\u5c0f\u6700\u5185\u7a33\u5b9a\u5706\u8f68\u9053\u534a\u5f84\uff0c\u540c\u65f6\u589e\u5f3a\u5bf9\u5e94\u7684\u901a\u91cf\u548c\u6e29\u5ea6\uff1b\u901a\u8fc7\u6bd4\u8f83\u6709\u6548\u76d8\u6e29\u5ea6\u4e0e\u4e8b\u4ef6\u89c6\u754c\u671b\u8fdc\u955c\u5bf9Sgr A*\u7684\u89c2\u6d4b\uff0c\u53d1\u73b0MOG\u548c\u9ad8\u7ef4\u4fee\u6b63\u5bf9\u5438\u79ef\u76d8\u6027\u8d28\u7684\u5f71\u54cd\u53ef\u80fd\u63a5\u8fd1\u5f53\u524d\u63a2\u6d4b\u9608\u503c\u3002", "conclusion": "\u9ad8\u7ef4\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u5929\u4f53\u5438\u79ef\u8fc7\u7a0b\u4e3a\u63a2\u6d4b\u989d\u5916\u7ef4\u5ea6\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u8fd9\u4e9b\u4fee\u6b63\u6548\u5e94\u53ef\u80fd\u5df2\u63a5\u8fd1\u5f53\u524d\u89c2\u6d4b\u8bbe\u5907\u7684\u63a2\u6d4b\u80fd\u529b\u3002"}}
{"id": "2511.01279", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.01279", "abs": "https://arxiv.org/abs/2511.01279", "authors": ["Sonali Gupta", "Amit Kumar", "Vikas S Bhat", "Sushil Mujumdar"], "title": "Super-resolved reconstruction of single-photon emitter locations from $g^{(2)}(0)$ maps", "comment": "17 pages, 5 figures. Submitted for peer review on September 25, 2025", "summary": "Single-photon sources are vital for emerging quantum technologies. In\nparticular, Nitrogen-vacancy (NV) centers in diamond are promising due to their\nroom-temperature stability, long spin coherence, and compatibility with\nnanophotonic structures. A key challenge, however, is the reliable\nidentification of isolated NV centers, since conventional confocal microscopy\nis diffraction-limited and cannot resolve emitter distributions within a focal\nspot. Besides, the associated intensity scanning is a time-expensive procedure.\nHere, we introduce a raster-scanned $g^{(2)}(0)$ mapping technique combined\nwith an inversion-based reconstruction algorithm. By directly measuring local\nphoton antibunching across the field of view, we extract the effective emitter\nnumber within each focal spot and reconstruct occupancy maps on a\nsub-focal-spot grid. This enables recovery of the number and spatial\ndistribution of emitters within regions smaller than the confocal focal spot,\nthereby offering possibilities of going beyond the diffraction limit. Our\nsimulations confirm robust reconstruction of NV-center distributions. The\nmethod provides a practical diagnostic tool for locating single-photon sources\nin an efficient and accurate manner, at much lesser time and effort compared to\nconventional intensity scanning. It offers valuable feedback for nanophotonic\ndevice fabrication, supporting more precise and scalable integration of\nNV-based quantum photonic technologies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5149\u6805\u626b\u63cfg(2)(0)\u6620\u5c04\u548c\u53cd\u6f14\u91cd\u5efa\u7b97\u6cd5\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u51c6\u786e\u5730\u8bc6\u522b\u91d1\u521a\u77f3\u4e2d\u5355\u4e2a\u6c2e\u7a7a\u4f4d\u4e2d\u5fc3\uff0c\u7a81\u7834\u884d\u5c04\u6781\u9650\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u5171\u805a\u7126\u663e\u5fae\u955c\u53d7\u884d\u5c04\u6781\u9650\u9650\u5236\uff0c\u65e0\u6cd5\u5206\u8fa8\u7126\u70b9\u5185\u7684\u53d1\u5c04\u5668\u5206\u5e03\uff0c\u4e14\u5f3a\u5ea6\u626b\u63cf\u8017\u65f6\u3002\u9700\u8981\u5f00\u53d1\u80fd\u53ef\u9760\u8bc6\u522b\u5b64\u7acbNV\u4e2d\u5fc3\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5149\u6805\u626b\u63cfg(2)(0)\u6620\u5c04\u6280\u672f\uff0c\u7ed3\u5408\u53cd\u6f14\u91cd\u5efa\u7b97\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u6d4b\u91cf\u5c40\u90e8\u5149\u5b50\u53cd\u805a\u675f\u6765\u63d0\u53d6\u7126\u70b9\u5185\u7684\u6709\u6548\u53d1\u5c04\u5668\u6570\u91cf\u3002", "result": "\u80fd\u591f\u5728\u5c0f\u4e8e\u5171\u805a\u7126\u7126\u70b9\u7684\u533a\u57df\u5185\u91cd\u5efa\u53d1\u5c04\u5668\u6570\u91cf\u548c\u7a7a\u95f4\u5206\u5e03\uff0c\u6a21\u62df\u8bc1\u5b9e\u4e86NV\u4e2d\u5fc3\u5206\u5e03\u7684\u7a33\u5065\u91cd\u5efa\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9a\u4f4d\u5355\u5149\u5b50\u6e90\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u76f8\u6bd4\u4f20\u7edf\u5f3a\u5ea6\u626b\u63cf\u66f4\u9ad8\u6548\u51c6\u786e\uff0c\u6709\u52a9\u4e8eNV\u57fa\u91cf\u5b50\u5149\u5b50\u6280\u672f\u7684\u7cbe\u786e\u96c6\u6210\u3002"}}
{"id": "2511.00100", "categories": ["cs.LG", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "stat.AP", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00100", "abs": "https://arxiv.org/abs/2511.00100", "authors": ["Marios Impraimakis"], "title": "Deep recurrent-convolutional neural network learning and physics Kalman filtering comparison in dynamic load identification", "comment": "31 pages, 20 figures, published in Structural Health Monitoring", "summary": "The dynamic structural load identification capabilities of the gated\nrecurrent unit, long short-term memory, and convolutional neural networks are\nexamined herein. The examination is on realistic small dataset training\nconditions and on a comparative view to the physics-based residual Kalman\nfilter (RKF). The dynamic load identification suffers from the uncertainty\nrelated to obtaining poor predictions when in civil engineering applications\nonly a low number of tests are performed or are available, or when the\nstructural model is unidentifiable. In considering the methods, first, a\nsimulated structure is investigated under a shaker excitation at the top floor.\nSecond, a building in California is investigated under seismic base excitation,\nwhich results in loading for all degrees of freedom. Finally, the International\nAssociation for Structural Control-American Society of Civil Engineers\n(IASC-ASCE) structural health monitoring benchmark problem is examined for\nimpact and instant loading conditions. Importantly, the methods are shown to\noutperform each other on different loading scenarios, while the RKF is shown to\noutperform the networks in physically parametrized identifiable cases.", "AI": {"tldr": "\u6bd4\u8f83\u95e8\u63a7\u5faa\u73af\u5355\u5143\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u52a8\u6001\u7ed3\u6784\u8f7d\u8377\u8bc6\u522b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u57fa\u4e8e\u7269\u7406\u7684\u6b8b\u5dee\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5206\u6790\u5728\u4e0d\u540c\u8f7d\u8377\u573a\u666f\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u89e3\u51b3\u571f\u6728\u5de5\u7a0b\u5e94\u7528\u4e2d\u7531\u4e8e\u6d4b\u8bd5\u6570\u636e\u6709\u9650\u6216\u7ed3\u6784\u6a21\u578b\u4e0d\u53ef\u8bc6\u522b\u5bfc\u81f4\u7684\u52a8\u6001\u8f7d\u8377\u8bc6\u522b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u5728\u5c0f\u6570\u636e\u96c6\u6761\u4ef6\u4e0b\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff08GRU\u3001LSTM\u3001CNN\uff09\u548c\u6b8b\u5dee\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08RKF\uff09\uff0c\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\uff1a\u6a21\u62df\u7ed3\u6784\u5728\u9876\u5c42\u6fc0\u632f\u5668\u6fc0\u52b1\u4e0b\u7684\u54cd\u5e94\u3001\u52a0\u5dde\u5efa\u7b51\u5728\u5730\u9707\u57fa\u7840\u6fc0\u52b1\u4e0b\u7684\u54cd\u5e94\u3001IASC-ASCE\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u57fa\u51c6\u95ee\u9898\u7684\u51b2\u51fb\u548c\u77ac\u65f6\u8f7d\u8377\u6761\u4ef6\u3002", "result": "\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u8f7d\u8377\u573a\u666f\u4e0b\u8868\u73b0\u5404\u5f02\uff0cRKF\u5728\u7269\u7406\u53c2\u6570\u53ef\u8bc6\u522b\u60c5\u51b5\u4e0b\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u5728\u5176\u4ed6\u573a\u666f\u4e0b\u53ef\u80fd\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5404\u79cd\u65b9\u6cd5\u5728\u4e0d\u540c\u8f7d\u8377\u8bc6\u522b\u573a\u666f\u4e2d\u5404\u6709\u4f18\u52bf\uff0cRKF\u5728\u7269\u7406\u53c2\u6570\u53ef\u8bc6\u522b\u60c5\u51b5\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u795e\u7ecf\u7f51\u7edc\u5728\u5c0f\u6570\u636e\u96c6\u6761\u4ef6\u4e0b\u4ecd\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01684", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2511.01684", "abs": "https://arxiv.org/abs/2511.01684", "authors": ["R. Morales-Cabrera", "Y. Bonder"], "title": "Semiclassical Gravity Beyond General Relativity: Insights from Torsion", "comment": "23 + 4 pages", "summary": "We develop a semiclassical theory of modified gravity with nontrivial\nspacetime torsion. In particular, we show that the semiclassical treatment can\nbe axiomatized in the case of Einstein--Cartan theory with a nonminimally\ncoupled, free Klein--Gordon field, in four dimensions. Using Hadamard\nrenormalization, we obtain well-defined expectation values for both, the\nenergy--momentum and spin--density operators. These objects exhibit scale and\nrenormalization ambiguities; we identify the latter by constructing a\nrenormalization Lagrangian in terms of differential forms, which are\nparticularly well suited for this purpose. Furthermore, we analyze the\nconformal anomaly, which persists in the presence of torsion.", "AI": {"tldr": "\u672c\u6587\u53d1\u5c55\u4e86\u5177\u6709\u975e\u5e73\u51e1\u65f6\u7a7a\u6320\u7387\u7684\u4fee\u6b63\u5f15\u529b\u7684\u534a\u7ecf\u5178\u7406\u8bba\uff0c\u7279\u522b\u5728\u56db\u7ef4\u7231\u56e0\u65af\u5766-\u5609\u5f53\u7406\u8bba\u4e2d\u5efa\u7acb\u4e86\u534a\u7ecf\u5178\u5904\u7406\u7684\u516c\u7406\u5316\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u6320\u7387\u5b58\u5728\u4e0b\u7684\u4fee\u6b63\u5f15\u529b\u7406\u8bba\uff0c\u7279\u522b\u662f\u5728\u7231\u56e0\u65af\u5766-\u5609\u5f53\u7406\u8bba\u6846\u67b6\u4e0b\uff0c\u5904\u7406\u975e\u6700\u5c0f\u8026\u5408\u81ea\u7531\u514b\u83b1\u56e0-\u6208\u767b\u573a\u7684\u60c5\u51b5\u3002", "method": "\u4f7f\u7528Hadamard\u91cd\u6574\u5316\u65b9\u6cd5\uff0c\u83b7\u5f97\u80fd\u91cf-\u52a8\u91cf\u548c\u81ea\u65cb\u5bc6\u5ea6\u7b97\u7b26\u7684\u660e\u786e\u5b9a\u4e49\u671f\u671b\u503c\uff0c\u5e76\u901a\u8fc7\u5fae\u5206\u5f62\u5f0f\u6784\u5efa\u91cd\u6574\u5316\u62c9\u683c\u6717\u65e5\u91cf\u6765\u8bc6\u522b\u91cd\u6574\u5316\u6a21\u7cca\u6027\u3002", "result": "\u83b7\u5f97\u4e86\u80fd\u91cf-\u52a8\u91cf\u548c\u81ea\u65cb\u5bc6\u5ea6\u7b97\u7b26\u7684\u660e\u786e\u5b9a\u4e49\u671f\u671b\u503c\uff0c\u8bc6\u522b\u4e86\u5c3a\u5ea6\u91cd\u6574\u5316\u6a21\u7cca\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5728\u6320\u7387\u5b58\u5728\u4e0b\u6301\u7eed\u5b58\u5728\u7684\u5171\u5f62\u53cd\u5e38\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u6320\u7387\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u7684\u534a\u7ecf\u5178\u5904\u7406\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u91cd\u6574\u5316\u95ee\u9898\u5e76\u786e\u8ba4\u4e86\u5171\u5f62\u53cd\u5e38\u7684\u6301\u7eed\u6027\u3002"}}
{"id": "2511.01300", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01300", "abs": "https://arxiv.org/abs/2511.01300", "authors": ["Zong-Wei Wu", "Jun-Hong An"], "title": "Strongly coupled giant-atom waveguide quantum electrodynamics", "comment": null, "summary": "Describing systems of superconducting atoms coupled to a continuum of\nphotonic modes at multiple separated locations in a waveguide, waveguide\nquantum electrodynamics (QED) with giant atoms has emerged as a promising\nplatform for realizing quantum interconnect. Such systems have been reported to\nexhibit rich phenomena that differ from those of natural atoms. Going beyond\nthe widely used Born-Markov and Wigner-Weisskopf approximations, we investigate\nthe non-Markovian dynamics of one and two giant atoms interacting with a\nwaveguide formed by an array of coupled resonators. We discover that the\ndiverse dynamical behaviors of the giant atoms are intrinsically determined by\nthe energy spectrum of the composite system consisting of the giant atoms and\nthe photonic modes in the waveguide. As long as one and more bound states are\npresent in the energy spectrum, their excited-state probabilities,\nrespectively, tend to stable finite values and lossless Rabi-like oscillations\nwith frequencies proportional to the differences of the bound-state\neigenenergies. Our result provides an insightful guideline for suppressing the\ndecoherence of giant atoms and facilitates the development of quantum\ninterconnect devices using giant-atom waveguide QED.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5de8\u578b\u539f\u5b50\u4e0e\u6ce2\u5bfc\u8026\u5408\u7cfb\u7edf\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u675f\u7f1a\u6001\u7684\u5b58\u5728\u80fd\u6291\u5236\u9000\u76f8\u5e72\u5e76\u4ea7\u751f\u7a33\u5b9a\u7684\u62c9\u6bd4\u632f\u8361\u3002", "motivation": "\u5de8\u578b\u539f\u5b50\u6ce2\u5bfc\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u662f\u5b9e\u73b0\u91cf\u5b50\u4e92\u8fde\u7684\u6709\u524d\u666f\u5e73\u53f0\uff0c\u4f46\u4f20\u7edfBorn-Markov\u548cWigner-Weisskopf\u8fd1\u4f3c\u65e0\u6cd5\u51c6\u786e\u63cf\u8ff0\u5176\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u8d85\u8d8a\u4f20\u7edf\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7814\u7a76\u5355\u4e2a\u548c\u4e24\u4e2a\u5de8\u578b\u539f\u5b50\u4e0e\u8026\u5408\u8c10\u632f\u5668\u9635\u5217\u6ce2\u5bfc\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\u3002", "result": "\u53d1\u73b0\u5de8\u578b\u539f\u5b50\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u7531\u590d\u5408\u7cfb\u7edf\u7684\u80fd\u8c31\u51b3\u5b9a\uff1a\u5f53\u80fd\u8c31\u4e2d\u5b58\u5728\u675f\u7f1a\u6001\u65f6\uff0c\u6fc0\u53d1\u6001\u6982\u7387\u8d8b\u4e8e\u7a33\u5b9a\u6709\u9650\u503c\uff0c\u5e76\u4ea7\u751f\u65e0\u635f\u8017\u7684\u62c9\u6bd4\u632f\u8361\u3002", "conclusion": "\u7ed3\u679c\u4e3a\u6291\u5236\u5de8\u578b\u539f\u5b50\u9000\u76f8\u5e72\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u57fa\u4e8e\u5de8\u578b\u539f\u5b50\u6ce2\u5bfcQED\u7684\u91cf\u5b50\u4e92\u8fde\u5668\u4ef6\u3002"}}
{"id": "2511.00101", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00101", "abs": "https://arxiv.org/abs/2511.00101", "authors": ["Yuchen Zhang", "Hanyue Du", "Chun Cao", "Jingwei Xu"], "title": "Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving", "comment": "26 pages including 10 pages of main text, 6 figures, 39th Conference\n  on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted parameter-efficient\nfine-tuning (PEFT) technique for adapting large language models (LLMs) to\ndownstream tasks. While prior work has explored strategies for integrating LLM\ntraining and serving, there still remains a gap in unifying fine-tuning and\ninference for LoRA-based models. We present Loquetier, a virtualized multi-LoRA\nframework that seamlessly integrates LoRA fine-tuning and serving within a\nsingle runtime. Loquetier introduces two key components: (1) a Virtualized\nModule that isolates PEFT-based modifications and supports multiple adapters on\na shared base model, and (2) an optimized computation flow with a kernel design\nthat merges fine-tuning and inference paths in forward propagation, enabling\nefficient batching and minimizing kernel invocation overhead. Extensive\nexperiments across three task settings show that Loquetier consistently\noutperforms existing baselines in both performance and flexibility, achieving\nup to $3.0\\times$ the throughput of the state-of-the-art co-serving system on\ninference-only tasks and $46.4\\times$ higher SLO attainment than PEFT on\nunified fine-tuning and inference tasks. The implementation of Loquetier is\npublicly available at https://github.com/NJUDeepEngine/Loquetier.", "AI": {"tldr": "Loquetier\u662f\u4e00\u4e2a\u865a\u62df\u5316\u591aLoRA\u6846\u67b6\uff0c\u7edf\u4e00\u4e86LoRA\u5fae\u8c03\u548c\u670d\u52a1\uff0c\u901a\u8fc7\u865a\u62df\u5316\u6a21\u5757\u548c\u4f18\u5316\u8ba1\u7b97\u6d41\u5b9e\u73b0\u9ad8\u6548\u6279\u5904\u7406\u548c\u6700\u5c0f\u5316\u5185\u6838\u8c03\u7528\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u7edf\u4e00LoRA\u5fae\u8c03\u548c\u670d\u52a1\u65b9\u9762\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u652f\u6301\u591a\u9002\u914d\u5668\u5fae\u8c03\u548c\u63a8\u7406\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u865a\u62df\u5316\u6a21\u5757\u9694\u79bbPEFT\u4fee\u6539\u5e76\u652f\u6301\u5171\u4eab\u57fa\u7840\u6a21\u578b\u4e0a\u7684\u591a\u9002\u914d\u5668\uff0c\u4ee5\u53ca\u4f18\u5316\u7684\u8ba1\u7b97\u6d41\u8bbe\u8ba1\uff0c\u5728\u6b63\u5411\u4f20\u64ad\u4e2d\u5408\u5e76\u5fae\u8c03\u548c\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u8bbe\u7f6e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLoquetier\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u63a8\u7406\u4efb\u52a1\u541e\u5410\u91cf\u8fbe\u5230\u6700\u5148\u8fdb\u5171\u670d\u52a1\u7cfb\u7edf\u76843.0\u500d\uff0c\u7edf\u4e00\u5fae\u8c03\u548c\u63a8\u7406\u4efb\u52a1\u7684SLO\u8fbe\u6210\u7387\u6bd4PEFT\u9ad846.4\u500d\u3002", "conclusion": "Loquetier\u6210\u529f\u586b\u8865\u4e86LoRA\u5fae\u8c03\u548c\u670d\u52a1\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6548\u7edf\u4e00\u7684\u591aLoRA\u6846\u67b6\u3002"}}
{"id": "2511.01693", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.01693", "abs": "https://arxiv.org/abs/2511.01693", "authors": ["Giuseppe Gaetano Luciano", "Emmanuel N. Saridakis"], "title": "Baryogenesis constraints on generalized mass-to-horizon entropy", "comment": "9 pages, 1 figure, 2 tables", "summary": "We investigate the generation of the baryon asymmetry within the cosmological\nframework based on a generalized mass-to-horizon entropy. This entropy,\nrecently proposed as a power-law extension of the Bekenstein-Hawking area law,\narises from a modified mass-horizon relation constructed to ensure consistency\nwith the Clausius relation. By applying the gravity-thermodynamics conjecture,\nthe resulting corrections to the Friedmann equations modify the evolution of\nthe Hubble parameter. Consequently, even the standard supergravity coupling\nbetween the Ricci scalar and the baryon current can generate a non-vanishing\nmatter-antimatter asymmetry. Comparison with observational data yields a\nstringent constraint on the entropic exponent, namely $0 < 1 - n \\lesssim\n\\mathcal{O}(10^{-2})$, at the decoupling temperature $T_D \\simeq\n10^{16}\\,\\text{GeV}$, corresponding to the current upper limit on tensor-mode\nfluctuations at the inflationary scale. These findings indicate that minor,\nsubtle, yet physically significant departures, from the standard\nBekenstein-Hawking entropy ($n = 1$) may be required to achieve full\nconsistency with present cosmological observations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5e7f\u4e49\u8d28\u91cf-\u89c6\u754c\u71b5\u7684\u5b87\u5b99\u5b66\u6846\u67b6\u4e0b\u751f\u6210\u91cd\u5b50\u4e0d\u5bf9\u79f0\u6027\u3002\u8fd9\u79cd\u71b5\u662fBekenstein-Hawking\u9762\u79ef\u5b9a\u5f8b\u7684\u5e42\u5f8b\u6269\u5c55\uff0c\u901a\u8fc7\u5e94\u7528\u5f15\u529b-\u70ed\u529b\u5b66\u731c\u60f3\uff0c\u4fee\u6b63\u4e86\u5f17\u91cc\u5fb7\u66fc\u65b9\u7a0b\u548c\u54c8\u52c3\u53c2\u6570\u7684\u6f14\u5316\uff0c\u4f7f\u5f97\u6807\u51c6\u8d85\u5f15\u529b\u8026\u5408\u53ef\u4ee5\u4ea7\u751f\u975e\u96f6\u7684\u7269\u8d28-\u53cd\u7269\u8d28\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u63a2\u7d22\u5728\u4fee\u6b63\u7684\u5f15\u529b-\u70ed\u529b\u5b66\u6846\u67b6\u4e0b\u5982\u4f55\u89e3\u91ca\u5b87\u5b99\u4e2d\u89c2\u6d4b\u5230\u7684\u91cd\u5b50\u4e0d\u5bf9\u79f0\u6027\uff0c\u7279\u522b\u662f\u7814\u7a76\u504f\u79bb\u6807\u51c6Bekenstein-Hawking\u71b5\u7684\u5fae\u5c0f\u4fee\u6b63\u5bf9\u91cd\u5b50\u751f\u6210\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5e7f\u4e49\u8d28\u91cf-\u89c6\u754c\u71b5\u4f5c\u4e3aBekenstein-Hawking\u9762\u79ef\u5b9a\u5f8b\u7684\u5e42\u5f8b\u6269\u5c55\uff0c\u5e94\u7528\u5f15\u529b-\u70ed\u529b\u5b66\u731c\u60f3\u63a8\u5bfc\u4fee\u6b63\u7684\u5f17\u91cc\u5fb7\u66fc\u65b9\u7a0b\uff0c\u5206\u6790\u54c8\u52c3\u53c2\u6570\u6f14\u5316\u5bf9\u91cd\u5b50\u4e0d\u5bf9\u79f0\u6027\u751f\u6210\u7684\u5f71\u54cd\u3002", "result": "\u5373\u4f7f\u4f7f\u7528\u6807\u51c6\u7684\u8d85\u5f15\u529b\u8026\u5408\uff0c\u4fee\u6b63\u7684\u54c8\u52c3\u53c2\u6570\u6f14\u5316\u4e5f\u80fd\u4ea7\u751f\u975e\u96f6\u7684\u91cd\u5b50\u4e0d\u5bf9\u79f0\u6027\u3002\u4e0e\u89c2\u6d4b\u6570\u636e\u6bd4\u8f83\uff0c\u5bf9\u71b5\u6307\u6570\u7ed9\u51fa\u4e86\u4e25\u683c\u7ea6\u675f\uff1a0 < 1 - n \u2272 O(10^-2)\uff0c\u5728\u9000\u8026\u6e29\u5ea6T_D \u2243 10^16 GeV\u65f6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4ece\u6807\u51c6Bekenstein-Hawking\u71b5\uff08n=1\uff09\u7684\u5fae\u5c0f\u4f46\u7269\u7406\u4e0a\u663e\u8457\u7684\u504f\u79bb\uff0c\u53ef\u80fd\u662f\u5b9e\u73b0\u4e0e\u5f53\u524d\u5b87\u5b99\u5b66\u89c2\u6d4b\u5b8c\u5168\u4e00\u81f4\u6027\u6240\u5fc5\u9700\u7684\u3002"}}
{"id": "2511.01312", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01312", "abs": "https://arxiv.org/abs/2511.01312", "authors": ["Asa Hopkins", "Viv Kendon"], "title": "Multi-stage quantum walks for finding Ising ground states", "comment": "14 pages (including appendix), 7 figures", "summary": "One way to approximate a quantum annealing schedule is to use multiple\nquantum walks chained together, without intermediate measurements, to produce a\nmulti-stage quantum walk (MSQW). Previous work has shown that MSQW is better\nthan QAOA (quantum alternating operator ansatz) for solving optimization tasks\nusing multiple stages [Gerblich et al, arXiv:2407.06663]. In this work, we\ndevelop an efficient heuristic for choosing the free parameters in MSQW, and\nuse it to obtain improved scaling compared to single stage quantum walks. We\nshow numerically that the heuristic works well for easy problems with a large\nminimum energy gap, giving a scaling polynomial in the number of stages,\nleading to an overall algorithm that scales polynomially in time. For harder\nproblems, the scaling breaks down such that adding more stages decreases the\nsuccess probability, leading to an overall scaling that is exponential in time,\nas expected. Our methods are general and can be applied to any optimization\nproblem to obtain good annealing schedules.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u9636\u6bb5\u91cf\u5b50\u884c\u8d70(MSQW)\u7684\u9ad8\u6548\u542f\u53d1\u5f0f\u53c2\u6570\u9009\u62e9\u65b9\u6cd5\uff0c\u76f8\u6bd4\u5355\u9636\u6bb5\u91cf\u5b50\u884c\u8d70\u83b7\u5f97\u4e86\u6539\u8fdb\u7684\u7f29\u653e\u6027\u80fd\u3002\u5bf9\u4e8e\u7b80\u5355\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u591a\u9879\u5f0f\u65f6\u95f4\u7f29\u653e\uff1b\u5bf9\u4e8e\u56f0\u96be\u95ee\u9898\uff0c\u7f29\u653e\u6027\u80fd\u4f1a\u4e0b\u964d\u3002", "motivation": "\u591a\u9636\u6bb5\u91cf\u5b50\u884c\u8d70(MSQW)\u5df2\u88ab\u8bc1\u660e\u5728\u89e3\u51b3\u4f18\u5316\u4efb\u52a1\u65f6\u4f18\u4e8eQAOA\uff0c\u4f46\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u81ea\u7531\u53c2\u6570\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7f29\u653e\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u9009\u62e9MSQW\u4e2d\u7684\u81ea\u7531\u53c2\u6570\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u83b7\u5f97\u6bd4\u5355\u9636\u6bb5\u91cf\u5b50\u884c\u8d70\u66f4\u597d\u7684\u7f29\u653e\u6027\u80fd\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u5177\u6709\u5927\u6700\u5c0f\u80fd\u9699\u7684\u7b80\u5355\u95ee\u9898\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u5b9e\u73b0\u4e86\u9636\u6bb5\u6570\u7684\u591a\u9879\u5f0f\u7f29\u653e\uff0c\u4ece\u800c\u5f97\u5230\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u6574\u4f53\u7b97\u6cd5\u3002\u5bf9\u4e8e\u56f0\u96be\u95ee\u9898\uff0c\u7f29\u653e\u6027\u80fd\u4f1a\u4e0b\u964d\uff0c\u5bfc\u81f4\u6307\u6570\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u4f18\u5316\u95ee\u9898\u4ee5\u83b7\u5f97\u826f\u597d\u7684\u9000\u706b\u8c03\u5ea6\u65b9\u6848\u3002"}}
{"id": "2511.00102", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00102", "abs": "https://arxiv.org/abs/2511.00102", "authors": ["Vivan Doshi"], "title": "Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers", "comment": "5th Math-AI Workshop - Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "The discovery of conservation laws is a cornerstone of scientific progress.\nHowever, identifying these invariants from observational data remains a\nsignificant challenge. We propose a hybrid framework to automate the discovery\nof conserved quantities from noisy trajectory data. Our approach integrates\nthree components: (1) a Neural Ordinary Differential Equation (Neural ODE) that\nlearns a continuous model of the system's dynamics, (2) a Transformer that\ngenerates symbolic candidate invariants conditioned on the learned vector\nfield, and (3) a symbolic-numeric verifier that provides a strong numerical\ncertificate for the validity of these candidates. We test our framework on\ncanonical physical systems and show that it significantly outperforms baselines\nthat operate directly on trajectory data. This work demonstrates the robustness\nof a decoupled learn-then-search approach for discovering mathematical\nprinciples from imperfect data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff0c\u4ece\u566a\u58f0\u8f68\u8ff9\u6570\u636e\u4e2d\u81ea\u52a8\u53d1\u73b0\u5b88\u6052\u91cf\uff0c\u7ed3\u5408\u795e\u7ecfODE\u3001Transformer\u548c\u7b26\u53f7-\u6570\u503c\u9a8c\u8bc1\u5668\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u5728\u8f68\u8ff9\u6570\u636e\u4e0a\u64cd\u4f5c\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u8bc6\u522b\u5b88\u6052\u5b9a\u5f8b\u662f\u79d1\u5b66\u8fdb\u6b65\u7684\u5173\u952e\uff0c\u4f46\u76ee\u524d\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u53d1\u73b0\u8fd9\u4e9b\u4e0d\u53d8\u91cf\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u96c6\u6210\u4e09\u4e2a\u7ec4\u4ef6\uff1a(1) \u795e\u7ecfODE\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u8fde\u7eed\u6a21\u578b\uff0c(2) Transformer\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u5411\u91cf\u573a\u751f\u6210\u7b26\u53f7\u5019\u9009\u4e0d\u53d8\u91cf\uff0c(3) \u7b26\u53f7-\u6570\u503c\u9a8c\u8bc1\u5668\u4e3a\u5019\u9009\u91cf\u7684\u6709\u6548\u6027\u63d0\u4f9b\u5f3a\u6570\u503c\u8bc1\u4e66\u3002", "result": "\u5728\u5178\u578b\u7269\u7406\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u5728\u8f68\u8ff9\u6570\u636e\u4e0a\u64cd\u4f5c\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5206\u79bb\u5f0f\"\u5148\u5b66\u4e60\u540e\u641c\u7d22\"\u65b9\u6cd5\u4ece\u975e\u5b8c\u7f8e\u6570\u636e\u4e2d\u53d1\u73b0\u6570\u5b66\u539f\u7406\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01713", "categories": ["gr-qc", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.01713", "abs": "https://arxiv.org/abs/2511.01713", "authors": ["Rodrigo Avalos", "Eric Ling", "Annachiara Piubello"], "title": "On energy and its positivity in spacetimes with an expanding flat de Sitter background", "comment": "16 pages, 2 figures", "summary": "The positive energy theorems are a fundamental pillar in mathematical general\nrelativity. Originally proved by Schoen-Yau and later Witten, these theorems\nwere established for asymptotically flat manifolds where the metric tends to\nthe standard Euclidean metric and whose second fundamental form decays to zero\nat infinity. This ansatz on the metric and second fundamental form is motivated\nby the desire to model an isolated gravitational system with a Minkowski space\nbackground for the spacetime. However, actual astrophysical massive objects are\nnot truly isolated but rather exist within an expanding cosmological universe,\nwhere the second fundamental form is umbilic. With this in mind, we seek a\nnotion of energy for initial data sets with an umbilic second fundamental form.\nIn this work, we present a definition of energy in such an expanding\ncosmological setting. Instead of Minkowski space, we take de Sitter space as\nthe background spacetime, which, when written in flat-expanding coordinates, is\nfoliated by umbilic hypersurfaces each isometric to Euclidean 3-space. This\ncosmological setting necessitates a quasi-local energy definition, as the\npresence of a cosmological horizon in de Sitter space obstructs a global one.\nWe define energy in this quasi-local setting by adapting the Liu-Yau energy to\nour framework and establish positivity of this energy for certain bounded\nvalues of the cosmological constant.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u81a8\u80c0\u5b87\u5b99\u80cc\u666f\u4e0b\uff08\u4ee5\u5fb7\u897f\u7279\u7a7a\u95f4\u4e3a\u80cc\u666f\u65f6\u7a7a\uff09\u7684\u80fd\u91cf\u5b9a\u4e49\uff0c\u5c06\u6b63\u80fd\u5b9a\u7406\u6269\u5c55\u5230\u5177\u6709\u8110\u70b9\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f\u7684\u521d\u59cb\u6570\u636e\u96c6\uff0c\u5e76\u5efa\u7acb\u4e86\u8be5\u80fd\u91cf\u7684\u6b63\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u6b63\u80fd\u5b9a\u7406\u57fa\u4e8e\u6e10\u8fd1\u5e73\u5766\u6d41\u5f62\uff0c\u5047\u8bbe\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f\u5728\u65e0\u7a77\u8fdc\u5904\u8870\u51cf\u4e3a\u96f6\uff0c\u7528\u4e8e\u6a21\u62df\u5b64\u7acb\u5f15\u529b\u7cfb\u7edf\u3002\u4f46\u5b9e\u9645\u5929\u4f53\u5b58\u5728\u4e8e\u81a8\u80c0\u5b87\u5b99\u4e2d\uff0c\u5176\u7b2c\u4e8c\u57fa\u672c\u5f62\u5f0f\u662f\u8110\u70b9\u7684\uff0c\u56e0\u6b64\u9700\u8981\u4e3a\u8fd9\u79cd\u5b87\u5b99\u5b66\u80cc\u666f\u5b9a\u4e49\u80fd\u91cf\u6982\u5ff5\u3002", "method": "\u4ee5\u5fb7\u897f\u7279\u7a7a\u95f4\u4e3a\u80cc\u666f\u65f6\u7a7a\uff0c\u91c7\u7528\u5e73\u5766\u81a8\u80c0\u5750\u6807\uff0c\u8be5\u7a7a\u95f4\u88ab\u8110\u70b9\u8d85\u66f2\u9762\u53f6\u72b6\u5316\u3002\u7531\u4e8e\u5fb7\u897f\u7279\u7a7a\u95f4\u4e2d\u5b87\u5b99\u89c6\u754c\u7684\u5b58\u5728\u963b\u788d\u4e86\u5168\u5c40\u80fd\u91cf\u5b9a\u4e49\uff0c\u56e0\u6b64\u91c7\u7528\u51c6\u5c40\u57df\u80fd\u91cf\u5b9a\u4e49\u65b9\u6cd5\uff0c\u5c06Liu-Yau\u80fd\u91cf\u9002\u914d\u5230\u8be5\u6846\u67b6\u4e2d\u3002", "result": "\u5efa\u7acb\u4e86\u5728\u81a8\u80c0\u5b87\u5b99\u5b66\u80cc\u666f\u4e0b\u7684\u51c6\u5c40\u57df\u80fd\u91cf\u5b9a\u4e49\uff0c\u5e76\u8bc1\u660e\u4e86\u5bf9\u4e8e\u5b87\u5b99\u5b66\u5e38\u6570\u7684\u67d0\u4e9b\u6709\u754c\u503c\uff0c\u8be5\u80fd\u91cf\u662f\u6b63\u7684\u3002", "conclusion": "\u6210\u529f\u5c06\u6b63\u80fd\u5b9a\u7406\u6269\u5c55\u5230\u5b87\u5b99\u5b66\u80cc\u666f\uff0c\u4e3a\u7814\u7a76\u81a8\u80c0\u5b87\u5b99\u4e2d\u7684\u5f15\u529b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u80fd\u91cf\u4ecd\u7136\u4fdd\u6301\u6b63\u5b9a\u6027\u3002"}}
{"id": "2511.01313", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2511.01313", "abs": "https://arxiv.org/abs/2511.01313", "authors": ["L. Y. Wu", "H. Yan"], "title": "Light-induced Frequency Shift and Relaxation of Ground-State 3He via Metastability-Exchange Collisions", "comment": "9 pages, 5 figures", "summary": "Metastability-exchange collisions (MECs) lie at the heart of\nmetastability-exchange optical pumping (MEOP) in 3He, enabling the transfer of\npolarization from the metastable state to the ground state, as well as the\noptical detection of nuclear magnetic resonance. Leveraging MECs, optically\npumped 3He nuclear magnetometers have been developed since the earliest\ndemonstrations of MEOP. However, it also induces an additional frequency shift\nand relaxation of the nuclear spin precession, thereby limiting the sensitivity\nof the magnetometer. In this work, we identify a new source of frequency shift\nand relaxation in the 3He nuclear spin, arising from the light shift. This\neffect arises from an MEC-mediated interaction between light and the nucleon\nspin. We develop a theoretical model to describe this light-induced effect and\nhighlight its significance in low magnetic fields. This effect is\nexperimentally demonstrated, and its dependence on various parameters --\nincluding magnetic field strength, light intensity, and wavelength -- is\ninvestigated. Our result provides a better understanding of the frequency shift\nand relaxation of 3He spin precession under MEOP conditions. Moreover, our\nexperiment reveals an MEC-mediated coupling between the 3He nuclear spin and\nlight, which may indicate the feasibility of MEC-assisted optical manipulation\nof 3He nuclear spins at the quantum level, as proposed in several theoretical\nschemes.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5e76\u7814\u7a76\u4e86\u6c26-3\u6838\u81ea\u65cb\u4e2d\u7531\u5149\u4f4d\u79fb\u5f15\u8d77\u7684\u65b0\u9891\u7387\u504f\u79fb\u548c\u5f1b\u8c6b\u6548\u5e94\uff0c\u8be5\u6548\u5e94\u6e90\u4e8e\u4e9a\u7a33\u6001\u4ea4\u6362\u78b0\u649e\u4ecb\u5bfc\u7684\u5149\u4e0e\u6838\u5b50\u81ea\u65cb\u76f8\u4e92\u4f5c\u7528\uff0c\u5bf9\u4f4e\u78c1\u573a\u4e0b\u7684\u6838\u78c1\u5171\u632f\u6d4b\u91cf\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u4e9a\u7a33\u6001\u4ea4\u6362\u78b0\u649e\u5728\u6c26-3\u6838\u78c1\u5f3a\u8ba1\u4e2d\u65e2\u5b9e\u73b0\u4e86\u5149\u5b66\u6cf5\u6d66\u548c\u68c0\u6d4b\uff0c\u53c8\u5f15\u5165\u4e86\u989d\u5916\u7684\u9891\u7387\u504f\u79fb\u548c\u5f1b\u8c6b\uff0c\u9650\u5236\u4e86\u78c1\u5f3a\u8ba1\u7684\u7075\u654f\u5ea6\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522b\u5e76\u7406\u89e3\u8fd9\u4e9b\u6548\u5e94\u7684\u65b0\u6765\u6e90\u3002", "method": "\u5efa\u7acb\u4e86\u7406\u8bba\u6a21\u578b\u6765\u63cf\u8ff0\u5149\u8bf1\u5bfc\u6548\u5e94\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6548\u5e94\uff0c\u7814\u7a76\u4e86\u5176\u4e0e\u78c1\u573a\u5f3a\u5ea6\u3001\u5149\u5f3a\u548c\u6ce2\u957f\u7b49\u53c2\u6570\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5149\u4f4d\u79fb\u5f15\u8d77\u7684\u9891\u7387\u504f\u79fb\u548c\u5f1b\u8c6b\u6548\u5e94\uff0c\u63ed\u793a\u4e86\u4e9a\u7a33\u6001\u4ea4\u6362\u78b0\u649e\u4ecb\u5bfc\u7684\u6c26-3\u6838\u81ea\u65cb\u4e0e\u5149\u4e4b\u95f4\u7684\u8026\u5408\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u6c26-3\u81ea\u65cb\u8fdb\u52a8\u5728\u4e9a\u7a33\u6001\u4ea4\u6362\u5149\u5b66\u6cf5\u6d66\u6761\u4ef6\u4e0b\u7684\u9891\u7387\u504f\u79fb\u548c\u5f1b\u8c6b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u8868\u660e\u4e9a\u7a33\u6001\u4ea4\u6362\u78b0\u649e\u53ef\u80fd\u7528\u4e8e\u91cf\u5b50\u6c34\u5e73\u7684\u5149\u5b66\u64cd\u63a7\u6c26-3\u6838\u81ea\u65cb\u3002"}}
{"id": "2511.00108", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00108", "abs": "https://arxiv.org/abs/2511.00108", "authors": ["Yi Zhang", "Che Liu", "Xiancong Ren", "Hanchu Ni", "Shuai Zhang", "Zeyuan Ding", "Jiayu Hu", "Hanzhe Shan", "Zhenwei Niu", "Zhaoyang Liu", "Yue Zhao", "Junbo Qi", "Qinfan Zhang", "Dengjie Li", "Yidong Wang", "Jiachen Luo", "Yong Dai", "Jian Tang", "Xiaozhu Ju"], "title": "Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence", "comment": null, "summary": "This report presents Pelican-VL 1.0, a new family of open-source embodied\nbrain models with parameter scales ranging from 7 billion to 72 billion. Our\nexplicit mission is clearly stated as: To embed powerful intelligence into\nvarious embodiments. Pelican-VL 1.0 is currently the largest-scale open-source\nembodied multimodal brain model. Its core advantage lies in the in-depth\nintegration of data power and intelligent adaptive learning mechanisms.\nSpecifically, metaloop distilled a high-quality dataset from a raw dataset\ncontaining 4+ billion tokens. Pelican-VL 1.0 is trained on a large-scale\ncluster of 1000+ A800 GPUs, consuming over 50k+ A800 GPU-hours per checkpoint.\nThis translates to a 20.3% performance uplift from its base model and\noutperforms 100B-level open-source counterparts by 10.6%, placing it on par\nwith leading proprietary systems on well-known embodied benchmarks. We\nestablish a novel framework, DPPO (Deliberate Practice Policy Optimization),\ninspired by human metacognition to train Pelican-VL 1.0. We operationalize this\nas a metaloop that teaches the AI to practice deliberately, which is a\nRL-Refine-Diagnose-SFT loop.", "AI": {"tldr": "Pelican-VL 1.0\u662f\u5f53\u524d\u6700\u5927\u89c4\u6a21\u7684\u5f00\u6e90\u5177\u8eab\u591a\u6a21\u6001\u5927\u8111\u6a21\u578b\uff0c\u53c2\u6570\u91cf\u4ece70\u4ebf\u5230720\u4ebf\uff0c\u57281000+ A800 GPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u534720.3%\uff0c\u8d85\u8d8a1000\u4ebf\u7ea7\u5f00\u6e90\u6a21\u578b10.6%\u3002", "motivation": "\u5c06\u5f3a\u5927\u667a\u80fd\u5d4c\u5165\u5230\u5404\u79cd\u5177\u8eab\u7cfb\u7edf\u4e2d\uff0c\u63a8\u52a8\u5177\u8eab\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528DPPO\uff08\u523b\u610f\u7ec3\u4e60\u7b56\u7565\u4f18\u5316\uff09\u6846\u67b6\uff0c\u901a\u8fc7metaloop\u673a\u5236\u5b9e\u73b0RL-\u7cbe\u70bc-\u8bca\u65ad-SFT\u5faa\u73af\u8bad\u7ec3\u3002", "result": "\u5728\u77e5\u540d\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u9886\u5148\u4e13\u6709\u7cfb\u7edf\u76f8\u5f53\u7684\u6c34\u5e73\uff0cmetaloop\u4ece40\u4ebf+token\u539f\u59cb\u6570\u636e\u4e2d\u84b8\u998f\u51fa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "conclusion": "Pelican-VL 1.0\u901a\u8fc7\u6570\u636e\u529b\u91cf\u4e0e\u667a\u80fd\u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u5177\u8eab\u667a\u80fd\u6a21\u578b\u6807\u51c6\u3002"}}
{"id": "2511.01314", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01314", "abs": "https://arxiv.org/abs/2511.01314", "authors": ["Yuyang Tang", "Yu Yang", "Min An", "Fuli Li"], "title": "Distinct Critical Scaling of Quantum Fisher Information in a Quantum Rabi Triangle System", "comment": "15 pages, 9 figures", "summary": "Critical properties of a quantum system are recognized as valuable resources\nfor quantum metrology. In this work, we investigate the criticality-enhanced\nsensing in a quantum Rabi triangle system, which exhibits multiple phases.\nAround the phase boundary, enhanced parameter estimation precision can be\nachieved by tuning either the scaled coupling strength or the hopping phase\ncontrolled by an artificial magnetic field. We observe that the quantum Fisher\ninformation shows divergent scaling near different quantum phase transition\npoints, characterized by distinct critical exponents. When the resource\nconsumption is taken into account, we find that the divergent quantum Fisher\ninformation can reach the Heisenberg limit. Furthermore, we propose a\nmeasurement scheme of the average photon number and the quantum Cram\\'er-Rao\nbound can be saturated.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u91cf\u5b50\u62c9\u6bd4\u4e09\u89d2\u7cfb\u7edf\u4e2d\u7684\u4e34\u754c\u589e\u5f3a\u4f20\u611f\uff0c\u53d1\u73b0\u5728\u76f8\u53d8\u8fb9\u754c\u9644\u8fd1\u901a\u8fc7\u8c03\u8282\u8026\u5408\u5f3a\u5ea6\u6216\u8df3\u8dc3\u76f8\u4f4d\u53ef\u4ee5\u5b9e\u73b0\u589e\u5f3a\u7684\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u91cf\u5b50Fisher\u4fe1\u606f\u5728\u91cf\u5b50\u76f8\u53d8\u70b9\u9644\u8fd1\u5448\u73b0\u53d1\u6563\u6807\u5ea6\u884c\u4e3a\uff0c\u4e14\u80fd\u8fbe\u5230\u6d77\u68ee\u5821\u6781\u9650\u3002", "motivation": "\u91cf\u5b50\u7cfb\u7edf\u7684\u4e34\u754c\u7279\u6027\u88ab\u8ba4\u4e3a\u662f\u91cf\u5b50\u8ba1\u91cf\u5b66\u7684\u5b9d\u8d35\u8d44\u6e90\uff0c\u7814\u7a76\u91cf\u5b50\u62c9\u6bd4\u4e09\u89d2\u7cfb\u7edf\u4e2d\u7684\u4e34\u754c\u589e\u5f3a\u4f20\u611f\uff0c\u63a2\u7d22\u5728\u76f8\u53d8\u8fb9\u754c\u9644\u8fd1\u5b9e\u73b0\u589e\u5f3a\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u7684\u53ef\u80fd\u6027\u3002", "method": "\u7814\u7a76\u91cf\u5b50\u62c9\u6bd4\u4e09\u89d2\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5448\u73b0\u591a\u4e2a\u76f8\u3002\u5728\u76f8\u8fb9\u754c\u9644\u8fd1\uff0c\u901a\u8fc7\u8c03\u8282\u6807\u5ea6\u8026\u5408\u5f3a\u5ea6\u6216\u7531\u4eba\u5de5\u78c1\u573a\u63a7\u5236\u7684\u8df3\u8dc3\u76f8\u4f4d\u6765\u5b9e\u73b0\u589e\u5f3a\u7684\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u3002\u5206\u6790\u91cf\u5b50Fisher\u4fe1\u606f\u5728\u4e0d\u540c\u91cf\u5b50\u76f8\u53d8\u70b9\u9644\u8fd1\u7684\u884c\u4e3a\uff0c\u5e76\u8003\u8651\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u91cf\u5b50Fisher\u4fe1\u606f\u5728\u4e0d\u540c\u91cf\u5b50\u76f8\u53d8\u70b9\u9644\u8fd1\u5448\u73b0\u53d1\u6563\u6807\u5ea6\u884c\u4e3a\uff0c\u5177\u6709\u4e0d\u540c\u7684\u4e34\u754c\u6307\u6570\u3002\u5f53\u8003\u8651\u8d44\u6e90\u6d88\u8017\u65f6\uff0c\u53d1\u6563\u7684\u91cf\u5b50Fisher\u4fe1\u606f\u53ef\u4ee5\u8fbe\u5230\u6d77\u68ee\u5821\u6781\u9650\u3002\u63d0\u51fa\u4e86\u5e73\u5747\u5149\u5b50\u6570\u7684\u6d4b\u91cf\u65b9\u6848\uff0c\u91cf\u5b50Cram\u00e9r-Rao\u754c\u53ef\u4ee5\u8fbe\u5230\u9971\u548c\u3002", "conclusion": "\u91cf\u5b50\u62c9\u6bd4\u4e09\u89d2\u7cfb\u7edf\u5728\u76f8\u53d8\u8fb9\u754c\u9644\u8fd1\u53ef\u4ee5\u5b9e\u73b0\u4e34\u754c\u589e\u5f3a\u7684\u4f20\u611f\u6027\u80fd\uff0c\u91cf\u5b50Fisher\u4fe1\u606f\u5728\u76f8\u53d8\u70b9\u9644\u8fd1\u5448\u73b0\u53d1\u6563\u884c\u4e3a\u4e14\u80fd\u8fbe\u5230\u6d77\u68ee\u5821\u6781\u9650\uff0c\u4e3a\u91cf\u5b50\u8ba1\u91cf\u5b66\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u3002"}}
{"id": "2511.00113", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00113", "abs": "https://arxiv.org/abs/2511.00113", "authors": ["Huseyin Goksu"], "title": "MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials", "comment": null, "summary": "Spectral Graph Neural Networks (GNNs) have achieved state-of-the-art results\nby defining graph convolutions in the spectral domain. A common approach,\npopularized by ChebyNet, is to use polynomial filters based on continuous\northogonal polynomials (e.g., Chebyshev). This creates a theoretical\ndisconnect, as these continuous-domain filters are applied to inherently\ndiscrete graph structures. We hypothesize this mismatch can lead to suboptimal\nperformance and fragility to hyperparameter settings.\n  In this paper, we introduce MeixnerNet, a novel spectral GNN architecture\nthat employs discrete orthogonal polynomials -- specifically, the Meixner\npolynomials $M_k(x; \\beta, c)$. Our model makes the two key shape parameters of\nthe polynomial, beta and c, learnable, allowing the filter to adapt its\npolynomial basis to the specific spectral properties of a given graph. We\novercome the significant numerical instability of these polynomials by\nintroducing a novel stabilization technique that combines Laplacian scaling\nwith per-basis LayerNorm.\n  We demonstrate experimentally that MeixnerNet achieves\ncompetitive-to-superior performance against the strong ChebyNet baseline at the\noptimal K = 2 setting (winning on 2 out of 3 benchmarks). More critically, we\nshow that MeixnerNet is exceptionally robust to variations in the polynomial\ndegree K, a hyperparameter to which ChebyNet proves to be highly fragile,\ncollapsing in performance where MeixnerNet remains stable.", "AI": {"tldr": "MeixnerNet\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u79bb\u6563\u6b63\u4ea4\u591a\u9879\u5f0f\uff08Meixner\u591a\u9879\u5f0f\uff09\u66ff\u4ee3\u4f20\u7edf\u7684\u8fde\u7eed\u6b63\u4ea4\u591a\u9879\u5f0f\uff0c\u89e3\u51b3\u4e86\u56fe\u7ed3\u6784\u4e0e\u8fde\u7eed\u57df\u6ee4\u6ce2\u5668\u4e4b\u95f4\u7684\u7406\u8bba\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8c31GNN\u4f7f\u7528\u8fde\u7eed\u6b63\u4ea4\u591a\u9879\u5f0f\uff08\u5982Chebyshev\uff09\u4f5c\u4e3a\u56fe\u5377\u79ef\u6ee4\u6ce2\u5668\uff0c\u8fd9\u4e0e\u79bb\u6563\u7684\u56fe\u7ed3\u6784\u5b58\u5728\u7406\u8bba\u4e0d\u5339\u914d\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u548c\u5bf9\u8d85\u53c2\u6570\u8bbe\u7f6e\u7684\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faMeixnerNet\u67b6\u6784\uff0c\u4f7f\u7528\u79bb\u6563Meixner\u591a\u9879\u5f0f\u4f5c\u4e3a\u6ee4\u6ce2\u5668\uff0c\u5e76\u4f7f\u5176\u4e24\u4e2a\u5f62\u72b6\u53c2\u6570\u03b2\u548cc\u53ef\u5b66\u4e60\uff0c\u540c\u65f6\u5f15\u5165\u7ed3\u5408\u62c9\u666e\u62c9\u65af\u7f29\u653e\u548c\u9010\u57faLayerNorm\u7684\u7a33\u5b9a\u5316\u6280\u672f\u6765\u89e3\u51b3\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "result": "\u5728\u6700\u4f18K=2\u8bbe\u7f6e\u4e0b\uff0cMeixnerNet\u57283\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76842\u4e2a\u4e0a\u8868\u73b0\u4f18\u4e8eChebyNet\u57fa\u7ebf\uff0c\u66f4\u91cd\u8981\u7684\u662f\uff0cMeixnerNet\u5bf9\u591a\u9879\u5f0f\u9636\u6570K\u7684\u53d8\u5316\u8868\u73b0\u51fa\u6781\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u800cChebyNet\u5bf9\u6b64\u9ad8\u5ea6\u654f\u611f\u4e14\u6027\u80fd\u4f1a\u5d29\u6e83\u3002", "conclusion": "MeixnerNet\u901a\u8fc7\u4f7f\u7528\u79bb\u6563\u6b63\u4ea4\u591a\u9879\u5f0f\u89e3\u51b3\u4e86\u8c31GNN\u4e2d\u7684\u7406\u8bba\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u5bf9\u5173\u952e\u8d85\u53c2\u6570\u7684\u663e\u8457\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01358", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01358", "abs": "https://arxiv.org/abs/2511.01358", "authors": ["Vladisalv Sukharnikov", "Stasis Chuchurka", "Frank Schlawin"], "title": "Non-Markovian dynamics in nonstationary Gaussian baths", "comment": null, "summary": "Building on the standard hierarchy of pure states (HOPS) approach, we\nconstruct a generalized formulation suitable for open quantum systems\ninteracting with nonstationary Gaussian baths, potentially extending its\napplicability to nonequilibrium baths. This is achieved by extending the\nconventional exponential decomposition of bath correlation functions (BCF) to\nallow explicitly time-dependent forms. We demonstrate the method's performance\non two examples of nonstationary squeezed reservoirs generated via uniform\nsqueezing and degenerate parametric amplification. Benchmarking against the\nassociated hierarchy of master equations shows that HOPS achieves superior\nefficiency under hierarchy truncation. In cases where each contribution in the\nBCF expansion can be associated with an independent physical bath, the\nformalism can be simplified in a pseudomode representation which is more\nefficient in a strongly non-Markovian regime. Our results highlight HOPS as a\nversatile and powerful tool for simulating open quantum systems in\nnonstationary baths, with potential applications ranging from squeezed\nlight-matter interactions to driven quantum materials and dissipative phase\ntransitions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u975e\u5e73\u7a33\u9ad8\u65af\u6d74\u7684\u5e7f\u4e49HOPS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55\u6d74\u76f8\u5173\u51fd\u6570\u7684\u65f6\u95f4\u76f8\u5173\u5206\u89e3\uff0c\u5728\u975e\u5e73\u8861\u6d74\u4e2d\u5b9e\u73b0\u9ad8\u6548\u91cf\u5b50\u7cfb\u7edf\u6a21\u62df", "motivation": "\u4f20\u7edfHOPS\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5e73\u7a33\u6d74\uff0c\u9700\u8981\u6269\u5c55\u5230\u975e\u5e73\u7a33\u9ad8\u65af\u6d74\u4ee5\u5904\u7406\u975e\u5e73\u8861\u91cf\u5b50\u7cfb\u7edf\u95ee\u9898", "method": "\u6269\u5c55\u6d74\u76f8\u5173\u51fd\u6570\u7684\u6307\u6570\u5206\u89e3\u4e3a\u663e\u5f0f\u65f6\u95f4\u76f8\u5173\u5f62\u5f0f\uff0c\u5efa\u7acb\u5e7f\u4e49HOPS\u6846\u67b6\uff0c\u5e76\u4e0e\u4f2a\u6a21\u8868\u793a\u7ed3\u5408\u63d0\u9ad8\u6548\u7387", "result": "\u5728\u5747\u5300\u538b\u7f29\u548c\u7b80\u5e76\u53c2\u91cf\u653e\u5927\u4ea7\u751f\u7684\u975e\u5e73\u7a33\u538b\u7f29\u5e93\u4e0a\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u76f8\u6bd4\u5c42\u6b21\u4e3b\u65b9\u7a0b\u5177\u6709\u66f4\u4f18\u7684\u622a\u65ad\u6548\u7387", "conclusion": "HOPS\u662f\u6a21\u62df\u975e\u5e73\u7a33\u6d74\u4e2d\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u901a\u7528\u5f3a\u5927\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u538b\u7f29\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u3001\u9a71\u52a8\u91cf\u5b50\u6750\u6599\u548c\u8017\u6563\u76f8\u53d8\u7b49\u5e94\u7528"}}
{"id": "2511.00116", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00116", "abs": "https://arxiv.org/abs/2511.00116", "authors": ["Avisek Naug", "Antonio Guillen", "Vineet Kumar", "Scott Greenwood", "Wesley Brewer", "Sahand Ghorbanpour", "Ashwin Ramesh Babu", "Vineet Gundecha", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for End-to-End Liquid Cooling Optimization in Data Centers", "comment": "Submitted to the NeurIPS 2025 conference", "summary": "Liquid cooling is critical for thermal management in high-density data\ncenters with the rising AI workloads. However, machine learning-based\ncontrollers are essential to unlock greater energy efficiency and reliability,\npromoting sustainability. We present LC-Opt, a Sustainable Liquid Cooling (LC)\nbenchmark environment, for reinforcement learning (RL) control strategies in\nenergy-efficient liquid cooling of high-performance computing (HPC) systems.\nBuilt on the baseline of a high-fidelity digital twin of Oak Ridge National\nLab's Frontier Supercomputer cooling system, LC-Opt provides detailed\nModelica-based end-to-end models spanning site-level cooling towers to data\ncenter cabinets and server blade groups. RL agents optimize critical thermal\ncontrols like liquid supply temperature, flow rate, and granular valve\nactuation at the IT cabinet level, as well as cooling tower (CT) setpoints\nthrough a Gymnasium interface, with dynamic changes in workloads. This\nenvironment creates a multi-objective real-time optimization challenge\nbalancing local thermal regulation and global energy efficiency, and also\nsupports additional components like a heat recovery unit (HRU). We benchmark\ncentralized and decentralized multi-agent RL approaches, demonstrate policy\ndistillation into decision and regression trees for interpretable control, and\nexplore LLM-based methods that explain control actions in natural language\nthrough an agentic mesh architecture designed to foster user trust and simplify\nsystem management. LC-Opt democratizes access to detailed, customizable liquid\ncooling models, enabling the ML community, operators, and vendors to develop\nsustainable data center liquid cooling control solutions.", "AI": {"tldr": "LC-Opt\u662f\u4e00\u4e2a\u53ef\u6301\u7eed\u6db2\u4f53\u51b7\u5374\u57fa\u51c6\u73af\u5883\uff0c\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u7684\u8282\u80fd\u6db2\u4f53\u51b7\u5374\u63d0\u4f9b\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u57fa\u4e8e\u6a61\u6811\u5cad\u56fd\u5bb6\u5b9e\u9a8c\u5ba4Frontier\u8d85\u7ea7\u8ba1\u7b97\u673a\u51b7\u5374\u7cfb\u7edf\u7684\u9ad8\u4fdd\u771f\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u3002", "motivation": "\u968f\u7740AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u589e\u52a0\uff0c\u9ad8\u5bc6\u5ea6\u6570\u636e\u4e2d\u5fc3\u7684\u6db2\u4f53\u51b7\u5374\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u63a7\u5236\u5668\u5bf9\u4e8e\u91ca\u653e\u66f4\u9ad8\u7684\u80fd\u6e90\u6548\u7387\u548c\u53ef\u9760\u6027\u3001\u4fc3\u8fdb\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u57fa\u4e8eModelica\u7684\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u4ece\u7ad9\u70b9\u7ea7\u51b7\u5374\u5854\u5230\u6570\u636e\u4e2d\u5fc3\u673a\u67dc\u548c\u670d\u52a1\u5668\u5200\u7247\u7ec4\u3002\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u901a\u8fc7Gymnasium\u63a5\u53e3\u4f18\u5316\u5173\u952e\u70ed\u63a7\u5236\u53c2\u6570\uff0c\u5982\u6db2\u4f53\u4f9b\u5e94\u6e29\u5ea6\u3001\u6d41\u91cf\u548c\u9600\u95e8\u8c03\u8282\uff0c\u4ee5\u53ca\u51b7\u5374\u5854\u8bbe\u5b9a\u70b9\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u591a\u76ee\u6807\u5b9e\u65f6\u4f18\u5316\u6311\u6218\uff0c\u5e73\u8861\u5c40\u90e8\u70ed\u8c03\u8282\u548c\u5168\u5c40\u80fd\u6e90\u6548\u7387\u3002\u652f\u6301\u96c6\u4e2d\u5f0f\u548c\u5206\u6563\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6f14\u793a\u4e86\u7b56\u7565\u84b8\u998f\u5230\u51b3\u7b56\u6811\u548c\u56de\u5f52\u6811\u4ee5\u5b9e\u73b0\u53ef\u89e3\u91ca\u63a7\u5236\uff0c\u5e76\u63a2\u7d22\u4e86\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u63a7\u5236\u52a8\u4f5c\u3002", "conclusion": "LC-Opt\u4e3aML\u793e\u533a\u3001\u8fd0\u8425\u5546\u548c\u4f9b\u5e94\u5546\u63d0\u4f9b\u4e86\u8be6\u7ec6\u3001\u53ef\u5b9a\u5236\u7684\u6db2\u4f53\u51b7\u5374\u6a21\u578b\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u5f00\u53d1\u53ef\u6301\u7eed\u7684\u6570\u636e\u4e2d\u5fc3\u6db2\u4f53\u51b7\u5374\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u7528\u6237\u4fe1\u4efb\u548c\u7b80\u5316\u7cfb\u7edf\u7ba1\u7406\u3002"}}
{"id": "2511.01387", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01387", "abs": "https://arxiv.org/abs/2511.01387", "authors": ["Hajar Assil", "Abderrahim El Allati", "Gian Luca Giorgi"], "title": "Entanglement estimation of Werner states with a quantum extreme learning machine", "comment": null, "summary": "Quantum Extreme Learning Machines (QELMs) have emerged as a potent tool for\nvarious quantum information processing tasks. We present a QELM protocol for\nestimating the amount of entanglement in Werner states. The protocol requires\nthe generation of a sequence of random Werner states, which are then combined\nwith a reservoir state and evolved using an Ising Hamiltonian. A set of\nobservables based on the Bloch basis is constructed and employed to train the\nsystem to recognize unseen features. To assess the protocol's robustness, noise\nis introduced into the input states, and the system's performance under these\nnoisy conditions is analyzed. Additionally, the influence of the magnetic field\nparameter within the Ising Hamiltonian on the estimation accuracy is\ninvestigated.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u91cf\u5b50\u6781\u9650\u5b66\u4e60\u673a\u7684\u534f\u8bae\uff0c\u7528\u4e8e\u4f30\u8ba1Werner\u6001\u7684\u7ea0\u7f20\u91cf\u3002\u8be5\u534f\u8bae\u901a\u8fc7\u751f\u6210\u968f\u673aWerner\u6001\u5e8f\u5217\uff0c\u4e0e\u50a8\u5c42\u6001\u7ed3\u5408\u5e76\u5728Ising\u54c8\u5bc6\u987f\u91cf\u4e0b\u6f14\u5316\uff0c\u6784\u5efa\u57fa\u4e8eBloch\u57fa\u7684\u89c2\u6d4b\u91cf\u6765\u8bad\u7ec3\u7cfb\u7edf\u8bc6\u522b\u672a\u77e5\u7279\u5f81\u3002", "motivation": "\u91cf\u5b50\u6781\u9650\u5b66\u4e60\u673a\u5df2\u6210\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u7684\u6709\u529b\u5de5\u5177\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u4f30\u8ba1Werner\u6001\u7ea0\u7f20\u91cf\u7684QELM\u534f\u8bae\u3002", "method": "\u751f\u6210\u968f\u673aWerner\u6001\u5e8f\u5217\uff0c\u4e0e\u50a8\u5c42\u6001\u7ed3\u5408\u5e76\u5728Ising\u54c8\u5bc6\u987f\u91cf\u4e0b\u6f14\u5316\uff0c\u6784\u5efa\u57fa\u4e8eBloch\u57fa\u7684\u89c2\u6d4b\u91cf\u6765\u8bad\u7ec3\u7cfb\u7edf\u3002\u8fd8\u7814\u7a76\u4e86\u566a\u58f0\u5bf9\u8f93\u5165\u6001\u7684\u5f71\u54cd\u4ee5\u53caIsing\u54c8\u5bc6\u987f\u91cf\u4e2d\u78c1\u573a\u53c2\u6570\u5bf9\u4f30\u8ba1\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u534f\u8bae\u80fd\u591f\u6709\u6548\u4f30\u8ba1Werner\u6001\u7684\u7ea0\u7f20\u91cf\uff0c\u5e76\u5728\u5b58\u5728\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002\u78c1\u573a\u53c2\u6570\u5bf9\u4f30\u8ba1\u7cbe\u5ea6\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u8be5QELM\u534f\u8bae\u4e3aWerner\u6001\u7ea0\u7f20\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u9c81\u68d2\u7684\u65b9\u6cd5\uff0cIsing\u54c8\u5bc6\u987f\u91cf\u4e2d\u7684\u78c1\u573a\u53c2\u6570\u662f\u4f18\u5316\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2511.00117", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00117", "abs": "https://arxiv.org/abs/2511.00117", "authors": ["Antonio Guillen-Perez", "Avisek Naug", "Vineet Gundecha", "Sahand Ghorbanpour", "Ricardo Luna Gutierrez", "Ashwin Ramesh Babu", "Munther Salim", "Shubhanker Banerjee", "Eoin H. Oude Essink", "Damien Fay", "Soumyendu Sarkar"], "title": "DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads", "comment": "Submitted to the NeurIPS 2025 conference", "summary": "The increasing energy demands and carbon footprint of large-scale AI require\nintelligent workload management in globally distributed data centers. Yet\nprogress is limited by the absence of benchmarks that realistically capture the\ninterplay of time-varying environmental factors (grid carbon intensity,\nelectricity prices, weather), detailed data center physics (CPUs, GPUs, memory,\nHVAC energy), and geo-distributed network dynamics (latency and transmission\ncosts). To bridge this gap, we present DCcluster-Opt: an open-source,\nhigh-fidelity simulation benchmark for sustainable, geo-temporal task\nscheduling. DCcluster-Opt combines curated real-world datasets, including AI\nworkload traces, grid carbon intensity, electricity markets, weather across 20\nglobal regions, cloud transmission costs, and empirical network delay\nparameters with physics-informed models of data center operations, enabling\nrigorous and reproducible research in sustainable computing. It presents a\nchallenging scheduling problem where a top-level coordinating agent must\ndynamically reassign or defer tasks that arrive with resource and service-level\nagreement requirements across a configurable cluster of data centers to\noptimize multiple objectives. The environment also models advanced components\nsuch as heat recovery. A modular reward system enables an explicit study of\ntrade-offs among carbon emissions, energy costs, service level agreements, and\nwater use. It provides a Gymnasium API with baseline controllers, including\nreinforcement learning and rule-based strategies, to support reproducible ML\nresearch and a fair comparison of diverse algorithms. By offering a realistic,\nconfigurable, and accessible testbed, DCcluster-Opt accelerates the development\nand validation of next-generation sustainable computing solutions for\ngeo-distributed data centers.", "AI": {"tldr": "DCcluster-Opt\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u9ad8\u4fdd\u771f\u6a21\u62df\u57fa\u51c6\uff0c\u7528\u4e8e\u53ef\u6301\u7eed\u7684\u5168\u7403\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u4efb\u52a1\u8c03\u5ea6\uff0c\u7ed3\u5408\u4e86\u771f\u5b9e\u4e16\u754c\u6570\u636e\u548c\u7269\u7406\u6a21\u578b\uff0c\u652f\u6301\u591a\u76ee\u6807\u4f18\u5316\u7814\u7a76\u3002", "motivation": "\u5927\u89c4\u6a21AI\u7684\u80fd\u6e90\u9700\u6c42\u548c\u78b3\u8db3\u8ff9\u4e0d\u65ad\u589e\u52a0\uff0c\u9700\u8981\u667a\u80fd\u7684\u5168\u7403\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u5de5\u4f5c\u8d1f\u8f7d\u7ba1\u7406\uff0c\u4f46\u7f3a\u4e4f\u80fd\u771f\u5b9e\u6355\u6349\u73af\u5883\u56e0\u7d20\u3001\u6570\u636e\u4e2d\u5fc3\u7269\u7406\u548c\u7f51\u7edc\u52a8\u6001\u76f8\u4e92\u4f5c\u7528\u7684\u57fa\u51c6\u3002", "method": "\u7ed3\u5408\u7cbe\u9009\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff08AI\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u3001\u7535\u7f51\u78b3\u5f3a\u5ea6\u3001\u7535\u529b\u5e02\u573a\u3001\u5929\u6c14\u3001\u4e91\u4f20\u8f93\u6210\u672c\u7b49\uff09\u4e0e\u57fa\u4e8e\u7269\u7406\u7684\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u6a21\u578b\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u5956\u52b1\u7cfb\u7edf\u548cGymnasium API\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u652f\u6301\u52a8\u6001\u91cd\u65b0\u5206\u914d\u6216\u5ef6\u8fdf\u4efb\u52a1\uff0c\u4f18\u5316\u78b3\u6392\u653e\u3001\u80fd\u6e90\u6210\u672c\u3001\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\u548c\u7528\u6c34\u7b49\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u5305\u542b\u70ed\u56de\u6536\u7b49\u9ad8\u7ea7\u7ec4\u4ef6\u5efa\u6a21\u3002", "conclusion": "DCcluster-Opt\u901a\u8fc7\u63d0\u4f9b\u771f\u5b9e\u3001\u53ef\u914d\u7f6e\u4e14\u53ef\u8bbf\u95ee\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u52a0\u901f\u4e86\u9762\u5411\u5168\u7403\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u7684\u4e0b\u4e00\u4ee3\u53ef\u6301\u7eed\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u7684\u5f00\u53d1\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2511.01418", "categories": ["quant-ph", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2511.01418", "abs": "https://arxiv.org/abs/2511.01418", "authors": ["Yunan Li", "Xi Zhang", "Weixin Zhang", "Ruonan Guo", "Yu Zhang", "Xinsheng Tan", "Yang Yu"], "title": "Fast and Robust Remote Two-Qubit Gates on Distributed Qubits", "comment": null, "summary": "Distributed quantum computing offers a potential solution to the complexity\nof superconducting chip hardware layouts and error correction algorithms.\nHigh-quality gates between distributed chips enable the simplification of\nexisting error correction algorithms. This article proposes and demonstrates a\nremote quantum geometric gate scheme via parametric modulation. Our scheme\ninherits the intrinsic robustness of geometric phases. Meanwhile, by employing\ngradient-based optimization algorithms(Adaptive Moment Estimation) from deep\nlearning, we design control waveforms that significantly suppress population\nleakage. We experimentally realize the rapid remote SWAP and\n$\\sqrt{\\text{SWAP}}$ gates with high fidelity, completing operation in about 30\nns. The gate error of SWAP ($\\sqrt{\\text{SWAP}}$) is 1.16\\% (0.91\\%) after\nexcluding the effect of energy relaxation. The simulation demonstrate that this\nscheme can be implemented in the distributed chips connected by cables\nextending several meters. Our results highlight the effectiveness of the\nproposed protocol in enabling modular quantum processors, offering a promising\npath toward the realization of fault-tolerant quantum computation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e00\u79cd\u901a\u8fc7\u53c2\u6570\u8c03\u5236\u5b9e\u73b0\u8fdc\u7a0b\u91cf\u5b50\u51e0\u4f55\u95e8\u7684\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5177\u6709\u51e0\u4f55\u76f8\u4f4d\u7684\u5185\u5728\u9c81\u68d2\u6027\uff0c\u5e76\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63a7\u5236\u6ce2\u5f62\u6765\u6291\u5236\u5e03\u5c45\u6570\u6cc4\u6f0f\u3002", "motivation": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u53ef\u4ee5\u89e3\u51b3\u8d85\u5bfc\u82af\u7247\u786c\u4ef6\u5e03\u5c40\u548c\u7ea0\u9519\u7b97\u6cd5\u7684\u590d\u6742\u6027\uff0c\u5206\u5e03\u5f0f\u82af\u7247\u95f4\u7684\u9ad8\u8d28\u91cf\u95e8\u64cd\u4f5c\u80fd\u591f\u7b80\u5316\u73b0\u6709\u7ea0\u9519\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u53c2\u6570\u8c03\u5236\u7684\u8fdc\u7a0b\u91cf\u5b50\u51e0\u4f55\u95e8\u65b9\u6848\uff0c\u7ed3\u5408\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\uff09\u8bbe\u8ba1\u63a7\u5236\u6ce2\u5f62\uff0c\u6291\u5236\u5e03\u5c45\u6570\u6cc4\u6f0f\u3002", "result": "\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u5feb\u901f\u8fdc\u7a0bSWAP\u548c\u221aSWAP\u95e8\uff0c\u64cd\u4f5c\u65f6\u95f4\u7ea630\u7eb3\u79d2\uff0c\u6392\u9664\u80fd\u91cf\u5f1b\u8c6b\u5f71\u54cd\u540e\uff0cSWAP\u95e8\u9519\u8bef\u7387\u4e3a1.16%\uff0c\u221aSWAP\u95e8\u9519\u8bef\u7387\u4e3a0.91%\u3002\u6a21\u62df\u8868\u660e\u8be5\u65b9\u6848\u53ef\u5728\u6570\u7c73\u7535\u7f06\u8fde\u63a5\u7684\u5206\u5e03\u5f0f\u82af\u7247\u4e2d\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u6a21\u5757\u5316\u91cf\u5b50\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u4e3a\u5b9e\u73b0\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.00121", "categories": ["cs.LG", "physics.soc-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00121", "abs": "https://arxiv.org/abs/2511.00121", "authors": ["Shoma Yagi", "Jun Ichikawa", "Genki Ichinose"], "title": "Analysis of Line Break prediction models for detecting defensive breakthrough in football", "comment": "14 pages, 8 figures", "summary": "In football, attacking teams attempt to break through the opponent's\ndefensive line to create scoring opportunities. This action, known as a Line\nBreak, is a critical indicator of offensive effectiveness and tactical\nperformance, yet previous studies have mainly focused on shots or goal\nopportunities rather than on how teams break the defensive line. In this study,\nwe develop a machine learning model to predict Line Breaks using event and\ntracking data from the 2023 J1 League season. The model incorporates 189\nfeatures, including player positions, velocities, and spatial configurations,\nand employs an XGBoost classifier to estimate the probability of Line Breaks.\nThe proposed model achieved high predictive accuracy, with an AUC of 0.982 and\na Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such\nas offensive player speed, gaps in the defensive line, and offensive players'\nspatial distributions significantly contribute to the occurrence of Line\nBreaks. Finally, we found a moderate positive correlation between the predicted\nprobability of being Line-Broken and the number of shots and crosses conceded\nat the team level. These results suggest that Line Breaks are closely linked to\nthe creation of scoring opportunities and provide a quantitative framework for\nunderstanding tactical dynamics in football.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4b\u8db3\u7403\u4e2d\u7684\u9632\u7ebf\u7a81\u7834\uff08Line Break\uff09\uff0c\u4f7f\u7528XGBoost\u5206\u7c7b\u5668\u5206\u6790\u7403\u5458\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u7a7a\u95f4\u914d\u7f6e\u7b49\u7279\u5f81\uff0c\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u63ed\u793a\u4e86\u9632\u7ebf\u7a81\u7834\u4e0e\u5c04\u95e8\u673a\u4f1a\u521b\u9020\u7684\u5bc6\u5207\u5173\u7cfb\u3002", "motivation": "\u8db3\u7403\u4e2d\u653b\u51fb\u65b9\u7a81\u7834\u5bf9\u65b9\u9632\u7ebf\u7684\u80fd\u529b\u662f\u8fdb\u653b\u6709\u6548\u6027\u548c\u6218\u672f\u8868\u73b0\u7684\u5173\u952e\u6307\u6807\uff0c\u4f46\u4ee5\u5f80\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5c04\u95e8\u6216\u8fdb\u7403\u673a\u4f1a\uff0c\u800c\u5ffd\u7565\u4e86\u7403\u961f\u5982\u4f55\u7a81\u7834\u9632\u7ebf\u7684\u8fc7\u7a0b\u3002", "method": "\u4f7f\u75282023\u5e74J1\u8054\u8d5b\u8d5b\u5b63\u7684\u4e8b\u4ef6\u548c\u8ffd\u8e2a\u6570\u636e\uff0c\u6784\u5efa\u5305\u542b189\u4e2a\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u7403\u5458\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u7a7a\u95f4\u914d\u7f6e\u7b49\u53d8\u91cf\uff0c\u91c7\u7528XGBoost\u5206\u7c7b\u5668\u6765\u9884\u6d4b\u9632\u7ebf\u7a81\u7834\u7684\u6982\u7387\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u5f88\u9ad8\uff0cAUC\u8fbe\u52300.982\uff0cBrier\u5206\u6570\u4e3a0.015\u3002SHAP\u5206\u6790\u663e\u793a\u8fdb\u653b\u7403\u5458\u901f\u5ea6\u3001\u9632\u7ebf\u7a7a\u9699\u548c\u8fdb\u653b\u7403\u5458\u7a7a\u95f4\u5206\u5e03\u662f\u5f71\u54cd\u9632\u7ebf\u7a81\u7834\u7684\u5173\u952e\u56e0\u7d20\u3002\u7403\u961f\u5c42\u9762\u7684\u9632\u7ebf\u7a81\u7834\u6982\u7387\u4e0e\u88ab\u5c04\u95e8\u6b21\u6570\u548c\u4f20\u4e2d\u6b21\u6570\u5448\u4e2d\u5ea6\u6b63\u76f8\u5173\u3002", "conclusion": "\u9632\u7ebf\u7a81\u7834\u4e0e\u5f97\u5206\u673a\u4f1a\u521b\u9020\u5bc6\u5207\u76f8\u5173\uff0c\u4e3a\u7406\u89e3\u8db3\u7403\u6218\u672f\u52a8\u6001\u63d0\u4f9b\u4e86\u91cf\u5316\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u7403\u961f\u7684\u8fdb\u653b\u8868\u73b0\u548c\u6218\u672f\u6548\u679c\u3002"}}
{"id": "2511.01467", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01467", "abs": "https://arxiv.org/abs/2511.01467", "authors": ["Ayanava Dasgupta", "Naqueeb Ahmad Warsi", "Masahito Hayashi"], "title": "Quantum Blackwell's Ordering and Differential Privacy", "comment": "46 pages, 3 figures", "summary": "We develop a framework for quantum differential privacy (QDP) based on\nquantum hypothesis testing and Blackwell's ordering. This approach\ncharacterizes $(\\eps,\\delta)$-QDP via hypothesis testing divergences and\nidentifies the most informative quantum state pairs under privacy constraints.\nWe apply this to analyze the stability of quantum learning algorithms,\ngeneralizing classical results to the case $\\delta>0$. Additionally, we study\nprivatized quantum parameter estimation, deriving tight bounds on the quantum\nFisher information under QDP. Finally, we establish near-optimal contraction\nbounds for differentially private quantum channels with respect to the\nhockey-stick divergence.", "AI": {"tldr": "\u57fa\u4e8e\u91cf\u5b50\u5047\u8bbe\u68c0\u9a8c\u548cBlackwell\u6392\u5e8f\u6784\u5efa\u91cf\u5b50\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5206\u6790\u91cf\u5b50\u5b66\u4e60\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u3001\u91cf\u5b50\u53c2\u6570\u4f30\u8ba1\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u4ee5\u53ca\u91cf\u5b50\u4fe1\u9053\u7684\u6536\u7f29\u754c\u9650\u3002", "motivation": "\u5c06\u7ecf\u5178\u5dee\u5206\u9690\u79c1\u6982\u5ff5\u6269\u5c55\u5230\u91cf\u5b50\u9886\u57df\uff0c\u4e3a\u91cf\u5b50\u7b97\u6cd5\u548c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u5047\u8bbe\u68c0\u9a8c\u548cBlackwell\u6392\u5e8f\u7406\u8bba\uff0c\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u6563\u5ea6\u6765\u8868\u5f81\u91cf\u5b50\u5dee\u5206\u9690\u79c1\uff0c\u5e76\u5206\u6790\u91cf\u5b50\u72b6\u6001\u5bf9\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u4fe1\u606f\u91cf\u3002", "result": "\u63a8\u5e7f\u4e86\u7ecf\u5178\u5b66\u4e60\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u7ed3\u679c\u5230\u03b4>0\u7684\u60c5\u51b5\uff0c\u63a8\u5bfc\u4e86\u91cf\u5b50Fisher\u4fe1\u606f\u5728QDP\u4e0b\u7684\u7d27\u754c\uff0c\u5efa\u7acb\u4e86\u91cf\u5b50\u4fe1\u9053\u5728hockey-stick\u6563\u5ea6\u4e0b\u7684\u8fd1\u6700\u4f18\u6536\u7f29\u754c\u9650\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u91cf\u5b50\u5dee\u5206\u9690\u79c1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5728\u91cf\u5b50\u5b66\u4e60\u3001\u53c2\u6570\u4f30\u8ba1\u548c\u4fe1\u9053\u5206\u6790\u7b49\u65b9\u9762\u90fd\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00124", "abs": "https://arxiv.org/abs/2511.00124", "authors": ["Sai Niranjan Ramachandran", "Manish Krishan Lal", "Suvrit Sra"], "title": "Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models", "comment": "Accepted at NeurIPS 2025. 10 pages, camera-ready version. appendices\n  included", "summary": "We analyse how the sampling dynamics of distributions evolve in score-based\ndiffusion models using cross-fluctuations, a centered-moment statistic from\nstatistical physics. Specifically, we show that starting from an unbiased\nisotropic normal distribution, samples undergo sharp, discrete transitions,\neventually forming distinct events of a desired distribution while\nprogressively revealing finer structure. As this process is reversible, these\ntransitions also occur in reverse, where intermediate states progressively\nmerge, tracing a path back to the initial distribution. We demonstrate that\nthese transitions can be detected as discontinuities in $n^{\\text{th}}$-order\ncross-fluctuations. For variance-preserving SDEs, we derive a closed-form for\nthese cross-fluctuations that is efficiently computable for the reverse\ntrajectory. We find that detecting these transitions directly boosts sampling\nefficiency, accelerates class-conditional and rare-class generation, and\nimproves two zero-shot tasks--image classification and style transfer--without\nexpensive grid search or retraining. We also show that this viewpoint unifies\nclassical coupling and mixing from finite Markov chains with continuous\ndynamics while extending to stochastic SDEs and non Markovian samplers. Our\nframework therefore bridges discrete Markov chain theory, phase analysis, and\nmodern generative modeling.", "AI": {"tldr": "\u4f7f\u7528\u7edf\u8ba1\u7269\u7406\u4e2d\u7684\u4ea4\u53c9\u6da8\u843d\u5206\u6790\u6269\u6563\u6a21\u578b\u91c7\u6837\u52a8\u6001\uff0c\u53d1\u73b0\u6837\u672c\u7ecf\u5386\u5c16\u9510\u7684\u79bb\u6563\u8f6c\u53d8\uff0c\u5f62\u6210\u76ee\u6807\u5206\u5e03\u3002\u8fd9\u4e9b\u8f6c\u53d8\u53ef\u88ab\u68c0\u6d4b\u5e76\u7528\u4e8e\u63d0\u5347\u91c7\u6837\u6548\u7387\u3001\u52a0\u901f\u6761\u4ef6\u751f\u6210\u548c\u96f6\u6837\u672c\u4efb\u52a1\u3002", "motivation": "\u7406\u89e3\u6269\u6563\u6a21\u578b\u4e2d\u91c7\u6837\u52a8\u6001\u7684\u6f14\u53d8\u8fc7\u7a0b\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u68c0\u6d4b\u79bb\u6563\u8f6c\u53d8\u6765\u63d0\u5347\u751f\u6210\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u4ea4\u53c9\u6da8\u843d\u7edf\u8ba1\u91cf\u5206\u6790\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u52a8\u6001\uff0c\u63a8\u5bfc\u65b9\u5dee\u4fdd\u6301SDE\u7684\u4ea4\u53c9\u6da8\u843d\u95ed\u5f0f\u89e3\uff0c\u68c0\u6d4b\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u79bb\u6563\u8f6c\u53d8\u3002", "result": "\u68c0\u6d4b\u8fd9\u4e9b\u8f6c\u53d8\u53ef\u76f4\u63a5\u63d0\u5347\u91c7\u6837\u6548\u7387\uff0c\u52a0\u901f\u7c7b\u522b\u6761\u4ef6\u548c\u7a00\u6709\u7c7b\u522b\u751f\u6210\uff0c\u6539\u8fdb\u56fe\u50cf\u5206\u7c7b\u548c\u98ce\u683c\u8fc1\u79fb\u7b49\u96f6\u6837\u672c\u4efb\u52a1\uff0c\u65e0\u9700\u6602\u8d35\u7684\u7f51\u683c\u641c\u7d22\u6216\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u94fe\u7406\u8bba\u4e0e\u8fde\u7eed\u52a8\u529b\u5b66\uff0c\u8fde\u63a5\u4e86\u7ecf\u5178\u8026\u5408\u6df7\u5408\u4e0e\u73b0\u4ee3\u751f\u6210\u5efa\u6a21\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002"}}
{"id": "2511.01514", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01514", "abs": "https://arxiv.org/abs/2511.01514", "authors": ["Mohammadreza Vali", "Hossein Aghababa", "Nasser Yazdani"], "title": "Non-unitary Quantum Physical Unclonable Functions: Modelling, Simulation, and Evaluation under Open Quantum Dynamics", "comment": "48 pages, 24 figures, 12 tables", "summary": "Physical Unclonable Functions (PUFs) provide hardware-level security by\nexploiting intrinsic randomness to produce device-unique responses. However,\nmachine learning and side-channel attacks increasingly undermine their\nclassical assumptions, calling for new approaches to ensure unforgeability.\nQuantum mechanics naturally supports this goal through intrinsic randomness and\nthe no-cloning theorem, motivating the study of Quantum Physical Unclonable\nFunctions (QPUFs). Yet, existing QPUF models often assume ideal unitary\ndynamics, neglecting non-unitary effects such as decoherence and dissipation\nthat arise in real quantum devices. This work introduces a new class of\nnon-unitary QPUFs that leverage open quantum system dynamics as a foundation\nfor security. Three architectures are proposed: the Dissipative QPUF (D-QPUF),\nwhich uses amplitude damping as an entropy source; the Measurement-Feedback\nQPUF (MF-QPUF), which employs mid-circuit measurements and conditional\nunitaries; and the Lindbladian QPUF (L-QPUF), which models Markovian noise via\nthe Lindblad master equation and Trotter-Suzuki decomposition. Simulation\nresults show that these non-unitary designs achieve strong uniqueness,\nuniformity, and unforgeability, with controllable reliability trade-offs from\nstochastic noise. The L-QPUF, in particular, exhibits exponential modeling\nresistance under limited challenge-response access. By reframing environmental\nnoise as a constructive resource, this work establishes a framework for\nnoise-aware quantum hardware authentication and highlights non-unitary\nevolution as a viable foundation for post-quantum security.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u975e\u5e7a\u6b63\u91cf\u5b50\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570(QPUFs)\uff0c\u901a\u8fc7\u5229\u7528\u9000\u76f8\u5e72\u548c\u8017\u6563\u7b49\u975e\u5e7a\u6b63\u6548\u5e94\u6765\u589e\u5f3a\u786c\u4ef6\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edfPUFs\u9762\u4e34\u673a\u5668\u5b66\u4e60\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u800c\u73b0\u6709QPUFs\u6a21\u578b\u5f80\u5f80\u5ffd\u7565\u5b9e\u9645\u91cf\u5b50\u8bbe\u5907\u4e2d\u7684\u975e\u5e7a\u6b63\u6548\u5e94\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u4e0d\u53ef\u4f2a\u9020\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u975e\u5e7a\u6b63QPUF\u67b6\u6784\uff1aD-QPUF\u5229\u7528\u632f\u5e45\u963b\u5c3c\u4f5c\u4e3a\u71b5\u6e90\uff1bMF-QPUF\u91c7\u7528\u4e2d\u95f4\u7535\u8def\u6d4b\u91cf\u548c\u6761\u4ef6\u5e7a\u6b63\u64cd\u4f5c\uff1bL-QPUF\u901a\u8fc7Lindblad\u4e3b\u65b9\u7a0b\u548cTrotter-Suzuki\u5206\u89e3\u6a21\u62df\u9a6c\u5c14\u53ef\u592b\u566a\u58f0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u975e\u5e7a\u6b63\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u5f3a\u72ec\u7279\u6027\u3001\u5747\u5300\u6027\u548c\u4e0d\u53ef\u4f2a\u9020\u6027\uff0c\u901a\u8fc7\u968f\u673a\u566a\u58f0\u5b9e\u73b0\u4e86\u53ef\u63a7\u7684\u53ef\u9760\u6027\u6743\u8861\uff0c\u5176\u4e2dL-QPUF\u5728\u6709\u9650\u6311\u6218-\u54cd\u5e94\u8bbf\u95ee\u4e0b\u8868\u73b0\u51fa\u6307\u6570\u7ea7\u5efa\u6a21\u62b5\u6297\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u73af\u5883\u566a\u58f0\u91cd\u6784\u4e3a\u5efa\u8bbe\u6027\u8d44\u6e90\uff0c\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u566a\u58f0\u611f\u77e5\u91cf\u5b50\u786c\u4ef6\u8ba4\u8bc1\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u975e\u5e7a\u6b63\u6f14\u5316\u662f\u540e\u91cf\u5b50\u5b89\u5168\u7684\u53ef\u884c\u57fa\u7840\u3002"}}
{"id": "2511.00126", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00126", "abs": "https://arxiv.org/abs/2511.00126", "authors": ["Lu Bowen"], "title": "Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features", "comment": null, "summary": "Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,\n2022) have achieved strong average accuracy but remain unreliable in complex\nlong-tail driving scenarios. These limitations reveal the weakness of the\nprevailing \"one-model-fits-all\" paradigm, particularly in safety-critical urban\ncontexts where simpler physics-based models can occasionally outperform\nadvanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic\nmulti-expert gating framework that adaptively selects the most reliable\ntrajectory predictor among a physics-informed LSTM, a Transformer, and a\nfine-tuned GameFormer on a per-sample basis.\n  Our method leverages internal model signals (meta-features) such as stability\nand uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be\nsubstantially more informative than geometric scene descriptors. To the best of\nour knowledge, this is the first work to formulate trajectory expert selection\nas a pairwise-ranking problem over internal model signals (Burges et al.,\n2005), directly optimizing decision quality without requiring post-hoc\ncalibration.\n  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287\nsamples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error\n(FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835\nm), and realizes 57.8 percent of the oracle performance bound. In open-loop\nsimulations, after trajectory horizon alignment, the same configuration reduces\nFDE on left-turn scenarios by approximately 10 percent, demonstrating\nconsistent improvements across both offline validation and open-loop\nevaluation. These results indicate that adaptive hybrid systems enhance\ntrajectory reliability in safety-critical autonomous driving, providing a\npractical pathway beyond static single-model paradigms.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u591a\u4e13\u5bb6\u95e8\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u90e8\u6a21\u578b\u4fe1\u53f7\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f73\u8f68\u8ff9\u9884\u6d4b\u5668\uff0c\u5728nuPlan-mini\u6570\u636e\u96c6\u4e0a\u5b9e\u73b09.5%\u7684FDE\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u8f68\u8ff9\u9884\u6d4b\u5668\u5728\u590d\u6742\u957f\u5c3e\u9a7e\u9a76\u573a\u666f\u4e2d\u4e0d\u53ef\u9760\uff0c\u5355\u4e00\u6a21\u578b\u8303\u5f0f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u591a\u4e13\u5bb6\u95e8\u63a7\u6846\u67b6\uff0c\u57fa\u4e8e\u7a33\u5b9a\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7b49\u5185\u90e8\u6a21\u578b\u4fe1\u53f7\uff0c\u5728\u7269\u7406\u4fe1\u606fLSTM\u3001Transformer\u548c\u5fae\u8c03GameFormer\u4e4b\u95f4\u81ea\u9002\u5e94\u9009\u62e9\u3002", "result": "\u5728nuPlan-mini\u6570\u636e\u96c6\u4e0aFDE\u8fbe\u52302.567\u7c73\uff0c\u6bd4GameFormer\u964d\u4f4e9.5%\uff0c\u8fbe\u5230oracle\u6027\u80fd\u768457.8%\u3002\u5de6\u8f6c\u573a\u666fFDE\u964d\u4f4e\u7ea610%\u3002", "conclusion": "\u81ea\u9002\u5e94\u6df7\u5408\u7cfb\u7edf\u80fd\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u8d85\u8d8a\u9759\u6001\u5355\u4e00\u6a21\u578b\u8303\u5f0f\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2511.01518", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01518", "abs": "https://arxiv.org/abs/2511.01518", "authors": ["Xiaokun Yan", "Kun Zhang", "Jin Wang"], "title": "Quantum Energy Teleportation under Equilibrium and Nonequilibrium Environments", "comment": "13 pages,9 figures", "summary": "Quantum energy teleportation (QET), implemented via local operations and\nclassical communication, enables carrier-free energy transfer by exploiting\nquantum resources. While QET has been extensively studied theoretically and\nvalidated experimentally in various quantum platforms, enhancing energy output\nfor mixed initial states, as the system inevitably interacts with environments,\nremains a significant challenge. In this work, we study QET performance in a\ntwo-qubit system coupled to equilibrium or nonequilibrium reservoirs. We derive\nan analytical expression for the energy output in terms of the system\nHamiltonian eigenstates, enabling analysis of energy output for mixed states.\nUsing the Redfield master equation, we systematically examine the effects of\nqubit detuning, nonequilibrium temperature difference, and nonequilibrium\nchemical potential difference on the energy output. We find that the energy\noutput for mixed states often follows that of the eigenstate with the highest\npopulation, and that nonequilibrium environments can enhance the energy output\nin certain parameter regimes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u91cf\u5b50\u80fd\u91cf\u9690\u5f62\u4f20\u6001\u5728\u6df7\u5408\u6001\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5728\u975e\u5e73\u8861\u73af\u5883\u4e2d\u67d0\u4e9b\u53c2\u6570\u8303\u56f4\u5185\u53ef\u4ee5\u589e\u5f3a\u80fd\u91cf\u8f93\u51fa\u3002", "motivation": "\u91cf\u5b50\u80fd\u91cf\u9690\u5f62\u4f20\u6001\u867d\u7136\u7406\u8bba\u4e0a\u548c\u5b9e\u9a8c\u4e0a\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u7cfb\u7edf\u4e0e\u73af\u5883\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u6df7\u5408\u6001\u65f6\uff0c\u5982\u4f55\u63d0\u9ad8\u80fd\u91cf\u8f93\u51fa\u4ecd\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u7814\u7a76\u53cc\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e0e\u5e73\u8861\u6216\u975e\u5e73\u8861\u70ed\u5e93\u8026\u5408\uff0c\u63a8\u5bfc\u4e86\u80fd\u91cf\u8f93\u51fa\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u4f7f\u7528Redfield\u4e3b\u65b9\u7a0b\u7cfb\u7edf\u5206\u6790\u91cf\u5b50\u6bd4\u7279\u5931\u8c10\u3001\u975e\u5e73\u8861\u6e29\u5ea6\u5dee\u548c\u5316\u5b66\u52bf\u5dee\u5bf9\u80fd\u91cf\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6df7\u5408\u6001\u7684\u80fd\u91cf\u8f93\u51fa\u901a\u5e38\u9075\u5faa\u6700\u9ad8\u5e03\u5c45\u6570\u672c\u5f81\u6001\u7684\u884c\u4e3a\uff0c\u975e\u5e73\u8861\u73af\u5883\u5728\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\u53ef\u4ee5\u589e\u5f3a\u80fd\u91cf\u8f93\u51fa\u3002", "conclusion": "\u975e\u5e73\u8861\u73af\u5883\u4e3a\u589e\u5f3a\u91cf\u5b50\u80fd\u91cf\u9690\u5f62\u4f20\u6001\u7684\u80fd\u91cf\u8f93\u51fa\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.00129", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00129", "abs": "https://arxiv.org/abs/2511.00129", "authors": ["Siyu Xiao", "Xindi Zhao", "Tianhao Mao", "Yiwei Wang", "Yuqiao Chen", "Hongyun Zhang", "Jian Wang", "Junjie Wang", "Shuang Liu", "Tupei Chen", "Yang Liu"], "title": "Casing Collar Identification using AlexNet-based Neural Networks for Depth Measurement in Oil and Gas Wells", "comment": null, "summary": "Accurate downhole depth measurement is essential for oil and gas well\noperations, directly influencing reservoir contact, production efficiency, and\noperational safety. Collar correlation using a casing collar locator (CCL) is\nfundamental for precise depth calibration. While neural network-based CCL\nsignal recognition has achieved significant progress in collar identification,\npreprocessing methods for such applications remain underdeveloped. Moreover,\nthe limited availability of real well data poses substantial challenges for\ntraining neural network models that require extensive datasets. This paper\npresents a system integrated into downhole tools for CCL signal acquisition to\nfacilitate dataset construction. We propose comprehensive preprocessing methods\nfor data augmentation and evaluate their effectiveness using our AlexNet-based\nneural network models. Through systematic experimentation across various\nconfiguration combinations, we analyze the contribution of each augmentation\nmethod. Results demonstrate that standardization, label distribution smoothing\n(LDS), and random cropping are fundamental requirements for model training,\nwhile label smoothing regularization (LSR), time scaling, and multiple sampling\nsignificantly enhance model generalization capability. The F1 scores of our two\nbenchmark models trained with the proposed augmentation methods maximumly\nimprove from 0.937 and 0.952 to 1.0 and 1.0, respectively. Performance\nvalidation on real CCL waveforms confirms the effectiveness and practical\napplicability of our approach. This work addresses the gaps in data\naugmentation methodologies for training casing collar recognition models in CCL\ndata-limited environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u5230\u4e95\u4e0b\u5de5\u5177\u4e2d\u7684CCL\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\uff0c\u7528\u4e8e\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u6570\u636e\u589e\u5f3a\u9884\u5904\u7406\u65b9\u6cd5\u5728\u57fa\u4e8eAlexNet\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u6cb9\u6c14\u4e95\u4f5c\u4e1a\u4e2d\uff0c\u7cbe\u786e\u7684\u4e95\u4e0b\u6df1\u5ea6\u6d4b\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u800c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684CCL\u4fe1\u53f7\u8bc6\u522b\u5728\u5957\u7ba1\u63a5\u7b8d\u8bc6\u522b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u9884\u5904\u7406\u65b9\u6cd5\u548c\u771f\u5b9e\u4e95\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u96c6\u6210\u5230\u4e95\u4e0b\u5de5\u5177\u4e2d\u7684CCL\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u636e\u96c6\u6784\u5efa\uff0c\u5e76\u8bc4\u4f30\u4e86\u6807\u51c6\u5316\u3001\u6807\u7b7e\u5206\u5e03\u5e73\u6ed1\u3001\u968f\u673a\u88c1\u526a\u3001\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\u3001\u65f6\u95f4\u7f29\u653e\u548c\u591a\u91cd\u91c7\u6837\u7b49\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6807\u51c6\u5316\u3001\u6807\u7b7e\u5206\u5e03\u5e73\u6ed1\u548c\u968f\u673a\u88c1\u526a\u662f\u6a21\u578b\u8bad\u7ec3\u7684\u57fa\u672c\u8981\u6c42\uff0c\u800c\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\u3001\u65f6\u95f4\u7f29\u653e\u548c\u591a\u91cd\u91c7\u6837\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e24\u4e2a\u57fa\u51c6\u6a21\u578b\u7684F1\u5206\u6570\u5206\u522b\u4ece0.937\u548c0.952\u63d0\u9ad8\u52301.0\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u89e3\u51b3\u4e86\u5728CCL\u6570\u636e\u6709\u9650\u73af\u5883\u4e2d\u8bad\u7ec3\u5957\u7ba1\u63a5\u7b8d\u8bc6\u522b\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7a7a\u767d\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2511.01525", "categories": ["quant-ph", "math.FA", "Primary 81P45, Secondary 15A60, 47A30, 47A63"], "pdf": "https://arxiv.org/pdf/2511.01525", "abs": "https://arxiv.org/abs/2511.01525", "authors": ["James Tian"], "title": "Graph Structured Operator Inequalities and Tsirelson-Type Bounds", "comment": null, "summary": "We establish operator norm bounds for bipartite tensor sums of self-adjoint\ncontractions. The inequalities generalize the analytic structure underlying the\nTsirelson and CHSH bounds, giving dimension-free estimates expressed through\ncommutator and anticommutator norms. A graph based formulation captures sparse\ninteraction patterns via constants depending only on graph connectivity. The\nresults link analytic operator inequalities with quantum information settings\nsuch as Bell correlations and network nonlocality, offering closed-form\nestimates that complement semidefinite and numerical methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u81ea\u4f34\u6536\u7f29\u7b97\u5b50\u7684\u4e8c\u5206\u5f20\u91cf\u548c\u7684\u7b97\u5b50\u8303\u6570\u754c\uff0c\u63a8\u5e7f\u4e86Tsirelson\u548cCHSH\u754c\u9650\u7684\u89e3\u6790\u7ed3\u6784\uff0c\u7ed9\u51fa\u4e86\u901a\u8fc7\u4ea4\u6362\u5b50\u548c\u53cd\u5bf9\u6613\u5b50\u8303\u6570\u8868\u8fbe\u7684\u65e0\u7ef4\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u5c06\u89e3\u6790\u7b97\u5b50\u4e0d\u7b49\u5f0f\u4e0e\u91cf\u5b50\u4fe1\u606f\u573a\u666f\uff08\u5982Bell\u5173\u8054\u548c\u7f51\u7edc\u975e\u5c40\u57df\u6027\uff09\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u4f9b\u5c01\u95ed\u5f62\u5f0f\u7684\u4f30\u8ba1\u6765\u8865\u5145\u534a\u5b9a\u548c\u6570\u503c\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u56fe\u7684\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u4f9d\u8d56\u4e8e\u56fe\u8fde\u901a\u6027\u7684\u5e38\u6570\u6765\u6355\u6349\u7a00\u758f\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "\u83b7\u5f97\u4e86\u7ef4\u5ea6\u65e0\u5173\u7684\u7b97\u5b50\u8303\u6570\u754c\uff0c\u8fd9\u4e9b\u754c\u9650\u901a\u8fc7\u4ea4\u6362\u5b50\u548c\u53cd\u5bf9\u6613\u5b50\u8303\u6570\u8868\u8fbe\uff0c\u5e76\u9002\u7528\u4e8e\u7a00\u758f\u4ea4\u4e92\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u81ea\u4f34\u6536\u7f29\u7b97\u5b50\u4e8c\u5206\u5f20\u91cf\u548c\u7684\u89e3\u6790\u4e0d\u7b49\u5f0f\uff0c\u4e3a\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u548c\u5c01\u95ed\u5f62\u5f0f\u4f30\u8ba1\u3002"}}
{"id": "2511.00130", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00130", "abs": "https://arxiv.org/abs/2511.00130", "authors": ["Bernd Bohnet", "Rumen Dangovski", "Kevin Swersky", "Sherry Moore", "Arslan Chaudhry", "Kathleen Kenealy", "Noah Fiedel"], "title": "A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios", "comment": null, "summary": "The remarkable capabilities of Large Language Models (LLMs) often need to be\ntailored for specific applications, requiring the integration of new knowledge\nor the acquisition of new skills. While full fine-tuning is a powerful\nadaptation method, it is computationally expensive and can lead to a\ndegradation of general reasoning abilities, a phenomenon known as catastrophic\nforgetting. A range of alternative techniques exists, each with its own\ntrade-offs. In-Context Learning (ICL) is fast but limited by context length,\nwhile Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation\n(LoRA) offer a middle ground by minimizing parameter changes. However, the\nchallenge of catastrophic forgetting persists, raising questions about the best\nadaptation strategy for a given task. This paper presents a comparative\nanalysis of Supervised Finetuning (SFT), LoRA, and ICL in data-scarce\nscenarios. We find that LoRA provides the most effective balance, successfully\ninstilling new skills with minimal impact on the base model's general\nknowledge. In contrast, while SFT excels at skill acquisition, it is highly\nsusceptible to catastrophic forgetting. ICL is effective for incorporating\nfactual knowledge but struggles with complex skills. Our findings offer a\npractical framework for selecting an LLM adaptation strategy. We highlight the\ncritical distinction between skill acquisition and knowledge integration,\nclarify the trade-offs between task-specific performance and the preservation\nof general capabilities.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cdLLM\u9002\u5e94\u65b9\u6cd5\uff08SFT\u3001LoRA\u3001ICL\uff09\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0LoRA\u5728\u6280\u80fd\u83b7\u53d6\u4e0e\u901a\u7528\u77e5\u8bc6\u4fdd\u6301\u4e4b\u95f4\u63d0\u4f9b\u6700\u4f73\u5e73\u8861\u3002", "motivation": "LLMs\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u5e94\u7528\u8fdb\u884c\u5b9a\u5236\uff0c\u4f46\u5b8c\u5168\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u6709\u6548\u7684\u9002\u5e94\u7b56\u7565\u3002", "method": "\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u5bf9\u76d1\u7763\u5fae\u8c03(SFT)\u3001\u4f4e\u79e9\u9002\u5e94(LoRA)\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60(ICL)\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "LoRA\u5728\u6280\u80fd\u83b7\u53d6\u4e0e\u901a\u7528\u77e5\u8bc6\u4fdd\u6301\u4e4b\u95f4\u63d0\u4f9b\u6700\u4f73\u5e73\u8861\uff1bSFT\u64c5\u957f\u6280\u80fd\u83b7\u53d6\u4f46\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\uff1bICL\u9002\u5408\u4e8b\u5b9e\u77e5\u8bc6\u6574\u5408\u4f46\u96be\u4ee5\u5904\u7406\u590d\u6742\u6280\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9009\u62e9LLM\u9002\u5e94\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u660e\u786e\u4e86\u6280\u80fd\u83b7\u53d6\u4e0e\u77e5\u8bc6\u6574\u5408\u7684\u5173\u952e\u533a\u522b\uff0c\u4ee5\u53ca\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u4e0e\u901a\u7528\u80fd\u529b\u4fdd\u6301\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2511.01559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01559", "abs": "https://arxiv.org/abs/2511.01559", "authors": ["Rajendra Singh Bhati"], "title": "Security in a prepare-and-measure quantum key distribution protocol when the receiver uses weak values to guess the sender's bits", "comment": null, "summary": "The weak values and weak measurement formalism were initially limited to pure\nstates, which were later extended to mixed states, leading to intriguing\napplications in quantum information processing tasks. Weak values are\nconsidered to be abstract properties of systems describing a complete picture\nbetween successive measurements in the two-state vector formalism (TSVF). The\nremarkable achievements of the weak value formalism in experimental quantum\nmechanics have persuaded most quantum physicists that it is impeccable.\nHowever, we explore a scenario where the formalism of weak values for mixed\nstates is employed in a quantum communication protocol, but discover that it\ngenerates inaccurate outcomes. This reinforces our previous conclusion that the\nweak values may not be elements of the reality of weak measurements, contrary\nto what the proponents of weak values proposed.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5f31\u503c\u5f62\u5f0f\u4e3b\u4e49\u5728\u6df7\u5408\u6001\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u4e2d\u4f1a\u4ea7\u751f\u4e0d\u51c6\u786e\u7ed3\u679c\uff0c\u6311\u6218\u4e86\u5f31\u503c\u4f5c\u4e3a\u5f31\u6d4b\u91cf\u73b0\u5b9e\u5143\u7d20\u7684\u89c2\u70b9\u3002", "motivation": "\u867d\u7136\u5f31\u503c\u5f62\u5f0f\u4e3b\u4e49\u5728\u5b9e\u9a8c\u91cf\u5b50\u529b\u5b66\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u5c31\u5e76\u88ab\u5e7f\u6cdb\u63a5\u53d7\uff0c\u4f46\u4f5c\u8005\u60f3\u8981\u63a2\u7d22\u5176\u5728\u6df7\u5408\u6001\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u4e2d\u7684\u9002\u7528\u6027\uff0c\u9a8c\u8bc1\u5176\u662f\u5426\u771f\u7684\u5b8c\u7f8e\u65e0\u7f3a\u3002", "method": "\u5728\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u4e2d\u5e94\u7528\u6df7\u5408\u6001\u7684\u5f31\u503c\u5f62\u5f0f\u4e3b\u4e49\uff0c\u5206\u6790\u5176\u4ea7\u751f\u7684\u7ed3\u679c\u51c6\u786e\u6027\u3002", "result": "\u53d1\u73b0\u5f31\u503c\u5f62\u5f0f\u4e3b\u4e49\u5728\u6df7\u5408\u6001\u91cf\u5b50\u901a\u4fe1\u534f\u8bae\u4e2d\u4f1a\u4ea7\u751f\u4e0d\u51c6\u786e\u7684\u7ed3\u679c\uff0c\u8fd9\u4e0e\u5f31\u503c\u652f\u6301\u8005\u7684\u89c2\u70b9\u76f8\u77db\u76fe\u3002", "conclusion": "\u5f31\u503c\u53ef\u80fd\u4e0d\u662f\u5f31\u6d4b\u91cf\u7684\u73b0\u5b9e\u5143\u7d20\uff0c\u8fd9\u5f3a\u5316\u4e86\u4f5c\u8005\u4e4b\u524d\u5173\u4e8e\u5f31\u503c\u672c\u8d28\u7684\u7ed3\u8bba\uff0c\u6311\u6218\u4e86\u5f31\u503c\u5f62\u5f0f\u4e3b\u4e49\u7684\u5b8c\u7f8e\u6027\u5047\u8bbe\u3002"}}
{"id": "2511.00133", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00133", "abs": "https://arxiv.org/abs/2511.00133", "authors": ["Kowshik Balasubramanian", "Andre Williams", "Ismail Butun"], "title": "Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning", "comment": "10 pages, 2 figures, 3 tables, submitted to IEEE Intelligent Systems\n  journal", "summary": "This paper introduces a novel framework for enhancing Random Forest\nclassifiers by integrating probabilistic feature sampling and hyperparameter\ntuning via Simulated Annealing. The proposed framework exhibits substantial\nadvancements in predictive accuracy and generalization, adeptly tackling the\nmultifaceted challenges of robust classification across diverse domains,\nincluding credit risk evaluation, anomaly detection in IoT ecosystems,\nearly-stage medical diagnostics, and high-dimensional biological data analysis.\nTo overcome the limitations of conventional Random Forests, we present an\napproach that places stronger emphasis on capturing the most relevant signals\nfrom data while enabling adaptive hyperparameter configuration. The model is\nguided towards features that contribute more meaningfully to classification and\noptimizing this with dynamic parameter tuning. The results demonstrate\nconsistent accuracy improvements and meaningful insights into feature\nrelevance, showcasing the efficacy of combining importance aware sampling and\nmetaheuristic optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6982\u7387\u7279\u5f81\u91c7\u6837\u548c\u6a21\u62df\u9000\u706b\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u968f\u673a\u68ee\u6797\u589e\u5f3a\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u9886\u57df\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u68ee\u6797\u5728\u5904\u7406\u590d\u6742\u5206\u7c7b\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u597d\u5730\u6355\u6349\u6570\u636e\u4e2d\u7684\u76f8\u5173\u4fe1\u53f7\u5e76\u5b9e\u73b0\u81ea\u9002\u5e94\u8d85\u53c2\u6570\u914d\u7f6e\u3002", "method": "\u91c7\u7528\u6982\u7387\u7279\u5f81\u91c7\u6837\u6280\u672f\uff0c\u5f3a\u8c03\u5bf9\u5206\u7c7b\u66f4\u6709\u610f\u4e49\u7684\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9000\u706b\u7b97\u6cd5\u8fdb\u884c\u52a8\u6001\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u51c6\u786e\u7387\u65b9\u9762\u83b7\u5f97\u6301\u7eed\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u7279\u5f81\u76f8\u5173\u6027\u5206\u6790\u3002", "conclusion": "\u7ed3\u5408\u91cd\u8981\u6027\u611f\u77e5\u91c7\u6837\u548c\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u63d0\u5347\u968f\u673a\u68ee\u6797\u6027\u80fd\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2511.01608", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01608", "abs": "https://arxiv.org/abs/2511.01608", "authors": ["Hyunho Cha", "Sangwoo Hong", "Jungwoo Lee"], "title": "Operator-aware shadow importance sampling for accurate fidelity estimation", "comment": "10 pages, 1 figure, 5 tables", "summary": "Estimating the fidelity between an unknown quantum state and a fixed target\nis a fundamental task in quantum information science. Direct fidelity\nestimation (DFE) enables this without full tomography by sampling observables\naccording to a target-dependent distribution. However, existing approaches face\nnotable trade-offs. Grouping-based DFE achieves strong accuracy for small\nsystems but suffers from exponential scaling, and its applicability is\nrestricted to Pauli measurements. In contrast, classical-shadow-based DFE\noffers scalability but yields lower accuracy on structured states. In this\nwork, we address these limitations by developing two classes of operator-aware\nshadow importance sampling algorithms using informationally overcomplete\npositive operator-valued measures. Instantiated with local Pauli measurements,\nour algorithm improves upon the grouping-based algorithms for Haar-random\nstates. For structured states such as the GHZ and W states, our algorithm also\neliminates the exponential memory requirements of previous grouping-based\nmethods. Numerical experiments confirm that our methods achieve\nstate-of-the-art performance across Haar-random, GHZ, and W targets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u7b97\u5b50\u611f\u77e5\u5f71\u5b50\u91cd\u8981\u6027\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u4fe1\u606f\u8fc7\u5b8c\u5907\u7684\u6b63\u7b97\u5b50\u503c\u6d4b\u5ea6\u6765\u6539\u8fdb\u76f4\u63a5\u4fdd\u771f\u5ea6\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u76f4\u63a5\u4fdd\u771f\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u9762\u4e34\u663e\u8457\u6743\u8861\uff1a\u57fa\u4e8e\u5206\u7ec4\u7684DFE\u5728\u5c0f\u7cfb\u7edf\u4e0a\u7cbe\u5ea6\u9ad8\u4f46\u5b58\u5728\u6307\u6570\u7ea7\u6269\u5c55\u95ee\u9898\uff0c\u4e14\u4ec5\u9650\u4e8ePauli\u6d4b\u91cf\uff1b\u800c\u57fa\u4e8e\u7ecf\u5178\u5f71\u5b50\u7684DFE\u5177\u6709\u53ef\u6269\u5c55\u6027\u4f46\u5bf9\u7ed3\u6784\u5316\u72b6\u6001\u7cbe\u5ea6\u8f83\u4f4e\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u57fa\u4e8e\u7b97\u5b50\u611f\u77e5\u5f71\u5b50\u91cd\u8981\u6027\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u4fe1\u606f\u8fc7\u5b8c\u5907\u7684\u6b63\u7b97\u5b50\u503c\u6d4b\u5ea6\uff0c\u5728\u5c40\u90e8Pauli\u6d4b\u91cf\u5b9e\u4f8b\u5316\u4e0b\u8fd0\u884c\u3002", "result": "\u5bf9\u4e8eHaar\u968f\u673a\u72b6\u6001\uff0c\u7b97\u6cd5\u4f18\u4e8e\u57fa\u4e8e\u5206\u7ec4\u7684\u65b9\u6cd5\uff1b\u5bf9\u4e8eGHZ\u548cW\u7b49\u7ed3\u6784\u5316\u72b6\u6001\uff0c\u6d88\u9664\u4e86\u5148\u524d\u5206\u7ec4\u65b9\u6cd5\u7684\u5185\u5b58\u6307\u6570\u9700\u6c42\u3002\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u5728Haar\u968f\u673a\u3001GHZ\u548cW\u76ee\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u5b50\u611f\u77e5\u5f71\u5b50\u91cd\u8981\u6027\u91c7\u6837\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u76f4\u63a5\u4fdd\u771f\u5ea6\u4f30\u8ba1\u4e2d\u7cbe\u5ea6\u4e0e\u53ef\u6269\u5c55\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u5404\u79cd\u91cf\u5b50\u72b6\u6001\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2511.00134", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00134", "abs": "https://arxiv.org/abs/2511.00134", "authors": ["Angana Borah", "Adrija Datta", "Ashish S. Kumar", "Raviraj Dave", "Udit Bhatia"], "title": "Physiologically Active Vegetation Reverses Its Cooling Effect in Humid Urban Climates", "comment": "27 pages, 5 figures", "summary": "Efforts to green cities for cooling are succeeding unevenly because the same\nvegetation that cools surfaces can also intensify how hot the air feels.\nPrevious studies have identified humid heat as a growing urban hazard, yet how\nphysiologically active vegetation governs this trade-off between cooling and\nmoisture accumulation remains poorly understood, leaving mitigation policy and\ndesign largely unguided. Here we quantify how vegetation structure and function\ninfluence the Heat Index (HI), a combined measure of temperature and humidity\nin 138 Indian cities spanning tropical savanna, semi-arid steppe, and humid\nsubtropical climates, and across dense urban cores and semi-urban rings. Using\nan extreme-aware, one kilometre reconstruction of HI and an interpretable\nmachine-learning framework that integrates SHapley Additive Explanations (SHAP)\nand Accumulated Local Effects (ALE), we isolate vegetation-climate\ninteractions. Cooling generally strengthens for EVI >= 0.4 and LAI >= 0.05, but\njoint-high regimes begin to reverse toward warming when EVI >= 0.5, LAI >= 0.2,\nand fPAR >= 0.5,with an earlier onset for fPAR >= 0.25 in humid, dense cores.\nIn such environments, highly physiologically active vegetation elevates\nnear-surface humidity faster than it removes heat, reversing its cooling effect\nand amplifying perceived heat stress. These findings establish the climatic\nlimits of vegetation-driven cooling and provide quantitative thresholds for\nclimate-specific greening strategies that promote equitable and heat-resilient\ncities.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u4e86\u690d\u88ab\u7ed3\u6784\u4e0e\u529f\u80fd\u5bf9\u70ed\u6307\u6570\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u690d\u88ab\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f1a\u9006\u8f6c\u51b7\u5374\u6548\u5e94\u5e76\u52a0\u5267\u70ed\u5e94\u6fc0\uff0c\u4e3a\u57ce\u5e02\u7eff\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u6c14\u5019\u7279\u5f02\u6027\u9608\u503c\u3002", "motivation": "\u57ce\u5e02\u7eff\u5316\u51b7\u5374\u6548\u679c\u4e0d\u5747\uff0c\u56e0\u4e3a\u690d\u88ab\u5728\u51b7\u5374\u8868\u9762\u7684\u540c\u65f6\u53ef\u80fd\u52a0\u5267\u7a7a\u6c14\u70ed\u611f\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u690d\u88ab\u5982\u4f55\u8c03\u8282\u51b7\u5374\u4e0e\u6e7f\u5ea6\u79ef\u7d2f\u4e4b\u95f4\u7684\u6743\u8861\u7406\u89e3\u4e0d\u8db3\uff0c\u5bfc\u81f4\u7f13\u89e3\u653f\u7b56\u548c\u8bbe\u8ba1\u7f3a\u4e4f\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u6781\u7aef\u611f\u77e5\u76841\u516c\u91cc\u70ed\u6307\u6570\u91cd\u5efa\u548c\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff08SHAP\u548cALE\uff09\uff0c\u5206\u6790138\u4e2a\u5370\u5ea6\u57ce\u5e02\u4e2d\u690d\u88ab-\u6c14\u5019\u76f8\u4e92\u4f5c\u7528\uff0c\u6db5\u76d6\u4e0d\u540c\u6c14\u5019\u5e26\u548c\u57ce\u5e02\u5bc6\u5ea6\u533a\u57df\u3002", "result": "\u5f53EVI\u22650.4\u3001LAI\u22650.05\u65f6\u51b7\u5374\u6548\u679c\u589e\u5f3a\uff0c\u4f46\u5f53EVI\u22650.5\u3001LAI\u22650.2\u3001fPAR\u22650.5\u65f6\u5f00\u59cb\u9006\u8f6c\u4e3a\u589e\u6e29\uff0c\u5728\u6f6e\u6e7f\u5bc6\u96c6\u6838\u5fc3\u533afPAR\u22650.25\u65f6\u66f4\u65e9\u51fa\u73b0\u9006\u8f6c\u3002\u9ad8\u751f\u7406\u6d3b\u6027\u690d\u88ab\u4f1a\u5feb\u901f\u63d0\u5347\u8fd1\u5730\u8868\u6e7f\u5ea6\uff0c\u9006\u8f6c\u51b7\u5374\u6548\u5e94\u5e76\u653e\u5927\u611f\u77e5\u70ed\u5e94\u6fc0\u3002", "conclusion": "\u786e\u5b9a\u4e86\u690d\u88ab\u9a71\u52a8\u51b7\u5374\u7684\u6c14\u5019\u9650\u5236\uff0c\u4e3a\u4fc3\u8fdb\u516c\u5e73\u548c\u70ed\u97e7\u6027\u57ce\u5e02\u7684\u6c14\u5019\u7279\u5f02\u6027\u7eff\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u91cf\u5316\u9608\u503c\u3002"}}
{"id": "2511.01657", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01657", "abs": "https://arxiv.org/abs/2511.01657", "authors": ["Athira Kalavampara Raghunadhan", "Matheus Guedes De Andrade", "Don Towsley", "Indrakshi Dey", "Daniel Kilper", "Nicola Marchetti"], "title": "Measurement Strategies and Estimation Precision in Quantum Network Tomography", "comment": null, "summary": "This work investigates measurement strategies for link parameter estimation\nin Quantum Network Tomography (QNT), where network links are modeled as\ndepolarizing quantum channels distributing Werner states. Three distinct\nmeasurement schemes are analyzed: local Z-basis measurements (LZM), joint\nBell-state measurements (JBM), and pre-shared entanglement-assisted\nmeasurements (PEM). For each scheme, we derive the probability distributions of\nmeasurement outcomes and examine how noise in the distributed states influences\nestimation precision. Closed-form expressions for the Quantum Fisher\nInformation Matrix (QFIM) are obtained, and the estimation precision is\nevaluated through the Quantum Cramer-Rao Bound (QCRB). Numerical analysis\nreveals that the PEM scheme achieves the lowest QCRB, offering the highest\nestimation accuracy, while JBM provides a favorable balance between precision\nand implementation complexity. The LZM method, although experimentally simpler,\nexhibits higher estimation error relative to the other schemes; however, it\noutperforms JBM in high-noise regimes for single-link estimation. We further\nevaluate the estimation performance on a four-node star network by comparing a\nJBM-only configuration with a hybrid configuration that combines JBM and LZM.\nWhen two monitors are used, the JBM-only strategy outperforms the hybrid\napproach across all noise regimes. However, with three monitors, it achieves a\nlower QCRB only in low-noise regimes with heterogeneous links. The results\nestablish a practical basis for selecting measurement strategies in\nexperimental quantum networks, enabling more accurate and scalable link\nparameter estimation under realistic noise conditions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u91cf\u5b50\u7f51\u7edc\u5c42\u6790\u6210\u50cf\u4e2d\u4e09\u79cd\u6d4b\u91cf\u7b56\u7565\uff1a\u5c40\u57dfZ\u57fa\u6d4b\u91cf(LZM)\u3001\u8054\u5408\u8d1d\u5c14\u6001\u6d4b\u91cf(JBM)\u548c\u9884\u5171\u4eab\u7ea0\u7f20\u8f85\u52a9\u6d4b\u91cf(PEM)\u3002PEM\u65b9\u6848\u8fbe\u5230\u6700\u4f4e\u91cf\u5b50Cram\u00e9r-Rao\u754c\uff0c\u7cbe\u5ea6\u6700\u9ad8\uff1bJBM\u5728\u7cbe\u5ea6\u548c\u5b9e\u73b0\u590d\u6742\u5ea6\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff1bLZM\u5b9e\u9a8c\u7b80\u5355\u4f46\u5728\u9ad8\u566a\u58f0\u5355\u94fe\u8def\u4f30\u8ba1\u4e2d\u4f18\u4e8eJBM\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u7f51\u7edc\u5c42\u6790\u6210\u50cf\u4e2d\u4e0d\u540c\u6d4b\u91cf\u7b56\u7565\u5bf9\u94fe\u8def\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9a8c\u91cf\u5b50\u7f51\u7edc\u9009\u62e9\u6d4b\u91cf\u7b56\u7565\u63d0\u4f9b\u5b9e\u7528\u57fa\u7840\uff0c\u5728\u73b0\u5b9e\u566a\u58f0\u6761\u4ef6\u4e0b\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u53ef\u6269\u5c55\u7684\u94fe\u8def\u53c2\u6570\u4f30\u8ba1\u3002", "method": "\u5206\u6790\u4e09\u79cd\u6d4b\u91cf\u65b9\u6848\uff1aLZM\u3001JBM\u548cPEM\uff0c\u63a8\u5bfc\u6d4b\u91cf\u7ed3\u679c\u7684\u6982\u7387\u5206\u5e03\uff0c\u7814\u7a76\u5206\u5e03\u5f0f\u6001\u4e2d\u566a\u58f0\u5bf9\u4f30\u8ba1\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u83b7\u5f97\u91cf\u5b50Fisher\u4fe1\u606f\u77e9\u9635\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u901a\u8fc7\u91cf\u5b50Cram\u00e9r-Rao\u754c\u8bc4\u4f30\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u5e76\u5728\u56db\u8282\u70b9\u661f\u578b\u7f51\u7edc\u4e0a\u8fdb\u884c\u6570\u503c\u5206\u6790\u3002", "result": "PEM\u65b9\u6848\u8fbe\u5230\u6700\u4f4eQCRB\uff0c\u4f30\u8ba1\u7cbe\u5ea6\u6700\u9ad8\uff1bJBM\u5728\u7cbe\u5ea6\u548c\u5b9e\u73b0\u590d\u6742\u5ea6\u95f4\u5e73\u8861\u826f\u597d\uff1bLZM\u5b9e\u9a8c\u7b80\u5355\u4f46\u5728\u9ad8\u566a\u58f0\u5355\u94fe\u8def\u4f30\u8ba1\u4e2d\u4f18\u4e8eJBM\u3002\u5728\u56db\u8282\u70b9\u7f51\u7edc\u4e2d\uff0c\u53cc\u76d1\u63a7\u5668\u65f6JBM-only\u7b56\u7565\u5728\u6240\u6709\u566a\u58f0\u6761\u4ef6\u4e0b\u4f18\u4e8e\u6df7\u5408\u7b56\u7565\uff1b\u4e09\u76d1\u63a7\u5668\u65f6\u4ec5\u5728\u4f4e\u566a\u58f0\u5f02\u8d28\u94fe\u8def\u4e2d\u8fbe\u5230\u66f4\u4f4eQCRB\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5b9e\u9a8c\u91cf\u5b50\u7f51\u7edc\u9009\u62e9\u6d4b\u91cf\u7b56\u7565\u5efa\u7acb\u4e86\u5b9e\u7528\u57fa\u7840\uff0cPEM\u63d0\u4f9b\u6700\u9ad8\u7cbe\u5ea6\uff0cJBM\u5728\u590d\u6742\u5ea6\u548c\u7cbe\u5ea6\u95f4\u5e73\u8861\u826f\u597d\uff0cLZM\u9002\u5408\u7b80\u5355\u5b9e\u9a8c\u8bbe\u7f6e\uff0c\u4e0d\u540c\u7b56\u7565\u5728\u4e0d\u540c\u7f51\u7edc\u914d\u7f6e\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.00136", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00136", "abs": "https://arxiv.org/abs/2511.00136", "authors": ["Qing Guo", "Xinhang Li", "Junyu Chen", "Zheng Guo", "Xiaocong Li", "Lin Zhang", "Lei Li"], "title": "A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control", "comment": null, "summary": "Leveraging large language models (LLMs) in traffic signal control (TSC)\nimproves optimization efficiency and interpretability compared to traditional\nreinforcement learning (RL) methods. However, existing LLM-based approaches are\nlimited by fixed time signal durations and are prone to hallucination errors,\nwhile RL methods lack robustness in signal timing decisions and suffer from\npoor generalization. To address these challenges, this paper proposes\nHeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The\nHerald Module extracts contextual information and forecasts queue lengths for\neach traffic phase based on real-time conditions. The first LLM, LLM-Agent,\nuses these forecasts to make fine grained traffic signal control, while the\nsecond LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and\nhallucinations. These refined outputs are used for score-based fine-tuning to\nimprove accuracy and robustness. Simulation experiments using CityFlow on real\nworld datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New\nYork (196) demonstrate that HeraldLight outperforms state of the art baselines,\nachieving a 20.03% reduction in average travel time across all scenarios and a\n10.74% reduction in average queue length on the Jinan and Hangzhou scenarios.\nThe source code is available on GitHub:\nhttps://github.com/BUPT-ANTlab/HeraldLight.", "AI": {"tldr": "HeraldLight\u63d0\u51fa\u4e86\u4e00\u79cd\u53ccLLM\u67b6\u6784\uff0c\u901a\u8fc7Herald\u5f15\u5bfc\u63d0\u793a\u589e\u5f3a\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u56fa\u5b9a\u4fe1\u53f7\u65f6\u957f\u548c\u5e7b\u89c9\u9519\u8bef\u7684\u95ee\u9898\uff0c\u4ee5\u53caRL\u65b9\u6cd5\u7f3a\u4e4f\u9c81\u68d2\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u5b58\u5728\u56fa\u5b9a\u65f6\u95f4\u4fe1\u53f7\u65f6\u957f\u548c\u5e7b\u89c9\u9519\u8bef\u7684\u9650\u5236\uff0c\u800c\u4f20\u7edfRL\u65b9\u6cd5\u5728\u4fe1\u53f7\u65f6\u5e8f\u51b3\u7b56\u4e2d\u7f3a\u4e4f\u9c81\u68d2\u6027\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u91c7\u7528\u53ccLLM\u67b6\u6784\uff1aHerald\u6a21\u5757\u63d0\u53d6\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u9884\u6d4b\u5404\u4ea4\u901a\u76f8\u4f4d\u961f\u5217\u957f\u5ea6\uff1bLLM-Agent\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff1bLLM-Critic\u4fee\u6b63LLM-Agent\u7684\u8f93\u51fa\u9519\u8bef\u548c\u5e7b\u89c9\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5206\u6570\u7684\u5fae\u8c03\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u5728CityFlow\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u6db5\u76d6\u6d4e\u5357(12)\u3001\u676d\u5dde(16)\u548c\u7ebd\u7ea6(196)\u5171224\u4e2a\u4ea4\u53c9\u53e3\u7684\u771f\u5b9e\u6570\u636e\u96c6\uff0cHeraldLight\u5728\u5e73\u5747\u65c5\u884c\u65f6\u95f4\u4e0a\u6bd4\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u51cf\u5c1120.03%\uff0c\u5728\u6d4e\u5357\u548c\u676d\u5dde\u573a\u666f\u4e2d\u5e73\u5747\u961f\u5217\u957f\u5ea6\u51cf\u5c1110.74%\u3002", "conclusion": "HeraldLight\u901a\u8fc7\u53ccLLM\u67b6\u6784\u548cHerald\u5f15\u5bfc\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2511.01709", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2511.01709", "abs": "https://arxiv.org/abs/2511.01709", "authors": ["Ruicheng Bao"], "title": "Initial-State Typicality in Quantum Relaxation", "comment": "9 + 15 pages, 2 figures. Comments and questions are very welcome", "summary": "Relaxation in open quantum systems is fundamental to quantum science and\ntechnologies. Yet, the influence of the initial state on relaxation remains a\ncentral, largely unanswered question. Here, by systematically characterizing\nthe relaxation behavior of generic initial states, we uncover a typicality\nphenomenon in high-dimensional open quantum systems: relaxation becomes nearly\ninitial-state-independent as system size increases under verifiable conditions.\nCrucially, we prove this typicality for thermalization processes above a\nsize-independent temperature. Our findings extend the typicality to open\nquantum dynamics, in turn identifying a class of systems where two widely used\nquantities -- the Liouvillian gap and the maximal relaxation time -- merit\nre-examination. We formalize this with two new concepts: the 'typical strong\nMpemba effect' and the 'typical relaxation time'. Beyond these conceptual\nadvances, our results provide practical implications: a scalable route to\naccelerating relaxation and a typical mixing-time benchmark that complements\nconventional worst-case metrics for quantum simulations and state preparation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u9ad8\u7ef4\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5b58\u5728\u5178\u578b\u6027\u73b0\u8c61\uff1a\u5728\u53ef\u9a8c\u8bc1\u6761\u4ef6\u4e0b\uff0c\u968f\u7740\u7cfb\u7edf\u5c3a\u5bf8\u589e\u5927\uff0c\u5f1b\u8c6b\u8fc7\u7a0b\u51e0\u4e4e\u4e0e\u521d\u59cb\u72b6\u6001\u65e0\u5173\uff0c\u7279\u522b\u662f\u5728\u70ed\u5316\u8fc7\u7a0b\u4e2d\u3002", "motivation": "\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u5f1b\u8c6b\u662f\u91cf\u5b50\u79d1\u5b66\u4e0e\u6280\u672f\u7684\u57fa\u7840\uff0c\u4f46\u521d\u59cb\u72b6\u6001\u5bf9\u5f1b\u8c6b\u7684\u5f71\u54cd\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8868\u5f81\u4e00\u822c\u521d\u59cb\u72b6\u6001\u7684\u5f1b\u8c6b\u884c\u4e3a\uff0c\u7814\u7a76\u9ad8\u7ef4\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u5178\u578b\u6027\u73b0\u8c61\uff0c\u5e76\u8bc1\u660e\u5728\u5c3a\u5bf8\u65e0\u5173\u6e29\u5ea6\u4ee5\u4e0a\u7684\u70ed\u5316\u8fc7\u7a0b\u4e2d\u5b58\u5728\u8fd9\u79cd\u5178\u578b\u6027\u3002", "result": "\u53d1\u73b0\u5f1b\u8c6b\u8fc7\u7a0b\u968f\u7740\u7cfb\u7edf\u5c3a\u5bf8\u589e\u5927\u53d8\u5f97\u51e0\u4e4e\u4e0e\u521d\u59cb\u72b6\u6001\u65e0\u5173\uff0c\u63d0\u51fa\u4e86'\u5178\u578b\u5f3a\u59c6\u5f6d\u5df4\u6548\u5e94'\u548c'\u5178\u578b\u5f1b\u8c6b\u65f6\u95f4'\u4e24\u4e2a\u65b0\u6982\u5ff5\uff0c\u5bf9Liouvillian\u80fd\u9699\u548c\u6700\u5927\u5f1b\u8c6b\u65f6\u95f4\u7b49\u5e38\u7528\u91cf\u63d0\u51fa\u4e86\u91cd\u65b0\u5ba1\u89c6\u7684\u5fc5\u8981\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e0d\u4ec5\u6269\u5c55\u4e86\u5178\u578b\u6027\u5230\u5f00\u653e\u91cf\u5b50\u52a8\u529b\u5b66\uff0c\u8fd8\u4e3a\u52a0\u901f\u5f1b\u8c6b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84\uff0c\u5e76\u4e3a\u91cf\u5b50\u6a21\u62df\u548c\u6001\u5236\u5907\u63d0\u4f9b\u4e86\u5178\u578b\u6df7\u5408\u65f6\u95f4\u57fa\u51c6\uff0c\u8865\u5145\u4e86\u4f20\u7edf\u7684worst-case\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2511.00166", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00166", "abs": "https://arxiv.org/abs/2511.00166", "authors": ["Shiman Zhang", "Jinghan Zhou", "Zhoufan Yu", "Ningai Leng"], "title": "Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning", "comment": "9 pages, 3 figures", "summary": "To improve decision-making and planning efficiency in back-end centralized\nredundant supply chains, this paper proposes a decision model integrating deep\nlearning with intelligent particle swarm optimization. A distributed node\ndeployment model and optimal planning path are constructed for the supply chain\nnetwork. Deep learning such as convolutional neural networks extracts features\nfrom historical data, and linear programming captures high-order statistical\nfeatures. The model is optimized using fuzzy association rule scheduling and\ndeep reinforcement learning, while neural networks fit dynamic changes. A\nhybrid mechanism of \"deep learning feature extraction - intelligent particle\nswarm optimization\" guides global optimization and selects optimal decisions\nfor adaptive control. Simulations show reduced resource consumption, enhanced\nspatial planning, and in dynamic environments improved real-time decision\nadjustment, distribution path optimization, and robust intelligent control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u667a\u80fd\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u51b3\u7b56\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u5347\u540e\u7aef\u96c6\u4e2d\u5f0f\u5197\u4f59\u4f9b\u5e94\u94fe\u7684\u51b3\u7b56\u6548\u7387\u548c\u89c4\u5212\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u540e\u7aef\u96c6\u4e2d\u5f0f\u5197\u4f59\u4f9b\u5e94\u94fe\u7684\u51b3\u7b56\u5236\u5b9a\u548c\u89c4\u5212\u6548\u7387\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u667a\u80fd\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5206\u5e03\u5f0f\u8282\u70b9\u90e8\u7f72\u6a21\u578b\u548c\u6700\u4f18\u89c4\u5212\u8def\u5f84\uff0c\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u7ebf\u6027\u89c4\u5212\u6355\u83b7\u9ad8\u9636\u7edf\u8ba1\u7279\u5f81\uff0c\u91c7\u7528\u6a21\u7cca\u5173\u8054\u89c4\u5219\u8c03\u5ea6\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\uff0c\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u52a8\u6001\u53d8\u5316\uff0c\u5efa\u7acb\"\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u63d0\u53d6-\u667a\u80fd\u7c92\u5b50\u7fa4\u4f18\u5316\"\u6df7\u5408\u673a\u5236\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\uff0c\u7a7a\u95f4\u89c4\u5212\u589e\u5f3a\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6539\u5584\u4e86\u5b9e\u65f6\u51b3\u7b56\u8c03\u6574\u3001\u914d\u9001\u8def\u5f84\u4f18\u5316\u548c\u9c81\u68d2\u667a\u80fd\u63a7\u5236\u3002", "conclusion": "\u8be5\u96c6\u6210\u6a21\u578b\u6709\u6548\u63d0\u5347\u4e86\u4f9b\u5e94\u94fe\u51b3\u7b56\u6548\u7387\u548c\u89c4\u5212\u80fd\u529b\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u4f18\u5316\u6548\u679c\u3002"}}
{"id": "2511.01761", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.01761", "abs": "https://arxiv.org/abs/2511.01761", "authors": ["Mariia Gumberidze", "Vladyslav C. Usenko"], "title": "Non-Gaussianity and security of entanglement-based QKD", "comment": "6 pages, 5 figures", "summary": "We theoretically analyse the relation between non-Gaussianity and security of\nentanglement-based quantum key distribution (QKD) protocols, namely\ndevice-independent (DI) and entanglement-based BB$84$. A similar analysis has\nalready been made for prepare-and-measure (P\\&M) protocols \\cite{Lasota2017}.\nIn addition, we consider imperfect detection with dark counts and limited\nefficiency. We assume a perfect source of entangled Bell states as produced by\nquantum-dot type sources, depolarisation in the channel and different noise\nstatistics, namely thermal and Poissonian. We consider single-photon avalanche\nphotodiodes (SPAD) and photon number resolving detectors (PNRD) and use their\nrespective criteria for non-Gaussianity. The results show cross-regions for\nboth security and non-Gaussianity, hence, the possibility to conclude about the\nsuitability of a given channel for secret key distribution. Our results can be\nuseful as a pre-check for the implementation of QKD protocols.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u975e\u9ad8\u65af\u6027\u4e0e\u57fa\u4e8e\u7ea0\u7f20\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8003\u8651\u4e86\u4e0d\u5b8c\u7f8e\u68c0\u6d4b\u548c\u4e0d\u540c\u566a\u58f0\u7edf\u8ba1\uff0c\u4e3aQKD\u534f\u8bae\u5b9e\u73b0\u63d0\u4f9b\u4e86\u9884\u68c0\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u975e\u9ad8\u65af\u6027\u4e0e\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u7406\u8bba\u5173\u7cfb\uff0c\u4e3a\u5b9e\u9645QKD\u5b9e\u73b0\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u7406\u8bba\u5206\u6790\u8bbe\u5907\u65e0\u5173\u548c\u57fa\u4e8e\u7ea0\u7f20\u7684BB84\u534f\u8bae\uff0c\u8003\u8651\u4e0d\u5b8c\u7f8e\u68c0\u6d4b\uff08\u6697\u8ba1\u6570\u548c\u6709\u9650\u6548\u7387\uff09\u3001\u4e0d\u540c\u566a\u58f0\u7edf\u8ba1\uff08\u70ed\u566a\u58f0\u548c\u6cca\u677e\u566a\u58f0\uff09\u4ee5\u53ca\u4e0d\u540c\u7c7b\u578b\u63a2\u6d4b\u5668\u3002", "result": "\u53d1\u73b0\u4e86\u5b89\u5168\u6027\u548c\u975e\u9ad8\u65af\u6027\u4e4b\u95f4\u7684\u4ea4\u53c9\u533a\u57df\uff0c\u80fd\u591f\u5224\u65ad\u7ed9\u5b9a\u4fe1\u9053\u662f\u5426\u9002\u5408\u5bc6\u94a5\u5206\u53d1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u4f5c\u4e3aQKD\u534f\u8bae\u5b9e\u73b0\u7684\u9884\u68c0\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u4fe1\u9053\u5bf9\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.00177", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00177", "abs": "https://arxiv.org/abs/2511.00177", "authors": ["Hiba Ahsan", "Byron C. Wallace"], "title": "Can SAEs reveal and mitigate racial biases of LLMs in healthcare?", "comment": null, "summary": "LLMs are increasingly being used in healthcare. This promises to free\nphysicians from drudgery, enabling better care to be delivered at scale. But\nthe use of LLMs in this space also brings risks; for example, such models may\nworsen existing biases. How can we spot when LLMs are (spuriously) relying on\npatient race to inform predictions? In this work we assess the degree to which\nSparse Autoencoders (SAEs) can reveal (and control) associations the model has\nmade between race and stigmatizing concepts. We first identify SAE latents in\nGemma-2 models which appear to correlate with Black individuals. We find that\nthis latent activates on reasonable input sequences (e.g., \"African American\")\nbut also problematic words like \"incarceration\". We then show that we can use\nthis latent to steer models to generate outputs about Black patients, and\nfurther that this can induce problematic associations in model outputs as a\nresult. For example, activating the Black latent increases the risk assigned to\nthe probability that a patient will become \"belligerent\". We evaluate the\ndegree to which such steering via latents might be useful for mitigating bias.\nWe find that this offers improvements in simple settings, but is less\nsuccessful for more realistic and complex clinical tasks. Overall, our results\nsuggest that: SAEs may offer a useful tool in clinical applications of LLMs to\nidentify problematic reliance on demographics but mitigating bias via SAE\nsteering appears to be of marginal utility for realistic tasks.", "AI": {"tldr": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAEs)\u5206\u6790Gemma-2\u6a21\u578b\u4e2d\u4e0e\u79cd\u65cf\u76f8\u5173\u7684\u6f5c\u5728\u7279\u5f81\uff0c\u53d1\u73b0\u8fd9\u4e9b\u7279\u5f81\u80fd\u8bc6\u522b\u6a21\u578b\u5bf9\u9ed1\u4eba\u60a3\u8005\u7684\u504f\u89c1\u5173\u8054\uff0c\u4f46\u901a\u8fc7SAE\u8c03\u63a7\u6765\u51cf\u8f7b\u504f\u89c1\u5728\u590d\u6742\u4e34\u5e8a\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\u3002", "motivation": "LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u5b58\u5728\u52a0\u5267\u73b0\u6709\u504f\u89c1\u7684\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u65b9\u6cd5\u6765\u68c0\u6d4b\u6a21\u578b\u662f\u5426\u9519\u8bef\u5730\u4f9d\u8d56\u60a3\u8005\u79cd\u65cf\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u5728Gemma-2\u6a21\u578b\u4e2d\u8bc6\u522b\u4e0e\u9ed1\u4eba\u4e2a\u4f53\u76f8\u5173\u7684SAE\u6f5c\u5728\u7279\u5f81\uff0c\u5206\u6790\u8fd9\u4e9b\u7279\u5f81\u7684\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u6f5c\u5728\u7279\u5f81\u8c03\u63a7\u6765\u6d4b\u8bd5\u6a21\u578b\u8f93\u51fa\u7684\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u4e0e\u9ed1\u4eba\u76f8\u5173\u7684\u6f5c\u5728\u7279\u5f81\u4e0d\u4ec5\u5bf9\u5408\u7406\u8f93\u5165(\u5982\"\u975e\u88d4\u7f8e\u56fd\u4eba\")\u6fc0\u6d3b\uff0c\u4e5f\u5bf9\u95ee\u9898\u8bcd\u6c47(\u5982\"\u76d1\u7981\")\u6fc0\u6d3b\uff1b\u6fc0\u6d3b\u8be5\u7279\u5f81\u4f1a\u589e\u52a0\u6a21\u578b\u5c06\u60a3\u8005\u9884\u6d4b\u4e3a\"\u597d\u6597\"\u7684\u98ce\u9669\uff1bSAE\u8c03\u63a7\u5728\u7b80\u5355\u573a\u666f\u4e2d\u80fd\u6539\u5584\u504f\u89c1\uff0c\u4f46\u5728\u590d\u6742\u4e34\u5e8a\u4efb\u52a1\u4e2d\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "SAEs\u53ef\u4f5c\u4e3a\u8bc6\u522bLLMs\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u95ee\u9898\u6027\u4f9d\u8d56\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u7684\u6709\u7528\u5de5\u5177\uff0c\u4f46\u901a\u8fc7SAE\u8c03\u63a7\u6765\u51cf\u8f7b\u504f\u89c1\u5728\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u6709\u9650\u3002"}}
{"id": "2511.01762", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01762", "abs": "https://arxiv.org/abs/2511.01762", "authors": ["Andrew D. King"], "title": "Multi-objective optimization by quantum annealing", "comment": null, "summary": "An important task in multi-objective optimization is generating the Pareto\nfront -- the set of all Pareto-optimal compromises among multiple objective\nfunctions applied to the same set of variables. Since this task can be\ncomputationally intensive even for small problems, it is a natural target for\nquantum optimization. Indeed, this problem was recently approached using the\nquantum approximate optimization algorithm (QAOA) on an IBM gate-model\nprocessor. Here we compare these QAOA results with quantum annealing on the\nsame two input problems, using the same methodology. We find that quantum\nannealing vastly outperforms not just QAOA run on the IBM processor, but all\nclassical and quantum methods analyzed in the previous study. On the harder\nproblem, quantum annealing improves upon the best known Pareto front. This\nsmall study reinforces the promise of quantum annealing in multi-objective\noptimization.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u91cf\u5b50\u9000\u706b\u548cQAOA\u5728\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u91cf\u5b50\u9000\u706b\u5728\u751f\u6210\u5e15\u7d2f\u6258\u524d\u6cbf\u65b9\u9762\u663e\u8457\u4f18\u4e8eQAOA\u548c\u6240\u6709\u5176\u4ed6\u7ecf\u5178\u4e0e\u91cf\u5b50\u65b9\u6cd5\u3002", "motivation": "\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u751f\u6210\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u8ba1\u7b97\u6210\u672c\u5f88\u9ad8\uff0c\u8fd9\u4f7f\u5176\u6210\u4e3a\u91cf\u5b50\u4f18\u5316\u7684\u81ea\u7136\u76ee\u6807\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u91cf\u5b50\u9000\u706b\u548cQAOA\u5728\u76f8\u540c\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u4e0e\u4e4b\u524d\u7814\u7a76\u76f8\u540c\u7684\u65b9\u6cd5\u8bba\uff0c\u5728\u4e24\u4e2a\u8f93\u5165\u95ee\u9898\u4e0a\u6bd4\u8f83\u91cf\u5b50\u9000\u706b\u548cQAOA\uff08\u5728IBM\u95e8\u6a21\u578b\u5904\u7406\u5668\u4e0a\u8fd0\u884c\uff09\u7684\u6027\u80fd\u3002", "result": "\u91cf\u5b50\u9000\u706b\u5728\u6027\u80fd\u4e0a\u5927\u5e45\u8d85\u8d8aQAOA\u4ee5\u53ca\u4e4b\u524d\u7814\u7a76\u4e2d\u5206\u6790\u7684\u6240\u6709\u7ecf\u5178\u548c\u91cf\u5b50\u65b9\u6cd5\u3002\u5728\u66f4\u96be\u7684\u95ee\u9898\u4e0a\uff0c\u91cf\u5b50\u9000\u706b\u6539\u8fdb\u4e86\u5df2\u77e5\u7684\u6700\u4f73\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "\u8fd9\u9879\u5c0f\u578b\u7814\u7a76\u5f3a\u5316\u4e86\u91cf\u5b50\u9000\u706b\u5728\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00183", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00183", "abs": "https://arxiv.org/abs/2511.00183", "authors": ["Shaghayegh Fazliani", "Madeleine Udell"], "title": "PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes", "comment": null, "summary": "Current LLM-driven approaches using test-time computing to generate PDE\nsolvers execute a large number of solver samples to identify high-accuracy\nsolvers. These paradigms are especially costly for complex PDEs requiring\nsubstantial computational resources for numerical evaluation. We introduce\nPDE-SHARP, a framework to reduce computational costs by replacing expensive\nscientific computation by cheaper LLM inference that achieves superior solver\naccuracy with 60-75% fewer computational evaluations. PDE-SHARP employs three\nstages: (1) Analysis: mathematical chain-of-thought analysis including PDE\nclassification, solution type detection, and stability analysis; (2) Genesis:\nsolver generation based on mathematical insights from the previous stage; and\n(3) Synthesis: collaborative selection-hybridization tournaments in which LLM\njudges iteratively refine implementations through flexible performance\nfeedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13\nsolver evaluations on average compared to 30+ for baseline methods, improving\naccuracy uniformly across tested PDEs by $4\\times$ on average, and demonstrates\nrobust performance across LLM architectures, from general-purpose to\nspecialized reasoning models.", "AI": {"tldr": "PDE-SHARP\u662f\u4e00\u4e2a\u901a\u8fc7\u7528\u66f4\u4fbf\u5b9c\u7684LLM\u63a8\u7406\u66ff\u4ee3\u6602\u8d35\u7684\u79d1\u5b66\u8ba1\u7b97\u6765\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u51cf\u5c1160-75%\u8ba1\u7b97\u8bc4\u4f30\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u6c42\u89e3\u5668\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u4f7f\u7528\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7684LLM\u9a71\u52a8\u65b9\u6cd5\u9700\u8981\u6267\u884c\u5927\u91cf\u6c42\u89e3\u5668\u6837\u672c\u6765\u8bc6\u522b\u9ad8\u7cbe\u5ea6\u6c42\u89e3\u5668\uff0c\u5bf9\u4e8e\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u6570\u503c\u8bc4\u4f30\u7684\u590d\u6742PDE\u6765\u8bf4\u6210\u672c\u5c24\u5176\u9ad8\u6602\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff1a(1)\u5206\u6790\uff1a\u5305\u62ecPDE\u5206\u7c7b\u3001\u89e3\u7c7b\u578b\u68c0\u6d4b\u548c\u7a33\u5b9a\u6027\u5206\u6790\u7684\u6570\u5b66\u601d\u7ef4\u94fe\u5206\u6790\uff1b(2)\u751f\u6210\uff1a\u57fa\u4e8e\u524d\u4e00\u9636\u6bb5\u6570\u5b66\u6d1e\u5bdf\u7684\u6c42\u89e3\u5668\u751f\u6210\uff1b(3)\u5408\u6210\uff1aLLM\u8bc4\u59d4\u901a\u8fc7\u7075\u6d3b\u6027\u80fd\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u5b9e\u73b0\u7684\u534f\u4f5c\u9009\u62e9-\u6df7\u5408\u9526\u6807\u8d5b\u3002", "result": "\u5e73\u5747\u9700\u8981\u5c11\u4e8e13\u6b21\u6c42\u89e3\u5668\u8bc4\u4f30\uff08\u57fa\u7ebf\u65b9\u6cd5\u9700\u898130+\u6b21\uff09\uff0c\u5728\u6d4b\u8bd5\u7684PDE\u4e0a\u5e73\u5747\u7cbe\u5ea6\u63d0\u9ad84\u500d\uff0c\u5e76\u5728\u4ece\u901a\u7528\u5230\u4e13\u7528\u63a8\u7406\u6a21\u578b\u7684\u5404\u79cdLLM\u67b6\u6784\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "PDE-SHARP\u901a\u8fc7\u5c06\u6602\u8d35\u79d1\u5b66\u8ba1\u7b97\u66ff\u6362\u4e3a\u66f4\u4fbf\u5b9c\u7684LLM\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6c42\u89e3\u5668\u7cbe\u5ea6\u548c\u7a33\u5065\u6027\u80fd\u3002"}}
{"id": "2511.01845", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01845", "abs": "https://arxiv.org/abs/2511.01845", "authors": ["Mario Herrero-Gonzalez", "Brian Coyle", "Kieran McDowall", "Ross Grassie", "Sjoerd Beentjes", "Ava Khamseh", "Elham Kashefi"], "title": "The Born Ultimatum: Conditions for Classical Surrogation of Quantum Generative Models with Correlators", "comment": "45 pages, 17 figures", "summary": "Quantum Circuit Born Machines (QCBMs) are powerful quantum generative models\nthat sample according to the Born rule, with complexity-theoretic evidence\nsuggesting potential quantum advantages for generative tasks. Here, we identify\nQCBMs as a quantum Fourier model independently of the loss function. This\nallows us to apply known dequantization conditions when the optimal quantum\ndistribution is available. However, realizing this distribution is hindered by\ntrainability issues such as vanishing gradients on quantum hardware. Recent\ntrain-classical, deploy-quantum approaches propose training classical\nsurrogates of QCBMs and using quantum devices only for inference. We analyze\nthe limitations of these methods arising from deployment discrepancies between\nclassically trained and quantumly deployed parameters. Using the Fourier\ndecomposition of the Born rule in terms of correlators, we quantify this\ndiscrepancy analytically. Approximating the decomposition via distribution\ntruncation and classical surrogation provides concrete examples of such\ndiscrepancies, which we demonstrate numerically. We study this effect using\ntensor-networks and Pauli-propagation-based classical surrogates. Our study\nexamines the use of IQP circuits, matchcircuits, Heisenberg-chain circuits, and\nHaldane-chain circuits for the QCBM ansatz. In doing so, we derive closed-form\nexpressions for Pauli propagation in IQP circuits and the dynamical Lie algebra\nof the Haldane chain, which may be of independent interest.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u91cf\u5b50\u7535\u8def\u73bb\u6069\u673a(QCBM)\u4f5c\u4e3a\u91cf\u5b50\u5085\u91cc\u53f6\u6a21\u578b\u7684\u7279\u6027\uff0c\u7814\u7a76\u4e86\u8bad\u7ec3-\u7ecf\u5178\u3001\u90e8\u7f72-\u91cf\u5b50\u65b9\u6cd5\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u5206\u89e3\u91cf\u5316\u4e86\u7ecf\u5178\u8bad\u7ec3\u4e0e\u91cf\u5b50\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "motivation": "\u91cf\u5b50\u7535\u8def\u73bb\u6069\u673a\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u5728\u91cf\u5b50\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u8bad\u7ec3\u56f0\u96be\u95ee\u9898\u3002\u6700\u8fd1\u63d0\u51fa\u7684\u8bad\u7ec3-\u7ecf\u5178\u3001\u90e8\u7f72-\u91cf\u5b50\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u8bad\u7ec3\u7ecf\u5178\u4ee3\u7406\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5b58\u5728\u90e8\u7f72\u5dee\u5f02\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5085\u91cc\u53f6\u5206\u89e3\u5206\u6790\u73bb\u6069\u89c4\u5219\uff0c\u901a\u8fc7\u5206\u5e03\u622a\u65ad\u548c\u7ecf\u5178\u4ee3\u7406\u6765\u8fd1\u4f3c\u5206\u89e3\uff0c\u4f7f\u7528\u5f20\u91cf\u7f51\u7edc\u548c\u6ce1\u5229\u4f20\u64ad\u57fa\u7ecf\u5178\u4ee3\u7406\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86IQP\u7535\u8def\u3001\u5339\u914d\u7535\u8def\u3001\u6d77\u68ee\u5821\u94fe\u7535\u8def\u548c\u970d\u5c14\u4e39\u94fe\u7535\u8def\u3002", "result": "\u63a8\u5bfc\u4e86IQP\u7535\u8def\u4e2d\u6ce1\u5229\u4f20\u64ad\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u970d\u5c14\u4e39\u94fe\u7684\u52a8\u6001\u674e\u4ee3\u6570\uff0c\u6570\u503c\u6f14\u793a\u4e86\u7ecf\u5178\u8bad\u7ec3\u4e0e\u91cf\u5b50\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "conclusion": "\u8bad\u7ec3-\u7ecf\u5178\u3001\u90e8\u7f72-\u91cf\u5b50\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7684\u90e8\u7f72\u5dee\u5f02\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u51cf\u5c11\u8fd9\u79cd\u5dee\u5f02\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u91cf\u5b50\u751f\u6210\u6a21\u578b\u90e8\u7f72\u3002"}}
{"id": "2511.00192", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00192", "abs": "https://arxiv.org/abs/2511.00192", "authors": ["Ali Satvaty", "Suzan Verberne", "Fatih Turkmen"], "title": "EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs", "comment": null, "summary": "Membership inference attacks (MIA) aim to infer whether a particular data\npoint is part of the training dataset of a model. In this paper, we propose a\nnew task in the context of LLM privacy: entity-level discovery of membership\nrisk focused on sensitive information (PII, credit card numbers, etc). Existing\nmethods for MIA can detect the presence of entire prompts or documents in the\nLLM training data, but they fail to capture risks at a finer granularity. We\npropose the ``EL-MIA'' framework for auditing entity-level membership risks in\nLLMs. We construct a benchmark dataset for the evaluation of MIA methods on\nthis task. Using this benchmark, we conduct a systematic comparison of existing\nMIA techniques as well as two newly proposed methods. We provide a\ncomprehensive analysis of the results, trying to explain the relation of the\nentity level MIA susceptability with the model scale, training epochs, and\nother surface level factors. Our findings reveal that existing MIA methods are\nlimited when it comes to entity-level membership inference of the sensitive\nattributes, while this susceptibility can be outlined with relatively\nstraightforward methods, highlighting the need for stronger adversaries to\nstress test the provided threat model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9LLM\u9690\u79c1\u7684\u65b0\u4efb\u52a1\u2014\u2014\u5b9e\u4f53\u7ea7\u6210\u5458\u63a8\u65ad\u98ce\u9669\u53d1\u73b0\uff0c\u4e13\u6ce8\u4e8e\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709MIA\u65b9\u6cd5\u53ea\u80fd\u68c0\u6d4b\u6574\u4e2a\u63d0\u793a\u6216\u6587\u6863\uff0c\u65e0\u6cd5\u6355\u6349\u66f4\u7ec6\u7c92\u5ea6\u7684\u98ce\u9669\u3002\u4f5c\u8005\u63d0\u51fa\u4e86EL-MIA\u6846\u67b6\u6765\u5ba1\u8ba1LLM\u4e2d\u7684\u5b9e\u4f53\u7ea7\u6210\u5458\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u5728\u68c0\u6d4bLLM\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u53ea\u80fd\u8bc6\u522b\u6574\u4e2a\u63d0\u793a\u6216\u6587\u6863\u7684\u6210\u5458\u8d44\u683c\uff0c\u65e0\u6cd5\u5728\u5b9e\u4f53\u7ea7\u522b\u4e0a\u53d1\u73b0\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86EL-MIA\u6846\u67b6\u7528\u4e8e\u5ba1\u8ba1LLM\u4e2d\u7684\u5b9e\u4f53\u7ea7\u6210\u5458\u98ce\u9669\uff0c\u6784\u5efa\u4e86\u8bc4\u4f30\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u73b0\u6709MIA\u6280\u672f\u548c\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5b9e\u4f53\u7ea7MIA\u6613\u611f\u6027\u4e0e\u6a21\u578b\u89c4\u6a21\u3001\u8bad\u7ec3\u8f6e\u6b21\u7b49\u56e0\u7d20\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709MIA\u65b9\u6cd5\u5728\u654f\u611f\u5c5e\u6027\u7684\u5b9e\u4f53\u7ea7\u6210\u5458\u63a8\u65ad\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f46\u8fd9\u79cd\u6613\u611f\u6027\u53ef\u4ee5\u901a\u8fc7\u76f8\u5bf9\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\uff0c\u8868\u660e\u9700\u8981\u66f4\u5f3a\u7684\u5bf9\u6297\u65b9\u6cd5\u6765\u5145\u5206\u6d4b\u8bd5\u5a01\u80c1\u6a21\u578b\u3002", "conclusion": "\u5b9e\u4f53\u7ea7\u6210\u5458\u63a8\u65ad\u98ce\u9669\u662fLLM\u9690\u79c1\u4fdd\u62a4\u4e2d\u7684\u91cd\u8981\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5bf9\u6b64\u7c7b\u7ec6\u7c92\u5ea6\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u5bf9\u6297\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2511.00203", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00203", "abs": "https://arxiv.org/abs/2511.00203", "authors": ["David L\u00fcdke", "Tom Wollschl\u00e4ger", "Paul Ungermann", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Diffusion LLMs are Natural Adversaries for any LLM", "comment": null, "summary": "We introduce a novel framework that transforms the resource-intensive\n(adversarial) prompt optimization problem into an \\emph{efficient, amortized\ninference task}. Our core insight is that pretrained, non-autoregressive\ngenerative LLMs, such as Diffusion LLMs, which model the joint distribution\nover prompt-response pairs, can serve as powerful surrogates for prompt search.\nThis approach enables the direct conditional generation of prompts, effectively\nreplacing costly, per-instance discrete optimization with a small number of\nparallelizable samples. We provide a probabilistic analysis demonstrating that\nunder mild fidelity assumptions, only a few conditional samples are required to\nrecover high-reward (harmful) prompts. Empirically, we find that the generated\nprompts are low-perplexity, diverse jailbreaks that exhibit strong\ntransferability to a wide range of black-box target models, including robustly\ntrained and proprietary LLMs. Beyond adversarial prompting, our framework opens\nnew directions for red teaming, automated prompt optimization, and leveraging\nemerging Flow- and Diffusion-based LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u5bf9\u6297\u6027\u63d0\u793a\u4f18\u5316\u8f6c\u5316\u4e3a\u9ad8\u6548\u644a\u9500\u63a8\u7406\u4efb\u52a1\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210LLM\u76f4\u63a5\u6761\u4ef6\u751f\u6210\u63d0\u793a\uff0c\u66ff\u4ee3\u6602\u8d35\u7684\u79bb\u6563\u4f18\u5316", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5bf9\u6297\u6027\u63d0\u793a\u4f18\u5316\u8d44\u6e90\u5bc6\u96c6\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u644a\u9500\u63a8\u7406\u63d0\u9ad8\u6548\u7387", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210LLM\uff08\u5982Diffusion LLMs\uff09\u4f5c\u4e3a\u63d0\u793a\u641c\u7d22\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u76f4\u63a5\u6761\u4ef6\u751f\u6210\u63d0\u793a\uff0c\u5c06\u79bb\u6563\u4f18\u5316\u8f6c\u5316\u4e3a\u5c11\u91cf\u5e76\u884c\u6837\u672c\u751f\u6210", "result": "\u751f\u6210\u7684\u63d0\u793a\u5177\u6709\u4f4e\u56f0\u60d1\u5ea6\u3001\u591a\u6837\u6027\uff0c\u80fd\u6709\u6548\u653b\u51fb\u591a\u79cd\u9ed1\u76d2\u76ee\u6807\u6a21\u578b\uff0c\u5305\u62ec\u9c81\u68d2\u8bad\u7ec3\u548c\u4e13\u6709LLM", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ea2\u961f\u6d4b\u8bd5\u3001\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u548c\u57fa\u4e8eFlow/Diffusion\u7684LLM\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411"}}
{"id": "2511.01741", "categories": ["cs.LG", "cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01741", "abs": "https://arxiv.org/abs/2511.01741", "authors": ["Ameya S. Bhave", "Navnil Choudhury", "Kanad Basu"], "title": "HyperNQ: A Hypergraph Neural Network Decoder for Quantum LDPC Codes", "comment": "6 pages, 4 figures, Submitted to the IEEE International Conference on\n  Communications (ICC 2026). Preprint version", "summary": "Quantum computing requires effective error correction strategies to mitigate\nnoise and decoherence. Quantum Low-Density Parity-Check (QLDPC) codes have\nemerged as a promising solution for scalable Quantum Error Correction (QEC)\napplications by supporting constant-rate encoding and a sparse parity-check\nstructure. However, decoding QLDPC codes via traditional approaches such as\nBelief Propagation (BP) suffers from poor convergence in the presence of short\ncycles. Machine learning techniques like Graph Neural Networks (GNNs) utilize\nlearned message passing over their node features; however, they are restricted\nto pairwise interactions on Tanner graphs, which limits their ability to\ncapture higher-order correlations. In this work, we propose HyperNQ, the first\nHypergraph Neural Network (HGNN)- based QLDPC decoder that captures\nhigher-order stabilizer constraints by utilizing hyperedges-thus enabling\nhighly expressive and compact decoding. We use a two-stage message passing\nscheme and evaluate the decoder over the pseudo-threshold region. Below the\npseudo-threshold mark, HyperNQ improves the Logical Error Rate (LER) up to 84%\nover BP and 50% over GNN-based strategies, demonstrating enhanced performance\nover the existing state-of-the-art decoders.", "AI": {"tldr": "\u63d0\u51fa\u4e86HyperNQ\uff0c\u9996\u4e2a\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684QLDPC\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u5229\u7528\u8d85\u8fb9\u6355\u6349\u9ad8\u9636\u7a33\u5b9a\u5b50\u7ea6\u675f\uff0c\u5728\u4f2a\u9608\u503c\u533a\u57df\u4e0b\u6bd4BP\u548cGNN\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u903b\u8f91\u9519\u8bef\u7387\u3002", "motivation": "\u4f20\u7edfBP\u89e3\u7801\u5728\u77ed\u73af\u5b58\u5728\u65f6\u6536\u655b\u6027\u5dee\uff0c\u800cGNN\u65b9\u6cd5\u53d7\u9650\u4e8eTanner\u56fe\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u65e0\u6cd5\u6355\u6349\u9ad8\u9636\u76f8\u5173\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u7801\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5229\u7528\u8d85\u8fb9\u6355\u6349\u9ad8\u9636\u7a33\u5b9a\u5b50\u7ea6\u675f\uff0c\u5b9e\u73b0\u9ad8\u5ea6\u8868\u8fbe\u6027\u548c\u7d27\u51d1\u7684\u89e3\u7801\u3002", "result": "\u5728\u4f2a\u9608\u503c\u6807\u8bb0\u4ee5\u4e0b\uff0cHyperNQ\u6bd4BP\u63d0\u5347\u903b\u8f91\u9519\u8bef\u7387\u9ad8\u8fbe84%\uff0c\u6bd4GNN\u7b56\u7565\u63d0\u534750%\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u89e3\u7801\u5668\u3002", "conclusion": "HyperNQ\u901a\u8fc7\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u6709\u6548\u6355\u6349\u9ad8\u9636\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86QLDPC\u7801\u7684\u89e3\u7801\u6027\u80fd\uff0c\u4e3a\u91cf\u5b50\u7ea0\u9519\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00209", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.00209", "abs": "https://arxiv.org/abs/2511.00209", "authors": ["Yiquan Wang", "Yahui Ma", "Yuhan Chang", "Jiayao Yan", "Jialin Zhang", "Minnuo Cai", "Kai Wei"], "title": "Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides", "comment": "21 pages, 3 figures", "summary": "Diffusion models have emerged as a leading framework in generative modeling,\nshowing significant potential to accelerate and transform the traditionally\nslow and costly process of drug discovery. This review provides a systematic\ncomparison of their application in designing two principal therapeutic\nmodalities: small molecules and therapeutic peptides. We analyze how a unified\nframework of iterative denoising is adapted to the distinct molecular\nrepresentations, chemical spaces, and design objectives of each modality. For\nsmall molecules, these models excel at structure-based design, generating\nnovel, pocket-fitting ligands with desired physicochemical properties, yet face\nthe critical hurdle of ensuring chemical synthesizability. Conversely, for\ntherapeutic peptides, the focus shifts to generating functional sequences and\ndesigning de novo structures, where the primary challenges are achieving\nbiological stability against proteolysis, ensuring proper folding, and\nminimizing immunogenicity. Despite these distinct challenges, both domains face\nshared hurdles: the need for more accurate scoring functions, the scarcity of\nhigh-quality experimental data, and the crucial requirement for experimental\nvalidation. We conclude that the full potential of diffusion models will be\nunlocked by bridging these modality-specific gaps and integrating them into\nautomated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby\nshifting the paradigm from chemical exploration to the targeted creation of\nnovel therapeutics.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7cfb\u7edf\u6bd4\u8f83\u4e86\u6269\u6563\u6a21\u578b\u5728\u5c0f\u5206\u5b50\u548c\u80bd\u7c7b\u6cbb\u7597\u836f\u7269\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u7edf\u4e00\u53bb\u566a\u6846\u67b6\u5982\u4f55\u9002\u5e94\u4e0d\u540c\u5206\u5b50\u8868\u5f81\u3001\u5316\u5b66\u7a7a\u95f4\u548c\u8bbe\u8ba1\u76ee\u6807\uff0c\u5e76\u8ba8\u8bba\u4e86\u5404\u81ea\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u6709\u671b\u52a0\u901f\u548c\u6539\u53d8\u4f20\u7edf\u7f13\u6162\u4e14\u6602\u8d35\u7684\u836f\u7269\u53d1\u73b0\u8fc7\u7a0b\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6bd4\u8f83\u8be5\u6846\u67b6\u5728\u4e24\u79cd\u4e3b\u8981\u6cbb\u7597\u6a21\u5f0f\uff08\u5c0f\u5206\u5b50\u548c\u80bd\u7c7b\uff09\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6bd4\u8f83\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u6790\u6269\u6563\u6a21\u578b\u7684\u8fed\u4ee3\u53bb\u566a\u7edf\u4e00\u6846\u67b6\u5982\u4f55\u9002\u5e94\u4e0d\u540c\u5206\u5b50\u8868\u5f81\u3001\u5316\u5b66\u7a7a\u95f4\u548c\u8bbe\u8ba1\u76ee\u6807\uff0c\u91cd\u70b9\u5173\u6ce8\u7ed3\u6784\u57fa\u7840\u8bbe\u8ba1\u3001\u529f\u80fd\u5e8f\u5217\u751f\u6210\u548c\u4ece\u5934\u7ed3\u6784\u8bbe\u8ba1\u7b49\u5e94\u7528\u3002", "result": "\u5bf9\u4e8e\u5c0f\u5206\u5b50\uff0c\u6269\u6563\u6a21\u578b\u5728\u7ed3\u6784\u57fa\u7840\u8bbe\u8ba1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u751f\u6210\u65b0\u9896\u7684\u3001\u9002\u5408\u53e3\u888b\u7684\u914d\u4f53\u5e76\u5177\u5907\u6240\u9700\u7406\u5316\u6027\u8d28\uff0c\u4f46\u9762\u4e34\u786e\u4fdd\u5316\u5b66\u53ef\u5408\u6210\u6027\u7684\u5173\u952e\u969c\u788d\u3002\u5bf9\u4e8e\u80bd\u7c7b\uff0c\u91cd\u70b9\u8f6c\u5411\u751f\u6210\u529f\u80fd\u5e8f\u5217\u548c\u8bbe\u8ba1\u4ece\u5934\u7ed3\u6784\uff0c\u4e3b\u8981\u6311\u6218\u662f\u5b9e\u73b0\u5bf9\u86cb\u767d\u6c34\u89e3\u7684\u751f\u7269\u7a33\u5b9a\u6027\u3001\u786e\u4fdd\u6b63\u786e\u6298\u53e0\u548c\u6700\u5c0f\u5316\u514d\u75ab\u539f\u6027\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u7684\u5168\u90e8\u6f5c\u529b\u5c06\u901a\u8fc7\u5f25\u5408\u8fd9\u4e9b\u6a21\u5f0f\u7279\u5b9a\u5dee\u8ddd\u5e76\u5c06\u5176\u6574\u5408\u5230\u81ea\u52a8\u5316\u7684\u95ed\u73af\u8bbe\u8ba1-\u6784\u5efa-\u6d4b\u8bd5-\u5b66\u4e60\u5e73\u53f0\u4e2d\u6765\u91ca\u653e\uff0c\u4ece\u800c\u5c06\u8303\u5f0f\u4ece\u5316\u5b66\u63a2\u7d22\u8f6c\u5411\u9776\u5411\u521b\u9020\u65b0\u578b\u6cbb\u7597\u836f\u7269\u3002"}}
{"id": "2511.00220", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00220", "abs": "https://arxiv.org/abs/2511.00220", "authors": ["Pouya M. Ghari", "Simone Sciabola", "Ye Wang"], "title": "Iterative Foundation Model Fine-Tuning on Multiple Rewards", "comment": "Accepted to NeurIPS 2025", "summary": "Fine-tuning foundation models has emerged as a powerful approach for\ngenerating objects with specific desired properties. Reinforcement learning\n(RL) provides an effective framework for this purpose, enabling models to\ngenerate outputs that maximize a given reward function. However, in many\napplications such as text generation and drug discovery, it can be suboptimal\nto optimize using a single reward signal, as multiple evaluation criteria are\noften necessary. This paper proposes a novel reinforcement learning-based\nmethod for fine-tuning foundation models using multiple reward signals. By\nemploying an iterative fine-tuning strategy across these rewards, our approach\ngeneralizes state-of-the-art RL-based methods. We further provide a theoretical\nanalysis that offers insights into the performance of multi-reward RL\nfine-tuning. Experimental results across diverse domains including text,\nbiological sequence, and small molecule generation, demonstrate the\neffectiveness of the proposed algorithm compared to state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u5956\u52b1\u4fe1\u53f7\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u5fae\u8c03\u7b56\u7565\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u5982\u6587\u672c\u751f\u6210\u548c\u836f\u7269\u53d1\u73b0\u4e2d\uff0c\u5355\u4e00\u5956\u52b1\u4fe1\u53f7\u4f18\u5316\u53ef\u80fd\u4e0d\u591f\u7406\u60f3\uff0c\u9700\u8981\u591a\u4e2a\u8bc4\u4f30\u6807\u51c6", "method": "\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u5956\u52b1\u4fe1\u53f7\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528\u8fed\u4ee3\u5fae\u8c03\u7b56\u7565\u5904\u7406\u591a\u4e2a\u5956\u52b1", "result": "\u5728\u6587\u672c\u3001\u751f\u7269\u5e8f\u5217\u548c\u5c0f\u5206\u5b50\u751f\u6210\u7b49\u591a\u4e2a\u9886\u57df\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf", "conclusion": "\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u57fa\u7840\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u652f\u6301"}}
{"id": "2511.00246", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00246", "abs": "https://arxiv.org/abs/2511.00246", "authors": ["Wadduwage Shanika Perera", "ABM Islam", "Van Vung Pham", "Min Kyung An"], "title": "Melanoma Classification Through Deep Ensemble Learning and Explainable AI", "comment": "Publisher-formatted version provided under CC BY-NC-ND 4.0 license.\n  Original source produced by SciTePress", "summary": "Melanoma is one of the most aggressive and deadliest skin cancers, leading to\nmortality if not detected and treated in the early stages. Artificial\nintelligence techniques have recently been developed to help dermatologists in\nthe early detection of melanoma, and systems based on deep learning (DL) have\nbeen able to detect these lesions with high accuracy. However, the entire\ncommunity must overcome the explainability limit to get the maximum benefit\nfrom DL for diagnostics in the healthcare domain. Because of the black box\noperation's shortcomings in DL models' decisions, there is a lack of\nreliability and trust in the outcomes. However, Explainable Artificial\nIntelligence (XAI) can solve this problem by interpreting the predictions of AI\nsystems. This paper proposes a machine learning model using ensemble learning\nof three state-of-the-art deep transfer Learning networks, along with an\napproach to ensure the reliability of the predictions by utilizing XAI\ntechniques to explain the basis of the predictions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u9ed1\u8272\u7d20\u7624\u65e9\u671f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u9ed1\u8272\u7d20\u7624\u68c0\u6d4b\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\u7f51\u7edc\u8fdb\u884c\u96c6\u6210\u5b66\u4e60\uff0c\u5e76\u5e94\u7528XAI\u6280\u672f\u6765\u89e3\u91ca\u9884\u6d4b\u4f9d\u636e\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u9ed1\u8272\u7d20\u7624\u4e14\u5177\u6709\u53ef\u89e3\u91ca\u6027\u7684\u7cfb\u7edf\u3002", "conclusion": "XAI\u6280\u672f\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u9ed1\u76d2\u95ee\u9898\uff0c\u63d0\u9ad8\u9884\u6d4b\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u4fe1\u4efb\u5ea6\u3002"}}
{"id": "2511.00257", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00257", "abs": "https://arxiv.org/abs/2511.00257", "authors": ["Zachary Chase", "Shinji Ito", "Idan Mehalel"], "title": "A Tight Lower Bound for Non-stochastic Multi-armed Bandits with Expert Advice", "comment": null, "summary": "We determine the minimax optimal expected regret in the classic\nnon-stochastic multi-armed bandit with expert advice problem, by proving a\nlower bound that matches the upper bound of Kale (2014). The two bounds\ndetermine the minimax optimal expected regret to be $\\Theta\\left( \\sqrt{T K\n\\log (N/K) } \\right)$, where $K$ is the number of arms, $N$ is the number of\nexperts, and $T$ is the time horizon.", "AI": {"tldr": "\u672c\u6587\u786e\u5b9a\u4e86\u975e\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4e13\u5bb6\u5efa\u8bae\u95ee\u9898\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u671f\u671b\u9057\u61be\uff0c\u901a\u8fc7\u8bc1\u660e\u4e0eKale(2014)\u4e0a\u754c\u5339\u914d\u7684\u4e0b\u754c\uff0c\u5f97\u51fa\u6700\u4f18\u9057\u61be\u4e3a\u0398(\u221a(TKlog(N/K)))\u3002", "motivation": "\u89e3\u51b3\u975e\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4e13\u5bb6\u5efa\u8bae\u95ee\u9898\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u671f\u671b\u9057\u61be\u7684\u7cbe\u786e\u786e\u5b9a\u95ee\u9898\uff0c\u586b\u8865\u73b0\u6709\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u4e0e\u5df2\u6709\u4e0a\u754c\u5339\u914d\u7684\u4e0b\u754c\u6765\u786e\u5b9a\u6781\u5c0f\u6781\u5927\u6700\u4f18\u671f\u671b\u9057\u61be\uff0c\u5176\u4e2dK\u4e3a\u81c2\u6570\uff0cN\u4e3a\u4e13\u5bb6\u6570\uff0cT\u4e3a\u65f6\u95f4\u8303\u56f4\u3002", "result": "\u786e\u5b9a\u4e86\u6781\u5c0f\u6781\u5927\u6700\u4f18\u671f\u671b\u9057\u61be\u4e3a\u0398(\u221a(TKlog(N/K)))\uff0c\u5176\u4e2d\u4e0b\u754c\u4e0eKale(2014)\u7684\u4e0a\u754c\u5b8c\u5168\u5339\u914d\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b8c\u6574\u523b\u753b\u4e86\u975e\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4e13\u5bb6\u5efa\u8bae\u95ee\u9898\u7684\u7406\u8bba\u6781\u9650\uff0c\u4e3a\u76f8\u5173\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2511.00266", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00266", "abs": "https://arxiv.org/abs/2511.00266", "authors": ["Aanchal Rajesh Chugh", "Marion Neumeier", "Sebastian Dorn"], "title": "X-TRACK: Physics-Aware xLSTM for Realistic Vehicle Trajectory Prediction", "comment": null, "summary": "Recent advancements in Recurrent Neural Network (RNN) architectures,\nparticularly the Extended Long Short Term Memory (xLSTM), have addressed the\nlimitations of traditional Long Short Term Memory (LSTM) networks by\nintroducing exponential gating and enhanced memory structures. These\nimprovements make xLSTM suitable for time-series prediction tasks as they\nexhibit the ability to model long-term temporal dependencies better than LSTMs.\nDespite their potential, these xLSTM-based models remain largely unexplored in\nthe context of vehicle trajectory prediction. Therefore, this paper introduces\na novel xLSTM-based vehicle trajectory prediction framework, X-TRAJ, and its\nphysics-aware variant, X-TRACK (eXtended LSTM for TRAjectory prediction\nConstraint by Kinematics), which explicitly integrates vehicle motion\nkinematics into the model learning process. By introducing physical\nconstraints, the proposed model generates realistic and feasible trajectories.\nA comprehensive evaluation on the highD and NGSIM datasets demonstrates that\nX-TRACK outperforms state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8exLSTM\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6X-TRAJ\u53ca\u5176\u7269\u7406\u611f\u77e5\u53d8\u4f53X-TRACK\uff0c\u901a\u8fc7\u6574\u5408\u8f66\u8f86\u8fd0\u52a8\u5b66\u7ea6\u675f\u6765\u751f\u6210\u66f4\u771f\u5b9e\u53ef\u884c\u7684\u8f68\u8ff9\u3002", "motivation": "\u867d\u7136xLSTM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u4f20\u7edfLSTM\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800cxLSTM\u901a\u8fc7\u6307\u6570\u95e8\u63a7\u548c\u589e\u5f3a\u5185\u5b58\u7ed3\u6784\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86X-TRAJ\u6846\u67b6\u53ca\u5176\u7269\u7406\u611f\u77e5\u53d8\u4f53X-TRACK\uff0c\u540e\u8005\u5728\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u6574\u5408\u8f66\u8f86\u8fd0\u52a8\u5b66\u7ea6\u675f\uff0c\u786e\u4fdd\u751f\u6210\u7684\u8f68\u8ff9\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u3002", "result": "\u5728highD\u548cNGSIM\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cX-TRACK\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "xLSTM\u67b6\u6784\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u80fd\u591f\u6709\u6548\u63d0\u5347\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u884c\u6027\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8f68\u8ff9\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00272", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.00272", "abs": "https://arxiv.org/abs/2511.00272", "authors": ["Michiel Straat", "Thorben Markmann", "Sebastian Peitz", "Barbara Hammer"], "title": "Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning", "comment": null, "summary": "Chaotic convective flows arise in many real-world systems, such as\nmicrofluidic devices and chemical reactors. Stabilizing these flows is highly\ndesirable but remains challenging, particularly in chaotic regimes where\nconventional control methods often fail. Reinforcement Learning (RL) has shown\npromise for control in laminar flow settings, but its ability to generalize and\nremain robust under chaotic and turbulent dynamics is not well explored,\ndespite being critical for real-world deployment. In this work, we improve the\npractical feasibility of RL-based control of such flows focusing on\nRayleigh-B\\'enard Convection (RBC), a canonical model for convective heat\ntransport. To enhance generalization and sample efficiency, we introduce\ndomain-informed RL agents that are trained using Proximal Policy Optimization\nacross diverse initial conditions and flow regimes. We incorporate domain\nknowledge in the reward function via a term that encourages B\\'enard cell\nmerging, as an example of a desirable macroscopic property. In laminar flow\nregimes, the domain-informed RL agents reduce convective heat transport by up\nto 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which\nis significantly better than the conventional controllers used in practice. We\ncompare the domain-informed to uninformed agents: Our results show that the\ndomain-informed reward design results in steady flows, faster convergence\nduring training, and generalization across flow regimes without retraining. Our\nwork demonstrates that elegant domain-informed priors can greatly enhance the\nrobustness of RL-based control of chaotic flows, bringing real-world deployment\ncloser.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a7\u5236\u6df7\u6c8c\u5bf9\u6d41\u6d41\u52a8\uff0c\u5728Rayleigh-B\u00e9nard\u5bf9\u6d41\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u70ed\u4f20\u8f93\u7684\u663e\u8457\u51cf\u5c11\uff0c\u5e76\u5c55\u793a\u4e86\u8de8\u6d41\u6001\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6df7\u6c8c\u5bf9\u6d41\u6d41\u52a8\u5728\u5fae\u6d41\u4f53\u8bbe\u5907\u548c\u5316\u5b66\u53cd\u5e94\u5668\u7b49\u5b9e\u9645\u7cfb\u7edf\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u6df7\u6c8c\u72b6\u6001\u4e0b\u5f80\u5f80\u5931\u6548\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u5728\u5c42\u6d41\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u6df7\u6c8c\u548c\u6e4d\u6d41\u52a8\u529b\u5b66\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u9886\u57df\u77e5\u8bc6\u589e\u5f3a\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u548c\u6d41\u6001\u4e0b\u8fdb\u884c\u8bad\u7ec3\u3002\u5728\u5956\u52b1\u51fd\u6570\u4e2d\u878d\u5165\u9886\u57df\u77e5\u8bc6\uff0c\u901a\u8fc7\u9f13\u52b1B\u00e9nard\u5355\u5143\u5408\u5e76\u6765\u5f15\u5bfc\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5728\u5c42\u6d41\u72b6\u6001\u4e0b\uff0c\u9886\u57df\u77e5\u8bc6\u589e\u5f3a\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5c06\u70ed\u4f20\u8f93\u51cf\u5c11\u4e8633%\uff1b\u5728\u6df7\u6c8c\u6d41\u6001\u4e0b\u4ecd\u5b9e\u73b0\u4e8610%\u7684\u51cf\u5c11\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u63a7\u5236\u5668\u3002\u4e0e\u65e0\u9886\u57df\u77e5\u8bc6\u7684\u4ee3\u7406\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u7a33\u5b9a\u6d41\u52a8\u3001\u8bad\u7ec3\u6536\u655b\u66f4\u5feb\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u8de8\u6d41\u6001\u6cdb\u5316\u3002", "conclusion": "\u4f18\u96c5\u7684\u9886\u57df\u77e5\u8bc6\u5148\u9a8c\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u6df7\u6c8c\u6d41\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u73b0\u5b9e\u9645\u90e8\u7f72\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.00280", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00280", "abs": "https://arxiv.org/abs/2511.00280", "authors": ["Abhinav Joshi", "Areeb Ahmad", "Ashutosh Modi"], "title": "Calibration Across Layers: Understanding Calibration Evolution in LLMs", "comment": "Accepted at EMNLP 2025 (main)", "summary": "Large Language Models (LLMs) have demonstrated inherent calibration\ncapabilities, where predicted probabilities align well with correctness,\ndespite prior findings that deep neural networks are often overconfident.\nRecent studies have linked this behavior to specific components in the final\nlayer, such as entropy neurons and the unembedding matrix null space. In this\nwork, we provide a complementary perspective by investigating how calibration\nevolves throughout the network depth. Analyzing multiple open-weight models on\nthe MMLU benchmark, we uncover a distinct confidence correction phase in the\nupper/later layers, where model confidence is actively recalibrated after\ndecision certainty has been reached. Furthermore, we identify a low-dimensional\ncalibration direction in the residual stream whose perturbation significantly\nimproves calibration metrics (ECE and MCE) without harming accuracy. Our\nfindings suggest that calibration is a distributed phenomenon, shaped\nthroughout the network forward pass, not just in its final projection,\nproviding new insights into how confidence-regulating mechanisms operate within\nLLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u7684\u6821\u51c6\u80fd\u529b\u5728\u7f51\u7edc\u6df1\u5ea6\u4e2d\u6f14\u5316\uff0c\u4e0a\u5c42\u5b58\u5728\u7f6e\u4fe1\u5ea6\u6821\u6b63\u9636\u6bb5\uff0c\u5e76\u8bc6\u522b\u51fa\u6b8b\u5dee\u6d41\u4e2d\u7684\u4f4e\u7ef4\u6821\u51c6\u65b9\u5411\uff0c\u6270\u52a8\u8be5\u65b9\u5411\u53ef\u663e\u8457\u6539\u5584\u6821\u51c6\u6307\u6807\u800c\u4e0d\u635f\u5bb3\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7814\u7a76\u53d1\u73b0\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u4f46LLMs\u8868\u73b0\u51fa\u5185\u5728\u7684\u6821\u51c6\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u4ece\u7f51\u7edc\u6df1\u5ea6\u6f14\u5316\u7684\u89d2\u5ea6\u8865\u5145\u7406\u89e3LLMs\u7684\u6821\u51c6\u673a\u5236\u3002", "method": "\u5206\u6790\u591a\u4e2a\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u5728MMLU\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u7814\u7a76\u6821\u51c6\u5982\u4f55\u968f\u7f51\u7edc\u6df1\u5ea6\u6f14\u5316\uff0c\u8bc6\u522b\u4e0a\u5c42\u5c42\u7684\u7f6e\u4fe1\u5ea6\u6821\u6b63\u9636\u6bb5\u548c\u6b8b\u5dee\u6d41\u4e2d\u7684\u4f4e\u7ef4\u6821\u51c6\u65b9\u5411\u3002", "result": "\u53d1\u73b0\u4e0a\u5c42\u5b58\u5728\u4e3b\u52a8\u91cd\u65b0\u6821\u51c6\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u9636\u6bb5\uff0c\u8bc6\u522b\u51fa\u6b8b\u5dee\u6d41\u4e2d\u7684\u4f4e\u7ef4\u6821\u51c6\u65b9\u5411\uff0c\u6270\u52a8\u8be5\u65b9\u5411\u53ef\u663e\u8457\u6539\u5584ECE\u548cMCE\u7b49\u6821\u51c6\u6307\u6807\u800c\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "conclusion": "\u6821\u51c6\u662f\u5206\u5e03\u5f0f\u73b0\u8c61\uff0c\u5728\u6574\u4e2a\u7f51\u7edc\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u5f62\u6210\uff0c\u800c\u4e0d\u4ec5\u9650\u4e8e\u6700\u7ec8\u6295\u5f71\u5c42\uff0c\u8fd9\u4e3a\u7406\u89e3LLMs\u5185\u90e8\u7684\u7f6e\u4fe1\u5ea6\u8c03\u8282\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.00301", "categories": ["cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.00301", "abs": "https://arxiv.org/abs/2511.00301", "authors": ["Ciaran Bench", "Oskar Pfeffer", "Vivek Desai", "Mohammad Moulaeifard", "Lo\u00efc Coquelin", "Peter H. Charlton", "Nils Strodthoff", "Nando Hegemann", "Philip J. Aston", "Andrew Thompson"], "title": "A systematic evaluation of uncertainty quantification techniques in deep learning: a case study in photoplethysmography signal analysis", "comment": null, "summary": "In principle, deep learning models trained on medical time-series, including\nwearable photoplethysmography (PPG) sensor data, can provide a means to\ncontinuously monitor physiological parameters outside of clinical settings.\nHowever, there is considerable risk of poor performance when deployed in\npractical measurement scenarios leading to negative patient outcomes. Reliable\nuncertainties accompanying predictions can provide guidance to clinicians in\ntheir interpretation of the trustworthiness of model outputs. It is therefore\nof interest to compare the effectiveness of different approaches. Here we\nimplement an unprecedented set of eight uncertainty quantification (UQ)\ntechniques to models trained on two clinically relevant prediction tasks:\nAtrial Fibrillation (AF) detection (classification), and two variants of blood\npressure regression. We formulate a comprehensive evaluation procedure to\nenable a rigorous comparison of these approaches. We observe a complex picture\nof uncertainty reliability across the different techniques, where the most\noptimal for a given task depends on the chosen expression of uncertainty,\nevaluation metric, and scale of reliability assessed. We find that assessing\nlocal calibration and adaptivity provides practically relevant insights about\nmodel behaviour that otherwise cannot be acquired using more commonly\nimplemented global reliability metrics. We emphasise that criteria for\nevaluating UQ techniques should cater to the model's practical use case, where\nthe use of a small number of measurements per patient places a premium on\nachieving small-scale reliability for the chosen expression of uncertainty,\nwhile preserving as much predictive performance as possible.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e868\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\u5728\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff08\u7279\u522b\u662fPPG\u4f20\u611f\u5668\u6570\u636e\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u5fc3\u623f\u98a4\u52a8\u68c0\u6d4b\u548c\u8840\u538b\u56de\u5f52\u4efb\u52a1\uff0c\u5f3a\u8c03\u9700\u8981\u6839\u636e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u5e94\u7528\u5b58\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u6027\u80fd\u4e0d\u4f73\u7684\u98ce\u9669\uff0c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u53ef\u4ee5\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u6a21\u578b\u8f93\u51fa\u53ef\u4fe1\u5ea6\u7684\u6307\u5bfc\uff0c\u56e0\u6b64\u9700\u8981\u6bd4\u8f83\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u5b9e\u73b0\u4e868\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\uff0c\u5e94\u7528\u4e8e\u4e24\u4e2a\u4e34\u5e8a\u76f8\u5173\u9884\u6d4b\u4efb\u52a1\uff1a\u5fc3\u623f\u98a4\u52a8\u68c0\u6d4b\uff08\u5206\u7c7b\uff09\u548c\u4e24\u79cd\u8840\u538b\u56de\u5f52\u53d8\u4f53\uff0c\u5e76\u5236\u5b9a\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u7a0b\u5e8f\u6765\u4e25\u683c\u6bd4\u8f83\u8fd9\u4e9b\u65b9\u6cd5\u3002", "result": "\u4e0d\u540c\u6280\u672f\u7684\u4e0d\u786e\u5b9a\u6027\u53ef\u9760\u6027\u5448\u73b0\u590d\u6742\u56fe\u666f\uff0c\u6700\u4f18\u65b9\u6cd5\u53d6\u51b3\u4e8e\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u65b9\u5f0f\u3001\u8bc4\u4f30\u6307\u6807\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u5c3a\u5ea6\u3002\u5c40\u90e8\u6821\u51c6\u548c\u9002\u5e94\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u9645\u76f8\u5173\u7684\u6a21\u578b\u884c\u4e3a\u6d1e\u5bdf\u3002", "conclusion": "\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\u7684\u6807\u51c6\u5e94\u9002\u5e94\u6a21\u578b\u7684\u5b9e\u9645\u4f7f\u7528\u573a\u666f\uff0c\u5728\u6bcf\u4f4d\u60a3\u8005\u6570\u636e\u91cf\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u5e94\u4f18\u5148\u5b9e\u73b0\u5c0f\u5c3a\u5ea6\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5c3d\u53ef\u80fd\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.00318", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00318", "abs": "https://arxiv.org/abs/2511.00318", "authors": ["Dana Kim", "Yichen Xu", "Tiffany Lin"], "title": "A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data", "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) offer a flexible means to generate synthetic\ntabular data, yet existing approaches often fail to preserve key causal\nparameters such as the average treatment effect (ATE). In this technical\nexploration, we first demonstrate that state-of-the-art synthetic data\ngenerators, both GAN- and LLM-based, can achieve high predictive fidelity while\nsubstantially misestimating causal effects. To address this gap, we propose a\nhybrid generation framework that combines model-based covariate synthesis\n(monitored via distance-to-closest-record filtering) with separately learned\npropensity and outcome models, thereby ensuring that (W, A, Y) triplets retain\ntheir underlying causal structure. We further introduce a synthetic pairing\nstrategy to mitigate positivity violations and a realistic evaluation protocol\nthat leverages unlimited synthetic samples to benchmark traditional estimators\n(IPTW, AIPW, substitution) under complex covariate distributions. This work\nlays the groundwork for LLM-powered data pipelines that support robust causal\nanalysis. Our code is available at\nhttps://github.com/Xyc-arch/llm-synthetic-for-causal-inference.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u534f\u53d8\u91cf\u5408\u6210\u548c\u56e0\u679c\u7ed3\u6784\u4fdd\u6301\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u4fdd\u7559\u56e0\u679c\u6548\u5e94\u7684\u5408\u6210\u8868\u683c\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94(ATE)\u65f6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u548cGAN\u65b9\u6cd5\u5728\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\u65f6\uff0c\u867d\u7136\u80fd\u8fbe\u5230\u8f83\u9ad8\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u4fdd\u6301\u5173\u952e\u7684\u56e0\u679c\u53c2\u6570\u5982\u5e73\u5747\u5904\u7406\u6548\u5e94(ATE)\uff0c\u9650\u5236\u4e86\u5176\u5728\u56e0\u679c\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u751f\u6210\u6846\u67b6\uff1a\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u7684\u534f\u53d8\u91cf\u5408\u6210\uff08\u901a\u8fc7\u8ddd\u79bb\u5230\u6700\u8fd1\u8bb0\u5f55\u8fc7\u6ee4\u76d1\u63a7\uff09\u3001\u5206\u522b\u5b66\u4e60\u7684\u503e\u5411\u8bc4\u5206\u548c\u7ed3\u679c\u6a21\u578b\uff0c\u786e\u4fdd(W, A, Y)\u4e09\u5143\u7ec4\u4fdd\u7559\u5e95\u5c42\u56e0\u679c\u7ed3\u6784\uff1b\u5f15\u5165\u5408\u6210\u914d\u5bf9\u7b56\u7565\u7f13\u89e3\u6b63\u6027\u8fdd\u4f8b\uff1b\u5229\u7528\u65e0\u9650\u5408\u6210\u6837\u672c\u5efa\u7acb\u590d\u6742\u534f\u53d8\u91cf\u5206\u5e03\u4e0b\u4f20\u7edf\u4f30\u8ba1\u5668(IPTW, AIPW, substitution)\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u4fdd\u7559\u56e0\u679c\u7ed3\u6784\u7684\u5408\u6210\u6570\u636e\uff0c\u4e3a\u652f\u6301\u7a33\u5065\u56e0\u679c\u5206\u6790\u7684LLM\u9a71\u52a8\u6570\u636e\u7ba1\u9053\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8eLLM\u7684\u6570\u636e\u7ba1\u9053\u652f\u6301\u7a33\u5065\u56e0\u679c\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4fdd\u7559\u56e0\u679c\u6548\u5e94\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2511.00351", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00351", "abs": "https://arxiv.org/abs/2511.00351", "authors": ["Amir Ziashahabi", "Yavuz Faruk Bakman", "Duygu Nur Yaldiz", "Mostafa El-Khamy", "Sai Praneeth Karimireddy", "Salman Avestimehr"], "title": "Reject Only Critical Tokens: Pivot-Aware Speculative Decoding", "comment": "Accepted at NeurIPS 2025 Efficient Reasoning Workshop", "summary": "Speculative Decoding (SD) ensures that the output matches the target model's\ndistribution exactly. However, we argue that this distribution matching\nrequirement is too stringent and results in unnecessarily low acceptance rates,\nlimiting potential speedups. Instead, we advocate a reformulation of the\ndecoding objective: the proposed decoding strategy should match the expected\nutility, i.e., the task-specific performance, of the target model. This\nperspective also aligns better with real-world use cases of LLMs, where utility\n(e.g., code correctness, factual accuracy) is often more important than\nsampling distribution. Based on this reformulation, we propose a novel decoding\nstrategy: Pivot-Aware Speculative Decoding, which rejects only those tokens\nthat would lead to a utility drop in the final output. We refer to these\ncritical tokens as pivot tokens. We propose a method for labeling tokens as\npivotal or non-pivotal and train a lightweight classifier to detect them. This\nmethod can be viewed as a relaxed version of standard SD, which offers much\nhigher acceptance while preserving utility. We evaluate our method across\nvarious datasets, demonstrating that we can achieve up to $2.5\\times$ speedup\nwith comparable utility. Source code is available at\nhttps://github.com/amir-zsh/PAD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\u2014\u2014Pivot-Aware Speculative Decoding\uff0c\u901a\u8fc7\u53ea\u62d2\u7edd\u4f1a\u5bfc\u81f4\u6700\u7ec8\u8f93\u51fa\u6548\u7528\u4e0b\u964d\u7684\u5173\u952etoken\uff08pivot tokens\uff09\u6765\u63d0\u5347\u63a5\u53d7\u7387\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe2.5\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u7684Speculative Decoding\u8981\u6c42\u8f93\u51fa\u5206\u5e03\u4e0e\u76ee\u6807\u6a21\u578b\u5b8c\u5168\u5339\u914d\uff0c\u8fd9\u5bfc\u81f4\u63a5\u53d7\u7387\u8fc7\u4f4e\uff0c\u9650\u5236\u4e86\u52a0\u901f\u6f5c\u529b\u3002\u4f5c\u8005\u8ba4\u4e3a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4efb\u52a1\u7279\u5b9a\u7684\u6027\u80fd\uff08\u5982\u4ee3\u7801\u6b63\u786e\u6027\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\uff09\u6bd4\u91c7\u6837\u5206\u5e03\u66f4\u91cd\u8981\u3002", "method": "\u63d0\u51faPivot-Aware Speculative Decoding\u7b56\u7565\uff0c\u8bc6\u522b\u5173\u952etoken\uff08pivot tokens\uff09\uff0c\u53ea\u62d2\u7edd\u90a3\u4e9b\u4f1a\u5bfc\u81f4\u6700\u7ec8\u8f93\u51fa\u6548\u7528\u4e0b\u964d\u7684token\u3002\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u6765\u68c0\u6d4b\u8fd9\u4e9b\u5173\u952etoken\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u9ad8\u8fbe2.5\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u76ee\u6807\u6a21\u578b\u76f8\u5f53\u7684\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u653e\u5bbd\u5206\u5e03\u5339\u914d\u8981\u6c42\uff0c\u4e13\u6ce8\u4e8e\u4efb\u52a1\u6548\u7528\u5339\u914d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u89e3\u7801\u6548\u7387\uff0c\u4e3a\u5b9e\u9645LLM\u5e94\u7528\u63d0\u4f9b\u66f4\u597d\u7684\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2511.00359", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00359", "abs": "https://arxiv.org/abs/2511.00359", "authors": ["Zhecheng Sheng", "Jiawei Zhang", "Enmao Diao"], "title": "Toward Unifying Group Fairness Evaluation from a Sparsity Perspective", "comment": "30 pages, 14 figures", "summary": "Ensuring algorithmic fairness remains a significant challenge in machine\nlearning, particularly as models are increasingly applied across diverse\ndomains. While numerous fairness criteria exist, they often lack\ngeneralizability across different machine learning problems. This paper\nexamines the connections and differences among various sparsity measures in\npromoting fairness and proposes a unified sparsity-based framework for\nevaluating algorithmic fairness. The framework aligns with existing fairness\ncriteria and demonstrates broad applicability to a wide range of machine\nlearning tasks. We demonstrate the effectiveness of the proposed framework as\nan evaluation metric through extensive experiments on a variety of datasets and\nbias mitigation methods. This work provides a novel perspective to algorithmic\nfairness by framing it through the lens of sparsity and social equity, offering\npotential for broader impact on fairness research and applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u7edf\u4e00\u6846\u67b6\u6765\u8bc4\u4f30\u7b97\u6cd5\u516c\u5e73\u6027\uff0c\u8be5\u6846\u67b6\u4e0e\u73b0\u6709\u516c\u5e73\u6027\u6807\u51c6\u4e00\u81f4\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u3002", "motivation": "\u7b97\u6cd5\u516c\u5e73\u6027\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6311\u6218\uff0c\u73b0\u6709\u516c\u5e73\u6027\u6807\u51c6\u7f3a\u4e4f\u8de8\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u6cdb\u5316\u6027\u3002", "method": "\u7814\u7a76\u5404\u79cd\u7a00\u758f\u6027\u5ea6\u91cf\u5728\u4fc3\u8fdb\u516c\u5e73\u6027\u65b9\u9762\u7684\u8054\u7cfb\u548c\u5dee\u5f02\uff0c\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u6846\u67b6\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u7a00\u758f\u6027\u548c\u793e\u4f1a\u516c\u5e73\u7684\u89c6\u89d2\u4e3a\u7b97\u6cd5\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5bf9\u516c\u5e73\u6027\u7814\u7a76\u548c\u5e94\u7528\u5177\u6709\u5e7f\u6cdb\u5f71\u54cd\u6f5c\u529b\u3002"}}
{"id": "2511.00369", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.00369", "abs": "https://arxiv.org/abs/2511.00369", "authors": ["Farjana Aktar", "Mohd Ruhul Ameen", "Akif Islam", "Md Ekramul Hamid"], "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet", "comment": "6 pages, 3 figures, 8 tables, Submitted to ICECTE 2026", "summary": "Achieving both accurate and interpretable classification of motor imagery EEG\nremains a key challenge in brain computer interface (BCI) research. This paper\ncompares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep\nlearning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS\npipeline combines filter bank common spatial pattern feature extraction with\nfuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet\nlearns hierarchical spatial temporal representations directly from raw EEG\ndata. In within-subject experiments, the fuzzy neural model performed better\n(68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43),\nwhile in cross-subject (LOSO) tests, the deep model exhibited stronger\ngeneralization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent\n+/- 16.22). The study provides practical guidance for selecting MI-BCI systems\naccording to design goals: interpretability or robustness across users. Future\ninvestigations into transformer based and hybrid neuro symbolic frameworks are\nexpected to advance transparent EEG decoding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u6a21\u7cca\u63a8\u7406\u65b9\u6cd5(ANFIS-FBCSP-PSO)\u4e0e\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6(EEGNet)\u5728\u8fd0\u52a8\u60f3\u8c61EEG\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u7cca\u65b9\u6cd5\u5728\u4e2a\u4f53\u5185\u6d4b\u8bd5\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u8de8\u4e2a\u4f53\u6d4b\u8bd5\u4e2d\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002", "motivation": "\u89e3\u51b3\u8fd0\u52a8\u60f3\u8c61EEG\u5206\u7c7b\u4e2d\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u96be\u4ee5\u517c\u987e\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3aBCI\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "method": "\u4f7f\u7528BCI Competition IV-2a\u6570\u636e\u96c6\uff0c\u6bd4\u8f83ANFIS-FBCSP-PSO\uff08\u7ed3\u5408\u6ee4\u6ce2\u5668\u7ec4\u5171\u540c\u7a7a\u95f4\u6a21\u5f0f\u7279\u5f81\u63d0\u53d6\u548c\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u6a21\u7ccaIF-THEN\u89c4\u5219\uff09\u4e0eEEGNet\uff08\u76f4\u63a5\u4ece\u539f\u59cbEEG\u6570\u636e\u5b66\u4e60\u5c42\u6b21\u65f6\u7a7a\u8868\u793a\uff09\u3002", "result": "\u4e2a\u4f53\u5185\u5b9e\u9a8c\uff1a\u6a21\u7cca\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff08\u51c6\u786e\u738768.58%\u00b113.76%\uff0ckappa=58.04%\u00b118.43\uff09\uff1b\u8de8\u4e2a\u4f53\u6d4b\u8bd5\uff1a\u6df1\u5ea6\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff08\u51c6\u786e\u738768.20%\u00b112.13%\uff0ckappa=57.33%\u00b116.22\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6839\u636e\u8bbe\u8ba1\u76ee\u6807\uff08\u53ef\u89e3\u91ca\u6027\u6216\u8de8\u7528\u6237\u9c81\u68d2\u6027\uff09\u9009\u62e9MI-BCI\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u672a\u6765\u57fa\u4e8eTransformer\u548c\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u7684\u7814\u7a76\u6709\u671b\u63a8\u8fdb\u900f\u660eEEG\u89e3\u7801\u3002"}}
{"id": "2511.00375", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00375", "abs": "https://arxiv.org/abs/2511.00375", "authors": ["Xin Wang", "Yunhao Xiao", "Rui Qiao"], "title": "PolyRecommender: A Multimodal Recommendation System for Polymer Discovery", "comment": null, "summary": "We introduce PolyRecommender, a multimodal discovery framework that\nintegrates chemical language representations from PolyBERT with molecular\ngraph-based representations from a graph encoder. The system first retrieves\ncandidate polymers using language-based similarity and then ranks them using\nfused multimodal embeddings according to multiple target properties. By\nleveraging the complementary knowledge encoded in both modalities,\nPolyRecommender enables efficient retrieval and robust ranking across related\npolymer properties. Our work establishes a generalizable multimodal paradigm,\nadvancing AI-guided design for the discovery of next-generation polymers.", "AI": {"tldr": "PolyRecommender\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u805a\u5408\u7269\u53d1\u73b0\u6846\u67b6\uff0c\u7ed3\u5408\u4e86PolyBERT\u7684\u5316\u5b66\u8bed\u8a00\u8868\u793a\u548c\u56fe\u7f16\u7801\u5668\u7684\u5206\u5b50\u56fe\u8868\u793a\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5d4c\u5165\u8fdb\u884c\u5019\u9009\u805a\u5408\u7269\u7684\u68c0\u7d22\u548c\u6392\u5e8f\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6574\u5408\u4e0d\u540c\u6a21\u6001\u4fe1\u606f\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u805a\u5408\u7269\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u7684\u68c0\u7d22\u6548\u7387\u548c\u6392\u5e8f\u9c81\u68d2\u6027\u3002", "method": "\u9996\u5148\u4f7f\u7528\u57fa\u4e8e\u8bed\u8a00\u7684\u76f8\u4f3c\u6027\u68c0\u7d22\u5019\u9009\u805a\u5408\u7269\uff0c\u7136\u540e\u4f7f\u7528\u878d\u5408\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6839\u636e\u591a\u4e2a\u76ee\u6807\u5c5e\u6027\u5bf9\u5019\u9009\u805a\u5408\u7269\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u901a\u8fc7\u5229\u7528\u4e24\u79cd\u6a21\u6001\u4e2d\u7f16\u7801\u7684\u4e92\u8865\u77e5\u8bc6\uff0cPolyRecommender\u5b9e\u73b0\u4e86\u8de8\u76f8\u5173\u805a\u5408\u7269\u5c5e\u6027\u7684\u9ad8\u6548\u68c0\u7d22\u548c\u9c81\u68d2\u6392\u5e8f\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u63a8\u5e7f\u7684\u591a\u6a21\u6001\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86AI\u5f15\u5bfc\u7684\u4e0b\u4e00\u4ee3\u805a\u5408\u7269\u53d1\u73b0\u8bbe\u8ba1\u3002"}}
{"id": "2511.00405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00405", "abs": "https://arxiv.org/abs/2511.00405", "authors": ["Zhibin Lan", "Liqiang Niu", "Fandong Meng", "Jie Zhou", "Jinsong Su"], "title": "UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings", "comment": null, "summary": "The remarkable success of multimodal large language models (MLLMs) has driven\nadvances in multimodal embeddings, yet existing models remain inherently\ndiscriminative, limiting their ability to benefit from reasoning-driven\ngeneration paradigm. In this work, we pioneer the exploration of generative\nembeddings, unifying embedding tasks within a generative paradigm. We propose\nUME-R1, a universal multimodal embedding framework consisting of a two-stage\ntraining strategy: a cold-start supervised fine-tuning equips the model with\nreasoning capabilities and enables it to generate both discriminative and\ngenerative embeddings; a subsequent reinforcement learning enhances reasoning\nand further optimizes generative embedding quality. This pioneering work\nreveals four key insights: 1) generative embeddings unlock substantial\nperformance gains over conventional discriminative embeddings by leveraging the\npowerful generative reasoning capabilities of MLLMs; 2) discriminative and\ngenerative embeddings are complementary, whose combined oracle performance far\nexceeding that of either alone; 3) RL can effectively enhance generative\nembeddings, establishing a scalable optimization paradigm.; 4) repeated\nsampling at inference boosts downstream task coverage (pass@k), highlighting\nthe inference-time scalability potential of generative embeddings. Evaluated on\nthe MMEB-V2 benchmark across 78 tasks spanning video, image, and visual\ndocuments, UME-R1 significantly outperforms conventional discriminative\nembedding models and offers a foundation for more interpretable,\nreasoning-driven generative multimodal embeddings. Our code, models, and\ndatasets will be publicly available at https://github.com/XMUDeepLIT/UME-R1.", "AI": {"tldr": "\u63d0\u51faUME-R1\u751f\u6210\u5f0f\u591a\u6a21\u6001\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u7edf\u4e00\u5d4c\u5165\u4efb\u52a1\u4e8e\u751f\u6210\u8303\u5f0f\uff0c\u663e\u8457\u8d85\u8d8a\u4f20\u7edf\u5224\u522b\u5f0f\u5d4c\u5165\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709MLLMs\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\u672c\u8d28\u4e0a\u662f\u5224\u522b\u5f0f\u7684\uff0c\u9650\u5236\u4e86\u5176\u4ece\u63a8\u7406\u9a71\u52a8\u7684\u751f\u6210\u8303\u5f0f\u4e2d\u83b7\u76ca\u7684\u80fd\u529b", "method": "\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u51b7\u542f\u52a8\u76d1\u7763\u5fae\u8c03\u8d4b\u4e88\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u751f\u6210\u5224\u522b\u5f0f\u548c\u751f\u6210\u5f0f\u5d4c\u5165\uff1b\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u63a8\u7406\u5e76\u4f18\u5316\u751f\u6210\u5f0f\u5d4c\u5165\u8d28\u91cf", "result": "\u5728MMEB-V2\u57fa\u51c6\u768478\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5224\u522b\u5f0f\u5d4c\u5165\u6a21\u578b\uff0c\u751f\u6210\u5f0f\u5d4c\u5165\u901a\u8fc7\u5229\u7528MLLMs\u7684\u5f3a\u5927\u751f\u6210\u63a8\u7406\u80fd\u529b\u5b9e\u73b0\u6027\u80fd\u5927\u5e45\u63d0\u5347", "conclusion": "\u751f\u6210\u5f0f\u5d4c\u5165\u4e3a\u66f4\u53ef\u89e3\u91ca\u3001\u63a8\u7406\u9a71\u52a8\u7684\u751f\u6210\u5f0f\u591a\u6a21\u6001\u5d4c\u5165\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u63a8\u7406\u65f6\u6269\u5c55\u6f5c\u529b"}}
{"id": "2511.00411", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00411", "abs": "https://arxiv.org/abs/2511.00411", "authors": ["Zenghao Niu", "Weicheng Xie", "Siyang Song", "Zitong Yu", "Feng Liu", "Linlin Shen"], "title": "Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling", "comment": "accepted by iccv 2025", "summary": "Adversarial attacks present a critical challenge to deep neural networks'\nrobustness, particularly in transfer scenarios across different model\narchitectures. However, the transferability of adversarial attacks faces a\nfundamental dilemma between Exploitation (maximizing attack potency) and\nExploration (enhancing cross-model generalization). Traditional momentum-based\nmethods over-prioritize Exploitation, i.e., higher loss maxima for attack\npotency but weakened generalization (narrow loss surface). Conversely, recent\nmethods with inner-iteration sampling over-prioritize Exploration, i.e.,\nflatter loss surfaces for cross-model generalization but weakened attack\npotency (suboptimal local maxima). To resolve this dilemma, we propose a simple\nyet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives\nthrough guiding sampling along the gradient ascent direction to improve both\nsampling efficiency and stability. Specifically, based on MI-FGSM, GGS\nintroduces inner-iteration random sampling and guides the sampling direction\nusing the gradient from the previous inner-iteration (the sampling's magnitude\nis determined by a random distribution). This mechanism encourages adversarial\nexamples to reside in balanced regions with both flatness for cross-model\ngeneralization and higher local maxima for strong attack potency. Comprehensive\nexperiments across multiple DNN architectures and multimodal large language\nmodels (MLLMs) demonstrate the superiority of our method over state-of-the-art\ntransfer attacks. Code is made available at https://github.com/anuin-cat/GGS.", "AI": {"tldr": "\u63d0\u51faGradient-Guided Sampling (GGS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u5f15\u5bfc\u91c7\u6837\u5e73\u8861\u5bf9\u6297\u653b\u51fb\u7684\u5229\u7528\u6027\uff08\u653b\u51fb\u5f3a\u5ea6\uff09\u548c\u63a2\u7d22\u6027\uff08\u8de8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff09\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8fd9\u4e24\u4e2a\u76ee\u6807\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5728\u8de8\u6a21\u578b\u67b6\u6784\u7684\u8fc1\u79fb\u573a\u666f\u4e2d\u9762\u4e34\u5229\u7528\u6027\uff08\u6700\u5927\u5316\u653b\u51fb\u5f3a\u5ea6\uff09\u548c\u63a2\u7d22\u6027\uff08\u589e\u5f3a\u8de8\u6a21\u578b\u6cdb\u5316\uff09\u4e4b\u95f4\u7684\u6839\u672c\u56f0\u5883\u3002\u4f20\u7edf\u52a8\u91cf\u65b9\u6cd5\u8fc7\u5ea6\u4f18\u5148\u5229\u7528\u6027\uff0c\u800c\u8fd1\u671f\u5185\u8fed\u4ee3\u91c7\u6837\u65b9\u6cd5\u8fc7\u5ea6\u4f18\u5148\u63a2\u7d22\u6027\u3002", "method": "\u57fa\u4e8eMI-FGSM\uff0cGGS\u5f15\u5165\u5185\u8fed\u4ee3\u968f\u673a\u91c7\u6837\uff0c\u5e76\u4f7f\u7528\u524d\u4e00\u6b21\u5185\u8fed\u4ee3\u7684\u68af\u5ea6\u6765\u5f15\u5bfc\u91c7\u6837\u65b9\u5411\uff08\u91c7\u6837\u5e45\u5ea6\u7531\u968f\u673a\u5206\u5e03\u51b3\u5b9a\uff09\uff0c\u4f7f\u5bf9\u6297\u6837\u672c\u4f4d\u4e8e\u65e2\u5e73\u5766\u53c8\u5177\u6709\u8f83\u9ad8\u5c40\u90e8\u6700\u5927\u503c\u7684\u5e73\u8861\u533a\u57df\u3002", "result": "\u5728\u591a\u4e2aDNN\u67b6\u6784\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8fc1\u79fb\u653b\u51fb\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "GGS\u65b9\u6cd5\u901a\u8fc7\u68af\u5ea6\u5f15\u5bfc\u91c7\u6837\u6709\u6548\u5e73\u8861\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u5229\u7528\u6027\u548c\u63a2\u7d22\u6027\uff0c\u5728\u4fdd\u6301\u5f3a\u653b\u51fb\u6548\u529b\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8de8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.00413", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00413", "abs": "https://arxiv.org/abs/2511.00413", "authors": ["Shaojie Wang", "Jinghui Wang", "Yinghan Cui", "Xuxing Chen", "Chao Wang", "Liang Huang", "Xiaojiang Zhang", "Junyi Peng", "Li Wan", "Haotian Zhang", "Bin Chen"], "title": "Tree Training: Accelerating Agentic LLMs Training via Shared Prefix Reuse", "comment": null, "summary": "In agentic LLM scenarios, an agent's interaction process during a single\nrollout often exhibits branching behaviors. Due to memory retrieval and\nconcurrent tool executions at certain decision points, the token trajectory of\none task evolves into a tree-like structure rather than a linear sequence.\nHowever, current training pipelines decompose such tree-structured trajectories\ninto separate linear segments, treating each branch as an independent sequence.\nAs a result, shared prefixes across these branches are repeatedly recomputed\nduring both forward and backward passes. To address this inefficiency, we\npropose Tree Training, a paradigm that computes each shared prefix only once\nand reuses its intermediate results across related branches during both forward\nand backward passes, substantially improving computation efficiency in\nlarge-scale agentic training. This is achieved via (i) Tree Packing, which\nefficiently reuses shared computations across trajectories, and (ii) Gradient\nRestoration, which ensures correct gradient propagation across reused prefixes.\nExperiments on multiple open-source models demonstrate up to 3.9x reduction in\ntotal training time, enabling more efficient agentic LLM SFT and RL training.", "AI": {"tldr": "\u63d0\u51faTree Training\u65b9\u6cd5\uff0c\u901a\u8fc7\u6811\u6253\u5305\u548c\u68af\u5ea6\u6062\u590d\u6280\u672f\uff0c\u5728\u667a\u80fd\u4f53LLM\u8bad\u7ec3\u4e2d\u91cd\u7528\u5171\u4eab\u524d\u7f00\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387", "motivation": "\u5f53\u524d\u8bad\u7ec3\u6d41\u7a0b\u5c06\u6811\u72b6\u8f68\u8ff9\u5206\u89e3\u4e3a\u72ec\u7acb\u7ebf\u6027\u5e8f\u5217\uff0c\u5bfc\u81f4\u5171\u4eab\u524d\u7f00\u88ab\u91cd\u590d\u8ba1\u7b97\uff0c\u9020\u6210\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b", "method": "\u4f7f\u7528\u6811\u6253\u5305\u6280\u672f\u91cd\u7528\u8f68\u8ff9\u95f4\u7684\u5171\u4eab\u8ba1\u7b97\uff0c\u914d\u5408\u68af\u5ea6\u6062\u590d\u786e\u4fdd\u91cd\u7528\u524d\u7f00\u7684\u6b63\u786e\u68af\u5ea6\u4f20\u64ad", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u603b\u8bad\u7ec3\u65f6\u95f4\u6700\u591a\u51cf\u5c113.9\u500d", "conclusion": "Tree Training\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53LLM SFT\u548cRL\u8bad\u7ec3\u7684\u6548\u7387"}}
{"id": "2511.00418", "categories": ["cs.LG", "math-ph", "math.MP", "nlin.PS", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.00418", "abs": "https://arxiv.org/abs/2511.00418", "authors": ["Victory Obieke", "Emmanuel Oguadimma"], "title": "Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation", "comment": "9 Pages, 11 figures", "summary": "Physics-Informed Neural Networks (PINNs) offer a flexible framework for\nsolving nonlinear partial differential equations (PDEs), yet conventional\nimplementations often fail to preserve key physical invariants during long-term\nintegration. This paper introduces a \\emph{structure-preserving PINN} framework\nfor the nonlinear Korteweg--de Vries (KdV) equation, a prototypical model for\nnonlinear and dispersive wave propagation. The proposed method embeds the\nconservation of mass and Hamiltonian energy directly into the loss function,\nensuring physically consistent and energy-stable evolution throughout training\nand prediction. Unlike standard \\texttt{tanh}-based\nPINNs~\\cite{raissi2019pinn,wang2022modifiedpinn}, our approach employs\nsinusoidal activation functions that enhance spectral expressiveness and\naccurately capture the oscillatory and dispersive nature of KdV solitons.\nThrough representative case studies -- including single-soliton propagation\n(shape-preserving translation), two-soliton interaction (elastic collision with\nphase shift), and cosine-pulse initialization (nonlinear dispersive breakup) --\nthe model successfully reproduces hallmark behaviors of KdV dynamics while\nmaintaining conserved invariants. Ablation studies demonstrate that combining\ninvariant-constrained optimization with sinusoidal feature mappings accelerates\nconvergence, improves long-term stability, and mitigates drift without\nmulti-stage pretraining. These results highlight that computationally\nefficient, invariant-aware regularization coupled with sinusoidal\nrepresentations yields robust, energy-consistent PINNs for Hamiltonian partial\ndifferential equations such as the KdV equation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u4fdd\u6301\u7684PINN\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u8d28\u91cf\u5b88\u6052\u548c\u54c8\u5bc6\u987f\u80fd\u91cf\u5b88\u6052\u5230\u635f\u5931\u51fd\u6570\u4e2d\uff0c\u7ed3\u5408\u6b63\u5f26\u6fc0\u6d3b\u51fd\u6570\uff0c\u89e3\u51b3\u4e86KdV\u65b9\u7a0b\u957f\u671f\u79ef\u5206\u4e2d\u7269\u7406\u4e0d\u53d8\u91cf\u4fdd\u6301\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfPINNs\u5728\u6c42\u89e3\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u5728\u957f\u671f\u79ef\u5206\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u5173\u952e\u7684\u7269\u7406\u4e0d\u53d8\u91cf\uff0c\u5bfc\u81f4\u7269\u7406\u4e0d\u4e00\u81f4\u548c\u80fd\u91cf\u4e0d\u7a33\u5b9a\u7684\u6f14\u5316\u3002", "method": "\u5c06\u8d28\u91cf\u5b88\u6052\u548c\u54c8\u5bc6\u987f\u80fd\u91cf\u5b88\u6052\u76f4\u63a5\u5d4c\u5165\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u6b63\u5f26\u6fc0\u6d3b\u51fd\u6570\u589e\u5f3a\u9891\u8c31\u8868\u8fbe\u80fd\u529b\uff0c\u51c6\u786e\u6355\u6349KdV\u5b64\u5b50\u7684\u632f\u8361\u548c\u8272\u6563\u7279\u6027\u3002", "result": "\u5728\u5355\u5b64\u5b50\u4f20\u64ad\u3001\u53cc\u5b64\u5b50\u76f8\u4e92\u4f5c\u7528\u548c\u4f59\u5f26\u8109\u51b2\u521d\u59cb\u5316\u7b49\u4ee3\u8868\u6027\u6848\u4f8b\u4e2d\uff0c\u6210\u529f\u91cd\u73b0\u4e86KdV\u52a8\u529b\u5b66\u7684\u6807\u5fd7\u6027\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b88\u6052\u4e0d\u53d8\u91cf\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408\u4e0d\u53d8\u7ea6\u675f\u4f18\u5316\u548c\u6b63\u5f26\u7279\u5f81\u6620\u5c04\u53ef\u4ee5\u52a0\u901f\u6536\u655b\u3001\u63d0\u9ad8\u957f\u671f\u7a33\u5b9a\u6027\u5e76\u51cf\u8f7b\u6f02\u79fb\u3002", "conclusion": "\u8ba1\u7b97\u9ad8\u6548\u7684\u4e0d\u53d8\u611f\u77e5\u6b63\u5219\u5316\u4e0e\u6b63\u5f26\u8868\u793a\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u4e3a\u54c8\u5bc6\u987f\u504f\u5fae\u5206\u65b9\u7a0b\uff08\u5982KdV\u65b9\u7a0b\uff09\u4ea7\u751f\u7a33\u5065\u3001\u80fd\u91cf\u4e00\u81f4\u7684PINNs\u3002"}}
{"id": "2511.00423", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00423", "abs": "https://arxiv.org/abs/2511.00423", "authors": ["Guojian Zhan", "Likun Wang", "Xiangteng Zhang", "Jiaxin Gao", "Masayoshi Tomizuka", "Shengbo Eben Li"], "title": "Bootstrap Off-policy with World Model", "comment": "NeurIPS 2025", "summary": "Online planning has proven effective in reinforcement learning (RL) for\nimproving sample efficiency and final performance. However, using planning for\nenvironment interaction inevitably introduces a divergence between the\ncollected data and the policy's actual behaviors, degrading both model learning\nand policy improvement. To address this, we propose BOOM (Bootstrap Off-policy\nwith WOrld Model), a framework that tightly integrates planning and off-policy\nlearning through a bootstrap loop: the policy initializes the planner, and the\nplanner refines actions to bootstrap the policy through behavior alignment.\nThis loop is supported by a jointly learned world model, which enables the\nplanner to simulate future trajectories and provides value targets to\nfacilitate policy improvement. The core of BOOM is a likelihood-free alignment\nloss that bootstraps the policy using the planner's non-parametric action\ndistribution, combined with a soft value-weighted mechanism that prioritizes\nhigh-return behaviors and mitigates variability in the planner's action quality\nwithin the replay buffer. Experiments on the high-dimensional DeepMind Control\nSuite and Humanoid-Bench show that BOOM achieves state-of-the-art results in\nboth training stability and final performance. The code is accessible at\nhttps://github.com/molumitu/BOOM_MBRL.", "AI": {"tldr": "BOOM\u6846\u67b6\u901a\u8fc7\u5f15\u5bfc\u5faa\u73af\u5c06\u89c4\u5212\u4e0e\u79bb\u7ebf\u5b66\u4e60\u7d27\u5bc6\u7ed3\u5408\uff0c\u4f7f\u7528\u8054\u5408\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u6765\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd\u3002", "motivation": "\u5728\u7ebf\u89c4\u5212\u867d\u7136\u80fd\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6536\u96c6\u6570\u636e\u4e0e\u5b9e\u9645\u7b56\u7565\u884c\u4e3a\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4ece\u800c\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\u548c\u7b56\u7565\u6539\u8fdb\u3002", "method": "\u63d0\u51faBOOM\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5bfc\u5faa\u73af\u5c06\u7b56\u7565\u521d\u59cb\u5316\u89c4\u5212\u5668\uff0c\u89c4\u5212\u5668\u901a\u8fc7\u884c\u4e3a\u5bf9\u9f50\u5f15\u5bfc\u7b56\u7565\u3002\u4f7f\u7528\u8054\u5408\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u8f68\u8ff9\u6a21\u62df\u548c\u4ef7\u503c\u76ee\u6807\u63d0\u4f9b\uff0c\u6838\u5fc3\u662f\u4f7f\u7528\u89c4\u5212\u5668\u7684\u975e\u53c2\u6570\u52a8\u4f5c\u5206\u5e03\u5f15\u5bfc\u7b56\u7565\u7684\u65e0\u4f3c\u7136\u5bf9\u9f50\u635f\u5931\u3002", "result": "\u5728DeepMind Control Suite\u548cHumanoid-Bench\u7b49\u9ad8\u7ef4\u73af\u5883\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBOOM\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6027\u80fd\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "BOOM\u901a\u8fc7\u7d27\u5bc6\u96c6\u6210\u89c4\u5212\u548c\u79bb\u7ebf\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u89c4\u5212\u5e26\u6765\u7684\u6570\u636e-\u7b56\u7565\u884c\u4e3a\u5dee\u5f02\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2511.00443", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00443", "abs": "https://arxiv.org/abs/2511.00443", "authors": ["Ruthwik Reddy Doodipala", "Pankaj Pandey", "Carolina Torres Rojas", "Manob Jyoti Saikia", "Ranganatha Sitaram"], "title": "Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model", "comment": null, "summary": "The emergence of foundation models in neuroimaging is driven by the\nincreasing availability of large-scale and heterogeneous brain imaging\ndatasets. Recent advances in self-supervised learning, particularly\nreconstruction-based objectives, have demonstrated strong potential for\npretraining models that generalize effectively across diverse downstream\nfunctional MRI (fMRI) tasks. In this study, we explore region-aware\nreconstruction strategies for a foundation model in resting-state fMRI, moving\nbeyond approaches that rely on random region masking. Specifically, we\nintroduce an ROI-guided masking strategy using the Automated Anatomical\nLabelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively\nmask semantically coherent brain regions during self-supervised pretraining.\nUsing the ADHD-200 dataset comprising 973 subjects with resting-state fMRI\nscans, we show that our method achieves a 4.23% improvement in classification\naccuracy for distinguishing healthy controls from individuals diagnosed with\nADHD, compared to conventional random masking. Region-level attribution\nanalysis reveals that brain volumes within the limbic region and cerebellum\ncontribute most significantly to reconstruction fidelity and model\nrepresentation. Our results demonstrate that masking anatomical regions during\nmodel pretraining not only enhances interpretability but also yields more\nrobust and discriminative representations. In future work, we plan to extend\nthis approach by evaluating it on additional neuroimaging datasets, and\ndeveloping new loss functions explicitly derived from region-aware\nreconstruction objectives. These directions aim to further improve the\nrobustness and interpretability of foundation models for functional\nneuroimaging.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eROI\u5f15\u5bfc\u63a9\u7801\u7b56\u7565\u7684fMRI\u57fa\u7840\u6a21\u578b\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u968f\u673a\u63a9\u7801\u5728ADHD\u5206\u7c7b\u4efb\u52a1\u4e0a\u63d0\u5347\u4e864.23%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a8\u52a8\u795e\u7ecf\u5f71\u50cf\u57fa\u7840\u6a21\u578b\u53d1\u5c55\uff0c\u5229\u7528\u5927\u89c4\u6a21\u5f02\u8d28\u6027\u8111\u6210\u50cf\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u8d85\u8d8a\u968f\u673a\u533a\u57df\u63a9\u7801\u7684\u533a\u57df\u611f\u77e5\u91cd\u5efa\u7b56\u7565\u3002", "method": "\u4f7f\u7528AAL3\u56fe\u8c31\u7684ROI\u5f15\u5bfc\u63a9\u7801\u7b56\u7565\uff0c\u57284D fMRI\u5168\u8111\u4f53\u79ef\u4e0a\u9009\u62e9\u6027\u63a9\u7801\u8bed\u4e49\u8fde\u8d2f\u7684\u8111\u533a\uff0c\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3002", "result": "\u5728ADHD-200\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u968f\u673a\u63a9\u7801\u5728ADHD\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u63d0\u53474.23%\uff0c\u8fb9\u7f18\u7cfb\u7edf\u548c\u8111\u5c0f\u8111\u533a\u57df\u5bf9\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u6a21\u578b\u8868\u793a\u8d21\u732e\u6700\u5927\u3002", "conclusion": "\u5728\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u63a9\u7801\u89e3\u5256\u533a\u57df\u4e0d\u4ec5\u80fd\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u8fd8\u80fd\u4ea7\u751f\u66f4\u9c81\u68d2\u548c\u53ef\u533a\u5206\u7684\u8868\u793a\uff0c\u672a\u6765\u5c06\u6269\u5c55\u5230\u66f4\u591a\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u548c\u5f00\u53d1\u65b0\u7684\u635f\u5931\u51fd\u6570\u3002"}}
{"id": "2511.00462", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00462", "abs": "https://arxiv.org/abs/2511.00462", "authors": ["Xin Chen", "Saili Uday Gadgil", "Kangning Gao", "Yi Hu", "Cong Nie"], "title": "Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders", "comment": null, "summary": "An anomaly detection method based on deep autoencoders is proposed to address\nanomalies that often occur in enterprise-level ETL data streams. The study\nfirst analyzes multiple types of anomalies in ETL processes, including delays,\nmissing values, duplicate loading, and sudden abnormal changes, and applies\ndata standardization and feature modeling to ensure stable and usable inputs.\nIn the method design, the encoder-decoder structure compresses high-dimensional\ninputs into latent representations and reconstructs them, while reconstruction\nerror is used to measure anomaly levels. Regularization constraints are\nintroduced in the latent space to enhance feature sparsity and distribution\nlearning, thereby improving robustness in complex data streams. Systematic\nanalyses under different hyperparameter settings, environmental changes, and\ndata characteristics show that the proposed method achieves superior\nperformance in AUC, ACC, Precision, and Recall. The results demonstrate that\nthe deep autoencoder-based detection mechanism can effectively capture latent\ndistribution patterns in enterprise-level ETL data streams and accurately\nidentify diverse anomalies, providing reliable support for enterprise data\nprocessing and intelligent analysis.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u4f01\u4e1a\u7ea7ETL\u6570\u636e\u6d41\u4e2d\u7684\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\uff0c\u901a\u8fc7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u548c\u6b63\u5219\u5316\u7ea6\u675f\u5b9e\u73b0\u9ad8\u6548\u5f02\u5e38\u8bc6\u522b\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u7ea7ETL\u6570\u636e\u6d41\u4e2d\u7ecf\u5e38\u51fa\u73b0\u7684\u5f02\u5e38\u95ee\u9898\uff0c\u5305\u62ec\u5ef6\u8fdf\u3001\u7f3a\u5931\u503c\u3001\u91cd\u590d\u52a0\u8f7d\u548c\u7a81\u53d1\u5f02\u5e38\u53d8\u5316\u7b49\uff0c\u9700\u8981\u7a33\u5b9a\u53ef\u9760\u7684\u5f02\u5e38\u68c0\u6d4b\u673a\u5236\u6765\u4fdd\u969c\u4f01\u4e1a\u6570\u636e\u5904\u7406\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u7ed3\u6784\uff0c\u5c06\u9ad8\u7ef4\u8f93\u5165\u538b\u7f29\u4e3a\u6f5c\u5728\u8868\u793a\u5e76\u91cd\u6784\uff0c\u5229\u7528\u91cd\u6784\u8bef\u5dee\u8861\u91cf\u5f02\u5e38\u7a0b\u5ea6\uff1b\u5728\u6f5c\u5728\u7a7a\u95f4\u5f15\u5165\u6b63\u5219\u5316\u7ea6\u675f\u589e\u5f3a\u7279\u5f81\u7a00\u758f\u6027\u548c\u5206\u5e03\u5b66\u4e60\uff0c\u63d0\u5347\u590d\u6742\u6570\u636e\u6d41\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u3001\u73af\u5883\u53d8\u5316\u548c\u6570\u636e\u7279\u5f81\u4e0b\u7684\u7cfb\u7edf\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728AUC\u3001ACC\u3001Precision\u548cRecall\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u6355\u83b7ETL\u6570\u636e\u6d41\u7684\u6f5c\u5728\u5206\u5e03\u6a21\u5f0f\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u7684\u68c0\u6d4b\u673a\u5236\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u4f01\u4e1a\u7ea7ETL\u6570\u636e\u6d41\u4e2d\u7684\u591a\u79cd\u5f02\u5e38\uff0c\u4e3a\u4f01\u4e1a\u6570\u636e\u5904\u7406\u548c\u667a\u80fd\u5206\u6790\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2511.00469", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00469", "abs": "https://arxiv.org/abs/2511.00469", "authors": ["Zhongxiang Lei", "Qi Yang", "Ping Qiu", "Gang Zhang", "Yuanchi Ma", "Jinyan Liu"], "title": "Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima", "comment": null, "summary": "Federated optimization is a constrained form of distributed optimization that\nenables training a global model without directly sharing client data. Although\nexisting algorithms can guarantee convergence in theory and often achieve\nstable training in practice, the reasons behind performance degradation under\ndata heterogeneity remain unclear. To address this gap, the main contribution\nof this paper is to provide a theoretical perspective that explains why such\ndegradation occurs. We introduce the assumption that heterogeneous client data\nlead to distinct local optima, and show that this assumption implies two key\nconsequences: 1) the distance among clients' local optima raises the lower\nbound of the global objective, making perfect fitting of all client data\nimpossible; and 2) in the final training stage, the global model oscillates\nwithin a region instead of converging to a single optimum, limiting its ability\nto fully fit the data. These results provide a principled explanation for\nperformance degradation in non-iid settings, which we further validate through\nexperiments across multiple tasks and neural network architectures. The\nframework used in this paper is open-sourced at:\nhttps://github.com/NPCLEI/fedtorch.", "AI": {"tldr": "\u672c\u6587\u4ece\u7406\u8bba\u89d2\u5ea6\u89e3\u91ca\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u8d28\u6027\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\uff0c\u6307\u51fa\u5f02\u8d28\u6570\u636e\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u8fd9\u65e2\u63d0\u9ad8\u4e86\u5168\u5c40\u76ee\u6807\u7684\u4e0b\u754c\uff0c\u53c8\u5bfc\u81f4\u6a21\u578b\u5728\u8bad\u7ec3\u540e\u671f\u5728\u533a\u57df\u5185\u632f\u8361\u800c\u975e\u6536\u655b\u5230\u5355\u4e00\u6700\u4f18\u89e3\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u867d\u7136\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u90fd\u80fd\u4fdd\u8bc1\u6536\u655b\uff0c\u4f46\u5728\u6570\u636e\u5f02\u8d28\u6027\u4e0b\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\uff0c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4f1a\u5bfc\u81f4\u6027\u80fd\u9000\u5316\u3002", "method": "\u5f15\u5165\u5047\u8bbe\uff1a\u5f02\u8d28\u5ba2\u6237\u7aef\u6570\u636e\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u5e76\u57fa\u4e8e\u6b64\u5047\u8bbe\u63a8\u5bfc\u51fa\u4e24\u4e2a\u5173\u952e\u540e\u679c\uff1a1) \u5ba2\u6237\u7aef\u5c40\u90e8\u6700\u4f18\u89e3\u4e4b\u95f4\u7684\u8ddd\u79bb\u63d0\u9ad8\u4e86\u5168\u5c40\u76ee\u6807\u7684\u4e0b\u754c\uff1b2) \u5728\u8bad\u7ec3\u540e\u671f\uff0c\u5168\u5c40\u6a21\u578b\u5728\u533a\u57df\u5185\u632f\u8361\u800c\u975e\u6536\u655b\u5230\u5355\u4e00\u6700\u4f18\u89e3\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u6570\u636e\u5f02\u8d28\u6027\u4f7f\u5f97\u5b8c\u7f8e\u62df\u5408\u6240\u6709\u5ba2\u6237\u7aef\u6570\u636e\u53d8\u5f97\u4e0d\u53ef\u80fd\uff0c\u4e14\u6a21\u578b\u5728\u6700\u7ec8\u8bad\u7ec3\u9636\u6bb5\u65e0\u6cd5\u5b8c\u5168\u6536\u655b\uff0c\u9650\u5236\u4e86\u5176\u6570\u636e\u62df\u5408\u80fd\u529b\u3002\u8fd9\u4e9b\u53d1\u73b0\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u5b9e\u9a8c\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8054\u90a6\u5b66\u4e60\u4e2d\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4e3a\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002"}}
{"id": "2511.00475", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00475", "abs": "https://arxiv.org/abs/2511.00475", "authors": ["Travis Barrett", "Amit Kumar Mishra", "Joyce Mwangama"], "title": "Variational Autoencoder for Calibration: A New Approach", "comment": "6 pages, 5 figures", "summary": "In this paper we present a new implementation of a Variational Autoencoder\n(VAE) for the calibration of sensors. We propose that the VAE can be used to\ncalibrate sensor data by training the latent space as a calibration output. We\ndiscuss this new approach and show a proof-of-concept using an existing\nmulti-sensor gas dataset. We show the performance of the proposed calibration\nVAE and found that it was capable of performing as calibration model while\nperforming as an autoencoder simultaneously. Additionally, these models have\nshown that they are capable of creating statistically similar outputs from both\nthe calibration output as well as the reconstruction output to their respective\ntruth data. We then discuss the methods of future testing and planned expansion\nof this work.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u4f20\u611f\u5668\u6821\u51c6\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6f5c\u5728\u7a7a\u95f4\u4f5c\u4e3a\u6821\u51c6\u8f93\u51fa\u6765\u6821\u51c6\u4f20\u611f\u5668\u6570\u636e\uff0c\u5e76\u5728\u591a\u4f20\u611f\u5668\u6c14\u4f53\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6982\u5ff5\u9a8c\u8bc1\u3002", "motivation": "\u63a2\u7d22\u4f7f\u7528VAE\u8fdb\u884c\u4f20\u611f\u5668\u6821\u51c6\u7684\u53ef\u80fd\u6027\uff0c\u5229\u7528\u5176\u6f5c\u5728\u7a7a\u95f4\u7279\u6027\u6765\u5b9e\u73b0\u540c\u65f6\u8fdb\u884c\u6570\u636e\u91cd\u5efa\u548c\u6821\u51c6\u7684\u53cc\u91cd\u529f\u80fd\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u5c06\u6f5c\u5728\u7a7a\u95f4\u8bad\u7ec3\u4e3a\u6821\u51c6\u8f93\u51fa\uff0c\u5e76\u5728\u73b0\u6709\u7684\u591a\u4f20\u611f\u5668\u6c14\u4f53\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u6821\u51c6VAE\u80fd\u591f\u540c\u65f6\u4f5c\u4e3a\u6821\u51c6\u6a21\u578b\u548c\u81ea\u7f16\u7801\u5668\u5de5\u4f5c\uff0c\u4ece\u6821\u51c6\u8f93\u51fa\u548c\u91cd\u5efa\u8f93\u51fa\u90fd\u80fd\u4ea7\u751f\u4e0e\u771f\u5b9e\u6570\u636e\u7edf\u8ba1\u76f8\u4f3c\u7684\u8f93\u51fa\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86VAE\u5728\u4f20\u611f\u5668\u6821\u51c6\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u6d4b\u8bd5\u548c\u6269\u5c55\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00521", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00521", "abs": "https://arxiv.org/abs/2511.00521", "authors": ["Bao Nguyen", "Hieu Trung Nguyen", "Ruifeng She", "Xiaojin Fu", "Viet Anh Nguyen"], "title": "Reasoning Planning for Language Models", "comment": "29 pages, 5 figures", "summary": "Selecting an appropriate reasoning method for a given query remains a key\nchallenge in language model generation. Existing approaches typically generate\nmultiple candidate responses and use an aggregation strategy to select the\noutput answer, often assuming that more candidate answers yield higher\naccuracy. We revisit this assumption through a rigorous theoretical analysis,\nderiving accuracy bounds for standard aggregation methods under fixed\ngeneration distributions and candidate sizes. Building on these insights, we\nintroduce EPIC, an Ensemble Planning with Contrastive learning framework to\nlearn a shared representation space that captures both model reasoning\nabilities and query-method compatibility. EPIC incorporates our probability\nbounds as a regularizer in a utility-driven optimization that balances accuracy\nand computational cost. Experiments on diverse mathematical reasoning tasks\nshow that EPIC consistently selects optimal reasoning methods, improving\naccuracy while reducing computational overhead. Our code can be found at\nhttps://github.com/nguyenngocbaocmt02/EPIC.", "AI": {"tldr": "EPIC\u6846\u67b6\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u5171\u4eab\u8868\u793a\u7a7a\u95f4\uff0c\u9009\u62e9\u6700\u4f18\u63a8\u7406\u65b9\u6cd5\uff0c\u5728\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u751f\u6210\u591a\u4e2a\u5019\u9009\u54cd\u5e94\u5e76\u4f7f\u7528\u805a\u5408\u7b56\u7565\u9009\u62e9\u7b54\u6848\uff0c\u4f46\u5047\u8bbe\u66f4\u591a\u5019\u9009\u7b54\u6848\u80fd\u5e26\u6765\u66f4\u9ad8\u51c6\u786e\u7387\u3002\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u5047\u8bbe\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u53d1\u73b0\u56fa\u5b9a\u751f\u6210\u5206\u5e03\u548c\u5019\u9009\u6570\u91cf\u4e0b\u7684\u51c6\u786e\u7387\u8fb9\u754c", "method": "\u63d0\u51faEPIC\u6846\u67b6\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u5171\u4eab\u8868\u793a\u7a7a\u95f4\u6765\u6355\u6349\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u67e5\u8be2-\u65b9\u6cd5\u517c\u5bb9\u6027\uff0c\u5c06\u6982\u7387\u8fb9\u754c\u4f5c\u4e3a\u6b63\u5219\u5316\u5668\u7eb3\u5165\u6548\u7528\u9a71\u52a8\u7684\u4f18\u5316\u4e2d\uff0c\u5e73\u8861\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6210\u672c", "result": "\u5728\u591a\u6837\u5316\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEPIC\u80fd\u6301\u7eed\u9009\u62e9\u6700\u4f18\u63a8\u7406\u65b9\u6cd5\uff0c\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500", "conclusion": "EPIC\u6846\u67b6\u901a\u8fc7\u7406\u8bba\u6307\u5bfc\u7684\u65b9\u6cd5\u9009\u62e9\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861"}}
{"id": "2511.00532", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00532", "abs": "https://arxiv.org/abs/2511.00532", "authors": ["Drago\u015f-Andrei \u015eerban", "R\u0103zvan-Alexandru Sm\u0103du", "Dumitru-Clementin Cercel"], "title": "Air Pollution Forecasting in Bucharest", "comment": "14 pages 3 figures", "summary": "Air pollution, especially the particulate matter 2.5 (PM2.5), has become a\ngrowing concern in recent years, primarily in urban areas. Being exposed to air\npollution is linked to developing numerous health problems, like the\naggravation of respiratory diseases, cardiovascular disorders, lung function\nimpairment, and even cancer or early death. Forecasting future levels of PM2.5\nhas become increasingly important over the past few years, as it can provide\nearly warnings and help prevent diseases. This paper aims to design, fine-tune,\ntest, and evaluate machine learning models for predicting future levels of\nPM2.5 over various time horizons. Our primary objective is to assess and\ncompare the performance of multiple models, ranging from linear regression\nalgorithms and ensemble-based methods to deep learning models, such as advanced\nrecurrent neural networks and transformers, as well as large language models,\non this forecasting task.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u548c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4bPM2.5\u6d53\u5ea6\uff0c\u5305\u62ec\u7ebf\u6027\u56de\u5f52\u3001\u96c6\u6210\u65b9\u6cd5\u3001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "PM2.5\u7a7a\u6c14\u6c61\u67d3\u5bf9\u5065\u5eb7\u9020\u6210\u4e25\u91cd\u5f71\u54cd\uff0c\u9884\u6d4b\u672a\u6765PM2.5\u6c34\u5e73\u53ef\u4ee5\u63d0\u4f9b\u65e9\u671f\u9884\u8b66\u5e76\u5e2e\u52a9\u9884\u9632\u75be\u75c5\u3002", "method": "\u8bbe\u8ba1\u3001\u5fae\u8c03\u3001\u6d4b\u8bd5\u548c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u7ebf\u6027\u56de\u5f52\u7b97\u6cd5\u3001\u96c6\u6210\u65b9\u6cd5\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3001\u53d8\u6362\u5668\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e86\u591a\u79cd\u6a21\u578b\u5728PM2.5\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3aPM2.5\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6a21\u578b\u9009\u62e9\u53c2\u8003\u3002"}}
{"id": "2511.00543", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00543", "abs": "https://arxiv.org/abs/2511.00543", "authors": ["Yunchuan Guan", "Yu Liu", "Ke Zhou", "Hui Li", "Sen Jia", "Zhiqi Shen", "Ziyang Wang", "Xinglin Zhang", "Tao Chen", "Jenq-Neng Hwang", "Lei Li"], "title": "Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance", "comment": null, "summary": "Recent advances in generative modeling enable neural networks to generate\nweights without relying on gradient-based optimization. However, current\nmethods are limited by issues of over-coupling and long-horizon. The former\ntightly binds weight generation with task-specific objectives, thereby limiting\nthe flexibility of the learned optimizer. The latter leads to inefficiency and\nlow accuracy during inference, caused by the lack of local constraints. In this\npaper, we propose Lo-Hp, a decoupled two-stage weight generation framework that\nenhances flexibility through learning various optimization policies. It adopts\na hybrid-policy sub-trajectory balance objective, which integrates on-policy\nand off-policy learning to capture local optimization policies. Theoretically,\nwe demonstrate that learning solely local optimization policies can address the\nlong-horizon issue while enhancing the generation of global optimal weights. In\naddition, we validate Lo-Hp's superior accuracy and inference efficiency in\ntasks that require frequent weight updates, such as transfer learning, few-shot\nlearning, domain generalization, and large language model adaptation.", "AI": {"tldr": "\u63d0\u51faLo-Hp\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u7684\u4e24\u9636\u6bb5\u6743\u91cd\u751f\u6210\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u751f\u6210\u5f0f\u6743\u91cd\u4f18\u5316\u4e2d\u7684\u8fc7\u8026\u5408\u548c\u957f\u89c6\u91ce\u95ee\u9898\uff0c\u91c7\u7528\u6df7\u5408\u7b56\u7565\u5b50\u8f68\u8ff9\u5e73\u8861\u76ee\u6807\u6765\u5b66\u4e60\u5c40\u90e8\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u751f\u6210\u5f0f\u5efa\u6a21\u7684\u6743\u91cd\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u8fc7\u8026\u5408\u548c\u957f\u89c6\u91ce\u95ee\u9898\uff0c\u524d\u8005\u9650\u5236\u4e86\u4f18\u5316\u5668\u7684\u7075\u6d3b\u6027\uff0c\u540e\u8005\u5bfc\u81f4\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u548c\u7cbe\u5ea6\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7684\u4e24\u9636\u6bb5\u6743\u91cd\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u6df7\u5408\u7b56\u7565\u5b50\u8f68\u8ff9\u5e73\u8861\u76ee\u6807\uff0c\u6574\u5408\u5728\u7ebf\u548c\u79bb\u7ebf\u5b66\u4e60\u6765\u6355\u6349\u5c40\u90e8\u4f18\u5316\u7b56\u7565\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4ec5\u5b66\u4e60\u5c40\u90e8\u4f18\u5316\u7b56\u7565\u5373\u53ef\u89e3\u51b3\u957f\u89c6\u91ce\u95ee\u9898\u5e76\u63d0\u5347\u5168\u5c40\u6700\u4f18\u6743\u91cd\u751f\u6210\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u3001\u5c11\u6837\u672c\u5b66\u4e60\u7b49\u9886\u57df\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "Lo-Hp\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u8bbe\u8ba1\u548c\u5c40\u90e8\u7b56\u7565\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u9700\u8981\u9891\u7e41\u6743\u91cd\u66f4\u65b0\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.00549", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00549", "abs": "https://arxiv.org/abs/2511.00549", "authors": ["Qiang Li", "Jin Niu", "Lina Yu"], "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations", "comment": null, "summary": "Traffic congestion, primarily driven by intersection queuing, significantly\nimpacts urban living standards, safety, environmental quality, and economic\nefficiency. While Traffic Signal Control (TSC) systems hold potential for\ncongestion mitigation, traditional optimization models often fail to capture\nreal-world traffic complexity and dynamics. This study introduces a novel\nsingle-agent reinforcement learning (RL) framework for regional adaptive TSC,\ncircumventing the coordination complexities inherent in multi-agent systems\nthrough a centralized decision-making paradigm. The model employs an adjacency\nmatrix to unify the encoding of road network topology, real-time queue states\nderived from probe vehicle data, and current signal timing parameters.\nLeveraging the efficient learning capabilities of the DreamerV3 world model,\nthe agent learns control policies where actions sequentially select\nintersections and adjust their signal phase splits to regulate traffic\ninflow/outflow, analogous to a feedback control system. Reward design\nprioritizes queue dissipation, directly linking congestion metrics (queue\nlength) to control actions. Simulation experiments conducted in SUMO\ndemonstrate the model's effectiveness: under inference scenarios with\nmulti-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the\nframework exhibits robust anti-fluctuation capability and significantly reduces\nqueue lengths. This work establishes a new paradigm for intelligent traffic\ncontrol compatible with probe vehicle technology. Future research will focus on\nenhancing practical applicability by incorporating stochastic OD demand\nfluctuations during training and exploring regional optimization mechanisms for\ncontingency events.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u4e2d\u51b3\u7b56\u907f\u514d\u591a\u667a\u80fd\u4f53\u534f\u8c03\u590d\u6742\u6027\uff0c\u5229\u7528DreamerV3\u4e16\u754c\u6a21\u578b\u9ad8\u6548\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u5728SUMO\u4eff\u771f\u4e2d\u9a8c\u8bc1\u4e86\u826f\u597d\u7684\u6297\u6ce2\u52a8\u80fd\u529b\u548c\u961f\u5217\u957f\u5ea6\u51cf\u5c11\u6548\u679c\u3002", "motivation": "\u4ea4\u901a\u62e5\u5835\u4e3b\u8981\u7531\u4ea4\u53c9\u53e3\u6392\u961f\u5f15\u8d77\uff0c\u4f20\u7edf\u4f18\u5316\u6a21\u578b\u96be\u4ee5\u6355\u6349\u771f\u5b9e\u4ea4\u901a\u590d\u6742\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u6709\u6548\u7f13\u89e3\u62e5\u5835\u7684\u667a\u80fd\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u90bb\u63a5\u77e9\u9635\u7edf\u4e00\u7f16\u7801\u8def\u7f51\u62d3\u6251\u3001\u5b9e\u65f6\u961f\u5217\u72b6\u6001\u548c\u4fe1\u53f7\u914d\u65f6\u53c2\u6570\uff0c\u5229\u7528DreamerV3\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u52a8\u4f5c\u5e8f\u5217\u9009\u62e9\u4ea4\u53c9\u53e3\u5e76\u8c03\u6574\u4fe1\u53f7\u76f8\u4f4d\u914d\u65f6\u3002", "result": "\u5728SUMO\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0c\u9762\u5bf9\u591a\u7ea7\u522b(10%\u300120%\u300130%)OD\u9700\u6c42\u6ce2\u52a8\uff0c\u8be5\u6846\u67b6\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6297\u6ce2\u52a8\u80fd\u529b\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u961f\u5217\u957f\u5ea6\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e0e\u63a2\u6d4b\u8f66\u8f86\u6280\u672f\u517c\u5bb9\u7684\u667a\u80fd\u4ea4\u901a\u63a7\u5236\u65b0\u8303\u5f0f\uff0c\u672a\u6765\u7814\u7a76\u5c06\u5173\u6ce8\u8bad\u7ec3\u4e2d\u7eb3\u5165\u968f\u673aOD\u9700\u6c42\u6ce2\u52a8\u548c\u533a\u57df\u4f18\u5316\u5e94\u6025\u673a\u5236\u3002"}}
{"id": "2511.00552", "categories": ["cs.LG", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00552", "abs": "https://arxiv.org/abs/2511.00552", "authors": ["Santhi Bharath Punati", "Sandeep Kanta", "Udaya Bhasker Cheerala", "Madhusudan G Lanjewar", "Praveen Damacharla"], "title": "Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales", "comment": "5 pages, 2025 6th International Conference on Data Analytics for\n  Business and Industry (ICDABI)", "summary": "Accurate multi-horizon retail forecasts are critical for inventory and\npromotions. We present a novel study of weekly Walmart sales (45 stores,\n2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store\nidentifiers with time-varying exogenous signals (holidays, CPI, fuel price,\ntemperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via\nQuantile Loss, yielding calibrated 90\\% prediction intervals and\ninterpretability through variable-selection networks, static enrichment, and\ntemporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of\n\\$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold\nchronological cross-validation, the averages are RMSE = \\$64.6k USD and $R^2$ =\n0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These\nresults demonstrate practical value for inventory planning and holiday-period\noptimization, while maintaining model transparency.", "AI": {"tldr": "\u4f7f\u7528\u65f6\u95f4\u878d\u5408\u53d8\u6362\u5668(TFT)\u5bf9\u6c83\u5c14\u739b\u5468\u9500\u552e\u989d\u8fdb\u884c\u591a\u671f\u9884\u6d4b\uff0c\u878d\u5408\u9759\u6001\u5546\u5e97\u6807\u8bc6\u7b26\u548c\u52a8\u6001\u5916\u90e8\u4fe1\u53f7\uff0c\u57281-5\u5468\u9884\u6d4b\u8303\u56f4\u5185\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5177\u6709\u6821\u51c6\u9884\u6d4b\u533a\u95f4\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u51c6\u786e\u7684\u96f6\u552e\u591a\u671f\u9884\u6d4b\u5bf9\u5e93\u5b58\u7ba1\u7406\u548c\u4fc3\u9500\u7b56\u7565\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u80fd\u591f\u5904\u7406\u9759\u6001\u548c\u52a8\u6001\u7279\u5f81\u5e76\u4fdd\u6301\u6a21\u578b\u900f\u660e\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u878d\u5408\u53d8\u6362\u5668(TFT)\u6a21\u578b\uff0c\u878d\u5408\u9759\u6001\u5546\u5e97\u6807\u8bc6\u7b26\u4e0e\u65f6\u95f4\u53d8\u5316\u7684\u5916\u90e8\u4fe1\u53f7(\u8282\u5047\u65e5\u3001CPI\u3001\u71c3\u6599\u4ef7\u683c\u3001\u6e29\u5ea6)\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u635f\u5931\u4ea7\u751f\u6982\u7387\u9884\u6d4b\uff0c\u5229\u7528\u53d8\u91cf\u9009\u62e9\u7f51\u7edc\u3001\u9759\u6001\u4e30\u5bcc\u5316\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u57282012\u5e74\u56fa\u5b9a\u6d4b\u8bd5\u96c6\u4e0a\uff0cTFT\u8fbe\u5230\u6bcf\u5e97\u5468RMSE 57.9k\u7f8e\u5143\u548cR\u00b2 0.9875\uff1b\u57285\u6298\u65f6\u5e8f\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\uff0c\u5e73\u5747RMSE 64.6k\u7f8e\u5143\u548cR\u00b2 0.9844\uff0c\u4f18\u4e8eXGB\u3001CNN\u3001LSTM\u548cCNN-LSTM\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "TFT\u6a21\u578b\u5728\u96f6\u552e\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u5b9e\u7528\u4ef7\u503c\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5e93\u5b58\u89c4\u5212\u548c\u8282\u5047\u65e5\u4f18\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.00554", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00554", "abs": "https://arxiv.org/abs/2511.00554", "authors": ["Phil Blandfort", "Robert Graham"], "title": "Red-teaming Activation Probes using Prompted LLMs", "comment": null, "summary": "Activation probes are attractive monitors for AI systems due to low cost and\nlatency, but their real-world robustness remains underexplored. We ask: What\nfailure modes arise under realistic, black-box adversarial pressure, and how\ncan we surface them with minimal effort? We present a lightweight black-box\nred-teaming procedure that wraps an off-the-shelf LLM with iterative feedback\nand in-context learning (ICL), and requires no fine-tuning, gradients, or\narchitectural access. Running a case study with probes for high-stakes\ninteractions, we show that our approach can help discover valuable insights\nabout a SOTA probe. Our analysis uncovers interpretable brittleness patterns\n(e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but\npersistent vulnerabilities under scenario-constraint attacks. These results\nsuggest that simple prompted red-teaming scaffolding can anticipate failure\npatterns before deployment and might yield promising, actionable insights to\nharden future probes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9ed1\u76d2\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4f7f\u7528\u73b0\u6210LLM\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u6765\u53d1\u73b0\u6fc0\u6d3b\u63a2\u9488\u7684\u8106\u5f31\u6027\u6a21\u5f0f\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u67b6\u6784\u8bbf\u95ee\u3002", "motivation": "\u6fc0\u6d3b\u63a2\u9488\u4f5c\u4e3aAI\u7cfb\u7edf\u76d1\u63a7\u5668\u6210\u672c\u4f4e\u3001\u5ef6\u8fdf\u5c0f\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u4e16\u754c\u9ed1\u76d2\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u53d1\u73b0\u5176\u5931\u6548\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u9ed1\u76d2\u7ea2\u961f\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u5c06\u73b0\u6210LLM\u5305\u88c5\u5728\u8fed\u4ee3\u53cd\u9988\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u65e0\u9700\u5fae\u8c03\u3001\u68af\u5ea6\u6216\u67b6\u6784\u8bbf\u95ee\u3002", "result": "\u5728\u9ad8\u98ce\u9669\u4ea4\u4e92\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u53d1\u73b0\u4e86\u53ef\u89e3\u91ca\u7684\u8106\u5f31\u6027\u6a21\u5f0f\uff08\u5982\u6cd5\u5f8b\u672f\u8bed\u5bfc\u81f4\u7684\u8bef\u62a5\u3001\u5e73\u6de1\u7a0b\u5e8f\u6027\u8bed\u8c03\u5bfc\u81f4\u7684\u6f0f\u62a5\uff09\uff0c\u4ee5\u53ca\u5728\u573a\u666f\u7ea6\u675f\u653b\u51fb\u4e0b\u51cf\u5c11\u4f46\u4ecd\u6301\u7eed\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u7b80\u5355\u7684\u63d0\u793a\u5f0f\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\u53ef\u4ee5\u5728\u90e8\u7f72\u524d\u9884\u6d4b\u5931\u6548\u6a21\u5f0f\uff0c\u5e76\u4e3a\u672a\u6765\u63a2\u9488\u7684\u5f3a\u5316\u63d0\u4f9b\u6709\u524d\u666f\u3001\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.00564", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00564", "abs": "https://arxiv.org/abs/2511.00564", "authors": ["Varun Teja Chirukiri", "Udaya Bhasker Cheerala", "Sandeep Kanta", "Abdul Karim", "Praveen Damacharla"], "title": "FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction", "comment": "5 pages, The 2025 International Conference on Computational Science\n  and Computational Intelligence", "summary": "Accurate prediction of the remaining useful life (RUL) of industrial\nmachinery is essential for reducing downtime and optimizing maintenance\nschedules. Existing approaches, such as long short-term memory (LSTM) networks\nand convolutional neural networks (CNNs), often struggle to model both global\ntemporal dependencies and fine-grained degradation trends in multivariate\nsensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal\nTransformer (FTT) -- a lightweight Transformer variant using linearized\nattention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU)\nlayer for sequential modeling. To the best of our knowledge, this is the first\napplication of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling\nsimultaneous capture of global and local degradation patterns in a compact\narchitecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and\n$R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published\ndeep baseline (TCN--Attention), it improves RMSE by 1.16\\% and MAE by 4.00\\%.\nTraining curves averaged over $k=3$ runs show smooth convergence with narrow\n95\\% confidence bands, and ablations (GRU-only, FTT-only) support the\ncontribution of both components. These results demonstrate that a compact\nTransformer-RNN hybrid delivers accurate and efficient RUL predictions on\nCMAPSS, making it suitable for real-time industrial prognostics.", "AI": {"tldr": "\u63d0\u51fa\u4e86FTT-GRU\u6df7\u5408\u6a21\u578b\uff0c\u7ed3\u5408\u5feb\u901f\u65f6\u5e8fTransformer\u548cGRU\uff0c\u7528\u4e8e\u5de5\u4e1a\u673a\u68b0\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u9884\u6d4b\uff0c\u5728CMAPSS\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u51c6\u786e\u9ad8\u6548\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982LSTM\u548cCNN\u96be\u4ee5\u540c\u65f6\u5efa\u6a21\u5168\u5c40\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u7ec6\u7c92\u5ea6\u9000\u5316\u8d8b\u52bf\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u6355\u83b7\u5168\u5c40\u548c\u5c40\u90e8\u9000\u5316\u6a21\u5f0f\u7684\u7d27\u51d1\u67b6\u6784\u3002", "method": "\u4f7f\u7528\u5feb\u901f\u65f6\u5e8fTransformer\uff08\u57fa\u4e8eFFT\u7ebf\u6027\u5316\u6ce8\u610f\u529b\u7684\u8f7b\u91cf\u7ea7Transformer\u53d8\u4f53\uff09\u4e0eGRU\u5c42\u7ed3\u5408\u7684\u6df7\u5408\u6a21\u578b\uff0c\u9996\u6b21\u5c06FTT\u4e0eGRU\u5e94\u7528\u4e8eRUL\u9884\u6d4b\u3002", "result": "\u5728CMAPSS FD001\u4e0a\u83b7\u5f97RMSE 30.76\u3001MAE 18.97\u3001R\u00b2=0.45\uff0cCPU\u5ef6\u8fdf1.12ms\uff0c\u76f8\u6bd4\u6700\u4f73\u6df1\u5ea6\u57fa\u7ebfTCN-Attention\uff0cRMSE\u63d0\u53471.16%\uff0cMAE\u63d0\u53474.00%\u3002", "conclusion": "\u7d27\u51d1\u7684Transformer-RNN\u6df7\u5408\u6a21\u578b\u80fd\u591f\u5728CMAPSS\u4e0a\u63d0\u4f9b\u51c6\u786e\u9ad8\u6548\u7684RUL\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5de5\u4e1a\u9884\u6d4b\u6027\u7ef4\u62a4\u3002"}}
{"id": "2511.00574", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00574", "abs": "https://arxiv.org/abs/2511.00574", "authors": ["Yinghuan Zhang", "Yufei Zhang", "Parisa Kordjamshidi", "Zijun Cui"], "title": "Bayesian Network Structure Discovery Using Large Language Models", "comment": null, "summary": "Understanding probabilistic relationships among variables is crucial for\nanalyzing complex systems. Traditional structure learning methods often require\nextensive observational data and incur high computational costs. Recent studies\nhave explored using large language models (LLMs) for structure learning, but\nmost treat LLMs as auxiliary tools for pre-processing or post-processing,\nleaving the core learning process data-driven. In this work, we propose a\nunified framework for Bayesian network structure discovery that places LLMs at\nthe center, supporting both data-free and data-aware settings. In the data-free\ncase, we introduce \\textbf{PromptBN} to query LLMs with metadata and\nefficiently uncover valid probabilistic relationships. When observational data\nare available, we introduce \\textbf{ReActBN}, which integrates the ReAct\nreasoning paradigm with structure scores such as the Bayesian Information\nCriterion (BIC) for iterative refinement. Unlike prior methods that offload\nrefinement to external algorithms, our framework maintains the LLM actively in\nthe loop throughout the discovery process. Experiments demonstrate that our\nmethod significantly outperforms both existing LLM-based approaches and\ntraditional data-driven algorithms, particularly in the low- or no-data\nscenario. Code is publicly available at\n{\\texttt{\\textcolor{magenta}{https://github.com/sherryzyh/prompt2bn}}}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u7ed3\u6784\u53d1\u73b0\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7f6e\u4e8e\u6838\u5fc3\u4f4d\u7f6e\uff0c\u652f\u6301\u65e0\u6570\u636e\u548c\u6709\u6570\u636e\u4e24\u79cd\u573a\u666f\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u89c2\u6d4b\u6570\u636e\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u4ec5\u5c06\u5176\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u672a\u5145\u5206\u53d1\u6325\u5176\u6838\u5fc3\u4f5c\u7528\u3002", "method": "\u63d0\u51faPromptBN\uff08\u65e0\u6570\u636e\u573a\u666f\uff09\u548cReActBN\uff08\u6709\u6570\u636e\u573a\u666f\uff09\u4e24\u4e2a\u65b9\u6cd5\uff0c\u524d\u8005\u901a\u8fc7\u5143\u6570\u636e\u67e5\u8be2LLM\u53d1\u73b0\u6982\u7387\u5173\u7cfb\uff0c\u540e\u8005\u7ed3\u5408ReAct\u63a8\u7406\u8303\u5f0f\u4e0e\u7ed3\u6784\u8bc4\u5206\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u6216\u65e0\u6570\u636e\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLM\u65b9\u6cd5\u548c\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u7b97\u6cd5\u3002", "conclusion": "\u5c06LLM\u7f6e\u4e8e\u7ed3\u6784\u5b66\u4e60\u6838\u5fc3\u4f4d\u7f6e\u7684\u6709\u6548\u6027\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e3a\u6982\u7387\u5173\u7cfb\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00579", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00579", "abs": "https://arxiv.org/abs/2511.00579", "authors": ["G. Pillonetto", "A. Giaretta", "A. Aravkin", "M. Bisiacco", "T. Elston"], "title": "Sparse and nonparametric estimation of equations governing dynamical systems with applications to biology", "comment": null, "summary": "Data-driven discovery of model equations is a powerful approach for\nunderstanding the behavior of dynamical systems in many scientific fields. In\nparticular, the ability to learn mathematical models from data would benefit\nsystems biology, where the complex nature of these systems often makes a bottom\nup approach to modeling unfeasible. In recent years, sparse estimation\ntechniques have gained prominence in system identification, primarily using\nparametric paradigms to efficiently capture system dynamics with minimal model\ncomplexity. In particular, the Sindy algorithm has successfully used sparsity\nto estimate nonlinear systems by extracting from a library of functions only a\nfew key terms needed to capture the dynamics of these systems. However,\nparametric models often fall short in accurately representing certain\nnonlinearities inherent in complex systems. To address this limitation, we\nintroduce a novel framework that integrates sparse parametric estimation with\nnonparametric techniques. It captures nonlinearities that Sindy cannot describe\nwithout requiring a priori information about their functional form. That is,\nwithout expanding the library of functions to include the one that is trying to\nbe discovered. We illustrate our approach on several examples related to\nestimation of complex biological phenomena.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7a00\u758f\u53c2\u6570\u4f30\u8ba1\u548c\u975e\u53c2\u6570\u6280\u672f\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u590d\u6742\u7cfb\u7edf\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7cfb\u7edf\u751f\u7269\u5b66\u4e2d\u96be\u4ee5\u901a\u8fc7\u81ea\u4e0b\u800c\u4e0a\u65b9\u6cd5\u5efa\u6a21\u7684\u60c5\u51b5\u3002", "motivation": "\u4f20\u7edf\u53c2\u6570\u6a21\u578b\u5728\u51c6\u786e\u8868\u793a\u590d\u6742\u7cfb\u7edf\u7684\u67d0\u4e9b\u975e\u7ebf\u6027\u7279\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u800cSindy\u7b49\u7a00\u758f\u4f30\u8ba1\u65b9\u6cd5\u867d\u7136\u80fd\u6709\u6548\u6355\u6349\u7cfb\u7edf\u52a8\u6001\uff0c\u4f46\u9700\u8981\u9884\u5148\u77e5\u9053\u975e\u7ebf\u6027\u51fd\u6570\u5f62\u5f0f\u6216\u6269\u5c55\u51fd\u6570\u5e93\u3002", "method": "\u5c06\u7a00\u758f\u53c2\u6570\u4f30\u8ba1\u4e0e\u975e\u53c2\u6570\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u65e0\u9700\u9884\u5148\u4e86\u89e3\u975e\u7ebf\u6027\u51fd\u6570\u5f62\u5f0f\u6216\u6269\u5c55\u51fd\u6570\u5e93\uff0c\u5c31\u80fd\u6355\u6349Sindy\u65e0\u6cd5\u63cf\u8ff0\u7684\u975e\u7ebf\u6027\u7279\u6027\u3002", "result": "\u5728\u591a\u4e2a\u4e0e\u590d\u6742\u751f\u7269\u73b0\u8c61\u4f30\u8ba1\u76f8\u5173\u7684\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8868\u793a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u975e\u7ebf\u6027\u7279\u6027\uff0c\u4e3a\u7cfb\u7edf\u751f\u7269\u5b66\u7b49\u9886\u57df\u7684\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2511.00588", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00588", "abs": "https://arxiv.org/abs/2511.00588", "authors": ["Dong Chen", "Yanzhe Wei", "Zonglin He", "Guan-Ming Kuang", "Canhua Ye", "Meiru An", "Huili Peng", "Yong Hu", "Huiren Tao", "Kenneth MC Cheung"], "title": "Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation", "comment": null, "summary": "Large language models (LLMs) offer transformative potential for clinical\ndecision support in spine surgery but pose significant risks through\nhallucinations, which are factually inconsistent or contextually misaligned\noutputs that may compromise patient safety. This study introduces a\nclinician-centered framework to quantify hallucination risks by evaluating\ndiagnostic precision, recommendation quality, reasoning robustness, output\ncoherence, and knowledge alignment. We assessed six leading LLMs across 30\nexpert-validated spinal cases. DeepSeek-R1 demonstrated superior overall\nperformance (total score: 86.03 $\\pm$ 2.08), particularly in high-stakes\ndomains such as trauma and infection. A critical finding reveals that\nreasoning-enhanced model variants did not uniformly outperform standard\ncounterparts: Claude-3.7-Sonnet's extended thinking mode underperformed\nrelative to its standard version (80.79 $\\pm$ 1.83 vs. 81.56 $\\pm$ 1.92),\nindicating extended chain-of-thought reasoning alone is insufficient for\nclinical reliability. Multidimensional stress-testing exposed model-specific\nvulnerabilities, with recommendation quality degrading by 7.4% under amplified\ncomplexity. This decline contrasted with marginal improvements in rationality\n(+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning\ndivergence between perceived coherence and actionable guidance. Our findings\nadvocate integrating interpretability mechanisms (e.g., reasoning chain\nvisualization) into clinical workflows and establish a safety-aware validation\nframework for surgical LLM deployment.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e866\u4e2a\u9886\u5148\u5927\u8bed\u8a00\u6a21\u578b\u5728\u810a\u67f1\u5916\u79d1\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u5e7b\u89c9\u98ce\u9669\uff0c\u53d1\u73b0DeepSeek-R1\u8868\u73b0\u6700\u4f73\uff0c\u800c\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u6807\u51c6\u7248\u672c\uff0c\u5f3a\u8c03\u9700\u8981\u5c06\u53ef\u89e3\u91ca\u6027\u673a\u5236\u6574\u5408\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u810a\u67f1\u5916\u79d1\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\uff0c\u53ef\u80fd\u5371\u53ca\u60a3\u8005\u5b89\u5168\uff0c\u9700\u8981\u91cf\u5316\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "\u91c7\u7528\u4e34\u5e8a\u533b\u751f\u4e2d\u5fc3\u6846\u67b6\uff0c\u8bc4\u4f30\u8bca\u65ad\u7cbe\u5ea6\u3001\u63a8\u8350\u8d28\u91cf\u3001\u63a8\u7406\u7a33\u5065\u6027\u3001\u8f93\u51fa\u4e00\u81f4\u6027\u548c\u77e5\u8bc6\u5bf9\u9f50\uff0c\u572830\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u810a\u67f1\u75c5\u4f8b\u4e0a\u6d4b\u8bd56\u4e2a\u9886\u5148LLM\u3002", "result": "DeepSeek-R1\u603b\u4f53\u8868\u73b0\u6700\u4f73\uff08\u603b\u5206\uff1a86.03\u00b12.08\uff09\uff0c\u5728\u521b\u4f24\u548c\u611f\u67d3\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u8868\u73b0\u7a81\u51fa\u3002\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u53d8\u4f53\u5e76\u672a\u4e00\u81f4\u4f18\u4e8e\u6807\u51c6\u7248\u672c\uff0c\u591a\u7ef4\u538b\u529b\u6d4b\u8bd5\u66b4\u9732\u4e86\u6a21\u578b\u7279\u5b9a\u8106\u5f31\u6027\u3002", "conclusion": "\u9700\u8981\u5c06\u53ef\u89e3\u91ca\u6027\u673a\u5236\u6574\u5408\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u5e76\u5efa\u7acb\u5b89\u5168\u611f\u77e5\u7684\u9a8c\u8bc1\u6846\u67b6\u7528\u4e8e\u5916\u79d1LLM\u90e8\u7f72\u3002"}}
{"id": "2511.00615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00615", "abs": "https://arxiv.org/abs/2511.00615", "authors": ["Daniel Griffiths", "Piper Moskow"], "title": "Gaining Momentum: Uncovering Hidden Scoring Dynamics in Hockey through Deep Neural Sequencing and Causal Modeling", "comment": "5 Pages, 4 Figures, 2 Tables", "summary": "We present a unified, data-driven framework for quantifying and enhancing\noffensive momentum and scoring likelihood (expected goals, xG) in professional\nhockey. Leveraging a Sportlogiq dataset of 541,000 NHL event records, our\nend-to-end pipeline comprises five stages: (1) interpretable momentum weighting\nof micro-events via logistic regression; (2) nonlinear xG estimation using\ngradient-boosted decision trees; (3) temporal sequence modeling with Long\nShort-Term Memory (LSTM) networks; (4) spatial formation discovery through\nprincipal component analysis (PCA) followed by K-Means clustering on\nstandardized player coordinates; and (5) use of an X-Learner causal inference\nestimator to quantify the average treatment effect (ATE) of adopting the\nidentified \"optimal\" event sequences and formations. We observe an ATE of 0.12\n(95% CI: 0.05-0.17, p < 1e-50), corresponding to a 15% relative gain in scoring\npotential. These results demonstrate that strategically structured sequences\nand compact formations causally elevate offensive performance. Our framework\ndelivers real-time, actionable insights for coaches and analysts, advancing\nhockey analytics toward principled, causally grounded tactical optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u9636\u6bb5\u91cf\u5316\u5e76\u589e\u5f3a\u51b0\u7403\u6bd4\u8d5b\u4e2d\u7684\u8fdb\u653b\u52bf\u5934\u548c\u5f97\u5206\u53ef\u80fd\u6027\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u5e8f\u5217\u548c\u7d27\u51d1\u9635\u578b\u80fd\u663e\u8457\u63d0\u5347\u8fdb\u653b\u8868\u73b0\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u6559\u7ec3\u548c\u5206\u6790\u5e08\u63d0\u4f9b\u5b9e\u65f6\u3001\u53ef\u64cd\u4f5c\u7684\u6218\u672f\u4f18\u5316\u89c1\u89e3\uff0c\u63a8\u52a8\u51b0\u7403\u5206\u6790\u5411\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u539f\u5219\u6027\u6218\u672f\u4f18\u5316\u53d1\u5c55\u3002", "method": "\u4e94\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u901a\u8fc7\u903b\u8f91\u56de\u5f52\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u52a8\u91cf\u52a0\u6743\uff1b2) \u4f7f\u7528\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u8fdb\u884c\u975e\u7ebf\u6027xG\u4f30\u8ba1\uff1b3) LSTM\u7f51\u7edc\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\uff1b4) PCA\u548cK-Means\u805a\u7c7b\u53d1\u73b0\u7a7a\u95f4\u9635\u578b\uff1b5) X-Learner\u56e0\u679c\u63a8\u65ad\u4f30\u8ba1\u5668\u91cf\u5316\u6700\u4f18\u5e8f\u5217\u548c\u9635\u578b\u7684\u5e73\u5747\u5904\u7406\u6548\u5e94\u3002", "result": "\u89c2\u5bdf\u5230ATE\u4e3a0.12\uff0895% CI: 0.05-0.17, p < 1e-50\uff09\uff0c\u76f8\u5f53\u4e8e\u5f97\u5206\u6f5c\u529b\u76f8\u5bf9\u63d0\u534715%\uff0c\u8bc1\u660e\u7ed3\u6784\u5316\u5e8f\u5217\u548c\u7d27\u51d1\u9635\u578b\u80fd\u56e0\u679c\u6027\u5730\u63d0\u5347\u8fdb\u653b\u8868\u73b0\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6559\u7ec3\u548c\u5206\u6790\u5e08\u63d0\u4f9b\u5b9e\u65f6\u3001\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5c06\u51b0\u7403\u5206\u6790\u63a8\u5411\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u539f\u5219\u6027\u6218\u672f\u4f18\u5316\uff0c\u8bc1\u660e\u4e86\u6218\u7565\u7ed3\u6784\u5316\u7684\u6bd4\u8d5b\u5e8f\u5217\u548c\u9635\u578b\u5bf9\u63d0\u5347\u8fdb\u653b\u6548\u679c\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.00617", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00617", "abs": "https://arxiv.org/abs/2511.00617", "authors": ["Eric Bigelow", "Daniel Wurgaft", "YingQiao Wang", "Noah Goodman", "Tomer Ullman", "Hidenori Tanaka", "Ekdeep Singh Lubana"], "title": "Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering", "comment": null, "summary": "Large language models (LLMs) can be controlled at inference time through\nprompts (in-context learning) and internal activations (activation steering).\nDifferent accounts have been proposed to explain these methods, yet their\ncommon goal of controlling model behavior raises the question of whether these\nseemingly disparate methodologies can be seen as specific instances of a\nbroader framework. Motivated by this, we develop a unifying, predictive account\nof LLM control from a Bayesian perspective. Specifically, we posit that both\ncontext- and activation-based interventions impact model behavior by altering\nits belief in latent concepts: steering operates by changing concept priors,\nwhile in-context learning leads to an accumulation of evidence. This results in\na closed-form Bayesian model that is highly predictive of LLM behavior across\ncontext- and activation-based interventions in a set of domains inspired by\nprior work on many-shot in-context learning. This model helps us explain prior\nempirical phenomena - e.g., sigmoidal learning curves as in-context evidence\naccumulates - while predicting novel ones - e.g., additivity of both\ninterventions in log-belief space, which results in distinct phases such that\nsudden and dramatic behavioral shifts can be induced by slightly changing\nintervention controls. Taken together, this work offers a unified account of\nprompt-based and activation-based control of LLM behavior, and a methodology\nfor empirically predicting the effects of these interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8d1d\u53f6\u65af\u6846\u67b6\u6765\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e24\u79cd\u63a7\u5236\u65b9\u6cd5\uff1a\u63d0\u793a\u5b66\u4e60\u548c\u6fc0\u6d3b\u5f15\u5bfc\uff0c\u8ba4\u4e3a\u5b83\u4eec\u90fd\u662f\u901a\u8fc7\u6539\u53d8\u6a21\u578b\u5bf9\u6f5c\u5728\u6982\u5ff5\u7684\u4fe1\u5ff5\u6765\u5b9e\u73b0\u63a7\u5236\u7684\u3002", "motivation": "\u73b0\u6709\u7684LLM\u63a7\u5236\u65b9\u6cd5\uff08\u63d0\u793a\u5b66\u4e60\u548c\u6fc0\u6d3b\u5f15\u5bfc\uff09\u867d\u7136\u770b\u4f3c\u4e0d\u540c\uff0c\u4f46\u90fd\u65e8\u5728\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5171\u540c\u673a\u5236\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u51fa\u53d1\uff0c\u5c06\u63d0\u793a\u5b66\u4e60\u89c6\u4e3a\u8bc1\u636e\u79ef\u7d2f\u8fc7\u7a0b\uff0c\u5c06\u6fc0\u6d3b\u5f15\u5bfc\u89c6\u4e3a\u6539\u53d8\u6982\u5ff5\u5148\u9a8c\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u95ed\u5f0f\u8d1d\u53f6\u65af\u6a21\u578b\u6765\u9884\u6d4bLLM\u884c\u4e3a\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u591f\u51c6\u786e\u9884\u6d4bLLM\u5728\u591a\u79cd\u5e72\u9884\u4e0b\u7684\u884c\u4e3a\uff0c\u5305\u62ec\u89e3\u91caS\u578b\u5b66\u4e60\u66f2\u7ebf\u7b49\u5df2\u77e5\u73b0\u8c61\uff0c\u5e76\u9884\u6d4b\u4e86\u65b0\u7684\u73b0\u8c61\u5982\u5bf9\u6570\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\u7684\u5e72\u9884\u53ef\u52a0\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u63d0\u793a\u548c\u57fa\u4e8e\u6fc0\u6d3b\u7684LLM\u884c\u4e3a\u63a7\u5236\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u4e86\u9884\u6d4b\u8fd9\u4e9b\u5e72\u9884\u6548\u679c\u7684\u7ecf\u9a8c\u65b9\u6cd5\u3002"}}
{"id": "2511.00637", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00637", "abs": "https://arxiv.org/abs/2511.00637", "authors": ["Emmeran Johnson", "Alberto Rumi", "Ciara Pike-Burke", "Patrick Rebeschini"], "title": "Stochastic Shortest Path with Sparse Adversarial Costs", "comment": null, "summary": "We study the adversarial Stochastic Shortest Path (SSP) problem with sparse\ncosts under full-information feedback. In the known transition setting,\nexisting bounds based on Online Mirror Descent (OMD) with negative-entropy\nregularization scale with $\\sqrt{\\log S A}$, where $SA$ is the size of the\nstate-action space. While we show that this is optimal in the worst-case, this\nbound fails to capture the benefits of sparsity when only a small number $M \\ll\nSA$ of state-action pairs incur cost. In fact, we also show that the\nnegative-entropy is inherently non-adaptive to sparsity: it provably incurs\nregret scaling with $\\sqrt{\\log S}$ on sparse problems. Instead, we propose a\nfamily of $\\ell_r$-norm regularizers ($r \\in (1,2)$) that adapts to the\nsparsity and achieves regret scaling with $\\sqrt{\\log M}$ instead of\n$\\sqrt{\\log SA}$. We show this is optimal via a matching lower bound,\nhighlighting that $M$ captures the effective dimension of the problem instead\nof $SA$. Finally, in the unknown transition setting the benefits of sparsity\nare limited: we prove that even on sparse problems, the minimax regret for any\nlearner scales polynomially with $SA$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u7a00\u758f\u6210\u672c\u7684\u5bf9\u6297\u6027\u968f\u673a\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u2113_r-\u8303\u6570\u6b63\u5219\u5316\u5668\u6765\u9002\u5e94\u7a00\u758f\u6027\uff0c\u5728\u5df2\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u221alog M\u6210\u6bd4\u4f8b\u7684\u9057\u61be\uff0c\u800c\u4e0d\u662f\u221alog SA\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8d1f\u71b5\u6b63\u5219\u5316\u7684\u5728\u7ebf\u955c\u50cf\u4e0b\u964d\u65b9\u6cd5\u5728\u5df2\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\u7684\u9057\u61be\u8fb9\u754c\u4e0e\u221alog SA\u6210\u6bd4\u4f8b\uff0c\u8fd9\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7a00\u758f\u6027\u5e26\u6765\u7684\u597d\u5904\uff0c\u5f53\u53ea\u6709\u5c11\u91cf\u72b6\u6001-\u52a8\u4f5c\u5bf9\u4ea7\u751f\u6210\u672c\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u65cf\u2113_r-\u8303\u6570\u6b63\u5219\u5316\u5668\uff08r\u2208(1,2)\uff09\uff0c\u8fd9\u4e9b\u6b63\u5219\u5316\u5668\u80fd\u591f\u9002\u5e94\u95ee\u9898\u7684\u7a00\u758f\u6027\uff0c\u5728\u5df2\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\u4f7f\u7528\u8fd9\u4e9b\u6b63\u5219\u5316\u5668\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u5df2\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\uff0c\u65b0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e0e\u221alog M\u6210\u6bd4\u4f8b\u7684\u9057\u61be\uff0c\u800c\u4e0d\u662f\u221alog SA\uff0c\u5176\u4e2dM\u662f\u4ea7\u751f\u6210\u672c\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u6570\u91cf\uff0c\u8fd9\u901a\u8fc7\u5339\u914d\u4e0b\u754c\u8bc1\u660e\u662f\u6700\u4f18\u7684\u3002\u5728\u672a\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\uff0c\u7a00\u758f\u6027\u7684\u597d\u5904\u6709\u9650\uff0c\u4efb\u4f55\u5b66\u4e60\u8005\u7684\u6781\u5c0f\u6781\u5927\u9057\u61be\u90fd\u4e0eSA\u6210\u591a\u9879\u5f0f\u5173\u7cfb\u3002", "conclusion": "\u2113_r-\u8303\u6570\u6b63\u5219\u5316\u5668\u80fd\u591f\u6709\u6548\u9002\u5e94\u7a00\u758f\u6210\u672c\u95ee\u9898\uff0cM\u800c\u975eSA\u6355\u83b7\u4e86\u95ee\u9898\u7684\u6709\u6548\u7ef4\u5ea6\uff0c\u4f46\u5728\u672a\u77e5\u8f6c\u79fb\u8bbe\u7f6e\u4e0b\u7a00\u758f\u6027\u7684\u597d\u5904\u53d7\u5230\u9650\u5236\u3002"}}
{"id": "2511.00648", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00648", "abs": "https://arxiv.org/abs/2511.00648", "authors": ["C. D\u00edaz-Faloh", "R. Mulet"], "title": "Diluting Restricted Boltzmann Machines", "comment": null, "summary": "Recent advances in artificial intelligence have relied heavily on\nincreasingly large neural networks, raising concerns about their computational\nand environmental costs. This paper investigates whether simpler, sparser\nnetworks can maintain strong performance by studying Restricted Boltzmann\nMachines (RBMs) under extreme pruning conditions. Inspired by the Lottery\nTicket Hypothesis, we demonstrate that RBMs can achieve high-quality generative\nperformance even when up to 80% of the connections are pruned before training,\nconfirming that they contain viable sub-networks. However, our experiments\nreveal crucial limitations: trained networks cannot fully recover lost\nperformance through retraining once additional pruning is applied. We identify\na sharp transition above which the generative quality degrades abruptly when\npruning disrupts a minimal core of essential connections. Moreover, re-trained\nnetworks remain constrained by the parameters originally learned performing\nworse than networks trained from scratch at equivalent sparsity levels. These\nresults suggest that for sparse networks to work effectively, pruning should be\nimplemented early in training rather than attempted afterwards. Our findings\nprovide practical insights for the development of efficient neural\narchitectures and highlight the persistent influence of initial conditions on\nnetwork capabilities.", "AI": {"tldr": "\u7814\u7a76\u8868\u660eRBMs\u5728\u8bad\u7ec3\u524d\u526a\u679d80%\u4ecd\u80fd\u4fdd\u6301\u826f\u597d\u751f\u6210\u6027\u80fd\uff0c\u4f46\u8bad\u7ec3\u540e\u526a\u679d\u4f1a\u5bfc\u81f4\u6027\u80fd\u65e0\u6cd5\u5b8c\u5168\u6062\u590d\uff0c\u4e14\u91cd\u8bad\u7ec3\u7f51\u7edc\u8868\u73b0\u4e0d\u5982\u4ece\u5934\u8bad\u7ec3\u7684\u7a00\u758f\u7f51\u7edc\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u548c\u73af\u5883\u6210\u672c\u95ee\u9898\uff0c\u63a2\u7d22\u66f4\u7b80\u5355\u7a00\u758f\u7684\u7f51\u7edc\u662f\u5426\u80fd\u4fdd\u6301\u5f3a\u6027\u80fd\uff0c\u53d7\u5f69\u7968\u5047\u8bbe\u542f\u53d1\u7814\u7a76RBMs\u5728\u6781\u7aef\u526a\u679d\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5728\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a(RBMs)\u4e0a\u8fdb\u884c\u6781\u7aef\u526a\u679d\u5b9e\u9a8c\uff0c\u7814\u7a76\u8bad\u7ec3\u524d\u526a\u679d\u548c\u8bad\u7ec3\u540e\u526a\u679d\u7684\u6548\u679c\u5dee\u5f02\uff0c\u5206\u6790\u5173\u952e\u8fde\u63a5\u88ab\u7834\u574f\u65f6\u7684\u6027\u80fd\u53d8\u5316\u3002", "result": "RBMs\u5728\u8bad\u7ec3\u524d\u526a\u679d80%\u4ecd\u80fd\u4fdd\u6301\u9ad8\u8d28\u91cf\u751f\u6210\u6027\u80fd\uff0c\u4f46\u8bad\u7ec3\u540e\u526a\u679d\u4f1a\u5bfc\u81f4\u6027\u80fd\u6025\u5267\u4e0b\u964d\u4e14\u65e0\u6cd5\u901a\u8fc7\u91cd\u8bad\u7ec3\u5b8c\u5168\u6062\u590d\uff0c\u91cd\u8bad\u7ec3\u7f51\u7edc\u8868\u73b0\u4e0d\u5982\u4ece\u5934\u8bad\u7ec3\u7684\u540c\u7b49\u7a00\u758f\u7f51\u7edc\u3002", "conclusion": "\u7a00\u758f\u7f51\u7edc\u8981\u6709\u6548\u5de5\u4f5c\uff0c\u526a\u679d\u5e94\u5728\u8bad\u7ec3\u65e9\u671f\u5b9e\u65bd\u800c\u975e\u8bad\u7ec3\u540e\u5c1d\u8bd5\uff0c\u521d\u59cb\u6761\u4ef6\u5bf9\u7f51\u7edc\u80fd\u529b\u6709\u6301\u4e45\u5f71\u54cd\u3002"}}
{"id": "2511.00655", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00655", "abs": "https://arxiv.org/abs/2511.00655", "authors": ["Baris Askin", "Holger R. Roth", "Zhenyu Sun", "Carlee Joe-Wong", "Gauri Joshi", "Ziyue Xu"], "title": "Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning", "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, yet its scalability is limited by\nsynchronization overhead. Asynchronous Federated Learning (AFL) alleviates this\nissue by allowing clients to communicate independently, thereby improving\nwall-clock efficiency in large-scale, heterogeneous environments. However, this\nasynchrony introduces stale updates (client updates computed on outdated global\nmodels) that can destabilize optimization and hinder convergence. We propose\nFedRevive, an asynchronous FL framework that revives stale updates through\ndata-free knowledge distillation (DFKD). FedRevive integrates parameter-space\naggregation with a lightweight, server-side DFKD process that transfers\nknowledge from stale client models to the current global model without access\nto real or public data. A meta-learned generator synthesizes pseudo-samples,\nwhich enables multi-teacher distillation. A hybrid aggregation scheme that\ncombines raw updates with DFKD updates effectively mitigates staleness while\nretaining the scalability of AFL. Experiments on various vision and text\nbenchmarks show that FedRevive achieves faster training up to 32.1% and higher\nfinal accuracy up to 21.5% compared to asynchronous baselines.", "AI": {"tldr": "FedRevive\u662f\u4e00\u4e2a\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u6570\u636e\u77e5\u8bc6\u84b8\u998f\u6765\u7f13\u89e3\u9648\u65e7\u66f4\u65b0\u95ee\u9898\uff0c\u5728\u4fdd\u6301AFL\u53ef\u6269\u5c55\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u548c\u6700\u7ec8\u7cbe\u5ea6\u3002", "motivation": "\u5f02\u6b65\u8054\u90a6\u5b66\u4e60(AFL)\u867d\u7136\u901a\u8fc7\u72ec\u7acb\u901a\u4fe1\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u5f02\u6784\u73af\u5883\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u4f46\u5f02\u6b65\u6027\u5f15\u5165\u4e86\u9648\u65e7\u66f4\u65b0\uff08\u57fa\u4e8e\u8fc7\u65f6\u5168\u5c40\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\uff09\uff0c\u8fd9\u4f1a\u7834\u574f\u4f18\u5316\u7a33\u5b9a\u6027\u5e76\u963b\u788d\u6536\u655b\u3002", "method": "FedRevive\u7ed3\u5408\u53c2\u6570\u7a7a\u95f4\u805a\u5408\u4e0e\u8f7b\u91cf\u7ea7\u670d\u52a1\u5668\u7aef\u65e0\u6570\u636e\u77e5\u8bc6\u84b8\u998f(DFKD)\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u751f\u6210\u5668\u5408\u6210\u4f2a\u6837\u672c\u5b9e\u73b0\u591a\u6559\u5e08\u84b8\u998f\uff0c\u91c7\u7528\u6df7\u5408\u805a\u5408\u65b9\u6848\u7ed3\u5408\u539f\u59cb\u66f4\u65b0\u548cDFKD\u66f4\u65b0\u3002", "result": "\u5728\u5404\u79cd\u89c6\u89c9\u548c\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedRevive\u76f8\u6bd4\u5f02\u6b65\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe32.1%\uff0c\u6700\u7ec8\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe21.5%\u3002", "conclusion": "FedRevive\u901a\u8fc7\u65e0\u6570\u636e\u77e5\u8bc6\u84b8\u998f\u6709\u6548\u7f13\u89e3\u4e86\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9648\u65e7\u66f4\u65b0\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.00663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00663", "abs": "https://arxiv.org/abs/2511.00663", "authors": ["Alex Dobra", "Jakiw Pidstrigach", "Tim Reichelt", "Paolo Fraccaro", "Johannes Jakubik", "Anne Jones", "Christian Schroeder de Witt", "Philip Stier", "Philip Torr"], "title": "Sensitivity Analysis for Climate Science with Generative Flow Models", "comment": null, "summary": "Sensitivity analysis is a cornerstone of climate science, essential for\nunderstanding phenomena ranging from storm intensity to long-term climate\nfeedbacks. However, computing these sensitivities using traditional physical\nmodels is often prohibitively expensive in terms of both computation and\ndevelopment time. While modern AI-based generative models are orders of\nmagnitude faster to evaluate, computing sensitivities with them remains a\nsignificant bottleneck. This work addresses this challenge by applying the\nadjoint state method for calculating gradients in generative flow models, with\ndiffusion models as a special case. We apply this method to the cBottle\ngenerative model, an emulator of ERA5 data, to perform sensitivity analysis\nwith respect to sea surface temperatures. Furthermore, we propose a novel\ngradient self-consistency check to quantitatively validate the computed\nsensitivities against the model's own outputs. Our results provide initial\nevidence that this approach can produce reliable gradients, reducing the\ncomputational cost of sensitivity analysis from weeks on a supercomputer with a\nphysical model to hours on a GPU, thereby simplifying a critical workflow in\nclimate science.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u4f34\u968f\u72b6\u6001\u65b9\u6cd5\u8ba1\u7b97\u751f\u6210\u6d41\u6a21\u578b\uff08\u7279\u522b\u662f\u6269\u6563\u6a21\u578b\uff09\u7684\u68af\u5ea6\uff0c\u7528\u4e8e\u6c14\u5019\u654f\u611f\u6027\u5206\u6790\uff0c\u5c06\u8ba1\u7b97\u6210\u672c\u4ece\u6570\u5468\u5927\u5e45\u964d\u4f4e\u5230\u6570\u5c0f\u65f6\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u6a21\u578b\u8ba1\u7b97\u6c14\u5019\u654f\u611f\u6027\u6210\u672c\u8fc7\u9ad8\uff0c\u800cAI\u751f\u6210\u6a21\u578b\u867d\u7136\u8bc4\u4f30\u901f\u5ea6\u5feb\uff0c\u4f46\u8ba1\u7b97\u654f\u611f\u6027\u4ecd\u662f\u74f6\u9888\u3002", "method": "\u5e94\u7528\u4f34\u968f\u72b6\u6001\u65b9\u6cd5\u8ba1\u7b97\u751f\u6210\u6d41\u6a21\u578b\u7684\u68af\u5ea6\uff0c\u4ee5\u6269\u6563\u6a21\u578b\u4e3a\u7279\u4f8b\uff0c\u5728cBottle\u751f\u6210\u6a21\u578b\u4e0a\u8fdb\u884c\u6d77\u8868\u6e29\u5ea6\u654f\u611f\u6027\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u68af\u5ea6\u81ea\u4e00\u81f4\u6027\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u4ea7\u751f\u53ef\u9760\u7684\u68af\u5ea6\uff0c\u5c06\u654f\u611f\u6027\u5206\u6790\u7684\u8ba1\u7b97\u6210\u672c\u4ece\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u7684\u6570\u5468\u964d\u4f4e\u5230GPU\u4e0a\u7684\u6570\u5c0f\u65f6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u6c14\u5019\u79d1\u5b66\u4e2d\u7684\u5173\u952e\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e3a\u53ef\u9760\u7684\u6c14\u5019\u654f\u611f\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00699", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00699", "abs": "https://arxiv.org/abs/2511.00699", "authors": ["Sophie Li", "Nicholas Huang", "Nayan Saxena", "Nina Luo", "Vincent Lin", "Kevin Zhu", "Sunishchal Dev"], "title": "Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals", "comment": null, "summary": "Large language models (LLMs) improve reasoning accuracy when generating\nmultiple candidate solutions at test time, but standard methods like Best-of-N\n(BoN) incur high computational cost by fully generating all branches.\nSelf-Truncation Best-of-N (ST-BoN) mitigates this by truncating unpromising\npaths early, but its reliance on consistency-based heuristics is a limitation\nas it does not directly evaluate branch quality. We present KL-Adjusted Pruned\nPath Algorithm (KAPPA), an inference-time method that combines Kullback-Leibler\ndivergence, confidence, and entropy into a principled scoring function to guide\nprogressive pruning. By promoting diversity during exploration and selectively\neliminating low-scoring branches, KAPPA maintains accuracy while substantially\nreducing memory and token usage. Experiments on GSM8K and MATH500 with\nDeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct demonstrate that KAPPA\nstabilizes performance in smaller models and achieves up to ~60% reduction in\npeak memory and ~90% reduction in total token generation relative to BoN, with\nminimal impact on accuracy.", "AI": {"tldr": "KAPPA\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408KL\u6563\u5ea6\u3001\u7f6e\u4fe1\u5ea6\u548c\u71b5\u7684\u8bc4\u5206\u51fd\u6570\u6765\u6307\u5bfc\u6e10\u8fdb\u5f0f\u526a\u679d\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u548ctoken\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982Best-of-N\u8ba1\u7b97\u6210\u672c\u9ad8\uff0cSelf-Truncation Best-of-N\u4f9d\u8d56\u4e00\u81f4\u6027\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4e0d\u80fd\u76f4\u63a5\u8bc4\u4f30\u5206\u652f\u8d28\u91cf\u3002", "method": "\u4f7f\u7528KL\u6563\u5ea6\u3001\u7f6e\u4fe1\u5ea6\u548c\u71b5\u6784\u5efa\u8bc4\u5206\u51fd\u6570\uff0c\u5728\u63a2\u7d22\u9636\u6bb5\u4fc3\u8fdb\u591a\u6837\u6027\uff0c\u5e76\u9009\u62e9\u6027\u6d88\u9664\u4f4e\u5206\u5206\u652f\u3002", "result": "\u5728GSM8K\u548cMATH500\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cKAPPA\u5728\u5c0f\u6a21\u578b\u4e2d\u7a33\u5b9a\u6027\u80fd\uff0c\u76f8\u6bd4BoN\u51cf\u5c11\u7ea660%\u5cf0\u503c\u5185\u5b58\u548c90%\u603btoken\u751f\u6210\uff0c\u5bf9\u51c6\u786e\u6027\u5f71\u54cd\u6700\u5c0f\u3002", "conclusion": "KAPPA\u901a\u8fc7\u539f\u5219\u6027\u8bc4\u5206\u51fd\u6570\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u548c\u63a8\u7406\u51c6\u786e\u6027\u3002"}}
{"id": "2511.00700", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00700", "abs": "https://arxiv.org/abs/2511.00700", "authors": ["Penghang Liu", "Haibei Zhu", "Eleonora Kreacic", "Svitlana Vyetrenko"], "title": "Privacy-Aware Time Series Synthesis via Public Knowledge Distillation", "comment": "Published on Transactions on Machine Learning Research (TMLR)", "summary": "Sharing sensitive time series data in domains such as finance, healthcare,\nand energy consumption, such as patient records or investment accounts, is\noften restricted due to privacy concerns. Privacy-aware synthetic time series\ngeneration addresses this challenge by enforcing noise during training,\ninherently introducing a trade-off between privacy and utility. In many cases,\nsensitive sequences is correlated with publicly available, non-sensitive\ncontextual metadata (e.g., household electricity consumption may be influenced\nby weather conditions and electricity prices). However, existing privacy-aware\ndata generation methods often overlook this opportunity, resulting in\nsuboptimal privacy-utility trade-offs. In this paper, we present Pub2Priv, a\nnovel framework for generating private time series data by leveraging\nheterogeneous public knowledge. Our model employs a self-attention mechanism to\nencode public data into temporal and feature embeddings, which serve as\nconditional inputs for a diffusion model to generate synthetic private\nsequences. Additionally, we introduce a practical metric to assess privacy by\nevaluating the identifiability of the synthetic data. Experimental results show\nthat Pub2Priv consistently outperforms state-of-the-art benchmarks in improving\nthe privacy-utility trade-off across finance, energy, and commodity trading\ndomains.", "AI": {"tldr": "Pub2Priv\u662f\u4e00\u4e2a\u5229\u7528\u5f02\u6784\u516c\u5171\u77e5\u8bc6\u751f\u6210\u79c1\u6709\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7f16\u7801\u516c\u5171\u6570\u636e\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u8f93\u5165\uff0c\u5728\u91d1\u878d\u3001\u80fd\u6e90\u548c\u5546\u54c1\u4ea4\u6613\u9886\u57df\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u5e73\u8861\u3002", "motivation": "\u5728\u91d1\u878d\u3001\u533b\u7597\u548c\u80fd\u6e90\u6d88\u8d39\u7b49\u9886\u57df\uff0c\u654f\u611f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u5171\u4eab\u5e38\u56e0\u9690\u79c1\u95ee\u9898\u53d7\u9650\u3002\u73b0\u6709\u9690\u79c1\u611f\u77e5\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u4e86\u4e0e\u516c\u5f00\u4e0a\u4e0b\u6587\u5143\u6570\u636e\u7684\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u9690\u79c1-\u6548\u7528\u6743\u8861\u4e0d\u7406\u60f3\u3002", "method": "\u4f7f\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5c06\u516c\u5171\u6570\u636e\u7f16\u7801\u4e3a\u65f6\u95f4\u548c\u7279\u5f81\u5d4c\u5165\uff0c\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u6761\u4ef6\u8f93\u5165\u6765\u751f\u6210\u5408\u6210\u79c1\u6709\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u8bc4\u4f30\u5408\u6210\u6570\u636e\u53ef\u8bc6\u522b\u6027\u7684\u9690\u79c1\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPub2Priv\u5728\u91d1\u878d\u3001\u80fd\u6e90\u548c\u5546\u54c1\u4ea4\u6613\u9886\u57df\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "conclusion": "Pub2Priv\u901a\u8fc7\u6709\u6548\u5229\u7528\u5f02\u6784\u516c\u5171\u77e5\u8bc6\uff0c\u4e3a\u9690\u79c1\u654f\u611f\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u9886\u57df\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.00704", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00704", "abs": "https://arxiv.org/abs/2511.00704", "authors": ["Morgan Lee", "Artem Frenk", "Eamon Worden", "Karish Gupta", "Thinh Pham", "Ethan Croteau", "Neil Heffernan"], "title": "Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift", "comment": "10 pages, 6 figures", "summary": "Knowledge Tracing (KT) has been an established problem in the educational\ndata mining field for decades, and it is commonly assumed that the underlying\nlearning process be- ing modeled remains static. Given the ever-changing land-\nscape of online learning platforms (OLPs), we investigate how concept drift and\nchanging student populations can im- pact student behavior within an OLP\nthrough testing model performance both within a single academic year and across\nmultiple academic years. Four well-studied KT models were applied to five\nacademic years of data to assess how suscep- tible KT models are to concept\ndrift. Through our analysis, we find that all four families of KT models can\nexhibit de- graded performance, Bayesian Knowledge Tracing (BKT) remains the\nmost stable KT model when applied to newer data, while more complex, attention\nbased models lose pre- dictive power significantly faster. To foster more\nlongitu- dinal evaluations of KT models, the data used to conduct our analysis\nis available at https://osf.io/hvfn9/?view_\nonly=b936c63dfdae4b0b987a2f0d4038f72a", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5728\u5728\u7ebf\u5b66\u4e60\u5e73\u53f0\u4e2d\u9762\u4e34\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u4f1a\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\uff0c\u5176\u4e2d\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u6700\u7a33\u5b9a\uff0c\u800c\u590d\u6742\u7684\u6ce8\u610f\u529b\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u6700\u5feb\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5047\u8bbe\u5b66\u4e60\u8fc7\u7a0b\u662f\u9759\u6001\u7684\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5728\u7ebf\u5b66\u4e60\u5e73\u53f0\u7684\u5b66\u751f\u7fa4\u4f53\u548c\u884c\u4e3a\u4f1a\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u9700\u8981\u7814\u7a76\u6982\u5ff5\u6f02\u79fb\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u7ecf\u5178\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\uff08\u5305\u62ec\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\u548c\u6ce8\u610f\u529b\u6a21\u578b\uff09\uff0c\u5728\u4e94\u5e74\u5b66\u672f\u6570\u636e\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u5355\u5b66\u5e74\u5185\u548c\u8de8\u5b66\u5e74\u7684\u6027\u80fd\u53d8\u5316\u3002", "result": "\u6240\u6709\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u90fd\u4f1a\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\uff0c\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5728\u65b0\u6570\u636e\u4e0a\u8868\u73b0\u6700\u7a33\u5b9a\uff0c\u800c\u590d\u6742\u6ce8\u610f\u529b\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u4e0b\u964d\u901f\u5ea6\u663e\u8457\u66f4\u5feb\u3002", "conclusion": "\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u6982\u5ff5\u6f02\u79fb\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u591a\u7eb5\u5411\u8bc4\u4f30\u7814\u7a76\uff0c\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5728\u53d8\u5316\u73af\u5883\u4e2d\u76f8\u5bf9\u66f4\u7a33\u5065\u3002"}}
{"id": "2511.00711", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00711", "abs": "https://arxiv.org/abs/2511.00711", "authors": ["Nardeep Kumar", "Arun Kanwar"], "title": "TRISKELION-1: Unified Descriptive-Predictive-Generative AI", "comment": "12 pages, 18 figures, submitted to arXiv (2025)", "summary": "TRISKELION-1 is a unified descriptive-predictive-generative architecture that\nintegrates statistical, mechanistic, and generative reasoning within a single\nencoder-decoder framework. The model demonstrates how descriptive\nrepresentation learning, predictive inference, and generative synthesis can be\njointly optimized using variational objectives. Experiments on MNIST validate\nthat descriptive reconstruction, predictive classification, and generative\nsampling can coexist stably within one model. The framework provides a\nblueprint toward universal intelligence architectures that connect\ninterpretability, accuracy, and creativity.", "AI": {"tldr": "TRISKELION-1\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u63cf\u8ff0-\u9884\u6d4b-\u751f\u6210\u67b6\u6784\uff0c\u5728\u5355\u4e00\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6846\u67b6\u4e2d\u6574\u5408\u4e86\u7edf\u8ba1\u3001\u673a\u5236\u548c\u751f\u6210\u63a8\u7406\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u8fde\u63a5\u53ef\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u521b\u9020\u6027\u7684\u901a\u7528\u667a\u80fd\u67b6\u6784\u84dd\u56fe\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u76ee\u6807\u8054\u5408\u4f18\u5316\u63cf\u8ff0\u6027\u8868\u793a\u5b66\u4e60\u3001\u9884\u6d4b\u63a8\u7406\u548c\u751f\u6210\u5408\u6210\uff0c\u5728MNIST\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u63cf\u8ff0\u6027\u91cd\u5efa\u3001\u9884\u6d4b\u5206\u7c7b\u548c\u751f\u6210\u91c7\u6837\u53ef\u4ee5\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u7a33\u5b9a\u5171\u5b58\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u73b0\u8fde\u63a5\u53ef\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u521b\u9020\u6027\u7684\u901a\u7528\u667a\u80fd\u67b6\u6784\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2511.00716", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00716", "abs": "https://arxiv.org/abs/2511.00716", "authors": ["Rama Kassoumeh", "David R\u00fcgamer", "Henning Oppel"], "title": "Enhancing Heavy Rain Nowcasting with Multimodal Data: Integrating Radar and Satellite Observations", "comment": "accepted to ICMLA 2025", "summary": "The increasing frequency of heavy rainfall events, which are a major cause of\nurban flooding, underscores the urgent need for accurate precipitation\nforecasting - particularly in urban areas where localized events often go\nundetected by ground-based sensors. In Germany, only 17.3% of hourly heavy rain\nevents between 2001 and 2018 were recorded by rain gauges, highlighting the\nlimitations of traditional monitoring systems. Radar data are another source\nthat effectively tracks ongoing precipitation; however, forecasting the\ndevelopment of heavy rain using radar alone remains challenging due to the\nbrief and unpredictable nature of such events. Our focus is on evaluating the\neffectiveness of fusing satellite and radar data for nowcasting. We develop a\nmultimodal nowcasting model that combines both radar and satellite imagery for\npredicting precipitation at lead times of 5, 15, and 30 minutes. We demonstrate\nthat this multimodal strategy significantly outperforms radar-only approaches.\nExperimental results show that integrating satellite data improves prediction\naccuracy, particularly for intense precipitation. The proposed model increases\nthe Critical Success Index for heavy rain by 4% and for violent rain by 3% at a\n5-minute lead time. Moreover, it maintains higher predictive skill at longer\nlead times, where radar-only performance declines. A qualitative analysis of\nthe severe flooding event in the state of North Rhine-Westphalia, Germany in\n2021 further illustrates the superior performance of the multimodal model.\nUnlike the radar-only model, which captures general precipitation patterns, the\nmultimodal model yields more detailed and accurate forecasts for regions\naffected by heavy rain. This improved precision enables timely, reliable,\nlife-saving warnings. Implementation available at\nhttps://github.com/RamaKassoumeh/Multimodal_heavy_rain", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408\u536b\u661f\u548c\u96f7\u8fbe\u6570\u636e\u7684\u591a\u6a21\u6001\u4e34\u8fd1\u9884\u62a5\u6a21\u578b\uff0c\u7528\u4e8e5-30\u5206\u949f\u964d\u6c34\u9884\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u4ec5\u4f7f\u7528\u96f7\u8fbe\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5f3a\u964d\u6c34\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u4f20\u7edf\u5730\u9762\u4f20\u611f\u5668\u96be\u4ee5\u76d1\u6d4b\u57ce\u5e02\u5c40\u90e8\u5f3a\u964d\u96e8\u4e8b\u4ef6\uff0c\u5fb7\u56fd2001-2018\u5e74\u4ec5\u670917.3%\u7684\u5c0f\u65f6\u5f3a\u964d\u96e8\u4e8b\u4ef6\u88ab\u96e8\u91cf\u8ba1\u8bb0\u5f55\uff0c\u96f7\u8fbe\u5355\u72ec\u9884\u62a5\u5f3a\u964d\u96e8\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u591a\u6a21\u6001\u4e34\u8fd1\u9884\u62a5\u6a21\u578b\uff0c\u7ed3\u5408\u96f7\u8fbe\u548c\u536b\u661f\u56fe\u50cf\u8fdb\u884c\u964d\u6c34\u9884\u6d4b\uff0c\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u4e3a5\u300115\u548c30\u5206\u949f\u3002", "result": "\u591a\u6a21\u6001\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u96f7\u8fbe\u5355\u72ec\u65b9\u6cd5\uff0c\u536b\u661f\u6570\u636e\u96c6\u6210\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5bf9\u5f3a\u964d\u6c34\u3002\u57285\u5206\u949f\u9884\u6d4b\u65f6\u95f4\uff0c\u5f3a\u964d\u96e8CSI\u63d0\u9ad84%\uff0c\u66b4\u96e8CSI\u63d0\u9ad83%\u3002\u57282021\u5e74\u5fb7\u56fd\u5317\u83b1\u8335-\u5a01\u65af\u7279\u6cd5\u4f26\u5dde\u6d2a\u6c34\u4e8b\u4ef6\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u591a\u6a21\u6001\u6a21\u578b\u80fd\u63d0\u4f9b\u66f4\u8be6\u7ec6\u51c6\u786e\u7684\u5f3a\u964d\u96e8\u533a\u57df\u9884\u62a5\uff0c\u5b9e\u73b0\u53ca\u65f6\u53ef\u9760\u7684\u6551\u751f\u9884\u8b66\u3002"}}
{"id": "2511.00747", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00747", "abs": "https://arxiv.org/abs/2511.00747", "authors": ["Zixuan Ma", "Chenfeng Huang"], "title": "Effective Series Decomposition and Components Learning for Time Series Generation", "comment": "Accepted at IEEE International Conference on Data Mining (ICDM 2025).\n  Camera-ready version to appear", "summary": "Time series generation focuses on modeling the underlying data distribution\nand resampling to produce authentic time series data. Key components, such as\ntrend and seasonality, drive temporal fluctuations, yet many existing\napproaches fail to employ interpretative decomposition methods, limiting their\nability to synthesize meaningful trend and seasonal patterns. To address this\ngap, we introduce Seasonal-Trend Diffusion (STDiffusion), a novel framework for\nmultivariate time series generation that integrates diffusion probabilistic\nmodels with advanced learnable series decomposition techniques, enhancing the\ninterpretability of the generation process. Our approach separates the trend\nand seasonal learning into distinct blocks: a Multi-Layer Perceptron (MLP)\nstructure captures the trend, while adaptive wavelet distillation facilitates\neffective multi-resolution learning of seasonal components. This decomposition\nimproves the interpretability of the model on multiple scales. In addition, we\ndesigned a comprehensive correction mechanism aimed at ensuring that the\ngenerated components exhibit a high degree of internal consistency and preserve\nmeaningful interrelationships with one another. Our empirical studies on eight\nreal-world datasets demonstrate that STDiffusion achieves state-of-the-art\nperformance in time series generation tasks. Furthermore, we extend the model's\napplication to multi-window long-sequence time series generation, which\ndelivered reliable results and highlighted its robustness and versatility.", "AI": {"tldr": "STDiffusion\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u6269\u6563\u6982\u7387\u6a21\u578b\u548c\u53ef\u5b66\u4e60\u7684\u5e8f\u5217\u5206\u89e3\u6280\u672f\uff0c\u901a\u8fc7\u5206\u522b\u5b66\u4e60\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6210\u5206\u6765\u63d0\u5347\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u5206\u89e3\u6280\u672f\uff0c\u96be\u4ee5\u5408\u6210\u6709\u610f\u4e49\u7684\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6982\u7387\u6a21\u578b\uff0c\u5c06\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u5b66\u4e60\u5206\u79bb\u5230\u4e0d\u540c\u6a21\u5757\uff1aMLP\u7ed3\u6784\u6355\u83b7\u8d8b\u52bf\uff0c\u81ea\u9002\u5e94\u5c0f\u6ce2\u84b8\u998f\u5b9e\u73b0\u5b63\u8282\u6027\u6210\u5206\u7684\u591a\u5206\u8fa8\u7387\u5b66\u4e60\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7efc\u5408\u6821\u6b63\u673a\u5236\u786e\u4fdd\u751f\u6210\u6210\u5206\u7684\u4e00\u81f4\u6027\u3002", "result": "\u57288\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTDiffusion\u5728\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u7a97\u53e3\u957f\u5e8f\u5217\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "conclusion": "STDiffusion\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u5206\u89e3\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u7684\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u65f6\u5e8f\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5f3a\u5927\u80fd\u529b\u3002"}}
{"id": "2511.00792", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.00792", "abs": "https://arxiv.org/abs/2511.00792", "authors": ["Akshay Sai Banderwaar", "Abhishek Gupta"], "title": "Fast PINN Eigensolvers via Biconvex Reformulation", "comment": "7 pages, 3 figures, Machine Learning and the Physical Sciences\n  Workshop NeurIPS 2025", "summary": "Eigenvalue problems have a distinctive forward-inverse structure and are\nfundamental to characterizing a system's thermal response, stability, and\nnatural modes. Physics-Informed Neural Networks (PINNs) offer a mesh-free\nalternative for solving such problems but are often orders of magnitude slower\nthan classical numerical schemes. In this paper, we introduce a reformulated\nPINN approach that casts the search for eigenpairs as a biconvex optimization\nproblem, enabling fast and provably convergent alternating convex search (ACS)\nover eigenvalues and eigenfunctions using analytically optimal updates.\nNumerical experiments show that PINN-ACS attains high accuracy with convergence\nspeeds up to 500$\\times$ faster than gradient-based PINN training. We release\nour codes at https://github.com/NeurIPS-ML4PS-2025/PINN_ACS_CODES.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684PINN\u65b9\u6cd5\uff0c\u5c06\u7279\u5f81\u503c\u95ee\u9898\u91cd\u6784\u4e3a\u53cc\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u4ea4\u66ff\u51f8\u641c\u7d22\u5b9e\u73b0\u5feb\u901f\u6536\u655b\uff0c\u6bd4\u4f20\u7edf\u68af\u5ea6\u8bad\u7ec3\u5feb500\u500d", "motivation": "\u4f20\u7edfPINN\u65b9\u6cd5\u6c42\u89e3\u7279\u5f81\u503c\u95ee\u9898\u901f\u5ea6\u8f83\u6162\uff0c\u6bd4\u7ecf\u5178\u6570\u503c\u65b9\u6cd5\u6162\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u7b56\u7565", "method": "\u5c06\u7279\u5f81\u503c\u95ee\u9898\u91cd\u6784\u4e3a\u53cc\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u4ea4\u66ff\u51f8\u641c\u7d22\u7b97\u6cd5\uff0c\u5bf9\u7279\u5f81\u503c\u548c\u7279\u5f81\u51fd\u6570\u5206\u522b\u8fdb\u884c\u6700\u4f18\u66f4\u65b0", "result": "PINN-ACS\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u6536\u655b\u901f\u5ea6\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684PINN\u8bad\u7ec3\u5feb500\u500d", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7279\u5f81\u503c\u95ee\u9898\u63d0\u4f9b\u4e86\u5feb\u901f\u3001\u7cbe\u786e\u7684\u7f51\u683c\u65e0\u5173\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86PINN\u5728\u7279\u5f81\u503c\u95ee\u9898\u4e0a\u7684\u8ba1\u7b97\u6548\u7387"}}
{"id": "2511.00794", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00794", "abs": "https://arxiv.org/abs/2511.00794", "authors": ["Yan Sun", "Jia Guo", "Stanley Kok", "Zihao Wang", "Zujie Wen", "Zhiqiang Zhang"], "title": "Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has improved the\nreasoning ability of large language models, yet training remains costly because\nmany rollouts contribute little to optimization, considering the amount of\ncomputation required. This study investigates how simply leveraging intrinsic\ndata properties, almost free benefit during training, can improve data\nefficiency for RLVR. We propose PREPO with two complementary components. First,\nwe adopt prompt perplexity as an indicator of model adaptability in learning,\nenabling the model to progress from well-understood contexts to more\nchallenging ones. Second, we amplify the discrepancy among the rollouts by\ndifferentiating their relative entropy, and prioritize sequences that exhibit a\nhigher degree of exploration. Together, these mechanisms reduce rollout demand\nwhile preserving competitive performance. On the Qwen and Llama models, PREPO\nachieves effective results on mathematical reasoning benchmarks with up to 3\ntimes fewer rollouts than the baselines. Beyond empirical gains, we provide\ntheoretical and in-depth analyses explaining the underlying rationale of our\nmethod to improve the data efficiency of RLVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86PREPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5185\u5728\u6570\u636e\u7279\u6027\u63d0\u9ad8RLVR\u7684\u6570\u636e\u6548\u7387\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u63d0\u793a\u56f0\u60d1\u5ea6\u7684\u9002\u5e94\u6027\u5b66\u4e60\u548c\u57fa\u4e8e\u76f8\u5bf9\u71b5\u5dee\u5f02\u7684\u63a2\u7d22\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u80fd\u5728\u51cf\u5c113\u500drollout\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "RLVR\u867d\u7136\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u4e3a\u8bb8\u591arollout\u5bf9\u4f18\u5316\u7684\u8d21\u732e\u5f88\u5c0f\u3002\u672c\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5229\u7528\u51e0\u4e4e\u514d\u8d39\u7684\u5185\u5728\u6570\u636e\u7279\u6027\u6765\u63d0\u9ad8RLVR\u7684\u6570\u636e\u6548\u7387\u3002", "method": "PREPO\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u4f7f\u7528\u63d0\u793a\u56f0\u60d1\u5ea6\u4f5c\u4e3a\u6a21\u578b\u9002\u5e94\u6027\u6307\u6807\uff0c\u4f7f\u6a21\u578b\u4ece\u6613\u5230\u96be\u5b66\u4e60\uff1b2\uff09\u901a\u8fc7\u533a\u5206\u76f8\u5bf9\u71b5\u6765\u653e\u5927rollout\u95f4\u7684\u5dee\u5f02\uff0c\u4f18\u5148\u9009\u62e9\u63a2\u7d22\u7a0b\u5ea6\u66f4\u9ad8\u7684\u5e8f\u5217\u3002", "result": "\u5728Qwen\u548cLlama\u6a21\u578b\u4e0a\uff0cPREPO\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6709\u6548\u7ed3\u679c\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c11\u4e86\u9ad8\u8fbe3\u500d\u7684rollout\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "PREPO\u901a\u8fc7\u5229\u7528\u5185\u5728\u6570\u636e\u7279\u6027\u663e\u8457\u63d0\u9ad8\u4e86RLVR\u7684\u6570\u636e\u6548\u7387\uff0c\u4e0d\u4ec5\u83b7\u5f97\u4e86\u5b9e\u8bc1\u6536\u76ca\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u6df1\u5165\u5206\u6790\u6765\u89e3\u91ca\u65b9\u6cd5\u7684\u57fa\u672c\u539f\u7406\u3002"}}
{"id": "2511.00797", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00797", "abs": "https://arxiv.org/abs/2511.00797", "authors": ["Wang Zixian"], "title": "Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation", "comment": null, "summary": "Pre-trained Transformers often exhibit over-confidence in source patterns and\ndifficulty in forming new target-domain patterns during fine-tuning. We\nformalize the mechanism of output saturation leading to gradient suppression\nthrough standard cross-entropy and softmax analysis, showing that gradient\nsuppression at inflection layers confines adaptation to high-level\nrecombination of existing features while preventing low-level reconstruction.\nWe introduce a set of layer-wise diagnostic metrics -- attention entropy\n(saturation proxy), activation gradient norm, parameter gradient norm, and\nDelta-CKA under a shared PCA basis -- to identify inflection layers\ncharacterized by both low attention entropy and steep gradient decay. Building\non these findings, we propose a diagnose-first, inject-light fine-tuning\nstrategy: selectively inserting LoRA adapters at inflection layers to restore\nsuppressed backward signals with minimal parameter overhead. Experiments on\nBERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and\nover-trained source regimes reveal that over-trained initialization benefits\nfrom inflection-layer LoRA injection, while under-trained initialization\nsuffers performance degradation. When base features are strong, unblocking\ninflection layers facilitates high-level compositional adaptation; when base\nfeatures are weak, full-pathway unblocking is required for low-level\nreconstruction, as supported by joint analysis of layer-wise activation\ngradients and Delta-CKA dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u9884\u8bad\u7ec3Transformer\u5728\u5fae\u8c03\u65f6\u51fa\u73b0\u7684\u8f93\u51fa\u9971\u548c\u548c\u68af\u5ea6\u6291\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8bca\u65ad\u6307\u6807\u6765\u8bc6\u522b\u62d0\u70b9\u5c42\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5728\u62d0\u70b9\u5c42\u9009\u62e9\u6027\u6ce8\u5165LoRA\u9002\u914d\u5668\u7684\u5fae\u8c03\u7b56\u7565\u3002", "motivation": "\u9884\u8bad\u7ec3Transformer\u5728\u5fae\u8c03\u65f6\u5f80\u5f80\u5bf9\u6e90\u57df\u6a21\u5f0f\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u96be\u4ee5\u5f62\u6210\u65b0\u7684\u76ee\u6807\u57df\u6a21\u5f0f\uff0c\u8fd9\u6e90\u4e8e\u8f93\u51fa\u9971\u548c\u5bfc\u81f4\u7684\u68af\u5ea6\u6291\u5236\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4ea4\u53c9\u71b5\u548csoftmax\u5206\u6790\u5f62\u5f0f\u5316\u8f93\u51fa\u9971\u548c\u673a\u5236\uff0c\u63d0\u51fa\u5c42\u95f4\u8bca\u65ad\u6307\u6807\uff08\u6ce8\u610f\u529b\u71b5\u3001\u68af\u5ea6\u8303\u6570\u3001Delta-CKA\uff09\uff0c\u5728\u62d0\u70b9\u5c42\u9009\u62e9\u6027\u6ce8\u5165LoRA\u9002\u914d\u5668\u6062\u590d\u88ab\u6291\u5236\u7684\u68af\u5ea6\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8fc7\u8bad\u7ec3\u521d\u59cb\u5316\u4e0b\uff0c\u62d0\u70b9\u5c42LoRA\u6ce8\u5165\u80fd\u63d0\u5347\u6027\u80fd\uff1b\u5728\u6b20\u8bad\u7ec3\u521d\u59cb\u5316\u4e0b\u5219\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u5f53\u57fa\u7840\u7279\u5f81\u5f3a\u65f6\uff0c\u89e3\u9664\u62d0\u70b9\u5c42\u963b\u585e\u6709\u52a9\u4e8e\u9ad8\u5c42\u7ec4\u5408\u9002\u5e94\uff1b\u5f53\u57fa\u7840\u7279\u5f81\u5f31\u65f6\uff0c\u9700\u8981\u5168\u8def\u5f84\u89e3\u9664\u963b\u585e\u8fdb\u884c\u4f4e\u5c42\u91cd\u5efa\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8bca\u65ad\u4f18\u5148\u3001\u8f7b\u91cf\u6ce8\u5165\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u89e3\u9664\u62d0\u70b9\u5c42\u68af\u5ea6\u6291\u5236\uff0c\u4ee5\u6700\u5c0f\u53c2\u6570\u5f00\u9500\u5b9e\u73b0\u6709\u6548\u7684\u9886\u57df\u9002\u5e94\u3002"}}
{"id": "2511.00804", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00804", "abs": "https://arxiv.org/abs/2511.00804", "authors": ["Abhiram Kusumba", "Maitreya Patel", "Kyle Min", "Changhoon Kim", "Chitta Baral", "Yezhou Yang"], "title": "EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment", "comment": "NeurIPS'25 Spotlight | Project page: https://eraseflow.github.io/", "summary": "Erasing harmful or proprietary concepts from powerful text to image\ngenerators is an emerging safety requirement, yet current \"concept erasure\"\ntechniques either collapse image quality, rely on brittle adversarial losses,\nor demand prohibitive retraining cycles. We trace these limitations to a myopic\nview of the denoising trajectories that govern diffusion based generation. We\nintroduce EraseFlow, the first framework that casts concept unlearning as\nexploration in the space of denoising paths and optimizes it with GFlowNets\nequipped with the trajectory balance objective. By sampling entire trajectories\nrather than single end states, EraseFlow learns a stochastic policy that steers\ngeneration away from target concepts while preserving the model's prior.\nEraseFlow eliminates the need for carefully crafted reward models and by doing\nthis, it generalizes effectively to unseen concepts and avoids hackable rewards\nwhile improving the performance. Extensive empirical results demonstrate that\nEraseFlow outperforms existing baselines and achieves an optimal trade off\nbetween performance and prior preservation.", "AI": {"tldr": "EraseFlow\u662f\u4e00\u4e2a\u57fa\u4e8eGFlowNets\u7684\u6982\u5ff5\u64e6\u9664\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u53bb\u566a\u8def\u5f84\u7a7a\u95f4\u6765\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\u8fdc\u79bb\u76ee\u6807\u6982\u5ff5\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\uff0c\u65e0\u9700\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684\u6982\u5ff5\u64e6\u9664\u6280\u672f\u5b58\u5728\u56fe\u50cf\u8d28\u91cf\u4e0b\u964d\u3001\u4f9d\u8d56\u8106\u5f31\u7684\u5bf9\u6297\u635f\u5931\u6216\u9700\u8981\u5927\u91cf\u91cd\u65b0\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u4ece\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u5668\u4e2d\u79fb\u9664\u6709\u5bb3\u6216\u4e13\u6709\u6982\u5ff5\u3002", "method": "\u5c06\u6982\u5ff5\u9057\u5fd8\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u53bb\u566a\u8def\u5f84\u7a7a\u95f4\u4e2d\u7684\u63a2\u7d22\u95ee\u9898\uff0c\u4f7f\u7528\u914d\u5907\u8f68\u8ff9\u5e73\u8861\u76ee\u6807\u7684GFlowNets\u6765\u4f18\u5316\uff0c\u901a\u8fc7\u91c7\u6837\u6574\u4e2a\u8f68\u8ff9\u800c\u975e\u5355\u4e2a\u6700\u7ec8\u72b6\u6001\u6765\u5b66\u4e60\u968f\u673a\u7b56\u7565\u3002", "result": "EraseFlow\u5728\u5e7f\u6cdb\u5b9e\u8bc1\u7ed3\u679c\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u6027\u80fd\u548c\u5148\u9a8c\u4fdd\u6301\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6700\u4f73\u6743\u8861\uff0c\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u6982\u5ff5\u5e76\u907f\u514d\u53ef\u88ab\u653b\u51fb\u7684\u5956\u52b1\u3002", "conclusion": "EraseFlow\u901a\u8fc7\u91cd\u65b0\u601d\u8003\u53bb\u566a\u8f68\u8ff9\u7684\u63a2\u7d22\u65b9\u5f0f\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u7cbe\u5fc3\u8bbe\u8ba1\u5956\u52b1\u6a21\u578b\u7684\u6982\u5ff5\u64e6\u9664\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u6709\u6548\u79fb\u9664\u76ee\u6807\u6982\u5ff5\u3002"}}
{"id": "2511.00806", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00806", "abs": "https://arxiv.org/abs/2511.00806", "authors": ["Guangxi Wan", "Peng Zeng", "Xiaoting Dong", "Chunhe Song", "Shijie Cui", "Dong Li", "Qingwei Dong", "Yiyang Liu", "Hongfei Bai"], "title": "Logic-informed reinforcement learning for cross-domain optimization of large-scale cyber-physical systems", "comment": null, "summary": "Cyber-physical systems (CPS) require the joint optimization of discrete cyber\nactions and continuous physical parameters under stringent safety logic\nconstraints. However, existing hierarchical approaches often compromise global\noptimality, whereas reinforcement learning (RL) in hybrid action spaces often\nrelies on brittle reward penalties, masking, or shielding and struggles to\nguarantee constraint satisfaction. We present logic-informed reinforcement\nlearning (LIRL), which equips standard policy-gradient algorithms with\nprojection that maps a low-dimensional latent action onto the admissible hybrid\nmanifold defined on-the-fly by first-order logic. This guarantees feasibility\nof every exploratory step without penalty tuning. Experimental evaluations have\nbeen conducted across multiple scenarios, including industrial manufacturing,\nelectric vehicle charging stations, and traffic signal control, in all of which\nthe proposed method outperforms existing hierarchical optimization approaches.\nTaking a robotic reducer assembly system in industrial manufacturing as an\nexample, LIRL achieves a 36.47\\% to 44.33\\% reduction at most in the combined\nmakespan-energy objective compared to conventional industrial hierarchical\nscheduling methods. Meanwhile, it consistently maintains zero constraint\nviolations and significantly surpasses state-of-the-art hybrid-action\nreinforcement learning baselines. Thanks to its declarative logic-based\nconstraint formulation, the framework can be seamlessly transferred to other\ndomains such as smart transportation and smart grid, thereby paving the way for\nsafe and real-time optimization in large-scale CPS.", "AI": {"tldr": "\u63d0\u51fa\u903b\u8f91\u4fe1\u606f\u5f3a\u5316\u5b66\u4e60(LIRL)\uff0c\u901a\u8fc7\u6295\u5f71\u673a\u5236\u5c06\u6f5c\u5728\u52a8\u4f5c\u6620\u5c04\u5230\u7531\u4e00\u9636\u903b\u8f91\u5b9a\u4e49\u7684\u53ef\u884c\u6df7\u5408\u6d41\u5f62\u4e0a\uff0c\u4fdd\u8bc1\u6bcf\u4e2a\u63a2\u7d22\u6b65\u9aa4\u7684\u53ef\u884c\u6027\uff0c\u65e0\u9700\u60e9\u7f5a\u8c03\u4f18\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u96be\u4ee5\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\uff0c\u5206\u5c42\u65b9\u6cd5\u727a\u7272\u5168\u5c40\u6700\u4f18\u6027\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u8106\u5f31\u7684\u60e9\u7f5a\u673a\u5236\u3002", "method": "\u4e3a\u6807\u51c6\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u914d\u5907\u6295\u5f71\u673a\u5236\uff0c\u5c06\u4f4e\u7ef4\u6f5c\u5728\u52a8\u4f5c\u6620\u5c04\u5230\u7531\u4e00\u9636\u903b\u8f91\u52a8\u6001\u5b9a\u4e49\u7684\u53ef\u884c\u6df7\u5408\u6d41\u5f62\u4e0a\u3002", "result": "\u5728\u5de5\u4e1a\u5236\u9020\u3001\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u548c\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7b49\u591a\u4e2a\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u673a\u5668\u4eba\u51cf\u901f\u5668\u88c5\u914d\u7cfb\u7edf\u4e2d\u4f7f\u5b8c\u5de5\u65f6\u95f4-\u80fd\u8017\u76ee\u6807\u964d\u4f4e36.47%\u81f344.33%\uff0c\u59cb\u7ec8\u4fdd\u6301\u96f6\u7ea6\u675f\u8fdd\u53cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u65e0\u7f1d\u8fc1\u79fb\u5230\u5176\u4ed6\u9886\u57df\uff0c\u4e3a\u5927\u89c4\u6a21\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u5b9e\u73b0\u5b89\u5168\u5b9e\u65f6\u4f18\u5316\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2511.00811", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00811", "abs": "https://arxiv.org/abs/2511.00811", "authors": ["Runyu Lu", "Peng Zhang", "Ruochuan Shi", "Yuanheng Zhu", "Dongbin Zhao", "Yang Liu", "Dong Wang", "Cesare Alippi"], "title": "Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games", "comment": null, "summary": "Equilibrium learning in adversarial games is an important topic widely\nexamined in the fields of game theory and reinforcement learning (RL).\nPursuit-evasion game (PEG), as an important class of real-world games from the\nfields of robotics and security, requires exponential time to be accurately\nsolved. When the underlying graph structure varies, even the state-of-the-art\nRL methods require recomputation or at least fine-tuning, which can be\ntime-consuming and impair real-time applicability. This paper proposes an\nEquilibrium Policy Generalization (EPG) framework to effectively learn a\ngeneralized policy with robust cross-graph zero-shot performance. In the\ncontext of PEGs, our framework is generally applicable to both pursuer and\nevader sides in both no-exit and multi-exit scenarios. These two\ngeneralizability properties, to our knowledge, are the first to appear in this\ndomain. The core idea of the EPG framework is to train an RL policy across\ndifferent graph structures against the equilibrium policy for each single\ngraph. To construct an equilibrium oracle for single-graph policies, we present\na dynamic programming (DP) algorithm that provably generates pure-strategy Nash\nequilibrium with near-optimal time complexity. To guarantee scalability with\nrespect to pursuer number, we further extend DP and RL by designing a grouping\nmechanism and a sequence model for joint policy decomposition, respectively.\nExperimental results show that, using equilibrium guidance and a distance\nfeature proposed for cross-graph PEG training, the EPG framework guarantees\ndesirable zero-shot performance in various unseen real-world graphs. Besides,\nwhen trained under an equilibrium heuristic proposed for the graphs with exits,\nour generalized pursuer policy can even match the performance of the fine-tuned\npolicies from the state-of-the-art PEG methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5747\u8861\u7b56\u7565\u6cdb\u5316\uff08EPG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5bf9\u6297\u6027\u6e38\u620f\u4e2d\u5b66\u4e60\u5177\u6709\u8de8\u56fe\u96f6\u6837\u672c\u6027\u80fd\u7684\u6cdb\u5316\u7b56\u7565\uff0c\u7279\u522b\u9488\u5bf9\u8ffd\u9003\u6e38\u620f\uff08PEG\uff09\u3002", "motivation": "\u89e3\u51b3\u8ffd\u9003\u6e38\u620f\u4e2d\u56fe\u7ed3\u6784\u53d8\u5316\u65f6\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u6216\u5fae\u8c03\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u5b9e\u65f6\u5e94\u7528\u6027\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u751f\u6210\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u901a\u8fc7\u5206\u7ec4\u673a\u5236\u548c\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u7b56\u7565\u5206\u89e3\uff0c\u5229\u7528\u5747\u8861\u5f15\u5bfc\u548c\u8ddd\u79bb\u7279\u5f81\u8fdb\u884c\u8de8\u56fe\u8bad\u7ec3\u3002", "result": "\u5728\u672a\u89c1\u8fc7\u7684\u771f\u5b9e\u4e16\u754c\u56fe\u4e2d\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5728\u5e26\u51fa\u53e3\u7684\u56fe\u4e2d\uff0c\u6cdb\u5316\u8ffd\u6355\u7b56\u7565\u751a\u81f3\u80fd\u4e0e\u5fae\u8c03\u540e\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "EPG\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8ffd\u9003\u6e38\u620f\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u5bf9\u6297\u6027\u6e38\u620f\u4e2d\u7684\u5747\u8861\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.00812", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00812", "abs": "https://arxiv.org/abs/2511.00812", "authors": ["Shashank Nag", "Alan T. L. Bacellar", "Zachary Susskind", "Anshul Jha", "Logan Liberty", "Aishwarya Sivakumar", "Eugene B. John", "Krishnan Kailas", "Priscila M. V. Lima", "Neeraja J. Yadwadkar", "Felipe M. G. Franca", "Lizy K. John"], "title": "LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons", "comment": "Accepted for FPT 2025, 9 pages, conference", "summary": "Vision Transformers have been tremendously successful in computer vision\ntasks. However, their large computational, memory, and energy demands are a\nchallenge for edge inference on FPGAs -- a field that has seen a recent surge\nin demand. We recognize the benefits of recent works on logic and Look Up Table\n(LUT) based networks, such as LogicNets, NeuraLUT, DWN, among others, in\noffering models that simultaneously reduce both the memory and compute\nfootprints. However, these models natively do not perform well on common vision\ntasks, such as CIFAR-10/100. In this work, we propose LL-ViT, a novel edge\noptimized vision transformer design that integrates layers of LUT neurons\nwithin the transformer architecture. Based on our characterization that reveals\nthat a majority of model weights and computations are from the channel mixer\n(MLP layer), we design an alternate LUT-based channel mixer, and simultaneously\ndevelop an FPGA-based accelerator for LL-ViT. Contrary to some attempts to\nreplace each multiplication with a table lookup, our architecture utilizes a\nneural learning approach which natively learns the LUT functions. This approach\nallows for reduced model sizes, and a computational and energy-efficient\ninference solution for vision transformer models. Evaluating on edge-suitable\nworkloads, we achieve accuracies of 95.5% on CIFAR-10, 78.8% on CIFAR-100, and\n60.9% on Tiny-ImageNet datasets, comparable to the baseline transformer. LL-ViT\neliminates over 60% of the model weights and 50% of the multiplications in the\nmodel, and achieves 1.9x energy efficiency and 1.3x lower latency over an\ninteger quantized ViT accelerator, while also offering superior throughput\nagainst prior works at a 10.9W power budget.", "AI": {"tldr": "LL-ViT\u662f\u4e00\u79cd\u9488\u5bf9\u8fb9\u7f18FPGA\u4f18\u5316\u7684\u89c6\u89c9Transformer\u8bbe\u8ba1\uff0c\u901a\u8fc7\u96c6\u6210LUT\u795e\u7ecf\u5143\u5c42\u6765\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9Transformer\u5728\u8fb9\u7f18FPGA\u4e0a\u90e8\u7f72\u65f6\u9762\u4e34\u7684\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u80fd\u8017\u6311\u6218\uff0c\u540c\u65f6\u514b\u670d\u73b0\u6709LUT\u7f51\u7edc\u5728\u89c6\u89c9\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eLUT\u7684\u901a\u9053\u6df7\u5408\u5668\u66ff\u4ee3\u4f20\u7edfMLP\u5c42\uff0c\u91c7\u7528\u795e\u7ecf\u5b66\u4e60\u65b9\u6cd5\u539f\u751f\u5b66\u4e60LUT\u51fd\u6570\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u7684FPGA\u52a0\u901f\u5668\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-100\u548cTiny-ImageNet\u4e0a\u5206\u522b\u8fbe\u523095.5%\u300178.8%\u548c60.9%\u7684\u7cbe\u5ea6\uff0c\u6d88\u966460%\u6743\u91cd\u548c50%\u4e58\u6cd5\u64cd\u4f5c\uff0c\u80fd\u6548\u63d0\u53471.9\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e1.3\u500d\u3002", "conclusion": "LL-ViT\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u89c6\u89c9Transformer\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2511.00851", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00851", "abs": "https://arxiv.org/abs/2511.00851", "authors": ["Abhishek Patange", "Sharat Chidambaran", "Prabhat Shankar", "Manjunath G. B.", "Anindya Chatterjee"], "title": "Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics", "comment": "This paper ID 254 has been accepted for presentation in the\n  Demonstration Track of the 13th ACM IKDD CODS Conference on Data Science CODS\n  2025, IISER Pune, India, from December 17 to 20, 2025", "summary": "Slug formation in oil and gas pipelines poses significant challenges to\noperational safety and efficiency, yet existing detection approaches are often\noffline, require domain expertise, and lack real-time interpretability. We\npresent an interactive application that enables end-to-end data-driven slug\ndetection through a compact and user-friendly interface. The system integrates\ndata exploration and labeling, configurable model training and evaluation with\nmultiple classifiers, visualization of classification results with time-series\noverlays, and a real-time inference module that generates persistence-based\nalerts when slug events are detected. The demo supports seamless workflows from\nlabeled CSV uploads to live inference on unseen datasets, making it\nlightweight, portable, and easily deployable. By combining domain-relevant\nanalytics with novel UI/UX features such as snapshot persistence, visual\nlabeling, and real-time alerting, our tool adds significant dissemination value\nas both a research prototype and a practical industrial application. The demo\nshowcases how interactive human-in-the-loop ML systems can bridge the gap\nbetween data science methods and real-world decision-making in critical process\nindustries, with broader applicability to time-series fault diagnosis tasks\nbeyond oil and gas.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u6cb9\u6c14\u7ba1\u9053\u6bb5\u585e\u6d41\u68c0\u6d4b\u7684\u4ea4\u4e92\u5f0f\u5e94\u7528\uff0c\u96c6\u6210\u4e86\u6570\u636e\u63a2\u7d22\u3001\u6a21\u578b\u8bad\u7ec3\u3001\u53ef\u89c6\u5316\u5206\u6790\u548c\u5b9e\u65f6\u63a8\u7406\u529f\u80fd\uff0c\u901a\u8fc7\u7528\u6237\u53cb\u597d\u754c\u9762\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u68c0\u6d4b\u6d41\u7a0b\u3002", "motivation": "\u73b0\u6709\u6bb5\u585e\u6d41\u68c0\u6d4b\u65b9\u6cd5\u591a\u4e3a\u79bb\u7ebf\u3001\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u7f3a\u4e4f\u5b9e\u65f6\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u6ee1\u8db3\u5de5\u4e1a\u5b9e\u65f6\u76d1\u6d4b\u9700\u6c42\u3002", "method": "\u6784\u5efa\u4ea4\u4e92\u5f0f\u5e94\u7528\uff0c\u5305\u542b\u6570\u636e\u6807\u6ce8\u3001\u53ef\u914d\u7f6e\u6a21\u578b\u8bad\u7ec3\u3001\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u5206\u7c7b\u7ed3\u679c\u548c\u57fa\u4e8e\u6301\u4e45\u6027\u7684\u5b9e\u65f6\u63a8\u7406\u544a\u8b66\u6a21\u5757\u3002", "result": "\u7cfb\u7edf\u652f\u6301\u4eceCSV\u6570\u636e\u4e0a\u4f20\u5230\u5b9e\u65f6\u63a8\u7406\u7684\u65e0\u7f1d\u5de5\u4f5c\u6d41\uff0c\u5177\u6709\u8f7b\u91cf\u3001\u4fbf\u643a\u3001\u6613\u90e8\u7f72\u7684\u7279\u70b9\uff0c\u7ed3\u5408\u4e86\u9886\u57df\u5206\u6790\u548c\u521b\u65b0\u7684UI/UX\u529f\u80fd\u3002", "conclusion": "\u8be5\u5de5\u5177\u5c55\u793a\u4e86\u4ea4\u4e92\u5f0f\u4eba\u673a\u534f\u540cML\u7cfb\u7edf\u5982\u4f55\u5f25\u5408\u6570\u636e\u79d1\u5b66\u65b9\u6cd5\u4e0e\u5173\u952e\u8fc7\u7a0b\u5de5\u4e1a\u4e2d\u5b9e\u9645\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u6545\u969c\u8bca\u65ad\u4efb\u52a1\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.00868", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00868", "abs": "https://arxiv.org/abs/2511.00868", "authors": ["Nazmul Takbir", "Hamidreza Alikhani", "Nikil Dutt", "Sangeetha Abdu Jyothi"], "title": "FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management", "comment": null, "summary": "Large Language Model (LLM) serving is increasingly constrained by the growing\nsize of the key-value (KV) cache, which scales with both context length and\ngeneration length. Prior work shows that attention is dominated by a small\nsubset of critical tokens, yet existing systems struggle to exploit this\nefficiently without degrading accuracy, especially in long generation. We make\na key observation: the temporal stability of these critical tokens varies\nsignificantly across KV heads: some heads consistently focus on the same\ntokens, while others shift frequently. Building on this insight, we introduce\nFlexiCache, a hierarchical KV-cache management system that leverages the\ntemporal stability of KV heads to reduce GPU memory usage and computation\noverhead, while preserving model accuracy. FlexiCache classifies KV heads as\nstable or unstable: it retains all KV-cache pages from unstable heads in GPU\nmemory, whereas for stable heads, it keeps only the top-K pages on the GPU and\noffloads the rest to host memory. By exploiting temporal stability, FlexiCache\nperforms periodic reranking for stable heads to fetch newly promoted top pages.\nImplemented atop vLLM, FlexiCache reduces GPU memory footprint for long-context\nrequests by up to 70%, improves offline serving throughput by 1.38-1.55x, and\nlowers online token latency by 1.6-2.1x, all while maintaining accuracy in\nlong-context, long-generation scenarios.", "AI": {"tldr": "FlexiCache\u662f\u4e00\u4e2a\u5206\u5c42KV\u7f13\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u5229\u7528KV\u5934\u7684\u65f6\u95f4\u7a33\u5b9a\u6027\u6765\u51cf\u5c11GPU\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u53d7KV\u7f13\u5b58\u589e\u957f\u7684\u7ea6\u675f\uff0c\u73b0\u6709\u7cfb\u7edf\u96be\u4ee5\u5728\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5173\u952e\u4ee4\u724c\u7684\u7a00\u758f\u6027\uff0c\u7279\u522b\u662f\u5728\u957f\u751f\u6210\u573a\u666f\u4e2d\u3002", "method": "FlexiCache\u5c06KV\u5934\u5206\u7c7b\u4e3a\u7a33\u5b9a\u548c\u4e0d\u7a33\u5b9a\uff1a\u4e0d\u7a33\u5b9a\u5934\u7684\u6240\u6709KV\u7f13\u5b58\u9875\u9762\u4fdd\u7559\u5728GPU\u5185\u5b58\u4e2d\uff0c\u800c\u7a33\u5b9a\u5934\u4ec5\u4fdd\u7559\u524dK\u4e2a\u9875\u9762\u5728GPU\u4e0a\uff0c\u5176\u4f59\u5378\u8f7d\u5230\u4e3b\u673a\u5185\u5b58\uff0c\u5e76\u5229\u7528\u65f6\u95f4\u7a33\u5b9a\u6027\u8fdb\u884c\u5b9a\u671f\u91cd\u65b0\u6392\u540d\u4ee5\u83b7\u53d6\u65b0\u63d0\u5347\u7684\u9876\u90e8\u9875\u9762\u3002", "result": "\u5728vLLM\u4e0a\u5b9e\u73b0\uff0cFlexiCache\u5c06\u957f\u4e0a\u4e0b\u6587\u8bf7\u6c42\u7684GPU\u5185\u5b58\u5360\u7528\u51cf\u5c11\u9ad8\u8fbe70%\uff0c\u79bb\u7ebf\u670d\u52a1\u541e\u5410\u91cf\u63d0\u9ad81.38-1.55\u500d\uff0c\u5728\u7ebf\u4ee4\u724c\u5ef6\u8fdf\u964d\u4f4e1.6-2.1\u500d\u3002", "conclusion": "FlexiCache\u901a\u8fc7\u5229\u7528KV\u5934\u7684\u65f6\u95f4\u7a33\u5b9a\u6027\uff0c\u5728\u4fdd\u6301\u957f\u4e0a\u4e0b\u6587\u3001\u957f\u751f\u6210\u573a\u666f\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u670d\u52a1\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2511.00874", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.00874", "abs": "https://arxiv.org/abs/2511.00874", "authors": ["Taowen Liu", "Marta Andronic", "Deniz G\u00fcnd\u00fcz", "George A. Constantinides"], "title": "Training with Fewer Bits: Unlocking Edge LLMs Training with Stochastic Rounding", "comment": null, "summary": "LLM training is resource-intensive. Quantized training improves computational\nand memory efficiency but introduces quantization noise, which can hinder\nconvergence and degrade model accuracy. Stochastic Rounding (SR) has emerged as\na theoretically attractive alternative to deterministic rounding, offering\nunbiased gradient estimates. However, its interaction with other training\nfactors -- especially batch size -- remains under explored. In this paper, we\npresent a theoretical and empirical study of mini-batch stochastic gradient\ndescent (SGD) with SR, showing that increased batch sizes can compensate for\nreduced precision during back-propagation. Furthermore, we show that quantizing\nweights and activations impacts gradient variance in distinct ways. Our\nexperiments validate these theoretical insights.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u589e\u52a0\u6279\u91cf\u5927\u5c0f\u53ef\u4ee5\u8865\u507f\u91cf\u5316\u8bad\u7ec3\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u91cf\u5316\u6743\u91cd\u548c\u6fc0\u6d3b\u5bf9\u68af\u5ea6\u65b9\u5dee\u6709\u4e0d\u540c\u5f71\u54cd", "motivation": "\u91cf\u5316\u8bad\u7ec3\u867d\u7136\u63d0\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u6548\u7387\uff0c\u4f46\u5f15\u5165\u91cf\u5316\u566a\u58f0\u4f1a\u963b\u788d\u6536\u655b\u548c\u964d\u4f4e\u6a21\u578b\u7cbe\u5ea6\uff0c\u968f\u673a\u820d\u5165\u4e0e\u6279\u91cf\u5927\u5c0f\u7b49\u8bad\u7ec3\u56e0\u7d20\u7684\u76f8\u4e92\u4f5c\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "\u5bf9\u5e26\u6709\u968f\u673a\u820d\u5165\u7684\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u91cf\u5316\u6743\u91cd\u548c\u6fc0\u6d3b\u5bf9\u68af\u5ea6\u65b9\u5dee\u7684\u4e0d\u540c\u5f71\u54cd", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u89c1\u89e3\uff0c\u8868\u660e\u589e\u52a0\u6279\u91cf\u5927\u5c0f\u53ef\u4ee5\u8865\u507f\u53cd\u5411\u4f20\u64ad\u671f\u95f4\u964d\u4f4e\u7684\u7cbe\u5ea6", "conclusion": "\u968f\u673a\u820d\u5165\u4e0e\u6279\u91cf\u5927\u5c0f\u7684\u534f\u540c\u4f5c\u7528\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u91cf\u5316\u8bad\u7ec3\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\u95ee\u9898"}}
{"id": "2511.00880", "categories": ["cs.LG", "cs.AI", "68T07, 90C15, 93E35"], "pdf": "https://arxiv.org/pdf/2511.00880", "abs": "https://arxiv.org/abs/2511.00880", "authors": ["Joonyoung Lim", "Younghwan Yoo"], "title": "KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization", "comment": "12 pages, 8 figures, submitted to ECAI 2025", "summary": "We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm\nthat combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based\nsecond-order policy optimization with safety-aware gradient manipulation. KFCPO\nleverages K-FAC to perform efficient and stable natural gradient updates by\napproximating the Fisher Information Matrix (FIM) in a layerwise, closed form\nmanner, avoiding iterative approximation overheads. To address the tradeoff\nbetween reward maximization and constraint satisfaction, we introduce a margin\naware gradient manipulation mechanism that adaptively adjusts the influence of\nreward and cost gradients based on the agent's proximity to safety boundaries.\nThis method blends gradients using a direction sensitive projection,\neliminating harmful interference and avoiding abrupt changes caused by fixed\nhard thresholds. Additionally, a minibatch level KL rollback strategy is\nadopted to ensure trust region compliance and to prevent destabilizing policy\nshifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves\n10.3% to 50.2% higher average return across environments compared to the best\nbaseline that respected the safety constraint, demonstrating superior balance\nof safety and performance.", "AI": {"tldr": "KFCPO\u662f\u4e00\u79cd\u7ed3\u5408Kronecker\u5206\u89e3\u8fd1\u4f3c\u66f2\u7387\u4e8c\u9636\u7b56\u7565\u4f18\u5316\u4e0e\u5b89\u5168\u611f\u77e5\u68af\u5ea6\u64cd\u4f5c\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7Fisher\u4fe1\u606f\u77e9\u9635\u8fd1\u4f3c\u5b9e\u73b0\u9ad8\u6548\u81ea\u7136\u68af\u5ea6\u66f4\u65b0\uff0c\u5e76\u4f7f\u7528\u8fb9\u754c\u611f\u77e5\u68af\u5ea6\u64cd\u4f5c\u673a\u5236\u5e73\u8861\u5956\u52b1\u6700\u5927\u5316\u4e0e\u7ea6\u675f\u6ee1\u8db3\u3002", "motivation": "\u89e3\u51b3\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u6700\u5927\u5316\u4e0e\u5b89\u5168\u7ea6\u675f\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u56fa\u5b9a\u9608\u503c\u5bfc\u81f4\u7684\u6027\u80fd\u4e0d\u7a33\u5b9a\u548c\u5b89\u5168\u6027\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528K-FAC\u8fd1\u4f3cFisher\u4fe1\u606f\u77e9\u9635\u8fdb\u884c\u9ad8\u6548\u4e8c\u9636\u7b56\u7565\u4f18\u5316\uff0c\u5f15\u5165\u8fb9\u754c\u611f\u77e5\u68af\u5ea6\u64cd\u4f5c\u673a\u5236\u81ea\u9002\u5e94\u8c03\u6574\u5956\u52b1\u548c\u6210\u672c\u68af\u5ea6\u5f71\u54cd\uff0c\u91c7\u7528\u5c0f\u6279\u91cfKL\u56de\u6eda\u7b56\u7565\u786e\u4fdd\u4fe1\u4efb\u533a\u57df\u5408\u89c4\u3002", "result": "\u5728Safety Gymnasium\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cKFCPO\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e8610.3%\u81f350.2%\u7684\u5e73\u5747\u56de\u62a5\u63d0\u5347\uff0c\u540c\u65f6\u6ee1\u8db3\u5b89\u5168\u7ea6\u675f\u3002", "conclusion": "KFCPO\u5728\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u4e0e\u6027\u80fd\u7684\u4f18\u8d8a\u5e73\u8861\uff0c\u901a\u8fc7\u4e8c\u9636\u4f18\u5316\u548c\u81ea\u9002\u5e94\u68af\u5ea6\u64cd\u4f5c\u6709\u6548\u89e3\u51b3\u4e86\u5956\u52b1\u4e0e\u7ea6\u675f\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2511.00885", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.00885", "abs": "https://arxiv.org/abs/2511.00885", "authors": ["Tal Argov", "Tal Wagner"], "title": "SpEx: A Spectral Approach to Explainable Clustering", "comment": "NeurIPS 2025", "summary": "Explainable clustering by axis-aligned decision trees was introduced by\nMoshkovitz et al. (2020) and has gained considerable interest. Prior work has\nfocused on minimizing the price of explainability for specific clustering\nobjectives, lacking a general method to fit an explanation tree to any given\nclustering, without restrictions. In this work, we propose a new and generic\napproach to explainable clustering, based on spectral graph partitioning. With\nit, we design an explainable clustering algorithm that can fit an explanation\ntree to any given non-explainable clustering, or directly to the dataset\nitself. Moreover, we show that prior algorithms can also be interpreted as\ngraph partitioning, through a generalized framework due to Trevisan (2013)\nwherein cuts are optimized in two graphs simultaneously. Our experiments show\nthe favorable performance of our method compared to baselines on a range of\ndatasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u56fe\u5212\u5206\u7684\u53ef\u89e3\u91ca\u805a\u7c7b\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5c06\u89e3\u91ca\u6811\u9002\u914d\u5230\u4efb\u4f55\u7ed9\u5b9a\u7684\u975e\u53ef\u89e3\u91ca\u805a\u7c7b\u6216\u6570\u636e\u96c6\u672c\u8eab\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u805a\u7c7b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u5c0f\u5316\u7279\u5b9a\u805a\u7c7b\u76ee\u6807\u7684\u53ef\u89e3\u91ca\u6027\u4ee3\u4ef7\uff0c\u7f3a\u4e4f\u901a\u7528\u7684\u65b9\u6cd5\u6765\u5c06\u89e3\u91ca\u6811\u9002\u914d\u5230\u4efb\u610f\u7ed9\u5b9a\u7684\u805a\u7c7b\uff0c\u800c\u4e0d\u53d7\u9650\u5236\u3002", "method": "\u57fa\u4e8e\u8c31\u56fe\u5212\u5206\u8bbe\u8ba1\u53ef\u89e3\u91ca\u805a\u7c7b\u7b97\u6cd5\uff0c\u901a\u8fc7Trevisan(2013)\u7684\u5e7f\u4e49\u6846\u67b6\u5c06\u5148\u524d\u7684\u7b97\u6cd5\u4e5f\u89e3\u91ca\u4e3a\u56fe\u5212\u5206\uff0c\u5176\u4e2d\u5728\u4e24\u4e2a\u56fe\u4e2d\u540c\u65f6\u4f18\u5316\u5207\u5272\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u8c31\u56fe\u5212\u5206\u7684\u901a\u7528\u53ef\u89e3\u91ca\u805a\u7c7b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9002\u914d\u89e3\u91ca\u6811\u5230\u4efb\u610f\u805a\u7c7b\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.00900", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00900", "abs": "https://arxiv.org/abs/2511.00900", "authors": ["Yoshihiro Maruyama"], "title": "Learning with Category-Equivariant Representations for Human Activity Recognition", "comment": null, "summary": "Human activity recognition is challenging because sensor signals shift with\ncontext, motion, and environment; effective models must therefore remain stable\nas the world around them changes. We introduce a categorical symmetry-aware\nlearning framework that captures how signals vary over time, scale, and sensor\nhierarchy. We build these factors into the structure of feature\nrepresentations, yielding models that automatically preserve the relationships\nbetween sensors and remain stable under realistic distortions such as time\nshifts, amplitude drift, and device orientation changes. On the UCI Human\nActivity Recognition benchmark, this categorical symmetry-driven design\nimproves out-of-distribution accuracy by approx. 46 percentage points (approx.\n3.6x over the baseline), demonstrating that abstract symmetry principles can\ntranslate into concrete performance gains in everyday sensing tasks via\ncategory-equivariant representation theory.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8303\u7574\u5bf9\u79f0\u6027\u611f\u77e5\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u3001\u5c3a\u5ea6\u548c\u4f20\u611f\u5668\u5c42\u6b21\u7ed3\u6784\u7684\u53d8\u5316\u56e0\u7d20\u878d\u5165\u7279\u5f81\u8868\u793a\u7ed3\u6784\uff0c\u4f7f\u6a21\u578b\u5728\u73b0\u5b9e\u626d\u66f2\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u4e2d\u4f20\u611f\u5668\u4fe1\u53f7\u968f\u4e0a\u4e0b\u6587\u3001\u8fd0\u52a8\u548c\u73af\u5883\u53d8\u5316\u800c\u6f02\u79fb\u7684\u95ee\u9898\uff0c\u9700\u8981\u6a21\u578b\u5728\u5468\u56f4\u4e16\u754c\u53d8\u5316\u65f6\u4fdd\u6301\u7a33\u5b9a\u3002", "method": "\u4f7f\u7528\u8303\u7574\u5bf9\u79f0\u6027\u611f\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u4fe1\u53f7\u5728\u65f6\u95f4\u3001\u5c3a\u5ea6\u548c\u4f20\u611f\u5668\u5c42\u6b21\u7ed3\u6784\u4e0a\u7684\u53d8\u5316\u56e0\u7d20\u6784\u5efa\u5230\u7279\u5f81\u8868\u793a\u7ed3\u6784\u4e2d\uff0c\u5b9e\u73b0\u7c7b\u522b\u7b49\u53d8\u8868\u793a\u7406\u8bba\u3002", "result": "\u5728UCI\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u8bbe\u8ba1\u5c06\u5206\u5e03\u5916\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u7ea646\u4e2a\u767e\u5206\u70b9\uff08\u7ea63.6\u500d\u4e8e\u57fa\u7ebf\uff09\u3002", "conclusion": "\u62bd\u8c61\u5bf9\u79f0\u6027\u539f\u7406\u53ef\u4ee5\u901a\u8fc7\u8303\u7574\u7b49\u53d8\u8868\u793a\u7406\u8bba\u8f6c\u5316\u4e3a\u65e5\u5e38\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u5177\u4f53\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.00904", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00904", "abs": "https://arxiv.org/abs/2511.00904", "authors": ["Ernesto Araya", "Massimiliano Datres", "Gitta Kutyniok"], "title": "Random Spiking Neural Networks are Stable and Spectrally Simple", "comment": null, "summary": "Spiking neural networks (SNNs) are a promising paradigm for energy-efficient\ncomputation, yet their theoretical foundations-especially regarding stability\nand robustness-remain limited compared to artificial neural networks. In this\nwork, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the\nlens of Boolean function analysis. We focus on noise sensitivity and stability\nin classification tasks, quantifying how input perturbations affect outputs.\nOur main result shows that wide LIF-SNN classifiers are stable on average, a\nproperty explained by the concentration of their Fourier spectrum on\nlow-frequency components. Motivated by this, we introduce the notion of\nspectral simplicity, which formalizes simplicity in terms of Fourier spectrum\nconcentration and connects our analysis to the simplicity bias observed in deep\nnetworks. Within this framework, we show that random LIF-SNNs are biased toward\nsimple functions. Experiments on trained networks confirm that these stability\nproperties persist in practice. Together, these results provide new insights\ninto the stability and robustness properties of SNNs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5e03\u5c14\u51fd\u6570\u5206\u6790\u7814\u7a76\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e( LIF )SNN\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5bbdLIF-SNN\u5206\u7c7b\u5668\u5728\u5e73\u5747\u610f\u4e49\u4e0a\u7a33\u5b9a\uff0c\u5176\u5085\u91cc\u53f6\u9891\u8c31\u96c6\u4e2d\u5728\u4f4e\u9891\u5206\u91cf\u3002\u63d0\u51fa\u4e86\u8c31\u7b80\u5355\u6027\u6982\u5ff5\uff0c\u8bc1\u660e\u968f\u673aLIF-SNN\u504f\u5411\u7b80\u5355\u51fd\u6570\u3002", "motivation": "SNN\u4f5c\u4e3a\u8282\u80fd\u8ba1\u7b97\u7684\u6709\u524d\u666f\u8303\u5f0f\uff0c\u5176\u7406\u8bba\u57fa\u7840\u7279\u522b\u662f\u5173\u4e8e\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u7684\u7814\u7a76\u76f8\u6bd4\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4ecd\u7136\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5e03\u5c14\u51fd\u6570\u5206\u6790\u7684\u89c6\u89d2\u7814\u7a76\u79bb\u6563\u65f6\u95f4LIF-SNN\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u566a\u58f0\u654f\u611f\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u91cf\u5316\u8f93\u5165\u6270\u52a8\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u8868\u660e\u5bbdLIF-SNN\u5206\u7c7b\u5668\u5728\u5e73\u5747\u610f\u4e49\u4e0a\u7a33\u5b9a\uff0c\u8fd9\u79cd\u6027\u8d28\u7531\u5176\u5085\u91cc\u53f6\u9891\u8c31\u5728\u4f4e\u9891\u5206\u91cf\u7684\u96c6\u4e2d\u6240\u89e3\u91ca\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u8fd9\u4e9b\u7a33\u5b9a\u6027\u7279\u6027\u5728\u5b9e\u8df5\u4e2d\u6301\u7eed\u5b58\u5728\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3aSNN\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u901a\u8fc7\u8c31\u7b80\u5355\u6027\u6846\u67b6\u5c06\u5206\u6790\u4e0e\u6df1\u5ea6\u7f51\u7edc\u4e2d\u89c2\u5bdf\u5230\u7684\u7b80\u5355\u6027\u504f\u5dee\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2511.00907", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00907", "abs": "https://arxiv.org/abs/2511.00907", "authors": ["Ruifeng Ren", "Sheng Ouyang", "Huayi Tang", "Yong Liu"], "title": "Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle", "comment": null, "summary": "Transformers have demonstrated strong adaptability across a wide range of\ntasks and have become the backbone of modern Large Language Models (LLMs).\nHowever, their underlying mechanisms remain open for further exploration. The\nenergy-based perspective has long provided a valuable principle for\nunderstanding neural computation. In this paper, we revisit the principle of\nenergy as a lens to understand attention-based Transformer models. We present a\nunified energy-based framework which is composed of three key components: the\nglobal energy $F^*$, the energy function $E_i$ and the employed gradient\ndescent (GD) form. Within this framework, standard softmax attention can be\nviewed as a special case of minimizing the Helmholtz free energy as $F^*$ using\nstandard GD when $E_i$ takes the form of elastic potential energy, with\nresidual connections ensuring that this optimization proceeds in an incremental\nmanner. In addition, linear attentions can also be naturally incorporated into\nthis framework by adjusting the corresponding energy forms. We also extend the\nabove analysis to the multi-head setting, where the energy is defined across\nmultiple low-dimensional subspaces. Building on this framework, we propose\nenergy-based modifications of attention structures. Inspired by classical GD\nalgorithms, we extend the original attention formulation based on standard GD\nto the momentum-based GD, Nesterov Accelerated Gradient (NAG), and Newton's\nmethod variants, each inducing a corresponding new attention structure. Our\nexperiments provide preliminary support for the potential of the energy-based\nframework for designing attention mechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u80fd\u91cf\u7684\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3Transformer\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u6807\u51c6softmax\u6ce8\u610f\u529b\u89c6\u4e3a\u6700\u5c0f\u5316\u4ea5\u59c6\u970d\u5179\u81ea\u7531\u80fd\u91cf\u7684\u7279\u4f8b\uff0c\u5e76\u57fa\u4e8e\u7ecf\u5178\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u63d0\u51fa\u4e86\u65b0\u7684\u6ce8\u610f\u529b\u7ed3\u6784\u53d8\u4f53\u3002", "motivation": "Transformer\u6a21\u578b\u867d\u7136\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u5185\u5728\u673a\u5236\u4ecd\u9700\u6df1\u5165\u63a2\u7d22\u3002\u80fd\u91cf\u89c6\u89d2\u957f\u671f\u4ee5\u6765\u4e3a\u7406\u89e3\u795e\u7ecf\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u539f\u5219\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u80fd\u91cf\u89c6\u89d2\u91cd\u65b0\u7406\u89e3\u57fa\u4e8e\u6ce8\u610f\u529b\u7684Transformer\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u80fd\u91cf\u6846\u67b6\uff0c\u5305\u542b\u5168\u5c40\u80fd\u91cf\u3001\u80fd\u91cf\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u5f62\u5f0f\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002\u5c06\u6807\u51c6softmax\u6ce8\u610f\u529b\u5efa\u6a21\u4e3a\u6700\u5c0f\u5316\u4ea5\u59c6\u970d\u5179\u81ea\u7531\u80fd\u91cf\u7684\u7279\u4f8b\uff0c\u5e76\u5c06\u7ebf\u6027\u6ce8\u610f\u529b\u81ea\u7136\u7eb3\u5165\u8be5\u6846\u67b6\u3002\u57fa\u4e8e\u7ecf\u5178\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff08\u52a8\u91cfGD\u3001NAG\u3001\u725b\u987f\u6cd5\uff09\u6269\u5c55\u4e86\u6ce8\u610f\u529b\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u521d\u6b65\u652f\u6301\u4e86\u57fa\u4e8e\u80fd\u91cf\u6846\u67b6\u8bbe\u8ba1\u6ce8\u610f\u529b\u673a\u5236\u7684\u6f5c\u529b\u3002", "conclusion": "\u80fd\u91cf\u89c6\u89d2\u4e3a\u7406\u89e3Transformer\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u7136\u5730\u89e3\u91ca\u73b0\u6709\u6ce8\u610f\u529b\u53d8\u4f53\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u65b0\u7684\u6ce8\u610f\u529b\u7ed3\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.00949", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00949", "abs": "https://arxiv.org/abs/2511.00949", "authors": ["Yangyang Zhao", "Matti Kaisti", "Olli Lahdenoja", "Tero Koivisto"], "title": "Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification", "comment": "Accepted for publication in the Companion of the 2025 ACM\n  International Joint Conference on Pervasive and Ubiquitous Computing and the\n  2025 International Symposium on Wearable Computers (UbiComp/ISWC 2025\n  Companion). 5 pages, 3 figures. Author's accepted manuscript (AAM)", "summary": "Atrial fibrillation (AF) is a leading cause of stroke and mortality,\nparticularly in elderly patients. Wrist-worn photoplethysmography (PPG) enables\nnon-invasive, continuous rhythm monitoring, yet suffers from significant\nvulnerability to motion artifacts and physiological noise. Many existing\napproaches rely solely on single-channel PPG and are limited to binary AF\ndetection, often failing to capture the broader range of arrhythmias\nencountered in clinical settings. We introduce RhythmiNet, a residual neural\nnetwork enhanced with temporal and channel attention modules that jointly\nleverage PPG and accelerometer (ACC) signals. The model performs three-class\nrhythm classification: AF, sinus rhythm (SR), and Other. To assess robustness\nacross varying movement conditions, test data are stratified by\naccelerometer-based motion intensity percentiles without excluding any\nsegments. RhythmiNet achieved a 4.3% improvement in macro-AUC over the PPG-only\nbaseline. In addition, performance surpassed a logistic regression model based\non handcrafted HRV features by 12%, highlighting the benefit of multimodal\nfusion and attention-based learning in noisy, real-world clinical data.", "AI": {"tldr": "RhythmiNet\u662f\u4e00\u79cd\u7ed3\u5408PPG\u548c\u52a0\u901f\u5ea6\u8ba1\u4fe1\u53f7\u7684\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u65f6\u95f4\u4e0e\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u6539\u8fdb\u5fc3\u623f\u98a4\u52a8\u68c0\u6d4b\uff0c\u5728\u5608\u6742\u7684\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5355\u901a\u9053PPG\u7684\u5fc3\u623f\u98a4\u52a8\u68c0\u6d4b\u65b9\u6cd5\u6613\u53d7\u8fd0\u52a8\u4f2a\u5f71\u548c\u751f\u7406\u566a\u58f0\u5f71\u54cd\uff0c\u4e14\u4ec5\u9650\u4e8e\u4e8c\u5143\u5206\u7c7b\uff0c\u65e0\u6cd5\u6355\u6349\u4e34\u5e8a\u4e2d\u66f4\u5e7f\u6cdb\u7684\u5fc3\u5f8b\u5931\u5e38\u7c7b\u578b\u3002", "method": "\u63d0\u51faRhythmiNet\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\uff0c\u96c6\u6210\u65f6\u95f4\u548c\u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8054\u5408\u5229\u7528PPG\u548c\u52a0\u901f\u5ea6\u8ba1\u4fe1\u53f7\u8fdb\u884c\u4e09\u7c7b\u5fc3\u5f8b\u5206\u7c7b\uff08AF\u3001\u7aa6\u6027\u5fc3\u5f8b\u3001\u5176\u4ed6\uff09\u3002\u6d4b\u8bd5\u6570\u636e\u6309\u8fd0\u52a8\u5f3a\u5ea6\u5206\u5c42\u8bc4\u4f30\u9c81\u68d2\u6027\u3002", "result": "RhythmiNet\u76f8\u6bd4\u4ec5\u4f7f\u7528PPG\u7684\u57fa\u7ebf\u65b9\u6cd5\u5728macro-AUC\u4e0a\u63d0\u53474.3%\uff0c\u6bd4\u57fa\u4e8e\u624b\u5de5HRV\u7279\u5f81\u903b\u8f91\u56de\u5f52\u6a21\u578b\u6027\u80fd\u63d0\u534712%\u3002", "conclusion": "\u591a\u6a21\u6001\u878d\u5408\u548c\u6ce8\u610f\u529b\u5b66\u4e60\u5728\u5608\u6742\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u63d0\u9ad8\u5fc3\u5f8b\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00958", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00958", "abs": "https://arxiv.org/abs/2511.00958", "authors": ["Khoat Than"], "title": "The Hidden Power of Normalization: Exponential Capacity Control in Deep Neural Networks", "comment": null, "summary": "Normalization methods are fundamental components of modern deep neural\nnetworks (DNNs). Empirically, they are known to stabilize optimization dynamics\nand improve generalization. However, the underlying theoretical mechanism by\nwhich normalization contributes to both optimization and generalization remains\nlargely unexplained, especially when using many normalization layers in a DNN\narchitecture.\n  In this work, we develop a theoretical framework that elucidates the role of\nnormalization through the lens of capacity control. We prove that an\nunnormalized DNN can exhibit exponentially large Lipschitz constants with\nrespect to either its parameters or inputs, implying excessive functional\ncapacity and potential overfitting. Such bad DNNs are uncountably many. In\ncontrast, the insertion of normalization layers provably can reduce the\nLipschitz constant at an exponential rate in the number of normalization\noperations. This exponential reduction yields two fundamental consequences: (1)\nit smooths the loss landscape at an exponential rate, facilitating faster and\nmore stable optimization; and (2) it constrains the effective capacity of the\nnetwork, thereby enhancing generalization guarantees on unseen data. Our\nresults thus offer a principled explanation for the empirical success of\nnormalization methods in deep learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u5bb9\u91cf\u63a7\u5236\u7684\u89d2\u5ea6\u89e3\u91ca\u4e86\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4f5c\u7528\u3002\u7814\u7a76\u8868\u660e\u5f52\u4e00\u5316\u5c42\u80fd\u6307\u6570\u7ea7\u964d\u4f4e\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\uff0c\u4ece\u800c\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u5e76\u7ea6\u675f\u6709\u6548\u5bb9\u91cf\uff0c\u6539\u5584\u4f18\u5316\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u662f\u57fa\u672c\u7ec4\u4ef6\uff0c\u7ecf\u9a8c\u4e0a\u5df2\u77e5\u80fd\u7a33\u5b9a\u4f18\u5316\u52a8\u6001\u5e76\u6539\u5584\u6cdb\u5316\uff0c\u4f46\u5176\u7406\u8bba\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u591a\u4e2a\u5f52\u4e00\u5316\u5c42\u65f6\u7684\u4f5c\u7528\u539f\u7406\uff0c\u4ecd\u7136\u7f3a\u4e4f\u89e3\u91ca\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5bb9\u91cf\u63a7\u5236\u7684\u89c6\u89d2\u5206\u6790\u5f52\u4e00\u5316\u4f5c\u7528\u3002\u8bc1\u660e\u4e86\u672a\u5f52\u4e00\u5316DNN\u53ef\u80fd\u5177\u6709\u6307\u6570\u7ea7\u5927\u7684Lipschitz\u5e38\u6570\uff0c\u800c\u63d2\u5165\u5f52\u4e00\u5316\u5c42\u80fd\u4ee5\u6307\u6570\u901f\u7387\u964d\u4f4eLipschitz\u5e38\u6570\u3002", "result": "\u5f52\u4e00\u5316\u5c42\u80fd\u6307\u6570\u7ea7\u964d\u4f4eLipschitz\u5e38\u6570\uff0c\u8fd9\u5bfc\u81f4\u4e24\u4e2a\u57fa\u672c\u540e\u679c\uff1a(1) \u4ee5\u6307\u6570\u901f\u7387\u5e73\u6ed1\u635f\u5931\u666f\u89c2\uff0c\u4fc3\u8fdb\u66f4\u5feb\u66f4\u7a33\u5b9a\u7684\u4f18\u5316\uff1b(2) \u7ea6\u675f\u7f51\u7edc\u7684\u6709\u6548\u5bb9\u91cf\uff0c\u4ece\u800c\u589e\u5f3a\u5728\u672a\u89c1\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u7ecf\u9a8c\u6210\u529f\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u91ca\uff0c\u4ece\u7406\u8bba\u4e0a\u9610\u660e\u4e86\u5f52\u4e00\u5316\u5982\u4f55\u901a\u8fc7\u63a7\u5236\u5bb9\u91cf\u6765\u540c\u65f6\u6539\u5584\u4f18\u5316\u548c\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2511.00964", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00964", "abs": "https://arxiv.org/abs/2511.00964", "authors": ["Hai Hoang Thanh", "Duy-Tung Nguyen", "Hung The Tran", "Khoat Than"], "title": "Using Synthetic Data to estimate the True Error is theoretically and practically doable", "comment": "To appear at Machine Learning journal and ACML", "summary": "Accurately evaluating model performance is crucial for deploying machine\nlearning systems in real-world applications. Traditional methods often require\na sufficiently large labeled test set to ensure a reliable evaluation. However,\nin many contexts, a large labeled dataset is costly and labor-intensive.\nTherefore, we sometimes have to do evaluation by a few labeled samples, which\nis theoretically challenging. Recent advances in generative models offer a\npromising alternative by enabling the synthesis of high-quality data. In this\nwork, we make a systematic investigation about the use of synthetic data to\nestimate the test error of a trained model under limited labeled data\nconditions. To this end, we develop novel generalization bounds that take\nsynthetic data into account. Those bounds suggest novel ways to optimize\nsynthetic samples for evaluation and theoretically reveal the significant role\nof the generator's quality. Inspired by those bounds, we propose a\ntheoretically grounded method to generate optimized synthetic data for model\nevaluation. Experimental results on simulation and tabular datasets demonstrate\nthat, compared to existing baselines, our method achieves accurate and more\nreliable estimates of the test error.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u751f\u6210\u6a21\u578b\u5408\u6210\u6570\u636e\u6765\u4f30\u8ba1\u6a21\u578b\u6d4b\u8bd5\u8bef\u5dee\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6807\u8bb0\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u57fa\u7ebf\u66f4\u51c6\u786e\u53ef\u9760\u3002", "motivation": "\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u83b7\u53d6\u5927\u91cf\u6807\u8bb0\u6d4b\u8bd5\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u800c\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u9700\u8981\u8db3\u591f\u5927\u7684\u6807\u8bb0\u6d4b\u8bd5\u96c6\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u6709\u9650\u6807\u8bb0\u6570\u636e\u6761\u4ef6\u4e0b\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u8003\u8651\u5408\u6210\u6570\u636e\u7684\u6cdb\u5316\u8fb9\u754c\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7406\u8bba\u6307\u5bfc\u7684\u4f18\u5316\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6a21\u578b\u8bc4\u4f30\u3002", "result": "\u5728\u6a21\u62df\u548c\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u66f4\u51c6\u786e\u53ef\u9760\u7684\u6d4b\u8bd5\u8bef\u5dee\u4f30\u8ba1\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u5408\u6210\u7684\u4f18\u5316\u6570\u636e\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u6709\u9650\u6807\u8bb0\u6570\u636e\u4e0b\u7684\u6a21\u578b\u8bc4\u4f30\u95ee\u9898\uff0c\u751f\u6210\u5668\u8d28\u91cf\u5bf9\u8bc4\u4f30\u51c6\u786e\u6027\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2511.00977", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.00977", "abs": "https://arxiv.org/abs/2511.00977", "authors": ["Kristiyan Sakalyan", "Alessandro Palma", "Filippo Guerranti", "Fabian J. Theis", "Stephan G\u00fcnnemann"], "title": "Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow", "comment": "37 pages, 15 figures, to appear in NeurIPS 2025", "summary": "Understanding the evolution of cellular microenvironments in spatiotemporal\ndata is essential for deciphering tissue development and disease progression.\nWhile experimental techniques like spatial transcriptomics now enable\nhigh-resolution mapping of tissue organization across space and time, current\nmethods that model cellular evolution operate at the single-cell level,\noverlooking the coordinated development of cellular states in a tissue. We\nintroduce NicheFlow, a flow-based generative model that infers the temporal\ntrajectory of cellular microenvironments across sequential spatial slides. By\nrepresenting local cell neighborhoods as point clouds, NicheFlow jointly models\nthe evolution of cell states and spatial coordinates using optimal transport\nand Variational Flow Matching. Our approach successfully recovers both global\nspatial architecture and local microenvironment composition across diverse\nspatiotemporal datasets, from embryonic to brain development.", "AI": {"tldr": "NicheFlow\u662f\u4e00\u79cd\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u63a8\u65ad\u8fde\u7eed\u7a7a\u95f4\u5207\u7247\u4e2d\u7ec6\u80de\u5fae\u73af\u5883\u7684\u65f6\u5e8f\u8f68\u8ff9\uff0c\u901a\u8fc7\u5c06\u5c40\u90e8\u7ec6\u80de\u90bb\u57df\u8868\u793a\u4e3a\u70b9\u4e91\uff0c\u7ed3\u5408\u6700\u4f18\u4f20\u8f93\u548c\u53d8\u5206\u6d41\u5339\u914d\u6765\u8054\u5408\u5efa\u6a21\u7ec6\u80de\u72b6\u6001\u548c\u7a7a\u95f4\u5750\u6807\u7684\u6f14\u5316\u3002", "motivation": "\u7406\u89e3\u7ec6\u80de\u5fae\u73af\u5883\u5728\u65f6\u7a7a\u6570\u636e\u4e2d\u7684\u6f14\u5316\u5bf9\u4e8e\u89e3\u6790\u7ec4\u7ec7\u53d1\u80b2\u548c\u75be\u75c5\u8fdb\u5c55\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u5355\u7ec6\u80de\u6c34\u5e73\u5efa\u6a21\u65b9\u6cd5\u5ffd\u7565\u4e86\u7ec4\u7ec7\u4e2d\u7ec6\u80de\u72b6\u6001\u7684\u534f\u8c03\u53d1\u80b2\u3002", "method": "\u5c06\u5c40\u90e8\u7ec6\u80de\u90bb\u57df\u8868\u793a\u4e3a\u70b9\u4e91\uff0c\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u548c\u53d8\u5206\u6d41\u5339\u914d\u8054\u5408\u5efa\u6a21\u7ec6\u80de\u72b6\u6001\u548c\u7a7a\u95f4\u5750\u6807\u7684\u6f14\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u65f6\u7a7a\u6570\u636e\u96c6\uff08\u4ece\u80da\u80ce\u53d1\u80b2\u5230\u5927\u8111\u53d1\u80b2\uff09\u4e2d\u6210\u529f\u6062\u590d\u4e86\u5168\u5c40\u7a7a\u95f4\u7ed3\u6784\u548c\u5c40\u90e8\u5fae\u73af\u5883\u7ec4\u6210\u3002", "conclusion": "NicheFlow\u80fd\u591f\u6709\u6548\u63a8\u65ad\u7ec6\u80de\u5fae\u73af\u5883\u7684\u65f6\u7a7a\u6f14\u5316\u8f68\u8ff9\uff0c\u4e3a\u7406\u89e3\u7ec4\u7ec7\u53d1\u80b2\u548c\u75be\u75c5\u8fdb\u5c55\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2511.00987", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00987", "abs": "https://arxiv.org/abs/2511.00987", "authors": ["Rongrong Xie", "Guido Sanguinetti"], "title": "Balanced Multimodal Learning via Mutual Information", "comment": null, "summary": "Multimodal learning has increasingly become a focal point in research,\nprimarily due to its ability to integrate complementary information from\ndiverse modalities. Nevertheless, modality imbalance, stemming from factors\nsuch as insufficient data acquisition and disparities in data quality, has\noften been inadequately addressed. This issue is particularly prominent in\nbiological data analysis, where datasets are frequently limited, costly to\nacquire, and inherently heterogeneous in quality. Conventional multimodal\nmethodologies typically fall short in concurrently harnessing intermodal\nsynergies and effectively resolving modality conflicts.\n  In this study, we propose a novel unified framework explicitly designed to\naddress modality imbalance by utilizing mutual information to quantify\ninteractions between modalities. Our approach adopts a balanced multimodal\nlearning strategy comprising two key stages: cross-modal knowledge distillation\n(KD) and a multitask-like training paradigm. During the cross-modal KD\npretraining phase, stronger modalities are leveraged to enhance the predictive\ncapabilities of weaker modalities. Subsequently, our primary training phase\nemploys a multitask-like learning mechanism, dynamically calibrating gradient\ncontributions based on modality-specific performance metrics and intermodal\nmutual information. This approach effectively alleviates modality imbalance,\nthereby significantly improving overall multimodal model performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u91cf\u5316\u6a21\u6001\u95f4\u4ea4\u4e92\uff0c\u91c7\u7528\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u548c\u591a\u4efb\u52a1\u5f0f\u8bad\u7ec3\u6765\u5e73\u8861\u4e0d\u540c\u6a21\u6001\u7684\u8d21\u732e\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u9762\u4e34\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u751f\u7269\u6570\u636e\u5206\u6790\u4e2d\uff0c\u6570\u636e\u96c6\u6709\u9650\u3001\u83b7\u53d6\u6210\u672c\u9ad8\u4e14\u8d28\u91cf\u4e0d\u5747\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5229\u7528\u6a21\u6001\u95f4\u534f\u540c\u6548\u5e94\u5e76\u6709\u6548\u89e3\u51b3\u6a21\u6001\u51b2\u7a81\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5e73\u8861\u591a\u6a21\u6001\u5b66\u4e60\u7b56\u7565\uff1a1) \u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u9884\u8bad\u7ec3\uff0c\u7528\u5f3a\u6a21\u6001\u589e\u5f3a\u5f31\u6a21\u6001\u9884\u6d4b\u80fd\u529b\uff1b2) \u591a\u4efb\u52a1\u5f0f\u4e3b\u8bad\u7ec3\uff0c\u57fa\u4e8e\u6a21\u6001\u7279\u5b9a\u6027\u80fd\u6307\u6807\u548c\u6a21\u6001\u95f4\u4e92\u4fe1\u606f\u52a8\u6001\u6821\u51c6\u68af\u5ea6\u8d21\u732e\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u901a\u8fc7\u4e92\u4fe1\u606f\u91cf\u5316\u548c\u5e73\u8861\u5b66\u4e60\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u6311\u6218\uff0c\u4e3a\u751f\u7269\u6570\u636e\u7b49\u591a\u6a21\u6001\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00989", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00989", "abs": "https://arxiv.org/abs/2511.00989", "authors": ["Asal Meskin", "Alireza Mirrokni", "Ali Najar", "Ali Behrouz"], "title": "Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis", "comment": null, "summary": "In recent years, effectively modeling multivariate time series has gained\nsignificant popularity, mainly due to its wide range of applications, ranging\nfrom healthcare to financial markets and energy management. Transformers, MLPs,\nand linear models as the de facto backbones of modern time series models have\nshown promising results in single-variant and/or short-term forecasting. These\nmodels, however: (1) are permutation equivariant and so lack temporal inductive\nbias, being less expressive to capture the temporal dynamics; (2) are naturally\ndesigned for univariate setup, missing the inter-dependencies of temporal and\nvariate dimensions; and/or (3) are inefficient for Long-term time series\nmodeling. To overcome training and inference efficiency as well as the lack of\ntemporal inductive bias, recently, linear Recurrent Neural Networks (RNNs) have\ngained attention as an alternative to Transformer-based models. These models,\nhowever, are inherently limited to a single sequence, missing inter-variate\ndependencies, and can propagate errors due to their additive nature. In this\npaper, we present Hydra, a by-design two-headed meta in-context memory module\nthat learns how to memorize patterns at test time by prioritizing time series\npatterns that are more informative about the data. Hydra uses a 2-dimensional\nrecurrence across both time and variate at each step, which is more powerful\nthan mixing methods. Although the 2-dimensional nature of the model makes its\ntraining recurrent and non-parallelizable, we present a new 2D-chunk-wise\ntraining algorithm that approximates the actual recurrence with $\\times 10$\nefficiency improvement, while maintaining the effectiveness. Our experimental\nresults on a diverse set of tasks and datasets, including time series\nforecasting, classification, and anomaly detection show the superior\nperformance of Hydra compared to state-of-the-art baselines.", "AI": {"tldr": "Hydra\u662f\u4e00\u4e2a\u53cc\u5934\u5143\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u6a21\u5757\uff0c\u901a\u8fc72\u7ef4\u9012\u5f52\u5728\u65f6\u95f4\u548c\u53d8\u91cf\u7ef4\u5ea6\u4e0a\u5b66\u4e60\u6a21\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7f3a\u4e4f\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\u3001\u5ffd\u7565\u53d8\u91cf\u95f4\u4f9d\u8d56\u5173\u7cfb\u4ee5\u53ca\u957f\u5e8f\u5217\u5efa\u6a21\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709Transformer\u3001MLP\u548c\u7ebf\u6027\u6a21\u578b\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(1)\u7f6e\u6362\u7b49\u53d8\u6027\u5bfc\u81f4\u7f3a\u4e4f\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\uff1b(2)\u81ea\u7136\u8bbe\u8ba1\u4e3a\u5355\u53d8\u91cf\u8bbe\u7f6e\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u548c\u53d8\u91cf\u7ef4\u5ea6\u7684\u76f8\u4e92\u4f9d\u8d56\uff1b(3)\u957f\u5e8f\u5217\u5efa\u6a21\u6548\u7387\u4f4e\u3002\u7ebf\u6027RNN\u867d\u7136\u89e3\u51b3\u4e86\u6548\u7387\u548c\u5f52\u7eb3\u504f\u7f6e\u95ee\u9898\uff0c\u4f46\u5c40\u9650\u4e8e\u5355\u5e8f\u5217\u4e14\u4f1a\u4f20\u64ad\u8bef\u5dee\u3002", "method": "Hydra\u91c7\u7528\u53cc\u5934\u5143\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u6a21\u5757\uff0c\u901a\u8fc72\u7ef4\u9012\u5f52\u5728\u65f6\u95f4\u548c\u53d8\u91cf\u7ef4\u5ea6\u4e0a\u5b66\u4e60\u6a21\u5f0f\uff0c\u4f18\u5148\u8bb0\u5fc6\u66f4\u4fe1\u606f\u4e30\u5bcc\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u3002\u867d\u71362\u7ef4\u7279\u6027\u4f7f\u8bad\u7ec3\u9012\u5f52\u4e14\u4e0d\u53ef\u5e76\u884c\uff0c\u4f46\u63d0\u51fa\u4e862D\u5206\u5757\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u6548\u679c\u7684\u540c\u65f6\u5b9e\u73b010\u500d\u6548\u7387\u63d0\u5347\u3002", "result": "\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3001\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u7b49\u591a\u4e2a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHydra\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "Hydra\u901a\u8fc72\u7ef4\u9012\u5f52\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u7b97\u6cd5\u4fdd\u8bc1\u4e86\u6548\u7387\u3002"}}
{"id": "2511.01006", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01006", "abs": "https://arxiv.org/abs/2511.01006", "authors": ["Diantong Li", "Kyunghyun Cho", "Chong Liu"], "title": "None To Optima in Few Shots: Bayesian Optimization with MDP Priors", "comment": null, "summary": "Bayesian Optimization (BO) is an efficient tool for optimizing black-box\nfunctions, but its theoretical guarantees typically hold in the asymptotic\nregime. In many critical real-world applications such as drug discovery or\nmaterials design, where each evaluation can be very costly and time-consuming,\nBO becomes impractical for many evaluations. In this paper, we introduce the\nProcedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization\nwith remarkably few function evaluations. At the heart of our algorithmic\ndesign are Markov Decision Process (MDP) priors that model optimization\ntrajectories from related source tasks, thereby capturing procedural knowledge\non efficient optimization. We embed these MDP priors into a prior-fitted neural\nnetwork and employ model-agnostic meta-learning for fast adaptation to new\ntarget tasks. Experiments on real-world Covid and Cancer benchmarks and\nhyperparameter tuning tasks demonstrate that ProfBO consistently outperforms\nstate-of-the-art methods by achieving high-quality solutions with significantly\nfewer evaluations, making it ready for practical deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86ProfBO\u7b97\u6cd5\uff0c\u901a\u8fc7MDP\u5148\u9a8c\u5efa\u6a21\u76f8\u5173\u4efb\u52a1\u7684\u4f18\u5316\u8f68\u8ff9\uff0c\u663e\u8457\u51cf\u5c11\u9ed1\u76d2\u4f18\u5316\u6240\u9700\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u56e0\u8bc4\u4f30\u6210\u672c\u9ad8\u6602\u800c\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5728\u5c11\u91cf\u8bc4\u4f30\u4e0b\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528MDP\u5148\u9a8c\u5efa\u6a21\u6e90\u4efb\u52a1\u7684\u4f18\u5316\u8f68\u8ff9\uff0c\u5c06\u5148\u9a8c\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u91c7\u7528\u6a21\u578b\u65e0\u5173\u5143\u5b66\u4e60\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1", "result": "\u5728Covid\u3001Cancer\u57fa\u51c6\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u4efb\u52a1\u4e2d\uff0cProfBO\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u7528\u66f4\u5c11\u8bc4\u4f30\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3", "conclusion": "ProfBO\u5df2\u51c6\u5907\u597d\u5b9e\u9645\u90e8\u7f72\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u8bc4\u4f30\u6210\u672c\u9ad8\u6602\u7684\u9ed1\u76d2\u4f18\u5316\u95ee\u9898"}}
{"id": "2511.01009", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01009", "abs": "https://arxiv.org/abs/2511.01009", "authors": ["Fabricio Olivetti de Franca", "Gabriel Kronberger"], "title": "Equality Graph Assisted Symbolic Regression", "comment": null, "summary": "In Symbolic Regression (SR), Genetic Programming (GP) is a popular search\nalgorithm that delivers state-of-the-art results in term of accuracy. Its\nsuccess relies on the concept of neutrality, which induces large plateaus that\nthe search can safely navigate to more promising regions. Navigating these\nplateaus, while necessary, requires the computation of redundant expressions,\nup to 60% of the total number of evaluation, as noted in a recent study. The\nequality graph (e-graph) structure can compactly store and group equivalent\nexpressions enabling us to verify if a given expression and their variations\nwere already visited by the search, thus enabling us to avoid unnecessary\ncomputation. We propose a new search algorithm for symbolic regression called\nSymRegg that revolves around the e-graph structure following simple steps:\nperturb solutions sampled from a selection of expressions stored in the\ne-graph, if it generates an unvisited expression, insert it into the e-graph\nand generates its equivalent forms. We show that SymRegg is capable of\nimproving the efficiency of the search, maintaining consistently accurate\nresults across different datasets while requiring a choice of a minimalist set\nof hyperparameters.", "AI": {"tldr": "\u63d0\u51faSymRegg\u7b97\u6cd5\uff0c\u5229\u7528\u7b49\u5f0f\u56fe(e-graph)\u7ed3\u6784\u907f\u514d\u7b26\u53f7\u56de\u5f52\u4e2d\u5197\u4f59\u8868\u8fbe\u5f0f\u8ba1\u7b97\uff0c\u63d0\u9ad8\u641c\u7d22\u6548\u7387", "motivation": "\u9057\u4f20\u7f16\u7a0b\u5728\u7b26\u53f7\u56de\u5f52\u4e2d\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u5197\u4f59\u8868\u8fbe\u5f0f\uff08\u53ef\u8fbe\u603b\u8bc4\u4f30\u6b21\u6570\u768460%\uff09\uff0c\u901a\u8fc7e-graph\u7ed3\u6784\u53ef\u4ee5\u907f\u514d\u91cd\u590d\u8ba1\u7b97", "method": "\u57fa\u4e8ee-graph\u7ed3\u6784\u7684\u65b0\u641c\u7d22\u7b97\u6cd5\uff1a\u4ecee-graph\u4e2d\u9009\u62e9\u8868\u8fbe\u5f0f\u8fdb\u884c\u6270\u52a8\uff0c\u82e5\u751f\u6210\u672a\u8bbf\u95ee\u8868\u8fbe\u5f0f\u5219\u63d2\u5165e-graph\u5e76\u751f\u6210\u7b49\u4ef7\u5f62\u5f0f", "result": "SymRegg\u63d0\u9ad8\u4e86\u641c\u7d22\u6548\u7387\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u51c6\u786e\u7ed3\u679c\uff0c\u4e14\u53ea\u9700\u6781\u7b80\u8d85\u53c2\u6570\u9009\u62e9", "conclusion": "e-graph\u7ed3\u6784\u80fd\u6709\u6548\u63d0\u5347\u7b26\u53f7\u56de\u5f52\u641c\u7d22\u6548\u7387\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97"}}
{"id": "2511.01015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01015", "abs": "https://arxiv.org/abs/2511.01015", "authors": ["Nabeel Seedat", "Jiashuo Liu", "Mihaela van der Schaar"], "title": "What's the next frontier for Data-centric AI? Data Savvy Agents", "comment": "Presented at ICLR 2025 Data-FM. Seedat & Liu contributed equally", "summary": "The recent surge in AI agents that autonomously communicate, collaborate with\nhumans and use diverse tools has unlocked promising opportunities in various\nreal-world settings. However, a vital aspect remains underexplored: how agents\nhandle data. Scalable autonomy demands agents that continuously acquire,\nprocess, and evolve their data. In this paper, we argue that data-savvy\ncapabilities should be a top priority in the design of agentic systems to\nensure reliable real-world deployment. Specifically, we propose four key\ncapabilities to realize this vision: (1) Proactive data acquisition: enabling\nagents to autonomously gather task-critical knowledge or solicit human input to\naddress data gaps; (2) Sophisticated data processing: requiring context-aware\nand flexible handling of diverse data challenges and inputs; (3) Interactive\ntest data synthesis: shifting from static benchmarks to dynamically generated\ninteractive test data for agent evaluation; and (4) Continual adaptation:\nempowering agents to iteratively refine their data and background knowledge to\nadapt to shifting environments. While current agent research predominantly\nemphasizes reasoning, we hope to inspire a reflection on the role of data-savvy\nagents as the next frontier in data-centric AI.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5728\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5e94\u5c06\u6570\u636e\u5904\u7406\u80fd\u529b\u4f5c\u4e3a\u9996\u8981\u8003\u91cf\uff0c\u63d0\u51fa\u4e86\u5b9e\u73b0\u6570\u636e\u611f\u77e5\u4ee3\u7406\u7684\u56db\u4e2a\u5173\u952e\u80fd\u529b\uff1a\u4e3b\u52a8\u6570\u636e\u83b7\u53d6\u3001\u590d\u6742\u6570\u636e\u5904\u7406\u3001\u4ea4\u4e92\u5f0f\u6d4b\u8bd5\u6570\u636e\u5408\u6210\u548c\u6301\u7eed\u9002\u5e94\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u81ea\u4e3b\u901a\u4fe1\u3001\u534f\u4f5c\u548c\u4f7f\u7528\u5de5\u5177\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u636e\u5904\u7406\u65b9\u9762\u4ecd\u88ab\u5ffd\u89c6\u3002\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u6027\u9700\u8981\u4ee3\u7406\u80fd\u591f\u6301\u7eed\u83b7\u53d6\u3001\u5904\u7406\u548c\u53d1\u5c55\u6570\u636e\uff0c\u4ee5\u786e\u4fdd\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u4e2a\u5173\u952e\u80fd\u529b\u6846\u67b6\uff1a(1)\u4e3b\u52a8\u6570\u636e\u83b7\u53d6\uff1a\u4ee3\u7406\u81ea\u4e3b\u6536\u96c6\u4efb\u52a1\u5173\u952e\u77e5\u8bc6\u6216\u5f81\u6c42\u4eba\u7c7b\u8f93\u5165\u586b\u8865\u6570\u636e\u7a7a\u767d\uff1b(2)\u590d\u6742\u6570\u636e\u5904\u7406\uff1a\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u7075\u6d3b\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u6311\u6218\u548c\u8f93\u5165\uff1b(3)\u4ea4\u4e92\u5f0f\u6d4b\u8bd5\u6570\u636e\u5408\u6210\uff1a\u4ece\u9759\u6001\u57fa\u51c6\u8f6c\u5411\u52a8\u6001\u751f\u6210\u7684\u4ea4\u4e92\u5f0f\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u4ee3\u7406\u8bc4\u4f30\uff1b(4)\u6301\u7eed\u9002\u5e94\uff1a\u4ee3\u7406\u8fed\u4ee3\u4f18\u5316\u6570\u636e\u548c\u80cc\u666f\u77e5\u8bc6\u4ee5\u9002\u5e94\u53d8\u5316\u73af\u5883\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6570\u636e\u611f\u77e5\u4ee3\u7406\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f3a\u8c03\u6570\u636e\u5904\u7406\u80fd\u529b\u5e94\u6210\u4e3a\u4ee3\u7406\u8bbe\u8ba1\u7684\u6838\u5fc3\u8981\u7d20\uff0c\u800c\u975e\u4ec5\u4ec5\u5173\u6ce8\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u5f53\u524d\u4ee3\u7406\u7814\u7a76\u4e3b\u8981\u5f3a\u8c03\u63a8\u7406\u80fd\u529b\uff0c\u672c\u6587\u65e8\u5728\u6fc0\u53d1\u5bf9\u6570\u636e\u611f\u77e5\u4ee3\u7406\u4f5c\u4e3a\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3AI\u4e0b\u4e00\u4e2a\u524d\u6cbf\u9886\u57df\u7684\u601d\u8003\uff0c\u63a8\u52a8\u4ee3\u7406\u7cfb\u7edf\u5411\u66f4\u53ef\u9760\u7684\u5b9e\u9645\u90e8\u7f72\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2511.01017", "categories": ["cs.LG", "62M10, 62P12", "G.3; H.2.8"], "pdf": "https://arxiv.org/pdf/2511.01017", "abs": "https://arxiv.org/abs/2511.01017", "authors": ["Haoran Ye", "Qiuzhuang Sun", "Yang Yang"], "title": "SARIMAX-Based Power Outage Prediction During Extreme Weather Events", "comment": "12 pages, 3 figures. This paper presents the solution of Team 12 for\n  the 2025 INFORMS Data Mining Society Data Challenge. The open-source code is\n  available at: https://github.com/yhr-code/2025-INFORMS-DM-Challenge-Team12", "summary": "This study develops a SARIMAX-based prediction system for short-term power\noutage forecasting during extreme weather events. Using hourly data from\nMichigan counties with outage counts and comprehensive weather features, we\nimplement a systematic two-stage feature engineering pipeline: data cleaning to\nremove zero-variance and unknown features, followed by correlation-based\nfiltering to eliminate highly correlated predictors. The selected features are\naugmented with temporal embeddings, multi-scale lag features, and weather\nvariables with their corresponding lags as exogenous inputs to the SARIMAX\nmodel. To address data irregularity and numerical instability, we apply\nstandardization and implement a hierarchical fitting strategy with sequential\noptimization methods, automatic downgrading to ARIMA when convergence fails,\nand historical mean-based fallback predictions as a final safeguard. The model\nis optimized separately for short-term (24 hours) and medium-term (48 hours)\nforecast horizons using RMSE as the evaluation metric. Our approach achieves an\nRMSE of 177.2, representing an 8.4\\% improvement over the baseline method (RMSE\n= 193.4), thereby validating the effectiveness of our feature engineering and\nrobust optimization strategy for extreme weather-related outage prediction.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eSARIMAX\u7684\u77ed\u671f\u505c\u7535\u9884\u6d4b\u7cfb\u7edf\uff0c\u7528\u4e8e\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u7279\u5f81\u5de5\u7a0b\u548c\u7a33\u5065\u4f18\u5316\u7b56\u7565\uff0c\u572824\u5c0f\u65f6\u548c48\u5c0f\u65f6\u9884\u6d4b\u8303\u56f4\u5185\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u53478.4%\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u671f\u95f4\u77ed\u671f\u7535\u529b\u4e2d\u65ad\u7684\u51c6\u786e\u9884\u6d4b\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u6570\u636e\u4e0d\u89c4\u5219\u6027\u548c\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7279\u5f81\u5de5\u7a0b\uff08\u6570\u636e\u6e05\u6d17\u548c\u76f8\u5173\u6027\u8fc7\u6ee4\uff09\uff0c\u7ed3\u5408\u65f6\u95f4\u5d4c\u5165\u3001\u591a\u5c3a\u5ea6\u6ede\u540e\u7279\u5f81\u548c\u5929\u6c14\u53d8\u91cf\u4f5c\u4e3a\u5916\u751f\u8f93\u5165\uff0c\u4f7f\u7528SARIMAX\u6a21\u578b\uff0c\u5e76\u5b9e\u65bd\u6807\u51c6\u5316\u3001\u5206\u5c42\u62df\u5408\u7b56\u7565\u548c\u56de\u9000\u673a\u5236\u3002", "result": "\u6a21\u578b\u5728RMSE\u6307\u6807\u4e0a\u8fbe\u5230177.2\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff08193.4\uff09\u63d0\u5347\u4e868.4%\uff0c\u9a8c\u8bc1\u4e86\u7279\u5f81\u5de5\u7a0b\u548c\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684SARIMAX\u9884\u6d4b\u7cfb\u7edf\u5728\u6781\u7aef\u5929\u6c14\u76f8\u5173\u7684\u505c\u7535\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u5f81\u5de5\u7a0b\u548c\u7a33\u5065\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2511.01054", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01054", "abs": "https://arxiv.org/abs/2511.01054", "authors": ["Sama Salarian", "Yue Zhang", "Swati Padhee", "Srinivasan Parthasarathy"], "title": "MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation", "comment": null, "summary": "Synthetic healthcare data generation presents a viable approach to enhance\ndata accessibility and support research by overcoming limitations associated\nwith real-world medical datasets. However, ensuring fairness across protected\nattributes in synthetic data is critical to avoid biased or misleading results\nin clinical research and decision-making. In this study, we assess the fairness\nof synthetic data generated by multiple generative adversarial network\n(GAN)-based models using the MIMIC-III dataset, with a focus on\nrepresentativeness across protected demographic attributes. We measure subgroup\nrepresentation using the logarithmic disparity metric and observe significant\nimbalances, with many subgroups either underrepresented or overrepresented in\nthe synthetic data, compared to the real data. To mitigate these disparities,\nwe introduce MedEqualizer, a model-agnostic augmentation framework that\nenriches the underrepresented subgroups prior to synthetic data generation. Our\nresults show that MedEqualizer significantly improves demographic balance in\nthe resulting synthetic datasets, offering a viable path towards more equitable\nand representative healthcare data synthesis.", "AI": {"tldr": "\u8bc4\u4f30\u57fa\u4e8eGAN\u7684\u5408\u6210\u533b\u7597\u6570\u636e\u516c\u5e73\u6027\uff0c\u63d0\u51faMedEqualizer\u6846\u67b6\u6539\u5584\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u8861", "motivation": "\u5408\u6210\u533b\u7597\u6570\u636e\u53ef\u63d0\u9ad8\u6570\u636e\u53ef\u8bbf\u95ee\u6027\uff0c\u4f46\u9700\u786e\u4fdd\u8de8\u53d7\u4fdd\u62a4\u5c5e\u6027\u7684\u516c\u5e73\u6027\uff0c\u907f\u514d\u4e34\u5e8a\u7814\u7a76\u548c\u51b3\u7b56\u4e2d\u7684\u504f\u89c1", "method": "\u4f7f\u7528MIMIC-III\u6570\u636e\u96c6\u8bc4\u4f30\u591a\u79cdGAN\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u5f15\u5165MedEqualizer\u6a21\u578b\u65e0\u5173\u589e\u5f3a\u6846\u67b6\u6765\u4e30\u5bcc\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u4e9a\u7ec4", "result": "\u5408\u6210\u6570\u636e\u4e2d\u5b58\u5728\u663e\u8457\u4e9a\u7ec4\u4e0d\u5e73\u8861\uff0cMedEqualizer\u663e\u8457\u6539\u5584\u4e86\u5408\u6210\u6570\u636e\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u8861", "conclusion": "MedEqualizer\u4e3a\u66f4\u516c\u5e73\u548c\u4ee3\u8868\u6027\u7684\u533b\u7597\u6570\u636e\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84"}}
{"id": "2511.01060", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01060", "abs": "https://arxiv.org/abs/2511.01060", "authors": ["Andrew Hallam", "R G Gayathri", "Glory Lee", "Atul Sajjanhar"], "title": "Window-Based Feature Engineering for Cognitive Workload Detection", "comment": "9 pages, 3 figures", "summary": "Cognitive workload is a topic of increasing interest across various fields\nsuch as health, psychology, and defense applications. In this research, we\nfocus on classifying cognitive workload using the COLET dataset, employing a\nwindow-based approach for feature generation and machine/deep learning\ntechniques for classification. We apply window-based temporal partitioning to\nenhance features used in existing research, followed by machine learning and\ndeep learning models to classify different levels of cognitive workload. The\nresults demonstrate that deep learning models, particularly tabular\narchitectures, outperformed traditional machine learning methods in precision,\nF1-score, accuracy, and classification precision. This study highlights the\neffectiveness of window-based temporal feature extraction and the potential of\ndeep learning techniques for real-time cognitive workload assessment in complex\nand dynamic tasks.", "AI": {"tldr": "\u4f7f\u7528COLET\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u57fa\u4e8e\u7a97\u53e3\u7684\u65f6\u95f4\u7279\u5f81\u63d0\u53d6\u548c\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5bf9\u8ba4\u77e5\u8d1f\u8377\u8fdb\u884c\u5206\u7c7b\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7279\u522b\u662f\u8868\u683c\u67b6\u6784\u5728\u5404\u9879\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u8ba4\u77e5\u8d1f\u8377\u5728\u5065\u5eb7\u3001\u5fc3\u7406\u5b66\u548c\u56fd\u9632\u5e94\u7528\u7b49\u9886\u57df\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5b9e\u65f6\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7a97\u53e3\u7684\u65f6\u95f4\u5206\u533a\u65b9\u6cd5\u589e\u5f3a\u7279\u5f81\uff0c\u7136\u540e\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u8ba4\u77e5\u8d1f\u8377\u6c34\u5e73\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662f\u8868\u683c\u67b6\u6784\uff09\u5728\u7cbe\u786e\u5ea6\u3001F1\u5206\u6570\u3001\u51c6\u786e\u7387\u548c\u5206\u7c7b\u7cbe\u5ea6\u65b9\u9762\u90fd\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u7a97\u53e3\u7684\u65f6\u95f4\u7279\u5f81\u63d0\u53d6\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5bf9\u4e8e\u590d\u6742\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u5b9e\u65f6\u8ba4\u77e5\u8d1f\u8377\u8bc4\u4f30\u5177\u6709\u663e\u8457\u6548\u679c\u548c\u6f5c\u529b\u3002"}}
{"id": "2511.01061", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.0"], "pdf": "https://arxiv.org/pdf/2511.01061", "abs": "https://arxiv.org/abs/2511.01061", "authors": ["Przemys\u0142aw Spyra", "Witold Dzwinel"], "title": "Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms", "comment": null, "summary": "The long-held assumption that backpropagation (BP) is essential for\nstate-of-the-art performance is challenged by this work. We present rigorous,\nhardware-validated evidence that the Mono-Forward (MF) algorithm, a\nbackpropagation-free method, consistently surpasses an optimally tuned BP\nbaseline in classification accuracy on its native Multi-Layer Perceptron (MLP)\narchitectures. This superior generalization is achieved with profound\nefficiency gains, including up to 41% less energy consumption and up to 34%\nfaster training. Our analysis, which charts an evolutionary path from Geoffrey\nHinton's Forward-Forward (FF) to the Cascaded Forward (CaFo) and finally to MF,\nis grounded in a fair comparative framework using identical architectures and\nuniversal hyperparameter optimization. We further provide a critical\nre-evaluation of memory efficiency in BP-free methods, empirically\ndemonstrating that practical overhead can offset theoretical gains. Ultimately,\nthis work establishes MF as a practical, high-performance, and sustainable\nalternative to BP for MLPs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6311\u6218\u4e86\u53cd\u5411\u4f20\u64ad(BP)\u5bf9\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u81f3\u5173\u91cd\u8981\u7684\u957f\u671f\u5047\u8bbe\uff0c\u63d0\u51faMono-Forward(MF)\u7b97\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u6301\u7eed\u8d85\u8d8a\u4f18\u5316\u8c03\u53c2\u7684BP\u57fa\u7ebf\uff0c\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u8d28\u7591\u53cd\u5411\u4f20\u64ad\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u89e3\u51b3BP\u5728\u80fd\u6548\u548c\u8bad\u7ec3\u901f\u5ea6\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMono-Forward(MF)\u7b97\u6cd5\uff0c\u8fd9\u662f\u4eceForward-Forward(FF)\u5230Cascaded Forward(CaFo)\u518d\u5230MF\u7684\u6f14\u8fdb\u8def\u5f84\uff0c\u5728\u76f8\u540c\u67b6\u6784\u548c\u901a\u7528\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\u4e0b\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\u3002", "result": "MF\u5728MLP\u67b6\u6784\u4e0a\u5206\u7c7b\u51c6\u786e\u7387\u6301\u7eed\u8d85\u8d8aBP\u57fa\u7ebf\uff0c\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe41%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe34%\uff0c\u4f46\u65e0BP\u65b9\u6cd5\u7684\u5185\u5b58\u6548\u7387\u4f18\u52bf\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u88ab\u5f00\u9500\u62b5\u6d88\u3002", "conclusion": "MF\u88ab\u786e\u7acb\u4e3aMLP\u4e2d\u5b9e\u7528\u3001\u9ad8\u6027\u80fd\u4e14\u53ef\u6301\u7eed\u7684BP\u66ff\u4ee3\u65b9\u6848\uff0c\u6311\u6218\u4e86BP\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002"}}
{"id": "2511.01069", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01069", "abs": "https://arxiv.org/abs/2511.01069", "authors": ["Georg Pichler", "Marco Romanelli", "Pablo Piantanida"], "title": "Happiness as a Measure of Fairness", "comment": null, "summary": "In this paper, we propose a novel fairness framework grounded in the concept\nof happi- ness, a measure of the utility each group gains fromdecisionoutcomes.\nBycapturingfairness through this intuitive lens, we not only offer a more\nhuman-centered approach, but also one that is mathematically rigorous: In order\nto compute the optimal, fair post-processing strategy, only a linear program\nneeds to be solved. This makes our method both efficient and scalable with\nexisting optimization tools. Furthermore, it unifies and extends several\nwell-known fairness definitions, and our em- pirical results highlight its\npractical strengths across diverse scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e78\u798f\u611f\u7684\u516c\u5e73\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u8ba1\u7b97\u6700\u4f18\u516c\u5e73\u540e\u5904\u7406\u7b56\u7565\uff0c\u7edf\u4e00\u5e76\u6269\u5c55\u4e86\u591a\u79cd\u5df2\u77e5\u516c\u5e73\u6027\u5b9a\u4e49", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u5b9a\u4e49\u7f3a\u4e4f\u76f4\u89c2\u6027\u548c\u4eba\u6027\u5316\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u8d34\u8fd1\u4eba\u7c7b\u611f\u77e5\u7684\u516c\u5e73\u6027\u5ea6\u91cf\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5e78\u798f\u611f\u7684\u516c\u5e73\u6846\u67b6\uff0c\u5c06\u516c\u5e73\u6027\u5b9a\u4e49\u4e3a\u5404\u7fa4\u4f53\u4ece\u51b3\u7b56\u7ed3\u679c\u4e2d\u83b7\u5f97\u7684\u6548\u7528\uff0c\u4f7f\u7528\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u6700\u4f18\u540e\u5904\u7406\u7b56\u7565", "result": "\u65b9\u6cd5\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\uff0c\u80fd\u591f\u7edf\u4e00\u548c\u6269\u5c55\u591a\u79cd\u5df2\u77e5\u516c\u5e73\u6027\u5b9a\u4e49\uff0c\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5b9e\u7528\u4f18\u52bf", "conclusion": "\u5e78\u798f\u611f\u516c\u5e73\u6846\u67b6\u63d0\u4f9b\u4e86\u65e2\u76f4\u89c2\u53c8\u6570\u5b66\u4e25\u8c28\u7684\u516c\u5e73\u6027\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u7406\u8bba\u7edf\u4e00\u6027\u548c\u5b9e\u8df5\u5e94\u7528\u4ef7\u503c"}}
{"id": "2511.01077", "categories": ["cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.01077", "abs": "https://arxiv.org/abs/2511.01077", "authors": ["David McCoy", "Yulun Wu", "Zachary Butzin-Dozier"], "title": "AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs", "comment": "9 pages (main) + appendix, 3 figures. Accepted at NeurIPS 2025\n  (Position Paper Track), submission #491. OpenReview:\n  https://openreview.net/forum?id=6plSmhBI33&noteId=KP5ZqY7JLg", "summary": "This position paper challenges the \"scaling fundamentalism\" dominating AI\nresearch, where unbounded growth in model size and computation has led to\nunsustainable environmental impacts and widening resource inequality. We argue\nthat LLM development should be fundamentally reoriented toward\ncapability-per-resource rather than capability alone. We present a theoretical\nframework demonstrating that resource-allocation decisions guided by gradient\ninfluence patterns can dramatically improve efficiency throughout the AI\nlifecycle. Our analysis shows that in transformer-based models, where a small\nfraction of parameters exert outsized influence (following heavy-tailed\ndistributions), three critical insights emerge: (1) updating only\nhigh-influence parameters strictly outperforms full-parameter tuning on a\nperformance-per-resource basis; (2) simple gradient norms provide\ncomputationally efficient proxies for identifying these high-influence\ncomponents; and (3) coordinated parameter and data selection yields\nmultiplicative efficiency gains, potentially reducing resource requirements by\norders of magnitude. Building on these theoretical foundations, we propose a\ntwo stage paradigm marginal-return pretraining for foundation developers and\ninfluence guided adaptation for downstream users bridged by gradient\nblueprints, metadata describing which parameters matter most for various tasks.\nThis capability-per-resource perspective transforms what were once considered\npragmatic hardware workarounds into theoretically optimal strategies,\ndemocratizing access to cutting-edge AI capabilities while significantly\nreducing environmental impact. By embedding resource consciousness into how we\ndevelop, adapt, and evaluate models, we can reshape AI progress toward a more\nsustainable and equitable future.", "AI": {"tldr": "\u6311\u6218AI\u7814\u7a76\u4e2d\u7684\"\u89c4\u6a21\u81f3\u4e0a\u4e3b\u4e49\"\uff0c\u63d0\u51fa\u4ee5\u80fd\u529b-\u8d44\u6e90\u6bd4\u4e3a\u5bfc\u5411\u7684LLM\u5f00\u53d1\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u68af\u5ea6\u5f71\u54cd\u6a21\u5f0f\u6307\u5bfc\u8d44\u6e90\u5206\u914d\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347AI\u751f\u547d\u5468\u671f\u6548\u7387\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u8fc7\u5ea6\u8ffd\u6c42\u6a21\u578b\u89c4\u6a21\u548c\u8ba1\u7b97\u91cf\u589e\u957f\uff0c\u5bfc\u81f4\u4e0d\u53ef\u6301\u7eed\u7684\u73af\u5883\u5f71\u54cd\u548c\u8d44\u6e90\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u91cd\u65b0\u5b9a\u4f4dLLM\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u57fa\u4e8e\u68af\u5ea6\u5f71\u54cd\u6a21\u5f0f\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bc6\u522btransformer\u6a21\u578b\u4e2d\u5177\u6709\u91cd\u5927\u5f71\u54cd\u7684\u5c11\u6570\u53c2\u6570\uff0c\u63d0\u51fa\u4ec5\u66f4\u65b0\u9ad8\u5f71\u54cd\u53c2\u6570\u3001\u4f7f\u7528\u68af\u5ea6\u8303\u6570\u4f5c\u4e3a\u9ad8\u6548\u4ee3\u7406\u6307\u6807\u3001\u534f\u8c03\u53c2\u6570\u548c\u6570\u636e\u9009\u62e9\u7684\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4ec5\u66f4\u65b0\u9ad8\u5f71\u54cd\u53c2\u6570\u5728\u6027\u80fd-\u8d44\u6e90\u6bd4\u4e0a\u4e25\u683c\u4f18\u4e8e\u5168\u53c2\u6570\u8c03\u4f18\uff0c\u7b80\u5355\u68af\u5ea6\u8303\u6570\u53ef\u9ad8\u6548\u8bc6\u522b\u5173\u952e\u7ec4\u4ef6\uff0c\u534f\u8c03\u53c2\u6570\u548c\u6570\u636e\u9009\u62e9\u53ef\u5927\u5e45\u964d\u4f4e\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8303\u5f0f\uff1a\u57fa\u7840\u5f00\u53d1\u8005\u7684\u8fb9\u9645\u6536\u76ca\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u7528\u6237\u7684\u5f71\u54cd\u5f15\u5bfc\u9002\u5e94\uff0c\u901a\u8fc7\u68af\u5ea6\u84dd\u56fe\u8fde\u63a5\uff0c\u5c06\u8d44\u6e90\u610f\u8bc6\u5d4c\u5165\u6a21\u578b\u5f00\u53d1\u3001\u9002\u5e94\u548c\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u548c\u516c\u5e73\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2511.01093", "categories": ["cs.LG", "cs.AI", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.01093", "abs": "https://arxiv.org/abs/2511.01093", "authors": ["Aman Jaglan", "Jarrod Barnes"], "title": "Continual Learning, Not Training: Online Adaptation For Agents", "comment": "12 pages, 4 figures", "summary": "Continual Learning (CL) methods have traditionally focused on mitigating\ncatastrophic forgetting through gradient-based retraining, an approach\nill-suited for deployed agents that must adapt in real time. We introduce our\nAdaptive Teaching and Learning System (ATLAS), a dual-agent architecture that\ndecouples reasoning (Teacher) from execution (Student) and incorporates a\npersistent learning memory that stores distilled guidance from experience. This\ninforms the orchestration layer, enabling the system to dynamically adjust its\noperational strategies, such as supervision level or initial plan selection, at\ninference time. In doing so, ATLAS achieves gradient-free continual learning,\nshifting the locus of adaptation from model parameters to system-level\norchestration. We formulate this as a system-centric paradigm for continual\nlearning, where the objective is adaptive efficiency: maximizing task success\nwhile minimizing computational cost through inference-time orchestration rather\nthan parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source\nbenchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1%\nsuccess with GPT-5-mini as its Student, outperforming the larger GPT-5 (High)\nby 13% while reducing cost by 86%. Cross-incident validation demonstrates\ngeneralization: frozen pamphlets from Incident #5 improve accuracy from 28% to\n41% with zero retraining, while shifting output composition from verbose\nexploration to structured reasoning. Together, these findings establish\ngradient-free continual learning as a viable path toward adaptive, deployable\nAI systems and provide causally annotated traces valuable for training explicit\nworld models.", "AI": {"tldr": "ATLAS\u662f\u4e00\u4e2a\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bb\u63a8\u7406\uff08\u6559\u5e08\uff09\u548c\u6267\u884c\uff08\u5b66\u751f\uff09\u89d2\u8272\uff0c\u7ed3\u5408\u6301\u4e45\u5b66\u4e60\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u5728\u63a8\u7406\u65f6\u52a8\u6001\u8c03\u6574\u64cd\u4f5c\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u57fa\u4e8e\u68af\u5ea6\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u4e0d\u9002\u5408\u9700\u8981\u5b9e\u65f6\u9002\u5e94\u7684\u90e8\u7f72\u667a\u80fd\u4f53\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u6559\u5e08\u8d1f\u8d23\u63a8\u7406\uff0c\u5b66\u751f\u8d1f\u8d23\u6267\u884c\uff1b\u5305\u542b\u6301\u4e45\u5b66\u4e60\u8bb0\u5fc6\u5b58\u50a8\u7ecf\u9a8c\u6307\u5bfc\uff1b\u901a\u8fc7\u7f16\u6392\u5c42\u5728\u63a8\u7406\u65f6\u52a8\u6001\u8c03\u6574\u76d1\u7763\u7ea7\u522b\u548c\u521d\u59cb\u8ba1\u5212\u9009\u62e9\u3002", "result": "\u5728\u5fae\u8f6fExCyTIn-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528GPT-5-mini\u4f5c\u4e3a\u5b66\u751f\uff0cATLAS\u8fbe\u523054.1%\u6210\u529f\u7387\uff0c\u6bd4GPT-5\uff08High\uff09\u9ad813%\uff0c\u6210\u672c\u964d\u4f4e86%\u3002\u8de8\u4e8b\u4ef6\u9a8c\u8bc1\u663e\u793a\u6cdb\u5316\u80fd\u529b\uff1a\u51bb\u7ed3\u7684\u5c0f\u518c\u5b50\u5c06\u51c6\u786e\u7387\u4ece28%\u63d0\u5347\u81f341%\u3002", "conclusion": "ATLAS\u786e\u7acb\u4e86\u65e0\u68af\u5ea6\u6301\u7eed\u5b66\u4e60\u4f5c\u4e3a\u5b9e\u73b0\u81ea\u9002\u5e94\u3001\u53ef\u90e8\u7f72AI\u7cfb\u7edf\u7684\u53ef\u884c\u8def\u5f84\uff0c\u63d0\u4f9b\u4e86\u53ef\u7528\u4e8e\u8bad\u7ec3\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u7684\u6709\u4ef7\u503c\u56e0\u679c\u6ce8\u91ca\u8f68\u8ff9\u3002"}}
{"id": "2511.01125", "categories": ["cs.LG", "cs.NA", "math.AP", "math.NA", "math.PR", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2511.01125", "abs": "https://arxiv.org/abs/2511.01125", "authors": ["Takashi Furuya", "Anastasis Kratsios", "Dylan Possama\u00ef", "Bogdan Raoni\u0107"], "title": "One model to solve them all: 2BSDE families via neural operators", "comment": null, "summary": "We introduce a mild generative variant of the classical neural operator\nmodel, which leverages Kolmogorov--Arnold networks to solve infinite families\nof second-order backward stochastic differential equations ($2$BSDEs) on\nregular bounded Euclidean domains with random terminal time. Our first main\nresult shows that the solution operator associated with a broad range of\n$2$BSDE families is approximable by appropriate neural operator models. We then\nidentify a structured subclass of (infinite) families of $2$BSDEs whose neural\noperator approximation requires only a polynomial number of parameters in the\nreciprocal approximation rate, as opposed to the exponential requirement in\ngeneral worst-case neural operator guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKolmogorov-Arnold\u7f51\u7edc\u7684\u6e29\u548c\u751f\u6210\u53d8\u4f53\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\uff0c\u7528\u4e8e\u6c42\u89e3\u5177\u6709\u968f\u673a\u7ec8\u6b62\u65f6\u95f4\u7684\u4e8c\u9636\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b(2BSDEs)\u65cf\u3002", "motivation": "\u89e3\u51b3\u65e0\u9650\u65cf\u4e8c\u9636\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u5728\u6b63\u5219\u6709\u754c\u6b27\u51e0\u91cc\u5f97\u57df\u4e0a\u7684\u6c42\u89e3\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u968f\u673a\u7ec8\u6b62\u65f6\u95f4\u7684\u60c5\u51b5\u3002", "method": "\u5229\u7528Kolmogorov-Arnold\u7f51\u7edc\u6784\u5efa\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u53c2\u6570\u6570\u91cf\u5b9e\u73b0\u9ad8\u6548\u8fd1\u4f3c\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u5e7f\u6cdb\u76842BSDE\u65cf\uff0c\u89e3\u7b97\u5b50\u53ef\u7531\u9002\u5f53\u7684\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u8fd1\u4f3c\uff1b\u8bc6\u522b\u51fa\u4e00\u4e2a\u7ed3\u6784\u5316\u5b50\u7c7b\uff0c\u5176\u795e\u7ecf\u7b97\u5b50\u8fd1\u4f3c\u4ec5\u9700\u591a\u9879\u5f0f\u53c2\u6570\u6570\u91cf\uff0c\u800c\u975e\u4e00\u822c\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6307\u6570\u9700\u6c42\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8fd1\u4f3c\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u53c2\u6570\u590d\u6742\u5ea6\uff0c\u4e3a\u9ad8\u6548\u6c42\u89e32BSDE\u65cf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.01126", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.01126", "abs": "https://arxiv.org/abs/2511.01126", "authors": ["Parvin Nazari", "Bojian Hou", "Davoud Ataee Tarzanagh", "Li Shen", "George Michailidis"], "title": "Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization", "comment": "Published at NeurIPS 2025. 88 pages and 3 figures", "summary": "Online bilevel optimization (OBO) is a powerful framework for machine\nlearning problems where both outer and inner objectives evolve over time,\nrequiring dynamic updates. Current OBO approaches rely on deterministic\n\\textit{window-smoothed} regret minimization, which may not accurately reflect\nsystem performance when functions change rapidly. In this work, we introduce a\nnovel search direction and show that both first- and zeroth-order (ZO)\nstochastic OBO algorithms leveraging this direction achieve sublinear\n{stochastic bilevel regret without window smoothing}. Beyond these guarantees,\nour framework enhances efficiency by: (i) reducing oracle dependence in\nhypergradient estimation, (ii) updating inner and outer variables alongside the\nlinear system solution, and (iii) employing ZO-based estimation of Hessians,\nJacobians, and gradients. Experiments on online parametric loss tuning and\nblack-box adversarial attacks validate our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u641c\u7d22\u65b9\u5411\uff0c\u4f7f\u4e00\u9636\u548c\u96f6\u9636\u968f\u673a\u5728\u7ebf\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u65e0\u9700\u7a97\u53e3\u5e73\u6ed1\u5373\u53ef\u5b9e\u73b0\u6b21\u7ebf\u6027\u968f\u673a\u53cc\u5c42\u9057\u61be\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u8d85\u68af\u5ea6\u4f30\u8ba1\u7684oracle\u4f9d\u8d56\u3002", "motivation": "\u5f53\u524d\u5728\u7ebf\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u786e\u5b9a\u6027\u7a97\u53e3\u5e73\u6ed1\u9057\u61be\u6700\u5c0f\u5316\uff0c\u5728\u51fd\u6570\u5feb\u901f\u53d8\u5316\u65f6\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f15\u5165\u65b0\u7684\u641c\u7d22\u65b9\u5411\uff0c\u7ed3\u5408\u4e00\u9636\u548c\u96f6\u9636\u968f\u673a\u7b97\u6cd5\uff0c\u51cf\u5c11\u8d85\u68af\u5ea6\u4f30\u8ba1\u7684oracle\u4f9d\u8d56\uff0c\u540c\u65f6\u66f4\u65b0\u5185\u5916\u5c42\u53d8\u91cf\u548c\u7ebf\u6027\u7cfb\u7edf\u89e3\uff0c\u4f7f\u7528\u96f6\u9636\u65b9\u6cd5\u4f30\u8ba1Hessian\u3001Jacobian\u548c\u68af\u5ea6\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u7a97\u53e3\u5e73\u6ed1\u7684\u6b21\u7ebf\u6027\u968f\u673a\u53cc\u5c42\u9057\u61be\uff0c\u5728\u5728\u7ebf\u53c2\u6570\u5316\u635f\u5931\u8c03\u4f18\u548c\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u7ebf\u53cc\u5c42\u4f18\u5316\u7684\u6548\u7387\u3002"}}
{"id": "2511.01137", "categories": ["cs.LG", "math.AG", "math.DS", "stat.ML", "14L24, 37J15, 37C10, 68T07, 93B10, 53D20, 49J15, 37N40"], "pdf": "https://arxiv.org/pdf/2511.01137", "abs": "https://arxiv.org/abs/2511.01137", "authors": ["Kathryn Lindsey", "Govind Menon"], "title": "Regularization Implies balancedness in the deep linear network", "comment": "18 pages, 3 figures", "summary": "We use geometric invariant theory (GIT) to study the deep linear network\n(DLN). The Kempf-Ness theorem is used to establish that the $L^2$ regularizer\nis minimized on the balanced manifold. This allows us to decompose the training\ndynamics into two distinct gradient flows: a regularizing flow on fibers and a\nlearning flow on the balanced manifold. We show that the regularizing flow is\nexactly solvable using the moment map.\n  This approach provides a common mathematical framework for balancedness in\ndeep learning and linear systems theory. We use this framework to interpret\nbalancedness in terms of model reduction and Bayesian principles.", "AI": {"tldr": "\u4f7f\u7528\u51e0\u4f55\u4e0d\u53d8\u91cf\u7406\u8bba\u7814\u7a76\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\uff0c\u901a\u8fc7Kempf-Ness\u5b9a\u7406\u8bc1\u660eL2\u6b63\u5219\u5316\u5668\u5728\u5e73\u8861\u6d41\u5f62\u4e0a\u6700\u5c0f\u5316\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u5206\u89e3\u4e3a\u7ea4\u7ef4\u4e0a\u7684\u6b63\u5219\u5316\u6d41\u548c\u5e73\u8861\u6d41\u5f62\u4e0a\u7684\u5b66\u4e60\u6d41\uff0c\u6b63\u5219\u5316\u6d41\u53ef\u901a\u8fc7\u77e9\u6620\u5c04\u7cbe\u786e\u6c42\u89e3\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u548c\u7ebf\u6027\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u5e73\u8861\u6027\u63d0\u4f9b\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u4ece\u6a21\u578b\u7b80\u5316\u548c\u8d1d\u53f6\u65af\u539f\u7406\u89d2\u5ea6\u89e3\u91ca\u5e73\u8861\u6027\u3002", "method": "\u5e94\u7528\u51e0\u4f55\u4e0d\u53d8\u91cf\u7406\u8bba\u548cKempf-Ness\u5b9a\u7406\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u5206\u89e3\u4e3a\u4e24\u4e2a\u68af\u5ea6\u6d41\uff1a\u7ea4\u7ef4\u4e0a\u7684\u6b63\u5219\u5316\u6d41\u548c\u5e73\u8861\u6d41\u5f62\u4e0a\u7684\u5b66\u4e60\u6d41\uff0c\u4f7f\u7528\u77e9\u6620\u5c04\u6c42\u89e3\u6b63\u5219\u5316\u6d41\u3002", "result": "\u5efa\u7acb\u4e86L2\u6b63\u5219\u5316\u5668\u5728\u5e73\u8861\u6d41\u5f62\u4e0a\u6700\u5c0f\u5316\u7684\u7406\u8bba\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u52a8\u6001\u7684\u7cbe\u786e\u5206\u89e3\uff0c\u6b63\u5219\u5316\u6d41\u53ef\u89e3\u6790\u6c42\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6df1\u5ea6\u5b66\u4e60\u548c\u7ebf\u6027\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u5e73\u8861\u6027\u6982\u5ff5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u5b66\u89e3\u91ca\u6846\u67b6\uff0c\u8fde\u63a5\u4e86\u6a21\u578b\u7b80\u5316\u548c\u8d1d\u53f6\u65af\u539f\u7406\u89c6\u89d2\u3002"}}
{"id": "2511.01172", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01172", "abs": "https://arxiv.org/abs/2511.01172", "authors": ["Ali Owfi", "Amirmohammad Bamdad", "Tolunay Seyfi", "Fatemeh Afghah"], "title": "Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification", "comment": null, "summary": "Deep learning has emerged as a leading approach for Automatic Modulation\nClassification (AMC), demonstrating superior performance over traditional\nmethods. However, vulnerability to adversarial attacks and susceptibility to\ndata distribution shifts hinder their practical deployment in real-world,\ndynamic environments. To address these threats, we propose a novel, unified\nframework that integrates meta-learning with domain adaptation, making AMC\nsystems resistant to both adversarial attacks and environmental changes. Our\nframework utilizes a two-phase strategy. First, in an offline phase, we employ\na meta-learning approach to train the model on clean and adversarially\nperturbed samples from a single source domain. This method enables the model to\ngeneralize its defense, making it resistant to a combination of previously\nunseen attacks. Subsequently, in the online phase, we apply domain adaptation\nto align the model's features with a new target domain, allowing it to adapt\nwithout requiring substantial labeled data. As a result, our framework achieves\na significant improvement in modulation classification accuracy against these\ncombined threats, offering a critical solution to the deployment and\noperational challenges of modern AMC systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5143\u5b66\u4e60\u548c\u9886\u57df\u81ea\u9002\u5e94\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4f7f\u81ea\u52a8\u8c03\u5236\u5206\u7c7b\u7cfb\u7edf\u80fd\u591f\u540c\u65f6\u62b5\u6297\u5bf9\u6297\u653b\u51fb\u548c\u73af\u5883\u53d8\u5316\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u8c03\u5236\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u548c\u6570\u636e\u5206\u5e03\u53d8\u5316\u7684\u5f71\u54cd\uff0c\u963b\u788d\u4e86\u5728\u5b9e\u9645\u52a8\u6001\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u79bb\u7ebf\u9636\u6bb5\u4f7f\u7528\u5143\u5b66\u4e60\u65b9\u6cd5\u5728\u5355\u4e00\u6e90\u57df\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u6cdb\u5316\u9632\u5fa1\u672a\u77e5\u653b\u51fb\uff1b\u5728\u7ebf\u9636\u6bb5\u5e94\u7528\u9886\u57df\u81ea\u9002\u5e94\u5c06\u6a21\u578b\u7279\u5f81\u4e0e\u65b0\u76ee\u6807\u57df\u5bf9\u9f50\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002", "result": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u8c03\u5236\u5206\u7c7b\u5728\u9762\u5bf9\u7ec4\u5408\u5a01\u80c1\u65f6\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3\u73b0\u4ee3AMC\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u64cd\u4f5c\u6311\u6218\u63d0\u4f9b\u4e86\u5173\u952e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01185", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01185", "abs": "https://arxiv.org/abs/2511.01185", "authors": ["Ruyue Zhang", "Xiaopeng Ke", "Ming Liu", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling", "comment": null, "summary": "Uplift modeling has emerged as a crucial technique for individualized\ntreatment effect estimation, particularly in fields such as marketing and\nhealthcare. Modeling uplift effects in multi-treatment scenarios plays a key\nrole in real-world applications. Current techniques for modeling\nmulti-treatment uplift are typically adapted from binary-treatment works. In\nthis paper, we investigate and categorize all current model adaptations into\ntwo types: Structure Adaptation and Feature Adaptation. Through our empirical\nexperiments, we find that these two adaptation types cannot maintain\neffectiveness under various data characteristics (noisy data, mixed with\nobservational data, etc.). To enhance estimation ability and robustness, we\npropose Orthogonal Function Adaptation (OFA) based on the function\napproximation theorem. We conduct comprehensive experiments with multiple data\ncharacteristics to study the effectiveness and robustness of all model\nadaptation techniques. Our experimental results demonstrate that our proposed\nOFA can significantly improve uplift model performance compared to other\nvanilla adaptation methods and exhibits the highest robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u903c\u8fd1\u5b9a\u7406\u7684\u6b63\u4ea4\u51fd\u6570\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u591a\u6cbb\u7597\u573a\u666f\u4e0b\u7684\u63d0\u5347\u5efa\u6a21\u6548\u679c\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6cbb\u7597\u63d0\u5347\u5efa\u6a21\u65b9\u6cd5\u901a\u5e38\u4ece\u4e8c\u5143\u6cbb\u7597\u5de5\u4f5c\u6539\u7f16\u800c\u6765\uff0c\u8fd9\u4e9b\u6539\u7f16\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u7279\u5f81\u4e0b\u65e0\u6cd5\u4fdd\u6301\u6709\u6548\u6027\u3002", "method": "\u5c06\u73b0\u6709\u6a21\u578b\u6539\u7f16\u5206\u4e3a\u7ed3\u6784\u9002\u5e94\u548c\u7279\u5f81\u9002\u5e94\u4e24\u7c7b\uff0c\u63d0\u51fa\u57fa\u4e8e\u51fd\u6570\u903c\u8fd1\u5b9a\u7406\u7684\u6b63\u4ea4\u51fd\u6570\u9002\u5e94\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOFA\u65b9\u6cd5\u76f8\u6bd4\u5176\u4ed6\u57fa\u7840\u6539\u7f16\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5177\u6709\u6700\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6b63\u4ea4\u51fd\u6570\u9002\u5e94\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u591a\u6cbb\u7597\u573a\u666f\u4e0b\u63d0\u5347\u5efa\u6a21\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01190", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01190", "abs": "https://arxiv.org/abs/2511.01190", "authors": ["Lijia Yu", "Xiao-Shan Gao", "Lijun Zhang"], "title": "Analyzing the Power of Chain of Thought through Memorization Capabilities", "comment": null, "summary": "It has been shown that the chain of thought (CoT) can enhance the power of\nlarge language models (LLMs) to solve certain mathematical reasoning problems.\nHowever, the capacity of CoT is still not fully explored. As an important\ninstance, the following basic question has not yet been answered: Does CoT\nexpand the capability of transformers across all reasoning tasks? We\ndemonstrate that reasoning with transformers is essentially a memorization\nproblem for reasoning datasets. Thus, examining the power of CoT across all\nreasoning tasks amounts to analyzing the memorization capabilities of CoT\ntransformers. In this paper, we give a complete description of the memorization\ncapabilities of fixed-precision transformers with or without CoT and give a\nnegative answer to the above-mentioned question. Precisely, we first give\nnecessary and sufficient conditions for fixed-precision transformers with and\nwithout CoT to memorize a finite reasoning dataset and show that these two\nconditions do not imply each other. Then, we give lower and upper bounds for\nthe number of parameters needed for transformers with or without CoT to\nmemorize a finite reasoning dataset with $N$ elements, which are\n$\\overline{\\Theta}(N)$ in all cases. This implies that there exist reasoning\ntasks for which CoT does not enhance the reasoning power of transformers,\nleading to a negative answer to the above-mentioned question. Finally, we give\nthe first results on memorizing infinite reasoning datasets by CoT transformers\nand show that some simple infinite datasets cannot be memorized by transformers\nwith or without CoT.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01198", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01198", "abs": "https://arxiv.org/abs/2511.01198", "authors": ["Tariq Abdul-Quddoos", "Tasnia Sharmin", "Xiangfang Li", "Lijun Qian"], "title": "Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge", "comment": null, "summary": "As spectrum sharing becomes increasingly vital to meet rising wireless\ndemands in the future, spectrum monitoring and transmitter identification are\nindispensable for enforcing spectrum usage policy, efficient spectrum\nutilization, and net- work security. This study proposed a robust framework for\ntransmitter identification and protocol categorization via multi- task RF\nsignal classification in shared spectrum environments, where the spectrum\nmonitor will classify transmission protocols (e.g., 4G LTE, 5G-NR, IEEE\n802.11a) operating within the same frequency bands, and identify different\ntransmitting base stations, as well as their combinations. A Convolutional\nNeural Network (CNN) is designed to tackle critical challenges such as\noverlapping signal characteristics and environmental variability. The proposed\nmethod employs a multi-channel input strategy to extract meaningful signal\nfeatures, achieving remarkable accuracy: 90% for protocol classification, 100%\nfor transmitting base station classification, and 92% for joint classification\ntasks, utilizing RF data from the POWDER platform. These results highlight the\nsignificant potential of the proposed method to enhance spectrum monitoring,\nmanagement, and security in modern wireless networks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u4efb\u52a1RF\u4fe1\u53f7\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u5171\u4eab\u9891\u8c31\u73af\u5883\u4e2d\u7684\u53d1\u5c04\u673a\u8bc6\u522b\u548c\u534f\u8bae\u5206\u7c7b\uff0c\u4f7f\u7528CNN\u5904\u7406\u4fe1\u53f7\u91cd\u53e0\u548c\u73af\u5883\u53d8\u5316\u95ee\u9898\uff0c\u5728POWDER\u5e73\u53f0\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u968f\u7740\u9891\u8c31\u5171\u4eab\u65e5\u76ca\u91cd\u8981\uff0c\u9891\u8c31\u76d1\u6d4b\u548c\u53d1\u5c04\u673a\u8bc6\u522b\u5bf9\u4e8e\u6267\u884c\u9891\u8c31\u4f7f\u7528\u653f\u7b56\u3001\u63d0\u9ad8\u9891\u8c31\u5229\u7528\u6548\u7387\u548c\u4fdd\u969c\u7f51\u7edc\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bbe\u8ba1\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\uff0c\u91c7\u7528\u591a\u901a\u9053\u8f93\u5165\u7b56\u7565\u63d0\u53d6\u6709\u610f\u4e49\u7684\u4fe1\u53f7\u7279\u5f81\uff0c\u89e3\u51b3\u4fe1\u53f7\u7279\u5f81\u91cd\u53e0\u548c\u73af\u5883\u53d8\u5316\u7b49\u5173\u952e\u6311\u6218\u3002", "result": "\u5728POWDER\u5e73\u53f0RF\u6570\u636e\u4e0a\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\uff1a\u534f\u8bae\u5206\u7c7b90%\uff0c\u53d1\u5c04\u57fa\u7ad9\u5206\u7c7b100%\uff0c\u8054\u5408\u5206\u7c7b\u4efb\u52a192%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u589e\u5f3a\u73b0\u4ee3\u65e0\u7ebf\u7f51\u7edc\u9891\u8c31\u76d1\u6d4b\u3001\u7ba1\u7406\u548c\u5b89\u5168\u65b9\u9762\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2511.01203", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01203", "abs": "https://arxiv.org/abs/2511.01203", "authors": ["Pavel Rumiantsev", "Soumyasundar Pal", "Yingxue Zhang", "Mark Coates"], "title": "FEval-TTC: Fair Evaluation Protocol for Test-Time Compute", "comment": null, "summary": "The performance of Large Language Models (LLMs) and the associated dollar\ncosts of API calls can fluctuate over time, potentially invalidating\nconclusions drawn in prior research. To address this, we propose a Fair\nEvaluation protocol for Test-Time Compute (FEval-TTC), designed to ensure\nconsistent assessment of test-time compute (TTC) methods, regardless of such\nfluctuations. FEval-TTC focuses on the evaluation of TTC methods that utilize\nunderlying Chains-of-Thought (CoT). It supports evaluations across multiple\nLLMs on a diverse set of mathematical and commonsense reasoning datasets. The\nfew-shot prompting and answer extraction processes are standardized across\ndatasets, reducing both time and monetary overhead for researchers.\nFurthermore, we provide a cost modelling procedure that estimates both the\ntoken and dollar cost per query, facilitating equitable comparisons of\nprevalent TTC methods. We open-source FEval-TTC for public use at\nhttps://github.com/networkslab/feval_ttc .", "AI": {"tldr": "\u63d0\u51fa\u4e86FEval-TTC\u516c\u5e73\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u786e\u4fdd\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65b9\u6cd5\u7684\u8bc4\u4f30\u4e00\u81f4\u6027\uff0c\u4e0d\u53d7LLM\u6027\u80fd\u548cAPI\u6210\u672c\u6ce2\u52a8\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u548cAPI\u8c03\u7528\u6210\u672c\u4f1a\u968f\u65f6\u95f4\u6ce2\u52a8\uff0c\u8fd9\u53ef\u80fd\u4f7f\u5148\u524d\u7814\u7a76\u7684\u7ed3\u8bba\u5931\u6548\uff0c\u9700\u8981\u4e00\u79cd\u516c\u5e73\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86FEval-TTC\u534f\u8bae\uff0c\u6807\u51c6\u5316\u5c11\u6837\u672c\u63d0\u793a\u548c\u7b54\u6848\u63d0\u53d6\u8fc7\u7a0b\uff0c\u652f\u6301\u8de8\u591a\u4e2aLLM\u5728\u6570\u5b66\u548c\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\uff0c\u5e76\u63d0\u4f9b\u6210\u672c\u5efa\u6a21\u7a0b\u5e8f\u3002", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90\u8bc4\u4f30\u6846\u67b6\uff0c\u51cf\u5c11\u4e86\u7814\u7a76\u8005\u7684\u65f6\u95f4\u548c\u91d1\u94b1\u5f00\u9500\uff0c\u4fbf\u4e8e\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65b9\u6cd5\u3002", "conclusion": "FEval-TTC\u4e3a\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65b9\u6cd5\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u548c\u516c\u5e73\u7684\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u786e\u4fdd\u7814\u7a76\u7ed3\u8bba\u7684\u957f\u671f\u6709\u6548\u6027\u3002"}}
{"id": "2511.01218", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01218", "abs": "https://arxiv.org/abs/2511.01218", "authors": ["Minh-Duc Nguyen", "Dung D. Le", "Phi Long Nguyen"], "title": "Optimizing Electric Vehicle Charging Station Placement Using Reinforcement Learning and Agent-Based Simulations", "comment": "Under Review", "summary": "The rapid growth of electric vehicles (EVs) necessitates the strategic\nplacement of charging stations to optimize resource utilization and minimize\nuser inconvenience. Reinforcement learning (RL) offers an innovative approach\nto identifying optimal charging station locations; however, existing methods\nface challenges due to their deterministic reward systems, which limit\nefficiency. Because real-world conditions are dynamic and uncertain, a\ndeterministic reward structure cannot fully capture the complexities of\ncharging station placement. As a result, evaluation becomes costly and\ntime-consuming, and less reflective of real-world scenarios. To address this\nchallenge, we propose a novel framework that integrates deep RL with\nagent-based simulations to model EV movement and estimate charging demand in\nreal time. Our approach employs a hybrid RL agent with dual Q-networks to\nselect optimal locations and configure charging ports, guided by a hybrid\nreward function that combines deterministic factors with simulation-derived\nfeedback. Case studies in Hanoi, Vietnam, show that our method reduces average\nwaiting times by 53.28% compared to the initial state, outperforming static\nbaseline methods. This scalable and adaptive solution enhances EV\ninfrastructure planning, effectively addressing real-world complexities and\nimproving user experience.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u4ee3\u7406\u6a21\u62df\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u5e03\u5c40\uff0c\u901a\u8fc7\u6df7\u5408\u5956\u52b1\u51fd\u6570\u548c\u53ccQ\u7f51\u7edc\u663e\u8457\u51cf\u5c11\u4e86\u7b49\u5f85\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u5145\u7535\u7ad9\u5e03\u5c40\u65b9\u6cd5\u4f7f\u7528\u786e\u5b9a\u6027\u5956\u52b1\u7cfb\u7edf\uff0c\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u7684\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u8bc4\u4f30\u6210\u672c\u9ad8\u4e14\u4e0d\u53cd\u6620\u771f\u5b9e\u573a\u666f\u3002", "method": "\u6574\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\uff0c\u4f7f\u7528\u5177\u6709\u53ccQ\u7f51\u7edc\u7684\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u6765\u9009\u62e9\u6700\u4f18\u4f4d\u7f6e\u548c\u914d\u7f6e\u5145\u7535\u7aef\u53e3\uff0c\u91c7\u7528\u7ed3\u5408\u786e\u5b9a\u6027\u56e0\u7d20\u548c\u6a21\u62df\u53cd\u9988\u7684\u6df7\u5408\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728\u8d8a\u5357\u6cb3\u5185\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u521d\u59cb\u72b6\u6001\u5c06\u5e73\u5747\u7b49\u5f85\u65f6\u95f4\u51cf\u5c11\u4e8653.28%\uff0c\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u89e3\u51b3\u65b9\u6848\u589e\u5f3a\u4e86\u7535\u52a8\u6c7d\u8f66\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\uff0c\u6709\u6548\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u5e76\u6539\u5584\u4e86\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.01226", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01226", "abs": "https://arxiv.org/abs/2511.01226", "authors": ["Themistoklis Vargiemezis", "Charilaos Kanatsoulis", "Catherine Gorl\u00e9"], "title": "WindMiL: Equivariant Graph Learning for Wind Loading Prediction", "comment": null, "summary": "Accurate prediction of wind loading on buildings is crucial for structural\nsafety and sustainable design, yet conventional approaches such as wind tunnel\ntesting and large-eddy simulation (LES) are prohibitively expensive for\nlarge-scale exploration. Each LES case typically requires at least 24 hours of\ncomputation, making comprehensive parametric studies infeasible. We introduce\nWindMiL, a new machine learning framework that combines systematic dataset\ngeneration with symmetry-aware graph neural networks (GNNs). First, we\nintroduce a large-scale dataset of wind loads on low-rise buildings by applying\nsigned distance function interpolation to roof geometries and simulating 462\ncases with LES across varying shapes and wind directions. Second, we develop a\nreflection-equivariant GNN that guarantees physically consistent predictions\nunder mirrored geometries. Across interpolation and extrapolation evaluations,\nWindMiL achieves high accuracy for both the mean and the standard deviation of\nsurface pressure coefficients (e.g., RMSE $\\leq 0.02$ for mean $C_p$) and\nremains accurate under reflected-test evaluation, maintaining hit rates above\n$96\\%$ where the non-equivariant baseline model drops by more than $10\\%$. By\npairing a systematic dataset with an equivariant surrogate, WindMiL enables\nefficient, scalable, and accurate predictions of wind loads on buildings.", "AI": {"tldr": "WindMiL\u662f\u4e00\u4e2a\u7ed3\u5408\u7cfb\u7edf\u6570\u636e\u96c6\u751f\u6210\u548c\u5bf9\u79f0\u611f\u77e5\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u9884\u6d4b\u5efa\u7b51\u98ce\u8377\u8f7d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u98ce\u6d1e\u6d4b\u8bd5\u548c\u5927\u6da1\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u6bcf\u4e2a\u5927\u6da1\u6a21\u62df\u6848\u4f8b\u9700\u8981\u81f3\u5c1124\u5c0f\u65f6\u8ba1\u7b97\u65f6\u95f4\uff0c\u4f7f\u5f97\u5927\u89c4\u6a21\u53c2\u6570\u7814\u7a76\u4e0d\u53ef\u884c\u3002", "method": "1) \u901a\u8fc7\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\u63d2\u503c\u751f\u6210\u5c4b\u9876\u51e0\u4f55\u5f62\u72b6\uff0c\u6a21\u62df462\u4e2a\u4e0d\u540c\u5f62\u72b6\u548c\u98ce\u5411\u7684\u5927\u6da1\u6a21\u62df\u6848\u4f8b\uff0c\u521b\u5efa\u5927\u89c4\u6a21\u98ce\u8377\u8f7d\u6570\u636e\u96c6\uff1b2) \u5f00\u53d1\u53cd\u5c04\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u786e\u4fdd\u5728\u955c\u50cf\u51e0\u4f55\u5f62\u72b6\u4e0b\u7684\u7269\u7406\u4e00\u81f4\u6027\u9884\u6d4b\u3002", "result": "\u5728\u63d2\u503c\u548c\u5916\u63a8\u8bc4\u4f30\u4e2d\uff0cWindMiL\u5bf9\u8868\u9762\u538b\u529b\u7cfb\u6570\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u5747\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\uff08\u5982\u5e73\u5747Cp\u7684RMSE\u22640.02\uff09\uff0c\u5728\u53cd\u5c04\u6d4b\u8bd5\u8bc4\u4f30\u4e2d\u4fdd\u630196%\u4ee5\u4e0a\u7684\u547d\u4e2d\u7387\uff0c\u800c\u975e\u7b49\u53d8\u57fa\u7ebf\u6a21\u578b\u4e0b\u964d\u8d85\u8fc710%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7cfb\u7edf\u6570\u636e\u96c6\u4e0e\u7b49\u53d8\u4ee3\u7406\u6a21\u578b\u76f8\u7ed3\u5408\uff0cWindMiL\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u5efa\u7b51\u98ce\u8377\u8f7d\u9884\u6d4b\u3002"}}
{"id": "2511.01234", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01234", "abs": "https://arxiv.org/abs/2511.01234", "authors": ["Min Gan", "Guang-Yong Chen", "Yang Yi", "Lin Yang"], "title": "A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization", "comment": null, "summary": "The proliferation of saddle points, rather than poor local minima, is\nincreasingly understood to be a primary obstacle in large-scale non-convex\noptimization for machine learning. Variable elimination algorithms, like\nVariable Projection (VarPro), have long been observed to exhibit superior\nconvergence and robustness in practice, yet a principled understanding of why\nthey so effectively navigate these complex energy landscapes has remained\nelusive. In this work, we provide a rigorous geometric explanation by comparing\nthe optimization landscapes of the original and reduced formulations. Through a\nrigorous analysis based on Hessian inertia and the Schur complement, we prove\nthat variable elimination fundamentally reshapes the critical point structure\nof the objective function, revealing that local maxima in the reduced landscape\nare created from, and correspond directly to, saddle points in the original\nformulation. Our findings are illustrated on the canonical problem of\nnon-convex matrix factorization, visualized directly on two-parameter neural\nnetworks, and finally validated in training deep Residual Networks, where our\napproach yields dramatic improvements in stability and convergence to superior\nminima. This work goes beyond explaining an existing method; it establishes\nlandscape simplification via saddle point transformation as a powerful\nprinciple that can guide the design of a new generation of more robust and\nefficient optimization algorithms.", "AI": {"tldr": "\u53d8\u91cf\u6d88\u9664\u7b97\u6cd5\u901a\u8fc7\u91cd\u5851\u4f18\u5316\u666f\u89c2\uff0c\u5c06\u539f\u59cb\u95ee\u9898\u4e2d\u7684\u978d\u70b9\u8f6c\u5316\u4e3a\u7b80\u5316\u95ee\u9898\u4e2d\u7684\u5c40\u90e8\u6700\u5927\u503c\uff0c\u4ece\u800c\u663e\u8457\u6539\u5584\u975e\u51f8\u4f18\u5316\u7684\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7406\u89e3\u53d8\u91cf\u6d88\u9664\u7b97\u6cd5\uff08\u5982VarPro\uff09\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u7684\u4f18\u8d8a\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\u7684\u539f\u7406\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u975e\u51f8\u4f18\u5316\u4e2d\u7684\u978d\u70b9\u95ee\u9898\u65f6\u3002", "method": "\u57fa\u4e8eHessian\u60ef\u6027\u548cSchur\u8865\u7684\u4e25\u683c\u51e0\u4f55\u5206\u6790\uff0c\u6bd4\u8f83\u539f\u59cb\u548c\u7b80\u5316\u516c\u5f0f\u7684\u4f18\u5316\u666f\u89c2\uff0c\u8bc1\u660e\u53d8\u91cf\u6d88\u9664\u5982\u4f55\u91cd\u5851\u4e34\u754c\u70b9\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u5c40\u90e8\u6700\u5927\u503c\u5728\u7b80\u5316\u666f\u89c2\u4e2d\u662f\u7531\u539f\u59cb\u516c\u5f0f\u4e2d\u7684\u978d\u70b9\u521b\u5efa\u5e76\u76f4\u63a5\u5bf9\u5e94\u7684\uff0c\u5728\u975e\u51f8\u77e9\u9635\u5206\u89e3\u3001\u53cc\u53c2\u6570\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u978d\u70b9\u53d8\u6362\u8fdb\u884c\u666f\u89c2\u7b80\u5316\u662f\u4e00\u4e2a\u5f3a\u5927\u539f\u5219\uff0c\u53ef\u4ee5\u6307\u5bfc\u8bbe\u8ba1\u66f4\u9c81\u68d2\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4ec5\u89e3\u91ca\u73b0\u6709\u65b9\u6cd5\u7684\u8303\u7574\u3002"}}
{"id": "2511.01249", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01249", "abs": "https://arxiv.org/abs/2511.01249", "authors": ["Kun-Wei Lin", "Yu-Chen Kuo", "Hsin-Yao Wang", "Yi-Ju Tseng"], "title": "KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records", "comment": "10 pages, 3 figures", "summary": "Clinical risk prediction using electronic health records (EHRs) is vital to\nfacilitate timely interventions and clinical decision support. However,\nmodeling heterogeneous and irregular temporal EHR data presents significant\nchallenges. We propose \\textbf{KAT-GNN} (Knowledge-Augmented Temporal Graph\nNeural Network), a graph-based framework that integrates clinical knowledge and\ntemporal dynamics for risk prediction. KAT-GNN first constructs\nmodality-specific patient graphs from EHRs. These graphs are then augmented\nusing two knowledge sources: (1) ontology-driven edges derived from SNOMED CT\nand (2) co-occurrence priors extracted from EHRs. Subsequently, a time-aware\ntransformer is employed to capture longitudinal dynamics from the graph-encoded\npatient representations. KAT-GNN is evaluated on three distinct datasets and\ntasks: coronary artery disease (CAD) prediction using the Chang Gung Research\nDatabase (CGRD) and in-hospital mortality prediction using the MIMIC-III and\nMIMIC-IV datasets. KAT-GNN achieves state-of-the-art performance in CAD\nprediction (AUROC: 0.9269 $\\pm$ 0.0029) and demonstrated strong results in\nmortality prediction in MIMIC-III (AUROC: 0.9230 $\\pm$ 0.0070) and MIMIC-IV\n(AUROC: 0.8849 $\\pm$ 0.0089), consistently outperforming established baselines\nsuch as GRASP and RETAIN. Ablation studies confirm that both knowledge-based\naugmentation and the temporal modeling component are significant contributors\nto performance gains. These findings demonstrate that the integration of\nclinical knowledge into graph representations, coupled with a time-aware\nattention mechanism, provides an effective and generalizable approach for risk\nprediction across diverse clinical tasks and datasets.", "AI": {"tldr": "KAT-GNN\u662f\u4e00\u4e2a\u7ed3\u5408\u4e34\u5e8a\u77e5\u8bc6\u548c\u65f6\u5e8f\u52a8\u6001\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u98ce\u9669\u9884\u6d4b\uff0c\u5728\u51a0\u72b6\u52a8\u8109\u75be\u75c5\u548c\u9662\u5185\u6b7b\u4ea1\u7387\u9884\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u5177\u6709\u5f02\u6784\u6027\u548c\u4e0d\u89c4\u5219\u65f6\u5e8f\u6027\uff0c\u5efa\u6a21\u8fd9\u4e9b\u6570\u636e\u9762\u4e34\u6311\u6218\u3002\u9700\u8981\u6574\u5408\u4e34\u5e8a\u77e5\u8bc6\u548c\u65f6\u5e8f\u52a8\u6001\u6765\u63d0\u9ad8\u98ce\u9669\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u6a21\u6001\u7279\u5b9a\u7684\u60a3\u8005\u56fe\uff0c\u4f7f\u7528SNOMED CT\u672c\u4f53\u548c\u5171\u73b0\u5148\u9a8c\u8fdb\u884c\u77e5\u8bc6\u589e\u5f3a\uff0c\u91c7\u7528\u65f6\u95f4\u611f\u77e5transformer\u6355\u6349\u7eb5\u5411\u52a8\u6001\u3002", "result": "\u5728CAD\u9884\u6d4b\u4e2dAUROC\u8fbe\u52300.9269\u00b10.0029\uff0c\u5728MIMIC-III\u548cMIMIC-IV\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u5206\u522b\u8fbe\u52300.9230\u00b10.0070\u548c0.8849\u00b10.0089\uff0c\u4f18\u4e8eGRASP\u548cRETAIN\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u4e34\u5e8a\u77e5\u8bc6\u6574\u5408\u5230\u56fe\u8868\u793a\u4e2d\uff0c\u7ed3\u5408\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4e3a\u8de8\u4e0d\u540c\u4e34\u5e8a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u7684\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.01267", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01267", "abs": "https://arxiv.org/abs/2511.01267", "authors": ["Yiyang Yang", "Xiejian Chi", "Shanxing Gao", "Kaidong Wang", "Yao Wang"], "title": "A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation", "comment": null, "summary": "Data quality is critical to Intelligent Transportation Systems (ITS), as\ncomplete and accurate traffic data underpin reliable decision-making in traffic\ncontrol and management. Recent advances in low-rank tensor recovery algorithms\nhave shown strong potential in capturing the inherent structure of\nhigh-dimensional traffic data and restoring degraded observations. However,\ntraditional batch-based methods demand substantial computational and storage\nresources, which limits their scalability in the face of continuously expanding\ntraffic data volumes. Moreover, recent online tensor recovery methods often\nsuffer from severe performance degradation in complex real-world scenarios due\nto their insufficient exploitation of the intrinsic structural properties of\ntraffic data. To address these challenges, we reformulate the traffic data\nrecovery problem within a streaming framework, and propose a novel online\nrobust tensor recovery algorithm that simultaneously leverages both the global\nspatio-temporal correlations and local consistency of traffic data, achieving\nhigh recovery accuracy and significantly improved computational efficiency in\nlarge-scale scenarios. Our method is capable of simultaneously handling missing\nand anomalous values in traffic data, and demonstrates strong adaptability\nacross diverse missing patterns. Experimental results on three real-world\ntraffic datasets demonstrate that the proposed approach achieves high recovery\naccuracy while significantly improving computational efficiency by up to three\norders of magnitude compared to state-of-the-art batch-based methods. These\nfindings highlight the potential of the proposed approach as a scalable and\neffective solution for traffic data quality enhancement in ITS.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5728\u7ebf\u9c81\u68d2\u5f20\u91cf\u6062\u590d\u7b97\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u4ea4\u901a\u6570\u636e\u6062\u590d\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u7f3a\u5931\u503c\u548c\u5f02\u5e38\u503c\uff0c\u5728\u4fdd\u6301\u9ad8\u6062\u590d\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u6279\u91cf\u5f20\u91cf\u6062\u590d\u65b9\u6cd5\u5728\u8ba1\u7b97\u548c\u5b58\u50a8\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u96be\u4ee5\u5e94\u5bf9\u6301\u7eed\u589e\u957f\u7684\u4ea4\u901a\u6570\u636e\u91cf\uff1b\u73b0\u6709\u5728\u7ebf\u65b9\u6cd5\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u6027\u80fd\u4e0b\u964d\u4e25\u91cd\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u4ea4\u901a\u6570\u636e\u7684\u56fa\u6709\u7ed3\u6784\u7279\u6027\u3002", "method": "\u5c06\u4ea4\u901a\u6570\u636e\u6062\u590d\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u6d41\u5f0f\u6846\u67b6\uff0c\u63d0\u51fa\u540c\u65f6\u5229\u7528\u4ea4\u901a\u6570\u636e\u5168\u5c40\u65f6\u7a7a\u76f8\u5173\u6027\u548c\u5c40\u90e8\u4e00\u81f4\u6027\u7684\u5728\u7ebf\u9c81\u68d2\u5f20\u91cf\u6062\u590d\u7b97\u6cd5\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6062\u590d\u7cbe\u5ea6\uff0c\u540c\u65f6\u8ba1\u7b97\u6548\u7387\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u6279\u91cf\u65b9\u6cd5\u63d0\u5347\u4e86\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u4ea4\u901a\u6570\u636e\u8d28\u91cf\u589e\u5f3a\u7684\u53ef\u6269\u5c55\u6709\u6548\u89e3\u51b3\u65b9\u6848\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.01275", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01275", "abs": "https://arxiv.org/abs/2511.01275", "authors": ["Zan Li", "Kyongmin Yeo", "Wesley Gifford", "Lara Marcuse", "Madeline Fields", "B\u00fclent Yener"], "title": "Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting", "comment": null, "summary": "Forecasting epileptic seizures from multivariate EEG signals represents a\ncritical challenge in healthcare time series prediction, requiring high\nsensitivity, low false alarm rates, and subject-specific adaptability. We\npresent STAN, an Adversarial Spatio-Temporal Attention Network that jointly\nmodels spatial brain connectivity and temporal neural dynamics through cascaded\nattention blocks with alternating spatial and temporal modules. Unlike existing\napproaches that assume fixed preictal durations or separately process spatial\nand temporal features, STAN captures bidirectional dependencies between spatial\nand temporal patterns through a unified cascaded architecture. Adversarial\ntraining with gradient penalty enables robust discrimination between interictal\nand preictal states learned from clearly defined 15-minute preictal windows.\nContinuous 90-minute pre-seizure monitoring reveals that the learned\nspatio-temporal attention patterns enable early detection: reliable alarms\ntrigger at subject-specific times (typically 15-45 minutes before onset),\nreflecting the model's capacity to capture subtle preictal dynamics without\nrequiring individualized training. Experiments on two benchmark EEG datasets\n(CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14\nevents) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011\nfalse detections per hour and 94.2% sensitivity with 0.063 false detections per\nhour, respectively, while maintaining computational efficiency (2.3M\nparameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond\nepilepsy, the proposed framework provides a general paradigm for\nspatio-temporal forecasting in healthcare and other time series domains where\nindividual heterogeneity and interpretability are crucial.", "AI": {"tldr": "STAN\u662f\u4e00\u4e2a\u5bf9\u6297\u6027\u65f6\u7a7a\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u7528\u4e8e\u4ece\u591a\u53d8\u91cfEEG\u4fe1\u53f7\u9884\u6d4b\u766b\u75eb\u53d1\u4f5c\uff0c\u901a\u8fc7\u7ea7\u8054\u6ce8\u610f\u529b\u5757\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u8111\u8fde\u63a5\u548c\u65f6\u95f4\u795e\u7ecf\u52a8\u6001\uff0c\u5b9e\u73b0\u9ad8\u7075\u654f\u5ea6\u548c\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u5728\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u9762\u4e34\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u9ad8\u7075\u654f\u5ea6\u3001\u4f4e\u8bef\u62a5\u7387\u548c\u4e2a\u4f53\u7279\u5f02\u6027\u9002\u5e94\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u56fa\u5b9a\u7684\u53d1\u4f5c\u524d\u6301\u7eed\u65f6\u95f4\u6216\u5206\u522b\u5904\u7406\u65f6\u7a7a\u7279\u5f81\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u53cc\u5411\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51faSTAN\u7f51\u7edc\uff0c\u901a\u8fc7\u4ea4\u66ff\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u6a21\u5757\u7ea7\u8054\u6ce8\u610f\u529b\u5757\uff0c\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u8111\u8fde\u63a5\u548c\u65f6\u95f4\u795e\u7ecf\u52a8\u6001\u3002\u91c7\u7528\u5e26\u68af\u5ea6\u60e9\u7f5a\u7684\u5bf9\u6297\u8bad\u7ec3\uff0c\u4ece\u660e\u786e\u5b9a\u4e49\u768415\u5206\u949f\u53d1\u4f5c\u524d\u7a97\u53e3\u5b66\u4e60\u533a\u5206\u53d1\u4f5c\u95f4\u671f\u548c\u53d1\u4f5c\u524d\u671f\u72b6\u6001\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6EEG\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1aCHB-MIT\u5934\u76ae\u6570\u636e\u96c696.6%\u7075\u654f\u5ea6\u30010.011\u6b21/\u5c0f\u65f6\u8bef\u62a5\uff1bMSSM\u9885\u5185\u6570\u636e\u96c694.2%\u7075\u654f\u5ea6\u30010.063\u6b21/\u5c0f\u65f6\u8bef\u62a5\u3002\u6a21\u578b\u8ba1\u7b97\u9ad8\u6548\uff08230\u4e07\u53c2\u6570\uff0c45ms\u5ef6\u8fdf\uff0c180MB\u5185\u5b58\uff09\uff0c\u9002\u5408\u5b9e\u65f6\u8fb9\u7f18\u90e8\u7f72\u3002", "conclusion": "STAN\u80fd\u591f\u6355\u6349\u7ec6\u5fae\u7684\u53d1\u4f5c\u524d\u52a8\u6001\uff0c\u5728\u4e2a\u4f53\u7279\u5f02\u6027\u65f6\u95f4\uff08\u901a\u5e38\u53d1\u4f5c\u524d15-45\u5206\u949f\uff09\u89e6\u53d1\u53ef\u9760\u8b66\u62a5\uff0c\u65e0\u9700\u4e2a\u4f53\u5316\u8bad\u7ec3\u3002\u8be5\u6846\u67b6\u4e3a\u533b\u7597\u548c\u5176\u4ed6\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u65f6\u7a7a\u9884\u6d4b\u63d0\u4f9b\u4e86\u901a\u7528\u8303\u4f8b\u3002"}}
{"id": "2511.01277", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.01277", "abs": "https://arxiv.org/abs/2511.01277", "authors": ["Annabelle Martin", "Daphne Kontogiorgos-Heintz", "Jeff Nivala"], "title": "Identification of Capture Phases in Nanopore Protein Sequencing Data Using a Deep Learning Model", "comment": null, "summary": "Nanopore protein sequencing produces long, noisy ionic current traces in\nwhich key molecular phases, such as protein capture and translocation, are\nembedded. Capture phases mark the successful entry of a protein into the pore\nand serve as both a checkpoint and a signal that a channel merits further\nanalysis. However, manual identification of capture phases is time-intensive,\noften requiring several days for expert reviewers to annotate the data due to\nthe need for domain-specific interpretation of complex signal patterns. To\naddress this, a lightweight one-dimensional convolutional neural network (1D\nCNN) was developed and trained to detect capture phases in down-sampled signal\nwindows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids,\nhistogram-based classifiers, and other CNN variants using run-level data\nsplits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and\nprecision of 93.39% on held-out test data. The model supports low-latency\ninference and is integrated into a dashboard for Oxford Nanopore experiments,\nreducing the total analysis time from several days to under thirty minutes.\nThese results show that efficient, real-time capture detection is possible\nusing simple, interpretable architectures and suggest a broader role for\nlightweight ML models in sequencing workflows.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea71D CNN\u6a21\u578bCaptureNet-Deep\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4b\u7eb3\u7c73\u5b54\u86cb\u767d\u6d4b\u5e8f\u4e2d\u7684\u6355\u83b7\u9636\u6bb5\uff0c\u5c06\u5206\u6790\u65f6\u95f4\u4ece\u6570\u5929\u7f29\u77ed\u523030\u5206\u949f\u4ee5\u5185\u3002", "motivation": "\u624b\u52a8\u8bc6\u522b\u7eb3\u7c73\u5b54\u86cb\u767d\u6d4b\u5e8f\u4e2d\u7684\u6355\u83b7\u9636\u6bb5\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(1D CNN)\u5728\u964d\u91c7\u6837\u4fe1\u53f7\u7a97\u53e3\u4e2d\u68c0\u6d4b\u6355\u83b7\u9636\u6bb5\uff0c\u5e76\u4e0eCNN-LSTM\u6df7\u5408\u6a21\u578b\u3001\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684\u5206\u7c7b\u5668\u548c\u5176\u4ed6CNN\u53d8\u4f53\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6700\u4f73\u6a21\u578bCaptureNet-Deep\u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fbe\u5230F1\u5206\u65700.94\u548c\u7cbe\u5ea693.39%\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u63a8\u7406\u5e76\u96c6\u6210\u5230\u5b9e\u9a8c\u4eea\u8868\u677f\u4e2d\u3002", "conclusion": "\u4f7f\u7528\u7b80\u5355\u53ef\u89e3\u91ca\u7684\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u5b9e\u65f6\u6355\u83b7\u68c0\u6d4b\uff0c\u5728\u6d4b\u5e8f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.01283", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01283", "abs": "https://arxiv.org/abs/2511.01283", "authors": ["Yupu Lu", "Shijie Lin", "Hao Xu", "Zeqing Zhang", "Jia Pan"], "title": "Lyapunov Stability Learning with Nonlinear Control via Inductive Biases", "comment": "Accepted by IEEE Robio 2025", "summary": "Finding a control Lyapunov function (CLF) in a dynamical system with a\ncontroller is an effective way to guarantee stability, which is a crucial issue\nin safety-concerned applications. Recently, deep learning models representing\nCLFs have been applied into a learner-verifier framework to identify\nsatisfiable candidates. However, the learner treats Lyapunov conditions as\ncomplex constraints for optimisation, which is hard to achieve global\nconvergence. It is also too complicated to implement these Lyapunov conditions\nfor verification. To improve this framework, we treat Lyapunov conditions as\ninductive biases and design a neural CLF and a CLF-based controller guided by\nthis knowledge. This design enables a stable optimisation process with limited\nconstraints, and allows end-to-end learning of both the CLF and the controller.\nOur approach achieves a higher convergence rate and larger region of attraction\n(ROA) in learning the CLF compared to existing methods among abundant\nexperiment cases. We also thoroughly reveal why the success rate decreases with\nprevious methods during learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06Lyapunov\u6761\u4ef6\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\u7684\u795e\u7ecf\u7f51\u7edc\u63a7\u5236Lyapunov\u51fd\u6570\uff08CLF\uff09\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u540c\u65f6\u4f18\u5316CLF\u548c\u63a7\u5236\u5668\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6536\u655b\u7387\u548c\u5438\u5f15\u57df\uff08ROA\uff09", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60-\u9a8c\u8bc1\u6846\u67b6\u7684\u6df1\u5ea6CLF\u65b9\u6cd5\u5c06Lyapunov\u6761\u4ef6\u4f5c\u4e3a\u590d\u6742\u7ea6\u675f\u8fdb\u884c\u4f18\u5316\uff0c\u96be\u4ee5\u5b9e\u73b0\u5168\u5c40\u6536\u655b\u4e14\u9a8c\u8bc1\u8fc7\u7a0b\u590d\u6742\uff0c\u9700\u8981\u6539\u8fdb\u8fd9\u4e00\u6846\u67b6", "method": "\u5c06Lyapunov\u6761\u4ef6\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edcCLF\u548c\u57fa\u4e8eCLF\u7684\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u6709\u9650\u7ea6\u675f\u4e0b\u7684\u7a33\u5b9a\u4f18\u5316\u8fc7\u7a0b\uff0c\u652f\u6301CLF\u548c\u63a7\u5236\u5668\u7684\u7aef\u5230\u7aef\u5b66\u4e60", "result": "\u5728\u5927\u91cf\u5b9e\u9a8c\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728CLF\u5b66\u4e60\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6536\u655b\u7387\u548c\u66f4\u5927\u7684\u5438\u5f15\u57df\uff08ROA\uff09\uff0c\u5e76\u6df1\u5165\u63ed\u793a\u4e86\u5148\u524d\u65b9\u6cd5\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6210\u529f\u7387\u4e0b\u964d\u7684\u539f\u56e0", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5f52\u7eb3\u504f\u7f6e\u7684CLF\u8bbe\u8ba1\u65b9\u6cd5\u6709\u6548\u6539\u8fdb\u4e86\u5b66\u4e60-\u9a8c\u8bc1\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684CLF\u5b66\u4e60"}}
{"id": "2511.01286", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.01286", "abs": "https://arxiv.org/abs/2511.01286", "authors": ["Sivaram Krishnan", "Jinho Choi", "Jihong Park", "Gregory Sherman", "Benjamin Campbell"], "title": "Koopman-based Prediction of Connectivity for Flying Ad Hoc Networks", "comment": null, "summary": "The application of machine learning (ML) to communication systems is expected\nto play a pivotal role in future artificial intelligence (AI)-based\nnext-generation wireless networks. While most existing works focus on ML\ntechniques for static wireless environments, they often face limitations when\napplied to highly dynamic environments, such as flying ad hoc networks\n(FANETs). This paper explores the use of data-driven Koopman approaches to\naddress these challenges. Specifically, we investigate how these approaches can\nmodel UAV trajectory dynamics within FANETs, enabling more accurate predictions\nand improved network performance. By leveraging Koopman operator theory, we\npropose two possible approaches -- centralized and distributed -- to\nefficiently address the challenges posed by the constantly changing topology of\nFANETs. To demonstrate this, we consider a FANET performing surveillance with\nUAVs following pre-determined trajectories and predict\nsignal-to-interference-plus-noise ratios (SINRs) to ensure reliable\ncommunication between UAVs. Our results show that these approaches can\naccurately predict connectivity and isolation events that lead to modelled\ncommunication outages. This capability could help UAVs schedule their\ntransmissions based on these predictions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u7684Koopman\u65b9\u6cd5\u6765\u89e3\u51b3\u98de\u884c\u81ea\u7ec4\u7ec7\u7f51\u7edc(FANETs)\u4e2d\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u4e0b\u7684\u901a\u4fe1\u6311\u6218\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0f\u4e24\u79cd\u65b9\u6cd5\u9884\u6d4b\u65e0\u4eba\u673a\u8f68\u8ff9\u52a8\u6001\u548cSINR\uff0c\u4ee5\u6539\u5584\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u9759\u6001\u65e0\u7ebf\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9ad8\u5ea6\u52a8\u6001\u7684FANETs\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u62d3\u6251\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0f\u4e24\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u65e0\u4eba\u673a\u8f68\u8ff9\u52a8\u6001\u548c\u4fe1\u53f7\u5e72\u6270\u52a0\u566a\u58f0\u6bd4(SINR)\u6765\u5efa\u6a21FANETs\u901a\u4fe1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5bfc\u81f4\u901a\u4fe1\u4e2d\u65ad\u7684\u8fde\u63a5\u548c\u9694\u79bb\u4e8b\u4ef6\uff0c\u4e3a\u65e0\u4eba\u673a\u57fa\u4e8e\u9884\u6d4b\u8c03\u5ea6\u4f20\u8f93\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684Koopman\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9FANETs\u7684\u52a8\u6001\u73af\u5883\u6311\u6218\uff0c\u63d0\u9ad8\u901a\u4fe1\u53ef\u9760\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01296", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01296", "abs": "https://arxiv.org/abs/2511.01296", "authors": ["Guanjie Cheng", "Mengzhen Yang", "Xinkui Zhao", "Shuyi Yu", "Tianyu Du", "Yangyang Wu", "Mengying Zhu", "Shuiguang Deng"], "title": "LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping", "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed nodes without exposing raw data, but its decentralized nature makes\nit vulnerable in trust-deficient environments. Inference attacks may recover\nsensitive information from gradient updates, while poisoning attacks can\ndegrade model performance or induce malicious behaviors. Existing defenses\noften suffer from high communication and computation costs, or limited\ndetection precision. To address these issues, we propose LSHFed, a robust and\ncommunication-efficient FL framework that simultaneously enhances aggregation\nrobustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a\nnovel gradient verification mechanism that projects high-dimensional gradients\ninto compact binary representations via multi-hyperplane locally-sensitive\nhashing. This enables accurate detection and filtering of malicious gradients\nusing only their irreversible hash forms, thus mitigating privacy leakage risks\nand substantially reducing transmission overhead. Extensive experiments\ndemonstrate that LSHFed maintains high model performance even when up to 50% of\nparticipants are collusive adversaries while achieving up to a 1000x reduction\nin gradient verification communication compared to full-gradient methods.", "AI": {"tldr": "LSHFed\u662f\u4e00\u4e2a\u9c81\u68d2\u4e14\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7LSHGM\u68af\u5ea6\u9a8c\u8bc1\u673a\u5236\u5c06\u9ad8\u7ef4\u68af\u5ea6\u6295\u5f71\u4e3a\u7d27\u51d1\u7684\u4e8c\u8fdb\u5236\u8868\u793a\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u68c0\u6d4b\u6076\u610f\u68af\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u9762\u4e34\u63a8\u7406\u653b\u51fb\u548c\u6295\u6bd2\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u901a\u4fe1\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u68c0\u6d4b\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLSHFed\u6846\u67b6\uff0c\u6838\u5fc3\u662fLSHGM\u68af\u5ea6\u9a8c\u8bc1\u673a\u5236\uff0c\u4f7f\u7528\u591a\u8d85\u5e73\u9762\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u5c06\u9ad8\u7ef4\u68af\u5ea6\u6295\u5f71\u4e3a\u7d27\u51d1\u7684\u4e8c\u8fdb\u5236\u8868\u793a\uff0c\u4ec5\u901a\u8fc7\u4e0d\u53ef\u9006\u7684\u54c8\u5e0c\u5f62\u5f0f\u68c0\u6d4b\u6076\u610f\u68af\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f50%\u53c2\u4e0e\u8005\u662f\u6076\u610f\u653b\u51fb\u8005\uff0cLSHFed\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u68af\u5ea6\u9a8c\u8bc1\u901a\u4fe1\u91cf\u76f8\u6bd4\u5168\u68af\u5ea6\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe1000\u500d\u3002", "conclusion": "LSHFed\u5728\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u9c81\u68d2\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u4e3a\u4fe1\u4efb\u7f3a\u5931\u73af\u5883\u4e0b\u7684\u5b89\u5168\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01343", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01343", "abs": "https://arxiv.org/abs/2511.01343", "authors": ["\u00c1lvaro V\u00e1zquez Rodr\u00edguez", "Manuel Fern\u00e1ndez-Veiga", "Carlos Giraldo-Rodr\u00edguez"], "title": "Diffusion-Based Solver for CNF Placement on the Cloud-Continuum", "comment": "7 pages, 7 figures. Presented at PE-WASUN'25 (IEEE International\n  Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and\n  Ubiquitous Networks)", "summary": "The placement of Cloud-Native Network Functions (CNFs) across the\nCloud-Continuum represents a core challenge in the orchestration of current 5G\nand future 6G networks. The process involves the placement of interdependent\ncomputing tasks, structured as Service Function Chains, over distributed cloud\ninfrastructures. This is achieved while satisfying strict resource, bandwidth\nand latency constraints. It is acknowledged that classical approaches,\nincluding mixed-integer nonlinear programming, heuristics and reinforcement\nlearning are limited in terms of scalability, constraint handling and\ngeneralisation capacity. In the present study, a novel theoretical framework is\nproposed, which is based on Denoising Diffusion Probabilistic Models (DDPM) for\nCNF placement. The present approach proposes a reconceptualisation of placement\nas a generative graph to assignment task, where the placement problem is\nencoded as a heterogeneous graph, and a Graph Neural Network denoiser is\ntrained to iteratively refine noisy CNF-to-cloud assignment matrices. The model\nincorporates constraint-specific losses directly into the loss function,\nthereby allowing it to learn feasible solution spaces. The integration of the\nDDPM formulation with structured combinatorial constraints is achieved through\na rigorous and systematic approach. Extensive evaluations across diverse\ntopologies have been conducted, which have confirmed that the model\nconsistently produces feasible solutions with orders of magnitude faster\ninference than MINLP solvers. The results obtained demonstrate the potential of\ndiffusion-based generative modelling for constrained network embedding\nproblems, making an impact towards the practical, scalable orchestration of\ndistributed Cloud-Native Network Functions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(DDPM)\u7684\u4e91\u539f\u751f\u7f51\u7edc\u529f\u80fd(CNF)\u653e\u7f6e\u65b0\u6846\u67b6\uff0c\u5c06\u653e\u7f6e\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u751f\u6210\u56fe\u5230\u5206\u914d\u4efb\u52a1\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u8fed\u4ee3\u4f18\u5316\u5206\u914d\u77e9\u9635\uff0c\u5b9e\u73b0\u5feb\u901f\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u3001\u542f\u53d1\u5f0f\u7b97\u6cd5\u3001\u5f3a\u5316\u5b66\u4e60\uff09\u5728\u53ef\u6269\u5c55\u6027\u3001\u7ea6\u675f\u5904\u7406\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf95G/6G\u7f51\u7edc\u4e2dCNF\u5728\u4e91\u8fde\u7eed\u4f53\u4e0a\u7684\u653e\u7f6e\u6311\u6218\u3002", "method": "\u5c06CNF\u653e\u7f6e\u95ee\u9898\u7f16\u7801\u4e3a\u5f02\u6784\u56fe\uff0c\u8bad\u7ec3\u56fe\u795e\u7ecf\u7f51\u7edc\u53bb\u566a\u5668\u8fed\u4ee3\u4f18\u5316\u566a\u58f0CNF\u5230\u4e91\u7684\u5206\u914d\u77e9\u9635\uff0c\u5728\u635f\u5931\u51fd\u6570\u4e2d\u76f4\u63a5\u6574\u5408\u7ea6\u675f\u7279\u5b9a\u635f\u5931\u6765\u5b66\u4e60\u53ef\u884c\u89e3\u7a7a\u95f4\u3002", "result": "\u5728\u591a\u79cd\u62d3\u6251\u7ed3\u6784\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6301\u7eed\u4ea7\u751f\u53ef\u884c\u89e3\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4MINLP\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u5728\u7ea6\u675f\u7f51\u7edc\u5d4c\u5165\u95ee\u9898\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u5b9e\u73b0\u5206\u5e03\u5f0f\u4e91\u539f\u751f\u7f51\u7edc\u529f\u80fd\u7684\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7f16\u6392\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2511.01352", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "hep-ex", "physics.data-an", "J.2; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.01352", "abs": "https://arxiv.org/abs/2511.01352", "authors": ["Lucie Flek", "Oliver Janik", "Philipp Alexander Jung", "Akbar Karimi", "Timo Saala", "Alexander Schmidt", "Matthias Schott", "Philipp Soldin", "Matthias Thiesmeyer", "Christopher Wiebusch", "Ulrich Willemsen"], "title": "MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks", "comment": "Submitted to Computing and Software for Big Science", "summary": "In this paper, we present a new algorithm, MiniFool, that implements\nphysics-inspired adversarial attacks for testing neural network-based\nclassification tasks in particle and astroparticle physics. While we initially\ndeveloped the algorithm for the search for astrophysical tau neutrinos with the\nIceCube Neutrino Observatory, we apply it to further data from other science\ndomains, thus demonstrating its general applicability. Here, we apply the\nalgorithm to the well-known MNIST data set and furthermore, to Open Data data\nfrom the CMS experiment at the Large Hadron Collider. The algorithm is based on\nminimizing a cost function that combines a $\\chi^2$ based test-statistic with\nthe deviation from the desired target score. The test statistic quantifies the\nprobability of the perturbations applied to the data based on the experimental\nuncertainties. For our studied use cases, we find that the likelihood of a\nflipped classification differs for both the initially correctly and incorrectly\nclassified events. When testing changes of the classifications as a function of\nan attack parameter that scales the experimental uncertainties, the robustness\nof the network decision can be quantified. Furthermore, this allows testing the\nrobustness of the classification of unlabeled experimental data.", "AI": {"tldr": "\u63d0\u51fa\u4e86MiniFool\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u542f\u53d1\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u7c92\u5b50\u7269\u7406\u548c\u5929\u4f53\u7c92\u5b50\u7269\u7406\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u7ed3\u5408\u03c7\u00b2\u68c0\u9a8c\u7edf\u8ba1\u91cf\u548c\u76ee\u6807\u5206\u6570\u504f\u5dee\u7684\u6210\u672c\u51fd\u6570\u6765\u5de5\u4f5c\uff0c\u53ef\u91cf\u5316\u7f51\u7edc\u51b3\u7b56\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u901a\u7528\u7684\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u6765\u6d4b\u8bd5\u795e\u7ecf\u7f51\u7edc\u5728\u7c92\u5b50\u7269\u7406\u548c\u5929\u4f53\u7c92\u5b50\u7269\u7406\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728IceCube\u4e2d\u5fae\u5b50\u89c2\u6d4b\u7ad9\u7684\u5929\u4f53\u03c4\u4e2d\u5fae\u5b50\u641c\u7d22\u7b49\u5e94\u7528\u573a\u666f\u3002", "method": "\u57fa\u4e8e\u6700\u5c0f\u5316\u6210\u672c\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u8be5\u51fd\u6570\u7ed3\u5408\u4e86\u03c7\u00b2\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff08\u57fa\u4e8e\u5b9e\u9a8c\u4e0d\u786e\u5b9a\u6027\u7684\u6270\u52a8\u6982\u7387\uff09\u4e0e\u671f\u671b\u76ee\u6807\u5206\u6570\u7684\u504f\u5dee\u3002\u901a\u8fc7\u8c03\u6574\u653b\u51fb\u53c2\u6570\u6765\u7f29\u653e\u5b9e\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u6d4b\u8bd5\u5206\u7c7b\u53d8\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u6b63\u786e\u5206\u7c7b\u548c\u9519\u8bef\u5206\u7c7b\u7684\u4e8b\u4ef6\uff0c\u5206\u7c7b\u7ffb\u8f6c\u7684\u53ef\u80fd\u6027\u4e0d\u540c\u3002\u901a\u8fc7\u653b\u51fb\u53c2\u6570\u6d4b\u8bd5\u5206\u7c7b\u53d8\u5316\uff0c\u53ef\u4ee5\u91cf\u5316\u7f51\u7edc\u51b3\u7b56\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u6d4b\u8bd5\u672a\u6807\u8bb0\u5b9e\u9a8c\u6570\u636e\u7684\u5206\u7c7b\u9c81\u68d2\u6027\u3002", "conclusion": "MiniFool\u7b97\u6cd5\u5728\u591a\u4e2a\u79d1\u5b66\u9886\u57df\uff08\u5305\u62ecMNIST\u6570\u636e\u96c6\u548cCMS\u5b9e\u9a8c\u6570\u636e\uff09\u90fd\u8868\u73b0\u51fa\u901a\u7528\u9002\u7528\u6027\uff0c\u4e3a\u6d4b\u8bd5\u795e\u7ecf\u7f51\u7edc\u5728\u7269\u7406\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.01356", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01356", "abs": "https://arxiv.org/abs/2511.01356", "authors": ["Rana Alaa", "Dar\u00edo Gonz\u00e1lez-Ferreiro", "Carlos Beis-Penedo", "Manuel Fern\u00e1ndez-Veiga", "Rebeca P. D\u00edaz-Redondo", "Ana Fern\u00e1ndez-Vilas"], "title": "Verifiable Split Learning via zk-SNARKs", "comment": "Submitted to CAI'26 (IEEE Conference on Artificial Intelligence 2026)", "summary": "Split learning is an approach to collaborative learning in which a deep\nneural network is divided into two parts: client-side and server-side at a cut\nlayer. The client side executes its model using its raw input data and sends\nthe intermediate activation to the server side. This configuration architecture\nis very useful for enabling collaborative training when data or resources are\nseparated between devices. However, split learning lacks the ability to verify\nthe correctness and honesty of the computations that are performed and\nexchanged between the parties. To this purpose, this paper proposes a\nverifiable split learning framework that integrates a zk-SNARK proof to ensure\ncorrectness and verifiability. The zk-SNARK proof and verification are\ngenerated for both sides in forward propagation and backward propagation on the\nserver side, guaranteeing verifiability on both sides. The verifiable split\nlearning architecture is compared to a blockchain-enabled system for the same\ndeep learning network, one that records updates but without generating the\nzero-knowledge proof. From the comparison, it can be deduced that applying the\nzk-SNARK test achieves verifiability and correctness, while blockchains are\nlightweight but unverifiable.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u7684\u5206\u5272\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210zk-SNARK\u8bc1\u660e\u6765\u786e\u4fdd\u5206\u5272\u5b66\u4e60\u4e2d\u8ba1\u7b97\u7684\u6b63\u786e\u5b9a\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5206\u5272\u5b66\u4e60\u5728\u534f\u4f5c\u5b66\u4e60\u4e2d\u5f88\u6709\u7528\uff0c\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u8ba1\u7b97\u6b63\u786e\u6027\u548c\u8bda\u5b9e\u6027\u7684\u80fd\u529b\u3002", "method": "\u5728\u670d\u52a1\u5668\u7aef\u7684\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u4e2d\u4e3a\u53cc\u65b9\u751f\u6210zk-SNARK\u8bc1\u660e\u548c\u9a8c\u8bc1\uff0c\u786e\u4fdd\u53cc\u65b9\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "result": "\u4e0e\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5e94\u7528zk-SNARK\u6d4b\u8bd5\u5b9e\u73b0\u4e86\u53ef\u9a8c\u8bc1\u6027\u548c\u6b63\u786e\u6027\uff0c\u800c\u533a\u5757\u94fe\u867d\u7136\u8f7b\u91cf\u4f46\u4e0d\u53ef\u9a8c\u8bc1\u3002", "conclusion": "zk-SNARK\u8bc1\u660e\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5206\u5272\u5b66\u4e60\u4e2d\u7684\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u8ba1\u7b97\u8fc7\u7a0b\u7684\u6b63\u786e\u6027\u548c\u8bda\u5b9e\u6027\u3002"}}
{"id": "2511.01374", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01374", "abs": "https://arxiv.org/abs/2511.01374", "authors": ["Ziqi Wang", "Jiashun Liu", "Ling Pan"], "title": "Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization", "comment": "NeurIPS 2025", "summary": "Traditional continuous deep reinforcement learning (RL) algorithms employ\ndeterministic or unimodal Gaussian actors, which cannot express complex\nmultimodal decision distributions. This limitation can hinder their performance\nin diversity-critical scenarios. There have been some attempts to design online\nmultimodal RL algorithms based on diffusion or amortized actors. However, these\nactors are intractable, making existing methods struggle with balancing\nperformance, decision diversity, and efficiency simultaneously. To overcome\nthis challenge, we first reformulate existing intractable multimodal actors\nwithin a unified framework, and prove that they can be directly optimized by\npolicy gradient via reparameterization. Then, we propose a distance-based\ndiversity regularization that does not explicitly require decision\nprobabilities. We identify two diversity-critical domains, namely multi-goal\nachieving and generative RL, to demonstrate the advantages of multimodal\npolicies and our method, particularly in terms of few-shot robustness. In\nconventional MuJoCo benchmarks, our algorithm also shows competitive\nperformance. Moreover, our experiments highlight that the amortized actor is a\npromising policy model class with strong multimodal expressivity and high\nperformance. Our code is available at https://github.com/PneuC/DrAC", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u53c2\u6570\u5316\u7684\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8ddd\u79bb\u591a\u6837\u6027\u6b63\u5219\u5316\u89e3\u51b3\u4f20\u7edf\u786e\u5b9a\u6027\u6216\u5355\u5cf0\u9ad8\u65af\u7b56\u7565\u5728\u591a\u6a21\u6001\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5728\u591a\u6837\u6027\u5173\u952e\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u8fde\u7eed\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f7f\u7528\u786e\u5b9a\u6027\u6216\u5355\u5cf0\u9ad8\u65af\u7b56\u7565\uff0c\u65e0\u6cd5\u8868\u8fbe\u590d\u6742\u7684\u591a\u6a21\u6001\u51b3\u7b56\u5206\u5e03\uff0c\u8fd9\u5728\u591a\u6837\u6027\u5173\u952e\u573a\u666f\u4e2d\u4f1a\u9650\u5236\u6027\u80fd\u8868\u73b0\u3002", "method": "\u9996\u5148\u5c06\u73b0\u6709\u96be\u5904\u7406\u7684\u591a\u6a21\u6001\u7b56\u7565\u7edf\u4e00\u6846\u67b6\u5316\uff0c\u8bc1\u660e\u53ef\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u76f4\u63a5\u4f18\u5316\uff1b\u7136\u540e\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u7684\u591a\u6837\u6027\u6b63\u5219\u5316\uff0c\u65e0\u9700\u663e\u5f0f\u8ba1\u7b97\u51b3\u7b56\u6982\u7387\u3002", "result": "\u5728\u591a\u76ee\u6807\u8fbe\u6210\u548c\u751f\u6210\u5f0fRL\u7b49\u591a\u6837\u6027\u5173\u952e\u9886\u57df\u5c55\u793a\u4e86\u591a\u6a21\u6001\u7b56\u7565\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u5c11\u6837\u672c\u9c81\u68d2\u6027\u65b9\u9762\uff1b\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "conclusion": "\u644a\u9500\u7b56\u7565\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u7b56\u7565\u6a21\u578b\u7c7b\u522b\uff0c\u5177\u6709\u5f3a\u5927\u7684\u591a\u6a21\u6001\u8868\u8fbe\u80fd\u529b\u548c\u9ad8\u6027\u80fd\uff1b\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u51b3\u7b56\u591a\u6837\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2511.01377", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01377", "abs": "https://arxiv.org/abs/2511.01377", "authors": ["Amir Hossein Khorasani", "Ali Jahanian", "Maryam Rastgarpour"], "title": "Protecting the Neural Networks against FGSM Attack Using Machine Unlearning", "comment": "7 pages, 9 figures, 1 table", "summary": "Machine learning is a powerful tool for building predictive models. However,\nit is vulnerable to adversarial attacks. Fast Gradient Sign Method (FGSM)\nattacks are a common type of adversarial attack that adds small perturbations\nto input data to trick a model into misclassifying it. In response to these\nattacks, researchers have developed methods for \"unlearning\" these attacks,\nwhich involves retraining a model on the original data without the added\nperturbations. Machine unlearning is a technique that tries to \"forget\"\nspecific data points from the training dataset, to improve the robustness of a\nmachine learning model against adversarial attacks like FGSM. In this paper, we\nfocus on applying unlearning techniques to the LeNet neural network, a popular\narchitecture for image classification. We evaluate the efficacy of unlearning\nFGSM attacks on the LeNet network and find that it can significantly improve\nits robustness against these types of attacks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01385", "categories": ["cs.LG", "I.2.6; G.1.2; D.1.3"], "pdf": "https://arxiv.org/pdf/2511.01385", "abs": "https://arxiv.org/abs/2511.01385", "authors": ["Xinyu Ding", "Bangtian Liu", "Siyu Liao", "Zhongfeng Wang"], "title": "Memory-Efficient Training with In-Place FFT Implementation", "comment": "Accepted at NeurIPS 2025. Presents a real-domain in-place FFT (rdFFT)\n  operator for memory-efficient fine-tuning of large language models", "summary": "Fast Fourier Transforms (FFT) are widely used to reduce memory and\ncomputational costs in deep learning. However, existing implementations,\nincluding standard FFT and real FFT (rFFT), cannot achieve true in-place\ncomputation. In particular, rFFT maps an input of size n to a complex output of\nsize n/2+1, causing dimensional mismatch and requiring additional memory\nallocation. We propose the first real-domain, fully in-place FFT framework\n(rdFFT) that preserves input-output memory space consistency. By leveraging\nbutterfly operation symmetry and conjugate properties in the frequency domain,\nwe design an implicit complex encoding scheme that eliminates intermediate\ncache usage entirely. Experiments on multiple natural language understanding\ntasks demonstrate the method effectiveness in reducing training memory cost,\noffering a promising direction for frequency-domain lightweight adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5b9e\u57df\u5b8c\u5168\u539f\u4f4dFFT\u6846\u67b6(rdFFT)\uff0c\u901a\u8fc7\u9690\u5f0f\u590d\u6570\u7f16\u7801\u6d88\u9664\u4e2d\u95f4\u7f13\u5b58\u4f7f\u7528\uff0c\u51cf\u5c11\u8bad\u7ec3\u5185\u5b58\u6210\u672c", "motivation": "\u73b0\u6709FFT\u5b9e\u73b0\uff08\u5305\u62ec\u6807\u51c6FFT\u548c\u5b9eFFT\uff09\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u539f\u4f4d\u8ba1\u7b97\uff0c\u7279\u522b\u662f\u5b9eFFT\u4f1a\u5bfc\u81f4\u7ef4\u5ea6\u4e0d\u5339\u914d\u548c\u989d\u5916\u5185\u5b58\u5206\u914d", "method": "\u5229\u7528\u8774\u8776\u64cd\u4f5c\u5bf9\u79f0\u6027\u548c\u9891\u57df\u5171\u8f6d\u7279\u6027\uff0c\u8bbe\u8ba1\u9690\u5f0f\u590d\u6570\u7f16\u7801\u65b9\u6848\uff0c\u4fdd\u6301\u8f93\u5165\u8f93\u51fa\u5185\u5b58\u7a7a\u95f4\u4e00\u81f4\u6027", "result": "\u5728\u591a\u4e2a\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u8bad\u7ec3\u5185\u5b58\u6210\u672c\u65b9\u9762\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9891\u57df\u8f7b\u91cf\u7ea7\u9002\u914d\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2511.01408", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01408", "abs": "https://arxiv.org/abs/2511.01408", "authors": ["Markus B. Pettersson", "Adel Daoud"], "title": "Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping", "comment": null, "summary": "Accurate, fine-grained poverty maps remain scarce across much of the Global\nSouth. While Demographic and Health Surveys (DHS) provide high-quality\nsocioeconomic data, their spatial coverage is limited and reported coordinates\nare randomly displaced for privacy, further reducing their quality. We propose\na graph-based approach leveraging low-dimensional AlphaEarth satellite\nembeddings to predict cluster-level wealth indices across Sub-Saharan Africa.\nBy modeling spatial relations between surveyed and unlabeled locations, and by\nintroducing a probabilistic \"fuzzy label\" loss to account for coordinate\ndisplacement, we improve the generalization of wealth predictions beyond\nexisting surveys. Our experiments on 37 DHS datasets (2017-2023) show that\nincorporating graph structure slightly improves accuracy compared to\n\"image-only\" baselines, demonstrating the potential of compact EO embeddings\nfor large-scale socioeconomic mapping.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u536b\u661f\u5d4c\u5165\u65b9\u6cd5\u9884\u6d4b\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u7684\u8d2b\u56f0\u6307\u6570\uff0c\u901a\u8fc7\u5efa\u6a21\u7a7a\u95f4\u5173\u7cfb\u548c\u6a21\u7cca\u6807\u7b7e\u635f\u5931\u5904\u7406\u5750\u6807\u4f4d\u79fb\u95ee\u9898\uff0c\u572837\u4e2aDHS\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5168\u7403\u5357\u65b9\u5730\u533a\u7f3a\u4e4f\u7cbe\u7ec6\u5316\u7684\u8d2b\u56f0\u5730\u56fe\uff0cDHS\u8c03\u67e5\u6570\u636e\u867d\u7136\u8d28\u91cf\u9ad8\u4f46\u7a7a\u95f4\u8986\u76d6\u6709\u9650\u4e14\u5750\u6807\u56e0\u9690\u79c1\u4fdd\u62a4\u800c\u88ab\u968f\u673a\u4f4d\u79fb\uff0c\u964d\u4f4e\u4e86\u6570\u636e\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u4f4e\u7ef4AlphaEarth\u536b\u661f\u5d4c\u5165\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u5efa\u6a21\u8c03\u67e5\u70b9\u548c\u672a\u6807\u8bb0\u4f4d\u7f6e\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u5f15\u5165\u6982\u7387\u6027\"\u6a21\u7cca\u6807\u7b7e\"\u635f\u5931\u51fd\u6570\u6765\u5904\u7406\u5750\u6807\u4f4d\u79fb\u95ee\u9898\u3002", "result": "\u572837\u4e2aDHS\u6570\u636e\u96c6\uff082017-2023\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u56fe\u50cf\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u52a0\u5165\u56fe\u7ed3\u6784\u7565\u5fae\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u7d27\u51d1\u7684\u5730\u7403\u89c2\u6d4b\u5d4c\u5165\u5728\u5927\u89c4\u6a21\u793e\u4f1a\u7ecf\u6d4e\u5236\u56fe\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u56fe\u7ed3\u6784\u65b9\u6cd5\u80fd\u591f\u6539\u5584\u8d22\u5bcc\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.01433", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01433", "abs": "https://arxiv.org/abs/2511.01433", "authors": ["Seunghun Yu", "Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment", "comment": "5 pages", "summary": "Federated learning (FL), widely used in privacy-critical applications,\nsuffers from limited interpretability, whereas Kolmogorov-Arnold Networks (KAN)\naddress this limitation via learnable spline functions. However, existing FL\nstudies applying KAN overlook the communication overhead introduced by grid\nextension, which is essential for modeling complex functions. In this letter,\nwe propose CG-FKAN, which compresses extended grids by sparsifying and\ntransmitting only essential coefficients under a communication budget.\nExperiments show that CG-FKAN achieves up to 13.6% lower RMSE than fixed-grid\nKAN in communication-constrained settings. In addition, we derive a theoretical\nupper bound on its approximation error.", "AI": {"tldr": "\u63d0\u51faCG-FKAN\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u5316\u4f20\u8f93\u5173\u952e\u7cfb\u6570\u6765\u538b\u7f29KAN\u7f51\u7edc\u4e2d\u7684\u6269\u5c55\u7f51\u683c\uff0c\u5728\u901a\u4fe1\u53d7\u9650\u7684\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60(FL)\u5728\u9690\u79c1\u654f\u611f\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4f46\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u800cKAN\u7f51\u7edc\u901a\u8fc7\u53ef\u5b66\u4e60\u6837\u6761\u51fd\u6570\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\u3002\u7136\u800c\u73b0\u6709FL\u7814\u7a76\u5e94\u7528KAN\u65f6\u5ffd\u7565\u4e86\u7f51\u683c\u6269\u5c55\u5e26\u6765\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\u3002", "method": "\u63d0\u51faCG-FKAN\u65b9\u6cd5\uff0c\u5728\u901a\u4fe1\u9884\u7b97\u7ea6\u675f\u4e0b\u901a\u8fc7\u7a00\u758f\u5316\u5904\u7406\u5e76\u4ec5\u4f20\u8f93\u5fc5\u8981\u7684\u7cfb\u6570\u6765\u538b\u7f29\u6269\u5c55\u7f51\u683c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCG-FKAN\u5728\u901a\u4fe1\u53d7\u9650\u8bbe\u7f6e\u4e0b\u6bd4\u56fa\u5b9a\u7f51\u683cKAN\u7684RMSE\u964d\u4f4e\u8fbe13.6%\u3002", "conclusion": "CG-FKAN\u6709\u6548\u89e3\u51b3\u4e86KAN\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u8fd1\u4f3c\u8bef\u5dee\u7684\u7406\u8bba\u4e0a\u754c\u3002"}}
{"id": "2511.01438", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01438", "abs": "https://arxiv.org/abs/2511.01438", "authors": ["Jacob Poschl"], "title": "The Curvature Rate \u03bb: A Scalar Measure of Input-Space Sharpness in Neural Networks", "comment": "14 pages", "summary": "Curvature influences generalization, robustness, and how reliably neural\nnetworks respond to small input perturbations. Existing sharpness metrics are\ntypically defined in parameter space (e.g., Hessian eigenvalues) and can be\nexpensive, sensitive to reparameterization, and difficult to interpret in\nfunctional terms. We introduce a scalar curvature measure defined directly in\ninput space: the curvature rate {\\lambda}, given by the exponential growth rate\nof higher-order input derivatives. Empirically, {\\lambda} is estimated as the\nslope of log ||D^n f|| versus n for small n. This growth-rate perspective\nunifies classical analytic quantities: for analytic functions, {\\lambda}\ncorresponds to the inverse radius of convergence, and for bandlimited signals,\nit reflects the spectral cutoff. The same principle extends to neural networks,\nwhere {\\lambda} tracks the emergence of high-frequency structure in the\ndecision boundary. Experiments on analytic functions and neural networks (Two\nMoons and MNIST) show that {\\lambda} evolves predictably during training and\ncan be directly shaped using a simple derivative-based regularizer, Curvature\nRate Regularization (CRR). Compared to Sharpness-Aware Minimization (SAM), CRR\nachieves similar accuracy while yielding flatter input-space geometry and\nimproved confidence calibration. By grounding curvature in differentiation\ndynamics, {\\lambda} provides a compact, interpretable, and\nparameterization-invariant descriptor of functional smoothness in learned\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8f93\u5165\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u7684\u66f2\u7387\u5ea6\u91cf\u2014\u2014\u66f2\u7387\u7387\u03bb\uff0c\u901a\u8fc7\u9ad8\u9636\u8f93\u5165\u5bfc\u6570\u7684\u6307\u6570\u589e\u957f\u7387\u6765\u8861\u91cf\u795e\u7ecf\u7f51\u7edc\u7684\u5e73\u6ed1\u6027\uff0c\u6bd4\u53c2\u6570\u7a7a\u95f4\u7684\u66f2\u7387\u5ea6\u91cf\u66f4\u6613\u89e3\u91ca\u4e14\u4e0d\u53d7\u53c2\u6570\u5316\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u66f2\u7387\u5ea6\u91cf\u901a\u5e38\u5728\u53c2\u6570\u7a7a\u95f4\u5b9a\u4e49\uff08\u5982Hessian\u7279\u5f81\u503c\uff09\uff0c\u8ba1\u7b97\u6602\u8d35\u3001\u5bf9\u91cd\u65b0\u53c2\u6570\u5316\u654f\u611f\uff0c\u4e14\u96be\u4ee5\u5728\u529f\u80fd\u5c42\u9762\u89e3\u91ca\u3002\u9700\u8981\u4e00\u79cd\u76f4\u63a5\u5728\u8f93\u5165\u7a7a\u95f4\u5b9a\u4e49\u7684\u66f2\u7387\u5ea6\u91cf\u3002", "method": "\u5f15\u5165\u66f2\u7387\u7387\u03bb\uff0c\u5b9a\u4e49\u4e3a\u9ad8\u9636\u8f93\u5165\u5bfc\u6570\u7684\u6307\u6570\u589e\u957f\u7387\uff0c\u901a\u8fc7log ||D^n f||\u4e0en\u7684\u659c\u7387\u6765\u4f30\u8ba1\u3002\u63d0\u51fa\u66f2\u7387\u7387\u6b63\u5219\u5316(CRR)\u6765\u76f4\u63a5\u5851\u9020\u8f93\u5165\u7a7a\u95f4\u51e0\u4f55\u3002", "result": "\u5728\u89e3\u6790\u51fd\u6570\u548c\u795e\u7ecf\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u03bb\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u9884\u6d4b\u5730\u6f14\u5316\uff0cCRR\u80fd\u8fbe\u5230\u4e0eSAM\u76f8\u4f3c\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u5e73\u5766\u7684\u8f93\u5165\u7a7a\u95f4\u51e0\u4f55\u548c\u66f4\u597d\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3002", "conclusion": "\u03bb\u901a\u8fc7\u5fae\u5206\u52a8\u529b\u5b66\u5c06\u66f2\u7387\u6982\u5ff5\u57fa\u7840\u5316\uff0c\u4e3a\u5b66\u4e60\u6a21\u578b\u7684\u529f\u80fd\u5e73\u6ed1\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u4e14\u53c2\u6570\u5316\u4e0d\u53d8\u7684\u63cf\u8ff0\u7b26\u3002"}}
{"id": "2511.01443", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01443", "abs": "https://arxiv.org/abs/2511.01443", "authors": ["Chaoqun Fei", "Tinglve Zhou", "Tianyong Hao", "Yangyang Li"], "title": "Efficient Curvature-aware Graph Network", "comment": null, "summary": "Graph curvature provides geometric priors for Graph Neural Networks (GNNs),\nenhancing their ability to model complex graph structures, particularly in\nterms of structural awareness, robustness, and theoretical interpretability.\nAmong existing methods, Ollivier-Ricci curvature has been extensively studied\ndue to its strong geometric interpretability, effectively characterizing the\nlocal geometric distribution between nodes. However, its prohibitively high\ncomputational complexity limits its applicability to large-scale graph\ndatasets. To address this challenge, we propose a novel graph curvature\nmeasure--Effective Resistance Curvature--which quantifies the ease of message\npassing along graph edges using the effective resistance between node pairs,\ninstead of the optimal transport distance. This method significantly\noutperforms Ollivier-Ricci curvature in computational efficiency while\npreserving comparable geometric expressiveness. Theoretically, we prove the low\ncomputational complexity of effective resistance curvature and establish its\nsubstitutability for Ollivier-Ricci curvature. Furthermore, extensive\nexperiments on diverse GNN tasks demonstrate that our method achieves\ncompetitive performance with Ollivier-Ricci curvature while drastically\nreducing computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u66f2\u7387\u5ea6\u91cf\u2014\u2014\u6709\u6548\u7535\u963b\u66f2\u7387\uff0c\u7528\u4e8e\u66ff\u4ee3\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684Ollivier-Ricci\u66f2\u7387\uff0c\u5728\u4fdd\u6301\u51e0\u4f55\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709Ollivier-Ricci\u66f2\u7387\u867d\u7136\u5177\u6709\u5f3a\u51e0\u4f55\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5728\u5927\u89c4\u6a21\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u8282\u70b9\u5bf9\u4e4b\u95f4\u7684\u6709\u6548\u7535\u963b\u6765\u91cf\u5316\u6cbf\u56fe\u8fb9\u4f20\u9012\u6d88\u606f\u7684\u96be\u6613\u7a0b\u5ea6\uff0c\u66ff\u4ee3\u6700\u4f18\u4f20\u8f93\u8ddd\u79bb\uff0c\u4ece\u800c\u5b9a\u4e49\u6709\u6548\u7535\u963b\u66f2\u7387\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u6709\u6548\u7535\u963b\u66f2\u7387\u7684\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cdGNN\u4efb\u52a1\u4e2d\u4e0eOllivier-Ricci\u66f2\u7387\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u6709\u6548\u7535\u963b\u66f2\u7387\u662fOllivier-Ricci\u66f2\u7387\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u51e0\u4f55\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2511.01468", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01468", "abs": "https://arxiv.org/abs/2511.01468", "authors": ["Hao Wang", "Zixuan Weng", "Jindong Han", "Wei Fan", "Hao Liu"], "title": "DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation", "comment": null, "summary": "Data Assimilation is a cornerstone of atmospheric system modeling, tasked\nwith reconstructing system states by integrating sparse, noisy observations\nwith prior estimation. While traditional approaches like variational and\nensemble Kalman filtering have proven effective, recent advances in deep\nlearning offer more scalable, efficient, and flexible alternatives better\nsuited for complex, real-world data assimilation involving large-scale and\nmulti-modal observations. However, existing deep learning-based DA research\nsuffers from two critical limitations: (1) reliance on oversimplified scenarios\nwith synthetically perturbed observations, and (2) the absence of standardized\nbenchmarks for fair model comparison. To address these gaps, in this work, we\nintroduce DAMBench, the first large-scale multi-modal benchmark designed to\nevaluate data-driven DA models under realistic atmospheric conditions. DAMBench\nintegrates high-quality background states from state-of-the-art forecasting\nsystems and real-world multi-modal observations (i.e., real-world weather\nstations and satellite imagery). All data are resampled to a common grid and\ntemporally aligned to support systematic training, validation, and testing. We\nprovide unified evaluation protocols and benchmark representative data\nassimilation approaches, including latent generative models and neural process\nframeworks. Additionally, we propose a lightweight multi-modal plugin to\ndemonstrate how integrating realistic observations can enhance even simple\nbaselines. Through comprehensive experiments, DAMBench establishes a rigorous\nfoundation for future research, promoting reproducibility, fair comparison, and\nextensibility to real-world multi-modal scenarios. Our dataset and code are\npublicly available at https://github.com/figerhaowang/DAMBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86DAMBench\uff0c\u9996\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5728\u771f\u5b9e\u5927\u6c14\u6761\u4ef6\u4e0b\u8bc4\u4f30\u6570\u636e\u9a71\u52a8\u7684\u6570\u636e\u540c\u5316\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4f9d\u8d56\u7b80\u5316\u573a\u666f\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u540c\u5316\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6570\u636e\u540c\u5316\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a(1)\u4f9d\u8d56\u5408\u6210\u6270\u52a8\u7684\u7b80\u5316\u573a\u666f\uff0c(2)\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u8fdb\u884c\u516c\u5e73\u6a21\u578b\u6bd4\u8f83\u3002", "method": "\u6574\u5408\u4e86\u6765\u81ea\u5148\u8fdb\u9884\u62a5\u7cfb\u7edf\u7684\u9ad8\u8d28\u91cf\u80cc\u666f\u72b6\u6001\u548c\u771f\u5b9e\u4e16\u754c\u7684\u591a\u6a21\u6001\u89c2\u6d4b\u6570\u636e\uff08\u6c14\u8c61\u7ad9\u548c\u536b\u661f\u56fe\u50cf\uff09\uff0c\u6240\u6709\u6570\u636e\u91cd\u91c7\u6837\u5230\u7edf\u4e00\u7f51\u683c\u5e76\u8fdb\u884c\u65f6\u95f4\u5bf9\u9f50\uff0c\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\u5e76\u57fa\u51c6\u6d4b\u8bd5\u4ee3\u8868\u6027\u6570\u636e\u540c\u5316\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u4e25\u8c28\u7684\u7814\u7a76\u57fa\u7840\uff0c\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u3001\u516c\u5e73\u6bd4\u8f83\u548c\u6269\u5c55\u5230\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u573a\u666f\u7684\u80fd\u529b\uff0c\u5e76\u5c55\u793a\u4e86\u96c6\u6210\u771f\u5b9e\u89c2\u6d4b\u5982\u4f55\u589e\u5f3a\u7b80\u5355\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "DAMBench\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u540c\u5316\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2511.01553", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.01553", "abs": "https://arxiv.org/abs/2511.01553", "authors": ["Elvin Hajizada", "Danielle Rager", "Timothy Shea", "Leobardo Campos-Macias", "Andreas Wild", "Eyke H\u00fcllermeier", "Yulia Sandamirskaya", "Mike Davies"], "title": "Real-time Continual Learning on Intel Loihi 2", "comment": null, "summary": "AI systems on edge devices face a critical challenge in open-world\nenvironments: adapting when data distributions shift and novel classes emerge.\nWhile offline training dominates current paradigms, online continual learning\n(OCL)--where models learn incrementally from non-stationary streams without\ncatastrophic forgetting--remains challenging in power-constrained settings. We\npresent a neuromorphic solution called CLP-SNN: a spiking neural network\narchitecture for Continually Learning Prototypes and its implementation on\nIntel's Loihi 2 chip. Our approach introduces three innovations: (1)\nevent-driven and spatiotemporally sparse local learning, (2) a self-normalizing\nthree-factor learning rule maintaining weight normalization, and (3) integrated\nneurogenesis and metaplasticity for capacity expansion and forgetting\nmitigation. On OpenLORIS few-shot learning experiments, CLP-SNN achieves\naccuracy competitive with replay methods while being rehearsal-free. CLP-SNN\ndelivers transformative efficiency gains: 70\\times faster (0.33ms vs 23.2ms),\nand 5,600\\times more energy efficient (0.05mJ vs 281mJ) than the best\nalternative OCL on edge GPU. This demonstrates that co-designed brain-inspired\nalgorithms and neuromorphic hardware can break traditional accuracy-efficiency\ntrade-offs for future edge AI systems.", "AI": {"tldr": "CLP-SNN\u662f\u4e00\u79cd\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u67b6\u6784\uff0c\u5728\u82f1\u7279\u5c14Loihi 2\u82af\u7247\u4e0a\u5b9e\u73b0\uff0c\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u7a00\u758f\u5b66\u4e60\u3001\u81ea\u5f52\u4e00\u5316\u5b66\u4e60\u89c4\u5219\u548c\u795e\u7ecf\u53d1\u751f\u673a\u5236\uff0c\u5728OpenLORIS\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0e\u91cd\u653e\u65b9\u6cd5\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5b9e\u73b070\u500d\u901f\u5ea6\u548c5600\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u9762\u4e34\u7684\u6570\u636e\u5206\u5e03\u53d8\u5316\u548c\u65b0\u7c7b\u522b\u51fa\u73b0\u7684\u6311\u6218\uff0c\u514b\u670d\u4f20\u7edf\u79bb\u7ebf\u8bad\u7ec3\u8303\u5f0f\u5728\u529f\u7387\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u3002", "method": "\u63d0\u51faCLP-SNN\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u521b\u65b0\uff1a\u4e8b\u4ef6\u9a71\u52a8\u65f6\u7a7a\u7a00\u758f\u5c40\u90e8\u5b66\u4e60\u3001\u81ea\u5f52\u4e00\u5316\u4e09\u56e0\u5b50\u5b66\u4e60\u89c4\u5219\u7ef4\u6301\u6743\u91cd\u5f52\u4e00\u5316\u3001\u96c6\u6210\u795e\u7ecf\u53d1\u751f\u548c\u5143\u53ef\u5851\u6027\u5b9e\u73b0\u5bb9\u91cf\u6269\u5c55\u548c\u9057\u5fd8\u7f13\u89e3\u3002", "result": "\u5728OpenLORIS\u5c11\u6837\u672c\u5b66\u4e60\u5b9e\u9a8c\u4e2d\uff0cCLP-SNN\u8fbe\u5230\u4e0e\u91cd\u653e\u65b9\u6cd5\u7ade\u4e89\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u65e0\u9700\u6392\u7ec3\u3002\u76f8\u6bd4\u8fb9\u7f18GPU\u4e0a\u7684\u6700\u4f73\u66ff\u4ee3OCL\u65b9\u6cd5\uff0c\u901f\u5ea6\u63d0\u534770\u500d\uff080.33ms vs 23.2ms\uff09\uff0c\u80fd\u6548\u63d0\u53475600\u500d\uff080.05mJ vs 281mJ\uff09\u3002", "conclusion": "\u5171\u540c\u8bbe\u8ba1\u7684\u8111\u542f\u53d1\u7b97\u6cd5\u548c\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u80fd\u591f\u6253\u7834\u4f20\u7edf\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\uff0c\u4e3a\u672a\u6765\u8fb9\u7f18AI\u7cfb\u7edf\u63d0\u4f9b\u7a81\u7834\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01570", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01570", "abs": "https://arxiv.org/abs/2511.01570", "authors": ["Xiaosha Xue", "Peibo Duan", "Zhipeng Liu", "Qi Chu", "Changsheng Zhang", "Bin zhang"], "title": "Gated Fusion Enhanced Multi-Scale Hierarchical Graph Convolutional Network for Stock Movement Prediction", "comment": null, "summary": "Accurately predicting stock market movements remains a formidable challenge\ndue to the inherent volatility and complex interdependencies among stocks.\nAlthough multi-scale Graph Neural Networks (GNNs) hold potential for modeling\nthese relationships, they frequently neglect two key points: the subtle\nintra-attribute patterns within each stock affecting inter-stock correlation,\nand the biased attention to coarse- and fine-grained features during\nmulti-scale sampling. To overcome these challenges, we introduce MS-HGFN\n(Multi-Scale Hierarchical Graph Fusion Network). The model features a\nhierarchical GNN module that forms dynamic graphs by learning patterns from\nintra-attributes and features from inter-attributes over different time scales,\nthus comprehensively capturing spatio-temporal dependencies. Additionally, a\ntop-down gating approach facilitates the integration of multi-scale\nspatio-temporal features, preserving critical coarse- and fine-grained features\nwithout too much interference. Experiments utilizing real-world datasets from\nU.S. and Chinese stock markets demonstrate that MS-HGFN outperforms both\ntraditional and advanced models, yielding up to a 1.4% improvement in\nprediction accuracy and enhanced stability in return simulations. The code is\navailable at https://anonymous.4open.science/r/MS-HGFN.", "AI": {"tldr": "MS-HGFN\u662f\u4e00\u79cd\u591a\u5c3a\u5ea6\u5206\u5c42\u56fe\u878d\u5408\u7f51\u7edc\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u5b66\u4e60\u548c\u591a\u5c3a\u5ea6\u65f6\u7a7a\u7279\u5f81\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80a1\u7968\u5e02\u573a\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u5c3a\u5ea6\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u80a1\u7968\u9884\u6d4b\u4e2d\u5ffd\u89c6\u4e86\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u80a1\u7968\u5185\u90e8\u5c5e\u6027\u6a21\u5f0f\u5bf9\u80a1\u7968\u95f4\u76f8\u5173\u6027\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u591a\u5c3a\u5ea6\u91c7\u6837\u4e2d\u5bf9\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u504f\u7f6e\u5173\u6ce8\u3002", "method": "\u63d0\u51fa\u5206\u5c42GNN\u6a21\u5757\uff0c\u901a\u8fc7\u5b66\u4e60\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u5185\u90e8\u5c5e\u6027\u6a21\u5f0f\u548c\u5916\u90e8\u5c5e\u6027\u7279\u5f81\u6784\u5efa\u52a8\u6001\u56fe\uff0c\u5e76\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u95e8\u63a7\u65b9\u6cd5\u878d\u5408\u591a\u5c3a\u5ea6\u65f6\u7a7a\u7279\u5f81\u3002", "result": "\u5728\u7f8e\u56fd\u548c\u4e2d\u56fd\u80a1\u5e02\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMS-HGFN\u4f18\u4e8e\u4f20\u7edf\u548c\u5148\u8fdb\u6a21\u578b\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe1.4%\uff0c\u4e14\u5728\u6536\u76ca\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "MS-HGFN\u901a\u8fc7\u5168\u9762\u6355\u6349\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u548c\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u80a1\u7968\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u91d1\u878d\u5e02\u573a\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2511.01572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01572", "abs": "https://arxiv.org/abs/2511.01572", "authors": ["Wang Hao", "Kuang Zhang", "Hou Chengyu", "Yuan Zhonghao", "Tan Chenxing", "Fu Weifeng", "Zhu Yangying"], "title": "HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET", "comment": null, "summary": "Time series classification holds broad application value in communications,\ninformation countermeasures, finance, and medicine. However, state-of-the-art\n(SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high\ncomputational complexity, coupled with lengthy parameter tuning and training\ncycles. In contrast, lightweight solutions like ROCKET (Random Convolutional\nKernel Transform) offer greater efficiency but leave substantial room for\nimprovement in kernel selection and computational overhead. To address these\nchallenges, we propose a feature extraction approach based on Hadamard\nconvolutional transform, utilizing column or row vectors of Hadamard matrices\nas convolution kernels with extended lengths of varying sizes. This enhancement\nmaintains full compatibility with existing methods (e.g., ROCKET) while\nleveraging kernel orthogonality to boost computational efficiency, robustness,\nand adaptability. Comprehensive experiments on multi-domain datasets-focusing\non the UCR time series dataset-demonstrate SOTA performance: F1-score improved\nby at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET\n(fastest ROCKET variant) under identical hyperparameters, enabling deployment\non ultra-low-power embedded devices. All code is available on GitHub.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eHadamard\u5377\u79ef\u53d8\u6362\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709SOTA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c1150%\u8bad\u7ec3\u65f6\u95f4", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\u5982HIVE-COTE\u3001Proximity Forest\u7b49\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u53c2\u6570\u8c03\u4f18\u548c\u8bad\u7ec3\u5468\u671f\u957f\uff0c\u800c\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u5982ROCKET\u5728\u6838\u9009\u62e9\u548c\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4", "method": "\u4f7f\u7528Hadamard\u77e9\u9635\u7684\u5217\u6216\u884c\u5411\u91cf\u4f5c\u4e3a\u4e0d\u540c\u957f\u5ea6\u7684\u5377\u79ef\u6838\uff0c\u5229\u7528\u6838\u6b63\u4ea4\u6027\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u5b8c\u5168\u517c\u5bb9", "result": "\u5728UCR\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cF1\u5206\u6570\u6bd4ROCKET\u81f3\u5c11\u63d0\u53475%\uff0c\u8bad\u7ec3\u65f6\u95f4\u6bd4\u6700\u5feb\u7684miniROCKET\u7f29\u77ed50%\uff0c\u53ef\u5728\u8d85\u4f4e\u529f\u8017\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u90e8\u7f72", "conclusion": "\u63d0\u51fa\u7684Hadamard\u5377\u79ef\u53d8\u6362\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.01588", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01588", "abs": "https://arxiv.org/abs/2511.01588", "authors": ["Zhicheng Wang", "Chen Ju", "Xu Chen", "Shuai Xiao", "Jinsong Lan", "Xiaoyong Zhu", "Ying Chen", "Zhiguo Cao"], "title": "Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization", "comment": null, "summary": "Embedding models are a cornerstone of modern AI. Driven by Multimodal Large\nLanguage Models (MLLMs), they have made great progress in architecture and data\ncuration, while the holistic paradigm is still limited to SSC, i.e., single\ninput, singular embedding, contrastive supervision, which collapses rich,\nmultifaceted inputs into monolithic embeddings and fails to fully exploit MLLM\ncapabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF)\nfor multimodal embedding learning, by utilizing the proprietary steerability of\nMLLMs, i.e., their ability to flexibly generate quite differentiated response\nunder explicit instructions. Concretely, PDF conditions a shared MLLM backbone\non distinct, learnable prefixes to roll out multiple parallel paths for one\ninput, then relies on these paths to obtain parallel embeddings. To promote\nfull parallel diversity, we employ Mutual Information Minimization (MIM) as an\nexplicit constraint, coupled with per-path contrastive supervision to maintain\nsemantic alignment. Such dual-objectives force PDF to yield robust semantic\ncoverage and a generalizable embedding space. Ultimately, the remarkable\nembedding space are accessible at inference via one single forward pass,\nincurring negligible computational overhead. We instantiate PDF on multiple\nMLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains\nare consistently achieved across various resolutions and model sizes, e.g.,\nboosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the\nVLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency,\nour 2B model surpasses its baseline by +2.6% using only half the computational\nbudget.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u884c\u89e3\u8026\u6846\u67b6(PDF)\u7528\u4e8e\u591a\u6a21\u6001\u5d4c\u5165\u5b66\u4e60\uff0c\u901a\u8fc7\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u4e0a\u4f7f\u7528\u53ef\u5b66\u4e60\u524d\u7f00\u751f\u6210\u5e76\u884c\u5d4c\u5165\u8def\u5f84\uff0c\u7ed3\u5408\u4e92\u4fe1\u606f\u6700\u5c0f\u5316\u548c\u5bf9\u6bd4\u76d1\u7763\u5b9e\u73b0\u591a\u6837\u5316\u7684\u8bed\u4e49\u8986\u76d6\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\u53d7\u9650\u4e8eSSC\u8303\u5f0f\uff08\u5355\u4e00\u8f93\u5165\u3001\u5355\u4e00\u5d4c\u5165\u3001\u5bf9\u6bd4\u76d1\u7763\uff09\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528MLLM\u7684\u80fd\u529b\uff0c\u5c06\u4e30\u5bcc\u7684\u591a\u9762\u8f93\u5165\u538b\u7f29\u4e3a\u5355\u4e00\u5d4c\u5165\u3002", "method": "\u4f7f\u7528\u5171\u4eabMLLM\u9aa8\u5e72\u7f51\u7edc\uff0c\u901a\u8fc7\u4e0d\u540c\u7684\u53ef\u5b66\u4e60\u524d\u7f00\u751f\u6210\u591a\u4e2a\u5e76\u884c\u8def\u5f84\uff0c\u7ed3\u5408\u4e92\u4fe1\u606f\u6700\u5c0f\u5316\u7ea6\u675f\u548c\u6bcf\u8def\u5f84\u5bf9\u6bd4\u76d1\u7763\u6765\u4fc3\u8fdb\u5d4c\u5165\u591a\u6837\u6027\u3002", "result": "\u5728MMEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1aVLM2Vec-LLaVA-1.6-LR\u6a21\u578b\u63d0\u5347+8.9%(7B)\uff0cVLM2Vec-Qwen2VL\u6a21\u578b\u63d0\u5347+4.2%(2B)\u548c+3.1%(7B)\u30022B\u6a21\u578b\u4ec5\u7528\u4e00\u534a\u8ba1\u7b97\u9884\u7b97\u5c31\u8d85\u8d8a\u57fa\u7ebf+2.6%\u3002", "conclusion": "PDF\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528MLLM\u7684\u53ef\u63a7\u6027\u751f\u6210\u591a\u6837\u5316\u5d4c\u5165\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5d4c\u5165\u6027\u80fd\u3002"}}
{"id": "2511.01592", "categories": ["cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.01592", "abs": "https://arxiv.org/abs/2511.01592", "authors": ["Nat\u00e1lia Ribeiro Marinho", "Richard Loendersloot", "Frank Grooteman", "Jan Willem Wiegman", "Uraz Odyurt", "Tiedo Tinga"], "title": "Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective", "comment": null, "summary": "Energy estimation is critical to impact identification on aerospace\ncomposites, where low-velocity impacts can induce internal damage that is\nundetectable at the surface. Current methodologies for energy prediction are\noften constrained by data sparsity, signal noise, complex feature\ninterdependencies, non-linear dynamics, massive design spaces, and the\nill-posed nature of the inverse problem. This study introduces a\nphysics-informed framework that embeds domain knowledge into machine learning\nthrough a dedicated input space. The approach combines observational biases,\nwhich guide the design of physics-motivated features, with targeted feature\nselection to retain only the most informative indicators. Features are\nextracted from time, frequency, and time-frequency domains to capture\ncomplementary aspects of the structural response. A structured feature\nselection process integrating statistical significance, correlation filtering,\ndimensionality reduction, and noise robustness ensures physical relevance and\ninterpretability. Exploratory data analysis further reveals domain-specific\ntrends, yielding a reduced feature set that captures essential dynamic\nphenomena such as amplitude scaling, spectral redistribution, and transient\nsignal behaviour. Together, these steps produce a compact set of\nenergy-sensitive indicators with both statistical robustness and physical\nsignificance, resulting in impact energy predictions that remain interpretable\nand traceable to measurable structural responses. Using this optimised input\nspace, a fully-connected neural network is trained and validated with\nexperimental data from multiple impact scenarios, including pristine and\ndamaged states. The resulting model demonstrates significantly improved impact\nenergy prediction accuracy, reducing errors by a factor of three compared to\nconventional time-series techniques and purely data-driven models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u7528\u8f93\u5165\u7a7a\u95f4\u5c06\u9886\u57df\u77e5\u8bc6\u5d4c\u5165\u5230\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u822a\u7a7a\u822a\u5929\u590d\u5408\u6750\u6599\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u65b9\u6cd5\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u758f\u6027\u3001\u4fe1\u53f7\u566a\u58f0\u3001\u590d\u6742\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u3001\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u3001\u5927\u89c4\u6a21\u8bbe\u8ba1\u7a7a\u95f4\u548c\u53cd\u95ee\u9898\u7684\u4e0d\u9002\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u80fd\u91cf\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u89c2\u6d4b\u504f\u5dee\u548c\u9488\u5bf9\u6027\u7279\u5f81\u9009\u62e9\uff0c\u4ece\u65f6\u57df\u3001\u9891\u57df\u548c\u65f6\u9891\u57df\u63d0\u53d6\u7279\u5f81\uff0c\u901a\u8fc7\u7edf\u8ba1\u663e\u8457\u6027\u3001\u76f8\u5173\u6027\u8fc7\u6ee4\u3001\u964d\u7ef4\u548c\u566a\u58f0\u9c81\u68d2\u6027\u7684\u7ed3\u6784\u5316\u7279\u5f81\u9009\u62e9\u8fc7\u7a0b\uff0c\u751f\u6210\u7d27\u51d1\u7684\u80fd\u91cf\u654f\u611f\u6307\u6807\u96c6\u3002", "result": "\u4f7f\u7528\u4f18\u5316\u7684\u8f93\u5165\u7a7a\u95f4\u8bad\u7ec3\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u591a\u4e2a\u51b2\u51fb\u573a\u666f\u4e0b\u9a8c\u8bc1\uff0c\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u9ad8\uff0c\u8bef\u5dee\u6bd4\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u6280\u672f\u548c\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u51cf\u5c11\u4e09\u500d\u3002", "conclusion": "\u8be5\u7269\u7406\u4fe1\u606f\u6846\u67b6\u4ea7\u751f\u4e86\u5177\u6709\u7edf\u8ba1\u9c81\u68d2\u6027\u548c\u7269\u7406\u610f\u4e49\u7684\u7d27\u51d1\u7279\u5f81\u96c6\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u4e14\u53ef\u8ffd\u6eaf\u5230\u53ef\u6d4b\u91cf\u7ed3\u6784\u54cd\u5e94\u7684\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u3002"}}
{"id": "2511.01605", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01605", "abs": "https://arxiv.org/abs/2511.01605", "authors": ["Daniel Busbib", "Ami Wiesel"], "title": "Estimation of Toeplitz Covariance Matrices using Overparameterized Gradient Descent", "comment": null, "summary": "We consider covariance estimation under Toeplitz structure. Numerous\nsophisticated optimization methods have been developed to maximize the Gaussian\nlog-likelihood under Toeplitz constraints. In contrast, recent advances in deep\nlearning demonstrate the surprising power of simple gradient descent (GD)\napplied to overparameterized models. Motivated by this trend, we revisit\nToeplitz covariance estimation through the lens of overparameterized GD. We\nmodel the $P\\times P$ covariance as a sum of $K$ complex sinusoids with\nlearnable parameters and optimize them via GD. We show that when $K = P$, GD\nmay converge to suboptimal solutions. However, mild overparameterization ($K =\n2P$ or $4P$) consistently enables global convergence from random\ninitializations. We further propose an accelerated GD variant with separate\nlearning rates for amplitudes and frequencies. When frequencies are fixed and\nonly amplitudes are optimized, we prove that the optimization landscape is\nasymptotically benign and any stationary point recovers the true covariance.\nFinally, numerical experiments demonstrate that overparameterized GD can match\nor exceed the accuracy of state-of-the-art methods in challenging settings,\nwhile remaining simple and scalable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u6258\u666e\u5229\u8328\u534f\u65b9\u5dee\u4f30\u8ba1\u95ee\u9898\uff0c\u901a\u8fc7\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5f53\u53c2\u6570\u6570\u91cf\u4e3a2P\u62164P\u65f6\uff0c\u53ef\u4ee5\u4ece\u968f\u673a\u521d\u59cb\u5316\u5b9e\u73b0\u5168\u5c40\u6536\u655b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u901f\u68af\u5ea6\u4e0b\u964d\u53d8\u4f53\u3002", "motivation": "\u53d7\u5230\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\u53d6\u5f97\u6210\u529f\u7684\u542f\u53d1\uff0c\u91cd\u65b0\u5ba1\u89c6\u4f20\u7edf\u6258\u666e\u5229\u8328\u534f\u65b9\u5dee\u4f30\u8ba1\u95ee\u9898\uff0c\u63a2\u7d22\u7b80\u5355\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u8be5\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u3002", "method": "\u5c06P\u00d7P\u534f\u65b9\u5dee\u5efa\u6a21\u4e3aK\u4e2a\u590d\u6b63\u5f26\u6ce2\u7684\u53e0\u52a0\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u53c2\u6570\u3002\u5f53K=2P\u62164P\u65f6\u5b9e\u73b0\u8fc7\u53c2\u6570\u5316\uff0c\u5e76\u63d0\u51fa\u5177\u6709\u5206\u79bb\u5b66\u4e60\u7387\u7684\u52a0\u901f\u68af\u5ea6\u4e0b\u964d\u53d8\u4f53\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\u5728\u6311\u6218\u6027\u8bbe\u7f6e\u4e0b\u53ef\u4ee5\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u7b80\u5355\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\u4e3a\u6258\u666e\u5229\u8328\u534f\u65b9\u5dee\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u8fc7\u53c2\u6570\u5316\u4e0b\uff0c\u68af\u5ea6\u4e0b\u964d\u53ef\u4ee5\u5b9e\u73b0\u5168\u5c40\u6536\u655b\u5e76\u83b7\u5f97\u7ade\u4e89\u6027\u6027\u80fd\u3002"}}
{"id": "2511.01633", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01633", "abs": "https://arxiv.org/abs/2511.01633", "authors": ["Chengying Huan", "Ziheng Meng", "Yongchao Liu", "Zhengyi Yang", "Yun Zhu", "Yue Yun", "Shipeng Li", "Rong Gu", "Xiabao Wu", "Haitao Zhang", "Chuntao Hong", "Shaonan Ma", "Guihai Chen", "Chen Tian"], "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving", "comment": null, "summary": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to\nperform step-by-step reasoning over graph-structured knowledge, but existing\npipelines suffer from low accuracy, excessive token usage, high latency, and\nlow throughput due to single-agent monolithic prompts, repeated context\nre-encoding, and inefficient serving execution. We present GLM, the first\nmulti-agent Graph-CoT system co-designed with an optimized LLM serving\narchitecture. GLM decomposes reasoning into specialized agents for\nclassification, reasoning, action generation, and graph retrieval, enabling\nbranching and selective context sharing to reduce prompt length and reasoning\niterations while preserving reasoning quality, thereby improving accuracy and\nreducing overall token consumption. To scale inference, we introduce a\nGraph-CoT-aware LLM inference mechanism with graph-specific KV-cache\nmanagement, priority-based eviction, and pipelined execution to improve serving\nefficiency. Experiments demonstrate that GLM improves answer accuracy by up to\n38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and\nachieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT\nbaselines, enabling efficient adoption for complex real-world reasoning at\nscale.", "AI": {"tldr": "GLM\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u56fe\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u89e3\u63a8\u7406\u4efb\u52a1\u3001\u4f18\u5316LLM\u670d\u52a1\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u63a8\u7406\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u63a8\u7406\u7cfb\u7edf\u5b58\u5728\u51c6\u786e\u6027\u4f4e\u3001token\u4f7f\u7528\u8fc7\u591a\u3001\u5ef6\u8fdf\u9ad8\u548c\u541e\u5410\u91cf\u4f4e\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u5355\u667a\u80fd\u4f53\u63d0\u793a\u3001\u91cd\u590d\u4e0a\u4e0b\u6587\u7f16\u7801\u548c\u4f4e\u6548\u670d\u52a1\u6267\u884c\u3002", "method": "\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u5206\u7c7b\u3001\u63a8\u7406\u3001\u52a8\u4f5c\u751f\u6210\u548c\u56fe\u68c0\u7d22\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u5206\u652f\u548c\u9009\u62e9\u6027\u4e0a\u4e0b\u6587\u5171\u4eab\u51cf\u5c11\u63d0\u793a\u957f\u5ea6\u548c\u63a8\u7406\u8fed\u4ee3\uff1b\u5f15\u5165\u56fe\u63a8\u7406\u611f\u77e5\u7684LLM\u63a8\u7406\u673a\u5236\uff0c\u5305\u62ec\u56fe\u7279\u5b9aKV\u7f13\u5b58\u7ba1\u7406\u3001\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u6dd8\u6c70\u548c\u6d41\u6c34\u7ebf\u6267\u884c\u3002", "result": "GLM\u5c06\u7b54\u6848\u51c6\u786e\u6027\u63d0\u5347\u9ad8\u8fbe38%\uff0ctoken\u6210\u672c\u964d\u4f4e95.7%\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e90.3%\uff0c\u541e\u5410\u91cf\u63d0\u9ad815.1\u500d\u3002", "conclusion": "GLM\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u548c\u4f18\u5316\u7684LLM\u670d\u52a1\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u590d\u6742\u56fe\u63a8\u7406\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u63a8\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01641", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01641", "abs": "https://arxiv.org/abs/2511.01641", "authors": ["Xiaopeng Ke", "Yihan Yu", "Ruyue Zhang", "Zhishuo Zhou", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "Cross-Treatment Effect Estimation for Multi-Category, Multi-Valued Causal Inference via Dynamic Neural Masking", "comment": null, "summary": "Counterfactual causal inference faces significant challenges when extended to\nmulti-category, multi-valued treatments, where complex cross-effects between\nheterogeneous interventions are difficult to model. Existing methodologies\nremain constrained to binary or single-type treatments and suffer from\nrestrictive assumptions, limited scalability, and inadequate evaluation\nframeworks for complex intervention scenarios.\n  We present XTNet, a novel network architecture for multi-category,\nmulti-valued treatment effect estimation. Our approach introduces a\ncross-effect estimation module with dynamic masking mechanisms to capture\ntreatment interactions without restrictive structural assumptions. The\narchitecture employs a decomposition strategy separating basic effects from\ncross-treatment interactions, enabling efficient modeling of combinatorial\ntreatment spaces. We also propose MCMV-AUCC, a suitable evaluation metric that\naccounts for treatment costs and interaction effects. Extensive experiments on\nsynthetic and real-world datasets demonstrate that XTNet consistently\noutperforms state-of-the-art baselines in both ranking accuracy and effect\nestimation quality. The results of the real-world A/B test further confirm its\neffectiveness.", "AI": {"tldr": "XTNet\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u7c7b\u522b\u591a\u503c\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u7684\u65b0\u578b\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u4ea4\u53c9\u6548\u5e94\u4f30\u8ba1\u6a21\u5757\u548c\u52a8\u6001\u63a9\u7801\u673a\u5236\u6355\u6349\u5904\u7406\u4ea4\u4e92\uff0c\u65e0\u9700\u9650\u5236\u6027\u7ed3\u6784\u5047\u8bbe\u3002", "motivation": "\u53cd\u4e8b\u5b9e\u56e0\u679c\u63a8\u65ad\u5728\u6269\u5c55\u5230\u591a\u7c7b\u522b\u591a\u503c\u5904\u7406\u65f6\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u4e8c\u5143\u6216\u5355\u7c7b\u578b\u5904\u7406\uff0c\u5b58\u5728\u5047\u8bbe\u9650\u5236\u3001\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\u548c\u8bc4\u4f30\u6846\u67b6\u4e0d\u5b8c\u5584\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faXTNet\u67b6\u6784\uff0c\u91c7\u7528\u5206\u89e3\u7b56\u7565\u5c06\u57fa\u672c\u6548\u5e94\u4e0e\u4ea4\u53c9\u5904\u7406\u4ea4\u4e92\u5206\u79bb\uff0c\u5f15\u5165\u52a8\u6001\u63a9\u7801\u673a\u5236\u7684\u4ea4\u53c9\u6548\u5e94\u4f30\u8ba1\u6a21\u5757\uff0c\u5e76\u63d0\u51fa\u4e86\u8003\u8651\u5904\u7406\u6210\u672c\u548c\u4ea4\u4e92\u6548\u5e94\u7684MCMV-AUCC\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cXTNet\u5728\u6392\u5e8f\u51c6\u786e\u6027\u548c\u6548\u5e94\u4f30\u8ba1\u8d28\u91cf\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u771f\u5b9eA/B\u6d4b\u8bd5\u7ed3\u679c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "XTNet\u80fd\u591f\u6709\u6548\u5efa\u6a21\u590d\u6742\u7ec4\u5408\u5904\u7406\u7a7a\u95f4\uff0c\u4e3a\u591a\u7c7b\u522b\u591a\u503c\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01694", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01694", "abs": "https://arxiv.org/abs/2511.01694", "authors": ["Hossein Abdi", "Mingfei Sun", "Wei Pan"], "title": "Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering", "comment": null, "summary": "Vision-language pre-trained models, such as CLIP, have established new\nbenchmarks in multimodal data mining. In such models, few-shot fine-tuning is a\nmajor challenge to achieve optimal performance on both in-distribution (ID) and\nout-of-distribution (OOD) datasets, especially when labeled data is scarce.\nMost existing fine-tuning approaches rely on first-order gradient-based\noptimizers, which typically suffer from slow convergence, sensitivity to\nstep-size hyperparameters, and poor generalization in OOD settings. In\ncontrast, second-order methods utilize local curvature information of the loss\nlandscape to adjust the update step size. This is particularly beneficial for\nCLIP models, whose non-convex loss functions often contain sharp critical\npoints. In such cases, natural gradient direction can offer more substantial\nand efficient per-iteration updates when fine-tuning with limited data. Natural\nGradient Descent (NGD) is obtained by preconditioning the standard gradient\nwith the inverse Fisher Information Matrix (FIM), which is computationally\nexpensive for large models. To address this, we propose a Bayesian\napproximation of NGD using a Kalman filter for CLIP models. Our method combines\nthe benefits of second-order optimization with Bayesian inference, which\nenhances generalization while providing uncertainty quantification. Extensive\nexperiments conducted on diverse image classification datasets demonstrate that\nour algorithm consistently achieves superior--or comparable--ID performance and\nimproved OOD robustness compared to state-of-the-art baselines. To the best of\nour knowledge, this work represents the first successful application of Kalman\nfiltering to fine-tuning CLIP-based models, which enables more robust and\nefficient learning in vision-language tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u8d1d\u53f6\u65af\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u7528\u4e8eCLIP\u6a21\u578b\u7684\u5c0f\u6837\u672c\u5fae\u8c03\uff0c\u5728\u4fdd\u6301ID\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347OOD\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3CLIP\u6a21\u578b\u5728\u5c11\u6837\u672c\u5fae\u8c03\u4e2d\u9762\u4e34\u7684\u4e00\u9636\u4f18\u5316\u65b9\u6cd5\u6536\u655b\u6162\u3001\u5bf9\u8d85\u53c2\u6570\u654f\u611f\u3001OOD\u6cdb\u5316\u5dee\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u4e8c\u9636\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5bf9\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u8d1d\u53f6\u65af\u8fd1\u4f3c\uff0c\u7ed3\u5408\u4e8c\u9636\u4f18\u5316\u7684\u4f18\u52bf\u548c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u591a\u4e2a\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728ID\u6027\u80fd\u4e0a\u8fbe\u5230\u6216\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728OOD\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u6210\u529f\u5c06\u5361\u5c14\u66fc\u6ee4\u6ce2\u5e94\u7528\u4e8eCLIP\u6a21\u578b\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u9ad8\u6548\u7684\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u5b66\u4e60\u3002"}}
{"id": "2511.01695", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01695", "abs": "https://arxiv.org/abs/2511.01695", "authors": ["Jungyeon Koh", "Hyun Jong Yang"], "title": "Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding", "comment": null, "summary": "The growing demand for on-device large language model (LLM) inference\nhighlights the need for efficient mobile edge computing (MEC) solutions,\nespecially in resource-constrained settings. Speculative decoding offers a\npromising solution by partitioning token generation between a lightweight draft\nmodel on mobile devices and a powerful target model on edge servers, but\nsuffers from communication overhead and asynchronous delays. This paper is the\nfirst to propose a unified framework that jointly optimizes user association\nand resource allocation (UARA) to support efficient parallel speculative\ndecoding. We solve the UARA problem using a multi-agent deep reinforcement\nlearning algorithm. To evaluate our approach under realistic conditions, we\nconduct experiments using the Sionna simulator. Results show that our method\nachieves up to 28.0% and an average of 23.7% reduction in end-to-end latency\nwithout compromising inference accuracy, enabling scalable and low-latency LLM\nservices in MEC systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u4f18\u5316\u7528\u6237\u5173\u8054\u548c\u8d44\u6e90\u5206\u914d\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u652f\u6301\u9ad8\u6548\u7684\u5e76\u884c\u63a8\u6d4b\u89e3\u7801\uff0c\u5728\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u4f4e\u5ef6\u8fdf\u7684LLM\u670d\u52a1\u3002", "motivation": "\u8bbe\u5907\u4e0a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9700\u6c42\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002\u63a8\u6d4b\u89e3\u7801\u867d\u7136\u80fd\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8349\u7a3f\u6a21\u578b\u548c\u5f3a\u5927\u76ee\u6807\u6a21\u578b\u7684\u5206\u5de5\u6765\u63d0\u5347\u6548\u7387\uff0c\u4f46\u9762\u4e34\u901a\u4fe1\u5f00\u9500\u548c\u5f02\u6b65\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u7528\u6237\u5173\u8054\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u5e76\u5728Sionna\u6a21\u62df\u5668\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u5f71\u54cd\u63a8\u7406\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad828.0%\u3001\u5e73\u574723.7%\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u652f\u6301\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u53ef\u6269\u5c55\u548c\u4f4e\u5ef6\u8fdf\u7684LLM\u670d\u52a1\u3002"}}
{"id": "2511.01737", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01737", "abs": "https://arxiv.org/abs/2511.01737", "authors": ["Obaidullah Zaland", "Feras M. Awaysheh", "Sawsan Al Zubi", "Abdul Rahman Safi", "Monowar Bhuyan"], "title": "Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?", "comment": "Presented at IEEE FLTA 2025", "summary": "Federated learning (FL) has emerged as a transformative paradigm for edge\nintelligence, enabling collaborative model training while preserving data\nprivacy across distributed personal devices. However, the inherent volatility\nof edge environments, characterized by dynamic resource availability and\nheterogeneous client capabilities, poses significant challenges for achieving\nhigh accuracy and fairness in client participation. This paper investigates the\nfundamental trade-off between model accuracy and fairness in highly volatile\nedge environments. This paper provides an extensive empirical evaluation of\nfairness-based client selection algorithms such as RBFF and RBCSF against\nrandom and greedy client selection regarding fairness, model performance, and\ntime, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This\nwork aims to shed light on the fairness-performance and fairness-speed\ntrade-offs in a volatile edge environment and explore potential future research\nopportunities to address existing pitfalls in \\textit{fair client selection}\nstrategies in FL. Our results indicate that more equitable client selection\nalgorithms, while providing a marginally better opportunity among clients, can\nresult in slower global training in volatile environments\\footnote{The code for\nour experiments can be found at\nhttps://github.com/obaidullahzaland/FairFL_FLTA.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u9ad8\u5ea6\u6ce2\u52a8\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u8054\u90a6\u5b66\u4e60\u7684\u6a21\u578b\u51c6\u786e\u6027\u4e0e\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u4e0d\u540c\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\u5728\u516c\u5e73\u6027\u3001\u6a21\u578b\u6027\u80fd\u548c\u65f6\u95f4\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u8fb9\u7f18\u73af\u5883\u7684\u56fa\u6709\u6ce2\u52a8\u6027\uff08\u52a8\u6001\u8d44\u6e90\u53ef\u7528\u6027\u548c\u5f02\u6784\u5ba2\u6237\u7aef\u80fd\u529b\uff09\u7ed9\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u516c\u5e73\u7684\u5ba2\u6237\u7aef\u53c2\u4e0e\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u51c6\u786e\u6027\u4e0e\u516c\u5e73\u6027\u7684\u6743\u8861\u5173\u7cfb\u3002", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08CIFAR10\u3001FashionMNIST\u548cEMNIST\uff09\u4e0a\uff0c\u5bf9\u57fa\u4e8e\u516c\u5e73\u6027\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\uff08\u5982RBFF\u548cRBCSF\uff09\u4e0e\u968f\u673a\u548c\u8d2a\u5a6a\u9009\u62e9\u7b97\u6cd5\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u66f4\u516c\u5e73\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\u867d\u7136\u80fd\u4e3a\u5ba2\u6237\u7aef\u63d0\u4f9b\u7a0d\u597d\u7684\u53c2\u4e0e\u673a\u4f1a\uff0c\u4f46\u5728\u6ce2\u52a8\u73af\u5883\u4e2d\u4f1a\u5bfc\u81f4\u5168\u5c40\u8bad\u7ec3\u901f\u5ea6\u53d8\u6162\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u5728\u6ce2\u52a8\u8fb9\u7f18\u73af\u5883\u4e2d\u516c\u5e73\u6027\u4e0e\u6027\u80fd\u3001\u516c\u5e73\u6027\u4e0e\u901f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u63a2\u7d22\u4e86\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u516c\u5e73\u5ba2\u6237\u7aef\u9009\u62e9\u7b56\u7565\u73b0\u6709\u7f3a\u9677\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.01740", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01740", "abs": "https://arxiv.org/abs/2511.01740", "authors": ["Dmitrij Schlesinger", "Boris Flach"], "title": "Game-theoretic distributed learning of generative models for heterogeneous data collections", "comment": "The manuscript is accepted for publishing at the 2025 Symposium on\n  Federated Learning and Intelligent Computing Systems (FLICS 2025)", "summary": "One of the main challenges in distributed learning arises from the difficulty\nof handling heterogeneous local models and data. In light of the recent success\nof generative models, we propose to meet this challenge by building on the idea\nof exchanging synthetic data instead of sharing model parameters. Local models\ncan then be treated as ``black boxes'' with the ability to learn their\nparameters from data and to generate data according to these parameters.\nMoreover, if the local models admit semi-supervised learning, we can extend the\napproach by enabling local models on different probability spaces. This allows\nto handle heterogeneous data with different modalities. We formulate the\nlearning of the local models as a cooperative game starting from the principles\nof game theory. We prove the existence of a unique Nash equilibrium for\nexponential family local models and show that the proposed learning approach\nconverges to this equilibrium. We demonstrate the advantages of our approach on\nstandard benchmark vision datasets for image classification and conditional\ngeneration.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5408\u6210\u6570\u636e\u4ea4\u6362\u800c\u975e\u6a21\u578b\u53c2\u6570\u5171\u4eab\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u672c\u5730\u6a21\u578b\u548c\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5c06\u672c\u5730\u6a21\u578b\u89c6\u4e3a\u9ed1\u76d2\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u65b9\u6cd5\u5b9e\u73b0\u534f\u540c\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u5904\u7406\u5f02\u6784\u672c\u5730\u6a21\u578b\u548c\u6570\u636e\u7684\u6311\u6218\uff0c\u5229\u7528\u751f\u6210\u6a21\u578b\u7684\u6210\u529f\uff0c\u901a\u8fc7\u4ea4\u6362\u5408\u6210\u6570\u636e\u6765\u907f\u514d\u76f4\u63a5\u5171\u4eab\u6a21\u578b\u53c2\u6570\u3002", "method": "\u5c06\u672c\u5730\u6a21\u578b\u89c6\u4e3a\u9ed1\u76d2\uff0c\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53c2\u6570\u5e76\u751f\u6210\u6570\u636e\uff1b\u652f\u6301\u534a\u76d1\u7763\u5b66\u4e60\uff0c\u5141\u8bb8\u4e0d\u540c\u6982\u7387\u7a7a\u95f4\u7684\u672c\u5730\u6a21\u578b\u5904\u7406\u591a\u6a21\u6001\u5f02\u6784\u6570\u636e\uff1b\u57fa\u4e8e\u535a\u5f08\u8bba\u5c06\u672c\u5730\u6a21\u578b\u5b66\u4e60\u5236\u5b9a\u4e3a\u5408\u4f5c\u535a\u5f08\u3002", "result": "\u8bc1\u660e\u4e86\u6307\u6570\u65cf\u672c\u5730\u6a21\u578b\u5b58\u5728\u552f\u4e00\u7eb3\u4ec0\u5747\u8861\uff0c\u63d0\u51fa\u7684\u5b66\u4e60\u65b9\u6cd5\u6536\u655b\u5230\u8be5\u5747\u8861\uff1b\u5728\u6807\u51c6\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u5206\u7c7b\u548c\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5408\u6210\u6570\u636e\u4ea4\u6362\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u6846\u67b6\u5b9e\u73b0\u4e86\u672c\u5730\u6a21\u578b\u7684\u534f\u540c\u5b66\u4e60\uff0c\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2511.01743", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01743", "abs": "https://arxiv.org/abs/2511.01743", "authors": ["Song Gao", "Shusen Jing", "Shuai Zhang", "Yue Wang", "Xiangwei Zhou", "Songyang Zhang"], "title": "Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing", "comment": null, "summary": "Recent advancements in large artificial intelligence models (LAMs) are\ndriving significant innovations in mobile edge computing within next-generation\nwireless networks. However, the substantial demands for computational resources\nand large-scale training data required to train LAMs conflict with the limited\nstorage and computational capacity of edge devices, posing significant\nchallenges to training and deploying LAMs at the edge. In this work, we\nintroduce the Networked Mixture-of-Experts (NMoE) system, in which clients\ninfer collaboratively by distributing tasks to suitable neighbors based on\ntheir expertise and aggregate the returned results. For training the NMoE, we\npropose a federated learning framework that integrates both supervised and\nself-supervised learning to balance personalization and generalization, while\npreserving communication efficiency and data privacy. We conduct extensive\nexperiments to demonstrate the efficacy of the proposed NMoE system, providing\ninsights and benchmarks for the NMoE training algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86Networked Mixture-of-Experts (NMoE)\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\u4e2d\u534f\u540c\u8bad\u7ec3\u548c\u90e8\u7f72\u5927\u578bAI\u6a21\u578b\uff0c\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578bAI\u6a21\u578b\u5728\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u4e0e\u8fb9\u7f18\u8bbe\u5907\u6709\u9650\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u51b2\u7a81\uff0c\u8fd9\u7ed9\u8fb9\u7f18\u8bad\u7ec3\u548c\u90e8\u7f72\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165NMoE\u7cfb\u7edf\uff0c\u5ba2\u6237\u7aef\u57fa\u4e8e\u4e13\u5bb6\u80fd\u529b\u5c06\u4efb\u52a1\u5206\u53d1\u7ed9\u5408\u9002\u7684\u90bb\u5c45\u5e76\u805a\u5408\u8fd4\u56de\u7ed3\u679c\uff1b\u63d0\u51fa\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5e73\u8861\u4e2a\u6027\u5316\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86NMoE\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3aNMoE\u8bad\u7ec3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\u548c\u57fa\u51c6\u3002", "conclusion": "NMoE\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u901a\u4fe1\u6548\u7387\u548c\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u5927\u578bAI\u6a21\u578b\u7684\u8fb9\u7f18\u90e8\u7f72\u3002"}}
{"id": "2511.01745", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.01745", "abs": "https://arxiv.org/abs/2511.01745", "authors": ["Mei-Chin Pang", "Suraj Adhikari", "Takuma Kasahara", "Nagihiro Haba", "Saneyuki Ohno"], "title": "An Open-Access Benchmark of Statistical and Machine-Learning Anomaly Detection Methods for Battery Applications", "comment": null, "summary": "Battery safety is critical in applications ranging from consumer electronics\nto electric vehicles and aircraft, where undetected anomalies could trigger\nsafety hazards or costly downtime. In this study, we present OSBAD as an\nopen-source benchmark for anomaly detection frameworks in battery applications.\nBy benchmarking 15 diverse algorithms encompassing statistical, distance-based,\nand unsupervised machine-learning methods, OSBAD enables a systematic\ncomparison of anomaly detection methods across heterogeneous datasets. In\naddition, we demonstrate how a physics- and statistics-informed feature\ntransformation workflow enhances anomaly separability by decomposing collective\nanomalies into point anomalies. To address a major bottleneck in unsupervised\nanomaly detection due to incomplete labels, we propose a Bayesian optimization\npipeline that facilitates automated hyperparameter tuning based on\ntransfer-learning and regression proxies. Through validation on datasets\ncovering both liquid and solid-state chemistries, we further demonstrate the\ncross-chemistry generalization capability of OSBAD to identify irregularities\nacross different electrochemical systems. By making benchmarking database with\nopen-source reproducible anomaly detection workflows available to the\ncommunity, OSBAD establishes a unified foundation for developing safe,\nscalable, and transferable anomaly detection tools in battery analytics. This\nresearch underscores the significance of physics- and statistics-informed\nfeature engineering as well as model selection with probabilistic\nhyperparameter tuning, in advancing trustworthy, data-driven diagnostics for\nsafety-critical energy systems.", "AI": {"tldr": "OSBAD\u662f\u4e00\u4e2a\u7528\u4e8e\u7535\u6c60\u5e94\u7528\u5f02\u5e38\u68c0\u6d4b\u7684\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f8315\u79cd\u4e0d\u540c\u7b97\u6cd5\uff0c\u7ed3\u5408\u7269\u7406\u548c\u7edf\u8ba1\u7279\u5f81\u5de5\u7a0b\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u8d85\u53c2\u6570\u81ea\u52a8\u8c03\u4f18\u65b9\u6cd5\u3002", "motivation": "\u7535\u6c60\u5b89\u5168\u5728\u6d88\u8d39\u7535\u5b50\u3001\u7535\u52a8\u6c7d\u8f66\u548c\u822a\u7a7a\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u672a\u68c0\u6d4b\u5230\u7684\u5f02\u5e38\u53ef\u80fd\u5f15\u53d1\u5b89\u5168\u9690\u60a3\u6216\u9ad8\u6602\u505c\u673a\u65f6\u95f4\u3002\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u57fa\u51c6\u548c\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u5f00\u53d1OSBAD\u5f00\u6e90\u57fa\u51c6\uff0c\u5305\u542b15\u79cd\u7edf\u8ba1\u3001\u8ddd\u79bb\u548c\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff1b\u63d0\u51fa\u7269\u7406\u548c\u7edf\u8ba1\u7279\u5f81\u8f6c\u6362\u5de5\u4f5c\u6d41\u5206\u89e3\u96c6\u4f53\u5f02\u5e38\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u8d85\u53c2\u6570\u81ea\u52a8\u8c03\u4f18\u7ba1\u9053\u3002", "result": "\u5728\u6db5\u76d6\u6db2\u6001\u548c\u56fa\u6001\u5316\u5b66\u7535\u6c60\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u8de8\u5316\u5b66\u4f53\u7cfb\u7684\u6cdb\u5316\u80fd\u529b\uff1b\u7279\u5f81\u5de5\u7a0b\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u53ef\u5206\u79bb\u6027\uff1b\u8d85\u53c2\u6570\u8c03\u4f18\u89e3\u51b3\u4e86\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u6807\u7b7e\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\u3002", "conclusion": "OSBAD\u4e3a\u7535\u6c60\u5206\u6790\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u5f02\u5e38\u68c0\u6d4b\u5f00\u53d1\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u7269\u7406\u7edf\u8ba1\u7279\u5f81\u5de5\u7a0b\u548c\u6982\u7387\u8d85\u53c2\u6570\u8c03\u4f18\u5728\u5b89\u5168\u5173\u952e\u80fd\u6e90\u7cfb\u7edf\u4e2d\u53ef\u4fe1\u6570\u636e\u9a71\u52a8\u8bca\u65ad\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.01758", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01758", "abs": "https://arxiv.org/abs/2511.01758", "authors": ["Mian Wu", "Gavin Zhang", "Sewon Min", "Sergey Levine", "Aviral Kumar"], "title": "RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks", "comment": "Project page: https://mianwu01.github.io/RLAC_website/", "summary": "Open-ended generation tasks require outputs to satisfy diverse and often\nimplicit task-specific evaluation rubrics. The sheer number of relevant rubrics\nleads to prohibitively high verification costs and incomplete assessments of a\nresponse, making reinforcement learning (RL) post-training with rubric-based\nrewards difficult to scale. This problem is exacerbated by the fact that often\nthe best way to combine these rubrics into one single reward is also highly\nprompt-specific. We propose Reinforcement Learning with Adversarial Critic\n(RLAC), a post-training approach that addresses these challenges via dynamic\nrubric verification. Our approach employs a large language model (LLM) as a\ncritic that dynamically identifies only the most likely failure modes (e.g., a\nfactual error or unhandled edge case), which are then verified by an external\nvalidator to optimize both generator and critic jointly. By training both the\ngenerator and the critic, this game enhances the critic's error detection and\nthe generator's output quality while reducing required verifications. Our\nexperiments demonstrate that RLAC improves factual accuracy in text generation\nand correctness in code generation, while also outperforming exhaustive\nverification and reward model methods. We show that dynamic critics are more\neffective than fixed critics, showcasing the potential of RLAC for scaling RL\npost-training to free-form generation tasks.", "AI": {"tldr": "RLAC\u662f\u4e00\u79cd\u4f7f\u7528\u52a8\u6001\u6279\u8bc4\u5668\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u6700\u53ef\u80fd\u7684\u5931\u8d25\u6a21\u5f0f\u6765\u51cf\u5c11\u9a8c\u8bc1\u6210\u672c\uff0c\u540c\u65f6\u63d0\u5347\u751f\u6210\u5668\u548c\u6279\u8bc4\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u5f00\u653e\u751f\u6210\u4efb\u52a1\u9700\u8981\u6ee1\u8db3\u591a\u6837\u5316\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4f46\u9a8c\u8bc1\u6210\u672c\u8fc7\u9ad8\u4e14\u8bc4\u4f30\u4e0d\u5b8c\u6574\uff0c\u4f7f\u5f97\u57fa\u4e8e\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u4f7f\u7528LLM\u4f5c\u4e3a\u52a8\u6001\u6279\u8bc4\u5668\u8bc6\u522b\u6700\u53ef\u80fd\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u901a\u8fc7\u5916\u90e8\u9a8c\u8bc1\u5668\u9a8c\u8bc1\uff0c\u8054\u5408\u4f18\u5316\u751f\u6210\u5668\u548c\u6279\u8bc4\u5668\u3002", "result": "RLAC\u5728\u6587\u672c\u751f\u6210\u4e2d\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u63d0\u9ad8\u4e86\u6b63\u786e\u6027\uff0c\u4f18\u4e8e\u7a77\u4e3e\u9a8c\u8bc1\u548c\u5956\u52b1\u6a21\u578b\u65b9\u6cd5\u3002", "conclusion": "\u52a8\u6001\u6279\u8bc4\u5668\u6bd4\u56fa\u5b9a\u6279\u8bc4\u5668\u66f4\u6709\u6548\uff0cRLAC\u6709\u6f5c\u529b\u5c06\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u6269\u5c55\u5230\u81ea\u7531\u5f62\u5f0f\u751f\u6210\u4efb\u52a1\u3002"}}
{"id": "2511.01794", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01794", "abs": "https://arxiv.org/abs/2511.01794", "authors": ["Vi Retault", "Yoha\u00ef-Eliel Berreby"], "title": "Random Initialization of Gated Sparse Adapters", "comment": "13 pages (8 main), 6 figures (4 main). Accepted by NewInML workshop @\n  ICML 2025 on June 27, 2025", "summary": "When fine-tuning language models on new tasks, catastrophic forgetting --\nperformance degradation on previously-learned tasks -- is a ubiquitous problem.\nWhile Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA address this\nthrough low-rank adapters, sparse adaptation offers an alternative that doesn't\nimpose rank constraints. We introduce Random Initialization of Gated Sparse\nAdapters (RIGSA), which starts from randomly-initialized full-rank adapters,\ngates them with a ReZero analog, and sparsifies them with iterative magnitude\npruning. We evaluate RIGSA on SmolLM2-1.7B-Instruct using a novel\nvision-in-text task (Textual MNIST) and measure forgetting on PIQA, HellaSwag,\nand GSM8k. SmolLM2-1.7B-Instruct initially performs around chance level on\nTextual MNIST, and is capable of learning the task through RIGSA, 4-bit QLoRA\nand random masking. In spite of having more trainable parameters than QLoRA,\nthe RIGSA configurations that we studied displayed less forgetting than QLoRA,\nparticularly on GSM8k, though it performs comparably to random masking.", "AI": {"tldr": "RIGSA\u662f\u4e00\u79cd\u65b0\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u521d\u59cb\u5316\u5168\u79e9\u9002\u914d\u5668\u3001ReZero\u95e8\u63a7\u548c\u8fed\u4ee3\u5e45\u5ea6\u526a\u679d\u6765\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u65b0\u4efb\u52a1\u4e0a\u5fae\u8c03\u65f6\u51fa\u73b0\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u73b0\u6709PEFT\u65b9\u6cd5\u5982LoRA\u5b58\u5728\u79e9\u7ea6\u675f\u9650\u5236\uff0c\u7a00\u758f\u9002\u914d\u63d0\u4f9b\u4e86\u4e0d\u65bd\u52a0\u79e9\u7ea6\u675f\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "RIGSA\u65b9\u6cd5\uff1a\u4ece\u968f\u673a\u521d\u59cb\u5316\u7684\u5168\u79e9\u9002\u914d\u5668\u5f00\u59cb\uff0c\u4f7f\u7528ReZero\u7c7b\u4f3c\u7684\u95e8\u63a7\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u5e45\u5ea6\u526a\u679d\u8fdb\u884c\u7a00\u758f\u5316\u5904\u7406\u3002", "result": "\u5728SmolLM2-1.7B-Instruct\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cRIGSA\u80fd\u591f\u5b66\u4e60\u65b0\u7684Textual MNIST\u4efb\u52a1\uff0c\u4e14\u76f8\u6bd4QLoRA\u663e\u793a\u51fa\u66f4\u5c11\u7684\u9057\u5fd8\uff0c\u7279\u522b\u662f\u5728GSM8k\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u4e0e\u968f\u673a\u63a9\u7801\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "RIGSA\u4f5c\u4e3a\u4e00\u79cd\u7a00\u758f\u9002\u914d\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\u65b9\u9762\u4f18\u4e8eQLoRA\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.01795", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01795", "abs": "https://arxiv.org/abs/2511.01795", "authors": ["Gabriel Nobis", "Maximilian Springenberg", "Arina Belova", "Rembert Daems", "Christoph Knochenhauer", "Manfred Opper", "Tolga Birdal", "Wojciech Samek"], "title": "Fractional Diffusion Bridge Models", "comment": "To appear in NeurIPS 2025 proceedings. This version includes\n  post-camera-ready revisions", "summary": "We present Fractional Diffusion Bridge Models (FDBM), a novel generative\ndiffusion bridge framework driven by an approximation of the rich and\nnon-Markovian fractional Brownian motion (fBM). Real stochastic processes\nexhibit a degree of memory effects (correlations in time), long-range\ndependencies, roughness and anomalous diffusion phenomena that are not captured\nin standard diffusion or bridge modeling due to the use of Brownian motion\n(BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM),\nwe construct FDBM that enable tractable inference while preserving the\nnon-Markovian nature of fBM. We prove the existence of a coupling-preserving\ngenerative diffusion bridge and leverage it for future state prediction from\npaired training data. We then extend our formulation to the Schr\\\"{o}dinger\nbridge problem and derive a principled loss function to learn the unpaired data\ntranslation. We evaluate FDBM on both tasks: predicting future protein\nconformations from aligned data, and unpaired image translation. In both\nsettings, FDBM achieves superior performance compared to the Brownian\nbaselines, yielding lower root mean squared deviation (RMSD) of C$_\\alpha$\natomic positions in protein structure prediction and lower Fr\\'echet Inception\nDistance (FID) in unpaired image translation.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6570\u6269\u6563\u6865\u6a21\u578b(FDBM)\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u8fd1\u4f3c\u7684\u65b0\u578b\u751f\u6210\u6269\u6563\u6865\u6846\u67b6\uff0c\u80fd\u591f\u6355\u6349\u771f\u5b9e\u968f\u673a\u8fc7\u7a0b\u4e2d\u7684\u8bb0\u5fc6\u6548\u5e94\u3001\u957f\u7a0b\u4f9d\u8d56\u6027\u548c\u5f02\u5e38\u6269\u6563\u73b0\u8c61\u3002", "motivation": "\u771f\u5b9e\u968f\u673a\u8fc7\u7a0b\u5177\u6709\u8bb0\u5fc6\u6548\u5e94\u3001\u65f6\u95f4\u76f8\u5173\u6027\u3001\u957f\u7a0b\u4f9d\u8d56\u6027\u548c\u5f02\u5e38\u6269\u6563\u7b49\u7279\u6027\uff0c\u8fd9\u4e9b\u5728\u6807\u51c6\u6269\u6563\u6216\u6865\u6a21\u578b\u4e2d\u65e0\u6cd5\u88ab\u6355\u6349\uff0c\u56e0\u4e3a\u6807\u51c6\u6a21\u578b\u4f7f\u7528\u5e03\u6717\u8fd0\u52a8\u3002", "method": "\u5229\u7528\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u7684\u9a6c\u5c14\u53ef\u592b\u8fd1\u4f3c(MA-fBM)\u6784\u5efaFDBM\uff0c\u4fdd\u6301\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u540c\u65f6\u5b9e\u73b0\u53ef\u5904\u7406\u7684\u63a8\u7406\u3002\u6269\u5c55\u5230Schr\u00f6dinger\u6865\u95ee\u9898\u5e76\u63a8\u5bfc\u51fa\u5b66\u4e60\u975e\u914d\u5bf9\u6570\u636e\u8f6c\u6362\u7684\u539f\u5219\u6027\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u86cb\u767d\u8d28\u6784\u8c61\u9884\u6d4b\u548c\u56fe\u50cf\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0cFDBM\u76f8\u6bd4\u5e03\u6717\u8fd0\u52a8\u57fa\u7ebf\u8868\u73b0\u66f4\u4f18\uff1a\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u4e2dC\u03b1\u539f\u5b50\u4f4d\u7f6e\u7684RMSD\u66f4\u4f4e\uff0c\u975e\u914d\u5bf9\u56fe\u50cf\u7ffb\u8bd1\u4e2dFID\u5206\u6570\u66f4\u4f4e\u3002", "conclusion": "FDBM\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u771f\u5b9e\u968f\u673a\u8fc7\u7a0b\u7684\u590d\u6742\u7279\u6027\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u5e03\u6717\u8fd0\u52a8\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.01800", "categories": ["cs.LG", "I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2511.01800", "abs": "https://arxiv.org/abs/2511.01800", "authors": ["Prateek Chanda", "Shrey Modi", "Ganesh Ramakrishnan"], "title": "Bayesian Coreset Optimization for Personalized Federated Learning", "comment": "9 pages, 5 figures, ICLR 2024", "summary": "In a distributed machine learning setting like Federated Learning where there\nare multiple clients involved which update their individual weights to a single\ncentral server, often training on the entire individual client's dataset for\neach client becomes cumbersome. To address this issue we propose $\\methodprop$:\na personalized coreset weighted federated learning setup where the training\nupdates for each individual clients are forwarded to the central server based\non only individual client coreset based representative data points instead of\nthe entire client data. Through theoretical analysis we present how the average\ngeneralization error is minimax optimal up to logarithm bounds (upper bounded\nby $\\mathcal{O}(n_k^{-\\frac{2 \\beta}{2 \\beta+\\boldsymbol{\\Lambda}}} \\log ^{2\n\\delta^{\\prime}}(n_k))$) and lower bounds of $\\mathcal{O}(n_k^{-\\frac{2\n\\beta}{2 \\beta+\\boldsymbol{\\Lambda}}})$, and how the overall generalization\nerror on the data likelihood differs from a vanilla Federated Learning setup as\na closed form function ${\\boldsymbol{\\Im}}(\\boldsymbol{w}, n_k)$ of the coreset\nweights $\\boldsymbol{w}$ and coreset sample size $n_k$. Our experiments on\ndifferent benchmark datasets based on a variety of recent personalized\nfederated learning architectures show significant gains as compared to random\nsampling on the training data followed by federated learning, thereby\nindicating how intelligently selecting such training samples can help in\nperformance. Additionally, through experiments on medical datasets our proposed\nmethod showcases some gains as compared to other submodular optimization based\napproaches used for subset selection on client's data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e2a\u6027\u5316\u6838\u5fc3\u96c6\u52a0\u6743\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u4ee3\u8868\u6027\u6570\u636e\u70b9\u800c\u975e\u5168\u90e8\u5ba2\u6237\u7aef\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u8bad\u7ec3\u6574\u4e2a\u6570\u636e\u96c6\u7684\u8ba1\u7b97\u8d1f\u62c5\u95ee\u9898\uff0c\u901a\u8fc7\u6838\u5fc3\u96c6\u9009\u62e9\u4ee3\u8868\u6027\u6570\u636e\u70b9\u6765\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u4e2a\u6027\u5316\u6838\u5fc3\u96c6\u52a0\u6743\u8054\u90a6\u5b66\u4e60\uff0c\u4f7f\u7528\u6838\u5fc3\u96c6\u4ee3\u8868\u6027\u6570\u636e\u70b9\u800c\u975e\u5168\u90e8\u5ba2\u6237\u7aef\u6570\u636e\u6765\u66f4\u65b0\u4e2d\u592e\u670d\u52a1\u5668\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a8\u5bfc\u6cdb\u5316\u8bef\u5dee\u8fb9\u754c\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u5e73\u5747\u6cdb\u5316\u8bef\u5dee\u5728\u6781\u5c0f\u6781\u5927\u610f\u4e49\u4e0b\u6700\u4f18\uff0c\u5b9e\u9a8c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u968f\u673a\u91c7\u6837\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u533b\u7597\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u5b50\u6a21\u4f18\u5316\u7684\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u667a\u80fd\u9009\u62e9\u8bad\u7ec3\u6837\u672c\u80fd\u6709\u6548\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u6027\u80fd\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u7684\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4e86\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2511.01804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01804", "abs": "https://arxiv.org/abs/2511.01804", "authors": ["Viraj Patel", "Lisa Kreusser", "Katharine Fraser"], "title": "Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields", "comment": "29 pages, 18 figures", "summary": "Blood flow is sensitive to disease and provides insight into cardiac\nfunction, making flow field analysis valuable for diagnosis. However, while\nsafer than radiation-based imaging and more suitable for patients with medical\nimplants, ultrasound suffers from attenuation with depth, limiting the quality\nof the image. Despite advances in echocardiographic particle image velocimetry\n(EchoPIV), accurately measuring blood velocity remains challenging due to the\ntechnique's limitations and the complexity of blood flow dynamics.\nPhysics-informed machine learning can enhance accuracy and robustness,\nparticularly in scenarios where noisy or incomplete data challenge purely\ndata-driven approaches. We present a physics-informed neural field model with\nmulti-scale Fourier Feature encoding for estimating blood flow from sparse and\nnoisy ultrasound data without requiring ground truth supervision. We\ndemonstrate that this model achieves consistently low mean squared error in\ndenoising and inpainting both synthetic and real datasets, verified against\nreference flow fields and ground truth flow rate measurements. While\nphysics-informed neural fields have been widely used to reconstruct medical\nimages, applications to medical flow reconstruction are mostly prominent in\nFlow MRI. In this work, we adapt methods that have proven effective in other\nimaging modalities to address the specific challenge of ultrasound-based flow\nreconstruction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u77e5\u8bc6\u7684\u795e\u7ecf\u573a\u6a21\u578b\uff0c\u4f7f\u7528\u591a\u5c3a\u5ea6\u5085\u91cc\u53f6\u7279\u5f81\u7f16\u7801\u4ece\u7a00\u758f\u566a\u58f0\u8d85\u58f0\u6570\u636e\u4e2d\u4f30\u8ba1\u8840\u6d41\uff0c\u65e0\u9700\u771f\u5b9e\u76d1\u7763\u5373\u53ef\u5b9e\u73b0\u53bb\u566a\u548c\u4fee\u590d\u3002", "motivation": "\u8d85\u58f0\u8840\u6d41\u5206\u6790\u5bf9\u75be\u75c5\u8bca\u65ad\u6709\u4ef7\u503c\uff0c\u4f46\u8d85\u58f0\u5b58\u5728\u6df1\u5ea6\u8870\u51cf\u95ee\u9898\uff0c\u4f20\u7edfEchoPIV\u6280\u672f\u6d4b\u91cf\u8840\u6d41\u901f\u5ea6\u5b58\u5728\u6311\u6218\u3002\u7269\u7406\u77e5\u8bc6\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u589e\u5f3a\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u566a\u58f0\u6216\u4e0d\u5b8c\u6574\u6570\u636e\u573a\u666f\u4e0b\u3002", "method": "\u4f7f\u7528\u7269\u7406\u77e5\u8bc6\u795e\u7ecf\u573a\u6a21\u578b\u7ed3\u5408\u591a\u5c3a\u5ea6\u5085\u91cc\u53f6\u7279\u5f81\u7f16\u7801\uff0c\u4ece\u7a00\u758f\u566a\u58f0\u8d85\u58f0\u6570\u636e\u91cd\u5efa\u8840\u6d41\uff0c\u65e0\u9700\u5730\u9762\u771f\u5b9e\u76d1\u7763\u3002", "result": "\u6a21\u578b\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u4e86\u4f4e\u5747\u65b9\u8bef\u5dee\u7684\u53bb\u566a\u548c\u4fee\u590d\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4e8e\u53c2\u8003\u6d41\u573a\u548c\u771f\u5b9e\u6d41\u91cf\u6d4b\u91cf\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5c06\u5176\u4ed6\u6210\u50cf\u6a21\u6001\u4e2d\u8bc1\u660e\u6709\u6548\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u8d85\u58f0\u8840\u6d41\u91cd\u5efa\uff0c\u5c55\u793a\u4e86\u7269\u7406\u77e5\u8bc6\u795e\u7ecf\u573a\u5728\u533b\u5b66\u8840\u6d41\u91cd\u5efa\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.01816", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.01816", "abs": "https://arxiv.org/abs/2511.01816", "authors": ["Maryam Bagherian"], "title": "No-rank Tensor Decomposition Using Metric Learning", "comment": null, "summary": "Tensor decomposition faces fundamental challenges in analyzing\nhigh-dimensional data, where traditional methods based on reconstruction and\nfixed-rank constraints often fail to capture semantically meaningful\nstructures. This paper introduces a no-rank tensor decomposition framework\ngrounded in metric learning, which replaces reconstruction objectives with a\ndiscriminative, similarity-based optimization. The proposed approach learns\ndata-driven embeddings by optimizing a triplet loss with diversity and\nuniformity regularization, creating a feature space where distance directly\nreflects semantic similarity. We provide theoretical guarantees for the\nframework's convergence and establish bounds on its metric properties.\nEvaluations across diverse domains --including face recognition (LFW,\nOlivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy\nmorphology, crystal structures)-- demonstrate that our method outperforms\nbaseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition\nbaselines (CP and Tucker). Results show substantial improvements in clustering\nmetrics (Silhouette Score, Davies--Bouldin Index, Calinski--Harabasz Index,\nSeparation Ratio, Adjusted Rand Index, Normalized Mutual Information) and\nreveal a fundamental trade-off: while metric learning optimizes global class\nseparation, it deliberately transforms local geometry to align with semantic\nrelationships. Crucially, our approach achieves superior performance with\nsmaller training datasets compared to transformer-based methods, offering an\nefficient alternative for domains with limited labeled data. This work\nestablishes metric learning as a paradigm for tensor-based analysis,\nprioritizing semantic relevance over pixel-level fidelity while providing\ncomputational advantages in data-scarce scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u65e0\u79e9\u5f20\u91cf\u5206\u89e3\u6846\u67b6\uff0c\u7528\u5224\u522b\u6027\u76f8\u4f3c\u5ea6\u4f18\u5316\u66ff\u4ee3\u4f20\u7edf\u91cd\u6784\u76ee\u6807\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u57fa\u4e8e\u91cd\u6784\u548c\u56fa\u5b9a\u79e9\u7ea6\u675f\uff0c\u96be\u4ee5\u6355\u6349\u9ad8\u7ef4\u6570\u636e\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u76f4\u63a5\u53cd\u6620\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u65b0\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u4e09\u5143\u7ec4\u635f\u5931\u548c\u591a\u6837\u6027\u3001\u5747\u5300\u6027\u6b63\u5219\u5316\uff0c\u5b66\u4e60\u6570\u636e\u9a71\u52a8\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u4f7f\u8ddd\u79bb\u76f4\u63a5\u53cd\u6620\u8bed\u4e49\u76f8\u4f3c\u5ea6", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff08\u4eba\u8138\u8bc6\u522b\u3001\u8111\u8fde\u63a5\u5206\u6790\u3001\u6a21\u62df\u6570\u636e\uff09\u5747\u4f18\u4e8ePCA\u3001t-SNE\u3001UMAP\u548c\u4f20\u7edf\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\uff0c\u5728\u805a\u7c7b\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u4e14\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5", "conclusion": "\u5ea6\u91cf\u5b66\u4e60\u4e3a\u5f20\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u4f18\u5148\u8003\u8651\u8bed\u4e49\u76f8\u5173\u6027\u800c\u975e\u50cf\u7d20\u7ea7\u4fdd\u771f\u5ea6\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u5177\u6709\u8ba1\u7b97\u4f18\u52bf"}}
{"id": "2511.01819", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01819", "abs": "https://arxiv.org/abs/2511.01819", "authors": ["Hamed Fard", "Mahsa Kholghi", "Benedikt Gro\u00df", "Gerhard Wunder"], "title": "Machine and Deep Learning for Indoor UWB Jammer Localization", "comment": "Accepted at the 20th International Conference on Risks and Security\n  of Internet and Systems (CRiSIS 2025, Gatineau-Canada,\n  https://crisis2025.uqo.ca/). The paper will soon be published as\n  post-proceedings in Springer's LNCS", "summary": "Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is\nvulnerable to jamming attacks, creating security risks for asset tracking and\nintrusion detection in smart buildings. Although machine learning (ML) and deep\nlearning (DL) methods have improved tag localization, localizing malicious\njammers within a single room and across changing indoor layouts remains largely\nunexplored. Two novel UWB datasets, collected under original and modified room\nconfigurations, are introduced to establish comprehensive ML/DL baselines.\nPerformance is rigorously evaluated using a variety of classification and\nregression metrics. On the source dataset with the collected UWB features,\nRandom Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves\nthe lowest mean Euclidean error of 20.16 cm. However, deploying these\nsource-trained models in the modified room layout led to severe performance\ndegradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99\ncm, demonstrating significant domain shift. To mitigate this degradation, a\ndomain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a\ngradient-reversal layer to align CIR-derived features across domains. The A-CNT\nframework restores localization performance by reducing the mean Euclidean\nerror to 34.67 cm. This represents a 77 percent improvement over\nnon-adversarial transfer learning and an 83 percent improvement over the best\nbaseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the\nresults demonstrate that adversarial feature alignment enables robust and\ntransferable indoor jammer localization despite environmental changes. Code and\ndataset available at https://github.com/afbf4c8996f/Jammer-Loc", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57df\u5bf9\u6297ConvNeXt\u81ea\u7f16\u7801\u5668(A-CNT)\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5ba4\u5185\u73af\u5883\u53d8\u5316\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u6076\u610f\u5e72\u6270\u6e90\u5b9a\u4f4d\uff0c\u89e3\u51b3\u4e86UWB\u5b9a\u4f4d\u7cfb\u7edf\u5728\u73af\u5883\u5e03\u5c40\u6539\u53d8\u65f6\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002", "motivation": "UWB\u5b9a\u4f4d\u7cfb\u7edf\u867d\u7136\u80fd\u63d0\u4f9b\u5398\u7c73\u7ea7\u7cbe\u5ea6\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u5e72\u6270\u653b\u51fb\uff0c\u4e14\u5728\u5ba4\u5185\u73af\u5883\u5e03\u5c40\u6539\u53d8\u65f6\u5b9a\u4f4d\u6027\u80fd\u4f1a\u4e25\u91cd\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u623f\u95f4\u5e03\u5c40\u7684\u5e72\u6270\u6e90\u5b9a\u4f4d\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e24\u4e2aUWB\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u57df\u5bf9\u6297ConvNeXt\u81ea\u7f16\u7801\u5668(A-CNT)\uff0c\u5229\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u5bf9\u9f50\u8de8\u57df\u7684CIR\u884d\u751f\u7279\u5f81\uff0c\u5b9e\u73b0\u7279\u5f81\u5c42\u9762\u7684\u57df\u9002\u5e94\u3002", "result": "\u5728\u539f\u59cb\u6570\u636e\u96c6\u4e0a\uff0cRandom Forest\u8fbe\u5230\u6700\u9ad8F1-macro\u5206\u65700.95\uff0cXGBoost\u8fbe\u5230\u6700\u4f4e\u5e73\u5747\u6b27\u51e0\u91cc\u5f97\u8bef\u5dee20.16cm\u3002\u4f46\u5728\u4fee\u6539\u5e03\u5c40\u540e\uff0cXGBoost\u8bef\u5dee\u589e\u81f3207.99cm\u3002A-CNT\u65b9\u6cd5\u5c06\u8bef\u5dee\u964d\u81f334.67cm\uff0c\u6bd4\u975e\u5bf9\u6297\u8fc1\u79fb\u5b66\u4e60\u63d0\u534777%\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534783%\u3002", "conclusion": "\u57df\u5bf9\u6297\u7279\u5f81\u5bf9\u9f50\u80fd\u591f\u5728\u73af\u5883\u53d8\u5316\u4e0b\u5b9e\u73b0\u9c81\u68d2\u4e14\u53ef\u8fc1\u79fb\u7684\u5ba4\u5185\u5e72\u6270\u6e90\u5b9a\u4f4d\uff0c\u4e3a\u667a\u80fd\u5efa\u7b51\u4e2d\u7684\u8d44\u4ea7\u8ddf\u8e2a\u548c\u5165\u4fb5\u68c0\u6d4b\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2511.01830", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.01830", "abs": "https://arxiv.org/abs/2511.01830", "authors": ["Paul Setinek", "Gianluca Galletti", "Johannes Brandstetter"], "title": "Towards Multi-Fidelity Scaling Laws of Neural Surrogates in CFD", "comment": null, "summary": "Scaling laws describe how model performance grows with data, parameters and\ncompute. While large datasets can usually be collected at relatively low cost\nin domains such as language or vision, scientific machine learning is often\nlimited by the high expense of generating training data through numerical\nsimulations. However, by adjusting modeling assumptions and approximations,\nsimulation fidelity can be traded for computational cost, an aspect absent in\nother domains. We investigate this trade-off between data fidelity and cost in\nneural surrogates using low- and high-fidelity Reynolds-Averaged Navier-Stokes\n(RANS) simulations. Reformulating classical scaling laws, we decompose the\ndataset axis into compute budget and dataset composition. Our experiments\nreveal compute-performance scaling behavior and exhibit budget-dependent\noptimal fidelity mixes for the given dataset configuration. These findings\nprovide the first study of empirical scaling laws for multi-fidelity neural\nsurrogate datasets and offer practical considerations for compute-efficient\ndataset generation in scientific machine learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u6570\u636e\u4fdd\u771f\u5ea6\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u901a\u8fc7\u91cd\u65b0\u5236\u5b9a\u7ecf\u5178\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c06\u6570\u636e\u96c6\u8f74\u5206\u89e3\u4e3a\u8ba1\u7b97\u9884\u7b97\u548c\u6570\u636e\u96c6\u7ec4\u6210\uff0c\u63ed\u793a\u4e86\u8ba1\u7b97-\u6027\u80fd\u7f29\u653e\u884c\u4e3a\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u901a\u5e38\u53d7\u9650\u4e8e\u901a\u8fc7\u6570\u503c\u6a21\u62df\u751f\u6210\u8bad\u7ec3\u6570\u636e\u7684\u9ad8\u6602\u6210\u672c\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u5efa\u6a21\u5047\u8bbe\u548c\u8fd1\u4f3c\u6765\u5728\u6a21\u62df\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u8fd9\u662f\u5176\u4ed6\u9886\u57df\u6240\u4e0d\u5177\u5907\u7684\u7279\u70b9\u3002", "method": "\u4f7f\u7528\u4f4e\u4fdd\u771f\u5ea6\u548c\u9ad8\u4fdd\u771f\u5ea6\u7684\u96f7\u8bfa\u5e73\u5747\u7eb3\u7ef4-\u65af\u6258\u514b\u65af(RANS)\u6a21\u62df\u6765\u7814\u7a76\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\u4e2d\u6570\u636e\u4fdd\u771f\u5ea6\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u91cd\u65b0\u5236\u5b9a\u7ecf\u5178\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c06\u6570\u636e\u96c6\u8f74\u5206\u89e3\u4e3a\u8ba1\u7b97\u9884\u7b97\u548c\u6570\u636e\u96c6\u7ec4\u6210\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u8ba1\u7b97-\u6027\u80fd\u7f29\u653e\u884c\u4e3a\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u7ed9\u5b9a\u6570\u636e\u96c6\u914d\u7f6e\u4e0b\u9884\u7b97\u4f9d\u8d56\u7684\u6700\u4f18\u4fdd\u771f\u5ea6\u6df7\u5408\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u591a\u4fdd\u771f\u5ea6\u795e\u7ecf\u4ee3\u7406\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u9996\u4e2a\u7ecf\u9a8c\u7f29\u653e\u5b9a\u5f8b\u7814\u7a76\uff0c\u5e76\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u8ba1\u7b97\u9ad8\u6548\u7684\u6570\u636e\u96c6\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u9645\u8003\u8651\u3002"}}
{"id": "2511.01831", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01831", "abs": "https://arxiv.org/abs/2511.01831", "authors": ["Jay Mohta", "Kenan Emir Ak", "Dimitrios Dimitriadis", "Yan Xu", "Mingwei Shen"], "title": "Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) suffer from catastrophic forgetting when\nsequentially fine-tuned on new tasks, degrading performance on previously\nlearned foundational and task-specific capabilities. While multi-task learning\ncan mitigate forgetting, it requires simultaneous access to all datasets and\nimposes computational overhead that scales linearly with the number of tasks.\nIn this work, we introduce a routing-based approach that enables the\nintegration of new tasks while preserving the foundational knowledge acquired\nduring pretraining. We evaluate our method using InternVL-2 models (2B and 8B\nparameters) and demonstrate that routing preserves the model's foundational\ncapabilities by maintaining performance on general-purpose benchmarks such as\nChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on\nspecialized tasks. Importantly, our approach achieves this without requiring\nconcurrent access to data from all tasks, avoiding the significant\ncomputational and data overhead associated with traditional multi-task\nlearning. We further conduct extensive ablation studies to evaluate the\nscalability and robustness of routing-based learning, showing that the approach\nis resilient to a growing number of tasks and performs particularly well when\nnew tasks are semantically related. Finally, we show that the routing mechanism\nenables superior cross-modal transfer between language and vision capabilities,\nallowing knowledge learned in one modality to enhance performance in another\ncapability not achieved by existing continual learning methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u987a\u5e8f\u5fae\u8c03\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u65e0\u9700\u540c\u65f6\u8bbf\u95ee\u6240\u6709\u4efb\u52a1\u6570\u636e\uff0c\u4fdd\u6301\u57fa\u7840\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u4e13\u4e1a\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u987a\u5e8f\u5fae\u8c03\u65b0\u4efb\u52a1\u65f6\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f20\u7edf\u591a\u4efb\u52a1\u5b66\u4e60\u9700\u8981\u540c\u65f6\u8bbf\u95ee\u6240\u6709\u6570\u636e\u96c6\u4e14\u8ba1\u7b97\u5f00\u9500\u968f\u4efb\u52a1\u6570\u91cf\u7ebf\u6027\u589e\u957f\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\uff0c\u5728InternVL-2\u6a21\u578b(2B\u548c8B\u53c2\u6570)\u4e0a\u5b9e\u73b0\u65b0\u4efb\u52a1\u96c6\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u57fa\u7840\u77e5\u8bc6\u3002", "result": "\u8def\u7531\u65b9\u6cd5\u5728ChartQA\u3001MMBench\u548cDocVQA\u7b49\u901a\u7528\u57fa\u51c6\u4e0a\u4fdd\u6301\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u5347\u4e13\u4e1a\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u65e0\u9700\u6240\u6709\u4efb\u52a1\u6570\u636e\u5e76\u53d1\u8bbf\u95ee\u3002", "conclusion": "\u8def\u7531\u673a\u5236\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8bed\u4e49\u76f8\u5173\u7684\u65b0\u4efb\u52a1\uff0c\u5e76\u5b9e\u73b0\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff0c\u4f18\u4e8e\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2511.01836", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01836", "abs": "https://arxiv.org/abs/2511.01836", "authors": ["Ekdeep Singh Lubana", "Can Rager", "Sai Sumedh R. Hindupur", "Valerie Costa", "Greta Tuckute", "Oam Patel", "Sonia Krishna Murthy", "Thomas Fel", "Daniel Wurgaft", "Eric J. Bigelow", "Johnny Lin", "Demba Ba", "Martin Wattenberg", "Fernanda Viegas", "Melanie Weber", "Aaron Mueller"], "title": "Priors in Time: Missing Inductive Biases for Language Model Interpretability", "comment": "Preprint", "summary": "Recovering meaningful concepts from language model activations is a central\naim of interpretability. While existing feature extraction methods aim to\nidentify concepts that are independent directions, it is unclear if this\nassumption can capture the rich temporal structure of language. Specifically,\nvia a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose\npriors that assume independence of concepts across time, implying stationarity.\nMeanwhile, language model representations exhibit rich temporal dynamics,\nincluding systematic growth in conceptual dimensionality, context-dependent\ncorrelations, and pronounced non-stationarity, in direct conflict with the\npriors of SAEs. Taking inspiration from computational neuroscience, we\nintroduce a new interpretability objective -- Temporal Feature Analysis --\nwhich possesses a temporal inductive bias to decompose representations at a\ngiven time into two parts: a predictable component, which can be inferred from\nthe context, and a residual component, which captures novel information\nunexplained by the context. Temporal Feature Analyzers correctly parse garden\npath sentences, identify event boundaries, and more broadly delineate abstract,\nslow-moving information from novel, fast-moving information, while existing\nSAEs show significant pitfalls in all the above tasks. Overall, our results\nunderscore the need for inductive biases that match the data in designing\nrobust interpretability tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65f6\u95f4\u7279\u5f81\u5206\u6790\uff08Temporal Feature Analysis\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u4e2d\u7684\u65f6\u95f4\u52a8\u6001\u7279\u6027\uff0c\u5c06\u8868\u793a\u5206\u89e3\u4e3a\u53ef\u9884\u6d4b\u6210\u5206\u548c\u6b8b\u5dee\u6210\u5206\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u6355\u6349\u8bed\u8a00\u65f6\u5e8f\u7ed3\u6784\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5047\u8bbe\u6982\u5ff5\u662f\u72ec\u7acb\u65b9\u5411\uff0c\u4f46\u8bed\u8a00\u6a21\u578b\u8868\u793a\u5177\u6709\u4e30\u5bcc\u7684\u65f6\u95f4\u52a8\u6001\u7279\u6027\uff08\u5305\u62ec\u6982\u5ff5\u7ef4\u5ea6\u7684\u7cfb\u7edf\u6027\u589e\u957f\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u76f8\u5173\u6027\u548c\u975e\u5e73\u7a33\u6027\uff09\uff0c\u8fd9\u4e0e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u72ec\u7acb\u6027\u5148\u9a8c\u76f8\u51b2\u7a81\u3002", "method": "\u5f15\u5165\u65f6\u95f4\u7279\u5f81\u5206\u6790\u76ee\u6807\uff0c\u5177\u6709\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\uff0c\u5c06\u7ed9\u5b9a\u65f6\u95f4\u7684\u8868\u793a\u5206\u89e3\u4e3a\u4e24\u90e8\u5206\uff1a\u53ef\u4ece\u4e0a\u4e0b\u6587\u63a8\u65ad\u7684\u53ef\u9884\u6d4b\u6210\u5206\uff0c\u4ee5\u53ca\u6355\u6349\u4e0a\u4e0b\u6587\u65e0\u6cd5\u89e3\u91ca\u7684\u65b0\u4fe1\u606f\u7684\u6b8b\u5dee\u6210\u5206\u3002", "result": "\u65f6\u95f4\u7279\u5f81\u5206\u6790\u5668\u80fd\u6b63\u786e\u89e3\u6790\u82b1\u56ed\u8def\u5f84\u53e5\u5b50\u3001\u8bc6\u522b\u4e8b\u4ef6\u8fb9\u754c\uff0c\u5e76\u66f4\u5e7f\u6cdb\u5730\u533a\u5206\u62bd\u8c61\u6162\u901f\u4fe1\u606f\u548c\u65b0\u9896\u5feb\u901f\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u4e0a\u8ff0\u6240\u6709\u4efb\u52a1\u4e2d\u90fd\u663e\u793a\u51fa\u663e\u8457\u7f3a\u9677\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1\u7a33\u5065\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u65f6\u9700\u8981\u4e0e\u6570\u636e\u5339\u914d\u7684\u5f52\u7eb3\u504f\u7f6e\u3002"}}
{"id": "2511.01837", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01837", "abs": "https://arxiv.org/abs/2511.01837", "authors": ["Isabela Suaza-Sierra", "Hernan A. Moreno", "Luis A De la Fuente", "Thomas M. Neeson"], "title": "Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South", "comment": null, "summary": "Accurate prediction of Reservoir Water Temperature (RWT) is vital for\nsustainable water management, ecosystem health, and climate resilience. Yet,\nprediction alone offers limited insight into the governing physical processes.\nTo bridge this gap, we integrated explainable machine learning (ML) with\nsymbolic modeling to uncover the drivers of RWT dynamics across ten reservoirs\nin the Red River Basin, USA, using over 10,000 depth-resolved temperature\nprofiles. We first employed ensemble and neural models, including Random Forest\n(RF), Extreme Gradient Boosting (XGBoost), and Multilayer Perceptron (MLP),\nachieving high predictive skill (best RMSE = 1.20 degree Celsius, R^2 = 0.97).\nUsing SHAP (SHapley Additive exPlanations), we quantified the contribution of\nphysical drivers such as air temperature, depth, wind, and lake volume,\nrevealing consistent patterns across reservoirs. To translate these data-driven\ninsights into compact analytical expressions, we developed Kolmogorov Arnold\nNetworks (KANs) to symbolically approximate RWT. Ten progressively complex KAN\nequations were derived, improving from R^2 = 0.84 using a single predictor\n(7-day antecedent air temperature) to R^2 = 0.92 with ten predictors, though\ngains diminished beyond five, highlighting a balance between simplicity and\naccuracy. The resulting equations, dominated by linear and rational forms,\nincrementally captured nonlinear behavior while preserving interpretability.\nDepth consistently emerged as a secondary but critical predictor, whereas\nprecipitation had limited effect. By coupling predictive accuracy with\nexplanatory power, this framework demonstrates how KANs and explainable ML can\ntransform black-box models into transparent surrogates that advance both\nprediction and understanding of reservoir thermal dynamics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u548c\u7b26\u53f7\u5efa\u6a21\uff0c\u5f00\u53d1\u4e86Kolmogorov-Arnold\u7f51\u7edc(KANs)\u6765\u9884\u6d4b\u548c\u89e3\u91ca\u6c34\u5e93\u6c34\u6e29\u52a8\u6001\uff0c\u5728\u7ea2\u6cb3\u6d41\u57df10\u4e2a\u6c34\u5e93\u768410,000\u591a\u4e2a\u6e29\u5ea6\u5256\u9762\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u9ad8\u7cbe\u5ea6\u9884\u6d4b(RMSE=1.20\u00b0C, R\u00b2=0.97)\uff0c\u5e76\u63a8\u5bfc\u51fa\u53ef\u89e3\u91ca\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u6c34\u5e93\u6c34\u6e29\u5bf9\u6c34\u8d44\u6e90\u7ba1\u7406\u3001\u751f\u6001\u7cfb\u7edf\u5065\u5eb7\u548c\u6c14\u5019\u97e7\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5355\u7eaf\u9884\u6d4b\u65e0\u6cd5\u63ed\u793a\u80cc\u540e\u7684\u7269\u7406\u673a\u5236\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5c06\u9884\u6d4b\u80fd\u529b\u4e0e\u8fc7\u7a0b\u7406\u89e3\u76f8\u7ed3\u5408\u3002", "method": "\u4f7f\u7528\u96c6\u6210\u5b66\u4e60(RF\u3001XGBoost)\u548c\u795e\u7ecf\u7f51\u7edc(MLP)\u8fdb\u884c\u9884\u6d4b\uff0c\u901a\u8fc7SHAP\u5206\u6790\u91cf\u5316\u7269\u7406\u9a71\u52a8\u56e0\u7d20\u7684\u8d21\u732e\uff0c\u7136\u540e\u5f00\u53d1KANs\u7f51\u7edc\u7b26\u53f7\u5316\u8fd1\u4f3c\u6c34\u5e93\u6c34\u6e29\uff0c\u63a8\u5bfc\u51fa\u6e10\u8fdb\u590d\u6742\u7684\u89e3\u6790\u65b9\u7a0b\u3002", "result": "\u6700\u4f73\u9884\u6d4b\u7cbe\u5ea6RMSE=1.20\u00b0C\uff0cR\u00b2=0.97\u3002KANs\u65b9\u7a0b\u4ece\u5355\u9884\u6d4b\u56e0\u5b50(R\u00b2=0.84)\u9010\u6b65\u63d0\u5347\u523010\u4e2a\u9884\u6d4b\u56e0\u5b50(R\u00b2=0.92)\uff0c\u4f46\u8d85\u8fc75\u4e2a\u56e0\u5b50\u540e\u589e\u76ca\u9012\u51cf\u3002\u6df1\u5ea6\u662f\u5173\u952e\u6b21\u8981\u9884\u6d4b\u56e0\u5b50\uff0c\u964d\u6c34\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408KANs\u548c\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\uff0c\u6210\u529f\u5c06\u9ed1\u76d2\u6a21\u578b\u8f6c\u5316\u4e3a\u900f\u660e\u66ff\u4ee3\u6a21\u578b\uff0c\u65e2\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u53c8\u589e\u5f3a\u4e86\u5bf9\u6c34\u5e93\u70ed\u52a8\u529b\u5b66\u7684\u7406\u89e3\uff0c\u5e73\u8861\u4e86\u7b80\u6d01\u6027\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2511.01847", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01847", "abs": "https://arxiv.org/abs/2511.01847", "authors": ["Zhi Wang", "Chicheng Zhang", "Ramya Korlakai Vinayak"], "title": "Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure", "comment": null, "summary": "In lifelong learning, a learner faces a sequence of tasks with shared\nstructure and aims to identify and leverage it to accelerate learning. We study\nthe setting where such structure is captured by a common representation of\ndata. Unlike multi-task learning or learning-to-learn, where tasks are\navailable upfront to learn the representation, lifelong learning requires the\nlearner to make use of its existing knowledge while continually gathering\npartial information in an online fashion. In this paper, we consider a\ngeneralized framework of lifelong representation learning. We propose a simple\nalgorithm that uses multi-task empirical risk minimization as a subroutine and\nestablish a sample complexity bound based on a new notion we introduce--the\ntask-eluder dimension. Our result applies to a wide range of learning problems\ninvolving general function classes. As concrete examples, we instantiate our\nresult on classification and regression tasks under noise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec8\u8eab\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u4efb\u52a1\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4f5c\u4e3a\u5b50\u7a0b\u5e8f\uff0c\u5e76\u57fa\u4e8e\u65b0\u5f15\u5165\u7684\u4efb\u52a1\u89c4\u907f\u7ef4\u5ea6\u5efa\u7acb\u4e86\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\u3002", "motivation": "\u7ec8\u8eab\u5b66\u4e60\u9700\u8981\u5b66\u4e60\u8005\u5728\u9762\u5bf9\u8fde\u7eed\u4efb\u52a1\u65f6\u8bc6\u522b\u548c\u5229\u7528\u5171\u4eab\u7ed3\u6784\u6765\u52a0\u901f\u5b66\u4e60\uff0c\u8fd9\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\u6216\u5143\u5b66\u4e60\u4e0d\u540c\uff0c\u540e\u8005\u9700\u8981\u9884\u5148\u83b7\u5f97\u6240\u6709\u4efb\u52a1\u6765\u5b66\u4e60\u8868\u793a\u3002", "method": "\u4f7f\u7528\u591a\u4efb\u52a1\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4f5c\u4e3a\u5b50\u7a0b\u5e8f\uff0c\u5f15\u5165\u4efb\u52a1\u89c4\u907f\u7ef4\u5ea6\u6765\u5206\u6790\u6837\u672c\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u6d89\u53ca\u4e00\u822c\u51fd\u6570\u7c7b\u7684\u5e7f\u6cdb\u5b66\u4e60\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\uff0c\u8be5\u754c\u9650\u9002\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\u7b49\u5177\u4f53\u4efb\u52a1\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4e5f\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ec8\u8eab\u8868\u793a\u5b66\u4e60\u6846\u67b6\u548c\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u5171\u4eab\u8868\u793a\u7ed3\u6784\uff0c\u5728\u8fde\u7eed\u4efb\u52a1\u5b66\u4e60\u4e2d\u5b9e\u73b0\u52a0\u901f\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.01855", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01855", "abs": "https://arxiv.org/abs/2511.01855", "authors": ["Bettina Hanlon", "Angel Garcia Fernandez"], "title": "Coordinate ascent neural Kalman-MLE for state estimation", "comment": null, "summary": "This paper presents a coordinate ascent algorithm to learn dynamic and\nmeasurement models in dynamic state estimation using maximum likelihood\nestimation in a supervised manner. In particular, the dynamic and measurement\nmodels are assumed to be Gaussian and the algorithm learns the neural network\nparameters that model the dynamic and measurement functions, and also the noise\ncovariance matrices. The trained dynamic and measurement models are then used\nwith a non-linear Kalman filter algorithm to estimate the state during the\ntesting phase.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5750\u6807\u4e0a\u5347\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u76d1\u7763\u5b66\u4e60\u52a8\u6001\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\uff0c\u5305\u62ec\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u548c\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u7136\u540e\u7ed3\u5408\u975e\u7ebf\u6027\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6a21\u578b\u5df2\u77e5\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\u5f80\u5f80\u672a\u77e5\u6216\u96be\u4ee5\u7cbe\u786e\u5efa\u6a21\uff0c\u9700\u8981\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u8fd9\u4e9b\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5750\u6807\u4e0a\u5347\u7b97\u6cd5\uff0c\u5728\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u6846\u67b6\u4e0b\u4ea4\u66ff\u5b66\u4e60\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u4ee5\u53ca\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5047\u8bbe\u6a21\u578b\u4e3a\u9ad8\u65af\u5206\u5e03\u3002", "result": "\u8bad\u7ec3\u5f97\u5230\u7684\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\u80fd\u591f\u4e0e\u975e\u7ebf\u6027\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7ed3\u5408\uff0c\u5728\u6d4b\u8bd5\u9636\u6bb5\u6709\u6548\u4f30\u8ba1\u7cfb\u7edf\u72b6\u6001\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u52a8\u6001\u72b6\u6001\u4f30\u8ba1\u6240\u9700\u7684\u5b8c\u6574\u6a21\u578b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
