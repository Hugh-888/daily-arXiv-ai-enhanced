<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 156]
- [quant-ph](#quant-ph) [Total: 81]
- [gr-qc](#gr-qc) [Total: 21]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Fast Physics-Driven Untrained Network for Highly Nonlinear Inverse Scattering Problems](https://arxiv.org/abs/2602.13805)
*Yutong Du,Zicheng Liu,Yi Huang,Bazargul Matkerim,Bo Qi,Yali Zong,Peixian Han*

Main category: cs.LG

TL;DR: 提出实时物理驱动傅里叶谱求解器，通过谱域降维实现亚秒级电磁逆散射重建，相比现有方法提速100倍


<details>
  <summary>Details</summary>
Motivation: 未训练神经网络(UNNs)虽然能实现高保真电磁逆散射重建，但受限于高维空间域优化的计算负担，难以满足实时应用需求

Method: 1) 使用截断傅里叶基展开感应电流，将优化限制在紧凑低频参数空间；2) 集成收缩积分方程(CIE)缓解高对比度非线性；3) 对比度补偿算子(CCO)校正谱诱导衰减；4) 桥抑制损失函数增强散射体边界锐度

Result: 数值和实验结果显示：相比最先进的UNNs方法实现100倍加速，在噪声和天线不确定性下保持鲁棒性能，支持实时微波成像应用

Conclusion: PDF求解器通过谱域降维有效解决了UNNs的计算瓶颈，实现了实时电磁逆散射重建，为微波成像应用开辟了新途径

Abstract: Untrained neural networks (UNNs) offer high-fidelity electromagnetic inverse scattering reconstruction but are computationally limited by high-dimensional spatial-domain optimization. We propose a Real-Time Physics-Driven Fourier-Spectral (PDF) solver that achieves sub-second reconstruction through spectral-domain dimensionality reduction. By expanding induced currents using a truncated Fourier basis, the optimization is confined to a compact low-frequency parameter space supported by scattering measurements. The solver integrates a contraction integral equation (CIE) to mitigate high-contrast nonlinearity and a contrast-compensated operator (CCO) to correct spectral-induced attenuation. Furthermore, a bridge-suppressing loss is formulated to enhance boundary sharpness between adjacent scatterers. Numerical and experimental results demonstrate a 100-fold speedup over state-of-the-art UNNs with robust performance under noise and antenna uncertainties, enabling real-time microwave imaging applications.

</details>


### [2] [Directional Concentration Uncertainty: A representational approach to uncertainty quantification for generative models](https://arxiv.org/abs/2602.13264)
*Souradeep Chattopadhyay,Brendan Kennedy,Sai Munikoti,Soumik Sarkar,Karl Pazdernik*

Main category: cs.LG

TL;DR: 提出了一种基于方向集中不确定性（DCU）的新型不确定性量化框架，使用von Mises-Fisher分布测量生成输出的几何分散度，无需任务特定启发式方法，在多模态任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法依赖僵化的启发式规则，难以跨任务和模态泛化。需要更灵活、通用的框架来提高生成模型的可靠性和鲁棒性。

Method: 提出方向集中不确定性（DCU）方法，基于von Mises-Fisher分布，通过连续嵌入测量语言模型多个生成输出的几何分散度来量化不确定性，无需任务特定启发式。

Result: DCU在不确定性校准方面达到或超越了语义熵等先前方法，在更复杂的多模态任务中表现出良好的泛化能力。

Conclusion: DCU提供了一个灵活有效的不确定性量化框架，具有在多模态和智能体框架中集成的广泛潜力，为生成模型的可靠性和鲁棒性提供了新途径。

Abstract: In the critical task of making generative models trustworthy and robust, methods for Uncertainty Quantification (UQ) have begun to show encouraging potential. However, many of these methods rely on rigid heuristics that fail to generalize across tasks and modalities. Here, we propose a novel framework for UQ that is highly flexible and approaches or surpasses the performance of prior heuristic methods. We introduce Directional Concentration Uncertainty (DCU), a novel statistical procedure for quantifying the concentration of embeddings based on the von Mises-Fisher (vMF) distribution. Our method captures uncertainty by measuring the geometric dispersion of multiple generated outputs from a language model using continuous embeddings of the generated outputs without any task specific heuristics. In our experiments, we show that DCU matches or exceeds calibration levels of prior works like semantic entropy (Kuhn et al., 2023) and also generalizes well to more complex tasks in multi-modal domains. We present a framework for the wider potential of DCU and its implications for integration into UQ for multi-modal and agentic frameworks.

</details>


### [3] [BLUEPRINT Rebuilding a Legacy: Multimodal Retrieval for Complex Engineering Drawings and Documents](https://arxiv.org/abs/2602.13345)
*Ethan Seefried,Ran Eldegaway,Sanjay Das,Nathaniel Blanchard,Tirthankar Ghosal*

Main category: cs.LG

TL;DR: Blueprint是一个面向大规模工程图纸档案的布局感知多模态检索系统，通过区域检测、OCR、标识符归一化和混合检索，显著提升工程图纸检索效果


<details>
  <summary>Details</summary>
Motivation: 数十年的工程图纸和技术记录被锁定在遗留档案中，元数据不一致或缺失，导致检索困难且通常需要人工操作，需要自动化解决方案来解锁这些宝贵资源

Method: 系统检测标准图纸区域，应用区域限制的VLM-based OCR，归一化标识符（如DWG、零件、设施），融合词汇检索和密集检索，并使用轻量级区域级重排序器

Result: 在77万未标记文件上部署，自动生成结构化元数据；在5k文件基准测试中，相比最强视觉语言基线，Success@3提升10.1%，nDCG@3相对提升18.9%

Conclusion: Blueprint有效解决了工程图纸档案检索难题，在视觉、文本和多模态查询中表现一致优异，为遗留工程档案的可重复评估提供了完整解决方案

Abstract: Decades of engineering drawings and technical records remain locked in legacy archives with inconsistent or missing metadata, making retrieval difficult and often manual. We present Blueprint, a layout-aware multimodal retrieval system designed for large-scale engineering repositories. Blueprint detects canonical drawing regions, applies region-restricted VLM-based OCR, normalizes identifiers (e.g., DWG, part, facility), and fuses lexical and dense retrieval with a lightweight region-level reranker. Deployed on ~770k unlabeled files, it automatically produces structured metadata suitable for cross-facility search.
  We evaluate Blueprint on a 5k-file benchmark with 350 expert-curated queries using pooled, graded (0/1/2) relevance judgments. Blueprint delivers a 10.1% absolute gain in Success@3 and an 18.9% relative improvement in nDCG@3 over the strongest vision-language baseline}, consistently outperforming across vision, text, and multimodal intents. Oracle ablations reveal substantial headroom under perfect region detection and OCR. We release all queries, runs, annotations, and code to facilitate reproducible evaluation on legacy engineering archives.

</details>


### [4] [BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations](https://arxiv.org/abs/2602.14853)
*Jonathan Gorard,Ammar Hakim,James Juno*

Main category: cs.LG

TL;DR: BEACONS框架：通过形式化验证的神经网络求解PDE，在训练域外提供有界误差保证，克服传统神经网络外推不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在训练数据凸包外泛化不可靠，而计算物理中经常需要在远超实验或解析验证的区域内求解PDE，这构成了一个重要问题。

Method: 1. 使用特征线法预测PDE解的解析性质，构建浅层神经网络近似的最坏情况L^∞误差的严格外推边界；2. 将PDE解分解为简单函数的组合，基于组合深度学习思想，将浅层神经网络组合成深层架构，抑制近似中的大L^∞误差；3. 开发BEACONS框架，包括神经网络求解器的自动代码生成器和定制化的自动定理证明系统，用于生成机器可检查的正确性证书。

Result: 将框架应用于线性和非线性PDE，包括线性对流方程、无粘性Burgers方程以及完整的可压缩Euler方程（1D和2D），证明BEACONS架构能够以可靠且有界的方式在训练数据之外外推解。

Conclusion: BEACONS框架通过形式化验证的神经网络求解器，在PDE求解中实现了严格的外推能力，相比经典PINN方法具有多种优势，为计算物理中超越传统验证范围的可靠求解提供了新途径。

Abstract: The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.

</details>


### [5] [Exploring the Performance of ML/DL Architectures on the MNIST-1D Dataset](https://arxiv.org/abs/2602.13348)
*Michael Beebe,GodsGift Uzor,Manasa Chepuri,Divya Sree Vemula,Angel Ayala*

Main category: cs.LG

TL;DR: 本文评估了ResNet、TCN和DCNN在MNIST-1D数据集上的表现，发现这些先进架构在小型结构化数据集上优于简单模型，验证了MNIST-1D作为计算受限环境下机器学习架构评估基准的实用性。


<details>
  <summary>Details</summary>
Motivation: 传统小型数据集（如MNIST）虽然便于快速实验，但过于简单难以区分先进神经网络架构。MNIST-1D作为一维序列数据集，既保持了小规模优势，又增加了复杂性和变异性，适合研究架构的归纳偏置。

Method: 在MNIST-1D数据集上实现并评估了三种先进架构：残差网络（ResNet）、时序卷积网络（TCN）和扩张卷积神经网络（DCNN）。这些模型与之前测试的逻辑回归、MLP、CNN和GRU等架构进行基准比较。

Result: TCN和DCNN表现最佳，达到接近人类水平的性能。ResNet也有显著改进。所有先进架构都明显优于简单模型，证明了利用归纳偏置和层次特征提取在小型结构化数据集中的重要性。

Conclusion: MNIST-1D是评估计算受限环境下机器学习架构的有效基准。架构创新对提升模型性能至关重要，研究结果为资源有限环境下的深度学习模型优化提供了见解。

Abstract: Small datasets like MNIST have historically been instrumental in advancing machine learning research by providing a controlled environment for rapid experimentation and model evaluation. However, their simplicity often limits their utility for distinguishing between advanced neural network architectures. To address these challenges, Greydanus et al. introduced the MNIST-1D dataset, a one-dimensional adaptation of MNIST designed to explore inductive biases in sequential data. This dataset maintains the advantages of small-scale datasets while introducing variability and complexity that make it ideal for studying advanced architectures.
  In this paper, we extend the exploration of MNIST-1D by evaluating the performance of Residual Networks (ResNet), Temporal Convolutional Networks (TCN), and Dilated Convolutional Neural Networks (DCNN). These models, known for their ability to capture sequential patterns and hierarchical features, were implemented and benchmarked alongside previously tested architectures such as logistic regression, MLPs, CNNs, and GRUs. Our experimental results demonstrate that advanced architectures like TCN and DCNN consistently outperform simpler models, achieving near-human performance on MNIST-1D. ResNet also shows significant improvements, highlighting the importance of leveraging inductive biases and hierarchical feature extraction in small structured datasets.
  Through this study, we validate the utility of MNIST-1D as a robust benchmark for evaluating machine learning architectures under computational constraints. Our findings emphasize the role of architectural innovations in improving model performance and offer insights into optimizing deep learning models for resource-limited environments.

</details>


### [6] [The Speed-up Factor: A Quantitative Multi-Iteration Active Learning Performance Metric](https://arxiv.org/abs/2602.13359)
*Hannes Kath,Thiago S. Gouvêa,Daniel Sonntag*

Main category: cs.LG

TL;DR: 该论文提出了"加速因子"作为主动学习评估的新性能指标，用于量化查询方法相比随机采样达到相同性能所需的样本比例。


<details>
  <summary>Details</summary>
Motivation: 主动学习研究主要关注查询方法开发，但缺乏合适的迭代过程评估指标。现有评估方法不足以准确衡量查询方法在多轮迭代中的性能表现。

Method: 回顾八年主动学习评估文献，正式提出加速因子指标，使用四个不同领域的数据集和七种不同类型的查询方法进行实证评估，并与现有最先进的AL性能指标进行比较。

Result: 结果证实了加速因子的理论假设，证明其能准确捕捉所需样本比例，并显示出在迭代过程中优于其他指标的稳定性。

Conclusion: 加速因子是主动学习评估中一个准确、稳定的多轮迭代性能指标，能有效衡量查询方法相比随机采样的效率提升。

Abstract: Machine learning models excel with abundant annotated data, but annotation is often costly and time-intensive. Active learning (AL) aims to improve the performance-to-annotation ratio by using query methods (QMs) to iteratively select the most informative samples. While AL research focuses mainly on QM development, the evaluation of this iterative process lacks appropriate performance metrics. This work reviews eight years of AL evaluation literature and formally introduces the speed-up factor, a quantitative multi-iteration QM performance metric that indicates the fraction of samples needed to match random sampling performance. Using four datasets from diverse domains and seven QMs of various types, we empirically evaluate the speed-up factor and compare it with state-of-the-art AL performance metrics. The results confirm the assumptions underlying the speed-up factor, demonstrate its accuracy in capturing the described fraction, and reveal its superior stability across iterations.

</details>


### [7] [Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2602.13398)
*Daniel Emerson,Nora Gaby-Biegel,Purva Joshi,Yoed Rabin,Rebecca D. Sandlin,Levent Burak Kara*

Main category: cs.LG

TL;DR: 提出一个结合高通量筛选与多目标贝叶斯优化的主动学习框架，用于高效设计玻璃化冷冻保护剂配方，在减少实验次数的同时获得高浓度和高细胞存活率的平衡方案。


<details>
  <summary>Details</summary>
Motivation: 设计玻璃化冷冻保护剂配方面临挑战：需要足够浓度抑制冰晶形成，又要足够低毒性保持细胞活性。传统方法依赖专家经验或大量实验，效率低下。

Method: 结合高通量筛选与基于多目标贝叶斯优化的主动学习循环。从初始配方集开始，训练概率代理模型预测浓度和存活率，量化不确定性。迭代选择预期能改进帕累托前沿的实验配方，最大化不确定条件下的期望帕累托改进，并用新实验结果更新模型。

Result: 湿实验验证显示该方法高效发现同时实现高CPA浓度和高暴露后存活率的配方。相比朴素策略和强基线，分别提高支配超体积9.5%和4.5%，减少达到高质量解所需的实验次数。合成研究中仅需先前最先进多目标方法30%的评估次数即可获得相当强的帕累托最优解集，节省约10周实验时间。

Conclusion: 该框架仅需合适的检测方法和明确的配方空间，可适应不同的CPA库、目标定义和细胞系，加速冷冻保存技术的发展。

Abstract: Designing cryoprotectant agent (CPA) cocktails for vitrification is challenging because formulations must be concentrated enough to suppress ice formation yet non-toxic enough to preserve cell viability. This tradeoff creates a large, multi-objective design space in which traditional discovery is slow, often relying on expert intuition or exhaustive experimentation. We present a data-efficient framework that accelerates CPA cocktail design by combining high-throughput screening with an active-learning loop based on multi-objective Bayesian optimization. From an initial set of measured cocktails, we train probabilistic surrogate models to predict concentration and viability and quantify uncertainty across candidate formulations. We then iteratively select the next experiments by prioritizing cocktails expected to improve the Pareto front, maximizing expected Pareto improvement under uncertainty, and update the models as new assay results are collected. Wet-lab validation shows that our approach efficiently discovers cocktails that simultaneously achieve high CPA concentrations and high post-exposure viability. Relative to a naive strategy and a strong baseline, our method improves dominated hypervolume by 9.5\% and 4.5\%, respectively, while reducing the number of experiments needed to reach high-quality solutions. In complementary synthetic studies, it recovers a comparably strong set of Pareto-optimal solutions using only 30\% of the evaluations required by the prior state-of-the-art multi-objective approach, which amounts to saving approximately 10 weeks of experimental time. Because the framework assumes only a suitable assay and defined formulation space, it can be adapted to different CPA libraries, objective definitions, and cell lines to accelerate cryopreservation development.

</details>


### [8] [Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise](https://arxiv.org/abs/2602.13413)
*Yuchen Fang,James Demmel,Javad Lavaei*

Main category: cs.LG

TL;DR: 本文分析了在重尾噪声下随机预条件随机梯度下降（SPSGD）的最坏情况复杂度，发现归一化方法能保证收敛，而裁剪方法在最坏情况下可能失败，这解释了大规模模型训练中归一化优于裁剪的实证现象。


<details>
  <summary>Details</summary>
Motivation: 研究随机预条件随机梯度下降（如Adam、RMSProp、Shampoo等自适应方法）在重尾噪声下的最坏情况复杂度，解释为什么在实证中归一化比裁剪更受青睐。

Method: 开发了随机预条件随机梯度下降（SPSGD）及其加速变体的最坏情况复杂度理论，假设随机梯度噪声具有有限p阶矩（p∈(1,2]），并比较了归一化和裁剪两种稳定化方法。提出了一种新颖的向量值Burkholder型不等式来支持分析。

Result: 归一化方法在问题参数已知时收敛速率为O(T^{-(p-1)/(3p-2)})，参数未知时为O(T^{-(p-1)/(2p)})，匹配归一化SGD的最优速率。而裁剪方法在最坏情况下可能因随机预条件器与梯度估计之间的统计依赖而无法收敛。

Conclusion: 归一化能保证随机预条件SGD在重尾噪声下的收敛性，而裁剪在最坏情况下可能失败，这为大规模模型训练中归一化优于裁剪的实证偏好提供了理论解释。

Abstract: We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and Shampoo. We assume the stochastic gradient noise has a finite $p$-th moment for some $p \in (1,2]$, and measure convergence after $T$ iterations. While clipping and normalization are parallel tools for stabilizing training of SGD under heavy-tailed noise, there is a fundamental separation in their worst-case properties in stochastically preconditioned settings. We demonstrate that normalization guarantees convergence to a first-order stationary point at rate $\mathcal{O}(T^{-\frac{p-1}{3p-2}})$ when problem parameters are known, and $\mathcal{O}(T^{-\frac{p-1}{2p}})$ when problem parameters are unknown, matching the optimal rates for normalized SGD, respectively. In contrast, we prove that clipping may fail to converge in the worst case due to the statistical dependence between the stochastic preconditioner and the gradient estimates. To enable the analysis, we develop a novel vector-valued Burkholder-type inequality that may be of independent interest. These results provide a theoretical explanation for the empirical preference for normalization over clipping in large-scale model training.

</details>


### [9] [High-Resolution Climate Projections Using Diffusion-Based Downscaling of a Lightweight Climate Emulator](https://arxiv.org/abs/2602.13416)
*Haiwen Guan,Moein Darman,Dibyajyoti Chakraborty,Troy Arcomano,Ashesh Chattopadhyay,Romit Maulik*

Main category: cs.LG

TL;DR: 提出基于扩散模型的深度学习降尺度框架，将LUCIE气候模拟器的300km分辨率输出降尺度至25km，用于区域气候影响评估


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动气候模型存在长期不稳定性、气候漂移和计算成本高等问题。LUCIE气候模拟器虽然能准确再现长期统计特征，但其原生分辨率约300km，无法满足详细区域影响评估的需求

Method: 采用基于概率扩散的生成模型，结合条件采样和后验采样框架，将粗分辨率LUCIE输出降尺度至25km分辨率。模型在2000-2009年约14,000个ERA5时间步长上训练，在2010-2020年LUCIE预测上评估

Result: 模型能够保持LUCIE的粗粒度动力学特征，同时在约28km分辨率上生成精细尺度的气候统计特征。通过纬度平均RMSE、功率谱、概率密度函数和纬向风的第一经验正交函数等多种指标评估性能

Conclusion: 提出的深度学习降尺度框架成功解决了LUCIE气候模拟器分辨率不足的问题，能够在保持粗尺度动力学的同时生成高分辨率气候统计，为区域气候影响评估提供了有效工具

Abstract: The proliferation of data-driven models in weather and climate sciences has marked a significant paradigm shift, with advanced models demonstrating exceptional skill in medium-range forecasting. However, these models are often limited by long-term instabilities, climatological drift, and substantial computational costs during training and inference, restricting their broader application for climate studies. Addressing these limitations, Guan et al. (2024) introduced LUCIE, a lightweight, physically consistent climate emulator utilizing a Spherical Fourier Neural Operator (SFNO) architecture. This model is able to reproduce accurate long-term statistics including climatological mean and seasonal variability. However, LUCIE's native resolution (~300 km) is inadequate for detailed regional impact assessments. To overcome this limitation, we introduce a deep learning-based downscaling framework, leveraging probabilistic diffusion-based generative models with conditional and posterior sampling frameworks. These models downscale coarse LUCIE outputs to 25 km resolution. They are trained on approximately 14,000 ERA5 timesteps spanning 2000-2009 and evaluated on LUCIE predictions from 2010 to 2020. Model performance is assessed through diverse metrics, including latitude-averaged RMSE, power spectrum, probability density functions and First Empirical Orthogonal Function of the zonal wind. We observe that the proposed approach is able to preserve the coarse-grained dynamics from LUCIE while generating fine-scaled climatological statistics at ~28km resolution.

</details>


### [10] [Text Has Curvature](https://arxiv.org/abs/2602.13418)
*Karish Grover,Hanqing Zeng,Yinglong Xia,Christos Faloutsos,Geoffrey J. Gordon*

Main category: cs.LG

TL;DR: 该论文提出Texture——一种文本原生的离散曲率信号，证明语言具有内在曲率，定义曲率计算方法，并展示其在长文本推理和检索增强生成中的实用价值。


<details>
  <summary>Details</summary>
Motivation: 语言建模越来越多地使用弯曲几何（如双曲空间表示层次结构），但一个基本科学问题仍未解决：曲率对文本本身意味着什么？作者旨在探究语言是否具有内在曲率，而非仅仅是嵌入空间选择的产物。

Method: 提出Texture方法：通过调和左右上下文对掩码词的信念，使用Schrödinger桥计算曲率场。正曲率表示上下文聚焦意义，负曲率表示上下文发散为竞争性延续。

Result: 提供理论和经验证明自然语料库中的语义推理是非平坦的（语言具有内在曲率）。Texture作为通用测量和控制原语，在长文本推理中通过曲率引导压缩，在检索增强生成中通过曲率引导路由，提升了任务性能。

Conclusion: 文本确实具有曲率，Texture建立了文本原生曲率范式，使曲率可测量且具有实际用途，为语言几何分析提供了新视角。

Abstract: Does text have an intrinsic curvature? Language is increasingly modeled in curved geometries - hyperbolic spaces for hierarchy, mixed-curvature manifolds for compositional structure - yet a basic scientific question remains unresolved: what does curvature mean for text itself, in a way that is native to language rather than an artifact of the embedding space we choose? We argue that text does indeed have curvature, and show how to detect it, define it, and use it. To this end, we propose Texture, a text-native, word-level discrete curvature signal, and make three contributions. (a) Existence: We provide empirical and theoretical certificates that semantic inference in natural corpora is non-flat, i.e. language has inherent curvature. (b) Definition: We define Texture by reconciling left- and right-context beliefs around a masked word through a Schrodinger bridge, yielding a curvature field that is positive where context focuses meaning and negative where it fans out into competing continuations. (c) Utility: Texture is actionable: it serves as a general-purpose measurement and control primitive enabling geometry without geometric training; we instantiate it on two representative tasks, improving long-context inference through curvature-guided compression and retrieval-augmented generation through curvature-guided routing. Together, our results establish a text-native curvature paradigm, making curvature measurable and practically useful.

</details>


### [11] [Comparing Classifiers: A Case Study Using PyCM](https://arxiv.org/abs/2602.13482)
*Sadra Sabouri,Alireza Zolanvari,Sepand Haghighi*

Main category: cs.LG

TL;DR: PyCM库教程：展示如何通过多维度评估框架深入分析多分类器性能，强调标准指标可能忽略的细微性能权衡


<details>
  <summary>Details</summary>
Motivation: 选择最优分类模型需要全面理解模型性能，但标准评估指标可能无法揭示细微但重要的性能差异

Method: 使用PyCM库进行深入的多分类器评估，通过两个案例场景展示不同评估指标如何改变对模型效能的解释

Result: 评估指标的选择会从根本上改变对模型效能的解释，多维度评估框架能揭示标准指标可能忽略的细微性能权衡

Conclusion: 多维度评估框架对于发现模型性能中细微但重要的差异至关重要，标准指标可能无法捕捉这些细微的性能权衡

Abstract: Selecting an optimal classification model requires a robust and comprehensive understanding of the performance of the model. This paper provides a tutorial on the PyCM library, demonstrating its utility in conducting deep-dive evaluations of multi-class classifiers. By examining two different case scenarios, we illustrate how the choice of evaluation metrics can fundamentally shift the interpretation of a model's efficacy. Our findings emphasize that a multi-dimensional evaluation framework is essential for uncovering small but important differences in model performance. However, standard metrics may miss these subtle performance trade-offs.

</details>


### [12] [Finding Highly Interpretable Prompt-Specific Circuits in Language Models](https://arxiv.org/abs/2602.13483)
*Gabriel Franco,Lucas M. Tassis,Azalea Rohr,Mark Crovella*

Main category: cs.LG

TL;DR: 该研究挑战了传统电路分析假设每个任务有单一稳定机制的局限，提出电路是提示特定的，并开发了ACC++方法来提取更干净的因果信号，发现不同提示模板会诱导不同机制，但可聚类为提示家族，为每个家族提供代表性电路作为分析单元。


<details>
  <summary>Details</summary>
Motivation: 传统机制可解释性研究在任务层面识别电路，假设每个任务有单一稳定机制，但这种假设可能掩盖了电路结构的重要来源：即使在固定任务中，电路也是提示特定的。研究者希望揭示这种提示特异性，并开发更精确的方法来分析这种变化。

Method: 在注意力因果通信（ACC）基础上引入ACC++改进，从单次前向传播中提取更干净、更低维的注意力头内部因果信号，无需替换模型或激活修补。应用于GPT-2、Pythia和Gemma 2模型的间接宾语识别（IOI）任务，分析不同提示模板下的电路变化。

Result: 发现任何模型中都不存在IOI的单一电路：不同提示模板会系统性地诱导不同机制。尽管存在这种变化，提示可以聚类为具有相似电路的提示家族，并为每个家族提出代表性电路作为实用分析单元。开发了自动化可解释性流程，使用ACC++信号提取人类可解释特征并构建机制解释。

Conclusion: 研究通过将分析单元从任务转移到提示，重新定义了电路作为有意义的研究对象，使得在存在提示特定机制的情况下能够进行可扩展的电路描述。这为机制可解释性提供了更精细的分析框架。

Abstract: Understanding the internal circuits that language models use to solve tasks remains a central challenge in mechanistic interpretability. Most prior work identifies circuits at the task level by averaging across many prompts, implicitly assuming a single stable mechanism per task. We show that this assumption can obscure a crucial source of structure: circuits are prompt-specific, even within a fixed task. Building on attention causal communication (ACC) (Franco & Crovella, 2025), we introduce ACC++, refinements that extract cleaner, lower-dimensional causal signals inside attention heads from a single forward pass. Like ACC, our approach does not require replacement models (e.g., SAEs) or activation patching; ACC++ further improves circuit precision by reducing attribution noise. Applying ACC++ to indirect object identification (IOI) in GPT-2, Pythia, and Gemma 2, we find there is no single circuit for IOI in any model: different prompt templates induce systematically different mechanisms. Despite this variation, prompts cluster into prompt families with similar circuits, and we propose a representative circuit for each family as a practical unit of analysis. Finally, we develop an automated interpretability pipeline that uses ACC++ signals to surface human-interpretable features and assemble mechanistic explanations for prompt families behavior. Together, our results recast circuits as a meaningful object of study by shifting the unit of analysis from tasks to prompts, enabling scalable circuit descriptions in the presence of prompt-specific mechanisms.

</details>


### [13] [Federated Learning of Nonlinear Temporal Dynamics with Graph Attention-based Cross-Client Interpretability](https://arxiv.org/abs/2602.13485)
*Ayse Tursucular,Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 提出一个联邦学习框架，用于在分散式非线性系统中学习跨客户端的时间依赖性，同时保证隐私和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现代工业系统网络由分布式传感器监控，子系统相互依赖且生成高维时间序列数据。在分散式设置中，原始测量数据无法共享，客户端观测具有异质性，且每个子系统运行固定的专有模型无法修改或重新训练。非线性动态使得跨客户端时间依赖性难以解释。

Method: 每个客户端使用非线性状态空间模型将高维本地观测映射到低维潜在状态。中央服务器使用图注意力网络在通信的潜在状态上学习图结构化的神经状态转移模型。通过将学习到的服务器端转移模型的雅可比矩阵与注意力系数关联，提供可解释性。

Result: 建立了理论收敛保证，证明能收敛到集中式预言机。通过合成实验验证了收敛性、可解释性、可扩展性和隐私性。真实世界实验显示性能与分散式基线方法相当。

Conclusion: 该框架首次在分散式非线性系统中提供了跨客户端时间依赖性的可解释性表征，解决了工业系统中子系统相互依赖但数据隐私受限的挑战。

Abstract: Networks of modern industrial systems are increasingly monitored by distributed sensors, where each system comprises multiple subsystems generating high dimensional time series data. These subsystems are often interdependent, making it important to understand how temporal patterns at one subsystem relate to others. This is challenging in decentralized settings where raw measurements cannot be shared and client observations are heterogeneous. In practical deployments each subsystem (client) operates a fixed proprietary model that cannot be modified or retrained, limiting existing approaches. Nonlinear dynamics further make cross client temporal interdependencies difficult to interpret because they are embedded in nonlinear state transition functions. We present a federated framework for learning temporal interdependencies across clients under these constraints. Each client maps high dimensional local observations to low dimensional latent states using a nonlinear state space model. A central server learns a graph structured neural state transition model over the communicated latent states using a Graph Attention Network. For interpretability we relate the Jacobian of the learned server side transition model to attention coefficients, providing the first interpretable characterization of cross client temporal interdependencies in decentralized nonlinear systems. We establish theoretical convergence guarantees to a centralized oracle and validate the framework through synthetic experiments demonstrating convergence, interpretability, scalability and privacy. Additional real world experiments show performance comparable to decentralized baselines.

</details>


### [14] [Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity](https://arxiv.org/abs/2602.13486)
*Fei Wu,Jia Hu,Geyong Min,Shiqiang Wang*

Main category: cs.LG

TL;DR: 论文提出raFLoRA方法解决联邦低秩自适应中的秩崩溃问题，通过秩分区聚合提升异构联邦学习性能


<details>
  <summary>Details</summary>
Motivation: 在联邦低秩自适应中，客户端在系统资源和数据分布上的异构性导致需要不同的LoRA秩。作者发现异构FedLoRA中存在"秩崩溃"现象，即全局更新的能量集中在最小共享秩上，导致性能下降和对秩配置高度敏感

Method: 提出raFLoRA方法：将本地更新分解为秩分区，然后根据每个分区的有效客户端贡献加权聚合每个分区。通过秩分区聚合解决秩无关聚合权重与秩相关客户端贡献之间的不匹配问题

Result: 在分类和推理任务上的广泛实验表明，raFLoRA能够防止秩崩溃，提高模型性能，同时保持与最先进FedLoRA基线相当的通信效率

Conclusion: raFLoRA通过解决异构联邦低秩自适应中的秩崩溃问题，显著提升了模型性能，为实际联邦学习场景中的异构客户端提供了有效的解决方案

Abstract: Federated low-rank adaptation (FedLoRA) has facilitated communication-efficient and privacy-preserving fine-tuning of foundation models for downstream tasks. In practical federated learning scenarios, client heterogeneity in system resources and data distributions motivates heterogeneous LoRA ranks across clients. We identify a previously overlooked phenomenon in heterogeneous FedLoRA, termed rank collapse, where the energy of the global update concentrates on the minimum shared rank, resulting in suboptimal performance and high sensitivity to rank configurations. Through theoretical analysis, we reveal the root cause of rank collapse: a mismatch between rank-agnostic aggregation weights and rank-dependent client contributions, which systematically suppresses higher-rank updates at a geometric rate over rounds. Motivated by this insight, we propose raFLoRA, a rank-partitioned aggregation method that decomposes local updates into rank partitions and then aggregates each partition weighted by its effective client contributions. Extensive experiments across classification and reasoning tasks show that raFLoRA prevents rank collapse, improves model performance, and preserves communication efficiency compared to state-of-the-art FedLoRA baselines.

</details>


### [15] [TrasMuon: Trust-Region Adaptive Scaling for Orthogonalized Momentum Optimizers](https://arxiv.org/abs/2602.13498)
*Peng Cheng,Jiucheng Zang,Qingnan Li,Liheng Ma,Yufei Cui,Yingxue Zhang,Boxing Chen,Ming Jian,Wen Tong*

Main category: cs.LG

TL;DR: TrasMuon优化器在Muon的基础上引入全局RMS校准和基于能量的信任区域裁剪，既保持了近等距几何特性，又通过稳定更新幅度解决了训练敏感性和高能量爆发问题。


<details>
  <summary>Details</summary>
Motivation: Muon系列优化器使用Newton-Schulz迭代正交化更新，虽然几何特性优于Adam系列方法，但正交化过程丢弃了幅度信息，导致训练对步长超参数敏感且容易产生高能量爆发。

Method: TrasMuon在保持Muon近等距几何特性的同时，通过两种机制稳定更新幅度：(1) 全局RMS校准，(2) 基于相对能量比定义信任区域并进行裁剪，将更新限制在稳定区域内。

Result: 在视觉和语言模型上的实验表明，TrasMuon比基线方法收敛更快。在没有预热阶段的实验中，TrasMuon展现出更好的稳定性和鲁棒性。

Conclusion: TrasMuon通过结合自适应缩放和信任区域机制，成功解决了Muon优化器的稳定性问题，在保持几何优势的同时实现了更稳定高效的优化。

Abstract: Muon-style optimizers leverage Newton-Schulz (NS) iterations to orthogonalize updates, yielding update geometries that often outperform Adam-series methods. However, this orthogonalization discards magnitude information, rendering training sensitive to step-size hyperparameters and vulnerable to high-energy bursts. To mitigate this, we introduce TrasMuon (\textbf{T}rust \textbf{R}egion \textbf{A}daptive \textbf{S}caling \textbf{Muon}). TrasMuon preserves the near-isometric geometry of Muon while stabilizing magnitudes through (i) global RMS calibration and (ii) energy-based trust-region clipping. We demonstrate that while reintroducing adaptive scaling improves optimization efficiency, it typically exacerbates instability due to high-energy outliers. TrasMuon addresses this by defining a trust region based on relative energy ratios, confining updates to a stable zone. Empirical experiments on vision and language models demonstrate that TrasMuon converges faster than baselines. Furthermore, experiments without warmup stages confirm TrasMuon's superior stability and robustness.

</details>


### [16] [$γ$-weakly $θ$-up-concavity: Linearizable Non-Convex Optimization with Applications to DR-Submodular and OSS Functions](https://arxiv.org/abs/2602.13506)
*Mohammad Pedramfar,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 该论文提出了一种新的函数类——γ-弱θ-上凹函数，它统一了DR-子模函数和单边光滑函数，并证明了这类函数具有上线性化性质，从而为单调非凸优化问题提供了统一的近似保证。


<details>
  <summary>Details</summary>
Motivation: 单调非凸函数优化是机器学习和组合优化中的基本挑战。现有研究主要关注DR-子模函数和单边光滑函数等特定类别，缺乏一个统一的框架来理解和优化更广泛的单调非凸函数。

Method: 引入γ-弱θ-上凹性这一新的函数类，它严格推广了DR-子模函数和单边光滑函数。核心理论贡献是证明了这类函数具有上线性化性质：对于任意可行点，可以构造一个线性替代函数，其增益能够以常数因子近似原始非线性目标。

Result: 该框架为离线优化提供了统一的近似保证，并为在线设置中的静态和动态遗憾界提供了标准约简到线性优化的方法。特别地，恢复了DR-子模最大化的最优近似系数，并显著改进了OSS优化（特别是拟阵约束下）的现有近似系数。

Conclusion: γ-弱θ-上凹函数提供了一个强大的统一框架，能够处理广泛的单调非凸优化问题。通过上线性化技术，该框架为离线优化和在线优化提供了统一的近似保证，并改进了现有特定函数类的近似结果。

Abstract: Optimizing monotone non-convex functions is a fundamental challenge across machine learning and combinatorial optimization. We introduce and study $γ$-weakly $θ$-up-concavity, a novel first-order condition that characterizes a broad class of such functions. This condition provides a powerful unifying framework, strictly generalizing both DR-submodular functions and One-Sided Smooth (OSS) functions. Our central theoretical contribution demonstrates that $γ$-weakly $θ$-up-concave functions are upper-linearizable: for any feasible point, we can construct a linear surrogate whose gains provably approximate the original non-linear objective. This approximation holds up to a constant factor, namely the approximation coefficient, dependent solely on $γ$, $θ$, and the geometry of the feasible set. This linearizability yields immediate and unified approximation guarantees for a wide range of problems. Specifically, we obtain unified approximation guarantees for offline optimization as well as static and dynamic regret bounds in online settings via standard reductions to linear optimization. Moreover, our framework recovers the optimal approximation coefficient for DR-submodular maximization and significantly improves existing approximation coefficients for OSS optimization, particularly over matroid constraints.

</details>


### [17] [Singular Vectors of Attention Heads Align with Features](https://arxiv.org/abs/2602.13524)
*Gabriel Franco,Carson Loughridge,Mark Crovella*

Main category: cs.LG

TL;DR: 论文研究了注意力矩阵奇异向量与特征表示对齐的理论基础，证明了在特定条件下这种对齐是合理的，并提出了可操作的验证方法。


<details>
  <summary>Details</summary>
Motivation: 近期研究隐含假设注意力矩阵的奇异向量可以推断特征表示，但缺乏理论依据。本文旨在探究奇异向量何时以及为何能与特征对齐，为特征识别提供理论基础。

Method: 1) 在可直接观察特征的模型中验证奇异向量与特征的对齐；2) 理论分析对齐发生的条件；3) 提出稀疏注意力分解作为可操作的验证方法，并在真实模型中测试。

Result: 奇异向量在可观察特征的模型中确实与特征对齐；理论分析表明在一定条件下这种对齐是预期的；稀疏注意力分解在真实模型中以符合预测的方式出现。

Conclusion: 奇异向量与特征的对齐可以作为语言模型中特征识别的合理且理论上有依据的基础，为机制可解释性提供了更可靠的方法。

Abstract: Identifying feature representations in language models is a central task in mechanistic interpretability. Several recent studies have made an implicit assumption that feature representations can be inferred in some cases from singular vectors of attention matrices. However, sound justification for this assumption is lacking. In this paper we address that question, asking: why and when do singular vectors align with features? First, we demonstrate that singular vectors robustly align with features in a model where features can be directly observed. We then show theoretically that such alignment is expected under a range of conditions. We close by asking how, operationally, alignment may be recognized in real models where feature representations are not directly observable. We identify sparse attention decomposition as a testable prediction of alignment, and show evidence that it emerges in a manner consistent with predictions in real models. Together these results suggest that alignment of singular vectors with features can be a sound and theoretically justified basis for feature identification in language models.

</details>


### [18] [QuaRK: A Quantum Reservoir Kernel for Time Series Learning](https://arxiv.org/abs/2602.13531)
*Abdallah Aaraba,Soumaya Cherkaoui,Ola Ahmad,Shengrui Wang*

Main category: cs.LG

TL;DR: QuaRK框架结合硬件可实现的量子储层与核基读出方案，用于时间序列学习，提供学习理论保证和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子储层计算为时间序列学习提供了有前景的途径，但现有研究缺乏高效、可实现的量子储层架构以及模型学习保证。

Method: 提出QuaRK端到端框架：1）硬件现实的量子储层特征提取器，使用经典阴影层析高效测量k-局部可观测量；2）核基读出方案，通过显式正则化和快速优化学习目标映射。

Result: 框架提供清晰的计算参数（电路宽度、深度、测量预算），保持核方法建模非线性时间泛函的灵活性，可扩展到高维数据，并为依赖时间数据提供泛化保证。

Conclusion: QuaRK通过结合量子储层特征提取和核基学习，为构建可靠的时间序列学习器提供原则性指导，实验验证了其插值和泛化行为。

Abstract: Quantum reservoir computing offers a promising route for time series learning by modelling sequential data via rich quantum dynamics while the only training required happens at the level of a lightweight classical readout. However, studies featuring efficient and implementable quantum reservoir architectures along with model learning guarantees remain scarce in the literature. To close this gap, we introduce QuaRK, an end-to-end framework that couples a hardware-realistic quantum reservoir featurizer with a kernel-based readout scheme. Given a sequence of sample points, the reservoir injects the points one after the other to yield a compact feature vector from efficiently measured k-local observables using classical shadow tomography, after which a classical kernel-based readout learns the target mapping with explicit regularization and fast optimization. The resulting pipeline exposes clear computational knobs -- circuit width and depth as well as the measurement budget -- while preserving the flexibility of kernel methods to model nonlinear temporal functionals and being scalable to high-dimensional data. We further provide learning-theoretic generalization guarantees for dependent temporal data, linking design and resource choices to finite-sample performance, thereby offering principled guidance for building reliable temporal learners. Empirical experiments validate QuaRK and illustrate the predicted interpolation and generalization behaviours on synthetic beta-mixing time series tasks.

</details>


### [19] [Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction](https://arxiv.org/abs/2602.13532)
*Nobutaka Ono*

Main category: cs.LG

TL;DR: 提出一种快速元素选择算法，作为无乘法的降维方法，通过选择输入元素的子集实现降维，避免矩阵乘法瓶颈


<details>
  <summary>Details</summary>
Motivation: 传统降维方法如PCA依赖矩阵乘法，在资源受限系统中乘法计算本身可能成为瓶颈。需要一种无乘法的降维方法，通过简单选择元素子集来减少计算开销

Method: 使用基于最小均方误差的线性回归评估候选子集，预测目标向量。通过矩阵求逆引理推导元素交换对目标函数的影响公式，采用基于交换的局部搜索算法，反复应用目标函数减少的交换直到无法改进

Result: 在MNIST手写数字图像数据集上的实验证明了该方法的有效性

Conclusion: 提出的元素选择算法提供了一种无乘法的降维方法，在资源受限系统中能够有效减少计算开销，同时保持降维效果

Abstract: In this paper, we propose a fast algorithm for element selection, a multiplication-free form of dimension reduction that produces a dimension-reduced vector by simply selecting a subset of elements from the input. Dimension reduction is a fundamental technique for reducing unnecessary model parameters, mitigating overfitting, and accelerating training and inference. A standard approach is principal component analysis (PCA), but PCA relies on matrix multiplications; on resource-constrained systems, the multiplication count itself can become a bottleneck. Element selection eliminates this cost because the reduction consists only of selecting elements, and thus the key challenge is to determine which elements should be retained. We evaluate a candidate subset through the minimum mean-squared error of linear regression that predicts a target vector from the selected elements, where the target may be, for example, a one-hot label vector in classification. When an explicit target is unavailable, the input itself can be used as the target, yielding a reconstruction-based criterion. The resulting optimization is combinatorial, and exhaustive search is impractical. To address this, we derive an efficient formula for the objective change caused by swapping a selected and an unselected element, using the matrix inversion lemma, and we perform a swap-based local search that repeatedly applies objective-decreasing swaps until no further improvement is possible. Experiments on MNIST handwritten-digit images demonstrate the effectiveness of the proposed method.

</details>


### [20] [Out-of-Support Generalisation via Weight Space Sequence Modelling](https://arxiv.org/abs/2602.13550)
*Roussel Desmond Nzoyem*

Main category: cs.LG

TL;DR: WeightCaster框架将分布外泛化问题重构为权重空间的序列建模任务，通过将训练集划分为同心壳层作为离散序列步骤，实现可解释、不确定性感知的预测，无需显式归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在训练集范围外的数据点（分布外样本）上经常表现出灾难性失败，产生不现实但过度自信的预测，这限制了AI在安全关键应用中的广泛采用。

Method: 将分布外泛化问题重构为权重空间的序列建模任务，将训练集划分为同心壳层对应离散序列步骤，提出WeightCaster框架，实现高效计算。

Result: 在合成余弦数据集和真实空气质量传感器读数上的实证验证显示，性能达到或优于最先进方法，产生合理、可解释且不确定性感知的预测。

Conclusion: 通过增强分布外场景的可靠性，这些结果对人工智能在安全关键应用中的更广泛采用具有重要意义，WeightCaster框架为分布外泛化提供了有效的解决方案。

Abstract: As breakthroughs in deep learning transform key industries, models are increasingly required to extrapolate on datapoints found outside the range of the training set, a challenge we coin as out-of-support (OoS) generalisation. However, neural networks frequently exhibit catastrophic failure on OoS samples, yielding unrealistic but overconfident predictions. We address this challenge by reformulating the OoS generalisation problem as a sequence modelling task in the weight space, wherein the training set is partitioned into concentric shells corresponding to discrete sequential steps. Our WeightCaster framework yields plausible, interpretable, and uncertainty-aware predictions without necessitating explicit inductive biases, all the while maintaining high computational efficiency. Emprical validation on a synthetic cosine dataset and real-world air quality sensor readings demonstrates performance competitive or superior to the state-of-the-art. By enhancing reliability beyond in-distribution scenarios, these results hold significant implications for the wider adoption of artificial intelligence in safety-critical applications.

</details>


### [21] [Scenario-Adaptive MU-MIMO OFDM Semantic Communication With Asymmetric Neural Network](https://arxiv.org/abs/2602.13557)
*Chongyang Li,Tianqian Zhang,Shouyin Liu*

Main category: cs.LG

TL;DR: 提出一种面向6G下行MU-MIMO OFDM系统的场景自适应语义通信框架，通过CSI/SNR感知的语义编码和神经预编码抑制多用户干扰，在接收端使用导频引导注意力机制进行隐式信道均衡，显著提升低信噪比下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度联合信源信道编码方案主要针对点对点链路设计，在多用户场景下性能饱和。将语义通信应用于实际的下行MU-MIMO OFDM系统面临严重多用户干扰和频率选择性衰落的挑战。

Method: 提出非对称架构的下行MU-MIMO语义通信框架：发射端包含场景感知语义编码器（根据CSI和SNR动态调整特征提取）和神经预编码网络（在语义域抑制多用户干扰）；接收端采用轻量级解码器，配备导频引导注意力机制，利用参考导频符号隐式执行信道均衡和特征校准。

Result: 在3GPP信道模型上的大量仿真结果表明，所提框架在峰值信噪比和分类准确率方面显著优于深度联合信源信道编码和传统分离信源信道编码方案，特别是在低信噪比区域，同时保持边缘设备的低延迟和低计算成本。

Conclusion: 该场景自适应MU-MIMO语义通信框架成功解决了多用户干扰和频率选择性衰落问题，为6G网络中实际多用户语义通信系统提供了有效的解决方案，在保持边缘设备效率的同时显著提升性能。

Abstract: Semantic Communication (SemCom) has emerged as a promising paradigm for 6G networks, aiming to extract and transmit task-relevant information rather than minimizing bit errors. However, applying SemCom to realistic downlink Multi-User Multi-Input Multi-Output (MU-MIMO) Orthogonal Frequency Division Multiplexing (OFDM) systems remains challenging due to severe Multi-User Interference (MUI) and frequency-selective fading. Existing Deep Joint Source-Channel Coding (DJSCC) schemes, primarily designed for point-to-point links, suffer from performance saturation in multi-user scenarios. To address these issues, we propose a scenario-adaptive MU-MIMO SemCom framework featuring an asymmetric architecture tailored for downlink transmission. At the transmitter, we introduce a scenario-aware semantic encoder that dynamically adjusts feature extraction based on Channel State Information (CSI) and Signal-to-Noise Ratio (SNR), followed by a neural precoding network designed to mitigate MUI in the semantic domain. At the receiver, a lightweight decoder equipped with a novel pilot-guided attention mechanism is employed to implicitly perform channel equalization and feature calibration using reference pilot symbols. Extensive simulation results over 3GPP channel models demonstrate that the proposed framework significantly outperforms DJSCC and traditional Separate Source-Channel Coding (SSCC) schemes in terms of Peak Signal-to-Noise Ratio (PSNR) and classification accuracy, particularly in low-SNR regimes, while maintaining low latency and computational cost on edge devices.

</details>


### [22] [Interpretable clustering via optimal multiway-split decision trees](https://arxiv.org/abs/2602.13586)
*Hayato Suzuki,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: 提出基于最优多路分割决策树的解释性聚类方法，通过0-1整数线性规划优化，结合一维K-means离散化连续变量，在聚类精度和可解释性上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法通常构建二叉决策树，需要解决混合整数非线性优化问题，计算成本高且易得次优解。同时，二叉决策树往往过深，难以解释。需要开发更高效、更可解释的聚类方法。

Method: 提出基于最优多路分割决策树的解释性聚类方法，将问题重新表述为0-1整数线性优化问题，使优化更易处理。关键创新是集成一维K-means算法对连续变量进行离散化，实现灵活、数据驱动的分支。

Result: 在公开真实数据集上的大量数值实验表明，该方法在聚类精度和可解释性方面优于基线方法。能够生成具有简洁决策规则的多路分割决策树，同时在各种评估指标上保持竞争力。

Conclusion: 该方法通过将聚类问题重新表述为0-1整数线性优化，结合一维K-means离散化，实现了更高效、更可解释的聚类。多路分割决策树相比传统二叉决策树具有更好的可解释性和性能。

Abstract: Clustering serves as a vital tool for uncovering latent data structures, and achieving both high accuracy and interpretability is essential. To this end, existing methods typically construct binary decision trees by solving mixed-integer nonlinear optimization problems, often leading to significant computational costs and suboptimal solutions. Furthermore, binary decision trees frequently result in excessively deep structures, which makes them difficult to interpret. To mitigate these issues, we propose an interpretable clustering method based on optimal multiway-split decision trees, formulated as a 0-1 integer linear optimization problem. This reformulation renders the optimization problem more tractable compared to existing models. A key feature of our method is the integration of a one-dimensional K-means algorithm for the discretization of continuous variables, allowing for flexible and data-driven branching. Extensive numerical experiments on publicly available real-world datasets demonstrate that our method outperforms baseline methods in terms of clustering accuracy and interpretability. Our method yields multiway-split decision trees with concise decision rules while maintaining competitive performance across various evaluation metrics.

</details>


### [23] [Benchmark Leakage Trap: Can We Trust LLM-based Recommendation?](https://arxiv.org/abs/2602.13626)
*Mingqiao Zhang,Qiyao Peng,Yumeng Wang,Chunyuan Liu,Hongtao Liu*

Main category: cs.LG

TL;DR: LLM推荐系统中存在基准数据泄露问题，当LLM在预训练或微调时接触并记忆基准数据集时，会导致性能指标虚假膨胀，无法反映真实模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在推荐系统中的广泛应用，评估可靠性面临严峻挑战。本文发现并研究了一个先前被忽视的问题：基于LLM的推荐系统中的基准数据泄露现象。

Method: 通过在不同领域（领域相关和领域无关）的战略性混合语料库上对基础模型进行持续预训练，模拟多样化的数据泄露场景。

Result: 数据泄露具有双重效应：当泄露数据与领域相关时，会导致显著但虚假的性能提升，误导性地夸大模型能力；而领域无关的泄露通常会降低推荐准确性，揭示了这种污染的复杂性和条件性。

Conclusion: 数据泄露是基于LLM推荐系统中一个关键且先前未被考虑的因素，可能影响真实模型性能。作者发布了相关代码供进一步研究。

Abstract: The expanding integration of Large Language Models (LLMs) into recommender systems poses critical challenges to evaluation reliability. This paper identifies and investigates a previously overlooked issue: benchmark data leakage in LLM-based recommendation. This phenomenon occurs when LLMs are exposed to and potentially memorize benchmark datasets during pre-training or fine-tuning, leading to artificially inflated performance metrics that fail to reflect true model performance. To validate this phenomenon, we simulate diverse data leakage scenarios by conducting continued pre-training of foundation models on strategically blended corpora, which include user-item interactions from both in-domain and out-of-domain sources. Our experiments reveal a dual-effect of data leakage: when the leaked data is domain-relevant, it induces substantial but spurious performance gains, misleadingly exaggerating the model's capability. In contrast, domain-irrelevant leakage typically degrades recommendation accuracy, highlighting the complex and contingent nature of this contamination. Our findings reveal that data leakage acts as a critical, previously unaccounted-for factor in LLM-based recommendation, which could impact the true model performance. We release our code at https://github.com/yusba1/LLMRec-Data-Leakage.

</details>


### [24] [Optimization-Free Graph Embedding via Distributional Kernel for Community Detection](https://arxiv.org/abs/2602.13634)
*Shuaibin Song,Kai Ming Ting,Kaifeng Zhang,Tianrun Liang*

Main category: cs.LG

TL;DR: 本文提出一种考虑节点分布和节点度分布特征的加权分布感知核，解决NAS方法中的过平滑问题，无需优化即可提升图嵌入表达力。


<details>
  <summary>Details</summary>
Motivation: 现有基于邻域聚合策略（NAS）的图嵌入方法（如GNN和WL方法）容易出现过平滑问题，即随着迭代次数增加，节点可区分性下降。作者发现节点分布和节点度分布这两个关键特征在现有方法中被忽视，而这些特征对过平滑有重要影响。

Method: 提出一种新颖的加权分布感知核，在嵌入节点时考虑节点的分布特征。该方法有三个特点：1）首次明确结合两种分布特征；2）无需优化过程；3）有效缓解过平滑的负面影响，使WL方法即使在多次迭代后仍能保持节点可区分性和表达力。

Result: 实验表明，通过谱聚类进行社区检测时，该方法优于现有的图嵌入方法（包括深度学习方法），在标准基准测试中取得了优越性能。

Conclusion: 通过考虑节点分布和节点度分布特征，提出的加权分布感知核能有效解决NAS方法的过平滑问题，提升图嵌入的表达能力，且无需复杂的优化过程。

Abstract: Neighborhood Aggregation Strategy (NAS) is a widely used approach in graph embedding, underpinning both Graph Neural Networks (GNNs) and Weisfeiler-Lehman (WL) methods. However, NAS-based methods are identified to be prone to over-smoothing-the loss of node distinguishability with increased iterations-thereby limiting their effectiveness. This paper identifies two characteristics in a network, i.e., the distributions of nodes and node degrees that are critical for expressive representation but have been overlooked in existing methods. We show that these overlooked characteristics contribute significantly to over-smoothing of NAS-methods. To address this, we propose a novel weighted distribution-aware kernel that embeds nodes while taking their distributional characteristics into consideration. Our method has three distinguishing features: (1) it is the first method to explicitly incorporate both distributional characteristics; (2) it requires no optimization; and (3) it effectively mitigates the adverse effects of over-smoothing, allowing WL to preserve node distinguishability and expressiveness even after many iterations of embedding. Experiments demonstrate that our method achieves superior community detection performance via spectral clustering, outperforming existing graph embedding methods, including deep learning methods, on standard benchmarks.

</details>


### [25] [Joint Time Series Chain: Detecting Unusual Evolving Trend across Time Series](https://arxiv.org/abs/2602.13649)
*Li Zhang,Nital Patel,Xiuqi Li,Jessica Lin*

Main category: cs.LG

TL;DR: 提出联合时间序列链(Joint TSC)新定义，用于在中断时间序列或两个相关时间序列中发现意外演化趋势，解决现有TSC只能处理单一连续时间序列的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列链(TSC)定义仅能在单一连续时间序列中发现演化模式，容易错过中断时间序列中的意外演化模式，或无法捕捉两个相关时间序列间的演化趋势。需要新方法来处理时间序列中断或跨序列的演化模式发现。

Method: 提出联合时间序列链新定义，专门设计用于在中断时间序列或两个相关时间序列中发现意外演化趋势。重点解决时间序列中断或间隔带来的鲁棒性问题，并提出有效的排序标准来识别最佳链。

Result: 通过大量实证评估证明，所提方法在定位异常演化模式方面优于现有TSC工作。在英特尔的实际制造应用中展示了方法的实用性。

Conclusion: 联合时间序列链定义能有效发现中断时间序列或相关时间序列间的意外演化趋势，解决了现有方法的局限性，具有实际应用价值。

Abstract: Time series chain (TSC) is a recently introduced concept that captures the evolving patterns in large scale time series. Informally, a time series chain is a temporally ordered set of subsequences, in which consecutive subsequences in the chain are similar to one another, but the last and the first subsequences maybe be dissimilar. Time series chain has the great potential to reveal latent unusual evolving trend in the time series, or identify precursor of important events in a complex system. Unfortunately, existing definitions of time series chains only consider finding chains in a single time series. As a result, they are likely to miss unexpected evolving patterns in interrupted time series, or across two related time series. To address this limitation, in this work, we introduce a new definition called \textit{Joint Time Series Chain}, which is specially designed for the task of finding unexpected evolving trend across interrupted time series or two related time series. Our definition focuses on mitigating the robustness issues caused by the gap or interruption in the time series. We further propose an effective ranking criterion to identify the best chain. We demonstrate that our proposed approach outperforms existing TSC work in locating unusual evolving patterns through extensive empirical evaluations. We further demonstrate the utility of our work with a real-life manufacturing application from Intel. Our source code is publicly available at the supporting page https://github.com/lizhang-ts/JointTSC .

</details>


### [26] [Cumulative Utility Parity for Fair Federated Learning under Intermittent Client Participation](https://arxiv.org/abs/2602.13651)
*Stefan Behfar,Richard Mortier*

Main category: cs.LG

TL;DR: 提出累积效用均等原则，解决联邦学习中因客户端参与不均导致的长期代表性偏差问题，而非仅关注每轮训练的公平性。


<details>
  <summary>Details</summary>
Motivation: 现实联邦学习系统中，客户端参与是间歇性、异质性的，且常与数据特征或资源约束相关。现有公平性方法主要关注参与条件下的损失或准确率均等，隐含假设客户端有可比的机会随时间贡献。但当参与本身不均时，这些目标会导致间歇可用客户端系统性代表性不足，即使每轮性能看似公平。

Method: 提出累积效用均等原则，评估客户端是否获得可比的长期收益（按参与机会而非训练轮次）。引入可用性归一化累积效用，将不可避免的物理约束与调度和聚合产生的可避免算法偏差分离。

Result: 在时间偏斜、非独立同分布的联邦基准测试中，该方法显著改善了长期代表性均等，同时保持近乎完美的性能。

Conclusion: 需要超越传统每轮公平性指标，考虑长期参与机会的公平性，提出的累积效用均等方法能有效解决间歇参与客户端代表性不足问题。

Abstract: In real-world federated learning (FL) systems, client participation is intermittent, heterogeneous, and often correlated with data characteristics or resource constraints. Existing fairness approaches in FL primarily focus on equalizing loss or accuracy conditional on participation, implicitly assuming that clients have comparable opportunities to contribute over time. However, when participation itself is uneven, these objectives can lead to systematic under-representation of intermittently available clients, even if per-round performance appears fair. We propose cumulative utility parity, a fairness principle that evaluates whether clients receive comparable long-term benefit per participation opportunity, rather than per training round. To operationalize this notion, we introduce availability-normalized cumulative utility, which disentangles unavoidable physical constraints from avoidable algorithmic bias arising from scheduling and aggregation. Experiments on temporally skewed, non-IID federated benchmarks demonstrate that our approach substantially improves long-term representation parity, while maintaining near-perfect performance.

</details>


### [27] [Zero-Order Optimization for LLM Fine-Tuning via Learnable Direction Sampling](https://arxiv.org/abs/2602.13659)
*Valery Parfenov,Grigoriy Evseev,Andrey Veprikov,Nikolay Bushkov,Stanislav Moiseev,Aleksandr Beznosikov*

Main category: cs.LG

TL;DR: 提出一种基于策略学习的零阶优化框架，通过可学习的扰动方向采样分布降低梯度估计方差，改善大语言模型微调中的内存效率问题


<details>
  <summary>Details</summary>
Motivation: 传统零阶优化方法虽然能避免反向传播的内存开销，但存在高方差和对参数维度依赖严重的问题，限制了其在大规模语言模型微调中的应用

Method: 将扰动方向采样分布视为可学习策略，通过更新该策略来降低方向估计的方差，开发了实用算法并提供了理论分析

Result: 在具有挑战性的大语言模型微调基准测试中，相比标准零阶基线方法，性能显著提升，收敛界限对参数维度的依赖得到缓解

Conclusion: 自适应方向采样是使零阶优化在大规模微调中可行的有前景路径，为资源受限环境下的语言模型部署提供了新思路

Abstract: Fine-tuning large pretrained language models (LLMs) is a cornerstone of modern NLP, yet its growing memory demands (driven by backpropagation and large optimizer States) limit deployment in resource-constrained settings. Zero-order (ZO) methods bypass backpropagation by estimating directional derivatives from forward evaluations, offering substantial memory savings. However, classical ZO estimators suffer from high variance and an adverse dependence on the parameter dimensionality $d$, which has constrained their use to low-dimensional problems. In this work, we propose a policy-driven ZO framework that treats the sampling distribution over perturbation directions as a learnable policy and updates it to reduce the variance of directional estimates. We develop a practical algorithm implementing this idea and provide a theoretical analysis, showing that learned sampling distributions improve the quality of gradient information and relax the explicit dependence on $d$ in convergence bounds. Empirically, we validate the approach on challenging LLM fine-tuning benchmarks, demonstrating substantially improved performance compared to standard ZO baselines. Our results suggest that adaptive direction sampling is a promising route to make ZO fine-tuning viable at scale. The source code is available at https://github.com/brain-lab-research/zo_ldsd

</details>


### [28] [Optimized Certainty Equivalent Risk-Controlling Prediction Sets](https://arxiv.org/abs/2602.13660)
*Jiayi Huang,Amirmohammad Farzaneh,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 本文提出OCE-RCPS框架，为医学图像分割等安全关键应用提供基于优化确定性等价风险度量的高概率保证，超越传统风险控制预测集。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分割等安全关键应用中，传统风险控制预测集仅提供期望风险的概率保证，无法捕捉尾部行为和最坏情况。需要一种能提供更严格风险保证的框架。

Method: 提出优化确定性等价风险控制预测集框架，利用置信上界识别满足用户指定风险容忍水平的预测集参数，支持条件风险价值、熵风险等多种风险度量。

Result: 理论证明OCE-RCPS对误覆盖率和假阴性率等损失函数满足所需概率约束。图像分割实验显示OCE-RCPS在各种风险度量和可靠性配置下始终达到目标满足率，而OCE-CRC无法提供概率保证。

Conclusion: OCE-RCPS为安全关键应用提供了超越传统期望风险控制的严格风险保证框架，能有效处理尾部风险和最坏情况。

Abstract: In safety-critical applications such as medical image segmentation, prediction systems must provide reliability guarantees that extend beyond conventional expected loss control. While risk-controlling prediction sets (RCPS) offer probabilistic guarantees on the expected risk, they fail to capture tail behavior and worst-case scenarios that are crucial in high-stakes settings. This paper introduces optimized certainty equivalent RCPS (OCE-RCPS), a novel framework that provides high-probability guarantees on general optimized certainty equivalent (OCE) risk measures, including conditional value-at-risk (CVaR) and entropic risk. OCE-RCPS leverages upper confidence bounds to identify prediction set parameters that satisfy user-specified risk tolerance levels with provable reliability. We establish theoretical guarantees showing that OCE-RCPS satisfies the desired probabilistic constraint for loss functions such as miscoverage and false negative rate. Experiments on image segmentation demonstrate that OCE-RCPS consistently meets target satisfaction rates across various risk measures and reliability configurations, while OCE-CRC fails to provide probabilistic guarantees.

</details>


### [29] [ALMo: Interactive Aim-Limit-Defined, Multi-Objective System for Personalized High-Dose-Rate Brachytherapy Treatment Planning and Visualization for Cervical Cancer](https://arxiv.org/abs/2602.13666)
*Edward Chen,Natalie Dullerud,Pang Wei Koh,Thomas Niedermayr,Elizabeth Kidd,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: ALMo系统通过直观的"目标-限制"阈值交互界面，帮助临床医生在宫颈癌高剂量率近距离放疗中高效制定个性化治疗计划，在保证质量的同时显著缩短规划时间。


<details>
  <summary>Details</summary>
Motivation: 临床决策中需要同时追踪多个竞争性指标（目标阈值和限制阈值），处理这些高维权衡关系对医生认知要求高且容易产生变异性。特别是在宫颈癌高剂量率近距离放疗中，需要在严格控制辐射热点同时平衡肿瘤覆盖和器官保护。

Method: 提出ALMo（目标-限制定义的多目标系统），采用新颖的优化框架，通过自动化参数设置减少手动输入，允许医生通过直接操作直观的目标和限制值来导航帕累托前沿的剂量权衡关系。

Result: 在25个临床病例的回顾性评估中，ALMo生成的治疗计划质量始终达到或超过手动规划，65%的病例显示出剂量学改进。系统显著提高效率，平均规划时间缩短至约17分钟（传统方法需要30-60分钟）。

Conclusion: ALMo在近距离放疗中得到验证，展示了一个通用的框架，可用于简化多标准临床决策中的交互过程，帮助医生更高效地制定个性化治疗方案。

Abstract: In complex clinical decision-making, clinicians must often track a variety of competing metrics defined by aim (ideal) and limit (strict) thresholds. Sifting through these high-dimensional tradeoffs to infer the optimal patient-specific strategy is cognitively demanding and historically prone to variability. In this paper, we address this challenge within the context of High-Dose-Rate (HDR) brachytherapy for cervical cancer, where planning requires strictly managing radiation hot spots while balancing tumor coverage against organ sparing. We present ALMo (Aim-Limit-defined Multi-Objective system), an interactive decision support system designed to infer and operationalize clinician intent. ALMo employs a novel optimization framework that minimizes manual input through automated parameter setup and enables flexible control over toxicity risks. Crucially, the system allows clinicians to navigate the Pareto surface of dosimetric tradeoffs by directly manipulating intuitive aim and limit values. In a retrospective evaluation of 25 clinical cases, ALMo generated treatment plans that consistently met or exceeded manual planning quality, with 65% of cases demonstrating dosimetric improvements. Furthermore, the system significantly enhanced efficiency, reducing average planning time to approximately 17 minutes, compared to the conventional 30-60 minutes. While validated in brachytherapy, ALMo demonstrates a generalized framework for streamlining interaction in multi-criteria clinical decision-making.

</details>


### [30] [Advancing Analytic Class-Incremental Learning through Vision-Language Calibration](https://arxiv.org/abs/2602.13670)
*Binyu Zhao,Wei Zhang,Xingrui Yu,Zhaonian Zou,Ivor Tsang*

Main category: cs.LG

TL;DR: VILA提出双分支视觉语言校准框架，通过特征级几何校准和决策级跨模态先验，解决预训练模型在类增量学习中表示刚性问题，保持解析学习效率的同时提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在类增量学习中面临快速适应与长期稳定性的权衡。解析学习虽然能实现快速递归闭式更新，但存在累积误差和特征不兼容问题。研究发现表示刚性是主要瓶颈，需要克服解析学习的脆弱性。

Method: 提出VILA双分支框架：1) 特征级几何校准，融合可塑性任务适应特征与冻结的通用语义锚点；2) 决策级跨模态先验，利用视觉语言先验纠正预测偏差。保持解析学习效率的同时增强鲁棒性。

Result: 在8个基准测试中，VILA始终表现优异，特别是在细粒度和长序列场景下。框架实现了高保真预测与解析学习简洁性的平衡。

Conclusion: VILA通过双分支视觉语言校准策略，成功解决了预训练模型在类增量学习中的表示刚性问题，在保持解析学习高效性的同时显著提升了系统稳定性和性能。

Abstract: Class-incremental learning (CIL) with pre-trained models (PTMs) faces a critical trade-off between efficient adaptation and long-term stability. While analytic learning enables rapid, recursive closed-form updates, its efficacy is often compromised by accumulated errors and feature incompatibility. In this paper, we first conduct a systematic study to dissect the failure modes of PTM-based analytic CIL, identifying representation rigidity as the primary bottleneck. Motivated by these insights, we propose \textbf{VILA}, a novel dual-branch framework that advances analytic CIL via a two-level vision-language calibration strategy. Specifically, we coherently fuse plastic, task-adapted features with a frozen, universal semantic anchor at the feature level through geometric calibration, and leverage cross-modal priors at the decision level to rectify prediction bias. This confluence maintains analytic-learning's extreme efficiency while overcoming its inherent brittleness. Extensive experiments across eight benchmarks demonstrate that VILA consistently yields superior performance, particularly in fine-grained and long-sequence scenarios. Our framework harmonizes high-fidelity prediction with the simplicity of analytic learning. Our code is available at https://github.com/byzhaoAI/VILA

</details>


### [31] [On the Sparsifiability of Correlation Clustering: Approximation Guarantees under Edge Sampling](https://arxiv.org/abs/2602.13684)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 本文研究相关性聚类的稀疏化-近似权衡，揭示了伪度量与一般加权实例之间的结构二分性，提出了最优大小核心集、精确切割平面求解器，以及基于稀疏化LP-PIVOT的鲁棒近似算法。


<details>
  <summary>Details</summary>
Motivation: 相关性聚类（CC）是一种基础的无监督学习原语，其最强的基于线性规划（LP）的近似保证需要Θ(n³)个三角不等式约束，在大规模场景下计算成本过高。本文旨在研究CC的稀疏化-近似权衡，探索需要多少边信息才能保持LP的近似保证。

Method: 1. 证明聚类分歧类的VC维度恰好为n-1，从而得到最优大小的加性ε-核心集；2. 证明在任何LP顶点处最多有binom(n,2)个三角不等式是活跃的，实现精确切割平面求解器；3. 提出稀疏化LP-PIVOT算法，通过三角不等式填补缺失的LP边际值；4. 使用Yao极小极大原理证明负向结果。

Result: 1. 获得大小为Õ(n/ε²)的最优加性ε-核心集；2. 实现精确切割平面求解器；3. 稀疏化LP-PIVOT在观察到Õ(n^{3/2})条边时达到鲁棒的10/3近似（受可计算的填补质量统计量Γ_w控制），且该阈值是尖锐的；4. 证明对于非伪度量结构，任何观察o(n)条均匀随机边的算法都会产生无界近似比。

Conclusion: 本文揭示了相关性聚类中伪度量结构与一般加权实例之间的根本差异，表明伪度量条件不仅影响计算可处理性，还决定了CC对不完全信息的鲁棒性。研究结果为大规模相关性聚类提供了理论保证和实用算法。

Abstract: Correlation Clustering (CC) is a fundamental unsupervised learning primitive whose strongest LP-based approximation guarantees require $Θ(n^3)$ triangle inequality constraints and are prohibitive at scale. We initiate the study of \emph{sparsification--approximation trade-offs} for CC, asking how much edge information is needed to retain LP-based guarantees. We establish a structural dichotomy between pseudometric and general weighted instances. On the positive side, we prove that the VC dimension of the clustering disagreement class is exactly $n{-}1$, yielding additive $\varepsilon$-coresets of optimal size $\tilde{O}(n/\varepsilon^2)$; that at most $\binom{n}{2}$ triangle inequalities are active at any LP vertex, enabling an exact cutting-plane solver; and that a sparsified variant of LP-PIVOT, which imputes missing LP marginals via triangle inequalities, achieves a robust $\frac{10}{3}$-approximation (up to an additive term controlled by an empirically computable imputation-quality statistic $\overlineΓ_w$) once $\tildeΘ(n^{3/2})$ edges are observed, a threshold we prove is sharp. On the negative side, we show via Yao's minimax principle that without pseudometric structure, any algorithm observing $o(n)$ uniformly random edges incurs an unbounded approximation ratio, demonstrating that the pseudometric condition governs not only tractability but also the robustness of CC to incomplete information.

</details>


### [32] [Physics Aware Neural Networks: Denoising for Magnetic Navigation](https://arxiv.org/abs/2602.13690)
*Aritra Das,Yashas Shende,Muskaan Chugh,Reva Laxmi Chauhan,Arghya Pathak,Debayan Gupta*

Main category: cs.LG

TL;DR: 提出基于物理约束的深度学习框架，用于飞机磁异常导航中的磁场建模，通过散度自由和E(3)-等变性约束提升预测精度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 磁异常导航在GPS不可用时是重要替代方案，但飞机自身会产生磁噪声。经典的Tolles-Lawson模型无法有效处理导航所需的随机噪声污染磁数据。

Method: 提出基于两个物理约束的框架：1) 散度自由向量场约束，通过神经网络输出矢量势A，磁场定义为A的旋度；2) E(3)-等变性约束，使用几何张量的张量积表示。采用Contiformer架构处理连续时间动态和长期记忆，并使用WMM和条件GAN生成合成数据缓解数据稀缺问题。

Result: 实验表明，嵌入物理约束显著提高了预测精度和物理合理性，优于经典方法和无约束的深度学习方法。Contiformer架构在建模磁时间序列方面表现最佳。

Conclusion: 通过物理约束和先进神经网络架构的结合，有效解决了磁异常导航中的随机噪声问题，为GPS受限环境下的导航提供了更可靠的解决方案。

Abstract: Magnetic-anomaly navigation, leveraging small-scale variations in the Earth's magnetic field, is a promising alternative when GPS is unavailable or compromised. Airborne systems face a key challenge in extracting geomagnetic field data: the aircraft itself induces magnetic noise. Although the classical Tolles-Lawson model addresses this, it inadequately handles stochastically corrupted magnetic data required for navigation. To address stochastic noise, we propose a framework based on two physics-based constraints: divergence-free vector field and E(3)-equivariance. These ensure the learned magnetic field obeys Maxwell's equations and that outputs transform correctly with sensor position/orientation. The divergence-free constraint is implemented by training a neural network to output a vector potential $A$, with the magnetic field defined as its curl. For E(3)-equivariance, we use tensor products of geometric tensors representable via spherical harmonics with known rotational transformations. Enforcing physical consistency and restricting the admissible function space acts as an implicit regularizer that improves spatio-temporal performance. We present ablation studies evaluating each constraint alone and jointly across CNNs, MLPs, Liquid Time Constant models, and Contiformers. Continuous-time dynamics and long-term memory are critical for modelling magnetic time series; the Contiformer architecture, which provides both, outperforms state-of-the-art methods. To mitigate data scarcity, we generate synthetic datasets using the World Magnetic Model (WMM) with time-series conditional GANs, producing realistic, temporally consistent magnetic sequences across varied trajectories and environments. Experiments show that embedding these constraints significantly improves predictive accuracy and physical plausibility, outperforming classical and unconstrained deep learning approaches.

</details>


### [33] [Attention Head Entropy of LLMs Predicts Answer Correctness](https://arxiv.org/abs/2602.13699)
*Sophie Ostmeier,Brian Axelrod,Maya Varma,Asad Aali,Yabin Zhang,Magdalini Paschali,Sanmi Koyejo,Curtis Langlotz,Akshay Chaudhari*

Main category: cs.LG

TL;DR: Head Entropy方法通过分析注意力熵模式预测LLM回答正确性，在分布内和跨域泛化方面优于基线方法，特别是在医学等安全关键领域。


<details>
  <summary>Details</summary>
Motivation: LLM经常生成看似合理但实际错误的答案，在医学等安全关键领域存在风险。人工评估成本高，而LLM作为评判者的方法可能引入隐藏错误。现有的白盒方法主要关注上下文幻觉检测，但两个问题仍未解决：这些方法能否扩展到预测答案正确性？能否在跨域场景中泛化？

Method: 提出Head Entropy方法，通过测量注意力质量的分散程度来预测答案正确性。使用稀疏逻辑回归对每个注意力头的2-Renyi熵进行分析，捕捉注意力熵模式。

Result: Head Entropy在分布内匹配或超越基线方法，在跨域泛化方面显著优于基线，平均AUROC比最接近的基线高+8.5%。更重要的是，在答案生成前仅基于问题/上下文的注意力模式就已经具有预测信号，平均AUROC比最接近的基线高+17.7%。

Conclusion: Head Entropy方法能够有效预测LLM回答的正确性，具有良好的跨域泛化能力，为安全关键应用中的LLM可靠性评估提供了有前景的白盒解决方案。

Abstract: Large language models (LLMs) often generate plausible yet incorrect answers, posing risks in safety-critical settings such as medicine. Human evaluation is expensive, and LLM-as-judge approaches risk introducing hidden errors. Recent white-box methods detect contextual hallucinations using model internals, focusing on the localization of the attention mass, but two questions remain open: do these approaches extend to predicting answer correctness, and do they generalize out-of-domains? We introduce Head Entropy, a method that predicts answer correctness from attention entropy patterns, specifically measuring the spread of the attention mass. Using sparse logistic regression on per-head 2-Renyi entropies, Head Entropy matches or exceeds baselines in-distribution and generalizes substantially better on out-of-domains, it outperforms the closest baseline on average by +8.5% AUROC. We further show that attention patterns over the question/context alone, before answer generation, already carry predictive signal using Head Entropy with on average +17.7% AUROC over the closest baseline. We evaluate across 5 instruction-tuned LLMs and 3 QA datasets spanning general knowledge, multi-hop reasoning, and medicine.

</details>


### [34] [Optimal Regret for Policy Optimization in Contextual Bandits](https://arxiv.org/abs/2602.13700)
*Orin Levy,Yishay Mansour*

Main category: cs.LG

TL;DR: 首个高概率最优遗憾界的上下文多臂老虎机策略优化算法，实现了$\widetilde{O}(\sqrt{K|\mathcal{A}|\log|\mathcal{F}|})$的最优遗憾界


<details>
  <summary>Details</summary>
Motivation: 解决上下文多臂老虎机问题中策略优化方法的理论保证不足问题，弥合理论与实践的差距，证明广泛使用的策略优化方法可以获得严格证明的最优遗憾界

Method: 采用策略优化技术，结合一般离线函数逼近，设计高效的算法来处理随机上下文多臂老虎机问题

Result: 实现了$\widetilde{O}(\sqrt{K|\mathcal{A}|\log|\mathcal{F}|})$的最优遗憾界，其中K是回合数，$\mathcal{A}$是臂集合，$\mathcal{F}$是函数类，并通过实证评估支持理论结果

Conclusion: 该研究首次为上下文多臂老虎机的策略优化方法提供了高概率最优遗憾界，证明了广泛使用的实践方法具有严格的理论保证，弥合了理论与实践的鸿沟

Abstract: We present the first high-probability optimal regret bound for a policy optimization technique applied to the problem of stochastic contextual multi-armed bandit (CMAB) with general offline function approximation. Our algorithm is both efficient and achieves an optimal regret bound of $\widetilde{O}(\sqrt{ K|\mathcal{A}|\log|\mathcal{F}|})$, where $K$ is the number of rounds, $\mathcal{A}$ is the set of arms, and $\mathcal{F}$ is the function class used to approximate the losses. Our results bridge the gap between theory and practice, demonstrating that the widely used policy optimization methods for the contextual bandit problem can achieve a rigorously-proved optimal regret bound. We support our theoretical results with an empirical evaluation of our algorithm.

</details>


### [35] [Near-Optimal Regret for Policy Optimization in Contextual MDPs with General Offline Function Approximation](https://arxiv.org/abs/2602.13706)
*Orin Levy,Aviv Rosenberg,Alon Cohen,Yishay Mansour*

Main category: cs.LG

TL;DR: OPO-CMDP是首个在一般离线函数逼近下的随机上下文马尔可夫决策过程（CMDPs）策略优化算法，实现了最优的状态和动作空间依赖的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 当前CMDPs的离线学习算法在状态和动作空间的依赖上不是最优的，需要开发一个既计算高效又理论接近最优的算法来解决这个问题。

Method: 提出了OPO-CMDP算法，采用乐观策略优化方法，在一般离线函数逼近框架下工作，使用有限函数类来逼近损失和动态。

Result: 获得了高概率遗憾界$\widetilde{O}(H^4\sqrt{T|S||A|\log(|\mathcal{F}||\mathcal{P}|)})$，这是首个在状态和动作空间依赖上达到最优的遗憾界，直接改进了当前最先进的结果。

Conclusion: 乐观策略优化为求解CMDPs提供了一条自然、计算上优越且理论上接近最优的路径，证明了该方法在离线强化学习中的有效性。

Abstract: We introduce \texttt{OPO-CMDP}, the first policy optimization algorithm for stochastic Contextual Markov Decision Process (CMDPs) under general offline function approximation. Our approach achieves a high probability regret bound of $\widetilde{O}(H^4\sqrt{T|S||A|\log(|\mathcal{F}||\mathcal{P}|)}),$ where $S$ and $A$ denote the state and action spaces, $H$ the horizon length, $T$ the number of episodes, and $\mathcal{F}, \mathcal{P}$ the finite function classes used to approximate the losses and dynamics, respectively. This is the first regret bound with optimal dependence on $|S|$ and $|A|$, directly improving the current state-of-the-art (Qian, Hu, and Simchi-Levi, 2024). These results demonstrate that optimistic policy optimization provides a natural, computationally superior and theoretically near-optimal path for solving CMDPs.

</details>


### [36] [HBVLA: Pushing 1-Bit Post-Training Quantization for Vision-Language-Action Models](https://arxiv.org/abs/2602.13710)
*Xin Yan,Zhenglin Wan,Feiyang Ye,Xingrui Yu,Hangyu Du,Yang You,Ivor Tsang*

Main category: cs.LG

TL;DR: HBVLA：针对视觉-语言-动作模型的二值化框架，通过策略感知增强Hessian识别关键权重、稀疏正交变换降低熵、Haar域分组1-bit量化，显著提升量化模型在资源受限机器人上的部署性能。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在资源受限的机器人和边缘平台上部署困难，现有二值化方法存在分布差距，导致量化误差在长时闭环执行中累积，严重影响动作生成质量。

Method: 1) 使用策略感知增强Hessian识别对动作生成真正关键的权重；2) 对非显著权重应用稀疏正交变换诱导低熵中间状态；3) 在Haar域对显著和非显著权重进行分组1-bit量化。

Result: 在LIBERO上，量化后的OpenVLA-OFT保持92.2%全精度性能；在SimplerEnv上，量化CogAct保持93.6%性能，显著优于现有二值化方法。真实世界评估显示仅边际成功率下降。

Conclusion: HBVLA为VLA模型提供了实用的超低比特量化基础，能够在硬件受限的机器人平台上实现可靠部署，填补了二值化与全精度权重之间的分布差距。

Abstract: Vision-Language-Action (VLA) models enable instruction-following embodied control, but their large compute and memory footprints hinder deployment on resource-constrained robots and edge platforms. While reducing weights to 1-bit precision through binarization can greatly improve efficiency, existing methods fail to narrow the distribution gap between binarized and full-precision weights, causing quantization errors to accumulate under long-horizon closed-loop execution and severely degrade actions. To fill this gap, we propose HBVLA, a VLA-tailored binarization framework. First, we use a policy-aware enhanced Hessian to identify weights that are truly critical for action generation. Then, we employ a sparse orthogonal transform for non-salient weights to induce a low-entropy intermediate state. Finally, we quantize both salient and non-salient weights in the Harr domain with group-wise 1-bit quantization. We have evaluated our approach on different VLAs: on LIBERO, quantized OpenVLA-OFT retains 92.2% of full-precision performance; on SimplerEnv, quantized CogAct retains 93.6%, significantly outperforming state-of-the-art binarization methods. We further validate our method on real-world evaluation suite and the results show that HBVLA incurs only marginal success-rate degradation compared to the full-precision model, demonstrating robust deployability under tight hardware constraints. Our work provides a practical foundation for ultra-low-bit quantization of VLAs, enabling more reliable deployment on hardware-limited robotic platforms.

</details>


### [37] [Data-driven Bi-level Optimization of Thermal Power Systems with embedded Artificial Neural Networks](https://arxiv.org/abs/2602.13746)
*Talha Ansar,Muhammad Mujtaba Abbas,Ramit Debnath,Vivek Dua,Waqar Muhammad Ashraf*

Main category: cs.LG

TL;DR: 提出基于机器学习的双层优化框架（ANN-KKT），用于工业热电系统的数据驱动优化，通过神经网络近似目标函数并结合KKT条件，实现计算高效的分层优化。


<details>
  <summary>Details</summary>
Motivation: 工业热电系统具有耦合的性能变量和重要性层次结构，传统同时优化方法计算复杂或不可行，限制了系统集成和可扩展的操作优化。

Method: 提出完全机器学习驱动的双层优化框架：1）用人工神经网络（ANN）近似上下层目标函数；2）通过KKT最优性条件解析嵌入下层问题；3）将ANN模型与KKT约束整合为单层优化框架（ANN-KKT）。

Result: 1）在基准问题上获得与双层解相当的结果；2）计算时间极短（0.22-0.88秒）；3）实际应用中：660MW煤电厂输出583MW（最优热耗率7337 kJ/kWh），395MW燃气轮机输出402MW（最优热耗率7542 kJ/kWh）；4）方法可扩展至考虑不确定性的稳健运行包络。

Conclusion: ANN-KKT框架为工业热电系统的分层数据驱动优化提供了可扩展且计算高效的途径，实现大规模工程系统的能源高效运行，有助于工业5.0发展。

Abstract: Industrial thermal power systems have coupled performance variables with hierarchical order of importance, making their simultaneous optimization computationally challenging or infeasible. This barrier limits the integrated and computationally scaleable operation optimization of industrial thermal power systems. To address this issue for large-scale engineering systems, we present a fully machine learning-powered bi-level optimization framework for data-driven optimization of industrial thermal power systems. The objective functions of upper and lower levels are approximated by artificial neural network (ANN) models and the lower-level problem is analytically embedded through Karush-Kuhn-Tucker (KKT) optimality conditions. The reformulated single level optimization framework integrating ANN models and KKT constraints (ANN-KKT) is validated on benchmark problems and on real-world power generation operation of 660 MW coal power plant and 395 MW gas turbine system. The results reveal a comparable solutions obtained from the proposed ANN-KKT framework to the bi-level solutions of the benchmark problems. Marginal computational time requirement (0.22 to 0.88 s) to compute optimal solutions yields 583 MW (coal) and 402 MW (gas turbine) of power output at optimal turbine heat rate of 7337 kJ/kWh and 7542 kJ/kWh, respectively. In addition, the method expands to delineate a feasible and robust operating envelope that accounts for uncertainty in operating variables while maximizing thermal efficiency in various scenarios. These results demonstrate that ANN-KKT offers a scalable and computationally efficient route for hierarchical, data-driven optimization of industrial thermal power systems, achieving energy-efficient operations of large-scale engineering systems and contributing to industry 5.0.

</details>


### [38] [Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition](https://arxiv.org/abs/2602.13759)
*ZhiMing Li,JiaHe Feng*

Main category: cs.LG

TL;DR: 提出一种离散双括号流算法，用于矩阵向量乘积（MVP）预言机下的特征分解，该算法对协方差算子中的各向同性偏移具有不变性，仅依赖于迹自由协方差，实现了全局收敛和加速鞍点逃逸。


<details>
  <summary>Details</summary>
Motivation: 现有随机逼近方法要么使用固定步长（稳定性与‖C_k‖_2耦合），要么采用自适应步长（因更新消失而减慢）。需要一种对协方差算子中的各向同性偏移具有不变性的算法，以更高效地解决特征分解问题。

Method: 引入离散双括号流，其生成器对各向同性偏移具有不变性，在离散时间层面上对σ_k^2 I具有路径不变性。算法轨迹和最大稳定步长η_max ∝ 1/‖C_e‖_2^2仅依赖于迹自由协方差C_e。

Result: 通过严格鞍点几何和对角化目标以及输入到状态稳定性分析建立了全局收敛性，样本复杂度为O(‖C_e‖_2^2/(Δ^2ε))。通过退化块的显式表征实现了O(log(1/ζ))的加速鞍点逃逸率和高概率有限时间收敛保证。

Conclusion: 提出的离散双括号流算法解决了现有随机逼近方法的局限性，通过利用迹自由协方差的特性实现了对特征分解问题的高效求解，具有理论保证的收敛性和加速性能。

Abstract: We study matrix-free eigendecomposition under a matrix-vector product (MVP) oracle, where each step observes a covariance operator $C_k = C_{sig} + σ_k^2 I + E_k$. Standard stochastic approximation methods either use fixed steps that couple stability to $\|C_k\|_2$, or adapt steps in ways that slow down due to vanishing updates. We introduce a discrete double-bracket flow whose generator is invariant to isotropic shifts, yielding pathwise invariance to $σ_k^2 I$ at the discrete-time level. The resulting trajectory and a maximal stable step size $η_{max} \propto 1/\|C_e\|_2^2$ depend only on the trace-free covariance $C_e$. We establish global convergence via strict-saddle geometry for the diagonalization objective and an input-to-state stability analysis, with sample complexity scaling as $O(\|C_e\|_2^2 / (Δ^2 ε))$ under trace-free perturbations. An explicit characterization of degenerate blocks yields an accelerated $O(\log(1/ζ))$ saddle-escape rate and a high-probability finite-time convergence guarantee.

</details>


### [39] [On Representation Redundancy in Large-Scale Instruction Tuning Data Selection](https://arxiv.org/abs/2602.13773)
*Youwei Shu,Shaomian Zheng,Dingnan Jin,Wenjie Qu,Ziyao Guo,Qing Cui,Jun Zhou,Jiaheng Zhang*

Main category: cs.LG

TL;DR: 提出CRDS框架，通过压缩语义表示减少冗余，提升指令调优数据选择质量，仅用3.5%数据即可超越全数据基线


<details>
  <summary>Details</summary>
Motivation: 工业规模指令调优的数据选择方法研究不足，现有LLM编码器产生的语义嵌入高度冗余，需要更有效的数据选择框架

Method: 提出CRDS框架：CRDS-R使用Rademacher随机投影和transformer隐藏层表示拼接；CRDS-W采用白化降维提升表示质量

Result: 两种变体显著提升数据质量，优于现有表示选择方法；CRDS-W仅用3.5%数据即可超越全数据基线，平均提升0.71%

Conclusion: CRDS通过压缩语义表示有效解决LLM编码器冗余问题，为工业规模指令调优数据选择提供高效解决方案

Abstract: Data quality is a crucial factor in large language models training. While prior work has shown that models trained on smaller, high-quality datasets can outperform those trained on much larger but noisy or low-quality corpora, systematic methods for industrial-scale data selection in instruction tuning remain underexplored. In this work, we study instruction-tuning data selection through the lens of semantic representation similarity and identify a key limitation of state-of-the-art LLM encoders: they produce highly redundant semantic embeddings. To mitigate this redundancy, we propose Compressed Representation Data Selection (CRDS), a novel framework with two variants. CRDS-R applies Rademacher random projection followed by concatenation of transformer hidden-layer representations, while CRDS-W employs whitening-based dimensionality reduction to improve representational quality. Experimental results demonstrate that both variants substantially enhance data quality and consistently outperform state-of-the-art representation-based selection methods. Notably, CRDS-W achieves strong performance using only 3.5% of the data, surpassing the full-data baseline by an average of 0.71% across four datasets. Our code is available at https://github.com/tdano1/CRDS.

</details>


### [40] [MEMTS: Internalizing Domain Knowledge via Parameterized Memory for Retrieval-Free Domain Adaptation of Time Series Foundation Models](https://arxiv.org/abs/2602.13783)
*Xiaoyun Yu,Li fan,Xiangfei Qiu,Nanqing Dong,Yonggui Huang,Honggang Qi,Geguang Pu,Wanli Ouyang,Xi Chen,Jilin Hu*

Main category: cs.LG

TL;DR: MEMTS提出了一种轻量级、即插即用的检索自由时间序列领域自适应方法，通过知识持久化模块将领域特定时间动态内化为可学习的潜在原型，实现恒定时间推理和近零延迟，同时避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在垂直领域部署时面临两个主要问题：1）时间分布偏移和领域特定周期性结构导致性能显著下降；2）现有解决方案（领域自适应预训练和检索增强生成）存在灾难性遗忘或高检索开销，无法满足实时流处理的高效要求。

Method: 提出MEMTS方法，核心是知识持久化模块（KPM），将领域特定的时间动态（如季节性模式和趋势）内化为紧凑的可学习潜在原型集，将碎片化的历史观测转化为连续的参数化知识表示。该方法无需修改冻结的时间序列基础模型架构。

Result: 在多个数据集上的广泛实验表明，MEMTS实现了最先进的性能，能够以恒定时间推理和近零延迟实现准确的领域自适应，同时有效缓解对通用时间模式的灾难性遗忘。

Conclusion: MEMTS通过将领域特定知识内化为参数化表示，解决了现有时间序列领域自适应方法的局限性，实现了高效、轻量级且无需检索的自适应，为实时流处理场景提供了可行的解决方案。

Abstract: While Time Series Foundation Models (TSFMs) have demonstrated exceptional performance in generalized forecasting, their performance often degrades significantly when deployed in real-world vertical domains characterized by temporal distribution shifts and domain-specific periodic structures. Current solutions are primarily constrained by two paradigms: Domain-Adaptive Pretraining (DAPT), which improves short-term domain fitting but frequently disrupts previously learned global temporal patterns due to catastrophic forgetting; and Retrieval-Augmented Generation (RAG), which incorporates external knowledge but introduces substantial retrieval overhead. This creates a severe scalability bottleneck that fails to meet the high-efficiency requirements of real-time stream processing. To break this impasse, we propose Memory for Time Series (MEMTS), a lightweight and plug-and-play method for retrieval-free domain adaptation in time series forecasting. The key component of MEMTS is a Knowledge Persistence Module (KPM), which internalizes domain-specific temporal dynamics, such as recurring seasonal patterns and trends into a compact set of learnable latent prototypes. In doing so, it transforms fragmented historical observations into continuous, parameterized knowledge representations. This paradigm shift enables MEMTS to achieve accurate domain adaptation with constant-time inference and near-zero latency, while effectively mitigating catastrophic forgetting of general temporal patterns, all without requiring any architectural modifications to the frozen TSFM backbone. Extensive experiments on multiple datasets demonstrate the SOTA performance of MEMTS.

</details>


### [41] [MechPert: Mechanistic Consensus as an Inductive Bias for Unseen Perturbation Prediction](https://arxiv.org/abs/2602.13791)
*Marc Boubnovski Martell,Josefa Lia Stoisser,Lawrence Phillips,Aditya Misra,Robert Kitchen,Jesper Ferkinghoff-Borg,Jialin Yu,Philip Torr,Kaspar Märten*

Main category: cs.LG

TL;DR: MechPert是一个轻量级框架，使用LLM代理生成定向调控假设而非依赖功能相似性，通过共识机制聚合候选调控因子，在低数据扰动预测和实验设计方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预测未见遗传扰动的转录反应对于理解基因调控和优先考虑大规模扰动实验至关重要。现有方法要么依赖静态、可能不完整的知识图谱，要么基于功能相似性提示语言模型，这些方法检索的是科学文本中对称共现形成的关联，而非定向调控逻辑。

Method: MechPert框架鼓励LLM代理生成定向调控假设而非依赖功能相似性。多个代理独立提出候选调控因子及其置信度分数，通过共识机制聚合这些建议，过滤虚假关联，为下游预测生成加权邻域。

Result: 在四个人类细胞系的Perturb-seq基准测试中，对于低数据机制（N=50个观测扰动），MechPert将Pearson相关性比基于相似性的基线方法提高了10.5%。在实验设计中，MechPert选择的锚基因在特征良好的细胞系中比标准网络中心性启发式方法表现优46%。

Conclusion: MechPert通过利用LLM代理生成定向调控假设并采用共识机制，显著改善了遗传扰动预测和实验设计，特别是在数据有限的情况下，为基因调控研究提供了更有效的工具。

Abstract: Predicting transcriptional responses to unseen genetic perturbations is essential for understanding gene regulation and prioritizing large-scale perturbation experiments. Existing approaches either rely on static, potentially incomplete knowledge graphs, or prompt language models for functionally similar genes, retrieving associations shaped by symmetric co-occurrence in scientific text rather than directed regulatory logic. We introduce MechPert, a lightweight framework that encourages LLM agents to generate directed regulatory hypotheses rather than relying solely on functional similarity. Multiple agents independently propose candidate regulators with associated confidence scores; these are aggregated through a consensus mechanism that filters spurious associations, producing weighted neighborhoods for downstream prediction. We evaluate MechPert on Perturb-seq benchmarks across four human cell lines. For perturbation prediction in low-data regimes ($N=50$ observed perturbations), MechPert improves Pearson correlation by up to 10.5\% over similarity-based baselines. For experimental design, MechPert-selected anchor genes outperform standard network centrality heuristics by up to 46\% in well-characterized cell lines.

</details>


### [42] [Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting](https://arxiv.org/abs/2602.13802)
*Xiaoyu Tao,Mingyue Cheng,Chuang Jiang,Tian Gao,Huanjian Zhang,Yaguo Liu*

Main category: cs.LG

TL;DR: Cast-R1将时间序列预测重构为顺序决策问题，通过基于记忆的状态管理和工具增强的智能体工作流实现迭代式预测优化


<details>
  <summary>Details</summary>
Motivation: 传统模型中心方法将预测视为从历史观测到未来值的单次映射，难以处理复杂演化场景，缺乏自主获取证据、推理未来变化或迭代修正预测的能力

Method: 提出Cast-R1框架：1) 基于记忆的状态管理机制维护决策相关信息；2) 工具增强的智能体工作流，自主与模块化工具包交互提取特征、调用轻量模型、进行推理预测和迭代优化；3) 两阶段训练策略结合监督微调与多轮强化学习，配合课程学习逐步增加任务难度

Result: 在多个真实世界时间序列数据集上的广泛实验证明了Cast-R1的有效性

Conclusion: 这项工作为时间序列建模的智能体范式探索提供了实用步骤，展示了将预测重构为顺序决策问题的潜力

Abstract: Time series forecasting has long been dominated by model-centric approaches that formulate prediction as a single-pass mapping from historical observations to future values. Despite recent progress, such formulations often struggle in complex and evolving settings, largely because most forecasting models lack the ability to autonomously acquire informative evidence, reason about potential future changes, or revise predictions through iterative decision processes. In this work, we propose Cast-R1, a learned time series forecasting framework that reformulates forecasting as a sequential decision-making problem. Cast-R1 introduces a memory-based state management mechanism that maintains decision-relevant information across interaction steps, enabling the accumulation of contextual evidence to support long-horizon reasoning. Building on this formulation, forecasting is carried out through a tool-augmented agentic workflow, in which the agent autonomously interacts with a modular toolkit to extract statistical features, invoke lightweight forecasting models for decision support, perform reasoning-based prediction, and iteratively refine forecasts through self-reflection. To train Cast-R1, we adopt a two-stage learning strategy that combines supervised fine-tuning with multi-turn reinforcement learning, together with a curriculum learning scheme that progressively increases task difficulty to improve policy learning. Extensive experiments on multiple real-world time series datasets demonstrate the effectiveness of Cast-R1. We hope this work provides a practical step towards further exploration of agentic paradigms for time series modeling. Our code is available at https://github.com/Xiaoyu-Tao/Cast-R1-TS.

</details>


### [43] [AnomaMind: Agentic Time Series Anomaly Detection with Tool-Augmented Reasoning](https://arxiv.org/abs/2602.13807)
*Xiaoyu Tao,Yuchong Wu,Mingyue Cheng,Ze Guo,Tian Gao*

Main category: cs.LG

TL;DR: AnomaMind：一个基于智能体的时间序列异常检测框架，将异常检测重构为顺序决策过程，通过多轮工具交互和自反思实现自适应特征准备和推理感知检测


<details>
  <summary>Details</summary>
Motivation: 现有方法将异常检测视为固定特征输入的纯判别预测任务，而非证据驱动的诊断过程，导致在异常具有强上下文依赖或多样模式时表现不佳。这些限制源于缺乏自适应特征准备、推理感知检测和迭代优化。

Method: 提出AnomaMind框架，通过结构化工作流程：1）粗到细逐步定位异常区间；2）多轮工具交互实现自适应特征准备；3）自反思优化异常决策。采用混合推理机制：通用模型负责自主工具交互和自反思优化，核心异常检测决策通过强化学习在工作流程级反馈下学习。

Result: 在多样化设置下的广泛实验表明，AnomaMind持续提升异常检测性能。

Conclusion: AnomaMind通过将异常检测重构为顺序决策过程，结合自适应特征准备、推理感知检测和迭代优化，有效解决了现有方法在复杂异常模式下的局限性，为时间序列异常检测提供了更可靠的解决方案。

Abstract: Time series anomaly detection is critical in many real-world applications, where effective solutions must localize anomalous regions and support reliable decision-making under complex settings. However, most existing methods frame anomaly detection as a purely discriminative prediction task with fixed feature inputs, rather than an evidence-driven diagnostic process. As a result, they often struggle when anomalies exhibit strong context dependence or diverse patterns. We argue that these limitations stem from the lack of adaptive feature preparation, reasoning-aware detection, and iterative refinement during inference. To address these challenges, we propose AnomaMind, an agentic time series anomaly detection framework that reformulates anomaly detection as a sequential decision-making process. AnomaMind operates through a structured workflow that progressively localizes anomalous intervals in a coarse-to-fine manner, augments detection through multi-turn tool interactions for adaptive feature preparation, and refines anomaly decisions via self-reflection. The workflow is supported by a set of reusable tool engines, enabling context-aware diagnostic analysis. A key design of AnomaMind is an explicitly designed hybrid inference mechanism for tool-augmented anomaly detection. In this mechanism, general-purpose models are responsible for autonomous tool interaction and self-reflective refinement, while core anomaly detection decisions are learned through reinforcement learning under verifiable workflow-level feedback, enabling task-specific optimization within a flexible reasoning framework. Extensive experiments across diverse settings demonstrate that AnomaMind consistently improves anomaly detection performance. The code is available at https://anonymous.4open.science/r/AnomaMind.

</details>


### [44] [Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation](https://arxiv.org/abs/2602.13810)
*Guojian Zhan,Letian Tao,Pengcheng Wang,Yixiao Wang,Yiheng Li,Yuxin Chen,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 提出MVP（平均速度策略），一种新的生成式策略函数，通过建模平均速度场实现最快的一步动作生成，在表达能力和计算效率之间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 基于流的策略虽然在建模复杂动作分布和快速确定性采样方面有效，但仍面临表达能力和计算负担之间的权衡，通常通过流步骤数量来控制。需要一种既能保持高表达能力又能实现快速推理的策略函数。

Method: 提出平均速度策略（MVP），建模平均速度场实现一步动作生成。引入瞬时速度约束（IVC）作为训练时的边界条件，理论上证明能提高学习精度和策略表达能力。

Result: 在Robomimic和OGBench的多个挑战性机器人操作任务中达到最先进的成功率。相比现有基于流的策略基线，在训练和推理速度上都有显著提升。

Conclusion: MVP通过建模平均速度场和引入IVC约束，成功解决了流策略在表达能力和计算效率之间的权衡问题，实现了既高效又表达力强的策略函数。

Abstract: Learning expressive and efficient policy functions is a promising direction in reinforcement learning (RL). While flow-based policies have recently proven effective in modeling complex action distributions with a fast deterministic sampling process, they still face a trade-off between expressiveness and computational burden, which is typically controlled by the number of flow steps. In this work, we propose mean velocity policy (MVP), a new generative policy function that models the mean velocity field to achieve the fastest one-step action generation. To ensure its high expressiveness, an instantaneous velocity constraint (IVC) is introduced on the mean velocity field during training. We theoretically prove that this design explicitly serves as a crucial boundary condition, thereby improving learning accuracy and enhancing policy expressiveness. Empirically, our MVP achieves state-of-the-art success rates across several challenging robotic manipulation tasks from Robomimic and OGBench. It also delivers substantial improvements in training and inference speed over existing flow-based policy baselines.

</details>


### [45] [Pawsterior: Variational Flow Matching for Structured Simulation-Based Inference](https://arxiv.org/abs/2602.13813)
*Jorge Carrasco-Pollo,Floor Eijkelboom,Jan-Willem van de Meent*

Main category: cs.LG

TL;DR: Pawsterior是一个变分流匹配框架，用于改进和扩展基于模拟的推理(SBI)，特别针对具有结构化域约束的后验分布问题。


<details>
  <summary>Details</summary>
Motivation: 许多SBI问题涉及受结构化域约束的后验分布，如有界物理参数或混合离散-连续变量，但标准流匹配方法通常在无约束空间中操作，导致学习效率低下且难以满足物理约束。

Method: 提出端点诱导仿射几何约束原理，通过双变分模型将域几何直接纳入推理过程；开发变分参数化方法，支持涉及离散潜在结构的SBI任务。

Result: 提高了采样时的数值稳定性，在标准SBI基准测试中表现出更好的分类器双样本测试性能；能够处理传统流匹配方法无法处理的离散潜在结构问题。

Conclusion: Pawsterior通过同时解决几何约束和离散潜在结构问题，将流匹配扩展到更广泛的结构化SBI问题类别，这些问题是以前无法处理的。

Abstract: We introduce Pawsterior, a variational flow-matching framework for improved and extended simulation-based inference (SBI). Many SBI problems involve posteriors constrained by structured domains, such as bounded physical parameters or hybrid discrete-continuous variables, yet standard flow-matching methods typically operate in unconstrained spaces. This mismatch leads to inefficient learning and difficulty respecting physical constraints. Our contributions are twofold. First, generalizing the geometric inductive bias of CatFlow, we formalize endpoint-induced affine geometric confinement, a principle that incorporates domain geometry directly into the inference process via a two-sided variational model. This formulation improves numerical stability during sampling and leads to consistently better posterior fidelity, as demonstrated by improved classifier two-sample test performance across standard SBI benchmarks. Second, and more importantly, our variational parameterization enables SBI tasks involving discrete latent structure (e.g., switching systems) that are fundamentally incompatible with conventional flow-matching approaches. By addressing both geometric constraints and discrete latent structure, Pawsterior extends flow-matching to a broader class of structured SBI problems that were previously inaccessible.

</details>


### [46] [Testing For Distribution Shifts with Conditional Conformal Test Martingales](https://arxiv.org/abs/2602.13848)
*Shalev Shaer,Yarin Bar,Drew Prinster,Yaniv Romano*

Main category: cs.LG

TL;DR: 提出一种基于固定参考集的序列检测方法，避免传统CTM中的测试污染问题，实现任意分布漂移的检测


<details>
  <summary>Details</summary>
Motivation: 传统CTM方法在检测分布漂移时存在测试污染问题：漂移后的样本会进入参考集，稀释漂移证据，导致检测延迟增加和检测能力下降

Method: 使用固定的空假设参考数据集，通过稳健的马丁格尔构造，显式考虑有限参考集引起的参考分布估计误差，实现条件于空假设参考数据的有效性

Result: 方法实现了任意时间有效的类型I错误控制，同时保证渐近检测能力为1和有界的期望检测延迟；实验表明比标准CTM检测更快

Conclusion: 该方法通过避免测试污染，提供了一种强大可靠的分布漂移检测器，在保持任意时间有效性的同时提高了检测速度和能力

Abstract: We propose a sequential test for detecting arbitrary distribution shifts that allows conformal test martingales (CTMs) to work under a fixed, reference-conditional setting. Existing CTM detectors construct test martingales by continually growing a reference set with each incoming sample, using it to assess how atypical the new sample is relative to past observations. While this design yields anytime-valid type-I error control, it suffers from test-time contamination: after a change, post-shift observations enter the reference set and dilute the evidence for distribution shift, increasing detection delay and reducing power.
  In contrast, our method avoids contamination by design by comparing each new sample to a fixed null reference dataset. Our main technical contribution is a robust martingale construction that remains valid conditional on the null reference data, achieved by explicitly accounting for the estimation error in the reference distribution induced by the finite reference set. This yields anytime-valid type-I error control together with guarantees of asymptotic power one and bounded expected detection delay. Empirically, our method detects shifts faster than standard CTMs, providing a powerful and reliable distribution-shift detector.

</details>


### [47] [sleep2vec: Unified Cross-Modal Alignment for Heterogeneous Nocturnal Biosignals](https://arxiv.org/abs/2602.13857)
*Weixuan Yuan,Zengrui Jin,Yichen Wang,Donglin Xie,Ziyi Ye,Chao Zhang,Xuesong Chen*

Main category: cs.LG

TL;DR: sleep2vec是一个用于处理多样且不完整夜间生物信号的基础模型，通过跨模态对齐学习共享表示，在睡眠分期和临床评估任务上表现优异，并对传感器丢失具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统睡眠监测和临床诊断依赖多种设备采集夜间生物信号，但设备异质性和频繁的传感器丢失给多模态信号统一建模带来挑战。

Method: 提出sleep2vec基础模型，通过跨模态对齐学习共享表示。使用包含人口统计学、年龄、地点和历史信息的InfoNCE目标进行对比预训练，动态加权负样本来减轻特定队列的捷径学习。在42,249个夜间记录上预训练，涵盖九种模态。

Result: 在睡眠分期和临床结果评估任务上，sleep2vec始终优于强基线模型，并对任何可用模态子集和传感器丢失保持鲁棒性。首次描述了夜间生物信号在模态多样性和模型容量方面的缩放规律。

Conclusion: 统一的跨模态对齐结合原则性缩放，能够实现现实世界夜间生物信号的标签高效、通用建模。

Abstract: Tasks ranging from sleep staging to clinical diagnosis traditionally rely on standard polysomnography (PSG) devices, bedside monitors and wearable devices, which capture diverse nocturnal biosignals (e.g., EEG, EOG, ECG, SpO$_2$). However, heterogeneity across devices and frequent sensor dropout pose significant challenges for unified modelling of these multimodal signals. We present \texttt{sleep2vec}, a foundation model for diverse and incomplete nocturnal biosignals that learns a shared representation via cross-modal alignment. \texttt{sleep2vec} is contrastively pre-trained on 42,249 overnight recordings spanning nine modalities using a \textit{Demography, Age, Site \& History-aware InfoNCE} objective that incorporates physiological and acquisition metadata (\textit{e.g.}, age, gender, recording site) to dynamically weight negatives and mitigate cohort-specific shortcuts. On downstream sleep staging and clinical outcome assessment, \texttt{sleep2vec} consistently outperforms strong baselines and remains robust to any subset of available modalities and sensor dropout. We further characterize, to our knowledge for the first time, scaling laws for nocturnal biosignals with respect to modality diversity and model capacity. Together, these results show that unified cross-modal alignment, coupled with principled scaling, enables label-efficient, general-purpose modelling of real-world nocturnal biosignals.

</details>


### [48] [Sufficient Conditions for Stability of Minimum-Norm Interpolating Deep ReLU Networks](https://arxiv.org/abs/2602.13910)
*Ouns El Harzli,Yoonsoo Nam,Ilja Kuzborskij,Bernardo Cuenca Grau,Ard A. Louis*

Main category: cs.LG

TL;DR: 该论文研究了深度ReLU同质神经网络的算法稳定性，这些网络通过最小L2范数参数实现零训练误差。研究发现，当网络包含稳定子网络且后续层具有低秩权重矩阵时，网络是稳定的；但如果后续层不是低秩，即使有稳定子网络也不能保证稳定性。


<details>
  <summary>Details</summary>
Motivation: 算法稳定性是分析学习算法泛化误差的经典框架，但在深度神经网络分析中应用有限。本文旨在研究深度ReLU同质神经网络在实现最小范数插值（零训练误差）时的稳定性条件，特别是探索过参数化模型通过梯度算法训练时观察到的现象。

Method: 研究深度ReLU同质神经网络，这些网络通过最小L2范数参数实现零训练误差（最小范数插值）。分析网络稳定性条件：1）当网络包含稳定子网络且后续层具有低秩权重矩阵时；2）当网络包含稳定子网络但后续层不是低秩时。低秩假设基于最近的经验和理论结果，表明深度神经网络训练偏向于低秩权重矩阵。

Result: 发现两个关键结果：1）当深度ReLU同质神经网络包含稳定子网络且后续层具有低秩权重矩阵时，网络是稳定的；2）即使网络包含稳定子网络，如果后续层不是低秩，也不能保证网络的稳定性。这表明低秩权重矩阵在确保算法稳定性中起关键作用。

Conclusion: 深度ReLU同质神经网络在最小范数插值下的算法稳定性取决于网络结构特性。低秩权重矩阵是确保稳定性的关键因素，即使网络包含稳定子网络，如果后续层不是低秩，稳定性也无法保证。这一发现为理解过参数化深度神经网络的泛化性能提供了理论依据。

Abstract: Algorithmic stability is a classical framework for analyzing the generalization error of learning algorithms. It predicts that an algorithm has small generalization error if it is insensitive to small perturbations in the training set such as the removal or replacement of a training point. While stability has been demonstrated for numerous well-known algorithms, this framework has had limited success in analyses of deep neural networks. In this paper we study the algorithmic stability of deep ReLU homogeneous neural networks that achieve zero training error using parameters with the smallest $L_2$ norm, also known as the minimum-norm interpolation, a phenomenon that can be observed in overparameterized models trained by gradient-based algorithms. We investigate sufficient conditions for such networks to be stable. We find that 1) such networks are stable when they contain a (possibly small) stable sub-network, followed by a layer with a low-rank weight matrix, and 2) such networks are not guaranteed to be stable even when they contain a stable sub-network, if the following layer is not low-rank. The low-rank assumption is inspired by recent empirical and theoretical results which demonstrate that training deep neural networks is biased towards low-rank weight matrices, for minimum-norm interpolation and weight-decay regularization.

</details>


### [49] [GREPO: A Benchmark for Graph Neural Networks on Repository-Level Bug Localization](https://arxiv.org/abs/2602.13921)
*Juntong Wang,Libin Chen,Xiyuan Wang,Shijia Kang,Haotong Yang,Da Zheng,Muhan Zhang*

Main category: cs.LG

TL;DR: 提出了首个用于仓库级bug定位的GNN基准测试GREPO，包含86个Python仓库和47294个bug修复任务，GNN方法相比传统检索方法表现优异。


<details>
  <summary>Details</summary>
Motivation: 仓库级bug定位是关键的软件工程挑战，标准LLM由于上下文窗口限制无法处理整个代码仓库，现有检索方法（关键词匹配、文本相似性、简单图启发式）有限，而GNN虽然能建模复杂依赖但缺乏专用基准。

Method: 引入GREPO基准测试，包含86个Python仓库和47294个bug修复任务，提供可直接用于GNN处理的图数据结构，评估了多种GNN架构。

Result: GNN架构相比传统信息检索基线表现出色，展示了GNN在bug定位任务中的潜力。

Conclusion: GREPO为未来研究提供了基础资源，证明了GNN在仓库级bug定位任务中的有效性，代码已开源。

Abstract: Repository-level bug localization-the task of identifying where code must be modified to fix a bug-is a critical software engineering challenge. Standard Large Language Modles (LLMs) are often unsuitable for this task due to context window limitations that prevent them from processing entire code repositories. As a result, various retrieval methods are commonly used, including keyword matching, text similarity, and simple graph-based heuristics such as Breadth-First Search. Graph Neural Networks (GNNs) offer a promising alternative due to their ability to model complex, repository-wide dependencies; however, their application has been hindered by the lack of a dedicated benchmark. To address this gap, we introduce GREPO, the first GNN benchmark for repository-scale bug localization tasks. GREPO comprises 86 Python repositories and 47294 bug-fixing tasks, providing graph-based data structures ready for direct GNN processing. Our evaluation of various GNN architectures shows outstanding performance compared to established information retrieval baselines. This work highlights the potential of GNNs for bug localization and established GREPO as a foundation resource for future research, The code is available at https://github.com/qingpingmo/GREPO.

</details>


### [50] [Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning](https://arxiv.org/abs/2602.13934)
*Zhimin Zhao*

Main category: cs.LG

TL;DR: 论文提出了基于信息结构的五级可学习性层次，解释了为什么代码生成比强化学习更可靠，并指出ML进展的上限更多取决于任务是否可学习而非模型规模。


<details>
  <summary>Details</summary>
Motivation: 代码生成比强化学习进展更可靠，因为代码具有更好的信息结构，提供密集、局部、可验证的反馈。这种反馈质量的差异不是二元的而是渐进的，需要从信息结构角度理解不同任务的可学习性差异。

Method: 提出了基于信息结构的五级可学习性层次，形式化区分了计算问题的三个属性（可表达性、可计算性、可学习性），建立了它们之间的成对关系，并提供了一个统一的模板来明确结构差异。

Result: 分析表明代码的监督学习可预测地扩展，而强化学习则不然，同时指出仅靠扩展就能解决剩余ML挑战的常见假设值得审视。

Conclusion: ML进展的上限更多取决于任务是否可学习，而非模型规模。代码的可学习性结构解释了为什么代码生成比强化学习更可靠，这对理解ML的扩展限制和未来研究方向具有重要意义。

Abstract: Code generation has progressed more reliably than reinforcement learning, largely because code has an information structure that makes it learnable. Code provides dense, local, verifiable feedback at every token, whereas most reinforcement learning problems do not. This difference in feedback quality is not binary but graded. We propose a five-level hierarchy of learnability based on information structure and argue that the ceiling on ML progress depends less on model size than on whether a task is learnable at all. The hierarchy rests on a formal distinction among three properties of computational problems (expressibility, computability, and learnability). We establish their pairwise relationships, including where implications hold and where they fail, and present a unified template that makes the structural differences explicit. The analysis suggests why supervised learning on code scales predictably while reinforcement learning does not, and why the common assumption that scaling alone will solve remaining ML challenges warrants scrutiny.

</details>


### [51] [A Multi-Agent Framework for Code-Guided, Modular, and Verifiable Automated Machine Learning](https://arxiv.org/abs/2602.13937)
*Dat Le,Duc-Cuong Le,Anh-Son Nguyen,Tuan-Dung Bui,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo*

Main category: cs.LG

TL;DR: iML是一个基于多智能体的AutoML框架，通过代码引导的模块化架构解决传统AutoML黑盒问题和LLM智能体的逻辑幻觉问题，显著提升了自动化机器学习系统的可靠性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统AutoML框架作为"黑盒"缺乏灵活性和透明度，而基于LLM的智能体存在逻辑幻觉和逻辑纠缠问题，导致运行时故障难以恢复。需要一种更可靠、可验证的AutoML架构。

Method: iML采用三核心设计：1) 代码引导规划 - 基于自主经验分析生成战略蓝图消除幻觉；2) 代码模块化实现 - 将预处理和建模解耦为专业组件，通过严格接口契约管理；3) 代码可验证集成 - 通过动态契约验证和迭代自校正确保物理可行性。

Result: 在MLE-BENCH上实现85%的有效提交率和45%的竞争奖牌率，标准化性能得分(APS)为0.77。在iML-BENCH上比其他方法提升38%-163%的APS。即使在简化任务描述下仍保持70%的成功率。

Conclusion: iML通过代码引导的模块化架构成功弥合了随机生成与可靠工程之间的差距，为实现真正的AutoML迈出了重要一步，展示了在复杂现实工程任务中的强大潜力。

Abstract: Automated Machine Learning (AutoML) has revolutionized the development of data-driven solutions; however, traditional frameworks often function as "black boxes", lacking the flexibility and transparency required for complex, real-world engineering tasks. Recent Large Language Model (LLM)-based agents have shifted toward code-driven approaches. However, they frequently suffer from hallucinated logic and logic entanglement, where monolithic code generation leads to unrecoverable runtime failures. In this paper, we present iML, a novel multi-agent framework designed to shift AutoML from black-box prompting to a code-guided, modular, and verifiable architectural paradigm. iML introduces three main ideas: (1) Code-Guided Planning, which synthesizes a strategic blueprint grounded in autonomous empirical profiling to eliminate hallucination; (2) Code-Modular Implementation, which decouples preprocessing and modeling into specialized components governed by strict interface contracts; and (3) Code-Verifiable Integration, which enforces physical feasibility through dynamic contract verification and iterative self-correction. We evaluate iML across MLE-BENCH and the newly introduced iML-BENCH, comprising a diverse range of real-world Kaggle competitions. The experimental results show iML's superiority over state-of-the-art agents, achieving a valid submission rate of 85% and a competitive medal rate of 45% on MLE-BENCH, with an average standardized performance score (APS) of 0.77. On iML-BENCH, iML significantly outperforms the other approaches by 38%-163% in APS. Furthermore, iML maintains a robust 70% success rate even under stripped task descriptions, effectively filling information gaps through empirical profiling. These results highlight iML's potential to bridge the gap between stochastic generation and reliable engineering, marking a meaningful step toward truly AutoML.

</details>


### [52] [An Adaptive Model Selection Framework for Demand Forecasting under Horizon-Induced Degradation to Support Business Strategy and Operations](https://arxiv.org/abs/2602.13939)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: AHSIV是一个自适应混合选择框架，用于处理间歇性和高变异性需求环境中的模型选择问题，通过整合多指标、需求分类和层次偏差优化来解决预测时域导致的排名不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 在结构性需求间歇性、高变异性和多步预测时域的商业环境中，没有单一预测模型能始终表现最佳，且模型排名会随误差指标、需求机制和预测时域而变化，导致多SKU决策中的模糊性。

Method: 提出AHSIV框架，整合了：1）通过MDFH程序调整的缩放和绝对误差指标；2）结构性需求分类；3）多目标帕累托支配；4）层次偏差优化，形成统一的决策架构。

Result: 在Walmart、M3、M4和M5数据集上评估，AHSIV在聚合性能上与最强单指标基线统计等价，同时提高了特定时域最佳模型选择的频率。

Conclusion: 异构需求环境中的模型选择不能视为静态排名问题，时域一致、结构自适应的机制为多SKU预测提供了原则性、操作连贯的解决方案。

Abstract: Business environments characterized by structural demand intermittency, high variability, and multi-step planning horizons require robust and reproducible model selection mechanisms. Empirical evidence shows that no forecasting model is universally dominant and that relative rankings vary across error metrics, demand regimes, and forecast horizons, generating ambiguity in multi-SKU decision contexts. This study proposes AHSIV (Adaptive Hybrid Selector for Intermittency and Variability), a horizon-aware and regime-conditioned model selection framework designed to address horizon-induced ranking instability. The proposed approach integrates scaled and absolute error metrics adjusted through a Metric Degradation by Forecast Horizon (MDFH) procedure, structural demand classification, multi-objective Pareto dominance, and hierarchical bias refinement within a unified decision architecture. The empirical evaluation is conducted on the Walmart, M3, M4, and M5 datasets under multiple train-test partition schemes and twelve-step forecasting horizons. Results indicate that AHSIV achieves statistical equivalence with the strongest monometric baseline in terms of aggregated performance while increasing the frequency of horizon-specific best-model selection. The findings demonstrate that model selection in heterogeneous demand environments cannot be treated as a static ranking problem, and that horizon-consistent, structurally adaptive mechanisms provide a principled, operationally coherent solution for multi-SKU forecasting.

</details>


### [53] [You Can Learn Tokenization End-to-End with Reinforcement Learning](https://arxiv.org/abs/2602.13940)
*Sam Dauncey,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 本文提出了一种使用分数函数估计学习token边界的方法，替代了之前的直通估计方法，在1亿参数规模上表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练流程中，tokenization仍然是一个硬编码的压缩步骤，而架构趋势是越来越端到端。虽然已有工作尝试将这一步骤融入LLM架构，但现有方法（如直通估计）存在理论缺陷。

Method: 使用分数函数估计来学习离散的token边界，直接优化边界划分以最小化损失。采用强化学习技术（如时间折扣）来降低分数函数的方差，使其在实践中可行。

Result: 该方法在1亿参数规模上，在定性和定量评估中都优于先前提出的直通估计方法。

Conclusion: 分数函数估计为学习token边界提供了更优的方法，具有更严格的理论保证，通过强化学习技术降低方差后在实践中表现良好。

Abstract: Tokenization is a hardcoded compression step which remains in the training pipeline of Large Language Models (LLMs), despite a general trend towards architectures becoming increasingly end-to-end. Prior work has shown promising results at scale in bringing this compression step inside the LLMs' architecture with heuristics to draw token boundaries, and also attempts to learn these token boundaries with straight-through estimates, which treat the problem of drawing discrete token boundaries as a continuous one. We show that these token boundaries can instead be learned using score function estimates, which have tighter theoretical guarantees due to directly optimizing the problem of drawing discrete token boundaries to minimize loss. We observe that techniques from reinforcement learning, such as time discounting, are necessary to reduce the variance of this score function sufficiently to make it practicable. We demonstrate that the resultant method outperforms prior proposed straight-through estimates, both qualitatively and quantitatively at the $100$ million parameter scale.

</details>


### [54] [Experiential Reinforcement Learning](https://arxiv.org/abs/2602.13949)
*Taiwei Shi,Sihao Chen,Bowen Jiang,Linxin Song,Longqi Yang,Jieyu Zhao*

Main category: cs.LG

TL;DR: ERL（体验式强化学习）通过嵌入经验-反思-巩固循环，将环境反馈转化为结构化行为修正，提升语言模型在稀疏延迟奖励任务中的学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为语言模型从环境奖励或反馈中学习的主要方法，但实际应用中环境反馈通常是稀疏且延迟的。学习这种信号很困难，因为语言模型必须隐式推断观察到的失败应如何转化为未来迭代的行为改变。

Method: 引入ERL训练范式，在强化学习过程中嵌入显式的经验-反思-巩固循环：模型生成初始尝试→接收环境反馈→产生反思指导第二次尝试→成功结果被强化并内化到基础策略中。

Result: 在稀疏奖励控制环境和智能推理基准测试中，ERL相比强基线持续提升学习效率和最终性能：在复杂多步环境中提升高达81%，在工具使用推理任务中提升高达11%。

Conclusion: 将显式自我反思整合到策略训练中，为将反馈转化为持久行为改进提供了实用机制，改善探索、稳定优化，且部署时无需额外推理成本。

Abstract: Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.

</details>


### [55] [QuRL: Efficient Reinforcement Learning with Quantized Rollout](https://arxiv.org/abs/2602.13953)
*Yuhang Li,Reena Elangovan,Xin Dong,Priyadarshini Panda,Brucek Khailany*

Main category: cs.LG

TL;DR: 提出QuRL方法，使用量化actor加速RL训练中的rollout过程，解决训练崩溃和权重更新问题，实现20-80%的rollout加速


<details>
  <summary>Details</summary>
Motivation: 在RLVR训练推理大语言模型时，由于自回归解码特性，rollout过程占用了高达70%的训练时间，成为效率瓶颈

Method: 提出量化强化学习QuRL：1) 自适应裁剪范围(ACR)动态调整裁剪比例防止训练崩溃；2) 不变缩放技术减少量化噪声，增强权重更新

Result: 在DeepScaleR和DAPO上使用INT8和FP8量化实验，实现了20%到80%的rollout加速

Conclusion: QuRL通过量化actor有效加速RL训练中的rollout过程，解决了量化带来的训练稳定性和权重更新问题，显著提升训练效率

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a trending paradigm for training reasoning large language models (LLMs). However, due to the autoregressive decoding nature of LLMs, the rollout process becomes the efficiency bottleneck of RL training, consisting of up to 70\% of the total training time. In this work, we propose Quantized Reinforcement Learning (QuRL) that uses a quantized actor for accelerating the rollout. We address two challenges in QuRL. First, we propose Adaptive Clipping Range (ACR) that dynamically adjusts the clipping ratio based on the policy ratio between the full-precision actor and the quantized actor, which is essential for mitigating long-term training collapse. Second, we identify the weight update problem, where weight changes between RL steps are extremely small, making it difficult for the quantization operation to capture them effectively. We mitigate this problem through the invariant scaling technique that reduces quantization noise and increases weight update. We evaluate our method with INT8 and FP8 quantization experiments on DeepScaleR and DAPO, and achieve 20% to 80% faster rollout during training.

</details>


### [56] [Chemical Language Models for Natural Products: A State-Space Model Approach](https://arxiv.org/abs/2602.13958)
*Ho-Hsuan Wang,Afnan Sultan,Andrea Volkamer,Dietrich Klakow*

Main category: cs.LG

TL;DR: 该研究开发了针对天然产物(NPs)的化学语言模型(NPCLMs)，首次系统比较了选择性状态空间模型(Mamba/Mamba-2)与Transformer(GPT)在天然产物任务上的表现，使用8种分词策略，在约100万NPs数据集上进行预训练。


<details>
  <summary>Details</summary>
Motivation: 天然产物在药物发现中很重要，但当前语言模型主要关注一般分子性质预测和小分子生成，对天然产物的研究不足。需要开发专门针对天然产物的化学语言模型来填补这一空白。

Method: 使用约100万天然产物数据集，预训练状态空间模型(Mamba和Mamba-2)并与Transformer基线(GPT)比较。采用8种分词策略：字符级、Atom-in-SMILES(AIS)、字节对编码(BPE)和NP-specific BPE。评估分子生成(有效性、独特性、新颖性)和性质预测(膜渗透性、味道、抗癌活性)，使用MCC和AUC-ROC指标。

Result: Mamba在分子生成方面比Mamba-2和GPT多生成1-2%的有效和独特分子，长程依赖错误更少；GPT生成的结构略新颖。在性质预测方面，Mamba变体在随机分割下比GPT高0.02-0.04 MCC，在骨架分割下性能相当。领域特定预训练在约100万NPs数据集上能达到在100倍更大数据集上训练模型的性能。

Conclusion: 针对天然产物的领域特定预训练能显著提升模型性能，选择性状态空间模型在天然产物任务上表现优于Transformer，特别是在分子生成方面。较小的领域特定数据集训练能达到大规模通用数据集训练的效果。

Abstract: Language models are widely used in chemistry for molecular property prediction and small-molecule generation, yet Natural Products (NPs) remain underexplored despite their importance in drug discovery. To address this gap, we develop NP-specific chemical language models (NPCLMs) by pre-training state-space models (Mamba and Mamba-2) and comparing them with transformer baselines (GPT). Using a dataset of about 1M NPs, we present the first systematic comparison of selective state-space models and transformers for NP-focused tasks, together with eight tokenization strategies including character-level, Atom-in-SMILES (AIS), byte-pair encoding (BPE), and NP-specific BPE. We evaluate molecule generation (validity, uniqueness, novelty) and property prediction (membrane permeability, taste, anti-cancer activity) using MCC and AUC-ROC. Mamba generates 1-2 percent more valid and unique molecules than Mamba-2 and GPT, with fewer long-range dependency errors, while GPT yields slightly more novel structures. For property prediction, Mamba variants outperform GPT by 0.02-0.04 MCC under random splits, while scaffold splits show comparable performance. Results demonstrate that domain-specific pre-training on about 1M NPs can match models trained on datasets over 100 times larger.

</details>


### [57] [Steady-State Behavior of Constant-Stepsize Stochastic Approximation: Gaussian Approximation and Tail Bounds](https://arxiv.org/abs/2602.13960)
*Zedong Wang,Yuyang Wang,Ijay Narang,Felix Wang,Yuzhou Wang,Siva Theja Maguluri*

Main category: cs.LG

TL;DR: 论文为固定步长随机逼近算法提供了非渐近误差界，证明稳态分布与高斯极限之间的Wasserstein距离为O(α^{1/2}log(1/α))，并推导了Berry-Esseen型尾界


<details>
  <summary>Details</summary>
Motivation: 固定步长随机逼近算法在计算效率上广泛应用，但稳态分布难以精确分析。现有理论仅提供步长趋于0时的渐近高斯极限，缺乏固定步长下的实用误差界，限制了实际应用中的性能评估

Method: 首先建立通用定理，在漂移正则性和噪声矩条件下，用Wasserstein距离度量中心化缩放稳态与高斯分布的距离；然后具体应用于三种典型设置：SGD（强凸光滑目标）、线性SA、压缩非线性SA；最后推导Berry-Esseen型尾界

Result: 获得维度依赖和步长依赖的显式误差界：Wasserstein距离为O(α^{1/2}log(1/α))；对于SGD在非强凸情形，识别出非高斯（Gibbs）极限律；数值验证了理论结果

Conclusion: 论文为固定步长随机逼近提供了首个非渐近误差分析框架，建立了稳态分布与高斯极限之间的定量关系，扩展了传统渐近理论，为实际算法性能评估提供了理论工具

Abstract: Constant-stepsize stochastic approximation (SA) is widely used in learning for computational efficiency. For a fixed stepsize, the iterates typically admit a stationary distribution that is rarely tractable. Prior work shows that as the stepsize $α\downarrow 0$, the centered-and-scaled steady state converges weakly to a Gaussian random vector. However, for fixed $α$, this weak convergence offers no usable error bound for approximating the steady-state by its Gaussian limit. This paper provides explicit, non-asymptotic error bounds for fixed $α$. We first prove general-purpose theorems that bound the Wasserstein distance between the centered-scaled steady state and an appropriate Gaussian distribution, under regularity conditions for drift and moment conditions for noise. To ensure broad applicability, we cover both i.i.d. and Markovian noise models. We then instantiate these theorems for three representative SA settings: (1) stochastic gradient descent (SGD) for smooth strongly convex objectives, (2) linear SA, and (3) contractive nonlinear SA. We obtain dimension- and stepsize-dependent, explicit bounds in Wasserstein distance of order $α^{1/2}\log(1/α)$ for small $α$. Building on the Wasserstein approximation error, we further derive non-uniform Berry--Esseen-type tail bounds that compare the steady-state tail probability to Gaussian tails. We achieve an explicit error term that decays in both the deviation level and stepsize $α$. We adapt the same analysis for SGD beyond strongly convexity and study general convex objectives. We identify a non-Gaussian (Gibbs) limiting law under the correct scaling, which is validated numerically, and provide a corresponding pre-limit Wasserstein error bound.

</details>


### [58] [KoopGen: Koopman Generator Networks for Representing and Predicting Dynamical Systems with Continuous Spectra](https://arxiv.org/abs/2602.14011)
*Liangyu Su,Jun Shu,Rui Liu,Deyu Meng,Zongben Xu*

Main category: cs.LG

TL;DR: KoopGen：基于生成器的神经Koopman框架，通过状态相关的Koopman生成器表示高维时空混沌系统，分离保守传输与耗散过程，提高预测精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型在宽带或连续谱主导的混沌系统中缺乏稳定性、可解释性和可扩展性，而传统Koopman方法依赖有限维假设或显式谱参数化，在高维设置中效果不佳。

Method: 引入KoopGen框架，通过状态相关的Koopman生成器结构化表示动力学，利用笛卡尔分解将算子分解为斜伴随（保守传输）和自伴随（不可逆耗散）分量，并在学习中强制算子理论约束。

Result: 在从非线性振荡器到高维混沌和时空动力学的多种系统中，KoopGen提高了预测精度和稳定性，同时阐明了连续谱动力学的哪些分量具有可解释和可学习的表示。

Conclusion: KoopGen为高维混沌系统提供了更稳定、可解释的Koopman表示框架，通过生成器结构和算子约束实现了对连续谱动力学的有效建模。

Abstract: Representing and predicting high-dimensional and spatiotemporally chaotic dynamical systems remains a fundamental challenge in dynamical systems and machine learning. Although data-driven models can achieve accurate short-term forecasts, they often lack stability, interpretability, and scalability in regimes dominated by broadband or continuous spectra. Koopman-based approaches provide a principled linear perspective on nonlinear dynamics, but existing methods rely on restrictive finite-dimensional assumptions or explicit spectral parameterizations that degrade in high-dimensional settings. Against these issues, we introduce KoopGen, a generator-based neural Koopman framework that models dynamics through a structured, state-dependent representation of Koopman generators. By exploiting the intrinsic Cartesian decomposition into skew-adjoint and self-adjoint components, KoopGen separates conservative transport from irreversible dissipation while enforcing exact operator-theoretic constraints during learning. Across systems ranging from nonlinear oscillators to high-dimensional chaotic and spatiotemporal dynamics, KoopGen improves prediction accuracy and stability, while clarifying which components of continuous-spectrum dynamics admit interpretable and learnable representations.

</details>


### [59] [S2SServiceBench: A Multimodal Benchmark for Last-Mile S2S Climate Services](https://arxiv.org/abs/2602.14017)
*Chenyue Li,Wen Deng,Zhuotao Sun,Mengxi Jin,Hanzhe Cui,Han Li,Shentong Li,Man Kit Yu,Ming Long Lai,Yuhao Yang,Mengqian Lu,Binhang Yuan*

Main category: cs.LG

TL;DR: S2SServiceBench：一个用于评估多模态大语言模型在次季节到季节（S2S）气候服务中"最后一公里"决策支持能力的基准测试，涵盖6个应用领域、10种服务产品、约500个任务。


<details>
  <summary>Details</summary>
Motivation: S2S预报对气候韧性和可持续发展至关重要，但存在"最后一公里"瓶颈：如何将科学预报转化为可信、可操作的气候服务，这需要可靠的多模态理解和不确定性下的决策推理。虽然多模态大语言模型在支持各种工作流方面进展迅速，但尚不清楚它们能否在不确定性下可靠地从业务服务产品生成决策交付物。

Method: 引入S2SServiceBench，这是一个从业务气候服务系统中策划的多模态基准测试，用于评估MLLMs在S2S气候服务中的能力。基准涵盖农业、灾害、能源、金融、健康、航运6个领域的10种服务产品，约150+专家选择的案例，每个案例在三个服务级别实例化，产生约500个任务和1000+评估项。

Result: 使用S2SServiceBench对最先进的MLLMs和智能体进行基准测试，分析不同产品和服务级别的性能，揭示了S2S服务图理解和推理中的持续挑战：可操作信号理解、将不确定性操作化为可执行交接、以及对动态危害的稳定、基于证据的分析和规划。

Conclusion: 该研究为构建未来气候服务智能体提供了可操作指导，同时揭示了当前MLLMs在气候服务决策支持方面的局限性，特别是在不确定性处理和证据基础推理方面需要进一步改进。

Abstract: Subseasonal-to-seasonal (S2S) forecasts play an essential role in providing a decision-critical weeks-to-months planning window for climate resilience and sustainability, yet a growing bottleneck is the last-mile gap: translating scientific forecasts into trusted, actionable climate services, requiring reliable multimodal understanding and decision-facing reasoning under uncertainty. Meanwhile, multimodal large language models (MLLMs) and corresponding agentic paradigms have made rapid progress in supporting various workflows, but it remains unclear whether they can reliably generate decision-making deliverables from operational service products (e.g., actionable signal comprehension, decision-making handoff, and decision analysis & planning) under uncertainty. We introduce S2SServiceBench, a multimodal benchmark for last-mile S2S climate services curated from an operational climate-service system to evaluate this capability. S2SServiceBenchcovers 10 service products with about 150+ expert-selected cases in total, spanning six application domains - Agriculture, Disasters, Energy, Finance, Health, and Shipping. Each case is instantiated at three service levels, yielding around 500 tasks and 1,000+ evaluation items across climate resilience and sustainability applications. Using S2SServiceBench, we benchmark state-of-the-art MLLMs and agents, and analyze performance across products and service levels, revealing persistent challenges in S2S service plot understanding and reasoning - namely, actionable signal comprehension, operationalizing uncertainty into executable handoffs, and stable, evidence-grounded analysis and planning for dynamic hazards-while offering actionable guidance for building future climate-service agents.

</details>


### [60] [EIDOS: Latent-Space Predictive Learning for Time Series Foundation Models](https://arxiv.org/abs/2602.14024)
*Xinxing Zhou,Qingren Yao,Yiji Zhao,Chenghao Liu,Flora Salim,Xiaojie Yuan,Yanlong Wen,Ming Jin*

Main category: cs.LG

TL;DR: EIDOS是一个时间序列基础模型，通过从未来值预测转向潜在空间预测学习，训练Transformer预测潜在表示演化，从而获得结构化、时间一致的潜在状态。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型通过直接预测未来观测值进行预训练，这通常产生弱结构化的潜在表示，捕捉表面噪声而非连贯可预测的时间动态。

Method: 1) 训练因果Transformer预测潜在表示演化；2) 设计轻量聚合分支构建目标表示；3) 采用联合目标函数：潜在空间对齐、观测基础化（将表示锚定到输入信号）和直接预测监督。

Result: 在GIFT-Eval基准测试中，EIDOS缓解了表示空间中的结构碎片化，并实现了最先进的性能。

Conclusion: 约束模型学习可预测的潜在动态是构建更稳健可靠时间序列基础模型的原则性步骤。

Abstract: Most time series foundation models are pretrained by directly predicting future observations, which often yields weakly structured latent representations that capture surface noise rather than coherent and predictable temporal dynamics. In this work, we introduce EIDOS, a foundation model family that shifts pretraining from future value prediction to latent-space predictive learning. We train a causal Transformer to predict the evolution of latent representations, encouraging the emergence of structured and temporally coherent latent states. To ensure stable targets for latent-space learning, we design a lightweight aggregation branch to construct target representations. EIDOS is optimized via a joint objective that integrates latent-space alignment, observational grounding to anchor representations to the input signal, and direct forecasting supervision. On the GIFT-Eval benchmark, EIDOS mitigates structural fragmentation in the representation space and achieves state-of-the-art performance. These results demonstrate that constraining models to learn predictable latent dynamics is a principled step toward more robust and reliable time series foundation models.

</details>


### [61] [UniST-Pred: A Robust Unified Framework for Spatio-Temporal Traffic Forecasting in Transportation Networks Under Disruptions](https://arxiv.org/abs/2602.14049)
*Yue Wang,Areg Karapetyan,Djellel Difallah,Samer Madanat*

Main category: cs.LG

TL;DR: UniST-Pred是一个解耦时空建模的轻量级交通预测框架，通过自适应表示级融合实现鲁棒预测，在真实和模拟数据上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有交通预测模型通常紧密耦合时空建模，导致复杂度高、模块化差，且很少考虑现实部署中的结构和观测不确定性。需要一种既能处理不确定性又保持轻量化的方法。

Method: 提出UniST-Pred统一框架：1）将时间建模与空间表示学习解耦；2）通过自适应表示级融合集成两者；3）使用基于代理的微观交通模拟器（MATSim）构建数据集评估网络断开场景下的鲁棒性。

Result: 在标准交通预测数据集上表现与现有模型相当，在模拟的网络断开场景下保持强预测性能，同时产生可解释的时空表示，且设计轻量。

Conclusion: UniST-Pred通过解耦时空建模和自适应融合，实现了鲁棒、轻量且可解释的交通预测，能有效处理现实世界的不确定性，为智能交通系统提供了实用解决方案。

Abstract: Spatio-temporal traffic forecasting is a core component of intelligent transportation systems, supporting various downstream tasks such as signal control and network-level traffic management. In real-world deployments, forecasting models must operate under structural and observational uncertainties, conditions that are rarely considered in model design. Recent approaches achieve strong short-term predictive performance by tightly coupling spatial and temporal modeling, often at the cost of increased complexity and limited modularity. In contrast, efficient time-series models capture long-range temporal dependencies without relying on explicit network structure. We propose UniST-Pred, a unified spatio-temporal forecasting framework that first decouples temporal modeling from spatial representation learning, then integrates both through adaptive representation-level fusion. To assess robustness of the proposed approach, we construct a dataset based on an agent-based, microscopic traffic simulator (MATSim) and evaluate UniST-Pred under severe network disconnection scenarios. Additionally, we benchmark UniST-Pred on standard traffic prediction datasets, demonstrating its competitive performance against existing well-established models despite a lightweight design. The results illustrate that UniST-Pred maintains strong predictive performance across both real-world and simulated datasets, while also yielding interpretable spatio-temporal representations under infrastructure disruptions. The source code and the generated dataset are available at https://anonymous.4open.science/r/UniST-Pred-EF27

</details>


### [62] [Position Encoding with Random Float Sampling Enhances Length Generalization of Transformers](https://arxiv.org/abs/2602.14050)
*Atsushi Shimizu,Shohei Taniguchi,Yutaka Matsuo*

Main category: cs.LG

TL;DR: 提出随机浮点采样位置编码策略，通过使用随机连续值而非预定义离散索引，解决长度泛化问题，可轻松集成到现有位置编码方法中。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在训练时未见过的输入长度上的性能下降问题（长度泛化问题），避免因位置索引超出训练分布范围导致的分布外问题。

Method: 提出随机浮点采样位置编码策略，使用随机采样的连续值作为位置索引，而非预定义的离散集合，使模型在训练时接触更广泛的索引分布，可应用于绝对正弦编码、RoPE、ALiBi等现有位置编码方法。

Result: 实验证明RFS在长度泛化任务中表现优异，同时在零样本常识推理基准测试中也显示出优越性能。

Conclusion: 随机浮点采样是一种简单而有效的位置编码策略，能显著提升语言模型在未见长度上的泛化能力，且易于集成到现有位置编码框架中。

Abstract: Length generalization is the ability of language models to maintain performance on inputs longer than those seen during pretraining. In this work, we introduce a simple yet powerful position encoding (PE) strategy, Random Float Sampling (RFS), that generalizes well to lengths unseen during pretraining or fine-tuning. In particular, instead of selecting position indices from a predefined discrete set, RFS uses randomly sampled continuous values, thereby avoiding out-of-distribution (OOD) issues on unseen lengths by exposing the model to diverse indices during training. Since assigning indices to tokens is a common and fundamental procedure in widely used PEs, the advantage of RFS can easily be incorporated into, for instance, the absolute sinusoidal encoding, RoPE, and ALiBi. Experiments corroborate its effectiveness by showing that RFS results in superior performance in length generalization tasks as well as zero-shot commonsense reasoning benchmarks.

</details>


### [63] [Decentralized Federated Learning With Energy Harvesting Devices](https://arxiv.org/abs/2602.14051)
*Kai Zhang,Xuanyu Cao,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出了一种用于能量收集无线去中心化联邦学习的完全去中心化策略迭代算法，通过联合设备调度和功率控制加速收敛，同时降低通信开销和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）中设备间的本地训练和模型交换能耗巨大，会快速耗尽设备电池，降低设备运行寿命和学习性能。为了解决这一问题，作者将能量收集技术应用于DFL系统，使边缘设备能够提取环境能量并可持续运行。

Method: 首先推导了带有能量收集的无线DFL的收敛界，表明收敛受部分设备参与和传输丢包的影响，这两者又取决于可用能量供应。为了加速收敛，将联合设备调度和功率控制问题建模为多智能体马尔可夫决策过程（MDP），并提出了一种完全去中心化的策略迭代算法，该算法仅利用两跳邻居设备的局部状态信息，显著降低了通信开销和计算复杂度。

Result: 理论分析表明所提出的去中心化算法具有渐近最优性。在真实世界数据集上的综合数值实验验证了理论结果，并证实了所提算法的有效性。

Conclusion: 通过将能量收集技术与去中心化联邦学习相结合，并开发高效的去中心化算法，可以在保证学习性能的同时显著延长设备运行寿命，实现可持续的边缘智能。

Abstract: Decentralized federated learning (DFL) enables edge devices to collaboratively train models through local training and fully decentralized device-to-device (D2D) model exchanges. However, these energy-intensive operations often rapidly deplete limited device batteries, reducing their operational lifetime and degrading the learning performance. To address this limitation, we apply energy harvesting technique to DFL systems, allowing edge devices to extract ambient energy and operate sustainably. We first derive the convergence bound for wireless DFL with energy harvesting, showing that the convergence is influenced by partial device participation and transmission packet drops, both of which further depend on the available energy supply. To accelerate convergence, we formulate a joint device scheduling and power control problem and model it as a multi-agent Markov decision process (MDP). Traditional MDP algorithms (e.g., value or policy iteration) require a centralized coordinator with access to all device states and exhibit exponential complexity in the number of devices, making them impractical for large-scale decentralized networks. To overcome these challenges, we propose a fully decentralized policy iteration algorithm that leverages only local state information from two-hop neighboring devices, thereby substantially reducing both communication overhead and computational complexity. We further provide a theoretical analysis showing that the proposed decentralized algorithm achieves asymptotic optimality. Finally, comprehensive numerical experiments on real-world datasets are conducted to validate the theoretical results and corroborate the effectiveness of the proposed algorithm.

</details>


### [64] [Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning](https://arxiv.org/abs/2602.14078)
*Yaqian Zhang,Bernhard Pfahringer,Eibe Frank,Albert Bifet*

Main category: cs.LG

TL;DR: 论文提出aEPG方法，通过强化学习视角将分类视为马尔可夫决策过程，直接最小化误分类误差，在参数高效微调中优于传统的交叉熵损失


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练视觉模型在类别增量学习中容易发生灾难性遗忘，现有的参数高效微调方法仍主要依赖交叉熵损失，而交叉熵只是0-1损失的替代目标。作者希望直接优化真正的目标（0-1损失）来提升模型适应能力

Method: 将分类问题建模为一步马尔可夫决策过程，推导出期望策略梯度方法直接最小化误分类误差。基于交叉熵强调低置信度样本而EPG强调高置信度样本的洞察，提出自适应熵退火策略，从探索性学习过渡到利用性学习

Result: aEPG方法在多种基准测试和不同PEFT模块中都优于基于交叉熵的方法。实验表明，输出预测分布的低熵能增强预训练视觉模型的适应能力

Conclusion: 通过强化学习视角直接优化0-1损失比使用交叉熵损失更有效，自适应熵退火策略能平衡探索与利用，提升参数高效微调在类别增量学习中的性能

Abstract: Despite their success, large pretrained vision models remain vulnerable to catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) alleviates this by restricting trainable parameters, yet most approaches still rely on cross-entropy (CE) loss, a surrogate for the 0-1 loss, to learn from new data. We revisit this choice and revive the true objective (0-1 loss) through a reinforcement learning perspective. By formulating classification as a one-step Markov Decision Process, we derive an Expected Policy Gradient (EPG) method that directly minimizes misclassification error with a low-variance gradient estimation. Our analysis shows that CE can be interpreted as EPG with an additional sample-weighting mechanism: CE encourages exploration by emphasizing low-confidence samples, while EPG prioritizes high-confidence ones. Building on this insight, we propose adaptive entropy annealing (aEPG), a training strategy that transitions from exploratory (CE-like) to exploitative (EPG-like) learning. aEPG-based methods outperform CE-based methods across diverse benchmarks and with various PEFT modules. More broadly, we evaluate various entropy regularization methods and demonstrate that lower entropy of the output prediction distribution enhances adaptation in pretrained vision models.

</details>


### [65] [Neural Optimal Transport in Hilbert Spaces: Characterizing Spurious Solutions and Gaussian Smoothing](https://arxiv.org/abs/2602.14086)
*Jae-Hwan Choi,Jiwoo Yoon,Dohyun Kwon,Jaewoong Choi*

Main category: cs.LG

TL;DR: 该论文研究无限维希尔伯特空间中的神经最优传输，通过高斯平滑策略解决半对偶神经OT在非正则设置下产生的虚假解问题，证明了在正则源测度下公式的适定性并恢复唯一的Monge映射。


<details>
  <summary>Details</summary>
Motivation: 在无限维希尔伯特空间中，半对偶神经最优传输在非正则设置下会产生虚假解，无法准确捕捉目标分布，需要解决这一适定性问题。

Method: 使用基于布朗运动的高斯平滑策略扩展半对偶框架，通过正则测度理论分析虚假解问题，并建立平滑测度正则性的严格特征。

Result: 理论证明在正则源测度下，公式是适定的并能恢复唯一的Monge映射；实验表明该方法能有效抑制虚假解，在合成函数数据和时序数据集上优于现有基线方法。

Conclusion: 通过高斯平滑策略解决了无限维希尔伯特空间中神经最优传输的适定性问题，为处理非正则设置提供了理论保证和有效方法。

Abstract: We study Neural Optimal Transport in infinite-dimensional Hilbert spaces. In non-regular settings, Semi-dual Neural OT often generates spurious solutions that fail to accurately capture target distributions. We analytically characterize this spurious solution problem using the framework of regular measures, which generalize Lebesgue absolute continuity in finite dimensions. To resolve ill-posedness, we extend the semi-dual framework via a Gaussian smoothing strategy based on Brownian motion. Our primary theoretical contribution proves that under a regular source measure, the formulation is well-posed and recovers a unique Monge map. Furthermore, we establish a sharp characterization for the regularity of smoothed measures, proving that the success of smoothing depends strictly on the kernel of the covariance operator. Empirical results on synthetic functional data and time-series datasets demonstrate that our approach effectively suppresses spurious solutions and outperforms existing baselines.

</details>


### [66] [Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures](https://arxiv.org/abs/2602.14108)
*Luigi Ciceri,Corrado Mio,Jianyi Lin,Gabriele Gianini*

Main category: cs.LG

TL;DR: 论文提出两种物理信息学习方法(PIPN和PI-GANO)来预测多孔体周围和内部的流动，通过统一损失函数结合自由流区的Navier-Stokes方程和多孔区的Darcy-Forchheimer扩展，在2D管道和3D防风场景中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 预测多孔体周围和内部的流动具有挑战性，因为需要在流体和多孔区域之间耦合物理，并且需要泛化到不同的几何形状和边界条件。传统方法难以处理这种跨区域耦合和几何变化的问题。

Method: 提出两种物理信息学习方法：物理信息PointNets(PIPN)和物理信息几何感知神经算子(PI-GANO)。在统一损失函数中强制执行自由流区的不可压缩Navier-Stokes方程和多孔区的Darcy-Forchheimer扩展，并将网络条件化于几何和材料参数。使用OpenFOAM生成2D管道含多孔障碍物和3D防风场景(树冠和建筑)的数据集。

Result: 通过制造解方法验证管道，在可见和未见形状上均显示低速度和压力误差，准确再现尾流结构。PI-GANO还能泛化到变化的边界条件和参数设置。性能下降主要发生在尖锐界面附近和大梯度区域。

Conclusion: 研究首次系统评估了PIPN/PI-GANO用于同时预测多孔体周围和内部流动的能力，展示了它们在不需针对每个几何形状重新训练的情况下加速设计研究的潜力。

Abstract: Predicting flows that occur both through and around porous bodies is challenging due to coupled physics across fluid and porous regions and the need to generalize across diverse geometries and boundary conditions. We address this problem using two Physics Informed learning approaches: Physics Informed PointNets (PIPN) and Physics Informed Geometry Aware Neural Operator (P-IGANO). We enforce the incompressible Navier Stokes equations in the free-flow region and a Darcy Forchheimer extension in the porous region within a unified loss and condition the networks on geometry and material parameters. Datasets are generated with OpenFOAM on 2D ducts containing porous obstacles and on 3D windbreak scenarios with tree canopies and buildings. We first verify the pipeline via the method of manufactured solutions, then assess generalization to unseen shapes, and for PI-GANO, to variable boundary conditions and parameter settings. The results show consistently low velocity and pressure errors in both seen and unseen cases, with accurate reproduction of the wake structures. Performance degrades primarily near sharp interfaces and in regions with large gradients. Overall, the study provides a first systematic evaluation of PIPN/PI-GANO for simultaneous through-and-around porous flows and shows their potential to accelerate design studies without retraining per geometry.

</details>


### [67] [Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?](https://arxiv.org/abs/2602.14111)
*Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Rogov,Ivan Oseledets,Elena Tutubalina*

Main category: cs.LG

TL;DR: SAEs在解释神经网络方面表现不佳：在合成数据中仅恢复9%的真实特征，在真实数据中与随机基线表现相当，表明当前SAEs无法可靠分解模型内部机制。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）被认为是解释神经网络的有前景工具，但越来越多的下游任务负面结果让人质疑SAEs是否真的能恢复有意义的特征。本研究旨在直接评估SAEs在特征恢复方面的有效性。

Method: 采用两种互补评估方法：1）在已知真实特征的合成设置中测试SAEs的特征恢复能力；2）在真实激活中引入三种基线方法，将SAE特征方向或其激活模式约束为随机值，并与完全训练的SAEs进行对比。

Result: 在合成数据中，SAEs仅恢复9%的真实特征，尽管达到71%的解释方差；在真实数据中，随机基线在可解释性（0.87 vs 0.90）、稀疏探测（0.69 vs 0.72）和因果编辑（0.73 vs 0.72）方面与完全训练的SAEs表现相当。

Conclusion: 当前状态的SAEs无法可靠地分解模型的内部机制，即使重建效果良好也不能保证特征恢复的有效性，需要重新评估和改进SAEs作为解释工具的方法。

Abstract: Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only $9\%$ of true features despite achieving $71\%$ explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms.

</details>


### [68] [ROAST: Rollout-based On-distribution Activation Steering Technique](https://arxiv.org/abs/2602.14143)
*Xuanbo Su,Hao Luo,Yingfang Zhang,Lijun Zhang*

Main category: cs.LG

TL;DR: ROAST是一种基于模型自身分布内滚动的激活引导技术，通过连续软缩放和分组均值归一化来避免硬稀疏化，在各种模型和任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的激活引导方法依赖于分布外监督和离散掩码，导致干预脆弱。需要一种更鲁棒的、基于模型自身分布内行为的激活引导技术。

Method: ROAST通过ROC从模型自身的分布内滚动中估计引导方向，采用连续软缩放（CSS）避免硬稀疏化，并使用分组均值归一化平衡不同样本的贡献。

Result: 在0.6B到32B的各种模型上，ROAST在多样化任务上持续提升性能（如Qwen3-0.6B在GSM8K上提升9.7%，GLM4-32B在TruthfulQA上提升12.1%），CSS能更好地保留激活能量。

Conclusion: ROAST提供了一种更鲁棒的激活引导方法，通过分布内估计和适当的归一化技术，有效解决了现有方法中激活幅度不平衡和干预脆弱的问题。

Abstract: Activation steering provides parameter-efficient control over large language models (LLMs) at inference time, but many methods rely on off-distribution supervision and discrete masking, leading to brittle interventions. We propose ROAST (Rollout-based On-distribution Activation Steering Technique), which estimates steering directions from the model's own on-distribution rollouts via ROC and avoids hard sparsification via Continuous Soft Scaling (CSS) and Grouped Mean Normalization. Our empirical analysis reveals that while activation magnitude correlates moderately with directional consistency, the variance in magnitude is significant and often disproportionate to semantic quality. This suggests that high-magnitude activations risk dominating the global steering direction if not properly normalized. To address this, ROAST employs grouped normalization to balance contributions across samples, ensuring a more robust estimation of the consensus steering direction. Across models (0.6B to 32B), ROAST consistently improves performance on diverse tasks (e.g., +9.7% on GSM8K for Qwen3-0.6B and +12.1% on TruthfulQA for GLM4-32B), and analyses show that CSS better preserves activation energy.

</details>


### [69] [A Penalty Approach for Differentiation Through Black-Box Quadratic Programming Solvers](https://arxiv.org/abs/2602.14154)
*Yuxuan Linghu,Zhiyuan Liu,Qi Deng*

Main category: cs.LG

TL;DR: dXPP：基于惩罚的二次规划可微优化框架，将求解与微分分离，提高计算效率和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有基于KKT系统的可微优化方法在大规模问题上存在计算成本和数值鲁棒性问题，需要更高效、更稳健的解决方案

Method: 提出dXPP惩罚框架：前向传递使用任意黑盒QP求解器；反向传递将解映射到平滑近似惩罚问题，通过隐式微分仅需求解更小的线性系统

Result: 在随机QP、大规模稀疏投影问题、多期投资组合优化等任务上，dXPP与KKT方法竞争力相当，在大规模问题上实现显著加速

Conclusion: dXPP通过解耦QP求解与微分，避免了KKT显式微分的困难，显著提高了计算效率和鲁棒性，适用于大规模可微优化问题

Abstract: Differentiating through the solution of a quadratic program (QP) is a central problem in differentiable optimization. Most existing approaches differentiate through the Karush--Kuhn--Tucker (KKT) system, but their computational cost and numerical robustness can degrade at scale. To address these limitations, we propose dXPP, a penalty-based differentiation framework that decouples QP solving from differentiation. In the solving step (forward pass), dXPP is solver-agnostic and can leverage any black-box QP solver. In the differentiation step (backward pass), we map the solution to a smooth approximate penalty problem and implicitly differentiate through it, requiring only the solution of a much smaller linear system in the primal variables. This approach bypasses the difficulties inherent in explicit KKT differentiation and significantly improves computational efficiency and robustness. We evaluate dXPP on various tasks, including randomly generated QPs, large-scale sparse projection problems, and a real-world multi-period portfolio optimization task. Empirical results demonstrate that dXPP is competitive with KKT-based differentiation methods and achieves substantial speedups on large-scale problems.

</details>


### [70] [Synergistic Intra- and Cross-Layer Regularization Losses for MoE Expert Specialization](https://arxiv.org/abs/2602.14159)
*Rizhen Hu,Yuan Cao,Boao Kong,Mou Sun,Kun Yuan*

Main category: cs.LG

TL;DR: 提出两种即插即用的正则化损失函数，无需修改MoE架构即可提升专家专业化和路由效率，通过减少专家重叠和建立跨层连贯路径来改善模型性能


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家模型存在专家重叠问题，导致表示冗余和路由模糊，严重降低了模型容量利用率。现有架构解决方案需要大量结构修改且仅依赖层内信号

Method: 提出两种正则化损失：1) 层内专业化损失，惩罚相同token上专家SwiGLU激活的余弦相似度；2) 跨层耦合损失，最大化相邻层间的联合Top-k路由概率。两种损失与标准负载均衡损失正交，兼容多种MoE架构

Result: 在预训练、微调和零样本基准测试中均获得一致的任务提升，实现了更高的专家专业化程度和更低熵的路由，这些改进通过更稳定的专家路径转化为更快的推理速度

Conclusion: 提出的两种即插即用正则化损失有效解决了MoE模型的专家重叠问题，无需修改架构即可显著提升专家专业化和路由效率，为MoE模型的优化提供了灵活高效的解决方案

Abstract: Sparse Mixture-of-Experts (MoE) models scale Transformers efficiently but suffer from expert overlap -- redundant representations across experts and routing ambiguity, resulting in severely underutilized model capacity. While architectural solutions like DeepSeekMoE promote specialization, they require substantial structural modifications and rely solely on intra-layer signals. In this paper, we propose two plug-and-play regularization losses that enhance MoE specialization and routing efficiency without modifying router or model architectures. First, an intra-layer specialization loss penalizes cosine similarity between experts' SwiGLU activations on identical tokens, encouraging experts to specialize in complementary knowledge. Second, a cross-layer coupling loss maximizes joint Top-$k$ routing probabilities across adjacent layers, establishing coherent expert pathways through network depth while reinforcing intra-layer expert specialization. Both losses are orthogonal to the standard load-balancing loss and compatible with both the shared-expert architecture in DeepSeekMoE and vanilla top-$k$ MoE architectures. We implement both losses as a drop-in Megatron-LM module. Extensive experiments across pre-training, fine-tuning, and zero-shot benchmarks demonstrate consistent task gains, higher expert specialization, and lower-entropy routing; together, these improvements translate into faster inference via more stable expert pathways.

</details>


### [71] [When Benchmarks Lie: Evaluating Malicious Prompt Classifiers Under True Distribution Shift](https://arxiv.org/abs/2602.14161)
*Max Fomin*

Main category: cs.LG

TL;DR: 该论文提出Leave-One-Dataset-Out (LODO)评估方法，揭示传统评估严重高估提示攻击检测性能，发现28%特征为数据集依赖的捷径特征，现有防护系统在间接攻击上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理处理越来越多来自电子邮件、文档、工具输出和外部API的不受信任数据，检测提示注入和越狱攻击变得至关重要。然而当前评估实践和生产系统存在根本性限制，需要更可靠的评估方法和更好的攻击检测方案。

Method: 1) 使用包含有害请求、越狱、间接提示注入和提取攻击的18个多样化数据集构建基准；2) 提出Leave-One-Dataset-Out (LODO)评估方法测量真正的分布外泛化能力；3) 分析稀疏自编码器(SAE)特征系数识别数据集依赖的捷径特征；4) 系统比较生产防护系统(PromptGuard 2, LlamaGuard)和LLM-as-judge方法。

Result: 1) 传统同一数据集划分评估严重高估性能：AUC平均高估8.4个百分点，各数据集准确率差距1-25%；2) 28%的顶级特征是数据集依赖的捷径特征；3) 现有防护系统在针对代理的间接攻击上检测率仅7-37%；4) PromptGuard 2和LlamaGuard因架构限制无法评估代理工具注入；5) LODO稳定的SAE特征提供更可靠的分类器决策解释。

Conclusion: LODO评估协议应成为提示攻击检测研究的适当标准，传统评估方法严重高估泛化性能。需要开发更鲁棒的检测方法，特别是针对间接攻击和代理工具注入场景。LODO稳定的SAE特征有助于过滤数据集伪影，提供更可靠的解释。

Abstract: Detecting prompt injection and jailbreak attacks is critical for deploying LLM-based agents safely. As agents increasingly process untrusted data from emails, documents, tool outputs, and external APIs, robust attack detection becomes essential. Yet current evaluation practices and production systems have fundamental limitations. We present a comprehensive analysis using a diverse benchmark of 18 datasets spanning harmful requests, jailbreaks, indirect prompt injections, and extraction attacks. We propose Leave-One-Dataset-Out (LODO) evaluation to measure true out-of-distribution generalization, revealing that the standard practice of train-test splits from the same dataset sources severely overestimates performance: aggregate metrics show an 8.4 percentage point AUC inflation, but per-dataset gaps range from 1% to 25% accuracy-exposing heterogeneous failure modes. To understand why classifiers fail to generalize, we analyze Sparse Auto-Encoder (SAE) feature coefficients across LODO folds, finding that 28% of top features are dataset-dependent shortcuts whose class signal depends on specific dataset compositions rather than semantic content. We systematically compare production guardrails (PromptGuard 2, LlamaGuard) and LLM-as-judge approaches on our benchmark, finding all three fail on indirect attacks targeting agents (7-37% detection) and that PromptGuard 2 and LlamaGuard cannot evaluate agentic tool injection due to architectural limitations. Finally, we show that LODO-stable SAE features provide more reliable explanations for classifier decisions by filtering dataset artifacts. We release our evaluation framework at https://github.com/maxf-zn/prompt-mining to establish LODO as the appropriate protocol for prompt attack detection research.

</details>


### [72] [Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling](https://arxiv.org/abs/2602.14169)
*Yiran Guo,Zhongjian Qiao,Yingqi Xie,Jie Liu,Dan Ye,Ruiqing Zhang,Shuang Qiu,Lijie Xu*

Main category: cs.LG

TL;DR: 提出Deep Dense Exploration (DDE)策略，专注于探索失败轨迹中的深度可恢复状态（pivots），以解决强化学习中探索效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大型语言模型强化学习中存在探索效率低的问题：GRPO仅从根节点采样，导致高概率轨迹饱和而深度错误状态探索不足；基于树的方法盲目分散采样预算，导致采样稀释，无法发现罕见正确后缀并破坏局部基线。

Method: 提出DDE策略，具体实现为DEEP-GRPO，包含三个关键创新：1）轻量级数据驱动的效用函数自动平衡可恢复性和深度偏差以识别pivot状态；2）在每个pivot处进行局部密集重采样以增加发现正确后续轨迹的概率；3）解耦全局策略学习和局部校正更新的双流优化目标。

Result: 在数学推理基准测试中，该方法一致优于GRPO、基于树的方法和其他强基线。

Conclusion: 通过专注于深度可恢复状态的密集探索，DDE策略显著提高了强化学习中的探索效率，在数学推理任务中取得了优越性能。

Abstract: Effective exploration is a key challenge in reinforcement learning for large language models: discovering high-quality trajectories within a limited sampling budget from the vast natural language sequence space. Existing methods face notable limitations: GRPO samples exclusively from the root, saturating high-probability trajectories while leaving deep, error-prone states under-explored. Tree-based methods blindly disperse budgets across trivial or unrecoverable states, causing sampling dilution that fails to uncover rare correct suffixes and destabilizes local baselines. To address this, we propose Deep Dense Exploration (DDE), a strategy that focuses exploration on $\textit{pivots}$-deep, recoverable states within unsuccessful trajectories. We instantiate DDE with DEEP-GRPO, which introduces three key innovations: (1) a lightweight data-driven utility function that automatically balances recoverability and depth bias to identify pivot states; (2) local dense resampling at each pivot to increase the probability of discovering correct subsequent trajectories; and (3) a dual-stream optimization objective that decouples global policy learning from local corrective updates. Experiments on mathematical reasoning benchmarks demonstrate that our method consistently outperforms GRPO, tree-based methods, and other strong baselines.

</details>


### [73] [TS-Haystack: A Multi-Scale Retrieval Benchmark for Time Series Language Models](https://arxiv.org/abs/2602.14200)
*Nicolas Zumarraga,Thomas Kaar,Ning Wang,Maxwell A. Xu,Max Rosenblattl,Markus Kreft,Kevin O'Sullivan,Paul Schmiedmayer,Patrick Langer,Robert Jakob*

Main category: cs.LG

TL;DR: TS-Haystack：针对时间序列语言模型的长上下文检索基准，揭示现有模型在长序列中时间粒度丢失的问题，分类性能与检索性能存在矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列语言模型通常在短序列上训练和评估，而真实世界的时间序列传感器数据可能长达数百万个数据点。这种不匹配需要在严格计算约束下进行精确的时间定位，而当前基准无法捕捉这一需求。

Method: 引入TS-Haystack基准，通过将短活动片段嵌入到更长的纵向加速度计记录中，实现受控的"针插入"测试。基准包含10种任务类型，涵盖四个类别：直接检索、时间推理、多步推理和上下文异常检测。

Result: 实验发现，随着上下文长度增加，现有模型的时间编码器会丢失时间粒度，产生任务依赖效应：压缩有助于分类但损害局部事件的检索。学习到的潜在压缩在高达176倍的压缩比下能保持或改善分类准确率，但检索性能随上下文长度增加而下降。

Conclusion: 需要设计能够解耦序列长度与计算复杂度同时保持时间保真度的架构，以解决长上下文时间序列检索的挑战。

Abstract: Time Series Language Models (TSLMs) are emerging as unified models for reasoning over continuous signals in natural language. However, long-context retrieval remains a major limitation: existing models are typically trained and evaluated on short sequences, while real-world time-series sensor streams can span millions of datapoints. This mismatch requires precise temporal localization under strict computational constraints, a regime that is not captured by current benchmarks. We introduce TS-Haystack, a long-context temporal retrieval benchmark comprising ten task types across four categories: direct retrieval, temporal reasoning, multi-step reasoning and contextual anomaly. The benchmark uses controlled needle insertion by embedding short activity bouts into longer longitudinal accelerometer recordings, enabling systematic evaluation across context lengths ranging from seconds to 2 hours per sample. We hypothesize that existing TSLM time series encoders overlook temporal granularity as context length increases, creating a task-dependent effect: compression aids classification but impairs retrieval of localized events. Across multiple model and encoding strategies, we observe a consistent divergence between classification and retrieval behavior. Learned latent compression preserves or improves classification accuracy at compression ratios up to 176$\times$, but retrieval performance degrades with context length, incurring in the loss of temporally localized information. These results highlight the importance of architectural designs that decouple sequence length from computational complexity while preserving temporal fidelity.

</details>


### [74] [Fast Catch-Up, Late Switching: Optimal Batch Size Scheduling via Functional Scaling Laws](https://arxiv.org/abs/2602.14208)
*Jinbo Wang,Binghui Li,Zhanpeng Zhou,Mingze Wang,Yuxuan Sun,Jiaqi Zhang,Xunliang Cai,Lei Wu*

Main category: cs.LG

TL;DR: 论文提出基于功能缩放定律框架分析批量大小调度，发现最优调度结构取决于任务难度：简单任务应持续增加批量大小，困难任务应保持小批量训练并在后期切换到大批量，这归因于快速追赶效应。


<details>
  <summary>Details</summary>
Motivation: 批量大小调度在大规模深度学习训练中至关重要，影响优化动态和计算效率，但其理论基础仍不明确。需要从理论角度理解批量大小调度的最优策略。

Method: 采用功能缩放定律框架分析批量大小调度，理论推导最优调度结构，提出快速追赶效应机制解释后期切换现象，并通过大规模语言模型预训练实验验证理论预测。

Result: 理论分析表明：简单任务的最优调度应持续增加批量大小，困难任务应保持小批量并在后期切换到大批量。实验验证了后期切换调度在密集和MoE架构（最大11亿参数、1万亿token）上均优于恒定批量大小和早期切换基线。

Conclusion: 功能缩放定律为批量大小调度提供了理论框架，揭示了任务难度决定最优调度结构。后期切换策略可显著减少数据消耗而不牺牲性能，快速追赶效应解释了这一现象，为大规模深度学习训练提供了实用指导。

Abstract: Batch size scheduling (BSS) plays a critical role in large-scale deep learning training, influencing both optimization dynamics and computational efficiency. Yet, its theoretical foundations remain poorly understood. In this work, we show that the functional scaling law (FSL) framework introduced in Li et al. (2025a) provides a principled lens for analyzing BSS. Specifically, we characterize the optimal BSS under a fixed data budget and show that its structure depends sharply on task difficulty. For easy tasks, optimal schedules keep increasing batch size throughout. In contrast, for hard tasks, the optimal schedule maintains small batch sizes for most of training and switches to large batches only in a late stage. To explain the emergence of late switching, we uncover a dynamical mechanism -- the fast catch-up effect -- which also manifests in large language model (LLM) pretraining. After switching from small to large batches, the loss rapidly aligns with the constant large-batch trajectory. Using FSL, we show that this effect stems from rapid forgetting of accumulated gradient noise, with the catch-up speed determined by task difficulty. Crucially, this effect implies that large batches can be safely deferred to late training without sacrificing performance, while substantially reducing data consumption. Finally, extensive LLM pretraining experiments -- covering both Dense and MoE architectures with up to 1.1B parameters and 1T tokens -- validate our theoretical predictions. Across all settings, late-switch schedules consistently outperform constant-batch and early-switch baselines.

</details>


### [75] [MAGE: All-[MASK] Block Already Knows Where to Look in Diffusion LLM](https://arxiv.org/abs/2602.14209)
*Omin Kwon,Yeonjae Kim,Doyeon Kim,Minseo Kim,Yeonhong Park,Jae W. Lee*

Main category: cs.LG

TL;DR: MAGE提出了一种针对块扩散LLM的稀疏注意力方法，利用首次去噪步骤的注意力模式预测重要KV条目，实现训练自由的稀疏去噪，在长上下文任务中达到接近无损的精度和3-4倍加速。


<details>
  <summary>Details</summary>
Motivation: 块扩散LLM在长上下文生成中面临KV缓存内存访问瓶颈问题。现有的动态稀疏注意力方法主要针对自回归LLM设计，依赖近似重要性估计，在块扩散场景下表现不佳。

Method: MAGE利用块扩散的独特特性：首次全[MASK]去噪步骤的注意力模式能可靠预测重要KV条目和预算需求。通过单次精确注意力传递和训练自由的稀疏去噪重用，结合轻量级微调策略增强[MASK]引导模式。

Result: 在LongBench和Needle-in-a-Haystack等长上下文基准测试中，MAGE以少量KV预算实现接近无损的精度，获得3-4倍端到端加速，持续优于自回归导向的稀疏注意力基线。

Conclusion: MAGE有效解决了块扩散LLM在长上下文中的内存瓶颈问题，通过利用首次去噪步骤的注意力模式实现高效稀疏注意力，为块扩散模型提供了实用的加速解决方案。

Abstract: Block diffusion LLMs are emerging as a promising next paradigm for language generation, but their use of KV caching makes memory access a dominant bottleneck in long-context settings. While dynamic sparse attention has been actively explored, existing methods designed for autoregressive LLMs rely on approximate importance estimation and perform poorly when adapted to block diffusion. This work identifies a key opportunity unique to block diffusion: attention at the first All-[MASK] denoising step reliably predicts important KV entries and budget requirements, enabling MAGE to perform a single exact attention pass per block and reuse it for training-free sparse denoising. Across long-context benchmarks including LongBench and Needle-in-a-Haystack, MAGE achieves near-lossless accuracy with a fraction of the KV budget while delivering up to 3-4x end-to-end speedup, consistently outperforming AR-oriented sparse attention baselines. A lightweight fine-tuning strategy further strengthens [MASK]-guided patterns with minimal cost, requiring only a few hours of training on a single NVIDIA H100 GPU for both 1.5B and 7B models.

</details>


### [76] [Robust multi-task boosting using clustering and local ensembling](https://arxiv.org/abs/2602.14231)
*Seyedsaman Emami,Daniel Hernández-Lobato,Gonzalo Martínez-Muñoz*

Main category: cs.LG

TL;DR: 提出RMB-CLE框架，通过基于误差的任务聚类和局部集成实现鲁棒多任务学习，避免负迁移


<details>
  <summary>Details</summary>
Motivation: 传统多任务学习方法在任务不相关或存在噪声时容易发生负迁移，需要更鲁棒的框架来智能共享信息

Method: RMB-CLE框架：1）基于交叉任务误差计算任务相似度，将风险分解为功能不匹配和不可约噪声；2）使用凝聚聚类自适应分组任务；3）在每个聚类内使用局部集成实现鲁棒知识共享

Result: 在合成数据中能恢复真实聚类，在多种真实世界和合成基准测试中持续优于多任务、单任务和基于池化的集成方法

Conclusion: RMB-CLE不仅是聚类和提升的组合，而是一个通用可扩展的框架，为鲁棒多任务学习建立了新基础

Abstract: Multi-Task Learning (MTL) aims to boost predictive performance by sharing information across related tasks, yet conventional methods often suffer from negative transfer when unrelated or noisy tasks are forced to share representations. We propose Robust Multi-Task Boosting using Clustering and Local Ensembling (RMB-CLE), a principled MTL framework that integrates error-based task clustering with local ensembling. Unlike prior work that assumes fixed clusters or hand-crafted similarity metrics, RMB-CLE derives inter-task similarity directly from cross-task errors, which admit a risk decomposition into functional mismatch and irreducible noise, providing a theoretically grounded mechanism to prevent negative transfer. Tasks are grouped adaptively via agglomerative clustering, and within each cluster, a local ensemble enables robust knowledge sharing while preserving task-specific patterns. Experiments show that RMB-CLE recovers ground-truth clusters in synthetic data and consistently outperforms multi-task, single-task, and pooling-based ensemble methods across diverse real-world and synthetic benchmarks. These results demonstrate that RMB-CLE is not merely a combination of clustering and boosting but a general and scalable framework that establishes a new basis for robust multi-task learning.

</details>


### [77] [Evaluating LLMs in Finance Requires Explicit Bias Consideration](https://arxiv.org/abs/2602.14233)
*Yaxuan Kong,Hoyoung Lee,Yoontae Hwang,Alejandro Lopez-Lira,Bradford Levy,Dhagash Mehta,Qingsong Wen,Chanyeol Choi,Yongjae Lee,Stefan Zohren*

Main category: cs.LG

TL;DR: 论文指出金融LLM评估存在五大偏见问题，提出结构有效性框架和检查清单来解决这些偏见


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地应用于金融工作流，但评估实践滞后。金融特定偏见会夸大性能、污染回测结果，使报告结果对部署声明毫无用处

Method: 识别金融LLM应用中的五大偏见（前瞻偏见、幸存者偏见、叙事偏见、目标偏见、成本偏见），审查2023-2025年164篇论文，提出结构有效性框架和评估检查清单

Result: 发现没有单一偏见在超过28%的研究中被讨论，偏见问题普遍存在且经常复合产生有效性幻觉

Conclusion: 金融LLM系统中的偏见需要明确关注，在支持部署声明前应强制执行结构有效性，提出了偏诊断和未来系统设计的最低要求框架

Abstract: Large Language Models (LLMs) are increasingly integrated into financial workflows, but evaluation practice has not kept up. Finance-specific biases can inflate performance, contaminate backtests, and make reported results useless for any deployment claim. We identify five recurring biases in financial LLM applications. They include look-ahead bias, survivorship bias, narrative bias, objective bias, and cost bias. These biases break financial tasks in distinct ways and they often compound to create an illusion of validity. We reviewed 164 papers from 2023 to 2025 and found that no single bias is discussed in more than 28 percent of studies. This position paper argues that bias in financial LLM systems requires explicit attention and that structural validity should be enforced before any result is used to support a deployment claim. We propose a Structural Validity Framework and an evaluation checklist with minimal requirements for bias diagnosis and future system design. The material is available at https://github.com/Eleanorkong/Awesome-Financial-LLM-Bias-Mitigation.

</details>


### [78] [Multi-Agent Debate: A Unified Agentic Framework for Tabular Anomaly Detection](https://arxiv.org/abs/2602.14251)
*Pinqiao Wang,Sheng Li*

Main category: cs.LG

TL;DR: MAD是一个多智能体辩论框架，通过协调层处理表格异常检测中不同模型间的分歧，产生最终异常分数和可审计的辩论轨迹


<details>
  <summary>Details</summary>
Motivation: 表格异常检测通常使用单一检测器或静态集成，但表格数据的强性能通常来自异构模型族（树集成、深度表格网络、表格基础模型），这些模型在分布偏移、缺失值和罕见异常情况下经常产生分歧

Method: 提出MAD多智能体辩论框架：每个智能体是基于ML的检测器，输出归一化异常分数、置信度和结构化证据，由LLM批评者增强；协调器将这些消息转换为有界的每智能体损失，通过指数梯度规则更新智能体影响

Result: 建立了合成损失的遗憾保证，展示了如何通过保形校准包装辩论分数以在可交换性下控制假阳性；在多样化表格异常基准测试中显示出比基线更好的鲁棒性和更清晰的模型分歧轨迹

Conclusion: MAD是一个统一的智能体框架，可以通过限制消息空间和合成算子恢复现有方法（如专家混合门控和学习专家建议聚合），为表格异常检测提供了数学基础的可审计辩论方法

Abstract: Tabular anomaly detection is often handled by single detectors or static ensembles, even though strong performance on tabular data typically comes from heterogeneous model families (e.g., tree ensembles, deep tabular networks, and tabular foundation models) that frequently disagree under distribution shift, missingness, and rare-anomaly regimes. We propose MAD, a Multi-Agent Debating framework that treats this disagreement as a first-class signal and resolves it through a mathematically grounded coordination layer. Each agent is a machine learning (ML)-based detector that produces a normalized anomaly score, confidence, and structured evidence, augmented by a large language model (LLM)-based critic. A coordinator converts these messages into bounded per-agent losses and updates agent influence via an exponentiated-gradient rule, yielding both a final debated anomaly score and an auditable debate trace. MAD is a unified agentic framework that can recover existing approaches, such as mixture-of-experts gating and learning-with-expert-advice aggregation, by restricting the message space and synthesis operator. We establish regret guarantees for the synthesized losses and show how conformal calibration can wrap the debated score to control false positives under exchangeability. Experiments on diverse tabular anomaly benchmarks show improved robustness over baselines and clearer traces of model disagreement

</details>


### [79] [Cross-household Transfer Learning Approach with LSTM-based Demand Forecasting](https://arxiv.org/abs/2602.14267)
*Manal Rahal,Bestoun S. Ahmed,Roger Renström,Robert Stener*

Main category: cs.LG

TL;DR: DELTAiF是一个基于迁移学习的框架，用于预测家庭热水消耗，通过从代表性家庭学习知识并微调到其他家庭，实现可扩展的热水需求预测，减少67%的训练时间。


<details>
  <summary>Details</summary>
Motivation: 随着住宅热泵安装的快速增长，优化家庭热水生产至关重要，但面临技术和可扩展性挑战。传统方法为每个家庭单独训练机器学习模型在云连接热泵部署中计算成本过高。

Method: 提出DELTAiF迁移学习框架，从代表性家庭学习知识，然后微调到其他家庭，预测大量热水使用事件（如淋浴），无需为每个热泵安装单独训练模型。

Result: 减少约67%的总训练时间，同时保持高预测准确性（0.874-0.991），平均绝对百分比误差在0.001-0.017之间。当源家庭表现出规律消费模式时，迁移学习特别有效。

Conclusion: 迁移学习能够实现可扩展的家庭热水需求预测，DELTAiF框架通过知识转移显著降低计算成本，同时保持高预测准确性，特别适用于具有规律消费模式的家庭。

Abstract: With the rapid increase in residential heat pump (HP) installations, optimizing hot water production in households is essential, yet it faces major technical and scalability challenges. Adapting production to actual household needs requires accurate forecasting of hot water demand to ensure comfort and, most importantly, to reduce energy waste. However, the conventional approach of training separate machine learning models for each household becomes computationally expensive at scale, particularly in cloud-connected HP deployments.
  This study introduces DELTAiF, a transfer learning (TL) based framework that provides scalable and accurate prediction of household hot water consumption. By predicting large hot water usage events, such as showers, DELTAiF enables adaptive yet scalable hot water production at the household level. DELTAiF leverages learned knowledge from a representative household and fine-tunes it across others, eliminating the need to train separate machine learning models for each HP installation. This approach reduces overall training time by approximately 67 percent while maintaining high predictive accuracy values between 0.874 and 0.991, and mean absolute percentage error values between 0.001 and 0.017. The results show that TL is particularly effective when the source household exhibits regular consumption patterns, enabling hot water demand forecasting at scale.

</details>


### [80] [Radial-VCReg: More Informative Representation Learning Through Radial Gaussianization](https://arxiv.org/abs/2602.14272)
*Yilun Kuang,Yash Dagade,Deep Chakraborty,Erik Learned-Miller,Randall Balestriero,Tim G. J. Rudner,Yann LeCun*

Main category: cs.LG

TL;DR: Radial-VCReg通过添加径向高斯化损失增强VCReg，将特征范数与Chi分布对齐，减少高阶依赖并促进更多样化和信息丰富的表示。


<details>
  <summary>Details</summary>
Motivation: 自监督学习旨在学习最大信息表示，但显式信息最大化受到维度诅咒的阻碍。现有方法如VCReg通过正则化一阶和二阶特征统计量无法完全实现最大熵。

Method: 提出Radial-VCReg，在VCReg基础上添加径向高斯化损失，将特征范数与Chi分布对齐——这是高维高斯分布的一个定义性特征。

Result: 证明Radial-VCReg相比VCReg能将更广泛的分布类别转化为正态分布，在合成和真实数据集上一致提升性能，减少高阶依赖并促进更多样化和信息丰富的表示。

Conclusion: 径向高斯化损失是增强自监督学习表示质量的有效方法，通过更好地逼近最大熵分布来改进现有正则化技术。

Abstract: Self-supervised learning aims to learn maximally informative representations, but explicit information maximization is hindered by the curse of dimensionality. Existing methods like VCReg address this by regularizing first and second-order feature statistics, which cannot fully achieve maximum entropy. We propose Radial-VCReg, which augments VCReg with a radial Gaussianization loss that aligns feature norms with the Chi distribution-a defining property of high-dimensional Gaussians. We prove that Radial-VCReg transforms a broader class of distributions towards normality compared to VCReg and show on synthetic and real-world datasets that it consistently improves performance by reducing higher-order dependencies and promoting more diverse and informative representations.

</details>


### [81] [Integrating Unstructured Text into Causal Inference: Empirical Evidence from Real Data](https://arxiv.org/abs/2602.14274)
*Boning Zhou,Ziyu Wang,Han Hong,Haoqi Hu*

Main category: cs.LG

TL;DR: 提出基于Transformer语言模型的框架，利用非结构化文本进行因果推断，验证了与结构化数据方法结果的一致性


<details>
  <summary>Details</summary>
Motivation: 传统因果推断严重依赖结构化数据，但现实场景中结构化数据可能不完整或不可得，限制了因果推断的应用范围

Method: 开发基于Transformer语言模型的框架，从非结构化文本中提取因果估计，并在群体、组别和个体三个层次与结构化数据方法进行比较

Result: 两种方法在群体、组别和个体三个层次上得到一致的因果估计结果，验证了非结构化文本在因果推断任务中的潜力

Conclusion: 该框架扩展了因果推断方法的应用范围，使其在仅有文本数据的情况下也能进行数据驱动的商业决策，解决了结构化数据稀缺的问题

Abstract: Causal inference, a critical tool for informing business decisions, traditionally relies heavily on structured data. However, in many real-world scenarios, such data can be incomplete or unavailable. This paper presents a framework that leverages transformer-based language models to perform causal inference using unstructured text. We demonstrate the effectiveness of our framework by comparing causal estimates derived from unstructured text against those obtained from structured data across population, group, and individual levels. Our findings show consistent results between the two approaches, validating the potential of unstructured text in causal inference tasks. Our approach extends the applicability of causal inference methods to scenarios where only textual data is available, enabling data-driven business decision-making when structured tabular data is scarce.

</details>


### [82] [Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems](https://arxiv.org/abs/2602.14275)
*Lamine Rihani*

Main category: cs.LG

TL;DR: 提出反向n-wise输出测试框架，通过构建输出等价类覆盖阵列，解决AI/ML和量子计算的高维连续输入空间、概率性输出分布等测试挑战


<details>
  <summary>Details</summary>
Motivation: AI/ML系统和量子计算软件面临前所未有的测试挑战：高维连续输入空间、概率性非确定性输出分布、仅通过可观测预测行为定义正确性，以及公平性、鲁棒性、量子错误模式等关键质量维度需要通过复杂的多向交互来体现

Method: 提出反向n-wise输出测试范式，直接在领域特定的输出等价类上构建覆盖阵列，包括ML置信度校准桶、决策边界区域、公平性分区、嵌入聚类、量子测量结果分布等，然后通过无梯度元启发式优化解决黑盒逆映射问题，合成能够从模型中引出目标行为特征的输入配置

Result: 该框架为两个领域带来协同效益：明确的以客户为中心的预测/测量覆盖保证，显著提高ML校准/边界失败和量子错误综合征的故障检测率，增强测试套件效率，以及通过不确定性分析和覆盖漂移监控实现结构化MLOps/量子验证管道

Conclusion: 反向n-wise输出测试为AI/ML和量子计算系统提供了一种数学原理的测试范式转换，通过输出空间覆盖和黑盒逆映射，有效应对这些新兴技术特有的测试挑战

Abstract: Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over observable prediction behaviors and measurement outcomes, and critical quality dimensions, trustworthiness, fairness, calibration, robustness, error syndrome patterns, that manifest through complex multi-way interactions among semantically meaningful output properties rather than deterministic input-output mappings. This paper introduces reverse n-wise output testing, a mathematically principled paradigm inversion that constructs covering arrays directly over domain-specific output equivalence classes, ML confidence calibration buckets, decision boundary regions, fairness partitions, embedding clusters, ranking stability bands, quantum measurement outcome distributions (0-dominant, 1-dominant, superposition collapse), error syndrome patterns (bit-flip, phase-flip, correlated errors), then solves the computationally challenging black-box inverse mapping problem via gradient-free metaheuristic optimization to synthesize input feature configurations or quantum circuit parameters capable of eliciting targeted behavioral signatures from opaque models. The framework delivers synergistic benefits across both domains: explicit customer-centric prediction/measurement coverage guarantees, substantial improvements in fault detection rates for ML calibration/boundary failures and quantum error syndromes, enhanced test suite efficiency, and structured MLOps/quantum validation pipelines with automated partition discovery from uncertainty analysis and coverage drift monitoring.

</details>


### [83] [Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions](https://arxiv.org/abs/2602.14279)
*Ruomeng Ding,Tianwei Gao,Thomas P. Zollo,Eitan Bachmat,Richard Zemel,Zhun Deng*

Main category: cs.LG

TL;DR: 提出自适应群体信息获取框架，结合LLM的信息增益评估和图神经网络传播，在有限预算下优化问题选择和受访者选择，提高群体层面响应预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有信息获取方法通常优化问题选择但固定受访者池，无法适应受访者选择和利用群体结构处理不完整响应。需要一种能同时自适应选择问题和受访者的方法，在有限查询和参与预算下提高群体层面信息获取效率。

Method: 提出自适应群体信息获取框架：1) 使用LLM基于预期信息增益评估候选问题；2) 使用异构图神经网络传播聚合观察到的响应和参与者属性，填补缺失响应并指导每轮受访者选择；3) 形成闭环过程，查询少量信息丰富的个体，同时通过结构化相似性推断群体层面响应。

Result: 在三个真实世界意见数据集上，该方法在有限预算下持续提高群体层面响应预测性能，在CES数据集上以10%受访者预算获得超过12%的相对增益。

Conclusion: 提出的自适应群体信息获取框架能有效结合LLM的信息评估能力和图神经网络的结构化传播，在有限预算下通过优化问题和受访者选择，显著提高群体层面信息获取效率。

Abstract: Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget.

</details>


### [84] [KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning](https://arxiv.org/abs/2602.14293)
*Kris Shengjun Dong,Sahil Modi,Dima Nikiforov,Sana Damani,Edward Lin,Siva Kumar Sastry Hari,Christos Kozyrakis*

Main category: cs.LG

TL;DR: KernelBlaster是一个基于记忆增强上下文强化学习的CUDA代码优化框架，通过构建可检索的持久知识库，让LLM代理能够从经验中学习并做出系统性优化决策，实现跨GPU架构的高性能代码生成。


<details>
  <summary>Details</summary>
Motivation: 传统编译器受限于固定启发式方法，而微调大型语言模型成本高昂。现有的CUDA代码优化代理工作流难以聚合先前探索的知识，导致采样偏差和次优解。需要一种能够积累知识并系统性优化CUDA代码的方法。

Method: 提出Memory-Augmented In-context Reinforcement Learning (MAIC-RL)框架，构建可检索的Persistent CUDA Knowledge Base，采用基于配置文件的文本梯度代理流程进行CUDA生成和优化，系统性地探索高潜力优化策略。

Result: 在KernelBench测试中，相比PyTorch基线，在Level 1、2、3上分别实现了1.43倍、2.50倍和1.50倍的几何平均加速。框架已开源，包含测试工具、验证组件和可复现评估流程。

Conclusion: KernelBlaster通过记忆增强强化学习框架，显著提升了LLM代理在CUDA代码优化方面的能力，能够跨GPU架构实现高性能优化，解决了传统方法和现有代理工作流的局限性。

Abstract: Optimizing CUDA code across multiple generations of GPU architectures is challenging, as achieving peak performance requires an extensive exploration of an increasingly complex, hardware-specific optimization space. Traditional compilers are constrained by fixed heuristics, whereas finetuning Large Language Models (LLMs) can be expensive. However, agentic workflows for CUDA code optimization have limited ability to aggregate knowledge from prior exploration, leading to biased sampling and suboptimal solutions. We propose KernelBlaster, a Memory-Augmented In-context Reinforcement Learning (MAIC-RL) framework designed to improve CUDA optimization search capabilities of LLM-based GPU coding agents. KernelBlaster enables agents to learn from experience and make systematically informed decisions on future tasks by accumulating knowledge into a retrievable Persistent CUDA Knowledge Base. We propose a novel profile-guided, textual-gradient-based agentic flow for CUDA generation and optimization to achieve high performance across generations of GPU architectures. KernelBlaster guides LLM agents to systematically explore high-potential optimization strategies beyond naive rewrites. Compared to the PyTorch baseline, our method achieves geometric mean speedups of 1.43x, 2.50x, and 1.50x on KernelBench Levels 1, 2, and 3, respectively. We release KernelBlaster as an open-source agentic framework, accompanied by a test harness, verification components, and a reproducible evaluation pipeline.

</details>


### [85] [Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows](https://arxiv.org/abs/2602.14295)
*Edwin Chen,Zulekha Bibi*

Main category: cs.LG

TL;DR: MLAT是一种设计模式，将预训练机器学习模型作为可调用工具集成到LLM智能体工作流中，使LLM能够根据对话上下文决定何时以及如何使用定量预测。


<details>
  <summary>Details</summary>
Motivation: 传统ML推理通常作为静态预处理步骤，缺乏与LLM的交互性。MLAT旨在将ML模型定位为一等工具，使LLM能够根据上下文动态调用定量预测，实现定量估计与上下文推理的结合。

Method: 提出MLAT设计模式，将预训练ML模型作为可调用工具暴露在LLM智能体工作流中。通过PitchCraft系统验证：使用研究智能体收集情报，草稿智能体调用XGBoost定价模型作为工具，通过结构化输出生成完整提案。在极度数据稀缺下训练定价模型（70个真实+人工验证合成数据）。

Result: 定价模型在保留数据上达到R^2=0.807，平均绝对误差3688美元。系统将提案生成时间从数小时减少到10分钟以内。敏感性分析显示模型学习了有意义的关联关系。

Conclusion: MLAT框架适用于需要定量估计与上下文推理结合的领域，将ML模型作为一等工具集成到LLM工作流中，提高了系统的灵活性和实用性。

Abstract: We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason about their outputs in context. Unlike conventional pipelines that treat ML inference as a static preprocessing step, MLAT positions the model as a first-class tool alongside web search, database queries, and APIs, enabling the LLM to decide when and how to use it based on conversational context.
  To validate MLAT, we present PitchCraft, a pilot production system that converts discovery call recordings into professional proposals with ML-predicted pricing. The system uses two agents: a Research Agent that gathers prospect intelligence via parallel tool calls, and a Draft Agent that invokes an XGBoost pricing model as a tool call and generates a complete proposal through structured outputs. The pricing model, trained on 70 examples combining real and human-verified synthetic data, achieves R^2 = 0.807 on held-out data with a mean absolute error of 3688 USD. The system reduces proposal generation time from multiple hours to under 10 minutes.
  We describe the MLAT framework, structured output architecture, training methodology under extreme data scarcity, and sensitivity analysis demonstrating meaningful learned relationships. MLAT generalizes to domains requiring quantitative estimation combined with contextual reasoning.

</details>


### [86] [DeepFusion: Accelerating MoE Training via Federated Knowledge Distillation from Heterogeneous Edge Devices](https://arxiv.org/abs/2602.14301)
*Songyuan Li,Jia Hu,Ahmed M. Abdelmoniem,Geyong Min,Haojun Huang,Jiwei Huang*

Main category: cs.LG

TL;DR: DeepFusion：首个可扩展的联邦MoE训练框架，通过联邦知识蒸馏融合异构设备上的LLM知识，解决资源受限设备无法承载大型MoE模型的问题。


<details>
  <summary>Details</summary>
Motivation: MoE-based LLMs需要大量多样化训练数据，联邦学习可利用异构边缘设备的私有数据，但传统FL要求设备本地承载MoE模型，这对资源受限设备不切实际。

Method: 1) 设备独立配置和训练适合自身需求的本地LLM；2) 提出View-Aligned Attention模块，整合全局MoE模型的多阶段特征表示，构建与本地LLM对齐的预测视角，实现跨架构知识蒸馏。

Result: 在工业级MoE模型和真实数据集上，DeepFusion性能接近集中式MoE训练，相比基线方法通信成本降低71%，token困惑度提升5.28%。

Conclusion: DeepFusion通过视角对齐的联邦知识蒸馏，有效解决了异构模型架构间的视图不匹配问题，实现了资源受限设备参与MoE模型训练，为隐私保护的分布式AI训练提供了可行方案。

Abstract: Recent Mixture-of-Experts (MoE)-based large language models (LLMs) such as Qwen-MoE and DeepSeek-MoE are transforming generative AI in natural language processing. However, these models require vast and diverse training data. Federated learning (FL) addresses this challenge by leveraging private data from heterogeneous edge devices for privacy-preserving MoE training. Nonetheless, traditional FL approaches require devices to host local MoE models, which is impractical for resource-constrained devices due to large model sizes. To address this, we propose DeepFusion, the first scalable federated MoE training framework that enables the fusion of heterogeneous on-device LLM knowledge via federated knowledge distillation, yielding a knowledge-abundant global MoE model. Specifically, DeepFusion features each device to independently configure and train an on-device LLM tailored to its own needs and hardware limitations. Furthermore, we propose a novel View-Aligned Attention (VAA) module that integrates multi-stage feature representations from the global MoE model to construct a predictive perspective aligned with on-device LLMs, thereby enabling effective cross-architecture knowledge distillation. By explicitly aligning predictive perspectives, VAA resolves the view-mismatch problem in traditional federated knowledge distillation, which arises from heterogeneity in model architectures and prediction behaviors between on-device LLMs and the global MoE model. Experiments with industry-level MoE models (Qwen-MoE and DeepSeek-MoE) and real-world datasets (medical and finance) demonstrate that DeepFusion achieves performance close to centralized MoE training. Compared with key federated MoE baselines, DeepFusion reduces communication costs by up to 71% and improves token perplexity by up to 5.28%.

</details>


### [87] [In Transformer We Trust? A Perspective on Transformer Architecture Failure Modes](https://arxiv.org/abs/2602.14318)
*Trishit Mondal,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: 该论文系统评估Transformer模型在安全关键应用中的可信度，涵盖可解释性、鲁棒性、公平性和隐私等方面，识别其结构脆弱性和领域特定风险。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer架构在自然语言处理、计算机视觉、医疗健康、自主系统以及气候建模、材料发现、药物发现、核科学、机器人等科学计算关键领域的高风险应用中日益广泛部署，迫切需要对其可信度进行更深入和严谨的理解。

Method: 通过全面综述可解释性、可解释性、对抗攻击鲁棒性、公平性和隐私等方面，系统评估Transformer模型的可信度。同时系统检查Transformer模型在自然语言处理、计算机视觉以及机器人、医学、地球科学、材料科学、流体动力学、核科学、自动定理证明等科学与工程领域安全关键应用中的可信度。

Result: 识别了Transformer模型在跨领域应用中反复出现的结构脆弱性、领域特定风险以及限制其可靠部署的开放研究挑战。

Conclusion: Transformer模型在高风险应用中的可信度需要系统评估和持续研究，特别是在安全关键领域部署时需要解决其结构脆弱性和领域特定风险。

Abstract: Transformer architectures have revolutionized machine learning across a wide range of domains, from natural language processing to scientific computing. However, their growing deployment in high-stakes applications, such as computer vision, natural language processing, healthcare, autonomous systems, and critical areas of scientific computing including climate modeling, materials discovery, drug discovery, nuclear science, and robotics, necessitates a deeper and more rigorous understanding of their trustworthiness. In this work, we critically examine the foundational question: \textitHow trustworthy are transformer models?} We evaluate their reliability through a comprehensive review of interpretability, explainability, robustness against adversarial attacks, fairness, and privacy. We systematically examine the trustworthiness of transformer-based models in safety-critical applications spanning natural language processing, computer vision, and science and engineering domains, including robotics, medicine, earth sciences, materials science, fluid dynamics, nuclear science, and automated theorem proving; highlighting high-impact areas where these architectures are central and analyzing the risks associated with their deployment. By synthesizing insights across these diverse areas, we identify recurring structural vulnerabilities, domain-specific risks, and open research challenges that limit the reliable deployment of transformers.

</details>


### [88] [Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study](https://arxiv.org/abs/2602.14322)
*Hani Beirami,M M Manjurul Islam*

Main category: cs.LG

TL;DR: 使用形式化时序逻辑规范增强强化学习在航空航天控制中的安全性和鲁棒性，通过符合性STL屏蔽器实时过滤RL动作，在F-16仿真中验证效果。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过形式化时序逻辑规范提升强化学习在航空航天控制中的安全性和鲁棒性，解决传统RL方法在安全关键应用中缺乏形式化保证的问题。

Method: 在AeroBench F-16仿真环境中训练PPO代理控制引擎油门和跟踪指令空速，将控制目标编码为STL要求，引入符合性STL屏蔽器使用在线符合性预测过滤RL代理动作。

Result: 实验表明符合性屏蔽器在保持STL满足性的同时维持接近基线的性能，相比经典规则型屏蔽器提供更强的鲁棒性保证，在模型失配、执行器限制、测量噪声和设定点跳变等压力场景下表现良好。

Conclusion: 形式化规范监控与数据驱动RL控制相结合可以显著提升自主飞行控制在挑战性环境中的可靠性，为安全关键应用提供了有前景的方法。

Abstract: We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specification monitoring with data driven RL control can substantially improve the reliability of autonomous flight control in challenging environments.

</details>


### [89] [Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning](https://arxiv.org/abs/2602.14338)
*Zhi Zhang,Zhen Han,Costas Mavromatis,Qi Zhu,Yunyi Zhang,Sheng Guan,Dingmin Wang,Xiong Zhou,Shuai Wang,Soji Adeshina,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.LG

TL;DR: AERO改进GRPO的RL对齐方法，通过自适应采样、选择性拒绝和贝叶斯后验避免零梯度，在相同预算下减少48%计算和45%时间，保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在RL对齐中存在效率问题：当组内所有rollouts结果相同（全对或全错）时，组归一化优势为零，导致无梯度信号和计算浪费。

Method: AERO在GRPO基础上改进：1) 自适应rollout策略；2) 选择性拒绝策略修剪rollouts；3) 贝叶斯后验防止零优势死区。

Result: 在Qwen2.5-Math-1.5B、Qwen2.5-7B和Qwen2.5-7B-Instruct三个模型上，相同总rollout预算下，AERO减少约48%总训练计算和45%每步时间，同时保持或提升Pass@8和Avg@8性能。

Conclusion: AERO提供了一种实用、可扩展且计算高效的RL-based LLM对齐策略，显著提升计算效率而不牺牲性能。

Abstract: Reinforcement learning (RL) plays a central role in large language model (LLM) post-training. Among existing approaches, Group Relative Policy Optimization (GRPO) is widely used, especially for RL with verifiable rewards (RLVR) fine-tuning. In GRPO, each query prompts the LLM to generate a group of rollouts with a fixed group size $N$. When all rollouts in a group share the same outcome, either all correct or all incorrect, the group-normalized advantages become zero, yielding no gradient signal and wasting fine-tuning compute. We introduce Adaptive Efficient Rollout Optimization (AERO), an enhancement of GRPO. AERO uses an adaptive rollout strategy, applies selective rejection to strategically prune rollouts, and maintains a Bayesian posterior to prevent zero-advantage dead zones. Across three model configurations (Qwen2.5-Math-1.5B, Qwen2.5-7B, and Qwen2.5-7B-Instruct), AERO improves compute efficiency without sacrificing performance. Under the same total rollout budget, AERO reduces total training compute by about 48% while shortening wall-clock time per step by about 45% on average. Despite the substantial reduction in compute, AERO matches or improves Pass@8 and Avg@8 over GRPO, demonstrating a practical, scalable, and compute-efficient strategy for RL-based LLM alignment.

</details>


### [90] [Zero-Shot Instruction Following in RL via Structured LTL Representations](https://arxiv.org/abs/2602.14344)
*Mathias Jackermeier,Mattia Giuri,Jacques Cloete,Alessandro Abate*

Main category: cs.LG

TL;DR: 该论文提出了一种基于线性时序逻辑(LTL)的多任务强化学习方法，通过层次化神经网络架构和注意力机制学习结构化任务表示，以提升零样本执行未见任务的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多任务强化学习中训练通用策略时，难以有效捕捉LTL规范中丰富的逻辑和时间结构，导致在零样本执行未见任务时表现不佳。

Method: 基于任务有限自动机构建布尔公式序列作为策略条件，采用层次化神经网络架构编码公式的逻辑结构，并引入注意力机制使策略能够推理未来子目标。

Result: 在多种复杂环境中的实验表明，该方法具有强大的泛化能力和优越的性能表现。

Conclusion: 提出的结构化任务表示学习方法能够有效提升多任务强化学习中零样本执行未见任务的能力，特别是在处理具有复杂逻辑和时间结构的LTL规范时表现优异。

Abstract: We study instruction following in multi-task reinforcement learning, where an agent must zero-shot execute novel tasks not seen during training. In this setting, linear temporal logic (LTL) has recently been adopted as a powerful framework for specifying structured, temporally extended tasks. While existing approaches successfully train generalist policies, they often struggle to effectively capture the rich logical and temporal structure inherent in LTL specifications. In this work, we address these concerns with a novel approach to learn structured task representations that facilitate training and generalisation. Our method conditions the policy on sequences of Boolean formulae constructed from a finite automaton of the task. We propose a hierarchical neural architecture to encode the logical structure of these formulae, and introduce an attention mechanism that enables the policy to reason about future subgoals. Experiments in a variety of complex environments demonstrate the strong generalisation capabilities and superior performance of our approach.

</details>


### [91] [WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control](https://arxiv.org/abs/2602.14351)
*Mehran Aghabozorgi,Alireza Moazeni,Yanshu Zhang,Ke Li*

Main category: cs.LG

TL;DR: WIMLE是一种基于模型的强化学习方法，通过扩展隐式最大似然估计(IMLE)来学习随机多模态世界模型，使用集成和潜在采样估计预测不确定性，并通过置信度加权合成转移来稳定学习。


<details>
  <summary>Details</summary>
Motivation: 基于模型的强化学习虽然样本效率高，但在实践中表现不佳，主要原因是：1) 模型误差累积；2) 单模态世界模型平均了多模态动态；3) 过度自信的预测偏差学习。

Method: 将IMLE扩展到基于模型的RL框架中，学习随机多模态世界模型（无需迭代采样），通过集成和潜在采样估计预测不确定性。训练时，根据预测置信度对每个合成转移进行加权，保留有用的模型展开，同时减弱不确定预测的偏差。

Result: 在40个连续控制任务（DeepMind Control、MyoSuite、HumanoidBench）上，WIMLE实现了卓越的样本效率和竞争性或更好的渐近性能。在Humanoid-run任务上，样本效率比最强竞争对手提高50%以上；在HumanoidBench上解决了14个任务中的8个（BRO解决4个，SimbaV2解决5个）。

Conclusion: 基于IMLE的多模态和不确定性感知加权对于稳定的基于模型的强化学习具有重要价值，能够有效处理模型误差累积和多模态动态问题。

Abstract: Model-based reinforcement learning promises strong sample efficiency but often underperforms in practice due to compounding model error, unimodal world models that average over multi-modal dynamics, and overconfident predictions that bias learning. We introduce WIMLE, a model-based method that extends Implicit Maximum Likelihood Estimation (IMLE) to the model-based RL framework to learn stochastic, multi-modal world models without iterative sampling and to estimate predictive uncertainty via ensembles and latent sampling. During training, WIMLE weights each synthetic transition by its predicted confidence, preserving useful model rollouts while attenuating bias from uncertain predictions and enabling stable learning. Across $40$ continuous-control tasks spanning DeepMind Control, MyoSuite, and HumanoidBench, WIMLE achieves superior sample efficiency and competitive or better asymptotic performance than strong model-free and model-based baselines. Notably, on the challenging Humanoid-run task, WIMLE improves sample efficiency by over $50$\% relative to the strongest competitor, and on HumanoidBench it solves $8$ of $14$ tasks (versus $4$ for BRO and $5$ for SimbaV2). These results highlight the value of IMLE-based multi-modality and uncertainty-aware weighting for stable model-based RL.

</details>


### [92] [A Study on Multi-Class Online Fuzzy Classifiers for Dynamic Environments](https://arxiv.org/abs/2602.14375)
*Kensuke Ajimoto,Yuma Yamamoto,Yoshifumi Kusunoki,Tomoharu Nakashima*

Main category: cs.LG

TL;DR: 提出一种用于动态环境的多类在线模糊分类器，扩展了传统仅处理二分类问题的在线模糊分类器


<details>
  <summary>Details</summary>
Motivation: 传统在线模糊分类器只能处理二分类问题，但在实际动态环境中需要处理多类别分类任务。在线学习框架下，训练数据不是一次性全部可用，而是随时间逐步到达，需要适应这种动态环境

Method: 使用模糊if-then规则构建分类器，其中前件模糊集由用户预先确定，后件实值通过训练数据学习。在在线框架中，每次只处理少量训练模式，随时间逐步更新模型。扩展传统二分类在线模糊分类器以处理多类别问题

Result: 通过合成动态数据和多个基准数据集进行数值实验评估，验证了多类在线模糊分类器的性能

Conclusion: 成功将在线模糊分类器扩展到多类别问题，为动态环境中的多类分类任务提供了有效解决方案

Abstract: This paper proposes a multi-class online fuzzy classifier for dynamic environments. A fuzzy classifier comprises a set of fuzzy if-then rules where human users determine the antecedent fuzzy sets beforehand. In contrast, the consequent real values are determined by learning from training data. In an online framework, not all training dataset patterns are available beforehand. Instead, only a few patterns are available at a time step, and the subsequent patterns become available at the following time steps. The conventional online fuzzy classifier considered only two-class problems. This paper investigates the extension to the conventional fuzzy classifiers for multi-class problems. We evaluate the performance of the multi-class online fuzzy classifiers through numerical experiments on synthetic dynamic data and also several benchmark datasets.

</details>


### [93] [The geometry of invariant learning: an information-theoretic analysis of data augmentation and generalization](https://arxiv.org/abs/2602.14423)
*Abdelali Bouyahia,Frédéric LeBlanc,Mario Marchand*

Main category: cs.LG

TL;DR: 提出信息论框架分析数据增强对泛化和不变性学习的影响，推导出包含分布差异、算法稳定性和增强敏感性的三部分泛化界，引入群直径概念揭示增强强度与正则化效果的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 数据增强是提升机器学习泛化能力的常用技术，但其理论作用尚未完全理解。本文旨在建立系统框架分析增强如何影响泛化性能，特别是如何促进对标签无关变换的不变性学习。

Method: 基于互信息泛化界框架，将增强分布建模为原始数据分布与变换分布的复合，推导轨道平均损失函数。在损失函数和增强过程的次高斯假设下，得到包含分布差异、算法稳定性和增强敏感性的三部分泛化界，并引入群直径概念量化增强强度。

Result: 理论分析表明泛化界由三部分组成：原始与增强数据的分布差异、算法对训练数据的依赖程度、增强变异性影响。群直径作为统一控制参数揭示了增强强度与正则化效果的权衡关系，数值实验验证了理论界能可靠预测真实泛化差距。

Conclusion: 提出的信息论框架为理解数据增强的泛化效应提供了系统理论工具，揭示了增强强度、数据保真度和正则化效果之间的内在权衡，为设计更有效的增强策略提供了理论指导。

Abstract: Data augmentation is one of the most widely used techniques to improve generalization in modern machine learning, often justified by its ability to promote invariance to label-irrelevant transformations. However, its theoretical role remains only partially understood. In this work, we propose an information-theoretic framework that systematically accounts for the effect of augmentation on generalization and invariance learning. Our approach builds upon mutual information-based bounds, which relate the generalization gap to the amount of information a learning algorithm retains about its training data. We extend this framework by modeling the augmented distribution as a composition of the original data distribution with a distribution over transformations, which naturally induces an orbit-averaged loss function. Under mild sub-Gaussian assumptions on the loss function and the augmentation process, we derive a new generalization bound that decompose the expected generalization gap into three interpretable terms: (1) a distributional divergence between the original and augmented data, (2) a stability term measuring the algorithm dependence on training data, and (3) a sensitivity term capturing the effect of augmentation variability. To connect our bounds to the geometry of the augmentation group, we introduce the notion of group diameter, defined as the maximal perturbation that augmentations can induce in the input space. The group diameter provides a unified control parameter that bounds all three terms and highlights an intrinsic trade-off: small diameters preserve data fidelity but offer limited regularization, while large diameters enhance stability at the cost of increased bias and sensitivity. We validate our theoretical bounds with numerical experiments, demonstrating that it reliably tracks and predicts the behavior of the true generalization gap.

</details>


### [94] [A unified framework for evaluating the robustness of machine-learning interpretability for prospect risking](https://arxiv.org/abs/2602.14430)
*Prithwijit Chowdhury,Ahmad Mustafa,Mohit Prabhushankar,Ghassan AlRegib*

Main category: cs.LG

TL;DR: 提出一个统一框架，通过反事实生成和必要性/充分性量化来评估LIME和SHAP在油气勘探风险评估中的解释鲁棒性


<details>
  <summary>Details</summary>
Motivation: 机器学习分类器在油气勘探风险评估中缺乏透明度，而现有的XAI方法（如LIME和SHAP）对同一场景的解释可能不一致，需要更可靠的方法来评估解释的鲁棒性

Method: 提出统一框架，生成反事实并量化必要性和充分性，用于评估LIME和SHAP在高维结构化勘探数据上的解释鲁棒性

Result: 鲁棒性测试提供了对模型处理错误数据能力的深入洞察，并确定了哪种XAI模块与哪种模型在油气指示数据集上表现最佳

Conclusion: 基于因果理论中的必要性和充分性概念来评估XAI解释的鲁棒性，可以提高解释策略的可信度，为油气勘探风险评估提供更可靠的决策支持

Abstract: In geophysics, hydrocarbon prospect risking involves assessing the risks associated with hydrocarbon exploration by integrating data from various sources. Machine learning-based classifiers trained on tabular data have been recently used to make faster decisions on these prospects. The lack of transparency in the decision-making processes of such models has led to the emergence of explainable AI (XAI). LIME and SHAP are two such examples of these XAI methods which try to generate explanations of a particular decision by ranking the input features in terms of importance. However, explanations of the same scenario generated by these two different explanation strategies have shown to disagree or be different, particularly for complex data. This is because the definitions of "importance" and "relevance" differ for different explanation strategies. Thus, grounding these ranked features using theoretically backed causal ideas of necessity and sufficiency can prove to be a more reliable and robust way to improve the trustworthiness of the concerned explanation strategies.We propose a unified framework to generate counterfactuals as well as quantify necessity and sufficiency and use these to perform a robustness evaluation of the explanations provided by LIME and SHAP on high dimensional structured prospect risking data. This robustness test gives us deeper insights into the models capabilities to handle erronous data and which XAI module works best in pair with which model for our dataset for hydorcarbon indication.

</details>


### [95] [S2D: Selective Spectral Decay for Quantization-Friendly Conditioning of Neural Activations](https://arxiv.org/abs/2602.14432)
*Arnav Chavan,Nahush Lele,Udbhav Bamba,Sankalp Dayal,Aditi Raghunathan,Deepak Gupta*

Main category: cs.LG

TL;DR: 论文提出选择性谱衰减(S²D)方法，通过正则化权重矩阵的最大奇异值来减少激活异常值，显著提升大模型量化后的精度。


<details>
  <summary>Details</summary>
Motivation: 大尺度Transformer模型中的激活异常值给模型量化带来根本性挑战，这些异常值产生过大的数值范围，导致量化时精度严重下降。随着预训练规模增大（如从CLIP到SigLIP再到SigLIP2），异常值问题更加严重。

Method: 通过理论分析和实证研究，建立了激活异常值与权重矩阵主导奇异值的直接联系。基于此，提出了选择性谱衰减(S²D)方法，这是一种几何原理驱动的条件化方法，在微调过程中仅对对应最大奇异值的权重分量进行手术式正则化。

Result: S²D显著减少了激活异常值，产生了对量化友好的良好条件化表示。在W4A4量化下，使用S²D训练的模型在ImageNet上实现了高达7%的PTQ精度提升，与QAT结合时获得4%的增益。这些改进在下游任务和视觉语言模型中也能泛化。

Conclusion: S²D方法能够在不牺牲部署效率的前提下，扩展越来越大规模和严格训练的模型，解决了大模型量化中的激活异常值问题。

Abstract: Activation outliers in large-scale transformer models pose a fundamental challenge to model quantization, creating excessively large ranges that cause severe accuracy drops during quantization. We empirically observe that outlier severity intensifies with pre-training scale (e.g., progressing from CLIP to the more extensively trained SigLIP and SigLIP2). Through theoretical analysis as well as empirical correlation studies, we establish the direct link between these activation outliers and dominant singular values of the weights. Building on this insight, we propose Selective Spectral Decay ($S^2D$), a geometrically-principled conditioning method that surgically regularizes only the weight components corresponding to the largest singular values during fine-tuning. Through extensive experiments, we demonstrate that $S^2D$ significantly reduces activation outliers and produces well-conditioned representations that are inherently quantization-friendly. Models trained with $S^2D$ achieve up to 7% improved PTQ accuracy on ImageNet under W4A4 quantization and 4% gains when combined with QAT. These improvements also generalize across downstream tasks and vision-language models, enabling the scaling of increasingly large and rigorously trained models without sacrificing deployment efficiency.

</details>


### [96] [Broken Chains: The Cost of Incomplete Reasoning in LLMs](https://arxiv.org/abs/2602.14444)
*Ian Su,Gaurav Purushothaman,Jey Narayan,Ruhika Goel,Kevin Zhu,Sunishchal Dev,Yash More,Maheep Chaudhary*

Main category: cs.LG

TL;DR: 研究不同推理模式（代码、自然语言、混合、无推理）在token预算受限下的性能表现，发现代码推理在预算削减时表现更稳健，而截断的推理链会误导模型。


<details>
  <summary>Details</summary>
Motivation: 推理专用模型（如GPT-5.1、DeepSeek-V3.2）需要大量推理token，成本高昂。研究在token预算受限时，不同推理模式（代码、自然语言、混合、无推理）的性能差异，为资源受限环境部署推理系统提供指导。

Method: 提出框架限制模型仅通过代码、注释、两者结合或不进行推理，系统地将token预算削减至最优的10%、30%、50%、70%。在四个前沿模型（GPT-5.1、Gemini 3 Flash、DeepSeek-V3.2、Grok 4.1）和数学基准（AIME、GSM8K、HMMT）上评估。

Result: 1) 截断推理有害：DeepSeek-V3.2在50%预算下，无推理得53%，截断CoT仅17%；2) 代码推理稳健：Gemini的注释性能降至0%时，代码仍保持43-47%；3) 混合推理不如单一模式；4) 稳健性模型相关：Grok在30%预算下保持80-90%，而OpenAI和DeepSeek降至7-27%。

Conclusion: 不完整的推理链会主动误导模型，代码推理在token受限时表现更稳健，混合推理效果不佳。这些发现对在资源约束下部署推理专用系统有重要启示。

Abstract: Reasoning-specialized models like OpenAI's 5.1 and DeepSeek-V3.2 allocate substantial inference compute to extended chain-of-thought (CoT) traces, yet reasoning tokens incur significant costs. How do different reasoning modalities of code, natural language, hybrid, or none do perform under token constraints? We introduce a framework that constrains models to reason exclusively through code, comments, both, or neither, then systematically ablates token budgets to 10\%, 30\%, 50\%, and 70\% of optimal. We evaluate four frontier models (GPT-5.1, Gemini 3 Flash, DeepSeek-V3.2, Grok 4.1) across mathematical benchmarks (AIME, GSM8K, HMMT). Our findings reveal: (1) \textbf{truncated reasoning can hurt} as DeepSeek-V3.2 achieves 53\% with no reasoning but only 17\% with truncated CoT at 50\% budget; (2) \textbf{code degrades gracefully} as Gemini's comments collapse to 0\% while code maintains 43-47\%; (3) \textbf{hybrid reasoning underperforms} single modalities; (4) \textbf{robustness is model-dependent} as Grok maintains 80-90\% at 30\% budget where OpenAI and DeepSeek collapse to 7-27\%. These results suggest incomplete reasoning chains actively mislead models, with implications for deploying reasoning-specialized systems under resource constraints.

</details>


### [97] [Selective Synchronization Attention](https://arxiv.org/abs/2602.14445)
*Hasi Hays*

Main category: cs.LG

TL;DR: 提出SSA注意力机制，基于Kuramoto耦合振子模型，用同步强度替代点积注意力，实现自然稀疏性、统一位置语义编码和单次闭式计算


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力机制存在二次计算复杂度问题，且缺乏生物学神经计算基础。需要更高效、更符合生物原理的注意力机制

Method: 提出选择性同步注意力(SSA)：将每个token表示为具有可学习自然频率和相位的振子，基于频率依赖耦合和相位锁定条件计算同步强度作为注意力权重。构建振荡同步网络(OSN)作为Transformer块的替代

Result: SSA具有自然稀疏性（相位锁定阈值）、统一位置语义编码（自然频率谱）、单次闭式计算优势。同步矩阵分析显示非均匀、头多样化的耦合模式，比随机初始化Transformer具有更强的架构归纳偏置

Conclusion: SSA提供了一种基于物理启发的注意力机制，在保持Transformer表达能力的同时，解决了计算复杂度和生物学基础问题，为深度学习架构设计提供了新方向

Abstract: The Transformer architecture has become the foundation of modern deep learning, yet its core self-attention mechanism suffers from quadratic computational complexity and lacks grounding in biological neural computation. We propose Selective Synchronization Attention (SSA), a novel attention mechanism that replaces the standard dot-product self-attention with a closed-form operator derived from the steady-state solution of the Kuramoto model of coupled oscillators. In SSA, each token is represented as an oscillator characterized by a learnable natural frequency and phase; the synchronization strength between token pairs, determined by a frequency-dependent coupling and phase-locking condition, serves as the attention weight. This formulation provides three key advantages: (i) natural sparsity arising from the phase-locking threshold, whereby tokens with incompatible frequencies automatically receive zero attention weight without explicit masking; (ii) unified positional-semantic encoding through the natural frequency spectrum, eliminating the need for separate positional encodings; and (iii) a single-pass, closed-form computation that avoids iterative ODE integration, with all components (coupling, order parameter, synchronization) derived from the oscillatory framework. We instantiate SSA within the Oscillatory Synchronization Network (OSN), a drop-in replacement for the Transformer block. Analysis of the synchronization matrices reveals non-uniform, head-diverse coupling patterns even at initialization, demonstrating a stronger architectural inductive bias than the approximately uniform attention produced by randomly initialized Transformers.

</details>


### [98] [WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity](https://arxiv.org/abs/2602.14452)
*Lei Chen,Yuan Meng,Xiaoyu Zhan,Zhi Wang,Wenwu Zhu*

Main category: cs.LG

TL;DR: WiSparse：一种训练无关的激活稀疏化方法，通过权重感知和混合粒度分配，在保持模型性能的同时显著加速LLM推理


<details>
  <summary>Details</summary>
Motivation: 现有训练无关激活稀疏化方法仅依赖激活信息且使用统一稀疏率，忽略了权重的重要性和不同模块对稀疏化的敏感性差异，导致性能不佳

Method: 提出权重感知混合粒度训练无关激活稀疏化（WiSparse）：1）权重感知机制结合激活幅度和预计算权重范数识别重要通道；2）混合粒度分配方案：通过进化搜索全局分配稀疏预算保护敏感模块，然后在模块内最小化重构误差

Result: 在50%稀疏率下，WiSparse保持Llama3.1 97%的密集性能，比最强基线提升2.23个百分点，端到端推理速度加速21.4%

Conclusion: WiSparse推动了训练无关方法在高效LLM推理中的极限，在不训练的情况下实现了显著的加速效果

Abstract: Large Language Models (LLMs) offer strong capabilities but incur high inference costs due to dense computation and memory access. Training-free activation sparsity is a promising approach for efficient LLM inference, yet existing methods often rely solely on activation information and uniform sparsity ratios. This overlooks the critical interplay with weights and inter-block sensitivity variation, leading to suboptimal performance. We identify two key phenomena in modern LLMs: 1) less significant activations may align with highly important weights, and 2) sparsity sensitivity varies non-monotonically across model blocks. We propose Weight-aware Mixed-Granularity Training-free Activation Sparsity (WiSparse), which leverages both activation and weight information for adaptive sparsity allocation. Specifically, we introduce a weight-aware mechanism integrating activation magnitudes with precomputed weight norms to accurately identify salient channels. This is combined with a mixed-granularity allocation scheme: a global budget is distributed across blocks via evolutionary search to protect sensitive regions, then refined within blocks to minimize reconstruction error. We improve sparse kernels and demonstrate effectiveness on three representative models. Notably, at 50% sparsity, WiSparse preserves 97% of Llama3.1's dense performance, surpassing the strongest baseline by 2.23 percentage points while achieving a 21.4% acceleration in end-to-end inference speed. Our research advances the limits of training-free approaches for efficient LLM inference, pushing the boundaries of achievable speedup without training.

</details>


### [99] [Traceable Latent Variable Discovery Based on Multi-Agent Collaboration](https://arxiv.org/abs/2602.14456)
*Huaming Du,Tao Hu,Yijie Huang,Yu Zhao,Guisong Liu,Tao Gu,Gang Kou,Carl Yang*

Main category: cs.LG

TL;DR: TLVD是一个结合大语言模型元数据推理能力和传统因果发现算法数据建模能力的新框架，用于推断潜在变量及其语义，在真实数据集上表现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现算法存在两个主要问题：1) 依赖"无潜在混杂因素"的假设，2) 忽视潜在变量的精确语义。同时缺乏高质量数据也限制了因果发现的实际应用。

Method: 提出TLVD三阶段框架：1) 数据驱动构建包含潜在变量的因果图；2) 多LLM协作进行潜在变量推断，建模为不完全信息博弈并寻求贝叶斯纳什均衡；3) 利用LLM进行证据探索以验证推断结果的可追溯性。

Result: 在三个医院提供的真实患者数据集和两个基准数据集上评估，TLVD在五个数据集上平均提升：准确率(Acc)32.67%、因果准确率(CAcc)62.21%、证据引用率(ECit)26.72%。

Conclusion: TLVD框架通过结合LLM的元数据推理能力和传统因果发现算法的数据建模能力，有效解决了潜在变量推断和语义理解问题，在真实世界应用中表现出显著效果和可靠性。

Abstract: Revealing the underlying causal mechanisms in the real world is crucial for scientific and technological progress. Despite notable advances in recent decades, the lack of high-quality data and the reliance of traditional causal discovery algorithms (TCDA) on the assumption of no latent confounders, as well as their tendency to overlook the precise semantics of latent variables, have long been major obstacles to the broader application of causal discovery. To address this issue, we propose a novel causal modeling framework, TLVD, which integrates the metadata-based reasoning capabilities of large language models (LLMs) with the data-driven modeling capabilities of TCDA for inferring latent variables and their semantics. Specifically, we first employ a data-driven approach to construct a causal graph that incorporates latent variables. Then, we employ multi-LLM collaboration for latent variable inference, modeling this process as a game with incomplete information and seeking its Bayesian Nash Equilibrium (BNE) to infer the possible specific latent variables. Finally, to validate the inferred latent variables across multiple real-world web-based data sources, we leverage LLMs for evidence exploration to ensure traceability. We comprehensively evaluate TLVD on three de-identified real patient datasets provided by a hospital and two benchmark datasets. Extensive experimental results confirm the effectiveness and reliability of TLVD, with average improvements of 32.67% in Acc, 62.21% in CAcc, and 26.72% in ECit across the five datasets.

</details>


### [100] [Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment](https://arxiv.org/abs/2602.14462)
*Hong Li,Zhen Zhou,Honggang Zhang,Yuping Luo,Xinyue Wang,Han Gong,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种轻量级诊断框架，用于检测数据并行训练中的"静默不一致性"问题，即尽管模型权重在每次迭代后数值相等，但工作节点间的优化动态可能存在潜在差异。


<details>
  <summary>Details</summary>
Motivation: 数据并行训练中，虽然参数同步保证了模型权重的数值等价性，但工作节点间的损失和梯度可能存在潜在差异，这种"静默不一致性"在传统的聚合监控信号下不可见，可能导致训练不稳定。

Method: 提出了一个轻量级、模型无关的诊断框架，包含三个互补指标：损失离散度、梯度范数离散度、以及通过工作节点间余弦相似度测量的梯度方向一致性。这些指标无需修改模型架构、同步机制或优化算法。

Result: 在8-NPU数据并行设置下，对1B参数的openPangu-Embedded-1B-V1.1模型进行全参数微调实验。结果显示，逐步去同步的数据洗牌和随机种子会导致损失/梯度离散度显著增加和方向对齐度降低，尽管全局平均损失曲线保持平滑。

Conclusion: 提出的指标能够有效揭示大规模数据并行微调中的隐藏不稳定模式，为更可靠的诊断和配置评估提供了可操作的可见性，有助于提高训练稳定性。

Abstract: Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of worker-level optimization dynamics before gradient aggregation. This paper identifies and studies this latent mismatch, termed \emph{silent inconsistency}, where cross-worker divergence in losses and gradients can remain invisible under conventional aggregated monitoring signals. We propose a lightweight, model-agnostic diagnostic framework that quantifies worker-level consistency using training signals readily available in standard pipelines. Specifically, we introduce three complementary metrics: loss dispersion, gradient-norm dispersion, and gradient-direction consistency measured by inter-worker cosine similarity. The proposed metrics incur negligible overhead and require no modification to model architecture, synchronization mechanisms, or optimization algorithms. We validate the framework by fully fine-tuning the 1B-parameter \texttt{openPangu-Embedded-1B-V1.1} model on the \texttt{tatsu-lab/alpaca} dataset using an 8-NPU DP setup, under controlled perturbations of cross-rank stochasticity. Experimental results show that progressively desynchronized data shuffling and random seeds lead to substantial increases in loss/gradient dispersion and reduced directional alignment, despite smooth globally averaged loss curves. These findings demonstrate that the proposed indicators provide actionable visibility into hidden instability modes in large-scale DP fine-tuning, enabling more reliable diagnosis and configuration assessment.

</details>


### [101] [LACONIC: Length-Aware Constrained Reinforcement Learning for LLM](https://arxiv.org/abs/2602.14468)
*Chang Liu,Yiran Zhao,Lawrence Liu,Yaoqi Ye,Csaba Szepesvári,Lin F. Yang*

Main category: cs.LG

TL;DR: LACONIC是一种强化学习方法，通过自适应长度成本控制，在保持任务性能的同时将输出长度减少50%以上


<details>
  <summary>Details</summary>
Motivation: 强化学习训练大语言模型时会产生过长的响应，增加推理延迟和计算开销。现有的长度控制方法依赖固定的启发式奖励调整，容易与任务目标不对齐且需要脆弱的调参

Method: 提出LACONIC方法，在训练期间强制执行目标令牌预算。使用增强目标更新策略模型，结合任务奖励和基于长度的成本。通过自适应调整成本规模来平衡简洁性和任务性能

Result: 在数学推理模型和数据集上，LACONIC保持或提高pass@1性能，同时将输出长度减少50%以上。在通用知识和多语言基准测试中保持域外性能，使用44%更少的令牌

Conclusion: LACONIC能够实现鲁棒的长度控制同时保持任务奖励，无需推理更改且部署开销最小，提供了理论保证支持

Abstract: Reinforcement learning (RL) has enhanced the capabilities of large language models (LLMs) through reward-driven training. Nevertheless, this process can introduce excessively long responses, inflating inference latency and computational overhead. Prior length-control approaches typically rely on fixed heuristic reward shaping, which can misalign with the task objective and require brittle tuning. In this work, we propose LACONIC, a reinforcement learning method that enforces a target token budget during training. Specifically, we update policy models using an augmented objective that combines the task reward with a length-based cost. To balance brevity and task performance, the cost scale is adaptively adjusted throughout training. This yields robust length control while preserving task reward. We provide a theoretical guarantee that support the method. Across mathematical reasoning models and datasets, LACONIC preserves or improves pass@1 while reducing output length by over 50%. It maintains out-of-domain performance on general knowledge and multilingual benchmarks with 44% fewer tokens. Moreover, LACONIC integrates into standard RL-tuning with no inference changes and minimal deployment overhead.

</details>


### [102] [One Good Source is All You Need: Near-Optimal Regret for Bandits under Heterogeneous Noise](https://arxiv.org/abs/2602.14474)
*Aadirupa Saha,Amith Bhat,Haipeng Luo*

Main category: cs.LG

TL;DR: SOAR算法解决多数据源多臂老虎机问题，通过快速剪枝高方差数据源，实现接近最优方差的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 传统多臂老虎机问题假设单一数据源，但现实应用中常面临多个具有不同噪声方差的数据源。如何自适应选择最佳数据源同时最小化遗憾是重要挑战。

Method: 提出SOAR算法：1) 使用方差集中界快速剪枝高方差数据源；2) 采用平衡的min-max LCB-UCB方法，同时识别最佳臂和最优（最小方差）数据源。

Result: SOAR获得实例依赖遗憾界为$\tilde{O}\left({σ^*}^2\sum_{i=2}^K \frac{\log T}{Δ_i} + \sqrt{K \sum_{j=1}^M σ_j^2}\right)$，接近单源最优方差${σ^*}^2$的遗憾，仅增加不可避免的源识别成本。

Conclusion: SOAR能在未知最小方差源的情况下，实现接近最优方差的遗憾性能，显著优于基线方法，在合成数据和真实数据集上表现优越。

Abstract: We study $K$-armed Multiarmed Bandit (MAB) problem with $M$ heterogeneous data sources, each exhibiting unknown and distinct noise variances $\{σ_j^2\}_{j=1}^M$. The learner's objective is standard MAB regret minimization, with the additional complexity of adaptively selecting which data source to query from at each round. We propose Source-Optimistic Adaptive Regret minimization (SOAR), a novel algorithm that quickly prunes high-variance sources using sharp variance-concentration bounds, followed by a `balanced min-max LCB-UCB approach' that seamlessly integrates the parallel tasks of identifying the best arm and the optimal (minimum-variance) data source. Our analysis shows SOAR achieves an instance-dependent regret bound of $\tilde{O}\left({σ^*}^2\sum_{i=2}^K \frac{\log T}{Δ_i} + \sqrt{K \sum_{j=1}^M σ_j^2}\right)$, up to preprocessing costs depending only on problem parameters, where ${σ^*}^2 := \min_j σ_j^2$ is the minimum source variance and $Δ_i$ denotes the suboptimality gap of the $i$-th arm. This result is both surprising as despite lacking prior knowledge of the minimum-variance source among $M$ alternatives, SOAR attains the optimal instance-dependent regret of standard single-source MAB with variance ${σ^*}^2$, while incurring only an small (and unavoidable) additive cost of $\tilde O(\sqrt{K \sum_{j=1}^M σ_j^2})$ towards the optimal (minimum variance) source identification. Our theoretical bounds represent a significant improvement over some proposed baselines, e.g. Uniform UCB or Explore-then-Commit UCB, which could potentially suffer regret scaling with $σ_{\max}^2$ in place of ${σ^*}^2$-a gap that can be arbitrarily large when $σ_{\max} \gg σ^*$. Experiments on multiple synthetic problem instances and the real-world MovieLens\;25M dataset, demonstrating the superior performance of SOAR over the baselines.

</details>


### [103] [Revisiting the Platonic Representation Hypothesis: An Aristotelian View](https://arxiv.org/abs/2602.14486)
*Fabian Gröger,Shuo Wen,Maria Brbić*

Main category: cs.LG

TL;DR: 论文提出一个校准框架来修正神经网络表示相似性度量中的尺度偏差，发现全局谱相似性度量校准后收敛消失，而局部邻域相似性保留显著一致性，提出亚里士多德表示假说。


<details>
  <summary>Details</summary>
Motivation: 现有度量表示相似性的方法存在网络尺度偏差问题（深度或宽度增加会系统性地提高相似性分数），这影响了柏拉图表示假说的验证准确性。

Method: 引入基于排列的零校准框架，将任何表示相似性度量转换为具有统计保证的校准分数，用于修正尺度偏差。

Result: 校准后发现：全局谱相似性度量报告的收敛现象基本消失，而局部邻域相似性（非局部距离）在不同模态间保持显著一致性。

Conclusion: 提出亚里士多德表示假说：神经网络表示正在收敛到共享的局部邻域关系，而非全局统计模型。

Abstract: The Platonic Representation Hypothesis suggests that representations from neural networks are converging to a common statistical model of reality. We show that the existing metrics used to measure representational similarity are confounded by network scale: increasing model depth or width can systematically inflate representational similarity scores. To correct these effects, we introduce a permutation-based null-calibration framework that transforms any representational similarity metric into a calibrated score with statistical guarantees. We revisit the Platonic Representation Hypothesis with our calibration framework, which reveals a nuanced picture: the apparent convergence reported by global spectral measures largely disappears after calibration, while local neighborhood similarity, but not local distances, retains significant agreement across different modalities. Based on these findings, we propose the Aristotelian Representation Hypothesis: representations in neural networks are converging to shared local neighborhood relationships.

</details>


### [104] [Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts](https://arxiv.org/abs/2602.14490)
*Buze Zhang,Jinkai Tao,Zilang Zeng,Neil He,Ali Maatouk,Menglin Yang,Rex Ying*

Main category: cs.LG

TL;DR: MoSLoRA：一种混合几何空间的参数高效微调方法，通过动态选择不同几何空间（如双曲、球面等）来增强语言模型表示能力，相比传统欧几里得空间方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法主要在欧几里得空间中操作，限制了捕捉语言数据复杂几何结构的能力。虽然其他几何空间（如双曲几何、球面流形）有理论优势，但强制使用单一流形类型会限制表达能力。

Method: 提出混合空间框架，同时利用多种几何空间学习更丰富的曲率感知表示。基于此开发MoSLoRA，扩展LoRA方法，包含异构几何专家，使模型能根据输入上下文动态选择或组合适当的几何空间。为减少频繁流形切换的计算开销，设计了轻量级路由机制。

Result: 在多个基准测试中，MoSLoRA始终优于强基线方法，在MATH500上提升达5.6%，在MAWPS上提升达15.9%。

Conclusion: 混合几何空间方法能有效增强语言模型的表示能力，通过动态选择适当的几何空间，在参数高效微调中取得显著性能提升，同时提供了曲率优化对训练稳定性和模型性能影响的实证见解。

Abstract: Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric structures inherent in language data. While alternative geometric spaces, like hyperbolic geometries for hierarchical data and spherical manifolds for circular patterns, offer theoretical advantages, forcing representations into a single manifold type ultimately limits expressiveness, even when curvature parameters are learnable. To address this, we propose Mixture of Space (MoS), a unified framework that leverages multiple geometric spaces simultaneously to learn richer, curvature-aware representations. Building on this scheme, we develop MoSLoRA, which extends Low-Rank Adaptation (LoRA) with heterogeneous geometric experts, enabling models to dynamically select or combine appropriate geometric spaces based on input context. Furthermore, to address the computational overhead of frequent manifold switching, we develop a lightweight routing mechanism. Moreover, we provide empirical insights into how curvature optimization impacts training stability and model performance. Our experiments across diverse benchmarks demonstrate that MoSLoRA consistently outperforms strong baselines, achieving up to 5.6% improvement on MATH500 and 15.9% on MAWPS.

</details>


### [105] [Divine Benevolence is an $x^2$: GLUs scale asymptotically faster than MLPs](https://arxiv.org/abs/2602.14495)
*Alejandro Francisco Queiruga*

Main category: cs.LG

TL;DR: 该论文从数值分析角度解释了GLU架构在LLM中成功的原因，发现GLU具有x²项，相比MLP能实现更快的渐进缩放（L(P)∝P⁻³ vs P⁻²），并提出了具有更陡缩放斜率的Gated Quadratic Unit。


<details>
  <summary>Details</summary>
Motivation: 理解为什么GLU变体在大型语言模型中占据主导地位，以及为什么类似的外积架构在排序模型中普遍存在。这些架构的成功大多被当作经验发现，缺乏理论解释。

Method: 应用数值分析工具，特别是函数逼近理论，分析GLU和MLP的缩放特性。通过参数构造和在一维函数逼近问题上的实证验证，比较两者的L(P)缩放斜率。

Result: 发现GLU具有x²项，使其在函数重构问题上具有L(P)∝P⁻³的缩放斜率，而MLP只有L(P)=P⁻²。基于此提出了具有更陡缩放斜率的Gated Quadratic Unit。

Conclusion: 从数值分析的第一性原理出发，可以解释GLU架构的优越缩放特性，并为从数值理论出发设计具有更优缩放性能的架构开辟了可能性，有望解锁大型模型的更优缩放。

Abstract: Scaling laws can be understood from ground-up numerical analysis, where traditional function approximation theory can explain shifts in model architecture choices. GLU variants now dominate frontier LLMs and similar outer-product architectures are prevalent in ranking models. The success of these architectures has mostly been left as an empirical discovery. In this paper, we apply the tools of numerical analysis to expose a key factor: these models have an $x^2$ which enables \emph{asymptotically} faster scaling than MLPs. GLUs have piecewise quadratic functional forms that are sufficient to exhibit quadratic order of approximation. Our key contribution is to demonstrate that the $L(P)$ scaling slope is $L(P)\propto P^{-3}$ for GLUs but only $L(P)=P^{-2}$ for MLPs on function reconstruction problems. We provide a parameter construction and empirical verification of these slopes for 1D function approximation. From the first principles we discover, we make one stride and propose the ``Gated Quadratic Unit'' which has an even steeper $L(P)$ slope than the GLU and MLP. This opens the possibility of architecture design from first principles numerical theory to unlock superior scaling in large models. Replication code is available at https://github.com/afqueiruga/divine_scaling.

</details>


### [106] [Covariance-Aware Transformers for Quadratic Programming and Decision Making](https://arxiv.org/abs/2602.14506)
*Kutay Tire,Yufan Zhang,Ege Onur Taga,Samet Oymak*

Main category: cs.LG

TL;DR: Transformer可以解决二次规划问题，并利用协方差矩阵提升时序基础模型在投资组合优化等决策问题中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer如何利用协方差矩阵解决二次规划问题，以提升涉及协方差矩阵的决策问题（如投资组合优化）的性能。

Method: 1) 证明线性注意力机制可通过逐行标记矩阵变量来求解无约束QP；2) 加入MLPs后，Transformer块可求解ℓ1惩罚QP（模拟迭代软阈值）和ℓ1约束QP（需额外反馈环）；3) 提出Time2Decide方法，在时序基础模型中显式输入变量间的协方差矩阵。

Result: Time2Decide在投资组合优化问题上一致优于基础时序模型，并在适当设置下优于传统的"预测-优化"流程。Transformer能从显式使用二阶统计量中受益，并能有效解决复杂决策问题。

Conclusion: Transformer能够有效解决二次规划问题，显式使用协方差矩阵能显著提升其在投资组合优化等决策任务中的性能，实现单次前向传播解决复杂决策问题。

Abstract: We explore the use of transformers for solving quadratic programs and how this capability benefits decision-making problems that involve covariance matrices. We first show that the linear attention mechanism can provably solve unconstrained QPs by tokenizing the matrix variables (e.g.~$A$ of the objective $\frac{1}{2}x^\top Ax+b^\top x$) row-by-row and emulating gradient descent iterations. Furthermore, by incorporating MLPs, a transformer block can solve (i) $\ell_1$-penalized QPs by emulating iterative soft-thresholding and (ii) $\ell_1$-constrained QPs when equipped with an additional feedback loop. Our theory motivates us to introduce Time2Decide: a generic method that enhances a time series foundation model (TSFM) by explicitly feeding the covariance matrix between the variates. We empirically find that Time2Decide uniformly outperforms the base TSFM model for the classical portfolio optimization problem that admits an $\ell_1$-constrained QP formulation. Remarkably, Time2Decide also outperforms the classical "Predict-then-Optimize (PtO)" procedure, where we first forecast the returns and then explicitly solve a constrained QP, in suitable settings. Our results demonstrate that transformers benefit from explicit use of second-order statistics, and this can enable them to effectively solve complex decision-making problems, like portfolio construction, in one forward pass.

</details>


### [107] [DeepMTL2R: A Library for Deep Multi-task Learning to Rank](https://arxiv.org/abs/2602.14519)
*Chaosheng Dong,Peiyao Xiao,Yijia Wang,Kaiyi Ji*

Main category: cs.LG

TL;DR: DeepMTL2R是一个开源深度学习框架，用于多任务学习排序，通过Transformer自注意力机制整合异构相关性信号，支持21种多任务学习算法和多目标优化，实现帕累托最优排序模型。


<details>
  <summary>Details</summary>
Motivation: 现代排序系统需要同时优化多个相关性标准，这些标准可能相互冲突。现有方法难以有效整合异构相关性信号并处理复杂的依赖关系，需要一个统一的、可扩展的框架来支持多任务学习排序。

Method: 基于Transformer架构的自注意力机制，整合异构相关性信号到统一的上下文感知模型中。框架包含21种最先进的多任务学习算法，支持多目标优化以识别帕累托最优排序模型，能够捕捉项目和标签间的复杂依赖关系和长距离交互。

Result: 在公开数据集上展示了有效性，报告了具有竞争力的性能，并可视化了目标间的权衡关系。框架已开源，支持现代排序系统的可扩展和表达性解决方案。

Conclusion: DeepMTL2R提供了一个强大的开源框架，用于多任务学习排序，能够有效处理多个相关性标准的优化问题，支持算法比较和帕累托最优模型发现，促进了多任务学习策略的研究和应用。

Abstract: This paper presents DeepMTL2R, an open-source deep learning framework for Multi-task Learning to Rank (MTL2R), where multiple relevance criteria must be optimized simultaneously. DeepMTL2R integrates heterogeneous relevance signals into a unified, context-aware model by leveraging the self-attention mechanism of transformer architectures, enabling effective learning across diverse and potentially conflicting objectives. The framework includes 21 state-of-the-art multi-task learning algorithms and supports multi-objective optimization to identify Pareto-optimal ranking models. By capturing complex dependencies and long-range interactions among items and labels, DeepMTL2R provides a scalable and expressive solution for modern ranking systems and facilitates controlled comparisons across MTL strategies. We demonstrate its effectiveness on a publicly available dataset, report competitive performance, and visualize the resulting trade-offs among objectives. DeepMTL2R is available at \href{https://github.com/amazon-science/DeepMTL2R}{https://github.com/amazon-science/DeepMTL2R}.

</details>


### [108] [Truly Adapting to Adversarial Constraints in Constrained MABs](https://arxiv.org/abs/2602.14543)
*Francesco Emanuele Stradi,Kalana Kalupahana,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti*

Main category: cs.LG

TL;DR: 论文研究了带未知约束的多臂老虎机问题，在非平稳环境下同时最小化损失和控制约束违反，提出了在不同反馈机制下的最优算法。


<details>
  <summary>Details</summary>
Motivation: 传统多臂老虎机问题只关注最小化损失，但实际应用中常存在未知约束需要控制。现有研究要么假设约束是随机的，要么在完全对抗性约束下放宽基准。本文旨在处理约束随机但损失任意变化的情况，并提供平滑退化的保证。

Method: 针对不同反馈机制设计算法：1）完全反馈下提出达到$\widetilde{\mathcal{O}}(\sqrt{T}+C)$后悔和$\widetilde{\mathcal{O}}(\sqrt{T}+C)$正违反的算法；2）损失只有老虎机反馈时扩展这些保证；3）约束只有老虎机反馈时设计达到$\widetilde{\mathcal{O}}(\sqrt{T}+C)$正违反和$\widetilde{\mathcal{O}}(\sqrt{T}+C\sqrt{T})$后悔的算法。

Result: 首次在约束随机而损失任意变化的情况下实现了最优后悔率和正约束违反率，同时保证随约束对抗性程度平滑退化。算法在不同反馈机制下都达到了理论最优边界。

Conclusion: 本文为带未知约束的非平稳多臂老虎机问题提供了首个最优算法框架，统一处理了随机和对抗性约束，在不同反馈机制下都实现了理论最优性能，填补了该领域的重要空白。

Abstract: We study the constrained variant of the \emph{multi-armed bandit} (MAB) problem, in which the learner aims not only at minimizing the total loss incurred during the learning dynamic, but also at controlling the violation of multiple \emph{unknown} constraints, under both \emph{full} and \emph{bandit feedback}. We consider a non-stationary environment that subsumes both stochastic and adversarial models and where, at each round, both losses and constraints are drawn from distributions that may change arbitrarily over time. In such a setting, it is provably not possible to guarantee both sublinear regret and sublinear violation. Accordingly, prior work has mainly focused either on settings with stochastic constraints or on relaxing the benchmark with fully adversarial constraints (\emph{e.g.}, via competitive ratios with respect to the optimum). We provide the first algorithms that achieve optimal rates of regret and \emph{positive} constraint violation when the constraints are stochastic while the losses may vary arbitrarily, and that simultaneously yield guarantees that degrade smoothly with the degree of adversariality of the constraints. Specifically, under \emph{full feedback} we propose an algorithm attaining $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ regret and $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ {positive} violation, where $C$ quantifies the amount of non-stationarity in the constraints. We then show how to extend these guarantees when only bandit feedback is available for the losses. Finally, when \emph{bandit feedback} is available for the constraints, we design an algorithm achieving $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ {positive} violation and $\widetilde{\mathcal{O}}(\sqrt{T}+C\sqrt{T})$ regret.

</details>


### [109] [Governing AI Forgetting: Auditing for Machine Unlearning Compliance](https://arxiv.org/abs/2602.14553)
*Qinqi Lin,Ningning Ding,Lingjie Duan,Jianwei Huang*

Main category: cs.LG

TL;DR: 提出首个机器学习遗忘合规性审计的经济框架，结合认证遗忘理论与监管执行，通过博弈论分析审计者与运营者策略互动，发现审计强度可随删除请求增加而降低。


<details>
  <summary>Details</summary>
Motivation: 尽管存在"被遗忘权"法律要求，AI运营者经常未能遵守数据删除请求。虽然机器学习遗忘提供了技术解决方案，但确保合规性仍然困难，因为存在技术可行性与监管实施之间的根本差距。

Method: 1) 使用认证遗忘的假设检验解释来表征遗忘固有的验证不确定性；2) 提出博弈论模型捕捉审计者与运营者间的策略互动；3) 将复杂的双变量非线性固定点问题转化为可处理的单变量辅助问题，解耦系统并建立均衡存在性、唯一性和结构性质。

Result: 反直觉地发现：随着删除请求增加，审计者可最优地降低检查强度，因为运营者的弱化遗忘使不合规更容易检测。这与近期中国审计减少但删除请求增加的现象一致。此外，证明未披露审计虽然为审计者提供信息优势，但相对于披露审计反而降低监管成本效益。

Conclusion: 提出了首个机器学习遗忘合规性审计的经济框架，解决了技术可行性与监管实施之间的差距。通过理论分析揭示了反直觉的审计策略，为监管机构提供了实用的政策见解，特别是在平衡审计强度与检测效率方面。

Abstract: Despite legal mandates for the right to be forgotten, AI operators routinely fail to comply with data deletion requests. While machine unlearning (MU) provides a technical solution to remove personal data's influence from trained models, ensuring compliance remains challenging due to the fundamental gap between MU's technical feasibility and regulatory implementation. In this paper, we introduce the first economic framework for auditing MU compliance, by integrating certified unlearning theory with regulatory enforcement. We first characterize MU's inherent verification uncertainty using a hypothesis-testing interpretation of certified unlearning to derive the auditor's detection capability, and then propose a game-theoretic model to capture the strategic interactions between the auditor and the operator. A key technical challenge arises from MU-specific nonlinearities inherent in the model utility and the detection probability, which create complex strategic couplings that traditional auditing frameworks do not address and that also preclude closed-form solutions. We address this by transforming the complex bivariate nonlinear fixed-point problem into a tractable univariate auxiliary problem, enabling us to decouple the system and establish the equilibrium existence, uniqueness, and structural properties without relying on explicit solutions. Counterintuitively, our analysis reveals that the auditor can optimally reduce the inspection intensity as deletion requests increase, since the operator's weakened unlearning makes non-compliance easier to detect. This is consistent with recent auditing reductions in China despite growing deletion requests. Moreover, we prove that although undisclosed auditing offers informational advantages for the auditor, it paradoxically reduces the regulatory cost-effectiveness relative to disclosed auditing.

</details>


### [110] [Fluid-Agent Reinforcement Learning](https://arxiv.org/abs/2602.14559)
*Shishir Sharma,Doina Precup,Theodore J. Perkins*

Main category: cs.LG

TL;DR: 本文提出了一种"流体智能体环境"框架，允许智能体动态创建其他智能体，解决了传统多智能体强化学习中智能体数量固定的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中智能体数量通常不固定且未知，智能体可以创建其他智能体（如细胞分裂、公司分拆）。传统多智能体强化学习研究固定数量智能体的交互，无法处理这种动态变化。

Method: 提出了流体智能体环境框架，允许智能体动态创建其他智能体。提出了流体智能体博弈的博弈论解概念，并在该框架下实证评估了多种多智能体强化学习算法。

Result: 实验包括Predator-Prey和Level-Based Foraging的流体变体，以及新引入的环境。结果显示该框架能产生根据环境需求动态调整团队规模的智能体团队，并展示了流体性如何解锁固定群体设置中无法观察到的新颖解决策略。

Conclusion: 流体智能体框架为处理动态智能体数量的现实场景提供了有效方法，能够产生适应环境需求动态调整规模的智能体团队，扩展了多智能体强化学习的应用范围。

Abstract: The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create other agents (for example, a cell may divide, or a company may spin off a division). In this paper, we propose a framework that allows agents to create other agents; we call this a fluid-agent environment. We present game-theoretic solution concepts for fluid-agent games and empirically evaluate the performance of several MARL algorithms within this framework. Our experiments include fluid variants of established benchmarks such as Predator-Prey and Level-Based Foraging, where agents can dynamically spawn, as well as a new environment we introduce that highlights how fluidity can unlock novel solution strategies beyond those observed in fixed-population settings. We demonstrate that this framework yields agent teams that adjust their size dynamically to match environmental demands.

</details>


### [111] [DCTracks: An Open Dataset for Machine Learning-Based Drift Chamber Track Reconstruction](https://arxiv.org/abs/2602.14571)
*Qian Liyan,Zhang Yao,Yuan Ye,Zhang Zhaoke,Fang Jin,Jiang Shimiao,Zhang Jin,Li Ke,Liu Beijiang,Xu Chenglin,Zhang Yifan,Jia Xiaoqian,Qin Xiaoshuai,Huang Xingtao*

Main category: cs.LG

TL;DR: 提出用于机器学习轨道重建的蒙特卡洛数据集，定义标准化评估指标，比较传统算法与图神经网络方法


<details>
  <summary>Details</summary>
Motivation: 为推进基于机器学习的轨道重建研究，需要标准化的数据集和评估指标，以便进行可重复、可比较的验证

Method: 创建包含单轨道和双轨道的漂移室事件蒙特卡洛数据集，定义轨道重建专用评估指标，测试传统算法和图神经网络方法

Result: 建立了标准化的评估框架，为传统算法和GNN方法提供了可比较的性能基准

Conclusion: 该数据集和评估指标为未来轨道重建研究提供了严格的、可重复的验证基础

Abstract: We introduce a Monte Carlo (MC) dataset of single- and two-track drift chamber events to advance Machine Learning (ML)-based track reconstruction. To enable standardized and comparable evaluation, we define track reconstruction specific metrics and report results for traditional track reconstruction algorithms and a Graph Neural Networks (GNNs) method, facilitating rigorous, reproducible validation for future research.

</details>


### [112] [RNM-TD3: N:M Semi-structured Sparse Reinforcement Learning From Scratch](https://arxiv.org/abs/2602.14578)
*Isam Vrce,Andreas Kassler,Gökçe Aydos*

Main category: cs.LG

TL;DR: 首次在强化学习中研究N:M结构化稀疏性，提出RNM-TD3框架，在保持硬件加速兼容性的同时，在50%-75%稀疏度下性能优于密集网络


<details>
  <summary>Details</summary>
Motivation: 现有DRL稀疏化方法多为非结构化细粒度稀疏，限制了硬件加速机会；结构化粗粒度稀疏虽能硬件加速但通常性能下降且剪枝复杂。需要平衡压缩、性能和硬件效率的稀疏化方法

Method: 提出RNM-TD3框架，在离策略RL（TD3）的所有网络中实施行级N:M稀疏性，保持与支持N:M稀疏矩阵运算的加速器兼容，在整个训练过程中强制执行这种稀疏模式

Result: 在连续控制基准测试中，RNM-TD3在50%-75%稀疏度（如2:4和1:4）下性能优于密集对应物，在Ant环境中2:4稀疏度下性能提升达14%，即使在87.5%稀疏度（1:8）下仍保持竞争力

Conclusion: N:M结构化稀疏在强化学习中实现了压缩、性能和硬件效率的良好平衡，为DRL的高效部署提供了有前景的解决方案

Abstract: Sparsity is a well-studied technique for compressing deep neural networks (DNNs) without compromising performance. In deep reinforcement learning (DRL), neural networks with up to 5% of their original weights can still be trained with minimal performance loss compared to their dense counterparts. However, most existing methods rely on unstructured fine-grained sparsity, which limits hardware acceleration opportunities due to irregular computation patterns. Structured coarse-grained sparsity enables hardware acceleration, yet typically degrades performance and increases pruning complexity. In this work, we present, to the best of our knowledge, the first study on N:M structured sparsity in RL, which balances compression, performance, and hardware efficiency. Our framework enforces row-wise N:M sparsity throughout training for all networks in off-policy RL (TD3), maintaining compatibility with accelerators that support N:M sparse matrix operations. Experiments on continuous-control benchmarks show that RNM-TD3, our N:M sparse agent, outperforms its dense counterpart at 50%-75% sparsity (e.g., 2:4 and 1:4), achieving up to a 14% increase in performance at 2:4 sparsity on the Ant environment. RNM-TD3 remains competitive even at 87.5% sparsity (1:8), while enabling potential training speedups.

</details>


### [113] [Replicable Constrained Bandits](https://arxiv.org/abs/2602.14580)
*Matteo Bollini,Gianmarco Genalti,Francesco Emanuele Stradi,Matteo Castiglioni,Alberto Marchesi*

Main category: cs.LG

TL;DR: 该论文首次研究了约束多臂老虎机问题中的算法可复制性，设计了可复制算法，其遗憾和约束违反与非可复制算法相当。


<details>
  <summary>Details</summary>
Motivation: 机器学习实验需要可重复性，算法可复制性要求在不同执行中做出相同决策。约束MAB问题中，学习者既要最大化奖励又要满足多个约束，研究如何在约束MAB中实现可复制性具有重要意义。

Method: 设计了可复制的约束MAB算法，关键步骤是开发了第一个可复制的UCB类算法用于无约束MAB，证明了采用乐观面对不确定性原则的算法可以是可复制的。

Result: 在约束MAB中实现了可复制性，设计的可复制算法的遗憾和约束违反在T方面与非可复制算法相匹配。

Conclusion: 可复制性可以在约束MAB问题中实现，且性能与非可复制算法相当，为机器学习实验的可重复性提供了重要保证。

Abstract: Algorithmic \emph{replicability} has recently been introduced to address the need for reproducible experiments in machine learning. A \emph{replicable online learning} algorithm is one that takes the same sequence of decisions across different executions in the same environment, with high probability. We initiate the study of algorithmic replicability in \emph{constrained} MAB problems, where a learner interacts with an unknown stochastic environment for $T$ rounds, seeking not only to maximize reward but also to satisfy multiple constraints. Our main result is that replicability can be achieved in constrained MABs. Specifically, we design replicable algorithms whose regret and constraint violation match those of non-replicable ones in terms of $T$. As a key step toward these guarantees, we develop the first replicable UCB-like algorithm for \emph{unconstrained} MABs, showing that algorithms that employ the optimism in-the-face-of-uncertainty principle can be replicable, a result that we believe is of independent interest.

</details>


### [114] [Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow](https://arxiv.org/abs/2602.14587)
*Minh Nguyen*

Main category: cs.LG

TL;DR: 提出解耦的连续时间actor-critic算法，通过交替更新解决连续时间控制问题，在金融交易和机器人控制任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现实世界控制问题（金融、机器人）在连续时间中演化，具有非均匀、事件驱动的决策特性。标准离散时间RL基于固定步长Bellman更新，在时间间隔缩小时Q函数会坍缩到值函数V，失去动作排序能力。现有连续时间方法通过优势率函数q重新引入动作信息，但使用复杂的鞅损失或正交约束，对测试过程选择敏感，将V和q耦合为复杂优化问题，难以可靠训练。

Method: 提出解耦的连续时间actor-critic算法，采用交替更新策略：1）q通过V的扩散生成器学习；2）V通过基于Hamiltonian的值流更新，该值流在无穷小时间步下仍保持信息性（标准max/softmax备份会失效）。理论上通过新的概率论证证明收敛，绕过了生成器基Hamiltonian在sup-norm下缺乏Bellman式收缩的挑战。

Result: 在具有挑战性的连续控制基准测试和真实世界交易任务中，该方法优于先前的连续时间方法和领先的离散时间基线，在单个季度实现21%的利润，几乎是最佳方法的2倍。

Conclusion: 提出的解耦连续时间actor-critic算法有效解决了连续时间RL中的关键问题，通过交替更新策略和新的理论框架，在理论和实证上都取得了显著改进，为现实世界连续时间控制问题提供了可靠解决方案。

Abstract: Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses to the value function $V$, eliminating action ranking. Existing continuous-time methods reintroduce action information via an advantage-rate function $q$. However, they enforce optimality through complicated martingale losses or orthogonality constraints, which are sensitive to the choice of test processes. These approaches entangle $V$ and $q$ into a large, complex optimization problem that is difficult to train reliably. To address these limitations, we propose a novel decoupled continuous-time actor-critic algorithm with alternating updates: $q$ is learned from diffusion generators on $V$, and $V$ is updated via a Hamiltonian-based value flow that remains informative under infinitesimal time steps, where standard max/softmax backups fail. Theoretically, we prove rigorous convergence via new probabilistic arguments, sidestepping the challenge that generator-based Hamiltonians lack Bellman-style contraction under the sup-norm. Empirically, our method outperforms prior continuous-time and leading discrete-time baselines across challenging continuous-control benchmarks and a real-world trading task, achieving 21% profit over a single quarter$-$nearly doubling the second-best method.

</details>


### [115] [OPBench: A Graph Benchmark to Combat the Opioid Crisis](https://arxiv.org/abs/2602.14602)
*Tianyi Ma,Yiyang Li,Yiyue Qian,Zheyuan Zhang,Zehong Wang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: OPBench是首个全面的阿片类药物危机基准测试，包含5个数据集，涵盖三个关键应用领域：医疗索赔中的阿片类药物过量检测、数字平台中的非法毒品贩运检测以及饮食模式中的药物滥用预测。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机持续肆虐全球社区，迫切需要计算解决方案。虽然图学习方法已成为建模复杂药物相关现象的有前景范式，但缺乏一个全面的基准来系统评估这些方法在真实世界阿片类药物危机场景中的表现。

Method: 引入OPBench基准，包含五个数据集，涵盖三个关键应用领域。采用异构图和超图等多样化图结构来保留药物相关数据中丰富复杂的关系信息。与领域专家和权威机构合作，遵循隐私和伦理准则进行数据收集和标注。建立统一的评估框架，包含标准化协议、预定义数据分割和可复现基线。

Result: 通过大量实验分析了现有图学习方法的优势和局限性，为未来阿片类药物危机研究提供了可操作的见解。代码和数据集已开源。

Conclusion: OPBench填补了阿片类药物危机研究中缺乏系统评估基准的空白，为公平、系统地比较图学习方法提供了统一框架，有助于推动对抗阿片类药物危机的研究进展。

Abstract: The opioid epidemic continues to ravage communities worldwide, straining healthcare systems, disrupting families, and demanding urgent computational solutions. To combat this lethal opioid crisis, graph learning methods have emerged as a promising paradigm for modeling complex drug-related phenomena. However, a significant gap remains: there is no comprehensive benchmark for systematically evaluating these methods across real-world opioid crisis scenarios. To bridge this gap, we introduce OPBench, the first comprehensive opioid benchmark comprising five datasets across three critical application domains: opioid overdose detection from healthcare claims, illicit drug trafficking detection from digital platforms, and drug misuse prediction from dietary patterns. Specifically, OPBench incorporates diverse graph structures, including heterogeneous graphs and hypergraphs, to preserve the rich and complex relational information among drug-related data. To address data scarcity, we collaborate with domain experts and authoritative institutions to curate and annotate datasets while adhering to privacy and ethical guidelines. Furthermore, we establish a unified evaluation framework with standardized protocols, predefined data splits, and reproducible baselines to facilitate fair and systematic comparison among graph learning methods. Through extensive experiments, we analyze the strengths and limitations of existing graph learning methods, thereby providing actionable insights for future research in combating the opioid crisis. Our source code and datasets are available at https://github.com/Tianyi-Billy-Ma/OPBench.

</details>


### [116] [Concepts' Information Bottleneck Models](https://arxiv.org/abs/2602.14626)
*Karim Galliamov,Syed M Ahsan Kazmi,Adil Khan,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 该论文提出在概念瓶颈模型(CBMs)的概念层加入信息瓶颈正则化，通过惩罚I(X;C)同时保持I(C;Y)中的任务相关信息，从而获得最小充分的概念表示，提高预测性能和概念干预的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型(CBMs)虽然通过人类可理解的概念层提供可解释预测，但存在准确率下降和概念泄漏问题，这破坏了模型的忠实性。需要一种方法来改进CBMs的预测性能和概念干预的可靠性。

Method: 在概念瓶颈模型的概念层引入显式的信息瓶颈正则化器，惩罚输入X与概念C之间的互信息I(X;C)，同时保持概念C与标签Y之间的任务相关信息I(C;Y)。提出了两种实用变体：变分目标函数和基于熵的替代方法，无需改变架构或额外监督即可集成到标准CBM训练中。

Result: 在六个CBM家族和三个基准测试上的评估表明，信息瓶颈正则化模型始终优于原始版本。信息平面分析进一步证实了预期行为，表明强制执行最小充分概念瓶颈既提高了预测性能，也增强了概念级干预的可靠性。

Conclusion: 提出的正则化器为更忠实和可干预的CBMs提供了一条理论基础、架构无关的路径，通过统一训练协议解决了先前评估的不一致性，并在不同模型家族和数据集上展示了稳健的性能提升。

Abstract: Concept Bottleneck Models (CBMs) aim to deliver interpretable predictions by routing decisions through a human-understandable concept layer, yet they often suffer reduced accuracy and concept leakage that undermines faithfulness. We introduce an explicit Information Bottleneck regularizer on the concept layer that penalizes $I(X;C)$ while preserving task-relevant information in $I(C;Y)$, encouraging minimal-sufficient concept representations. We derive two practical variants (a variational objective and an entropy-based surrogate) and integrate them into standard CBM training without architectural changes or additional supervision. Evaluated across six CBM families and three benchmarks, the IB-regularized models consistently outperform their vanilla counterparts. Information-plane analyses further corroborate the intended behavior. These results indicate that enforcing a minimal-sufficient concept bottleneck improves both predictive performance and the reliability of concept-level interventions. The proposed regularizer offers a theoretic-grounded, architecture-agnostic path to more faithful and intervenable CBMs, resolving prior evaluation inconsistencies by aligning training protocols and demonstrating robust gains across model families and datasets.

</details>


### [117] [Alignment Adapter to Improve the Performance of Compressed Deep Learning Models](https://arxiv.org/abs/2602.14635)
*Rohit Raj Rai,Abhishek Dhaka,Amit Awekar*

Main category: cs.LG

TL;DR: 提出Alignment Adapter (AlAd)，一种轻量级滑动窗口适配器，用于提升压缩深度学习模型的性能，使其接近原始大模型水平。


<details>
  <summary>Details</summary>
Motivation: 压缩的深度学习模型在资源受限环境中部署很重要，但其性能通常落后于大规模模型。需要一种方法来缩小压缩模型与原始大模型之间的性能差距。

Method: 提出Alignment Adapter (AlAd)：轻量级滑动窗口适配器，将压缩模型的token级嵌入与原始大模型的嵌入对齐。保持局部上下文语义，支持不同维度或架构的灵活对齐，且与底层压缩方法无关。可部署为冻结压缩模型的即插即用模块，或与压缩模型联合微调以获得更好性能。

Result: 在BERT系列模型和三个token级NLP任务上的实验表明，AlAd显著提升了压缩模型的性能，同时只增加了极小的尺寸和延迟开销。

Conclusion: AlAd是一种有效的适配器方法，能够显著提升压缩深度学习模型的性能，使其更接近原始大模型，同时保持轻量级特性，适合资源受限环境部署。

Abstract: Compressed Deep Learning (DL) models are essential for deployment in resource-constrained environments. But their performance often lags behind their large-scale counterparts. To bridge this gap, we propose Alignment Adapter (AlAd): a lightweight, sliding-window-based adapter. It aligns the token-level embeddings of a compressed model with those of the original large model. AlAd preserves local contextual semantics, enables flexible alignment across differing dimensionalities or architectures, and is entirely agnostic to the underlying compression method. AlAd can be deployed in two ways: as a plug-and-play module over a frozen compressed model, or by jointly fine-tuning AlAd with the compressed model for further performance gains. Through experiments on BERT-family models across three token-level NLP tasks, we demonstrate that AlAd significantly boosts the performance of compressed models with only marginal overhead in size and latency.

</details>


### [118] [An Embarrassingly Simple Way to Optimize Orthogonal Matrices at Scale](https://arxiv.org/abs/2602.14656)
*Adrián Javaloy,Antonio Vergari*

Main category: cs.LG

TL;DR: 提出POGO优化算法，高效解决大规模正交约束优化问题，相比现有方法显著提升速度并保持正交性


<details>
  <summary>Details</summary>
Motivation: 当前正交约束优化器计算昂贵，难以扩展到数百或数千个约束的问题。虽然Landing算法有所改进，但会暂时放松正交性，且无法利用现代自适应优化器

Method: 改进Landing算法的思想，开发POGO算法，结合现代自适应优化器，确保正交约束有效满足。算法仅需5个矩阵乘积，GPU友好，始终保持正交性

Result: POGO在多个挑战性基准测试中大幅优于近期优化器，能在几分钟内优化数千个正交矩阵的问题，而替代方法需要数小时

Conclusion: POGO为在机器学习中大规模利用正交约束设定了里程碑，提供了高效实用的解决方案

Abstract: Orthogonality constraints are ubiquitous in robust and probabilistic machine learning. Unfortunately, current optimizers are computationally expensive and do not scale to problems with hundreds or thousands of constraints. One notable exception is the Landing algorithm (Ablin et al., 2024) which, however comes at the expense of temporarily relaxing orthogonality. In this work, we revisit and improve on the ideas behind Landing, enabling the inclusion of modern adaptive optimizers while ensuring that orthogonal constraints are effectively met. Remarkably, these improvements come at little to no cost, and reduce the number of required hyperparemeters. Our algorithm POGO is fast and GPU-friendly, consisting of only 5 matrix products, and in practice maintains orthogonality at all times. On several challenging benchmarks, POGO greatly outperforms recent optimizers and shows it can optimize problems with thousands of orthogonal matrices in minutes while alternatives would take hours. As such, POGO sets a milestone to finally exploit orthogonality constraints in ML at scale. A PyTorch implementation of POGO is publicly available at https://github.com/adrianjav/pogo.

</details>


### [119] [Pseudo-differential-enhanced physics-informed neural networks](https://arxiv.org/abs/2602.14663)
*Andrew Gracyk*

Main category: cs.LG

TL;DR: 提出伪微分增强物理信息神经网络(PINNs)，在傅里叶空间进行梯度增强，通过傅里叶变换将PDE残差提升到更高微分阶数，改善训练效果和学习保真度。


<details>
  <summary>Details</summary>
Motivation: 传统梯度增强PINNs在物理空间进行高阶微分增强，但存在局限性。作者希望在傅里叶空间实现类似增强，利用傅里叶空间中微分等价于波数乘法的特性，提高训练效率和精度。

Method: 在傅里叶空间对PDE残差进行伪微分增强：1) 将残差转换到傅里叶空间；2) 乘以波数进行微分增强；3) 作为增强项加入目标函数。方法支持分数阶导数，兼容傅里叶特征嵌入等技术。

Result: 方法在较少训练迭代中达到优于数值方法的PINN误差，在低配点设置中能突破平台期，改善神经正切核(NTK)的谱特征值衰减，促进高频分量学习，缓解频率偏差问题。

Conclusion: 伪微分增强PINNs在傅里叶空间实现高效梯度增强，提升训练效率和精度，支持多种域和分数阶导数，为PINNs训练提供新思路。

Abstract: We present pseudo-differential enhanced physics-informed neural networks (PINNs), an extension of gradient enhancement but in Fourier space. Gradient enhancement of PINNs dictates that the PDE residual is taken to a higher differential order than prescribed by the PDE, added to the objective as an augmented term in order to improve training and overall learning fidelity. We propose the same procedure after application via Fourier transforms, since differentiating in Fourier space is multiplication with the Fourier wavenumber under suitable decay. Our methods are fast and efficient. Our methods oftentimes achieve superior PINN versus numerical error in fewer training iterations, potentially pair well with few samples in collocation, and can on occasion break plateaus in low collocation settings. Moreover, our methods are suitable for fractional derivatives. We establish that our methods improve spectral eigenvalue decay of the neural tangent kernel (NTK), and so our methods contribute towards the learning of high frequencies in early training, mitigating the effects of frequency bias up to the polynomial order and possibly greater with smooth activations. Our methods accommodate advanced techniques in PINNs, such as Fourier feature embeddings. A pitfall of discrete Fourier transforms via the Fast Fourier Transform (FFT) is mesh subjugation, and so we demonstrate compatibility of our methods for greater mesh flexibility and invariance on alternative Euclidean and non-Euclidean domains via Monte Carlo methods and otherwise.

</details>


### [120] [Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error](https://arxiv.org/abs/2602.14682)
*Farzan Farnia,Mohammad Jalali,Azim Ospanov*

Main category: cs.LG

TL;DR: 研究发现现代生成模型存在系统性多样性低估偏差，测试数据多样性显著高于生成样本，并提出基于熵的多样性评分和正则化策略来缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 虽然深度生成模型在样本质量方面取得巨大成功，但模型是否忠实捕捉底层数据分布的多样性这一重要问题尚未得到系统研究。本文旨在探究生成模型在多样性方面的表现偏差。

Method: 使用无参考的基于熵的多样性评分方法（Vendi和RKE），直接比较最先进生成模型的生成样本与测试数据分布的多样性。分析有限样本下熵基多样性评分的行为特征，并探讨基于Vendi和RKE的多样性感知正则化和引导策略。

Result: 在多个基准数据集上，测试数据的Vendi和RKE多样性评分始终显著高于生成样本，表明现代生成模型存在系统性向下多样性偏差。研究发现熵基多样性评分的期望值随样本量增加而增加，导致基于有限训练集估计的多样性会固有地低估真实分布的多样性。

Conclusion: 优化生成器以最小化与经验数据分布的散度会导致多样性损失。基于Vendi和RKE的多样性感知正则化和引导策略是缓解这种偏差的有原则方向，实证证据表明这些策略有潜力改善结果。

Abstract: Deep generative models have achieved great success in producing high-quality samples, making them a central tool across machine learning applications. Beyond sample quality, an important yet less systematically studied question is whether trained generative models faithfully capture the diversity of the underlying data distribution. In this work, we address this question by directly comparing the diversity of samples generated by state-of-the-art models with that of test samples drawn from the target data distribution, using recently proposed reference-free entropy-based diversity scores, Vendi and RKE. Across multiple benchmark datasets, we find that test data consistently attains substantially higher Vendi and RKE diversity scores than the generated samples, suggesting a systematic downward diversity bias in modern generative models. To understand the origin of this bias, we analyze the finite-sample behavior of entropy-based diversity scores and show that their expected values increase with sample size, implying that diversity estimated from finite training sets could inherently underestimate the diversity of the true distribution. As a result, optimizing the generators to minimize divergence to empirical data distributions would induce a loss of diversity. Finally, we discuss potential diversity-aware regularization and guidance strategies based on Vendi and RKE as principled directions for mitigating this bias, and provide empirical evidence suggesting their potential to improve the results.

</details>


### [121] [SynthSAEBench: Evaluating Sparse Autoencoders on Scalable Realistic Synthetic Data](https://arxiv.org/abs/2602.14687)
*David Chanin,Adrià Garriga-Alonso*

Main category: cs.LG

TL;DR: SynthSAEBench是一个用于稀疏自编码器(SAE)评估的工具包，通过生成具有真实特征的大规模合成数据来精确比较SAE架构，发现了新的失败模式并验证了现有观察。


<details>
  <summary>Details</summary>
Motivation: 当前SAE基准测试在LLM上噪声太大，无法区分架构改进；而合成数据实验规模太小且不真实，无法提供有意义的比较。需要一种能够精确验证SAE架构创新的基准测试方法。

Method: 引入SynthSAEBench工具包，生成具有相关特征（相关性、层次结构、叠加）的大规模合成数据，并创建标准化基准模型SynthSAEBench-16k，实现SAE架构的直接比较。

Result: 基准测试重现了多个先前观察到的LLM SAE现象，包括重建与潜在质量指标之间的脱节、SAE探测结果差、以及由L0调节的精度-召回权衡。还发现了新的失败模式：匹配追踪SAE利用叠加噪声来改进重建而不学习真实特征。

Conclusion: SynthSAEBench通过提供真实特征和受控消融，补充了LLM基准测试，使研究人员能够在扩展到LLM之前精确诊断SAE失败模式并验证架构改进。

Abstract: Improving Sparse Autoencoders (SAEs) requires benchmarks that can precisely validate architectural innovations. However, current SAE benchmarks on LLMs are often too noisy to differentiate architectural improvements, and current synthetic data experiments are too small-scale and unrealistic to provide meaningful comparisons. We introduce SynthSAEBench, a toolkit for generating large-scale synthetic data with realistic feature characteristics including correlation, hierarchy, and superposition, and a standardized benchmark model, SynthSAEBench-16k, enabling direct comparison of SAE architectures. Our benchmark reproduces several previously observed LLM SAE phenomena, including the disconnect between reconstruction and latent quality metrics, poor SAE probing results, and a precision-recall trade-off mediated by L0. We further use our benchmark to identify a new failure mode: Matching Pursuit SAEs exploit superposition noise to improve reconstruction without learning ground-truth features, suggesting that more expressive encoders can easily overfit. SynthSAEBench complements LLM benchmarks by providing ground-truth features and controlled ablations, enabling researchers to precisely diagnose SAE failure modes and validate architectural improvements before scaling to LLMs.

</details>


### [122] [A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)](https://arxiv.org/abs/2602.14696)
*Nihal V. Nayak,Paula Rodriguez-Diaz,Neha Hulkund,Sara Beery,David Alvarez-Melis*

Main category: cs.LG

TL;DR: 本文系统分析了指令微调中的数据选择方法，发现梯度表示与贪心轮询算法在低预算下表现最佳，并统一了现有算法为近似距离最小化问题。


<details>
  <summary>Details</summary>
Motivation: 指令微调中如何为目标任务选择训练数据缺乏系统指导，现有研究碎片化、方法不透明，需要澄清数据表示和选择算法这两个核心要素的作用。

Method: 提出一个分析框架，分离数据表示和选择算法，在模型、任务和预算上进行控制比较，将现有算法统一为查询集与选择子集间的近似距离最小化问题。

Result: 只有基于梯度的数据表示能稳定预测性能；梯度表示+贪心轮询在低预算下平均表现最佳，但高预算时优势减弱；为多种算法提供了新的泛化界限。

Conclusion: 研究为LLM微调中的数据选择提供了关键见解和理论基础，促进了更原则化的数据选择方法发展。

Abstract: Instruction fine-tuning of large language models (LLMs) often involves selecting a subset of instruction training data from a large candidate pool, using a small query set from the target task. Despite growing interest, the literature on targeted instruction selection remains fragmented and opaque: methods vary widely in selection budgets, often omit zero-shot baselines, and frequently entangle the contributions of key components. As a result, practitioners lack actionable guidance on selecting instructions for their target tasks. In this work, we aim to bring clarity to this landscape by disentangling and systematically analyzing the two core ingredients: data representation and selection algorithms. Our framework enables controlled comparisons across models, tasks, and budgets. We find that only gradient-based data representations choose subsets whose similarity to the query consistently predicts performance across datasets and models. While no single method dominates, gradient-based representations paired with a greedy round-robin selection algorithm tend to perform best on average at low budgets, but these benefits diminish at larger budgets. Finally, we unify several existing selection algorithms as forms of approximate distance minimization between the selected subset and the query set, and support this view with new generalization bounds. More broadly, our findings provide critical insights and a foundation for more principled data selection in LLM fine-tuning. The code is available at https://github.com/dcml-lab/targeted-instruction-selection.

</details>


### [123] [Unbiased Approximate Vector-Jacobian Products for Efficient Backpropagation](https://arxiv.org/abs/2602.14701)
*Killian Bakong,Laurent Massoulié,Edouard Oyallon,Kevin Scaman*

Main category: cs.LG

TL;DR: 提出一种通过随机化、无偏近似向量-雅可比乘积来降低深度神经网络训练计算和内存成本的方法


<details>
  <summary>Details</summary>
Motivation: 降低深度神经网络训练的计算和内存成本，这是深度学习应用中的主要瓶颈

Method: 在反向传播中用随机化、无偏的近似代替精确的向量-雅可比乘积，并识别具有最小方差的最优无偏估计

Result: 理论分析了精度与成本降低之间的权衡，实验验证了该方法在多层感知机、BagNets和视觉Transformer上的有效性

Conclusion: 提出的无偏随机化反向传播方法具有降低深度学习成本的潜力，理论分析和实验验证都支持这一结论

Abstract: In this work we introduce methods to reduce the computational and memory costs of training deep neural networks. Our approach consists in replacing exact vector-jacobian products by randomized, unbiased approximations thereof during backpropagation. We provide a theoretical analysis of the trade-off between the number of epochs needed to achieve a target precision and the cost reduction for each epoch. We then identify specific unbiased estimates of vector-jacobian products for which we establish desirable optimality properties of minimal variance under sparsity constraints. Finally we provide in-depth experiments on multi-layer perceptrons, BagNets and Visual Transfomers architectures. These validate our theoretical results, and confirm the potential of our proposed unbiased randomized backpropagation approach for reducing the cost of deep learning.

</details>


### [124] [D2-LoRA: A Synergistic Approach to Differential and Directional Low-Rank Adaptation](https://arxiv.org/abs/2602.14728)
*Nozomu Fujisawa,Masaaki Kondo*

Main category: cs.LG

TL;DR: D2-LoRA：一种参数高效微调方法，通过带符号的低秩残差更新和列向投影，在少量训练数据下实现高性能，同时保持推理时的代数可合并性。


<details>
  <summary>Details</summary>
Motivation: 在有限数据和计算资源下，系统探索参数高效微调的设计空间，寻求在保持推理效率的同时提升性能的方法。

Method: 结合带符号的低秩残差更新（加减分量）和训练时的列向投影，保持每列接近原始范数。训练后将适配器合并为单一权重矩阵，实现零推理延迟。

Result: 在8个问答和阅读理解基准上平均准确率达76.4%（仅用5k样本/任务，2个epoch）。相比LoRA提升2.2个百分点，相比DoRA在多数任务上表现相当或更好。生成任务也有提升，训练波动降低36%。

Conclusion: D2-LoRA在参数高效微调中实现了性能、效率和可合并性的平衡，通过创新的架构设计而非单纯增加参数量来提升效果。

Abstract: We systematically investigate the parameter-efficient fine-tuning design space under practical data and compute constraints, and propose D2-LoRA. D2-LoRA achieves 76.4 percent average accuracy across eight question answering and reading comprehension benchmarks using only 5k training samples per task and two epochs, while preserving algebraic mergeability at inference with near-exact numerical equivalence. The method combines signed low-rank residual updates with additive and subtractive components, together with a train-time column-wise projection that keeps each column close to its original norm. After training, the adapter is merged into a single weight matrix, adding zero inference latency. Compared with LoRA, D2-LoRA improves average accuracy by 2.2 percentage points; at matched parameter counts (LoRA rank 2r versus D2-LoRA rank r), the improvement is 1.6 points, indicating gains from architectural design rather than increased parameterization. Compared with DoRA, it matches or exceeds performance on most tasks. Beyond QA and reading comprehension, D2-LoRA improves generative tasks (plus 1.2 ROUGE-L and plus 1.1 percent win rate) and shows 36 percent lower training volatility. The merge preserves numerical fidelity (mean gap about 0.03 percentage points) and recovers about 1.91x evaluation throughput. Training overhead is 19 percent, comparable to DoRA, and decreases with longer input sequences. We provide a geometric analysis explaining how the projection stabilizes training, together with ablation studies isolating the contribution of each design component.

</details>


### [125] [Scale redundancy and soft gauge fixing in positively homogeneous neural networks](https://arxiv.org/abs/2602.14729)
*Rodrigo Carmo Terin*

Main category: cs.LG

TL;DR: 论文研究神经网络中正齐次激活函数的连续重参数化对称性，将其解释为规范冗余，并提出规范适应坐标和软轨道选择方法改善优化稳定性


<details>
  <summary>Details</summary>
Motivation: 神经网络中正齐次激活函数存在神经元尺度重标度的连续对称性，这种对称性导致参数空间存在冗余轨道，可能影响优化过程的稳定性和收敛性

Method: 1) 将尺度对称性解释为规范冗余；2) 引入规范适应坐标分离不变和尺度不平衡方向；3) 借鉴场论中的规范固定，提出软轨道选择（范数平衡）泛函；4) 该泛函仅作用于冗余尺度坐标，诱导不平衡模式的耗散松弛

Result: 理论分析表明轨道选择惩罚能诱导不平衡模式的耗散松弛；实验证明该方法能扩展稳定学习率范围，抑制尺度漂移，同时不改变网络表达能力

Conclusion: 建立了规范轨道几何与优化条件之间的结构联系，为规范理论概念与机器学习提供了具体连接，展示了利用对称性改善神经网络优化的新途径

Abstract: Neural networks with positively homogeneous activations exhibit an exact continuous reparametrization symmetry: neuron-wise rescalings generate parameter-space orbits along which the input--output function is invariant. We interpret this symmetry as a gauge redundancy and introduce gauge-adapted coordinates that separate invariant and scale-imbalance directions. Inspired by gauge fixing in field theory, we introduce a soft orbit-selection (norm-balancing) functional acting only on redundant scale coordinates. We show analytically that it induces dissipative relaxation of imbalance modes to preserve the realized function. In controlled experiments, this orbit-selection penalty expands the stable learning-rate regime and suppresses scale drift without changing expressivity. These results establish a structural link between gauge-orbit geometry and optimization conditioning, providing a concrete connection between gauge-theoretic concepts and machine learning.

</details>


### [126] [Parameter-Minimal Neural DE Solvers via Horner Polynomials](https://arxiv.org/abs/2602.14737)
*T. Matulić,D. Seršić*

Main category: cs.LG

TL;DR: 提出一种参数极少的神经网络架构，通过将假设类限制为Horner分解多项式来求解微分方程，得到隐式可微的试解，仅需少量可学习系数。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络求解微分方程通常需要大量参数，本文旨在开发一种参数极少的架构，实现资源高效的科学建模。

Method: 1. 将假设类限制为Horner分解多项式，构建隐式可微的试解；2. 通过固定低阶多项式自由度精确满足初始条件；3. 引入分段（类样条）扩展，在子区间训练多个小型Horner模型，同时在边界处强制连续性（和一阶导数连续性）。

Result: 在ODE基准测试和热方程示例中，仅用数十个参数的Horner网络能准确匹配解及其导数，在相同训练设置下优于小型MLP和正弦表示基线，展示了实用的精度-参数权衡。

Conclusion: Horner网络提供了一种参数高效的微分方程求解方法，特别适合资源受限的科学建模场景，通过多项式表示和分段扩展实现了良好的精度-参数权衡。

Abstract: We propose a parameter-minimal neural architecture for solving differential equations by restricting the hypothesis class to Horner-factorized polynomials, yielding an implicit, differentiable trial solution with only a small set of learnable coefficients. Initial conditions are enforced exactly by construction by fixing the low-order polynomial degrees of freedom, so training focuses solely on matching the differential-equation residual at collocation points. To reduce approximation error without abandoning the low-parameter regime, we introduce a piecewise ("spline-like") extension that trains multiple small Horner models on subintervals while enforcing continuity (and first-derivative continuity) at segment boundaries. On illustrative ODE benchmarks and a heat-equation example, Horner networks with tens (or fewer) parameters accurately match the solution and its derivatives and outperform small MLP and sinusoidal-representation baselines under the same training settings, demonstrating a practical accuracy-parameter trade-off for resource-efficient scientific modeling.

</details>


### [127] [Inner Loop Inference for Pretrained Transformers: Unlocking Latent Capabilities Without Training](https://arxiv.org/abs/2602.14759)
*Jonathan Lys,Vincent Gripon,Bastien Pasdeloup,Lukas Mauch,Fabien Cardinaux,Ghouthi Boukli Hacene*

Main category: cs.LG

TL;DR: 提出"推理时内部循环"方法，通过重复应用预训练语言模型中的选定块范围来延长细化过程，在冻结模型上获得准确率提升


<details>
  <summary>Details</summary>
Motivation: 基于Transformer架构中残差连接使内部表示可视为潜在表示的迭代细化的观察，以及早期解码和细化层存在的假设，探索通过延长细化过程来提升模型性能

Method: 在推理阶段对预训练语言模型的选定块范围进行重复应用（内部循环），延长细化过程而不改变模型参数

Result: 在多个基准测试中，内部循环带来了适度但一致的准确率提升，潜在轨迹分析显示更稳定的状态演化和持续的语义细化

Conclusion: 通过简单的测试时循环可以在冻结的预训练模型中扩展计算，获得额外的细化效果，为模型推理优化提供了新思路

Abstract: Deep Learning architectures, and in particular Transformers, are conventionally viewed as a composition of layers. These layers are actually often obtained as the sum of two contributions: a residual path that copies the input and the output of a Transformer block. As a consequence, the inner representations (i.e. the input of these blocks) can be interpreted as iterative refinement of a propagated latent representation. Under this lens, many works suggest that the inner space is shared across layers, meaning that tokens can be decoded at early stages. Mechanistic interpretability even goes further by conjecturing that some layers act as refinement layers. Following this path, we propose inference-time inner looping, which prolongs refinement in pretrained off-the-shelf language models by repeatedly re-applying a selected block range. Across multiple benchmarks, inner looping yields modest but consistent accuracy improvements. Analyses of the resulting latent trajectories suggest more stable state evolution and continued semantic refinement. Overall, our results suggest that additional refinement can be obtained through simple test-time looping, extending computation in frozen pretrained models.

</details>


### [128] [Universal Algorithm-Implicit Learning](https://arxiv.org/abs/2602.14761)
*Stefano Woerner,Seong Joon Oh,Christian F. Baumgartner*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架来形式化元学习的实用性，并提出了TAIL——一种基于Transformer的算法隐式元学习器，能够在不同领域、模态和标签配置的任务中工作。


<details>
  <summary>Details</summary>
Motivation: 当前元学习方法局限于狭窄的任务分布和固定的特征/标签空间，限制了应用范围。同时，元学习文献中"通用"和"通用目的"等术语使用不一致且缺乏精确定义，阻碍了可比性。

Method: 提出了一个理论框架，形式化定义了实用通用性，并区分了算法显式和算法隐式学习。基于此框架，提出了TAIL——一种基于Transformer的算法隐式元学习器，具有三个创新：跨模态特征编码的随机投影、可外推到更大标签空间的随机注入标签嵌入，以及高效的内联查询处理。

Result: TAIL在标准少样本基准测试中达到最先进性能，同时能泛化到未见领域。它还能泛化到未见模态（如仅用图像训练却能解决文本分类任务），处理比训练时多20倍的类别数，并且比之前基于Transformer的方法节省数量级的计算成本。

Conclusion: 该研究为元学习提供了一个形式化的理论框架和词汇表，并展示了TAIL作为实用通用元学习器的有效性，能够跨领域、模态和标签配置工作，解决了当前元学习方法的局限性。

Abstract: Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting applicability. Moreover, the current meta-learning literature uses key terms like "universal" and "general-purpose" inconsistently and lacks precise definitions, hindering comparability. We introduce a theoretical framework for meta-learning which formally defines practical universality and introduces a distinction between algorithm-explicit and algorithm-implicit learning, providing a principled vocabulary for reasoning about universal meta-learning methods. Guided by this framework, we present TAIL, a transformer-based algorithm-implicit meta-learner that functions across tasks with varying domains, modalities, and label configurations. TAIL features three innovations over prior transformer-based meta-learners: random projections for cross-modal feature encoding, random injection label embeddings that extrapolate to larger label spaces, and efficient inline query processing. TAIL achieves state-of-the-art performance on standard few-shot benchmarks while generalizing to unseen domains. Unlike other meta-learning methods, it also generalizes to unseen modalities, solving text classification tasks despite training exclusively on images, handles tasks with up to 20$\times$ more classes than seen during training, and provides orders-of-magnitude computational savings over prior transformer-based approaches.

</details>


### [129] [Learning Structural Hardness for Combinatorial Auctions: Instance-Dependent Algorithm Selection via Graph Neural Networks](https://arxiv.org/abs/2602.14772)
*Sungwoo Kang*

Main category: cs.LG

TL;DR: 该论文提出了一种机器学习方法，用于预测组合拍卖中贪心算法何时会失败，并通过算法选择框架结合贪心算法和GNN专家模型来提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 组合拍卖中的胜者确定问题（WDP）是NP难问题，现有方法无法可靠预测哪些实例会击败快速贪心启发式算法。虽然机器学习社区专注于学习替代求解器，但GNN在标准基准测试中很少优于经典方法。因此，作者转向学习预测实例何时对贪心算法困难，实现基于实例的算法选择。

Method: 设计了20维结构特征向量，训练轻量级MLP硬度分类器来预测贪心最优性差距。对于被识别为困难的实例（表现出"鲸鱼-小鱼"陷阱结构），部署异构GNN专家模型。最终构建混合分配器，结合硬度分类器、GNN和贪心求解器。

Result: 硬度分类器预测贪心最优性差距的平均绝对误差为0.033，Pearson相关系数为0.937，二元分类准确率达94.7%。对于困难实例，GNN专家模型在所有六种对抗配置上实现约0%的最优性差距（贪心算法为3.75-59.24%）。混合分配器在混合分布上实现0.51%的整体差距。在CATS基准测试中，GNN未能优于Gurobi（0.45-0.71 vs. 0.20差距）。

Conclusion: 学习何时部署昂贵求解器比学习替代它们更可行。算法选择框架比直接替代求解器更有效，通过预测实例硬度并相应选择算法，可以在保持效率的同时提升性能。

Abstract: The Winner Determination Problem (WDP) in combinatorial auctions is NP-hard, and no existing method reliably predicts which instances will defeat fast greedy heuristics. The ML-for-combinatorial-optimization community has focused on learning to \emph{replace} solvers, yet recent evidence shows that graph neural networks (GNNs) rarely outperform well-tuned classical methods on standard benchmarks. We pursue a different objective: learning to predict \emph{when} a given instance is hard for greedy allocation, enabling instance-dependent algorithm selection. We design a 20-dimensional structural feature vector and train a lightweight MLP hardness classifier that predicts the greedy optimality gap with mean absolute error 0.033, Pearson correlation 0.937, and binary classification accuracy 94.7\% across three random seeds. For instances identified as hard -- those exhibiting ``whale-fish'' trap structure where greedy provably fails -- we deploy a heterogeneous GNN specialist that achieves ${\approx}0\%$ optimality gap on all six adversarial configurations tested (vs.\ 3.75--59.24\% for greedy). A hybrid allocator combining the hardness classifier with GNN and greedy solvers achieves 0.51\% overall gap on mixed distributions. Our honest evaluation on CATS benchmarks confirms that GNNs do not outperform Gurobi (0.45--0.71 vs.\ 0.20 gap), motivating the algorithm selection framing. Learning \emph{when} to deploy expensive solvers is more tractable than learning to replace them.

</details>


### [130] [On the Stability of Nonlinear Dynamics in GD and SGD: Beyond Quadratic Potentials](https://arxiv.org/abs/2602.14789)
*Rotem Mulayoff,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 论文研究梯度下降优化算法中非线性项对动态稳定性的影响，发现线性分析可能误导，并推导了GD稳定振荡的精确判据，以及SGD中单批次不稳定可导致整体发散。


<details>
  <summary>Details</summary>
Motivation: 现有研究常依赖线性化分析优化算法的稳定性，但线性化动态是否能准确捕捉完整非线性行为尚不明确。最近研究表明GD可能在线性不稳定最小值附近稳定振荡，表明线性分析可能具有误导性。

Method: 显式研究非线性项的影响，推导多元设置中GD在最小值附近稳定振荡的精确判据，该条件依赖于高阶导数。将分析扩展到SGD，研究非线性动态在期望中的发散行为。

Result: 建立了GD稳定振荡的精确判据，该判据推广了现有结果。对于SGD，发现即使单个批次不稳定，非线性动态也可能在期望中发散，稳定性可能由单个不稳定振荡的批次决定，而非线性分析所建议的平均效应。

Conclusion: 非线性项在优化算法稳定性中起关键作用，线性分析可能误导。证明了如果所有批次都线性稳定，SGD的非线性动态在期望中是稳定的。这为理解优化算法收敛行为提供了更完整的理论框架。

Abstract: The dynamical stability of the iterates during training plays a key role in determining the minima obtained by optimization algorithms. For example, stable solutions of gradient descent (GD) correspond to flat minima, which have been associated with favorable features. While prior work often relies on linearization to determine stability, it remains unclear whether linearized dynamics faithfully capture the full nonlinear behavior. Recent work has shown that GD may stably oscillate near a linearly unstable minimum and still converge once the step size decays, indicating that linear analysis can be misleading. In this work, we explicitly study the effect of nonlinear terms. Specifically, we derive an exact criterion for stable oscillations of GD near minima in the multivariate setting. Our condition depends on high-order derivatives, generalizing existing results. Extending the analysis to stochastic gradient descent (SGD), we show that nonlinear dynamics can diverge in expectation even if a single batch is unstable. This implies that stability can be dictated by a single batch that oscillates unstably, rather than an average effect, as linear analysis suggests. Finally, we prove that if all batches are linearly stable, the nonlinear dynamics of SGD are stable in expectation.

</details>


### [131] [Extending Multi-Source Bayesian Optimization With Causality Principles](https://arxiv.org/abs/2602.14791)
*Luuk Jacobs,Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 该论文提出了多源因果贝叶斯优化（MSCBO）算法，将多源贝叶斯优化与因果贝叶斯优化相结合，用于处理具有因果信息和多信息源的优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统多源贝叶斯优化假设输入变量独立同分布，无法有效利用因果信息和干预能力，限制了在临床试验、政策制定等领域的应用。因果贝叶斯优化在单源领域已证明能更好建模变量依赖关系，但尚未扩展到多源场景。

Method: 提出多源因果贝叶斯优化（MSCBO）算法，将MSBO和CBO方法原则性地整合。利用因果原理进行维度约简，结合多信息源（仿真、代理模型、实验）的优势，降低高维问题的计算复杂度。

Result: 在合成和真实数据集上测试MSCBO，与基础算法对比显示：MSCBO具有更好的鲁棒性和适用性，能降低操作成本，提高收敛速度、性能和可扩展性。

Conclusion: 将MSBO与CBO的因果原理相结合，能够实现维度约简、降低操作成本，最终改善收敛速度、性能和可扩展性，为具有因果信息和多信息源的优化问题提供了有效解决方案。

Abstract: Multi-Source Bayesian Optimization (MSBO) serves as a variant of the traditional Bayesian Optimization (BO) framework applicable to situations involving optimization of an objective black-box function over multiple information sources such as simulations, surrogate models, or real-world experiments. However, traditional MSBO assumes the input variables of the objective function to be independent and identically distributed, limiting its effectiveness in scenarios where causal information is available and interventions can be performed, such as clinical trials or policy-making. In the single-source domain, Causal Bayesian Optimization (CBO) extends standard BO with the principles of causality, enabling better modeling of variable dependencies. This leads to more accurate optimization, improved decision-making, and more efficient use of low-cost information sources. In this article, we propose a principled integration of the MSBO and CBO methodologies in the multi-source domain, leveraging the strengths of both to enhance optimization efficiency and reduce computational complexity in higher-dimensional problems. We present the theoretical foundations of both Causal and Multi-Source Bayesian Optimization, and demonstrate how their synergy informs our Multi-Source Causal Bayesian Optimization (MSCBO) algorithm. We compare the performance of MSCBO against its foundational counterparts for both synthetic and real-world datasets with varying levels of noise, highlighting the robustness and applicability of MSCBO. Based on our findings, we conclude that integrating MSBO with the causality principles of CBO facilitates dimensionality reduction and lowers operational costs, ultimately improving convergence speed, performance, and scalability.

</details>


### [132] [Learning State-Tracking from Code Using Linear RNNs](https://arxiv.org/abs/2602.14814)
*Julien Siems,Riccardo Grazzi,Kirill Kalinin,Hitesh Ballani,Babak Rahmani*

Main category: cs.LG

TL;DR: 论文将状态跟踪任务（特别是置换组合）转换为代码形式的REPL跟踪，发现线性RNN在此设置下表现良好而Transformer失败，并进一步研究了在代码中跟踪状态困难的本质原因。


<details>
  <summary>Details</summary>
Motivation: 当前的状态跟踪任务（如置换组合）通常是序列到序列的映射任务，与语言模型常用的下一个token预测设置不兼容。作者希望填补这一空白，将状态跟踪任务转换为更适合语言模型训练的形式。

Method: 通过REPL跟踪将置换组合转换为代码形式，其中通过print语句揭示状态和变量转换。然后研究线性RNN和非线性RNN在跟踪概率有限状态自动机状态时的表现差异。

Result: 线性RNN在代码形式的状态跟踪任务中表现出色，而Transformer仍然失败。在动作不完全可观察的情况下，线性RNN在跟踪概率有限状态自动机状态时可能比非线性RNN表现更差。

Conclusion: 代码形式的状态跟踪任务揭示了不同架构的能力差异，线性RNN在完全可观察设置下表现良好，但在不完全可观察设置下可能不如非线性RNN，这为理解序列模型的局限性提供了新视角。

Abstract: Over the last years, state-tracking tasks, particularly permutation composition, have become a testbed to understand the limits of sequence models architectures like Transformers and RNNs (linear and non-linear). However, these are often sequence-to-sequence tasks: learning to map actions (permutations) to states, which is incompatible with the next-token prediction setting commonly used to train language models. We address this gap by converting permutation composition into code via REPL traces that interleave state-reveals through prints and variable transformations. We show that linear RNNs capable of state-tracking excel also in this setting, while Transformers still fail. Motivated by this representation, we investigate why tracking states in code is generally difficult: actions are not always fully observable. We frame this as tracking the state of a probabilistic finite-state automaton with deterministic state reveals and show that linear RNNs can be worse than non-linear RNNs at tracking states in this setup.

</details>


### [133] [Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment](https://arxiv.org/abs/2602.14844)
*Elias Malomgré,Pieter Simoens*

Main category: cs.LG

TL;DR: 提出Interactionless Inverse Reinforcement Learning和Alignment Flywheel，将AI对齐从与策略纠缠的临时方案转变为可检查、可编辑、可验证的工程资产


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐方法存在结构性缺陷，将安全目标与智能体策略纠缠在一起。RLHF和DPO等方法产生不透明、一次性使用的对齐产物（Alignment Waste），需要更可持续、可验证的解决方案

Method: 1. Interactionless Inverse Reinforcement Learning：将对齐产物学习与策略优化解耦，生成可检查、可编辑、模型无关的奖励模型。2. Alignment Flywheel：人机协同生命周期，通过自动化审计和精化迭代强化奖励模型

Result: 该方法将安全从一次性消耗转变为持久、可验证的工程资产，解决了Alignment Waste问题，提供更透明、可持续的对齐解决方案

Conclusion: 通过解耦对齐产物学习和策略优化，结合迭代强化机制，可以建立更可靠、可审计的AI对齐框架，为AI安全提供工程化解决方案

Abstract: AI alignment is growing in importance, yet current approaches suffer from a critical structural flaw that entangles the safety objectives with the agent's policy. Methods such as Reinforcement Learning from Human Feedback and Direct Preference Optimization create opaque, single-use alignment artifacts, which we term Alignment Waste. We propose Interactionless Inverse Reinforcement Learning to decouple alignment artifact learning from policy optimization, producing an inspectable, editable, and model-agnostic reward model. Additionally, we introduce the Alignment Flywheel, a human-in-the-loop lifecycle that iteratively hardens the reward model through automated audits and refinement. This architecture transforms safety from a disposable expense into a durable, verifiable engineering asset.

</details>


### [134] [Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows](https://arxiv.org/abs/2602.14849)
*Bardia Mohammadi,Nearchos Potamitis,Lars Klein,Akhil Arora,Laurent Bindschaedler*

Main category: cs.LG

TL;DR: Atomix为LLM智能体工具调用提供进度感知的事务语义，通过epoch标记、资源前沿跟踪和进度谓词控制提交，支持缓冲延迟和补偿回滚，提高任务成功率并增强隔离性。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在外部系统上执行操作时，工具调用效果是立即的。当发生故障、推测执行或资源争用时，失败的分支会产生意外的副作用且无法安全回滚，这需要一种事务机制来保证安全性和隔离性。

Method: Atomix运行时为智能体工具调用提供进度感知的事务语义：1）为每个调用标记epoch；2）跟踪每个资源的前沿状态；3）仅当进度谓词指示安全时才提交；4）可缓冲的效果延迟执行；5）外部化效果被跟踪并在中止时补偿。

Result: 在实际工作负载和故障注入测试中，事务重试提高了任务成功率，前沿门控提交在推测执行和资源争用场景下增强了隔离性。

Conclusion: Atomix通过进度感知的事务语义解决了LLM智能体工具调用中的副作用泄漏问题，提供了安全回滚机制，提高了系统可靠性和隔离性。

Abstract: LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are tracked and compensated on abort. Across real workloads with fault injection, transactional retry improves task success, while frontier-gated commit strengthens isolation under speculation and contention.

</details>


### [135] [A Pragmatic Method for Comparing Clusterings with Overlaps and Outliers](https://arxiv.org/abs/2602.14855)
*Ryan DeWolfe,Paweł Prałat,François Théberge*

Main category: cs.LG

TL;DR: 提出了一种用于比较包含重叠聚类和异常值的聚类结果的相似性度量方法


<details>
  <summary>Details</summary>
Motivation: 当前聚类算法评估方法无法处理包含异常值和重叠聚类的情况，需要开发一种通用的聚类比较方法

Method: 定义了一种实用的相似性度量方法，用于比较包含重叠和异常值的聚类结果，并证明其具有多个理想性质

Result: 该方法具有多个理想性质，实验证明它不受其他聚类比较度量常见偏差的影响

Conclusion: 提出的相似性度量方法能够有效比较包含重叠聚类和异常值的聚类结果，填补了当前聚类评估方法的空白

Abstract: Clustering algorithms are an essential part of the unsupervised data science ecosystem, and extrinsic evaluation of clustering algorithms requires a method for comparing the detected clustering to a ground truth clustering. In a general setting, the detected and ground truth clusterings may have outliers (objects belonging to no cluster), overlapping clusters (objects may belong to more than one cluster), or both, but methods for comparing these clusterings are currently undeveloped. In this note, we define a pragmatic similarity measure for comparing clusterings with overlaps and outliers, show that it has several desirable properties, and experimentally confirm that it is not subject to several common biases afflicting other clustering comparison measures.

</details>


### [136] [Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning](https://arxiv.org/abs/2602.14868)
*Ilia Mahrooghi,Aryo Lotfi,Emmanuel Abbe*

Main category: cs.LG

TL;DR: Goldilocks是一种教师驱动的数据采样策略，通过预测问题难度为模型选择"刚刚好"难度的训练数据，提升强化学习效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能解锁大语言模型的推理能力，但稀疏奖励导致样本效率低下。传统课程学习通过复杂度排序数据，但难以确定适合特定模型的最佳排序。

Method: 提出Goldilocks策略：教师模型预测每个问题对学生模型的难度，选择既不太简单也不太困难的问题（Goldilocks原则），同时使用GRPO训练学生模型。教师根据学生在已见样本上的表现持续适应其能力变化。

Result: 在OpenMathReasoning数据集上，Goldilocks数据采样在相同计算预算下，比标准GRPO训练提升了模型性能。

Conclusion: Goldilocks通过动态适应学生模型能力的智能数据采样策略，有效解决了强化学习中稀疏奖励导致的样本效率问题，提升了训练效果。

Abstract: Reinforcement learning has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, relying on sparse rewards makes this process highly sample-inefficient, as models must navigate vast search spaces with minimal feedback. While classic curriculum learning aims to mitigate this by ordering data based on complexity, the right ordering for a specific model is often unclear. To address this, we propose Goldilocks, a novel teacher-driven data sampling strategy that aims to predict each question's difficulty for the student model. The teacher model selects questions of appropriate difficulty for the student model, i.e., questions that are neither too easy nor too hard (Goldilocks principle), while training the student with GRPO. By leveraging the student's performance on seen samples, the teacher continuously adapts to the student's evolving abilities. On OpenMathReasoning dataset, Goldilocks data sampling improves the performance of models trained with standard GRPO under the same compute budget.

</details>


### [137] [On the Learning Dynamics of RLVR at the Edge of Competence](https://arxiv.org/abs/2602.14872)
*Yu Huang,Zixin Wen,Yuejie Chi,Yuting Wei,Aarti Singh,Yingbin Liang,Yuxin Chen*

Main category: cs.LG

TL;DR: RLVR通过平滑难度谱实现连续改进，避免学习停滞；理论解释了最终结果奖励如何克服长时程推理障碍


<details>
  <summary>Details</summary>
Motivation: 理解仅基于最终结果的奖励如何帮助克服长时程推理障碍，探索RLVR在组合推理任务中的训练动态机制

Method: 开发RL在Transformer上进行组合推理任务的训练动态理论，使用有限群上的傅里叶分析工具，通过合成实验验证预测机制

Result: 理论表明RLVR效果受难度谱平滑性调控：平滑难度谱产生接力效应，实现稳定连续改进；不连续难度谱导致grokking型相变和平台期

Conclusion: RLVR通过提升模型在能力边缘的性能来改进推理，适当设计的数据混合可以产生可扩展的增益，为RLVR训练策略提供理论指导

Abstract: Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theory of the training dynamics of RL for transformers on compositional reasoning tasks. Our theory characterizes how the effectiveness of RLVR is governed by the smoothness of the difficulty spectrum. When data contains abrupt discontinuities in difficulty, learning undergoes grokking-type phase transitions, producing prolonged plateaus before progress recurs. In contrast, a smooth difficulty spectrum leads to a relay effect: persistent gradient signals on easier problems elevate the model's capabilities to the point where harder ones become tractable, resulting in steady and continuous improvement. Our theory explains how RLVR can improve performance at the edge of competence, and suggests that appropriately designed data mixtures can yield scalable gains. As a technical contribution, our analysis develops and adapts tools from Fourier analysis on finite groups to our setting. We validate the predicted mechanisms empirically via synthetic experiments.

</details>


### [138] [Web-Scale Multimodal Summarization using CLIP-Based Semantic Alignment](https://arxiv.org/abs/2602.14889)
*Mounvik K,N Harshit*

Main category: cs.LG

TL;DR: 提出Web-Scale Multimodal Summarization框架，通过结合网络检索的文本和图像数据生成摘要，支持可配置参数和用户扩展


<details>
  <summary>Details</summary>
Motivation: 需要一种轻量级框架来处理网络规模的多模态数据摘要生成，结合文本和图像信息以提供更全面的内容总结

Method: 基于用户定义主题进行并行网络、新闻和图像搜索，使用微调CLIP模型对检索图像进行语义对齐排序，可选BLIP字幕生成增强多模态一致性

Result: 在500个图像-字幕对评估中，ROC-AUC达到0.9270，F1分数0.6504，准确率96.99%，显示强大的多模态对齐能力

Conclusion: 提供了一个可配置、可部署的网络规模摘要生成工具，将语言、检索和视觉模型集成到用户可扩展的管道中

Abstract: We introduce Web-Scale Multimodal Summarization, a lightweight framework for generating summaries by combining retrieved text and image data from web sources. Given a user-defined topic, the system performs parallel web, news, and image searches. Retrieved images are ranked using a fine-tuned CLIP model to measure semantic alignment with topic and text. Optional BLIP captioning enables image-only summaries for stronger multimodal coherence.The pipeline supports features such as adjustable fetch limits, semantic filtering, summary styling, and downloading structured outputs. We expose the system via a Gradio-based API with controllable parameters and preconfigured presets.Evaluation on 500 image-caption pairs with 20:1 contrastive negatives yields a ROC-AUC of 0.9270, an F1-score of 0.6504, and an accuracy of 96.99%, demonstrating strong multimodal alignment. This work provides a configurable, deployable tool for web-scale summarization that integrates language, retrieval, and vision models in a user-extensible pipeline.

</details>


### [139] [Algorithmic Simplification of Neural Networks with Mosaic-of-Motifs](https://arxiv.org/abs/2602.14896)
*Pedram Bakhtiarifard,Tong Chen,Jonathan Wenshøj,Erik B Dam,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 该论文从算法复杂度角度解释深度神经网络为何适合压缩，提出基于可重用模块的MoMos方法，在保持性能的同时降低模型算法复杂度。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在压缩后仍能保持良好性能，作者希望从算法复杂度角度解释这一现象。假设训练后的模型参数比随机初始化时具有更多结构和更低的算法复杂度，压缩方法正是利用了这种降低的复杂度。

Method: 提出MoMos方法：将参数划分为大小为s的块，每个块从k个可重用模块中选择，形成重用模式（马赛克）。这种约束参数化相比无约束模型具有更低的算法复杂度。

Result: 实验表明，通过近似Kolmogorov复杂度测量的神经网络算法复杂度在训练过程中可以降低。MoMos方法产生的模型与无约束模型性能相当，但算法复杂度更低。

Conclusion: 深度神经网络适合压缩的原因是训练后的参数具有更低的算法复杂度。MoMos方法通过约束参数化为可重用模块，有效降低了模型复杂度，为模型压缩提供了理论解释和新方法。

Abstract: Large-scale deep learning models are well-suited for compression. Methods like pruning, quantization, and knowledge distillation have been used to achieve massive reductions in the number of model parameters, with marginal performance drops across a variety of architectures and tasks. This raises the central question: \emph{Why are deep neural networks suited for compression?} In this work, we take up the perspective of algorithmic complexity to explain this behavior. We hypothesize that the parameters of trained models have more structure and, hence, exhibit lower algorithmic complexity compared to the weights at (random) initialization. Furthermore, that model compression methods harness this reduced algorithmic complexity to compress models. Although an unconstrained parameterization of model weights, $\mathbf{w} \in \mathbb{R}^n$, can represent arbitrary weight assignments, the solutions found during training exhibit repeatability and structure, making them algorithmically simpler than a generic program. To this end, we formalize the Kolmogorov complexity of $\mathbf{w}$ by $\mathcal{K}(\mathbf{w})$. We introduce a constrained parameterization $\widehat{\mathbf{w}}$, that partitions parameters into blocks of size $s$, and restricts each block to be selected from a set of $k$ reusable motifs, specified by a reuse pattern (or mosaic). The resulting method, $\textit{Mosaic-of-Motifs}$ (MoMos), yields algorithmically simpler model parameterization compared to unconstrained models. Empirical evidence from multiple experiments shows that the algorithmic complexity of neural networks, measured using approximations to Kolmogorov complexity, can be reduced during training. This results in models that perform comparably with unconstrained models while being algorithmically simpler.

</details>


### [140] [Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems](https://arxiv.org/abs/2602.14901)
*Pramit Saha,Joshua Strong,Mohammad Alsharid,Divyanshu Mishra,J. Alison Noble*

Main category: cs.LG

TL;DR: ToolSelect：一种通过学习选择最佳专家模型的方法，用于医疗代理系统中处理胸部X光任务，在包含多种任务模型的基准测试中优于10种现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医疗代理系统中，针对特定临床任务（如疾病诊断、定位、报告生成），通常存在多个专家模型，每个模型在不同数据样本上表现优异。然而，目前缺乏可靠的方法为给定查询从异构模型池中选择最合适的专家模型。

Method: 提出ToolSelect方法，通过最小化基于任务条件选择损失的一致代理的群体风险，自适应学习工具选择。具体采用基于注意力神经过程的选择器，以查询和每个模型的行为摘要为条件，从专家模型中进行选择。

Result: 构建了首个胸部X光代理环境ToolSelectBench，包含55个任务专业化模型（17个疾病检测、19个报告生成、6个视觉定位、13个VQA）和1448个查询的基准。ToolSelect在四个不同任务家族中一致优于10种最先进方法。

Conclusion: ToolSelect为医疗代理系统中的模型选择问题提供了有效解决方案，通过自适应学习从异构专家模型池中选择最合适的模型，显著提升了临床查询处理的性能。

Abstract: Task-specialized models form the backbone of agentic healthcare systems, enabling the agents to answer clinical queries across tasks such as disease diagnosis, localization, and report generation. Yet, for a given task, a single "best" model rarely exists. In practice, each task is better served by multiple competing specialist models where different models excel on different data samples. As a result, for any given query, agents must reliably select the right specialist model from a heterogeneous pool of tool candidates. To this end, we introduce ToolSelect, which adaptively learns model selection for tools by minimizing a population risk over sampled specialist tool candidates using a consistent surrogate of the task-conditional selection loss. Concretely, we propose an Attentive Neural Process-based selector conditioned on the query and per-model behavioral summaries to choose among the specialist models. Motivated by the absence of any established testbed, we, for the first time, introduce an agentic Chest X-ray environment equipped with a diverse suite of task-specialized models (17 disease detection, 19 report generation, 6 visual grounding, and 13 VQA) and develop ToolSelectBench, a benchmark of 1448 queries. Our results demonstrate that ToolSelect consistently outperforms 10 SOTA methods across four different task families.

</details>


### [141] [Coverage Guarantees for Pseudo-Calibrated Conformal Prediction under Distribution Shift](https://arxiv.org/abs/2602.14913)
*Farbod Siahkali,Ashwin Verma,Vijay Gupta*

Main category: cs.LG

TL;DR: 论文提出了一种在分布偏移下保持覆盖率的伪校准方法，通过引入松弛参数和源调谐算法来应对标签条件协变量偏移。


<details>
  <summary>Details</summary>
Motivation: 传统保形预测（CP）在数据分布偏移时可能失效，因为其基于数据可交换性假设。当数据分布发生变化时，CP的边际覆盖保证可能无法维持，需要新的方法来应对分布偏移。

Method: 1. 使用伪校准作为工具来应对分布偏移下的性能损失；2. 基于域适应工具推导目标覆盖的下界；3. 设计伪校准集，通过松弛参数膨胀保形阈值以保持目标覆盖率；4. 提出源调谐伪校准算法，根据分类器不确定性在硬伪标签和随机标签之间插值。

Result: 数值实验表明：1. 推导的边界能够定性跟踪伪校准行为；2. 源调谐方案能够减轻分布偏移下的覆盖退化；3. 同时保持非平凡的预测集大小。

Conclusion: 伪校准是应对分布偏移的有效工具，源调谐算法能够在保持覆盖率的同时维持合理的预测集大小，为保形预测在现实世界分布偏移场景中的应用提供了实用方法。

Abstract: Conformal prediction (CP) offers distribution-free marginal coverage guarantees under an exchangeability assumption, but these guarantees can fail if the data distribution shifts. We analyze the use of pseudo-calibration as a tool to counter this performance loss under a bounded label-conditional covariate shift model. Using tools from domain adaptation, we derive a lower bound on target coverage in terms of the source-domain loss of the classifier and a Wasserstein measure of the shift. Using this result, we provide a method to design pseudo-calibrated sets that inflate the conformal threshold by a slack parameter to keep target coverage above a prescribed level. Finally, we propose a source-tuned pseudo-calibration algorithm that interpolates between hard pseudo-labels and randomized labels as a function of classifier uncertainty. Numerical experiments show that our bounds qualitatively track pseudo-calibration behavior and that the source-tuned scheme mitigates coverage degradation under distribution shift while maintaining nontrivial prediction set sizes.

</details>


### [142] [Additive Control Variates Dominate Self-Normalisation in Off-Policy Evaluation](https://arxiv.org/abs/2602.14914)
*Olivier Jeunen,Shashank Gupta*

Main category: cs.LG

TL;DR: 本文证明带最优加性基线的β*-IPS估计器在均方误差上渐近优于SNIPS，为排序和推荐系统的离策略评估提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 离策略评估对排序推荐系统至关重要，SNIPS是方差缩减的标准工具但使用乘性控制变量。近期研究表明加性控制变量可能性能更优，但缺乏理论保证。

Method: 提出β*-IPS估计器，使用最优加性基线，通过理论分析证明其在均方误差上渐近优于SNIPS，并解析分解方差差距。

Result: 证明β*-IPS渐近主导SNIPS，SNIPS等价于使用特定但通常次优的加性基线，为从自归一化转向最优基线校正提供理论依据。

Conclusion: 理论证明支持在排序和推荐系统的离策略评估中，从自归一化转向最优加性基线校正，β*-IPS在渐近意义上优于SNIPS。

Abstract: Off-policy evaluation (OPE) is essential for assessing ranking and recommendation systems without costly online interventions. Self-Normalised Inverse Propensity Scoring (SNIPS) is a standard tool for variance reduction in OPE, leveraging a multiplicative control variate. Recent advances in off-policy learning suggest that additive control variates (baseline corrections) may offer superior performance, yet theoretical guarantees for evaluation are lacking. This paper provides a definitive answer: we prove that $β^\star$-IPS, an estimator with an optimal additive baseline, asymptotically dominates SNIPS in Mean Squared Error. By analytically decomposing the variance gap, we show that SNIPS is asymptotically equivalent to using a specific -- but generally sub-optimal -- additive baseline. Our results theoretically justify shifting from self-normalisation to optimal baseline corrections for both ranking and recommendation.

</details>


### [143] [BHyGNN+: Unsupervised Representation Learning for Heterophilic Hypergraphs](https://arxiv.org/abs/2602.14919)
*Tianyi Ma,Yiyue Qian,Zehong Wang,Zheyuan Zhang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: BHyGNN+是一个自监督学习框架，通过超图对偶性进行对比学习，无需标签数据即可在异质性和同质性超图上学习有效表示。


<details>
  <summary>Details</summary>
Motivation: 现有超图神经网络在处理异质性超图（超边内节点语义不同）时性能下降，且依赖标注数据，限制了在实际标注稀缺场景中的应用。

Method: 基于超图对偶性（节点和超边角色互换），通过对比原始超图与其对偶的增强视图的余弦相似度，以完全无监督方式捕获结构模式，无需负样本。

Result: 在11个基准数据集上的实验表明，BHyGNN+在异质性和同质性超图上均优于现有监督和自监督基线方法。

Conclusion: 利用超图对偶性进行自监督学习是有效的，为无标注超图表示学习建立了新范式。

Abstract: Hypergraph Neural Networks (HyGNNs) have demonstrated remarkable success in modeling higher-order relationships among entities. However, their performance often degrades on heterophilic hypergraphs, where nodes connected by the same hyperedge tend to have dissimilar semantic representations or belong to different classes. While several HyGNNs, including our prior work BHyGNN, have been proposed to address heterophily, their reliance on labeled data significantly limits their applicability in real-world scenarios where annotations are scarce or costly. To overcome this limitation, we introduce BHyGNN+, a self-supervised learning framework that extends BHyGNN for representation learning on heterophilic hypergraphs without requiring ground-truth labels. The core idea of BHyGNN+ is hypergraph duality, a structural transformation where the roles of nodes and hyperedges are interchanged. By contrasting augmented views of a hypergraph against its dual using cosine similarity, our framework captures essential structural patterns in a fully unsupervised manner. Notably, this duality-based formulation eliminates the need for negative samples, a common requirement in existing hypergraph contrastive learning methods that is often difficult to satisfy in practice. Extensive experiments on eleven benchmark datasets demonstrate that BHyGNN+ consistently outperforms state-of-the-art supervised and self-supervised baselines on both heterophilic and homophilic hypergraphs. Our results validate the effectiveness of leveraging hypergraph duality for self-supervised learning and establish a new paradigm for representation learning on challenging, unlabeled hypergraphs.

</details>


### [144] [Variance-Reduced $(\varepsilon,δ)-$Unlearning using Forget Set Gradients](https://arxiv.org/abs/2602.14938)
*Martin Van Waerebeke,Marco Lorenzi,Kevin Scaman,El Mahdi El Mhamdi,Giovanni Neglia*

Main category: cs.LG

TL;DR: 提出了首个在更新规则中直接包含遗忘集梯度的一阶算法VRU，在满足(ε,δ)-遗忘理论保证的同时，相比忽略遗忘集的现有方法获得严格改进的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 现有(ε,δ)-遗忘方法仅使用遗忘集来校准注入的噪声，而不将其作为直接优化信号；而高效的启发式方法虽利用遗忘样本但缺乏理论保证。需要弥合这一差距。

Method: 提出了方差减少遗忘(VRU)算法，这是首个在更新规则中直接包含遗忘集梯度的一阶算法，通过理论分析证明其满足(ε,δ)-遗忘保证。

Result: VRU在收敛性上优于现有忽略遗忘集的一阶(ε,δ)-遗忘方法，在低误差区域渐近优于任何忽略遗忘集的一阶方法。实验验证了理论，相比现有方法获得一致提升。

Conclusion: VRU成功弥合了理论保证方法与启发式方法之间的差距，通过直接利用遗忘集作为优化信号，在保持理论保证的同时获得更好的性能。

Abstract: In machine unlearning, $(\varepsilon,δ)-$unlearning is a popular framework that provides formal guarantees on the effectiveness of the removal of a subset of training data, the forget set, from a trained model. For strongly convex objectives, existing first-order methods achieve $(\varepsilon,δ)-$unlearning, but they only use the forget set to calibrate injected noise, never as a direct optimization signal. In contrast, efficient empirical heuristics often exploit the forget samples (e.g., via gradient ascent) but come with no formal unlearning guarantees. We bridge this gap by presenting the Variance-Reduced Unlearning (VRU) algorithm. To the best of our knowledge, VRU is the first first-order algorithm that directly includes forget set gradients in its update rule, while provably satisfying ($(\varepsilon,δ)-$unlearning. We establish the convergence of VRU and show that incorporating the forget set yields strictly improved rates, i.e. a better dependence on the achieved error compared to existing first-order $(\varepsilon,δ)-$unlearning methods. Moreover, we prove that, in a low-error regime, VRU asymptotically outperforms any first-order method that ignores the forget set.Experiments corroborate our theory, showing consistent gains over both state-of-the-art certified unlearning methods and over empirical baselines that explicitly leverage the forget set.

</details>


### [145] [Locally Adaptive Multi-Objective Learning](https://arxiv.org/abs/2602.14952)
*Jivat Neet Kaur,Isaac Gibbs,Michael I. Jordan*

Main category: cs.LG

TL;DR: 提出一种自适应多目标在线学习方法，通过将多目标学习中的部分组件替换为自适应在线算法，在分布漂移下实现局部自适应性和无偏预测


<details>
  <summary>Details</summary>
Motivation: 现有多目标在线学习方法在整个时间范围内以最坏情况最小化目标，无法适应分布漂移。虽然已有研究尝试通过引入针对连续子区间的局部保证来缓解此问题，但实证评估不足

Method: 提出一种替代方法，通过将多目标学习方法中的部分组件替换为自适应在线算法，实现局部自适应能力。该方法在能源预测和算法公平数据集上进行评估

Result: 在能源预测和算法公平数据集上的实证评估表明，所提方法优于现有方法，能在子组间实现无偏预测，同时在分布漂移下保持鲁棒性

Conclusion: 通过将自适应在线算法集成到多目标学习框架中，可以有效地实现局部自适应，在分布漂移环境下提高预测性能并保持公平性

Abstract: We consider the general problem of learning a predictor that satisfies multiple objectives of interest simultaneously, a broad framework that captures a range of specific learning goals including calibration, regret, and multiaccuracy. We work in an online setting where the data distribution can change arbitrarily over time. Existing approaches to this problem aim to minimize the set of objectives over the entire time horizon in a worst-case sense, and in practice they do not necessarily adapt to distribution shifts. Earlier work has aimed to alleviate this problem by incorporating additional objectives that target local guarantees over contiguous subintervals. Empirical evaluation of these proposals is, however, scarce. In this article, we consider an alternative procedure that achieves local adaptivity by replacing one part of the multi-objective learning method with an adaptive online algorithm. Empirical evaluations on datasets from energy forecasting and algorithmic fairness show that our proposed method improves upon existing approaches and achieves unbiased predictions over subgroups, while remaining robust under distribution shift.

</details>


### [146] [Use What You Know: Causal Foundation Models with Partial Graphs](https://arxiv.org/abs/2602.14972)
*Arik Reuter,Anish Dhir,Cristiana Diaconu,Jake Robertson,Ole Ossen,Frank Hutter,Adrian Weller,Mark van der Wilk,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 该论文提出了一种在因果基础模型（CFMs）中融入因果信息（如因果图或祖先信息）的方法，通过向注意力机制注入可学习的偏置，使通用CFM能够匹配针对特定因果结构训练的专业模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统因果估计需要针对特定假设定制专门的估计器，而现有的因果基础模型虽然统一了因果发现和推断，但无法融入领域知识，导致预测效果不佳。需要解决如何在CFMs中有效利用因果信息的问题。

Method: 提出在CFMs中融入因果信息的方法，包括完整的因果图信息和部分因果信息。系统评估了多种条件化策略，发现向注意力机制注入可学习的偏置是最有效的方法，能够充分利用完整和部分因果信息。

Result: 实验表明，通过这种条件化方法，通用因果基础模型能够匹配针对特定因果结构训练的专业模型的性能。该方法有效利用了不同程度的领域专业知识，提升了模型在因果查询中的表现。

Conclusion: 该方法解决了通向一体化因果基础模型的关键障碍：在数据驱动回答因果查询的同时，有效利用任何程度的领域专业知识。为构建更强大的因果基础模型提供了重要技术路径。

Abstract: Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.

</details>


### [147] [MacroGuide: Topological Guidance for Macrocycle Generation](https://arxiv.org/abs/2602.14977)
*Alicja Maksymiuk,Alexandre Duplessis,Michael Bronstein,Alexander Tong,Fernanda Duarte,İsmail İlkan Ceylan*

Main category: cs.LG

TL;DR: MacroGuide是一种使用持续同调指导扩散模型生成大环分子的新方法，将大环生成率从1%提升到99%


<details>
  <summary>Details</summary>
Motivation: 大环分子因其对困难靶点具有增强的选择性和结合亲和力而成为有前景的药物替代品，但由于公共数据集中稀缺且标准深度生成模型难以强制执行拓扑约束，在生成建模中仍未得到充分探索

Method: MacroGuide：一种扩散指导机制，使用持续同调引导预训练分子生成模型的采样过程，在每一步去噪步骤中，从原子位置构建Vietoris-Rips复形，并通过优化持续同调特征促进环形成

Result: 将MacroGuide应用于预训练扩散模型后，大环生成率从1%提高到99%，同时在化学有效性、多样性和PoseBusters检查等关键质量指标上达到或超过最先进性能

Conclusion: MacroGuide通过拓扑指导成功解决了大环分子生成中的挑战，为药物发现提供了有效的生成工具

Abstract: Macrocycles are ring-shaped molecules that offer a promising alternative to small-molecule drugs due to their enhanced selectivity and binding affinity against difficult targets. Despite their chemical value, they remain underexplored in generative modeling, likely owing to their scarcity in public datasets and the challenges of enforcing topological constraints in standard deep generative models. We introduce MacroGuide: Topological Guidance for Macrocycle Generation, a diffusion guidance mechanism that uses Persistent Homology to steer the sampling of pretrained molecular generative models toward the generation of macrocycles, in both unconditional and conditional (protein pocket) settings. At each denoising step, MacroGuide constructs a Vietoris-Rips complex from atomic positions and promotes ring formation by optimizing persistent homology features. Empirically, applying MacroGuide to pretrained diffusion models increases macrocycle generation rates from 1% to 99%, while matching or exceeding state-of-the-art performance on key quality metrics such as chemical validity, diversity, and PoseBusters checks.

</details>


### [148] [Orthogonalized Multimodal Contrastive Learning with Asymmetric Masking for Structured Representations](https://arxiv.org/abs/2602.14983)
*Carolin Cissee,Raneen Younis,Zahra Ahmadi*

Main category: cs.LG

TL;DR: COrAL是一个多模态学习框架，通过正交约束和不对称掩码技术，显式地同时保留冗余、独特和协同信息，实现更稳定、可靠和全面的多模态表示。


<details>
  <summary>Details</summary>
Motivation: 现有自监督多模态对比学习方法主要捕获冗余的跨模态信号，往往忽视模态特定（独特）信息和交互驱动（协同）信息。现有扩展方法要么未能显式建模协同交互，要么以纠缠方式学习不同信息组件，导致表示不完整和潜在信息泄漏。

Method: COrAL采用双路径架构，通过正交约束解耦共享和模态特定特征，确保信息组件的清晰分离。为促进协同建模，引入具有互补视图特定模式的不对称掩码，迫使模型推断跨模态依赖关系而非仅依赖冗余线索。

Result: 在合成基准和多样化的MultiBench数据集上的广泛实验表明，COrAL始终匹配或优于最先进方法，同时在多次运行中表现出低性能方差。

Conclusion: 显式建模多模态信息的完整频谱能产生更稳定、可靠和全面的嵌入，COrAL框架通过解耦冗余、独特和协同信息实现了这一目标。

Abstract: Multimodal learning seeks to integrate information from heterogeneous sources, where signals may be shared across modalities, specific to individual modalities, or emerge only through their interaction. While self-supervised multimodal contrastive learning has achieved remarkable progress, most existing methods predominantly capture redundant cross-modal signals, often neglecting modality-specific (unique) and interaction-driven (synergistic) information. Recent extensions broaden this perspective, yet they either fail to explicitly model synergistic interactions or learn different information components in an entangled manner, leading to incomplete representations and potential information leakage. We introduce \textbf{COrAL}, a principled framework that explicitly and simultaneously preserves redundant, unique, and synergistic information within multimodal representations. COrAL employs a dual-path architecture with orthogonality constraints to disentangle shared and modality-specific features, ensuring a clean separation of information components. To promote synergy modeling, we introduce asymmetric masking with complementary view-specific patterns, compelling the model to infer cross-modal dependencies rather than rely solely on redundant cues. Extensive experiments on synthetic benchmarks and diverse MultiBench datasets demonstrate that COrAL consistently matches or outperforms state-of-the-art methods while exhibiting low performance variance across runs. These results indicate that explicitly modeling the full spectrum of multimodal information yields more stable, reliable, and comprehensive embeddings.

</details>


### [149] [Spectral Convolution on Orbifolds for Geometric Deep Learning](https://arxiv.org/abs/2602.14997)
*Tim Mangliers,Bernhard Mössner,Benjamin Himpel*

Main category: cs.LG

TL;DR: 该论文将几何深度学习扩展到轨道流形，引入轨道流形上的谱卷积，为处理轨道流形结构数据提供基础构建模块，并以音乐理论为例进行说明。


<details>
  <summary>Details</summary>
Motivation: 几何深度学习主要处理图或流形等非欧几里得结构数据，但实际应用中存在更多拓扑和几何结构（如轨道流形）需要被机器学习方法处理，目前缺乏针对轨道流形结构数据的有效学习框架。

Method: 引入轨道流形上的谱卷积概念，将其作为几何深度学习的基础构建模块，使轨道流形结构数据能够通过类似卷积神经网络的架构进行处理。

Result: 提出了轨道流形上的谱卷积理论框架，为处理轨道流形结构数据提供了数学基础，并通过音乐理论的实例展示了该理论的实际应用。

Conclusion: 轨道流形上的谱卷积扩展了几何深度学习的应用范围，使机器学习能够处理更广泛的拓扑和几何结构数据，为相关领域提供了新的理论工具。

Abstract: Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with which these use cases can be made accessible to machine learning. There are various techniques, such as spectral convolution, that form the basic building blocks for some convolutional neural network-like architectures on non-Euclidean data. In this paper, the concept of spectral convolution on orbifolds is introduced. This provides a building block for making learning on orbifold structured data accessible using GDL. The theory discussed is illustrated using an example from music theory.

</details>


### [150] [Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001)
*Xander Davies,Giorgi Giglemiani,Edmund Lau,Eric Winsor,Geoffrey Irving,Yarin Gal*

Main category: cs.LG

TL;DR: BPJ是一种新型自动化越狱攻击方法，仅使用单比特分类器标志信息，成功绕过最强行业部署的安全防护系统。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击依赖白盒/灰盒假设或已有越狱库，而最强行业防护系统已能抵御数千小时人工红队测试，需要开发完全黑盒的自动化攻击方法来评估真实世界防御系统的鲁棒性。

Method: 将目标有害字符串转化为中间攻击目标的课程，主动选择最能检测攻击强度微小变化的评估点（边界点），仅使用分类器是否标记交互的单比特信息进行优化。

Result: BPJ是首个成功开发针对Constitutional Classifiers通用越狱的完全自动化攻击算法，也是首个在不依赖人工攻击种子情况下成功攻击GPT-5输入分类器的自动化算法。

Conclusion: BPJ难以在单个交互中防御，但在优化过程中会产生大量标记，表明有效防御需要补充单交互方法为批量级监控。

Abstract: Frontier LLMs are safeguarded against attempts to extract harmful information via adversarial prompts known as "jailbreaks". Recently, defenders have developed classifier-based systems that have survived thousands of hours of human red teaming. We introduce Boundary Point Jailbreaking (BPJ), a new class of automated jailbreak attacks that evade the strongest industry-deployed safeguards. Unlike previous attacks that rely on white/grey-box assumptions (such as classifier scores or gradients) or libraries of existing jailbreaks, BPJ is fully black-box and uses only a single bit of information per query: whether or not the classifier flags the interaction. To achieve this, BPJ addresses the core difficulty in optimising attacks against robust real-world defences: evaluating whether a proposed modification to an attack is an improvement. Instead of directly trying to learn an attack for a target harmful string, BPJ converts the string into a curriculum of intermediate attack targets and then actively selects evaluation points that best detect small changes in attack strength ("boundary points"). We believe BPJ is the first fully automated attack algorithm that succeeds in developing universal jailbreaks against Constitutional Classifiers, as well as the first automated attack algorithm that succeeds against GPT-5's input classifier without relying on human attack seeds. BPJ is difficult to defend against in individual interactions but incurs many flags during optimisation, suggesting that effective defence requires supplementing single-interaction methods with batch-level monitoring.

</details>


### [151] [PDE foundation models are skillful AI weather emulators for the Martian atmosphere](https://arxiv.org/abs/2602.15004)
*Johannes Schmude,Sujit Roy,Liping Wang,Theodore van Kessel,Levente Klein,Marcus Freitag,Eloisa Bentivegna,Robert Manson-Sawko,Bjorn Lutjens,Manil Maskey,Campbell Watson,Rahul Ramachandran,Juan Bernabe-Moreno*

Main category: cs.LG

TL;DR: 该研究展示了预训练在偏微分方程数值解上的AI基础模型可以微调为火星大气预测模拟器，通过将二维Poseidon模型扩展到三维并利用稀疏初始条件，在有限计算资源下实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索偏微分方程基础模型（PDEs-FMs）是否不仅能近似其他偏微分方程的解，还能作为解决现实世界复杂问题的锚定模型，特别是在训练数据不足或计算预算有限的情况下。火星大气预测就是一个典型例子，需要处理复杂相互作用且数据有限。

Method: 方法包括：1）使用预训练在偏微分方程数值解上的Poseidon二维基础模型；2）开发将模型从二维扩展到三维的技术，同时保留预训练信息；3）研究模型在稀疏初始条件下的性能；4）使用约34GB的火星大气数据（四个火星年）进行训练；5）在中等计算预算（13GPU小时）下进行实验。

Result: 结果显示：1）预训练与模型扩展相结合使模型在保留测试年上的性能提升了34.4%；2）证明了偏微分方程基础模型不仅能近似其他偏微分方程的解，还能作为现实世界复杂问题的有效解决方案，特别是在数据有限或计算资源受限的情况下。

Conclusion: 结论是偏微分方程基础模型（PDEs-FMs）具有双重能力：既能近似其他偏微分方程的解，又能作为解决现实世界复杂问题的锚定模型。这项研究为在训练数据不足或计算预算有限的情况下开发高效预测模型提供了新途径，特别是在行星科学和地球系统建模等领域。

Abstract: We show that AI foundation models that are pretrained on numerical solutions to a diverse corpus of partial differential equations can be adapted and fine-tuned to obtain skillful predictive weather emulators for the Martian atmosphere. We base our work on the Poseidon PDE foundation model for two-dimensional systems. We develop a method to extend Poseidon from two to three dimensions while keeping the pretraining information. Moreover, we investigate the performance of the model in the presence of sparse initial conditions. Our results make use of four Martian years (approx.~34 GB) of training data and a median compute budget of 13 GPU hours. We find that the combination of pretraining and model extension yields a performance increase of 34.4\% on a held-out year. This shows that PDEs-FMs can not only approximate solutions to (other) PDEs but also anchor models for real-world problems with complex interactions that lack a sufficient amount of training data or a suitable compute budget.

</details>


### [152] [Efficient Sampling with Discrete Diffusion Models: Sharp and Adaptive Guarantees](https://arxiv.org/abs/2602.15008)
*Daniil Dmitriev,Zhihan Huang,Yuting Wei*

Main category: cs.LG

TL;DR: 本文为离散扩散模型建立了理论收敛保证，针对均匀和掩码两种噪声过程，提出了τ-leaping采样器，在KL散度上达到ε精度，并证明了算法下界。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在经验上取得了显著成功，但理论基础尚不完整。本文旨在研究基于连续时间马尔可夫链（CTMC）的离散扩散模型的采样效率，重点关注τ-leaping采样器。

Method: 采用连续时间马尔可夫链（CTMC）框架，研究τ-leaping采样器。针对均匀离散扩散，分析标准τ-leaping算法；针对掩码离散扩散，引入改进的τ-leaping采样器，其收敛速率由有效总相关这一信息论量控制。

Result: 对于均匀离散扩散，τ-leaping算法达到迭代复杂度Õ(d/ε)，消除了对词汇大小S的线性依赖，比现有界改进了d倍，并建立了匹配的算法下界。对于掩码离散扩散，改进采样器的收敛速率由有效总相关控制，该量有界于d log S，但对结构化数据可以是次线性甚至常数。

Conclusion: 本文为离散扩散模型建立了严格的收敛理论，证明了τ-leaping采样器的高效性，特别是掩码扩散采样器能够自适应低维结构，无需先验知识或算法修改，为实际应用提供了理论保证。

Abstract: Diffusion models over discrete spaces have recently shown striking empirical success, yet their theoretical foundations remain incomplete. In this paper, we study the sampling efficiency of score-based discrete diffusion models under a continuous-time Markov chain (CTMC) formulation, with a focus on $τ$-leaping-based samplers. We establish sharp convergence guarantees for attaining $\varepsilon$ accuracy in Kullback-Leibler (KL) divergence for both uniform and masking noising processes. For uniform discrete diffusion, we show that the $τ$-leaping algorithm achieves an iteration complexity of order $\tilde O(d/\varepsilon)$, with $d$ the ambient dimension of the target distribution, eliminating linear dependence on the vocabulary size $S$ and improving existing bounds by a factor of $d$; moreover, we establish a matching algorithmic lower bound showing that linear dependence on the ambient dimension is unavoidable in general. For masking discrete diffusion, we introduce a modified $τ$-leaping sampler whose convergence rate is governed by an intrinsic information-theoretic quantity, termed the effective total correlation, which is bounded by $d \log S$ but can be sublinear or even constant for structured data. As a consequence, the sampler provably adapts to low-dimensional structure without prior knowledge or algorithmic modification, yielding sublinear convergence rates for various practical examples (such as hidden Markov models, image data, and random graphs). Our analysis requires no boundedness or smoothness assumptions on the score estimator beyond control of the score entropy loss.

</details>


### [153] [Scaling Beyond Masked Diffusion Language Models](https://arxiv.org/abs/2602.15014)
*Subham Sekhar Sahoo,Jean-Marie Lemercier,Zhihan Yang,Justin Deschenaux,Jingyu Liu,John Thickstun,Ante Jukic*

Main category: cs.LG

TL;DR: 该研究挑战了Masked diffusion在扩散语言模型中的主导地位，发现uniform-state扩散方法在推理速度和质量权衡上更有优势，尽管在困惑度指标上表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前Masked diffusion在离散扩散方法中占据主导地位，主要基于其在语言建模基准上的强困惑度表现。但研究者质疑困惑度是否足以进行跨算法比较，并探索其他扩散方法在推理速度和实际应用中的优势。

Method: 1) 首次对uniform-state和interpolating离散扩散方法进行缩放定律研究；2) 发现Masked diffusion模型可以通过简单的交叉熵目标训练提高约12%的FLOPs效率；3) 将所有方法扩展到17亿参数规模进行比较。

Result: 1) 困惑度在扩散家族内部具有信息性，但在跨家族比较中可能产生误导；2) uniform-state扩散在基于似然的基准上保持竞争力，并在GSM8K上优于自回归和Masked diffusion模型，尽管验证困惑度更差；3) 推理速度和质量权衡的Pareto前沿显示，某些模型虽然似然缩放较差，但由于采样更快更实用而更可取。

Conclusion: Masked diffusion并非扩散语言建模的绝对未来，困惑度指标不足以进行跨算法比较。uniform-state扩散方法在实际应用中具有优势，特别是在推理速度和任务性能的权衡上，挑战了当前基于困惑度的评估范式。

Abstract: Diffusion language models are a promising alternative to autoregressive models due to their potential for faster generation. Among discrete diffusion approaches, Masked diffusion currently dominates, largely driven by strong perplexity on language modeling benchmarks. In this work, we present the first scaling law study of uniform-state and interpolating discrete diffusion methods. We also show that Masked diffusion models can be made approximately 12% more FLOPs-efficient when trained with a simple cross-entropy objective. We find that perplexity is informative within a diffusion family but can be misleading across families, where models with worse likelihood scaling may be preferable due to faster and more practical sampling, as reflected by the speed-quality Pareto frontier. These results challenge the view that Masked diffusion is categorically the future of diffusion language modeling and that perplexity alone suffices for cross-algorithm comparison. Scaling all methods to 1.7B parameters, we show that uniform-state diffusion remains competitive on likelihood-based benchmarks and outperforms autoregressive and Masked diffusion models on GSM8K, despite worse validation perplexity. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/scaling-dllms

</details>


### [154] [Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation](https://arxiv.org/abs/2602.15022)
*Cai Zhou,Zijie Chen,Zian Li,Jike Wang,Kaiyi Jiang,Pan Li,Rose Yu,Muhan Zhang,Stephen Bates,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 该论文提出了一种新的"规范化"视角来生成具有群对称性不变性的分布，通过将样本映射到轨道代表元，在规范切片上训练无约束扩散模型，再通过随机对称变换恢复不变分布，显著提升了3D分子生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过架构约束（如等变去噪器和不变先验）来强制对称不变性，但本文挑战这一传统，提出更优的规范化视角，旨在提高表达能力和训练效率。

Method: 基于商空间理论，提出规范化扩散框架：1) 将每个样本映射到轨道代表元（规范姿态或顺序）；2) 在规范切片上训练无约束扩散或流模型；3) 生成时通过随机对称变换恢复不变分布。针对分子图生成，利用几何谱基规范化和温和位置编码。

Result: 规范化扩散在3D分子生成任务中显著优于等变基线，计算量相似或更少。在GEOM-DRUG数据集上，CanonFlow架构实现了最先进的性能，在少步生成中优势尤为明显。

Conclusion: 规范化生成模型在理论上正确、通用且表达力更强，能加速训练并减少条件方差。对齐先验和最优传输与规范化互补，进一步提升训练效率，为对称不变分布生成提供了新范式。

Abstract: Many generative tasks in chemistry and science involve distributions invariant to group symmetries (e.g., permutation and rotation). A common strategy enforces invariance and equivariance through architectural constraints such as equivariant denoisers and invariant priors. In this paper, we challenge this tradition through the alternative canonicalization perspective: first map each sample to an orbit representative with a canonical pose or order, train an unconstrained (non-equivariant) diffusion or flow model on the canonical slice, and finally recover the invariant distribution by sampling a random symmetry transform at generation time. Building on a formal quotient-space perspective, our work provides a comprehensive theory of canonical diffusion by proving: (i) the correctness, universality and superior expressivity of canonical generative models over invariant targets; (ii) canonicalization accelerates training by removing diffusion score complexity induced by group mixtures and reducing conditional variance in flow matching. We then show that aligned priors and optimal transport act complementarily with canonicalization and further improves training efficiency. We instantiate the framework for molecular graph generation under $S_n \times SE(3)$ symmetries. By leveraging geometric spectra-based canonicalization and mild positional encodings, canonical diffusion significantly outperforms equivariant baselines in 3D molecule generation tasks, with similar or even less computation. Moreover, with a novel architecture Canon, CanonFlow achieves state-of-the-art performance on the challenging GEOM-DRUG dataset, and the advantage remains large in few-step generation.

</details>


### [155] [Long Context, Less Focus: A Scaling Gap in LLMs Revealed through Privacy and Personalization](https://arxiv.org/abs/2602.15028)
*Shangding Gu*

Main category: cs.LG

TL;DR: 本文提出PAPerBench基准，系统研究上下文长度对LLM个性化质量和隐私保护的影响，发现随着上下文增长，个性化和隐私性能均下降，揭示了注意力稀释现象。


<details>
  <summary>Details</summary>
Motivation: LLM在隐私敏感和个性化场景中广泛应用，但上下文长度如何影响隐私泄露和个性化效果尚不明确，需要系统研究长上下文模型的行为。

Method: 构建PAPerBench大规模基准，包含约29,000个实例，上下文长度从1K到256K tokens，总计377K评估问题，联合评估个性化性能和隐私风险，并进行注意力稀释的理论分析。

Result: 实验表明，随着上下文长度增加，个性化和隐私保护性能均出现一致下降；理论分析揭示了固定容量Transformer中软注意力的注意力稀释现象，解释了这一行为。

Conclusion: 当前模型存在普遍的扩展差距：长上下文导致注意力分散。基准的发布支持可复现评估和未来可扩展隐私与个性化研究。

Abstract: Large language models (LLMs) are increasingly deployed in privacy-critical and personalization-oriented scenarios, yet the role of context length in shaping privacy leakage and personalization effectiveness remains largely unexplored. We introduce a large-scale benchmark, PAPerBench, to systematically study how increasing context length influences both personalization quality and privacy protection in LLMs. The benchmark comprises approximately 29,000 instances with context lengths ranging from 1K to 256K tokens, yielding a total of 377K evaluation questions. It jointly evaluates personalization performance and privacy risks across diverse scenarios, enabling controlled analysis of long-context model behavior. Extensive evaluations across state-of-the-art LLMs reveal consistent performance degradation in both personalization and privacy as context length increases. We further provide a theoretical analysis of attention dilution under context scaling, explaining this behavior as an inherent limitation of soft attention in fixed-capacity Transformers. The empirical and theoretical findings together suggest a general scaling gap in current models -- long context, less focus. We release the benchmark to support reproducible evaluation and future research on scalable privacy and personalization. Code and data are available at https://github.com/SafeRL-Lab/PAPerBench

</details>


### [156] [Symmetry in language statistics shapes the geometry of model representations](https://arxiv.org/abs/2602.15029)
*Dhruva Karkada,Daniel J. Korchinski,Andres Nava,Matthieu Wyart,Yasaman Bahri*

Main category: cs.LG

TL;DR: 论文揭示了语言统计中的平移对称性如何导致LLM表示中出现简单几何结构，并证明了这种结构在统计扰动下具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管神经网络的表示学习取得了成功，但其基本性质仍不清楚。一个引人注目的现象是LLM表示中出现了简单的几何结构（如月份形成圆形、年份形成一维流形），需要解释这些结构为何出现及其鲁棒性。

Method: 首先识别语言统计中的平移对称性（如两个月份共现概率仅取决于时间间隔），然后从理论上证明这种对称性导致高维词嵌入模型中的几何结构。通过扰动共现统计（如删除包含两个月份的句子）和中等嵌入维度实验验证鲁棒性，提出这些结构由潜在连续变量集体控制的理论框架。

Result: 理论分析表明平移对称性确实控制着词嵌入中的几何结构。实验验证显示这些结构在统计扰动下具有鲁棒性，即使在中等嵌入维度下也持续存在。在词嵌入模型、文本嵌入模型和大语言模型中都得到了实证验证。

Conclusion: 语言统计的平移对称性是LLM表示中出现简单几何结构的关键驱动因素，这些结构在统计扰动下具有鲁棒性，且可由潜在连续变量集体控制。这为理解神经网络表示的基本性质提供了理论框架。

Abstract: Although learned representations underlie neural networks' success, their fundamental properties remain poorly understood. A striking example is the emergence of simple geometric structures in LLM representations: for example, calendar months organize into a circle, years form a smooth one-dimensional manifold, and cities' latitudes and longitudes can be decoded by a linear probe. We show that the statistics of language exhibit a translation symmetry -- e.g., the co-occurrence probability of two months depends only on the time interval between them -- and we prove that the latter governs the aforementioned geometric structures in high-dimensional word embedding models. Moreover, we find that these structures persist even when the co-occurrence statistics are strongly perturbed (for example, by removing all sentences in which two months appear together) and at moderate embedding dimension. We show that this robustness naturally emerges if the co-occurrence statistics are collectively controlled by an underlying continuous latent variable. We empirically validate this theoretical framework in word embedding models, text embedding models, and large language models.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [157] [Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation](https://arxiv.org/abs/2602.13438)
*Sean D. Lam,Roberto dos Reis*

Main category: quant-ph

TL;DR: 量子算法框架用于模拟相位衬度透射电镜图像形成，通过量子电路实现电子波场传播和样品相互作用，在傅里叶空间查询等特定任务中具有量子优势。


<details>
  <summary>Details</summary>
Motivation: 开发一个基于量子电路的物理基础框架，将经典透射电镜图像形成理论映射到量子计算中，探索在特定计算任务中实现量子优势的可能性。

Method: 使用故障容忍的门基量子电路模型，将电子波场振幅编码到量子寄存器中，通过二维量子傅里叶变换和相位算子实现自由空间传播和透镜像差，在弱相位物体近似下模拟样品相互作用。

Result: 验证了MoS2的投影势、衬度传递函数行为和图像衬度趋势与经典多层切片模拟一致，提供了资源估计和关键假设。虽然完整图像重建需要大量测量，但在傅里叶空间查询、全局图像统计和相位相干可观测量等任务中可实现量子优势。

Conclusion: 该框架为透射电镜理论到量子电路的物理基础映射建立了基准，为扩展到完整多层切片和非弹性散射模型奠定了基础，在特定计算任务中展示了量子计算的优势。

Abstract: We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\times N$ grid is amplitude-encoded into a $2\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\times N$ intensity images requires $O(N^2/ε^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models.

</details>


### [158] [Entanglement in quantum spin chains is strictly finite at any temperature](https://arxiv.org/abs/2602.13386)
*Ainesh Bakshi,Soonwon Choi,Saúl Pilatowsky-Cameo*

Main category: quant-ph

TL;DR: 证明了量子自旋链的吉布斯态可以在任意有限温度下精确分解为矩阵乘积态的混合，且键维数与系统尺寸无关


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子物理的核心特征，但在热平衡下相互作用多体系统中的纠缠表征仍然是量子统计物理中最重要挑战之一

Method: 提出并证明了一种将量子自旋链吉布斯态精确分解为矩阵乘积态混合的方法，键维数与系统尺寸无关，并提供了高效的经典采样算法

Result: 证明了热态中施密特数（最严格的二分纠缠度量）在热力学极限下仍然是严格有限的，提供了明确的分解和高效采样算法

Conclusion: 该工作解决了热平衡多体系统纠缠表征的重要问题，为热态纠缠研究提供了新的理论框架和计算工具

Abstract: Entanglement is the hallmark of quantum physics, yet its characterization in interacting many-body systems at thermal equilibrium remains one of the most important challenges in quantum statistical physics. We prove that the Gibbs state of any quantum spin chain can be exactly decomposed into a mixture of matrix product states with a bond dimension that is independent of the system size, at any finite temperature. As a consequence, the Schmidt number, arguably the most stringent measure of bipartite entanglement, is strictly finite for thermal states, even in the thermodynamic limit. Our decomposition is explicit and is accompanied by an efficient classical algorithm to sample the resulting matrix product states.

</details>


### [159] [Boundary conditions for the Schrödinger equation in the numerical simulation of quantum systems](https://arxiv.org/abs/2602.14654)
*Marco Patriarca*

Main category: quant-ph

TL;DR: 该论文研究量子系统数值模拟中的边界条件问题，指出封闭系统可用局域边界条件，而开放系统因不确定性原理无法定义局域边界条件，提出了一种新方法来解决有限数值格点上模拟无限扩展波的问题。


<details>
  <summary>Details</summary>
Motivation: 量子系统数值模拟中，边界条件处理是一个关键问题。传统方法在有限数值格点上模拟无限扩展的平面波或波包时会遇到困难，特别是对于开放量子系统，由于不确定性原理，无法定义局域边界条件，这限制了数值模拟的准确性。

Method: 提出了一种新方法，使用小型数值格点来模拟开放量子系统。该方法避免了传统边界条件的局限性，保持了与物理图像的对应关系，能够处理入射波和散射波可能无限扩展的情况。

Result: 研究表明：1）封闭量子系统可以通过局域边界条件定义；2）开放量子系统由于不确定性原理无法定义局域边界条件；3）提出的新方法能够有效解决有限格点上模拟无限扩展波的问题。

Conclusion: 对于开放量子系统的数值模拟，传统局域边界条件方法存在根本性限制。提出的新方法为在有限数值格点上准确模拟开放量子系统提供了可行方案，解决了波函数无限扩展与有限计算域之间的矛盾。

Abstract: We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schrödinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended.

</details>


### [160] [No-Go Theorem on Fault Tolerant Gadgets for Multiple Logical Qubits](https://arxiv.org/abs/2602.13395)
*Aranya Chakraborty,Daniel Gottesman*

Main category: quant-ph

TL;DR: 证明了稳定子码无法通过横向或折叠横向结构在多逻辑量子比特上完全实现Clifford群，这对容错量子计算架构有重要限制。


<details>
  <summary>Details</summary>
Motivation: 寻找能够容错实现完整逻辑Clifford群的稳定子码，以推进容错量子计算的发展。目前单逻辑量子比特码（如Steane码）已有横向实现，但多逻辑量子比特码尚无类似方案。

Method: 研究了几类容错结构：横向门、码自同构和折叠横向结构。通过理论证明建立了"不可能定理"，表明稳定子码无法通过横向结构在多逻辑量子比特上完全实现Clifford群。引入了k-折叠横向结构概念并证明实现k个逻辑量子比特的完整Clifford群至少需要k-折叠横向结构。

Result: 1) 证明没有稳定子码能在多于一个逻辑量子比特上通过完全横向结构实现Clifford群；2) 证明对于编码多于两个逻辑量子比特的码，折叠横向实现完整Clifford群也不可能；3) 证明实现k个逻辑量子比特的完整Clifford群至少需要k-折叠横向结构；4) 码自同构结构也无法在多逻辑量子比特上实现完整Clifford群。

Conclusion: 这些结果为容错Clifford门设计设置了基本限制，表明通过横向或折叠横向架构在多逻辑量子比特上支持完整Clifford群的稳定子码不存在。由于Clifford群是通用门集的核心组件，这意味着在多逻辑量子比特编码的量子计算中，容错必然需要更复杂的构造。

Abstract: Identifying stabilizer codes that admit fault-tolerant implementations of the full logical Clifford group would significantly advance fault-tolerant quantum computation. Motivated by this goal, we study several classes of fault-tolerant gadget constructions consisting of Clifford gates acting on the physical qubits, including transversal gadgets, code automorphisms, and fold-transversal gadgets. While stabilizer codes encoding a single logical qubit, most notably the [[7,1,3]] Steane code, are known to admit transversal implementations of the full logical Clifford group, no analogous examples are known for codes encoding multiple logical qubits. In this work, we prove a no-go theorem establishing that no stabilizer code admits a fully transversal implementation of the Clifford group on more than one logical qubit. We further strengthen this result by showing that fold-transversal implementations of the full logical Clifford group are impossible for stabilizer codes encoding more than two logical qubits. More generally, we introduce the notion of k-fold transversal gadgets and prove that implementing the full Clifford group on k logical qubits requires at least k-fold transversal gadgets at the physical level. In addition, we analyze code-automorphism based constructions and demonstrate that they also fail to realize the full Clifford group on multiple logical qubits for any stabilizer code. Together, these results place fundamental constraints on fault-tolerant Clifford gadget design and show that stabilizer codes supporting the full logical Clifford group on multiple logical qubits via these architectures do not exist. Since the Clifford group is a core component of universal gate sets, our findings imply that quantum computing with codes encoding multiple logical qubits within a single code block necessarily entails more complex constructions for fault tolerance.

</details>


### [161] [Protection of Exponential Operation using Stabilizer Codes in the Early Fault Tolerance Era](https://arxiv.org/abs/2602.13399)
*Dawei Zhong,Todd A. Brun*

Main category: quant-ph

TL;DR: 该论文提出了一种将指数映射编码到稳定子码中的系统方案，用于在早期容错量子计算时代降低非克利福德操作的逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 量子纠错是实现量子优势的关键，但保护逻辑操作（特别是非克利福德操作）所需的资源在早期容错量子计算时代面临巨大挑战。需要开发低开销的编码方案来抑制噪声。

Method: 开发了将指数映射 $\exp(-iθP)$ 编码到稳定子码的系统方案，使用简单的电路结构和低量子比特开销。为[[n, n-2, 2]]量子错误检测码以及[[5,1,3]]、[[7,1,3]]、[[15,7,3]]量子纠错码提供了编码电路。

Result: 编码电路在筛选后具有较低的一阶逻辑错误率。在当前设备的物理噪声水平下，编码方案比未编码操作噪声低4-7倍，最多只需丢弃3%的运行。

Conclusion: 该编码方案为早期容错量子计算提供了一种实用的低开销方法，能够显著降低非克利福德操作的逻辑错误率，为实现量子优势铺平道路。

Abstract: Quantum error correction offers a promising path to suppress errors in quantum processors, but the resources required to protect logical operations from noise, especially non-Clifford operations, pose a substantial challenge to achieve practical quantum advantage in the early fault-tolerant quantum computing (EFTQC) era. In this work, we develop a systematic scheme to encode exponential maps of the form $\exp(-iθP)$ into stabilizer codes with simple circuit structures and low qubit overhead. We provide encoded circuits with small first-order logical error rate after postselection for the [[n, n-2, 2]] quantum error-detecting codes and the [[5, 1, 3]], [[7, 1, 3]], and [[15, 7, 3]] quantum error-correcting codes. Detailed analysis shows that under the level of physical noise of current devices, our encoding scheme is 4--7 times less noisy than the unencoded operation, while at most 3% of runs need to be discarded.

</details>


### [162] [On the Redfield and Lindblad master equations](https://arxiv.org/abs/2602.13429)
*Hans C. Fogedby*

Main category: quant-ph

TL;DR: 该论文解决了Redfield方程与Lindblad方程之间的一致性差异问题，通过引入能量守恒条件，在不使用旋转波近似的情况下实现了两个方程的等价性。


<details>
  <summary>Details</summary>
Motivation: 先前工作中发现Redfield方程存在不一致性问题，特别是它不构成一个合适的量子映射。这种不一致性与图展开和准粒子近似中的一致性要求相关。本文旨在解决这个开放性问题，建立Redfield方程与Lindblad方程之间的正式等价关系。

Method: 采用场论方法，通过施加能量守恒条件来解决Born近似层面的不一致性。详细分析了图展开和准粒子近似中的一致性要求，并将场论方法映射到开放量子系统理论的标准微观推导。

Result: 成功识别了标准Redfield方程中的差异，并通过施加能量守恒条件解决了这一差异。结果表明，能量守恒的Redfield方程与Lindblad方程在形式上等价，无需使用旋转波近似。

Conclusion: 本文解决了Redfield方程与Lindblad方程之间的一致性问题，通过引入能量守恒条件建立了两个方程的等价性，为开放量子系统的场论方法提供了更严格的基础。

Abstract: In a previous work we developed a field theoretical approach to open quantum systems using condensed matter methods. In the Born approximation we derived the Redfield equation on the basis of a multi-oscillator bath, a Dyson equation, a diagrammatic expansion and a quasi-particle approximation. In addition applying a rotating wave approximation we obtained the Lindblad equation describing a proper quantum map. The issue regarding the additional rotating wave approximation was left as an open problem.
  The present work addresses the open problem and presents new results. We identify a discrepancy in the popular and standard Redfield equation. The discrepancy is associated with the well-known fact that the Redfield equation does not represent a proper quantum map. The discrepancy is related to the diagrammatic expansion and a consistency requirement in the quasi-particle approximation. The explicit resolution of this discrepancy is obtained by imposing energy conservation on the Born level. As a result we obtain formal equivalence between the energy-conserving Redfield equation and the Lindblad equation without invoking the rotating wave approximation. We provide a detailed mapping of the field theoretical approach to the standard microscopic derivation in the theory of open quantum systems.

</details>


### [163] [Non-Uniform Quantum Fourier Transform](https://arxiv.org/abs/2602.13472)
*Junaid Aftab,Yuehaw Khoo,Haizhao Yang*

Main category: quant-ph

TL;DR: 提出了一种基于低秩分解的非均匀量子傅里叶变换(NUQFT)算法，通过块编码、量子信号处理和线性组合酉框架实现，在非均匀采样下具有多项式对数复杂度。


<details>
  <summary>Details</summary>
Motivation: 离散傅里叶变换(DFT)适用于均匀采样信号，但实际应用中常遇到非均匀采样，需要非均匀离散傅里叶变换(NUDFT)。虽然标准DFT的量子算法已成熟，但非均匀情况的量子框架尚未充分发展。

Method: 基于NUDFT矩阵的低秩分解，通过块编码、量子信号处理(QSP)和线性组合酉(LCU)框架构建量子电路，实现NUDFT矩阵的ε精确块编码，控制经典截断和量子实现的近似误差。

Result: 在标准oracle访问假设下，推导出明确的非渐近门级资源估计。复杂度随目标精度呈多项式对数增长，随量子比特数通过量子傅里叶变换呈二次增长，随非均匀网格诱导的几何相关条件参数呈对数增长。

Conclusion: 建立了NUDFT的具体且资源高效的量子模拟，为不规则采样数据的量子算法奠定了基础。

Abstract: The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $ε$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data.

</details>


### [164] [Quantum Speedups for Group Relaxations of Integer Linear Programs](https://arxiv.org/abs/2602.13494)
*Brandon Augustino,Dylan Herman,Guneykan Ozgul,Jacob Watkins,Atithi Acharya,Enrico Fontana,Junhyung Lyle Kim,Shouvanik Chakrabarti*

Main category: quant-ph

TL;DR: 该论文提出了一种用于整数线性规划（ILP）的量子算法，通过Gomory群松弛方法实现超二次加速，并在满足非退化条件时能获得ILP的最优解。


<details>
  <summary>Details</summary>
Motivation: 整数线性规划（ILP）是离散优化问题的核心模型，但求解ILP是NP难问题。传统量子框架难以获得超二次加速，因为经典算法是全局和穷举的，而量子框架需要利用目标和可行集的局部结构。

Method: 采用Gomory群松弛方法，通过丢弃线性规划松弛最优解中正变量的非负性约束，同时保持决策变量的整数性。提出了竞争性的经典局部搜索算法和相应的量子算法，并构建了具有良好谱性质的约束保持混合器。

Result: 在合理技术条件下，量子算法实现了超二次加速。当群松弛满足比LP非退化更强的非退化条件时，可获得原始ILP的最优解；否则能收紧ILP最优目标值的界限，减少整数间隙，改善分支切割法。

Conclusion: 该研究通过量子算法处理Gomory群松弛，为ILP求解提供了超二次加速的新途径，构建的约束保持混合器具有独立研究价值，并在多个实际相关ILP上验证了有效性。

Abstract: Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest.

</details>


### [165] [Efficient discrimination schemes for unextendible product bases with strong quantum nonlocality](https://arxiv.org/abs/2602.13545)
*Qiqi Feng,Huaqi Zhou,Limin Gao*

Main category: quant-ph

TL;DR: 本文针对三维系统中的强非局域UPB，提出了三种纠缠分配方案，仅需两个最大纠缠态即可完美区分，显著降低了纠缠资源消耗。


<details>
  <summary>Details</summary>
Motivation: 纠缠是量子信息科学的核心资源，设计能够最小化资源消耗的局域区分协议至关重要。本文旨在为特定未可扩展乘积基（UPB）设计高效的纠缠分配方案，这些UPB在三维系统中表现出强量子非局域性。

Method: 利用UPB的结构特征和最大纠缠态的操作优势，提出了三种纠缠分配方案。通过避免不必要的量子隐形传态，将协议扩展到d维系统中的强非局域UPB，实现仅需两个最大纠缠态即可完美区分。

Result: 成功设计了仅需两个最大纠缠态即可完美区分三维系统中强非局域UPB的协议。资源成本分析表明，这些协议能够显著降低纠缠消耗，相比传统方法更加高效。

Conclusion: 本文提出的纠缠分配方案不仅促进了资源高效的量子信息处理，还进一步揭示了最大纠缠态在操作中的作用，为量子非局域性和纠缠资源优化提供了新见解。

Abstract: Entanglement is a central resource in quantum information science; therefore, it is important to design local discrimination protocols that minimize resource consumption. In this paper, we propose three entanglement-allocation schemes for the local discrimination of particular unextendible product bases (UPB) exhibiting strong quantum nonlocality in a \(3 \otimes 3 \otimes 3\) system. By exploiting the structural features of these UPB and the operational advantages of maximally entangled states, we further extend our protocols to strongly nonlocal UPB in \(d \otimes d \otimes d\) systems. In particular, we show that these UPB can be perfectly distinguished with only two maximally entangled states. Moreover, a resource-cost analysis indicates that our protocols, which avoid quantum teleportation whenever possible, can reduce the entanglement consumption. These results not only facilitate resource-efficient quantum information processing, but also provide further insight into the operational role of maximally entangled states.

</details>


### [166] [Flux Pumped Kerr-Free Parametric Amplifier](https://arxiv.org/abs/2602.13563)
*Kagan Yanik,Irwin Huang,Bibek Bhandari,Bingcheng Qing,Ahmed Hajr,Ke Wang,David I. Santiago,Irfan Siddiqi,Justin Dressel,Andrew N. Jordan*

Main category: quant-ph

TL;DR: 提出一种基于对称穿线SQUID的磁通泵浦超导参量放大器，通过消除Kerr非线性实现量子极限放大性能


<details>
  <summary>Details</summary>
Motivation: 传统参量放大器中的Kerr非线性会导致量子效率降低和信号失真，特别是在高增益强驱动条件下。消除Kerr非线性对于实现量子极限放大至关重要。

Method: 采用对称穿线SQUID结构，将中心结替换为线性电感，从而消除Kerr非线性，使有效哈密顿量简化为简并参量放大器模型

Result: 该设计能够实现接近量子极限的相位保持增益和效率，在Kerr-free点可达到25dB增益的鲁棒操作，高阶修正项的影响远小于Kerr非线性

Conclusion: STS设计通过消除Kerr非线性，在强驱动条件下仍能保持接近量子极限的性能，为量子极限放大提供了有效的解决方案

Abstract: We propose a flux-pumped superconducting parametric amplifier based on symmetrically threaded superconducting quantum interference devices (SQUIDs) that achieves a Kerr-free operating point under suitable drive conditions. Eliminating the Kerr nonlinearity is advantageous for quantum-limited amplification, as it mitigates unwanted distortions in squeezing and prevents degradation of both gain and quantum efficiency in the high-gain strong drive regime. By replacing the central junction in the symmetrically threaded SQUIDs (STS) configuration with a linear inductor, we find that the Kerr-nonlinearity can be eliminated and the effective Hamiltonian reduces to that of a degenerate parametric amplifier (DPA), up to higher-order corrections in the zero-point fluctuations of the superconducting phase operator. We show that the deviations from ideal DPA behavior introduced by these higher-order terms are significantly weaker than those associated with a Kerr nonlinearity. Consequently, the STS design can be driven strongly while maintaining near-quantum-limited performance at the Kerr-free point. Our analysis predicts phase-preserving gain and efficiency approaching the quantum limit, with robust operation demonstrated up to 25 dB of gain.

</details>


### [167] [Time-Domain Two-Magnon Interference Enabled by a Tunable Beamsplitter](https://arxiv.org/abs/2602.13572)
*Cody Trevillian,Steven Louis,Vasyl Tyberkevych*

Main category: quant-ph

TL;DR: 该论文提出了一种基于混合腔磁子系统的可控双磁子干涉模型，实现了类似光子Hong-Ou-Mandel效应的磁子干涉，并能产生可调相位灵敏度的最大纠缠磁子N00N态。


<details>
  <summary>Details</summary>
Motivation: 开发一种可控的双磁子干涉系统，实现磁子版本的Hong-Ou-Mandel效应，为研究基本磁子动力学和开发混合磁子量子计算架构提供新工具。

Method: 使用混合腔磁子系统，包含一对相互耦合的磁子模式。通过施加时变磁场，独立激发每个模式的磁子，然后让它们相互作用，实现从独立振荡到集体振荡的转变，形成可调磁子分束器操作。

Result: 成功实现了可控的双磁子干涉，当分束器操作应用于初始非纠缠的双磁子态时，产生了具有可调相位灵敏度的最大纠缠磁子N00N态。

Conclusion: 混合腔磁子系统中的双磁子干涉有望实现新型量子计量器件，用于研究基本磁子动力学，并为开发混合磁子量子计算架构做出贡献。

Abstract: This letter presents a model system for controllable two-magnon interference in the time domain. This two-magnon interference, i.e., a magnonic analog to the photonic Hong-Ou-Mandel effect, is supported by a tunable magnonic beamsplitter operation formed in a hybrid cavity magnonic system comprising a pair of mutually coupled magnon modes. By applying a time-dependent magnetic field, magnons can be excited independently in each mode and subsequently brought into interaction, shifting from independent to collective oscillations, to realize a controllable magnonic beamsplitter. When the beamsplitter operation is applied to an initially unentangled two-magnon state, a maximally entangled magnonic $N00N$ state with tunable phase sensitivity is produced. These findings suggest that two-magnon interference in hybrid cavity magnonic systems may enable novel quantum metrological devices to study fundamental magnon dynamics and contribute to developing hybrid magnonic quantum computing architectures.

</details>


### [168] [Digitizing ultrafast adiabatic passage with a pulse train](https://arxiv.org/abs/2602.13592)
*Bo Y. Chang,Ignacio R. Sola,Svetlana A. Malinovskaya,Sebastian C. Carrasco,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 提出基于频率变化超快脉冲序列的数字化快速绝热通道实现方法，通过弱脉冲采样连续演化，实现高保真度绝热控制


<details>
  <summary>Details</summary>
Motivation: 传统长脉冲绝热激发需要连续时间控制，本文旨在开发数字化实现方法，利用超快脉冲序列来模拟连续绝热演化，提高控制灵活性和精度

Method: 使用频率变化的弱超快脉冲序列作为离散采样，推导子脉冲拉比频率和失谐的解析条件，通过频率梳边带实现大失谐下的共振激发和叠加态精确制备

Result: 即使在子脉冲数量较少的情况下，只要每个子脉冲保持在微扰范围内，就能实现高保真度的绝热动力学再现；复杂动力学需要更多子脉冲

Conclusion: 数字化快速绝热通道方法有效，为量子控制提供了灵活的工具，特别适用于利用频率梳边带进行精确量子态制备

Abstract: We present a digitized implementation of rapid adiabatic passage based on a train of weak, frequency-varying ultrafast pulses. Analytic conditions on the subpulse Rabi frequencies and detunings are derived to reproduce the continuous-time population dynamics of a conventional long-pulse excitation. We find that the reproduced dynamics achieves high fidelity even for pulse trains with a small number of subpulses, provided that each subpulse remains within the perturbative regime. The subpulses act as discrete samples of the underlying continuous evolution; consequently, more complex population dynamics, characterized by multiple oscillations prior to the onset of adiabaticity, require a larger number of subpulses for accurate reproduction. In addition, we demonstrate how the sidebands of a frequency comb can be exploited for resonant excitation at large carrier detuning and for the precise preparation of superposition states.

</details>


### [169] [Single-reference coupled-cluster theory based on the multi-purpose cluster operator](https://arxiv.org/abs/2602.13605)
*Karol Kowalski,Nicholas P. Bauman*

Main category: quant-ph

TL;DR: 本文扩展了单参考耦合簇理论，使其能同时描述多个电子态，提出新的降维形式，并引入基于酉耦合簇的厄米变体以降低量子计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统单参考耦合簇理论只能描述单一电子态（通常是基态），限制了其在激发态计算和多态描述中的应用。需要扩展理论框架以同时处理多个电子态，特别是对于量子计算应用。

Method: 1. 扩展单参考耦合簇理论，让簇算符的不同分量扮演不同角色；2. 发展新的降维形式，使有效哈密顿量能同时表示多个相关态；3. 建立三个定理形式化这一扩展；4. 引入基于酉耦合簇表示的厄米变体。

Result: 1. 证明了标准耦合簇降维是新框架的特例；2. 建立了能同时描述多个非正交态的数学框架；3. 开发了厄米变体，能更高效地模拟基态和激发态，减少量子计算资源需求。

Conclusion: 本文成功扩展了单参考耦合簇理论，使其能同时描述多个电子态，为量子计算中的多态模拟提供了更高效的框架，将传统耦合簇降维作为特例包含在内。

Abstract: In this paper, we develop a theoretical framework that extends single-reference (SR) coupled-cluster (CC) theory beyond its conventional role of describing a single electronic state-typically the lowest-energy state within the symmetry sector defined by the reference determinant. Rather than viewing the SR-CC cluster operator solely as a device for reproducing one target state, we consider more general constructions in which different components of the cluster operator play distinct roles, ranging from encoding states of different symmetry than the reference to enabling SR-CC Ansatz to describe multiple states simultaneously. These developments lead to a new class of SR-CC downfolding formalisms in which the resulting active-space effective Hamiltonians are capable of concurrently representing multiple correlated states nonorthogonal to the reference function. We establish three theorems that formalize this extension and demonstrate that standard CC downfolding emerges as a special case of the proposed framework. Finally, we introduce a Hermitian variant based on a unitary CC representation, which enables realistic simulations of ground and excited states while reducing the quantum resources required.

</details>


### [170] [Generation of large Fock states from coherent states using Kerr interaction and displacement](https://arxiv.org/abs/2602.13623)
*Nilakantha Meher,Anirban Pathak,S. Sivakumar*

Main category: quant-ph

TL;DR: 提出一种通过重复应用实验可行的幺正变换，将半经典态转换为大福克态的方案，结合克尔相互作用和脉冲相干驱动，在电路QED架构中实现高保真度大福克态生成。


<details>
  <summary>Details</summary>
Motivation: 大福克态在量子信息处理、量子计量学和基础量子物理研究中具有重要应用价值，但传统方法难以高效生成高质量的大福克态。需要开发实验可行的方案来生成高保真度的大福克态。

Method: 方案基于重复应用特定的幺正变换，该变换结合了克尔相互作用（非高斯操作）和脉冲相干驱动。通过优化克尔强度、脉冲时序和位移幅度等参数，将初始的半经典态逐步转换为目标福克态。

Result: 确定了实现该变换的合适参数值（克尔强度、脉冲时序、位移幅度），能够以接近1的保真度生成大福克态。讨论了在电路QED架构中实现该方案的可行性，并表明该方法也适用于腔场福克态的生成。

Conclusion: 提出了一种实验可行的方案来生成大福克态，结合克尔相互作用和相干驱动，在电路QED平台中具有实现潜力，为量子信息处理提供了重要的态制备工具。

Abstract: We discuss a scheme to generate large Fock states. The scheme involves repeatedly applying an experimentally feasible unitary transformation to convert a semiclassical state into a Fock state. The transformation combines Kerr interaction, which is a non-Gaussian operation, and pulsed coherent drives. We identify suitable parameter values (Kerr strength, pulse timings, displacement amplitude) for the physical processes to implement the transformation and generate large Fock states with near-unity fidelity. The feasibility of implementing the scheme in circuit QED architectures is discussed. The method is also suitable for generating Fock states of cavity fields.

</details>


### [171] [Ward-Takahashi Identity and Gauge-Invariant Response Theory for Open Quantum Systems](https://arxiv.org/abs/2602.13632)
*Hongchao Li,Xie-Hang Yu,Masaya Nakagawa,Masahito Ueda*

Main category: quant-ph

TL;DR: 该论文证明了开放量子系统中的规范不变性不需要粒子数守恒，构建了测试规范不变性的可观测量，并发现二体损耗在耗散BCS超导中诱导扩散模式。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中的规范不变性，特别是当粒子数不守恒时如何保持规范不变性，这对于理解耗散量子系统的响应理论至关重要。

Method: 推导Ward-Takahashi恒等式，建立Lindblad描述的开放量子系统的规范不变响应理论，构造测试规范不变性的可观测量，推导低能集体模式。

Result: 证明了粒子数守恒不是规范不变性的必要条件，发现二体损耗在耗散BCS超导中诱导扩散模式，构建了可用于实验测试规范不变性的方法。

Conclusion: 开放量子系统可以在粒子数不守恒的情况下保持规范不变性，二体损耗导致新的集体模式，为实验测试开放量子系统的规范不变性提供了理论框架。

Abstract: We derive the Ward-Takahashi identity and establish the gauge-invariant response theory for open quantum systems described by Lindbladians to show that particle-number conservation is not necessary to satisfy gauge invariance. We construct an observable which can be used to test the gauge invariance in the absence of particle-number conservation. We derive the low-energy collective modes that emerge as a consequence of gauge invariance in open quantum systems, and find that two-body loss induces diffusive modes in dissipative Bardeen-Cooper-Schrieffer (BCS) superconductivity. Possible experimental situations for testing gauge invariance in open quantum systems are also discussed.

</details>


### [172] [A theory of quantum error correction for permutation-invariant codes](https://arxiv.org/abs/2602.13638)
*Yingkai Ouyang,Gavin K. Brennen*

Main category: quant-ph

TL;DR: 首次提出置换不变码的通用纠错理论，利用对称群表示论构建高效算法，可纠正任何可纠正错误


<details>
  <summary>Details</summary>
Motivation: 置换不变码在量子计算中具有重要应用，但缺乏通用的纠错理论。需要开发能够处理任何可纠正错误的系统化纠错方法。

Method: 利用对称群表示论构建算法，包括总角动量测量、量子Schur变换或逻辑态隐形传态、几何相位门等技术。针对擦除/删除错误提供简化算法。

Result: 首次建立了置换不变码的通用纠错理论，为任何置换不变码构建了能够纠正任何可纠正错误的高效算法。

Conclusion: 该工作填补了置换不变码纠错理论的空白，为量子计算中的纠错提供了新的系统化方法，特别适用于擦除/删除错误场景。

Abstract: We present for the first time a general theory of error correction for permutation invariant (PI) codes. Using representation theory of the symmetric group we construct efficient algorithms that can correct any correctible error on any PI code. These algorithms involve measurements of total angular momentum, quantum Schur transforms or logical state teleportations, and geometric phase gates. For erasure errors, or more generally deletion errors, on certain PI codes, we give a simpler quantum error correction algorithm.

</details>


### [173] [Comment on "Evolution Operator Can Always Be Separated into the Product of Holonomy and Dynamic Operators"](https://arxiv.org/abs/2602.13648)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 该论文反驳了先前研究中的错误主张，指出量子时间演化不能总是表示为完整算符和动态算符的乘积


<details>
  <summary>Details</summary>
Motivation: 先前研究（PRL 131, 200202 (2023)）声称量子时间演化总能表示为完整算符和动态算符的乘积，本文旨在证明这一主张是错误的

Method: 通过分析先前研究中时间演化算符的循环使用，指出其论证中的逻辑缺陷

Result: 成功证明了先前研究的结论是错误的，量子时间演化不能总是分解为完整算符和动态算符的乘积

Conclusion: 先前关于量子时间演化分解的普遍性主张是不成立的，其论证存在根本性的逻辑错误

Abstract: We show that the claim in Ref. [PRL 131, 200202 (2023)], that the quantum time evolution always can be written as a product of a holonomy operator and a dynamic operator, is false, as it is based on a circular use of the time evolution operator.

</details>


### [174] [Strong-Field Quantum Metrology Beyond the Standard Quantum Limit](https://arxiv.org/abs/2602.13667)
*Tsendsuren Khurelbaatar,R. T. Sang,Igor Litvinyuk*

Main category: quant-ph

TL;DR: 该论文提出了一种将量子光学与强场物理结合的新方法，通过强场光电子全息术研究压缩光对极端非线性光-物质相互作用的影响，建立了阿秒量子层析成像框架。


<details>
  <summary>Details</summary>
Motivation: 量子光学与强场物理的结合为探索量子光如何塑造极端非线性光-物质相互作用提供了途径。然而，在损伤阈值强度下直接表征非经典光仍然是一个未解决的问题。

Method: 使用量子光学强场近似理论，研究压缩光的光子数涨落对强场光电子全息术的影响。通过分析电子半经典作用的稳定性，识别了"有质动力失相"机制，并评估了经典费希尔信息。

Result: 发现振幅压缩光能稳定作用并增强全息对比度，而相位压缩光会放大光子数噪声导致条纹可见度快速坍塌。这种量子光学敏感性遵循陡峭的四次方波长标度，使中红外驱动对场的量子性质特别敏感。全息对比度坍塌不是信息损失而是计量增益。

Conclusion: 强场电离可作为非线性量子转换器，将阿秒电子动力学与量子信息科学联系起来。建立了阿秒量子层析成像框架，这是一种原位、无参考的协议，用于重建强量子光的维格纳分布。

Abstract: Bridging quantum optics and strong-field physics provides a pathway to explore how quantum light shapes extreme nonlinear light-matter interactions. However, direct characterization of non-classical light at damage-threshold intensities remains an open question. Here, we theoretically investigate the impact of photon-number fluctuations of squeezed light on strong-field photoelectron holography using a quantum-optical strong-field approximation. We identify a mechanism, ponderomotive dephasing, whereby the inherent quantum fluctuations of the driving field dictate the stability of the electron's semiclassical action. While amplitude-squeezed light stabilizes the action to enhance holographic contrast, phase-squeezed light amplifies photon-number noise, causing a rapid collapse of fringe visibility. This quantum-optical sensitivity follows a steep quartic wavelength scaling, rendering mid-infrared drivers uniquely sensitive to the field's underlying quantum nature. Crucially, we show that the collapse of holographic contrast is not a loss of information but a metrological gain. By evaluating the Classical Fisher Information, we identify a "dark-port" mechanism in the tunneling tail that enables the estimation of field quadrature noise beyond the Standard Quantum Limit. This fundamental trade-off between structural imaging fidelity and statistical sensitivity establishes the framework for Attosecond Quantum Tomography: an in-situ, reference-free protocol to reconstruct the Wigner distribution of intense quantum light. Our results identify strong-field ionization as a nonlinear quantum transducer, bridging attosecond electron dynamics with quantum information science.

</details>


### [175] [A group structure arising from Grover walks on complete graphs with self-loops and its application](https://arxiv.org/abs/2602.13686)
*Tatsuya Tsurii,Naoharu Ito*

Main category: quant-ph

TL;DR: 提出群论框架分析带自环完全图上Grover行走的代数结构，证明商群同构于有限循环群，其结构取决于顶点数的奇偶性。


<details>
  <summary>Details</summary>
Motivation: 研究Grover量子行走在带自环完全图上的代数结构，揭示其时间演化中的对称性和周期性行为，为理解量子行走的代数性质提供理论框架。

Method: 构建由Grover矩阵和以复单位根幂为对角元的对角矩阵生成的群，利用这些矩阵的交换子形成的子群定义商群，并分析商群的代数结构。

Result: 证明该商群同构于有限循环群，其结构依赖于顶点数的奇偶性：当顶点数为奇数时商群同构于Z_2，当顶点数为偶数时商群同构于Z_4。

Conclusion: 群论框架揭示了Grover行走时间演化中的潜在对称性，为理解其周期性行为提供了代数解释，建立了量子行走与有限群理论之间的联系。

Abstract: This paper introduces a group-theoretic framework to analyze the algebraic structure of the Grover walk on a complete graph with self-loops. We construct a group generated by the Grover matrix and a diagonal matrix whose entries are powers of a complex root of unity. We then characterize the resulting quotient group, which is defined using a subgroup formed by commutators involving these matrices. We show that this quotient group is isomorphic to a finite cyclic group whose structure depends on the parity of the number of vertices. This group-theoretic characterization reveals underlying symmetries in the time evolution of the Grover walk and provides an algebraic framework for understanding its periodic behavior.

</details>


### [176] [Quantum dynamics of microwave photons in synthetic frequency dimension](https://arxiv.org/abs/2602.13736)
*Zheshu Xie,Luojia Wang,Jiawei Qiu,Libo Zhang,Yuxuan Zhou,Ziyu Tao,Wenhui Huang,Yongqi Liang,Jiajian Zhang,Yuanzhen Chen,Song Liu,Jingjing Niu,Yang Liu,Youpeng Zhong,Luqi Yuan,Dapeng Yu*

Main category: quant-ph

TL;DR: 该研究实现了超导量子电路中的合成频率维度，在单光子水平上演示了量子随机行走、布洛赫振荡和单向频率转换等量子现象。


<details>
  <summary>Details</summary>
Motivation: 合成频率维度为模拟晶格模型和控制光子动力学提供了强大工具，但将其扩展到量子领域（特别是单光子水平）在光子平台中一直具有挑战性。

Method: 将超导量子比特与16米铝同轴电缆集成，使用可调谐SQUID调制器合成晶格耦合和人工规范场，通过快速时间调制实现非绝热单向频率转换。

Result: 成功观察到单光子量子随机行走、布洛赫振荡，以及晶格哈密顿量快速时间调制下的非绝热单向频率转换，并测量了能带结构。

Conclusion: 超导量子电路成为可编程哈密顿量和可扩展合成晶格的通用平台，具有灵活的单光子控制能力。

Abstract: Synthetic frequency dimension offers a powerful approach to simulate lattice models and control photon dynamics. However, extending this concept into the quantum regime, particularly at the single-photon level, has remained challenging in photonic platforms. Here, we demonstrate quantum-state initialization and detection of single-photon evolutions within a synthetic frequency lattice by integrating a superconducting qubit with a 16-meter aluminum coaxial cable. A tunable superconducting quantum interference device (SQUID)-based modulator is employed to synthesize lattice couplings and artificial gauge fields. We observe single-photon quantum random walks and Bloch oscillations, as well as nonadiabatic, unidirectional frequency conversion under rapid temporal modulation of the lattice Hamiltonian, together with band-structure measurements. The lattice connectivity can be readily reconfigured to construct higher-dimensional lattices using multiple drive tones. Our results establish superconducting quantum circuits as a versatile platform for programmable Hamiltonians and extensible synthetic lattices with flexible single-photon control.

</details>


### [177] [Non-Abelian Aharonov-Bohm Caging in Synthetic Dimensions with a Trapped Ion](https://arxiv.org/abs/2602.13796)
*Wanchao Yao,Sai Li,Zhiyuan Liu,Yi Li,Zihan Xie,Xingyu Zhao,Xu Cheng,Yue Li,Zheng-Yuan Xue,Yiheng Lin*

Main category: quant-ph

TL;DR: 实验在离子阱系统中实现了可调谐的非阿贝尔SU(2)规范场，并在菱形晶格中观测到了阿贝尔和非阿贝尔情况下的Aharonov-Bohm囚禁现象。


<details>
  <summary>Details</summary>
Motivation: 目前对Aharonov-Bohm囚禁的研究大多局限于阿贝尔规范场情况，在量子系统中观测非阿贝尔规范场下的AB囚禁仍然难以实现。该研究旨在填补这一空白。

Method: 在离子阱系统中，利用多能级振动模式构建合成维度，在菱形晶格上实现可调谐的非阿贝尔SU(2)规范场，并系统研究其输运特性。

Result: 成功实现了阿贝尔和非阿贝尔规范场下的AB囚禁，观测到非阿贝尔AB囚禁特有的量子动力学现象，包括初态依赖动力学、二阶效应和非对称囚禁行为。

Conclusion: 离子阱系统是模拟具有奇异合成规范场的高维量子系统中涌现现象的强大平台。

Abstract: Aharonov-Bohm (AB) caging is a complete localization phenomenon in two-dimensional lattices due to destructive interference induced by the background gauge fields. However, current investigations of AB caging are mostly restricted to the Abelian gauge field case, and the observation of AB caging under non-Abelian gauge fields in a quantum system still remains elusive. Here, we report experimental realization of tunable synthetic non-Abelian SU(2) gauge fields in a rhombic lattice, engineered within the synthetic dimensions of a vibrating trapped ion with multiple levels. We realize AB caging under both Abelian and non-Abelian gauge fields and systematically investigate the distinctive transport properties of the non-Abelian case. In particular, we observe typical emergent quantum dynamics unique to non-Abelian AB caging, including initial-state-dependent dynamics, second-order effects, and asymmetric caging behavior. These observations demonstrate the trapped ion system as a powerful platform for simulating emergent phenomena in high-dimensional quantum systems with exotic synthetic gauge fields.

</details>


### [178] [Field-Tunable Meissner-Levitated Ferromagnetic Microsphere Sensor for Cryogenic Casimir and Short-Range Gravity Tests](https://arxiv.org/abs/2602.13829)
*Yi-Chong Ren,Feng Xu,Wijnand Broer,Xiao-Jing Chen,Fei Xue*

Main category: quant-ph

TL;DR: 提出一种自校准量子力梯度传感器，利用迈斯纳悬浮铁磁微球在超导平面上方，通过偏置磁场可调间隙，实现亚微米分离下的近场力测量，可探测卡西米尔效应和短程相互作用。


<details>
  <summary>Details</summary>
Motivation: 亚微米分离下的近场力测量可以探测卡西米尔效应和假设的短程相互作用，但需要低温操作和稳定的原位间隙控制。现有技术面临机械接近困难、背景噪声控制复杂等问题。

Method: 使用铁磁微球在I型超导平面上方迈斯纳悬浮，通过偏置磁场可调平衡间隙。力梯度编码为共振频率偏移，通过锁相环跟踪。运动通过SQUID耦合、通量可调微波谐振器读取，提供可调测量强度而无光学加热。

Result: 推导出达到标准量子极限的条件，发现反直觉的缩放定律：由于位移到通量的转换随微球尺寸增加，更大的微球需要更少光子达到SQL，为宏观量子计量学提供途径。预测在毫开尔文温度下力灵敏度可达~10^{-19} N/Hz^{1/2}。

Conclusion: 该自校准量子力梯度传感器为亚微米分离下的近场力测量提供新方法，可提取卡西米尔压力，约束牛顿引力在0.1-10μm范围内的Yukawa型偏差，具有高灵敏度和原位间隙控制优势。

Abstract: Near-field force measurements at submicron separations can probe Casimir effects and hypothetical short-range interactions, but require cryogenic operation and stable, \textit{in situ} control of separation-dependent backgrounds. We propose a self-calibrating quantum force-gradient sensor in which a ferromagnetic microsphere is Meissner-levitated above a type-I superconducting plane, while a bias magnetic field reproducibly tunes the equilibrium gap for in situ separation scans without mechanical approach. The force gradient is encoded as a resonance-frequency shift tracked by a phase-locked loop, and the motion is read out with a SQUID-coupled, flux-tunable microwave resonator that provides adjustable measurement strength without optical heating. Using the input--output formalism, we derive the conditions for reaching the standard quantum limit (SQL) and identify a counterintuitive scaling law: because displacement-to-flux transduction increases with microsphere size, larger microspheres require fewer photons to reach the SQL, enabling a pathway to macroscopic quantum metrology. We quantify the trade-off between suppression of electrostatic patch potentials (via Au coating) and eddy-current dissipation, project force sensitivities of $\sim 10^{-19}\,\rm{N\,Hz^{-1/2}}$ at millikelvin temperatures, and outline protocols to extract Casimir pressure and constrain Yukawa-type deviations from Newtonian gravity over $0.1$--$10\,μ\mathrm{m}$.

</details>


### [179] [Quantum computation and quantum error correction: the theoretical minimum](https://arxiv.org/abs/2602.13876)
*Mark Wildon*

Main category: quant-ph

TL;DR: 介绍量子计算与量子纠错的基础知识，重点讨论稳定子理论和李理论基础，以Steane [[7,1,3]]码为主要示例


<details>
  <summary>Details</summary>
Motivation: 为读者提供量子计算和量子纠错的基本数学框架，强调稳定子理论的重要性，并建立量子计算与基础数学理论（李理论）的联系

Method: 使用SU₂→SO₃(ℝ)的双重覆盖映射说明单量子比特的状态与测量区别，讨论纠缠和CNOT门，Deutsch-Jozsa问题，最后以Steane [[7,1,3]]码为例介绍量子纠错

Result: 建立了量子计算的基本数学框架，通过具体示例（如Steane码）展示了量子纠错的实际应用，为理解量子计算提供了系统的理论基础

Conclusion: 该笔记系统介绍了量子计算和量子纠错的核心概念，强调了数学基础（特别是李理论和稳定子理论）在理解量子计算中的重要性，为后续研究提供了坚实的理论基础

Abstract: These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\mathrm{SU}_2 \rightarrow \mathrm{SO}_3(\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout.

</details>


### [180] [High-fidelity non-adiabatic dark state gates for neutral atoms](https://arxiv.org/abs/2602.13885)
*Nader Mostaan,Kapil Goswami,Peter Schmelcher,Rick Mukherjee*

Main category: quant-ph

TL;DR: 量子最优控制使非阻塞门方案能够使用实验成熟的脉冲整形技术实现，在保持暗态协议固有鲁棒性的同时，实现与时间最优阻塞门相当的快速门操作。


<details>
  <summary>Details</summary>
Motivation: 里德堡阻塞门是目前中性原子量子处理器中最成熟的纠缠操作，但在较大原子间距下性能下降，且对运动和噪声敏感。非阻塞门方案（如暗态和几何协议）具有互补的鲁棒性，但通常需要复杂且实验要求高的控制。

Method: 采用量子最优控制技术，将非阻塞门方案（特别是暗态门）与实验成熟的脉冲整形技术相结合，构建非绝热实现方案，仅使用平滑、实验可行的脉冲。

Result: 实现了与时间最优阻塞门相当的快速门操作，同时增强了对运动耦合、激光噪声和相互作用不均匀性的鲁棒性，特别是在阻塞半径附近和超出阻塞半径的区域。

Conclusion: 这项工作为在不增加实验复杂性的情况下实现快速、鲁棒的两量子比特门提供了一条实用途径，将量子最优控制与非阻塞门方案的优势相结合。

Abstract: Rydberg blockade gates are the most experimentally mature entangling operations in neutral-atom quantum processors, combining fast gate times with simple control, but their performance degrades at larger interatomic separations and remains sensitive to motional and technical noise. Non-blockade gate schemes, such as dark-state and geometric protocols, offer complementary robustness but typically rely on complex and experimentally demanding control. Here we show that quantum optimal control enables non-blockade gate schemes to be implemented using the experimentally established pulse-shaping techniques developed for blockade-based gates. Focusing on the dark-state gate, we construct non-adiabatic implementations that preserve the intrinsic robustness of adiabatic dark-state protocols while achieving gate times comparable to time-optimal blockade gates using only smooth, experimentally feasible pulses. The resulting gates exhibit enhanced resilience to motional coupling, laser noise, and interaction inhomogeneity, particularly near and beyond the blockade radius. This work establishes a practical route to fast, robust two-qubit gates without increased experimental complexity.

</details>


### [181] [High-Field NMR Characterization and Indirect $J$-Spectroscopy of a Nuclear Spin Chain [U-$^{13}$C,$^{15}$N]-butyronitrile](https://arxiv.org/abs/2602.13895)
*Alexey Kiryutin,Ivan Zhukov,Danil Markelov,Erik Van Dyke,Alexandra Yurkovskaya,Danila Barskiy*

Main category: quant-ph

TL;DR: 研究人员使用[U-13C,15N]-丁腈作为化学工程核自旋链模型，结合高场NMR检测与超低场演化，实现了12自旋网络的完整耦合表征。


<details>
  <summary>Details</summary>
Motivation: 一维耦合自旋链是强关联量子物质的最小模型，可作为量子信息传输的导线。在零场到超低场条件下，各向异性耦合被平均，内部哈密顿量可近似为各向同性海森堡模型，需要建立特征良好的自旋链模型系统。

Method: 1) 从16.4T高场NMR谱中提取12自旋网络(4个13C、1个15N、7个1H)的所有J耦合；2) 使用机械场循环装置在高场预极化自旋，转移到<50nT的磁屏蔽区进行演化，然后返回高场检测；3) 通过傅里叶分析获得间接J谱；4) 进行2D实验关联高场化学位移。

Result: 观察到清晰的J、1.5J和2J谱特征，与使用提取的耦合矩阵进行的模拟结果良好一致。成功建立了[U-13C,15N]-丁腈作为特征良好的自旋链模型系统，为未来超极化和量子控制研究提供了哈密顿量基准。

Conclusion: 该工作建立了一个化学工程的自旋链模型系统，通过结合高场NMR检测与超低场演化，实现了分子自旋链内相互作用的完整映射，为量子控制和超极化研究提供了定量基准。

Abstract: One-dimensional chains of coupled spins are minimal models of strongly correlated quantum matter, and have been proposed as wires for transporting quantum information. In liquids, rapid molecular tumbling averages anisotropic dipolar couplings and leaves effective isotropic scalar $J$-coupling Hamiltonians. At zero- to ultralow-field (ZULF) conditions, differences in frequency between nuclear spins of different types are quenched and the internal Hamiltonians can be closely approximated by an isotropic Heisenberg model. In this work, we present [U-$^{13}$C,$^{15}$N]-butyronitrile as a chemically engineered nuclear spin chain whose full spin-spin coupling network can be determined and validated by combining high-field NMR detection with evolution at ultralow fields. Starting from high-field (16.4 T) NMR spectra of $^1$H, $^{13}$C, and $^{15}$N nuclei, we extract all relevant $J$-couplings within a 12-spin network (four $^{13}$C, one $^{15}$N, and seven $^1$H). We then employ a mechanical field-cycling apparatus to prepolarize the spins at high field, shuttle them into a magnetically shielded region for evolution at <50 nT, and detect signals after returning to high field. Fourier analysis of the ultralow-field evolution yields indirect $J$-spectra that are conceptually analogous to ZULF NMR spectra but measured by a high-field NMR spectrometer. We observe clear spectral features at $J$, 1.5$J$, and 2$J$, in good agreement with simulations using the extracted coupling matrix. Finally, we demonstrate 2D experiments that correlate high-field chemical shifts and, thus, fully map interactions within the molecular spin chain. Our results establish [U-$^{13}$C,$^{15}$N]-butyronitrile as an extremely well-characterized spin chain model system and provide a quantitative Hamiltonian benchmark for future hyperpolarization and quantum-control studies.

</details>


### [182] [Decoherence, Perturbations and Symmetry in Lindblad Dynamics](https://arxiv.org/abs/2602.13922)
*A. Y. Klimenko*

Main category: quant-ph

TL;DR: 将Dyson型微扰处理和离散对称性约束从薛定谔方程和冯·诺依曼方程扩展到退相Lindblad框架，应用于单/双衍射散射数据，得到改进的拟合结果，支持CPT不变退相而非CP不变退相。


<details>
  <summary>Details</summary>
Motivation: 将量子力学中的奇对称表述从一般动力学考虑扩展到具体工具，特别是将退相干效应纳入衍射散射分析，改进传统近似方法。

Method: 扩展Dyson型微扰处理和离散对称性约束到退相Lindblad框架，基于随机实在论和双时间边界条件，建立标度关系并应用于pp和p\bar{p}碰撞的单/双衍射数据。

Result: 单衍射截面通过三参数拟合得到相对RMS偏差约4%的良好描述，显著优于忽略退相干的传统近似；提取的退相干因子φ≈0.89，在SD、DD和E710直接估计中一致，支持CPT不变退相而非CP不变退相。

Conclusion: 退相干效应在衍射散射中至关重要，提取的退相干因子φ≈0.89一致支持CPT不变退相机制，为量子力学中的对称性破缺提供了实验证据。

Abstract: We extend a perturbative Dyson-type treatment and discrete-symmetry constraints from the Schrödinger and von Neumann equations to a dephasing Lindblad framework. This work develops further the odd-symmetric formulation -- based on stochastic realism and dual temporal boundary conditions -- from general dynamical considerations to specific tools of quantum mechanics. Applying the resulting scaling relations to published single- and double-diffractive data in $pp$ and $p\bar{p}$ collisions (ISR, UA4, UA5, CDF, D0, ALICE, and E710), we show that single-diffraction cross sections are well described by a three-parameter fit with a relative RMS deviation of $\sim 4\%$, substantially improving upon conventional approximations that neglect decoherence. The extracted decoherence factor is consistently $φ\approx 0.89$, in agreement across SD, DD, and E710-based (direct) estimates, and is naturally interpreted as $φ=1$ for CP-invariant dephasing but $φ<1$ for CPT-invariant dephasing, favouring the latter.

</details>


### [183] [Homodyne Detection of Temporally Resolved Quantum States](https://arxiv.org/abs/2602.13946)
*Owen Sandner,Brendan Mackey,Yuyang Liu,Connor Kupchak,Andrew MacRae*

Main category: quant-ph

TL;DR: 提出一种基于平衡零差探测的时间分辨量子态测量分析方法，包括形式化框架、模拟算法和开源实现


<details>
  <summary>Details</summary>
Motivation: 研究如何在任意时间模式下通过探测器自然基投影来测量时间分辨量子态，并分析实际测量误差对量子态重构的影响

Method: 建立时间模式投影到探测器自然基的形式化框架，开发连续零差探测光电流模拟算法，分析测量误差对边际重构和量子态层析的影响

Result: 提供了完整的开源实现，能够模拟时间分辨模式下的连续零差探测，并探索实际测量误差对量子态重构的影响

Conclusion: 该方法为时间分辨量子态测量提供了理论框架和实用工具，有助于理解和优化实际量子测量系统中的误差影响

Abstract: We present an analysis of the time domain measurement of temporally resolvable quantum states using balanced homodyne detection. Our approach outlines a formalism of detecting quantum states in arbitrary temporal modes via projection of the temporal mode onto a natural detector basis. We then present an algorithm for simulating the resultant photocurrent of continuous homodyne detection in the presence of a temporally resolved mode, and use this algorithm to explore the effects of realistic measurement errors on marginal reconstruction and quantum state tomography. A complete implementation of the method is provided through open source code on a GitHub repository.

</details>


### [184] [Wideband Quantum Transduction for Rydberg Atomic Receivers Using Six-Wave Mixing](https://arxiv.org/abs/2602.13955)
*Yuanbin Chen,Chau Yuen,Chong Meng Samson See*

Main category: quant-ph

TL;DR: SWM-based Rydberg原子接收器相比传统EIT方案，将3dB基带带宽提升了一个数量级以上，同时保持相当的电场灵敏度，并揭示了宽可调的线性工作区域。


<details>
  <summary>Details</summary>
Motivation: 传统基于电磁感应透明（EIT）的Rydberg原子接收器虽然电场灵敏度极高，但其3dB基带带宽通常限制在几十到几百kHz，这限制了宽带无线应用。需要突破这一瓶颈以实现更广泛的应用。

Method: 研究基于六波混频（SWM）的Rydberg原子接收器作为宽带射频到光量子转换器。建立了从探针输入到输出光场的显式基带输入输出模型，推导出3dB带宽的闭式表达式，并使用1dB压缩点（P1dB）和输入参考三阶截点（IIP3）量化线性动态范围。

Result: 在相同光学驱动条件下，SWM配置相比EIT方案将3dB基带带宽提升了一个数量级以上，同时保持了相当的电场灵敏度，并揭示了宽可调的线性工作区域。

Conclusion: SWM-based Rydberg原子接收器通过显著提升带宽同时保持高灵敏度，为宽带无线应用提供了有前景的解决方案，并揭示了带宽-线性度权衡的通信兼容特性。

Abstract: Rydberg atomic receivers hold extremely high sensitivity to electric fields, yet their effective 3-dB baseband bandwidth under conventional electromagnetically induced transparency (EIT) is typically constrained to tens to a few hundreds of kilohertz, which hinders wideband wireless applications. To relax this bottleneck, we investigate a six-wave mixing (SWM)-based Rydberg atomic receiver as a wideband radio frequency (RF)-to-optical quantum transducer. Specifically, we develop an explicit baseband input-output model spanning from the probe input to the output light field. Based upon this model, a closed-form 3-dB bandwidth expression is derived to expose its dependence on key optical and RF parameters. We further quantify the linear dynamic range by employing the 1-dB compression point (P1dB) and the input-referred third-order intercept point (IIP3), unveiling a communication-compatible characterization of the bandwidth-linearity trade-off. Finally, our numerical results demonstrate that, given identical optical driving conditions, the SWM configuration increases the 3-dB baseband bandwidth by more than an order of magnitude compared to the EIT-based counterpart, while retaining comparable electric-field sensitivity and revealing a broad, tunable linear operating region.

</details>


### [185] [Phase sensitive topological classification of single-qubit measurements in linear cluster states](https://arxiv.org/abs/2602.13990)
*Sougata Bhattacharyya,Sovik Roy*

Main category: quant-ph

TL;DR: 该论文为单量子比特投影测量在一维线性簇态上提供了明确的几何分类，通过建立测量与拓扑手术操作的对应关系，将簇态表示为线性Hopf链，并引入带框架的带状表示来编码量子相位。


<details>
  <summary>Details</summary>
Motivation: 动机在于为基于测量的量子计算中的测量诱导纠缠变换提供统一的几何解释，揭示量子相位如何直接对应于带框架的拓扑不变量，从而更好地理解测量对簇态拓扑结构的影响。

Method: 方法包括：1）建立测量与拓扑手术操作的明确对应关系（测量手术对应）；2）将簇态表示为线性Hopf链；3）引入带框架的带状表示，其中量子相位编码为几何扭曲；4）分析不同Pauli基测量对拓扑结构的影响。

Result: 结果显示：Z基测量在体测量时执行拓扑切断，在边界测量时执行边界修剪；X基测量移除被测量量子比特并拼接其邻居；Y基测量也保持连通性但产生复相位因子。通过引入框架表示，成功区分了X和Y测量的拓扑效应。

Conclusion: 结论是该方法为线性簇态上的单量子比特测量提供了相位敏感且结果解析的拓扑描述，揭示了量子相位直接对应于带框架的拓扑不变量，为测量诱导的纠缠变换提供了统一的几何解释。

Abstract: We provide an explicit geometric classification of single-qubit projective measurements on one-dimensional linear cluster states within a topological framework. By establishing an explicit geometrical correspondence between local measurements and topological surgery operations on an associated link model i.e. a measurement surgery correspondence, we represent the cluster state as a linear Hopf chain. Within this model, measurements in the computational ($Z$) basis act as topological severance in case of bulk measurements while boundary pruning happens for end measurements of qubits. In contrast, transverse ($X$) basis measurements remove the measured qubit while splicing its neighbours, preserving connectivity through real valued correlations. We show that lateral ($Y$) basis measurements also preserve connectivity but generate intrinsically complex phase factors that are not captured by unframed link models, rendering X and Y measurements topologically indistinguishable at the level of connectivity alone. To resolve this ambiguity, we introduce a framed ribbon representation in which quantum phases are encoded as geometric twists, with chiral $\pm 90^\circ} twists corresponding to the phases $\pm i$. This framing yields a phase-sensitive and outcome resolved topological description of all single qubit measurements on linear cluster states. Our approach provides a unified geometric interpretation of measurement-induced entanglement transformations in measurement-based quantum computation, revealing that quantum phases correspond directly to framed topological invariants. The work is restricted to one-dimensional linear cluster states and single-qubit measurements in the Pauli bases.

</details>


### [186] [Semiclassical Simulation of Homogeneous Emitter Ensembles with Local Dissipation](https://arxiv.org/abs/2602.14025)
*Lewis Ruks*

Main category: quant-ph

TL;DR: 提出一种基于截断维格纳近似（TWA）的方法，用于高效模拟具有局部耗散的置换不变发射体系综，可处理数百个相互作用系综的大规模模拟。


<details>
  <summary>Details</summary>
Motivation: 量子光学技术中的发射体系综是基础组件，但高效准确模拟大规模系综仍然具有挑战性。需要建立微观模型与涌现行为之间的桥梁。

Method: 通过将置换不变发射体系综的随机轨迹采样扩展到包含布洛赫球的扩展相空间，构建截断维格纳近似（TWA）方法。

Result: TWA能准确捕捉动力学行为（包括非经典特征），且近似精度随系综规模增大而提高。成功模拟了泵浦一维链中数百个相互作用系综，揭示了涌现的空间相干性和合作发射的选择性方向性。

Conclusion: 该方法扩展了量子发射体系综的可扩展模拟范围，为研究扩展的光-物质系统提供了实用路径，建立了微观模型与涌现行为之间的桥梁。

Abstract: Emitter ensembles constitute a fundamental component in quantum optical technologies, yet efficient and accurate simulation of large ensembles remains challenging. Here, we formulate a truncated Wigner approximation (TWA) for permutation-invariant emitter ensembles subject to local dissipation by sampling stochastic trajectories in an extended phase space encompassing the Bloch sphere. Benchmarks show that the TWA accurately captures dynamics, including nonclassical signatures, with the approximation improving with ensemble size. We demonstrate large-scale simulations of hundreds of interacting ensembles within the TWA to reveal emergent spatial coherence and selective directionality of cooperative emission in a pumped 1D chain, highlighting a practical path to studying extended light-matter systems. Our results expand the scope of scalable simulations of quantum emitter ensembles, establishing a bridge between microscopic models and emergent behavior.

</details>


### [187] [Enhancing collective spin squeezing via one-axis twisting echo control of individual atoms](https://arxiv.org/abs/2602.14036)
*Zhiwei Hu,Youwei Zhang,Junlei Duan,Mingfeng Wang,Yanhong Xiao*

Main category: quant-ph

TL;DR: 提出一种相干控制方案，通过回声序列中的量子非破坏测量和内部单轴扭曲相互作用，增强集体自旋压缩并将原子间纠缠映射到两个明确磁子能级上


<details>
  <summary>Details</summary>
Motivation: 现有利用内部原子自由度增强压缩的方案通常将集体压缩编码在磁子能级的复杂叠加态中，这使得状态控制复杂化并限制了实际应用。需要一种既能增强压缩又能将纠缠映射到明确能级上的方法。

Method: 提出一种相干控制方案，采用回声序列：将量子非破坏测量夹在两个内部单轴扭曲相互作用之间，同时增强集体自旋压缩并将原子间纠缠映射到两个明确的磁子能级上。

Result: 该方法能最优地利用内部态来增强原子间纠缠，同时将其编码在两个磁子能级中，可直接转换为计量学上有用的自旋压缩。

Conclusion: 该方案为多能级原子系统中生成高度纠缠且易于访问的量子态提供了一种直接有效的策略。

Abstract: Spin squeezing generated via inter-atom entanglement in multilevel atomic ensembles provides a powerful resource for quantum-enhanced metrology. Existing schemes that harness internal atomic degrees of freedom to boost squeezing typically encode the collective squeezing in complex superpositions of magnetic sublevels, which complicates state control and limits practical applications. Here, we propose a coherent control scheme that simultaneously enhances collective spin squeezing and maps the resulting atom-atom entanglement onto two well-defined magnetic sublevels suitable for subsequent metrology experiments. Our protocol sandwiches a quantum non-demolition measurement between two internal one-axis-twisting interactions arranged in an echo sequence. We show that this approach can optimally leverage internal states to boost the inter-atom entanglement and, at the same time, encode it in two magnetic sublevels, which is readily convertible into metrologically useful spin squeezing. Our results offer a straightforward and efficient strategy for generating highly entangled yet readily accessible quantum states in multilevel atomic systems.

</details>


### [188] [Non-Hermitian Quantum Mechanics of Open Quantum Systems: Revisiting The One-Body Problem](https://arxiv.org/abs/2602.14105)
*Naomichi Hatano,Gonzalo Ordonez*

Main category: quant-ph

TL;DR: 该论文回顾了开放量子系统的分析方法，展示了在无限环境系统中非厄米性的产生，通过单粒子问题完全求解，发现了包含共振态的新完备基组，并强调了动力学的时间反演对称性。


<details>
  <summary>Details</summary>
Motivation: 重新审视开放量子系统的单粒子问题，因为该问题可以完全求解，有助于理解开放量子系统的问题结构，为处理多体相互作用问题奠定基础。同时，该方法允许系统与环境之间的强耦合，这在当前研究背景下很有价值。

Method: 采用两种方法：1) 势散射理论中直接定义满足Siegert出射边界条件的薛定谔方程本征态作为共振态；2) Feshbach形式主义，通过消除环境的无限自由度，将其效应表示为复势，得到显式非厄米的有效哈密顿量。将这两种方法统一，获得了包含所有离散本征态（包括共振态）的新完备基组。

Result: 发现了包含共振态的新完备基组，可用于散射问题。展示了即使哈密顿量看似厄米，共振本征态仍可具有复能量本征值。通过新完备基组能够捕捉开放量子系统的非马尔可夫动力学及其时间反演对称性。

Conclusion: 通过完全可解的开放量子系统单粒子问题，揭示了非厄米性的产生机制，建立了包含共振态的新完备基组，为理解开放量子系统结构和处理多体问题提供了理论基础，并强调了动力学的时间反演对称性。

Abstract: We review analyses of open quantum systems. We show how non-Hermiticity arises in an open quantum system with an infinite environment, focusing on the one-body problem. One of the reasons for taking the present approach is that we can solve the problem completely, making it easier to see the structures of problems involving open quantum systems. We show that this results in the discovery of a new complete set, which is one of the main topics of the present article. Another reason for focusing on the one-body problem is that the theory permits the strong coupling between the system and the environment. In the current research landscape, it is valuable to revisit the one-body problem for open quantum systems, which can be solved accurately for arbitrary strengths of the system-environment couplings. A rigorous understanding of the problem structures in the present approach will be helpful when we tackle problems with many-body interactions. First, we consider potential scattering and directly define the resonant state as an eigenstate of the Schrödinger equation under the Siegert outgoing boundary condition. We show that the resonant eigenstate can have a complex energy eigenvalue, even though the Hamiltonian is seemingly Hermitian. Second, we introduce the Feshbach formalism, which eliminates the infinite degrees of freedom of the environment and represents its effect as a complex potential. The resulting effective Hamiltonian is explicitly non-Hermitian. By unifying these two ways of defining resonant states, we obtain a new complete set of bases for the scattering problem that contains all discrete eigenstates, including resonant states. We finally mention the non-Markovian dynamics of open quantum systems. We emphasize the time-reversal symmetry of the dynamics that continuously connects the past and the future. We can capture it using the new complete set that we develop here.

</details>


### [189] [Early-stage memory effect on the dephasing charger-mediated quantum battery](https://arxiv.org/abs/2602.14146)
*Yu Wang,Jiasen Jin*

Main category: quant-ph

TL;DR: 研究充电器介导的量子电池性能，发现早期非马尔可夫效应能提高最大功输出，并提出基于量子电路的测量增强方案。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池在非马尔可夫环境下的性能，探索如何利用量子效应提升能量存储和提取效率。

Method: 采用双量子比特系统模型，一个作为电池，一个作为充电器并耦合到热库。推导了含时退相干率的Lindblad形式主方程，并设计了基于量子电路的全局和局域操作测量增强方案。

Result: 发现早期退相干率可为负值，表明存在记忆效应，这种非马尔可夫效应相比马尔可夫近似能提高电池的最大功输出。通过非马尔可夫量子跃迁解释了性能增强机制。

Conclusion: 量子电池的性能可以通过利用非马尔可夫效应得到增强，提出的测量增强方案为量子电池的实际实现提供了新思路。

Abstract: We investigate the performance of the charger-mediated quantum battery modeled by a two-qubit system. One of the qubits acts as the battery and the other acts as the charger which is subjected to a reservoir. We derived the time-local master equation in Lindblad form with a time-dependent dephasing rate. The dephasing rate may be negative in the early-stage of the charging process and thus indicate the presence of the memory effect. We find that such early-stage memory effect could increase the maximal ergotropy of the battery compared with the one under Markovian approximation with the corresponding asymptotic dephase rate. The enhancement of the performance is explained by means of the non-Markovian quantum jumps. Moreover, a discrete time scheme of the measurement-enhanced quantum battery is proposed in a quantum circuit with global and random local operations.

</details>


### [190] [Approximating the $S$ matrix for solving the Marchenko equation: the case of channels with different thresholds](https://arxiv.org/abs/2602.14150)
*N. A. Khokhlov*

Main category: quant-ph

TL;DR: 本文扩展了Marchenko理论框架下的逆散射问题研究，提出了一种将S矩阵近似为有理项加截断sinc级数的方法，并应用于πN散射数据分析。


<details>
  <summary>Details</summary>
Motivation: 扩展Marchenko理论在逆散射问题中的应用，特别是在多通道散射情况下，需要处理部分通道关闭时的S矩阵解析结构问题，以及如何从实验可测的开放通道数据重建完整信息。

Method: 将n通道S矩阵近似为有理项加截断sinc级数的组合，考虑相对论运动学关系，推广Marchenko理论，分析通道关闭时的S矩阵解析结构，从开放通道子矩阵重建关闭通道信息。

Result: 方法收敛性通过已知势场的散射数据验证，重建势场与原始势场一致；成功应用于πN散射数据S31的分析。

Conclusion: 提出的方法能有效处理多通道逆散射问题，特别是在部分通道关闭的情况下，可以从实验可测数据重建完整散射信息，为实际散射数据分析提供了有效工具。

Abstract: This work extends previous results on the inverse scattering problem within the framework of Marchenko theory (fixed-$l$ inversion). In particular, I approximate an $n$-channel $S$-matrix as a function of the first-channel momentum $q$ by a sum of a rational term and a truncated sinc series for each matrix element. Relativistic kinematics are taken into account through the correct momentum-energy relation, and the necessary minor generalization of Marchenko theory is given.
  For energies where only a subset of scattering channels is open, the analytic structure of the $S$-matrix is analyzed. I demonstrate that the submatrix corresponding to closed channels, particularly near their thresholds, can be reconstructed from the experimentally accessible submatrix of open channels.The convergence of the proposed method is verified by applying it to data generated from a direct solution of the scattering problem for a known potential, and comparing the reconstructed potential with the original one. Finally, the method is applied to the analysis of $S_{31}$ $πN$ scattering data.

</details>


### [191] [Bidirectional Quantum Processor Interfacing by a 4-Kelvin Analog Signal Chain for Superconducting Qubit Control and Quantum State Readout](https://arxiv.org/abs/2602.14165)
*Deepak R,Lokendra Kanawat,Jayadeep K,Priyesh Shukla*

Main category: quant-ph

TL;DR: 提出完整的4K低温模拟信号处理架构，用于超导量子比特控制和量子态读取，实现室温数字控制器与毫开尔文量子处理器之间的双向信号传输。


<details>
  <summary>Details</summary>
Motivation: 量子计算需要精确的量子比特控制和读取系统，传统室温系统与低温量子处理器之间存在信号传输挑战，需要开发能在4K低温下工作的完整信号处理架构。

Method: 设计包含控制路径和读取路径的双向信号处理系统：控制路径采用PLL稳定本地振荡器、I/Q调制实现精确量子门操作、低温功率放大器；读取路径包含14dB增益LNA和8-PSK解调器。所有电路采用180nm工艺的低温MOSFET模型，考虑载流子冻结、阈值电压升高和迁移率增强等低温效应，通过SPICE仿真验证。

Result: 仿真结果显示端到端信号完整性良好：I/Q相位误差低于2°，镜像抑制比超过35dB，符号错误率低于10^-6，验证了系统在4K低温下的可行性。

Conclusion: 该工作提供了一个模块化、经过仿真验证的框架，为可扩展的低温量子控制系统奠定了基础，解决了量子计算中信号处理的关键挑战。

Abstract: This paper presents a comprehensive cryogenic analog signal processing architecture designed for superconducting qubit control and quantum state readout operating at 4 Kelvin. The proposed system implements a complete bidirectional signal path bridging room-temperature digital controllers with quantum processors at millikelvin stages. The control path incorporates a Phase-Locked Loop (PLL) for stable local oscillator generation, In-phase/Quadrature (I/Q) modulation for precise qubit gate operations, and a cryogenic power amplifier for signal conditioning. The readout path features a Low Noise Amplifier (LNA) with 14 dB gain and 8-Phase Shift Keying (8-PSK) demodulation for quantum state discrimination. All circuit blocks are designed and validated through SPICE simulations employing cryogenic MOSFET models at 180nm that account for carrier freeze-out, threshold voltage elevation, and enhanced mobility at 4 K. Simulation results demonstrate successful end-to-end signal integrity with I/Q phase error below 2°, image rejection ratio exceeding 35~dB, and symbol error rate below $10^{-6}$. This work provides a modular, simulation-validated framework for scalable cryogenic quantum control systems.

</details>


### [192] [TensorCircuit-NG: A Universal, Composable, and Scalable Platform for Quantum Computing and Quantum Simulation](https://arxiv.org/abs/2602.14167)
*Shi-Xin Zhang,Yu-Qin Chen,Weitang Li,Jiace Sun,Wei-Guo Ma,Pei-Lin Zheng,Yu-Xiang Huang,Qi-Xiang Wang,Hui Yu,Zhuo Li,Xuyang Huang,Zong-Liang Li,Zhou-Quan Wan,Shuo Liu,Jiezhong Qiu,Jiaqi Miao,Zixuan Song,Yuxuan Yan,Kazuki Tsuoka,Pan Zhang,Lei Wang,Heng Fan,Chang-Yu Hsieh,Hong Yao,Tao Xiang*

Main category: quant-ph

TL;DR: TensorCircuit-NG是一个下一代量子软件平台，将量子电路、张量网络和神经网络融合为端到端可微分计算图，基于主流机器学习后端构建，支持分布式计算和多种量子系统模拟。


<details>
  <summary>Details</summary>
Motivation: 传统量子电路模拟器功能有限，无法有效连接量子物理、人工智能和高性能计算。需要建立一个统一的编程范式，将量子电路、张量网络和神经网络融合，以支持更复杂的量子计算应用。

Method: 基于JAX、TensorFlow、PyTorch等工业标准机器学习后端，构建张量原生编程范式。实现近似电路模拟、模拟动力学、费米子高斯态、qudit系统和可扩展噪声建模。采用自动数据并行和模型并行张量网络切片等分布式计算策略。

Result: 在GPU集群上验证了分布式变分量子算法的近线性加速。实现了CIFAR-100计算机视觉的端到端量子机器学习、通过经典阴影从量子态到神经网络的高效管道，以及多体物理中张量网络态的可微分优化等旗舰应用。

Conclusion: TensorCircuit-NG成功建立了连接量子物理、人工智能和高性能计算的统一平台，为复杂量子计算应用提供了强大的软件基础设施，展示了在分布式计算和实际应用中的显著性能提升。

Abstract: We present TensorCircuit-NG, a next-generation quantum software platform designed to bridge the gap between quantum physics, artificial intelligence, and high-performance computing. Moving beyond the scope of traditional circuit simulators, TensorCircuit-NG establishes a unified, tensor-native programming paradigm where quantum circuits, tensor networks, and neural networks fuse into a single, end-to-end differentiable computational graph. Built upon industry-standard machine learning backends (JAX, TensorFlow, PyTorch), the framework introduces comprehensive capabilities for approximate circuit simulation, analog dynamics, fermion Gaussian states, qudit systems, and scalable noise modeling. To tackle the exponential complexity of deep quantum circuits, TensorCircuit-NG implements advanced distributed computing strategies, including automated data parallelism and model-parallel tensor network slicing. We validate these capabilities on GPU clusters, demonstrating a near-linear speedup in distributed variational quantum algorithms. TensorCircuit-NG enables flagship applications, including end-to-end QML for CIFAR-100 computer vision, efficient pipelines from quantum states to neural networks via classical shadows, and differentiable optimization of tensor network states for many-body physics.

</details>


### [193] [Quantum field theory measurements for relativistic particles](https://arxiv.org/abs/2602.14175)
*Nadia Koliopoulou,Charis Anastopoulos,Ntina Savvidou*

Main category: quant-ph

TL;DR: 本文提出基于量子时间概率（QTP）框架的相对论性测量理论，解决了标准非相对论测量模型在量子场论中缺乏相对论原理（局域性、因果性、洛伦兹协变性）的问题，并扩展到具有自旋、极化和内部自由度的实际粒子。


<details>
  <summary>Details</summary>
Motivation: 标准非相对论测量模型无法纳入相对论的基本原理（局域性、因果性、洛伦兹协变性），因此不适用于量子场论环境。现有研究大多关注标量场，而实际粒子具有自旋、极化和内部自由度，这带来了新的概念和操作挑战。

Method: 采用量子时间概率（QTP）框架来处理相对论性测量，并将其应用于电磁场、狄拉克场和具有内部结构的标量场。

Result: 获得了考虑自旋/极化的到达时间概率，推导出超越Glauber理论的广义光电探测公式，明确推导了粒子振荡公式及其局限性，并对相对论性qudit进行了第一性原理分析。

Conclusion: QTP框架为处理具有自旋、极化和内部自由度的相对论性量子场的测量问题提供了系统方法，解决了标准非相对论测量模型的局限性，为量子场论中的测量理论建立了更完整的基础。

Abstract: The formulation of a consistent measurement theory for relativistic quantum fields has become a problem of growing foundational and practical significance. Standard non-relativistic measurement models fail to incorporate the essential relativistic principles of locality, causality, and Lorentz covariance, and are therefore inadequate for quantum field theoretic settings. While most existing work focuses on scalar fields, realistic particles possess spin, polarization, and internal degrees of freedom that introduce new conceptual and operational challenges. To this end, we employ the Quantum Temporal Probabilities (QTP) framework for relativistic measurements to describe electromagnetic, Dirac, and internally structured scalar fields. Our results include probabilities for the time-of-arrival that take spin/polarization into account, generalized photodetection formulas beyond Glauber's theory, an unambiguous derivation of the particle oscillation formula together with its limitations, and a first-principles analysis of relativistic qudits.

</details>


### [194] [Fully integrated quantum frequency processor on a silicon chip](https://arxiv.org/abs/2602.14240)
*Sara Congia,Leopold Virot,Elena Rovetta,Antonio Fincato,Frederic Boeuf,Matteo Galli,Daniele Bajoni,Massimo Borghi*

Main category: quant-ph

TL;DR: 首次实现了完全集成的量子频率处理器，在单个硅光子芯片上集成了量子频率梳源、泵浦抑制滤波器、高速相位调制器和可编程脉冲整形器，实现了高保真度的频率分束器和量子态操控。


<details>
  <summary>Details</summary>
Motivation: 频率编码在光子量子信息处理中具有高维性、门并行性和与现有电信基础设施兼容的优势，但缺乏能够统一量子态生成、相干频率混合和可编程光谱控制的集成平台，阻碍了其可扩展部署。

Method: 在单个4×7mm²硅光子芯片上单片集成了微谐振器双光子量子频率梳源、泵浦抑制滤波器、高速相位调制器和四通道逐行脉冲整形器，实现了完全集成的量子频率处理器。

Result: 实现了成功率超过94%、保真度高于99.9%的可调频率分束器，能够合成更通用的单量子比特门，生成并相干操控高维频率纠缠态，首次在芯片上实现了贝尔态的量子态层析，保真度达95.7(3)%。

Conclusion: 通过将所有关键功能元件集成在同一芯片上，并具备扩展到更多模式的潜力，这项工作标志着向大规模频率域光子处理器（包括经典和量子应用）迈出了重要一步。

Abstract: Frequency-bin encoding has recently emerged as a powerful approach for photonic quantum information processing, offering high dimensionality, gate-parallelization, and compatibility with existing telecommunication infrastructure. However, its scalable deployment has so far been hindered by the lack of an integrated platform capable of unifying quantum state generation, coherent frequency mixing, and programmable spectral control.\\ Here, we report the first fully integrated quantum frequency processor, monolithically integrating on the same silicon photonic chip a microresonator-based biphoton quantum frequency comb source, a pump-rejection filter, high-speed phase modulators, and a four-channel, line-by-line pulse shaper. We demonstrate key functionalities, such as tunable frequency beamsplitters with success probabilities exceeding $94\%$ and fidelities above $99.9\%$, as well as the ability to synthesize more general single-qubit gates. Finally, we generate and coherently manipulate high-dimensional frequency-bin entangled states entirely on chip, showcasing control over two-photon quantum walks and performing the first on-chip frequency-bin quantum state tomography of a Bell-state with a fidelity of $95.7(3)\%$. By integrating all key functional elements on the same $4\times7\,\textrm{mm}^2$ chip, with the possibility of scaling to a larger number of modes, our work marks an important step toward large-scale frequency-domain photonic processors for both classical and quantum applications.

</details>


### [195] [Geometric phase of arbitrary Mueller evolutions and its two-level quantum analogue](https://arxiv.org/abs/2602.14245)
*José J Gil*

Main category: quant-ph

TL;DR: 干涉几何相位仅由Mueller变换的酉部分决定，退相干部分只影响条纹可见度


<details>
  <summary>Details</summary>
Motivation: 研究物理可实现的Mueller变换中几何相位的性质，特别是退极化过程如何影响干涉几何相位

Method: 使用特征分解方法分析Mueller变换，将变换分解为酉部分、判别部分和最大混合部分，研究各部分对几何相位的影响

Result: 几何相位完全由酉部分（SO(3)旋转）决定，退相干部分只降低干涉条纹可见度而不产生几何全息效应

Conclusion: 干涉几何相位对退极化过程具有鲁棒性，仅依赖于系统的酉演化部分，这为量子信息处理中几何相位的应用提供了理论基础

Abstract: We show that, for any physically realizable Mueller transformation -- including arbitrarily depolarizing maps -- the interferometric (Pancharatnam) geometric phase is fixed uniquely by the SO(3) rotation associated with the unitary (retarding) part of the pure characteristic component selected by the characteristic decomposition. All remaining characteristic contributions (discriminant and maximally mixed) can only reduce fringe visibility; they never generate geometric holonomy, even if their pure constituents involve rotations. We further establish the quantum analogue for open two-level dynamics: in the Choi representation of qubit channels, the geometric phase is fixed by the coherent unitary part of the dominant rank-one characteristic component, while the remaining dissipative structure affects visibility only.

</details>


### [196] [RASCqL: Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic](https://arxiv.org/abs/2602.14273)
*Willers Yang,Jason Chadwick,Mariesa H. Teo,Joshua Viszlai,Fred Chong*

Main category: quant-ph

TL;DR: RASCqL是一种针对qLDPC码设计的复杂指令集量子计算机架构，通过代码修改方案嵌入特定复杂Clifford指令，在保持时空效率的同时实现2-7倍的物理资源缩减。


<details>
  <summary>Details</summary>
Motivation: qLDPC码虽然能显著减少量子计算的物理资源需求，但在实用规模下，如果没有高效的指令集架构来支持关键算法子程序，这些优势会被稀释。需要设计一种既能利用qLDPC码资源效率，又能高效执行量子算术、查表、魔法态蒸馏等关键操作的架构。

Method: RASCqL采用应用定制的代码修改方案，将特定复杂Clifford指令作为可虚拟实现的矩阵自同构嵌入到共设计的qLDPC码中。利用中性原子阵列平台的可重构并行物理操作，实现快速量子纠错周期和高保真度横向操作。

Result: 在2×10⁻³到5×10⁻⁴的现实物理错误率下，RASCqL实现了关键算法子程序的时空成本与最先进的横向表面码架构相当，同时获得了2倍到7倍的物理资源缩减，且无需额外的硬件复杂性。

Conclusion: RASCqL为qLDPC码作为复杂指令集量子计算模块提供了一条具体路径，扩展了它们在容错量子计算架构中的实际效用，尽管设计复杂性有所增加。

Abstract: Quantum low-density parity-check (qLDPC) codes offer a promising route to scalable fault-tolerant quantum computing (FTQC) due to their substantially reduced footprint, but these gains can be diluted at utility scale if we cannot also realize a space-time-efficient instruction-set architecture (ISA) for relevant quantum applications. We present RASCqL, a Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic, introducing a complex-instruction-set quantum computer (CISQ) that supports key algorithmic subroutines such as quantum arithmetic, table lookups, and magic-state distillation directly in co-designed qLDPC codes.
  Unlike prior constructions for qLDPC logic that aim at versatile ISAs amenable to diverse circuits, RASCqL adopts an application-tailored code-modification scheme that embeds specific complex Clifford instructions useful for functional subroutines as virtually implementable matrix automorphisms. RASCqL further leverages parallel physical operations in reconfigurable neutral-atom array platforms to achieve fast QEC cycles and high-fidelity transversal operations. At the cost of increased design complexity, RASCqL implements key algorithmic subroutines at space-time costs comparable to state-of-the-art transversal surface-code architectures while achieving up to $2\times$ to $7\times$ footprint reduction under realistic physical error rates of $2 \times 10^{-3}$ to $5 \times 10^{-4}$, without additional hardware complexity. RASCqL thus demonstrates a concrete path forward for qLDPC codes as CISQ compute modules, extending their practical utility in fault-tolerant quantum computing architectures.

</details>


### [197] [Quantum entanglement enhanced via dark mode control in molecular optomechanics](https://arxiv.org/abs/2602.14312)
*E. Kongkui Berinyuy,P. Djorwé,A. N. Al-Ahmadi,H. Ardah,A. -H. Abdel-Aty*

Main category: quant-ph

TL;DR: 提出基于分子腔光力结构的方案，通过打破暗模效应来增强量子双体和三体纠缠，实现高达两倍的纠缠增强并提高抗热噪声能力


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是现代量子技术的重要资源，但多模纠缠的产生受到暗模效应的强烈抑制，需要解决暗模效应对纠缠生成的限制问题

Method: 使用分子腔光力结构，包含两个通过分子间耦合相互作用的分子系综，通过合成规范场方法对振动跳跃率进行相位调制，通过调节分子间耦合及其调制相位来控制暗模的打破

Result: 在暗模打破区域，双体和三体纠缠显著增强（高达两倍），且生成的纠缠在热噪声下更加鲁棒；在暗模未打破区域，纠缠生成显著降低或被抑制

Conclusion: 该方案可作为基准系统来改进量子关联工程，为现代量子技术应用生成抗噪声的量子资源

Abstract: Quantum entanglement is an interesting resource for modern quantum technologies, where generating multiple quantum entanglement is highly required. However, entanglement engineering between multiple modes is strongly suppressed by dark mode effect. Here, we proposed a scheme based on molecular cavity optomechanical structure that enhances quantum bipartite and tripartite entanglement via dark mode breaking. Our proposal consists of an optical cavity that hosts two molecular ensembles which are coupled through an intermolecular coupling. A vibrational hopping rate $J_m$ captures the intermolecular coupling that is phase modulated via the synthetic gauge field method. The breaking of the dark mode is controlled by tuning both the intermolecular coupling and its modulation phase. By adjusting these parameters in our proposal, we can flexibly switch between the Dark Mode Unbroken (DMU) and the Dark Mode Broken (DMB) regimes. We find that in the dark-mode-unbroken regime, the amount of the generated bipartite and tripartite entanglement is significantly low or is suppressed. In contrast, in the dark-mode-broken regime, the entanglement is greatly enhanced,i.e., up to twofold enhancement. Moreover, the generated entanglement is more resilient against thermal noise in the dark-mode-broken regime compared to the thermal robustness in the unbroken regime. Therefore, our proposed scheme serves as a benckmark system to improve quantum correlations engineering, and to generate noise-tolerant quantum resources for applications in numerous modern quantum technologies.

</details>


### [198] [Scalable Clifford-Based Classical Initialization for the Quantum Approximate Optimization Algorithm](https://arxiv.org/abs/2602.14327)
*Dhanvi Bharadwaj,Yuewen Hou,Guang-Yi Li,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: SPIQ框架通过松弛QAOA ansatz实现经典搜索，找到高质量Clifford可制备量子态作为QAOA初始化，显著提升收敛速度和解决方案质量，减少量子电路评估需求。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法（如QAOA）的性能严重依赖初始参数选择，而QAOA ansatz的表达能力有限，使得寻找有效的初始化既困难又不可扩展。

Method: 提出SPIQ框架，使用松弛的QAOA ansatz进行经典搜索，寻找Clifford可制备的高质量量子态作为初始化；引入两种互补策略选择高质量Clifford点并用于多起点优化。

Result: 在QUBO、PUBO和PCBO问题上，相比最先进初始化方法，绝对准确率提升高达80%，初始状态多样性减少高达10,000倍；在真实世界数据集的问题实例上表现出一致且可扩展的改进。

Conclusion: SPIQ框架为QAOA提供了可扩展、应用无关的初始化方法，显著提升性能并降低量子设备成本，通过高质量Clifford点选择和多起点优化进一步增强探索能力和解决方案质量。

Abstract: Variational Quantum Algorithms (VQAs), such as the Quantum Approximate Optimization Algorithm (QAOA), offer a promising route to tackling combinatorial optimization problems on near and intermediate-term quantum devices. However, their performance critically depends on the choice of initial parameters, and the limited expressiveness of the QAOA ansatz makes identifying effective initializations both difficult and unscalable. To address this, we propose a framework, Scalable Parameter Initialization for QAOA (SPIQ), that employs a relaxed QAOA ansatz to enable classical search over a set of Clifford-preparable quantum states that yield high-quality solutions. These states serve as superior QAOA initializations, driving rapid convergence while significantly reducing the quantum circuit evaluations needed to reach high-quality solutions and consequently lowering quantum-device cost. We present a scalable, application-agnostic initialization framework that achieves an absolute accuracy improvement of up to 80% over state-of-the-art initialization and reduces initial-state diversity by up to 10,000x across QUBO, PUBO, and PCBO problems spanning tens to hundreds of qubits. We further benchmark its performance on a wide range of problem formulations and instances derived from real-world datasets, demonstrating consistent and scalable improvements. Furthermore, we introduce two complementary strategies for selecting high-quality Clifford points identified by our search procedure and using them to seed multi-start optimization, thereby enhancing exploration and improving solution quality.

</details>


### [199] [High-fidelity Quantum Readout Processing via an Embedded SNAIL Amplifier](https://arxiv.org/abs/2602.14333)
*Leon Bello,Boris Mesits,Michael Hatridge,Hakan E. Türeci*

Main category: quant-ph

TL;DR: 提出了一种基于SNAIL的超导量子态读取新架构，通过片上非线性元件实现相干、定向的信号处理，提高保真度并简化硬件复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统色散读取架构依赖笨重的隔离器和外部放大器，硬件开销大且限制了片上信息处理的机会，需要可扩展、高保真度的量子态读取方案。

Method: 将非线性SNAIL元件嵌入读取链中，形成可调谐的读取-放大-输出架构，通过工程化耦合实现频率复用谐振器的相互作用，支持片上量子读取数据的原位处理。

Result: 该平台提高了读取保真度，抑制了测量引起的退相干，简化了硬件复杂度，为下一代处理器提供了有前景的可扩展相干量子态读取构建模块。

Conclusion: 混合SNAIL平台是实现可扩展、相干量子态读取的有前景方案，为下一代超导量子处理器的发展提供了重要技术路径。

Abstract: Scalable, high-fidelity quantum-state readout remains a central challenge in the development of large-scale superconducting quantum processors. Conventional dispersive readout architectures depend on bulky isolators and external amplifiers, introducing significant hardware overhead and limiting opportunities for on-chip information processing. In this work, we propose a novel approach that embeds a nonlinear Superconducting Nonlinear Asymmetric Inductive eLement (SNAIL) into the readout chain, enabling coherent and directional processing of readout signals directly on-chip. This embedded SNAIL platform allows frequency-multiplexed resonators to interact through engineered couplings, forming a tunable readout-amplifier-output architecture that can manipulate quantum readout data \textit{in situ}. Through theoretical modeling and numerical optimization, we show that this platform enhances fidelity, suppresses measurement-induced decoherence, and simplifies hardware complexity. These results establish the hybridized SNAIL as a promising building block for scalable and coherent quantum-state readout in next-generation processors.

</details>


### [200] [Fine-Grained Complexity for Quantum Problems from Size-Preserving Circuit-to-Hamiltonian Constructions](https://arxiv.org/abs/2602.14379)
*Nai-Hui Chia,Atsuya Hasegawa,François Le Gall,Yu-Ching Shen*

Main category: quant-ph

TL;DR: 该论文证明了3-local Hamiltonian问题在SETH和QSETH下的精细复杂度下界，并改进了量子配分函数近似算法。


<details>
  <summary>Details</summary>
Motivation: 研究local Hamiltonian问题的计算复杂度下界，探索经典和量子算法在解决该问题时的根本性限制，并为量子配分函数近似提供更优算法。

Method: 引入首个保持规模不变的电路到哈密顿量构造，将T时间量子电路编码到(d+1)-local哈密顿量中，使用N+O(T^{1/d})个量子比特，改进传统的N+O(T)构造。

Result: 证明了在SETH下，3-local Hamiltonian问题无法在O(2^{(1-ε)n})经典时间内解决；在QSETH下，无法在O(2^{(1-ε)n/2})量子时间内解决。同时提供了O(√2^n)时间的量子算法，以任意1/poly(n)相对误差近似量子配分函数。

Conclusion: 该工作为local Hamiltonian问题建立了精细复杂度下界，表明现有算法难以显著改进，并改进了量子配分函数近似算法，在低温区域优于现有最佳算法。

Abstract: The local Hamiltonian (LH) problem is the canonical $\mathsf{QMA}$-complete problem introduced by Kitaev. In this paper, we show its hardness in a very strong sense: we show that the 3-local Hamiltonian problem on $n$ qubits cannot be solved classically in time $O(2^{(1-\varepsilon)n})$ for any $\varepsilon>0$ under the Strong Exponential-Time Hypothesis (SETH), and cannot be solved quantumly in time $O(2^{(1-\varepsilon)n/2})$ for any $\varepsilon>0$ under the Quantum Strong Exponential-Time Hypothesis (QSETH). These lower bounds give evidence that the currently known classical and quantum algorithms for LH cannot be significantly improved.
  Furthermore, we are able to demonstrate fine-grained complexity lower bounds for approximating the quantum partition function (QPF) with an arbitrary constant relative error. Approximating QPF with relative error is known to be equivalent to approximately counting the dimension of the solution subspace of $\mathsf{QMA}$ problems. We show the SETH and QSETH hardness to estimate QPF with constant relative error. We then provide a quantum algorithm that runs in $O(\sqrt{2^n})$ time for an arbitrary $1/\mathrm{poly}(n)$ relative error, matching our lower bounds and improving the state-of-the-art algorithm by Bravyi, Chowdhury, Gosset, and Wocjan (Nature Physics 2022) in the low-temperature regime.
  To prove our fine-grained lower bounds, we introduce the first size-preserving circuit-to-Hamiltonian construction that encodes the computation of a $T$-time quantum circuit acting on $N$ qubits into a $(d+1)$-local Hamiltonian acting on $N+O(T^{1/d})$ qubits. This improves the standard construction based on the unary clock, which uses $N+O(T)$ qubits.

</details>


### [201] [Anonymous quantum sensing robust against state preparation errors](https://arxiv.org/abs/2602.14396)
*Hiroto Kasai,Seiichiro Tani,Yasuhiro Tokura,Yuki Takeuchi*

Main category: quant-ph

TL;DR: 提出了一种抗噪声的匿名量子传感协议，通过结合量子态验证技术来保护生物磁场测量中的位置隐私


<details>
  <summary>Details</summary>
Motivation: 生物磁场测量涉及隐私信息，需要保护非零磁场位置不被窃听者获取。现有匿名量子传感协议在存在状态制备误差时无法正确估计磁场幅度

Method: 设计了一种针对GHZ态和Dicke态叠加态的量子态验证协议，并将其与原始匿名量子传感协议结合。验证协议能高效判断实际态与理想态的保真度高低

Result: 新协议比直接保真度估计更高效，且能抵抗状态制备中的独立噪声，提高了匿名量子传感在现实场景中的性能

Conclusion: 提出的抗噪声匿名量子传感协议能有效保护生物磁场测量中的位置隐私，在存在状态制备误差的现实条件下仍能正常工作

Abstract: Networked quantum sensors have several applications such as the mapping of magnetic fields. When the magnetic fields are biomagnetic ones, i.e., they contain some private information, the information of from who non-zero magnetic fields occur has to be protected from eavesdroppers. Anonymous quantum sensing keeps it secret by estimating amplitudes of the magnetic fields without disclosing the positions of non-zero magnetic fields. In this paper, we propose an anonymous quantum sensing protocol that is robust against any independent noise in state preparations. To this end, we devise a quantum state verification protocol for a superposition of Greenberger-Horne-Zeilinger and Dicke states and combine it with the original protocol of anonymous quantum sensing. Our verification protocol can decide whether the fidelity between the ideal and actual states is high or low more efficiently than the direct fidelity estimation. Since the original protocol of anonymous quantum sensing cannot correctly estimate the amplitudes of the magnetic fields under state preparation errors, our results would improve the performance of anonymous quantum sensing in realistic situations.

</details>


### [202] [The Multiparameter Frontier: Metrological Hierarchy and Robustness in Dispersive Quantum Interferometry](https://arxiv.org/abs/2602.14420)
*Lucas Ferreira R. de Moura,Daniel Y. Akamatsu,G. D. de Moraes Neto,Norton G. de Almeida*

Main category: quant-ph

TL;DR: 提出一种基于非线性马赫-曾德尔干涉仪的热力学参数同时估计协议，通过量子费希尔信息矩阵分析性能，验证了不同量子态在热力学传感中的鲁棒性差异，并在NISQ硬件上实验验证。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时估计温度β和相互作用强度x的量子热力学传感协议，研究不同量子态在实际噪声环境下的鲁棒性，探索NISQ硬件在量子传感基准测试中的应用。

Method: 使用非线性马赫-曾德尔干涉仪耦合热辅助比特，推导量子费希尔信息矩阵的闭式解，分析理想演化及振幅/相位阻尼噪声下的性能，通过费希尔信息敏感性评估不同量子态的鲁棒性，并在IBM量子处理器上实现数字量子电路验证。

Result: 理论分析表明：NOON态具有最大理论灵敏度但对损耗呈指数脆弱；压缩真空态在稳态传感中鲁棒性最佳；猫态在瞬态热力学测量中保持显著相干性。实验验证了预测的费希尔信息分布，同时揭示了噪声引起的系统性偏差。

Conclusion: 该协议实现了热力学参数的同时估计，光子计数达到全局最优且无需自适应反馈。研究揭示了量子态选择在噪声环境下的关键权衡，证明了当前NISQ硬件能够有效基准测试多参数量子传感的基本权衡关系。

Abstract: We present a dispersive quantum thermometry protocol for simultaneous estimation of inverse temperature $β$ and interaction strength $x$ using a nonlinear Mach-Zehnder interferometer coupled to a thermal ancilla. We derive closed-form expressions for the quantum Fisher information matrix, establishing that metrological performance depends solely on the thermal visibility $\mathcal{V}(β)$ and its derivative. The output state remains diagonal in photon-number basis, making photon counting globally optimal and saturating the multiparameter quantum Cramér-Rao bound without adaptive feedback. Moving beyond ideal unitary evolution, we analyze protocol robustness under concurrent amplitude and phase damping. Using Fisher Information Susceptibility, we establish a clear hierarchy: NOON states offer maximal theoretical sensitivity but exhibit exponential fragility to loss, rendering them impractical. Squeezed vacuum states emerge as robust candidates for steady-state sensing, while cat states prove compelling for transient thermometry by retaining significant coherence after photon loss. We validate these predictions through digital quantum circuit implementation on IBM's \texttt{ibm_torino} processor. Experimental results confirm the predicted Fisher information landscape while revealing systematic noise-induced biases, demonstrating that current NISQ hardware can effectively benchmark fundamental trade-offs in multiparameter quantum sensing.

</details>


### [203] [Electron readout contrast enhancement in the parallel nuclear regime of an exchange-coupled donor spin qubit system](https://arxiv.org/abs/2602.14426)
*Holly G. Stemp,Mark R. van Blankenstein,Benjamin Wilhelm,Serwan Asaad,Mateusz T. Mądzik,Arne Laucht,Fay E. Hudson,Andrew S. Dzurak,Kohei M. Itoh,Alexander M. Jakob,Brett C. Johnson,David N. Jamieson,Andrea Morello*

Main category: quant-ph

TL;DR: 硅基施主自旋量子比特系统中，当施主核自旋平行排列时，通过单电子晶体管读取电子自旋的对比度显著增强，这是由于平行核自旋配置下额外的电子隧穿事件导致的。


<details>
  <summary>Details</summary>
Motivation: 解释硅基施主自旋量子比特系统中观察到的现象：当施主核自旋平行排列时，通过Elzerman式单电子晶体管读取电子自旋的对比度显著高于反平行排列的情况，这一现象一直未得到合理解释。

Method: 对平行核自旋配置下的交换耦合施主系统进行详细分析，提出物理机制来解释增强的读取对比度。研究认为这是由于在平行核自旋配置下，单个读取周期内发生了额外的电子隧穿事件。

Result: 成功解释了观察到的现象：平行核自旋配置下读取对比度增强是由于额外的电子隧穿事件。这一发现为改进这些系统中电子读取保真度提供了策略，并有助于更全面地理解施主基量子比特架构中的自旋相关隧穿过程。

Conclusion: 平行核自旋配置下读取对比度的增强机制得到解释，这为优化硅基施主自旋量子比特的读取性能提供了理论基础，并深化了对自旋相关隧穿过程的理解。

Abstract: Recent experiments on donor-based spin qubits in silicon have leveraged the exchange interaction between electrons bound to separate donor nuclei to perform two-qubit operations. A consistently observed yet unexplained phenomenon in such systems is the significant increase in electron readout contrast, measured via Elzerman-style readout to a single-electron transistor (SET) island, when the donor nuclei are initialized in a parallel spin orientation compared to an anti-parallel orientation. In this work, we present a detailed analysis of the exchange-coupled donor system in the parallel nuclear regime and propose a physical mechanism for this effect. We attribute the enhanced readout contrast to an additional electron tunneling event to the SET during a single read period, when the donor nuclei are aligned in a parallel spin configuration. These insights inform strategies for improving electron readout fidelity in these systems and contribute to a more complete understanding of spin-dependent tunnelling processes in donor-based qubit architectures.

</details>


### [204] [Fermionic Stoner-Dicke phase transition in Circuit Quantum Magnetostatics](https://arxiv.org/abs/2602.14437)
*Adel Ali,Alexey Belyanin*

Main category: quant-ph

TL;DR: 提出一个可调谐的费米子-量子磁通耦合多体系统，可解析对角化，展示多种多体现象如Stoner轨道不稳定性和Dicke类量子相变


<details>
  <summary>Details</summary>
Motivation: 传统腔量子电动力学主要研究电场与物质的电偶极耦合，本文探索量子化磁场与粒子角动量的耦合，为研究非线性磁通-物质相和扇区选择性光子修饰提供新平台

Method: 构建LC谐振器量子化磁场与粒子角动量耦合的最小可调多体系统，加入约瑟夫森结探索非线性相，同时考虑无需实际约瑟夫森结的紧束缚系统实现可调非线性

Result: 系统可解析对角化，展示Stoner轨道不稳定性、Dicke类量子相变等丰富多体现象，适用于电路QED和介观环相关领域

Conclusion: 该最小可调系统为研究磁通-物质耦合、非线性量子相变和扇区选择性光子修饰提供了新的理论框架和实验平台

Abstract: We present a minimal tunable many-body system of fermions coupled to quantum magnetic flux, which is analytically diagonalizable and exhibits a variety of many-body phenomena such as Stoner orbital instability and Dicke-like quantum phase transition. In contrast to standard cavity quantum electrodynamics with its electric-dipole coupling of the electric field operators with matter, here it is the quantized magnetic field of an LC-resonator which is coupled to the angular momentum of particles. Adding the Josephson junction (JJ) to the linear LC circuit allows us to explore nonlinear flux-matter phases and sector-selective photon dressing in regimes relevant to circuit QED and mesoscopic rings. Furthermore, we consider the tight-binding systems that exhibit a tunable nonlinearity representing artificial JJ, but without actual JJs included in the circuit.

</details>


### [205] [A hardware-native time-frequency GKP logical qubit toward fault-tolerant photonic operation](https://arxiv.org/abs/2602.14461)
*Tai Hyun Yoon*

Main category: quant-ph

TL;DR: 该论文实现了基于单光子连续相空间的硬件原生时频GKP逻辑量子比特，建立了传播光子实现的玻色子网格编码，为容错光子量子计算提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 动机是开发一种硬件兼容的GKP逻辑量子比特实现方案，利用光子系统的时频自由度进行玻色子网格编码，为基于擦除和融合的容错光子量子架构提供逻辑层支持。

Method: 采用相干驱动的纠缠非线性双光子源产生单光子频率梳超模，生成有限能量网格态；利用光学频率梳参考锚定时频相空间，在硬件层面直接实施对易位移稳定器；通过相位和延迟控制实现确定性状态制备和操作。

Result: 成功实现了硬件原生的时频GKP逻辑量子比特编码，将时序抖动、频谱漂移和相位噪声自然映射到网格内的高斯位移误差，实现了稳定器单元内的固有可校正性。

Conclusion: 该工作建立了基于模态时频GKP框架的具体路径，通过辅助网格态和干涉时频测量实现主动综合征提取和确定性位移恢复，为集成时频GKP逻辑层到容错光子架构提供了硬件兼容的路线。

Abstract: We realize a hardware-native time--frequency Gottesman--Kitaev--Preskill (GKP) logical qubit encoded in the continuous phase space of single photons, establishing a propagating photonic implementation of bosonic grid encoding. Finite-energy grid states are generated deterministically using coherently driven entangled nonlinear biphoton sources that produce single-photon frequency-comb supermodes. An optical-frequency-comb reference anchors the time--frequency phase space and enforces commuting displacement stabilizers directly at the hardware level, continuously defining the logical subspace. Timing jitter, spectral drift, and phase noise map naturally onto Gaussian displacement errors within this lattice, yielding intrinsic correctability inside a stabilizer cell. Logical operations correspond to experimentally accessible phase and delay controls, enabling deterministic state preparation and manipulation. Building on the modal time--frequency GKP framework, we identify a concrete pathway toward active syndrome extraction and deterministic displacement recovery using ancillary grid states and interferometric time--frequency measurements. These primitives establish a hardware-compatible route for integrating the time--frequency GKP logical layer into erasure-aware and fusion-based fault-tolerant photonic architectures.

</details>


### [206] [A lesson from a small particle about quantum theory with strong implications for cosmology](https://arxiv.org/abs/2602.14465)
*Daniel Sudarsky,Octavio Guerrero*

Main category: quant-ph

TL;DR: 论文质疑将量子不确定性解释为实际随机涨落的做法，认为这与中子电偶极矩的强约束相矛盾，需要新的物理概念来协调宇宙结构形成与量子理论的一致性。


<details>
  <summary>Details</summary>
Motivation: 中子电偶极矩的极强约束对强相互作用的时间反演对称性有重要意义，这为重新审视暴胀宇宙学中量子不确定性解释提供了重要启示。当前将量子不确定性等同于实际随机涨落的标准解释存在概念问题。

Method: 通过分析中子电偶极矩的强约束与暴胀宇宙学中量子不确定性解释之间的逻辑矛盾，进行概念性论证和理论分析。

Result: 发现将量子不确定性解释为实际随机涨落的做法与中子电偶极矩的强约束相矛盾，这表明当前宇宙结构形成的物理描述存在概念缺陷。

Conclusion: 需要引入新的物理概念来提供既概念清晰又不与其他量子理论应用相冲突的满意解释，为宇宙结构形成机制开辟新的研究方向。

Abstract: The establishment of extremely strong bounds on the magnitude of the electric dipole moment of the neutron, a quantity that is of great importance for determining the level of time reversal symmetry respected by the strong interactions, offers an important lesson regarding the manner in which quantum uncertainties are interpreted in the inflationary cosmological account of the generation of the primordial inhomogeneities that give rise to the universe's structure. The identification of quantum uncertainties with actual stochastic fluctuations, a standard aspect of the current physical account for the emergence of the cosmic structure, is called into question. This opens the door for novel aspects of physics that are needed in order to provide a satisfactory account that is both conceptually clear and does not conflict with the use of quantum theory in other settings.

</details>


### [207] [Homological origin of transversal implementability of logical diagonal gates in quantum CSS codes](https://arxiv.org/abs/2602.14499)
*Junichi Haruna*

Main category: quant-ph

TL;DR: 本文利用同调理论中的Bockstein同态，完全刻画了CSS码中逻辑对角门的横向实现问题，证明了X稳定子生成元的线性独立性和模2幂交换条件可确保所有离散角度逻辑Pauli Z旋转的横向实现存在。


<details>
  <summary>Details</summary>
Motivation: 横向Pauli Z旋转为量子CSS码提供了实现容错逻辑对角门的自然途径，但其能力受到根本限制。本文旨在系统研究如何通过更精细的离散旋转角度来实现逻辑对角门的横向实现问题。

Method: 采用同调理论方法，将逻辑对角门的横向实现问题表述为细化问题，并证明其可解性完全由同调理论中的Bockstein同态刻画。通过分析X稳定子生成元的线性独立性和模2幂交换条件，建立了横向实现的存在性判据。

Result: 证明了逻辑对角门横向实现的可解性完全由Bockstein同态表征。发现X稳定子生成元的线性独立性与模2幂交换条件共同确保了所有离散角度逻辑Pauli Z旋转在一般CSS码中的横向实现存在。

Conclusion: 研究结果识别了控制横向可实现性的典型同调障碍，为量子纠错中横向结构的正式理论提供了概念基础，深化了对CSS码中逻辑门实现机制的理解。

Abstract: Transversal Pauli Z rotations provide a natural route to fault-tolerant logical diagonal gates in quantum CSS codes, yet their capability is fundamentally constrained. In this work, we formulate the refinement problem of realizing a logical diagonal gate by a transversal implementation with a finer discrete rotation angle and show that its solvability is completely characterized by the Bockstein homomorphism in homology theory. Furthermore, we prove that the linear independence of the X-stabilizer generators together with the commutativity condition modulo a power of two ensures the existence of transversal implementations of all logical Pauli Z rotations with discrete angles in general CSS codes. Our results identify a canonical homological obstruction governing transversal implementability and provide a conceptual foundation for a formal theory of transversal structures in quantum error correction.

</details>


### [208] [Bell-like States in Classical Optics: A Process-Theoretic and Sheaf-Theoretic (Categorical) Clarification](https://arxiv.org/abs/2602.14508)
*Partha Ghose*

Main category: quant-ph

TL;DR: 该论文展示了经典偏振光学系统可以产生量子强度的贝尔-克劳瑟-霍恩-希莫尼（Bell-CHSH）关联，并提供了可调谐的低成本测试平台来研究贝尔不等式和上下文性，同时通过范畴论框架将制备过程形式化。


<details>
  <summary>Details</summary>
Motivation: 研究经典光学系统是否能够模拟量子关联行为，探索经典与量子边界，并为贝尔不等式和上下文性测试提供低成本、可调谐的实验平台。

Method: 使用统计光学场和两光束偏振态，在操作主义框架下（不假设检测前结果已预定），通过哈达玛样分裂、CNOT样耦合和路由/条件化等制备过程，构建可产生贝尔-CHSH关联的经典系统。同时提出基于外部锥形折射的替代制备方案，并使用范畴论（CPM(FHilb)）对整个过程进行形式化描述。

Result: 经典偏振光学系统可以产生量子强度的贝尔-CHSH关联，为研究贝尔不等式和上下文性提供了可调谐、低成本的测试平台。通过范畴论框架成功分离了运动学不可分离性与操作上下文性，并澄清了这两者单独都不能导致非局域因果性。

Conclusion: 上下文性可以在经典可实现的随机光学体系中产生，经典系统能够模拟量子关联行为，这为理解经典与量子边界以及研究贝尔不等式和上下文性提供了新的视角和实验工具。

Abstract: Classical polarization optics is naturally described by a two-dimensional complex Hilbert space (Jones vectors), so the tensor-product kinematics underlying bipartite nonseparability is already available classically. For statistical (stochastic) optical fields, and under an operational stance where outcomes are not assumed pre-assigned prior to detection, suitably prepared two-beam polarization states can exhibit Bell--CHSH correlations of quantum strength. The same platform offers a tunable, low-cost testbed for stress-testing Bell/CHSH and contextuality witnesses under realistic imperfections (noise, coarse binning, selective sampling). We also outline an alternative preparation based on external conical refraction (ECR), where engineered intersecting conical-refraction rings mimic the intersecting emission cones of SPDC. We give a self-contained categorical formulation: the preparation-and-conditioning pipeline (Hadamard-like splitting, CNOT-like coupling, and routing/conditioning that removes unwanted contributions) is treated as a single morphism in an operational process theory (e.g. $\mathbf{CPM}(\mathbf{FHilb})$). From it we functorially extract an empirical model, i.e. a compatible family of context-indexed probability distributions. The Abramsky--Brandenburger sheaf criterion then applies: noncontextuality is the existence of a global section, and CHSH violation is a precise failure-to-glue. This separates kinematic nonseparability from operational contextuality and clarifies why neither, by itself, entails nonlocal causation; contextuality can arise in a classically implementable stochastic-optics regime.

</details>


### [209] [Forked Physics Informed Neural Networks for Coupled Systems of Differential equations](https://arxiv.org/abs/2602.14554)
*Zhao-Wei Wang,Zhao-Ming Wang*

Main category: quant-ph

TL;DR: 提出Forked PINN (FPINN)框架解决耦合微分方程系统，通过共享基础网络和独立分支隔离梯度路径，并引入演化正则化损失避免局部最优，成功应用于非马尔可夫开放量子动力学模拟。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在处理耦合微分方程系统时面临多目标优化冲突和局部最优陷阱问题，特别是在非马尔可夫开放量子动力学等复杂系统中，这些问题导致训练停滞和物理意义缺失。

Method: 提出Forked PINN (FPINN)框架：1）共享基础网络提取共同特征；2）独立分支网络隔离梯度路径，稳定训练；3）引入演化正则化损失，引导模型远离平凡解，确保物理演化有意义。

Result: 在spin-boson和XXZ模型中，FPINN准确捕捉了量子相干性恢复和信息回流等非马尔可夫特征，显著优于标准PINN，证明了框架在耦合系统求解中的有效性。

Conclusion: FPINN为解决从经典物理到现代人工智能中广泛存在的耦合方程系统提供了通用有效框架，具有在旋转动力学、投资组合优化、化学反应动力学和深度表示学习等领域的应用潜力。

Abstract: Solving coupled systems of differential equations (DEs) is a central problem across scientific computing. While Physics Informed Neural Networks (PINNs) offer a promising, mesh-free approach, their standard architectures struggle with the multi-objective optimization conflicts and local optima traps inherent in coupled problems. To address the first issue, we propose a Forked PINN (FPINN) framework designed for coupled systems of DEs. FPINN employs a shared base network with independent branches, isolating gradient pathways to stabilize training. We demonstrate the effectiveness of FPINN in simulating non-Markovian open quantum dynamics governed by coupled DEs, where multi-objective conflicts and local optima traps often cause evolutionary stagnation. To overcome this second challenge, we incorporate an evolution regularization loss that guides the model away from trivial solutions and ensures physically meaningful evolution. We demonstrate the effectiveness of FPINN in simulating non-Markovian open quantum dynamics governed by coupled DEs, where multi-objective conflicts and local optima traps often cause evolutionary stagnation. For the spin-boson and XXZ models, FPINN accurately captures hallmark non-Markovian features, such as quantum coherence revival and information backflow, significantly outperforming standard PINNs. The proposed FPINN architecture offers a general and effective framework for solving coupled systems of equations, which arise across a broad spectrum from classical physics to modern artificial intelligence, including applications in multi-body rotational dynamics, multi-asset portfolio optimization, chemical reaction kinetics, and deep representation learning.

</details>


### [210] [Effective Caldirola-Kanai Model for Accelerating Twisted Dirac States in Nonuniform Axial Fields](https://arxiv.org/abs/2602.14555)
*N. V. Filina,S. S. Baturin*

Main category: quant-ph

TL;DR: 研究相对论性扭曲（轨道角动量）态在轴向对称、纵向不均匀螺线管场和同向加速/减速电场中的传播，通过狄拉克方程推导出有效非定态薛定谔方程，利用Ermakov映射获得闭式传播解。


<details>
  <summary>Details</summary>
Motivation: 研究带电粒子在复杂电磁场（轴向对称不均匀螺线管场和同向电场）中的轨道角动量态传播，建立统一理论框架连接现有加速和聚焦模型。

Method: 从狄拉克方程出发，采用受控无自旋和傍轴近似，推导出横向包络满足Caldirola-Kanai哈密顿量支配的有效非定态薛定谔方程。利用Ermakov映射（Caldirola-Kanai系统的幺正等价性），通过变换定态朗道基获得闭式传播扭曲波函数。

Result: 横向演化由单一标度函数b(z)控制，该函数满足广义Ermakov-Pinney方程，系数由Ez(z)和Bz(z)决定。在均匀加速（Bz=0）和螺线管聚焦（加速度可忽略）极限情况下，解简化为已知解析结果。

Conclusion: 建立了带电粒子扭曲态在复杂电磁场中传播的统一理论框架，通过Ermakov映射获得闭式解，为连接加速和聚焦模型提供了直接桥梁，扩展了相对论性轨道角动量态的理论描述。

Abstract: We study relativistic twisted (orbital-angular-momentum) states of a massive charged particle propagating through an axially symmetric, longitudinally inhomogeneous solenoid field and a co-directed accelerating or decelerating electric field. Starting from the Dirac equation and using controlled spinless and paraxial approximations, we show that the transverse envelope obeys an effective nonstationary Schrödinger equation governed by a Caldirola--Kanai Hamiltonian. The longitudinal energy gain or loss encoded in $f(z)=[E_0-V(z)]^2-m^2$ generates an effective gain or damping rate $\widetildeγ(z)=\partial_z f(z)/[2f(z)]$ and a $z$-dependent oscillator frequency $\widetildeω(z)=p_0Ω(z)/\sqrt{f(z)}$. Exploiting the Ermakov mapping (unitary equivalence of Caldirola--Kanai systems), we obtain a closed-form propagated twisted wave function by transforming the stationary Landau basis. The transverse evolution is controlled by a single scaling function $b(z)$ that satisfies a generalized Ermakov--Pinney equation with coefficients determined by $E_z(z)$ and $B_z(z)$. In the limiting cases of uniform acceleration with $B_z=0$ and of solenoid focusing with negligible acceleration, our solution reduces to previously known analytic results, providing a direct bridge to established models.

</details>


### [211] [Sparse identification of quantum Hamiltonian dynamics via quantum circuit learning](https://arxiv.org/abs/2602.14556)
*Yusei Tateyama,Yuzuru Kato*

Main category: quant-ph

TL;DR: 提出SIQHDy框架，将稀疏识别非线性动力学(SINDy)思想应用于量子系统，通过稀疏优化从测量数据中学习量子哈密顿量动力学。


<details>
  <summary>Details</summary>
Motivation: 经典SINDy方法在非线性动力学识别中表现良好，但量子系统动力学识别面临挑战。需要开发能从量子测量时间序列数据中稀疏识别哈密顿量动力学的方法。

Method: 将量子系统的幺正演化表示为基量子电路的乘积，通过稀疏促进优化估计电路参数。扩展方法处理可观测受限场景，并用于网络结构识别。

Result: 数值实验表明SIQHDy能准确重构单自旋、三自旋和五自旋系统的动力学，对测量噪声具有鲁棒性。在可观测受限情况下能识别两自旋系统，并能识别五自旋系统的网络结构。

Conclusion: SIQHDy是SINDy在量子领域的有效扩展，能从测量数据中稀疏识别量子哈密顿量动力学，具有噪声鲁棒性，并能处理可观测受限和网络结构识别问题。

Abstract: Sparse identification of nonlinear dynamics (SINDy) is a data-driven framework for estimating classical nonlinear dynamical systems from time-series data. In this approach, system dynamics is represented as a linear combination of a predefined set of basis functions, and the corresponding coefficients are sparsely estimated from observed time-series data. In this study, we propose sparse identification of quantum Hamiltonian dynamics (SIQHDy), a SINDy-inspired quantum circuit learning framework for estimating quantum Hamiltonian dynamics from time-series data of quantum measurement outcomes. In SIQHDy, the unitary evolution of a quantum Hamiltonian system is expressed as a product of basis quantum circuits, and the corresponding circuit parameters are estimated through sparsity-promoting optimization. We numerically demonstrate that SIQHDy accurately reconstructs the dynamics of single-, three-, and five-spin systems, and exhibits robustness to measurement noise in the three-spin case. Furthermore, we propose an extension of SIQHDy for scenarios with limited accessible observables and evaluate its performance in identifying two-spin systems and in network-structure identification for five-spin systems.

</details>


### [212] [Dissipative Spectroscopy](https://arxiv.org/abs/2602.14557)
*Xudong He,Yu Chen*

Main category: quant-ph

TL;DR: 提出耗散谱学框架，通过受控耗散从量子系统中提取谱信息，可探测平衡性质并预测非平衡耗散动力学


<details>
  <summary>Details</summary>
Motivation: 传统方法在准粒子主导区域可能被视为平凡，需要新框架来提取量子系统的谱信息，特别是量子临界点附近的软模特征

Method: 建立适用于马尔可夫和非马尔可夫环境的耗散响应理论，通过驱动振荡-耗散共振协议获取耗散谱，引入扩展耗散磁化率捕捉主要记忆效应

Result: 耗散谱能识别量子临界点附近的两粒子软模，在正常相侧预测耗散淬火后宏观序参量的幂律增长，在耗散费米子模型中验证了扩展耗散磁化率的实用性

Conclusion: 耗散谱学框架易于实现，为探测量子系统平衡性质和非平衡耗散动力学提供了通用工具，在传统认为平凡的区域揭示了重要物理特征

Abstract: We introduce dissipative spectroscopy as a framework for extracting spectral information from quantum systems via controlled dissipation. By establishing a general dissipative response theory applicable to both Markovian and non-Markovian environments, we develop a protocol to access the dissipative spectrum (DS) through driven oscillation-dissipation resonance. We show that the DS can identify two-particle soft modes near quantum critical points and, on the normal-phase side, predict the emergence of macroscopic order exhibiting power-law growth following a dissipation quench. These distinctive signatures appear in quasiparticle-dominant regimes, previously considered trivial. Furthermore, we introduce extended dissipative susceptibilities that capture leading memory effects and demonstrate their utility in a dissipative fermionic model. Our results indicate that the DS is readily accessible and offers a versatile tool for probing equilibrium properties as well as predicting nonequilibrium dissipative dynamics.

</details>


### [213] [Quantum-Assisted Trainable-Embedding Physics-Informed Neural Networks for Parabolic PDEs](https://arxiv.org/abs/2602.14596)
*Ban Q. Tran,Nahid Binandeh Dehaghani,Rafal Wisniewski,Susan Mengel,A. Pedro Aguiar*

Main category: quant-ph

TL;DR: 该论文研究了量子辅助物理信息神经网络（PINNs）中可训练嵌入策略，用于求解抛物型偏微分方程，提出了两种量子辅助架构并比较了它们的性能。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习的最新进展促使了混合量子-经典扩展，旨在增强表示能力同时保持与近期量子硬件的兼容性。研究者希望探索量子辅助PINNs在求解抛物型PDEs中的可训练嵌入策略。

Method: 提出了两种量子辅助架构：1）FNN-TE-QPINN：使用经典前馈神经网络生成可训练特征映射用于量子数据编码；2）QNN-TE-QPINN：嵌入阶段完全由参数化量子电路实现，产生完全量子特征映射。以一维和二维热方程作为基准测试。

Result: 研究结果强调了嵌入设计的关键作用，并支持在NISQ时代使用混合量子-经典方法进行抛物型PDE建模。

Conclusion: 量子辅助PINNs为求解抛物型PDEs提供了有前景的框架，嵌入设计对性能至关重要，混合量子-经典方法在NISQ时代具有实际应用价值。

Abstract: Physics-informed neural networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding governing physical laws directly into the training objective. Recent advances in quantum machine learning have motivated hybrid quantum-classical extensions aimed at enhancing representational capacity while remaining compatible with near-term quantum hardware. In this work, we investigate trainable embedding strategies within quantum-assisted PINNs for solving parabolic PDEs, using one- and two-dimensional heat equations as canonical benchmarks. We introduce two quantum-assisted architectures that differ in their embedding components. In the first approach, a classical feed-forward neural network generates trainable feature maps for quantum data encoding (FNN-TE-QPINN). In the second, the embedding stage is realized entirely by a parameterized quantum circuit (QNN-TE-QPINN), yielding a fully quantum feature map. Our findings emphasize the critical role of embedding design and support hybrid quantum-classical approaches for parabolic PDE modeling in the NISQ era.

</details>


### [214] [On the challenge of simulating dipolar contributions to spin relaxation with generalized cluster correlation expansion methods](https://arxiv.org/abs/2602.14613)
*Conor Ryan,Alessandro Lunghi*

Main category: quant-ph

TL;DR: gCCE方法在标准形式下无法准确描述自旋-自旋弛豫，需要理论改进


<details>
  <summary>Details</summary>
Motivation: 传统观点认为低温下自旋-自旋偶极相互作用主要导致纯退相，忽略了其对弛豫的贡献，需要全面理解低温自旋动力学

Method: 分析广义簇关联展开(gCCE)方法，该方法通过显式包含中心自旋自由度来模拟能量从中心自旋向浴的转移

Result: 标准形式的gCCE无法提供自旋-自旋弛豫的定性准确描述，理论分析揭示了其失效根源

Conclusion: gCCE方法需要理论改进才能有效研究自旋-自旋弛豫，本文的理论解构为未来解决这一问题提供了起点

Abstract: The study of spin decoherence is often performed by assuming that spin-phonon interactions lead to relaxation at high temperatures, and spin-spin dipolar interactions instead contribute to pure dephasing at low temperatures. This has resulted in the neglect of spin relaxation due to spin-spin dipolar interactions and its influence on decoherence at low temperatures. For a complete understanding of low temperature spin dynamics, it is then imperative to focus also on the latter mechanism. One such method which has shown great promise in the efficient calculation of central spin dynamics due to spin-spin dipolar interactions with a surrounding spin bath is the Cluster-Correlation Expansion (CCE). An extension of this method through the explicit inclusion of the central spin degrees of freedom, known as the generalized Cluster-Correlation Expansion (gCCE) is capable of simulating the transfer of energy from the central spin into the bath, and thus could have the potential to investigate spin relaxation in this setting. In this work, we show that gCCE, in its standard form, is insufficient for providing even a qualitatively accurate description of spin-spin relaxation. A full mathematical deconstruction of the underlying theory of gCCE clearly points to the origin of such a breakdown and provides a starting point for its potential future resolution.

</details>


### [215] [Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset](https://arxiv.org/abs/2602.14641)
*Luke Antoncich,Yuben Moodley,Ugo Varetto,Jingbo Wang,Jonathan Wurtz,Jing Chen,Pascal Jahan Elahi,Casey R. Myers*

Main category: quant-ph

TL;DR: 量子储层计算在生物标志物预测中表现与传统方法相当，但硬件执行比无噪声模拟具有更好的正则化效果和测试准确性


<details>
  <summary>Details</summary>
Motivation: 生物标志物预测面临非线性关系、特征相关性和数据集规模有限等挑战，传统机器学习方法在这些条件下表现不佳，需要探索量子计算等替代方案

Method: 使用量子储层计算（QRC），包括无噪声模拟和中性原子Rydberg处理器Aquila的硬件执行，与6种经典机器学习模型比较，使用SHAP生成特征子集

Result: 模拟量子特征训练的模型测试准确率与经典特征相当，但训练准确率更高且数据分割间变异性更大，出现过拟合；硬件执行比模拟更稳健，测试准确率有统计显著提升，表现出正则化效应

Conclusion: 硬件执行通过结构化、时间依赖的变换（向均值压缩和互信息逐步减少）产生正则化效果，提高了量子储层计算在生物标志物预测中的稳健性和准确性

Abstract: Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation.

</details>


### [216] [Exploiting the path-integral radius of gyration in open quantum dynamics](https://arxiv.org/abs/2602.14647)
*Andrew C. Hunt,Stuart C. Althorpe*

Main category: quant-ph

TL;DR: 该论文提出了一种改进的HEOM方法，通过分析量子浴模式的虚时费曼路径的转动半径平方，开发了更高效的低温计算方案。


<details>
  <summary>Details</summary>
Motivation: 开放量子动力学中，包含Matsubara衰减项是一个主要挑战，这些项源于量子玻尔兹曼分布导致的浴模式离域。传统HEOM方法在处理这些项时存在效率问题，特别是在低温条件下。

Method: 1. 分析浴模式虚时费曼路径的转动半径平方函数；2. 将Ishizaki-Tanimura修正重新解释为平滑项与"布朗"项的分离；3. 开发"A4"算法（Adaptive Antoulas--Anderson的改进版），将转动半径平方函数拟合为极点之和；4. 针对快速浴情况优化HEOM实现。

Result: 1. 证明了Ishizaki-Tanimura修正等价于分离转动半径平方函数的平滑项和布朗项；2. 修改后的修正方法在快速浴情况下能实现更高效的HEOM计算；3. A4算法能有效拟合转动半径平方函数，实现了标准HEOM方法在低温下的极高效实现。

Conclusion: 通过重新解释和优化现有修正方法，并结合新的数值拟合算法，显著提高了HEOM方法在开放量子动力学计算中的效率，特别是在低温条件下，为解决Matsubara衰减项的计算挑战提供了有效方案。

Abstract: A major challenge in open quantum dynamics is the inclusion of Matsubara-decay terms in the memory kernel, which arise from the quantum-Boltzmann delocalisation of the bath modes. This delocalisation can be quantified by the radius of gyration squared ${\mathcal R}^2(ω)$ of the imaginary-time Feynman paths of the bath modes as a function of the frequency $ω$. In a Hierarchical Equations of Motion (HEOM) calculation with a Debye--Drude spectral density, ${\mathcal R}^2(ω)$ is the only quantity that is treated approximately (assuming convergence with respect to hierarchy depth). Here, we show that the well-known Ishizaki--Tanimura correction is equivalent to separating smooth from `Brownian' contributions to ${\mathcal R}^2(ω)$, and that modifying the correction leads to a more efficient HEOM in the case of fast baths. We also develop a simple `A4' adaptation of the `AAA' (Adaptive Antoulas--Anderson) algorithm in order to fit ${\mathcal R}^2(ω)$ to a sum over poles, which results in an extremely efficient implementation of the standard HEOM method at low temperatures.

</details>


### [217] [Geometric Visualizations of Quantum Mixed States and Density Matrices](https://arxiv.org/abs/2602.14661)
*Athanasios Kostikas,Yaroslav Valchyshen,Paul Cadden-Zimansky*

Main category: quant-ph

TL;DR: 该论文介绍了一种量子态的几何表示方法，将纯态和混合态映射到欧几里得空间中的唯一点，从qubit的Bloch球面扩展到任意有限维qudit态，旨在帮助读者发展对这些空间的视觉直觉。


<details>
  <summary>Details</summary>
Motivation: 量子力学的代数形式主义对学习者来说可能抽象难懂，需要一种几何表示方法来提供直观理解。现有的Bloch球面表示虽然常用，但其许多特性未被充分认识，且需要扩展到更高维度和无限维情况。

Method: 从qubit的Bloch球面表示出发，分析其被忽视的特性，然后将这些几何概念扩展到任意有限维qudit态，最终推广到无限维极限。强调基无关的态表示，并展示概率幅和密度矩阵元素如何对应几何表示中的线段和角度。

Result: 建立了从qubit到任意维qudit态再到无限维极限的统一几何表示框架，能够可视化叠加、混合、退相干和测量等概念，并可用简单的几何计算替代繁琐的线性代数运算。

Conclusion: 几何表示为量子态提供了直观的视觉理解工具，特别适合初学者学习混合态和密度矩阵，并能解释纯度等常用度量的几何意义，将有限维qudit空间作为无限维空间的子空间包含其中。

Abstract: This paper presents an introduction to geometric representations of quantum states in which each distinct quantum state, pure and mixed, corresponds to a unique point in a Euclidean space. Beginning with a review of some underappreciated properties of the most commonly used geometric representation, the Bloch sphere visualization of qubit states, we show how concepts, algorithms, and spatial relations viewable on this geometric representation can be extended to representations of qudit states of any finite quantum dimension $d$ and on to the infinite-dimensional limit. A primary goal of the work is helping the reader develop a visual intuition of these spaces, which can complement the understanding of the algebraic formalism of quantum mechanics for learners, teachers, and researchers at any level. Particular emphasis is given both to understanding states in a basis-independent way and to understanding how probability amplitudes and density matrix elements used to algebraically represent states in a particular basis correspond to line segments and angles in the geometric representations. In addition to providing visualizations for such concepts as superpositions, mixtures, decoherence, and measurement, we demonstrate how the representations can be used to substitute simple geometrical calculations for more cumbersome linear algebra ones, which may be of particular use in introducing mixed states and density matrices to beginning quantum students at an early stage. The work concludes with the geometrical interpretation of some commonly used metrics such as the purity of states and their relation to real, Euclidean vectors in the infinite-dimensional limit of the space, which contains all lower-dimensional qudit spaces as subspaces.

</details>


### [218] [Kernel-based optimization of measurement operators for quantum reservoir computers](https://arxiv.org/abs/2602.14677)
*Markus Gross,Hans-Martin Rieser*

Main category: quant-ph

TL;DR: 该论文提出了一种基于核岭回归框架的量子储层计算机最优测量算子训练方法，适用于无状态（QELM）和有状态（memory dependent）QRC，能最小化预测误差并提高多量子比特系统的效率。


<details>
  <summary>Details</summary>
Motivation: 量子储层计算机（QRCs）使用固定的量子特征映射，因此寻找最优测量算子对性能至关重要。传统QRC训练方法在大规模量子比特系统中效率较低，需要更有效的训练方法。

Method: 在核岭回归框架中制定QRC训练，推导出最小化预测误差的最优测量算子。提出实现策略包括Pauli基分解和算子对角化，以适应硬件约束。该方法适用于量子极端学习机（QELM）和具有记忆依赖性的QRC。

Result: 数值实验在图像分类和时间序列预测任务上证明了该方法的有效性。对于大量量子比特，该方法比传统QRC训练更高效，并可应用于其他量子机器学习模型。

Conclusion: 基于核岭回归的QRC训练方法能够有效找到最优测量算子，提高预测性能，并为硬件实现提供了实用策略，对量子机器学习模型具有广泛适用性。

Abstract: Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models.

</details>


### [219] [NISQ-compatible quantum cryptography based on Parrondo dynamics in discrete-time quantum walks](https://arxiv.org/abs/2602.14678)
*Aditi Rath,Dinesh Kumar Panda,Colin Benjamin*

Main category: quant-ph

TL;DR: 该论文提出了一种基于离散时间量子行走的量子密码方案，专门针对NISQ设备设计，通过数值模拟和实际硬件测试验证了协议的安全性和可行性。


<details>
  <summary>Details</summary>
Motivation: 当前NISQ设备存在噪声和规模限制，需要开发与之兼容的量子密码协议。研究旨在设计一种基于量子行走的密码方案，能够在实际NISQ硬件上实现安全通信。

Method: 利用离散时间量子行走在循环图上的Parrondo动力学（混沌硬币算符序列产生周期性演化），构建专门针对NISQ架构的量子电路实现。使用Qiskit进行数值模拟，分析理想和噪声条件下的性能，通过概率分布、Hellinger保真度和总变差距离量化性能。在电路层面建模拦截重发和中间人攻击，评估量子比特错误率。

Result: 协议在无攻击时能可靠恢复消息，而窃听会破坏周期性重构机制。在ibm_torino等NISQ处理器上的硬件测试表明，空间分离的逻辑模块间通信会增加电路深度（通过SWAP操作），导致累积噪声效应。混合状态传输策略显示，量子比特选择和连接性对保真度和协议性能起决定性作用。

Conclusion: 该研究证明了基于量子行走的密码协议在NISQ设备上的可行性，但硬件依赖性（量子比特连接性、状态传输策略）对性能有显著影响，需要在实现中权衡这些因素。

Abstract: Compatibility with noisy intermediate-scale quantum (NISQ) devices is crucial for the realistic implementation of quantum cryptographic protocols. We investigate a cryptographic scheme based on discrete-time quantum walks (DTQWs) on cyclic graphs that exploits Parrondo dynamics, wherein periodic evolution emerges from a deterministic sequence of individually chaotic coin operators. We construct an explicit quantum circuit realization tailored to NISQ architectures and analyze its performance through numerical simulations in Qiskit under both ideal and noisy conditions. Protocol performance is quantified using probability distributions, Hellinger fidelity, and total variation distance. To assess security at the circuit level, we model intercept-resend and man-in-the-middle attacks and evaluate the resulting quantum bit error rate. In the absence of adversarial intervention, the protocol enables reliable message recovery, whereas eavesdropping induces characteristic disturbances that disrupt the periodic reconstruction mechanism. We further examine hardware feasibility on contemporary NISQ processors, specifically $ibm\_torino$, incorporating qubit connectivity and state-transfer constraints into the circuit design. Our analysis demonstrates that communication between spatially separated logical modules increases circuit depth via SWAP operations, leading to cumulative noise effects. By exploring hybrid state-transfer strategies, we show that qubit selection and connectivity play a decisive role in determining fidelity and overall protocol performance, highlighting hardware-dependent trade-offs in NISQ implementations.

</details>


### [220] [Enhanced multiparameter quantum estimation in cavity magnomechanics via a coherent feedback loop](https://arxiv.org/abs/2602.14688)
*Adnan Naimy,Abdallah Slaoui,Abderrahim Lakhfif,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 提出一种在混合腔磁振子机械平台中，利用相干反馈回路和相干驱动场增强光子-磁振子和磁振子-机械耦合强度同时量子估计的方案，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 多参数量子计量在揭示和利用量子系统独特特性方面具有重要作用。当前需要有效且实验可行的方案来增强混合腔磁振子机械平台中耦合强度的同时估计精度。

Method: 采用相干反馈回路结合相干驱动场注入的方法，通过适当调节系统和反馈参数来降低估计误差。使用量子Cramér-Rao界作为多参数估计的基本基准，分别计算基于对称对数导数和右对数导数的QCRB。

Result: RLD基QCRB系统性地低于SLD基边界，表明在非对易估计场景中具有更优的估计精度。外差检测在合适参数区域下，其经典估计精度能接近方案预测的最终量子极限。

Conclusion: 所提方案在当前可用的腔磁振子机械平台中具有实验可行性，且该框架可推广到其他混合量子系统中物理参数的高精度估计。

Abstract: Multiparameter quantum metrology plays a fundamental role in uncovering and exploiting the distinctive features of quantum systems. In this work, we propose an effective and experimentally feasible scheme to significantly enhance the simultaneous quantum estimation of the photon magnon and magnon mechanical coupling strengths in a hybrid cavity magnon mechanical platform. Our approach relies on the assistance of a coherent feedback loop combined with the injection of a coherent driving field. We show that an appropriate tuning of the system and feedback parameters leads to a substantial reduction of the estimation errors associated with both coupling strengths. To quantify the metrological performance of the proposed scheme, we employ the quantum Cramer Rao bound (QCRB) as a fundamental benchmark for multiparameter estimation. We explicitly compute and compare the QCRBs derived from the symmetric logarithmic derivative (SLD) and the right logarithmic derivative (RLD) formalisms. Our results demonstrate that the RLD based QCRB is systematically lower than the SLD based bound, indicating superior estimation precision in the considered noncommutative estimation scenario. We further analyze the performance of heterodyne detection and show that, in suitable parameter regimes, the corresponding classical estimation precision closely approaches the ultimate quantum limit predicted by our scheme. Finally, we discuss the experimental feasibility of the proposed setup within currently available cavity magnon mechanical platforms. Owing to its general character, the framework developed here can be readily extended to the high precision estimation of other physical parameters in hybrid quantum systems.

</details>


### [221] [Demonstrating and Benchmarking Classical Shadows for Lindblad Tomography](https://arxiv.org/abs/2602.14694)
*Rune Thinggaard Birke,Johann Bock Severin,Malthe A. Marciniak,Emil Hogedal,Andreas Nylander,Irshad Ahmad,Amr Osman,Janka Biznárová,Marcus Rommel,Anita Fadavi Roudsari,Jonas Bylander,Giovanna Tancredi,Daniel Stilck França,Albert Werner,Christopher W. Warren,Jacob Hastrup,Svend Krøjer,Morten Kjaergaard*

Main category: quant-ph

TL;DR: 实验验证了随机化阴影测量加速超导量子处理器上的Lindblad动力学断层扫描，相比传统方法显著减少资源消耗


<details>
  <summary>Details</summary>
Motivation: 固态量子处理器中的虚假耦合和退相干会降低性能，需要精确表征。传统的Lindblad动力学断层扫描方法随量子比特数量呈指数级扩展，资源消耗巨大

Method: 提出并实验实现了两种方法：1) 可扩展Lindblad断层扫描（传统完整断层扫描数据集）；2) 阴影Lindblad断层扫描（利用随机化配置回收，在物理启发的局域性假设下使用更少资源）

Result: 在1和3量子比特子系统上验证了阴影方法能准确重现可扩展方法的结果，同时使用指数级更少的配置。在5量子比特处理器上，阴影方法仅需9小时采集时间（相比传统方法的58小时），成功恢复了所有单量子比特耗散和双量子比特耦合参数

Conclusion: 随机化阴影断层扫描协议可以实际应用于学习量子处理器动力学，随着量子比特数量的增加，这种方法展现出显著的效率优势，且兼容传统高斯误差传播方法

Abstract: Spurious couplings and decoherence degrade the performance of solid-state quantum processors, demanding careful design, calibration, and mitigation protocols. These strategies often rely on characterization of the idling processor, but tomographic recovery of (time-independent) Lindblad dynamics scales exponentially with qubit count. Here, we experimentally benchmark and demonstrate that randomized ("shadow") measurements accelerate Lindblad tomography on a superconducting transmon processor. We first implement extensible Lindblad tomography, which estimates Lindblad parameters using a complete tomographic dataset, and use it as a baseline to benchmark a shadow tomography approach, shadow Lindblad tomography. The shadow approach recycles randomized configurations to estimate the same Lindblad parameters using far fewer resources under physically motivated locality assumptions. We experimentally verify these assumptions in our processor by implementing the protocols on one- and three-qubit subsystems; here, shadow Lindblad tomography reproduces extensible Lindblad tomography within uncertainties while using exponentially fewer configurations. Leveraging this efficiency, we apply shadow Lindblad tomography to the full five-qubit processor and recover all single qubit dissipation and two-qubit coupling parameters in 9 hours of acquisition time compared to an estimated 58 hours for extensible Lindblad tomography. Additionally, our shadow implementation is compatible with conventional Gaussian error propagation, avoiding the use of median-of-means estimators. Together, these results demonstrate how randomized shadow tomography protocols can be practically implemented to learn quantum processor dynamics at an increasing qubit count.

</details>


### [222] [Erratic Liouvillian Skin Localization and Subdiffusive Transport](https://arxiv.org/abs/2602.14698)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 研究全局互易性Liouvillian动力学中的输运行为，发现虽然能抑制皮肤效应，但仍会出现超慢的Sinai型亚扩散输运，与哈密顿系统有本质区别。


<details>
  <summary>Details</summary>
Motivation: 探索当非互易性源于Liouvillian层面而非通过后选择得到的有效非厄米哈密顿量时，是否会出现类似全局互易耦合非厄米系统中的行为。特别是在Liouvillian特有的效应尚未充分研究的无序设置中。

Method: 研究具有全局互易Liouvillian动力学和局部非对称非相干跳跃的晶格模型，分析稳态性质和输运行为。

Result: 稳态表现出无序依赖的、无边界积累的随机局域化。在非相干跳跃主导的区域，激发通过Sinai型亚扩散传播，比对称随机晶格中的普通扩散慢得多。

Conclusion: 全局互易性哈密顿量和Liouvillian动力学之间存在根本区别：全局互易性在两种情况下都能抑制皮肤效应，但只有在Liouvillian动力学中，它才能与超慢的、无序诱导的亚扩散输运共存。

Abstract: Non-Hermitian systems with globally reciprocal couplings -- such as the Hatano-Nelson model with stochastic imaginary gauge fields -- avoid the conventional non-Hermitian skin effect, displaying erratic bulk localization while retaining ballistic transport. An open question is whether similar behavior arises when non-reciprocity originates at the Liouvillian level rather than from an effective non-Hermitian Hamiltonian obtained via post-selection. Here we investigate this scenario in a lattice model with globally reciprocal Liouvillian dynamics and locally asymmetric incoherent hopping, a disordered setting in which Liouvillian-specific effects have remained largely unexplored. While the steady state again shows disorder-dependent, erratic localization without boundary accumulation, we find that global reciprocity in the Liouvillian does not protect transport. Instead, in the regime dominated by incoherent hopping, excitations spread via Sinai-type subdiffusion, dramatically slower than the ordinary diffusion found in symmetric stochastic lattices. Our results reveal a fundamental distinction between globally reciprocal Hamiltonian and Liouvillian dynamics: global reciprocity suppresses the skin effect in both cases, but only in Liouvillian dynamics can it coexist with ultra-slow, disorder-induced subdiffusive transport.

</details>


### [223] [Faster Optimal Decoder for Graph Codes with a Single Logical Qubit](https://arxiv.org/abs/2602.14730)
*Nirupam Basak,Goutam Paul*

Main category: quant-ph

TL;DR: 提出一种基于图态结构特性的分层解码器，用于图码（一种稳定子量子纠错码），在多项式时间内实现高效解码，避免NP难的最大似然解码。


<details>
  <summary>Details</summary>
Motivation: 图码的最优解码通常是NP难问题，需要开发更高效的解码方法。虽然不同错误模式可能产生相同的综合征，但测量后状态具有由投影综合征测量确定的结构特性，这为设计高效解码器提供了机会。

Method: 利用图态的结构特性，提出分层解码器：1）基于投影综合征测量后状态的结构特性；2）每层都可在多项式时间内求解；3）在较低层级实现最优解码性能；4）避免完整的最大似然解码。

Result: 数值结果表明该方法既高效又有效，能够在多项式时间内实现解码，同时在较低层级保持最优解码性能。

Conclusion: 通过利用图态的结构特性，成功开发了一种高效的分层解码器，解决了图码解码的NP难问题，为量子纠错码的实际应用提供了可行的解码方案。

Abstract: In this work, we develop an efficient decoding method for graph codes, a class of stabilizer quantum error-correcting codes constructed from graph states. While optimal decoding is generally NP-hard, we propose a faster decoder exploiting the structural properties of the underlying graph states. Although distinct error patterns may yield the same syndrome, we demonstrate that the post-measurement state follows a well-defined structure determined by the projective syndrome measurement. Building on this idea, we introduce a hierarchical decoder in which each level can be solved in polynomial time. Additionally, this decoder achieves optimal decoding performance at the lower levels of the hierarchy. This strategy avoids the need for full maximum-likelihood decoding of graph codes. Numerical results illustrate the efficiency and effectiveness of the proposed approach.

</details>


### [224] [Projections with Respect to Bures Distance and Fidelity: Closed-Forms and Applications](https://arxiv.org/abs/2602.14732)
*A. Afham,Marco Tomamichel*

Main category: quant-ph

TL;DR: 本文推导了关于保真度（等价于Bures距离和纯化距离）投影的简单统一闭式表达式，应用于多种集合，包括具有给定边缘的二分正半定矩阵集合、量子通道集合和测量集合。引入了完全正映射的先验-通道分解，将任意二分PSD矩阵与通道-状态对建立双射对应。应用包括证明pretty good measurement是加权系综到测量集合的保真度投影，Petz恢复映射是CP映射到反向量子通道集合的投影。


<details>
  <summary>Details</summary>
Motivation: 量子信息理论中，保真度投影在各种集合上的闭式表达式具有重要意义，但现有方法复杂且不统一。本文旨在推导简单统一的闭式表达式，建立量子通道、测量等关键概念的几何解释，并为量子贝叶斯规则和量子状态随时间演化形式提供信息几何基础。

Method: 1. 推导保真度（Bures距离、纯化距离）投影到多种集合的闭式表达式，包括：具有给定边缘的二分PSD矩阵集合、给定矩阵的PSD分解集合、量子通道集合（通过Choi同构）、测量集合。2. 引入完全正映射的先验-通道分解，将任意CP映射唯一分解为先验PSD矩阵和量子通道。3. 建立该分解与保真度投影的自然联系。

Result: 1. 获得了保真度投影到关键量子信息集合的简单统一闭式表达式。2. 证明了先验-通道分解建立了任意二分PSD矩阵与通道-状态对之间的双射对应。3. 应用方面：证明pretty good measurement是加权系综到测量集合的保真度投影；Petz恢复映射是CP映射到反向量子通道集合的投影，为量子贝叶斯规则提供信息几何解释。4. 为Leifer-Spekkens量子状态随时间演化形式提供信息几何基础。

Conclusion: 本文通过推导保真度投影的统一闭式表达式，建立了量子信息关键概念的信息几何框架。先验-通道分解推广了Choi-Jamiolkowski同构，为量子通道、测量、恢复映射等提供了自然的几何解释，并将量子贝叶斯规则和量子状态随时间演化形式纳入统一的信息几何视角。

Abstract: We derive simple and unified closed-form expressions for projections with respect to fidelity (equivalently, the Bures and purified distances) onto several sets of interest. These include projections of bipartite positive semidefinite (PSD) matrices onto the set of PSD matrices with a given marginal, and projections of ensembles of PSD matrices onto the set of PSD decompositions of a given matrix, with important special cases corresponding to projections onto the set of quantum channels (via the Choi isomorphism) and onto the set of measurements. We introduce prior-channel decompositions of completely positive (CP) maps, which uniquely decompose any CP map into a prior PSD matrix and a quantum channel. This decomposition generalizes the Choi-Jamiolkowski isomorphism by establishing a bijective correspondence between arbitrary bipartite PSD matrices and channel-state pairs, and we show that it arises naturally from the fidelity projections developed here. As applications, we show that the pretty good measurement - associated with a weighted ensemble - is the fidelity projection of the ensemble onto the set of measurements, and that the Petz recovery map - associated with a reference state and forward channel - is the projection of a CP map (constructed from the channel-state pair) onto the set of reverse quantum channels, thereby recasting the well-known identification of the Petz map with quantum Bayes' rule in information-geometric terms. Our results also provide an information-geometric underpinning of the Leifer-Spekkens quantum state over time formalism [Leifer and Spekkens, Phys. Rev. A 88, 052130 (2013)].

</details>


### [225] [The Signal Horizon: Local Blindness and the Contraction of Pauli-Weight Spectra in Noisy Quantum Encodings](https://arxiv.org/abs/2602.14735)
*Ait Haddou Marwan*

Main category: quant-ph

TL;DR: 量子分类器在噪声下局部可访问信息的研究，提出k-局部可区分性度量，分析局部测量下的分类性能


<details>
  <summary>Details</summary>
Motivation: 研究在噪声环境下，受局部性约束的测量能够保留多少类别信息，探索局部测量与全局可区分性之间的关系

Method: 将二元量子分类表述为约束量子态区分问题，引入k-局部可区分性度量，分析独立退极化噪声下的Pauli权重依赖收缩机制，提出k-局部Pauli可访问振幅作为可计算预测器

Result: 数值实验显示经验准确率与理论预测在噪声水平上定量一致，识别出k-局部分类器变得与随机猜测无法区分的操作崩溃阈值

Conclusion: 即使全局可区分性持续存在，局部测量下的分类性能仍会因噪声而崩溃，揭示了量子分类中局部信息可访问性的重要限制

Abstract: The performance of quantum classifiers is typically analyzed through global state distinguishability or the trainability of variational models. This study investigates how much class information remains accessible under locality-constrained measurements in the presence of noise. The authors formulate binary quantum classification as constrained quantum state discrimination and introduce a locality-restricted distinguishability measure quantifying the maximum bias achievable by observables acting on at most $k$ subsystems. For $n$-qubit systems subject to independent depolarizing noise, the locally accessible signal is governed by a Pauli-weight-dependent contraction mechanism. This motivates a computable predictor, the $k$-local Pauli-accessible amplitude $A_{k}(p)$, which lower bounds the optimal $k$-local classification advantage. Numerical experiments on four-qubit encodings demonstrate quantitative agreement between empirical accuracy and the prediction across noise levels. The research identifies an operational breakdown threshold where $k$-local classifiers become indistinguishable from random guessing despite persistent global distinguishability.

</details>


### [226] [Coupled integrated photonic quantum memristors using a single photon source made of a colour center](https://arxiv.org/abs/2602.14736)
*Alessio Baldazzi,Roy Philip George Konnoth Ancel,Sebastiano Guaraldo,Xuan Chen,Ziad Abi Akar,Regis Deturche,Stefano Azzini,Christophe Couteau,Lorenzo Pavesi*

Main category: quant-ph

TL;DR: 实验实现并表征了两个耦合光子量子忆阻器的网络，展示了增强的非马尔可夫动力学和记忆行为，为量子神经形态计算提供了可扩展的构建模块。


<details>
  <summary>Details</summary>
Motivation: 先前光子量子忆阻器的研究局限于孤立设备或简单级联配置，需要探索更复杂的耦合网络以实现更丰富的非线性动力学和记忆行为，为量子神经形态计算奠定基础。

Method: 在氮化硅光子集成电路上实现两个交叉反馈耦合的光子量子忆阻器网络，每个忆阻器由集成马赫-曾德尔干涉仪构成，其传递函数通过另一个忆阻器的光子检测事件自适应更新，使用基于硅空位色心的室温单光子源。

Result: 观察到增强的忆阻行为，包括更大的形状因子和自相交环的输入输出迟滞曲线，揭示了显著的双稳态和拓扑非平凡记忆动力学。数值模拟显示这些特征源于记忆深度和相对输入相位的相互作用。

Conclusion: 耦合集成光子量子忆阻器可作为可扩展的非线性构建模块，在紧凑型量子神经形态和储备池计算架构中具有重要应用潜力。

Abstract: Photonic quantum memristors provide a measurement-induced route to nonlinear and history-dependent quantum dynamics. Experimental demonstrations have so far focused on isolated devices or simple cascaded devices configurations. Here, we experimentally realize and characterize a network of two coupled photonic quantum memristors with crossed feedback, implemented on a silicon nitride photonic integrated circuit and fed by a room-temperature single-photon source based on a silicon-vacancy color center SiV$^-$ in a nanodiamond. Each memristor consists of an integrated Mach-Zehnder interferometer whose transfer function is adaptively updated by photon detection events on another memristor, thus generating novel non-Markovian input-output dynamics with an enhanced memristive behaviour compared to single devices. In particular, we report inter-memristor input-output hysteresis curves exhibiting larger form factors and displaying self-intersecting loops, respectively revealing marked bistability and topologically non-trivial memory dynamics. Furthermore, numerical simulations show how these features emerge from the interplay between memory depth and relative input phase, for both intra- and inter-memristor input-output relations. Our results establish coupled integrated photonic quantum memristors as scalable nonlinear building blocks and highlight their potential for implementing compact quantum neuromorphic and reservoir computing architectures.

</details>


### [227] [Probabilistic Cutoffs in Homogeneous Quantum Repeater Chains](https://arxiv.org/abs/2602.14738)
*Jeroen Grimbergen,Stav Haldar,Alvaro Gomez Inesta,Stephanie Wehner*

Main category: quant-ph

TL;DR: 研究量子中继器链中纠缠链接的生成与交换，提出无需跟踪链接年龄的概率性截断策略，与确定性策略进行性能比较。


<details>
  <summary>Details</summary>
Motivation: 量子中继器链中，由于概率性纠缠生成和退相干导致的保真度下降，需要有效管理链接存储时间。确定性截断策略虽然能严格控制保真度，但需要跟踪链接年龄，增加了复杂性。

Method: 提出概率性截断策略，无需跟踪链接年龄，放弃对保真度的严格控制。将该策略与确定性截断策略进行基准测试，比较端到端速率、保真度和密钥生成速率。

Result: 概率性截断策略在节点较少或基本链接生成概率较高的链中，能提供与确定性策略相同数量级的密钥速率。在某些场景下，还能以更高速率提供满足最低保真度要求的端到端链接。

Conclusion: 概率性截断策略虽然放弃了对保真度的严格控制，但在减少状态跟踪复杂性的同时，仍能在特定条件下提供与确定性策略相当的性能，为量子中继器链管理提供了更简单的替代方案。

Abstract: We study quantum repeater chains in which entangled links between neighbouring nodes are created through heralded entanglement generation and adjacent links are swapped as soon as possible. Since heralded entanglement generation attempts succeed only probabilistically, some links will have to be stored in quantum memories at the nodes of the chain while waiting for adjacent links to be generated. The fidelity of these stored links decreases with time due to decoherence, and if they are stored for too long then this can lead to low end-to-end fidelity. Previous work has shown that the end-to-end fidelity can be improved by deterministically discarding links when their ages exceed some cutoff value. Such deterministic cutoff policies provide strict control of the fidelity of all links, but they come at the expense of having to track link ages. In this work, we introduce a probabilistic cutoff policy that does not require tracking link ages, at the cost of abandoning strict control of the fidelity. We benchmark this new probabilistic cutoff policy against a deterministic cutoff policy. We compare the policies in terms of the end-to-end rate and fidelity, and the secret-key rate. We find that even though the probabilistic cutoff policy keeps track of less state, it can provide secret-key rates of the same order of magnitude as the deterministic cutoff policy in chains with few nodes or high elementary link generation probabilities. Moreover, we identify a scenario in which the probabilistic cutoff policy can deliver end-to-end links that are required to have some minimum threshold fidelity at a higher rate than the deterministic cutoff policy.

</details>


### [228] [Finer sub-Planck structures and displacement sensitivity of SU(1,1) circular states](https://arxiv.org/abs/2602.14752)
*Naeem Akhtar,Jia-Xin Peng,Tariq Aziz,Xiaosen Yang,Dong Wang*

Main category: quant-ph

TL;DR: 本文提出了一种广义SU(1,1)罗盘态，通过叠加n̄≥6个等间距排列在双曲平面圆环上的SU(1,1)相干态，实现了各向同性的亚普朗克特征，从而在相空间位移测量中提供均匀的灵敏度增强。


<details>
  <summary>Details</summary>
Motivation: 现有SU(1,1)罗盘态（叠加4个相干态）产生的亚普朗克特征在不同相空间方向上尺度不同，导致灵敏度增强不均匀。需要克服这一限制，实现各向同性的灵敏度增强。

Method: 构造n̄-分量罗盘态：叠加n̄≥6个SU(1,1)相干态（总数为偶数），这些态在双曲平面上沿圆形路径均匀排列（距原点距离相同，角间距为2π/n̄）。

Result: 广义SU(1,1)罗盘态产生圆形亚普朗克特征（各向同性亚普朗克性），对相空间位移提供均匀的灵敏度增强。随着n̄增加，这种精细化改进逐渐提升。已验证n̄=16的情况，结果适用于任意大n̄的叠加态。

Conclusion: 通过构造广义SU(1,1)罗盘态，成功克服了传统四分量罗盘态的非均匀灵敏度增强问题，实现了各向同性的亚普朗克特征，为量子计量学提供了更优的测量资源。

Abstract: Quantum states with sub-Planck features exhibit sensitivity to phase-space displacements beyond the standard quantum limit, making them useful for quantum metrology. In the context of the SU(1,1) group, sub-Planck features have been constructed through the superposition of four Perelomov coherent states on the hyperbolic plane (the SU(1,1) compass state). However, these structures differ in scale along different phase-space directions, resulting in nonuniform sensitivity enhancement. We overcome this limitation by constructing $\overline{n}$-component compass states, which are obtained by superposing $\overline{n} \geq 6$ SU(1,1) coherent states, with an even total number, evenly arranged along a circular path on the hyperbolic plane; that is, all components lie at the same distance from the origin and have equal angular spacing of $\frac{2π}{\overline{n}}$. These generalized SU(1,1) compass states generate circularly shaped sub-Planck features (isotropic sub-Planckness) and provide uniform enhancement in sensitivity to phase-space displacements. As the number of coherent states $\overline{n}$ increases, these refinements progressively improve. While verified for $\overline{n} = 16$ SU(1,1) coherent states, the results remain valid for superpositions with arbitrarily large $\overline{n}$ components.

</details>


### [229] [Multi-level spectral navigation with geometric diabatic-adiabatic control](https://arxiv.org/abs/2602.14756)
*Christian Ventura-Meinersen,Edmondo Valvo,Stefano Bosco,Maximilian Rimbach-Russ*

Main category: quant-ph

TL;DR: 提出几何框架用于多能级量子系统的高效少参数脉冲优化，实现超越绝热极限的高保真度态转移


<details>
  <summary>Details</summary>
Motivation: 在多能级量子系统中实现高效脉冲优化，超越传统绝热方法的限制，减少不必要激发并最大化目标跃迁

Method: 采用几何框架，在绝热和绝热动力学之间平滑插值，对于单参数脉冲控制，优化简化为求解一阶常微分方程

Result: 展示了该方法的灵活性，通过自旋量子信息处理中的两个实例：态初始化和量子比特态转移

Conclusion: 该几何框架为多能级量子系统提供了高效、少参数的脉冲优化方法，能够实现高保真度的态转移操作

Abstract: We introduce a geometric framework for efficient few-parameter pulse optimization in multi-level quantum systems, enabling high-fidelity state transfer beyond the adiabatic limit. Our method interpolates smoothly between adiabatic and diabatic dynamics to minimize unwanted excitations and maximize desired transitions even within a multi-level structure. Crucially, for single-parameter pulse control, the optimization reduces to solving a first-order ordinary differential equation. We showcase the flexibility of our diabatic-adiabatic protocols through two examples in spin-based quantum information processing: state initialization and qubit state transfer.

</details>


### [230] [Localization Tensor Revisited: Geometric-Probabilistic Foundations and a Structure-Factor Criterion under Periodic Boundaries](https://arxiv.org/abs/2602.14779)
*Zhe-Hao Zhang,Xiaoming Cai,Yi-Cong Yu*

Main category: quant-ph

TL;DR: 重新审视局域化张量，构建与周期性边界条件兼容的扩展，提出基于结构因子的局域化诊断方法，可区分安德森局域化和二聚化相。


<details>
  <summary>Details</summary>
Motivation: 传统局域化张量在周期性边界条件下存在问题，需要重新定义位置算符。本文旨在构建与周期性边界条件自然兼容的局域化张量扩展，并发展能够区分不同类型局域化相（如安德森局域化和二聚化）的诊断方法。

Method: 从几何和概率角度重新审视局域化张量，提出两种周期性边界条件下的扩展：(1) 基于圆上黎曼中心（Frechet均值）的几何方法；(2) 基于互信息的度量无关方法。将局域化张量与静态结构因子联系起来，通过分析局域化函数C(p)的动量行为来区分不同相。

Result: 成功构建了与周期性边界条件兼容的局域化张量扩展，发现局域化张量本身无法区分安德森局域化和二聚化相，但结合C(p)的有限动量行为和逆参与率上界可提供清晰的区分标准。在SSH和Aubry-Andre模型（包括相互作用情况）中验证了这些结果。

Conclusion: 基于结构因子的探针为周期性边界条件下的局域化和二聚化相提供了稳健且实验可访问的诊断工具，解决了传统方法在区分不同局域化机制方面的局限性。

Abstract: We revisit the localization tensor (LT) from geometric and probabilistic perspectives and construct extensions that are naturally compatible with periodic boundary conditions (PBC), without redefining the position operator. In open boundary conditions, we show that the LT can be written exactly as the covariance of a bivariate probability distribution built from density-density correlations. This leads to two conceptually distinct extensions to PBC: (i) a geometric one based on the Riemannian center (Frechet mean) on the circle, and (ii) a metric-free one based on the mutual information I, which treats the configuration space purely as a probability space. We then relate the LT to the static structure factor by identifying the diagonal part, Cpp, as a "localization function" C(p), whose small-momentum behavior determines the LT in the thermodynamic limit. This clarifies why the LT is sensitive to transitions out of the extended phase but by itself cannot distinguish Anderson-type localization from dimerization: both share the same low-momentum asymptotics. We show that the finite-momentum behavior of C(p), together with an inverse participation ratio (IPR)-based upper bound valid in localized phases, provides a sharp criterion that discriminates localization from dimerization. These results are illustrated on the Su-Schrieffer-Heeger and Aubry-Andre models, with and without interactions, and suggest that structure factor-based probes offer robust and experimentally accessible diagnostics of localized and dimerized phases under PBC.

</details>


### [231] [Constrained Portfolio Optimization via Quantum Approximate Optimization Algorithm (QAOA) with XY-Mixers and Trotterized Initialization: A Hybrid Approach for Direct Indexing](https://arxiv.org/abs/2602.14827)
*Javier Mancilla,Theodoros D. Bouloumis,Frederic Goguikian*

Main category: quant-ph

TL;DR: 该论文提出了一种在严格基数约束下进行投资组合优化的量子近似优化算法(QAOA)方法，使用Dicke态初始化和XY混合器严格保持投资组合规模，在2025年10只美国股票的回测中实现了1.81的夏普比率，显著优于模拟退火和分层风险平价方法。


<details>
  <summary>Details</summary>
Motivation: 在"直接指数化"和ESG约束任务中，严格基数约束下的投资组合优化是一个组合挑战，传统凸优化方法难以处理。在NISQ时代，QAOA提供了一种有前景的混合方法，但标准QAOA实现通常无法严格强制执行硬约束，需要软惩罚项，这会扭曲能量景观。

Method: 提出了一种约束保持的QAOA公式，使用Dicke态初始化和XY混合器哈密顿量，严格保持解的汉明权重，确保只探索规模为K的有效投资组合。引入受绝热量子计算启发的Trotterized参数初始化调度，以缓解"贫瘠高原"问题。

Result: 在2025年10只美国股票的回测中，QAOA方法实现了1.81的夏普比率，显著优于模拟退火(1.31)和分层风险平价(0.98)。但算法的高换手率(76.8%)需要在理论最优性和实施成本之间进行权衡。

Conclusion: 该约束保持的QAOA方法在严格基数约束的投资组合优化中表现出优越性能，但高换手率表明在机构设置中需要平衡理论最优性和实际实施成本。该方法为NISQ时代的组合优化问题提供了有前景的解决方案。

Abstract: Portfolio optimization under strict cardinality constraints is a combinatorial challenge that defies classical convex optimization techniques, particularly in the context of "Direct Indexing" and ESG-constrained mandates. In the Noisy Intermediate-Scale Quantum (NISQ) era, the Quantum Approximate Optimization Algorithm (QAOA) offers a promising hybrid approach. However, standard QAOA implementations utilizing transverse field mixers often fail to strictly enforce hard constraints, necessitating soft penalties that distort the energy landscape. This paper presents a comprehensive analysis of a constraint-preserving QAOA formulation against Simulated Annealing (SA) and Hierarchical Risk Parity (HRP). We implement a specific QAOA ansatz utilizing a Dicke state initialization and an XY-mixer Hamiltonian that strictly preserves the Hamming weight of the solution, ensuring only valid portfolios of size K are explored. Furthermore, we introduce a Trotterized parameter initialization schedule inspired by adiabatic quantum computing to mitigate the "Barren Plateau" problem. Backtesting on a basket of 10 US equities over 2025 reveals that our QAOA approach achieves a Sharpe Ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98). We further analyze the operational implications of the algorithm's high turnover (76.8%), discussing the trade-offs between theoretical optimality and implementation costs in institutional settings.

</details>


### [232] [Gravitational Decoherence Estimation in Optomechanical Systems](https://arxiv.org/abs/2602.14841)
*Leonardo A. M. Souza,Olimpio P. de Sá Neto,Enrico Russo,Rosario Lo Franco,Gerardo Adesso*

Main category: quant-ph

TL;DR: 该论文开发了一个量子估计框架，用于量化在光机械系统中使用单模高斯探针态推断引力诱导退相干所能达到的精度极限。


<details>
  <summary>Details</summary>
Motivation: 研究引力诱导退相干的检测极限，建立量化引力扩散机制在光机械系统中可测量性的理论框架。

Method: 结合引力扩散机制的微观描述与量子费希尔信息，使用单模高斯探针态，分析瞬态演化和稳态下的机械状态特征。

Result: 引力扩散在机械状态中留下可测量的特征信号，探针态制备方式显著影响可达到的精度，建立了检测引力驱动退相干的基本极限。

Conclusion: 该框架为量化引力诱导退相干的检测精度提供了理论基础，确定了探针态制备对测量精度的关键影响，为实验设计提供了指导原则。

Abstract: We develop a comprehensive quantum estimation framework to quantify how precisely gravitationally induced decoherence can be inferred in optomechanical systems, using single-mode Gaussian probe states. Our approach combines a microscopic description of the gravitational diffusion mechanism with quantum Fisher information to determine the ultimate sensitivity achievable in principle. We show that gravitational diffusion leaves distinct, measurable signatures in the mechanical state, both during transient evolution and in the stationary regime. Finally, we identify how probe state preparation shapes the attainable precision, thereby establishing fundamental limits for detecting and estimating gravity-driven decoherence.

</details>


### [233] [Infinite reduction in absorbing time in quantum walks over classical ones](https://arxiv.org/abs/2602.14880)
*Shuva Mondal,Amrita Mandal,Ujjwal Sen*

Main category: quant-ph

TL;DR: 量子行走在线性路径上的吸收时间和传播速率研究：有吸收体时平均吸收时间有限（与经典随机行走不同），无序插入会逆转此行为，且吸收体存在时传播速率加快，无序量子行走从亚弹道恢复为弹道传播


<details>
  <summary>Details</summary>
Motivation: 研究量子行走在线性路径上的动力学特性，特别关注吸收体存在对吸收时间和传播速率的影响，以及无序如何改变量子行走的行为，探索量子行走与经典随机行走的差异

Method: 采用离散时间量子行走模型，在线性路径上分析有/无吸收体的情况，通过解析方法建立平均吸收时间的理论结果，并利用数值模拟研究无序步长对行为的影响

Result: 1. 有吸收体时量子行走的平均吸收时间是有限的，而经典随机行走是无限的，表明量子版本在资源消耗上显著减少；2. 插入无序步长会逆转这一行为；3. 吸收体存在时传播速率加快；4. 无序量子行走从亚弹道传播恢复为清洁量子行走的弹道传播

Conclusion: 量子行走在有吸收体时表现出与经典随机行走显著不同的特性，包括有限的吸收时间和加速的传播速率，无序可以逆转某些量子效应，但也能恢复弹道传播特性，这些发现对量子计算和量子信息处理有重要意义

Abstract: We study the absorption time and spreading rate of the discrete-time quantum walk propagating on a line in the presence or absence of an absorber. We analytically establish that in the presence of an absorber, the average absorption time of the quantum walker is finite, contrary to the behavior of a classical random walker, indicating an infinite resource reduction on moving over to a quantum version of a walker. Furthermore, numerical simulations indicate a reversal of this behavior due to the insertion of disorder in the walker's step lengths. Additionally, we demonstrate that in the presence of an absorber, there is a speed-up in the spreading rate, and that a disordered quantum walk that is sub-ballistic regains the ballistic spreading of a clean quantum walk.

</details>


### [234] [Scaling QAOA: transferring optimal adiabatic schedules from small-scale to large-scale variational circuits](https://arxiv.org/abs/2602.14986)
*Ugo Nzongani,Dylan Laplace Mermoud,Arthur Braida*

Main category: quant-ph

TL;DR: 提出基于谱隙的调度学习框架，将小规模问题的谱隙信息迁移到大规模系统，将QAOA参数从2p个压缩到2个，实现参数高效优化。


<details>
  <summary>Details</summary>
Motivation: QAOA在近期量子设备上用于组合优化，但可扩展性受限于2p个变分参数的优化难度。研究发现最优QAOA角度具有集中性和可迁移性，因此希望利用小规模问题的谱隙信息来指导大规模系统的优化。

Method: 从小规模问题中提取谱隙剖面，构建连续调度方程∂_t s = κg^q(s)，其中g(s)是瞬时谱隙，(κ,q)是全局超参数。离散化该调度得到所有QAOA角度的闭式表达式，将经典优化任务从2p个参数减少到仅2个。

Result: 在随机QUBO和3-正则MaxCut实例上的数值模拟表明，学习的调度能有效迁移到更大系统，同时获得有竞争力的近似比。参数压缩减轻了经典优化开销，降低了对贫瘠高原现象的敏感性。

Conclusion: 谱隙指导的调度迁移为QAOA提供了可扩展且参数高效的策略，通过利用小规模问题的谱隙信息来指导大规模系统的优化，显著减少了参数优化复杂度。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for combinatorial optimization on near-term quantum devices, yet its scalability is limited by the difficulty of optimizing \(2p\) variational parameters for a large number \(p\) of layers. Recent empirical studies indicate that optimal QAOA angles exhibit concentration and transferability across problem sizes. Leveraging this observation, we propose a schedule-learning framework that transfers spectral-gap-informed adiabatic control strategies from small-scale instances to larger systems.
  Our method extracts the spectral gap profile of small problems and constructs a continuous schedule governed by \(\partial_t s = κg^q(s)\), where \(g(s)\) is the instantaneous gap and \((κ, q)\) are global hyperparameters. Discretizing this schedule yields closed-form expressions for all QAOA angles, reducing the classical optimization task from \(2p\) parameters to only \(2\), independent of circuit depth. This drastic parameter compression mitigates classical optimization overhead and reduces sensitivity to barren plateau phenomena.
  Numerical simulations on random QUBO and 3-regular MaxCut instances demonstrate that the learnt schedules transfer effectively to larger systems while achieving competitive approximation ratios. Our results suggest that gap-informed schedule transfers provide a scalable and parameter-efficient strategy for QAOA.

</details>


### [235] [Rotational Quantum Friction via Spontaneous Decay](https://arxiv.org/abs/2602.14992)
*Nicolas Schüler,O. J. Franca,Michael Vaz,Hervé Bercegol,Stefan Yoshi Buhmann*

Main category: quant-ph

TL;DR: 研究旋转量子摩擦：双原子极性分子在自由空间绕质心旋转时，由于量子真空场产生的耗散扭矩，在马尔可夫区域发现Ω³依赖的摩擦扭矩，在非马尔可夫短时区域发现Ω依赖的摩擦。


<details>
  <summary>Details</summary>
Motivation: 量子摩擦是真空力和涨落领域的一个有趣现象，指运动物体由于量子真空场而产生的耗散力。本研究旨在探索旋转量子摩擦，特别是双原子极性分子在自由空间中绕自身质心旋转的情况。

Method: 将旋转运动量子化，研究由于自发衰变导致的耗散。分别在马尔可夫区域和非马尔可夫短时区域进行分析。

Result: 在马尔可夫区域，即使在零温度下也存在与Ω³成正比的摩擦扭矩，且在大旋转量子数l的极限下与经典结果一致。在非马尔可夫短时区域，发现摩擦与Ω成正比。

Conclusion: 旋转量子摩擦在不同区域表现出不同的标度行为：马尔可夫区域为Ω³依赖，非马尔可夫短时区域为Ω依赖，这为理解量子真空场对旋转系统的耗散效应提供了重要见解。

Abstract: A fascinating effect belonging to the field of vacuum forces and fluctuations is that of quantum friction. It refers to the prediction of a dissipative force acting on a moving object due to the quantum vacuum field. In this work, we investigate rotational quantum friction where a diatomic polar molecule rotates around its own center of mass in free space. We quantize the rotational motion and investigate the resulting dissipation due to spontaneous decay. We find in the Markovian regime that a friction torque $\propto Ω^3$ persists even for zero temperature, and in agreement with the classical result in the limit of large rotational quantum number $l$. Within the non-Markovian short-time regime we find a friction $\proptoΩ$.

</details>


### [236] [Instruction-Set Architecture for Programmable NV-Center Quantum Repeater Nodes](https://arxiv.org/abs/2602.14995)
*Vinay Kumar,Claudio Cicconetti,Riccardo Bassoli,Marco Conti,Andrea Passarella*

Main category: quant-ph

TL;DR: 提出基于氮空位中心的量子中继器节点指令集架构，支持确定性寄存器控制和相干寄存器控制两种可编程模式，实现网络协议表达和干涉测量诊断。


<details>
  <summary>Details</summary>
Motivation: 量子网络软件栈中可编程性日益重要，但量子中继器设备的控制器-硬件接口仍缺乏规范。需要为氮空位中心量子中继器节点设计控制器驱动的可编程接口。

Method: 提出指令集架构概念，将节点设计为光学接口电子自旋（数据量子比特）和长寿命核自旋寄存器（控制程序）。形式化两种可编程模式：确定性寄存器控制（寄存器初始化为基础态选择操作）和相干寄存器控制（寄存器制备为叠加态，实现相干操作组合）。

Result: 通过BBPSSW纯化协议的紧凑实现展示网络协议表达；相干寄存器控制支持保真度见证和校准等干涉测量诊断；讨论了向多电子/核自旋架构的可扩展性以及与线性组合幺正算子和Kraus表述的联系。

Conclusion: 提出的指令集架构为量子中继器节点提供了控制器驱动的可编程接口，支持经典和量子增强的可编程性，为量子网络协议实现和诊断提供了新工具。

Abstract: Programmability is increasingly central in emerging quantum network software stacks, yet the node-internal controller-to-hardware interface for quantum repeater devices remains under-specified. We introduce the idea of an instruction-set architecture (ISA) for controller-driven programmability of nitrogen-vacancy (NV) center quantum repeater nodes. Each node consists of an optically interfaced electron spin acting as a data qubit and a long-lived nuclear-spin register acting as a control program. We formalize two modes of programmability: (i) deterministic register control, where the nuclear register is initialized in a basis state to select a specific operation on the data qubit; and (ii) coherent register control, where the register is prepared in superposition, enabling coherent combinations of operations beyond classical programmability. Network protocols are expressed as controller-issued instruction vectors, which we illustrate through a compact realization of the BBPSSW purification protocol. We further show that coherent register control enables interferometric diagnostics such as fidelity witnessing and calibration, providing tools unavailable in classical programmability. Finally, we discuss scalability to multi-electron and multi-nuclear spin architectures and connection to Linear combination of unitaries (LCU) and Kraus formulation.

</details>


### [237] [Low Depth Unitary Coupled Cluster Algorithm for Large Chemical Systems](https://arxiv.org/abs/2602.14999)
*Jeremy Canfield,Dominika Zgid,J K Freericks*

Main category: quant-ph

TL;DR: 提出qUCC方法，通过泰勒展开小角度UCC因子来减少量子电路深度，同时精确处理大角度因子，在强关联系统中实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 传统UCC算法在处理大系统时会产生过深的量子电路，难以在现有量子硬件上执行。需要一种方法在保持精度的同时减少电路深度。

Method: 提出二次展开的qUCC方法：对小角度UCC因子进行泰勒展开以减少电路深度，同时精确处理大角度因子。在氢链和BeH2分子等强关联系统中测试，系统性地增加精确处理的UCC因子数量。

Result: qUCC在强关联系统中表现良好，特别是在传统低激发耦合簇方法失效的情况下。结果显示，仅需处理总UCC因子数的约1/3到1/2就能获得良好收敛，最难收敛的区域是弱耦合到强耦合的过渡区。

Conclusion: qUCC方法通过混合处理策略（精确处理大角度因子+泰勒展开小角度因子）有效减少了量子电路深度，为在现有量子硬件上实现UCC计算提供了可行方案，特别适用于强关联系统。

Abstract: The unitary coupled cluster (UCC) algorithm is one of the most promising implementations of the variational quantum eigensolver for quantum computers. However, for large systems, the number of UCC factors leads to deep quantum circuits, which are prohibitive for execution on quantum hardware. To address this, circuit depth can be reduced at the cost of more measurements with a Taylor series expansion of UCC factors with small angles, while treating the large-angle factors exactly. We implement this approach to quadratic order (qUCC) for systems with strong correlations and systems where conventional methods like coupled cluster (CC) with low excitation levels fail, but UCC and qUCC perform well. We study hydrogen chains and the BeH2 molecule that allow us to change the degree of strong correlation due to geometrical distortions. We show, via a dramatic increase in number of factors able to handle exactly, a systematic convergence of these results as more exact UCC factors are included in the calculations -- the hardest to converge regime is in the crossover from weak to strong coupling. In all cases the total number of UCC factors needed to be treated exactly is much less than the total number of UCC factors available (typically about one-third to one-half of the total number of factors).

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [238] [Symmetric teleparallel gravitational effects on solar neutrino oscillations](https://arxiv.org/abs/2602.13355)
*Aysel Cetinkaya,Muzaffer Adak,Özcan Sert,Caglar Pala*

Main category: gr-qc

TL;DR: 首次在对称远平行引力（非度量性引力）时空中分析中微子振荡，使用太阳的简化Kerr度规，推导Dirac哈密顿量并计算相位差，为中微子振荡作为非度量性探针开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 虽然广义相对论和基于挠率的几何中引力对中微子的影响已有研究，但在对称远平行引力体系（引力完全源于非度量性，曲率和挠率为零）中，中微子振荡尚未被探索。本研究旨在填补这一空白，探索中微子振荡作为非度量性引力的新探针。

Method: 使用缓慢旋转、弱引力球对称太阳的简化Kerr度规（在重合规范中），从广义Dirac方程推导Dirac哈密顿量，计算中微子质量本征态的累积相位。模型包含六个自由耦合常数，基于观测数据推断这些常数的上限，简化计算过程。

Result: 计算了太阳中微子振荡中起关键作用的相位差，分析了六个自由耦合常数的贡献。基于观测数据推断出了这些任意耦合常数的上限，建立了中微子振荡作为非度量性引力探针的有效性。

Conclusion: 中微子振荡可作为非度量性引力的新颖探针，为通过天体物理观测测试对称远平行引力开辟了新途径。研究首次在曲率和挠率为零、引力完全源于非度量性的时空中分析了中微子振荡现象。

Abstract: Neutrino oscillations probe the quantum gravity interface in unique ways. While gravitational effects on neutrinos are well studied in general relativity and torsion based geometries, the symmetric teleparallel regime where gravity stems solely from non-metricity, with zero curvature and torsion has remained uncharted. In this work, we perform the first analysis of neutrino oscillations in such a spacetime. Using the reduced Kerr metric in coincident gauge for the slowly rotating and weakly gravitating spherical Sun, we derive the Dirac Hamiltonian from the generalized Dirac equation and compute the accumulated phase of neutrino mass eigenstates. There are six free coupling constants in our model. Based on certain observational inputs, we inferred upper bounds on our arbitrary coupling constants. This allowed us to simplify the otherwise cumbersome calculations to some extent. Ultimately, we computed the phase differences that play a crucial role in solar neutrino oscillations and analyzed the contributions arising from our arbitrary coupling constants. Our results establish neutrino oscillations as a novel probe of non-metricity and open a new avenue for testing symmetric teleparallel gravity through astrophysical observations.

</details>


### [239] [Dynamical Formation of Self-Similar Wormholes](https://arxiv.org/abs/2602.13609)
*Yasutaka Koga,Ryota Maeda,Daiki Saito,Daisuke Yoshida*

Main category: gr-qc

TL;DR: 研究自相似虫洞解及其动力学形成，通过负能量零尘埃支撑，展示黑洞如何演化为虫洞


<details>
  <summary>Details</summary>
Motivation: 研究虫洞的动力学形成机制，特别是如何从黑洞演化而来，扩展Hayward和Koyama 2004年静态虫洞形成模型到非静态情况

Method: 在自相似性假设下，将爱因斯坦场方程简化为常微分方程组，数值求解满足喉部存在条件的解；通过Barrabes-Israel形式将史瓦西黑洞、负能量Vaidya时空和自相似虫洞几何拼接构建动力学形成场景

Result: 获得足够大喉部半径时在空间和未来零无穷远处保持正则的几何，但过去方向仍存在奇点；建立了喉部半径、黑洞质量和壳层能量注入之间的明确关系，证明初始黑洞可演化为虫洞

Conclusion: 成功将静态虫洞形成模型推广到非静态情况，为规则可穿越虫洞的形成提供了新的理论框架和视角

Abstract: We study spherically symmetric, self-similar wormhole solutions supported by colliding streams of negative-energy null dust, and their dynamical formation. Under the assumption of self-similarity, the Einstein equations reduce to a system of ordinary differential equations, which we solve numerically under boundary conditions enforcing the existence of a minimal areal radius (the throat) on constant-time hypersurfaces. For a sufficiently large throat radius, the resulting geometries remain regular at both spatial and future null infinity, while a singularity is retained in the past direction. We then construct a dynamical formation scenario by patching together three regions: a Schwarzschild black hole, negative-energy Vaidya spacetimes, and the self-similar wormhole geometry. These regions are joined across null shells using the Barrabes--Israel formalism, which provides explicit relations among the throat radius, the black hole's mass and the energy injection by the shell, demonstrating that an initial black hole can evolve into a wormhole. Our analysis generalizes the formation model for static wormhole solutions proposed by Hayward and Koyama in 2004 to non-static wormhole solutions, offering a novel perspective on the formation of regular traversable wormholes.

</details>


### [240] [Harmonic Analysis on Correlation for Gravitational-Wave Backgrounds of Arbitrary Polarization from Interfering Sources in Generic Dispersion Relation](https://arxiv.org/abs/2602.13621)
*Yan-Chen Bi,Yu-Mei Wu,Qing-Guo Huang*

Main category: gr-qc

TL;DR: 论文研究了脉冲星计时阵列中引力波背景的空间相关性，发现离散源干涉会改变相关性形状，但保留各极化模式的最低非零多极矩，这限制了仅通过空间相关性区分修正引力和广义相对论的能力。


<details>
  <summary>Details</summary>
Motivation: Hellings-Downs相关性是广义相对论中脉冲星计时阵列探测引力波背景的基本基准，但它基于连续源的理想化假设。在实际天体物理场景中，超大质量黑洞双星等离散源之间的干涉会引入空间相关性的内在偏差，可能模拟或掩盖修正引力的特征。

Method: 推导了具有任意极化和通用引力波色散关系的引力波背景在源干涉存在下的闭式空间相关函数，通过严格的谐波分析研究干涉效应，并量化干涉引起的变异与修正引力特征之间的统计简并性。

Result: 源干涉会改变相关性形状，但严格保留了各极化模式的最低非零多极矩特征：张量模式的四极矩、矢量模式的偶极矩、标量模式的单极矩。高阶多极矩的截断由脉冲星距离和色散效应之间的相互作用决定。

Conclusion: 由于只能观测到宇宙的单一实现，仅通过空间相关性来区分修正引力和广义相对论存在根本性的理论限制，干涉效应与修正引力特征之间存在统计简并性。

Abstract: The Hellings-Downs (HD) correlation serves as the fundamental benchmark for detecting the gravitational-wave background (GWB) in pulsar timing arrays (PTAs) within General Relativity (GR). However, this canonical signature relies on the idealization of a continuum of sources without interference. In realistic astrophysical scenarios dominated by supermassive black hole binaries (SMBHBs), interference between discrete sources induces intrinsic deviations in the spatial correlation, which may mimic or obscure signatures of modified gravity. In this work, we derive the closed-form spatial correlation functions for a GWB with arbitrary polarization and generic GW dispersion relations, in the presence of source interference. Through a rigorous harmonic analysis, we demonstrate that source interference modifies the correlation shape but strictly preserves the lowest non-vanishing multipole moment characteristic of each polarization, specifically the quadrupole for tensor, dipole for vector, and monopole for scalar modes. The truncation at higher-order multipoles is governed by the interplay between pulsar distances and dispersion effects. Furthermore, we quantify the statistical degeneracy between interference-induced variation and modified gravity signatures. We conclude that access to only a single realization of the Universe imposes a fundamental theoretical limit on distinguishing modified gravity from GR using spatial correlations alone.

</details>


### [241] [Spherically symmetric black holes in Gravity from Entropy and spontaneous emission](https://arxiv.org/abs/2602.13694)
*Udaykrishna Thattarampilly,Yunlong Zheng,Vishnu Kakkat*

Main category: gr-qc

TL;DR: 该论文在熵引力框架下研究了静态和动态球对称黑洞解，发现经典史瓦西几何会收到r^{-4}尺度的微扰修正，该框架与当前强场天体物理观测一致，并预测了黑洞的质量演化规律。


<details>
  <summary>Details</summary>
Motivation: 研究熵引力框架下的静态和动态球对称黑洞解，探索经典广义相对论之外的引力理论如何描述黑洞物理，特别是黑洞质量演化和霍金辐射的经典对应。

Method: 在熵引力框架下推导并求解静态球对称时空的修正真空场方程，分析黑洞几何的微扰修正，研究高阶几何应力驱动的质量演化规律。

Result: 发现经典史瓦西几何会收到r^{-4}尺度的微扰修正；熵引力框架与当前强场天体物理观测一致；高阶几何应力驱动一致的质量演化剖面；大质量黑洞极限下预测恒定的背景蒸发率-β/24；中等尺度下通过修正背景的纯经典响应复制标准的霍金辐射质量损失定律。

Conclusion: 熵引力框架为黑洞物理提供了新的视角，能够自然地描述黑洞质量演化，包括霍金辐射的经典对应和"熵泄漏"现象，为超越经典广义相对论的引力理论提供了观测一致的候选方案。

Abstract: We investigate static and dynamical spherically symmetric black hole solutions within the Gravity from Entropy (GfE) framework. We derive and solve the modified vacuum field equations for a static, spherically symmetric spacetime, revealing that the classical Schwarzschild geometry receives perturbative corrections scaling as $r^{-4}$. We establish that the GfE framework is consistent with current strong-field astrophysical observations. Higher-order geometric stresses inherent to the GfE vacuum drive a consistent mass-evolution profile. In the limit of large black hole mass, the theory predicts a constant background evaporation rate $ -β/24$, suggesting an inherent "entropic leakage" of the vacuum. At intermediate scales, the framework replicates the standard Hawking radiation mass-loss law as $\dot{M} \propto M^{-2}$ through a purely classical response of the modified background.

</details>


### [242] [Reconstruction of Accelerating Nonlinear $f(T)$ Gravity Models via Hybrid Scale Factor: Cosmological Dynamics and Bayesian Evidence](https://arxiv.org/abs/2602.13744)
*Suraj Kumar Behera,Pratik P. Ray*

Main category: gr-qc

TL;DR: 该研究使用混合尺度因子重建了三种不同的非线性f(T)引力模型，通过MCMC方法约束参数，验证了模型与宇宙加速膨胀观测的一致性，并发现这些模型在晚期能有效模拟ΛCDM模型。


<details>
  <summary>Details</summary>
Motivation: 研究f(T)引力理论作为广义相对论的可能扩展，解释宇宙从早期减速到晚期加速膨胀的演化历史，探索暗能量主导的宇宙加速机制。

Method: 使用混合尺度因子重建三种非线性f(T)引力模型；采用贝叶斯统计和MCMC方法，结合BAO和Patheon+SH0ES晚期观测数据约束模型参数；分析状态方程参数和宇宙学参数；评估能量条件特别是强能量条件的违反情况。

Result: 模型参数得到严格约束；动力学参数显示与当前和晚期加速膨胀阶段一致；能量条件分析验证了模型的可行性，特别是强能量条件的违反表明暗能量主导；重建模型在晚期能有效模拟ΛCDM模型。

Conclusion: 重建的f(T)引力模型与宇宙学观测和理论要求一致，为广义相对论的可能扩展提供了重要见解，支持f(T)引力理论作为宇宙加速膨胀的稳健解释。

Abstract: This study offers a comprehensive reconstruction of $f(T)$ gravity model with three distinct non-linear as well as novel forms employing a hybrid scale factor to depict the expansion history of the universe starting from early decelerated epoch to late-time accelerated evolution. Model parameters are rigorously constrained using the Monte Carlo Markov Chain (MCMC) analysis with the help of Bayesian statistics and incorporating late-time observations from BAO and Patheon+SH0ES. The investigation of dynamical parameters such as the equation of state parameter and cosmological parameters indicates alignment with an accelerated expansion phase in both the present and late time epochs. Validation is conducted by assessing the energy conditions, verifying the feasibility of the model forms with particular emphasis on the violation of the strong energy condition that indicates dark energy dominance in modified gravity scenarios. This investigation has been instrumental in determining models that remain consistent with cosmological observations and theoretical requirements. The reconstructed forms of the model effectively mimic $Λ$CDM at late times, providing significant insights into possible extensions of general relativity and bolstering $f(T)$ gravity theory as a robust explanation for cosmic acceleration.

</details>


### [243] [Bounding the graviton mass using non-linear density wave theory](https://arxiv.org/abs/2602.13854)
*M. Vukcevic*

Main category: gr-qc

TL;DR: 使用非线性密度波理论和修正的牛顿引力势，通过非线性波的波长作为引力子康普顿波长，获得了引力子质量的新上限，与LIGO/Virgo结果一致。


<details>
  <summary>Details</summary>
Motivation: 现有引力子质量限制方法有限，需要独立的新方法来验证引力子质量上限。本文提出使用非线性密度波理论，通过修正的牛顿引力势获得完全独立于现有方法的引力子质量限制。

Method: 使用非线性效应修正的牛顿引力势，结合非线性密度波理论，将非线性波的波长定义为引力子的康普顿波长。通过求解可积非线性微分方程（非线性薛定谔方程）获得解析解，从而确定引力子质量的上限。

Result: 获得了引力子质量的新上限，与LIGO和Virgo合作组首次评估的结果高度一致。该结果与多个已发表方法的结果进行了比较验证。

Conclusion: 提出的非线性密度波理论方法为引力子质量限制提供了完全独立的新途径，结果与现有实验数据吻合良好，验证了方法的有效性。

Abstract: In this paper we use the Newtonian gravitational potential corrected by non-liner effects to obtain new bounds on graviton mass using non-linear density wave theory (NLDW). This potential differs from the gravitational potential obtained in other modified gravity theories (e.g. the weak field limit of Yukawa gravity, Modified Newtonian Dynamics, non-local theories, $Λ$ cold dark matter..). Using this model, we are able to define wavelength of the non-linear wave as an analytical solution of integrable non-linear differential equation (namely, non-linear Schrodinger equation). Assuming that the wavelength of the non-linear wave represents the graviton Compton wavelength, we have found the corresponding upper bound of graviton mass. We compare obtained result with first assessments of LIGO $\&$ Virgo collaboration and we find they are in a good agreement. Present model used to determine the upper limit of graviton mass is completely independent from other methods published until now. We have compared our result with results obtained using several chosen published methods.

</details>


### [244] [Hidden Conformal Symmetry and Emergent Holographic Structure in the AdS Teo Rotating Wormhole](https://arxiv.org/abs/2602.13923)
*Ramesh Radhakrishnan,Gerald B. Cleaver,William Julius*

Main category: gr-qc

TL;DR: 论文研究了嵌入渐近反德西特时空的旋转Teo虫洞的标量扰动，发现径向克莱因-戈登方程具有涌现的共形结构，虫洞喉部导致了对数乌龟坐标，使径向方程可重写为二次卡西米尔本征值方程。


<details>
  <summary>Details</summary>
Motivation: 研究旋转Teo虫洞在AdS背景下的标量扰动，探索无视界几何中的隐藏共形对称性，与旋转Kerr黑洞的隐藏共形对称性进行对比，理解虫洞连接的两个AdS边界之间的因果关系。

Method: 使用径向克莱因-戈登方程分析标量扰动，引入对数乌龟坐标将方程重写为二次卡西米尔本征值方程，构建近喉部生成元，推导有效势，应用AdS边界条件和喉部正则性条件获得准正规模谱。

Result: 发现旋转Teo虫洞具有涌现的共形结构，获得离散的准正规模谱，通过大Δ极限下的等时两点函数计算，展示了虫洞几何如何耦合两个渐近边界，提供了虫洞的微全息解释。

Conclusion: 该研究为旋转、无视界的渐近AdS虫洞提供了统一的描述框架，涵盖了隐藏共形结构、谱特性和边界关联函数，展示了虫洞几何中涌现的共形对称性及其在全息对应中的应用。

Abstract: We study scalar perturbations of the rotating Teo wormhole embedded in asymptotically Anti-de Sitter (AdS) spacetime and demonstrate that the radial Klein Gordon equation exhibits an emergent conformal structure. The smooth traversable throat induces a logarithmic tortoise coordinate that allows the radial equation to be recast as the quadratic Casimir eigenvalue equation, paralleling the hidden conformal symmetry of the rotating Kerr black hole but arising here in a horizonless geometry. The AdS-Teo spacetime possesses two disconnected timelike AdS conformal boundaries that remain causally connected through the wormhole throat, in contrast to the two-sided eternal AdS black hole where horizons play a central role. Using the emergent conformal symmetry, we construct the near-throat generators, derive the effective potential, and obtain a discrete quasinormal-mode spectrum determined by regularity at the throat and standard AdS boundary conditions at infinity. The AdS embedding further enables a minimal holographic interpretation. As an explicit illustration, we compute an equal-time two-point function in the large-Delta (geodesic) limit from a regulated spacelike geodesic that traverses the wormhole, showing how the bulk geometry couples the two asymptotic boundaries. Together, these results provide a unified description of hidden conformal structure, spectral properties, and boundary correlators in a rotating, horizonless asymptotically AdS wormhole.

</details>


### [245] [Torsion-Induced Quantum Fluctuations in Metric-Affine Gravity using the Stochastic Variational Method](https://arxiv.org/abs/2602.13927)
*Tomoi Koide,Armin van de Venn*

Main category: gr-qc

TL;DR: 该综述论文从度量仿射引力和随机变分法角度，系统研究了空间挠率对量子涨落的影响，揭示了挠率如何通过量子涨落影响无自旋自由度，并在薛定谔方程中引入非线性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为挠率只影响自旋自由度，但本文旨在探索挠率如何通过量子涨落影响更广泛的物理系统，特别是无自旋自由度，并研究挠率与曲率在量子力学非线性中的竞争关系。

Method: 结合度量仿射引力理论（包含挠率和非度量性）和随机变分法（能够有效纳入几何效应的量子化技术），通过理论框架整合来分析挠率对量子涨落的影响。

Result: 发现挠率不仅影响自旋自由度，还能通过量子涨落影响无自旋自由度；挠率在薛定谔方程中引入非线性，并与Levi-Civita曲率存在竞争关系；揭示了随机变分法与信息几何之间的结构平行性。

Conclusion: 挠率通过量子涨落对量子力学产生深远影响，包括引入非线性和影响无自旋自由度。这些发现为包含非度量性的引力理论扩展铺平道路，有望加深对未解决宇宙学问题的理解。

Abstract: This review paper comprehensively examines the influence of spatial torsion on quantum fluctuations from the perspectives of Metric-Affine Gravity (MAG) and the Stochastic Variational Method (SVM). We first outline the fundamental framework of MAG, a generalized theory that includes both torsion and non-metricity, and discuss the geometrical significance of torsion within this context. Subsequently, we summarize SVM, a powerful technique that facilitates quantization while effectively incorporating geometrical effects. By integrating these frameworks, we evaluate how the geometrical structures originating from torsion affect quantum fluctuations, demonstrating that they induce non-linearity in quantum mechanics. Notably, torsion, traditionally believed to influence only spin degrees of freedom, can also affect spinless degrees of freedom via quantum fluctuations. Furthermore, extending beyond the results of previous work [Koide and van de Venn, Phys. Rev. A112, 052217 (2025)], we investigate the competitive interplay between the Levi-Civita curvature and torsion within the non-linearity of the Schrödinger equation. Finally, we discuss the structural parallelism between SVM and information geometry, highlighting that the splitting of time derivatives in stochastic processes corresponds to the dual connections in statistical manifolds. These insights pave the way for future extensions to gravity theories involving non-metricity and are expected to deepen our understanding of unresolved cosmological problems.

</details>


### [246] [The Theoretical Landscape of Mimetic Gravity: A Comprehensive Review](https://arxiv.org/abs/2602.14082)
*O. Malaeb*

Main category: gr-qc

TL;DR: 这篇综述全面回顾了拟态引力理论及其在宇宙学和高能物理中的应用，包括原始公式、与广义相对论的等价性问题、宇宙学模型构建、奇点解决机制、稳定性挑战及早期宇宙应用。


<details>
  <summary>Details</summary>
Motivation: 拟态引力最初是为了分离引力场的共形自由度而提出的，它通过重新参数化物理度规，自然地产生了一个模拟冷暗物质行为的纵向自由度，为引力理论和宇宙学提供了新的框架。

Method: 通过将物理度规用辅助度规和标量场重新参数化，利用奇异的disformal变换引入新的物理自由度；扩展到f(R,φ)引力以重建任意膨胀历史；采用f(□φ)修正实现"极限曲率"假说；通过无鬼拟态大质量引力和Hořava引力的协变公式解决稳定性问题。

Result: 拟态引力能够统一描述暗物质行为，重建任意宇宙膨胀历史，经典地解决宇宙学和黑洞奇点问题，并在早期宇宙中解决暴胀的自繁殖问题，但存在梯度不稳定性和鬼不稳定性等挑战。

Conclusion: 拟态引力是一个有前景的广义相对论扩展框架，在宇宙学模型构建和奇点解决方面展现出强大能力，但需要解决稳定性问题才能成为完全自洽的理论，未来研究应关注其量子引力含义和观测检验。

Abstract: Mimetic gravity has emerged as a compelling extension of General Relativity (GR), originally motivated by the attempt to isolate the conformal degree of freedom of the gravitational field. By reparametrizing the physical metric in terms of an auxiliary metric and a scalar field, the theory naturally gives rise to a longitudinal degree of freedom that mimics the behavior of cold dark matter. This review provides a comprehensive survey of the theoretical landscape of mimetic gravity and its multifaceted applications to cosmology and high-energy physics. We begin by examining the original formulation and addressing the fundamental question of its equivalence to GR, highlighting how a singular disformal transformation introduces new physical degrees of freedom. We then explore minimal generalizations that lead to unified cosmological models, including mimetic matter scenarios and extensions into $f(R, φ)$ gravity, which allow for the reconstruction of any desired expansion history. Significant attention is given to the ``limiting curvature'' hypothesis through $f(\Box φ)$ modifications, providing a classical mechanism for resolving cosmological and black hole singularities. We critically assess the challenges facing the theory, specifically the gradient and ghost instabilities identified in cosmological perturbations, and discuss modern resolutions such as ghost-free mimetic massive gravity and covariant formulations of Hořava gravity. Finally, we discuss the role of the mimetic field in the early universe, specifically in the context of asymptotically free gravity and the resolution of the self-reproduction problem in inflation.

</details>


### [247] [On the Cuspy Structure of Rotating Wormhole Shadows](https://arxiv.org/abs/2602.14182)
*Peng Cheng,Ruo-Fan Xu,Peng Zhao*

Main category: gr-qc

TL;DR: 研究Teo类旋转可穿越虫洞的阴影形状，特别关注尖点结构的出现，发现阴影形态随红移参数变化呈现四种不同形态。


<details>
  <summary>Details</summary>
Motivation: 研究旋转可穿越虫洞的阴影形态，特别是尖点结构的形成机制，为未来高分辨率天文观测提供区分不同致密天体的诊断工具。

Method: 分析Teo类旋转可穿越虫洞的阴影边界，将其视为两个临界轨道族的共同包络：喉部外的圆形不稳定轨道和喉部本身的轨道，研究红移参数λ对阴影形态的影响。

Result: 发现阴影边界尖点的形成需要红移参数λ变化，存在一个普适临界值λ_c标志尖点开始出现；通过自旋和红移参数构建的相图揭示了四种不同阴影形态：平滑、尖点、耳朵接触和喉部淹没。

Conclusion: 虫洞阴影的形态特征（特别是尖点结构）可作为未来高分辨率成像观测中区分不同致密天体的观测诊断工具。

Abstract: We investigate the shadow cast by a rotating traversable wormhole in the Teo class endowed with a general redshift function, with particular emphasis on the emergence of cuspy structures. The shadow boundary is the common envelope of two critical orbit families: unstable circular orbits outside the throat and orbits at the throat itself. The formation of cusps, marking the transition between smooth and cuspy shadow boundaries, only becomes possible when the redshift parameter $λ$ is allowed to vary. Moreover, we uncover a universal critical value $λ_c$ that signals the onset of the cusp. A phase diagram characterized by the spin and redshift parameters reveals four distinct morphologies: smooth, cuspy, ears touching, and throat drowning. The morphology of the wormhole shadow may provide observational diagnostics for the different compact objects in future high-resolution imaging observations.

</details>


### [248] [The initial states of high frequency gravitons](https://arxiv.org/abs/2602.14235)
*Massimo Giovannini*

Main category: gr-qc

TL;DR: 论文区分经典与量子不均匀性在宇宙背景中的作用，约束遗迹引力子在波长跨越共动哈勃半径时的初始态，发现低频区可存在非真空初始态，而中高频区主要由真空产生引力子主导。


<details>
  <summary>Details</summary>
Motivation: 研究遗迹引力子的初始状态如何影响宇宙学背景下的引力波谱，特别是区分经典和量子不均匀性的作用，以理解引力子在跨越哈勃半径时的量子态演化。

Method: 采用实用主义视角，在引力子波长跨越共动哈勃半径时约束其初始态，不参考更早的时间尺度。分析有限能量密度的量子态如何一致地影响两点函数和相关功率谱。

Result: 低频区（对应最大可观测波长）允许存在非真空初始态，而中高频区的引力子谱主要由真空产生主导。kHz到THz范围内的非经典相关性占主导，因为该区域引力子主要通过量子力学过程产生，初始态贡献可忽略。

Conclusion: 遗迹引力子的初始态在低频区可能偏离真空态，而中高频区主要由量子真空产生过程决定。kHz-THz频段的非经典相关性为探测引力子的量子起源提供了重要窗口。

Abstract: After distinguishing the role of classical and quantum inhomogeneities in cosmological backgrounds, we constrain the initial states of the relic gravitons as soon as the different wavelengths of the spectrum cross the comoving Hubble radius, without any reference to earlier timescales. According to this pragmatic perspective the quantum states with finite energy density at the crossing time consistently affect the two-point functions and the related power spectra. An initial state different from the vacuum turns out to be marginally permitted in the low frequency range (associated with the largest observable wavelengths that crossed the comoving Hubble radius) while the intermediate and high frequency domains of the spectrum are populated by the gravitons produced from the vacuum. The non classical correlations are expected to dominate between the kHz and the THz since in this region gravitons are produced quantum mechanically with a negligible contribution from the initial state.

</details>


### [249] [A synthetic Gannon-Lee incompleteness theorem](https://arxiv.org/abs/2602.14246)
*Mathias Braun,Carlo Rotolo*

Main category: gr-qc

TL;DR: 论文将Gannon-Lee不完备性定理推广到加权情况，适用于满足合成零能量条件和"合成渐近正则"陷获条件的全局双曲时空


<details>
  <summary>Details</summary>
Motivation: 将经典的Gannon-Lee不完备性定理推广到更一般的加权情况，并为低正则性扩展提供理论基础

Method: 假设Ketterer的合成零能量条件和作者提出的"合成渐近正则"陷获条件，证明全局双曲时空中的不完备性定理

Result: 成功证明了加权情况下的Gannon-Lee不完备性定理，将经典结果推广到更一般的时空结构

Conclusion: 该工作为低正则性扩展奠定了基础，相关扩展将留待未来研究，表明该理论框架具有进一步发展的潜力

Abstract: We prove the Gannon-Lee incompleteness theorem for globally hyperbolic spacetimes. We assume the synthetic null energy condition of Ketterer and a trappedness condition we call "synthetically asymptotically regular". Our result generalizes this classical result to the weighted case. It also motivates and indicates extensions to low regularity, which are deferred to future work.

</details>


### [250] [$Λ(t)$CDM Model: Cosmological Implications and Dynamical System Analysis](https://arxiv.org/abs/2602.14269)
*Himanshu Chaudhary,Ratul Mandal,Masroor Bashir,Vipin Kumar Sharma,Ujjal Debnath*

Main category: gr-qc

TL;DR: 使用DESI DR2的BAO测量、Ia型超新星样本和CMB位移参数约束时变宇宙学常数模型，发现相互作用项Q(z)在低红移和高红移处符号相反，表明真空能量与暗物质之间的能量转移方向随宇宙演化而改变。


<details>
  <summary>Details</summary>
Motivation: 研究时变宇宙学常数模型Λ(t)CDM，探索暗能量与暗物质之间的相互作用如何随宇宙时间演化，并检验该模型相对于标准ΛCDM模型的优越性。

Method: 结合DESI DR2的BAO测量、Pantheon⁺、DES-Dovekie和Union3超新星样本以及CMB位移参数，通过马尔可夫链蒙特卡洛分析约束Λ(t)CDM模型参数，并进行动力系统分析研究临界点稳定性。

Result: 相互作用项Q(z)在所有数据集组合中均显示符号变化：低红移时Q(z)<0（真空能量衰变为暗物质），高红移时Q(z)>0（暗物质衰变为真空能量）。模型预测ω₀ > -1，支持动力学暗能量而非宇宙学常数，并预测宇宙加速转变发生在N≈-0.51到-0.48之间，当前减速参数q₀在-0.54到-0.52之间。

Conclusion: Λ(t)CDM模型比标准ΛCDM模型更受贝叶斯证据支持，表明时变宇宙学常数能更好地描述观测数据，暗能量与暗物质之间的相互作用在宇宙演化中扮演重要角色。

Abstract: We investigated a time-varying cosmological constant model using recent BAO measurements from DESI DR2, combined with Type Ia supernova samples (Pantheon$^{+}$, DES-Dovekie, and Union3) and CMB shift parameters, to constrain the $Λ(t)$CDM model parameters via Markov Chain Monte Carlo analysis. We find that the interaction term $Q(z)$ shows a sign change for all dataset combinations by crossing $Q(z)=0$, depending on the choice of the dataset: at low redshift $Q(z)<0$, indicating vacuum energy decaying into dark matter, while at high redshift $Q(z)>0$, corresponding to dark matter decaying into vacuum energy. The dynamical system analysis found three critical points, namely $P_1,P_2$, and $P_3$ respectively. The resulting critical points, determined by the underlying cosmological parameters, correspond to distinct epochs in cosmic evolution. Depending on the parameter combinations, these points characterize various cosmological phases, ranging from an accelerated stiff matter-dominated era to late-time accelerated expansion. The stability of each critical point is analyzed using linear stability theory, with the relevant physical constraints on the cosmological parameters duly incorporated throughout the analysis. For each dataset combinations, the $Λ(t)$CDM model predicts that $ω_0 > -1$, showing a preference for dynamical dark energy over the cosmological constant scenario with $ω_0 = -1$. Consequently, the model exhibits a transition phase in the range $N \equiv \log a(t) \approx -0.51$ to $-0.48$ and predicts $q_0$ in the range $-0.54$ to $-0.52$, with the precise transition point depending on the choice of dataset. Finally, the Bayesian evidence shows strong support for the $Λ(t)$CDM model over $Λ$CDM

</details>


### [251] [Quantum Geometry Effects in Quantum Field Theory: Hamiltonian constraint Generates Gravity-Matter Entanglement](https://arxiv.org/abs/2602.14282)
*Gaoping Long,Cong Zhang*

Main category: gr-qc

TL;DR: 在弯曲时空量子场论中，基于圈量子引力建立了一个一致框架，定义了量子几何与物质态的叠加，推导了量子哈密顿约束的弱解，并将Hartle-Hawking真空态推广到量子几何框架。


<details>
  <summary>Details</summary>
Motivation: 解决弯曲时空量子场论的基础性挑战，为研究几何-物质纠缠建立原则性框架，为黑洞信息悖论的量子基础提供新见解。

Method: 在圈量子引力框架内，通过识别引力相空间的受限子空间，确保标量场在不同量子几何下的Fock表象之间的幺正等价性，从而定义量子几何与物质态的叠加。

Result: 建立了定义良好的态空间，推导了广义相对论量子哈密顿约束的弱解，将Hartle-Hawking真空态推广到量子几何框架，揭示了由量子哈密顿约束产生的几何与物质之间的固有纠缠。

Conclusion: 这项工作为研究几何-物质纠缠建立了原则性框架，为黑洞信息悖论的量子基础提供了新见解，推进了弯曲时空量子场论的发展。

Abstract: In this paper, we address a foundational challenge in quantum field theory on curved spacetime by developing a consistent framework within loop quantum gravity. We introduce a methodology for defining meaningful superpositions of quantum geometry and matter states. This is achieved by identifying a restricted subspace of the gravitational phase space, which ensures unitary equivalence among Fock representations of a scalar field across different quantum geometries. Within the resulting well-defined state space, we derive weak solutions to the quantum Hamiltonian constraint of general relativity. Furthermore, we generalize the Hartle-Hawking vacuum state to this quantum geometric framework. The resulting state exhibits the inherent entanglement between geometry and matter, which arises from the quantum Hamiltonian constraint of general relativity. This work establishes a principled framework for studying geometry-matter entanglement and offers new insights into the quantum foundations of the black hole information paradox.

</details>


### [252] [Local Short-Time Acceleration and deSitter Spacetime induced Extra Spectral Broadening: a Simple Interpretation of Modified Inertial in MOND](https://arxiv.org/abs/2602.14515)
*M. J. Luo*

Main category: gr-qc

TL;DR: 论文提出了一种新的量子效应：局部短时加速会导致粒子谱额外展宽，这为修正牛顿动力学（MOND）的修正惯性解释提供了简单的运动学解释框架。


<details>
  <summary>Details</summary>
Motivation: 为MOND的修正惯性解释提供量子理论基础，统一解释宇宙加速膨胀和星系旋转曲线异常现象，将经典等效原理扩展到量子涨落层面。

Method: 提出局部短时非均匀加速的量子效应，将Unruh效应的热黑体谱（来自长时间均匀加速）推广到短时非均匀加速情形，建立量子等效原理。

Result: 该效应为MOND的加速度插值关系提供了简单的运动学解释，能够统一描述宇宙加速膨胀和星系旋转曲线异常，并需要量子等效原理作为物理基础。

Conclusion: 局部短时加速的量子效应为MOND提供了量子理论基础，将经典等效原理扩展到二阶矩量子涨落层面，在量子参考系和量子引力框架中具有重要意义。

Abstract: This paper proposes a novel quantum effect wherein particle spectra show extra broadening due to local short-time acceleration (as well as in a deSitter spacetime background). This effect provides a simple interpretation for the acceleration interpolation relation required to modify the kinematics of a test particle in the Modified Inertial interpretation of Modified Newtonian Dynamics (MOND). This effect can be regarded as a generalization of the thermal blackbody spectrum generated by the Unruh effect (which arises from long-time uniform acceleration in a flat background) to the scenario of local short-time non-uniform acceleration. This effect offers a unified framework for understanding the accelerated expansion of the universe and the anomalies in galactic rotation curves or radial acceleration. It is worth emphasizing that this modified kinematic interpretation of MOND necessitates a quantum equivalence principle as its physical foundation, that is, extending the equivalence at the level of expectation values (first-order moments) in the classical equivalence principle to the equivalence at the level of second-order moment quantum fluctuations. Therefore, the role of this effect within the frameworks of quantum reference frames and quantum gravity is also discussed to some extent.

</details>


### [253] [The initial data of effective field theories of relativistic viscous fluids and gravity](https://arxiv.org/abs/2602.14541)
*Lorenzo Gavassino,Áron D. Kovács,Harvey S. Reall*

Main category: gr-qc

TL;DR: 提出一种"降阶"方法处理相对论粘性流体力学和引力有效场论中的非物理自由度，通过初始数据而非运动方程来唯一确定非物理模式的数据


<details>
  <summary>Details</summary>
Motivation: 相对论粘性流体力学和引力有效场论都引入了非物理自由度，需要解决如何处理这些非物理模式的问题

Method: 提出"降阶"方法，在初始数据层面而非运动方程层面应用，唯一确定非物理模式数据与物理模式数据的关系

Result: 该方法能够明确处理非物理自由度，同时保持洛伦兹不变性在有效场论假设明显成立的参考系中有效

Conclusion: 通过初始数据降阶方法可以合理处理理论中的非物理自由度，相关的洛伦兹不变性破缺在有效场论框架内不是问题

Abstract: There has been recent progress in developing well-posed theories of relativistic viscous hydrodynamics and of gravitational effective field theories. These have in common the feature that they introduce unphysical degrees of freedom. We address the problem of how these should be treated. We propose a ''reduction of order'' approach which is applied not at the level of equations of motion but only to initial data. This specifies uniquely the data for the unphysical modes in terms of the data for the physical modes. We argue that the apparent breaking of Lorentz invariance associated with this approach is not a problem provided one restricts to Lorentz frames for which the assumptions of effective field theory are manifestly valid.

</details>


### [254] [Investigating the impact of quasi-universal relations on neutron star constraints in third-generation detectors](https://arxiv.org/abs/2602.14659)
*Natalie Williams,Anna Puecher,Guilherme Grams,César V. Flores,Tim Dietrich*

Main category: gr-qc

TL;DR: 研究探讨引力波分析中准普适关系（如Love-Q关系、基频-潮汐形变关系、二元Love关系）可能引入的偏差，发现这些偏差在第三代引力波探测器时代可能影响致密物质状态方程的测量精度。


<details>
  <summary>Details</summary>
Motivation: 通过双中子星系统的引力波观测可以揭示未知的致密物质状态方程，但分析中常用的准普适关系并非精确关系，可能引入不确定性和偏差，特别是在第三代引力波探测器时代需要评估这些偏差的影响。

Method: 研究评估了三种准普适关系在引力波分析中的潜在偏差：(1) 连接自旋诱导四极矩与潮汐形变能力的Love-Q关系；(2) 基频与潮汐形变能力的关系；(3) 二元Love关系。分析了这些关系在不同条件下的偏差程度。

Result: 发现四极矩关系仅在快速旋转系统中存在偏差；二元Love关系在次主导阶潮汐参数中引入中等偏差，可能传播到低质量状态方程推断中；基频关系引入的偏差可忽略不计，但波形系统效应相对较大。

Conclusion: 准普适关系在引力波分析中仍是有用工具，但需要谨慎处理以避免在下一代探测器测量状态方程时产生偏差，特别是在快速旋转系统和低质量区域。

Abstract: Gravitational-wave observations of binary neutron star systems can shed light on the currently unknown dense matter equation of state. The equation of state determines a large number of neutron star properties, such as tidal deformability, radius, and quadrupole moment, several of which directly affect the emitted gravitational-wave signals. To reduce the dimensionality when computing gravitational-waves and when interpreting observational data, quasi-universal relations are commonly employed to connect different neutron star properties. However, quasi-universal relations are not exact and their use may introduce uncertainty and bias. We explore the potential biases arising from different quasi-universal relations in the third generation era: (i) the Love-Q relation connecting the spin-induced quadrupole moment and the tidal deformability, (ii) the relation between the fundamental mode frequency and the tidal deformability, and (iii) the binary Love relation. We find that for the quadrupole relation biases are only present for rapidly rotating systems, for the binary-Love relation induces moderate biases only in the next-to-leading-order tidal parameters, which can however propagate into the inferred equation of state at low masses. Regarding fundamental mode frequencies, we find that the employed relation introduces only negligible biases, while waveform systematic effects can become comparatively large. Our results highlight that while quasi-universal relations remain a useful tool within gravitational-wave analyses, careful treatment is needed to avoid biases in equation of state measurements with next-generation detectors.

</details>


### [255] [Diffeomorphism Invariant Formulation of CP Violation](https://arxiv.org/abs/2602.14723)
*Alibordi Muhammad*

Main category: gr-qc

TL;DR: 论文指出标准CP破坏表述与广义相对论微分同胚不变性之间存在根本矛盾，提出基于相对熵的信息几何框架来重新解释Sakharov条件


<details>
  <summary>Details</summary>
Motivation: 标准CP破坏的有效哈密顿量方法依赖于优先时间分层，这与广义协变性不兼容。在曲率大的原点附近，质量和相位的定义变得不明确，需要与广义相对论兼容的新框架

Method: 提出基于相对熵的信息几何框架，利用粒子和反粒子希尔伯特空间中的纯量子态，将CP破坏重新解释为信息几何量

Result: 展示了Sakharov条件可以重新解释为信息几何量，但完整的现象学实现仍有待开发

Conclusion: 标准CP破坏表述与广义相对论存在根本矛盾，信息几何框架为解决这一矛盾提供了新途径，但需要进一步研究来实现完整的现象学应用

Abstract: We identify a fundamental tension between the standard formulation of CP violation and diffeomorphism invariance in general relativity. The effective Hamiltonian approach, while phenomenologically successful, relies on a preferred time foliation that is incompatible with general covariance. The CP-violating phases are scalars along the worldline of the decaying parent particle; however, the definition of masses and phases presupposes a local covariant structure, which becomes ill-defined near the origin where curvature is large and metric fluctuations become significant. We propose an information-geometric framework based on relative entropy, exploiting pure quantum states in particle and antiparticle Hilbert spaces. We show how the Sakharov conditions could be reinterpreted in terms of information-geometric quantities, although a fully rigorous phenomenological implementation remains to be developed.

</details>


### [256] [FLRW-Cosmology in Scalar-Vector-Tensor Theories of Gravity](https://arxiv.org/abs/2602.14808)
*Metin Gürses,Yaghoub Heydarzade*

Main category: gr-qc

TL;DR: 该研究将先前在FLRW时空中无物质场情况下广义引力理论场方程简化为爱因斯坦场方程的结果，推广到包含标量场和矢量场的情况，证明了场方程仍然等价于具有完美流体源的爱因斯坦场方程。


<details>
  <summary>Details</summary>
Motivation: 先前研究证明了在无物质场情况下，任何广义引力理论的场方程都可以简化为具有有效完美流体源的爱因斯坦场方程。本研究旨在将这一结果推广到包含标量场和矢量场的情况，检验在更一般的物质场存在下是否仍然成立。

Method: 将标量场和矢量场纳入广义引力理论框架，分析场方程的简化形式。通过显式检验最近发展的爱因斯坦-标量场理论和爱因斯坦-普罗卡场理论来验证结果。

Result: 即使包含标量场和矢量场，广义引力理论的场方程仍然等价于具有完美流体分布的爱因斯坦场方程。这一结果通过爱因斯坦-标量场和爱因斯坦-普罗卡场理论的具体检验得到验证。

Conclusion: 在FLRW时空中，广义引力理论（包括标量场和矢量场）的场方程可以统一地简化为具有完美流体源的爱因斯坦场方程形式，这为研究各种引力理论提供了统一的框架。

Abstract: We generalize our previous theorem for FLRW spacetime within the framework of generic metric gravity theories. In our earlier work, we demonstrated that, in the absence of matter fields, the field equations of any generic gravity theory reduce to the Einstein field equations with an effective perfect fluid source. In the present study, we extend this analysis by incorporating scalar and vector fields into a generic gravity theory and show that the resulting field equations remain equivalent to the Einstein field equations with a perfect fluid distribution. We further verify our findings by explicitly examining recently developed Einstein-scalar and Einstein-Proca field theories.

</details>


### [257] [Tarnished by Tools: Cost of Systematics in Golden Dark Siren Cosmology](https://arxiv.org/abs/2602.14898)
*Giovanni Benetti,Koustav Chandra,Bangalore S. Sathyaprakash*

Main category: gr-qc

TL;DR: 黄金暗警报（无电磁对应体的精确定位引力波源）有望在下一代探测器时代精确测量哈勃常数，但波形建模和探测器校准的系统误差可能主导统计不确定性，影响红移分配和H0测量精度。


<details>
  <summary>Details</summary>
Motivation: 黄金暗警报作为下一代引力波探测器测量哈勃常数的强大工具，其统计潜力受到波形精度和探测器校准系统误差的限制，需要量化这些系统误差对宇宙学测量的影响。

Method: 使用与当前观测一致的合成双黑洞种群，在下一代探测器背景下，通过将最先进波形模型与数值相对论参考信号比较，从建模和数据分析角度量化不准确性，评估其对光度距离、宿主星系关联和单事件H0推断的偏差传播。

Result: 当前波形模型通常能恢复统计一致的H0后验分布，但小波形偏差会显著影响三维定位和宿主星系排名，偶尔导致错误红移分配。需要波形和校准精度按信噪比平方反比缩放才能实现亚百分比的H0测量。

Conclusion: 为实现黄金暗警报的亚百分比H0测量，需要波形和校准精度达到O(ρ^{-2})量级，这要求波形建模、数值相对论和探测器校准在下一代探测器时代持续进步。

Abstract: Golden dark sirens - exceptionally well-localized gravitational-wave (GW) sources without electromagnetic counterparts - offer a powerful route to precision measurements of the Hubble constant, $H_0$, with next-generation (XG) detectors. The statistical promise of this method, however, places stringent demands on waveform accuracy and detector calibration, as even small systematic errors can dominate over statistical uncertainties at high signal-to-noise ratios. We investigate the impact of waveform-modeling systematics on golden dark siren cosmology using a synthetic population of binary black holes consistent with current GW observations and analyzed in the XG-detector era. By comparing state-of-the-art waveform models against numerical-relativity-based reference signals, we quantify modeling inaccuracies from both modeling and data-analysis perspectives and assess how they propagate into biases in luminosity distance, host-galaxy association, and single-event $H_0$ inference. We find that while current waveform models often allow recovery of statistically consistent $H_0$ posteriors, small waveform-induced biases can significantly affect three-dimensional localization and host galaxy ranking, occasionally leading to incorrect redshift assignments. We further derive order-of-magnitude requirements on detector calibration accuracy needed to ensure that calibration systematics remain subdominant for golden dark sirens observed with XG networks. To realize sub-percent $H_0$ measurements with golden dark sirens will require waveform and calibration accuracies that scale as $\mathcal{O}(ρ^{-2})$ with signal-to-noise ratio, motivating sustained advances in waveform modeling, numerical relativity, and detector calibration for the XG era.

</details>


### [258] [On a Gödel-like Solution in Non-Relativistic Gravity](https://arxiv.org/abs/2602.14976)
*A. F. Santos,R. G. G. Amorim,K. V. S. Araújo,S. C. Ulhoa*

Main category: gr-qc

TL;DR: 在伽利略引力框架下构造了类似Gödel的精确解，描述了旋转的非相对论宇宙，避免了闭合类时曲线问题。


<details>
  <summary>Details</summary>
Motivation: 研究非相对论引力理论（伽利略引力）中的Gödel类解，探索在牛顿动力学背景下是否会出现类似广义相对论中的因果性问题（如闭合类时曲线）。

Method: 采用五维伽利略流形上的几何表述，使用Gödel类度规假设，将引力场与从变分原理导出的伽利略流体耦合，得到高度非线性的耦合场方程，通过固定物质部分与场方程一致来构造精确解。

Result: 得到了描述旋转非相对论宇宙的精确解，这些解在整个空间域满足D(x)>H(x)，使得相关的Killing矢量处处类空，从而避免了闭合类时曲线的出现。

Conclusion: 在伽利略引力框架下，Gödel类解可以描述旋转的非相对论宇宙，但与广义相对论中的Gödel解不同，这些解不会产生因果性问题（闭合类时曲线），因为相关的Killing矢量始终保持类空。

Abstract: The article deals with Gödel-like solutions in the context of Galilean gravity, a geometric formulation of non-relativistic gravitation defined on a five-dimensional Galilean manifold. Within this framework, non-relativistic matter fields admit a covariant description, while the physical Newtonian dynamics is recovered through an immersion into the usual $3+1$ spacetime. By adopting a Gödel-like metric ansatz and coupling the gravitational field to a Galilean fluid derived from a variational principle, we obtain a system of highly nonlinear and coupled field equations. Exact solutions are constructed by fixing the matter sector consistently with the field equations. The resulting configurations describe rotating non-relativistic universes and satisfy $D(x)>H(x)$ throughout the entire spatial domain. As a consequence, the associated Killing vector remains spacelike everywhere and no closed timelike curves arise.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [259] [Geometry Challenges Entropy: Regime-DependentRectification in Nanofluidic Cascades](https://arxiv.org/abs/2602.13931)
*Ting Peng*

Main category: physics.comp-ph

TL;DR: 几何不对称的纳米流体腔室在弹道输运区产生反向整流效应，窄侧粒子积累超过宽侧5倍以上，挑战传统熵输运理论


<details>
  <summary>Details</summary>
Motivation: 传统上将纳米流体腔室中的复杂积累模式归因于几何二极管效应，但需要区分漏斗整流与边界反射的贡献，以理解几何不对称在粒子输运中的真实作用

Method: 使用3D分子动力学模拟，采用氩原子参数（r=0.19nm），研究2腔室和10腔室级联系统，通过对称控制实验（w_L=w_R）验证漏斗不对称性的作用

Result: 在2腔室系统中观察到"反向"整流效应：窄侧粒子积累比宽侧多5.37±0.01倍（p<0.0001）；在10腔室级联中，该效应驱动大规模下游积累；对称控制消除了梯度，证实漏斗不对称是弹道区主要驱动力

Conclusion: 漏斗几何不对称（而非边界/边缘效应）是弹道输运区密度梯度的主要驱动力，而超原子区由边界反射主导；研究结果为无泵、无驱动的被动几何驱动密度梯度提供了设计规则

Abstract: Can geometry alone reshape equilibrium? Cascaded nanofluidic chambers show complex accumulation patterns, traditionally attributed to geometric diode effects. We use 3D molecular dynamics to decouple funnel rectification from boundary reflection. Simulations with argon parameters (r = 0.19 nm) reveal a striking "reverse" rectification in a 2-chamber setup: the narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 +/- 0.01, p < 0.0001). In a 10-chamber argon cascade, this effect drives massive downstream accumulation. A symmetric control (w_L = w_R) eliminates the gradient, confirming that funnel asymmetry - not boundary/edge effects - is the primary driver in the ballistic regime. By contrast, the super-atom regime is dominated by boundary reflection. Our results challenge standard entropic transport theory and provide design rules for passive, geometry-driven density gradients - no pump, no drive.

</details>


### [260] [Auxiliary field quantum Monte Carlo at the basis set limit: application to lattice constants](https://arxiv.org/abs/2602.14923)
*Moritz Humer,Martin Schlipf,Zoran Sukurma,Sajad Bazrafshan,Georg Kresse*

Main category: physics.comp-ph

TL;DR: 在VASP中实现了平面波辅助场量子蒙特卡洛方法，结合投影缀加波形式，用于精确计算凝聚态系统的结构性质。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在完全基组极限下精确计算凝聚态系统结构性质的方法，解决现有方法（如MP2和RPA）在长程屏蔽和高阶交换方面的不足。

Method: 在VASP软件中实现平面波辅助场量子蒙特卡洛方法，采用投影缀加波形式，通过精确反转PAW重叠算符保持立方标度，在平面波截断定义的完全基组极限下工作。

Result: 计算C、BN、BP和Si的平衡晶格常数和体模量，结果显示AFQMC能系统修正MP2缺乏的长程屏蔽和RPA缺失的高阶交换，晶格常数与实验值的平均绝对相对误差仅为0.14%。

Conclusion: 该方法为凝聚态系统结构性质提供了严格的基准工具，RPA是最佳参考方法，因为剩余短程关联在超晶胞尺寸下快速收敛。

Abstract: We present a plane-wave (PW) implementation of the auxiliary-field quantum Monte Carlo (AFQMC) method within the projector augmented-wave (PAW) formalism in the Vienna ab initio Simulation Package (VASP). By employing an exact inversion of the PAW overlap operator, our approach maintains cubic scaling while naturally operating at the complete basis set limit defined by the PW cutoff. We benchmark this framework by calculating the equilibrium lattice constants and bulk moduli of C, BN, BP, and Si. Our analysis demonstrates that AFQMC systematically corrects the lack of long-range screening in MP2 and the missing higher-order exchange in RPA. We identify RPA as the optimal reference method due to the rapid convergence of the remaining short-range correlations with respect to supercell size. The resulting lattice constants exhibit a mean absolute relative error of 0.14 % relative to experiment, establishing the method as a rigorous benchmark tool for structural properties in condensed matter systems.

</details>
