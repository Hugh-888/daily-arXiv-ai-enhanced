{"id": "2601.09709", "categories": ["cs.LG", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09709", "abs": "https://arxiv.org/abs/2601.09709", "authors": ["Sharim Khan", "Paul Landes", "Adam Cross", "Jimeng Sun"], "title": "Social Determinants of Health Prediction for ICD-9 Code with Reasoning Models", "comment": "Published as part of Machine Learning for Health (ML4H) 2025 Findings Track", "summary": "Social Determinants of Health correlate with patient outcomes but are rarely captured in structured data. Recent attention has been given to automatically extracting these markers from clinical text to supplement diagnostic systems with knowledge of patients' social circumstances. Large language models demonstrate strong performance in identifying Social Determinants of Health labels from sentences. However, prediction in large admissions or longitudinal notes is challenging given long distance dependencies. In this paper, we explore hospital admission multi-label Social Determinants of Health ICD-9 code classification on the MIMIC-III dataset using reasoning models and traditional large language models. We exploit existing ICD-9 codes for prediction on admissions, which achieved an 89% F1. Our contributions include our findings, missing SDoH codes in 139 admissions, and code to reproduce the results."}
{"id": "2601.09775", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09775", "abs": "https://arxiv.org/abs/2601.09775", "authors": ["Faruk Alpay", "Bilge Senturk"], "title": "The Geometry of Thought: Disclosing the Transformer as a Tropical Polynomial Circuit", "comment": "7 pages, 2 figures", "summary": "We prove that the Transformer self-attention mechanism in the high-confidence regime ($β\\to \\infty$, where $β$ is an inverse temperature) operates in the tropical semiring (max-plus algebra). In particular, we show that taking the tropical limit of the softmax attention converts it into a tropical matrix product. This reveals that the Transformer's forward pass is effectively executing a dynamic programming recurrence (specifically, a Bellman-Ford path-finding update) on a latent graph defined by token similarities. Our theoretical result provides a new geometric perspective for chain-of-thought reasoning: it emerges from an inherent shortest-path (or longest-path) algorithm being carried out within the network's computation."}
{"id": "2601.09776", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09776", "abs": "https://arxiv.org/abs/2601.09776", "authors": ["Khalid Oublal", "Quentin Bouniot", "Qi Gan", "Stephan Clémençon", "Zeynep Akata"], "title": "TimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models", "comment": null, "summary": "As black box models and pretrained models gain traction in time series applications, understanding and explaining their predictions becomes increasingly vital, especially in high-stakes domains where interpretability and trust are essential. However, most of the existing methods involve only in-distribution explanation, and do not generalize outside the training support, which requires the learning capability of generalization. In this work, we aim to provide a framework to explain black-box models for time series data through the dual lenses of Sparse Autoencoders (SAEs) and causality. We show that many current explanation methods are sensitive to distributional shifts, limiting their effectiveness in real-world scenarios. Building on the concept of Sparse Autoencoder, we introduce TimeSAE, a framework for black-box model explanation. We conduct extensive evaluations of TimeSAE on both synthetic and real-world time series datasets, comparing it to leading baselines. The results, supported by both quantitative metrics and qualitative insights, show that TimeSAE provides more faithful and robust explanations. Our code is available in an easy-to-use library TimeSAE-Lib: https://anonymous.4open.science/w/TimeSAE-571D/."}
{"id": "2601.09809", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09809", "abs": "https://arxiv.org/abs/2601.09809", "authors": ["Samar Abdelghani", "Soumaya Cherkaoui"], "title": "QFed: Parameter-Compact Quantum-Classical Federated Learning", "comment": null, "summary": "Organizations and enterprises across domains such as healthcare, finance, and scientific research are increasingly required to extract collective intelligence from distributed, siloed datasets while adhering to strict privacy, regulatory, and sovereignty requirements. Federated Learning (FL) enables collaborative model building without sharing sensitive raw data, but faces growing challenges posed by statistical heterogeneity, system diversity, and the computational burden from complex models. This study examines the potential of quantum-assisted federated learning, which could cut the number of parameters in classical models by polylogarithmic factors and thus lessen training overhead. Accordingly, we introduce QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. We evaluate the proposed framework using the widely adopted FashionMNIST dataset. Experimental results show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining an accuracy comparable to classical approaches in a scalable environment. These results point to the potential of leveraging quantum computing within a federated learning context to strengthen FL capabilities of edge devices."}
{"id": "2601.09829", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.09829", "abs": "https://arxiv.org/abs/2601.09829", "authors": ["Marc Boulé"], "title": "RLC Parameters of a Two-Wire Line with the Finite Element Method", "comment": "11 pages, 16 figures (includes code listings)", "summary": "This tutorial paper shows how to compute the DC (or low-frequency) resistance, inductance and capacitance of a pair of parallel wires using the finite element method. A three-dimensional infinite domain (open boundary) modeling of electrostatic and magnetostatic fields is presented, along with the electrokinetic formulation for the current flow inside the wires. The effects of the insulation and of a proposed physical defect in the wires are also considered. The open-source ONELAB software is used to perform the simulations and the code listing is provided. Comparisons using analytical models (when applicable) and the Altair Flux software are performed to help validate the simulations."}
{"id": "2601.09819", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2601.09819", "abs": "https://arxiv.org/abs/2601.09819", "authors": ["Murdoc Newell", "Alexis Boudon", "Hong Qi"], "title": "Multibanded Reduced Order Quadrature Techniques for Gravitational Wave Inference", "comment": "6 pages, 3 figures, 3 tables", "summary": "Reduced-order quadrature (ROQ) is commonly used to speed up parameter estimation in gravitational wave astronomy; however, the construction of ROQ bases can be computationally costly, particularly for longer duration signals. We propose a modified construction strategy based on PyROQ that accelerates this process by performing the basis search using multiband waveforms, without compromising the desired likelihood speed and accuracy. We use this altered method to construct a set of ROQs in the sub-solar mass range using the \\texttt{IMRPhenomXAS\\_NRTidalV3} waveform. We find a 20\\% to 30\\% decrease in basis size and a $\\sim 10$ times decrease in basis construction time. We verify the altered method preserves the likelihood accuracy and mantains consitent parameter estimation results."}
{"id": "2601.09754", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09754", "abs": "https://arxiv.org/abs/2601.09754", "authors": ["Seungbeom Choi"], "title": "Limits of Rank Recovery in Bilinear Observation Problems", "comment": "10 pages, 5 figures", "summary": "Bilinear observation problems arise in many physical and information-theoretic settings, where observables and states enter multiplicatively. Rank-based diagnostics are commonly used in such problems to assess the effective dimensionality accessible to observation, often under the implicit assumption that rank deficiency can be resolved through numerical refinement. Here we examine this assumption by analyzing the rank and nullity of a bilinear observation operator under systematic tolerance variation. Rather than focusing on a specific reconstruction algorithm, we study the operator directly and identify extended rank plateaus that persist across broad tolerance ranges. These plateaus indicate stable dimensional deficits that are not removed by refinement procedures applied within a fixed problem definition. To investigate the origin of this behavior, we resolve the nullspace into algebraic sectors defined by the block structure of the variables. The nullspace exhibits a pronounced but nonexclusive concentration in specific sectors, revealing an organized internal structure rather than uniform dimensional loss. Comparing refinement with explicit modification of the problem formulation further shows that rank recovery in the reported setting requires a change in the structure of the observation problem itself. Here, \"problem modification\" refers to changes that alter the bilinear observation structure (e.g., admissible operator/state families or coupling constraints), in contrast to refinements that preserve the original formulation such as tolerance adjustment and numerical reparameterizations. Together, these results delineate limits of rank recovery in bilinear observation problems and clarify the distinction between numerical refinement and problem modification in accessing effective dimensional structure."}
{"id": "2601.09825", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09825", "abs": "https://arxiv.org/abs/2601.09825", "authors": ["Alireza Bakhtiari", "Alex Ayoub", "Samuel Robertson", "David Janz", "Csaba Szepesvári"], "title": "Eluder dimension: localise it!", "comment": null, "summary": "We establish a lower bound on the eluder dimension of generalised linear model classes, showing that standard eluder dimension-based analysis cannot lead to first-order regret bounds. To address this, we introduce a localisation method for the eluder dimension; our analysis immediately recovers and improves on classic results for Bernoulli bandits, and allows for the first genuine first-order bounds for finite-horizon reinforcement learning tasks with bounded cumulative returns."}
{"id": "2601.09939", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.09939", "abs": "https://arxiv.org/abs/2601.09939", "authors": ["Jinjin He", "Taiyuan Zhang", "Zhiqi Li", "Junwei Zhou", "Duowen Chen", "Bo Zhu"], "title": "A Level Set Method on Particle Flow Maps", "comment": null, "summary": "This paper introduces a Particle Flow Map Level Set (PFM-LS) method for high-fidelity interface tracking. We store level-set values, gradients, and Hessians on particles concentrated in a narrow band around the interface, advecting them via bidirectional flow maps while using a conventional grid-based representation elsewhere. By interpreting the level set value as a 3-form and its gradient as a 1-form, PFM-LS achieves exceptional geometric fidelity during complex deformations and preserves sub-grid features that traditional methods cannot capture. Our dual-timescale approach utilizes long-range maps for values and gradients, with frequent reinitialization of short-range maps for the distortion-sensitive Hessian, alongside adaptive particle control that maintains sufficient density within the narrow band. We also develop a hybrid particle-grid quasi-Newton redistancing scheme that preserves fine-scale features while enforcing the signed-distance property. Benchmark comparisons in 2D and 3D demonstrate that PFM-LS achieves state-of-the-art volume preservation and shape fidelity against a broad range of existing level-set methods."}
{"id": "2601.09820", "categories": ["gr-qc", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09820", "abs": "https://arxiv.org/abs/2601.09820", "authors": ["Paul M. Alsing"], "title": "Quantum Optical Inspired Models for Unitary Black Hole Evaporation", "comment": "23 page and 21 figures", "summary": "In this work, we describe optically inspired models for unitary black hole (BH) evaporation. The goal of these models are (i) to be operationally simple, (ii) approximately preserve the thermal nature of the emitted Hawking Radiation (HR), and (iii) attempt to reproduce the Page Curve that purports that information flows forth from the BH when it has evaporated to approximately half its initial mass. We concentrate on modeling the BH as a single mode squeezed state successively interacting, by means of beam splitters and squeezers, with vacuum modes near the horizon, giving rise to entangled pairs representing the external Hawking radiation and its partner particle inside the horizon. Since all states and operations are Gaussian throughout, we use a symplectic formalism to track the evolution of the composite system through the evolving means and variances of their quadrature operators. This allows us to easily compute correlations and entanglement between the BH and the HR, as well as calculate correlations between the BH at early and late times."}
{"id": "2601.09763", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09763", "abs": "https://arxiv.org/abs/2601.09763", "authors": ["Ashish Kumar Patra", "Saikumar Krithivasan"], "title": "Fractional Revival Dynamics in Kerr-Type Systems: Angular Momentum Moments and Classical Analogs", "comment": "42 pages, 24 figures", "summary": "Wave packet revivals and fractional revivals are hallmark quantum interference phenomena that arise in systems with nonlinear energy spectra, and their signatures in expectation values of observables have been studied extensively in earlier work. In this article, we build on these studies and extend the analysis in two important directions. First, we investigate fractional revival dynamics in angular momentum observables, deriving explicit expressions for the time evolution of their moments and demonstrating that higher-order angular momentum moments provide clear and selective signatures of fractional revivals. Second, we examine classical analogs of quantum revival phenomena and elucidate structural similarities between quantum fractional revivals and recurrence behavior in representative classical systems. Using the Kerr-type nonlinear Hamiltonian as a paradigmatic model, we analyze the autocorrelation function, moment dynamics, and phase-space structures, supported by visualizations such as quantum carpets. Our results broaden the range of experimentally accessible diagnostics of fractional revivals and provide a unified perspective on revival phenomena across quantum and classical dynamical systems."}
{"id": "2601.09831", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.09831", "abs": "https://arxiv.org/abs/2601.09831", "authors": ["Guixian Xu", "Jinglai Li", "Junqi Tang"], "title": "A New Convergence Analysis of Plug-and-Play Proximal Gradient Descent Under Prior Mismatch", "comment": null, "summary": "In this work, we provide a new convergence theory for plug-and-play proximal gradient descent (PnP-PGD) under prior mismatch where the denoiser is trained on a different data distribution to the inference task at hand. To the best of our knowledge, this is the first convergence proof of PnP-PGD under prior mismatch. Compared with the existing theoretical results for PnP algorithms, our new results removed the need for several restrictive and unverifiable assumptions."}
{"id": "2601.10134", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.10134", "abs": "https://arxiv.org/abs/2601.10134", "authors": ["Ming Liu", "Yosuke Hasegawa"], "title": "A volume penalization method for solving conjugate scalar transport with interfacial jump conditions", "comment": null, "summary": "Conjugate scalar transport with interfacial jump conditions on complex interfacial geometries is common in thermal and chemical processes, while its accurate and efficient simulations are still quite challenging. In the present study, a novel treatment of a two-phase interface in the volume penalization method, a kind of immersed boundary method, for solving conjugate scalar transport with general interfacial boundary conditions is developed. We first propose an interfacial treatment for solving an advection-diffusion equation with a Neumann boundary condition, and then extend it to general conjugate scalar transport with both interfacial flux and scalar jumps. A one-dimensional diffusion problem is solved to verify the present scheme and demonstrate the advantage of the present scheme in improving accuracy and unifying the governing equations in the two phases with an additional source term representing the local jump condition of the interfacial scalar flux. Then, the present scheme is further applied to fluid-solid coupled scalar diffusion and advection-diffusion problems with the scalar and its flux jumps across the interface. The simulation results of the present scheme generally show good agreement with reference results obtained by body-fitted mesh simulations with average relative deviations less than 3.0%."}
{"id": "2601.09919", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.09919", "abs": "https://arxiv.org/abs/2601.09919", "authors": ["Mirjavoxir Mirkhaydarov", "Tursunali Xamidov", "Pankaj Sheoran", "Sanjar Shaymatov", "Hemwati Nandan"], "title": "Non-Monotonic Enhancement of the Magnetic Penrose Process in Kerr-Bertotti-Robinson Spacetime and its Implication for Electron Acceleration", "comment": "16 pages, 8 captioned figures and 2 tables", "summary": "We studied the magnetic Penrose process (MPP) in the Kerr-Bertotti-Robinson (KBR) spacetime, an exact rotating electrovacuum solution describing a black hole (BH) immersed in an intrinsic, uniform electromagnetic field. We analyze the behavior of charged particles in this geometry and find that the spacetime structure itself responds non-monotonically to the background magnetic field $B$. Specifically, both the event horizon and the static limit surface first expand as $B$ increases, reach a maximum size at an intermediate field strength, and then contract toward the extremal limit. Although the ergoregion itself shrinks monotonically with $B$, this structural feature gives rise to a pronounced non-monotonic dependence of the energy extraction efficiency on the magnetic field $B$, i.e., the efficiency initially rises, attains a maximum value, and subsequently falls as the extremal condition is approached. This contrasts sharply with the monotonic trends usually associated with magnetic enhancements in the Kerr geometry. We further explore an astrophysical application of the MPP by estimating the maximum energy of electrons escaping from the ergoregion of the KBR BH. Modeling neutron beta decay occurring near the event horizon, we derive an analytical expression for the energy gained by electrons accelerated by the magnetic field. Applying our results to the supermassive BH at the Galactic center, $\\mathrm{SgrA}^*$, we find that electrons can be accelerated up to energies of $\\sim 10^{15}\\,\\mathrm{eV}$ for realistic values of the spin and magnetic field. Although these energies exceed the observed upper range of cosmic-ray electrons, radiative losses such as synchrotron emission and inverse-Compton scattering can efficiently reduce them to the observed $\\mathrm{TeV}$ scale."}
{"id": "2601.09769", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09769", "abs": "https://arxiv.org/abs/2601.09769", "authors": ["S. Radenkovic", "M. Dugic", "I. Radojevic"], "title": "Three questions on the future of quantum science and technology", "comment": "The Editorial Board of the Kragujevac Journal of Science decided to ask the prominent researchers and scholars to take part in the poll on the status and the future of Quantum Science and Technology", "summary": "The answers on the current status and future development of Quantum Science and Technology are presented."}
{"id": "2601.09841", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09841", "abs": "https://arxiv.org/abs/2601.09841", "authors": ["Aparajita Kashyap", "Sara Matijevic", "Noémie Elhadad", "Steven A. Kushner", "Shalmali Joshi"], "title": "A pipeline for enabling path-specific causal fairness in observational health data", "comment": null, "summary": "When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur (e.g., direct discrimination by a clinician or model versus bias due to differential access to the healthcare system) and to characterize how these biases may appear in learned models. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target \"fair\" model. Our work fills two major gaps: first, we expand on characterizations of the \"fairness-accuracy\" tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias."}
{"id": "2601.10166", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.10166", "abs": "https://arxiv.org/abs/2601.10166", "authors": ["Miriam Goldack", "Yosi Atia", "Ori Alberton", "Karl Jansen"], "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware", "comment": "25 pages, 16 figures", "summary": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez."}
{"id": "2601.10127", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.10127", "abs": "https://arxiv.org/abs/2601.10127", "authors": ["Santosh V. Lohakare", "S. K. Maurya", "Aaisha Al Qassabi", "B. Mishra"], "title": "Hubble Tension and Dark Energy in Teleparallel Gauss-Bonnet Gravity: New Constraints from DESI BAO, Pantheon$^+$ and Hubble Data", "comment": "4 Tables and 5 Figures", "summary": "We explore the cosmological dynamics of a teleparallel Gauss-Bonnet gravity model defined by the torsion scalar $T$ and the torsion-based Gauss-Bonnet invariant $T_{\\mathcal{G}}$, deriving modified Friedmann equations for a flat FLRW Universe and corresponding linear scalar perturbation equations. Using a numerical approach, we solve these equations for pressureless matter, predicting the redshift evolution of the Hubble parameter $H(z)$. Bayesian Markov chain Monte Carlo analysis, incorporating late-time observations from Cosmic Chronometers, Pantheon$^+$ with SH0ES, and DESI BAO (Data Release 1 and Data Release 2), constrains the model parameters, revealing that $f(T, T_{\\mathcal{G}})$ mimics dark energy in the absence of a cosmological constant, presenting a viable alternative to $Λ$CDM paradigm. Stability is confirmed via scalar perturbation analysis of Hubble and matter density fluctuations, positioning $f(T, T_{\\mathcal{G}})$ gravity as a robust framework to address cosmic acceleration challenges. The model yields a present-day effective equation of state $ω_{\\mathrm{eff}}(z=0) \\approx -0.664$ to \\(-0.693\\), consistent with observations, and partially alleviates the Hubble tension with $H_0$ estimates of 69 to 71.5\\kms. These findings highlight the potential of $f(T, T_{\\mathcal{G}})$ gravity to resolve fundamental cosmological puzzles while aligning with late-time observational data."}
{"id": "2601.09779", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09779", "abs": "https://arxiv.org/abs/2601.09779", "authors": ["Jan Carlo Schumann", "Igor Lesanovsky", "Parvinder Solanki"], "title": "Hierarchical time crystals", "comment": null, "summary": "Spontaneous symmetry breaking is one of the central organizing principles in physics. Time crystals have emerged as an exotic phase of matter, spontaneously breaking the time translational symmetry, and are mainly categorized as discrete or continuous. While these distinct types of time crystals have been extensively explored as standalone systems, intriguing effects can arise from their mutual interaction. Here, we demonstrate that a time-independent coupled system of discrete and continuous time crystals induces a simultaneous two-fold temporal symmetry breaking, resulting in a hierarchical time crystal phase. Interestingly, one of the subsystems breaks an emergent discrete temporal symmetry that does not exist in the dynamical generator but rather emerges dynamically, leading to a convoluted non-equilibrium phase. We demonstrate that hierarchical time crystals are robust, emerging for fundamentally different coupling schemes and persisting across wide ranges of system parameters."}
{"id": "2601.09865", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09865", "abs": "https://arxiv.org/abs/2601.09865", "authors": ["Jacob Sander", "Brian Jalaian", "Venkat R. Dasari"], "title": "Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment", "comment": "12 pages, 5 figures", "summary": "Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. By leveraging data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, our pipeline achieves up to 2x memory compression (e.g., reducing a 6GB model to 3GB) and enables efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models' resistance to accuracy decay during quantization."}
{"id": "2601.10239", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.10239", "abs": "https://arxiv.org/abs/2601.10239", "authors": ["Emma Bruyère", "Cyril Pitrou"], "title": "Gravitational lensing beyond the eikonal approximation", "comment": "29 pages, 5 figures", "summary": "Waves propagating through a gravitational potential exhibit wave-optics effects when their wavelength is not significantly smaller than the lensing scales. We study the propagation of a scalar wave, governed by the Klein-Gordon equation in curved spacetime, to focus on effects on amplitude and phase, while leaving aside the issue of wave polarization which affects electromagnetic and gravitational waves. Using the Newman-Penrose formalism, we obtain the first corrections beyond the geometric optics in the expansion in the inverse frequency. In vacuum, that is for Weyl tensor lensing, there is no wave effect at first order in $G$ and wave effects start at order $G^2$. Conversely, if the wave travels through a non-vanishing matter density, the first corrections start at order $G$. We check these analytic results by solving numerically the equations dictating the evolution of the corrections either in the vicinity of a Schwarzschild black hole or through a transparent star."}
{"id": "2601.09786", "categories": ["quant-ph", "cs.IT", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09786", "abs": "https://arxiv.org/abs/2601.09786", "authors": ["Marco Dalai", "Filippo Girardi", "Ludovico Lami"], "title": "Zero-Error List Decoding for Classical-Quantum Channels", "comment": "5+1 pages, 1 figure", "summary": "The aim of this work is to study the zero-error capacity of pure-state classical-quantum channels in the setting of list decoding. We provide an achievability bound for list-size two and a converse bound holding for every fixed list size. The two bounds coincide for channels whose pairwise absolute state overlaps form a positive semi-definite matrix. Finally, we discuss a remarkable peculiarity of the classical-quantum case: differently from the fully classical setting, the rate at which the sphere-packing bound diverges might not be achievable by zero-error list codes, even when we take the limit of fixed but arbitrarily large list size."}
{"id": "2601.09926", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09926", "abs": "https://arxiv.org/abs/2601.09926", "authors": ["Kirandeep Kaur", "Vinayak Gupta", "Aditya Gupta", "Chirag Shah"], "title": "The PROPER Approach to Proactivity: Benchmarking and Advancing Knowledge Gap Navigation", "comment": null, "summary": "Most language-based assistants follow a reactive ask-and-respond paradigm, requiring users to explicitly state their needs. As a result, relevant but unexpressed needs often go unmet. Existing proactive agents attempt to address this gap either by eliciting further clarification, preserving this burden, or by extrapolating future needs from context, often leading to unnecessary or mistimed interventions. We introduce ProPer, Proactivity-driven Personalized agents, a novel two-agent architecture consisting of a Dimension Generating Agent (DGA) and a Response Generating Agent (RGA). DGA, a fine-tuned LLM agent, leverages explicit user data to generate multiple implicit dimensions (latent aspects relevant to the user's task but not considered by the user) or knowledge gaps. These dimensions are selectively filtered using a reranker based on quality, diversity, and task relevance. RGA then balances explicit and implicit dimensions to tailor personalized responses with timely and proactive interventions. We evaluate ProPer across multiple domains using a structured, gap-aware rubric that measures coverage, initiative appropriateness, and intent alignment. Our results show that ProPer improves quality scores and win rates across all domains, achieving up to 84% gains in single-turn evaluation and consistent dominance in multi-turn interactions."}
{"id": "2601.10303", "categories": ["gr-qc", "astro-ph.HE", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10303", "abs": "https://arxiv.org/abs/2601.10303", "authors": ["Faizuddin Ahmed", "Ahmad Al-Badawi", "İzzet Sakallı"], "title": "Effects of spontaneous Lorentz Symmetry breaking on Letelier-AdS charged black boles within Kalb-Ramond gravity", "comment": "45 pages, 25 Figures, and 2 Tables", "summary": "In this study, we investigate the geodesic motion of massless particles -- specifically photons -- in the spacetime of a charged anti-de Sitter (AdS) black hole (BH) surrounded by a cloud of strings (CoS) within the framework of Kalb-Ramond (KR) gravity. We analyze the effective potential that governs photon trajectories, explore the properties and location of the photon sphere (PS), and examine the effective radial force acting on photons. The resulting BH shadow is also studied, highlighting the roles of both the CoS parameter $α$ and the KR field parameter $\\ell$ in shaping its geometry. We constrain these parameters using observational data from M87* and Sgr A* obtained by the Event Horizon Telescope (EHT). Furthermore, we extend our investigation to the motion of neutral test particles in the same gravitational background. By examining the impact of the CoS and KR field, we show how these additional fields modify the dynamics relative to standard charged BH scenarios. Finally, we study the fundamental frequencies associated with quasiperiodic oscillations (QPOs) of test particles, demonstrating how these frequencies are affected by the presence of the CoS and KR field. Our results reveal the rich structure of AdS-BH spacetimes influenced by string clouds and antisymmetric tensor fields, with potential observational consequences in gravitational wave and BH imaging astronomy."}
{"id": "2601.09792", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09792", "abs": "https://arxiv.org/abs/2601.09792", "authors": ["Ricard Puig", "Nathan Constantinides", "Bharath Hebbe Madhusudhana", "Daniel Bowring", "C. Huerta Alderete", "Andrew T. Sornborger"], "title": "Background cancellation for frequency-selective quantum sensing", "comment": "5 + 11 pages, 3 figures", "summary": "A key challenge in quantum sensing is the detection of weak time dependent signals, particularly those that arise as specific frequency perturbations over a background field. Conventional methods usually demand complex dynamical control of the quantum sensor and heavy classical post-processing. We propose a quantum sensor that leverages time independent interactions and entanglement to function as a passive, tunable, thresholded frequency filter. By encoding the frequency selectivity and thresholding behavior directly into the dynamics, the sensor is responsive only to a target frequency of choice whose amplitude is above a threshold. This approach circumvents the need for complex control schemes and reduces the post-processing overhead."}
{"id": "2601.09946", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09946", "abs": "https://arxiv.org/abs/2601.09946", "authors": ["Chenxi Qiu"], "title": "Interpolation-Based Optimization for Enforcing lp-Norm Metric Differential Privacy in Continuous and Fine-Grained Domains", "comment": "USENIX Security 2026", "summary": "Metric Differential Privacy (mDP) generalizes Local Differential Privacy (LDP) by adapting privacy guarantees based on pairwise distances, enabling context-aware protection and improved utility. While existing optimization-based methods reduce utility loss effectively in coarse-grained domains, optimizing mDP in fine-grained or continuous settings remains challenging due to the computational cost of constructing dense perterubation matrices and satisfying pointwise constraints.\n  In this paper, we propose an interpolation-based framework for optimizing lp-norm mDP in such domains. Our approach optimizes perturbation distributions at a sparse set of anchor points and interpolates distributions at non-anchor locations via log-convex combinations, which provably preserve mDP. To address privacy violations caused by naive interpolation in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms. in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms."}
{"id": "2601.10339", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.10339", "abs": "https://arxiv.org/abs/2601.10339", "authors": ["Xue-Nan Chen"], "title": "Distinguishing Quantum Matter by Gravity with Differential Scattering Cross Section at Tree Level", "comment": null, "summary": "The definition of weak equivalence principle of quantum matter is an open problem at present. In order to reflect the probability of quantum system in the quantum version of weak equivalence principle, we proposed a quantum weak equivalence principle based on differential scattering cross section at tree level, that is, the differential scattering cross section does not depend on the mass and properties of the scattered particles when the target particles take the large mass limit. This version of the quantum equivalence principle we proposed will be broken by the spin properties of quantum matter. In the non-relativistic case, the difference of differential scattering cross sections of scattered particles with different spin properties scattered by target particles is mainly reflected in the order of $ \\mathcal O (p _ {\\mathrm{cm}} ^2) $. In the relativistic case , we studied the asymptotic behavior of differential scattering cross sections at small angles. When the target particles are scalar particles, the difference of light particles with different spin properties is mainly reflected in the $ \\mathcal O (1/θ^2) $ order. When the target particles are Dirac particles, the difference of light particles with different spin properties is mainly reflected in the $ \\mathcal O (1/θ^4) $ order. The polarization of differential scattering cross section when scattered particles are Dirac particles is investigated. The result of the degree of polarization depends on the polarization direction of the incident particles."}
{"id": "2601.09817", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09817", "abs": "https://arxiv.org/abs/2601.09817", "authors": ["L. L. Salcedo"], "title": "Localization of quantum states within subspaces", "comment": "15 pages, 4 figures, 1 table", "summary": "A precise definition is proposed for the localization probability of a quantum state within a given subspace of the full Hilbert space of a quantum system. The corresponding localized component of the state is explicitly identified, and several mathematical properties are established. Applications and interpretations in the context of quantum information are also discussed."}
{"id": "2601.09949", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.09949", "abs": "https://arxiv.org/abs/2601.09949", "authors": ["Griffin Kearney"], "title": "Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series", "comment": null, "summary": "Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses."}
{"id": "2601.10428", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.10428", "abs": "https://arxiv.org/abs/2601.10428", "authors": ["Xiaolin Liu", "Sachiko Kuroyanagi"], "title": "Analyzing intermittent stochastic gravitational wave background I:Effect of detector response", "comment": "13 pages, 9 figures", "summary": "With the growing number of gravitational-wave detections, particularly from binary black hole mergers, there is increasing anticipation that an astrophysical background, formed by an ensemble of faint, high-redshift events, will be observed in the near future by the ground-based detector network. This background is anticipated to exhibit non-Gaussian statistical properties. To develop a robust method for detecting such a non-Gaussian gravitational-wave background, we revisit optimal detection strategies based on the Gaussian-mixture likelihood model. In this work, we demonstrate that properly accounting for the detector antenna pattern is essential. Current approaches typically rely on the overlap reduction function averaged over the sky. Through simulations, we show that using such an averaged response introduces significant biases in parameter estimation. In addition, we propose a computationally feasible method that incorporates second-order corrections as an approximation of the full integral over the source distribution. Our results indicate that this approach effectively eliminates these biases. We also show that our method remains robust even when considering anisotropic backgrounds."}
{"id": "2601.09850", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09850", "abs": "https://arxiv.org/abs/2601.09850", "authors": ["Meng-Yuan Li", "Yue Wu"], "title": "Fragmented Topological Excitations in Generalized Hypergraph Product Codes", "comment": "12 pages, 10 figures", "summary": "Product code construction is a powerful tool for constructing quantum stabilizer codes, which serve as a promising paradigm for realizing fault-tolerant quantum computation. Furthermore, the natural mapping between stabilizer codes and the ground states of exactly solvable spin models also motivates the exploration of many-body orders in the stabilizer codes. In this work, we investigate the fracton topological orders in a family of codes obtained by a recently proposed general construction. More specifically, this code family can be regarded as a class of generalized hypergraph product (HGP) codes. We term the corresponding exactly solvable spin models \\textit{orthoplex models}, based on the geometry of the stabilizers. In the 3D orthoplex model, we identify a series of intriguing properties within this model family, including non-monotonic ground state degeneracy (GSD) as a function of system size and non-Abelian lattice defects. Most remarkably, in 4D we discover \\textit{fragmented topological excitations}: while such excitations manifest as discrete, isolated points in real space, their projections onto lower-dimensional subsystems form connected objects such as loops, revealing the intrinsic topological nature of these excitations. Therefore, fragmented excitations constitute an intriguing intermediate class between point-like and spatially extended topological excitations. In addition, these rich features establish the generalized HGP codes as a versatile and analytically tractable platform for studying the physics of fracton orders."}
{"id": "2601.09966", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09966", "abs": "https://arxiv.org/abs/2601.09966", "authors": ["Ruoxi Jia", "Luis Oala", "Wenjie Xiong", "Suqin Ge", "Jiachen T. Wang", "Feiyang Kang", "Dawn Song"], "title": "A Sustainable AI Economy Needs Data Deals That Work for Generators", "comment": "Published at NeurIPS 2025 (https://neurips.cc/virtual/2025/loc/san-diego/poster/121926)", "summary": "We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic welfare concern: as data and its derivatives become economic assets, the feedback loop that sustains current learning algorithms is at risk. We identify three structural faults - missing provenance, asymmetric bargaining power, and non-dynamic pricing - as the operational machinery of this inequality. In our analysis, we trace these problems along the machine learning value chain and propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants. Finally, we outline research directions where our community can make concrete contributions to data deals and contextualize our position with related and orthogonal viewpoints."}
{"id": "2601.10469", "categories": ["gr-qc", "astro-ph.HE", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10469", "abs": "https://arxiv.org/abs/2601.10469", "authors": ["Faizuddin Ahmed", "Ahmad Al-Badawi", "Mohsen Fathi"], "title": "Charged Simpson-Visser AdS Black Holes: Geodesic Structure and Thermodynamic Properties", "comment": "19 pages, 15 Figures", "summary": "In this article, we apply the Simpson-Visser (SV) regularization scheme to Anti-de Sitter (AdS) charged black holes and investigate the resulting spacetime geometry in detail, with emphasis on both geodesic structure and thermodynamic behavior. In particular, we analyze the motion of massless particle, focusing on key features such as the photon sphere, black hole shadow, photon trajectory and the dynamics of charged particles, including the characteristics of the circular and type of orbits. Furthermore, we compare the theoretical predictions of the charged SV-AdS black hole with recent observations reported by the Event Horizon telescope (EHT) for M87* and Sgr~A*. Beyond the geodesic analysis, we explore the thermodynamics of the regularized charged SV-AdS black hole by deriving essential quantities such as the Hawking temperature, Gibbs free energy, and specific heat capacity. Through a systematic examination of these thermodynamic variables, we demonstrate how the regularization parameter inherent in the SV regularization influences particle dynamics, stability conditions, and the overall thermal properties of the modified black hole solution. This comprehensive study highlights the interplay between regularization effects and the physical observables associated with charged AdS black holes."}
{"id": "2601.09854", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09854", "abs": "https://arxiv.org/abs/2601.09854", "authors": ["Ben Lang"], "title": "Multi-level quantum emitter in an optical waveguide: paradoxes and resolutions", "comment": "15 pages, 4 figures", "summary": "We theoretically investigate the optical dipole interaction between a multi-level quantum system and a single-mode optical waveguide of any local polarisation. We investigate several paradoxical seeming situations, for example we find a situation in which there exist two non-orthogonal quantum states, each of which results in a photon flux in the opposite direction to the other. We show how, despite appearances, this does not break the unitary requirements of quantum mechanics. We also find that an isotropic quantum emitter can be either reflective or transmissive to light depending on the waveguide polarisation at the emitter location, indeed in the zero loss limit such a system changes from 100% transmission to 100% reflection due to an infinitesimal polarisation rotation. An example case for a four level system is also considered, which is found to operate as a non-destructive parity measurement of the photon number."}
{"id": "2601.09971", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09971", "abs": "https://arxiv.org/abs/2601.09971", "authors": ["Hansen He", "Shuheng Li"], "title": "An Exploratory Study to Repurpose LLMs to a Unified Architecture for Time Series Classification", "comment": null, "summary": "Time series classification (TSC) is a core machine learning problem with broad applications. Recently there has been growing interest in repurposing large language models (LLMs) for TSC, motivated by their strong reasoning and generalization ability. Prior work has primarily focused on alignment strategies that explicitly map time series data into the textual domain; however, the choice of time series encoder architecture remains underexplored. In this work, we conduct an exploratory study of hybrid architectures that combine specialized time series encoders with a frozen LLM backbone. We evaluate a diverse set of encoder families, including Inception, convolutional, residual, transformer-based, and multilayer perceptron architectures, among which the Inception model is the only encoder architecture that consistently yields positive performance gains when integrated with an LLM backbone. Overall, this study highlights the impact of time series encoder choice in hybrid LLM architectures and points to Inception-based models as a promising direction for future LLM-driven time series learning."}
{"id": "2601.10499", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10499", "abs": "https://arxiv.org/abs/2601.10499", "authors": ["Jan Ambjorn", "Yoshiyuki Watabiki"], "title": "The emergence of our Universe", "comment": null, "summary": "We show how our Universe can emerge from a symmetry breaking of a multicomponent $W_3$ algebra, where the components in addition form a Jordan algebra. We discuss how symmetry breaking related to the Jordan algebras $H_3(C)$ and $H_3(O)$ over the complex and octonion numbers can lead to an extended four-dimensional spacetime, where the expansion of the Universe is governed by a modified Friedmann equation. We finally discuss how this modified Friedmann equation might explain a number of puzzling cosmological observations."}
{"id": "2601.09911", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09911", "abs": "https://arxiv.org/abs/2601.09911", "authors": ["Younghun Kim", "Spiro Gicev", "Martin Sevior", "Muhammad Usman"], "title": "Time-Dynamic Circuits for Fault-Tolerant Shift Automorphisms in Quantum LDPC Codes", "comment": "16 pages, 8 figures", "summary": "Quantum low-density parity-check (qLDPC) codes have emerged as a promising approach for realizing low-overhead logical quantum memories. Recent theoretical developments have established shift automorphisms as a fundamental building block for completing the universal set of logical gates for qLDPC codes. However, practical challenges remain because the existing SWAP-based shift automorphism yields logical error rates that are orders of magnitude higher than those for fault-tolerant idle operations. In this work, we address this issue by dynamically varying the syndrome measurement circuits to implement the shift automorphisms without reducing the circuit distance. We benchmark our approach on both twisted and untwisted weight-6 generalized toric codes, including the gross code family. Our time-dynamic circuits for shift automorphisms achieve performance comparable to the idle operations under the circuit-level noise model (SI1000). Specifically, the dynamic circuits achieve more than an order of magnitude reduction in logical error rates relative to the SWAP-based scheme for the gross code at a physical error rate of $10^{-3}$, employing the BP-OSD decoder. Our findings improve both the error resilience and the time overhead of the shift automorphisms in qLDPC codes. Furthermore, our work can lead to alternative syndrome extraction circuit designs, such as leakage removal protocols, providing a practical pathway to utilizing dynamic circuits that extend beyond surface codes towards qLDPC codes."}
{"id": "2601.09979", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.09979", "abs": "https://arxiv.org/abs/2601.09979", "authors": ["Frank Cole", "Dixi Wang", "Yineng Chen", "Yulong Lu", "Rongjie Lai"], "title": "In-Context Operator Learning on the Space of Probability Measures", "comment": null, "summary": "We introduce \\emph{in-context operator learning on probability measure spaces} for optimal transport (OT). The goal is to learn a single solution operator that maps a pair of distributions to the OT map, using only few-shot samples from each distribution as a prompt and \\emph{without} gradient updates at inference. We parameterize the solution operator and develop scaling-law theory in two regimes. In the \\emph{nonparametric} setting, when tasks concentrate on a low-intrinsic-dimension manifold of source--target pairs, we establish generalization bounds that quantify how in-context accuracy scales with prompt size, intrinsic task dimension, and model capacity. In the \\emph{parametric} setting (e.g., Gaussian families), we give an explicit architecture that recovers the exact OT map in context and provide finite-sample excess-risk bounds. Our numerical experiments on synthetic transports and generative-modeling benchmarks validate the framework."}
{"id": "2601.10550", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2601.10550", "abs": "https://arxiv.org/abs/2601.10550", "authors": ["Santiago Jaraba", "Jérôme Novak", "Micaela Oertel"], "title": "Numerical simulations of oscillating and differentially rotating neutron stars", "comment": "10 pages, 9 figures", "summary": "The remnants of binary neutron star mergers are expected to be massive, rapidly rotating stars whose oscillations produce gravitational waves in the kilohertz band. The degree of differential rotation and the rotation profiles strongly influence their structure, stability and oscillation spectrum, and must therefore be taken into account when modeling their dynamics. We extend the pseudospectral code ROXAS (Relativistic Oscillations of non-aXisymmetric neutron stArS) to enable the dynamical evolution of oscillating, differentially rotating neutron stars. Using the updated code, we aim to study the star's oscillation frequencies. We extend the previous formalism, based on primitive variables and the conformal flatness approximation, to differential rotation. Within this framework, we run a series of axisymmetric and non-axisymmetric simulations of perturbed, differentially rotating neutron stars with different rotation rates, and extract their oscillation frequencies. Axisymmetric modes, as well as those under the Cowling approximation, show excellent agreement with published results. We show that the secondary fundamental mode in the Cowling approximation is an artifact that does not appear in dynamical spacetimes. In addition, we provide, for the first time, frequency values for non-axisymmetric modes in differentially rotating configurations evolved in conformal flatness. This extension broadens the range of physical scenarios that can be studied with ROXAS, and represents a step toward more realistic modeling of post-merger remnants and their gravitational-wave emission."}
{"id": "2601.09921", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09921", "abs": "https://arxiv.org/abs/2601.09921", "authors": ["Kai Zhang", "Zhengzhong Yi", "Shaojun Guo", "Linghang Kong", "Situ Wang", "Xiaoyu Zhan", "Tan He", "Weiping Lin", "Tao Jiang", "Dongxin Gao", "Yiming Zhang", "Fangming Liu", "Fang Zhang", "Zhengfeng Ji", "Fusheng Chen", "Jianxin Chen"], "title": "Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction", "comment": "The main text consists of 25 pages and 9 figures, extending our prior work (arXiv:2509.03815) with new results on surface code decoding in superconducting qubit systems and real-time performance benchmarks on TPU v6e", "summary": "Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation (FTQC). Neural network decoders like AlphaQubit have demonstrated potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders lack the parallelism required to decode the syndrome stream generated by a superconducting logical qubit in real time. Moreover, integrating AlphaQubit with sliding window-based parallel decoding schemes presents non-trivial challenges: AlphaQubit is trained solely to output a single bit corresponding to the global logical correction for an entire memory experiment, rather than local physical corrections that can be easily integrated. We address this issue by training a recurrent, transformer-based neural network specifically tailored for parallel window decoding. While it still outputs a single bit, we derive training labels from a consistent set of local corrections and train on various types of decoding windows simultaneously. This approach enables the network to self-coordinate across neighboring windows, facilitating high-accuracy parallel decoding of arbitrarily long memory experiments.\n  As a result, we overcome the throughput bottleneck that previously precluded the use of AlphaQubit-type decoders in FTQC. Our work presents the first scalable, neural-network-based parallel decoding framework that simultaneously achieves SOTA accuracy and the stringent throughput required for real-time quantum error correction. Using an end-to-end experimental workflow, we benchmark our decoder on the Zuchongzhi 3.2 superconducting quantum processor on surface codes with distances up to 7, demonstrating its superior accuracy. Moreover, we demonstrate that, using our approach, a single TPU v6e is capable of decoding surface codes with distances up to 25 within 1us per decoding round."}
{"id": "2601.09985", "categories": ["cs.LG", "cs.AR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.09985", "abs": "https://arxiv.org/abs/2601.09985", "authors": ["Tianqi Zhang", "Flavio Ponzina", "Tajana Rosing"], "title": "FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems", "comment": null, "summary": "Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed vector-quantized representations in fast memory. However, they still rely on a costly second-pass refinement stage that reads full-precision vectors from slower storage like SSDs. For modern text and multimodal embeddings, these reads now dominate the latency of the entire query. We propose FaTRQ, a far-memory-aware refinement system using tiered memory that eliminates the need to fetch full vectors from storage. It introduces a progressive distance estimator that refines coarse scores using compact residuals streamed from far memory. Refinement stops early once a candidate is provably outside the top-k. To support this, we propose tiered residual quantization, which encodes residuals as ternary values stored efficiently in far memory. A custom accelerator is deployed in a CXL Type-2 device to perform low-latency refinement locally. Together, FaTRQ improves the storage efficiency by 2.4$\\times$ and improves the throughput by up to 9$ \\times$ than SOTA GPU ANNS system."}
{"id": "2601.10552", "categories": ["gr-qc", "hep-ph"], "pdf": "https://arxiv.org/pdf/2601.10552", "abs": "https://arxiv.org/abs/2601.10552", "authors": ["Zhong-Hao Luo", "Fa Peng Huang", "Pengming Zhang", "Chen Zhang"], "title": "Rapid post-merger signal of circularly polarized gravitational wave from magnetic black hole superradiance: novel approach to detect magnetic monopole", "comment": "38 pages, 8 figures, comments are welcome", "summary": "We present an analytic framework demonstrating that a spinning black hole endowed with a net magnetic charge exhibits a dramatically amplified superradiant instability against charged scalar fields, enhanced by several orders of magnitude compared with the neutral Kerr case. The amplification arises from a monopole induced reduction of the centrifugal barrier. This shift deepens the gravitational bound-state potential well and produces a parametrically larger instability growth rate. This resulting rapid growth yields a macroscopic boson cloud that acts as a coherent source of near monochromatic continuous gravitational waves (GWs). We find an enhanced GW power. Monopole harmonic selection rules restrict the emission from the north (south) clouds corresponding to opposite helicities. Their superposition generates an (approximately) circularly polarized continuous GWs at a fixed sky location within even parity general relativity, distinct from the generic elliptical polarization of the Kerr case. In light of these new findings, we propose a potential smoking-gun search strategy for magnetic monopole and ultralight boson: the rapid post-merger follow-up GW signals from binary-black-hole merger remnants through ground-based and space-based GW experiments. In contrast to the Kerr case, where the signal turn-on can be delayed to decades-centuries, a magnetic remnant can form a cloud and emit a stronger, circularly polarized continuous GWs within weeks to months. Taking the magnetic supermassive remnants as an example, we demonstrate that the rapid follow-up GW signal in the mHz band appears just in few weeks after binary black hole mergers. Moreover, future polarization (ellipticity) measurements can distinguish the magnetic scenario from Kerr while providing a parity-even mechanism for circularly polarized GWs in general relativity."}
{"id": "2601.09938", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09938", "abs": "https://arxiv.org/abs/2601.09938", "authors": ["Akitada Sakurai", "Aoi Hayashi", "Tadayoshi Matumori", "Daisuke Kaji", "Tadashi Kadowaki", "Kae Nemoto"], "title": "Beyond Optimization: Harnessing Quantum Annealer Dynamics for Machine Learning", "comment": "6pages, 3 figures", "summary": "Quantum annealing is typically regarded as a tool for combinatorial optimization, but its coherent dynamics also offer potential for machine learning. We present a model that encodes classical data into an Ising Hamiltonian, evolves it on a quantum annealer, and uses the resulting probability distributions as feature maps for classification. Experiments on the quantum annealer machine with the Digits dataset, together with simulations on MNIST, demonstrate that short annealing times yield higher classification accuracy, while longer times reduce accuracy but lower sampling costs. We introduce the participation ratio as a measure of the effective model size and show its strong correlation with generalization."}
{"id": "2601.10007", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10007", "abs": "https://arxiv.org/abs/2601.10007", "authors": ["Peter Jemley"], "title": "Continuous-Depth Transformers with Learned Control Dynamics", "comment": "9 pages, 4 figures. Code available at: https://github.com/PeterJemley/Continuous-Depth-Transformers-with-Learned-Control-Dynamics", "summary": "We present a hybrid transformer architecture that replaces discrete middle layers with a continuous-depth Neural Ordinary Differential Equation (ODE) block, enabling inference-time control over generation attributes via a learned steering signal. Unlike standard transformers that process representations through fixed discrete layers, our approach treats depth as a continuous variable governed by a learned vector field $F_θ(H, τ, u)$, where $u$ is a low-dimensional control signal injected via explicit concatenation. We validate the architecture through four experiments: (1) gradient flow stability with zero exploding/vanishing gradient events, (2) semantic steering achieving 98\\%/88\\% accuracy for positive/negative sentiment control, (3) continuous interpolation validated by a negligible 0.068\\% trajectory divergence between fixed and adaptive solvers, and (4) efficiency benchmarking demonstrating latency parity with standard discrete baselines. Additionally, we show that adaptive ODE solvers reveal geometric structure in the learned dynamics: the control signal partitions the vector field into distinct dynamical regimes with different curvature characteristics. The adjoint method enables $O(1)$ memory training regardless of integration depth. Our results demonstrate that continuous-depth dynamics with learned control signals provide a viable, efficient mechanism for steerable language generation."}
{"id": "2601.10627", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2601.10627", "abs": "https://arxiv.org/abs/2601.10627", "authors": ["Rajdeep Mazumdar", "Kalyan Malakar", "Kalyan Bhuyan"], "title": "Dynamics of Late time cosmology in $f(Q,L_{m})$ Gravity with Constraints from DESI DR2 BAO Data", "comment": "24 pages, 7 figures and 6 tables", "summary": "We investigate late-time cosmology in the context of modified $f(Q,L_m)$ gravity, considering a non-linear model$ f(Q,L_m) = αQ + βL_m^n + λ$ where, $α$, $β$, $λ$, and $n$ are some free parameters. The modified Friedmann equations are derived for a barotropic cosmic fluid, and an analytical solution for the Hubble parameter $H(z)$ is obtained. Using the latest DESI DR2 BAO data, previous BAO compilations (P-BAO), and cosmic chronometer (CC) datasets, we constrain the model parameters through a Markov Chain Monte Carlo analysis. Our results show that the model successfully describes the observed late-time cosmic acceleration with slightly tighter constraints from the inclusion of DESI dataset. The present-day Hubble constant is determined as $H_0 \\simeq 69.5\\ \\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$, while the deceleration parameter confirms accelerated expansion with $q_0 \\simeq -0.57$. The transition redshift, where the universe switches from deceleration to acceleration, occurs in the range $z_{\\rm tr} \\sim 0.56 - 0.77$. Similarly, a smooth and physically consistent transition from a matter-dominated decelerated period at high redshifts to an accelerated phase at late times is revealed by the evolution of $ω_{eff}(z)$. While statefinder diagnostic shows the model favours a Chaplygin gas like nature for DESI and DESI+CC, whereas the model favours as quintessence dominated evolution for P-BAO+CC in the late time regime. Conclusively, all these results along with the study of the energy conditions and stability analysis showcases the given $f(Q,L_m)$ model offers a viable alternative to GR-based cosmology"}
{"id": "2601.09943", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09943", "abs": "https://arxiv.org/abs/2601.09943", "authors": ["Darrell Teegarden", "Allison Casey", "F. Gino Serpa", "Patrick Becker", "Asmita Brahme", "Saanvi Kataria", "Paul Lopata"], "title": "Three Months in the Life of Cloud Quantum Computing", "comment": null, "summary": "Quantum Computing (QC) has evolved from a few custom quantum computers, which were only accessible to their creators, to an array of commercial quantum computers that can be accessed on the cloud by anyone. Accessing these cloud quantum computers requires a complex chain of tools that facilitate connecting, programming, simulating algorithms, estimating resources, submitting quantum computing jobs, retrieving results, and more. Some steps in the chain are hardware dependent and subject to change as both hardware and software tools, such as available gate sets and optimizing compilers, evolve. Understanding the trade-offs inherent in this process is essential for evaluating the power and utility of quantum computers. ARLIS has been systematically investigating these environments to understand these complexities. The work presented here is a detailed summary of three months of using such quantum programming environments. We show metadata obtained from these environments, including the connection metrics to the different services, the execution of algorithms, the testing of the effects of varying the number of qubits, comparisons to simulations, execution times, and cost. Our objective is to provide concrete data and insights for those who are exploring the potential of quantum computing. It is not our objective to present any new algorithms or optimize performance on any particular machine or cloud platform; rather, this work is focused on providing a consistent view of a single algorithm executed using out-of-the-box settings and tools across machines, cloud platforms, and time. We present insights only available from these carefully curated data."}
{"id": "2601.10012", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10012", "abs": "https://arxiv.org/abs/2601.10012", "authors": ["Yanhang Shi", "Xiaoyu Wang", "Houwei Cao", "Jian Li", "Yong Liu"], "title": "PID-Guided Partial Alignment for Multimodal Decentralized Federated Learning", "comment": null, "summary": "Multimodal decentralized federated learning (DFL) is challenging because agents differ in available modalities and model architectures, yet must collaborate over peer-to-peer (P2P) networks without a central coordinator. Standard multimodal pipelines learn a single shared embedding across all modalities. In DFL, such a monolithic representation induces gradient misalignment between uni- and multimodal agents; as a result, it suppresses heterogeneous sharing and cross-modal interaction. We present PARSE, a multimodal DFL framework that operationalizes partial information decomposition (PID) in a server-free setting. Each agent performs feature fission to factorize its latent representation into redundant, unique, and synergistic slices. P2P knowledge sharing among heterogeneous agents is enabled by slice-level partial alignment: only semantically shareable branches are exchanged among agents that possess the corresponding modality. By removing the need for central coordination and gradient surgery, PARSE resolves uni-/multimodal gradient conflicts, thereby overcoming the multimodal DFL dilemma while remaining compatible with standard DFL constraints. Across benchmarks and agent mixes, PARSE yields consistent gains over task-, modality-, and hybrid-sharing DFL baselines. Ablations on fusion operators and split ratios, together with qualitative visualizations, further demonstrate the efficiency and robustness of the proposed design."}
{"id": "2601.09951", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09951", "abs": "https://arxiv.org/abs/2601.09951", "authors": ["Rylan Malarchick", "Ashton Steed"], "title": "Parallelizing the Variational Quantum Eigensolver: From JIT Compilation to Multi-GPU Scaling", "comment": null, "summary": "The Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm for computing ground state energies of molecular systems. We implement VQE to calculate the potential energy surface of the hydrogen molecule (H$_2$) across 100 bond lengths using the PennyLane quantum computing framework on an HPC cluster featuring 4$\\times$ NVIDIA H100 GPUs (80GB each). We present a comprehensive parallelization study with four phases: (1) Optimizer + JIT compilation achieving 4.13$\\times$ speedup, (2) GPU device acceleration achieving 3.60$\\times$ speedup at 4 qubits scaling to 80.5$\\times$ at 26 qubits, (3) MPI parallelization achieving 28.5$\\times$ speedup, and (4) Multi-GPU scaling achieving 3.98$\\times$ speedup with 99.4% parallel efficiency across 4 H100 GPUs. The combined effect yields 117$\\times$ total speedup for the H$_2$ potential energy surface (593.95s $\\rightarrow$ 5.04s). We conduct a CPU vs GPU scaling study from 4--26 qubits, finding GPU advantage at all scales with speedups ranging from 10.5$\\times$ to 80.5$\\times$. Multi-GPU benchmarks demonstrate near-perfect scaling with 99.4% efficiency and establish that a single H100 can simulate up to 29 qubits before hitting memory limits. The optimized implementation reduces runtime from nearly 10 minutes to 5 seconds, enabling interactive quantum chemistry exploration."}
{"id": "2601.10015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10015", "abs": "https://arxiv.org/abs/2601.10015", "authors": ["Boyi Liu", "Zimu Zhou", "Yongxin Tong"], "title": "CAFEDistill: Learning Personalized and Dynamic Models through Federated Early-Exit Network Distillation", "comment": "12 pages, conference", "summary": "Personalized Federated Learning (PFL) enables collaboratively model training on decentralized, heterogeneous data while tailoring them to each client's unique distribution. However, existing PFL methods produce static models with a fixed tradeoff between accuracy and efficiency, limiting their applicability in environments where inference requirements vary with contexts and resource availability. Early-exit networks (EENs) offer adaptive inference by attaching intermediate classifiers. Yet integrating them into PFL is challenging due to client-wise heterogeneity and depth-wise interference arising from conflicting exit objectives. Prior studies fail to resolve both conflicts simultaneously, leading to suboptimal performance. In this paper, we propose CAFEDistill, a Conflict-Aware Federated Exit Distillation framework that jointly addresses these conflicts and extends PFL to early-exit networks. Through a progressive, depth-prioritized student coordination mechanism, CAFEDistill mitigates interference among shallow and deep exits while allowing effective personalized knowledge transfer across clients. Furthermore, it reduces communication overhead via a client-decoupled formulation. Extensive evaluations show that CAFEDistill outperforms the state-of-the-arts, achieving higher accuracy and reducing inference costs by 30.79%-46.86%."}
{"id": "2601.09977", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09977", "abs": "https://arxiv.org/abs/2601.09977", "authors": ["Rikizo Ikuta"], "title": "Statistical-noise-enhanced multi-photon interference", "comment": "11 pages, 6 figures", "summary": "Photon statistics plays a governing role in multi-photon interference. While interference visibility in the standard two-photon case, known as Hong-Ou-Mandel interference, monotonically degrades with higher intensity correlation functions, we show that this monotonicity does not hold for three-photon interference in symmetric circuits. We reveal that, in the discrete Fourier transform circuit, engineered super-Poissonian photon-number fluctuations, realized using a modulated laser, maximize the visibility, surpassing the magnitude of the single-photon signature. In addition, by tuning the symmetric circuit parameters, we demonstrate that the visibility hierarchy inverts relative to the benchmark of Poissonian statistics. This trade-off implies that quantum and classical advantages are mutually exclusive resources for interference, indicating a form of statistical complementarity."}
{"id": "2601.10019", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10019", "abs": "https://arxiv.org/abs/2601.10019", "authors": ["Mykola Pinchuk"], "title": "Time Aggregation Features for XGBoost Models", "comment": "17 pages, 18 tables and figures", "summary": "This paper studies time aggregation features for XGBoost models in click-through rate prediction. The setting is the Avazu click-through rate prediction dataset with strict out-of-time splits and a no-lookahead feature constraint. Features for hour H use only impressions from hours strictly before H. This paper compares a strong time-aware target encoding baseline to models augmented with entity history time aggregation under several window designs. Across two rolling-tail folds on a deterministic ten percent sample, a trailing window specification improves ROC AUC by about 0.0066 to 0.0082 and PR AUC by about 0.0084 to 0.0094 relative to target encoding alone. Within the time aggregation design grid, event count windows provide the only consistent improvement over trailing windows, and the gain is small. Gap windows and bucketized windows underperform simple trailing windows in this dataset and protocol. These results support a practical default of trailing windows, with an optional event count window when marginal ROC AUC gains matter."}
{"id": "2601.09995", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09995", "abs": "https://arxiv.org/abs/2601.09995", "authors": ["Masahito Hayashi", "Jinpei Zhao"], "title": "Double Markovity for quantum systems", "comment": null, "summary": "The subadditivity-doubling-rotation (SDR) technique is a powerful route to Gaussian optimality in classical information theory and relies on strict subadditivity and its equality-case analysis, where double Markovity is a standard tool. We establish quantum analogues of double Markovity. For tripartite states, we characterize the simultaneous Markov conditions A-B-C and A-C-B via compatible projective measurements on B and C that induce a common classical label J yielding A-J-(BC). For strictly positive four-party states, we show that A-(BD)-C and A-(CD)-B hold if and only if A-D-(BC) holds. These results remove a key bottleneck in extending SDR-type arguments to quantum systems."}
{"id": "2601.10024", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10024", "abs": "https://arxiv.org/abs/2601.10024", "authors": ["Yanxin Liu", "Yunqi Zhang"], "title": "BPE: Behavioral Profiling Ensemble", "comment": null, "summary": "Ensemble learning is widely recognized as a pivotal strategy for pushing the boundaries of predictive performance. Traditional static ensemble methods, such as Stacking, typically assign weights by treating each base learner as a holistic entity, thereby overlooking the fact that individual models exhibit varying degrees of competence across different regions of the instance space. To address this limitation, Dynamic Ensemble Selection (DES) was introduced. However, both static and dynamic approaches predominantly rely on the divergence among different models as the basis for integration. This inter-model perspective neglects the intrinsic characteristics of the models themselves and necessitates a heavy reliance on validation sets for competence estimation. In this paper, we propose the Behavioral Profiling Ensemble (BPE) framework, which introduces a novel paradigm shift. Unlike traditional methods, BPE constructs a ``behavioral profile'' intrinsic to each model and derives integration weights based on the deviation between the model's response to a specific test instance and its established behavioral profile. Extensive experiments on both synthetic and real-world datasets demonstrate that the algorithm derived from the BPE framework achieves significant improvements over state-of-the-art ensemble baselines. These gains are evident not only in predictive accuracy but also in computational efficiency and storage resource utilization across various scenarios."}
{"id": "2601.09997", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.09997", "abs": "https://arxiv.org/abs/2601.09997", "authors": ["Guo-Qing Zhang", "L. F. Quezada", "Shi-Hai Dong"], "title": "Reentrant topological phases and entanglement scalings in moiré-modulated extended Su-Schrieffer-Heeger Model", "comment": "10 pages, 7 figures", "summary": "Recent studies of moiré physics have unveiled a wealth of opportunities for significantly advancing the field of quantum phase transitions. However, properties of reentrant phase transitions driven by moiré strength are poorly understood. Here, we investigate the reentrant sequence of phase transitions and the invariant of universality class in moiré-modulated extended Su-Schrieffer-Heeger (SSH) model. For the simplified case with intercell hopping $w=0$, we analytically derive renormalization relations of Hamiltonian parameters to explain the reentrant phenomenon. For the general case, numerical phase boundaries are calculated in the thermodynamic limit. The bulk boundary correspondence between zero-energy edge modes and entanglement spectrum is revealed from the degeneracy of both quantities. We also address the correspondence between the central charge obtained from entanglement entropy and the change in winding number during the phase transition. Our results shed light on the understanding of universal characteristics and bulk-boundary correspondence for moiré induced reentrant phase transitions in 1D condensed-matter systems."}
{"id": "2601.10058", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10058", "abs": "https://arxiv.org/abs/2601.10058", "authors": ["Renpu Liu", "Jing Yang"], "title": "Unlabeled Data Can Provably Enhance In-Context Learning of Transformers", "comment": "Published as a conference paper at NeurIPS 2025", "summary": "Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel augmented ICL framework, in which the prompt includes a small set of labeled examples alongside a block of unlabeled inputs. We focus on the multi-class linear classification setting and demonstrate that, with chain-of-thought (CoT) prompting, a multi-layer transformer can effectively emulate an expectation-maximization (EM) algorithm. This enables the transformer to implicitly extract useful information from both labeled and unlabeled data, leading to provable improvements in ICL accuracy. Moreover, we show that such a transformer can be trained via teacher forcing, with its parameters converging to the desired solution at a linear rate. Experiments demonstrate that the augmented ICL framework consistently outperforms conventional few-shot ICL, providing empirical support for our theoretical findings. To the best of our knowledge, this is the first theoretical study on the impact of unlabeled data on the ICL performance of transformers."}
{"id": "2601.10034", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10034", "abs": "https://arxiv.org/abs/2601.10034", "authors": ["Song-Ju Kim"], "title": "Contextuality Derived from Minimal Decision Dynamics: Quantum Tug-of-War Decision Making", "comment": "This work addresses contextuality and non-Kolmogorovian probability as structural properties of decision dynamics, without assuming quantum physical substrates", "summary": "Decision making often exhibits context dependence that challenges classical probability theory. While quantum cognition has successfully modeled such phenomena, it remains unclear whether quantum probability is merely a convenient assumption or a necessary consequence of decision dynamics. Here we present a theoretical framework in which contextuality arises generatively from physically grounded constraints on decision making. By developing a quantum extension of the Tug-of-War (TOW) model, we show that conservation-based internal state updates and measurement-induced disturbance preclude any non-contextual classical description with a single, unified internal state. Contextuality therefore emerges as a structural consequence of adaptive learning dynamics. We further show that the resulting measurement structure admits Klyachko-Can-Binicioglu-Shumovsky (KCBS)-type contextuality witnesses in a minimal single-system setting. These results indicate that quantum probability is not merely a descriptive convenience, but an unavoidable effective theory for adaptive decision dynamics."}
{"id": "2601.10067", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.10067", "abs": "https://arxiv.org/abs/2601.10067", "authors": ["Hung Vinh Tran", "Tong Chen", "Hechuan Wen", "Quoc Viet Hung Nguyen", "Bin Cui", "Hongzhi Yin"], "title": "Efficient Content-based Recommendation Model Training via Noise-aware Coreset Selection", "comment": "WebConf 2026", "summary": "Content-based recommendation systems (CRSs) utilize content features to predict user-item interactions, serving as essential tools for helping users navigate information-rich web services. However, ensuring the effectiveness of CRSs requires large-scale and even continuous model training to accommodate diverse user preferences, resulting in significant computational costs and resource demands. A promising approach to this challenge is coreset selection, which identifies a small but representative subset of data samples that preserves model quality while reducing training overhead. Yet, the selected coreset is vulnerable to the pervasive noise in user-item interactions, particularly when it is minimally sized. To this end, we propose Noise-aware Coreset Selection (NaCS), a specialized framework for CRSs. NaCS constructs coresets through submodular optimization based on training gradients, while simultaneously correcting noisy labels using a progressively trained model. Meanwhile, we refine the selected coreset by filtering out low-confidence samples through uncertainty quantification, thereby avoid training with unreliable interactions. Through extensive experiments, we show that NaCS produces higher-quality coresets for CRSs while achieving better efficiency than existing coreset selection techniques. Notably, NaCS recovers 93-95\\% of full-dataset training performance using merely 1\\% of the training data. The source code is available at \\href{https://github.com/chenxing1999/nacs}{https://github.com/chenxing1999/nacs}."}
{"id": "2601.10042", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10042", "abs": "https://arxiv.org/abs/2601.10042", "authors": ["Sha Shi", "Xiao-Yang Xu", "Min-Quan Cheng", "Dong-Sheng Wang", "Yun-Jiang Wang"], "title": "Towards Minimal Fault-tolerant Error-Correction Sequence with Quantum Hamming Codes", "comment": "11pages, 1 figure", "summary": "The high overhead of fault-tolerant measurement sequences (FTMSs) poses a major challenge for implementing quantum stabilizer codes. Here, we address this problem by constructing efficient FTMSs for the class of quantum Hamming codes $[\\![2^r-1, 2^r-1-2r, 3]\\!]$ with $r=3k+1$ ($k \\in \\mathbb{Z}^+$). Our key result demonstrates that the sequence length can be reduced to exactly $2r+1$-only one additional measurement beyond the original non-fault-tolerant sequence, establishing a tight lower bound. The proposed method leverages cyclic matrix transformations to systematically combine rows of the initial stabilizer matrix and preserving a self-dual CSS-like symmetry analogous to that of the original quantum Hamming codes. This induced symmetry enables hardware-efficient circuit reuse: the measurement circuits for the first $r$ stabilizers are transformed into circuits for the remaining $r$ stabilizers simply by toggling boundary Hadamard gates, eliminating redundant hardware. For distance-3 fault-tolerant error correction, our approach simultaneously reduces the time overhead via shorting the FTMS length and the hardware overhead through symmetry-enabled circuit multiplexing. These results provide an important advance towards the important open problem regarding the design of minimal FTMSs for quantum Hamming codes and may shed light on similar challenges in other quantum stabilizer codes."}
{"id": "2601.10070", "categories": ["cs.LG", "cs.CV", "eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.10070", "abs": "https://arxiv.org/abs/2601.10070", "authors": ["Mohammad Abbadi"], "title": "Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment", "comment": "Under review at Computers in Biology and Medicine", "summary": "Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)).\n  The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities.\n  These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment."}
{"id": "2601.10059", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10059", "abs": "https://arxiv.org/abs/2601.10059", "authors": ["Shuowei Ma", "Qianfan Wang", "Lvzhou Li", "Fei Shi"], "title": "Optimal qudit overlapping tomography and optimal measurement order", "comment": null, "summary": "Quantum state tomography is essential for characterizing quantum systems, but it becomes infeasible for large systems due to exponential resource scaling. Overlapping tomography addresses this challenge by reconstructing all $k$-body marginals using few measurement settings, enabling the efficient extraction of key information for many quantum tasks. While optimal schemes are known for qubits, the extension to higher-dimensional qudit systems remains largely unexplored. Here, we investigate optimal qudit overlapping tomography, constructing local measurement settings from generalized Gell-Mann matrices. By establishing a correspondence with combinatorial covering arrays, we present two explicit constructions of optimal measurement schemes. For $n$-qutrit systems, we prove that pairwise tomography requires at most $8 + 56\\left\\lceil \\log_{8} n \\right\\rceil$ measurement settings, and provide an explicit scheme achieving this bound. Furthermore, we develop an efficient algorithm to determine the optimal order of these measurement settings, minimizing the experimental overhead associated with switching configurations. Compared to the worst-case ordering, our optimized schedule reduces switching costs by approximately 50\\%. These results provide a practical pathway for efficient characterization of qudit systems, facilitating their application in quantum communication and computation."}
{"id": "2601.10079", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10079", "abs": "https://arxiv.org/abs/2601.10079", "authors": ["Sijia Luo", "Xiaokang Zhang", "Yuxuan Hu", "Bohan Zhang", "Ke Wang", "Jinbo Su", "Mengshu Sun", "Lei Liang", "Jing Zhang"], "title": "Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts", "comment": null, "summary": "Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment."}
{"id": "2601.10066", "categories": ["quant-ph", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10066", "abs": "https://arxiv.org/abs/2601.10066", "authors": ["Awanish Pandey"], "title": "Geometric Criteria for Complete Mode Conversion in Detuned Systems via Piecewise-Coherent Modulation", "comment": "6 pages, 4 figures", "summary": "Static phase detuning fundamentally constrains coherent state transfer in asymmetric classical and quantum systems. We introduce a Bloch-sphere formulation for piecewise-coherent modulation that recasts coupled-mode dynamics as geometric trajectories, transforming algebraic control into path optimization. The approach reveals a cone of inaccessibility at the target pole and yields exact geodesic criteria for complete mode conversion in detuned systems. Leveraging this framework, we break time-reversal symmetry to realize a magnet-free optical isolator with near-unity contrast. Furthermore, for detuning larger than coupling between modes, we develop a recursive multi-step protocol enabling deterministic transfer for arbitrary detunings and derive a universal geometric lower bound on the required number of coupling-switching events."}
{"id": "2601.10084", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10084", "abs": "https://arxiv.org/abs/2601.10084", "authors": ["Zan Chaudhry", "Noam H. Rotenberg", "Brian Caffo", "Craig K. Jones", "Haris I. Sair"], "title": "Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection", "comment": "10 pages, 5 figures", "summary": "Machine learning classification systems are susceptible to poor performance when trained with incorrect ground truth labels, even when data is well-curated by expert annotators. As machine learning becomes more widespread, it is increasingly imperative to identify and correct mislabeling to develop more powerful models. In this work, we motivate and describe Adaptive Label Error Detection (ALED), a novel method of detecting mislabeling. ALED extracts an intermediate feature space from a deep convolutional neural network, denoises the features, models the reduced manifold of each class with a multidimensional Gaussian distribution, and performs a simple likelihood ratio test to identify mislabeled samples. We show that ALED has markedly increased sensitivity, without compromising precision, compared to established label error detection methods, on multiple medical imaging datasets. We demonstrate an example where fine-tuning a neural network on corrected data results in a 33.8% decrease in test set errors, providing strong benefits to end users. The ALED detector is deployed in the Python package statlab."}
{"id": "2601.10087", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10087", "abs": "https://arxiv.org/abs/2601.10087", "authors": ["Kazuki Kobayashi", "Tatsuro Yuge"], "title": "Pseudomode approach to Fano effect in dissipative cavity quantum electrodynamics", "comment": "9 pages, 2 figures", "summary": "We study the Fano effect in dissipative cavity quantum electrodynamics, which originates from the interference between the emitter's direct radiation and that mediated by a cavity mode. Starting from a two-level system coupled to a structured reservoir, we show that a quantum master equation previously derived within the Born-Markov approximation can be rederived by introducing a single auxiliary mode via pseudomode approach. We identify the corresponding spectral function of the system--environment interaction and demonstrate that it consists of a constant and a non-Lorentzian contribution forming the Fano profile. The constant term is shown to be essential for obtaining a Lindblad master equation and is directly related to the rate associated with this Fano interference. Furthermore, by applying Fano diagonalization to a common-environment setup including an explicit cavity mode, we independently derive the same spectral function in the strongest-interference regime. Our results establish a unified framework for describing the Fano effect in single-mode cavity QED systems and clarify its non-Markovian origin encoded in the spectral function."}
{"id": "2601.10089", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10089", "abs": "https://arxiv.org/abs/2601.10089", "authors": ["Ashley Klein", "Edward Raff", "Marcia DesJardin"], "title": "Bayesian Meta-Analyses Could Be More: A Case Study in Trial of Labor After a Cesarean-section Outcomes and Complications", "comment": "To appear in AAAI 2026", "summary": "The meta-analysis's utility is dependent on previous studies having accurately captured the variables of interest, but in medical studies, a key decision variable that impacts a physician's decisions was not captured. This results in an unknown effect size and unreliable conclusions. A Bayesian approach may allow analysis to determine if the claim of a positive effect is still warranted, and we build a Bayesian approach to this common medical scenario. To demonstrate its utility, we assist professional OBGYNs in evaluating Trial of Labor After a Cesarean-section (TOLAC) situations where few interventions are available for patients and find the support needed for physicians to advance patient care."}
{"id": "2601.10111", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10111", "abs": "https://arxiv.org/abs/2601.10111", "authors": ["Jiwon Heo", "Sojeong Park", "Changhun Oh"], "title": "Classical simulation of a quantum circuit with noisy magic inputs", "comment": "21 pages, 5 figures", "summary": "Magic states are essential for universal quantum computation and are widely viewed as a key source of quantum advantage, yet in realistic devices they are inevitably noisy. In this work, we characterize how noise on injected magic resources changes the classical simulability of quantum circuits and when it induces a transition from classically intractable behavior to efficient classical simulation. We adopt a resource-centric noise model in which only the injected magic components are noisy, while the baseline states, operations, and measurements belong to an efficiently simulable family. Within this setting, we develop an approximate classical sampling algorithm with controlled error and prove explicit noise-dependent conditions under which the algorithm runs in polynomial time. Our framework applies to both qubit circuits with Clifford baselines and fermionic circuits with matchgate baselines, covering representative noise channels such as dephasing and particle loss. We complement the analysis with numerical estimates of the simulation cost, providing concrete thresholds and runtime scaling across practically relevant parameter regimes."}
{"id": "2601.10092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10092", "abs": "https://arxiv.org/abs/2601.10092", "authors": ["Jongseok Kim", "Seongae Kang", "Jonghwan Shin", "Yuhan Lee", "Ohyun Jo"], "title": "LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data", "comment": null, "summary": "Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions."}
{"id": "2601.10118", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.10118", "abs": "https://arxiv.org/abs/2601.10118", "authors": ["Calum F. Shelden", "Jeremy N. Munday"], "title": "Casimir interactions as a probe of broadband optical response", "comment": "13 pages, 4 figures", "summary": "Casimir forces arise from quantum electromagnetic fluctuations and depend on the dielectric response of interacting materials across the entire frequency spectrum. Although this dependence is central to Lifshitz theory of the Casimir effect, the formulation of the force in terms of dielectric functions evaluated at imaginary frequencies has largely obscured its connection to real-frequency optical properties, limiting the use of Casimir interactions as a probe of materials. Here we demonstrate that Casimir force measurements encode sufficient information to reconstruct a material's broadband optical response. Using supervised machine learning to invert Lifshitz theory, we determine the complex permittivity of a material over more than seven orders of magnitude in frequency from a single force-distance curve. We show that measurements at different separations selectively constrain distinct frequency ranges of the dielectric response, providing direct physical insight into how quantum fluctuations sample the electromagnetic spectrum. These results establish Casimir interactions as a physically constrained, broadband spectroscopic tool and open new opportunities for optical characterization in regimes inaccessible to conventional techniques."}
{"id": "2601.10096", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10096", "abs": "https://arxiv.org/abs/2601.10096", "authors": ["Piyush Singh Pasi"], "title": "Multilingual-To-Multimodal (M2M): Unlocking New Languages with Monolingual Text", "comment": "EACL 2026 Findings accepted. Initial Draft of Camera-ready", "summary": "Multimodal models excel in English, supported by abundant image-text and audio-text data, but performance drops sharply for other languages due to limited multilingual multimodal resources. Existing solutions rely heavily on machine translation, while advances in multilingual text modeling remain underutilized. We introduce METAL, a lightweight alignment method that learns only a few linear layers using English text alone to map multilingual text embeddings into a multimodal space. Despite its simplicity, METAL matches baseline performance in English (94.9 percent Recall at 10) and achieves strong zero-shot transfer (89.5 percent Recall at 10 averaged across 11 languages, 10 unseen) on XTD text-to-image retrieval. Qualitative t-SNE visualizations show that multilingual embeddings align tightly with multimodal representations, while weight analysis reveals that the transformation reshapes embedding geometry rather than performing trivial rotations. Beyond image-text retrieval, METAL generalizes to audio-text retrieval and cross-lingual text-to-image generation. We release code and checkpoints at https://github.com/m2m-codebase/M2M , as well as multilingual evaluation datasets including MSCOCO Multilingual 30K (https://huggingface.co/datasets/piyushsinghpasi/mscoco-multilingual-30k ), AudioCaps Multilingual (https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual ), and Clotho Multilingual (https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual ), to facilitate further research."}
{"id": "2601.10144", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10144", "abs": "https://arxiv.org/abs/2601.10144", "authors": ["Xiang Fang", "Jixuan Ruan", "Sharanya Prabhu", "Ang Li", "Travis Humble", "Dean Tullsen", "Yufei Ding"], "title": "Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures", "comment": "15 pages, 7 figures", "summary": "The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers."}
{"id": "2601.10137", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10137", "abs": "https://arxiv.org/abs/2601.10137", "authors": ["Ziyi Ding", "Chenfei Ye-Hao", "Zheyuan Wang", "Xiao-Ping Zhang"], "title": "Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation", "comment": null, "summary": "Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96."}
{"id": "2601.10147", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10147", "abs": "https://arxiv.org/abs/2601.10147", "authors": ["Mei-Qi Gao", "Song-hai Li", "Xun Li", "Xingli Li", "Jiong Cheng", "Wenlin Li"], "title": "Fluctuation-induced quenching of chaos in quantum optics", "comment": null, "summary": "Recent studies have extensively explored chaotic dynamics in quantum optical systems through the mean-field approximation, which corresponds to an ideal, fluctuation-free scenario. However, the inherent sensitivity of chaos to initial conditions implies that even minute fluctuations can be amplified, thereby questioning the applicability of this approximation. Here, we analyze these chaotic effects using stochastic Langevin equations or the Lindblad master equation. For systems operating at frequencies of $10^5$ to $10^7$ Hz, we demonstrate that room-temperature thermal fluctuations are sufficient to suppress chaos at the level of expectation values, even under weak nonlinearity. Furthermore, nonlinearity induces deviations from Gaussian phase-space distributions of the quantum state, revealing attractor-like features in the Wigner function. With increasing nonlinearity, the noise threshold for chaos suppression decreases, approaching the scale of vacuum fluctuations. These results provide a bidirectional validation of the quantum mechanical suppression of chaos."}
{"id": "2601.10141", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10141", "abs": "https://arxiv.org/abs/2601.10141", "authors": ["Jiawen Zhang", "Yangfan Hu", "Kejia Chen", "Lipeng He", "Jiachen Ma", "Jian Lou", "Dan Li", "Jian Liu", "Xiaohu Yang", "Ruoxi Jia"], "title": "Understanding and Preserving Safety in Fine-Tuned LLMs", "comment": null, "summary": "Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task performance, whereas prioritizing utility typically requires deep fine-tuning that inevitably leads to steep safety declination.\n  In this work, we address this dilemma by shedding new light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, we uncover three key insights: (I) safety gradients lie in a low-rank subspace, while utility gradients span a broader high-dimensional space; (II) these subspaces are often negatively correlated, causing directional conflicts during fine-tuning; and (III) the dominant safety direction can be efficiently estimated from a single sample. Building upon these novel insights, we propose safety-preserving fine-tuning (SPF), a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace. Theoretically, we show that SPF guarantees utility convergence while bounding safety drift. Empirically, SPF consistently maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. Furthermore, SPF exhibits robust resistance to both deep fine-tuning and dynamic jailbreak attacks. Together, our findings provide new mechanistic understanding and practical guidance toward always-aligned LLM fine-tuning."}
{"id": "2601.10166", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.10166", "abs": "https://arxiv.org/abs/2601.10166", "authors": ["Miriam Goldack", "Yosi Atia", "Ori Alberton", "Karl Jansen"], "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware", "comment": "25 pages, 16 figures", "summary": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez."}
{"id": "2601.10150", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10150", "abs": "https://arxiv.org/abs/2601.10150", "authors": ["Qiang Yu", "Xinran Cheng", "Shiqiang Xu", "Chuanyi Liu"], "title": "Simple Network Graph Comparative Learning", "comment": "10 pages, 5 figures", "summary": "The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks."}
{"id": "2601.10190", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10190", "abs": "https://arxiv.org/abs/2601.10190", "authors": ["Zhiwen Lin", "Ke Li", "Kun Fang"], "title": "Exponential Analysis for Entanglement Distillation", "comment": null, "summary": "Historically, the focus in entanglement distillation has predominantly been on the distillable entanglement, and the framework assumes complete knowledge of the initial state. In this paper, we study the reliability function of entanglement distillation, which specifies the optimal exponent of the decay of the distillation error when the distillation rate is below the distillable entanglement. Furthermore, to capture greater operational significance, we extend the framework from the standard setting of known states to a black-box setting, where distillation is performed from a set of possible states. We establish an exact finite blocklength result connecting to composite correlated hypothesis testing without any redundant correction terms. Based on this, the reliability function of entanglement distillation is characterized by the regularized quantum Hoeffding divergence. In the special case of a pure initial state, our result reduces to the error exponent for entanglement concentration derived by Hayashi et al. in 2003. Given full prior knowledge of the state, we construct a concrete optimal distillation protocol. Additionally, we analyze the strong converse exponent of entanglement distillation. While all the above results assume the free operations to be non-entangling, we also investigate other free operation classes, including PPT-preserving, dually non-entangling, and dually PPT-preserving operations."}
{"id": "2601.10155", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10155", "abs": "https://arxiv.org/abs/2601.10155", "authors": ["Aryan Karmore"], "title": "LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers", "comment": null, "summary": "Compressing the KV cache is a required step to deploy large language models on edge devices. Current quantization methods compress storage but fail to reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16 before use. We observe that attention scoring is mathematically equivalent to the inner product similarity search and we can apply some compression techniques from vector databases to compress KV-cache better. We propose LOOKAT, which applies product quantization and asymmetric distance computation, to transformer architecture by decomposing key vectors into subspaces, learning codebooks and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64 $\\times$ compression at 95.7\\% output fidelity and 32 $\\times$ compression at 95.0\\% fidelity when tested on GPT-2. LOOKAT requires no architecture changes or training while maintaining rank correlation $ρ> 0.95$. Theoretical analysis confirms that rank correlation degrades as $O(d_k/mK)$, with guarantees validated across sequence lengths up to 1024 tokens."}
{"id": "2601.10194", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.10194", "abs": "https://arxiv.org/abs/2601.10194", "authors": ["Weitang Li", "Jiajun Ren", "Lixue Cheng", "Cunxi Gong"], "title": "Autonomous Quantum Simulation through Large Language Model Agents", "comment": null, "summary": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training. By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes. We benchmark three configurations (baseline, single-agent with in-context learning, and multi-agent with in-context learning) on problems spanning quantum phase transitions, open quantum system dynamics, and photochemical reactions. Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures."}
{"id": "2601.10176", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10176", "abs": "https://arxiv.org/abs/2601.10176", "authors": ["Mingyu Zhao", "Haoran Bai", "Yu Tian", "Bing Zhu", "Hengliang Luo"], "title": "CC-OR-Net: A Unified Framework for LTV Prediction through Structural Decoupling", "comment": "Accepted by WWW'26", "summary": "Customer Lifetime Value (LTV) prediction, a central problem in modern marketing, is characterized by a unique zero-inflated and long-tail data distribution. This distribution presents two fundamental challenges: (1) the vast majority of low-to-medium value users numerically overwhelm the small but critically important segment of high-value \"whale\" users, and (2) significant value heterogeneity exists even within the low-to-medium value user base. Common approaches either rely on rigid statistical assumptions or attempt to decouple ranking and regression using ordered buckets; however, they often enforce ordinality through loss-based constraints rather than inherent architectural design, failing to balance global accuracy with high-value precision. To address this gap, we propose \\textbf{C}onditional \\textbf{C}ascaded \\textbf{O}rdinal-\\textbf{R}esidual Networks \\textbf{(CC-OR-Net)}, a novel unified framework that achieves a more robust decoupling through \\textbf{structural decomposition}, where ranking is architecturally guaranteed. CC-OR-Net integrates three specialized components: a \\textit{structural ordinal decomposition module} for robust ranking, an \\textit{intra-bucket residual module} for fine-grained regression, and a \\textit{targeted high-value augmentation module} for precision on top-tier users. Evaluated on real-world datasets with over 300M users, CC-OR-Net achieves a superior trade-off across all key business metrics, outperforming state-of-the-art methods in creating a holistic and commercially valuable LTV prediction solution."}
{"id": "2601.10197", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10197", "abs": "https://arxiv.org/abs/2601.10197", "authors": ["Maxwell West"], "title": "On the average-case complexity of learning states from the circular and Gaussian ensembles", "comment": "22 pages", "summary": "Studying the complexity of states sampled from various ensembles is a central component of quantum information theory. In this work we establish the average-case hardness of learning, in the statistical query model, the Born distributions of states sampled uniformly from the circular and (fermionic) Gaussian ensembles. These ensembles of states are induced variously by the uniform measures on the compact symmetric spaces of type AI, AII, and DIII. This finding complements analogous recent results for states sampled from the classical compact groups. On the technical side, we employ a somewhat unconventional approach to integrating over the compact groups which may be of some independent interest. For example, our approach allows us to exactly evaluate the total variation distances between the output distributions of Haar random unitary and orthogonal circuits and the constant distribution, which were previously known only approximately."}
{"id": "2601.10180", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10180", "abs": "https://arxiv.org/abs/2601.10180", "authors": ["Chuyi Wang", "Xiaohui Xie", "Tongze Wang", "Yong Cui"], "title": "Bias in the Shadows: Explore Shortcuts in Encrypted Network Traffic Classification", "comment": null, "summary": "Pre-trained models operating directly on raw bytes have achieved promising performance in encrypted network traffic classification (NTC), but often suffer from shortcut learning-relying on spurious correlations that fail to generalize to real-world data. Existing solutions heavily rely on model-specific interpretation techniques, which lack adaptability and generality across different model architectures and deployment scenarios.\n  In this paper, we propose BiasSeeker, the first semi-automated framework that is both model-agnostic and data-driven for detecting dataset-specific shortcut features in encrypted traffic. By performing statistical correlation analysis directly on raw binary traffic, BiasSeeker identifies spurious or environment-entangled features that may compromise generalization, independent of any classifier. To address the diverse nature of shortcut features, we introduce a systematic categorization and apply category-specific validation strategies that reduce bias while preserving meaningful information.\n  We evaluate BiasSeeker on 19 public datasets across three NTC tasks. By emphasizing context-aware feature selection and dataset-specific diagnosis, BiasSeeker offers a novel perspective for understanding and addressing shortcut learning in encrypted network traffic classification, raising awareness that feature selection should be an intentional and scenario-sensitive step prior to model training."}
{"id": "2601.10203", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10203", "abs": "https://arxiv.org/abs/2601.10203", "authors": ["Zheng Zhao", "Weifeng Zhuang", "Yanwu Gu", "Peng Qian", "Xiao Xiao", "Dong E. Liu"], "title": "Topology-Aware Block Coordinate Descent for Qubit Frequency Calibration of Superconducting Quantum Processors", "comment": "17 pages,6 figures", "summary": "Pre-execution calibration is a major bottleneck for operating superconducting quantum processors, and qubit frequency allocation is especially challenging due to crosstalk-coupled objectives. We establish that the widely-used Snake optimizer is mathematically equivalent to Block Coordinate Descent (BCD), providing a rigorous theoretical foundation for this calibration strategy. Building on this formalization, we present a topology-aware block ordering obtained by casting order selection as a Sequence-Dependent Traveling Salesman Problem (SD-TSP) and solving it efficiently with a nearest-neighbor heuristic. The SD-TSP cost reflects how a given block choice expands the reduced-circuit footprint required to evaluate the block-local objective, enabling orders that minimize per-epoch evaluation time. Under local crosstalk/bounded-degree assumptions, the method achieves linear complexity in qubit count per epoch, while retaining calibration quality. We formalize the calibration objective, clarify when reduced experiments are equivalent or approximate to the full objective, and analyze convergence of the resulting inexact BCD with noisy measurements. Simulations on multi-qubit models show that the proposed BCD-NNA ordering attains the same optimization accuracy at markedly lower runtime than graph-based heuristics (BFS, DFS) and random orders, and is robust to measurement noise and tolerant to moderate non-local crosstalk. These results provide a scalable, implementation-ready workflow for frequency calibration on NISQ-era processors."}
{"id": "2601.10181", "categories": ["cs.LG", "astro-ph.EP"], "pdf": "https://arxiv.org/pdf/2601.10181", "abs": "https://arxiv.org/abs/2601.10181", "authors": ["Kiattikun Chobtham"], "title": "Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand", "comment": null, "summary": "Climate prediction is a challenge due to the intricate spatiotemporal patterns within Earth systems. Global climate indices, such as the El Niño Southern Oscillation, are standard input features for long-term rainfall prediction. However, a significant gap persists regarding local-scale indices capable of improving predictive accuracy in specific regions of Thailand. This paper introduces a novel NorthEast monsoon climate index calculated from sea surface temperature to reflect the climatology of the boreal winter monsoon. To optimise the calculated areas used for this index, a Deep Q-Network reinforcement learning agent explores and selects the most effective rectangles based on their correlation with seasonal rainfall. Rainfall stations were classified into 12 distinct clusters to distinguish rainfall patterns between southern and upper Thailand. Experimental results show that incorporating the optimised index into Long Short-Term Memory models significantly improves long-term monthly rainfall prediction skill in most cluster areas. This approach effectively reduces the Root Mean Square Error for 12-month-ahead forecasts."}
{"id": "2601.10206", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10206", "abs": "https://arxiv.org/abs/2601.10206", "authors": ["Nirupam Basak", "Goutam Paul", "Pritam Chattopadhyay"], "title": "Noise-Resilient Quantum Evolution in Open Systems through Error-Correcting Frameworks", "comment": null, "summary": "We analyze quantum state preservation in open quantum systems using quantum error-correcting (QEC) codes that are explicitly embedded into microscopic system-bath models. Instead of abstract quantum channels, we consider multi-qubit registers coupled to bosonic thermal environments, derive a second-order master equation for the reduced dynamics, and use it to benchmark the five-qubit, Steane, and toric codes under local and collective noise. We compute state fidelities for logical qubits as functions of coupling strength, bath temperature, and the number of correction cycles. In the low-temperature regime, we find that repeated error-correction with the five-qubit code strongly suppresses decoherence and relaxation, while in the high-temperature regime, thermal excitations dominate the dynamics and reduce the benefit of all codes, though the five-qubit code still outperforms the Steane and toric codes. For two-qubit Werner states, we identify a critical evolution time before which QEC does not improve fidelity, and this time increases as entanglement grows. After this critical time, QEC does improve fidelity. Comparative analysis further reveals that the five-qubit code (the smallest perfect code) offers consistently higher fidelities than topological and concatenated architectures in these open-system settings. These findings establish a quantitative framework for evaluating QEC under realistic noise environments and provide guidance for developing noise-resilient quantum architectures in near-term quantum technologies."}
{"id": "2601.10199", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10199", "abs": "https://arxiv.org/abs/2601.10199", "authors": ["Antonio Briola", "Marwin Schmidt", "Fabio Caccioli", "Carlos Ros Perez", "James Singleton", "Christian Michler", "Tomaso Aste"], "title": "Graph Regularized PCA", "comment": "15 pages, 2 figures, 4 Tables", "summary": "High-dimensional data often exhibit dependencies among variables that violate the isotropic-noise assumption under which principal component analysis (PCA) is optimal. For cases where the noise is not independent and identically distributed across features (i.e., the covariance is not spherical) we introduce Graph Regularized PCA (GR-PCA). It is a graph-based regularization of PCA that incorporates the dependency structure of the data features by learning a sparse precision graph and biasing loadings toward the low-frequency Fourier modes of the corresponding graph Laplacian. Consequently, high-frequency signals are suppressed, while graph-coherent low-frequency ones are preserved, yielding interpretable principal components aligned with conditional relationships. We evaluate GR-PCA on synthetic data spanning diverse graph topologies, signal-to-noise ratios, and sparsity levels. Compared to mainstream alternatives, it concentrates variance on the intended support, produces loadings with lower graph-Laplacian energy, and remains competitive in out-of-sample reconstruction. When high-frequency signals are present, the graph Laplacian penalty prevents overfitting, reducing the reconstruction accuracy but improving structural fidelity. The advantage over PCA is most pronounced when high-frequency signals are graph-correlated, whereas PCA remains competitive when such signals are nearly rotationally invariant. The procedure is simple to implement, modular with respect to the precision estimator, and scalable, providing a practical route to structure-aware dimensionality reduction that improves structural fidelity without sacrificing predictive performance."}
{"id": "2601.10209", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10209", "abs": "https://arxiv.org/abs/2601.10209", "authors": ["S. Messelot", "A. Leblanc", "J. -S. Tettekpoe", "F. Lefloch", "Q. Ficheux", "J. Renard", "É. Dumur"], "title": "Coherence Limits in Interference-Based cos(2$\\varphi$) Qubits", "comment": "19 pages, 14 figures", "summary": "We investigate the coherence properties of parity-protected $\\cos(2\\varphi)$ qubits based on interferences between two Josephson elements in a superconducting loop. We show that qubit implementations of a $\\cos(2\\varphi)$ potential using a single loop, such as those employing semiconducting junctions, rhombus circuits, flowermon and KITE structures, can be described by the same Hamiltonian as two multi-harmonic Josephson junctions in a SQUID geometry. We find that, despite the parity protection arising from the suppression of single Cooper pair tunneling, there exists a fundamental trade-off between charge and flux noise dephasing channels. Using numerical simulations, we examine how relaxation and dephasing rates depend on external flux and circuit parameters, and we identify the best compromise for maximum coherence. With currently existing circuit parameters, the qubit lifetime $T_1$ can exceed milliseconds while the dephasing time $T_\\varphi$ remains limited to only a few microseconds due to either flux or charge noise. Our findings establish practical limits on the coherence of this class of qubits and raise questions about the long-term potential of this approach."}
{"id": "2601.10201", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10201", "abs": "https://arxiv.org/abs/2601.10201", "authors": ["Jiarui Yao", "Ruida Wang", "Tong Zhang"], "title": "PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary", "comment": null, "summary": "Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuition behind the process signals design lacks rigorous theoretical support, leaving the understanding of the optimization mechanism opaque. In this paper, we propose Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps, with rigorous process rewards that could be assigned to models accordingly. Starting from theoretical motivation, we derive the formulation of PRL that is essentially equivalent to the objective of reward maximization plus a KL-divergence penalty term between the policy model and a reference model. However, PRL could turn the outcome reward into process supervision signals, which helps better guide the exploration during RL optimization. From our experiment results, we demonstrate that PRL not only improves the average performance for LLMs' reasoning ability measured by average @ n, but also broadens the reasoning boundary by improving the pass @ n metric. Extensive experiments show the effectiveness of PRL could be verified and generalized."}
{"id": "2601.10210", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10210", "abs": "https://arxiv.org/abs/2601.10210", "authors": ["J. Leibig", "M. Hörmann", "A. Langheld", "A. Schellenberger", "K. P. Schmidt"], "title": "Quantitative approach for the Dicke-Ising chain with an effective self-consistent matter Hamiltonian", "comment": "23 pages, 8 figures", "summary": "In the thermodynamic limit, the Dicke-Ising chain maps exactly onto an effective self-consistent matter Hamiltonian with the photon field acting solely as a self-consistent effective field. As a consequence, no quantum correlations between photons and spins are needed to understand the quantum phase diagram. This enables us to determine the quantum phase diagram in the thermodynamic limit using numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) to solve the resulting self-consistent matter Hamiltonian. This includes magnetically ordered phases with significantly improved accuracy compared to previous estimates. For ferromagnetic Ising couplings, we refine the location of the multicritical point governing the change in the order of the superradiant phase transition, reaching a relative accuracy of $10^{-4}$. For antiferromagnetic Ising couplings, we confirm the existence of the narrow antiferromagnetic superradiant phase in the thermodynamic limit. The effective matter Hamiltonian framework identifies the antiferromagnetic superradiant phase as the many-body ground state of an antiferromagnetic transverse-field Ising model with longitudinal field. This phase emerges through continuous Dicke-type polariton condensation from the antiferromagnetic normal phase, followed by a first-order transition to the paramagnetic superradiant phase. Thus, NLCE+DMRG provides a precise determination of the Dicke-Ising phase diagram in one dimension by solving the self-consistent effective matter Hamiltonian."}
{"id": "2601.10237", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.10237", "abs": "https://arxiv.org/abs/2601.10237", "authors": ["Murat Bilgehan Ertan", "Marten van Dijk"], "title": "Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD", "comment": null, "summary": "Differentially Private Stochastic Gradient Descent (DP-SGD) is the dominant paradigm for private training, but its fundamental limitations under worst-case adversarial privacy definitions remain poorly understood. We analyze DP-SGD in the $f$-differential privacy framework, which characterizes privacy via hypothesis-testing trade-off curves, and study shuffled sampling over a single epoch with $M$ gradient updates. We derive an explicit suboptimal upper bound on the achievable trade-off curve. This result induces a geometric lower bound on the separation $κ$ which is the maximum distance between the mechanism's trade-off curve and the ideal random-guessing line. Because a large separation implies significant adversarial advantage, meaningful privacy requires small $κ$. However, we prove that enforcing a small separation imposes a strict lower bound on the Gaussian noise multiplier $σ$, which directly limits the achievable utility. In particular, under the standard worst-case adversarial model, shuffled DP-SGD must satisfy\n  $σ\\ge \\frac{1}{\\sqrt{2\\ln M}}$ $\\quad\\text{or}\\quad$ $κ\\ge\\ \\frac{1}{\\sqrt{8}}\\!\\left(1-\\frac{1}{\\sqrt{4π\\ln M}}\\right)$,\n  and thus cannot simultaneously achieve strong privacy and high utility. Although this bound vanishes asymptotically as $M \\to \\infty$, the convergence is extremely slow: even for practically relevant numbers of updates the required noise magnitude remains substantial. We further show that the same limitation extends to Poisson subsampling up to constant factors. Our experiments confirm that the noise levels implied by this bound leads to significant accuracy degradation at realistic training settings, thus showing a critical bottleneck in DP-SGD under standard worst-case adversarial assumptions."}
{"id": "2601.10243", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10243", "abs": "https://arxiv.org/abs/2601.10243", "authors": ["Masahito Hayashi", "Hao-Chung Cheng", "Li Gao"], "title": "Adversarial Hypothesis Testing for Quantum Channels", "comment": "15 pages. Comments are welcome", "summary": "This paper presents a systematic study of adversarial hypothesis testing for both quantum-quantum (QQ) and classical-quantum (CQ) channels. Unlike conventional channel discrimination, we consider a framework where the sender, Alice, selects the channel input adversarially to minimize Bob's distinguishability. We analyze this problem across four settings based on whether Alice employs i.i.d. or general inputs and whether the receiver, Bob, is informed of the specific input choice (allowing his measurement to depend on the input). We characterize the Stein exponents for each setting and reveal a striking distinction in behavior: for QQ channels with i.i.d. inputs, Bob's knowledge of the input significantly enhances distinguishability, yet this advantage vanishes when general inputs are permitted. In contrast, for CQ channels, Bob being informed provides a consistent advantage over the corresponding entanglement-breaking channels for both i.i.d. and general inputs. These results demonstrate a unique phenomenon in adversarial hypothesis testing where the CQ channel does not merely behave as a special case of the QQ channel."}
{"id": "2601.10251", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10251", "abs": "https://arxiv.org/abs/2601.10251", "authors": ["Hongru Duan", "Yongle Chen", "Lei Guan"], "title": "X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction", "comment": null, "summary": "Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, during training, its optimization behavior does not always align with theoretical expectations, since both sharp and flat regions may yield a small perturbed loss. In such cases, the gradient may still point toward sharp regions, failing to achieve the intended effect of SAM. To address this issue, we investigate SAM from a spectral and geometric perspective: specifically, we utilize the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. Our analysis illustrates that when this angle is less than or equal to ninety degrees, the effect of SAM's sharpness regularization can be weakened. Furthermore, we propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. We prove X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages."}
{"id": "2601.10281", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10281", "abs": "https://arxiv.org/abs/2601.10281", "authors": ["Maristella Crotti", "Luca Razzoli", "Luigi Giannelli", "Giuseppe A. Falci", "Giuliano Benenti"], "title": "Optimal control of a dissipative micromaser quantum battery in the ultrastrong coupling regime", "comment": "13 pages, 6 figures", "summary": "We investigate the open system dynamics of a micromaser quantum battery operating in the ultrastrong coupling (USC) regime under environmental dissipation. The battery consists of a single-mode electromagnetic cavity sequentially interacting, via the Rabi Hamiltonian, with a stream of qubits acting as chargers. Dissipative effects arise from the weak coupling of the qubit-cavity system to a thermal bath. Non-negligible in the USC regime, the counter-rotating terms substantially improve the charging speed, but also lead, in the absence of dissipation, to unbounded energy growth and highly mixed cavity states. Dissipation during each qubit-cavity interaction mitigates these detrimental effects, yielding steady-state of finite energy and ergotropy. Optimal control on qubit preparation and interaction times enhances battery's performance in: (i) Maximizing the stored ergotropy trhough an optimized charging protocol; (ii) Stabilizing the stored ergotropy against dissipative losses through an optimized measurement-based passive-feedback strategy. Overall, our numerical results demonstrate that the interplay of ultrastrong light-matter coupling, controlled dissipation, and optimized control strategies enables micromaser quantum batteries to achieve both enhanced charging performance and long-term stability under realistic conditions."}
{"id": "2601.10267", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10267", "abs": "https://arxiv.org/abs/2601.10267", "authors": ["Ziqiong Wang", "Tianqi Ren", "Rongpeng Li", "Zhifeng Zhao", "Honggang Zhang"], "title": "In-Context Source and Channel Coding", "comment": null, "summary": "Separate Source-Channel Coding (SSCC) remains attractive for text transmission due to its modularity and compatibility with mature entropy coders and powerful channel codes. However, SSCC often suffers from a pronounced cliff effect in low Signal-to-Noise Ratio (SNR) regimes, where residual bit errors after channel decoding can catastrophically break lossless source decoding, especially for Arithmetic Coding (AC) driven by Large Language Models (LLMs). This paper proposes a receiver-side In-Context Decoding (ICD) framework that enhances SSCC robustness without modifying the transmitter. ICD leverages an Error Correction Code Transformer (ECCT) to obtain bit-wise reliability for the decoded information bits. Based on the context-consistent bitstream, ICD constructs a confidence-ranked candidate pool via reliability-guided bit flipping, samples a compact yet diverse subset of candidates, and applies an LLM-based arithmetic decoder to obtain both reconstructions and sequence-level log-likelihoods. A reliability-likelihood fusion rule then selects the final output. We further provide theoretical guarantees on the stability and convergence of the proposed sampling procedure. Extensive experiments over Additive White Gaussian Noise (AWGN) and Rayleigh fading channels demonstrate consistent gains compared with conventional SSCC baselines and representative Joint Source-Channel Coding (JSCC) schemes."}
{"id": "2601.10289", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10289", "abs": "https://arxiv.org/abs/2601.10289", "authors": ["Rodrigo M. Sanz", "Emilio Annoni", "Stephen C. Wein", "Carmen G. Almudever", "Shane Mansfield", "Ellen Derbyshire", "Rawad Mezher"], "title": "Exponential improvement in benchmarking multiphoton interference", "comment": "7 pages + 20 pages appendix, comments welcome !", "summary": "Several photonic quantum technologies rely on the ability to generate multiple indistinguishable photons. Benchmarking the level of indistinguishability of these photons is essential for scalability. The Hong-Ou-Mandel dip provides a benchmark for the indistinguishability between two photons, and extending this test to the multi-photon setting has so far resulted in a protocol that computes the genuine n-photon indistinguishability (GI). However, this protocol has a sample complexity that increases exponentially with the number of input photons for an estimation of GI up to a given additive error. To address this problem, we introduce new theorems that strengthen our understanding of the relationship between distinguishability and the suppression laws of the quantum Fourier transform interferometer (QFT). Building on this, we propose a protocol using the QFT for benchmarking GI that achieves constant sample complexity for the estimation of GI up to a given additive error for prime photon numbers, and sub-polynomial scaling otherwise, representing an exponential improvement over the state of the art. We prove the optimality of our protocol in many relevant scenarios and validate our approach experimentally on Quandela's reconfigurable photonic quantum processor, where we observe a clear advantage in runtime and precision over the state of the art. We therefore establish the first scalable method for computing multi-photon indistinguishability, which applies naturally to current and near-term photonic quantum hardware."}
{"id": "2601.10269", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10269", "abs": "https://arxiv.org/abs/2601.10269", "authors": ["P. Sánchez", "K. Reyes", "B. Radu", "E. Fernández"], "title": "Early Fault Detection on CMAPSS with Unsupervised LSTM Autoencoders", "comment": null, "summary": "This paper introduces an unsupervised health-monitoring framework for turbofan engines that does not require run-to-failure labels. First, operating-condition effects in NASA CMAPSS sensor streams are removed via regression-based normalisation; then a Long Short-Term Memory (LSTM) autoencoder is trained only on the healthy portion of each trajectory. Persistent reconstruction error, estimated using an adaptive data-driven threshold, triggers real-time alerts without hand-tuned rules. Benchmark results show high recall and low false-alarm rates across multiple operating regimes, demonstrating that the method can be deployed quickly, scale to diverse fleets, and serve as a complementary early-warning layer to Remaining Useful Life models."}
{"id": "2601.10302", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10302", "abs": "https://arxiv.org/abs/2601.10302", "authors": ["Yu. M. Poluektov"], "title": "Complex scalar relativistic field as a probability amplitude", "comment": "11 pages", "summary": "A relativistic equation for a neutral complex field as a probability amplitude is proposed. The continuity equation for the probability density is obtained. It is shown that there are two types of excitations of this field, which describe particles with positive energy and different dispersion laws. Based on the Lagrangian formalism, conservation laws are obtained. The transition to secondary quantization is considered."}
{"id": "2601.10274", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10274", "abs": "https://arxiv.org/abs/2601.10274", "authors": ["Emre Ozbas", "Melih Bastopcu"], "title": "Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers", "comment": null, "summary": "We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results."}
{"id": "2601.10319", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10319", "abs": "https://arxiv.org/abs/2601.10319", "authors": ["Gavriil Voloshin", "Konstantin Barantsev", "Andrey Litvinov"], "title": "Addition to the dynamic Stark shift of the coherent population trapping resonance", "comment": "11 pages, 7 figures", "summary": "This paper presents a theoretical study of the light-induced shift of the coherent population trapping resonance. An analytical model is proposed that describes the interaction of two radiation components with an atomic system using a $Λ$ scheme and takes into account an additional level of excited state. Both weak and strong coupling regimes with off-resonant transitions are considered. It is shown that, in addition to the conventional dynamic Stark shift, an extra shift arises due to the distortion of the resonance line shape when bichromatic laser radiation interacts with off-resonant atomic transitions. An analytical expression for this additional shift is derived in the weak-coupling limit, and its significant impact on the resonance shape and sensitivity to the intensities of the laser field components is demonstrated. It is found that under strong coupling conditions, the additional shift can deviate substantially from a linear dependence on light intensity, suggesting new opportunities for controlling light shifts in precision atomic devices such as quantum frequency standards."}
{"id": "2601.10282", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.10282", "abs": "https://arxiv.org/abs/2601.10282", "authors": ["Jose Marie Antonio Minoza"], "title": "SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics $dz/dt = Az$ in a learned observable space, both PIKE (without explicit sparsity) and SPIKE (with L1 regularization on $A$) learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across parabolic, hyperbolic, dispersive, and stiff PDEs, including fluid dynamics (Navier-Stokes) and chaotic ODEs (Lorenz), demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators."}
{"id": "2601.10325", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10325", "abs": "https://arxiv.org/abs/2601.10325", "authors": ["Yifang Xu", "Yilong Zhou", "Ziyue Hua", "Lida Sun", "Jie Zhou", "Weiting Wang", "Weizhou Cai", "Hongwei Huang", "Lintao Xiao", "Guangming Xue", "Haifeng Yu", "Ming Li", "Chang-Ling Zou", "Luyan Sun"], "title": "Principles of Optics in the Fock Space: Scalable Manipulation of Giant Quantum States", "comment": "25 pages, 15 figures, 1 table", "summary": "The manipulation of distinct degrees of freedom of photons plays a critical role in both classical and quantum information processing. While the principles of wave optics provide elegant and scalable control over classical light in spatial and temporal domains, engineering quantum states in Fock space has been largely restricted to few-photon regimes, hindered by the computational and experimental challenges of large Hilbert spaces. Here, we introduce ``Fock-space optics\", establishing a conceptual framework of wave propagation in the quantum domain by treating photon number as a synthetic dimension. Using a superconducting microwave resonator, we experimentally demonstrate Fock-space analogues of optical propagation, refraction, lensing, dispersion, and interference with up to 180 photons. These results establish a fundamental correspondence between Schrödinger evolution in a single bosonic mode and classical paraxial wave propagation. By mapping intuitive optical concepts onto high-dimensional quantum state engineering, our work opens a path toward scalable control of large-scale quantum systems with thousands of photons and advanced bosonic information processing."}
{"id": "2601.10312", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10312", "abs": "https://arxiv.org/abs/2601.10312", "authors": ["Zhipeng Liu", "Peibo Duan", "Xuan Tang", "Haodong Jing", "Mingyang Geng", "Yongsheng Huang", "Jialu Xu", "Bin Zhang", "Binwu Wang"], "title": "We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental Time Series Classification", "comment": "This paper has been accepted for publication at ACM WWW 2026", "summary": "The World Wide Web thrives on intelligent services that rely on accurate time series classification, which has recently witnessed significant progress driven by advances in deep learning. However, existing studies face challenges in domain incremental learning. In this paper, we propose a lightweight and robust dual-causal disentanglement framework (DualCD) to enhance the robustness of models under domain incremental scenarios, which can be seamlessly integrated into time series classification models. Specifically, DualCD first introduces a temporal feature disentanglement module to capture class-causal features and spurious features. The causal features can offer sufficient predictive power to support the classifier in domain incremental learning settings. To accurately capture these causal features, we further design a dual-causal intervention mechanism to eliminate the influence of both intra-class and inter-class confounding features. This mechanism constructs variant samples by combining the current class's causal features with intra-class spurious features and with causal features from other classes. The causal intervention loss encourages the model to accurately predict the labels of these variant samples based solely on the causal features. Extensive experiments on multiple datasets and models demonstrate that DualCD effectively improves performance in domain incremental scenarios. We summarize our rich experiments into a comprehensive benchmark to facilitate research in domain incremental time series classification."}
{"id": "2601.10354", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10354", "abs": "https://arxiv.org/abs/2601.10354", "authors": ["Riccardo Falcone", "Claudio Conti"], "title": "Realistic prospects for testing a relativistic local quantum measurement inequality", "comment": null, "summary": "We investigate the experimental prospects for testing a relativistic local quantum measurement inequality that quantifies the trade-off between vacuum insensitivity and responsiveness to excitations for finite-size detectors. Building on the Reeh--Schlieder approximation for coherent states, we derive an explicit and practically applicable bound for arbitrary coherent states. To connect with realistic photodetection scenarios, we model the detection region as a square prism operating over a finite time window and consider a normally incident single-mode coherent state. Numerical results exhibit the expected qualitative behavior: suppressing dark counts necessarily tightens the achievable click probability."}
{"id": "2601.10328", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10328", "abs": "https://arxiv.org/abs/2601.10328", "authors": ["Yiqing Zou", "Hanning Yuan", "Qianyu Yang", "Ziqiang Yuan", "Shuliang Wang", "Sijie Ruan"], "title": "Meta Dynamic Graph for Traffic Flow Prediction", "comment": "Accepted to AAAI 2026", "summary": "Traffic flow prediction is a typical spatio-temporal prediction problem and has a wide range of applications. The core challenge lies in modeling the underlying complex spatio-temporal dependencies. Various methods have been proposed, and recent studies show that the modeling of dynamics is useful to meet the core challenge. While handling spatial dependencies and temporal dependencies using separate base model structures may hinder the modeling of spatio-temporal correlations, the modeling of dynamics can bridge this gap. Incorporating spatio-temporal heterogeneity also advances the main goal, since it can extend the parameter space and allow more flexibility. Despite these advances, two limitations persist: 1) the modeling of dynamics is often limited to the dynamics of spatial topology (e.g., adjacency matrix changes), which, however, can be extended to a broader scope; 2) the modeling of heterogeneity is often separated for spatial and temporal dimensions, but this gap can also be bridged by the modeling of dynamics. To address the above limitations, we propose a novel framework for traffic prediction, called Meta Dynamic Graph (MetaDG). MetaDG leverages dynamic graph structures of node representations to explicitly model spatio-temporal dynamics. This generates both dynamic adjacency matrices and meta-parameters, extending dynamic modeling beyond topology while unifying the capture of spatio-temporal heterogeneity into a single dimension. Extensive experiments on four real-world datasets validate the effectiveness of MetaDG."}
{"id": "2601.10380", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10380", "abs": "https://arxiv.org/abs/2601.10380", "authors": ["Shrigyan Brahmachari", "Shuchen Zhu", "Iman Marvian", "Yu Tong"], "title": "Learning Hamiltonians in the Heisenberg limit with static single-qubit fields", "comment": null, "summary": "Learning the Hamiltonian governing a quantum system is a central task in quantum metrology, sensing, and device characterization. Existing Heisenberg-limited Hamiltonian learning protocols either require multi-qubit operations that are prone to noise, or single-qubit operations whose frequency or strength increases with the desired precision. These two requirements limit the applicability of Hamiltonian learning on near-term quantum platforms. We present a protocol that learns a quantum Hamiltonian with the optimal Heisenberg-limited scaling using only single-qubit control in the form of static fields with strengths that are independent of the target precision. Our protocol is robust against the state preparation and measurement (SPAM) error. By overcoming these limitations, our protocol provides new tools for device characterization and quantum sensing. We demonstrate that our method achieves the Heisenberg-limited scaling through rigorous mathematical proof and numerical experiments. We also prove an information-theoretic lower bound showing that a non-vanishing static field strength is necessary for achieving the Heisenberg limit unless one employs an extensive number of discrete control operations."}
{"id": "2601.10349", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.10349", "abs": "https://arxiv.org/abs/2601.10349", "authors": ["Mark Kashirskiy", "Ilya Makarov"], "title": "SuS: Strategy-aware Surprise for Intrinsic Exploration", "comment": "8 pages, 7 figures, 3 tables. Code available at https://github.com/mariklolik/sus", "summary": "We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training."}
{"id": "2601.10385", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10385", "abs": "https://arxiv.org/abs/2601.10385", "authors": ["Eliya Blumenthal", "Natan Karaev", "Shay Hacohen-Gourgy"], "title": "Experimental Realization of Rabi-Driven Reset for Fast Cooling of a High-Q Cavity", "comment": null, "summary": "High-Q bosonic memories are central to hardware-efficient quantum error correction, but their isolation makes fast, high-fidelity reset a persistent bottleneck. Existing approaches either rely on weak intermode cross-Kerr conversion or on measurement-based sequences with substantial latency. Here we demonstrate a hardware-efficient Rabi-Driven Reset (RDR) that implements continuous, measurement-free cooling of a superconducting cavity mode. A strong resonant Rabi drive on a transmon, together with sideband drives on the memory and readout modes detuned by the Rabi frequency, converts the dispersive interaction into an effective Jaynes-Cummings coupling between the qubit dressed states and each mode. This realizes a tunable dissipation channel from the memory to the cold readout bath. Crucially, the engineered coupling scales with the qubit-mode dispersive interaction and the drive amplitude, rather than with the intermode cross-Kerr, enabling fast cooling even in very weakly coupled architectures that deliberately suppress direct mode-mode coupling. We demonstrate RDR of a single photon with a decay time of $1.2 μs$, more than two orders of magnitude faster than the intrinsic lifetime. Furthermore, we reset about 30 thermal photons in about $80 μs$ to a steady-state average photon number of $\\bar{n} = 0.045 \\pm 0.025$."}
{"id": "2601.10356", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10356", "abs": "https://arxiv.org/abs/2601.10356", "authors": ["Mesut Ceylan", "Alexis Tabin", "Patrick Langer", "Elgar Fleisch", "Filipe Barata"], "title": "EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography", "comment": null, "summary": "Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand whether predictions are stable under physiologically plausible variations and to what extent realistic, attainable changes in physiological signals would meaningfully alter a model's prediction. Counterfactual explanations (CFE) address these \"what-if\" questions, yet existing time series CFE generation methods are largely restricted to classification, overlook waveform morphology, and often produce physiologically implausible signals, limiting their applicability to continuous biomedical time series. To address these limitations, we introduce EvoMorph, a multi-objective evolutionary framework for generating physiologically plausible and diverse CFE for TSER applications. EvoMorph optimizes morphology-aware objectives defined on interpretable signal descriptors and applies transformations to preserve the waveform structure. We evaluated EvoMorph on three PPG datasets (heart rate, respiratory rate, and oxygen saturation) against a nearest-unlike-neighbor baseline. In addition, in a case study, we evaluated EvoMorph as a tool for uncertainty quantification by relating counterfactual sensitivity to bootstrap-ensemble uncertainty and data-density measures. Overall, EvoMorph enables the generation of physiologically-aware counterfactuals for continuous biomedical signals and supports uncertainty-aware interpretability, advancing trustworthy model analysis for clinical time-series applications."}
{"id": "2601.10395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10395", "abs": "https://arxiv.org/abs/2601.10395", "authors": ["Kläre Wienecke", "Gereon Koßmann", "René Schwonnek"], "title": "A Collection of Pinsker-type Inequalities for Quantum Divergences", "comment": "14 pages, 7 figures", "summary": "Pinsker's inequality sets a lower bound on the Umegaki divergence of two quantum states in terms of their trace distance. In this work, we formulate corresponding estimates for a variety of quantum and classical divergences including $f$-divergences like Hellinger and $χ^2$-divergences as well as Rényi divergences and special cases thereof like the Umegaki divergence, collision divergence, max divergence. We further provide a strategy on how to adapt these bounds to smoothed divergences."}
{"id": "2601.10358", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10358", "abs": "https://arxiv.org/abs/2601.10358", "authors": ["Jay Nandy", "Arnab Kumar Mondal", "Anuj Rathore", "Mahesh Chandran"], "title": "PLGC: Pseudo-Labeled Graph Condensation", "comment": null, "summary": "Large graph datasets make training graph neural networks (GNNs) computationally costly. Graph condensation methods address this by generating small synthetic graphs that approximate the original data. However, existing approaches rely on clean, supervised labels, which limits their reliability when labels are scarce, noisy, or inconsistent. We propose Pseudo-Labeled Graph Condensation (PLGC), a self-supervised framework that constructs latent pseudo-labels from node embeddings and optimizes condensed graphs to match the original graph's structural and feature statistics -- without requiring ground-truth labels. PLGC offers three key contributions: (1) A diagnosis of why supervised condensation fails under label noise and distribution shift. (2) A label-free condensation method that jointly learns latent prototypes and node assignments. (3) Theoretical guarantees showing that pseudo-labels preserve latent structural statistics of the original graph and ensure accurate embedding alignment. Empirically, across node classification and link prediction tasks, PLGC achieves competitive performance with state-of-the-art supervised condensation methods on clean datasets and exhibits substantial robustness under label noise, often outperforming all baselines by a significant margin. Our findings highlight the practical and theoretical advantages of self-supervised graph condensation in noisy or weakly-labeled environments."}
{"id": "2601.10408", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10408", "abs": "https://arxiv.org/abs/2601.10408", "authors": ["Luke Mortimer", "Leonardo Zambrano", "Antonio Acín", "Donato Farina"], "title": "Bounding many-body properties under partial information and finite measurement statistics", "comment": "12 pages, 7 figures", "summary": "Calculating bounds of properties of many-body quantum systems is of paramount importance, since they guide our understanding of emergent quantum phenomena and complement the insights obtained from estimation methods. Recent semidefinite programming approaches enable probabilistic bounds from finite-shot measurements of easily accessible, yet informationally incomplete, observables. Here we render these methods scalable in the number of qubits by instead utilizing moment-matrix relaxations. After introducing the general formalism, we show how the approach can be adapted with specific knowledge of the system, such as it being the ground state of a given Hamiltonian, possessing specific symmetries or being the steady state of a given Lindbladian. Our approach defines a scalable real-world certification scheme leveraging semidefinite programming relaxations and experimental estimations which, unavoidably, contain shot noise."}
{"id": "2601.10403", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10403", "abs": "https://arxiv.org/abs/2601.10403", "authors": ["Mohsin Hasan", "Viktor Ohanesian", "Artem Gazizov", "Yoshua Bengio", "Alán Aspuru-Guzik", "Roberto Bondesan", "Marta Skreta", "Kirill Neklyudov"], "title": "Discrete Feynman-Kac Correctors", "comment": "Code: https://github.com/hasanmohsin/discrete_fkc", "summary": "Discrete diffusion models have recently emerged as a promising alternative to the autoregressive approach for generating discrete sequences. Sample generation via gradual denoising or demasking processes allows them to capture hierarchical non-sequential interdependencies in the data. These custom processes, however, do not assume a flexible control over the distribution of generated samples. We propose Discrete Feynman-Kac Correctors, a framework that allows for controlling the generated distribution of discrete masked diffusion models at inference time. We derive Sequential Monte Carlo (SMC) algorithms that, given a trained discrete diffusion model, control the temperature of the sampled distribution (i.e. perform annealing), sample from the product of marginals of several diffusion processes (e.g. differently conditioned processes), and sample from the product of the marginal with an external reward function, producing likely samples from the target distribution that also have high reward. Notably, our framework does not require any training of additional models or fine-tuning of the original model. We illustrate the utility of our framework in several applications including: efficient sampling from the annealed Boltzmann distribution of the Ising model, improving the performance of language models for code generation and amortized learning, as well as reward-tilted protein sequence generation."}
{"id": "2601.10409", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10409", "abs": "https://arxiv.org/abs/2601.10409", "authors": ["Marcin Kotowski", "Michał Oszmaniec"], "title": "Tight bounds on recurrence time in closed quantum systems", "comment": null, "summary": "The evolution of an isolated quantum system inevitably exhibits recurrence: the state returns to the vicinity of its initial condition after finite time. Despite its fundamental nature, a rigorous quantitative understanding of recurrence has been lacking. We establish upper bounds on the recurrence time, $t_{\\mathrm{rec}} \\lesssim t_{\\mathrm{exit}}(ε)(1/ε)^d$, where $d$ is the Hilbert-space dimension, $ε$ the neighborhood size, and $t_{\\mathrm{exit}}(ε)$ the escape time from this neighborhood. For pure states evolving under a Hamiltonian $H$, estimating $t_{\\mathrm{exit}}$ is equivalent to an inverse quantum speed limit problem: finding upper bounds on the time a time-evolved state $ψ_t$ needs to depart from the $ε$-vicinity of the initial state $ψ_0$. We provide a partial solution, showing that under mild assumptions $t_{\\mathrm{exit}}(ε) \\approx ε/\\sqrt{ Δ(H^2)}$, with $Δ(H^2)$ the Hamiltonian variance in $ψ_0$. We show that our upper bound on $t_{\\mathrm{rec}}$ is generically saturated for random Hamiltonians. Finally, we analyze the impact of coherence of the initial state in the eigenbasis of $H$ on recurrence behavior."}
{"id": "2601.10407", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10407", "abs": "https://arxiv.org/abs/2601.10407", "authors": ["Yuanjie Zhao", "Junnan Qiu", "Yue Ding", "Jie Li"], "title": "CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning", "comment": null, "summary": "Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructiveness under a strict budget. Leveraging the theoretical insight that samples with high Temporal Difference (TD) errors are pivotal for value function convergence, we introduce an adaptive Critical Sample Selection strategy that concentrates the attack budget on the most influential transitions. To evade OOD detection, we propose a Correlation-Breaking Trigger mechanism that exploits the physical mutual exclusivity of state features (e.g., 95th percentile boundaries) to remain statistically concealed. Furthermore, we replace the conventional label inversion with a Gradient-Guided Action Generation mechanism, which searches for worst-case actions within the data manifold using the victim Q-network's gradient. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms state-of-the-art baselines, achieving high attack success rates against representative safety-constrained algorithms with a minimal 5% poisoning budget, while maintaining the agent's performance in clean environments."}
{"id": "2601.10423", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10423", "abs": "https://arxiv.org/abs/2601.10423", "authors": ["Abdul Rahaman Shaikh", "Tabish Qureshi"], "title": "Unifying Quantum and Classical Dynamics", "comment": "4 pages", "summary": "Classical and quantum physics represent two distinct theories; however, quantum physics is regarded as the more fundamental of the two. It is posited that classical mechanics should arise from quantum mechanics under certain limiting conditions. Nevertheless, this remains a challenging objective. In this work, we explore the potential for unifying the dynamics of classical and quantum physics. This discussion does not suggest that classical behavior emerges from quantum mechanics; rather, it demonstrates the exact equivalence between the dynamics of quantum observables and their classical counterparts. It is shown that the Heisenberg equations of motion can be cast in a form that is identical to Newton's equations of motion, with $\\hbar$ being absent from the formulation. This implies that both quantum and classical dynamics are governed by the same equations, with the Heisenberg operators substituting the classical observables."}
{"id": "2601.10418", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10418", "abs": "https://arxiv.org/abs/2601.10418", "authors": ["Nadav Merlis"], "title": "Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching", "comment": null, "summary": "We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead in chunks of predefined sizes ('fixed batching policies'), and model predictive control. We first illustrate the problems with these two approaches and propose utilizing the lookahead in adaptive (state-dependent) batches; we refer to such policies as adaptive batching policies (ABPs). We derive the optimal Bellman equations for these strategies and design an optimistic regret-minimizing algorithm that enables learning the optimal ABP when interacting with unknown environments. Our regret bounds are order-optimal up to a potential factor of the lookahead horizon $\\ell$, which can usually be considered a small constant."}
{"id": "2601.10429", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10429", "abs": "https://arxiv.org/abs/2601.10429", "authors": ["Yang Li", "Fu-Lin Zhang"], "title": "Reduction of thermodynamic uncertainty by a virtual qubit", "comment": "23 pages (including 13 pages of appendices), 7 figures", "summary": "The thermodynamic uncertainty relation (TUR) imposes a fundamental constraint between current fluctuations and entropy production, providing a refined formulation of the second law for micro- and nanoscale systems. Quantum violations of the classical TUR reveal genuinely quantum thermodynamic effects, which are essential for improving performance and enabling optimization in quantum technologies. In this work, we analyze the TUR in a class of paradigmatic quantum thermal-machine models whose operation is enabled by coherent coupling between two energy levels forming a virtual qubit. Steady-state coherences are confined to this virtual-qubit subspace, while in the absence of coherent coupling the system satisfies detailed balance with the thermal reservoirs and supports no steady-state heat currents. We show that the steady-state currents and entropy production can be fully reproduced by an effective classical Markov process, whereas current fluctuations acquire an additional purely quantum correction originating from coherence. As a result, the thermodynamic uncertainty naturally decomposes into a classical (diagonal) contribution and a coherent contribution. The latter becomes negative under resonant conditions and reaches its minimum at the coupling strength that maximizes steady-state coherence. We further identify the optimization conditions and the criteria for surpassing the classical TUR bound in the vicinity of the reversible limit."}
{"id": "2601.10471", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10471", "abs": "https://arxiv.org/abs/2601.10471", "authors": ["Zhancun Mu"], "title": "DeFlow: Decoupling Manifold Modeling and Value Maximization for Offline Policy Extraction", "comment": "13 pages, 3 figures", "summary": "We present DeFlow, a decoupled offline RL framework that leverages flow matching to faithfully capture complex behavior manifolds. Optimizing generative policies is computationally prohibitive, typically necessitating backpropagation through ODE solvers. We address this by learning a lightweight refinement module within an explicit, data-derived trust region of the flow manifold, rather than sacrificing the iterative generation capability via single-step distillation. This way, we bypass solver differentiation and eliminate the need for balancing loss terms, ensuring stable improvement while fully preserving the flow's iterative expressivity. Empirically, DeFlow achieves superior performance on the challenging OGBench benchmark and demonstrates efficient offline-to-online adaptation."}
{"id": "2601.10435", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10435", "abs": "https://arxiv.org/abs/2601.10435", "authors": ["Benoît Vermersch", "Oscar Gravier", "Nathan Miscopein", "Julia Guignon", "Carlos Ramos Marimón", "Jonathan Durandau", "Matthieu Dartiailh", "Tristan Meunier", "Valentin Savin"], "title": "The SpinPulse library for transpilation and noise-accurate simulation of spin qubit quantum computers", "comment": "Code available at https://quobly-sw.github.io/SpinPulse/", "summary": "We introduce SpinPulse, an open-source python package for simulating spin qubit-based quantum computers at the pulse-level. SpinPulse models the specific physics of spin qubits, particularly through the inclusion of classical non-Markovian noise. This enables realistic simulations of native gates and quantum circuits, in order to support hardware development. In SpinPulse, a quantum circuit is first transpiled into the native gate set of our model and then converted to a pulse sequence. This pulse sequence is subsequently integrated numerically in the presence of a simulated noisy experimental environment. We showcase workflows including transpilation, pulse-level compilation, hardware benchmarking, quantum error mitigation, and large-scale simulations via integration with the tensor-network library quimb. We expect SpinPulse to be a valuable open-source tool for the quantum computing community, fostering efforts to devise high-fidelity quantum circuits and improved strategies for quantum error mitigation and correction."}
{"id": "2601.10491", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10491", "abs": "https://arxiv.org/abs/2601.10491", "authors": ["Shenlong Zheng", "Zhen Zhang", "Yuhui Deng", "Geyong Min", "Lin Cui"], "title": "Communication-Efficient Federated Learning by Exploiting Spatio-Temporal Correlations of Gradients", "comment": null, "summary": "Communication overhead is a critical challenge in federated learning, particularly in bandwidth-constrained networks. Although many methods have been proposed to reduce communication overhead, most focus solely on compressing individual gradients, overlooking the temporal correlations among them. Prior studies have shown that gradients exhibit spatial correlations, typically reflected in low-rank structures. Through empirical analysis, we further observe a strong temporal correlation between client gradients across adjacent rounds. Based on these observations, we propose GradESTC, a compression technique that exploits both spatial and temporal gradient correlations. GradESTC exploits spatial correlations to decompose each full gradient into a compact set of basis vectors and corresponding combination coefficients. By exploiting temporal correlations, only a small portion of the basis vectors need to be dynamically updated in each round. GradESTC significantly reduces communication overhead by transmitting lightweight combination coefficients and a limited number of updated basis vectors instead of the full gradients. Extensive experiments show that, upon reaching a target accuracy level near convergence, GradESTC reduces uplink communication by an average of 39.79% compared to the strongest baseline, while maintaining comparable convergence speed and final accuracy to uncompressed FedAvg. By effectively leveraging spatio-temporal gradient structures, GradESTC offers a practical and scalable solution for communication-efficient federated learning."}
{"id": "2601.10446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10446", "abs": "https://arxiv.org/abs/2601.10446", "authors": ["Adonai Hilário da Silva", "Octávio da Motta", "Leonardo Kleber Castelano", "Reginaldo de Jesus Napolitano"], "title": "Minimal-Energy Optimal Control of Tunable Two-Qubit Gates in Superconducting Platforms Using Continuous Dynamical Decoupling", "comment": "17 pages, 4 figures, 1 table", "summary": "We present a unified scheme for generating high-fidelity entangling gates in superconducting platforms by continuous dynamical decoupling (CDD) combined with variational minimal-energy optimal control. During the CDD stage, we suppress residual couplings, calibration drifting, and quasistatic noise, resulting in a stable effective Hamiltonian that preserves the designed ZZ interaction intended for producing tunable couplers. In this stable $\\mathrm{SU}(4)$ manifold, we calculate smooth low-energy single-quibt control functions using a variational geodesic optimization process that directly minimizes gate infidelity. We illustrate the methodology by applying it to CZ, CX, and generic engangling gates, achieving virtually unit fidelity and robustness under restricted single-qubit action, with experimentally realistic control fields. These results establish CDD-enhanced variational geometric optimal control as a practical and noise-resilient scheme for designing superconducting entangling gates."}
{"id": "2601.10498", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10498", "abs": "https://arxiv.org/abs/2601.10498", "authors": ["Nilin Abrahamsen"], "title": "Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning", "comment": null, "summary": "This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping."}
{"id": "2601.10451", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2601.10451", "abs": "https://arxiv.org/abs/2601.10451", "authors": ["David Guéry-Odelin", "François Impens"], "title": "Localization Landscape in Non-Hermitian and Floquet quantum systems", "comment": null, "summary": "We propose a generalization of the Filoche--Mayboroda localization landscape that extends the theory well beyond the static, elliptic and Hermitian settings while preserving its geometric interpretability. Using the positive operator $H^\\dagger H$, we obtain a landscape that predicts localization across non-Hermitian, Floquet, and topological systems without computing eigenstates. Singular-value collapse reveals spectral instabilities and skin effects, the Sambe formulation captures coherent destruction of tunneling, and topological zero modes emerge directly from the landscape. Applications to Hatano--Nelson chains, driven two-level systems, and driven Aubry--André--Harper models confirm quantitative accuracy, establishing a unified predictor for localization in equilibrium and driven quantum matter."}
{"id": "2601.10519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10519", "abs": "https://arxiv.org/abs/2601.10519", "authors": ["Andrea Melis", "Andrea Piroddi", "Roberto Girau"], "title": "Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models", "comment": null, "summary": "Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems."}
{"id": "2601.10461", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10461", "abs": "https://arxiv.org/abs/2601.10461", "authors": ["Adam Siegel", "Simon Benjamin"], "title": "Erasure conversion for singlet-triplet spin qubits enables high-performance shuttling-based quantum error correction", "comment": null, "summary": "Fast and high fidelity shuttling of spin qubits has been demonstrated in semiconductor quantum dot devices. Several architectures based on shuttling have been proposed; it has been suggested that singlet-triplet (dual-spin) qubits could be optimal for the highest shuttling fidelities. Here we present a fault-tolerant framework for quantum error correction based on such dual-spin qubits, establishing them as a natural realisation of erasure qubits within semiconductor architectures. We introduce a hardware-efficient leakage-detection protocol that automatically projects leaked qubits back onto the computational subspace, without the need for measurement feedback or increased classical control overheads. When combined with the XZZX surface code and leakage-aware decoding, we demonstrate a twofold increase in the error correction threshold and achieve orders-of-magnitude reductions in logical error rates. This establishes the singlet-triplet encoding as a practical route toward high-fidelity shuttling and erasure-based, fault-tolerant quantum computation in semiconductor devices."}
{"id": "2601.10541", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10541", "abs": "https://arxiv.org/abs/2601.10541", "authors": ["Niffa Cheick Oumar Diaby", "Thierry Duchesne", "Mario Marchand"], "title": "Mixtures of Transparent Local Models", "comment": "44 pages, 32 figues", "summary": "The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models."}
{"id": "2601.10465", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.10465", "abs": "https://arxiv.org/abs/2601.10465", "authors": ["Johannes N. Kriel", "Emma C. King", "Michael Kastner"], "title": "Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature", "comment": "21 pages, 5+1 figures", "summary": "We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by the critical exponents $ν$ and $z$) of an equilibrium quantum phase transition at zero temperature. Key to this is the identification of ramps in which both coherent and incoherent parts of the open-system dynamics affect the excitation density in a non-negligible way. We also identify the specific ramps for which subleading corrections to the asymptotic scaling laws are suppressed, which serves as a guide to dynamically probing quantum critical exponents in experimentally realistic finite-temperature situations."}
{"id": "2601.10562", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10562", "abs": "https://arxiv.org/abs/2601.10562", "authors": ["Reza M. Asiyabi", "SEOSAW Partnership", "Steven Hancock", "Casey Ryan"], "title": "Process-Guided Concept Bottleneck Model", "comment": "13 pages with 7 figures and 1 table, Supplementary Materials 10 pages with 3 figures", "summary": "Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications."}
{"id": "2601.10473", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10473", "abs": "https://arxiv.org/abs/2601.10473", "authors": ["Daniel Koch", "Brian Pardo", "Kip Nieman"], "title": "Analysis and Experimental Demonstration of Amplitude Amplification for Combinatorial Optimization", "comment": null, "summary": "Quantum Amplitude Amplification (QAA), the generalization of Grover's algorithm, is capable of yielding optimal solutions to combinatorial optimization problems with high probabilities. In this work we extend the conventional 2-dimensional representation of Grover's (orthogonal collective states) to oracles which encode cost functions such as QUBO, and show that linear cost functions are a special case whereby an exact formula exists for determining optimal oracle parameter settings. Using simulations of problem sizes up to 40 qubits we demonstrate QAA's algorithmic performance across all possible solutions, with an emphasis on the closeness in Grover-like performance for solutions near the global optimum. We conclude with experimental demonstrations of generalized QAA on both IBMQ (superconducting) and IonQ (trapped ion) qubits, showing that the observed probabilities of each basis state match our equations as a function of varying the free parameters in the oracle and diffusion operators."}
{"id": "2601.10563", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10563", "abs": "https://arxiv.org/abs/2601.10563", "authors": ["Aradhya Gaonkar", "Nihal Jain", "Vignesh Chougule", "Nikhil Deshpande", "Sneha Varur", "Channabasappa Muttal"], "title": "Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling", "comment": "13 pages, 8 figures, 2 tables", "summary": "The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov's representation theorem, KANs utilize adaptive spline-based activation functions and grid-based structures, providing a transformative approach compared to traditional neural network frameworks. Utilizing a variety of datasets spanning mathematical function estimation (quadratic and cubic) to practical uses like predicting daily temperatures and categorizing wines, the proposed research thoroughly assesses model performance via accuracy measures like Mean Squared Error (MSE) and computational expense assessed through Floating Point Operations (FLOPs). The results indicate that KANs reliably exceed MLPs in every benchmark, attaining higher predictive accuracy with significantly reduced computational costs. Such an outcome highlights their ability to maintain a balance between computational efficiency and accuracy, rendering them especially beneficial in resource-limited and real-time operational environments. By elucidating the architectural and functional distinctions between KANs and MLPs, the paper provides a systematic framework for selecting the most suitable neural architectures for specific tasks. Furthermore, the proposed study highlights the transformative capabilities of KANs in progressing intelligent systems, influencing their use in situations that require both interpretability and computational efficiency."}
{"id": "2601.10479", "categories": ["quant-ph", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10479", "abs": "https://arxiv.org/abs/2601.10479", "authors": ["Eyad I. B Hamid"], "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance", "comment": "7 pages, 5 figuers, Appendix", "summary": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial θ] \\in Ω(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$."}
{"id": "2601.10583", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10583", "abs": "https://arxiv.org/abs/2601.10583", "authors": ["Maximilian Schiffer", "Heiko Hoppe", "Yue Su", "Louis Bouvier", "Axel Parmentier"], "title": "Combinatorial Optimization Augmented Machine Learning", "comment": null, "summary": "Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operations research, and stochastic optimization. This paper provides a comprehensive overview of the state of the art in COAML. We introduce a unifying framework for COAML pipelines, describe their methodological building blocks, and formalize their connection to empirical cost minimization. We then develop a taxonomy of problem settings based on the form of uncertainty and decision structure. Using this taxonomy, we review algorithmic approaches for static and dynamic problems, survey applications across domains such as scheduling, vehicle routing, stochastic programming, and reinforcement learning, and synthesize methodological contributions in terms of empirical cost minimization, imitation learning, and reinforcement learning. Finally, we identify key research frontiers. This survey aims to serve both as a tutorial introduction to the field and as a roadmap for future research at the interface of combinatorial optimization and machine learning."}
{"id": "2601.10492", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10492", "abs": "https://arxiv.org/abs/2601.10492", "authors": ["Liang Chen", "Wen-Yi Zhu", "Zi-Jie Chen", "Zhu-Bo Wang", "Ya-Dong Hu", "Qing-Xuan Jie", "Guang-Can Guo", "Chang-Ling Zou"], "title": "Optimized readout strategies for neutral atom quantum processors", "comment": null, "summary": "Neutral atom quantum processors have emerged as a promising platform for scalable quantum information processing, offering high-fidelity operations and exceptional qubit scalability. A key challenge in realizing practical applications is efficiently extracting readout outcomes while maintaining high system throughput, i.e., the rate of quantum task executions. In this work, we develop a theoretical framework to quantify the trade-off between readout fidelity and atomic retention. Moreover, we introduce a metric of quantum circuit iteration rate (qCIR) and employ normalized quantum Fisher information to characterize system overall performance. Further, by carefully balancing fidelity and retention, we demonstrate a readout strategy for optimizing information acquisition efficiency. Considering the experimentally feasible parameters for 87Rb atoms, we demonstrate that qCIRs of 197.2Hz and 154.5Hz are achievable using single photon detectors and cameras, respectively. These results provide practical guidance for constructing scalable and high-throughput neutral atom quantum processors for applications in sensing, simulation, and near-term algorithm implementation."}
{"id": "2601.10591", "categories": ["cs.LG", "cs.AI", "q-fin.RM", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.10591", "abs": "https://arxiv.org/abs/2601.10591", "authors": ["Arundeep Chinta", "Lucas Vinh Tran", "Jay Katukuri"], "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition", "comment": "Accepted for oral presentation at the AI Meets Quantitative Finance Workshop at ICAIF 2025. An enhanced version was accepted for oral presentation at the AI for Time Series Analysis Workshop at AAAI 2026", "summary": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications."}
{"id": "2601.10558", "categories": ["quant-ph", "cs.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10558", "abs": "https://arxiv.org/abs/2601.10558", "authors": ["Yu-Hong Lai", "Hao-Chung Cheng"], "title": "A Mirror-Descent Algorithm for Computing the Petz-Rényi Capacity of Classical-Quantum Channels", "comment": "This paper is independent and concurrent to arXiv:2601.06492", "summary": "We study the computation of the $α$-Rényi capacity of a classical-quantum (c-q) channel for $α\\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded."}
{"id": "2601.10639", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10639", "abs": "https://arxiv.org/abs/2601.10639", "authors": ["Ranajoy Sadhukhan", "Sheng Cao", "Harry Dong", "Changsheng Zhao", "Attiano Purpura-Pontoniere", "Yuandong Tian", "Zechun Liu", "Beidi Chen"], "title": "STEM: Scaling Transformers with Embedding Modules", "comment": null, "summary": "Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from both per-token FLOPs and cross-device communication. Empirically, STEM trains stably despite extreme sparsity. It improves downstream performance over dense baselines while reducing per-token FLOPs and parameter accesses (eliminating roughly one-third of FFN parameters). STEM learns embedding spaces with large angular spread which enhances its knowledge storage capacity. More interestingly, this enhanced knowledge capacity comes with better interpretability. The token-indexed nature of STEM embeddings allows simple ways to perform knowledge editing and knowledge injection in an interpretable manner without any intervention in the input text or additional computation. In addition, STEM strengthens long-context performance: as sequence length grows, more distinct parameters are activated, yielding practical test-time capacity scaling. Across 350M and 1B model scales, STEM delivers up to ~3--4% accuracy improvements overall, with notable gains on knowledge and reasoning-heavy benchmarks (ARC-Challenge, OpenBookQA, GSM8K, MMLU). Overall, STEM is an effective way of scaling parametric memory while providing better interpretability, better training stability and improved efficiency."}
{"id": "2601.10559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10559", "abs": "https://arxiv.org/abs/2601.10559", "authors": ["Mo Xiong", "Jize Han", "Chuanzhen Cao", "Jinbin Li", "Qi Liu", "Zhiguo Huang", "Ming Xue"], "title": "Deterministic and scalable generation of large Fock states", "comment": "(6+2) pages, comments are welcome", "summary": "The scalable and deterministic preparation of large Fock-number states represents a long-standing frontier in quantum science, with direct implications for quantum metrology, communication, and simulation. Despite significant progress in small-scale implementations, extending such state generation to large excitation numbers while maintaining high fidelity remains a formidable challenge. Here, we present a scalable protocol for generating large Fock states with fidelities exceeding 0.9 up to photon numbers on the order of 100, achieved using only native control operations and, when desired, further enhanced by an optional post-selection step. Our method employs a hybrid Genetic-Adam optimization framework that combines the global search efficiency of genetic algorithms with the adaptive convergence of Adam to optimize multi-pulse control sequences comprising Jaynes-Cummings interactions and displacement operations, both of which are native to leading experimental platforms. The resulting control protocols achieve high fidelities with shallow circuit depths and strong robustness against parameter variations. These results establish an efficient and scalable pathway toward high-fidelity non-classical state generation for precision metrology and fault-tolerant quantum technologies."}
{"id": "2601.10673", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10673", "abs": "https://arxiv.org/abs/2601.10673", "authors": ["Aditya Agrawal", "Albert Magyar", "Hiteshwar Eswaraiah", "Patrick Sheridan", "Pradeep Janedula", "Ravi Krishnan Venkatesan", "Krishna Nair", "Ravi Iyer"], "title": "Single-Stage Huffman Encoder for ML Compression", "comment": "5 pages, 4 figures", "summary": "Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensitive scenarios such as die-to-die communication. This paper proposes a single-stage Huffman encoder that eliminates these overheads by using fixed codebooks derived from the average probability distribution of previous data batches. Through our analysis of the Gemma 2B model, we demonstrate that tensors exhibit high statistical similarity across layers and shards. Using this approach we achieve compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon compressibility, enabling efficient on-the-fly compression."}
{"id": "2601.10588", "categories": ["quant-ph", "cs.LG", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.10588", "abs": "https://arxiv.org/abs/2601.10588", "authors": ["I. K. Kominis", "C. Xie", "S. Li", "M. Skotiniotis", "G. P. Tsironis"], "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders", "comment": "6 pages, 2 figures", "summary": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation."}
{"id": "2601.10684", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10684", "abs": "https://arxiv.org/abs/2601.10684", "authors": ["Maissam Barkeshli", "Alberto Alfarano", "Andrey Gromov"], "title": "On the origin of neural scaling laws: from random graphs to natural language", "comment": "33 pages", "summary": "Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization."}
{"id": "2601.10594", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.10594", "abs": "https://arxiv.org/abs/2601.10594", "authors": ["Mariia Karabin", "Tanvir Sohail", "Dmytro Bykov", "Eduardo Antonio Coello Pérez", "Swarnava Ghosh", "Murali Gopalakrishnan Meena", "Seongmin Kim", "Amir Shehata", "In-Saeng Suh", "Hanna Terletska", "Markus Eisenbach"], "title": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "comment": null, "summary": "Quantum embedding methods, such as dynamical mean-field theory (DMFT), provide a powerful framework for investigating strongly correlated materials. A central computational bottleneck in DMFT is in solving the Anderson impurity model (AIM), whose exact solution is classically intractable for large bath sizes. In this work, we develop and benchmark a quantum-classical hybrid solver tailored for DMFT applications, using the variational quantum eigensolver (VQE) to prepare the ground state of the AIM with shallow quantum circuits. The solver uses a unified ansatz framework to prepare the particle and hole excitations of the ground-state from parameter-shifted circuits, enabling the reconstruction of the impurity Green's function through a continued-fraction expansion. We evaluate the performance of this approach across a few bath sizes and interaction strengths under noisy, shot-limited conditions. We compare three optimization routines (COBYLA, Adam, and L-BFGS-B) in terms of convergence and fidelity, assess the benefits of estimating a quantum-computed moment (QCM) correction to the variational energies, and benchmark the approach by comparing the reconstructed density of states (DOS) against that obtained using a classical pipeline. Our results demonstrate the feasibility of Green's function reconstruction on near-term devices and establish practical benchmarks for quantum impurity solvers embedded within self-consistent DMFT loops."}
{"id": "2601.10690", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10690", "abs": "https://arxiv.org/abs/2601.10690", "authors": ["Andrew F. Ilersich", "Kevin Course", "Prasanth B. Nair"], "title": "Data-driven stochastic reduced-order modeling of parametrized dynamical systems", "comment": null, "summary": "Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches."}
{"id": "2601.10650", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10650", "abs": "https://arxiv.org/abs/2601.10650", "authors": ["M. P. Tonne", "Kh. P. Gnatenko"], "title": "Quantifying the properties of evolutionary quantum states of the XXZ spin model using quantum computing", "comment": null, "summary": "The entanglement distance of evolutionary quantum states of a two-spin system with the XXZ model has been studied. The analysis has been conducted both analytically and using quantum computing. An analytical dependence of the entanglement distance on the values of the model coupling constants and the parameters of the initial states has been obtained. The speed of evolution of a two-spin system has been investigated. The analysis has been performed analytically and using quantum computing. An explicit dependence of the speed of evolution on the coupling constants and on the parameters of the initial state has been obtained. The results of quantum computations are in good agreement with the theoretical predictions."}
{"id": "2601.10701", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10701", "abs": "https://arxiv.org/abs/2601.10701", "authors": ["Chun Hei Michael Shiu", "Chih Wei Ling"], "title": "Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis", "comment": "19 pages, 5 figures. This work is submitted in part to the 2026 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2501.12046", "summary": "Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties."}
{"id": "2601.10655", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10655", "abs": "https://arxiv.org/abs/2601.10655", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Symmetry-based Perspectives on Hamiltonian Quantum Search Algorithms and Schrodinger's Dynamics between Orthogonal States", "comment": "21 pages, 3 figures, 2 tables", "summary": "It is known that the continuous-time variant of Grover's search algorithm is characterized by quantum search frameworks that are governed by stationary Hamiltonians, which result in search trajectories confined to the two-dimensional subspace of the complete Hilbert space formed by the source and target states. Specifically, the search approach is ineffective when the source and target states are orthogonal. In this paper, we employ normalization, orthogonality, and energy limitations to demonstrate that it is unfeasible to breach time-optimality between orthogonal states with constant Hamiltonians when the evolution is limited to the two-dimensional space spanned by the initial and final states. Deviations from time-optimality for unitary evolutions between orthogonal states can only occur with time-dependent Hamiltonian evolutions or, alternatively, with constant Hamiltonian evolutions in higher-dimensional subspaces of the entire Hilbert space. Ultimately, we employ our quantitative analysis to provide meaningful insights regarding the relationship between time-optimal evolutions and analog quantum search methods. We determine that the challenge of transitioning between orthogonal states with a constant Hamiltonian in a sub-optimal time is closely linked to the shortcomings of analog quantum search when the source and target states are orthogonal and not interconnected by the search Hamiltonian. In both scenarios, the fundamental cause of the failure lies in the existence of an inherent symmetry within the system."}
{"id": "2601.10705", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10705", "abs": "https://arxiv.org/abs/2601.10705", "authors": ["Keval Jain", "Anant Raj", "Saurav Prakash", "Girish Varma"], "title": "Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication", "comment": null, "summary": "We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition."}
{"id": "2601.10659", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.10659", "abs": "https://arxiv.org/abs/2601.10659", "authors": ["Georgios Theologou", "Mikkel F. Andersen", "Sandro Wimberger"], "title": "Counterdiabatic driving for random-gap Landau-Zener transitions", "comment": "Keywords: Shortcuts to adiabaticity; Landau-Zener problem; quantum control; random-gap distribution; adiabatic quantum computing", "summary": "The Landau--Zener (LZ) model describes a two-level quantum system that undergoes an avoided crossing. In the adiabatic limit, the transition probability vanishes. An auxiliary control field $H_\\text{CD}$ can be reverse-engineered so that the full Hamiltonian $H_0 + H_\\text{CD}$ reproduces adiabaticity for all parameter values. Our aim is to construct a single control field $H_1$ that drives an ensemble of LZ-type Hamiltonians with a distribution of energy gaps. $H_1$ works best statistically, minimizing the average transition probability. We restrict our attention to a special class of $H_1$ controls, motivated by $H_\\text{CD}$. We found a systematic trade-off between instantaneous adiabaticity and the final transition probability. Certain limiting cases with a linear sweep can be treated analytically; one of them being the LZ system with Dirac $δ(t)$ function. Comprehensive and systematic numerical simulations support and extend the analytic results."}
{"id": "2601.10708", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10708", "abs": "https://arxiv.org/abs/2601.10708", "authors": ["Khashayar Gatmiry", "Sitan Chen", "Adil Salim"], "title": "High-accuracy and dimension-free sampling with diffusions", "comment": null, "summary": "Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \\emph{high-quality} samples.\n  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \\emph{polylogarithmically} in $1/\\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \\emph{effective radius} of the support of the target distribution only."}
{"id": "2601.10662", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10662", "abs": "https://arxiv.org/abs/2601.10662", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Geometric Aspects of Entanglement Generating Hamiltonian Evolutions", "comment": "24 pages, 2 figures, 3 tables", "summary": "We examine the pertinent geometric characteristics of entanglement that arise from stationary Hamiltonian evolutions transitioning from separable to maximally entangled two-qubit quantum states. From a geometric perspective, each evolution is characterized by means of geodesic efficiency, speed efficiency, and curvature coefficient. Conversely, from the standpoint of entanglement, these evolutions are quantified using various metrics, such as concurrence, entanglement power, and entangling capability. Overall, our findings indicate that time-optimal evolution trajectories are marked by high geodesic efficiency, with no energy resource wastage, no curvature (i.e., zero bending), and an average path entanglement that is less than that observed in time-suboptimal evolutions. Additionally, when analyzing separable-to-maximally entangled evolutions between nonorthogonal states, time-optimal evolutions demonstrate a greater short-time degree of nonlocality compared to time-suboptimal evolutions between the same initial and final states. Interestingly, the reverse is generally true for separable-to-maximally entangled evolutions involving orthogonal states. Our investigation suggests that this phenomenon arises because suboptimal trajectories between orthogonal states are characterized by longer path lengths with smaller curvature, which are traversed with a higher energy resource wastage compared to suboptimal trajectories between nonorthogonal states. Consequently, a higher initial degree of nonlocality in the unitary time propagators appears to be essential for achieving the maximally entangled state from a separable state. Furthermore, when assessing optimal and suboptimal evolutions..."}
{"id": "2601.10715", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10715", "abs": "https://arxiv.org/abs/2601.10715", "authors": ["Navami Kairanda", "Shanthika Naik", "Marc Habermann", "Avinash Sharma", "Christian Theobalt", "Vladislav Golyanik"], "title": "DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids", "comment": "25 pages; 16 figures; project page: https://4dqv.mpi-inf.mpg.de/DInf-Grid/", "summary": "We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness."}
{"id": "2601.10672", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10672", "abs": "https://arxiv.org/abs/2601.10672", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Efficiency, Curvature, and Complexity of Quantum Evolutions for Qubits in Nonstationary Magnetic Fields", "comment": "27 pages, 4 figures, 1 table", "summary": "In optimal quantum-mechanical evolutions, motion can take place along paths of minimal length within an optimal time frame. Alternatively, optimal evolutions may occur along established paths without any waste of energy resources and achieving 100% speed efficiency. Unfortunately, realistic physical scenarios often lead to less-than-ideal evolutions that demonstrate suboptimal efficiency, nonzero curvature, and a high level of complexity. In this paper, we provide an exact analytical expression for the curvature of a quantum evolution pertaining to a two-level quantum system subjected to various time-dependent magnetic fields. Specifically, we examine the dynamics produced by a two-parameter nonstationary Hermitian Hamiltonian with unit speed efficiency. To enhance our understanding of the physical implications of the curvature coefficient, we analyze the curvature behavior in relation to geodesic efficiency, speed efficiency, and the complexity of the quantum evolution (as described by the ratio of the difference between accessible and accessed Bloch-sphere volumes for the evolution from initial to final state to the accessible volume for the given quantum evolution). Our findings indicate that, generally, efficient quantum evolutions exhibit lower complexity compared to inefficient ones. However, we also note that complexity transcends mere length. In fact, longer paths that are sufficiently curved can demonstrate a complexity that is less than that of shorter paths with a lower curvature coefficient."}
{"id": "2601.10479", "categories": ["quant-ph", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10479", "abs": "https://arxiv.org/abs/2601.10479", "authors": ["Eyad I. B Hamid"], "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance", "comment": "7 pages, 5 figuers, Appendix", "summary": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial θ] \\in Ω(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$."}
{"id": "2601.10683", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10683", "abs": "https://arxiv.org/abs/2601.10683", "authors": ["Kean Chen", "Zhicheng Zhang", "Nengkun Yu"], "title": "Optimal lower bound for quantum channel tomography in away-from-boundary regime", "comment": "23 pages", "summary": "Consider quantum channels with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. Any such channel must satisfy the constraint $rd_2\\geq d_1$, and the parameter regime $rd_2=d_1$ is called the boundary regime. In this paper, we show an optimal query lower bound $Ω(rd_1d_2/\\varepsilon^2)$ for quantum channel tomography to within diamond norm error $\\varepsilon$ in the away-from-boundary regime $rd_2\\geq 2d_1$, matching the existing upper bound $O(rd_1d_2/\\varepsilon^2)$. In particular, this lower bound fully settles the query complexity for the commonly studied case of equal input and output dimensions $d_1=d_2=d$ with $r\\geq 2$, in sharp contrast to the unitary case $r=1$ where Heisenberg scaling $Θ(d^2/\\varepsilon)$ is achievable."}
{"id": "2601.10588", "categories": ["quant-ph", "cs.LG", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.10588", "abs": "https://arxiv.org/abs/2601.10588", "authors": ["I. K. Kominis", "C. Xie", "S. Li", "M. Skotiniotis", "G. P. Tsironis"], "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders", "comment": "6 pages, 2 figures", "summary": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation."}
{"id": "2601.10689", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10689", "abs": "https://arxiv.org/abs/2601.10689", "authors": ["Daniel Allepuz-Requena", "Zohran Ali", "Dennis Høj", "Yingxuan Chen", "Luiz Couto Correa Pinto Filho", "Alexander Huck", "Ulrik L. Andersen"], "title": "Mitigating nonlinear transduction noise in high-cooperativity cavity optomechanics", "comment": null, "summary": "Coupling mechanical motion to an optical resonator enables displacement measurements approaching the standard quantum limit (SQL). However, increasing the optomechanical coupling strength will inevitably lead to probing of the nonlinear response of the optical resonator. Thermal intermodulation noise (TIN) arising from the nonlinear mixing of thermomechanical motion can further increase the imprecision well above the SQL and has hitherto been canceled up to second order of nonlinearity via operation at the \"magic detuning\". In this work, we record the output of a membrane-in-the-middle microcavity system operating at room temperature and achieving high cooperativity, $C>n_\\text{th}$, and apply a nonlinear transform that removes all orders of TIN, improving the mechanical signal-to-noise ratio by nearly 10 dB. Our results can be applied to experiments affected by third-order TIN, which we expect to be the dominating intrinsic source of noise in high-cooperativity room-temperature cavity optomechanical systems."}
{"id": "2601.10693", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2601.10693", "abs": "https://arxiv.org/abs/2601.10693", "authors": ["Francisca Vasconcelos", "Malvika Raj Joshi"], "title": "Constant-Depth Unitary Preparation of Dicke States", "comment": null, "summary": "Dicke states serve as a critical resource in quantum metrology, communication, and computation. However, unitary preparation of Dicke states is limited to logarithmic depth in standard circuit models and existing constant-depth protocols require measurement and feed-forward. In this work, we present the first unitary, constant-depth protocols for exact Dicke state preparation. We overcome the logarithmic-depth barrier by moving beyond the standard circuit model and leveraging global interactions (native to architectures such as neutral atoms and trapped ions). Specifically, utilizing unbounded CZ gates (i.e. within the QAC$^0$ circuit class), we offer circuits for exact computation of constant-weight Dicke states, using polynomial ancillae, and approximation of weight-1 Dicke states (i.e. $W$ states), using only constant ancillae. Granted additional access to the quantum FAN-OUT operation (i.e. upgrading to the QAC$_f^0$ circuit class), we also achieve exact preparation of arbitrary-weight Dicke states, with polynomial ancillae. These protocols distinguish the constant-depth capabilities of quantum architectures based on connectivity and offer a novel path toward resolving a long-standing quantum complexity conjecture."}
{"id": "2601.10698", "categories": ["quant-ph", "cond-mat.other", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10698", "abs": "https://arxiv.org/abs/2601.10698", "authors": ["Cesare Tronci"], "title": "Madelung hydrodynamics of spin-orbit coupling: action principles, currents, and correlations", "comment": "First version. Comments welcome", "summary": "We exploit the variational and Hamiltonian structures of quantum hydrodynamics with spin to unfold the correlation and torque mechanisms accompanying spin-orbit coupling (SOC) in electronic motion. Using Hamilton's action principle for the Pauli equation, we isolate SOC-induced quantum forces that act on the orbital Madelung--Bohm trajectories and complement the usual force terms known to appear in quantum hydrodynamics with spin. While the latter spin-hydrodynamic forces relate to the quantum geometric tensor (QGT), SOC-induced orbital forces originate from a particular current operator that contributes prominently to the spin current and whose contribution was overlooked in the past. The distinction between different force terms reveals two fundamentally different mechanisms generating quantum spin-orbit correlations. Leveraging the Hamiltonian structure of the hydrodynamic system, we also elucidate spin transport features such as the current shift in the spin Hall effect and the correlation-induced quantum torques. Finally, we illustrate the framework via the Madelung--Rashba equations for planar SOC configurations and propose a particle-based scheme for numerical implementation."}
{"id": "2601.10703", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.10703", "abs": "https://arxiv.org/abs/2601.10703", "authors": ["Samuel E. Begg", "Bishal K. Ghosh", "Chong Zu", "Chuanwei Zhang", "Michael Kolodrubetz"], "title": "Scalable Spin Squeezing in Power-Law Interacting XXZ Models with Disorder", "comment": "5 + 4 pages", "summary": "While spin squeezing has been traditionally considered in all-to-all interacting models, recent works have shown that spin squeezing can occur in systems with power-law interactions, leading to direct testing in Rydberg atoms, trapped ions, ultracold atoms and nitrogen vacancy (NV) centers in diamond. For the latter, Wu. et al. Nature 646 (2025) demonstrated that spin squeezing is heavily affected by positional disorder, reducing any capacity for a practical squeezing advantage, which requires scalability with the system size. In this Letter we explore the robustness of spin-squeezing in two-dimensional lattices with a fraction of unoccupied lattice sites. Using semi-classical modeling, we demonstrate the existence of scalable squeezing in power-law interacting XXZ models up to a disorder threshold, above which squeezing is not scalable. We produce a phase diagram for scalable squeezing, and explain its absence in the aforementioned NV experiment. Our work illustrates the maximum disorder allowed for realizing scalable spin squeezing in a host of quantum simulators, highlights a regime with substantial tolerance to disorder, and identifies controlled defect creation as a promising route for scalable squeezing in solid-state systems."}
{"id": "2601.10713", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10713", "abs": "https://arxiv.org/abs/2601.10713", "authors": ["Bruno Costa Alves Freire", "François-Marie Le Régent", "Anthony Leverrier"], "title": "Quantum Maxwell Erasure Decoder for qLDPC codes", "comment": "8 pages, 3 figures, submitted to the IEEE ISIT 2026", "summary": "We introduce a quantum Maxwell erasure decoder for CSS quantum low-density parity-check (qLDPC) codes that extends peeling with bounded guessing. Guesses are tracked symbolically and can be eliminated by restrictive checks, giving a tunable tradeoff between complexity and performance via a guessing budget: an unconstrained budget recovers Maximum-Likelihood (ML) performance, while a constant budget yields linear-time decoding and approximates ML. We provide theoretical guarantees on asymptotic performance and demonstrate strong performance on bivariate bicycle and quantum Tanner codes."}
{"id": "2601.09820", "categories": ["gr-qc", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09820", "abs": "https://arxiv.org/abs/2601.09820", "authors": ["Paul M. Alsing"], "title": "Quantum Optical Inspired Models for Unitary Black Hole Evaporation", "comment": "23 page and 21 figures", "summary": "In this work, we describe optically inspired models for unitary black hole (BH) evaporation. The goal of these models are (i) to be operationally simple, (ii) approximately preserve the thermal nature of the emitted Hawking Radiation (HR), and (iii) attempt to reproduce the Page Curve that purports that information flows forth from the BH when it has evaporated to approximately half its initial mass. We concentrate on modeling the BH as a single mode squeezed state successively interacting, by means of beam splitters and squeezers, with vacuum modes near the horizon, giving rise to entangled pairs representing the external Hawking radiation and its partner particle inside the horizon. Since all states and operations are Gaussian throughout, we use a symplectic formalism to track the evolution of the composite system through the evolving means and variances of their quadrature operators. This allows us to easily compute correlations and entanglement between the BH and the HR, as well as calculate correlations between the BH at early and late times."}
