<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 57]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.LG](#cs.LG) [Total: 60]
- [gr-qc](#gr-qc) [Total: 13]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Enhancing the Practical Reliability of Shor's Quantum Algorithm via Generalized Period Decomposition: Theory and Large-Scale Empirical Validation](https://arxiv.org/abs/2512.11004)
*Chih-Chen Liao,Chia-Hsin Liu,Yun-Cheng Tsai*

Main category: quant-ph

TL;DR: 提出一种广义周期分解方法，显著提升Shor量子因式分解算法的实际可靠性，通过利用任意周期除数放宽条件限制，在百万级测试中达到99.998%以上的成功率。


<details>
  <summary>Details</summary>
Motivation: Shor算法理论上可实现多项式时间整数分解，但实际性能严重依赖于量子相位估计获得的周期条件限制。传统方法对周期有严格要求，限制了算法的实际应用可靠性。

Method: 提出广义周期分解方法，通过系统性地利用获得的周期的任意除数来放宽条件限制。该方法与现有量子计算框架无缝集成，不改变算法的多项式时间复杂度，同时减少不必要的重复执行。

Result: 在超过100万个测试案例（2到8位整数）的经典模拟中，该方法达到接近完美的成功率：7位数超过99.998%，8位数超过99.999%，显著超越传统和改进的Shor算法变体。

Conclusion: 该方法在保持多项式时间复杂度的同时，显著提高了Shor算法的实际可靠性，特别适用于NISQ设备的量子密码分析，为量子算法研究和量子信息处理领域提供了理论和实践贡献。

Abstract: This work presents a generalized period decomposition approach, significantly improving the practical reliability of Shor's quantum factoring algorithm. Although Shor's algorithm theoretically enables polynomial-time integer factorization, its real-world performance heavily depends on stringent conditions related to the period obtained via quantum phase estimation. Our generalized decomposition method relaxes these conditions by systematically exploiting arbitrary divisors of the obtained period, effectively broadening the applicability of each quantum execution. Extensive classical simulations were performed to empirically validate our approach, involving over one million test cases across integers ranging from 2 to 8 digits. The proposed method achieved near-perfect success rates, exceeding 99.998% for 7-digit numbers and 99.999% for 8-digit numbers, significantly surpassing traditional and recently improved variants of Shor's algorithm. Crucially, this improvement is achieved without compromising the algorithm's polynomial-time complexity and integrates seamlessly with existing quantum computational frameworks. Moreover, our method enhances the efficiency of quantum resource usage by minimizing unnecessary repetitions, making it particularly relevant for quantum cryptanalysis with noisy intermediate-scale quantum (NISQ) devices. This study thus provides both theoretical advancements and substantial practical benefits, contributing meaningfully to the field of quantum algorithm research and the broader field of quantum information processing.

</details>


### [2] [Undecidability of the Unitary Hitting Time Problem: No Universal Time-Step Selector and an Operational No-Go for Finite-Time Decisions](https://arxiv.org/abs/2512.11006)
*Katsufumi Matsuura*

Main category: quant-ph

TL;DR: 量子动力学中的酉击中时间问题（UHTP）是不可判定的，不存在通用算法能计算所有输入下的击中时间，也没有有限资源协议能统一输出结果。


<details>
  <summary>Details</summary>
Motivation: 研究量子动力学中的酉击中时间问题，探索是否存在通用算法或协议能够计算量子系统从初始态演化到目标态所需的时间，这对于量子控制和量子计算具有重要意义。

Method: 通过将停机问题归约到UHTP来证明其不可判定性。使用可逆计算嵌入酉动力学、固定目标信标构造以及通过分段常数哈密顿量进行连续时间提升等技术。

Result: 证明了UHTP是不可判定的，不存在总算法能输出所有输入的击中时间。同时证明了不存在满足观测时间和耗散/功的均匀有限上界的通用有限资源协议。

Conclusion: 量子动力学中的击中时间问题本质上是不可判定的，这补充了谱隙和量子控制可达性等先前的不可判定性结果。区分了逻辑时间（方程内部）和物理/操作时间（准备、演化、测量），并证明在这两种意义上都不存在通用的时间步选择。

Abstract: We study the Unitary Hitting Time Problem (UHTP) in quantum dynamics. Given computably described pure states |a>, |b> and a time-dependent unitary U(t), define the hitting time as the infimum of t > 0 such that the fidelity between U(t)|a> and |b> reaches a fixed threshold (with infinity if the threshold is never reached). We prove that there is no total algorithm that outputs this hitting time for all inputs; equivalently, the total UHTP is undecidable via a reduction from the halting problem. Operationally, we show a no-go theorem: for any fixed accuracy parameters, there is no universal finite-resource protocol that, for all computably described inputs, correctly outputs the hitting time while obeying uniform finite upper bounds on observation time and on dissipation/work. The proofs use reversible computation embedded into unitary dynamics, a fixed-target beacon construction, and a continuous-time lifting via piecewise-constant Hamiltonians. Our results target systems capable of embedding universal computation and complement prior undecidability results such as spectral-gap and quantum-control reachability. We distinguish logical time (inside the equations) from physical/operational time (of preparation, evolution, measurement), and show that universal time-step selection is impossible in both senses.

</details>


### [3] [Generative Adversarial Variational Quantum Kolmogorov-Arnold Network](https://arxiv.org/abs/2512.11014)
*Hikaru Wakaura*

Main category: quant-ph

TL;DR: 提出了一种名为生成对抗变分量子KAN的新方法，将变分量子KAN作为生成器，相比传统神经网络和量子生成对抗网络，能以更少参数和更少数据实现更高精度。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov Arnold Networks（KAN）虽然比神经网络精度更高、参数更少，但学习速度较慢，因此尚未被充分研究作为生成器使用。作者希望利用KAN的优势，同时解决其学习速度问题。

Method: 提出生成对抗变分量子KAN，使用变分量子KAN作为生成器，结合量子电路的计算优势和输出分布，实现高效学习。

Result: 在MNIST和CIFAR10数据集上进行训练和生成任务，结果显示该方法比神经网络和量子生成对抗网络达到更高精度，且所需数据更少。

Conclusion: 生成对抗变分量子KAN是一种有效的方法，能够以更少参数和更少数据实现优于传统方法的性能，为KAN作为生成器的应用开辟了新途径。

Abstract: Kolmogorov Arnold Networks is a novel multilayer neuromorphic network that can exhibit higher accuracy than a neural network. It can learn and predict more accurately than neural networks with a smaller number of parameters, and many research groups worldwide have adopted it. As a result, many types of applications have been proposed. This network can be used as a generator solely or with a Generative Adversarial Network; however, KAN has a slower speed of learning than neural networks for the number of parameters. Hence,it has not been researched as a generator. Therefore, we propose a novel Generative Adversarial Network called Generative Adversarial Variational Quantum KAN that uses Variational Quantum KAN as a generator. This method enables efficient learning with significantly fewer parameters by leveraging the computational advantages of quantum circuits and their output distributions. We performed the training and generation task on MNIST and CIFAR10, and revealed that our method can achieve higher accuracy than neural networks and Quantum Generative Adversarial Network with less data.

</details>


### [4] [Choi echo: dynamical irreversibility and local decoherence in quantum many-body chaos](https://arxiv.org/abs/2512.11030)
*Jose Alfredo de Leon,Miguel Gonzalez,Carlos Diaz-Mejia*

Main category: quant-ph

TL;DR: 本文引入Choi回波作为量子通道纯度的一种操作解释，用于量化开放量子动力学中的内在不可逆性，并分析局部退相干能否探测多体系统中的量子混沌。


<details>
  <summary>Details</summary>
Motivation: 量化开放量子动力学中的内在不可逆性对于理解多体系统的退相干和信息损失至关重要。需要开发能够区分相干输运和真正混洗动力学的局部探针。

Method: 引入Choi回波框架，将Choi态的纯度解释为量子关联对局部信息擦除的鲁棒性度量。应用该框架分析子系统的约化动力学，并在典型自旋链模型中测试局部退相干能否探测量子混沌。

Result: Choi回波虽然能捕捉关键动力学特征，但在某些参数区域存在内在限制，无法在谱关联层面分辨可积到混沌的转变。局部退相干可能在可积区域虚假地指示量子混沌，因为它无法区分高效相干输运和真正混洗动力学。

Conclusion: 局部退相干信号由探针与环境在动力学过程中产生的纠缠控制，而非由谱关联控制。这澄清了局部动力学诊断的实际适用范围，强调了严格局部探针在区分不同动力学机制方面的局限性。

Abstract: Quantifying intrinsic irreversibility in open quantum dynamics is central to understanding decoherence and information loss in many-body systems. In this work, we introduce the Choi echo, which provides an operational interpretation of the purity of the Choi state, the state representation of a quantum channel, as a quantifier of the robustness of quantum correlations against local information erasure. We employ this framework to analyze the reduced dynamics of a subsystem and to test whether local decoherence probes quantum chaos in many-body systems. Across paradigmatic spin chain models, we show that while the Choi echo captures key dynamical features, it also exhibits intrinsic limitations that, in certain regions of parameter space, restrict its ability to resolve the integrable-to-chaos transition at the level of spectral correlations. In particular, we demonstrate that local decoherence can spuriously signal quantum chaos in integrable regimes, tracing them to the inability of a strictly local probe to distinguish efficient coherent transport from genuinely scrambling dynamics. Our results show that local decoherence signals are controlled by the entanglement generated between the probe and its environment during the dynamics, rather than by spectral correlations, clarifying the practical scope of local dynamical diagnostics.

</details>


### [5] [Information-Theoretic and Operational Measures of Quantum Contextuality](https://arxiv.org/abs/2512.11049)
*Ali Can Günhan,Mehmet Zafer Gedik*

Main category: quant-ph

TL;DR: 提出一个信息论框架量化Kochen-Specker语境性，引入两种互补度量：基于互信息能量的状态独立量，以及基于对易子期望值的操作度量。建立与Robertson不确定关系的层次界限，应用于KCBS场景，通过Majorana-stellar表示进行几何分析。


<details>
  <summary>Details</summary>
Motivation: 需要量化Kochen-Specker语境性，传统方法缺乏系统框架。希望建立信息论基础，将语境性与不确定关系联系起来，提供几何直观理解。

Method: 1. 引入互信息能量（状态独立）捕捉上下文内联合本征空间的几何重叠；2. 基于对易子期望值的操作度量反映测量结果层面的语境行为；3. 建立与Robertson不确定关系的层次界限；4. 应用于KCBS场景（自旋-1系统）；5. 使用Majorana-stellar表示进行几何分析。

Result: 1. 获得KCBS场景的闭式表达式；2. Majorana-stellar表示提供三维欧几里得可视化；3. 平面上的状态在垂直方向表现出最大不确定性；4. 所有KCBS上下文同时优化选出对称轴上的唯一状态；5. 达到最优不确定性和的状态具有零操作语境性，而具有显著操作语境性的状态满足非平凡Robertson界限。

Conclusion: 建立了量化Kochen-Specker语境性的信息论框架，揭示了语境性与不确定关系之间的深刻联系。两种互补度量捕捉不同方面，几何表示提供直观理解。最优不确定性和与零操作语境性相关，而显著语境性状态满足更强的Robertson界限。

Abstract: We propose an information -- theoretic framework for quantifying Kochen-Specker contextuality. Two complementary measures are introduced: the mutual information energy, a state-independent quantity inspired by Onicescu's information energy that captures the geometric overlap between joint eigenspaces within a context; and an operational measure based on commutator expectation values that reflects contextual behavior at the level of measurement outcomes. We establish a hierarchy of bounds connecting these measures to the Robertson uncertainty relation, including spectral, purity-corrected, and operator norm estimates. The framework is applied to the Klyachko-Can-Binicioğlu-Shumovsky (KCBS) scenario for spin-1 systems, where all quantities admit closed-form expressions. The Majorana-stellar representation furnishes a common geometric platform on which both the operational measure and the uncertainty products can be analyzed. For spin-1, this representation yields a three-dimensional Euclidean-like visualization of the Hilbert space in which, states lying on a plane exhibit maximum uncertainty for the observable along the perpendicular direction; simultaneous optimization across all KCBS contexts singles out a unique state on the symmetry axis. Notably, states achieving the optimal sum of uncertainty products exhibit vanishing operational contextuality, while states with substantial operational contextuality satisfy a nontrivial Robertson bound -- the two extremes are achieved by distinct quantum states.

</details>


### [6] [Crystalline Spectral Form Factors](https://arxiv.org/abs/2512.11054)
*Dmitrii A. Trunin,David A. Huse*

Main category: quant-ph

TL;DR: 研究具有极强本征值排斥的酉量子系统中谱形因子(SFF)的类晶体行为，推导了抑制SFF周期振荡的德拜-瓦勒因子，并估计其在海森堡时间倍数处的奇异性阶数。


<details>
  <summary>Details</summary>
Motivation: 探索介于标准随机矩阵系综和置换电路之间的中间能级统计量子系统，研究极强本征值排斥如何导致谱形因子呈现类晶体行为。

Method: 使用低温库仑气体作为排斥本征值模型，推导德拜-瓦勒因子；通过微扰置换电路和与Lax矩阵相关的随机矩阵系综复现类晶体行为。

Result: 成功推导出抑制SFF周期振荡的德拜-瓦勒因子，估计了其在海森堡时间倍数处的奇异性阶数，并在不同模型中复现了类晶体行为。

Conclusion: 为研究介于标准随机矩阵系综和置换电路之间的中间能级统计量子系统奠定了基础，揭示了极强本征值排斥导致的谱形因子类晶体行为。

Abstract: We investigate crystalline-like behavior of the spectral form factor (SFF) in unitary quantum systems with extremely strong eigenvalue repulsion. Using a low-temperature Coulomb gas as a model of repulsive eigenvalues, we derive the Debye-Waller factor suppressing periodic oscillations of the SFF and estimate the order of its singularities at multiples of the Heisenberg time. We also reproduce this crystalline-like behavior using perturbed permutation circuits and random matrix ensembles associated with Lax matrices. Our results lay a foundation for future studies of quantum systems that exhibit intermediate level statistics between standard random matrix ensembles and permutation circuits.

</details>


### [7] [Correlation and Entanglement partners in Gaussian systems](https://arxiv.org/abs/2512.11055)
*Ivan Agullo,Eduardo Martín-Martínez,Sergi Nadal-Gisbert,Patricia Ribes-Metidieri,Koji Yamaguchi*

Main category: quant-ph

TL;DR: 提出一个框架来识别高斯量子系统中特定自由度与其他部分的关联和纠缠分布，证明了纯态中每个关联模式都有唯一的单自由度伙伴，混合态中则分裂为关联伙伴和纠缠伙伴


<details>
  <summary>Details</summary>
Motivation: 研究复杂高斯多体系统中双分关联和纠缠的结构与分布，提供工具来理解这些量子关联在系统中的具体位置和组织方式

Method: 针对玻色多体高斯量子系统，通过系统的复结构构造伙伴子系统，对纯态和混合态分别提出不同的伙伴构造方法

Result: 1. 纯高斯态中每个关联模式都有唯一的单自由度伙伴，能完全捕获其关联（包括纠缠）
2. 混合高斯态中伙伴概念分裂为关联伙伴（包含所有经典和量子关联）和纠缠伙伴（总是至多单模）
3. 将伙伴构造扩展到多模子系统

Conclusion: 该框架为研究复杂高斯多体系统中双分关联和纠缠的结构与分布提供了概念性和实用性的工具

Abstract: We introduce a framework to identify where the total correlations and entanglement with a chosen degree of freedom reside within the rest of a system, in the context of bosonic many-body Gaussian quantum systems. Our results are organized into two main propositions. First, for pure Gaussian states, we show that every correlated mode possesses a unique single-degree-of-freedom partner that fully captures its correlations (consisting of entanglement), and we provide an explicit construction of this partner from the complex structure of the system's state. Second, for mixed Gaussian states, we constructively demonstrate that the notion of a partner subsystem splits into two: a correlation partner, which contains all classical and quantum correlations and need not correspond to a single degree of freedom, and an entanglement partner, which is always at most single-mode. Finally, we extend the construction of partners to multi-mode subsystems. Together, these results provide conceptual practical tools to study how bipartite correlations and entanglement are structured and where they can be found in complex Gaussian many-body systems.

</details>


### [8] [Deterministic Equations for Feedback Control of Open Quantum Systems III: Full counting statistics for jump-based feedback](https://arxiv.org/abs/2512.11078)
*Alberto J. B. Rosal,Guilherme Fiusa,Patrick P. Potts,Gabriel T. Landi*

Main category: quant-ph

TL;DR: 论文提出了一种基于量子跃迁检测的通用反馈协议框架，将检测到的跃迁通道存储在内存中用于反馈控制，并建立了混合经典-量子空间中的Lindblad主方程描述方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统中基于跃迁检测的反馈控制协议，旨在开发一个通用框架来描述这类反馈系统的动力学和统计特性，特别是如何将检测到的量子跃迁信息转化为有用的功。

Method: 提出基于量子跃迁检测的通用反馈协议，将最后检测到的跃迁通道存储在经典内存中，用于条件性地修改系统哈密顿量。建立了混合经典-量子空间中的Lindblad主方程表示，其中经典部分编码测量记录，量子部分表示被监测系统。

Result: 该框架能够完全表征基于跃迁反馈协议系统的计数统计特性，包括平均电流、噪声、相关函数和功率谱等关键统计性质。应用于耦合两个热浴的三能级系统热机时，证明跃迁反馈可以将检测到的跃迁信息转化为功。

Conclusion: 该工作提供了一个通用分析框架，能够表征基于跃迁反馈协议下任何计数可观测量（如电流、噪声、相关函数等）的关键统计特性，为量子反馈控制系统的分析和设计提供了有力工具。

Abstract: In this work, we consider a general feedback protocol based on quantum-jump detections, where the last detected jump channel is stored in a memory and subsequently used to implement a feedback action, such as modifying the system Hamiltonian conditioned on the last jump. We show that the time evolution of this general protocol can be described by a Lindblad master equation defined in a hybrid classical-quantum space, where the classical part encodes the stored measurement record (memory) and the quantum part represents the monitored system. Moreover, we show that this new representation can be used to fully characterize the counting statistics of a system subject to a general jump-based feedback protocol. We apply the formalism to a three-level system coupled to two thermal baths operating as a thermal machine, and we show that jump-based feedback can be used to convert the information obtained from the jump detections into work. Our framework provides analytical tools that enable the characterization of key statistical properties of any counting observable under jump-based feedback, such as the average current, noise, correlation functions, and power spectrum.

</details>


### [9] [Universal and non-universal facets of quantum critical phenomena unveiled along the Schmidt decomposition theorem](https://arxiv.org/abs/2512.11093)
*Samuel M. Soares,Lucas Squillante,Henrique S. Lima,Constantino Tsallis,Mariano de Souza*

Main category: quant-ph

TL;DR: 研究一维横场伊辛模型中自旋大小S对量子Grüneisen参数Γ^{0K}_q在临界点的影响，揭示了Γ^{0K}_q随S增大而增加但保持有限，并探讨了非可加q熵S_q的广延性、普适性类别及实验方案。


<details>
  <summary>Details</summary>
Motivation: 探索自旋大小S如何影响量子临界点处的Grüneisen参数Γ^{0K}_q，以及非可加q熵S_q在量子临界性中的行为，旨在揭示量子临界性的普适性和非普适性特征。

Method: 研究一维横场伊辛模型，分析不同自旋大小S下的量子Grüneisen参数Γ^{0K}_q，应用Schmidt分解定理分析q熵S_q的广延性，并基于对称性探讨普适性类别。

Result: 发现：1) Γ^{0K}_q随S增大而增加但保持有限；2) 仅特定q值下S_q才具有广延性；3) S_q框架下的普适性类别仅取决于系统对称性；4) 提出了探索有限尺寸效应与希尔伯特空间占据的实验方案。

Conclusion: 研究揭示了量子临界性在Γ^{0K}_q和S_q方面的普适性和非普适性特征，为理解量子临界现象提供了新视角，并提出了可行的实验验证方案。

Abstract: We investigate the influence of the spin magnitude $S$ on the quantum Grüneisen parameter $Γ^{0\text{K}}_q$ right at critical points (CPs) for the 1D Ising model under a transverse magnetic field. Our findings are fourfold: $\textit{i)}$ for higher $S$, $Γ^{0\text{K}}_q$ is increased, but remains finite, reflecting the enhancement of the Hilbert space dimensionality; $\textit{ii)}$ the Schmidt decomposition theorem recovers the extensivity of the nonadditive $q$-entropy $S_q$ only for a $\textit{special}$ value of the entropic index $q$; $\textit{iii)}$ the universality class in the frame of $S_q$ depends only on the symmetry of the system; $\textit{iv)}$ we propose an experimental setup to explore finite size effects in connection with the Hilbert space occupation at CPs. Our findings unveil both universal and non-universal aspects of quantum criticality in terms of $Γ^{0\text{K}}_q$ and $S_q$.

</details>


### [10] [Digital Coherent-State QRNG Using System-Jitter Entropy via Random Permutation](https://arxiv.org/abs/2512.11107)
*Randy Kuang*

Main category: quant-ph

TL;DR: 提出完全数字框架，通过系统时序抖动和随机置换过程，复制相干态量子随机数生成的统计行为，无需量子硬件。


<details>
  <summary>Details</summary>
Motivation: 传统相干态量子随机数生成需要量子光子硬件，成本高且复杂。本文旨在通过纯计算过程实现相同的统计特性，降低实现门槛。

Method: 利用硬件和操作系统的计算时序变化，通过随机置换过程生成泊松分布数字，模拟光学相干态的光子统计。基于Uniform Convergence Theorem提供理论保证。

Result: 实验验证显示优异性能：香农熵接近7.999998比特/字节，最小熵超过7.99比特/字节，在10^8字节规模上超越理论界限，无需后处理。

Conclusion: 相干态QRNG功能可通过纯经典计算过程完全实现，提供数学可证明的均匀性和实际密码安全性，无需量子光子硬件。

Abstract: We present a fully digital framework that replicates the statistical behavior of coherent-state quantum random number generation (QRNG) by harnessing system timing jitter through random permutation processes. Our approach transforms computational timing variations from hardware and operating system sources into permutation dynamics that generate Poisson-distributed numbers, accurately reproducing the photon statistics of optical coherent states. The theoretical foundation is established by the Uniform Convergence Theorem, which provides exponential convergence to uniformity under modular projection with rigorous error bounds. Extensive experimental validation across multiple parameter regimes and sample sizes up to $10^8$ bytes demonstrates exceptional performance: Shannon entropy approaching 7.999998 bits/byte and min-entropy exceeding 7.99 bits/byte, outperforming theoretical bounds at scale. The architecture inherently resists side-channel attacks through compound timing distributions and adaptive permutation behavior, while operating without classical cryptographic post-processing. Our results establish that coherent-state QRNG functionality can be entirely realized through classical computational processes, delivering mathematically provable uniformity and practical cryptographic security without quantum photonic hardware.

</details>


### [11] [Network-Irreducible Multiparty Entanglement in Quantum Matter](https://arxiv.org/abs/2512.11118)
*Liuke Lyu,Pedro Lauand,William Witczak-Krempa*

Main category: quant-ph

TL;DR: 该论文提出了一种超越传统真多体纠缠(GME)的新方法——真网络多体纠缠(GNME)，用于表征量子物质中真正的集体纠缠，并发现GNME在相变点附近出现尖锐峰值，而在某些量子自旋液体中微观子区域没有GNME但具有强GME。


<details>
  <summary>Details</summary>
Motivation: 传统通过真多体纠缠(GME)表征集体纠缠的方法在局域哈密顿量的基态和热Gibbs态中会导致面积律，只能捕捉与子区域界面相关的短程贡献，无法真正捕获集体纠缠的本质。

Method: 提出真网络多体纠缠(GNME)概念，通过分析k-体态是否可以通过由(k-1)-体资源组成的量子网络来制备，系统性地解决这一问题。开发了GNME的认证和量化工具，并在GHZ、W和Dicke态上进行基准测试。然后研究了1D横向场伊辛模型和2D量子自旋液体。

Result: 在1D横向场伊辛模型中，GNME在临界相变附近出现尖锐峰值，在其他区域快速抑制。有限温度下GNME比GME更快消失。某些2D量子自旋液体在微观子区域中没有GNME，但具有强GME。

Conclusion: GNME方法能够超越传统GME的面积律限制，真正表征量子物质中的集体纠缠，为平衡和非平衡态量子物质的集体纠缠研究提供了新工具。

Abstract: We show that the standard approach to characterize collective entanglement via genuine multiparty entanglement (GME) leads to an area law in ground and thermal Gibbs states of local Hamiltonians. To capture the truly collective part one needs to go beyond this short-range contribution tied to interfaces between subregions. Genuine network multiparty entanglement (GNME) achieves a systematic resolution of this goal by analyzing whether a $k$-party state can be prepared by a quantum network consisting of $(k-1)$-partite resources. We develop tools to certify and quantify GNME, and benchmark them for GHZ, W and Dicke states. We then study the 1d transverse field Ising model, where we find a sharp peak of GNME near the critical phase transition, and rapid suppression elsewhere. Finite temperature leads to a faster death of GNME compared to GME. Furthermore, certain 2d quantum spin liquids do not have GNME in microscopic subregions while possessing strong GME. This approach will allow to chart truly collective entanglement in quantum matter both in and out of equilibrium.

</details>


### [12] [Solutions of Koopman-von Neumann equations, their superpositions, orthogonality and uncertainties](https://arxiv.org/abs/2512.11148)
*Mustafa Amin,Mark A. Walton*

Main category: quant-ph

TL;DR: 该论文研究了Koopman-von Neumann（KvN）公式在希尔伯特空间中的扩展，通过规范自由度的分离变量方法，构建了正交归一的本征态集合，并发现了与温度相关的正则系综描述。


<details>
  <summary>Details</summary>
Motivation: KvN公式将经典力学引入希尔伯特空间，但许多量子力学中常用的技术（如求解本征值问题、获得厄米算符的正交归一本征态、理解态的相干叠加等）在经典框架下仍然缺失。研究者希望填补这一空白。

Method: 研究经典概率幅的一般KvN方程，利用其规范自由度实现变量分离。通过不同规范下的刘维尔本征态构建叠加态，并从中找到正交归一集合。分析可分离解与正则系综的关系。

Result: 成功构建了正交归一的本征态集合；发现某些可分离解描述了正则系综，其中分离常数与温度相关；经典不确定性关系在KvN形式中自然出现，特别是动力学时间与刘维尔算符之间的不确定性关系。

Conclusion: KvN公式的规范自由度为实现希尔伯特空间方法提供了关键途径，使得经典系统能够应用量子力学中的数学工具，包括本征值问题、正交归一性和不确定性关系等，为经典系统的统计描述提供了新视角。

Abstract: The Koopman-von Neumann (KvN) formulation brings classical mechanics to Hilbert space, but many techniques familiar from quantum mechanics remain missing. One would hope to solve eigenvalue problems, obtain orthonormal eigenstates of Hermitian operators and ascribe meaning to a coherent superposition of states, among other things. Here we consider the general KvN equation for a classical probability amplitude and show that its so-called gauge freedom allows the separation of variables. The amenability to Hilbert-space methods of the resulting KvN solutions is investigated. We construct superpositions from differently-gauged Liouvillian eigenstates, and find an orthonormal set among them. We find that some separable solutions describe the canonical ensemble with temperature related to the separation constant. Classical uncertainty relations arise naturally in the KvN formalism. We discuss one between the dynamical time and the Liouvillian in terms of the statistical description of classical systems.

</details>


### [13] [Investigating Different Barren Plateaus Mitigation Strategies in Variational Quantum Eigensolver](https://arxiv.org/abs/2512.11171)
*Mostafa Atallah,Nouhaila Innan,Muhammad Kashif,Muhammad Shafique*

Main category: quant-ph

TL;DR: 研究比较了四种缓解VQE算法中贫瘠高原问题的方法，发现梯度保持效果与迭代次数相关，不同方法在不同系统规模和计算预算下表现各异，梯度方差不能单独预测性能。


<details>
  <summary>Details</summary>
Motivation: VQE算法面临贫瘠高原问题，梯度随系统规模和电路深度消失。现有缓解策略与收敛性能在不同迭代预算下的关系不明确，缺乏系统分析确定哪种先进缓解技术在特定场景下表现最佳。

Method: 对四种方法（Local-Global、Adiabatic、State Efficient Ansatz (SEA)和Pretrained VQE）与标准VQE进行基准测试，在4到14量子比特的分子系统上分析梯度方差（最多50层）和收敛性（最多1000次迭代）。

Result: 梯度保持效果与迭代次数相关：在14量子比特BeH2系统中，Pretrained VQE在100次迭代时优于SEA，但SEA在1000次迭代时准确度提高2.2倍。对于较小系统，SEA实现接近精确能量（H2: 10^-5 Ha, LiH: 2x10^-4 Ha），保真度0.999，而标准方法早期就达到平台期。

Conclusion: 有效的贫瘠高原缓解策略需要根据系统规模和可用计算预算进行选择，而不是将梯度方差作为性能的唯一预测指标。不同方法在不同场景下表现最佳，需要针对具体应用场景进行策略选择。

Abstract: Variational Quantum Eigensolver (VQE) algorithms suffer from barren plateaus, where gradients vanish with system size and circuit depth. Although many mitigation strategies exist, their connection to convergence performance under different iteration budgets remains unclear. Moreover, a systematic analysis identifying which state-of-the-art mitigation techniques perform best under specific scenarios is also lacking. We benchmark four approaches, Local-Global, Adiabatic, State Efficient Ansatz (SEA), and Pretrained VQE, against standard VQE on molecular systems from 4 to 14 qubits, analyzing gradient variance up to 50 layers and convergence over 1000 iterations. Our results show that the impact of gradient preservation is iteration-dependent. In the 14-qubit BeH2 system, Pretrained VQE outperforms SEA at 100 iterations despite lower gradient variance, but SEA becomes 2.2x more accurate at 1000 iterations. For smaller systems, SEA achieves near-exact energies (H2: 10^-5 Ha, LiH: 2x10^-4 Ha) with fidelities 0.999, while standard methods plateau early. The results demonstrate that robust barren plateau mitigation depends on aligning the chosen strategy with both system size and available computational budget, rather than treating gradient variance as the sole predictor of performance.

</details>


### [14] [Negative Marginal Densities in Mixed Quantum-Classical Liouville Dynamics](https://arxiv.org/abs/2512.11174)
*Kai Gu,Jeremy Schofield*

Main category: quant-ph

TL;DR: 量子-经典混合刘维尔方程（QCLE）在描述耦合量子-经典系统动力学时，其相空间分布可能违反正定性，特别是在低能态情况下，这为评估混合量子-经典描述的有效性提供了新的度量指标。


<details>
  <summary>Details</summary>
Motivation: 虽然QCLE在描述量子-经典混合系统动力学方面表现出色，并能保持总粒子数、能量和纯度等量子特性，但由于其密度矩阵算符来自全量子密度矩阵的部分Wigner变换，其矩阵元素可能出现负值，这意味着对角矩阵元素表现为伪密度而非经典相空间密度。本研究旨在探讨QCLE生成的相空间分布与精确量子动力学结果的差异。

Method: 通过比较精确量子动力学与QCLE演化从纯量子初始态生成的相空间分布，分析共振效应在非对角矩阵元素中的差异。使用低维模型进行数值和解析研究，特别关注QCLE对边际相空间密度正定性的违反情况。通过模型系统的微扰分析确认这种违反的普遍性。

Result: 研究发现，QCLE的离对角矩阵元素共振效应与精确量子动力学存在定性差异，特别是在低能态情况下。数值和解析结果表明，QCLE可能违反边际相空间密度的正定性，这是任何物理系统都应始终满足的性质。微扰分析证实这种违反具有普遍性。同时发现，当系统初始能量相对于子系统态间能隙增加时，这种正定性违反会消失。

Conclusion: QCLE在描述量子-经典混合系统时可能违反相空间分布的正定性，特别是在低能区域。这种违反为评估混合量子-经典描述的有效性提供了重要指标，建议使用负性指数来量化与正定性的偏差，作为判断QCLE适用性的有用度量。

Abstract: The mixed quantum-classical Liouville equation (QCLE) provides an approximate perturbative framework for describing the dynamics of systems with coupled quantum and classical degrees of freedom of disparate thermal wavelengths. The evolution governed by the Liouville operator preserves many properties of full quantum dynamics, including the conservation of total population, energy, and purity, and has shown quantitative agreement with exact quantum results for the expectation values of many observables where direct comparisons are feasible. However, since the QCLE density matrix operator is obtained from the partial Wigner transform of the full quantum density matrix, its matrix elements can have negative values, implying that the diagonal matrix elements behave as pseudo-densities rather than densities of classical phase space. Here, we compare phase-space distributions generated by exact quantum dynamics with those produced by QCLE evolution from pure quantum initial states. We show that resonance effects in the off-diagonal matrix elements differ qualitatively, particularly for low-energy states. Furthermore, numerical and analytical results for low-dimensional models reveal that the QCLE can violate the positivity of marginal phase-space densities, a property that should hold at all times for any physical system. A perturbative analysis of a model system confirms that such violations arise generically. We also show that the violations of positivity of the marginal densities vanish as the initial energy of the system increases relative to the energy gap between subsystem states. These findings suggest that a negativity index, quantifying deviations from positivity, may provide a useful metric for assessing the validity of mixed quantum\textendash{}classical descriptions.

</details>


### [15] [Enhancing Long-distance Continuous-variable Quantum-key-distribution with an Error-correcting Relay](https://arxiv.org/abs/2512.11224)
*S. Nibedita Swain,Ryan J. Marshman,Josephine Dias,Alexander S. Solntsev,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 结合无噪声线性放大器和酉平均技术，同时补偿热损耗效应并抑制相位噪声，实现超越无中继器界限的长距离连续变量量子密钥分发。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发在长距离传输中面临热损耗效应和相位噪声的挑战，现有技术难以同时有效解决这两个问题，限制了其超越无中继器界限的能力。

Method: 将无噪声线性放大器（用于补偿热损耗）与酉平均技术（用于抑制相位噪声）相结合，形成一种混合协议来同时处理两种主要的噪声源。

Result: 该组合协议能够实现超越无中继器界限的长距离连续变量量子密钥分发，即使在非单位协调效率的现实条件下也能工作。

Conclusion: 通过结合无噪声线性放大器和酉平均技术，可以同时解决热损耗和相位噪声问题，为超越无中继器界限的长距离连续变量量子密钥分发提供了有效解决方案。

Abstract: Noiseless linear amplifiers (NLAs) serve as an effective means to enable long-distance continuous-variable (CV) quantum key distribution (QKD), even under realistic conditions with non-unit reconciliation efficiency. Separately, unitary averaging has been suggested to mitigate some stochastic noise, including phase noise in continuous-variable states. In this work, we combine these two protocols to simultaneously compensate for thermal-loss effects and suppress phase noise, thereby enabling long-distance CV QKD that surpasses the repeaterless bound, the fundamental rate-distance limit, for repeaterless quantum communication systems.

</details>


### [16] [On Shor's conjecture on the accessible information of quantum dichotomies](https://arxiv.org/abs/2512.11233)
*Khac Duc An Thai,Michele Dall'Arno*

Main category: quant-ph

TL;DR: 本文通过研究量子二分态的可达信息与猜测概率之间的权衡关系，反驳了先前关于可达信息在猜测概率中单调性的假设，并提出了量子测量的状态依赖极值性推广，从而推进了Shor猜想的解决。


<details>
  <summary>Details</summary>
Motivation: Shor在世纪之交提出了一个至今未解的猜想：任何量子二分态的可达信息（即从二进制量子编码中解码的最大经典信息量）都可以通过冯·诺依曼测量实现。25年后，量子主化和统计比较领域的新发展为解决这一长期开放问题提供了可能。

Method: 首先研究了二进制情况下可达信息与猜测概率之间的权衡关系，反驳了可达信息在猜测概率中单调性的假设。其次提出了量子测量的状态依赖极值性推广，并应用于量子比特二分态的可达信息分析。

Result: 1. 证明了可达信息在猜测概率中并非单调，这推翻了先前可能解决Shor问题的假设；2. 提出了量子测量的状态依赖极值性理论，并应用于量子比特二分态的可达信息分析，改进了先前的结果。

Conclusion: 通过分析可达信息与猜测概率的权衡关系，以及发展状态依赖极值性理论，本文为最终解决Shor关于量子二分态可达信息的长期开放问题提供了新的工具和见解。

Abstract: Around the turn of the century, Shor formulated his well-known and still-open conjecture stating that the accessible information of any quantum dichotomy, that is the maximum amount of classical information that can be decoded from a binary quantum encoding, is attained by a von Neumann measurement. A quarter of a century later, new developments on the Lorenz curves of quantum dichotomies in the field of quantum majorization and statistical comparison may provide the key to unlock such a longstanding open problem. Here, we first investigate the tradeoff relations between accessible information and guessing probability in the binary case, thus disproving the claimed monotonicity of the former quantity in the latter that, if true, would have settled Shor's problem in the qubit case. Our second result is to provide a state-dependent generalization of extremality for quantum measurements, to characterize state-dependent extremality for qubit dichotomies, and to apply such results to tighten previous results on the accessible information of qubit dichotomies.

</details>


### [17] [Creation of Depth-Confined, Shallow Nitrogen-Vacancy Centers in Diamond With Tunable Density](https://arxiv.org/abs/2512.11242)
*Lillian B. Hughes Wyatt,Shreyas Parthasarathy,Isaac Kantor,Casey K. Kim,Lingjie Chen,Taylor A. Morrison,Jeffrey Ahlers,Kunal Mukherjee,Ania C. Bleszynski Jayich*

Main category: quant-ph

TL;DR: 通过金刚石生长过程中的δ掺杂技术，实现了对近表面氮空位中心深度和密度的可调控制，相比低能离子注入深度限制提升两倍，并成功应用于二维磁体CrSBr的磁性成像。


<details>
  <summary>Details</summary>
Motivation: 工程化浅层氮空位中心是解锁纳米级量子传感新进展的关键。传统方法如低能离子注入在深度控制和NV密度方面存在限制，需要开发更精确的近表面NV制备技术。

Method: 在金刚石生长过程中采用δ掺杂技术创建近表面氮空位中心，实现对NV深度限制和密度的可调控制。该方法相比低能离子注入提供了更好的深度控制能力。

Result: δ掺杂技术使NV深度限制相比低能离子注入提升两倍，能够制备高灵敏度的单缺陷和系综，相干性受NV-NV相互作用限制。成功应用该技术成像了二维磁体CrSBr的磁性。

Conclusion: 近表面δ掺杂提供的控制能力将推动NV量子传感的新发展，从纳米级NMR到纠缠增强计量学等应用领域。

Abstract: Engineering shallow nitrogen-vacancy (NV) centers in diamond holds the key to unlocking new advances in nanoscale quantum sensing. We find that the creation of near-surface NVs through delta doping during diamond growth allows for tunable control over both NV depth confinement (with a twofold improvement relative to low-energy ion implantation) and NV density, ultimately resulting in highly-sensitive single defects and ensembles with coherence limited by NV-NV interactions. Additionally, we demonstrate the utility of our shallow delta-doped NVs by imaging magnetism in few-layer CrSBr, a two-dimensional magnet. We anticipate that the control afforded by near-surface delta doping will enable new developments in NV quantum sensing from nanoscale NMR to entanglement-enhanced metrology.

</details>


### [18] [A Survey of OAM-Encoded High-Dimensional Quantum Key Distribution: Foundations, Experiments, and Recent Trends](https://arxiv.org/abs/2512.11286)
*Huan Zhang,Zhenyu Cao,Yu Sun,Hu Jin*

Main category: quant-ph

TL;DR: 这篇综述论文系统梳理了基于轨道角动量(OAM)编码的高维量子密钥分发技术，总结了基本原理、实验进展和系统限制，重点关注混合编码、模式分选、自适应光学等实用化技术。


<details>
  <summary>Details</summary>
Motivation: 高维量子密钥分发(HD-QKD)通过在大希尔伯特空间中编码数据，可以提高信息效率和噪声容忍度。光的轨道角动量(OAM)为这种编码提供了可扩展的基础，并支持高维光子通信。然而，基于OAM的实际实现仍然受到状态生成、传输和检测方面的挑战限制。

Method: 这篇综述采用系统性的文献分析方法，整合了OAM编码HD-QKD领域的研究成果。论文概述了基本原理，总结了代表性实验，分析了系统级限制，并特别关注了混合编码、模式分选、自适应光学以及时间频率(TF)、连续变量(CV)、测量设备无关(MDI)和设备无关(DI)框架的最新进展。

Result: 论文提供了OAM编码HD-QKD的全面概述，突出了该技术在提高信息效率和噪声容忍度方面的潜力，同时识别了实际实现中的关键挑战。综述强调了混合编码策略和先进光学技术在克服当前限制方面的重要性。

Conclusion: 基于OAM的高维量子密钥分发是一个有前景的研究方向，但需要进一步解决状态生成、传输和检测方面的技术挑战。通过整合混合编码方案和先进的光学技术，可以推动该技术向实际应用发展。未来的研究应重点关注提高系统的实用性和可行性。

Abstract: High-dimensional quantum key distribution (HD-QKD) enhances information efficiency and noise tolerance by encoding data in large Hilbert spaces. The orbital angular momentum (OAM) of light provides a scalable basis for such encoding and supports high-dimensional photonic communication. Practical OAM-based implementations remain constrained by challenges in state generation, transmission, and detection. This survey offers a consolidated overview of OAM-encoded HD-QKD, outlining fundamental principles, representative experiments, and system-level limitations. Recent progress in hybrid encodings, mode sorting, adaptive optics, and TF, CV, MDI, and DI frameworks is summarized with emphasis on practical feasibility.

</details>


### [19] [Distributed Quantum Magnetic Sensing for Infrastructure-free Geo-localization](https://arxiv.org/abs/2512.11300)
*Thinh Le,Shiqian Guo,Jianqing Liu*

Main category: quant-ph

TL;DR: 量子磁传感用于地磁定位：理论推导NV中心CRLB证明量子优势，提出分布式协议饱和CRLB，基于地磁图匹配实现粗到精马氏距离搜索，在美加四城市仿真验证梯度区亚公里误差。


<details>
  <summary>Details</summary>
Motivation: GNSS信号易受干扰和遮挡，而地球磁场包含位置信息且对动物导航至关重要。但地磁定位需要超高灵敏度磁力计，量子磁传感为此提供了可能。

Method: 1) 理论推导氮空位中心量子传感的CRLB，证明量子优势；2) 采用分布式量子传感协议饱和CRLB；3) 基于地磁图将定位建模为地图匹配问题；4) 提出梯度空间和角点空间的粗到精马氏距离搜索算法。

Result: 在美国和加拿大四个城市的仿真中：高梯度区域，梯度空间马氏搜索实现亚公里中值定位误差；磁平滑区域，角点空间搜索提供更好精度且运行时间减少4-8倍。

Conclusion: 量子磁传感为GNSS受限环境提供了有前景的替代定位方案，通过理论证明量子优势并开发实用算法，在不同地形条件下均能实现高精度定位。

Abstract: Modern navigation systems rely heavily on Global Navigation Satellite Systems (GNSS), whose weak spaceborne signals are vulnerable to jamming, spoofing, and line-of-sight blockage. As an alternative, the Earth's magnetic field entails location information and is found critical to many animals' cognitive and navigation behavior. However, the practical use of the Earth's magnetic field for geo-localization hinges on an ultra-sensitive magnetometer. This work investigates how quantum magnetic sensing can be used for this purpose. We theoretically derive the Cramér-Rao lower bound (CRLB) for the estimation error of quantum sensing when using a nitrogen-vacancy (NV) center and prove the quantum advantage over classical magnetometers. Moreover, we employ a practical distributed quantum sensing protocol to saturate CRLB. Based on the estimated magnetic field and the earth's magnetic field map, we formulate geo-localization as a map-matching problem and introduce a coarse-to-fine Mahalanobis distance search in both gradient space (local field derivatives) and corner space (raw field samples). We simulate the proposed quantum sensing-based geo-localization framework over four cities in the United States and Canada. The results report that in high-gradient regions, gradient-space Mahalanobis search achieves sub-kilometer median localization error; while in magnetically smoother areas, corner-space search provides better accuracy and a $4-8\times$ reduction in runtime.

</details>


### [20] [Why cut-and-choose quantum state verification cannot be both efficient and secure](https://arxiv.org/abs/2512.11358)
*Fabian Wiesner,Ziad Chaoui,Diana Kessler,Anna Pappa,Martti Karvonen*

Main category: quant-ph

TL;DR: 量子态验证的cut-and-choose方法存在根本性限制：无法同时实现高效性和安全性，这使得该方法在实际中不可用。


<details>
  <summary>Details</summary>
Motivation: 量子态验证在量子密码协议中至关重要，但最常用的cut-and-choose方法是否能在保证安全性的同时保持高效性，这一问题尚未得到全面解答。

Method: 通过理论分析证明cut-and-choose量子态验证的基本限制，展示了该方法在独立安全和可组合安全场景下的安全参数下界。

Result: 证明了cut-and-choose技术无法同时实现高效（轮数少）和安全的量子态验证协议，安全参数的下界缩放使得该方法在实际中不可用。

Conclusion: cut-and-choose量子态验证存在根本性效率-安全性权衡，需要探索替代方法来构建实用且安全的量子态验证协议。

Abstract: Quantum state verification plays a vital role in many quantum cryptographic protocols, as it allows the use of quantum states from untrusted sources. While some progress has been made in this direction, the question of whether the most prevalent type of quantum state verification, namely cut-and-choose verification, can be efficient and secure, is still not answered in full generality. In this work, we show a fundamental limit for quantum state verification for all cut-and-choose approaches used to verify arbitrary quantum states. We provide a no-go result showing that the cut-and-choose techniques cannot lead to quantum state verification protocols that are both efficient in the number of rounds and secure. We show this trade-off for stand-alone and composable security, where the scaling of the lower bound for the security parameters renders cut-and-choose quantum state verification effectively unusable.

</details>


### [21] [Maritime object classification with SAR imagery using quantum kernel methods](https://arxiv.org/abs/2512.11367)
*John Tanner,Nicholas Davies,Pascal Elahi,Casey R. Myers,Du Huynh,Wei Liu,Mark Reynolds,Jingbo Wang*

Main category: quant-ph

TL;DR: 量子机器学习首次应用于SAR图像海上目标分类，量子核方法在某些情况下能达到或超越经典核方法性能，但对复数SAR数据优势不明显。


<details>
  <summary>Details</summary>
Motivation: 非法、未报告和无管制(IUU)捕鱼每年造成100-250亿美元经济损失，破坏海洋可持续性和治理。合成孔径雷达(SAR)能在全天候条件下提供可靠的海上监视，但SAR图像中的小型海上目标分类仍然具有挑战性。

Method: 研究量子机器学习，特别是量子核方法(QKMs)，应用于从SARFish数据集提取的实数和复数SAR图像块。处理两个二元分类问题：1)区分船只与非船只；2)区分渔船与其他类型船只。将QKMs应用于实数和复数SAR数据，与应用于实数SAR数据的经典拉普拉斯核、RBF核和线性核进行比较。

Result: 使用无噪声数值模拟量子核，发现在最佳情况下，QKMs能够获得与经典核相等或更好的性能，但对于复数SAR数据没有显示出明显优势。

Conclusion: 这是量子核方法首次应用于SAR图像海上分类，为量子增强学习在海事监视中的潜力和当前局限性提供了见解。

Abstract: Illegal, unreported, and unregulated (IUU) fishing causes global economic losses of \$10-25 billion annually and undermines marine sustainability and governance. Synthetic Aperture Radar (SAR) provides reliable maritime surveillance under all weather and lighting conditions, but classifying small maritime objects in SAR imagery remains challenging. We investigate quantum machine learning for this task, focusing on Quantum Kernel Methods (QKMs) applied to real and complex SAR chips extracted from the SARFish dataset. We tackle two binary classification problems, the first for distinguishing vessels from non-vessels, and the second for distinguishing fishing vessels from other types of vessels. We compare QKMs applied to real and complex SAR chips against classical Laplacian, RBF, and linear kernels applied to real SAR chips. Using noiseless numerical simulations of the quantum kernels, we find that QKMs are capable of obtaining equal or better performance than the classical kernel on these tasks in the best case, but do not demonstrate a clear advantage for the complex SAR data. This work presents the first application of QKMs to maritime classification in SAR imagery and offers insight into the potential and current limitations of quantum-enhanced learning for maritime surveillance.

</details>


### [22] [Quantum limits of a space-time reference frame](https://arxiv.org/abs/2512.11407)
*Davide Mattei,Esteban Castro Ruiz*

Main category: quant-ph

TL;DR: 量子复合系统无法同时作为完美的空间和时间参考系，空间定位精度和时间分辨率之间存在海森堡式的不确定性关系


<details>
  <summary>Details</summary>
Motivation: 研究当唯一可用的参考系是单个复合量子系统时，定义空间和时间间隔的局限性。该系统内部自由度作为时钟，质心自由度作为空间参考（尺子）。

Method: 结合量子速度极限和狭义相对论的质能等价原理，分析内部能量相干性对质心动力学的影响。从外部视角分析后，通过相对于时空量子参考系的协变可观测量进行纯关系性表述。

Result: 空间局域性和时间分辨率不独立：提高一个精度必然模糊另一个。精确计时所需的内能相干性增强自由演化期间的位置扩散。单个复合系统无法同时作为完美的空间和时间量子参考系，导致空间和时间间隔之间的海森堡式不确定性关系，并揭示出与参考系康普顿波长量级的额外内在不确定性。

Conclusion: 量子参考系存在基本限制：空间和时间测量精度之间存在根本性的权衡，单个复合量子系统无法同时完美地作为空间和时间参考系，这揭示了量子引力背景下时空测量的内在不确定性。

Abstract: We study the limitations for defining spatial and temporal intervals when the only available reference frame is a single composite quantum system, whose internal degrees of freedom serve as a temporal reference, a clock, and whose center of mass degrees of freedom act as a spatial reference, a rod. By combining quantum speed limits with the mass energy equivalence of special relativity, we show that spatial localizability and temporal resolution are not independent: sharpening one inevitably blurs the other. Specifically, the internal energy coherence needed for precise timekeeping affects the center of mass dynamics, enhancing position spreading during free evolution. As a result, a single composite system cannot act as a perfect quantum reference frame for both space and time, leading to a Heisenberg like uncertainty relation between spatial and temporal intervals. After analyzing this trade off from an external perspective, we formulate it in a purely relational manner, by means of covariant observables relative to the space time quantum reference frame, uncovering an additional intrinsic uncertainty of order the Compton wavelength of the frame.

</details>


### [23] [Stabilizer-based quantum simulation of fermion dynamics with local qubit encodings](https://arxiv.org/abs/2512.11418)
*Anthony Gandon,Samuele Piccinelli,Max Rossmannek,Francesco Tacchino,Alberto Baiardi,Jannes Nys,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 提出基于流集的新框架，用于实现局部费米子编码的时间演化幺正算符，通过分类流集形式设计低深度量子电路，在二维编码中实现空间-时间权衡。


<details>
  <summary>Details</summary>
Motivation: 大规模多费米子系统的动力学模拟是量子化学、材料科学和凝聚态物理的重要目标。局部费米子-量子比特编码为在数字量子硬件上实现费米子模拟提供了新途径，但需要有效实现相应的时间演化幺正算符。

Method: 提出基于流集的新框架，流集是定向费米子相互作用图的一维子集。对局部费米子编码在给定流集上的结构进行分类，针对每种流集形式，利用稳定子形式设计低深度量子比特电路来实现时间演化幺正算符。

Result: 为已知的二维编码引入了新颖的基于流的分解，实现了时间演化幺正算符的高效电路分解。观察到空间-时间权衡：具有较大量子比特-费米子比率的映射产生更浅的时间演化量子电路。

Conclusion: 流集框架为局部费米子编码的时间演化幺正算符实现提供了系统方法，通过分类流集结构设计低深度电路，在二维编码中展示了空间-时间权衡的优势。

Abstract: Simulating the dynamical properties of large-scale many-fermion systems is a longstanding goal of quantum chemistry, material science and condensed matter. Local fermion-to-qubit encodings have opened a new path for practical fermionic simulations on digital quantum hardware where fermionic statistics are not enforced at the hardware level. In this paper, we explore these local encodings from the perspective of the corresponding time-evolution unitaries. Specifically, we propose a new framework for digital implementations of these qubit-encoded fermionic time-evolution unitaries based on \emph{flow sets}, which are one-dimensional subsets of the directed fermionic interaction graph. We find that any local fermionic encoding, when restricted to a given flow set, adopts a simple structure that we can classify systematically. For each categorized flow-set form, we propose a low-depth qubit quantum circuit that implements the time evolution unitary using the stabilizer formalism. As an application of our construction, we introduce novel flow-based decompositions for known two-dimensional encodings, leading to efficient circuit decompositions of time-evolution unitaries. We generally observe a space-time trade-off, where mappings with larger qubit-to-fermion ratios yield shallower time-evolution quantum circuits.

</details>


### [24] [Nonreciprocal flow of fluctuations, populations and correlations between doubly coupled bosonic modes](https://arxiv.org/abs/2512.11436)
*Zbigniew Ficek*

Main category: quant-ph

TL;DR: 双耦合玻色模式在环境作用下展现出新颖的相关性和单向特性，非厄米动力学导致热态向单模压缩态转化，并可控制关联的单向流动。


<details>
  <summary>Details</summary>
Motivation: 研究玻色模式在同时存在线性模式跳跃和非线性压缩相互作用的双耦合下，与环境相互作用时出现的新颖相关性和单向特性，探索非厄米动力学带来的独特现象。

Method: 分析两个玻色模式在同时施加线性模式跳跃和非线性压缩相互作用下的双耦合系统，研究其场算符正交分量的动力学特性，探讨非厄米性表现和异常点控制机制。

Result: 发现系统哈密顿量虽为厄米，但场算符正交分量的动力学表现出非厄米性，导致正交分量间的不对称耦合；异常点控制热态向单模经典或量子压缩态的转化；压缩态库中的双光子关联导致模式和关联的单向流动，可通过调节压缩噪声椭圆方向控制。

Conclusion: 双耦合玻色模式系统展现出非厄米动力学特性，为产生单模压缩场提供了新途径，并在玻色链中实现可控的单向布居和关联转移方面具有潜在应用价值。

Abstract: Interesting new correlation and unidirectional properties of two bosonic modes under the influence of environment appear when the modes are mutually coupled through the simultaneously applied linear mode-hopping and nonlinear squeezing interactions. Under such double coupling, it is found that while the Hamiltonian of the system is clearly Hermitian the dynamics of the quadrature components of the field operators can be attributed to non-Hermicity of the system. It is manifested in an asymmetric coupling between the quadrature components which then leads to a variety of remarkable features. In particular, we identify how the emerging exceptional point controls the conversion of thermal states of the modes into single-mode classically or quantum squeezed states. Furthermore, for reservoirs being in squeezed states, we find that the two-photon correlations present in these reservoirs are responsible for unidirectional flow of populations and correlations among the modes and the flow can be controlled by appropriate tuning of the mutual orientation of the squeezed noise ellipses. In the course of analyzing these effects we find that the flow of the population creates the first-order coherence between the modes which, on the other hand rules out an enhancement of the two photon correlations responsible for entanglement between the modes. These results suggest new alternatives for the creation of single mode squeezed fields and the potential applications for controlled unidirectional transfer of population and correlations in bosonic chains.

</details>


### [25] [Comment on "Contextuality and quantum discord"](https://arxiv.org/abs/2512.11450)
*Chellasamy Jebarathinam*

Main category: quant-ph

TL;DR: 本文指出Al-Qasimi关于两量子比特Werner态上下文性的论证是错误的，并引用了相关研究


<details>
  <summary>Details</summary>
Motivation: 纠正Al-Qasimi在Physics Letters A 449 (2022) 128347中关于两量子比特Werner态上下文性的错误结论，该结论认为只有当discord为零时系统才是非上下文性的

Method: 通过分析Al-Qasimi的论证逻辑，指出其错误之处，并引用C. Jebarathinam和R. Srikanth的相关研究来支持这一批评

Result: Al-Qasimi的论证是错误的，两量子比特Werner态的上下文性不能简单地用discord是否为零来判断

Conclusion: 需要重新审视两量子比特态的上下文性分析，Al-Qasimi的结论不可靠，相关研究提供了更准确的理解

Abstract: In a paper, Al-Qasimi [Physics Letters A 449 (2022) 128347] studied contextuality of two-qubit states using an argument by Peres [Phys. Lett. A 151 (1990) 107]. For two-qubit system in the Werner state, Al-Qasimi argued that only when discord is zero, the system is noncontextual. Here I point out that this argument is false and the related work in C. Jebarathinam and R. Srikanth [Int. J. Quantum Inf. https://doi.org/10.1142/S0219749925500376 (arXiv:2403.01762v2)].

</details>


### [26] [Processing through encoding: Quantum circuit approaches for point-wise multiplication and convolution](https://arxiv.org/abs/2512.11457)
*Andreas Papageorgiou,Paulo Vitor Itaborai,Kostas Blekos,Karl Jansen*

Main category: quant-ph

TL;DR: 该论文提出了一种量子电路方法，用于复数函数的逐点乘法和卷积运算，采用"通过编码处理"的概念，将多个复数函数编码到辅助量子比特上，并展示了如何实现函数乘积和卷积运算。


<details>
  <summary>Details</summary>
Motivation: 开发量子信号处理技术，特别是针对音频信号处理领域，探索量子增强的音频操作和合成的潜在应用。

Method: 利用已知技术，将多个复数函数编码到辅助量子比特上，通过量子电路实现函数的逐点乘法，然后基于卷积定理构建卷积运算，涉及傅里叶系数的编码、逐点乘法和逆量子傅里叶变换。

Result: 成功展示了如何将两个函数f和g的逐点乘积f(x)g(x)自然地形成量子态系数，并构建了卷积运算f*g，开发了扩展的quantumaudio包用于音频信号处理，并进行了初步实验验证。

Conclusion: 这项工作为量子信号处理提供了一个有前景的途径，特别是在量子增强的音频操作和合成等领域具有潜在应用价值。

Abstract: This paper introduces quantum circuit methodologies for pointwise multiplication and convolution of complex functions, conceptualized as "processing through encoding". Leveraging known techniques, we describe an approach where multiple complex functions are encoded onto auxiliary qubits. Applying the proposed scheme for two functions $f$ and $g$, their pointwise product $f(x)g(x)$ is shown to naturally form as the coefficients of part of the resulting quantum state. Adhering to the convolution theorem, we then demonstrate how the convolution $f*g$ can be constructed. Similarly to related work, this involves the encoding of the Fourier coefficients $\mathcal{F}[f]$ and $\mathcal{F}[g]$, which facilitates their pointwise multiplication, followed by the inverse Quantum Fourier Transform. We discuss the simulation of these techniques, their integration into an extended \verb|quantumaudio| package for audio signal processing, and present initial experimental validations. This work offers a promising avenue for quantum signal processing, with potential applications in areas such as quantum-enhanced audio manipulation and synthesis.

</details>


### [27] [Bell, Spinors, and the Impossibility of a Classical Spin-Vector Model](https://arxiv.org/abs/2512.11476)
*G. A. Koroteev*

Main category: quant-ph

TL;DR: 该论文重新审视贝尔-CHSH场景，从代数角度揭示贝尔矛盾的根源：量子自旋的非交换代数结构与经典概率的交换代数结构不兼容。


<details>
  <summary>Details</summary>
Motivation: 论文旨在从代数角度精确揭示贝尔矛盾的根源，理解量子自旋的数学结构与经典概率假设之间的根本性不匹配。

Method: 采用C*代数方法，分析自旋-1/2粒子的非交换旋量（克利福德）代数与经典概率的交换代数之间的代数结构差异，并在量子指数代数框架中给出具体实现。

Result: 证明了在标准贝尔假设下，无法将自旋-1/2的旋量代数表示到任何交换的柯尔莫哥洛夫代数中，同时保持局部自旋分量的谱和单态相关性，这从代数角度解释了贝尔矛盾。

Conclusion: 贝尔-CHSH矛盾本质上是自旋的非交换旋量/克利福德描述与经典单一全局概率空间假设之间的代数不匹配，为量子概率理论提供了C*代数重构。

Abstract: We revisit the Bell--CHSH scenario for two spin-\(\tfrac{1}{2}\) particles and isolate the precise algebraic origin of the Bell contradiction. On the quantum side, spin-\(\tfrac{1}{2}\) is described by a noncommutative spinor (Clifford) algebra acting on the Hilbert space of two spin-\(\tfrac{1}{2}\) particles, with the singlet state yielding the usual correlation \(E(a,b) = -\,a\cdot b\) and Tsirelson's bound \(2\sqrt{2}\). On the classical side, the standard Bell assumptions amount to describing all measurement outcomes as \(\{\pm1\}\)-valued random variables on a single Kolmogorov probability space, i.e.\ elements of a commutative algebra \(\mathcal{C}(Λ)\).
  We show that there is no representation of the spinor algebra of spin-\(\tfrac{1}{2}\) (with its singlet state and locality structure) into any such commutative Kolmogorov algebra that preserves the \(\{\pm1\}\) spectra of local spin components and the singlet correlations entering the CHSH expression, under the standard Bell assumptions of locality (factorization) and measurement independence. In this sense, the Bell--CHSH contradiction is exhibited as an algebraic mismatch between a noncommutative spinor/Clifford description of spin and the classical assumption of a single global Kolmogorov space supporting all outcomes. In the language of quantum probability, this is a C\(^*\)-algebraic reformulation of the known fact that the singlet correlations admit no local hidden-variable model with jointly distributed outcomes on one probability space.
  We also give an explicit realization of the same spinor structure within the author's Quantum Index Algebra (QIA) framework, where locality appears as disjoint index slots and the singlet state as a simple index cocycle.

</details>


### [28] [NetQMPI: An MPI-Inspired software for programming Distributed Quantum Applications over Quantum Networks using NetQASM SDK](https://arxiv.org/abs/2512.11483)
*F. Javier Cardama,Tomás F. Pena*

Main category: quant-ph

TL;DR: NetQMPI：基于MPI标准的高层Python框架，用于分布式量子计算，通过抽象物理拓扑和自动化网络资源管理，显著降低代码复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前分布式量子计算软件生态系统要求开发者手动管理底层网络资源（如纠缠生成和经典同步），导致代码冗长、易错且难以扩展。

Method: 基于NetQASM SDK构建中间件，采用SPMD范式将MPI标准适配到量子领域，提供统一的Communicator接口，提出语义点对点原语和新型集体操作（如expose/unexpose），利用多体纠缠进行数据分发。

Result: NetQMPI将算法逻辑与网络规模解耦，将生成N节点GHZ态的代码复杂度从O(N²)降低到常数复杂度O(1)，同时确保后端无关性，可在NetSquid等物理模拟器和未来量子硬件上无缝执行。

Conclusion: NetQMPI为分布式量子计算提供了一个高层抽象框架，显著简化了编程模型，提高了代码的可扩展性和可维护性，为大规模量子算法开发奠定了基础。

Abstract: Distributed Quantum Computing (DQC) is essential for scaling quantum algorithms beyond the limitations of monolithic NISQ devices. However, the current software ecosystem forces developers to manually orchestrate low-level network resources, such as entanglement generation (EPR pairs) and classical synchronization, leading to verbose, error-prone, and non-scalable code. This paper introduces \textbf{NetQMPI}, a high-level Python framework that adapts the Message Passing Interface (MPI) standard to the quantum domain using the Single Program Multiple Data (SPMD) paradigm. Built as a middleware over the NetQASM SDK, NetQMPI abstracts the underlying physical topology, automating network initialization and resource management through a unified Communicator interface. We propose semantic point-to-point primitives and novel collective operations--such as expose and unexpose--that address the constraints of the No-Cloning Theorem by leveraging multipartite entanglement for data distribution. Our comparative analysis demonstrates that NetQMPI decouples algorithmic logic from network size, reducing the code complexity for generating an $N$-node GHZ state from $\mathcal{O}(N^2)$ to constant complexity $\mathcal{O}(1)$. Furthermore, the framework ensures backend agnosticism, enabling the seamless execution of high-level applications on rigorous physical simulators like NetSquid (via SquidASM) and future quantum hardware adhering to the NetQASM standard.

</details>


### [29] [FRQI Pairs method for image classification using Quantum Recurrent Neural Network](https://arxiv.org/abs/2512.11499)
*Rafał Potempa,Michał Kordasz,Sundas Naqeeb Khan,Krzysztof Werner,Kamil Wereszczyński,Krzysztof Simiński,Krzysztof A. Cyran*

Main category: quant-ph

TL;DR: FRQI Pairs方法是一种使用量子循环神经网络进行图像分类的新方法，通过量子编码数据减少量子算法复杂度。


<details>
  <summary>Details</summary>
Motivation: 将量子计算原理与神经网络架构结合，开发量子机器学习，利用量子编码数据简化图像分类任务的量子算法复杂度。

Method: 使用FRQI（柔性量子图像表示）Pairs方法，结合量子循环神经网络进行图像分类。

Result: 与当代技术相比，FRQI Pairs方法显示出将量子计算与神经网络结合用于量子机器学习的潜力。

Conclusion: 量子编码数据方法能显著降低量子算法复杂度，量子计算与神经网络的结合为量子机器学习发展提供了有前景的方向。

Abstract: This study aims to introduce the FRQI Pairs method to a wider audience, a novel approach to image classification using Quantum Recurrent Neural Networks (QRNN) with Flexible Representation for Quantum Images (FRQI).
  The study highlights an innovative approach to use quantum encoded data for an image classification task, suggesting that such quantum-based approaches could significantly reduce the complexity of quantum algorithms. Comparison of the FRQI Pairs method with contemporary techniques underscores the promise of integrating quantum computing principles with neural network architectures for the development of quantum machine learning.

</details>


### [30] [Irreducibility of Quantum Markov Semigroups, uniqueness of invariant states and related properties](https://arxiv.org/abs/2512.11517)
*Franco Fagnola,Federico Girotti*

Main category: quant-ph

TL;DR: 该论文研究了量子马尔可夫半群的不可约性概念，建立了不可约性、本原性和松弛性之间的等价关系，并提供了在GKLS形式下检验不可约性的实用方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子马尔可夫半群中不可约性概念的不同特征，探索其与其他动力学特性（如本原性、正性改进和松弛性）之间的关系，为量子动力学分析提供理论工具。

Method: 采用自包含的数学分析方法，收集相关文献并给出基本证明，研究有限维和无限维演化，利用GKLS形式的生成元算子检验不可约性，特别关注由Schwarz映射构成的半群。

Result: 证明了当半群存在不变密度时，不可约性、本原性和向忠实不变密度的松弛性是等价的；为一致连续量子马尔可夫半群提供了多种检验不可约性的实用方法。

Conclusion: 该研究系统建立了量子马尔可夫半群不可约性的理论框架，揭示了不可约性与其他动力学特性的深刻联系，为量子系统的动力学分析提供了有效的数学工具和检验方法。

Abstract: We present different characterizations of the notion of irreducibility for Quantum Markov Semigroups (QMSs) and investigate its relationship with other relevant features of the dynamics, such as primitivity, positivity improvement and relaxation; in particular, we show that irreducibility, primitivity and relaxation towards a faithful invariant density are equivalent when the semigroup admits an invariant density. Moreover, in the case of uniformly continuous QMSs, we present several useful ways of checking irreducibility in terms of the operators appearing in the generator in GKLS form. Our exposition is as much self-contained as possible, we present some well known results with elementary proofs (collecting all the relevant literature) and we derive new ones. We study both finite and infinite dimensional evolutions and we remark that many results only require the QMS to be made of Schwarz maps.

</details>


### [31] [Equilibration and the Eigenstate Thermalization Hypothesis as Limits to Observing Macroscopic Quantum Superpositions](https://arxiv.org/abs/2512.11522)
*Gabriel Dias Carvalho,Pedro S. Correia,Thiago R. de Oliveira*

Main category: quant-ph

TL;DR: 本研究表明，即使完美隔离，本征态热化假说下的幺正动力学也会抑制宏观量子叠加的可观测特征，幺正热化是限制宏观量子效应出现的基本机制。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为宏观量子叠加不可观测是因为大系统无法完美隔离环境，但本文探讨即使完美隔离情况下，内在动力学如何抑制宏观相干性的可观测特征。

Method: 使用GHZ态作为代表性例子，分析完全相关测量如何初始区分宏观叠加与经典混合，研究一般多体演化如何使它们在大部分演化时间内操作上不可区分，分析可区分性度量和已建立的宏观量子性量化指标。

Result: 研究发现：1）完全相关测量初始能区分宏观叠加与经典混合；2）一般多体演化使它们在大部分时间内操作上不可区分；3）平衡化不仅从可观测中隐藏相干性，还抑制宏观叠加本身。

Conclusion: 幺正热化（独立于环境退相干）是限制宏观量子效应出现的基本机制，即使完美隔离的系统，其内在动力学也会抑制宏观量子叠加的可观测特征。

Abstract: Macroscopic quantum superpositions are widely believed to be unobservable because large systems cannot be perfectly isolated from their environments. Here, we show that even under perfect isolation, intrinsic unitary dynamics with the eigenstate thermalization hypothesis suppress the observable signatures of macroscopic coherence. Using the GHZ state as a representative example, we demonstrate that while fully correlated measurements can initially distinguish a macroscopic superposition from its corresponding classical mixture, generic many-body evolution renders them operationally indistinguishable for most times during the evolution. By analyzing both distinguishability measures and established quantifiers of macroscopic quantumness, we find that equilibration not only hides coherence from accessible observables but also suppresses macroscopic superpositions themselves. These results identify unitary thermalization, independent of environmental decoherence, as a fundamental mechanism that limits the emergence of macroscopic quantum effects.

</details>


### [32] [The Lattice Schwinger Model and Its Quantum Simulation](https://arxiv.org/abs/2512.11533)
*Joao C. Pinto Barros,Pierpaolo Fontana,Pasquale Sodano,Andrea Trombettoni*

Main category: quant-ph

TL;DR: 本章回顾了格点Schwinger模型的研究成果，重点展示了反常效应如何在格点上重现，并讨论了量子模拟该模型的方案。


<details>
  <summary>Details</summary>
Motivation: 连接格点场论与量子模拟领域的最新进展，探索如何通过量子模拟方法研究相互作用的场论模型。

Method: 回顾格点Schwinger模型的研究成果，分析反常效应在格点上的重现机制，讨论量子模拟Schwinger模型的近似方案。

Result: 展示了反常效应可以在格点上正确重现，建立了格点场论与量子模拟之间的连接，提出了可行的量子模拟方案。

Conclusion: 格点Schwinger模型为研究量子场论提供了重要平台，量子模拟技术为实现这类相互作用场论的实验研究开辟了新途径。

Abstract: In this chapter we review results on the lattice Schwinger model. In par-ticular, we show how the effect of the anomaly is reproduced on the lattice. We connect these results to recent developments in the field of quantum simulation of interacting field theories. Schemes for the quantum simulation of (approximations of) Schwinger models are discussed.

</details>


### [33] [A slightly improved upper bound for quantum statistical zero-knowledge](https://arxiv.org/abs/2512.11597)
*François Le Gall,Yupan Liu,Qisheng Wang*

Main category: quant-ph

TL;DR: 该论文将QSZK的上界改进为QIP(2) ∩ co-QIP(2)且验证者只需量子线性空间，类似改进也适用于NIQSZK


<details>
  <summary>Details</summary>
Motivation: QSZK的已知上界是QIP(2) ∩ co-QIP(2)，但验证者通常需要无限制计算能力。作者希望改进这一上界，使验证者只需量子线性空间，从而降低计算复杂度。

Method: 主要技术包括：1) Holevo-Helstrom测量的算法版本；2) Uhlmann变换；3) 利用Le Gall等人最近提出的空间高效量子奇异值变换技术，这些技术都可在量子线性空间中实现。

Result: 成功将QSZK的上界改进为QIP(2) ∩ co-QIP(2)且验证者只需量子线性空间，类似改进也适用于非交互变体NIQSZK。

Conclusion: 该研究在保持证明系统表达能力的同时，显著降低了验证者的计算资源需求，为量子零知识证明的实际应用提供了更可行的方案。

Abstract: The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$), introduced by Watrous (FOCS 2002) and later refined in Watrous (SICOMP, 2009), has the best known upper bound $\mathsf{QIP(2)} \cap \text{co-}\mathsf{QIP(2)}$, which was simplified following the inclusion $\mathsf{QIP(2)} \subseteq \mathsf{PSPACE}$ established in Jain, Upadhyay, and Watrous (FOCS 2009). Here, $\mathsf{QIP(2)}$ denotes the class of promise problems that admit two-message quantum interactive proof systems in which the honest prover is typically \textit{computationally unbounded}, and $\text{co-}\mathsf{QIP(2)}$ denotes the complement of $\mathsf{QIP(2)}$.
  We slightly improve this upper bound to $\mathsf{QIP(2)} \cap \text{co-}\mathsf{QIP(2)}$ with a quantum linear-space honest prover. A similar improvement also applies to the upper bound for the non-interactive variant $\mathsf{NIQSZK}$. Our main techniques are an algorithmic version of the Holevo-Helstrom measurement and the Uhlmann transform, both implementable in quantum linear space, implying polynomial-time complexity in the state dimension, using the recent space-efficient quantum singular value transformation of Le Gall, Liu, and Wang (CC, to appear).

</details>


### [34] [The Casimir-Polder interaction between atoms and hollow-core fibers](https://arxiv.org/abs/2512.11603)
*Bettina Beverungen,Daniel Reiche,Kurt Busch,Francesco Intravaia*

Main category: quant-ph

TL;DR: 研究圆柱形空心光纤附近原子的卡西米尔-波尔德力，分析几何和材料尺度对相互作用的影响，特别关注壳层厚度作为调控参数的作用。


<details>
  <summary>Details</summary>
Motivation: 圆柱形空心光纤是量子技术实验中操控原子的典型结构，需要理解其几何和材料特性如何影响卡西米尔-波尔德相互作用，特别是壳层厚度作为调控参数的可能性。

Method: 开发灵活快速收敛的数值方案，在零温和有限温度下计算宽范围原子-圆柱分离距离的相互作用；同时进行详细解析分析，研究不同材料特性如何修改势能。

Result: 壳层厚度成为调控卡西米尔-波尔德相互作用的有用参数；该几何结构能区分欧姆和非欧姆导体描述；数值计算与解析渐近表达式吻合良好。

Conclusion: 壳层厚度作为控制参数为卡西米尔-波尔德相互作用调控开辟了新途径，对基础物理和量子技术应用具有重要意义。

Abstract: The Casimir-Polder force acts on polarizable particles due to quantum fluctuations of the electromagnetic field that are modified by the presence of material bodies. We investigate the Casimir-Polder interaction for atoms near cylindrical fibers with hollow cores. This geometry represents one of the archetypal configurations encountered in numerous experimental setups designed to control and manipulate atoms in fundamental and quantum technological applications. Specifically, we analyze how the interplay of both geometrical and material-related length scales characterize the interaction, emphasizing the impact of the shell thickness. We develop a flexible and fast-converging numerical scheme for evaluating the interaction over a wide range of atom-cylinder separations at both zero and finite temperature. Furthermore, we provide a detailed analytical investigation of how various material properties modify the Casimir-Polder potential. Finally, we analyze and discuss a number of limiting cases and compare numerical computations with corresponding analytical asymptotic expressions. In particular, in this geometry the Casimir-Polder potential is able to distinguish between an ohmic and non-ohmic description of conductors. One of the most significant outcomes of our work is that the shell thickness emerges as a useful parameter for controlling the interaction, opening avenues for both fundamental physics and applications in quantum technologies.

</details>


### [35] [Tailoring quantum walks in integrated photonic lattices](https://arxiv.org/abs/2512.11608)
*A. Raymond,P. Cathala,M. Morassi,A. Lemaître,F. Raineri,S. Ducci,F. Baboux*

Main category: quant-ph

TL;DR: 该论文系统比较了线性波导阵列（外部注入光子）与非线性波导阵列（通过参量下转换连续产生光子对）两种量子行走方法，实验验证了预测，并展示了逆向设计非周期波导阵列生成最大纠缠态的能力。


<details>
  <summary>Details</summary>
Motivation: 为了阐明离散光子电路与耦合波导阵列这两种量子行走方法的相似性和区别，需要对线性波导阵列（外部光子注入）和非线性波导阵列（内部光子对生成）进行系统比较。

Method: 采用III-V族半导体非线性波导晶格进行实验，通过改变几何结构调节量子行走深度，并开发逆向设计方法优化非周期波导阵列的耦合剖面。

Result: 实验验证了量子行走深度可调节一个数量级，观察到输出态中非经典性的逐渐显现，并成功设计了能生成最大纠缠态（如双光子W态）的非周期波导阵列。

Conclusion: 连续耦合光子系统在紧凑架构中利用高维纠缠具有巨大潜力，非线性波导阵列为量子态生成和操控提供了新途径。

Abstract: Unlike discrete photonic circuits, which manipulate photons step-by-step using a series of optical elements, arrays of coupled waveguides enable photons to interfere continuously across the entire structure. When composed of a nonlinear material, such arrays can also directly generate quantum states of light within the circuit. To clarify the similarities and distinctions between these two approaches of quantum walks, we conduct here a systematic comparison between linear waveguide arrays, injected with photons produced externally, and nonlinear arrays, where photon pairs are continuously generated via parametric down-conversion. We experimentally validate these predictions using III-V semiconductor nonlinear waveguide lattices with varied geometries, enabling us to tune the depth of the quantum walks over an order of magnitude and reveal the gradual emergence of non-classicality in the output state. Finally, we demonstrate an inverse-design approach to engineer \textit{aperiodic} waveguide arrays, whose optimized coupling profiles generate maximally entangled states such as the biphoton W-state. These results highlight the potential of continuously-coupled photonic systems to harness high-dimensional entanglement within compact architectures.

</details>


### [36] [Boltzmann to Lindblad: Classical and Quantum Approaches to Out-of-Equilibrium Statistical Mechanics](https://arxiv.org/abs/2512.11613)
*Stefano Giordano,Giuseppe Florio,Giuseppe Puglisi,Fabrizio Cleri,Ralf Blossey*

Main category: quant-ph

TL;DR: 该论文开发了一个将经典随机动力学扩展到量子领域的框架，通过对称地引入摩擦和噪声，构建了同时满足经典热力学和完全正性的量子主方程。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统在现代纳米技术中至关重要，但构建同时符合经典热力学和完全正性的动力学模型是一个重大理论挑战。

Method: 首先构建广义朗之万方程，其中摩擦和噪声对称地作用于两个哈密顿方程。然后推导出用泊松括号表示的广义Klein-Kramers方程，最后通过正则量子化得到两种量子主方程（厄米和非厄米摩擦算子）。

Result: 分析谐振子动力学发现，只有当摩擦和噪声同时包含在两个哈密顿方程中时，才能确保完全正性。摩擦系数在厄米和非厄米表述中需满足相同的正性条件，显示出一种超越特定算子表示的普适性。

Conclusion: 该框架为推导量子版本的热力学定律提供了通用工具，可直接应用于广泛的非平衡纳米尺度系统，解决了开放量子系统建模中的关键理论问题。

Abstract: Open quantum systems play a central role in contemporary nanoscale technologies, including molecular electronics, quantum heat engines, quantum computation and information processing. A major theoretical challenge is to construct dynamical models that are simultaneously consistent with classical thermodynamics and complete positivity. In this work, we develop a framework that addresses this issue by extending classical stochastic dynamics to the quantum domain. We begin by formulating a generalized Langevin equation in which both friction and noise act symmetrically on the two Hamiltonian equations. From this, we derive a generalized Klein-Kramers equation expressed in terms of Poisson brackets, and we show that it admits the Boltzmann distribution as its stationary solution while satisfying the first and second laws of thermodynamics along individual trajectories. Applying canonical quantization to this classical framework yields two distinct quantum master equations, depending on whether the friction operators are taken to be Hermitian or non-Hermitian. By analyzing the dynamics of a harmonic oscillator, we determine the conditions under which these equations reduce to a Lindblad-type generator. Our results demonstrate that complete positivity is ensured only when friction and noise are included in both Hamiltonian equations, thus fully justifying the classical construction. Moreover, we find that the friction coefficients must satisfy the same positivity condition in both the Hermitian and non-Hermitian formulations, revealing a form of universality that transcends the specific operator representation. The formalism offers a versatile tool for deriving quantum versions of the thermodynamic laws and is directly applicable to a wide class of nonequilibrium nanoscale systems.

</details>


### [37] [Tight bound for the total time in digital-analog quantum computation](https://arxiv.org/abs/2512.11619)
*Mikel Garcia-de-Andoin,Mikel Sanz*

Main category: quant-ph

TL;DR: DAQC（数字-模拟量子计算）是一种结合纠缠哈密顿量演化与单量子比特门的通用计算范式。本文改进了实现任意酉操作所需总时间的最优上界，证明了该时间与耦合数呈线性关系，为量子模拟和算法的时间资源估计提供了精确基准。


<details>
  <summary>Details</summary>
Motivation: DAQC作为一种通用量子计算范式，能够通过纠缠哈密顿量演化和单量子比特门实现任意酉操作。然而，之前提出的实现这些演化所需总时间的上界并非最优，限制了DAQC与其他量子计算方法的精确比较和时间资源评估。

Method: 本文改进了DAQC中实现任意酉操作所需总时间的上界分析。通过数学推导，为这一关键参数提供了紧致边界（tight bound），证明了总时间与系统耦合数之间的线性依赖关系。

Result: 获得了DAQC实现任意酉操作所需总时间的紧致上界，该边界显示总时间与耦合数呈线性比例关系。这一结果显著优于先前提出的次优上界。

Conclusion: 改进的时间边界为DAQC框架下的量子模拟和量子算法提供了精确的时间资源估计，使得DAQC能够与其他量子计算方法进行严格比较，有助于评估DAQC在实际应用中的可行性和效率。

Abstract: Digital-analog quantum computing (DAQC) is a universal computational paradigm that combines the evolution under an entangling Hamiltonian with the application of single-qubit gates. Since any unitary operation can be decomposed into a sequence of evolutions generated by two-body Hamiltonians, DAQC is inherently well-suited for realizing such operations. Suboptimal upper bounds for the total time required to perform these evolutions have been previously proposed. Here, we improve these limits by providing a tight bound for this crucial parameter, which shows a linear dependence with the number of couplings. This result enables a precise estimation of the time resources needed for quantum simulations and quantum algorithms implemented within the DAQC framework, facilitating a rigorous comparison with other approaches.

</details>


### [38] [Polarization Entanglement in Atomic Biphotons via OAM-to-Spin Mapping](https://arxiv.org/abs/2512.11625)
*Chang-Wei Lin,Yi-Ting Ma,Jiun-Shiuan Shiu,Yong-Fan Chen*

Main category: quant-ph

TL;DR: 在冷原子双Λ系统中实现了偏振纠缠双光子，通过空间光调制器将轨道角动量纠缠映射到偏振基，首次在冷原子四波混频平台中演示了OAM到偏振的纠缠转移。


<details>
  <summary>Details</summary>
Motivation: 原子选择规则通常会抑制偏振关联而偏向轨道角动量纠缠，这限制了冷原子系统与基于偏振的量子通信网络的集成。需要开发一种方法将原子OAM资源转换为偏振纠缠。

Method: 使用空间光调制器将选定的二维OAM子空间相干地映射到偏振基上，从而打开原本不可访问的偏振通道。通过量子态层析验证映射过程保持了双光子相干性。

Result: 生成了四个偏振贝尔态，保真度达到92-94%，统计不确定度仅为几个百分点。平均Clauser-Horne-Shimony-Holt参数S=2.44，证实了非局域关联的保持。

Conclusion: 这项工作首次在冷原子自发四波混频平台中演示了OAM到偏振的纠缠转移，为将原子OAM资源与基于偏振的量子通信网络集成建立了实用接口。

Abstract: We demonstrate polarization-entangled biphotons in a cold-atom double-$Λ$ system, overcoming atomic selection rules that suppress polarization correlations and favor orbital angular momentum (OAM) entanglement. Using spatial light modulators, we coherently map a selected two-dimensional OAM subspace onto the polarization basis and thereby open an otherwise inaccessible polarization channel. Quantum-state tomography confirms that the mapping preserves the biphoton coherence. The four polarization Bell states are generated with fidelities of $92\text{-}94\%$ with few-percent statistical uncertainties, and an average Clauser-Horne-Shimony-Holt parameter of $S=2.44$ verifies the survival of nonlocal correlations. To the best of our knowledge, this work presents the first demonstration of OAM-to-polarization entanglement transfer in a cold-atom spontaneous four-wave mixing platform and establishes a practical interface for integrating atomic OAM resources with polarization-based quantum communication networks.

</details>


### [39] [Highly Nondegenerate Entangled Photon Source for Fiber-Based Quantum Key Distribution](https://arxiv.org/abs/2512.11630)
*Vasile-Laurentiu Dosan,Alek Lagarrigue,Alessandro Zannotti,Tushar Parab,Yannick Folwill,Fabian Steinlechner,Oliver de Vries*

Main category: quant-ph

TL;DR: 开发了一种基于交叉晶体配置的稳定、高度非简并纠缠光子源，产生680nm和1550nm光子对，结合了硅探测器的高效率和光纤通信的低损耗特性。


<details>
  <summary>Details</summary>
Motivation: 纠缠光子源是量子通信和量子密钥分发的关键组件。现有系统需要在探测器效率和光纤传输损耗之间进行权衡，本文旨在开发一种同时具备高探测效率和低传输损耗的波长混合纠缠光子源。

Method: 采用基于0型自发参量下转换的交叉晶体配置，使用473nm激光泵浦，产生680nm（信号）和1550nm（闲频）光子对。这种波长组合首次报道，结合了硅单光子雪崩二极管在可见/近红外波段的高峰探测效率和电信C波段的低损耗光纤传输特性。

Result: 光源表现出300GHz的测量光谱带宽，光谱亮度高达1.9×10³ pairs s⁻¹ mW⁻¹ GHz⁻¹。预示效率达到18%（信号）和34%（闲频）。纠缠态在H/V基下的可见度为(97.3±1.0)%，在D/A基下为(94.9±1.6)%，保真度≥(96.1±1.3)%。

Conclusion: 该纠缠光子源为基于光纤的量子密钥分发和新兴的长距离量子网络架构提供了一个实用的波长混合平台，在性能和成本之间实现了最有利的平衡。

Abstract: Entangled photon sources (EPSs) are essential building blocks for scalable quantum communication and quantum key distribution (QKD). We present a stable, highly nondegenerate EPS based on type-0 spontaneous parametric down-conversion (SPDC) in a crossed-crystal configuration, generating photon pairs at 680~nm and 1550~nm when pumped by a 473~nm laser. This wavelength combination, reported here for the first time, simultaneously benefits from the peak detection efficiency of the most of the Si-SPADs in the visible/near-infrared spectral range and the low-loss fiber transmission of the telecom C-band. This configuration provides the most favorable balance between performance and cost for detection using Si-SPADs and InGaAs detectors. The source exhibits a measured spectral bandwidth of 300~GHz, corresponding to a spectral brightness of up to $1.9\times 10^3$~pairs~s$^{-1}$~mW$^{-1}$~GHz$^{-1}$. Heralding efficiencies reach 18~\% (signal) and 34~\% (idler) with Si-SPAD and superconducting nanowire single-photon detectors (SNSPD) detection. The entangled state achieves visibilities of $(97.3\pm 1.0)\,\%$ in the H/V basis and $(94.9\pm1.6)\,\%$ in the D/A basis, yielding a fidelity of $\geq(96.1\pm1.3)\,\%$. These results establish the presented EPS as a practical wavelength-hybrid platform for fiber-based QKD and emerging long-haul quantum network architectures.

</details>


### [40] [Basis dependence of Neural Quantum States for the Transverse Field Ising Model](https://arxiv.org/abs/2512.11632)
*Ronald Santiago Cortes,Aravindh S. Shankar,Marcello Dalmonte,Roberto Verdel,Nils Niggemann*

Main category: quant-ph

TL;DR: 研究神经量子态(NQS)在不同计算基下的表现差异，发现性能与基选择相关，与多自旋算符的累积展开收敛性有关


<details>
  <summary>Details</summary>
Motivation: 尽管神经量子态在量子多体问题中应用广泛，但目前对其局限性理解不足。本文旨在研究NQS性能如何依赖于计算基的选择，特别是针对受限玻尔兹曼机架构

Method: 通过旋转横向场伊辛模型的哈密顿量，研究不同基下的NQS表现。分析基态简并性、振幅和相位的均匀性等性质，并将性能与多自旋算符的累积展开收敛性联系起来

Result: 发现NQS性能的基依赖性与其收敛性质相关，特别是与多自旋算符的簇展开或累积展开的收敛特性有关。这为理解NQS在不同基下的表现提供了理论框架

Conclusion: 研究结果为评估NQS在新问题中的适用性提供了见解，并有助于识别数值计算的最优基选择。建立了物理性质与NQS性能之间的直接联系框架

Abstract: Neural Quantum States (NQS) are powerful tools used to represent complex quantum many-body states in an increasingly wide range of applications. However, despite their popularity, at present only a rudimentary understanding of their limitations exists. In this work, we investigate the dependence of NQS on the choice of the computational basis, focusing on restricted Boltzmann machines. Considering a family of rotated Hamiltonians corresponding to the paradigmatic transverse-field Ising model, we discuss the properties of ground states responsible for the dependence of NQS performance, namely the presence of ground state degeneracies as well as the uniformity of amplitudes and phases, carefully examining their interplay. We identify that the basis-dependence of the performance is linked to the convergence properties of a cluster or cumulant expansion of multi-spin operators -- providing a framework to directly connect physical, basis-dependent properties, to performance itself. Our results provide insights that may be used to gauge the applicability of NQS to new problems and to identify the optimal basis for numerical computations.

</details>


### [41] [Shot-to-shot displacement noise in state-expansion protocols with inverted potentials](https://arxiv.org/abs/2512.11633)
*Giuseppe Paolo Seta,Louisiane Devaud,Lorenzo Dania,Lukas Novotny,Martin Frimmer*

Main category: quant-ph

TL;DR: 该论文研究了光悬浮纳米粒子在量子态扩展协议中，由于电势对准的随机波动导致的相干性限制问题。


<details>
  <summary>Details</summary>
Motivation: 光悬浮纳米粒子是生成宏观量子态的有前景平台，但在实验协议中需要将粒子暴露于不同电势序列。不同实验实现之间电势对准的可重复性有限，会引入额外噪声，影响量子态的相干性。

Method: 实验研究和建模分析了在利用暗反转电势进行态扩展协议时，随机波动如何限制悬浮纳米粒子的相干长度。识别了电场杂散场和机械不稳定性作为主要波动源。

Result: 确定了电场杂散场和机械不稳定性是导致随机波动的主要因素，这些波动限制了态扩展协议中粒子的相干长度。

Conclusion: 讨论了利用反转电势进行态扩展协议所需的实验要求，强调了控制电场杂散场和机械稳定性对于实现高质量宏观量子态的重要性。

Abstract: Optically levitated nanoparticles are promising candidates for the generation of macroscopic quantum states of mechanical motion. Protocols to generate such states expose the particle to a succession of different potentials. Limited reproducibility of the alignment of these potentials across experimental realizations introduces additional noise. Here, we experimentally investigate and model how such shot-to-shot noise limits the coherence length of a levitated nanoparticle during a state-expansion protocol using a dark, inverted electrical potential. We identify electric stray fields and mechanical instabilities as major sources of shot-to-shot fluctuations. We discuss the resulting experimental requirements for state expansion protocols exploiting inverted potentials.

</details>


### [42] [Nuclear magnetic resonance on a single atom with a local probe](https://arxiv.org/abs/2512.11652)
*Hester G. Vennema,Cristina Mier,Evert W. Stolte,Leonard Edens,Jinwon Lee,Sander Otte*

Main category: quant-ph

TL;DR: 该论文展示了在单个表面原子上实现核磁共振，使用扫描探针技术成功探测了单个47Ti同位素的核自旋跃迁，为量子信息应用提供了重要进展。


<details>
  <summary>Details</summary>
Motivation: 核自旋因其与环境弱耦合和长相干时间而成为量子信息应用的理想候选者，但弱耦合也带来了核自旋寻址的挑战。需要在原子尺度上实现对单个核自旋的控制和探测。

Method: 采用电子-核双共振测量方案，使用局部扫描探针在单个表面原子上进行核磁共振实验。通过四极相互作用解析多个NMR跃迁，并与本征能计算进行比较。

Result: 成功解析了单个47Ti同位素（核自旋I=5/2）的核自旋跃迁。实验结果表明，无论核自旋与电子自旋的杂化程度如何，都能有效驱动核自旋，这对于在长寿命体系中直接控制核自旋至关重要。

Conclusion: 在具有原子尺度控制的平台上实现单个原子的核磁共振，为其他利用核自旋进行表征技术或量子信息技术开发的平台提供了宝贵的发展。

Abstract: The nuclear spin is a prime candidate for quantum information applications due to its weak coupling to the environment and inherently long coherence times. However, this weak coupling also challenges the addressability of the nuclear spin. Here we demonstrate nuclear magnetic resonance (NMR) on a single on-surface atom using a local scanning probe. We employ an electron-nuclear double resonance measurement scheme and resolve nuclear spin transitions of a single 47Ti isotope with a nuclear spin of I = 5/2. The quadrupole interaction enables to resolve multiple NMR transitions, which are consistent with our eigenenergy calculations. Our experimental results indicate that the nuclear spin can be driven efficiently irrespective of its hybridization with the electron spin, which is required for direct control of the nuclear spin in the long-lifetime regime. This investigation of NMR on a single atom in a platform with atomic-scale control is a valuable development for other platforms deploying nuclear spins for characterization techniques or quantum information technology.

</details>


### [43] [Tailored Error Mitigation for Single-Qubit Magnetometry](https://arxiv.org/abs/2512.11671)
*Miriam Resch,Dennis Herb,Mirko Rossini,Joachim Ankerhold,Dominik Maile*

Main category: quant-ph

TL;DR: 提出一种新型量子传感误差缓解技术，可逆转任意完全正定保迹映射描述的噪声影响，通过预表征设备知识自动适应耗散演化复杂性，指示最优传感时间，在单NV中心磁力计中实现最佳灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子传感在精度和空间分辨率方面有超越经典方法的潜力，但其对噪声高度敏感。现有量子误差缓解技术利用噪声信息改善测量结果，但需要更高效的方法来逆转任意噪声影响。

Method: 提出新型缓解技术，利用设备预表征获得的知识，自动适应耗散演化的复杂性，指示最优传感时间τ。该方法可逆转任何由完全正定保迹映射描述的噪声效应。

Result: 在单NV中心磁力计中验证了该方法能达到噪声环境下最佳可实现的灵敏度，展示了其有效性。

Conclusion: 这项工作是迈向更具弹性、具有最小分辨率尺度的量子传感器的进一步进展，为量子传感的实际应用提供了重要技术支撑。

Abstract: Quantum sensing is an emerging field with the potential to outperform classical methods in both precision and spatial resolution. However, the sensitivity of the underlying quantum platform also makes the sensors highly susceptible to their environmental noise. To address this issue, techniques from the field of quantum error mitigation use information about the noise to improve measurement results. We present a novel mitigation technique for quantum sensors to efficiently reverse the effects of any noise that can be described by a completely positive trace preserving map. The method leverages the knowledge acquired by a pre-characterization step of the device to automatically adapt to the complexity of the dissipative evolution and to indicate optimal sensing times $τ$ to achieve the most accurate results. We demonstrate that our method reaches the best achievable sensitivity in noisy single-NV-center magnetometry.
  This work marks a further step toward more resilient quantum sensors with the smallest scale of resolution.

</details>


### [44] [Hardware Efficient Quantum Kernels Using Multimode Bulk Acoustic Resonators](https://arxiv.org/abs/2512.11672)
*Collin C. D. Frink,Chaoyang Ti,Stephen K. Gray,Xu Han,Matthew Otten*

Main category: quant-ph

TL;DR: 提出一种基于Kerr非线性量子系统的量子增强核方法，通过声学谐振器与Kerr量子比特耦合实现时间相关模拟，展示量子优势


<details>
  <summary>Details</summary>
Motivation: 传统核方法在处理高维数据集时面临计算复杂度和数据效率问题，需要探索量子计算在核方法中的优势

Method: 扩展Kerr非线性器件的量子核设计，实现Kerr量子比特与声学谐振器耦合的时间相关模拟，利用Kerr非线性诱导多模系统的非经典行为定义量子增强核

Result: 在实验可行参数下，Kerr非线性直接诱导多模系统的非经典行为，成功定义并分析了量子增强核，展示了随着谐振器数量增加，经典模拟该核的计算不可行性

Conclusion: 基于Kerr非线性量子系统的量子增强核方法具有量子计算优势，随着系统规模扩大，经典模拟变得计算不可行，为量子机器学习提供了有前景的方向

Abstract: The kernel trick is a widely applicable technique in machine learning domains that maps datasets that are difficult to classify into a computationally friendly feature space. As the dimension of the dataset scales, these kernel calculations can quickly become computationally intractable or data inefficient. In this work, we extend prior efforts in quantum kernel design for Kerr nonlinear devices by implementing time-dependent simulations of a Kerr-qubit coupled to acoustic resonators. For experimentally feasible parameters, we demonstrate that the Kerr nonlinearity directly induces non-classical behavior in the multimode system, which we use to define and analyze a quantum-enhanced kernel. Finally, we present a brief scaling characterization that demonstrates the computational intractability of classically simulating the kernel as the number of resonators scales.

</details>


### [45] [Optimal Control of Coupled Sensor-Ancilla Qubits for Multiparameter Estimation](https://arxiv.org/abs/2512.11673)
*Ayumi Kanamoto,Takuya Isogawa,Shunsuke Nishimura,Haidong Yuan,Paola Cappellaro*

Main category: quant-ph

TL;DR: 使用GRAPE算法优化两量子比特传感器-辅助系统的控制脉冲，实现多参数量子传感的高精度测量


<details>
  <summary>Details</summary>
Motivation: 多参数量子传感需要最优控制设计以达到极限精度，但复杂系统（如耦合量子比特和时变哈密顿量）通常缺乏解析解

Method: 采用梯度上升脉冲工程（GRAPE）算法，通过递归优化策略（从小耦合强度开始逐步优化）和合适的初始猜测，优化两量子比特传感器-辅助系统的控制脉冲

Result: 该方法在广泛的相互作用强度和场配置范围内实现了鲁棒的收敛和高精度，为高灵敏度、鲁棒的多参数磁强计提供了实用途径

Conclusion: 该数值优化方法适用于固态量子传感器（如金刚石氮空位中心），为实际实验环境中的多参数量子传感提供了有效解决方案

Abstract: Designing optimal control for multiparameter quantum sensing is essential for approaching the ultimate precision limits. However, analytical solutions are generally available only for simple systems, while realistic scenarios often involve coupled qubits and time-dependent Hamiltonians. Here we numerically investigate optimal control of a two-qubit sensor-ancilla system coupled via an Ising term using Gradient Ascent Pulse Engineering (GRAPE) to minimize the objective function. By seeding the optimization recursively with solutions obtained for smaller coupling strengths and selecting a suitable initial guess, we achieve robust convergence and high precision across a wide range of interaction strengths and field configurations. The proposed approach offers a practical route toward high-sensitivity, robust multiparameter magnetometry and it is applicable to solid-state quantum sensors such as nitrogen-vacancy (NV) centers in realistic experimental settings.

</details>


### [46] [Bloch oscillation in a Floquet engineering quadratic potential system](https://arxiv.org/abs/2512.11675)
*J. Cao,H. Shen,R. Wang,X. Z. Zhang*

Main category: quant-ph

TL;DR: 研究一维紧束缚晶格在空间二次型、时间周期势驱动下的量子动力学，分析厄米与非厄米跃迁机制，发现临界频率下出现准能谱梯子结构，导致鲁棒的周期性复兴和布洛赫振荡。


<details>
  <summary>Details</summary>
Motivation: 探索周期驱动量子系统中准能谱的规律性及其对动力学行为的影响，特别是在非厄米体系中驱动如何稳定准能谱结构。

Method: 基于Floquet理论，将含时哈密顿量映射为有效静态Floquet哈密顿量，分析准能谱和本征态局域化，通过数值模拟研究时间演化。

Result: 识别出临界频率ω_c，在该频率下出现近似等间距的准能梯子结构，能级间距方差最小，平均逆参与率峰值，导致鲁棒的周期性复兴和布洛赫振荡，非厄米体系中驱动能稳定准实数均匀准能梯子。

Conclusion: 周期驱动能诱导准能谱的规律性结构，即使在非厄米体系中也能产生稳定的相干振荡，为调控量子动力学提供了新途径。

Abstract: We investigate the quantum dynamics of a one-dimensional tight-binding lattice driven by a spatially quadratic and time-periodic potential. Both Hermitian ($J_1 = J_2$) and non-Hermitian ($J_1 \neq J_2$) hopping regimes are analyzed. Within the framework of Floquet theory, the time-dependent Hamiltonian is mapped onto an effective static Floquet Hamiltonian, enabling a detailed study of the quasi-energy spectrum and eigenstate localization as function of the driving frequency $ω$. We identify critical frequencies $ω_c$ at which nearly equidistant quasi-energy ladders emerge, characterized by a pronounced minimum in the normalized variance of level spacings. This spectral regularity, which coincides with a peak in the mean inverse participation ratio (\textrm{MIPR}), leads to robust periodic revivals and Bloch-like oscillations in the time evolution. Numerical simulations confirm that such coherent oscillations persist even in the non-Hermitian regime, where the periodic driving stabilizes an almost real and uniformly spaced quasi-energy ladder.

</details>


### [47] [Spectral side channels in quantum key distribution under laser damage](https://arxiv.org/abs/2512.11701)
*Binwu Gao,Junxuan Liu,Ekaterina Borisova,Hao Tan,Mingyang Zhong,Zihao Chen,Qingquan Peng,Weixu Shi,Anastasiya Ponosova,Vadim Makarov,Anqi Huang*

Main category: quant-ph

TL;DR: 该研究系统分析了量子密钥分发系统中密集波分复用器在激光注入攻击下的特性，发现某些DWDM在高功率激光照射下会出现显著的光谱特性变化，这种光谱侧信道会严重降低QKD系统的最大安全传输距离。


<details>
  <summary>Details</summary>
Motivation: 在QKD系统中，DWDM通常用于合并量子信号和同步信号，并直接连接到量子信道，因此成为激光注入攻击的首个暴露光学元件。了解DWDM在此类攻击下的行为对于评估QKD系统的实际安全性至关重要。

Method: 通过实验系统研究DWDM在高功率激光照射下的特性，并以特洛伊木马攻击为例进行理论分析，结合实验观察和理论建模研究DWDM对QKD系统实际安全性的影响。

Result: 实验结果显示某些DWDM样品在注入激光功率超过特定阈值后会出现显著的光谱特性变化。理论分析表明由此产生的光谱侧信道可以将最大安全传输距离降低到原始值的66.9%以下。

Conclusion: 通过结合实验观察和理论建模，本研究推进了对DWDM影响QKD系统实际安全性的理解，揭示了DWDM在激光注入攻击下可能产生的安全漏洞。

Abstract: In the transmitter of a quantum key distribution (QKD) system, a dense wavelength-division multiplexer (DWDM) is typically used to combine quantum and synchronization signals and is directly connected to the quantum channel. As a result, it becomes the first optical component exposed to laser-injection attacks. Therefore, understanding the behavior of DWDMs under such attacks is essential for assessing the practical security of QKD systems. In this work, we systematically investigate the characteristics of DWDMs under high-power laser illumination. Our experimental results show that certain DWDM samples exhibit pronounced changes in their spectral features once the injected laser power surpasses a specific threshold. Taking the Trojan-horse attack as an illustrative example, we further perform a theoretical analysis of the resulting spectral side channel and show that it can reduce the maximum secure transmission distance to below 66.9% of its original value. By combining experimental observations with theoretical modeling, this study advances the understanding of the influence of DWDMs on the practical security of QKD systems.

</details>


### [48] [Thermal interaction-free ghost imaging](https://arxiv.org/abs/2512.11709)
*Shun Li,Jing-Yang Xiao Feng,Xiu-Qing Yang,Xiaodong Zeng,Xi-Hua Yang,M. Al-Amri,Zheng-Hong Li*

Main category: quant-ph

TL;DR: 提出一种基于热光源的无相互作用鬼成像方案，利用量子芝诺效应减少样品吸收的光剂量，避免光-物质相互作用导致的样品损伤，同时提高图像质量


<details>
  <summary>Details</summary>
Motivation: 传统鬼成像需要纠缠光子源和单光子探测器，且光-物质相互作用可能损伤光敏样品。需要一种既能保护样品又能获得高质量图像的非破坏性成像方法

Method: 基于热光源的无相互作用鬼成像方案，利用量子芝诺效应减少样品吸收的光剂量，消除对纠缠光子源和单光子探测器的依赖，通过可控光子损耗主动抑制背景噪声

Result: 显著减少了样品吸收的光剂量，有效防止样品损伤；相比传统鬼成像，能利用更多光子进行图像重建，显著提高图像质量；实现了背景噪声的主动抑制

Conclusion: 该工作为生命科学等领域的敏感样品提供了一种实用且经济高效的非破坏性高质量成像途径

Abstract: We propose an interaction-free ghost imaging scheme based on a thermal light source. By utilizing the quantum Zeno-like effect, our approach significantly reduces the light dose absorbed by the sample, thereby effectively preventing sample damage induced by light-matter interactions. Combined with the elimination of entangled photon sources and single-photon detectors, our approach enables significantly more photons to be utilized for image reconstruction, thereby markedly enhancing image quality compared to conventional ghost imaging. We further demonstrate active suppression of background noise via controllable photon loss. Our work offers a practical and cost-effective route to non-destructive, high-quality imaging for light-sensitive samples in fields such as life sciences.

</details>


### [49] [Real-Time Polarization Control for Satellite QKD with Liquid-Crystal Beacon Stabilization](https://arxiv.org/abs/2512.11714)
*Ondrej Klicnik,Alessandro Zannotti,Yannick Folwill,Oliver de Vries,Petr Munster,Tomas Horvath*

Main category: quant-ph

TL;DR: 提出使用液晶可变延迟器作为紧凑快速偏振补偿方法，通过经典参考信号表征信道引起的偏振旋转，实现卫星量子密钥分发中的实时偏振跟踪


<details>
  <summary>Details</summary>
Motivation: 偏振不稳定性是偏振纠缠卫星量子密钥分发的关键挑战，大气效应和平台运动持续扭曲光子偏振，必须精确识别和补偿这些变换以保持纠缠保真度

Method: 使用液晶可变延迟器作为紧凑快速偏振补偿方法，通过经典参考信号（信标）表征信道引起的偏振旋转，实现实时偏振跟踪

Result: 开发了一种能够实时补偿卫星量子密钥分发链路中偏振旋转的紧凑快速偏振补偿系统

Conclusion: 液晶可变延迟器提供了一种有效的解决方案，能够应对卫星量子密钥分发中的偏振不稳定性挑战，实现实时偏振跟踪和补偿

Abstract: Polarization instability is a critical challenge for polarization-entangled satellite quantum key distribution (QKD), where atmospheric effects and platform motion continuously distort photon polarization. To maintain entanglement fidelity, these transformations must be precisely identified and compensated before detection. The channel-induced polarization rotation of a classical reference signal (beacon) is characterized using liquidcrystal variable retarders as a compact and fast polarizationcompensation approach, enabling real-time polarization tracking for satellite QKD links.

</details>


### [50] [Qubits in second quantisation in fermionic simulators](https://arxiv.org/abs/2512.11726)
*Ahana Ghoshal,Carlos de Gois,Kiara Hansenne,Otfried Gühne,Hai-Chau Nguyen*

Main category: quant-ph

TL;DR: 提出将费米子模式配对形成"二次量子化量子比特"，使费米子门可表示为这些量子比特的旋转，从而将费米子模拟器中的测量优化问题转化为图论问题


<details>
  <summary>Details</summary>
Motivation: 传统量子比特计算机模拟多体费米子系统存在编码费米子统计的显著开销，而原生费米子模拟器虽然能高效模拟费米子问题，但也带来特定约束和不熟悉的挑战

Method: 将费米子模式配对形成"二次量子化量子比特"，使费米子门可表示为这些量子比特的旋转，从而能够适应量子比特系统的方法。将费米子模拟器中二点和四点关联函数的测量表示为其原生门的图论问题

Result: 通过配对方案，费米子模拟器的测量设置优化可以转化为图论问题，并使用各种分析和算法方法进行优化分析

Conclusion: 提出的二次量子化量子比特表示方法为费米子模拟器提供了一种新框架，能够利用量子比特系统的优化技术来解决费米子模拟中的测量挑战

Abstract: Simulating many-body fermionic systems in conventional qubit-based quantum computers poses significant challenges due to the overheads associated with the encoding of fermionic statistics in qubits, leading to the proposal of native fermionic simulators as an alternative. While allowing for fermionic problems to be simulated efficiently, this class of fermionic simulators carries also specific constraints with them and poses other challenges unfamiliar to qubit systems. Here, we propose to pair fermionic modes to form a so-called qubit in second quantisation representation. This allows fermionic gates to be represented as rotations of these second quantised qubits, enabling adaptation of methods for qubit systems. As an application, we use this pairing scheme to represent the measurement of two- and four-point correlators in fermionic simulators with its native gates as a graph problem. Optimising measurement settings is then analysed with various analytical and algorithmic methods.

</details>


### [51] [Entanglement generation in qubit-ADAPT-VQE through four-qubit algebraic classification](https://arxiv.org/abs/2512.11729)
*Diego Tancara,Herbert Díaz-Moraga,Vicente Sepúlveda-Trivelli,Dardo Goyeneche*

Main category: quant-ph

TL;DR: Qubit-ADAPT-VQE算法在具有高纠缠度的自旋模型基态估计中表现良好，能够准确达到所有纠缠类别的基态。


<details>
  <summary>Details</summary>
Motivation: ADAPT-VQE算法在分子哈密顿量（基态纠缠度低）中已有广泛基准测试，但在高纠缠基态中的性能尚未充分探索。需要评估该算法在具有显著纠缠的自旋模型中的表现。

Method: 使用qubit-ADAPT-VQE算法变体，在四量子比特系统中评估其达到高纠缠基态的能力。采用代数纠缠分类识别基态的不同纠缠类别，并为每个类别选择代表性初始状态来评估算法性能。

Result: qubit-ADAPT-VQE表现出良好的通用性，能够准确达到所有纠缠类别的基态，且不受初始能量值的影响。

Conclusion: 该研究证明了qubit-ADAPT-VQE算法在处理高纠缠量子态时的有效性，为在NISQ时代解决变分量子算法的可扩展性问题提供了重要见解。

Abstract: While variational quantum algorithms are among the most promising approaches for the noisy intermediate-scale quantum (NISQ) era, their scalability is often hindered by the barren plateau problem. Among the proposals that have demonstrated robustness against this issue, the ADAPT-VQE algorithm stands out for ground state estimation, primarily due to its iterative ansatz construction. Although ADAPT-VQE has been extensively benchmarked on molecular Hamiltonians, where the ground states typically exhibit low entanglement, its performance for highly entangled ground states remains largely unexplored. In this work, we explore a variant of this algorithm known as qubit-ADAPT-VQE, assessing its ability to achieve ground states with substantial entanglement in spin models. We focus on four-qubit systems and employ an algebraic entanglement classification to identify distinct entanglement classes among ground states, and consider a representative of each class as an initial state to evaluate the performance of the algorithm. Our findings highlight the versatility of qubit-ADAPT-VQE, demonstrating that it accurately reaches the ground state across all entanglement classes and initial energy values.

</details>


### [52] [CNOT gates in inductively coupled multi-fluxonium systems](https://arxiv.org/abs/2512.11756)
*Valeria Díaz Moreno,Nikola D. Dimitrov,Vladimir E. Manucharyan,Maxim G. Vavilov*

Main category: quant-ph

TL;DR: 四比特fluxonium系统中，通过调节旁观量子比特频率与活跃量子比特充分失谐，可以抑制旁观效应导致的误差，实现低于10⁻⁴的CNOT门误差，为可扩展量子处理器提供可行路径。


<details>
  <summary>Details</summary>
Motivation: 虽然双比特fluxonium系统已实现高保真度两比特门，但构建可扩展量子处理器需要在更大架构中保持低错误率。本研究旨在分析四比特耦合fluxonium系统中旁观量子比特对CNOT门性能的影响。

Method: 分析四个电感耦合的fluxonium量子比特系统，研究旁观量子比特对CNOT门性能的影响。通过调节旁观量子比特与活跃量子比特的跃迁频率失谐度，识别有利的频率配置。

Result: 当旁观量子比特的跃迁频率与活跃量子比特充分失谐时，旁观效应导致的误差被强烈抑制。在四比特链中识别出有利频率配置，可在门时间短于100纳秒时实现低于10⁻⁴的CNOT门误差。

Conclusion: 利用最近邻耦合的局域性，研究结果可外推到更长的fluxonium链，为构建可扩展、低误差的量子信息处理系统提供了可行路径。

Abstract: High-fidelity two-qubit gates have been demonstrated in systems of two fluxonium qubits; however, the realization of scalable quantum processors requires maintaining low error rates in substantially larger architectures. In this work, we analyze a system of four inductively coupled fluxonium qubits to determine the impact of spectator qubits on the performance of a \textsc{cnot} gate. Our results show that spectator-induced errors are strongly suppressed when the transition frequencies of the spectator qubits are sufficiently detuned from those of the active qubits. We identify favorable frequency configurations for the four-qubit chain that yield \textsc{cnot} gate errors below $10^{-4}$ for gate times shorter than 100 ns. Leveraging the locality of the nearest-neighbor coupling, we extrapolate our findings to longer fluxonium chains, suggesting a viable path toward scalable, low-error quantum information processing.

</details>


### [53] [Computing the molecular ground state energy in a restricted active space using quantum annealing](https://arxiv.org/abs/2512.11757)
*Stefano Bruni,Enrico Prati*

Main category: quant-ph

TL;DR: 该论文展示了使用量子退火计算水分子基态能量的改进方法，通过XBK映射和先进退火策略，实现了比先前方法更高的成功率和精度。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法（如CASCI）在计算分子基态能量时存在指数级扩展问题，无法处理大分子。量子计算提供了替代方案，但之前的量子退火方法受限于硬件和退火技术。

Method: 使用Xian-Bias-Kas (XBK)方法将H₂O基态问题映射到Ising哈密顿量，利用增强的量子比特连接性和更短的嵌入链，结合先进的退火策略。

Result: 相比最先进的前代方法，获得Hartree-Fock水平解的概率提高了一倍以上；使用物理嵌入量子比特数量增加了近2.5倍；能量精度达到0.120 Hartree（相对于Hartree-Fock）。

Conclusion: 这些结果表明在NISQ时代量子退火应用取得了实质性进展，为实际量子退火应用展示了有希望的进展。

Abstract: Calculating the molecular ground-state energy is a central challenge in computational chemistry. Conventional methods such as the Complete Active Space Configuration Interaction scale exponentially with molecular size, limiting their applicability to large molecules. Quantum computing offers a promising alternative by mapping molecular Hamiltonians by qubits, enabling cheaper computational scaling. Previous studies have shown that it is possible to formulate molecular ground state calculations as discrete optimization problems, addressable by quantum annealing. However, these efforts have been limited by previous generations of hardware and suboptimal annealing techniques. Here, the $H_{2}O$ ground-state problem is mapped to an Ising Hamiltonian using the Xian-Bias-Kas (XBK) method. By taking advantage of enhanced qubit connectivity and shorter embedding chains, it is solved with a more than doubled probability of achieving Hartree-Fock-level solutions with respect to the most advanced predecessor. Advanced annealing strategies extend Hartree-Fock-level accuracy to significantly larger problem instances, enabling solutions that use nearly 2.5 times more physically embedded qubits than the largest cases previously reported and allowing to improve annealing results by two orders of magnitude, reaching an energy difference of 0.120~Hartree relative to Hartree-Fock. These results show tangible progress toward practical quantum annealing applications in NISQ era.

</details>


### [54] [Learning Minimal Representations of Fermionic Ground States](https://arxiv.org/abs/2512.11767)
*Felix Frohnert,Emiel Koridon,Stefano Polla*

Main category: quant-ph

TL;DR: 提出無監督機器學習框架，透過自動編碼器發現量子多體基態的最優壓縮表示，並將解碼器用作可微分變分擬設，直接最小化能量。


<details>
  <summary>Details</summary>
Motivation: 量子多體系統的狀態空間維度隨系統大小指數增長，傳統方法面臨計算複雜度挑戰。需要開發能自動發現系統內在自由度並有效壓縮表示的方法。

Method: 使用自動編碼器神經網絡架構，在L-site Fermi-Hubbard模型數據上訓練，識別最小潛在空間。將訓練好的解碼器用作可微分變分擬設，直接在潛在空間中最小化能量。

Result: 發現重建質量在L-1潛在維度處存在尖銳閾值，與系統內在自由度匹配。該方法繞過了N-可表示性問題，因為學習的流形隱含地將優化限制在物理有效的量子態上。

Conclusion: 該框架能夠自動發現量子多體系統的最優壓縮表示，並提供一種繞過N-可表示性問題的有效變分方法，為量子多體物理的機器學習應用開闢新途徑。

Abstract: We introduce an unsupervised machine-learning framework that discovers optimally compressed representations of quantum many-body ground states. Using an autoencoder neural network architecture on data from $L$-site Fermi-Hubbard models, we identify minimal latent spaces with a sharp reconstruction quality threshold at $L-1$ latent dimensions, matching the system's intrinsic degrees of freedom. We demonstrate the use of the trained decoder as a differentiable variational ansatz to minimize energy directly within the latent space. Crucially, this approach circumvents the $N$-representability problem, as the learned manifold implicitly restricts the optimization to physically valid quantum states.

</details>


### [55] [A Vlasov-Bohm approach to Quantum Mechanics for statistical systems](https://arxiv.org/abs/2512.11772)
*Pedro Luis Grande,Raul Carlos Fadanelli,Maarten Vos*

Main category: quant-ph

TL;DR: 该论文提出了一种基于玻姆量子势的量子化方法，通过将玻姆量子势纳入弗拉索夫框架，得到了能够捕捉物质粒子性的平均场理论，该理论与随机相位近似下的量子力学一致。


<details>
  <summary>Details</summary>
Motivation: 量子力学是描述微观现象最成功的理论，但存在多种表述方式。论文旨在探索玻姆力学（特别是玻姆量子势）作为经典非相对论系统量子化的新起点，提供一种替代的量子化方法。

Method: 将玻姆量子势整合到弗拉索夫框架中，构建一个平均场理论。这种方法保留了物质的粒子性特征，并与随机相位近似下的量子力学结果保持一致。

Result: 成功开发了一种基于玻姆量子势的量子化方案，得到的平均场理论能够准确描述物质的粒子性，且在随机相位近似下与标准量子力学结果一致。

Conclusion: 玻姆力学可以作为经典系统量子化的有效起点，通过玻姆量子势与弗拉索夫框架的结合，提供了一种既能保持粒子性又与量子力学一致的理论框架，为量子力学提供了新的视角和计算方法。

Abstract: Quantum mechanics is the most successful theory to describe microscopic phenomena. It was derived in different ways over the past 100 years by Heisenberg, Schrödinger, and Feynman. At the same time, other interpretations have been suggested, including the Bohm-De Broglie interpretation and the so-called Bohmian mechanics. Here, we show that Bohmian mechanics, which utilizes the concept of the Bohm quantum potential, can also serve as a starting point for quantizing classical non-relativistic systems. By incorporating the Bohm quantum potential into the Vlasov framework, we obtain a mean-field theory that captures the corpuscular nature of matter, in agreement with quantum mechanics within the Random Phase Approximation (RPA).

</details>


### [56] [Quantum Krylov algorithm using unitary decomposition for exact eigenstates of fermionic systems using quantum computers](https://arxiv.org/abs/2512.11788)
*Ayush Asthana*

Main category: quant-ph

TL;DR: 提出QKUD算法，通过酉分解构建精确的Krylov子空间，解决了传统量子Krylov算法中时间演化不精确、依赖时间步长参数的问题。


<details>
  <summary>Details</summary>
Motivation: 传统量子Krylov算法使用实时间或虚时间演化构建Krylov向量，这种方法不精确、需要任意时间步长参数Δt，且随着Δt增大Krylov向量质量迅速下降。

Method: 开发了基于酉分解的量子Krylov算法(QKUD)，通过酉分解精确构建Krylov子空间，无需时间演化，误差参数ε的缩放为O(ε²)。

Result: QKUD在ε→0时给出精确结果，在ε≠0时比传统时间演化更准确，数值模拟显示：(1)小ε时提供数值精确结果；(2)在宽ε范围内保持稳定；(3)能解决传统方法无法处理的问题。

Conclusion: QKUD解决了量子Krylov算法的核心限制——不精确性和对时间步长参数的敏感性，为量子计算机上实现更强量子优势的新型量子Krylov算法铺平了道路。

Abstract: Quantum Krylov algorithms have emerged as a useful framework for quantum simulations in quantum chemistry and many-body physics, offering a favorable trade-off between potential quantum speedups and practical resource demands. However, the current primary approach to building Krylov vectors in these algorithms is to use real or imaginary-time evolution, which is not exact, require an arbitrary time-step parameter ($Δt$), and degrade the Krylov vectors quickly with increasing $Δt$. In this paper, we develop a quantum Krylov algorithm without time evolution and with an exact formulation of the Krylov subspace, named ``Quantum Krylov using Unitary Decomposition'' (QKUD), along with implementation proposals for quantum computers. Not only is this algorithm exact in the limit $ε\to 0$ of the error parameter $ε$, but it also produces more accurate Krylov vectors at $ε\neq 0$ than conventional time evolution due to more favorable error scaling (O($ε^2$) vs O($Δt$)). Through simulations, we demonstrate that these theoretical benefits yield numerical advantages: (i) QKUD provides numerically exact results at small $ε$, (ii) it remains stable across a broad range of $ε$ values, indicating low parameter sensitivity, and (iii) it can solve problems unreachable by conventional time evolution. This development resolves a central limitation of quantum Krylov algorithms, namely their inexactness and sensitivity to the time-step parameter, and paves the way for new and powerful quantum Krylov algorithms for quantum computers with a stronger promise of quantum advantage.

</details>


### [57] [A Room-Temperature Extreme High Vacuum System for Trapped-Ion Quantum Information Processing](https://arxiv.org/abs/2512.11794)
*Lewis Hahn,Nikhil Kotibhaskar,Fabien Lefebvre,Sakshee Patil,Sainath Motlakunta,Mahmood Sabooni,Rajibul Islam*

Main category: quant-ph

TL;DR: 研发室温极端高真空系统，将离子阱量子处理器连续运行时间延长至1.9小时/离子碰撞间隔


<details>
  <summary>Details</summary>
Motivation: 背景气体碰撞限制了离子阱量子处理器的性能和可扩展性，会中断算法执行甚至将离子弹出阱外。现有系统需要低温装置，增加了复杂性。

Method: 通过分子流模拟优化腔室几何、导电路径和泵浦配置；对不锈钢真空组件进行高温热处理降低H₂出气率；使用混合同位素Yb⁺离子链观测碰撞诱导重排事件来测量局部压力

Result: 最终腔室压力达到1.5×10⁻¹² mbar（测量极限）；离子位置局部压力为(3.9±0.3)×10⁻¹² mbar；离子碰撞平均间隔为(1.9±0.1)小时/离子

Conclusion: 成功开发出室温极端高真空系统，无需低温装置即可显著延长量子处理器连续运行时间，为离子阱量子计算的可扩展性提供了重要支持

Abstract: We present a room-temperature Extreme High Vacuum (XHV) system engineered to support the long-duration operation of a trapped-ion quantum processor. Background-gas collisions impose limitations on trapped-ion performance and scalability by interrupting algorithmic execution and, in some cases, ejecting ions from the trap. Using molecular-flow simulations, we optimize the chamber geometry, conductance pathways, and pumping configuration to maximize the effective pumping speed at the ion location. We perform high-temperature heat treatment of stainless steel vacuum components to achieve the desired outgassing rate, guided by quantitative relations of bulk diffusive processes, allowing us to reduce the \(\mathrm{H_2}\) outgassing load to the \(10^{-15}\,\mathrm{mbar\,l\,s^{-1}\,cm^{-2}}\) level. The final pressure in our chamber, measured by a hot cathode gauge, is \(1.5\times10^{-12}\,\mathrm{mbar}\), corresponding to the gauge's measurement limit. We measure the local pressure at the ion location by observing collision-induced reordering events in a long ion chain of mixed-isotope Yb\(^+\). From the observed reordering frequency, we extract the average interval between collisions to be \((1.9 \pm 0.1)\,\mathrm{hrs/ion}\). This corresponds to a local pressure of \((3.9 \pm 0.3)\times10^{-12}\,\mathrm{mbar}\) at the ion location, assuming that all collisions arise from background H\(_2\) molecules at room temperature. Our demonstration extends the continuous operation time of a quantum processor while maintaining the simplicity of a room-temperature system that does not require cryogenic apparatus.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [58] [HPRMAT: A high-performance R-matrix solver with GPU acceleration for coupled-channel problems in nuclear physics](https://arxiv.org/abs/2512.11590)
*Jin Lei*

Main category: physics.comp-ph

TL;DR: HPRMAT是一个用于核物理中R-矩阵耦合道散射计算的高性能线性系统求解器库，作为现有R-矩阵代码的线性代数例程直接替代品，通过优化算法和GPU加速实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统R-矩阵代码使用矩阵求逆方法效率低下，特别是在处理大规模矩阵时。需要开发高性能求解器来加速核物理中的耦合道散射计算，使研究人员能够在标准桌面工作站上进行大规模计算，而无需昂贵的数据中心GPU。

Method: 采用直接线性方程求解替代传统矩阵求逆，提供四种求解器后端：(1)双精度LU分解，(2)混合精度算术与迭代精化，(3)利用动力学耦合矩阵结构的Woodbury公式方法，(4)GPU加速。混合精度策略在消费级GPU上特别有效，通过单精度分解和迭代精化克服FP64性能不足。

Result: GPU求解器相比优化CPU直接求解器实现9倍加速，相比传统求逆代码实现18倍加速（N=25600）。混合精度策略在消费级GPU上特别有效，CPU求解器提供5-7倍加速。所有求解器保持物理精度，截面计算相对误差低于10^-5。

Conclusion: HPRMAT通过算法优化和硬件加速显著提升了R-矩阵耦合道散射计算的性能，使大规模CDCC和耦合道计算能够在标准桌面工作站上进行，为核物理研究提供了高性能计算工具。

Abstract: I present HPRMAT, a high-performance solver library for the linear systems arising in R-matrix coupled-channel scattering calculations in nuclear physics. Designed as a drop-in replacement for the linear algebra routines in existing R-matrix codes, HPRMAT employs direct linear equation solving with optimized libraries instead of traditional matrix inversion, achieving significant performance improvements. The package provides four solver backends: (1) double-precision LU factorization, (2) mixed-precision arithmetic with iterative refinement, (3) a Woodbury formula approach exploiting the kinetic-coupling matrix structure, and (4) GPU acceleration. Benchmark calculations demonstrate that the GPU solver achieves up to 9$\times$ speedup over optimized CPU direct solvers, and 18$\times$ over legacy inversion-based codes, for large matrices ($N=25600$). The mixed-precision strategy is particularly effective on consumer GPUs (e.g., NVIDIA RTX 3090/4090), where single-precision throughput exceeds double-precision by a factor of 64:1; by performing factorization in single precision with iterative refinement, HPRMAT overcomes the poor FP64 performance of consumer hardware while maintaining double-precision accuracy. This makes large-scale CDCC and coupled-channel calculations accessible to researchers using standard desktop workstations, without requiring expensive data-center GPUs. CPU-only solvers provide 5--7$\times$ speedup through optimized libraries and algorithmic improvements. All solvers maintain physics accuracy with relative errors below $10^{-5}$ in cross-section calculations, validated against Descouvemont's reference code (Comput.\ Phys.\ Commun.\ 200, 199--219 (2016)). HPRMAT provides interfaces for Fortran, C, Python, and Julia.

</details>


### [59] [Stable spectral neural operator for learning stiff PDE systems from limited data](https://arxiv.org/abs/2512.11686)
*Rui Zhang,Han Wan,Yang Liu,Hao Sun*

Main category: physics.comp-ph

TL;DR: SSNO是一种无需方程的学习框架，通过谱神经网络架构和积分因子时间步进方案，仅需少量数据即可准确预测刚性PDE系统的时空动态。


<details>
  <summary>Details</summary>
Motivation: 当控制方程未知且观测数据稀疏时，准确建模时空动态面临根本挑战。系统刚性（多时间尺度耦合）进一步加剧了这一问题，阻碍了长期预测。现有方法不足：纯数据驱动方法需要海量数据，而物理感知方法受限于对已知方程和精细时间步长的依赖。

Method: 提出稳定谱神经算子（SSNO）框架，在架构中嵌入谱启发结构，而非编码特定方程项。在频域自动学习局部和全局空间交互，并使用稳健的积分因子时间步进方案处理系统刚性。

Result: 在多个2D和3D基准测试（笛卡尔和球面几何）中，SSNO的预测误差比领先模型低1-2个数量级。具有显著的数据效率，仅需2-5个训练轨迹即可稳健泛化到分布外条件。

Conclusion: SSNO为从有限数据中学习刚性时空动态提供了一个稳健且可泛化的方法，无需PDE项的显式先验知识。

Abstract: Accurate modeling of spatiotemporal dynamics is crucial to understanding complex phenomena across science and engineering. However, this task faces a fundamental challenge when the governing equations are unknown and observational data are sparse. System stiffness, the coupling of multiple time-scales, further exacerbates this problem and hinders long-term prediction. Existing methods fall short: purely data-driven methods demand massive datasets, whereas physics-aware approaches are constrained by their reliance on known equations and fine-grained time steps. To overcome these limitations, we introduce an equation-free learning framework, namely, the Stable Spectral Neural Operator (SSNO), for modeling stiff partial differential equation (PDE) systems based on limited data. Instead of encoding specific equation terms, SSNO embeds spectrally inspired structures in its architecture, yielding strong inductive biases for learning the underlying physics. It automatically learns local and global spatial interactions in the frequency domain, while handling system stiffness with a robust integrating factor time-stepping scheme. Demonstrated across multiple 2D and 3D benchmarks in Cartesian and spherical geometries, SSNO achieves prediction errors one to two orders of magnitude lower than leading models. Crucially, it shows remarkable data efficiency, requiring only very few (2--5) training trajectories for robust generalization to out-of-distribution conditions. This work offers a robust and generalizable approach to learning stiff spatiotemporal dynamics from limited data without explicit \textit{a priori} knowledge of PDE terms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [60] [Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering](https://arxiv.org/abs/2512.10962)
*Yifei He,Pranit Chawla,Yaser Souri,Subhojit Som,Xia Song*

Main category: cs.LG

TL;DR: 提出WebSTAR数据集和StepRM奖励模型，通过步骤级过滤从噪声轨迹中提取可靠监督信号，显著提升计算机使用代理性能


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理训练面临GUI交互成本高和高质量轨迹数据稀缺的问题，现有基于人类演示的数据集难以扩展，而强代理的轨迹噪声大，需要有效的数据合成方法

Method: 提出可扩展的数据合成流水线：1) 步骤级过滤，单独评估动作保留正确步骤；2) 推理增强改进规划；3) 从OpenAI计算机使用预览模型合成WebSTAR数据集；4) 基于步骤级评分创建WebSCORE数据集；5) 训练轻量级奖励模型StepRM

Result: WebSTAR包含13.3K轨迹和100K评分步骤，训练的7B模型在WebVoyager上超越SoTA开源模型15%以上；StepRM奖励模型匹配o4-mini评分质量但部署效率更高

Conclusion: 步骤级过滤是扩展计算机使用代理训练的关键原则，WebSTAR、WebSCORE数据集和StepRM奖励模型为构建鲁棒高效的计算机使用代理提供了实用工具

Abstract: Computer use agents (CUAs) can operate real-world digital interfaces but remain difficult to train due to the high cost of graphical user interface (GUI) interaction and the scarcity of high-quality trajectory data. Existing datasets rely on human demonstrations, limiting scalability. A natural alternative is to synthesize data from strong CUAs, yet their rollouts are highly noisy, with incorrect or suboptimal actions consisting a large proportion of the steps, making naive imitation ineffective. To tackle this challenge, we introduce a scalable data synthesis pipeline that transforms noisy rollouts into reliable supervision without human annotation. The core idea is step-level filtering, which evaluates actions individually to retain only correct steps, complemented by reasoning augmentation for improved planning. Using this pipeline, we construct WebSTAR, a dataset of 13.3K trajectories and 100K graded, reasoning-rich steps synthesized from OpenAI's computer-use-preview model. We train Qwen-2.5-VL-Instruct models (7B and 32B) on WebSTAR. On WebVoyager, our 7B model surpasses SoTA open-source CUA model UI-TARS-1.5-7B by more than 15% with only supervised finetuning. Building on step-level grading, we further create WebSCORE, a dataset of graded step-level actions, and train StepRM, a 7B multimodal reward model distilled from o4-mini, which matches its grading quality while being far more efficient to deploy at scale. Our results establish step-level filtering as a key principle for scalable CUA training and construct two new datasets (WebSTAR, WebSCORE) and a lightweight reward model (StepRM) as practical tools to advance robust and efficient CUAs.

</details>


### [61] [Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2512.10966)
*Farica Zhuang,Dinara Aliyeva,Shu Yang,Zixuan Wen,Duy Duong-Tran,Christos Davatzikos,Tianlong Chen,Song Wang,Li Shen*

Main category: cs.LG

TL;DR: MREF-AD：一种用于阿尔茨海默病诊断的多模态区域专家融合模型，采用混合专家框架，通过两级门控网络自适应融合淀粉样蛋白PET和MRI等多模态信息，提供区域特异性生物标志物解释。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的准确早期诊断需要整合多模态信息，但传统融合方法通常采用简单的特征拼接，无法自适应平衡不同脑区生物标志物（如淀粉样蛋白PET和MRI）的贡献。

Method: 提出MREF-AD模型：1）将每个模态的中尺度脑区建模为独立专家；2）采用两级门控网络学习受试者特定的融合权重；3）基于混合专家框架实现自适应多模态融合。

Result: 在ADNI数据上，MREF-AD实现了最先进的诊断性能，同时提供了增强的可解释性，能够揭示脑区特异性生物标志物的相关性。

Conclusion: MREF-AD不仅提高了诊断性能，还提供了模态和区域层面的洞察，展示了结构和分子成像如何共同贡献于疾病诊断，是一个适用于神经影像自适应可解释多模态融合的通用框架。

Abstract: Accurate and early diagnosis of Alzheimer's disease (AD) can benefit from integrating complementary information from multiple modalities, mirroring clinical practice. However, conventional fusion approaches often rely on simple concatenation of features, which cannot adaptively balance the contributions of biomarkers such as amyloid PET and MRI across brain regions. In this work, we propose MREF-AD, a Multimodal Regional Expert Fusion model for AD diagnosis. It is a Mixture-of-Experts (MoE) framework that models meso-scale brain regions in each modality as an independent expert and employs two-level gating networks to learn subject-specific fusion weights. Beyond improving diagnostic performance, MREF-AD provides modality- and region-level insight into how structural and molecular imaging jointly contribute to disease diagnosis. Using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), MREF-AD achieves state-of-the-art performance over baselines while providing enhanced interpretability of brain region-specific biomarker relevance, underscoring its utility as a general framework for adaptive and interpretable multimodal fusion in neuroimaging.

</details>


### [62] [MoB: Mixture of Bidders](https://arxiv.org/abs/2512.10969)
*Dev Vyas*

Main category: cs.LG

TL;DR: MoB用拍卖机制替代MoE的门控网络，通过VCG拍卖让专家竞标数据批次，解决了持续学习中灾难性遗忘问题，在Split-MNIST上比基线提升4.5倍。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构在持续学习中的主要限制是学习的门控网络本身会遭受灾难性遗忘，这阻碍了MoE在持续学习场景中的应用。

Method: 提出Mixture of Bidders框架，用VCG拍卖机制替代学习的门控网络。专家通过竞标真实成本（执行成本+遗忘成本）来竞争数据批次，实现无状态路由。还扩展了具有自我监控能力的专家，可自主检测知识整合边界。

Result: 在Split-MNIST基准测试中，MoB达到88.77%的平均准确率，而Gated MoE为19.54%，Monolithic EWC为27.96%，比最强基线提升4.5倍。

Conclusion: MoB通过将专家路由重新概念化为去中心化的经济机制，解决了MoE在持续学习中的关键限制，提供了对灾难性遗忘的免疫、真实竞标保证和无任务边界的涌现专业化。

Abstract: Mixture of Experts (MoE) architectures have demonstrated remarkable success in scaling neural networks, yet their application to continual learning remains fundamentally limited by a critical vulnerability: the learned gating network itself suffers from catastrophic forgetting. We introduce Mixture of Bidders (MoB), a novel framework that reconceptualizes expert routing as a decentralized economic mechanism. MoB replaces learned gating networks with Vickrey-Clarke-Groves (VCG) auctions, where experts compete for each data batch by bidding their true cost -- a principled combination of execution cost (predicted loss) and forgetting cost (Elastic Weight Consolidation penalty). This game-theoretic approach provides three key advantages: (1) {stateless routing that is immune to catastrophic forgetting, (2) \textbf{truthful bidding} guaranteed by dominant-strategy incentive compatibility, and (3) emergent specialization without explicit task boundaries. On Split-MNIST benchmarks, MoB achieves 88.77% average accuracy compared to 19.54% for Gated MoE and 27.96% for Monolithic EWC, representing a 4.5 times improvement over the strongest baseline. We further extend MoB with autonomous self-monitoring experts that detect their own knowledge consolidation boundaries, eliminating the need for explicit task demarcation.

</details>


### [63] [TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis](https://arxiv.org/abs/2512.10973)
*Jiang Liu,Yujie Li,Chan Zhou,Yihao Xie,Qilong Sun,Xin Shu,Peiwei Li,Chunyong Yang,Yiziting Zhu,Jiaqi Zhu,Yuwen Chen,Bo An,Hao Wu,Bin Yi*

Main category: cs.LG

TL;DR: 提出基于强化学习的个性化肝素治疗优化框架，使用连续cxSOFA评分和TECM评估矩阵，在脓毒症手术患者中降低死亡率并缩短住院时间


<details>
  <summary>Details</summary>
Motivation: 脓毒症是危及生命的严重感染状态，需要优化肝素治疗。现有SOFA评分是离散的，缺乏治疗评估的连续性，需要更精细的数据驱动方法来个性化治疗策略

Method: 使用MIMIC-IV和eICU数据库数据，提出强化学习框架：1) 将离散SOFA转换为连续cxSOFA评分；2) 基于cxSOFA定义"好/坏"治疗策略；3) 提出类似混淆矩阵的TECM评估矩阵；应用Q-Learning、DQN、DDQN、BCQ、CQL等算法优化治疗

Result: cxSOFA-CQL模型表现最佳，将死亡率从1.83%降至0.74%，平均住院时间从11.11天缩短至9.42天。TECM在不同模型中显示一致结果，证明框架稳健性

Conclusion: 该强化学习框架实现了肝素治疗的可解释和稳健优化，连续cxSOFA评分和TECM评估提供了精细的治疗评估，有望改善临床结果和决策支持可靠性

Abstract: Objective: Sepsis is a life-threatening condition caused by severe infection leading to acute organ dysfunction. This study proposes a data-driven metric and a continuous reward function to optimize personalized heparin therapy in surgical sepsis patients. Methods: Data from the MIMIC-IV v1.0 and eICU v2.0 databases were used for model development and evaluation. The training cohort consisted of abdominal surgery patients receiving unfractionated heparin (UFH) after postoperative sepsis onset. We introduce a new RL-based framework: converting the discrete SOFA score to a continuous cxSOFA for more nuanced state and reward functions; Second, defining "good" or "bad" strategies based on cxSOFA by a stepwise manner; Third, proposing a Treatment Effect Comparison Matrix (TECM), analogous to a confusion matrix for classification tasks, to evaluate the treatment strategies. We applied different RL algorithms, Q-Learning, DQN, DDQN, BCQ and CQL to optimize the treatment and comprehensively evaluated the framework. Results: Among the AI-derived strategies, the cxSOFA-CQL model achieved the best performance, reducing mortality from 1.83% to 0.74% with the average hospital stay from 11.11 to 9.42 days. TECM demonstrated consistent outcomes across models, highlighting robustness. Conclusion: The proposed RL framework enables interpretable and robust optimization of heparin therapy in surgical sepsis. Continuous cxSOFA scoring and TECM-based evaluation provide nuanced treatment assessment, showing promise for improving clinical outcomes and decision-support reliability.

</details>


### [64] [Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems](https://arxiv.org/abs/2512.10975)
*Matvey Nepomnyaschiy,Oleg Pereziabov,Anvar Tliamov,Stanislav Mikhailov,Ilya Afanasyev*

Main category: cs.LG

TL;DR: 提出一种基于多智能体框架的多模态情感识别系统，通过模块化架构实现模态灵活集成和训练效率提升。


<details>
  <summary>Details</summary>
Motivation: 传统多模态深度学习模型虽然情感识别准确率高，但训练维护计算量大，且对模态变化不灵活，需要更高效、可扩展的解决方案。

Method: 采用多智能体框架，每个模态编码器和融合分类器作为自主智能体，由中央监督器协调，支持模块化集成新模态（如emotion2vec音频特征）和组件替换。

Result: 通过支持视觉、音频和文本模态的概念验证实现，展示了框架的可行性，分类器作为共享决策智能体，提高了训练效率。

Conclusion: 该框架不仅提升训练效率，还为HAI场景中的具身和虚拟智能体设计更灵活、可扩展、易维护的感知模块提供了新思路。

Abstract: Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

</details>


### [65] [MolSculpt: Sculpting 3D Molecular Geometries from Chemical Syntax](https://arxiv.org/abs/2512.10991)
*Zhanpeng Chen,Weihao Gao,Shunyu Wang,Yanan Zhu,Hong Meng,Yuexian Zou*

Main category: cs.LG

TL;DR: MolSculpt是一个新颖的3D分子生成框架，通过从冻结的1D分子基础模型中提取化学知识，指导3D扩散模型生成精确的分子几何结构，实现了1D化学知识与3D几何生成的深度融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用1D表示（如SELFIES）确保分子有效性，但未能充分利用1D模型中丰富的化学知识，导致1D语法生成与3D几何实现之间存在脱节。需要弥合这一差距以生成更精确的3D分子几何结构。

Method: MolSculpt基于冻结的1D分子基础模型和3D分子扩散模型构建。引入可学习的查询从基础模型中提取内在化学知识，通过可训练投影器将这些跨模态信息注入扩散模型的条件空间，以端到端优化方式将1D潜在化学知识深度整合到3D生成过程中。

Result: 实验表明，MolSculpt在从头3D分子生成和条件3D分子生成方面实现了最先进的性能，在GEOM-DRUGS和QM9数据集上表现出优越的3D保真度和稳定性。

Conclusion: MolSculpt成功地将1D化学知识与3D几何生成深度融合，为药物发现和材料科学提供了更精确的3D分子生成解决方案，代码已开源。

Abstract: Generating precise 3D molecular geometries is crucial for drug discovery and material science. While prior efforts leverage 1D representations like SELFIES to ensure molecular validity, they fail to fully exploit the rich chemical knowledge entangled within 1D models, leading to a disconnect between 1D syntactic generation and 3D geometric realization. To bridge this gap, we propose MolSculpt, a novel framework that "sculpts" 3D molecular geometries from chemical syntax. MolSculpt is built upon a frozen 1D molecular foundation model and a 3D molecular diffusion model. We introduce a set of learnable queries to extract inherent chemical knowledge from the foundation model, and a trainable projector then injects this cross-modal information into the conditioning space of the diffusion model to guide the 3D geometry generation. In this way, our model deeply integrates 1D latent chemical knowledge into the 3D generation process through end-to-end optimization. Experiments demonstrate that MolSculpt achieves state-of-the-art (SOTA) performance in \textit{de novo} 3D molecule generation and conditional 3D molecule generation, showing superior 3D fidelity and stability on both the GEOM-DRUGS and QM9 datasets. Code is available at https://github.com/SakuraTroyChen/MolSculpt.

</details>


### [66] [Memoryless Policy Iteration for Episodic POMDPs](https://arxiv.org/abs/2512.11082)
*Roy van Zuijlen,Duarte Antunes*

Main category: cs.LG

TL;DR: 提出了一种新的策略迭代算法族，用于求解部分可观测马尔可夫决策过程（POMDPs），通过交替执行单阶段基于输出的策略改进和策略评估，在模型无关和模型相关设置中实现计算加速。


<details>
  <summary>Details</summary>
Motivation: 解决POMDPs时，无记忆和有限记忆策略提供了一种实用替代方案，因为它们直接在输出空间而非高维信念空间中操作。然而，将经典方法（如策略迭代）扩展到这一设置仍然困难，因为输出过程是非马尔可夫的，使得策略改进步骤在不同阶段相互依赖。

Method: 引入了一个新的单调改进策略迭代算法族，这些算法按照规定的周期性模式，在单阶段基于输出的策略改进和策略评估之间交替进行。确定了最大化计算效率指标的最优模式，并找到了具有最小周期的最简单模式。基于此结构，进一步开发了一个模型无关变体，可以从数据中估计值并直接学习无记忆策略。

Result: 在多个POMDPs示例中，该方法在模型相关和模型无关设置中均实现了相对于策略梯度基线和近期专门算法的显著计算加速。

Conclusion: 提出了一种有效的策略迭代框架，用于在POMDPs中学习无记忆和有限记忆策略，通过周期性交替改进和评估模式克服了输出过程的非马尔可夫性，并在计算效率方面表现出色。

Abstract: Memoryless and finite-memory policies offer a practical alternative for solving partially observable Markov decision processes (POMDPs), as they operate directly in the output space rather than in the high-dimensional belief space. However, extending classical methods such as policy iteration to this setting remains difficult; the output process is non-Markovian, making policy-improvement steps interdependent across stages. We introduce a new family of monotonically improving policy-iteration algorithms that alternate between single-stage output-based policy improvements and policy evaluations according to a prescribed periodic pattern. We show that this family admits optimal patterns that maximize a natural computational-efficiency index, and we identify the simplest pattern with minimal period. Building on this structure, we further develop a model-free variant that estimates values from data and learns memoryless policies directly. Across several POMDPs examples, our method achieves significant computational speedups over policy-gradient baselines and recent specialized algorithms in both model-based and model-free settings.

</details>


### [67] [Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerating Neural Network Verification](https://arxiv.org/abs/2512.11087)
*Duo Zhou,Jorge Chavez,Hesun Chen,Grani A. Hanasusanto,Huan Zhang*

Main category: cs.LG

TL;DR: 提出线性约束驱动的剪裁框架，通过有效利用线性约束减少分支定界中的子问题数量并提升边界紧致度，显著提升神经网络验证器的效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证器在处理复杂验证属性时，分支定界（BaB）过程与快速边界技术结合是关键，但仍有提升空间。需要更高效的方法来增强验证器的效能。

Method: 提出线性约束驱动的剪裁框架，开发两种新算法：1）利用线性约束减少已验证或与子问题无关的输入空间；2）直接改进网络中的中间边界。通过专门的GPU程序高效处理线性约束，无需昂贵的外部求解器。

Result: Clip-and-Verify在多个基准测试中持续收紧边界，分支定界子问题数量最多减少96%，在多个基准上达到最先进的验证准确率，成为VNN-COMP 2025获胜者α,β-CROWN验证器的一部分。

Conclusion: 线性约束驱动的剪裁框架为神经网络验证提供了可扩展且高效的方法，能显著提升验证效率，已在α,β-CROWN验证器中实现并取得优异性能。

Abstract: State-of-the-art neural network (NN) verifiers demonstrate that applying the branch-and-bound (BaB) procedure with fast bounding techniques plays a key role in tackling many challenging verification properties. In this work, we introduce the linear constraint-driven clipping framework, a class of scalable and efficient methods designed to enhance the efficacy of NN verifiers. Under this framework, we develop two novel algorithms that efficiently utilize linear constraints to 1) reduce portions of the input space that are either verified or irrelevant to a subproblem in the context of branch-and-bound, and 2) directly improve intermediate bounds throughout the network. The process novelly leverages linear constraints that often arise from bound propagation methods and is general enough to also incorporate constraints from other sources. It efficiently handles linear constraints using a specialized GPU procedure that can scale to large neural networks without the use of expensive external solvers. Our verification procedure, Clip-and-Verify, consistently tightens bounds across multiple benchmarks and can significantly reduce the number of subproblems handled during BaB. We show that our clipping algorithms can be integrated with BaB-based verifiers such as $α,β$-CROWN, utilizing either the split constraints in activation-space BaB or the output constraints that denote the unverified input space. We demonstrate the effectiveness of our procedure on a broad range of benchmarks where, in some instances, we witness a 96% reduction in the number of subproblems during branch-and-bound, and also achieve state-of-the-art verified accuracy across multiple benchmarks. Clip-and-Verify is part of the $α,β$-CROWN verifier (http://abcrown.org), the VNN-COMP 2025 winner. Code available at https://github.com/Verified-Intelligence/Clip_and_Verify.

</details>


### [68] [Investigating ECG Diagnosis with Ambiguous Labels using Partial Label Learning](https://arxiv.org/abs/2512.11095)
*Sana Rahmani,Javad Hashemi,Ali Etemad*

Main category: cs.LG

TL;DR: 本文首次系统研究部分标签学习(PLL)方法在心电图(ECG)诊断中的应用，评估了九种PLL算法在不同临床模糊性场景下的表现，发现现有方法对模糊类型的鲁棒性差异显著。


<details>
  <summary>Details</summary>
Motivation: 心电图诊断中存在固有的标签模糊性问题（如重叠病症和诊断分歧），但现有ECG模型都假设标签是干净无歧义的，这限制了模型在真实临床环境中的发展和评估。尽管部分标签学习(PLL)框架专门处理模糊标签，但其在医疗时间序列领域（特别是ECG）的应用尚未得到充分探索。

Method: 将九种PLL算法适配到多标签ECG诊断任务中，使用多种临床驱动的模糊性生成策略进行评估，包括非结构化（如随机）和结构化模糊性（如心脏病专家定义的相似性、治疗关系和诊断分类）。在PTB-XL和Chapman数据集上进行实验。

Result: 实验表明，不同PLL方法对各种类型和程度的模糊性表现出显著不同的鲁棒性。某些方法在某些模糊性场景下表现良好，但在其他场景下效果有限。

Conclusion: 研究揭示了当前PLL方法在临床环境中的关键局限性，并为开发鲁棒且符合临床需求的模糊性感知学习框架指明了未来方向，强调了需要针对ECG诊断特点设计专门的模糊性处理方法。

Abstract: Label ambiguity is an inherent problem in real-world electrocardiogram (ECG) diagnosis, arising from overlapping conditions and diagnostic disagreement. However, current ECG models are trained under the assumption of clean and non-ambiguous annotations, which limits both the development and the meaningful evaluation of models under real-world conditions. Although Partial Label Learning (PLL) frameworks are designed to learn from ambiguous labels, their effectiveness in medical time-series domains, ECG in particular, remains largely unexplored. In this work, we present the first systematic study of PLL methods for ECG diagnosis. We adapt nine PLL algorithms to multi-label ECG diagnosis and evaluate them using a diverse set of clinically motivated ambiguity generation strategies, capturing both unstructured (e.g., random) and structured ambiguities (e.g., cardiologist-derived similarities, treatment relationships, and diagnostic taxonomies). Our experiments on the PTB-XL and Chapman datasets demonstrate that PLL methods vary substantially in their robustness to different types and degrees of ambiguity. Through extensive analysis, we identify key limitations of current PLL approaches in clinical settings and outline future directions for developing robust and clinically aligned ambiguity-aware learning frameworks for ECG diagnosis.

</details>


### [69] [Limits and Gains of Test-Time Scaling in Vision-Language Reasoning](https://arxiv.org/abs/2512.11109)
*Mohammadjavad Ahmadpour,Amirmahdi Meighani,Payam Taebi,Omid Ghahroodi,Amirmohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.LG

TL;DR: 该论文系统研究了测试时扩展（TTS）在视觉语言模型（VLMs）中的应用效果，发现闭源模型能从结构化推理和迭代自优化中受益，而开源模型表现不一致，且TTS效果高度依赖数据集和任务类型。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展（TTS）在提升大语言模型推理能力方面已证明有效，但在多模态系统如视觉语言模型中的应用仍未被充分探索。研究者希望了解TTS方法在不同VLM上的适用性和效果差异。

Method: 对开源和闭源视觉语言模型进行系统性实证研究，在不同基准测试上应用推理时间推理方法，包括结构化推理、迭代自优化和外部验证等TTS技术。

Result: 闭源模型能一致地从结构化推理和迭代自优化中获益，而开源VLM表现不一致：外部验证提供最可靠的性能提升，迭代优化反而常降低性能。TTS效果高度数据集依赖，在多步推理任务上改善明显，但在感知为主的基准上增益有限。

Conclusion: TTS并非通用解决方案，必须根据模型能力和任务特性进行调整。这推动了未来自适应TTS策略和多模态奖励模型的研究方向。

Abstract: Test-time scaling (TTS) has emerged as a powerful paradigm for improving the reasoning ability of Large Language Models (LLMs) by allocating additional computation at inference, yet its application to multimodal systems such as Vision-Language Models (VLMs) remains underexplored. In this work, we present a systematic empirical study of inference time reasoning methods applied across both open-source and closed-source VLMs on different benchmarks. Our results reveal that while closed-source models consistently benefit from structured reasoning and iterative Self-Refinement, open-source VLMs show inconsistent behavior: external verification provides the most reliable gains, whereas iterative refinement often degrades performance. We further find that the effectiveness of TTS is dataset-dependent, yielding clear improvements on multi-step reasoning tasks but offering only limited gains on perception-focused benchmarks. These findings demonstrate that TTS is not a universal solution and must be tailored to both model capabilities and task characteristics, motivating future work on adaptive TTS strategies and multimodal reward models.

</details>


### [70] [In-Context Multi-Objective Optimization](https://arxiv.org/abs/2512.11114)
*Xinyu Zhang,Conor Hassan,Julien Martinelli,Daolang Huang,Samuel Kaski*

Main category: cs.LG

TL;DR: TAMO：基于Transformer的完全摊销式多目标黑盒优化策略，通过预训练实现跨问题迁移，无需每任务代理拟合和采集函数设计，大幅提升优化效率。


<details>
  <summary>Details</summary>
Motivation: 传统多目标贝叶斯优化需要针对每个问题定制代理模型和采集函数，难以跨问题迁移，且存在短视性、重拟合开销等问题，特别是在并行或时间敏感场景中效率低下。

Method: 使用Transformer架构构建通用优化策略，支持可变输入和目标维度，通过强化学习预训练最大化累积超体积改进，基于完整查询历史近似帕累托前沿，测试时单次前向传播即可生成新设计。

Result: 在合成基准和实际任务中，TAMO将提议时间减少50-1000倍，同时在有限评估预算下保持或提升帕累托前沿质量，实现了快速高效的优化。

Conclusion: Transformer能够在上下文中执行多目标优化，消除每任务代理拟合和采集工程，为科学发现工作流程开辟了基础模型式、即插即用优化器的新路径。

Abstract: Balancing competing objectives is omnipresent across disciplines, from drug design to autonomous systems. Multi-objective Bayesian optimization is a promising solution for such expensive, black-box problems: it fits probabilistic surrogates and selects new designs via an acquisition function that balances exploration and exploitation. In practice, it requires tailored choices of surrogate and acquisition that rarely transfer to the next problem, is myopic when multi-step planning is often required, and adds refitting overhead, particularly in parallel or time-sensitive loops. We present TAMO, a fully amortized, universal policy for multi-objective black-box optimization. TAMO uses a transformer architecture that operates across varying input and objective dimensions, enabling pretraining on diverse corpora and transfer to new problems without retraining: at test time, the pretrained model proposes the next design with a single forward pass. We pretrain the policy with reinforcement learning to maximize cumulative hypervolume improvement over full trajectories, conditioning on the entire query history to approximate the Pareto frontier. Across synthetic benchmarks and real tasks, TAMO produces fast proposals, reducing proposal time by 50-1000x versus alternatives while matching or improving Pareto quality under tight evaluation budgets. These results show that transformers can perform multi-objective optimization entirely in-context, eliminating per-task surrogate fitting and acquisition engineering, and open a path to foundation-style, plug-and-play optimizers for scientific discovery workflows.

</details>


### [71] [Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee](https://arxiv.org/abs/2512.11127)
*Kshitiz Khanal*

Main category: cs.LG

TL;DR: 提出结合物理信息图神经网络与连续流匹配的两阶段学习框架，用于快速求解直流最优潮流问题，在保证100%可行性的同时达到接近最优解的效果。


<details>
  <summary>Details</summary>
Motivation: 传统优化求解器计算成本高，难以满足大规模电力系统实时调度需求；现有机器学习方法在约束满足和成本最优性方面存在不足，需要一种既能快速求解又能保证约束满足和接近最优性的新方法。

Method: 两阶段学习框架：第一阶段使用物理信息图神经网络通过物理约束损失函数生成可行初始解；第二阶段采用连续流匹配技术，通过学习的向量场回归将初始解优化至接近最优。

Result: 在IEEE 30节点系统的5种负荷场景（70%-130%额定负荷）测试中，该方法在额定负荷下成本差距低于0.1%，极端条件下低于3%，同时保持100%可行性。

Conclusion: 该框架在快速神经网络预测与精确但缓慢的数值求解器之间架起桥梁，为高可再生能源渗透率、需要频繁调度更新的现代电力系统提供了实用解决方案。

Abstract: The DC Optimal Power Flow (DC-OPF) problem is fundamental to power system operations, requiring rapid solutions for real-time grid management. While traditional optimization solvers provide optimal solutions, their computational cost becomes prohibitive for large-scale systems requiring frequent recalculations. Machine learning approaches offer promise for acceleration but often struggle with constraint satisfaction and cost optimality. We present a novel two-stage learning framework that combines physics-informed Graph Neural Networks (GNNs) with Continuous Flow Matching (CFM) for solving DC-OPF problems. Our approach embeds fundamental physical principles--including economic dispatch optimality conditions, Kirchhoff's laws, and Karush-Kuhn-Tucker (KKT) complementarity conditions--directly into the training objectives. The first stage trains a GNN to produce feasible initial solutions by learning from physics-informed losses that encode power system constraints. The second stage employs CFM, a simulation-free continuous normalizing flow technique, to refine these solutions toward optimality through learned vector field regression. Evaluated on the IEEE 30-bus system across five load scenarios ranging from 70\% to 130\% nominal load, our method achieves near-optimal solutions with cost gaps below 0.1\% for nominal loads and below 3\% for extreme conditions, while maintaining 100\% feasibility. Our framework bridges the gap between fast but approximate neural network predictions and optimal but slow numerical solvers, offering a practical solution for modern power systems with high renewable penetration requiring frequent dispatch updates.

</details>


### [72] [Fairness-Regularized Online Optimization with Switching Costs](https://arxiv.org/abs/2512.11131)
*Pengfei Li,Yuelin Han,Adam Wierman,Shaolei Ren*

Main category: cs.LG

TL;DR: 论文提出FairOBD算法，在具有切换成本的公平正则化平滑在线凸优化中同时解决公平性和动作平滑性问题，通过分解长期公平成本为在线成本序列，实现与离线最优算法的竞争性保证。


<details>
  <summary>Details</summary>
Motivation: 现有在线优化问题中，公平性和动作平滑性这两个关键考虑因素尚未被同时解决。论文旨在研究具有切换成本的公平正则化平滑在线凸优化这一新挑战性场景。

Method: 提出FairOBD算法：1) 通过引入辅助变量将长期公平成本分解为在线成本序列；2) 利用辅助变量正则化在线动作以实现公平结果；3) 采用新方法处理切换成本。

Result: 理论证明：1) 即使没有切换成本，任何在线算法也无法实现相对于离线最优算法的次线性遗憾或有限竞争比；2) FairOBD针对参数化约束的最优离线算法基准，在最坏情况下提供渐近竞争比保证。实验验证：在动态计算资源供给的AI推理应用中，FairOBD能有效降低总公平正则化成本并更好地促进公平结果。

Conclusion: FairOBD算法成功解决了公平性和动作平滑性在在线优化中的协同挑战，通过创新的成本分解和正则化方法，在理论和实践中都表现出色，为社会责任AI推理等应用提供了有效解决方案。

Abstract: Fairness and action smoothness are two crucial considerations in many online optimization problems, but they have yet to be addressed simultaneously. In this paper, we study a new and challenging setting of fairness-regularized smoothed online convex optimization with switching costs. First, to highlight the fundamental challenges introduced by the long-term fairness regularizer evaluated based on the entire sequence of actions, we prove that even without switching costs, no online algorithms can possibly achieve a sublinear regret or finite competitive ratio compared to the offline optimal algorithm as the problem episode length $T$ increases. Then, we propose FairOBD (Fairness-regularized Online Balanced Descent), which reconciles the tension between minimizing the hitting cost, switching cost, and fairness cost. Concretely, FairOBD decomposes the long-term fairness cost into a sequence of online costs by introducing an auxiliary variable and then leverages the auxiliary variable to regularize the online actions for fair outcomes. Based on a new approach to account for switching costs, we prove that FairOBD offers a worst-case asymptotic competitive ratio against a novel benchmark -- the optimal offline algorithm with parameterized constraints -- by considering $T\to\infty$. Finally, we run trace-driven experiments of dynamic computing resource provisioning for socially responsible AI inference to empirically evaluate FairOBD, showing that FairOBD can effectively reduce the total fairness-regularized cost and better promote fair outcomes compared to existing baseline solutions.

</details>


### [73] [The Vekua Layer: Exact Physical Priors for Implicit Neural Representations via Generalized Analytic Functions](https://arxiv.org/abs/2512.11138)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: Vekua Layer (VL) 是一种基于广义解析函数理论的微分谱方法，通过将假设空间限制在控制微分算子的核中，将学习任务从非凸优化转化为严格凸的最小二乘问题，在椭圆PDE上实现了机器精度重建和优越的噪声稳定性。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）在参数化物理场方面表现出色，但存在谱偏差和非凸优化的计算开销问题。作者希望开发一种更高效、更稳定的替代方法。

Method: 提出Vekua Layer (VL)，这是一种基于广义解析函数理论的微分谱方法。通过将假设空间限制在控制微分算子（如调和函数和傅里叶-贝塞尔基）的核中，将学习任务从迭代梯度下降转化为严格凸的最小二乘问题，通过线性投影求解。

Result: 在齐次椭圆偏微分方程上，VL相比SIRENs实现了机器精度（MSE ≈ 10^-33）的精确重建，在非相干传感器噪声下表现出优越的稳定性（MSE ≈ 0.03），并能够从部分边界数据通过解析延拓实现"全息"外推。

Conclusion: VL提供了一种基于物理的谱滤波器，将学习任务转化为凸优化问题，在精度、稳定性和外推能力方面超越了传统的坐标基近似方法，为物理场参数化提供了更高效可靠的解决方案。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful paradigm for parameterizing physical fields, yet they often suffer from spectral bias and the computational expense of non-convex optimization. We introduce the Vekua Layer (VL), a differentiable spectral method grounded in the classical theory of Generalized Analytic Functions. By restricting the hypothesis space to the kernel of the governing differential operator -- specifically utilizing Harmonic and Fourier-Bessel bases -- the VL transforms the learning task from iterative gradient descent to a strictly convex least-squares problem solved via linear projection. We evaluate the VL against Sinusoidal Representation Networks (SIRENs) on homogeneous elliptic Partial Differential Equations (PDEs). Our results demonstrate that the VL achieves machine precision ($\text{MSE} \approx 10^{-33}$) on exact reconstruction tasks and exhibits superior stability in the presence of incoherent sensor noise ($\text{MSE} \approx 0.03$), effectively acting as a physics-informed spectral filter. Furthermore, we show that the VL enables "holographic" extrapolation of global fields from partial boundary data via analytic continuation, a capability absent in standard coordinate-based approximations.

</details>


### [74] [Autoencoder-based Semi-Supervised Dimensionality Reduction and Clustering for Scientific Ensembles](https://arxiv.org/abs/2512.11145)
*Lennard Manuel,Hamid Gadirov,Steffen Frey*

Main category: cs.LG

TL;DR: 提出一种结合聚类损失和对比损失的增强自编码器框架，用于高维科学集合数据的可视化分析，在土壤通道结构和液滴冲击动力学数据集上取得优于基线方法的效果。


<details>
  <summary>Details</summary>
Motivation: 高维复杂的科学集合数据给分析和可视化带来挑战，传统降维技术和自编码器难以有效处理此类数据，需要改进方法来提取特征并提升可视化效果。

Method: 使用EfficientNetV2为无标签数据生成伪标签，构建增强自编码器框架，联合优化重构损失、基于软轮廓分数的聚类损失和对比损失，促使相似数据点聚集而不同簇分离，最后用UMAP生成2D投影。

Result: 在土壤通道结构（MCMC生成）和液滴冲击动力学两个科学集合数据集上，结合聚类或对比损失的模型在轮廓分数评估中略优于基线方法，能提取更有意义的特征。

Conclusion: 提出的增强自编码器框架通过整合聚类和对比学习，能有效改善高维科学集合数据的可视化效果和可解释性，为复杂科学数据的分析提供了新方法。

Abstract: Analyzing and visualizing scientific ensemble datasets with high dimensionality and complexity poses significant challenges. Dimensionality reduction techniques and autoencoders are powerful tools for extracting features, but they often struggle with such high-dimensional data. This paper presents an enhanced autoencoder framework that incorporates a clustering loss, based on the soft silhouette score, alongside a contrastive loss to improve the visualization and interpretability of ensemble datasets. First, EfficientNetV2 is used to generate pseudo-labels for the unlabeled portions of the scientific ensemble datasets. By jointly optimizing the reconstruction, clustering, and contrastive objectives, our method encourages similar data points to group together while separating distinct clusters in the latent space. UMAP is subsequently applied to this latent representation to produce 2D projections, which are evaluated using the silhouette score. Multiple types of autoencoders are evaluated and compared based on their ability to extract meaningful features. Experiments on two scientific ensemble datasets - channel structures in soil derived from Markov chain Monte Carlo, and droplet-on-film impact dynamics - show that models incorporating clustering or contrastive loss marginally outperform the baseline approaches.

</details>


### [75] [Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities](https://arxiv.org/abs/2512.11178)
*Takuya Kurihana,Xiaojian Zhang,Wing Yee Au,Hon Yung Wong*

Main category: cs.LG

TL;DR: 提出一个异构数据管道，用于融合时空变化的城市多模态数据，解决跨领域城市问题，具有强泛化能力和最小化重新配置需求。


<details>
  <summary>Details</summary>
Motivation: 城市数据存在异构格式、独立收集、标准不一的问题，尽管国家级数据集丰富但存在显著异质性和多模态性，需要解决智能城市分析中的跨领域数据融合挑战。

Method: 提出异构数据管道，执行跨领域数据融合，处理时空变化和时空序列数据集。数据学习模块将空间变化数据集中的同质性整合到图学习中，将不同地区的信息嵌入模型。

Result: 使用来自多个城市的50多个数据源（如网约车、交通事故、犯罪报告），在五个真实世界观察中展示了框架的泛化性和灵活性，表现出强预测性能，且迁移到新地区或领域时只需最小重新配置。

Conclusion: 该研究推进了以可扩展方式构建数据驱动的城市系统的目标，解决了智能城市分析中最紧迫的挑战之一。

Abstract: Modern cities are increasingly reliant on data-driven insights to support decision making in areas such as transportation, public safety and environmental impact. However, city-level data often exists in heterogeneous formats, collected independently by local agencies with diverse objectives and standards. Despite their numerous, wide-ranging, and uniformly consumable nature, national-level datasets exhibit significant heterogeneity and multi-modality. This research proposes a heterogeneous data pipeline that performs cross-domain data fusion over time-varying, spatial-varying and spatial-varying time-series datasets. We aim to address complex urban problems across multiple domains and localities by harnessing the rich information over 50 data sources. Specifically, our data-learning module integrates homophily from spatial-varying dataset into graph-learning, embedding information of various localities into models. We demonstrate the generalizability and flexibility of the framework through five real-world observations using a variety of publicly accessible datasets (e.g., ride-share, traffic crash, and crime reports) collected from multiple cities. The results show that our proposed framework demonstrates strong predictive performance while requiring minimal reconfiguration when transferred to new localities or domains. This research advances the goal of building data-informed urban systems in a scalable way, addressing one of the most pressing challenges in smart city analytics.

</details>


### [76] [Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning](https://arxiv.org/abs/2512.11179)
*Wei Duan,Jie Lu,En Yu,Junyu Xuan*

Main category: cs.LG

TL;DR: 提出BVME方法，在带宽受限的多智能体强化学习中通过变分消息编码实现高效通信，在保持性能的同时大幅减少消息维度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的MARL方法虽然能学习稀疏协调图（决定谁与谁通信），但未解决在硬带宽约束下应该传输什么信息的问题。简单的维度降维方法会持续降低协调性能。

Method: 提出带宽受限变分消息编码（BVME），将消息视为从学习的后验分布中采样，通过KL散度正则化到无信息先验。该变分框架通过可解释的超参数提供对压缩强度的原则性控制。

Result: 在SMACv1、SMACv2和MPE基准测试中，BVME在使用67-83%更少消息维度的同时，实现了相当或更优的性能。在稀疏图上增益最明显，其中消息质量对协调影响关键。

Conclusion: BVME为带宽受限的MARL提供了一种轻量级解决方案，通过变分编码实现高效通信，在极端带宽比下表现优异，同时增加的开销最小。

Abstract: Graph-based multi-agent reinforcement learning (MARL) enables coordinated behavior under partial observability by modeling agents as nodes and communication links as edges. While recent methods excel at learning sparse coordination graphs-determining who communicates with whom-they do not address what information should be transmitted under hard bandwidth constraints. We study this bandwidth-limited regime and show that naive dimensionality reduction consistently degrades coordination performance. Hard bandwidth constraints force selective encoding, but deterministic projections lack mechanisms to control how compression occurs. We introduce Bandwidth-constrained Variational Message Encoding (BVME), a lightweight module that treats messages as samples from learned Gaussian posteriors regularized via KL divergence to an uninformative prior. BVME's variational framework provides principled, tunable control over compression strength through interpretable hyperparameters, directly constraining the representations used for decision-making. Across SMACv1, SMACv2, and MPE benchmarks, BVME achieves comparable or superior performance while using 67--83% fewer message dimensions, with gains most pronounced on sparse graphs where message quality critically impacts coordination. Ablations reveal U-shaped sensitivity to bandwidth, with BVME excelling at extreme ratios while adding minimal overhead.

</details>


### [77] [Progress over Points: Reframing LM Benchmarks Around Scientific Objectives](https://arxiv.org/abs/2512.11183)
*Alwin Jin,Sean M. Hendryx,Vaskar Nath*

Main category: cs.LG

TL;DR: 该论文提出"进展导向基准测试"新范式，用NanoGPT速度挑战作为实例，将基准测试从静态问题排行榜转变为可测量的开放式科学研究平台。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试主要关注静态、已解决的问题（如数学应用题），这种方法限制了可衡量和激励的进步类型。需要一种能真正推动科学进展的基准测试范式。

Method: 创建基于NanoGPT速度挑战的进展导向环境：标准化数据集切片、参考模型和训练工具、丰富遥测数据，包含运行时验证和防作弊检查。评估聚焦于科学增量：最佳损失值和效率前沿。

Result: 在该环境中实现了新的最先进训练时间，比之前记录快3秒，并定性观察到新颖算法思想的涌现。模型和代理之间的比较仍然可能，但只是手段而非目的。

Conclusion: 基准测试应成为科学进展的载体，而非仅仅是性能排行榜。通过这一发布，旨在推动社区从静态问题排行榜转向可测量的开放式科学研究，使基准测试进步等同于科学进步。

Abstract: Current benchmarks that test LLMs on static, already-solved problems (e.g., math word problems) effectively demonstrated basic capability acquisition. The natural progression has been toward larger, more comprehensive and challenging collections of static problems, an approach that inadvertently constrains the kinds of advances we can measure and incentivize. To address this limitation, we argue for progress-oriented benchmarks, problem environments whose objectives are themselves the core targets of scientific progress, so that achieving state of the art on the benchmark advances the field. As a introductory step, we instantiate an environment based on the NanoGPT speedrun. The environment standardizes a dataset slice, a reference model and training harness, and rich telemetry, with run-time verification and anti-gaming checks. Evaluation centers on the scientific delta achieved: best-attained loss and the efficiency frontier. Using this environment, we achieve a new state-of-the-art training time, improving upon the previous record by 3 seconds, and qualitatively observe the emergence of novel algorithmic ideas. Moreover, comparisons between models and agents remain possible, but they are a means, not the end; the benchmark's purpose is to catalyze reusable improvements to the language modeling stack. With this release, the overarching goal is to seed a community shift from static problem leaderboards to test-time research on open-ended yet measurable scientific problems. In this new paradigm, progress on the benchmark is progress on the science, thus reframing "benchmarking" as a vehicle for scientific advancement.

</details>


### [78] [On the failure of ReLU activation for physics-informed machine learning](https://arxiv.org/abs/2512.11184)
*Conor Rowan*

Main category: cs.LG

TL;DR: 本文分析了ReLU激活函数在物理信息机器学习中表现不佳的原因，发现自动微分无法正确处理不连续场的导数，导致梯度计算错误。


<details>
  <summary>Details</summary>
Motivation: 物理信息机器学习使用控制微分方程训练神经网络，激活函数的选择影响性能。多项研究表明ReLU在基准微分方程问题上表现不如sigmoid、tanh和swish等激活函数，本文旨在诊断ReLU表现不佳的根本原因。

Method: 通过分析ReLU的分段线性特性及其在自动微分中的行为，研究其在物理信息机器学习训练过程中的二阶导数问题。特别关注PyTorch自动微分对不连续场导数的处理方式。

Result: 发现ReLU失败的原因不是二阶微分方程的直接要求，而是训练过程中自动微分无法正确表征不连续场的导数，导致物理信息损失的梯度计算错误，即使在仅涉及一阶导数的变分问题中也会失败。

Conclusion: ReLU在物理信息机器学习中表现不佳的根本原因是自动微分系统无法正确处理其不连续特性，导致梯度计算错误。这解释了为什么即使在一阶导数问题中ReLU也会失败，为激活函数选择提供了重要见解。

Abstract: Physics-informed machine learning uses governing ordinary and/or partial differential equations to train neural networks to represent the solution field. Like any machine learning problem, the choice of activation function influences the characteristics and performance of the solution obtained from physics-informed training. Several studies have compared common activation functions on benchmark differential equations, and have unanimously found that the rectified linear unit (ReLU) is outperformed by competitors such as the sigmoid, hyperbolic tangent, and swish activation functions. In this work, we diagnose the poor performance of ReLU on physics-informed machine learning problems. While it is well-known that the piecewise linear form of ReLU prevents it from being used on second-order differential equations, we show that ReLU fails even on variational problems involving only first derivatives. We identify the cause of this failure as second derivatives of the activation, which are taken not in the formulation of the loss, but in the process of training. Namely, we show that automatic differentiation in PyTorch fails to characterize derivatives of discontinuous fields, which causes the gradient of the physics-informed loss to be mis-specified, thus explaining the poor performance of ReLU.

</details>


### [79] [Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models](https://arxiv.org/abs/2512.11194)
*Divya Kothandaraman,Jaclyn Pytlarz*

Main category: cs.LG

TL;DR: 提出梯度投影框架，在扩散模型训练中通过正交投影消除敏感概念特征的梯度影响，实现概念级别的选择性遗忘，减少记忆化风险同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 大规模文生图扩散模型的记忆化带来安全和知识产权风险，传统方法（正则化、数据过滤）只能防止对具体训练样本的过拟合，无法系统性地阻止概念级别敏感特征的内化。直接丢弃包含敏感特征的所有图像会浪费宝贵训练数据，需要概念级别的选择性遗忘方法。

Method: 提出梯度投影框架：在反向传播过程中，识别与禁止属性嵌入对齐的训练信号并将其切除。具体将每个梯度更新投影到敏感特征嵌入空间的正交补空间上，从而消除其对模型权重的影响。该方法可无缝集成到标准扩散模型训练流程中，并与现有防御方法互补。

Result: 在广泛实验中，该框架显著减少了记忆化，同时严格保持了生成质量和语义保真度。通过将记忆化控制重新定义为选择性学习，为IP安全和隐私保护的生成式AI建立了新范式。

Conclusion: 梯度投影框架通过概念级别的选择性遗忘，有效解决了扩散模型中的记忆化问题，在保护知识产权和隐私的同时，充分利用了训练数据，为生成式AI的安全部署提供了新方法。

Abstract: Memorization in large-scale text-to-image diffusion models poses significant security and intellectual property risks, enabling adversarial attribute extraction and the unauthorized reproduction of sensitive or proprietary features. While conventional dememorization techniques, such as regularization and data filtering, limit overfitting to specific training examples, they fail to systematically prevent the internalization of prohibited concept-level features. Simply discarding all images containing a sensitive feature wastes invaluable training data, necessitating a method for selective unlearning at the concept level.
  To address this, we introduce a Gradient Projection Framework designed to enforce a stringent requirement of concept-level feature exclusion. Our defense operates during backpropagation by systematically identifying and excising training signals aligned with embeddings of prohibited attributes. Specifically, we project each gradient update onto the orthogonal complement of the sensitive feature's embedding space, thereby zeroing out its influence on the model's weights. Our method integrates seamlessly into standard diffusion model training pipelines and complements existing defenses. We analyze our method against an adversary aiming for feature extraction. In extensive experiments, we demonstrate that our framework drastically reduces memorization while rigorously preserving generation quality and semantic fidelity. By reframing memorization control as selective learning, our approach establishes a new paradigm for IP-safe and privacy-preserving generative AI.

</details>


### [80] [Fast EXP3 Algorithms](https://arxiv.org/abs/2512.11201)
*Ryoma Sato,Shinji Ito*

Main category: cs.LG

TL;DR: EXP3算法可实现每轮常数时间运行，作者提出更实用的算法并分析遗憾界与时间复杂度的权衡


<details>
  <summary>Details</summary>
Motivation: EXP3算法作为多臂赌博机问题的经典算法，其实践中的时间效率有待改进。作者旨在设计更实用的算法版本，在保持理论保证的同时提升计算效率。

Method: 作者指出EXP3算法可以优化为每轮常数时间实现，并提出了多个更实用的算法变体，这些算法在计算复杂度和遗憾界之间进行权衡设计。

Result: 展示了EXP3算法可以实现常数时间每轮运行，提出了多个具有不同时间复杂度和遗憾保证的实用算法，系统分析了这些算法在计算效率与理论性能之间的权衡关系。

Conclusion: EXP3算法的时间复杂度可以显著优化，通过算法设计可以在计算效率和遗憾界之间找到合适的平衡点，为实际应用提供更实用的多臂赌博机算法。

Abstract: We point out that EXP3 can be implemented in constant time per round, propose more practical algorithms, and analyze the trade-offs between the regret bounds and time complexities of these algorithms.

</details>


### [81] [Latent Variable Causal Discovery under Selection Bias](https://arxiv.org/abs/2512.11219)
*Haoyue Dai,Yiwen Qiu,Ignavier Ng,Xinshuai Dong,Peter Spirtes,Kun Zhang*

Main category: cs.LG

TL;DR: 提出利用秩约束处理线性高斯模型中潜变量因果发现的样本选择偏差问题，证明即使在选择偏差下协方差子矩阵的秩仍能保留因果结构和选择机制的信息


<details>
  <summary>Details</summary>
Motivation: 潜变量因果发现中的选择偏差问题尚未得到充分研究，主要是因为缺乏合适的统计工具。现有处理潜变量的方法大多基于条件独立性，但未针对选择偏差进行适配

Method: 研究秩约束作为条件独立性约束的推广，利用线性高斯模型中协方差子矩阵的秩。提供秩约束的图论特征化，并证明单因子模型在选择偏差下可识别

Result: 证明即使存在选择偏差，有偏协方差矩阵中的秩仍能保留因果结构和选择机制的有意义信息。通过图论特征化和实验验证了秩约束的有效性

Conclusion: 秩约束为处理潜变量因果发现中的选择偏差问题提供了有效的统计工具，单因子模型在选择偏差下可识别，为这一重要但未充分探索的问题提供了解决方案

Abstract: Addressing selection bias in latent variable causal discovery is important yet underexplored, largely due to a lack of suitable statistical tools: While various tools beyond basic conditional independencies have been developed to handle latent variables, none have been adapted for selection bias. We make an attempt by studying rank constraints, which, as a generalization to conditional independence constraints, exploits the ranks of covariance submatrices in linear Gaussian models. We show that although selection can significantly complicate the joint distribution, interestingly, the ranks in the biased covariance matrices still preserve meaningful information about both causal structures and selection mechanisms. We provide a graph-theoretic characterization of such rank constraints. Using this tool, we demonstrate that the one-factor model, a classical latent variable model, can be identified under selection bias. Simulations and real-world experiments confirm the effectiveness of using our rank constraints.

</details>


### [82] [Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference](https://arxiv.org/abs/2512.11221)
*Adilet Metinov,Gulida M. Kudakeeva,Bolotbek uulu Nursultan,Gulnara D. Kabaeva*

Main category: cs.LG

TL;DR: 提出ASR-KF-EGR框架，通过可逆软冻结机制在推理时动态管理KV缓存，无需训练即可减少55-67%的活跃KV缓存大小，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长上下文生成中的内存瓶颈问题，传统方法如KV缓存逐出会永久丢弃上下文信息，需要一种能保留所有令牌信息但更高效管理内存的方法。

Method: 采用自适应软滚动KV冻结与熵引导恢复机制：1) 在滑动注意力窗口内识别低重要性令牌；2) 可逆软冻结机制暂时暂停这些令牌的KV更新；3) 所有令牌保存在GPU外存储，按需恢复；4) 引入亚线性冻结调度，冻结时长随重复检测次数亚线性增长。

Result: 在LLaMA-3 8B上的初步实验显示：活跃KV缓存大小减少55-67%，同时保持生成质量，通过"大海捞针"检索测试，方法无需微调且架构无关。

Conclusion: ASR-KF-EGR为内存受限的长上下文LLM部署提供了实用解决方案，通过可逆软冻结机制在保持所有上下文信息的同时显著减少内存使用，无需训练即可实现高效推理。

Abstract: We present Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery (ASR-KF-EGR), a training-free inference-time framework for efficient large language model generation. Our method introduces a reversible soft-freeze mechanism that temporarily suspends key-value (KV) updates for low-importance tokens identified within a sliding attention window. Unlike eviction-based approaches that permanently discard context, ASR-KF-EGR preserves all tokens in off-GPU storage and restores them on demand. We extend the framework with sublinear freeze scheduling, where freeze duration grows sublinearly with repeated low-importance detections, preventing over-aggressive compression. Preliminary experiments on LLaMA-3 8B demonstrate 55-67% reduction in active KV cache size while maintaining generation quality and passing needle-in-haystack retrieval tests. The method is architecture-agnostic, requires no fine-tuning, and provides a practical solution for memory-constrained deployment of long-context LLMs.

</details>


### [83] [Task-Aware Multi-Expert Architecture For Lifelong Deep Learning](https://arxiv.org/abs/2512.11243)
*Jianyu Wang,Jacob Nean-Hua Sheikh,Cat P. Le,Hoda Bidkhori*

Main category: cs.LG

TL;DR: TAME是一种终身学习算法，通过任务相似性指导专家选择和知识转移，使用多专家池、共享密集层、回放缓冲区和注意力机制来平衡新任务适应和旧任务知识保留。


<details>
  <summary>Details</summary>
Motivation: 终身深度学习需要在连续学习多个任务时保持先前知识，同时适应新任务，这面临灾难性遗忘的挑战。需要一种能够灵活适应新任务同时保留重要历史知识的算法。

Method: TAME算法包含四个核心组件：1）任务感知多专家池，根据任务相似性激活最相关专家；2）共享密集层整合选定专家特征进行预测；3）回放缓冲区存储先前任务的代表性样本和嵌入；4）注意力机制优先处理最相关的存储信息。

Result: 在基于CIFAR-100的二分类任务实验中，TAME在提高新任务准确率的同时，保持了先前任务的性能表现，有效平衡了适应性和知识保留。

Conclusion: TAME通过任务相似性指导的专家选择和知识转移机制，结合回放和注意力技术，在终身学习场景中有效平衡了适应新任务和保留旧知识的需求，展示了在演化任务序列中的灵活性。

Abstract: Lifelong deep learning (LDL) trains neural networks to learn sequentially across tasks while preserving prior knowledge. We propose Task-Aware Multi-Expert (TAME), a continual learning algorithm that leverages task similarity to guide expert selection and knowledge transfer. TAME maintains a pool of pretrained neural networks and activates the most relevant expert for each new task. A shared dense layer integrates features from the chosen expert to generate predictions. To reduce catastrophic forgetting, TAME uses a replay buffer that stores representative samples and embeddings from previous tasks and reuses them during training. An attention mechanism further prioritizes the most relevant stored information for each prediction. Together, these components allow TAME to adapt flexibly while retaining important knowledge across evolving task sequences. Experiments on binary classification tasks derived from CIFAR-100 show that TAME improves accuracy on new tasks while sustaining performance on earlier ones, highlighting its effectiveness in balancing adaptation and retention in lifelong learning settings.

</details>


### [84] [Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language](https://arxiv.org/abs/2512.11251)
*Yunkai Zhang,Yawen Zhang,Ming Zheng,Kezhen Chen,Chongyang Gao,Ruian Ge,Siyuan Teng,Amine Jelloul,Jinmeng Rao,Xiaoyuan Guo,Chiang-Wei Fang,Zeyu Zheng,Jie Yang*

Main category: cs.LG

TL;DR: Insight Miner是一个多模态大模型，能够生成高质量的时间序列描述和洞察，通过新的TS-Insights数据集和智能工作流程，在时间序列描述任务上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在多个领域都很重要，但从中挖掘洞察需要深厚的领域专业知识，这个过程耗时耗力。需要让大模型能够理解时间序列数据并生成有价值的描述。

Method: 提出了Insight Miner多模态模型，并创建了TS-Insights数据集（包含100k个时间序列窗口）。使用智能工作流程：先用统计工具提取原始时间序列特征，然后用GPT-4合成连贯的趋势描述。在TS-Insights上进行指令调优。

Result: Insight Miner在生成时间序列描述和洞察方面超越了LLaVA和GPT-4等最先进的多模态模型，展示了LMM在时间序列分析中的潜力。

Conclusion: 这项工作为利用多模态大模型进行时间序列分析提供了有前景的方向，是让LLM将时间序列作为原生输入模态的基础性步骤。

Abstract: Time-series data is critical across many scientific and industrial domains, including environmental analysis, agriculture, transportation, and finance. However, mining insights from this data typically requires deep domain expertise, a process that is both time-consuming and labor-intensive. In this paper, we propose \textbf{Insight Miner}, a large-scale multimodal model (LMM) designed to generate high-quality, comprehensive time-series descriptions enriched with domain-specific knowledge. To facilitate this, we introduce \textbf{TS-Insights}\footnote{Available at \href{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}.}, the first general-domain dataset for time series and language alignment. TS-Insights contains 100k time-series windows sampled from 20 forecasting datasets. We construct this dataset using a novel \textbf{agentic workflow}, where we use statistical tools to extract features from raw time series before synthesizing them into coherent trend descriptions with GPT-4. Following instruction tuning on TS-Insights, Insight Miner outperforms state-of-the-art multimodal models, such as LLaVA \citep{liu2023llava} and GPT-4, in generating time-series descriptions and insights. Our findings suggest a promising direction for leveraging LMMs in time series analysis, and serve as a foundational step toward enabling LLMs to interpret time series as a native input modality.

</details>


### [85] [A Simple Generalisation of the Implicit Dynamics of In-Context Learning](https://arxiv.org/abs/2512.11255)
*Francesco Innocenti,El Mehdi Achour*

Main category: cs.LG

TL;DR: 该论文将Dherin等人(2025)关于transformer隐式权重更新的理论扩展到更一般的场景：所有序列位置、任意transformer块、包含层归一化的残差块，并通过线性回归任务验证理论。


<details>
  <summary>Details</summary>
Motivation: 现有ICL理论多基于简化模型，Dherin等人(2025)发现transformer块能隐式更新前馈网络权重，但该理论局限于最后位置、第一个块和简化结构。本文旨在将该理论推广到更接近实际模型的场景。

Method: 提出Dherin理论的一般化扩展：(1)扩展到所有序列位置而不仅是最后位置；(2)扩展到任意transformer块而不仅是第一个块；(3)扩展到包含层归一化的更真实残差块。在简单上下文线性回归任务上进行实证验证。

Result: 成功将隐式权重更新理论扩展到更一般的transformer架构，实证验证了理论在不同token和块之间的关系，使理论更接近实际应用。

Conclusion: 该研究将ICL隐式权重更新理论扩展到更接近实际transformer模型的场景，为在大规模模型上验证该理论奠定了基础，推动了ICL机制的理论理解。

Abstract: In-context learning (ICL) refers to the ability of a model to learn new tasks from examples in its input without any parameter updates. In contrast to previous theories of ICL relying on toy models and data settings, recently it has been shown that an abstraction of a transformer block can be seen as implicitly updating the weights of its feedforward network according to the context (Dherin et al., 2025). Here, we provide a simple generalisation of this result for (i) all sequence positions beyond the last, (ii) any transformer block beyond the first, and (iii) more realistic residual blocks including layer normalisation. We empirically verify our theory on simple in-context linear regression tasks and investigate the relationship between the implicit updates related to different tokens within and between blocks. These results help to bring the theory of Dherin et al. (2025) even closer to practice, with potential for validation on large-scale models.

</details>


### [86] [Features Emerge as Discrete States: The First Application of SAEs to 3D Representations](https://arxiv.org/abs/2512.11263)
*Albert Miao,Chenliang Zhou,Jiawei Zhou,Cengiz Oztireli*

Main category: cs.LG

TL;DR: 首次将稀疏自编码器应用于3D领域，分析3D重建VAE的特征，发现模型编码离散而非连续特征，通过状态转换框架解释多个反直觉行为。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在文本领域表现优异，但很少应用于3D领域，限制了特征分解的理论探索。本研究旨在将SAE应用于3D重建模型，分析其特征表示。

Method: 将SAE应用于最先进的3D重建VAE模型，分析来自Objaverse数据集的53k个3D模型。通过状态转换框架分析特征激活行为。

Result: 发现模型编码离散特征而非连续特征，表现出类似相变的特征激活转换。解释了三个反直觉行为：模型偏好位置编码表示、特征消融的重建损失呈现S型曲线、相变点分布呈现双峰性。

Conclusion: 该工作不仅解释了特征分解中的意外现象，还提供了理解模型特征学习动态的框架。发现模型通过重新分配叠加干扰来优先处理不同特征的显著性。

Abstract: Sparse Autoencoders (SAEs) are a powerful dictionary learning technique for decomposing neural network activations, translating the hidden state into human ideas with high semantic value despite no external intervention or guidance. However, this technique has rarely been applied outside of the textual domain, limiting theoretical explorations of feature decomposition. We present the \textbf{first application of SAEs to the 3D domain}, analyzing the features used by a state-of-the-art 3D reconstruction VAE applied to 53k 3D models from the Objaverse dataset. We observe that the network encodes discrete rather than continuous features, leading to our key finding: \textbf{such models approximate a discrete state space, driven by phase-like transitions from feature activations}. Through this state transition framework, we address three otherwise unintuitive behaviors -- the inclination of the reconstruction model towards positional encoding representations, the sigmoidal behavior of reconstruction loss from feature ablation, and the bimodality in the distribution of phase transition points. This final observation suggests the model \textbf{redistributes the interference caused by superposition to prioritize the saliency of different features}. Our work not only compiles and explains unexpected phenomena regarding feature decomposition, but also provides a framework to explain the model's feature learning dynamics. The code and dataset of encoded 3D objects will be available on release.

</details>


### [87] [SRLR: Symbolic Regression based Logic Recovery to Counter Programmable Logic Controller Attacks](https://arxiv.org/abs/2512.11298)
*Hao Zhou,Suman Sourav,Binbin Chen,Ke Yu*

Main category: cs.LG

TL;DR: SRLR：基于符号回归的逻辑恢复方案，用于从PLC输入输出中识别控制逻辑，生成可解释规则检测控制器逻辑攻击，在ICS环境中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PLC作为工业控制系统关键组件易受网络攻击，现有检测方法存在局限：基于规范的方法需要专家手动工作或访问源代码，机器学习方法缺乏决策解释性。

Method: 设计SRLR方案，利用ICS特定属性增强深度符号回归方法：1) 部分控制逻辑在频域表示更佳；2) 控制器多模式运行且切换不频繁；3) 控制器过滤异常输入；4) 降低公式复杂度实现有效搜索。

Result: SRLR在各种ICS设置中始终优于现有方法，恢复准确率在某些挑战性环境中可提高39%，在包含数百个电压调节器的配电网上验证了其处理大规模复杂系统的稳定性。

Conclusion: SRLR通过结合ICS特定属性增强符号回归，能够从PLC输入输出中有效恢复控制逻辑，生成可解释的攻击检测规则，为工业控制系统安全提供了实用解决方案。

Abstract: Programmable Logic Controllers (PLCs) are critical components in Industrial Control Systems (ICSs). Their potential exposure to external world makes them susceptible to cyber-attacks. Existing detection methods against controller logic attacks use either specification-based or learnt models. However, specification-based models require experts' manual efforts or access to PLC's source code, while machine learning-based models often fall short of providing explanation for their decisions. We design SRLR -- a it Symbolic Regression based Logic Recovery} solution to identify the logic of a PLC based only on its inputs and outputs. The recovered logic is used to generate explainable rules for detecting controller logic attacks. SRLR enhances the latest deep symbolic regression methods using the following ICS-specific properties: (1) some important ICS control logic is best represented in frequency domain rather than time domain; (2) an ICS controller can operate in multiple modes, each using different logic, where mode switches usually do not happen frequently; (3) a robust controller usually filters out outlier inputs as ICS sensor data can be noisy; and (4) with the above factors captured, the degree of complexity of the formulas is reduced, making effective search possible. Thanks to these enhancements, SRLR consistently outperforms all existing methods in a variety of ICS settings that we evaluate. In terms of the recovery accuracy, SRLR's gain can be as high as 39% in some challenging environment. We also evaluate SRLR on a distribution grid containing hundreds of voltage regulators, demonstrating its stability in handling large-scale, complex systems with varied configurations.

</details>


### [88] [QGEC : Quantum Golay Code Error Correction](https://arxiv.org/abs/2512.11307)
*Hideo Mukai,Hoshitaro Ohnishi*

Main category: cs.LG

TL;DR: 提出基于Golay码的量子纠错方法QGEC，使用Transformer进行解码计算，在多种噪声模型下评估性能，发现Golay码比toric码在更少数据量子位下获得更高解码精度。


<details>
  <summary>Details</summary>
Motivation: 量子计算机在特定问题上相比经典计算机有计算负载优势，但量子比特易受外部噪声影响。量子纠错对处理量子比特至关重要，需要从稳定子生成器的综合征测量结果预测实际错误，而不是直接测量数据量子比特。

Method: 提出QGEC方法，使用经典信息论中的高效编码方法Golay码进行量子纠错。使用Transformer进行解码计算，在由生成多项式定义的码空间中评估解码器精度，采用三种不同权重集和三种具有不同比特翻转错误和相位翻转错误相关性的噪声模型。

Result: 较小相关性的噪声模型给出更好的精度，生成多项式的权重对解码器精度影响不大。Golay码（需要23个数据量子位，码距为7）比toric码（需要50个数据量子位，码距为5）获得更高的解码精度。

Conclusion: 使用Transformer实现量子纠错可能使Golay码更高效地实现容错量子计算，因为Golay码在更少量子位资源下表现出更好的纠错性能。

Abstract: Quantum computers have the possibility of a much reduced calculation load compared with classical computers in specific problems. Quantum error correction (QEC) is vital for handling qubits, which are vulnerable to external noise. In QEC, actual errors are predicted from the results of syndrome measurements by stabilizer generators, in place of making direct measurements of the data qubits. Here, we propose Quantum Golay code Error Correction (QGEC), a QEC method using Golay code, which is an efficient coding method in classical information theory. We investigated our method's ability in decoding calculations with the Transformer. We evaluated the accuracy of the decoder in a code space defined by the generative polynomials with three different weights sets and three noise models with different correlations of bit-flip error and phase-flip error. Furthermore, under a noise model following a discrete uniform distribution, we compared the decoding performance of Transformer decoders with identical architectures trained respectively on Golay and toric codes. The results showed that the noise model with the smaller correlation gave better accuracy, while the weights of the generative polynomials had little effect on the accuracy of the decoder. In addition, they showed that Golay code requiring 23 data qubits and having a code distance of 7 achieved higher decoding accuracy than toric code which requiring 50 data qubits and having a code distance of 5. This suggests that implementing quantum error correction using a Transformer may enable the Golay code to realize fault-tolerant quantum computation more efficiently.

</details>


### [89] [Benchmarking the Generality of Vision-Language-Action Models](https://arxiv.org/abs/2512.11315)
*Pranav Guruprasad,Sudipta Chowdhury,Harsh Sikka,Mridul Sharma,Helen Lu,Sean Rivera,Aryan Khurana,Hangliang Ren,Yangyue Wang*

Main category: cs.LG

TL;DR: MultiNet v1.0是一个统一基准测试，用于评估视觉语言模型和视觉语言动作模型在六个核心能力领域的跨领域泛化能力，发现当前模型在未见领域存在显著性能下降。


<details>
  <summary>Details</summary>
Motivation: 当前多模态智能体评估分散在孤立基准中，难以判断基础模型是否真正超越了训练分布实现泛化。需要统一基准来评估模型的跨领域通用性。

Method: 引入MultiNet v1.0基准，涵盖视觉基础、空间推理、工具使用、物理常识、多智能体协调和连续机器人控制六个能力领域，用于评估GPT-5、Pi0和Magma等模型的跨领域泛化能力。

Result: 所有评估模型都未表现出一致的泛化能力，在未见领域、不熟悉模态或跨领域任务转换时性能显著下降，表现出模态不对齐、输出格式不稳定和领域转移下的灾难性知识退化。

Conclusion: 当前基础模型的实际能力与通用智能的期望之间存在持续差距。MultiNet v1.0为诊断这些差距和指导未来通用智能体开发提供了标准化评估基础。

Abstract: Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.

</details>


### [90] [Condensation-Concatenation Framework for Dynamic Graph Continual Learning](https://arxiv.org/abs/2512.11317)
*Tingxu Yan,Ye Yuan*

Main category: cs.LG

TL;DR: 提出CCC框架解决动态图中GNN的灾难性遗忘问题，通过压缩历史图快照为语义表示并与当前图表示选择性拼接，改进遗忘度量以适应动态图场景。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的动态图结构持续变化会导致图神经网络出现灾难性遗忘。现有动态图持续学习方法忽略了拓扑变化对现有节点的影响。

Method: 提出CCC框架：1) 将历史图快照压缩为紧凑的语义表示，保持原始标签分布和拓扑特性；2) 选择性拼接历史嵌入与当前图表示；3) 改进遗忘度量(FM)以量化结构更新导致的现有节点预测性能下降。

Result: 在四个真实世界数据集上的大量实验中，CCC表现出优于最先进基线的性能。

Conclusion: CCC框架有效解决了动态图中GNN的灾难性遗忘问题，通过压缩-拼接策略和改进的遗忘度量，在动态图持续学习任务中取得了优异表现。

Abstract: Dynamic graphs are prevalent in real-world scenarios, where continuous structural changes induce catastrophic forgetting in graph neural networks (GNNs). While continual learning has been extended to dynamic graphs, existing methods overlook the effects of topological changes on existing nodes. To address it, we propose a novel framework for continual learning on dynamic graphs, named Condensation-Concatenation-based Continual Learning (CCC). Specifically, CCC first condenses historical graph snapshots into compact semantic representations while aiming to preserve the original label distribution and topological properties. Then it concatenates these historical embeddings with current graph representations selectively. Moreover, we refine the forgetting measure (FM) to better adapt to dynamic graph scenarios by quantifying the predictive performance degradation of existing nodes caused by structural updates. CCC demonstrates superior performance over state-of-the-art baselines across four real-world datasets in extensive experiments.

</details>


### [91] [Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation](https://arxiv.org/abs/2512.11332)
*Sara Sameer,Wei Zhang,Kannan Dhivya Dharshini,Xin Lou,Yulin Gao,Terence Goh,Qingyu Yan*

Main category: cs.LG

TL;DR: Pace：一种用于电池健康估计的物理感知注意力时序卷积网络，结合原始传感器数据和电池物理特征，在公开数据集上性能显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 电池是现代能源系统（如电动汽车和电网储能）的关键组件，有效的电池健康管理对于系统安全、成本效益和可持续性至关重要。需要开发准确高效的电池健康估计方法。

Method: 提出Pace模型，将原始传感器测量数据与基于等效电路模型提取的电池物理特征相结合。开发了三个电池专用模块：用于高效时序编码的扩张时序块、用于上下文建模的分块注意力块，以及用于融合短期和长期电池退化模式的双头输出块。

Result: 在大型公开数据集上，Pace性能显著优于现有模型，相比两个最佳基线模型平均性能提升6.5%和2.0倍。在树莓派上的实时边缘部署验证了其实用可行性。

Conclusion: Pace为电池健康分析提供了一个实用且高性能的解决方案，能够准确高效地预测各种使用条件下的电池健康状况。

Abstract: Batteries are critical components in modern energy systems such as electric vehicles and power grid energy storage. Effective battery health management is essential for battery system safety, cost-efficiency, and sustainability. In this paper, we propose Pace, a physics-aware attentive temporal convolutional network for battery health estimation. Pace integrates raw sensor measurements with battery physics features derived from the equivalent circuit model. We develop three battery-specific modules, including dilated temporal blocks for efficient temporal encoding, chunked attention blocks for context modeling, and a dual-head output block for fusing short- and long-term battery degradation patterns. Together, the modules enable Pace to predict battery health accurately and efficiently in various battery usage conditions. In a large public dataset, Pace performs much better than existing models, achieving an average performance improvement of 6.5 and 2.0x compared to two best-performing baseline models. We further demonstrate its practical viability with a real-time edge deployment on a Raspberry Pi. These results establish Pace as a practical and high-performance solution for battery health analytics.

</details>


### [92] [Spectral entropy prior-guided deep feature fusion architecture for magnetic core loss](https://arxiv.org/abs/2512.11334)
*Cong Yao,Chunye Gong,Jin Zhang*

Main category: cs.LG

TL;DR: 提出SEPI-TFPNet混合模型，结合经验模型与深度学习，通过物理先验子模块选择合适经验模型，数据驱动子模块提取特征，自适应特征融合模块提升多模态特征交互，在MagNet数据集上优于21个代表性模型。


<details>
  <summary>Details</summary>
Motivation: 传统磁芯损耗建模方法预测精度有限，纯数据驱动模型虽然拟合性能强，但可解释性和跨分布泛化能力不足。为解决这些问题，需要结合物理先验与数据驱动方法的优势。

Method: 提出SEPI-TFPNet混合模型：1) 物理先验子模块使用谱熵判别机制选择最适合不同激励波形的经验模型；2) 数据驱动子模块结合CNN、多头注意力机制和双向LSTM提取磁通密度时间序列特征；3) 引入自适应特征融合模块改善多模态特征交互与集成。

Result: 在包含多种磁性材料的MagNet数据集上评估，与2023年挑战赛的21个代表性模型以及2024-2025年的三种先进方法比较，所提方法在建模精度和鲁棒性方面均有提升。

Conclusion: SEPI-TFPNet混合模型通过结合物理先验与深度学习，有效提升了磁芯损耗建模的精度和鲁棒性，解决了纯数据驱动模型在可解释性和泛化能力方面的局限性。

Abstract: Accurate core loss modeling is critical for the design of high-efficiency power electronic systems. Traditional core loss modeling methods have limitations in prediction accuracy. To advance this field, the IEEE Power Electronics Society launched the MagNet Challenge in 2023, the first international competition focused on data-driven power electronics design methods, aiming to uncover complex loss patterns in magnetic components through a data-driven paradigm. Although purely data-driven models demonstrate strong fitting performance, their interpretability and cross-distribution generalization capabilities remain limited. To address these issues, this paper proposes a hybrid model, SEPI-TFPNet, which integrates empirical models with deep learning. The physical-prior submodule employs a spectral entropy discrimination mechanism to select the most suitable empirical model under different excitation waveforms. The data-driven submodule incorporates convolutional neural networks, multi-head attention mechanisms, and bidirectional long short-term memory networks to extract flux-density time-series features. An adaptive feature fusion module is introduced to improve multimodal feature interaction and integration. Using the MagNet dataset containing various magnetic materials, this paper evaluates the proposed method and compares it with 21 representative models from the 2023 challenge and three advanced methods from 2024-2025. The results show that the proposed method achieves improved modeling accuracy and robustness.

</details>


### [93] [DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning](https://arxiv.org/abs/2512.11342)
*Jinming Ge,Linfeng Du,Likith Anaparty,Shangkun Li,Tingyuan Liang,Afzal Ahmad,Vivek Chaturvedi,Sharad Sinha,Zhiyao Xie,Jiang Xu,Wei Zhang*

Main category: cs.LG

TL;DR: DAPO是一个基于强化学习的HLS优化框架，通过程序语义提取、对比学习和硬件指标估计，自动发现设计特定的优化策略，相比Vitis HLS平均提升2.36倍性能。


<details>
  <summary>Details</summary>
Motivation: 现有HLS工具采用固定的优化策略，这些策略继承自软件编译器，无法针对特定硬件设计进行优化。需要深度语义理解、准确的硬件指标估计和高级搜索算法，而当前方法缺乏这些能力。

Method: DAPO框架：1) 从控制流和数据流图中提取程序语义；2) 使用对比学习生成丰富的嵌入表示；3) 利用分析模型进行准确的硬件指标估计；4) 基于强化学习代理发现设计特定的优化策略。

Result: 在经典HLS设计上的评估显示，DAPO端到端流程相比Vitis HLS平均实现了2.36倍的性能加速。

Conclusion: DAPO通过结合程序语义理解、对比学习和强化学习，能够自动发现针对特定硬件设计的优化策略，显著提升了HLS工具的性能优化能力。

Abstract: High-Level Synthesis (HLS) tools are widely adopted in FPGA-based domain-specific accelerator design. However, existing tools rely on fixed optimization strategies inherited from software compilations, limiting their effectiveness. Tailoring optimization strategies to specific designs requires deep semantic understanding, accurate hardware metric estimation, and advanced search algorithms -- capabilities that current approaches lack.
  We propose DAPO, a design structure-aware pass ordering framework that extracts program semantics from control and data flow graphs, employs contrastive learning to generate rich embeddings, and leverages an analytical model for accurate hardware metric estimation. These components jointly guide a reinforcement learning agent to discover design-specific optimization strategies. Evaluations on classic HLS designs demonstrate that our end-to-end flow delivers a 2.36 speedup over Vitis HLS on average.

</details>


### [94] [Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits](https://arxiv.org/abs/2512.11345)
*Minwoo Park,Junwoo Chang,Jongeun Choi,Roberto Horowitz*

Main category: cs.LG

TL;DR: 本文提出了一种对称感知的强化学习框架，用于引导等变扩散策略，通过利用几何对称性提高样本效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 等变扩散策略结合了扩散模型的生成表达能力与几何对称性带来的强泛化能力，但使用标准（非等变）强化学习进行微调时，会忽略这些对称性，导致样本效率低下和不稳定。

Method: 理论证明等变扩散过程的扩散过程是等变的，从而诱导出适合等变扩散引导的群不变潜在噪声MDP。在此基础上，提出了一个原则性的对称感知引导框架，并比较了标准、等变和近似等变强化学习策略。

Result: 实验表明，在对称性引导过程中利用对称性能带来显著好处：提高样本效率、防止价值发散，即使在演示数据极其有限的情况下也能实现强大的策略改进。同时识别了严格等变在对称性破坏下的实际边界。

Conclusion: 对称感知的强化学习框架能有效引导等变扩散策略，在保持对称性优势的同时实现稳定高效的策略优化，为有限演示数据下的策略学习提供了有效解决方案。

Abstract: Equivariant diffusion policies (EDPs) combine the generative expressivity of diffusion models with the strong generalization and sample efficiency afforded by geometric symmetries. While steering these policies with reinforcement learning (RL) offers a promising mechanism for fine-tuning beyond demonstration data, directly applying standard (non-equivariant) RL can be sample-inefficient and unstable, as it ignores the symmetries that EDPs are designed to exploit. In this paper, we theoretically establish that the diffusion process of an EDP is equivariant, which in turn induces a group-invariant latent-noise MDP that is well-suited for equivariant diffusion steering. Building on this theory, we introduce a principled symmetry-aware steering framework and compare standard, equivariant, and approximately equivariant RL strategies through comprehensive experiments across tasks with varying degrees of symmetry. While we identify the practical boundaries of strict equivariance under symmetry breaking, we show that exploiting symmetry during the steering process yields substantial benefits-enhancing sample efficiency, preventing value divergence, and achieving strong policy improvements even when EDPs are trained from extremely limited demonstrations.

</details>


### [95] [CAT: Can Trust be Predicted with Context-Awareness in Dynamic Heterogeneous Networks?](https://arxiv.org/abs/2512.11352)
*Jie Wang,Zheng Yan,Jiahe Lan,Xuyan Li,Elisa Bertino*

Main category: cs.LG

TL;DR: CAT：首个支持信任动态性和真实世界异质性的上下文感知GNN信任预测模型，通过连续时间表示、双重注意力机制和元路径实现上下文感知信任预测。


<details>
  <summary>Details</summary>
Motivation: 现有GNN信任预测模型存在三个主要局限：1）无法捕捉信任动态性；2）忽略真实网络的异质性；3）不支持上下文感知这一信任的基本属性。这些限制导致预测结果粗糙且不可靠。

Method: CAT包含图构建层、嵌入层、异质注意力层和预测层。采用连续时间表示处理动态图，通过时间编码函数捕捉时序信息。使用双重注意力机制建模图异质性，引入元路径概念提取上下文特征，构建上下文嵌入并集成上下文感知聚合器。

Result: 在三个真实世界数据集上的实验表明，CAT在信任预测任务上优于五组基线方法，同时展现出对大规模图的高度可扩展性，以及对信任导向和GNN导向攻击的强大鲁棒性。

Conclusion: CAT是首个支持信任动态性和真实世界异质性的上下文感知GNN信任预测模型，能够同时预测上下文感知信任和整体信任，在性能、可扩展性和鲁棒性方面均表现出色。

Abstract: Trust prediction provides valuable support for decision-making, risk mitigation, and system security enhancement. Recently, Graph Neural Networks (GNNs) have emerged as a promising approach for trust prediction, owing to their ability to learn expressive node representations that capture intricate trust relationships within a network. However, current GNN-based trust prediction models face several limitations: (i) Most of them fail to capture trust dynamicity, leading to questionable inferences. (ii) They rarely consider the heterogeneous nature of real-world networks, resulting in a loss of rich semantics. (iii) None of them support context-awareness, a basic property of trust, making prediction results coarse-grained.
  To this end, we propose CAT, the first Context-Aware GNN-based Trust prediction model that supports trust dynamicity and accurately represents real-world heterogeneity. CAT consists of a graph construction layer, an embedding layer, a heterogeneous attention layer, and a prediction layer. It handles dynamic graphs using continuous-time representations and captures temporal information through a time encoding function. To model graph heterogeneity and leverage semantic information, CAT employs a dual attention mechanism that identifies the importance of different node types and nodes within each type. For context-awareness, we introduce a new notion of meta-paths to extract contextual features. By constructing context embeddings and integrating a context-aware aggregator, CAT can predict both context-aware trust and overall trust. Extensive experiments on three real-world datasets demonstrate that CAT outperforms five groups of baselines in trust prediction, while exhibiting strong scalability to large-scale graphs and robustness against both trust-oriented and GNN-oriented attacks.

</details>


### [96] [Attacking and Securing Community Detection: A Game-Theoretic Framework](https://arxiv.org/abs/2512.11359)
*Yifan Niu,Aochuan Chen,Tingyang Xu,Jia Li*

Main category: cs.LG

TL;DR: 该论文将对抗图攻击扩展到社区检测问题，提出攻击和防御方法，并建立博弈论框架CD-GAME来模拟攻防交互，最终达到纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 现有对抗图攻击主要针对图分类任务，但社区检测问题更具挑战性。研究社区检测中的攻防技术有重要实际应用价值，如保护社交网络中的个人隐私和理解交易网络中的伪装模式。

Method: 提出针对社区检测的攻击和防御技术，攻击目标是隐藏特定个体不被检测模型发现，防御目标是增强社区检测模型的鲁棒性。进一步提出博弈论框架CD-GAME，包含图攻击者和Rayleigh Quotient防御者两个玩家，模拟动态交互过程直至达到纳什均衡。

Result: 实验证明提出的攻击和防御方法均显著优于现有基线方法。CD-GAME框架揭示了攻防交互的动态演化过程，发现在传统单步攻防中攻击者采用最有效但易被检测的策略，而在纳什均衡下攻击者采用更隐蔽且仍能保持满意攻击效果的策略。

Conclusion: 该研究成功将对抗图概念扩展到社区检测问题，提出的攻防方法和CD-GAME框架不仅在实际应用中有效，还为理解社区检测中的交互攻防场景提供了有价值的见解。

Abstract: It has been demonstrated that adversarial graphs, i.e., graphs with imperceptible perturbations, can cause deep graph models to fail on classification tasks. In this work, we extend the concept of adversarial graphs to the community detection problem, which is more challenging. We propose novel attack and defense techniques for community detection problem, with the objective of hiding targeted individuals from detection models and enhancing the robustness of community detection models, respectively. These techniques have many applications in real-world scenarios, for example, protecting personal privacy in social networks and understanding camouflage patterns in transaction networks. To simulate interactive attack and defense behaviors, we further propose a game-theoretic framework, called CD-GAME. One player is a graph attacker, while the other player is a Rayleigh Quotient defender. The CD-GAME models the mutual influence and feedback mechanisms between the attacker and the defender, revealing the dynamic evolutionary process of the game. Both players dynamically update their strategies until they reach the Nash equilibrium. Extensive experiments demonstrate the effectiveness of our proposed attack and defense methods, and both outperform existing baselines by a significant margin. Furthermore, CD-GAME provides valuable insights for understanding interactive attack and defense scenarios in community detection problems. We found that in traditional single-step attack or defense, attacker tends to employ strategies that are most effective, but are easily detected and countered by defender. When the interactive game reaches a Nash equilibrium, attacker adopts more imperceptible strategies that can still achieve satisfactory attack effectiveness even after defense.

</details>


### [97] [Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](https://arxiv.org/abs/2512.11391)
*Yifan Niu,Han Xiao,Dongyi Liu,Nuo Chen,Jia Li*

Main category: cs.LG

TL;DR: NSPO是一种新的强化学习框架，通过将安全策略梯度投影到通用任务零空间来减少对齐税，在保持LLM核心能力的同时实现安全对齐。


<details>
  <summary>Details</summary>
Motivation: LLM在现实应用中需要确保行为符合人类价值观、社会规范和伦理原则，但现有的RL安全对齐方法会导致模型忘记已学习的通用能力（对齐税问题）。

Method: 提出零空间约束策略优化（NSPO），将安全策略梯度几何投影到通用任务的零空间中，从而减少对齐税，理论上证明该方法能保持模型原始核心能力同时保证有效的安全对齐方向。

Result: NSPO大幅超越现有方法，在数学、代码和指令跟随等通用任务上保持准确性的同时实现最先进的安全性能，且数据效率高，仅需PKU-SafeRLHF中40%的公开人类标注安全数据。

Conclusion: NSPO是一种有效的RL框架，能在保持LLM核心能力的同时实现安全对齐，解决了对齐税问题，具有数据效率高、性能优越的特点。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general abilities, which is also known as the alignment tax. To address this issue, we introduce Null-Space constrained Policy Optimization (NSPO), a novel RL framework for LLM safety alignment while preserving their core abilities. The safety policy gradients are geometrically projected into the null space of general tasks, thereby mitigating the safety alignment tax. In addition, we theoretically prove that NSPO preserves the model's original core capabilities, while still guaranteeing a descent direction for effective safety alignment. Extensive experiments demonstrate that NSPO outperforms existing methods by a large margin, achieving state-of-the-art safety performance without sacrificing accuracy on general tasks, including math, code, and instruction-following tasks. Notably, NSPO is data-efficient and only requires 40% of public human-annotated safety data from PKU-SafeRLHF to achieve promising safety performance, without a large amount of mixed general tasks data in existing alignment methods.

</details>


### [98] [Bhargava Cube--Inspired Quadratic Regularization for Structured Neural Embeddings](https://arxiv.org/abs/2512.11392)
*S Sairam,Prateek P Kulkarni*

Main category: cs.LG

TL;DR: 提出一种结合数论中Bhargava立方体代数约束的神经表示学习方法，在3D潜在空间中学习满足二次关系的可解释嵌入


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在非结构化潜在空间中学习表示，缺乏可解释性和数学一致性。需要将数学结构融入神经网络表示学习

Method: 将输入数据映射到受约束的3维潜在空间，通过可微辅助损失函数正则化嵌入，使其满足从Bhargava组合结构推导出的二次关系

Result: 在MNIST上达到99.46%准确率，产生可解释的3D嵌入，自然地按数字类别聚类并满足学习的二次约束

Conclusion: 这是数论结构在神经表示学习中的首次应用，为在神经网络中融入结构化数学先验奠定了基础

Abstract: We present a novel approach to neural representation learning that incorporates algebraic constraints inspired by Bhargava cubes from number theory. Traditional deep learning methods learn representations in unstructured latent spaces lacking interpretability and mathematical consistency. Our framework maps input data to constrained 3-dimensional latent spaces where embeddings are regularized to satisfy learned quadratic relationships derived from Bhargava's combinatorial structures. The architecture employs a differentiable auxiliary loss function operating independently of classification objectives, guiding models toward mathematically structured representations. We evaluate on MNIST, achieving 99.46% accuracy while producing interpretable 3D embeddings that naturally cluster by digit class and satisfy learned quadratic constraints. Unlike existing manifold learning approaches requiring explicit geometric supervision, our method imposes weak algebraic priors through differentiable constraints, ensuring compatibility with standard optimization. This represents the first application of number-theoretic constructs to neural representation learning, establishing a foundation for incorporating structured mathematical priors in neural networks.

</details>


### [99] [Sliced ReLU attention: Quasi-linear contextual expressivity via sorting](https://arxiv.org/abs/2512.11411)
*Siwan Boufadène,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 提出切片ReLU注意力机制，通过排序实现O(n log n)复杂度，适用于长上下文，保持理论表达能力


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如softmax和ReLU-based）在长上下文场景下计算复杂度高，需要一种既高效又保持理论表达能力的替代方案

Method: 使用键-查询差异的一维投影，通过排序操作构建可微分的非对称核，实现O(n log n)的准线性复杂度

Result: 证明了切片ReLU注意力具有与softmax注意力相同的上下文表达能力，能够执行非平凡的序列到序列解耦任务，并满足上下文通用逼近性质

Conclusion: 切片ReLU注意力机制在计算效率和理论表达能力之间取得了良好平衡，为长上下文处理提供了有前景的解决方案

Abstract: We introduce sliced ReLU attention, a new attention mechanism that departs structurally from both softmax and ReLU-based alternatives. Instead of applying a nonlinearity to pairwise dot products, we operate on one-dimensional projections of key--query differences and leverage sorting to obtain quasi-linear complexity. This construction yields a differentiable, non-symmetric kernel that can be computed in O(n log(n)) through a sorting procedure, making it suitable for very long contexts. Beyond computational benefits, the model retains strong theoretical expressive power: we establish two in-context expressivity results, previously known for softmax attention, showing that sliced ReLU attention preserves the ability to perform nontrivial sequence-to-sequence disentangling tasks and satisfies a contextual universal approximation property. Finally, we illustrate the potential practical interest of this kernel in small-scale experiments.

</details>


### [100] [Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces](https://arxiv.org/abs/2512.11448)
*Arghya Pratihar,Arnab Seal,Swagatam Das,Inesh Chattopadhyay*

Main category: cs.LG

TL;DR: HypeGBMS将高斯模糊均值漂移扩展到双曲空间，使用双曲距离和Möbius加权均值，能有效处理具有层次结构的数据集。


<details>
  <summary>Details</summary>
Motivation: 传统高斯模糊均值漂移(GBMS)在欧几里得空间中有效，但难以处理具有层次或树状结构的数据集。双曲空间能更好地表示层次结构，因此需要将GBMS扩展到双曲空间。

Method: 将GBMS扩展到双曲空间，用双曲距离替代欧几里得距离，使用Möbius加权均值确保更新与空间几何一致，保持密度寻求行为的同时捕捉潜在层次结构。

Result: 在11个真实世界数据集上的实验表明，HypeGBMS在非欧几里得设置下显著优于传统均值漂移方法，证明了其鲁棒性和有效性。

Conclusion: HypeGBMS桥接了经典均值漂移聚类和双曲表示学习，为弯曲空间中的密度聚类提供了原则性方法，能有效处理层次结构数据。

Abstract: Clustering is a fundamental unsupervised learning task for uncovering patterns in data. While Gaussian Blurring Mean Shift (GBMS) has proven effective for identifying arbitrarily shaped clusters in Euclidean space, it struggles with datasets exhibiting hierarchical or tree-like structures. In this work, we introduce HypeGBMS, a novel extension of GBMS to hyperbolic space. Our method replaces Euclidean computations with hyperbolic distances and employs Möbius-weighted means to ensure that all updates remain consistent with the geometry of the space. HypeGBMS effectively captures latent hierarchies while retaining the density-seeking behavior of GBMS. We provide theoretical insights into convergence and computational complexity, along with empirical results that demonstrate improved clustering quality in hierarchical datasets. This work bridges classical mean-shift clustering and hyperbolic representation learning, offering a principled approach to density-based clustering in curved spaces. Extensive experimental evaluations on $11$ real-world datasets demonstrate that HypeGBMS significantly outperforms conventional mean-shift clustering methods in non-Euclidean settings, underscoring its robustness and effectiveness.

</details>


### [101] [Rethinking Expert Trajectory Utilization in LLM Post-training](https://arxiv.org/abs/2512.11470)
*Bowen Ding,Yuhan Chen,Jiayang Lv,Jiyao Yuan,Qi Zhu,Shuangshuang Tian,Dantong Zhu,Futing Wang,Heyuan Deng,Fei Mi,Lifeng Shang,Tao Lin*

Main category: cs.LG

TL;DR: 提出Plasticity-Ceiling框架，理论分析专家轨迹利用机制，确立SFT-then-RL为最佳流程，并提供具体扩展指导原则。


<details>
  <summary>Details</summary>
Motivation: 当前后训练中结合监督微调(SFT)和强化学习(RL)虽然有效，但如何最优利用专家轨迹的问题尚未解决，需要理论框架指导实践。

Method: 提出Plasticity-Ceiling框架，将性能分解为基础SFT性能和后续RL可塑性，通过大量基准测试验证Sequential SFT-then-RL流程的优越性。

Result: 1) SFT稳定或轻度过拟合阶段转向RL能最大化最终性能上限；2) 数据规模决定后训练潜力，轨迹难度作为性能乘数；3) 最小SFT验证损失是选择专家轨迹的可靠指标。

Conclusion: 研究为最大化专家轨迹价值提供了可操作的指导原则，确立了SFT-then-RL为后训练的标准流程，并提供了具体的扩展指导。

Abstract: While effective post-training integrates Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), the optimal mechanism for utilizing expert trajectories remains unresolved. We propose the Plasticity-Ceiling Framework to theoretically ground this landscape, decomposing performance into foundational SFT performance and the subsequent RL plasticity. Through extensive benchmarking, we establish the Sequential SFT-then-RL pipeline as the superior standard, overcoming the stability deficits of synchronized approaches. Furthermore, we derive precise scaling guidelines: (1) Transitioning to RL at the SFT Stable or Mild Overfitting Sub-phase maximizes the final ceiling by securing foundational SFT performance without compromising RL plasticity; (2) Refuting ``Less is More'' in the context of SFT-then-RL scaling, we demonstrate that Data Scale determines the primary post-training potential, while Trajectory Difficulty acts as a performance multiplier; and (3) Identifying that the Minimum SFT Validation Loss serves as a robust indicator for selecting the expert trajectories that maximize the final performance ceiling. Our findings provide actionable guidelines for maximizing the value extracted from expert trajectories.

</details>


### [102] [NeuralOGCM: Differentiable Ocean Modeling with Learnable Physics](https://arxiv.org/abs/2512.11525)
*Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Guangliang Liu,Yuxuan Liang,Xiaomeng Huang*

Main category: cs.LG

TL;DR: NeuralOGCM：融合可微分编程与深度学习的海洋建模框架，通过可学习的物理求解器和神经网络校正，在保持物理一致性的同时显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 解决科学模拟中长期存在的计算效率与物理保真度之间的权衡问题，传统数值模型计算成本高，而纯AI方法缺乏物理一致性

Method: 1) 完全可微分的动力学求解器，将关键物理参数（如扩散系数）转化为可学习参数；2) 深度神经网络校正次网格过程和离散化误差；3) 两者通过统一的ODE求解器协同工作

Result: NeuralOGCM保持长期稳定性和物理一致性，在速度上显著优于传统数值模型，在精度上优于纯AI基线方法

Conclusion: 该工作为构建快速、稳定且物理合理的科学计算模型开辟了新路径，实现了物理知识与数据驱动方法的有效融合

Abstract: High-precision scientific simulation faces a long-standing trade-off between computational efficiency and physical fidelity. To address this challenge, we propose NeuralOGCM, an ocean modeling framework that fuses differentiable programming with deep learning. At the core of NeuralOGCM is a fully differentiable dynamical solver, which leverages physics knowledge as its core inductive bias. The learnable physics integration captures large-scale, deterministic physical evolution, and transforms key physical parameters (e.g., diffusion coefficients) into learnable parameters, enabling the model to autonomously optimize its physical core via end-to-end training. Concurrently, a deep neural network learns to correct for subgrid-scale processes and discretization errors not captured by the physics model. Both components work in synergy, with their outputs integrated by a unified ODE solver. Experiments demonstrate that NeuralOGCM maintains long-term stability and physical consistency, significantly outperforming traditional numerical models in speed and pure AI baselines in accuracy. Our work paves a new path for building fast, stable, and physically-plausible models for scientific computing.

</details>


### [103] [Contrastive Time Series Forecasting with Anomalies](https://arxiv.org/abs/2512.11526)
*Joel Ekstrand,Zahra Taghiyarrenani,Slawomir Nowaczyk*

Main category: cs.LG

TL;DR: Co-TSFA是一个对比学习框架，通过区分预测相关和预测无关的异常，提高时间序列预测在异常条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测中，有些异常事件具有持久影响需要响应，有些则是短暂噪声应该忽略。传统预测模型无法区分这两类异常，要么对噪声过度反应，要么错过真正的分布变化。

Method: 提出Co-TSFA对比学习正则化框架：1）生成仅输入增强和输入-输出增强来分别建模预测无关和预测相关的异常；2）引入潜在输出对齐损失，将表示变化与预测变化关联起来；3）鼓励模型对无关扰动保持不变性，同时对有意义的分布变化保持敏感性。

Result: 在Traffic和Electricity基准数据集以及真实现金需求数据集上的实验表明，Co-TSFA在异常条件下提升了预测性能，同时在正常数据上保持了准确性。

Conclusion: Co-TSFA通过对比学习有效区分了预测相关和预测无关的异常，提高了时间序列预测模型在现实异常条件下的鲁棒性，同时不影响正常数据的预测精度。

Abstract: Time series forecasting predicts future values from past data. In real-world settings, some anomalous events have lasting effects and influence the forecast, while others are short-lived and should be ignored. Standard forecasting models fail to make this distinction, often either overreacting to noise or missing persistent shifts. We propose Co-TSFA (Contrastive Time Series Forecasting with Anomalies), a regularization framework that learns when to ignore anomalies and when to respond. Co-TSFA generates input-only and input-output augmentations to model forecast-irrelevant and forecast-relevant anomalies, and introduces a latent-output alignment loss that ties representation changes to forecast changes. This encourages invariance to irrelevant perturbations while preserving sensitivity to meaningful distributional shifts. Experiments on the Traffic and Electricity benchmarks, as well as on a real-world cash-demand dataset, demonstrate that Co-TSFA improves performance under anomalous conditions while maintaining accuracy on normal data. An anonymized GitHub repository with the implementation of Co-TSFA is provided and will be made public upon acceptance.

</details>


### [104] [xGR: Efficient Generative Recommendation Serving at Scale](https://arxiv.org/abs/2512.11529)
*Qingxiao Sun,Tongxuan Liu,Shen Zhang,Siyu Wu,Peijun Yang,Haotian Liang,Menxin Li,Xiaolong Ma,Zhiwei Liang,Ziyi Ren,Minchao Zhang,Xinyu Liu,Ke Zhang,Depei Qian,Hailong Yang*

Main category: cs.LG

TL;DR: xGR是一个面向生成式推荐系统的服务系统，通过统一prefill和decode阶段处理、早期排序终止和掩码过滤、重构流水线实现多级重叠和多流并行，在严格延迟约束下实现至少3.49倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统虽然使用基于注意力的架构，但其工作负载与LLM服务显著不同：处理长提示但产生短固定长度输出，解码阶段计算成本高（由于大beam宽度），在巨大物品空间中进行beam搜索时排序开销特别耗时。需要满足高并发场景下的严格低延迟要求。

Method: 1. 通过分阶段计算和分离KV缓存统一prefill和decode阶段处理；2. 启用早期排序终止和基于掩码的物品过滤，重用数据结构；3. 重构整体流水线以利用多级重叠和多流并行。

Result: 在真实世界推荐服务数据集上的实验表明，xGR在严格延迟约束下相比最先进的基线实现了至少3.49倍的吞吐量提升。

Conclusion: xGR是一个专门针对生成式推荐系统工作负载特点设计的服务系统，通过多项优化技术有效解决了GR服务中的计算瓶颈，显著提升了高并发场景下的系统性能。

Abstract: Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LLM serving. GR typically processes long prompt while producing short, fixed-length outputs, yet the computational cost of each decode phase is especially high due to the large beam width. In addition, since the beam search involves a vast item space, the sorting overhead becomes particularly time-consuming. We propose xGR, a GR-oriented serving system that meets strict low-latency requirements under highconcurrency scenarios. First, xGR unifies the processing of prefill and decode phases through staged computation and separated KV cache. Second, xGR enables early sorting termination and mask-based item filtering with data structure reuse. Third, xGR reconstructs the overall pipeline to exploit multilevel overlap and multi-stream parallelism. Our experiments with real-world recommendation service datasets demonstrate that xGR achieves at least 3.49x throughput compared to the state-of-the-art baseline under strict latency constraints.

</details>


### [105] [Parametric Numerical Integration with (Differential) Machine Learning](https://arxiv.org/abs/2512.11530)
*Álvaro Leitao,Jonatan Ráfales*

Main category: cs.LG

TL;DR: 提出一种基于微分学习的机器学习方法求解参数积分，相比传统方法在精度、可扩展性和样本效率方面表现更优


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在求解参数积分时存在精度和效率限制，需要一种能够利用导数信息提升性能的新方法

Method: 采用微分学习框架，在训练过程中融入导数信息，应用于三类代表性积分问题：统计泛函、Chebyshev展开函数逼近、微分方程积分

Result: 微分学习方法在所有测试案例中均优于标准架构，获得更低的均方误差、更好的可扩展性和更高的样本效率

Conclusion: 微分学习框架为参数积分求解提供了有效方法，特别适用于从光滑闭式基准到挑战性数值积分的各类问题

Abstract: In this work, we introduce a machine/deep learning methodology to solve parametric integrals. Besides classical machine learning approaches, we consider a differential learning framework that incorporates derivative information during training, emphasizing its advantageous properties. Our study covers three representative problem classes: statistical functionals (including moments and cumulative distribution functions), approximation of functions via Chebyshev expansions, and integrals arising directly from differential equations. These examples range from smooth closed-form benchmarks to challenging numerical integrals. Across all cases, the differential machine learning-based approach consistently outperforms standard architectures, achieving lower mean squared error, enhanced scalability, and improved sample efficiency.

</details>


### [106] [A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts](https://arxiv.org/abs/2512.11541)
*Emmanuel K. Katalay,David O. Dimandja,Jordan F. Masakuna*

Main category: cs.LG

TL;DR: 提出自动化MLOps管道，通过多准则统计技术检测数据分布漂移，仅在必要时触发模型重训练，提高计算效率和模型鲁棒性


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在数据分布随时间变化时性能会下降（数据分布漂移），需要重新训练和部署。当前的MLOps流程通常是手动的，需要人工触发模型重训练和重新部署过程

Method: 设计自动化MLOps管道，采用多准则统计技术检测显著的数据分布变化，仅在必要时触发神经网络分类器的更新，确保计算效率和资源优化

Result: 在多个基准异常检测数据集上的实验表明，与传统重训练策略相比，该框架显著提高了模型准确性和鲁棒性

Conclusion: 为在动态现实环境中部署更可靠和自适应的机器学习系统提供了基础，这些环境中数据分布变化很常见

Abstract: The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the process of model retraining and redeployment. In this work, we present an automated MLOps pipeline designed to address neural network classifier retraining in response to significant data distribution changes. Our MLOps pipeline employs multi-criteria statistical techniques to detect distribution shifts and triggers model updates only when necessary, ensuring computational efficiency and resource optimization. We demonstrate the effectiveness of our framework through experiments on several benchmark anomaly detection data sets, showing significant improvements in model accuracy and robustness compared to traditional retraining strategies. Our work provides a foundation for deploying more reliable and adaptive ML systems in dynamic real-world settings, where data distribution changes are common.

</details>


### [107] [Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting](https://arxiv.org/abs/2512.11546)
*Federico Pennino,Maurizio Gabbrielli*

Main category: cs.LG

TL;DR: 提出数据选择框架，通过优化训练数据组成而非模型超参数，发现"训练食谱"能显著提升模型性能，在PMSM数据集上MSE从1.70提升至1.37（19.41%改进）。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习训练范式假设数据越多越好，但原始传感器数据通常存在不平衡和冗余问题，并非所有数据点对模型泛化都有同等贡献。研究表明在某些情况下"少即是多"，需要重新思考数据选择问题。

Method: 提出数据中心化框架：1）使用大规模编码器和k-means聚类将未标注时间序列数据划分为行为一致的聚类作为基本"成分"；2）采用Optuna优化框架在可能的数据混合高维空间中搜索，为每个聚类提议特定采样比例；3）根据"食谱"构建训练集，训练并评估目标模型。

Result: 实验表明该数据中心化搜索方法能持续发现比在整个数据集上训练的基线模型性能显著更高的数据混合方案。在PMSM数据集上，MSE从基线1.70提升至1.37，改进19.41%。

Conclusion: 通过优化训练数据组成而非模型超参数，可以显著提升模型性能，验证了"少即是多"的数据选择理念，为传感器数据训练提供了新的数据中心化优化范式。

Abstract: The standard paradigm for training deep learning models on sensor data assumes that more data is always better. However, raw sensor streams are often imbalanced and contain significant redundancy, meaning that not all data points contribute equally to model generalization. In this paper, we show that, in some cases, "less is more" when considering datasets. We do this by reframing the data selection problem: rather than tuning model hyperparameters, we fix the model and optimize the composition of the training data itself. We introduce a framework for discovering the optimal "training diet" from a large, unlabeled time series corpus. Our framework first uses a large-scale encoder and k-means clustering to partition the dataset into distinct, behaviorally consistent clusters. These clusters represent the fundamental 'ingredients' available for training. We then employ the Optuna optimization framework to search the high-dimensional space of possible data mixtures. For each trial, Optuna proposes a specific sampling ratio for each cluster, and a new training set is constructed based on this recipe. A smaller target model is then trained and evaluated. Our experiments reveal that this data-centric search consistently discovers data mixtures that yield models with significantly higher performance compared to baselines trained on the entire dataset. Specifically - evaluated on PMSM dataset - our method improved performance from a baseline MSE of 1.70 to 1.37, a 19.41% improvement.

</details>


### [108] [Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction](https://arxiv.org/abs/2512.11547)
*Janaina Mourão-Miranda,Zakria Hussain,Konstantinos Tsirlis,Christophe Phillips,John Shawe-Taylor*

Main category: cs.LG

TL;DR: 提出一种新的弹性网络正则化多核学习方法，通过解析更新核权重，在神经影像应用中实现稀疏且可解释的模型。


<details>
  <summary>Details</summary>
Motivation: 现有弹性网络正则化多核学习方法采用两阶段优化过程，计算复杂。需要更高效的方法来处理神经影像中相关的核特征，同时保持模型稀疏性和可解释性。

Method: 提出新的ENMKL公式，能够解析更新核权重。为SVM和核岭回归开发了具体算法，并在PRoNTo工具箱中实现。

Result: ENMKL在所有任务中匹配或优于l1正则化MKL，仅在一种情况下略逊于标准SVM。更重要的是，ENMKL通过选择性加权相关核，产生了更稀疏、更可解释的模型。

Conclusion: 新提出的ENMKL方法提供了高效且可解释的多核学习框架，特别适用于神经影像等需要处理相关特征且模型可解释性重要的领域。

Abstract: Multiple Kernel Learning (MKL) models combine several kernels in supervised and unsupervised settings to integrate multiple data representations or sources, each represented by a different kernel. MKL seeks an optimal linear combination of base kernels that maximizes a generalized performance measure under a regularization constraint. Various norms have been used to regularize the kernel weights, including $l1$, $l2$ and $lp$, as well as the "elastic-net" penalty, which combines $l1$- and $l2$-norm to promote both sparsity and the selection of correlated kernels. This property makes elastic-net regularized MKL (ENMKL) especially valuable when model interpretability is critical and kernels capture correlated information, such as in neuroimaging. Previous ENMKL methods have followed a two-stage procedure: fix kernel weights, train a support vector machine (SVM) with the weighted kernel, and then update the weights via gradient descent, cutting-plane methods, or surrogate functions. Here, we introduce an alternative ENMKL formulation that yields a simple analytical update for the kernel weights. We derive explicit algorithms for both SVM and kernel ridge regression (KRR) under this framework, and implement them in the open-source Pattern Recognition for Neuroimaging Toolbox (PRoNTo). We evaluate these ENMKL algorithms against $l1$-norm MKL and against SVM (or KRR) trained on the unweighted sum of kernels across three neuroimaging applications. Our results show that ENMKL matches or outperforms $l1$-norm MKL in all tasks and only underperforms standard SVM in one scenario. Crucially, ENMKL produces sparser, more interpretable models by selectively weighting correlated kernels.

</details>


### [109] [Fully Inductive Node Representation Learning via Graph View Transformation](https://arxiv.org/abs/2512.11561)
*Dooho Lee,Myeong Kong,Minho Jeong,Jaemin Yoo*

Main category: cs.LG

TL;DR: 提出图视图空间和Graph View Transformation (GVT)方法，实现无需重新训练的跨数据集全归纳图表示学习，在27个节点分类基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在不重新训练的情况下泛化到未见数据集是基础模型的关键，但图数据中特征空间的维度和语义差异大，特征空间的任何变换都可能破坏对未见数据集的归纳适用性，限制了图模型的设计空间。

Method: 引入视图空间作为新的表示轴，提出图视图变换(GVT)——在视图空间中节点和特征置换等变的映射，并构建循环GVT作为全归纳节点表示学习模型。

Result: 在OGBN-Arxiv上预训练并在27个节点分类基准上评估，循环GVT比现有全归纳图模型GraphAny提升8.93%，比12个单独调优的GNN至少提升3.30%。

Conclusion: 视图空间为全归纳节点表示学习提供了原则性和有效的理论基础，GVT方法在跨数据集泛化方面表现出色。

Abstract: Generalizing a pretrained model to unseen datasets without retraining is an essential step toward a foundation model. However, achieving such cross-dataset, fully inductive inference is difficult in graph-structured data where feature spaces vary widely in both dimensionality and semantics. Any transformation in the feature space can easily violate the inductive applicability to unseen datasets, strictly limiting the design space of a graph model. In this work, we introduce the view space, a novel representational axis in which arbitrary graphs can be naturally encoded in a unified manner. We then propose Graph View Transformation (GVT), a node- and feature-permutation-equivariant mapping in the view space. GVT serves as the building block for Recurrent GVT, a fully inductive model for node representation learning. Pretrained on OGBN-Arxiv and evaluated on 27 node-classification benchmarks, Recurrent GVT outperforms GraphAny, the prior fully inductive graph model, by +8.93% and surpasses 12 individually tuned GNNs by at least +3.30%. These results establish the view space as a principled and effective ground for fully inductive node representation learning.

</details>


### [110] [Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model](https://arxiv.org/abs/2512.11582)
*Sam Gijsen,Marc-Andre Schulz,Kerstin Ritter*

Main category: cs.LG

TL;DR: Brain-Semantoks：一种自监督框架，通过语义标记器和自蒸馏目标学习fMRI时间序列的抽象表征，无需大量微调即可在下游任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 当前fMRI基础模型通常在小脑区域上使用掩码-重建目标训练，这导致表征对噪声和时间波动敏感，需要大量微调才能用于下游任务。需要一种能够学习大脑动态抽象表征的方法。

Method: 提出Brain-Semantoks框架，包含两个核心创新：1）语义标记器将噪声区域信号聚合成代表功能网络的稳健标记；2）自蒸馏目标强制表征在时间上的稳定性。通过新颖的训练课程确保模型从低信噪比时间序列中稳健学习有意义的特征。

Result: 学习到的表征即使仅使用线性探针也能在各种下游任务中实现强大性能。扩展分析表明，更多未标记数据可靠地带来分布外性能提升，无需领域适应。

Conclusion: Brain-Semantoks能够学习fMRI时间序列的抽象表征，对噪声不敏感，减少了下游任务所需的微调，为功能磁共振成像基础模型的发展提供了有前景的方向。

Abstract: The development of foundation models for functional magnetic resonance imaging (fMRI) time series holds significant promise for predicting phenotypes related to disease and cognition. Current models, however, are often trained using a mask-and-reconstruct objective on small brain regions. This focus on low-level information leads to representations that are sensitive to noise and temporal fluctuations, necessitating extensive fine-tuning for downstream tasks. We introduce Brain-Semantoks, a self-supervised framework designed specifically to learn abstract representations of brain dynamics. Its architecture is built on two core innovations: a semantic tokenizer that aggregates noisy regional signals into robust tokens representing functional networks, and a self-distillation objective that enforces representational stability across time. We show that this objective is stabilized through a novel training curriculum, ensuring the model robustly learns meaningful features from low signal-to-noise time series. We demonstrate that learned representations enable strong performance on a variety of downstream tasks even when only using a linear probe. Furthermore, we provide comprehensive scaling analyses indicating more unlabeled data reliably results in out-of-distribution performance gains without domain adaptation.

</details>


### [111] [Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents](https://arxiv.org/abs/2512.11584)
*Stefan Tabakov,Asen Popov,Dimitar Dimitrov,S. Ensiye Kiyamousavi,Vladimir Hristov,Boris Kraychev*

Main category: cs.LG

TL;DR: 提出Atomic Action Slicing (AAS)方法，将长时程演示分解为短时原子动作，提升VLA模型泛化能力，在LIBERO数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在需要新技能或物体组合的任务上泛化能力差，需要更好的动作分解方法来提升规划和学习效果。

Method: 提出原子动作切片方法，将长时程演示分解为短时、类型化的原子动作，生成带动作类型、时间跨度和置信度标签的数据集，并用更强的分割模型匹配规划器定义的计划。

Result: 在LIBERO-Goal上任务成功率从94.2%提升到95.3%，在LIBERO-Long上从83.8%提升到88.8%，并公开了GATE-VLAP数据集。

Conclusion: 原子动作切片方法能有效提升VLA模型的泛化能力，特别是在需要新组合的任务上，为规划和学习提供了更好的基础。

Abstract: Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)

</details>


### [112] [Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration](https://arxiv.org/abs/2512.11587)
*Alexander Tyurin*

Main category: cs.LG

TL;DR: 论文通过将梯度下降在神经网络训练中的步骤简化为广义感知机算法，揭示了非线性模型相比线性模型能实现更快的迭代复杂度，解释了神经网络中的隐式加速现象。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络训练中梯度下降的优化动态（包括收敛速度、迭代轨迹、函数值振荡，特别是隐式加速现象）是一个具有挑战性的问题。论文旨在通过新的视角分析这些动态。

Method: 使用逻辑损失分析非线性模型，将梯度下降步骤简化为广义感知机算法（Rosenblatt, 1958）。利用经典线性代数工具分析简化后的算法步骤，并通过一个最小化示例进行理论证明。

Result: 理论证明在两层模型中，非线性可以产生 $\tilde{O}(\sqrt{d})$ 的迭代复杂度，而线性模型只能达到 $Ω(d)$，其中 $d$ 是特征数量。这解释了神经网络中观察到的优化动态和隐式加速现象。数值实验支持了理论结果。

Conclusion: 通过将梯度下降简化为广义感知机算法，论文为理解神经网络优化动态提供了新的视角，揭示了非线性带来的加速优势，这一替代视角有望进一步推动神经网络优化研究。

Abstract: Even for the gradient descent (GD) method applied to neural network training, understanding its optimization dynamics, including convergence rate, iterate trajectories, function value oscillations, and especially its implicit acceleration, remains a challenging problem. We analyze nonlinear models with the logistic loss and show that the steps of GD reduce to those of generalized perceptron algorithms (Rosenblatt, 1958), providing a new perspective on the dynamics. This reduction yields significantly simpler algorithmic steps, which we analyze using classical linear algebra tools. Using these tools, we demonstrate on a minimalistic example that the nonlinearity in a two-layer model can provably yield a faster iteration complexity $\tilde{O}(\sqrt{d})$ compared to $Ω(d)$ achieved by linear models, where $d$ is the number of features. This helps explain the optimization dynamics and the implicit acceleration phenomenon observed in neural networks. The theoretical results are supported by extensive numerical experiments. We believe that this alternative view will further advance research on the optimization of neural networks.

</details>


### [113] [A Fast Interpretable Fuzzy Tree Learner](https://arxiv.org/abs/2512.11616)
*Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez*

Main category: cs.LG

TL;DR: 提出一种基于贪心算法的模糊树方法，将传统决策树分裂算法扩展到模糊规则，在保持预测性能的同时显著提升计算效率并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有模糊规则挖掘算法难以同时保证合理的语言分区和小规模规则库，进化方法计算成本过高，而神经方法如ANFIS难以保持语言可解释性。

Method: 将经典决策树分裂算法从清晰规则扩展到模糊树，结合贪心算法的计算效率和模糊逻辑的可解释性优势。

Result: 在表格分类基准测试中，该方法实现了与最先进模糊分类器相当的准确率，同时显著降低计算成本，并产生具有约束复杂度的更可解释规则库。

Conclusion: 提出的模糊贪心树方法成功平衡了预测性能、计算效率和可解释性，为可解释决策系统提供了实用解决方案。

Abstract: Fuzzy rule-based systems have been mostly used in interpretable decision-making because of their interpretable linguistic rules. However, interpretability requires both sensible linguistic partitions and small rule-base sizes, which are not guaranteed by many existing fuzzy rule-mining algorithms. Evolutionary approaches can produce high-quality models but suffer from prohibitive computational costs, while neural-based methods like ANFIS have problems retaining linguistic interpretations. In this work, we propose an adaptation of classical tree-based splitting algorithms from crisp rules to fuzzy trees, combining the computational efficiency of greedy algoritms with the interpretability advantages of fuzzy logic. This approach achieves interpretable linguistic partitions and substantially improves running time compared to evolutionary-based approaches while maintaining competitive predictive performance. Our experiments on tabular classification benchmarks proof that our method achieves comparable accuracy to state-of-the-art fuzzy classifiers with significantly lower computational cost and produces more interpretable rule bases with constrained complexity. Code is available in: https://github.com/Fuminides/fuzzy_greedy_tree_public

</details>


### [114] [Bridging Streaming Continual Learning via In-Context Large Tabular Models](https://arxiv.org/abs/2512.11668)
*Afonso Lourenço,João Gama,Eric P. Xing,Goreti Marreiros*

Main category: cs.LG

TL;DR: 论文提出使用大型上下文表格模型作为流式持续学习的桥梁，通过将无界数据流压缩为紧凑摘要供模型使用，同时满足流学习的数据压缩需求和持续学习的经验回放需求。


<details>
  <summary>Details</summary>
Motivation: 当前持续学习和流学习研究社区各自为政：CL关注长期记忆但缺乏实时约束，SL强调快速适应但忽视遗忘问题。需要一种统一框架来结合两者的优势，实现既能快速适应数据流变化又能保留历史知识的流式持续学习。

Method: 提出使用大型上下文表格模型作为SCL的核心架构，将无界数据流实时压缩为紧凑摘要（sketches）。基于数据选择的两个核心原则：1）分布匹配（平衡可塑性与稳定性），2）分布压缩（通过多样化和检索机制控制内存大小）。

Result: 论文提出了一个理论框架，将SL和CL的隐含策略统一为"分而治之"方法，管理可塑性（适应当前分布）与稳定性（保留过去知识）之间的张力，同时满足最小复杂度约束。

Conclusion: 大型上下文表格模型为流式持续学习提供了自然桥梁，通过将流学习的数据压缩动机与持续学习的经验回放需求相结合，可以构建更有效的SCL系统。提出的分布匹配和分布压缩原则为设计此类系统提供了理论基础。

Abstract: In streaming scenarios, models must learn continuously, adapting to concept drifts without erasing previously acquired knowledge. However, existing research communities address these challenges in isolation. Continual Learning (CL) focuses on long-term retention and mitigating catastrophic forgetting, often without strict real-time constraints. Stream Learning (SL) emphasizes rapid, efficient adaptation to high-frequency data streams, but typically neglects forgetting. Recent efforts have tried to combine these paradigms, yet no clear algorithmic overlap exists. We argue that large in-context tabular models (LTMs) provide a natural bridge for Streaming Continual Learning (SCL). In our view, unbounded streams should be summarized on-the-fly into compact sketches that can be consumed by LTMs. This recovers the classical SL motivation of compressing massive streams with fixed-size guarantees, while simultaneously aligning with the experience-replay desiderata of CL. To clarify this bridge, we show how the SL and CL communities implicitly adopt a divide-to-conquer strategy to manage the tension between plasticity (performing well on the current distribution) and stability (retaining past knowledge), while also imposing a minimal complexity constraint that motivates diversification (avoiding redundancy in what is stored) and retrieval (re-prioritizing past information when needed). Within this perspective, we propose structuring SCL with LTMs around two core principles of data selection for in-context learning: (1) distribution matching, which balances plasticity and stability, and (2) distribution compression, which controls memory size through diversification and retrieval mechanisms.

</details>


### [115] [High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control](https://arxiv.org/abs/2512.11705)
*Sebastian Hirt,Valentinus Suwanto,Hendrik Alsmeier,Maik Pfefferkorn,Rolf Findeisen*

Main category: cs.LG

TL;DR: 贝叶斯神经网络作为替代模型在优化高维控制器参数时优于高斯过程，能处理数百甚至上千维参数空间


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在控制器参数学习中被广泛应用，但传统高斯过程替代模型难以处理密集高维参数空间（如模型预测控制器调参），需要更有效的替代模型

Method: 使用贝叶斯神经网络作为替代模型，比较了Matern核高斯过程、有限宽度贝叶斯神经网络和无限宽度贝叶斯神经网络在倒立摆任务上的表现

Result: 贝叶斯神经网络替代模型实现了更快速可靠的闭环成本收敛，能成功优化数百维参数化；无限宽度贝叶斯神经网络在超过一千个参数的设置中仍保持性能，而Matern核高斯过程迅速失效

Conclusion: 贝叶斯神经网络替代模型适合学习密集高维控制器参数化，为基于学习的控制器设计中替代模型选择提供了实用指导

Abstract: Learning controller parameters from closed-loop data has been shown to improve closed-loop performance. Bayesian optimization, a widely used black-box and sample-efficient learning method, constructs a probabilistic surrogate of the closed-loop performance from few experiments and uses it to select informative controller parameters. However, it typically struggles with dense high-dimensional controller parameterizations, as they may appear, for example, in tuning model predictive controllers, because standard surrogate models fail to capture the structure of such spaces. This work suggests that the use of Bayesian neural networks as surrogate models may help to mitigate this limitation. Through a comparison between Gaussian processes with Matern kernels, finite-width Bayesian neural networks, and infinite-width Bayesian neural networks on a cart-pole task, we find that Bayesian neural network surrogate models achieve faster and more reliable convergence of the closed-loop cost and enable successful optimization of parameterizations with hundreds of dimensions. Infinite-width Bayesian neural networks also maintain performance in settings with more than one thousand parameters, whereas Matern-kernel Gaussian processes rapidly lose effectiveness. These results indicate that Bayesian neural network surrogate models may be suitable for learning dense high-dimensional controller parameterizations and offer practical guidance for selecting surrogate models in learning-based controller design.

</details>


### [116] [SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning](https://arxiv.org/abs/2512.11760)
*Aditya Tripathi,Karan Sharma,Rahul Mishra,Tapas Kumar Maiti*

Main category: cs.LG

TL;DR: SpectralKrum是一种联邦学习防御方法，通过谱子空间估计结合几何邻居选择来抵御拜占庭攻击，在非IID数据分布下比传统防御方法更有效。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中拜占庭客户端可能注入恶意更新破坏全局模型，现有防御方法在数据分布异构（非IID）且攻击者能观察防御机制时效果显著下降。

Method: SpectralKrum结合谱子空间估计和几何邻居选择：1) 从历史聚合中学习低维流形；2) 将更新投影到学习到的子空间；3) 在压缩坐标中应用Krum选择；4) 过滤正交残差能量超过数据驱动阈值的候选者。

Result: 在CIFAR-10非IID数据（Dirichlet分布，alpha=0.1）上评估，SpectralKrum在方向性和子空间感知攻击（adaptive-steer, buffer-drift）中表现优异，但在标签翻转和min-max攻击中优势有限，因为恶意更新在谱特征上与良性更新难以区分。

Conclusion: SpectralKrum为联邦学习提供了一种无需辅助数据、保护隐私的防御方法，在非IID数据分布下对某些攻击类型有效，但对谱特征相似的攻击类型防御效果有限。

Abstract: Federated Learning (FL) distributes model training across clients who retain their data locally, but this architecture exposes a fundamental vulnerability: Byzantine clients can inject arbitrarily corrupted updates that degrade or subvert the global model. While robust aggregation methods (including Krum, Bulyan, and coordinate-wise defenses) offer theoretical guarantees under idealized assumptions, their effectiveness erodes substantially when client data distributions are heterogeneous (non-IID) and adversaries can observe or approximate the defense mechanism.
  This paper introduces SpectralKrum, a defense that fuses spectral subspace estimation with geometric neighbor-based selection. The core insight is that benign optimization trajectories, despite per-client heterogeneity, concentrate near a low-dimensional manifold that can be estimated from historical aggregates. SpectralKrum projects incoming updates into this learned subspace, applies Krum selection in compressed coordinates, and filters candidates whose orthogonal residual energy exceeds a data-driven threshold. The method requires no auxiliary data, operates entirely on model updates, and preserves FL privacy properties.
  We evaluate SpectralKrum against eight robust baselines across seven attack scenarios on CIFAR-10 with Dirichlet-distributed non-IID partitions (alpha = 0.1). Experiments spanning over 56,000 training rounds show that SpectralKrum is competitive against directional and subspace-aware attacks (adaptive-steer, buffer-drift), but offers limited advantage under label-flip and min-max attacks where malicious updates remain spectrally indistinguishable from benign ones.

</details>


### [117] [The Adaptive Vekua Cascade: A Differentiable Spectral-Analytic Solver for Physics-Informed Representation](https://arxiv.org/abs/2512.11776)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: AVC提出了一种混合架构，通过域扭曲和可微线性求解器，解决了坐标神经网络中的频谱偏差和维度灾难问题，在物理基准测试中实现了参数减少和收敛加速。


<details>
  <summary>Details</summary>
Motivation: 坐标神经网络在表示连续物理场时面临两个基本问题：频谱偏差（阻碍高频动力学学习）和维度灾难（导致离散特征网格参数爆炸）。需要一种既能准确学习高频动态又内存高效的方法。

Method: AVC将流形学习与函数逼近解耦：1）使用深度网络学习物理域的微分同胚扭曲，将复杂时空动力学投影到潜在流形；2）在潜在流形上使用广义解析函数基表示解；3）用可微线性求解器替代标准梯度下降输出层，在前向传播中以闭式形式最优解析频谱系数。

Result: 在五个严格的物理基准测试中（包括高频Helmholtz波传播、稀疏医学重建和非定常3D Navier-Stokes湍流），AVC实现了最先进的精度，同时将参数数量减少了数量级（例如，840参数 vs. 420万参数的3D网格），收敛速度比隐式神经表示快2-3倍。

Conclusion: AVC建立了一种内存高效、频谱准确的科学机器学习新范式，通过结合深度学习和经典逼近理论，有效解决了坐标神经网络的核心病理问题。

Abstract: Coordinate-based neural networks have emerged as a powerful tool for representing continuous physical fields, yet they face two fundamental pathologies: spectral bias, which hinders the learning of high-frequency dynamics, and the curse of dimensionality, which causes parameter explosion in discrete feature grids. We propose the Adaptive Vekua Cascade (AVC), a hybrid architecture that bridges deep learning and classical approximation theory. AVC decouples manifold learning from function approximation by using a deep network to learn a diffeomorphic warping of the physical domain, projecting complex spatiotemporal dynamics onto a latent manifold where the solution is represented by a basis of generalized analytic functions. Crucially, we replace the standard gradient-descent output layer with a differentiable linear solver, allowing the network to optimally resolve spectral coefficients in a closed form during the forward pass. We evaluate AVC on a suite of five rigorous physics benchmarks, including high-frequency Helmholtz wave propagation, sparse medical reconstruction, and unsteady 3D Navier-Stokes turbulence. Our results demonstrate that AVC achieves state-of-the-art accuracy while reducing parameter counts by orders of magnitude (e.g., 840 parameters vs. 4.2 million for 3D grids) and converging 2-3x faster than implicit neural representations. This work establishes a new paradigm for memory-efficient, spectrally accurate scientific machine learning. The code is available at https://github.com/VladimerKhasia/vecua.

</details>


### [118] [Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective](https://arxiv.org/abs/2512.11784)
*Etienne Boursier,Claire Boyer*

Main category: cs.LG

TL;DR: 该论文提出了一个基于测度的统一框架，用于分析softmax注意力机制在有限和无限提示下的行为，证明了在长提示下softmax注意力会收敛到线性注意力，从而可以将线性注意力的优化分析直接应用于softmax注意力。


<details>
  <summary>Details</summary>
Motivation: Softmax注意力是Transformer架构的核心组件，但其非线性结构给理论分析带来了重大挑战。现有研究缺乏对softmax注意力在有限和无限提示下的统一理论框架，特别是在训练动态和统计行为方面的分析。

Method: 开发了一个基于测度的统一框架，研究单层softmax注意力在有限和无限提示下的行为。对于i.i.d.高斯输入，利用softmax算子在无限提示极限下收敛到作用于底层输入标记测度的线性算子这一事实，建立了输出和梯度的非渐近集中界，并证明在上下文学习设置中这种集中性在整个训练轨迹上保持稳定。

Result: 证明了当提示足够长时，softmax注意力会收敛到其线性对应物，使得为线性注意力开发的优化分析可以直接转移到softmax注意力。在上下文线性回归案例中，利用可处理的无限提示动态分析了有限提示长度下的训练。提供了研究softmax注意力层在大提示机制下训练动态和统计行为的原理性工具包。

Conclusion: 该研究为softmax注意力的理论分析提供了统一框架，证明了大提示机制下softmax注意力继承了线性注意力的分析结构，这为研究Transformer中softmax注意力层的训练动态和统计行为提供了理论基础和实用工具。

Abstract: Softmax attention is a central component of transformer architectures, yet its nonlinear structure poses significant challenges for theoretical analysis. We develop a unified, measure-based framework for studying single-layer softmax attention under both finite and infinite prompts. For i.i.d. Gaussian inputs, we lean on the fact that the softmax operator converges in the infinite-prompt limit to a linear operator acting on the underlying input-token measure. Building on this insight, we establish non-asymptotic concentration bounds for the output and gradient of softmax attention, quantifying how rapidly the finite-prompt model approaches its infinite-prompt counterpart, and prove that this concentration remains stable along the entire training trajectory in general in-context learning settings with sub-Gaussian tokens. In the case of in-context linear regression, we use the tractable infinite-prompt dynamics to analyze training at finite prompt length. Our results allow optimization analyses developed for linear attention to transfer directly to softmax attention when prompts are sufficiently long, showing that large-prompt softmax attention inherits the analytical structure of its linear counterpart. This, in turn, provides a principled and broadly applicable toolkit for studying the training dynamics and statistical behavior of softmax attention layers in large prompt regimes.

</details>


### [119] [A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions](https://arxiv.org/abs/2512.11793)
*Ahmad Shamail,Claire McWhite*

Main category: cs.LG

TL;DR: 提出一种几何方法L-score，通过分析元素随机顺序添加时的贡献模式，量化特征间的交互作用（协同、冗余、独立）。


<details>
  <summary>Details</summary>
Motivation: 许多系统存在复杂的组件交互：有些特征相互增强，有些提供冗余信息，有些独立贡献。需要一种统一的方法来发现和量化这些交互模式。

Method: 通过随机顺序添加元素并绘制贡献图，观察L形模式。提出L-score度量，范围从-1（完美协同）到0（独立）到+1（完美冗余）。可视化二维点云，分析特征主导性。

Result: 方法能够区分协同、冗余和独立模式：冗余对形成L形（仅先添加元素贡献），协同对形成L形（仅一起添加时贡献），独立元素显示顺序不变分布。

Conclusion: L-score提供了一种度量无关的统一几何方法，仅需成对测量即可揭示高阶交互，适用于任何可增量评估性能的领域。

Abstract: Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish interaction, independence, and redundancy on a unified scale. When pairwise contributions are visualized as two--dimensional point clouds, redundant pairs form L--shaped patterns where only the first-added element contributes, while synergistic pairs form L--shaped patterns where only elements contribute together. Independent elements show order--invariant distributions. We formalize this with the L--score, a continuous measure ranging from $-1$ (perfect synergy, e.g. $Y=X_1X_2$) to $0$ (independence) to $+1$ (perfect redundancy, $X_1 \approx X_2$). The relative scaling of the L--shaped arms reveals feature dominance in which element consistently provides more information. Although computed only from pairwise measurements, higher--order interactions among three or more elements emerge naturally through consistent cross--pair relationships (e.g. AB, AC, BC). The method is metric--agnostic and broadly applicable to any domain where performance can be evaluated incrementally over non-repeating element sequences, providing a unified geometric approach to uncovering interaction structure.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [120] [Sources of matter for wormholes in a k-essence theory](https://arxiv.org/abs/2512.11018)
*Marcos V. de S. Silva,Carlos F. S. Pereira,Bruna Bragato,Manuel E. Rodrigues,Júlio C. Fabris,H. Belich*

Main category: gr-qc

TL;DR: 在k-essence理论中，通过幻影标量场耦合引力，分析了带电虫洞模型，研究了标量场、势函数和电磁函数，发现零能量条件违反与面积函数参数相关。


<details>
  <summary>Details</summary>
Motivation: 研究k-essence理论中耦合幻影标量场的虫洞模型，探索带电虫洞的物理特性，特别是电磁场与标量场的相互作用。

Method: 采用(3+1)维球对称背景，考虑两种带电系统：电性和磁性。第一种采用广义Ellis-Bronnikov模型，固定k-essence场指数n=1/2，参数m≥2；第二、三种模型调整虫洞面积函数Σ²的参数，同样采用n=1/2。

Result: 获得了任意m≥2参数下的标量场表达式、势函数和电磁函数；展示了零能量条件的违反取决于面积函数的参数。

Conclusion: 在k-essence理论中，虫洞模型的零能量条件违反行为可以通过调整面积函数参数来控制，为理解带电虫洞的物理特性提供了新见解。

Abstract: In this work, we analyze some matter sources associated with wormhole models within a k-essence theory coupled to the gravitational sector through a phantom scalar field. We adopt a spherically symmetric background in (3+1) dimensions and consider two types of systems: electrically and magnetically charged. In the first case, we consider the generalized Ellis-Bronnikov model, in which we fix the k-essence field exponent to $n=1/2$ and take the parameter $m\ge 2$, where $m$ is the parameter that modifies the area of this wormhole model. From this we obtained the expression for the scalar field, the potential, and the associated electromagnetic functions for any values of the parameter $m\geq{2}$. In the second and third models, we consider the scenario of two wormholes that are structured according to the adjustment of the parameters that define their area function $Σ^2$, and in both cases we adopt $n=1/2$. Finally, we show that the violation of the null energy conditions is conditioned by the parameters of the area function.

</details>


### [121] [A well-posed BSSN-type formulation for scalar-tensor theories of gravity with second-order field equations](https://arxiv.org/abs/2512.11034)
*Harry L. H. Shum,Llibert Aresté Saló,Farid Thaalba,Miguel Bezares,Thomas P. Sotiriou*

Main category: gr-qc

TL;DR: 提出了一种适用于修正引力理论的BSSN形式体系，通过修改谐和规范与穿刺规范技术，建立了广义相对论之外的形式体系连接，并在黑洞系统中验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 最近发展的修正谐和规范与修正穿刺规范为超越广义相对论的稳定数值演化提供了新可能。本文旨在利用这些技术推导出与特定修正引力理论兼容的BSSN形式体系。

Method: 利用修正谐和规范与修正穿刺规范的技术，推导出修正的BSSN形式体系。作为中间步骤，还推导了修正的Z4和Z3形式体系，从而在广义相对论之外建立了这些形式体系之间的完整连接。

Result: 通过模拟黑洞系统的动力学，并与修正的CCZ4公式进行基准测试，验证了新修正BSSN形式体系的鲁棒性。

Conclusion: 这一发展为许多使用不同版本穿刺规范方法的数值相对论代码探索超越广义相对论的理论提供了可能。

Abstract: Recent developments in the modified harmonic and modified puncture gauges have opened new possibilities for performing stable numerical evolutions beyond General Relativity. In this work, we utilise techniques developed in the aforementioned formalisms to derive a BSSN-type formalism compatible with certain classes of modified gravity theories. As an intermediate step, we also derived modified versions of the Z4 and Z3 formalisms, thereby completing the connection between these formalisms beyond General Relativity. We then test the robustness of the new modified BSSN formalism by simulating the dynamics of black hole systems and benchmarking the results against the modified CCZ4 formulation. These developments enable the exploration of theories beyond General Relativity in many well-known Numerical Relativity codes that use different versions of the puncture gauge approach.

</details>


### [122] [Gravitational synchronization in bosonic dark matter admixed neutron stars](https://arxiv.org/abs/2512.11044)
*Claudio Lazarte,Nicolas Sanchis-Gual,José A. Font*

Main category: gr-qc

TL;DR: 研究暗物质与中子星的相互作用，通过数值模拟发现费米子-玻色子星中两种成分通过引力耦合同步振荡，产生新的多态标量构型和改变中子星径向模式层次结构。


<details>
  <summary>Details</summary>
Motivation: 暗物质是现代天体物理学和高能物理学的核心研究课题，中子星为研究暗物质与重子物质相互作用提供了天然实验室。本文旨在探索暗物质作为超轻玻色子场与中子星相互作用时形成的复合天体结构。

Method: 将暗物质建模为超轻玻色子场，研究其在中子星上的吸积过程，形成引力束缚的复合天体。采用球对称的长期数值相对论模拟，提取和分析费米子-玻色子星的径向振荡模式频率谱。

Result: 模拟显示费米子和玻色子成分通过引力耦合实现同步，丰富了振荡谱。这种同步导致新的多态标量构型出现，并重塑了中子星径向模式的层次结构。研究还提出了计算新主导模式值作为玻色子质量函数的方法。

Conclusion: 费米子-玻色子星的同步振荡现象为研究暗物质与中子星相互作用提供了新视角，对中子星物理学和引力波天文学具有重要意义，可能为探测暗物质提供新的观测特征。

Abstract: While the search for dark matter remains a central focus of modern astrophysics and high-energy physics, neutron stars provide natural laboratories in which the interaction between dark matter and baryonic matter can be studied. In this work we model dark matter as an ultralight bosonic field, which can accrete onto the neutron star and form a composite object bound through gravity. Using long-term, numerical relativity simulations in spherical symmetry, we extract and analyze the frequency spectra of the radial oscillation modes of fermion-boson stars. Our simulations reveal that the fermionic and bosonic components synchronize through gravitational coupling, enriching their oscillation spectrum. This synchronization leads to new multi-state scalar configurations and reshapes the hierarchy of the neutron-star radial modes. We further propose a procedure to compute the values of the new dominant modes as a function of the bosonic mass, and discuss the implications for neutron-star physics and gravitational-wave astronomy.

</details>


### [123] [Spin in Uniform Gravity, Hidden Momentum, and the Anomalous Hall Effect](https://arxiv.org/abs/2512.11158)
*Andrzej Czarnecki,Ting Gao*

Main category: gr-qc

TL;DR: 该论文回顾了均匀引力场中自旋霍尔效应缺失的讨论，指出尽管哈密顿量形式相似，但与铁磁材料中的反常自旋霍尔效应存在差异


<details>
  <summary>Details</summary>
Motivation: 澄清均匀引力场中自旋霍尔效应的理论讨论，明确其与铁磁材料中反常自旋霍尔效应的区别，避免概念混淆

Method: 通过理论回顾和分析，比较两种不同物理系统中的哈密顿量形式，指出形式相似性背后的物理本质差异

Result: 均匀引力场中不存在自旋霍尔效应，这与铁磁材料中的反常自旋霍尔效应有本质区别，尽管哈密顿量形式相似

Conclusion: 需要仔细区分不同物理系统中的相似数学形式，避免将铁磁材料中的反常自旋霍尔效应错误推广到引力场情形

Abstract: We review the recent discussion of the absence of spin Hall effect in a uniform gravitational field, pointing out differences from the anomalous spin Hall effect in ferromagnetics despite a similar form of the Hamiltonian.

</details>


### [124] [Black hole thermodynamics is gauge independent](https://arxiv.org/abs/2512.11196)
*O. Ramirez,Y. Bonder*

Main category: gr-qc

TL;DR: 论文提出了一种新方法，证明黑洞热力学第一定律在包含挠率和规范自由度的引力理论中不依赖于特定规范选择，从而巩固了该定律作为量子引力指南的地位。


<details>
  <summary>Details</summary>
Motivation: 在包含挠率和规范自由度的引力理论一阶形式中，有人认为黑洞热力学第一定律需要特定的规范选择，这会削弱其基本特性。本文旨在证明第一定律实际上独立于规范选择。

Method: 提出了一种替代方法，比之前使用主纤维丛的方法更直接地建立第一定律的规范独立性。该方法还便于显式计算第一定律，并帮助解决此类分析中常见的几个模糊性。

Result: 成功证明了黑洞热力学第一定律在包含挠率和规范自由度的引力理论中确实独立于规范选择，从而巩固了该定律作为量子引力指南的地位。

Conclusion: 黑洞热力学第一定律作为量子引力研究的重要指导原则，其基本特性不受规范选择的影响。新方法不仅更直接地证明了这一点，还提供了更清晰的计算框架，有助于解决相关分析中的模糊性问题。

Abstract: Black hole thermodynamics provides a rare window into the elusive quantum nature of gravity. In the first-order formalism for gravitational theories, where torsion and gauge freedom are present, it has been suggested that the first law of black hole thermodynamics requires a specific gauge choice, which would undermine its fundamental character. By using principal fiber bundles, it has been shown that the first law is independent of this gauge choice. The present work introduces an alternative method that establishes this independence in a more direct manner, thereby reinforcing the status of the first law as a guide toward quantum gravity. This method also facilitates explicit computations of the first law and helps resolve several ambiguities that commonly appear in such analyses.

</details>


### [125] [Gravitational Wave Detection Based on Gravitomagnetic Effects](https://arxiv.org/abs/2512.11262)
*Yu-Qi Dong,Zhoujian Cao,Yu-Xiao Liu*

Main category: gr-qc

TL;DR: 探索通过监测测试粒子角动量矢量相对方向来探测引力波产生的引力磁效应的可行性，发现当测试粒子具有磁矩时，外加磁场可诱导角动量方向在引力波作用下共振进动，从而放大信号。


<details>
  <summary>Details</summary>
Motivation: 现有引力波探测器主要依赖引力电效应，本文探索通过引力磁效应来探测引力波，以补充现有观测手段。研究测试粒子角动量方向对引力波的响应，特别是所有六种极化模式。

Method: 分析测试粒子相对角动量方向对引力波所有六种极化模式的响应，估计引力波事件期间角动量方向变化的幅度。研究当测试粒子具有磁矩时，施加适当强度的外部磁场如何诱导角动量方向在引力波作用下发生共振进动。

Result: 研究发现，当测试粒子具有磁矩时，施加适当强度的外部磁场可以诱导角动量方向在引力波作用下发生共振进动。这种共振可能显著放大引力波信号，使未来的陀螺仪基探测器能够探测到这些信号。

Conclusion: 通过监测测试粒子角动量方向的相对变化来探测引力波产生的引力磁效应是可行的。基于陀螺仪的探测器可以补充现有的引力波天文台，为引力波探测提供新的途径。

Abstract: In this paper, we explore the feasibility of detecting gravitomagnetic effects generated by gravitational waves, by monitoring the relative orientation of the angular momentum vectors of test particles. We analyze the response of the relative angular momentum direction to all six polarization modes of gravitational waves and estimate the magnitude of its variation during gravitational wave events. Our findings indicate that when test particles possess magnetic moments, applying an external magnetic field of appropriate strength can induce resonant precession of the angular momentum direction under the influence of gravitational waves. This resonance may significantly amplify the gravitational wave signal, potentially enabling its detection with future gyroscope-based detectors. Such detectors would complement existing gravitational wave observatories that rely on gravitoelectric effects.

</details>


### [126] [Vibration Isolation for the Laser Interferometer Lunar Antenna](https://arxiv.org/abs/2512.11268)
*Brett N. Shapiro*

Main category: gr-qc

TL;DR: LILA是一种月球激光干涉仪引力波探测器，旨在填补亚赫兹频段的观测空白，利用月球低地震环境实现亚赫兹引力波探测


<details>
  <summary>Details</summary>
Motivation: 填补空间探测器（毫赫兹）和地面探测器（10赫兹至几千赫兹）之间的观测空白，利用月球极低的地震环境实现亚赫兹频段的引力波探测

Method: 提出两种设计方案：LILA Pioneer使用非悬挂光学系统，依赖月球共振模式响应引力波；LILA Horizon采用悬挂系统实现带内自由浮动测试质量并过滤残余地震背景

Result: 为不同地震背景假设建立了悬挂系统的基准设计，为月球引力波探测器的实现提供了技术方案

Conclusion: LILA概念展示了利用月球低地震环境实现亚赫兹引力波探测的可行性，为填补引力波观测频段空白提供了有前景的解决方案

Abstract: The Laser Interferometer Lunar Antenna (LILA) presents a novel concept for observing gravitational waves from astrophysical sources at sub-Hertz frequencies. Compared to the Earth, the seismic environment of the moon, while uncertain, is known to be orders of magnitude lower, opening the possibility for achieving this sub-Hz band. This band fills the gap between space-based detectors (mHz) and Earth-based detectors (10 Hz to a few kHz). The initial version of LILA, known as LILA Pioneer, calls for non-suspended optics, relying on the moon's resonant modes to respond to gravitational waves. However, the follow-on design, LILA Horizon, requires suspensions to realize in-band free floating test masses and to filter the residual seismic background. This paper will establish baseline designs for these suspensions for different assumptions of the seismic background.

</details>


### [127] [Mixmaster Fluids Near the Big Bang](https://arxiv.org/abs/2512.11375)
*Elliot Marshall*

Main category: gr-qc

TL;DR: 研究T²对称宇宙时空中含非刚体完美流体时奇点附近动力学，发现局域振荡行为，流体速度呈现mixmaster式振荡，导致早期宇宙物质密度局部不均匀性


<details>
  <summary>Details</summary>
Motivation: 研究含非刚体完美流体的宇宙时空在奇点附近的动力学行为，验证广义BKL猜想在非均匀宇宙中的适用性，探索早期宇宙不均匀性的形成机制

Method: 数值研究T²对称宇宙时空，考虑满足线性状态方程p=Kρ的非刚体完美流体（K∈[0,1)），分析奇点附近的动力学行为

Result: 发现奇点附近动力学是局域和振荡的，流体速度呈现mixmaster式振荡，首次在非均匀宇宙学中观察到这种振荡，且流体振荡导致早期宇宙物质密度局部不均匀性的形成

Conclusion: 研究支持广义BKL猜想，揭示了流体振荡在早期宇宙不均匀性形成中的关键作用，为理解宇宙奇点附近动力学提供了新见解

Abstract: We numerically study the approach to the singularity in $\mathbb{T}^{2}$-symmetric cosmological spacetimes containing a non-stiff perfect fluid satisfying a linear equation of state $p=Kρ$, $K \in [0,1)$. Near the singularity, the dynamics are found to be local and oscillatory. In particular, our results show, for the first time, that the fluid velocity in inhomogeneous cosmologies develops mixmaster-esque oscillations consistent with the generalised BKL conjecture of Uggla et al. Moreover, we find these fluid oscillations are responsible for the development of local inhomogeneities in the matter density of the early universe.

</details>


### [128] [A Global Isometric Embedding of the Reissner-Nordström Metric into Pseudo-Euclidean Spacetime](https://arxiv.org/abs/2512.11554)
*A. T. Eberlein,C. N. Pope*

Main category: gr-qc

TL;DR: 本文提出了一个将极大延展的Reissner-Nordström时空全局等距嵌入到九维伪欧几里得时空的方法，解决了先前嵌入只覆盖外视界区域或单个Eddington-Finkelstein坐标片的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然Schwarzschild黑洞视界的坐标奇异性已通过Fronsdal的六维嵌入得到解释，但Reissner-Nordström度规的现有嵌入要么只覆盖外视界外部区域，要么局限于单个Eddington-Finkelstein坐标片，缺乏全局嵌入来描述整个极大延展时空。

Method: 构建了一个九维伪欧几里得时空的全局等距嵌入，使用显式的四维局部坐标表示，并作为高维嵌入时空函数的水平集来描述。相比Fronsdal嵌入，增加了额外的嵌入坐标和项来处理两个视界的存在。

Result: 成功实现了Reissner-Nordström时空的全局等距嵌入，该嵌入在每个视界上都有定义且有限，能够完整描述极大延展的时空结构。

Conclusion: 通过九维伪欧几里得时空的全局等距嵌入，证明了Reissner-Nordström度规在视界上的奇异性是坐标奇异性而非本质奇异性，为理解带电黑洞的几何结构提供了新的数学框架。

Abstract: The event horizon of the Schwarzschild black hole has been well studied and the singular behavior of the Schwarzschild metric on horizon is understood as a coordinate singularity rather than an essential singularity. One demonstration of this non-singular behavior on horizon was provided by Fronsdal in 1959, by finding a global isometric embedding of the Schwarzschild metric into a six-dimensional pseudo-Euclidean spacetime. Isometric embeddings for the Reissner-Nordström metric have also been constructed, but they only embed the region external to the inner horizon or in a single Eddington-Finkelstein patch. This paper presents a global isometric embedding for the maximally extended Reissner-Nordström spacetime into a nine-dimensional pseudo-Euclidean spacetime. We present the solution in terms of explicit local four-dimensional coordinates, and also as a level-set of functions of the higher-dimensional embedding spacetime. While the Reissner-Nordström embedding presented has several similarities to the Fronsdal embedding of the Schwarzschild metric, the presence of the second horizon requires additional embedding coordinates and terms not found in the Fronsdal embedding, in order that the embedding is defined and finite on each horizon.

</details>


### [129] [Gravitational Foundations and Exact Solutions in $n$--Dimensional Fractional Cosmology](https://arxiv.org/abs/2512.11583)
*S. M. M. Rasouli,J. Marto,D. Oliveira,P. Moniz*

Main category: gr-qc

TL;DR: 本文提出了三种理论可行的分数阶标量场宇宙学模型构建方法，选择了时间依赖核加权作用量，在n维FLRW度规和广义Sáez-Ballester理论基础上建立了分数阶宇宙学模型，研究了引力结构特征、精确解析解，并提出了进一步推广的新思路。


<details>
  <summary>Details</summary>
Motivation: 构建分数阶标量场宇宙学模型，研究分数阶理论对宇宙学的影响，探索与传统标准模型的区别，并寻找可能的反弹宇宙解。

Method: 1) 提出三种理论可行的分数阶标量场宇宙学模型构建技术，选择时间依赖核加权作用量方法；2) 在n维FLRW度规和广义Sáez-Ballester理论基础上建立分数阶宇宙学模型；3) 分析场方程的动力学行为、Bianchi恒等式、守恒定律和Noether定理；4) 获得精确解析解并分析关键宇宙学量的时间演化；5) 提出进一步推广模型的新思路。

Result: 建立了分数阶标量场宇宙学模型，分析了其引力结构特征，获得了精确解析解，研究了积分常数、时空维数和分数阶参数的影响，并与标准模型和观测数据进行了比较。

Conclusion: 成功构建了分数阶标量场宇宙学模型，揭示了分数阶理论在宇宙学中的独特特征，为研究反弹宇宙解提供了新思路，为进一步推广分数阶宇宙学模型奠定了基础。

Abstract: Three theoretically plausible techniques to developing a fractional scalar field cosmological model are pointed in this paper; the time-dependent kernel weighted action being then selected. Upon this choice, we proceed to establish a fractional cosmological model in $n$ dimensions considering the FLRW metric and a generalized version of the Sáez-Ballester (SB) theory. Our study focuses on the following purposes. Firstly, to investigate the fundamental gravitational structural features of the model, we analyze the dynamical behavior of the field equations, the fulfillment of the Bianchi identities, the associated conservation laws, and the application of the second Noether theorem at the background and first-order perturbation levels. Moreover, the model's distinguishing characteristics and theoretical differences from the corresponding standard scenarios are also investigated.
  Secondly, we aim to obtain exact analytical solutions and analyze the time evolution of key cosmological quantities, considering the integration constants influence, and the number of spacetime dimensions, and the fractional parameter effects. Furthermore, the model's predictions are compared with those of the corresponding standard models and observational data.
  Lastly, we propose new ideas to further generalize our model, with a focus on constructing an effective potential and investigating the conditions under which bounce solutions may emerge.

</details>


### [130] [The cosmological volume function](https://arxiv.org/abs/2512.11626)
*Leonardo García-Heveling*

Main category: gr-qc

TL;DR: 本文证明了在多数感兴趣的情况下，宇宙体积函数τ_V是连续可微的时间函数，这导致度规张量的规范分裂，并诱导出规范的"Wick旋转"黎曼度规。


<details>
  <summary>Details</summary>
Motivation: 在先前工作中引入了正则宇宙体积函数τ_V作为Andersson、Galloway和Howard的正则宇宙时间函数的替代。本文旨在进一步研究τ_V的性质及其在时空几何中的应用。

Method: 通过数学分析证明在多种感兴趣的情况下，τ_V是连续可微的时间函数。利用这一性质推导度规张量的规范分裂，并构造相应的Wick旋转黎曼度规。

Result: 证明了τ_V在多数情况下是连续可微的时间函数，这导致度规张量的规范分裂，并诱导出规范的Wick旋转黎曼度规。还提供了与宇宙时间和体积函数相关的进一步结果和例子。

Conclusion: 宇宙体积函数τ_V具有比先前预期更好的正则性，可作为宇宙时间函数的有效替代，为时空几何分析提供了新的工具和视角。

Abstract: In a previous work, the regular cosmological volume function $τ_V$ was introduced as an alternative to the regular cosmological time function of Andersson, Galloway, and Howard. In this paper, we show that in many cases of interest, $τ_V$ is a continuously differentiable temporal function. This leads to a canonical splitting of the metric tensor, and induces a canonical ``Wick-rotated" Riemannian metric. We also provide some further results and examples related to the cosmological time and volume functions.

</details>


### [131] [Thermodynamics of Black Holes, far from Equilibrium](https://arxiv.org/abs/2512.11659)
*Abhay Ashtekar,Daniel E. Paraizo,Jonathan Shu*

Main category: gr-qc

TL;DR: 该论文推广了黑洞热力学定律，提出了适用于远离平衡态黑洞的新第一定律（涉及物理过程的有限变化）和定量化的新第二定律（将动力学视界面积变化与落入黑洞的能量通量联系起来）。


<details>
  <summary>Details</summary>
Motivation: 经典的黑洞热力学第一定律只描述平衡态附近的无穷小变化，不涉及具体物理过程；第二定律是定性陈述（视界面积不减少）。作者希望推广这些定律，使其适用于远离平衡态的黑洞，并建立与物理过程的直接联系。

Method: 作者在广义相对论框架下，将第一定律推广到适用于任意远离平衡态的黑洞，涉及物理过程引起的有限变化。第二定律则从定性陈述转化为定量关系，将动力学视界面积的变化与落入黑洞的能量通量直接联系起来。

Result: 提出了两个新的黑洞力学定律：1）新第一定律适用于一般相对论中的黑洞，可处理远离平衡态的情况，描述物理过程引起的有限变化；2）新第二定律是定量关系，将动力学视界面积的变化与落入黑洞的能量通量相关联。

Conclusion: 该工作成功推广了黑洞热力学定律，建立了更普适的框架：新第一定律连接了黑洞的有限变化与物理过程，新第二定律提供了视界面积变化的定量描述。这些推广使黑洞力学定律更贴近实际物理过程。

Abstract: As in thermodynamics, the celebrated first law of black hole mechanics relates infinitesimal changes in the properties of nearby equilibrium states of black holes (without reference to any physical process that causes the transition). The second law is a qualitative statement that the area of an event horizon cannot decrease under appropriate physical assumptions. These laws are generalized. The new first law applies to black holes in general relativity that can be arbitrarily far from equilibrium and refers to \emph{finite} changes that occur due to \emph{physical processes}. The new second law is a \emph{quantitative} statement that relates the change in the dynamical horizon area with the flux of energy falling into the black hole in a physical process.6

</details>


### [132] [Cosmic Acceleration from Quantum Gravity: Emergent Inflation and Dynamical Dark Energy](https://arxiv.org/abs/2512.11712)
*Luca Marchetti,Tom R. Ladstätter,Daniele Oriti*

Main category: gr-qc

TL;DR: 量子引力理论中的群场理论模型通过平均场近似产生宇宙加速机制，可解释暗能量或早期暴胀


<details>
  <summary>Details</summary>
Motivation: 探索量子引力理论如何自然产生宇宙加速现象，包括暗能量和早期暴胀，避免传统暴胀理论的优雅退出问题

Method: 采用群场理论模型的平均场近似方法，分析不同相互作用类型对宇宙动力学的影响

Result: 根据相互作用类型，该机制可产生暗能量相（常表现为幻影行为）或早期慢滚暴胀，后者能自然过渡到经典非加速相

Conclusion: 量子引力效应可统一解释宇宙加速现象，为暗能量和暴胀提供自然机制，避免传统暴胀理论的优雅退出问题

Abstract: We present a mechanism for the emergence of cosmic acceleration within the mean-field approximation of Group Field Theory models of quantum gravity. Depending on the interaction type, the resulting cosmological dynamics can either feature a late-time attractor corresponding to a dynamical dark energy phase, often with characteristic phantom behavior, including in models inspired by simplicial gravity, or instead support an early slow-roll inflationary epoch driven by the same underlying quantum-gravitational effects. This emergent inflation, effectively captured by a single-field description, can sustain the required expansion, naturally avoids the graceful exit problem, and appears to transition into a persistent, non-accelerating phase consistent with classical expectations.

</details>
