<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 29]
- [quant-ph](#quant-ph) [Total: 69]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]
- [cs.LG](#cs.LG) [Total: 140]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [Exploring Hybrid Star Models with Quark and Hadronic Matter in $f(Q)$ Gravity](https://arxiv.org/abs/2601.00929)
*M. Sharif,Madiha Ajmal*

Main category: gr-qc

TL;DR: 在f(Q)引力框架下，使用Finch-Skea度规构建包含奇异夸克物质和强子物质的静态各向异性混合星模型，分析EXO 1785-248的物理特性


<details>
  <summary>Details</summary>
Motivation: 研究f(Q)引力理论能否有效描述混合星（包含奇异夸克物质和强子物质）的宏观物理性质，探索非度量性引力框架下致密天体的行为

Method: 1. 在f(Q)引力框架下求解场方程；2. 使用Finch-Skeas度规；3. 奇异夸克物质采用MIT袋模型状态方程；4. 强子物质采用线性状态方程；5. 选取EXO 1785-248作为研究对象；6. 分析五个不同耦合常数取值；7. 通过图形分析各种物理特性

Result: 1. 成功构建了f(Q)引力下的混合星模型；2. 分析了度量分量、能量密度、径向和切向压强、各向异性等关键物理量；3. 检验了能量条件、稳定性判据（致密性、红移、因果条件、Herrera开裂、绝热指数、TOV方程）；4. 发现f(Q)引力能有效描述混合星的宏观性质

Conclusion: f(Q)引力理论框架能够有效描述包含奇异夸克物质和强子物质的混合星的宏观物理特性，为研究致密天体提供了新的理论工具

Abstract: In this paper, we develop a model for a static anisotropic hybrid star that includes strange quark matter and hadronic matter. We solve the field equations in the $f(Q)$ gravity framework (where $Q$ is the non-metricity) using the Finch-Skea metric. The relationship between density and pressure for strange quark matter is described using the MIT bag model equation, while for hadronic matter, the radial pressure and density are related by a linear equation of state. We select the compact star EXO 1785-248 and analyze five different values of the coupling constant. To evaluate the physical feasibility of the model, we perform a graphical analysis of key properties, including the metric components, energy density, radial and tangential pressures, anisotropy, gradients, quark matter density and pressure, the equation of state parameter, energy conditions and the mass function. We further examine the stability and equilibrium of the star through parameters such as compactness, redshift, causality conditions, Herrera cracking, the adiabatic index and the Tolman-Oppenheimer-Volkoff equation. We observe that $f(Q)$ gravity effectively describes the macroscopic properties of hybrid stars.

</details>


### [2] [Tidal perturbations of an extreme mass ratio inspiral around a Kerr black hole](https://arxiv.org/abs/2601.00954)
*Marta Cocco,Gianluca Grignani,Troels Harmark,Marta Orselli,David Pereñiguez,Maarten van de Meent*

Main category: gr-qc

TL;DR: 本文通过度量重构技术，计算了受外部潮汐场影响的克尔黑洞的度量，并推导了测试粒子在潮汐变形克尔时空中的长期运动哈密顿量，特别计算了最内稳定圆轨道和光环的潮汐诱导偏移。


<details>
  <summary>Details</summary>
Motivation: 研究旋转黑洞在外部潮汐场作用下的度量变形，为极端质量比旋近系统的长期潮汐效应提供分析框架，对引力波建模和强场引力测试有直接应用价值。

Method: 采用Newman-Penrose形式体系，求解Teukolsky主方程得到静态四极模式，在出射辐射规范下重构相应的度量扰动，推导测试粒子在潮汐变形克尔时空中的长期运动哈密顿量。

Result: 潮汐修正具有强烈的自旋依赖性，对于快速旋转黑洞的逆行轨道效应显著更大；计算了最内稳定圆轨道和光环的潮汐诱导偏移，为旋转黑洞时空中的潮汐相互作用和长期动力学提供了完全解析框架。

Conclusion: 本文建立了研究旋转黑洞潮汐相互作用的完整解析框架，结果可直接应用于引力波建模和强场引力测试，特别适用于极端质量比旋近系统的长期动力学研究。

Abstract: We determine the metric of a Kerr black hole subject to external tidal fields using metric reconstruction techniques. Working within the Newman-Penrose formalism, we solve the Teukolsky master equation for static, quadrupolar modes associated with a slowly varying tidal environment, and reconstruct the corresponding metric perturbation in the outgoing radiation gauge. As an application, we derive the secular Hamiltonian governing the motion of a test particle in the tidally deformed Kerr spacetime and investigate long-term tidal effects relevant to extreme-mass-ratio inspirals. In particular, we compute tidal-induced shifts of the innermost stable circular orbit and the light ring. We find that these tidal corrections are strongly spin dependent, with significantly larger effects for retrograde orbits around rapidly rotating black holes. Our results provide a fully analytic framework for studying tidal interactions and secular dynamics in rotating black-hole spacetimes, with direct applications to gravitational-wave modeling and tests of gravity in the strong-field regime.

</details>


### [3] [Cosmological redshift of a Schwarzschild-de Sitter black hole: Towards estimating the Hubble constant](https://arxiv.org/abs/2601.00989)
*Deborah Villaraos,Alfredo Herrera-Aguilar,Mehrab Momennia,Ulises Nucamendi*

Main category: gr-qc

TL;DR: 该研究首次将考虑宇宙膨胀的Schwarzschild-de Sitter度规应用于实际天体物理系统，通过分析活动星系核中黑洞吸积盘的运动学，同时估计黑洞质量、距离和哈勃常数。


<details>
  <summary>Details</summary>
Motivation: 传统黑洞参数估计通常忽略宇宙膨胀效应，而该研究旨在开发一个包含宇宙膨胀的广义相对论框架，更准确地估计活动星系核中黑洞的参数。

Method: 推导了Schwarzschild-de Sitter黑洞中圆轨道粒子发射光子的红移表达式，首次将该理论模型应用于哈勃流中的megamaser星系，使用基于马尔可夫链蒙特卡洛方法的贝叶斯推断来估计参数。

Result: 成功估计了多个活动星系核中黑洞的质量、距离、发射体角位置和哈勃常数，提供了一个不同于标准经验哈勃定律的广义相对论框架。

Conclusion: 该研究建立了一个包含宇宙膨胀效应的新框架，能够更准确地估计黑洞参数，为未来天体物理观测提供了改进的理论基础。

Abstract: We estimate the parameters of several astrophysical black holes hosted at the core of active galactic nuclei by studying the kinematics of test objects in their accretion disk. We derive an expression for the redshift of photons emitted by a massive particle circularly orbiting a Schwarzschild-de Sitter black hole, and detected by a distant receding observer. The redshift depends on the mass and distance of the black hole, the orbital radius of the photon source, as well as the Hubble constant, directly relating these quantities to astrophysical observables, namely, the redshift and the angular position of the test particle on the sky. We apply for the first time this theoretical model, which accounts for the universe expansion through the Schwarzschild-de Sitter metric, to real astrophysical systems using megamaser galaxies within the Hubble flow. Bayesian inference based on Markov Chain Monte Carlo methods is employed to estimate the black hole mass, its distance, the angular position of the emitter, and the Hubble constant, for which a Gaussian prior is assumed. Our results introduce a general relativistic framework to take the contribution of cosmic expansion into account that differs from the standard empirical Hubble law.

</details>


### [4] [Gauge-Invariant Gravitational Wave Polarization in Metric f(R) Gravity with Cosmological Implications](https://arxiv.org/abs/2601.01028)
*Ramesh Radhakrishnan,David McNutt,Delaram Mirfendereski,Alejandro Pinero,Eric Davis,William Julius,Gerald Cleaver*

Main category: gr-qc

TL;DR: 在度规f(R)引力中，特别是修正的Starobinsky模型下，作者建立了完全规范不变的分析框架，研究引力波极化模式。发现张量部分保持广义相对论的两个横向无迹极化，而标量部分则产生由质量标量传播模式决定的呼吸-纵向极化模式。


<details>
  <summary>Details</summary>
Motivation: 研究度规f(R)引力理论中的引力波极化模式，特别是修正的Starobinsky模型，该模型在常曲率解下为早期和晚期宇宙学提供了自然的de Sitter背景。目标是建立完全规范不变的分析框架，连接引力波现象学与宇宙学观测。

Method: 1. 在de Sitter背景上线性化场方程；2. 推导曲率扰动的Klein-Gordon方程；3. 使用标量-矢量-张量(SVT)分解和扰动Ricci张量分解；4. 建立完全规范不变的传播方程；5. 通过测地偏离方程（在局部Minkowski补丁和完全协变的de Sitter形式中计算）验证极化内容。

Result: 1. 张量部分保持广义相对论的两个横向无迹极化；2. 标量部分支持由质量标量传播模式决定的呼吸-纵向模式；3. 标量传播模式获得质量，表明同一标量自由度既控制高曲率下的暴胀动力学，又控制当前加速宇宙中引力波的传播；4. 通过测地偏离方程独立恢复了相同的极化内容并识别了其潮汐特征。

Conclusion: 建立了一个统一的、规范不变的框架，将额外的标量极化与宇宙学可观测量连接起来，为度规f(R)引力的引力波现象学和宇宙学含义提供了重要联系。该框架表明，同一标量自由度在早期宇宙暴胀和当前宇宙加速膨胀中都起着关键作用。

Abstract: We develop a fully gauge invariant analysis of gravitational wave polarizations in metric f(R) gravity with a particular focus on the modified Starobinsky model, whose constant curvature solution provides a natural deSitter background for both early and late time cosmology. Linearizing the field equations around this background, we derive the Klein Gordon equation for the curvature perturbation and show that the scalar propagating mode acquires a mass, highlighting how the same scalar degree of freedom governs inflationary dynamics at high curvature and the propagation of gravitational waves in the current accelerating Universe. Using the scalar vector tensor (SVT) decomposition and a decomposition of the perturbed Ricci tensor, we obtain a set of fully gauge invariant propagation equations that isolate the contributions of the scalar, vector, and tensor modes in the presence of matter. We find that the tensor sector retains the two transverse traceless polarizations of General Relativity, while the scalar sector supports a massive breathing-longitudinal mode determined by the massive scalar propagating mode. Through the geodesic deviation equation, computed both in a local Minkowski patch and in fully covariant de Sitter form, we independently recover the same polarization content and identify its tidal signatures. The resulting framework connects the extra scalar polarization to cosmological observables, providing a unified, gauge invariant link between gravitational wave phenomenology and the cosmological implications of metric f(R) gravity.

</details>


### [5] [Area discreteness, Lorentz covariance and Hilbert space non-separability](https://arxiv.org/abs/2601.01198)
*Madhavan Varadarajan*

Main category: gr-qc

TL;DR: 量子空间面积离散性与洛伦兹变换幺正实现的相容性研究


<details>
  <summary>Details</summary>
Motivation: 探索在LQG类型量子化中，量子空间面积离散性如何与洛伦兹变换的幺正实现相协调，这是量子引力理论中的一个重要问题。

Method: 使用参数化场理论（PFT）——二维平直时空上自由标量场理论的微分同胚不变重表述，在LQG类型量子化框架下进行研究。

Result: 通过Hilbert空间的不可分性（LQG表示的特征性质），证明了量子空间面积离散性与洛伦兹变换幺正实现的相容性。

Conclusion: Hilbert空间的不可分性可能对应于观察者视角的差异，为量子引力理论提供了新的物理解释。

Abstract: We show how quantum discreteness of spatial area is consistent with a unitary implementation of Lorentz boosts in an LQG type quantization of a diffeomorphism invariant reformulation of free scalar field theory on 2d flat spacetime known as Parameterized Field Theory (PFT). This consistency is a result of Hilbert space non-separability which is a characteristic feature of LQG representations. Our results suggest a possible interpretation of Hilbert space non-separability in terms of observer perspectives.

</details>


### [6] [On the Properties of the Power-Law Cosmological Solutions in Lovelock Gravity](https://arxiv.org/abs/2601.01275)
*Sergey Pavluchenko*

Main category: gr-qc

TL;DR: 在Lovelock引力中，Kasner宇宙学解的性质：二次和三次Lovelock引力中高阶幂律解可同时作为未来和过去渐近点，但四次及以上Lovelock引力中高阶Kasner解不能作为过去渐近点


<details>
  <summary>Details</summary>
Motivation: 研究Lovelock引力中Kasner宇宙学解的特性，特别是探索高阶幂律解作为渐近点的能力是否仅限于二次和三次Lovelock引力，还是Lovelock引力的普遍特征

Method: 分析Lovelock引力中的Kasner宇宙学解，比较不同阶数（二次、三次、四次及以上）Lovelock引力中高阶幂律解的行为特性

Result: 从四次Lovelock引力开始，在所有更高阶Lovelock引力中，高阶Kasner解不能作为过去渐近点，这既阻止了从过去到未来的平滑过渡，也可能阻碍实现可行的紧致化

Conclusion: 高阶Kasner解作为过去渐近点的能力是二次和三次Lovelock引力的独特特征，而非Lovelock引力的普遍性质，四次及以上Lovelock引力中这一特性消失

Abstract: In this paper we study the properties of Kasner cosmological solutions in Lovelock gravity. Recent progress in the investigation of flat cosmological models in Lovelock gravity unveiled the fact that in quadratic (Gauss--Bonnet) and cubic Lovelock gravities, the higher-order power-law solutions could play the role of both future and past asymptotes, and under some conditions, there could exist a smooth transition between them. So it is natural to question if this feature is unique to Gauss--Bonnet and cubic Lovelock gravities, or if it is a general feature of Lovelock gravity. Our analysis suggests that starting from quartic and in all higher-order Lovelock gravities, the high-order Kasner solution cannot play the role of a past asymptote, not only preventing the abovementioned transition from happening, but also potentially hindering the possibility of reaching viable compactification.

</details>


### [7] [On the Emergence of Einstein's Gravity from f(R) Gravity through Cosmological Evolution](https://arxiv.org/abs/2601.01395)
*Gahan Chattopadhyay,Soumitra Sengupta*

Main category: gr-qc

TL;DR: f(R)=R+αR^n 引力模型在宇宙演化中会动态冻结额外标量自由度，最终退化为爱因斯坦引力加宇宙学常数项


<details>
  <summary>Details</summary>
Motivation: 研究f(R)引力理论作为解释早期暴胀和晚期宇宙加速膨胀的纯引力方法，特别关注R+αR^n这类模型在宇宙演化中的行为

Method: 考虑f(R)=R+αR^n引力理论及其在爱因斯坦框架下的对偶标量张量理论，在均匀各向同性宇宙背景下分析正负整数n值的情况

Result: f(R)理论的额外标量自由度（在爱因斯坦框架中表现为标量场）会因宇宙演化而动态冻结，最终只保留爱因斯坦-希尔伯特项和最多一个宇宙学常数项

Conclusion: 所有R+αR^n引力模型都不可避免地通过宇宙演化退化为纯爱因斯坦引力加宇宙学常数项，这意味着这类修正引力理论在宇宙演化中会失去其修正特征

Abstract: $f(R)$-Gravity, a simple generalization of Einstein's General theory of Relativity has been considered in the context of Cosmology as one of the approaches to explain phenomena such as early-time inflation and late-time accelerated expansion of the Universe purely from the Gravity sector. In this work, we have considered a class of $f(R)$-Gravity theories with $f(R)=R+αR^n$ and it's dual scalar tensor theory in the Einstein frame. We have shown that in an isotropic and homogeneous background, for both positive and negative integral values of $n$, the extra scalar degree of freedom of the $f(R)$-theory (manifested as the scalar field in the Einstein frame action) dynamically freezes out due to cosmological evolution, resulting in the survival of only the Einstein-Hilbert term and a cosmological constant at most. This implies that all gravity models given as $R + αR^n$ inevitably evolve into pure Einstein gravity with a cosmological constant term through cosmological evolution.

</details>


### [8] [Repetitive Penrose Process in Accelerating Kerr Black Holes](https://arxiv.org/abs/2601.01414)
*Xiao-Xiong Zeng,Ke Wang*

Main category: gr-qc

TL;DR: 研究加速克尔黑洞中的重复彭罗斯过程，发现加速因子增强了能量提取能力，能量利用效率可超过50%，与普通克尔黑洞不同。


<details>
  <summary>Details</summary>
Motivation: 探索加速克尔黑洞中重复彭罗斯过程的特性，特别是加速因子对能量提取过程的影响，比较与普通克尔黑洞的差异。

Method: 回顾加速克尔黑洞理论，研究该时空中彭罗斯过程的基本方程，分析重复过程的停止条件，并进行数值计算。

Result: 加速克尔黑洞在重复彭罗斯过程中表现出更强的能量提取能力；能量利用效率可超过50%（之前研究难以超过50%）；当加速因子初始值较大时，可提取能量可降至接近零。

Conclusion: 加速克尔黑洞的重复彭罗斯过程与普通克尔黑洞有显著差异：能量提取能力更强，效率更高，但加速因子较大时会抑制能量提取；减少的可提取能量主要转化为提取能量而非不可约质量。

Abstract: This paper investigates the repetitive Penrose process in accelerating Kerr black holes and explores the influence of the acceleration factor on the repetitive Penrose process. After a brief review of accelerating Kerr black holes, we study the fundamental equations of the Penrose process in this spacetime, examine the stopping conditions required for the repetitive Penrose process, and obtain corresponding numerical results. The conclusions indicate that, apart from the third law of thermodynamics similar to previous cases, accelerating Kerr black holes exhibit stronger energy extraction capabilities compared to Kerr black holes during the repetitive Penrose process. Moreover, in prior studies, the energy utilization efficiency was difficult to exceed $50\%$. However, in accelerating Kerr black holes, when the decay radius is relatively small, the energy utilization efficiency can exceed $50\%$, indicating that the reduced extractable energy primarily transforms into extracted energy rather than irreducible mass. On the other hand, when the initial value of the acceleration factor is large, the extractable energy can decrease to nearly zero, which also differs from the case of Kerr black holes in previous studies.

</details>


### [9] [A universal upper bound on the photon sphere radius in higher-dimensional black holes](https://arxiv.org/abs/2601.01451)
*Yiting Cen,Yong Song,Jiaqi Fu*

Main category: gr-qc

TL;DR: 推导了任意维度(n≥4)静态球对称渐近平坦黑洞时空中光子球半径的普适上界，要求各向异性物质场满足弱能量条件且能动张量迹非正


<details>
  <summary>Details</summary>
Motivation: 研究高维引力理论中光子球半径的普适性质，为理解高维时空结构提供理论基础

Method: 使用有效势方法，在满足弱能量条件且能动张量迹非正的各向异性物质场条件下，推导光子球半径的上界

Result: 得到光子球半径上界：r_γ ≤ [(n-1)M]^(1/(n-3))，其中n为维度，M为ADM质量。四维时简化为r_γ ≤ 3M，与已知结果一致

Conclusion: 该工作给出了维度依赖的光子球半径上界，深化了对高维引力理论中时空结构的理解

Abstract: In this work, we derive a universal upper bound for the photon sphere radius in static, spherically symmetric, asymptotically flat black hole spacetimes of arbitrary dimension $n\ge 4$, in the presence of an anisotropic matter field satisfying the weak energy condition and a non-positive trace of the energy-momentum tensor. Using the effective potential method, we obtain the bound $r_γ\le [(n-1)M]^{\frac{1}{n-3}}$, where $M$ is the ADM mass of the black hole. This bound reduces to $r_γ\le 3M$ in four dimensions, consistent with the known result in the literature. Our result provides a dimension-dependent upper bound for photon spheres and deepens the understanding of spacetime structure in higher-dimensional gravitational theories.

</details>


### [10] [Quantum dust cores of rotating black holes](https://arxiv.org/abs/2601.01506)
*Tommaso Bambagiotti,Roberto Casadio*

Main category: gr-qc

TL;DR: 将黑洞几何中的尘埃核心量子描述从球对称推广到旋转几何，研究角动量对核心尺寸和有效内部几何的影响


<details>
  <summary>Details</summary>
Motivation: 先前工作仅限于球对称情况，需要将量子尘埃核心描述推广到旋转黑洞几何，以研究角动量对核心结构的影响

Method: 通过量子化尘埃粒子的测地线运动，找到相应的多体基态，将球对称方法推广到旋转几何

Result: 展示了角动量对核心尺寸和有效内部几何的影响，为旋转黑洞提供了量子尘埃核心描述

Conclusion: 成功将量子尘埃核心框架扩展到旋转黑洞几何，角动量显著影响核心结构和内部几何

Abstract: A quantum description of dust cores for black hole geometries can be obtained by quantising the geodesic motion of dust particles and finding the corresponding many-body ground state. We here generalise previous works in spherical symmetry to rotating geometries and show the effect of angular momentum on the size of the core and effective interior geometry.

</details>


### [11] [Electric Penrose process in the spacetime of a quantum-corrected Reissner-Nordström black hole](https://arxiv.org/abs/2601.01508)
*Jiawei Chen,Jinsong Yang*

Main category: gr-qc

TL;DR: 研究带电粒子在协变量子修正Reissner-Nordström黑洞时空中的电Penrose能量提取过程，分析量子修正对能量提取效率、粒子轨迹和逃逸条件的影响。


<details>
  <summary>Details</summary>
Motivation: 探索量子修正对黑洞能量提取过程的影响，研究量子修正如何改变带电粒子的动力学行为，为区分经典和量子修正的Reissner-Nordström黑洞提供可能的运动学特征。

Method: 首先推导带电粒子在量子修正黑洞周围的运动方程和有效势，然后研究Penrose过程，分析广义能层边界如何受粒子电荷、角动量和量子参数ζ影响，计算能量提取效率，并研究分裂后带电粒子的后续运动。

Result: 量子参数ζ会轻微改变粒子轨迹，但在特定初始条件下能定性改变结果：在经典时空中能逃逸的粒子在量子修正时空中可能被捕获。量子修正对Penrose过程有阻碍作用，且在特定简化条件下，分裂产生的碎片粒子总能携带更多能量返回远处观测者。

Conclusion: 量子修正对Penrose能量提取过程有阻碍效应，提供了区分经典和量子修正Reissner-Nordström黑洞的潜在运动学特征，量子效应能显著改变粒子的逃逸行为。

Abstract: In this paper, we study the electric Penrose energy extraction for charged particles in the spacetime of a covariant quantum-corrected Reissner-Nordström black hole. We first derive the equations of motion and effective potential for charged particles around the black hole. Subsequently, we investigate the Penrose process for such particles, analyze how the generalized ergoregion boundary is influenced by the particle's charge, angular momentum, and the quantum parameter $ζ$, and calculate the energy-extraction efficiency. We then investigate the subsequent motion of charged particles in the electric Penrose process, and rigorously prove that under specific simplified conditions, the resulting fragment particle can always carry more energy back to a distant observer--a conclusion applicable to a wide range of charged black hole models. Finally, we examine a special class of the electric Penrose process, wherein the initial particle cannot escape the black hole, but the high-energy fragment produced through splitting may still escape successfully. Moreover, it is observed that $ζ$ slightly alters the particle trajectories, but under specific initial conditions, it can qualitatively change the outcome: a particle that escapes in the classical Reissner-Nordström black hole spacetime may become trapped in the quantum-corrected one. These results demonstrate the obstructive effect of quantum corrections on the Penrose process and provide potential kinematic signatures to distinguish quantum-corrected from classical Reissner-Nordström black holes.

</details>


### [12] [Cauchy Data for Formation of Multiple Black Holes with Prescribed ADM Parameters](https://arxiv.org/abs/2601.01517)
*Dawei Shen,Jingbo Wan*

Main category: gr-qc

TL;DR: 提出了一个简单的光滑渐近平坦真空初始数据构造，用于模拟相对论性N体坍缩系统，可以独立指定每个组分的ADM能量、线性动量和角动量，满足类时条件E>|P|。初始数据不含陷俘面，未来发展包含多个因果独立的陷俘区域，这些区域从初始切片的局部子集动态形成。


<details>
  <summary>Details</summary>
Motivation: 构建能够模拟相对论性多体坍缩系统的初始数据，特别是要能够独立控制每个组分的物理参数（能量、动量、角动量），并研究这种系统中多个黑洞形成的动力学过程。

Method: 采用简单的构造方法，生成光滑的渐近平坦真空初始数据。数据满足类时条件E>|P|，确保每个组分在物理上合理。初始数据设计为不含陷俘面，但未来演化会自然形成陷俘区域。

Result: 成功构造了满足要求的初始数据，这些数据在演化中会产生多个因果独立的陷俘区域（黑洞形成区域）。对于分离良好的坍缩组分和相对运动的情况，最大发展预期会产生包含多个黑洞的时空。

Conclusion: 该工作提供了一种简洁的方法来构造相对论性多体坍缩系统的初始数据，能够独立控制各组分参数，并为研究多黑洞形成动力学提供了理论基础。

Abstract: We give a simple construction of smooth, asymptotically flat vacuum initial data modeling a relativistic collapsing $N$--body system, with independently prescribed ADM energy, linear momentum, and angular momentum for each component, subject to the timelike condition $\E>|¶|$. The initial data contain no trapped surfaces, and the future development contains multiple causally independent trapped regions that dynamically form from localized subsets of the initial slice. In particular, the maximal development of data with well-separated collapsing components and relative motion is expected to yield spacetimes containing multiple black holes.

</details>


### [13] [Constraining Lorentz Violation in Kalb-Ramond Gravity via Thermodynamics and Gravitational Wave Analysis](https://arxiv.org/abs/2601.01557)
*Nikko John Leo S. Lobos*

Main category: gr-qc

TL;DR: 研究嵌入自发Kalb-Ramond背景的静态球对称黑洞的观测特征，发现洛伦兹破坏参数l会抑制光学阴影半径并增强准正规模频率，利用EHT数据对Sgr A*给出l≲0.19的约束。


<details>
  <summary>Details</summary>
Motivation: 探索Kalb-Ramond场背景下黑洞的观测特征，特别是洛伦兹对称性破坏如何影响黑洞的几何和动力学性质，为通过黑洞观测约束普朗克尺度物理提供途径。

Method: 将黑洞解归一化到物理可观测质量M_phys，分析KR黑洞的热力学和几何效应，利用EHT对Sgr A*的观测数据约束洛伦兹破坏参数l。

Result: KR黑洞热力学与广义相对论一致，熵-面积定律无偏差；但参数l使光学阴影半径抑制√(1-l)倍，准正规模频率增强1/√(1-l)倍；基于EHT数据对Sgr A*给出l≲0.19的约束。

Conclusion: 虽然阴影半径与环降频率的乘积与广义相对论简并，但阴影大小的特异性抑制为利用当前和未来视界尺度成像约束普朗克尺度物理提供了可行途径。

Abstract: We investigate the observational signatures of a static, spherically symmetric black hole embedded in a spontaneous Kalb-Ramond (KR) background. By normalizing the solution to the physically observable mass $M_{\text{phys}}$, we demonstrate that the thermodynamics of the KR black hole are consistent with General Relativity, with no deviations in the entropy-area law. However, the Lorentz-violating parameter $l$ induces distinct geometric effects: it suppresses the optical shadow radius by a factor of $\sqrt{1-l}$ and hardens the quasinormal mode frequency by the inverse factor. Utilizing Event Horizon Telescope (EHT) data for Sagittarius A*, and assuming the mass prior derived from stellar dynamics, we place a constraint of $l \lesssim 0.19$. While the product of the shadow radius and ringdown frequency remains degenerate with General Relativity, the specific suppression of the shadow size offers a viable pathway to constrain Planck-scale physics with current and future horizon-scale imaging.

</details>


### [14] [Exact solutions of the FLRW cosmological model via invariants of the Hamilton-Jacobi method](https://arxiv.org/abs/2601.01574)
*E. Ahmadi-Azar,K. Atazadeh,A. Eghbali*

Main category: gr-qc

TL;DR: 使用哈密顿-雅可比不变量方法求解含宇宙常数Λ的FLRW宇宙学模型场方程，获得两个独立首次积分，并解决变分法逆问题。


<details>
  <summary>Details</summary>
Motivation: 研究FLRW宇宙学模型在宇宙常数Λ存在下的场方程求解问题，通过哈密顿-雅可比不变量方法系统提取首次积分，同时解决变分法逆问题而不依赖Helmholtz条件。

Method: 采用哈密顿-雅可比不变量方法，寻找保持哈密顿正则方程形式不变的变换群，提取两个独立首次积分l_HJ,1和l_HJ,2，通过哈密顿-雅可比方程找到正则变换的生成函数。

Result: 成功获得FLRW模型场方程的通解，同时得到模型的拉格朗日函数和哈密顿函数，揭示了哈密顿函数正则变换群与保持爱因斯坦-弗里德曼动力学方程不变的单参数李群之间的紧密联系。

Conclusion: 哈密顿-雅可比不变量方法与对称群不变量方法相结合，可以建立统一的综合积分理论，为研究宇宙学模型提供系统的方法框架。

Abstract: In this study, we proceed to solve the field equations of the spatially flat Friedman-Lemaitre-Robertson-Walker (FLRW) cosmological model in the presence of the cosmological constant \(Λ\) by making use of the Invariants of Hamilton-Jacobi method (IHJM). This method enables us to extract systematically two independent first integrals such as \(l_{\rm HJ,1}(a,\dot{a})=c_{1}\) and \(l_{\rm HJ,2}(t,a,\dot{a})=c_{2}\) associated to the transformations group keeping the form of the Hamilton's canonical equations (HCEs) of the cosmological model invariant. Extracting these invariants means not only finding the general solution of the field equations of the model, but also obtaining the Lagrangian and Hamiltonian functions for the model whose dynamics acts like the dynamics of a single particle in a one-dimensional mini-super space \(\mathbb{Q}=(a)\). In addition, to obtain the general solution of the model, the IHJM have also solved the inverse problem of calculus of variation (IPCV) without resorting to Helmholtz conditions and whether the necessary conditions for the existence of the Lagrangian function are hold or not. The main part of the IHJM is to find the generating function of the canonical transformation (CT) and then extract two independent invariants for the desired model by using the Hamilton-Jacobi equation (HJE). This study shows that there is a close relationship between the group of the CTs of the Hamiltonian function of the particle and the one-parameter Lie group of transformations keeping invariant the Einstein-Friedmann dynamical equation (EFDE) \(\ddot{a}=F(a,\dot{a})\), so that both of them lead to the same result. In this way, having both the IHJM and the invariants of the symmetry groups method (ISGM), a comprehensive integration theory by unifying them can be achieved for studying the desired models.

</details>


### [15] [Comparison of MOND and Verlinde's emergent gravity in dwarf spheroidals](https://arxiv.org/abs/2601.01715)
*Youngsub Yoon,Sanghyeon Han,Ho Seong Hwang*

Main category: gr-qc

TL;DR: 比较MOND和Verlinde涌现引力在23个矮球状星系中的径向加速度预测，发现Verlinde理论与观测值更吻合，统计显著性达5.2σ


<details>
  <summary>Details</summary>
Motivation: 测试两种替代暗物质的理论（MOND和Verlinde涌现引力）在矮球状星系中的表现，通过比较预测与观测的径向加速度来评估哪种理论更符合观测数据

Method: 分别应用MOND和Verlinde涌现引力计算23个矮球状星系的径向加速度，然后与观测值比较。不仅考虑整体数据集，还分析每个星系的个体表现，计算统计显著性

Result: Verlinde涌现引力在21/23个样本中比MOND更接近观测值趋势。所有23个样本的统计显著性范围从-0.25σ到3.41σ，综合显示Verlinde理论在5.2σ水平上优于MOND

Conclusion: Verlinde的涌现引力理论在解释矮球状星系的径向加速度方面比MOND更符合观测数据，具有5.2σ的统计显著性优势

Abstract: We apply Modified Newtonian Dynamics (MOND) and Verlinde's emergent gravity separately to calculate the radial accelerations in 23 dwarf spheroidals. Then, we compare them with the observed radial accelerations. In our earlier work, we determined that, when the data set is considered in its entirety without isolating individual dwarf spheroidal, Verlinde's emergent gravity is in close agreement with the observed values. In the present work, we additionally confirm that, for 21 of the 23 samples examined, Verlinde's emergent gravity follows the trend of the observed values within each dwarf spheroidal more closely than MOND. Combining the statistical significance of all the 23 samples, ranging from $-0.25σ$ to 3.41$σ$, we conclude that Verlinde's emergent gravity is favored over MOND at 5.2$σ$.

</details>


### [16] [Shadow of a circular disformal Kerr black hole beyond GR](https://arxiv.org/abs/2601.01767)
*Fen Long,Songbai Chen,Jiliang Jing*

Main category: gr-qc

TL;DR: 研究圆形非共形Kerr黑洞的阴影，发现非旋转情况下阴影保持完美圆形且半径与变形参数无关；旋转情况下阴影尺寸随变形参数减小而减小，形状逐渐扁平化，且阴影的南北对称性在观测者离开赤道面时被破坏。


<details>
  <summary>Details</summary>
Motivation: 研究Horndeski引力理论中广义标量-张量框架下的圆形非共形Kerr黑洞阴影特征，探索标量场对黑洞阴影的影响，以增进对该黑洞解和Horndeski引力理论的理解。

Method: 通过分析具有变形参数的圆形非共形Kerr黑洞的阴影，分别研究非旋转和旋转情况下的阴影特性，考察观测者位置（赤道面和南北半球）对阴影形状和对称性的影响。

Result: 非旋转黑洞阴影保持完美圆形且半径与变形参数无关；旋转黑洞阴影尺寸随变形参数减小而减小，形状逐渐扁平化；赤道面观测者看到南北对称的阴影，但离开赤道面时对称性被破坏，阴影几何中心随变形参数符号和观测者半球位置发生特定方向的偏移。

Conclusion: 黑洞阴影中源自标量场的这些特征有助于理解圆形非共形Kerr黑洞和Horndeski引力理论的广义标量-张量框架，为通过观测黑洞阴影探测标量场效应提供了理论依据。

Abstract: We have studied the shadows of a circular disformal Kerr black hole with a deformation parameter, which represents a rotating solution within a generalized scalar-tensor framework of Horndeski gravity that characterized by second-order field equations. Our result show that for the non-rotating case, the shadow remains perfectly circular, with its radius independent of the deformation parameter. For the rotating case, the size of the shadow decreases as the deformation parameter decreases, and the shape of the shadow gradually becomes more flattened. It is worth noting that while the shadow of a rotating black hole remains north-south symmetric for equatorial observers, this symmetry is broken once the observer moves away from the equatorial plane. For an observer in the northern hemisphere, the geometric center of the shadow shifts northward when $D_0<0$ and southward when $D_0>0$, while the opposite behavior occurs for observers in the southern hemisphere. These features in the black hole shadow originating from the scalar field could help us to understand the circular disformal Kerr black hole and generalized scalar-tensor framework of Horndeski gravity.

</details>


### [17] [Adiabatic tides in compact binaries on quasi-elliptic orbits: Radiation at the second-and-a-half relative post-Newtonian order](https://arxiv.org/abs/2601.01794)
*Quentin Henry*

Main category: gr-qc

TL;DR: 计算包含绝热潮汐相互作用的偏心致密双星系统的引力辐射通量和波形，达到相对2.5PN精度，发现潮汐项的偏心修正可能在某些参数空间产生可探测的相位偏移。


<details>
  <summary>Details</summary>
Motivation: 研究偏心致密双星系统的引力波辐射，特别是考虑物质效应（通过绝热潮汐相互作用）对引力波信号的影响，这对于引力波天文学中更精确的波形建模至关重要。

Method: 使用后牛顿近似方法，在相对2.5PN精度下进行计算。基于伴篇论文推导的动力学，首先推导辐射能量和角动量，进而得到轨道元素长期演化的方程。数值求解长期动力学，并计算应变振幅的球谐分解。

Result: 潮汐项的偏心修正会导致相位偏移，在某些引力波源的参数空间内可能被探测到。提供了包含瞬时、尾部和后绝热修正的应变振幅模式，展开到偏心率的12阶，所有相关结果在辅助文件中提供。

Conclusion: 偏心致密双星系统的潮汐相互作用对引力波信号有重要影响，特别是在偏心轨道情况下，这些修正可能对引力波探测和参数估计产生可观测的影响，为未来更精确的波形建模提供了理论基础。

Abstract: We compute the gravitational fluxes and waveform for eccentric compact binaries including matter effects through adiabatic tidal interactions within the post-Newtonian approximation. The computations are performed at the relative 2.5PN order. Using the dynamics derived in the companion paper, we first derive the radiated energy and angular momentum, from which we deduce the equations describing the secular evolution of the orbital elements. We numerically solve for the secular dynamics for various systems. We find that the eccentric corrections to tidal terms induce a dephasing that could potentially be detectable in some regions of the parameter space of gravitational wave sources. Finally, we compute the amplitude of the strain, decomposed in spin-weighted spherical harmonics. Besides the memory contributions that are left for future works, we provide the amplitude modes containing the instantaneous, tail and post-adiabatic corrections expanded to the twelfth order in eccentricity. All relevant results are provided in an ancillary file.

</details>


### [18] [The extended phase space thermodynamics and Ehrenfest scheme for the Kerr-Sen AdS black holes](https://arxiv.org/abs/2601.01814)
*Md Sabir Ali,Arindam Mondal,Sushant G. Ghosh*

Main category: gr-qc

TL;DR: 该论文数值研究了Kerr-Sen-AdS黑洞的视界结构、相变和临界现象，验证了临界点的二阶相变特性，并探讨了Penrose过程能量提取和边界CFT热力学。


<details>
  <summary>Details</summary>
Motivation: 研究Kerr-Sen-AdS黑洞在扩展相空间中的热力学性质，特别是相变行为和临界现象，以理解这类带有伸缩子电荷的黑洞系统的热力学特性。

Method: 采用数值方法分析Kerr-Sen-AdS黑洞的视界结构，定义无量纲参数ε，将质量、温度、体积和吉布斯自由能表示为ε的多项式。通过数值拟合确定临界点，引入Ehrenfest方程验证相变性质，计算比热容、体积膨胀系数和等温压缩率等热力学量。

Result: 发现Kerr-Sen-AdS黑洞在临界点处表现出二阶相变特性，比热容、体积膨胀系数和等温压缩率在临界点发散，Prigogine-Defay比等于1。在适当极限下，临界点表达式退化为Kerr-AdS黑洞的相应结果。

Conclusion: Kerr-Sen-AdS黑洞在临界点处经历二阶相变，其热力学行为与Kerr-AdS黑洞在适当极限下一致。研究还探讨了Penrose过程的能量提取、声速和绝热压缩率，以及边界CFT的热力学量。

Abstract: In the present work, we numerically investigate the horizon structure of the Kerr-Sen black holes in anti-de Sitter (AdS) spacetime. Further, we investigate the phase transitions and critical phenomena in Kerr-Sen-AdS black holes at the critical points. Such black holes are characterized by its mass ($M$), the dilaton charge ($Q$), and the negative cosmological constant, $Λ(<0)$. We define a dimensionless parameter $ε=\bar{J}/{\bar{Q}^2}$ and express the mass, temperature, volume, and Gibbs free energy in terms of $ε$ and its polynomials. Moreover, we numerically fit the data for the critical points and find that in the appropriate limit, the expressions for critical points would correspond to the respective critical points of the Kerr-AdS black hole thermodynamics. Such a study involves a systematic analysis of temperature, Gibbs free energy, and volume in the extended phase space. We provide an analytical verification of the nature of the phase transitions at the critical points by introducing the Ehrenfest equations. We also check that all three quantities, e.g., the specific heat at constant pressure, $C_P$, the volume expansion coefficient, $α$, and the isothermal compressibility, $κ_T$, diverge at the critical points. We find the $Prigogine$-$Defay$ ratio using the expressions of $C_P$, $α$, and $κ_T$, and find that it identically equals unity. Hence, the phase transition behavior of the Kerr-Sen-AdS black holes at their critical points is of second order. In addition, we propose investigating the energy extraction process via the Penrose process. Later, we calculate the speed of sound and adiabatic compressibility for the rotating Kerr-Sen-AdS black holes. Finally, on a specific note, we calculate the thermodynamic quantities of the boundary conformal field theory (CFT) dual to the extended phase space.

</details>


### [19] [The FRW Universe as a van der Waals-like Thermodynamic Heat Engine](https://arxiv.org/abs/2601.01851)
*Haximjan Abdusattar*

Main category: gr-qc

TL;DR: 研究FRW宇宙作为热机的热力学特性，通过相图分析卡诺循环和矩形循环，计算做功和效率


<details>
  <summary>Details</summary>
Motivation: FRW宇宙具有动力学时空特性，在视界上体现热力学性质，并且拥有类似范德瓦尔斯的状态方程。这使得我们可以将FRW宇宙视为热机，研究其热力学循环特性

Method: 基于状态方程推导的相图，研究两种热力学循环：卡诺循环和矩形循环。计算循环过程中的做功，评估相应的热机效率，并绘制效率图

Result: 矩形循环的效率始终低于1且不超过卡诺效率，符合传统热力学原理。建立了FRW宇宙热机的效率图

Conclusion: FRW宇宙可以作为热机进行研究，其热力学行为遵循传统热力学原理，特别是效率上限由卡诺效率决定

Abstract: It is well known that the Friedmann-Robertson-Walker (FRW) universe is a dynamical spacetime, and it has thermodynamics embodied on the apparent horizon. Notably, it also possesses a van der Waals-like equation of state, enabling us to consider thermodynamic cycles and explore the FRW universe's potential as a heat engine. In this paper, we investigate two types of cycles--the Carnot cycle and the rectangular cycle--based on the phase diagram derived from the equation of state, to study the heat engine characteristics of the FRW universe. Furthermore, we calculate the work done and assess the corresponding efficiencies, illustrating the efficiency diagram for the FRW universe's heat engine. We observe that the efficiency of the rectangular cycle consistently remains below unity and never exceeds the Carnot efficiency--the thermodynamic upper limit. This finding aligns with traditional thermodynamic principles governing heat engines.

</details>


### [20] [Regular Black Holes in Quasitopological Gravity: Null Shells and Mass Inflation](https://arxiv.org/abs/2601.01861)
*Valeri P. Frolov,Andrei Zelnikov*

Main category: gr-qc

TL;DR: 研究拟拓扑引力中规则黑洞内部的质量暴胀现象，发现与经典黑洞不同，显著的质量暴胀需要壳层在非常靠近内视界处相交，距离尺度远小于基本长度ℓ。


<details>
  <summary>Details</summary>
Motivation: 研究拟拓扑引力中规则黑洞内部的质量暴胀现象是否持续存在，这些几何具有有界曲率核心和位于基本尺度ℓ附近的内（柯西）视界。

Method: 通过考虑黑洞内部两个球形零壳的碰撞来模拟入射和出射扰动的相互作用，使用Dray-'t Hooft-Barrabes-Israel连接条件推导度规函数和曲率不变量在内视界附近可能显著放大的条件。

Result: 与经典Reissner-Nordström或Kerr几何不同，显著的质量暴胀需要壳层在非常靠近视界的半径处相交，径向分离为r-r* ≲ ℓ(ℓ/r_g)^{2n(D-3)}，对于宏观黑洞r_g≫ℓ，这个距离远小于基本尺度ℓ。

Conclusion: 拟拓扑引力中规则黑洞的质量暴胀现象与经典情况有显著差异，需要极靠近内视界的相互作用条件，这可能导致不同的物理后果。

Abstract: We investigate the phenomenon of mass inflation in the interior of regular black holes arising in quasitopological gravity (QTG). These geometries are characterized by a bounded curvature core and the presence of an inner (Cauchy) horizon located near the fundamental scale $\ell$. To examine whether mass inflation persists in this setting, we model the interaction of ingoing and outgoing perturbations by considering the collision of two spherical null shells inside the black hole. Using the Dray-'t\,Hooft-Barrabes-Israel junction condition, we derive conditions under which the metric function and curvature invariants may experience significant amplification near the inner horizon. Our analysis shows that, unlike in classical Reissner--Nordström or Kerr geometries, significant mass inflation requires shell intersection at radii very close to the horizon, with radial separations from it of the order $r-r_* \lesssim \ell \big(\ell/r_g\big)^{2n(D-3)}$, where $r_g$ is the gravitational radius of the black hole, $D$ is the number of spacetime dimensions and $n\ge 1$ is a parameter depending on a concrete QTG model. For macroscopic black holes with $r_g\gg \ell$ this distance is much smaller than the fundamental scale $\ell$. We discuss possible consequences of this effect.

</details>


### [21] [Bianchi I spacetimes within 4D Einstein-Gauss-Bonnet scalar field theory](https://arxiv.org/abs/2601.01909)
*Alex Giacomini,Chevara Hansraj,Genly Leon,Andronikos Paliathanasis*

Main category: gr-qc

TL;DR: 研究4D爱因斯坦-高斯-博内标量场理论中Bianchi I时空各向异性的演化，发现存在加速解，其中标量场和高斯-博内标量有效扮演宇宙常数角色，恢复了各向异性和各向同性膨胀解以及闵可夫斯基时空。


<details>
  <summary>Details</summary>
Motivation: 研究4D爱因斯坦-高斯-博内标量场理论框架下Bianchi I时空各向异性的演化动力学，探索该引力模型中是否存在加速宇宙解和各向异性解。

Method: 使用无量纲变量建立场方程，结合解析和数值技术研究渐近动力学。对于局部旋转对称情况，解析探索场方程的固定点；对于一般各向异性Bianchi I几何，分析三类不同尺度因子的解。

Result: 发现存在加速解，其中标量场和高斯-博内标量有效扮演宇宙常数角色，恢复了各向异性和各向同性膨胀解以及闵可夫斯基时空。获得一类紧致化Kasner-like解，以及描述背景几何二维分裂的新解族，类似于先前在高维时空中观察到的纯爱因斯坦-高斯-博内理论行为。

Conclusion: 4D爱因斯坦-高斯-博内标量场理论支持加速宇宙解，其中标量场和高斯-博内标量有效扮演宇宙常数，能够恢复各向异性、各向同性膨胀解和闵可夫斯基时空，但该引力模型不支持标度解。

Abstract: We investigate the evolution of anisotropies in Bianchi I spacetimes within the framework of the 4D Einstein-Gauss-Bonnet scalar field theory. The field equations are formulated using dimensionless variables, and the asymptotic dynamics are studied through a combination of analytical and numerical techniques. For the locally rotationally symmetric case, we analytically explore the stationary points of the field equations. The analysis reveals the existence of accelerating solutions in which the scalar field and the Gauss-Bonnet scalar effectively play the role of a cosmological constant. As a result, both anisotropic and isotropic expanding solutions are recovered, along with the Minkowski spacetime. No scaling solutions are supported by the gravitational model. For the general anisotropic Bianchi I geometry with three distinct scale factors, we find that a class of compactified Kasner-like solutions is obtained. In addition, a new family of solutions follows, describing a two-dimensional splitting of the background geometry. This behavior is similar to the previously observed pure Einstein-Gauss-Bonnet theory in higher-dimensional spacetimes.

</details>


### [22] [Cosmological perturbation theory of primordial compact sources](https://arxiv.org/abs/2601.01967)
*Geoffrey Compère,Sk Jahanur Hoque*

Main category: gr-qc

TL;DR: 构建了位置空间的宇宙扰动理论，用于模拟局域化的原初引力波源，在FLRW几何中推导了精确的格林函数和线性度规扰动表达式。


<details>
  <summary>Details</summary>
Motivation: 为了在平坦FLRW宇宙中建模局域化的原初引力波源，需要发展一种避免传统标量-矢量-张量分解的扰动理论，以更有效地处理引力波源问题。

Method: 使用广义谐波规范构建位置空间宇宙扰动理论，在幂律宇宙学中推导精确的格林函数（用超几何函数表示），并求解多极展开到四极矩阶的度规扰动。

Result: 获得了幂律宇宙学中所有度规扰动的精确格林函数，与Chu先前推导的结果一致，并得到了线性度规扰动的闭式表达式，适用于多极展开到四极矩阶的源。

Conclusion: 成功构建了FLRW宇宙中处理局域化引力波源的扰动理论框架，指出源通常不能定义在紧致域中，并提供了精确的解析解工具用于研究原初引力波。

Abstract: We construct a position-space cosmological perturbation theory around spatially flat Friedmann-Lemaître-Robertson-Walker geometries that allows to model localized primordial sources of gravitational waves. The equations of motion are decoupled using a generalized harmonic gauge, which avoids the use of a scalar-vector-tensor decomposition. We point out that sources cannot generically be defined in a compact domain due to fluctuations of the cosmic perfect fluid. For power law cosmologies, we obtain the exact Green's function necessary to solve for all metric perturbations in terms of a hypergeometric function, which matches with a Green's function derived earlier by Chu. This allows us to derive the closed form expression of the linearized metric perturbation generated by sources up to quadrupolar order in the multipolar expansion.

</details>


### [23] [Consistent Truncation of Linearized gravitational waves in de Sitter space-time](https://arxiv.org/abs/2601.02014)
*Ghanashyam Date,Harsh*

Main category: gr-qc

TL;DR: 该论文澄清了在de Sitter背景下引力波多极展开截断的规范一致性问题，修正了先前文献中的错误，并提出了确保截断一致性的通用程序。


<details>
  <summary>Details</summary>
Motivation: 在de Sitter背景下，引力波的多极展开没有像Minkowski背景那样方便的闭式关系，需要截断到特定多极阶数。先前文献中出现了截断不一致的问题，如出现不允许的log(r)项，以及截断解满足波动方程但不满足规范条件的情况。本文旨在澄清这些一致性问题并修正先前文献中的错误陈述。

Method: 通过显式积分规范条件和源守恒方程在共形时间上，分析截断的一致性。提出了确保截断一致性的通用程序，并将该程序应用于完全规范固定解的截断，以说明其一致性。

Result: 澄清了de Sitter背景下引力波多极展开截断的规范一致性问题，修正了先前文献中的错误陈述。提出了一个通用程序来确保截断的一致性，并成功将该程序应用于完全规范固定解的截断，证明了其一致性。

Conclusion: 该研究解决了de Sitter背景下引力波多极展开截断的规范一致性问题，提供了确保截断一致性的系统方法，这对于正确分析引力波观测数据与源动力学之间的关系至关重要。

Abstract: An important step in using observations of gravitational waves from bounded sources is to relate the observed waveforms far away from a source to the local dynamics and environment of the source. To isolate and identify different features of the source, multipole expansion of radiation field as well as that of the source distribution is crucial. Unlike the waves on Minkowski background, those on de Sitter background do not have a convenient, close form relation among these multipoles of arbitrary order to draw general conclusions. This requires truncation to some multipole order to be employed and a consistency issue arises. This was flagged in \cite{CHK} as emergence of disallowed $log(r)$ terms in certain asymptotic forms and a particular quadrupolar truncation was proposed which was consistent with the source conservation.
  In \cite{NKD80}, it was noticed that a truncated solution while satisfying the wave equation, may fail to satisfy the gauge condition. Truncation in a fully gauge fixed form should not generate the unwanted $log(r)$ terms. In this work, we clarify the consistency issue and also correct a couple of erroneous statements in \cite{NKD80}. The consistency is analyzed by explicitly integrating the gauge conditions and the source conservation equations over the conformal time. This gives a general procedure for a consistent truncation. The procedure is applied to truncations of completely gauge fixed solution illustrating its consistency.

</details>


### [24] [O Nature, Where Art Thou?](https://arxiv.org/abs/2601.02140)
*Fay Dowker*

Main category: gr-qc

TL;DR: 论文探讨量子系统中"事件发生位置"问题，指出标准量子力学回答不精确，而费曼历史求和法更适合量子引力研究。


<details>
  <summary>Details</summary>
Motivation: 量子力学标准表述对"事件在何处发生"提供模糊回答，在试图统一引力与量子理论时，这种不精确性成为问题，需要替代方法。

Method: 采用费曼历史求和法，该方法与广义相对论共享"事件"和"历史"基本概念，特别适合量子引力研究。

Result: 费曼历史求和法为解决量子引力中的时空定位问题提供了更合适的框架，因其与广义相对论概念基础一致。

Conclusion: 在统一量子理论与引力时，需要超越标准量子力学表述，费曼历史求和法因其与广义相对论的共同概念基础而成为有前景的替代方案。

Abstract: Where does what happens happen in a quantum system? The standard textbook formulation of quantum mechanics provides a strange, imprecise and yet successful-in-practice answer to this question. In the struggle to unify our understanding of gravity with quantum theory, though, the textbook answer no longer suffices, and an alternative approach is needed. The Feynman Sum Over Histories approach provides an alternative that is particularly suited to quantum gravity because the Sum Over Histories and General Relativity are built on the same fundamental concepts of `event' and `history'.

</details>


### [25] [Discrete vs continuum gravitational diagrams in the soft synchronous gauge](https://arxiv.org/abs/2601.02181)
*V. M. Khatsymovsky*

Main category: gr-qc

TL;DR: 该论文提出了一种在离散Regge引力中处理规范固定和奇点的方法，通过引入软规范固定项和修改导数形式来消除奇点，最终得到与连续情况匹配的传播子。


<details>
  <summary>Details</summary>
Motivation: 由于连续引力的不可重整性，需要在离散的Regge微积分框架下进行微扰展开。离散引力作用量在站点间度规变分下具有领头阶的微分同胚对称性，但需要处理传播子在p₀=0处的奇点问题。

Method: 1. 添加双线性规范固定项来"软"固定同步规范g₀λ = g₀λ⁽⁰⁾ = -δ₀λ；2. 使用混合导数形式：在部分项中使用通常导数Δλ = exp(ipλ)-1代替对称导数Δλ⁽ˢ⁾ = i sin pλ；3. 构造主值型传播子，通过解析延拓处理奇点。

Result: 发现当k=1时，该方法能正确工作并与连续情况匹配。规范固定项所需的鬼场贡献在ε→0时消失。该方法成功消除了传播子在p₀=0处的奇点，并解决了引力子极点加倍问题。

Conclusion: 该方法为离散引力中的微扰计算提供了可行的方案，通过适当的规范固定和导数选择，能够获得与连续理论一致的传播子，为后续的图技术计算奠定了基础。

Abstract: Due to the non-renormalizability of continuum gravity, the perturbative expansion makes sense, say, for its discrete simplicial (Regge calculus) version. The finite-difference form of the gravity action has diffeomorphism symmetry at leading order over metric variations from site to site, and we add a term bilinear in $n^λ( g_{λμ} - g_{λμ}^{(0 ) } )$, $n^λ= [ 1, - \varepsilon ( Δ^{(s ) α} Δ^{(s ) }_α)^{- 1} Δ^{(s ) β} ]$, to "softly" fix the synchronous gauge $g_{0 λ} = g_{0 λ}^{(0 ) } = - δ_{0 λ}$ at $\varepsilon \to 0$, thereby resolving singularities at $p_0 = 0$.
  For the symmetric form of the derivative $Δ^{(s ) }_λ$, the propagator has a graviton pole at $p_0$ close to 0 or $\pm π$ at small $p_α$. This pole doubling compared to the continuum case is removed by using the action $\check{S}_{\rm g}$ with the usual derivative $Δ_λ= \exp ( i p_λ) - 1$ instead of $Δ^{(s ) }_λ= i \sin p_λ$ in some terms, including in the $k$ part of some term, and $Δ^{(s ) }_λ$ in the $1 - k$ part of that term.
  Given the propagator $\check{G} ( n, \overline{n} )$, we form the principal value type propagator $\frac{1}{2} [ \check{G} ( n, n ) + \check{G} ( \overline{n}, \overline{n} ) ]$ by analytically continuing from real $n$. Singularities are roughly resolved as $p_0^{-j} \Rightarrow [ (p_0 + i \varepsilon )^{-j} + (p_0 - i \varepsilon )^{-j} ] / 2$.
  We find that it is $k = 1$ that provides this prescription to properly work and match the continuum case. The gauge-fixing term required for this propagator and its finiteness are considered; the ghost contribution is found to vanish at $\varepsilon \to 0$. The results are used for the diagram technique in our recent paper. The calculations are illustrated by the electromagnetic (Yang-Mills) case.

</details>


### [26] [Optical echoes of light near a black hole](https://arxiv.org/abs/2601.02197)
*Suting Ju,Jingxuan Zhang,Li-Gang Wang*

Main category: gr-qc

TL;DR: 该研究通过模拟引力框架，揭示了黑洞附近脉冲点源的光学回波行为，发现当脉冲持续时间尺度与光子球相当时，会在时域响应中出现连续的"回波尾"，这是脉冲与光子球共振的特征。


<details>
  <summary>Details</summary>
Motivation: 强引力透镜是研究时空几何的有力工具，而实验室模拟模型可用于研究弯曲时空效应和光学器件设计。本研究旨在从波动光学角度探讨动态源与黑洞的相互作用。

Method: 使用模拟引力框架，将史瓦西时空建模为Flamm抛物面，结合解析测地线解和惠更斯-菲涅尔原理计算回波响应。

Result: 发现当脉冲持续时间尺度与光子球相当时，时域响应中会沿着明亮干涉条纹出现连续的"回波尾"。时域和频域分析表明这些回波尾是入射脉冲与光子球共振的特征。

Conclusion: 这项工作为动态源与黑洞相互作用提供了波动光学视角，为强引力透镜研究提供了一个桌面尺度的观察窗口。

Abstract: The light deflection under a strong gravitational field, referred to as strong gravitational lensing, provides a powerful probe of spacetime geometry. Besides, laboratory analogue models are employed to study the effects of curved spacetime and explore the design of optical devices. Here, applying the framework of analogue gravity, we reveal the behavior of the optical echo from a pulsed point-like source near a black hole, which is strongly dependent on the interplay of the black hole's photon sphere and the source's duration. We model the Schwarzschild spacetime as a Flamm paraboloid and calculate the echo response, using analytical geodesic solutions and the Huygens-Fresnel principle. Particularly, when the spatial scale of pulse duration is comparable to the photon sphere, continuous ``echo tails" appear along bright interference fringes in temporal response. Analysis in both the temporal and frequency domains reveals that these echo tails are a signature of resonance between the incoming pulse and the photon sphere. This work provides a wave-optics perspective on the interaction between dynamic sources and black holes, offering a table top window on strong gravitational lensing.

</details>


### [27] [Misinterpreting Spin Precession as Orbital Eccentricity in Gravitational-Wave Signals](https://arxiv.org/abs/2601.02260)
*Snehal Tibrewal,Aaron Zimmerman,Jacob Lange,Deirdre Shoemaker*

Main category: gr-qc

TL;DR: 该研究发现引力波信号中的偏心率和自旋进动参数存在局部退化效应，这种误识别在信号较短时更严重，且对源系统的倾角高度敏感。


<details>
  <summary>Details</summary>
Motivation: 随着引力波探测器范围的扩大，需要探索偏心率和自旋进动这两个关键参数来推断引力波源的起源。然而，参数解释可能受到退化效应的影响，特别是偏心率和自旋进动之间可能存在退化关系，这会妨碍正确测量源参数和推断双星形成过程。

Method: 研究通过分析引力波信号中偏心率和自旋进动参数的可区分性，量化这种退化效应的强度，并识别存在退化的参数空间区域。

Result: 确实存在偏心率和自旋进动之间的退化效应，但这种效应是高度局部化的。误识别的偏心率估计在信号较短时变得更糟，且这种误识别对源系统的倾角高度敏感。研究提供了这种退化效应强度的量化估计。

Conclusion: 偏心率和自旋进动参数之间存在局部退化效应，这会影响引力波源参数的准确测量和双星形成过程的推断。需要开发同时包含自旋进动和偏心率的完整模型来覆盖紧凑双星并合的全部参数空间。

Abstract: The increasing scope and breadth of gravitational wave detectors is providing the opportunity to explore new parameters in gravitational-wave astronomy. Eccentricity and spin-precession are two key observables to infer the origin of a gravitational wave (GW) source. The interpretation of GW source parameters can be plagued by degeneracy, such as the well-known degeneracy between mass and spin. As the field has explored new parameters, questions have been raised about possible degeneracies between eccentricity and spin-precession. Although some state-of-the-art models now include these effects individually, models that incorporate spin-precession and eccentricity are only in their infancy. Until models faithfully cover the complete parameter space of compact binary coalescence, our ability to correctly measure the source parameters and infer the formation of the binary is compromised. Here, we present a study of the distinguishability of these two key parameters. Our work finds that there is indeed a degeneracy between eccentricity and spin-precession; however, it is a highly localized effect. We find that the misidentified eccentricity estimates get worse as the signal gets shorter. Additionally, this misidentification is highly sensitive to the inclination angle of the source system. We provide quantifiable estimates of the potency of this degeneracy in addition to identifying some of the regions of parameter space where this degeneracy exists.

</details>


### [28] [The No-Short Hair Theorem for Black Holes and Wormholes in Extra-Dimension](https://arxiv.org/abs/2601.02261)
*Mandas Biswas*

Main category: gr-qc

TL;DR: 将广义相对论中的无短毛定理推广到后爱因斯坦引力中的高维黑洞和虫洞，并探讨该定理的观测验证如何探测额外维度的存在


<details>
  <summary>Details</summary>
Motivation: 将广义相对论中的无短毛定理扩展到更广泛的引力理论中，特别是包含额外维度的情形，探索通过观测验证该定理来探测额外维度的可能性

Method: 将无短毛定理推广到后爱因斯坦引力理论中的各种高维黑洞和虫洞情形，分析定理在这些扩展情况下的适用性

Result: 成功将无短毛定理推广到高维黑洞和虫洞，发现该定理的观测验证可能成为探测额外维度的工具，并证明在量子引力理论（如弦论）中该定理也成立

Conclusion: 无短毛定理在广义引力理论中具有普适性，其观测验证可作为探测额外维度的新方法，且在排除额外维度的量子引力理论中同样适用

Abstract: The no-short hair theorem for static spherically symmetric black holes in general theory of relativity asserts that if a black hole has hair, that hair must extend beyond the lowest photon sphere radius of the black hole. This report generalizes the theorem to various extra-dimensional cases of black holes and wormholes in post-Einstein gravity and shows how the observational satisfaction of the no-short hair theorem may lead to a probe for the existence of extra-dimensions. We also show how we may lead to argue that this no-short hair theorem is satisfied for black holes in theories of quantum gravity that naturally precludes extra-dimensional cases, like string theory.

</details>


### [29] [The Sequential Monte Carlo goes NUTS: Boosting Gravitational-Wave Inference](https://arxiv.org/abs/2601.02336)
*Gabriele Demasi,Giulia Capurri,Massimo Lenti,Angelo Ricciardone,Barbara Patricelli,Adriano Frattale Mascioli,Lorenzo Piccari,Saulo Albuquerque,Gianluca M. Guidi,Francesco Pannarale,Giulia Stratta,Walter Del Pozzo*

Main category: gr-qc

TL;DR: SHARPy是一个结合SMC并行性和NUTS高效采样的贝叶斯推理框架，用于引力波数据分析，能在10分钟内完成双黑洞事件推断。


<details>
  <summary>Details</summary>
Motivation: 现有引力波推理方法如嵌套采样计算成本高，需要结合SMC的并行性和证据估计能力与NUTS的高维采样效率，以加速贝叶斯推理过程。

Method: SHARPy结合了顺序蒙特卡洛(SMC)的并行性和证据估计能力，以及No-U-Turn Sampler(NUTS)的高效梯度采样，利用后验分布的局部几何结构提高效率，基于JAX框架并GPU加速。

Result: SHARPy能在约10分钟内完成双黑洞事件的引力波推理，产生的后验样本和贝叶斯证据估计与嵌套采样结果一致，显著提升了计算效率。

Conclusion: SHARPy为基于似然方法的引力波推理设立了新里程碑，使模型比较任务能在几分钟内完成，为快速引力波数据分析提供了强大工具。

Abstract: Sequential Monte Carlo (SMC) methods have recently been applied to gravitational-wave inference as a powerful alternative to standard sampling techniques, such as Nested Sampling. At the same time, gradient-based Markov Chain Monte Carlo algorithms, most notably the No-U-Turn Sampler (NUTS), provide an efficient way to explore high-dimensional parameter spaces. In this work we present SHARPy, a Bayesian inference framework that combines the parallelism and evidence-estimation capabilities of SMC with the state-of-the-art sampling performance of NUTS. Moreover, SHARPy exploits the local geometric structure of the posterior to further improve efficiency. Built on JAX and accelerated on GPUs, SHARPy performs gravitational-wave inference on binary black-hole events in around ten minutes, yielding posterior samples and Bayesian evidence estimates that are consistent with those obtained through Nested Sampling. This work sets a new milestone in GW inference with likelihood-based methods and paves the way for model comparison tasks to be accomplished in minutes.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [30] [Sample Complexity for Embedded Multipartite Entanglement Witness via Pauli and Clifford Classical Shadows](https://arxiv.org/abs/2601.00859)
*Ziran Zhang*

Main category: quant-ph

TL;DR: 使用经典影子协议研究估计N量子比特系统中子系统n-部分纠缠见证的样本复杂度，发现局部见证适合Pauli测量，全局见证适合Clifford测量


<details>
  <summary>Details</summary>
Motivation: 多量子比特系统中的多部分纠缠检测需要大量测量，需要开发仅估计选定可观测量且具有可证明效率的协议

Method: 使用经典影子协议，推导系综依赖的方差界限，分析估计子系统n-部分纠缠见证的样本复杂度

Result: 数值模拟确认了不同缩放趋势，显示出从局部见证的Pauli有利性能到全局见证的Clifford有利性能的明显交叉

Conclusion: 纠缠见证的局部性决定了最优测量策略：局部见证适合Pauli测量，全局见证适合Clifford测量，为高效纠缠检测提供了指导

Abstract: Detecting multipartite entanglement in many qubit systems is measurement-intensive, motivating protocols that estimate only selected observables with provable efficiency. In this work we use the classical shadow protocol to study the sample complexity required to estimate a family of subsystem $n$-partite entanglement witness embedded in an larger $N$-qubit system. We derive ensemble dependent variance bounds that lead to qualitatively distinct scaling for the snapshots cost at fixed additive error $ε$ with numerical simulations confirm these trends, exhibiting a clear crossover from Pauli favorable performance for local witness to Clifford favorable performance as the witness becomes more global.

</details>


### [31] [The Quantum State Continuity Problem and Temporal Enforcement Against Fork Attacks](https://arxiv.org/abs/2601.00870)
*Samet Ünsal*

Main category: quant-ph

TL;DR: 提出量子状态连续性问题和见证机制，解决经典和量子认证中的分叉攻击漏洞，通过状态量子和累积审计确保执行连续性


<details>
  <summary>Details</summary>
Motivation: 传统认证机制无法保证系统执行的连续性，存在分叉攻击漏洞。量子状态连续性是一个未被充分探索的安全维度，需要新的机制来确保执行的合法延续

Method: 提出量子状态连续性见证(QSCW)机制，通过状态量子演化和累积审计实现执行的时间链接。使用GHZ态实例化并进行广泛模拟验证

Result: 时间执行机制能指数级抑制分叉攻击的成功概率，同时对噪声和系统参数保持鲁棒性。量子状态连续性成为系统安全的新维度

Conclusion: 执行连续性是一个独特且未被充分探索的系统安全维度，量子状态连续性见证机制能有效解决传统认证机制中的分叉攻击问题

Abstract: We introduce the Quantum State Continuity Problem (QSCP), a security objective orthogonal to identity authentication that captures whether a systems current execution is a legitimate continuation of a unique past execution. We show that classical and stateless quantum authentication mechanisms fail to enforce continuity and remain vulnerable to fork attacks. To address this gap, we propose the Quantum State Continuity Witness (QSCW), a minimal quantum-assisted primitive that enforces temporal linkage of execution through stateful quantum evolution and cumulative auditing. Using a GHZ-based toy instantiation and extensive simulation, we demonstrate that temporal enforcement suppresses fork attacks with exponential decay in success probability, while remaining robust to noise and system parameters. Our results highlight execution continuity as a distinct and underexplored dimension of system security.

</details>


### [32] [Entanglement dynamics of multi-fluxonium-qubits under Non-Markovian TLS noise](https://arxiv.org/abs/2601.00884)
*Chenghong Ji,Chaoying Zhao*

Main category: quant-ph

TL;DR: 针对Fluxonium量子比特中的非马尔可夫TLS噪声，提出了一种优化的动态解耦序列，通过调整脉冲位置最小化噪声功率谱与洛伦兹形状的重叠，显著提升了纠缠门保真度。


<details>
  <summary>Details</summary>
Motivation: Fluxonium量子比特对TLS（双能级系统）噪声敏感，TLS噪声具有显著的非马尔可夫特性，传统动态解耦方法无法有效抑制低频TLS噪声，需要开发专门针对非马尔可夫噪声的解耦协议。

Method: 基于Ornstein-Uhlenbeck过程，提出新型动态解耦序列，通过优化脉冲位置最小化噪声功率谱与洛伦兹形状的重叠，使用PMME（后马尔可夫主方程）一致框架进行建模。

Result: 实现了更强的低频噪声抑制，显著延长了基于Bell态的保真度和纠缠寿命，有效提高了NISQ量子设备中纠缠门的保真度。

Conclusion: 针对非马尔可夫TLS噪声设计的动态解耦协议能够有效改善量子纠缠门的性能，为NISQ时代量子设备的噪声抑制提供了新方法。

Abstract: The research on open quantum systems is important for both quantum computing and quantum sensing. So far, we can only use the main equation to make an approximate description. The dynamics of a single Fluxonium qubit under Markovian environment satisfied Lindblad Master Equation. In experiments, pulse sequence dynamic decoupling (DD) can enhance the coherence of qubits and effectively suppress noise. Two Fluxonium qubits sensitive to two-level systems (TLS) noise. TLS formed by material defects results in noise with significant non-Markovian characteristics. The dynamics of non-Markovian noise satisfied the post Markov Master Equation (PMME). The TLS noise spectrum is mainly concentrated in low frequencies, so traditional DD cannot effectively suppress TLS noise. The relaxation and dephasing behavior with a complex dynamic characteristics. Based on Ornstein-Uhlenbeck process, we put forward a novel DD sequence and design a TLS-tailored dynamical decoupling protocol by optimizing pulse locations to minimize noise power spectral overlap with the Lorentzian shape. Using PMME-consistent framework, we can obtain a stronger low frequency suppression and significantly prolong both Bell-based fidelity and entanglement. We explore specific DD design and precise modeling of entanglement dynamics under non-Markovian TLS noise. Our dynamical decoupling protocol can effectively improve entanglement gates fidelity in NISQ quantum devices.

</details>


### [33] [Four-Photon Interference with a High-Efficiency Quantum Dot Source](https://arxiv.org/abs/2601.00966)
*Alistair J. Brash,Luke Brunswick,Mark R. Hogg,Catherine L. Phillips,Malwina A. Marczak,Timon L. Baltisberger,Sascha R. Valentin,Arne Ludwig,Richard J. Warburton*

Main category: quant-ph

TL;DR: 该研究通过结合先进量子点光源与确定性解复用技术，首次实现了四光子Hong-Ou-Mandel干涉，观测到高达84.1%的干涉对比度，揭示了"深条纹"现象及其在量子计量学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 虽然双光子Hong-Ou-Mandel干涉可见度已成为单光子源的标准度量，但许多光学量子技术需要生成和操纵更大的光子态。目前效率限制阻碍了量子点基干涉扩展到单分束器上超过两个光子的聚束。

Method: 结合最先进的量子点光源与确定性解复用技术，实现了直接观测多达四个光子的量子干涉条纹。通过理论模型完全复现复杂的条纹结构，并进行Fisher信息分析评估相位灵敏度。

Result: 测量到高平均干涉对比度：双光子为93.0±0.1%，四光子为84.1±1.0%。发现了"深条纹"现象，其最小值不受可区分光子的影响，使四光子干涉的最大对比度对多光子发射高度敏感但对光子可区分性具有鲁棒性。

Conclusion: 该研究成功突破了量子点基多光子干涉的规模限制，预测这些现象将扩展到更多光子的干涉，在量子计量学中具有应用潜力，其干涉条纹可表现出超越标准量子极限的相位灵敏度。

Abstract: While two-photon Hong-Ou-Mandel interference visibility has become a standard metric for single-photon sources, many optical quantum technologies require the generation and manipulation of larger photonic states. To date, efficiency limitations have prevented scaling quantum dot-based interference to the coalescence of more than two photons at a single beamsplitter. We overcome this limitation by combining a state-of-the-art quantum dot source with deterministic demultiplexing, enabling the direct observation of quantum interference fringes arising from up to four photons. We measure high mean interference contrasts of $93.0 \pm 0.1~\%$ for two photons, and $84.1 \pm 1.0~\%$ for four photons, with the complex fringe structure fully reproduced by a theoretical model. These results reveal the existence of "deep fringes" whose minima are unaffected by distinguishable photons, rendering the maximum contrast of four-photon interference highly sensitive to multi-photon emission but robust against photon distinguishability. We predict that these phenomena will extend to interference of larger numbers of photons, with relevance across a range of potential optical quantum technologies. A Fisher information analysis demonstrates that interference fringes from our source can exhibit phase sensitivity beyond the standard quantum limit, illustrating potential applications in quantum metrology.

</details>


### [34] [Impersonating Quantum Secrets over Classical Channels](https://arxiv.org/abs/2601.01058)
*Luowen Qian,Mark Zhandry*

Main category: quant-ph

TL;DR: 窃听者通过监听量子方之间的经典通信，最终能够冒充任何一方；如果单向谜题不存在，攻击是高效的。因此，可重复使用的认证方案需要单向谜题。此外，仅通过经典查询验证的量子货币方案无法实现信息论安全。


<details>
  <summary>Details</summary>
Motivation: 研究量子方之间通过经典信道通信时的安全性问题，特别是当量子方可能共享纠缠态时。探索量子货币方案的安全性限制，特别是验证过程仅使用经典查询时的局限性。

Method: 分析窃听者监听经典通信的攻击模型，证明如果单向谜题不存在，攻击是高效的。将结果应用于量子货币方案，证明仅通过经典查询验证的方案无法达到信息论安全。

Result: 1. 窃听者最终能够冒充任何量子方；2. 如果单向谜题不存在，攻击是高效的；3. 可重复使用的认证方案需要单向谜题；4. 仅通过经典查询验证的量子货币方案无法实现信息论安全。

Conclusion: 量子通信中的经典信道认证需要单向谜题作为基础。量子货币方案的验证需要相干评估底层密码工具，这对近期量子设备提出了挑战。这扩展了先前关于随机预言机的研究，适用于更一般的黑盒构造。

Abstract: We show that a simple eavesdropper listening in on classical communication between potentially entangled quantum parties will eventually be able to impersonate any of the parties. Furthermore, the attack is efficient if one-way puzzles do not exist. As a direct consequence, one-way puzzles are implied by reusable authentication schemes over classical channels with quantum pre-shared secrets that are potentially evolving.
  As an additional application, we show that any quantum money scheme that can be verified through only classical queries to any oracle cannot be information-theoretically secure. This significantly generalizes the prior work by Ananth, Hu, and Yuen (ASIACRYPT'23) where they showed the same but only for the specific case of random oracles. Therefore, verifying black-box constructions of quantum money inherently requires coherently evaluating the underlying cryptographic tools, which may be difficult for near-term quantum devices.

</details>


### [35] [Molchanov's Formula and Quantum Walks: A Probabilistic Approach](https://arxiv.org/abs/2601.01071)
*Hoang Vu*

Main category: quant-ph

TL;DR: 论文通过推导连续时间和离散时间量子行走的概率表示，建立了量子动力学与经典动力学之间的稳健联系。


<details>
  <summary>Details</summary>
Motivation: 建立量子动力学与经典动力学之间的联系，为研究量子系统提供新的分析途径，通过经典随机过程来理解量子行走。

Method: 首先将Molchanov公式（最初用于多维整数格上薛定谔算子的研究）应用于连续时间量子行走，然后扩展该框架开发概率方法来表示无限整数线上的离散时间量子行走，绕过Molchanov公式的直接应用限制。

Result: 通过Hadamard行走的基准分析，经验证实了该概率表示的有效性，显示出与传统幺正演化高度一致。结果表明该概率视角为学习多维量子行走提供了强大替代方案。

Conclusion: 该概率表示方法为通过经典随机过程研究量子系统提供了新的分析途径，建立了量子动力学与经典动力学之间的稳健联系。

Abstract: This paper establishes a robust link between quantum dynamics and classical ones by deriving probabilistic representation for both continuous time and discrete time quantum walks. We first adapt Molchanov formula, originally employed in the study of Schrodinger operators on multidimensional integer lattice, to characterize the evolution of continuous time quantum walks. Extending this framework, we develop a probabilistic method to represent discrete time quantum walks on an infinite integer line, bypassing the locality constraints that typically inhibit direct application of Molchanov formula. The validity of our representation is empirically confirmed through a benchmark analysis of the Hadamard walk, demonstrating high fidelity with traditional unitary evolution. Our results suggest that this probabilistic lens offer a powerful alternative for learning multidimensional quantum walks and provides new analytical pathways for investigating quantum systems via classical stochastic processes.

</details>


### [36] [Single-Step Hybrid CV-DV Transfer of Multipartite W States Using Cat-State Qubits](https://arxiv.org/abs/2601.01078)
*Muhammad Nehal Khan,Sumrah Hussain*

Main category: quant-ph

TL;DR: 提出一种确定性混合连续变量-离散变量方案，用于在电路QED架构中单步传输光子薛定谔猫态编码的n-qubit W态


<details>
  <summary>Details</summary>
Motivation: 在电路QED系统中实现高效的多粒子纠缠态传输，避免激发更高原子能级以减少退相干，探索混合CV-DV系统的可扩展性

Method: 使用偶数和奇数宇称猫态编码逻辑量子比特，通过单个超导磁通量子三能级系统在色散区介导谐振器对之间的有效拉曼型相互作用，实现单步集体传输

Result: 基于完整Lindblad主方程的数值模拟显示，三量子比特猫态W态传输的最大保真度约为0.92，考虑了腔耗散、量子三能级系统弛豫和退相干以及腔间串扰等实际因素

Conclusion: 该方案证明了使用当前电路QED技术实现可扩展混合CV-DV纠缠传输的可行性

Abstract: We propose a deterministic hybrid continuous-variable-discrete-variable (CV-DV) scheme for the single-step transfer of an $n$-qubit W state encoded in photonic Schr$\ddot{o}$dinger cat-state qubits within a circuit QED architecture. Logical qubits are encoded in even- and odd-parity cat states of bosonic modes, while effective Raman-type interactions between resonator pairs are mediated by a single superconducting flux qutrit operating in the dispersive regime. The protocol coherently transfers the multipartite W state in a single collective operation without populating higher excited atomic levels, thereby strongly suppressing decoherence. Numerical simulations based on the full Lindblad master equation, including realistic cavity dissipation, qutrit relaxation and dephasing, and inter-cavity crosstalk, show that a three-qubit cat-state W state can be transferred with a maximum fidelity of approximately $0.92$. These results demonstrate the feasibility of scalable hybrid CV-DV entanglement transfer using current circuit QED technology.

</details>


### [37] [Quantum optimisation applied to the Quadratic Assignment Problem](https://arxiv.org/abs/2601.01104)
*Andrew Freeland,Jingbo Wang*

Main category: quant-ph

TL;DR: 本文研究了基于量子行走的非变分优化算法(NV-QWOA)在求解小型二次分配问题(QAP)实例上的性能，并与经典启发式算法(MMAS和GLS)以及Grover量子搜索算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于经典精确方法和当前量子算法的局限性。变分量子算法(VQAs)如QAOA和VQE虽然被广泛研究，但存在参数调优成本高和"贫瘠高原"问题，阻碍了收敛。通过采用非变分方法，本研究探索了一种可能更高效、可扩展的量子组合优化策略。

Method: 使用新兴的非变分量子行走优化算法(NV-QWOA)解决5-10个设施的小型QAP实例。将NV-QWOA与经典启发式算法(最大最小蚂蚁系统MMAS和贪婪局部搜索GLS)以及作为量子基线的Grover量子搜索算法进行基准测试。使用两个指标评估性能：目标函数评估次数和算法迭代次数，要求在不同QAP实例上一致达到最优或接近最优解。

Result: 研究结果提供了经典和量子框架之间的直接比较分析，描述了NV-QWOA的平均性能表现。发现强调了量子行走在复杂组合问题中的实际效用。

Conclusion: 本研究为未来量子优化算法奠定了基础，证明了非变分量子方法在组合优化问题中的潜力，特别是避免了变分量子算法的参数调优和收敛问题。

Abstract: This paper investigates the performance of the emerging non-variational Quantum Walk-based Optimisation Algorithm (NV-QWOA) for solving small instances of the Quadratic Assignment Problem (QAP). NV-QWOA is benchmarked against classical heuristics, the MaxMin Ant System (MMAS) and Greedy Local Search (GLS), as well as the Grover quantum search algorithm, which serves as a quantum baseline. Performance is evaluated using two metrics: the number of objective function evaluations and the number of algorithm iterations required to consistently reach optimal or near optimal solutions across QAP instances with 5 to 10 facilities. The motivation for this study stems from limitations of both classical exact methods and current quantum algorithms. Variational Quantum Algorithms (VQAs), such as QAOA and VQE, while widely studied, suffer from costly parameter tuning and barren plateaus that hinder convergence. By adopting a non-variational approach, this work explores a potentially more efficient and scalable quantum strategy for combinatorial optimisation. The results provide a direct comparative analysis between classical and quantum frameworks, characterising the average case performance of NV-QWOA. Our findings highlight the practical utility of quantum walks for complex combinatorial problems and establish a foundation for future quantum optimisation algorithms.

</details>


### [38] [Non-Markovian and Thermodynamic Signatures in the Classicality Assessment via Kolmogorov Consistency](https://arxiv.org/abs/2601.01122)
*Arghya Maity,Ahana Ghoshal,Kelvin Onggadinata,Teck Seng Koh*

Main category: quant-ph

TL;DR: 该论文建立了Kolmogorov一致性条件违反与开放量子系统非马尔可夫性之间的直接联系，揭示了时间量子关联的信息论和热力学解释。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov一致性条件是区分经典与量子动力学的统计边界，其违反标志着经典马尔可夫描述的失效。研究旨在建立KCC违反与开放量子系统非马尔可夫性之间的直接联系，并探索时间量子关联的信息论和热力学意义。

Method: 在通用的两能级开放量子系统框架内，建立KCC违反幅度与信息论和热力学量（如互信息、法诺因子、热交换和熵产生率）之间的定量联系，并揭示KCC违反与Leggett-Garg不等式、Kirkwood-Dirac准分布负性之间的形式对应关系。

Result: 建立了KCC违反与非马尔可夫性之间的直接解析联系，发现了时间量子关联与信息论、热力学量之间的定量关系，并识别了KCC违反、Leggett-Garg不等式和Kirkwood-Dirac准分布负性作为时间量子非经典性的互补见证。

Conclusion: 该研究提供了一个统一框架，将开放量子系统中量子性的信息论、热力学和时间指标联系起来，为理解时间量子关联的本质提供了新的视角。

Abstract: The Kolmogorov consistency condition (KCC) defines the statistical boundary between classical and quantum dynamics. Its violation signifies the breakdown of a classical Markov description of temporal correlations. In this work, we establish a direct analytical connection between KCC violation and non-Markovianity in open quantum dynamics, revealing how memory effects manifest as departures from classical probabilistic consistency. Within a generic two-level open quantum system framework, we establish quantitative connections between the magnitude of KCC violation and key information-theoretic and thermodynamic quantities, such as mutual information, the Fano factor, heat exchange, and entropy production rate, thereby enabling a thermodynamic interpretation of temporal quantum correlations. Furthermore, we uncover formal correspondences between KCC violation, the Leggett-Garg inequality, and the negativity of the Kirkwood-Dirac quasi-distribution, identifying them as complementary witnesses of temporal quantum non-classicality. Our results thus provide a unified framework linking information-theoretic, thermodynamic, and temporal indicators of quantumness in open quantum systems.

</details>


### [39] [PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations](https://arxiv.org/abs/2601.02233)
*Leon Müller,Adelina Bärligea,Alexander Knapp,Jakob S. Kottmann*

Main category: quant-ph

TL;DR: PauliEngine是一个高性能C++框架，用于高效处理Pauli字符串运算，为量子软件提供可扩展的后端支持。


<details>
  <summary>Details</summary>
Motivation: 量子计算本质上是混合的，需要快速经典计算处理量子比特算符以确保量子软件的可扩展性。

Method: 基于二进制辛表示和优化的位操作，提供Pauli字符串乘法、对易子、符号相位跟踪和结构变换等高效原语，支持数值和符号系数，并提供Python接口。

Result: 运行时基准测试显示相比现有最先进实现有显著加速。

Conclusion: PauliEngine为基于算符的量子软件工具和模拟提供了可扩展的后端。

Abstract: Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.

</details>


### [40] [The Completeness of Eigenstates in Quantum Mechanics](https://arxiv.org/abs/2601.01136)
*Guoping Zhang*

Main category: quant-ph

TL;DR: 该研究系统分析了量子力学中本征态完备性的证明方法，根据势函数在无穷远处的极限分为八种情况，分别提供理论证明或数值模拟，并提出了自由态正交归一化的定义和归一化系数的解法。


<details>
  <summary>Details</summary>
Motivation: 量子力学中本征态的完备性是理论物理的基础问题，但现有证明方法不够系统化。该研究旨在建立一套完整的本征态完备性证明框架，为量子力学理论提供更坚实的数学基础。

Method: 根据势函数在无穷远处的极限行为，将完备性证明分为八种情况。提出了自由态正交归一化的定义和归一化系数的解法，定义了连续能量本征值的谱函数，并将谱函数作为展开函数的原始积分变量。

Result: 建立了八种情况下的完备性证明框架，提供了理论证明或数值模拟。提出的谱函数方法赋予了测量概率振幅与展开函数之间关系以坐标-动量变换的物理意义。

Conclusion: 该研究系统化了量子力学本征态完备性的证明方法，提出的谱函数框架不仅简化了证明过程，还为量子力学中的展开理论提供了新的物理诠释。

Abstract: We delineate the scope of research on the completeness of eigenstates in quantum mechanics. Based on the limit of the potential function at infinity, the proof of completeness is divided into eight cases, and theoretical proofs or numerical simulations are provided for each case. We present the definition of orthonormalization for general free states and the solution to the normalization coefficients, as well as a general set of initial states, which simplifies and concretizes the proof of completeness. Additionally, we define the spectral function for continuous energy eigenvalues. By taking the spectral function as the original integral variable of the expansion function, the relationship between the measured probability amplitude and the expansion function is endowed with the physical meaning of coordinate-momentum transformation.

</details>


### [41] [Constant Depth Digital-Analog Counterdiabatic Quantum Computing](https://arxiv.org/abs/2601.01154)
*Balaganchi A. Bhargava,Shubham Kumar,Anne-Maria Visuri,Paolo A. Erdman,Enrique Solano,Narendra N. Hegade*

Main category: quant-ph

TL;DR: 提出了一种数字-模拟量子计算框架，通过常数深度的电路实现反绝热协议，用于当前量子硬件上的快速、资源高效量子态制备。


<details>
  <summary>Details</summary>
Motivation: 反绝热协议可以抑制有限时间绝热演化中的非绝热激发，但其实际应用受到所需哈密顿量的非局域结构和全数字实现资源开销的限制。

Method: 利用对易子乘积公式在数字-模拟设置中高效实现反绝热项的代数结构，使用原生多量子比特模拟相互作用增强局域单量子比特旋转，实现高阶反绝热协议。

Result: 该方法实现了常数数量的模拟块用于任何固定截断阶数的反绝热协议，与系统尺寸无关，并在二维自旋模型中进行了验证和误差分析。

Conclusion: 数字-模拟量子计算为反绝热协议和相关量子控制原语提供了全新的资源缩放特性，对当前量子设备上的量子模拟、优化和算法态制备有直接意义。

Abstract: We introduce a digital-analog quantum computing framework that enables counterdiabatic protocols to be implemented at constant circuit depth, allowing fast and resource-efficient quantum state preparation on current quantum hardware. Counterdiabatic protocols suppress diabatic excitations in finite-time adiabatic evolution, but their practical application is limited by the non-local structure of the required Hamiltonians and the resource overhead of fully digital implementations. Counterdiabatic terms can be expressed as truncated expansions of nested commutators of the adiabatic Hamiltonian and its parametric derivative. Here, we show how this algebraic structure can be efficiently realized in a digital-analog setting using commutator product formulas. Using native multi-qubit analog interactions augmented by local single-qubit rotations, this approach enables higher-order counterdiabatic protocols whose implementation requires a constant number of analog blocks for any fixed truncation order, independent of system size. We demonstrate the method for two-dimensional spin models and analyze the associated approximation errors. These results show that digital-analog quantum computing enables a qualitatively new resource scaling for counterdiabatic protocols and related quantum control primitives, with direct implications for quantum simulation, optimization, and algorithmic state preparation on current quantum devices.

</details>


### [42] [Harnessing Environmental Memory with Reinforcement Learning in Open Quantum Systems](https://arxiv.org/abs/2601.01252)
*Safae Gaidi,Abdallah Slaoui,Mohammed EL Falaki,Amine Jaouadi*

Main category: quant-ph

TL;DR: 使用强化学习框架增强开放量子系统中的非马尔可夫记忆效应，相比传统最优控制理论能产生更持久的正迹距离增长和更高的非马尔可夫性积分。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫记忆效应是开放量子系统中保持相干性和增强可控性的宝贵资源，但利用这些效应需要适应历史依赖动力学的策略。传统方法在利用这些效应方面存在局限性。

Method: 引入强化学习框架，使用基于Breuer-Laine-Piilo度量的迹距离正时间导数的奖励函数，训练PPO和SAC智能体，并与基于梯度的最优控制理论进行性能对比。

Result: 最优控制理论仅增强单个主导的回流峰值，而强化学习策略能拓宽这一复兴并激活后期记忆窗口中的额外贡献，产生更长时间内持续的正迹距离增长。强化学习实现的非马尔可夫性积分显著超过最优控制理论。

Conclusion: 强化学习能够自然发现分布式回流策略，在工程化开放量子系统的记忆效应方面具有巨大潜力，特别是长时域、无模型学习能够有效利用非马尔可夫特性。

Abstract: Non-Markovian memory effects in open quantum systems provide valuable resources for preserving coherence and enhancing controllability. However, exploiting them requires strategies adapted to history-dependent dynamics. We introduce a reinforcement-learning framework that autonomously learns to amplify information backflow in a driven two-level system coupled to a structured reservoir. Using a reward based on the positive time derivative of the trace distance associated with the Breuer-Laine-Piilo measure, we train PPO and SAC agents and benchmark their performance against gradient-based optimal control theory (OCT). While OCT enhances a single dominant backflow peak, RL policies broaden this revival and activate additional contributions in later memory windows, producing sustained positive trace-distance growth over a longer duration. Consequently, the integrated non-Markovianity achieved by RL substantially exceeds that obtained with OCT. These results demonstrate how long-horizon, model-free learning naturally uncovers distributed-backflow strategies and highlight the potential of reinforcement learning for engineering memory effects in open quantum systems.

</details>


### [43] [Simulating Wigner Localisation with the IBM Heron 2 Quantum Processor: A Proof-of-Principle Benchmarking Study](https://arxiv.org/abs/2601.01263)
*Airat Kiiamov,Dmitrii Tayurskii*

Main category: quant-ph

TL;DR: 使用IBM Heron 2量子处理器在6量子比特环晶格上数字模拟准一维电子系统的维格纳局域化，成功重构2电子维格纳二聚体在15个相互作用区间的基态能景，强相互作用极限下相对误差低于7%。


<details>
  <summary>Details</summary>
Motivation: 将液氦上电子的基础实验模型转化为现代量子计算领域，为使用超导量子硬件精确探测强关联物质相提供原理验证，并为超越经典极限的未来模拟建立基准。

Method: 使用IBM Heron 2量子处理器的6量子比特段，将库仑相互作用哈密顿量映射到6量子比特环晶格上，在U∈[5,75]范围内对15个相互作用区间进行数字量子模拟。

Result: 数字模拟准确捕捉了维格纳二聚体形成的能量最小化趋势，在强相互作用极限下实现了低于7%的相对误差，成功重构了2电子维格纳二聚体的基态能景。

Conclusion: 该研究为使用超导量子硬件高精度探测强关联物质相提供了关键的原理验证，建立了未来超越经典极限模拟的基准，展示了现代量子处理器在量子模拟中的潜力。

Abstract: We report on a high-fidelity digital quantum simulation of Wigner localisation in a quasi-one-dimensional (quasi-1D) electron system using a 6-qubit segment of the state-of-the-art \textbf{IBM\,Heron\,2} quantum processor. By mapping the Coulomb interaction Hamiltonian onto a 6-qubit ring lattice, we reconstruct the ground-state energy landscape for a 2-electron Wigner dimer across fifteen interaction regimes in the range $U \in [5, 75]$. This study serves as a rigorous \textbf{benchmarking} exercise, translating foundational experimental models originally developed for electrons on liquid helium into the domain of modern quantum computing. Leveraging the enhanced gate fidelity and tunable coupler architecture of the Heron 2, we demonstrate that the digital simulation accurately captures the energy minimisation trends associated with Wigner dimer formation, achieving a relative error below 7\% in the strong-interaction limit. Our results provide a crucial \textbf{proof-of-principle} validation for using superconducting quantum hardware to probe strongly correlated phases of matter with high precision, establishing a baseline for future simulations beyond the classical limit.

</details>


### [44] [Thermodynamic analysis of autonomous quantum systems](https://arxiv.org/abs/2601.01272)
*Tiago F. F. Santos,Camille Latune*

Main category: quant-ph

TL;DR: 传统热力学框架将功与外部控制产生的幺正变换引起的能量交换相关联，而热与浴相互作用引起的能量交换相关联。自主量子热力学框架将热力学形式扩展到无外部控制的自主量子系统，识别出传统框架中仅被视为热交换的功交换机制。


<details>
  <summary>Details</summary>
Motivation: 将热力学形式扩展到真正的量子设置（自主量子系统），这些系统没有外部控制，只有量子系统之间的相互作用。传统框架在分析实验中的相互作用量子系统时存在局限性。

Method: 应用自主热力学框架来分析常见的相互作用量子系统的实验情况。该框架识别出传统框架中仅被视为热交换的功交换机制，包括粒子数反转和相干性生成/消耗两种机制。

Result: 自主框架识别出传统框架中仅被视为热交换的功交换机制，包括粒子数反转和相干性生成/消耗。这些机制与ergotropy（功提取能力）相关，验证了自主框架的相关性。还识别出与非热性相关的真正非幺正功交换机制。在半经典极限下，所有能量交换都被识别为纯功，但区分了局部功和相互作用能。

Conclusion: 自主框架为量子领域中的功交换机制提供了精细分析，并作为分析现实量子设备中热力学过程的一致方法。它克服了传统框架的局限性，在真正的量子设置中提供了更全面的热力学描述。

Abstract: Traditional quantum thermodynamic frameworks associate work to energy exchanges induced by unitary transformations generated by external controls, and heat to energy exchanges induced by bath interaction. Recently, a framework was introduced aiming at extending the thermodynamic formalism to genuine quantum settings, also referred to as autonomous quantum systems: free from external controls, only quantum systems interacting with each other. In this paper, we apply such a thermodynamic framework to common experimental situations of interacting quantum systems. In situations where traditional frameworks detect only heat exchanges, the recent autonomous thermodynamic framework points at work exchanges based on two mechanisms: population inversion and coherence generation / consumption. Such mechanisms are well known in the literature for being related to work expenditure and extraction, in particular in relation with ergotropy, which emphasizes the relevance of the autonomous framework and the limitations of traditional ones. Furthermore, the autonomous framework also identifies a genuine non-unitary mechanism of work exchange related to athermality. %, also pointed out as a resource for work extraction. Finally, in the semi-classical limit, the autonomous framework identifies all energy exchanges as pure work, but distinguishes between local work and interaction energy.
  Our results show that the autonomous framework provides a refined analysis of work exchange mechanisms in the quantum realm and serves as a consistent approach to analyze thermodynamic processes in realistic quantum devices.

</details>


### [45] [Assessing the entanglement of three coupled harmonic oscillators](https://arxiv.org/abs/2601.01292)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abderrahim El Allati,Abdallah Slaoui*

Main category: quant-ph

TL;DR: 提出几何对角化方法分析三体耦合谐振子纠缠，推导线性熵和纯度解析表达式，揭示激发水平和混合角对纠缠的影响规律。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是多体系统关联理解的关键现象，但三体耦合谐振子的解析结果稀缺，需要填补这一研究空白。

Method: 引入几何对角化方法，通过约束欧拉角减少纠缠分析自由度，在维格纳函数框架下推导线性熵和纯度的解析表达式。

Result: 任何振子的激发都会增强系统关联的重新分布；混合角θ控制纠缠强度，从可分离到最大关联；发现对称关系，如SLy[(n,m,l),θ]=SLz[(n,m,l),-θ]和(x|yz)分区内的内在对称性。

Conclusion: 阐明了激发水平和混合角在三耦合谐振子中如何创造和增强纠缠，为多体系统纠缠分析提供了新的解析工具。

Abstract: Quantum entanglement serves as a key phenomenon in understanding correlations in many-body systems, but analytical results remain scarce for coupled three-body oscillators. In this work, we address this gap by introducing a geometrical diagonalization approach that constrains Euler angles, thereby reducing the degrees of freedom in the entanglement analysis. It consists of deriving analytical expressions for linear entropy and purity under the bipartitions $(x|yz)$, $(y|xz)$, and $(xy|z)$ using the Wigner function framework. Our results indicate that excitations in any oscillator basically enhance the redistribution of correlations across the system. The mixing angle $θ$ governs entanglement intensity, ranging from separability to maximal correlation. Moreover, we reveal the symmetry relations, notably $S_{Ly}[(n,m,l),θ]=S_{Lz}[(n,m,l),-θ]$ and an intrinsic symmetry within $(x|yz)$. Hence, we clarify how excitation levels and mixing angles create and enhance entanglement in the three coupled harmonic oscillators.

</details>


### [46] [Einstein-Podolsky-Rosen Steering in Three Coupled Harmonic Oscillators](https://arxiv.org/abs/2601.01307)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abdallah Slaoui*

Main category: quant-ph

TL;DR: 该论文通过几何对角化方法研究三体耦合谐振子中的量子导引现象，发现激发态显著增强导引效应，且导引的方向性和拓扑结构由激发的空间分布而非幅度决定。


<details>
  <summary>Details</summary>
Motivation: 量子导引是量子力学中的重要现象，对理解多体系统关联至关重要，但三体耦合谐振子的解析结果仍然稀缺，需要深入研究。

Method: 采用几何对角化方法减少系统自由度，在Wigner函数框架下推导所有可能方向的量子导引解析表达式。

Result: 激发态显著增强系统量子导引，基态(0,0,0)无导引关联；导引的方向性和拓扑结构由激发的空间分布决定而非幅度；在等效激发条件下，x、y、z振子间存在对称导引行为。

Conclusion: 阐明了激发水平和混合角如何在三耦合谐振子中产生和增强量子导引，为理解多体量子关联提供了新的解析见解。

Abstract: Quantum steering is one of the most intriguing phenomena in quantum mechanics and is essential for understanding correlations in multi-body systems. Despite its importance, analytical results for coupled three-body oscillators remain scarce. In this work, we investigate this phenomenon through a geometrical diagonalization approach, which reduces the degrees of freedom associated with the system's steering properties. Specifically, we derive analytical expressions for quantum steering in all possible directions using the Wigner function framework, as it provides a complete description of the system's quantum state. Our results indicate that excitations significantly enhance quantum steering across the system; this stands in contrast to the ground state $(0,0,0)$, which exhibits no steerable correlations. Furthermore, both the directionality and topology of these correlations are governed by the spatial distribution of the excitations rather than their magnitude. We also observe symmetric steering behavior between oscillators $x$, $y$, and $z$ under equivalent excitation conditions, which can be formalized as $S^{(n,m,l)}_{x\to z}(θ)=S^{(n,m,l)}_{x\to y}(-θ),\quad S^{(n,m,l)}_{z\to x}(θ)=S^{(n,m,l)}_{y\to x}(-θ)$, and $S^{(n,m,l)}_{y\to z}(θ)=S^{(n,m,l)}_{z\to y}(-θ)$. Therefore, we elucidate how excitation levels and mixing angles generate and enhance steering in three coupled harmonic oscillators.

</details>


### [47] [Evidence for a two-dimensional quantum glass state at high temperatures](https://arxiv.org/abs/2601.01309)
*Aleksey Lunkin,Nicole S. Ticea,Shashwat Kumar,Connie Miao,Jaehong Choi,Mohammed Alghadeer,Ilya Drozdov,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Alexandre Bourassa,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. Graaf,Alejandro Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Cody Jones,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Dvir Kafri,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Julian Kelly,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joonho Lee,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Ming Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Laura Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Gabrielle Roberts,Roberto Rodriguez,Emma Ropes,Lucia B. Rose,Eliott Rosenberg,Emma Rosenfeld,Dario Rosenstock,Elizabeth Rossi,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Kevin J. Satzinger,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Vladimir Shvarts,Volodymyr Sivak,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Sergio Boixo,Hartmut Neven,Vadim Smelyanskiy,Trond I. Andersen,Pedram Roushan,Mikhail V. Feigelman,Lev B. Ioffe*

Main category: quant-ph

TL;DR: 二维超导量子比特阵列实验发现，在有限温度和中等无序强度下，存在具有玻璃特性的非遍历中间相，表现为物理可观测量分布变宽、部分自由度冻结、希尔伯特空间返回概率幂律衰减，并检测到有限爱德华兹-安德森序参量和自旋扩散消失。


<details>
  <summary>Details</summary>
Motivation: 量子多体系统中的无序可以驱动遍历和非遍历相之间的转变，但这些转变的性质甚至存在性一直存在激烈争议。研究旨在通过实验探索二维系统中无序对量子多体系统动力学的影响。

Method: 使用二维超导量子比特阵列，在无序环境中研究有限温度下的相互作用自旋模型，同时在实空间和希尔伯特空间中追踪动力学行为。

Result: 在广泛的无序范围内观察到具有玻璃特性的中间非遍历相：物理可观测量分布变宽，部分自由度有效冻结；希尔伯特空间返回概率呈现缓慢的幂律衰减；检测到有限的爱德华兹-安德森序参量，自旋扩散消失。而在较低无序时，自旋输运持续存在非零扩散系数。

Conclusion: 实验结果表明，在二维系统中确实存在从遍历相出发的转变，为量子多体系统中的无序诱导相变提供了实验证据。

Abstract: Disorder in quantum many-body systems can drive transitions between ergodic and non-ergodic phases, yet the nature--and even the existence--of these transitions remains intensely debated. Using a two-dimensional array of superconducting qubits, we study an interacting spin model at finite temperature in a disordered landscape, tracking dynamics both in real space and in Hilbert space. Over a broad disorder range, we observe an intermediate non-ergodic regime with glass-like characteristics: physical observables become broadly distributed and some, but not all, degrees of freedom are effectively frozen. The Hilbert-space return probability shows slow power-law decay, consistent with finite-temperature quantum glassiness. In the same regime, we detect the onset of a finite Edwards-Anderson order parameter and the disappearance of spin diffusion. By contrast, at lower disorder, spin transport persists with a nonzero diffusion coefficient. Our results show that there is a transition out of the ergodic phase in two-dimensional systems.

</details>


### [48] [Bond Additivity and Persistent Geometric Imprints of Entanglement in Quantum Thermalization](https://arxiv.org/abs/2601.01327)
*Chun-Yue Zhang,Shi-Xin Zhang,Zi-Xiang Li*

Main category: quant-ph

TL;DR: 提出多二分纠缠层析框架，通过分析所有可能的二分划分来探测纠缠的精细几何结构，发现"键可加定律"将纠缠熵分解为体积律基线和几何修正项，揭示了哈密顿热化与随机量子电路热化的本质区别。


<details>
  <summary>Details</summary>
Motivation: 量子多体系统中的纠缠结构表征是一个核心挑战，标准度量方法常常掩盖了底层的几何细节。需要开发新的框架来揭示纠缠的精细几何结构。

Method: 提出"多二分纠缠层析"框架，通过穷举所有不同的二分划分来探测纠缠结构。核心发现是"键可加定律"，该定律将纠缠熵精确分解为体积律基线和几何修正项之和，几何修正项由交叉键的局部贡献组成。

Result: 该框架将复杂的纠缠景观提炼为一组纠缠键张力{ω_j}，作为相互作用局域性的定量指纹。应用于哈密顿动力学、随机量子电路和Floquet动力学时，发现哈密顿热化态保留了显著的几何印记（非零ω_1），而随机量子电路和Floquet动力学则完全抹去了这种结构。

Conclusion: 多二分纠缠层析为量子多体系统中量子信息的几何结构研究提供了一个通用工具箱，能够区分不同热化机制的几何特征，揭示了哈密顿热化与随机电路热化的本质区别。

Abstract: Characterizing the intricate structure of entanglement in quantum many-body systems remains a central challenge, as standard measures often obscure underlying geometric details. In this Letter, we introduce a powerful framework, termed multi-bipartition entanglement tomography, which probes the fine structure of entanglement across an exhaustive ensemble of distinct bipartitions. Our cornerstone is the discovery of a ``bond-additive law'', which reveals that the entanglement entropy can be precisely decomposed into a bulk volume-law baseline plus a geometric correction formed by a sum of local contributions from crossed bonds of varying ranges. This law distills complex entanglement landscapes into a concise set of entanglement bond tensions $\{ω_j\}$, serving as a quantitative fingerprint of interaction locality. By applying this tomography to Hamiltonian dynamics, random quantum circuits, and Floquet dynamics, we resolve a fundamental distinction between thermalization mechanisms: Hamiltonian thermalized states retain a persistent geometric imprint characterized by a significantly non-zero $ω_1$, while this structure is completely erased in random quantum circuit and Floquet dynamics. Our work establishes multi-bipartition entanglement tomography as a versatile toolbox for the geometric structure of quantum information in many-body systems.

</details>


### [49] [Quantum Kaczmarz Algorithm for Solving Linear Algebraic Equations](https://arxiv.org/abs/2601.01342)
*Nhat A. Nghiem,Tuan K. Do,Trung V. Phan*

Main category: quant-ph

TL;DR: 提出基于Kaczmarz方法的量子线性系统求解算法，不依赖矩阵条目查询，在某些条件下实现指数级电路深度改进


<details>
  <summary>Details</summary>
Motivation: 现有量子线性求解器通常需要查询矩阵条目的oracle访问，这在实际应用中构成关键瓶颈。Kaczmarz方法因其简单性和低内存成本在实际应用中广泛使用，但缺乏相应的量子实现

Method: 基于经典Kaczmarz方法的量子算法，每次迭代通过强制满足一个方程来更新解。当系统秩较小且矩阵行具有适当结构时，算法复杂度与稀疏度s无关；对于任意结构行，使用额外辅助量子比特实现对数级深度增长

Result: 在秩较小且行结构适当时，电路复杂度为O(1/ε·log m)，不依赖稀疏度s，可能也不依赖条件数κ。对于任意结构行，电路深度为O(1/ε·log s)，使用O(s)辅助量子比特。当s=O(log m)时，相比现有算法实现指数级电路深度改进

Conclusion: 该量子Kaczmarz算法突破了现有量子线性求解器的关键瓶颈，不依赖矩阵条目查询，在特定条件下实现了显著的复杂度改进，为实际应用提供了更实用的量子线性系统求解方案

Abstract: We introduce a quantum linear system solving algorithm based on the Kaczmarz method, a widely used workhorse for large linear systems and least-squares problems that updates the solution by enforcing one equation at a time. Its simplicity and low memory cost make it a practical choice across data regression, tomographic reconstruction, and optimization. In contrast to many existing quantum linear solvers, our method does not rely on oracle access to query entries, relaxing a key practicality bottleneck. In particular, when the rank of the system of interest is sufficiently small and the rows of the matrix of interest admit an appropriate structure, we achieve circuit complexity $\mathcal{O}\left(\frac{1}{\varepsilon}\log m\right)$, where $m$ is the number of variables and $\varepsilon$ is the target precision, without dependence on the sparsity $s$, and could possibly be without explicit dependence on condition number $κ$. This shows a significant improvement over previous quantum linear solvers where the dependence on $κ,s$ is at least linear. At the same time, when the rows have an arbitrary structure and have at most $s$ nonzero entries, we obtain the circuit depth $\mathcal{O}\left(\frac{1}{\varepsilon}\log s\right)$ using extra $\mathcal{O}(s)$ ancilla qubits, so the depth grows only logarithmically with sparsity $s$. When the sparsity $s$ grows as $\mathcal{O}(\log m)$, then our method can achieve an exponential improvement with respect to circuit depth compared to existing quantum algorithms, while using (asymptotically) the same amount of qubits.

</details>


### [50] [Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective](https://arxiv.org/abs/2601.01353)
*Shahrooz Pouryousef,Eneet Kaur,Hassan Shapourian,Don Towsley,Ramana Kompella,Reza Nejabati*

Main category: quant-ph

TL;DR: 该论文系统性地比较了四种量子数据中心架构（QFly、BCube、Clos、Fat-Tree）在分布式量子计算中的性能表现，分析了量子特有的物理约束对执行延迟、资源争用和可扩展性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有量子数据中心架构采用不同的设计理念，但在实际量子硬件约束下的相对性能表现尚不清楚。需要系统评估这些架构在量子特定效应（如光学损耗、相干时间限制等）下的表现，为可扩展分布式量子计算提供设计指导。

Method: 对四种代表性QDC架构（QFly、BCube、Clos、Fat-Tree）进行系统性基准测试，量化它们对分布式量子电路执行延迟、资源争用和可扩展性的影响。重点分析量子特有的效应：光学损耗引起的EPR对生成延迟、相干时间限制的纠缠重试窗口、基于隐形传态的非局域门争用。评估架构特性（路径多样性、路径长度、共享BSM资源）与光学开关插入损耗和重配置延迟的相互作用。

Result: 分布式量子性能由拓扑结构、调度策略和物理层参数共同决定，这些因素以非平凡的方式相互作用。研究结果为设计可扩展、高性能的量子数据中心架构提供了定量指导。

Conclusion: 该研究提供了对量子数据中心架构性能的系统性理解，揭示了在量子特定约束下不同架构设计的相对优劣，为未来分布式量子计算系统的设计提供了重要参考依据。

Abstract: Scalable distributed quantum computing (DQC) has motivated the design of multiple quantum data-center (QDC) architectures that overcome the limitations of single quantum processors through modular interconnection. While these architectures adopt fundamentally different design philosophies, their relative performance under realistic quantum hardware constraints remains poorly understood.
  In this paper, we present a systematic benchmarking study of four representative QDC architectures-QFly, BCube, Clos, and Fat-Tree-quantifying their impact on distributed quantum circuit execution latency, resource contention, and scalability. Focusing on quantum-specific effects absent from classical data-center evaluations, we analyze how optical-loss-induced Einstein-Podolsky-Rosen (EPR) pair generation delays, coherence-limited entanglement retry windows, and contention from teleportation-based non-local gates shape end-to-end execution performance. Across diverse circuit workloads, we evaluate how architectural properties such as path diversity and path length, and shared BSM (Bell State Measurement) resources interact with optical-switch insertion loss and reconfiguration delay. Our results show that distributed quantum performance is jointly shaped by topology, scheduling policies, and physical-layer parameters, and that these factors interact in nontrivial ways. Together, these insights provide quantitative guidance for the design of scalable and high-performance quantum data-center architectures for DQC.

</details>


### [51] [Distant Entanglement Generation between Magnon and Superconducting Qubits in Magnon-Mediated Hybrid Systems](https://arxiv.org/abs/2601.01394)
*Guosen Liu,Pei Pei*

Main category: quant-ph

TL;DR: 提出一种高效的两阶段协议，用于在磁振子介导的混合量子系统中生成远距离纠缠，其中磁振子同时充当相互作用媒介和量子比特。


<details>
  <summary>Details</summary>
Motivation: 分布式量子网络需要高效、稳健的远距离纠缠生成方案。传统方法通常需要多个物理组件，而磁振子具有强耦合、低耗散和高集成度等优势，可以简化系统设计并提高性能。

Method: 采用两阶段协议：1) 利用绝热捷径在超导量子比特和本地磁振子系统之间确定性生成贝尔态；2) 通过工程化的哈密顿动力学将纠缠态相干转移到远程磁振子系统。系统由超导谐振器连接超导量子比特和本地磁振子系统，后者通过波导耦合到远程磁振子系统。

Result: 在现实噪声条件下的数值模拟显示，该协议对退相干具有很强的鲁棒性，保真度F > 0.90，负性N₂ > 0.40，表明能够有效生成远距离纠缠。

Conclusion: 该协议为分布式量子网络提供了一个可扩展且实用的构建模块，通过磁振子的双重角色简化了系统设计，同时利用绝热特性增强了对环境耗散的鲁棒性。

Abstract: We propose an efficient two-stage protocol for generating distant entanglement in a magnon-mediated hybrid quantum system, where magnons serve dual roles as both interaction mediators and qubits. This integrated design reduces the physical component count while leveraging the inherent advantages of magnons, such as their strong coupling via magnetic dipole interactions, low dissipation, and high integrability. In our setup, a superconducting resonator interfaces between a local superconducting qubit (SQ) and a local magnonic system (QM1), which is waveguide-coupled to a remote magnonic system (QM2). The protocol comprises two stages: (i) deterministic Bell-state generation between the SQ and QM1 using shortcuts to adiabaticity, and (ii) coherent state transfer to QM2 via engineered Hamiltonian dynamics. This adiabatic characteristic enhances robustness against environmental dissipation. Numerical simulations under realistic noise conditions confirm strong resilience to decoherence, achieving fidelity $F > 0.90$ and negativity $\mathcal{N}_2 > 0.40$. These results establish the protocol as a scalable and practical building block for distributed quantum networks.

</details>


### [52] [Noise-Resilient Heisenberg-limited Quantum Sensing via Indefinite-Causal-Order Error Correction](https://arxiv.org/abs/2601.01404)
*Hang Xu,Xiaoyang Deng,Ze Zheng,Tailong Xiao,Guihua Zeng*

Main category: quant-ph

TL;DR: 提出基于不定因果序的量子纠错协议，首次将不定因果序应用于量子纠错，通过非对易干涉实现实时错误纠正，恢复海森堡极限标度


<details>
  <summary>Details</summary>
Motivation: 传统量子纠错在量子传感中存在严格限制：需要先验噪声表征、信号-噪声兼容条件、基于测量的全局控制。海森堡极限标度在现实噪声设备中通常无法实现。

Method: 引入基于不定因果序的量子纠错协议，通过将辅助控制和噪声演化置于不定因果序中，利用非对易干涉使辅助系统实时宣告和纠正错误。

Result: 协议在单噪声和多噪声场景中均有效，在单量子比特、多体系统和连续变量平台上展示性能，在某些情况下可实现完全基于幺正控制的纠错。

Conclusion: 不定因果序是计量学量子纠错的强大资源，为噪声鲁棒的量子信息处理提供了广泛适用的框架。

Abstract: Quantum resources can, in principle, enable Heisenberg-limited (HL) sensing, yet no-go theorems imply that HL scaling is generically unattainable in realistic noisy devices. While quantum error correction (QEC) can suppress noise, its use in quantum sensing is constrained by stringent requirements, including prior noise characterization, restrictive signal-noise compatibility conditions, and measurement-based syndrome extraction with global control. Here we introduce an ICO-based QEC protocol, providing the first application of indefinite causal order (ICO) to QEC. By coherently placing auxiliary controls and noisy evolution in an indefinite causal order, the resulting noncommutative interference enables an auxiliary system to herald and correct errors in real time, thereby circumventing the limitations of conventional QEC and restoring HL scaling. We rigorously establish the protocol for single- and multi-noise scenarios and demonstrate its performance in single-qubit, many-body, and continuous-variable platforms. We further identify regimes in which error correction can be implemented entirely by unitary control, without measurements. Our results reveal ICO as a powerful resource for metrological QEC and provide a broadly applicable framework for noise-resilient quantum information processing.

</details>


### [53] [Implicitly Restarted Lanczos Enables Chemically-Accurate Shallow Neural Quantum States](https://arxiv.org/abs/2601.01437)
*Wei Liu,Wenjie Dou*

Main category: quant-ph

TL;DR: 本文提出使用隐式重启Lanczos方法作为神经量子态训练的核心优化引擎，解决了传统一阶优化方法收敛慢、超参数敏感和数值不稳定的问题，实现了二阶优化框架，大幅提升了训练效率和精度。


<details>
  <summary>Details</summary>
Motivation: 神经量子态等高维神经网络模型的变分优化面临重大挑战。传统一阶随机方法（如Adam）存在收敛缓慢、对超参数敏感和数值不稳定等问题，无法达到基础科学所需的高精度要求。

Method: 引入隐式重启Lanczos方法作为NQS训练的核心引擎，构建了一个内在稳定的二阶优化框架。该方法将病态参数更新问题重新表述为一个小型、适定的厄米特特征值问题，通过IRL高效稳健地求解，自动确定最优下降方向和步长。

Result: IRL方法使浅层NQS架构（参数数量少几个数量级）能够在仅3到5个优化步骤中持续实现极高精度（1e-12 kcal/mol）。对于F2分子，与Adam相比实现了约17,900倍的总运行时间加速。

Conclusion: 这项工作确立了IRL作为变分量子模型的优越、稳健且高效的二阶优化策略，为神经网络在量子物理和化学中的实际高保真应用铺平了道路。

Abstract: The variational optimization of high-dimensional neural network models, such as those used in neural quantum states (NQS), presents a significant challenge in machine intelligence. Conventional first-order stochastic methods (e.g., Adam) are plagued by slow convergence, sensitivity to hyperparameters, and numerical instability, preventing NQS from reaching the high accuracy required for fundamental science. We address this fundamental optimization bottleneck by introducing the implicitly restarted Lanczos (IRL) method as the core engine for NQS training. Our key innovation is an inherently stable second-order optimization framework that recasts the ill-conditioned parameter update problem into a small, well-posed Hermitian eigenvalue problem. By solving this problem efficiently and robustly with IRL, our approach automatically determines the optimal descent direction and step size, circumventing the need for demanding hyperparameter tuning and eliminating the numerical instabilities common in standard iterative solvers. We demonstrate that IRL enables shallow NQS architectures (with orders of magnitude fewer parameters) to consistently achieve extreme precision (1e-12 kcal/mol) in just 3 to 5 optimization steps. For the F2 molecule, this translates to an approximate 17,900-fold speed-up in total runtime compared to Adam. This work establishes IRL as a superior, robust, and efficient second-order optimization strategy for variational quantum models, paving the way for the practical, high-fidelity application of neural networks in quantum physics and chemistry.

</details>


### [54] [The Equivalence between Hardy-type paradox and Logical Contextuality](https://arxiv.org/abs/2601.01445)
*Songyi Liu,Yongjun Wang,Baoshan Wang,Chang He,Yunyi Jia*

Main category: quant-ph

TL;DR: 该论文提出了逻辑Hardy型悖论作为量子上下文性的统一逻辑框架，证明了在有限场景中逻辑Hardy型悖论的存在等价于逻辑上下文性，特别地强上下文性等价于成功概率SP=1的Hardy型悖论。


<details>
  <summary>Details</summary>
Motivation: Hardy型悖论为量子上下文性提供了优雅的无不等式证明，但现有研究局限于特定场景（如(2,k,2)、(2,2,d)和n-cycle），且存在误解认为这种等价性不适用于一般场景。需要建立统一框架来理解Hardy型悖论与逻辑上下文性的普遍关系。

Method: 提出逻辑Hardy型悖论作为统一逻辑表述，证明在任意有限场景中，逻辑Hardy型悖论的存在等价于逻辑上下文性。特别分析(2,2,2)和(2,3,3)贝尔场景以及KCBS场景，计算KCBS场景中Hardy型悖论的成功概率。

Result: 1. 证明了逻辑Hardy型悖论存在性等价于逻辑上下文性；2. 强上下文性等价于SP=1的Hardy型悖论；3. 纠正了先前认为这种等价不适用于一般场景的误解；4. 发现KCBS场景只有一种Hardy型悖论，在特定参数设置下达到SP≈10.56%的成功概率。

Conclusion: 逻辑Hardy型悖论为理解量子上下文性提供了统一的逻辑框架，建立了Hardy型悖论与逻辑上下文性之间的普遍等价关系，这一结果推广了先前特定场景的研究并纠正了相关误解。

Abstract: Hardy-type paradoxes offer elegant, inequality-free proof of quantum contextuality. In this work, we introduce a unified logical formulation for general Hardy-type paradoxes, which we term logical Hardy-type paradoxes. We prove that for any finite scenario, the existence of a logical Hardy-type paradox is equivalent to logical contextuality. Specially, strong contextuality is equivalent to logical Hardy-type paradoxes with success probability SP = 1. These results generalize prior work on (2,k,2), (2,2,d), and n-cycle scenarios, and resolve a misconception that such equivalence does not hold for general scenarios [1]. We analyse the logical Hardy-type paradoxes on the (2,2,2) and (2,3,3) Bell scenarios, as well as the Klyachko-Can-Binicioglu-Shumovsky (KCBS) scenario. We show that the KCBS scenario admits only one kind of Hardy-type paradox, achieving a success probability of SP \approx 10.56% for a specific parameter setting.

</details>


### [55] [Constraint-Aware Quantum Optimization via Hamming Weight Operators](https://arxiv.org/abs/2601.01516)
*Yajie Hao,Qiming Ding,Xiao Yuan,Xiaoting Wang*

Main category: quant-ph

TL;DR: 提出基于汉明权重算子的自适应QAOA方法，用于解决带严格线性约束的组合优化问题，相比传统惩罚方法收敛更快、近似比更高、所需门数减半。


<details>
  <summary>Details</summary>
Motivation: 传统惩罚方法在量子近似优化算法中会扭曲优化景观并需要深层电路，限制了在近期量子硬件上的可扩展性。需要一种能严格保持在可行子空间内的高效方法。

Method: 引入汉明权重算子类，将量子演化严格限制在可行子空间内。在此基础上开发自适应汉明权重算子QAOA，动态选择最有效的算子构建浅层、针对问题定制的电路。

Result: 在金融投资组合优化和高能物理双喷注聚类等基准任务上，该方法能固有地满足所有约束，收敛更快，获得比惩罚方法更高的近似比，同时所需门数减少约一半。

Conclusion: 通过将约束感知算子嵌入自适应变分框架，为在近期量子设备上解决实际约束优化问题建立了可扩展且硬件高效的途径。

Abstract: Constrained combinatorial optimization with strict linear constraints underpins applications in drug discovery, power grids, logistics, and finance, yet remains computationally demanding for classical algorithms, especially at large scales. The Quantum Approximate Optimization Algorithm (QAOA) offers a promising quantum framework, but conventional penalty-based formulations distort optimization landscapes and demand deep circuits, undermining scalability on near-term hardware. In this work, we introduce Hamming Weight Operators, a new class of constraint-aware operators that confine quantum evolution strictly within the feasible subspace. Building on this idea, we develop Adaptive Hamming Weight Operator QAOA, which dynamically selects the most effective operators to construct shallow, problem-tailored circuits. We validate our approach on benchmark tasks from both finance and high-energy physics, specifically portfolio optimization and two-jet clustering with energy balance. Across these problems, our method inherently satisfies all constraints by construction, converges faster, and achieves higher Approximation Ratios than penalty-based QAOA, while requiring roughly half as many gates. By embedding constraint-aware operators into an adaptive variational framework, our approach establishes a scalable and hardware-efficient pathway for solving practical constrained optimization problems on near-term quantum devices.

</details>


### [56] [Entropy and Variance Squeezing of V-type Atom in Dissipative Cavity](https://arxiv.org/abs/2601.01519)
*Zijin Liang,Qiying Pan,Hong-Mei Zou,Chenrui Bi*

Main category: quant-ph

TL;DR: 研究V型原子在耗散腔中的熵压缩和方差压缩，分析自发干涉、腔环境耦合、原子-腔失谐等参数对原子压缩的影响


<details>
  <summary>Details</summary>
Motivation: 探索V型原子在耗散腔中的量子压缩特性，为量子信息处理提供超低噪声资源

Method: 基于参考文献，研究V型原子在耗散腔中的熵压缩和方差压缩，分析自发干涉参数θ、腔环境耦合γ₀/κ、原子-腔失谐Δ以及不同初始态对原子压缩的影响

Result: 1. S_y在任何条件下都不出现压缩；2. S_x的方差压缩仅在Δ>0时出现；3. 熵压缩比方差压缩能更精确地量化量子涨落；4. S_x的原子压缩明显依赖于θ、γ₀/κ、Δ和初始态

Conclusion: 这些发现对于量子信息处理作为超低噪声资源具有重要意义，熵压缩比方差压缩能更精确地描述量子涨落特性

Abstract: Based on Ref.\cite{Riccardi A}, we investigate the entropy and variance squeezing of a V-type atom in a dissipative cavity, and discuss the influences of parameters including the spontaneously generated interference (SGI) ($θ$), the cavity-environment coupling ($γ_0/κ$) and the atom-cavity detuning ($Δ$) on the atomic squeezing by using different initial states. The results show that no squeezing of $S_y$ occurs under any condition and that variance squeezing of $S_x$ appears only when $Δ>0$. Entropy squeezing quantifies quantum fluctuations more precisely than variance squeezing. Moreover, the atomic squeezing of $S_x$ clearly depends on $θ$, $γ_0/κ$, $Δ$ and the initial state. These findings are meaningful for quantum information processing as an ultra-low-noise resource.

</details>


### [57] [Overcoming Stark-Shift Constraints in Phase-Controlled Rydberg Two-Qubit Gates](https://arxiv.org/abs/2601.01521)
*Ignacio R. Sola,Sebastian C. Carrasco,Vladimir S. Malinovsky,Seokmin Shin,Bo Y. Chang*

Main category: quant-ph

TL;DR: 提出两种鲁棒控制方案，通过三脉冲序列在强里德堡阻塞限制下实现高保真度两量子位相位门


<details>
  <summary>Details</summary>
Motivation: 斯塔克位移引入的额外相位限制了在强里德堡阻塞限制下通过双光子跃迁制备纠缠门的能力，需要解决非独立寻址量子位的相位门实现问题

Method: 通过控制每个量子位的绝对相位和局部脉冲幅度，使用三脉冲序列实现任意两量子位相位门；针对不同相位门设计两种鲁棒控制方案，分别适用于偶数或奇数长度脉冲序列

Result: 能够以高保真度制备任意两量子位相位门，两种鲁棒控制方案在不同相位门类型下都能获得更好的结果

Conclusion: 通过精确控制相位和脉冲参数，可以在存在斯塔克位移的情况下实现高保真度的两量子位相位门操作，为里德堡量子计算提供了有效的控制方案

Abstract: Stark shifts introduce additional phases that constrain the set of entangling gates that can be prepared via two-photon transitions in the strong Rydberg blockade limit. For non-independently addressed qubits, by controlling the absolute phases and the local amplitudes of the pulses at each qubit, we show that any two-qubit phase gate can be prepared with high fidelity using a three-pulse sequence. Based on these insights, we introduce two robust control schemes tailored to different phase gates that yield better results with pulse sequences of either even or odd length.

</details>


### [58] [Non-Hermitian second-order topological insulator with point gap](https://arxiv.org/abs/2601.01524)
*Xue-Min Yang,Hao Lin,Jian Li,Jia-Ji Zhu,Jun-Li Zhu,Hong Wu*

Main category: quant-ph

TL;DR: 非厄米SSH模型的零模角态在热力学极限下展现高阶拓扑，通过奇异值分析建立体边对应关系


<details>
  <summary>Details</summary>
Motivation: 传统认为二维非厄米SSH模型的零模角态在保持手征对称性的微扰下是鲁棒的，但作者发现这一结论在大尺寸系统中不再成立，需要重新理解非厄米系统的高阶拓扑特性

Method: 建立稳定零模奇异态与热力学极限下能谱拓扑保护角态之间的对应关系，通过实空间绕数来计数稳定零模奇异态的数量

Result: 零模奇异值的数量直接与中能隙角态数量相关，为静态和Floquet非厄米系统建立了体边对应关系，这种拓扑特性本质源于非厄米性，甚至不需要对称性

Conclusion: 非厄米系统的高阶拓扑可以通过奇异值分析来表征，建立了新的体边对应框架，揭示了非厄米性本身就能产生拓扑保护态，超越了传统对称性保护拓扑的范畴

Abstract: The zero-mode corner states in the gap of two-dimensional non-Hermitian Su-Schrieffer-Heeger model are robust to infinitesimal perturbations that preserve chiral symmetry. However, we demonstrate that this general belief is no longer valid in large-sized systems. To reveal the higher-order topology of non-Hermitian systems, we establish a correspondence between the stable zero-mode singular states and the topologically protected corner states of energy spectrum in the thermodynamic limit. Within this framework, the number of zero-mode singular values is directly linked to the number of mid-gap corner states. The winding numbers in real space can be defined to count the number of stable zero-mode singular states. Our results formulate a bulk-boundary correspondence for both static and Floquet non-Hermitian systems, where topology arises intrinsically from the non-Hermiticity, even without symmetries.

</details>


### [59] [Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace](https://arxiv.org/abs/2601.01550)
*Shuo Zhou,Zhaokai Pan,Weiyuan Gong,Tongyang Li*

Main category: quant-ph

TL;DR: 本文研究了在低能假设下时间依赖哈密顿量的量子模拟算法改进，通过分析低能子空间上的Trotter误差，证明了相比标准模拟的性能提升。


<details>
  <summary>Details</summary>
Motivation: 哈密顿量模拟是绝热量子计算、量子控制和量子多体物理中的关键子程序，量子动力学通常发生在低能区。与时间无关哈密顿量模拟相比，在低能假设下对时间依赖哈密顿量的量子模拟算法理解仍然有限，需要研究在初始态处于低能子空间时能有多大改进。

Method: 计算了时间依赖自旋哈密顿量在低能假设下的Trotter数，利用绝热微扰理论分析哈密顿量的时变能谱，推导了乘积公式的低能模拟误差（具有对易子标度）。

Result: 证明了在初始态仅占据少量低能本征态时，相比完整酉模拟的标准成本有改进。讨论了在非平衡量子多体动力学模拟和绝热态制备中的应用，并证明了时间依赖哈密顿量模拟的查询复杂度下界。

Conclusion: 通过低能假设可以显著改进时间依赖哈密顿量的量子模拟性能，为绝热量子计算和量子多体物理模拟提供了更高效的算法框架。

Abstract: Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.

</details>


### [60] [Utilizing intermediate states in quantum annealing for multi-objective optimization](https://arxiv.org/abs/2601.01559)
*Keita Takahashi,Shu Tanaka*

Main category: quant-ph

TL;DR: 该论文研究通过获取量子退火过程中的中间量子态来解决多目标优化中线性加权和方法无法到达帕累托前沿非凸区域的局限性


<details>
  <summary>Details</summary>
Motivation: 传统多目标优化中的线性加权和方法存在固有缺陷，无法到达帕累托前沿的非凸区域，这限制了多目标量子退火算法的性能和应用范围

Method: 通过两种方法验证：1) 物理实验中使用基于淬灭的读出技术获取中间量子态；2) 数值模拟中假设理想的中途测量来获取中间状态

Result: 两种方法一致显示明显的权衡关系：较早的测量时间增强解的多样性，较晚的测量时间确保收敛到非支配解。存在一个实用的折中时间点能平衡这两个指标

Conclusion: 实际淬灭方法与理想模拟之间的定性一致性表明，访问中间量子态具有全面探索帕累托前沿的潜力，为解决多目标优化中的非凸问题提供了新途径

Abstract: We investigate obtaining intermediate quantum states during the quantum annealing process to address the limitation of the linear weighted sum method in multi-objective optimization, which inherently fails to reach non-convex regions of the Pareto front. We validate this approach through physical experiments utilizing quench-based readout and numerical simulations assuming ideal mid-anneal measurements. Both methods consistently demonstrate a clear trade-off where earlier timing enhances diversity of the solutions, whereas later timing ensures convergence to non-dominated solutions. Notably, a practical compromise timing balances both metrics. The qualitative agreement between practical quench and ideal simulation indicates the potential of accessing the intermediate states for comprehensive Pareto front exploration.

</details>


### [61] [Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics](https://arxiv.org/abs/2601.01589)
*Yazhen Wang*

Main category: quant-ph

TL;DR: 该论文研究了量子计算中的量子游走搜索算法和经典计算中的朗之万动力学采样算法，通过Le Cam缺陷距离证明了带随机化的量子游走与欠阻尼朗之万动力学渐近等价，揭示了量子加速与经典梯度加速的内在机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索量子计算中的量子游走搜索算法和经典计算中的朗之万动力学采样算法之间的学习关系，这两种算法都用于解决学习任务，且分别展示了量子加速和经典梯度加速的特性。

Method: 使用Le Cam缺陷距离作为度量工具，分析带随机化和不带随机化的量子游走与欠阻尼朗之万动力学的渐近等价性，并讨论这些等价和非等价结果对机器学习任务中相关算法的计算和推断特性的影响。

Result: 研究发现带随机化的量子游走与欠阻尼朗之万动力学在Le Cam缺陷距离下是渐近等价的，而不带随机化的量子游走由于高频振荡行为而不等价。这些结果为理解量子加速和经典梯度加速的内在机制提供了新见解。

Conclusion: 论文揭示了量子游走与欠阻尼朗之万动力学之间的深刻联系，为理解量子加速和经典梯度加速的内在机制提供了新的理论视角，对机器学习算法的设计和分析具有重要意义。

Abstract: Fast computational algorithms are in constant demand, and their development has been driven by advances such as quantum speedup and classical acceleration. This paper intends to study search algorithms based on quantum walks in quantum computation and sampling algorithms based on Langevin dynamics in classical computation. On the quantum side, quantum walk-based search algorithms can achieve quadratic speedups over their classical counterparts. In classical computation, a substantial body of work has focused on gradient acceleration, with gradient-adjusted algorithms derived from underdamped Langevin dynamics providing quadratic acceleration over conventional Langevin algorithms.
  Since both search and sampling algorithms are designed to address learning tasks, we study learning relationship between coined quantum walks and underdamped Langevin dynamics. Specifically, we show that, in terms of the Le Cam deficiency distance, a quantum walk with randomization is asymptotically equivalent to underdamped Langevin dynamics, whereas the quantum walk without randomization is not asymptotically equivalent due to its high-frequency oscillatory behavior. We further discuss the implications of these equivalence and nonequivalence results for the computational and inferential properties of the associated algorithms in machine learning tasks. Our findings offer new insight into the relationship between quantum walks and underdamped Langevin dynamics, as well as the intrinsic mechanisms underlying quantum speedup and classical gradient acceleration.

</details>


### [62] [Generation of circular polarized high-order harmonics from single color quantum light](https://arxiv.org/abs/2601.01611)
*Lidija Petrovic,Philipp Stammer,Maciej Lewenstein,Javier Rivera-Dean*

Main category: quant-ph

TL;DR: 使用压缩椭圆偏振光驱动原子产生高次谐波，可在经典禁戒的大椭圆率区域实现HHG，并产生具有超泊松光子统计的高度椭圆谐波辐射，同时谐波光谱编码了驱动场的量子压缩信息。


<details>
  <summary>Details</summary>
Motivation: 经典圆偏振驱动场无法产生高次谐波，这限制了HHG在圆偏振光领域的应用。通过引入驱动场的量子特性（压缩态），可以突破这一经典限制，实现在大椭圆率区域的HHG，同时谐波光谱还能揭示驱动场的量子性质。

Method: 采用压缩态的高度椭圆偏振光作为驱动场，分析原子在该量子驱动场下的高次谐波响应。通过研究谐波光谱强度随驱动场椭圆率和压缩取向的变化关系，探索探测驱动场量子特性的方法。

Result: 压缩椭圆偏振驱动场不仅能在经典禁戒的大椭圆率区域实现HHG，还能产生高度椭圆化的谐波辐射，并表现出明显的超泊松光子统计特性。谐波光谱特征编码了驱动场的量子压缩涨落信息。

Conclusion: 量子压缩驱动场为高次谐波生成开辟了新途径，特别是在圆偏振光领域。谐波光谱可作为探测驱动场量子性质的探针，为研究高光子数区域的量子光学特性提供了新方法。

Abstract: The atomic response to an ultra-intense driving field produces a characteristic high-harmonic spectrum featuring a rapid drop in intensity for the lower harmonics, followed by a plateau and a sharp cutoff. This response vanishes for circularly polarized classical drivers -- a limitation that can be overcome by introducing quantum features into the driving field. In this work, we show that squeezed highly elliptically polarized drivers not only enable the high-harmonic generation (HHG) process in classically forbidden regimes of large ellipticity, but also yield highly elliptical harmonic radiation with pronounced super-Poissonian photon statistics. Moreover, we show that the HHG spectral features encode information about the quantum nature of the driving field, revealing the presence of its squeezed field fluctuations. By analyzing the HHG spectral intensity dependence as a function of the driver's ellipticity and squeezing orientation, we identify a means to probe the driving field's quantum properties that intrinsically lie in the high-photon number regime.

</details>


### [63] [Scattering Cross Section Formula Derived From Macroscopic Model of Detectors](https://arxiv.org/abs/2601.01625)
*Rashi Kaimal,Roderich Tumulka*

Main category: quant-ph

TL;DR: 论文推导了量子散射理论中自由非相对论粒子在大半径球面上探测器检测概率分布的渐近公式，提供了两种不同的宏观检测模型推导，并与玻姆力学进行了比较。


<details>
  <summary>Details</summary>
Motivation: 量子散射理论中常用一个关于自由非相对论粒子在球面探测器上检测概率分布的渐近公式，但该公式的严格证明需要明确检测过程的宏观模型。本文旨在为这一公式提供两种不同的物理推导，并探讨检测过程对粒子行为的影响。

Method: 提出了两种不同的宏观检测模型：1）在探测器体积内使用强度为λ的负虚势，在极限R→∞, λ→0, Rλ→∞下推导；2）采用重复近似投影测量方法，在极限R→∞, T→∞, T/R→0下推导。同时与玻姆力学的结果进行比较。

Result: 两种不同的检测模型都得到了相同的渐近检测概率密度公式：σ(x,t)= m³ħ⁻³R t⁻⁴|Ψ̂₀(mx/ħt)|²。与玻姆力学比较发现，虽然无探测器时玻姆轨迹到达球面的分布与σ相同，但检测时间与轨迹到达时间的偏差不可忽略，不过在远场区域检测器对粒子的影响可以忽略。

Conclusion: 论文为量子散射理论中的检测概率公式提供了两种物理上合理的推导，验证了该公式在不同检测模型下的普适性。同时表明在远场极限下，检测过程对粒子行为的影响可以忽略，这为量子散射实验提供了理论支持。研究还推广到非球面、多粒子、时变曲面和狄拉克方程等情况。

Abstract: We are concerned with the justification of the statement, commonly (explicitly or implicitly) used in quantum scattering theory, that for a free non-relativistic quantum particle with initial wave function $Ψ_0(\boldsymbol{x})$, surrounded by detectors along a sphere of large radius $R$, the probability distribution of the detection time and place has asymptotic density (i.e., scattering cross section) $σ(\boldsymbol{x},t)= m^3 \hbar^{-3} R t^{-4} |\widehatΨ_0(m\boldsymbol{x}/\hbar t)|^2$ with $\widehatΨ_0$ the Fourier transform of $Ψ_0$. We give two derivations of this formula, based on different macroscopic models of the detection process. The first one consists of a negative imaginary potential of strength $λ>0$ in the detector volume (i.e., outside the sphere of radius $R$) in the limit $R\to\infty,λ\to 0, Rλ\to \infty$. The second one consists of repeated nearly-projective measurements of (approximately) the observable $1_{|\boldsymbol{x}|>R}$ at times $\mathscr{T},2\mathscr{T},3\mathscr{T},\ldots$ in the limit $R\to\infty,\mathscr{T}\to\infty,\mathscr{T}/R\to 0$; this setup is similar to that of the quantum Zeno effect, except that there one considers $\mathscr{T}\to 0$ instead of $\mathscr{T}\to\infty$. We also provide a comparison to Bohmian mechanics: while in the absence of detectors, the arrival times and places of the Bohmian trajectories on the sphere of radius $R$ have asymptotic distribution density given by the same formula as $σ$, their deviation from the detection times and places is not necessarily small, although it is small compared to $R$, so the effect of the presence of detectors on the particle can be neglected in the far-field regime. We also cover the generalization to surfaces with non-spherical shape, to the case of $N$ non-interacting particles, to time-dependent surfaces, and to the Dirac equation.

</details>


### [64] [Quantum simulation with Rydberg ions in a Penning trap](https://arxiv.org/abs/2601.01626)
*Wilson S. Martins,Markus Hennrich,Ferdinand Schmidt-Kaler,Igor Lesanovsky*

Main category: quant-ph

TL;DR: 该论文提出了一种基于里德伯态和彭宁阱的新型量子模拟平台，可将二维自旋系统的相互作用强度提高数个数量级，为研究长时标现象（如受挫和动力学约束系统中的缓慢集体弛豫）开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有离子阱量子模拟平台中，自旋相互作用通过晶体振动介导，强度有限。需要开发能够实现更强相互作用、更长寿命的平台，以研究长时标物理现象。

Method: 利用里德伯态之间的强偶极相互作用和彭宁阱提供的平面约束。研究彭宁阱强电磁场对里德伯态性质的影响，展示在实验现实条件下可实现MHz量级的自旋-自旋相互作用强度。

Result: 提出了一种新方法，可将二维自旋系统的相互作用强度提高数个数量级。通过三个离子实现的受挫自旋系统，展示了该量子模拟器在纠缠研究方面的能力。

Conclusion: 该平台结合了里德伯态的强相互作用和彭宁阱的长寿命特性，为探索受挫和动力学约束系统中的长时标现象提供了新工具，有望推动量子模拟技术的发展。

Abstract: Quantum simulation of interacting many-body spin systems is routinely performed with cold trapped ions, and systems with hundreds of spins have been studied in one and two dimensions. In the most common realizations of these platforms, spin degrees of freedom are encoded in low-lying electronic levels, and interactions among the spins are mediated through crystal vibrations. Here we propose a new approach which enables the quantum simulation of two-dimensional spin systems with interaction strengths that are increased by orders of magnitude. This, together with the unprecedented longevity of trapped ions, opens an avenue for the exploration of phenomena that take place on long timescales, e.g., slow and collective relaxation in frustrated and kinetically constrained systems. Our platform makes use of the strong dipolar interactions among electronic Rydberg states and planar confinement provided by a Penning trap. We investigate how the strong electric and magnetic fields that form this trap affect the properties of the Rydberg states and show that spin-spin interaction strengths on the order of MHz are achievable under experimentally realistic conditions. As a brief illustration of the capabilities of this quantum simulator, we study the entanglement in a frustrated spin system realized by three ions.

</details>


### [65] [Design and Characterization of Compact Acousto-Optic-Deflector Individual Addressing System for Trapped-Ion Quantum Computing](https://arxiv.org/abs/2601.01647)
*Jiyong Yu,Kavyashree Ranawat,Andrew Van Horn,Jacob Whitlow,Seunghyun Baek,Junki Kim,Jungsang Kim*

Main category: quant-ph

TL;DR: 提出基于声光偏转器的紧凑型光束偏转系统，用于囚禁离子量子计算中的单独寻址，实现高光学稳定性和低串扰


<details>
  <summary>Details</summary>
Motivation: 为囚禁离子量子计算开发紧凑、稳定的单独寻址系统，减少光机械自由度和光路以提高光学稳定性

Method: 使用声光偏转器作为光束偏转核心，设计紧凑的光学系统（小于1平方英尺），最小化光机械自由度和光路

Result: 实现了355nm波长的高斯光束，光束偏转范围约50倍光束直径，五离子链中相邻离子强度串扰<9×10⁻⁴，成功演示30离子链单独寻址，光束切换时间约240ns

Conclusion: 紧凑系统设计提供高光学稳定性，为长离子链的高保真度囚禁离子量子计算奠定基础

Abstract: We present a compact design for a beam-steering system based on acousto-optic-deflectors (AODs) used as an individual addressing system for trapped-ion quantum computing. The design targets to minimize the optomechanical degrees of freedom and the optical beam paths to improve optical stability, and we successfully implemented a solution with a compact footprint of less than 1 square foot. The system characterization results show that we achieve clean Gaussian beams at 355nm wavelength with a beam steering range of $\sim$50 times the beam diameter, and an intensity crosstalk of $< 9 \times 10^{-4}$ at all neighboring ions in a five-ion chain. Based on these capabilities, we experimentally demonstrate individual addressing of a 30-ion chain. We estimate the beam switching time of the AOD to be $\sim$240 ns. The compact system design is expected to provide high optical stability, providing the potential for high-fidelity trapped-ion quantum computing with long ion chains.

</details>


### [66] [A Geometric Approach to Strongly Correlated Bosons: From $N$-Representability to the Generalized BEC Force](https://arxiv.org/abs/2601.01652)
*Chih-Chun Wang,Christian Schilling*

Main category: quant-ph

TL;DR: 该论文基于约化密度矩阵理论，为强关联晶格玻色子建立了几何框架，通过动量占据数精确描述系统，揭示了单粒子N-可表示性条件的关键作用。


<details>
  <summary>Details</summary>
Motivation: 建立强关联晶格玻色子的几何描述框架，利用约化密度矩阵理论，通过动量占据数精确描述系统，探索单粒子N-可表示性条件在基态泛函中的核心作用。

Method: 采用约束搜索形式，利用平移对称性和固定对相互作用，建立N-玻色子构型态与单粒子约化密度矩阵之间的几何对应关系，推导基态泛函的一般形式。

Result: 发现泛函结构完全由N-可表示性条件决定：定义域精确由这些条件确定；在边界处泛函梯度发散（推广了BEC力）；通过几何论证直接得到边界力的显式表达式。

Conclusion: 该几何框架为强关联玻色子系统提供了精确描述，揭示了单粒子N-可表示性条件的基础性作用，并为系统性的泛函近似层次提供了理论基础。

Abstract: Building on recent advances in reduced density matrix theory, we develop a geometric framework for describing strongly correlated lattice bosons. We first establish that translational symmetry, together with a fixed pair interaction, enables an exact functional formulation expressed solely in terms of momentum occupation numbers. Employing the constrained-search formalism and exploiting a geometric correspondence between $N$-boson configuration states and their one-particle reduced density matrices, we derive the general form of the ground-state functional. Its structure highlights the omnipresent significance of one-body $N$-representability: (i) the domain is exactly determined by the $N$-representability conditions; (ii) at its boundary, the gradient of the functional diverges repulsively, thereby generalizing the recently discovered Bose-Einstein condensate (BEC) force; and (iii) an explicit expression for this boundary force follows directly from geometric arguments. These key results are demonstrated analytically for few-site lattice systems, and we illustrate the broader significance of our functional form in defining a systematic hierarchy of functional approximations.

</details>


### [67] [Demonstration of Discrete-Time Quantum Walks and Observation of Topological Edge States in a Superconducting Qutrit Chain](https://arxiv.org/abs/2601.01759)
*Kun Zhou,Jian-Wen Xu,Qi-Ping Su,Yu Zhang,Xiang-Min Yu,Zhuang Ma,Han-Yu Zhang,Hong-Yi Shi,Wen Zheng,Shu-Yi Pan,Yi-Hao Kang,Zhi-Guo Huang,Chui-Ping Yang,Shao-Xiong Li,Yang Yu*

Main category: quant-ph

TL;DR: 该论文利用超导量子三能级系统（qutrits）实现了可扩展的离散时间量子行走，首次在超导平台上观测到拓扑相界面处的受粒子-空穴对称性保护的边缘态。


<details>
  <summary>Details</summary>
Motivation: 离散时间量子行走是实现通用量子计算和算法研究的重要工具，但传统超导电路实现存在操作精度、电路深度和连接性等限制。本研究旨在利用超导量子三能级系统（qutrits）提高硬件效率，实现可扩展的量子行走系统。

Method: 采用超导量子三能级系统（qutrits）构建量子行走链，利用qutrits高效编码行走者位置和硬币自由度。通过利用qutrit-based量子行走的灵活性和内在对称性，在链中制备两种拓扑相，并在其界面处观测边缘态。

Result: 实验成功实现了可扩展的离散时间量子行走，观测到量子行走在qutrit链中的弹道扩散。首次在超导平台上观测到受粒子-空穴对称性保护的边缘态，这些边缘态被限制在两个拓扑相的界面处。测量的参数依赖性进一步验证了边缘态的特性。

Conclusion: 所展示的量子行走具有可扩展性和门控兼容性，为超导量子计算和量子模拟提供了一个多功能工具。qutrits的使用显著提高了硬件效率，为拓扑量子现象的实验研究开辟了新途径。

Abstract: Quantum walk serves as a versatile tool for universal quantum computing and algorithmic research. However, the implementation of discrete-time quantum walks (DTQWs) with superconducting circuits is still constrained by some limitations such as operation precision, circuit depth and connectivity. With improved hardware efficiency by using superconducting qutrits (three-level systems), we experimentally demonstrate a scalable DTQW in a superconducting circuit, observing the ballistic spreading of quantum walk in a qutrit chain. The usage of qutrits in our implementation allows hardware efficiently encoding of the walker position and the coin degree of freedom. By exploiting the flexibility and intrinsic symmetries of qutrit-based DTQWs, we successfully prepare two topological phases in the chain. For the first time, particle-hole-symmetry-protected edge states, bounded at the interface between these two topological phases, are observed in the superconducting platform. Measured parameter dependencies further validate the properties of edge states. The scalability and gate-control compatibility of the demonstrated DTQWs enable a versatile tool for superconducting quantum computing and quantum simulation.

</details>


### [68] [A Survey on Applications of Quantum Computing for Unit Commitment](https://arxiv.org/abs/2601.01777)
*Milad Hasanzadeh,Ali Rajabi,Amin Kargarian*

Main category: quant-ph

TL;DR: 量子计算在机组组合问题中的应用综述：涵盖量子退火、变分混合算法、量子机器学习等方法，分析建模策略、硬件实现和计算权衡


<details>
  <summary>Details</summary>
Motivation: 传统机组组合优化方法（混合整数规划、动态规划、元启发式）面临系统规模增大和不确定性增加时的可扩展性挑战，量子计算通过量子并行性和纠缠特性为解决这一问题提供了新的机会

Method: 对现有量子计算应用于机组组合问题的研究进行全面综述，按量子范式分类：退火基方法、变分混合算法、量子机器学习、量子启发方法，讨论关键建模策略、硬件实现和计算权衡

Result: 综述了量子计算在机组组合问题中的当前研究进展，识别了各种量子方法的优势和局限性，为大规模量子赋能机组组合提供了发展方向

Conclusion: 量子计算为解决大规模机组组合问题提供了有前景的新途径，但仍面临硬件限制、算法成熟度等挑战，需要进一步研究以实现实际应用

Abstract: Unit Commitment (UC) is a core optimization problem in power system operation and electricity market scheduling. It determines the optimal on/off status and dispatch of generating units while satisfying system, operational, and market constraints. Traditionally, UC has been solved using mixed-integer programming, dynamic programming, or metaheuristic methods, all of which face scalability challenges as systems grow in size and uncertainty. Recent advances in quantum computing, spanning quantum annealing, variational algorithms, and hybrid quantum classical optimization, have opened new opportunities to accelerate UC solution processes by exploiting quantum parallelism and entanglement. This paper presents a comprehensive survey of existing research on the applications of quantum computing for solving the UC problem. The reviewed works are categorized based on the employed quantum paradigms, including annealing-based, variational hybrid, quantum machine learning, and quantum-inspired methods. Key modeling strategies, hardware implementations, and computational trade-offs are discussed, highlighting the current progress, limitations, and potential future directions for large-scale quantum-enabled UC.

</details>


### [69] [Physically natural metric-measure Lindbladian ensembles and their learning hardness](https://arxiv.org/abs/2601.01806)
*Caisheng Cheng,Ruicheng Bao*

Main category: quant-ph

TL;DR: 该论文研究了开放量子系统中随机Lindbladian动力学的可学习性和密码学应用，证明了学习这类系统需要指数级查询次数，并设计了基于随机Lindbladian的物理不可克隆函数协议。


<details>
  <summary>Details</summary>
Motivation: 研究如何从有限时间测量统计中推断噪声和耗散生成器的结构，这是量子信息、统计物理和多体动力学交叉领域的基本问题。

Method: 在GKSL锥的仿射包中引入物理动机的随机局部Lindbladian集合，扩展统计查询和量子过程统计查询框架到开放系统设置，推导线性响应表达式，并设计Lindbladian物理不可克隆函数协议。

Result: 证明了学习随机Lindbladian动力学需要指数级查询次数，建立了平均情况下的SQ-hardness和QPStat-hardness，验证了随机局部振幅阻尼链中的非零标度，并设计了两种Lindbladian-PUF协议。

Conclusion: 随机Lindbladian动力学的学习具有计算难度，这种学习困难可以转化为密码学安全保证，为开放量子系统提供了新的密码学应用框架。

Abstract: In open quantum systems, a basic question at the interface of quantum information, statistical physics, and many-body dynamics is how well can one infer the structure of noise and dissipation generators from finite-time measurement statistics alone. Motivated by this question, we study the learnability and cryptographic applications of random open-system dynamics generated by Lindblad-Gorini-Kossakowski-Sudarshan (GKSL) master equations. Working in the affine hull of the GKSL cone, we introduce physically motivated ensembles of random local Lindbladians via a linear parametrisation around a reference generator. On top of this geometric structure, we extend statistical query (SQ) and quantum-process statistical query (QPStat) frameworks to the open-system setting and prove exponential (in the parameter dimension $M$) lower bounds on the number of queries required to learn random Lindbladian dynamics. In particular, we establish average-case SQ-hardness for learning output distributions in total variation distance and average-case QPStat-hardness for learning Lindbladian channels in diamond norm. To support these results physically, we derive a linear-response expression for the ensemble-averaged total variation distance and verify the required nonvanishing scaling in a random local amplitude-damping chain. Finally, we design two Lindbladian physically unclonable function (Lindbladian-PUF) protocols based on random Lindbladian ensembles with distribution-level and tomography-based verification, thereby providing open-system examples where learning hardness can be translated into cryptographic security guarantees.

</details>


### [70] [Photon blockade effect from synergistic optical parametric amplification and driving force in Kerr-medium single-mode cavity](https://arxiv.org/abs/2601.01819)
*Zhang Zhiqiang*

Main category: quant-ph

TL;DR: 该研究探讨了在包含克尔非线性腔与光学参量放大器耦合的混合量子系统中光子阻塞的控制，通过解析和数值方法验证了光子阻塞效应，并展示了驱动相位对最佳阻塞区域的调控作用。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子系统中光子阻塞的控制机制，旨在理解如何通过系统参数调控单光子源性能，为增强单光子源亮度提供理论途径。

Method: 使用包含腔衰减的有效哈密顿量推导主方程，在福克基矢中展开至双光子水平求解稳态薛定谔方程，获得解析解和最优光子阻塞条件，并与数值模拟进行对比验证。

Result: 解析解与数值模拟在稳态、等时二阶关联函数方面高度一致，验证了光子阻塞效应；共振条件下腔内平均光子数显著增加；驱动相位可调控最佳阻塞区域的位置和方向；克尔非线性在宽参数范围内保持阻塞稳定性。

Conclusion: 光子阻塞可通过合适的系统参数实现，其稳定性源于两条激发路径间的破坏性量子干涉；驱动相位可作为有效调控工具；该研究为增强单光子源亮度提供了理论框架。

Abstract: This work investigates photon blockade control in a hybrid quantum system containing a Kerr-nonlinear cavity coupled to an optical parametric amplifier (OPA). The dynamics are governed by a master equation derived from an effective Hamiltonian that includes cavity decay.To obtain analytical solutions, the system's quantum state is expanded in the Fock basis up to the two-photon level. Solving the steady-state Schrodinger equation yields probability amplitudes and the analytical conditions for optimal photon blockade. Results confirm that photon blockade is achievable with suitable parameters. Excellent agreement is found between the analytical solutions and numerical simulations for the steady-state, equal-time second-order correlation function, validating both the analytical method and the blockade effect.Numerically, the average intracavity photon number increases significantly under resonance, providing a theoretical pathway for enhancing single-photon source brightness. Furthermore, the driving phase is shown to regulate the optimal blockade region: it shifts the parabolic region within the two-dimensional parameter space of driving strength and OPA nonlinearity and can even reverse its opening direction.The influence of Kerr nonlinearity is also examined. Photon blockade remains robust across a wide range of Kerr strengths. Physical analysis attributes the effect to destructive quantum interference between two distinct excitation pathways that suppress two-photon states. While Kerr nonlinearity shifts the system's energy levels, it does not disrupt this interference mechanism, explaining the effect's stability over a broad parameter range.

</details>


### [71] [Quantum information of optical magnetometry: Semiclassical Cramer-Rao bound violation and Heisenberg scaling](https://arxiv.org/abs/2601.01820)
*Georg Engelhardt,Ming Li,Xingchang Wang,JunYan Luo,J. F. Chen*

Main category: quant-ph

TL;DR: 该论文通过量子信息理论分析光学磁力计，发现半经典模型在弱耗散和大原子数下会违反量子Cramér-Rao界限，而集体自旋模型则始终遵守该界限并预测海森堡标度，揭示了海森堡标度源于测量诱导的量子关联。


<details>
  <summary>Details</summary>
Motivation: 研究光学磁力计中量子信息处理的特性，特别是比较半经典模型和量子集体自旋模型在磁场测量中的表现，探索海森堡标度极限的物理起源。

Method: 采用两种模型进行分析：1）半经典模型，描述激光与原子相互作用的经典近似；2）集体自旋模型，将原子视为量子集体自旋系统。通过比较两种模型的量子费舍尔信息特性，并与实验数据对比。

Result: 半经典模型在弱耗散和大原子数下会违反量子Cramér-Rao界限数个数量级，而集体自旋模型始终遵守该界限。集体模型预测量子费舍尔信息具有海森堡标度，这种标度源于测量诱导的量子关联而非原子间相互作用。

Conclusion: 海森堡标度在宏观量子系统的稳态中出现，为量子传感提供了新范式。两种模型与实验数据的比较可作为量子力学基础在宏观原子系综中的检验。

Abstract: Optical magnetometers use the rotation of linearly polarized laser light induced by the Faraday effect for high precision magnetic field measurements. Here, we carry out an in-depth quantum information investigation, deploying two distinct models: The first, semiclassical model can violate the quantum Cramer-Rao bound by several orders of magnitude for weak dissipation and large atom numbers, invalidating the semiclassical approach in this parameter regime. The second model, describing the atoms as a collective spin, respects the Cramer-Rao bound for all parameters. Interestingly, the collective model also predicts Heisenberg scaling for the quantum Fisher information. The comparison of both models shows that Heisenberg scaling is a result of measurement-induced quantum correlation in an otherwise non-interacting quantum system. As the Heisenberg scaling appears in a stationary state of a macroscopic quantum system, it can be thus viewed as a new paradigm in quantum sensing. Intriguingly, the comparison of both models with experimental data can constitute a test for the foundations of quantum mechanics in a macroscopic ensemble of atoms.

</details>


### [72] [Global Parametric Gates for Multi-qubit Entanglement](https://arxiv.org/abs/2601.01826)
*Jize Yang,Lin Guo,Haonan Xiong,Jiahui Wang,Yan Li,Yunfan Yang,Chenjie An,Hongyi Zhang,Luyan Sun,Yipu Song,Luming Duan*

Main category: quant-ph

TL;DR: 提出并实验演示了一种全局参量门，可在单步操作中生成多量子比特纠缠态，兼容固定频率量子比特，仅需微波驱动


<details>
  <summary>Details</summary>
Motivation: 传统多量子比特纠缠生成通常需要多个两步操作，效率较低。需要一种更高效、可重构且兼容固定频率量子比特的方案来简化多量子比特纠缠的生成

Method: 通过对公共量子比特施加参量驱动，在相对于计算量子比特的精确失谐频率下，直接生成多量子比特纠缠态。该方法仅使用微波驱动，兼容固定频率量子比特

Result: 实验成功生成2、3、4量子比特纠缠态，保真度分别为99.4%±0.2%、93.4%±0.3%、91.4%±0.3%。误差分析表明主要误差源为退相干和相干控制误差。模拟预测在六量子比特系统中可实现99.70%的高保真度纠缠

Conclusion: 该全局参量门提供了一种高效、可重构的多量子比特纠缠生成方法，仅需微波驱动且兼容固定频率量子比特架构，为可扩展量子计算提供了有前景的解决方案

Abstract: We propose and experimentally demonstrate a global parametric gate that generates multi-qubit entangled states in a single step. By applying a parametric drive to a common qubit at precise detunings relative to computational qubits, we directly produce two-, three-, and four-qubit entanglement with state fidelities of 99.4\%\pm0.2\%, 93.4\%\pm0.3\%, and 91.4\%\pm0.3\%, respectively. This scheme enables efficient, reconfigurable control using only microwave drives and is compatible with fixed-frequency qubits. Error analyses indicate that infidelity stems primarily from decoherence and coherent control errors, with negligible contributions from static ZZ coupling and flux noise. Furthermore, simulations with state-of-the-art parameters predict this global gate can generate high-fidelity (99.70\%) entanglement in systems of up to six qubits.

</details>


### [73] [Quantum Interaction Between Free Electrons and Light Involving First-order and Second-order Process](https://arxiv.org/abs/2601.01846)
*Hongteng Lin,Xiaotong Xiong,Junjie Liu,Yidong Huang,Fang Liu*

Main category: quant-ph

TL;DR: 该论文建立了考虑双光子过程的电子-光子相互作用全量子理论，揭示了双光子过程增强机制、量子干涉效应，并阐明了PINEM、Kapitza-Dirac效应和非线性康普顿散射之间的关系。


<details>
  <summary>Details</summary>
Motivation: 虽然PINEM效应揭示了自由电子与光学近场的量子相互作用，但自由电子通常只吸收/发射单个光子，双光子相互作用的物理机制和现象尚未研究。同时，PINEM与Kapitza-Dirac效应和非线性康普顿散射之间的关系也不明确。

Method: 发展了考虑双光子过程的电子-光子相互作用全量子理论，通过操纵光学近场的电场分量来增强双光子过程，并分析单光子和双光子过程之间的量子干涉。

Result: 发现通过操纵光学近场电场分量可显著增强电子的双光子发射/吸收；在某些情况下单光子和双光子过程会发生量子干涉，影响光子数态、电子能态和电子-光子纠缠；同时揭示Kapitza-Dirac效应和非线性康普顿散射也是双光子过程，并基于全量子理论解析推导了电子分布。

Conclusion: 该工作揭示了自由电子与双光子相互作用可能产生的丰富现象，为未来电子-光子量子相互作用中非线性过程的深入研究奠定了基础。

Abstract: Photon-induced Near-field Electron Microscopy (PINEM) effect has revealed the quantum interaction between free electrons and optical near filed, which demonstrated plenty of novel phenomena of manipulating free electron wave packet and detecting/shaping quantum photonic states. However, free electrons generally only absorb/emit one photon at a time, while the physical mechanism and phenomena of free electron-two-photon interaction have not been studied yet. Moreover, the relationship between PINEM and Kapitza-Dirac (KD) effect and nonlinear Compton scattering is still unclear. Here we develop the full quantum theory of electron-photon interaction considering the two-photon process. It is revealed that the emission/absorption of two photons by electrons can be greatly enhanced by manipulating the electric field component of optical near field, and the quantum interference between single-photon and two-photon processes can occur in some circumstances, which affects the photon number state, electron energy states and electron-photon entanglement. Meanwhile, it is found that the KD effect (elastic electron-photon scattering) and nonlinear Compton scattering (inelastic electron-photon scattering) are also a kind of two-photon process and the distribution of electrons can be deduced analytically based on the full quantum theory. Our work uncovers the possible abundant phenomena when free electron interacting with two photons, paves the way for more in-depth studies of nonlinear processes in electron-photon quantum interactions in the future.

</details>


### [74] [A Survey of Bargmann Invariants: Geometric Foundations and Applications](https://arxiv.org/abs/2601.01858)
*Lin Zhang,Bing Xie*

Main category: quant-ph

TL;DR: Bargmann不变量是量子态向量重叠产生的规范不变量，为理解量子力学几何结构提供了统一框架，在量子信息几何、局域幺正等价性判断和纠缠检测中有重要应用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面综述Bargmann不变量，强调其在塑造量子态空间信息几何结构中的核心作用，并展示它们如何从数学概念发展为量子信息科学中的实用工具。

Method: 采用综述研究方法，综合历史背景与最新进展，系统分析Bargmann不变量作为规范不变量如何表征量子态空间的内在几何结构，并探讨其在局域幺正等价性判断、混合态多项式不变量构造以及无需完整态层析的纠缠检测等方面的应用。

Result: Bargmann不变量被证明是表征量子态空间内在几何的强大工具，能够用于确定局域幺正等价性、构造混合态的完整多项式不变量集，并在现代量子信息科学中发展为无需完整态层析的纠缠检测方法。

Conclusion: Bargmann不变量不仅是数学上的有趣概念，更是探索量子系统关系和几何特征的重要工具，在量子信息几何和量子信息科学中具有基础性和实用性价值。

Abstract: Bargmann invariants, a class of gauge-invariant quantities arising from the overlaps of quantum state vectors, provide a profound and unifying framework for understanding the geometric structure of quantum mechanics. This survey offers a comprehensive overview of Bargmann invariants, with a particular focus on their role in shaping the informational geometry of the state space. The core of this review demonstrates how these invariants serve as a powerful tool for characterizing the intrinsic geometry of the space of quantum states, leading to applications in determining local unitary equivalence and constructing a complete set of polynomial invariants for mixed states. Furthermore, we explore their pivotal role in modern quantum information science, specifically in developing operational methods for entanglement detection without the need for full state tomography. By synthesizing historical context with recent advances, this survey aims to highlight Bargmann invariants not merely as mathematical curiosities, but as essential instruments for probing the relational and geometric features of quantum systems.

</details>


### [75] [Random-Matrix-Induced Simplicity Bias in Over-parameterized Variational Quantum Circuits](https://arxiv.org/abs/2601.01877)
*Jun Qi,Chao-Han Huck Yang,Pin-Yu Chen,Min-Hsiu Hsieh*

Main category: quant-ph

TL;DR: 过参数化量子变分电路会进入Haar类普适性，导致可观测量期望值和梯度指数集中，引发简单性偏置和贫瘠高原，但张量结构化的电路可以避免这一问题。


<details>
  <summary>Details</summary>
Motivation: 解释为什么过参数化的变分量子电路(VQCs)经常表现出训练困难和泛化能力有限的现象，从函数类角度提供理论解释。

Method: 使用随机矩阵理论和测度集中工具，分析不同电路架构的普适性类别，比较非结构化ansatze和张量结构化VQCs（包括基于张量网络和张量超网络的参数化）的行为差异。

Result: 充分表达的非结构化变分ansatze进入Haar类普适性，导致可观测量期望值和参数梯度随系统尺寸指数集中，引发简单性偏置和贫瘠高原；而张量结构化VQCs通过限制可访问的酉系综，防止测度集中，保持局部可观测量输出变异性和非退化梯度信号。

Conclusion: 贫瘠高原、表达能力限制和泛化崩溃都源于随机矩阵普适性的单一结构机制，强调了架构归纳偏置在变分量子算法中的核心作用。

Abstract: Over-parameterization is commonly used to increase the expressivity of variational quantum circuits (VQCs), yet deeper and more highly parameterized circuits often exhibit poor trainability and limited generalization. In this work, we provide a theoretical explanation for this phenomenon from a function-class perspective. We show that sufficiently expressive, unstructured variational ansatze enter a Haar-like universality class in which both observable expectation values and parameter gradients concentrate exponentially with system size. As a consequence, the hypothesis class induced by such circuits collapses with high probability to a narrow family of near-constant functions, a phenomenon we term simplicity bias, with barren plateaus arising as a consequence rather than the root cause. Using tools from random matrix theory and concentration of measure, we rigorously characterize this universality class and establish uniform hypothesis-class collapse over finite datasets. We further show that this collapse is not unavoidable: tensor-structured VQCs, including tensor-network-based and tensor-hypernetwork parameterizations, lie outside the Haar-like universality class. By restricting the accessible unitary ensemble through bounded tensor rank or bond dimension, these architectures prevent concentration of measure, preserve output variability for local observables, and retain non-degenerate gradient signals even in over-parameterized regimes. Together, our results unify barren plateaus, expressivity limits, and generalization collapse under a single structural mechanism rooted in random-matrix universality, highlighting the central role of architectural inductive bias in variational quantum algorithms.

</details>


### [76] [Pervasive Vulnerability Analysis and Defense for QKD-based Quantum Private Query](https://arxiv.org/abs/2601.01918)
*Xiaoyu Peng,Bin Liu,Shiyu He,Nankun Mu,Wei Huang,Bingjie Xu,Fei Gao*

Main category: quant-ph

TL;DR: 大多数基于QKD的量子私密查询协议存在后处理阶段的安全漏洞，攻击者可通过直接观测和最小误差判别攻击窃取数据库信息，提出的多重加密防御方案可兼容现有协议并增强安全性。


<details>
  <summary>Details</summary>
Motivation: 量子私密查询(QPQ)作为仅次于QKD的最实用量子通信协议，现有基于QKD的QPQ协议普遍存在后处理阶段的安全漏洞被严重忽视，需要解决这些关键缺陷以构建实用的安全协议。

Method: 研究聚焦于未确定信号比特下的隐藏信息提取，分析两种攻击方式：直接观测攻击导致渐进信息泄露，最小误差判别攻击高效窃取额外数据库信息。提出多重加密防御方案，兼容现有QPQ协议。

Result: 研究发现大多数QKD-based QPQ协议面临严重安全威胁，即使没有复杂量子资源也能被攻击。多重加密策略被证明对数据库安全至关重要，为构建抵抗现实攻击的实用QPQ协议提供关键理论和技术支持。

Conclusion: 多重加密防御方案是确保QPQ数据库安全的必要策略，该研究填补了QPQ协议后处理阶段安全漏洞的研究空白，为开发实用的抗攻击量子私密查询协议奠定基础。

Abstract: Quantum Private Query (QPQ) based on Quantum Key Distribution (QKD) is among the most practically viable quantum communication protocols, with application value second only to QKD itself. However, prevalent security vulnerabilities in the post-processing stages of most existing QKD-based QPQ protocols have been severely overlooked. This study focuses on hidden information extraction under undetermined signal bits, revealing that most such QPQ protocols face severe security threats even without complex quantum resources. Specifically, direct observation attack causes incremental information leakage, while the minimum error discrimination attack efficiently steals additional database inforamtion. To address these critical flaws, the proposed multi-encryption defense scheme is compatible with existing QPQ protocols. The study demonstrates the necessity of the multi-encryption strategy for the security of databases in QPQ, providing key theoretical and technical support for constructing practical QPQ protocols resistant to real-world attacks.

</details>


### [77] [Interpretation of Unfair Sampling in Quantum Annealing by Node Centrality](https://arxiv.org/abs/2601.01920)
*Naoki Maruyama,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: 本文分析了横向场量子退火在采样简并基态时的偏好问题，发现基态图邻接矩阵的特征向量中心性与采样概率相关，并提出了两种提高采样公平性的实用方法。


<details>
  <summary>Details</summary>
Motivation: 在需要多个最优解的应用中，横向场量子退火已知会以强烈偏置的方式采样简并基态。尽管有大量经验观察，但尚不清楚量子退火优先采样简并基态的哪些特征以及原因。

Method: 使用简并微扰理论分析最终状态，通过基态图邻接矩阵的特征向量中心性预测采样概率，并在一阶和二阶简并解除的玩具模型上验证预测。

Result: 分析表明二阶权重编码了局部势垒信息，将采样公平性与局部能量景观的平坦度联系起来。特征向量中心性确实与采样概率相关。

Conclusion: 提出了两种提高采样公平性的实用途径：促进图的连通性和减少中心性的异质性，并与高阶驱动器和次要嵌入变换的观察结果一致。

Abstract: In applications where multiple optimal solutions are needed, transverse-field quantum annealing (QA) is known to sample degenerate ground states in a strongly biased manner. Despite extensive empirical observations, it remains unclear which features of degenerate ground states are preferentially sampled and why by QA. Here we analyze the final states using degenerate perturbation theory to characterize the preference among them. In this analysis, the adjacency matrix of the graph composed by the ground states naturally emerges, and we can predict the eigenvector centralities (one of the node centralities) are related to the probabilities of these states. We verify this prediction on toy models where degeneracy is lifted at first and second order, and we show that second-order weights encode local barrier information, relating sampling fairness to the flatness of the local energy landscape. Finally, this perspective suggests two practical routes toward fair sampling -- promoting connectivity of the graph and reducing heterogeneity of centralities -- and we illustrate consistency with higher-order drivers and minor-embedding transformations.

</details>


### [78] [Self-Supervised Learning with Noisy Dataset for Rydberg Microwave Sensors Denoising](https://arxiv.org/abs/2601.01924)
*Zongkai Liu,Qiming Ren,Wenguang Yang,Yanjie Tong,Huizhen Wang,Yijie Zhang,Ruohao Zhi,Junyao Xie,Mingyong Jing,Hao Zhang,Liantuan Xiao,Suotang Jia,Ke Tang,Linjie Zhang*

Main category: quant-ph

TL;DR: 自监督深度学习框架用于里德堡传感器，实现单次噪声抑制，精度匹配多次测量平均，无需干净参考信号。


<details>
  <summary>Details</summary>
Motivation: 量子传感中通常需要多次测量平均来抑制噪声，但这种方法耗时且计算量大。现有方法如小波变换和卡尔曼滤波效果有限，且传统深度学习需要难以获得的干净参考信号。

Method: 提出自监督深度学习框架，利用两组统计分布相同的噪声信号进行训练，无需干净参考信号。框架基于U-Net和Transformer架构，通过量化复杂度-性能权衡来优化模型选择。

Result: 在里德堡传感数据集上，该框架优于小波变换和卡尔曼滤波，达到相当于10,000次测量平均的去噪效果，同时计算时间减少三个数量级。在不同噪声分布下均表现良好。

Conclusion: 该自监督框架为里德堡传感器系统提供了高效的单次噪声抑制解决方案，通过量化架构权衡为深度学习去噪优化提供实用指导，有望推动量子传感的实际应用。

Abstract: We report a self-supervised deep learning framework for Rydberg sensors that enables single-shot noise suppression matching the accuracy of multi-measurement averaging. The framework eliminates the need for clean reference signals (hardly required in quantum sensing) by training on two sets of noisy signals with identical statistical distributions. When evaluated on Rydberg sensing datasets, the framework outperforms wavelet transform and Kalman filtering, achieving a denoising effect equivalent to 10,000-set averaging while reducing computation time by three orders of magnitude. We further validate performance across diverse noise profiles and quantify the complexity-performance trade-off of U-Net and Transformer architectures, providing actionable guidance for optimizing deep learning-based denoising in Rydberg sensor systems.

</details>


### [79] [On the homogeneity of the quantum transition probability](https://arxiv.org/abs/2601.01936)
*Gerd Niestegge*

Main category: quant-ph

TL;DR: 论文揭示了量子力学跃迁概率在简单欧几里得约当代数中的物理意义，这些代数具有最大程度的齐次性，包括常见的有限维希尔伯特空间量子理论。


<details>
  <summary>Details</summary>
Motivation: 将H.-C. Wang和U. Hirzebruch在1952和1965年关于两点齐次紧空间的数学成果与量子力学跃迁概率联系起来，揭示其物理意义。

Method: 分析简单欧几里得约当代数中的跃迁概率特性，研究其齐次性，并通过纯拓扑方法表征这些代数的原子部分或状态空间的极端边界。

Result: 发现简单欧几里得约当代数中的跃迁概率具有最大程度的齐次性，包括有限维希尔伯特空间量子理论。这些代数的原子部分可以通过纯拓扑方法表征，与许多其他区分凸紧集状态空间的方法形成重要区别。

Conclusion: 数学上两点齐次紧空间的分类结果与量子力学跃迁概率的物理特性密切相关。当使用E6对称双八元数射影平面作为量子逻辑时，会出现非齐次跃迁概率的有趣情况。

Abstract: In the years 1952 and 1965, H.-C. Wang and U. Hirzebruch showed that the two-point homogeneous compact spaces with convex metrics are isometric to the spheres, the real, complex, octonion projective spaces and the Moufang plane and as well to the sets of the minimal idempotents or pure states in the simple Euclidean Jordan algebras. Here we reveal the physical meaning of these mathematical achievements for the quantum mechanical transition probability. We show that this transition probability features a maximum degree of homogeneity in all simple Euclidean Jordan algebras, which includes common finite-dimensional Hilbert space quantum theory. The atomic parts of these algebras or, equivalently, the extreme boundaries of their state spaces can be characterized by purely topological means. This is an important difference to many other recent approaches that aim to distinguish the entire state spaces among the convex compact sets. An interesting case with non-homogeneous transition probability arises, when the $E_6$-symmetric bioctonionic projective plane is used as quantum logic.

</details>


### [80] [Discrete symmetries in classical and quantum oscillators](https://arxiv.org/abs/2601.01960)
*Alexander D. Popov*

Main category: quant-ph

TL;DR: 论文通过谐振子例子探讨波函数本质，证明Bargmann-Fock-Segal表示中的本征函数ψ_n=z^n对应经典谐振子坐标，定义在锥形空间ℂ/ℤ_n上，叠加态源于初始数据的不完全知识。


<details>
  <summary>Details</summary>
Motivation: 探讨量子力学波函数的本质，特别是通过谐振子这一基本系统来理解本征函数与经典系统之间的关系。

Method: 使用Bargmann-Fock-Segal复表示，分析谐振子的本征函数ψ_n=z^n，将其解释为经典谐振子在锥形空间ℂ/ℤ_n上的坐标，其中ℤ_n是旋转2π/n的有限循环群。

Result: 证明量子谐振子的本征函数ψ_n=z^n对应经典谐振子坐标，能量为E_n=ħωn，定义在锥角为2π/n的锥形空间ℂ/ℤ_n上，这些空间嵌入经典相空间ℂ中。

Conclusion: 波函数叠加态ψ=∑c_nψ_n源于求解薛定谔方程时初始数据的不完全知识，当不施加离散群ℤ_n的不变性条件时，一般解包含所有可能的初始数据参数n∈ℕ。

Abstract: We consider the nature of the wave function using the example of a harmonic oscillator. We show that the eigenfunctions $ψ_n{=}z^n$ of the quantum Hamiltonian in the complex Bargmann-Fock-Segal representation with $z\in\mathbb C$ are the coordinates of a classical oscillator with energy $E_n=\hbarωn$, $n=0,1,2,...\,$. They are defined on conical spaces ${\mathbb C}/{\mathbb Z}_n$ with cone angles $2π/n$, which are embedded as subspaces in the phase space $\mathbb C$ of the classical oscillator. Here ${\mathbb Z}_n$ is the finite cyclic group of rotations of the space $\mathbb C$ by an angle $2π/n$. The superposition $ψ=\sum_n c_nψ_n$ of the eigenfunctions $ψ_n$ arises only with incomplete knowledge of the initial data for solving the Schrödinger equation, when the conditions of invariance with respect to the discrete groups ${\mathbb Z}_n$ are not imposed and the general solution takes into account all possible initial data parametrized by the numbers $n\in\mathbb N$.

</details>


### [81] [Experimental realization of quantum Zeno dynamics for robust quantum metrology](https://arxiv.org/abs/2601.01987)
*Ran Liu,Xiaodong Yang,Xiang Lv,Xinyue Long,Hongfeng Liu,Dawei Lu,Ying Dong,Jun Li*

Main category: quant-ph

TL;DR: 该论文提出了一种利用量子芝诺动力学(QZD)实现鲁棒量子计量学的方法，通过在参数编码阶段引入强粒子间相互作用，克服了传统QZD研究的局限性，并在核磁共振平台上实验验证了该方案。


<details>
  <summary>Details</summary>
Motivation: 量子芝诺动力学(QZD)通过将系统演化限制在受保护子空间，为保护量子信息免受噪声影响提供了有前景的方法。然而，以往的QZD研究主要关注单粒子系统，且面临QZD可能干扰参数编码过程的挑战。本研究旨在探索利用QZD实现鲁棒量子计量的实用方法。

Method: 在参数编码阶段引入强粒子间相互作用，克服传统QZD研究的局限性。该方法在核磁共振平台上进行实验验证，并在平行和顺序设置下测试其性能。通过数值模拟进一步验证该方法的可扩展性和与其他控制技术的兼容性。

Result: 实验结果表明，在振幅阻尼噪声下，该方法在平行和顺序设置中均实现了接近最优的精度标度。数值模拟进一步证明该方法具有良好的可扩展性，并且能够与其他控制技术兼容以抑制更一般类型的噪声。

Conclusion: 量子芝诺动力学(QZD)是一种强大的噪声弹性量子计量策略。通过引入强粒子间相互作用，该方法克服了传统QZD研究的局限性，为实际量子计量应用提供了有效的噪声抑制方案。

Abstract: Quantum Zeno dynamics (QZD), which restricts the system's evolution to a protected subspace, provides a promising approach for protecting quantum information from noise. Here, we explore a practical approach to harnessing QZD for robust quantum metrology. By introducing strong inter-particle interactions during the parameter encoding stage, we overcome the typical limitations of previous QZD studies, which have largely focused on single-particle systems and faced challenges where QZD could interfere with the encoding process. We experimentally validate the proposed scheme on a nuclear magnetic resonance platform, achieving near-optimal precision scaling under amplitude damping in both parallel and sequential settings. Numerical simulations further demonstrate the scalability of the approach and its compatibility with other control techniques for suppressing more general types of noise. These findings highlight QZD as a powerful strategy for noise-resilient quantum metrology.

</details>


### [82] [Continuous Unitary Designs for Universally Robust Quantum Control](https://arxiv.org/abs/2601.01988)
*Xiaodong Yang,Jiaqing Leng,Jun Li*

Main category: quant-ph

TL;DR: 该论文首次研究连续幺正设计，构建了单量子比特和任意维度的连续幺正设计路径，并展示了其在量子控制中的实际应用，优于传统脉冲技术。


<details>
  <summary>Details</summary>
Motivation: 现有幺正设计研究集中于离散集合，但许多物理过程（如量子混沌、热化和控制）自然涉及连续时间演化产生的连续集合。需要研究连续幺正设计以填补这一空白。

Method: 对于单量子比特系统，利用球面2-设计曲线和Hopf纤维化理论构建显式幺正1-设计路径。对于任意维度，开发两种系统构建框架：基于幺正群拓扑丛理论和基于Heisenberg-Weyl群的方法。

Result: 构建的幺正设计路径为通用鲁棒量子控制提供解析解。仿真显示其在抑制任意未知静态噪声方面优于传统脉冲技术，增强了实验可行性。

Conclusion: 将幺正设计扩展到连续域不仅引入了强大的几何和拓扑工具，还提高了实验可行性。这项工作为使用连续幺正设计探索复杂量子动力学和设计量子信息协议铺平了道路。

Abstract: Unitary designs are unitary ensembles that emulate Haar-random unitary statistics. They provide a vital tool for studying quantum randomness and have found broad applications in quantum technologies. However, existing research has focused on discrete ensembles, despite that many physical processes, such as in quantum chaos, thermalization, and control, naturally involve continuous ensembles generated from continuous time-evolution. Here we initial the study of continuous unitary designs, addressing fundamental questions about their construction and practical utility. For single-qubit system, we construct explicit unitary 1-design paths from spherical 2-design curves and Hopf fibration theory. For arbitrary dimensions, we develop two systematic construction frameworks, one based on topological bundle theory of the unitary group and the other based on the Heisenberg-Weyl group. On the practical front, our unitary design paths provide analytical solutions to universally robust quantum control. Simulations show they outperform conventional pulse techniques in mitigating arbitrary unknown static noises, demonstrating immediate utility for quantum engineering. Extending unitary designs to the continuous domain not only introduces powerful geometric and topological tools that complement conventional combinatorial and group-theoretic methods, but also enhances experimental feasibility over discrete counterparts which usually involve instantaneous pulses. As an outlook, we anticipate that this work will pave the way for using continuous unitary designs to explore complex quantum dynamics and devise quantum information protocols.

</details>


### [83] [Parallel Quantum Gates via Scalable Subsystem-Optimized Robust Control](https://arxiv.org/abs/2601.01990)
*Xiaodong Yang,Ran Liu,Jun Li*

Main category: quant-ph

TL;DR: 提出一种可扩展的并行量子控制框架，通过将全系统优化简化为对恒定大小子系统的串扰鲁棒控制，显著降低计算成本，有效消除串扰引起的门操作偏差。


<details>
  <summary>Details</summary>
Motivation: 当前量子处理器中不可避免的量子比特串扰阻碍了高保真度门的实现，且全希尔伯特空间控制优化计算成本过高，难以扩展。

Method: 将全系统优化简化为对恒定大小子系统的串扰鲁棒控制，构建并行单量子比特门的解析脉冲解和并行多量子比特门的数值脉冲解。

Result: 在多个平台上验证有效：耦合氮空位中心、核自旋处理器和最多200个量子比特的超导量子比特阵列。并行单量子比特门的噪声缩放从指数级降至线性级，并行多量子比特门的误差降低一个数量级。

Conclusion: 该方法无需精确了解串扰强度，不依赖底层量子比特连接性或晶格几何结构，为大规模量子架构中的并行量子控制建立了可扩展框架。

Abstract: Accurate and efficient implementation of parallel quantum gates is crucial for scalable quantum information processing. However, the unavoidable crosstalk between qubits in current noisy processors impedes the achievement of high gate fidelities and renders full Hilbert-space control optimization prohibitively difficult. Here, we overcome this challenge by reducing the full-system optimization to crosstalk-robust control over constant-sized subsystems, which dramatically reduces the computational cost. Our method effectively eliminates the leading-order gate operation deviations induced by crosstalk, thereby suppressing error rates. Within this framework, we construct analytical pulse solutions for parallel single-qubit gates and numerical pulses for parallel multi-qubit operations. We validate the proposed approach numerically across multiple platforms, including coupled nitrogen-vacancy centers, a nuclear-spin processor, and superconducting-qubit arrays with up to 200 qubits. As a result, the noise scaling is reduced from exponential to linear for parallel single-qubit gates, and an order-of-magnitude reduction is achieved for parallel multi-qubit gates. Moreover, our method does not require precise knowledge of crosstalk strengths and makes no assumption about the underlying qubit connectivity or lattice geometry, thereby establishing a scalable framework for parallel quantum control in large-scale quantum architectures.

</details>


### [84] [Absolutely Maximal Contextual Correlations](https://arxiv.org/abs/2601.02009)
*Nripendra Majumdar,S. Aravinda*

Main category: quant-ph

TL;DR: 该论文研究量子信息中的最大关联，类比纠缠理论中的最大纠缠态，定义了绝对最大上下文关联(AMCC)，并构建了无限族AMCC，应用于秘密共享和随机性提取。


<details>
  <summary>Details</summary>
Motivation: 受Bell非定域性工作的启发，研究如何定义和构造类似于纠缠理论中最大纠缠态的最大关联，为量子信息处理提供理论基础。

Method: 采用层论(contextuality)框架，使用上下文分数(CF)度量关联性，定义绝对最大上下文关联(AMCC)，利用奇偶校验方法和约束满足问题(CSP)方案构造无限族AMCC。

Result: 成功定义了AMCC概念，构建了无限族各种形式的AMCC，发现了非AMCC的最大上下文关联，并将结果应用于秘密共享和随机性提取。

Conclusion: 该研究建立了量子关联理论中最大关联的框架，类比于纠缠理论，为量子信息处理应用提供了新的工具和理论基础。

Abstract: The foundational work by Bell led to an interest in understanding non-local correlations that arise from entangled states shared between distinct, spacelike-separated parties, which formed a foundation for the theory of quantum information processing. We investigate the question of maximal correlations analogous to the maximally entangled states defined in the entanglement theory of multipartite systems. To formalize this, we employ the sheaf-theoretic framework for contextuality, which generalizes non-locality. This provides a new metric for correlations called contextual fraction (CF), which ranges from 0 (non-contextual) to 1 (maximally contextual). Using this, we have defined the absolutely maximal contextual correlations (AMCC), which are maximally contextual and have maximal marginals, which captures the notion of absolutely maximal entangled (AME) states. The Popescu-Rohrlich (PR) box serves as the bipartite example, and we construct various extensions of such correlations in the tripartite case. An infinite family of various forms of AMCC is constructed using the parity check method and the constraint satisfiability problem (CSP) scheme. We also demonstrate the existence of maximally contextual correlations, which do not exhibit maximal marginals, and refer to them as non-AMCC. The results are further applied to secret sharing and randomness extraction using AMCC correlations.

</details>


### [85] [Integrating Quantum Software Tools with(in) MLIR](https://arxiv.org/abs/2601.02062)
*Patrick Hopf,Erick Ochoa Lopez,Yannick Stade,Damian Rovara,Nils Quetschlich,Ioan Albert Florea,Josh Izaac,Robert Wille,Lukas Burgholzer*

Main category: quant-ph

TL;DR: 本文为量子软件工程师提供MLIR实用指南，通过PennyLane与MQT集成案例，降低MLIR学习门槛，促进量子软件工具互操作性


<details>
  <summary>Details</summary>
Motivation: 量子编译仍处于初级阶段，现有解决方案多为临时性且缺乏互操作性，导致量子软件工具孤立。MLIR在经典计算领域解决了类似问题，但其陡峭的学习曲线阻碍了在量子计算领域的应用，而量子软件栈主要由实验人员而非专业软件工程师构建

Method: 通过具体案例研究，将Xanadu的PennyLane框架与慕尼黑量子工具包(MQT)连接，提供可操作的集成步骤、最佳实践和实际开发经验

Result: 提供实用指南帮助量子工具开发者克服MLIR学习曲线，促进MLIR作为量子软件工具生态系统的统一桥梁，支持更模块化、可互操作和集成的量子软件栈开发

Conclusion: 本文旨在支持量子工具开发者应对MLIR复杂性，促进MLIR在快速增长的量子软件工具生态系统中的采用，作为统一桥梁，最终指导开发更模块化、可互操作和集成的量子软件栈

Abstract: Compilers transform code into action. They convert high-level programs into executable hardware instructions - a crucial step in enabling reliable and scalable quantum computation. However, quantum compilation is still in its infancy, and many existing solutions are ad hoc, often developed independently and from scratch. The resulting lack of interoperability leads to significant missed potential, as quantum software tools remain isolated and cannot be seamlessly integrated into cohesive toolchains.
  The Multi-Level Intermediate Representation (MLIR) has addressed analogous challenges in the classical domain. It was developed within the LLVM project, which has long powered robust software stacks and enabled compilation across diverse software and hardware components, with particular importance in high-performance computing environments. However, MLIR's steep learning curve poses a significant barrier to entry, particularly in quantum computing, where much of the software stack is still predominantly built by experimentalists out of necessity rather than by experienced software engineers.
  This paper provides a practical and hands-on guide for quantum software engineers to overcome this steep learning curve. Through a concrete case study linking Xanadu's PennyLane framework with the Munich Quantum Toolkit (MQT), we outline actionable integration steps, highlight best practices, and share hard-earned insights from real-world development. This work aims to support quantum tool developers in navigating MLIR's complexities and to foster its adoption as a unifying bridge across a rapidly growing ecosystem of quantum software tools, ultimately guiding the development of more modular, interoperable, and integrated quantum software stacks.

</details>


### [86] [Cutting Quantum Circuits Beyond Qubits](https://arxiv.org/abs/2601.02064)
*Manav Seksaria,Anil Prabhakar*

Main category: quant-ph

TL;DR: 将量子电路切割扩展到包含混合维度量子比特的异构寄存器，通过分解非局域相互作用为局部广义Gell-Mann矩阵的张量积，实现高维电路在断开硬件片段上的模拟和执行。


<details>
  <summary>Details</summary>
Motivation: 现有量子电路切割主要针对同构量子比特系统，无法处理包含不同维度量子比特（如qubit-qutrit混合）的异构寄存器。需要开发能够处理混合维度量子系统的电路切割方法，以在断开硬件上执行高维量子电路。

Method: 通过将非局域相互作用分解为局部广义Gell-Mann矩阵的张量积，将高维量子电路切割成可在断开硬件片段上执行的子电路。该方法特别适用于异构寄存器，如qubit-qutrit（2-3维度）接口。

Result: 在qubit-qutrit接口上验证了框架，实现了精确状态重建，总变差距离在单精度浮点容差内为0。在8粒子、维度8的系统中展示了内存优势，将每电路内存使用从128MB减少到64KB。

Conclusion: 成功扩展量子电路切割到异构混合维度寄存器，为在断开硬件上执行高维量子电路提供了有效方法，显著减少了内存需求，为大规模异构量子系统模拟和执行开辟了新途径。

Abstract: We extend quantum circuit cutting to heterogeneous registers comprising mixed-dimensional qudits. By decomposing non-local interactions into tensor products of local generalised Gell-Mann matrices, we enable the simulation and execution of high-dimensional circuits on disconnected hardware fragments. We validate this framework on qubit--qutrit ($2$--$3$) interfaces, achieving exact state reconstruction with a Total Variation Distance of 0 within single-precision floating-point tolerance. Furthermore, we demonstrate the memory advantage in an 8-particle, dimension-8 system, reducing memory usage from 128 MB to 64 KB per circuit.

</details>


### [87] [Optimization of modulation transfer protocol for Rydberg RF receivers](https://arxiv.org/abs/2601.02070)
*Mickael Branco,K V Adwaith,Duc-Anh Trinh,Sacha Welinski,Perrine Berger,Fabienne Goldfarb,Fabien Bretenaker*

Main category: quant-ph

TL;DR: 提出并优化了一种基于热里德堡原子的量子射频接收器调制转移协议，通过耦合光束的相位调制转换为探测光束的幅度调制，显著扩展了检测带宽。


<details>
  <summary>Details</summary>
Motivation: 传统基于热里德堡原子的量子射频接收器存在带宽限制，需要开发新协议来扩展检测带宽，特别是对于失谐射频信号的测量。

Method: 采用调制转移协议，对耦合光束进行相位调制，利用原子的非线性响应将其转换为探测光束的幅度调制。建立理论模型优化调制频率和调制幅度，最大化原子响应。

Result: 优化后的调制转移协议在射频信号失谐超过几MHz时，灵敏度优于传统协议，显著扩展了检测带宽。实验结果与模拟结果吻合良好。

Conclusion: 调制转移协议为扩展量子射频接收器带宽提供了有效方法，特别适用于失谐射频信号的检测，是传统协议的有力补充。

Abstract: We explore theoretically and experimentally the recently demonstrated modulation transfer protocol [D.-A. Trinh, K. V. Adwaith, M. Branco, A. Rouxel, S. Welinski, P. Berger, F. Goldfarb, and F. Bretenaker, Applied Physics Letters 125, 154001 (2024)] aiming at extending the bandwidth of quantum RF receivers based on hot Rydberg atoms. This protocol is based on a phase modulation of the coupling beam, which is transformed by the nonlinear response of the atoms into an amplitude modulation of the probe beam. We develop a theoretical model to optimize both the modulation frequency and the modulation amplitude of the coupling beam, thereby maximizing the atomic response. Once optimized, the sensitivity to detuned RF fields of this modulation transfer protocol is compared with that of the conventional protocol. This comparison shows that the new protocol outperforms the usual one as soon as the RF signal to be measured is detuned by more than a few MHz and offers a complementary approach to increase the detection bandwidth. In all cases, the experimental results are in good agreement with the simulations.

</details>


### [88] [Adaptive Framework for Failure-Aware Protocols in Fusion-Based Graph-State Generation](https://arxiv.org/abs/2601.02087)
*Korbinian Staudacher,Bhilahari Jeevanesan,Tobias Guggemos*

Main category: quant-ph

TL;DR: 提出一个优化线性光学系统中光子图态生成过程的框架，通过图论分析和马尔可夫过程建模来降低融合测量的硬件成本


<details>
  <summary>Details</summary>
Motivation: 在量子计算中，光子图态是重要资源，但通过非确定性融合测量构建大规模图态效率低下，需要优化构建过程以降低硬件成本

Method: 开发基于图论的框架来优化融合网络，提出自适应融合失败的协议，将协议建模为有限马尔可夫过程，使用多项式算法优化融合顺序

Result: 相比简单的重复直到成功协议，该策略能将融合开销降低几个数量级，特别是在50-75%的现实融合成功率下效果显著

Conclusion: 提出的图论框架和优化方法能有效降低光子图态生成的硬件需求，为实际量子计算应用提供了可行的构建策略

Abstract: We consider the generation of photonic graph states in a linear optics setting where sequential non-deterministic fusion measurements are used to build large graph states out of small linear clusters and develop a framework to optimize the building process using graph theoretic characterizations of fusion networks. We present graph state generation protocols for linear cluster resource states and Type-I/Type-II fusions which are adaptive to fusion failure, that is, they reuse leftover graph states in the remaining building process. To estimate hardware costs, we interpret our protocols as finite Markov processes. This viewpoint allows to cast the expected number of fusion measurements until success as a first passage problem. We then deploy a pipeline of polynomial algorithms to optimize arbitrary graph states, extract fusion networks and find beneficial orderings of fusions with the goal of lowering the corresponding mean first passage times. We evaluate our pipeline for different initial resource states and fusion mechanisms with varying success probabilities. Results show that our strategies can reduce the fusion overhead by several orders of magnitude when compared to simple repeat until success protocols, especially for realistic fusion success probabilities between 50-75 %.

</details>


### [89] [Efficient Calculation of the Maximal Rényi Divergence for a Matrix Product State via Generalized Eigenvalue Density Matrix Renormalization Group](https://arxiv.org/abs/2601.02122)
*Uri Levin,Noa Feldman,Moshe Goldstein*

Main category: quant-ph

TL;DR: 本文提出了一种基于最大Rényi散度的量子互信息计算方法，针对矩阵乘积态开发了广义特征值版本的密度矩阵重整化群算法，并在XXZ链上进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 量子互信息的传统计算方法（基于冯·诺依曼熵）需要指数级资源，存在"维度灾难"问题。基于Rényi散度的替代度量具有重要理论特性，但需要高效的计算方法。

Method: 针对一维矩阵乘积态，开发了广义特征值版本的密度矩阵重整化群算法来计算最大Rényi散度，该度量可表示为广义特征值问题的解。

Result: 在典型的XXZ链模型上进行基准测试，发现最大Rényi散度与冯·诺依曼互信息表现出不同的趋势，验证了方法的有效性。

Conclusion: 提出的算法能高效计算最大Rényi散度，为量子多体系统中的关联研究提供了新工具，揭示了不同互信息度量的差异特性。

Abstract: The study of quantum and classical correlations between subsystems is fundamental to understanding many-body physics. In quantum information theory, the quantum mutual information, $I(A;B)$, is a measure of correlation between the subsystems $A,B$ in a quantum state, and is defined by the means of the von Neumann entropy: $I\left(A;B\right)=S\left(ρ_{A}\right)+S\left(ρ_{B}\right)-S\left(ρ_{AB}\right)$. However, such a computation requires an exponential amount of resources. This is a defining feature of quantum systems, the infamous ``curse of dimensionality'' . Other measures, which are based on Rényi divergences instead of von Neumann entropy, were suggested as alternatives in a recent paper showing them to possess important theoretical features, and making them leading candidates as mutual information measures. In this work, we concentrate on the maximal Rényi divergence. This measure can be shown to be the solution of a generalized eigenvalue problem. To calculate it efficiently for a 1D state represented as a matrix product state, we develop a generalized eigenvalue version of the density matrix renormalization group algorithm. We benchmark our method for the paradigmatic XXZ chain, and show that the maximal Rényi divergence may exhibit different trends than the von Neumann mutual information.

</details>


### [90] [Flux-noise-resilient transmon qubit via a doubly-connected gradiometric design](https://arxiv.org/abs/2601.02137)
*J. B. Fu,Da-Wei Wang,B. Ren,Z. H. Yang,S. Hu,G. Y. Huang,S. H. Cao,D. D. Liu,X. F. Zhang,X. Fu,S. C. Xue,Y. G. Che,Yu-xi Liu,M. T. Deng,J. J. Wu*

Main category: quant-ph

TL;DR: 提出一种新型梯度计式超导量子比特"8-mon"，通过纳米空气桥连接两个环路，在保持电调谐性的同时显著抑制低频磁通噪声，提升相干时间。


<details>
  <summary>Details</summary>
Motivation: 传统可调谐超导transmon量子比特对低频磁通噪声敏感，这限制了其相干时间和性能。需要一种既能保持电调谐性又能抑制磁通噪声的设计。

Method: 设计了一种双连接梯度计式transmon量子比特（"8-mon"），采用纳米空气桥连接两个环路。该设计保持完全电调谐性，与标准X-mon控制和读取兼容，无需额外测量开销。

Result: 8-mon在保持与参考X-mons相当的T1弛豫时间的同时，在小磁通偏置区域将Ramsey相干时间T2*提升了近三倍，达到与T1相同的量级。设备还表现出优异的长期频率稳定性，即使没有磁屏蔽。通过空间相关磁通噪声模型模拟，揭示了超导芯片环境中短程和长程相关磁噪声的共存。

Conclusion: 8-mon通过稳健的几何设计将高调谐性与内在磁通噪声抑制相结合，为实现更相干、更稳定的超导量子处理器提供了实用途径。

Abstract: Frequency-tunable superconducting transmon qubits are a cornerstone of scalable quantum processors, yet their performance is often degraded by sensitivity to low-frequency flux noise. Here we present a doubly-connected gradiometric transmon (the ``8-mon") that incorporates a nano-airbridge to link its two loops. This design preserves full electrical tunability and remains fully compatible with standard X-mon control and readout, requiring no additional measurement overhead. The airbridge interconnect eliminates dielectric loss, which enables the 8-mon to achieve both energy relaxation times $T_{\rm 1}$ comparable to reference X-mons and, in the small flux-bias regime, a nearly threefold enhancement in Ramsey coherence time $T_{\rm 2}^*$. This improved $T_{\rm 2}^*$ reaches the same order as $T_{\rm 1}$ without employing echo decoupling. The device also exhibits superior long-term frequency stability even without any magnetic field shielding. We develop a spatially correlated flux-noise model whose simulations quantitatively reproduce the experimental coherence trends, revealing the coexistence of short- and long-correlation-length magnetic noise in the superconducting chip environment. By unifying high tunability with intrinsic flux-noise suppression through a robust geometric design, the 8-mon provides a practical pathway toward more coherent and stable superconducting quantum processors.

</details>


### [91] [Quantum Extreme Reservoir Computing for Phase Classification of Polymer Alloy Microstructures](https://arxiv.org/abs/2601.02150)
*Arisa Ikeda,Akitada Sakurai,Kae Nemoto,Mayu Muramatsu*

Main category: quant-ph

TL;DR: 量子极端储层计算应用于聚合物合金微观结构图像分类，展示了量子机器学习在材料科学中的实际应用潜力


<details>
  <summary>Details</summary>
Motivation: 量子机器学习有望通过利用量子系统的指数级状态空间高效处理高维数据，但先前研究主要关注MNIST等基准数据集，缺乏在具有直接材料相关性的工程数据上的应用验证

Method: 采用量子极端储层计算(QERC)方法，应用于自洽场理论生成的聚合物合金微观结构图像分类，通过数值实验研究关键计算参数（量子比特数、采样成本、储层配置）对分类性能的影响

Result: 分类结果以相图形式展示聚合物形态的相变，建立了量子模型输出与材料行为之间的可理解联系，为量子编码器设计和模型泛化提供了实用指南

Conclusion: 该工作展示了QERC在真实材料数据集上的性能，为将量子学习技术整合到材料信息学中奠定了基础

Abstract: Quantum machine learning (QML) is expected to offer new opportunities to process high-dimensional data efficiently by exploiting the exponentially large state space of quantum systems. In this work, we apply quantum extreme reservoir computing (QERC) to the classification of microstructure images of polymer alloys generated using self-consistent field theory (SCFT). While previous QML efforts have primarily focused on benchmark datasets such as MNIST, our work demonstrates the applicability of QERC to engineering data with direct materials relevance. Through numerical experiments, we examine the influence of key computational parameters-including the number of qubits, sampling cost (the number of measurement shots), and reservoir configuration-on classification performance. The resulting phase classifications are depicted as phase diagrams that illustrate the phase transitions in polymer morphology, establishing an understandable connection between quantum model outputs and material behavior. These results illustrate QERC performance on realistic materials datasets and suggest practical guidelines for quantum encoder design and model generalization. This work establishes a foundation for integrating quantum learning techniques into materials informatics.

</details>


### [92] [Optical nonlinearity of cold atomic ensemble driven by strong coherent field in a saturation regime](https://arxiv.org/abs/2601.02152)
*A. S. Usoltsev,L. V. Gerasimov,A. D. Manukhova,S. P. Kulik,D. V. Kupriyanov*

Main category: quant-ph

TL;DR: 该论文研究了由矢量型二能级原子组成的介电介质在强相干场驱动下的介电响应，发现通过调控泵浦和密度可显著增强光学非线性，这对基于参量过程产生纠缠光子的量子通信协议存在限制。


<details>
  <summary>Details</summary>
Motivation: 研究在强相干场驱动下，由矢量型二能级原子组成的介电介质的微观介电响应特性，特别关注介质密度对光学非线性的影响及其对量子通信协议的潜在限制。

Method: 采用微观分析方法，研究稀薄原子气体中遵循Mollow型非线性激发机制的原子动力学，并将单个原子响应集体化到介质介电响应中，进一步将集体动力学外推到致密介质情况。

Result: 在致密介质中，通过同时调控相干泵浦和样品密度，可以显著增强光学非线性（特别是其参量部分），这表明基于参量过程产生纠缠光子的量子通信协议存在潜在的能力限制。

Conclusion: 介电介质的光学非线性可通过泵浦和密度调控显著增强，这对利用参量过程产生纠缠光子作为主要量子关联资源的量子通信协议提出了重要限制和挑战。

Abstract: We present a microscopic analysis and evaluation of the dielectric susceptibility of a dielectric medium consisting of vector-type two-energy-level atoms responding on a weak probe mode when the atoms are driven by a strong coherent field. Each atom, in an environment of others, exists as a quasiparticle further structuring a bulk medium. In a limit of dilute atomic gas, the dynamics of each atom follows the Mollow-type nonlinear excitation regime, and the medium susceptibility collectivizes the individual atomic responses to the probe mode. We outline how the collective dynamics can be interpolated up to a dense medium, and we argue from general positions that in such a medium the optical nonlinearity and, in particular, its parametric part could be significantly magnified by manipulating both the coherent pump and the sample density. That indicates certain limitations for potential capabilities of quantum communication protocols utilizing the entangled photons, created by a parametric process, as a main resource of quantum correlations.

</details>


### [93] [Simulating Non-Markovian Dynamics in Open Quantum Systems](https://arxiv.org/abs/2601.02160)
*Meng Xu,Vasilii Vadimov,J. T. Stockburger,J. Ankerhold*

Main category: quant-ph

TL;DR: 该论文系统综述了开放量子系统动力学的各种模拟方法，通过统一框架分析不同方法的联系、优缺点及适用性


<details>
  <summary>Details</summary>
Motivation: 量子技术发展需要高精度、高效的计算方法来模拟开放量子系统动力学，但现有方法来自不同领域，导致碎片化，阻碍了跨领域应用和进展

Method: 采用统一框架，在扩展状态空间中包含有效库模式，系统分析和比较各种方法（层次运动方程、Lindblad伪模公式、链映射方法、量子布朗运动主方程、随机展开、精化量子主方程等）

Result: 建立了不同方法之间的联系，阐明了它们的物理解释、相互关系和适用性，为理解现有方法提供了全面视角

Conclusion: 统一框架有助于催化该领域的进一步进展，促进不同方法的交叉应用，为复杂系统的当前问题提供有效解决方案

Abstract: Recent advances in quantum technologies and related experiments have created a need for highly accurate, versatile, and computationally efficient simulation techniques for the dynamics of open quantum systems. Long-lived correlation effects (non-Markovianity), system-environment hybridization, and the necessity for accuracy beyond the Born-Markov approximation form particular challenges. Approaches to meet these challenges have been introduced, originating from different fields, such as hierarchical equations of motion, Lindblad-pseudomode formulas, chain-mapping approaches, quantum Brownian motion master equations, stochastic unravelings, and refined quantum master equations. This diversity, while indicative of the field's relevance, has inadvertently led to a fragmentation that hinders cohesive advances and their effective cross-community application to current problems for complex systems. How are different approaches related to each other? What are their strengths and limitations? Here we give a systematic overview and concise discussion addressing these questions. We make use of a unified framework which very conveniently allows to link different schemes and, this way, may also catalyze further progress. In line with the state of the art, this framework is formulated not in a fully reduced space of the system but in an extended state space which in a minimal fashion includes effective reservoir modes. This in turn offers a comprehensive understanding of existing methods, elucidating their physical interpretations, interconnections, and applicability.

</details>


### [94] [Developments in superconducting erasure qubits for hardware-efficient quantum error correction](https://arxiv.org/abs/2601.02183)
*Maria Violaris,Luciana Henaut,James Wills,Gioele Consani,Jamie Friel,Brian Vlastakis*

Main category: quant-ph

TL;DR: 本文探讨了擦除量子比特在量子纠错中的应用，重点介绍了基于超导量子比特的双轨编码擦除量子比特实现，以及如何通过硬件特定噪声配置实现更高效的量子纠错。


<details>
  <summary>Details</summary>
Motivation: 量子计算机本质上是噪声的，实现大规模容错量子计算的关键挑战在于实施量子纠错。通过设计具有特定噪声配置的硬件，可以为某些量子纠错码显著提高噪声阈值。

Method: 采用擦除量子比特方法，通过将硬件内置的内码与外码级联来实现硬件高效的量子纠错。重点关注基于超导量子比特的双轨编码擦除量子比特实现。

Result: 综述了理论和模拟的最新进展以及硬件演示器，讨论了不同实现方式的差异、使用量子错误检测的近中期应用，以及开发早期容错量子计算机的开放问题。

Conclusion: 擦除量子比特为实现硬件高效的量子纠错提供了有前景的方向，通过特定硬件设计可以显著提高噪声阈值，为早期容错量子计算机的发展铺平道路。

Abstract: Quantum computers are inherently noisy, and a crucial challenge for achieving large-scale, fault-tolerant quantum computing is to implement quantum error correction. A promising direction that has made rapid recent progress is to design hardware that has a specific noise profile, leading to a significantly higher threshold for noise with certain quantum error correcting codes. This Perspective focuses on erasure qubits, which enable hardware-efficient quantum error correction, by concatenating an inner code built-in to the hardware with an outer code. We focus on implementations of dual-rail encoded erasure qubits using superconducting qubits, giving an overview of recent developments in theory and simulation, and hardware demonstrators. We also discuss the differences between implementations; near-term applications using quantum error detection; and the open problems for developing this approach towards early fault-tolerant quantum computers.

</details>


### [95] [A General Class of Functionals for Certifying Quantum Incompatibility](https://arxiv.org/abs/2601.02239)
*Kuan-Yi Lee,Jhen-Dong Lin,Adam Miranowicz,Yueh-Nan Chen*

Main category: quant-ph

TL;DR: 提出基于凸泛函的优化自由非线性不兼容见证框架，证明其非平凡性条件，展示在纯态纠缠度量、测量不兼容和仪器不兼容中的应用


<details>
  <summary>Details</summary>
Motivation: 量子导引、测量不兼容和仪器不兼容最近被统一为量子不兼容的表现形式，需要发展更有效的检测方法

Method: 构建基于凸泛函的优化自由非线性不兼容见证框架，证明其非平凡性条件，应用于纯态纠缠度量、测量不兼容和仪器不兼容

Result: 证明了见证的非平凡性条件，在纯态情况下优于线性导引不等式，可作为真正的不兼容单调量，并用Wigner-Yanase偏信息和相干泛函验证

Conclusion: 建立了统一的不兼容见证框架，在纯态纠缠检测中表现优异，可推广到测量和仪器不兼容，具有操作相关性

Abstract: Quantum steering, measurement incompatibility, and instrument incompatibility have recently been recognized as unified manifestations of quantum incompatibility. Building on this perspective, we develop a general framework for constructing optimization-free, nonlinear incompatibility witnesses based on convex functionals, valid in arbitrary dimensions. We prove that these witnesses are nontrivial precisely when the underlying functional is non-affine on extremal points (e.g., pure states for ensembles). For pure bipartite states, the witnesses yield lower bounds on entanglement measures, thereby outperforming most linear steering inequalities in the pure-state regime. Moreover, the construction extends in full generality to certify measurement and instrument incompatibility, where the witnesses act as genuine incompatibility monotones. We demonstrate the versatility of our approach with two operationally relevant functionals: the Wigner-Yanase skew information and an $\ell_{2}$-type coherence functional.

</details>


### [96] [Topological Obstructions for Quantum Adiabatic Algorithms: Evidence from MaxCut Instances](https://arxiv.org/abs/2601.02255)
*Prathamesh S. Joshi*

Main category: quant-ph

TL;DR: 量子绝热算法在具有简并解流形的优化问题中，简并性会强制产生谱带相互作用、编织和置换，形成无法通过增加演化时间消除的拓扑障碍。


<details>
  <summary>Details</summary>
Motivation: 传统基于局部能隙的分析方法无法完全描述具有简并解流形的优化问题中的谱演化全局结构，需要揭示简并性如何对谱流施加全局约束。

Method: 通过数字化量子绝热演化，分析沿插值路径生成的累积酉算子的本征相位，显式跟踪本征相位轨迹，研究谱带相互作用、编织和置换现象。

Result: 在受控简并的MaxCut实例中，观察到持续的谱拥塞和非平凡的谱带置换，这些现象无法通过增加演化时间或细化数字化来消除，表明成功的绝热优化可以与复杂的谱流共存。

Conclusion: 简并性在绝热算法中引入了基于本征态全局连通性的拓扑障碍，而非局部能隙闭合，这突显了基于能隙分析的局限性，并推动了基于谱流的诊断方法的发展。

Abstract: Quantum adiabatic algorithms are commonly analyzed through local spectral properties of an interpolating Hamiltonian, most notably the minimum energy gap. While this perspective captures an important constraint on adiabatic runtimes, it does not fully describe the global structure of spectral evolution in optimization problems with degenerate solution manifolds. In this work, we show that degeneracy alone imposes unavoidable global constraints on spectral flow, even in instances where adiabatic algorithms succeed with high probability. Focusing on digitized quantum adiabatic evolutions, we analyze the eigenphases of the cumulative unitary operator generated along the interpolation path. By explicitly tracking eigenphase trajectories, we demonstrate that multiple spectral bands are forced to interact, braid, and permute before coalescing into a degenerate manifold at the end of the evolution. This global reordering manifests as persistent spectral congestion and nontrivial band permutations that cannot be removed by increasing evolution time or refining the digitization. Using MaxCut instances with controlled degeneracy as a concrete setting, we extract quantitative diagnostics of spectral congestion and explicitly compute the induced band permutations. Our results show that successful adiabatic optimization can coexist with complex and constrained spectral flow, revealing a form of topological obstruction rooted in the global connectivity of eigenstates rather than in local gap closures. These findings highlight intrinsic limitations of gap-based analyses and motivate spectral-flow-based diagnostics for understanding adiabatic algorithms in degenerate optimization landscapes.

</details>


### [97] [Schwarz maps with symmetry](https://arxiv.org/abs/2601.02282)
*Alfonso García-Velo,Alberto Ibort*

Main category: quant-ph

TL;DR: 该论文将量子力学对称性理论应用于量子信息论中的CPTP、PPT和Schwarz映射研究，系统分类了不同对称性下的映射结构，揭示了群对称性如何控制非完全正映射的性质。


<details>
  <summary>Details</summary>
Motivation: 研究量子信息论中重要映射类（CPTP、PPT、Schwarz映射）的结构与性质，探索群对称性如何约束和决定这些映射的特性，特别是非完全正映射的行为。

Method: 应用量子力学对称性理论，首先发展C*-代数间等变映射的一般结构，然后系统研究在自然酉群作用下保持单位性和厄米性的等变映射。对U(n)-等变映射进行完全分类，并对DU(n)-等变和张量积对称性进行部分分类。

Result: 完全分类了M_n(C)上的U(n)-等变映射，确定了完全正和Schwarz映射的参数区域；获得了DU(n)-等变和张量积对称性的部分分类；发现U(n)-等变族满足PPT⇔EB，而DU(2)、对称DU(3)、U(2)⊗U(2)和U(2)⊗U(3)族通过对称性论证满足PPT²猜想。

Conclusion: 群对称性显著控制着非完全正映射的结构，为PPT²猜想提供了新的具体实例，揭示了对称性在量子信息映射分类中的核心作用。

Abstract: The theory of symmetry of quantum mechanical systems is applied to study the structure and properties of several classes of relevant maps in quantum information theory: CPTP, PPT and Schwarz maps. First, we develop the general structure that equivariant maps $Φ:\mathcal A \to \mathcal B$ between $C^\ast$-algebras satisfy. Then, we undertake a systematic study of unital, Hermiticity-preserving maps that are equivariant under natural unitary group actions. Schwarz maps satisfy Kadison's inequality $Φ(X^\ast X) \geq Φ(X)^\ast Φ(X)$ and form an intermediate class between positive and completely positive maps. We completely classify $U(n)$-equivariant on $M_n(\mathbb C)$ and determine those that are completely positive and Schwarz. Partial classifications are then obtained for the weaker $DU(n)$-equivariance (diagonal unitary symmetry) and for tensor-product symmetries $U(n_1) \otimes U(n_2)$. In each case, the parameter regions where $Φ$ is Schwarz or completely positive are described by explicit algebraic inequalities, and their geometry is illustrated. Finally, we further show that the $U(n)$-equivariant family satisfies $\mathrm{PPT} \iff \mathrm{EB}$, while the $DU(2)$, symmetric $DU(3)$, $U(2) \otimes U(2)$ and $U(2) \otimes U(3)$, families obey the $\mathrm{PPT}^2$ conjecture through a direct symmetry argument. These results reveal how group symmetry controls the structure of non-completely positive maps and provide new concrete examples where the $\mathrm{PPT}^2$ property holds.

</details>


### [98] [Binarisation-loophole-free observation of high-dimensional quantum nonlocality](https://arxiv.org/abs/2601.02350)
*Jia-le Miao,Elna Svegborn,Zhuo Chen,Yu Guo,Xiao-Min Hu,Yun-Feng Huang,Chuan-Feng Li,Guang-Can Guo,Armin Tavakoli,Bi-Heng Liu*

Main category: quant-ph

TL;DR: 该研究通过使用四维光子路径模式纠缠和多结果检测，关闭了高维贝尔不等式测试中的二值化漏洞，并展示了真正的高维非局域性。


<details>
  <summary>Details</summary>
Motivation: 高维纠缠的贝尔不等式测试通常需要能够分辨多个可能结果的多结果测量。然而，实际实现中多结果测量往往被简化为"点击或无点击"的二元测量，这在高维贝尔测试中引入了一个可被局部隐变量模型利用的漏洞。

Method: 使用四维光子路径模式纠缠和多结果检测技术，测试了Collins-Gisin-Linden-Massar-Popescu不等式以及为高维最大纠缠态定制的相关贝尔不等式。

Result: 观察到了足够大的违反值，不仅证实了量子非局域性，还排除了任何基于低维纠缠的量子模型，从而证明了无二值化漏洞的真正高维非局域性。

Conclusion: 该研究成功关闭了高维贝尔测试中的二值化漏洞，通过多结果测量技术实现了真正的高维非局域性验证，为高维量子信息处理提供了更可靠的基础。

Abstract: Bell inequality tests based on high-dimensional entanglement usually require measurements that can resolve multiple possible outcomes. However, the implementation of high-dimensional multi-outcome measurements is often only emulated via a collection of ``click or no-click'' measurements. This reduction of multi-outcome measurements to binary-outcome measurements opens a loophole in high-dimensional tests Bell inequalities which can be exploited by local hidden variable models [Tavakoli et al., Phys. Rev. A 111, 042433 (2025)]. Here, we close this loophole by using four-dimensional photonic path-mode entanglement and multi-outcome detection. We test both the well-known Collins-Gisin-Linden-Massar-Popescu inequality and a related Bell inequality tailored for maximally entangled states in high-dimension. We observe violations that are large enough to also rule out any quantum model based on entanglement of lower dimension, thereby demonstrating genuinely high-dimensional nonlocality free of the binarisation loophole.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [99] [New RVE concept and FFT methods in micromechanics of composites subjected to body force with compact support](https://arxiv.org/abs/2601.00822)
*Valeriy A. Buryachenko*

Main category: physics.comp-ph

TL;DR: 提出基于紧凑支撑体力的新RVE概念，通过FFT求解器生成数据集训练ML/NN模型，学习有效的非局部代理算子，用于复杂材料均质化


<details>
  <summary>Details</summary>
Motivation: 传统均质化方法在处理周期性复合材料时存在边界效应和有限样本尺寸影响的问题，需要一种能准确捕捉微观结构特征和非局部相互作用的物理基础数据驱动框架

Method: 设计紧凑支撑体力场生成新数据集，提出功能缩减RVE概念消除边界伪影，开发基于FFT的求解器进行直接数值模拟，使用ML/NN模型学习非局部代理算子

Result: 该方法能准确预测宏观响应，同时反映微观结构特征和非局部相互作用，消除了有限样本尺寸和边界效应的影响

Conclusion: 为复杂材料均质化提供了物理基础和数据驱动的准确代理模型构建框架，结合了场局部化考虑与边界效应消除的优势

Abstract: We consider static linear elastic composite materials (CMs) with periodic structure. The core of the proposed methodology is the generation of a novel dataset using specially designed body force fields with compact support (BFCS), enabling a new RVE concept that reduces the infinite periodic medium to a finite domain without boundary artifacts. This functionally reduced RVE is used for translated averaging of direct numerical simulations (DNS) results, efficiently computed via a newly developed FFT-based solver for BFCS loading. The resulting dataset captures localized field responses and is used to train machine learning (ML) and neural networks (NN) models to learn effective nonlocal surrogate operators. These operators accurately predict macroscopic responses while reflecting microstructural features and nonlocal interactions. By accounting for field localization while simultaneously eliminating influences from finite sample size and boundary effects, it provides a physically grounded and data-driven framework for constructing accurate surrogate models for the homogenization of complex materials.

</details>


### [100] [AutoPot: Automated and massively parallelized construction of Machine-Learning Potentials](https://arxiv.org/abs/2601.01185)
*Max Hodapp,Guillaume Anciaux*

Main category: physics.comp-ph

TL;DR: AutoPot是一个自动化构建和归档机器学习势能（MLIPs）的软件，基于BlackDynamite和Motoko框架，支持从大型候选训练集中选择配置，并在分子动力学模拟中进行在线选择。


<details>
  <summary>Details</summary>
Motivation: 机器学习势能（MLIPs）需要训练集与模拟中遇到的邻域非常接近才能达到接近量子精度。然而，构建一个适用于所有应用的单一训练集是不可行的，现有补充学习方法（如主动学习、微调）导致训练协议复杂、难以高效实现、解释、分析和复现。

Method: 基于BlackDynamite（用于高度并行化运行参数化任务）和Motoko（基于事件的工作流管理器）开发AutoPot软件。支持从大型训练候选集中选择训练配置，在分子动力学模拟中进行在线选择，使用MLIP-2中的Moment Tensor Potentials，并使用VASP对选定配置进行单点计算。

Result: 开发出AutoPot软件，能够自动化构建和归档MLIPs。该软件具有高度灵活性，BlackDynamite任务和协调器是Python函数，可以轻松添加和操作现有代码，无需编写复杂解析器。

Conclusion: AutoPot解决了MLIPs训练协议复杂性的问题，提供了一个灵活、可扩展的自动化框架，便于添加其他MLIP和从头算代码，并实现其他训练协议。

Abstract: Machine-learning potentials (MLIPs) have been a breakthrough for computational physics in bringing the accuracy of quantum mechanics to atomistic modeling. To achieve near-quantum accuracy, it is necessary that neighborhoods contained in the training set are rather close to the ones encountered during a simulation. Yet, constructing a single training set that works well for all applications is, and likely will remain, infeasible, so, one strategy is to supplement training protocols for MLIPs with additional learning methods, such as active learning, or fine-tuning. This strategy, however, yields very complex training protocols that are difficult to implement efficiently, and cumbersome to interpret, analyze, and reproduce.
  To address the above difficulties, we propose AutoPot, a software for automating the construction and archiving of MLIPs. AutoPot is based on BlackDynamite, a software operating parametric tasks, e.g., running simulations, or single-point ab initio calculations, in a highly-parallelized fashion, and Motoko, an event-based workflow manager for orchestrating interactions between the tasks. The initial version of AutoPot supports selection of training configurations from large training candidate sets, and on-the-fly selection from molecular dynamics simulations, using Moment Tensor Potentials as implemented in MLIP-2, and single-point calculations of the selected training configurations using VASP. Another strength of AutoPot is its flexibility: BlackDynamite tasks and orchestrators are Python functions to which own existing code can be easily added and manipulated without writing complex parsers. Therefore, it will be straightforward to add other MLIP and ab initio codes, and manipulate the Motoko orchestrators to implement other training protocols.

</details>


### [101] [From Fermat's Principle to Physics-Informed Neural Networks: A Unified Computational Approach to Variational Physics](https://arxiv.org/abs/2601.01262)
*Aman Razdan,Aditya Shankar Mazumdar,Amit Tanwar,Pragati Ashdhir*

Main category: physics.comp-ph

TL;DR: 论文提出了一种结合现代计算工具（梯度下降、自动微分、PINNs）的教学方法，将经典变分问题重新表述为优化任务，通过Python实现，涵盖从光学到量子物理的多个物理问题。


<details>
  <summary>Details</summary>
Motivation: 变分原理是物理学多个领域的统一数学框架，但在本科教学中主要停留在解析层面。作者希望将现代计算工具融入变分建模教学，增强概念理解的同时引入现代计算研究方法。

Method: 将经典变分问题重新表述为优化任务，使用Python库（NumPy、Matplotlib、PyTorch、JAX）实现，结合梯度下降、自动微分和物理信息神经网络（PINNs）等现代计算工具。

Result: 演示了从本科课程中选取的一系列问题：从费马原理推导斯涅尔定律、有/无粘性阻力的抛体运动、简谐运动、非线性阻尼摆、稳态热传导、双摆、振动弦，以及氢原子、氦原子和硅核的量子力学变分解。

Conclusion: 该方法展示了变分原理在经典、量子、核物理中的广泛适用性，旨在增强学生的概念理解，同时引入现代计算研究方法，为物理教育提供了计算增强的教学框架。

Abstract: Variational principles are a unifying mathematical framework across many areas of physics, yet their instruction at the undergraduate level remains primarily analytical. This work presents a pedagogically oriented and computationally enhanced approach to variational modeling that integrates contemporary tools including gradient descent, automatic differentiation, and Physics-Informed Neural Networks (PINNs). Classical variational problems are reformulated as optimization tasks and implemented using open-source Python libraries such as NumPy, Matplotlib, PyTorch, and JAX. The proposed approach is demonstrated through a progression of problems drawn from standard undergraduate curricula, including the derivation of Snell's law from Fermat's principle, projectile motion with and without viscous drag, simple harmonic motion, nonlinear pendulum with damping, steady-state heat conduction governed by the Laplace and Poisson equations with nonlinear temperature-dependent internal heat generation, the double pendulum via the principle of least action, and variational treatments of vibrating strings. In addition, quantum mechanical applications are presented through variational solutions of the hydrogen atom, helium atom, and a schematic nuclear model of the silicon nucleus, illustrating the breadth of the framework across classical, quantum, and nuclear physics. The approach aims to enhance conceptual understanding while simultaneously introducing students to modern computational research methodologies.

</details>


### [102] [Learning Stiff Dynamical Operators: Scaling, Fast-Slow Excitation, and Eigen-Consistent Neural Models](https://arxiv.org/abs/2601.01632)
*Mauro Valorani*

Main category: physics.comp-ph

TL;DR: 提出三种关键技术解决神经网络算子学习中的刚性问题：刚度感知时间导数缩放、局部轨迹云爆发激发快方向、自动梯度雅可比诊断确保特征结构保真度，显著提升刚性问题学习效果。


<details>
  <summary>Details</summary>
Motivation: 刚性问题在多尺度建模中普遍存在，但传统神经网络算子学习方法面临严重挑战：训练误差集中在慢流形状态、快动态崩溃、学习算子无法重现真实特征结构。

Method: 提出三种关键技术：1) 刚度感知时间导数缩放；2) 通过局部轨迹云爆发激发快方向；3) 基于自动梯度的雅可比诊断确保特征结构保真度。

Result: 在Davis-Skodje系统上，该方法能够恢复刚性问题中的慢模式和快模式，将快特征值误差降低一个数量级，同时提高轨迹推演保真度。

Conclusion: 特征结构保真度（而不仅仅是轨迹精度）应成为数据驱动刚性问题算子学习的首要目标，该方法为刚性问题学习提供了有效解决方案。

Abstract: Stiff dynamical systems represent a central challenge in multi scale modeling across combustion, chemical kinetics, and nonlinear dynamical systems. Neural operator learning has recently emerged as a promising approach to approximate dynamical generators from data, yet stiffness imposes severe obstacles: training errors concentrate on slow manifold states, collapse of fast dynamics occurs, and the learned operator may fail to reproduce the true eigenstructure.
  We demonstrate three key advances enabling accurate learning of stiff operators and preserving spectral fidelity: (i) stiffness aware scaling of time derivatives, (ii) fast direction excitation via local trajectory cloud bursts, and (iii) autograd-based Jacobian diagnostics ensuring eigenstructure fidelity. Applied to the Davis-Skodje system, the approach recovers both slow and fast modes across stiffness regimes, reducing fast eigenvalue error by an order of magnitude while improving rollout fidelity. These results argue that spectral fidelity - not trajectory accuracy alone - should be a first-class target in data driven learning of stiff operators.

</details>


### [103] [Ab initio quantum embedding at finite temperature with density matrix embedding theory](https://arxiv.org/abs/2601.01641)
*Laurence Giordano,Y. Stanley Tan,Zhi-Hao Cui,Chong Sun*

Main category: physics.comp-ph

TL;DR: 提出了有限温度密度矩阵嵌入理论（FT-DMET）的扩展，用于研究真实晶体系统，包含实用的框架构建、计算成本降低策略，并应用于氢链和方晶格研究其有限温度相行为。


<details>
  <summary>Details</summary>
Motivation: 将密度矩阵嵌入理论（DMET）扩展到有限温度，以研究真实晶体系统的热力学性质，特别是需要处理有限温度下的电子相关效应和相变行为。

Method: 开发了FT-DMET框架，包括扩展浴轨道的构建、嵌入问题的求解、DMET自洽过程。为降低计算成本，采用了互信息引导的浴轨道截断、无需显式优化的热电子数控制、低温杂质求解器和低温区的一步FT-DMET等策略。

Result: 将方法应用于周期性氢链和方晶格，观察到一维中的Pomeranchuk-like效应和二维中长程有序的增强稳定性，成功表征了这些系统的有限温度相行为。

Conclusion: FT-DMET为研究真实晶体系统的有限温度性质提供了实用框架，通过计算优化策略实现了高效计算，能够揭示低维系统中的有趣热力学现象。

Abstract: We present a finite-temperature extension of density matrix embedding theory (FT-DMET) for realistic crystalline systems. We describe a practical framework for constructing extended bath orbitals, solving the embedding problem, and performing DMET self-consistency at finite temperature. To reduce computational cost, we introduce strategies based on mutual-information-guided bath truncation, controlled treatment of the thermal electron number without explicit optimization, and the use of low-temperature impurity solvers and one-shot FT-DMET in the low-temperature regime. We apply this approach to periodic hydrogen chains and square lattices to characterize their finite-temperature phases. We observe the Pomeranchuk-like effect in one dimension and enhanced stability of long-range order in two dimensions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [104] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

TL;DR: 论文证明离线RL中的视野缩减会导致不可恢复的信息损失，即使有无限数据和完美函数逼近，最优策略也可能与次优策略统计不可区分。


<details>
  <summary>Details</summary>
Motivation: 尽管经验证据表明视野缩减可以改善离线RL的扩展性，但其理论影响尚未充分发展。本文旨在揭示视野缩减可能导致的根本性信息损失问题。

Method: 将视野缩减形式化为从固定长度轨迹片段中学习，通过最小反例马尔可夫决策过程识别三种结构失效模式：前缀不可区分性、截断回报导致的目标错误指定、离线数据集支持和表示混叠。

Result: 证明在固定长度轨迹片段的学习范式下，即使有无限数据和完美函数逼近，最优策略也可能与次优策略统计不可区分。确定了视野缩减安全的必要条件。

Conclusion: 视野缩减在离线RL中会导致不可恢复的信息损失，存在算法改进无法克服的内在限制。这为视野缩减的安全应用提供了理论边界，补充了现有关于保守目标和分布偏移的研究。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [105] [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)
*Israk Hasan Jone,D. M. Rafiun Bin Masud,Promit Sarker,Sayed Fuad Al Labib,Nazmul Islam,Farhad Billah*

Main category: cs.LG

TL;DR: 该研究提出基于深度学习的虾病自动分类方法，使用1,149张图像，评估六种预训练模型，采用背景去除、对抗训练、数据增强等技术，ConvNeXt-Tiny模型在测试集上达到96.88%准确率。


<details>
  <summary>Details</summary>
Motivation: 虾养殖是全球重要的水产养殖产业，但疾病爆发严重威胁其可持续发展。传统方法难以实现及时准确的疾病检测，需要自动化分类方法来提高诊断效率和准确性。

Method: 使用1,149张虾病图像构建四类疾病数据集；采用六种预训练深度学习模型（ResNet50、EfficientNet、DenseNet201、MobileNet、ConvNeXt-Tiny、Xception）；进行背景去除和标准化预处理；使用FGSM对抗训练增强模型鲁棒性；应用CutMix和MixUp数据增强防止过拟合；采用Grad-CAM、Grad-CAM++、XGrad-CAM等后解释方法可视化模型关注区域。

Result: ConvNeXt-Tiny模型表现最佳，在测试集上达到96.88%准确率；经过1000次迭代后，模型99%置信区间为[0.953,0.971]；对抗训练和数据增强有效提高了模型泛化能力；解释方法成功可视化模型决策依据。

Conclusion: 深度学习方法能够有效实现虾病的自动分类，ConvNeXt-Tiny模型在该任务中表现最优，为虾养殖业的疾病监测提供了可行的自动化解决方案，有助于提高虾养殖的可持续性和经济效益。

Abstract: Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and accurate detection. This research proposes a deep learning-based approach for the automated classification of shrimp diseases. A dataset comprising 1,149 images across four disease classes was utilized. Six pretrained deep learning models, ResNet50, EfficientNet, DenseNet201, MobileNet, ConvNeXt-Tiny, and Xception were deployed and evaluated for performance. The images background was removed, followed by standardized preprocessing through the Keras image pipeline. Fast Gradient Sign Method (FGSM) was used for enhancing the model robustness through adversarial training. While advanced augmentation strategies, including CutMix and MixUp, were implemented to mitigate overfitting and improve generalization. To support interpretability, and to visualize regions of model attention, post-hoc explanation methods such as Grad-CAM, Grad-CAM++, and XGrad-CAM were applied. Exploratory results demonstrated that ConvNeXt-Tiny achieved the highest performance, attaining a 96.88% accuracy on the test dataset. After 1000 iterations, the 99% confidence interval for the model is [0.953,0.971].

</details>


### [106] [Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds](https://arxiv.org/abs/2601.00834)
*Julian Evan Chrisnanto,Salsabila Rahma Alia,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: IM-PINN：一种无网格几何深度学习框架，通过在连续参数域中嵌入黎曼度量张量，直接求解复杂非欧几里得流形上的非线性反应扩散方程，解决了传统方法的高保真网格生成成本和辛漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂非欧几里得流形上模拟非线性反应扩散动力学是计算形态发生学的基本挑战，受限于高保真网格生成成本和离散时间步进方案中的辛漂移问题。

Method: 提出内在度量物理信息神经网络（IM-PINN），将黎曼度量张量嵌入自动微分图中，解析重建拉普拉斯-贝尔特拉米算子，使解复杂度与几何离散化解耦。采用双流架构和傅里叶特征嵌入来缓解谱偏差。

Result: 在具有极端高斯曲率波动的"随机布料"流形上验证，IM-PINN恢复了Gray-Scott模型的"分裂斑点"和"迷宫"机制。相比表面有限元法，IM-PINN实现全局质量守恒误差0.157（SFEM为0.258），作为热力学一致的全局求解器消除了半隐式积分固有的质量漂移。

Conclusion: IM-PINN为在演化表面上模拟生物模式形成提供了内存高效、分辨率无关的范式，桥接了微分几何和物理信息机器学习。

Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a "Stochastic Cloth" manifold with extreme Gaussian curvature fluctuations ($K \in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the "splitting spot" and "labyrinthine" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\mathcal{E}_{mass} \approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.

</details>


### [107] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

TL;DR: 该论文研究了RAG系统中的查询级控制问题，通过离线数据集学习策略来平衡成本、拒绝率和幻觉风险等SLO指标，发现固定基线策略表现良好，学习策略主要在质量导向SLO下能节省成本。


<details>
  <summary>Details</summary>
Motivation: RAG系统面临实际控制问题：需要为每个查询选择检索深度和生成模式（防护模式vs自动模式）以满足服务级别目标（SLOs），如成本、拒绝率和幻觉风险。

Method: 将查询级控制建模为离散动作选择：选择检索深度和生成模式，或拒绝查询。基于SQuAD 2.0构建离线日志数据集，记录每个动作的准确性、token成本、幻觉/拒绝指标和SLO加权奖励。评估两种简单的策略学习目标：基于状态的最佳动作监督分类（Argmax-CE）和奖励加权变体（Argmax-CE-WT）。

Result: 在评估的设置中，固定基线策略（低k值、防护提示）表现具有竞争力；学习策略主要在质量导向SLO下能提供额外的成本节省，在廉价SLO下当拒绝被高度奖励时可能出现拒绝崩溃现象。

Conclusion: 本文提供了一个可复现的RAG管道SLO感知控制案例研究，强调失败模式和报告规范，而非提出新的检索器或语言模型，为RAG系统控制提供了实用见解。

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [108] [LLMize: A Framework for Large Language Model-Based Numerical Optimization](https://arxiv.org/abs/2601.00874)
*M. Rizki Oktavian*

Main category: cs.LG

TL;DR: LLMize是一个开源Python框架，利用大语言模型进行优化，通过自然语言描述问题、迭代生成和评估候选解，支持多种优化策略，特别适用于复杂领域特定问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型展现出超越传统语言任务的推理能力，这启发了将其用于数值优化的想法。传统优化方法需要数学编程或元启发式设计专业知识，而LLMize旨在让从业者能够通过自然语言描述复杂优化问题，无需专业优化知识。

Method: LLMize将优化建模为黑盒过程：通过自然语言生成候选解，由外部目标函数评估，利用解-分数反馈进行迭代优化。框架支持多种策略，包括优化提示（OPRO）以及受进化算法和模拟退火启发的混合LLM方法。关键优势是通过自然语言描述直接注入约束、规则和领域知识。

Result: 在凸优化、线性规划、旅行商问题、神经网络超参数调优和核燃料晶格优化等任务上评估。结果显示，对于简单问题，LLM优化不如经典求解器有竞争力，但对于复杂、领域特定的任务，特别是当约束和启发式难以形式化时，LLMize提供了实用且易用的方法。

Conclusion: LLMize为复杂优化问题提供了实用且易用的框架，特别适用于领域特定任务，其中约束和启发式难以形式化。虽然对于简单问题不如经典方法，但通过自然语言描述问题的能力使其在特定应用场景中具有价值。

Abstract: Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.

</details>


### [109] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

TL;DR: 提出一种增强JEPA世界模型规划能力的方法，通过塑造表示空间使负目标条件值函数近似于状态嵌入间的距离，从而显著提升简单控制任务中的规划性能。


<details>
  <summary>Details</summary>
Motivation: JEPA框架能通过自监督预测目标学习环境动态表示，但其支持有效行动规划的能力有限。需要增强JEPA世界模型的规划能力。

Method: 通过塑造JEPA的表示空间，使负目标条件值函数（针对特定环境中的到达成本）近似于状态嵌入间的距离（或准距离）。提出在训练期间强制执行此约束的实用方法。

Result: 相比标准JEPA模型，在简单控制任务上实现了显著改进的规划性能。

Conclusion: 通过塑造表示空间使值函数近似于嵌入距离，能有效增强JEPA世界模型的规划能力，为构建能推理环境动态的深度学习模型提供有前景的方向。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [110] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

TL;DR: MFEE框架将推理重构为控制平面决策问题，通过语义分析选择性执行transformer，在保持100%正确性的同时减少78.1%的计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前AI推理系统将transformer执行视为强制性的，混淆了模型能力与执行必要性。需要将推理重构为控制平面决策问题，确定何时必须执行transformer，何时可以通过替代路径保持正确性。

Method: 提出Meaning-First Execution (MFEE)控制平面架构，作为现有堆栈之上的门控层，不修改模型、权重或参数。通过语义分析选择性调用transformer推理，仅在实际需要时执行。

Result: 在1000个多样化提示的确定性解码下，MFEE实现78.1%的执行减少，同时保持100%的精确匹配等价性。相比基于模式的路由器最多只能达到53.3%的避免率且存在正确性失败，MFEE通过语义分析实现100%避免且零失败。

Conclusion: 证明了基于有限特征映射的路由器无法同时保证零错误跳过和正避免率，确立了执行治理作为ML系统基础设施的基础层，与模型级优化技术正交。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [111] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

TL;DR: EdgeJury是一个轻量级集成框架，使用小型指令调优语言模型(3B-8B)通过四阶段协作流程来减少幻觉，在TruthfulQA上实现76.2%准确率，比单模型基线提升21.4%，在边缘部署中保持低延迟。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘部署场景中，使用前沿大模型或检索管道可能不切实际，而幻觉问题会严重影响问答系统的可靠性。需要一种轻量级方法，仅使用小型模型就能提高真实性和鲁棒性。

Method: EdgeJury采用四阶段框架：1)并行角色专业化生成；2)匿名交叉评审，包含结构化批评和排名；3)主席合成，整合最强内容并解决标记问题；4)基于模型间一致性的声明级一致性标记。

Result: 在TruthfulQA(MC1)上达到76.2%准确率，比单8B模型基线(62.8%)提升21.4%；在200个对抗性EdgeCases问题上获得48.2%相对增益；人工分析显示事实性幻觉错误减少约55%；在Cloudflare Workers AI上部署时中位端到端延迟为8.4秒。

Conclusion: 协调的小型模型集成可以在不依赖外部检索或专有大模型API的情况下，显著提高问答系统的真实性，特别适用于误解密集的基准测试，同时保持边缘部署的可行性。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [112] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: FedSCAM是一种联邦学习算法，通过基于客户端异质性动态调整SAM扰动半径和聚合权重，解决非IID数据分布下的收敛和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的统计异质性（特别是非IID标签分布）对收敛和泛化构成挑战。现有的SAM方法在FL中通常对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性。

Method: 提出FedSCAM算法：1）为每个客户端计算异质性度量；2）根据异质性分数反向调制SAM扰动半径，防止高方差客户端破坏全局模型稳定性；3）引入异质性感知的加权聚合机制，优先考虑与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上，基于不同程度的狄利克雷标签偏斜进行实验，FedSCAM在收敛速度和最终测试准确率方面达到了与FedSAM、FedLESAM等最先进基线方法竞争的性能。

Conclusion: FedSCAM通过动态调整扰动半径和异质性感知聚合，有效解决了联邦学习中非IID数据带来的挑战，提高了模型的收敛性和泛化能力。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [113] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

TL;DR: 评估AlphaEarth Foundation (AEF)地理空间基础模型在农业监测任务中的表现，包括产量预测、耕作制图和覆盖作物制图，并与传统遥感模型对比。


<details>
  <summary>Details</summary>
Motivation: 尽管AEF等地理空间基础模型在土地覆盖分类任务中表现优异，但在农业监测关键下游任务中缺乏深入评估，且缺少与传统遥感模型的全面比较。

Method: 使用AEF嵌入在美国进行三个农业下游任务评估：作物产量预测、耕作制图和覆盖作物制图；编译公共和私有数据集在不同尺度和位置进行评估；训练传统遥感模型作为对比基准。

Result: AEF模型在所有任务中表现良好，在产量预测和县级耕作制图任务中与专门构建的遥感模型竞争力相当。但也发现AEF嵌入存在空间可迁移性有限、可解释性低和时间敏感性不足等局限性。

Conclusion: AEF嵌入在农业应用中需谨慎使用，特别是在时间敏感性、泛化能力和可解释性要求高的场景中。研究为研究人员和从业者提供了有价值的指导。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [114] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

TL;DR: 该论文证明纯机械系统通过耗散量子动力学和非局部上下文聚合可以生成智能语言，而守恒定律会导致根本性失败。语言生成本质上是耗散量子场论。


<details>
  <summary>Details</summary>
Motivation: 探究纯机械系统是否能够生成智能语言，研究量子动力学中耗散与守恒对语言生成能力的影响，建立语言生成与量子场论的理论联系。

Method: 使用Koopman算子和闭式路径积分传播子分析耗散量子动力学，通过谱分析揭示特征值结构（衰减模式、增长模式、中性模式），研究非局部上下文聚合机制。

Result: 证明耗散量子动力学能够产生连贯的文本生成，而哈密顿约束会消除耗散模式并导致性能下降。建立了语言生成作为耗散量子场论的理论框架。

Conclusion: 机械系统通过耗散和非局域性的组合获得智能，而不是通过守恒。语言生成本质上是耗散量子场论，需要受控信息耗散和因果上下文聚合。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [115] [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)
*Joey Chan,Huan Wang,Haoyu Pan,Wei Wu,Zirong Wang,Zhen Chen,Ershun Pan,Min Xie,Lifeng Xi*

Main category: cs.LG

TL;DR: 提出基于时间序列基础模型(TSFM)的统一电池容量衰减预测框架，通过LoRA参数高效微调和物理引导对比学习，在包含1704个电池的大规模数据集上实现跨化学体系、容量尺度和工况的稳定预测性能。


<details>
  <summary>Details</summary>
Motivation: 电池容量衰减预测对储能系统的安全、可靠和长期效率至关重要，但不同化学体系、外形尺寸和运行条件的高度异质性使得单一模型难以泛化到训练域之外。

Method: 1) 构建大规模电池老化数据集：整合20个公开数据集，涵盖1704个电池和3,961,195个充放电循环段；2) 采用时间序列基础模型(TSFM)作为主干；3) 结合参数高效的LoRA微调；4) 引入物理引导的对比表示学习来捕捉共享的衰减模式。

Result: 单一统一模型在已见和刻意保留的未见数据集上均表现出色，相比强力的按数据集基线模型，达到竞争性或更优的准确度，同时在训练中未包含的化学体系、容量尺度和运行条件下保持稳定性能。

Conclusion: 基于TSFM的架构展示了作为电池管理系统容量衰减预测的可扩展和可迁移解决方案的潜力，能够应对实际应用中电池的强异质性挑战。

Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and usage scenarios. We curate 20 public aging datasets into a large-scale corpus covering 1,704 cells and 3,961,195 charge-discharge cycle segments, spanning temperatures from $-5\,^{\circ}\mathrm{C}$ to $45\,^{\circ}\mathrm{C}$, multiple C-rates, and application-oriented profiles such as fast charging and partial cycling. On this corpus, we adopt a Time-Series Foundation Model (TSFM) backbone and apply parameter-efficient Low-Rank Adaptation (LoRA) together with physics-guided contrastive representation learning to capture shared degradation patterns. Experiments on both seen and deliberately held-out unseen datasets show that a single unified model achieves competitive or superior accuracy compared with strong per-dataset baselines, while retaining stable performance on chemistries, capacity scales, and operating conditions excluded from training. These results demonstrate the potential of TSFM-based architectures as a scalable and transferable solution for capacity degradation forecasting in real battery management systems.

</details>


### [116] [Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery](https://arxiv.org/abs/2601.00863)
*Markus J. Buehler*

Main category: cs.LG

TL;DR: 该论文提出"物质音乐"生成框架，将物质层次结构与音乐创作逻辑相连接，通过可逆映射将分子光谱、三维网络等物理结构转化为音乐元素，揭示科学与艺术在约束条件下的生成共性。


<details>
  <summary>Details</summary>
Motivation: 探索物质结构与音乐创作之间的深层联系，将声音作为科学探测工具，通过听觉理解物质世界，建立科学与艺术的统一生成框架。

Method: 使用可逆映射方法：1) 分子光谱映射到音调；2) 三维网络映射到可演奏乐器；3) 枚举所有2^12音乐音阶进行定量分析；4) 采用基于群体的AI模型进行音乐创作。

Result: 1) 发现文化重要的音乐系统聚集在中熵、中缺陷区域，与材料科学中的Hall-Petch最优缺陷密度直接对应；2) AI创作的音乐表现出类人结构特征，如小世界连接性、模块化整合、长程相干性；3) 建立了从飞秒分子振动到亿年进化历史的可听化模式。

Conclusion: 科学与艺术都是在约束条件下的世界构建生成行为，振动作为跨尺度的共享语法组织结构。选择性不完美提供了恢复连贯性与适应性平衡的机制，这种映射创造了人类创造力与物理学的生产性碰撞。

Abstract: We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical form. Using reversible mappings, from molecular spectra to musical tones and from three-dimensional networks to playable instruments, we show how sound functions as a scientific probe, an epistemic inversion where listening becomes a mode of seeing and musical composition becomes a blueprint for matter. These mappings excavate deep time: patterns originating in femtosecond molecular vibrations or billion-year evolutionary histories become audible. We posit that novelty in science and art emerges when constraints cannot be satisfied within existing degrees of freedom, forcing expansion of the space of viable configurations. Selective imperfection provides the mechanism restoring balance between coherence and adaptability. Quantitative support comes from exhaustive enumeration of all 2^12 musical scales, revealing that culturally significant systems cluster in a mid-entropy, mid-defect corridor, directly paralleling the Hall-Petch optimum where intermediate defect densities maximize material strength. Iterating these mappings creates productive collisions between human creativity and physics, generating new information as musical structures encounter evolutionary constraints. We show how swarm-based AI models compose music exhibiting human-like structural signatures such as small-world connectivity, modular integration, long-range coherence, suggesting a route beyond interpolation toward invention. We show that science and art are generative acts of world-building under constraint, with vibration as a shared grammar organizing structure across scales.

</details>


### [117] [Distribution Matching for Graph Quantification Under Structural Covariate Shift](https://arxiv.org/abs/2601.00864)
*Clemens Damke,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 将KDEy量化学习方法扩展到图数据，通过结构重要性采样处理训练和测试数据之间的结构偏移，提升标签分布估计性能。


<details>
  <summary>Details</summary>
Motivation: 在社交网络等图数据中，我们通常更关注标签的整体分布（如政治倾向的普遍性）而非单个实例的标签。现有量化学习方法基于先验概率偏移假设，但在图数据中，当训练和测试数据来自图的不同区域时，这种假设不成立，导致结构偏移问题。

Method: 将结构重要性采样的思想扩展到最先进的KDEy量化学习方法。通过重要性采样技术来适应训练和测试数据之间的结构偏移，使模型能够处理图数据中不同区域之间的分布差异。

Result: 提出的方法能够有效适应结构偏移，在标签分布估计任务上优于标准的量化学习方法。

Conclusion: 通过将结构重要性采样与KDEy量化学习相结合，成功解决了图数据中的结构偏移问题，为图数据上的标签分布估计提供了更有效的解决方案。

Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.

</details>


### [118] [A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam](https://arxiv.org/abs/2601.00866)
*Shivani Saini,Ramesh Kumar Vats,Arup Kumar Sahoo*

Main category: cs.LG

TL;DR: 提出一种改进的辅助物理信息神经网络框架，结合平衡自适应优化器，用于结构振动分析，在数值稳定性和预测精度上相比基线提升至少40%。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络及其变体在求解微分方程控制的正反问题方面表现出色，但需要改进以准确捕捉结构振动现象，确保可靠的预测分析，这对于深入了解科学机器学习模型在振动问题中的鲁棒性至关重要。

Method: 提出改进的辅助物理信息神经网络框架，结合平衡自适应优化器，用于分析结构振动问题。通过数值模拟近似欧拉-伯努利梁方程在各种场景下的行为。

Result: 数值结果证实了模型在数值稳定性和预测精度方面的增强性能，相比基线模型至少提升40%。

Conclusion: 改进的A-PINN框架在结构振动分析中表现出优越性能，为科学机器学习模型在振动问题中的应用提供了更可靠的解决方案。

Abstract: Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.

</details>


### [119] [SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation](https://arxiv.org/abs/2601.00868)
*Aditya Sreevatsa K,Arun Kumar Raveendran,Jesrael K Mani,Prakash G Shigli,Rajkumar Rangadore,Narayana Darapaneni,Anwesh Reddy Paduri*

Main category: cs.LG

TL;DR: SmartFlow是一个多层框架，结合强化学习和智能体AI，用于解决城市共享单车系统的动态再平衡问题，通过分层架构实现高效调度和人工操作的无缝对接。


<details>
  <summary>Details</summary>
Motivation: 城市共享单车系统面临车辆分布不均的问题，导致空闲时间增加、可用性降低和运营成本上升。传统方法难以处理复杂的动态再平衡挑战，需要一种智能、可扩展且可解释的解决方案。

Method: 采用多层架构：战略层使用深度Q网络在纽约Citi Bike网络的高保真模拟中学习再平衡策略；战术层进行确定性优化，安排多段行程和及时调度；通信层通过基于大语言模型的智能体AI将计划转化为可执行指令。

Result: 评估显示SmartFlow能减少95%以上的网络不平衡，同时最小化行驶距离并实现高卡车利用率。系统显著减少空闲时间，提高单车可用性，降低运营成本。

Conclusion: SmartFlow为复杂城市移动网络提供了可解释、AI驱动的物流蓝图，成功将机器智能与人工操作相结合，实现了可扩展的智能调度解决方案。

Abstract: SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.

</details>


### [120] [Quantum Machine Learning Approaches for Coordinated Stealth Attack Detection in Distributed Generation Systems](https://arxiv.org/abs/2601.00873)
*Osasumwen Cedric Ogiesoba-Eguakun,Suman Rath*

Main category: cs.LG

TL;DR: 量子机器学习方法用于检测微电网分布式发电单元的协同隐蔽攻击，混合量子经典模型在低维数据集上表现最佳


<details>
  <summary>Details</summary>
Motivation: 协同隐蔽攻击是分布式发电系统的严重网络安全威胁，它们修改控制和测量信号但保持接近正常行为，使得传统入侵检测方法难以检测

Method: 使用三个特征创建平衡二元分类数据集：DG1的无功功率、相对于标称值的频率偏差和端电压幅值。评估了经典机器学习基线、完全量子变分分类器和混合量子经典模型

Result: 混合量子经典模型（量子特征嵌入与经典RBF支持向量机结合）在低维数据集上获得最佳整体性能，在准确率和F1分数上比经典SVM基线有适度提升。完全量子模型由于训练不稳定性和当前NISQ硬件限制表现较差

Conclusion: 混合模型训练更可靠，表明量子特征映射即使在完全量子学习尚不实用的情况下也能增强入侵检测能力，为量子机器学习在网络安全应用中的实际部署提供了路径

Abstract: Coordinated stealth attacks are a serious cybersecurity threat to distributed generation systems because they modify control and measurement signals while remaining close to normal behavior, making them difficult to detect using standard intrusion detection methods. This study investigates quantum machine learning approaches for detecting coordinated stealth attacks on a distributed generation unit in a microgrid. High-quality simulated measurements were used to create a balanced binary classification dataset using three features: reactive power at DG1, frequency deviation relative to the nominal value, and terminal voltage magnitude. Classical machine learning baselines, fully quantum variational classifiers, and hybrid quantum classical models were evaluated. The results show that a hybrid quantum classical model combining quantum feature embeddings with a classical RBF support vector machine achieves the best overall performance on this low dimensional dataset, with a modest improvement in accuracy and F1 score over a strong classical SVM baseline. Fully quantum models perform worse due to training instability and limitations of current NISQ hardware. In contrast, hybrid models train more reliably and demonstrate that quantum feature mapping can enhance intrusion detection even when fully quantum learning is not yet practical.

</details>


### [121] [LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification](https://arxiv.org/abs/2601.00877)
*Thomas Andrews,Mark Law,Sara Ahmadi-Abhari,Alessandra Russo*

Main category: cs.LG

TL;DR: LearnAD是一种神经符号方法，用于从脑部MRI数据预测阿尔茨海默病，学习完全可解释的规则，结合统计模型和符号学习，在保持可解释性的同时达到接近黑盒模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在临床神经科学中，深度学习模型（如GNN）虽然性能优秀但缺乏可解释性，而传统统计模型可解释但性能有限。需要一种既能保持高性能又能提供完全可解释性的方法，以加深对GNN行为在临床神经科学中的理解。

Method: LearnAD采用神经符号方法：1）首先使用统计模型（决策树、随机森林或GNN）识别相关的脑连接特征；2）然后使用FastLAS符号学习系统从这些特征中学习全局规则。这种方法结合了神经网络的表示能力和符号系统的可解释性。

Result: 最佳实例性能优于决策树，与支持向量机相当，仅略低于使用所有特征的随机森林和GNN，同时保持完全可解释性。消融研究表明，神经符号方法在保持可比性能的同时显著提高了可解释性。

Conclusion: LearnAD展示了符号学习如何能够加深对GNN在临床神经科学中行为的理解，为开发既高性能又完全可解释的医疗AI模型提供了有前景的途径，在保持临床可信度的同时不牺牲预测准确性。

Abstract: We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.

</details>


### [122] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

TL;DR: 提出基于向量余弦相似度的多维异常检测方法，通过添加零值维度构建新数据集，利用观测点和测量点之间的向量相似性识别异常数据。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的多维数据异常检测方法，传统方法可能在高维空间中效果不佳，因此提出基于向量几何关系的新方法。

Method: 通过向原始数据添加零值维度构建新数据集，选择测量点并创建观测点（原点），观测点与测量点仅在新维度上有非零值差异。然后从观测点到测量点和其他点形成向量，通过比较这些向量的余弦相似度来识别异常数据。

Result: 开发了优化的MDOD实现并已在PyPI发布，提供了一种新的异常检测工具。

Conclusion: 该方法为多维异常检测提供了一种基于向量余弦相似度的新方法，通过几何关系有效识别异常数据。

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [123] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

TL;DR: FANoS是一种受物理学启发的优化器，结合了二阶动力系统、Nosé-Hoover热浴变量和半隐式积分器，在特定非凸问题上表现良好，但总体上不如现代基线方法。


<details>
  <summary>Details</summary>
Motivation: 将分子动力学中的结构保持积分和热浴思想应用于优化算法，开发一种物理启发的优化器，旨在处理某些困难的非凸优化问题。

Method: 结合三个要素：(1) 离散化二阶动力系统的动量更新，(2) 使用动能反馈调整标量摩擦系数的Nosé-Hoover类热浴变量，(3) 半隐式（辛欧拉）积分器，可选对角RMS预处理器。

Result: 在Rosenbrock-100D基准测试中，FANoS-RMS达到1.74×10^{-2}，优于未裁剪的AdamW(48.50)和SGD+momentum(90.76)，但不如梯度裁剪的AdamW(1.87×10^{-3})和L-BFGS(4.4×10^{-10})。在病态凸二次问题和PINN问题上表现不佳。

Conclusion: FANoS是现有思想的可解释综合，在某些刚性非凸谷问题上可能有帮助，但不是现代基线的通用替代品，其行为对温度调度和超参数选择敏感。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [124] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

TL;DR: 提出一种分层拓扑聚类算法，适用于任意距离度量，能识别任意形状的聚类和离群点，在图像、医疗和经济数据中验证了有效性


<details>
  <summary>Details</summary>
Motivation: 拓扑方法能够在不假设数据结构的情况下探索数据云，但需要一种能处理任意距离度量、识别任意形状聚类和离群点的聚类算法

Method: 提出分层拓扑聚类算法，使用持久性推断离群点和任意形状聚类的稳定性，算法可适用于任何距离选择

Result: 在图像、医疗和经济数据等数据集上验证了算法有效性，特别是在离群点起重要作用的情况下，算法能提供有意义的聚类结果

Conclusion: 该拓扑聚类算法在传统方法失败的情况下仍能提供有意义的聚类，具有处理任意形状聚类和识别离群点的优势

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [125] [When to Ponder: Adaptive Compute Allocation for Code Generation via Test-Time Training](https://arxiv.org/abs/2601.00894)
*Gihyeon Sim*

Main category: cs.LG

TL;DR: PonderTTT：一种基于自监督重建损失的训练无关门控策略，用于选择性触发测试时训练更新，在代码语言建模中显著优于随机跳过基线


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对所有输入采用统一计算，不考虑难度差异。需要一种方法在推理时选择性触发测试时训练更新，以提高效率

Method: 提出PonderTTT门控策略，使用TTT层的自监督重建损失作为门控信号，无需训练分类器或辅助网络，仅需在无标签数据上校准单个标量阈值并通过EMA持续调整以维持目标更新率

Result: 在GPT-2模型（124M到1.5B）的代码语言建模实验中，重建门控实现了82-89%的Oracle恢复率，完全训练无关，显著优于随机跳过基线（在OOD语言上损失降低达16%）

Conclusion: 自监督重建损失是推理兼容的有效门控信号，PonderTTT策略能够在保持训练无关的同时，高效选择性地触发测试时训练更新

Abstract: Large language models apply uniform computation to all inputs, regardless of difficulty. We propose PonderTTT, a gating strategy using the TTT layer's self-supervised reconstruction loss to selectively trigger Test-Time Training (TTT) updates. The gating decision itself is training-free--requiring no learned classifier or auxiliary networks; only a single scalar threshold is initially calibrated on unlabeled data and continuously adapted via EMA to maintain target update rates. Our experiments with GPT-2 models (124M to 1.5B) on code language modeling (The Stack v2, teacher-forced perplexity) demonstrate that this signal is inference-compatible, requiring no ground-truth labels. Our Reconstruction Gating achieves 82-89% Oracle Recovery while being fully training-free, significantly outperforming Random Skip baselines (up to 16% lower loss on OOD languages).

</details>


### [126] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

TL;DR: DIPOLE是一种新颖的强化学习算法，通过将最优策略分解为一对稳定学习的二分策略（一个最大化奖励，一个最小化奖励），解决了扩散策略在RL训练中的不稳定和计算问题。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在决策任务中表现出色，但使用强化学习有效训练大型扩散策略仍然具有挑战性。现有方法要么因直接最大化价值目标而导致训练不稳定，要么因依赖粗糙的高斯似然近似而面临计算问题。

Method: 提出DIPOLE算法：重新审视RL中的KL正则化目标，制定贪婪化策略正则化方案，将最优策略分解为一对二分策略（奖励最大化和最小化策略）。在推理时通过线性组合二分策略的分数生成优化动作。

Result: 在ExORL和OGBench的离线和离线到在线RL设置中验证了方法的有效性。还成功训练了用于端到端自动驾驶的大型视觉-语言-动作模型，并在大规模真实世界AD基准NAVSIM上进行了评估。

Conclusion: DIPOLE为扩散策略提供了稳定且可控的优化方法，能够灵活控制贪婪程度，在复杂现实应用中具有潜力。

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [127] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

TL;DR: 研究发现在分布漂移下，保形预测的覆盖保证会下降，特别是在COVID-19供应链任务中，覆盖下降幅度从0%到86.7%不等。通过SHAP分析发现，灾难性失败与单特征依赖性相关，特征重要性集中在单一特征的任务容易失败。季度性重新训练可以部分恢复覆盖，但仅对脆弱任务有效。


<details>
  <summary>Details</summary>
Motivation: 保形预测在分布漂移下的性能保证会下降，但不同任务间的下降幅度差异很大。研究旨在理解这种差异的原因，特别是在COVID-19导致的供应链分布漂移背景下，探索哪些因素导致某些任务出现灾难性失败而其他任务保持稳健。

Method: 使用COVID-19作为自然实验，分析8个供应链任务在严重特征周转（Jaccard约等于0）下的表现。采用SHAP分析特征重要性分布，计算特征集中度指标。通过季度性重新训练评估恢复效果，并额外分析4个具有中等特征稳定性的任务进行比较。

Result: 覆盖下降幅度差异巨大（0%-86.7%）。灾难性失败与单特征依赖性高度相关（rho=0.714, p=0.047）。脆弱任务的特征重要性集中在单一特征（增加4.5倍），而稳健任务则分散在多个特征（10-20倍）。季度重新训练可将脆弱任务的覆盖从22%提升到41%，但对稳健任务无益（99.8%覆盖）。特征稳定性而非集中度决定了中等漂移下的稳健性。

Conclusion: 提出了一个决策框架：部署前监控SHAP集中度；如果脆弱（>40%集中度）则进行季度重新训练；如果稳健则跳过重新训练。特征集中度效应主要适用于严重分布漂移情况，而特征稳定性是更一般的稳健性决定因素。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [128] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

TL;DR: 提出LC-CVAE方法，通过强制潜在空间在锚点位置的一致性，解决多气候模型集成生成中的泛化问题，实现从有限运行中生成统计一致的时空气候变量。


<details>
  <summary>Details</summary>
Motivation: 大规模气候模型集成计算成本高，但许多下游分析需要更多统计一致的时空气候变量实现。现有方法在从有限运行中生成新实现时面临泛化问题。

Method: 提出潜在约束条件变分自编码器(LC-CVAE)，在共享地理"锚点"位置强制潜在嵌入的跨实现同质性，然后使用多输出高斯过程回归预测新实现中未采样位置的潜在坐标，最后解码生成完整时间序列场。

Result: 实验表明：(1)在单个实现上训练不稳定；(2)纳入约五个实现后收益递减；(3)空间覆盖与重建质量之间存在权衡，这与潜在空间中的平均邻居距离密切相关。

Conclusion: LC-CVAE方法有效解决了多气候模型集成生成中的泛化问题，能够从有限运行中生成统计一致的气候变量实现，为下游分析提供更多数据支持。

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [129] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 提出Lazy Attention机制，通过位置区分和弹性Softmax解决注意力过载和欠载问题，缓解表示坍塌和注意力沉没，在多个基准测试中达到59.58%的注意力稀疏度。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的标准注意力机制存在表示坍塌和注意力沉没问题，现有研究往往孤立处理这些问题，缺乏统一视角。本文认为这两个问题都源于不恰当的注意力分配，需要统一的解决方案。

Method: 提出Lazy Attention机制：1) 针对注意力过载，使用跨头和维度的位置区分来增强token区分度；2) 针对注意力欠载，引入Elastic-Softmax归一化函数，放松标准softmax约束以抑制无关token的注意力。

Result: 在FineWeb-Edu语料库上实验，在九个不同基准测试中，Lazy Attention成功缓解了注意力沉没问题，与标准注意力和现代架构相比具有竞争力，同时达到最高59.58%的注意力稀疏度。

Conclusion: 表示坍塌和注意力沉没问题都源于不恰当的注意力分配，Lazy Attention通过统一的机制有效解决了这两个问题，实现了更聚焦的注意力分布和更高的稀疏性。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [130] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

TL;DR: MODE：结合低秩神经ODE与增强Mamba架构的统一时间序列预测框架，在效率和准确性上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在处理长程依赖和不规则采样数据时，难以平衡效率、可扩展性和准确性

Method: 提出MODE框架，集成低秩神经ODE与增强Mamba架构，包含线性标记化层、多个Mamba编码器块（含因果卷积、SiLU激活和低秩神经ODE增强），以及受伪ODE动态启发的分段选择性扫描机制

Result: 在基准数据集上的大量实验表明，MODE在预测准确性和计算效率方面均超越现有基线方法

Conclusion: MODE为长期时间序列建模提供了统一高效架构，通过低秩神经ODE与Mamba选择性扫描的集成增强了时间表示能力，低秩近似和动态选择性扫描显著提升了效率和可扩展性

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [131] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

TL;DR: 量子核方法与几何感知描述符在低数据、低特征生物医学预测中优于经典基线，用于COPD相关肌肉功能障碍预测


<details>
  <summary>Details</summary>
Motivation: 慢性阻塞性肺病（COPD）的骨骼肌功能障碍与全身和气道炎症密切相关，需要从微创生物标志物预测肌肉结果，特别是在小样本临床前数据中

Method: 使用经典基线模型、几何感知对称正定（SPD）描述符与Stein散度、以及为低维表格数据设计的量子核模型，比较预测肌肉重量、特定力量和肌肉质量指数

Result: 量子核岭回归在肌肉重量预测中表现最佳（RMSE 4.41 mg，R² 0.605），优于匹配的岭回归基线（4.70 mg，0.553）。几何方法在仅使用生物标志物时也有提升（4.55 mg vs 4.79 mg）。筛查评估的ROC-AUC最高达0.90

Conclusion: 几何和量子核提升在低数据、低特征的生物医学预测问题中能提供可测量的优势，同时保持可解释性和透明的模型选择

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [132] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

TL;DR: 提出一种将算法源代码转换为数值嵌入的通用方法，通过动态分析程序在不同输入下的行为，并针对分析指标定制多个通用复杂度函数，基于r-Complexity构建代码嵌入，在Codeforces真实代码片段数据集上实现多标签分类的XGBoost算法


<details>
  <summary>Details</summary>
Motivation: 需要一种通用方法将各种算法的源代码转换为数值嵌入，以便进行机器学习分析，特别是针对编程竞赛中的代码片段

Method: 通过动态分析计算机程序在不同输入下的行为，为分析指标定制多个通用复杂度函数，基于r-Complexity构建算法嵌入，使用这些嵌入实现XGBoost算法进行多标签分类

Result: 在包含11个类别的多标签数据集上，使用Codeforces平台真实代码片段构建的数据集上，实现了平均F1-score的性能表现

Conclusion: 提出的代码嵌入方法能够有效将源代码转换为数值表示，支持机器学习算法在代码分析任务中的应用，特别是在编程竞赛代码的多标签分类任务中表现良好

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [133] [Enhanced Data-Driven Product Development via Gradient Based Optimization and Conformalized Monte Carlo Dropout Uncertainty Estimation](https://arxiv.org/abs/2601.00932)
*Andrea Thomas Nava,Lijo Johny,Fabio Azzalini,Johannes Schneider,Arianna Casanova*

Main category: cs.LG

TL;DR: 提出一个数据驱动的产品开发框架，使用联合神经网络优化多属性产品设计，并引入ConfMC方法提供不确定性估计和覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 许多产品需要同时优化多个相关属性，传统方法难以捕捉这些属性间的相互依赖关系，且缺乏可靠的不确定性估计和覆盖保证。

Method: 1) 使用神经网络学习产品设计规格与性能的关系；2) 采用投影梯度下降寻找最优设计；3) 使用联合神经网络捕捉多目标间的相互依赖；4) 提出ConfMC方法（嵌套保形预测与蒙特卡洛dropout结合）进行不确定性估计。

Result: 在五个真实世界数据集上的实验表明，该方法达到最先进性能，提供自适应、非均匀的预测区间，且调整覆盖水平时无需重新训练模型。

Conclusion: 该框架有效解决了多属性产品优化问题，提供可靠的不确定性估计和覆盖保证，为数据驱动的产品开发提供了实用工具。

Abstract: Data-Driven Product Development (DDPD) leverages data to learn the relationship between product design specifications and resulting properties. To discover improved designs, we train a neural network on past experiments and apply Projected Gradient Descent to identify optimal input features that maximize performance. Since many products require simultaneous optimization of multiple correlated properties, our framework employs joint neural networks to capture interdependencies among targets. Furthermore, we integrate uncertainty estimation via \emph{Conformalised Monte Carlo Dropout} (ConfMC), a novel method combining Nested Conformal Prediction with Monte Carlo dropout to provide model-agnostic, finite-sample coverage guarantees under data exchangeability. Extensive experiments on five real-world datasets show that our method matches state-of-the-art performance while offering adaptive, non-uniform prediction intervals and eliminating the need for retraining when adjusting coverage levels.

</details>


### [134] [LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection](https://arxiv.org/abs/2601.00933)
*Jinyu Xu,Abhishek K. Umrawal*

Main category: cs.LG

TL;DR: 在线影响力最大化问题中，提出LOFA算法，在完全老虎机反馈下实现更低经验遗憾


<details>
  <summary>Details</summary>
Motivation: 在线影响力最大化问题中，现有算法虽然利用子模性实现低遗憾，但仍有改进空间。作者希望进一步利用子模性设计更高效的算法。

Method: 提出懒惰在线前向算法（LOFA），在完全老虎机反馈模型下，利用影响力函数的子模性，通过懒惰更新机制减少计算复杂度。

Result: 在真实社交网络上的实验表明，LOFA在累积遗憾和瞬时奖励方面均优于现有老虎机算法。

Conclusion: LOFA通过有效利用子模性，在在线影响力最大化问题中实现了更优的性能表现。

Abstract: We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\unicode{x2014}$called the seed set$\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.

</details>


### [135] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

TL;DR: 稀疏MoE架构在随机解码下的可靠性研究表明，指令微调而非架构稀疏性是决定模型在确定性任务上鲁棒性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 随着稀疏混合专家（MoE）架构在大型语言模型中的普及，需要研究其在随机解码下的可靠性。虽然条件计算带来了计算效率提升，但稀疏路由与基于温度的采样之间的相互作用是否会损害输出稳定性尚不清楚。

Method: 评估三个代表性模型：OLMoE-7B（稀疏基础模型）、Mixtral-8x7B（稀疏指令微调模型）和Qwen2.5-3B（密集指令微调模型）。在具有客观可验证答案的确定性算术推理任务上进行测试，涵盖四种解码配置（从贪婪解码到T=1.0），评估准确性、格式合规性、重复生成输出一致性和置信度指标，总计9360次模型生成。

Result: 稀疏指令微调模型在所有解码温度下表现出与密集指令微调模型相当的稳定性，而稀疏基础模型随着温度升高出现系统性性能下降。这表明指令微调而非架构稀疏性是决定模型在确定性任务上对解码随机性鲁棒性的主要因素。

Conclusion: 指令微调是确保稀疏语言模型在可靠性关键应用中稳定性的关键，稀疏架构可以在不牺牲输出稳定性的情况下安全部署，前提是经过适当的指令微调。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [136] [Adapting Feature Attenuation to NLP](https://arxiv.org/abs/2601.00965)
*Tianshuo Yang,Ryan Rabinowitz,Terrance E. Boult,Jugal Kalita*

Main category: cs.LG

TL;DR: 该研究将计算机视觉中的特征衰减假设移植到Transformer模型，评估了多种开放集识别方法在文本分类任务上的表现，发现移植方法未带来显著提升，并指出需要更大模型和任务定制策略。


<details>
  <summary>Details</summary>
Motivation: Transformer分类器在封闭集上表现出色，但在面对未见类别输入时仍然脆弱，这是部署NLP系统常见场景。研究旨在探索文本开放集识别，将计算机视觉中的特征衰减假设移植到Transformer模型。

Method: 将计算机视觉中的COSTARR框架适配到BERT和GPT-2模型，训练模型标注176个arXiv主题领域。同时评估了最大softmax概率、最大logit、温度缩放自由能分数等方法，使用OOSA和AUOSCR指标。

Result: COSTARR可以扩展到NLP领域而无需重新训练，但相比MaxLogit或MSP没有统计显著提升；自由能分数在这个高类别数量设置中落后于所有其他方法。

Conclusion: 研究显示了将视觉中心开放集识别思想移植到语言模型的潜力和当前局限性，指出需要更大的骨干网络和任务定制的衰减策略。

Abstract: Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.

</details>


### [137] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

TL;DR: 提出一种基于LIME解释的对抗鲁棒性训练框架，通过抑制虚假特征来同时提升模型的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医疗和自动驾驶等安全关键领域，深度学习模型需要同时具备对抗鲁棒性和决策透明度。研究发现，通过LIME识别出的虚假、不稳定或语义无关特征会显著增加模型的对抗脆弱性。

Method: 提出基于属性引导的精炼框架，将LIME从被动诊断工具转变为主动训练信号。方法包括特征掩码、敏感感知正则化和对抗增强，形成闭环精炼流程，无需额外数据集或模型架构，可无缝集成到标准对抗训练中。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100数据集上的实验表明，该方法显著提升了对抗鲁棒性和分布外泛化能力。

Conclusion: 建立了可解释性与鲁棒性之间的直接联系，通过抑制虚假特征可以同时提升模型的透明度和对抗鲁棒性，为安全关键应用提供了有效的训练框架。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [138] [Zero-shot Forecasting by Simulation Alone](https://arxiv.org/abs/2601.00970)
*Boris N. Oreshkin,Mayank Jauhari,Ravi Kiran Selvam,Malcolm Wolff,Wenhao Pan,Shankar Ramasubramanian,Kin G. Olivares,Tatiana Konstantinova,Andres Potapczynski,Mengfei Cao,Dmitry Efimov,Michael W. Mahoney,Andrew G. Wilson*

Main category: cs.LG

TL;DR: 提出SarSim0时间序列模拟器，基于SARIMA模型，通过三步法生成稳定、多季节性的模拟数据，实现快速零样本预测，在M-Series和GiftEval基准上超越统计方法和现有基础模型。


<details>
  <summary>Details</summary>
Motivation: 解决零样本时间序列预测面临的挑战：数据有限且存在偏差、评估易泄露、隐私和许可限制，需要一种实用的模拟方法。

Method: 基于SARIMA模型的三步模拟流程：1)从特征多项式稳定区域采样稳定轨迹；2)通过叠加方案组合多个路径生成多季节性轨迹；3)添加基于速率的重尾噪声模型捕捉突发性和间歇性。

Result: SarSim0比基于核的生成器快几个数量级，可实时生成约10亿个独特模拟序列。训练后的神经网络在零样本协议下表现出强泛化能力，超越统计预测器和近期基础模型，在GiftEval上甚至超过生成过程AutoARIMA的准确性。

Conclusion: SarSim0是首个实用的单变量时间序列模拟管道，能够快速生成高质量模拟数据，显著提升零样本预测性能，为工业预测应用提供了有效解决方案。

Abstract: Zero-shot time-series forecasting holds great promise, but is still in its infancy, hindered by limited and biased data corpora, leakage-prone evaluation, and privacy and licensing constraints. Motivated by these challenges, we propose the first practical univariate time series simulation pipeline which is simultaneously fast enough for on-the-fly data generation and enables notable zero-shot forecasting performance on M-Series and GiftEval benchmarks that capture trend/seasonality/intermittency patterns, typical of industrial forecasting applications across a variety of domains. Our simulator, which we call SarSim0 (SARIMA Simulator for Zero-Shot Forecasting), is based off of a seasonal autoregressive integrated moving average (SARIMA) model as its core data source. Due to instability in the autoregressive component, naive SARIMA simulation often leads to unusable paths. Instead, we follow a three-step procedure: (1) we sample well-behaved trajectories from its characteristic polynomial stability region; (2) we introduce a superposition scheme that combines multiple paths into rich multi-seasonality traces; and (3) we add rate-based heavy-tailed noise models to capture burstiness and intermittency alongside seasonalities and trends. SarSim0 is orders of magnitude faster than kernel-based generators, and it enables training on circa 1B unique purely simulated series, generated on the fly; after which well-established neural network backbones exhibit strong zero-shot generalization, surpassing strong statistical forecasters and recent foundation baselines, while operating under strict zero-shot protocol. Notably, on GiftEval we observe a "student-beats-teacher" effect: models trained on our simulations exceed the forecasting accuracy of the AutoARIMA generating processes.

</details>


### [139] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

TL;DR: 论文提出收缩扩散策略（CDPs），通过在扩散采样动力学中引入收缩行为来增强离线策略学习的鲁棒性，减少求解器和分数匹配误差的影响，特别在数据稀缺时表现优异。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽然强大，但其基于分数的SDE建模会带来求解器和分数匹配误差、大数据需求以及动作生成不一致等问题。这些在图像生成中不太关键的问题在连续控制环境中会累积并导致失败。

Method: 引入收缩扩散策略（CDPs），在扩散采样动力学中诱导收缩行为。收缩将附近的流拉近，增强对求解器和分数匹配误差的鲁棒性，同时减少不需要的动作方差。提供理论分析和实践实现方法，可轻松集成到现有扩散策略架构中。

Result: 在模拟和真实世界环境中进行广泛实验评估。在多个基准测试中，CDPs通常优于基线策略，在数据稀缺情况下表现出更明显的优势。

Conclusion: CDPs通过引入收缩行为有效解决了扩散策略在连续控制中的误差累积问题，提高了鲁棒性和性能，特别是在数据有限的情况下。

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [140] [Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms](https://arxiv.org/abs/2601.01009)
*Mojtaba Aliasghar-Mamaghani,Mohammadreza Khalafi*

Main category: cs.LG

TL;DR: 使用多种机器学习算法分析混凝土配合比对氯离子渗透时间演化的影响，为基础设施寿命评估提供数据驱动方法


<details>
  <summary>Details</summary>
Motivation: 评估混凝土结构在侵蚀环境中的使用寿命需要理解氯离子渗透的时间演化规律，传统方法难以揭示配合比成分与氯离子渗透之间的复杂隐藏关系

Method: 采用简单和复杂的机器学习算法：线性回归、KNN回归、核岭回归、支持向量回归、高斯过程回归、前馈神经网络和门控循环单元，使用综合数据集进行训练和评估

Result: 核岭回归、高斯过程回归和MLP表现最佳，GRU在多样化配合比数据上表现不佳。多数配合比成分与氯离子含量呈负相关，少数呈正相关。GPR模型能清晰揭示潜在相关性

Conclusion: 机器学习方法可作为替代方法有效描述氯离子渗透物理过程及相关关系，有助于提高基础设施使用寿命评估的准确性

Abstract: This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.

</details>


### [141] [Geometric and Dynamic Scaling in Deep Transformers](https://arxiv.org/abs/2601.01014)
*Haoran Su,Chenyu You*

Main category: cs.LG

TL;DR: 论文提出Transformer深度扩展导致表示崩溃的根本原因是几何问题，而非优化不稳定，并提出Manifold-Geometric Transformer (MGT)通过流形约束和深度增量学习解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有解释将Transformer深度扩展时的表示崩溃归因于优化不稳定或梯度消失，但这些解释无法解释为什么在现代归一化和初始化方案下崩溃仍然存在。作者认为这本质上是一个几何问题。

Method: 提出统一的几何框架，包含两个正交原则：1) 流形约束超连接，限制残差更新到有效的局部切向方向，防止不受控制的流形漂移；2) 深度增量学习，引入数据依赖的非单调更新，能够反射和擦除冗余特征而非无条件累积。

Result: 提出的MGT架构将特征更新的方向和符号解耦，实现跨深度的稳定几何演化。分析预测强制几何有效性同时允许动态擦除对于避免超深网络中的秩崩溃至关重要。

Conclusion: 深度Transformer的崩溃本质上是几何问题而非深度本身。通过流形约束和动态擦除机制，可以构建超过100层的稳定Transformer架构，几何而非深度是深度表示学习的关键限制因素。

Abstract: Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.

</details>


### [142] [Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study](https://arxiv.org/abs/2601.01016)
*Ata Akbari Asanjan,Milad Memarzadeh,Bryan Matthews,Nikunj Oza*

Main category: cs.LG

TL;DR: 论文研究使用随机傅里叶变换(RFT)改进自编码器和变分自编码器的训练与推理，通过频率原理分析发现RFT模型能同时学习高低频特征，而传统DNN只能从低频逐渐学习高频。研究还引入了可训练的RFT变体，并在合成数据集和航空安全数据集上验证了傅里叶变换模型的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络在训练过程中存在频率学习顺序的限制（从低频到高频），这可能会影响模型性能。研究旨在探索随机傅里叶变换如何改进自编码器和变分自编码器的训练过程，特别是在异常检测任务中，并研究可训练的傅里叶变换变体是否能带来额外优势。

Method: 1. 使用随机傅里叶变换(RFT)改进自编码器和变分自编码器的训练；2. 通过频率原理分析模型训练行为；3. 引入可训练的RFT变体，利用现有计算图训练傅里叶展开；4. 在低维合成数据集上进行数据表示实验；5. 在航空安全数据集(Dashlink)上进行高维重建式异常检测实验。

Result: 1. RFT模型能同时学习低频和高频特征，而传统DNN只能从低频开始逐步学习高频；2. 使用傅里叶变换的模型在性能上优于传统对应模型；3. 可训练傅里叶变换与随机变体相比的优势尚不明确，结果尚无定论。

Conclusion: 随机傅里叶变换能有效改进自编码器和变分自编码器的训练过程，使模型能同时学习不同频率特征，在异常检测任务中表现优于传统方法。然而，可训练傅里叶变换相对于随机变体的额外优势仍需进一步研究验证。

Abstract: In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.

</details>


### [143] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

TL;DR: 基于Wiener混沌展开设计神经算子架构，用于学习SDE/SPDE的解算子，通过正交Hermite特征投影噪声路径，参数化确定性混沌系数，实现单次前向传播从噪声重构完整解轨迹。


<details>
  <summary>Details</summary>
Motivation: SDE和SPDE是建模随机动力学的基本工具，开发深度学习模型逼近其解算子不仅能提供快速实用的求解器，还能从新视角解决经典学习任务。传统Wiener混沌展开为设计神经算子架构提供了理论基础。

Method: 基于Wiener混沌展开：1) 将驱动噪声路径投影到正交Wick Hermite特征上；2) 用神经算子参数化得到的确定性混沌系数；3) 实现从噪声到完整解轨迹的单次前向传播重构。理论方面推导了多维SDE和半线性SPDE的混沌系数耦合ODE/PDE系统。

Result: 在多样化问题上验证模型：经典SPDE基准、图像扩散一步采样、图拓扑插值、金融外推、参数估计、洪水预测的流形SDE，展示了竞争性精度和广泛适用性。

Conclusion: 基于Wiener混沌展开的神经算子为学习SDE/SPDE解算子提供了实用且可扩展的方法，在多个领域表现出色，表明该框架具有广泛的应用潜力。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [144] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

TL;DR: 提出一个任务和模型感知的无线数据集相似性测量框架，用于预测跨数据集可迁移性，在CSI压缩和波束预测任务中验证有效性


<details>
  <summary>Details</summary>
Motivation: 无线通信中需要评估不同数据集之间的相似性，以支持数据集选择/增强、仿真到真实场景比较、任务特定合成数据生成等应用，但缺乏系统化的评估方法

Method: 提出任务和模型感知的框架，通过数据集距离度量预测跨数据集可迁移性；使用基于UMAP嵌入结合Wasserstein和欧氏距离的度量；对于监督任务，集成监督UMAP和数据集不平衡惩罚

Result: 在CSI压缩任务中，数据集距离与训练-测试性能的Pearson相关系数超过0.85；在波束预测任务中，提出的标签感知距离优于传统基线，与模型可迁移性有更强相关性

Conclusion: 该框架能够有效测量无线数据集之间的相似性，支持任务相关的数据集比较，为数据集选择、模型训练和适应新部署提供决策依据

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [145] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

TL;DR: 提出基于信息论Lyapunov函数V-δ的投影反向扩散方法，用于在生成模型中控制粗粒度特征（如区块强度）的演化


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型缺乏理论描述粗粒度特征（如图像空间区块强度）在反向扩散过程中的演化机制，需要开发能显式控制这些特征的方法

Method: 移植信息论Lyapunov函数框架到反向扩散过程，提出V-δ投影反向扩散方案，将反向扩散过程投影到满足粗粒度约束的分布集合上

Result: 在区块常数图像的玩具模型中，该方法能将区块质量误差和泄漏容忍势函数控制在预设容差内，同时保持与非投影方法相当的像素级精度和视觉质量

Conclusion: 将生成采样重新解释为从噪声到数据的信息势函数下降过程，为具有显式粗粒度特征控制的反向扩散过程提供了设计原则

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [146] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

TL;DR: ML-UCB：一种将任意机器学习模型集成到多臂老虎机框架中的广义上置信界算法，通过直接建模底层估计器的学习曲线行为来克服传统方法缺乏可处理浓度不等式的问题。


<details>
  <summary>Details</summary>
Motivation: 在序列决策中部署复杂机器学习模型时面临的核心挑战是缺乏用于原则性探索的可处理浓度不等式。传统方法需要针对每个模型进行特定的理论分析，限制了ML模型在多臂老虎机框架中的应用。

Method: 提出ML-UCB算法，假设均方误差随训练样本数量呈幂律下降，基于此推导广义浓度不等式。该方法通过经验表征任何ML模型的学习曲线，无需模型特定的理论分析，实现了ML模型与多臂老虎机框架的原则性集成。

Result: 理论证明ML-UCB能够实现次线性遗憾。在协同过滤推荐系统的实验中，使用在线矩阵分解和模拟简化双塔模型的合成数据，相比LinUCB取得了显著改进。

Conclusion: ML-UCB为将任意机器学习模型集成到多臂老虎机框架提供了通用解决方案，通过直接建模学习曲线行为克服了传统浓度不等式的局限性，实现了原则性探索和次线性遗憾保证。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [147] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种端到端的视觉播客生成管道，通过微调Qwen3-VL-32B模型，使用合成到真实的训练策略，在对话自然度和叙事深度上显著超越了更大的基础模型。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在描述性任务上表现出色，但在生成引人入胜的长篇叙事（特别是多说话者播客对话）方面仍有待探索且难以评估。标准指标如BLEU和ROUGE无法捕捉对话自然度、个性和叙事流程的细微差别，往往奖励安全、重复的输出而非引人入胜的叙事。

Method: 1. 提出端到端视觉播客生成管道；2. 在精选的4,000个图像-对话对数据集上微调Qwen3-VL-32B模型；3. 采用合成到真实的训练策略：在结构化播客研究语料库的高质量播客对话与合成生成图像上进行训练，在视觉叙事数据集的真实世界照片序列上进行评估；4. 提出超越文本重叠的综合评估框架，使用AI作为评判和新型风格指标。

Result: 微调的32B模型在对话自然度上显著优于235B基础模型（>80%胜率），叙事深度提升50%（平均轮次长度），同时保持相同的视觉基础能力（CLIPScore: 20.39）。

Conclusion: 该研究展示了通过精心设计的训练策略和评估框架，相对较小的模型可以在叙事生成质量上超越更大的基础模型，为视觉叙事生成领域提供了新的方法和评估标准。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [148] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

TL;DR: 本文提出将基于TinyML的低功耗边缘设备集成到水产养殖系统中，实现实时自动化监测和控制，以解决传统人工监测效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业面临水质波动、疾病爆发和饲料管理效率低等挑战，传统人工监测方法耗时且可能导致问题处理延迟，需要更高效的自动化解决方案。

Method: 采用TinyML技术结合低功耗边缘设备，设计传感器系统监测pH值、温度、溶解氧、氨氮等关键参数，实现实时数据采集、异常检测和自动报警功能。

Result: 系统能够实时监测水质参数，在检测到异常时自动报警，收集的数据可用于优化水处理过程、饲料分配和饲料效率分析，降低运营成本。

Conclusion: TinyML技术在水产养殖监测中具有可行性，能够实现更可持续和高效的养殖实践，研究考虑了传感器选择、算法设计、硬件约束和伦理因素。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [149] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种改进的分析框架，简化了非平稳参数化赌博机中加权策略的理论推导和算法设计，在线性赌博机中实现了更简单的算法，并在广义线性赌博机、自协调赌博机以及具有函数逼近的MDP中改进了遗憾界。


<details>
  <summary>Details</summary>
Motivation: 非平稳参数化赌博机中，加权策略在实际应用中常用于处理渐变漂移模式，但先前理论研究显示其分析复杂，算法要么计算效率低要么统计次优。本文旨在解决加权策略分析框架的不足，简化算法设计并改进理论性能。

Method: 提出了一种精炼的分析框架，重新审视加权策略在非平稳参数化赌博机中的应用。在线性赌博机中，该框架简化了推导过程，产生了更简单的加权算法。框架还可扩展到广义线性赌博机、自协调赌博机以及具有函数逼近的马尔可夫决策过程（包括线性混合MDP和多项Logit混合MDP）。

Result: 在线性赌博机中，新框架产生了与窗口/重启算法同样高效但更简单的加权算法，且保持了相同的遗憾界。在广义线性赌博机中，获得了$\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$的遗憾界，优于先前工作的$\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$。框架还成功扩展到非平稳MDP，为线性混合MDP和多项Logit混合MDP建立了动态遗憾保证。

Conclusion: 本文提出的精炼分析框架解决了非平稳参数化赌博机中加权策略的理论分析难题，简化了算法设计，提高了计算效率，并在多个模型类别中改进了遗憾界，为处理非平稳环境提供了更有效的理论工具。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [150] [Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments](https://arxiv.org/abs/2601.01075)
*Hansen Jin Lillemark,Benhao Huang,Fangneng Zhan,Yilun Du,Thomas Anderson Keller*

Main category: cs.LG

TL;DR: 提出Flow Equivariant World Models框架，将自运动和外部物体运动统一为单参数李群"流"，利用群等变性实现稳定潜在世界表示，在部分观测视频世界建模任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络世界模型忽略了感知流中平滑的时间参数化对称性结构，反复从数据中重新学习相同变换，缺乏对内部和外部运动统一数学结构的利用。

Method: 将自运动和外部物体运动统一为单参数李群"流"，实现对这些变换的群等变性，构建具有稳定潜在表示的世界模型框架。

Result: 在2D和3D部分观测视频世界建模基准测试中，显著优于可比较的基于扩散和记忆增强的世界建模架构，特别是在智能体当前视野外存在可预测世界动态时表现更优。

Conclusion: 通过将世界模型表示结构化以考虑内部和外部运动，流等变性为数据高效、对称性引导的具身智能提供了可扩展路径。

Abstract: Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.

</details>


### [151] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: DMS（折扣模型搜索）是一种新的质量多样性优化算法，使用连续模型替代直方图来指导高维度量空间中的探索，解决了现有算法在图像等高维空间中的停滞问题。


<details>
  <summary>Details</summary>
Motivation: 当前QD算法在处理高维度量空间时存在失真问题，许多解映射到相似的度量值，导致探索停滞。特别是CMA-MAE算法使用直方图记录折扣值，但在高维空间中相似度量的解会落入同一单元格，获得相同折扣值而无法继续探索。

Method: 提出折扣模型搜索（DMS），使用一个提供平滑连续折扣值表示的模型来指导探索。该模型能够区分高维度量空间中相似度量的解，从而支持持续探索。特别适用于图像空间作为度量空间的场景。

Result: 在高维基准测试和两个新引入的图像域中，DMS优于CMA-MAE和其他黑盒QD算法。DMS能够处理图像作为高维度量空间的应用，用户只需提供图像数据集而无需手动设计度量函数。

Conclusion: DMS通过连续折扣模型解决了高维度量空间中的探索停滞问题，扩展了QD算法的应用范围，特别是在图像空间等复杂度量场景中表现出色。

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [152] [Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding](https://arxiv.org/abs/2601.01089)
*Nobuyuki Ota*

Main category: cs.LG

TL;DR: CDT是一个整合DNA、RNA和蛋白质预训练语言模型的架构，遵循中心法则的方向逻辑，通过跨注意力机制生成统一的虚拟细胞嵌入，在CRISPRi增强子扰动数据上取得了良好预测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然DNA、RNA和蛋白质的领域特定基础模型各自取得了成功，但它们仍然相互隔离，限制了我们对整合细胞过程的建模能力。需要一种能够遵循中心法则方向逻辑整合这三种分子系统的架构。

Method: 提出中心法则变换器（CDT），整合DNA、RNA和蛋白质的预训练语言模型，采用方向性跨注意力机制：DNA-to-RNA注意力建模转录调控，RNA-to-Protein注意力建模翻译关系，生成统一的虚拟细胞嵌入。

Result: 在K562细胞的CRISPRi增强子扰动数据上，CDT v1（使用固定RNA和蛋白质嵌入的概念验证实现）达到Pearson相关系数0.503，占交叉实验变异性理论上限（r=0.797）的63%。注意力和梯度分析提供了互补的解释窗口。

Conclusion: 与生物信息流对齐的AI架构可以实现预测准确性和机制可解释性，CDT为整合多模态细胞数据建模提供了有前景的方向。

Abstract: Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability.

</details>


### [153] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 开发了一个针对孟加拉国和南亚人群的可解释机器学习框架，用于社区早期慢性肾病筛查，在资源有限环境下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有CKD筛查工具主要基于高收入国家人群开发，在孟加拉国和南亚地区表现不佳，因为这些地区的风险特征不同。现有工具依赖简单的累加评分函数，且基于晚期CKD患者数据，无法捕捉风险因素间的复杂交互作用，对早期CKD预测能力有限。

Method: 使用孟加拉国社区数据集（南亚首个此类数据集），评估12种机器学习分类器，应用10种互补的特征选择技术识别稳健、可泛化的预测因子。采用10折交叉验证评估最终模型，并在印度、阿联酋和孟加拉国的三个独立数据集上进行外部验证。使用SHAP提供模型可解释性。

Result: RFECV选择的特征子集训练的ML模型达到90.40%的平衡准确率，最小非病理测试特征集也表现出色（89.23%平衡准确率），通常优于更大或完整特征集。相比现有筛查工具，提出的模型准确率和灵敏度显著更高，同时需要更少且更易获得的输入。外部验证显示78%至98%的灵敏度，SHAP解释识别出与已确立CKD风险因素一致的临床有意义预测因子。

Conclusion: 开发的可解释机器学习框架为孟加拉国和南亚人群提供了有效的早期CKD筛查工具，在资源有限环境下表现出优异的预测性能和泛化能力，同时保持临床可解释性。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [154] [Learning from Historical Activations in Graph Neural Networks](https://arxiv.org/abs/2601.01123)
*Yaniv Galron,Hadar Sinai,Haggai Maron,Moshe Eliasof*

Main category: cs.LG

TL;DR: HISTOGRAPH是一种新颖的两阶段注意力聚合层，通过利用中间层的历史激活来改进图分类性能，特别在深层GNN中表现稳健。


<details>
  <summary>Details</summary>
Motivation: 现有图池化方法仅依赖最后一层GNN特征，未能充分利用前向传播过程中产生的中间层历史激活，这在节点表示可能发生显著变化的深层架构中尤为明显，且图特有的过平滑问题加剧了这一缺陷。

Method: 提出HISTOGRAPH：一种两阶段注意力聚合层。首先应用统一的层间注意力对中间激活进行加权，然后应用节点间注意力。通过建模节点表示在层间的演化过程，利用节点的激活历史和图结构来精炼用于最终预测的特征。

Result: 在多个图分类基准测试中，HISTOGRAPH表现出强大的性能，持续改进传统技术，在深层GNN中特别展现出稳健性。

Conclusion: HISTOGRAPH通过有效利用历史图激活，解决了现有池化方法对中间层特征利用不足的问题，为图神经网络提供了更有效的最终聚合机制，特别是在深层架构中表现出色。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.

</details>


### [155] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 基于维特根斯坦家族相似性概念的图聚类算法，无需预设簇数或形状假设


<details>
  <summary>Details</summary>
Motivation: 将维特根斯坦哲学中的家族相似性概念引入机器学习，解决传统聚类算法需要预设簇数和形状假设的限制

Method: 提出WFR算法及其核变体，通过计算相邻数据实例的相似度分数构建相似图，图的连通分量即为聚类结果

Result: 在基准数据集上的模拟表明WFR是有效的非线性聚类算法，无需簇数先验知识或形状假设

Conclusion: 哲学概念成功转化为实用的机器学习算法，为聚类问题提供了新的解决方案

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [156] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

TL;DR: 提出一种结合神经混沌学习与自训练的混合半监督学习方法，在低标签数据场景下显著提升分类性能


<details>
  <summary>Details</summary>
Motivation: 实际应用中获取大量标注数据困难且昂贵，而无标注数据易得。传统监督学习方法在少量标注数据或不平衡数据集场景下表现不佳

Method: 结合神经混沌学习(NL)与基于阈值的自训练(ST)方法。NL将输入特征转换为混沌发放率表示以捕捉数据非线性关系，ST利用高置信度伪标签样本逐步扩展标注集

Result: 在10个基准数据集和5个机器学习分类器上评估，仅使用15%标注数据。NL+ST架构相比单独ST模型获得显著性能提升，特别是在Iris(188.66%)、Wine(158.58%)和Glass Identification(110.48%)等有限、非线性、不平衡数据集上

Conclusion: 混沌特征提取与半监督学习结合可提升低数据场景下的泛化能力、鲁棒性和分类准确率

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [157] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: 提出Evo-TFS进化过采样方法，结合时域和频域特征处理不平衡时间序列分类问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法假设数据分布平衡，在不平衡分布下会忽略少数类；传统过采样方法依赖线性插值，难以保持时间动态性和生成多样性样本

Method: 使用强类型遗传编程进化多样化的高质量时间序列，通过结合时域和频域特征的适应度函数指导进化过程

Result: 在不平衡时间序列数据集上的实验表明，Evo-TFS优于现有过采样方法，显著提升了时域和频域分类器的性能

Conclusion: Evo-TFS通过进化方法结合时域和频域特征，有效解决了不平衡时间序列分类问题，生成了高质量、多样化的少数类样本

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [158] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: ARISE利用大语言模型的外部语义知识增强分类数据聚类，通过LLM描述属性值构建语义感知表示，结合原始数据探索语义显著簇，在8个基准数据集上相比7个代表性方法提升19-27%


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类面临相似性度量的核心挑战，属性值缺乏固有顺序或距离，传统方法将值视为等距造成语义鸿沟，当样本有限时基于共现模式的关系推断不可靠，导致聚类质量下降

Method: ARISE利用大语言模型的外部语义知识构建语义感知表示，LLM描述属性值进行表示增强，将LLM增强的嵌入与原始数据结合，探索语义显著的聚类结构

Result: 在8个基准数据集上的实验表明，相比7个代表性对比方法，ARISE取得了19-27%的性能提升

Conclusion: ARISE通过整合LLM的外部语义知识有效解决了分类数据聚类中的语义鸿沟问题，显著提升了聚类质量，特别是在样本有限的情况下

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [159] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 使用多类型严肃游戏框架结合机器学习预测软件开发岗位适合度，通过游戏行为数据而非传统问卷评估人格特质，达到97%精度和94%准确率


<details>
  <summary>Details</summary>
Motivation: 传统职业评估中的人格测试问卷存在响应偏差、疲劳和故意扭曲等问题，需要一种更客观、可扩展且无偏见的替代方案。游戏化评估通过捕捉游戏过程中的隐性行为信号，为职业适合度评估提供了新途径。

Method: 1) 通过文献综述和软件工程师实证研究确定与开发相关的性格和行为特质；2) 设计定制移动游戏来激发问题解决、规划、适应性、坚持性、时间管理和信息寻求等行为；3) 收集细粒度游戏事件数据；4) 采用两阶段建模策略，仅使用游戏行为特征预测适合度

Result: 模型达到最高97%的精确度和94%的准确率。行为分析显示，适合的候选人表现出独特的游戏模式：解谜游戏获胜更多、完成更多侧挑战、更频繁浏览菜单、暂停/重试/放弃行为更少

Conclusion: 游戏过程中捕捉的隐性行为痕迹能够有效预测软件开发适合度，无需显性人格测试。严肃游戏作为职业评估工具具有可扩展性、趣味性和较少偏见等优势，是传统问卷的有前景替代方案

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [160] [Sparse Bayesian Message Passing under Structural Uncertainty](https://arxiv.org/abs/2601.01207)
*Yoonhyuk Choi,Jiho Choi,Chanran Kim,Yumin Lee,Hawon Shin,Yeowon Jeon,Minjeong Kim,Jiwoo Kang*

Main category: cs.LG

TL;DR: 提出一种通过建模有符号邻接矩阵后验分布来处理异质图和结构噪声的半监督学习方法，结合稀疏有符号消息传递网络，在异质图基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界图中的半监督学习常面临异质性问题，现有图神经网络要么依赖固定邻接结构，要么通过正则化处理结构噪声，缺乏对结构不确定性的显式建模。

Method: 建模有符号邻接矩阵的后验分布（边可为正、负或缺失），提出稀疏有符号消息传递网络，结合后验边缘化和稀疏有符号消息聚合，从贝叶斯角度提供理论解释。

Result: 在合成和真实世界结构噪声下的异质图基准测试中，该方法优于强基线模型。

Conclusion: 通过显式建模结构不确定性并采用稀疏有符号消息传递，为处理边噪声和异质性提供了原则性方法，在异质图学习任务中表现出色。

Abstract: Semi-supervised learning on real-world graphs is frequently challenged by heterophily, where the observed graph is unreliable or label-disassortative. Many existing graph neural networks either rely on a fixed adjacency structure or attempt to handle structural noise through regularization. In this work, we explicitly capture structural uncertainty by modeling a posterior distribution over signed adjacency matrices, allowing each edge to be positive, negative, or absent. We propose a sparse signed message passing network that is naturally robust to edge noise and heterophily, which can be interpreted from a Bayesian perspective. By combining (i) posterior marginalization over signed graph structures with (ii) sparse signed message aggregation, our approach offers a principled way to handle both edge noise and heterophily. Experimental results demonstrate that our method outperforms strong baseline models on heterophilic benchmarks under both synthetic and real-world structural noise.

</details>


### [161] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

TL;DR: 提出混合贝叶斯-保形框架，结合贝叶斯层次随机森林与分组感知保形校准，为临床决策提供分布自由覆盖保证和风险自适应精度


<details>
  <summary>Details</summary>
Motivation: 临床决策需要同时满足分布自由覆盖保证和风险自适应精度的不确定性量化，现有方法无法同时满足这两个要求

Method: 混合贝叶斯-保形框架：集成贝叶斯层次随机森林与分组感知保形校准，使用后验不确定性加权保形分数，同时保持严格的覆盖有效性

Result: 在61,538例入院患者、3,793家美国医院和4个地区评估中，方法达到目标覆盖（94.3% vs 95%目标），低不确定性病例区间宽度减少21%，高风险预测适当加宽；纯贝叶斯不确定性严重欠覆盖（14.1%）

Conclusion: 该框架支持风险分层临床协议、高效资源规划和高置信度预测，为不确定病例提供增强监督的保守分配，为多样化医疗环境提供不确定性感知决策支持

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [162] [The Dependency Divide: An Interpretable Machine Learning Framework for Profiling Student Digital Satisfaction in the Bangladesh Context](https://arxiv.org/abs/2601.01231)
*Md Muhtasim Munif Fahim,Humyra Ankona,Md Monimul Huq,Md Rezaul Karim*

Main category: cs.LG

TL;DR: 研究提出"依赖鸿沟"框架，发现在基础设施脆弱环境下，高度投入的学生反而因依赖数字平台而更易受网络故障影响，挑战了"投入越多越好"的传统假设。


<details>
  <summary>Details</summary>
Motivation: 传统数字鸿沟框架无法解释在资源受限环境中，拥有相似网络连接的学生对数字学习平台的满意度差异。本研究旨在探索这些差异背后的机制，特别是高度投入学生可能面临的脆弱性。

Method: 采用三阶段分析方法：1) 使用稳定性验证的K-prototypes聚类识别学生档案；2) 构建档案特异性随机森林模型，结合SHAP和ALE分析确定满意度驱动因素；3) 使用倾向得分匹配进行正式交互分析，检验依赖鸿沟假设。

Result: 识别出三类学生档案：随意投入(58%)、高效学习者(35%)和超投入(7%)。发现教育设备使用时间与网络可靠性之间存在显著交互作用(β=0.033, p=0.028)，证实依赖鸿沟存在。超投入学生尽管拥有复杂数字工作流程，却表现出最大脆弱性。针对性可靠性改进对高依赖用户的回报是统一干预的2.06倍。

Conclusion: 在基础设施脆弱环境中，数字能力可能成为负担。数字转型政策应优先保障高依赖用户的可靠性，建立应急系统，并教育学生认识依赖风险，而非一味推广数字参与。

Abstract: Background: While digital access has expanded rapidly in resource-constrained contexts, satisfaction with digital learning platforms varies significantly among students with seemingly equal connectivity. Traditional digital divide frameworks fail to explain these variations.
  Purpose: This study introduces the "Dependency Divide", a novel framework proposing that highly engaged students become conditionally vulnerable to infrastructure failures, challenging assumptions that engagement uniformly benefits learners in post-access environments.
  Methods: We conducted a cross-sectional study of 396 university students in Bangladesh using a three-stage analytical approach: (1) stability-validated K-prototypes clustering to identify student profiles, (2) profile-specific Random Forest models with SHAP and ALE analysis to determine satisfaction drivers, and (3) formal interaction analysis with propensity score matching to test the Dependency Divide hypothesis.
  Results: Three distinct profiles emerged: Casually Engaged (58%), Efficient Learners (35%), and Hyper-Engaged (7%). A significant interaction between educational device time and internet reliability (\b{eta} = 0.033, p = 0.028) confirmed the Dependency Divide: engagement increased satisfaction only when infrastructure remained reliable. Hyper-Engaged students showed greatest vulnerability despite or because of their sophisticated digital workflows. Policy simulations demonstrated that targeted reliability improvements for high-dependency users yielded 2.06 times greater returns than uniform interventions.
  Conclusions: In fragile infrastructure contexts, capability can become liability. Digital transformation policies must prioritize reliability for dependency-prone users, establish contingency systems, and educate students about dependency risks rather than uniformly promoting engagement.

</details>


### [163] [Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions](https://arxiv.org/abs/2601.01237)
*Abidemi Koledoye,Chinemerem Unachukwu,Gold Nwobu,Hasin Rana*

Main category: cs.LG

TL;DR: 该论文比较了Mamba SSM和LLaMA Transformer在长上下文序列建模中的性能，使用治疗会话作为测试案例，评估计算效率和表征效率


<details>
  <summary>Details</summary>
Motivation: 状态空间模型(SSMs)作为Transformer的替代方案，在长上下文序列建模中具有线性计算复杂度优势，但需要系统比较其在实际应用中的表现

Method: 使用治疗会话作为测试案例，从两个维度评估：计算效率（内存使用和推理速度，512-8192 tokens）和表征效率（隐藏状态动态和注意力模式分析）

Result: 研究结果为长上下文应用提供了实用见解，明确了SSMs相对于Transformers的优势条件

Conclusion: 该研究为从业者提供了选择SSMs还是Transformers的具体指导，建立了SSMs优于Transformers的精确条件

Abstract: State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.

</details>


### [164] [Accelerated Full Waveform Inversion by Deep Compressed Learning](https://arxiv.org/abs/2601.01268)
*Maayan Gelboim,Amir Adler,Mauricio Araya-Polo*

Main category: cs.LG

TL;DR: 提出一种通过深度神经网络和压缩学习来降低全波形反演数据维度的分层选择方法，仅使用10%数据即可超越随机采样效果


<details>
  <summary>Details</summary>
Motivation: 工业级全波形反算需要太字节级数据存储，计算成本过高，限制了复杂地下情况分析和多场景探索

Method: 使用带二值化感知层的深度神经网络从大量地下模型中学习压缩的采集布局，通过自编码器计算潜在表示，再用K-means聚类选择最相关数据

Result: 该方法在仅使用10%数据的2D FWI中始终优于随机数据采样，为大规模3D反演加速铺平道路

Conclusion: 提出的分层选择方法能有效降低FWI计算成本，为工业应用提供可行的数据降维解决方案

Abstract: We propose and test a method to reduce the dimensionality of Full Waveform Inversion (FWI) inputs as computational cost mitigation approach. Given modern seismic acquisition systems, the data (as input for FWI) required for an industrial-strength case is in the teraflop level of storage, therefore solving complex subsurface cases or exploring multiple scenarios with FWI become prohibitive. The proposed method utilizes a deep neural network with a binarized sensing layer that learns by compressed learning a succinct but consequential seismic acquisition layout from a large corpus of subsurface models. Thus, given a large seismic data set to invert, the trained network selects a smaller subset of the data, then by using representation learning, an autoencoder computes latent representations of the data, followed by K-means clustering of the latent representations to further select the most relevant data for FWI. Effectively, this approach can be seen as a hierarchical selection. The proposed approach consistently outperforms random data sampling, even when utilizing only 10% of the data for 2D FWI, these results pave the way to accelerating FWI in large scale 3D inversion.

</details>


### [165] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

TL;DR: 本文通过比较上下文学习与监督分类器的行为，探究LLMs如何工作，发现当演示相关性高时，LLMs行为类似kNN分类器，相关性低时LLMs表现更好


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习在实践中有效，但其工作机制尚不清楚。本文旨在通过比较LLMs与监督分类器的行为来深入理解上下文学习的工作原理

Method: 使用文本分类作为用例，在6个数据集和3个LLMs上，比较上下文学习与基于梯度下降和k近邻的监督分类器的行为

Result: 当演示相关性高时，LLMs行为与监督分类器相似，且更接近kNN而非逻辑回归；当演示相关性低时，LLMs表现优于这些分类器，因为LLMs可以依赖其参数记忆

Conclusion: 上下文学习机制更类似于kNN而非梯度下降，LLMs在演示相关性低时的优势源于其参数记忆能力，这为理解上下文学习提供了实证证据

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [166] [Sobolev Approximation of Deep ReLU Network in Log-weighted Barron Space](https://arxiv.org/abs/2601.01295)
*Changhoon Song,Seungchan Ko,Youngjoon Hong*

Main category: cs.LG

TL;DR: 本文提出对数加权Barron空间，比传统Barron空间要求更弱的正则性条件，证明了深度ReLU网络在该空间中的逼近能力，阐明了深度如何降低高效表示所需的正则性要求。


<details>
  <summary>Details</summary>
Motivation: 传统Barron空间理论虽然解释了神经网络对高维函数的逼近能力，但仍需比Sobolev空间更强的正则性条件，且现有深度敏感结果常假设约束条件如sL≤1/2。需要建立更弱的正则性空间来更精确解释深度架构的实际性能。

Method: 1. 引入对数加权Barron空间B^log，其正则性要求比任何s>0的B^s空间都弱；2. 研究该空间的嵌入性质并通过Rademacher复杂度进行统计分析；3. 证明B^log中函数可由深度ReLU网络逼近，并给出显式的深度依赖关系；4. 定义B^{s,log}空间族，建立H^1范数下的逼近界，并确定保持这些速率的深度尺度。

Result: 1. 对数加权Barron空间B^log比传统Barron空间B^s(s>0)要求更弱的正则性；2. 深度ReLU网络可以在该空间中实现有效逼近；3. 建立了明确的深度依赖逼近界；4. 确定了保持逼近速率的深度尺度，阐明了深度降低正则性要求的机制。

Conclusion: 本文提出的对数加权Barron空间为深度神经网络在高维问题中的优异表现提供了更精确的理论解释，表明深度架构可以在更弱的正则性条件下实现高效表示，超越了经典Barron空间的限制。

Abstract: Universal approximation theorems show that neural networks can approximate any continuous function; however, the number of parameters may grow exponentially with the ambient dimension, so these results do not fully explain the practical success of deep models on high-dimensional data. Barron space theory addresses this: if a target function belongs to a Barron space, a two-layer network with $n$ parameters achieves an $O(n^{-1/2})$ approximation error in $L^2$. Yet classical Barron spaces $\mathscr{B}^{s+1}$ still require stronger regularity than Sobolev spaces $H^s$, and existing depth-sensitive results often assume constraints such as $sL \le 1/2$. In this paper, we introduce a log-weighted Barron space $\mathscr{B}^{\log}$, which requires a strictly weaker assumption than $\mathscr{B}^s$ for any $s>0$. For this new function space, we first study embedding properties and carry out a statistical analysis via the Rademacher complexity. Then we prove that functions in $\mathscr{B}^{\log}$ can be approximated by deep ReLU networks with explicit depth dependence. We then define a family $\mathscr{B}^{s,\log}$, establish approximation bounds in the $H^1$ norm, and identify maximal depth scales under which these rates are preserved. Our results clarify how depth reduces regularity requirements for efficient representation, offering a more precise explanation for the performance of deep architectures beyond the classical Barron setting, and for their stable use in high-dimensional problems used today.

</details>


### [167] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

TL;DR: Argus框架将高维数据流中的分布漂移检测重新定义为在数据流形固定空间划分上跟踪局部统计量，通过Voronoi划分实现正交变换不变性、O(N)复杂度、漂移传播图论分析，以及通过乘积量化扩展到500+维度。


<details>
  <summary>Details</summary>
Motivation: 高维数据流中的分布漂移检测面临三大挑战：全局比较方法扩展性差，基于投影的方法丢失几何结构，重新聚类方法存在身份不稳定性。需要一种既能保持高维结构又计算高效的方法。

Method: Argus框架将漂移检测重新定义为在数据流形的固定空间划分上跟踪局部统计量。使用规范正交基上的Voronoi划分实现正交变换不变性，通过图论方法分析漂移传播模式，采用乘积量化划分将高维空间分解为独立子空间并聚合漂移信号。

Result: 理论证明Voronoi划分在正交变换下保持漂移度量不变性，实现每快照O(N)复杂度并提供细胞级空间定位，实验验证框架能正确识别坐标旋转下的漂移而现有方法会产生误报。

Conclusion: Argus为分布监测提供了有原则的几何基础，在保持高维结构的同时避免了成对比较的计算负担，通过固定空间划分实现了高效、可解释的漂移检测。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [168] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: Warp Cortex是一个异步多智能体LLM框架，通过解耦智能体逻辑与物理内存，将内存复杂度从O(N*L)降至O(1)权重和O(N*k)上下文，实现在消费级硬件上支持百万级智能体并行推理。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架存在线性内存扩展问题，导致"系统2"并行推理在消费级硬件上不可行。需要解决内存瓶颈以实现大规模智能体认知扩展。

Method: 采用异步架构，通过Singleton权重共享和基于拓扑数据分析的Topological Synapse技术，将KV缓存视为潜在空间中的点云，应用witness-complex稀疏化来保持上下文流形的持久同调特征。引入非侵入式KV缓存更新机制Referential Injection。

Result: 在单张NVIDIA RTX 4090上，实现了100个并发智能体仅占用2.2GB显存，理论容量超过1000个智能体（计算延迟成为瓶颈前）。内存复杂度显著降低。

Conclusion: Warp Cortex通过创新的内存优化架构，解决了多智能体LLM框架的内存扩展瓶颈，为在消费级硬件上实现大规模智能体并行推理提供了可行方案。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [169] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

TL;DR: 本文提出Muon++，一种改进的矩阵优化器，能在整个训练过程中可靠地保证μ参数化所需的谱条件，无需显式权重谱归一化，降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: μ参数化(μP)为LLM训练提供了理论基础，但现有研究在保证矩阵优化器(如Muon)满足μP谱条件方面存在不足：要么无法保证整个训练过程的谱条件，要么需要重复的谱归一化导致计算开销大。

Method: 提出Muon++，核心洞察是对于中等规模模型，仅需在优化器更新层面维持谱控制即可保持μP兼容的缩放，无需显式权重谱归一化。还首次引入数据依赖效应的自适应谱条件。

Result: Muon++能在整个训练过程中可靠地保证μP所需的谱条件，弥合了μP理论承诺与矩阵优化器实际部署之间的差距，降低了计算开销。

Conclusion: 该工作为矩阵优化器在长时程LLM训练中的实际部署提供了可行的解决方案，通过仅控制更新层面的谱条件而非权重本身，实现了μP兼容的训练。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [170] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: SWH是一种混合架构，通过并行全局分支（利用卷积定理建模长程衰减动态）和局部分支（滑动窗口注意力）来平衡计算效率和表达能力，实现线性扩展至长序列。


<details>
  <summary>Details</summary>
Motivation: 将序列建模扩展到极长上下文时，需要在计算效率和表示表达能力之间取得平衡。Transformer虽然通过注意力机制提供精确检索，但其二次复杂度限制了在长序列任务中的应用。

Method: 提出Spectral-Window Hybrid (SWH)架构，将序列建模解耦为两个并行流：1) 全局分支利用卷积定理在O(T log T)时间内建模长程衰减动态；2) 局部分支采用滑动窗口注意力处理有限上下文内的token交互。通过聚合这些表示，避免了全局注意力的计算瓶颈。

Result: SWH在短上下文上能达到标准Transformer的困惑度，同时能够高效地线性扩展到长序列。

Conclusion: SWH架构通过结合全局频谱建模和局部窗口注意力，在保持局部精度的同时避免了全局注意力的计算瓶颈，为长序列建模提供了有效的解决方案。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [171] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

TL;DR: GM-MLG：基于图-基序特征融合和多标签生成的开放式药物不良反应预测新范式，将多标签分类转化为基于Transformer解码器的多标签生成，显著提升预测性能并扩展预测空间


<details>
  <summary>Details</summary>
Motivation: 当前药物不良反应预测方法面临数据稀缺导致的冷启动问题、封闭标签集以及标签依赖关系建模不足等挑战，限制了预测能力和应用范围

Method: 1) 构建原子级、局部分子级（通过BRICS算法动态提取精细基序）和全局分子级的双图表示架构；2) 将ADR预测从多标签分类转化为基于Transformer解码器的多标签生成，将ADR标签视为离散标记序列，使用位置嵌入显式捕获标签依赖关系，通过自回归解码动态扩展预测空间

Result: GM-MLG实现了最高38%的性能提升，平均增益20%，将预测空间从200种扩展到超过10,000种。通过逆合成基序分析阐明了ADR与基序之间的非线性构效关系

Conclusion: GM-MLG提出了一种创新的开放式ADR预测范式，通过图-基序特征融合和多标签生成方法有效解决了现有方法的局限性，为药物安全性系统风险降低提供了可解释的创新支持

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [172] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 提出基于因子分解机与二次优化退火(FMQA)的高阶上位性检测方法，将上位性检测转化为黑盒优化问题，显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 高阶上位性检测面临组合爆炸的计算挑战，传统MDR方法在基因位点数量或交互阶数增加时计算不可行

Method: 将上位性检测定义为黑盒优化问题，使用因子分解机结合二次优化退火(FMQA)，以MDR计算的分类错误率作为目标函数

Result: 在模拟病例对照数据集上成功识别预设的高阶上位性，在不同交互阶数和基因位点数量下均能有效发现真实上位性

Conclusion: 该方法对高阶上位性检测有效且计算高效，能在有限迭代次数内完成检测

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [173] [Towards LLM-enabled autonomous combustion research: A literature-aware agent for self-corrective modeling workflows](https://arxiv.org/abs/2601.01357)
*Ke Xiao,Haoze Zhang,Runze Mao,Han Li,Zhi X. Chen*

Main category: cs.LG

TL;DR: FlamePilot是一个专门为燃烧建模设计的LLM智能体，能够自动执行CFD仿真工作流，从科学文献中学习并指导仿真设置，在基准测试中超越了现有智能体的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在复杂科学领域（如燃烧建模）的应用存在关键缺口，需要将领域文献知识与专业工具（如CFD代码）的执行能力无缝集成，以实现实用的AI辅助研究。

Method: FlamePilot采用基于原子工具的架构，确保在OpenFOAM和DeepFlame等框架中稳健设置和执行复杂仿真。系统能够从科学文献中提取关键信息，指导从初始设置到优化结果的整个仿真流程。

Result: 在公开基准测试中，FlamePilot获得了完美的1.0可执行性分数和0.438的成功率，超越了先前最佳智能体报告的0.625和0.250分数。在MILD燃烧仿真实例研究中，系统能够自主将研究论文转化为配置仿真、执行仿真、后处理结果、提出基于证据的改进建议，并在最少人工干预下管理多步骤参数研究直至收敛。

Conclusion: FlamePilot通过透明可解释的范式，为AI赋能的燃烧建模建立了基础框架，促进了智能体管理工作流编排、研究人员专注于高层次分析的协作伙伴关系。

Abstract: The rapid evolution of large language models (LLMs) is transforming artificial intelligence into autonomous research partners, yet a critical gap persists in complex scientific domains such as combustion modeling. Here, practical AI assistance requires the seamless integration of domain literature knowledge with robust execution capabilities for expertise-intensive tools such as computational fluid dynamics (CFD) codes. To bridge this gap, we introduce FlamePilot, an LLM agent designed to empower combustion modeling research through automated and self-corrective CFD workflows. FlamePilot differentiates itself through an architecture that leverages atomic tools to ensure the robust setup and execution of complex simulations in both OpenFOAM and extended frameworks such as DeepFlame. The system is also capable of learning from scientific articles, extracting key information to guide the simulation from initial setup to optimized results. Validation on a public benchmark shows FlamePilot achieved a perfect 1.0 executability score and a 0.438 success rate, surpassing the prior best reported agent scores of 0.625 and 0.250, respectively. Furthermore, a detailed case study on Moderate or Intense Low-oxygen Dilution (MILD) combustion simulation demonstrates its efficacy as a collaborative research copilot, where FlamePilot autonomously translated a research paper into a configured simulation, conducted the simulation, post-processed the results, proposed evidence-based refinements, and managed a multi-step parameter study to convergence under minimal human intervention. By adopting a transparent and interpretable paradigm, FlamePilot establishes a foundational framework for AI-empowered combustion modeling, fostering a collaborative partnership where the agent manages workflow orchestration, freeing the researcher for high-level analysis.

</details>


### [174] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

TL;DR: 提出基于f-GAN框架的因果发现方法，从存在未测量混杂因素的数据中学习因果结构，将结构学习问题转化为最小化贝叶斯自由能量，并证明其等价于最小化真实数据分布与模型生成分布之间的f-散度。


<details>
  <summary>Details</summary>
Motivation: 从存在未测量混杂因素的数据中进行因果发现是一个具有挑战性的问题。传统方法通常依赖于特定的权重值假设，而本文旨在开发一种独立于具体权重值的因果结构学习方法。

Method: 基于f-GAN框架，将因果结构学习问题重新表述为最小化贝叶斯自由能量。证明该问题等价于最小化真实数据分布与模型生成分布之间的f-散度。使用f-GAN框架将目标转化为最小-最大对抗优化问题，并在离散图空间中使用Gumbel-Softmax松弛实现梯度搜索。

Result: 该方法能够从存在未测量混杂因素的数据中学习因果结构，且不依赖于特定的权重值假设。通过对抗优化和Gumbel-Softmax松弛，实现了在离散图空间中的有效梯度搜索。

Conclusion: 提出的基于f-GAN框架的方法为从存在未测量混杂因素的数据中进行因果发现提供了一种有效的解决方案，通过将结构学习问题转化为对抗优化问题，实现了独立于具体权重值的因果结构学习。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [175] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

TL;DR: 提出轻量级两阶段框架，无需训练即可预测深度学习模型性能，并能指导架构选择和检测数据质量问题


<details>
  <summary>Details</summary>
Motivation: 深度学习模型架构选择通常依赖试错过程，耗时耗力且难以自动化。现有性能预测方法要么需要部分训练，要么计算开销大，缺乏通用性

Method: 两阶段框架：第一阶段基于数据集可测量属性预测基线性能；第二阶段结合模型架构和超参数细节调整估计。框架可跨数据集和模型类型泛化

Result: 框架不仅能预测模型性能，还能指导架构选择、预处理流程，并在训练前检测潜在问题数据集。数据集方差等特征可作为数据质量的早期指标

Conclusion: 提出的轻量级框架为深度学习模型选择和性能预测提供了高效、通用的解决方案，减少了试错成本，并能提供数据质量洞察

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [176] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

TL;DR: 提出SaMPFA框架，通过局部拓扑切片采样和多任务图学习，提升电力潮流分析模型对拓扑变化的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发具有强拓扑适应性的深度学习模型对电力潮流分析具有重要实践意义，需要增强模型在可变系统规模下的性能，并提高支路功率预测的鲁棒性。

Method: 1) 提出局部拓扑切片(LTS)采样技术，从完整电网中提取不同规模的子图，增强模型的跨尺度学习能力；2) 设计无参考多任务图学习(RMGL)模型，预测母线电压和支路功率而非相角，避免误差放大并引导模型学习相角差的物理关系；3) 损失函数中加入额外项，鼓励模型捕捉角度差和功率传输的物理模式。

Result: 在IEEE 39节点系统和实际省级电网上的仿真表明，该模型在可变系统规模下实现了优越的适应性和泛化能力，准确率分别提高了4.47%和36.82%。

Conclusion: SaMPFA框架通过局部拓扑切片和多任务学习，有效提升了电力潮流分析模型对拓扑变化的适应性，避免了传统相角预测的误差放大问题，在可变系统规模下表现出优异的性能。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [177] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

TL;DR: 提出GDME框架，一种基于图的无监督在线时间序列异常检测方法，通过动态模型池和图结构进行模型集成，能有效处理异构流数据


<details>
  <summary>Details</summary>
Motivation: 工业系统中流数据量不断增加，在线异常检测变得至关重要。现有方法多为离线设计或难以有效处理异构流数据，需要能适应快速演化数据模式的在线检测框架

Method: GDME框架维护动态模型池，持续更新（修剪表现不佳模型并引入新模型）。使用动态图结构表示模型间关系，通过社区检测选择合适子集进行集成。利用图结构变化监测概念漂移，适应流数据演化

Result: 在7个异构时间序列数据集上的实验表明，GDME优于现有在线异常检测方法，性能提升高达24%。其集成策略相比单个模型和平均集成具有更优检测性能，计算效率具有竞争力

Conclusion: GDME框架通过动态模型池和图结构集成，有效解决了在线时间序列异常检测中处理异构流数据的挑战，在检测性能和适应性方面表现出色

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [178] [A Depth Hierarchy for Computing the Maximum in ReLU Networks via Extremal Graph Theory](https://arxiv.org/abs/2601.01417)
*Itay Safran*

Main category: cs.LG

TL;DR: 该论文证明了ReLU神经网络计算d个实数最大值函数时存在深度层次结构：对于3≤k≤log₂(log₂(d))的深度，需要宽度Ω(d^{1+1/(2^{k-2}-1)})才能表示最大值函数，这是首个针对该基本算子在深度k≥3时的无条件超线性下界。


<details>
  <summary>Details</summary>
Motivation: 研究ReLU神经网络精确计算最大值函数的能力，探索深度与宽度之间的权衡关系。最大值函数虽然看似简单，但其非可微的几何结构可能带来固有的计算复杂性，理解这种复杂性有助于揭示神经网络的表达能力限制。

Method: 采用组合论证方法，将最大值函数的非可微脊线与计算网络第一隐藏层诱导的图中的团相关联。利用极值图论中的Turán定理证明，足够窄的网络无法捕获最大值函数的非线性特性。

Result: 证明了对于3≤k≤log₂(log₂(d))的深度，表示d个实数最大值函数需要宽度Ω(d^{1+1/(2^{k-2}-1)})，这是首个针对深度k≥3时的无条件超线性下界，即使深度随d变化也成立。

Conclusion: 最大值函数虽然简单，但其非可微分超平面的几何结构带来了固有的复杂性。该研究为证明深度神经网络下界提供了新方法，揭示了深度与宽度在表示基本算子时的权衡关系。

Abstract: We consider the problem of exact computation of the maximum function over $d$ real inputs using ReLU neural networks. We prove a depth hierarchy, wherein width $Ω\big(d^{1+\frac{1}{2^{k-2}-1}}\big)$ is necessary to represent the maximum for any depth $3\le k\le \log_2(\log_2(d))$. This is the first unconditional super-linear lower bound for this fundamental operator at depths $k\ge3$, and it holds even if the depth scales with $d$. Our proof technique is based on a combinatorial argument and associates the non-differentiable ridges of the maximum with cliques in a graph induced by the first hidden layer of the computing network, utilizing Turán's theorem from extremal graph theory to show that a sufficiently narrow network cannot capture the non-linearities of the maximum. This suggests that despite its simple nature, the maximum function possesses an inherent complexity that stems from the geometric structure of its non-differentiable hyperplanes, and provides a novel approach for proving lower bounds for deep neural networks.

</details>


### [179] [Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance](https://arxiv.org/abs/2601.01424)
*Akshay Sasi,Malavika Pradeep,Nusaibah Farrukh,Rahul Venugopal,Elizabeth Sherly*

Main category: cs.LG

TL;DR: ECG信号可替代EEG用于认知负荷监测，通过跨模态XGBoost框架将ECG特征映射到EEG认知空间，实现仅用ECG的准确分类。


<details>
  <summary>Details</summary>
Motivation: 虽然EEG是评估心理负荷的金标准，但其便携性有限，限制了实际应用。广泛可用的可穿戴ECG设备提供了实用的替代方案，需要研究ECG是否能可靠反映认知负荷并替代EEG指标。

Method: 收集工作记忆和被动听力任务的多模态数据，提取ECG时域HRV指标和Catch22描述符，对应EEG频谱和Catch22特征。提出跨模态XGBoost框架，将ECG特征投影到EEG代表的认知空间，实现仅用ECG进行工作负荷推断。

Result: ECG衍生的投影能显著捕捉认知状态变化，为准确分类提供良好支持，证明ECG作为可解释、实时、可穿戴的日常认知监测解决方案的可行性。

Conclusion: ECG可作为EEG的有效替代方案，用于认知负荷监测，为日常认知监测提供了实用、可穿戴的解决方案。

Abstract: Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.

</details>


### [180] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

TL;DR: BSZO是一种基于贝叶斯子空间的零阶优化方法，通过卡尔曼滤波结合多个扰动方向的有限差分信息，相比传统ZO方法提高了收敛速度，在保持接近推理基线内存使用的同时，在多个LLM上实现了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法依赖随机扰动的一步梯度估计，限制了优化效率。需要一种能够结合多个扰动方向信息、提高梯度估计质量的方法，同时保持内存效率优势。

Method: 提出BSZO方法：将每个有限差分测量视为噪声观测，通过卡尔曼滤波构建投影梯度的后验分布，使用贝叶斯推断更新梯度估计，并采用基于残差的自适应机制调整扰动尺度。

Result: 理论分析显示BSZO比标准ZO方法收敛速度提高k/γ倍。在RoBERTa、Mistral和OPT模型上的实验表明，BSZO优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上获得最高6.67%的绝对平均改进，内存使用仅为MeZO的1.00-1.08倍。

Conclusion: BSZO通过贝叶斯方法有效结合多个扰动方向信息，显著提升了零阶优化的效率和性能，同时保持了内存效率优势，为大规模语言模型的高效微调提供了新方法。

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [181] [Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD](https://arxiv.org/abs/2601.01465)
*Ze Peng,Jian Zhang,Yisen Wang,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 该论文提出了一种新的信息论泛化界，能够更好地利用SGD的平坦性偏好，在数值上更紧且能正确反映平坦性改善时的泛化提升。


<details>
  <summary>Details</summary>
Motivation: 现有信息论泛化界虽然理论上数据依赖和算法依赖，但实际上未能充分捕捉SGD的平坦性偏好对泛化的影响，导致在平坦性改善时无法正确反映泛化提升，且数值上较松。

Method: 提出"全知轨迹"技术，推导出更充分利用平坦性的信息论泛化界，该界表明当最终权重协方差的大方差方向在损失景观中具有小局部曲率时，学习模型泛化更好。

Result: 在深度神经网络上的实验表明，新界不仅正确反映了平坦性改善时的泛化提升，数值上也更紧。应用于凸-Lipschitz-有界问题的梯度下降极小极大超额风险时，将代表性信息论界的Ω(1)率改进为O(1/√n)。

Conclusion: 通过"全知轨迹"技术提出的新信息论泛化界成功利用了SGD的平坦性偏好，解决了现有界无法捕捉平坦性影响的问题，同时暗示了可以绕过记忆化-泛化权衡。

Abstract: Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called "omniscient trajectory". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.

</details>


### [182] [Accelerating Storage-Based Training for Graph Neural Networks](https://arxiv.org/abs/2601.01473)
*Myung-Hwan Jang,Jeong-Min Park,Yunyong Ko,Sang-Wook Kim*

Main category: cs.LG

TL;DR: AGNES是一个存储式GNN训练框架，通过块级存储I/O处理和超批次处理技术，解决了大规模图神经网络训练中的存储I/O瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有存储式GNN训练方法在处理大规模图时面临严重的数据准备瓶颈，主要问题在于大量小规模存储I/O操作效率低下，无法充分利用高性能存储设备的带宽。

Method: 提出AGNES框架：1）采用块级存储I/O处理技术，将多个小I/O请求合并为更大的块级操作；2）基于真实图特性的超批次处理策略，进一步优化每个存储I/O的效率。

Result: 在五个真实世界图数据集上的实验表明，AGNES在性能上持续优于四种最先进的方法，比最佳竞争对手快达4.1倍。

Conclusion: AGNES通过创新的存储I/O优化技术，有效解决了大规模GNN训练中的存储瓶颈问题，为单机处理网络规模图提供了高效解决方案。

Abstract: Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \textsf{AGNES}, that employs a method of \textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \textsf{AGNES} employs a simple yet effective strategy, \textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.

</details>


### [183] [Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts](https://arxiv.org/abs/2601.01475)
*Ruofeng Yang,Yongcan Li,Bo Jiang,Cheng Chen,Shuai Li*

Main category: cs.LG

TL;DR: 提出MoLR-MoG建模方法，将数据建模为K个线性子空间的并集，每个子空间采用混合高斯隐变量，解决了传统扩散模型在高维数据中的维度诅咒问题，实现了更好的生成质量和更快的优化收敛。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在高维数据中面临维度诅咒问题（误差随维度D呈n^{-1/D}衰减），且现有方法虽然考虑了数据的多流形结构，但使用高斯隐变量无法捕捉隐流形的多模态特性。

Method: 提出混合子空间-低秩混合高斯（MoLR-MoG）建模：将目标数据建模为K个线性子空间的并集，每个子空间采用混合高斯隐变量（n_k个模态，维度d_k）。对应的得分函数具有混合专家（MoE）结构，能捕捉多模态信息和非线性特性。

Result: 1. 实验表明MoE-latent MoG NN的生成结果优于MoE-latent Gaussian score，且与参数多10倍的MoE-latent Unet性能相当；2. 理论分析得到R^4√(Σn_k)√(Σn_kd_k)/√n的估计误差，摆脱了维度诅咒；3. 证明了MoLR-MoG建模下的优化收敛保证。

Conclusion: MoLR-MoG建模合理且适用于真实世界数据，解释了为什么扩散模型只需少量训练样本和快速优化过程就能取得优异性能，通过利用数据结构摆脱了维度诅咒问题。

Abstract: Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\sqrt{Σ_{k=1}^Kn_k}\sqrt{Σ_{k=1}^Kn_kd_k}/\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.

</details>


### [184] [SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines](https://arxiv.org/abs/2601.01484)
*Itai Morad,Nir Shlezinger,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 论文从贝叶斯视角分析知识蒸馏，证明使用贝叶斯分类概率作为教师输出能降低方差、提升收敛稳定性，并实验验证贝叶斯教师模型能让学生获得更高准确率和更稳定收敛。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏虽然经验上成功，但理论基础不足。本文旨在从贝叶斯角度分析知识蒸馏的收敛行为，特别是研究使用精确贝叶斯分类概率与噪声近似时的差异，为选择更好的教师模型提供理论依据。

Method: 采用贝叶斯视角分析知识蒸馏，研究两种监督方式：1）教师提供精确贝叶斯分类概率；2）使用噪声近似的贝叶斯分类概率。理论分析SGD收敛行为，并通过实验验证贝叶斯深度学习模型作为教师的效果。

Result: 理论分析表明：学习贝叶斯分类概率能降低方差、移除收敛边界中的邻域项。噪声水平影响泛化和准确性。实验证明：从贝叶斯教师蒸馏的学生准确率最高提升4.27%，收敛噪声降低30%，比从确定性教师蒸馏表现更好。

Conclusion: 贝叶斯视角为知识蒸馏提供了理论解释，贝叶斯教师模型能提供更好的贝叶斯分类概率估计，从而让学生获得更高准确率和更稳定收敛。建议在知识蒸馏中使用贝叶斯深度学习模型作为教师。

Abstract: Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.

</details>


### [185] [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)
*Yijie Zhou,Shi Pu*

Main category: cs.LG

TL;DR: 提出OLDSGD方法，通过计算-通信重叠加速去中心化训练，减少网络空闲时间，保持与Local SGD相同的平均更新，同时提升实际运行时间。


<details>
  <summary>Details</summary>
Motivation: 去中心化优化在分布式学习中很重要，但现有方法存在通信瓶颈，节点间频繁同步导致效率低下。需要一种能减少通信延迟影响的方法来加速训练。

Method: 提出OLDSGD（重叠本地去中心化SGD），通过精心设计的更新机制实现计算和通信的重叠，减少网络空闲时间，同时保持与Local SGD相同的平均更新。

Result: 理论上证明了在平滑非凸目标上的非渐近收敛率，保持与标准Local Decentralized SGD相同的迭代复杂度，但改善了每次迭代的运行时间。实验显示在不同通信延迟下都能提升实际收敛时间。

Conclusion: OLDSGD通过对现有框架的最小修改，提供了不牺牲理论保证的更快去中心化学习实用方案，有效解决了通信瓶颈问题。

Abstract: Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.

</details>


### [186] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

TL;DR: HiGO：一种用于全球野火行为预测的多尺度图神经网络框架，通过分层图ODE建模连续时空动态，在长期预测上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 野火作为地球系统的重要组成部分，受到大气、海洋和陆地过程在多种时空尺度上的复杂相互作用影响。虽然深度学习在天气预报方面取得突破，但在全球野火行为预测方面的潜力尚未充分探索。

Method: 提出分层图ODE（HiGO）框架：1）将地球系统表示为多层图层次结构；2）提出自适应过滤消息传递机制处理层内和层间信息流；3）在多个层次集成GNN参数化的神经ODE模块，显式学习每个尺度的连续动态。

Result: 在SeasFire Cube数据集上的实验表明，HiGO在长期野火预测上显著优于现有最先进方法，其连续时间预测表现出很强的观测一致性。

Conclusion: HiGO框架成功建模了野火的多尺度连续动态，为全球野火行为预测提供了有效解决方案，具有实际应用潜力。

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [187] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

TL;DR: 卫星图像嵌入比传统流域属性更能有效预测无测站河流流量，通过选择相似流域可提高预测精度


<details>
  <summary>Details</summary>
Motivation: 传统流域属性无法完全描述自然环境的复杂性，需要更有效的方法来表征流域特征以预测无测站河流流量

Method: 使用AlphaEarth Foundation嵌入（从大量卫星图像学习得到）来描述流域特征，并研究如何选择适当的供体流域来预测无测站区域

Result: 基于嵌入的模型在预测未参与训练的流域流量时精度更高，基于嵌入相似性选择相似流域可提高预测性能，而添加不相似流域会降低精度

Conclusion: 卫星信息的环境表征能增强水文预测能力，支持开发更适应不同景观的水文模型

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [188] [The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs](https://arxiv.org/abs/2601.01580)
*Zibo Zhao,Yuanting Zha,Haipeng Zhang,Xingcheng Xu*

Main category: cs.LG

TL;DR: 论文提出梯度归因属性理论，解释RL为何优于SFT：RL的平衡梯度归因让模型同时优化生成和验证能力，而SFT的不平衡梯度归因导致验证能力不足。


<details>
  <summary>Details</summary>
Motivation: 虽然RL后训练能让大语言模型获得自我反思能力，但统一的优化目标如何产生生成解决方案和评估何时修订这两种不同功能，其机制仍不明确。

Method: 引入梯度归因属性来表征奖励梯度在策略组件中的分布，形式化为两阶段决策-采样假设，将策略分解为生成用的采样策略和验证用的决策策略。

Result: 理论证明：替代奖励展现平衡梯度归因，而SFT和KL惩罚展现不平衡梯度归因；长度加权造成不对称正则化，约束采样策略而让决策策略优化不足。

Conclusion: RL的优越泛化能力主要来自改进的决策能力而非采样能力，为思维模型的自我纠正提供了第一性原理的机制解释。

Abstract: Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.

</details>


### [189] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 提出REE-TTT模型，通过时空测试时训练机制增强雷达回波外推的泛化能力，解决传统方法对高质量本地数据和静态参数的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的雷达回波外推方法在降水临近预报中占主导地位，但存在泛化能力差的问题，因为它依赖高质量的本地训练数据和静态模型参数，限制了在不同区域和极端事件中的适用性。

Method: 提出REE-TTT模型，引入自适应测试时训练机制，核心是设计的时空测试时训练块，用任务特定的注意力机制替代标准线性投影，使模型能适应非平稳的气象分布，增强降水特征表示。

Result: 在跨区域极端降水场景下的实验表明，REE-TTT在预测精度和泛化能力上显著优于最先进的基线模型，展现出对数据分布变化的显著适应性。

Conclusion: REE-TTT通过测试时训练机制有效解决了降水临近预报中的泛化问题，为跨区域和极端事件的降水预测提供了更可靠的解决方案。

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [190] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

TL;DR: 提出基于NILM的实时工业监控框架，针对孟加拉国纺织业相同电机负载，开发硬件系统收集数据，评估MATNILM模型性能，发现总能耗估计准确但相同设备同时运行时分解困难，系统实现远程实时监控。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织业作为高能耗行业，监控方法落后导致能源使用效率低下和运营成本高昂，需要改进工业能源监控系统。

Method: 开发基于电压电流传感器、Arduino Mega和ESP8266的硬件系统，收集总负载和单个负载数据；创建包含三个相同感应电机和辅助负载的新数据集（超过18万样本）；在云平台上存储处理数据；评估MATNILM模型在工业条件下的性能。

Result: 总能耗估计相对准确，但相同设备同时运行时设备级分解面临困难；集成系统通过Blynk应用实现了实用的远程实时监控。

Conclusion: NILM在工业应用中既有潜力也有局限性，未来改进方向包括更高频率数据采集、更大规模数据集以及处理相同负载的先进深度学习方法。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [191] [Communication-Efficient Federated AUC Maximization with Cyclic Client Participation](https://arxiv.org/abs/2601.01649)
*Umesh Vangapally,Wenhan Wu,Chen Chen,Zhishuai Guo*

Main category: cs.LG

TL;DR: 本文针对联邦学习中客户端周期性参与的场景，提出了高效的联邦AUC最大化算法，在平方替代损失下达到最优通信复杂度，在一般成对损失下也显著改进现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联邦AUC最大化方法通常假设客户端完全可用，但实际联邦学习系统中客户端往往周期性参与训练。这种周期性参与对不可分解的AUC目标函数带来了独特的优化挑战，需要专门设计高效的通信算法。

Method: 针对两种不同损失函数设置：1) 平方替代损失，将问题重构为非凸-强凹极小极大优化，利用Polyak-Łojasiewicz条件；2) 一般成对AUC损失。为周期性客户端参与场景设计通信高效的联邦优化算法。

Result: 平方替代损失下达到最优通信复杂度$\widetilde{O}(1/ε^{1/2})$和迭代复杂度$\widetilde{O}(1/ε)$；一般成对损失下通信复杂度$O(1/ε^3)$，迭代复杂度$O(1/ε^4)$，在PL条件下可改进到$\widetilde{O}(1/ε^{1/2})$和$\widetilde{O}(1/ε)$。在图像分类、医学影像和欺诈检测等任务上验证了方法的优越性。

Conclusion: 本文首次系统研究了周期性客户端参与下的联邦AUC最大化问题，提出了理论保证最优的通信高效算法，为实际联邦学习系统中处理不平衡数据提供了有效的解决方案。

Abstract: Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.

</details>


### [192] [Learning Resilient Elections with Adversarial GNNs](https://arxiv.org/abs/2601.01653)
*Hao Xiang Li,Yash Shah,Lorenzo Giusti*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图神经网络和对抗训练的投票规则学习方法，通过将选举表示为二分图来提升投票规则的表达能力和抗策略性投票的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管选举在现代民主、市场调节和推荐系统中至关重要，但设计一个满足所有假设场景的通用投票规则仍然具有挑战性。现有的基于集合不变架构的自动机制设计方法虽然适合建模选举系统，但在实际应用中面临鲁棒性不足（特别是对策略性投票）等问题。

Method: 1. 将选举表示为二分图结构；2. 使用图神经网络学习投票规则；3. 结合对抗训练提升投票规则对策略性投票的鲁棒性；4. 在最大化社会福利的同时提高系统的抗干扰能力。

Result: 该方法在合成和真实数据集上都表现出有效性，解决了先前工作中关于学习投票规则的关键限制，特别是在表达能力和鲁棒性方面取得了改进。

Conclusion: 该研究为将机器学习应用于真实世界选举开辟了新前沿，通过图神经网络和对抗训练的结合，显著提升了学习投票规则的表达能力和抗策略性投票的鲁棒性。

Abstract: In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.

</details>


### [193] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

TL;DR: 提出长度感知采样(LAS)方法，通过按长度分组轨迹减少批次内长度异质性，改善生成模型对轨迹衍生变量的分布匹配


<details>
  <summary>Details</summary>
Motivation: 标准小批量训练在轨迹长度高度异质时不稳定，这会降低轨迹衍生统计量的分布匹配质量

Method: 长度感知采样(LAS)：按轨迹长度分组，从单一长度桶中采样批次，减少批次内长度异质性；结合条件轨迹GAN和辅助时间对齐损失

Result: LAS在多商场购物轨迹数据集和多种公共序列数据集(GPS、教育、电子商务、电影)上一致改善衍生变量分布的匹配，优于随机采样

Conclusion: LAS通过消除仅基于长度的捷径批评器并针对桶内差异，改善了分布匹配，为轨迹生成建模提供了简单有效的批次采样策略

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [194] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 提出新框架，利用算法在基准数据集上的完整排名信息（不仅是胜场数），来更准确估计每个算法在未来未见数据集上的获胜概率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只统计算法在基准数据集上的胜场数来评估性能，但忽略了完整的排名信息（如第二名、第三名等）。这些额外信息可能对更准确地预测算法在未来数据集上的表现有重要价值。

Method: 引入新的概念框架，利用算法在基准数据集上的完整排名信息（不仅是胜场数），来估计每个算法在未来未见数据集上的获胜概率。该方法比现有方法更有效地利用了排名数据。

Result: 提出的新框架在合成和真实世界示例中显著优于现有已知方法，能够更准确地预测算法在未来数据集上的获胜概率。

Conclusion: 利用算法在基准数据集上的完整排名信息（而不仅仅是胜场数）可以显著提高对算法未来性能的预测准确性，为算法选择提供了更可靠的方法。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [195] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 提出一个面向鲁棒性的偏好条件DRL求解器框架，包含偏好对抗攻击生成困难实例和硬度感知偏好选择的防御策略，提升多目标组合优化问题求解器的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度强化学习在多目标组合优化问题上表现出潜力，但基于学习的求解器鲁棒性研究不足，特别是在多样化和复杂的问题分布上。需要探索如何评估和提升这些求解器在不同分布下的鲁棒性。

Method: 提出统一鲁棒性框架：1）偏好对抗攻击方法，生成暴露求解器弱点的困难实例；2）防御策略，将硬度感知偏好选择集成到对抗训练中，减少对受限偏好区域的过拟合。

Result: 在MOTSP、MOCVRP和MOKP问题上的实验表明：攻击方法成功为不同求解器生成困难实例；防御方法显著增强了神经求解器的鲁棒性和泛化能力，在困难或分布外实例上表现优异。

Conclusion: 提出的鲁棒性框架有效评估和提升了偏好条件DRL求解器的性能，攻击方法能识别求解器弱点，防御策略通过硬度感知偏好选择改善泛化能力，为多目标组合优化问题的学习型求解器提供了鲁棒性保障。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [196] [HeurekaBench: A Benchmarking Framework for AI Co-scientist](https://arxiv.org/abs/2601.01678)
*Siba Smarak Panigrahi,Jovana Videnović,Maria Brbić*

Main category: cs.LG

TL;DR: HeurekaBench是一个用于评估科学AI代理的基准框架，通过半自动流程从真实科学研究和代码仓库中创建开放式研究问题，并在单细胞生物学领域实例化为sc-HeurekaBench。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM驱动的科学代理系统面临挑战，需要真实、端到端的研究场景来整合数据分析、解释和从实验数据生成新见解。现有评估方法缺乏这种综合性。

Method: 开发半自动化流水线，利用多个LLM从科学研究和对应代码仓库中提取见解并生成候选工作流程，然后与报告发现进行验证，创建基于真实科学研究的开放式研究问题基准。

Result: 在单细胞生物学领域实例化为sc-HeurekaBench，用于比较最先进的单细胞代理。研究发现批评模块可将开源LLM代理的错误响应改善达22%，缩小与闭源模型的差距。

Conclusion: HeurekaBench为科学代理的严格端到端评估设定了路径，将基准构建基于真实科学工作流程，有助于定量分析代理系统设计选择。

Abstract: LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.

</details>


### [197] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

TL;DR: DiMEx利用预训练潜在扩散模型的语义先验，通过潜在空间贝叶斯优化绕过数据自由模型窃取的"冷启动"问题，显著提升攻击效率；同时提出混合状态集成防御，通过检测潜在空间攻击的优化轨迹来有效对抗此类攻击。


<details>
  <summary>Details</summary>
Motivation: 模型窃取攻击对机器学习即服务构成生存威胁，而数据自由模型提取面临"冷启动"问题：基于GAN的攻击者需要数千次查询才能从随机噪声收敛到有意义的数据。需要更高效的攻击方法，同时也需要相应的防御机制。

Method: 提出DiMEx攻击框架：利用预训练潜在扩散模型的丰富语义先验，在生成器潜在空间中使用随机嵌入贝叶斯优化，立即合成高保真查询。同时提出HSE防御：混合状态集成防御，通过识别潜在空间攻击的独特"优化轨迹"来检测攻击。

Result: DiMEx在SVHN数据集上仅用2000次查询就达到52.1%的协议率，比最先进的GAN基线高出16%以上。HSE防御能够将攻击成功率抑制到21.6%，且延迟可忽略不计，同时能规避静态分布检测器。

Conclusion: DiMEx通过利用预训练扩散模型的语义先验，有效解决了数据自由模型提取的冷启动问题，显著提升了攻击效率；而HSE防御通过分析攻击的时序特征，能够有效对抗这种语义丰富的攻击，为MLaaS安全提供了新的防御思路。

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [198] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

TL;DR: 提出一种新颖的多模型在线共形预测算法，通过二分图选择有效模型子集，降低计算复杂度并提高预测效率


<details>
  <summary>Details</summary>
Motivation: 传统共形预测依赖单一固定模型，在在线环境中可能表现不稳定；现有多模型方法计算成本高且可能包含性能差的模型

Method: 开发多模型在线共形预测算法，每个时间步生成二分图识别有效模型子集，从中选择模型构建预测集

Result: 实验表明该方法在预测集大小和计算效率方面优于现有多模型共形预测技术

Conclusion: 提出的算法能有效降低计算复杂度并提高预测效率，解决了多模型共形预测中的计算和性能问题

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [199] [Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT](https://arxiv.org/abs/2601.01701)
*Mohammed Ayalew Belay,Adil Rasheed,Pierluigi Salvo Rossi*

Main category: cs.LG

TL;DR: 提出数字孪生集成联邦学习(DTFL)方法，通过五种新颖方法解决工业异常检测中的数据隐私、通信效率和有限标签数据问题，显著提升收敛速度和通信效率。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测面临真实传感器数据依赖、标签数据有限、高误报率和隐私问题等挑战，需要既能保护数据隐私又能提升模型性能的解决方案。

Method: 提出数字孪生集成联邦学习(DTFL)框架，包含五种方法：DTML（数字孪生元学习）、FPF（联邦参数融合）、LPE（层间参数交换）、CWA（循环权重适应）和DTKD（数字孪生知识蒸馏），结合合成和真实世界知识。

Result: 在公开网络物理异常检测数据集上，CWA在33轮达到80%目标准确率，FPF需41轮，LPE需48轮，DTML需87轮，而标准FedAvg和DTKD在100轮内未达标。CWA比DTML减少62%通信轮次，比LPE减少31%。

Conclusion: 将数字孪生知识集成到联邦学习中能显著加速收敛到有意义的准确率阈值，为工业物联网异常检测提供通信高效且隐私保护的解决方案。

Abstract: Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.

</details>


### [200] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

TL;DR: EPIC是一种无需超参数的解码方法，通过将未来轨迹的熵纳入语言模型解码，在每一步生成时显式调节不确定性，使采样分布的熵与数据不确定性对齐，从而提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型解码算法存在局限性：随机采样质量低，而基于贪婪启发式的解码算法会产生短视扭曲，导致生成内容同质化、重复且不连贯。需要一种能更好处理生成过程中不确定性的解码方法。

Method: 提出EPIC解码方法，通过熵感知懒惰Gumbel-Max采样，将未来轨迹的熵纳入解码过程。该方法显式调节每一步生成时表达的不确定性量，使采样分布的熵与数据（偶然性）不确定性对齐。该方法无需超参数，且计算高效，每步仅需亚线性次数的熵评估。

Result: 在创意写作和摘要任务中，EPIC在LM-as-judge偏好胜率上持续优于广泛使用的解码策略。自动指标显示EPIC产生更多样化的生成内容和更忠实的摘要。在数学推理任务中，EPIC也优于所有基线方法。

Conclusion: EPIC通过将未来不确定性纳入解码过程，有效解决了现有解码方法的局限性，在多个任务上实现了更好的生成质量，为语言模型解码提供了新的有效方法。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [201] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

TL;DR: 本文证明循环Transformer在O(log n)循环层和O(n⁶)填充标记下可以识别所有上下文无关语言，但对于自然子类如无歧义CFL，仅需O(n³)填充，使识别更高效。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理自然语言和代码等语法结构良好的输入方面表现出色，但尚不清楚它们如何处理语法结构。现有研究表明标准Transformer无法识别上下文无关语言（CFL），甚至无法识别其子类正则语言。虽然已有工作表明O(log n)循环层可以让Transformer识别正则语言，但CFL识别问题仍然开放。

Method: 提出循环Transformer模型，通过添加O(log n)循环层和O(n⁶)填充标记来实现CFL识别。对于无歧义CFL等自然子类，将填充标记需求降低到O(n³)。通过理论分析和实验验证方法。

Result: 理论上证明循环Transformer在O(log n)循环层和O(n⁶)填充标记下可以识别所有CFL。对于无歧义CFL，仅需O(n³)填充标记。实验验证循环机制在需要对数深度的语言上确实有帮助。

Conclusion: CFL识别对Transformer具有复杂性：通用识别可能需要不可行的填充量，但自然约束（如无歧义性）能产生高效的识别算法。循环机制为Transformer处理语法结构提供了理论保证。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [202] [UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk](https://arxiv.org/abs/2601.01786)
*Intae Jeon,Yujeong Kwon,Hyungjoon Koo*

Main category: cs.LG

TL;DR: UnPII：首个基于PII风险的机器学习遗忘框架，通过PII风险指数（PRI）量化不同敏感属性的隐私风险，实现差异化遗忘策略，显著提升遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融、医疗等关键领域的广泛应用，处理敏感个人身份信息（PII）时的隐私问题日益突出。GDPR等法规要求按需删除PII，但现有遗忘技术采用统一策略，无法区分不同PII属性的隐私风险和业务风险差异。

Method: 提出UnPII框架，引入PII风险指数（PRI）——一个包含可识别性、敏感性、可用性、可链接性、持久性、可暴露性和合规性七个维度的复合指标。基于PRI对PII属性进行风险评估，并与现有遗忘算法（如梯度上升、负偏好优化等）无缝集成，实现基于风险的差异化遗忘。

Result: 实验表明，UnPII在准确性上提升达11.8%，实用性提升6.3%，泛化能力提升12.4%，同时遗忘过程中的微调开销平均仅增加27.5%。构建了包含1700个PII实例的合成数据集用于真实场景评估。

Conclusion: UnPII是首个PII中心的遗忘方法，通过量化PII风险实现差异化遗忘策略，显著优于传统统一遗忘方法，为组织隐私政策提供了可定制的风险评估框架，具有实际应用价值。

Abstract: The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.

</details>


### [203] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

TL;DR: HyperCLOVA X 8B Omni是首个支持文本、音频和视觉作为输入输出的任意到任意全模态模型，通过统一的多模态序列预测实现跨模态理解与生成。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的任意到任意全模态助手，避免传统方法中需要多个模态特定管道的复杂性，实现更实用的跨模态交互。

Method: 采用共享的下一个token预测接口处理交错的多模态序列，通过视觉和音频编码器注入连续嵌入以实现细粒度理解和基础。

Result: 在韩语和英语的文本、音频、视觉等多种输入输出组合上，与类似规模模型相比表现出有竞争力的性能。

Conclusion: HyperCLOVA X 8B Omni作为8B规模的全模态探索点，其开源权重将支持广泛的研究和部署场景，推动任意到任意全模态助手的发展。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [204] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

TL;DR: 提出分布式联邦学习框架，使用多服务器架构解决传统联邦学习的可扩展性和容错性问题


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习依赖单一中央服务器，在面对大量客户端时存在可扩展性挑战和单点故障风险，需要更健壮的分布式解决方案

Method: 设计分布式联邦学习框架，包含多个具有服务器间通信能力的服务器，提出DFL算法，交替进行客户端本地训练和服务器间全局训练

Result: 在适当参数选择下，DFL算法确保所有服务器收敛到理想模型的微小容忍范围内，有效整合本地和全局训练模型

Conclusion: 分布式联邦学习框架通过多服务器架构成功解决了传统联邦学习的可扩展性和容错性限制，并通过数值模拟验证了理论结果

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [205] [Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2601.01800)
*Qi Wei,Junchao Fan,Zhao Yang,Jianhua Wang,Jingkai Mao,Xiaolin Chang*

Main category: cs.LG

TL;DR: CARRL是一种针对自动驾驶的对抗训练方法，通过风险暴露对手和风险目标鲁棒代理的博弈交互，专门处理稀疏的安全关键风险，显著降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶中具有潜力，但对扰动的脆弱性阻碍了实际部署。现有对抗训练方法通常采用零和博弈和连续攻击，忽略了代理与对手之间的不对称性，未能反映安全关键风险的稀疏性，导致鲁棒性不足。

Method: 提出CARRL框架，包含两个交互组件：风险暴露对手（REA）和风险目标鲁棒代理（RTRA）。将交互建模为一般和博弈，REA专注于暴露安全关键故障（如碰撞），RTRA学习平衡安全与驾驶效率。REA采用解耦优化机制识别稀疏安全关键时刻，RTRA通过双回放缓冲区联合利用良性对抗经验，并强制策略一致性以稳定行为。

Result: 实验结果表明，与最先进的基线方法相比，该方法在所有情况下至少降低了22.66%的碰撞率。

Conclusion: CARRL通过专门处理稀疏的安全关键风险，显著提高了自动驾驶策略的鲁棒性，为解决实际部署中的安全性问题提供了有效方案。

Abstract: Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\% across all cases compared to state-of-the-art baseline methods.

</details>


### [206] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

TL;DR: 提出一种基于分布评论家高阶矩（偏度和峰度）修正PPO优势函数的方法，通过惩罚极端尾部行为来稳定策略更新，在Walker2D任务中提升稳定性达75%。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习智能体在相同回合回报下可能表现出不同行为，这源于环境和算法因素。连续控制任务中，微小参数变化可能导致不稳定步态，影响算法比较和现实迁移。现有方法通过约束策略保持窄的回报分布来提升稳定性，但直接估计该分布计算成本高。

Method: 利用环境随机性缓解更新引起的变异性：1）通过分布评论家建模状态-动作回报分布；2）使用该分布的高阶矩（偏度和峰度）修正PPO的优势函数；3）通过惩罚极端尾部行为，阻止策略进入易失稳的参数区域。

Result: 在Walker2D环境中，该方法将策略稳定性提升达75%，同时保持可比较的评估回报。当更新后评论家值与更新后回报对齐不佳时，标准PPO难以产生窄的回报分布，而基于矩的修正能有效缩窄该分布。

Conclusion: 通过分布评论家的高阶矩修正优势函数，可以有效提升强化学习策略的稳定性，特别是在连续控制任务中。该方法避免了直接估计高维回报分布的计算成本，利用环境随机性来缓解更新引起的变异性。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [207] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

TL;DR: RealPDEBench是首个结合真实测量数据与配对数值模拟的科学机器学习基准，包含5个数据集、3个任务、8个指标和10个基线模型，旨在解决科学ML中真实数据缺乏和模拟-现实差距的问题。


<details>
  <summary>Details</summary>
Motivation: 当前科学机器学习模型大多在模拟数据上训练和验证，缺乏昂贵的真实世界数据，这限制了科学ML的发展、评估以及模拟到现实的迁移研究。

Method: 构建包含5个真实世界测量数据集及其配对模拟数据集的基准，定义3个任务（允许真实与模拟数据比较），设计8个评估指标（数据导向和物理导向），并评估10个代表性基线模型。

Result: 实验显示模拟数据与真实世界数据存在显著差异，同时表明使用模拟数据进行预训练能持续提高准确性和收敛性。

Conclusion: RealPDEBench为科学机器学习提供了从真实世界数据的洞察，推动科学ML弥合模拟-现实差距并实现真实世界部署。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [208] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

TL;DR: FAROS：一个增强的联邦学习框架，通过自适应差分缩放和鲁棒核心集计算来防御后门攻击，相比现有方法在攻击成功率和主任务准确率上表现更好。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临后门攻击威胁，现有防御方法依赖固定参数，存在单点故障风险，难以应对复杂攻击者策略。

Method: 提出FAROS框架，包含自适应差分缩放（ADS）和鲁棒核心集计算（RCC）。ADS根据客户端上传梯度的离散度动态调整防御灵敏度；RCC通过计算高置信度客户端核心集的质心来降低单点故障风险。

Result: 在多个数据集、模型和攻击场景下的实验表明，该方法在攻击成功率和主任务准确率方面优于现有防御方法。

Conclusion: FAROS框架通过自适应防御机制和鲁棒核心集计算，有效提升了联邦学习对后门攻击的防御能力，解决了现有方法参数固定和单点故障的问题。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [209] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

TL;DR: FedCSPACK：一种基于余弦稀疏化参数打包和双重加权聚合的个性化联邦学习方法，通过参数打包和选择性共享减少带宽需求，利用掩码矩阵和加权聚合机制提升全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中边缘客户端数据异构性会降低模型性能，现有方法虽然通过模型分割和知识蒸馏增强模型兼容性，但忽略了客户端通信带宽和计算能力有限的现实约束，未能有效平衡处理数据异构性与适应有限客户端资源之间的矛盾。

Method: 提出FedCSPACK方法：1) 客户端打包模型参数，基于余弦相似度选择贡献最大的参数包进行共享，减少带宽需求；2) 客户端生成基于共享参数包的掩码矩阵，提升稀疏更新在服务器上的对齐和聚合效率；3) 在掩码中嵌入方向和分布距离权重，实现加权引导聚合机制。

Result: 在四个数据集上使用十种最先进方法的广泛实验表明，FedCSPACK在保持高模型准确率的同时，有效提高了通信和计算效率。

Conclusion: FedCSPACK通过参数打包、选择性共享和双重加权聚合机制，在有限客户端资源条件下有效缓解数据异构性对模型性能的影响，实现了通信效率、计算效率和模型性能的良好平衡。

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [210] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 仅需单个安全样本即可完全恢复安全对齐大语言模型，无需牺牲实用性，成本极低


<details>
  <summary>Details</summary>
Motivation: 微调安全对齐的大语言模型会严重损害其安全性，现有方法需要大量安全样本或校准集，计算开销大且导致模型实用性下降

Method: 发现仅需单个安全示例即可完全恢复安全对齐，无需牺牲实用性，揭示安全梯度的低秩结构解释了这种高效修正的可能性

Result: 恢复效果不受有害示例数量或模型大小影响，仅需几个epoch即可收敛，在五个安全对齐LLM和多个数据集上验证了方法的通用性

Conclusion: 安全对齐可以通过极低成本高效恢复，这得益于安全梯度的低秩结构特性，为LLM安全维护提供了高效解决方案

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [211] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

TL;DR: FedBiCross：一种个性化的单次联邦学习框架，通过聚类、双层跨集群优化和个性化蒸馏解决非IID数据下预测冲突问题


<details>
  <summary>Details</summary>
Motivation: 现有的单次联邦学习方法在非IID数据下存在预测冲突问题，平均预测会产生接近均匀的软标签，导致蒸馏监督信号弱

Method: 三阶段框架：1）基于模型输出相似性聚类客户端形成连贯子集成；2）双层跨集群优化学习自适应权重，选择性利用有益跨集群知识同时抑制负迁移；3）个性化蒸馏进行客户端特定适应

Result: 在四个医学图像数据集上的实验表明，FedBiCross在不同非IID程度下始终优于最先进的基线方法

Conclusion: FedBiCross通过聚类和选择性知识转移有效解决了非IID数据下单次联邦学习的预测冲突问题，为隐私敏感的医疗应用提供了有效的解决方案

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [212] [TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train](https://arxiv.org/abs/2601.01903)
*Ungsik Kim,Suwon Lee*

Main category: cs.LG

TL;DR: TT-FSI：利用矩阵乘积算子（MPO）高效计算忠实Shapley交互指数（FSI），实现指数级加速和内存优化


<details>
  <summary>Details</summary>
Motivation: FSI指数是唯一满足忠实性公理的Shapley交互指数，但现有计算方法需要O(d^ℓ·2^d)时间和O(4^d)内存，计算成本极高，限制了其在实际高维问题中的应用。

Method: 提出TT-FSI方法，利用FSI的代数结构，证明线性算子v↦FSI(v)具有TT秩为O(ℓd)的MPO表示，从而设计高效的扫描算法，实现指数级优化。

Result: 在6个数据集（d=8到d=20）上实验，相比基线加速280倍，相比SHAP-IQ加速85倍，内存减少290倍。TT-FSI可扩展到d=20（100万个联盟），而所有竞争方法均失败。

Conclusion: TT-FSI通过MPO表示和张量网络技术，首次实现了高维FSI指数的高效计算，为机器学习模型的高阶交互分析提供了实用工具。

Abstract: The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\ell \cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \mapsto \text{FSI}(v)$ admits an MPO representation with TT-rank $O(\ell d)$, enabling an efficient sweep algorithm with $O(\ell^2 d^3 \cdot 2^d)$ time and $O(\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\times$ speedup over baseline, 85$\times$ over SHAP-IQ, and 290$\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.

</details>


### [213] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

TL;DR: 该论文研究了偏好强化学习中特征依赖噪声的问题，发现现有噪声鲁棒方法在特征依赖噪声下性能显著下降，而无需显式去噪的方法反而表现更好，语言模型噪声也表现出类似特征依赖噪声的特性。


<details>
  <summary>Details</summary>
Motivation: 偏好强化学习（PbRL）适用于奖励函数不易获取的复杂任务，但偏好数据常带有不确定性和噪声。现有研究大多关注均匀分布的噪声检测，而忽略了与观测特征相关的噪声类型。本文旨在研究特征依赖噪声对PbRL方法的影响。

Method: 形式化定义了目标特征依赖噪声的概念，提出了几种变体：轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声和语言模型噪声。在DMControl和Meta-world的复杂连续控制任务中评估特征依赖噪声的影响。

Result: 实验表明，在某些特征依赖噪声设置下，最先进的噪声鲁棒PbRL方法的学习性能显著恶化，而无显式去噪的PbRL方法在多数设置中反而优于噪声鲁棒方法。语言模型噪声表现出与特征依赖噪声相似的特征。

Conclusion: 特征依赖噪声对现有PbRL方法构成挑战，语言模型噪声模拟了真实人类偏好的噪声特性。需要进一步研究如何鲁棒地学习具有特征依赖噪声的偏好数据。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [214] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

TL;DR: 提出了一种名为"分位数扭曲"的新概念，用于解决离线分布强化学习中均匀悲观估计的问题，通过基于数据可用性调整保守程度来实现非均匀悲观，从而提升性能。


<details>
  <summary>Details</summary>
Motivation: 分布强化学习方法在在线场景中表现出色，但在离线场景中效果有限。作者假设现有离线DRL方法的关键限制在于它们对回报分位数进行均匀低估，这种均匀悲观会导致过于保守的价值估计，最终阻碍泛化和性能提升。

Method: 引入"分位数扭曲"这一新概念，通过基于支持数据的可用性调整保守程度，实现非均匀悲观。该方法基于理论分析，并通过实证验证。

Result: 该方法在实证验证中表现出改进的性能，相比均匀悲观方法有更好的表现。

Conclusion: 提出的分位数扭曲方法能够有效解决离线分布强化学习中均匀悲观估计的问题，通过非均匀悲观调整提升模型性能，为离线DRL提供了新的研究方向。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [215] [Theoretical Convergence of SMOTE-Generated Samples](https://arxiv.org/abs/2601.01927)
*Firuz Kamalov,Hana Sulieman,Witold Pedrycz*

Main category: cs.LG

TL;DR: 本文对SMOTE过采样方法进行了严格的理论分析，证明了合成随机变量Z依概率收敛于原始随机变量X，并在X紧致时证明了更强的均值收敛，同时发现较小的最近邻秩k值能带来更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 不平衡数据广泛影响机器学习应用，SMOTE作为最流行的解决方法之一，不仅需要经验验证，更需要理论分析来理解其收敛性质。

Method: 对SMOTE进行严格的理论分析，证明合成随机变量Z的收敛性质，包括依概率收敛和均值收敛，并通过数值实验使用真实和合成数据进行验证。

Result: 证明了Z依概率收敛于X，当X紧致时存在更强的均值收敛，且较小的最近邻秩k值能带来更快的收敛速度，为实践者提供了可操作的指导。

Conclusion: 本文提供了对SMOTE收敛性质的基础理论理解，这不仅增强了不平衡数据处理技术，也为超越不平衡数据场景的数据增强技术提供了理论基础。

Abstract: Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.

</details>


### [216] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

TL;DR: DéjàQ是一个通过进化合成数学问题来增强模型推理能力的框架，它让模型在训练过程中动态生成和演化训练数据，避免静态数据集导致的记忆问题。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型大多依赖静态数据集，这容易导致模型记忆而非真正理解，限制了泛化能力。需要一种动态的数据生成方法来提升模型的数学推理能力。

Method: 提出DéjàQ框架，联合演化多样化的合成数学问题与模型训练。采用两种LLM驱动的变异策略：1）改变上下文细节；2）直接修改问题结构。模型在训练过程中根据自身能力动态生成和优化问题。

Result: 模型能够生成新颖且有意义的数学问题，LLM驱动的变异策略改善了强化学习训练效果。分析了生成问题的有效性和计算开销，证明了动态演化训练数据的潜力。

Conclusion: 动态演化训练数据能有效增强数学推理能力，具有广泛适用性。作者将开源代码以支持进一步研究。

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [217] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

TL;DR: SynRXN是一个用于计算机辅助合成规划的统一基准测试框架和开放数据资源，将端到端合成规划分解为五个任务族，提供标准化数据集和评估流程。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划领域缺乏统一的基准测试框架，数据集异构且评估方法不一致，难以进行公平的方法比较和性能评估。

Method: 将合成规划分解为五个任务族：反应平衡、原子映射、反应分类、反应性质预测和合成路线设计；从多个公共来源收集反应数据，进行标准化处理；提供泄漏感知的数据划分、标准化评估工作流和指标套件。

Result: 创建了一个包含版本化数据集、透明数据划分、标准化评估流程的完整基准测试框架，支持可重复的数据集重建和公平的方法比较。

Conclusion: SynRXN通过消除数据集异质性并提供透明的评估框架，支持计算机辅助合成规划方法的公平纵向比较，降低了从业者获取稳健性能评估的门槛。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [218] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

TL;DR: 该论文提出RePro框架，用于推断指令调优训练数据中提示是原始版本还是经过LLM优化的版本，解决数据集治理和争议问题。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优越来越多地使用LLM优化提示，需要解决实例级审计问题：对于微调模型和训练提示-响应对，能否推断模型是在原始提示还是其优化版本上训练的？这对数据集治理和训练数据争议解决很重要。

Method: 提出RePro框架，基于教师强制token分布的可检测偏移，融合教师强制似然特征和logit排序信号。通过影子微调学习可迁移表示，使用轻量级线性头在未见受害者模型上推断来源，无需访问训练数据。

Result: RePro在实验中始终表现出强大性能，并能很好地跨优化器迁移，表明它利用了优化器无关的分布偏移而非重写风格伪影。

Conclusion: 该研究形式化了优化来源推断任务，证明了提示优化会产生稳定可检测的token分布偏移，提出的RePro框架能有效解决这一审计问题。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [219] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

TL;DR: SerpentFlow提出了一种无配对域对齐的生成框架，通过将数据分解为共享结构和域特定组件，生成伪训练对，从而在无配对数据下实现条件生成模型的应用。


<details>
  <summary>Details</summary>
Motivation: 在无配对观测数据的情况下，跨域对齐具有挑战性。传统条件生成模型需要配对数据，而现实应用中往往缺乏这种监督信号。需要一种方法能够在无配对数据下学习域间的对应关系。

Method: SerpentFlow在潜在空间中将数据分解为共享组件（跨域共同结构）和域特定组件。通过用随机噪声替换域特定组件，构建共享表示与目标域样本之间的合成训练对，从而支持条件生成模型。在超分辨率任务中，共享组件对应低频内容，高频细节对应域特定变异性，通过分类器准则自动确定分离频率。

Result: 在合成图像、物理过程模拟和气候降尺度任务上的实验表明，该方法能有效重建与底层低频模式一致的高频结构，支持共享结构分解作为无配对域对齐的有效策略。

Conclusion: 共享结构分解为无配对域对齐提供了有效框架，通过生成伪训练对使传统需要配对数据的条件生成模型能够在无监督设置下应用，在多个领域展示了良好性能。

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [220] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 本文证明了Thompson采样在线性高斯赌博机中具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中burn-in项与minimax遗憾项呈加性而非乘性关系。


<details>
  <summary>Details</summary>
Motivation: 现有Thompson采样在线性高斯赌博机中的遗憾界中，先验相关的"burn-in"项与minimax（长期）遗憾项呈乘性关系。本文旨在证明这两个项实际上可以解耦为加性关系，从而提供更精确的遗憾分析。

Method: 通过新的"椭圆势能"引理（elliptical potential lemma）来分析Thompson采样的遗憾界，并提供了下界证明表明burn-in项是不可避免的。

Result: 证明了Thompson采样具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中$d$是维度，$T$是时间范围，$r$是动作的最大$\ell_2$范数，$σ^2$是噪声方差。这表明确实存在加性而非乘性的关系。

Conclusion: 在线性高斯赌博机中，Thompson采样的先验相关burn-in项与minimax遗憾项可以解耦为加性关系，这一发现改进了现有理论分析，并通过下界证明了burn-in项的必然性。

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [221] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

TL;DR: 提出输出嵌入中心化（OEC）方法，通过μ-centering和μ-loss两种实现方式解决大语言模型预训练中的输出logit发散问题，相比z-loss在训练稳定性和学习率敏感性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 大语言模型预训练不仅昂贵，而且容易出现训练不稳定性。在训练后期使用大学习率时经常出现输出logit发散问题。目前最广泛使用的缓解策略z-loss只是治标不治本，没有解决根本原因。

Method: 从输出嵌入几何的角度分析不稳定性，识别其根本原因。提出输出嵌入中心化（OEC）作为新的缓解策略，证明它能抑制输出logit发散。OEC有两种实现方式：确定性操作μ-centering和正则化方法μ-loss。

Result: 实验表明，两种OEC变体在训练稳定性和学习率敏感性方面都优于z-loss。特别是在z-loss失败的大学习率情况下，OEC能确保训练收敛。此外，μ-loss对正则化超参数调优的敏感性显著低于z-loss。

Conclusion: 输出嵌入中心化（OEC）通过解决输出嵌入几何的根本问题，有效缓解大语言模型预训练中的输出logit发散不稳定性，相比现有方法具有更好的稳定性和更低的超参数敏感性。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [222] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

TL;DR: GDRO是一种针对整流流扩散模型的群体级奖励对齐后训练范式，通过离线优化解决在线RL效率低、依赖随机采样器和奖励黑客问题


<details>
  <summary>Details</summary>
Motivation: 现有方法使用在线强化学习从LLMs到文本到图像的整流流扩散模型进行奖励对齐，但面临效率低、依赖随机采样器和奖励黑客问题。整流流模型与LLMs有本质区别：1) 在线图像采样耗时；2) 整流流在初始噪声固定后是确定性的

Method: 提出Group-level Direct Reward Optimization (GDRO)，结合整流流模型特性的群体级奖励对齐后训练范式。通过理论分析支持完全离线训练，节省图像采样时间；扩散采样器独立，无需ODE-to-SDE近似；考虑奖励黑客陷阱，使用校正分数进行评估

Result: 在OCR和GenEval任务上的广泛实验表明，GDRO通过群体级离线优化有效提升扩散模型的奖励分数，同时展示出缓解奖励黑客的强稳定性和鲁棒性

Conclusion: GDRO为整流流扩散模型提供了一种高效、稳定且鲁棒的群体级奖励对齐方法，解决了现有在线RL方法的局限性

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [223] [Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling](https://arxiv.org/abs/2601.02037)
*Wei Hu,Zewei Yu,Jianqiu Xu*

Main category: cs.LG

TL;DR: DMPEAD：一种用于多元时间序列异常检测的动态模型池与集成框架，通过构建多样化模型池、动态更新和集成排名靠前模型，解决了现有多模型方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多元时间序列异常检测多模型方法存在三个主要问题：1) 选择方法依赖单一模型且对策略敏感；2) 集成方法通常组合所有模型或仅限于单变量数据；3) 大多数方法依赖固定数据维度，限制了可扩展性。

Method: 提出DMPEAD框架：1) 通过参数传递和多样性度量构建多样化模型池；2) 使用元模型和基于相似性的策略动态更新模型池，实现自适应扩展、子集选择和池合并；3) 在选定子集中通过代理度量排名和top-k聚合集成排名靠前模型，输出最终异常检测结果。

Result: 在8个真实世界数据集上的广泛实验表明，该模型优于所有基线方法，展示了优越的适应性和可扩展性。

Conclusion: DMPEAD框架有效解决了现有多元时间序列异常检测多模型方法的局限性，通过动态模型池构建和集成策略实现了更好的性能和可扩展性。

Abstract: Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.

</details>


### [224] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

TL;DR: 该论文提出了一个基于有界变差函数的可解释性框架，通过激活函数的饱和区"拯救"死亡神经元来增强模型表达能力，揭示了ENSO预测主要来自热带太平洋，并探讨了春季可预测性障碍的原因。


<details>
  <summary>Details</summary>
Motivation: ENSO对全球气候变化有深远影响，但其预测仍是重大挑战。虽然深度学习显著提高了预测技能，但这些模型的不透明性阻碍了科学信任和业务部署。

Method: 引入基于有界变差函数的数学可解释性框架，通过从激活函数的饱和区"拯救"死亡神经元来增强模型表达能力，并进行控制实验验证方法的稳健性。

Result: 分析显示ENSO可预测性主要来自热带太平洋，印度洋和大西洋也有贡献，这与物理理解一致。研究发现尽管春季敏感性扩大，但预测性能下降，这可能与次优变量选择有关。

Conclusion: 结果表明，纳入额外的海洋-大气变量可能有助于超越春季可预测性障碍的限制，并推进长期ENSO预测。

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [225] [The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks](https://arxiv.org/abs/2601.02080)
*Yizhi Liu*

Main category: cs.LG

TL;DR: 论文发现双随机矩阵约束在深度学习架构中会导致"同质性陷阱"——最大熵偏置使混合算子趋向均匀重心，抑制次主导奇异值，过滤高频特征，限制网络的有效感受野。


<details>
  <summary>Details</summary>
Motivation: 双随机矩阵在保持结构的深度学习架构（如最优传输层和Sinkhorn注意力）中广泛使用，以确保数值稳定性和概率可解释性。然而，这些约束可能导致谱退化现象，影响网络的表达能力。

Method: 通过理论分析识别"同质性陷阱"现象，推导谱边界将σ_2与网络有效深度联系起来，并形式化证明层归一化在噪声主导机制中无法缓解这种崩溃。

Result: 发现最大熵偏置使混合算子趋向均匀重心，抑制次主导奇异值σ_2，过滤高频特征分量。高熵约束将特征变换限制在浅层有效感受野内。当信噪比低于临界阈值时，几何结构会因噪声诱导的正交崩溃而不可逆地丢失。

Conclusion: 双随机矩阵约束网络存在熵稳定性和谱表达能力之间的基本权衡。需要重新思考如何在保持数值稳定性的同时避免谱退化，以维持网络的深度表达能力。

Abstract: Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.

</details>


### [226] [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)
*Jiacheng Lyu,Bihua Bao*

Main category: cs.LG

TL;DR: 提出对抗性软选择子采样框架，将数据缩减重构为可微分端到端学习问题，通过选择器网络和任务网络的对抗博弈学习样本重要性权重，实现任务感知的智能数据子采样。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集给模型训练带来计算挑战，传统数据子采样方法作为静态、任务无关的预处理步骤，通常会丢弃对下游预测至关重要的信息。需要一种能够保留任务相关信息的智能数据缩减方法。

Method: 提出对抗性软选择子采样框架，包含选择器网络和任务网络。选择器网络学习为样本分配连续重要性权重，通过Gumbel-Softmax松弛实现直接优化，在平衡预测保真度和稀疏性的损失函数指导下，识别并保留对特定任务目标信息量最大的样本。

Result: 在四个大规模真实世界数据集上的综合实验表明，ASSS始终优于聚类和最近邻稀疏化等启发式子采样基线方法。值得注意的是，ASSS不仅能匹配，有时甚至能超过使用整个数据集的训练性能，展示了智能去噪的效果。

Conclusion: 该工作将任务感知数据子采样确立为可学习组件，为有效的大规模数据学习提供了原则性解决方案。理论分析将该框架与信息瓶颈原理联系起来，展示了其理论基础。

Abstract: The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.

</details>


### [227] [Horizon Activation Mapping for Neural Networks in Time Series Forecasting](https://arxiv.org/abs/2601.02094)
*Hans Krupakar,V A Kandappan*

Main category: cs.LG

TL;DR: 提出HAM（Horizon Activation Mapping）方法，用于跨不同神经网络家族的时序预测模型的可视化解释，通过梯度范数平均值分析子序列的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有时序预测模型依赖误差指标和特定架构的可解释性方法，这些方法无法跨不同模型家族应用，需要一种模型无关的可视化解释技术。

Method: HAM受grad-CAM启发，使用梯度范数平均值分析子序列，引入因果和反因果模式计算每个时间步的梯度更新范数平均值，并研究批次大小、早停、数据分割等优化景观。

Result: 在ETTm2数据集上测试了多种模型（CycleNet、N-Linear、N-HITS、FEDformer等），发现批次大小差异可能指示指数近似关系，NHITS的神经近似定理和SpaceTime的指数自回归活动在HAM图中呈现趋势。

Conclusion: HAM可用于细粒度模型选择、验证集选择以及跨不同神经网络模型家族的比较，为时序预测模型提供统一的解释框架。

Abstract: Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.

</details>


### [228] [LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training](https://arxiv.org/abs/2601.02105)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: LION-DG：一种针对深度监督网络的层感知初始化方法，通过零初始化辅助分类器头，实现梯度唤醒机制，无需超参数即可加速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有初始化方法大多是层无关的，而深度监督架构中的未训练辅助分类器头会通过梯度干扰破坏早期训练稳定性。

Method: 提出LION-DG初始化方法：对主干网络应用标准He初始化，对辅助分类器头进行零初始化。这实现了梯度唤醒机制——辅助梯度在初始化时为零，随着权重增长自然引入。

Result: 在CIFAR-10和CIFAR-100上的实验表明：DenseNet-DS收敛速度提升8.3%；LSUV与LION-DG结合获得最佳准确率81.92%；ResNet-DS在CIFAR-100上加速11.3%。

Conclusion: LION-DG是一种简单、无需超参数、无计算开销的初始化方法，为深度监督网络提供了有效的训练加速方案，并给出了架构特定的实践指导。

Abstract: Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.
  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.
  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.
  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.

</details>


### [229] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: ProtoPal框架通过原型学习实现个性化预防医疗，提供可理解和可验证的预测与干预，具有前后端模式，在定量性能和直观展示方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习和可解释AI有所进展，但个性化预防医疗仍存在缺口：预测、干预和推荐需要对所有医疗领域利益相关者来说都是可理解和可验证的。

Method: 提出ProtoPal框架，采用原型学习方法，具有前端和后端两种模式，能够直观展示干预措施及其模拟结果。

Result: 框架在定量性能方面表现优异，同时提供了干预措施及其模拟结果的直观呈现。

Conclusion: 原型学习能够有效满足个性化预防医疗中对可理解性和可验证性的需求，ProtoPal框架为此提供了可行的解决方案。

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [230] [Edge-aware GAT-based protein binding site prediction](https://arxiv.org/abs/2601.02138)
*Weisen Yang,Hanqing Zhang,Wangren Qiu,Xuan Xiao,Weizhong Lin*

Main category: cs.LG

TL;DR: 提出Edge-aware GAT模型，通过原子级图和多维结构特征，结合距离和方向向量作为边特征，实现蛋白质结合位点的细粒度预测，在基准数据集上达到0.93的ROC-AUC。


<details>
  <summary>Details</summary>
Motivation: 准确识别蛋白质结合位点对理解生物分子相互作用机制和药物靶点理性设计至关重要。传统预测方法在捕捉复杂空间构象时难以平衡预测精度和计算效率。

Method: 提出Edge-aware GAT模型，构建原子级图并整合几何描述符、DSSP二级结构和相对溶剂可及性等多维结构特征。在注意力机制中引入原子间距离和方向向量作为边特征，增强表示能力。采用方向张量传播和残基级注意力池化技术。

Result: 在基准数据集上，模型在蛋白质-蛋白质结合位点预测中达到0.93的ROC-AUC，优于多个最先进方法。PyMOL可视化证实了模型的实用性和可解释性。已部署公开可访问的Web服务器。

Conclusion: 该方法为识别蛋白质功能位点提供了新颖高效的解决方案，在预测精度、泛化能力和可解释性之间取得了良好平衡。

Abstract: Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.

</details>


### [231] [Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting](https://arxiv.org/abs/2601.02151)
*Muxi Diao,Lele Yang,Wuxuan Gong,Yutong Zhang,Zhonghao Yan,Yufei Han,Kongming Liang,Weiran Xu,Zhanyu Ma*

Main category: cs.LG

TL;DR: EAFT（熵自适应微调）通过基于token级熵的门控机制，区分认知不确定性和知识冲突，在保持下游性能的同时显著缓解SFT中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调（SFT）在领域适应中经常导致灾难性遗忘，而强化学习（RL）却能有效保持通用能力。研究发现这种差异源于分布差距：RL与模型内部信念对齐，而SFT强制模型拟合外部监督，导致"自信冲突"token（低概率但低熵）引发破坏性梯度更新。

Method: 提出熵自适应微调（EAFT），利用token级熵作为门控机制来区分认知不确定性和知识冲突。该方法让模型从不确信样本中学习，同时抑制冲突数据的梯度更新，而不是仅依赖预测概率。

Result: 在Qwen和GLM系列模型（4B到32B参数）上，在数学、医疗和智能体领域的广泛实验证实了假设。EAFT在匹配标准SFT下游性能的同时，显著减轻了通用能力的退化。

Conclusion: EAFT通过熵自适应机制有效解决了SFT中的灾难性遗忘问题，为领域适应提供了一种既能保持下游性能又能保护通用能力的新方法。

Abstract: Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as "Confident Conflicts" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.

</details>


### [232] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

TL;DR: 研究标准机器学习算法对数据可交换性和独立性的依赖程度，通过引入单调对抗性污染模型，发现已知最优分类算法在看似有帮助的单调污染下会表现不佳，而基于一致收敛的算法则不受影响。


<details>
  <summary>Details</summary>
Motivation: 探究标准机器学习算法对数据可交换性和独立性的依赖程度，理解算法在面对看似有帮助的单调污染时的鲁棒性，揭示最优算法可能过度依赖数据可交换性的问题。

Method: 引入单调对抗性污染模型：攻击者观察"干净"的i.i.d.数据集后，插入自己选择的"污染"点，这些点必须是单调污染（即按照真实目标函数标记）。在此设置下分析不同算法的表现。

Result: 所有已知的二进制分类最优学习算法在单调污染下都会在新独立测试点上获得次优的期望误差；而基于一致收敛的算法则不会降低其性能保证。

Conclusion: 最优学习算法在面对看似有帮助的单调污染时会失效，这暴露了它们对数据可交换性的过度依赖；基于一致收敛的算法则更加鲁棒，不受此类污染影响。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [233] [ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense](https://arxiv.org/abs/2601.02196)
*Yu Li,Sizhe Tang,Rongqian Chen,Fei Xu Yu,Guangyu Jiang,Mahdi Imani,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: 该论文提出了一种基于蒙特卡洛树搜索和图神经网络的自动化网络防御方法，在CAGE-4挑战中实现了比现有强化学习方法更高效的防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的自动化网络防御方法在复杂网络中面临探索困难、状态/决策空间大、需要大量样本的问题，需要更高效的防御策略学习方法。

Method: 将ACD建模为基于上下文的部分可观测马尔可夫决策过程，提出基于MCTS的规划中心防御策略，使用GNN嵌入网络观测为属性图，结合学习到的图嵌入和图编辑动作先验来指导MCTS搜索。

Result: 在CC4场景中评估表明，该搜索引导、基于图嵌入的规划方法相比最先进的RL基线，提高了防御奖励和鲁棒性。

Conclusion: 该方法结合了无模型泛化、策略蒸馏和前瞻规划，在复杂搜索空间中实现了更高效的自动化网络防御。

Abstract: Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.

</details>


### [234] [CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents](https://arxiv.org/abs/2601.02201)
*Keyu Wang,Bingchen Miao,Wendong Bu,Yu Wu,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: CORE提出了一种基于代码的逆自训练框架，通过图扩展桥接模仿学习与强化学习，无需人工设计奖励函数，同时提升行为多样性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态虚拟智能体训练存在两种主流范式：行为克隆简单有效但行为多样性低；强化学习能探索新策略但严重依赖人工设计的奖励函数。这两种方法存在冲突，需要一种能结合两者优势的新框架。

Method: 1. 语义代码抽象：从专家演示中自动推断奖励函数（标签函数），无需人工设计；2. 策略图扩展：构建多路径策略图，捕捉超越专家演示的多样化有效解决方案，增强域内行为多样性；3. 轨迹引导外推：利用成功和失败轨迹扩展任务空间，丰富域外行为多样性。

Result: 在Web和Android平台上的实验表明，CORE显著提高了整体性能和泛化能力，证明了其作为构建强大虚拟智能体的稳健且可泛化训练范式的潜力。

Conclusion: CORE通过桥接模仿学习和探索学习，提供了一种新颖的训练框架，既能促进行为多样性，又能消除对人工奖励设计的依赖，为多模态虚拟智能体的发展提供了有力支持。

Abstract: The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.

</details>


### [235] [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)
*Haoyu Zhou,Ping Xue,Tianfan Fu,Hao Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种用于压缩和加速SO(3)-等变图神经网络的低比特量化方法，通过三种创新技术实现高效部署，在保持精度和物理对称性的同时显著提升推理速度并减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署3D旋转等变的图神经网络面临高计算成本挑战，需要压缩和加速SO(3)-等变GNN以支持实际化学应用。

Method: 提出三种量化等变变换器的创新技术：1) 幅值-方向解耦量化方案，分别量化等变特征的范数和方向；2) 分支分离的量化感知训练策略，在注意力机制中区别处理不变和等变特征通道；3) 鲁棒性增强的注意力归一化机制，稳定低精度注意力计算。

Result: 在QM9和rMD17分子基准测试中，8位模型在能量和力预测方面达到与全精度基线相当的精度，同时实现2.37-2.73倍推理加速和4倍模型尺寸减小，使用局部等变误差(LEE)指标验证了量化后等变性的保持。

Conclusion: 所提出的量化技术能够在不牺牲精度或物理对称性的情况下，实现对称感知GNN在实际化学应用中的高效部署，为边缘设备上的3D等变GNN应用提供了可行解决方案。

Abstract: Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.

</details>


### [236] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

TL;DR: ELLA：一种基于选择性子空间去相关原则的持续学习框架，通过惩罚任务特定方向的对齐来减少灾难性遗忘，同时保留低能量子空间的自由度以实现正向迁移。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在持续学习设置中面临严重的灾难性遗忘问题。现有方法存在根本性限制：基于重放的方法不切实际且侵犯隐私，而基于严格正交性的方法在规模扩展时会崩溃，因为它们逐渐减少剩余自由度并禁止共享表示的重叠，从而消除正向迁移。

Method: ELLA基于选择性子空间去相关原则。它显式地表征过去更新的结构，并惩罚沿高能量、任务特定方向的对齐，同时保留低能量残差子空间的自由度以实现迁移。这通过一个轻量级正则化器在单个聚合更新矩阵上实现，对应于一个各向异性收缩算子，可以限制干扰。

Result: 在三个流行基准测试中实现了最先进的持续学习性能，相对准确率提升高达9.6%，内存占用减少35倍。无需数据重放、架构扩展和可忽略的存储开销，并能稳健地扩展到不同架构，同时增强模型在未见任务上的零样本泛化性能。

Conclusion: ELLA为构建性终身LLM适应提供了一个原则性和可扩展的解决方案，通过选择性子空间去相关平衡了任务特定学习和正向迁移，解决了现有方法的根本限制。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [237] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

TL;DR: 提出Neuro-Channel Networks (NCN)，一种无乘法神经网络架构，用通道宽度和神经递质参数替代权重，仅使用加法、减法和位运算，旨在降低AI对昂贵GPU硬件的依赖。


<details>
  <summary>Details</summary>
Motivation: 深度学习严重依赖昂贵、高能耗且供应稀缺的GPU硬件，限制了AI在边缘设备的普及。传统人工感知器依赖密集矩阵乘法，而生物神经系统通过物理离子通道限制和化学神经递质调节信号传输，无需算术乘法，效率更高。

Method: 提出Neuro-Channel Networks (NCN)：1) 用通道宽度物理限制信号幅度；2) 引入神经递质参数基于符号逻辑调节信号传输；3) 前向传播仅使用加法、减法和位运算（最小值、符号），完全消除浮点乘法；4) 使用标准反向传播训练。

Result: 概念验证研究表明，NCN能够100%准确解决非线性可分问题（如XOR和多数函数），证明其无需乘法权重即可形成复杂决策边界的能力。

Conclusion: NCN架构为下一代神经形态硬件提供了高效替代方案，使复杂模型能够在商用CPU或超低功耗芯片上运行，无需依赖昂贵的GPU集群，有望推动AI在边缘设备的普及。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [238] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

TL;DR: POSEIDON是一个基于物理约束的能量模型，用于统一的多任务地震事件预测，结合了最大的开源全球地震目录，在余震识别、海啸生成潜力和前震检测等任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前地震预测和地震危险性评估中的机器学习方法通常是黑箱模型，忽略了已建立的物理定律。需要开发能够结合物理原理的模型，提高预测的可解释性和准确性。

Method: 提出POSEIDON模型，将古登堡-里克特震级-频率关系和Omori-Utsu余震衰减定律等基本地震学原理作为可学习的约束，嵌入到基于能量的建模框架中。同时处理三个相互关联的预测任务：余震序列识别、海啸生成潜力和前震检测。

Result: POSEIDON在所有任务上都达到了最先进的性能，超过了梯度提升、随机森林和CNN基线方法，获得了最高的平均F1分数。学习到的物理参数收敛到科学可解释的值：古登堡-里克特b值为0.752，Omori-Utsu参数p=0.835，c=0.1948天，这些值都在已建立的地震学范围内。

Conclusion: POSEIDON成功地将物理约束整合到机器学习模型中，在保持预测准确性的同时提高了可解释性。发布的Poseidon数据集（包含280万个事件，跨越30年）为物理信息的地震研究提供了重要资源。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [239] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

TL;DR: 提出一种通过共享带噪声的transformer嵌入来保护隐私的文本数据共享方法，使用非参数变分差分隐私(NVDP)在隐私保护和数据效用之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: transformer嵌入包含多个向量（每个token一个），可能编码敏感信息，使攻击者能够以相当高的准确率恢复输入数据，因此需要一种既能有效共享数据又能提供强隐私保护的方法。

Method: 提出非参数变分差分隐私(NVDP)，将非参数变分信息瓶颈(NVIB)层集成到transformer架构中，向多向量嵌入注入噪声以隐藏信息，使用Rényi散度及其对应的贝叶斯差分隐私(BDP)保证来测量隐私保护。

Result: 在GLUE基准测试中，通过调整噪声水平可以在隐私和准确性之间实现有用的权衡，较低噪声水平下模型保持高准确性同时提供强隐私保证。

Conclusion: NVDP方法有效地平衡了隐私和效用，通过校准噪声水平实现了隐私保护与数据共享的优化平衡。

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [240] [Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310)
*Ahmad Makinde*

Main category: cs.LG

TL;DR: 使用T-KAN网络替代传统LSTM的固定线性权重，通过可学习的B样条激活函数捕捉市场信号的"形状"，在HFT环境中显著提升预测性能并实现可观回报。


<details>
  <summary>Details</summary>
Motivation: 高频交易环境中，限价订单簿数据噪声大、非线性强，传统模型如DeepLOB随着时间跨度增加预测能力衰减严重（Alpha衰减问题），需要更有效的模型来处理市场信号的复杂模式。

Method: 提出Temporal Kolmogorov-Arnold Networks (T-KAN)，用可学习的B样条激活函数替代标准LSTM的固定线性权重，使模型能够学习市场信号的"形状"而不仅仅是幅度。模型针对低延迟FPGA实现进行了优化，使用FI-2010数据集进行验证。

Result: 在k=100时间跨度上，F1分数相对提升19.1%；在1.0基点交易成本下，T-KAN实现132.48%回报，而DeepLOB亏损82.76%。模型还具有较好的可解释性，样条中的"死区"清晰可见。

Conclusion: T-KAN网络在高频限价订单簿预测中显著优于传统模型，不仅提高了预测精度和投资回报，还提供了更好的可解释性，并且适合低延迟FPGA实现，具有实际部署价值。

Abstract: High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.

</details>


### [241] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

TL;DR: 论文提出了一种结合博弈论与编码理论的新框架"编码游戏"，用于去中心化系统中理性对手（而非纯恶意对手）的场景，能在诚实节点不占多数的情况下实现非零的数据恢复概率。


<details>
  <summary>Details</summary>
Motivation: 传统编码理论假设最坏情况的对抗模型，要求诚实节点数量超过恶意节点。但在去中心化机器学习等新兴应用中，参与节点因贡献获得奖励，这催生了理性对手（strategic adversaries）而非纯恶意对手。现有方法无法有效处理这种理性对手场景。

Method: 引入"编码游戏"这一博弈论框架，将编码理论扩展到信任最小化的环境中。重点关注重复编码，分析在理性对手场景下的博弈均衡。该框架具有两个关键特性：1）即使对手节点占多数也能实现非零数据恢复概率；2）Sybil抵抗性（对手节点数量增加不影响均衡）。

Result: 该框架能够在诚实节点不占多数的情况下实现非零的数据恢复概率，并具有Sybil抵抗性（对手节点数量增加不会改变均衡状态）。这为去中心化系统中的外包计算等应用提供了新的解决方案。

Conclusion: 论文提出了一个将博弈论与编码理论相结合的新框架，解决了去中心化系统中理性对手的问题。该框架突破了传统编码理论对诚实节点数量的限制，为去中心化机器学习等应用提供了新的理论工具，并指出了对手策略未知等未来研究方向。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [242] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 论文提出评估视觉语言模型(VLMs)的三个标准：忠实性、区分性和效率，并发现现有评估存在多项缺陷，通过转换多项选择题为生成任务、过滤可盲答和错误标注样本，创建了优化评估套件DatBench，实现13倍加速。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型训练研究众多，但评估方法仍不成熟。现有评估存在多项问题：多项选择题格式鼓励猜测、不能反映实际应用、容易饱和；高达70%的问题可盲答（无需图像）；某些数据集中高达42%的样本存在错误标注或歧义；评估计算成本过高（占开发算力的20%）。

Method: 提出评估应满足的三个标准：忠实性（对模态和应用的忠实）、区分性（能区分不同质量模型）、效率（计算效率）。通过转换多项选择题为生成任务来揭示真实能力差异，过滤可盲答和错误标注样本，创建优化评估套件DatBench-Full（33个数据集）和高效子集DatBench。

Result: 将多项选择题转换为生成任务后，模型能力下降高达35%；过滤问题样本后提高了区分能力同时降低了计算成本；DatBench子集实现平均13倍加速（最高50倍），同时保持与原数据集相近的区分能力。

Conclusion: 论文为视觉语言模型评估提供了更严谨和可持续的路径，通过识别和修复现有评估的缺陷，创建了更忠实、区分性更强、效率更高的评估框架，为VLMs规模化发展提供了更好的评估实践。

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [243] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo与低带宽流水线模型并行结合，通过激活压缩和异构分布式训练框架，在保持性能的同时显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要分布式计算，但带宽限制阻碍了在数据中心之外的扩展，特别是模型并行需要频繁的大规模设备间通信。需要研究如何将低通信数据并行方法与低带宽模型并行结合。

Method: 提出异构分布式训练框架：高带宽参与者托管完整副本，资源有限参与者通过流水线并行联合实例化副本，使用子空间投影的级间通信压缩。将SparseLoCo（基于稀疏伪梯度交换的低通信数据并行）与激活和激活梯度压缩的流水线模型并行结合。

Result: 在大规模语言建模实验（178M-1B参数）中，激活压缩与SparseLoCo结合成本适中，选择性（异构）压缩相比压缩所有副本能持续改善损失-通信权衡，特别是在高压缩比下。

Conclusion: 研究结果表明了一条将低带宽模型并行和异构参与者纳入LLM预训练的实用路径，为在带宽受限环境中扩展大规模语言模型训练提供了可行方案。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>
