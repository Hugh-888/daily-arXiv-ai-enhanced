<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 34]
- [gr-qc](#gr-qc) [Total: 6]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [cs.LG](#cs.LG) [Total: 69]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Quantum machine learning -- lecture notes](https://arxiv.org/abs/2512.05151)
*Bojan Žunkovič*

Main category: quant-ph

TL;DR: 量子机器学习入门讲义，面向计算机科学家介绍量子计算与机器学习的交叉领域


<details>
  <summary>Details</summary>
Motivation: 随着量子计算技术的发展，量子机器学习成为新兴交叉领域。计算机科学家需要了解量子计算如何增强传统机器学习算法，以及量子机器学习的基本概念和原理。

Method: 采用讲义形式，系统介绍量子计算基础、量子机器学习算法、量子神经网络等核心概念，结合计算机科学背景进行讲解。

Result: 提供了一套完整的量子机器学习教学材料，帮助计算机科学家理解量子计算在机器学习中的应用潜力，为后续研究奠定基础。

Conclusion: 量子机器学习是一个充满潜力的新兴领域，计算机科学家需要掌握相关基础知识，以推动该领域的发展和应用。

Abstract: Lecture notes on quantum machine learning for computer scientists.

</details>


### [2] [A Mutual Information-based Metric for Temporal Expressivity and Trainability Estimation in Quantum Policy Gradient Pipelines](https://arxiv.org/abs/2512.05157)
*Jaehun Jeong,Donghwa Ji,Junghee Ryu,Kabgyun Jeong*

Main category: quant-ph

TL;DR: 该研究为量子强化学习中的参数化量子电路提出了新的表达能力定义，并证明动作分布与奖励信号分布之间的互信息可以同时反映表达能力和可训练性，为电路选择和黑盒环境中的学习进度评估提供了新标准。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习的局限性推动了强化学习和量子强化学习的发展。在量子强化学习中，基于梯度的策略梯度方法因其易于通过参数化量子电路实现而具有优势。然而，尽管已有研究量化PQCs的表达能力和可训练性，但在强化学习背景下缺乏明确的研究。因此，需要为强化学习量身定制表达能力概念，并找到能同时反映表达能力和可训练性的指标。

Method: 研究新定义了适用于强化学习背景的表达能力概念。通过理论分析证明，动作分布与奖励信号分布之间的互信息可以在某些方面同时指示表达能力和可训练性。该方法为评估不同参数化量子电路在强化学习中的性能提供了数学框架。

Result: 研究发现互信息可以作为表达能力和可训练性的有效指标。这为选择强化学习中使用的不同参数化量子电路提供了简单标准，并且能够在黑盒设置中间接估计学习进度，即使无法明确评估智能体在回合中的表现。

Conclusion: 该研究为量子强化学习领域提供了重要的理论贡献，通过新定义的表达能力概念和互信息指标，解决了电路选择和黑盒环境评估的难题，对推动量子强化学习的实际应用具有重要意义。

Abstract: In recent years, various limitations of conventional supervised learning have been highlighted, leading to the emergence of reinforcement learning -- and, further, quantum reinforcement learning that exploits quantum resources such as entanglement and superposition -- as promising alternatives. Among the various reinforcement learning methodologies, gradient-based approaches, particularly policy gradient methods, are considered to have many benefits. Moreover, in the quantum regime, they also have a profit in that they can be readily implemented through parameterized quantum circuits (PQCs). From the perspective of learning, two indicators can be regarded as most crucial: expressivity and, for gradient-based methods, trainability. While a number of attempts have been made to quantify the expressivity and trainability of PQCs, clear efforts in the context of reinforcement learning have so far been lacking. Therefore, in this study, we newly define the notion of expressivity suited to reinforcement learning and demonstrate that the mutual information between action distribution and reward-signal distribution can, in certain respects, indicate information about both expressivity and trainability. Such research is valuable in that it provides an easy criterion for choosing among various PQCs employed in reinforcement learning, and further, enables the indirect estimation of learning progress even in black-box settings where the agent's achievement aligned with the episodes cannot be explicitly evaluated.

</details>


### [3] [From Kinematics to Interference: Operational Requirements for the Quantum Principle of Relativity](https://arxiv.org/abs/2512.05164)
*Mikołaj Sienicki,Krzysztof Sienicki*

Main category: quant-ph

TL;DR: 该论文旨在为"量子相对性原理"研究项目提供组织框架，将运动学、操作内容和动力学/桥梁三个层面分开，明确需要补充什么才能使"相对论推导量子理论"成为定义良好的研究计划。


<details>
  <summary>Details</summary>
Motivation: 量子相对性原理(QPR)提出了一个雄心勃勃的想法：用形式上的超光速洛伦兹型映射扩展狭义相对论，并将由此产生的一致性约束视为量子理论结构原因的线索。然而，先前讨论强调了基本观点：写下坐标映射并不等于提供物理理论。该论文旨在为这一研究项目提供清晰的组织框架。

Method: 论文采用组织性方法，将研究分为三个独立层面：(K)运动学(存在哪些映射以及它们保留什么)，(O)操作内容(实验必须实际再现什么，特别是闭合环路干涉)，以及(D/B)动力学和桥梁(如何生成振幅和概率，以及亚光速和超光速区域如何连接)。

Result: 论文提出了一个清晰的检查清单，明确了要使"相对论推导量子理论"成为定义良好的研究计划必须添加的内容。通过将不同层面分开，为QPR研究项目提供了组织框架，而不是直接推导量子理论。

Conclusion: 该论文为量子相对性原理研究项目提供了组织框架，通过将运动学、操作内容和动力学/桥梁三个层面分开，明确了需要解决的关键问题。目标不是直接从相对论推导量子理论，而是为这一雄心勃勃的计划提供一个清晰的检查清单，使其成为定义良好的研究项目。

Abstract: The quantum principle of relativity (QPR) puts forward an ambitious idea: extend special relativity with a formally superluminal branch of Lorentz-type maps, and treat the resulting consistency constraints as hints about why quantum theory has the structure it does [1]. The discussion that followed has emphasized a basic point: writing down coordinate maps is not the same thing as providing a physical theory. In particular, quantum superposition is not operationally defined by drawing multiple paths on paper: it is defined by what happens when alternatives recombine in an interference loop [2, 3]. In parallel, careful 1+1 analyses have clarified how sign conventions and time-orientation choices enter the superluminal formulas [4]. Finally, tachyonic QFT proposals suggest a possible mathematical bridge via an enlarged (twin) Hilbert space [5], although this proposal remains contested (e.g., on commutator covariance and microcausality grounds) [6]. The aim of this short note is organizational. We keep three layers separate: (K) kinematics (which maps exist and what they preserve), (O) operational content (what an experiment must actually reproduce, especially closed-loop interference), and (D/B) dynamics and bridges (how amplitudes and probabilities are generated, and how subluminal and superluminal sectors might be linked). The goal is not relativity derives quantum theory, but a clear checklist of what must be added for that ambition to become a well-posed programme.

</details>


### [4] [Quantum compilation framework for data loading](https://arxiv.org/abs/2512.05183)
*Guillermo Alonso-Linaje,Utkarsh Azad,Jay Soni,Jarrett Smalley,Leigh Lapworth,Juan Miguel Arrazola*

Main category: quant-ph

TL;DR: 自动化量子数据加载编译框架，通过误差预算分配在精度与近似间权衡，最小化量子资源成本，支持多种先进方法，在流体动力学应用中实现超4个数量级的资源节省。


<details>
  <summary>Details</summary>
Motivation: 经典数据到量子电路的编码效率直接影响量子算法的可扩展性，需要解决量子数据加载的资源优化问题。

Method: 提出自动化编译框架，通过系统分配总误差预算到精度误差和近似误差之间，支持多路复用器加载器、QROM、稀疏编码、MPS、傅里叶级数加载器、Walsh变换等多种方法。

Result: 框架在多个应用中展现有效性，特别是在计算流体动力学工作流中，通过自动选择MPS状态准备和Walsh变换编码，结合新的Walsh测量技术，相比先前方法实现超过4个数量级的资源减少。

Conclusion: 自动化、近似感知的编译对于在资源受限硬件上实现大规模量子算法至关重要，框架展示了通过受控近似实现非明显资源高效策略的能力。

Abstract: Efficient encoding of classical data into quantum circuits is a critical challenge that directly impacts the scalability of quantum algorithms. In this work, we present an automated compilation framework for resource-aware quantum data loading tailored to a given input vector and target error tolerance. By explicitly exploiting the trade-off between exact and approximate state preparation, our approach systematically partitions the total error budget between precision and approximation errors, thereby minimizing quantum resource costs. The framework supports a comprehensive suite of state-of-the-art methods, including multiplexer-based loaders, quantum read-only memory (QROM) constructions, sparse encodings, matrix product states (MPS), Fourier series loaders (FSL), and Walsh transform-based diagonal operators. We demonstrate the effectiveness of our framework across several applications, where it consistently uncovers non-obvious, resource-efficient strategies enabled by controlled approximation. In particular, we analyze a computational fluid dynamics workflow where the automated selection of MPS state preparation and Walsh transform-based encoding, combined with a novel Walsh-based measurement technique, leads to resource reductions of over four orders of magnitude compared to previous approaches. We also introduce two independent advances developed through the framework: a more efficient circuit for d-diagonal matrices, and an optimized block encoding for kinetic energy operators. Our results underscore the indispensable role of automated, approximation-aware compilation in making large-scale quantum algorithms feasible on resource-constrained hardware.

</details>


### [5] [The deep Hilbert space of all-to-all interacting SU(3) atoms: from quantum to classical](https://arxiv.org/abs/2512.05184)
*Federico Balducci,Aleksandra A. Ziolkowska*

Main category: quant-ph

TL;DR: 研究全对全相互作用多能级原子中的混沌涌现，通过Schur-Weyl对偶性揭示希尔伯特空间碎片化，发现非对称性子空间对经典极限动力学的贡献，并提出自旋相干态的半经典描述来解释混沌起源。


<details>
  <summary>Details</summary>
Motivation: 研究多能级全对全相互作用系统中的混沌涌现，特别是超越完全对称子空间的希尔伯特空间结构，探索量子-经典对应关系，揭示多能级全对全相互作用模型的丰富结构。

Method: 采用3能级Tavis-Cummings模型在远失谐极限下，利用Schur-Weyl对偶性（基于哈密顿量的置换对称性）枚举所有不同的动力学扇区，提出基于自旋相干态的半经典描述来解释混沌或规则动力学的起源。

Result: 发现由于对称性的非阿贝尔性质导致强希尔伯特空间碎片化，某些扇区显示规则动力学而其他扇区呈现混沌；在经典极限下，除了通常研究的完全对称子空间外，许多置换对称性扇区对动力学有贡献；通过简单的几何论证解释了混沌或规则动力学的起源。

Conclusion: 该工作为混沌系统中的量子-经典对应关系研究做出贡献，揭示了多能级全对全相互作用模型的丰富结构，展示了超越完全对称子空间的动力学扇区在经典极限中的重要性。

Abstract: We study the emergence of chaos in multilevel atoms with all-to-all interactions, inspired by cavity QED. Focusing on a 3-level Tavis-Cummings model in a far detuned limit, we detail its deep Hilbert space structure -- i.e. we enumerate all distinct dynamical sectors, beyond the totally symmetric subspace -- by using the Schur-Weyl duality, which is applicable thanks to the permutation symmetry in the all-to-all Hamiltonian. Strong Hilbert space fragmentation ensues from the non-abelian nature of the symmetry, with some sectors displaying regular dynamics and others being chaotic. We uncover that many permutation symmetry sectors contribute to the dynamics in the classical limit, in addition to the commonly studied totally symmetric subspace. To elucidate the dynamical responses in each of the symmetry sectors, we propose a semiclassical description in terms of spin coherent states, which is also able to explain the origin of chaotic or regular dynamics with a simple geometrical argument. Our work contributes to the study of the quantum-classical correspondence in chaotic systems, and uncovers a rich structure in multilevel all-to-all interacting models.

</details>


### [6] [Investigating a Quantum-Inspired Method for Quantum Dynamics](https://arxiv.org/abs/2512.05185)
*Bo Xiao,Benedikt Kloss,E. Miles Stoudenmire*

Main category: quant-ph

TL;DR: 该论文提出了一种结合量子算法测量重用和经典投影测量模拟的新方法，用于量子多体系统实时动力学模拟，通过利用因果光锥结构和交错时空演化来减少采样开销。


<details>
  <summary>Details</summary>
Motivation: 基于近期量子算法中测量重用和经典投影测量高效模拟的进展，希望将这些框架扩展到量子多体系统的实时动力学模拟中，减少采样开销并提高模拟效率。

Method: 通过交错时间和空间演化，利用因果光锥结构，当局部子系统达到目标物理时间时立即应用投影测量，从而抑制纠缠增长。该方法结合了量子硬件优化思路和经典张量网络模拟。

Result: 相比时间演化块消减方法，该方法在相同资源下能获得更长的模拟时间；能够研究量子硬件上类似协议下的纠缠动力学；能高效获取局域可观测量以及等时和含时关联函数。

Conclusion: 量子硬件优化技术可以有益于经典张量网络模拟，而这类经典方法又能为量子模拟的实用性提供见解，展示了量子-经典模拟方法的相互促进。

Abstract: Building on recent advances in quantum algorithms which measure and reuse qubits and in efficient classical simulation leveraging projective measurements, we extend these frameworks to real-time dynamics of quantum many-body systems undergoing discrete-time and continuous-time Hamiltonian evolution, and find improvements that significantly reduce sampling overhead. The approach exploits causal light-cone structure by interleaving time and space evolution and applying projective measurements as soon as local subsystems reach the target physical time, suppressing entanglement growth. Comparing to time-evolving block decimation, the method reaches longer times per sample for the same resources. We also gain the ability to study dynamics of entanglement that would be occurring on quantum hardware when following similar protocols, such as the holographic quantum dynamics simulation framework. We show how to efficiently obtain local observables as well as equal-time and time-dependent correlation functions. Our findings show how optimizations for quantum hardware can benefit classical tensor network simulations and how such classical methods can yield insights into the utility of quantum simulations.

</details>


### [7] [Multimode equilibrium approximations in light-matter systems from weak to strong coupling](https://arxiv.org/abs/2512.05196)
*Davis M. Welakuh,Vasil Rokaj,Michael Ruggenthaler,Angel Rubio*

Main category: quant-ph

TL;DR: 提出多种高效处理多模光子环境的量子电动力学方法，用于平衡态光-物质耦合系统


<details>
  <summary>Details</summary>
Motivation: 需要高效处理多模光子环境对物质系统的影响，特别是在腔量子电动力学中模拟真实材料

Method: 在长度规范中仅保留电场的极化部分，或使用少数有效模式来近似多模光子环境的影响

Result: 方法适用于从弱耦合到强耦合的各种复杂光子环境，成功应用于原子、分子模型和二维量子环

Conclusion: 为腔量子电动力学中真实材料的第一性原理模拟奠定了基础，展示了方法的通用性

Abstract: In this work, we detail different approaches to treat multi-mode photonic environments within non-relativistic quantum electrodynamics in the long-wavelength approximation efficiently. Specifically we show that for equilibrium properties of coupled light-matter systems, we can approximately capture the effects of multi-mode photonic environments on matter systems by either only keeping the polarization part of the electric field in the length-gauge formulation or by a few effective modes. We present a comprehensive set of approximation methods designed to accurately capture equilibrium phenomena in quantum light-matter systems across a range of complex photonic environments, from weak to strong coupling. These methods are applied to atomic and molecular models as well as to a two-dimensional quantum ring, demonstrating the versatility of our approach and laying the groundwork for first-principles simulations of real materials in cavity quantum electrodynamics.

</details>


### [8] [Hardware-inspired Continuous Variables Quantum Optical Neural Networks](https://arxiv.org/abs/2512.05204)
*Todor Krasimirov-Ivanov,Alba Cervera-Lierta,Paolo Stornati,Federico Centrone*

Main category: quant-ph

TL;DR: 提出了一种实验可行的连续变量量子光学神经网络框架，使用相干态编码、高斯变换加多模光子减法作为处理层、零差探测作为读出，单层即可满足通用逼近定理。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子光学天然适合神经网络建模，但需要非高斯资源来实现非线性激活函数。现有实现面临实验挑战，需要开发既实验可行又理论完备的量子光学神经网络架构。

Method: 使用相干态输入编码，高斯变换后接多模光子减法作为处理层，零差探测输出。开发了QuaNNTO库进行经典模拟，基于Wick-Isserlis展开和Bogoliubov变换精确计算非高斯态期望值，无需截断无限维希尔伯特空间。

Result: 推导出封闭形式表达式，证明架构产生自适应激活函数和量子光学神经元，单层即可满足通用逼近定理。在监督学习和态制备任务中表现出平衡的资源效率、强表达能力和泛化能力。

Conclusion: 该框架为可扩展的光子量子机器学习和复杂非高斯门合成等量子应用提供了有前景的架构，结合了实验可行性和理论完备性。

Abstract: Continuous-variables (CV) quantum optics is a natural formalism for neural networks (NNs) due to its ability to reproduce the information processing of such trainable interconnected systems. In quantum optics, Gaussian operators induce affine mappings on the quadratures of optical modes while non-Gaussian resources -- the challenging piece for physical implementation -- originate the nonlinear effects, unlocking quantum analogs of an artificial neuron. This work presents a novel experimentally-feasible framework for continuous-variable quantum optical neural networks (QONNs) developed with available photonic components: coherent states as input encoding, a general Gaussian transformation followed by multi-mode photon subtractions as the processing layer, and homodyne detection as outputs readout. The closed-form expressions of such architecture are derived demonstrating the family of adaptive activations and the quantum-optical neurons that emerge from the amount of photon-subtracted modes, proving that the proposed design satisfies the Universal Approximation Theorem within a single layer. To classically simulate the QONN training, the high-performance QuaNNTO library has been developed based on Wick--Isserlis expansion and Bogoliubov transformations, allowing multi-layer exact expectation values of non-Gaussian states without truncating the infinite-dimensional Hilbert space. Experiments on supervised learning and state-preparation tasks show balanced-resource efficiency with strong expressivity and generalization capabilities, illustrating the potential of the architecture for scalable photonic quantum machine learning and for quantum applications such as complex non-Gaussian gate synthesis.

</details>


### [9] [Constraint-oriented biased quantum search for linear constrained combinatorial optimization problems](https://arxiv.org/abs/2512.05205)
*Sören Wilkening,Timo Ziegler,Maximilian Hess*

Main category: quant-ph

TL;DR: 提出一种基于Grover算法的启发式方法框架，用于解决带线性约束的组合优化问题，通过电路优化和机器学习提升性能，在适当量子硬件下可能实现速度优势


<details>
  <summary>Details</summary>
Motivation: 扩展先前提出的Grover启发式方法，以处理更一般的带线性约束的组合优化问题，并探索量子算法在解决此类问题上的潜力

Method: 基于Grover算法的启发式框架，结合电路优化技术和机器学习方法提升算法性能

Result: 与经典求解器比较显示，在适当量子硬件条件下，该算法在速度方面具有实现量子优势的潜力

Conclusion: 提出的Grover启发式框架为解决带线性约束的组合优化问题提供了有前景的量子方法，未来在量子硬件成熟时可能实现实际优势

Abstract: In this paper, we extend a previously presented Grover-based heuristic to tackle general combinatorial optimization problems with linear constraints. We further describe the introduced method as a framework that enables performance improvements through circuit optimization and machine learning techniques. Comparisons with state-of-the-art classical solvers further demonstrate the algorithm's potential to achieve a quantum advantage in terms of speed, given appropriate quantum hardware.

</details>


### [10] [A Framework for Quantum Simulations of Energy-Loss and Hadronization in Non-Abelian Gauge Theories: SU(2) Lattice Gauge Theory in 1+1D](https://arxiv.org/abs/2512.05210)
*Zhiyao Li,Marc Illa,Martin J. Savage*

Main category: quant-ph

TL;DR: 建立量子计算框架模拟非阿贝尔规范场论中的能量损失和强子化过程，在1+1D SU(2)格点上实现重夸克运动模拟


<details>
  <summary>Details</summary>
Motivation: 理解非平衡强相互作用物质中的能量损失和强子化现象需要有效的模拟框架，量子计算机为此提供了新的可能性

Method: 将重夸克映射为量子比特，使用域分解进行量子态制备，构建可扩展量子电路处理非阿贝尔荷异质性，通过费米子SWAP操作实现重夸克运动

Result: 在IBM 18量子比特计算机上成功模拟了3个空间格点的系统，经过误差缓解后结果与经典模拟吻合良好

Conclusion: 该框架可推广到其他非阿贝尔群（包括QCD的SU(3)），为量子计算模拟强相互作用物理开辟了新途径

Abstract: Simulations of energy loss and hadronization are essential for understanding a range of phenomena in non-equilibrium strongly-interacting matter. We establish a framework for performing such simulations on a quantum computer and apply it to a heavy quark moving across a modest-sized 1+1D SU(2) lattice of light quarks. Conceptual advances with regard to simulations of non-Abelian versus Abelian theories are developed, allowing for the evolution of the energy in light quarks, of their local non-Abelian charge densities, and of their multi-partite entanglement to be computed. The non-trivial action of non-Abelian charge operators on arbitrary states suggests mapping the heavy quarks to qubits alongside the light quarks, and limits the heavy-quark motion to discrete steps among spatial lattice sites. Further, the color entanglement among the heavy quarks and light quarks is implemented using hadronic operators, and Domain Decomposition is shown to be effective in quantum state preparation. Scalable quantum circuits that account for the heterogeneity of non-Abelian charge sectors across the lattice are used to prepare the interacting ground-state wavefunction in the presence of heavy quarks. The discrete motion of heavy quarks between adjacent spatial sites is implemented using fermionic SWAP operations. Quantum simulations of the dynamics of a system on $L=3$ spatial sites are performed using IBM's ${\tt ibm\_pittsburgh}$ quantum computer using 18 qubits, for which the circuits for state preparation, motion, and one second-order Trotter step of time evolution have a two-qubit depth of 398. A suite of error mitigation techniques are used to extract the observables from the simulations, providing results that are in good agreement with classical simulations. The framework presented here generalizes straightforwardly to other non-Abelian groups, including SU(3) for quantum chromodynamics.

</details>


### [11] [Analog quantum simulation of the Lipkin-Meshkov-Glick model in a transmon qudit](https://arxiv.org/abs/2512.05237)
*Elizabeth Champion,Annie Schwartz,Muhammad A. Ijaz,Xiaohui Xu,Steve Campbell,Gabriel T. Landi,Machiel S. Blok*

Main category: quant-ph

TL;DR: 该论文通过超导transmon qudit实现了Lipkin-Meshkov-Glick模型的模拟量子模拟，展示了qudit在模拟多体物理中的优势。


<details>
  <summary>Details</summary>
Motivation: 大多数模拟量子模拟使用基于qubit的处理器，但许多物理系统更自然地用qudit（d能级系统）表示。研究旨在展示高维qudit在模拟多体物理中的潜力。

Method: 使用单个超导transmon qudit（d=9能级）作为模拟模拟器，通过旋转框架实现时间依赖局部场和单轴扭曲的演化，结合通用控制和单次读取。

Result: 成功实现了LMG模型，并详细研究了量子临界性的五个有限尺寸前兆：动力学相变、能隙闭合、Kibble-Zurek类动力学、序参数统计和激发态相变。

Conclusion: 高维transmon qudit为模拟多体物理提供了有前景的路径，所开发协议无需系统本征态先验知识，可扩展到更高维度或更复杂模型。

Abstract: The simulation of large-scale quantum systems is one of the most sought-after applications of quantum computers. Of particular interest for near-term demonstrations of quantum computational advantage are analog quantum simulations, which employ analog controls instead of digitized gates. Most analog quantum simulations to date, however, have been performed using qubit-based processors, despite the fact that many physical systems are more naturally represented in terms of qudits (i.e., $d$-level systems). Motivated by this, we present an experimental realization of the Lipkin-Meshkov-Glick (LMG) model using an analog simulator based on a single superconducting transmon qudit with up to $d = 9$ levels. This is accomplished by moving to a rotated frame in which evolution under any time-dependent local field and one-axis twisting can be realized by the application of multiple simultaneous drives. Combining this analog drive scheme with universal control and single-shot readout of the qudit state, we provide a detailed study of five finite-size precursors of quantum criticality in the LMG model: dynamical phase transitions, closing of the energy gap, Kibble-Zurek-like dynamics, statistics of the order parameter, and excited-state phase transitions. For each experiment we devise a protocol for extracting the relevant properties which does not require any prior knowledge of the system eigenstates, and can therefore be readily extended to higher dimensions or more complicated models. Our results cement high-dimensional transmon qudits as an exciting path towards simulating many-body physics.

</details>


### [12] [Boosting Work Extraction in Quantum Batteries via Continuous Environment Monitoring](https://arxiv.org/abs/2512.05244)
*Gabriele Cenedese,Giuliano Benenti,Dario Ferraro,Marco G. Genoni*

Main category: quant-ph

TL;DR: 通过耦合可连续监测的环境来减弱量子电池与充电器之间的关联，从而提高可提取功，超越理想封闭系统的极限


<details>
  <summary>Details</summary>
Motivation: 量子电池与充电器之间通常会产生量子关联，这些关联会减少可从电池中提取的功。需要找到方法来减弱这些关联以提高工作提取效率。

Method: 通过将系统与一个可连续监测的额外环境耦合，利用这种耦合来减弱量子电池与充电器之间的量子关联。该方法在腔介导的自旋-自旋模型和Dicke量子电池模型中进行验证。

Result: 研究表明，通过耦合可连续监测的环境，可以减弱量子关联，从而将可提取功提高到超越理想封闭系统所能达到的极限。

Conclusion: 利用可连续监测的环境耦合是一种有效的通用机制，可以减弱量子电池系统中的有害关联，显著提高工作提取效率，为量子电池性能优化提供了新途径。

Abstract: Quantum correlations that typically develop between a quantum battery and its charger reduce the amount of work extractable from the battery. We show that by coupling the system with an additional environment that can be continuously monitored, one can weaken these correlations and enhance work extraction beyond what is achievable in the ideal (closed system) limit. This general mechanism is illustrated using both a cavity-mediated spin-spin and Dicke quantum battery models.

</details>


### [13] [Real-time optimal quantum control for atomic magnetometers with decoherence](https://arxiv.org/abs/2512.05265)
*Julia Amoros-Binefa*

Main category: quant-ph

TL;DR: 该研究将连续量子测量和估计理论应用于光学原子磁力计，推导了瞬态磁场传感的量子极限，并开发了可实现量子极限性能的实时估计与控制架构。


<details>
  <summary>Details</summary>
Motivation: 传统量子纠缠（自旋压缩）主要提升静态或缓变场的传感灵敏度，但在瞬态事件传感（如自旋进动磁力测量）中尚未证明其优势。需要新的分析工具和理论框架来优化瞬态磁场传感性能。

Method: 1. 推导瞬态磁场传感的量子极限（噪声限制）；2. 开发基于随机主方程的量子动力学模型，采用共动高斯近似实现可扩展性；3. 设计集成扩展卡尔曼滤波器和线性二次调节器的实时估计与控制架构。

Result: 1. 证明瞬态传感的量子极限最多随传感时间和原子数N线性缩放，排除了超经典缩放的可能性；2. 开发的理论模型和EKF+LQR策略能实现量子极限性能；3. 该策略可跟踪生物相关信号（如心跳波形）并驱动原子系综进入纠缠态。

Conclusion: 该研究为瞬态磁场传感建立了完整的量子极限理论和实现框架，证明当前原子磁力计可实现量子极限的常量和波动场跟踪，为实际应用中的最优传感策略提供了理论基础。

Abstract: Quantum entanglement, in the form of spin squeezing, is known to improve the sensitivity of atomic sensors to static or slowly varying fields. Sensing transient events presents a distinct challenge, requires different analysis tools, and has not been shown to benefit from entanglement in practically important scenarios such as spin-precession magnetometry. To address this, we apply concepts from continuous quantum measurements and estimation theory to optical atomic magnetometers, aiming to accurately model these devices, interpret their measurement data, control their dynamics, and achieve optimal sensitivity. Quantifying this optimal performance requires determining a fundamental quantum limit on sensitivity. We derive this limit, imposed by noise, and show that it scales at best linearly with sensing time and atom number N, ruling out any super-classical scaling. This limit is independent of the initial state, measurement, estimator, and measurement-based feedback, and depends only on the decoherence model and the strength of field fluctuations. Thus, finding an estimator that attains this bound proves the sensing strategy optimal. To approach this limit, we develop a quantum dynamical model scalable with N, based on a co-moving Gaussian approximation of the stochastic master equation, which includes measurement backaction and decoherence. This enables a real-time estimation and control architecture integrating an extended Kalman filter with a linear quadratic regulator. Simulating the magnetometer with our model and EKF+LQR strategy shows that quantum-limited tracking of constant and fluctuating fields is within reach of current atomic magnetometers. Our sensing strategy can also track biologically relevant signals, such as heartbeat-like waveforms, and drive the atomic ensemble into an entangled state, even when the measurement record is used for feedback but later discarded.

</details>


### [14] [Non-equilibrium quantum field theory of the free-electron laser in Keldysh formalism](https://arxiv.org/abs/2512.05266)
*Loris Di Cairano*

Main category: quant-ph

TL;DR: 基于Preparata模型，使用实时Keldysh形式体系发展了自由电子激光的非平衡量子场论，将FEL阈值解释为激光普适类中的连续非平衡相变。


<details>
  <summary>Details</summary>
Motivation: 建立自由电子激光的微观量子场论描述，统一处理增益、色散和噪声，避免传统理论中这些元素作为分离的唯象成分引入。

Method: 从相对论电子束与单辐射模式耦合的微观拉格朗日量出发，构建Keldysh泛函积分，进行大N重整化，积分掉电子自由度，得到FEL模式的有效作用量。

Result: 获得了静止高斯束流下自能推迟分量和Keldysh分量的闭合解析表达式，直接编码频率牵引、能量展宽导致的增益降低以及场经历的噪声谱。低频下理论简化为Landau-Ginzburg-Keldysh描述。

Conclusion: 该理论为Vlasov-Maxwell FEL理论的最小开放量子场论类比，其中增益、色散和噪声源于统一的自能框架而非分离的唯象成分，FEL阈值表现为激光普适类中的连续非平衡相变。

Abstract: We develop a non-equilibrium quantum field theory of the free-electron laser based on the Preparata model, using the real-time Keldysh formalism. Starting from a microscopic Lagrangian for a relativistic electron beam coupled to a single radiation mode, we construct a Keldysh functional integral, perform the large-N rescaling, and integrate out the electronic degrees of freedom. This yields an effective action for the FEL mode in which dispersion, gain, and noise are all generated by a single electronic self-energy built from the current correlations of the beam. For a stationary Gaussian beam, we obtain closed analytic expressions for the retarded and Keldysh components of the self-energy, which directly encode frequency pulling, gain reduction due to energy spread, and the noise spectrum experienced by the field. At low frequency, the theory reduces to a Landau-Ginzburg-Keldysh description of a single complex mode with a mass, growth rate, nonlinearity, and noise strength fully determined by beam current, energy spread, and detuning. In this framework, the FEL threshold appears as a continuous non-equilibrium phase transition in the laser universality class: the coherent field amplitude plays the role of an order parameter, while the amplitude of critical fluctuations is fixed by the microscopic noise kernel. The result is a minimal open quantum field theory analog of Vlasov-Maxwell FEL theory, in which gain, dispersion, and noise arise from a unified self-energy framework rather than from separate phenomenological ingredients.

</details>


### [15] [Photoelectrical detection and characterization of divacancy and PL5-PL7 spins in silicon carbide](https://arxiv.org/abs/2512.05283)
*Naoya Morioka,Tetsuri Nishikawa,Hiroshi Abe,Takeshi Ohshima,Norikazu Mizuochi*

Main category: quant-ph

TL;DR: 该论文展示了室温下对PL3、PL5、PL6和PL7自旋缺陷的光电探测磁共振，发现PL7和PL5比PL6更适合电学读出，并确定了PL7的零场分裂参数。


<details>
  <summary>Details</summary>
Motivation: 光电探测磁共振为半导体中自旋缺陷提供了一种可扩展的读取方法，特别适用于近红外发射器，因为传统光学检测在这些波长下具有挑战性。

Method: 使用光电探测磁共振技术，在室温下对PL3、PL5、PL6和PL7自旋缺陷进行相干检测，通过Rabi振荡和双频光谱分析其特性。

Result: PL7和PL5表现出比PL6更强的光电探测磁共振信号，表明更高的电离效率和更适合电学读出；发现了PL7的次级共振，确定了其零场分裂参数，并将PL3a缺陷识别为PL7。

Conclusion: 这些近红外缺陷的光电探测磁共振演示是量子电子器件发展的关键进展，澄清的自旋参数和电离特性为利用这些缺陷的量子技术提供了坚实基础。

Abstract: Photoelectrical detection of magnetic resonance (PDMR) offers a scalable alternative to optical readout of spin defects in semiconductors and is particularly promising for near-infrared (NIR) emitters, where photodetection is often challenging. Here, we demonstrate room-temperature coherent PDMR of PL3 (divacancy), PL5, PL6, and PL7 spins. PL7 and PL5 exhibit notably stronger PDMR than PL6 as opposed to optical detection, indicating higher ionization efficiency and suitability for electrical readout. Rabi oscillation and two-frequency spectroscopy reveal a previously undiscovered secondary resonance of PL7. We determine the zero-field splitting parameters of PL7 and assign the recently reported PL3a defect to PL7. The demonstrated PDMR of these NIR defects constitutes a key advancement toward quantum electronic devices. Also, the clarified spin parameters and ionization characteristics provide a solid foundation for advancing quantum technologies utilizing these defects regardless of the detection schemes.

</details>


### [16] [Highly resilient, error-protected quantum gates in a solid-state quantum network node](https://arxiv.org/abs/2512.05322)
*E. Poem,M. I. Cohen,S. Blum,D. Minin,D. Korn,O. Heifler,S. Maayani,A. Hamo,I. Bayn,N. Bar-Gill,M. Tordjman*

Main category: quant-ph

TL;DR: 该论文提出了PUDDING（功率无影响、双失谐不敏感门）框架，用于构建对振幅和频率误差都具有免疫性的量子门，在固态NV中心系统中实现了高达99.9988%保真度的两量子比特门。


<details>
  <summary>Details</summary>
Motivation: 实现高保真度量子门是量子计算和通信架构的基础，但在存在实际误差的情况下达到超越阈值量子纠错所需的控制水平是所有量子硬件平台面临的长期挑战。

Method: 结合室温随机基准测试与新型复合脉冲技术，开发了PUDDING框架——一种构建对振幅和频率误差都具有免疫性的条件门的理论框架，并在固态氮空位中心系统中进行了单量子比特和两量子比特CNOT门实验验证。

Result: 在固态NV中心系统中，系统性地测量到门误差降低了高达9倍，通过将PUDDING应用于低温环境，实现了创纪录的两量子比特门误差1.2×10⁻⁵（保真度99.9988%），远低于表面码和颜色码纠错所需的阈值。

Conclusion: PUDDING框架为新型容错量子网络提供了可行的构建模块，代表了固态系统中误差保护条件门的首次实验实现，为实现超越阈值量子纠错铺平了道路。

Abstract: High-fidelity quantum gates are a cornerstone of any quantum computing and communications architecture. Realizing such control in the presence of realistic errors at the level required for beyond-threshold quantum error correction is a long-standing challenge for all quantum hardware platforms. Here we theoretically develop and experimentally demonstrate error-protected quantum gates in a solid-state quantum network node. Our work combines room-temperature randomized benchmarking with a new class of composite pulses that are simultaneously robust to frequency and amplitude, affecting random and systematic errors. We introduce Power-Unaffected, Doubly-Detuning-Insensitive Gates (PUDDINGs) -- a theoretical framework for constructing conditional gates with immunity to both amplitude and frequency errors. For single-qubit and two-qubit CNOT gate demonstrations in a solid-state nitrogen-vacancy (NV) center in diamond, we systematically measure an improvement in the error per gate up to a factor of 9. By projecting the application of PUDDING to cryogenic temperatures we show a record two-qubit error per gate of $1.2 \times 10^{-5}$, corresponding to a fidelity of $99.9988\%$, far below the thresholds required by surface and color code error correction. These results present viable building blocks for a new class of fault-tolerant quantum networks and represent the first experimental realization of error-protected conditional gates in solid-state systems.

</details>


### [17] [Comparison of Nb and Ta Pentoxide Loss Tangents for Superconducting Quantum Devices](https://arxiv.org/abs/2512.05407)
*D. P. Goronzy,W. W. Mah,P. G. Lim,T. Guess,S. Majumder,D. A. Garcia-Wetten,M. J. Walker,J. Ramirez,W. -R. Syong,D. Bennett,M. Vissers,R. dos Reis,T. Pham,V. P. Dravid,M. C. Hersam,M. J. Bedzyk,C. R. H. McRae*

Main category: quant-ph

TL;DR: Nb2O5的TLS损耗比Ta2O5高约30%，表明使用Nb布线的量子比特受更高损耗影响


<details>
  <summary>Details</summary>
Motivation: 比较Nb和Ta的五氧化物介电损耗，以理解量子比特中的限制性损耗。虽然超导transmon量子比特常用Nb布线，但最近研究表明Ta布线性能更优

Method: 通过脉冲激光沉积在相同共面波导谐振器上沉积三种厚度的Nb2O5和Ta2O5，测量谐振器诱导的单光子、毫开尔文介电损耗

Result: Nb2O5的两能级系统(TLS)损耗比Ta2O5高约30%，表明使用Nb布线的量子比特受更高损耗影响，可能源于原生五氧化物本身以及亚氧化物的存在

Conclusion: Nb布线量子比特的更高损耗源于其原生五氧化物Nb2O5的较高TLS损耗，而Ta布线由于缺乏亚氧化物且Ta2O5损耗较低，性能更优

Abstract: Superconducting transmon qubits are commonly made with thin-film Nb wiring, but recent studies have shown increased performance with Ta wiring. In this work, we compare the resonator-induced single photon, millikelvin dielectric loss for pentoxides of Nb (Nb2O5) and Ta (Ta2O5) in order to further understand limiting losses in qubits. Nb and Ta pentoxides of three thicknesses are deposited via pulsed laser deposition onto identical coplanar waveguide resonators. The two-level system (TLS) loss in Nb2O5 is determined to be about 30% higher than that of Ta2O5. This work indicates that qubits with Nb wiring are affected by higher loss arising from the native pentoxide itself, likely in addition to the presence of suboxides, which are largely absent in Ta.

</details>


### [18] [Verifier-initiated quantum message-authentication via quantum zero-knowledge proofs](https://arxiv.org/abs/2512.05420)
*Wusheng Wang,Masahito Hayashi*

Main category: quant-ph

TL;DR: 提出了首个验证者发起的量子签名方案，允许验证者按需请求认证，无需签名者主动通信，提高了量子网络和区块链的效率。


<details>
  <summary>Details</summary>
Motivation: 现有量子认证方法需要签名者主动发起通信，造成不必要的开销。对于可扩展的量子系统和量子网络，需要更高效的按需认证机制。

Method: 将经典密码学中的零知识证明概念适配到量子设置，开发通用框架将合适的量子证明转换为验证者驱动的签名协议，并基于量子测量给出具体实现。

Result: 协议实现了强安全性保证，包括抗伪造性和对好奇验证者的隐私保护，不依赖计算硬度假设，适用于现有量子比特技术。

Conclusion: 这是首个具有形式化安全性的通用验证者发起量子签名方案，为未来量子基础设施和去中心化系统的可扩展安全认证铺平了道路。

Abstract: On-demand authentication is critical for scalable quantum systems, yet current approaches require the signer to initiate communication, creating unnecessary overhead. We introduce a new method where the verifier can request authentication only when needed, improving efficiency for quantum networks and blockchain applications. Our approach adapts the concept of zero-knowledge proofs widely used in classical cryptography to quantum settings, ensuring that verification reveals nothing about secret keys. We develop a general framework that converts any suitable quantum proof into a verifier-driven signature protocol and present a concrete implementation based on quantum measurements. The protocol achieves strong security guarantees, including resistance to forgery and privacy against curious verifiers, without relying on computational hardness assumptions and with qubit technologies. This work delivers the first general verifier-initiated quantum signature scheme with formal security, paving the way for scalable, secure authentication in future quantum infrastructures and decentralized systems.

</details>


### [19] [Nonlinear Classical Dynamics described by a Density Matrix in the Classical Limit](https://arxiv.org/abs/2512.05423)
*Gaspar Gonzalez,Angelo Plastino,Andrés Kowalski*

Main category: quant-ph

TL;DR: 在MaxEnt框架下研究非线性半经典混合系统的经典极限，证明经典极限由代表单一态的纯密度矩阵表征，能重现经典类似物的动力学


<details>
  <summary>Details</summary>
Motivation: 研究一般非线性半经典混合系统的经典极限，理解量子-经典混合系统在经典极限下的行为，验证混合动力学的自洽性

Method: 采用最大熵(MaxEnt)框架分析混合系统，推导混合动力学所需的代数约束和平滑条件，解析证明经典极限的特征

Result: 经典极限由纯密度矩阵表征，代表单一态，能精确重现经典类似物的动力学行为，并通过两个先前研究的例子验证方法

Conclusion: 在MaxEnt框架下，非线性半经典混合系统的经典极限能自洽地退化为经典动力学，为量子-经典混合系统的理论研究提供了坚实基础

Abstract: We examine the classical limit of a fairly general nonlinear semiclassical hybrid system within a MaxEnt framework. The consistency of the hybrid dynamics requires algebraic constraints on quantum operators and smoothness conditions for the classical variables. Analytically, we demonstrate that the classical limit is characterized by a pure density matrix representing a single state, which reproduces the dynamics of its classical analogue. To illustrate the methodology, we revisit and synthesize two previously studied examples.

</details>


### [20] [Concentrated Monte Carlo sampling for local observables in quantum spin chains](https://arxiv.org/abs/2512.05440)
*Wenxuan Zhang,Dingzu Wang,Dario Poletti*

Main category: quant-ph

TL;DR: 提出集中蒙特卡洛采样方法，通过优先采样局部可观测量周围区域，在短程关联系统中用更少样本获得更高精度


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法需要大量样本才能达到足够精度，但在短程关联系统中，局部观测量的准确估计更依赖于其周围区域的详细信息

Method: 集中蒙特卡洛采样方法：考虑局部可观测量周围所有可能构型，对剩余部分使用马尔可夫链蒙特卡洛进行独特采样

Result: 在自旋-1/2倾斜伊辛模型基态和自旋-1双线性-双二次模型热态中测试，CMCS在短程关联态中对局部观测量获得更高精度且所需样本显著减少

Conclusion: CMCS方法在短程关联系统中能有效加速期望值计算，展示了在哪些体系中可以获得计算加速

Abstract: Monte Carlo methods are widely used to estimate observables in many-body quantum systems. However, conventional sampling schemes often require a large number of samples to achieve sufficient accuracy. In this work we propose the concentrated Monte Carlo sampling approach, which builds on the idea that in systems with only short range correlations, to obtain accurate expectation values for local observables, one would favor detailed information in the surroundings of this observable compared to far away from it. In this approach we consider all possible configurations in the surroundings of a local observable, and unique samples from the remaining of the setup drawn using Markov chain Monte Carlo. We have tested the performance of this approach for ground states of the spin-1/2 tilted Ising model in different phases, and also for thermal states in the a spin-1 bilinear-biquadratic model. Our results demonstrate that CMCS yields higher accuracy for local observables in short-range correlated states while requiring substantially fewer samples, showcasing in which regimes one can obtain acceleration for the evaluation of expectation values.

</details>


### [21] [Shadow Tomography Against Adversaries](https://arxiv.org/abs/2512.05451)
*Maryam Aliakbarpour,Vladimir Braverman,Nai-Hui Chia,Chia-Ying Lin,Yuhan Liu,Aadil Oufkir,Yu-Ching Shen*

Main category: quant-ph

TL;DR: 本文研究了对抗性鲁棒设置下的单拷贝阴影层析成像，设计了在γ比例测量结果被恶意篡改时仍能实现接近最优误差的算法，样本复杂度与无噪声情况相同。


<details>
  <summary>Details</summary>
Motivation: 在量子测量中，部分测量结果可能被对抗性攻击者恶意篡改。现有算法如经典阴影算法在这种对抗性噪声下性能严重下降，需要设计能够抵抗对抗性噪声的鲁棒阴影层析算法。

Method: 设计了新的对抗性鲁棒阴影层析算法，通过巧妙的数据处理策略来抵抗γ比例的被篡改测量结果。算法只需要n=1/γ²·log(M/δ)个副本就能以至少1-δ的概率达到目标误差。

Result: 算法实现了ε=Õ(γ·max_i∥O_i∥_HS)的误差，当M≥d时几乎匹配最坏情况误差下界。对于秩r的状态，实现了ε=Õ(γ√r)的渐近误差和Õ(dr²/ε²)=Õ(dr/γ²)的副本复杂度。

Conclusion: 本文填补了对抗性鲁棒阴影层析成像的理论空白，设计了概念简单、易于实现的算法，在对抗性噪声下实现了接近最优的性能，且样本复杂度与无噪声情况相同，显著改进了现有方法。

Abstract: We study single-copy shadow tomography in the adversarial robust setting, where the goal is to learn the expectation values of $M$ observables $O_1, \ldots, O_M$ with $\varepsilon$ accuracy, but $γ$-fraction of the outcomes can be arbitrarily corrupted by an adversary. We show that all non-adaptive shadow tomography algorithms must incur an error of $\varepsilon=\tildeΩ(γ\min\{\sqrt{M}, \sqrt{d}\})$ for some choice of observables, even with unlimited copies. Unfortunately, the classical shadows algorithm by [HKP20] and naive algorithms that directly measure each observable suffer even more. We design an algorithm that achieves an error of $\varepsilon=\tilde{O}(γ\max_{i\in[M]}\|O_i\|_{HS})$, which nearly matches our worst-case error lower bound for $M\ge d$ and guarantees better accuracy when the observables have stronger structure. Remarkably, the algorithm only needs $n=\frac{1}{γ^2}\log(M/δ)$ copies to achieve that error with probability at least $1-δ$, matching the sample complexity of the classical shadows algorithm that achieves the same error without corrupted measurement outcomes. Our algorithm is conceptually simple and easy to implement. Classical simulation for fidelity estimation shows that our algorithm enjoys much stronger robustness than [HKP20] under adversarial noise. Finally, based on a reduction from full-state tomography to shadow tomography, we prove that for rank $r$ states, both the near-optimal asymptotic error of $\varepsilon=\tilde{O}(γ\sqrt{r})$ and copy complexity $\tilde{O}(dr^2/\varepsilon^2)=\tilde{O}(dr/γ^2)$ can be achieved for adversarially robust state tomography, closing the large gap in [ABCL25] where optimal error can only be achieved using pseudo-polynomial number of copies in $d$.

</details>


### [22] [Mechanically mediated optical-microwave quantum state transfer by feedback](https://arxiv.org/abs/2512.05457)
*Max P. Foreman,Jesse J. Slim,Warwick P. Bowen*

Main category: quant-ph

TL;DR: 该论文提出了一种基于反馈的连续光学-微波量子态转移方案，使用宽带、边带未解析腔和参数机械-微波转换，突破了传统电光机械转换器对解析边带腔的限制。


<details>
  <summary>Details</summary>
Motivation: 传统电光机械转换器虽然实现了高效率，但需要解析边带腔，在可扩展性和噪声性能方面存在局限。本文旨在放松这一约束，开发更实用的量子网络转换方案。

Method: 扩展Navarathna等人的协议，使用宽带、边带未解析腔和反馈将光学量子信息转移到机械谐振器，结合参数机械-微波转换，实现基于测量的反馈连续光学-微波量子态转移，以及全光学相干反馈的双向转移。

Result: 提出了量子转移见证者𝒲_T，用于评估转换性能，证明该方案既能保持高斯纠缠，又能超越经典转换方案。展示了量子兼容的噪声性能在当前实验能力范围内可达到。

Conclusion: 该工作为电光机械转换器开辟了新的设计空间，增强了其作为可扩展量子网络节点间连接器的候选地位，突破了传统转换器的限制。

Abstract: State transfer between light and microwaves is a key challenge in quantum networks. Promising transducers use a mechanical intermediary that couples to both fields via radiation pressure. Such electro-optomechanical devices have achieved high efficiencies, yet require resolved-sideband cavities, and generally compromise in scalability and noise performance. Here, we relax this constraint by extending the protocol of Navarathna et al. that transfers optical quantum information onto a mechanical resonator using a broadband, sideband-unresolved cavity and feedback. Combining this with parametric mechanical-to-microwave conversion, we show that continuous optical-to-microwave quantum state transfer is possible using measurement-based feedback, while all-optical coherent feedback enables bidirectional transfer. To assess the transfer, we introduce the quantum transfer witness $\mathcal{W}_T$, which -- though similar to the input-referred added noise -- also identifies whether a channel is capable of both preserving Gaussian entanglement and outperforming classical transduction schemes. Finally, we show that quantum-compatible noise performance is within reach of current experimental capabilities. Our results unlock a new design space for electro-optomechanical transducers and strengthens their candidacy as scalable quantum links between distant nodes.

</details>


### [23] [Observability Architecture for Quantum-Centric Supercomputing Workflows](https://arxiv.org/abs/2512.05484)
*Naoki Kanazawa,Yuto Morohoshi,Hitomi Takahashi,Yukio Kawashima,Hiroshi Horii,Kengo Nakajima*

Main category: quant-ph

TL;DR: 提出量子中心超级计算工作流的可观测性架构，实现跨系统与算法层的持久监控，支持可重复分析并减少冗余运行


<details>
  <summary>Details</summary>
Motivation: 量子中心超级计算工作流涉及混合经典-量子算法，具有概率性且运行在远程量子硬件上，难以解释和监控运行时性能。量子电路执行成本高，大规模HPC基础设施限制了可行试验次数，需要全面评估执行结果以支持迭代开发。

Method: 提出专门为QCSC工作流设计的可观测性架构，将遥测收集与工作负载执行解耦，实现跨系统和算法层的持久监控，保留详细的执行数据以支持可重复和回顾性分析。

Result: 应用于基于采样的量子对角化代表性工作流时，该系统揭示了求解器在多次迭代中的行为。该方法增强了QCSC环境的透明度和可重复性。

Conclusion: 该可观测性架构支持基础设施感知的算法设计和系统化实验，通过消除冗余运行来提高量子中心超级计算工作流的效率和可解释性。

Abstract: Quantum-centric supercomputing (QCSC) workflows often involve hybrid classical-quantum algorithms that are inherently probabilistic and executed on remote quantum hardware, making them difficult to interpret and limiting the ability to monitor runtime performance and behavior. The high cost of quantum circuit execution and large-scale high-performance computing (HPC) infrastructure further restricts the number of feasible trials, making comprehensive evaluation of execution results essential for iterative development. We propose an observability architecture tailored for QCSC workflows that decouples telemetry collection from workload execution, enabling persistent monitoring across system and algorithmic layers and retaining detailed execution data for reproducible and retrospective analysis, eliminating redundant runs. Applied to a representative workflow involving sample-based quantum diagonalization, our system reveals solver behavior across multiple iterations. This approach enhances transparency and reproducibility in QCSC environments, supporting infrastructure-aware algorithm design and systematic experimentation.

</details>


### [24] [Frequency-matching quantum key distribution](https://arxiv.org/abs/2512.05496)
*Hao-Tao Zhu,Yizhi Huang,Abdullah Rasmita,Chao Ding,Xiangbin Cai,Haoran Zhang,Xiongfeng Ma,Weibo Gao*

Main category: quant-ph

TL;DR: 提出使用经典光电二极管补偿激光频率差异的方法，解决量子密钥分发中的相位不稳定问题，在模式配对QKD系统中实现接近理论极限的性能。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)虽然能实现信息论安全的通信，但相位不稳定问题在许多QKD应用中仍然存在挑战，特别是在双场QKD和测量设备无关QKD等方案中。最主要的相位波动源来自独立激光器之间的频率偏移。

Method: 提出使用经典光电二极管来补偿激光频率差异的方法。将该技术应用于模式配对QKD系统，通过频率匹配解决相位稳定问题。

Result: 在296.8公里的光纤距离上，实现了接近理论极限的误码率，并超越了线性密钥率界限。该方法为独立激光器之间的频率匹配提供了实用解决方案。

Conclusion: 该方法不仅解决了QKD中的相位稳定问题，还可以扩展到其他需要精确相位稳定的领域，为实际QKD系统的实现提供了重要技术支持。

Abstract: Quantum key distribution (QKD) enables information-theoretically secure communication against eavesdropping. However, phase instability remains a challenge across many QKD applications, particularly in schemes such as twin-field QKD and measurement-device-independent QKD. The most dominant source of phase fluctuation arises from the frequency offset between independent lasers. Here we propose a method to address this issue by employing a classical photodiode to compensate for the laser frequency difference. As an application of this method, we implement this technique in a mode-pairing QKD system, achieving an error rate approaching the theoretical limit and surpassing the linear key-rate bound over a fiber distance of 296.8 km. This approach provides a practical solution for frequency matching between independent lasers and can be extended to other fields requiring precise phase stabilization.

</details>


### [25] [Quantum advantages in multiparty communication](https://arxiv.org/abs/2512.05538)
*Ankush Pandit*

Main category: quant-ph

TL;DR: 研究两发送方一接收方的多方通信场景，在维度和可区分性约束下，量子通信能系统性地超越经典极限，实现量子优势。


<details>
  <summary>Details</summary>
Motivation: 研究多方通信场景中，在维度和可区分性约束下，量子通信相对于经典通信的优势。基于Phys.Rev.A83, 062112和arXiv:2506.07699的工作，探索量子通信在多方设置中的潜力。

Method: 1. 明确表征在维度和可区分性约束下可实现的经典相关性；2. 证明量子通信能系统性地超越这些经典极限；3. 为两发送方一接收方设置开发半定层次工具，适用于两种约束类型。

Result: 1. 提供了经典相关性在约束下的显式表征；2. 证明了量子通信即使在没有预共享纠缠且接收方无输入选择的情况下，也能系统性地超越经典极限；3. 开发了适用于该设置的工具。

Conclusion: 在维度和可区分性约束下，多方通信存在明确的量子优势，量子通信能超越经典通信的极限。

Abstract: We investigate two senders and one receiver multiparty communication scenario. Following Phys.Rev.A83, 062112 and arXiv : 2506.07699, we study multiparty communication bounded by dimension and distinguishability. We provide an explicit characterization of the classical correlations achievable under these constraints. We then demonstrate that quantum communication systematically exceeds these classical limits, even in the absence of preshared entanglement and without any input choice for the receiver. Furthermore, we implement semidefinite hierarchy tools tailored to the two-sender, one-receiver setting for both types of constraints considered. Our results reveal a clear quantum advantage in multiparty communication under those restrictions.

</details>


### [26] [Measurement-based Initial Point Smoothing and Control Approach to Quantum Memory Systems](https://arxiv.org/abs/2512.05586)
*Igor G. Vladimirov,Ian R. Petersen,Guodong Shi*

Main category: quant-ph

TL;DR: 该论文提出了一种量子记忆系统，通过基于测量的经典控制器来补偿环境噪声引起的量子信息偏差，控制器利用量子输出场的观测过程来调整系统哈密顿量的经典参数。


<details>
  <summary>Details</summary>
Motivation: 量子记忆系统在环境噪声下存储量子信息时，初始动态变量会偏离初始条件，需要设计控制方案来补偿这种偏差，保持量子信息的完整性。

Method: 将系统建模为开放量子谐振子，其海森堡演化由线性Hudson-Parthasarathy量子随机微分方程描述。控制器设计为经典线性时变系统，采用线性-二次-高斯控制和固定点平滑技术，在头两阶矩层面进行控制，控制器具有分离结构，包含对初始量子变量的连续更新估计。

Result: 通过初始点平滑器形成执行器信号，最小化量子记忆系统变量在给定时间范围内与初始值的均方偏差以及控制信号的积分二次惩罚之和。

Conclusion: 该研究提出了一种结合量子系统和经典控制的混合控制方案，通过测量反馈和最优控制技术有效补偿环境噪声对量子记忆系统的影响，为量子信息存储提供了新的控制方法。

Abstract: This paper is concerned with a quantum memory system for storing quantum information in the form of its initial dynamic variables in the presence of environmental noise. In order to compensate for the deviation from the initial conditions, the classical parameters of the system Hamiltonian are affected by the actuator output of a measurement-based classical controller. The latter uses an observation process produced by a measuring apparatus from the quantum output field of the memory system. The underlying system is modelled as an open quantum harmonic oscillator whose Heisenberg evolution is governed by linear Hudson-Parthasarathy quantum stochastic differential equations. The controller is organised as a classical linear time-varying system, so that the resulting closed-loop system has quantum and classical dynamic variables. We apply linear-quadratic-Gaussian control and fixed-point smoothing at the level of the first two moments and consider controllers with a separation structure which involve a continuously updated estimate for the initial quantum variables. The initial-point smoother is used for actuator signal formation so as to minimise the sum of a mean-square deviation of the quantum memory system variables at a given time horizon from their initial values and an integral quadratic penalty on the control signal.

</details>


### [27] [Heisenberg-Weyl bosonic phase spaces: emergence, constraints and quantum informational resources](https://arxiv.org/abs/2512.05603)
*Eloi Descamps,Astghik Saharyan,Arne Keller,Pérola Milman*

Main category: quant-ph

TL;DR: 本文提出了一个连接物理相空间与编码计算表示的通用框架，强调参考系在定义计算基和连接相空间可模拟性中的关键作用，并分析了平面相空间极限下的经典可模拟行为。


<details>
  <summary>Details</summary>
Motivation: 量子计算中，相空间负性通常被认为是量子优势的必要条件，但在玻色系统中编码量子信息时，这种联系变得复杂：即使物理态表现出大的负性，对应的架构仍可能是经典可模拟的。现有框架未能一致地连接物理相空间与计算相空间的非负性。

Method: 引入一个通用框架，连接玻色系统的物理相空间结构与任意维度和编码下的计算表示。该框架强调参考系（真空选择）在定义计算基和连接相空间可模拟性中的关键作用，并分析平面（类似正交）相空间极限。

Result: 建立了物理相空间与编码计算表示之间的系统对应关系，揭示了参考系选择对计算基定义和相空间可模拟性的决定性影响。在平面相空间极限下，真正的量子特征可能逐渐消失，产生经典可模拟行为。

Conclusion: 本文提供了一个统一框架来理解玻色系统中物理相空间与计算表示之间的关系，强调参考系选择在连接两者可模拟性中的核心作用，为评估量子计算架构的经典可模拟性提供了新视角。

Abstract: Phase space quasi-probability functions provide powerful representations of quantum states and operators, as well as criteria for assessing quantum computational resources. In discrete, odd-dimensional systems (qudits), protocols involving only non-negative phase space distributions can be efficiently classically simulated. For bosonic systems, defined in continuous variables, phase space negativities are likewise necessary to prevent efficient classical simulation of the underlying physical processes. However, when quantum information is encoded in bosonic systems, this connection becomes subtler: as negativity is only a necessary property for potential quantum advantage, encoding (i.e., physical) states may exhibit large negativities while still corresponding to architectures that remain classically simulable. Several frameworks have attempted to relate non-negativity of states and gates in the computational phase space to non-negativity of processes in the physical bosonic phase space, but a consistent correspondence remains elusive. Here, we introduce a general framework that connects the physical phase space structure of bosonic systems to their encoded computational representations across arbitrary dimensions and encodings. This framework highlights the key role of the reference frame-equivalently, the choice of vacuum-in defining the computational basis and linking its phase space simulability properties to those of the physical system. Finally, we provide computational and physical interpretations of the planar (quadrature-like) phase space limit, where genuinely quantum features may gradually vanish, yielding classically simulable behavior.

</details>


### [28] [Squeezing Classical Antiferromagnets into Quantum Spin Liquids via Global Cavity Fluctuations](https://arxiv.org/abs/2512.05630)
*Charlie-Ray Mann,Mark A. Oehlgrien,Błażej Jaworowski,Giuseppe Calajó,Jamir Marino,Kyung S. Choi,Darrick E. Chang*

Main category: quant-ph

TL;DR: 利用腔量子电动力学将原子系综投影到总自旋单态子空间，从而将经典反铁磁体压缩成量子自旋液体，实现强关联量子物质


<details>
  <summary>Details</summary>
Motivation: 传统腔QED研究通常关注集体自旋现象（如超辐射、自旋压缩），但本文发现腔介导的相互作用可以用于产生新型强关联量子物质，而不仅仅是集体自旋现象

Method: 使用均匀腔介导的相互作用将系统能量投影到总自旋单态子空间（S=0），利用腔涨落将里德堡原子阵列耦合到单模腔中，将经典反铁磁体压缩成量子自旋液体

Result: 全局腔涨落能够有效将经典反铁磁体压缩成量子自旋液体，其特征包括非局域纠缠、分数化激发和涌现规范场

Conclusion: 腔QED可以作为诱导强关联现象的新资源，这可以在新一代混合光镊-腔平台中进行探索

Abstract: Cavity quantum electrodynamics with atomic ensembles is typically associated with collective spin phenomena, such as superradiance and spin squeezing, in which the atoms evolve collectively as a macroscopic spin ($S\sim N/2$) on the Bloch sphere. Surprisingly, we show that the tendency toward a collective spin description need not imply collective spin phenomena; rather, it can be exploited to generate new forms of strongly correlated quantum matter. The key idea is to use uniform cavity-mediated interactions to energetically project the system into the total-spin singlet sector ($S=0$) - a highly entangled subspace where the physics is governed entirely by cavity fluctuations. Focusing on Rydberg atom arrays coupled to a single-mode cavity, we show that global cavity fluctuations can effectively squeeze classical antiferromagnets into quantum spin liquids, characterized by non-local entanglement, fractionalized excitations, and emergent gauge fields. This work suggests that cavity QED can be a surprising resource for inducing strongly correlated phenomena, which could be explored in the new generation of hybrid tweezer-cavity platforms.

</details>


### [29] [Randomness quantification in spontaneous emission](https://arxiv.org/abs/2512.05713)
*Chenxu Li,Shengfan Liu,Xiongfeng Ma*

Main category: quant-ph

TL;DR: 本文为基于自发辐射的量子随机数生成器建立了量子信息理论框架，分析了两种窃听策略，发现单光子检测方案仅对第二种窃听安全，而空间模式检测方案对两种窃听都安全。


<details>
  <summary>Details</summary>
Motivation: 量子相干性是产生内在随机性的基本资源，但基于自发辐射的QRNG的随机性量化一直停留在现象学层面，缺乏严格的对抗模型和量子相干性作用的清晰描述。

Method: 开发了全面的量子信息理论框架来分析自发辐射过程中的随机性生成，表征了两种窃听策略：一种是攻击者直接访问原子系综，另一种是攻击者仅访问其纯化系统。

Result: 分析表明：单光子检测和时间模式测量的QRNG对第一种窃听策略脆弱，但对第二种窃听策略即使在原子信息最大泄漏情况下仍能保证内在随机性的下界；而基于空间模式检测和相位波动的QRNG对两种窃听策略都安全。

Conclusion: 本文为自发辐射QRNG提供了严格的随机性量化框架，揭示了不同检测方案的安全特性差异，并给出了内在随机性的定量计算，为设计更安全的QRNG提供了理论基础。

Abstract: Quantum coherence serves as a fundamental resource for generating intrinsic randomness, yet the quantification of randomness in quantum random number generators (QRNGs) based on spontaneous emission has remained largely phenomenological. Existing randomness analysis lacks rigorous adversarial models and a clear characterization of the role of quantum coherence in these systems. In this work, we develop a comprehensive quantum information-theoretic framework for randomness generation in spontaneous emission processes. We characterize two distinct eavesdropping strategies: one where the adversary directly accesses the atom ensemble, and the other where the adversary accesses only its purification. Our analysis reveals that when randomness is generated through single-photon detection and temporal mode measurements, the QRNG is vulnerable to the first adversary scenario, though it still guarantees a lower bound on intrinsic randomness against the second adversary scenario even under maximal information leakage from the atoms. In contrast, QRNGs based on spatial mode detection and phase fluctuations demonstrate security against both types of adversaries, providing robust randomness generation. Furthermore, we provide a quantitative calculation of intrinsic randomness for these spontaneous-emission-based QRNG schemes.

</details>


### [30] [Exclusive Control of Quantum Memory Erasure](https://arxiv.org/abs/2512.05761)
*Mir Alimuddin,Nathan Shettell,Raja Yehia,Antonio Acín,Federico Centrone*

Main category: quant-ph

TL;DR: 量子擦除从热力学约束转变为操作原语：擦除功成本量化了对量子内存的安全、独占控制，确保未经授权的代理无法在有限功下完全擦除信息。


<details>
  <summary>Details</summary>
Motivation: 研究量子信息处理中的记忆擦除操作，探索如何利用远程系统的相关性降低重置记忆的能量成本，并将量子擦除从热力学约束提升为操作原语。

Method: 引入辅助量子擦除概念，在设备依赖场景中证明形成纠缠精确表征独占性；在单边设备无关场景中开发基于随机去相位和条件操作的操作擦除协议。

Result: 纠缠被确立为决定性的热力学资源，擦除功成本能够量化对量子内存的安全、独占控制，保证未经授权的代理无法在有限功下完全擦除信息。

Conclusion: 量子擦除从热力学约束转变为操作原语，擦除功成本成为衡量量子内存安全、独占控制的量化指标，为量子信息处理提供了新的操作框架。

Abstract: Erasing memory is a fundamental operational task in quantum information processing, governed by Landauer's principle, which links information loss to thermodynamic work. We introduce and analyze assisted quantum erasure, where correlations with a remote system reduce the energetic cost of resetting a memory. We identify exclusive control of erasure as the central operational requirement: only a designated party should be able to achieve the minimal cost, while any adversary necessarily fails. In the device-dependent regime, we show that entanglement of formation exactly characterizes exclusivity, establishing entanglement as the decisive thermodynamic resource. Moving to a one-sided device-independent scenario, in which only the memory holder's device is trusted, we develop an operational erasure protocol based on random dephasing and conditional operations. These results elevate quantum erasure from a thermodynamic constraint to an operational primitive: the erasure work cost quantifies secure, exclusive control over quantum memory, guaranteeing that an unauthorized agent cannot fully erase information under bounded work.

</details>


### [31] [Lattice field theory for superconducting circuits](https://arxiv.org/abs/2512.05851)
*Joshua Lin,Max Hays,Stephen Sorokanich,Julian Bender,Phiala E. Shanahan,Neill C. Warrington*

Main category: quant-ph

TL;DR: 本文提出了一种基于晶格场论的新方法，用于分析大型超导量子电路，避免了传统方法中因截断无限维希尔伯特空间而引入的系统误差。


<details>
  <summary>Details</summary>
Motivation: 大型超导量子电路在量子计算中有重要应用，但从第一性原理准确预测其性能具有挑战性，因为需要求解多体薛定谔方程。现有方法如张量网络会因截断无限维希尔伯特空间而引入系统误差。

Method: 引入基于晶格场论的新方法，该方法通常应用于核物理和粒子物理领域。该方法应用于fluxonium这种具有良好量子计算特性的多组件超导量子比特，通过统计分析方法研究阻抗和接地电容的影响。

Result: 该方法能够与最先进的张量网络技术竞争，但避免了截断误差。通过对fluxonium中约瑟夫森结阵列的数千个电荷无序实例进行微观层面的显式平均，成功提取了量子比特频率和电荷噪声退相干速率。

Conclusion: 基于晶格场论的新方法为分析大型超导量子电路提供了一种准确且无截断误差的途径，这在现有其他方法中难以实现，特别适用于研究电荷噪声等微观效应。

Abstract: Large superconducting quantum circuits have a number of important applications in quantum computing. Accurately predicting the performance of these devices from first principles is challenging, as it requires solving the many-body Schrödinger equation. This work introduces a new, general ab-initio method for analyzing large quantum circuits based on lattice field theory, a tool commonly applied in nuclear and particle physics. This method is competitive with state-of-the-art techniques such as tensor networks, but avoids introducing systematic errors due to truncation of the infinite-dimensional Hilbert space associated with superconducting phases. The approach is applied to fluxonium, a specific many-component superconducting qubit with favorable qualities for quantum computation. A systematic study of the influence of impedance on fluxonium is conducted that parallels previous experimental studies, and ground capacitance effects are explored. The qubit frequency and charge noise dephasing rate are extracted from statistical analyses of charge noise, where thousands of instantiations of charge disorder in the Josephson junction array of a fixed fluxonium qubit are explicitly averaged over at the microscopic level. This is difficult to achieve with any other existing method.

</details>


### [32] [Continuous operations on non-Markovian processes](https://arxiv.org/abs/2512.05884)
*Fabio Costa,Jing Yang*

Main category: quant-ph

TL;DR: 提出基于过程和操作泛函的连续时间多时间量子过程框架，扩展离散时间过程矩阵，为连续测量提供模型无关的描述


<details>
  <summary>Details</summary>
Motivation: 连续测量在量子控制和传感中至关重要，但缺乏模型无关的操作描述，现有离散时间框架无法表示有限持续时间的测量

Method: 引入基于过程和操作泛函的连续时间扩展，推广Feynman-Vernon影响泛函，建立连续Born规则，清晰分离过程和操作

Result: 为连续监测下的非马尔可夫动力学提供一致表示，自然定义连续时间马尔可夫性，在广义Caldeira-Leggett模型中验证适用性

Conclusion: 该框架为任意非马尔可夫过程的连续测量提供了模型无关的描述工具，填补了现有离散时间框架的空白

Abstract: Continuous measurements are central to quantum control and sensing, yet lack a model-independent operational description that can be applied to arbitrary non-Markovian processes without specifying a microscopic measurement model. Existing multi-time frameworks, such as process matrices, allow for an arbitrary sequence of operations to be applied on a general process, but are restricted to interventions at discrete times and cannot represent measurements of finite duration. We introduce a continuous-time extension of multi-time quantum processes based on process and operation functionals, which generalize the Feynman-Vernon influence functional and yield a continuous Born rule that cleanly separates processes from operations. This framework provides a consistent representation of non-Markovian dynamics under continuous monitoring and leads to a natural definition of Markovianity in continuous time. We illustrate the formalism by analyzing continuous measurements in a generalized Caldeira-Leggett model, demonstrating its applicability to realistic non-Markovian scenarios.

</details>


### [33] [Spectroscopy and Coherent Control of Two-Level System Defect Ensembles Using a Broadband 3D Waveguide](https://arxiv.org/abs/2512.05934)
*Qianxu Wang,Juan S. Salcedo-Gallo,Salil Bedkihal,Tian Xia,Maciej W. Olszewski,Valla Fatemi,Mattias Fitzpatrick*

Main category: quant-ph

TL;DR: 开发宽带低温瞬态介电光谱技术，研究非晶电介质中二能级系统缺陷的集体动力学，揭示量子干涉效应和相干控制


<details>
  <summary>Details</summary>
Motivation: 非晶电介质中的二能级系统缺陷是超导量子器件退相干和能量损耗的主要来源，但表征其集体动力学比探测单个缺陷更具挑战性

Method: 基于先前开发的宽带低温瞬态介电光谱技术，在3-5 GHz宽频范围内研究二能级系统缺陷系综的相干控制和时间分辨动力学，无需完整器件制造

Result: 揭示了量子干涉效应、记忆依赖动力学和修饰态演化，提取了硅样品在4.1-4.6 GHz范围内的缺陷谱密度为84 GHz^-1，通过幅度和相位控制干涉条纹证实了相干动力学

Conclusion: BCTDS技术为宽带缺陷光谱学建立了多功能平台，为诊断退相干源、调控多体动力学和探索无序量子系统中的非平衡现象提供了新能力

Abstract: Defects in solid-state materials play a central role in determining coherence, stability, and performance in quantum technologies. Although narrowband techniques can probe specific resonances with high precision, a broadband spectroscopic approach captures the full spectrum of defect properties and dynamics. Two-level system (TLS) defects in amorphous dielectrics are a particularly important example because they are major sources of decoherence and energy loss in superconducting quantum devices. However, accessing and characterizing their collective dynamics remains far more challenging than probing individual TLS defects. Building on our previously developed Broadband Cryogenic Transient Dielectric Spectroscopy (BCTDS) technique, we study the coherent control and time-resolved dynamics of TLS defect ensembles over a wide frequency range of 3-5 GHz without requiring full device fabrication, revealing quantum interference effects, memory-dependent dynamics, and dressed-state evolution within the TLS defect bath. The spectral response reveals distinct V-shaped structures corresponding to the bare eigenmode frequencies. Using these features, we extract a TLS defect spectral density of 84 GHz^-1 for a silicon sample, across a 4.1-4.6 GHz span. Furthermore, we systematically investigate amplitude- and phase-controlled interference fringes for multiple temperatures and inter-pulse delays, providing direct evidence of coherent dynamics and control. A driven minimal spin model with dipole-dipole interactions that qualitatively capture the observed behavior is presented. Our results establish BCTDS as a versatile platform for broadband defect spectroscopy, offering new capabilities for diagnosing and mitigating sources of decoherence, engineering many-body dynamics, and exploring non-equilibrium phenomena in disordered quantum systems.

</details>


### [34] [Entanglement-Enhanced Quantum Nano-Vibrometry](https://arxiv.org/abs/2512.05961)
*Colin P. Lualdi,Joshua Rapp,Spencer J. Johnson,Michael Vayninger,Paul G. Kwiat*

Main category: quant-ph

TL;DR: 利用极端能量纠缠的光子实现纳米尺度动态系统的高频振动测量，在损耗和背景噪声下展现量子优势


<details>
  <summary>Details</summary>
Motivation: 纳米尺度动态系统研究需要高分辨率快速测量，但传统方法在损耗和背景噪声下难以实现

Method: 引入极端能量纠缠的光子进行量子双光子干涉，采用通量探测分析技术

Result: 成功恢复高达21kHz的振动信号，验证了纳米级精度和准确度，在损耗和背景噪声下观察到显著的量子优势

Conclusion: 极端能量纠缠的光子干涉技术为纳米尺度动态系统测量提供了有效的解决方案，在恶劣测量条件下具有明显优势

Abstract: The study of dynamic systems at the nanometer scale can benefit from the loss and background resilience offered by quantum two-photon interference. However, fast measurements with the required resolution are difficult to realize. As a solution, we introduce extreme energy entanglement between the photons undergoing interference. Using a flux probing analysis technique, we recover vibrational signals with frequencies as high as 21 kHz. Along with validating nanometer-scale precision and accuracy, we observe a significant quantum advantage when measuring in the presence of loss and background.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [35] [Effective $f(Q)$ model emerging from $f(Q,T)$ under a special EOS limit in symmetric cosmology with Bayesian and ANN observational constraints](https://arxiv.org/abs/2512.05142)
*Anil Kumar Yadav,S. H. Shekh,N. Myrzakulov*

Main category: gr-qc

TL;DR: 研究f(Q,T)引力理论在特殊状态方程条件ρ+p=0下导出的有效f(Q)模型的宇宙学意义，该模型背景演化与ΛCDM一致，并通过CC、BAO和Pantheon+数据集约束参数，比较传统MCMC和ANN方法，发现ANN提供更紧的后验约束且计算更快。


<details>
  <summary>Details</summary>
Motivation: 探索从更一般的f(Q,T)引力理论在特殊状态方程条件下导出的有效f(Q)模型的宇宙学意义，测试其观测一致性，并解决当前宇宙学中的H_0和S_8张力问题。

Method: 在ρ+p=0条件下从f(Q,T)理论推导出有效f(Q)模型，得到函数形式f(Q)和有效宇宙学常数。使用宇宙计时器(CC)、重子声学振荡(BAO)和Pantheon+超新星数据集约束参数H_0、Ω_m和S_8。采用传统贝叶斯MCMC采样和基于机器学习的ANN模拟器进行对比分析。

Result: ANN方法相比传统MCMC提供更紧的后验约束且显著减少计算时间。模型成功再现各数据集的观测趋势，为H_0和S_8张力问题提供见解。有效非度量性暗能量场景是ΛCDM的可行替代方案。

Conclusion: 从f(Q,T)引力导出的有效非度量性暗能量模型提供了与观测一致的ΛCDM替代方案，未来高精度巡天将进一步区分这些框架。ANN方法在参数约束中表现出优越性能。

Abstract: In this work, we investigate the cosmological consequences of an effective $f(Q)$ model emerging from the more general $f(Q,T)$ gravity theory under the special equation-of-state condition $ρ+ p = 0$. Under this limit, the field equations yield the constraint $F(Q,T)H(t)=C$, implying that the function $F=f_Q$ becomes purely dependent on the nonmetricity scalar $Q$, and the background evolution mimics that of the standard $Λ$CDM model. We derive the resulting functional forms of $f(Q)$, obtain the corresponding effective cosmological constant, and analyze the physical nature of this reduction. To test the model against observations, we constrain the parameters $H_0$, $Ω_m$, and $S_8$ using cosmic chronometers (CC), baryon acoustic oscillations (BAO), and Pantheon+ SN Ia datasets. A comparative analysis is performed using both the conventional Bayesian Markov Chain Monte Carlo (MCMC) sampling and a machine-learning based Artificial Neural Network (ANN) emulator. We find that the ANN approach yields tighter posterior constraints while significantly reducing computational time. The model successfully reproduces the observational trends of each dataset and offers insights into the persistent $H_0$ and $S_8$ tensions. Our results indicate that effective nonmetricity-based dark energy scenarios derived from $f(Q,T)$ gravity provide a viable and observationally consistent alternative to $Λ$CDM, with future high-precision surveys expected to further distinguish between these frameworks.

</details>


### [36] [Images from disk and spherical accretions of Bardeen black hole surrounded by perfect fluid dark matter](https://arxiv.org/abs/2512.05147)
*Hui Zeng,Xi-Jing Wang,Yuan Meng*

Main category: gr-qc

TL;DR: 研究巴丁黑洞在完美流体暗物质环境下，受不同静态吸积模型照射时的阴影和光学外观。发现暗物质参数α和磁荷参数g对黑洞基本性质有竞争性影响，并用EHT观测数据约束暗物质参数，分析不同吸积模型对黑洞图像的影响。


<details>
  <summary>Details</summary>
Motivation: 探索暗物质如何影响黑洞的阴影和光学外观，为利用黑洞观测数据研究暗物质提供理论依据。特别关注巴丁黑洞在完美流体暗物质环境下的表现，以及如何通过黑洞图像区分经典巴丁黑洞和被暗物质包围的巴丁黑洞。

Method: 1. 分析暗物质参数|α|和磁荷参数g对黑洞基本特征量（事件视界、光子球半径、临界撞击参数、有效势能峰值）的影响；2. 使用事件视界望远镜(EHT)观测数据约束暗物质参数α；3. 基于不同吸积模型研究黑洞图像，比较暗物质参数对图像特征的影响。

Result: 1. 暗物质参数|α|增加会使事件视界、光子球半径、临界撞击参数增大，有效势能峰值降低并向r增大方向移动；磁荷参数g则有相反效果。2. 利用EHT数据发现SgrA*对暗物质参数的约束范围比M87*更严格。3. 暗物质参数|α|越大，黑洞的内阴影或中央暗区越大，但明亮环更暗淡；不同吸积模型显著影响黑洞图像。

Conclusion: 暗物质参数和磁荷参数对黑洞性质有竞争性影响，黑洞阴影和图像特征对暗物质参数敏感，这为利用黑洞观测区分经典巴丁黑洞和被暗物质包围的巴丁黑洞提供了潜在方法，也为未来利用黑洞阴影和图像研究暗物质提供了线索。

Abstract: In this paper, we investigate the shadow and optical appearance of the Bardeen black hole surrounded by perfect fluid dark matter (PFDM) illuminated by various static accretions. First, we find that as the dark matter parameter $\left|α\right|$ increases, the fundamental characteristic quantities of the black hole, the event horizon $r_h$, the photon sphere radius $r_{ph}$, and the critical impact parameter $b_{ph}$ all increase, while the peak of the effective potential $V_{\text{eff}}$ decreases and shifts toward the direction of increasing $r$. In contrast, the magnetic charge parameter $g$ suppresses $r_h$, $r_{ph}$, and $b_{ph}$, while increases the peak of $V_{\text{eff}}$ and shifts it toward the direction of decreasing $r$. This indicates a competing effect between the dark matter parameter $\left|α\right|$ and the magnetic charge parameter $g$ on the fundamental properties of the black hole. Furthermore, we use the EHT observational data to constrain the dark matter parameters $α$ and find that the constraint range given by the supermassive black hole SgrA* is stricter than that of the black hole M87*. Finally, the black hole images are studied based on different accretion models, and it is found that both dark matter parameters $α$ and accretion models significantly influence the black hole images. For larger dark matter parameters $\left|α\right|$, the inner shadow or central faint illuminating region of the Bardeen black hole surrounded by PFDM is larger but the bright ring of the image is fainter. This provides a potential method for us to distinguish between classical Bardeen black holes and Bardeen black holes surrounded by PFDM. These preliminary results may provide some clues for future investigations of dark matter using black hole shadows and images.

</details>


### [37] [Black-hole ringdown with templates capturing spin precession: a critical re-analysis of GW190521](https://arxiv.org/abs/2512.05193)
*Chiara Anselmo,Costantino Pacilio,Davide Gerosa*

Main category: gr-qc

TL;DR: 本文实现了自旋进动振幅模型，并将其应用于GW190521引力波事件的环降信号分析，发现进动效应会引起参数的系统性偏移，但环降单独分析未能提供自旋进动的强有力证据。


<details>
  <summary>Details</summary>
Motivation: 黑洞合并的环降阶段是研究强场引力的理想窗口，但现有环降分析通常忽略自旋进动效应。GW190521事件持续时间短、以合并为主，且存在相互冲突的解释，为研究环降阶段的自旋进动提供了独特机会。

Method: 采用最近发展的自旋进动振幅模型，结合基于模拟的推理流程，专门针对环降信号进行分析。对GW190521事件进行了自旋对齐和自旋进动两种分析，并在两个不同的环降起始时间进行比较。

Result: 自旋进动分析显示，进动效应会引起推断参数和次主导模式振幅的系统性偏移，但这些偏移相对较小。环降单独分析未能提供自旋进动的强有力证据，表明需要更灵敏的探测方法。

Conclusion: 研究证明了基于物理信息的自旋进动环降建模的可行性，为未来仅利用环降阶段识别引力波事件中的自旋进动铺平了道路，而环降阶段的波形系统误差预期会显著减少。

Abstract: The ringdown phase of a binary black-hole merger provides a clean probe of strong-field gravity, as it can be modeled with minimal assumptions. The quasi-normal-mode frequencies encode the mass and spin of the Kerr black-hole remnant, while the mode excitation depends on the progenitor binary. In this paper, we implement a recently developed amplitude model that captures spin precession in a simulation-based inference pipeline that specifically targets ringdown signals. We present a critical re-analysis of GW190521 -- a short-duration, merger-dominated event with conflicting interpretations. Spin-aligned and precessing analyses at two ringdown start times show that precession induces modest but systematic shifts in inferred parameters and subdominant mode amplitudes, although such ringdown-only analyses provide no strong evidence for precession. Our results demonstrate the feasibility of physics-informed precessing ringdown modelling, paving the way for the identification of spin precession in gravitational-wave events using solely their ringdown stages, where waveform systematics are expected to be substantially less prominent.

</details>


### [38] [On the regularity of deformed extremal horizons](https://arxiv.org/abs/2512.05200)
*Francesco Di Filippo,Shinji Mukohyama,José M. M. Senovilla*

Main category: gr-qc

TL;DR: 重新审视极端黑洞作为新物理放大器的观点，研究非球形极端黑洞的可行性，发现虽然某些标量应力能张量分量发散，但反作用保持有限，且满足特定几何约束时零测地线可平滑穿过视界。


<details>
  <summary>Details</summary>
Motivation: 最近有观点认为极端黑洞可以作为新物理的放大器，因为视界不稳定性会增强紫外修正效应。本文旨在重新审视这些主张，并研究一类非球形极端黑洞的可行性。

Method: 重新审视受扰动的极端Reissner-Nordström AdS黑洞的正则性，分析标量应力能张量的发散情况；研究测地线完备性，识别确保零测地线平滑穿过视界的几何约束条件。

Result: 虽然某些标量应力能张量分量发散，但反作用保持有限；发现一个简单的几何约束条件，如果满足该条件，零测地线可以平滑穿过视界，这表明存在一大类具有正则非球形视界的时空。

Conclusion: 存在一大类具有正则非球形视界的时空，这支持了极端黑洞可以作为新物理放大器的观点，但需要满足特定的几何约束条件以确保物理行为的正则性。

Abstract: It has recently been argued that extremal black holes can act as amplifiers of new physics, due to horizon instabilities that enhance the effects of ultraviolet corrections. In this paper, we revisit some of these claims and investigate the viability of a class of non-spherical extremal black holes. In particular, we revisit the regularity of perturbed extremal Reissner--Nordström AdS black holes showing that, while some certain components of the scalar stress energy tensor diverge, the backreaction remains finite. We also study geodesic completeness, identifying a simple geometric constraint which, if satisfied, ensures that null geodesics cross the horizon smoothly. This analysis suggests the existence of a broad class of spacetimes with regular non-spherical horizons.

</details>


### [39] [Repetitive Penrose process in Kerr-de Sitter black holes](https://arxiv.org/abs/2512.05491)
*Ke Wang,Xiao-Xiong Zeng*

Main category: gr-qc

TL;DR: 研究Kerr-de Sitter黑洞中的重复Penrose过程，发现宇宙学参数增强了能量提取效率和单次提取能力，同时存在类似热力学第三定律的限制。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现重复Penrose过程无法提取Kerr黑洞的所有旋转能量和RN黑洞的所有电能，暗示存在类似热力学第三定律的规律。本文旨在研究Kerr-de Sitter黑洞中的重复Penrose过程，探索宇宙学参数对能量提取过程的影响。

Method: 研究Kerr-de Sitter黑洞中的重复Penrose过程，分析宇宙学参数对能量提取的影响，比较Kerr-dS黑洞与Kerr黑洞在能量投资回报率、单次提取能力、能量利用效率等方面的差异。

Result: 1. Kerr-dS黑洞存在类似热力学第三定律的限制；2. Kerr-dS黑洞比Kerr黑洞具有更高的能量投资回报率和单次提取能力，且宇宙学参数越大，这些能力越强；3. 在较低衰变半径下，Kerr黑洞的能量利用效率和总提取能量更高；在较高衰变半径下，情况相反，Kerr-dS黑洞表现更优，这与迭代停止条件有关。

Conclusion: 宇宙学参数显著影响重复Penrose过程的能量提取特性，Kerr-dS黑洞在某些条件下比Kerr黑洞具有更好的能量提取性能，这为黑洞能量提取研究提供了新的视角。

Abstract: Recently, references [1,2] found that the repetitive Penrose process cannot extract all the extractable rotational energy of a Kerr black hole, and reference [3] found that the repetitive electric Penrose process cannot extract all the electrical energy of a Reissner-Nordström (RN) black hole. This suggests that a law analogous to the third law of thermodynamics exists for the repetitive Penrose process. In this paper, we intend to study the repetitive Penrose process in the Kerr-de Sitter (Kerr-dS) black hole. We will explore influences of the cosmological parameter on the repetitive Penrose process. The results show that, in addition to a similar third law of thermodynamics, the Kerr-dS black hole yields a higher energy return on investment (EROI) and single-extraction energy capability compared to the Kerr black hole. Specifically, the larger the cosmological parameter, the stronger the EROI and the single-extraction energy capability. Furthermore, we also find that at a lower decay radius, the Kerr black hole exhibits a higher energy utilization efficiency (EUE) and more extracted energy after the repetitive Penrose process is completed. However, at a higher decay radius, the situation is reversed, i.e., the Kerr-dS black hole exhibits a higher EUE and more extracted energy, which is due to the existence of stopping condition of the iteration.

</details>


### [40] [Tidal Love numbers for regular black holes](https://arxiv.org/abs/2512.05767)
*Rui Wang,Qi-Long Shi,Wei Xiong,Peng-Cheng Li*

Main category: gr-qc

TL;DR: 该论文研究了三种典型正则黑洞（Bardeen黑洞、亚普朗克曲率黑洞、渐近安全引力黑洞）在标量、矢量和轴向引力扰动下的潮汐Love数，发现这些正则黑洞的潮汐Love数通常非零且具有模型和模式依赖性，其高阶修正表现出类似量子场论重整化群跑动的对数尺度依赖性，揭示了经典黑洞中不存在的尺度相关潮汐响应。


<details>
  <summary>Details</summary>
Motivation: 潮汐Love数表征致密天体对外部潮汐场的响应，在广义相对论中经典Schwarzschild和Kerr黑洞的潮汐Love数为零。非零的潮汐Love数因此提供了一个观测新物理的潜在窗口。正则黑洞的内部结构（如de Sitter或Minkowski核心以及量子引力修正）可能在潮汐特性中留下独特印记。

Method: 采用格林函数方法结合系统微扰展开，对三类代表性正则黑洞（Bardeen黑洞、亚普朗克曲率黑洞、渐近安全引力黑洞）在标量、矢量和轴向引力扰动下的潮汐Love数进行统一且完全解析的研究。

Result: 正则黑洞的潮汐Love数通常非零，表现出强烈的模型和模式依赖性。在许多情况下，高阶修正发展出对数尺度依赖性，类似于量子场论中的重整化群跑动，揭示了经典黑洞中不存在的尺度相关潮汐响应。

Conclusion: 正则黑洞的内部结构（包括de Sitter或Minkowski核心以及量子引力修正）在其潮汐特性中留下独特指纹。这些结果确立了潮汐Love数作为未来引力波观测中测试正则黑洞模型的有前景的探针。

Abstract: Tidal Love numbers (TLNs) characterize the response of compact objects to external tidal fields and vanish for classical Schwarzschild and Kerr black holes in general relativity. Nonvanishing TLNs therefore provide a potential observational window into new physics. In this work, we present a unified and fully analytic study of the TLNs of three representative classes of regular black holes -- the Bardeen black hole,the black hole with sub-Planckian curvature, and the black hole arising in asymptotically safe gravity -- under scalar, vector, and axial gravitational perturbations. Employing a Green's function method combined with systematic perturbative expansions, we show that TLNs of regular black holes are generically nonzero and exhibit strong model and mode dependence. In many cases, higher-order corrections develop logarithmic scale dependence, closely resembling renormalization-group running in quantum field theory and revealing a scale-dependent tidal response absent in classical black holes. Our analysis demonstrates that the internal structure of regular black holes, including de Sitter or Minkowski cores and quantum-gravity-inspired modifications, leaves distinct fingerprints in their tidal properties. These results establish TLNs as promising probes for testing regular black hole models with future gravitational-wave observations.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [41] [A Conservative Discontinuous Galerkin Algorithm for Particle Kinetics on Smooth Manifolds](https://arxiv.org/abs/2512.05298)
*Grant Johnson,Ammar Hakim,James Juno*

Main category: physics.comp-ph

TL;DR: 提出了一种用于流形上粒子动力学的保守间断伽辽金算法，支持正则和非正则哈密顿表述，精确守恒粒子密度和能量，并耦合BGK碰撞算子。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在流形上进行粒子动力学模拟的数值方法，特别是为广义相对论中的动力学理论模拟奠定基础。现有方法在处理流形上的粒子运动、哈密顿表述以及碰撞过程方面存在挑战。

Method: 采用保守的间断伽辽金算法，支持正则和非正则哈密顿表述描述粒子在流形上的运动。耦合BGK碰撞算子模拟弛豫过程，通过迭代方案确保碰撞不变量（密度、动量和能量）的数值守恒。通过修改哈密顿量处理流形旋转。

Result: 算法成功应用于多个测试问题：经典Sod激波问题的动力学版本、球面和抛物面上的Kelvin-Helmholtz不稳定性（含旋转情况）。正则哈密顿表述特别高效且能精确守恒粒子密度和能量。

Conclusion: 该方法为流形上的粒子动力学模拟提供了有效的数值框架，特别是正则哈密顿表述表现出优越性能。该工作为广义相对论中的动力学理论模拟开辟了进一步发展的前景。

Abstract: A novel, conservative discontinuous Galerkin algorithm is presented for particle kinetics on manifolds. The motion of particles on the manifold is represented using using both canonical and non-canonical Hamiltonian formulations. Our schemes apply to either formulations, but the canonical formulation results in a particularly efficient scheme that also conserves particle density and energy exactly. The collisionless update is coupled to a Bhatnagar-Gross-Krook (BGK) collision operator that provides a simplified model for relaxation to local thermodynamic equilibrium. An iterative scheme is constructed to ensure collisional invariants (density, momentum and energy) are preserved numerically. Rotation of the manifold is incorporated by modifying the Hamiltonian while ensuring a canonical formulation. Several test problems, including a kinetic version of the classical Sod-shock problem, Kelvin-Helmholtz instability on the surfaces of a sphere and a paraboloid, with and without rotations, is presented. A prospectus for further development of this approach to simulation of kinetic theory in general relativity is presented.

</details>


### [42] [Hypothesis-Based Particle Detection for Accurate Nanoparticle Counting and Digital Diagnostics](https://arxiv.org/abs/2512.05346)
*Neil H. Kim,Xiao-Liu Chu,Joseph B. DeGrandchamp,Matthew R. Foreman*

Main category: physics.comp-ph

TL;DR: 提出一种基于多重假设统计检验的纳米粒子计数算法，用于数字分子诊断中的纳米粒子成像检测，无需训练数据或经验参数调整，在弱信号、可变背景等条件下保持稳健计数精度。


<details>
  <summary>Details</summary>
Motivation: 数字检测技术能够精确检测低丰度分析物，对早期疾病诊断和个性化医疗至关重要。传统阈值法或机器学习方法需要训练数据或经验参数调整，且结果解释性有限。需要一种基于成像物理和统计决策理论的解释性计数方法。

Method: 将纳米粒子计数问题构建为多重假设统计检验，基于显式成像形成模型，使用惩罚似然规则进行评估。该方法无需训练数据或经验参数调整，输出结果通过成像物理和统计决策理论直接解释。

Result: 数值模拟显示在弱信号、可变背景、放大倍数变化和适度点扩散函数失配条件下具有稳健计数精度。粒子可分辨性测试揭示了特征性错误模式。实验验证应用于SARS-CoV-2 DNA生物标志物检测的暗场图像，观察到对照组和阳性样本间粒子计数分布的统计学显著差异，并揭示了非特异性和靶标诱导的粒子聚集现象。

Conclusion: 该方法为数字分子诊断中的纳米粒子检测提供了一个可靠的框架，结合了成像物理和统计决策理论，在无需训练数据的情况下实现稳健且可解释的粒子计数。

Abstract: Digital assays represent a shift from traditional diagnostics and enable the precise detection of low-abundance analytes, critical for early disease diagnosis and personalized medicine, through discrete counting of biomolecular reporters. Within this paradigm, we present a particle counting algorithm for nanoparticle based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model and evaluated using a penalized likelihood rule. In contrast to thresholding or machine learning methods, this approach requires no training data or empirical parameter tuning, and its outputs remain interpretable through direct links to imaging physics and statistical decision theory.
  Through numerical simulations we demonstrate robust count accuracy across weak signals, variable backgrounds, magnification changes and moderate PSF mismatch. Particle resolvability tests further reveal characteristic error modes, including under-counting at very small separations and localized over-counting near the resolution limit. Practically, we also confirm the algorithm's utility, through application to experimental dark-field images comprising a nanoparticle-based assay for detection of DNA biomarkers derived from SARS-CoV-2. Statistically significant differences in particle count distributions are observed between control and positive samples. Full count statistics obtained further exhibit consistent over-dispersion, and provide insight into non-specific and target-induced particle aggregation. These results establish our method as a reliable framework for nanoparticle-based detection assays in digital molecular diagnostics.

</details>


### [43] [Beyond Adam: Disentangling Optimizer Effects in the Fine-Tuning of Atomistic Foundation Models](https://arxiv.org/abs/2512.05489)
*Xiaoqing Liu,Yangshuai Wang,Teng Zhao*

Main category: physics.comp-ph

TL;DR: 本文系统评估了七种一阶优化器在原子基础模型微调中的性能，发现AdamW和ScheduleFree在曲率条件和力精度方面表现最佳，而SGD收敛慢且不稳定。通过二阶细化阶段可进一步提升物理观测量的保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管微调对于将预训练的原子基础模型适配到特定目标系统至关重要，但优化算法对此过程的影响尚未得到充分表征。现有研究缺乏对不同优化器在材料科学不同领域（分子、晶体、液体）微调性能的系统评估。

Method: 对七种一阶优化器（Adam、AdamW、RAdam、SGD、LAMB、Ranger、ScheduleFree）在分子、晶体和液体体系中进行严格基准测试。通过预条件框架将每个优化器视为梯度依赖的线性变换，分析不同更新规则如何对有效损失Hessian施加特定谱滤波。评估能量和力精度（包括分布内和分布外配置），以及对弹性模量、声子谱和界面动力学等下游物理性质的影响。

Result: 在所有体系中，AdamW和ScheduleFree实现了最佳的曲率条件和力精度。SGD表现出收敛缓慢和不稳定性。通过简短的二阶细化阶段可以减少损失景观中的残余各向异性，提高物理观测量的保真度，而不增加推理成本。

Conclusion: 研究为选择和设计优化器提供了概念见解和实践指导，以确保通用原子间势能稳定高效的微调。优化器的选择显著影响微调后模型的准确性和物理性质预测能力，适当的二阶细化可以进一步提升性能。

Abstract: Atomistic foundation models constitute a paradigm shift in computational materials science by providing universal machine-learned interatomic potentials with broad transferability across chemical spaces. Although fine-tuning is essential for adapting these pretrained models to specific target systems, the influence of the optimization algorithm on this process remains insufficiently characterized. In this work, we perform a rigorous benchmark of seven first-order optimizers, including Adam, AdamW, RAdam, SGD, LAMB, Ranger, and ScheduleFree, for the fine-tuning of foundation models across molecular, crystalline, and liquid regimes. We evaluate these algorithms based on energy and force accuracy for both in-distribution and out-of-distribution configurations, as well as their impact on downstream physical properties such as elastic moduli, phonon spectra, and interfacial dynamics. We interpret these empirical results through a preconditioning framework that views each optimizer as a data-dependent linear transformation of the gradient. This analysis clarifies how different update rules impose specific spectral filters on the effective loss Hessian. Across all regimes, AdamW and ScheduleFree achieve superior curvature conditioning and force accuracy, whereas stochastic gradient descent exhibits slow convergence and instability. Furthermore, we demonstrate that a brief second-order refinement stage reduces residual anisotropy in the loss landscape and enhances the fidelity of physical observables without increasing inference costs. These findings provide conceptual insight and practical guidance for selecting and designing optimizers to ensure the stable and efficient fine-tuning of universal interatomic potentials.

</details>


### [44] [A Continuous Nonlinear Optimization Perspective on the Spin Glass Problem](https://arxiv.org/abs/2512.05852)
*Phil Duxbury,Carlile Lavor,Luiz Leduino de Salles-Neto*

Main category: physics.comp-ph

TL;DR: 提出一个连续非线性优化模型求解自旋玻璃问题，基于Rosenberg(1972)的理论，证明连续松弛与离散模型最优值一致，并能将连续解转换为最优离散自旋配置。


<details>
  <summary>Details</summary>
Motivation: 为自旋玻璃问题提供一个直接且概念透明的连续公式化方法，能够利用现代全局优化软件求解，作为统计物理与组合优化交叉领域研究者的实用工具。

Method: 基于Rosenberg(1972)的多线性多项式问题理论，构建连续非线性优化模型，通过问题特定的论证将连续求解器输出的解转换为最优离散自旋配置。

Result: 在标准基准实例上的计算实验表明，该方法能够匹配并在多个情况下超越最近的整数规划线性化技术。

Conclusion: 该方法为自旋玻璃问题提供了一个实用的连续公式化方法，可作为整数规划技术的补充工具，在统计物理与组合优化交叉领域具有应用价值。

Abstract: We present a continuous nonlinear optimization model for the Spin Glass Problem (SGP), building on a classical result by Rosenberg (1972), which shows that for a class of multilinear polynomial problems the optimal values of the continuous relaxation and the corresponding discrete model coincide. Using the SGP as a case study, we provide a simple, problem-specific argument showing how any optimal solution returned by a continuous solver can be converted into an optimal discrete spin configuration, even when the solver outputs non-integer values. The relaxed model remains nonconvex and does not alter the inherent computational hardness of the problem, but it offers a direct and conceptually transparent continuous formulation that can be handled by modern global optimization software. Computational experiments on standard benchmark instances indicate that this approach can match, and in several cases surpass, recent integer programming linearization techniques, making it a practical and complementary tool for researchers working at the interface between statistical physics and combinatorial optimization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques](https://arxiv.org/abs/2512.05169)
*Abdelmalik Moujahid,Fadi Dornaika*

Main category: cs.LG

TL;DR: 这篇综述论文系统性地回顾了多视图聚类方法，将其分类为七种主要策略，分析了各自的优缺点和实际挑战，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 机器学习技术面临计算约束、单视图学习算法局限性以及处理来自不同领域、来源或视图的大型数据集的复杂性等挑战。多视图聚类作为一种无监督多视图学习方法，能够克服这些挑战，弥补单视图方法的不足，为各种无监督学习任务提供更丰富的数据表示和有效解决方案。

Method: 论文对多视图聚类方法进行了系统性分类，包括：协同训练、协同正则化、子空间、深度学习、基于核、基于锚点和基于图的策略。同时开发了关于集成策略（如早期融合、晚期融合和联合学习）的比较见解，并结构化地研究了医疗保健、多媒体和社交网络分析等领域的实际用例。

Result: 这篇综述涵盖了超过140篇基础性和近期出版物，提供了对多视图聚类方法的全面分析。论文识别了各种方法的优势和弱点，解决了可扩展性和不完整数据等实际挑战，并提出了该领域的未来研究方向。

Conclusion: 多视图聚类是一个强大且有前景的研究方向，能够处理复杂的多视图数据。这篇综述填补了现有研究空白，为领域发展提供了可操作的见解，并指出了跨学科应用和新兴趋势的未来发展方向。

Abstract: Machine learning techniques face numerous challenges to achieve optimal performance. These include computational constraints, the limitations of single-view learning algorithms and the complexity of processing large datasets from different domains, sources or views. In this context, multi-view clustering (MVC), a class of unsupervised multi-view learning, emerges as a powerful approach to overcome these challenges. MVC compensates for the shortcomings of single-view methods and provides a richer data representation and effective solutions for a variety of unsupervised learning tasks. In contrast to traditional single-view approaches, the semantically rich nature of multi-view data increases its practical utility despite its inherent complexity. This survey makes a threefold contribution: (1) a systematic categorization of multi-view clustering methods into well-defined groups, including co-training, co-regularization, subspace, deep learning, kernel-based, anchor-based, and graph-based strategies; (2) an in-depth analysis of their respective strengths, weaknesses, and practical challenges, such as scalability and incomplete data; and (3) a forward-looking discussion of emerging trends, interdisciplinary applications, and future directions in MVC research. This study represents an extensive workload, encompassing the review of over 140 foundational and recent publications, the development of comparative insights on integration strategies such as early fusion, late fusion, and joint learning, and the structured investigation of practical use cases in the areas of healthcare, multimedia, and social network analysis. By integrating these efforts, this work aims to fill existing gaps in MVC research and provide actionable insights for the advancement of the field.

</details>


### [46] [Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models](https://arxiv.org/abs/2512.05216)
*Rajna Fani,Rafi Al Attrach,David Restrepo,Yugang Jia,Leo Anthony Celi,Peter Schüffler*

Main category: cs.LG

TL;DR: 提出CV-Masking方法，根据生物标志物的波动性调整掩码概率，相比随机掩码在电子健康记录表示学习中表现更好


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法在电子健康记录中使用均匀随机掩码，假设所有特征同等可预测。但实际上实验室测试的波动性差异很大：有些生物标志物稳定，有些波动剧烈且更难建模。临床上，波动性大的生物标志物常提示急性病理生理变化，需要更复杂的建模来捕捉其时间模式。

Method: 提出波动性感知预训练策略CV-Masking（变异系数掩码），根据每个特征的内在变异性自适应调整掩码概率。结合与临床工作流程对齐的仅值掩码目标，该方法优于随机和基于方差的策略。

Result: 在大规模实验室测试面板上的实验表明，CV-Masking增强了重建能力，提高了下游预测性能，加速了收敛，产生了更鲁棒和临床意义更强的电子健康记录表示。

Conclusion: CV-Masking方法通过考虑生物标志物的波动性差异，为电子健康记录的表示学习提供了更有效的预训练策略，能够更好地捕捉临床相关的复杂时间模式。

Abstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly assuming all features are equally predictable. In reality, laboratory tests exhibit substantial heterogeneity in volatility: some biomarkers (e.g., sodium) remain stable, while others (e.g., lactate) fluctuate considerably and are more difficult to model. Clinically, volatile biomarkers often signal acute pathophysiology and require more sophisticated modeling to capture their complex temporal patterns. We propose a volatility-aware pretraining strategy, Coefficient of Variation Masking (CV-Masking), that adaptively adjusts masking probabilities according to the intrinsic variability of each feature. Combined with a value-only masking objective aligned with clinical workflows, CV-Masking yields systematic improvements over random and variance-based strategies. Experiments on a large panel of laboratory tests show that CV-Masking enhances reconstruction, improves downstream predictive performance, and accelerates convergence, producing more robust and clinically meaningful EHR representations.

</details>


### [47] [Rethinking Tokenization for Clinical Time Series: When Less is More](https://arxiv.org/abs/2512.05217)
*Rafi Al Attrach,Rajna Fani,David Restrepo,Yugang Jia,Peter Schüffler*

Main category: cs.LG

TL;DR: 系统评估临床时间序列建模中的分词策略，发现时间编码无显著效益，值特征重要性任务相关，冻结预训练编码器优于可训练版本且参数更少。


<details>
  <summary>Details</summary>
Motivation: 当前对电子健康记录处理中分词策略的有效性缺乏公平比较，需要系统评估不同分词方法在临床时间序列建模中的表现。

Method: 使用基于Transformer的架构，在MIMIC-IV数据集上对四个临床预测任务进行控制性消融实验，比较不同分词策略（包括时间编码、值特征、代码序列等）。

Result: 1) 明确的时间编码对评估的下游任务无一致的统计显著效益；2) 值特征的重要性任务相关，影响死亡率预测但不影响再入院预测；3) 冻结的预训练代码编码器显著优于可训练版本且参数更少；4) 更大的临床编码器在所有任务中表现一致更好。

Conclusion: 更简单、参数高效的方法在许多情况下能取得良好性能，但最优分词策略仍取决于具体任务。研究为公平比较分词策略提供了框架，并展示了临床建模中参数效率的重要性。

Abstract: Tokenization strategies shape how models process electronic health records, yet fair comparisons of their effectiveness remain limited. We present a systematic evaluation of tokenization approaches for clinical time series modeling using transformer-based architectures, revealing task-dependent and sometimes counterintuitive findings about temporal and value feature importance. Through controlled ablations across four clinical prediction tasks on MIMIC-IV, we demonstrate that explicit time encodings provide no consistent statistically significant benefit for the evaluated downstream tasks. Value features show task-dependent importance, affecting mortality prediction but not readmission, suggesting code sequences alone can carry sufficient predictive signal. We further show that frozen pretrained code encoders dramatically outperform their trainable counterparts while requiring dramatically fewer parameters. Larger clinical encoders provide consistent improvements across tasks, benefiting from frozen embeddings that eliminate computational overhead. Our controlled evaluation enables fairer tokenization comparisons and demonstrates that simpler, parameter-efficient approaches can, in many cases, achieve strong performance, though the optimal tokenization strategy remains task-dependent.

</details>


### [48] [Mitigating the Antigenic Data Bottleneck: Semi-supervised Learning with Protein Language Models for Influenza A Surveillance](https://arxiv.org/abs/2512.05222)
*Yanhua Xu*

Main category: cs.LG

TL;DR: 结合预训练蛋白质语言模型与半监督学习，可在标记数据稀缺时保持高预测准确性，解决流感病毒抗原性检测瓶颈


<details>
  <summary>Details</summary>
Motivation: 流感A病毒抗原性进化快，需要频繁更新疫苗，但传统的血凝抑制试验劳动密集且难以规模化，导致基因组数据远多于可用的表型标记，限制了传统监督模型的有效性

Method: 评估两种半监督学习策略（自训练和标签传播），使用四种PLM衍生嵌入（ESM-2、ProtVec、ProtT5、ProtBert）应用于血凝素序列，通过嵌套交叉验证框架模拟低标记数据场景

Result: 半监督学习在标记稀缺情况下持续改善性能；自训练与ProtVec组合产生最大相对增益；ESM-2保持高度稳健，仅用25%标记数据即可达到0.82以上的F1分数；H1N1和H9N2预测准确度高，H3N2亚型仍有挑战但半监督学习缓解了性能下降

Conclusion: 整合蛋白质语言模型与半监督学习可以解决抗原性标记瓶颈，更有效地利用未标记的监测序列，支持快速变异优先排序和及时的疫苗株选择

Abstract: Influenza A viruses (IAVs) evolve antigenically at a pace that requires frequent vaccine updates, yet the haemagglutination inhibition (HI) assays used to quantify antigenicity are labor-intensive and unscalable. As a result, genomic data vastly outpace available phenotypic labels, limiting the effectiveness of traditional supervised models. We hypothesize that combining pre-trained Protein Language Models (PLMs) with Semi-Supervised Learning (SSL) can retain high predictive accuracy even when labeled data are scarce. We evaluated two SSL strategies, Self-training and Label Spreading, against fully supervised baselines using four PLM-derived embeddings (ESM-2, ProtVec, ProtT5, ProtBert) applied to haemagglutinin (HA) sequences. A nested cross-validation framework simulated low-label regimes (25%, 50%, 75%, and 100% label availability) across four IAV subtypes (H1N1, H3N2, H5N1, H9N2). SSL consistently improved performance under label scarcity. Self-training with ProtVec produced the largest relative gains, showing that SSL can compensate for lower-resolution representations. ESM-2 remained highly robust, achieving F1 scores above 0.82 with only 25% labeled data, indicating that its embeddings capture key antigenic determinants. While H1N1 and H9N2 were predicted with high accuracy, the hypervariable H3N2 subtype remained challenging, although SSL mitigated the performance decline. These findings demonstrate that integrating PLMs with SSL can address the antigenicity labeling bottleneck and enable more effective use of unlabeled surveillance sequences, supporting rapid variant prioritization and timely vaccine strain selection.

</details>


### [49] [Variance Matters: Improving Domain Adaptation via Stratified Sampling](https://arxiv.org/abs/2512.05226)
*Andrea Napoli,Paul White*

Main category: cs.LG

TL;DR: 提出VaRDASS方法，通过分层采样减少无监督域适应中的方差，提高域差异估计准确性


<details>
  <summary>Details</summary>
Motivation: 无监督域适应（UDA）在随机设置中域差异估计存在高方差问题，这会阻碍方法的理论优势，需要专门的方差减少技术

Method: 提出VaRDASS方法，针对相关性对齐和最大均值差异（MMD）两种域差异度量，推导分层采样目标，并设计k-means风格优化算法

Result: 在三个域偏移数据集上实验表明，该方法提高了域差异估计准确性和目标域性能

Conclusion: VaRDASS是首个专门针对UDA的随机方差减少技术，在特定假设下对MMD的方差减少是最优的，能有效提升域适应效果

Abstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high variance in stochastic settings, which can stifle the theoretical benefits of the method. This paper proposes Variance-Reduced Domain Adaptation via Stratified Sampling (VaRDASS), the first specialised stochastic variance reduction technique for UDA. We consider two specific discrepancy measures -- correlation alignment and the maximum mean discrepancy (MMD) -- and derive ad hoc stratification objectives for these terms. We then present expected and worst-case error bounds, and prove that our proposed objective for the MMD is theoretically optimal (i.e., minimises the variance) under certain assumptions. Finally, a practical k-means style optimisation algorithm is introduced and analysed. Experiments on three domain shift datasets demonstrate improved discrepancy estimation accuracy and target domain performance.

</details>


### [50] [MAR-FL: A Communication Efficient Peer-to-Peer Federated Learning System](https://arxiv.org/abs/2512.05234)
*Felix Mulitze,Herbert Woisetschläger,Hans Arno Jacobsen*

Main category: cs.LG

TL;DR: MAR-FL是一种新型的P2P联邦学习系统，通过迭代分组聚合大幅降低通信开销，同时保持对网络波动的鲁棒性，通信复杂度从O(N²)降至O(N log N)。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统与分布式机器学习融合需要高效且鲁棒的联邦学习方法。现有的P2P FL方法存在通信复杂度过高的问题（O(N²)），限制了实际可扩展性，特别是在无线连接对等节点和网络波动环境下。

Method: MAR-FL采用迭代分组聚合机制，通过创新的对等节点组织方式减少通信开销。系统设计能够处理不可靠的FL客户端，并可以集成隐私计算功能。

Result: MAR-FL将通信复杂度从O(N²)降低到O(N log N)，显著提升了系统可扩展性。系统在聚合轮次中随着对等节点数量增加时仍能保持有效性，同时对不可靠客户端具有鲁棒性。

Conclusion: MAR-FL为无线环境下的分布式联邦学习提供了一种高效、可扩展且鲁棒的解决方案，通过创新的分组聚合机制解决了传统P2P FL通信开销过大的问题。

Abstract: The convergence of next-generation wireless systems and distributed Machine Learning (ML) demands Federated Learning (FL) methods that remain efficient and robust with wireless connected peers and under network churn. Peer-to-peer (P2P) FL removes the bottleneck of a central coordinator, but existing approaches suffer from excessive communication complexity, limiting their scalability in practice. We introduce MAR-FL, a novel P2P FL system that leverages iterative group-based aggregation to substantially reduce communication overhead while retaining resilience to churn. MAR-FL achieves communication costs that scale as O(N log N), contrasting with the O(N^2) complexity of previously existing baselines, and thereby maintains effectiveness especially as the number of peers in an aggregation round grows. The system is robust towards unreliable FL clients and can integrate private computing.

</details>


### [51] [Edged Weisfeiler-Lehman Algorithm](https://arxiv.org/abs/2512.05238)
*Xiao Yue,Bo Liu,Feng Zhang,Guangzhi Qu*

Main category: cs.LG

TL;DR: 提出E-WL算法扩展1-WL以包含边特征，并基于此构建EGIN模型，在12个边特征图数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统GNN和1-WL算法在利用边特征方面存在局限，许多GNN模型未充分利用图数据的边特征信息，限制了在图学习任务中的表现。

Method: 提出E-WL算法扩展1-WL以纳入边特征，并基于此设计EGIN模型，通过改进的传播-聚合机制更好地利用边特征信息。

Result: 在12个边特征基准图数据集上的实验表明，EGIN模型在图表分类任务中普遍优于现有最先进的基线模型。

Conclusion: E-WL算法和EGIN模型有效解决了传统方法忽略边特征的问题，为利用边特征的图学习提供了新思路，并在多个任务中表现出优越性能。

Abstract: As a classical approach on graph learning, the propagation-aggregation methodology is widely exploited by many of Graph Neural Networks (GNNs), wherein the representation of a node is updated by aggregating representations from itself and neighbor nodes recursively. Similar to the propagation-aggregation methodology, the Weisfeiler-Lehman (1-WL) algorithm tests isomorphism through color refinement according to color representations of a node and its neighbor nodes. However, 1-WL does not leverage any edge features (labels), presenting a potential improvement on exploiting edge features in some fields. To address this limitation, we proposed a novel Edged-WL algorithm (E-WL) which extends the original 1-WL algorithm to incorporate edge features. Building upon the E-WL algorithm, we also introduce an Edged Graph Isomorphism Network (EGIN) model for further exploiting edge features, which addresses one key drawback in many GNNs that do not utilize any edge features of graph data. We evaluated the performance of proposed models using 12 edge-featured benchmark graph datasets and compared them with some state-of-the-art baseline models. Experimental results indicate that our proposed EGIN models, in general, demonstrate superior performance in graph learning on graph classification tasks.

</details>


### [52] [Bridging quantum and classical computing for partial differential equations through multifidelity machine learning](https://arxiv.org/abs/2512.05241)
*Bruno Jacob,Amanda A. Howard,Panos Stinis*

Main category: cs.LG

TL;DR: 提出多保真度学习框架，用量子求解器生成低保真度解，再通过少量经典训练数据学习修正映射，将粗糙量子解提升至高保真度精度。


<details>
  <summary>Details</summary>
Motivation: 量子PDE求解器受限于近端硬件的量子比特数和电路深度，只能生成粗糙网格解且无法长时间积分，导致低保真度结果。需要克服硬件瓶颈，使量子计算在科学计算中实现实用价值。

Method: 多保真度学习框架：先用丰富的量子求解器输出训练低保真度代理模型，然后通过多保真度神经网络架构学习修正映射，该架构平衡线性和非线性变换。在粘性Burgers方程和不可压缩Navier-Stokes流等非线性PDE上通过量子格子玻尔兹曼方法验证。

Result: 框架成功修正粗糙量子预测，实现远超经典训练窗口的时间外推。在减少昂贵高保真度模拟需求的同时，获得与经典精度竞争的结果。

Conclusion: 该工作通过弥合硬件受限量子模拟与应用需求之间的差距，为从当前量子设备中提取计算价值建立途径，推进近端量子计算在计算物理中的算法开发和实际部署。

Abstract: Quantum algorithms for partial differential equations (PDEs) face severe practical constraints on near-term hardware: limited qubit counts restrict spatial resolution to coarse grids, while circuit depth limitations prevent accurate long-time integration. These hardware bottlenecks confine quantum PDE solvers to low-fidelity regimes despite their theoretical potential for computational speedup. We introduce a multifidelity learning framework that corrects coarse quantum solutions to high-fidelity accuracy using sparse classical training data, facilitating the path toward practical quantum utility for scientific computing. The approach trains a low-fidelity surrogate on abundant quantum solver outputs, then learns correction mappings through a multifidelity neural architecture that balances linear and nonlinear transformations. Demonstrated on benchmark nonlinear PDEs including viscous Burgers equation and incompressible Navier-Stokes flows via quantum lattice Boltzmann methods, the framework successfully corrects coarse quantum predictions and achieves temporal extrapolation well beyond the classical training window. This strategy illustrates how one can reduce expensive high-fidelity simulation requirements while producing predictions that are competitive with classical accuracy. By bridging the gap between hardware-limited quantum simulations and application requirements, this work establishes a pathway for extracting computational value from current quantum devices in real-world scientific applications, advancing both algorithm development and practical deployment of near-term quantum computing for computational physics.

</details>


### [53] [When unlearning is free: leveraging low influence points to reduce computational costs](https://arxiv.org/abs/2512.05254)
*Anat Kleiman,Robert Fisher,Ben Deaner,Udi Wieder*

Main category: cs.LG

TL;DR: 提出了一种高效的机器学习遗忘框架，通过识别对模型输出影响可忽略的训练数据子集，在遗忘前减少数据集规模，实现显著的计算节省（约50%）


<details>
  <summary>Details</summary>
Motivation: 随着机器学习中数据隐私问题的日益突出，从训练模型中遗忘或移除特定数据点的能力变得越来越重要。现有的遗忘方法通常平等对待遗忘集中的所有数据点，但并非所有数据点对模型学习都有显著影响。

Method: 通过比较语言和视觉任务中的影响函数，识别对模型输出影响可忽略的训练数据子集。基于这一洞察，提出一个高效的遗忘框架，在遗忘前减少数据集规模。

Result: 在真实世界的经验示例中，该方法实现了显著的计算节省（高达约50%），同时保持了有效的遗忘效果。

Conclusion: 并非所有数据点都需要被遗忘，通过识别对模型学习影响可忽略的数据子集，可以设计出更高效的遗忘框架，在保护隐私的同时显著降低计算成本。

Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically treat all points in the forget set equally. In this work, we challenge this approach by asking whether points that have a negligible impact on the model's learning need to be removed. Through a comparative analysis of influence functions across language and vision tasks, we identify subsets of training data with negligible impact on model outputs. Leveraging this insight, we propose an efficient unlearning framework that reduces the size of datasets before unlearning leading to significant computational savings (up to approximately 50 percent) on real world empirical examples.

</details>


### [54] [DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models](https://arxiv.org/abs/2512.05287)
*Ziqi Zhang*

Main category: cs.LG

TL;DR: 提出DMAGT模型，基于多层Transformer图神经网络预测药物-miRNA关联，在多个数据集上达到95.24%的AUC，实验验证了14/20的预测关联。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验在探索药物与miRNA关联时存在效率和成本限制，需要计算模型来加速miRNA靶向药物的开发。

Method: 将药物-miRNA关联转化为图结构，使用Word2Vec嵌入药物分子结构和miRNA碱基序列特征，采用图Transformer模型学习嵌入特征和关系结构进行预测。

Result: 在ncDR、RNAInter和SM2miR三个数据集上达到最高95.24±0.05%的AUC，优于其他对比方法。对5-氟尿嘧啶和奥沙利铂两种药物的预测中，20个最可能关联中有14个得到验证。

Conclusion: DMAGT在预测药物-miRNA关联方面表现出优异的性能和稳定性，为miRNA药物开发提供了新的捷径。

Abstract: MiRNAs, due to their role in gene regulation, have paved a new pathway for pharmacology, focusing on drug development that targets miRNAs. However, traditional wet lab experiments are limited by efficiency and cost constraints, making it difficult to extensively explore potential associations between developed drugs and target miRNAs. Therefore, we have designed a novel machine learning model based on a multi-layer transformer-based graph neural network, DMAGT, specifically for predicting associations between drugs and miRNAs. This model transforms drug-miRNA associations into graphs, employs Word2Vec for embedding features of drug molecular structures and miRNA base structures, and leverages a graph transformer model to learn from embedded features and relational structures, ultimately predicting associations between drugs and miRNAs. To evaluate DMAGT, we tested its performance on three datasets composed of drug-miRNA associations: ncDR, RNAInter, and SM2miR, achieving up to AUC of $95.24\pm0.05$. DMAGT demonstrated superior performance in comparative experiments tackling similar challenges. To validate its practical efficacy, we specifically focused on two drugs, namely 5-Fluorouracil and Oxaliplatin. Of the 20 potential drug-miRNA associations identified as the most likely, 14 were successfully validated. The above experiments demonstrate that DMAGT has an excellent performance and stability in predicting drug-miRNA associations, providing a new shortcut for miRNA drug development.

</details>


### [55] [Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2512.05291)
*Na Li,Hangguan Shan,Wei Ni,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 提出RSA2C算法，通过RKHS-SHAP状态归因增强Actor-Critic方法，实现可解释性、效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有Actor-Critic方法可解释性有限，可解释RL方法很少利用状态归因辅助训练，且忽视不同状态维度对奖励的异质性影响

Method: 提出基于RKHS-SHAP的归因感知核化双时间尺度AC算法，包含Actor、Value Critic和Advantage Critic，均基于RKHS实现，使用稀疏化字典，通过RKHS-SHAP计算状态归因并转换为Mahalanobis门控权重来调节Actor梯度和Advantage Critic目标

Result: 理论上推导了状态扰动下的全局非渐近收敛界，显示通过扰动误差项实现稳定性，通过收敛误差项实现效率；在三个标准连续控制环境上的实验结果表明算法实现了效率、稳定性和可解释性

Conclusion: RSA2C算法成功将状态归因集成到Actor-Critic框架中，通过RKHS-SHAP归因和核化方法实现了可解释性、效率和稳定性的平衡

Abstract: Actor-critic (AC) methods are a cornerstone of reinforcement learning (RL) but offer limited interpretability. Current explainable RL methods seldom use state attributions to assist training. Rather, they treat all state features equally, thereby neglecting the heterogeneous impacts of individual state dimensions on the reward. We propose RKHS--SHAP-based Advanced Actor--Critic (RSA2C), an attribution-aware, kernelized, two-timescale AC algorithm, including Actor, Value Critic, and Advantage Critic. The Actor is instantiated in a vector-valued reproducing kernel Hilbert space (RKHS) with a Mahalanobis-weighted operator-valued kernel, while the Value Critic and Advantage Critic reside in scalar RKHSs. These RKHS-enhanced components use sparsified dictionaries: the Value Critic maintains its own dictionary, while the Actor and Advantage Critic share one. State attributions, computed from the Value Critic via RKHS--SHAP (kernel mean embedding for on-manifold expectations and conditional mean embedding for off-manifold expectations), are converted into Mahalanobis-gated weights that modulate Actor gradients and Advantage Critic targets. Theoretically, we derive a global, non-asymptotic convergence bound under state perturbations, showing stability through the perturbation-error term and efficiency through the convergence-error term. Empirical results on three standard continuous-control environments show that our algorithm achieves efficiency, stability, and interpretability.

</details>


### [56] [CFO: Learning Continuous-Time PDE Dynamics via Flow-Matched Neural Operators](https://arxiv.org/abs/2512.05297)
*Xianglong Hou,Xinquan Huang,Paris Perdikaris*

Main category: cs.LG

TL;DR: CFO是一种用于时间相关PDE的连续流算子框架，通过流匹配直接学习PDE右侧，避免自回归预测和均匀时间离散化，实现时间分辨率不变性和高效长时程预测。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子代理使用自回归预测方案，在长时间推演中会累积误差，且需要均匀时间离散化。现有连续方法（如神经ODE）计算负担重。需要一种既能学习连续时间PDE动态，又避免这些限制的方法。

Method: CFO框架重新利用流匹配直接学习PDE右侧，无需通过ODE求解器反向传播。方法包括：1）对轨迹数据拟合时间样条；2）在节点处使用时间导数的有限差分估计构建概率路径；3）通过流匹配训练神经算子预测这些解析速度场。

Result: 在四个基准测试（Lorenz、1D Burgers、2D扩散反应、2D浅水方程）中，CFO表现出优越的长时程稳定性和显著的数据效率。仅使用25%不规则子采样时间点训练的CFO优于使用完整数据训练的自回归基线，相对误差减少高达87%。

Conclusion: CFO提供了一种时间分辨率不变的PDE求解框架，能够处理任意非均匀时间网格，通过ODE积分实现任意时间分辨率查询，同时支持反向时间推理，在保持计算效率的同时显著提升预测精度和稳定性。

Abstract: Neural operator surrogates for time-dependent partial differential equations (PDEs) conventionally employ autoregressive prediction schemes, which accumulate error over long rollouts and require uniform temporal discretization. We introduce the Continuous Flow Operator (CFO), a framework that learns continuous-time PDE dynamics without the computational burden of standard continuous approaches, e.g., neural ODE. The key insight is repurposing flow matching to directly learn the right-hand side of PDEs without backpropagating through ODE solvers. CFO fits temporal splines to trajectory data, using finite-difference estimates of time derivatives at knots to construct probability paths whose velocities closely approximate the true PDE dynamics. A neural operator is then trained via flow matching to predict these analytic velocity fields. This approach is inherently time-resolution invariant: training accepts trajectories sampled on arbitrary, non-uniform time grids while inference queries solutions at any temporal resolution through ODE integration. Across four benchmarks (Lorenz, 1D Burgers, 2D diffusion-reaction, 2D shallow water), CFO demonstrates superior long-horizon stability and remarkable data efficiency. CFO trained on only 25% of irregularly subsampled time points outperforms autoregressive baselines trained on complete data, with relative error reductions up to 87%. Despite requiring numerical integration at inference, CFO achieves competitive efficiency, outperforming autoregressive baselines using only 50% of their function evaluations, while uniquely enabling reverse-time inference and arbitrary temporal querying.

</details>


### [57] [Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)](https://arxiv.org/abs/2512.05306)
*Y. Sungtaek Ju*

Main category: cs.LG

TL;DR: SVGP KANs：将稀疏变分高斯过程与Kolmogorov-Arnold网络结合，实现可扩展的贝叶斯推理和不确定性量化，适用于科学机器学习。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov-Arnold网络缺乏系统的不确定性量化能力，而这对科学应用至关重要。需要一种既能保持可解释性又能提供不确定性量化的架构。

Method: 将稀疏变分高斯过程推理与Kolmogorov-Arnold拓扑结构集成，通过解析矩匹配在深层加性结构中传播不确定性，计算复杂度与样本量呈准线性关系。

Result: 通过三个案例研究展示了框架区分偶然不确定性和认知不确定性的能力：流体流动重建中的异方差测量噪声校准、平流扩散动力学多步预测中的置信度退化量化、卷积自编码器中的分布外检测。

Conclusion: SVGP KANs是科学机器学习中不确定性感知学习的有前景架构，结合了可解释性和可扩展的贝叶斯推理能力。

Abstract: Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Gaussian process inference with the Kolmogorov-Arnold topology, enabling scalable Bayesian inference with computational complexity quasi-linear in sample size. Through analytic moment matching, we propagate uncertainty through deep additive structures while maintaining interpretability. We use three example studies to demonstrate the framework's ability to distinguish aleatoric from epistemic uncertainty: calibration of heteroscedastic measurement noise in fluid flow reconstruction, quantification of prediction confidence degradation in multi-step forecasting of advection-diffusion dynamics, and out-of-distribution detection in convolutional autoencoders. These results suggest Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KANs) is a promising architecture for uncertainty-aware learning in scientific machine learning.

</details>


### [58] [The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?](https://arxiv.org/abs/2512.05311)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee*

Main category: cs.LG

TL;DR: 研究评估了SOTA模型区分人类与LLM生成科学想法的能力，发现连续改写会显著降低检测性能，而加入研究问题作为上下文可略微提升检测效果


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为研究代理的日益普及，区分LLM与人类生成的想法对于理解LLM研究能力的认知差异变得至关重要。虽然检测LLM生成文本已有广泛研究，但区分人类与LLM生成的科学想法仍是一个未探索的领域

Method: 系统评估了最先进的机器学习模型区分人类与LLM生成想法的能力，特别是在连续改写阶段后。研究了加入研究问题作为上下文信息对检测性能的影响，并分析了不同改写风格对检测难度的影响

Result: SOTA模型在来源归因方面面临挑战，连续五次改写后检测性能平均下降25.4%。加入研究问题作为上下文可将检测性能提升最多2.97%。检测算法在想法被改写成简化的非专家风格时表现最差，这是导致可区分LLM特征消失的主要原因

Conclusion: 区分人类与LLM生成的科学想法具有挑战性，连续改写会显著降低检测性能，而简化的改写风格对检测算法构成最大困难。上下文信息可略微改善检测效果，但总体而言，LLM生成想法的检测仍是一个需要进一步研究的难题

Abstract: With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs' research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.

</details>


### [59] [Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay](https://arxiv.org/abs/2512.05320)
*Mehmet Efe Lorasdagi,Dogan Can Cicek,Furkan Burak Mutlu,Suleyman Serdar Kozat*

Main category: cs.LG

TL;DR: 提出DPER方法，通过为Actor和Critic网络分别采样不同的transition批次，改进深度确定性策略梯度算法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统Actor-Critic架构中，两个网络使用相同的transition批次进行训练，但它们的优化目标和更新动态不同，这种统一的采样方式可能不是最优的。

Method: 提出Decoupled Prioritized Experience Replay (DPER)，允许为Actor和Critic独立采样transition批次。该方法可集成到任何连续控制领域的off-policy深度强化学习算法中，并与Twin Delayed DDPG算法结合。

Result: DPER在多个MuJoCo任务中，优于传统的经验回放策略（如vanilla经验回放和优先经验回放）。

Conclusion: 解耦Actor和Critic的经验回放可以改善训练动态和最终策略质量。DPER为广泛的actor-critic off-policy强化学习算法提供了通用的性能提升机制。

Abstract: Background: Deep Deterministic Policy Gradient-based reinforcement learning algorithms utilize Actor-Critic architectures, where both networks are typically trained using identical batches of replayed transitions. However, the learning objectives and update dynamics of the Actor and Critic differ, raising concerns about whether uniform transition usage is optimal.
  Objectives: We aim to improve the performance of deep deterministic policy gradient algorithms by decoupling the transition batches used to train the Actor and the Critic. Our goal is to design an experience replay mechanism that provides appropriate learning signals to each component by using separate, tailored batches.
  Methods: We introduce Decoupled Prioritized Experience Replay (DPER), a novel approach that allows independent sampling of transition batches for the Actor and the Critic. DPER can be integrated into any off-policy deep reinforcement learning algorithm that operates in continuous control domains. We combine DPER with the state-of-the-art Twin Delayed DDPG algorithm and evaluate its performance across standard continuous control benchmarks.
  Results: DPER outperforms conventional experience replay strategies such as vanilla experience replay and prioritized experience replay in multiple MuJoCo tasks from the OpenAI Gym suite.
  Conclusions: Our findings show that decoupling experience replay for Actor and Critic networks can enhance training dynamics and final policy quality. DPER offers a generalizable mechanism that enhances performance for a wide class of actor-critic off-policy reinforcement learning algorithms.

</details>


### [60] [Robustness Test for AI Forecasting of Hurricane Florence Using FourCastNetv2 and Random Perturbations of the Initial Condition](https://arxiv.org/abs/2512.05323)
*Adam Lizerbram,Shane Stevenson,Iman Khadir,Matthew Tu,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 测试AI天气预报模型FourCastNetv2对输入噪声的鲁棒性，通过注入高斯噪声到飓风初始条件和完全随机初始条件来评估模型输出稳定性


<details>
  <summary>Details</summary>
Motivation: 评估AI天气预报模型对输入噪声和不确定性的鲁棒性对于确保极端天气事件（如飓风）预测的可靠性至关重要

Method: 进行两个实验：1）在飓风Florence的ERA5初始条件中注入不同水平的高斯噪声，评估轨迹和强度预测；2）使用完全随机初始条件，观察模型对无意义输入的响应

Result: FCNv2在低到中等噪声下能准确保持飓风特征；高噪声下仍保持基本轨迹和结构但位置精度下降；模型在所有噪声水平下都低估风暴强度和持续性；完全随机初始条件后几个时间步生成平滑连贯的预测

Conclusion: FCNv2对输入噪声表现出良好的鲁棒性，倾向于生成稳定平滑的输出，该方法简单且可移植到其他数据驱动的AI天气预报模型

Abstract: Understanding the robustness of a weather forecasting model with respect to input noise or different uncertainties is important in assessing its output reliability, particularly for extreme weather events like hurricanes. In this paper, we test sensitivity and robustness of an artificial intelligence (AI) weather forecasting model: NVIDIAs FourCastNetv2 (FCNv2). We conduct two experiments designed to assess model output under different levels of injected noise in the models initial condition. First, we perturb the initial condition of Hurricane Florence from the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset (September 13-16, 2018) with varying amounts of Gaussian noise and examine the impact on predicted trajectories and forecasted storm intensity. Second, we start FCNv2 with fully random initial conditions and observe how the model responds to nonsensical inputs. Our results indicate that FCNv2 accurately preserves hurricane features under low to moderate noise injection. Even under high levels of noise, the model maintains the general storm trajectory and structure, although positional accuracy begins to degrade. FCNv2 consistently underestimates storm intensity and persistence across all levels of injected noise. With full random initial conditions, the model generates smooth and cohesive forecasts after a few timesteps, implying the models tendency towards stable, smoothed outputs. Our approach is simple and portable to other data-driven AI weather forecasting models.

</details>


### [61] [Non-Convex Federated Optimization under Cost-Aware Client Selection](https://arxiv.org/abs/2512.05327)
*Xiaowen Jiang,Anton Rodomanov,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦优化模型，能够量化不同客户端选择策略的通信和本地计算成本，并基于此开发了RG-SAGA算法，在非凸优化中实现了最优的通信和本地计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有联邦优化算法的比较指标通常不区分不同的客户端选择策略（随机采样、全客户端通信或混合方案），而这些策略在实际中具有不同的通信成本。需要一个新的模型来量化这些差异。

Method: 1. 引入一个简单自然的联邦优化模型，量化通信和本地计算复杂度；2. 基于SAGA方差缩减梯度估计器，推导新的方差界限；3. 提出递归梯度技术改进条件无偏梯度估计器的误差界限；4. 将递归梯度技术应用于SAGA，得到RG-SAGA新估计器；5. 基于不精确复合梯度方法和精心构造的梯度估计器设计新算法。

Result: 提出的新算法在非凸优化的联邦优化方法中实现了已知最佳的通信和本地计算复杂度。RG-SAGA相比原始SAGA具有改进的误差界限。

Conclusion: 通过量化不同客户端选择策略的成本差异，并开发基于递归梯度技术的RG-SAGA算法，本文为联邦优化提供了更准确的比较框架和更高效的优化方法。

Abstract: Different federated optimization algorithms typically employ distinct client-selection strategies: some methods communicate only with a randomly sampled subset of clients at each round, while others need to periodically communicate with all clients or use a hybrid scheme that combines both strategies. However, existing metrics for comparing optimization methods typically do not distinguish between these strategies, which often incur different communication costs in practice. To address this disparity, we introduce a simple and natural model of federated optimization that quantifies communication and local computation complexities. This new model allows for several commonly used client-selection strategies and explicitly associates each with a distinct cost. Within this setting, we propose a new algorithm that achieves the best-known communication and local complexities among existing federated optimization methods for non-convex optimization. This algorithm is based on the inexact composite gradient method with a carefully constructed gradient estimator and a special procedure for solving the auxiliary subproblem at each iteration. The gradient estimator is based on SAGA, a popular variance-reduced gradient estimator. We first derive a new variance bound for it, showing that SAGA can exploit functional similarity. We then introduce the Recursive-Gradient technique as a general way to potentially improve the error bound of a given conditionally unbiased gradient estimator, including both SAGA and SVRG. By applying this technique to SAGA, we obtain a new estimator, RG-SAGA, which has an improved error bound compared to the original one.

</details>


### [62] [PathFinder: MCTS and LLM Feedback-based Path Selection for Multi-Hop Question Answering](https://arxiv.org/abs/2512.05336)
*Durga Prasad Maram,Kalpa Gunaratna,Vijay Srinivasan,Haris Jeelani,Srinivas Chappidi*

Main category: cs.LG

TL;DR: PATHFINDER使用蒙特卡洛树搜索生成训练路径轨迹，通过子答案召回和LLM作为评判者过滤错误轨迹，并重新表述子查询处理检索失败，从而提升多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于训练的多跳问答方法仍受LLM幻觉和错误推理路径影响，导致性能受限，需要更可靠的训练数据生成和验证机制。

Method: 1) 使用蒙特卡洛树搜索生成训练路径轨迹；2) 通过子答案召回和LLM作为评判者验证过滤错误和冗长轨迹；3) 重新表述子查询处理检索失败情况。

Result: PATHFINDER在公开基准数据集上提升了多跳问答的性能表现。

Conclusion: 通过改进训练数据质量和处理检索失败，PATHFINDER能有效提升多跳问答系统的性能，减少LLM幻觉和错误推理的影响。

Abstract: Multi-hop question answering is a challenging task in which language models must reason over multiple steps to reach the correct answer. With the help of Large Language Models and their reasoning capabilities, existing systems are able to think and decompose an input question over multiple steps to analyze, retrieve, and reason. However, training-based approaches for this problem still suffer from LLM hallucinations and incorrect reasoning paths that hinder performance. Hence, we propose PATHFINDER, an approach that: (i) uses Monte Carlo Tree Search to generate training path traces, (ii) improves training data quality by filtering erroneous and lengthy traces using sub-answer recall and LLM-as-a-judge verification, and (iii) reformulates sub-queries to handle failed retrieval cases. By following these steps, we demonstrate that PATHFINDER improves the performance of multi-hop QA over public benchmark datasets.

</details>


### [63] [Interaction Tensor Shap](https://arxiv.org/abs/2512.05338)
*Hiroki Hasegawa,Yukihiko Okada*

Main category: cs.LG

TL;DR: 提出IT SHAP方法，通过张量网络收缩高效计算高阶Shapley交互作用，将指数复杂度降至多项式时间


<details>
  <summary>Details</summary>
Motivation: 现有Shapley值方法无法高效计算高阶特征交互作用：STII需要指数级枚举，MST仅限一阶效应。需要同时保持STII的公理精确性并避免指数计算复杂度的方法

Method: 提出Interaction Tensor SHAP (IT SHAP)，将STII重新表述为值张量和权重张量的收缩，假设权重张量具有多项式TT秩的有限状态TT表示。在TT结构化的模型和分布张量下，通过张量网络收缩实现高效计算

Result: IT SHAP将STII的指数复杂度Θ(4^n)降低到NC2并行时间，在多项式时间和多对数深度下计算高阶Shapley交互作用

Conclusion: IT SHAP为高维模型中的主效应和高阶交互作用提供了统一、公理化且计算可行的公式，为可扩展的交互感知可解释AI奠定了基础

Abstract: Machine learning models have grown increasingly deep and high dimensional, making it difficult to understand how individual and combined features influence their predictions. While Shapley value based methods provide principled feature attributions, existing formulations cannot tractably evaluate higher order interactions: the Shapley Taylor Interaction Index (STII) requires exponential scale enumeration of subsets, and current tensor based approaches such as the Marginal SHAP Tensor (MST) are restricted to first order effects. The central problem is that no existing framework simultaneously preserves the axiomatic exactness of STII and avoids the exponential computational blow up inherent to high order discrete derivatives. Here we show that high order Shapley interactions can be represented exactly as tensor network contractions, enabling polynomial time and polylog depth computation under Tensor Train (TT) structure. We introduce Interaction Tensor SHAP (IT SHAP), which reformulates STII as the contraction of a Value Tensor and a Weight Tensor, and assume a finite state TT representation of the Weight Tensor with polynomial TT ranks. Under TT structured model and distribution tensors, we show that IT SHAP reduces the exponential complex Theta(4^n) of STII to NC2 parallel time. These results demonstrate that IT SHAP provides a unified, axiomatic, and computationally tractable formulation of main effects and higher order interactions in high dimensional models. This framework establishes a foundation for scalable interaction aware explainable AI, with implications for large black box models whose combinatorial structure has previously rendered interaction analysis infeasible.

</details>


### [64] [Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models](https://arxiv.org/abs/2512.05339)
*Mahesh Kumar Nandwana,Youngwan Lim,Joseph Liu,Alex Yang,Varun Notibala,Nishchaie Khanna*

Main category: cs.LG

TL;DR: Roblox Guard 1.0是基于Llama-3.1-8B-Instruct构建的安全防护LLM，通过指令微调增强LLM系统的输入输出安全审核能力，并发布了RobloxGuard-Eval评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在训练后进行了安全对齐，但仍可能生成不适当的输出，对用户构成风险，因此需要跨输入输出的强大安全防护机制。

Method: 基于Llama-3.1-8B-Instruct进行指令微调，使用合成和开源安全数据集混合训练，增强链式思维推理和输入反转技术，构建LLM管道提升审核能力。

Result: 模型能够泛化到未见过的安全分类体系，在领域外安全基准测试中表现优异，同时发布了可扩展安全分类的RobloxGuard-Eval评估基准。

Conclusion: Roblox Guard 1.0为LLM系统提供了全面的输入输出安全防护框架，通过指令微调和系统化评估基准增强了LLM的安全审核能力。

Abstract: Large Language Models (LLMs) are typically aligned for safety during the post-training phase; however, they may still generate inappropriate outputs that could potentially pose risks to users. This challenge underscores the need for robust safeguards that operate across both model inputs and outputs. In this work, we introduce Roblox Guard 1.0, a state-of-the-art instruction fine-tuned LLM designed to enhance the safety of LLM systems through comprehensive input-output moderation, using a pipeline of LLMs to enhance moderation capability. Built on the Llama-3.1-8B-Instruct backbone, our model is instruction fine-tuned to generalize across previously unseen safety taxonomies and demonstrates strong performance on out-of-domain safety benchmarks. The instruction fine-tuning process uses a mix of synthetic and open-source safety datasets, augmented with chain-of-thought (CoT) rationales and input inversion to enhance contextual understanding and decision making. To support systematic evaluation, we also release RobloxGuard-Eval, a new benchmark featuring an extensible safety taxonomy to assess the effectiveness of LLM guardrails and moderation frameworks.

</details>


### [65] [When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation](https://arxiv.org/abs/2512.05341)
*Yiwen Liang,Qiufeng Li,Shikai Wang,Weidong Cao*

Main category: cs.LG

TL;DR: 提出针对硬件代码生成的LLM遗忘框架，结合语法保持遗忘策略和细粒度选择性损失，有效移除问题知识而不损害代码生成能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM在硬件代码生成中存在可靠性问题，包括记忆专有IP、基准测试污染和不安全编码模式，需要专门解决方案

Method: 结合语法保持遗忘策略保护硬件代码结构完整性，以及细粒度floor-aware选择性损失实现精确高效的问题知识移除

Result: 支持3倍大的遗忘集，通常只需单次训练周期，保持RTL代码的语法正确性和功能完整性

Conclusion: 为可靠的LLM辅助硬件设计开辟了新途径，解决了LLM在硬件代码生成中的可靠性挑战

Abstract: Large Language Models (LLMs) have shown strong potential in accelerating digital hardware design through automated code generation. Yet, ensuring their reliability remains a critical challenge, as existing LLMs trained on massive heterogeneous datasets often exhibit problematic memorization of proprietary intellectual property (IP), contaminated benchmarks, and unsafe coding patterns. To mitigate these risks, we propose a novel unlearning framework tailored for LLM-based hardware code generation. Our method combines (i) a syntax-preserving unlearning strategy that safeguards the structural integrity of hardware code during forgetting, and (ii) a fine-grained floor-aware selective loss that enables precise and efficient removal of problematic knowledge. This integration achieves effective unlearning without degrading LLM code generation capabilities. Extensive experiments show that our framework supports forget sets up to 3x larger, typically requiring only a single training epoch, while preserving both syntactic correctness and functional integrity of register-transfer level (RTL) codes. Our work paves an avenue towards reliable LLM-assisted hardware design.

</details>


### [66] [Enhancing Dimensionality Prediction in Hybrid Metal Halides via Feature Engineering and Class-Imbalance Mitigation](https://arxiv.org/abs/2512.05367)
*Mariia Karabin,Isaac Armstrong,Leo Beck,Paulina Apanel,Markus Eisenbach,David B. Mitzi,Hanna Terletska,Hendrik Heinz*

Main category: cs.LG

TL;DR: 提出机器学习框架预测杂化金属卤化物结构维度，通过化学特征工程和类别不平衡处理技术提升预测性能


<details>
  <summary>Details</summary>
Motivation: 杂化金属卤化物（包括有机-无机钙钛矿）的结构维度预测对材料设计至关重要，但现有数据集存在严重的类别不平衡问题（0D、1D、2D、3D类别样本分布不均），这给预测建模带来重大挑战

Method: 1) 使用SMOTE技术将数据集从494个样本扩充到1336个以缓解类别不平衡；2) 开发基于相互作用的描述符；3) 采用多阶段工作流程，结合特征选择、模型堆叠和性能优化

Result: 该方法显著提高了少数类别的F1分数，在所有维度类别上都实现了稳健的交叉验证性能

Conclusion: 提出的机器学习框架通过化学特征工程和先进的类别不平衡处理技术，有效解决了杂化金属卤化物结构维度预测中的类别不平衡问题，为材料设计提供了可靠的工具

Abstract: We present a machine learning framework for predicting the structural dimensionality of hybrid metal halides (HMHs), including organic-inorganic perovskites, using a combination of chemically-informed feature engineering and advanced class-imbalance handling techniques. The dataset, consisting of 494 HMH structures, is highly imbalanced across dimensionality classes (0D, 1D, 2D, 3D), posing significant challenges to predictive modeling. This dataset was later augmented to 1336 via the Synthetic Minority Oversampling Technique (SMOTE) to mitigate the effects of the class imbalance. We developed interaction-based descriptors and integrated them into a multi-stage workflow that combines feature selection, model stacking, and performance optimization to improve dimensionality prediction accuracy. Our approach significantly improves F1-scores for underrepresented classes, achieving robust cross-validation performance across all dimensionalities.

</details>


### [67] [Text Rationalization for Robust Causal Effect Estimation](https://arxiv.org/abs/2512.05373)
*Lijinghua Zhang,Hengrui Cai*

Main category: cs.LG

TL;DR: CATR框架通过选择稀疏的文本特征子集来解决文本数据因果推断中的正性假设违反问题，提高因果效应估计的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 文本数据在因果推断中应用日益增多，但高维文本特征会导致正性假设违反，产生极端倾向得分、不稳定权重和方差膨胀等问题。

Method: 提出Confounding-Aware Token Rationalization (CATR)框架，使用残差独立性诊断选择稀疏的必要token子集，保留足够的混杂信息同时丢弃无关文本。

Result: 在合成数据和MIMIC-III数据库的真实世界研究中，CATR比现有基线方法产生更准确、稳定和可解释的因果效应估计。

Conclusion: CATR通过选择稀疏的文本特征子集有效缓解了观测层面的正性假设违反问题，提高了文本数据因果推断的稳定性和准确性。

Abstract: Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.

</details>


### [68] [China Regional 3km Downscaling Based on Residual Corrective Diffusion Model](https://arxiv.org/abs/2512.05377)
*Honglu Sun,Hao Jing,Zhixiang Dai,Sa Xiao,Wei Xue,Jian Sun,Qifeng Lu*

Main category: cs.LG

TL;DR: 该研究扩展了CorrDiff扩散模型，将其应用于中国区域20倍更大范围的天气预测，不仅考虑地表变量，还包含6个气压层的高层变量，并添加全局残差连接提升精度，在3公里分辨率预测上优于传统区域模型。


<details>
  <summary>Details</summary>
Motivation: 数值天气预报中高效生成高分辨率预报是一个基本挑战。传统方法包括动力降尺度和统计降尺度，本研究专注于统计降尺度，利用深度学习建立低分辨率与高分辨率历史数据之间的统计关系，以生成更精细的天气预报。

Method: 采用基于扩散模型的CorrDiff降尺度框架，将其扩展到中国区域（面积扩大近20倍），不仅处理地表变量，还包含6个气压层的高层变量。添加全局残差连接提升精度，将模型应用于CMA-GFS（25公里全球网格预报）和SFF（基于球面傅里叶神经算子的数据驱动模型），生成3公里分辨率的中国区域预报。

Result: 实验结果表明，该方法降尺度后的预报在目标变量的平均绝对误差（MAE）上普遍优于CMA-MESO区域模型的直接预报。雷达组合反射率预报显示，CorrDiff作为生成模型能够生成更精细的细节，相比确定性回归模型产生更真实的预测。

Conclusion: 扩展后的CorrDiff扩散模型能够有效生成中国区域高分辨率天气预报，在精度和细节生成方面优于传统区域模型，展示了深度学习在天气降尺度任务中的强大潜力。

Abstract: A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep learning has emerged as a powerful tool for this task, giving rise to various high-performance super-resolution models, which can be directly applied for downscaling, such as diffusion models and Generative Adversarial Networks. This work relies on a diffusion-based downscaling framework named CorrDiff. In contrast to the original work of CorrDiff, the region considered in this work is nearly 20 times larger, and we not only consider surface variables as in the original work, but also encounter high-level variables (six pressure levels) as target downscaling variables. In addition, a global residual connection is added to improve accuracy. In order to generate the 3km forecasts for the China region, we apply our trained models to the 25km global grid forecasts of CMA-GFS, an operational global model of the China Meteorological Administration (CMA), and SFF, a data-driven deep learning-based weather model developed from Spherical Fourier Neural Operators (SFNO). CMA-MESO, a high-resolution regional model, is chosen as the baseline model. The experimental results demonstrate that the forecasts downscaled by our method generally outperform the direct forecasts of CMA-MESO in terms of MAE for the target variables. Our forecasts of radar composite reflectivity show that CorrDiff, as a generative model, can generate fine-scale details that lead to more realistic predictions compared to the corresponding deterministic regression models.

</details>


### [69] [Generalization Beyond Benchmarks: Evaluating Learnable Protein-Ligand Scoring Functions on Unseen Targets](https://arxiv.org/abs/2512.05386)
*Jakub Kopko,David Graber,Saltuk Mustafa Eyrilmez,Stanislav Mazurenko,David Bednar,Jiri Sedlar,Josef Sivic*

Main category: cs.LG

TL;DR: 评估蛋白质-配体评分函数在新靶点上的泛化能力，发现现有基准测试未能反映真实挑战，探索大规模自监督预训练和简单测试数据利用方法改善泛化性能


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在分子设计中日益重要，需要确保可学习的蛋白质-配体评分函数在新蛋白质靶点上的可靠性。虽然许多评分函数在标准基准测试中表现良好，但其在训练数据之外的泛化能力仍然是一个重大挑战

Method: 通过模拟在已知结构和实验亲和力测量有限的靶点上进行评估的数据集分割，评估最先进评分函数的泛化能力。研究大规模自监督预训练是否能弥合泛化差距，并探索利用有限测试靶点数据改进评分函数性能的简单方法

Result: 分析表明常用的基准测试未能反映泛化到新靶点的真实挑战。提供了大规模自监督预训练潜力的初步证据，并展示了利用有限测试数据改进性能的方法

Conclusion: 研究结果强调了需要更严格的评估协议，并为设计具有扩展到新蛋白质靶点预测能力的评分函数提供了实用指导

Abstract: As machine learning becomes increasingly central to molecular design, it is vital to ensure the reliability of learnable protein-ligand scoring functions on novel protein targets. While many scoring functions perform well on standard benchmarks, their ability to generalize beyond training data remains a significant challenge. In this work, we evaluate the generalization capability of state-of-the-art scoring functions on dataset splits that simulate evaluation on targets with a limited number of known structures and experimental affinity measurements. Our analysis reveals that the commonly used benchmarks do not reflect the true challenge of generalizing to novel targets. We also investigate whether large-scale self-supervised pretraining can bridge this generalization gap and we provide preliminary evidence of its potential. Furthermore, we probe the efficacy of simple methods that leverage limited test-target data to improve scoring function performance. Our findings underscore the need for more rigorous evaluation protocols and offer practical guidance for designing scoring functions with predictive power extending to novel protein targets.

</details>


### [70] [Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction](https://arxiv.org/abs/2512.05402)
*Sithumi Wickramasinghe,Bikramjit Das,Dorien Herremans*

Main category: cs.LG

TL;DR: 提出MineROI-Net，一个基于Transformer的模型，用于预测比特币挖矿硬件购买时机，将购买决策转化为时间序列分类任务，预测一年内投资回报率是否盈利。


<details>
  <summary>Details</summary>
Motivation: 比特币挖矿硬件采购面临市场波动、技术快速过时和协议驱动的收入周期等挑战，但缺乏何时购买新ASIC硬件的指导，也没有计算框架解决这一决策问题。

Method: 将硬件采购问题建模为时间序列分类任务，预测购买ASIC机器在一年内是否盈利。提出MineROI-Net，一种基于Transformer的开源架构，旨在捕捉挖矿盈利能力的多尺度时间模式。

Result: 在2015-2024年间发布的20种ASIC矿机数据上评估，MineROI-Net优于LSTM和TSLANet基线，达到83.7%准确率和83.1%宏F1分数。模型在经济相关性方面表现强劲，检测不盈利时期的精确度为93.6%，盈利时期的精确度为98.5%。

Conclusion: MineROI-Net为挖矿硬件采购时机提供了实用的数据驱动工具，可能降低资本密集型挖矿运营的财务风险。模型已在GitHub开源。

Abstract: Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net.

</details>


### [71] [RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design](https://arxiv.org/abs/2512.05403)
*Gyusam Chang,Jeongyoon Yoon,Shin han yi,JaeHyeok Lee,Sujin Jang,Sangpil Kim*

Main category: cs.LG

TL;DR: RevoNAD是一个反射进化编排器，通过多轮多专家共识、自适应反射探索和帕累托进化选择，将LLM推理与反馈对齐的架构搜索有效结合，实现高性能神经网络架构设计。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的神经架构设计（NAD）系统存在挑战：令牌级设计循环是离散且不可微分的，导致反馈无法平滑引导架构改进。这些方法容易陷入冗余结构的模式崩溃或漂移到不可行设计，当建设性推理缺乏良好基础时。

Method: RevoNAD采用三个核心技术：1）多轮多专家共识，将孤立的设计规则转化为有意义的架构线索；2）自适应反射探索，根据奖励方差调整探索程度，在反馈不确定时探索，在稳定性达到时优化；3）帕累托引导的进化选择，共同优化准确性、效率、延迟、置信度和结构多样性。

Result: 在CIFAR10、CIFAR100、ImageNet16-120、COCO-5K和Cityscape等多个数据集上，RevoNAD实现了最先进的性能。消融和迁移研究进一步验证了RevoNAD在实际可靠和可部署神经架构设计中的有效性。

Conclusion: RevoNAD通过反射进化编排有效桥接了LLM推理与反馈对齐的架构搜索，解决了现有LLM驱动生成方法的局限性，实现了高性能、可靠且可部署的神经网络架构设计。

Abstract: Recent progress in leveraging large language models (LLMs) has enabled Neural Architecture Design (NAD) systems to generate new architecture not limited from manually predefined search space. Nevertheless, LLM-driven generation remains challenging: the token-level design loop is discrete and non-differentiable, preventing feedback from smoothly guiding architectural improvement. These methods, in turn, commonly suffer from mode collapse into redundant structures or drift toward infeasible designs when constructive reasoning is not well grounded. We introduce RevoNAD, a reflective evolutionary orchestrator that effectively bridges LLM-based reasoning with feedback-aligned architectural search. First, RevoNAD presents a Multi-round Multi-expert Consensus to transfer isolated design rules into meaningful architectural clues. Then, Adaptive Reflective Exploration adjusts the degree of exploration leveraging reward variance; it explores when feedback is uncertain and refines when stability is reached. Finally, Pareto-guided Evolutionary Selection effectively promotes architectures that jointly optimize accuracy, efficiency, latency, confidence, and structural diversity. Across CIFAR10, CIFAR100, ImageNet16-120, COCO-5K, and Cityscape, RevoNAD achieves state-of-the-art performance. Ablation and transfer studies further validate the effectiveness of RevoNAD in allowing practically reliable, and deployable neural architecture design.

</details>


### [72] [Sepsis Prediction Using Graph Convolutional Networks over Patient-Feature-Value Triplets](https://arxiv.org/abs/2512.05416)
*Bozhi Dan,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi*

Main category: cs.LG

TL;DR: Triplet-GCN：一种基于图卷积网络的脓毒症早期预警模型，通过患者-特征-值三元组构建EHR图，在ICU环境中显著优于传统表格基线模型


<details>
  <summary>Details</summary>
Motivation: ICU中脓毒症是导致患者疾病和死亡的主要原因，但电子健康记录数据的复杂性、稀疏性和异质性阻碍了其及时检测，需要更有效的建模方法

Method: 提出Triplet-GCN模型，将每次就诊表示为患者-特征-值三元组，构建二分EHR图，通过图卷积网络学习患者嵌入，再经过轻量级多层感知机进行分类；采用类型特定的预处理策略

Result: 在中国三家三级医院的648名患者队列中，Triplet-GCN在区分度和平衡误差指标上持续优于KNN、SVM、XGBoost、随机森林等基线模型，具有更优的敏感性-特异性权衡和整体效用

Conclusion: 将EHR编码为三元组并在患者-特征图上传播信息比特征独立模型产生更具信息量的患者表示，为可部署的脓毒症风险分层提供了简单、端到端的蓝图

Abstract: In the intensive care setting, sepsis continues to be a major contributor to patient illness and death; however, its timely detection is hindered by the complex, sparse, and heterogeneous nature of electronic health record (EHR) data. We propose Triplet-GCN, a single-branch graph convolutional model that represents each encounter as patient-feature-value triplets, constructs a bipartite EHR graph, and learns patient embeddings via a Graph Convolutional Network (GCN) followed by a lightweight multilayer perceptron (MLP). The pipeline applies type-specific preprocessing -- median imputation and standardization for numeric variables, effect coding for binary features, and mode imputation with low-dimensional embeddings for rare categorical attributes -- and initializes patient nodes with summary statistics, while retaining measurement values on edges to preserve "who measured what and by how much". In a retrospective, multi-center Chinese cohort (N = 648; 70/30 train-test split) drawn from three tertiary hospitals, Triplet-GCN consistently outperforms strong tabular baselines (KNN, SVM, XGBoost, Random Forest) across discrimination and balanced error metrics, yielding a more favorable sensitivity-specificity trade-off and improved overall utility for early warning. These findings indicate that encoding EHR as triplets and propagating information over a patient-feature graph produce more informative patient representations than feature-independent models, offering a simple, end-to-end blueprint for deployable sepsis risk stratification.

</details>


### [73] [TS-HINT: Enhancing Semiconductor Time Series Regression Using Attention Hints From Large Language Model Reasoning](https://arxiv.org/abs/2512.05419)
*Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu*

Main category: cs.LG

TL;DR: 提出TS-Hint框架，结合时间序列基础模型与思维链推理，通过注意力机制和显著性数据提供训练提示，解决半导体制造中材料去除率预测的时序动态丢失和数据量需求大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法从时间序列中提取静态特征来近似半导体制造过程（如化学机械抛光）的材料去除率，但这会导致时序动态信息丢失，且需要大量数据进行有效训练。

Method: 提出TS-Hint框架，集成时间序列基础模型与思维链推理，基于注意力机制数据和显著性数据在训练过程中提供注意力提示，支持从多元时间序列特征直接学习。

Result: 实验结果表明，该模型在有限数据设置下通过少样本学习表现出有效性，能够直接从多元时间序列特征中学习。

Conclusion: TS-Hint框架通过结合时间序列基础模型与思维链推理，有效解决了半导体制造过程中材料去除率预测的时序动态丢失和数据需求大的问题，在少样本场景下表现出色。

Abstract: Existing data-driven methods rely on the extraction of static features from time series to approximate the material removal rate (MRR) of semiconductor manufacturing processes such as chemical mechanical polishing (CMP). However, this leads to a loss of temporal dynamics. Moreover, these methods require a large amount of data for effective training. In this paper, we propose TS-Hint, a Time Series Foundation Model (TSFM) framework, integrated with chain-of-thought reasoning which provides attention hints during training based on attention mechanism data and saliency data. Experimental results demonstrate the effectiveness of our model in limited data settings via few-shot learning and can learn directly from multivariate time series features.

</details>


### [74] [IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?](https://arxiv.org/abs/2512.05442)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: 提出IdealTSF框架，利用非理想负样本增强时间序列预测，通过预训练、训练和优化三阶段，在注意力架构中挖掘负样本潜力


<details>
  <summary>Details</summary>
Motivation: 时间序列数据常存在缺失值和异常，传统方法主要关注特征提取或将非理想数据作为正样本进行知识迁移，但利用负样本增强事件预测更有效

Method: 提出IdealTSF三阶段框架：1)预训练阶段从负样本数据中提取知识；2)训练阶段将序列数据转化为理想正样本；3)应用带对抗扰动的负优化机制

Result: 实验表明负样本数据在基本注意力架构中释放了显著潜力，IdealTSF特别适合噪声样本或低质量数据的应用场景

Conclusion: IdealTSF通过整合理想正负样本，有效利用非理想负样本增强时间序列预测性能，为噪声数据场景提供有效解决方案

Abstract: Deep learning has shown strong performance in time series forecasting tasks. However, issues such as missing values and anomalies in sequential data hinder its further development in prediction tasks. Previous research has primarily focused on extracting feature information from sequence data or addressing these suboptimal data as positive samples for knowledge transfer. A more effective approach would be to leverage these non-ideal negative samples to enhance event prediction. In response, this study highlights the advantages of non-ideal negative samples and proposes the IdealTSF framework, which integrates both ideal positive and negative samples for time series forecasting. IdealTSF consists of three progressive steps: pretraining, training, and optimization. It first pretrains the model by extracting knowledge from negative sample data, then transforms the sequence data into ideal positive samples during training. Additionally, a negative optimization mechanism with adversarial disturbances is applied. Extensive experiments demonstrate that negative sample data unlocks significant potential within the basic attention architecture for time series forecasting. Therefore, IdealTSF is particularly well-suited for applications with noisy samples or low-quality data.

</details>


### [75] [How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data](https://arxiv.org/abs/2512.05469)
*Zubair Ahmed Mohammad*

Main category: cs.LG

TL;DR: 研究通过四个表格分类任务验证了集成模型在保持高精度的同时控制过拟合的能力，发现集成方法在非线性数据上能提升5-7%的测试精度且泛化差距小于3%，而在线性数据上增益有限。


<details>
  <summary>Details</summary>
Motivation: 集成模型通常比单一学习器获得更高精度，但其保持较小泛化差距的能力尚未被充分理解。本研究旨在探索集成模型如何在精度和过拟合之间取得平衡。

Method: 使用重复分层交叉验证和统计显著性检验，在四个表格分类任务（乳腺癌、心脏病、皮马糖尿病、信用卡欺诈）上比较线性模型、单一决策树和九种集成方法。

Result: 集成模型通过平均或受控提升减少方差，能在保持高精度的同时控制泛化差距。在线性数据上增益有限，在非线性数据上测试精度提升5-7%且泛化差距低于3%，在噪声或高度不平衡数据上需要正则化避免过拟合。

Conclusion: 研究明确了集成模型何时及如何保持高精度同时控制过拟合，通过数据集复杂度指标（线性度评分、Fisher比率、噪声估计）解释了集成模型有效控制方差的条件，为实际表格应用中的模型选择提供了实用指导。

Abstract: Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.

</details>


### [76] [PERM EQ x GRAPH EQ: Equivariant Neural Networks for Quantum Molecular Learning](https://arxiv.org/abs/2512.05475)
*Saumya Biswas,Jiten Oswal*

Main category: cs.LG

TL;DR: 比较不同几何量子机器学习模型在分子几何结构学习中的性能，发现置换对称嵌入是最具泛化性的量子模型


<details>
  <summary>Details</summary>
Motivation: 研究不同对称性等变性的量子机器学习模型在分子几何结构学习中的性能差异，为几何数据集选择合适模型提供标准

Method: 使用两个分子数据集（线性LiH分子和三角锥形NH3分子），比较四种模型：无对称等变性模型、旋转和置换等变性模型、图嵌入置换等变性模型，以经典等变模型为基线

Result: 图嵌入特征能有效提高几何数据集的训练能力，置换对称嵌入是几何学习中最具泛化性的量子机器学习模型

Conclusion: 分子几何结构与模型性能差异揭示了模型选择标准，图嵌入是提高几何数据集可训练性的有效途径，置换对称嵌入模型具有最佳泛化性

Abstract: In hierarchal order of molecular geometry, we compare the performances of Geometric Quantum Machine Learning models. Two molecular datasets are considered: the simplistic linear shaped LiH-molecule and the trigonal pyramidal molecule NH3. Both accuracy and generalizability metrics are considered. A classical equivariant model is used as a baseline for the performance comparison. The comparative performance of Quantum Machine Learning models with no symmetry equivariance, rotational and permutational equivariance, and graph embedded permutational equivariance is investigated. The performance differentials and the molecular geometry in question reveals the criteria for choice of models for generalizability. Graph embedding of features is shown to be an effective pathway to greater trainability for geometric datasets. Permutational symmetric embedding is found to be the most generalizable quantum Machine Learning model for geometric learning.

</details>


### [77] [Turbulence Regression](https://arxiv.org/abs/2512.05483)
*Yingang Fan,Binjie Ding,Baiyi Chen*

Main category: cs.LG

TL;DR: 论文提出NeuTucker分解模型，利用离散化数据处理三维风场数据，通过Tucker神经网络构建低秩分解模型来捕捉风场中的潜在交互作用，在缺失观测值估计中表现优于传统回归模型。


<details>
  <summary>Details</summary>
Motivation: 低空湍流结果复杂，传统方法在使用风廓线雷达数据时难以准确预测湍流状态，需要新的建模方法来处理连续但稀疏的三维风场数据。

Method: 1) 将连续输入数据离散化以适应需要离散数据输入的模型；2) 构建四维Tucker交互张量来表示不同高度和三维风速之间所有可能的时空交互作用；3) 基于Tucker神经网络构建低秩Tucker分解模型。

Result: 在真实数据集的缺失观测值估计中，离散化的NeuTucF模型相比各种常见回归模型表现出更优越的性能。

Conclusion: NeuTucker分解模型能有效处理三维风场数据，捕捉其中的潜在交互作用，为低空湍流预测提供了更准确的方法。

Abstract: Air turbulence refers to the disordered and irregular motion state generated by drastic changes in velocity, pressure, or direction during airflow. Various complex factors lead to intricate low-altitude turbulence outcomes. Under current observational conditions, especially when using only wind profile radar data, traditional methods struggle to accurately predict turbulence states. Therefore, this paper introduces a NeuTucker decomposition model utilizing discretized data. Designed for continuous yet sparse three-dimensional wind field data, it constructs a low-rank Tucker decomposition model based on a Tucker neural network to capture the latent interactions within the three-dimensional wind field data. Therefore, two core ideas are proposed here: 1) Discretizing continuous input data to adapt to models like NeuTucF that require discrete data inputs. 2) Constructing a four-dimensional Tucker interaction tensor to represent all possible spatio-temporal interactions among different elevations and three-dimensional wind speeds. In estimating missing observations in real datasets, this discretized NeuTucF model demonstrates superior performance compared to various common regression models.

</details>


### [78] [GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop](https://arxiv.org/abs/2512.05502)
*Omid Bazgir,Vineeth Manthapuri,Ilia Rattsev,Mohammad Jafarnejad*

Main category: cs.LG

TL;DR: GRASP是一个多智能体、图推理框架，通过人机对话界面将定量系统药理学模型编码为类型化生物知识图谱，并编译为可执行的MATLAB/SimBiology代码，同时保持单位、质量平衡和生理约束。


<details>
  <summary>Details</summary>
Motivation: 定量系统药理学建模对药物开发至关重要，但需要大量时间投入，限制了领域专家的吞吐量。现有方法在生物合理性、数学正确性和代码质量方面存在不足。

Method: 采用两阶段工作流：理解阶段（重构遗留代码为图）和行动阶段（约束检查、语言驱动的修改），由状态机协调迭代验证。使用广度优先参数对齐新实体，发现依赖量并提出生物合理的默认值，自动执行/诊断直至收敛。

Result: 在LLM作为评判的对比评估中，GRASP在生物合理性、数学正确性、结构保真度和代码质量方面优于SME引导的CoT和ToT基线（约9-10/10 vs. 5-7/10）。BFS对齐在依赖发现、单位和范围方面达到F1=0.95。

Conclusion: 图结构化的智能体工作流可以使QSP模型开发既易于访问又严谨，使领域专家能够用自然语言指定机制而不牺牲生物医学保真度。

Abstract: Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that encodes QSP models as typed biological knowledge graphs and compiles them to executable MATLAB/SimBiology code while preserving units, mass balance, and physiological constraints. A two-phase workflow -- \textsc{Understanding} (graph reconstruction of legacy code) and \textsc{Action} (constraint-checked, language-driven modification) -- is orchestrated by a state machine with iterative validation. GRASP performs breadth-first parameter-alignment around new entities to surface dependent quantities and propose biologically plausible defaults, and it runs automatic execution/diagnostics until convergence. In head-to-head evaluations using LLM-as-judge, GRASP outperforms SME-guided CoT and ToT baselines across biological plausibility, mathematical correctness, structural fidelity, and code quality (\(\approx\)9--10/10 vs.\ 5--7/10). BFS alignment achieves F1 = 0.95 for dependency discovery, units, and range. These results demonstrate that graph-structured, agentic workflows can make QSP model development both accessible and rigorous, enabling domain experts to specify mechanisms in natural language without sacrificing biomedical fidelity.

</details>


### [79] [Credal and Interval Deep Evidential Classifications](https://arxiv.org/abs/2512.05526)
*Michele Caprio,Shireen K. Manchingal,Fabio Cuzzolin*

Main category: cs.LG

TL;DR: 提出CDEC和IDEC两种新方法，通过信度集和证据预测分布区间进行不确定性量化，能识别并拒绝超出阈值的不确定性，在可接受范围内提供具有概率保证的标签集合。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化是AI领域的关键挑战，影响决策制定、风险评估和模型可靠性。现有方法存在局限性，需要能同时评估认知不确定性和偶然不确定性，并在不确定性过高时拒绝分类的方法。

Method: 提出CDEC（基于信度集）和IDEC（基于证据预测分布区间）两种方法。使用标准反向传播和基于证据理论的损失函数进行训练，避免对训练数据的过拟合，能系统评估认知和偶然不确定性。

Result: 在MNIST、CIFAR-10、CIFAR-100及其自然分布偏移数据集上，CDEC和IDEC实现了竞争性的预测准确率、最先进的分布外检测性能，以及紧致且校准良好的预测区域。CDEC仅需小规模集成就能获得稳定的不确定性估计。

Conclusion: CDEC和IDEC是有效的UQ方法，能克服先前工作的不足，扩展了证据深度学习文献，为分类任务提供了可靠的不确定性量化框架。

Abstract: Uncertainty Quantification (UQ) presents a pivotal challenge in the field of Artificial Intelligence (AI), profoundly impacting decision-making, risk assessment and model reliability. In this paper, we introduce Credal and Interval Deep Evidential Classifications (CDEC and IDEC, respectively) as novel approaches to address UQ in classification tasks. CDEC and IDEC leverage a credal set (closed and convex set of probabilities) and an interval of evidential predictive distributions, respectively, allowing us to avoid overfitting to the training data and to systematically assess both epistemic (reducible) and aleatoric (irreducible) uncertainties. When those surpass acceptable thresholds, CDEC and IDEC have the capability to abstain from classification and flag an excess of epistemic or aleatoric uncertainty, as relevant. Conversely, within acceptable uncertainty bounds, CDEC and IDEC provide a collection of labels with robust probabilistic guarantees. CDEC and IDEC are trained using standard backpropagation and a loss function that draws from the theory of evidence. They overcome the shortcomings of previous efforts, and extend the current evidential deep learning literature. Through extensive experiments on MNIST, CIFAR-10 and CIFAR-100, together with their natural OoD shifts (F-MNIST/K-MNIST, SVHN/Intel, TinyImageNet), we show that CDEC and IDEC achieve competitive predictive accuracy, state-of-the-art OoD detection under epistemic and total uncertainty, and tight, well-calibrated prediction regions that expand reliably under distribution shift. An ablation over ensemble size further demonstrates that CDEC attains stable uncertainty estimates with only a small ensemble.

</details>


### [80] [IDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection](https://arxiv.org/abs/2512.05531)
*Yang Xu,Yixiao Ma,Kaifeng Zhang,Zuliang Yang,Kai Ming Ting*

Main category: cs.LG

TL;DR: IDK-S是一种用于数据流异常检测的增量分布核方法，通过动态核均值嵌入实现高精度实时检测，相比现有方法在保持精度的同时大幅提升速度。


<details>
  <summary>Details</summary>
Motivation: 数据流异常检测面临两大挑战：需要在分布不断演变的情况下保持高检测精度，同时确保实时处理效率。现有方法难以同时满足这两个要求。

Method: 提出IDK-S（增量分布核流式异常检测），基于核均值嵌入框架创建动态表示。继承离线检测器Isolation Distributional Kernel的数据依赖核优势，采用轻量级增量更新机制，避免完整模型重训练的计算开销。

Result: 在13个基准测试中，IDK-S实现了优越的检测精度，同时运行速度显著快于现有最先进方法，在许多情况下快一个数量级，且统计上等效于完整重训练模型。

Conclusion: IDK-S成功解决了数据流异常检测中精度与效率的平衡问题，通过创新的增量分布核方法，在保持检测精度的同时实现了显著的速度提升，为实时异常检测提供了有效解决方案。

Abstract: Anomaly detection on data streams presents significant challenges, requiring methods to maintain high detection accuracy among evolving distributions while ensuring real-time efficiency. Here we introduce $\mathcal{IDK}$-$\mathcal{S}$, a novel $\mathbf{I}$ncremental $\mathbf{D}$istributional $\mathbf{K}$ernel for $\mathbf{S}$treaming anomaly detection that effectively addresses these challenges by creating a new dynamic representation in the kernel mean embedding framework. The superiority of $\mathcal{IDK}$-$\mathcal{S}$ is attributed to two key innovations. First, it inherits the strengths of the Isolation Distributional Kernel, an offline detector that has demonstrated significant performance advantages over foundational methods like Isolation Forest and Local Outlier Factor due to the use of a data-dependent kernel. Second, it adopts a lightweight incremental update mechanism that significantly reduces computational overhead compared to the naive baseline strategy of performing a full model retraining. This is achieved without compromising detection accuracy, a claim supported by its statistical equivalence to the full retrained model. Our extensive experiments on thirteen benchmarks demonstrate that $\mathcal{IDK}$-$\mathcal{S}$ achieves superior detection accuracy while operating substantially faster, in many cases by an order of magnitude, than existing state-of-the-art methods.

</details>


### [81] [On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability](https://arxiv.org/abs/2512.05534)
*Yiming Tang,Harshvardhan Saini,Yizhen Liao,Dianbo Liu*

Main category: cs.LG

TL;DR: 本文提出了首个统一的稀疏字典学习理论框架，涵盖多种SDL方法，分析了优化景观，解释了特征吸收、死亡神经元等经验现象，并通过实验验证理论结果。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型能力增强，理解其内部表示和处理机制变得至关重要。现有稀疏字典学习方法虽然经验上成功，但缺乏统一的理论基础，特别是对稀疏自编码器之外的方法缺乏形式化分析。

Method: 将各种稀疏字典学习方法统一为一个优化问题框架，包括稀疏自编码器、转码器和交叉编码器。提供严格的优化景观分析，并设计受控实验验证理论结果。

Result: 建立了首个统一的SDL理论框架，解释了特征吸收、死亡神经元等经验现象，为神经元重采样技术提供了理论依据，并通过实验验证了理论分析的正确性。

Conclusion: 本文填补了稀疏字典学习领域的理论空白，为理解神经网络表示学习提供了统一的理论基础，有助于推动可解释AI的发展。

Abstract: As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode many concepts in superposition. Various sparse dictionary learning (SDL) methods, including sparse autoencoders, transcoders, and crosscoders, address this by training auxiliary models with sparsity constraints to disentangle these superposed concepts into interpretable features. These methods have demonstrated remarkable empirical success but have limited theoretical understanding. Existing theoretical work is limited to sparse autoencoders with tied-weight constraints, leaving the broader family of SDL methods without formal grounding. In this work, we develop the first unified theoretical framework considering SDL as one unified optimization problem. We demonstrate how diverse methods instantiate the theoretical framwork and provide rigorous analysis on the optimization landscape. We provide the first theoretical explanations for some empirically observed phenomena, including feature absorption, dead neurons, and the neuron resampling technique. We further design controlled experiments to validate our theoretical results.

</details>


### [82] [SCoNE: Spherical Consistent Neighborhoods Ensemble for Effective and Efficient Multi-View Anomaly Detection](https://arxiv.org/abs/2512.05540)
*Yang Xu,Hang Zhang,Yixiao Ma,Ye Zhu,Kai Ming Ting*

Main category: cs.LG

TL;DR: SCoNE：一种新型多视图异常检测方法，通过球面一致邻域集成直接表示多视图实例，无需学习过程，实现O(N)时间复杂度，在准确率和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多视图异常检测方法存在两个关键问题：1）无法保证在不同视图密度变化区域中有效捕获一致邻域，导致检测精度低；2）学习过程计算复杂度为O(N²)，不适用于大规模数据集。

Method: 提出SCoNE方法，具有两个独特特征：a) 直接使用多视图实例表示一致邻域，无需中间表示；b) 邻域具有数据依赖特性，在稀疏区域形成大邻域，在密集区域形成小邻域。

Result: 实验评估表明，SCoNE在检测精度上优于现有方法，在大规模数据集上运行速度比现有方法快几个数量级。

Conclusion: SCoNE通过数据依赖的球面一致邻域表示，解决了多视图异常检测中的一致邻域表示和计算效率问题，实现了高精度和线性时间复杂度。

Abstract: The core problem in multi-view anomaly detection is to represent local neighborhoods of normal instances consistently across all views. Recent approaches consider a representation of local neighborhood in each view independently, and then capture the consistent neighbors across all views via a learning process. They suffer from two key issues. First, there is no guarantee that they can capture consistent neighbors well, especially when the same neighbors are in regions of varied densities in different views, resulting in inferior detection accuracy. Second, the learning process has a high computational cost of $\mathcal{O}(N^2)$, rendering them inapplicable for large datasets. To address these issues, we propose a novel method termed \textbf{S}pherical \textbf{C}onsistent \textbf{N}eighborhoods \textbf{E}nsemble (SCoNE). It has two unique features: (a) the consistent neighborhoods are represented with multi-view instances directly, requiring no intermediate representations as used in existing approaches; and (b) the neighborhoods have data-dependent properties, which lead to large neighborhoods in sparse regions and small neighborhoods in dense regions. The data-dependent properties enable local neighborhoods in different views to be represented well as consistent neighborhoods, without learning. This leads to $\mathcal{O}(N)$ time complexity. Empirical evaluations show that SCoNE has superior detection accuracy and runs orders-of-magnitude faster in large datasets than existing approaches.

</details>


### [83] [RoBoN: Routed Online Best-of-n for Test-Time Scaling with Multiple LLMs](https://arxiv.org/abs/2512.05542)
*Jonathan Geuter,Gregor Kornhardt*

Main category: cs.LG

TL;DR: RoBoN是一种多LLM推理方法，通过在线路由在不同模型间顺序生成响应，利用奖励模型和一致性信号选择最佳输出，无需额外训练即可超越单模型最佳选择策略。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在不同任务上表现出互补优势，但传统的最佳选择方法（best-of-n）仅依赖单个模型生成响应，未能充分利用多模型多样性。作者希望开发一种能利用多模型优势的推理时扩展方法。

Method: RoBoN（Routed Online Best-of-n）是一种顺序多LLM推理方法：给定一组模型，它基于奖励模型评分和预测响应的一致性信号，逐个在模型间路由生成过程。该方法无需额外训练，保持计算对等性，可与任何插件奖励模型配合使用。

Result: 在多个推理基准测试（MATH500、OlympiadBench、MinervaMath、GSM8K、MMLU）中，RoBoN在较大n值时始终优于应用于单个模型的标准best-of-n，绝对准确率提升高达3.4%，同时也优于均匀多模型组合基线。

Conclusion: 研究表明，在推理时利用模型间的多样性可以改善best-of-n性能，超越任何单一组成模型，为多LLM的测试时扩展提供了一种简单、无需训练的路径。

Abstract: Best-of-$n$ is a widely used test-time scaling approach for LLM inference. Yet despite evidence that LLMs exhibit complementary strengths across tasks, traditionally best-of-$n$ relies on a single model to generate responses. We propose RoBoN (Routed Online Best-of-$n$), a sequential multi-LLM alternative to the prevailing single-model best-of-$n$. Given a suite of models $\{m_i\}_{i=1}^M$, RoBoN sequentially routes generations one-by-one across models, based on scores computed using a reward model and an agreement signal on the predicted responses. This online routing requires no additional training, keeps compute parity, and works with any plug-in reward model. Across reasoning benchmarks (MATH500, OlympiadBench, MinervaMath, GSM8K, MMLU), RoBoN consistently outperforms standard best-of-$n$ applied to each individual model for larger $n$, with gains of up to 3.4\% in absolute accuracy, and also improves over a uniform multi-model portfolio baseline. Our results indicate that diversity across models can be exploited at inference to improve best-of-$n$ performance over any constituent model alone, providing a simple, training-free path to test-time scaling with multiple LLMs.

</details>


### [84] [Improving Local Fidelity Through Sampling and Modeling Nonlinearity](https://arxiv.org/abs/2512.05556)
*Sanjeev Shrestha,Rahul Dubey,Hui Liu*

Main category: cs.LG

TL;DR: 提出基于MARS的非线性局部解释方法，替代LIME的线性假设，通过N-ball采样提升解释保真度，在多个数据集上显著降低误差


<details>
  <summary>Details</summary>
Motivation: 随着黑盒机器学习模型在关键领域的应用增加，需要提供可靠的预测解释。现有LIME方法假设局部决策边界是线性的，无法捕捉非线性关系，导致解释不准确。

Method: 使用多元自适应回归样条(MARS)建模非线性局部边界，捕捉参考模型的底层行为；采用N-ball采样技术直接从目标分布采样，而非像LIME那样重新加权样本。

Result: 在三个UCI数据集上评估，相比基线方法，新方法能产生更忠实的解释，平均降低37%的均方根误差，显著提升了局部保真度。

Conclusion: 提出的基于MARS的非线性局部解释方法能够有效捕捉复杂模型的非线性决策边界，通过改进采样策略生成更高保真度的解释，解决了LIME的局限性。

Abstract: With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.

</details>


### [85] [Wasserstein distance based semi-supervised manifold learning and application to GNSS multi-path detection](https://arxiv.org/abs/2512.05567)
*Antoine Blais,Nicolas Couëllan*

Main category: cs.LG

TL;DR: 提出基于最优传输的半监督学习方法，利用Wasserstein距离作为图像相似性度量，通过标签传播机制处理稀缺标注数据，在GNSS多径干扰检测中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决图像数据标注稀缺的问题，特别是在实际应用中获取大量标注数据成本高昂，需要利用少量标注数据和大量未标注数据进行有效学习。

Method: 基于隐式图传导的半监督学习方法，使用Wasserstein距离作为图像样本间的相似性度量，将该度量融入标签传播机制，结合深度卷积网络进行学习。

Result: 在GNSS多径干扰检测实验中，通过调整半监督程度和度量敏感度的超参数，分类准确率相比全监督训练方法有显著提升。

Conclusion: 基于最优传输的半监督学习方法能有效利用稀缺标注数据，在特定超参数设置下显著提升分类性能，为实际应用中的标注数据稀缺问题提供解决方案。

Abstract: The main objective of this study is to propose an optimal transport based semi-supervised approach to learn from scarce labelled image data using deep convolutional networks. The principle lies in implicit graph-based transductive semi-supervised learning where the similarity metric between image samples is the Wasserstein distance. This metric is used in the label propagation mechanism during learning. We apply and demonstrate the effectiveness of the method on a GNSS real life application. More specifically, we address the problem of multi-path interference detection. Experiments are conducted under various signal conditions. The results show that for specific choices of hyperparameters controlling the amount of semi-supervision and the level of sensitivity to the metric, the classification accuracy can be significantly improved over the fully supervised training method.

</details>


### [86] [Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning](https://arxiv.org/abs/2512.05591)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Tiehua Mei,Zijia Lin,Yuntao Li,Wenping Hu,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 提出熵比率裁剪(ERC)机制，通过约束当前与先前策略的熵比率来稳定强化学习训练，解决分布偏移问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型后训练依赖强化学习提升能力，但离策略训练引入分布偏移，导致训练不稳定（策略熵波动、梯度不稳定）。PPO-Clip虽通过重要性裁剪缓解，但忽略了动作的全局分布偏移。

Method: 提出熵比率作为量化策略探索相对变化的全局指标，基于此设计熵比率裁剪(ERC)机制，对熵比率施加双向约束。将ERC集成到DAPO和GPPO强化学习算法中。

Result: 在多个基准测试中，ERC持续提升性能表现。

Conclusion: ERC机制能有效稳定策略更新，弥补PPO-clip无法调节未采样动作概率偏移的不足，提升强化学习训练效果。

Abstract: Large language model post-training relies on reinforcement learning to improve model capability and alignment quality. However, the off-policy training paradigm introduces distribution shift, which often pushes the policy beyond the trust region, leading to training instabilities manifested as fluctuations in policy entropy and unstable gradients. Although PPO-Clip mitigates this issue through importance clipping, it still overlooks the global distributional shift of actions. To address these challenges, we propose using the entropy ratio between the current and previous policies as a new global metric that effectively quantifies the relative change in policy exploration throughout updates. Building on this metric, we introduce an \textbf{Entropy Ratio Clipping} (ERC) mechanism that imposes bidirectional constraints on the entropy ratio. This stabilizes policy updates at the global distribution level and compensates for the inability of PPO-clip to regulate probability shifts of un-sampled actions. We integrate ERC into both DAPO and GPPO reinforcement learning algorithms. Experiments across multiple benchmarks show that ERC consistently improves performance.

</details>


### [87] [Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales](https://arxiv.org/abs/2512.05620)
*Shikai Qiu,Zixi Chen,Hoang Phan,Qi Lei,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 该研究探讨了如何通过超参数迁移来扩展预条件优化器（如Shampoo、SOAP、Muon）的规模，发现遵循μP缩放学习率并结合分块和谱归一化可改善迁移效果，而计算最优缩放时权重衰减应随宽度反比缩放。应用这些规则后，Muon和Shampoo在1.4B参数规模的Llama模型上分别实现了1.4倍和1.3倍相对于AdamW的加速。


<details>
  <summary>Details</summary>
Motivation: 尽管近期基于矩阵级预条件的深度学习优化器在小规模实验中显示出优于AdamW的加速效果，但其在大规模场景下的有效性验证结果不一。本研究旨在通过超参数迁移来理解这些预条件优化器在扩展规模时的有效性，为可靠比较不同优化器提供方法。

Method: 研究基于μP等先前工作，探索了学习率和权重衰减应如何随模型宽度和深度缩放，涵盖了Shampoo、SOAP、Muon等多种优化器。考虑了分块和嫁接等常用技术的影响，并通过实验验证缩放规则在190M到1.4B参数规模的Llama架构语言模型上的效果。

Result: 研究发现：1）按μP缩放学习率可改善迁移，但仍存在有限宽度偏差导致最优学习率漂移，可通过分块和显式谱归一化缓解；2）计算最优缩放时，权重衰减按1/宽度缩放近乎最优；3）应用正确缩放规则后，Muon和Shampoo在Llama模型上分别实现1.4倍和1.3倍相对于AdamW的加速，而错误缩放下加速效果随规模扩大迅速消失。

Conclusion: 研究强调在现实调优预算下，研究最优超参数迁移对于可靠比较大规模优化器至关重要。正确的缩放规则能使预条件优化器在大规模场景下保持相对于AdamW的显著加速优势。

Abstract: Several recently introduced deep learning optimizers utilizing matrix-level preconditioning have shown promising speedups relative to the current dominant optimizer AdamW, particularly in relatively small-scale experiments. However, efforts to validate and replicate their successes have reported mixed results. To better understand the effectiveness of these optimizers at scale, in this work we investigate how to scale preconditioned optimizers via hyperparameter transfer, building on prior works such as $μ$P. We study how the optimal learning rate and weight decay should scale with model width and depth for a wide range of optimizers, including Shampoo, SOAP, and Muon, accounting for the impact of commonly used techniques such as blocking and grafting. We find that scaling the learning rate according to $μ$P improves transfer, but can still suffer from significant finite-width deviations that cause drifting optimal learning rates, which we show can be mitigated by blocking and explicit spectral normalization. For compute-optimal scaling, we find scaling independent weight decay as $1/\mathrm{width}$ is nearly optimal across optimizers. Applying these scaling rules, we show Muon and Shampoo consistently achieve $1.4\times$ and $1.3\times$ speedup over AdamW for training Llama-architecture language models of sizes ranging from $190$M to $1.4$B, whereas the speedup vanishes rapidly with scale under incorrect scaling. Based on these results and further ablations, we argue that studying optimal hyperparameter transfer is essential for reliably comparing optimizers at scale given a realistic tuning budget.

</details>


### [88] [Bounded Graph Clustering with Graph Neural Networks](https://arxiv.org/abs/2512.05623)
*Kibidi Neocosmos,Diego Baptista,Nicole Ludwig*

Main category: cs.LG

TL;DR: 提出一种灵活控制GNN社区发现数量的框架，允许用户指定范围或精确数量


<details>
  <summary>Details</summary>
Motivation: 传统社区检测方法需要预先指定聚类数量，而GNN方法即使指定了期望数量也常常无法准确返回，存在设计上的局限性

Method: 提出一个灵活框架，允许用户指定社区数量的合理范围，并在训练过程中强制执行这些边界约束；同时也支持指定精确的社区数量

Result: 框架能够可靠地返回用户指定的社区数量，解决了GNN在社区检测中无法准确控制输出聚类数量的问题

Conclusion: 该方法为GNN社区检测提供了灵活且原则性的社区数量控制机制，既支持范围约束也支持精确数量指定

Abstract: In community detection, many methods require the user to specify the number of clusters in advance since an exhaustive search over all possible values is computationally infeasible. While some classical algorithms can infer this number directly from the data, this is typically not the case for graph neural networks (GNNs): even when a desired number of clusters is specified, standard GNN-based methods often fail to return the exact number due to the way they are designed. In this work, we address this limitation by introducing a flexible and principled way to control the number of communities discovered by GNNs. Rather than assuming the true number of clusters is known, we propose a framework that allows the user to specify a plausible range and enforce these bounds during training. However, if the user wants an exact number of clusters, it may also be specified and reliably returned.

</details>


### [89] [Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability](https://arxiv.org/abs/2512.05638)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 论文提出了"模块化喷射"方法，通过分析模块对输入扰动的局部线性响应来识别模型内部分解的唯一性，区分了"幻象"和"可识别"两种状态。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习仅通过预测风险评估模型，无法确定模型内部分解是否由数据和评估设计唯一确定。需要一种方法来分析模型模块分解的唯一性问题。

Method: 提出了模块化喷射方法：给定任务流形、模块分解和模块级表示访问，估计经验喷射（描述模块对输入结构化扰动的局部线性响应映射）。定义了幻象状态（多个分解产生不可区分的喷射）和可识别状态（喷射唯一确定分解）。

Result: 在双模块线性回归管道中证明了喷射可识别性定理：在温和的秩假设和模块级喷射访问下，内部分解是唯一确定的。开发了MoJet算法进行经验喷射估计和幻象诊断，在线性和深度回归以及管道分类中进行了验证。

Conclusion: 模块化喷射提供了一种超越预测风险的方法，能够分析模型内部分解的唯一性。该方法揭示了仅凭风险评估无法区分的幻象分解，为理解模型内部结构提供了新工具。

Abstract: Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.

</details>


### [90] [Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs](https://arxiv.org/abs/2512.05648)
*Igor Shilov,Alex Cloud,Aryo Pradipta Gema,Jacob Goldman-Wetzler,Nina Panickssery,Henry Sleight,Erik Jones,Cem Anil*

Main category: cs.LG

TL;DR: SGTM是一种改进的梯度路由技术，通过选择性梯度掩码将目标知识隔离到特定参数子集中，以应对训练数据标签噪声问题，在去除特定知识时比数据过滤和传统梯度路由方法更有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在双重用途风险，传统的数据过滤方法面临标签成本高和标签噪声问题，即使少量错误标签也可能导致危险能力。需要一种更鲁棒的预训练时缓解方法。

Method: 提出选择性梯度掩码（SGTM），通过零掩码选定梯度，使目标领域示例仅更新其专用参数，从而将目标知识局部化到特定参数子集中，便于后续移除。

Result: 在双语数据集去除语言知识和英语维基百科去除生物学知识两个应用中，SGTM在存在标签错误时比数据过滤和传统梯度路由方法具有更好的保留/遗忘权衡。对对抗性微调表现出强鲁棒性，需要7倍微调步骤才能恢复到基线性能。

Conclusion: SGTM为现有安全缓解措施提供了一个有前景的预训练时补充，特别是在标签噪声不可避免的场景下，能够有效应对双重用途风险。

Abstract: Large Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) -- a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM's effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.

</details>


### [91] [Feasibility of AI-Assisted Programming for End-User Development](https://arxiv.org/abs/2512.05666)
*Irene Weber*

Main category: cs.LG

TL;DR: AI辅助的终端用户编程是可行的终端用户开发范式，非程序员通过与AI助手交互成功开发基础Web应用，可能补充或替代现有的低代码/无代码平台。


<details>
  <summary>Details</summary>
Motivation: 探索AI辅助的终端用户编程是否可行，评估其作为终端用户开发新范式的潜力，可能补充或替代现有的低代码/无代码平台。

Method: 通过案例研究，让非程序员通过与AI助手交互来开发基础Web应用，分析任务完成情况和参与者反馈。

Result: 大多数研究参与者在合理时间内成功完成任务，并支持AI辅助的终端用户编程作为可行的终端用户开发方法。

Conclusion: AI辅助的终端用户编程是可行的终端用户开发范式，具有灵活性、适用性广、开发速度快、可重用性高和减少供应商锁定等优势，可能成为低代码/无代码平台的重要补充或替代方案。

Abstract: End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and "copilots", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.

</details>


### [92] [Meta-Learning Multi-armed Bandits for Beam Tracking in 5G and 6G Networks](https://arxiv.org/abs/2512.05680)
*Alexander Mattick,George Yammine,Georgios Kontes,Setareh Maghsudi,Christopher Mutschler*

Main category: cs.LG

TL;DR: 提出基于POMDP的在线波束选择方法，通过信念状态建模处理移动用户和动态环境，相比传统监督学习方法性能提升显著


<details>
  <summary>Details</summary>
Motivation: 5G/6G网络中大规模天线阵列的波束管理面临挑战：大码本、反射和遮挡效应使得最优波束选择困难，现有基于监督学习的方法难以处理新轨迹和环境变化

Method: 将波束选择问题建模为部分可观测马尔可夫决策过程（POMDP），将环境建模为码本本身，基于不可观测最优波束的信念状态和先前探测波束选择候选波束，实现在线搜索定位移动最优波束

Result: 该方法能够处理新出现或未预见的轨迹和物理环境变化，相比先前工作性能提升数个数量级

Conclusion: 基于POMDP的在线波束选择方法比传统监督学习方法更有效，能够适应动态环境和移动用户，为5G/6G波束管理提供了更优解决方案

Abstract: Beamforming-capable antenna arrays with many elements enable higher data rates in next generation 5G and 6G networks. In current practice, analog beamforming uses a codebook of pre-configured beams with each of them radiating towards a specific direction, and a beam management function continuously selects \textit{optimal} beams for moving user equipments (UEs). However, large codebooks and effects caused by reflections or blockages of beams make an optimal beam selection challenging. In contrast to previous work and standardization efforts that opt for supervised learning to train classifiers to predict the next best beam based on previously selected beams we formulate the problem as a partially observable Markov decision process (POMDP) and model the environment as the codebook itself. At each time step, we select a candidate beam conditioned on the belief state of the unobservable optimal beam and previously probed beams. This frames the beam selection problem as an online search procedure that locates the moving optimal beam. In contrast to previous work, our method handles new or unforeseen trajectories and changes in the physical environment, and outperforms previous work by orders of magnitude.

</details>


### [93] [BERTO: an Adaptive BERT-based Network Time Series Predictor with Operator Preferences in Natural Language](https://arxiv.org/abs/2512.05721)
*Nitin Priyadarshini Shankar,Vaibhav Singh,Sheetal Kalyani,Christian Maciocco*

Main category: cs.LG

TL;DR: BERTO是一个基于BERT的框架，用于蜂窝网络流量预测和能耗优化，通过自然语言提示平衡节能与性能的权衡。


<details>
  <summary>Details</summary>
Motivation: 蜂窝网络需要同时优化流量预测准确性和能耗效率，现有模型难以灵活平衡节能与性能的权衡，需要更智能的解决方案。

Method: 基于Transformer架构构建BERT框架，引入平衡损失函数和基于提示的自定义功能，允许运营商通过自然语言提示调整欠预测和过预测的权衡。

Result: 在真实数据集上，BERTO相比现有模型将MSE降低4.13%，能在1.4kW功率范围和9倍服务质量变化范围内灵活运行，通过简单自然语言输入平衡节能与性能目标。

Conclusion: BERTO为智能无线接入网络部署提供了有效的解决方案，通过自然语言提示实现了流量预测准确性与能耗优化的灵活平衡。

Abstract: We introduce BERTO, a BERT-based framework for traffic prediction and energy optimization in cellular networks. Built on transformer architectures, BERTO delivers high prediction accuracy, while its Balancing Loss Function and prompt-based customization allow operators to adjust the trade-off between power savings and performance. Natural language prompts guide the model to manage underprediction and overprediction in accordance with the operator's intent. Experiments on real-world datasets show that BERTO improves upon existing models with a $4.13$\% reduction in MSE while introducing the feature of balancing competing objectives of power saving and performance through simple natural language inputs, operating over a flexible range of $1.4$ kW in power and up to $9\times$ variation in service quality, making it well suited for intelligent RAN deployments.

</details>


### [94] [Teaching Language Models Mechanistic Explainability Through Arrow-Pushing](https://arxiv.org/abs/2512.05722)
*Théo A. Neukomm,Zlatko Jončev,Philippe Schwaller*

Main category: cs.LG

TL;DR: 提出基于箭头推演形式主义的反应机理预测框架，开发MechSMILES编码格式，训练语言模型在机理预测任务上取得高精度，并应用于合成规划验证、原子映射和催化剂感知模板提取。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划系统缺乏机理基础，无法提供化学合成的机理洞察。需要建立能够预测化学反应机理的计算框架，使合成规划更加可靠和可解释。

Method: 开发MechSMILES编码格式，将分子结构和电子流动编码为紧凑文本格式。基于箭头推演形式主义训练语言模型，在四个复杂度递增的机理预测任务上进行训练，使用mech-USPTO-31k和FlowER等机理反应数据集。

Result: 模型在基本步骤预测上达到超过95%的top-3准确率，在mech-USPTO-31k数据集上超过73%，在FlowER数据集上达到93%的完整反应机理检索准确率。模型成功应用于合成规划验证、全原子映射和催化剂感知模板提取。

Conclusion: 通过基于物理意义的电子流动预测，该工作为更可解释、化学有效的计算合成规划提供了途径，同时为机理预测提供了架构无关的基准测试框架。

Abstract: Chemical reaction mechanisms provide crucial insight into synthesizability, yet current Computer-Assisted Synthesis Planning (CASP) systems lack mechanistic grounding. We introduce a computational framework for teaching language models to predict chemical reaction mechanisms through arrow pushing formalism, a century-old notation that tracks electron flow while respecting conservation laws. We developed MechSMILES, a compact textual format encoding molecular structure and electron flow, and trained language models on four mechanism prediction tasks of increasing complexity using mechanistic reaction datasets, such as mech-USPTO-31k and FlowER. Our models achieve more than 95\% top-3 accuracy on elementary step prediction and scores that surpass 73\% on mech-USPTO-31k, and 93\% on FlowER dataset for the retrieval of complete reaction mechanisms on our hardest task. This mechanistic understanding enables three key applications. First, our models serve as post-hoc validators for CASP systems, filtering chemically implausible transformations. Second, they enable holistic atom-to-atom mapping that tracks all atoms, including hydrogens. Third, they extract catalyst-aware reaction templates that distinguish recycled catalysts from spectator species. By grounding predictions in physically meaningful electron moves that ensure conservation of mass and charge, this work provides a pathway toward more explainable and chemically valid computational synthesis planning, while providing an architecture-agnostic framework for the benchmarking of mechanism prediction.

</details>


### [95] [Towards agent-based-model informed neural networks](https://arxiv.org/abs/2512.05764)
*Nino Antulov-Fantulin*

Main category: cs.LG

TL;DR: 提出ABM-NNs框架，将基于主体的建模原则融入神经网络设计，确保学习到的动力学保持物理约束和结构特性。


<details>
  <summary>Details</summary>
Motivation: 标准神经微分方程在建模复杂系统时存在局限，无法保证质量守恒、网络局部性、有限理性等约束条件。需要设计既能学习复杂动力学又能保持主体模型原则的神经网络。

Method: 提出Agent-Based-Model informed Neural Networks(ABM-NNs)，利用受限图神经网络和层次分解来学习可解释、结构保持的动力学。

Result: 在三个案例中验证：1)广义Lotka-Volterra系统从短轨迹中恢复真实参数；2)图基SIR传播模型在样本外预测和噪声鲁棒性上优于GCN、GraphSAGE等基线；3)十大经济体宏观经济模型从经验数据学习耦合GDP动力学，支持基于梯度的反事实政策分析。

Conclusion: ABM-NNs框架成功将基于主体建模的原则融入神经网络，既能学习复杂系统动力学，又能保持必要的结构约束，在多个领域展现出优越性能。

Abstract: In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka--Volterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.

</details>


### [96] [Learnability Window in Gated Recurrent Neural Networks](https://arxiv.org/abs/2512.05790)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 论文提出理论框架，解释门控机制如何决定循环神经网络的"可学习窗口"——梯度信息在时间上保持统计可恢复的最大时间范围。


<details>
  <summary>Details</summary>
Motivation: 传统分析强调雅可比乘积的数值稳定性，但这不足以解释门控循环网络学习长程时间依赖的能力。需要理解门控机制如何影响梯度传输的统计可恢复性。

Method: 通过一阶展开门控诱导的雅可比乘积，推导出"有效学习率"μ_{t,ℓ}，这些量作为乘性滤波器控制梯度传输的幅度和各向异性。在重尾梯度噪声假设下，建立样本复杂度与有效学习率衰减的关系。

Result: 推导出可学习窗口H_N的显式公式和标度律，预测更宽或更异质的门控谱产生更慢的有效学习率衰减，从而扩大可学习窗口；而更重的噪声尾部会压缩可学习窗口。

Conclusion: 有效学习率是决定门控循环网络何时以及多长能够学习长程时间依赖的基本量，该框架连接了门控时间尺度结构、梯度噪声和样本复杂度。

Abstract: We develop a theoretical framework that explains how gating mechanisms determine the learnability window $\mathcal{H}_N$ of recurrent neural networks, defined as the largest temporal horizon over which gradient information remains statistically recoverable. While classical analyses emphasize numerical stability of Jacobian products, we show that stability alone is insufficient: learnability is governed instead by the \emph{effective learning rates} $μ_{t,\ell}$, per-lag and per-neuron quantities obtained from first-order expansions of gate-induced Jacobian products in Backpropagation Through Time. These effective learning rates act as multiplicative filters that control both the magnitude and anisotropy of gradient transport. Under heavy-tailed ($α$-stable) gradient noise, we prove that the minimal sample size required to detect a dependency at lag~$\ell$ satisfies $N(\ell)\propto f(\ell)^{-α}$, where $f(\ell)=\|μ_{t,\ell}\|_1$ is the effective learning rate envelope. This leads to an explicit formula for $\mathcal{H}_N$ and closed-form scaling laws for logarithmic, polynomial, and exponential decay of $f(\ell)$. The theory predicts that broader or more heterogeneous gate spectra produce slower decay of $f(\ell)$ and hence larger learnability windows, whereas heavier-tailed noise compresses $\mathcal{H}_N$ by slowing statistical concentration. By linking gate-induced time-scale structure, gradient noise, and sample complexity, the framework identifies the effective learning rates as the fundamental quantities that govern when -- and for how long -- gated recurrent networks can learn long-range temporal dependencies.

</details>


### [97] [Mechanistic Interpretability of Antibody Language Models Using SAEs](https://arxiv.org/abs/2512.05794)
*Rebonto Haque,Oliver M. Turnbull,Anisha Parsan,Nithin Parsan,John J. Yang,Charlotte M. Deane*

Main category: cs.LG

TL;DR: TopK SAEs可识别生物学特征但控制生成效果有限，Ordered SAEs能可靠控制生成但可解释性较差，两者各有适用场景


<details>
  <summary>Details</summary>
Motivation: 研究稀疏自编码器在蛋白质语言模型中的机制可解释性，特别是如何有效控制抗体语言模型p-IgGen的生成过程

Method: 使用TopK和Ordered两种稀疏自编码器技术分析自回归抗体语言模型p-IgGen，比较它们在特征识别和生成控制方面的表现

Result: TopK SAEs能揭示有生物学意义的潜在特征，但高特征概念相关性不能保证对生成的有效因果控制；Ordered SAEs能可靠识别可控制特征，但激活模式更复杂且可解释性较差

Conclusion: TopK SAEs适用于将潜在特征映射到概念，而Ordered SAEs在需要精确生成控制时更优，这推进了领域特定蛋白质语言模型的机制可解释性研究

Abstract: Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.

</details>


### [98] [Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws](https://arxiv.org/abs/2512.05817)
*Zhengquan Luo,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 提出统一的配置-动态-误差分析框架，将主流数据集蒸馏方法统一到泛化误差视角，揭示了误差随蒸馏样本数增长的缩放规律和随配置多样性线性增长的覆盖规律。


<details>
  <summary>Details</summary>
Motivation: 尽管数据集蒸馏在实证上进展迅速，但其理论基础有限：现有方法基于不同的代理目标和优化假设，难以分析共同原理或提供一般性保证。同时，不清楚在训练配置（优化器、架构、增强等）变化时，蒸馏数据如何保持全数据集的有效性。

Method: 提出配置-动态-误差分析统一理论框架，将梯度匹配、分布匹配、轨迹匹配等主要DD方法重新表述为共同的泛化误差视角。该框架提供两个主要结果：缩放规律（单配置上界）和覆盖规律（所需蒸馏样本数与配置多样性线性缩放）。

Result: 推导出误差随蒸馏样本数增长的缩放规律，解释了常见的性能饱和效应；证明了所需蒸馏样本数与配置多样性呈线性缩放，并提供了可证明匹配的上界和下界。实验验证了这些规律在不同方法和配置中的有效性。

Conclusion: 统一分析揭示了各种匹配方法是可互换的代理，减少相同的泛化误差，解释了它们都能实现数据集蒸馏的原因，并为代理选择如何影响样本效率和鲁棒性提供了指导。这为DD建立了理论基础，并支持理论驱动的紧凑、配置鲁棒的数据集蒸馏设计。

Abstract: Dataset distillation (DD) aims to construct compact synthetic datasets that allow models to achieve comparable performance to full-data training while substantially reducing storage and computation. Despite rapid empirical progress, its theoretical foundations remain limited: existing methods (gradient, distribution, trajectory matching) are built on heterogeneous surrogate objectives and optimization assumptions, which makes it difficult to analyze their common principles or provide general guarantees. Moreover, it is still unclear under what conditions distilled data can retain the effectiveness of full datasets when the training configuration, such as optimizer, architecture, or augmentation, changes. To answer these questions, we propose a unified theoretical framework, termed configuration--dynamics--error analysis, which reformulates major DD approaches under a common generalization-error perspective and provides two main results: (i) a scaling law that provides a single-configuration upper bound, characterizing how the error decreases as the distilled sample size increases and explaining the commonly observed performance saturation effect; and (ii) a coverage law showing that the required distilled sample size scales linearly with configuration diversity, with provably matching upper and lower bounds. In addition, our unified analysis reveals that various matching methods are interchangeable surrogates, reducing the same generalization error, clarifying why they can all achieve dataset distillation and providing guidance on how surrogate choices affect sample efficiency and robustness. Experiments across diverse methods and configurations empirically confirm the derived laws, advancing a theoretical foundation for DD and enabling theory-driven design of compact, configuration-robust dataset distillation.

</details>


### [99] [Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization](https://arxiv.org/abs/2512.05825)
*Shuhei Watanabe*

Main category: cs.LG

TL;DR: 本文提供了超体积近似算法的完整数学和算法描述，填补了文献中的空白


<details>
  <summary>Details</summary>
Motivation: 超体积贝叶斯优化中，获取函数的优化计算成本高，主要源于超体积改进计算的开销。虽然超体积盒分解能应对频繁的精确改进计算，但在最坏情况下具有超多项式内存复杂度。现有近似算法缺乏严格的算法描述。

Method: 提供Couckuyt等人（2012）提出的超体积近似算法的全面数学和算法细节描述

Result: 填补了文献中关于超体积近似算法缺乏严格算法描述的空白

Conclusion: 本文通过提供该近似算法的完整数学和算法细节，为超体积贝叶斯优化领域做出了贡献

Abstract: Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\lfloor \frac{M + 1}{2} \rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.

</details>


### [100] [NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation](https://arxiv.org/abs/2512.05844)
*Daniel Rose,Roxane Axel Jacob,Johannes Kirchmair,Thierry Langer*

Main category: cs.LG

TL;DR: NEAT是一种用于3D分子生成的邻域引导、高效、自回归的集合Transformer，通过将分子图视为原子集合并学习图边界上可接受标记的顺序无关分布，解决了自回归模型中原子排列顺序假设的限制问题。


<details>
  <summary>Details</summary>
Motivation: 自回归模型是3D分子结构生成中扩散模型的有前途替代方案，但存在一个关键限制：假设标记顺序。文本具有自然顺序，但给定分子图前缀的下一个标记预测应该对原子排列不变。先前工作通过使用规范顺序或焦点原子来回避这种不匹配，但作者认为这是不必要的。

Method: NEAT（邻域引导、高效、自回归、集合Transformer）将分子图视为原子集合，使用自回归流模型学习图边界上可接受标记的顺序无关分布。它通过集合Transformer架构实现原子级排列不变性。

Result: NEAT在3D分子生成方面接近最先进性能，具有高计算效率和原子级排列不变性，为可扩展分子设计建立了实用基础。

Conclusion: NEAT通过将分子图视为集合并学习顺序无关分布，解决了自回归模型在分子生成中的原子排列顺序假设问题，为高效、可扩展的3D分子设计提供了实用解决方案。

Abstract: Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.

</details>


### [101] [Sparse Attention Post-Training for Mechanistic Interpretability](https://arxiv.org/abs/2512.05865)
*Florent Draye,Anson Lei,Ingmar Posner,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 提出一种简单的后训练方法，通过稀疏正则化使Transformer注意力稀疏化，在保持性能的同时将注意力连接减少到约0.3%，并发现这种局部稀疏性会级联到全局电路简化。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法主要关注计算效率，但本文旨在利用稀疏性作为结构先验，揭示Transformer中更有序、可解释的连接模式，证明大部分计算是冗余的。

Method: 采用简单的后训练方法，在约束损失目标下应用灵活的稀疏正则化，使Transformer注意力稀疏化而不牺牲性能，适用于高达10亿参数的模型。

Result: 在保持原始预训练损失的同时，将注意力连接减少到约0.3%的边；任务特定电路涉及的组件（注意力头和MLP）更少，连接边减少高达100倍。

Conclusion: Transformer注意力可以变得稀疏数个数量级，表明其大部分计算是冗余的，稀疏性可以作为构建更结构化、可解释模型的指导原则。

Abstract: We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\approx 0.3 \%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.

</details>


### [102] [Predicting Price Movements in High-Frequency Financial Data with Spiking Neural Networks](https://arxiv.org/abs/2512.05868)
*Brian Ezinwoke,Oliver Rhodes*

Main category: cs.LG

TL;DR: 该研究将脉冲神经网络应用于高频交易中的价格尖峰预测，通过贝叶斯优化和惩罚性脉冲准确率目标函数提升性能，实验表明优化后的脉冲神经网络在模拟交易中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 高频交易环境中存在突然的价格尖峰，这既是风险也是机会。传统的金融模型往往无法捕捉所需的精细时间结构，而脉冲神经网络具有处理离散事件和保持毫秒级时间精度的天然优势，适合解决这一挑战。

Method: 将高频股票数据转换为脉冲序列，评估三种架构：1) 基于STDP训练的无监督脉冲神经网络；2) 具有显式抑制竞争的新型脉冲神经网络；3) 监督反向传播网络。使用贝叶斯优化进行超参数调优，并引入新的目标函数——惩罚性脉冲准确率，确保网络预测的价格尖峰率与经验价格事件率一致。

Result: 使用PSA优化的模型在模拟交易中始终优于使用SA优化的模型和基线方法。具体而言，扩展的脉冲神经网络模型在简单回测中实现了最高的累计回报率（76.8%），显著优于监督替代方案（42.54%回报率）。

Conclusion: 研究验证了脉冲神经网络在通过任务特定目标进行稳健调优后，在高频交易价格尖峰预测中的有效性。这表明脉冲神经网络框架在捕捉金融市场中精细时间结构方面具有潜力。

Abstract: Modern high-frequency trading (HFT) environments are characterized by sudden price spikes that present both risk and opportunity, but conventional financial models often fail to capture the required fine temporal structure. Spiking Neural Networks (SNNs) offer a biologically inspired framework well-suited to these challenges due to their natural ability to process discrete events and preserve millisecond-scale timing. This work investigates the application of SNNs to high-frequency price-spike forecasting, enhancing performance via robust hyperparameter tuning with Bayesian Optimization (BO). This work converts high-frequency stock data into spike trains and evaluates three architectures: an established unsupervised STDP-trained SNN, a novel SNN with explicit inhibitory competition, and a supervised backpropagation network. BO was driven by a novel objective, Penalized Spike Accuracy (PSA), designed to ensure a network's predicted price spike rate aligns with the empirical rate of price events. Simulated trading demonstrated that models optimized with PSA consistently outperformed their Spike Accuracy (SA)-tuned counterparts and baselines. Specifically, the extended SNN model with PSA achieved the highest cumulative return (76.8%) in simple backtesting, significantly surpassing the supervised alternative (42.54% return). These results validate the potential of spiking networks, when robustly tuned with task-specific objectives, for effective price spike forecasting in HFT.

</details>


### [103] [Computational Design of Low-Volatility Lubricants for Space Using Interpretable Machine Learning](https://arxiv.org/abs/2512.05870)
*Daniel Miliate,Ashlie Martini*

Main category: cs.LG

TL;DR: 使用机器学习预测蒸汽压，筛选适用于太空机械组件的液体润滑剂


<details>
  <summary>Details</summary>
Motivation: 太空中的移动机械组件需要液体润滑剂，但现有适合真空条件的润滑剂种类有限且各有局限性，限制了机械设计

Method: 采用数据驱动的机器学习方法，结合高通量分子动力学模拟和实验数据库数据训练模型，注重模型可解释性以识别化学结构与蒸汽压的关系

Result: 训练出能够预测蒸汽压的机器学习模型，基于模型洞察提出了几种有潜力的候选分子用于未来太空润滑剂应用

Conclusion: 机器学习方法能够有效预测蒸汽压，为发现新型太空适用液体润滑剂提供了虚拟筛选工具，有助于突破现有润滑剂限制

Abstract: The function and lifetime of moving mechanical assemblies (MMAs) in space depend on the properties of lubricants. MMAs that experience high speeds or high cycles require liquid based lubricants due to their ability to reflow to the point of contact. However, only a few liquid-based lubricants have vapor pressures low enough for the vacuum conditions of space, each of which has limitations that add constraints to MMA designs. This work introduces a data-driven machine learning (ML) approach to predicting vapor pressure, enabling virtual screening and discovery of new space-suitable liquid lubricants. The ML models are trained with data from both high-throughput molecular dynamics simulations and experimental databases. The models are designed to prioritize interpretability, enabling the relationships between chemical structure and vapor pressure to be identified. Based on these insights, several candidate molecules are proposed that may have promise for future space lubricant applications in MMAs.

</details>


### [104] [Neural Coherence : Find higher performance to out-of-distribution tasks from few samples](https://arxiv.org/abs/2512.05880)
*Simon Guiroy,Mats Richter,Sarath Chandar,Christopher Pal*

Main category: cs.LG

TL;DR: 提出基于神经相干性的模型选择方法，仅需少量无标注目标域样本即可有效选择预训练模型检查点，在数据稀缺、分布外场景下显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前微调预训练视觉模型时，如何从大量训练检查点中选择最佳起点仍是一个开放问题。当目标任务数据稀缺、无标注且分布外时，依赖分布内验证数据的传统方法变得不可靠或不适用。

Method: 提出神经相干性概念，通过分析模型在源域和目标域的激活统计特征，构建数据高效的模型选择方法。该方法仅需少量无标注目标域样本即可评估模型适应性。

Result: 在ImageNet1K预训练模型上，对Food-101、PlantNet-300K和iNaturalist等目标域进行实验，并在元学习设置中验证。相比现有基线，该方法在不同目标域上的泛化能力显著提升。

Conclusion: 神经相干性是一个强大的原则，不仅可用于模型选择，还可扩展到训练数据选择等任务，为数据稀缺场景下的模型适配提供了有效解决方案。

Abstract: To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.

</details>


### [105] [DAE-HardNet: A Physics Constrained Neural Network Enforcing Differential-Algebraic Hard Constraints](https://arxiv.org/abs/2512.05881)
*Rahul Golder,Bimol Nath Roy,M. M. Faruque Hasan*

Main category: cs.LG

TL;DR: DAE-HardNet：一种物理约束神经网络，通过可微分投影层严格满足微分代数方程约束，相比传统PINNs实现物理损失数量级降低


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）通常以软约束方式最小化物理约束违反，难以严格满足包含微分算子的约束。数据驱动模型将原始函数视为黑盒，其导数只能在函数求值后获得，这使得严格嵌入微分代数方程（DAEs）约束具有挑战性。

Method: 提出DAE-HardNet，同时学习函数及其导数，通过可微分投影层将模型预测投影到约束流形上，严格强制执行代数和微分约束。该方法包含投影层，可在推理时绕过以加速。

Result: 在Lotka-Volterra捕食者-猎物系统和瞬态热传导等DAEs控制的问题上，相比多层感知机（MLPs）和PINNs，DAE-HardNet实现物理损失数量级降低，同时保持预测精度。还能学习导数，改进投影层前主干网络的约束学习。

Conclusion: DAE-HardNet是一种物理约束而非仅物理信息的神经网络，能严格满足DAEs约束，在保持精度的同时显著降低物理损失，具有学习导数、可绕过投影层加速推理等优势。

Abstract: Traditional physics-informed neural networks (PINNs) do not always satisfy physics based constraints, especially when the constraints include differential operators. Rather, they minimize the constraint violations in a soft way. Strict satisfaction of differential-algebraic equations (DAEs) to embed domain knowledge and first-principles in data-driven models is generally challenging. This is because data-driven models consider the original functions to be black-box whose derivatives can only be obtained after evaluating the functions. We introduce DAE-HardNet, a physics-constrained (rather than simply physics-informed) neural network that learns both the functions and their derivatives simultaneously, while enforcing algebraic as well as differential constraints. This is done by projecting model predictions onto the constraint manifold using a differentiable projection layer. We apply DAE-HardNet to several systems and test problems governed by DAEs, including the dynamic Lotka-Volterra predator-prey system and transient heat conduction. We also show the ability of DAE-HardNet to estimate unknown parameters through a parameter estimation problem. Compared to multilayer perceptrons (MLPs) and PINNs, DAE-HardNet achieves orders of magnitude reduction in the physics loss while maintaining the prediction accuracy. It has the added benefits of learning the derivatives which improves the constrained learning of the backbone neural network prior to the projection layer. For specific problems, this suggests that the projection layer can be bypassed for faster inference. The current implementation and codes are available at https://github.com/SOULS-TAMU/DAE-HardNet.

</details>


### [106] [NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process](https://arxiv.org/abs/2512.05893)
*Neha Gupta,Aditya Maheshwari*

Main category: cs.LG

TL;DR: 使用LSTM神经网络估计分数泊松过程参数，相比传统矩估计法降低55.3%均方误差，在真实高频率数据上有效追踪日模式和参数变化。


<details>
  <summary>Details</summary>
Motivation: 分数泊松过程能建模具有记忆性和长程依赖的事件到达，但传统参数估计方法（如矩估计法）可能不够准确。需要更有效的方法来估计FPP的关键参数μ和β，特别是在处理具有复杂时间依赖性的真实世界数据时。

Method: 提出基于循环神经网络（RNN）的框架，具体使用长短期记忆（LSTM）网络，从到达时间间隔序列中估计分数泊松过程的参数μ>0和β∈(0,1)。LSTM能有效建模时间依赖关系。

Result: 在合成数据上，相比传统矩估计法（MOM），该方法降低约55.3%的均方误差（MSE），在不同训练条件下表现稳定。在真实高频率数据集（蒙哥马利县紧急呼叫记录和AAPL股票交易数据）上，LSTM能有效追踪日模式和参数变化。

Conclusion: LSTM神经网络能有效估计分数泊松过程的参数，在合成和真实数据上都表现出优越性能，特别适用于具有复杂时间依赖性的高频率事件数据。

Abstract: In this paper, we propose a recurrent neural network (RNN)-based framework for estimating the parameters of the fractional Poisson process (FPP), which models event arrivals with memory and long-range dependence. The Long Short-Term Memory (LSTM) network estimates the key parameters $μ>0$ and $β\in(0,1)$ from sequences of inter-arrival times, effectively modeling their temporal dependencies. Our experiments on synthetic data show that the proposed approach reduces the mean squared error (MSE) by about 55.3\% compared to the traditional method of moments (MOM) and performs reliably across different training conditions. We tested the method on two real-world high-frequency datasets: emergency call records from Montgomery County, PA, and AAPL stock trading data. The results show that the LSTM can effectively track daily patterns and parameter changes, indicating its effectiveness on real-world data with complex time dependencies.

</details>


### [107] [LDLT $\mathcal{L}$-Lipschitz Network: Generalized Deep End-To-End Lipschitz Network Construction](https://arxiv.org/abs/2512.05915)
*Marius F. R. Juston,Ramavarapu S. Sreenivas,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.LG

TL;DR: 提出基于LMI框架的L-Lipschitz深度残差网络设计方法，通过LDL^T分解扩展至任意非线性架构，在121个UCI数据集上相比SLL Layers获得3%-13%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: ResNets在计算机视觉任务中表现出色，但需要控制Lipschitz常数以增强对抗鲁棒性和网络可验证性。现有方法在构建Lipschitz约束网络方面存在局限性。

Method: 将ResNet架构重新表述为循环三对角LMI，推导网络参数的闭式约束以确保L-Lipschitz连续性。采用新的LDL^T分解方法验证LMI可行性，将Lipschitz网络构造扩展到任意非线性架构。使用Cholesky分解进行高效参数化。

Result: LDL^T公式是SDP基网络的紧松弛，保持完全表达能力，在121个UCI数据集上相比SLL Layers获得3%-13%的准确率提升。实现了可证明的参数化方法，适用于对抗鲁棒性、认证训练和控制系统。

Conclusion: 提出的LMI框架为构建Lipschitz约束的残差网络和其他分层架构提供了严格方法，LDL^T分解扩展了适用范围，在保持表达能力的同时提升了性能，为鲁棒网络设计提供了新途径。

Abstract: Deep residual networks (ResNets) have demonstrated outstanding success in computer vision tasks, attributed to their ability to maintain gradient flow through deep architectures. Simultaneously, controlling the Lipschitz constant in neural networks has emerged as an essential area of research to enhance adversarial robustness and network certifiability. This paper presents a rigorous approach to the general design of $\mathcal{L}$-Lipschitz deep residual networks using a Linear Matrix Inequality (LMI) framework. Initially, the ResNet architecture was reformulated as a cyclic tridiagonal LMI, and closed-form constraints on network parameters were derived to ensure $\mathcal{L}$-Lipschitz continuity; however, using a new $LDL^\top$ decomposition approach for certifying LMI feasibility, we extend the construction of $\mathcal{L}$-Lipchitz networks to any other nonlinear architecture. Our contributions include a provable parameterization methodology for constructing Lipschitz-constrained residual networks and other hierarchical architectures. Cholesky decomposition is also used for efficient parameterization. These findings enable robust network designs applicable to adversarial robustness, certified training, and control systems. The $LDL^\top$ formulation is shown to be a tight relaxation of the SDP-based network, maintaining full expressiveness and achieving 3\%-13\% accuracy gains over SLL Layers on 121 UCI data sets.

</details>


### [108] [KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity](https://arxiv.org/abs/2512.05916)
*Damien Lesens,Beheshteh T. Rakhshan,Guillaume Rabusseau*

Main category: cs.LG

TL;DR: KQ-SVD：一种直接对注意力矩阵进行最优低秩分解的新方法，通过闭式解提升KV缓存压缩效果


<details>
  <summary>Details</summary>
Motivation: 随着序列长度和批处理大小的增加，Transformer大语言模型中的KV缓存成为主要内存瓶颈。现有压缩方法通常只对键进行低秩分解或尝试联合嵌入查询和键，但都忽略了注意力机制本质上依赖于它们的内积这一事实。

Method: 提出KQ-SVD方法，直接对注意力矩阵进行最优低秩分解，通过闭式解实现。该方法针对冗余的真正来源，在压缩下能更高保真地保留注意力输出。

Result: 在LLaMA和Mistral模型上的广泛评估表明，KQ-SVD方法在投影质量方面始终提供更优越的性能。

Conclusion: 通过直接对注意力矩阵进行最优分解，KQ-SVD方法比现有压缩策略能更有效地解决KV缓存的内存瓶颈问题。

Abstract: The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.

</details>


### [109] [On the Bayes Inconsistency of Disagreement Discrepancy Surrogates](https://arxiv.org/abs/2512.05931)
*Neil G. Marchant,Andrew C. Cullen,Feng Liu,Sarah M. Erfani*

Main category: cs.LG

TL;DR: 论文提出了一种新的可证明一致的替代损失函数来解决现有方法在最大化分歧差异时的贝叶斯不一致问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在现实世界部署中常因分布偏移而失效。现有基于分歧差异的方法使用不可微的0-1损失，需要替代损失函数，但现有替代损失存在贝叶斯不一致的根本缺陷。

Method: 提出新的理论结果，为替代损失的最优性差距提供上下界。基于此理论，设计了一种新的分歧损失，与交叉熵配对使用，形成可证明一致的分歧差异替代损失。

Result: 在多样化基准测试中，新方法比现有方法提供更准确和鲁棒的分歧差异估计，特别是在具有挑战性的对抗条件下表现更优。

Conclusion: 通过理论分析和实验验证，提出的新损失函数解决了现有替代损失的贝叶斯不一致问题，为分布偏移下的模型鲁棒性评估提供了更可靠的工具。

Abstract: Deep neural networks often fail when deployed in real-world contexts due to distribution shift, a critical barrier to building safe and reliable systems. An emerging approach to address this problem relies on \emph{disagreement discrepancy} -- a measure of how the disagreement between two models changes under a shifting distribution. The process of maximizing this measure has seen applications in bounding error under shifts, testing for harmful shifts, and training more robust models. However, this optimization involves the non-differentiable zero-one loss, necessitating the use of practical surrogate losses. We prove that existing surrogates for disagreement discrepancy are not Bayes consistent, revealing a fundamental flaw: maximizing these surrogates can fail to maximize the true disagreement discrepancy. To address this, we introduce new theoretical results providing both upper and lower bounds on the optimality gap for such surrogates. Guided by this theory, we propose a novel disagreement loss that, when paired with cross-entropy, yields a provably consistent surrogate for disagreement discrepancy. Empirical evaluations across diverse benchmarks demonstrate that our method provides more accurate and robust estimates of disagreement discrepancy than existing approaches, particularly under challenging adversarial conditions.

</details>


### [110] [Developing synthetic microdata through machine learning for firm-level business surveys](https://arxiv.org/abs/2512.05948)
*Jorge Cisneros Paz,Timothy Wojan,Matthew Williams,Jennifer Ozawa,Robert Chew,Kimberly Janda,Timothy Navarro,Michael Floyd,Christine Task,Damon Streat*

Main category: cs.LG

TL;DR: 该论文提出使用机器学习方法为美国年度商业调查(ABS)生成合成公共使用微数据样本(PUMS)，以解决商业数据去匿名化风险，并通过实证研究验证合成数据的真实性。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力提升和大数据可用性增加，传统匿名化方法已不足以保护商业调查数据的机密性。商业数据面临独特挑战，因为企业缺乏匿名性且某些行业在特定地理区域容易被识别。需要开发既能保护受访者隐私又能保持数据实用性的合成数据方法。

Method: 采用机器学习模型构建基于年度商业调查(ABS)的合成PUMS数据。具体方法包括：1) 使用数据科学技术生成合成数据，保留原始数据的关键统计特征；2) 开发质量评估指标；3) 以2007年企业主调查为案例创建合成PUMS；4) 通过计量经济学复制已发表的高影响力研究来验证数据真实性。

Result: 成功开发了ABS合成PUMS数据，虽然当前ABS PUMS仍在完善中且结果保密，但基于2007年企业主调查的合成PUMS已展示出良好效果。通过复制《小企业经济学》期刊上的高影响力分析，证明合成数据与真实数据具有高度相似性，验证了方法的有效性。

Conclusion: 机器学习生成的合成商业数据能够有效平衡数据实用性与隐私保护，为ABS等商业调查数据的公共使用提供了可行方案。该方法不仅保护了受访者机密性，还能支持有意义的实证研究，展示了合成数据在商业统计领域的应用潜力。

Abstract: Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.

</details>


### [111] [Impugan: Learning Conditional Generative Models for Robust Data Imputation](https://arxiv.org/abs/2512.05950)
*Zalish Mahmud,Anantaa Kotal,Aritran Piplai*

Main category: cs.LG

TL;DR: Impugan使用条件生成对抗网络(cGAN)填补缺失值并整合异构数据集，相比传统方法能更好地捕捉非线性多模态关系，在基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常存在缺失值，传统填补方法基于线性独立性假设，难以处理复杂异构数据，导致估计偏差或过度平滑。

Method: 提出Impugan条件生成对抗网络：生成器根据观测特征重建缺失值，判别器区分真实与填补数据，通过对抗训练学习缺失变量与观测变量的依赖关系。

Result: 在基准数据集和多源整合任务中，Impugan相比领先基线方法，Earth Mover's Distance降低82%，互信息偏差降低70%。

Conclusion: 对抗训练的生成模型为填补和整合不完整、异构数据提供了可扩展且原则性的方法，能有效捕捉传统方法无法表示的非线性和多模态关系。

Abstract: Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\% lower Earth Mover's Distance (EMD) and 70\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025

</details>


### [112] [MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution](https://arxiv.org/abs/2512.05958)
*Sara Patel,Mingxun Zhou,Giulia Fanti*

Main category: cs.LG

TL;DR: 提出MaxShapley算法，用于生成式搜索引擎中基于检索增强生成(RAG)的内容提供者公平归因和补偿，计算效率比传统Shapley值指数级提升。


<details>
  <summary>Details</summary>
Motivation: 生成式搜索引擎正在取代传统搜索，改变了信息提供者的补偿模式。需要公平的机制来归因和补偿内容提供者基于他们对生成答案的贡献。

Method: 提出MaxShapley算法，这是Shapley值的一个特例，利用可分解的最大和效用函数，将归因计算复杂度从指数级降低到线性级。

Result: 在三个多跳QA数据集(HotPotQA、MuSiQUE、MS MARCO)上评估，MaxShapley达到与精确Shapley计算相当的归因质量，同时显著减少计算资源消耗，比现有方法减少高达8倍资源消耗。

Conclusion: MaxShapley为生成式搜索生态系统提供了一种高效公平的内容提供者归因机制，解决了传统Shapley值计算成本过高的问题。

Abstract: Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.

</details>


### [113] [Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity](https://arxiv.org/abs/2512.05962)
*Germán Kruszewski,Pierre Erbacher,Jos Rozen,Marc Dymetman*

Main category: cs.LG

TL;DR: 该论文提出使用α-散度替代传统RL方法，通过显式目标分布和α-散度插值控制精度-多样性权衡，在Lean定理证明基准上实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在微调LLMs时会导致多样性显著损失，这是因为RL隐式优化了"模式寻求"的反向KL散度，使模型集中在目标分布的高概率区域而忽略其他区域。

Method: 从显式目标分布出发（通过过滤错误答案同时保留正确答案的相对概率），使用α-散度族近似该目标分布，通过插值在模式寻求和质量覆盖散度之间实现精度-多样性权衡的直接控制。

Result: 在Lean定理证明基准上，该方法在覆盖度-精度Pareto前沿上实现了最先进的性能，在覆盖度轴上优于所有先前方法。

Conclusion: 通过α-散度族显式控制精度-多样性权衡的方法优于传统RL方法，能够在保持多样性的同时实现高性能，为LLMs微调提供了更平衡的解决方案。

Abstract: Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the "mode-seeking" or "zero-forcing" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.

</details>
