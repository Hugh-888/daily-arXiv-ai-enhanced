<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [cs.LG](#cs.LG) [Total: 159]
- [quant-ph](#quant-ph) [Total: 62]
- [gr-qc](#gr-qc) [Total: 33]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Updating DMD Operators for Changes in Domain Properties](https://arxiv.org/abs/2602.18441)
*Dimitrios Voulanas,Eduardo Gildin*

Main category: physics.comp-ph

TL;DR: 提出两种轻量级更新策略，无需重新训练即可调整DMD模型以适应储层参数变化，实现快速碳封存优化分析


<details>
  <summary>Details</summary>
Motivation: 地质碳封存项目需要快速可靠的代理模型，但高精度多相模拟器计算成本高。传统DMD方法在储层性质变化时需要重新训练，失去了速度优势

Method: 提出两种轻量级更新策略：1) 当渗透率均匀变化时，调整模型内部动力学和控制响应以匹配新的流动时间尺度；2) 当渗透率空间变化时，修改空间表示使高渗透率区域在降维基中具有更大影响

Result: 数值实验表明，提出的更新方法能在新训练代理模型的3%误差内恢复羽流迁移和压力积聚，执行速度比完全重新训练快数百倍

Conclusion: 这些方法能够在保持碳封存工作流程所需物理保真度的同时，实现实时优化和快速假设分析，无需重新训练或新模拟数据

Abstract: Fast and reliable surrogate models are critical for optimization, control and uncertainty analysis in geological carbon-storage projects, yet high-fidelity multiphase simulators remain too expensive. Dynamic Mode Decomposition (DMD) offers an attractive data-driven reduction framework, but its operators are trained for a single set of reservoir properties. When permeability or well location changes, conventional practice is to regenerate snapshots and retrain the surrogate, erasing most of the speed advantage. This work presents a lightweight alternative that updates an existing DMD or DMD-with-control model without incorporating new simulation data or retraining. Two complementary update strategies are introduced. For cases where permeability changes uniformly across the domain, the proposed updates adjust the models internal dynamics and control response to match the new flow timescale. When permeability varies in space, the approach modifies the spatial representation so that high-permeability zones are given greater influence on the models reduced basis. Numerical experiments demonstrate that the proposed updates recover plume migration and pressure build-up within three percent of a freshly trained surrogate yet execute hundreds of times faster than full retraining. These methods therefore enable real-time optimization and rapid what-if studies while preserving the physical fidelity demanded by carbon-storage workflows.

</details>


### [2] [Boltzmann Generators for Condensed Matter via Riemannian Flow Matching](https://arxiv.org/abs/2602.18482)
*Emil Hoffmann,Maximilian Schebek,Leon Klein,Frank Noé,Jutta Rogal*

Main category: physics.comp-ph

TL;DR: 提出了一种结合黎曼流匹配和周期性边界条件的连续归一化流方法，用于凝聚相系统的平衡采样，通过Hutchinson迹估计器和累积展开偏差校正降低计算成本，在单原子冰系统上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然流匹配已成为生成建模的最新范式，但其在凝聚相系统平衡采样中的应用尚未充分探索。凝聚相系统具有周期性边界条件，需要专门的方法来处理这种几何结构。

Method: 1. 将凝聚相系统的周期性纳入连续归一化流，使用黎曼流匹配处理周期性几何；2. 采用Hutchinson迹估计器降低精确密度估计的高计算成本；3. 基于累积展开的关键偏差校正步骤，使随机估计适用于严格的热力学重加权。

Result: 在单原子冰系统上验证了方法，能够训练前所未有的系统规模，并获得高度准确的自由能估计，无需传统的多阶段估计器。

Conclusion: 该方法成功将流匹配技术应用于凝聚相系统的平衡采样，通过创新的偏差校正和计算优化，实现了大规模系统的高精度自由能计算，为统计力学中的平衡分布采样提供了新工具。

Abstract: Sampling equilibrium distributions is fundamental to statistical mechanics. While flow matching has emerged as scalable state-of-the-art paradigm for generative modeling, its potential for equilibrium sampling in condensed-phase systems remains largely unexplored. We address this by incorporating the periodicity inherent to these systems into continuous normalizing flows using Riemannian flow matching. The high computational cost of exact density estimation intrinsic to continuous normalizing flows is mitigated by using Hutchinson's trace estimator, utilizing a crucial bias-correction step based on cumulant expansion to render the stochastic estimates suitable for rigorous thermodynamic reweighting. Our approach is validated on monatomic ice, demonstrating the ability to train on systems of unprecedented size and obtain highly accurate free energy estimates without the need for traditional multistage estimators.

</details>


### [3] [Multiphysics Modelling of the Molten Salt Fast Reactor using NekRS and the Fission Matrix Method](https://arxiv.org/abs/2602.18626)
*Maximiliano Dalinger,Elia Merzari,Saya Lee*

Main category: physics.comp-ph

TL;DR: 提出使用降阶模型（裂变矩阵法）结合高保真工具Cardinal开发MSFR的中子学-热工水力学耦合计算模型


<details>
  <summary>Details</summary>
Motivation: 熔盐快堆（MSFR）的冷却剂同时也是燃料，导致燃料在初级系统中循环时中子学与热工水力学紧密耦合，需要多物理场方法进行分析

Method: 使用MOOSE框架中的高保真工具Cardinal，结合计算流体动力学代码NekRS，但用裂变矩阵法代替OpenMC求解中子学方程，该方法基于预计算的蒙特卡洛数据库实现快速准确模拟

Result: 论文提出了一个MSFR的中子学-热工水力学耦合计算模型框架，利用降阶模型（裂变矩阵法）提高计算效率

Conclusion: 开发了基于裂变矩阵法的降阶模型与高保真工具结合的MSFR多物理场计算方法，为MSFR分析提供了高效准确的计算框架

Abstract: The Molten Salt Fast Reactor (MSFR) has the particularity that the coolant is also the fuel, which tightens the coupling between neutronics and thermal hydraulics as the fuel circulates through the primary system. Therefore, developing computational models to analyze the MSFR requires a multiphysics approach. In this paper, we propose developing a neutronic thermal-hydraulic computational model of the MSFR that uses a reduced-order model to solve the neutronics equations. The principal computational tool chosen for this purpose is the high-fidelity code Cardinal, a wrapping within the MOOSE framework that integrates the Computational Fluid Dynamics code NekRS and the Monte Carlo particle transport code OpenMC. However, we use the Fission Matrix (FM) Method to solve the neutronics equations instead of OpenMC. The FM method can perform fast and still accurate neutronics simulations. It relies on precalculated databases obtained through a Monte Carlo simulation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Revisiting the Seasonal Trend Decomposition for Enhanced Time Series Forecasting](https://arxiv.org/abs/2602.18465)
*Sanjeev Panta,Xu Yuan,Li Chen,Nian-Feng Tzeng*

Main category: cs.LG

TL;DR: 该论文提出了一种基于时间序列分解的改进方法，通过分别处理趋势和季节成分来提升多元时间序列预测性能，在多个基准数据集上实现了约10%的MSE平均降低。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用中时间序列预测面临重大挑战，现有方法在处理趋势和季节成分时存在局限性，特别是可逆实例归一化仅对趋势成分有效，需要更有效的解决方案来减少预测误差。

Method: 采用时间序列分解方法，分别处理趋势和季节成分：对趋势成分使用可逆实例归一化，对季节成分直接应用骨干模型而不进行任何归一化或缩放。最终提出双MLP模型作为计算效率更高的解决方案。

Result: 在四个最先进的基准模型上实现了约10%的MSE平均降低，在美国地质调查局水文数据集上也取得了显著改进，同时保持线性时间复杂度，证明了实际应用的有效性。

Conclusion: 通过分别优化处理趋势和季节成分的策略，能够有效减少时间序列预测误差，提出的双MLP模型在保持性能的同时提高了计算效率，为实际应用提供了可行的解决方案。

Abstract: Time series forecasting presents significant challenges in real-world applications across various domains. Building upon the decomposition of the time series, we enhance the architecture of machine learning models for better multivariate time series forecasting. To achieve this, we focus on the trend and seasonal components individually and investigate solutions to predict them with less errors. Recognizing that reversible instance normalization is effective only for the trend component, we take a different approach with the seasonal component by directly applying backbone models without any normalization or scaling procedures. Through these strategies, we successfully reduce error values of the existing state-of-the-art models and finally introduce dual-MLP models as more computationally efficient solutions. Furthermore, our approach consistently yields positive results with around 10% MSE average reduction across four state-of-the-art baselines on the benchmark datasets. We also evaluate our approach on a hydrological dataset extracted from the United States Geological Survey (USGS) river stations, where our models achieve significant improvements while maintaining linear time complexity, demonstrating real-world effectiveness. The source code is available at https://github.com/Sanjeev97/Time-Series-Decomposition

</details>


### [5] [Physiologically Informed Deep Learning: A Multi-Scale Framework for Next-Generation PBPK Modeling](https://arxiv.org/abs/2602.18472)
*Shunqi Liu,Han Qiu,Tong Wang*

Main category: cs.LG

TL;DR: 提出统一科学机器学习框架，结合机理建模与数据驱动方法，改进PBPK模型的计算效率、参数识别和种间外推问题。


<details>
  <summary>Details</summary>
Motivation: PBPK建模是药物开发的重要工具，但面临计算成本高、复杂系统参数识别困难、种间外推不确定性等挑战，限制了其广泛应用。

Method: 提出统一SciML框架：1) Foundation PBPK Transformers将药代动力学预测作为序列建模任务；2) 生理约束扩散模型使用物理信息损失生成生物合规虚拟患者群体；3) 神经异速生长结合图神经网络与神经ODE学习连续跨物种缩放规律。

Result: 在合成数据集上的实验显示，该框架在约束条件下将生理违规率从2.00%降低到0.50%，同时提供了更快的模拟路径。

Conclusion: 该SciML框架成功结合了机理严谨性和数据驱动灵活性，为解决PBPK建模的关键挑战提供了有前景的解决方案。

Abstract: Physiologically Based Pharmacokinetic (PBPK) modeling is a cornerstone of model-informed drug development (MIDD), providing a mechanistic framework to predict drug absorption, distribution, metabolism, and excretion (ADME). Despite its utility, adoption is hindered by high computational costs for large-scale simulations, difficulty in parameter identification for complex biological systems, and uncertainty in interspecies extrapolation. In this work, we propose a unified Scientific Machine Learning (SciML) framework that bridges mechanistic rigor and data-driven flexibility. We introduce three contributions: (1) Foundation PBPK Transformers, which treat pharmacokinetic forecasting as a sequence modeling task; (2) Physiologically Constrained Diffusion Models (PCDM), a generative approach that uses a physics-informed loss to synthesize biologically compliant virtual patient populations; and (3) Neural Allometry, a hybrid architecture combining Graph Neural Networks (GNNs) with Neural ODEs to learn continuous cross-species scaling laws. Experiments on synthetic datasets show that the framework reduces physiological violation rates from 2.00% to 0.50% under constraints while offering a path to faster simulation.

</details>


### [6] [Decentralized Attention Fails Centralized Signals: Rethinking Transformers for Medical Time Series](https://arxiv.org/abs/2602.18473)
*Guoqi Yu,Juncheng Wang,Chen Yang,Jing Qin,Angelica I. Aviles-Rivero,Shujun Wang*

Main category: cs.LG

TL;DR: 提出CoTAR模块，用中心化的MLP替代Transformer的分散注意力机制，更好地捕捉医学时间序列的通道依赖关系，在效果和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 医学时间序列数据（如EEG、ECG）具有时间依赖性和通道依赖性两个关键模式。现有的Transformer模型能有效捕捉时间依赖性，但由于其注意力机制是分散式的，难以有效建模通道依赖性，这与医学信号的集中化特性存在结构不匹配。

Method: 提出CoTAR（核心令牌聚合-重分配）模块，这是一个中心化的基于MLP的模块，用于替代分散的注意力机制。CoTAR引入一个全局核心令牌作为代理，促进令牌间的交互，实现集中化的聚合和重分配策略，计算复杂度从二次降为线性。

Result: 在五个基准测试上验证了方法的优越性，在APAVA数据集上实现了12.13%的性能提升，同时仅使用先前最优方法33%的内存和20%的推理时间。

Conclusion: CoTAR模块通过中心化设计更好地匹配医学时间序列的集中化特性，在保持高效计算的同时显著提升了模型性能，为医学时间序列分析提供了更有效的解决方案。

Abstract: Accurate analysis of medical time series (MedTS) data, such as electroencephalography (EEG) and electrocardiography (ECG), plays a pivotal role in healthcare applications, including the diagnosis of brain and heart diseases. MedTS data typically exhibit two critical patterns: temporal dependencies within individual channels and channel dependencies across multiple channels. While recent advances in deep learning have leveraged Transformer-based models to effectively capture temporal dependencies, they often struggle with modeling channel dependencies. This limitation stems from a structural mismatch: MedTS signals are inherently centralized, whereas the Transformer's attention mechanism is decentralized, making it less effective at capturing global synchronization and unified waveform patterns. To address this mismatch, we propose CoTAR (Core Token Aggregation-Redistribution), a centralized MLP-based module designed to replace decentralized attention. Instead of allowing all tokens to interact directly, as in standard attention, CoTAR introduces a global core token that serves as a proxy to facilitate inter-token interactions, thereby enforcing a centralized aggregation and redistribution strategy. This design not only better aligns with the centralized nature of MedTS signals but also reduces computational complexity from quadratic to linear. Experiments on five benchmarks validate the superiority of our method in both effectiveness and efficiency, achieving up to a 12.13% improvement on the APAVA dataset, while using only 33% of the memory and 20% of the inference time compared to the previous state of the art. Code and all training scripts are available at https://github.com/Levi-Ackman/TeCh.

</details>


### [7] [Support Vector Data Description for Radar Target Detection](https://arxiv.org/abs/2602.18486)
*Jean Pinsolle,Yadang Alexis Rouzoumka,Chengfang Ren,Chistèle Morisseau,Jean-Philippe Ovarlez*

Main category: cs.LG

TL;DR: 提出基于SVDD和Deep SVDD的雷达目标检测方法，避免直接估计噪声协方差矩阵，在杂波环境中表现优于传统自适应检测器


<details>
  <summary>Details</summary>
Motivation: 传统雷达自适应检测器在高斯环境中有效，但在杂波（重尾分布）环境中性能下降，特别是当热噪声与杂波混合时，即使鲁棒协方差估计器也难以应对

Method: 采用支持向量数据描述(SVDD)及其深度扩展Deep SVDD作为一类学习方法，避免直接噪声协方差估计，将其适配为CFAR检测器，提出两种新的SVDD基检测算法

Result: 在模拟雷达数据上证明了所提方法的有效性

Conclusion: SVDD和Deep SVDD为杂波环境中的雷达目标检测提供了有前景的替代方案，避免了传统协方差估计的局限性

Abstract: Classical radar detection techniques rely on adaptive detectors that estimate the noise covariance matrix from target-free secondary data. While effective in Gaussian environments, these methods degrade in the presence of clutter, which is better modeled by heavy-tailed distributions such as the Complex Elliptically Symmetric (CES) and Compound-Gaussian (CGD) families. Robust covariance estimators like M-estimators or Tyler's estimator address this issue, but still struggle when thermal noise combines with clutter. To overcome these challenges, we investigate the use of Support Vector Data Description (SVDD) and its deep extension, Deep SVDD, for target detection. These one-class learning methods avoid direct noise covariance estimation and are adapted here as CFAR detectors. We propose two novel SVDD-based detection algorithms and demonstrate their effectiveness on simulated radar data.

</details>


### [8] [Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning](https://arxiv.org/abs/2602.18493)
*Kehao Zhang,Shangtong Gui,Sheng Yang,Wei Chen,Yang Feng*

Main category: cs.LG

TL;DR: UMA是一个统一的强化学习框架，将内存操作和问答整合到单一策略中，通过主动内存管理在超长流处理中优于传统长上下文LLM和RAG系统。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文LLM和RAG系统在处理超长信息流时存在被动处理的局限性，将状态跟踪、矛盾解决和证据聚合推迟到查询时，导致在频繁更新的长流中变得脆弱。

Method: 提出统一内存代理(UMA)，采用端到端强化学习框架，维护双重内存表示：紧凑的核心摘要用于全局上下文，结构化内存库支持对键值条目的显式CRUD操作，在流处理过程中实现主动整合。

Result: 在涵盖Ledger-QA、测试时学习和准确检索的13个数据集上，UMA在动态推理和学习任务上显著优于长上下文和RAG基线，同时在标准检索基准上保持竞争力。

Conclusion: UMA展示了端到端学习内存管理的重要性，通过主动内存操作在超长流处理中实现更鲁棒的动态推理能力。

Abstract: Long-context LLMs and Retrieval-Augmented Generation (RAG) systems process information passively, deferring state tracking, contradiction resolution, and evidence aggregation to query time, which becomes brittle under ultra long streams with frequent updates. We propose the Unified Memory Agent (UMA), an end-to-end reinforcement learning framework that unifies memory operations and question answering within a single policy. UMA maintains a dual memory representation: a compact core summary for global context and a structured Memory Bank that supports explicit CRUD (create, update, delete, reorganize) over key value entries, enabling proactive consolidation during streaming. To evaluate long-horizon memory behavior, we introduce Ledger-QA, a diagnostic benchmark for continuous state tracking where answers are latent values derived from accumulated updates rather than lo cal span retrieval. Across 13 datasets spanning Ledger-QA, Test-Time Learning, and Accurate Retrieval, UMA substantially outperforms long-context and RAG baselines on dynamic reasoning and learning tasks while remaining competitive on standard retrieval benchmarks, underscoring the importance of learned, end-to-end memory management.

</details>


### [9] [Weak-Form Evolutionary Kolmogorov-Arnold Networks for Solving Partial Differential Equations](https://arxiv.org/abs/2602.18515)
*Bongseok Kim,Jiahao Zhang,Guang Lin*

Main category: cs.LG

TL;DR: 提出弱形式演化KAN网络，通过弱形式解耦线性系统规模与训练样本数，提升PDE求解的可扩展性和稳定性


<details>
  <summary>Details</summary>
Motivation: 传统强形式演化神经网络在求解时间依赖PDE时存在两个主要问题：1）点状残差离散化导致线性系统病态；2）计算成本随训练样本数增加而不利增长

Method: 提出弱形式演化Kolmogorov-Arnold网络框架，通过弱形式解耦线性系统规模与训练样本数，使用边界约束KAN构造试函数空间满足Dirichlet和周期性边界条件，将Neumann边界条件直接纳入弱形式

Result: 相比强形式方法，弱形式演化KAN提供了更稳定和可扩展的PDE求解方法，线性系统规模与训练样本数解耦，边界条件得到严格满足

Conclusion: 弱形式演化KAN框架为PDE求解提供了稳定且可扩展的方法，对科学机器学习有贡献，在工程应用中具有潜在价值

Abstract: Partial differential equations (PDEs) form a central component of scientific computing. Among recent advances in deep learning, evolutionary neural networks have been developed to successively capture the temporal dynamics of time-dependent PDEs via parameter evolution. The parameter updates are obtained by solving a linear system derived from the governing equation residuals at each time step. However, strong-form evolutionary approaches can yield ill-conditioned linear systems due to pointwise residual discretization, and their computational cost scales unfavorably with the number of training samples. To address these limitations, we propose a weak-form evolutionary Kolmogorov-Arnold Network (KAN) for the scalable and accurate prediction of PDE solutions. We decouple the linear system size from the number of training samples through the weak formulation, leading to improved scalability compared to strong-form approaches. We also rigorously enforce boundary conditions by constructing the trial space with boundary-constrained KANs to satisfy Dirichlet and periodic conditions, and by incorporating derivative boundary conditions directly into the weak formulation for Neumann conditions. In conclusion, the proposed weak-form evolutionary KAN framework provides a stable and scalable approach for PDEs and contributes to scientific machine learning with potential relevance to future engineering applications.

</details>


### [10] [Measuring the Prevalence of Policy Violating Content with ML Assisted Sampling and LLM Labeling](https://arxiv.org/abs/2602.18518)
*Attila Dobi,Aravindh Manickavasagam,Benjamin Thompson,Xiaohan Yang,Faisal Farooq*

Main category: cs.LG

TL;DR: 提出基于设计的测量系统，通过概率抽样和LLM标注，准确测量平台内容违规的流行率，支持多维度分析和实时监控。


<details>
  <summary>Details</summary>
Motivation: 内容安全团队需要反映用户实际体验的指标，而不仅仅是报告数据。准确测量内容违规流行率面临挑战：违规内容通常稀少，人工标注成本高，难以进行频繁、平台代表性的研究。

Method: 设计基于概率抽样的测量系统：1) 使用ML辅助权重从印象流中抽取每日概率样本，将标注预算集中在高曝光和高风险内容上；2) 使用多模态LLM根据政策提示和黄金集验证标注样本；3) 生成设计一致的流行率估计，包含置信区间和仪表板钻取功能。

Result: 系统实现"一个全局样本，多个维度分析"的设计目标：同一每日样本支持通过后分层估计，按表面、观众地理位置、内容年龄等维度分析流行率。系统可配置跨政策使用。

Conclusion: 提出的基于设计的测量系统能够准确、高效地测量内容违规流行率，为内容安全团队提供反映用户实际体验的指标，支持多维度分析和实时监控。

Abstract: Content safety teams need metrics that reflect what users actually experience, not only what is reported. We study prevalence: the fraction of user views (impressions) that went to content violating a given policy on a given day. Accurate prevalence measurement is challenging because violations are often rare and human labeling is costly, making frequent, platform-representative studies slow. We present a design-based measurement system that (i) draws daily probability samples from the impression stream using ML-assisted weights to concentrate label budget on high-exposure and high-risk content while preserving unbiasedness, (ii) labels sampled items with a multimodal LLM governed by policy prompts and gold-set validation, and (iii) produces design-consistent prevalence estimates with confidence intervals and dashboard drilldowns. A key design goal is one global sample with many pivots: the same daily sample supports prevalence by surface, viewer geography, content age, and other segments through post-stratified estimation. We describe the statistical estimators, variance and confidence interval construction, label-quality monitoring, and an engineering workflow that makes the system configurable across policies.

</details>


### [11] [Wide Open Gazes: Quantifying Visual Exploratory Behavior in Soccer with Pose Enhanced Positional Data](https://arxiv.org/abs/2602.18519)
*Joris Bekkers*

Main category: cs.LG

TL;DR: 提出一种基于姿态增强时空追踪的连续随机视觉层方法，量化足球运动员视觉感知，解决传统视觉探索行为测量的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统足球视觉探索行为测量方法存在多个问题：球员位置偏见（主要关注中场球员）、标注困难、二元测量限制（扫描或不扫描）、无法预测短期比赛成功、与基本足球分析模型（如球场控制）不兼容。

Method: 提出公式化连续随机视觉层，使用概率视野和遮挡模型，结合头部和肩部旋转角度，为每个球员创建速度依赖的二维俯视平面视觉地图。将这些视觉地图与球场控制和球场价值表面结合，分析等待阶段（球员等待队友传球）和随后的持球阶段。

Result: 使用2024年美洲杯32场比赛的同步姿态增强追踪数据和持球事件数据，证明聚合视觉指标（如等待传球时观察到的防守区域百分比）能够预测带球动作结束时获得的控制球场价值。该方法不受球员位置限制，无需手动标注，提供连续测量，可无缝集成到现有足球分析框架中。

Conclusion: 新方法克服了传统视觉探索行为测量的局限性，提供更全面、连续、可预测的视觉感知量化，并与现有足球分析框架兼容，开源相关工具以支持集成。

Abstract: Traditional approaches to measuring visual exploratory behavior in soccer rely on counting visual exploratory actions (VEAs) based on rapid head movements exceeding 125°/s, but this method suffer from player position bias (i.e., a focus on central midfielders), annotation challenges, binary measurement constraints (i.e., a player is scanning, or not), lack the power to predict relevant short-term in-game future success, and are incompatible with fundamental soccer analytics models such as pitch control. This research introduces a novel formulaic continuous stochastic vision layer to quantify players' visual perception from pose-enhanced spatiotemporal tracking. Our probabilistic field-of-view and occlusion models incorporate head and shoulder rotation angles to create speed-dependent vision maps for individual players in a two-dimensional top-down plane. We combine these vision maps with pitch control and pitch value surfaces to analyze the awaiting phase (when a player is awaiting the ball to arrive after a pass for a teammate) and their subsequent on-ball phase. We demonstrate that aggregated visual metrics - such as the percentage of defended area observed while awaiting a pass - are predictive of controlled pitch value gained at the end of dribbling actions using 32 games of synchronized pose-enhanced tracking data and on-ball event data from the 2024 Copa America. This methodology works regardless of player position, eliminates manual annotation requirements, and provides continuous measurements that seamlessly integrate into existing soccer analytics frameworks. To further support the integration with existing soccer analytics frameworks we open-source the tools required to make these calculations.

</details>


### [12] [AdaptStress: Online Adaptive Learning for Interpretable and Personalized Stress Prediction Using Multivariate and Sparse Physiological Signals](https://arxiv.org/abs/2602.18521)
*Xueyi Wang,Claudine J. C. Lamoth,Elisabeth Wilhelm*

Main category: cs.LG

TL;DR: 提出一种基于消费级智能手表生理数据的可解释个性化压力预测模型，在16个时间窗口上评估，性能优于现有方法，睡眠指标是最重要的预测因子。


<details>
  <summary>Details</summary>
Motivation: 连续压力预测对生活方式干预有潜在价值，但需要可解释、个性化的方法，利用消费级可穿戴设备数据实现现实环境中的心理健康监测。

Method: 开发时间序列预测模型，利用心率变异性、活动模式和睡眠指标等多变量特征，在16个时间窗口（历史窗口：3、5、7、9天；预测窗口：1、3、5、7天）上预测压力水平，并与最先进的时间序列模型（Informer、TimesNet、PatchTST）和传统基线（CNN、LSTM、CNN-LSTM）进行比较。

Result: 模型在最优设置（5天输入，1天预测）下取得MSE 0.053、MAE 0.190、RMSE 0.226的性能，在所有条件下优于TimesNet、PatchTST、CNN-LSTM、LSTM和CNN，相对最佳基线改进36.9%、25.5%和21.5%。可解释性分析显示睡眠指标是最主要且一致的预测因子（重要性：1.1，一致性：0.9-1.0），而活动特征存在高个体间变异性（0.1-0.2）。

Conclusion: 消费级可穿戴设备结合自适应可解释深度学习能够提供适应个体生理反应的相关压力评估，为现实环境中可扩展、连续、可解释的心理健康监测奠定基础。

Abstract: Continuous stress forecasting could potentially contribute to lifestyle interventions. This paper presents a novel, explainable, and individualized approach for stress prediction using physiological data from consumer-grade smartwatches. We develop a time series forecasting model that leverages multivariate features, including heart rate variability, activity patterns, and sleep metrics, to predict stress levels across 16 temporal horizons (History window: 3, 5, 7, 9 days; forecasting window: 1, 3, 5, 7 days). Our evaluation involves 16 participants monitored for 10-15 weeks. We evaluate our approach across 16 participants, comparing against state-of-the-art time series models (Informer, TimesNet, PatchTST) and traditional baselines (CNN, LSTM, CNN-LSTM) across multiple temporal horizons. Our model achieved performance with an MSE of 0.053, MAE of 0.190, and RMSE of 0.226 in optimal settings (5-day input, 1-day prediction). A comparison with the baseline models shows that our model outperforms TimesNet, PatchTST, CNN-LSTM, LSTM, and CNN under all conditions, representing improvements of 36.9%, 25.5%, and 21.5% over the best baseline. According to the explanability analysis, sleep metrics are the most dominant and consistent stress predictors (importance: 1.1, consistency: 0.9-1.0), while activity features exhibit high inter-participant variability (0.1-0.2). Most notably, the model captures individual-specific patterns where identical features can have opposing effects across users, validating its personalization capabilities. These findings establish that consumer wearables, combined with adaptive and interpretable deep learning, can deliver relevant stress assessment adapted to individual physiological responses, providing a foundation for scalable, continuous, explainable mental health monitoring in real-world settings.

</details>


### [13] [The Geometry of Multi-Task Grokking: Transverse Instability, Superposition, and Weight Decay Phase Structure](https://arxiv.org/abs/2602.18523)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 多任务模块化算术中，共享主干Transformer在权重衰减扫描下表现出五个一致现象：交错grokking顺序、通用可积性、权重衰减相结构、全息不可压缩性、横向脆弱性和冗余性。


<details>
  <summary>Details</summary>
Motivation: 将几何分析扩展到多任务模块化算术，研究共享主干Transformer在双任务（模加+模乘）和三任务（模加+模乘+模平方）目标下的grokking现象，探索权重衰减对多任务学习动态的影响。

Method: 在系统权重衰减扫描下训练共享主干Transformer，分析双任务（模加+模乘）和三任务（模加+模乘+模平方）目标，使用几何分析方法研究优化轨迹、执行流形和参数空间结构。

Result: 发现五个一致现象：1) 交错grokking顺序（乘→平方→加）；2) 优化轨迹限制在低维执行流形；3) 权重衰减影响grokking时间尺度等动态特性；4) 最终解占据少量主方向但分布在全秩权重中；5) 横向梯度分量删除影响grokking但存在冗余。

Conclusion: 多任务grokking在参数空间中构建紧凑叠加子空间，权重衰减作为压缩压力，过参数化提供优化路径的几何冗余，支持多任务学习中的动态压缩机制。

Abstract: Grokking -- the abrupt transition from memorization to generalization long after near-zero training loss -- has been studied mainly in single-task settings. We extend geometric analysis to multi-task modular arithmetic, training shared-trunk Transformers on dual-task (mod-add + mod-mul) and tri-task (mod-add + mod-mul + mod-sq) objectives across a systematic weight decay sweep. Five consistent phenomena emerge. (1) Staggered grokking order: multiplication generalizes first, followed by squaring, then addition, with consistent delays across seeds. (2) Universal integrability: optimization trajectories remain confined to an empirically invariant low-dimensional execution manifold; commutator defects orthogonal to this manifold reliably precede generalization. (3) Weight decay phase structure: grokking timescale, curvature depth, reconstruction threshold, and defect lead covary systematically with weight decay, revealing distinct dynamical regimes and a sharp no-decay failure mode. (4) Holographic incompressibility: final solutions occupy only 4--8 principal trajectory directions yet are distributed across full-rank weights and destroyed by minimal perturbations; SVD truncation, magnitude pruning, and uniform scaling all fail to preserve performance. (5) Transverse fragility and redundancy: removing less than 10% of orthogonal gradient components eliminates grokking, yet dual-task models exhibit partial recovery under extreme deletion, suggesting redundant center manifolds enabled by overparameterization. Together, these results support a dynamical picture in which multi-task grokking constructs a compact superposition subspace in parameter space, with weight decay acting as compression pressure and excess parameters supplying geometric redundancy in optimization pathways.

</details>


### [14] [Audio-Visual Continual Test-Time Adaptation without Forgetting](https://arxiv.org/abs/2602.18528)
*Sarthak Kumar Maharana,Akshay Mehra,Bhavya Ramakrishna,Yunhui Guo,Guan-Ming Su*

Main category: cs.LG

TL;DR: 本文提出AV-CTTA方法，通过选择性参数检索机制动态获取最佳融合层参数，以解决音频-视觉连续测试时适应中的灾难性遗忘问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉连续测试时适应方法在非平稳域中面临灾难性遗忘问题，模型性能会因持续参数更新而大幅下降，甚至低于源模型。作者发现仅调整模态融合层不仅能提升当前域性能，还能增强后续域表现，这为改进方法提供了基础。

Method: 提出AV-CTTA方法：1）仅调整模态融合层参数以适应目标域；2）使用选择性参数检索机制，基于少量测试数据动态从缓冲区检索最佳融合层参数；3）将检索参数整合到模型中，适应当前测试分布后保存回缓冲区供未来使用。

Result: 在包含单模态和双模态损坏的基准数据集上进行广泛实验，结果表明AV-CTTA方法显著优于现有方法，同时最小化了灾难性遗忘问题。

Conclusion: 通过利用融合层参数的强跨任务可迁移性，AV-CTTA方法在无需访问源数据的情况下有效提升了音频-视觉模型的测试时性能，解决了连续测试时适应中的灾难性遗忘问题。

Abstract: Audio-visual continual test-time adaptation involves continually adapting a source audio-visual model at test-time, to unlabeled non-stationary domains, where either or both modalities can be distributionally shifted, which hampers online cross-modal learning and eventually leads to poor accuracy. While previous works have tackled this problem, we find that SOTA methods suffer from catastrophic forgetting, where the model's performance drops well below the source model due to continual parameter updates at test-time. In this work, we first show that adapting only the modality fusion layer to a target domain not only improves performance on that domain but can also enhance performance on subsequent domains. Based on this strong cross-task transferability of the fusion layer's parameters, we propose a method, $\texttt{AV-CTTA}$, that improves test-time performance of the models without access to any source data. Our approach works by using a selective parameter retrieval mechanism that dynamically retrieves the best fusion layer parameters from a buffer using only a small batch of test data. These parameters are then integrated into the model, adapted to the current test distribution, and saved back for future use. Extensive experiments on benchmark datasets involving unimodal and bimodal corruptions show our proposed $\texttt{AV-CTTA}$ significantly outperforms existing methods while minimizing catastrophic forgetting.

</details>


### [15] [Deep Reinforcement Learning for Optimizing Energy Consumption in Smart Grid Systems](https://arxiv.org/abs/2602.18531)
*Abeer Alsheikhi,Amirfarhad Farhadi,Azadeh Zamanifar*

Main category: cs.LG

TL;DR: 使用物理信息神经网络(PINNs)作为智能电网模拟器的替代，加速强化学习策略训练，相比无替代模型训练速度提升50%


<details>
  <summary>Details</summary>
Motivation: 智能电网能源管理问题复杂，传统强化学习方法需要与模拟器迭代交互，计算成本高且样本效率低

Method: 采用物理信息神经网络(PINNs)替代传统智能电网模拟器，将物理知识融入神经网络，增强强化学习策略学习过程

Result: PINN替代模型是唯一能在无真实模拟器样本情况下获得强RL策略的方法，训练速度比无替代模型快50%，能快速生成与原模拟器相似性能评分

Conclusion: PINN作为智能电网模拟器替代方案能显著加速强化学习训练，解决传统方法计算成本高的问题，为复杂能源管理问题提供高效解决方案

Abstract: The energy management problem in the context of smart grids is inherently complex due to the interdependencies among diverse system components. Although Reinforcement Learning (RL) has been proposed for solving Optimal Power Flow (OPF) problems, the requirement for iterative interaction with an environment often necessitates computationally expensive simulators, leading to significant sample inefficiency. In this study, these challenges are addressed through the use of Physics-Informed Neural Networks (PINNs), which can replace conventional and costly smart grid simulators. The RL policy learning process is enhanced so that convergence can be achieved in a fraction of the time required by the original environment. The PINN-based surrogate is compared with other benchmark data-driven surrogate models. By incorporating knowledge of the underlying physical laws, the results show that the PINN surrogate is the only approach considered in this context that can obtain a strong RL policy even without access to samples from the true simulator. The results demonstrate that using PINN surrogates can accelerate training by 50% compared to RL training without a surrogate. This approach enables the rapid generation of performance scores similar to those produced by the original simulator.

</details>


### [16] [Sub-City Real Estate Price Index Forecasting at Weekly Horizons Using Satellite Radar and News Sentiment](https://arxiv.org/abs/2602.18572)
*Baris Arat,Hasan Fehmi Ates,Emre Sefer*

Main category: cs.LG

TL;DR: 结合卫星雷达物理开发信号和新闻文本市场叙事，可以显著改善城市子区域房价指数的周度长期预测（26-34周），误差降低35%。


<details>
  <summary>Details</summary>
Motivation: 传统房地产价格指标通常在市级层面发布且频率较低，限制了其在社区尺度监测和长期规划中的应用。需要开发能够预测城市子区域周度价格指数的方法。

Method: 使用迪拜土地部门2015-2025年的35万+交易数据，构建19个子区域的周度价格指数。融合区域交易历史、Sentinel-1 SAR后向散射数据、结合词汇语气和语义嵌入的新闻情感分析，以及宏观经济背景。评估2-34周的预测效果。

Result: 预测效果高度依赖时间跨度：10周内仅价格历史即可匹配多模态配置，但14周后情感和SAR数据变得关键。在长期跨度（26-34周），完整多模态模型将平均绝对误差从4.48降至2.93（降低35%），各区域增益统计显著。非参数学习器在此数据体系下始终优于深度架构。

Conclusion: 研究为周度子城市指数预测建立了基准，证明遥感和新闻情感能在战略相关的时间跨度上显著改善预测能力，为社区尺度房地产监测提供了新工具。

Abstract: Reliable real estate price indicators are typically published at city level and low frequency, limiting their use for neighborhood-scale monitoring and long-horizon planning. We study whether sub-city price indices can be forecasted at weekly frequency by combining physical development signals from satellite radar with market narratives from news text. Using over 350,000 transactions from Dubai Land Department (2015-2025), we construct weekly price indices for 19 sub-city regions and evaluate forecasts from 2 to 34 weeks ahead. Our framework fuses regional transaction history with Sentinel-1 SAR backscatter, news sentiment combining lexical tone and semantic embeddings, and macroeconomic context. Results are strongly horizon dependent: at horizons up to 10 weeks, price history alone matches multimodal configurations, but beyond 14 weeks sentiment and SAR become critical. At long horizons (26-34 weeks), the full multimodal model reduces mean absolute error from 4.48 to 2.93 (35% reduction), with gains statistically significant across regions. Nonparametric learners consistently outperform deep architectures in this data regime. These findings establish benchmarks for weekly sub-city index forecasting and demonstrate that remote sensing and news sentiment materially improve predictability at strategically relevant horizons.

</details>


### [17] [Learning Beyond Optimization: Stress-Gated Dynamical Regime Regulation in Autonomous Systems](https://arxiv.org/abs/2602.18581)
*Sheng Ran*

Main category: cs.LG

TL;DR: 该论文提出了一种无显式目标函数的学习框架，通过评估内部动力学健康度来调节结构可塑性，实现自主学习和自我调节。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习依赖固定的标量目标函数优化，但在自主系统需要长期运行和适应变化环境时，目标可能变得不明确、动态变化或完全缺失。需要解决在没有显式目标函数的情况下，系统如何判断自身内部动态是否健康，以及如何在没有外部监督的情况下调节结构变化的问题。

Method: 提出一个双时间尺度架构：快速状态演化与慢速结构适应分离，通过内部生成的压力变量耦合。压力变量积累持续动态功能障碍的证据，结构修改不是连续触发，而是作为状态依赖事件。通过最小玩具模型验证该机制。

Result: 压力调节机制能够产生时间分段、自组织的学习过程，无需依赖外部定义的目标。系统能够进行自我评估和内部调节的结构重组。

Conclusion: 该框架为实现自主学习系统提供了一条可能路径，使系统能够进行自我评估和内部调节的结构重组，摆脱对外部目标函数的依赖。

Abstract: Despite their apparent diversity, modern machine learning methods can be reduced to a remarkably simple core principle: learning is achieved by continuously optimizing parameters to minimize or maximize a scalar objective function. This paradigm has been extraordinarily successful for well-defined tasks where goals are fixed and evaluation criteria are explicit. However, if artificial systems are to move toward true autonomy-operating over long horizons and across evolving contexts-objectives may become ill-defined, shifting, or entirely absent. In such settings, a fundamental question emerges: in the absence of an explicit objective function, how can a system determine whether its ongoing internal dynamics are productive or pathological? And how should it regulate structural change without external supervision? In this work, we propose a dynamical framework for learning without an explicit objective. Instead of minimizing external error signals, the system evaluates the intrinsic health of its own internal dynamics and regulates structural plasticity accordingly. We introduce a two-timescale architecture that separates fast state evolution from slow structural adaptation, coupled through an internally generated stress variable that accumulates evidence of persistent dynamical dysfunction. Structural modification is then triggered not continuously, but as a state-dependent event. Through a minimal toy model, we demonstrate that this stress-regulated mechanism produces temporally segmented, self-organized learning episodes without reliance on externally defined goals. Our results suggest a possible route toward autonomous learning systems capable of self-assessment and internally regulated structural reorganization.

</details>


### [18] [GIST: Targeted Data Selection for Instruction Tuning via Coupled Optimization Geometry](https://arxiv.org/abs/2602.18584)
*Guanghui Min,Tianhao Huang,Ke Wan,Chen Chen*

Main category: cs.LG

TL;DR: GIST是一种用于参数高效微调的数据选择方法，通过子空间对齐而非坐标独立假设来更准确地评估训练样本对目标任务的影响。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法通常基于优化器统计量（如Adam状态）作为参数更新的代理，这假设参数是坐标独立的。但在LoRA等参数高效微调方法中，优化几何表现出强烈的跨参数耦合和非对角相互作用，而任务相关的更新方向被限制在低维子空间中，导致现有方法失效。

Method: GIST通过谱滤波（SVD）从验证梯度中恢复任务特定子空间，将训练梯度投影到这个耦合子空间中，并根据样本与目标方向的对齐程度进行评分。它用鲁棒的子空间对齐替代了轴对齐缩放。

Result: 大量实验表明，GIST在相同选择预算下，仅需0.29%的存储和25%的计算时间，就能匹配或超越最先进的基线方法。

Conclusion: GIST为参数高效微调场景提供了一种简单而原则性的数据选择方法，通过考虑优化几何中的跨参数耦合特性，显著提高了选择效率和准确性。

Abstract: Targeted data selection has emerged as a crucial paradigm for efficient instruction tuning, aiming to identify a small yet influential subset of training examples for a specific target task. In practice, influence is often measured through the effect of an example on parameter updates. To make selection scalable, many approaches leverage optimizer statistics (e.g., Adam states) as an axis-aligned surrogate for update geometry (i.e., diagonal precondition), implicitly treating parameters as coordinate-wise independent. We show that this assumption breaks down in parameter-efficient fine-tuning (PEFT) methods such as LoRA. In this setting, the induced optimization geometry exhibits strong cross-parameter coupling with non-trivial off-diagonal interactions, while the task-relevant update directions are confined to a low-dimensional subspace. Motivated by this mismatch, we propose GIST (Gradient Isometric Subspace Transformation), a simple yet principled alternative that replaces axis-aligned scaling with robust subspace alignment. GIST recovers a task-specific subspace from validation gradients via spectral filtering (SVD), projects training gradients into this coupled subspace, and scores examples by their alignment with target directions.Extensive experiments have demonstrated that GIST matches or outperforms the state-of-the-art baseline with only 0.29% of the storage and 25% of the computational time under the same selection budget.

</details>


### [19] [Ensemble Prediction of Task Affinity for Efficient Multi-Task Learning](https://arxiv.org/abs/2602.18591)
*Afiya Ayman,Ayan Mukhopadhyay,Aron Laszka*

Main category: cs.LG

TL;DR: ETAP是一个可扩展的多任务学习任务亲和力预测框架，通过集成线性梯度相似度估计器和非线性预测器来准确预测任务组合的协同效益，从而实现更有效的任务分组。


<details>
  <summary>Details</summary>
Motivation: 多任务学习中需要识别哪些任务应该一起学习以获得性能提升，但为所有可能的任务组合训练模型成本过高。因此需要一种能够预测任务组是否受益于共同学习的方法。

Method: ETAP集成两种估计器：1) 基于梯度的线性亲和力评分器，通过共享参数更新相似度衡量任务对/组的亲和力；2) 非线性预测器，通过少量任务组的真实性能增益数据进行训练，捕捉复杂非线性任务关系并修正残差误差。

Result: 在基准数据集上，ETAP在多任务学习增益预测方面优于现有方法，能够实现更有效的任务分组，在不同应用领域都表现出色。

Conclusion: ETAP通过集成线性梯度相似度估计和非线性预测器，提供了一种可扩展且准确的多任务学习任务亲和力预测框架，能够有效指导任务分组决策。

Abstract: A fundamental problem in multi-task learning (MTL) is identifying groups of tasks that should be learned together. Since training MTL models for all possible combinations of tasks is prohibitively expensive for large task sets, a crucial component of efficient and effective task grouping is predicting whether a group of tasks would benefit from learning together, measured as per-task performance gain over single-task learning. In this paper, we propose ETAP (Ensemble Task Affinity Predictor), a scalable framework that integrates principled and data-driven estimators to predict MTL performance gains. First, we consider the gradient-based updates of shared parameters in an MTL model to measure the affinity between a pair of tasks as the similarity between the parameter updates based on these tasks. This linear estimator, which we call affinity score, naturally extends to estimating affinity within a group of tasks. Second, to refine these estimates, we train predictors that apply non-linear transformations and correct residual errors, capturing complex and non-linear task relationships. We train these predictors on a limited number of task groups for which we obtain ground-truth gain values via multi-task learning for each group. We demonstrate on benchmark datasets that ETAP improves MTL gain prediction and enables more effective task grouping, outperforming state-of-the-art baselines across diverse application domains.

</details>


### [20] [MapTab: Can MLLMs Master Constrained Route Planning?](https://arxiv.org/abs/2602.18600)
*Ziqiao Shang,Lingyue Ge,Yang Chen,Shi-Yu Tian,Zhenyu Huang,Wenbo Fu,Yu-Feng Li,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: MapTab是一个专门评估多模态大语言模型约束推理能力的基准测试，通过地铁网络和旅游地图的路径规划任务，包含时间、价格、舒适度和可靠性四个关键约束条件。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试不足以严格评估多模态大语言模型的约束推理能力，需要创建更具挑战性和现实性的测试平台来推动系统评估。

Method: 设计MapTab基准测试，包含Metromap（160个城市地铁网络）和Travelmap（168个旅游景点）两个场景，共328张图像、196,800个路径规划查询和3,936个QA查询，整合视觉地图图像和结构化表格数据。

Result: 对15个代表性MLLM的评估显示，当前模型在约束多模态推理方面面临重大挑战，在视觉感知有限的情况下，多模态协作往往不如单模态方法。

Conclusion: MapTab为MLLM的系统评估提供了一个具有挑战性和现实性的测试平台，有助于推动多模态约束推理能力的发展。

Abstract: Systematic evaluation of Multimodal Large Language Models (MLLMs) is crucial for advancing Artificial General Intelligence (AGI). However, existing benchmarks remain insufficient for rigorously assessing their constrained reasoning capabilities. To bridge this gap, we introduce MapTab, a multimodal benchmark specifically designed to evaluate constrained reasoning in MLLMs via route planning tasks. MapTab requires MLLMs to perceive and ground visual cues from map images alongside route attributes (e.g., Time, Price) from structured tabular data. The benchmark encompasses two scenarios: Metromap, covering metro networks in 160 cities across 52 countries, and Travelmap, depicting 168 representative tourist attractions from 19 countries. In total, MapTab comprises 328 images, 196,800 route planning queries, and 3,936 QA queries, all incorporating 4 key constraints: Time, Price, Comfort, and Reliability. Extensive evaluations across 15 representative MLLMs reveal that current models face substantial challenges in constrained multimodal reasoning. Notably, under conditions of limited visual perception, multimodal collaboration often underperforms compared to unimodal approaches. We believe MapTab provides a challenging and realistic testbed to advance the systematic evaluation of MLLMs.

</details>


### [21] [Diagnosing LLM Reranker Behavior Under Fixed Evidence Pools](https://arxiv.org/abs/2602.18613)
*Baris Arat,Emre Sefer*

Main category: cs.LG

TL;DR: 该研究提出了一种诊断方法，通过使用Multi-News集群作为固定证据池来隔离重排序行为，消除检索质量的影响，从而直接评估排名策略本身。


<details>
  <summary>Details</summary>
Motivation: 传统重排序评估将排名行为与检索质量耦合，无法区分输出差异是源于排名策略还是检索质量。需要一种能够隔离重排序行为的诊断方法。

Method: 使用Multi-News集群作为固定证据池，每个池限制为8个文档，向所有排名器提供相同输入。BM25和MMR作为词汇匹配和多样性优化的可解释参考点。

Result: 在345个集群中，冗余模式因模型而异：一个LLM在较大选择预算时隐式多样化，而另一个增加冗余。LLM在小选择预算下的词汇覆盖表现不佳。LLM排名与两个基线均有显著差异。

Conclusion: 通过消除检索方差，可以直接将排名差异归因于排名策略。这种诊断方法是模型无关的，适用于包括开源系统和专有API在内的任何排名器。

Abstract: Standard reranking evaluations study how a reranker orders candidates returned by an upstream retriever. This setup couples ranking behavior with retrieval quality, so differences in output cannot be attributed to the ranking policy alone. We introduce a controlled diagnostic that isolates reranking by using Multi-News clusters as fixed evidence pools. We limit each pool to exactly eight documents and pass identical inputs to all rankers. Within this setup, BM25 and MMR serve as interpretable reference points for lexical matching and diversity optimization. Across 345 clusters, we find that redundancy patterns vary by model: one LLM implicitly diversifies at larger selection budgets, while another increases redundancy. In contrast, LLMs underperform on lexical coverage at small selection budgets. As a result, LLM rankings diverge substantially from both baselines rather than consistently approximating either strategy. By eliminating retrieval variance, we can attribute these differences directly to the ranking policy. This diagnostic is model-agnostic and applicable to any ranker, including open source systems and proprietary APIs.

</details>


### [22] [Non-Interfering Weight Fields: Treating Model Parameters as a Continuously Extensible Function](https://arxiv.org/abs/2602.18628)
*Sarim Chaudhry*

Main category: cs.LG

TL;DR: NIWF提出用可学习的权重场函数替代固定权重，通过在能力坐标空间中锁定已学任务的区域，实现零灾难性遗忘的持续学习框架。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型将所有知识存储在固定权重中，学习新能力会修改权重导致灾难性遗忘。现有方法如正则化、回放缓冲或适配器模块无法提供结构性的防遗忘保证。

Method: 提出非干涉权重场(NIWF)框架，用学习函数从连续能力坐标空间按需生成权重配置。训练任务后，通过锚点快照锁定已占用的坐标区域，在后续训练中强制执行功能锁定。

Result: 在Mistral-7B上验证了顺序指令跟随和代码生成任务，实现了对已提交任务的零遗忘，同时在新任务上保持有竞争力的困惑度。

Conclusion: 该框架引入了类似软件版本控制的神经网络智能管理方式，使能力可以被提交、扩展、组合和回滚而无需重新训练，解决了灾难性遗忘的根本问题。

Abstract: Large language models store all learned knowledge in a single, fixed weight vector. Teaching a model new capabilities requires modifying those same weights, inevitably degrading previously acquired knowledge. This fundamental limitation, known as catastrophic forgetting, has resisted principled solutions for decades. Existing approaches treat weights as immutable artifacts that must be protected through techniques like regularization heuristics, replay buffers, or isolated adapter modules. The problem is none of these provide a structural guarantee against forgetting. In this work, we propose Non-Interfering Weight Fields (NIWF), a framework that replaces the fixed weight paradigm with a learned function that generates weight configurations on demand from a continuous capability coordinate space. After training on a task, we commit the occupied coordinate region by snapshotting the fields outputs on anchor points to enforce a functional lock during all future training. We validate NIWF on sequential instructionfollowing and code generation tasks using Mistral-7B, demonstrating zero forgetting on committed tasks with competitive perplexity on new tasks. The framework introduces the notion of software-like versioning for neural network intelligence, where capabilities can be committed, extended, composed, and rolled back without retraining.

</details>


### [23] [Online decoding of rat self-paced locomotion speed from EEG using recurrent neural networks](https://arxiv.org/abs/2602.18637)
*Alejandro de Miguel,Nelson Totah,Uri Maoz*

Main category: cs.LG

TL;DR: 使用32通道头皮EEG通过循环神经网络解码大鼠自主步态速度，达到0.88相关性，主要依赖视觉皮层和低频振荡，可跨会话泛化但无法跨动物迁移。


<details>
  <summary>Details</summary>
Motivation: 现有研究多在电机驱动跑步机上解码运动学参数，而在自主步态（自选速度）的自然场景中解码研究较少，且精度有限、需要侵入式植入。本文旨在使用非侵入性皮层宽EEG连续解码大鼠自主步态速度。

Method: 提出异步脑机接口，处理32电极头皮表面EEG信号（0.01-45 Hz），使用循环神经网络在超过133小时记录的数据集上训练解码器，将持续EEG活动映射到非电机驱动跑步机上的瞬时速度。

Result: 速度解码达到0.88相关性（R²=0.78），主要由视觉皮层电极和低频振荡（<8 Hz）驱动。单会话预训练可在同一大鼠的其他会话中解码，表明存在跨会话泛化的统一神经特征，但无法跨动物迁移。皮层状态不仅包含当前速度信息，还包含未来和过去动态信息（延伸至1000 ms）。

Conclusion: 自主步态速度可从非侵入性皮层宽EEG准确连续解码。该方法为开发高性能非侵入性BCI系统提供了框架，并有助于理解动作动态的分布式神经表征。

Abstract: $\textit{Objective.}$ Accurate neural decoding of locomotion holds promise for advancing rehabilitation, prosthetic control, and understanding neural correlates of action. Recent studies have demonstrated decoding of locomotion kinematics across species on motorized treadmills. However, efforts to decode locomotion speed in more natural contexts$-$where pace is self-selected rather than externally imposed$-$are scarce, generally achieve only modest accuracy, and require intracranial implants. Here, we aim to decode self-paced locomotion speed non-invasively and continuously using cortex-wide EEG recordings from rats. $\textit{Approach.}$ We introduce an asynchronous brain$-$computer interface (BCI) that processes a stream of 32-electrode skull-surface EEG (0.01$-$45 Hz) to decode instantaneous speed from a non-motorized treadmill during self-paced locomotion in head-fixed rats. Using recurrent neural networks and a dataset of over 133 h of recordings, we trained decoders to map ongoing EEG activity to treadmill speed. $\textit{Main results.}$ Our decoding achieves a correlation of 0.88 ($R^2$ = 0.78) for speed, primarily driven by visual cortex electrodes and low-frequency ($< 8$ Hz) oscillations. Moreover, pre-training on a single session permitted decoding on other sessions from the same rat, suggesting uniform neural signatures that generalize across sessions but fail to transfer across animals. Finally, we found that cortical states not only carry information about current speed, but also about future and past dynamics, extending up to 1000 ms. $\textit{Significance.}$ These findings demonstrate that self-paced locomotion speed can be decoded accurately and continuously from non-invasive, cortex-wide EEG. Our approach provides a framework for developing high-performing, non-invasive BCI systems and contributes to understanding distributed neural representations of action dynamics.

</details>


### [24] [Learning Invariant Visual Representations for Planning with Joint-Embedding Predictive World Models](https://arxiv.org/abs/2602.18639)
*Leonardo F. Toso,Davit Shadunts,Yunyang Lu,Nihal Sharma,Donglin Zhan,Nam H. Nguyen,James Anderson*

Main category: cs.LG

TL;DR: 论文提出一种增强世界模型鲁棒性的方法，通过引入双模拟编码器来抑制对任务无关的"慢特征"的敏感性，在多种视觉编码器上都能提升测试时鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在预测架构（如DINO-WM）对"慢特征"（如背景变化、视觉干扰物等任务无关的视觉变化）过于敏感，导致测试时鲁棒性下降。需要一种方法来增强模型对控制相关特征的关注，同时抑制无关特征的影响。

Method: 在预测目标基础上增加双模拟编码器，强制控制相关的状态等价性，将具有相似转移动态的状态映射到相近的潜在状态，同时限制慢特征的贡献。该方法与预训练视觉编码器选择无关，可与DINOv2、SimDINOv2、iBOT等多种特征配合使用。

Result: 在简单导航任务的不同测试时背景变化和视觉干扰物场景下，模型在所有基准测试中都一致地提高了对慢特征的鲁棒性，同时潜在空间大小比DINO-WM最多缩小10倍。模型对预训练视觉编码器的选择具有鲁棒性。

Conclusion: 通过双模拟编码器增强预测目标可以有效提高世界模型对任务无关视觉变化的鲁棒性，同时减少潜在空间维度，该方法具有通用性，适用于多种预训练视觉特征。

Abstract: World models learned from high-dimensional visual observations allow agents to make decisions and plan directly in latent space, avoiding pixel-level reconstruction. However, recent latent predictive architectures (JEPAs), including the DINO world model (DINO-WM), display a degradation in test time robustness due to their sensitivity to "slow features". These include visual variations such as background changes and distractors that are irrelevant to the task being solved. We address this limitation by augmenting the predictive objective with a bisimulation encoder that enforces control-relevant state equivalence, mapping states with similar transition dynamics to nearby latent states while limiting contributions from slow features. We evaluate our model on a simple navigation task under different test-time background changes and visual distractors. Across all benchmarks, our model consistently improves robustness to slow features while operating in a reduced latent space, up to 10x smaller than that of DINO-WM. Moreover, our model is agnostic to the choice of pretrained visual encoder and maintains robustness when paired with DINOv2, SimDINOv2, and iBOT features.

</details>


### [25] [Adaptive Time Series Reasoning via Segment Selection](https://arxiv.org/abs/2602.18645)
*Shvat Messica,Jiawen Zhang,Kevin Li,Theodoros Tsiligkaridis,Marinka Zitnik*

Main category: cs.LG

TL;DR: ARTIST：一种将时间序列推理建模为顺序决策问题的新方法，通过强化学习训练控制器选择信息片段，推理器生成答案，在6个基准测试上比最强基线提升6.46个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列推理方法通常将整个时间序列编码为固定表示，无论整个序列是否相关。然而，证据可能分布在整个序列中或仅出现在少数短间隔中，模型需要决定检查哪些部分。需要一种能够自适应选择相关信息片段的方法。

Method: ARTIST采用控制器-推理器架构：控制器使用强化学习训练来选择信息丰富的时间片段，推理器生成基于片段的推理轨迹和最终答案。使用新颖的分层策略优化方法进行后训练，使模型在片段选择和问答行为上都表现出色。

Result: 在6个时间序列推理基准测试中，ARTIST比最强基线（大型语言模型、视觉语言模型和先前的时间序列推理系统）平均准确率提升6.46个百分点。在罕见事件定位和多片段推理任务上提升最大。监督微调提升性能，强化学习通过优化问题自适应片段选择提供额外增益。

Conclusion: 选择性使用数据驱动有效的时间序列推理。ARTIST通过将推理与自适应时间片段选择交织，在推理过程中主动获取任务相关信息，而不是依赖整个序列的静态摘要，显著提升了时间序列推理性能。

Abstract: Time series reasoning tasks often start with a natural language question and require targeted analysis of a time series. Evidence may span the full series or appear in a few short intervals, so the model must decide what to inspect. Most existing approaches encode the entire time series into a fixed representation before inference, regardless of whether or not the entire sequence is relevant. We introduce ARTIST, which formulates time-series reasoning as a sequential decision problem. ARTIST interleaves reasoning with adaptive temporal segment selection. It adopts a controller-reasoner architecture and uses reinforcement learning to train the controller role to select informative segments and the reasoner role to generate segment-conditioned reasoning traces and final answers. During inference, the model actively acquires task-relevant information instead of relying on a static summary of the full sequence. We use a novel hierarchical policy optimization approach for post-training that allows the model to excel in both segment selection and question-answering behavior. We evaluate ARTIST on six time-series reasoning benchmarks and compare it with large language models, vision-language models, and prior time-series reasoning systems. ARTIST improves average accuracy by 6.46 absolute percentage points over the strongest baseline. The largest gains appear on rare event localization and multi-segment reasoning tasks. Supervised fine-tuning improves performance, and reinforcement learning provides additional gains by optimizing question-adaptive segment selection. These results show that selective data use drives effective time-series reasoning.

</details>


### [26] [Information-Guided Noise Allocation for Efficient Diffusion Training](https://arxiv.org/abs/2602.18647)
*Gabriel Raya,Bac Nguyen,Georgios Batzolis,Yuhta Takida,Dejan Stancevic,Naoki Murata,Chieh-Hsin Lai,Yuki Mitsufuji,Luca Ambrogioni*

Main category: cs.LG

TL;DR: InfoNoise：一种基于信息论的噪声调度方法，通过条件熵率分析优化噪声分配，实现数据自适应训练，减少手动调参需求


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型依赖手动调参的噪声调度，存在计算浪费和跨数据集/分辨率/表示迁移受限的问题，需要更理论化、数据自适应的调度方法

Method: 从信息论角度分析前向过程的条件熵率，提出基于熵减少率的信息引导噪声采样分布，利用训练中已有的去噪损失估计来替代启发式调度设计

Result: 在自然图像基准测试中匹配或超越EDM风格调度，CIFAR-10上实现约1.4倍训练加速；在离散数据集上，相比标准图像调度，以最多3倍更少的训练步骤达到更高质量

Conclusion: InfoNoise使噪声调度数据自适应，减少跨领域扩散模型对每数据集调度设计的需求，为扩散模型扩展提供更通用的训练框架

Abstract: Training diffusion models typically relies on manually tuned noise schedules, which can waste computation on weakly informative noise regions and limit transfer across datasets, resolutions, and representations. We revisit noise schedule allocation through an information-theoretic lens and propose the conditional entropy rate of the forward process as a theoretically grounded, data-dependent diagnostic for identifying suboptimal noise-level allocation in existing schedules. Based on these insight, we introduce InfoNoise, a principled data-adaptive training noise schedule that replaces heuristic schedule design with an information-guided noise sampling distribution derived from entropy-reduction rates estimated from denoising losses already computed during training. Across natural-image benchmarks, InfoNoise matches or surpasses tuned EDM-style schedules, in some cases with a substantial training speedup (about $1.4\times$ on CIFAR-10). On discrete datasets, where standard image-tuned schedules exhibit significant mismatch, it reaches superior quality in up to $3\times$ fewer training steps. Overall, InfoNoise makes noise scheduling data-adaptive, reducing the need for per-dataset schedule design as diffusion models expand across domains.

</details>


### [27] [Global Low-Rank, Local Full-Rank: The Holographic Encoding of Learned Algorithms](https://arxiv.org/abs/2602.18649)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 论文研究了神经网络训练中"顿悟"现象的本质，发现虽然学习轨迹是低维的，但权重矩阵本身保持高秩，表明算法是通过跨矩阵的动态协调更新编码的。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络训练中"顿悟"现象（从记忆到泛化的突然转变）与低维结构的关系。虽然学习动态显示低维特征，但网络参数存在于极高维空间，需要解释这种矛盾。

Method: 在多任务模运算任务上训练共享主干Transformer，使用三种重建方法：单矩阵SVD、跨矩阵联合SVD和轨迹PCA。比较不同模型规模和权重衰减设置下的表现。

Result: 顿悟轨迹被限制在2-6维全局子空间，但单个权重矩阵保持高秩。使用3-5个轨迹主成分可恢复95%以上最终准确率，而SVD方法在低于全秩时失败。静态分解即使捕获大部分谱能量也会破坏任务相关结构。

Conclusion: 学习算法是通过跨所有矩阵的动态协调更新编码的，而不是局部低秩组件。提出全息编码原理：顿悟解在学习方向空间是全局低秩的，但在参数空间是局部高秩的，这对压缩、可解释性和理解神经网络如何编码计算有重要意义。

Abstract: Grokking -- the abrupt transition from memorization to generalization after extended training -- has been linked to the emergence of low-dimensional structure in learning dynamics. Yet neural network parameters inhabit extremely high-dimensional spaces. How can a low-dimensional learning process produce solutions that resist low-dimensional compression?
  We investigate this question in multi-task modular arithmetic, training shared-trunk Transformers with separate heads for addition, multiplication, and a quadratic operation modulo 97. Across three model scales (315K--2.2M parameters) and five weight decay settings, we compare three reconstruction methods: per-matrix SVD, joint cross-matrix SVD, and trajectory PCA.
  Across all conditions, grokking trajectories are confined to a 2--6 dimensional global subspace, while individual weight matrices remain effectively full-rank. Reconstruction from 3--5 trajectory PCs recovers over 95\% of final accuracy, whereas both per-matrix and joint SVD fail at sub-full rank. Even when static decompositions capture most spectral energy, they destroy task-relevant structure.
  These results show that learned algorithms are encoded through dynamically coordinated updates spanning all matrices, rather than localized low-rank components. We term this the holographic encoding principle: grokked solutions are globally low-rank in the space of learning directions but locally full-rank in parameter space, with implications for compression, interpretability, and understanding how neural networks encode computation.

</details>


### [28] [Communication-Efficient Personalized Adaptation via Federated-Local Model Merging](https://arxiv.org/abs/2602.18658)
*Yinan Zou,Md Kamran Chowdhury Shisher,Christopher G. Brinton,Vishrant Tripathi*

Main category: cs.LG

TL;DR: Potara：基于线性模式连通性的联邦个性化框架，通过理论推导的最优混合权重合并联邦模型和本地模型，实现更好的个性化效果和通信效率


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的个性化方法面临两个主要问题：1）任务级异构性下，平衡通用知识和个性化知识缺乏理论依据，主要依赖启发式混合规则；2）模型合并方法计算和通信开销大，在联邦场景下效率低下

Method: 提出Potara框架，为每个客户端构建个性化模型，通过合并两个互补模型：1）捕获通用知识的联邦模型；2）捕获个性化知识的本地模型。利用线性模式连通性，推导出任务损失的方差迹上界，通过最小化该上界得到闭式最优混合权重

Result: 在视觉和语言基准测试中，Potara在减少通信的同时持续改进个性化效果，实现了强大的性能-通信权衡

Conclusion: Potara提供了一个理论上有保证的联邦个性化框架，通过最优模型合并策略有效平衡通用知识和个性化知识，在保持通信效率的同时显著提升个性化性能

Abstract: Parameter-efficient fine-tuning methods, such as LoRA, offer a practical way to adapt large vision and language models to client tasks. However, this becomes particularly challenging under task-level heterogeneity in federated deployments. In this regime, personalization requires balancing general knowledge with personalized knowledge, yet existing approaches largely rely on heuristic mixing rules and lack theoretical justification. Moreover, prior model merging approaches are also computation and communication intensive, making the process inefficient in federated settings. In this work, we propose Potara, a principled framework for federated personalization that constructs a personalized model for each client by merging two complementary models: (i) a federated model capturing general knowledge, and (ii) a local model capturing personalized knowledge. Through the construct of linear mode connectivity, we show that the expected task loss admits a variance trace upper bound, whose minimization yields closed-form optimal mixing weights that guarantee a tighter bound for the merged model than for either the federated or local model alone. Experiments on vision and language benchmarks show that Potara consistently improves personalization while reducing communication, leading to a strong performance-communication trade-off.

</details>


### [29] [Large Causal Models for Temporal Causal Discovery](https://arxiv.org/abs/2602.18662)
*Nikolaos Kougioulis,Nikolaos Gkorgkolis,MingXue Wang,Bora Caglayan,Dario Simionato,Andrea Tonon,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: LCMs（大型因果模型）是一种用于时序因果发现的预训练神经网络架构，通过多数据集训练实现跨数据集泛化，相比传统方法能处理更多变量、保持性能并实现快速推理。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法采用数据集特定范式，每个新数据集都需要重新训练模型，限制了多数据集预训练的潜力，且现有方法受限于变量数量少、依赖合成数据、泛化能力差等问题。

Method: 提出LCMs框架，结合多样化的合成数据生成器和真实时序数据集进行大规模学习，支持更高变量数量和更深层架构，实现单次快速推理。

Result: 在合成、半合成和真实基准测试中，LCMs能有效扩展到更高变量数量，保持强性能，在分布外设置中表现优于经典和神经基线方法，推理速度快。

Conclusion: LCMs为时序因果发现提供了一个有前景的基础模型范式，展示了预训练因果模型在跨数据集泛化和可扩展性方面的潜力。

Abstract: Causal discovery for both cross-sectional and temporal data has traditionally followed a dataset-specific paradigm, where a new model is fitted for each individual dataset. Such an approach limits the potential of multi-dataset pretraining. The concept of large causal models (LCMs) envisions a class of pre-trained neural architectures specifically designed for temporal causal discovery. Prior approaches are constrained to small variable counts, degrade with larger inputs, and rely heavily on synthetic data, limiting generalization. We propose a principled framework for LCMs, combining diverse synthetic generators with realistic time-series datasets, allowing learning at scale. Extensive experiments on synthetic, semi-synthetic and realistic benchmarks show that LCMs scale effectively to higher variable counts and deeper architectures while maintaining strong performance. Trained models achieve competitive or superior accuracy compared to classical and neural baselines, particularly in out-of-distribution settings, while enabling fast, single-pass inference. Results demonstrate LCMs as a promising foundation-model paradigm for temporal causal discovery. Experiments and model weights are available at https://github.com/kougioulis/LCM-paper/.

</details>


### [30] [Robustness of Deep ReLU Networks to Misclassification of High-Dimensional Data](https://arxiv.org/abs/2602.18674)
*Věra Kůrková*

Main category: cs.LG

TL;DR: 该论文从理论上研究了参数化网络对随机输入扰动的鲁棒性，分析了在给定网络输入下，小的加性随机扰动导致错误分类的概率，并针对ReLU深度网络推导了局部鲁棒性下界。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络对输入扰动的鲁棒性对于理解模型的安全性和可靠性至关重要。随机扰动可能导致模型错误分类，因此需要量化这种风险并建立理论保证。

Method: 通过理论分析，针对具有整流线性单元（ReLU）的深度网络，在给定网络输入下分析局部鲁棒性。量化输入的小加性随机扰动导致错误分类的概率，并推导鲁棒性下界。

Result: 为ReLU深度网络推导了局部鲁棒性的下界，这些下界与输入维度和网络单元总数相关，为网络对随机扰动的鲁棒性提供了理论保证。

Conclusion: 该研究为深度神经网络的鲁棒性分析提供了理论框架，证明了ReLU网络对随机输入扰动具有一定的鲁棒性保证，这些保证与网络架构参数相关。

Abstract: We present a theoretical study of the robustness of parameterized networks to random input perturbations. Specifically, we analyze local robustness at a given network input by quantifying the probability that a small additive random perturbation of the input leads to misclassification. For deep networks with rectified linear units, we derive lower bounds on local robustness in terms of the input dimensionality and the total number of network units.

</details>


### [31] [Transformers for dynamical systems learn transfer operators in-context](https://arxiv.org/abs/2602.18679)
*Anthony Bao,Jeffrey Lai,William Gilpin*

Main category: cs.LG

TL;DR: 该研究探索了科学机器学习中基础模型在未见物理系统上的零样本迁移能力，发现注意力模型通过延迟嵌入和全局吸引子识别实现上下文学习。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大规模基础模型在科学机器学习中展现的上下文学习现象——即模型能够适应训练时未见过的物理系统设置，如湍流尺度间的零样本迁移。这种现象挑战了传统对物理系统学习和适应的理解。

Method: 研究方法是在最小化设置中研究动力学系统的上下文学习：训练一个小的两层单头Transformer来预测一个动力学系统，然后评估其在未经重新训练的情况下预测不同动力学系统的能力。通过分析训练过程中的性能变化和模型机制。

Result: 研究发现：1) 训练早期存在分布内和分布外性能的权衡，表现为二次双下降现象；2) 注意力模型采用转移算子预测策略：通过延迟嵌入将低维时间序列提升到高维动力流形，识别并预测表征全局流的长期不变集；3) 模型能够利用全局吸引子信息进行短期预测。

Conclusion: 研究阐明了大型预训练模型无需重新训练即可预测未见物理系统的机制，展示了注意力模型在利用全局吸引子信息进行短期预测方面的独特能力，为理解科学机器学习中的上下文学习提供了理论基础。

Abstract: Large-scale foundation models for scientific machine learning adapt to physical settings unseen during training, such as zero-shot transfer between turbulent scales. This phenomenon, in-context learning, challenges conventional understanding of learning and adaptation in physical systems. Here, we study in-context learning of dynamical systems in a minimal setting: we train a small two-layer, single-head transformer to forecast one dynamical system, and then evaluate its ability to forecast a different dynamical system without retraining. We discover an early tradeoff in training between in-distribution and out-of-distribution performance, which manifests as a secondary double descent phenomenon. We discover that attention-based models apply a transfer-operator forecasting strategy in-context. They (1) lift low-dimensional time series using delay embedding, to detect the system's higher-dimensional dynamical manifold, and (2) identify and forecast long-lived invariant sets that characterize the global flow on this manifold. Our results clarify the mechanism enabling large pretrained models to forecast unseen physical systems at test without retraining, and they illustrate the unique ability of attention-based models to leverage global attractor information in service of short-term forecasts.

</details>


### [32] [In-Context Planning with Latent Temporal Abstractions](https://arxiv.org/abs/2602.18694)
*Baiting Luo,Yunuo Zhang,Nathaniel S. Keplinger,Samir Gupta,Abhishek Dubey,Ayan Mukhopadhyay*

Main category: cs.LG

TL;DR: I-TAP是一个离线强化学习框架，结合了上下文适应和在线规划，通过学习离散时间抽象空间来解决连续控制中的规划问题。


<details>
  <summary>Details</summary>
Motivation: 连续控制中的规划面临两个实际问题：在原始时间尺度规划会导致分支爆炸和长视野问题；真实环境通常是部分可观测的，且存在机制转换，这破坏了平稳、完全可观测的动态假设。

Method: 从离线轨迹中学习观察条件化的残差量化VAE，将观察-宏动作片段压缩成粗到细的离散残差标记堆栈，以及一个时间Transformer来自回归预测这些标记堆栈。在测试时，直接在标记空间进行蒙特卡洛树搜索，使用短历史进行隐式适应，并将选定的标记堆栈解码为可执行动作。

Result: 在确定性MuJoCo、具有每集潜在动态机制的随机MuJoCo以及高维Adroit操作任务（包括部分可观测变体）中，I-TAP始终匹配或优于强大的无模型和基于模型的离线基线方法。

Conclusion: I-TAP展示了在随机动态和部分可观测性下进行高效且鲁棒的上下文规划的能力，统一了上下文适应和在线规划，解决了连续控制中的关键挑战。

Abstract: Planning-based reinforcement learning for continuous control is bottlenecked by two practical issues: planning at primitive time scales leads to prohibitive branching and long horizons, while real environments are frequently partially observable and exhibit regime shifts that invalidate stationary, fully observed dynamics assumptions. We introduce I-TAP (In-Context Latent Temporal-Abstraction Planner), an offline RL framework that unifies in-context adaptation with online planning in a learned discrete temporal-abstraction space. From offline trajectories, I-TAP learns an observation-conditioned residual-quantization VAE that compresses each observation-macro-action segment into a coarse-to-fine stack of discrete residual tokens, and a temporal Transformer that autoregressively predicts these token stacks from a short recent history. The resulting sequence model acts simultaneously as a context-conditioned prior over abstract actions and a latent dynamics model. At test time, I-TAP performs Monte Carlo Tree Search directly in token space, using short histories for implicit adaptation without gradient update, and decodes selected token stacks into executable actions. Across deterministic MuJoCo, stochastic MuJoCo with per-episode latent dynamics regimes, and high-dimensional Adroit manipulation, including partially observable variants, I-TAP consistently matches or outperforms strong model-free and model-based offline baselines, demonstrating efficient and robust in-context planning under stochastic dynamics and partial observability.

</details>


### [33] [Insertion Based Sequence Generation with Learnable Order Dynamics](https://arxiv.org/abs/2602.18695)
*Dhruvesh Patel,Benjamin Rozonoyer,Gaurav Pandey,Tahira Naseem,Ramón Fernandez Astudillo,Andrew McCallum*

Main category: cs.LG

TL;DR: 提出一种结合可训练顺序动态与离散流匹配的方法，用于改进插入式生成模型，在分子生成任务中提升有效分子数量和生成质量


<details>
  <summary>Details</summary>
Motivation: 插入式生成模型相比自回归模型具有更大灵活性，但其动作空间更大导致学习困难。需要解决插入顺序动态的优化问题。

Method: 将可训练的顺序动态纳入离散流匹配的目标速率中，通过合适的参数化使顺序动态和生成器的联合训练无需数值模拟。使用可变长度掩码扩散模型作为生成插入模型。

Result: 在图遍历任务中探索了参数化选择的权衡；在分子生成任务中，学习到的顺序动态相比均匀顺序动态提高了有效分子数量和生成质量

Conclusion: 通过结合可训练顺序动态与离散流匹配，能够有效改进插入式生成模型的性能，在保持灵活性的同时提升训练稳定性和生成质量

Abstract: In many domains generating variable length sequences through insertions provides greater flexibility over autoregressive models. However, the action space of insertion models is much larger than that of autoregressive models (ARMs) making the learning challenging. To address this, we incorporate trainable order dynamics into the target rates for discrete flow matching, and show that with suitable choices of parameterizations, joint training of the target order dynamics and the generator is tractable without the need for numerical simulation. As the generative insertion model, we use a variable length masked diffusion model, which generates by inserting and filling mask tokens. On graph traversal tasks for which a locally optimal insertion order is known, we explore the choices of parameterization empirically and demonstrate the trade-offs between flexibility, training stability and generation quality. On de novo small molecule generation, we find that the learned order dynamics leads to an increase in the number of valid molecules generated and improved quality, when compared to uniform order dynamics.

</details>


### [34] [Phase-Consistent Magnetic Spectral Learning for Multi-View Clustering](https://arxiv.org/abs/2602.18728)
*Mingdong Lu,Zhikui Chen,Meng Liu,Shubin Ma,Liang Zhao*

Main category: cs.LG

TL;DR: 提出相位一致磁谱学习用于多视图聚类，通过建模跨视图方向一致性作为相位项，结合非负幅度主干形成复值磁亲和力，提取稳定共享谱信号指导无监督多视图表示学习和聚类。


<details>
  <summary>Details</summary>
Motivation: 现有多视图聚类方法通常依赖幅度亲和力或早期伪目标，当不同视图产生强度相当但方向矛盾的关系时不稳定，这会扭曲全局谱几何并降低聚类性能。

Method: 1) 将跨视图方向一致性建模为相位项，结合非负幅度主干形成复值磁亲和力；2) 通过厄米磁拉普拉斯提取稳定共享谱信号；3) 使用谱信号作为结构化自监督指导无监督多视图表示学习和聚类；4) 通过基于锚点的高阶共识建模构建紧凑共享结构，并应用轻量级细化抑制噪声或不一致关系。

Result: 在多个公开多视图基准测试上的广泛实验表明，该方法始终优于强基线方法。

Conclusion: 通过显式建模跨视图方向一致性作为相位项，结合幅度信息形成磁亲和力，能够提取更稳定的共享谱信号，有效指导无监督多视图表示学习和聚类，提升聚类性能。

Abstract: Unsupervised multi-view clustering (MVC) aims to partition data into meaningful groups by leveraging complementary information from multiple views without labels, yet a central challenge is to obtain a reliable shared structural signal to guide representation learning and cross-view alignment under view discrepancy and noise. Existing approaches often rely on magnitude-only affinities or early pseudo targets, which can be unstable when different views induce relations with comparable strengths but contradictory directional tendencies, thereby distorting the global spectral geometry and degrading clustering. In this paper, we propose \emph{Phase-Consistent Magnetic Spectral Learning} for MVC: we explicitly model cross-view directional agreement as a phase term and combine it with a nonnegative magnitude backbone to form a complex-valued magnetic affinity, extract a stable shared spectral signal via a Hermitian magnetic Laplacian, and use it as structured self-supervision to guide unsupervised multi-view representation learning and clustering. To obtain robust inputs for spectral extraction at scale, we construct a compact shared structure with anchor-based high-order consensus modeling and apply a lightweight refinement to suppress noisy or inconsistent relations. Extensive experiments on multiple public multi-view benchmarks demonstrate that our method consistently outperforms strong baselines.

</details>


### [35] [Prior Aware Memorization: An Efficient Metric for Distinguishing Memorization from Generalization in Large Language Models](https://arxiv.org/abs/2602.18733)
*Trishita Tiwari,Ari Trachtenberg,G. Edward Suh*

Main category: cs.LG

TL;DR: 提出Prior-Aware Memorization方法，区分LLM训练数据泄露中的真实记忆与统计常见模式，发现55-90%被标记为记忆的序列实际上是统计常见模式


<details>
  <summary>Details</summary>
Motivation: 现有方法难以区分LLM训练数据泄露中的真实记忆与统计常见模式，Counterfactual Memorization方法计算成本高且难以扩展

Method: 提出Prior-Aware Memorization方法，通过评估候选后缀是否与特定训练前缀强相关，还是由于统计常见性而在多个无关提示中出现，无需重新训练模型

Result: 在LLaMA和OPT模型上测试显示，55-90%被标记为记忆的序列实际上是统计常见模式；在SATML数据集上约40%序列也表现出常见模式行为

Conclusion: 低频序列不足以证明记忆，评估数据泄露时必须考虑模型先验，Prior-Aware Memorization提供了一种轻量级、无需训练的真实记忆识别方法

Abstract: Training data leakage from Large Language Models (LLMs) raises serious concerns related to privacy, security, and copyright compliance. A central challenge in assessing this risk is distinguishing genuine memorization of training data from the generation of statistically common sequences. Existing approaches to measuring memorization often conflate these phenomena, labeling outputs as memorized even when they arise from generalization over common patterns. Counterfactual Memorization provides a principled solution by comparing models trained with and without a target sequence, but its reliance on retraining multiple baseline models makes it computationally expensive and impractical at scale.
  This work introduces Prior-Aware Memorization, a theoretically grounded, lightweight and training-free criterion for identifying genuine memorization in LLMs. The key idea is to evaluate whether a candidate suffix is strongly associated with its specific training prefix or whether it appears with high probability across many unrelated prompts due to statistical commonality.
  We evaluate this metric on text from the training corpora of two pre-trained models, LLaMA and OPT, using both long sequences (to simulate copyright risks) and named entities (to simulate PII leakage). Our results show that between 55% and 90% of sequences previously labeled as memorized are in fact statistically common. Similar findings hold for the SATML training data extraction challenge dataset, where roughly 40% of sequences exhibit common-pattern behavior despite appearing only once in the training data. These results demonstrate that low frequency alone is insufficient evidence of memorization and highlight the importance of accounting for model priors when assessing leakage.

</details>


### [36] [When World Models Dream Wrong: Physical-Conditioned Adversarial Attacks against World Models](https://arxiv.org/abs/2602.18739)
*Zhixiang Guo,Siyuan Liang,Andras Balogh,Noah Lunberry,Rong-Cheng Tu,Mark Jelasity,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出PhysCond-WMA攻击方法，通过扰动生成世界模型的物理条件通道（如HDMap嵌入和3D框特征），在保持感知保真度的同时诱导语义、逻辑或决策级失真。


<details>
  <summary>Details</summary>
Motivation: 生成世界模型在自动驾驶视频合成中应用日益广泛，但其对物理先验的依赖暴露了新的攻击面。目前缺乏针对世界模型物理条件通道的白盒攻击研究，需要揭示和量化这类模型的安全漏洞。

Method: 提出两阶段优化攻击方法：1）质量保持引导阶段，将反向扩散损失约束在校准阈值以下；2）动量引导去噪阶段，沿去噪轨迹积累目标对齐梯度，实现稳定、时间一致的语义偏移。

Result: 攻击在保持感知质量的同时有效，平均FID增加约9%，FVD增加约3.9%。目标攻击成功率（ASR）达0.55。下游研究显示，使用攻击视频训练会使3D检测性能下降约4%，开环规划性能恶化约20%。

Conclusion: 首次揭示并量化了生成世界模型的安全漏洞，表明物理条件通道攻击对下游任务构成实际风险，推动更全面的安全检查器开发。

Abstract: Generative world models (WMs) are increasingly used to synthesize controllable, sensor-conditioned driving videos, yet their reliance on physical priors exposes novel attack surfaces. In this paper, we present Physical-Conditioned World Model Attack (PhysCond-WMA), the first white-box world model attack that perturbs physical-condition channels, such as HDMap embeddings and 3D-box features, to induce semantic, logic, or decision-level distortion while preserving perceptual fidelity. PhysCond-WMA is optimized in two stages: (1) a quality-preserving guidance stage that constrains reverse-diffusion loss below a calibrated threshold, and (2) a momentum-guided denoising stage that accumulates target-aligned gradients along the denoising trajectory for stable, temporally coherent semantic shifts. Extensive experimental results demonstrate that our approach remains effective while increasing FID by about 9% on average and FVD by about 3.9% on average. Under the targeted attack setting, the attack success rate (ASR) reaches 0.55. Downstream studies further show tangible risk, which using attacked videos for training decreases 3D detection performance by about 4%, and worsens open-loop planning performance by about 20%. These findings has for the first time revealed and quantified security vulnerabilities in generative world models, driving more comprehensive security checkers.

</details>


### [37] [HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.18740)
*Ziyan Zhang,Changxin Wan,Peng Hao,Kanok Boriboonsomsin,Matthew J. Barth,Yongkang Liu,Seyhan Ucar,Guoyuan Wu*

Main category: cs.LG

TL;DR: 提出分层网络级交通流控制框架，通过多智能体强化学习优化信号控制，结合机器学习轨迹规划算法引导网联自动驾驶车辆执行生态接近与离开操作，提升混合交通网络的效率和能源表现。


<details>
  <summary>Details</summary>
Motivation: 随着网联自动驾驶车辆（CAVs）在交通系统中的比例增加，需要开发能够同时优化车辆级生态驾驶行为和交叉口级交通信号控制的综合框架，以提升混合交通网络的整体效率和减少能源消耗。

Method: 采用分层控制框架：1）基于值分解网络（VDN）的去中心化多智能体强化学习（MARL）方法管理交叉口的周期交通信号控制；2）创新的信号相位与时间预测方法结合基于机器学习的轨迹规划算法（MLTPA），引导CAVs执行生态接近与离开（EAD）操作。

Result: 在4*4真实世界网络中测试，MARL交通信号控制方法在速度、燃油消耗和怠速时间方面优于Webster基准方法。结合MLTPA的HONEST-CAV进一步改善了能源消耗和怠速时间。当CAV比例为60%时，车辆平均速度提升7.67%，燃油消耗减少10.23%，怠速时间减少45.83%。

Conclusion: 提出的分层控制框架有效提升了混合交通网络的效率和能源表现，特别是在高CAV比例情况下效果显著。研究还量化了自动化和电气化对系统性能的影响，为未来智能交通系统设计提供了重要参考。

Abstract: This study presents a hierarchical, network-level traffic flow control framework for mixed traffic consisting of Human-driven Vehicles (HVs), Connected and Automated Vehicles (CAVs). The framework jointly optimizes vehicle-level eco-driving behaviors and intersection-level traffic signal control to enhance overall network efficiency and decrease energy consumption. A decentralized Multi-Agent Reinforcement Learning (MARL) approach by Value Decomposition Network (VDN) manages cycle-based traffic signal control (TSC) at intersections, while an innovative Signal Phase and Timing (SPaT) prediction method integrates a Machine Learning-based Trajectory Planning Algorithm (MLTPA) to guide CAVs in executing Eco-Approach and Departure (EAD) maneuvers. The framework is evaluated across varying CAV proportions and powertrain types to assess its effects on mobility and energy performance. Experimental results conducted in a 4*4 real-world network demonstrate that the MARL-based TSC method outperforms the baseline model (i.e., Webster method) in speed, fuel consumption, and idling time. In addition, with MLTPA, HONEST-CAV benefits the traffic system further in energy consumption and idling time. With a 60% CAV proportion, vehicle average speed, fuel consumption, and idling time can be improved/saved by 7.67%, 10.23%, and 45.83% compared with the baseline. Furthermore, discussions on CAV proportions and powertrain types are conducted to quantify the performance of the proposed method with the impact of automation and electrification.

</details>


### [38] [RadioGen3D: 3D Radio Map Generation via Adversarial Learning on Large-Scale Synthetic Data](https://arxiv.org/abs/2602.18744)
*Junshen Chen,Angzi Xu,Zezhong Zhang,Shiyao Zhang,Junting Chen,Shuguang Cui*

Main category: cs.LG

TL;DR: RadioGen3D框架通过合成高质量3D无线电地图数据和条件生成对抗网络训练，解决了现有2D方法无法捕捉3D信号传播特性和天线极化效应的问题，在6G和低空网络中实现准确快速的无线电地图估计。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习无线电地图估计方法主要局限于2D近地面场景，无法捕捉关键的3D信号传播特性和天线极化效应，主要原因是缺乏3D数据和训练挑战。需要开发能够处理3D场景的无线电地图估计方法。

Method: 提出RadioGen3D框架：1) 高效数据合成方法，通过参数化目标模型捕捉2D射线追踪和3D信道衰落特性，从少量真实测量推导现实系数组合，构建大规模合成数据集Radio3DMix；2) 基于条件生成对抗网络(cGAN)的3D模型训练方案，训练出能够处理多样化输入特征组合的3D U-Net模型。

Result: 实验结果表明，RadioGen3D在所有基线方法中在估计精度和速度方面都表现更优。微调实验验证了其通过成功知识转移展现出的强大泛化能力。

Conclusion: RadioGen3D框架通过创新的数据合成和模型训练方法，有效解决了3D无线电地图估计的挑战，为6G和低空网络的无线电资源管理提供了高效准确的解决方案。

Abstract: Radio maps are essential for efficient radio resource management in future 6G and low-altitude networks. While deep learning (DL) techniques have emerged as an efficient alternative to conventional ray-tracing for radio map estimation (RME), most existing DL approaches are confined to 2D near-ground scenarios. They often fail to capture essential 3D signal propagation characteristics and antenna polarization effects, primarily due to the scarcity of 3D data and training challenges. To address these limitations, we present the RadioGen3D framework. First, we propose an efficient data synthesis method to generate high-quality 3D radio map data. By establishing a parametric target model that captures 2D ray-tracing and 3D channel fading characteristics, we derive realistic coefficient combinations from minimal real measurements, enabling the construction of a large-scale synthetic dataset, Radio3DMix. Utilizing this dataset, we propose a 3D model training scheme based on a conditional generative adversarial network (cGAN), yielding a 3D U-Net capable of accurate RME under diverse input feature combinations. Experimental results demonstrate that RadioGen3D surpasses all baselines in both estimation accuracy and speed. Furthermore, fine-tuning experiments verify its strong generalization capability via successful knowledge transfer.

</details>


### [39] [GLaDiGAtor: Language-Model-Augmented Multi-Relation Graph Learning for Predicting Disease-Gene Associations](https://arxiv.org/abs/2602.18769)
*Osman Onur Kuzucu,Tunca Doğan*

Main category: cs.LG

TL;DR: 提出GLaDiGAtor模型，一种基于图神经网络的疾病-基因关联预测框架，通过整合异质生物图和多模态特征，在预测准确性和泛化能力上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于人工标注和文献回顾的疾病-基因关联分析方法劳动密集且不可扩展，需要利用机器学习处理大规模生物医学数据。现有模型存在局限性，需要更有效的预测方法。

Method: 提出GLaDiGAtor框架，采用编码器-解码器架构的图神经网络。构建整合基因-基因、疾病-疾病、基因-疾病相互作用的异质生物图，并使用ProtT5（蛋白质序列）和BioBERT（疾病文本）语言模型为节点提供上下文特征。

Result: 模型在预测准确性和泛化能力上优于14种现有方法。文献支持的案例研究证实了高置信度新预测的生物学相关性，展示了发现候选疾病基因的潜力。

Conclusion: GLaDiGAtor展示了图卷积网络在生物医学信息学中的强大能力，可能通过揭示新的基因-疾病关联促进药物发现。源代码和数据集已公开。

Abstract: Understanding disease-gene associations is essential for unravelling disease mechanisms and advancing diagnostics and therapeutics. Traditional approaches based on manual curation and literature review are labour-intensive and not scalable, prompting the use of machine learning on large biomedical data. In particular, graph neural networks (GNNs) have shown promise for modelling complex biological relationships. To address limitations in existing models, we propose GLaDiGAtor (Graph Learning-bAsed DIsease-Gene AssociaTiOn pRediction), a novel GNN framework with an encoder-decoder architecture for disease-gene association prediction. GLaDiGAtor constructs a heterogeneous biological graph integrating gene-gene, disease-disease, and gene-disease interactions from curated databases, and enriches each node with contextual features from well-known language models (ProtT5 for protein sequences and BioBERT for disease text). In evaluations, our model achieves superior predictive accuracy and generalisation, outperforming 14 existing methods. Literature-supported case studies confirm the biological relevance of high-confidence novel predictions, highlighting GLaDiGAtor's potential to discover candidate disease genes. These results underscore the power of graph convolutional networks in biomedical informatics and may ultimately facilitate drug discovery by revealing new gene-disease links. The source code and processed datasets are publicly available at https://github.com/HUBioDataLab/GLaDiGAtor.

</details>


### [40] [CaliCausalRank: Calibrated Multi-Objective Ad Ranking with Robust Counterfactual Utility Optimization](https://arxiv.org/abs/2602.18786)
*Xikai Yang,Sebastian Sun,Yilin Li,Yue Xing,Ming Wang,Yang Wang*

Main category: cs.LG

TL;DR: CaliCausalRank是一个统一的广告排序框架，通过训练时尺度校准、基于约束的多目标优化和鲁棒的反事实效用估计，解决了评分尺度不一致和位置偏差问题。


<details>
  <summary>Details</summary>
Motivation: 生产系统中的广告排序面临两个关键挑战：1）不同流量段之间的评分尺度不一致，削弱了阈值的可转移性；2）点击日志中的位置偏差导致离线-在线指标差异。

Method: 提出CaliCausalRank框架，将评分校准作为首要训练目标而非后处理，采用拉格朗日松弛法满足约束条件，并使用方差减少的反事实估计器进行可靠的离线评估。

Result: 在Criteo和Avazu数据集上的实验表明，相比最佳基线（PairRank），CaliCausalRank实现了1.1%的相对AUC提升，31.6%的校准误差减少，以及3.2%的效用增益，同时在不同流量段保持一致的性能。

Conclusion: CaliCausalRank通过统一的训练时校准和鲁棒的反事实估计，有效解决了广告排序中的尺度不一致和位置偏差问题，实现了多目标优化和跨流量段的一致性性能。

Abstract: Ad ranking systems must simultaneously optimize multiple objectives including click-through rate (CTR), conversion rate (CVR), revenue, and user experience metrics. However, production systems face critical challenges: score scale inconsistency across traffic segments undermines threshold transferability, and position bias in click logs causes offline-online metric discrepancies. We propose CaliCausalRank, a unified framework that integrates training-time scale calibration, constraint-based multi-objective optimization, and robust counterfactual utility estimation. Our approach treats score calibration as a first-class training objective rather than post-hoc processing, employs Lagrangian relaxation for constraint satisfaction, and utilizes variance-reduced counterfactual estimators for reliable offline evaluation. Experiments on the Criteo and Avazu datasets demonstrate that CaliCausalRank achieves 1.1% relative AUC improvement, 31.6% calibration error reduction, and 3.2% utility gain compared to the best baseline (PairRank) while maintaining consistent performance across different traffic segments.

</details>


### [41] [From Few-Shot to Zero-Shot: Towards Generalist Graph Anomaly Detection](https://arxiv.org/abs/2602.18793)
*Yixin Liu,Shiyuan Li,Yu Zheng,Qingfeng Chen,Chengqi Zhang,Philip S. Yu,Shirui Pan*

Main category: cs.LG

TL;DR: 提出ARC和ARC_zero两种通用图异常检测方法，通过少量样本或无标签实现跨数据集异常检测，无需针对每个数据集单独训练。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法通常采用"一个模型对应一个数据集"的模式，需要针对每个数据集进行特定训练，存在计算成本高、泛化能力差、在隐私敏感场景下难以应用等问题。

Method: 提出ARC方法，包含三个核心模块：特征对齐模块统一跨数据集特征，残差GNN编码器捕捉数据集无关的异常表示，跨注意力上下文学习模块利用少量正常样本进行异常评分。进一步提出ARC_zero，通过伪上下文机制选择代表性伪正常节点，实现零样本检测。

Result: 在17个真实世界图数据集上的实验表明，ARC和ARC_zero都能有效检测异常，表现出强大的泛化能力，在少样本和零样本设置下均能高效运行。

Conclusion: 提出的通用图异常检测范式解决了传统方法的局限性，通过少量样本或无标签即可实现跨数据集的异常检测，为图异常检测提供了新的解决方案。

Abstract: Graph anomaly detection (GAD) is critical for identifying abnormal nodes in graph-structured data from diverse domains, including cybersecurity and social networks. The existing GAD methods often focus on the learning paradigms of "one-model-for-one-dataset", requiring dataset-specific training for each dataset to achieve optimal performance. However, this paradigm suffers from significant limitations, such as high computational and data costs, limited generalization and transferability to new datasets, and challenges in privacy-sensitive scenarios where access to full datasets or sufficient labels is restricted. To address these limitations, we propose a novel generalist GAD paradigm that aims to develop a unified model capable of detecting anomalies on multiple unseen datasets without extensive retraining/fine-tuning or dataset-specific customization. To this end, we propose ARC, a few-shot generalist GAD method that leverages in-context learning and requires only a few labeled normal samples at inference time. Specifically, ARC consists of three core modules: a feature Alignment module to unify and align features across datasets, a Residual GNN encoder to capture dataset-agnostic anomaly representations, and a cross-attentive in-Context learning module to score anomalies using few-shot normal context. Building on ARC, we further introduce ARC_zero for the zero-shot generalist GAD setting, which selects representative pseudo-normal nodes via a pseudo-context mechanism and thus enables fully label-free inference on unseen datasets. Extensive experiments on 17 real-world graph datasets demonstrate that both ARC and ARC_zero effectively detect anomalies, exhibit strong generalization ability, and perform efficiently under few-shot and zero-shot settings.

</details>


### [42] [Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation](https://arxiv.org/abs/2602.18795)
*Zheng Wang,Nizar Bouguila*

Main category: cs.LG

TL;DR: LDTA是LDA的扩展，用狄利克雷树分布替代狄利克雷先验，能建模主题间的相关性和层次结构，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统LDA的狄利克雷先验无法表示主题间丰富的相关性和层次关系，限制了建模能力。

Method: 提出LDTA框架，用任意狄利克雷树分布替代狄利克雷先验，开发通用变分推断和期望传播算法，实现GPU加速的向量化实现。

Result: LDTA显著扩展了LDA的建模能力，同时保持了可扩展性和计算效率。

Conclusion: LDTA为LDA提供了更丰富的先验表达能力，同时保持了计算可行性，是LDA的重要扩展。

Abstract: Latent Dirichlet Allocation (LDA) is a foundational model for discovering latent thematic structure in discrete data, but its Dirichlet prior cannot represent the rich correlations and hierarchical relationships often present among topics. We introduce the framework of Latent Dirichlet-Tree Allocation (LDTA), a generalization of LDA that replaces the Dirichlet prior with an arbitrary Dirichlet-Tree (DT) distribution. LDTA preserves LDA's generative structure but enables expressive, tree-structured priors over topic proportions. To perform inference, we develop universal mean-field variational inference and Expectation Propagation, providing tractable updates for all DT. We reveal the vectorized nature of the two inference methods through theoretical development, and perform fully vectorized, GPU-accelerated implementations. The resulting framework substantially expands the modeling capacity of LDA while maintaining scalability and computational efficiency.

</details>


### [43] [SGNO: Spectral Generator Neural Operators for Stable Long Horizon PDE Rollouts](https://arxiv.org/abs/2602.18801)
*Jiayi Li,Zhaonan Wang,Flora D. Salim*

Main category: cs.LG

TL;DR: SGNO是一种新型神经算子，通过谱空间指数时间差分更新和门控非线性项，解决了自回归推演中的不稳定问题，在长时预测中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 神经算子在短训练长测试场景下，自回归推演容易变得不稳定，主要原因有两个：单步误差随时间累积，以及高频分量反馈增长。

Method: SGNO使用谱空间指数时间差分更新，学习对角生成器并约束其实部非正；添加门控强迫项进行通道混合；应用谱截断和可选平滑掩码限制高频反馈。

Result: 在APEBench的1D、2D和3D PDE系列上，SGNO实现了更低的长期误差和更长的稳定推演长度，优于现有神经算子基线。

Conclusion: SGNO通过约束线性生成器和控制非线性更新，有效解决了神经算子自回归推演的不稳定性问题，为长时PDE预测提供了可靠解决方案。

Abstract: Neural operators provide fast PDE surrogates and often generalize across parameters and resolutions. However, in the short train long test setting, autoregressive rollouts can become unstable. This typically happens for two reasons: one step errors accumulate over time, and high frequency components feed back and grow.
  We introduce the Spectral Generator Neural Operator (SGNO), a residual time stepper that targets both effects. For the linear part, SGNO uses an exponential time differencing update in Fourier space with a learned diagonal generator. We constrain the real part of this generator to be nonpositive, so iterating the step does not amplify the linear dynamics. For nonlinear dynamics, SGNO adds a gated forcing term with channel mixing within each Fourier mode, which keeps the nonlinear update controlled. To further limit high frequency feedback, SGNO applies spectral truncation and an optional smooth mask on the forcing pathway.
  We derive a one step amplification bound and a finite horizon rollout error bound. The bound separates generator approximation error from nonlinear mismatch and gives sufficient conditions under which the latent $L^2$ norm does not grow across rollout steps. On APEBench spanning 1D, 2D, and 3D PDE families, SGNO achieves lower long horizon error and longer stable rollout lengths than strong neural operator baselines. Ablations confirm the roles of the generator constraint, gating, and filtering.The code is available at https://github.com/lijy32123-cloud/SGNO.

</details>


### [44] [Bayesian Lottery Ticket Hypothesis](https://arxiv.org/abs/2602.18825)
*Nicholas Kuhn,Arvid Weyrauch,Lars Heyen,Achim Streit,Markus Götz,Charlotte Debus*

Main category: cs.LG

TL;DR: 贝叶斯神经网络中存在彩票假设，稀疏子网络能达到甚至超越原始网络的精度，但需要基于权重幅值和标准差进行剪枝。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯神经网络(BNNs)用于不确定性量化但计算成本高，彩票假设(LTH)在传统神经网络中已证实存在高效稀疏子网络。研究BNNs中是否存在类似彩票假设，可推动稀疏训练算法发展并深入理解训练过程。

Method: 将彩票假设实验扩展到贝叶斯设置，使用常见计算机视觉模型。研究贝叶斯彩票票券的特征，并扩展到连接BNNs与确定性彩票票券的移植方法。主要基于权重幅值和标准差进行剪枝策略分析。

Result: 彩票假设在BNNs中成立，存在匹配甚至超越原始网络精度的获胜票券，且与模型大小无关（在极高稀疏度下性能会下降）。剪枝策略应主要基于权重幅值，其次基于标准差。模型对掩码结构和权重初始化的依赖程度不同。

Conclusion: 贝叶斯神经网络中存在彩票假设，稀疏子网络能保持甚至提升性能，这为开发稀疏训练算法提供了理论基础，并揭示了BNNs训练过程的内在机制。

Abstract: Bayesian neural networks (BNNs) are a useful tool for uncertainty quantification, but require substantially more computational resources than conventional neural networks. For non-Bayesian networks, the Lottery Ticket Hypothesis (LTH) posits the existence of sparse subnetworks that can train to the same or even surpassing accuracy as the original dense network. Such sparse networks can lower the demand for computational resources at inference, and during training. The existence of the LTH and corresponding sparse subnetworks in BNNs could motivate the development of sparse training algorithms and provide valuable insights into the underlying training process. Towards this end, we translate the LTH experiments to a Bayesian setting using common computer vision models. We investigate the defining characteristics of Bayesian lottery tickets, and extend our study towards a transplantation method connecting BNNs with deterministic Lottery Tickets. We generally find that the LTH holds in BNNs, and winning tickets of matching and surpassing accuracy are present independent of model size, with degradation at very high sparsities. However, the pruning strategy should rely primarily on magnitude, secondly on standard deviation. Furthermore, our results demonstrate that models rely on mask structure and weight initialization to varying degrees.

</details>


### [45] [L2G-Net: Local to Global Spectral Graph Neural Networks via Cauchy Factorizations](https://arxiv.org/abs/2602.18837)
*Samuel Fernández-Menduiña,Eduardo Pavez,Antonio Ortega*

Main category: cs.LG

TL;DR: L2G-Net：一种新颖的谱图神经网络，通过将图傅里叶变换分解为作用于子图的算子，并使用柯西矩阵组合，实现了从局部到全局的谱处理，避免了完全特征分解，在非局部依赖任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的谱方法要么完全全局（使用完整的图傅里叶变换），要么完全局部（使用多项式滤波器），前者计算成本高且缺乏顶点域局部性，后者难以建模长程依赖关系。需要一种既能利用谱表示优势又能保持计算效率的方法。

Method: 提出图傅里叶变换的新分解方法，将其分解为作用于子图的算子，然后通过一系列柯西矩阵组合这些子图谱表示。构建L2G-Net（局部到全局网络），避免完全特征分解，利用图拓扑结构构建分解，计算复杂度为节点数的二次方乘以子图接口大小。

Result: 在强调非局部依赖的基准测试中，L2G-Net优于现有谱技术，并与最先进方法竞争，同时使用数量级更少的可学习参数。

Conclusion: L2G-Net通过局部到全局的谱处理方法，解决了传统谱方法计算成本高和缺乏局部性的问题，同时能够有效建模长程依赖，为谱图神经网络提供了新的有效框架。

Abstract: Despite their theoretical advantages, spectral methods based on the graph Fourier transform (GFT) are seldom used in graph neural networks (GNNs) due to the cost of computing the eigenbasis and the lack of vertex-domain locality in spectral representations. As a result, most GNNs rely on local approximations such as polynomial Laplacian filters or message passing, which limit their ability to model long-range dependencies. In this paper, we introduce a novel factorization of the GFT into operators acting on subgraphs, which are then combined via a sequence of Cauchy matrices. We use this factorization to propose a new class of spectral GNNs, which we term L2G-Net (Local-to-Global Net). Unlike existing spectral methods, which are either fully global (when they use the GFT) or local (when they use polynomial filters), L2G-Net operates by processing the spectral representations of subgraphs and then combining them via structured matrices. Our algorithm avoids full eigendecompositions, exploiting graph topology to construct the factorization with quadratic complexity in the number of nodes, scaled by the subgraph interface size. Experiments on benchmarks stressing non-local dependencies show that L2G-Net outperforms existing spectral techniques and is competitive with the state-of-the-art with orders of magnitude fewer learnable parameters.

</details>


### [46] [Exact Attention Sensitivity and the Geometry of Transformer Stability](https://arxiv.org/abs/2602.18849)
*Seyed Morteza Emadi*

Main category: cs.LG

TL;DR: 论文提出了一个解释Transformer训练稳定性的理论框架，揭示了pre-LayerNorm有效、DeepNorm使用N^{-1/4}缩放以及warmup必要性的根本原因，发现稳定性主要来自架构设计而非注意力动态。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer是现代AI的核心，但其训练过程仍然神秘且脆弱。研究者希望从基本原理出发，解释为什么某些架构设计（如pre-LayerNorm、DeepNorm）能够提高训练稳定性，以及为什么需要warmup等训练技巧。

Method: 提出了一个包含两大支柱的理论框架：(1) 推导了softmax Jacobian的精确算子范数，引入平衡质量因子θ(p)量化注意力敏感性；(2) 引入了与tokenwise计算对齐的block-∞/RMS几何，得到与序列长度无关的Lipschitz边界。使用这个框架证明了pre-LN保持恒等梯度路径，而post-LN会指数级累积LayerNorm Jacobians。

Result: 证明了DeepNorm的N^{-1/4}缩放来自注意力四个投影矩阵的四次结构；在774M参数模型上验证了理论，发现θ(p)≈1在整个训练过程中持续存在，表明Transformer稳定性完全来自架构梯度流而非注意力动态。

Conclusion: Transformer的稳定性源于架构设计本身，而非学习到的注意力模式。这一发现改变了我们对训练的理解：架构本身必须处理敏感性，而不是依赖注意力动态。这为设计更稳定的Transformer架构提供了理论基础。

Abstract: Despite powering modern AI, transformers remain mysteriously brittle to train. We develop a stability theory that explains why pre-LayerNorm works, why DeepNorm uses $N^{-1/4}$ scaling, and why warmup is necessary, all from first principles. Our framework has two pillars: (1) We derive the \emph{exact} operator norm of the softmax Jacobian, $\|J_{softmax}(u/τ)\|_{\infty\to 1} = θ(p)/τ$, where the balanced-mass factor $θ(p)\in[0,1]$ quantifies attention sensitivity. (2) We introduce a block-$\infty$/RMS geometry aligned with tokenwise computation, yielding Lipschitz bounds independent of sequence length. Using this framework, we prove that pre-LN preserves identity gradient paths while post-LN compounds LayerNorm Jacobians exponentially with depth, and we show that DeepNorm's $N^{-1/4}$ emerges from the quartic structure of attention's four projection matrices. We validate our theory on 774M-parameter models and find that, contrary to the intuition that attention sharpens during training to reduce sensitivity, $θ(p) \approx 1$ persists throughout. Transformer stability arises entirely from architectural gradient flow, not from attention dynamics. This finding changes how we reason about training: the architecture itself must handle sensitivity, not learned attention patterns.

</details>


### [47] [Rank-Aware Spectral Bounds on Attention Logits for Stable Low-Precision Training](https://arxiv.org/abs/2602.18851)
*Seyed Morteza Emadi*

Main category: cs.LG

TL;DR: 该论文提出了一种针对Transformer注意力分数的秩感知集中不等式，用于分析低精度训练中的溢出风险，并基于此推导出几何感知的缩放因子来保证FP8训练中的溢出安全。


<details>
  <summary>Details</summary>
Motivation: Transformer注意力分数是双线性形式，其最大幅度决定了低精度训练中的溢出风险。现有方法缺乏对注意力矩阵低秩结构的考虑，导致溢出保护不足或过度保守。

Method: 1. 推导秩感知集中不等式：当交互矩阵M=W^Q W^{K⊤}的秩r≪d时，max|S_ij|的尾概率以exp(-d²α²/(γr))衰减，而非exp(-dα²)。2. 应用该结果到FP8训练，提出几何感知缩放因子：通过隐式幂迭代计算谱范数||W^Q W^{K⊤}||₂，推导每层缩放因子。3. 包含分组查询注意力公式，避免键扩展，保持与融合注意力内核的兼容性。

Result: 1. 对于Transformer注意力（r=d_h），新不等式比秩无关边界紧致8-28倍。2. 在GPT-2 XL到Llama-2-70B模型中，几何感知缩放在延迟缩放失败的瞬态场景中消除了溢出，同时保持可比较的下游MMLU准确率。

Conclusion: 通过利用注意力矩阵的低秩结构，提出的秩感知集中不等式和几何感知缩放因子为FP8训练提供了理论保证的溢出保护，优于现有方法，且在实际大规模模型中验证有效。

Abstract: Attention scores in transformers are bilinear forms $S_{ij} = x_i^\top M x_j / \sqrt{d_h}$ whose maximum magnitude governs overflow risk in low-precision training. We derive a \emph{rank-aware concentration inequality}: when the interaction matrix $M = W^Q W^{K\top}$ has rank $r \ll d$, tail probabilities for $\max_{i,j}|S_{ij}|$ decay as $\exp(-d^{2}α^{2}/(γr))$ rather than $\exp(-dα^{2})$, where $γ> 1$ is a typicality parameter. For transformer attention where $r = d_h$, this yields $8$--$28\times$ tighter concentration than rank-agnostic bounds in modern architectures. We apply this result to FP8 training, deriving \emph{geometry-aware scale factors} that provide principled overflow guarantees without observing activations. The method computes per-layer scales from the spectral norm $\|W^Q W^{K\top}\|_2$ via implicit power iteration, includes a grouped query attention formulation that avoids key expansion, and remains compatible with fused attention kernels. Across GPT-2 XL to Llama-2-70B, geometry-aware scaling eliminates overflows in transient scenarios where delayed scaling fails, while achieving comparable downstream MMLU accuracy.

</details>


### [48] [Issues with Measuring Task Complexity via Random Policies in Robotic Tasks](https://arxiv.org/abs/2602.18856)
*Reabetswe M. Nkhumise,Mohamed S. Talamali,Aditya Gilra*

Main category: cs.LG

TL;DR: 本文评估了非表格强化学习中任务复杂度度量方法（PIC和POIC），发现它们与机器人控制和经验RL结果相矛盾，表明需要超越基于随机权重猜测的度量方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人等领域取得重大进展，但非表格环境中任务复杂度度量方法相对缺乏。现有方法如PIC和POIC依赖随机权重猜测，需要在实际机器人任务中验证其有效性。

Method: 使用渐进式难度增加的机器人操作任务（单连杆和双连杆机械臂），在密集和稀疏奖励两种设置下，评估PIC和POIC等复杂度度量方法，并与已知的相对复杂度进行比较。

Result: PIC显示双连杆机械臂比单连杆更容易（与机器人控制常识相矛盾），POIC显示稀疏奖励任务比密集奖励更容易（与RL经验相矛盾），表明现有度量方法不可靠。

Conclusion: 基于随机权重猜测的复杂度度量方法（PIC和POIC）不能准确反映非表格RL中的任务复杂度，需要开发更好的度量方法，本文的任务框架可作为起点。

Abstract: Reinforcement learning (RL) has enabled major advances in fields such as robotics and natural language processing. A key challenge in RL is measuring task complexity, which is essential for creating meaningful benchmarks and designing effective curricula. While there are numerous well-established metrics for assessing task complexity in tabular settings, relatively few exist in non-tabular domains. These include (i) Statistical analysis of the performance of random policies via Random Weight Guessing (RWG), and (ii) information-theoretic metrics Policy Information Capacity (PIC) and Policy-Optimal Information Capacity (POIC), which are reliant on RWG. In this paper, we evaluate these methods using progressively difficult robotic manipulation setups, with known relative complexity, with both dense and sparse reward formulations. Our empirical results reveal that measuring complexity is still nuanced. Specifically, under the same reward formulation, PIC suggests that a two-link robotic arm setup is easier than a single-link setup - which contradicts the robotic control and empirical RL perspective whereby the two-link setup is inherently more complex. Likewise, for the same setup, POIC estimates that tasks with sparse rewards are easier than those with dense rewards. Thus, we show that both PIC and POIC contradict typical understanding and empirical results from RL. These findings highlight the need to move beyond RWG-based metrics towards better metrics that can more reliably capture task complexity in non-tabular RL with our task framework as a starting point.

</details>


### [49] [VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning](https://arxiv.org/abs/2602.18857)
*Joery A. de Vries,Jinke He,Yaniv Oren,Pascal R. van der Vaart,Mathijs M. de Weerdt,Matthijs T. J. Spaan*

Main category: cs.LG

TL;DR: 提出VariBASeD方法，通过变分框架结合信念学习、序列蒙特卡洛规划和元强化学习，在单GPU上实现更高效的贝叶斯自适应MDP学习与规划。


<details>
  <summary>Details</summary>
Motivation: 强化学习中探索与利用的最优权衡是圣杯问题，贝叶斯最优智能体可实现这一目标，但信念状态获取和规划通常难以处理。现有深度学习方法训练成本高，需要更高效的解决方案。

Method: 提出变分框架，融合变分信念学习、序列蒙特卡洛规划和元强化学习，形成VariBASeD方法，在单GPU环境中实现高效计算。

Result: 在单GPU设置下，VariBASeD方法在更大规划预算下表现出良好的扩展性，相比先前方法提高了样本效率和运行时效率。

Conclusion: VariBASeD为贝叶斯自适应MDP提供了一个高效的学习和规划框架，在计算效率和扩展性方面优于现有方法，推动了强化学习中探索与利用最优权衡的研究。

Abstract: Optimally trading-off exploration and exploitation is the holy grail of reinforcement learning as it promises maximal data-efficiency for solving any task. Bayes-optimal agents achieve this, but obtaining the belief-state and performing planning are both typically intractable. Although deep learning methods can greatly help in scaling this computation, existing methods are still costly to train. To accelerate this, this paper proposes a variational framework for learning and planning in Bayes-adaptive Markov decision processes that coalesces variational belief learning, sequential Monte-Carlo planning, and meta-reinforcement learning. In a single-GPU setup, our new method VariBASeD exhibits favorable scaling to larger planning budgets, improving sample- and runtime-efficiency over prior methods.

</details>


### [50] [Hyperbolic Busemann Neural Networks](https://arxiv.org/abs/2602.18858)
*Ziheng Chen,Bernhard Schölkopf,Nicu Sebe*

Main category: cs.LG

TL;DR: 提出基于Busemann函数的双曲空间多层逻辑回归和全连接层，在多个任务上提升效果和效率


<details>
  <summary>Details</summary>
Motivation: 双曲空间适合表示层次化和树状结构数据，但需要直接在双曲空间中操作的高效神经网络组件

Method: 通过Busemann函数将多层逻辑回归和全连接层提升到双曲空间，得到BMLR和BFC层，具有统一的数学解释

Result: 在图像分类、基因组序列学习、节点分类和链接预测任务上，相比现有双曲层在效果和效率上都有提升

Conclusion: 基于Busemann函数的双曲神经网络组件提供了紧凑参数、点-超球面距离解释、批量高效计算和欧几里得极限等优势

Abstract: Hyperbolic spaces provide a natural geometry for representing hierarchical and tree-structured data due to their exponential volume growth. To leverage these benefits, neural networks require intrinsic and efficient components that operate directly in hyperbolic space. In this work, we lift two core components of neural networks, Multinomial Logistic Regression (MLR) and Fully Connected (FC) layers, into hyperbolic space via Busemann functions, resulting in Busemann MLR (BMLR) and Busemann FC (BFC) layers with a unified mathematical interpretation. BMLR provides compact parameters, a point-to-horosphere distance interpretation, batch-efficient computation, and a Euclidean limit, while BFC generalizes FC and activation layers with comparable complexity. Experiments on image classification, genome sequence learning, node classification, and link prediction demonstrate improvements in effectiveness and efficiency over prior hyperbolic layers. The code is available at https://github.com/GitZH-Chen/HBNN.

</details>


### [51] [Boosting for Vector-Valued Prediction and Conditional Density Estimation](https://arxiv.org/abs/2602.18866)
*Jian Qian,Shu Ge*

Main category: cs.LG

TL;DR: 论文提出了一种基于几何中位数聚合的通用提升框架GeoMedBoost，用于结构化预测中的向量值和条件密度预测，通过(α,β)-boostability理论将弱保证放大为强保证。


<details>
  <summary>Details</summary>
Motivation: 尽管提升方法在结构化预测中广泛应用，但超越标量损失的聚合理论理解仍不完整。需要研究在一般散度下的向量值和条件密度预测，并识别在何种稳定性条件下聚合能将弱保证放大为强保证。

Method: 提出(α,β)-boostability稳定性概念，证明几何中位数聚合对广泛散度类具有此性质。基于此构建GeoMedBoost框架，结合指数重加权和几何中位数聚合，在弱学习器条件和(α,β)-boostability下实现经验散度超限误差的指数衰减。

Result: 几何中位数聚合对ℓ₁、ℓ₂、TV和Hellinger散度具有boostability性质，揭示了维度依赖和维度无关机制之间的明显区别。KL散度虽不能直接通过几何中位数聚合提升，但可通过Hellinger距离间接处理。GeoMedBoost框架统一了MedBoost、AdaBoost和SAMME等经典算法。

Conclusion: 论文建立了结构化预测中提升的统一几何视角，通过几何中位数聚合和(α,β)-boostability理论，为向量值和条件密度预测提供了通用框架，将经典提升算法统一于同一几何框架下。

Abstract: Despite the widespread use of boosting in structured prediction, a general theoretical understanding of aggregation beyond scalar losses remains incomplete. We study vector-valued and conditional density prediction under general divergences and identify stability conditions under which aggregation amplifies weak guarantees into strong ones.
  We formalize this stability property as \emph{$(α,β)$-boostability}. We show that geometric median aggregation achieves $(α,β)$-boostability for a broad class of divergences, with tradeoffs that depend on the underlying geometry. For vector-valued prediction and conditional density estimation, we characterize boostability under common divergences ($\ell_1$, $\ell_2$, $\TV$, and $\Hel$) with geometric median, revealing a sharp distinction between dimension-dependent and dimension-free regimes. We further show that while KL divergence is not directly boostable via geometric median aggregation, it can be handled indirectly through boostability under Hellinger distance.
  Building on these structural results, we propose a generic boosting framework \textsc{GeoMedBoost} based on exponential reweighting and geometric-median aggregation. Under a weak learner condition and $(α,β)$-boostability, we obtain exponential decay of the empirical divergence exceedance error. Our framework recovers classical algorithms such as \textsc{MedBoost}, \textsc{AdaBoost}, and \textsc{SAMME} as special cases, and provides a unified geometric view of boosting for structured prediction.

</details>


### [52] [HEHRGNN: A Unified Embedding Model for Knowledge Graphs with Hyperedges and Hyper-Relational Edges](https://arxiv.org/abs/2602.18897)
*Rajesh Rajagopalamenon,Unnikrishnan Cheramangalath*

Main category: cs.LG

TL;DR: HEHRGNN：一个统一的超图超关系边图神经网络模型，用于处理包含超边和超关系边的n元关系知识图谱嵌入


<details>
  <summary>Details</summary>
Motivation: 现实世界知识库包含大量无法用二元边表示的复杂n元事实，现有研究主要关注简单二元关系图，对包含超边和超关系边的混合n元事实缺乏统一处理框架

Method: 提出HEHR统一事实表示格式和HEHRGNN编码器，采用新颖的消息传播模型，能够同时捕获超边和超关系边的复杂图结构

Result: 在链接预测任务中，HEHRGNN在包含不同类型n元事实的真实数据集上表现出有效性，具有归纳预测能力，且在超边和超关系数据集上的预测性能优于基线模型

Conclusion: HEHRGNN为处理包含超边和超关系边的n元关系知识图谱提供了一个统一的嵌入模型，能够有效处理现实世界知识库中的复杂事实表示问题

Abstract: Knowledge Graph(KG) has gained traction as a machine-readable organization of real-world knowledge for analytics using artificial intelligence systems. Graph Neural Network(GNN), is proven to be an effective KG embedding technique that enables various downstream tasks like link prediction, node classification, and graph classification. The focus of research in both KG embedding and GNNs has been mostly oriented towards simple graphs with binary relations. However, real-world knowledge bases have a significant share of complex and n-ary facts that cannot be represented by binary edges. More specifically, real-world knowledge bases are often a mix of two types of n-ary facts - (i) that require hyperedges and (ii) that require hyper-relational edges. Though there are research efforts catering to these n-ary fact types, they are pursued independently for each type. We propose $H$yper$E$dge $H$yper-$R$elational edge $GNN$(HEHRGNN), a unified embedding model for n-ary relational KGs with both hyperedges and hyper-relational edges. The two main components of the model are i)HEHR unified fact representation format, and ii)HEHRGNN encoder, a GNN-based encoder with a novel message propagation model capable of capturing complex graph structures comprising both hyperedges and hyper-relational edges. The experimental results of HEHRGNN on link prediction tasks show its effectiveness as a unified embedding model, with inductive prediction capability, for link prediction across real-world datasets having different types of n-ary facts. The model also shows improved link prediction performance over baseline models for hyperedge and hyper-relational datasets.

</details>


### [53] [PCA-VAE: Differentiable Subspace Quantization without Codebook Collapse](https://arxiv.org/abs/2602.18904)
*Hao Lu,Onur C. Koyun,Yongxin Guo,Zhengjie Zhu,Abbas Alili,Metin Nafi Gurcan*

Main category: cs.LG

TL;DR: PCA-VAE用在线PCA瓶颈替代向量量化，解决了VQ的非可微、梯度直通和坍缩问题，在更少比特下获得更好重建质量，并产生自然可解释的语义维度。


<details>
  <summary>Details</summary>
Motivation: 向量量化自编码器存在固有缺陷：量化器不可微、需要梯度直通技巧、容易坍缩。需要从根本上解决这些问题。

Method: 用在线PCA瓶颈替代VQ，通过Oja规则训练，学习正交、方差排序的潜在基，无需码本、承诺损失或查找噪声。

Result: PCA-VAE在CelebAHQ上的重建质量超过VQ-GAN和SimVQ，同时使用10-100倍更少的潜在比特。能自然产生可解释维度（如姿态、光照、性别线索），无需对抗正则化或解耦目标。

Conclusion: PCA是VQ的可行替代方案：数学基础扎实、稳定、比特高效、语义结构化，为生成模型提供了超越向量量化的新方向。

Abstract: Vector-quantized autoencoders deliver high-fidelity latents but suffer inherent flaws: the quantizer is non-differentiable, requires straight-through hacks, and is prone to collapse. We address these issues at the root by replacing VQ with a simple, principled, and fully differentiable alternative: an online PCA bottleneck trained via Oja's rule. The resulting model, PCA-VAE, learns an orthogonal, variance-ordered latent basis without codebooks, commitment losses, or lookup noise. Despite its simplicity, PCA-VAE exceeds VQ-GAN and SimVQ in reconstruction quality on CelebAHQ while using 10-100x fewer latent bits. It also produces naturally interpretable dimensions (e.g., pose, lighting, gender cues) without adversarial regularization or disentanglement objectives. These results suggest that PCA is a viable replacement for VQ: mathematically grounded, stable, bit-efficient, and semantically structured, offering a new direction for generative models beyond vector quantization.

</details>


### [54] [TRUE: A Trustworthy Unified Explanation Framework for Large Language Model Reasoning](https://arxiv.org/abs/2602.18905)
*Yujiao Yang*

Main category: cs.LG

TL;DR: TRUE框架通过可执行推理验证、可行域DAG建模和因果故障模式分析，为LLM推理提供多层级可验证解释


<details>
  <summary>Details</summary>
Motivation: 现有解释方法缺乏可信结构洞察，仅限于单实例分析，无法揭示推理稳定性和系统性故障机制

Method: 提出TRUE框架：实例级重新定义推理轨迹为可执行过程规范并引入盲执行验证；局部结构级通过结构一致扰动构建可行域DAG；类别级引入因果故障模式分析方法识别重复结构故障模式

Result: 在多个推理基准测试中，框架提供多层级可验证解释：单个实例的可执行推理结构、相邻输入的可行域表示、类别级可解释故障模式及量化重要性

Conclusion: 建立统一原则性范式，提高LLM推理系统的可解释性和可靠性

Abstract: Large language models (LLMs) have demonstrated strong capabilities in complex reasoning tasks, yet their decision-making processes remain difficult to interpret. Existing explanation methods often lack trustworthy structural insight and are limited to single-instance analysis, failing to reveal reasoning stability and systematic failure mechanisms. To address these limitations, we propose the Trustworthy Unified Explanation Framework (TRUE), which integrates executable reasoning verification, feasible-region directed acyclic graph (DAG) modeling, and causal failure mode analysis. At the instance level, we redefine reasoning traces as executable process specifications and introduce blind execution verification to assess operational validity. At the local structural level, we construct feasible-region DAGs via structure-consistent perturbations, enabling explicit characterization of reasoning stability and the executable region in the local input space. At the class level, we introduce a causal failure mode analysis method that identifies recurring structural failure patterns and quantifies their causal influence using Shapley values. Extensive experiments across multiple reasoning benchmarks demonstrate that the proposed framework provides multi-level, verifiable explanations, including executable reasoning structures for individual instances, feasible-region representations for neighboring inputs, and interpretable failure modes with quantified importance at the class level. These results establish a unified and principled paradigm for improving the interpretability and reliability of LLM reasoning systems.

</details>


### [55] [DeepInterestGR: Mining Deep Multi-Interest Using Multi-Modal LLMs for Generative Recommendation](https://arxiv.org/abs/2602.18907)
*Yangchen Zeng*

Main category: cs.LG

TL;DR: DeepInterestGR通过多LLM挖掘深层兴趣、奖励标注和兴趣增强离散化，解决现有生成推荐框架的浅层兴趣问题，在亚马逊基准上超越SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐框架主要依赖浅层行为信号，仅通过标题和描述等表面文本特征编码物品，导致浅层兴趣问题：模型无法捕捉用户交互背后的潜在、语义丰富的兴趣，限制了个性化深度和推荐可解释性。

Method: 提出三个关键创新：1) 多LLM兴趣挖掘：利用多个前沿LLM及其多模态变体通过思维链提示提取深层文本和视觉兴趣表示；2) 奖励标注深层兴趣：使用轻量级二元分类器为挖掘的兴趣分配奖励标签，为强化学习提供有效监督信号；3) 兴趣增强物品离散化：将整理的深层兴趣编码为语义嵌入并通过RQ-VAE量化为SID令牌。采用两阶段训练流程：监督微调使生成模型与深层兴趣信号和协同过滤模式对齐，然后通过兴趣感知奖励优化的GRPO进行强化学习。

Result: 在三个亚马逊评论基准上的实验表明，DeepInterestGR在HR@K和NDCG@K指标上持续优于最先进的基线方法。

Conclusion: DeepInterestGR通过挖掘深层兴趣表示解决了生成推荐中的浅层兴趣问题，显著提升了推荐性能和个人化深度，为可解释推荐提供了新思路。

Abstract: Recent generative recommendation frameworks have demonstrated remarkable scaling potential by reformulating item prediction as autoregressive Semantic ID (SID) generation. However, existing methods primarily rely on shallow behavioral signals, encoding items solely through surface-level textual features such as titles and descriptions. This reliance results in a critical Shallow Interest problem: the model fails to capture the latent, semantically rich interests underlying user interactions, limiting both personalization depth and recommendation interpretability. DeepInterestGR introduces three key innovations: (1) Multi-LLM Interest Mining (MLIM): We leverage multiple frontier LLMs along with their multi-modal variants to extract deep textual and visual interest representations through Chain-of-Thought prompting. (2) Reward-Labeled Deep Interest (RLDI): We employ a lightweight binary classifier to assign reward labels to mined interests, enabling effective supervision signals for reinforcement learning. (3) Interest-Enhanced Item Discretization (IEID): The curated deep interests are encoded into semantic embeddings and quantized into SID tokens via RQ-VAE. We adopt a two-stage training pipeline: supervised fine-tuning aligns the generative model with deep interest signals and collaborative filtering patterns, followed by reinforcement learning with GRPO optimized by our Interest-Aware Reward. Experiments on three Amazon Review benchmarks demonstrate that DeepInterestGR consistently outperforms state-of-the-art baselines across HR@K and NDCG@K metrics.

</details>


### [56] [SLDP: Semi-Local Differential Privacy for Density-Adaptive Analytics](https://arxiv.org/abs/2602.18910)
*Alexey Kroshnin,Alexandra Suvorikova*

Main category: cs.LG

TL;DR: 提出半局部差分隐私(SLDP)框架，通过为每个用户分配基于局部密度的隐私区域，解耦隐私成本与迭代次数，实现高效密度自适应域离散化。


<details>
  <summary>Details</summary>
Motivation: 在本地差分隐私(LDP)下，密度自适应的域离散化对于高效用隐私保护分析至关重要，但由于迭代细化需要隐私预算成本，这一直是个挑战。

Method: 提出半局部差分隐私(SLDP)框架：1) 基于局部密度为每个用户分配隐私区域；2) 通过点在隐私区域内可能移动来定义邻接关系；3) 设计由诚实但好奇服务器在公共信道上协调的交互式(ε,δ)-SLDP协议来私有估计这些区域。

Result: 该框架将隐私成本与细化迭代次数解耦，允许高分辨率网格而无需额外隐私预算成本。在合成和真实数据集上的估计任务实验证明了该框架的有效性。

Conclusion: SLDP框架解决了LDP下密度自适应域离散化的关键挑战，通过创新的隐私区域定义和协议设计，实现了高效用隐私保护分析。

Abstract: Density-adaptive domain discretization is essential for high-utility privacy-preserving analytics but remains challenging under Local Differential Privacy (LDP) due to the privacy-budget costs associated with iterative refinement. We propose a novel framework, Semi-Local Differential Privacy (SLDP), that assigns a privacy region to each user based on local density and defines adjacency by the potential movement of a point within its privacy region. We present an interactive $(\varepsilon, δ)$-SLDP protocol, orchestrated by an honest-but-curious server over a public channel, to estimate these regions privately. Crucially, our framework decouples the privacy cost from the number of refinement iterations, allowing for high-resolution grids without additional privacy budget cost. We experimentally demonstrate the framework's effectiveness on estimation tasks across synthetic and real-world datasets.

</details>


### [57] [From Human-Level AI Tales to AI Leveling Human Scales](https://arxiv.org/abs/2602.18911)
*Peter Romero,Fernando Martínez-Plumed,Zachary R. Tyler,Matthieu Téhénan,Sipeng Chen,Álvaro David Gómez Antón,Luning Sun,Manuel Cebrian,Lexin Zhou,Yael Moros Daval,Daniel Romero-Alvarado,Félix Martí Pérez,Kevin Wei,José Hernández-Orallo*

Main category: cs.LG

TL;DR: 提出一个将AI模型性能校准到"全球人口"基准的框架，使用对数尺度将不同能力映射到人类锚定尺度上


<details>
  <summary>Details</summary>
Motivation: 当前将AI模型与"人类水平"比较存在问题，因为基准分数不可比较且人类基线通常来自狭窄人群，需要更准确、基于全球人口的校准方法

Method: 1) 为不同能力构建多级尺度，每级代表全球人口成功概率的对数尺度；2) 使用公开人类测试数据(PISA、TIMSS等)校准每个尺度；3) 使用LLM估计基数B，通过两个人口样本外推；4) 使用群体切片和后分层评估映射质量

Result: 开发出新的校准技术，能够重新校准和标准化相对于全球人口的尺度，提供更准确的人类基准比较框架

Conclusion: 该框架解决了AI与人类比较中的基准不可比性问题，通过全球人口校准提供了更可靠的人类锚定尺度，有助于更准确地评估AI模型性能

Abstract: Comparing AI models to "human level" is often misleading when benchmark scores are incommensurate or human baselines are drawn from a narrow population. To address this, we propose a framework that calibrates items against the 'world population' and report performance on a common, human-anchored scale. Concretely, we build on a set of multi-level scales for different capabilities where each level should represent a probability of success of the whole world population on a logarithmic scale with a base $B$. We calibrate each scale for each capability (reasoning, comprehension, knowledge, volume, etc.) by compiling publicly released human test data spanning education and reasoning benchmarks (PISA, TIMSS, ICAR, UKBioBank, and ReliabilityBench). The base $B$ is estimated by extrapolating between samples with two demographic profiles using LLMs, with the hypothesis that they condense rich information about human populations. We evaluate the quality of different mappings using group slicing and post-stratification. The new techniques allow for the recalibration and standardization of scales relative to the whole-world population.

</details>


### [58] [LoMime: Query-Efficient Membership Inference using Model Extraction in Label-Only Settings](https://arxiv.org/abs/2602.18934)
*Abdullah Caglar Oksuz,Anisa Halimi,Erman Ayday*

Main category: cs.LG

TL;DR: 提出基於可轉移性和模型提取的標籤專屬成員推斷攻擊框架，通過一次性提取代理模型大幅降低查詢成本


<details>
  <summary>Details</summary>
Motivation: 現有成員推斷攻擊依賴不切實際的假設（如公開數據集、影子模型、置信度分數），且容易受到置信度掩碼和對抗正則化等防禦措施的影響。標籤專屬攻擊雖然限制較嚴格，但每個樣本需要大量查詢，成本高昂。

Method: 通過主動採樣、基於擾動的選擇和合成數據查詢目標模型M，提取功能相似的代理模型S，然後在S上進行成員推斷。將查詢開銷轉移到一次性提取階段，消除對M的重複查詢。

Result: 在Purchase、Location和Texas Hospital基準測試中，僅需約1%訓練樣本的查詢預算即可提取S，並實現與M相比±1%的成員推斷準確率。該方法在嚴格黑盒約束下與最先進的標籤專屬MIAs性能相當，同時顯著降低查詢成本。

Conclusion: 提出了一種成本效益高的標籤專屬成員推斷攻擊框架，通過模型提取和可轉移性實現高效攻擊，並評估了標準防禦措施對該攻擊的有效性。

Abstract: Membership inference attacks (MIAs) threaten the privacy of machine learning models by revealing whether a specific data point was used during training. Existing MIAs often rely on impractical assumptions such as access to public datasets, shadow models, confidence scores, or training data distribution knowledge and making them vulnerable to defenses like confidence masking and adversarial regularization. Label-only MIAs, even under strict constraints suffer from high query requirements per sample. We propose a cost-effective label-only MIA framework based on transferability and model extraction. By querying the target model M using active sampling, perturbation-based selection, and synthetic data, we extract a functionally similar surrogate S on which membership inference is performed. This shifts query overhead to a one-time extraction phase, eliminating repeated queries to M . Operating under strict black-box constraints, our method matches the performance of state-of-the-art label-only MIAs while significantly reducing query costs. On benchmarks including Purchase, Location, and Texas Hospital, we show that a query budget equivalent to testing $\approx1\%$ of training samples suffices to extract S and achieve membership inference accuracy within $\pm1\%$ of M . We also evaluate the effectiveness of standard defenses proposed for label-only MIAs against our attack.

</details>


### [59] [Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression](https://arxiv.org/abs/2602.18946)
*Sacchit Kale,Piyushi Manupriya,Pierre Marion,Francis bach,Anant Raj*

Main category: cs.LG

TL;DR: 论文证明梯度下降和随机梯度下降可以通过非自适应递增步长实现指数收敛，无需进入不稳定区域，改进了现有理论。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，在可分离逻辑回归中，通过利用接近稳定性边缘的不稳定区域可以实现加速收敛，但这种方法使优化轨迹变得不稳定且难以分析。作者质疑这种不稳定性是否是实现加速的必要条件。

Method: 提出两种方法：1）梯度下降使用简单的非自适应递增步长计划；2）随机梯度下降使用轻量级自适应步长规则，无需线搜索或专门程序。两种方法都保持在稳定优化区域内。

Result: 证明了在边界条件下，梯度下降的递增步长计划可以实现指数收敛，且始终保持在稳定区域内。随机梯度下降的自适应步长规则也实现了指数收敛，改进了现有的多项式速率保证。

Conclusion: 精心设计的步长增长结构本身就足以实现梯度下降和随机梯度下降的指数加速，无需进入不稳定区域，证明了不稳定性不是加速的必要条件。

Abstract: Gradient descent and stochastic gradient descent are central to modern machine learning, yet their behavior under large step sizes remains theoretically unclear. Recent work suggests that acceleration often arises near the edge of stability, where optimization trajectories become unstable and difficult to analyze. Existing results for separable logistic regression achieve faster convergence by explicitly leveraging such unstable regimes through constant or adaptive large step sizes. In this paper, we show that instability is not inherent to acceleration. We prove that gradient descent with a simple, non-adaptive increasing step-size schedule achieves exponential convergence for separable logistic regression under a margin condition, while remaining entirely within a stable optimization regime. The resulting method is anytime and does not require prior knowledge of the optimization horizon or target accuracy. We also establish exponential convergence of stochastic gradient descent using a lightweight adaptive step-size rule that avoids line search and specialized procedures, improving upon existing polynomial-rate guarantees. Together, our results demonstrate that carefully structured step-size growth alone suffices to obtain exponential acceleration for both gradient descent and stochastic gradient descent.

</details>


### [60] [Toward Manifest Relationality in Transformers via Symmetry Reduction](https://arxiv.org/abs/2602.18948)
*J. François,L. Ravera*

Main category: cs.LG

TL;DR: 提出基于对称性约简的Transformer框架，通过不变关系量重新表述表示、注意力机制和优化动态，消除冗余自由度。


<details>
  <summary>Details</summary>
Motivation: Transformer模型存在大量内部冗余，这些冗余源于坐标依赖表示和连续对称性。现有方法通过显式打破对称性来解决，但本文提出互补的对称性约简框架。

Method: 重新表述表示、注意力机制和优化动态为不变关系量，消除构造中的冗余自由度。提出直接在关系结构上操作的架构。

Result: 建立了几何框架，用于减少参数冗余和分析优化过程。提供了处理Transformer对称性的新视角。

Conclusion: 对称性约简为减少Transformer冗余提供了原则性几何框架，补充了现有对称性打破方法，有助于参数优化分析。

Abstract: Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.

</details>


### [61] [Incremental Transformer Neural Processes](https://arxiv.org/abs/2602.18955)
*Philip Mortimer,Cristiana Diaconu,Tommy Rochussen,Bruno Mlodozeniec,Richard E. Turner*

Main category: cs.LG

TL;DR: 提出Incremental TNP (incTNP)，通过因果掩码、KV缓存和高效自回归训练，在保持标准TNP性能的同时，将序列推理的计算复杂度从二次降至线性


<details>
  <summary>Details</summary>
Motivation: 现有Transformer Neural Processes (TNPs)在处理连续数据流（如实时传感器读数、数据库更新）时，需要为每个新观测从头重新计算内部表示，缺乏增量更新能力，计算成本高

Method: 借鉴大语言模型技术，引入因果掩码确保自回归预测、Key-Value缓存避免重复计算、数据高效的自回归训练策略，实现增量式Transformer Neural Processes

Result: 在合成和真实世界任务（表格回归、温度预测）上，incTNP性能与标准TNPs相当或更好，同时实现数量级的序列推理加速，计算复杂度从二次降至线性

Conclusion: incTNP通过因果掩码获得计算优势，同时保持与标准非因果TNPs相当的隐式贝叶斯一致性，为流式推理提供了高效且一致的解决方案

Abstract: Neural Processes (NPs), and specifically Transformer Neural Processes (TNPs), have demonstrated remarkable performance across tasks ranging from spatiotemporal forecasting to tabular data modelling. However, many of these applications are inherently sequential, involving continuous data streams such as real-time sensor readings or database updates. In such settings, models should support cheap, incremental updates rather than recomputing internal representations from scratch for every new observation -- a capability existing TNP variants lack. Drawing inspiration from Large Language Models, we introduce the Incremental TNP (incTNP). By leveraging causal masking, Key-Value (KV) caching, and a data-efficient autoregressive training strategy, incTNP matches the predictive performance of standard TNPs while reducing the computational cost of updates from quadratic to linear time complexity. We empirically evaluate our model on a range of synthetic and real-world tasks, including tabular regression and temperature prediction. Our results show that, surprisingly, incTNP delivers performance comparable to -- or better than -- non-causal TNPs while unlocking orders-of-magnitude speedups for sequential inference. Finally, we assess the consistency of the model's updates -- by adapting a metric of ``implicit Bayesianness", we show that incTNP retains a prediction rule as implicitly Bayesian as standard non-causal TNPs, demonstrating that incTNP achieves the computational benefits of causal masking without sacrificing the consistency required for streaming inference.

</details>


### [62] [Conditionally Site-Independent Neural Evolution of Antibody Sequences](https://arxiv.org/abs/2602.18982)
*Stephen Zhewen Lu,Aakarsh Vermani,Kohei Sanno,Jiarui Lu,Frederick A Matsen,Milind Jagota,Yun S. Song*

Main category: cs.LG

TL;DR: CoSiNE：一种结合深度学习与系统发育建模的抗体进化模型，通过连续时间马尔可夫链捕获表位相互作用，在零射击变异效应预测中优于现有语言模型，并提出引导采样方案优化抗体亲和力。


<details>
  <summary>Details</summary>
Motivation: 现有抗体工程深度学习方法仅建模序列的边际分布，忽略了亲和力成熟过程中丰富的进化信息；而传统系统发育模型虽能表示进化动态，但缺乏捕捉复杂表位相互作用的能力。需要弥合这一差距。

Method: CoSiNE（Continuous-time Markov chain parameterized by a deep neural network）：用深度神经网络参数化的连续时间马尔可夫链，数学上证明其为一阶近似不可处理的顺序点突变过程，误差界与分支长度平方相关。还提出Guided Gillespie分类器引导采样方案，在推理时引导CoSiNE优化抗体结合亲和力。

Result: CoSiNE在零射击变异效应预测任务中优于最先进的语言模型，通过显式解耦选择与上下文依赖的体细胞超突变。引导采样方案能有效优化抗体对特定抗原的结合亲和力。

Conclusion: CoSiNE成功弥合了深度学习方法与系统发育模型之间的差距，为抗体工程提供了更准确的进化建模框架，并能有效指导抗体亲和力优化。

Abstract: Common deep learning approaches for antibody engineering focus on modeling the marginal distribution of sequences. By treating sequences as independent samples, however, these methods overlook affinity maturation as a rich and largely untapped source of information about the evolutionary process by which antibodies explore the underlying fitness landscape. In contrast, classical phylogenetic models explicitly represent evolutionary dynamics but lack the expressivity to capture complex epistatic interactions. We bridge this gap with CoSiNE, a continuous-time Markov chain parameterized by a deep neural network. Mathematically, we prove that CoSiNE provides a first-order approximation to the intractable sequential point mutation process, capturing epistatic effects with an error bound that is quadratic in branch length. Empirically, CoSiNE outperforms state-of-the-art language models in zero-shot variant effect prediction by explicitly disentangling selection from context-dependent somatic hypermutation. Finally, we introduce Guided Gillespie, a classifier-guided sampling scheme that steers CoSiNE at inference time, enabling efficient optimization of antibody binding affinity toward specific antigens.

</details>


### [63] [Why ReLU? A Bit-Model Dichotomy for Deep Network Training](https://arxiv.org/abs/2602.19017)
*Ilan Doron-Arad,Elchanan Mossel*

Main category: cs.LG

TL;DR: 在有限精度比特模型下，ERM训练复杂度呈现尖锐二分：多项式激活函数导致#P-难，而ReLU等分段线性激活函数保持NP完全


<details>
  <summary>Details</summary>
Motivation: 传统ERM分析基于Real-RAM计算模型，但实际数字计算使用有限精度硬件。需要研究在比特级模型下ERM的理论复杂度，以更贴近实际计算环境

Method: 提出比特级ERM模型，约束网络参数和输入为有理数且比特长度多项式有界。分析不同激活函数下的计算复杂度：证明多项式激活函数导致#P-难，而分段线性激活函数保持NP完全

Result: 发现尖锐的二分现象：多项式激活函数训练比特复杂度严重（#P-难），梯度符号判定困难，单比特梯度确定#P-难；ReLU等分段线性激活函数训练在NP内，标准反向传播多项式时间可解

Conclusion: 有限精度约束不是实现细节，而是可学习性的基本决定因素。激活函数选择对实际训练复杂度有根本性影响，为梯度爆炸/消失现象提供了复杂度理论视角

Abstract: Theoretical analyses of Empirical Risk Minimization (ERM) are standardly framed within the Real-RAM model of computation. In this setting, training even simple neural networks is known to be $\exists \mathbb{R}$-complete -- a complexity class believed to be harder than NP, that characterizes the difficulty of solving systems of polynomial inequalities over the real numbers. However, this algebraic framework diverges from the reality of digital computation with finite-precision hardware. In this work, we analyze the theoretical complexity of ERM under a realistic bit-level model ($\mathsf{ERM}_{\text{bit}}$), where network parameters and inputs are constrained to be rational numbers with polynomially bounded bit-lengths. Under this model, we reveal a sharp dichotomy in tractability governed by the network's activation function. We prove that for deep networks with {\em any} polynomial activations with rational coefficients and degree at least $2$, the bit-complexity of training is severe: deciding $\mathsf{ERM}_{\text{bit}}$ is $\#P$-Hard, hence believed to be strictly harder than NP-complete problems. Furthermore, we show that determining the sign of a single partial derivative of the empirical loss function is intractable (unlikely in BPP), and deciding a specific bit in the gradient is $\#P$-Hard. This provides a complexity-theoretic perspective for the phenomenon of exploding and vanishing gradients. In contrast, we show that for piecewise-linear activations such as ReLU, the precision requirements remain manageable: $\mathsf{ERM}_{\text{bit}}$ is contained within NP (specifically NP-complete), and standard backpropagation runs in polynomial time. Our results demonstrate that finite-precision constraints are not merely implementation details but fundamental determinants of learnability.

</details>


### [64] [Learning to Detect Language Model Training Data via Active Reconstruction](https://arxiv.org/abs/2602.19020)
*Junjie Oscar Yin,John X. Morris,Vitaly Shmatikov,Sewon Min,Hannaneh Hajishirzi*

Main category: cs.LG

TL;DR: 本文提出主动数据重建攻击(ADRA)，一种通过主动训练诱导模型重建文本的成员推理攻击方法，相比传统被动方法显著提升检测效果


<details>
  <summary>Details</summary>
Motivation: 传统成员推理攻击(MIA)被动使用固定模型权重，而训练数据可能比非成员数据更容易被重建，这种可重建性差异可用于改进成员检测

Method: 利用强化学习主动诱导数据重建：通过从目标模型初始化的策略进行微调，设计重建度量和对比奖励，开发ADRA及其自适应变体ADRA+

Result: ADRA方法在检测预训练、后训练和蒸馏数据方面一致优于现有MIA方法，平均提升10.7%，在BookMIA上比Min-K%++提升18.8%

Conclusion: 主动数据重建攻击通过强化学习诱导模型重建训练数据，有效利用训练数据与非成员数据在可重建性上的差异，显著提升成员推理攻击性能

Abstract: Detecting LLM training data is generally framed as a membership inference attack (MIA) problem. However, conventional MIAs operate passively on fixed model weights, using log-likelihoods or text generations. In this work, we introduce \textbf{Active Data Reconstruction Attack} (ADRA), a family of MIA that actively induces a model to reconstruct a given text through training. We hypothesize that training data are \textit{more reconstructible} than non-members, and the difference in their reconstructibility can be exploited for membership inference. Motivated by findings that reinforcement learning (RL) sharpens behaviors already encoded in weights, we leverage on-policy RL to actively elicit data reconstruction by finetuning a policy initialized from the target model. To effectively use RL for MIA, we design reconstruction metrics and contrastive rewards. The resulting algorithms, \textsc{ADRA} and its adaptive variant \textsc{ADRA+}, improve both reconstruction and detection given a pool of candidate data. Experiments show that our methods consistently outperform existing MIAs in detecting pre-training, post-training, and distillation data, with an average improvement of 10.7\% over the previous runner-up. In particular, \MethodPlus~improves over Min-K\%++ by 18.8\% on BookMIA for pre-training detection and by 7.6\% on AIME for post-training detection.

</details>


### [65] [Pushing the Limits of Inverse Lithography with Generative Reinforcement Learning](https://arxiv.org/abs/2602.19027)
*Haoyu Yang,Haoxing Ren*

Main category: cs.LG

TL;DR: 提出混合生成AI与数值ILT的框架，通过条件采样生成多个掩模候选，再经快速ILT精炼，显著提升掩模质量与效率


<details>
  <summary>Details</summary>
Motivation: 传统逆光刻技术（ILT）因高度非凸目标函数易陷入局部最优，现有生成式AI方法多训练确定性图像转换器模仿次优数据集，对逃逸非凸陷阱指导有限

Method: 将掩模合成重构为条件采样问题：生成器学习基于设计条件的掩模分布并提出多个候选；先通过WGAN加重建损失预训练，再用GRPO和ILT引导模仿损失微调；推理时采样小批量掩模，运行快速批处理ILT精炼，评估光刻指标后选择最佳候选

Result: 在LithoBench数据集上，3nm容差下减少EPE违规，吞吐量比强数值ILT基线提升约2倍；在ICCAD13竞赛案例上，EPE改进超20%，速度比SOTA数值ILT求解器快3倍

Conclusion: 通过学习提出ILT友好的初始化，该方法缓解了非凸性问题，超越了传统求解器或生成式AI单独能达到的效果

Abstract: Inverse lithography (ILT) is critical for modern semiconductor manufacturing but suffers from highly non-convex objectives that often trap optimization in poor local minima. Generative AI has been explored to warm-start ILT, yet most approaches train deterministic image-to-image translators to mimic sub-optimal datasets, providing limited guidance for escaping non-convex traps during refinement. We reformulate mask synthesis as conditional sampling: a generator learns a distribution over masks conditioned on the design and proposes multiple candidates. The generator is first pretrained with WGAN plus a reconstruction loss, then fine-tuned using Group Relative Policy Optimization (GRPO) with an ILT-guided imitation loss. At inference, we sample a small batch of masks, run fast batched ILT refinement, evaluate lithography metrics (e.g., EPE, process window), and select the best candidate. On \texttt{LithoBench} dataset, the proposed hybrid framework reduces EPE violations under a 3\,nm tolerance and roughly doubles throughput versus a strong numerical ILT baseline, while improving final mask quality. We also present over 20\% EPE improvement on \texttt{ICCAD13} contest cases with 3$\times$ speedup over the SOTA numerical ILT solver. By learning to propose ILT-friendly initializations, our approach mitigates non-convexity and advances beyond what traditional solvers or GenAI can achieve.

</details>


### [66] [Spectral Phase Encoding for Quantum Kernel Methods](https://arxiv.org/abs/2602.19644)
*Pablo Herrero Gómez,Antonio Jimeno Morenilla,David Muñoz-Hernández,Higinio Mora Mora*

Main category: cs.LG

TL;DR: 量子核方法在数据污染下的鲁棒性分析：提出SPE（谱相位编码）方法，结合DFT前端与对角相位嵌入，在噪声环境下表现优于其他量子变体和经典SVM基线。


<details>
  <summary>Details</summary>
Motivation: 量子核方法在近期量子机器学习中具有前景，但其在数据污染下的行为尚未得到充分理解。需要分析量子特征构造在受控加性噪声下的退化情况，为NISQ时代的量子机器学习提供鲁棒性优先的视角。

Method: 提出谱相位编码（SPE）方法，结合离散傅里叶变换（DFT）前端与对角相位嵌入，与对角量子映射的几何结构对齐。在统一框架下比较QK-DFT与其他量子变体（QK-PCA、QK-RP）和经典SVM基线，使用数据集固定效应回归和wild cluster bootstrap推断量化鲁棒性。

Result: 在量子方法家族中，基于DFT的预处理在噪声增加时表现出最小的退化率，相对于PCA和RP具有统计支持的斜率差异。与经典基线相比，QK-DFT的退化与线性SVM相当，比RBF SVM更稳定。硬件实验证实SPE在执行和数值稳定性方面表现良好。

Conclusion: 量子核的鲁棒性关键取决于结构对齐的预处理及其与对角嵌入的相互作用，这支持了NISQ时代量子机器学习的鲁棒性优先视角。SPE方法在噪声环境下表现出优越的鲁棒性。

Abstract: Quantum kernel methods are promising for near-term quantum ma- chine learning, yet their behavior under data corruption remains insuf- ficiently understood. We analyze how quantum feature constructions degrade under controlled additive noise. We introduce Spectral Phase Encoding (SPE), a hybrid construc- tion combining a discrete Fourier transform (DFT) front-end with a diagonal phase-only embedding aligned with the geometry of diagonal quantum maps. Within a unified framework, we compare QK-DFT against alternative quantum variants (QK-PCA, QK-RP) and classi- cal SVM baselines under identical clean-data hyperparameter selection, quantifying robustness via dataset fixed-effects regression with wild cluster bootstrap inference across heterogeneous real-world datasets. Across the quantum family, DFT-based preprocessing yields the smallest degradation rate as noise increases, with statistically sup- ported slope differences relative to PCA and RP. Compared to classical baselines, QK-DFT shows degradation comparable to linear SVM and more stable than RBF SVM under matched tuning. Hardware exper- iments confirm that SPE remains executable and numerically stable for overlap estimation. These results indicate that robustness in quan- tum kernels depends critically on structure-aligned preprocessing and its interaction with diagonal embeddings, supporting a robustness-first perspective for NISQ-era quantum machine learning.

</details>


### [67] [A Markovian View of Iterative-Feedback Loops in Image Generative Models: Neural Resonance and Model Collapse](https://arxiv.org/abs/2602.19033)
*Vibhas Kumar Vats,David J. Crandall,Samuel Goree*

Main category: cs.LG

TL;DR: 论文提出"神经共振"概念，解释AI训练中反馈过程导致模型崩溃的机制：当反馈过程满足遍历性和潜在表示方向收缩条件时，会收敛到低维不变结构。


<details>
  <summary>Details</summary>
Motivation: AI训练数据集中不可避免地包含AI生成的样本，导致模型输出影响其他模型训练的"反馈"现象。虽然已知这种迭代反馈会导致模型崩溃，但其退化机制仍不清楚，需要深入理解。

Method: 将迭代反馈建模为马尔可夫链，证明神经共振需要两个条件：反馈过程的遍历性和潜在表示的方向收缩。通过在MNIST和ImageNet上的扩散模型、CycleGAN以及音频反馈实验，研究局部和全局流形几何的演化。

Result: 发现了反馈过程收敛到潜在空间低维不变结构的现象（神经共振），并建立了八种崩溃行为的分类体系。通过实验验证了不同模型中的共振现象。

Conclusion: 神经共振为生成模型中长期退化行为提供了统一解释，并为识别、表征和最终缓解模型崩溃提供了实用的诊断工具。

Abstract: AI training datasets will inevitably contain AI-generated examples, leading to ``feedback'' in which the output of one model impacts the training of another. It is known that such iterative feedback can lead to model collapse, yet the mechanisms underlying this degeneration remain poorly understood. Here we show that a broad class of feedback processes converges to a low-dimensional invariant structure in latent space, a phenomenon we call neural resonance. By modeling iterative feedback as a Markov Chain, we show that two conditions are needed for this resonance to occur: ergodicity of the feedback process and directional contraction of the latent representation. By studying diffusion models on MNIST and ImageNet, as well as CycleGAN and an audio feedback experiment, we map how local and global manifold geometry evolve, and we introduce an eight-pattern taxonomy of collapse behaviors. Neural resonance provides a unified explanation for long-term degenerate behavior in generative models and provides practical diagnostics for identifying, characterizing, and eventually mitigating collapse.

</details>


### [68] [Back to Blackwell: Closing the Loop on Intransitivity in Multi-Objective Preference Fine-Tuning](https://arxiv.org/abs/2602.19041)
*Jiahao Zhang,Lujing Zhang,Keltin Grimes,Zhuohao Yu,Gokul Swamy,Zhiwei Steven Wu*

Main category: cs.LG

TL;DR: 该论文提出了一种处理偏好微调中不可传递偏好的新方法，通过最大熵Blackwell获胜者概念和PROSPER算法，在多目标LLM微调中优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 偏好微调面临不可传递偏好的挑战，这些偏好可能源于单一目标的不一致排名或多个目标的标量化。不可传递偏好导致没有明确定义的最优策略，破坏了标准PFT流程的核心假设。

Method: 提出最大熵Blackwell获胜者作为新的博弈论解决方案概念，并推导出PROSPER算法——一种可证明高效的PFT算法，能够直接处理多目标而不需要标量化。

Result: PROSPER在基于多目标LLM-as-a-Judge反馈的大语言模型微调中表现优异，在指令遵循和通用聊天基准测试中均优于所有基线模型，并发布了7B和3B参数的训练模型检查点。

Conclusion: 该研究为解决偏好微调中的不可传递偏好问题提供了有效的博弈论解决方案，PROSPER算法在多目标LLM微调中展现出显著优势，为处理复杂偏好场景提供了新工具。

Abstract: A recurring challenge in preference fine-tuning (PFT) is handling $\textit{intransitive}$ (i.e., cyclic) preferences. Intransitive preferences often stem from either $\textit{(i)}$ inconsistent rankings along a single objective or $\textit{(ii)}$ scalarizing multiple objectives into a single metric. Regardless of their source, the downstream implication of intransitive preferences is the same: there is no well-defined optimal policy, breaking a core assumption of the standard PFT pipeline. In response, we propose a novel, game-theoretic solution concept -- the $\textit{Maximum Entropy Blackwell Winner}$ ($\textit{MaxEntBW}$) -- that is well-defined under multi-objective intransitive preferences. To enable computing MaxEntBWs at scale, we derive $\texttt{PROSPER}$: a provably efficient PFT algorithm. Unlike prior self-play techniques, $\texttt{PROSPER}$ directly handles multiple objectives without requiring scalarization. We then apply $\texttt{PROSPER}$ to the problem of fine-tuning large language models (LLMs) from multi-objective LLM-as-a-Judge feedback (e.g., rubric-based judges), a setting where both sources of intransitivity arise. We find that $\texttt{PROSPER}$ outperforms all baselines considered across both instruction following and general chat benchmarks, releasing trained model checkpoints at the 7B and 3B parameter scales.

</details>


### [69] [IDLM: Inverse-distilled Diffusion Language Models](https://arxiv.org/abs/2602.19066)
*David Li,Nikita Gushchin,Dmitry Abulkhanov,Eric Moulines,Ivan Oseledets,Maxim Panov,Alexander Korotin*

Main category: cs.LG

TL;DR: IDLM通过将连续扩散模型的逆蒸馏技术扩展到离散文本生成，解决了DLMs推理速度慢的问题，实现了4x-64x的加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在文本生成方面表现优秀，但多步采样导致推理速度慢，限制了实际应用。需要找到加速推理的方法。

Method: 将连续扩散模型的逆蒸馏技术扩展到离散设置，通过理论证明逆蒸馏目标存在唯一解，并引入梯度稳定的松弛技术来支持有效训练。

Result: IDLM方法在多个扩散语言模型上实现了4x-64x的推理步骤减少，同时保持了教师模型的熵和生成困惑度。

Conclusion: 提出的IDLM方法成功解决了扩散语言模型推理速度慢的问题，通过理论保证和实用技术实现了高效的加速，为实际应用提供了可行方案。

Abstract: Diffusion Language Models (DLMs) have recently achieved strong results in text generation. However, their multi-step sampling leads to slow inference, limiting practical use. To address this, we extend Inverse Distillation, a technique originally developed to accelerate continuous diffusion models, to the discrete setting. Nonetheless, this extension introduces both theoretical and practical challenges. From a theoretical perspective, the inverse distillation objective lacks uniqueness guarantees, which may lead to suboptimal solutions. From a practical standpoint, backpropagation in the discrete space is non-trivial and often unstable. To overcome these challenges, we first provide a theoretical result demonstrating that our inverse formulation admits a unique solution, thereby ensuring valid optimization. We then introduce gradient-stable relaxations to support effective training. As a result, experiments on multiple DLMs show that our method, Inverse-distilled Diffusion Language Models (IDLM), reduces the number of inference steps by 4x-64x, while preserving the teacher model's entropy and generative perplexity.

</details>


### [70] [TimeRadar: A Domain-Rotatable Foundation Model for Time Series Anomaly Detection](https://arxiv.org/abs/2602.19068)
*Hui He,Hezhe Qiao,Yutong Chen,Kun Yi,Guansong Pang*

Main category: cs.LG

TL;DR: TimeRadar是一个创新的时间序列基础模型，在分数时频域中构建，用于支持跨不同未见数据集的通用时间序列异常检测。


<details>
  <summary>Details</summary>
Motivation: 当前的时间序列基础模型主要关注学习预定义时间或频域中的普遍规律模式，用于监督下游任务（如预测）。然而，对于本质上无监督的下游任务——如时间序列异常检测（旨在识别罕见、不规则模式）——这些模型往往无效。因为异常模式在相同时间/频域中可能与正常模式非常相似。

Method: 1. 提出分数调制时频重建（FTFRecon）组件，利用可学习的分数阶将时间序列旋转到连续时间和频率域之间最显著的角度进行精确数据重建；2. 引入上下文偏差学习（CDL）组件，在可旋转域中建模输入相对于其上下文时间序列数据的局部偏差。

Result: TimeRadar能够在最优时频域中为每个数据输入提供自适应数据重建，从而有效区分来自不同数据集（包括未见数据集）的无限异常模式与常规模式。

Conclusion: 通过在分数时频域中构建时间序列基础模型，TimeRadar能够自适应地区分正常和异常信号，解决了现有模型在时间序列异常检测任务中的局限性，支持跨数据集的通用异常检测。

Abstract: Current time series foundation models (TSFMs) primarily focus on learning prevalent and regular patterns within a predefined time or frequency domain to enable supervised downstream tasks (e.g., forecasting). Consequently, they are often ineffective for inherently unsupervised downstream tasks-such as time series anomaly detection (TSAD), which aims to identify rare, irregular patterns. This limitation arises because such abnormal patterns can closely resemble the regular patterns when presented in the same time/frequency domain. To address this issue, we introduce TimeRadar, an innovative TSFM built in a fractional time-frequency domain to support generalist TSAD across diverse unseen datasets. Our key insight is that rotating a time series into a data-dependent fractional time-frequency representation can adaptively differentiate the normal and abnormal signals across different datasets. To this end, a novel component, namely Fractionally modulated Time-Frequency Reconstruction (FTFRecon), is proposed in TimeRadar to leverage a learnable fractional order to rotate the time series to the most pronounced angle between a continuous time and frequency domain for accurate data reconstruction. This provides adaptive data reconstruction in an optimal time-frequency domain for each data input, enabling effective differentiation of the unbounded abnormal patterns from the regular ones across datasets, including unseen datasets. To allow TimeRadar to model local abnormality that is not captured by the global data reconstruction, we further introduce a Contextual Deviation Learning (CDL) component to model the local deviation of the input relative to its contextual time series data in the rotatable domain.

</details>


### [71] [RKHS Representation of Algebraic Convolutional Filters with Integral Operators](https://arxiv.org/abs/2602.19094)
*Alejandro Parada-Mayorga,Alejandro Ribeiro,Juan Bazerque*

Main category: cs.LG

TL;DR: 该论文建立了积分算子与再生核希尔伯特空间(RKHS)之间的系统联系，展示了积分算子的值域自然地诱导出RKHS卷积信号模型，其再生核由算子符号的盒积决定。


<details>
  <summary>Details</summary>
Motivation: 传统上积分算子通过谱分解进行分析，但在代数信号处理框架中，它们与再生核希尔伯特空间(RKHS)的联系尚未被系统探索。本文旨在填补这一空白，建立积分算子与RKHS之间的理论联系。

Method: 开发了一个综合理论，证明积分算子的值域自然地诱导出RKHS卷积信号模型。通过算子符号的盒积确定再生核，并表征这些诱导RKHS的代数和谱性质。展示了多项式滤波对应于迭代盒积，形成了单位核代数。

Result: 建立了积分算子与RKHS之间的精确联系，提供了通过再生性质实现滤波器的逐点RKHS表示。在graphon信号处理中建立了特征分解与RKHS表示之间的精确连接，自然地扩展到有向graphon，并实现了新颖的空间-谱定位结果。

Conclusion: 该理论为基于积分算子的神经网络架构中的可学习滤波器提供了原则性基础。当谱域是信号原始域的子集时，正则化学习问题的最优滤波器允许有限维RKHS表示，为可学习滤波器提供了数学基础。

Abstract: Integral operators play a central role in signal processing, underpinning classical convolution, and filtering on continuous network models such as graphons. While these operators are traditionally analyzed through spectral decompositions, their connection to reproducing kernel Hilbert spaces (RKHS) has not been systematically explored within the algebraic signal processing framework. In this paper, we develop a comprehensive theory showing that the range of integral operators naturally induces RKHS convolutional signal models whose reproducing kernels are determined by a box product of the operator symbols. We characterize the algebraic and spectral properties of these induced RKHS and show that polynomial filtering with integral operators corresponds to iterated box products, giving rise to a unital kernel algebra. This perspective yields pointwise RKHS representations of filters via the reproducing property, providing an alternative to operator-based implementations. Our results establish precise connections between eigendecompositions and RKHS representations in graphon signal processing, extend naturally to directed graphons, and enable novel spatial--spectral localization results. Furthermore, we show that when the spectral domain is a subset of the original domain of the signals, optimal filters for regularized learning problems admit finite-dimensional RKHS representations, providing a principled foundation for learnable filters in integral-operator-based neural architectures.

</details>


### [72] [The Power of Decaying Steps: Enhancing Attack Stability and Transferability for Sign-based Optimizers](https://arxiv.org/abs/2602.19096)
*Wei Tao,Yang Dai,Jincai Huang,Qing Tao*

Main category: cs.LG

TL;DR: 该论文提出了一种改进对抗样本生成的方法，通过引入单调递减的坐标步长(MDCS)来解决传统符号优化器在收敛性和稳定性方面的问题，显著提高了对抗样本的迁移性和攻击稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前基于符号的优化器（如I-FGSM和MI-FGSM）在对抗样本生成中存在两个主要问题：非收敛性和不稳定性。作者观察到攻击成功率在更多迭代次数时可能急剧下降，这影响了对抗样本的迁移性。因此需要从优化角度解决这些问题。

Method: 将基于符号的优化器重新表述为特定的坐标梯度下降，指出非衰减步长调度是导致问题的主要原因。提出了一系列新的攻击算法，在符号优化器中强制执行单调递减的坐标步长(MDCS)。特别地，提出了MDCS-MI算法，并提供了理论保证证明其达到O(1/√T)的最优收敛率。

Result: 在图像分类和跨模态检索任务上的大量实验表明，该方法不仅显著提高了对抗样本的迁移性，而且与最先进的基于符号方法相比，增强了攻击稳定性。理论分析证明MDCS-MI达到了最优收敛率。

Conclusion: 通过从优化角度重新审视对抗样本生成问题，提出的单调递减坐标步长方法有效解决了传统符号优化器的收敛性和稳定性问题，为对抗攻击提供了更可靠和有效的优化框架。

Abstract: Crafting adversarial examples can be formulated as an optimization problem. While sign-based optimizers such as I-FGSM and MI-FGSM have become the de facto standard for the induced optimization problems, there still exist several unsolved problems in theoretical grounding and practical reliability especially in non-convergence and instability, which inevitably influences their transferability. Contrary to the expectation, we observe that the attack success rate may degrade sharply when more number of iterations are conducted. In this paper, we address these issues from an optimization perspective. By reformulating the sign-based optimizer as a specific coordinate-wise gradient descent, we argue that one cause for non-convergence and instability is their non-decaying step-size scheduling. Based upon this viewpoint, we propose a series of new attack algorithms that enforce Monotonically Decreasing Coordinate-wise Step-sizes (MDCS) within sign-based optimizers. Typically, we further provide theoretical guarantees proving that MDCS-MI attains an optimal convergence rate of $O(1/\sqrt{T})$, where $T$ is the number of iterations. Extensive experiments on image classification and cross-modal retrieval tasks demonstrate that our approach not only significantly improves transferability but also enhances attack stability compared to state-of-the-art sign-based methods.

</details>


### [73] [Learning from Complexity: Exploring Dynamic Sample Pruning of Spatio-Temporal Training](https://arxiv.org/abs/2602.19113)
*Wei Chen,Junle Chen,Yuqian Wu,Yuxuan Liang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: ST-Prune：一种用于时空预测的动态样本剪枝方法，通过智能识别最信息丰富的样本来加速训练收敛，在保持或提升模型性能的同时显著提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 时空预测领域的大规模数据集通常包含大量冗余样本，传统方法在整个静态数据集上迭代训练会浪费大量计算资源在易学习或重复样本上。现有解决方案主要关注模型架构或优化器优化，而忽视了训练数据本身的低效性。

Method: 提出ST-Prune方法，基于模型实时学习状态动态剪枝样本，智能识别最信息丰富的样本。通过动态样本剪枝技术，加速模型收敛并提高训练效率。

Result: 在真实世界时空数据集上的大量实验表明，ST-Prune显著加速了训练速度，同时保持甚至提高了模型性能。该方法还具有可扩展性和通用性。

Conclusion: ST-Prune为时空预测提供了一种新颖的训练效率提升方法，通过动态样本剪枝有效解决了大规模冗余数据集带来的计算瓶颈问题，在保持性能的同时显著加速训练过程。

Abstract: Spatio-temporal forecasting is fundamental to intelligent systems in transportation, climate science, and urban planning. However, training deep learning models on the massive, often redundant, datasets from these domains presents a significant computational bottleneck. Existing solutions typically focus on optimizing model architectures or optimizers, while overlooking the inherent inefficiency of the training data itself. This conventional approach of iterating over the entire static dataset each epoch wastes considerable resources on easy-to-learn or repetitive samples. In this paper, we explore a novel training-efficiency techniques, namely learning from complexity with dynamic sample pruning, ST-Prune, for spatio-temporal forecasting. Through dynamic sample pruning, we aim to intelligently identify the most informative samples based on the model's real-time learning state, thereby accelerating convergence and improving training efficiency. Extensive experiments conducted on real-world spatio-temporal datasets show that ST-Prune significantly accelerates the training speed while maintaining or even improving the model performance, and it also has scalability and universality.

</details>


### [74] [Robust Predictive Uncertainty and Double Descent in Contaminated Bayesian Random Features](https://arxiv.org/abs/2602.19126)
*Michele Caprio,Katerina Papagiannouli,Siu Lun Chau,Sayan Mukherjee*

Main category: cs.LG

TL;DR: 该论文提出了一种鲁棒的贝叶斯随机特征回归框架，通过Huber式污染集显式处理先验和似然误设，推导出可计算的后验预测密度界限，并引入不精确最高密度区域用于鲁棒预测不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯随机特征回归假设高斯先验和似然，但在实际应用中存在先验和似然误设问题。需要一种鲁棒框架来显式处理这些误设，同时保持计算可处理性。

Method: 使用ε-和η-污染信度集替换单一先验和似然，通过悲观广义贝叶斯更新进行推断。推导后验预测密度的显式可计算界限，引入不精确最高密度区域(IHDR)用于鲁棒不确定性量化。

Result: 当污染适度时，先验和似然模糊性直接转化为后验预测分布的污染，产生围绕经典高斯预测的不确定性包络。IHDR可通过调整的高斯可信区间高效外近似，预测方差界限保持随机特征模型的比例增长渐近性。

Conclusion: 该研究建立了贝叶斯随机特征的鲁棒性理论：预测不确定性保持计算可处理性，继承经典双下降相位结构，并在有界先验和似然误设下获得显式最坏情况保证。

Abstract: We propose a robust Bayesian formulation of random feature (RF) regression that accounts explicitly for prior and likelihood misspecification via Huber-style contamination sets. Starting from the classical equivalence between ridge-regularized RF training and Bayesian inference with Gaussian priors and likelihoods, we replace the single prior and likelihood with $ε$- and $η$-contaminated credal sets, respectively, and perform inference using pessimistic generalized Bayesian updating. We derive explicit and tractable bounds for the resulting lower and upper posterior predictive densities. These bounds show that, when contamination is moderate, prior and likelihood ambiguity effectively acts as a direct contamination of the posterior predictive distribution, yielding uncertainty envelopes around the classical Gaussian predictive. We introduce an Imprecise Highest Density Region (IHDR) for robust predictive uncertainty quantification and show that it admits an efficient outer approximation via an adjusted Gaussian credible interval. We further obtain predictive variance bounds (under a mild truncation approximation for the upper bound) and prove that they preserve the leading-order proportional-growth asymptotics known for RF models. Together, these results establish a robustness theory for Bayesian random features: predictive uncertainty remains computationally tractable, inherits the classical double-descent phase structure, and is improved by explicit worst-case guarantees under bounded prior and likelihood misspecification.

</details>


### [75] [Detecting labeling bias using influence functions](https://arxiv.org/abs/2602.19130)
*Frida Jørgensen,Nina Weng,Siavash Bigdeli*

Main category: cs.LG

TL;DR: 本文研究如何利用影响函数检测数据标注偏见，通过在MNIST和CheXpert数据集上实验，证明影响函数能有效识别错误标注样本。


<details>
  <summary>Details</summary>
Motivation: 标注偏见源于数据收集过程中的资源限制或无意识偏见，导致不同子组的标签错误率不均或子组代表性失真。现有公平性约束通常假设训练标签反映真实分布，在标注偏见存在时失效，因此需要检测标注偏见的方法。

Method: 使用影响函数检测标注偏见，影响函数通过损失函数的梯度和Hessian矩阵估计每个训练样本对模型预测的影响。开发了样本评估流程，在MNIST和CheXpert数据集上测试，通过翻转20%的某类标签引入可控错误，使用对角Hessian近似进行计算。

Result: 在MNIST数据集上成功检测出近90%的错误标注样本；在更复杂的CheXpert医学影像数据集上，错误标注样本始终表现出更高的影响分数，验证了影响函数识别标签错误的潜力。

Conclusion: 影响函数在检测标注偏见方面具有潜力，能够有效识别训练集中的错误标注样本，为解决标注偏见问题提供了有前景的技术途径。

Abstract: Labeling bias arises during data collection due to resource limitations or unconscious bias, leading to unequal label error rates across subgroups or misrepresentation of subgroup prevalence. Most fairness constraints assume training labels reflect the true distribution, rendering them ineffective when labeling bias is present; leaving a challenging question, that \textit{how can we detect such labeling bias?} In this work, we investigate whether influence functions can be used to detect labeling bias. Influence functions estimate how much each training sample affects a model's predictions by leveraging the gradient and Hessian of the loss function -- when labeling errors occur, influence functions can identify wrongly labeled samples in the training set, revealing the underlying failure mode. We develop a sample valuation pipeline and test it first on the MNIST dataset, then scaled to the more complex CheXpert medical imaging dataset. To examine label noise, we introduced controlled errors by flipping 20\% of the labels for one class in the dataset. Using a diagonal Hessian approximation, we demonstrated promising results, successfully detecting nearly 90\% of mislabeled samples in MNIST. On CheXpert, mislabeled samples consistently exhibit higher influence scores. These results highlight the potential of influence functions for identifying label errors.

</details>


### [76] [Test-Time Learning of Causal Structure from Interventional Data](https://arxiv.org/abs/2602.19131)
*Wei Chen,Rui Ding,Bojun Huang,Yang Zhang,Qiang Fu,Yuxuan Liang,Han Shi,Dongmei Zhang*

Main category: cs.LG

TL;DR: TICL提出了一种结合测试时训练与联合因果推理的新方法，通过自增强策略生成实例特定的训练数据，有效解决因果发现中的泛化问题


<details>
  <summary>Details</summary>
Motivation: 监督因果学习在跨不同干预设置时泛化能力有限，特别是在干预目标未知的情况下，需要解决分布偏移问题

Method: 结合测试时训练与联合因果推理，设计自增强策略在测试时生成实例特定训练数据，并采用PC启发的两阶段监督学习方案

Result: 在bnlearn基准测试上的广泛实验表明，TICL在因果发现和干预目标检测的多个方面具有优越性

Conclusion: TICL通过测试时训练与联合因果推理的协同作用，有效解决了监督因果学习的泛化问题，为未知干预目标下的因果发现提供了有效解决方案

Abstract: Supervised causal learning has shown promise in causal discovery, yet it often struggles with generalization across diverse interventional settings, particularly when intervention targets are unknown. To address this, we propose TICL (Test-time Interventional Causal Learning), a novel method that synergizes Test-Time Training with Joint Causal Inference. Specifically, we design a self-augmentation strategy to generate instance-specific training data at test time, effectively avoiding distribution shifts. Furthermore, by integrating joint causal inference, we developed a PC-inspired two-phase supervised learning scheme, which effectively leverages self-augmented training data while ensuring theoretical identifiability. Extensive experiments on bnlearn benchmarks demonstrate TICL's superiority in multiple aspects of causal discovery and intervention target detection.

</details>


### [77] [Celo2: Towards Learned Optimization Free Lunch](https://arxiv.org/abs/2602.19142)
*Abhinav Moudgil,Boris Knyazev,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出了一种简单归一化的优化器架构，仅用4.5 GPU小时就能训练出性能优异的通用学习优化器，相比之前需要4000 TPU月的VeLO大幅降低了计算成本，并能稳定扩展到十亿参数规模的预训练任务。


<details>
  <summary>Details</summary>
Motivation: 学习优化器作为手工设计优化规则（如Adam）的强大替代品，在实际应用中受到限制，因为它们往往无法超越训练分布进行元泛化，且元训练成本高昂。例如，之前的VeLO工作花费了4000 TPU月（约10倍GPT-3计算量）来元训练通用优化器，但无法泛化到6亿参数以上的任务。

Method: 设计简单的归一化优化器架构，并增强元训练过程。该方法与现代优化框架兼容，包括正交化、输入输出权重与隐藏权重的不同更新规则，以及解耦权重衰减。

Result: 仅用4.5 GPU小时（相比VeLO大幅降低）就能元训练出性能优异的通用学习更新规则。该规则能稳定扩展到十亿参数规模的预训练任务（GPT-3 XL 1.3B），这比其元训练分布大了六个数量级。在多样化的分布外任务上表现出强大性能。

Conclusion: 这项工作为实际可应用的学习优化算法铺平了道路，解锁了更丰富的元训练和数据管理方法的探索，以进一步提升性能。

Abstract: Learned optimizers are powerful alternatives to hand-designed update rules like Adam, yet they have seen limited practical adoption since they often fail to meta-generalize beyond their training distribution and incur high meta-training cost. For instance, prior work, VeLO, scaled meta-training to 4,000 TPU months ($\sim$10$\times$ GPT-3 compute) to meta-train a general-purpose optimizer but it failed to generalize beyond 600M parameters tasks. In this work, we present a surprising finding: by crafting a simple normalized optimizer architecture and augmenting meta-training, it becomes feasible to meta-train a performant general-purpose learned update rule on a tiny fraction of VeLO compute, 4.5 GPU hours to be precise. Our learned update rule scales stably to a billion-scale pretraining task (GPT-3 XL 1.3B) which is six orders of magnitude larger than its meta-training distribution. Furthermore, it shows strong performance across diverse out-of-distribution tasks and is compatible with modern optimization harness that includes orthogonalization, distinct update rules for input-output and hidden weights, and decoupled weight decay. In all, this work paves the way for practically applicable learnable optimization algorithms, unlocking exploration of richer meta-training and data curation recipes to further improve performance.

</details>


### [78] [Incremental Learning of Sparse Attention Patterns in Transformers](https://arxiv.org/abs/2602.19143)
*Oğuz Kaan Yüksel,Rodrigo Alvarez Lucendo,Nicolas Flammarion*

Main category: cs.LG

TL;DR: Transformer学习高阶马尔可夫链任务时呈现阶段性学习：从竞争性学习（注意力头收敛于统计主导模式）转向合作性学习（注意力头专门化不同模式），通过简化微分方程建模并证明阶段性收敛，揭示了Transformer通过更简单的错误指定假设类逐步提升复杂性的阶梯式学习过程。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer如何学习整合来自多个历史位置且具有不同统计显著性的信息，理解其阶段性学习动态和复杂行为的涌现机制，为自然语言处理和算法推理中的泛化提供理论基础。

Method: 引入高阶马尔可夫链任务，通过稀疏注意力模式分析Transformer的学习过程，使用简化微分方程建模学习动态，证明阶段性收敛结果，并研究早期停止作为隐式正则化器的作用。

Result: Transformer以增量方式学习该任务，每个阶段通过稀疏注意力模式获取特定信息；学习动态从竞争性转向合作性；模型通过更简单的错误指定假设类逐步提升复杂性；早期停止作为隐式正则化器偏向这些更简单的类。

Conclusion: 该研究为Transformer中阶段性学习和复杂行为的涌现提供了理论基础，揭示了Transformer通过逐步提升复杂性的阶梯式学习过程，对理解NLP和算法推理中的泛化机制具有重要意义。

Abstract: This paper introduces a high-order Markov chain task to investigate how transformers learn to integrate information from multiple past positions with varying statistical significance. We demonstrate that transformers learn this task incrementally: each stage is defined by the acquisition of specific information through sparse attention patterns. Notably, we identify a shift in learning dynamics from competitive, where heads converge on the most statistically dominant pattern, to cooperative, where heads specialize in distinct patterns. We model these dynamics using simplified differential equations that characterize the trajectory and prove stage-wise convergence results. Our analysis reveals that transformers ascend a complexity ladder by passing through simpler, misspecified hypothesis classes before reaching the full model class. We further show that early stopping acts as an implicit regularizer, biasing the model toward these simpler classes. These results provide a theoretical foundation for the emergence of staged learning and complex behaviors in transformers, offering insights into generalization for natural language processing and algorithmic reasoning.

</details>


### [79] [Virtual Parameter Sharpening: Dynamic Low-Rank Perturbations for Inference-Time Reasoning Enhancement](https://arxiv.org/abs/2602.19169)
*Saba Kublashvili*

Main category: cs.LG

TL;DR: VPS是一种推理时技术，通过动态的低秩扰动增强冻结的Transformer线性层，实现无需参数更新的测试时自适应。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（如LoRA）学习静态的低秩适配器，无法在推理时动态适应不同输入。VPS旨在通过激活条件化的动态扰动，在保持模型参数冻结的同时实现测试时自适应。

Method: VPS基于批次激活统计和可选梯度信号，动态构建低秩扰动ΔW = γ * W^T V U^T W。使用稀疏激活引导选择或Sylvester耦合回归构建选择矩阵U和V，并采用基于激活能量和令牌级熵的自适应策略系统来调节扰动幅度。

Result: 论文提供了扰动谱特性的理论分析，描述了完整的算法框架，并讨论了激活条件化计算如何增强大语言模型的推理能力。实现代码已开源。

Conclusion: VPS为冻结Transformer模型提供了一种无需参数更新的推理时自适应方法，通过动态低秩扰动增强模型性能，为激活条件化计算在大语言模型中的应用提供了新思路。

Abstract: I introduce Virtual Parameter Sharpening (VPS), an inference-time technique that augments frozen transformer linear layers with dynamic, activation-conditioned low-rank perturbations. Unlike parameter-efficient fine-tuning methods such as LoRA, which learn static low-rank adapters, VPS constructs its perturbation factors on the fly from batch activation statistics and optional gradient signals, enabling test-time adaptation without persistent parameter updates. The perturbation takes the form Delta W = gamma * W^T V U^T W, where selector matrices U and V are constructed via sparse activation-guided selection or Sylvester-coupled regression. We provide a theoretical analysis of the perturbation's spectral properties and describe an adaptive policy system that modulates perturbation magnitude based on activation energy and token-level entropy. This system incorporates multi-objective verification with iterative refinement for tasks with ground-truth supervision. We present the complete algorithmic framework, analyze its mathematical foundations, and discuss the mechanisms by which activation-conditioned computation may enhance reasoning capabilities in large language models. Implementation and experimental code are available at https://github.com/Saba-Kublashvili/vps-virtual-parameter-synthesis .

</details>


### [80] [Online Realizable Regression and Applications for ReLU Networks](https://arxiv.org/abs/2602.19172)
*Ilan Doron-Arad,Idan Mehalel,Elchanan Mossel*

Main category: cs.LG

TL;DR: 论文提出了一种通用的势能方法，通过Dudley型熵积分上界在线回归的Littlestone维度，证明多项式度量熵可保证有限累积损失。


<details>
  <summary>Details</summary>
Motivation: 研究在线回归在对抗性模型下的可实现性，特别是当损失函数满足近似三角不等式时。现有研究表明最小最大可实现累积损失由缩放Littlestone维度表征，但该量难以分析。

Method: 提出通用的势能方法，将在线维度上界为具体的Dudley型熵积分，仅依赖于假设类在诱导sup伪度量下的覆盖数。定义熵势能Φ(ℋ)=∫₀^{diam(ℋ)} log N(ℋ,ε) dε。

Result: 对于每个c-近似伪度量损失，证明𝔻_onl(ℋ) ≤ O(c)Φ(ℋ)。多项式度量熵意味着Φ(ℋ)<∞，从而获得具有透明维度依赖的无限视野可实现累积损失界。

Conclusion: 该方法为分析在线回归提供了实用工具，在两类问题上展示了应用：证明了Lipschitz回归的q-vs-d二分法，以及有界范数k-ReLU网络的回归与分类分离。

Abstract: Realizable online regression can behave very differently from online classification. Even without any margin or stochastic assumptions, realizability may enforce horizon-free (finite) cumulative loss under metric-like losses, even when the analogous classification problem has an infinite mistake bound. We study realizable online regression in the adversarial model under losses that satisfy an approximate triangle inequality (approximate pseudo-metrics). Recent work of Attias et al. shows that the minimax realizable cumulative loss is characterized by the scaled Littlestone/online dimension $\mathbb{D}_{\mathrm{onl}}$, but this quantity can be difficult to analyze.
  Our main contribution is a generic potential method that upper bounds $\mathbb{D}_{\mathrm{onl}}$ by a concrete Dudley-type entropy integral that depends only on covering numbers of the hypothesis class under the induced sup pseudo-metric. We define an \emph{entropy potential} $Φ(\mathcal{H})=\int_{0}^{diam(\mathcal{H})} \log N(\mathcal{H},\varepsilon)\,d\varepsilon$, where $N(\mathcal{H},\varepsilon)$ is the $\varepsilon$-covering number of $\mathcal{H}$, and show that for every $c$-approximate pseudo-metric loss, $\mathbb{D}_{\mathrm{onl}}(\mathcal{H})\le O(c)\,Φ(\mathcal{H})$. In particular, polynomial metric entropy implies $Φ(\mathcal{H})<\infty$ and hence a horizon-free realizable cumulative-loss bound with transparent dependence on effective dimension.
  We illustrate the method on two families. We prove a sharp $q$-vs.-$d$ dichotomy for realizable online learning (finite and efficiently achievable $Θ_{d,q}(L^d)$ total loss for $L$-Lipschitz regression iff $q>d$, otherwise infinite), and for bounded-norm $k$-ReLU networks separate regression (finite loss, even $\widetilde O(k^2)$, and $O(1)$ for one ReLU) from classification (impossible already for $k=2,d=1$).

</details>


### [81] [Adaptive Problem Generation via Symbolic Representations](https://arxiv.org/abs/2602.19187)
*Teresa Yeo,Myeongho Jeon,Dulaj Weerakoon,Rui Qiao,Alok Prakash,Armando Solar-Lezama,Archan Misra*

Main category: cs.LG

TL;DR: 提出一种为强化学习生成可验证奖励训练数据的方法，通过符号空间表示和闭环框架改进小型开源语言模型的数学任务能力


<details>
  <summary>Details</summary>
Motivation: 现有数据生成方法依赖开环流水线和固定修改，无法适应模型能力，且通常在文字问题上直接操作，限制了问题结构的控制

Method: 1) 在符号问题空间进行修改，将问题表示为符号变量和约束集合；2) 引入闭环框架，通过符号空间中的提示优化学习修改策略，以适应模型难度

Result: 实验结果表明，自适应问题生成和符号表示修改都有助于提高模型的数学解题能力，并能产生更多样化的生成结果

Conclusion: 符号空间表示和闭环自适应框架为改进小型语言模型的数学能力提供了有效的数据生成方法，实现了对问题结构的精确控制和自动生成真实解

Abstract: We present a method for generating training data for reinforcement learning with verifiable rewards to improve small open-weights language models on mathematical tasks. Existing data generation approaches rely on open-loop pipelines and fixed modifications that do not adapt to the model's capabilities. Furthermore, they typically operate directly on word problems, limiting control over problem structure. To address this, we perform modifications in a symbolic problem space, representing each problem as a set of symbolic variables and constraints (e.g., via algebraic frameworks such as SymPy or SMT formulations). This representation enables precise control over problem structure, automatic generation of ground-truth solutions, and decouples mathematical reasoning from linguistic realization. We also show that this results in more diverse generations. To adapt the problem difficulty to the model, we introduce a closed-loop framework that learns modification strategies through prompt optimization in symbolic space. Experimental results demonstrate that both adaptive problem generation and symbolic representation modifications contribute to improving the model's math solving ability.

</details>


### [82] [HybridFL: A Federated Learning Approach for Financial Crime Detection](https://arxiv.org/abs/2602.19207)
*Afsana Khan,Marijn ten Thij,Guangzhi Tang,Anna Wilbik*

Main category: cs.LG

TL;DR: 提出混合联邦学习(HybridFL)解决数据同时水平和垂直分割的场景，在金融犯罪检测中整合交易方和银行的特征，实现隐私保护的联合学习


<details>
  <summary>Details</summary>
Motivation: 现实场景中数据分布复杂，既有水平分割（不同用户）又有垂直分割（不同特征集），传统联邦学习只处理单一分割方式，需要新方法处理混合数据分布

Method: 提出混合联邦学习架构，整合水平聚合和垂直特征融合，在金融犯罪检测场景中，交易方持有交易级特征，银行持有账户级特征，通过隐私保护方式联合训练

Result: 在AMLSim和SWIFT数据集上的实验表明，HybridFL显著优于仅使用交易数据的本地模型，性能接近集中式基准模型

Conclusion: HybridFL能有效处理混合数据分割场景，在严格保护数据隐私的前提下实现高性能的联合学习，在金融犯罪检测等实际应用中具有重要价值

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm that enables multiple parties to collaboratively train models on privately owned data without sharing raw information. While standard FL typically addresses either horizontal or vertical data partitions, many real-world scenarios exhibit a complex hybrid distribution. This paper proposes Hybrid Federated Learning (HybridFL) to address data split both horizontally across disjoint users and vertically across complementary feature sets. We evaluate HybridFL in a financial crime detection context, where a transaction party holds transaction-level attributes and multiple banks maintain private account-level features. By integrating horizontal aggregation and vertical feature fusion, the proposed architecture enables joint learning while strictly preserving data locality. Experiments on AMLSim and SWIFT datasets demonstrate that HybridFL significantly outperforms the transaction-only local model and achieves performance comparable to a centralized benchmark.

</details>


### [83] [How to Allocate, How to Learn? Dynamic Rollout Allocation and Advantage Modulation for Policy Optimization](https://arxiv.org/abs/2602.19208)
*Yangyi Fang,Jiaye Lin,Xiaoliang Fu,Cong Qin,Haolin Shi,Chaowen Hu,Lu Pan,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: DynaMO：针对LLM推理的强化学习框架，通过序列级方差最小化分配和令牌级梯度感知优势调制，解决均匀分配和梯度衰减问题，在数学推理基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于可验证奖励的强化学习（RLVR）方法存在两个关键问题：1）均匀的rollout分配忽略了不同问题间梯度方差的异质性；2）softmax策略结构导致高置信度正确动作的梯度衰减，而过度的梯度更新可能破坏训练稳定性。

Method: 提出DynaMO双管齐下的优化框架：1）序列级：证明均匀分配是次优的，从第一性原理推导出方差最小化分配，将伯努利方差作为梯度信息量的可计算代理；2）令牌级：基于梯度幅度界限的理论分析，开发梯度感知优势调制，补偿高置信度正确动作的梯度衰减，同时利用熵变化作为可计算指标来稳定过度更新幅度。

Result: 在多种数学推理基准上进行广泛实验，结果显示DynaMO相比强大的RLVR基线方法取得了持续改进。

Conclusion: DynaMO通过理论驱动的序列级分配优化和令牌级梯度调制，有效解决了RLVR中的资源分配和策略优化动态问题，为LLM推理任务提供了更高效稳定的强化学习框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for Large Language Model (LLM) reasoning, yet current methods face key challenges in resource allocation and policy optimization dynamics: (i) uniform rollout allocation ignores gradient variance heterogeneity across problems, and (ii) the softmax policy structure causes gradient attenuation for high-confidence correct actions, while excessive gradient updates may destabilize training. Therefore, we propose DynaMO, a theoretically-grounded dual-pronged optimization framework. At the sequence level, we prove that uniform allocation is suboptimal and derive variance-minimizing allocation from the first principle, establishing Bernoulli variance as a computable proxy for gradient informativeness. At the token level, we develop gradient-aware advantage modulation grounded in theoretical analysis of gradient magnitude bounds. Our framework compensates for gradient attenuation of high-confidence correct actions while utilizing entropy changes as computable indicators to stabilize excessive update magnitudes. Extensive experiments conducted on a diverse range of mathematical reasoning benchmarks demonstrate consistent improvements over strong RLVR baselines. Our implementation is available at: \href{https://anonymous.4open.science/r/dynamo-680E/README.md}{https://anonymous.4open.science/r/dynamo}.

</details>


### [84] [Understanding Empirical Unlearning with Combinatorial Interpretability](https://arxiv.org/abs/2602.19215)
*Shingo Kodama,Niv Cohen,Micah Adler,Nir Shavit*

Main category: cs.LG

TL;DR: 该研究在组合可解释性框架下分析知识遗忘方法，发现看似被遗忘的知识往往仍然存在，并可通过微调恢复。


<details>
  <summary>Details</summary>
Motivation: 当前的知识遗忘方法虽然声称能移除预训练模型中的知识，但这些知识往往以各种方式持续存在并可被恢复。由于大型基础模型难以解释，理解知识是否以及如何持续存在是一个重要挑战。

Method: 采用组合可解释性框架（专为两层神经网络设计），在该框架内复现基线遗忘方法，从两个维度分析：1）是否真正移除了目标概念知识，还是仅仅抑制其表达而保留底层信息；2）通过不同微调操作恢复"被遗忘"知识的难易程度。

Result: 研究结果在完全可解释的设置下揭示了知识如何在遗忘后仍然持续存在，以及在什么情况下可能重新浮现。

Conclusion: 知识遗忘方法往往不能真正移除知识，而只是抑制其表达，这些知识仍然存在于模型权重中，并可通过微调操作恢复。

Abstract: While many recent methods aim to unlearn or remove knowledge from pretrained models, seemingly erased knowledge often persists and can be recovered in various ways. Because large foundation models are far from interpretable, understanding whether and how such knowledge persists remains a significant challenge. To address this, we turn to the recently developed framework of combinatorial interpretability. This framework, designed for two-layer neural networks, enables direct inspection of the knowledge encoded in the model weights. We reproduce baseline unlearning methods within the combinatorial interpretability setting and examine their behavior along two dimensions: (i) whether they truly remove knowledge of a target concept (the concept we wish to remove) or merely inhibit its expression while retaining the underlying information, and (ii) how easily the supposedly erased knowledge can be recovered through various fine-tuning operations. Our results shed light within a fully interpretable setting on how knowledge can persist despite unlearning and when it might resurface.

</details>


### [85] [Evaluating SAP RPT-1 for Enterprise Business Process Prediction: In-Context Learning vs. Traditional Machine Learning on Structured SAP Data](https://arxiv.org/abs/2602.19237)
*Amit Lal*

Main category: cs.LG

TL;DR: 本文对SAP的RPT-1表格基础模型进行了首次独立评估，发现该64.6MB模型在零样本情况下能达到调优GBDT模型91-96%的准确率，在小样本场景下（75-100行）甚至能超越XGBoost。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型旨在降低企业数据的机器学习门槛，无需任务特定训练。本文从实践者角度首次独立评估SAP的RPT-1模型，验证其在真实业务场景中的实用性。

Method: 在三个SAP业务场景（需求预测、数据完整性预测、财务风险分类）上，使用五折交叉验证，将RPT-1与调优的梯度提升决策树（XGBoost、LightGBM、CatBoost）进行对比评估。数据集规模为2,500-3,200行。

Result: RPT-1在零训练样本情况下达到调优GBDT准确率的91-96%。分类任务差距较小（AUC-ROC差距3.6-4.1个百分点），回归任务差距较大（R²差距8.9-11.1个百分点）。有趣的是，在约75-100行的小样本场景下，RPT-1甚至能超越XGBoost。

Conclusion: 提出实用混合工作流：使用RPT-1进行快速筛选，然后在预测精度值得投入的场景下有选择性地训练GBDT。所有实验通过公开的Hugging Face Spaces可复现。

Abstract: Tabular foundation models aim to make machine learning accessible for enterprise data without task-specific training. This paper presents the first independent evaluation of SAP's Retrieval Pretrained Transformer (RPT-1) from a practitioner perspective. RPT-1 is a compact 64.6 MB model pretrained on 1.34 TB of structured data across 3.1 million tables. We benchmark it against tuned gradient-boosted decision trees (XGBoost, LightGBM, CatBoost) on three SAP business scenarios: demand forecasting across SD/MM/PP modules, predictive data integrity in BC/MM/QM, and financial risk classification in FI/CO/AR. Across five-fold cross-validation on datasets ranging from 2,500 to 3,200 rows, RPT-1 reaches 91-96% of tuned GBDT accuracy without any training examples. The classification gap is modest at 3.6-4.1 percentage points on AUC-ROC, though regression tasks show wider gaps of 8.9-11.1 percentage points on R-squared. An interesting finding is a crossover at roughly 75-100 context rows where RPT-1 actually outperforms XGBoost under limited data. Based on these results, we propose a practical hybrid workflow: use RPT-1 for rapid screening, then train GBDT selectively where prediction accuracy justifies the effort. All experiments are reproducible through publicly available Hugging Face Spaces.

</details>


### [86] [Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems](https://arxiv.org/abs/2602.19253)
*Qusai Khaled,Uzay Kaymak,Laura Genga*

Main category: cs.LG

TL;DR: X-ANFIS：一种交替双目标梯度优化方案，用于可解释自适应神经模糊推理系统，在保持预测准确性的同时实现目标可区分性，并能恢复超出MOO帕累托前沿凸包的解决方案。


<details>
  <summary>Details</summary>
Motivation: 模糊系统因其基于规则的结构和语言变量在可解释AI中具有强大潜力。现有方法要么通过计算昂贵的进化多目标优化（MOO）来权衡准确性与可解释性，要么使用基于梯度的标量化方法，但后者无法恢复非凸帕累托区域。

Method: 提出X-ANFIS，一种交替双目标梯度优化方案，使用柯西隶属函数实现语义控制初始化下的稳定训练，引入可微分的可解释性目标，并通过交替梯度传递将其与性能目标解耦。

Result: 在9个UCI回归数据集上进行了约5,000次实验验证，X-ANFIS始终实现目标可区分性，同时保持有竞争力的预测准确性，能够恢复超出MOO帕累托前沿凸包的解决方案。

Conclusion: X-ANFIS提供了一种有效的梯度优化方法，解决了模糊系统中准确性与可解释性的权衡问题，超越了现有方法的限制，为可解释AI提供了实用解决方案。

Abstract: Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.

</details>


### [87] [DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation](https://arxiv.org/abs/2602.19261)
*Aleksei Liuliakov,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: DGPO提出了一种用于有向无环图（DAG）的强化学习微调方法，通过拓扑节点排序和位置编码扩展离散图扩散模型，在NAS基准测试中达到最优性能，并展示了可迁移的结构先验。


<details>
  <summary>Details</summary>
Motivation: 现有图扩散方法主要针对无向图设计，而神经架构等组合结构是有向无环图（DAG），边的方向编码了重要的功能语义（如数据流信息），现有方法丢弃了这些方向信息。

Method: 提出Directed Graph Policy Optimization (DGPO)，通过拓扑节点排序和位置编码，将强化学习对离散图扩散模型的微调扩展到有向无环图。该方法能够处理DAG的方向性，实现可控生成。

Result: 在NAS-Bench-101和NAS-Bench-201上验证，DGPO在NAS-Bench-201的所有三个任务上都匹配了基准最优（91.61%, 73.49%, 46.77%）。模型仅用7%搜索空间预训练后，经过微调就能生成接近最优的架构，与全数据模型相差仅0.32个百分点，并超出其训练上限7.3个百分点。

Conclusion: 强化学习引导的离散扩散方法在扩展到处理方向性后，为有向组合结构提供了一个可控的生成框架。模型学习到了可迁移的结构先验，能够实现真正的奖励驱动控制。

Abstract: Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.

</details>


### [88] [Spectral bias in physics-informed and operator learning: Analysis and mitigation guidelines](https://arxiv.org/abs/2602.19265)
*Siavash Khodakarami,Vivek Oommen,Nazanin Ahmadi Daryakenari,Maxim Beekenkamp,George Em Karniadakis*

Main category: cs.LG

TL;DR: 该论文系统研究了物理信息神经网络和算子学习中的谱偏差现象，发现谱偏差不仅是表示限制，更是优化动力学问题，二阶优化方法能显著改善高频模式学习。


<details>
  <summary>Details</summary>
Motivation: 虽然神经网络求解PDE时存在谱偏差（低频成分学习快于高频）是已知现象，但通常被视为神经架构的内在表示限制。然而，谱偏差与优化动力学和物理损失公式的相互作用仍不清楚，需要系统研究。

Method: 使用频率解析误差度量、Barron范数诊断和高阶统计矩量化谱偏差；在椭圆、双曲和色散PDE上进行统一分析；通过KdV方程、波动方程、稳态扩散反应方程、湍流重建和地震动力学等基准问题验证；比较不同网络架构、激活函数、损失设计和优化策略。

Result: 谱偏差本质上是动力学问题而非单纯表示限制；二阶优化方法显著改变谱学习顺序，使所有PDE类型的高频模式能更早更准确地恢复；对于神经算子，谱偏差依赖于架构，可通过谱感知损失公式有效缓解而不增加推理成本。

Conclusion: 谱偏差是物理信息学习和算子学习中的基本动力学现象，可通过二阶优化方法和谱感知损失设计有效缓解，为改进PDE求解的神经网络方法提供了新见解。

Abstract: Solving partial differential equations (PDEs) by neural networks as well as Kolmogorov-Arnold Networks (KANs), including physics-informed neural networks (PINNs), physics-informed KANs (PIKANs), and neural operators, are known to exhibit spectral bias, whereby low-frequency components of the solution are learned significantly faster than high-frequency modes. While spectral bias is often treated as an intrinsic representational limitation of neural architectures, its interaction with optimization dynamics and physics-based loss formulations remains poorly understood. In this work, we provide a systematic investigation of spectral bias in physics-informed and operator learning frameworks, with emphasis on the coupled roles of network architecture, activation functions, loss design, and optimization strategy. We quantify spectral bias through frequency-resolved error metrics, Barron-norm diagnostics, and higher-order statistical moments, enabling a unified analysis across elliptic, hyperbolic, and dispersive PDEs. Through diverse benchmark problems, including the Korteweg-de Vries, wave and steady-state diffusion-reaction equations, turbulent flow reconstruction, and earthquake dynamics, we demonstrate that spectral bias is not simply representational but fundamentally dynamical. In particular, second-order optimization methods substantially alter the spectral learning order, enabling earlier and more accurate recovery of high-frequency modes for all PDE types. For neural operators, we further show that spectral bias is dependent on the neural operator architecture and can also be effectively mitigated through spectral-aware loss formulations without increasing the inference cost.

</details>


### [89] [Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data](https://arxiv.org/abs/2602.19271)
*Junkang Liu,Fanhua Shang,Hongying Liu,Jin Liu,Weixin An,Yuanyuan Liu*

Main category: cs.LG

TL;DR: FedPAC通过预条件器对齐与校正解决联邦二阶优化中的几何失配问题，提升非IID数据下的训练稳定性与精度


<details>
  <summary>Details</summary>
Motivation: 联邦二阶优化在非IID数据上不稳定甚至发散，主要原因是预条件器漂移：客户端二阶训练产生异质的曲率定义几何，服务器端模型平均在不兼容的度量下计算更新，破坏了全局下降方向

Method: FedPAC框架通过解耦参数聚合与几何同步：(1) 对齐：聚合本地预条件器为全局参考，用全局预条件器预热客户端；(2) 校正：使用全局预条件方向引导本地预条件更新，抑制长期漂移

Result: 理论证明在部分参与下具有线性加速的漂移耦合非凸收敛保证；实验表明FedPAC在视觉和语言任务上提升稳定性与精度，在CIFAR-100上ViTs获得5.8%绝对精度提升

Conclusion: FedPAC通过预条件器对齐与校正有效解决联邦二阶优化中的几何失配问题，为大规模非IID联邦学习提供稳定高效的第二阶优化方案

Abstract: Second-order optimizers can significantly accelerate large-scale training, yet their naive federated variants are often unstable or even diverge on non-IID data.
  We show that a key culprit is \emph{preconditioner drift}: client-side second-order training induces heterogeneous \emph{curvature-defined geometries} (i.e., preconditioner coordinate systems), and server-side model averaging updates computed under incompatible metrics, corrupting the global descent direction.
  To address this geometric mismatch, we propose \texttt{FedPAC}, a \emph{preconditioner alignment and correction} framework for reliable federated second-order optimization.
  \texttt{FedPAC} explicitly decouples parameter aggregation from geometry synchronization by:
  (i) \textbf{Alignment} (i.e.,aggregating local preconditioners into a global reference and warm-starting clients via global preconditioner); and
  (ii) \textbf{Correction} (i.e., steering local preconditioned updates using a global preconditioned direction to suppress long-term drift).
  We provide drift-coupled non-convex convergence guarantees with linear speedup under partial participation.
  Empirically, \texttt{FedPAC} consistently improves stability and accuracy across vision and language tasks, achieving up to $5.8\%$ absolute accuracy gain on CIFAR-100 with ViTs.
  Code is available at https://anonymous.4open.science/r/FedPAC-8B24.

</details>


### [90] [AdsorbFlow: energy-conditioned flow matching enables fast and realistic adsorbate placement](https://arxiv.org/abs/2602.19289)
*Jiangjie Qiu,Wentao Li,Honghao Chen,Leyi Zhao,Xiaonan Wang*

Main category: cs.LG

TL;DR: AdsorbFlow是一种确定性生成模型，通过条件流匹配学习吸附物平动和转动的刚性构型空间上的能量条件向量场，相比扩散模型使用更少步骤（5步 vs 100步）实现更高的吸附几何结构预测成功率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在催化表面寻找低能吸附几何结构面临两大挑战：DFT计算成本高和初始构型难以收敛到正确能量盆地。现有条件去噪扩散方法需要约100次迭代步骤，效率较低。

Method: 提出AdsorbFlow确定性生成模型，通过条件流匹配学习刚性构型空间上的能量条件向量场。使用无分类器引导条件而非能量梯度引导，采样简化为只需积分ODE（仅需5步）。采用EquiformerV2作为骨干网络。

Result: 在OC20-Dense数据集上，AdsorbFlow达到61.4% SR@10和34.1% SR@1，超越AdsorbDiff（31.8% SR@1）和AdsorbML（47.7% SR@10）。仅需20分之1的生成步骤，异常率最低（6.8%）。在50个分布外系统上保持58.0% SR@10，MLFF-DFT差距仅4个百分点。

Conclusion: 确定性传输方法比随机去噪方法在吸附物放置任务上更快且更准确，为计算异相催化中的吸附几何结构识别提供了高效解决方案。

Abstract: Identifying low-energy adsorption geometries on catalytic surfaces is a practical bottleneck for computational heterogeneous catalysis: the difficulty lies not only in the cost of density functional theory (DFT) but in proposing initial placements that relax into the correct energy basins. Conditional denoising diffusion has improved success rates, yet requires $\sim$100 iterative steps per sample.
  Here we introduce AdsorbFlow, a deterministic generative model that learns an energy-conditioned vector field on the rigid-body configuration space of adsorbate translation and rotation via conditional flow matching. Energy information enters through classifier-free guidance conditioning -- not energy-gradient guidance -- and sampling reduces to integrating an ODE in as few as 5 steps.
  On OC20-Dense with full DFT single-point verification, AdsorbFlow with an EquiformerV2 backbone achieves 61.4% SR@10 and 34.1% SR@1 -- surpassing AdsorbDiff (31.8% SR@1, 41.0% SR@10) at every evaluation level and AdsorbML (47.7% SR@10) -- while using 20 times fewer generative steps and achieving the lowest anomaly rate among generative methods (6.8%). On 50 out-of-distribution systems, AdsorbFlow retains 58.0% SR@10 with a MLFF-to-DFT gap of only 4~percentage points. These results establish that deterministic transport is both faster and more accurate than stochastic denoising for adsorbate placement.

</details>


### [91] [Soft Sequence Policy Optimization: Bridging GMPO and SAPO](https://arxiv.org/abs/2602.19327)
*Svetlana Glazyrina,Maksim Kryzhanovskiy,Roman Ischenko*

Main category: cs.LG

TL;DR: 提出Soft Sequence Policy Optimization方法，在序列级重要性权重中引入token级概率比值的软门控函数，以促进策略探索同时保持训练稳定性


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐研究中的GRPO方法存在两个主要方向：转向序列级重要性采样权重以更好匹配序列级奖励，以及寻找替代PPO风格裁剪的方法以避免训练信号损失和熵崩溃。需要一种既能促进有效策略探索又能保持训练稳定性的新方法。

Method: 提出Soft Sequence Policy Optimization，这是一种离策略强化学习目标，在序列级重要性权重中引入token级概率比值的软门控函数，结合了序列连贯性和token适应性。

Result: 该方法在GRPO框架内实现了有效的策略探索和训练稳定性，结合了序列级重要性采样和token级适应性调整的优势。

Conclusion: 提出的Soft Sequence Policy Optimization方法通过软门控函数在序列级重要性权重中整合token级概率比值，为LLM对齐提供了一种既能促进探索又能保持稳定性的有效解决方案。

Abstract: A significant portion of recent research on Large Language Model (LLM) alignment focuses on developing new policy optimization methods based on Group Relative Policy Optimization (GRPO). Two prominent directions have emerged: (i) a shift toward sequence-level importance sampling weights that better align with the sequence-level rewards used in many tasks, and (ii) alternatives to PPO-style clipping that aim to avoid the associated loss of training signal and entropy collapse. Recent work, such as Soft Adaptive Policy Optimization (SAPO), reformulates the Scopic objective within the GRPO framework and achieves both sequence coherence and token adaptivity. Geometric-Mean Policy Optimization (GMPO) leverages token-wise ratio clipping within sequence importance sampling weights. Building on these ideas, this work proposes a new objective that promotes effective policy exploration while maintaining training stability. Specifically, we introduce Soft Sequence Policy Optimization, an off-policy reinforcement learning objective that incorporates soft gating functions over token-level probability ratios within sequence-level importance weights.

</details>


### [92] [CTS-Bench: Benchmarking Graph Coarsening Trade-offs for GNNs in Clock Tree Synthesis](https://arxiv.org/abs/2602.19330)
*Barsat Khadka,Kawsher Roxy,Md Rubel Ahmed*

Main category: cs.LG

TL;DR: CTS-Bench：一个用于评估图神经网络在时钟树综合分析中图粗化权衡的基准套件，展示精度与效率的明确折衷


<details>
  <summary>Details</summary>
Motivation: 图神经网络在EDA物理设计分析中应用受限，主要因为原始门级网表的内存和运行时成本过高。图粗化虽能提升可扩展性，但其对CTS关键学习目标的影响尚未得到充分研究。

Method: 提出CTS-Bench基准套件，包含4,860个收敛的物理设计解决方案，涵盖五种架构，提供原始门级和聚类图表示。以时钟偏斜预测为代表任务，系统评估图粗化对预测精度和计算效率的影响。

Result: 图粗化可将GPU内存使用减少17.2倍，训练加速3倍，但会移除对时钟分布建模至关重要的结构信息，导致零样本评估中经常出现负R²分数。通用图聚类技术可能从根本上损害CTS学习目标。

Conclusion: CTS-Bench为CTS感知图粗化策略的系统评估、GNN架构和加速器在真实物理设计约束下的基准测试提供了基础，支持开发学习辅助的CTS分析和优化技术。

Abstract: Graph Neural Networks (GNNs) are increasingly explored for physical design analysis in Electronic Design Automation, particularly for modeling Clock Tree Synthesis behavior such as clock skew and buffering complexity. However, practical deployment remains limited due to the prohibitive memory and runtime cost of operating on raw gate-level netlists. Graph coarsening is commonly used to improve scalability, yet its impact on CTS-critical learning objectives is not well characterized. This paper introduces CTS-Bench, a benchmark suite for systematically evaluating the trade-offs between graph coarsening, prediction accuracy, and computational efficiency in GNN-based CTS analysis. CTS-Bench consists of 4,860 converged physical design solutions spanning five architectures and provides paired raw gate-level and clustered graph representations derived from post-placement designs. Using clock skew prediction as a representative CTS task, we demonstrate a clear accuracy-efficiency trade-off. While graph coarsening reduces GPU memory usage by up to 17.2x and accelerates training by up to 3x, it also removes structural information essential for modeling clock distribution, frequently resulting in negative $R^2$ scores under zero-shot evaluation. Our findings indicate that generic graph clustering techniques can fundamentally compromise CTS learning objectives, even when global physical metrics remain unchanged. CTS-Bench enables principled evaluation of CTS-aware graph coarsening strategies, supports benchmarking of GNN architectures and accelerators under realistic physical design constraints, and provides a foundation for developing learning-assisted CTS analysis and optimization techniques.

</details>


### [93] [Partial Soft-Matching Distance for Neural Representational Comparison with Partial Unit Correspondence](https://arxiv.org/abs/2602.19331)
*Chaitanya Kapoor,Alex H. Williams,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 本文提出了一种部分最优传输的软匹配距离方法，允许部分神经元不匹配，提高了神经表示相似性度量的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的表示相似性度量方法强制所有单元都必须匹配，这使得它们容易受到神经表示中常见的噪声和异常值的影响。需要一种更鲁棒的方法来处理部分对应关系。

Method: 将软匹配距离扩展到部分最优传输设置，允许一些神经元保持不匹配状态。这种方法放松了严格的质量守恒约束，同时保持了可解释的传输成本，并通过高效的神经元排名实现跨网络对齐。

Result: 在模拟中，该方法在存在异常值时保持正确匹配，并在噪声污染的身份识别任务中可靠地选择正确模型。在fMRI数据上，自动排除低可靠性体素，产生与计算昂贵的暴力方法密切匹配的对齐质量体素排名。在深度网络中，高度匹配的单元表现出相似的极大兴奋图像，而不匹配的单元显示不同的模式。

Conclusion: 部分软匹配为部分对应下的表示比较提供了一种原则性和实用的方法，能够根据匹配质量进行分区，实现更集中的分析。

Abstract: Representational similarity metrics typically force all units to be matched, making them susceptible to noise and outliers common in neural representations. We extend the soft-matching distance to a partial optimal transport setting that allows some neurons to remain unmatched, yielding rotation-sensitive but robust correspondences. This partial soft-matching distance provides theoretical advantages -- relaxing strict mass conservation while maintaining interpretable transport costs -- and practical benefits through efficient neuron ranking in terms of cross-network alignment without costly iterative recomputation. In simulations, it preserves correct matches under outliers and reliably selects the correct model in noise-corrupted identification tasks. On fMRI data, it automatically excludes low-reliability voxels and produces voxel rankings by alignment quality that closely match computationally expensive brute-force approaches. It achieves higher alignment precision across homologous brain areas than standard soft-matching, which is forced to match all units regardless of quality. In deep networks, highly matched units exhibit similar maximally exciting images, while unmatched units show divergent patterns. This ability to partition by match quality enables focused analyses, e.g., testing whether networks have privileged axes even within their most aligned subpopulations. Overall, partial soft-matching provides a principled and practical method for representational comparison under partial correspondence.

</details>


### [94] [Training-Free Cross-Architecture Merging for Graph Neural Networks](https://arxiv.org/abs/2602.19332)
*Rishabh Bhattacharya,Vikaskumar Kalsariya,Naresh Manwani*

Main category: cs.LG

TL;DR: H-GRAMA是一个无需训练的异构图神经网络合并框架，通过将参数空间合并提升到算子空间，实现不同架构GNN（如GCN到GAT）的合并，保持专家模型精度并获得1.2-1.9倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 当前模型合并方法主要局限于同构架构，而GNN的消息传递依赖于拓扑结构且对错位敏感，使得参数空间直接合并不可靠。需要一种能够处理异构GNN架构合并的方法。

Method: 提出H-GRAMA框架，引入通用消息传递混合（UMPM）算子族，将异构GNN层表示为统一的函数语言。通过将合并从参数空间提升到算子空间，实现无需训练的跨架构GNN合并。

Result: 在兼容深度设置下，H-GRAMA在大多数情况下能保持高专家精度，相比集成方法获得1.2倍到1.9倍的推理加速，实现了不同架构GNN（如GCN到GAT）的有效合并。

Conclusion: H-GRAMA成功解决了异构GNN架构合并的挑战，通过算子空间合并方法克服了传统参数空间合并的限制，为图神经网络的高效模型融合提供了新范式。

Abstract: Model merging has emerged as a powerful paradigm for combining the capabilities of distinct expert models without the high computational cost of retraining, yet current methods are fundamentally constrained to homogeneous architectures. For GNNs, however, message passing is topology-dependent and sensitive to misalignment, making direct parameter-space merging unreliable. To bridge this gap, we introduce H-GRAMA (Heterogeneous Graph Routing and Message Alignment), a training-free framework that lifts merging from parameter space to operator space. We formalize Universal Message Passing Mixture (UMPM), a shared operator family that expresses heterogeneous GNN layers in a common functional language. H-GRAMA enables cross-architecture GNN merging (e.g., GCN to GAT) without retraining, retaining high specialist accuracy in most cases in compatible depth settings and achieving inference speedups of 1.2x to 1.9x over ensembles.

</details>


### [95] [Smooth Gate Functions for Soft Advantage Policy Optimization](https://arxiv.org/abs/2602.19345)
*Egor Denisov,Svetlana Glazyrina,Maksim Kryzhanovskiy,Roman Ischenko*

Main category: cs.LG

TL;DR: 本文研究了不同门函数对策略优化稳定性和性能的影响，通过Qwen2.5-7B-Instruct模型在数学推理任务上的实验，为设计更平滑、更鲁棒的LLM训练目标提供指导。


<details>
  <summary>Details</summary>
Motivation: GRPO在提升大语言模型推理能力方面效果显著，但由于使用硬截断容易导致训练不稳定。SAPO通过sigmoid门函数解决了这一问题，但作者希望进一步探索不同门函数对训练稳定性和最终性能的影响。

Method: 形式化了可接受门函数应满足的关键性质，识别了多个函数族进行实证评估。使用Qwen2.5-7B-Instruct模型在数学推理任务上进行实验，分析不同门函数的效果。

Result: 实验结果表明不同门函数对训练稳定性和模型性能有显著影响，为设计更优的策略优化目标提供了实证依据。

Conclusion: 通过系统研究不同门函数，为设计更平滑、更鲁棒的大语言模型策略优化目标提供了实用指导，有助于提升训练稳定性和最终模型性能。

Abstract: Group Relative Policy Optimization (GRPO) has significantly advanced the training of large language models and enhanced their reasoning capabilities, while it remains susceptible to instability due to the use of hard clipping. Soft Adaptive Policy Optimization (SAPO) addresses this limitation by replacing clipping with a smooth sigmoid-based gate function, which leads to more stable updates. We have decided to push this theory further and investigate the impact of different gate functions on both training stability and final model performance. We formalize the key properties that admissible gates should satisfy and identify several families of such functions for empirical evaluation. This paper presents an analysis of our findings based on experiments conducted with the Qwen2.5-7B-Instruct model on mathematical reasoning tasks. These results provide practical guidance for designing smoother and more robust policy optimization objectives for large language model training.

</details>


### [96] [Active perception and disentangled representations allow continual, episodic zero and few-shot learning](https://arxiv.org/abs/2602.19355)
*David Rawlinson,Gideon Kowadlo*

Main category: cs.LG

TL;DR: 论文提出了一种互补学习系统，其中快速学习器放弃泛化能力，专注于零样本和少样本学习，与传统的慢速统计学习器协同工作，实现鲁棒的持续学习。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习系统追求泛化，但泛化会导致表示在类别边界处纠缠，在需要快速、大幅度更新的持续学习或少样本学习中产生破坏性干扰。现有快速学习方法通常无法泛化，需要一种能同时支持快速学习和结构化泛化的系统。

Method: 设计互补学习系统：快速学习器专注于解耦表示，放弃泛化以支持零样本和少样本学习；慢速学习器负责统计学习和泛化。两者通过主动感知系统协同：快速学习器提供上下文偏置，引导慢速学习器用熟悉的泛化术语编码新刺激。

Result: 该架构展示了快速上下文驱动推理与慢速结构化泛化可以共存，为鲁棒的持续学习提供了途径。快速学习器能够克服观测变异性和不确定性，实现零样本和少样本学习。

Conclusion: 并非系统的每个组件都需要泛化。通过让快速学习器专注于解耦表示和快速学习，慢速学习器负责泛化，两者在互补学习系统中协同工作，可以实现快速推理与结构化泛化的平衡，支持鲁棒的持续学习。

Abstract: Generalization is often regarded as an essential property of machine learning systems. However, perhaps not every component of a system needs to generalize. Training models for generalization typically produces entangled representations at the boundaries of entities or classes, which can lead to destructive interference when rapid, high-magnitude updates are required for continual or few-shot learning. Techniques for fast learning with non-interfering representations exist, but they generally fail to generalize. Here, we describe a Complementary Learning System (CLS) in which the fast learner entirely foregoes generalization in exchange for continual zero-shot and few-shot learning. Unlike most CLS approaches, which use episodic memory primarily for replay and consolidation, our fast, disentangled learner operates as a parallel reasoning system. The fast learner can overcome observation variability and uncertainty by leveraging a conventional slow, statistical learner within an active perception system: A contextual bias provided by the fast learner induces the slow learner to encode novel stimuli in familiar, generalized terms, enabling zero-shot and few-shot learning. This architecture demonstrates that fast, context-driven reasoning can coexist with slow, structured generalization, providing a pathway for robust continual learning.

</details>


### [97] [LLMs Can Learn to Reason Via Off-Policy RL](https://arxiv.org/abs/2602.19362)
*Daniel Ritter,Owen Oertell,Bradley Guo,Jonathan Chang,Kianté Brantley,Wen Sun*

Main category: cs.LG

TL;DR: 提出OAPL算法，一种针对大语言模型的新型离策略强化学习方法，无需重要性采样或修改推理引擎，在数学和编程基准上优于现有方法，且训练效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有LLM强化学习方法（如PPO、GRPO）通常假设为同策略学习，但分布式训练架构导致策略滞后，以及训练与推理策略的差异，使得数据本质上就是离策略的。先前工作试图通过重要性采样或修改推理引擎来使数据看起来更像同策略，但这种方法存在局限性。

Method: 提出OAPL（Optimal Advantage-based Policy Optimization with Lagged Inference policy）算法，直接拥抱离策略性，不需要重要性采样或修改推理引擎。该方法基于最优优势的策略优化，专门处理训练与推理策略之间存在滞后（可达400+梯度步）的情况。

Result: 在数学竞赛基准上优于带重要性采样的GRPO；在LiveCodeBench上与公开的DeepCoder模型性能相当，但训练时生成次数减少3倍；在Pass@k指标下测试时扩展性更好；能处理训练与推理策略间超过400梯度步的滞后，比先前方法离策略程度高100倍。

Conclusion: OAPL提供了一种高效有效的后训练方法，能够直接处理LLM强化学习中的离策略问题，无需复杂修改，在保持性能的同时显著提高训练效率。

Abstract: Reinforcement learning (RL) approaches for Large Language Models (LLMs) frequently use on-policy algorithms, such as PPO or GRPO. However, policy lag from distributed training architectures and differences between the training and inference policies break this assumption, making the data off-policy by design. To rectify this, prior work has focused on making this off-policy data appear more on-policy, either via importance sampling (IS), or by more closely aligning the training and inference policies by explicitly modifying the inference engine. In this work, we embrace off-policyness and propose a novel off-policy RL algorithm that does not require these modifications: Optimal Advantage-based Policy Optimization with Lagged Inference policy (OAPL). We show that OAPL outperforms GRPO with importance sampling on competition math benchmarks, and can match the performance of a publicly available coding model, DeepCoder, on LiveCodeBench, while using 3x fewer generations during training. We further empirically demonstrate that models trained via OAPL have improved test time scaling under the Pass@k metric. OAPL allows for efficient, effective post-training even with lags of more than 400 gradient steps between the training and inference policies, 100x more off-policy than prior approaches.

</details>


### [98] [Stable Deep Reinforcement Learning via Isotropic Gaussian Representations](https://arxiv.org/abs/2602.19373)
*Ali Saheb,Johan Obando-Ceron,Aaron Courville,Pouya Bashivan,Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 论文提出使用各向同性高斯嵌入来应对深度强化学习中非平稳环境带来的训练不稳定问题，并设计了Sketched Isotropic Gaussian Regularization方法，在多种领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习系统在非平稳环境下经常面临训练不稳定的问题，因为学习目标和数据分布会随时间变化。这种非平稳性导致训练动态不稳定，影响智能体的适应性和性能。

Method: 提出使用各向同性高斯嵌入（isotropic Gaussian embeddings），并在此基础上设计了Sketched Isotropic Gaussian Regularization方法。该方法在训练过程中将表征塑造成各向同性高斯分布，计算成本低廉且实现简单。

Result: 在多种领域进行实证研究，证明该方法能够：1) 在非平稳环境下提高性能；2) 减少表征坍缩；3) 减少神经元休眠；4) 降低训练不稳定性。

Conclusion: 各向同性高斯嵌入在理论上对非平稳目标具有优势，而提出的正则化方法在实践中能够有效提升深度强化学习系统在非平稳环境下的适应性和稳定性，是一种简单而有效的解决方案。

Abstract: Deep reinforcement learning systems often suffer from unstable training dynamics due to non-stationarity, where learning objectives and data distributions evolve over time. We show that under non-stationary targets, isotropic Gaussian embeddings are provably advantageous. In particular, they induce stable tracking of time-varying targets for linear readouts, achieve maximal entropy under a fixed variance budget, and encourage a balanced use of all representational dimensions--all of which enable agents to be more adaptive and stable. Building on this insight, we propose the use of Sketched Isotropic Gaussian Regularization for shaping representations toward an isotropic Gaussian distribution during training. We demonstrate empirically, over a variety of domains, that this simple and computationally inexpensive method improves performance under non-stationarity while reducing representation collapse, neuron dormancy, and training instability.

</details>


### [99] [Spiking Graph Predictive Coding for Reliable OOD Generalization](https://arxiv.org/abs/2602.19392)
*Jing Ren,Jiapeng Du,Bowen Li,Ziqi Xu,Xin Zheng,Hong Jia,Suyu Ma,Xiwei Xu,Feng Xia*

Main category: cs.LG

TL;DR: SIGHT是一个用于图神经网络的插件模块，通过尖峰图状态迭代纠错来提升OOD泛化能力，改善预测准确性、不确定性估计和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中普遍存在的分布外（OOD）偏移问题，导致预测不稳定或过度自信，影响Web4Good应用的可信度。现有方法大多是后处理的，对分布偏移不敏感，且无法解释不确定性来源。

Method: 提出SpIking GrapH predicTive coding（SIGHT）模块，通过尖峰图状态进行迭代的、误差驱动的校正，使模型能够暴露内部不匹配信号，揭示预测不可靠的来源。

Result: 在多个图基准测试和多样化的OOD场景中，SIGHT与GNNs集成后，持续提升了预测准确性、不确定性估计和可解释性。

Conclusion: SIGHT为解决图学习中的OOD泛化问题提供了一个有效的、可解释的不确定性感知解决方案，增强了模型在动态Web环境中的可靠性和可信度。

Abstract: Graphs provide a powerful basis for modeling Web-based relational data, with expressive GNNs to support the effective learning in dynamic web environments. However, real-world deployment is hindered by pervasive out-of-distribution (OOD) shifts, where evolving user activity and changing content semantics alter feature distributions and labeling criteria. These shifts often lead to unstable or overconfident predictions, undermining the trustworthiness required for Web4Good applications. Achieving reliable OOD generalization demands principled and interpretable uncertainty estimation; however, existing methods are largely post-hoc, insensitive to distribution shifts, and unable to explain where uncertainty arises especially in high-stakes settings. To address these limitations, we introduce SpIking GrapH predicTive coding (SIGHT), an uncertainty-aware plug-in graph learning module for reliable OOD Generalization. SIGHT performs iterative, error-driven correction over spiking graph states, enabling models to expose internal mismatch signals that reveal where predictions become unreliable. Across multiple graph benchmarks and diverse OOD scenarios, SIGHT consistently enhances predictive accuracy, uncertainty estimation, and interpretability when integrated with GNNs.

</details>


### [100] [In Defense of Cosine Similarity: Normalization Eliminates the Gauge Freedom](https://arxiv.org/abs/2602.19393)
*Taha Bouhsine*

Main category: cs.LG

TL;DR: 论文反驳了Steck等人的观点，指出余弦相似度本身没有问题，问题在于没有对嵌入进行归一化。当嵌入被约束在单位球面上时，D矩阵歧义消失，余弦距离与欧氏距离等价。


<details>
  <summary>Details</summary>
Motivation: Steck等人指出矩阵分解模型学习到的嵌入的余弦相似度可以通过对角"规范"矩阵D变得任意，并警告不要使用余弦相似度。本文作者认为这个结论混淆了不兼容训练目标的问题与余弦距离在单位球面上的几何有效性。

Method: 证明当嵌入被约束在单位球面S^{d-1}上时（无论是在训练期间还是训练后通过适当的目标），D矩阵歧义完全消失，余弦距离恰好等于欧氏距离平方的一半。

Result: 归一化嵌入上的余弦距离与欧氏距离之间存在单调等价关系，这意味着基于余弦和基于欧氏的邻居排名在归一化嵌入上是完全相同的。

Conclusion: 余弦相似度本身没有问题，问题在于没有对嵌入进行归一化。正确的做法是在使用余弦相似度时确保嵌入被归一化到单位球面上。

Abstract: Steck, Ekanadham, and Kallus [arXiv:2403.05440] demonstrate that cosine similarity of learned embeddings from matrix factorization models can be rendered arbitrary by a diagonal ``gauge'' matrix $D$. Their result is correct and important for practitioners who compute cosine similarity on embeddings trained with dot-product objectives. However, we argue that their conclusion, cautioning against cosine similarity in general, conflates the pathology of an incompatible training objective with the geometric validity of cosine distance on the unit sphere. We prove that when embeddings are constrained to the unit sphere $\mathbb{S}^{d-1}$ (either during or after training with an appropriate objective), the $D$-matrix ambiguity vanishes identically, and cosine distance reduces to exactly half the squared Euclidean distance. This monotonic equivalence implies that cosine-based and Euclidean-based neighbor rankings are identical on normalized embeddings. The ``problem'' with cosine similarity is not cosine similarity, it is the failure to normalize.

</details>


### [101] [One Size Fits None: Modeling NYC Taxi Trips](https://arxiv.org/abs/2602.19404)
*Tomas Eglinskas*

Main category: cs.LG

TL;DR: 研究发现纽约市传统出租车小费高度可预测（R²≈0.72），而基于应用的高频叫车服务小费随机难预测（R²≈0.17），表明需要针对不同服务类型建立专门模型而非通用模型。


<details>
  <summary>Details</summary>
Motivation: 应用叫车服务的兴起改变了纽约市的小费文化，研究旨在分析传统出租车与高频叫车服务的小费预测差异，探讨是否能够建立统一的小费预测模型。

Method: 分析了2024年的2.8亿次行程数据，使用从线性回归到深度神经网络等多种方法进行小费预测，比较传统出租车和应用叫车服务的预测效果。

Result: 传统出租车小费高度可预测（R²≈0.72），主要得益于车内支付屏幕的标准化流程；而应用叫车服务小费随机性高，难以建模（R²≈0.17）。

Conclusion: 建立通用小费预测模型是错误的，由于辛普森悖论，组合模型在平均上看似准确，但无法准确预测各类出租车的小费，需要针对不同服务类型建立专门模型。

Abstract: The rise of app-based ride-sharing has fundamentally changed tipping culture in New York City. We analyzed 280 million trips from 2024 to see if we could predict tips for traditional taxis versus high-volume for-hire services. By testing methods from linear regression to deep neural networks, we found two very different outcomes. Traditional taxis are highly predictable ($R^2 \approx 0.72$) due to the in-car payment screen. In contrast, app-based tipping is random and hard to model ($R^2 \approx 0.17$). In conclusion, we show that building one universal model is a mistake and, due to Simpson's paradox, a combined model looks accurate on average but fails to predict tips for individual taxi categories requiring specialized models.

</details>


### [102] [LEVDA: Latent Ensemble Variational Data Assimilation via Differentiable Dynamics](https://arxiv.org/abs/2602.19406)
*Phillip Si,Peng Chen*

Main category: cs.LG

TL;DR: LEVDA：一种在预训练神经动力学替代模型的低维潜空间中运行的集合空间变分平滑器，通过集合子空间中的4DEnVar优化联合同化状态和未知参数，无需伴随代码或辅助编码器。


<details>
  <summary>Details</summary>
Motivation: 传统变分平滑器需要计算昂贵的切线性模型和伴随模型，而最近的潜空间滤波方法通常施加弱轨迹级约束并假设固定观测网格。需要弥合这一差距。

Method: 在预训练可微分神经动力学替代模型的低维潜空间中执行集合空间变分平滑，通过集合子空间中的四维集合变分（4DEnVar）优化，联合同化状态和未知参数。

Result: 在三个具有挑战性的地球物理基准测试中，LEVDA在严重观测稀疏性下匹配或优于最先进的潜空间滤波基线，同时提供更可靠的不确定性量化。相比全状态4DEnVar，实现了显著改进的同化精度和计算效率。

Conclusion: LEVDA通过利用完全可微分、时空连续的替代模型，自然地适应高度不规则的时空采样，为地球物理数据同化提供了一种高效准确的解决方案。

Abstract: Long-range geophysical forecasts are fundamentally limited by chaotic dynamics and numerical errors. While data assimilation can mitigate these issues, classical variational smoothers require computationally expensive tangent-linear and adjoint models. Conversely, recent efficient latent filtering methods often enforce weak trajectory-level constraints and assume fixed observation grids. To bridge this gap, we propose Latent Ensemble Variational Data Assimilation (LEVDA), an ensemble-space variational smoother that operates in the low-dimensional latent space of a pretrained differentiable neural dynamics surrogate. By performing four-dimensional ensemble-variational (4DEnVar) optimization within an ensemble subspace, LEVDA jointly assimilates states and unknown parameters without the need for adjoint code or auxiliary observation-to-latent encoders. Leveraging the fully differentiable, continuous-in-time-and-space nature of the surrogate, LEVDA naturally accommodates highly irregular sampling at arbitrary spatiotemporal locations. Across three challenging geophysical benchmarks, LEVDA matches or outperforms state-of-the-art latent filtering baselines under severe observational sparsity while providing more reliable uncertainty quantification. Simultaneously, it achieves substantially improved assimilation accuracy and computational efficiency compared to full-state 4DEnVar.

</details>


### [103] [Federated Causal Representation Learning in State-Space Systems for Decentralized Counterfactual Reasoning](https://arxiv.org/abs/2602.19414)
*Nazal Mohamed,Ayush Mohanty,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 提出一个联邦因果表示学习框架，用于状态空间系统中捕捉工业资产间的相互依赖关系，支持去中心化的反事实推理。


<details>
  <summary>Details</summary>
Motivation: 工业资产网络紧密耦合，但客户数据高维且私有，无法集中原始数据，且每个客户都有专有本地模型不能修改，需要解决跨客户反事实推理的挑战。

Method: 每个客户端将高维观测映射到低维潜在状态，分离内在动态和控制驱动影响；中央服务器估计全局状态转移和控制结构；通过交换紧凑潜在状态实现去中心化反事实推理。

Result: 证明了收敛到集中式oracle，提供隐私保证；实验显示框架具有可扩展性，在合成和真实工业控制系统数据集上实现准确的跨客户反事实推理。

Conclusion: 该联邦框架在保护数据隐私和模型专有性的前提下，有效解决了工业资产网络中跨客户反事实推理的难题。

Abstract: Networks of interdependent industrial assets (clients) are tightly coupled through physical processes and control inputs, raising a key question: how would the output of one client change if another client were operated differently? This is difficult to answer because client-specific data are high-dimensional and private, making centralization of raw data infeasible. Each client also maintains proprietary local models that cannot be modified. We propose a federated framework for causal representation learning in state-space systems that captures interdependencies among clients under these constraints. Each client maps high-dimensional observations into low-dimensional latent states that disentangle intrinsic dynamics from control-driven influences. A central server estimates the global state-transition and control structure. This enables decentralized counterfactual reasoning where clients predict how outputs would change under alternative control inputs at others while only exchanging compact latent states. We prove convergence to a centralized oracle and provide privacy guarantees. Our experiments demonstrate scalability, and accurate cross-client counterfactual inference on synthetic and real-world industrial control system datasets.

</details>


### [104] [RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs](https://arxiv.org/abs/2602.19419)
*Pranay Anchuri*

Main category: cs.LG

TL;DR: 本文提出RAmmStein深度强化学习方法，解决去中心化交易所中流动性提供的脉冲控制问题，通过减少再平衡频率同时保持高活跃时间，实现0.72%的净投资回报率。


<details>
  <summary>Details</summary>
Motivation: 去中心化交易所中的集中流动性提供面临基本脉冲控制问题：流动性提供者需要在通过紧密价格区间集中来最大化手续费收益与最小化再平衡摩擦成本（包括gas费和交易滑点）之间做出权衡。现有方法通常采用启发式或阈值策略，未能考虑市场动态。

Method: 将流动性管理表述为最优控制问题，推导相应的Hamilton-Jacobi-Bellman拟变分不等式（HJB-QVI）。提出RAmmStein深度强化学习方法，将Ornstein-Uhlenbeck过程的均值回归速度（theta）等特征作为模型输入。智能体学习将状态空间划分为行动区域和非行动区域。

Result: 使用包含超过680万笔交易的高频1Hz Coinbase交易数据进行评估。RAmmStein实现了0.72%的净投资回报率，优于被动和激进策略。与贪婪再平衡策略相比，再平衡频率减少67%，同时保持88%的活跃时间。

Conclusion: 制度感知的"懒惰"策略通过保留原本会被运营成本侵蚀的回报，显著提高了资本效率。智能体能够学习在适当的时间采取行动，避免不必要的再平衡成本。

Abstract: Concentrated liquidity provision in decentralized exchanges presents a fundamental Impulse Control problem. Liquidity Providers (LPs) face a non-trivial trade-off between maximizing fee accrual through tight price-range concentration and minimizing the friction costs of rebalancing, including gas fees and swap slippage. Existing methods typically employ heuristic or threshold strategies that fail to account for market dynamics. This paper formulates liquidity management as an optimal control problem and derives the corresponding Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI). We present an approximate solution RAmmStein, a Deep Reinforcement Learning method that incorporates the mean-reversion speed (theta) of an Ornstein-Uhlenbeck process among other features as input to the model. We demonstrate that the agent learns to separate the state space into regions of action and inaction. We evaluate the framework using high-frequency 1Hz Coinbase trade data comprising over 6.8M trades. Experimental results show that RAmmStein achieves a superior net ROI of 0.72% compared to both passive and aggressive strategies. Notably, the agent reduces rebalancing frequency by 67% compared to a greedy rebalancing strategy while maintaining 88% active time. Our results demonstrate that regime-aware laziness can significantly improve capital efficiency by preserving the returns that would otherwise be eroded by the operational costs.

</details>


### [105] [PIS: A Physics-Informed System for Accurate State Partitioning of $Aβ_{42}$ Protein Trajectories](https://arxiv.org/abs/2602.19444)
*Qianfeng Yu,Ningkang Peng,Yanhui Gu*

Main category: cs.LG

TL;DR: 提出PIS系统，通过整合物理先验知识改进蛋白质构象轨迹分析，特别针对Aβ42的亚稳态划分


<details>
  <summary>Details</summary>
Motivation: 现有端到端深度学习模型在捕捉蛋白质轨迹中的细微状态转变方面存在不足，缺乏明确的物理约束，这限制了阿尔茨海默病相关Aβ42构象演变的研究

Method: 开发PIS系统，整合预计算的物理先验（如回转半径和溶剂可及表面积）到拓扑特征提取中，提供交互式平台进行动态物理特性监测和多维结果验证

Result: 在Aβ42数据集上表现出优越性能，为生物研究者提供具有物理基础可解释性的强大分析工具

Conclusion: PIS系统通过整合物理约束显著改进了蛋白质轨迹分析，为理解Aβ42构象演变和阿尔茨海默病机制提供了更可靠的工具

Abstract: Understanding the conformational evolution of $β$-amyloid ($Aβ$), particularly the $Aβ_{42}$ isoform, is fundamental to elucidating the pathogenic mechanisms underlying Alzheimer's disease. However, existing end-to-end deep learning models often struggle to capture subtle state transitions in protein trajectories due to a lack of explicit physical constraints. In this work, we introduce PIS, a Physics-Informed System designed for robust metastable state partitioning. By integrating pre-computed physical priors, such as the radius of gyration and solvent-accessible surface area, into the extraction of topological features, our model achieves superior performance on the $Aβ_{42}$ dataset. Furthermore, PIS provides an interactive platform that features dynamic monitoring of physical characteristics and multi-dimensional result validation. This system offers biological researchers a powerful set of analytical tools with physically grounded interpretability. A demonstration video of PIS is available on https://youtu.be/AJHGzUtRCg0.

</details>


### [106] [SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning](https://arxiv.org/abs/2602.19455)
*Zelin He,Boran Han,Xiyuan Zhang,Shuai Zhang,Haotian Lin,Qi Zhu,Haoyang Fang,Danielle C. Maddix,Abdul Fatir Ansari,Akash Chandrayan,Abhinav Pradhan,Bernie Wang,Matthew Reimherr*

Main category: cs.LG

TL;DR: 提出混合知识注入框架，将时间序列LLM的领域知识注入通用推理LLM，结合强化学习实现无监督知识提取，显著提升时间序列诊断推理性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列诊断推理存在两难：通用推理大语言模型（GRLM）有强推理能力但缺乏领域知识理解复杂时间序列模式；而微调的时间序列LLM（TSLM）理解模式但缺乏复杂问题的泛化推理能力。需要弥合这一差距。

Method: 提出混合知识注入框架，将TSLM生成的洞察直接注入GRLM的推理轨迹中。采用基于可验证奖励的强化学习（RLVR）方法，无需人工监督即可提取知识丰富的推理轨迹，然后将这种领域思维轨迹转移到GRLM中进行高效知识注入。

Result: 在SenTSR-Bench（新发布的真实工业操作多变量时间序列诊断推理基准）和其他公共数据集上，该方法持续超越TSLM 9.1%-26.1%，超越GRLM 7.9%-22.4%，提供稳健、上下文感知的时间序列诊断洞察。

Conclusion: 提出的混合知识注入框架成功弥合了时间序列诊断推理中的知识-推理差距，通过无监督强化学习方法实现高效知识转移，显著提升了时间序列诊断推理的性能。

Abstract: Time-series diagnostic reasoning is essential for many applications, yet existing solutions face a persistent gap: general reasoning large language models (GRLMs) possess strong reasoning skills but lack the domain-specific knowledge to understand complex time-series patterns. Conversely, fine-tuned time-series LLMs (TSLMs) understand these patterns but lack the capacity to generalize reasoning for more complicated questions. To bridge this gap, we propose a hybrid knowledge-injection framework that injects TSLM-generated insights directly into GRLM's reasoning trace, thereby achieving strong time-series reasoning with in-domain knowledge. As collecting data for knowledge injection fine-tuning is costly, we further leverage a reinforcement learning-based approach with verifiable rewards (RLVR) to elicit knowledge-rich traces without human supervision, then transfer such an in-domain thinking trace into GRLM for efficient knowledge injection. We further release SenTSR-Bench, a multivariate time-series-based diagnostic reasoning benchmark collected from real-world industrial operations. Across SenTSR-Bench and other public datasets, our method consistently surpasses TSLMs by 9.1%-26.1% and GRLMs by 7.9%-22.4%, delivering robust, context-aware time-series diagnostic insights.

</details>


### [107] [Making Conformal Predictors Robust in Healthcare Settings: a Case Study on EEG Classification](https://arxiv.org/abs/2602.19483)
*Arjun Chatterjee,Sayeed Sajjad Razin,John Wu,Siddhartha Laghuvarapu,Jathurshan Pradeepkumar,Jimeng Sun*

Main category: cs.LG

TL;DR: 评估多种保形预测方法在EEG癫痫分类任务上的表现，展示个性化校准策略能显著改善覆盖率


<details>
  <summary>Details</summary>
Motivation: 临床预测中的不确定性量化对高风险诊断任务至关重要。保形预测提供理论覆盖保证，但实际中患者分布偏移违反标准方法的i.i.d.假设，导致医疗场景中覆盖率不佳

Method: 在EEG癫痫分类任务上评估多种保形预测方法，这是一个已知存在分布偏移和标签不确定性的任务。采用个性化校准策略来应对分布偏移问题

Result: 个性化校准策略能将覆盖率提高超过20个百分点，同时保持可比的预测集大小

Conclusion: 个性化校准策略能有效应对医疗场景中的分布偏移问题，显著改善保形预测的覆盖率。研究代码已通过开源医疗AI框架PyHealth公开

Abstract: Quantifying uncertainty in clinical predictions is critical for high-stakes diagnosis tasks. Conformal prediction offers a principled approach by providing prediction sets with theoretical coverage guarantees. However, in practice, patient distribution shifts violate the i.i.d. assumptions underlying standard conformal methods, leading to poor coverage in healthcare settings. In this work, we evaluate several conformal prediction approaches on EEG seizure classification, a task with known distribution shift challenges and label uncertainty. We demonstrate that personalized calibration strategies can improve coverage by over 20 percentage points while maintaining comparable prediction set sizes. Our implementation is available via PyHealth, an open-source healthcare AI framework: https://github.com/sunlabuiuc/PyHealth.

</details>


### [108] [Federated Learning Playground](https://arxiv.org/abs/2602.19489)
*Bryan Guanrong Shan,Alysa Ziying Tan,Han Yu*

Main category: cs.LG

TL;DR: Federated Learning Playground是一个基于浏览器的交互式教育平台，无需编码即可实验联邦学习概念，通过实时可视化帮助用户理解非IID数据、本地过拟合等挑战。


<details>
  <summary>Details</summary>
Motivation: 降低联邦学习的学习门槛，为分布式AI新手提供易于使用的教育工具，同时为快速原型设计和比较FL方法提供沙盒环境，促进这一重要范式的更广泛理解和采用。

Method: 开发了受TensorFlow Playground启发的交互式浏览器平台，用户可以直接在浏览器中实验异构客户端数据分布、模型超参数和聚合算法，无需编码或系统设置，通过实时可视化观察对客户端和全局模型的影响。

Result: 创建了一个功能完整的联邦学习教育平台，用户可以通过直观的界面获得对非IID数据、本地过拟合和可扩展性等挑战的直观理解，有效降低了学习联邦学习的门槛。

Conclusion: 该平台作为易于使用的教育工具，通过民主化联邦学习的探索，促进了这一重要范式的更广泛理解和采用，为分布式AI领域的新手提供了宝贵的入门资源。

Abstract: We present Federated Learning Playground, an interactive browser-based platform inspired by and extends TensorFlow Playground that teaches core Federated Learning (FL) concepts. Users can experiment with heterogeneous client data distributions, model hyperparameters, and aggregation algorithms directly in the browser without coding or system setup, and observe their effects on client and global models through real-time visualizations, gaining intuition for challenges such as non-IID data, local overfitting, and scalability. The playground serves as an easy to use educational tool, lowering the entry barrier for newcomers to distributed AI while also offering a sandbox for rapidly prototyping and comparing FL methods. By democratizing exploration of FL, it promotes broader understanding and adoption of this important paradigm.

</details>


### [109] [Softmax is not Enough (for Adaptive Conformal Classification)](https://arxiv.org/abs/2602.19498)
*Navid Akhavan Attar,Hesam Asadollahzadeh,Ling Luo,Uwe Aickelin*

Main category: cs.LG

TL;DR: 本文提出了一种基于能量的方法，通过利用预softmax logit空间中的Helmholtz自由能来改进共形预测的适应性和效率，从而生成更适应输入难度的预测集。


<details>
  <summary>Details</summary>
Motivation: 传统共形预测使用softmax输出作为非共形分数，但这些分数可能不可靠，导致预测集无法准确反映输入难度。当模型对某些输入过度自信或过度犹豫时，预测集的大小无法自适应调整，限制了共形预测的适应性和效率。

Method: 提出基于能量的方法，利用预softmax logit空间中的Helmholtz自由能作为模型不确定性和样本难度的度量。通过对每个样本的能量分数进行单调变换来重新加权非共形分数，从而提高对输入难度的敏感性。

Result: 在多个数据集和深度架构上，使用四种最先进的评分函数进行实验，结果显示基于能量的增强方法显著提高了预测集的适应性和效率，相比基线非共形分数有明显改进，且没有引入额外的后处理复杂度。

Conclusion: 通过利用预softmax logit空间中的能量信息，可以显著改善共形预测集的适应性和效率，为不确定性量化提供更可靠的方法，同时保持方法的简洁性。

Abstract: The merit of Conformal Prediction (CP), as a distribution-free framework for uncertainty quantification, depends on generating prediction sets that are efficient, reflected in small average set sizes, while adaptive, meaning they signal uncertainty by varying in size according to input difficulty. A central limitation for deep conformal classifiers is that the nonconformity scores are derived from softmax outputs, which can be unreliable indicators of how certain the model truly is about a given input, sometimes leading to overconfident misclassifications or undue hesitation. In this work, we argue that this unreliability can be inherited by the prediction sets generated by CP, limiting their capacity for adaptiveness. We propose a new approach that leverages information from the pre-softmax logit space, using the Helmholtz Free Energy as a measure of model uncertainty and sample difficulty. By reweighting nonconformity scores with a monotonic transformation of the energy score of each sample, we improve their sensitivity to input difficulty. Our experiments with four state-of-the-art score functions on multiple datasets and deep architectures show that this energy-based enhancement improves the adaptiveness of the prediction sets, leading to a notable increase in both efficiency and adaptiveness compared to baseline nonconformity scores, without introducing any post-hoc complexity.

</details>


### [110] [Less is More: Convergence Benefits of Fewer Data Weight Updates over Longer Horizon](https://arxiv.org/abs/2602.19510)
*Rudrajit Das,Neel Patel,Meisam Razaviyayn,Vahab Mirrokni*

Main category: cs.LG

TL;DR: 本文分析了数据混合（data mixing）中双层优化的收敛行为，证明了实际中常用的T=1贪心方法可能失败，并推导了在固定参数更新预算下最优内层步数T的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 数据混合通过重新加权训练域来训练鲁棒模型，这自然是一个双层优化问题。实际中由于计算限制，通常只使用有限（常为很小）的内层更新步数，但这种近似的理论影响尚未被充分理解。

Method: 本文对数据混合中有限内层步数T的收敛行为进行严格分析。在固定参数更新预算N和假设每域损失强凸的条件下，推导最优T的缩放规律，并通过概念验证实验进行补充。

Result: 证明了T=1的贪心方法即使在简单二次例子中也可能失败。对于使用完整梯度的数据混合问题，最优T缩放为Θ(log N)；对于使用随机梯度的数据混合问题，最优T缩放为Θ((N log N)^{1/2})。

Conclusion: 本文为数据混合中有限内层步数的使用提供了理论指导，揭示了实际贪心方法的局限性，并给出了在固定计算预算下最优内层步数的理论缩放规律。

Abstract: Data mixing--the strategic reweighting of training domains--is a critical component in training robust machine learning models. This problem is naturally formulated as a bilevel optimization task, where the outer loop optimizes domain weights to minimize validation loss, and the inner loop optimizes model parameters to minimize the weighted training loss. Classical bilevel optimization relies on hypergradients, which theoretically require the inner optimization to reach convergence. However, due to computational constraints, state-of-the-art methods use a finite, often small, number of inner update steps before updating the weights. The theoretical implications of this approximation are not well understood. In this work, we rigorously analyze the convergence behavior of data mixing with a finite number of inner steps $T$. We prove that the "greedy" practical approach of using $T=1$ can fail even in a simple quadratic example. Under a fixed parameter update budget $N$ and assuming the per-domain losses are strongly convex, we show that the optimal $T$ scales as $Θ(\log N)$ (resp., $Θ({(N \log N)}^{1/2})$) for the data mixing problem with access to full (resp., stochastic) gradients. We complement our theoretical results with proof-of-concept experiments.

</details>


### [111] [Variational Trajectory Optimization of Anisotropic Diffusion Schedules](https://arxiv.org/abs/2602.19512)
*Pengxi Liu,Zeyu Michael Li,Xiang Cheng*

Main category: cs.LG

TL;DR: 提出一个各向异性噪声调度的变分扩散模型框架，通过矩阵值路径M_t(θ)在不同子空间分配噪声，在多个数据集上优于基线EDM模型


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型通常使用各向同性噪声调度，限制了在不同子空间上噪声分配的灵活性。本文旨在开发一个更通用的框架，允许通过矩阵值路径在各向异性的方式下分配噪声，以提升扩散模型的性能。

Method: 1) 引入变分框架，使用矩阵值路径M_t(θ)参数化各向异性噪声调度；2) 提出轨迹级目标函数联合训练分数网络和学习M_t(θ)；3) 推导关于θ的分数导数估计器，实现M_t(θ)调度的高效优化；4) 开发各向异性推广的二阶Heun离散化算法的反向ODE求解器

Result: 在CIFAR-10、AFHQv2、FFHQ和ImageNet-64等多个数据集上，该方法在所有NFE（噪声函数评估）机制下都一致优于基线EDM模型

Conclusion: 提出的各向异性扩散框架通过矩阵值噪声调度在子空间上灵活分配噪声，显著提升了扩散模型的性能，为噪声调度设计提供了更通用的参数化方法

Abstract: We introduce a variational framework for diffusion models with anisotropic noise schedules parameterized by a matrix-valued path $M_t(θ)$ that allocates noise across subspaces. Central to our framework is a trajectory-level objective that jointly trains the score network and learns $M_t(θ)$, which encompasses general parameterization classes of matrix-valued noise schedules. We further derive an estimator for the derivative with respect to $θ$ of the score that enables efficient optimization of the $M_t(θ)$ schedule. For inference, we develop an efficiently-implementable reverse-ODE solver that is an anisotropic generalization of the second-order Heun discretization algorithm. Across CIFAR-10, AFHQv2, FFHQ, and ImageNet-64, our method consistently improves upon the baseline EDM model in all NFE regimes. Code is available at https://github.com/lizeyu090312/anisotropic-diffusion-paper.

</details>


### [112] [Beyond Accuracy: A Unified Random Matrix Theory Diagnostic Framework for Crash Classification Models](https://arxiv.org/abs/2602.19528)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 提出基于随机矩阵理论和重尾自正则化的谱诊断框架，用于检测交通碰撞分类模型的过拟合，通过幂律指数α评估模型结构质量。


<details>
  <summary>Details</summary>
Motivation: 传统交通碰撞分类模型使用准确率、F1分数或AUC等指标评估，但这些指标无法揭示模型是否在静默过拟合。需要一种能够检测模型结构质量的新诊断方法。

Method: 引入基于随机矩阵理论和重尾自正则化的谱诊断框架，适用于多种机器学习模型：BERT/ALBERT/Qwen2.5的权重矩阵、XGBoost/Random Forest的交叉验证增量矩阵、Logistic回归的经验Hessian矩阵、决策树的诱导亲和矩阵、KNN的图拉普拉斯矩阵。使用稀疏Lanczos近似实现大规模数据集的可扩展性。

Result: 在爱荷华州交通部两个碰撞分类任务（173,512和371,062条记录）上评估九个模型族，发现正则化良好的模型幂律指数α在[2,4]范围内（均值2.87±0.34），而过拟合变体显示α<2或谱崩溃。α与专家一致性有强秩相关（Spearman ρ=0.89，p<0.001）。

Conclusion: 幂律指数α可作为模型结构质量的信号，提出基于α的早停准则和谱模型选择协议，验证了其相对于交叉验证F1基线的有效性。谱质量能够捕捉与专家推理一致的模型行为。

Abstract: Crash classification models in transportation safety are typically evaluated using accuracy, F1, or AUC, metrics that cannot reveal whether a model is silently overfitting. We introduce a spectral diagnostic framework grounded in Random Matrix Theory (RMT) and Heavy-Tailed Self-Regularization (HTSR) that spans the ML taxonomy: weight matrices for BERT/ALBERT/Qwen2.5, out-of-fold increment matrices for XGBoost/Random Forest, empirical Hessians for Logistic Regression, induced affinity matrices for Decision Trees, and Graph Laplacians for KNN. Evaluating nine model families on two Iowa DOT crash classification tasks (173,512 and 371,062 records respectively), we find that the power-law exponent $α$ provides a structural quality signal: well-regularized models consistently yield $α$ within $[2, 4]$ (mean $2.87 \pm 0.34$), while overfit variants show $α< 2$ or spectral collapse. We observe a strong rank correlation between $α$ and expert agreement (Spearman $ρ= 0.89$, $p < 0.001$), suggesting spectral quality captures model behaviors aligned with expert reasoning. We propose an $α$-based early stopping criterion and a spectral model selection protocol, and validate both against cross-validated F1 baselines. Sparse Lanczos approximations make the framework scalable to large datasets.

</details>


### [113] [A Statistical Approach for Modeling Irregular Multivariate Time Series with Missing Observations](https://arxiv.org/abs/2602.19531)
*Dingyi Nie,Yixing Wu,C. -C. Jay Kuo*

Main category: cs.LG

TL;DR: 提出一种处理不规则多元时间序列的简单方法：提取时间无关的汇总统计量（均值、标准差、变化均值、变化变异性），消除时间轴，然后用标准分类器实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 医疗等领域的不规则多元时间序列存在缺失值，传统深度学习方法通常关注时间插值或复杂架构来处理不规则性，但作者认为这些方法可能过于复杂。本文旨在探索更简单有效的替代方案。

Method: 为每个变量计算四个关键特征：观测值的均值和标准差，以及连续观测之间变化的均值和变异性。这些特征形成固定维度的表示，然后与标准分类器（如逻辑回归和XGBoost）结合使用。

Result: 在四个生物医学数据集上评估，方法在AUROC/AUPRC上超过最近的transformer和图模型0.5-1.7%，在准确率/F1分数上超过1.1-1.7%，同时降低计算复杂度。消融研究表明性能提升主要来自特征提取而非分类器选择。

Conclusion: 当任务目标允许时间无关表示时，复杂的时间建模可能不是必需的。本文方法为不规则时间序列分类提供了高效且可解释的解决方案，特别是在缺失模式本身包含预测信号的情况下。

Abstract: Irregular multivariate time series with missing values present significant challenges for predictive modeling in domains such as healthcare. While deep learning approaches often focus on temporal interpolation or complex architectures to handle irregularities, we propose a simpler yet effective alternative: extracting time-agnostic summary statistics to eliminate the temporal axis. Our method computes four key features per variable-mean and standard deviation of observed values, as well as the mean and variability of changes between consecutive observations to create a fixed-dimensional representation. These features are then utilized with standard classifiers, such as logistic regression and XGBoost. Evaluated on four biomedical datasets (PhysioNet Challenge 2012, 2019, PAMAP2, and MIMIC-III), our approach achieves state-of-the-art performance, surpassing recent transformer and graph-based models by 0.5-1.7% in AUROC/AUPRC and 1.1-1.7% in accuracy/F1-score, while reducing computational complexity. Ablation studies demonstrate that feature extraction-not classifier choice-drives performance gains, and our summary statistics outperform raw/imputed input in most benchmarks. In particular, we identify scenarios where missing patterns themselves encode predictive signals, as in sepsis prediction (PhysioNet, 2019), where missing indicators alone can achieve 94.2% AUROC with XGBoost, only 1.6% lower than using original raw data as input. Our results challenge the necessity of complex temporal modeling when task objectives permit time-agnostic representations, providing an efficient and interpretable solution for irregular time series classification.

</details>


### [114] [Grokking Finite-Dimensional Algebra](https://arxiv.org/abs/2602.19533)
*Pascal Jr Tikeng Notsawo,Guillaume Dumas,Guillaume Rabusseau*

Main category: cs.LG

TL;DR: 该论文研究了神经网络训练中从记忆到泛化的突然转变现象（grokking），将其扩展到有限维代数中的乘法学习，揭示了代数结构如何影响泛化动态。


<details>
  <summary>Details</summary>
Motivation: 先前关于grokking现象的研究主要集中在群运算上，本文旨在将分析扩展到更一般的代数结构，包括非结合、非交换、非单位的代数，以建立统一的grokking理论框架。

Method: 将有限维代数中的乘法学习问题转化为结构张量的学习问题，对于实数域代数连接矩阵分解与低秩偏置，对于有限域代数分析离散表示学习，并通过实验研究代数性质对grokking的影响。

Result: 证明了群运算学习是有限维代数学习的特例，揭示了代数性质（交换性、结合性、单位元）和结构张量特性（稀疏性、秩）对grokking出现时机和泛化能力的影响，以及模型学习与代数表示对齐的潜在嵌入。

Conclusion: 该研究为跨代数结构的grokking现象提供了统一框架，揭示了数学结构如何控制神经网络泛化动态，为理解神经网络学习机制提供了新的理论见解。

Abstract: This paper investigates the grokking phenomenon, which refers to the sudden transition from a long memorization to generalization observed during neural networks training, in the context of learning multiplication in finite-dimensional algebras (FDA). While prior work on grokking has focused mainly on group operations, we extend the analysis to more general algebraic structures, including non-associative, non-commutative, and non-unital algebras. We show that learning group operations is a special case of learning FDA, and that learning multiplication in FDA amounts to learning a bilinear product specified by the algebra's structure tensor. For algebras over the reals, we connect the learning problem to matrix factorization with an implicit low-rank bias, and for algebras over finite fields, we show that grokking emerges naturally as models must learn discrete representations of algebraic elements. This leads us to experimentally investigate the following core questions: (i) how do algebraic properties such as commutativity, associativity, and unitality influence both the emergence and timing of grokking, (ii) how structural properties of the structure tensor of the FDA, such as sparsity and rank, influence generalization, and (iii) to what extent generalization correlates with the model learning latent embeddings aligned with the algebra's representation. Our work provides a unified framework for grokking across algebraic structures and new insights into how mathematical structure governs neural network generalization dynamics.

</details>


### [115] [The Sample Complexity of Replicable Realizable PAC Learning](https://arxiv.org/abs/2602.19552)
*Kasper Green Larsen,Markus Engelund Mathiasen,Chirag Pabbaraju,Clement Svendsen*

Main category: cs.LG

TL;DR: 本文研究了可复制可实现PAC学习问题，构建了一个特别困难的学习实例，证明了样本复杂度下界与假设类大小|H|的(log|H|)^{3/2}成正比，并给出了几乎匹配的上界。


<details>
  <summary>Details</summary>
Motivation: 研究可复制可实现PAC学习问题的样本复杂度下界，探索假设类大小对样本需求的影响，填补该领域理论理解的空白。

Method: 构建了一个特别困难的学习问题实例，通过定义与假设类H相关的特定Cayley图，分析该图上随机游走的性质，并利用邻接矩阵的谱特性来证明下界。

Result: 证明了样本复杂度下界具有接近(log|H|)^{3/2}的依赖关系，同时给出了几乎匹配的上界，表明如果要获得更强的下界，必须考虑不同的问题实例。

Conclusion: 可复制可实现PAC学习存在接近(log|H|)^{3/2}的样本复杂度下界，该下界在构建的特定实例中几乎是最优的，为理解该问题的理论极限提供了重要见解。

Abstract: In this paper, we consider the problem of replicable realizable PAC learning. We construct a particularly hard learning problem and show a sample complexity lower bound with a close to $(\log|H|)^{3/2}$ dependence on the size of the hypothesis class $H$. Our proof uses several novel techniques and works by defining a particular Cayley graph associated with $H$ and analyzing a suitable random walk on this graph by examining the spectral properties of its adjacency matrix.
  Furthermore, we show an almost matching upper bound for the lower bound instance, meaning if a stronger lower bound exists, one would have to consider a different instance of the problem.

</details>


### [116] [Leap+Verify: Regime-Adaptive Speculative Weight Prediction for Accelerating Neural Network Training](https://arxiv.org/abs/2602.19580)
*Jeremy McEntire*

Main category: cs.LG

TL;DR: Leap+Verify框架使用推测执行加速神经网络训练，通过激活空间余弦相似度检测训练的三个动态阶段，使用权重预测器预测未来模型参数，并通过验证损失标准接受预测。实验发现动量预测失败，有限差分预测在特定阶段有效，大模型更可预测但可预测阶段更少。


<details>
  <summary>Details</summary>
Motivation: 受语言模型推测解码和自动可扩展计算架构启发，旨在加速神经网络训练过程。传统训练方法计算密集，通过预测未来模型权重并验证预测来减少实际计算步骤。

Method: 1. 使用激活空间余弦相似度作为实时Lyapunov代理信号，动态检测训练的三个阶段：混沌、过渡、稳定；2. 在每个阶段使用分析权重预测器（动量、线性、二次外推）预测K步后的模型参数；3. 预测仅当通过验证损失标准时才被接受。

Result: 1. 动量预测在两个规模上都灾难性失败，预测损失超过实际100-10,000倍；2. 有限差分预测在124M模型的稳定阶段K=5时达到24%严格接受率，在1.5B模型的过渡阶段达到37%；3. 规模依赖发现：GPT-2 124M有34%训练时间处于稳定阶段，而Qwen 1.5B有64%处于混沌阶段；4. 跨种子结果高度一致，验证损失方差小于1%。

Conclusion: 大模型在可预测时更可预测，但可预测阶段更少，实际瓶颈从预测精度转向阶段可用性。三阶段框架产生一致的阶段边界，有限差分预测在特定条件下有效，为加速训练提供了新方向。

Abstract: We introduce Leap+Verify, a framework that applies speculative execution -- predicting future model weights and validating predictions before acceptance -- to accelerate neural network training. Inspired by speculative decoding in language model inference and by the Automatically Scalable Computation (ASC) architecture for program execution, Leap+Verify decomposes training into three dynamically detected regimes (chaotic, transition, stable) using activation-space cosine similarity as a real-time Lyapunov proxy signal. Within each regime, analytic weight predictors (momentum, linear, quadratic extrapolation) attempt to forecast model parameters K training steps ahead; predictions are accepted only when validated against a held-out loss criterion. We evaluate Leap+Verify on GPT-2 124M and Qwen 2.5-1.5B trained on WikiText-103 across five random seeds, sweeping prediction depth K in {5, 10, 25, 50, 75, 100}. Momentum-based prediction (Adam moment extrapolation) fails catastrophically at both scales, with predicted losses exceeding actuals by 100-10,000x -- a universal norm explosion in optimizer-state extrapolation. Finite-difference predictors (linear, quadratic) succeed where momentum fails: at 124M, they achieve 24% strict acceptance at K=5 in stable regimes; at 1.5B, they achieve 37% strict acceptance in transition regimes. The scale-dependent finding is in regime distribution: GPT-2 124M spends 34% of training in stable regime, while Qwen 1.5B spends 64% in chaotic regime and reaches stable in only 0-2 of 40 checkpoints. Larger models are more predictable when predictable, but less often predictable -- the practical bottleneck shifts from predictor accuracy to regime availability. Cross-seed results are highly consistent (less than 1% validation loss variance), and the three-regime framework produces identical phase boundaries (plus or minus 50 steps) across seeds.

</details>


### [117] [Advantage-based Temporal Attack in Reinforcement Learning](https://arxiv.org/abs/2602.19582)
*Shenghong He*

Main category: cs.LG

TL;DR: 提出AAT方法，通过多尺度因果自注意力机制和加权优势机制，生成具有更强时间相关性的对抗样本来提升攻击性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于奖励的攻击方法在生成对抗扰动时无法捕捉不同时间步之间的依赖关系，导致当前扰动与先前扰动之间的时间相关性较弱，限制了攻击效果。

Method: 提出优势对抗变换器(AAT)：1) 使用多尺度因果自注意力机制动态捕捉历史信息与当前状态之间的依赖关系；2) 引入加权优势机制量化扰动在给定状态下的有效性，通过采样高优势区域指导生成过程。

Result: 在Atari、DeepMind Control Suite和Google football任务上的大量实验表明，AAT的性能达到或超越了主流对抗攻击基线方法。

Conclusion: AAT能够生成具有更强时间相关性的对抗示例，通过更好地建模时间依赖关系和利用优势指导，显著提升了对抗攻击的性能。

Abstract: Extensive research demonstrates that Deep Reinforcement Learning (DRL) models are susceptible to adversarially constructed inputs (i.e., adversarial examples), which can mislead the agent to take suboptimal or unsafe actions. Recent methods improve attack effectiveness by leveraging future rewards to guide adversarial perturbation generation over sequential time steps (i.e., reward-based attacks). However, these methods are unable to capture dependencies between different time steps in the perturbation generation process, resulting in a weak temporal correlation between the current perturbation and previous perturbations.In this paper, we propose a novel method called Advantage-based Adversarial Transformer (AAT), which can generate adversarial examples with stronger temporal correlations (i.e., time-correlated adversarial examples) to improve the attack performance. AAT employs a multi-scale causal self-attention (MSCSA) mechanism to dynamically capture dependencies between historical information from different time periods and the current state, thus enhancing the correlation between the current perturbation and the previous perturbation. Moreover, AAT introduces a weighted advantage mechanism, which quantifies the effectiveness of a perturbation in a given state and guides the generation process toward high-performance adversarial examples by sampling high-advantage regions. Extensive experiments demonstrate that the performance of AAT matches or surpasses mainstream adversarial attack baselines on Atari, DeepMind Control Suite and Google football tasks.

</details>


### [118] [Interpolation-Driven Machine Learning Approaches for Plume Shine Dose Estimation: A Comparison of XGBoost, Random Forest, and TabNet](https://arxiv.org/abs/2602.19584)
*Biswajit Sadhu,Kalpak Gupte,Trijit Sadhu,S. Anand*

Main category: cs.LG

TL;DR: 开发了一个插值辅助的机器学习框架，用于快速准确估计羽流照射剂量，XGBoost在插值高分辨率数据集上表现最佳，并开发了基于Web的GUI用于实际部署。


<details>
  <summary>Details</summary>
Motivation: 机器学习在辐射剂量评估中的应用受到安全关键约束、训练数据稀缺以及为物理主导系统选择合适架构的挑战的限制。快速准确的羽流照射剂量估计对于核设施安全评估和放射应急响应至关重要，而传统基于光子传输的计算计算成本高。

Method: 开发了插值辅助的机器学习框架，使用pyDOSEIA套件生成的离散剂量数据集，通过形状保持插值构建密集高分辨率训练数据。评估了两种基于树的模型（随机森林和XGBoost）和一种深度学习模型（TabNet），并进行了可解释性分析。

Result: 所有模型在插值高分辨率数据集上都比离散数据表现出更高的预测准确性，XGBoost始终达到最高准确性。可解释性分析显示，基于树的模型主要关注主导的几何-扩散特征，而TabNet将注意力更广泛地分布在多个变量上。

Conclusion: 插值辅助的机器学习框架能够有效提高辐射剂量预测的准确性，XGBoost是最佳选择。开发了基于Web的GUI用于交互式场景评估和与光子传输参考计算的透明比较，为实际部署提供了实用工具。

Abstract: Despite the success of machine learning (ML) in surrogate modeling, its use in radiation dose assessment is limited by safety-critical constraints, scarce training-ready data, and challenges in selecting suitable architectures for physics-dominated systems. Within this context, rapid and accurate plume shine dose estimation serves as a practical test case, as it is critical for nuclear facility safety assessment and radiological emergency response, while conventional photon-transport-based calculations remain computationally expensive. In this work, an interpolation-assisted ML framework was developed using discrete dose datasets generated with the pyDOSEIA suite for 17 gamma-emitting radionuclides across varying downwind distances, release heights, and atmospheric stability categories. The datasets were augmented using shape-preserving interpolation to construct dense, high-resolution training data. Two tree-based ML models (Random Forest and XGBoost) and one deep learning (DL) model (TabNet) were evaluated to examine predictive performance and sensitivity to dataset resolution. All models showed higher prediction accuracy with the interpolated high-resolution dataset than with the discrete data; however, XGBoost consistently achieved the highest accuracy. Interpretability analysis using permutation importance (tree-based models) and attention-based feature attribution (TabNet) revealed that performance differences stem from how the models utilize input features. Tree-based models focus mainly on dominant geometry-dispersion features (release height, stability category, and downwind distance), treating radionuclide identity as a secondary input, whereas TabNet distributes attention more broadly across multiple variables. For practical deployment, a web-based GUI was developed for interactive scenario evaluation and transparent comparison with photon-transport reference calculations.

</details>


### [119] [Detecting High-Potential SMEs with Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2602.19591)
*Yijiashun Qi,Hanzhe Guo,Yijiazhen Qi*

Main category: cs.LG

TL;DR: SME-HGT：基于异构图Transformer的框架，利用公开数据预测哪些获得SBIR第一阶段资助的中小企业能进入第二阶段，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 中小企业占美国企业99.9%，贡献44%经济活动，但系统性地识别高潜力中小企业仍是挑战。现有方法难以有效利用企业、研究主题和政府机构之间的复杂关系。

Method: 构建包含32,268个公司节点、124个研究主题节点和13个政府机构节点的异构图，通过约99,000条边连接三种语义关系类型。采用异构图Transformer框架SME-HGT，使用时序分割测试集防止信息泄露。

Result: SME-HGT在时序测试集上AUPRC达到0.621±0.003，优于MLP基线(0.590±0.002)和R-GCN(0.608±0.013)。在筛选100家公司时，精度达89.6%，比随机选择提升2.14倍。

Conclusion: 企业、研究主题和资助机构之间的关联结构为中小企业潜力评估提供了有效信号。该方法仅依赖公开数据，具有可复现性，对政策制定者和早期投资者有重要意义。

Abstract: Small and Medium Enterprises (SMEs) constitute 99.9% of U.S. businesses and generate 44% of economic activity, yet systematically identifying high-potential SMEs remains an open challenge. We introduce SME-HGT, a Heterogeneous Graph Transformer framework that predicts which SBIR Phase I awardees will advance to Phase II funding using exclusively public data. We construct a heterogeneous graph with 32,268 company nodes, 124 research topic nodes, and 13 government agency nodes connected by approximately 99,000 edges across three semantic relation types. SME-HGT achieves an AUPRC of 0.621 0.003 on a temporally-split test set, outperforming an MLP baseline (0.590 0.002) and R-GCN (0.608 0.013) across five random seeds. At a screening depth of 100 companies, SME-HGT attains 89.6% precision with a 2.14 lift over random selection. Our temporal evaluation protocol prevents information leakage, and our reliance on public data ensures reproducibility. These results demonstrate that relational structure among firms, research topics, and funding agencies provides meaningful signal for SME potential assessment, with implications for policymakers and early-stage investors.

</details>


### [120] [ISO-Bench: Can Coding Agents Optimize Real-World Inference Workloads?](https://arxiv.org/abs/2602.19594)
*Ayush Nangia,Shikhar Mishra,Aman Gokrani,Paras Chopra*

Main category: cs.LG

TL;DR: ISO-Bench是一个用于评估编码代理在真实世界推理优化任务中能力的基准测试，包含来自vLLM和SGLang的54个任务，结合硬性（执行）和软性（LLM）指标进行综合评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要依赖运行时指标，容易被操纵通过测试而无法捕捉代码变更的真实意图，需要更全面的评估方法来测试编码代理在真实世界优化任务中的能力。

Method: 从vLLM和SGLang两个流行LLM服务框架的合并pull request中收集54个可测量性能改进的任务，为代理提供代码库和瓶颈描述，要求其生成优化补丁，并采用硬性（执行）和软性（LLM）双重指标进行评估。

Result: 评估发现没有单个编码代理在所有代码库中表现最优；代理常能识别正确瓶颈但无法执行有效解决方案；相同底层模型的代理表现差异显著，表明框架设计的重要性。

Conclusion: ISO-Bench为编码代理评估提供了更全面的基准，证明硬性和软性指标结合的必要性，并显示代理能力仍有限，框架设计对性能影响重大。

Abstract: We introduce ISO-Bench, a benchmark for coding agents to test their capabilities on real-world inference optimization tasks. These tasks were taken from vLLM and SGLang, two of the most popular LLM serving frameworks. Each task provides an agent with a codebase and bottleneck description, whereby the agent must produce an optimization patch evaluated against expert human solutions. We curated 54 tasks from merged pull requests with measurable performance improvements. While existing benchmarks heavily use runtime-based metrics, such approaches can be gamed to pass tests without capturing the actual intent of the code changes. Therefore, we combine both hard (execution-based) and soft (LLM-based) metrics to show that both are necessary for complete evaluation. While evaluating both closed and open-source coding agents, we find no single agent dominates across codebases. Surprisingly, agents often identify correct bottlenecks but fail to execute working solutions. We also show that agents with identical underlying models differ substantially, suggesting scaffolding is as important as the model.

</details>


### [121] [Variational Inference for Bayesian MIDAS Regression](https://arxiv.org/abs/2602.19610)
*Luigi Simeone*

Main category: cs.LG

TL;DR: 开发了用于贝叶斯混合数据抽样回归的坐标上升变分推断算法，通过分离影响系数和权重函数参数实现条件共轭，相比吉布斯采样获得107-1772倍加速，点估计精度相当但置信区间存在平均场近似典型的下分散问题。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯MIDAS回归具有双线性结构，使得通用哈密顿蒙特卡洛采样器不可靠，但存在条件共轭性可被变分推断利用。需要开发高效推理方法以处理高维预测变量（最多50个）。

Method: 采用坐标上升变分推断算法，通过归一化约束分离影响系数和权重函数参数，利用条件共轭性获得闭式解：回归系数和权重参数为高斯分布，误差方差为逆伽马分布。算法通过二阶矩在块间传播不确定性。

Result: 在21种数据生成配置的蒙特卡洛研究中，CAVI的后验均值与块吉布斯采样基准几乎相同，速度提升107-1772倍。权重函数参数校准优秀（覆盖率>92%），影响系数置信区间存在平均场近似典型的下分散问题。实证应用中CAVI与吉布斯采样产生几乎相同的点预测，每月估计在10毫秒内完成。

Conclusion: CAVI为贝叶斯MIDAS回归提供了高效准确的推理方法，在点估计精度上与吉布斯采样相当且速度大幅提升，但置信区间校准存在平均场近似的局限性。模型特定的变分推断推导优于通用自动微分VI方法。

Abstract: We develop a Coordinate Ascent Variational Inference (CAVI) algorithm for Bayesian Mixed Data Sampling (MIDAS) regression with linear weight parameterizations. The model separates impact coeffcients from weighting function parameters through a normalization constraint, creating a bilinear structure that renders generic Hamiltonian Monte Carlo samplers unreliable while preserving conditional conjugacy exploitable by CAVI. Each variational update admits a closed-form solution: Gaussian for regression coefficients and weight parameters, Inverse-Gamma for the error variance. The algorithm propagates uncertainty across blocks through second moments, distinguishing it from naive plug-in approximations. In a Monte Carlo study spanning 21 data-generating configurations with up to 50 predictors, CAVI produces posterior means nearly identical to a block Gibbs sampler benchmark while achieving speedups of 107x to 1,772x (Table 9). Generic automatic differentiation VI (ADVI), by contrast, produces bias 714 times larger while being orders of magnitude slower, confirming the value of model-specific derivations. Weight function parameters maintain excellent calibration (coverage above 92%) across all configurations. Impact coefficient credible intervals exhibit the underdispersion characteristic of mean-field approximations, with coverage declining from 89% to 55% as the number of predictors grows a documented trade-off between speed and interval calibration that structured variational methods can address. An empirical application to realized volatility forecasting on S&P 500 daily returns cofirms that CAVI and Gibbs sampling yield virtually identical point forecasts, with CAVI completing each monthly estimation in under 10 milliseconds.

</details>


### [122] [Is Your Diffusion Sampler Actually Correct? A Sampler-Centric Evaluation of Discrete Diffusion Language Models](https://arxiv.org/abs/2602.19619)
*Luhan Tang,Longxuan Yu,Shaorong Zhang,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 论文提出了一种评估离散扩散语言模型采样器的新框架，通过使用精确的隐马尔可夫模型后验作为oracle去噪器，分离了采样器误差和去噪器近似误差，发现少步离散扩散采样器即使在oracle去噪器下也无法正确采样。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法混淆了去噪器近似误差和采样器动态引起的误差，而自回归模型不存在这个问题，因为其自回归采样精确反映了学习到的概率模型。需要一种能够隔离采样器误差的评估框架。

Method: 提出了一个采样器中心的oracle框架，用从真实马尔可夫链导出的精确隐马尔可夫模型后验替代学习的去噪器，在受控环境中隔离采样器引起的误差。

Result: 研究发现少步离散扩散采样器即使在oracle去噪器下也不是分布正确的，只有当步数接近序列长度时，转移级不匹配才会消失。此外，负对数似然、生成困惑度或MAUVE的改进并不保证正确采样。

Conclusion: 离散扩散语言模型的采样器评估需要新的方法，现有指标不能反映采样器的分布正确性，少步采样存在系统性偏差，需要重新思考离散扩散模型的评估框架。

Abstract: Discrete diffusion language models (dLLMs) provide a fast and flexible alternative to autoregressive models (ARMs) via iterative denoising with parallel updates. However, their evaluation is challenging: existing metrics conflate denoiser approximation error with sampler-induced error from the sampling dynamics, a problem that does not arise for ARMs whose autoregressive sampling exactly reflects the learned probability model. We introduce a sampler-centric oracle framework that replaces learned denoisers with an exact Hidden Markov Model posterior derived from a ground-truth Markov chain, isolating sampler-induced error in a controlled setting. We show that few-step discrete diffusion samplers are not distributionally correct even under an oracle denoiser, with transition-level mismatch that vanishes only as the number of steps approaches the sequence length. Moreover, improvements in negative log-likelihood, generative perplexity, or MAUVE do not imply correct sampling. Code is available at https://luhantang.github.io/dllm_sampler

</details>


### [123] [VecFormer: Towards Efficient and Generalizable Graph Transformer with Graph Token Attention](https://arxiv.org/abs/2602.19622)
*Jingbo Zhou,Jun Xia,Siyuan Li,Yunfan Liu,Wenjun Wang,Yufei Huang,Changxi Chi,Mutian Hong,Zhuoli Ouyang,Shu Wang,Zhongqi Wang,Xingyu Wu,Chang Yu,Stan Z. Li*

Main category: cs.LG

TL;DR: VecFormer是一种高效的向量量化图Transformer，通过两阶段训练解决现有图Transformer的计算复杂度和泛化问题，在节点分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图Transformer面临两大挑战：1) 计算复杂度指数增长，难以扩展到大规模图；2) 基于节点级操作的注意力机制限制了模型灵活性，在分布外场景泛化性能差。

Method: 采用两阶段训练范式：第一阶段使用两个码本重建节点特征和图结构，学习丰富的语义图编码；第二阶段在基于转换的交叉码本上进行图令牌级注意力操作，降低计算复杂度并增强泛化能力。

Result: 在不同规模数据集上的广泛实验表明，VecFormer在性能和速度上都优于现有图Transformer。

Conclusion: VecFormer通过向量量化和图令牌级注意力机制，有效解决了图Transformer的计算效率和泛化问题，为大规模图学习和分布外场景提供了高效解决方案。

Abstract: Graph Transformer has demonstrated impressive capabilities in the field of graph representation learning. However, existing approaches face two critical challenges: (1) most models suffer from exponentially increasing computational complexity, making it difficult to scale to large graphs; (2) attention mechanisms based on node-level operations limit the flexibility of the model and result in poor generalization performance in out-of-distribution (OOD) scenarios. To address these issues, we propose \textbf{VecFormer} (the \textbf{Vec}tor Quantized Graph Trans\textbf{former}), an efficient and highly generalizable model for node classification, particularly under OOD settings. VecFormer adopts a two-stage training paradigm. In the first stage, two codebooks are used to reconstruct the node features and the graph structure, aiming to learn the rich semantic \texttt{Graph Codes}. In the second stage, attention mechanisms are performed at the \texttt{Graph Token} level based on the transformed cross codebook, reducing computational complexity while enhancing the model's generalization capability. Extensive experiments on datasets of various sizes demonstrate that VecFormer outperforms the existing Graph Transformer in both performance and speed.

</details>


### [124] [Compositional Planning with Jumpy World Models](https://arxiv.org/abs/2602.19634)
*Jesse Farebrother,Matteo Pirotta,Andrea Tirinzoni,Marc G. Bellemare,Alessandro Lazaric,Ahmed Touati*

Main category: cs.LG

TL;DR: 该论文提出了一种使用"跳跃世界模型"进行组合规划的方法，通过预测预训练策略的多步动态来估计策略序列的访问分布，从而在长时程任务中实现零样本性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前组合规划面临的主要挑战是长时程预测中的累积误差使得难以准确估计策略序列诱导的状态访问分布。现有的原始动作规划在复杂任务中效率低下，而预训练策略的组合使用可以解决单一策略无法完成的复杂任务。

Method: 1. 学习"跳跃世界模型"来预测预训练策略在不同时间尺度上的多步动态和状态占用分布；2. 基于时序差分流框架，引入跨时间尺度预测一致性的新目标函数；3. 结合这些生成预测来估计任意策略序列在不同时间尺度上执行的价值。

Result: 在具有挑战性的操作和导航任务上，使用跳跃世界模型的组合规划相比原始动作规划，在长时程任务中平均实现了200%的相对性能提升，显著提高了零样本性能。

Conclusion: 跳跃世界模型通过有效预测预训练策略的多步动态，解决了组合规划中的长时程预测误差问题，为复杂任务的智能决策提供了一种有效的时序抽象规划方法。

Abstract: The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone can solve. Such compositional planning remains elusive as compounding errors in long-horizon predictions make it challenging to estimate the visitation distribution induced by sequencing policies. Motivated by the geometric policy composition framework introduced in arXiv:2206.08736, we address these challenges by learning predictive models of multi-step dynamics -- so-called jumpy world models -- that capture state occupancies induced by pre-trained policies across multiple timescales in an off-policy manner. Building on Temporal Difference Flows (arXiv:2503.09817), we enhance these models with a novel consistency objective that aligns predictions across timescales, improving long-horizon predictive accuracy. We further demonstrate how to combine these generative predictions to estimate the value of executing arbitrary sequences of policies over varying timescales. Empirically, we find that compositional planning with jumpy world models significantly improves zero-shot performance across a wide range of base policies on challenging manipulation and navigation tasks, yielding, on average, a 200% relative improvement over planning with primitive actions on long-horizon tasks.

</details>


### [125] [Evaluating the Impact of Data Anonymization on Image Retrieval](https://arxiv.org/abs/2602.19641)
*Marvin Chen,Manuel Eberhardinger,Johannes Maucher*

Main category: cs.LG

TL;DR: 本文系统研究了匿名化对基于内容的图像检索系统性能的影响，发现匿名化会导致检索偏差，而使用原始数据训练的模型在匿名化后能产生最相似的检索结果。


<details>
  <summary>Details</summary>
Motivation: 随着GDPR等隐私法规的重要性日益增加，视觉数据匿名化变得越来越重要。然而，匿名化可能会影响依赖视觉特征的计算机视觉系统（如CBIR）的性能，但这一影响尚未得到系统研究。本研究旨在填补这一空白，并受到德国巴登-符腾堡州刑事警察局实际使用的DOKIQ文档验证系统的启发。

Method: 提出了一个简单的评估框架：匿名化后的检索结果应尽可能接近匿名化前的结果。使用两个公共数据集和内部DOKIQ数据集，系统评估了三种匿名化方法、四种匿名化程度和四种训练策略，所有实验都基于最先进的DINOv2骨干网络。

Result: 实验结果显示存在明显的检索偏差，偏向于使用原始数据训练的模型，这些模型在匿名化后能产生最相似的检索结果。这为开发隐私合规的CBIR系统提供了实用见解。

Conclusion: 本研究为开发既符合隐私法规又能保持性能的CBIR系统提供了实践指导。研究结果表明，在原始数据上训练的模型在匿名化后表现最佳，这有助于平衡隐私保护和系统性能的需求。

Abstract: With the growing importance of privacy regulations such as the General Data Protection Regulation, anonymizing visual data is becoming increasingly relevant across institutions. However, anonymization can negatively affect the performance of Computer Vision systems that rely on visual features, such as Content-Based Image Retrieval (CBIR). Despite this, the impact of anonymization on CBIR has not been systematically studied. This work addresses this gap, motivated by the DOKIQ project, an artificial intelligence-based system for document verification actively used by the State Criminal Police Office Baden-Württemberg. We propose a simple evaluation framework: retrieval results after anonymization should match those obtained before anonymization as closely as possible. To this end, we systematically assess the impact of anonymization using two public datasets and the internal DOKIQ dataset. Our experiments span three anonymization methods, four anonymization degrees, and four training strategies, all based on the state of the art backbone Self-Distillation with No Labels (DINO)v2. Our results reveal a pronounced retrieval bias in favor of models trained on original data, which produce the most similar retrievals after anonymization. The findings of this paper offer practical insights for developing privacy-compliant CBIR systems while preserving performance.

</details>


### [126] [NEXUS : A compact neural architecture for high-resolution spatiotemporal air quality forecasting in Delhi Nationa Capital Region](https://arxiv.org/abs/2602.19654)
*Rampunit Kumar,Aditya Maheshwari*

Main category: cs.LG

TL;DR: NEXUS架构用于德里NCR地区空气污染预测，仅用18,748参数实现高精度（R²>0.94），优于现有模型，揭示污染时空模式与气象阈值。


<details>
  <summary>Details</summary>
Motivation: 德里国家首都区作为特大城市面临严重的空气污染问题，影响数百万人健康，需要高效准确的空气污染预测系统来支持实时监测和预警。

Method: 提出NEXUS（神经提取与统一时空）架构，整合补丁嵌入、低秩投影和自适应融合机制，处理2018-2021年16个空间网格的大气数据，预测CO、NO和SO₂浓度。

Result: NEXUS在CO、NO和SO₂预测上分别达到R²>0.94、0.91和0.95，参数仅18,748个，显著少于SCINet、Autoformer和FEDformer。研究发现明显的昼夜节律和季节变化，冬季污染最严重。

Conclusion: NEXUS架构在预测性能和计算效率上均表现优异，能够实现实时部署，为空气质量监测系统提供有效工具，同时揭示了德里地区污染的关键时空模式和气象驱动因素。

Abstract: Urban air pollution in megacities poses critical public health challenges, particularly in Delhi National Capital Region (NCR) where severe degradation affects millions. We present NEXUS (Neural Extraction and Unified Spatiotemporal) architecture for forecasting carbon monoxide, nitrogen oxide, and sulfur dioxide. Working with four years (2018--2021) of atmospheric data across sixteen spatial grids, NEXUS achieves R$^2$ exceeding 0.94 for CO, 0.91 for NO, and 0.95 for SO$_2$ using merely 18,748 parameters -- substantially fewer than SCINet (35,552), Autoformer (68,704), and FEDformer (298,080). The architecture integrates patch embedding, low-rank projections, and adaptive fusion mechanisms to decode complex atmospheric chemistry patterns. Our investigation uncovers distinct diurnal rhythms and pronounced seasonal variations, with winter months experiencing severe pollution episodes driven by temperature inversions and agricultural biomass burning. Analysis identifies critical meteorological thresholds, quantifies wind field impacts on pollutant dispersion, and maps spatial heterogeneity across the region. Extensive ablation experiments demonstrate each architectural component's role. NEXUS delivers superior predictive performance with remarkable computational efficiency, enabling real-time deployment for air quality monitoring systems.

</details>


### [127] [Representation Stability in a Minimal Continual Learning Agent](https://arxiv.org/abs/2602.19655)
*Vishnu Subramanian*

Main category: cs.LG

TL;DR: 该论文研究了最小化持续学习系统中表征动态的演化，发现即使没有显式正则化或复杂架构，系统也会自然地从初始可塑性阶段过渡到稳定表征阶段，并在语义扰动后能够恢复稳定。


<details>
  <summary>Details</summary>
Motivation: 当前持续学习系统通常部署在无法重新训练或重置的环境中，但许多方法过于关注任务性能而忽视了内部表征随时间的演化。需要建立一个透明的基础框架来研究表征积累和适应的基本动态。

Method: 设计了一个最小化持续学习代理，维护跨执行的持久状态向量，并在引入新文本数据时增量更新。使用连续归一化状态向量之间的余弦相似度量化表征变化，并定义时间间隔上的稳定性度量。

Result: 在八个执行的纵向实验中，观察到从初始可塑性阶段到稳定表征阶段的转变。故意引入的语义扰动导致相似度有界下降，随后在后续连贯输入下恢复并重新稳定。

Conclusion: 即使在最小化、有状态的学习系统中，没有显式正则化、回放或架构复杂性，也能出现有意义的稳定性-可塑性权衡。该工作为研究持续学习系统中的表征积累和适应建立了透明的实证基线。

Abstract: Continual learning systems are increasingly deployed in environments where retraining or reset is infeasible, yet many approaches emphasize task performance rather than the evolution of internal representations over time. In this work, we study a minimal continual learning agent designed to isolate representational dynamics from architectural complexity and optimization objectives. The agent maintains a persistent state vector across executions and incrementally updates it as new textual data is introduced. We quantify representational change using cosine similarity between successive normalized state vectors and define a stability metric over time intervals. Longitudinal experiments across eight executions reveal a transition from an initial plastic regime to a stable representational regime under consistent input. A deliberately introduced semantic perturbation produces a bounded decrease in similarity, followed by recovery and restabilization under subsequent coherent input. These results demonstrate that meaningful stability plasticity tradeoffs can emerge in a minimal, stateful learning system without explicit regularization, replay, or architectural complexity. The work establishes a transparent empirical baseline for studying representational accumulation and adaptation in continual learning systems.

</details>


### [128] [PaReGTA: An LLM-based EHR Data Encoding Approach to Capture Temporal Information](https://arxiv.org/abs/2602.19661)
*Kihyuk Yoon,Lingchao Mao,Catherine Chong,Todd J. Schwedt,Chia-Chun Chiang,Jing Li*

Main category: cs.LG

TL;DR: PaReGTA：基于LLM的EHR编码框架，将纵向医疗事件转换为带时间线索的文本，通过轻量级对比微调学习领域适应的就诊嵌入，使用混合时间池化生成患者表示，在数据有限情况下表现良好。


<details>
  <summary>Details</summary>
Motivation: 结构化电子健康记录中的时间信息在稀疏的one-hot或基于计数的表示中经常丢失，而序列模型可能成本高昂且需要大量数据。需要一种能在数据有限情况下有效捕捉时间信息的方法。

Method: 1) 将纵向EHR事件转换为带明确时间线索的就诊级模板文本；2) 通过轻量级对比微调句子嵌入模型学习领域适应的就诊嵌入；3) 使用混合时间池化（捕捉近期和全局信息就诊）将就诊嵌入聚合为固定维度的患者表示。

Result: 在All of Us研究项目的39,088名偏头痛患者中，PaReGTA在偏头痛类型分类任务上优于稀疏基线方法，而深度序列模型在该队列中表现不稳定。

Conclusion: PaReGTA是一种有效的EHR编码框架，利用预训练LLM在数据有限情况下表现良好，具有模型无关性，并能通过PaReGTA-RSS提供临床可解释性。

Abstract: Temporal information in structured electronic health records (EHRs) is often lost in sparse one-hot or count-based representations, while sequence models can be costly and data-hungry. We propose PaReGTA, an LLM-based encoding framework that (i) converts longitudinal EHR events into visit-level templated text with explicit temporal cues, (ii) learns domain-adapted visit embeddings via lightweight contrastive fine-tuning of a sentence-embedding model, and (iii) aggregates visit embeddings into a fixed-dimensional patient representation using hybrid temporal pooling that captures both recency and globally informative visits. Because PaReGTA does not require training from scratch but instead utilizes a pre-trained LLM, it can perform well even in data-limited cohorts. Furthermore, PaReGTA is model-agnostic and can benefit from future EHR-specialized sentence-embedding models. For interpretability, we introduce PaReGTA-RSS (Representation Shift Score), which quantifies clinically defined factor importance by recomputing representations after targeted factor removal and projecting representation shifts through a machine learning model. On 39,088 migraine patients from the All of Us Research Program, PaReGTA outperforms sparse baselines for migraine type classification while deep sequential models were unstable in our cohort.

</details>


### [129] [PerturbDiff: Functional Diffusion for Single-Cell Perturbation Modeling](https://arxiv.org/abs/2602.19685)
*Xinyu Yuan,Xixian Liu,Ya Shi Zhang,Zuobai Zhang,Hongyu Guo,Jian Tang*

Main category: cs.LG

TL;DR: PerturbDiff是一个用于单细胞扰动预测的新方法，通过将建模对象从单个细胞转向整个分布，在希尔伯特空间中嵌入分布并使用基于扩散的生成过程，能够捕捉隐藏因素引起的群体水平响应变化。


<details>
  <summary>Details</summary>
Motivation: 单细胞测序的破坏性本质使得无法观察同一细胞在扰动前后的状态，因此扰动预测需要映射未配对的对照和扰动群体。现有模型通常假设在给定观察到的细胞上下文（如细胞类型）和扰动类型时，响应分布是单一的固定分布，但实际上响应会因未观察到的潜在因素（如微环境波动和复杂的批次效应）而系统性地变化。

Method: PerturbDiff将建模对象从单个细胞转向整个分布。通过将分布嵌入希尔伯特空间作为点，定义了一个直接在概率分布上操作的基于扩散的生成过程。这种方法能够捕捉隐藏因素引起的群体水平响应变化。

Result: 在已建立的数据集上的基准测试表明，PerturbDiff在单细胞响应预测方面实现了最先进的性能，并且对未见过的扰动具有显著更好的泛化能力。

Conclusion: PerturbDiff通过将建模对象从单个细胞转向整个分布，能够更好地捕捉单细胞扰动响应中的变异性，为构建能够准确模拟细胞对扰动响应的虚拟细胞提供了新的方法。

Abstract: Building Virtual Cells that can accurately simulate cellular responses to perturbations is a long-standing goal in systems biology. A fundamental challenge is that high-throughput single-cell sequencing is destructive: the same cell cannot be observed both before and after a perturbation. Thus, perturbation prediction requires mapping unpaired control and perturbed populations. Existing models address this by learning maps between distributions, but typically assume a single fixed response distribution when conditioned on observed cellular context (e.g., cell type) and the perturbation type. In reality, responses vary systematically due to unobservable latent factors such as microenvironmental fluctuations and complex batch effects, forming a manifold of possible distributions for the same observed conditions. To account for this variability, we introduce PerturbDiff, which shifts modeling from individual cells to entire distributions. By embedding distributions as points in a Hilbert space, we define a diffusion-based generative process operating directly over probability distributions. This allows PerturbDiff to capture population-level response shifts across hidden factors. Benchmarks on established datasets show that PerturbDiff achieves state-of-the-art performance in single-cell response prediction and generalizes substantially better to unseen perturbations. See our project page (https://katarinayuan.github.io/PerturbDiff-ProjectPage/), where code and data will be made publicly available (https://github.com/DeepGraphLearning/PerturbDiff).

</details>


### [130] [Understanding the Curse of Unrolling](https://arxiv.org/abs/2602.19733)
*Sheheryar Mehmood,Florian Knoll,Peter Ochs*

Main category: cs.LG

TL;DR: 本文分析了算法展开中的"展开诅咒"现象，解释了导数迭代初始发散的原因，并提出通过截断早期迭代和使用热启动来缓解问题。


<details>
  <summary>Details</summary>
Motivation: 算法展开在机器学习中广泛应用，特别是在超参数优化和元学习中，用于计算解映射的雅可比矩阵。然而，虽然展开在渐近条件下能产生正确的雅可比矩阵，但最近研究发现导数迭代可能初始发散，这种现象被称为"展开诅咒"。本文旨在分析这一现象的起源和影响因素。

Method: 1. 提供非渐近分析来解释展开诅咒的行为起源；2. 识别控制该现象的算法因素；3. 提出截断导数计算的早期迭代来缓解问题；4. 证明在双层优化中使用热启动自然诱导了隐式截断形式。

Result: 1. 解释了展开诅咒的起源和机制；2. 发现截断早期迭代既能缓解诅咒又能减少内存需求；3. 证明热启动在双层优化中提供了实用的解决方案；4. 理论发现在代表性示例的数值实验中得到了支持。

Conclusion: 本文通过非渐近分析深入理解了算法展开中的导数发散现象，提出了截断和热启动作为有效的缓解策略，为实际应用提供了理论指导和实用解决方案。

Abstract: Algorithm unrolling is ubiquitous in machine learning, particularly in hyperparameter optimization and meta-learning, where Jacobians of solution mappings are computed by differentiating through iterative algorithms. Although unrolling is known to yield asymptotically correct Jacobians under suitable conditions, recent work has shown that the derivative iterates may initially diverge from the true Jacobian, a phenomenon known as the curse of unrolling. In this work, we provide a non-asymptotic analysis that explains the origin of this behavior and identifies the algorithmic factors that govern it. We show that truncating early iterations of the derivative computation mitigates the curse while simultaneously reducing memory requirements. Finally, we demonstrate that warm-starting in bilevel optimization naturally induces an implicit form of truncation, providing a practical remedy. Our theoretical findings are supported by numerical experiments on representative examples.

</details>


### [131] [The Confusion is Real: GRAPHIC - A Network Science Approach to Confusion Matrices in Deep Learning](https://arxiv.org/abs/2602.19770)
*Johanna S. Fröhlich,Bastian Heinlein,Jan U. Claar,Hans Rosenberger,Vasileios Belagiannis,Ralf R. Müller*

Main category: cs.LG

TL;DR: GRAPHIC是一个架构无关的方法，通过分析神经网络中间层的混淆矩阵来可视化类别混淆关系和学习动态，提供对线性类别可分性、数据集问题和架构行为的洞察。


<details>
  <summary>Details</summary>
Motivation: 尽管可解释AI取得了显著进展，但现有方法缺乏系统性的方式来可视化类别混淆关系以及这些关系如何随着训练进展而演化。需要一种能够揭示神经网络学习过程中真实混淆模式的方法。

Method: GRAPHIC采用架构无关的方法，从神经网络中间层提取混淆矩阵，将其解释为有向图的邻接矩阵，并利用网络科学工具来可视化和量化跨训练周期和中间层的学习动态。

Result: GRAPHIC能够揭示线性类别可分性、数据集问题（如标签歧义）和架构行为，例如发现比目鱼和人类的相似性，这些发现在人类研究中得到了验证。

Conclusion: 通过揭示真实的混淆模式，GRAPHIC为理解神经网络如何学习提供了新的视角，有助于提高AI系统的可靠性和可解释性。

Abstract: Explainable artificial intelligence has emerged as a promising field of research to address reliability concerns in artificial intelligence. Despite significant progress in explainable artificial intelligence, few methods provide a systematic way to visualize and understand how classes are confused and how their relationships evolve as training progresses. In this work, we present GRAPHIC, an architecture-agnostic approach that analyzes neural networks on a class level. It leverages confusion matrices derived from intermediate layers using linear classifiers. We interpret these as adjacency matrices of directed graphs, allowing tools from network science to visualize and quantify learning dynamics across training epochs and intermediate layers. GRAPHIC provides insights into linear class separability, dataset issues, and architectural behavior, revealing, for example, similarities between flatfish and man and labeling ambiguities validated in a human study. In summary, by uncovering real confusions, GRAPHIC offers new perspectives on how neural networks learn. The code is available at https://github.com/Johanna-S-Froehlich/GRAPHIC.

</details>


### [132] [Addressing Instrument-Outcome Confounding in Mendelian Randomization through Representation Learning](https://arxiv.org/abs/2602.19782)
*Shimeng Huang,Matthew Robinson,Francesco Locatello*

Main category: cs.LG

TL;DR: 提出基于表示学习的框架，利用跨环境不变性恢复遗传工具变量的潜在外生成分，解决孟德尔随机化中工具变量与未观测混杂因素不独立的问题。


<details>
  <summary>Details</summary>
Motivation: 孟德尔随机化方法的核心假设——工具变量与未观测混杂因素独立——常因群体分层或选型交配而被违反，需要新的方法来解决这一问题。

Method: 提出表示学习框架，利用多环境数据中的跨环境不变性来恢复遗传工具变量的潜在外生成分，提供了不同混合机制下的理论保证。

Result: 通过模拟实验和使用All of Us研究中心的半合成实验验证了方法的有效性。

Conclusion: 该方法能够有效处理孟德尔随机化中工具变量与混杂因素相关的挑战，为因果推断提供了更可靠的工具。

Abstract: Mendelian Randomization (MR) is a prominent observational epidemiological research method designed to address unobserved confounding when estimating causal effects. However, core assumptions -- particularly the independence between instruments and unobserved confounders -- are often violated due to population stratification or assortative mating. Leveraging the increasing availability of multi-environment data, we propose a representation learning framework that exploits cross-environment invariance to recover latent exogenous components of genetic instruments. We provide theoretical guarantees for identifying these latent instruments under various mixing mechanisms and demonstrate the effectiveness of our approach through simulations and semi-synthetic experiments using data from the All of Us Research Hub.

</details>


### [133] [Unsupervised Anomaly Detection in NSL-KDD Using $β$-VAE: A Latent Space and Reconstruction Error Approach](https://arxiv.org/abs/2602.19785)
*Dylan Baptiste,Ramla Saddem,Alexandre Philippot,François Foyer*

Main category: cs.LG

TL;DR: 该论文探索了在NSL-KDD数据集上使用β-VAE进行网络流量异常检测的无监督方法，比较了潜在空间距离和重构误差两种检测策略。


<details>
  <summary>Details</summary>
Motivation: 随着运营技术(OT)与信息技术(IT)的日益融合，对入侵检测系统的需求变得更加重要。需要探索有效的无监督异常检测方法来应对网络安全挑战。

Method: 采用β-变分自编码器(β-VAE)的无监督方法，研究两种异常检测策略：1)利用潜在空间结构，测量测试样本与训练数据投影之间的距离；2)使用重构误差作为传统异常检测指标。

Result: 实验结果表明，在无监督设置下，利用潜在空间结构的方法在分类任务中表现出色，突显了潜在空间利用的有效性。

Conclusion: 通过比较两种方法，论文揭示了它们在无监督环境中的各自优势和局限性，为网络流量异常检测提供了有价值的见解。

Abstract: As Operational Technology increasingly integrates with Information Technology, the need for Intrusion Detection Systems becomes more important. This paper explores an unsupervised approach to anomaly detection in network traffic using $β$-Variational Autoencoders on the NSL-KDD dataset. We investigate two methods: leveraging the latent space structure by measuring distances from test samples to the training data projections, and using the reconstruction error as a conventional anomaly detection metric. By comparing these approaches, we provide insights into their respective advantages and limitations in an unsupervised setting. Experimental results highlight the effectiveness of latent space exploitation for classification tasks.

</details>


### [134] [Bayesian Meta-Learning with Expert Feedback for Task-Shift Adaptation through Causal Embeddings](https://arxiv.org/abs/2602.19788)
*Lotta Mäkinen,Jorge Loría,Samuel Kaski*

Main category: cs.LG

TL;DR: 提出因果感知的贝叶斯元学习方法，通过基于因果任务嵌入的条件化任务特定先验，实现基于机制相似性而非虚假相关的迁移，减少负迁移并改善分布外适应。


<details>
  <summary>Details</summary>
Motivation: 传统元学习方法在分布内任务上表现良好，但在适应分布外目标任务时经常失败，因为从源任务的迁移可能引发负迁移。需要一种能够基于机制相似性而非虚假相关性进行迁移的方法。

Method: 提出因果感知的贝叶斯元学习方法，将任务特定先验条件化于预计算的潜在因果任务嵌入上。考虑实际部署场景，目标任务数据有限，适应依赖于专家提供的源任务与目标任务之间因果相似性的噪声成对判断。

Result: 理论分析表明，基于因果嵌入的条件化控制了先验不匹配，减轻了任务偏移下的负迁移。实证显示，在受控模拟和真实世界临床预测（跨疾病迁移）中，负迁移减少，分布外适应能力提升。

Conclusion: 通过因果任务嵌入条件化任务先验的贝叶斯元学习方法，能够基于机制相似性进行迁移，有效减少负迁移并改善分布外适应性能，在临床预测等实际应用中具有价值。

Abstract: Meta-learning methods perform well on new within-distribution tasks but often fail when adapting to out-of-distribution target tasks, where transfer from source tasks can induce negative transfer. We propose a causally-aware Bayesian meta-learning method, by conditioning task-specific priors on precomputed latent causal task embeddings, enabling transfer based on mechanistic similarity rather than spurious correlations. Our approach explicitly considers realistic deployment settings where access to target-task data is limited, and adaptation relies on noisy (expert-provided) pairwise judgments of causal similarity between source and target tasks. We provide a theoretical analysis showing that conditioning on causal embeddings controls prior mismatch and mitigates negative transfer under task shift. Empirically, we demonstrate reductions in negative transfer and improved out-of-distribution adaptation in both controlled simulations and a large-scale real-world clinical prediction setting for cross-disease transfer, where causal embeddings align with underlying clinical mechanisms.

</details>


### [135] [Stop Preaching and Start Practising Data Frugality for Responsible Development of AI](https://arxiv.org/abs/2602.19789)
*Sophia N. Wilson,Guðrún Fjóla Guðmundsdóttir,Andrew Millard,Raghavendra Selvan,Sebastian Mair*

Main category: cs.LG

TL;DR: 该立场论文主张机器学习社区应从"宣扬"转向"实践"数据节俭，以负责任地发展人工智能，因为持续的数据扩展带来巨大环境成本，而数据节俭方法既能减少能耗又能保持性能。


<details>
  <summary>Details</summary>
Motivation: 长期以来，AI进步被等同于使用越来越大的数据集，这虽然带来了显著进展，但现在性能提升越来越有限，同时能耗和碳排放不断增加。尽管数据节俭方法的意识有所提高，但实际采用仍停留在口头层面，数据扩展仍然是主流开发实践。这种"宣扬与实践"之间的差距必须弥合，因为持续的数据扩展带来了巨大且未被充分核算的环境影响。

Method: 论文首先提供了ImageNet-1K下游使用的能耗和碳排放的指示性估算。然后通过实证证据展示数据节俭的可行性：使用核心集（coreset）基于子集选择方法，可以显著减少训练能耗，同时保持准确率损失很小，还能缓解数据集偏差。

Result: 研究表明数据节俭方法既实用又有益：核心集子集选择能大幅降低训练能耗（减少约80%），准确率损失很小（仅下降1-2%），同时还能减轻数据集偏差问题。这证明数据节俭在保持性能的同时能显著减少环境足迹。

Conclusion: 论文呼吁机器学习社区必须将数据节俭从口头宣扬转变为具体实践，并提出了负责任AI发展的可操作建议。数据节俭不仅是环境可持续性的需要，也是保持AI性能同时减少资源消耗的实际可行方法。

Abstract: This position paper argues that the machine learning community must move from preaching to practising data frugality for responsible artificial intelligence (AI) development. For long, progress has been equated with ever-larger datasets, driving remarkable advances but now yielding increasingly diminishing performance gains alongside rising energy use and carbon emissions. While awareness of data frugal approaches has grown, their adoption has remained rhetorical, and data scaling continues to dominate development practice. We argue that this gap between preach and practice must be closed, as continued data scaling entails substantial and under-accounted environmental impacts. To ground our position, we provide indicative estimates of the energy use and carbon emissions associated with the downstream use of ImageNet-1K. We then present empirical evidence that data frugality is both practical and beneficial, demonstrating that coreset-based subset selection can substantially reduce training energy consumption with little loss in accuracy, while also mitigating dataset bias. Finally, we outline actionable recommendations for moving data frugality from rhetorical preach to concrete practice for responsible development of AI.

</details>


### [136] [Drift Localization using Conformal Predictions](https://arxiv.org/abs/2602.19790)
*Fabian Hinder,Valerie Vaquet,Johannes Brinkrolf,Barbara Hammer*

Main category: cs.LG

TL;DR: 提出基于 conformal predictions 的新方法进行概念漂移定位，解决高维低信号场景下传统局部测试方法的不足


<details>
  <summary>Details</summary>
Motivation: 概念漂移（数据分布随时间变化）对学习系统构成重大挑战，而漂移定位（确定哪些样本受漂移影响）对于监控和理解漂移至关重要。现有方法大多依赖局部测试方案，在高维低信号场景下效果不佳。

Method: 采用基于 conformal predictions 的根本性不同方法，而非传统的局部测试方案。该方法利用 conformal predictions 框架来识别受概念漂移影响的样本。

Result: 在最新的图像数据集上展示了该方法的性能，证明了其有效性。同时讨论并展示了常见方法的缺点。

Conclusion: 基于 conformal predictions 的方法为解决高维低信号场景下的概念漂移定位问题提供了有效的替代方案，优于传统的局部测试方法。

Abstract: Concept drift -- the change of the distribution over time -- poses significant challenges for learning systems and is of central interest for monitoring. Understanding drift is thus paramount, and drift localization -- determining which samples are affected by the drift -- is essential. While several approaches exist, most rely on local testing schemes, which tend to fail in high-dimensional, low-signal settings. In this work, we consider a fundamentally different approach based on conformal predictions. We discuss and show the shortcomings of common approaches and demonstrate the performance of our approach on state-of-the-art image datasets.

</details>


### [137] [Decision MetaMamba: Enhancing Selective SSM in Offline RL with Heterogeneous Sequence Mixing](https://arxiv.org/abs/2602.19805)
*Wall Kim,Chaeyoung Song,Hanul Kim*

Main category: cs.LG

TL;DR: DMM用密集层序列混合器替代Mamba的token混合器，解决RL中关键步骤被选择性机制忽略的问题，在多种任务中实现SOTA性能且参数紧凑


<details>
  <summary>Details</summary>
Motivation: Mamba模型在离线RL中受到关注，但其选择性机制在RL序列中关键步骤被忽略时会产生负面影响，需要解决信息丢失问题

Method: 提出Decision MetaMamba (DMM)，用密集层序列混合器替代Mamba的token混合器，修改位置结构以保留局部信息，在Mamba之前进行全通道序列混合

Result: DMM在多种RL任务中实现最先进的性能，同时保持紧凑的参数规模，展示出实际应用的强大潜力

Conclusion: DMM通过防止选择性扫描和残差门控导致的信息丢失，为离线RL提供了简单有效的解决方案，在性能和效率上都表现出色

Abstract: Mamba-based models have drawn much attention in offline RL. However, their selective mechanism often detrimental when key steps in RL sequences are omitted. To address these issues, we propose a simple yet effective structure, called Decision MetaMamba (DMM), which replaces Mamba's token mixer with a dense layer-based sequence mixer and modifies positional structure to preserve local information. By performing sequence mixing that considers all channels simultaneously before Mamba, DMM prevents information loss due to selective scanning and residual gating. Extensive experiments demonstrate that our DMM delivers the state-of-the-art performance across diverse RL tasks. Furthermore, DMM achieves these results with a compact parameter footprint, demonstrating strong potential for real-world applications.

</details>


### [138] [I Dropped a Neural Net](https://arxiv.org/abs/2602.19845)
*Hyunwoo Park*

Main category: cs.LG

TL;DR: 提出了一种从训练好的残差网络中恢复96层随机打乱层顺序的方法，通过配对每个块的输入输出投影并排序重组块，解决了搜索空间巨大的问题。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络层被打乱后的恢复问题，特别是针对残差网络，探索训练过程中的稳定性条件如何留下可识别的结构特征。

Method: 1. 利用训练稳定性条件（如动态等距）使正确配对的层具有负对角结构；2. 使用对角优势比作为配对信号；3. 对于排序，使用delta-norm或Frobenius范数作为初始代理，然后通过爬山算法优化到零均方误差。

Result: 成功恢复了残差网络96层的精确排序，解决了搜索空间为(48!)^2 ≈ 10^122的巨大组合问题。

Conclusion: 神经网络训练过程中的稳定性条件会在权重矩阵中留下可识别的结构特征，这些特征可用于恢复被打乱的层顺序，为理解神经网络内部表示提供了新视角。

Abstract: A recent Dwarkesh Patel podcast with John Collison and Elon Musk featured an interesting puzzle from Jane Street: they trained a neural net, shuffled all 96 layers, and asked to put them back in order.
  Given unlabelled layers of a Residual Network and its training dataset, we recover the exact ordering of the layers. The problem decomposes into pairing each block's input and output projections ($48!$ possibilities) and ordering the reassembled blocks ($48!$ possibilities), for a combined search space of $(48!)^2 \approx 10^{122}$, which is more than the atoms in the observable universe. We show that stability conditions during training like dynamic isometry leave the product $W_{\text{out}} W_{\text{in}}$ for correctly paired layers with a negative diagonal structure, allowing us to use diagonal dominance ratio as a signal for pairing. For ordering, we seed-initialize with a rough proxy such as delta-norm or $\|W_{\text{out}}\|_F$ then hill-climb to zero mean squared error.

</details>


### [139] [Generalized Random Direction Newton Algorithms for Stochastic Optimization](https://arxiv.org/abs/2602.19893)
*Soumen Pachal,Prashanth L. A.,Shalabh Bhatnagar,Avinash Achar*

Main category: cs.LG

TL;DR: 提出基于随机方向逼近的广义Hessian估计器家族，仅使用噪声函数测量，展示不同测量次数对估计偏差的影响，并进行收敛性分析和数值验证。


<details>
  <summary>Details</summary>
Motivation: 在仅能获得噪声函数测量值的情况下，需要开发有效的Hessian矩阵估计方法，以支持随机牛顿法的实现。传统方法可能无法充分利用多个函数测量来降低估计偏差。

Method: 提出基于随机方向逼近(RDSA)的广义Hessian估计器家族，通过不同数量的函数测量构建估计器，分析测量次数与估计偏差阶数的关系，并集成到随机牛顿法中进行收敛性分析。

Result: 证明估计器的渐近无偏性，展示更多函数测量的估计器具有更低阶的估计偏差，通过渐近和非渐近收敛分析验证随机牛顿法的性能，数值实验支持理论发现。

Conclusion: 提出的广义Hessian估计器家族能有效利用多个函数测量降低估计偏差，为仅能获得噪声函数测量的优化问题提供了实用的二阶方法实现途径。

Abstract: We present a family of generalized Hessian estimators of the objective using random direction stochastic approximation (RDSA) by utilizing only noisy function measurements. The form of each estimator and the order of the bias depend on the number of function measurements. In particular, we demonstrate that estimators with more function measurements exhibit lower-order estimation bias. We show the asymptotic unbiasedness of the estimators. We also perform asymptotic and non-asymptotic convergence analyses for stochastic Newton methods that incorporate our generalized Hessian estimators. Finally, we perform numerical experiments to validate our theoretical findings.

</details>


### [140] [DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning](https://arxiv.org/abs/2602.19895)
*Zhongwei Wan,Yun Shen,Zhihao Dou,Donghao Zhou,Yu Zhang,Xin Wang,Hui Shen,Jing Xiong,Chaofan Tao,Zixuan Zhong,Peizhou Huang,Mi Zhang*

Main category: cs.LG

TL;DR: DSDR提出了一种双尺度多样性正则化强化学习框架，通过全局和局部两个尺度促进LLM推理的多样性，解决现有RLVR方法探索不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在探索有限的问题：策略容易坍缩到少数推理模式，过早停止深度探索；传统熵正则化仅引入局部随机性，无法产生有意义的路径级多样性，导致基于群体的策略优化中学习信号弱且不稳定。

Method: DSDR将LLM推理多样性分解为全局和耦合两个组件：全局层面促进正确推理轨迹间的多样性以探索不同的解决方案模式；局部层面在正确轨迹上应用长度不变、token级的熵正则化，防止每个模式内的熵坍缩同时保持正确性；通过全局到局部的分配机制耦合两个尺度，对更独特的正确轨迹强调局部正则化。

Result: 在多个推理基准测试中，DSDR在准确率和pass@k指标上均取得了一致的改进，证明了双尺度多样性对于RLVR中深度探索的重要性。

Conclusion: DSDR通过双尺度多样性正则化框架有效解决了RLVR中的探索不足问题，理论分析表明其在有界正则化下保持最优正确性，维持基于群体优化的信息性学习信号，并提供了原则性的全局-局部耦合规则。

Abstract: Reinforcement learning with verifiers (RLVR) is a central paradigm for improving large language model (LLM) reasoning, yet existing methods often suffer from limited exploration. Policies tend to collapse onto a few reasoning patterns and prematurely stop deep exploration, while conventional entropy regularization introduces only local stochasticity and fails to induce meaningful path-level diversity, leading to weak and unstable learning signals in group-based policy optimization. We propose DSDR, a Dual-Scale Diversity Regularization reinforcement learning framework that decomposes diversity in LLM reasoning into global and coupling components. Globally, DSDR promotes diversity among correct reasoning trajectories to explore distinct solution modes. Locally, it applies a length-invariant, token-level entropy regularization restricted to correct trajectories, preventing entropy collapse within each mode while preserving correctness. The two scales are coupled through a global-to-local allocation mechanism that emphasizes local regularization for more distinctive correct trajectories. We provide theoretical support showing that DSDR preserves optimal correctness under bounded regularization, sustains informative learning signals in group-based optimization, and yields a principled global-to-local coupling rule. Experiments on multiple reasoning benchmarks demonstrate consistent improvements in accuracy and pass@k, highlighting the importance of dual-scale diversity for deep exploration in RLVR. Code is available at https://github.com/SUSTechBruce/DSDR.

</details>


### [141] [De novo molecular structure elucidation from mass spectra via flow matching](https://arxiv.org/abs/2602.19912)
*Ghaith Mqawass,Tuan Le,Fabian Theis,Djork-Arné Clevert*

Main category: cs.LG

TL;DR: MSFlow：基于流匹配的两阶段生成模型，将质谱数据转化为分子结构，性能提升14倍


<details>
  <summary>Details</summary>
Motivation: 质谱是识别分子结构的有力工具，但将质谱数据转化为完整分子结构是一个困难且定义不足的逆问题。解决这个问题对于获得生物学洞察、发现新代谢物以及推进化学研究至关重要。

Method: 开发了两阶段编码器-解码器流匹配生成模型。第一阶段：采用公式限制的Transformer模型将质谱编码为连续且具有化学信息的嵌入空间。第二阶段：训练解码器流匹配模型从质谱的潜在嵌入中重建分子。

Result: MSFlow能够准确地将高达45%的分子质谱转化为相应的分子表示，比当前最先进技术提高了14倍。模型已在GitHub上公开供非商业用户使用。

Conclusion: MSFlow在分子结构解析任务上实现了最先进的性能，通过创新的两阶段流匹配方法显著提升了质谱到分子结构的转化能力，为化学和生物学研究提供了强大工具。

Abstract: Mass spectrometry is a powerful and widely used tool for identifying molecular structures due to its sensitivity and ability to profile complex samples. However, translating spectra into full molecular structures is a difficult, under-defined inverse problem. Overcoming this problem is crucial for enabling biological insight, discovering new metabolites, and advancing chemical research across multiple fields. To this end, we develop MSFlow, a two-stage encoder-decoder flow-matching generative model that achieves state-of-the-art performance on the structure elucidation task for small molecules. In the first stage, we adopt a formula-restricted transformer model for encoding mass spectra into a continuous and chemically informative embedding space, while in the second stage, we train a decoder flow matching model to reconstruct molecules from latent embeddings of mass spectra. We present ablation studies demonstrating the importance of using information-preserving molecular descriptors for encoding mass spectra and motivate the use of our discrete flow-based decoder. Our rigorous evaluation demonstrates that MSFlow can accurately translate up to 45 percent of molecular mass spectra into their corresponding molecular representations - an improvement of up to fourteen-fold over the current state-of-the-art. A trained version of MSFlow is made publicly available on GitHub for non-commercial users.

</details>


### [142] [Fully Convolutional Spatiotemporal Learning for Microstructure Evolution Prediction](https://arxiv.org/abs/2602.19915)
*Michael Trimboli,Mohammed Alsubaie,Sirani M. Perera,Ke-Gang Wang,Xianqi Li*

Main category: cs.LG

TL;DR: 提出基于深度学习的框架，加速微观结构演化预测，保持高精度，使用全卷积时空模型自监督训练，在晶粒生长和旋节分解等过程中验证


<details>
  <summary>Details</summary>
Motivation: 传统相场模型等微观结构演化模拟方法计算成本高，需要求解复杂偏微分方程。需要开发快速准确的替代方法以加速材料科学研究。

Method: 使用全卷积时空模型，通过自监督方式训练，利用微观结构演化过程的序列图像数据。模型学习物理动力学，捕捉短期局部行为和长期统计特性。

Result: 模型能准确预测微观结构演化，泛化到未见过的时空域和不同配置/材料参数。相比循环神经网络，达到最先进预测性能，显著降低计算成本。

Conclusion: 该工作为材料科学中的时空学习建立了稳健基线，提供了可扩展的数据驱动替代方案，用于快速可靠的微观结构模拟。

Abstract: Understanding and predicting microstructure evolution is fundamental to materials science, as it governs the resulting properties and performance of materials. Traditional simulation methods, such as phase-field models, offer high-fidelity results but are computationally expensive due to the need to solve complex partial differential equations at fine spatiotemporal resolutions. To address this challenge, we propose a deep learning-based framework that accelerates microstructure evolution predictions while maintaining high accuracy. Our approach utilizes a fully convolutional spatiotemporal model trained in a self-supervised manner using sequential images generated from simulations of microstructural processes, including grain growth and spinodal decomposition. The trained neural network effectively learns the underlying physical dynamics and can accurately capture both short-term local behaviors and long-term statistical properties of evolving microstructures, while also demonstrating generalization to unseen spatiotemporal domains and variations in configuration and material parameters. Compared to recurrent neural architectures, our model achieves state-of-the-art predictive performance with significantly reduced computational cost in both training and inference. This work establishes a robust baseline for spatiotemporal learning in materials science and offers a scalable, data-driven alternative for fast and reliable microstructure simulations.

</details>


### [143] [Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning](https://arxiv.org/abs/2602.19917)
*Thanh Nguyen,Tung Luu,Tri Ton,Sungwoong Kim,Chang D. Yoo*

Main category: cs.LG

TL;DR: 提出一种不确定性感知的Rank-One MIMO Q网络框架，通过量化数据不确定性并利用其训练策略，在保证计算效率的同时提升离线强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习面临分布外数据带来的外推误差问题。现有方法存在过于保守使用OOD数据、OOD数据表征不精确、计算开销大等局限性。

Method: 引入不确定性感知的Rank-One MIMO Q网络框架：1) 量化数据不确定性并将其融入训练损失；2) 训练策略最大化对应Q函数的置信下界；3) 采用Rank-One MIMO架构建模不确定性感知Q函数，提供与集成网络相同的uncertainty quantification能力但成本接近单网络。

Result: 在D4RL基准测试中达到最先进性能，同时保持计算高效性。框架在精度、速度和内存效率之间取得良好平衡。

Conclusion: 通过引入不确定性量化概念，该框架为缓解外推误差和提升离线RL效率提供了有前景的途径。

Abstract: Offline reinforcement learning (RL) has garnered significant interest due to its safe and easily scalable paradigm. However, training under this paradigm presents its own challenge: the extrapolation error stemming from out-of-distribution (OOD) data. Existing methodologies have endeavored to address this issue through means like penalizing OOD Q-values or imposing similarity constraints on the learned policy and the behavior policy. Nonetheless, these approaches are often beset by limitations such as being overly conservative in utilizing OOD data, imprecise OOD data characterization, and significant computational overhead. To address these challenges, this paper introduces an Uncertainty-Aware Rank-One Multi-Input Multi-Output (MIMO) Q Network framework. The framework aims to enhance Offline Reinforcement Learning by fully leveraging the potential of OOD data while still ensuring efficiency in the learning process. Specifically, the framework quantifies data uncertainty and harnesses it in the training losses, aiming to train a policy that maximizes the lower confidence bound of the corresponding Q-function. Furthermore, a Rank-One MIMO architecture is introduced to model the uncertainty-aware Q-function, \TP{offering the same ability for uncertainty quantification as an ensemble of networks but with a cost nearly equivalent to that of a single network}. Consequently, this framework strikes a harmonious balance between precision, speed, and memory efficiency, culminating in improved overall performance. Extensive experimentation on the D4RL benchmark demonstrates that the framework attains state-of-the-art performance while remaining computationally efficient. By incorporating the concept of uncertainty quantification, our framework offers a promising avenue to alleviate extrapolation errors and enhance the efficiency of offline RL.

</details>


### [144] [Rethinking LoRA for Privacy-Preserving Federated Learning in Large Models](https://arxiv.org/abs/2602.19926)
*Jin Liu,Yinbin Miao,Ning Xi,Junkang Liu*

Main category: cs.LG

TL;DR: LA-LoRA：一种在差分隐私联邦学习中增强LoRA性能的新方法，通过解耦梯度交互和对齐客户端更新方向来解决隐私-效用权衡问题


<details>
  <summary>Details</summary>
Motivation: 在差分隐私联邦学习（DPFL）中直接应用LoRA方法会导致性能下降，特别是在大型视觉模型中。研究发现三个未充分探索的挑战：梯度耦合、噪声放大和参数空间中的尖锐性

Method: 提出LA-LoRA（本地交替LoRA），通过解耦两个低秩矩阵的梯度交互，对齐客户端更新方向，增强在严格隐私约束下的鲁棒性

Result: 在Swin Transformer和RoBERTa模型上实现最先进性能，在严格隐私预算（ε=1）下，Swin-B模型在Tiny-ImageNet数据集上比最佳基线RoLoRA提升16.83%的测试准确率

Conclusion: LA-LoRA有效解决了DPFL中LoRA的性能退化问题，提供了理论收敛保证，并在大型视觉和语言模型中展示了鲁棒性和广泛适用性

Abstract: Fine-tuning large vision models (LVMs) and large language models (LLMs) under differentially private federated learning (DPFL) is hindered by a fundamental privacy-utility trade-off. Low-Rank Adaptation (LoRA), a promising parameter-efficient fine-tuning (PEFT) method, reduces computational and communication costs by introducing two trainable low-rank matrices while freezing pre-trained weights. However, directly applying LoRA in DPFL settings leads to performance degradation, especially in LVMs. Our analysis reveals three previously underexplored challenges: (1) gradient coupling caused by the simultaneous update of two asymmetric low-rank matrices, (2) compounded noise amplification under differential privacy, and (3) sharpness of the global aggregated model in the parameter space. To address these issues, we propose LA-LoRA (\textbf{L}ocal \textbf{A}lternating \textbf{LoRA}), a novel approach that decouples gradient interactions and aligns update directions across clients to enhance robustness under stringent privacy constraints. Theoretically, LA-LoRA strengthens convergence guarantees in noisy federated environments. Extensive experiments demonstrate that LA-LoRA achieves state-of-the-art (SOTA) performance on Swin Transformer and RoBERTa models, showcasing robustness to DP noise and broad applicability across both LVMs and LLMs. For example, when fine-tuning the Swin-B model on the Tiny-ImageNet dataset under a strict privacy budget ($ε= 1$), LA-LoRA outperforms the best baseline, RoLoRA, by 16.83\% in test accuracy. Code is provided in \repolink.

</details>


### [145] [Expanding the Role of Diffusion Models for Robust Classifier Training](https://arxiv.org/abs/2602.19931)
*Pin-Han Huang,Shang-Tse Chen,Hsuan-Tien Lin*

Main category: cs.LG

TL;DR: 将扩散模型内部表征作为辅助学习信号加入对抗训练，可提升分类器鲁棒性，并与扩散生成数据形成互补


<details>
  <summary>Details</summary>
Motivation: 现有研究已证明扩散生成数据能提升对抗训练效果，但扩散模型内部表征（编码数据有意义的特征）是否也能为鲁棒分类器训练提供额外益处尚未探索

Method: 在对抗训练中显式引入扩散模型表征作为辅助学习信号，系统实验分析扩散表征的多样性和部分鲁棒性，研究其如何影响特征解缠

Result: 扩散表征能持续提升各种设置下的鲁棒性，与扩散生成数据形成互补作用，促进更解缠的特征学习，在CIFAR-10、CIFAR-100和ImageNet上验证有效

Conclusion: 扩散模型内部表征可作为有价值的辅助学习信号，与扩散生成数据联合使用能更有效地提升对抗训练中分类器的鲁棒性

Abstract: Incorporating diffusion-generated synthetic data into adversarial training (AT) has been shown to substantially improve the training of robust image classifiers. In this work, we extend the role of diffusion models beyond merely generating synthetic data, examining whether their internal representations, which encode meaningful features of the data, can provide additional benefits for robust classifier training. Through systematic experiments, we show that diffusion models offer representations that are both diverse and partially robust, and that explicitly incorporating diffusion representations as an auxiliary learning signal during AT consistently improves robustness across settings. Furthermore, our representation analysis indicates that incorporating diffusion models into AT encourages more disentangled features, while diffusion representations and diffusion-generated synthetic data play complementary roles in shaping representations. Experiments on CIFAR-10, CIFAR-100, and ImageNet validate these findings, demonstrating the effectiveness of jointly leveraging diffusion representations and synthetic data within AT.

</details>


### [146] [A Replicate-and-Quantize Strategy for Plug-and-Play Load Balancing of Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.19938)
*Zijie Liu,Jie Peng,Jinhao Duan,Zirui Liu,Kaixiong Zhou,Mingfu Liang,Luke Simon,Xi Liu,Zhaozhuo Xu,Tianlong Chen*

Main category: cs.LG

TL;DR: 提出Replicate-and-Quantize框架，通过复制热门专家和量化次要专家来动态平衡SMoE推理时的工作负载，无需重新训练或修改路由器。


<details>
  <summary>Details</summary>
Motivation: SMoE模型在推理时存在严重的专家负载不平衡问题，少数专家处理大部分token，而其他专家利用率低。现有方法主要关注训练时解决方案，对推理时行为（对部署至关重要）探索不足。

Method: 提出Replicate-and-Quantize框架：1）复制热门专家以增加并行处理能力；2）量化次要专家和副本以保持在原始内存预算内；3）引入负载不平衡分数(LIS)来衡量路由偏斜。

Result: 在代表性SMoE模型和基准测试中，负载不平衡最多减少1.4倍，准确率保持在±0.6%范围内，实现了更可预测和高效的推理。

Conclusion: R&Q框架提供了一种无需训练、近乎无损的动态工作负载再平衡方法，有效解决了SMoE推理时的负载不平衡问题，提高了推理效率和可预测性。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are increasingly used to scale large language models efficiently, delivering strong accuracy under fixed compute budgets. However, SMoE models often suffer from severe load imbalance across experts, where a small subset of experts receives most tokens while others are underutilized. Prior work has focused mainly on training-time solutions such as routing regularization or auxiliary losses, leaving inference-time behavior, which is critical for deployment, less explored.
  We present a systematic analysis of expert routing during inference and identify three findings: (i) load imbalance persists and worsens with larger batch sizes, (ii) selection frequency does not reliably reflect expert importance, and (iii) overall expert workload and importance can be estimated using a small calibration set. These insights motivate inference-time mechanisms that rebalance workloads without retraining or router modification.
  We propose Replicate-and-Quantize (R&Q), a training-free and near-lossless framework for dynamic workload rebalancing. In each layer, heavy-hitter experts are replicated to increase parallel capacity, while less critical experts and replicas are quantized to remain within the original memory budget. We also introduce a Load-Imbalance Score (LIS) to measure routing skew by comparing heavy-hitter load to an equal allocation baseline. Experiments across representative SMoE models and benchmarks show up to 1.4x reduction in imbalance with accuracy maintained within +/-0.6%, enabling more predictable and efficient inference.

</details>


### [147] [DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models](https://arxiv.org/abs/2602.19945)
*Jin Liu,Yinbin Miao,Ning Xi,Junkang Liu*

Main category: cs.LG

TL;DR: 提出DP-FedAdamW，首个针对差分隐私联邦学习的AdamW优化器，解决隐私噪声和数据异构性导致的二阶矩估计偏差、方差放大和客户端漂移问题，实现线性加速收敛。


<details>
  <summary>Details</summary>
Motivation: 差分隐私联邦学习中，AdamW直接应用面临三个主要问题：1) 数据异构性和隐私噪声共同放大二阶矩估计方差；2) DP扰动导致二阶矩估计偏差；3) DP加剧AdamW对局部过拟合的敏感性，恶化客户端漂移。需要设计专门的优化器来平衡收敛效率和鲁棒性。

Method: 提出DP-FedAdamW优化器：1) 稳定二阶矩估计方差；2) 消除DP引起的偏差；3) 对齐局部更新与全局下降方向以抑制客户端漂移。理论上建立无偏二阶矩估计器，证明无需异构性假设的线性加速收敛率，并提供更紧的(ε,δ)-DP保证。

Result: 在语言和视觉Transformer以及ResNet-18上验证有效性。在Tiny-ImageNet数据集（Swin-Base，ε=1）上，DP-FedAdamW比现有最优方法提升5.83%。

Conclusion: DP-FedAdamW成功解决了差分隐私联邦学习中AdamW应用的三大问题，实现了收敛效率和鲁棒性的平衡，为大规模模型的隐私保护训练提供了有效解决方案。

Abstract: Balancing convergence efficiency and robustness under Differential Privacy (DP) is a central challenge in Federated Learning (FL). While AdamW accelerates training and fine-tuning in large-scale models, we find that directly applying it to Differentially Private FL (DPFL) suffers from three major issues: (i) data heterogeneity and privacy noise jointly amplify the variance of second-moment estimator, (ii) DP perturbations bias the second-moment estimator, and (iii) DP amplify AdamW sensitivity to local overfitting, worsening client drift. We propose DP-FedAdamW, the first AdamW-based optimizer for DPFL. It restores AdamW under DP by stabilizing second-moment variance, removing DP-induced bias, and aligning local updates to the global descent to curb client drift. Theoretically, we establish an unbiased second-moment estimator and prove a linearly accelerated convergence rate without any heterogeneity assumption, while providing tighter $(\varepsilon,δ)$-DP guarantees. Our empirical results demonstrate the effectiveness of DP-FedAdamW across language and vision Transformers and ResNet-18. On Tiny-ImageNet (Swin-Base, $\varepsilon=1$), DP-FedAdamW outperforms the state-of-the-art (SOTA) by 5.83\%. The code is available in Appendix.

</details>


### [148] [Sparse Masked Attention Policies for Reliable Generalization](https://arxiv.org/abs/2602.19956)
*Caroline Horsch,Laurens Engwegen,Max Weltevrede,Matthijs T. J. Spaan,Wendelin Böhmer*

Main category: cs.LG

TL;DR: 提出一种基于注意力权重的信息移除方法，通过可学习的掩码函数提升策略在未见任务上的泛化能力


<details>
  <summary>Details</summary>
Motivation: 强化学习中常用的抽象方法通过移除观测中的不必要信息来提升策略泛化能力，但这些方法忽略了表示提取函数在未见观测上的泛化能力未知的问题

Method: 提出一种信息移除方法，使用可学习的掩码函数作用于注意力权重，并与基于注意力的策略网络集成，从而更可靠地泛化到新状态

Result: 在Procgen基准测试中，相比标准PPO和掩码方法，该方法显著提升了策略在未见任务上的泛化性能

Conclusion: 通过注意力权重的可学习掩码函数能够更可靠地泛化到新状态，有效提升强化学习策略在未见任务上的泛化能力

Abstract: In reinforcement learning, abstraction methods that remove unnecessary information from the observation are commonly used to learn policies which generalize better to unseen tasks. However, these methods often overlook a crucial weakness: the function which extracts the reduced-information representation has unknown generalization ability in unseen observations. In this paper, we address this problem by presenting an information removal method which more reliably generalizes to new states. We accomplish this by using a learned masking function which operates on, and is integrated with, the attention weights within an attention-based policy network. We demonstrate that our method significantly improves policy generalization to unseen tasks in the Procgen benchmark compared to standard PPO and masking approaches.

</details>


### [149] [On the Equivalence of Random Network Distillation, Deep Ensembles, and Bayesian Inference](https://arxiv.org/abs/2602.19964)
*Moritz A. Zanger,Yijun Wu,Pascal R. Van der Vaart,Wendelin Böhmer,Matthijs T. J. Spaan*

Main category: cs.LG

TL;DR: RND不确定性估计在无限宽神经网络极限下等价于深度集成方法的预测方差，通过特定目标函数构造可实现贝叶斯后验预测分布，建立了RND与理论框架的理论联系。


<details>
  <summary>Details</summary>
Motivation: 随机网络蒸馏（RND）是一种轻量级的不确定性量化方法，但缺乏严格的理论基础。本文旨在建立RND与贝叶斯推断、深度集成等理论框架之间的理论联系，为RND提供理论依据。

Method: 在神经正切核框架下分析无限宽神经网络极限中的RND，证明RND平方自预测误差等价于深度集成的预测方差，并通过构造特定RND目标函数使其分布匹配贝叶斯后验预测分布。

Result: 在无限宽极限下：1）RND不确定性信号等价于深度集成的预测方差；2）通过特定目标函数构造，RND误差分布可匹配贝叶斯后验预测分布；3）基于此开发了贝叶斯RND模型，可从精确贝叶斯后验预测分布生成独立同分布样本。

Conclusion: 本文为RND建立了与深度集成和贝叶斯推断的统一理论框架，为高效且理论可靠的不确定性量化方法提供了新途径，填补了RND理论基础的空白。

Abstract: Uncertainty quantification is central to safe and efficient deployments of deep learning models, yet many computationally practical methods lack lacking rigorous theoretical motivation. Random network distillation (RND) is a lightweight technique that measures novelty via prediction errors against a fixed random target. While empirically effective, it has remained unclear what uncertainties RND measures and how its estimates relate to other approaches, e.g. Bayesian inference or deep ensembles. This paper establishes these missing theoretical connections by analyzing RND within the neural tangent kernel framework in the limit of infinite network width. Our analysis reveals two central findings in this limit: (1) The uncertainty signal from RND -- its squared self-predictive error -- is equivalent to the predictive variance of a deep ensemble. (2) By constructing a specific RND target function, we show that the RND error distribution can be made to mirror the centered posterior predictive distribution of Bayesian inference with wide neural networks. Based on this equivalence, we moreover devise a posterior sampling algorithm that generates i.i.d. samples from an exact Bayesian posterior predictive distribution using this modified \textit{Bayesian RND} model. Collectively, our findings provide a unified theoretical perspective that places RND within the principled frameworks of deep ensembles and Bayesian inference, and offer new avenues for efficient yet theoretically grounded uncertainty quantification methods.

</details>


### [150] [Unlearning Noise in PINNs: A Selective Pruning Framework for PDE Inverse Problems](https://arxiv.org/abs/2602.19967)
*Yongsheng Chen,Yong Chen,Wei Guo,Xinghui Zhong*

Main category: cs.LG

TL;DR: P-PINN：通过选择性剪枝框架消除PINN中噪声数据影响，提升PDE逆问题求解的鲁棒性


<details>
  <summary>Details</summary>
Motivation: PINN在求解PDE逆问题时对噪声敏感，少量损坏数据就会扭曲内部神经表示，严重影响精度和训练稳定性。需要一种机制来消除噪声数据的影响。

Method: 提出P-PINN框架：1) 使用联合残差-数据保真度指标划分可靠和损坏数据子集；2) 引入基于偏置的神经元重要性度量，量化两个子集间的激活差异；3) 采用迭代剪枝策略逐层移除噪声敏感神经元；4) 在可靠数据上微调剪枝后的网络。

Result: 在多个PDE逆问题基准测试中，P-PINN显著提升了鲁棒性、精度和训练稳定性，在噪声条件下相比基线PINN实现了高达96.6%的相对误差减少。

Conclusion: 激活层面的后验剪枝是增强物理信息学习在噪声污染环境中可靠性的有前景机制，P-PINN为噪声鲁棒的PINN提供了一种有效的轻量级后处理方案。

Abstract: Physics-informed neural networks (PINNs) provide a promising framework for solving inverse problems governed by partial differential equations (PDEs) by integrating observational data and physical constraints in a unified optimization objective. However, the ill-posed nature of PDE inverse problems makes them highly sensitive to noise. Even a small fraction of corrupted observations can distort internal neural representations, severely impairing accuracy and destabilizing training. Motivated by recent advances in machine unlearning and structured network pruning, we propose P-PINN, a selective pruning framework designed to unlearn the influence of corrupted data in a pretrained PINN. Specifically, starting from a PINN trained on the full dataset, P-PINN evaluates a joint residual--data fidelity indicator, a weighted combination of data misfit and PDE residuals, to partition the training set into reliable and corrupted subsets. Next, we introduce a bias-based neuron importance measure that quantifies directional activation discrepancies between the two subsets, identifying neurons whose representations are predominantly driven by corrupted samples. Building on this, an iterative pruning strategy then removes noise-sensitive neurons layer by layer. The resulting pruned network is fine-tuned on the reliable data subject to the original PDE constraints, acting as a lightweight post-processing stage rather than a complete retraining. Numerical experiments on extensive PDE inverse-problem benchmarks demonstrate that P-PINN substantially improves robustness, accuracy, and training stability under noisy conditions, achieving up to a 96.6\% reduction in relative error compared with baseline PINNs. These results indicate that activation-level post hoc pruning is a promising mechanism for enhancing the reliability of physics-informed learning in noise-contaminated settings.

</details>


### [151] [Discrete Diffusion Models Exploit Asymmetry to Solve Lookahead Planning Tasks](https://arxiv.org/abs/2602.19980)
*Itamar Trainin,Shauli Ravfogel,Omri Abend,Amir Feder*

Main category: cs.LG

TL;DR: AR与NAR模型在规划任务中的差异：NAR模型通过反向解码利用未来信息，比AR模型更高效地学习多步前瞻任务


<details>
  <summary>Details</summary>
Motivation: 研究AR和NAR模型在需要多步前瞻的规划任务中的表现差异，探索两者在解决此类任务时的不同机制

Method: 通过训练AR和NAR模型（如离散扩散模型）在规划任务上，分析训练和推理动态机制，比较两者学习方式

Result: AR和NAR模型都能在规划任务上达到完美准确率，但NAR模型需要指数级更少的训练样本和更浅的网络结构，而AR模型通常需要特定课程调整才能收敛

Conclusion: 规划任务存在关键不对称性：前向生成需要复杂前瞻，而反向生成通常是确定性的。NAR模型利用这种不对称性，通过反向解码避免学习复杂遍历机制，从而更高效地解决规划问题

Abstract: While Autoregressive (AR) Transformer-based Generative Language Models are frequently employed for lookahead tasks, recent research suggests a potential discrepancy in their ability to perform planning tasks that require multi-step lookahead. In this work, we investigate the distinct emergent mechanisms that arise when training AR versus Non-Autoregressive (NAR) models, such as Discrete Diffusion Models (dLLMs), on lookahead tasks. By requiring the models to plan ahead to reach the correct conclusion, we analyze how these two paradigms fundamentally differ in their approach to the problem. We identify a critical asymmetry in planning problems: while forward generation requires complex lookahead at branching junctions, reverse generation is often deterministic. This asymmetry creates an opportunity for NAR models. Through mechanistic analysis of training and inference dynamics, we demonstrate that NAR models learn to solve planning tasks by utilizing future tokens to decode backwards, avoiding the need to learn complex traversal mechanisms entirely. Consequently, we report that both AR and NAR models are able to achieve perfect accuracy on the lookahead task. However, NAR models require exponentially fewer training examples and shallower architectures compared to AR models, which often fail to converge without specific curriculum adjustments.

</details>


### [152] [A Computationally Efficient Multidimensional Vision Transformer](https://arxiv.org/abs/2602.19982)
*Alaa El Ichi,Khalide Jbilou*

Main category: cs.LG

TL;DR: TCP-ViT：基于张量余弦积的新型视觉Transformer架构，通过利用图像数据的多线性结构和余弦变换的正交性，实现高效注意力机制和结构化特征表示，在保持竞争力的准确率的同时实现1/C参数减少。


<details>
  <summary>Details</summary>
Motivation: 视觉Transformer在各种计算机视觉任务中取得了最先进的性能，但其实际部署受到高计算和内存成本的限制。需要开发更高效的Transformer架构来降低计算复杂度。

Method: 提出基于张量余弦积（Cproduct）的张量框架，利用图像数据的多线性结构和余弦变换的正交性，构建高效的注意力机制和结构化特征表示。开发了张量余弦积的理论基础，分析其代数性质，并集成到新的TCP-ViT架构中。

Result: 在标准分类和分割基准测试中，该方法实现了统一的1/C参数减少（C为通道数），同时保持了竞争力的准确率。

Conclusion: 提出的基于张量余弦积的视觉Transformer框架能够显著减少参数数量，同时保持性能，为高效视觉Transformer部署提供了有前景的解决方案。

Abstract: Vision Transformers have achieved state-of-the-art performance in a wide range
  of computer vision tasks, but their practical deployment is limited by high
  computational and memory costs. In this paper, we introduce a novel tensor-based
  framework for Vision Transformers built upon the Tensor Cosine Product
  (Cproduct). By exploiting multilinear structures inherent in image data and the
  orthogonality of cosine transforms, the proposed approach enables efficient
  attention mechanisms and structured feature representations. We develop the
  theoretical foundations of the tensor cosine product, analyze its algebraic
  properties, and integrate it into a new Cproduct-based Vision Transformer
  architecture (TCP-ViT). Numerical experiments on standard classification and
  segmentation benchmarks demonstrate that the proposed method achieves a uniform
  1/C parameter reduction (where C is the number of channels) while
  maintaining competitive accuracy.

</details>


### [153] [Counterfactual Understanding via Retrieval-aware Multimodal Modeling for Time-to-Event Survival Prediction](https://arxiv.org/abs/2602.19987)
*Ha-Anh Hoang Nguyen,Tri-Duc Phan Le,Duc-Hoang Pham,Huy-Son Nguyen,Cam-Van Thi Nguyen,Duc-Trong Le,Hoang-Quynh Le*

Main category: cs.LG

TL;DR: CURE是一个用于反事实生存预测的多模态框架，通过跨注意力机制融合临床、人口统计和多组学数据，并利用专家混合架构自适应优化组学信号，通过隐式检索患者特定潜在亚组来提升生存预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在异质性和删失数据存在的情况下，优化个体化生存结果的问题。传统方法难以有效整合多模态数据并处理反事实生存预测的复杂性。

Method: 提出CURE框架：1）通过跨注意力机制对齐和融合临床、辅助临床、人口统计和多组学信息；2）使用专家混合架构自适应优化多组学信号，强调最具信息量的组学成分；3）基于该表示隐式检索患者特定潜在亚组，捕捉基线生存动态和治疗依赖性变异。

Result: 在METABRIC和TCGA-LUAD数据集上的实验表明，CURE在生存分析中始终优于强基线模型，使用时间依赖性一致性指数（C^{td}）和综合Brier评分（IBS）进行评估。

Conclusion: CURE展示了增强多模态理解的潜力，可作为未来治疗推荐模型的基础。所有代码和资源已公开以促进可重复性。

Abstract: This paper tackles the problem of time-to-event counterfactual survival prediction, aiming to optimize individualized survival outcomes in the presence of heterogeneity and censored data. We propose CURE, a framework that advances counterfactual survival modeling via comprehensive multimodal embedding and latent subgroup retrieval. CURE integrates clinical, paraclinical, demographic, and multi-omics information, which are aligned and fused through cross-attention mechanisms. Complex multi-omics signals can be adaptively refined using a mixture-of-experts architecture, emphasizing the most informative omics components. Building upon this representation, CURE implicitly retrieves patient-specific latent subgroups that capture both baseline survival dynamics and treatment-dependent variations. Experimental results on METABRIC and TCGA-LUAD datasets demonstrate that proposed CURE model consistently outperforms strong baselines in survival analysis, evaluated using the Time-dependent Concordance Index ($C^{td}$) and Integrated Brier Score (IBS). These findings highlight the potential of CURE to enhance multimodal understanding and serve as a foundation for future treatment recommendation models. All code and related resources are publicly available to facilitate the reproducibility https://github.com/L2R-UET/CURE.

</details>


### [154] [A Secure and Private Distributed Bayesian Federated Learning Design](https://arxiv.org/abs/2602.20003)
*Nuocheng Yang,Sihua Wang,Zhaohui Yang,Mingzhe Chen,Changchuan Yin,Kaibin Huang*

Main category: cs.LG

TL;DR: 提出一个集成拜占庭鲁棒性、隐私保护和收敛加速的分布式联邦学习框架，通过贝叶斯方法训练本地模型，使用GNN强化学习算法自主选择最优邻居子集进行后验交换。


<details>
  <summary>Details</summary>
Motivation: 分布式联邦学习面临三个关键挑战：1) 诚实但好奇的邻居导致的隐私泄露；2) 缺乏中央协调导致的收敛缓慢；3) 拜占庭攻击者旨在降低模型准确性的脆弱性。需要同时解决这些问题。

Method: 1) 使用贝叶斯方法训练本地模型；2) 将邻居选择建模为在安全和隐私约束下最小化全局损失函数的优化问题；3) 分析动态连接性、拜占庭检测、隐私级别和收敛速度之间的权衡关系；4) 开发基于图神经网络(GNN)的强化学习算法，使设备能够基于本地观察自主做出连接决策。

Result: 仿真结果表明，该方法相比传统安全和隐私方案，在显著降低开销的同时，实现了更优越的鲁棒性和效率。

Conclusion: 提出的框架成功解决了分布式联邦学习中的隐私泄露、收敛缓慢和拜占庭脆弱性三大挑战，通过集成贝叶斯方法、优化邻居选择和GNN强化学习算法，实现了安全、高效且鲁棒的分布式学习。

Abstract: Distributed Federated Learning (DFL) enables decentralized model training across large-scale systems without a central parameter server. However, DFL faces three critical challenges: privacy leakage from honest-but-curious neighbors, slow convergence due to the lack of central coordination, and vulnerability to Byzantine adversaries aiming to degrade model accuracy. To address these issues, we propose a novel DFL framework that integrates Byzantine robustness, privacy preservation, and convergence acceleration. Within this framework, each device trains a local model using a Bayesian approach and independently selects an optimal subset of neighbors for posterior exchange. We formulate this neighbor selection as an optimization problem to minimize the global loss function under security and privacy constraints. Solving this problem is challenging because devices only possess partial network information, and the complex coupling between topology, security, and convergence remains unclear. To bridge this gap, we first analytically characterize the trade-offs between dynamic connectivity, Byzantine detection, privacy levels, and convergence speed. Leveraging these insights, we develop a fully distributed Graph Neural Network (GNN)-based Reinforcement Learning (RL) algorithm. This approach enables devices to make autonomous connection decisions based on local observations. Simulation results demonstrate that our method achieves superior robustness and efficiency with significantly lower overhead compared to traditional security and privacy schemes.

</details>


### [155] [Learning Discriminative and Generalizable Anomaly Detector for Dynamic Graph with Limited Supervision](https://arxiv.org/abs/2602.20019)
*Yuxing Tian,Yiyan Qi,Fengran Mo,Weixu Zhang,Jian Guo,Jian-Yun Nie*

Main category: cs.LG

TL;DR: 提出一个动态图异常检测框架，通过残差表示编码、限制损失和双边界优化策略，从正常/未标记数据中学习判别边界，并利用有限标记异常而不牺牲对未见异常的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态图异常检测面临标注异常稀缺的挑战。现有无监督方法边界模糊，半监督方法容易过拟合有限标注异常且对未见异常泛化差。需要一种既能从正常/未标记数据学习判别边界，又能利用有限标注异常而不牺牲泛化能力的方法。

Method: 提出包含三个主要组件的框架：1) 残差表示编码 - 捕捉当前交互与历史背景的偏差，提供异常相关信号；2) 限制损失 - 将正常表示约束在两个同中心超球面界定的区间内，确保尺度一致同时保持异常可分离；3) 双边界优化策略 - 使用归一化流建模的正常对数似然分布学习判别且鲁棒的边界。

Result: 大量实验证明该框架在多种评估设置下的优越性，表明其能有效处理动态图异常检测问题。

Conclusion: 该框架解决了动态图异常检测中学习判别边界的关键问题，既能利用有限标注异常，又能保持对未见异常的泛化能力，为实际应用提供了有效的解决方案。

Abstract: Dynamic graph anomaly detection (DGAD) is critical for many real-world applications but remains challenging due to the scarcity of labeled anomalies. Existing methods are either unsupervised or semi-supervised: unsupervised methods avoid the need for labeled anomalies but often produce ambiguous boundary, whereas semi-supervised methods can overfit to the limited labeled anomalies and generalize poorly to unseen anomalies. To address this gap, we consider a largely underexplored problem in DGAD: learning a discriminative boundary from normal/unlabeled data, while leveraging limited labeled anomalies \textbf{when available} without sacrificing generalization to unseen anomalies. To this end, we propose an effective, generalizable, and model-agnostic framework with three main components: (i) residual representation encoding that capture deviations between current interactions and their historical context, providing anomaly-relevant signals; (ii) a restriction loss that constrain the normal representations within an interval bounded by two co-centered hyperspheres, ensuring consistent scales while keeping anomalies separable; (iii) a bi-boundary optimization strategy that learns a discriminative and robust boundary using the normal log-likelihood distribution modeled by a normalizing flow. Extensive experiments demonstrate the superiority of our framework across diverse evaluation settings.

</details>


### [156] [A Theory of How Pretraining Shapes Inductive Bias in Fine-Tuning](https://arxiv.org/abs/2602.20062)
*Nicolas Anguita,Francesco Locatello,Andrew M. Saxe,Marco Mondelli,Flavia Mancini,Samuel Lippl,Clementine Domine*

Main category: cs.LG

TL;DR: 该研究分析了预训练和微调过程中初始化参数对特征学习和泛化性能的影响，在线性网络中识别出四种不同的微调机制，发现较小初始化尺度能促进特征重用和精炼。


<details>
  <summary>Details</summary>
Motivation: 预训练和微调是现代机器学习系统的核心阶段，特征学习在这两个阶段都起着重要作用。然而，初始化选择如何影响微调过程中特征重用和精炼能力的端到端理论理解仍然缺乏。本研究旨在分析初始化参数如何与数据统计特性相互作用，塑造微调泛化性能。

Method: 在对角线性网络中开发预训练-微调管道的分析理论，推导泛化误差作为初始化参数和任务统计函数的精确表达式。通过理论分析和实验验证，研究初始化参数对特征学习和重用的影响。

Result: 发现不同初始化选择将网络置于四种不同的微调机制：1）支持特征学习和重用；2）仅支持重用；3）仅支持学习；4）两者都不支持。较小初始化尺度（特别是早期层）能使网络同时重用和精炼特征，在依赖预训练特征子集的微调任务上实现更优泛化。在CIFAR-100非线性网络上的实验验证了相同结论。

Conclusion: 初始化参数与数据统计特性共同塑造微调泛化性能，不同层初始化尺度的相对大小在支持微调期间持续特征学习方面起着重要作用。较小初始化尺度能促进特征重用和精炼，为实际应用中的初始化策略提供理论指导。

Abstract: Pretraining and fine-tuning are central stages in modern machine learning systems. In practice, feature learning plays an important role across both stages: deep neural networks learn a broad range of useful features during pretraining and further refine those features during fine-tuning. However, an end-to-end theoretical understanding of how choices of initialization impact the ability to reuse and refine features during fine-tuning has remained elusive. Here we develop an analytical theory of the pretraining-fine-tuning pipeline in diagonal linear networks, deriving exact expressions for the generalization error as a function of initialization parameters and task statistics. We find that different initialization choices place the network into four distinct fine-tuning regimes that are distinguished by their ability to support feature learning and reuse, and therefore by the task statistics for which they are beneficial. In particular, a smaller initialization scale in earlier layers enables the network to both reuse and refine its features, leading to superior generalization on fine-tuning tasks that rely on a subset of pretraining features. We demonstrate empirically that the same initialization parameters impact generalization in nonlinear networks trained on CIFAR-100. Overall, our results demonstrate analytically how data and network initialization interact to shape fine-tuning generalization, highlighting an important role for the relative scale of initialization across different layers in enabling continued feature learning during fine-tuning.

</details>


### [157] [Training-Free Generative Modeling via Kernelized Stochastic Interpolants](https://arxiv.org/abs/2602.20070)
*Florentin Coeurdoux,Etienne Lempereur,Nathanaël Cuvelle-Magar,Thomas Eboli,Stéphane Mallat,Anastasia Borovykh,Eric Vanden-Eijnden*

Main category: cs.LG

TL;DR: 提出一种基于核方法的生成建模框架，用线性系统替代神经网络训练，通过求解P×P线性系统计算生成SDE的漂移项，支持多种特征映射实现免训练生成。


<details>
  <summary>Details</summary>
Motivation: 传统基于神经网络的生成模型需要大量训练，本文旨在开发一种免训练的生成建模方法，通过核方法和线性系统简化计算，同时保持生成质量。

Method: 在随机插值框架下，将生成SDE的漂移项表示为∇φ(x)⊤η_t，其中η_t通过求解与数据维度d无关的P×P线性系统获得。开发了处理最优扩散系数D_t*在t=0处发散问题的积分器。

Result: 该方法在金融时间序列、湍流和图像生成等任务上得到验证，能够实现免训练生成和模型组合，支持散射变换、预训练生成模型等多种特征映射。

Conclusion: 提出的核方法为生成建模提供了一种高效的免训练替代方案，通过线性系统替代神经网络训练，在保持生成质量的同时显著简化了计算复杂度。

Abstract: We develop a kernel method for generative modeling within the stochastic interpolant framework, replacing neural network training with linear systems. The drift of the generative SDE is $\hat b_t(x) = \nablaφ(x)^\topη_t$, where $η_t\in\R^P$ solves a $P\times P$ system computable from data, with $P$ independent of the data dimension $d$. Since estimates are inexact, the diffusion coefficient $D_t$ affects sample quality; the optimal $D_t^*$ from Girsanov diverges at $t=0$, but this poses no difficulty and we develop an integrator that handles it seamlessly. The framework accommodates diverse feature maps -- scattering transforms, pretrained generative models etc. -- enabling training-free generation and model combination. We demonstrate the approach on financial time series, turbulence, and image generation.

</details>


### [158] [BarrierSteer: LLM Safety via Learning Barrier Steering](https://arxiv.org/abs/2602.20102)
*Thanh Q. Tran,Arun Verma,Kiwan Wong,Bryan Kian Hsiang Low,Daniela Rus,Wei Xiao*

Main category: cs.LG

TL;DR: BarrierSteer：基于控制屏障函数在潜在空间嵌入非线性安全约束的LLM安全框架，无需修改模型参数即可高效防止不安全响应


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在各种任务中表现出色，但其对对抗攻击的脆弱性和不安全内容生成问题阻碍了在高风险场景中的部署。需要既实用有效又有理论支持的安全机制。

Method: BarrierSteer框架通过在模型的潜在表示空间中嵌入学习到的非线性安全约束来形式化响应安全性。使用控制屏障函数（CBFs）作为转向机制，在推理过程中高效检测和防止不安全响应轨迹。通过高效约束合并来强制执行多个安全约束，且不修改底层LLM参数。

Result: 实验表明BarrierSteer显著降低了对抗攻击成功率，减少了不安全生成，并且优于现有方法。理论结果证明在潜在空间应用CBFs提供了原则性且计算高效的安全执行方法。

Conclusion: BarrierSteer是一个既实用又理论严谨的LLM安全框架，通过控制屏障函数在潜在空间嵌入安全约束，能在保持模型原有能力的同时有效防止不安全内容生成，为高风险场景部署提供了可靠解决方案。

Abstract: Despite the state-of-the-art performance of large language models (LLMs) across diverse tasks, their susceptibility to adversarial attacks and unsafe content generation remains a major obstacle to deployment, particularly in high-stakes settings. Addressing this challenge requires safety mechanisms that are both practically effective and supported by rigorous theory. We introduce BarrierSteer, a novel framework that formalizes response safety by embedding learned non-linear safety constraints directly into the model's latent representation space. BarrierSteer employs a steering mechanism based on Control Barrier Functions (CBFs) to efficiently detect and prevent unsafe response trajectories during inference with high precision. By enforcing multiple safety constraints through efficient constraint merging, without modifying the underlying LLM parameters, BarrierSteer preserves the model's original capabilities and performance. We provide theoretical results establishing that applying CBFs in latent space offers a principled and computationally efficient approach to enforcing safety. Our experiments across multiple models and datasets show that BarrierSteer substantially reduces adversarial success rates, decreases unsafe generations, and outperforms existing methods.

</details>


### [159] [Reliable Abstention under Adversarial Injections: Tight Lower Bounds and New Upper Bounds](https://arxiv.org/abs/2602.20111)
*Ezra Edelman,Surbhi Goel*

Main category: cs.LG

TL;DR: 该论文研究了对抗注入模型中的在线学习，证明了分布无关算法存在Ω(√T)下界，并提出基于鲁棒见证者的框架，为二维半空间等类别提供分布无关学习保证。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，在对抗注入模型中，拥有分布信息的算法能达到O(d²logT)误差，而分布无关算法只能达到Õ(√T)。这种差距是否本质存在是开放问题，需要研究分布无关算法的理论极限。

Method: 提出基于鲁棒见证者的潜在框架，使用两种组合维度：(1) 推理维度，为推理维度k的类别提供Õ(T^{1-1/k})误差；(2) 新引入的证书维度。将该框架应用于二维半空间，证明其证书维度为3。

Result: 证明了VC维度为1的类别存在Ω(√T)下界，确立了两种信息机制间的尖锐分离。为二维半空间获得Õ(T^{2/3})的分布无关误差界，这是首次为该类别提供分布无关保证。

Conclusion: 对抗注入模型中分布无关算法确实存在根本性限制，但通过鲁棒见证者框架和证书维度等新工具，可以为半空间等重要类别提供实用的分布无关学习算法。

Abstract: We study online learning in the adversarial injection model introduced by [Goel et al. 2017], where a stream of labeled examples is predominantly drawn i.i.d.\ from an unknown distribution $\mathcal{D}$, but may be interspersed with adversarially chosen instances without the learner knowing which rounds are adversarial. Crucially, labels are always consistent with a fixed target concept (the clean-label setting). The learner is additionally allowed to abstain from predicting, and the total error counts the mistakes whenever the learner decides to predict and incorrect abstentions when it abstains on i.i.d.\ rounds. Perhaps surprisingly, prior work shows that oracle access to the underlying distribution yields $O(d^2 \log T)$ combined error for VC dimension $d$, while distribution-agnostic algorithms achieve only $\tilde{O}(\sqrt{T})$ for restricted classes, leaving open whether this gap is fundamental.
  We resolve this question by proving a matching $Ω(\sqrt{T})$ lower bound for VC dimension $1$, establishing a sharp separation between the two information regimes. On the algorithmic side, we introduce a potential-based framework driven by \emph{robust witnesses}, small subsets of labeled examples that certify predictions while remaining resilient to adversarial contamination. We instantiate this framework using two combinatorial dimensions: (1) \emph{inference dimension}, yielding combined error $\tilde{O}(T^{1-1/k})$ for classes of inference dimension $k$, and (2) \emph{certificate dimension}, a new relaxation we introduce. As an application, we show that halfspaces in $\mathbb{R}^2$ have certificate dimension $3$, obtaining the first distribution-agnostic bound of $\tilde{O}(T^{2/3})$ for this class. This is notable since [Blum et al. 2021] showed halfspaces are not robustly learnable under clean-label attacks without abstention.

</details>


### [160] [Adaptation to Intrinsic Dependence in Diffusion Language Models](https://arxiv.org/abs/2602.20126)
*Yunxiao Zhao,Changxiao Cai*

Main category: cs.LG

TL;DR: 提出一种分布无关的去掩码调度方法，通过随机化每次迭代揭示的token数量，自适应数据依赖结构，显著提升扩散语言模型的采样收敛速度。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型作为自回归方法的替代方案，支持并行token生成，但现有理论对去掩码调度如何影响生成质量的理解有限。需要一种无需先验知识或超参数调优的自适应调度方法。

Method: 提出分布无关的去掩码调度方法，随机化每次迭代揭示的token数量（而非固定大小）。该方法自适应目标数据分布的未知依赖结构，无需任何先验知识或超参数调整。

Result: 采样收敛保证（以KL散度衡量）分别按Õ(TC/K)和Õ(DTC/K)缩放，其中TC和DTC是目标分布的总相关和双重总相关。在K<L的并行采样机制下，显著优于先前收敛理论，对低复杂度分布实现大幅采样加速。

Conclusion: 研究揭示了扩散语言模型对内在数据结构的自适应性，阐明了随机化去掩码大小在推理调度设计中的优势，为高效并行采样提供了理论基础。

Abstract: Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) approaches, enabling parallel token generation beyond a rigid left-to-right order. Despite growing empirical success, the theoretical understanding of how unmasking schedules -- which specify the order and size of unmasked tokens during sampling -- affect generation quality remains limited. In this work, we introduce a distribution-agnostic unmasking schedule for DLMs that adapts to the (unknown) dependence structure of the target data distribution, without requiring any prior knowledge or hyperparameter tuning. In contrast to prior deterministic procedures that fix unmasking sizes, our method randomizes the number of tokens revealed at each iteration. We show that, for two specific parameter choices, the sampling convergence guarantees -- measured by Kullback-Leibler (KL) divergence -- scale as $\widetilde O(\mathsf{TC}/K)$ and $\widetilde O(\mathsf{DTC}/K)$ respectively. Here, $K$ is the number of iterations, and $\mathsf{TC}$ and $\mathsf{DTC}$ are the total correlation and dual total correlation of the target distribution, capturing the intrinsic dependence structure underlying the data. Importantly, our guarantees hold in the practically relevant parallel-sampling regime $K<L$ where $L$ is the token sequence length. These results significantly improve upon prior convergence theories and yield substantial sampling acceleration for low-complexity distributions. Overall, our findings unveil the adaptivity of DLMs to intrinsic data structures and shed light on the benefit of randomized unmasking sizes in inference schedule design.

</details>


### [161] [LAD: Learning Advantage Distribution for Reasoning](https://arxiv.org/abs/2602.20132)
*Wendi Li,Sharon Li*

Main category: cs.LG

TL;DR: LAD是一个新的强化学习框架，通过匹配优势分布而非最大化期望奖励，解决了传统方法过度拟合主导奖励信号、忽视有效推理轨迹多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大模型推理的强化学习目标主要关注最大化期望奖励，这会导致过度拟合主导奖励信号，忽视其他有效但非主导的推理轨迹，从而限制了多样性和探索能力。

Method: 提出学习优势分布(LAD)框架，将优势最大化替换为学习优势诱导的分布。通过建立最优策略更新与基于优势的目标分布之间的等价关系，推导出最小化策略诱导分布与优势诱导分布之间f-散度的LAD目标。

Result: 在受控赌博机设置中，LAD能够忠实恢复多模态优势分布；在数学和代码推理任务中，LAD可靠地提高了多个LLM骨干的准确性和生成多样性。

Conclusion: LAD通过分布匹配框架有效解决了传统强化学习过度拟合问题，无需额外训练成本即可提高推理任务的准确性和多样性，为大模型后训练提供了可扩展的解决方案。

Abstract: Current reinforcement learning objectives for large-model reasoning primarily focus on maximizing expected rewards. This paradigm can lead to overfitting to dominant reward signals, while neglecting alternative yet valid reasoning trajectories, thereby limiting diversity and exploration. To address this issue, we introduce Learning Advantage Distributions (LAD), a distribution-matching framework that replaces advantage maximization with learning the advantage-induced distribution. By establishing the equivalence between the optimal policy update and an advantage-based target distribution, we derive a practical LAD objective formulated as minimizing an $f$-divergence between the policy-induced and advantage-induced distributions. This yields a gradient update that increases likelihood for high-advantage responses while suppressing over-confident probability growth, preventing collapse without requiring auxiliary entropy regularization. LAD incurs no extra training cost compared to GRPO and scales naturally to LLM post-training. In a controlled bandit setting, LAD faithfully recovers the multimodal advantage distribution, validating the theoretical formulation. Experiments on math and code reasoning tasks across several LLM backbones show that LAD reliably improves both accuracy and generative diversity.

</details>


### [162] [Behavior Learning (BL): Learning Hierarchical Optimization Structures from Data](https://arxiv.org/abs/2602.20152)
*Zhenyao Ma,Yue Liang,Dongxu Li*

Main category: cs.LG

TL;DR: 提出行为学习（BL）框架，通过可解释的模块化组件学习优化结构，统一预测性能、内在可解释性和可识别性


<details>
  <summary>Details</summary>
Motivation: 受行为科学启发，旨在从数据中学习可解释且可识别的优化结构，适用于涉及优化的科学领域

Method: 参数化由内在可解释模块构建的组合效用函数，支持从单个效用最大化问题到层次组合的架构，平滑单调变体（IBL）保证可识别性

Result: 理论上证明BL的通用逼近性质，分析IBL的M估计特性；实证显示BL具有强预测性能、内在可解释性和高维数据可扩展性

Conclusion: BL是一个通用机器学习框架，通过学习可解释的优化结构，统一了预测性能、内在可解释性和可识别性，具有广泛科学应用前景

Abstract: Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and identifiable optimization structures from data, ranging from single optimization problems to hierarchical compositions. It unifies predictive performance, intrinsic interpretability, and identifiability, with broad applicability to scientific domains involving optimization. BL parameterizes a compositional utility function built from intrinsically interpretable modular blocks, which induces a data distribution for prediction and generation. Each block represents and can be written in symbolic form as a utility maximization problem (UMP), a foundational paradigm in behavioral science and a universal framework of optimization. BL supports architectures ranging from a single UMP to hierarchical compositions, the latter modeling hierarchical optimization structures. Its smooth and monotone variant (IBL) guarantees identifiability. Theoretically, we establish the universal approximation property of BL, and analyze the M-estimation properties of IBL. Empirically, BL demonstrates strong predictive performance, intrinsic interpretability and scalability to high-dimensional data. Code: https://github.com/MoonYLiang/Behavior-Learning ; install via pip install blnetwork.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [163] [Detecting Initial System-Environment Correlations from a Single Observable](https://arxiv.org/abs/2602.18516)
*Ali Abu-Nada,Russell Ceballos,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 提出一种通过监测单个系统可观测量来检测初始系统-环境关联的方法，无需全态层析或环境直接访问


<details>
  <summary>Details</summary>
Motivation: 现有检测初始系统-环境关联的方法通常需要全态层析或多重系统制备，实验要求高。本文旨在开发一种更简单的方法，仅通过监测单个系统可观测量就能检测初始关联

Method: 对于已知的相互作用，推导出所有因子化初始状态下系统期望值的精确边界，形成"因子化包络"。如果观测轨迹超出此包络，则证明存在初始关联。该方法基于标准乘积分配映射作为无关联准备的零模型

Result: 在三个相关初始状态族中观察到清晰的包络违反，包括系统状态最大混合的情况。方法还扩展到无限环境的纯退相干自旋-玻色子模型，其中因子化初始状态生成简单的相干包络

Conclusion: 单轴测量结合一次系统初始状态校准，无需层析或环境访问即可认证初始系统-环境关联，为实验检测初始关联提供了更简单的方法

Abstract: We address the problem of detecting initial system--environment correlations when the environment is not directly accessible. Most existing approaches rely on full state tomography or multiple system preparations, which can be experimentally demanding.
  We show that, for a known interaction, it can be sufficient to monitor a single expectation value of the system. Focusing on a qubit interacting with an environment via isotropic Heisenberg exchange, we derive exact bounds on the signal $z(t)=\langleσ_z^S\rangle(t)$ that hold for all factorized initial states. These bounds define a \emph{factorized envelope}: if an observed trajectory exits this envelope at any time, initial system--environment correlations are certified.
  From a reduced-dynamics perspective, the envelope admits a clear operational interpretation as the admissible region generated by the standard product assignment (embedding) map, which serves as a null model for uncorrelated preparations. Envelope violations therefore rule out the entire product-assignment class using only a single calibrated observable.
  We illustrate the method using three families of correlated initial states and observe clear envelope violations, including cases in which the reduced system state is maximally mixed. We further show that the same single-observable logic extends to an exactly solvable pure-dephasing spin--boson model with an infinite environment, where factorized initial states generate a simple coherence envelope whose violation certifies initial correlations. Overall, our results demonstrate that single-axis measurements, combined with a one-time calibration of $ρ_S(0)$, can certify initial system--environment correlations without tomography or environment access.

</details>


### [164] [Vapor Phase Assembly of Molecular Emitter Crystals for Photonic Integrated Circuits](https://arxiv.org/abs/2602.18517)
*Arya D. Keni,Christian M. Lange,Adhyyan S. Mansukhani,Emma Daggett,Ankit Kundu,Ishita Agarwal,Patrick Bak,Benjamin Cerjan,Jonathan D. Hood*

Main category: quant-ph

TL;DR: 开发了一种气相生长方法制备DBT掺杂蒽晶体，该晶体具有纳米级厚度、低表面粗糙度，分子跃迁保持窄线宽和光谱稳定性，适用于集成纳米光子学应用。


<details>
  <summary>Details</summary>
Motivation: 有机分子在有机基质中在低温下表现出寿命限制的光学相干性和明亮发射，但需要开发与集成纳米光子学兼容的制备方法，以实现片上单光子源和集体多发射体效应。

Method: 采用简单的气相生长方法合成光学薄的DBT掺杂蒽晶体，晶体厚度约200纳米，表面粗糙度低于纳米级，横向尺寸可调至200微米，掺杂密度可调至每平方微米数百个分子。

Result: 制备的晶体分子跃迁保持窄线宽和光谱稳定性，非均匀展宽低于100 GHz，与块体蒽中的DBT相当。晶体可微定位到集成光子器件上，分子偶极子与光学模式对齐。

Conclusion: 该方法为片上单光子源和集体多发射体效应开辟了新途径，实现了与集成纳米光子学兼容的有机分子掺杂晶体的制备和定位。

Abstract: Organic molecules embedded in an organic matrix exhibit lifetime-limited optical coherence and bright emission at cryogenic temperatures below 3 K. Here we present a simple vapor-phase growth method for synthesizing optically thin DBT-doped anthracene crystals that are compatible with integrated nanophotonics. The crystals are ~200 nm thick with sub-nm surface roughness and a tunable lateral dimension of up to 200 $μ$m. The molecular transitions remain narrow and spectrally stable, with inhomogeneous broadening below 100 GHz, comparable to DBT in bulk anthracene. The dopant density is tunable up to several hundred molecules per $μ$m$^2$, ensuring emitters within the near-field of nanophotonic structures. We demonstrate that the crystals can be micropositioned onto integrated photonic devices with the molecular dipole aligned to the optical mode. This approach opens a path toward on-chip single-photon sources and collective many-emitter effects.

</details>


### [165] [Time uncertainty and fundamental sensitivity limits in quantum sensing: application to optomechanical gravimetry](https://arxiv.org/abs/2602.18524)
*Salman Sajad Wani,Saif Al-Kuwari,Arshid Shabir,Paolo Vezio,Francesco Marino,Mir Faizal*

Main category: quant-ph

TL;DR: 该论文揭示了量子传感器中时间不确定性对测量灵敏度的固有影响，提出了考虑时间作为不确定参数的两参数量子费舍尔信息分析方法，并针对光机械重力仪给出了最优解耦条件。


<details>
  <summary>Details</summary>
Motivation: 现有高灵敏度加速度计和重力计研究都忽略了时间估计中的固有量子不确定性，这限制了测量灵敏度的极限。论文旨在解决这一根本问题，建立更全面的量子传感器理论框架。

Method: 从通用线性量子传感器的哈密顿量出发，推导两参数量子费舍尔信息矩阵，建立相应的克拉美-罗界，将时间作为不确定（干扰）参数处理。然后将该方法应用于光机械重力仪，在连续测量方案中推导最优解耦条件。

Result: 分析揭示了时间与信号估计之间的基本耦合会固有地降低测量灵敏度，标准单参数量子极限仅在特定询问时间或特殊解耦条件下才能恢复。针对光机械重力仪，找到了时间不确定性效应被平均掉的最优解耦条件。

Conclusion: 时间不确定性对量子传感器灵敏度有根本性影响，必须作为关键参数纳入分析。提出的两参数量子费舍尔信息方法具有普适性，可扩展到广泛的量子传感器类别，为实现测量灵敏度的最终极限提供了更完整的理论框架。

Abstract: High-sensitivity accelerometers and gravimeters, achieving the ultimate limits of measurement sensitivity are key tools for advancing both fundamental and applied physics. While numerous platforms have been proposed to achieve this goal, from atom interferometers to optomechanical systems, all of these studies neglect the effects of intrinsic quantum uncertainty in time estimation. Starting from the Hamiltonian of a generic linear quantum sensor, we derive the two-parameter quantum Fisher information matrix and establish the corresponding Cram'er-Rao bound, treating time as an uncertain (nuisance) parameter. Our analysis reveals a fundamental coupling between time and signal estimation that inherently degrades measurement sensitivity, with the standard single-parameter quantum limit recovered only at specific interrogation times or under special decoupling conditions. We then apply these results to an optomechanical gravimeter and explicitly derive an optimal decoupling condition under which the effects of time uncertainty are averaged out in a continuous measurement scheme. Our approach is general and can be readily extended to a broad class of quantum sensors.

</details>


### [166] [Trotter Error and Orbital Transformations in Quantum Phase Estimation](https://arxiv.org/abs/2602.18913)
*Marvin Kronenberger,Mihael Erakovic,Markus Reiher*

Main category: quant-ph

TL;DR: 研究轨道变换对Trotter误差的影响，发现局部轨道基不会产生大的Trotter误差，这对高效量子相位估计算法设置很重要。


<details>
  <summary>Details</summary>
Motivation: 虽然局部轨道基能降低量子电路深度，但文献指出它们会导致大的Trotter误差。本研究旨在探索通过轨道变换减少Trotter误差的方法。

Method: 研究了三种通过轨道变换减少Trotter误差的策略：(1) 先验选择产生低Trotter误差的轨道基；(2) 推导产生无Trotter误差基态能量的轨道基；(3) 在Trotter步骤间应用改变计算基的传播子。

Result: 数值结果显示，通过轨道变换可靠地减少Trotter误差具有挑战性，无法轻易推导出产生低Trotter误差的通用方法。重要发现是：在分子计算中，局部轨道基不会产生大的Trotter误差。

Conclusion: 局部轨道基不会导致大的Trotter误差，这对使用Trotter乘积公式的高效量子相位估计算法设置具有重要意义。虽然解析表达式暗示了减少Trotter误差的方法，但通过轨道变换可靠地减少误差仍然困难。

Abstract: Quantum computation with Trotter product formulae is straightforward and requires little overhead in terms of logical qubits. The choice of the orbital basis significantly affects circuit depth, with localised orbitals yielding lowest circuit depths. However, literature results point to large Trotter errors incurred by localised orbitals. Here, we therefore investigate the effect of orbital transformations on Trotter error. We consider three strategies to reduce Trotter error by orbital transformation: (i) The a priori selection of an orbital basis that produces low Trotter error. (ii) The derivation of an orbital basis that produces a ground state energy free of Trotter error (as we observed that the Trotter error is a continuous function in the Givens-rotation parameter, from which continuity of this error upon orbital transformation can be deduced). (iii) Application of propagators that change the computational basis between Trotter steps. Our numerical results show that reliably reducing Trotter error by orbital transformations is challenging. General recipes to produce low Trotter errors cannot be easily derived, despite analytical expressions which suggest ways to decrease Trotter error. Importantly, we found that localised orbital bases do not produce large Trotter errors in molecular calculations, which is an important result for efficient QPE set-ups.

</details>


### [167] [Engineering quantum criticality and dynamics on an analog-digital simulator](https://arxiv.org/abs/2602.18555)
*Alexandra A. Geim,Nazli Ugur Koyluoglu,Simon J. Evered,Rahul Sahay,Sophie H. Li,Muqing Xu,Dolev Bluvstein,Nik O. Gjonbalaj,Nishad Maskara,Marcin Kalinowski,Tom Manovitz,Ruben Verresen,Susanne F. Yelin,Johannes Feldmeier,Markus Greiner,Vladan Vuletic,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 利用中性原子阵列模拟器，通过里德堡-超精细量子比特的相干映射，结合模拟动力学与全可编程控制，实现了复杂量子动力学工程，并在271位点kagome晶格中观测到Rokhsar-Kivelson型非平衡临界量子自旋液体特征。


<details>
  <summary>Details</summary>
Motivation: 研究非平衡相互作用多体系统中的涌现现象是物理科学的前沿挑战。量子模拟器是解决这一问题的有前景方法，但实践中存在实现所需相互作用、测量任意可观测量和抑制误差等困难。

Method: 采用中性原子阵列模拟器，通过里德堡和超精细量子比特的相干映射，结合高效的模拟动力学与全可编程状态制备和测量。利用非破坏性读取实现损耗信息和原子量子比特重用，使用原子库替换丢失原子。通过这种模拟-数字混合方法，首先展示Floquet驱动下的环交换和粒子跳跃动力学工程，并通过演化初始叠加态测量单激发的谱函数。在271位点kagome晶格中，采用闭环优化靶向Rokhsar-Kivelson型非平衡临界量子自旋液体。

Result: 成功实现了复杂量子动力学的工程化控制，在kagome晶格中观测到Rokhsar-Kivelson型量子自旋液体的关键特征：缺乏局域序、在多达18个位点上的近等幅二聚体构型间的多体相干性，以及与场论预测一致的普适关联。

Conclusion: 这些结果为利用模拟-数字量子模拟器中的动力学控制研究复杂量子多体系统开辟了新途径，展示了混合方法在量子模拟中的强大能力。

Abstract: Understanding emergent phenomena in out-of-equilibrium interacting many-body systems is an exciting frontier in physical science. While quantum simulators represent a promising approach to this long-standing problem, in practice it can be challenging to directly realize the required interactions, measure arbitrary observables, and mitigate errors. Here we use coherent mapping between the Rydberg and hyperfine qubits in a neutral atom array simulator to engineer and probe complex quantum dynamics. We combine efficient analog dynamics with fully programmable state preparation and measurement, leverage non-destructive readout for loss information and atomic qubit reuse, and use an atom reservoir for replacing lost atoms. With this analog-digital approach, we first demonstrate dynamical engineering of ring-exchange and particle hopping dynamics via Floquet driving and measure the spectral function of single excitations by evolving initial superposition states. Extending these techniques to a 271-site kagome lattice, we employ closed-loop optimization to target an out-of-equilibrium critical quantum spin liquid of the Rokhsar-Kivelson type. We observe the key features of such a state, including the absence of local order, many-body coherences between nearly equal-amplitude dimer configurations over up to 18 sites, and universal correlations consistent with predictions from field theory. Together, these results pave the way for using dynamical control in analog-digital quantum simulators to study complex quantum many-body systems.

</details>


### [168] [Controlling emergent dynamical behavior via phase-engineered strong symmetries](https://arxiv.org/abs/2602.18563)
*Marc Nairn,Beatriz Olmos,Parvinder Solanki*

Main category: quant-ph

TL;DR: 通过调节腔QED系统中集体光-物质耦合的可调相位，实现了对开放量子系统动力学的控制，显著降低了耗散相变的临界驱动强度


<details>
  <summary>Details</summary>
Motivation: 对称性约束为控制开放量子系统动力学提供了强大手段，但可访问的控制参数通常有限。本文探索如何通过调节集体光-物质耦合中的相位来实现对开放量子系统动力学的动态控制

Method: 在腔QED系统中引入集体光-物质耦合的可调相位，该相位诱导了Liouvillian算符的相位依赖强对称性。在两个实验相关的腔QED设置中验证：双物种两能级原子系综和单物种三能级原子系综

Result: 调节该相位显著降低了从稳态到非稳态相变的临界驱动强度，为耗散相变工程提供了新的控制手段

Conclusion: 相位控制是工程耗散相变的多功能工具，对量子态制备具有重要意义，为开放量子系统的动力学控制提供了新途径

Abstract: Symmetry constraints provide a powerful means to control the dynamics of open quantum systems. However, the set of accessible control parameters is often limited. Here, we show that a tunable phase in the collective light-matter coupling of a cavity QED system induces a phase-dependent strong symmetry of the Liouvillian, enabling dynamical control of the open quantum system evolution. We demonstrate that tuning this phase substantially reduces the critical driving strength for dissipative phase transitions between stationary and non-stationary phases. We illustrate this mechanism in two experimentally relevant cavity QED settings: a two-species ensemble of two-level atoms and a single-species ensemble of three-level atoms. Our results establish phase control as a versatile tool for engineering dissipative phase transitions, with implications for quantum state preparation.

</details>


### [169] [Four- and six-photon stimulated Raman transitions for coherent qubit and qudit operations](https://arxiv.org/abs/2602.18567)
*Gabriel J. Gregory,Evan R. Ritchie,Alex Quinn,Sean Brudney,David J. Wineland,David T. C. Allcock,Jameson O'Reilly*

Main category: quant-ph

TL;DR: 在单个囚禁原子中通过四光和六光受激拉曼跃迁实现了Δm_J=3,4,5的电子角动量态间跃迁


<details>
  <summary>Details</summary>
Motivation: 开发高效、高保真度的量子比特控制工具，为qudit和单原子逻辑量子比特操作提供新方法

Method: 使用四光和六光受激拉曼跃迁，通过绝热消除中间态的标准双光子跃迁处理方法推导拉比频率

Result: 实验验证了Δm_J=3,4,5的电子角动量态间跃迁，并讨论了将多光子跃迁保真度提升至>99.99%的途径

Conclusion: 该方法为高效高保真度的qudit和单原子逻辑量子比特控制提供了有力工具

Abstract: We experimentally demonstrate transitions between electronic angular momentum states with a difference in magnetic quantum numbers $Δ\mathrm{m_J} = $ 3, 4, and 5 via resonant four- and six-photon stimulated Raman transitions in a single trapped atom. Derivation of the corresponding Rabi frequencies, which are verified experimentally, follows the standard treatment of two-photon transitions including the adiabatic elimination of intermediate states. Finally, we discuss pathways to increase the observed multi-photon transition fidelities to $>99.99\%$, providing a tool for efficient, high-fidelity control of qu\textit{d}its and single-atom logical qubits.

</details>


### [170] [Auto Quantum Machine Learning for Multisource Classification](https://arxiv.org/abs/2602.18642)
*Tomasz Rybotycki,Sebastian Dziura,Piotr Gawron*

Main category: quant-ph

TL;DR: 提出自动化量子机器学习(AQML)方法用于数据融合任务，在ONERA多光谱数据集上实现比现有QML方法更好的变化检测精度


<details>
  <summary>Details</summary>
Motivation: 随着容错量子计算的发展，量子计算方法在遥感等数据密集型科学领域应用潜力巨大。量子数据融合作为复杂数据分析问题受到关注，需要探索量子机器学习在其中的应用

Method: 引入自动化量子机器学习(AQML)方法，自动生成量子电路来处理多源输入数据，并与经典多层感知器(MLP)和手动设计的QML模型进行对比

Result: 在ONERA多光谱数据集的变化检测任务中，AQML方法取得了比之前报道的QML方法更高的准确率

Conclusion: 自动化量子机器学习方法在数据融合任务中表现出潜力，能够生成优于手动设计的量子电路，为量子计算在遥感等领域的应用提供了新途径

Abstract: With fault-tolerant quantum computing on the horizon, there is growing interest in applying quantum computational methods to data-intensive scientific fields like remote sensing. Quantum machine learning (QML) has already demonstrated potential for such demanding tasks. One area of particular focus is quantum data fusion -- a complex data analysis problem that has attracted significant recent attention. In this work, we introduce an automated QML (AQML) approach for addressing data fusion challenges. We evaluate how AQML-generated quantum circuits perform compared to classical multilayer perceptrons (MLPs) and manually designed QML models when processing multisource inputs. Furthermore, we apply our method to change detection using the multispectral ONERA dataset, achieving improved accuracy over previously reported QML-based change detection results.

</details>


### [171] [Higher-order circuits](https://arxiv.org/abs/2602.18701)
*Matt Wilson*

Main category: quant-ph

TL;DR: 该论文提出了高阶电路图的基本定律，通过范畴论方法（富集和余张量）形式化高阶量子理论，并发现任何高阶电路理论都能嵌入到强profunctor理论中。


<details>
  <summary>Details</summary>
Motivation: 为严格的高阶电路图建立系统化的理论基础，形式化高阶量子理论中的关键特征，包括嵌套、时空组合以及不同阶过程之间的等价关系。

Method: 使用范畴论方法，在对称多范畴中通过富集和余张量定义高阶电路理论，引入类似Frobenius结构的相干性，并建立低阶二分过程与高阶二分态之间的等价关系。

Result: 成功建立了高阶电路理论的基本定律体系，发现任何高阶电路理论都能嵌入到强profunctor理论中，为高阶量子理论提供了严格的数学基础。

Conclusion: 该工作为高阶电路图提供了系统的范畴论框架，揭示了高阶量子理论的结构特征，并证明了强profunctor理论作为高阶电路理论的通用上界。

Abstract: We write down a series of basic laws for (strict) higher-order circuit diagrams. More precisely, we define higher-order circuit theories in terms of: (a) nesting, (b) temporal and spatial composition, and (c) equivalence between lower-order bipartite processes and higher-order bipartite states. In category-theoretic terms, these laws are expressed using enrichment and cotensors in symmetric polycategories, along with a frobenius-like coherence between them. We describe how these laws capture the salient features of higher-order quantum theory, and discover an upper bound for higher-order circuits: any higher-order circuit theory embeds into the theory of strong profunctors.

</details>


### [172] [Hierarchies of Gaussian multimode entanglement from thermodynamic quantifiers](https://arxiv.org/abs/2602.18816)
*Mrinmoy Samanta,Sudipta Mondal,Ayan Patra,Saptarshi Roy,Aditi Sen De*

Main category: quant-ph

TL;DR: 该论文开发了连续变量系统中多模纠缠的热力学表征方法，通过全局和局域可提取功（ergotropy）的差距来量化纠缠，证明了2-局域ergotropic差距是忠实纠缠单调量，并引入了k-ergotropic分数来量化多模纠缠。


<details>
  <summary>Details</summary>
Motivation: 研究动机是建立多模连续变量系统中纠缠的热力学表征框架，将量子纠缠与在局域性约束下的功提取能力联系起来，提供可计算且实验可访问的量化方法。

Method: 通过比较全局和局域可提取功（ergotropy）来量化纠缠差距，定义了2-局域ergotropic差距作为纠缠单调量，并引入k-ergotropic分数来表征多模纠缠。对纯高斯态进行理论分析，推导闭合形式关系。

Result: 证明了2-局域ergotropic差距是忠实纠缠单调量，是Renyi-2纠缠熵的上界；k-ergotropic分数能忠实量化k分割下的多模纠缠；对三模高斯态得到了与几何度量的闭合关系；对多于三模系统，该度量与标准几何度量功能独立。

Conclusion: 该研究揭示了高斯多模纠缠与局域约束下功提取之间的操作层次关系，为量子关联表征提供了可计算且实验可访问的热力学框架。

Abstract: We develop a thermodynamic characterization of multimode entanglement in pure continuous-variable systems by quantifying the gap between globally and locally extractable work (ergotropy). For arbitrary pure multimode Gaussian states, we prove that the $2$-local ergotropic gap is a faithful entanglement monotone across any bipartition and constitutes a functionally independent upper bound to the Renyi-2 entanglement entropy. We further introduce the $k$-ergotropic score, the minimum $k$-local ergotropic gap, and show that it faithfully quantifies multimode entanglement across $k$ partitions. For pure three-mode Gaussian states, we derive its closed-form relation with the geometric measure for genuine multimode entanglement $(k=2)$, and total Gaussian multimode entanglement $(k=3)$. For systems with more than three modes, the $k$-ergotropic score becomes a functionally independent measure of multimode entanglement to the standard geometric measures. Our results reveal a direct operational hierarchy linking Gaussian multimode entanglement to work extraction under locality constraints, and provide a computable and experimentally accessible thermodynamic framework for characterizing quantum correlations.

</details>


### [173] [Frozen and Growing Quantum Work under Noise: Coherence and Correlations as Key Resources](https://arxiv.org/abs/2602.18860)
*Mohammad B. Arjmandi*

Main category: quant-ph

TL;DR: 研究量子系统在马尔可夫噪声下功提取的分解，发现噪声可增强相干功提取，挑战了噪声纯有害的传统观点


<details>
  <summary>Details</summary>
Motivation: 传统观点认为噪声对量子系统有害，但本研究探索噪声是否可能辅助能量存储，特别是在量子电池背景下

Method: 将ergotropy分解为不相干和相干贡献，分析单比特系统，研究两类可分离两比特态在局部噪声下的行为，扩展到多比特系统

Result: 发现相干ergotropy在特定噪声条件下可冻结或增强，对于具有局部相干性的可分离态，所有考虑的噪声通道都能增强相干ergotropy，多比特系统中增强幅度和范围随比特数增加

Conclusion: 噪声可辅助能量存储，挑战了噪声纯有害的传统观点，表明噪声辅助增强与基于纠缠的快速充电机制在量子电池中可能兼容

Abstract: We investigate the decomposition of ergotropy into incoherent and coherent contributions for quantum systems subject to typical Markovian noise channels. The incoherent part originates from population inversion in the energy eigenbasis after dephasing, while the coherent part captures the role of quantum coherence in work extraction. For single-qubit systems, we derive explicit conditions for freezing and enhancement of coherent ergotropy and obtain an analytical upper bound, showing that it cannot exceed one half of the state's quantum coherence. We then study two classes of separable two-qubit states under local noise. For Bell-diagonal states, which are locally completely passive and possess no local coherence, we prove that the total extractable work equals the average of geometric quantum and classical correlations. In this case, coherent ergotropy cannot be enhanced, although freezing occurs under specific noise conditions. By contrast, for separable states with local coherence, coherent ergotropy can increase under all considered noise channels, including phase-flip and depolarizing noise. Extending the analysis to multipartite systems, we show that both the magnitude and range of noise-induced enhancement grow with the number of qubits, indicating collective reinforcement. Finally, we demonstrate through an explicit example that entanglement does not prevent this enhancement: coherent ergotropy may increase under noise even for entangled states. Our results reveal that noise can assist energy storage, challenging the conventional view of noise as purely detrimental and suggesting compatibility between noise-assisted enhancement and fast entanglement-based charging mechanisms in quantum batteries.

</details>


### [174] [Why measurements are made of effects](https://arxiv.org/abs/2602.18898)
*Tobias Fritz*

Main category: quant-ph

TL;DR: 本文提出了广义测量理论(GMT)作为物理理论的数学框架，证明了在概率态能区分测量的GMT中，测量由效应组成，并讨论了经典GMT的条件。


<details>
  <summary>Details</summary>
Motivation: 在量子理论和一般概率理论中，具有n个结果的测量被建模为n个效应之和等于单位效应。本文旨在探讨这一假设是否必要，以及能否有意义地放宽这一条件。

Method: 开发了广义测量理论(GMT)作为物理理论的数学框架，该框架与一般概率理论互补。定义了GMT上的概率态，并证明在概率态能区分测量的GMT中，测量由效应组成。

Result: 证明了在概率态能区分测量的GMT中，测量确实由效应组成。同时，将强经典和投影的GMT特征化为对应于布尔代数的理论。

Conclusion: GMT提供了一个研究测量结构的基础框架。在物理上合理的分离条件下，测量确实由效应组成。布尔代数对应的GMT是强经典和投影的，这为理解经典性提供了数学基础。

Abstract: Both in quantum theory and in general probabilistic theories, measurements with $n$ outcomes are modelled as $n$-tuples of \emph{effects} summing up to the unit effect. Why is this the case, and can this assumption be meaningfully relaxed? Here we develop \emph{generalized measurement theories (GMTs)} as a mathematical framework for physical theories that is complementary to general probabilistic theories, and where this kind of question can be made precise and answered. We then give a definition of \emph{probabilistic state} on a GMT, prove that measurements are made of effects in every GMT in which the probabilistic states separate the measurements, and also argue that this separation condition is physically well-motivated. Finally, we also discuss when a GMT should be considered classical and characterize GMTs corresponding to Boolean algebras as those that are strongly classical and projective.

</details>


### [175] [Integrable cascaded frequency conversion using the time rescaling shortcut to adiabaticity](https://arxiv.org/abs/2602.18930)
*J. L. Montenegro Ferreira*

Main category: quant-ph

TL;DR: 该论文提出了一种结合STIRAP协议和时间重标度方法的TR-STIRAP协议，用于实现全频率转换，显著缩短了所需传播距离，并简化了实验实现。


<details>
  <summary>Details</summary>
Motivation: 传统STIRAP协议在光学系统中实现全频率转换需要很长的传播距离（在体晶体或波导中），这限制了器件的集成化和实际应用。需要找到一种方法能在更短的器件中实现高效频率转换。

Method: 1. 将两个同时发生的三波混频过程的耦合方程表示为STIRAP-like系统；2. 将时间重标度（TR）方法修改以适应光学系统；3. 将TR方法应用于转换过程，创建TR-STIRAP协议；4. 用高斯函数近似TR-STIRAP所需的耦合系数整形，简化实验实现。

Result: TR-STIRAP协议能够实现全频率转换，且所需传播距离仅为传统STIRAP协议的一小部分。高斯函数近似能够以高转换保真度实现耦合系数整形，简化了实验实施。

Conclusion: TR-STIRAP协议为光学频率转换提供了一种高效、紧凑的解决方案，具有在光子源集成和量子密钥分发高效探测器等多个领域的应用潜力。

Abstract: In this letter we explore how full frequency conversion can be performed in shorter, integrable devices by using a STIRAP-like protocol modified by the time rescaling shortcut to adiabaticity. We show how the coupled equations for two simultaneous three-wave mixing processes can be written in terms of a STIRAP-like system, which creates robust conversion, albeit requiring long propagation distances inside a bulk crystal or waveguide. We then discuss how the time rescaling (TR) method can be modified to be applied in optical systems, then apply it in the conversion process to create a TR-STIRAP protocol, showing that full conversion is also obtained, but at a fraction of the propagation distance. We also show how the original shaping of the coupling coefficients required by the TR-STIRAP can be approximated by gaussian functions with high conversion fidelity, thus simplifying the experimental implementation. This protocol has the potential to be used in several areas, including the integration of photon sources and efficient detectors for quantum key distribution.

</details>


### [176] [Predicting Magic from Very Few Measurements](https://arxiv.org/abs/2602.18939)
*J. M. Varela,L. L. Keller,A. de Oliveira Junior,D. A. Moreira,R. Chaves,R. A. Macêdo*

Main category: quant-ph

TL;DR: 提出一个通用框架，通过任意包含反对易对的Pauli测量集合来见证和量化非稳定子性，算法复杂度在测量数m上指数级但在量子比特数n上多项式级，并证明相关决策问题是NP-hard。


<details>
  <summary>Details</summary>
Motivation: 非稳定子性是通用量子计算的必要资源，但其表征通常需要指数级测量和双指数级经典后处理成本，现有方法计算代价过高。

Method: 将稳定子多面体投影到由任意包含反对易对的Pauli测量集合定义的子空间，提出从Pauli期望值估计魔法的算法，复杂度为O(exp(m) × poly(n))，并将问题关联到量子边际问题的稳定子限制变体。

Result: 证明除非P=NP，否则不存在多项式时间算法能完全解决该问题，建立了基本复杂性理论限制；在不同哈密顿基态中计算非稳定子性，展示了方法在现有技术无法达到的区域的实用性能。

Conclusion: 非稳定子性在很大程度上取决于观察者的视角，可以通过任意包含反对易对的Pauli测量集合来见证和量化，为高效表征量子魔法提供了新框架，同时揭示了其固有的计算复杂性限制。

Abstract: The nonstabilizerness of quantum states is a necessary resource for universal quantum computation, yet its characterization is notoriously demanding. Quantifying nonstabilizerness typically requires an exponential number of measurements and a doubly exponential classical post-processing cost to evaluate its standard monotones. In this work, we show that nonstabilizerness is, to a large extent, in the eyes of the beholder: it can be witnessed and quantified using any set of $m$ $n$-qubit Pauli measurements, provided the set contains anti-commuting pairs. We introduce a general framework that projects the stabilizer polytope onto the subspace defined by these observables and provide an algorithm that estimates magic from Pauli expectation values with runtime exponential in the number of measurements $m$ and polynomial in the number of qubits $n$. By relating the problem to a stabilizer-restricted variant of the quantum marginal problem, we also prove that deciding membership in the corresponding reduced stabilizer polytope is NP-hard. In particular, unless $\mathrm{P} = \mathrm{NP}$, no algorithm polynomial in $m$ can solve the problem in full generality, thus establishing fundamental complexity-theoretic limitations. Finally, we employ our framework to compute nonstabilizerness in different Hamiltonian ground states, demonstrating the practical performance of our method in regimes beyond the reach of existing techniques.

</details>


### [177] [Co-Propagation of Quantum Time Synchronization and Optical Frequency Transfer over a 122 km Hollow-Core Fiber](https://arxiv.org/abs/2602.19013)
*Huibo Hong,Xiao Xiang,Runai Quan,Rongduo Lu,Qian Zhou,Dawei Ge,Liuyan Han,Bo Liu,Ru Yuan,Dechao Zhang,Yuting Liu,Bingke Shi,ZhiGuang Xia,Xinghua Li,Mingtao Cao,Tao Liu,Ruifang Dong,Shougang Zhang*

Main category: quant-ph

TL;DR: 利用空芯光纤的超低非线性特性抑制自发拉曼散射噪声，在122公里光纤链路上同时传输量子时间同步和经典光频传输信号，实现了量子-经典信号共存传输的重大突破。


<details>
  <summary>Details</summary>
Motivation: 量子网络需要量子信号与经典信号在同一光纤中共传，但经典信号的强光会产生自发拉曼散射噪声，严重干扰单光子级的量子信号传输，这是长期存在的技术瓶颈。

Method: 采用空芯光纤（HCF）利用其固有的超低非线性特性来抑制自发拉曼散射噪声。将量子时间同步（QTS）和经典光频传输（OFT）信号都设置在电信C波段，波长仅相差约10纳米，在122公里HCF链路上进行同时传输实验。

Result: 在1 mW经典功率下，QTS性能几乎无退化，保持亚皮秒级时间稳定性（2000秒），OFT达到10^-20的分数频率不稳定性。即使经典功率增至3 mW，QTS仍保持近亚皮秒稳定性。模拟显示，采用下一代低损耗HCF可耐受超过10 mW的经典功率，QTS传输距离可扩展至500公里以上。

Conclusion: 通过实现统一的量子-经典时频分发框架，该工作确立了空芯光纤作为未来可扩展量子网络的高性能实用平台，解决了量子与经典信号共传的根本限制。

Abstract: The co-propagation of quantum and classical signals through shared optical fibers is crucial for scalable quantum networks. However, this coexistence is fundamentally limited by spontaneous Raman scattering (SpRS) from the bright classical light, which generates overwhelming noise that disrupts the single-photon-level quantum signals. Here, we overcome this long-standing challenge by leveraging the inherently ultralow nonlinearity of hollow-core fiber (HCF) to suppress SpRS noise. By operating both the quantum time synchronization (QTS) and classical optical frequency transfer (OFT) signals within the telecom C-band, separated by only ~10 nm, we successfully demonstrate their simultaneous transmission over a 122-km HCF link. With a classical OFT power of 1 mW, the QTS performance shows negligible degradation, maintaining sub-picosecond time stability at 2000 s, while the OFT achieves a fractional frequency instability of 10^-20. Near-sub-picosecond QTS stability is preserved even when the classical power is increased to 3 mW. Furthermore, simulations based on our experimental data indicate that with next-generation low-loss HCF, the platform can tolerate classical powers beyond 10 mW and extend the QTS range to over 500 km. By realizing a unified quantum-classical time-frequency distribution framework, this work establishes HCF as a highly capable and practical platform for future scalable quantum networks.

</details>


### [178] [Exceptional Point Superradiant Lasing with Ultranarrow Linewidth](https://arxiv.org/abs/2602.19030)
*Min Du,Qian Bin,Qing-Yang Qiu,Franco Nori,Xin-You Lü*

Main category: quant-ph

TL;DR: 利用PT对称系统的异常点特性，实现μHz级超窄线宽的超辐射激光，提升原子钟稳定性


<details>
  <summary>Details</summary>
Motivation: 超窄线宽的超辐射激光对提高量子精密测量中原子钟的稳定性至关重要，但传统系统难以同时实现窄线宽和高功率

Method: 采用PT对称系统的异常点特性，在光学晶格钟跃迁中非相干泵浦超冷锶-87原子，使原子相干性在异常点达到最大值

Result: 实现了μHz量级的超窄线宽超辐射激光，线宽比无异常点系统小三个数量级，同时保持高功率水平

Conclusion: 通过引入异常点特性扩展了超辐射激光的研究领域，为开发具有卓越稳定性和精度的原子钟提供了有前景的应用

Abstract: Achieving superradiant lasing with an ultranarrow linewidth is crucial for enhancing atomic clock stability in quantum precision measurement. By employing the exceptional point (EP) property of the system, we demonstrate theoretically superradiant lasing with linewidths in the $μ$Hz range, sustained at the high-power level. This is achieved by incoherently pumping optical lattice clock transitions with ultracold alkaline-earth strontium-87 atoms in the EP of a $\mathcal{PT}$-symmetric system. Physically, the atomic coherence reaches a maximum in the EP, significantly amplifying the superradiance effect and resulting in superradiant lasing with an ultranarrow linewidth. This linewidth is even three orders of magnitude smaller than that of superradiant lasing in the systems without EP. Our work extends the realm of superradiant lasing by introducing the EP property, and offers promising applications for developing atomic clocks with exceptional stability and accuracy.

</details>


### [179] [Quantum Error Correction and Dynamical Decoupling: Better Together or Apart?](https://arxiv.org/abs/2602.19042)
*Victor Kasatkin,Mario Morford-Oberst,Arian Vezvaee,Daniel A. Lidar*

Main category: quant-ph

TL;DR: 论文分析了量子纠错(QEC)与逻辑动态解耦(LDD)的混合协议，推导了性能表达式，给出了混合协议优于单独使用QEC的条件，并通过数值模拟验证了结果。


<details>
  <summary>Details</summary>
Motivation: 量子纠错和动态解耦都是保护量子信息的工具，但它们的组合并不总是自动带来优势。物理DD可能与编码子空间冲突，而QEC性能取决于解码后存留的误差而非DD抑制的误差。因此需要研究如何有效结合两者。

Method: 提出混合内存周期：首先使用稳定子码的正规化元素实现逻辑动态解耦(LDD)，然后进行一轮综合征测量和恢复（在检测设置中，基于平凡综合征进行后选择）。在有效泡利模型中，推导了QEC-only、LDD-only、物理DD和混合LDD+QEC协议的纠缠保真度闭式表达式，通过少量码相关权重枚举多项式表示。

Result: 对于理想恢复，LDD+QEC优于QEC-only的条件是：在LDD抑制扇区中不可纠正泡利误差的条件分数大于未抑制扇区。在低噪声区域，保证混合优势的充分设计规则是：LDD至少抑制一个针对所选恢复映射的最小权重不可纠正泡利误差。通过[[7,1,3]] Steane码和[[13,1,3]]码的数值结果，绘制了参数空间中混合协议优势区域。

Conclusion: 研究表明需要协同设计码、解码器和逻辑解耦群，并阐明了混合LDD+QEC协议具有优势的条件。逻辑动态解耦与量子纠错的结合需要仔细设计才能实现性能提升。

Abstract: Quantum error correction (QEC) and dynamical decoupling (DD) are tools for protecting quantum information. A natural goal is to combine them to outperform either approach alone. Such a benefit is not automatic: physical DD can conflict with an encoded subspace, and QEC performance is governed by the errors that survive decoding, not necessarily those DD suppresses. We analyze a hybrid memory cycle where DD is implemented logically (LDD) using normalizer elements of an $[[n,k,d]]$ stabilizer code, followed by a round of syndrome measurement and recovery (or, in the detection setting, postselection on a trivial syndrome). In an effective Pauli model with physical error probability $p$, LDD suppression factor $p_{DD}$, and recovery imperfection rate $p_{QEC}$ (or $p_{QED}$), we derive closed-form entanglement-fidelity expressions for QEC-only, LDD-only, physical DD, and the hybrid LDD+QEC protocol. The formulas are expressed via a small set of code-dependent weight enumerator polynomials, making the role of the decoder and the LDD group explicit. For ideal recovery LDD+QEC outperforms QEC-only iff the conditional fraction of uncorrectable Pauli errors is larger in the LDD-suppressed sector than in the unsuppressed sector. In the low-noise regime, a sufficient design rule guaranteeing hybrid advantage is that LDD suppresses at least one minimum-weight uncorrectable Pauli error for the chosen recovery map. We show how stabilizer-equivalent choices of LDD generators can be used to enforce this condition. We supplement our analysis with numerical results for the $[[7,1,3]]$ Steane code and a $[[13,1,3]]$ code, mapping regions of hybrid-protocol advantage in parameter space beyond the small-$p$ regime. Our work illustrates the need for co-design of the code, decoder, and logical decoupling group, and clarifies the conditions under which the hybrid LDD+QEC protocol is advantageous.

</details>


### [180] [Structural Analysis of Directional qLDPC Codes](https://arxiv.org/abs/2602.19057)
*Mohammad Rowshan*

Main category: quant-ph

TL;DR: 本文为方向码开发了系统的"词优先"分析框架，通过方向词W推导支持模式P(W)，建立了完整的理论体系，包括闭式映射、奇偶性分类、等价规范化和逆问题求解等。


<details>
  <summary>Details</summary>
Motivation: 方向码是基于硬件实现的量子LDPC码，但缺乏系统的理论分析框架。本文旨在为基于方形或六边形网格的平移不变CSS码建立完整的数学分析工具。

Method: 提出"词优先"分析框架：1) 建立方向词W到有限支持模式P(W)的闭式映射；2) 通过奇多重性差格L(W)分类X/Z布局；3) 建立有限环面可容许性准则；4) 发展词等价和规范化理论；5) 解决逆问题；6) 应用准循环约简分析边界条件敏感性。

Result: 1) 建立了完整的理论分析体系；2) 对W=NE²NE²N进行案例研究，给出显式稳定子依赖关系；3) 发现薄矩形(2d,d)上维度k=4当且仅当6整除d，否则k=0的精确判据。

Conclusion: 本文为方向码提供了系统的数学分析框架，解决了词到支持模式的映射、布局分类、边界条件敏感性等核心问题，为硬件友好的量子纠错码设计提供了理论基础。

Abstract: Directional codes, recently introduced by Gehér--Byfield--Ruban \cite{Geher2025Directional}, constitute a hardware-motivated family of quantum low-density parity-check (qLDPC) codes. These codes are defined by stabilizers measured by ancilla qubits executing a fixed \emph{direction word} (route) on square- or hex-grid connectivity. In this work, we develop a comprehensive \emph{word-first} analysis framework for route-generated, translation-invariant CSS codes on rectangular tori. Under this framework, a direction word $W$ deterministically induces a finite support pattern $P(W)$, from which we analytically derive: (i)~a closed-form route-to-support map; (ii)~the odd-multiplicity difference lattice $L(W)$ that classifies commutation-compatible $X/Z$ layouts; and (iii)~conservative finite-torus admissibility criteria. Furthermore, we provide: (iv)~a rigorous word equivalence and canonicalization theory (incorporating dihedral lattice symmetries, reversal/inversion, and cyclic shifts) to enable symmetry-quotiented searches; (v)~an ``inverse problem'' criterion to determine when a translation-invariant support pattern is realizable by a single route, including reconstruction and non-realizability certificates; and (vi)~a quasi-cyclic (group-algebra) reduction for row-periodic layouts that explains the sensitivity of code dimension $k$ to boundary conditions. As a case study, we analyze the word $W=\texttt{NE$^2$NE$^2$N}$ end-to-end. We provide explicit stabilizer dependencies, commuting-operator motifs, and an exact criterion for dimension collapse on thin rectangles: for $(L_x, L_y) = (2d, d)$ with row alternation, we find $k=4$ if $6 \mid d$, and $k=0$ otherwise.

</details>


### [181] [Near-perfect Noisy Quantum State Teleportation](https://arxiv.org/abs/2602.19103)
*Md Manirul Ali,Sovik Roy,Dipankar Home*

Main category: quant-ph

TL;DR: 提出一种在噪声环境下实现接近单位保真度的量子隐形传态协议，通过Alice根据Bob的本地噪声参数调整贝尔基测量时机，并丢弃部分测量结果来最大化保真度。


<details>
  <summary>Details</summary>
Motivation: 在噪声环境中实现高保真度的量子隐形传态对于实际应用至关重要。传统方法受限于本地噪声的影响，需要设计能够抵抗噪声干扰的新协议。

Method: 设计了一种独特的协议：1) Alice根据Bob的本地噪声参数调整贝尔基测量时机；2) Alice只向Bob传输在Alice端对共同退相干具有退相干自由性的两种测量结果；3) Bob丢弃另外两种测量结果对应的量子比特状态。该方法适用于非马尔可夫退相干噪声下的任意两能级量子系统。

Result: 该协议能够实现接近单位保真度的量子隐形传态，且保真度与Alice端的噪声参数无关。即使使用纠缠度较小的资源态，也能实现高保真度。在Werner态的局部区域（不违反贝尔-CHSH不等式）也能保持显著高的保真度。

Conclusion: 提出了一种在噪声环境下实现高保真度量子隐形传态的有效协议，该协议对Alice端噪声具有鲁棒性，且适用于多种资源态。使用光子量子比特的实验可行性也得到了讨论。

Abstract: Achieving high fidelity of quantum teleportation (QT) in a noisy environment is an essential requirement for its real-world applications. To this end, we devise a distinctive protocol for ensuring teleportation fidelity {\it close to unity}, hinging essentially on the timing of Alice's Bell-basis measurement (BM) dependent on the choice of Bob's local noise parameters, but is independent of Alice's local noise. Our scheme is enabled by Alice communicating to Bob only two of the BM outcomes corresponding to the states that are decoherence-free under common dephasing at Alice's wing. On the other hand, Bob is asked to discard the states of his qubit for the other two BM outcomes in order to maximize fidelity of the teleported state. This ensures the teleportation fidelity's independence of noise parameters in Alice's wing. We formulate the protocol in terms of a generic two-level quantum system, subjected to non-Markovian dephasing noise, applicable for any pure maximally/non-maximally entangled state as well as a Werner-type mixed state as resource. Notably, we show that high fidelity is achievable even using resource states with small values of the entanglement measure. Remarkably, even within the local regime of Werner states, where Bell-CHSH inequalities are not violated, the teleportation fidelity remains significantly high. Finally, we discuss the empirical feasibility of our scheme using photonic qubits.

</details>


### [182] [Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection](https://arxiv.org/abs/2602.19114)
*Hongdong Zhu,Qi Gao,Yin Ma,Shaobo Chen,Haixu Liu,Fengao Wang,Tinglan Wang,Chang Wu,Kai Wen*

Main category: quant-ph

TL;DR: Kaiwu-PyTorch-Plugin (KPP) 将相干伊辛机集成到PyTorch生态系统中，通过量子计算加速玻尔兹曼采样、优化训练数据和构建混合架构，在能量基模型上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决能量基模型中经典计算方法的效率瓶颈，通过量子计算加速深度学习任务，建立量子-经典混合计算范式。

Method: 开发KPP框架，将相干伊辛机集成到PyTorch中，实现三个关键功能：1) 加速玻尔兹曼采样；2) 通过主动采样优化训练数据；3) 构建QBM-VAE和Q-Diffusion等混合架构。

Result: 在单细胞和OpenWebText数据集上实现了SOTA性能，验证了量子-经典混合范式的有效性。

Conclusion: KPP成功建立了深度学习与光子量子计算之间的桥梁，为能量基模型提供了高效的量子增强解决方案，推动了量子-经典混合计算范式的发展。

Abstract: This paper introduces the Kaiwu-PyTorch-Plugin (KPP) to bridge Deep Learning and Photonic Quantum Computing across multiple dimensions. KPP integrates the Coherent Ising Machine into the PyTorch ecosystem, addressing classical inefficiencies in Energy-Based Models. The framework facilitates quantum integration in three key aspects: accelerating Boltzmann sampling, optimizing training data via Active Sampling, and constructing hybrid architectures like QBM-VAE and Q-Diffusion. Empirical results on single-cell and OpenWebText datasets demonstrate KPPs ability to achieve SOTA performance, validating a comprehensive quantum-classical paradigm.

</details>


### [183] [Ion-atom two-qubit quantum gate based on phonon blockade](https://arxiv.org/abs/2602.19222)
*Subhra Mudli,Bimalendu Deb*

Main category: quant-ph

TL;DR: 该论文展示了在离子-原子混合系统中实现高保真度通用两量子比特CNOT门，利用里德堡原子激发产生的声子阻塞效应。


<details>
  <summary>Details</summary>
Motivation: 之前的研究表明囚禁离子可以介导两个分离里德堡原子间的相互作用，用于实现中性原子量子比特间的通用两量子比特门。本文旨在扩展这一概念，在离子-原子混合系统中实现高保真度通用量子门操作。

Method: 通过激发原子到里德堡态，利用由此产生的强离子-原子相互作用在谐波囚禁离子的运动态中产生声子阻塞效应，从而实现离子和原子量子比特间的CNOT门操作。

Result: 成功演示了离子和原子量子比特间的高保真度通用两量子比特CNOT门操作。

Conclusion: 离子-原子混合系统可以作为量子计算和量子网络的资源平台或模块，因为它能够同时利用带电和中性原子量子比特的最佳特性。

Abstract: In a previous paper [S. Mudli {\it et al.} Phys. Rev. A 110, 062618 (2024)], it was shown that a trapped ion can mediate interaction between two largely separated Rydberg atoms, and this mediated interaction can be leveraged to perform a universal two-qubit gate operation between neutral atom qubits in optical tweezers. In this paper, we demonstrate the universal two-qubit CNOT gate with high fidelity between an ionic and an atomic qubit relying on Rydberg excitation of the atom and the resulting phonon blockade in the motional states of the harmonically trapped ion. The phonon blockade arises due to strong ion-atom interaction when the atom is excited to a Rydberg state. These demonstrations suggest that an ion-atom hybrid system can serve as a resourceful platform or module for quantum computing and quantum networking as it can utilize the best features of charged as well as neutral atom qubits.

</details>


### [184] [Eigenstate-assisted realization of general quantum controlled unitaries with a fixed cost](https://arxiv.org/abs/2602.19250)
*Carlos Navas-Merlo,Juan Carlos García-Escartín*

Main category: quant-ph

TL;DR: 提出一种将任意酉算子U转换为受控版本c-U的通用方法，使用固定电路（每量子比特4个CNOT和2个Toffoli门），实现与U分解无关的恒定深度实现。


<details>
  <summary>Details</summary>
Motivation: 受控酉门是量子算法中的基本元素，但将一般酉算子U转换为受控版本c-U通常会导致电路深度显著增加，产生较大开销。需要一种更高效的方法来减少这种转换的开销。

Method: 使用固定电路结构：每量子比特4个CNOT门和2个Toffoli门。对于n量子比特酉算子和一个控制量子比特，需要2n+1个量子比特，并能生成U的本征态（已有多种成本效益高的算法）。该方法也适用于U的黑盒实现，实现与分解无关的恒定深度。

Result: 实现了将任意酉算子U转换为受控版本c-U的恒定深度电路，显著减少了传统方法带来的深度开销。该方法在Hadamard测试中得到验证，并适用于变分算法和量子机器学习算法。

Conclusion: 提出了一种高效、通用的受控酉门实现方法，通过固定电路结构实现恒定深度，显著降低了量子电路的开销，在量子计算的各种应用中具有重要价值。

Abstract: Controlled unitary gates are a basic element in many quantum algorithms. Converting a general unitary $U$ with a known decomposition into its controlled version, controlled-$U$, can introduce a large overhead in terms of the depth of the circuit. We present a general method to take any unitary $U$ into controlled-$U$ using a fixed circuit with 4 CNOT gates and 2 Toffoli gates per qubit. For $n$-qubit unitaries and one control qubit, we require $2n+1$ qubits and a circuit that can generate an eigenstate of $U$, for which there are many cost-effective known algorithms. The method also works for any black block implementation of $U$, achieving a constant-depth realization independent of its decomposition. We illustrate its use in the Hadamard test and discuss applications to variational and quantum machine-learning algorithms.

</details>


### [185] [Quantum Sketches, Hashing, and Approximate Nearest Neighbors](https://arxiv.org/abs/2602.19259)
*Sajjad Hashemian*

Main category: quant-ph

TL;DR: 该论文排除了使用O(log n)量子比特压缩近似最近邻数据结构（ANN）的可能性，证明对于Hamming空间中的n点实例，任何量子草图都需要Ω(n)量子比特。


<details>
  <summary>Details</summary>
Motivation: 受Johnson-Lindenstrauss降维、振幅编码和将测量视为哈希类原语的启发，研究者希望将n点近似最近邻数据结构压缩到O(log n)量子比特中。

Method: 采用广义量子草图模型：数据集P编码为m量子比特状态ρ_P，每个查询通过对ρ_P的新副本进行任意查询相关测量来回答。通过归约到量子随机访问码和Nayak下界，证明对于Hamming空间{0,1}^d（d=Θ(log n)）中的n点实例，任何此类草图都需要m=Ω(n)量子比特。

Result: 对于任意近似因子c≥1和常数成功概率p>1/2，存在Hamming空间中的n点实例，使得任何量子草图都需要Ω(n)量子比特。这与潜在的量子查询时间优势共存，在基于哈希的ANN的候选扫描抽象中，振幅放大可将候选检查次数二次减少，这本质上是最优的。

Conclusion: 不可能将n点近似最近邻数据结构压缩到O(log n)量子比特中，量子内存下界为Ω(n)量子比特。虽然量子计算可能在查询时间上提供优势，但在内存压缩方面存在根本性限制。

Abstract: Motivated by Johnson--Lindenstrauss dimension reduction, amplitude encoding, and the view of measurements as hash-like primitives, one might hope to compress an $n$-point approximate nearest neighbor (ANN) data structure into $O(\log n)$ qubits. We rule out this possibility in a broad quantum sketch model, the dataset $P$ is encoded as an $m$-qubit state $ρ_P$, and each query is answered by an arbitrary query-dependent measurement on a fresh copy of $ρ_P$. For every approximation factor $c\ge 1$ and constant success probability $p>1/2$, we exhibit $n$-point instances in Hamming space $\{0,1\}^d$ with $d=Θ(\log n)$ for which any such sketch requires $m=Ω(n)$ qubits, via a reduction to quantum random access codes and Nayak's lower bound. These memory lower bounds coexist with potential quantum query-time gains and in candidate-scanning abstractions of hashing-based ANN, amplitude amplification yields a quadratic reduction in candidate checks, which is essentially optimal by Grover/BBBV-type bounds.

</details>


### [186] [Entanglement dynamics of many-body quantum states: sensitivity to system conditions and a hidden universality](https://arxiv.org/abs/2602.19280)
*Devanshu Shekhar,Pragya Shukla*

Main category: quant-ph

TL;DR: 该论文研究了多参数高斯系综表示的物理哈密顿量，推导了其本征态的态系综，并分析了系统条件变化对二分纠缠熵的影响，提出了基于单一参数的通用数学框架来描述不同量子态之间的纠缠统计演化。


<details>
  <summary>Details</summary>
Motivation: 研究多参数高斯系综表示的物理哈密顿量的纠缠特性，揭示不同量子态之间隐藏的深层联系，建立统一的数学框架来描述具有相同对称约束的不同哈密顿量或同一哈密顿量不同态的纠缠统计演化。

Method: 采用多参数高斯系综理论表示物理哈密顿量，理论推导其本征态的态系综，分析系统参数变化对二分纠缠熵的影响，建立基于单一参数的通用数学公式来描述纠缠统计的演化。

Result: 发现纠缠统计的演化可以通过单一参数来描述，该参数是系统参数的单一泛函，揭示了不同量子态之间隐藏的深层联系网络，为具有相同对称约束的不同哈密顿量或同一哈密顿量不同态提供了统一的纠缠统计描述框架。

Conclusion: 该研究建立了基于单一参数的通用数学框架，能够统一描述多参数高斯系综表示的物理哈密顿量的纠缠统计演化，揭示了不同量子态之间的深层联系，为理解量子系统的纠缠特性提供了新的理论工具。

Abstract: We consider physical Hamiltonians that can be represented by the multiparametric Gaussian ensembles, theoretically derive the state ensembles for its eigenstates and analyze the effect of varying system conditions on its bipartite entanglement entropy. Our approach leads to a single parametric based common mathematical formulation for the evolution of the entanglement statistics of different states of a given Hamiltonian or different Hamiltonians subjected to same symmetry constraints. The parameter turns out to be a single functional of the system parameters and thereby reveals a deep web of connection hidden underneath different quantum states.

</details>


### [187] [Self-correction phase transition in the dissipative toric code](https://arxiv.org/abs/2602.19288)
*Sanjeev Kumar,Hendrik Weimer*

Main category: quant-ph

TL;DR: 分析时间连续版本的环面码元胞自动机解码器，发现自校正量子存储器可作为稳态的热力学相存在，表现为稳态具有拓扑序


<details>
  <summary>Details</summary>
Motivation: 研究在Lindblad主方程框架下，元胞自动机解码器能否实现自校正量子存储器，探索量子纠错与热力学相变的关系

Method: 采用时间连续版本的环面码元胞自动机解码器，构建Lindblad主方程模型，计算稳态相图

Result: 发现稳态相图显示元胞自动机经典场更新速率与纠错速率之间存在竞争；即使在传统量子纠错没有有限阈值的情况下，也能实现自校正

Conclusion: 自校正量子存储器可作为稳态的热力学相存在，元胞自动机解码器在某些情况下比传统量子纠错更具优势

Abstract: We analyze a time-continuous version of a cellular automaton decoder for the toric code in the form of a Lindblad master equation. In this setting, a self-correcting quantum memory becomes a thermodynamical phase of the steady state, which manifests itself through the steady state being topologically ordered. We compute the steady state phase diagram, finding a competition between the error correction rate and the update rate for the classical field of the cellular automaton. Strikingly, we find that self-correction of errors is possible even in situations where conventional quantum error correction does not have a finite threshold.

</details>


### [188] [Mass-Independent Gravitationally Induced Entanglement](https://arxiv.org/abs/2602.19306)
*Lorenzo Braccini,Alessio Serafini,Sougato Bose*

Main category: quant-ph

TL;DR: 该研究解析求解了两个相互作用的斯特恩-格拉赫干涉仪(SGI)的纠缠量子动力学，发现引力相互作用产生的纠缠相位与质量无关，并揭示了二阶效应可用于限定质量范围，讨论了基于NV中心的抗磁悬浮质量的具体实现。


<details>
  <summary>Details</summary>
Motivation: 研究两个相互作用的斯特恩-格拉赫干涉仪的量子动力学，探索引力相互作用对量子纠缠的影响，以及如何利用这些效应来限定实验中的质量范围，为量子引力实验提供理论基础。

Method: 解析求解两个相互作用SGI的量子动力学，考虑酉演化和开放动力学，包括扩散和退相干效应，分析初始压缩热态，研究四干涉路径的解，并讨论基于NV中心的抗磁悬浮质量的具体实现方案。

Result: 发现引力相互作用产生的两量子比特纠缠相位与质量无关，且不受初始态温度和压缩的影响；相互作用导致质心无法完美重组，这一二阶效应可用于从上下限限定质量范围；开放动力学中的噪声效应进一步收紧质量界限。

Conclusion: 该研究为量子引力实验提供了重要理论框架，表明通过分析相互作用SGI的动力学，可以在考虑实际噪声的情况下限定实验质量范围，为基于NV中心的抗磁悬浮系统的实验实现指明了方向。

Abstract: We analytically solve the entangling quantum dynamics of two interacting Stern-Gerlach Interferometers~(SGI). Each SGI exploits an operator-valued force applied by a qubit to create and recombine a non-Gaussian state of matter. The entangling phase between the two qubits generated by the leading-order gravitational interaction of the massive degrees of freedom is found to be mass-independent, both for unitary and open dynamics, irrespective of the temperature and squeezing of the initial states. Further, we show that the solution of the four interferometric paths reveals that the mere presence of the interaction does not allow for a perfect recombination of the centre of mass. This second-order effect, alongside higher-order interaction terms, can be used to bound the mass from above and below, thus restricting the experiment's regime to mesoscopic masses. By solving the open dynamics which includes diffusion and dephasing with initial squeezed thermal states, the bounds are tightened by the inclusion of realistic experimental noise. We discuss diamagnetic levitated masses with embedded NV-centres as a specific physical implementation.

</details>


### [189] [Learning partial transpose signatures in qubit ququart states from a few measurements](https://arxiv.org/abs/2602.19307)
*Christian Candeago,Paolo Da Rold,Michele Grossi,Pawel Horodecki,Antonio Mandarino*

Main category: quant-ph

TL;DR: 使用机器学习框架通过部分转置谱分类来识别高维量子系统中的可蒸馏纠缠态，相比完整层析需要更少的测量


<details>
  <summary>Details</summary>
Motivation: 高维量子系统能提升量子协议性能，但表征其量子资源实验成本高。纠缠蒸馏需要从噪声资源中提取最大纠缠态，但确定可蒸馏性通常需要完整状态层析，这对高维系统实验上不可行

Method: 采用机器学习框架，基于PPT准则（部分转置负特征值分类），使用SVM、随机森林和人工神经网络等算法，特征来自固定测量和可学习可观测量

Result: 可学习观测量的方法始终优于集体测量见证方法。所有模型都能区分不可蒸馏（PPT）和可蒸馏（NPT）状态，但区分NPT子类仍然困难，反映了希尔伯特空间的复杂几何结构

Conclusion: 该工作为高维量子系统中的可蒸馏性验证提供了一种无需完整状态重构的实验友好工具，展示了机器学习在量子资源表征中的潜力

Abstract: Higher-dimensional quantum systems are attracting interest for improving quantum protocol performance by increasing memory space. Characterizing quantum resources of such systems is fundamental but experimentally costly. We tackle the first non-trivial example: a qubit-ququart system, focusing on partial-transpose spectral classification. Entanglement distillation extracts maximally entangled states from noisy resources, but determining distillability typically requires full state tomography, experimentally prohibitive for high-dimensional systems. We explore a machine learning framework to classify distillable bipartite quantum states using fewer measurements than complete tomography. Our approach employs the PPT criterion, categorizing states by negative eigenvalues in the partial transpose. We use various ML algorithms, including Support Vector Machines, Random Forest, and Artificial Neural Networks, with features from fixed measurements and learnable observables. Results show learnable observables consistently outperform Collective Measurement Witnesses methods. While all models distinguish between non-distillable (PPT) and distillable (NPT) states, differentiating NPT subclasses remains challenging, underscoring the intricate Hilbert space geometry. This work provides an experimentally friendly tool for distillability verification in high-dimensional quantum systems without full state reconstruction

</details>


### [190] [Gravitational Poissonian Spontaneous Localization Model of Hybrid Quantum-Classical Newtonian Gravity: Energy Increase and Experimental Bounds](https://arxiv.org/abs/2602.19377)
*Nicolò Piccione*

Main category: quant-ph

TL;DR: GPSL模型中，当测量和引力反馈使用不同的空间平滑函数时，可以显著降低自发加热率，在某些情况下可减少60多个数量级，并利用中子星数据对模型参数设置了新的下界。


<details>
  <summary>Details</summary>
Motivation: GPSL模型作为经典-量子混合框架，需要空间平滑来避免发散的自发加热率。先前研究假设测量和引力反馈使用相同的平滑函数，本文研究不同平滑函数对自发加热率的影响，探索最小化加热率的可能性。

Method: 研究GPSL模型中测量和引力反馈使用不同空间平滑函数g_rC(x)和g_rG(x)的一般情况，分析自发加热率随平滑函数的变化，确定最小化加热率的最优平滑配置。

Result: 当测量噪声保持不变时，允许g_rG(x)≠g_rC(x)可以将反馈诱导的自发加热率降低60多个数量级（r_G=10r_C时）。利用中子星温度、半径和质量数据，为模型参数设置了新的下界。

Conclusion: GPSL模型中测量和引力反馈使用不同的空间平滑函数可以显著降低自发加热率，这为模型的实际应用提供了重要改进，并利用天体物理观测数据对模型参数进行了约束。

Abstract: The Gravitational Poissonian Spontaneous Localization (GPSL) model is a hybrid classical-quantum framework in which Newtonian gravity emerges from stochastic collapses of a smeared mass-density operator. Consistency of the hybrid dynamics entails momentum diffusion and, hence, spontaneous heating. Without smearing, which enters both the collapse (measurement) and gravitational-feedback components of the dynamics, the heating rate would be divergent. Previous work assumed identical smearings for both components. Here, we treat the general case of distinct spatial smearings $g_{r_C} (\mathbf{x})$ and $g_{r_G} (\mathbf{x})$, characterized, respectively, by length scales $r_C$ and $r_G$. We characterize the spontaneous heating rate for arbitrary $g_{r_C} (\mathbf{x})$ and $g_{r_G} (\mathbf{x})$, and then discuss which smearing profiles minimize the spontaneous heating rate in relevant physical situations. Remarkably, there are situations in which, while the measurement noise remains the same, allowing $g_{r_G} (\mathbf{x}) \neq g_{r_C} (\mathbf{x})$ may reduce the feedback-induced spontaneous heating by more than 60 orders of magnitude already for $r_G = 10 r_C$. Finally, we use our results to estimate the spontaneous heating rate of neutron stars and to set new lower bounds on the model's parameters by comparing the theoretical predictions with astronomical data on temperature, radius, and mass of neutron stars.

</details>


### [191] [AI Agents for Variational Quantum Circuit Design](https://arxiv.org/abs/2602.19387)
*Marco Knipfer,Alexander Roman,Konstantin T. Matchev,Katia Matcheva,Sergei Gleyzer*

Main category: quant-ph

TL;DR: 提出基于自主智能体的变分量子电路架构搜索框架，通过自动化训练和验证流水线，在NISQ时代实现量子模型开发的规模化方法


<details>
  <summary>Details</summary>
Motivation: 变分量子电路是近期量子机器学习的关键组件，但电路设计空间随量子比特数、层数、纠缠结构和门参数化呈组合增长，手动设计效率低且往往不是最优的，需要自动化设计方法

Method: 引入基于自主智能体的VQC架构搜索框架，将高层推理与量子模拟环境集成。智能体提出候选电路架构，通过完全自动化的训练和验证流水线进行评估，并通过性能驱动的反馈迭代改进设计策略

Result: 实验表明，智能体能够从简单的初始ansatz自主演化出越来越有表达力的电路架构，逐步提升任务性能，证明智能体AI能够在最小人工干预下有效导航和优化VQC设计空间

Conclusion: 该框架为NISQ时代的自动化量子模型开发提供了可扩展的方法论，展示了智能体AI在量子电路设计中的有效性

Abstract: Variational quantum circuits (VQCs) constitute a central building block of near-term quantum machine learning (QML), yet the principled design of expressive and trainable architectures remains a major open challenge. The VQC design space grows combinatorially with the number of qubits, layers, entanglement structures, and gate parameterizations, rendering manual circuit construction inefficient and often suboptimal. We introduce an autonomous agent-based framework for VQC architecture search that integrates high-level reasoning with a quantum simulation environment. The agent proposes candidate circuit architectures, evaluates them through fully automated training and validation pipelines, and iteratively improves its design strategy via performance-driven feedback. Empirically, we show that the agent autonomously evolves circuit architectures from simple initial ansätze toward increasingly expressive designs, progressively trying to improve task performance. This demonstrates that agentic AI can effectively navigate and refine the VQC design landscape with minimal human intervention, providing a scalable methodology for automated quantum model development in the Noisy Intermediate-Scale Quantum (NISQ) regime.

</details>


### [192] [Contextuality-enhanced quantum state discrimination under fixed failure probability](https://arxiv.org/abs/2602.19397)
*Min Namkung,Hyang-Tag Lim*

Main category: quant-ph

TL;DR: 该论文研究了量子态鉴别中语境性增强现象，发现在固定失败概率下存在无增强区域，且该区域随量子态可混淆性（保真度）和噪声强度变化。


<details>
  <summary>Details</summary>
Motivation: 传统量子态鉴别策略（最小错误鉴别和明确态鉴别）都显示出语境性增强的成功概率，但在实际应用中，错误和失败结果可能同时存在。需要一种统一策略来同时考虑这两个方面，并探索语境性增强的潜力。

Method: 理论分析了固定失败概率下的量子态鉴别，研究了语境性增强现象。分析了无增强区域与量子态可混淆性（保真度）的关系，并将讨论扩展到包含噪声的态鉴别，甚至包括最大置信度鉴别。

Result: 发现在固定失败概率下，语境性增强在某个中间失败概率范围内消失，这种现象在传统策略中不存在。无增强区域的存在取决于量子态的可混淆性（保真度）。在噪声态鉴别中，随着噪声强度增加，无增强区域趋于消失。

Conclusion: 量子态鉴别中的语境性增强现象在固定失败概率策略下表现出复杂行为，存在无增强区域，该区域受量子态可混淆性和噪声强度影响。这些发现对量子传感和通信应用有重要意义。

Abstract: Quantum state discrimination enables the accurate identification of quantum states, which are generally nonorthogonal. Among various strategies, minimum-error discrimination and unambiguous state discrimination exhibit contextuality-enhanced success probabilities that surpass classical bounds, offering significant advantages for quantum sensing and communication. However, in practice, both error and failure outcomes can occur, suggesting the need for a unified strategy that incorporates both aspects while exploring the potential for contextuality enhancement. In this work, we theoretically demonstrate contextuality enhancement in quantum state discrimination under a fixed failure probability. We show that this enhancement disappears within a certain intermediate range of failure probabilities--a phenomenon absent in conventional strategies, where both minimum-error and unambiguous discrimination consistently outperform the noncontextual bound for equal priors. Moreover, we analyze how the existence of this non-enhancement region depends on the confusability of the quantum states, which corresponds to their fidelity in a quantum model. We further extend the discussion to the noisy state discrimination, which even encompasses the maximal-confidence discrimination. In this extended discussion, we observe that the non-enhancement region tends to disappear with increasing noise strength.

</details>


### [193] [Robust GHZ State Preparation via Majority-Voted Boundary Measurements](https://arxiv.org/abs/2602.19405)
*Jean-Baptiste Waring,Sébastien Le Beux,Christophe Pere*

Main category: quant-ph

TL;DR: 提出Group-MV协议，通过分区并行准备局部GHZ态，利用多数表决测量融合，在噪声量子硬件上实现高保真度GHZ态制备


<details>
  <summary>Details</summary>
Motivation: 在噪声量子硬件上制备高保真度GHZ态面临挑战，主要受累积门错误和退相干影响，需要新的协议来提升制备质量

Method: Group-MV动态电路协议：1) 分割任意耦合图；2) 并行准备局部GHZ态；3) 通过多数表决的中电路测量进行融合；4) 利用冗余边界链路的多数表决减轻测量错误传播

Result: 在模拟的Heavy-hex和Grid拓扑上（30-60量子比特，真实噪声环境）评估：保真度比Line Dynamic方法高2.4倍，与单元基线相差在3%以内

Conclusion: Group-MV可推广到任意GHZ大小和任意耦合拓扑，显著提升噪声量子硬件上的GHZ态制备保真度，有效减轻测量错误传播

Abstract: Preparing high-fidelity Greenberger-Horne-Zeilinger (GHZ) states on noisy quantum hardware remains challenging due to cumulative gate errors and decoherence. We introduce Group-Majority-Voting (Group-MV), a dynamic-circuit protocol that partitions arbitrary coupling graphs, prepares local GHZ states in parallel, and fuses them via majority-voted mid-circuit measurements. The majority vote over redundant boundary links mitigates measurement errors that would otherwise propagate through classical feedforward. We evaluate Group-MV on simulated Heavy-hex and Grid topologies for 30 through 60 qubits under a realistic noise regime. Group-MV generalizes to arbitrary GHZ sizes on arbitrary coupling topologies, achieving 2.4x higher fidelity than the Line Dynamic method while tracking the unitary baseline within 3%.

</details>


### [194] [Subsystem Statistics and Conditional Self-Similarity of Random Quantum States](https://arxiv.org/abs/2602.19448)
*Sangchul Oh*

Main category: quant-ph

TL;DR: 论文通过Dirichlet分布推导了随机纯态和去极化随机态的子系统比特串概率分布，发现Beta分布是随机量子态的普适统计规律，并揭示了随机态具有精确的条件自相似性。


<details>
  <summary>Details</summary>
Motivation: 研究随机量子态的统计特性，特别是子系统概率分布规律，为验证随机电路采样提供理论基础，同时探索希尔伯特空间的基本对称性。

Method: 使用Dirichlet分布分析随机纯态和去极化随机态，推导子系统比特串概率分布，证明Beta分布是普适统计规律，并分析条件自相似性。

Result: 发现Beta分布是随机量子态的普适统计规律；随机态具有精确的条件自相似性；去极化噪声会缩放和移动分布；可以通过后选择从边缘Beta分布恢复全系统统计。

Conclusion: 研究揭示了希尔伯特空间的基本对称性，为通过子系统或条件交叉熵基准测试验证随机电路采样提供了可扩展的严格框架。

Abstract: We analytically derive the bit-string probability distributions of subsystems of random pure states and depolarized random states using the Dirichlet distribution. We identify the exact Beta distribution as the universal statistical law of random quantum states, providing a unified finite-size description of full-system, subsystem, and conditional statistics. In the presence of depolarizing noise, these distributions are scaled and shifted by the noise strength, producing a noise-induced gap in their support. Remarkably, we prove that random states exhibit exact conditional self-similarity: the distribution of subsystem bit-string probabilities conditioned on specific outcomes of the complementary subsystem is identical to that of the full system. This hidden scale invariance enables the exact restoration of the full-system statistics from the marginalized Beta distribution via post-selection, and persists under depolarizing noise. Our results uncover a fundamental symmetry of Hilbert space and provide a scalable, rigorous framework for validating random circuit sampling via subsystem or conditional cross-entropy benchmarking.

</details>


### [195] [Quantum Hamiltonian Learning using Time-Resolved Measurement Data and its Application to Gene Regulatory Network Inference](https://arxiv.org/abs/2602.19496)
*Mohammad Aamir Sohail,Ranga R. Sudharshan,S. Sandeep Pradhan,Arvind Rao*

Main category: quant-ph

TL;DR: 提出基于量子哈密顿量模型的基因调控网络推断框架，通过时间分辨测量数据和变分学习算法高效恢复网络结构，在胶质母细胞瘤单细胞RNA测序数据中揭示新的调控关系。


<details>
  <summary>Details</summary>
Motivation: 传统基因调控网络推断方法存在局限性，需要开发超越经典推理限制的新建模框架。量子哈密顿量模型为生物系统建模提供了新的可能性。

Method: 提出量子哈密顿量基因表达模型(QHGM)，将基因相互作用编码为参数化哈密顿量，控制基因表达在伪时间上的演化。开发基于经验风险最小化的可扩展变分学习算法，从固定局部IC-POVM的时间分辨测量数据中恢复参数。

Result: 建立了有限样本恢复保证，证明了参数估计所需时间和测量样本数量的多项式上界。在合成基准测试中高效恢复网络结构，在胶质母细胞瘤单细胞RNA测序数据中揭示了新颖且生物学上合理的调控连接。

Conclusion: 该框架为量子类模型在生物系统中的应用开辟了新方向，超越了经典推理的限制，在癌症研究中具有重要潜力。

Abstract: We present a new Hamiltonian-learning framework based on time-resolved measurement data from a fixed local IC-POVM and its application to inferring gene regulatory networks. We introduce the quantum Hamiltonian-based gene-expression model (QHGM), in which gene interactions are encoded as a parameterized Hamiltonian that governs gene expression evolution over pseudotime. We derive finite-sample recovery guarantees and establish upper bounds on the number of time and measurement samples required for accurate parameter estimation with high probability, scaling polynomially with system size. To recover the QHGM parameters, we develop a scalable variational learning algorithm based on empirical risk minimization. Our method recovers network structure efficiently on synthetic benchmarks and reveals novel, biologically plausible regulatory connections in Glioblastoma single-cell RNA sequencing data, highlighting its potential in cancer research. This framework opens new directions for applying quantum-like modeling to biological systems beyond the limits of classical inference.

</details>


### [196] [Deterministic Ground State Preparation via Power-Cosine Filtering of Time Evolution Operators](https://arxiv.org/abs/2602.19556)
*Jeongbin Jo*

Main category: quant-ph

TL;DR: 提出一种使用Power-Cosine量子信号处理滤波器的高效非变分基态制备协议，通过单辅助量子比特和中间电路测量重置技术，在早期容错量子架构上实现确定性多体基态制备。


<details>
  <summary>Details</summary>
Motivation: 确定性制备量子多体基态对量子模拟至关重要，但现有最优算法通常需要过高的硬件资源。需要开发更高效、实用的基态制备方法。

Method: 使用Power-Cosine量子信号处理滤波器，避免复杂的块编码技术，直接利用由单辅助量子比特控制的相干时间演化算子。集成中间电路测量和重置技术，将迭代非酉滤波转化为深度时间相干性。

Result: 该方法以O(Δ⁻²log(1/ε))的电路深度实现激发态的指数抑制。在一维Heisenberg XYZ模型上的数值模拟验证了理论正确性和抗散粒噪声能力。在相同电路深度下，该方法指数级优于标准Trotter化绝热态制备。

Conclusion: 这种单辅助量子比特框架为早期容错量子架构上的多体基态制备提供了高度实用和确定性的途径，在实现简单性和效率之间取得了良好平衡。

Abstract: The deterministic preparation of quantum many-body ground states is essential for advanced quantum simulation, yet optimal algorithms often require prohibitive hardware resources. Here, we propose a highly efficient, non-variational protocol for ground state preparation using a Power-Cosine quantum signal processing (QSP) filter. By eschewing complex block-encoding techniques, our method directly utilizes coherent time-evolution operators controlled by a single ancillary qubit. The integration of mid-circuit measurement and reset (MCMR) drastically minimizes spatial overhead, translating iterative non-unitary filtering into deep temporal coherence. We analytically demonstrate that this approach achieves exponential suppression of excited states with a circuit depth scaling of $\mathcal{O}(Δ^{-2}\log(1/ε))$, prioritizing implementational simplicity over optimal asymptotic complexity. Numerical simulations on the 1D Heisenberg XYZ model validate the theoretical soundness and shot-noise resilience of our method. Furthermore, an advantage analysis reveals that our protocol exponentially outperforms standard Trotterized Adiabatic State Preparation (TASP) at equivalent circuit depths. This single-ancilla framework provides a highly practical and deterministic pathway for many-body ground state preparation on Early Fault-Tolerant (EFT) quantum architectures.

</details>


### [197] [Calderbank-Shor-Steane codes on group-valued qudits](https://arxiv.org/abs/2602.19558)
*Ben T. McDonough,Jian-Hao Zhang,Victor V. Albert,Andrew Lucas*

Main category: quant-ph

TL;DR: 本文提出了一种基于任意有限群G的CSS-like量子纠错码，推广了Kitaev量子双模型，并在二维CW复形上构建了具有渐近最优参数的量子纠错码。


<details>
  <summary>Details</summary>
Motivation: 传统CSS码仅限于Z2群，而Kitaev量子双模型虽然适用于一般群，但仅限于流形上的晶格。本文旨在构建更通用的量子纠错码框架，能够处理任意有限群，并在更一般的拓扑结构（CW复形）上工作。

Method: 引入基于有限群G的group-CSS码，其中X-check对应群元素的左/右乘运算，Z-check投影到群字方程的解空间。在二维定向CW复形上构建量子双模型，并证明当G是非阿贝尔单群时，满足特定条件的group-CSS码可约化为CW量子双模型。

Result: 建立了group-CSS码与CW量子双模型的等价关系，获得了基于图论的距离界限，构造了具有渐近最优速率和距离的非阿贝尔码族。通过引入"幽灵顶点"推广了具有缺陷和粗糙边界条件的量子双模型。

Conclusion: 本文提出的group-CSS码框架统一了CSS码和量子双模型，提供了在一般拓扑结构上构建非阿贝尔量子纠错码的系统方法，并揭示了某些对称保护拓扑态与CW量子双模型码字的深刻联系。

Abstract: Calderbank-Shor-Steane (CSS) codes are a versatile quantum error-correcting family built out of commuting $X$- and $Z$-type checks. We introduce CSS-like codes on $G$-valued qudits for any finite group $G$ that reduce to qubit CSS codes for $G = \mathbb{Z}_2$ yet generalize the Kitaev quantum double model for general groups. The $X$-checks of our group-CSS codes correspond to left and/or right multiplication by group elements, while $Z$-checks project onto solutions to group word equations. We describe quantum-double models on oriented two-dimensional CW complexes (which need not cellulate a manifold) and prove that, when $G$ is non-Abelian and simple, every $G$-covariant group-CSS code with suitably upper-bounded $Z$-check weight and lower-bounded $Z$-distance reduces to a CW quantum double. We describe the codespace and logical operators of CW quantum doubles via the same intuition used to obtain logical structure of surface codes. We obtain distance bounds for codes on non-Abelian simple groups from the graph underlying the CW complex, and construct intrinsically non-Abelian code families with asymptotically optimal rate and distances. Adding "ghost vertices" to the CW complex generalizes quantum double models with defects and rough boundary conditions whose logical structure can be understood without reference to non-Abelian anyons or defects. Several non-invertible symmetry-protected topological states, both with ordinary and higher-form symmetries, are the unique codewords of simply-connected CW quantum doubles with a single ghost vertex.

</details>


### [198] [A Relation Between the Chrestenson Operator, Weyl Operator Basis, and Kronecker-Pauli Operator Basis](https://arxiv.org/abs/2602.19573)
*Mickaya A. Razanaparany,Christian Rakotonirina*

Main category: quant-ph

TL;DR: 本文在量子理论框架下，使用狄拉克符号回顾了d维希尔伯特空间中的Chrestenson算子、Weyl算子基和Kronecker-Pauli算子基，其中d是大于2的素数。建立了这些算子的新代数关系，并以d=3和d=5为例进行说明。


<details>
  <summary>Details</summary>
Motivation: 研究d维希尔伯特空间中不同算子基之间的关系，特别是当d为大于2的素数时，探索Chrestenson算子、Weyl算子基和Kronecker-Pauli算子基之间的代数联系，为量子理论中的算子分析提供新的数学工具。

Method: 使用狄拉克符号在量子理论框架下，对d维希尔伯特空间中的三种算子基进行系统回顾和分析。通过数学推导建立这些算子之间的新代数关系，并以具体的素数维度（d=3和d=5）作为示例来验证和说明所建立的代数关系。

Result: 成功建立了Chrestenson算子、Weyl算子基和Kronecker-Pauli算子基之间的新代数关系，并通过d=3和d=5的具体案例验证了这些关系的有效性，为理解d维量子系统中的算子结构提供了新的数学工具。

Conclusion: 本文为d维希尔伯特空间中的算子分析提供了新的代数关系，特别适用于素数维度大于2的情况。所建立的数学关系有助于深入理解量子系统中不同算子基之间的联系，并为量子信息处理和量子计算中的算子理论提供了基础工具。

Abstract: Within the framework of quantum theory, we review the Chrestenson operator, the Weyl operator basis, and the Kronecker-Pauli operator basis in $d$-dimensional Hilbert spaces using Dirac notation, where $d$ is a prime integer strictly greater than 2. We establish a new algebraic relation connecting these operators and present the cases $d=3$ and $d=5$ as illustrative examples.

</details>


### [199] [Characterization and active cancellation of power-line-induced motional-mode frequency noise in a trapped-ion system](https://arxiv.org/abs/2602.19588)
*Jaehun You,Jiyong Kang,Kyunghye Kim,Wonhyeong Choi,Taehyun Kim*

Main category: quant-ph

TL;DR: 该论文研究了60Hz电源线噪声对囚禁离子量子计算中运动模式频率稳定性的影响，通过主动补偿技术将相干时间从10ms延长至35ms。


<details>
  <summary>Details</summary>
Motivation: 在囚禁离子量子计算中，运动模式频率的稳定性对实现高保真度量子门至关重要。虽然宽带高斯噪声已被广泛研究并通过脉冲整形技术缓解，但相干周期性噪声的影响尚未得到充分探索。电源线噪声（60Hz）对囚禁离子运动频率的调制效应需要系统研究。

Method: 使用自旋回波Ramsey光谱技术表征60Hz噪声对单个¹⁷¹Yb⁺离子运动频率的调制幅度和相位。通过被动相位校正验证表征结果，然后实施主动补偿：将补偿信号注入到稳定阱射频驱动幅度的PI控制器设定点中，采用相量拟合程序优化补偿信号的幅度和相位。

Result: 主动补偿技术几乎完全抑制了60Hz噪声分量。径向运动模式的相干时间从约10ms延长至35ms，达到了由运动加热设定的极限。这显著提高了运动模式的频率稳定性。

Conclusion: 该研究不仅清晰表征了周期性运动模式噪声，还为囚禁离子量子计算平台提供了实用的噪声抑制框架。主动补偿技术能有效提升量子门保真度，对实现可扩展量子计算具有重要意义。

Abstract: The stability of motional-mode frequency is essential for realizing high-fidelity quantum gates in trapped-ion quantum computing. While broadband Gaussian noise has been extensively studied and mitigated using pulse shaping techniques, the impact of coherent periodic noise has remained largely unexplored. Here we report a systematic investigation of 60-Hz power-line noise and its effect on the secular frequencies of a single ${}^{171}\mathrm{Yb}^{+}$ ion. Using spin-echo Ramsey spectroscopy, we characterize the amplitude and phase of the resulting secular-frequency modulation and validate this characterization via passive phase correction of the Ramsey sequence. Building on this, we implement active cancellation by injecting a compensation tone into the set-point of a PI controller that stabilizes the trap RF drive amplitude. A phasor-fitting procedure optimizes the amplitude and phase of the compensation signal, enabling near-complete suppression of the 60-Hz component. With active cancellation engaged, the coherence time of a radial motional mode is extended from approximately 10 ms to 35 ms, consistent with the limit set by motional heating. Our results provide both a clear characterization of periodic motional-mode noise and a practical framework for its suppression in trapped-ion quantum computing platforms.

</details>


### [200] [Magnon squeezing in the quantum regime](https://arxiv.org/abs/2602.19671)
*Yuan-Chao Weng,Da Xu,Zhen Chen,Li-Zhou Tan,Xu-Ke Gu,Jie Li,Hai-Feng Yu,Shi-Yao Zhu,Xuedong Hu,Franco Nori,J. Q. You*

Main category: quant-ph

TL;DR: 在毫米级钇铁石榴石(YIG)球中首次实验观测到量子级磁振子压缩态，实现了磁振子数小于1的压缩态，为量子非线性磁振子学奠定基础。


<details>
  <summary>Details</summary>
Motivation: 压缩态对量子计量学和新兴量子技术至关重要，但宏观自旋系统中的磁振子量子压缩一直难以实现。本研究旨在填补这一空白，探索磁振子系统的量子非线性特性。

Method: 通过微波腔工程实现强色散磁振子-超导量子比特耦合，利用显著的自克尔非线性产生压缩磁振子态，并采用磁振子辅助拉曼过程进行维格纳层析成像。

Result: 成功观测到量子级磁振子压缩态，磁振子平均数小于1，测得正交方差约0.8（约1.0 dB压缩），相对于真空态有明显压缩效果。

Conclusion: 该工作为量子非线性磁振子学奠定基础，有望在量子计量学等领域实现潜在应用，首次在宏观自旋系统中实现了磁振子的量子压缩。

Abstract: Squeezed states, crucial for quantum metrology and emerging quantum technologies, have been demonstrated in various platforms, but quantum squeezing of magnons in macroscopic spin systems remains elusive. Here we report the experimental observation of quantum-level magnon squeezing in a millimeter-scale yttrium iron garnet (YIG) sphere. By engineering a strong dispersive magnon-superconducting qubit coupling via a microwave cavity, we implement a significant self-Kerr nonlinearity to generate squeezed magnon states with their mean magnon number less than one. Harnessing a magnon-assisted Raman process, we perform Wigner tomography, revealing quadrature variances of $\sim\!0.8$ ($\sim\!1.0$~dB squeezing) relative to the vacuum. These results lay the groundwork for quantum nonlinear magnonics and promise potential applications in quantum metrology.

</details>


### [201] [Reversible Information Transformation via Quantum Reservoir Computing: Conditions, Protocol, and Noise Resilience](https://arxiv.org/abs/2602.19700)
*Hikaru Wakaura,Taiki Tanimae*

Main category: quant-ph

TL;DR: 提出一种四方程编解码协议，在量子储层计算中实现输入数据的精确重构，解决了传统认为不可逆的问题


<details>
  <summary>Details</summary>
Motivation: 量子储层计算(QRC)利用固定的量子动力学和可训练的线性读出处理时序数据，但由于量子态演化的递归非线性，从储层输出重构输入一直被认为是不可能的。本文旨在解决这一可逆性问题。

Method: 提出四方程编解码协议，采用交叉密钥配对。使用具有10个数据量子位的完整XYZ哈密顿量储层，在不增加量子位数量的情况下将特征维度扩展到76。识别秩条件dim(V)≥N_c作为必要准则。

Result: 在理想条件下，对长度达30的数据实现机器精度重构(MSE∼10^{-17})。噪声分析显示层次结构：散粒噪声主导，退极化噪声添加中等因子。非对称资源分配(编码10次，解码10^5次)利用加密和解密特征矩阵的非对称噪声角色，使MSE提高约两个数量级。

Conclusion: 在现实噪声下MSE退化到10^{-3}-10^{-1}，表明实际部署需要误差缓解，但结果确立了QRC中双向可逆信息转换的可行性。

Abstract: Quantum reservoir computing (QRC) exploits fixed quantum dynamics and a trainable linear readout to process temporal data, yet reversing the transformation -- reconstructing the input from the reservoir output -- has been considered intractable owing to the recursive nonlinearity of sequential quantum state evolution. Here we propose a four-equation encode-decode protocol with cross-key pairing and constructively show that quantum reservoir and key combinations satisfying all four equations exist. Using a full XYZ Hamiltonian reservoir with 10 data qubits, we expand the feature dimension to 76 without increasing qubit count and achieve machine-precision reconstruction (mean-squared error $\mathrm{MSE} \sim 10^{-17}$) for data lengths up to 30 under ideal conditions; the rank condition $\mathrm{dim}(V) \geq N_c$ is identified as a necessary criterion. A comprehensive noise analysis across seven conditions and four baseline methods reveals a clear hierarchy: shot noise dominates, depolarizing noise adds a moderate factor, and asymmetric resource allocation -- 10 shots for encoding, $10^5$ for decoding -- yields approximately two orders of magnitude MSE improvement by exploiting the asymmetric noise roles of the encryption and decryption feature matrices. Under realistic noise the MSE degrades to $10^{-3}$-$10^{-1}$, indicating that error mitigation is needed before practical deployment, but our results establish the feasibility of bidirectional reversible information transformation within QRC.

</details>


### [202] [Direct access to the initial polarization of ${}^{13}C$ nuclei by measuring coherence evolution of an nitrogen-vacancy center spin qubit](https://arxiv.org/abs/2602.19701)
*Mateusz Kuniej,Katarzyna Roszak*

Main category: quant-ph

TL;DR: 提出一种测量金刚石中自旋核初始极化下限的方法，通过监测NV中心自旋量子比特的相干演化来推断环境极化状态，无需直接访问核自旋环境。


<details>
  <summary>Details</summary>
Motivation: 现有极化测量技术因需要直接访问环境而难以实现，需要一种更简单、实验要求更低的方法来推断核自旋初始极化状态。

Method: 通过操作量子比特将环境信息转移到量子比特状态，然后测量量子比特相干演化的差异。环境演化以量子比特指针状态为条件，通过这种条件演化获取核自旋极化信息。

Result: 该方法不强烈依赖于外加磁场，而主要取决于导致退相干的核自旋数量。当环境极化时能给出合理估计，在最多15个随机放置核自旋的模拟环境中验证了有效性。

Conclusion: 该方法简单且实验要求最低，无需直接访问环境即可推断初始核极化，为金刚石中核自旋极化测量提供了实用方案。

Abstract: We introduce a method for the measurement of the lower bound on the initial polarization of spinful nuclei in a diamond by following the coherence evolution of an NV center spin qubit after a simple scheme is operated on the qubit to facilitate the transfer of information from the environment into the qubit state. Current polarization measurement techniques are challenging to implement due to the need for direct access to the environment. In our method, information is obtained by measuring the difference of the evolution of the qubit coherence resulting from preparation phase when the environment evolution is conditional on the qubit pointer state. We find that the method does not depend strongly on the applied magnetic field, but rather on the number of spinfull nuclei that lead to decoherence, and gives a reasonable estimate if the environment is polarized. The key advantage of this approach is its simplicity and minimal experimental requirements, allowing the inference of initial nuclear polarizations without direct access to the environment. We demonstrate the efficacy of this method using a simulated environment of up to fifteen randomly placed nuclear spins.

</details>


### [203] [Differentiable Maximum Likelihood Noise Estimation for Quantum Error Correction](https://arxiv.org/abs/2602.19722)
*Hanyan Cao,Dongyang Feng,Cheng Ye,Feng Pan*

Main category: quant-ph

TL;DR: 提出可微分最大似然估计框架，通过梯度下降优化电路级噪声参数，在重复码和表面码上实现精确噪声估计，显著降低逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 精确的噪声估计对容错量子计算至关重要，因为解码性能严重依赖于电路级噪声参数的准确性。现有方法在噪声估计精度方面存在局限。

Method: 提出可微分最大似然估计框架，使用精确的Planar求解器处理重复码，结合新颖简化的张量网络架构和优化的收缩路径查找处理表面码，实现完全可微分的似然评估。

Result: 在仿真中几乎精确恢复底层错误概率，在Google处理器实验数据上，相比相关分析和强化学习方法，重复码逻辑错误率降低30.6(3)%，表面码降低8.1(2)%。

Conclusion: 该方法通过直接最大化综合征似然，产生可证明最优的解码器无关错误先验，为当前和未来纠错量子处理器提供了强大的噪声估计和控制工具。

Abstract: Accurate noise estimation is essential for fault-tolerant quantum computing, as decoding performance depends critically on the fidelity of the circuit-level noise parameters. In this work, we introduce a differentiable Maximum Likelihood Estimation (dMLE) framework that enables exact, efficient, and fully differentiable computation of syndrome log-likelihoods, allowing circuit-level noise parameters to be optimized directly via gradient descent. Leveraging the exact Planar solver for repetition codes and a novel, simplified Tensor Network (TN) architecture combined with optimized contraction path finding for surface codes, our method achieves tractable and fully differentiable likelihood evaluation even for distance 5 surface codes with up to 25 rounds. Our method recovers the underlying error probabilities with near-exact precision in simulations and reduces logical error rates by up to 30.6(3)% for repetition codes and 8.1(2)% for surface codes on experimental data from Google's processor compared to previous state-of-the-art methods: correlation analysis and Reinforcement Learning (RL) methods. Our approach yields provably optimal, decoder-independent error priors by directly maximizing the syndrome likelihood, offering a powerful noise estimation and control tool for unlocking the full potential of current and future error-corrected quantum processors.

</details>


### [204] [Symmetry and Exact Solutions of General Spin-Boson Models](https://arxiv.org/abs/2602.19747)
*Yifan Sun,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 利用对称性结构解析求解一般自旋-玻色子模型的精确能谱，并以双模情况为例进行数值验证


<details>
  <summary>Details</summary>
Motivation: 自旋-玻色子模型是量子耗散的基准模型，但其精确解通常难以获得。本文旨在利用模型的对称性结构来获得一般自旋-玻色子哈密顿量的精确能谱。

Method: 通过分析一般自旋-玻色子哈密顿量的对称性结构，利用对称性来显式求解能谱。以双模情况为例进行数值计算，验证方法的有效性。

Result: 获得了自旋-玻色子模型的精确能谱解析表达式，并通过双模情况的数值计算验证了方法的正确性。

Conclusion: 利用对称性结构可以解析求解一般自旋-玻色子模型的能谱，为量子耗散研究提供了新的理论工具。

Abstract: Spin-boson models are the canonical benchmark for quantum dissipation. We show the symmetry structure of general spin-boson Hamiltonians and obtain their spectra explicitly by exploiting the symmetry. As an illustration of the general case, we numerically demonstrate the exact solution for the two-mode case.

</details>


### [205] [Krylov Distribution and Universal Convergence of Quantum Fisher Information](https://arxiv.org/abs/2602.19750)
*Mohsen Alishahiha,Fatemeh Tarighi Tabesh,Mohammad Javad Vasli*

Main category: quant-ph

TL;DR: 开发基于谱分解和Krylov子空间的量子Fisher信息计算框架，通过Krylov分布量化QFI在算子空间中的分布，提供截断误差控制，并发现两种普适收敛机制。


<details>
  <summary>Details</summary>
Motivation: 为高维和多体系统中的量子Fisher信息计算提供高效、概念清晰且实用的工具，建立量子计量学、谱几何和Krylov动力学之间的直接联系。

Method: 将QFI表示为密度矩阵相关超算子$\mathcal{K}_ρ$的解析矩，引入Krylov分布概念量化QFI在Krylov层级上的权重分布，利用正交多项式理论分析收敛行为。

Result: 识别出两种普适收敛机制：当Liouville空间谱存在能隙时呈指数衰减；当小特征值在零附近累积时呈现由硬边（Bessel）普适性控制的代数衰减。

Conclusion: 该框架为量子计量学、谱几何和Krylov动力学建立了直接联系，为高维和多体系统中的高效QFI计算提供了概念洞察和实用工具。

Abstract: We develop a spectral-resolvent framework for computing the quantum Fisher information (QFI) using Krylov subspace methods, extending the notion of the Krylov distribution. By expressing the QFI as a resolvent moment of the superoperator $\mathcal{K}_ρ$ associated with a density matrix, the Krylov distribution quantifies how the QFI weight is distributed across Krylov levels in operator space and provides a natural measure for controlling the truncation error in Krylov approximations. Leveraging orthogonal polynomial theory, we identify two universal convergence regimes: exponential decay when the Liouville-space spectrum is gapped away from zero, and algebraic decay governed by hard-edge (Bessel) universality when small eigenvalues accumulate near zero. This framework establishes a direct connection between quantum metrology, spectral geometry, and Krylov dynamics, offering both conceptual insight and practical tools for efficient QFI computation in high-dimensional and many-body systems.

</details>


### [206] [Improving Generalization and Trainability of Quantum Eigensolvers via Graph Neural Encoding](https://arxiv.org/abs/2602.19752)
*Jungyun Lee,Daniel K. Park*

Main category: quant-ph

TL;DR: 提出结合图自编码器和经典神经网络的端到端表示学习框架，为变分量子本征求解器生成可泛化的参数，无需针对每个哈密顿量实例重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决传统变分量子本征求解器泛化能力差、需要针对每个哈密顿量实例重新训练、以及存在贫瘠高原问题（梯度随电路深度和系统尺寸指数衰减）的局限性。

Method: 提出端到端表示学习框架，结合图自编码器编码哈密顿量的相互作用拓扑和耦合结构，使用经典神经网络生成VQE参数，能够跨哈密顿量实例泛化。

Result: 在一元和二元局部哈密顿量族上的数值实验显示：改进的泛化能力和可训练性（表现为测试误差降低和梯度方差衰减显著减缓），并显著加速量子子空间本征求解器的收敛。

Conclusion: 该方法为下游量子算法提供了实用的初始态准备方案，解决了传统VQE的泛化问题和贫瘠高原挑战，展示了表示学习在量子计算中的潜力。

Abstract: Determining the ground state of a many-body Hamiltonian is a central problem across physics, chemistry, and combinatorial optimization, yet it is often classically intractable due to the exponential growth of Hilbert space with system size. Even on fault-tolerant quantum computers, quantum algorithms with convergence guarantees -- such as quantum phase estimation and quantum subspace methods -- require an initial state with sufficiently large overlap with the true ground state to be effective. Variational quantum eigensolvers (VQEs) are natural candidates for preparing such states; however, standard VQEs typically exhibit poor generalization, requiring retraining for each Hamiltonian instance, and often suffer from barren plateaus, where gradients can vanish exponentially with circuit depth and system size. To address these limitations, we propose an end-to-end representation learning framework that combines a graph autoencoder with a classical neural network to generate VQE parameters that generalize across Hamiltonian instances. By encoding interaction topology and coupling structure, the proposed model produces high-overlap initial states without instance-specific optimization. Through extensive numerical experiments on families of one- and two-local Hamiltonians, we demonstrate improved generalization and trainability, manifested as reduced test error and a significantly milder decay of gradient variance. We further show that our method substantially accelerates convergence in quantum subspace-based eigensolvers, highlighting its practical impact for downstream quantum algorithms.

</details>


### [207] [Multiphoton Hong-Ou-Mandel Interference Enables Superresolution of Bright Thermal Sources](https://arxiv.org/abs/2602.19772)
*Aiman Khan,Danilo Triggiani,Vincenzo Tamma*

Main category: quant-ph

TL;DR: 提出一种利用多光子干涉与单光子Fock态进行热源成像的量子光学方案，通过横向动量分辨的多光子概率实现超越衍射极限的超分辨率成像。


<details>
  <summary>Details</summary>
Motivation: 现有成像方案（如衍射受限直接成像和超分辨反转干涉成像）在粗像素尺寸下精度严重下降，限制了在纳米尺度化学和生物系统中的应用。需要一种能处理任意亮度热源、对像素尺寸不敏感且能实现量子超分辨的成像方案。

Method: 使用多光子干涉技术，将热源与参考单光子Fock态在分束器上干涉，获得横向动量分辨的L光子概率解析形式。通过Fisher信息分析构建分离估计器，利用多光子事件的干涉采样。

Result: 1) 多光子事件干涉采样的分离估计器在宽分离范围和亮度下精度显著提升；2) 偶数光子符合计数在亚瑞利区域展现恒定精度，实现超越衍射极限的量子超分辨率；3) 对于平均每帧发射Ns~1光子的源，精度界限与Ns呈线性比例，匹配最终量子标度；4) 傅里叶平面横向动量分辨允许使用粗像素尺寸（δy~100μm）获得有限成像精度。

Conclusion: 该方案结合Hong-Ou-Mandel干涉仪的相对简单传感操作、任意亮度热源的多光子符合检测以及横向光子动量的内变量分辨，为纳米尺度化学和生物系统中明亮源的非侵入性单粒子追踪和成像提供了稳健的替代方案。

Abstract: We present a quantum optical scheme for imaging transversely displaced thermal sources of arbitrary intensities by employing multiphoton interference with a reference single-photon Fock state at a beamsplitter. Obtaining an analytical form for transverse momenta-resolved $L$-photon probabilities in either output, we show via Fisher information analysis that separation estimators built using interference sampling of multiphoton events exhibit significantly enhanced precision vis-à-vis existing imaging schemes over a wide range of separations and brightness. Even-photon-number coincidences exhibit constant precision in the sub-Rayleigh regime, demonstrating quantum superresolution of our scheme beyond the diffraction limit. For sources emitting on average $N_s\sim1$ photon per frame (such as in IR emission of thermal sources), precision bounds for our scheme scale linearly in $N_s$, exemplifying an enhanced precision of estimators in relation to weak sources $N_s\ll1$, and matching the ultimate quantum scaling. Finally, transverse momenta resolution in the Fourier plane produces finite imaging precisions for intermediate and large source separations using coarse pixel sizes of order $δy\sim100\,μ\mathrm{m}$ for exemplary image spot sizes $σ_x \sim 0.1\, μ\mathrm{m}$, in contrast with existing schemes of diffraction-limited direct imaging and superresolved inversion interferometric imaging that are severely degraded by coarse pixel sizes and have limited use. Combining the relatively straightforward sensing operation of Hong-Ou-Mandel interferometers with multiphoton coincidence detection of arbitrarily bright thermal sources and inner variable resolution of transverse photonic momenta, our scheme offers a robust alternative to non-invasive single-particle tracking and imaging of bright sources in nanoscopic chemical and biological systems.

</details>


### [208] [Unlocking photodetection for quantum sensing with Bayesian likelihood-free methods and deep learning](https://arxiv.org/abs/2602.19792)
*Mateusz Molenda,Lewis A. Clark,Marcin Płodzień,Jan Kolodynski*

Main category: quant-ph

TL;DR: 该论文比较了贝叶斯无似然方法和深度学习方法在量子传感器实时参数估计中的应用，验证了深度学习方法在保持精度的同时能显著提高估计速度，并成功应用于非线性光机械设备的非经典光子统计实时推断。


<details>
  <summary>Details</summary>
Motivation: 为了在实时操作中实现量子传感器的量子极限性能，需要开发高效的数据推断工具来快速估计参数。特别是在光子探测中，关键挑战是快速解释表现出非经典统计特性的点击模式——这些特性正是量子精度增强的来源。

Method: 比较了两种方法：贝叶斯无似然方法和深度学习方法。首先在可解析处理的双能级系统（发射不相关光子）中验证两种方法，然后将它们应用于驱动非线性光机械设备（发射具有复杂多点击相关性的非经典光）的参数估计。

Result: 深度学习方法在训练后能提供显著更快的参数估计，同时保持与贝叶斯方法相当的精度，并能类似地预测相关误差。在非线性光机械设备的复杂非经典光子统计场景中，这些方法对于快速推断至关重要，实现了实时区分不同光子统计特性的能力。

Conclusion: 研究结果表明深度学习方法能够有效支持量子传感器的实时参数估计，挑战了深度学习无法提供误差估计的常见误解。这些成果为利用光子探测中非经典效应实现量子传感器的动态控制铺平了道路。

Abstract: To operate quantum sensors at their quantum limit in real time, it is crucial to identify efficient data inference tools for rapid parameter estimation. In photodetection, the key challenge is the fast interpretation of click-patterns that exhibit non-classical statistics -- the very features responsible for the quantum enhancement of precision. We achieve this goal by comparing Bayesian likelihood-free methods with ones based on deep learning (DL). While the former are more conceptually intuitive, the latter, once trained, provide significantly faster estimates with comparable precision and yield similar predictions of the associated errors, challenging a common misconception that DL lacks such capabilities. We first verify both approaches for an analytically tractable, yet multiparameter, scenario of a two-level system emitting uncorrelated photons. Our main result, however, is the application to a driven nonlinear optomechanical device emitting non-classical light with complex multiclick correlations; in this case, our methods are essential for fast inference and, hence, unlock the possibility of distinguishing different photon statistics in real time. Our results pave the way for dynamical control of quantum sensors that leverage non-classical effects in photodetection.

</details>


### [209] [Rapid state-resolved single-atom imaging of alkaline-earth fermions](https://arxiv.org/abs/2602.19876)
*Thies Plassmann,Leon Schaefer,Meny Menashes,Guillaume Salomon*

Main category: quant-ph

TL;DR: 研究人员开发了一种新的成像技术，能够在100微秒内同时检测单个锶原子核自旋流形中的最多4个量子态，保真度高达0.936-0.997，为量子信息处理提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 碱土金属原子的核自旋流形具有大维度且对外部扰动耦合弱，是量子信息的理想资源，但缺乏同时单原子和状态分辨的检测技术限制了其在量子计算和模拟中的应用。

Method: 开发了一种新的成像技术，能够同时检测单个费米子锶原子核自旋流形中最多4个量子态，检测时间仅需100微秒。

Result: 实现了状态分辨检测保真度在0.936到0.997之间，并成功追踪了淬火后高度相干的核自旋动力学。

Conclusion: 这项技术为多电子原子的量子科学开辟了广阔前景，包括基于qudit的量子计算和SU(N)费米-哈伯德模型的量子模拟。

Abstract: Local Hilbert spaces with large dimension are of key interest for quantum information with applications in quantum computing and memories, quantum simulations and metrology. Thanks to its weak coupling to external perturbations, the large ground-state nuclear spin manifold of fermionic alkaline-earth atoms is an exciting resource to explore for quantum information. Simultaneous single atom and state-resolved detection however remains an outstanding challenge limiting the development of novel quantum computing and simulation schemes beyond qubits. Here, we report on a new imaging technique enabling the simultaneous detection of up to four quantum states encoded in the nuclear spin manifold of a single fermionic strontium atom within 100 microseconds, with state-resolved detection fidelities ranging from 0.936 to 0.997. This technique is further used to track the highly coherent nuclear spin dynamics after a quench highlighting the potential of this system for quantum information. These results offer fascinating perspectives for quantum science with multi-electron atoms ranging from qudit-based quantum computing to quantum simulations of the SU(N) Fermi-Hubbard model.

</details>


### [210] [Heat flow through the quantum heat valve coupled to ohmic baths via a master equation approach](https://arxiv.org/abs/2602.19908)
*Antti Vaaranta,Marco Cattaneo,Paolo Muratore-Ginanneschi,Jukka Pekola*

Main category: quant-ph

TL;DR: 该论文提出了一个量子热阀非平衡稳态热流的理论模型，通过仔细应用部分旋波近似的主方程方法，解决了先前模型中谐振子双重计数的问题，并成功解释了实验结果。


<details>
  <summary>Details</summary>
Motivation: 先前量子热阀研究存在谐振子双重计数问题：谐振子既作为开放量子系统的一部分，又出现在浴的光谱密度中，这虽然能解释实验结果但存在物理解释问题。需要建立一个更准确的理论模型来解决这一概念性问题。

Method: 采用主方程方法，仔细执行部分旋波近似以获得准确结果。模型假设两个热浴具有欧姆光谱密度，与先前使用谐振频率附近峰值光谱密度的结构化浴模型形成对比，避免了谐振子双重计数问题。

Result: 新模型成功描述了量子热阀实验，捕获了实验结果，并改进了先前存在谐振子双重计数问题的理论模型。验证了仔细应用主方程方法（特别是旋波近似）对于解释实际实验装置的有效性。

Conclusion: 通过仔细应用主方程方法和部分旋波近似，建立了一个物理上更合理的量子热阀理论模型，解决了先前模型的谐振子双重计数问题，为解释实际实验装置提供了有用工具。

Abstract: We provide a theoretical model for the non-equilibrium steady state heat flow through a quantum heat valve. The model is based on a master equation approach, where the partial secular approximation has been carefully performed in order to obtain accurate results. Our study assumes an ohmic spectral density for the two thermal baths of the model. This is in contrast with previous treatments of the quantum heat valve, where the baths have been assumed as being structured with a peaked spectral density near the resonance frequency of the resonator. These studies have also taken the resonator to be a part of the open quantum system of interest, which results in double counting of the resonator, as the latter appears both in the spectral density of the bath and as a part of the open system. Although this model accounts for the observations in a satisfactory way, it raises issues regarding its physical interpretation. Our method solves this conceptual problem. We apply it to describe an experiment on a quantum heat valve, showing that it successfully captures the experimental results and improves upon the previous theoretical model, which suffered from the resonator double-counting issue. Our findings confirm that the careful application of the master equation approach, in particular when it comes to the secular approximation, is a useful tool for explaining realistic experimental setups.

</details>


### [211] [Two components relativistic quantum wave equation for scalar bosons](https://arxiv.org/abs/2602.19971)
*Roland Combescot*

Main category: quant-ph

TL;DR: 论文提出了一种标量玻色子的相对论性量子波方程，该方程类似于狄拉克方程，但适用于标量粒子


<details>
  <summary>Details</summary>
Motivation: 现有克莱因-戈登方程是时间二阶导数方程，作者希望为标量玻色子找到一个时间一阶导数的相对论性方程，类似于狄拉克方程处理自旋1/2费米子的方式

Method: 推导出标量玻色子的相对论性量子波方程，该方程在时间导数上是一阶的，波函数有两个分量，类似于狄拉克方程的四分量形式

Result: 成功得到了标量玻色子的时间一阶相对论性方程，该方程在非相对论极限下能正则地过渡到标准的薛定谔方程

Conclusion: 标量玻色子可以用类似于狄拉克方程的时间一阶波方程来描述，这为标量粒子的量子力学描述提供了新的数学框架

Abstract: We show that, in the relativistic regime, scalar bosons satisfy a quantum wave equation which is quite analogous to the Dirac equation. In contrast with the Klein-Gordon equation it is first order with respect to time derivation. It leads in a regular way to the standard Schrödinger equation in the non-relativistic limit. There are two components for the wave function in this representation for the scalar boson, in a way completely analogous to the four components for the spin $1/2$ fermion in the Dirac equation.

</details>


### [212] [GAP Measures and Wave Function Collapse](https://arxiv.org/abs/2602.19993)
*Roderich Tumulka*

Main category: quant-ph

TL;DR: GAP分布（又称Scrooge分布）是希尔伯特空间单位球面上的一类概率分布，在量子统计力学中自然出现。本文证明了一个新性质：如果波函数Ψ服从GAP_ρ分布，发生坍缩后，坍缩后的波函数Ψ'仍然服从GAP分布（相对于适当的ρ'）。


<details>
  <summary>Details</summary>
Motivation: GAP分布在量子统计力学中自然出现，但之前未被认识到的一个重要性质是：在波函数坍缩过程中，GAP分布具有闭合性。这一性质对于理解量子测量和自发坍缩理论中的统计行为具有重要意义。

Method: 通过数学分析和证明，展示了GAP分布在量子坍缩过程中的行为特性。具体研究了在量子测量（由观察者执行）以及自发坍缩理论（如CSL或GRW）中，波函数坍缩后条件分布的性质。

Result: 证明了如果初始波函数Ψ服从GAP_ρ分布，那么坍缩后的波函数Ψ'的条件分布（给定测量结果或坍缩历史）仍然是GAP分布，具体为GAP_{ρ'}，其中ρ'是坍缩后的适当密度矩阵。

Conclusion: GAP分布在量子坍缩过程中具有闭合性，这一性质为量子测量理论和自发坍缩理论提供了重要的数学基础，表明GAP分布是描述量子系统统计行为的自然框架。

Abstract: GAP measures (also known as Scrooge measures) are a natural class of probability distributions on the unit sphere of a Hilbert space that come up in quantum statistical mechanics; for each density matrix $ρ$ there is a unique measure GAP$_ρ$. We describe and prove a property of these measures that was not recognized so far: If a wave function $Ψ$ is GAP$_ρ$ distributed and a collapse occurs, then the collapsed wave function $Ψ'$ is again GAP distributed (relative to the appropriate $ρ'$). This fact applies to collapses due to a quantum measurement carried out by an observer, as well as to spontaneous collapse theories such as CSL or GRW. More precisely, it is the conditional distribution of $Ψ'$, given the measurement outcome (respectively, the noise in CSL or the collapse history in GRW), that is GAP$_{ρ'}$.

</details>


### [213] [A Quantum Internet Protocol Suite Beyond Layering](https://arxiv.org/abs/2602.19998)
*Angela Sara Cacciapuoti,Marcello Caleffi*

Main category: quant-ph

TL;DR: 该论文提出了一种基于动态组合的量子原生网络组织原则，取代了经典的分层协议结构，通过带内控制和分布式编排来管理量子纠缠服务。


<details>
  <summary>Details</summary>
Motivation: 经典互联网的分层协议原则不适用于基于纠缠的量子互联网，因为纠缠具有非局域性和状态性，需要新的组织原则来协调量子服务。

Method: 提出动态内核架构：每个节点运行动态内核，构建本地PoA（候选步骤证明），通过组合原子微协议形成上下文感知的元协议。量子数据包携带包含服务意图和操作记录的元头，节点利用这个历史记录来规划本地操作。

Result: 该设计确保了纠缠状态演化与控制流的一致性，防止资源状态与协议逻辑的分歧，同时保持与具体实现解耦。系统模块化、适应纠缠动态且可扩展，无论有无控制平面提示都能正确运行。

Conclusion: 动态组合是构建真正量子原生互联网所需的组织原则，通过认证而非封装来保证顺序，实现端到端服务认证而无需全局同步。

Abstract: Layering, the protocol organization principle underpinning the classical Internet, is ill-suited to the Quantum Internet, built around entanglement, which is non-local and stateful. This paper proposes a quantum-native organizational principle based on dynamic composition, which replaces static layering with a distributed orchestration fabric driven by the node local state and in-band control. Each node runs a Dynamic Kernel that i) constructs a local PoA of candidate steps to advance a service intent, and ii) executes the PoA by composing atomic micro-protocols into context-aware procedures (the meta-protocols). Quantum packets carry an in-band control-field (the meta-header) containing the service intent and an append-only list of action-commit records, termed as stamps. Successive nodes exploit this minimal, authoritative history to construct their local PoAs. As quantum packets progress, these local commits collectively induce a network-wide, direct acyclic graph that certifies end-to-end service fulfillment, without requiring global synchronization. In contrast to classical encapsulation, the proposed suite enforces order by certification: dependency-aware local scheduling decides what may run at a certain node, stamps certify what did run and constrain subsequent planning. By embedding procedural control within the quantum packet, the design ensures coherence and consistency between entanglement-state evolution and control-flow, preventing divergence between resource state ad protocol logic, while remaining MP-agnostic and implementation-decoupled. The resulting suite is modular, adaptable to entanglement dynamics, and scalable. It operates correctly with or without optional control-plane hints. Indeed, when present, hints can steer QoS policies, without changing semantics. We argue that dynamic composition is the organizing principle required for a truly quantum-native Internet.

</details>


### [214] [Electrical post-fabrication tuning of aluminum Josephson junctions at room temperature](https://arxiv.org/abs/2602.20002)
*Christian Križan,Maurizio Toselli,Irshad Ahmad,Hadi Khaksaran,Marcus Rommel,Nermin Trnjanin,Janka Biznárová,Mamta Dahiya,Emil Hogedal,Halldór Jakobsson,Andreas Nylander,Jonas Bylander,Per Delsing,Giovanna Tancredi*

Main category: quant-ph

TL;DR: 室温电脉冲可调控铝约瑟夫森结电阻，实现约瑟夫森能量调节，保持量子比特品质因子超百万，可用于量子处理器频率拥挤的后制造缓解


<details>
  <summary>Details</summary>
Motivation: 约瑟夫森结是超导量子技术的核心元件，但制造后频率拥挤问题限制了量子处理器性能，需要开发后制造调节技术

Method: 使用室温电脉冲调控铝约瑟夫森结，通过电压脉冲可控增加结电阻并调节约瑟夫森能量，研究电阻增加速率与脉冲幅度的关系，以及低温下的行为

Result: 电阻增加速率随脉冲幅度呈指数增长，自发电阻增加与调控量成正比；低温下自发增加停止，室温恢复；实现电阻增加270%，对应量子比特跃迁频率降低近2GHz

Conclusion: 电调控技术建立了可实现范围、弛豫行为和实际限制，为量子处理器频率拥挤问题提供了有效的后制造缓解方案

Abstract: Josephson junctions are a key element of superconducting quantum technology, serving as the core building blocks of superconducting qubits. We present an experimental study on room-temperature electrical tuning of aluminum junctions, showing that voltage pulses can controllably increase their resistance and adjust the Josephson energy while maintaining qubit quality factors above 1 million. We find that the rate of resistance increase scales exponentially with pulse amplitude during manipulation, after which the spontaneous resistance increase scales proportionally to the amount of manipulation. We show that this spontaneous increase halts at cryogenic temperatures, and resumes again at room temperature. Using our stepwise protocol, we achieve up to a 270% increase in junction resistance, corresponding to a reduction of nearly 2 GHz of the qubit transition frequency. These results establish the achievable range, relaxation behavior, and practical limits of electrical tuning, enabling post-fabrication mitigation of frequency crowding in quantum processors.

</details>


### [215] [Quantum correlation and coherence in a mononuclear nickel-based molecular Magnet](https://arxiv.org/abs/2602.20013)
*S. Bhuvaneswari,R. Muthuganesan,R. Radha*

Main category: quant-ph

TL;DR: 该研究分析了镍自由基分子磁体中的热纠缠、测量诱导非定域性和量子相干性，发现非纠缠量子关联在室温下比纠缠更稳定，表明此类分子磁体可作为实际条件下量子信息处理的可行平台。


<details>
  <summary>Details</summary>
Motivation: 研究镍自由基分子磁体中的量子资源（包括纠缠和超越纠缠的量子关联）在温度和磁场变化下的行为，探索这些系统在现实条件下进行量子信息处理的潜力。

Method: 使用实验估计的耦合参数计算系统的热态，分析量子资源（纠缠、测量诱导非定域性、量子相干性）对温度和磁场的依赖性，采用海森堡模型描述自旋-自旋相互作用。

Result: 量子资源在室温下仍然存在；纠缠随温度和磁场增加迅速消失，而测量诱导非定域性和量子相干性相对更稳定，在纠缠消失的区域仍然存在。

Conclusion: 超越纠缠的非经典关联在热激活自旋系统中具有重要意义，镍自由基分子磁体可作为现实条件下量子信息处理的可行平台。

Abstract: We investigate the behaviors of thermal entanglement, quantum correlation beyond entanglement namely, measurement-induced nonlocality (MIN) and coherence in a nickel radical molecular magnet (Et3NH)[Ni(hfac)2L], whose spin-spin interactions are well described by the Heisenberg model. Using experimentally estimated coupling parameters, we compute the thermal state of the system and analyze the dependence of quantum resources on temperature and magnetic field. The results indicate that the quantum resources of the nickel-radical molecular magnet persist even at room temperature. We show that while negativity (the entanglement measure) rapidly vanishes with increasing temperature and magnetic field, measurement-induced nonlocality and quantum coherence remain comparatively more stable and persist in regions where entanglement is absent. These results highlight the significance of nonclassical correlations beyond entanglement in thermally activated spin systems and suggest that such molecular magnets could serve as viable platforms for quantum information processing in realistic conditions.

</details>


### [216] [Spectroscopy of the Dirac oscillator perturbed by a surface delta potential](https://arxiv.org/abs/2602.20030)
*J. Munárriz,F. Domínguez-Adame,R. P. A. Lima*

Main category: quant-ph

TL;DR: 研究狄拉克振荡器在尖锐势场扰动下的能级移动，使用格林函数方法得到所有分波和宇称的封闭表达式


<details>
  <summary>Details</summary>
Motivation: 研究狄拉克振荡器在尖锐势场（趋近于表面δ势）扰动下的能级移动问题，这类问题在量子力学和相对论量子力学中具有重要意义

Method: 采用格林函数方法，分析狄拉克振荡器受尖锐势场扰动的情况，推导出所有分波和宇称的封闭表达式

Result: 获得了狄拉克振荡器能级移动的封闭表达式，适用于所有分波和宇称情况

Conclusion: 成功建立了狄拉克振荡器在尖锐势场扰动下的能级移动理论框架，为相关量子系统研究提供了分析工具

Abstract: We study theoretically the level shift of the Dirac oscillator perturbed by any sharply peaked potential approaching a surface delta potential. A Green function method is used to obtain closed expressions for all partial waves and parities.

</details>


### [217] [Entanglement formation in two-dimensional materials within microcavity](https://arxiv.org/abs/2602.20077)
*Fabricio Danel Matias,Facundo Arreyes,Juan Sebastián Ardenghi*

Main category: quant-ph

TL;DR: 研究微腔中两个六角晶格层间的纠缠生成，考虑电磁耦合和自旋轨道相互作用，发现系统快速从局域乘积态转变为相干叠加态，纠缠度对层间光子传播子和费米能级高度敏感。


<details>
  <summary>Details</summary>
Motivation: 研究微腔中嵌入的六角晶格层之间的量子纠缠生成，探索电磁耦合和自旋轨道相互作用对量子关联的影响，为理解类空间分离量子效应提供实验平台。

Method: 采用短时动力学方法，对约化密度矩阵进行微扰泰勒展开，表征六角晶格层间的二分量子关联，分析层间光子传播子、几何参数和费米能级的影响。

Result: 系统在t=0时从导带的局域乘积态快速转变为价带和导带态的相干叠加，纠缠度对层间光子传播子（包含层位置和腔高的几何比）以及特定费米能和SOI特征高度敏感。

Conclusion: 微腔中的异质结构可能适合开发实验来深入理解类空间分离量子效应，在超短演化区域出现了类空间分离的量子关联。

Abstract: In this work, the entanglement generation between two hexagonal-lattice layers embedded in a microcavity is studied, accounting for both electromagnetic coupling and intrinsic spin-orbit interaction (SOI). Utilizing a short-time dynamical approach, we perform a perturbative Taylor expansion of the reduced density matrix to characterize the bipartite quantum correlations between the hexagonal layers. We demonstrate that the system undergoes a rapid transition from a localized product state in the conduction bands at t = 0 to a coherent superposition of valence and conduction band states. Our results indicate that the degree of entanglement is highly sensitive to the interlayer photon propagator, which contains the geometric ratios of the layer positions and the height cavity, and the specific Fermi energy and SOI signatures of the respective layers. We show the emergence of spacelike-separated quantum correlations in the ultra-short evolution regime, suggesting that heterostructures in cavities may be suitable to develop experiments for a deep understanding of spacelike-separated quantum effects.

</details>


### [218] [Nonlinear quantum optomechanics in a Fano-mirror microcavity system](https://arxiv.org/abs/2602.20085)
*Lei Du,Juliette Monsel,Witlef Wieczorek,Janine Splettstoesser*

Main category: quant-ph

TL;DR: 研究量子非线性区域的法诺-镜面光力学系统，通过相干和耗散耦合形成有效光学模式，实现线宽大幅减小，同时达到单光子强耦合和边带分辨区域。


<details>
  <summary>Details</summary>
Motivation: 传统光力学系统难以同时实现单光子强耦合和边带分辨区域，限制了量子非线性效应的应用。法诺-镜面架构通过线宽减小有望解决这一难题。

Method: 采用有效主方程方法描述系统动力学，并与量子朗之万方程和修饰态主方程描述进行对比验证。利用相干和耗散耦合使两个强损耗光学模式杂化形成有效低线宽模式。

Result: 预测了清晰的量子特征，包括光子阻塞和机械猫态的产生。系统能够在实验可行参数下同时达到单光子强耦合和边带分辨区域。

Conclusion: 法诺-镜面架构为在可实现实验条件下利用单光子光力学非线性进行量子态工程提供了一个有前景的平台。

Abstract: We study a Fano-mirror optomechanical system in the quantum nonlinear regime. In this system, two strongly lossy optical modes hybridize through both coherent and dissipative couplings to form an effective optical mode with a drastically reduced linewidth. This linewidth reduction enables the system to access the single-photon strong-coupling and sideband-resolved regimes simultaneously. We formulate the system dynamics using an effective master-equation approach and benchmark it against quantum Langevin and dressed-state master-equation descriptions. With experimentally realistic parameters, we predict clear quantum signatures, including photon blockade and the generation of mechanical cat states. Our work establishes the Fano-mirror architecture as a promising platform for harnessing single-photon optomechanical nonlinearities for quantum state engineering under achievable experimental conditions.

</details>


### [219] [The quantum superluminality in the tunnel-ionization process of H-like atoms](https://arxiv.org/abs/2602.20106)
*Ossama Kullie,Igor A. Ivanov*

Main category: quant-ph

TL;DR: 量子隧穿时间存在争议，其中超光速隧穿现象尤为奇特。本文基于隧穿电离模型，证明高核电荷氢类原子中的隧穿电离可以呈现超光速特性，并可通过阿秒钟实验方案进行验证。


<details>
  <summary>Details</summary>
Motivation: 量子隧穿时间一直是激烈争论的话题，特别是其中存在的超光速（超光速）隧穿现象。作者先前提出的隧穿电离时间延迟模型在绝热和非绝热场校准中与阿秒钟测量结果吻合良好，这促使他们进一步探索隧穿电离中的超光速可能性。

Method: 采用隧穿电离模型，针对具有大核电荷的氢类原子进行分析。研究在不同隧穿电离机制下量子超光速性的表现，并探讨如何通过阿秒钟实验方案进行实验验证。

Result: 研究结果表明，对于具有大核电荷的氢类原子，隧穿电离确实可以呈现超光速特性（量子超光速性）。这种超光速隧穿虽然可能，但只在相对极端的条件下发生。

Conclusion: 量子隧穿确实可以快于光速，但这仅在特定极端条件下实现。研究为理解量子隧穿时间特性提供了新视角，并指出了通过阿秒钟实验验证量子超光速性的可能性。

Abstract: The quantum tunneling time remains the subject of heated debate,
  and one of its most curious features is faster-than-light or
  superluminal tunneling.
  Our tunnel-ionization model of the time-delay, presented in previous work, shows good agreement with the attoclock measurement in the adiabatic and nonadiabatic field calibrations, which also enables the determination of the barrier time-delay.
  In the present work, we show that the tunnel-ionization for H-like atoms with large nuclear charge can be superluminal (quantum superluminality), which in principle can be investigated experimentally using the attoclock scheme.
  We discuss the quantum superluminality in detail for the different regimes of the tunnel-ionization. Our result shows that quantum tunneling faster-than-light is indeed possible, albeit only under somewhat extreme conditions.

</details>


### [220] [CQM: Cyclic Qubit Mappings](https://arxiv.org/abs/2602.20123)
*Maxwell Poster,Sayam Sethi,Jonathan Baker*

Main category: quant-ph

TL;DR: 提出循环量子比特映射(CQM)技术，通过动态重映射逻辑量子比特来缓解NISQ设备硬件异质性，实现逻辑错误率平均化


<details>
  <summary>Details</summary>
Motivation: NISQ时代量子设备存在各种误差源，硬件具有时空变化的误差特性，导致逻辑量子比特性能不均，需要技术来缓解硬件异质性

Method: 提出循环量子比特映射(CQM)技术，在编译时实现动态重映射，通过扩展和收缩逻辑量子比特来利用表面码的晶格手术操作

Result: CQM能够实现逻辑错误率平均化，同时具有最小的执行时间开销和有效的资源利用率

Conclusion: CQM作为一种动态重映射技术，有望缓解NISQ设备的硬件异质性，为量子纠错和容错量子计算提供新途径

Abstract: Quantum computers show promise to solve select problems otherwise intractable on classical computers. However, noisy intermediate-scale quantum (NISQ) era devices are currently prone to various sources of error. Quantum error correction (QEC) shows promise as a path towards fault tolerant quantum computing. Surface codes, in particular, have become ubiquitous throughout literature for their efficacy as a quantum error correcting code, and can execute quantum circuits via lattice surgery operations. Lattice surgery also allows for logical qubits to maneuver around the architecture, if there is space for it. Hardware used for near-term demonstrations have both spatially and temporally varying error results in logical qubits. By maneuvering logical qubits around the topology, an average logical error rate (LER) can be enforced. We propose cyclic qubit mappings (CQM), a dynamic remapping technique implemented during compilation to mitigate hardware heterogeneity by expanding and contracting logical qubits. In addition to LER averaging, CQM shows initial promise given it's minimal execution time overhead and effective resource utilization.

</details>


### [221] [Experimental characterization of coherent and non-Markovian errors using tangent space decomposition](https://arxiv.org/abs/2602.20128)
*Elia Perego,Andrea Rodriguez-Blanco,K. Birgitta Whaley,Bharath Hebbe Madhusudhana*

Main category: quant-ph

TL;DR: 该论文提出了一种基于切空间分解的技术，用于在单量子比特门中量化相干、马尔可夫和非马尔可夫误差，并在离子阱平台上实验验证。


<details>
  <summary>Details</summary>
Motivation: 量子设备通常同时存在系统性相干失配和时间相关的涨落误差，而传统基准测试技术依赖于马尔可夫和时间无关的噪声假设，无法准确表征这些复杂误差。

Method: 采用切空间分解技术，将量子操作的微小缺陷视为目标量子映射的扰动，表示为量子通道空间中的切向量。这种方法将偏差自然分解为三个分量：相干、马尔可夫和非马尔可夫过程。通过分析实验重建的过程矩阵（使用泡利转移矩阵和Choi表示）来验证该方法。

Result: 在$^{40}$Ca$^+$离子阱平台上实验验证了该方法，成功识别并量化了由实验环境中缓慢涨落引起的非马尔可夫效应，同时表征了确定性相干失配。该方法通过单个层析快照提供了每种误差机制的定量贡献。

Conclusion: 该技术为量子控制系统中的复杂误差源诊断提供了物理透明且实验可访问的工具，能够同时处理相干、马尔可夫和非马尔可夫误差，超越了传统基准测试方法的局限性。

Abstract: Accurate characterization of coherent and non-Markovian errors remains a central challenge in quantum information processing, as conventional benchmarking techniques typically rely on Markovian and time-independent noise assumptions. In practice, however, quantum devices exhibit both systematic coherent miscalibrations and temporally correlated fluctuations, which complicate error diagnosis and mitigation. Here, we apply a technique based on tangent-space decomposition to characterize such error in single-qubit quantum gates implemented on a trapped ion platform. Small imperfections in a quantum operation are treated as perturbations of the target quantum map, represented as tangent vectors in the space of quantum channels. This formulations enables a natural decomposition of the deviation into three components corresponding to coherent, Markovian and non-Markovian processes.The relative weights of these components provide a quantitative measure of the contribution from each type of error mechanism, directly from a single tomographic snapshot. We experimentally validate this method on a single-qubit gates implemented on a trapped $^{40}$Ca$^+$ ion, where control is achieved through laser-driven optical transitions. By analyzing experimentally reconstructed process matrices, expressed in the Pauli Transfer Matrix and Choi representations, we identify and quantify non-Markovian effects arising from controlled injection of slow fluctuations in the experimental environment. We also characterize deterministic coherent miscalibrations using the same technique. This approach provides a physically transparent and experimentally accessible tool for diagnosing complex error sources in quantum control systems.

</details>


### [222] [Quantum Information Approach to Bosonization of Supersymmetric Yang-Mills Fields](https://arxiv.org/abs/2602.20149)
*Radhakrishnan Balu,S. James Gates*

Main category: quant-ph

TL;DR: 该论文研究了超对称性的玻色化，在Wess-Zumino量子力学中构建了最小玻色化系统，并发现了osp(2|2)对称性，通过两种诱导方法获得了量子比特算符表示。


<details>
  <summary>Details</summary>
Motivation: 玻色福克空间具有灵活性，任何经典概率分布都可以在其上实现，这使其成为处理量子过程的通用框架。作者希望通过玻色化超对称性来利用这一优势。

Method: 1. 构建具有一个玻色子和两个费米子自由度的最小玻色化系统；2. 迭代此过程构建类似展开Adinkras的SUSY系统塔；3. 识别系统的osp(2|2)对称性；4. 通过两种方法构建不可约表示：首先使用Clifford代数构建费米子表示，然后诱导到gl(2|2)并限制到osp(2|2)；其次从玻色子扇区诱导表示。

Result: 获得了用量子比特算符表示的系统，这些表示适用于在混合量子比特与费米子或玻色子量子计算机上实现，为使用量子信息方法解决SUSY问题提供了途径。

Conclusion: 成功实现了超对称性的玻色化，构建了具有osp(2|2)对称性的系统，并通过跨扇区诱导表示获得了量子比特算符表示，为量子信息方法应用于SUSY问题提供了新框架。

Abstract: We consider bosonization of supersymmetry in the context of Wess-Zumino quantum mechanics. Our motivation for this investigation is the flexibility the bosonic fock space affords as any classical probability distribution can be realized on it making it a versatile framework to work with for quantum processes. We proceed by constructing a minimal bosonization of a system with one bosonic and two fermionic degrees of freedom. We iterate this process to construct a tower of SUSY systems that is akin to unfolded Adinkras. We then identify an osp(2|2) symmetry of the system constructed. To build an irreducible representation of the system we induce representations across the sectors, a first to our knowledge, as the previous work have focused on induction only within the bosonic sector. First, we start with a fermionic representation using Clifford algebras and then induce a representation to gl(2|2) and restrict it to osp(2|2). In the second method, we induce a representation from that of the bosonic sector. In both cases, our representations are in terms of qubit operators that provide a way to solve SUSY problems using quantum information based approaches. Depending upon the direction of induction the representations are suitable for implementation on a hybrid qubit and fermionic or bosonic quantum computers.

</details>


### [223] [Quantum simulation in the Heisenberg picture via vectorization](https://arxiv.org/abs/2602.20154)
*Shao-Hen Chiew,Armando Angrisani,Zoë Holmes,Giuseppe Carleo*

Main category: quant-ph

TL;DR: 提出一个在量子硬件上模拟海森堡绘景量子系统的通用框架，通过向量化映射将海森堡算符任务转换为薛定谔绘景任务


<details>
  <summary>Details</summary>
Motivation: 量子计算机和模拟器天然适合处理薛定谔绘景任务，但许多重要量子任务（如算符采样、OTOCs、关联函数等）在海森堡绘景中定义，需要一种将海森堡绘景任务映射到薛定谔绘景的方法

Method: 基于向量化映射框架，利用算符与量子态之间的映射关系，将海森堡算符任务转换为标准的薛定谔绘景任务，继承了正反时间薛定谔绘景量子模拟的结构和资源需求

Result: 开发了算符采样、OTOCs/超算符期望值及其高阶矩、两点关联函数、算符稳定子和纠缠熵等任务的新协议或改进协议，提出了考虑设备连接约束的数字和模拟量子模拟器实现方案

Conclusion: 该框架为在量子硬件上模拟海森堡绘景量子系统提供了通用方法，能够充分利用量子计算机的薛定谔绘景优势来处理海森堡绘景任务，具有实际可实施性

Abstract: We present a general framework for simulating quantum systems in the Heisenberg picture on quantum hardware. Based on the vectorization map, our framework fully exploits the mapping between operators and quantum states, allowing any task defined on Heisenberg operators to be mapped to standard Schrödinger-picture tasks that are naturally accessible via quantum computers and simulators. This yields new or improved protocols for tasks such as operator sampling, the computation of OTOCs/superoperator expectation values and their higher order moments, two-point correlators, and operator stabilizer and entanglement entropies. Our approach is also amenable to implementation, as it inherits the structure and resource requirements of the (forward and time-reversed) Schrödinger-picture quantum simulation problem. We demonstrate this by proposing implementations of our framework for a 2D problem on digital and analog quantum simulators, taking into account device connectivity constraints.

</details>


### [224] [Generalized $\mathbb{Z}_p$ toric codes as qudit low-density parity-check codes](https://arxiv.org/abs/2602.20158)
*Zijian Liang,Yu-An Chen*

Main category: quant-ph

TL;DR: 研究二维平移不变CSS稳定子码，在扭曲边界条件下推广Kitaev Zp环面码，通过Gröbner基方法高效计算逻辑维度k，系统搜索发现具有最优有限尺寸性能的qudit LDPC码。


<details>
  <summary>Details</summary>
Motivation: 研究二维平移不变CSS稳定子码在扭曲边界条件下的性质，推广Kitaev Zp环面码，探索qudit低密度奇偶校验码的最优有限尺寸性能。

Method: 使用Laurent多项式形式体系，采用Gröbner基方法高效计算逻辑维度k，避免显式构建大型奇偶校验矩阵。对p∈{3,5,7,11}进行系统搜索，考察不同稳定子实现和晶格几何。

Result: 发现具有最优有限尺寸性能的qudit LDPC码，如[[242,10,22]]_3和[[120,6,20]]_11，均达到kd²/n=20。在搜索范围内，固定n时最佳kd²随p增加，经验关系为kd²=0.0541n²lnp+3.84n。

Conclusion: 研究展示了qudit CSS稳定子码在扭曲边界条件下的系统构造方法，发现了具有优异有限尺寸性能的代码，其性能与Bravyi-Poulin-Terhal型权衡兼容，当相互作用范围随系统尺寸增长时。

Abstract: We study two-dimensional translation-invariant CSS stabilizer codes over prime-dimensional qudits on the square lattice under twisted boundary conditions, generalizing the Kitaev $\mathbb{Z}_p$ toric code by augmenting each stabilizer with two additional qudits. Using the Laurent-polynomial formalism, we adapt the Gröbner basis to compute the logical dimension $k$ efficiently, without explicitly constructing large parity-check matrices. We then perform a systematic search over various stabilizer realizations and lattice geometries for $p\in\{3,5,7,11\}$, identifying qudit low-density parity-check codes with the optimal finite-size performance. Representative examples include $[[242,10,22]]_3$ and $[[120,6,20]]_{11}$, both achieving $k d^{2}/n=20$. Across the searched regime, the best observed $k d^{2}$ at fixed $n$ increases with $p$, with an empirical relation $k d^{2} = 0.0541 \, n^{2}\ln p + 3.84 \, n$, compatible with a Bravyi--Poulin--Terhal-type tradeoff when the interaction range grows with system size.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [225] [Canonical Vielbeins for General Relativity: D + 1 Decomposition and Constraint Analysis](https://arxiv.org/abs/2602.18491)
*Joakim Flinckman,Daniel Blixt*

Main category: gr-qc

TL;DR: 该论文自洽地推导了D+1维广义相对论在标架变量下的哈密顿形式，建立了洛伦兹协变和SO(D)协变的相空间作用量，并恢复了完整的局域洛伦兹对称性。


<details>
  <summary>Details</summary>
Motivation: 在广义相对论的哈密顿形式中，使用标架（vielbein）变量而非传统度规变量具有理论优势，但需要系统地推导其相空间结构、约束代数，并建立与度规表述的联系。

Method: 从标准D+1分解的爱因斯坦-希尔伯特作用出发，推导洛伦兹协变和SO(D)协变的相空间作用量，识别主要洛伦兹约束，获得哈密顿和动量约束，计算一级约束代数，并构建SO(D)协变表述中的boost生成元。

Result: 成功推导了标架变量下的哈密顿形式，建立了完整的约束代数，恢复了局域洛伦兹对称性，并明确了标架与度规相空间表述之间的关系。

Conclusion: 该工作为广义相对论的标架变量哈密顿形式提供了自洽的数学基础，特别在构建boost生成元方面恢复了完整的洛伦兹对称性，为相关理论研究提供了重要工具。

Abstract: We provide a self-contained derivation of the Hamiltonian formulation of General Relativity in vielbein variables in $d=D+1$ dimensions. Starting from the Einstein--Hilbert action in a standard metric $D+1$ decomposition, we derive Lorentz- and $\mathrm{SO}(D)$-covariant phase-space actions, identify the primary Lorentz constraints, and obtain the Hamiltonian and momentum constraints. We compute the resulting first-class constraint algebra, relate the vielbein and metric phase-space formulations, and discuss the rotation/boost decomposition. In particular, we construct the boost generator in the $\mathrm{SO}(D)$-covariant formulation, thereby recovering full local Lorentz symmetry.

</details>


### [226] [Null hypersurfaces in general relativity: Intrinsic symmetries and differential invariants](https://arxiv.org/abs/2602.18499)
*G. Dautcourt*

Main category: gr-qc

TL;DR: 本文研究广义相对论中零超曲面的内在Killing对称性，使用三元组微积分和微分不变量进行分类，给出四阶以下的运动群分类及度量正规形式，并讨论零剪切和零散度的视界。


<details>
  <summary>Details</summary>
Motivation: 研究零超曲面的内在几何对称性，脱离嵌入时空的依赖，建立独立于背景时空的零超曲面几何理论，为理解黑洞视界等物理结构提供数学基础。

Method: 采用三元组微积分和微分不变量方法，将零超曲面视为具有退化度量(0,+,+)的独立几何对象，对运动群进行四阶以下的分类，给出度量的正规形式并计算不变量。

Result: 建立了零超曲面的完整分类体系，给出了各类型的度量正规形式及其不变量列表，特别讨论了零剪切和零散度的视界情况，扩展了先前的研究工作。

Conclusion: 成功构建了零超曲面的内在Killing对称性理论框架，为研究广义相对论中的零超曲面（特别是黑洞视界）提供了系统的几何工具和分类方法。

Abstract: This paper investigates intrinsic Killing symmetries of null hypersurfaces $\mathcal{N}_3$ within the framework of general relativity. To this end we consider $\mathcal{N}_3$ as detached from the embedding spacetime and equipped with a degenerate metric of signature (0,+,+). As geometrical tools we use a triad calculus and differential invariants. Extending prior work, we present a classification of null hypersurfaces according to groups of motion up to the fourth order. For each type certain normal forms of the metric are given, and their invariants are listed. A discussion of horizons - defined as null hypersurfaces with vanishing shear and divergence - is included.

</details>


### [227] [Population-coherence routes to purity in Page-type models of black-hole evaporation](https://arxiv.org/abs/2602.18503)
*José J. Gil*

Main category: gr-qc

TL;DR: 本文从密度矩阵纯度的种群-相干分解视角重新审视黑洞信息问题，提出在蒸发过程中纯度的恢复必须是相干主导的。


<details>
  <summary>Details</summary>
Motivation: 重新审视黑洞信息问题，从密度矩阵纯度的内部结构分解角度分析黑洞蒸发过程中信息如何恢复，特别是区分种群和相干性对纯度的贡献。

Method: 1. 建立n维密度矩阵的种群-相干分解形式化框架，定义归一化全局纯度指数和两个互补指数（种群指数和相干指数）；2. 在二维情况下构造具有相同谱和全局纯度但内部结构相反的态族；3. 将此框架应用于标准的Page型蒸发模型，分析蒸发过程中纯度的种群和相干分量的行为。

Result: 在能量自由设定下，当辐射种群在选定基中保持近似均匀时，晚期纯度的恢复必须是相干主导的：辐射的全局纯度趋近于1，而种群指数保持较小，相干指数承载几乎所有的纯度。

Conclusion: 黑洞信息问题的解决需要关注纯度恢复的内部结构，特别是在蒸发后期，纯度的恢复主要通过相干性而非种群分布来实现，这为理解黑洞信息悖论提供了新的视角。

Abstract: We revisit the black-hole information problem from the viewpoint of a population-coherence decomposition of density-matrix purity. Building on a previously developed formalism for ndimensional density matrices, we characterize each state by a normalized global purity index and two complementary indices, which quantify the contributions of level populations and coherences. This yields a simple quadratic relation and a geometric representation in a population-coherence plane, where different routes to purity can be distinguished. In the two-level case we construct explicit families of states with identical spectra and global purity but opposite internal structure, realizing population-dominated and coherence-dominated routes. We then apply this framework to a standard Page-type evaporation model without an explicit Hamiltonian, in which a black hole and its Hawking radiation form a bipartite pure state with varying Hilbert-space dimensions. Using known results for typical reduced states in large dimensions, we analyze the behavior of population and coherence components of purity along the evaporation process. Under the physically motivated requirement that, in this energy-free setting, the radiation populations remain nearly uniform in the chosen basis, we show that the late-time recovery of purity must be coherence-dominated: the global purity of the radiation approaches unity while the population index stays small and the coherence index carries essentially all the purity.

</details>


### [228] [Two Parameter Deformation of Embedding Class-I Compact Stars in Linear $f(Q)$ Gravity](https://arxiv.org/abs/2602.18615)
*Samstuti Chanda,Ranjan Sharma*

Main category: gr-qc

TL;DR: 在线性f(Q)引力中引入引力解耦机制，通过参数(ε,β₁)联合作用扩大中子星质量窗口，同时保持物理可接受性


<details>
  <summary>Details</summary>
Motivation: 最近的多信使观测（包括中子星-黑洞质量间隙区域的引力波探测和高质量脉冲星的精确测量）需要能够扩大恒星质量窗口的机制，而不需要任意地使状态方程在因果极限处变得过于刚硬

Method: 在线性f(Q)引力中引入引力解耦机制，采用嵌入类-I Vaidya-Tikekar配置。通过两个参数(ε,β₁)控制：ε控制几何变形和状态方程刚度，β₁独立地重新标度物质部分而不改变度量结构

Result: 确定了从正则性、匹配性、因果性和致密性要求得出的可容许参数域，推导了解耦嵌入类-I配置的解析致密性界限。ε和β₁的联合作用扩大了可访问的恒星质量窗口，同时保持物理可接受性

Conclusion: 该框架允许与最近的高质量脉冲星和质量间隙候选体兼容的配置，而不超过因果极限，为在固定几何变形下直接比较GR和线性f(Q)引力提供了途径

Abstract: Recent multi-messenger observations, including gravitational wave detections of compact objects in the neutron star-black hole mass-gap region and precise measurements of high-mass pulsars, motivate mechanisms capable of enlarging the stellar mass window without arbitrarily stiffening the equation of state (EOS) toward the causal limit. In linear $f(Q)$ gravity of the form $f(Q)=β_1 Q+β_2$, the theory is dynamically equivalent to General Relativity at the geometric level and modifies stellar structure solely through a uniform rescaling of the matter sector governed by $β_1$. Consequently, linear $f(Q)$ alone does not introduce new geometric families of stellar solutions or alter classical compactness bounds. To overcome this structural limitation, we incorporate gravitational decoupling within an embedding class-I (Karmarkar) Vaidya-Tikekar configuration in linear $f(Q)$ gravity. While similar VT-based decoupling constructions exist in GR, the present framework introduces a controlled two-parameter deformation characterized by $(ε,β_1)$: the decoupling parameter $ε$ governs geometric deformation and EOS stiffness, whereas $β_1$ independently rescales the matter sector without altering the metric structure. This separation permits a direct comparison between GR and linear $f(Q)$ gravity at fixed geometric deformation, thereby isolating pure coupling-driven mass enhancement. We determine the admissible parameter domain from regularity, matching, causality and compactness requirements and derive an analytic compactness bound for the decoupled embedding class-I configuration. The combined action of $ε$ and $β_1$ enlarges the accessible stellar mass window while preserving physical acceptability, allowing configurations compatible with recent high-mass pulsars and mass-gap candidates without exceeding causal limits.

</details>


### [229] [Ultraviolet Fixed Point in Covariant Loop Quantum Gravity](https://arxiv.org/abs/2602.18665)
*Muxin Han*

Main category: gr-qc

TL;DR: 本文研究了4维洛伦兹协变圈量子引力的紫外行为，解决了自旋泡沫振幅对三角剖分的无限模糊性问题。通过引入自旋网络堆栈及其协变扩展，将复形求和划分为不同家族，发现理论存在凝聚现象，量子几何凝聚到主导的小自旋构型。找到了控制紫外区域候选固定点，在此固定点下完整LQG振幅在领头阶动态约化为拓扑理论，三角剖分依赖的无限模糊性减少为有限边界系数。


<details>
  <summary>Details</summary>
Motivation: 解决4维洛伦兹协变圈量子引力中自旋泡沫振幅对三角剖分的无限模糊性问题，探索理论的紫外行为，为自旋泡沫理论在基本层面定义连续极限。

Method: 引入自旋网络堆栈及其协变扩展（自旋泡沫堆栈），将复形求和划分为不同家族。通过分析量子几何的凝聚现象，识别控制紫外（小自旋）区域的候选固定点。

Result: 发现理论存在凝聚现象，量子几何凝聚到主导的小自旋构型。在候选固定点处，完整LQG振幅在领头阶动态约化为拓扑理论，三角剖分依赖的无限模糊性减少为与有限三维边界块基相关的有限边界系数。

Conclusion: 为自旋泡沫理论在基本层面提供了连续极限的定义，解决了三角剖分依赖的无限模糊性问题，表明在紫外区域理论可约化为拓扑理论。

Abstract: We investigate the ultraviolet behavior of 4-dimensional Lorentzian covariant Loop Quantum Gravity (LQG) and address the problem of infinite ambiguities relating to the triangulation dependence of spinfoam amplitudes. We consider the complete LQG amplitude that summing spinfoam amplitudes over 2-complexes. By introducing spin-network stacks and their covariant extension, spinfoam stacks, the summation over complexes is partitioned into distinct families. We demonstrate that the theory exhibits a condensation phenomenon, where quantum geometry condenses to a dominant small spin configuration. We identify a candidate fixed point controlling the ultraviolet (small spin) regime of covariant LQG. At this fix point, the complete LQG amplitude dynamically reduces to a topological theory at leading order, and the infinite ambiguities of triangulation dependence reduces to a finite set of boundary coefficients associated with a finite basis of 3-dimensional boundary blocks. These results provide a definition for the continuum limit of spinfoam theory at the fundamental level.

</details>


### [230] [New Black hole Solutions in $f(\mathbb{Q})$ Gravity](https://arxiv.org/abs/2602.18732)
*A. Dehyadegari,A. Sheykhi*

Main category: gr-qc

TL;DR: 本文研究了对称远平行f(Q)修正引力理论中的静态球对称真空解，发现了两个满足场方程的联络类，恢复了广义相对论的精确解，并推导了二次模型的微扰解，揭示了联络"毛发"的存在。


<details>
  <summary>Details</summary>
Motivation: 研究对称远平行f(Q)修正引力理论中的真空解，探索非度量性联络引入的丰富结构，寻找超越广义相对论的新解。

Method: 从最近提出的对称性和几何约束相容的仿射联络分类出发，发展系统方法求解完整场方程。识别两个满足场方程的联络类，对任意f(Q)函数当非度量性标量Q为零时恢复广义相对论解，对二次模型f(Q)=Q+αQ²使用微扰方法推导渐近平坦解析解。

Result: 发现了两个满足场方程的联络类；恢复了广义相对论的精确解（Schwarzschild和Schwarzschild (anti)de-Sitter度规）；推导了二次模型的二阶微扰解，显示对标准Schwarzschild度规的修正，包含可解释为联络毛发的新积分常数；揭示了视界半径的修正可用Lambert W函数紧凑表示。

Conclusion: 研究为f(Q)引力提供了新的非平凡真空解，突出了非度量性联络引入的丰富结构，连接"毛发"的存在表明对称远平行几何允许超越广义相对论度规解的新自由度。

Abstract: We investigate static and spherically symmetric vacuum solutions in the symmetric teleparallel $f(\mathbb{Q})$ modified theory of gravity. Starting from a recently proposed classification of affine connections compatible with both the symmetries of spacetime and the constraints of symmetric teleparallel geometry, we develop a systematic approach to solve the full field equations. We first identify two distinct classes of connections that satisfy the off-diagonal metric field equations and the connection constraints. For an arbitrary $f(\mathbb{Q})$ function when the non-metricity scalar $\mathbb{Q}$ vanishes, we recover exact analytical solutions equivalent to those of general relativity, including the Schwarzschild and Schwarzschild (anti)de-Sitter metrics. We then extend our analysis beyond general relativity by considering the quadratic model $f(\mathbb{Q})=\mathbb{Q}+α~\mathbb{Q}^2$ with a small parameter $α$. Using a perturbative approach, we derive asymptotically flat, analytical solutions up to second order in $α$. These solutions exhibit corrections to the standard Schwarzschild metric, characterized by new integration constants that can be interpreted as connection hair. We explore the asymptotic behavior of these solutions and disclose that the horizon radius receives corrections that can be expressed compactly using the Lambert $\mathcal{W}$ function. Our results provide new, non-trivial vacuum solutions within $f(\mathbb{Q})$ gravity and highlight the rich structure introduced by the non-metricity connection.

</details>


### [231] [Generalized Carter & Rüdiger Constants of $\sqrt{\text{Kerr}}$](https://arxiv.org/abs/2602.18790)
*Christopher de Firmian,Justin Vines*

Main category: gr-qc

TL;DR: 研究带电自旋测试粒子在带电旋转环盘奇点电磁场中的运动，探讨是否存在类似Carter常数的额外隐藏守恒量，发现仅当粒子的多极矩结构参数取特定值时这些常数才存在。


<details>
  <summary>Details</summary>
Motivation: 研究带电自旋测试粒子在特定电磁场背景下的运动规律，探索是否存在类似Kerr时空中Carter常数的额外守恒量，这对于理解带电旋转奇点附近的粒子动力学具有重要意义。

Method: 使用Mathisson-Papapetrou-Dixon方程描述带电自旋测试粒子的运动，考虑粒子的自旋和场诱导的多极矩，在带电旋转环盘奇点的电磁场背景下分析运动方程，寻找额外的守恒量。

Result: 发现两个额外的隐藏守恒量仅当粒子的Wilson系数取特定值时存在，这些特定值对应于通过二阶自旋的有效康普顿振幅的自旋指数化。

Conclusion: 带电自旋测试粒子在带电旋转环盘奇点电磁场中的运动存在额外的守恒量，但这些守恒量的存在强烈依赖于粒子的多极矩结构参数，仅当参数满足特定关系时才存在。

Abstract: We consider the motion of a charged spinning test/probe particle -- governed by the Mathisson-Papapetrou-Dixon equations with generic, adiabatic, and conservative spin- and field-induced multipole moments -- in a background $\sqrt{\text{Kerr}}$ field on flat spacetime: the electromagnetic field of a charged spinning ring-disk singularity obtained from the $G\to 0$ limit of the Kerr-Newman solution for a charged spinning black hole. We investigate the existence of two extra hidden constants of motion, analogous to the Carter constant (for geodesic motion in a Kerr spacetime, or for its spinning-probe generalization) and Rüdiger's linear-in-spin constant for a spinning probe in a Kerr background. We find that these two constants exist only when the Wilson coefficients parameterizing the probe's multipole structure take the particular values corresponding to spin-exponentiation of the effective Compton amplitudes through second order in spin.

</details>


### [232] [Hernquist distribution of matter as a source of black-hole geometry](https://arxiv.org/abs/2602.18877)
*Erdinç Ulaş Saka*

Main category: gr-qc

TL;DR: 某些暗晕密度剖面在径向压力条件Pr=-ρ下可产生规则黑洞解，但其他常见剖面（如Hernquist模型）仍保持中心奇点


<details>
  <summary>Details</summary>
Motivation: 先前研究表明Dehnen和Einasto暗晕模型在特定压力条件下可产生规则黑洞解，本研究旨在检验其他常用暗晕剖面是否也能产生类似的无奇点黑洞解

Method: 对多种常用暗晕密度剖面（包括Hernquist模型）施加径向压力条件Pr=-ρ，分析其是否产生规则几何结构

Result: 发现某些常用暗晕剖面（如Hernquist模型）在相同压力条件下无法产生规则几何，而是支持保留中心奇点的黑洞解

Conclusion: 并非所有暗晕密度剖面都能在Pr=-ρ条件下产生规则黑洞解，某些常见剖面仍会导致中心奇点存在

Abstract: It was recently demonstrated that imposing the condition $P_{r} = -ρ$ on the radial pressure of a galactic halo can lead to regular black-hole solutions for certain density profiles, such as the Dehnen and Einasto models. In the present work, we show that some of the most commonly used halo profiles, including the Hernquist model, do not yield regular geometries under the same condition, but instead support black-hole solutions that retain a central singularity

</details>


### [233] [Thermal aspects and particle dynamics of Euler-Heisenberg AdS black hole in 4D Einstein Gauss-Bonnet gravity](https://arxiv.org/abs/2602.18945)
*Bilel Hamil,Faisal Javed*

Main category: gr-qc

TL;DR: 在四维爱因斯坦-高斯-博内引力与欧拉-海森堡非线性电动力学耦合框架下，构建了带电AdS黑洞解，研究了其物理性质、热力学行为、焦耳-汤姆逊膨胀以及类时测地线。


<details>
  <summary>Details</summary>
Motivation: 研究高阶曲率修正（高斯-博内项）和非线性电动力学（欧拉-海森堡模型）如何共同影响AdS黑洞的几何结构、热力学性质和动力学行为。

Method: 在扩展相空间（将宇宙学常数解释为热力学压力）中，构建了四维爱因斯坦-高斯-博内引力与欧拉-海森堡非线性电动力学耦合的场方程，求解黑洞解并分析其视界结构、热力学行为、焦耳-汤姆逊膨胀和类时测地线。

Result: 高阶曲率和非线性电磁修正显著改变了黑洞视界结构（可产生多重视界），修改了状态方程、临界行为和热稳定性，影响了焦耳-汤姆逊膨胀的冷却/加热区域，并显著改变了强场区域的有效势、轨道稳定性和粒子运动。

Conclusion: 高斯-博内耦合和欧拉-海森堡参数对四维带电AdS黑洞的几何、热力学和动力学性质产生重要影响，为研究高阶曲率修正和非线性电动力学的联合效应提供了理论框架。

Abstract: We construct charged AdS black hole solutions in four dimensional Einstein Gauss Bonnet gravity coupled to Euler Heisenberg nonlinear electrodynamics and investigate their physical properties. The modified field equations admit black hole solutions whose horizon structure is significantly affected by higher-curvature and nonlinear electromagnetic corrections, allowing for multiple horizons depending on the model parameters. In the extended phase space, where the cosmological constant is interpreted as thermodynamic pressure, we analyze the thermodynamic behavior and show that both the Gauss Bonnet coupling and the Euler Heisenberg parameter induce notable modifications in the equation of state, critical behavior, and thermal stability. Interpreting the black hole mass as enthalpy, we study the Joule-Thomson expansion and determine the inversion temperature and pressure, demonstrating that higher curvature and nonlinear electrodynamic effects substantially influence the cooling and heating regions. Finally, we examine time-like geodesics and show that Gauss Bonnet corrections significantly modify the effective potential, orbital stability, and particle motion in the strong-field regime

</details>


### [234] [Inertial Frame Dragging as a Probe to Differentiate Kerr-Newman Naked Singularities from Black Holes](https://arxiv.org/abs/2602.18972)
*Arindam Kumar Chatterjee,Parthapratim Pradhan*

Main category: gr-qc

TL;DR: 研究Kerr-Newman时空中惯性系拖曳和相对论进动，展示陀螺仪观测如何区分黑洞和裸奇点，发现进动频率在黑洞视界附近发散，而在裸奇点时空中保持有限。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过陀螺仪观测操作性地区分Kerr-Newman黑洞和裸奇点，为检验宇宙监督假设提供强场探测工具。

Method: 研究附着于静止观测者的测试陀螺仪，推导Lense-Thirring、测地线和一般自旋进动频率的闭式表达式，分析赤道圆轨道的基本轨道频率和径向/垂直环频率。

Result: 发现黑洞和裸奇点在自旋进动行为上存在定性差异：黑洞视界附近进动频率发散（仅ZAMO家族除外），裸奇点进动在全时空保持有限；电荷参数Q会系统性地修改频率层次结构，包括节点进动频率出现有限最大值、峰值振幅随Q减小，以及在高自旋大电荷情况下可能发生方向反转。

Conclusion: 自旋进动行为可作为区分视界与暴露奇点的强有力探测工具，为未来高精度进动/QPO测量检验宇宙监督假设提供了潜在途径。

Abstract: We investigate inertial frame dragging and relativistic precession in the Kerr--Newman spacetime and show how gyroscopic observables can operationally discriminate between Kerr--Newman black holes and Kerr--Newman naked singularities. We study a test gyroscope attached to a stationary observer and derive closed-form expressions for the Lense--Thirring, geodetic, and general spin-precession frequencies. A sharp qualitative distinction emerges: for Kerr--Newman black holes, the spin-precession frequency generically diverges as the horizon is approached (remaining finite only for the ZAMO family), whereas for Kerr--Newman naked singularities, the precession remains finite throughout the spacetime, with divergences confined to the ring singularity on the equatorial plane. Working with physically admissible stationary observers (including ZAMOs), we first construct the timelike geodesic motion and the fundamental orbital frequencies for equatorial circular orbits. Using these, we analyse the radial and vertical epicyclic frequencies, the ISCO shift induced by the charge parameter $Q$, and the associated periastron and nodal precession frequencies relevant to quasi-periodic oscillations (QPOs). We demonstrate that nonzero $Q$ produces systematic, and in rapidly rotating regimes nontrivial, modifications to the frequency hierarchy: $ν_{\rm nod}$ can develop a finite maximum at $r=r_p=\mathcal{O}(M)$, its peak amplitude decreases with increasing $Q$, and sign reversals may occur for sufficiently large charge and high spin, signalling a reversal of nodal-precession orientation. These results establish spin-precession behaviour as a robust strong-field probe of horizons versus exposed singularities, with potential implications for testing cosmic censorship using future high-precision precession/QPO measurements.

</details>


### [235] [Testing the Spacetime Geometry of Sgr A* with the Relativistic Orbit of S2 star](https://arxiv.org/abs/2602.18994)
*Parth Bambhaniya,Preet Dalal,Giovani H. Vicentin,Riccardo Della Monica,Elisabete M. de Gouveia Dal Pino,Bina Patel*

Main category: gr-qc

TL;DR: 利用S2恒星轨道相对论性测试Sgr A*时空几何，比较多种黑洞和裸奇点模型，发现当前S2数据无法区分某些时空，但约束了非史瓦西时空参数。


<details>
  <summary>Details</summary>
Motivation: 利用S2恒星轨道观测数据测试银河系中心超大质量天体Sgr A*的时空几何结构，区分不同黑洞模型和裸奇点模型，突破事件视界望远镜阴影成像的局限性。

Method: 对史瓦西、Reissner-Nordström、Bardeen、Hayward、Simpson-Visser黑洞及Janis-Newman-Winicour裸奇点等模型，积分类时测地线方程，结合Rømer时间延迟和相对论红移效应，投影到天体测量和光谱观测数据，与VLT观测对比并考虑EHT阴影约束。

Result: 当前S2数据无法统计区分史瓦西、Reissner-Nordström和Bardeen规则黑洞等时空模型；基于AIC和BIC的模型比较显示这些模型性能相近；约束了非史瓦西时空的广义电荷参数q/M；识别出可通过未来VLT和Keck高精度观测进一步测试的特定几何。

Conclusion: 当前S2恒星观测数据尚不足以区分某些黑洞模型，但已能约束非史瓦西时空参数；未来更高精度的天体测量观测将能进一步测试和区分不同的时空几何模型。

Abstract: In this work, we perform a relativistic test of the spacetime geometry of Sagittarius A* (Sgr A*) using the orbit of the S2 star. We consider a broad class of compact object models, including Schwarzschild, Reissner-Nordström, Bardeen, Hayward, and Simpson-Visser black holes, as well as the Janis-Newman-Winicour naked singularity spacetime. For each geometry, we integrate the timelike geodesic equations and consistently project the resulting trajectories onto astrometric and spectroscopic observables, incorporating Rømer time delay and relativistic redshift effects. The theoretical predictions are tested with current Very Large Telescope (VLT) observations of the S2 star, while simultaneously imposing constraints from the Event Horizon Telescope shadow size. We find that several spacetimes that are degenerate at the level of shadow imaging, most notably Schwarzschild, Reissner-Nordström, and Bardeen regular black hole geometries, remain statistically indistinguishable when tested against present S2 data. We further carry out a statistical model comparison based on the Akaike and Bayesian information criteria (AIC and BIC) to evaluate the relative performance of the alternative spacetime models. Our analysis also constrains the generalized charge like parameter $q/M$ in non-Schwarzschild spacetimes based on current S2 star observations, and identifies specific black hole and horizonless geometries that can be further tested with forthcoming high precision astrometric observations from the VLT and Keck telescopes.

</details>


### [236] [Unitary and finite self-energy of a single classical point charge and naked point singularity spacetimes](https://arxiv.org/abs/2602.19015)
*Daxx W. Delucchi*

Main category: gr-qc

TL;DR: 该论文分析了超极端Reissner-Nordström几何中线性爱因斯坦-麦克斯韦扰动的动力学，证明了在静态点电荷非线性自场背景下，具有有限T能量的扰动在能量空间上具有幺正演化。


<details>
  <summary>Details</summary>
Motivation: 研究超极端Reissner-Nordström几何（带裸奇点的黑洞解）中线性爱因斯坦-麦克斯韦扰动的动力学行为，特别是理解在静态点电荷非线性自场背景下，扰动如何演化以及奇点的物理效应。

Method: 使用光学径向坐标和Kodama-Ishibashi规范不变形式，将每个辐射多极子编码为半直线上的单个标量主场。通过Regge-Wheeler型主方程分析，利用Friedrichs扩展构造主算子的自伴实现，并构建未来零无穷远处的辐射场。

Result: 证明了爱因斯坦-麦克斯韦T能量的空间加势能部分是闭的且有下界，定义了自然能量空间上的正二次型。所有具有有限空间T能量的线性扰动在能量空间上幺正演化，裸奇点在有限光学距离处是"沉默的"（不携带T能量通量）。

Conclusion: 超极端Reissner-Nordström几何中的线性爱因斯坦-麦克斯韦扰动具有幺正演化，裸奇点不影响能量守恒，辐射场的构造提供了自场动力学的平移表示，其中守恒的T能量与推迟时间中辐射剖面的L²范数一致。

Abstract: We analyze linear Einstein--Maxwell perturbations of the superextremal Reissner--Nordström geometry in its static Kerr--Schild rest frame, viewing it as the nonlinear self-field of a single static point charge. In optical radial coordinates, and using the Kodama--Ishibashi gauge-invariant formalism, each radiative multipole is encoded by a single scalar master field on the half-line. The resulting master equation is of Regge--Wheeler type, with an inverse-square potential core at the optical apex (controlled by a Hardy inequality) and a short-range tail at infinity. The spatial-plus-potential part of the Einstein--Maxwell $T$-energy is closable and bounded below, which defines a positive quadratic form on the natural energy space. Its Friedrichs extension then gives the canonical self-adjoint realization of the master operator. The static Coulomb field and its nonlinear gravitational backreaction are treated as the exact background. All linear Einstein--Maxwell perturbations with finite spatial $T$-energy evolve unitarily on the energy space. The naked singularity at finite optical distance is ``silent'' in the technical sense that it carries no $T$-energy flux. We also construct the forward radiation field at future null infinity, obtaining a translation representation of the self-field dynamics in which the conserved $T$-energy coincides with the $L^2$ norm of the radiation profile in retarded time.

</details>


### [237] [The Role of Inhomogeneities in the Turbulent Accretion of Black Holes](https://arxiv.org/abs/2602.19104)
*Giuseppe Ficarra,Michele Arcuri,Rita Megale,Sergio Servidio*

Main category: gr-qc

TL;DR: 通过高分辨率GRMHD模拟研究黑洞吸积盘扰动对吸积过程的影响，发现密度泡和磁岛扰动导致更陡的功率谱指数和更长的相关时间，为解释EHT观测提供新见解。


<details>
  <summary>Details</summary>
Motivation: 事件视界望远镜观测到超大质量黑洞存在显著不均匀性，可能与密度和磁场扰动有关。为了理解这些特征并解释观测数据，需要研究扰动对黑洞吸积过程的影响。

Method: 使用BHAC代码进行高分辨率2D广义相对论磁流体动力学模拟，比较未扰动吸积与包含等离子体密度泡和压力平衡磁岛扰动的案例。通过Blackman-Tukey方法进行功率谱分析，并进行空间自相关分析。

Result: 扰动案例显示：(1) 比未扰动案例更陡的功率谱指数，偏离特征1/ω噪声谱；(2) 更长的相关时间，表明宏观结构在事件视界被吸收。空间自相关分析证实扰动案例中存在更大的能量包含相干结构。

Conclusion: 这些结果为解释超大质量黑洞环境观测提供了新见解，表明视界附近的湍流可能在吸积过程中起关键作用，扰动改变了吸积率并影响观测特征。

Abstract: Observations of supermassive black holes by the Event Horizon Telescope reveal significant inhomogeneities, most likely related to density and magnetic field perturbations. To model these features, we conduct high-resolution 2D general-relativistic magnetohydrodynamics (GRMHD) simulations of a Fishbone-Moncrief torus around a Kerr black hole using the Black Hole Accretion Code $\texttt{BHAC}$. We compare unperturbed accretion with a case featuring plasma density bubbles with pressure balanced magnetic islands of different amplitudes. Power spectrum analysis of accretion time series, performed via the Blackman-Tukey method, shows that the perturbed case exhibits (1) steeper spectral indices compared to the unperturbed case, deviating from the characteristic $1/ω$ noise spectrum, and (2) increased correlation times, providing evidence for absorption of macro-structures at the event horizon. Spatial auto-correlation analysis of near-horizon turbulence confirms larger energy-containing coherent structures in the perturbed case altering the accretion rate. These results provide new insights for interpreting observations of supermassive black hole environments, where near-horizon turbulence may play a key role in the accretion process.

</details>


### [238] [A New Perspective on the Cosmological Constant and Its Core Problems](https://arxiv.org/abs/2602.19145)
*H. R. Fazlollahi*

Main category: gr-qc

TL;DR: 论文提出通过打破能量-动量对称性的新机制，为宇宙学常数的精细调节和巧合问题提供了新的物理解释和解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代宇宙学中长期存在的未解难题是宇宙学常数相关的精细调节问题和巧合问题。这些问题在标准LCDM框架中基本被"冻结"而无法解决，因此需要从根本上不同的视角来重新审视宇宙学常数的本质。

Method: 采用替代引力理论的观点，提出对宇宙学常数的新物理解释，特别是挑战将其等同于时空量子基态能量的传统观点。引入"打破能量-动量对称性"的新机制框架。

Result: 该框架为缓解甚至可能解决精细调节和巧合问题提供了自然统一的途径，为传统宇宙学范式提供了有说服力的替代方案。

Conclusion: 宇宙学常数问题的根源在于对其本质的深层误解，通过打破能量-动量对称性的新机制，能够从根本上重新解释宇宙学常数，为解决长期存在的宇宙学难题提供了新的可能性。

Abstract: One of the most enduring and unresolved challenges in modern theoretical and observational cosmology is the fine-tuning and coincidence problems associated with the cosmological constant. Rather than attempting to reconcile these issues within the standard LCDM framework where they remain effectively frozen, we adopt a fundamentally different viewpoint based on alternative theories of gravity. We argue that the root of these problems lies in a deep misinterpretation of the cosmological constant, particularly its identification with the quantum ground-state energy of spacetime. In this work, we propose a novel physical interpretation of the cosmological constant and introduce a new mechanism, termed Breaking Energy-Momentum Symmetry. This framework provides a natural and unified route toward alleviating, and potentially resolving, both the fine-tuning and coincidence problems, offering a compelling alternative to the conventional cosmological paradigm.

</details>


### [239] [Gauss-Bonnet Gravity and Spacetime Singularities](https://arxiv.org/abs/2602.19150)
*Tariq Allaithy,Adel Awad,Mohamed Hany Radwan,Mohsen Zahran*

Main category: gr-qc

TL;DR: 五维时空中，高斯-博内项可以将大爆炸/大挤压奇点替换为"突然"奇点，使黑洞径向测地线弱化但非径向测地线仍强奇异，符合彭罗斯-霍金奇点定理。


<details>
  <summary>Details</summary>
Motivation: 研究高阶曲率项（特别是高斯-博内项）对五维时空奇点的影响，探索这些项是否能缓解或改变奇点的性质。

Method: 分析FLRW宇宙学中的高斯-博内项效应，研究不同解分支；使用高斯-博内连接条件验证扩展与场方程的一致性；分析Boulware-Deser黑洞的测地线行为。

Result: 在宇宙学中，高斯-博内项将大爆炸/大挤压替换为"突然"奇点（尺度因子和哈勃率有限但高阶导数发散），测地线可扩展；在黑洞中，径向测地线弱化但非径向测地线仍强奇异，测地线仍不可扩展。

Conclusion: 高斯-博内项能改变奇点性质：宇宙学中产生可扩展的突然奇点，黑洞中弱化径向奇点但整体仍不可扩展，结果与彭罗斯-霍金奇点定理一致。

Abstract: We investigate the effect of higher-order curvature terms, specifically Gauss-Bonnet terms, on spacetime singularities in five dimensions. For FLRW cosmologies, we demonstrate that Gauss-Bonnet terms can replace the Big Bang/Crunch with a "sudden" singularity, characterized by a finite scale factor and Hubble rate but diverging higher-order derivatives. Investigating various branches of solutions shows the possibility of explicit extension of non-spacelike geodesics beyond the singular point. Furthermore, we employ the Gauss-Bonnet junction conditions to verify the consistency of the extension with the field equations. The whole solution describes a contracting phase prior to the expansion phase with a well-defined surface stress-energy tensor. Regarding the Boulware-Deser black hole, we find that Gauss-Bonnet terms soften the central singularity for radial geodesics--rendering them "weak" according to the Tipler and Krolak criteria--whereas non-radial geodesics remain strongly singular. Junction condition analysis of this solution shows that although higher-curvature corrections alter the nature of the singularity, geodesics are still inextendible as a result of divergent extrinsic curvature. Our results are consistent with the Penrose-Hawking singularity theorems since in Gauss-Bonnet black holes, geodesics suffer from focusing (expansion parameter diverges), while in cosmology, there is no focusing since the expansion parameter remains finite at the singularity.

</details>


### [240] [Propagation effects of Lorentz violation in gravitational waves](https://arxiv.org/abs/2602.19186)
*A. A. Araújo Filho,N. Heidari,Iarley P. Lobo*

Main category: gr-qc

TL;DR: 研究引力波在标准模型扩展中洛伦兹和微分同胚破坏算子存在时的传播特性，分析CPT偶维四系数和CPT奇维五系数对张量引力辐射的影响，推导修正的波算子和波形表达式，应用于双黑洞系统，并利用现有观测数据给出系数约束。


<details>
  <summary>Details</summary>
Motivation: 探索引力波在洛伦兹和微分同胚破坏背景下的传播特性，理解这些破坏算子如何修改引力波的色散关系、传播速度和偏振特性，为检验标准模型扩展中的引力部分提供理论框架。

Method: 在线性化引力标准模型扩展框架下，分析各向同性贡献，结合CPT偶维四系数和CPT奇维五系数，推导修正的色散关系和推迟格林函数，获得物质源产生的引力波形表达式，并应用于双黑洞系统。

Result: 修正的色散关系导致传播速度重新标定和螺旋度相关的色散修正，产生双折射和偏振混合但不引入额外传播自由度。CPT奇项产生特征性衰减和波形畸变，可解释为引力波与洛伦兹破坏背景之间的能量交换。利用LIGO-Virgo-KAGRA传播测试和偏振一致性论证，给出了系数的观测约束。

Conclusion: 洛伦兹和微分同胚破坏算子显著改变引力波的传播特性，包括传播速度、偏振混合和波形畸变。这些效应为通过引力波观测检验标准模型扩展中的引力部分提供了新途径，现有观测数据已能对相关系数给出约束。

Abstract: We investigate the propagation of gravitational waves in the presence of Lorentz- and diffeomorphism-violating operators within the linearized gravitational sector of the Standard Model Extension. Focusing on isotropic contributions, we analyze the combined effects of the nondispersive CPT-even dimension-four coefficient $\mathring{k}^{(4)}_{(I)}$ and the CPT-odd dimension-five coefficient $\mathring{k}^{(5)}_{(V)}$ on tensorial gravitational radiation. The modified dispersion relation induces both a rescaling of the propagation speed and helicity-dependent dispersive corrections, leading to birefringence and polarization mixing without introducing additional propagating degrees of freedom. We derive the retarded Green function associated with the modified wave operator and obtain explicit expressions for the gravitational waveform generated by matter sources. As a concrete application, we examine a binary black hole system and show how Lorentz violation alters the observed strain through shifted retarded times, amplitude rescaling, and higher derivative corrections to the quadrupole formula. The CPT-odd term produces characteristic attenuation and distortions in the waveform, which can be interpreted as energy exchange between the gravitational wave and the Lorentz-violating background rather than a violation of energy conservation. Using published LIGO-Virgo-KAGRA propagation tests and polarization consistency arguments, we translate current observational constraints into bounds on $\mathring{k}^{(4)}_{(I)}$ and $\mathring{k}^{(5)}_{(V)}$.

</details>


### [241] [The early history of symmetric teleparallel gravity: An overlooked period](https://arxiv.org/abs/2602.19194)
*Muzaffer Adak*

Main category: gr-qc

TL;DR: 作者回顾了他们在2004-2013年间对对称远平行引力的开创性贡献，这些工作在2017-2018年该领域兴起时被忽视，并简要介绍了2018年后的工作，最后展望了该领域的未来。


<details>
  <summary>Details</summary>
Motivation: 对称远平行引力近年来（特别是2017-2018年）受到广泛关注，但作者及其团队在2004-2013年间已发表了一系列系统性和开创性的论文。本文旨在总结这些被忽视的早期贡献，并澄清历史记录。

Method: 通过回顾性总结的方式，系统梳理作者团队在2004-2013年间发表的对称远平行引力相关论文，同时简要介绍2018年后的后续工作。

Result: 作者展示了他们在对称远平行引力领域的早期系统性贡献，这些工作在2004-2013年间完成，比该领域近年来的热潮早了十多年，为后续研究奠定了基础。

Conclusion: 作者强调了对历史贡献的正确认识的重要性，并分享了个人对对称远平行几何未来发展的展望，认为该领域仍有广阔的研究空间。

Abstract: It is noteworthy that symmetric teleparallel gravity has attracted considerable attention in recent years. A survey of the literature indicates that this surge of interest became particularly prominent around 2017 and 2018. However, together with my students and collaborators, we published a series of systematic and pioneering papers on this subject between 2004 and 2013. In this letter, we will summarize our overlooked contributions to symmetric teleparallel gravity produced during that period. For the sake of completeness and coherence, we will also briefly review our work on this topic carried out after 2018. In the final paragraph, we will write our personal perspectives on the future of symmetric teleparallel geometry.

</details>


### [242] [The linearised conformal Einstein field equations around a Petrov-type~D spacetime: the conformal Teukolsky equation](https://arxiv.org/abs/2602.19245)
*Edgar Gasperin,Rodrigo Panosso Macedo,Justin Feng*

Main category: gr-qc

TL;DR: 本文建立了黑洞微扰理论的共形表述，基于Friedrich共形爱因斯坦场方程推导出共形Teukolsky方程，将传统曲率微扰理论与共形广义相对论联系起来。


<details>
  <summary>Details</summary>
Motivation: 传统Teukolsky方程在代数特殊时空微扰中起核心作用，但其与Friedrich共形爱因斯坦场方程的关系尚未充分探索。随着双曲框架在黑洞微扰理论中日益重要，需要建立共形与传统微扰理论之间的直接联系。

Method: 基于Friedrich共形爱因斯坦场方程发展黑洞微扰理论的共形表述，推导共形Teukolsky方程。在线性化过程中，当围绕Petrov D型背景时，共形因子从重标Weyl张量的Newman-Penrose分量φ₀和φ₄的方程中解耦。

Result: 得到的方程保持了经典Teukolsky方程的结构形式，同时在共形边界处保持正则性。这为双曲主变量提供了几何解释，并为Kerr时空的共形表示推导了相应的方程。

Conclusion: 该框架通过桥接共形和传统黑洞微扰理论，突出了微扰动力学的几何正则表示，可能为超越线性区域的研究提供基础。

Abstract: While the Teukolsky equation plays a central role in traditional treatments of perturbations of algebraically special spacetimes, its relation to Friedrich's conformal Einstein field equations (CEFEs) remains largely unexplored. Here we develop a conformal formulation of black-hole perturbation theory based on the CEFEs and derive the conformal Teukolsky equation. Starting from a transparent review of Friedrich's regularisation strategy, this work establishes a direct connection between mainstream curvature-based linear perturbation theory and conformal formulations of general relativity. This perspective is timely given the growing relevance of hyperboloidal frameworks in black-hole perturbation theory, where conformal compactification is introduced at the level of an already linearised effective wave equation. Here instead, the conformal factor is a dynamical variable within the field equations. In the non-linear equations there is a coupling between conformal and curvature perturbations; however, when linearised around a Petrov-type D background, the conformal factor decouples from the equations governing the Newman-Penrose components $φ_0$ and $φ_4$ of the rescaled Weyl tensor. The resulting equation preserves the structural form of the classical Teukolsky equation while remaining regular at the conformal boundary. This provides a geometric interpretation of the hyperboloidal master variable and an entry point into the CEFE framework. We further derive the conformal Teukolsky equation for a conformal representation of Kerr spacetime where spatial infinity is realised as a blown-up cylinder. By bridging conformal and traditional approaches to black-hole perturbation theory, the framework highlights a geometrically regular representation of perturbative dynamics that may inform extensions beyond the linear regime.

</details>


### [243] [The extremely-tilted fluid regime near asymptotically Kasner big bang singularities](https://arxiv.org/abs/2602.19361)
*Florian Beyer*

Main category: gr-qc

TL;DR: 在具有Kasner大爆炸渐近性的背景时空上，求解线性状态方程的相对论欧拉方程，特别关注声速较小的极端倾斜渐近区域，证明解在大爆炸奇点附近存在并展现预期渐近行为。


<details>
  <summary>Details</summary>
Motivation: 研究相对论流体在具有Kasner大爆炸渐近性的时空中的动力学行为，特别是在声速较小的极端倾斜渐近区域，这是先前渐近非倾斜区域研究的自然延伸。

Method: 在具有Kasner大爆炸渐近性的背景时空上求解线性状态方程的相对论欧拉方程，考虑声速较小的极端倾斜渐近区域，解决柯西问题并证明解的时间全局存在性。

Result: 证明在初始超曲面平均曲率足够大的条件下，解在大爆炸奇点附近全局存在，且展现预期渐近行为：流体粒子在接近大爆炸奇点时以光速向最大Kasner指数方向运动。

Conclusion: 在Kasner大爆炸渐近性背景下，相对论欧拉方程在极端倾斜渐近区域存在全局解，流体动力学行为与标准启发式论证预期一致，为理解早期宇宙流体动力学提供了严格数学基础。

Abstract: In this paper, we solve the relativistic Euler equations with a linear barotropic equation of state on a large class of background spacetimes with Kasner big bang asymptotics. Building on previous work in the asymptotically non-tilted regime, which applies when the speed of sound of the fluid is large in comparison to the Kasner exponents, we now consider the asymptotically extremely-tilted regime when the speed of sound is small. We solve the Cauchy problem for the Euler equations towards the big bang singularity and prove, without any symmetry assumptions or smallness conditions on the Cauchy data, that the solutions exist globally in time provided the mean curvature of the initial hypersurface is sufficiently large. Finally, we prove that the solutions exhibit the asymptotics expected from standard heuristic arguments in this regime; in particular, fluid particles are driven towards the speed of light in the direction of the largest Kasner exponent as the big bang singularity is approached.

</details>


### [244] [Improving calibration accuracy with torque coupled gravity field calibrator for sub-Hz gravitational wave observation in CHRONOS](https://arxiv.org/abs/2602.19436)
*Yuki Inoue,Daiki Tanabe,Vivek Kumar*

Main category: gr-qc

TL;DR: 通过优化扭矩耦合重力场校准器的几何配置，将校准线信噪比提升超过一个数量级，解决了低频引力波探测器中校准信号信噪比低的长期问题。


<details>
  <summary>Details</summary>
Motivation: 低频引力波探测器面临校准线信噪比低的挑战，特别是在响应由旋转动力学控制的扭杆系统中。传统布局的校准信号信噪比有限，限制了探测器的精确校准能力。

Method: 优化扭矩耦合重力场校准器的几何配置，在CHRONOS探测器（Cryogenic sub-Hz cROss torsion-bar detector with quantum NOn-demolition Speed-meter）中实现高信噪比校准线注入。使用一阶微扰误差传播分析评估系统不确定性。

Result: 在1Hz频率下，应变等效校准幅度达到|h_GCal| = 1.18 × 10^{-14}，信噪比密度为4.25 × 10^3。总分数系统不确定性为0.24%，主要来自几何对准不确定性，对应的绝对系统不确定性δh_GCal ∼ 10^{-17}。

Conclusion: 扭矩耦合重力校准为亚赫兹扭杆探测器的低信噪比问题提供了实用解决方案，为低频区域的精确绝对校准建立了稳健途径。

Abstract: A fundamental challenge in low-frequency gravitational-wave detectors is the limited signal-to-noise ratio (SNR) of calibration lines, particularly in torsion-bar systems where the response is governed by rotational dynamics. In this work, we resolve this issue by optimizing the geometrical configuration of a torque-coupled gravity field calibrator (GCal), achieving an improvement in calibration-line SNR by more than an order of magnitude compared to conventional layouts.
  For the Cryogenic sub-Hz cROss torsion-bar detector with quantum NOn-demolition Speed-meter (CHRONOS), the calibration signal appears as a monochromatic line within the $0.1$--$10~\mathrm{Hz}$ band. At $1~\mathrm{Hz}$, the strain-equivalent calibration amplitude reaches $|h_{\rm GCal}| = 1.18 \times 10^{-14}$, corresponding to an SNR density of $|h_{\rm GCal}|/S_h = 4.25 \times 10^{3}$. This demonstrates for the first time that a high-SNR calibration line can be directly injected into the sub-Hz band of a torsion-bar detector.
  A first-order perturbative error propagation analysis yields a total fractional systematic uncertainty of $δh_{\rm GCal}/h_{\rm GCal} = 0.24\%$, dominated by geometric alignment uncertainties, while contributions from mass uncertainties and the gravitational constant remain subdominant. The corresponding absolute systematic uncertainty is $δh_{\rm GCal} \sim 10^{-17}$ at $1~\mathrm{Hz}$.
  These results establish torque-coupled gravitational calibration as a practical solution to the longstanding low-SNR problem in sub-Hz torsion-bar detectors and provide a robust pathway toward precision absolute calibration in the low-frequency regime.

</details>


### [245] [The Kerr two-twistor particle](https://arxiv.org/abs/2602.19495)
*Joon-Hwi Kim*

Main category: gr-qc

TL;DR: 在扭量粒子理论中实现了克尔黑洞的全阶世界线有效作用量


<details>
  <summary>Details</summary>
Motivation: 研究克尔黑洞的量子引力效应，特别是在扭量理论框架下建立完整的有效作用量描述

Method: 使用扭量粒子理论，构建克尔黑洞的世界线有效作用量，并扩展到所有阶次

Result: 成功推导出克尔黑洞的全阶世界线有效作用量，为研究黑洞量子性质提供了新工具

Conclusion: 扭量理论为描述克尔黑洞的量子引力效应提供了有效的数学框架，全阶有效作用量的建立是该领域的重要进展

Abstract: An all-orders worldline effective action for Kerr black hole is achieved in twistor particle theory.

</details>


### [246] [Chaotic imprints of dark matter in extreme mass-ratio inspirals](https://arxiv.org/abs/2602.19541)
*Mustapha Azreg-Aïnou,Mubasher Jamil,Emmanuel N. Saridakis*

Main category: gr-qc

TL;DR: 该论文研究了在非真空时空中极端质量比旋进系统的混沌动力学及其引力波特征，发现环境扰动会破坏强场区的可积性，产生混沌运动，导致引力波波形出现不规则调制和相位相干性丧失。


<details>
  <summary>Details</summary>
Motivation: 研究极端质量比旋进系统在非真空时空中（特别是暗物质环境下）的混沌动力学，探索环境扰动对轨道动力学和引力波信号的影响，以更好地理解强场引力现象和星系中心环境。

Method: 采用统一的动力学框架，分析测试粒子在多种暗物质嵌入几何结构中的运动，包括奇异黑洞、规则黑洞、裸奇点和爱因斯坦星团配置。使用数值Kludge方法计算混沌轨迹产生的引力波辐射。

Result: 环境扰动在强场区普遍破坏可积性，产生混沌运动，其起始、持续和终止对视界结构、核心正则化和物质分布敏感。混沌轨迹导致引力波辐射出现系统性的定性变化，如不规则振幅调制和相位相干性丧失，与规则运动产生的平滑准周期波形形成对比。

Conclusion: 研究证实了环境扰动下极端质量比旋进系统中混沌的鲁棒性，并建立了非线性轨道动力学、时空结构和可观测引力波特征之间的清晰概念联系，为探测强场引力和星系中心环境提供了新途径。

Abstract: Extreme mass-ratio inspirals (EMRIs) are among the most powerful probes of strong-field gravity and of the environments surrounding supermassive compact objects. Motivated by the expected presence of dark matter near galactic centers, we investigate the emergence and gravitational-wave imprints of chaotic dynamics in EMRIs evolving in non-vacuum spacetimes. Within a unified dynamical framework, we analyze test-particle motion in a broad class of dark-matter-embedded geometries, including singular black holes, regular black holes, naked singularities, and Einstein-cluster configurations. We show that environmental perturbations generically break integrability in the strong-field regime, giving rise to chaotic motion whose onset, duration, and termination depend sensitively on horizon structure, core regularization, and matter distribution. Using the numerical Kludge approach, we demonstrate that chaotic trajectories produce systematic qualitative modifications of the emitted gravitational radiation, such as irregular amplitude modulation and loss of phase coherence, in contrast to the smooth, quasi-periodic waveforms generated by regular motion. Our results establish the robustness of chaos in environmentally perturbed EMRIs and provide a clear conceptual link between nonlinear orbital dynamics, spacetime structure, and observable gravitational-wave signatures.

</details>


### [247] [Boltzmann Dynamics in K-essence Cosmology: Photon Propagation in an Emergent Spacetime](https://arxiv.org/abs/2602.19576)
*Krishnendu Roy,Debashis Gangopadhyay,Chiranjeeb Singha,Goutam Manna*

Main category: gr-qc

TL;DR: 该研究在K-essence宇宙学中建立了协变的玻尔兹曼形式，推导了倾斜时空中的粒子输运方程，发现CMB传播效应可作为观测K-essence和涌现引力框架的探针。


<details>
  <summary>Details</summary>
Motivation: 为解决哈勃张力和S8张力等宇宙学矛盾，需要超越标准ΛCDM框架。K-essence宇宙学中，标量场诱导的涌现FLRW几何与引力度量呈非共形联系，导致光锥传播与引力传播不同的"倾斜因果结构"，需要建立相应的粒子输运理论。

Method: 在均匀K-essence框架内发展协变玻尔兹曼形式，推导修正的质量壳条件、测地线方程和碰撞积分（包括无质量和有质量粒子）。分析光子分布的热性质、Thomson和Compton过程的微观结构，研究光子-重子流体在紧密耦合时期的声学振荡。

Result: 光子分布在涌现框架中保持热性质，在引力框架中呈现几何重新标度。Thomson和Compton过程保持微观结构但获得由标量场控制的有效质量和相互作用率。对于DBI型拉格朗日量，相互作用率按a^{-8}标度，表明早期宇宙强耦合；扩散阻尼尺度按a^{29/2}标度，表明小尺度各向异性对演化几何敏感。

Conclusion: 该研究为倾斜时空中的粒子输运提供了连贯的动力学描述，证明CMB传播效应可作为观测K-essence和涌现引力框架的探针，为解决宇宙学张力提供了新的理论工具。

Abstract: Recent cosmological tensions, notably the Hubble and $S_{8}$ tensions, necessitate extensions of the conventional $Λ$CDM framework, wherein additional dynamical fields alter the effective spacetime encountered by matter and radiation. In K-essence cosmology, the scalar field induces an emergent FLRW geometry that is disformally linked to the gravitational metric, resulting in a \emph{tilted causal structure} where the light cone propagation differs from that of gravity. This study develops a covariant Boltzmann formalism inside a homogeneous K-essence framework and derives the modified mass-shell condition, geodesic equations, and collision integrals for both massless and massive particles. We demonstrate that the photon distribution retains its thermal properties in the emergent frame, while it seems geometrically rescaled in the gravitational frame. The Thomson and Compton processes maintain their microscopic structure while obtaining effective masses and interaction rates governed by the scalar field. During the tightly coupled epoch, the photon-baryon fluid experiences acoustic oscillations characterized by a modified sound horizon. For the kinetic K-essence DBI-type Lagrangian, the interaction rate scales as $n_{e}σ_{T}^{\rm eff}a\propto a^{-8}$, indicating a strong coupling in the early universe. Additionally, the diffusion damping scale scales as $k_{D}^{-2}\propto a^{29/2}$, indicating that small-scale anisotropies become increasingly sensitive to the evolving geometry. The results provide a coherent kinetic description of particle transport in a tilted spacetime and demonstrate that CMB propagation effects may serve as an observational probe of K-essence and emergent gravity frameworks.

</details>


### [248] [Unimodular quantum cosmology in the connection representation: A minimal model](https://arxiv.org/abs/2602.19704)
*Shinji Yamashita*

Main category: gr-qc

TL;DR: 该论文研究了无物质、均匀各向同性平坦宇宙模型中单模引力的量子化，发现负宇宙常数与算符正则性和哈密顿算符自伴性不相容，而正宇宙常数下波函数在零空间体积处消失。


<details>
  <summary>Details</summary>
Motivation: 研究单模引力在量子层面的实现，特别是在宇宙学背景下，探索量子引力理论中宇宙常数问题的可能解决方案。

Method: 采用约化相空间方法，在连接表象中对无物质、均匀各向同性平坦宇宙模型进行量子化，推导出薛定谔型方程，分析算符的正则性和哈密顿算符的自伴性。

Result: 负宇宙常数与算符正则性和哈密顿算符自伴性不相容；正宇宙常数下波函数在零空间体积处消失；量子层面强制执行单模条件导致这一行为。

Conclusion: 在最小化设置中，单模引力量子化对宇宙常数施加了约束，负宇宙常数被排除，正宇宙常数导致波函数在奇点处消失，这为宇宙常数问题提供了新的量子引力视角。

Abstract: We present a quantization of unimodular gravity in the connection representation for a homogeneous, isotropic, and spatially flat cosmological model without matter. In this model, the wave function is governed by a Schrödinger-type equation derived from a reduced phase space approach. Our analysis suggests that, within this minimal setting, the regularity of the operators and the self-adjointness of the Hamiltonian operator are incompatible with a negative cosmological constant. For a positive cosmological constant, the wave functions vanish at zero spatial volume. This behavior emerges as a consequence of enforcing the unimodular condition at the quantum level. Semiclassical fluctuations of the geometry are evaluated and discussed in relation to the cosmological constant problem.

</details>


### [249] [Analytic Solutions for Geodesic Motion in Static Axially Symmetric Spacetime](https://arxiv.org/abs/2602.19737)
*R. Chan,M. F. A. da Silva,N. O. Santos*

Main category: gr-qc

TL;DR: 提出寻找爱因斯坦场方程静态轴对称解的方法，获得两个通解和五个特解，并分析该时空下所有可能的测地线解


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦场方程的静态轴对称解，探索这类时空结构下的测地线运动可能性，为理解引力场中的粒子运动提供理论基础

Method: 提出寻找静态轴对称解的系统性方法，通过分析圆形运动和z方向运动的存在条件，推导出两个通解和五个特解

Result: 成功获得两个通解和五个特解，并对该时空下所有可能的测地线解进行了全面分析

Conclusion: 该方法能有效找到爱因斯坦场方程的静态轴对称解，获得的解集为研究引力场中的粒子运动提供了完整的测地线分析框架

Abstract: A procedure to find static axially symmetric solutions to the Einstein field equations is presented. We obtained two general solutions and five particular solutions, which depend on the existence conditions for circular and $z$ direction motion. Our endeavour consists making a thoroughrowly analysis of all the possible geodesics solutions stemming from this spacetime.

</details>


### [250] [Spectral Analysis of Quasinormal Modes of Planck Stars](https://arxiv.org/abs/2602.19833)
*Davide Batic,Denys Dutykh,Fabio Scardigli*

Main category: gr-qc

TL;DR: 研究尺度依赖引力框架下普朗克星的准正规模，发现振荡谱具有稳定的Martini玻璃形态，过阻尼模式近乎等间距分布，引力扰动中出现与主序列分离的孤立过阻尼模式。


<details>
  <summary>Details</summary>
Motivation: 研究量子引力启发的普朗克星模型的准正规模谱，探索高精度谱技术在探测量子引力效应中的重要性，特别是尺度依赖引力框架下的普朗克星特征。

Method: 采用尺度依赖引力框架，将运行参数α固定为负值以匹配单圈有效场论结果；基于重整化群改进的史瓦西度规计算背景；使用谱方法计算标量、电磁和引力扰动的准正规模谱。

Result: 发现振荡谱呈现稳定的Martini玻璃形态；过阻尼模式近乎等间距分布且具有特征性异常间隙；引力扰动中出现与主序列分离的孤立过阻尼模式；首次在普朗克星背景下解析出这些特征。

Conclusion: 高精度谱技术对于探测量子引力启发的黑洞模型的微妙特征至关重要，尺度依赖引力框架下的普朗克星准正规模谱展现出独特而丰富的结构特征。

Abstract: We investigate the quasinormal modes (QNMs) of Planck stars within the framework of scale-dependent gravity (SDG). In our setup, the running parameter $α$ is fixed to a negative value by matching the effective Newtonian potential to the one-loop EFT result. As a consequence, the associated running Newton coupling does not realise the ultraviolet fixed point of asymptotically safe gravity, and the geometry should be interpreted as an SDG-inspired effective metric rather than a realisation of asymptotically safe gravity itself. We focus on the resulting renormalisation-group-improved Schwarzschild metric, which naturally yields a finite-size Planck-density core. Building on this background, we compute the QNM spectrum for scalar, electromagnetic, and gravitational perturbations using the Spectral Method (SM). This approach, known for its superior accuracy over high-order WKB schemes, enables the detection of fundamental modes, large families of overtones, and purely imaginary overdamped modes that are entirely missed in previous analysis. Our results reveal a robust Martini glass morphology of the oscillatory spectrum across perturbation sectors, nearly equally spaced overdamped modes with characteristic anomalous gaps, and the emergence, in the gravitational sector, of isolated overdamped modes separated from the main sequence by exceptionally large frequency intervals. These features, resolved here for the first time in the Planck-star context, underscore the importance of high-precision spectral techniques in probing subtle signatures of quantum-gravity-inspired black hole models.

</details>


### [251] [Axially symmetric wormholes](https://arxiv.org/abs/2602.19975)
*I. A. Sarmiento-Alvarado,Leonel Bixano,Tonatiuh Matos*

Main category: gr-qc

TL;DR: 提出了一种具有三个参数（喉部半径r₀、与Komar质量相关的q、避免锥形奇点的轴向拓扑缺陷参数s）的精确真空爱因斯坦场方程解，通过"剪切-粘贴"构造构建虫洞几何，并进行了全面的几何和物理分析。


<details>
  <summary>Details</summary>
Motivation: 寻找具有多个参数的精确真空爱因斯坦场方程解，特别是能够避免锥形奇点并包含轴向拓扑缺陷的虫洞几何，以研究其几何结构和物理性质。

Method: 推导了具有三个常数参数（r₀, q, s）的精确真空爱因斯坦场方程解，使用"剪切-粘贴"构造方法从该解生成虫洞几何（当q≠0时），并对各种几何和物理特性进行了详细分析。

Result: 获得了包含轴向拓扑缺陷参数s的精确真空解，该参数避免了锥形奇点的出现；通过剪切-粘贴构造成功生成了虫洞几何；分析了嵌入图、虫洞喉部、俘获面结构、测地线行为、潮汐力、Petrov代数分类、Newman-Penrose自旋系数以及相应的守恒电荷。

Conclusion: 成功推导了一个具有三个参数的精确真空爱因斯坦场方程解，该解能够构建虫洞几何并避免锥形奇点，为研究包含轴向拓扑缺陷的虫洞提供了完整的理论框架和全面的物理分析。

Abstract: In this work, we derive an exact vacuum solution to the Einstein field equations that depends on three constant parameters: the throat radius $r_0$, a parameter $q$, which is closely associated with the Komar mass, and a parameter $s$, which introduces axial topological defect while avoiding the emergence of conical singularities. We employ the cut-and-paste construction to generate wormhole geometries from this solution for $q \neq 0$. In addition, we perform a detailed analysis of the embedding diagrams, the wormhole throat, the occurrence and structure of trapped surfaces, the behavior of geodesics, the associated tidal forces, the Petrov algebraic classification, the Newman-Penrose spin coefficients, and the corresponding invariant conserved charges.

</details>


### [252] [New modified cosmology from a new generalized entropy](https://arxiv.org/abs/2602.20004)
*G. G. Luciano,E. N. Saridakis*

Main category: gr-qc

TL;DR: 该研究通过将热力学第一定律应用于宇宙视界，利用推广的熵函数构建了修正的宇宙学模型，该模型能产生有效的暗能量并呈现丰富的演化行为。


<details>
  <summary>Details</summary>
Motivation: 动机是构建更一般的宇宙学模型，通过推广标准熵概念（超越Boltzmann-Gibbs-Shannon熵），在重力-热力学框架下获得修正的宇宙学场景。

Method: 方法包括：1）从概率分布出发推导广义熵表达式；2）考虑可分离性破坏和微观状态标度推广；3）将广义熵应用于有边界系统，得到全息类面积律标度；4）在重力-热力学框架中结合该熵，推导修正的宇宙学方程。

Result: 结果得到：1）包含额外项的修正宇宙学场景，产生有效暗能量；2）暗能量密度和状态方程的解析表达式；3）宇宙经历标准热历史（物质和暗能量时代）；4）暗能量可表现为精质型、幽灵型或穿越幽灵分界线，最终渐近趋于宇宙常数。

Conclusion: 结论是提出的广义熵模型能产生比现有熵修正宇宙学更丰富的暗能量演化行为，包括多种状态方程演化路径，最终稳定于宇宙常数，为暗能量研究提供了新视角。

Abstract: We develop new modified cosmological scenarios by applying the first law of thermodynamics at the Universe horizon, utilizing a new entropic functional that generalizes the standard Boltzmann-Gibbs-Shannon entropy. In particular, starting from the general theory of entropy in terms of the probability distribution over the accessible microstates, and by imposing violation of the separability requirement and thus considering a generalized microstate scaling, we result to a generalized entropy expression, which applied in systems with boundaries yields a generalized holographic-like area-law scaling with two exponents. Hence, incorporating it within the gravity-thermodynamics framework, we result to a modified cosmological scenario with additional terms, which eventually give rise to an effective dark energy sector. We extract analytical expressions for the dark energy density and equation-of-state parameters, and we show that the Universe experiences the usual thermal history, with the sequence of matter and dark-energy eras. Additionally, depending on the values of the entropic exponents, the dark energy can be quintessence-like, phantom-like or experience the phantom-divide crossing during its evolution, ultimately stabilizing at the cosmological constant value in the asymptotic far future, a behavior richer than other entropic modified cosmologies.

</details>


### [253] [Dynamics of the Bianchi~V cosmological model inspired by quintessential $α$-attractors](https://arxiv.org/abs/2602.20072)
*Genly Leon,Amare Abebe,Andronikos Paliathanasis*

Main category: gr-qc

TL;DR: 研究Bianchi V时空中标量场宇宙学，使用动力系统方法分析α-吸引子势能，发现各向同性FLRW模型可自然扩展到各向异性Bianchi V宇宙，暴胀吸引子保持稳健，Milne型曲率解成为晚期状态。


<details>
  <summary>Details</summary>
Motivation: 研究α-吸引子势能（E-model和T-model）在Bianchi V各向异性时空中的宇宙学行为，探索各向同性FLRW模型向各向异性扩展的自然性。

Method: 使用动力系统框架，应用平均定理和振幅-相位约化方法，分析近似α-吸引子势能的单项式势能φ^{2n}，考虑具有barotropic指数γ的物质场。

Result: 约化平均系统有五个孤立平衡点：Kasner真空K₀⁺⁻、物质FLRW点F、标量FLRW点S、曲率Milne型点K。K₀⁺⁻总是源，F通常是鞍点但特定条件下可成为汇，S在特定参数范围是汇，K在γ>2/3且n>1/2时成为汇。

Conclusion: 各向同性FLRW α-吸引子模型可自然扩展到各向异性Bianchi V宇宙学，暴胀吸引子保持稳健，而Milne型曲率解成为晚期状态，展示了各向异性宇宙学中吸引子行为的普适性。

Abstract: We investigate scalar-field cosmologies in the Bianchi V spacetime using a dynamical-systems framework. Motivated by representative $α$-attractor potentials - the E-model and T-model - we apply averaging theorems and amplitude--phase reductions to monomial potentials $\sim φ^{2n}$ of the scalar field, which approximate the attractor models near their minima, in the presence of matter with barotropic index $γ$. The reduced averaged system admits five generic isolated equilibria: Kasner vacua $\mathcal{K}_0^\pm$, the matter FLRW point $\mathcal{F}$, the scalar FLRW point $\mathcal{S}$, and the curvature Milne-type point $\mathcal{K}$, together with special families for tuned $(n,γ)$. We find that $\mathcal{K}_0^\pm$ are always sources, $\mathcal{F}$ is generically a saddle but can act as a sink for $γ<\min\{\tfrac{2n}{n+1},\tfrac{2}{3}\}$, $\mathcal{S}$ is a sink if $0<n<\tfrac{1}{2}$ and $\tfrac{2n}{n+1}<γ\leq 2$, while $\mathcal{K}$ becomes a sink whenever $γ>\tfrac{2}{3}$ and $n>\tfrac{1}{2}$. These results demonstrate that isotropic FLRW $α$-attractor models extend naturally to anisotropic Bianchi~V cosmologies: inflationary attractors remain robust, while the Milne-type curvature solution emerges as the late-time state.

</details>


### [254] [Addressing leakage and mode suppression in angular power spectrum estimation for gravitational-wave backgrounds using pulsar timing arrays](https://arxiv.org/abs/2602.20075)
*Deepali Agarwal,Joseph D. Romano,Yacine Ali-Haïmoud,Tristan L. Smith*

Main category: gr-qc

TL;DR: PTA各向异性映射受限于阵列响应，需确定最大信息多极l_max^res而非传统l_max^N_pair，以避免小尺度功率泄漏，并建议使用去偏标准估计器但仅用于充分约束的模式。


<details>
  <summary>Details</summary>
Motivation: 传统PTA各向异性分析中，球谐展开截断于l_max^N_pair，但该选择基于简单的计数论证，未考虑阵列配置对可观测天空空间的真实限制，可能导致小尺度功率泄漏或信息损失。

Method: 通过分析PTA的Fisher信息矩阵特征映射，确定最大信息多极l_max^res，该值定义了阵列可观测天空空间。比较不同截断方案，评估标准功率谱估计器的偏差，并提出去偏方法。

Result: l_max^res比传统l_max^N_pair更能准确反映PTA可解析的角尺度，截断于l_max^res可避免小尺度功率泄漏。标准估计器存在偏差，去偏可改善与注入谱的一致性，但会增加方差，特别是对于l≫l_eff的弱约束模式。

Conclusion: 建议PTA分析中：(1)使用l_max^res进行球谐展开；(2)使用去偏标准估计器恢复C_l，但仅用于l<l_eff（≪l_max^res）的充分约束模式，以平衡偏差与方差。

Abstract: Mapping gravitational-wave background (GWB) anisotropy with pulsar timing arrays (PTAs) is affected by harmonic-space mode suppression and mode coupling arising from an array's nonuniform sky response. Spherical harmonic expansions must be truncated at finite multipole l_max^rec, often set to l_max^N_pair$\equiv {\rm int}\left[\sqrt{\text{N_pair}}-1\right]$, where N_pair is the number of distinct pulsar pairs in an array. This choice is motivated by the counting argument that cross-correlations provide at most N_pair independent constraints. We obtain the multipole l_max^res corresponding to the maximum informative angular scale of a PTA. It is defined such that expansions to l_max^res (approximately) span the space of "observable skies" encoded in the N_pair eigenmaps of the Fisher information matrix, and therefore depends on the array configuration. We explicitly show that GWB power contained in multipoles l$\gtrsim$l_max^res do not significantly affect analyses that use expansions out to l_max^res, because the PTA response acts as a low-pass filter. In contrast, truncating at l_max^rec< l_max^res leads to leakage of small-scale angular power from l_max^rec<l$\leq$l_max^res. Even choosing l_max^rec=l_max^res, the standard frequentist estimator of the angular power spectrum C_l remains biased by the modes unobservable by the array. Although we can (partially) debias the standard estimator -- improving its agreement with an injected spectrum -- this reduction in bias comes at the expense of an increase in variance, particularly for poorly constrained modes with l$\gg$l_eff. We therefore recommend: (i) using l_max^res for PTA analyses involving spherical harmonic expansions, and (ii) using the debiased standard estimator for C_l recovery, but only out to multipoles l<l_eff ($\ll$l_max^res) corresponding to sufficiently constrained modes.

</details>


### [255] [The Spacetime Positive Mass Theorem with Multiple Time Dimensions](https://arxiv.org/abs/2602.20081)
*Sven Hirsch,Alec Payne,Yiyue Zhang*

Main category: gr-qc

TL;DR: 将时空正质量定理推广到多时间维度，证明能量E不小于线性动量的迹范数，等号成立时数据集可嵌入广义pp波


<details>
  <summary>Details</summary>
Motivation: 将经典的正质量定理从单一时间维度推广到多个时间维度，探索广义相对论在更高维度时空中的质量性质

Method: 通过数学分析证明能量不等式，研究等号成立时的几何结构，并在附加脐点假设下构造等距嵌入

Result: 证明了在多时间维度下，能量E始终不小于线性动量J¹,...,Jᵐ的迹范数，等号成立时初始数据集可叶状化为平坦子流形

Conclusion: 成功将正质量定理推广到多时间维度，揭示了广义相对论中质量非负性在更高维度时空中的表现形式

Abstract: We generalize the spacetime positive mass theorem to include multiple time dimensions. In particular, we show that the mass remains nonnegative in the sense that the energy $E$ is bounded from below by the trace norm of the linear momenta $J^1,...,J^m$. Equality in this energy inequality implies a foliation by flat submanifolds of a generalized initial data set. Moreover, under an additional umbilicity assumption, we find that the initial data set isometrically embeds into a generalized pp-wave.

</details>


### [256] [Spherically symmetric solutions to the Einstein-scalar field conformal constraint equations](https://arxiv.org/abs/2602.20099)
*Philippe Castillon,The-Cang Nguyen*

Main category: gr-qc

TL;DR: 研究在调和流形和径向数据假设下，爱因斯坦-标量场共形约束方程的可解性，发现在球面上存在近CMC区域无解和不稳定性，而在欧几里得或双曲流形上总是可解，支持共形方法在渐近平坦和双曲流形上的应用价值。


<details>
  <summary>Details</summary>
Motivation: 爱因斯坦-标量场共形约束方程通常非常复杂且难以处理，即使在真空情况下也是如此。为了获得更清晰的理解并提供新视角，本文在特殊假设下研究这些方程：流形是调和的且数据是径向的。

Method: 在调和流形和径向数据的假设下，将系统简化为单个非线性方程。在标准情况下（球面、欧几里得空间、双曲空间）完全解析求解。同时研究质量的符号问题，特别是当对称(0,2)-张量k在无穷远处的衰减率为临界时的ADM和渐近双曲质量。

Result: 1. 在球面上：发现与无共形Killing向量场的紧致流形上的已知结果相反的现象，包括近CMC区域无解以及当平均曲率非常数时的不稳定性。
2. 在欧几里得或双曲流形上：方程总是可解，且解具有所有预期性质。
3. 质量符号：当k在无穷远处的衰减率为临界时，ADM和渐近双曲质量可以取任意符号。
4. 大多数解类是显式的，为广义相对论提供了多种模型。

Conclusion: 虽然共形方法在紧致流形上存在一些缺陷，但在渐近平坦和双曲流形上，对于任意平均曲率区域，它仍然是参数化约束方程解的有前景的工具。显式解类为广义相对论提供了多种模型，并对初始数据的结构和行为（特别是在数值应用中）提供了见解。

Abstract: Recent works by the second author and Dilts et al. have shown that the Einstein-scalar field conformal constraint equations are highly complex and generally intractable, even in the vacuum case. In this article, to gain a clearer understanding and offer a new perspective, we study these equations under special assumptions: the manifold $(M,g)$ is harmonic and data is radial.
  In this setting, the system reduces to a single nonlinear equation and is completely resolved in the standard cases. In particular, on the sphere, our results reveal phenomena that contrast with the well-known achievements on compact manifolds without conformal Killing vector fields, including nonexistence of solutions in the near-CMC regime and instability when the mean curvature is non-constant. By contrast, on Euclidean or hyperbolic manifolds, the equations are always solvable, with all expected properties of solutions satisfied. These findings support the view that, although the conformal method appears to present some drawbacks on compact manifolds, it remains a promising tool for parametrizing solutions to the constraint equations on asymptotically flat and hyperbolic manifolds in arbitrary mean curvature regimes.
  In this article, we also investigate the sign of mass, showing that the ADM and asymptotically hyperbolic mass can take arbitrary sign when the decay rate of symmetric $(0,2)$-tensor $k$ at infinity is critical. Finally, most solution classes in our framework are explicit, providing a variety of models in general relativity and offering insights into the structure and behavior of initial data, particularly in numerical applications.

</details>


### [257] [Exotic spherically-symmetric Lambda-vacuum in the four-dimensional Starobinsky model](https://arxiv.org/abs/2602.20147)
*Andrei Galiautdinov*

Main category: gr-qc

TL;DR: 在Starobinsky f(R)=R+αR²模型中，发现了一个精确的双参数静态球对称常数曲率Λ真空解族，当裸宇宙常数Λ=1/(8α)时，该解族表现出数学退化性，允许存在类似Reissner-Nordström毛发的几何项，但任何微小偏离都会使解崩溃回标准Schwarzschild-de Sitter族。


<details>
  <summary>Details</summary>
Motivation: 研究Starobinsky f(R)引力理论中精确解的性质，特别是探索当导数f'(R)=0时出现的数学退化边界情况，以及这种退化对物理解稳定性的影响。

Method: 通过精确代数推导，在四维Starobinsky f(R)=R+αR²模型中，寻找静态球对称常数曲率Λ真空解，特别关注当裸宇宙常数Λ=1/(8α)时f'(R)=0的退化情况。

Result: 发现了一个精确的双参数解族，在Λ=1/(8α)的退化边界上，修正场方程解耦，允许存在任意1/r²积分常数（类似Reissner-Nordström毛发）。但任何微小偏离都会使退化消失，几何毛发消失，时空坍缩回标准Schwarzschild-de Sitter族。

Conclusion: 该精确解在Starobinsky模型中起到了严格的"不可行定理"作用，展示了高度非线性f(R)引力理论中退化纯数学解的极端脆弱性和物理不友好性，包括Wald熵消失、有效引力耦合发散、反作用灾难和鬼场不稳定性等病理特征。

Abstract: We introduce an exact, two-parameter family of static, spherically-symmetric, constant-curvature $Λ$-vacuum solutions within the four-dimensional Starobinsky $f(R)=R+αR^2$ model. When the bare cosmological constant is precisely fine-tuned to $Λ= 1/(8α)$, the scalar curvature is fixed such that the derivative $f'(R)=1+2αR$ identically vanishes, demonstrating that the family represents a pathological $R_0$-degenerate boundary of the viable physical states. This mathematical degeneracy decouples the modified field equations, permitting the existence of an arbitrary $1/r^2$ integration constant in the metric, which functions as a purely geometric, Reissner-Nordström hair mimicker. However, any infinitesimal deviation from this exact boundary instantaneously destroys the degeneracy, rigorously forcing the geometric hair to vanish and collapsing the spacetime back into the standard Schwarzschild-de Sitter family. We provide the exact algebraic derivation of this spacetime and highlight its physical pathologies, including the identically vanishing Wald entropy of the associated black hole horizons, the divergence of the effective gravitational coupling, the resulting backreaction catastrophe, and the onset of severe ghost instabilities. Ultimately, this exact solution functions as a rigorous no-go theorem within the Starobinsky model, pedagogically illustrating the extreme fragility and physical hostility of degenerate, purely mathematical solutions in highly non-linear $f(R)$ gravity theories.

</details>
