<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 94]
- [gr-qc](#gr-qc) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 44]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution](https://arxiv.org/abs/2511.07459)
*Ashutosh Agarwal*

Main category: cs.LG

TL;DR: LEVER通过Siamese架构解决极端分类中低频类别的标签不一致问题，显著提升分类性能，并创建了两个新的多意图数据集。


<details>
  <summary>Details</summary>
Motivation: 极端分类任务中低频类别由于样本稀疏导致标签不一致，严重影响分类性能，需要专门解决方案。

Method: 采用鲁棒的Siamese风格架构，利用知识迁移减少标签不一致，增强一对多分类器的性能。

Result: 在多个极端分类数据集上的全面测试显示，对低频类别的处理有显著改进，为该领域设立了新基准。

Conclusion: LEVER有效解决了极端分类中低频类别的挑战，同时提供的新数据集将为未来研究提供重要资源。

Abstract: This paper presents a novel solution, LEVER, designed to address the challenges posed by underperforming infrequent categories in Extreme Classification (XC) tasks. Infrequent categories, often characterized by sparse samples, suffer from high label inconsistency, which undermines classification performance. LEVER mitigates this problem by adopting a robust Siamese-style architecture, leveraging knowledge transfer to reduce label inconsistency and enhance the performance of One-vs-All classifiers. Comprehensive testing across multiple XC datasets reveals substantial improvements in the handling of infrequent categories, setting a new benchmark for the field. Additionally, the paper introduces two newly created multi-intent datasets, offering essential resources for future XC research.

</details>


### [2] [Intelligent Optimization of Multi-Parameter Micromixers Using a Scientific Machine Learning Framework](https://arxiv.org/abs/2511.07702)
*Meraj Hassanzadeh,Ehsan Ghaderi,Mohamad Ali Bijarchi,Siamak Kazemzadeh Hannani*

Main category: cs.LG

TL;DR: 提出了一种基于科学机器学习的多维优化框架，通过深度强化学习与物理信息神经网络结合，实现复杂工程问题的瞬时优化求解。


<details>
  <summary>Details</summary>
Motivation: 传统仿真优化方法存在单次只能优化一个问题、计算时间长等局限性，需要开发更高效的优化方法。

Method: 使用深度强化学习作为优化器，与参数化物理信息神经网络环境交互，快速探索问题参数间的关系。

Result: 在微混合器案例中，该方法在宽范围施密特数下均优于基准值，最大效率提升约32%（施密特数13.3时）。

Conclusion: 该方法相比传统数值方法和遗传算法具有显著优势，能够为复杂多维优化问题提供瞬时解决方案。

Abstract: Multidimensional optimization has consistently been a critical challenge in engineering. However, traditional simulation-based optimization methods have long been plagued by significant limitations: they are typically capable of optimizing only a single problem at a time and require substantial computational time for meshing and numerical simulation. This paper introduces a novel framework leveraging cutting-edge Scientific Machine Learning (Sci-ML) methodologies to overcome these inherent drawbacks of conventional approaches. The proposed method provides instantaneous solutions to a spectrum of complex, multidimensional optimization problems. A micromixer case study is employed to demonstrate this methodology. An agent, operating on a Deep Reinforcement Learning (DRL) architecture, serves as the optimizer to explore the relationships between key problem parameters. This optimizer interacts with an environment constituted by a parametric Physics-Informed Neural Network (PINN), which responds to the agent's actions at a significantly higher speed than traditional numerical methods. The agent's objective, conditioned on the Schmidt number is to discover the optimal geometric and physical parameters that maximize the micromixer's efficiency. After training the agent across a wide range of Schmidt numbers, we analyzed the resulting optimal designs. Across this entire spectrum, the achieved efficiency was consistently greater than the baseline, normalized value. The maximum efficiency occurred at a Schmidt number of 13.3, demonstrating an improvement of approximately 32%. Finally, a comparative analysis with a Genetic Algorithm was conducted under equivalent conditions to underscore the advantages of the proposed method.

</details>


### [3] [Slimmable NAM: Neural Amp Models with adjustable runtime computational cost](https://arxiv.org/abs/2511.07470)
*Steven Atkinson*

Main category: cs.LG

TL;DR: 提出可调整大小的神经放大器模型，无需额外训练即可改变模型大小和计算成本，让音乐家能轻松在模型精度和计算量之间权衡。


<details>
  <summary>Details</summary>
Motivation: 让音乐家能够在使用神经放大器模型时，根据实际需求灵活调整模型大小和计算成本，而无需重新训练模型。

Method: 开发可调整大小的神经放大器模型，通过设计允许动态改变模型规模的结构，实现无需额外训练即可调整计算复杂度。

Result: 该方法在性能上优于常用基线方法，并开发了实时音频效果插件进行演示。

Conclusion: 可调整大小的神经放大器模型为音乐应用提供了实用的灵活性，能在保持性能的同时适应不同的计算资源约束。

Abstract: This work demonstrates "slimmable Neural Amp Models", whose size and computational cost can be changed without additional training and with negligible computational overhead, enabling musicians to easily trade off between the accuracy and compute of the models they are using. The method's performance is quantified against commonly-used baselines, and a real-time demonstration of the model in an audio effect plug-in is developed.

</details>


### [4] [Towards Personalized Quantum Federated Learning for Anomaly Detection](https://arxiv.org/abs/2511.07471)
*Ratun Rahman,Sina Shaham,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 提出了个性化量子联邦学习（PQFL）框架，用于解决量子联邦学习中客户端硬件能力、电路设计、噪声水平和数据编码差异导致的异质性问题，显著提升异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 量子联邦学习在异常检测中面临客户端硬件能力、电路设计、噪声水平和数据编码差异导致的异质性问题，传统单一全局模型训练在非独立同分布数据下效果不佳。

Method: 提出PQFL框架，结合参数化量子电路和经典优化器增强本地模型训练，采用量子中心个性化策略使每个客户端模型适应自身硬件特性和数据表示。

Result: PQFL显著提升异常检测准确率，在多样化现实条件下相比现有方法减少23%的误报错误，AUROC提升24.2%，AUPR提升20.5%。

Conclusion: PQFL在实用量子联邦设置中展现出有效性和可扩展性，为处理客户端异质性提供了有效解决方案。

Abstract: Anomaly detection has a significant impact on applications such as video surveillance, medical diagnostics, and industrial monitoring, where anomalies frequently depend on context and anomaly-labeled data are limited. Quantum federated learning (QFL) overcomes these concerns by distributing model training among several quantum clients, consequently eliminating the requirement for centralized quantum storage and processing. However, in real-life quantum networks, clients frequently differ in terms of hardware capabilities, circuit designs, noise levels, and how classical data is encoded or preprocessed into quantum states. These differences create inherent heterogeneity across clients - not just in their data distributions, but also in their quantum processing behaviors. As a result, training a single global model becomes ineffective, especially when clients handle imbalanced or non-identically distributed (non-IID) data. To address this, we propose a new framework called personalized quantum federated learning (PQFL) for anomaly detection. PQFL enhances local model training at quantum clients using parameterized quantum circuits and classical optimizers, while introducing a quantum-centric personalization strategy that adapts each client's model to its own hardware characteristics and data representation. Extensive experiments show that PQFL significantly improves anomaly detection accuracy under diverse and realistic conditions. Compared to state-of-the-art methods, PQFL reduces false errors by up to 23%, and achieves gains of 24.2% in AUROC and 20.5% in AUPR, highlighting its effectiveness and scalability in practical quantum federated settings.

</details>


### [5] [Multivariate Variational Autoencoder](https://arxiv.org/abs/2511.07472)
*Mehmet Can Yavuz*

Main category: cs.LG

TL;DR: 提出了MVAE（多元变分自编码器），一种保持高斯可处理性同时解除对角后验限制的VAE变体，通过全局耦合矩阵和样本特定对角尺度实现全协方差建模。


<details>
  <summary>Details</summary>
Motivation: 传统VAE使用对角后验协方差限制了建模能力，MVAE旨在保持计算可处理性的同时实现更丰富的协方差结构建模。

Method: 将后验协方差分解为全局耦合矩阵C（诱导数据集范围内的潜在相关性）和样本特定对角尺度（调节局部不确定性），使用L=Cdiag(σ)进行高效重参数化。

Result: 在多个数据集上，MVAE在重建质量、校准性能和无监督结构发现方面均优于对角协方差VAE，特别是在中等潜在维度下表现更佳。

Conclusion: MVAE提供了一种在保持高斯可处理性的同时实现全协方差建模的有效方法，显著提升了VAE的性能和表达能力。

Abstract: We present the Multivariate Variational Autoencoder (MVAE), a VAE variant that preserves Gaussian tractability while lifting the diagonal posterior restriction. MVAE factorizes each posterior covariance, where a \emph{global} coupling matrix $\mathbf{C}$ induces dataset-wide latent correlations and \emph{per-sample} diagonal scales modulate local uncertainty. This yields a full-covariance family with analytic KL and an efficient reparameterization via $\mathbf{L}=\mathbf{C}\mathrm{diag}(\boldsymbolσ)$. Across Larochelle-style MNIST variants, Fashion-MNIST, CIFAR-10, and CIFAR-100, MVAE consistently matches or improves reconstruction (MSE~$\downarrow$) and delivers robust gains in calibration (NLL/Brier/ECE~$\downarrow$) and unsupervised structure (NMI/ARI~$\uparrow$) relative to diagonal-covariance VAEs with matched capacity, especially at mid-range latent sizes. Latent-plane visualizations further indicate smoother, more coherent factor traversals and sharper local detail. We release a fully reproducible implementation with training/evaluation scripts and sweep utilities to facilitate fair comparison and reuse.

</details>


### [6] [RELEAP: Reinforcement-Enhanced Label-Efficient Active Phenotyping for Electronic Health Records](https://arxiv.org/abs/2511.07473)
*Yang Yang,Kathryn Pollak,Bibhas Chakraborty,Molei Liu,Doudou Zhou,Chuan Hong*

Main category: cs.LG

TL;DR: RELEAP是一个基于强化学习的主动学习框架，通过下游预测性能反馈来指导表型校正和样本选择，在有限标注预算下显著提升风险预测性能。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录表型分析通常依赖噪声代理标签，影响下游风险预测的可靠性。传统主动学习方法依赖固定启发式规则，无法确保表型细化能改善预测性能。

Method: 提出RELEAP框架，自适应整合多种查询策略，基于下游模型反馈更新策略。在杜克大学健康系统队列上评估，使用逻辑回归和惩罚Cox生存模型进行肺癌风险预测。

Result: RELEAP在所有基准测试中表现最优：逻辑AUC从0.774提升至0.805，生存C指数从0.718提升至0.752，在相同标注预算下比启发式方法获得更平滑稳定的增益。

Conclusion: RELEAP通过下游反馈优化表型校正，提供可扩展的标签高效范式，减少手动图表审查，增强基于EHR的风险预测可靠性。

Abstract: Objective: Electronic health record (EHR) phenotyping often relies on noisy proxy labels, which undermine the reliability of downstream risk prediction. Active learning can reduce annotation costs, but most rely on fixed heuristics and do not ensure that phenotype refinement improves prediction performance. Our goal was to develop a framework that directly uses downstream prediction performance as feedback to guide phenotype correction and sample selection under constrained labeling budgets.
  Materials and Methods: We propose Reinforcement-Enhanced Label-Efficient Active Phenotyping (RELEAP), a reinforcement learning-based active learning framework. RELEAP adaptively integrates multiple querying strategies and, unlike prior methods, updates its policy based on feedback from downstream models. We evaluated RELEAP on a de-identified Duke University Health System (DUHS) cohort (2014-2024) for incident lung cancer risk prediction, using logistic regression and penalized Cox survival models. Performance was benchmarked against noisy-label baselines and single-strategy active learning.
  Results: RELEAP consistently outperformed all baselines. Logistic AUC increased from 0.774 to 0.805 and survival C-index from 0.718 to 0.752. Using downstream performance as feedback, RELEAP produced smoother and more stable gains than heuristic methods under the same labeling budget.
  Discussion: By linking phenotype refinement to prediction outcomes, RELEAP learns which samples most improve downstream discrimination and calibration, offering a more principled alternative to fixed active learning rules.
  Conclusion: RELEAP optimizes phenotype correction through downstream feedback, offering a scalable, label-efficient paradigm that reduces manual chart review and enhances the reliability of EHR-based risk prediction.

</details>


### [7] [Comparing Reconstruction Attacks on Pretrained Versus Full Fine-tuned Large Language Model Embeddings on Homo Sapiens Splice Sites Genomic Data](https://arxiv.org/abs/2511.07481)
*Reem Al-Saidi,Erman Ayday,Ziad Kobti*

Main category: cs.LG

TL;DR: 该研究探讨了在基因组序列上应用的大型语言模型中的嵌入重建攻击，特别关注微调如何影响对这些攻击的脆弱性。研究发现微调可以增强模型对重建攻击的抵抗力，特别是在XLNet、GPT-2和BERT等架构中。


<details>
  <summary>Details</summary>
Motivation: 基于Pan等人的工作，该研究旨在确定任务特定的优化（微调）是加强还是削弱了隐私保护，特别是在处理敏感的基因组数据时。

Method: 研究扩展了Pan等人的工作，包括：1）将重建攻击管道应用于预训练和微调模型嵌入；2）为DNA序列实现专门的标记化机制；3）对预训练和微调嵌入进行详细的比较分析。

Result: 研究结果显示，微调在多个架构中增强了对抗重建攻击的抵抗力：XLNet (+19.8%)、GPT-2 (+9.8%) 和 BERT (+7.8%)。

Conclusion: 任务特定的优化（微调）可能是一种隐私增强机制，值得进一步探索，同时强调了为处理敏感基因组数据的语言模型开发高级保护机制的必要性。

Abstract: This study investigates embedding reconstruction attacks in large language models (LLMs) applied to genomic sequences, with a specific focus on how fine-tuning affects vulnerability to these attacks. Building upon Pan et al.'s seminal work demonstrating that embeddings from pretrained language models can leak sensitive information, we conduct a comprehensive analysis using the HS3D genomic dataset to determine whether task-specific optimization strengthens or weakens privacy protections. Our research extends Pan et al.'s work in three significant dimensions. First, we apply their reconstruction attack pipeline to pretrained and fine-tuned model embeddings, addressing a critical gap in their methodology that did not specify embedding types. Second, we implement specialized tokenization mechanisms tailored specifically for DNA sequences, enhancing the model's ability to process genomic data, as these models are pretrained on natural language and not DNA. Third, we perform a detailed comparative analysis examining position-specific, nucleotide-type, and privacy changes between pretrained and fine-tuned embeddings. We assess embeddings vulnerabilities across different types and dimensions, providing deeper insights into how task adaptation shifts privacy risks throughout genomic sequences. Our findings show a clear distinction in reconstruction vulnerability between pretrained and fine-tuned embeddings. Notably, fine-tuning strengthens resistance to reconstruction attacks in multiple architectures -- XLNet (+19.8\%), GPT-2 (+9.8\%), and BERT (+7.8\%) -- pointing to task-specific optimization as a potential privacy enhancement mechanism. These results highlight the need for advanced protective mechanisms for language models processing sensitive genomic data, while highlighting fine-tuning as a potential privacy-enhancing technique worth further exploration.

</details>


### [8] [Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits](https://arxiv.org/abs/2511.07482)
*Dev Patel,Gabrielle Gervacio,Diekola Raimi,Kevin Zhu,Ryan Lagasse,Gabriel Grand,Ashwinee Panda,Maheep Chaudhary*

Main category: cs.LG

TL;DR: AAPP是一种动态结构化剪枝方法，通过在推理过程中自适应保留对齐相关电路，在保持计算效率的同时显著提升LLM的安全对齐性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理需要大量计算资源，动态剪枝虽然比静态方法更高效，但会加剧对齐退化问题，因为只保留输入相关的安全关键电路。

Method: 基于Probe Pruning构建的Alignment-Aware Probe Pruning方法，在推理过程中自适应地保留对齐相关电路。

Result: 在LLaMA 2-7B、Qwen2.5-14B-Instruct和Gemma-3-12B-IT上的实验表明，AAPP在相同计算量下将拒绝率提高了50%。

Conclusion: AAPP实现了高效且安全保持的LLM部署，解决了动态剪枝带来的对齐漏洞问题。

Abstract: Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critical circuit preservation across diverse inputs. As a result, addressing these heightened alignment vulnerabilities remains critical. We introduce Alignment-Aware Probe Pruning (AAPP), a dynamic structured pruning method that adaptively preserves alignment-relevant circuits during inference, building upon Probe Pruning. Experiments on LLaMA 2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by 50\% at matched compute, enabling efficient yet safety-preserving LLM deployment.

</details>


### [9] [Counterfactual Forecasting of Human Behavior using Generative AI and Causal Graphs](https://arxiv.org/abs/2511.07484)
*Dharmateja Priyadarshi Uddandarao,Ravi Kiran Vadlamani*

Main category: cs.LG

TL;DR: 提出结合结构因果模型与Transformer生成AI的反事实用户行为预测框架，通过因果图建模用户交互关系，在多种数据集上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统预测方法难以模拟虚构情境下的用户行为，需要能有效评估产品干预措施效果的预测工具。

Method: 构建因果图映射用户交互、采用指标和产品特征间关系，使用基于因果变量的生成模型生成反事实条件下的行为轨迹。

Result: 在网页交互、移动应用和电商数据集上测试，性能优于传统预测和提升建模技术。

Conclusion: 该框架通过因果路径可视化提升可解释性，帮助产品团队在部署前有效模拟和评估潜在干预措施。

Abstract: This study presents a novel framework for counterfactual user behavior forecasting that combines structural causal models with transformer-based generative artificial intelligence. To model fictitious situations, the method creates causal graphs that map the connections between user interactions, adoption metrics, and product features. The framework generates realistic behavioral trajectories under counterfactual conditions by using generative models that are conditioned on causal variables. Tested on datasets from web interactions, mobile applications, and e-commerce, the methodology outperforms conventional forecasting and uplift modeling techniques. Product teams can effectively simulate and assess possible interventions prior to deployment thanks to the framework improved interpretability through causal path visualization.

</details>


### [10] [When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift](https://arxiv.org/abs/2511.07485)
*Sushant Mehta*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，证明不同偏差机制（如虚假相关性、子群体偏移、类别不平衡和公平性违反）在模型性能上会产生定量等效的影响。通过信息论方法将偏差形式化为条件独立性违反，并建立了这些偏差之间的等价关系。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统存在多种失败模式（不公平性、对虚假相关性的脆弱性、在少数子群体上表现差等），这些通常被不同研究社区孤立研究。作者希望建立一个统一框架来理解这些偏差机制之间的内在联系。

Method: 使用信息论方法将偏差形式化为条件独立性违反，通过理论推导证明不同偏差机制之间的定量等价关系。在6个数据集和3种架构上进行实证验证。

Result: 理论预测的等价关系在实证中得到验证，最差组准确率的预测误差在3%以内。例如，强度为α的虚假相关性产生的效果等价于子群体不平衡比r≈(1+α)/(1-α)。

Conclusion: 该工作将公平性、鲁棒性和分布偏移的研究文献统一到一个共同视角下，使得在不同问题领域间能够有原则地转移去偏方法。

Abstract: Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. We propose a unifying theoretical framework that characterizes when different bias mechanisms produce quantitatively equivalent effects on model performance. By formalizing biases as violations of conditional independence through information-theoretic measures, we prove formal equivalence conditions relating spurious correlations, subpopulation shift, class imbalance, and fairness violations. Our theory predicts that a spurious correlation of strength $α$ produces equivalent worst-group accuracy degradation as a sub-population imbalance ratio $r \approx (1+α)/(1-α)$ under feature overlap assumptions. Empirical validation in six datasets and three architectures confirms that predicted equivalences hold within the accuracy of the worst group 3\%, enabling the principled transfer of debiasing methods across problem domains. This work bridges the literature on fairness, robustness, and distribution shifts under a common perspective.

</details>


### [11] [Provably Efficient Sample Complexity for Robust CMDP](https://arxiv.org/abs/2511.07486)
*Sourav Ganguly,Arnob Ghosh*

Main category: cs.LG

TL;DR: 提出了首个具有样本复杂度保证的鲁棒约束MDP算法RCVI，通过增强状态空间处理约束，在不确定环境下实现安全强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒约束MDP研究主要关注迭代复杂度，但样本复杂度尚未探索，且马尔可夫策略在约束情况下可能不是最优的。

Method: 引入包含剩余效用预算的增强状态空间，提出鲁棒约束值迭代算法RCVI，使用生成模型进行采样。

Result: 实现了Õ(|S||A|H⁵/ε²)的样本复杂度，确保最多ε的约束违反，是首个具有样本复杂度保证的RCMDP算法。

Conclusion: RCVI算法有效解决了鲁棒约束MDP问题，实验验证了其有效性，为安全强化学习提供了理论基础。

Abstract: We study the problem of learning policies that maximize cumulative reward while satisfying safety constraints, even when the real environment differs from a simulator or nominal model. We focus on robust constrained Markov decision processes (RCMDPs), where the agent must maximize reward while ensuring cumulative utility exceeds a threshold under the worst-case dynamics within an uncertainty set. While recent works have established finite-time iteration complexity guarantees for RCMDPs using policy optimization, their sample complexity guarantees remain largely unexplored. In this paper, we first show that Markovian policies may fail to be optimal even under rectangular uncertainty sets unlike the {\em unconstrained} robust MDP. To address this, we introduce an augmented state space that incorporates the remaining utility budget into the state representation. Building on this formulation, we propose a novel Robust constrained Value iteration (RCVI) algorithm with a sample complexity of $\mathcal{\tilde{O}}(|S||A|H^5/ε^2)$ achieving at most $ε$ violation using a generative model where $|S|$ and $|A|$ denote the sizes of the state and action spaces, respectively, and $H$ is the episode length. To the best of our knowledge, this is the {\em first sample complexity guarantee} for RCMDP. Empirical results further validate the effectiveness of our approach.

</details>


### [12] [Methodological Precedence in Health Tech: Why ML/Big Data Analysis Must Follow Basic Epidemiological Consistency. A Case Study](https://arxiv.org/abs/2511.07500)
*Marco Roccetti*

Main category: cs.LG

TL;DR: 该研究通过一个疫苗与精神事件关联的队列研究案例，揭示了即使使用先进的机器学习和大数据分析，如果基础研究设计存在严重缺陷，复杂分析反而会放大错误，产生误导性结果。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和海量数据处理在健康研究中的广泛应用，研究者需要认识到这些复杂方法的严谨性完全依赖于基础数据集的质量和统计设计的有效性。本文旨在强调在应用高级分析之前验证基本方法一致性的重要性。

Method: 研究采用简单的标准描述性统计方法和已确立的国家流行病学基准，对一个已发表的关于疫苗结果与精神事件的队列研究进行分析，识别其中存在的统计矛盾。

Result: 分析发现了多个统计上不可调和的悖论，包括高风险人群中慢性疾病风险降低的不可信结果以及相互矛盾的发病率比较，这些悖论明确否定了报告的风险比（HRs）。

Conclusion: 研究结论强调，即使是复杂的健康研究也必须首先通过基本流行病学一致性测试，然后才能认为从后续高级机器学习或统计建模得出的结论是有效的。在缺乏随机化的情况下，倾向评分匹配等稳健方法对于从管理数据中获得有效的因果推断至关重要。

Abstract: The integration of advanced analytical tools, including Machine Learning (ML) and massive data processing, has revolutionized health research, promising unprecedented accuracy in diagnosis and risk prediction. However, the rigor of these complex methods is fundamentally dependent on the quality and integrity of the underlying datasets and the validity of their statistical design. We propose an emblematic case where advanced analysis (ML/Big Data) must necessarily be subsequent to the verification of basic methodological coherence. This study highlights a crucial cautionary principle: sophisticated analyses amplify, rather than correct, severe methodological flaws rooted in basic design choices, leading to misleading or contradictory findings. By applying simple, standard descriptive statistical methods and established national epidemiological benchmarks to a recently published cohort study on vaccine outcomes and psychiatric events, we expose multiple, statistically irreconcilable paradoxes. These paradoxes, including an implausible risk reduction for a chronic disorder in a high-risk group and contradictory incidence rate comparisons, definitively invalidate the reported hazard ratios (HRs). We demonstrate that the observed effects are mathematical artifacts stemming from an uncorrected selection bias in the cohort construction. This analysis serves as a robust reminder that even the most complex health studies must first pass the test of basic epidemiological consistency before any conclusion drawn from subsequent advanced ML or statistical modeling can be considered valid or publishable. We conclude that robust methods, such as Propensity Score Matching, are essential for achieving valid causal inference from administrative data in the absence of randomization

</details>


### [13] [N-ReLU: Zero-Mean Stochastic Extension of ReLU](https://arxiv.org/abs/2511.07559)
*Md Motaleb Hossen Manik,Md Zabirul Islam,Ge Wang*

Main category: cs.LG

TL;DR: N-ReLU是一种基于ReLU的随机激活函数，通过用高斯噪声替代负值激活来避免神经元死亡问题，在MNIST数据集上取得了与主流激活函数相当或略优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决标准ReLU激活函数导致的神经元死亡问题，同时保持期望输出不变，增强优化鲁棒性。

Method: 提出N-ReLU激活函数，将负值激活替换为零均值高斯噪声，保持期望输出与ReLU一致，作为退火式正则化器。

Result: 在MNIST数据集上，N-ReLU在中等噪声水平（sigma=0.05-0.10）下达到与ReLU、LeakyReLU、PReLU、GELU和RReLU相当或略优的准确率，且未观察到神经元死亡现象。

Conclusion: 轻量级高斯噪声注入是一种简单有效的机制，可在不修改网络结构或引入额外参数的情况下增强优化鲁棒性。

Abstract: Activation functions are fundamental for enabling nonlinear representations in deep neural networks. However, the standard rectified linear unit (ReLU) often suffers from inactive or "dead" neurons caused by its hard zero cutoff. To address this issue, we introduce N-ReLU (Noise-ReLU), a zero-mean stochastic extension of ReLU that replaces negative activations with Gaussian noise while preserving the same expected output. This expectation-aligned formulation maintains gradient flow in inactive regions and acts as an annealing-style regularizer during training. Experiments on the MNIST dataset using both multilayer perceptron (MLP) and convolutional neural network (CNN) architectures show that N-ReLU achieves accuracy comparable to or slightly exceeding that of ReLU, LeakyReLU, PReLU, GELU, and RReLU at moderate noise levels (sigma = 0.05-0.10), with stable convergence and no dead neurons observed. These results demonstrate that lightweight Gaussian noise injection offers a simple yet effective mechanism to enhance optimization robustness without modifying network structures or introducing additional parameters.

</details>


### [14] [SCALAR: Benchmarking SAE Interaction Sparsity in Toy LLMs](https://arxiv.org/abs/2511.07572)
*Sean P. Fillingham,Andrew Gordon,Peter Lai,Xavier Poncini,David Quarel,Stefan Heimersheim*

Main category: cs.LG

TL;DR: 提出了SCALAR基准来评估稀疏自编码器（SAE）特征间的交互稀疏性，并引入Staircase SAEs通过权重共享减少上游特征重复，显著提高了交互稀疏性。


<details>
  <summary>Details</summary>
Motivation: 现有SAE方法在单独训练时无法保证跨层连接的稀疏性，导致提取的电路中出现不必要的上游特征重复影响多个下游特征，而当前评估只关注单个SAE性能，忽略了交互稀疏性。

Method: 开发SCALAR基准来测量SAE特征间的交互稀疏性；提出Staircase SAEs，使用权重共享限制上游特征在下游特征中的重复；比较TopK SAEs、Jacobian SAEs和Staircase SAEs的性能。

Result: Staircase SAEs相比TopK SAEs在交互稀疏性上提升了59.67%（前馈层）和63.15%（Transformer块）；Jacobian SAEs在前馈层有8.54%提升但无法在Transformer块有效训练；在21.6K参数玩具模型和GPT-2 Small上验证了方法的有效性。

Conclusion: 通过基准测试和架构比较，强调了交互稀疏性在SAE中的重要性，Staircase SAEs在保持特征可解释性的同时显著改善了交互稀疏性。

Abstract: Mechanistic interpretability aims to decompose neural networks into interpretable features and map their connecting circuits. The standard approach trains sparse autoencoders (SAEs) on each layer's activations. However, SAEs trained in isolation don't encourage sparse cross-layer connections, inflating extracted circuits where upstream features needlessly affect multiple downstream features. Current evaluations focus on individual SAE performance, leaving interaction sparsity unexamined. We introduce SCALAR (Sparse Connectivity Assessment of Latent Activation Relationships), a benchmark measuring interaction sparsity between SAE features. We also propose "Staircase SAEs", using weight-sharing to limit upstream feature duplication across downstream features. Using SCALAR, we compare TopK SAEs, Jacobian SAEs (JSAEs), and Staircase SAEs. Staircase SAEs improve relative sparsity over TopK SAEs by $59.67\% \pm 1.83\%$ (feedforward) and $63.15\% \pm 1.35\%$ (transformer blocks). JSAEs provide $8.54\% \pm 0.38\%$ improvement over TopK for feedforward layers but cannot train effectively across transformer blocks, unlike Staircase and TopK SAEs which work anywhere in the residual stream. We validate on a $216$K-parameter toy model and GPT-$2$ Small ($124$M), where Staircase SAEs maintain interaction sparsity improvements while preserving feature interpretability. Our work highlights the importance of interaction sparsity in SAEs through benchmarking and comparing promising architectures.

</details>


### [15] [LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows](https://arxiv.org/abs/2511.07585)
*Raffi Khatchadourian,Rolando Franco*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Financial institutions deploy Large Language Models (LLMs) for reconciliations, regulatory reporting, and client communications, but nondeterministic outputs (output drift) undermine auditability and trust. We quantify drift across five model architectures (7B-120B parameters) on regulated financial tasks, revealing a stark inverse relationship: smaller models (Granite-3-8B, Qwen2.5-7B) achieve 100% output consistency at T=0.0, while GPT-OSS-120B exhibits only 12.5% consistency (95% CI: 3.5-36.0%) regardless of configuration (p<0.0001, Fisher's exact test). This finding challenges conventional assumptions that larger models are universally superior for production deployment.
  Our contributions include: (i) a finance-calibrated deterministic test harness combining greedy decoding (T=0.0), fixed seeds, and SEC 10-K structure-aware retrieval ordering; (ii) task-specific invariant checking for RAG, JSON, and SQL outputs using finance-calibrated materiality thresholds (plus or minus 5%) and SEC citation validation; (iii) a three-tier model classification system enabling risk-appropriate deployment decisions; and (iv) an audit-ready attestation system with dual-provider validation.
  We evaluated five models (Qwen2.5-7B via Ollama, Granite-3-8B via IBM watsonx.ai, Llama-3.3-70B, Mistral-Medium-2505, and GPT-OSS-120B) across three regulated financial tasks. Across 480 runs (n=16 per condition), structured tasks (SQL) remain stable even at T=0.2, while RAG tasks show drift (25-75%), revealing task-dependent sensitivity. Cross-provider validation confirms deterministic behavior transfers between local and cloud deployments. We map our framework to Financial Stability Board (FSB), Bank for International Settlements (BIS), and Commodity Futures Trading Commission (CFTC) requirements, demonstrating practical pathways for compliance-ready AI deployments.

</details>


### [16] [One Router to Route Them All: Homogeneous Expert Routing for Heterogeneous Graph Transformers](https://arxiv.org/abs/2511.07603)
*Georgiy Shakirov,Albert Arakelov*

Main category: cs.LG

TL;DR: 提出Homogeneous Expert Routing (HER)方法，将MoE集成到异质图神经网络中，通过随机掩码类型嵌入来鼓励类型无关的专家专业化，在链接预测任务上优于标准HGT和类型分离的MoE基线。


<details>
  <summary>Details</summary>
Motivation: 传统HGNNs基于节点/边类型设置参数，可能导致对表面标签的过度依赖并阻碍跨类型知识迁移。探索在异质图中集成MoE，质疑类型特定专家的必要性。

Method: 提出HER方法，在HGT中集成MoE层，在路由过程中随机掩码类型嵌入，促使专家基于语义模式而非节点类型进行专业化。

Result: 在IMDB、ACM和DBLP数据集上的链接预测任务中，HER一致优于标准HGT和类型分离的MoE基线。分析显示HER专家按语义模式（如电影类型）而非节点类型进行专业化。

Conclusion: 在专家路由中正则化类型依赖性可以产生更可泛化、高效和可解释的表示，为异质图学习提供了新的设计原则。

Abstract: A common practice in heterogeneous graph neural networks (HGNNs) is to condition parameters on node/edge types, assuming types reflect semantic roles. However, this can cause overreliance on surface-level labels and impede cross-type knowledge transfer. We explore integrating Mixture-of-Experts (MoE) into HGNNs--a direction underexplored despite MoE's success in homogeneous settings. Crucially, we question the need for type-specific experts. We propose Homogeneous Expert Routing (HER), an MoE layer for Heterogeneous Graph Transformers (HGT) that stochastically masks type embeddings during routing to encourage type-agnostic specialization. Evaluated on IMDB, ACM, and DBLP for link prediction, HER consistently outperforms standard HGT and a type-separated MoE baseline. Analysis on IMDB shows HER experts specialize by semantic patterns (e.g., movie genres) rather than node types, confirming routing is driven by latent semantics. Our work demonstrates that regularizing type dependence in expert routing yields more generalizable, efficient, and interpretable representations--a new design principle for heterogeneous graph learning.

</details>


### [17] [Partial Action Replacement: Tackling Distribution Shift in Offline MARL](https://arxiv.org/abs/2511.07629)
*Yue Jin,Giovanni Montana*

Main category: cs.LG

TL;DR: 提出了SPaCQL算法，通过部分动作替换(PAR)策略缓解离线多智能体强化学习中的分布外问题，在行为策略可分解的场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 离线多智能体强化学习面临分布外联合动作评估的严重挑战，特别是在行为策略可分解的常见场景下需要更有效的解决方案。

Method: 开发了Soft-Partial Conservative Q-Learning (SPaCQL)，使用部分动作替换策略缓解OOD问题，并基于价值估计不确定性动态加权不同的PAR策略。

Result: 理论证明在可分解行为策略下，分布偏移随偏离智能体数量线性增长而非指数增长，实验显示SPaCQL在具有独立性结构的离线数据集上显著优于基线算法。

Conclusion: SPaCQL通过部分动作替换策略有效解决了离线MARL中的分布外问题，在行为策略可分解的场景下具有理论保证和实际优势。

Abstract: Offline multi-agent reinforcement learning (MARL) is severely hampered by the challenge of evaluating out-of-distribution (OOD) joint actions. Our core finding is that when the behavior policy is factorized - a common scenario where agents act fully or partially independently during data collection - a strategy of partial action replacement (PAR) can significantly mitigate this challenge. PAR updates a single or part of agents' actions while the others remain fixed to the behavioral data, reducing distribution shift compared to full joint-action updates. Based on this insight, we develop Soft-Partial Conservative Q-Learning (SPaCQL), using PAR to mitigate OOD issue and dynamically weighting different PAR strategies based on the uncertainty of value estimation. We provide a rigorous theoretical foundation for this approach, proving that under factorized behavior policies, the induced distribution shift scales linearly with the number of deviating agents rather than exponentially with the joint-action space. This yields a provably tighter value error bound for this important class of offline MARL problems. Our theoretical results also indicate that SPaCQL adaptively addresses distribution shift using uncertainty-informed weights. Our empirical results demonstrate SPaCQL enables more effective policy learning, and manifest its remarkable superiority over baseline algorithms when the offline dataset exhibits the independence structure.

</details>


### [18] [FlowTIE: Flow-based Transport of Intensity Equation for Phase Gradient Estimation from 4D-STEM Data](https://arxiv.org/abs/2511.07633)
*Arya Bangun,Maximilian Töllner,Xuan Zhao,Christian Kübel,Hanno Scharr*

Main category: cs.LG

TL;DR: FlowTIE是一个基于神经网络的框架，用于从4D-STEM数据重建相位，将强度传输方程与基于流的相位梯度表示相结合，提高厚样品动态散射条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决在厚样品动态散射条件下传统相位重建方法的局限性，将数据驱动学习与物理先验相结合以提高鲁棒性。

Method: 将强度传输方程与基于流的相位梯度表示集成，结合神经网络框架进行相位重建，并可整合多层切片方法处理厚样品。

Result: 在模拟晶体材料数据集上的验证表明，FlowTIE相比经典TIE和基于梯度的优化方法提高了相位重建精度，速度更快，且能与厚样品模型集成。

Conclusion: FlowTIE框架有效结合了数据驱动和物理先验，在厚样品条件下实现了更准确、更快速的相位重建。

Abstract: We introduce FlowTIE, a neural-network-based framework for phase reconstruction from 4D-Scanning Transmission Electron Microscopy (STEM) data, which integrates the Transport of Intensity Equation (TIE) with a flow-based representation of the phase gradient. This formulation allows the model to bridge data-driven learning with physics-based priors, improving robustness under dynamical scattering conditions for thick specimen. The validation on simulated datasets of crystalline materials, benchmarking to classical TIE and gradient-based optimization methods are presented. The results demonstrate that FlowTIE improves phase reconstruction accuracy, fast, and can be integrated with a thick specimen model, namely multislice method.

</details>


### [19] [Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private](https://arxiv.org/abs/2511.07637)
*Ruihan Wu,Erchi Wang,Zhiyuan Zhang,Yu-Xiang Wang*

Main category: cs.LG

TL;DR: 本文提出了两种差分隐私保护的检索增强生成算法（MURAG和MURAG-ADA），能够在多查询场景下保护敏感文档的隐私，同时保持实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私RAG系统仅支持单查询设置，无法满足实际使用需求。当外部语料库包含敏感信息时，未受保护的RAG系统存在隐私泄露风险。

Method: MURAG利用个体隐私过滤器，使累积隐私损失仅取决于每个文档被检索的频率而非查询总数；MURAG-ADA通过私有发布查询特定阈值，进一步提高了实用性，实现更精确的相关文档选择。

Result: 在多个LLM和数据集上的实验表明，所提方法能在实用的DP预算（ε≈10）内扩展到数百个查询，同时保持有意义的实用性。

Conclusion: 本文提出的多查询差分隐私RAG算法解决了实际应用中的隐私保护需求，为敏感信息环境下的检索增强生成提供了可行的解决方案。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving documents from an external corpus at inference time. When this corpus contains sensitive information, however, unprotected RAG systems are at risk of leaking private information. Prior work has introduced differential privacy (DP) guarantees for RAG, but only in single-query settings, which fall short of realistic usage. In this paper, we study the more practical multi-query setting and propose two DP-RAG algorithms. The first, MURAG, leverages an individual privacy filter so that the accumulated privacy loss only depends on how frequently each document is retrieved rather than the total number of queries. The second, MURAG-ADA, further improves utility by privately releasing query-specific thresholds, enabling more precise selection of relevant documents. Our experiments across multiple LLMs and datasets demonstrate that the proposed methods scale to hundreds of queries within a practical DP budget ($\varepsilon\approx10$), while preserving meaningful utility.

</details>


### [20] [Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction](https://arxiv.org/abs/2511.07649)
*Pengfei Hu,Ming Fan,Xiaoxue Han,Chang Lu,Wei Zhang,Hyun Kang,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: AdaTrip是一个自适应时变图学习框架，用于多水库入流预测，通过动态图结构和注意力机制捕捉水库间的时空依赖关系，在科罗拉多河上游流域30个水库上表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有水库入流预测方法主要关注单一水库模型，忽略了相互连接水库之间的空间依赖性，这限制了预测的准确性和实用性。

Method: AdaTrip构建动态图结构，将水库作为节点，有向边反映水文连接，采用注意力机制自动识别关键的时空依赖关系，并通过参数共享提升记录有限水库的性能。

Result: 在科罗拉多河上游流域30个水库上的评估表明，AdaTrip优于现有基线方法，对记录有限的水库通过参数共享实现了性能提升，并提供可解释的注意力图。

Conclusion: AdaTrip框架不仅提高了多水库入流预测的准确性，还通过可解释的注意力图为运营决策提供水文控制洞察，代码已开源。

Abstract: Reservoir inflow prediction is crucial for water resource management, yet existing approaches mainly focus on single-reservoir models that ignore spatial dependencies among interconnected reservoirs. We introduce AdaTrip as an adaptive, time-varying graph learning framework for multi-reservoir inflow forecasting. AdaTrip constructs dynamic graphs where reservoirs are nodes with directed edges reflecting hydrological connections, employing attention mechanisms to automatically identify crucial spatial and temporal dependencies. Evaluation on thirty reservoirs in the Upper Colorado River Basin demonstrates superiority over existing baselines, with improved performance for reservoirs with limited records through parameter sharing. Additionally, AdaTrip provides interpretable attention maps at edge and time-step levels, offering insights into hydrological controls to support operational decision-making. Our code is available at https://github.com/humphreyhuu/AdaTrip.

</details>


### [21] [Enhancing Binary Encoded Crime Linkage Analysis Using Siamese Network](https://arxiv.org/abs/2511.07651)
*Yicheng Zhan,Fahim Ahmed,Amy Burrell,Matthew J. Tonkin,Sarah Galambos,Jessica Woodhams,Dalal Alrajeh*

Main category: cs.LG

TL;DR: 提出了一种Siamese Autoencoder框架，通过学**有意义的潜在表示来改进犯罪关联分析，在稀疏特征空间中整合地理-时间特征，相比传统方法AUC提升高达9%。


<details>
  <summary>Details</summary>
Motivation: 传统犯罪关联方法在处理高维、稀疏和异构数据时存在局限性，需要更有效的技术来识别系列犯罪者并提升公共安全。

Method: 使用Siamese Autoencoder框架，在解码器阶段整合地理-时间特征，减轻稀疏特征空间中的信号稀释问题，并分析不同领域知识驱动的数据降维策略。

Result: 在ViCLAS数据集上，该方法在多个评估指标上表现一致改善，AUC相比传统方法提升高达9%，并提供可解释的洞察支持调查决策。

Conclusion: 先进的机器学习方法能显著提升犯罪关联准确性，同时为调查决策提供可解释的见解，在犯罪关联领域具有重要应用价值。

Abstract: Effective crime linkage analysis is crucial for identifying serial offenders and enhancing public safety. To address limitations of traditional crime linkage methods in handling high-dimensional, sparse, and heterogeneous data, we propose a Siamese Autoencoder framework that learns meaningful latent representations and uncovers correlations in complex crime data. Using data from the Violent Crime Linkage Analysis System (ViCLAS), maintained by the Serious Crime Analysis Section of the UK's National Crime Agency, our approach mitigates signal dilution in sparse feature spaces by integrating geographic-temporal features at the decoder stage. This design amplifies behavioral representations rather than allowing them to be overshadowed at the input level, yielding consistent improvements across multiple evaluation metrics. We further analyze how different domain-informed data reduction strategies influence model performance, providing practical guidance for preprocessing in crime linkage contexts. Our results show that advanced machine learning approaches can substantially enhance linkage accuracy, improving AUC by up to 9% over traditional methods while offering interpretable insights to support investigative decision-making.

</details>


### [22] [CAE: Character-Level Autoencoder for Non-Semantic Relational Data Grouping](https://arxiv.org/abs/2511.07657)
*Veera V S Bhargav Nunna,Shinae Kang,Zheyuan Zhou,Virginia Wang,Sucharitha Boinapally,Michael Foley*

Main category: cs.LG

TL;DR: 提出了一种字符级自编码器方法，用于自动识别和分组非语义关系数据集中的语义相同列，通过数据模式和结构检测列相似性，显著优于传统NLP方法。


<details>
  <summary>Details</summary>
Motivation: 企业关系数据库包含大量非语义数据（如IP地址、产品标识符、编码键和时间戳），这些数据挑战传统语义分析，需要新的方法来处理这些非语义关系数据集。

Method: 采用字符级自编码器架构，在字符级别操作并保持固定字典约束，编码非语义关系表列的文本表示，提取高维特征嵌入进行数据分组。

Result: 实验评估显示，CAE方法在关系数据集的前5列匹配任务中达到80.95%的准确率，显著优于传统词袋方法（47.62%）。

Conclusion: 该工作填补了字符级神经架构理论进展与企业数据管理实践之间的差距，为非语义工业数据集的大规模模式理解和数据剖析提供了自动化解决方案。

Abstract: Enterprise relational databases increasingly contain vast amounts of non-semantic data - IP addresses, product identifiers, encoded keys, and timestamps - that challenge traditional semantic analysis. This paper introduces a novel Character-Level Autoencoder (CAE) approach that automatically identifies and groups semantically identical columns in non-semantic relational datasets by detecting column similarities based on data patterns and structures. Unlike conventional Natural Language Processing (NLP) models that struggle with limitations in semantic interpretability and out-of-vocabulary tokens, our approach operates at the character level with fixed dictionary constraints, enabling scalable processing of large-scale data lakes and warehouses. The CAE architecture encodes text representations of non-semantic relational table columns and extracts high-dimensional feature embeddings for data grouping. By maintaining a fixed dictionary size, our method significantly reduces both memory requirements and training time, enabling efficient processing of large-scale industrial data environments. Experimental evaluation demonstrates substantial performance gains: our CAE approach achieved 80.95% accuracy in top 5 column matching tasks across relational datasets, substantially outperforming traditional NLP approaches such as Bag of Words (47.62%). These results demonstrate its effectiveness for identifying and clustering identical columns in relational datasets. This work bridges the gap between theoretical advances in character-level neural architectures and practical enterprise data management challenges, providing an automated solution for schema understanding and data profiling of non-semantic industrial datasets at scale.

</details>


### [23] [ZeroSim: Zero-Shot Analog Circuit Evaluation with Unified Transformer Embeddings](https://arxiv.org/abs/2511.07658)
*Xiaomeng Yang,Jian Gao,Yanzhi Wang,Xuan Zhang*

Main category: cs.LG

TL;DR: ZeroSim是一个基于Transformer的性能建模框架，能够在训练过的拓扑结构下实现鲁棒的内分布泛化，并对未见过的拓扑结构实现零样本泛化，无需微调。


<details>
  <summary>Details</summary>
Motivation: 传统SPICE仿真耗时，现有机器学习方法需要拓扑特定重训练或手动子结构分割，限制了可扩展性和适应性。

Method: 采用三种关键策略：1) 包含360万实例的多样化训练语料库；2) 利用全局感知token和分层注意力的统一拓扑嵌入；3) 拓扑条件参数映射方法。

Result: ZeroSim显著优于多层感知机、图神经网络和Transformer等基线模型，在强化学习参数优化中比传统SPICE仿真快13倍。

Conclusion: ZeroSim为模拟电路设计自动化任务提供了实用价值，实现了高效的零样本性能预测。

Abstract: Although recent advancements in learning-based analog circuit design automation have tackled tasks such as topology generation, device sizing, and layout synthesis, efficient performance evaluation remains a major bottleneck. Traditional SPICE simulations are time-consuming, while existing machine learning methods often require topology-specific retraining or manual substructure segmentation for fine-tuning, hindering scalability and adaptability. In this work, we propose ZeroSim, a transformer-based performance modeling framework designed to achieve robust in-distribution generalization across trained topologies under novel parameter configurations and zero-shot generalization to unseen topologies without any fine-tuning. We apply three key enabling strategies: (1) a diverse training corpus of 3.6 million instances covering over 60 amplifier topologies, (2) unified topology embeddings leveraging global-aware tokens and hierarchical attention to robustly generalize to novel circuits, and (3) a topology-conditioned parameter mapping approach that maintains consistent structural representations independent of parameter variations. Our experimental results demonstrate that ZeroSim significantly outperforms baseline models such as multilayer perceptrons, graph neural networks and transformers, delivering accurate zero-shot predictions across different amplifier topologies. Additionally, when integrated into a reinforcement learning-based parameter optimization pipeline, ZeroSim achieves a remarkable speedup (13x) compared to conventional SPICE simulations, underscoring its practical value for a wide range of analog circuit design automation tasks.

</details>


### [24] [Probabilities Are All You Need: A Probability-Only Approach to Uncertainty Estimation in Large Language Models](https://arxiv.org/abs/2511.07694)
*Manh Nguyen,Sunil Gupta,Hung Le*

Main category: cs.LG

TL;DR: 提出一种无需训练的高效不确定性估计方法，通过使用回答的前K个概率来近似预测熵，并采用自适应机制确定K值，在多个LLM和问答数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP任务中表现优异但容易产生幻觉，生成事实错误或误导性输出。现有不确定性估计方法通常需要多次采样或额外计算来评估语义熵，效率较低。

Method: 提出训练免费的不确定性估计方法，使用回答的前K个概率近似预测熵，并采用自适应机制动态确定K值以过滤低置信度概率。

Result: 在三个自由形式问答数据集和多个LLM上的实验结果表明，该方法优于昂贵的现有最优基线方法。

Conclusion: 该方法有助于提升LLM的可信度，为更可靠的LLM应用提供了有效的不确定性估计解决方案。

Abstract: Large Language Models (LLMs) exhibit strong performance across various natural language processing (NLP) tasks but remain vulnerable to hallucinations, generating factually incorrect or misleading outputs. Uncertainty estimation, often using predictive entropy estimation, is key to addressing this issue. However, existing methods often require multiple samples or extra computation to assess semantic entropy. This paper proposes an efficient, training-free uncertainty estimation method that approximates predictive entropy using the responses' top-$K$ probabilities. Moreover, we employ an adaptive mechanism to determine $K$ to enhance flexibility and filter out low-confidence probabilities. Experimental results on three free-form question-answering datasets across several LLMs demonstrate that our method outperforms expensive state-of-the-art baselines, contributing to the broader goal of enhancing LLM trustworthiness.

</details>


### [25] [On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection](https://arxiv.org/abs/2511.07700)
*Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy*

Main category: cs.LG

TL;DR: AI模型在黑色素瘤检测中表现出专家级性能，但在性别、种族和年龄等人口统计亚组中存在性能差异。本文通过引入校准作为AUROC公平性指标的补充基准指标，评估了领先皮肤癌检测算法在不同亚组中的表现，发现现有模型虽然提高了判别准确性，但在新数据集上往往过度诊断风险并存在校准问题。


<details>
  <summary>Details</summary>
Motivation: AI模型在临床应用中面临性能在不同人口统计亚组间存在差异的问题，而现有的基准测试主要依赖AUROC指标，无法评估模型提供准确估计的能力。本文旨在填补这一空白，将校准作为补充指标来深入分析亚组偏见。

Method: 使用ISIC 2020挑战赛数据集和PROVE-AI数据集，评估ISIC 2020挑战赛领先皮肤癌检测算法以及第二、三名模型的表现，重点关注按性别、种族（Fitzpatrick皮肤类型）和年龄定义的亚组，将校准作为AUROC公平性指标的补充基准指标。

Result: 研究发现，现有模型虽然提高了判别准确性，但在应用于新数据集时往往过度诊断风险并表现出校准问题，揭示了模型在不同人口统计亚组中的性能差异。

Conclusion: 本研究强调了需要全面的模型审计策略和广泛的元数据收集，以实现公平的AI驱动医疗解决方案。所有代码已在GitHub上公开。

Abstract: Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.

</details>


### [26] [Diffusion Guided Adversarial State Perturbations in Reinforcement Learning](https://arxiv.org/abs/2511.07701)
*Xiaolin Sun,Feidi Liu,Zhengming Ding,ZiZhan Zheng*

Main category: cs.LG

TL;DR: SHIFT是一种基于扩散模型的策略无关状态扰动攻击，能够生成语义不同但真实且历史对齐的扰动状态，有效突破现有RL防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有RL系统在视觉环境中容易受到对抗攻击，但当前防御方法的有效性主要源于现有l_p范数约束攻击的局限性，这些攻击即使在大扰动预算下也难以改变图像输入的语义。

Method: 提出SHIFT攻击方法，利用扩散模型生成语义不同但保持真实性和历史对齐性的扰动状态，避免被检测到。

Result: 评估显示SHIFT攻击能有效突破现有防御机制，包括最复杂的防御方法，显著优于现有攻击，同时具有更好的感知隐蔽性。

Conclusion: RL智能体对语义感知的对抗扰动存在严重脆弱性，表明需要开发更鲁棒的政策。

Abstract: Reinforcement learning (RL) systems, while achieving remarkable success across various domains, are vulnerable to adversarial attacks. This is especially a concern in vision-based environments where minor manipulations of high-dimensional image inputs can easily mislead the agent's behavior. To this end, various defenses have been proposed recently, with state-of-the-art approaches achieving robust performance even under large state perturbations. However, after closer investigation, we found that the effectiveness of the current defenses is due to a fundamental weakness of the existing $l_p$ norm-constrained attacks, which can barely alter the semantics of image input even under a relatively large perturbation budget. In this work, we propose SHIFT, a novel policy-agnostic diffusion-based state perturbation attack to go beyond this limitation. Our attack is able to generate perturbed states that are semantically different from the true states while remaining realistic and history-aligned to avoid detection. Evaluations show that our attack effectively breaks existing defenses, including the most sophisticated ones, significantly outperforming existing attacks while being more perceptually stealthy. The results highlight the vulnerability of RL agents to semantics-aware adversarial perturbations, indicating the importance of developing more robust policies.

</details>


### [27] [A Ranking-Based Optimization Algorithm for the Vehicle Relocation Problem in Car Sharing Services](https://arxiv.org/abs/2511.07724)
*Piotr Szwed,Paweł Skrzynski,Jarosław Wąs*

Main category: cs.LG

TL;DR: 提出了一种基于区域划分和快速排序算法的车辆重新定位方法，用于解决自由流动汽车共享服务中的车辆重新分配问题，通过使用滑板车进行人员转移，相比基准方法平均提升8.44%的性能。


<details>
  <summary>Details</summary>
Motivation: 解决自由流动汽车共享服务中的车辆重新定位问题，优化车辆分布以提高服务效率和用户体验。

Method: 将服务区域划分为具有相似时间模式的区域，应用离散优化方法；提出基于可用车辆数量、需求概率密度和行程持续时间的快速排序算法。

Result: 在相同条件下，相比无优化的基准方法，该算法平均提升8.44%的性能，MIP模型提升19.6%；实际应用中可提升性能指标约3%-10%。

Conclusion: 提出的解决方案能有效改善汽车共享服务的车辆重新定位问题，性能提升显著，且算法效率较高。

Abstract: The paper addresses the Vehicle Relocation Problem in free-floating car-sharing services by presenting a solution focused on strategies for repositioning vehicles and transferring personnel with the use of scooters. Our method begins by dividing the service area into zones that group regions with similar temporal patterns of vehicle presence and service demand, allowing the application of discrete optimization methods. In the next stage, we propose a fast ranking-based algorithm that makes its decisions on the basis of the number of cars available in each zone, the projected probability density of demand, and estimated trip durations. The experiments were carried out on the basis of real-world data originating from a major car-sharing service operator in Poland. The results of this algorithm are evaluated against scenarios without optimization that constitute a baseline and compared with the results of an exact algorithm to solve the Mixed Integer Programming (MIP) model. As performance metrics, the total travel time was used. Under identical conditions (number of vehicles, staff, and demand distribution), the average improvements with respect to the baseline of our algorithm and MIP solver were equal to 8.44\% and 19.6\% correspondingly. However, it should be noted that the MIP model also mimicked decisions on trip selection, which are excluded by current services business rules. The analysis of results suggests that, depending on the size of the workforce, the application of the proposed solution allows for improving performance metrics by roughly 3%-10%.

</details>


### [28] [Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning](https://arxiv.org/abs/2511.07730)
*Bill Chunyuan Zheng,Vivek Myers,Benjamin Eysenbach,Sergey Levine*

Main category: cs.LG

TL;DR: 提出了一种结合时序差分和蒙特卡洛方法的GCRL方法，通过多步蒙特卡洛回报拟合拟度量距离，在长视野任务中表现出色，并在真实机器人操作领域实现多步拼接。


<details>
  <summary>Details</summary>
Motivation: 解决AI中长视野目标达成的问题，特别是如何估计观测对之间的时序距离。时序差分方法虽有最优性保证但性能不如蒙特卡洛方法，后者缺乏理论保证。

Method: 将时序差分和蒙特卡洛方法结合，使用多步蒙特卡洛回报拟合拟度量距离，形成实用的GCRL方法。

Result: 在长达4000步的长视野模拟任务中优于现有GCRL方法，即使使用视觉观测。在真实机器人操作领域（Bridge设置）实现拼接功能。

Conclusion: 这是第一个能够在真实世界操作领域从未标记的离线视觉观测数据集中实现多步拼接的端到端GCRL方法。

Abstract: Learning how to reach goals in an environment is a longstanding challenge in AI, yet reasoning over long horizons remains a challenge for modern methods. The key question is how to estimate the temporal distance between pairs of observations. While temporal difference methods leverage local updates to provide optimality guarantees, they often perform worse than Monte Carlo methods that perform global updates (e.g., with multi-step returns), which lack such guarantees. We show how these approaches can be integrated into a practical GCRL method that fits a quasimetric distance using a multistep Monte-Carlo return. We show our method outperforms existing GCRL methods on long-horizon simulated tasks with up to 4000 steps, even with visual observations. We also demonstrate that our method can enable stitching in the real-world robotic manipulation domain (Bridge setup). Our approach is the first end-to-end GCRL method that enables multistep stitching in this real-world manipulation domain from an unlabeled offline dataset of visual observations.

</details>


### [29] [Global Optimization on Graph-Structured Data via Gaussian Processes with Spectral Representations](https://arxiv.org/abs/2511.07734)
*Shu Hong,Yongsheng Mei,Mahdi Imani,Tian Lan*

Main category: cs.LG

TL;DR: 提出了一个可扩展的图结构全局优化框架，使用低秩谱表示从稀疏结构观测构建高斯过程代理模型，在有限数据下实现高效全局搜索和不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在优化昂贵黑盒目标方面很强大，但扩展到图结构领域仍具挑战性，因为图的离散和组合性质。现有方法要么依赖完整的图拓扑（对于大图或部分观测图不实用），要么采用增量探索（收敛缓慢）。

Method: 使用低秩谱表示从稀疏结构观测构建高斯过程代理模型，通过可学习嵌入联合推断图结构和节点表示。

Result: 在合成和真实数据集上的实验表明，与先前方法相比，该方法实现了更快的收敛和更好的优化性能。

Conclusion: 该框架为图结构优化提供了一种可扩展的解决方案，即使在有限数据下也能实现高效的全局搜索和原则性的不确定性估计。

Abstract: Bayesian optimization (BO) is a powerful framework for optimizing expensive black-box objectives, yet extending it to graph-structured domains remains challenging due to the discrete and combinatorial nature of graphs. Existing approaches often rely on either full graph topology-impractical for large or partially observed graphs-or incremental exploration, which can lead to slow convergence. We introduce a scalable framework for global optimization over graphs that employs low-rank spectral representations to build Gaussian process (GP) surrogates from sparse structural observations. The method jointly infers graph structure and node representations through learnable embeddings, enabling efficient global search and principled uncertainty estimation even with limited data. We also provide theoretical analysis establishing conditions for accurate recovery of underlying graph structure under different sampling regimes. Experiments on synthetic and real-world datasets demonstrate that our approach achieves faster convergence and improved optimization performance compared to prior methods.

</details>


### [30] [From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training](https://arxiv.org/abs/2511.07738)
*Donglai Xu,Hongzheng Yang,Yuzhi Zhao,Pingping Zhang,Jinpeng Chen,Wenao Ma,Zhijian Hou,Mengyang Wu,Xiaolei Li,Senkang Hu,Ziyi Guan,Jason Chun Lok Li,Lai Man Po*

Main category: cs.LG

TL;DR: 提出一种两阶段令牌级熵优化方法，用于增强多模态大语言模型在带噪声标签数据下的强化学习验证奖励的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中高质量标注数据稀缺且存在大量标注噪声，现有无监督方法容易过拟合错误标签，限制了GRPO中关键的奖励排序信号。

Method: 两阶段令牌级熵优化：探索阶段最大化熵以促进多样输出并防止过早收敛到噪声标签；利用阶段最小化熵以巩固知识并提升预测精度。

Result: 在Qwen2-VL-2B、Qwen2-VL-7B和Qwen2.5-VL-3B三个MLLM骨干网络上，该方法在多种噪声设置和任务中均优于现有方法。

Conclusion: 该分阶段策略通过统一和增强外部、内部和基于熵的方法，在所有测试场景中提供了一致且优越的鲁棒性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) for Multimodal Large Language Models (MLLMs) is highly dependent on high-quality labeled data, which is often scarce and prone to substantial annotation noise in real-world scenarios. Existing unsupervised RLVR methods, including pure entropy minimization, can overfit to incorrect labels and limit the crucial reward ranking signal for Group-Relative Policy Optimization (GRPO). To address these challenges and enhance noise tolerance, we propose a novel two-stage, token-level entropy optimization method for RLVR. This approach dynamically guides the model from exploration to exploitation during training. In the initial exploration phase, token-level entropy maximization promotes diverse and stochastic output generation, serving as a strong regularizer that prevents premature convergence to noisy labels and ensures sufficient intra-group variation, which enables more reliable reward gradient estimation in GRPO. As training progresses, the method transitions into the exploitation phase, where token-level entropy minimization encourages the model to produce confident and deterministic outputs, thereby consolidating acquired knowledge and refining prediction accuracy. Empirically, across three MLLM backbones - Qwen2-VL-2B, Qwen2-VL-7B, and Qwen2.5-VL-3B - spanning diverse noise settings and multiple tasks, our phased strategy consistently outperforms prior approaches by unifying and enhancing external, internal, and entropy-based methods, delivering robust and superior performance across the board.

</details>


### [31] [Schedulers for Schedule-free: Theoretically inspired hyperparameters](https://arxiv.org/abs/2511.07767)
*Yuen-Man Pun,Matthew Buchholz,Robert M. Gower*

Main category: cs.LG

TL;DR: 本文扩展了无调度方法的理论，支持任意学习率调度器，并提出了新的自适应Polyak学习率调度方法，在理论和实验中都取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的无调度方法理论只支持恒定学习率，而实际实现使用了预热调度，需要扩展理论以支持任意调度器。

Method: 扩展无调度方法的最后迭代收敛理论，允许使用任意学习率调度器，并基于凸性假设设计了新的自适应Polyak学习率调度方法。

Result: 理论证明了在wsd调度下达到最优收敛率O(1/√T)，新Polyak调度在模型蒸馏任务中表现优于多个基线方法。

Conclusion: 扩展后的无调度理论具有实际预测能力，新设计的自适应Polyak调度在理论和实践中都表现出色。

Abstract: The recently proposed schedule-free method has been shown to achieve strong performance when hyperparameter tuning is limited. The current theory for schedule-free only supports a constant learning rate, where-as the implementation used in practice uses a warm-up schedule. We show how to extend the last-iterate convergence theory of schedule-free to allow for any scheduler, and how the averaging parameter has to be updated as a function of the learning rate. We then perform experiments showing how our convergence theory has some predictive power with regards to practical executions on deep neural networks, despite that this theory relies on assuming convexity. When applied to the warmup-stable-decay (wsd) schedule, our theory shows the optimal convergence rate of $\mathcal{O}(1/\sqrt{T})$. We then use convexity to design a new adaptive Polyak learning rate schedule for schedule-free. We prove an optimal anytime last-iterate convergence for our new Polyak schedule, and show that it performs well compared to a number of baselines on a black-box model distillation task.

</details>


### [32] [Physical Consistency of Aurora's Encoder: A Quantitative Study](https://arxiv.org/abs/2511.07787)
*Benjamin Richards,Pushpa Kumar Balan*

Main category: cs.LG

TL;DR: 通过线性分类器探测Aurora天气模型编码器的潜在表示，验证其是否学习到与物理气象概念一致的特征，包括海陆边界、极端高温事件和大气不稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型天气预报模型如Aurora虽然精度高但缺乏透明度，这种'黑盒'特性阻碍了其在高风险业务环境中的应用，需要验证其内部表示是否与已知物理概念一致。

Method: 使用大规模嵌入数据集，训练线性分类器来识别三个不同概念：基本海陆边界、高影响极端温度事件和大气不稳定性。

Result: 研究提供了定量证据表明Aurora学习了物理一致的特征，但也突显了其在捕捉最罕见事件方面的局限性。

Conclusion: 这项工作强调了可解释性方法对于验证和建立对下一代AI驱动天气模型信任的关键需求。

Abstract: The high accuracy of large-scale weather forecasting models like Aurora is often accompanied by a lack of transparency, as their internal representations remain largely opaque. This "black box" nature hinders their adoption in high-stakes operational settings. In this work, we probe the physical consistency of Aurora's encoder by investigating whether its latent representations align with known physical and meteorological concepts. Using a large-scale dataset of embeddings, we train linear classifiers to identify three distinct concepts: the fundamental land-sea boundary, high-impact extreme temperature events, and atmospheric instability. Our findings provide quantitative evidence that Aurora learns physically consistent features, while also highlighting its limitations in capturing the rarest events. This work underscores the critical need for interpretability methods to validate and build trust in the next generation of Al-driven weather models.

</details>


### [33] [Analyzing Political Text at Scale with Online Tensor LDA](https://arxiv.org/abs/2511.07809)
*Sara Kangaslahti,Danny Ebanks,Jean Kossaifi,Anqi Liu,R. Michael Alvarez,Animashree Anandkumar*

Main category: cs.LG

TL;DR: 提出了一种可扩展到数十亿文档的主题建模方法TLDA，具有参数可识别性和样本复杂度保证，计算效率比现有并行LDA方法快3-4倍，并提供了GPU实现。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法难以扩展到海量文本数据，限制了社会科学研究者分析大规模语料库的能力。

Method: 提出了Tensor Latent Dirichlet Allocation (TLDA)方法，利用张量分解技术确保参数可识别性和恢复性，并设计了GPU加速实现。

Result: 该方法在包含超过10亿文档的数据集上线性扩展，成功应用于分析#MeToo运动演变和2020年总统选举欺诈讨论两个大规模研究。

Conclusion: TLDA为社会科学研究者提供了在近实时条件下研究超大规模语料库并回答重要理论问题的能力。

Abstract: This paper proposes a topic modeling method that scales linearly to billions of documents. We make three core contributions: i) we present a topic modeling method, Tensor Latent Dirichlet Allocation (TLDA), that has identifiable and recoverable parameter guarantees and sample complexity guarantees for large data; ii) we show that this method is computationally and memory efficient (achieving speeds over 3-4x those of prior parallelized Latent Dirichlet Allocation (LDA) methods), and that it scales linearly to text datasets with over a billion documents; iii) we provide an open-source, GPU-based implementation, of this method. This scaling enables previously prohibitive analyses, and we perform two real-world, large-scale new studies of interest to political scientists: we provide the first thorough analysis of the evolution of the #MeToo movement through the lens of over two years of Twitter conversation and a detailed study of social media conversations about election fraud in the 2020 presidential election. Thus this method provides social scientists with the ability to study very large corpora at scale and to answer important theoretically-relevant questions about salient issues in near real-time.

</details>


### [34] [Multi-Objective Bilevel Learning](https://arxiv.org/abs/2511.07824)
*Zhiyao Zhang,Zhuqing Liu,Xin Zhang,Wen-Yen Chen,Jiyan Yang,Jia Liu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的多目标双层学习算法框架WC-MHGD，用于解决具有偏好引导的多目标双层优化问题，在确定性和随机设置下都具有有限时间收敛保证。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习应用日益复杂，现代ML框架需要处理不同层级间具有耦合决策变量的多个潜在冲突目标，这产生了对多目标双层学习(MOBL)的需求。目前该领域仍处于起步阶段，许多重要问题尚未充分探索。

Method: 提出了加权切比雪夫多超梯度下降(WC-MHGD)算法框架，该框架能够识别偏好引导的帕累托平稳解，并支持系统的帕累托前沿探索。

Result: 在确定性和随机设置下都获得了有限时间帕累托平稳性收敛率保证，这意味着低oracle复杂度并能诱导系统的帕累托前沿探索。通过大量实验验证了理论结果。

Conclusion: WC-MHGD框架为多目标双层学习提供了有效的理论算法基础，能够高效解决具有偏好引导的多目标双层优化问题。

Abstract: As machine learning (ML) applications grow increasingly complex in recent years, modern ML frameworks often need to address multiple potentially conflicting objectives with coupled decision variables across different layers. This creates a compelling need for multi-objective bilevel learning (MOBL). So far, however, the field of MOBL remains in its infancy and many important problems remain under-explored. This motivates us to fill this gap and systematically investigate the theoretical and algorithmic foundation of MOBL. Specifically, we consider MOBL problems with multiple conflicting objectives guided by preferences at the upper-level subproblem, where part of the inputs depend on the optimal solution of the lower-level subproblem. Our goal is to develop efficient MOBL optimization algorithms to (1) identify a preference-guided Pareto-stationary solution with low oracle complexity; and (2) enable systematic Pareto front exploration. To this end, we propose a unifying algorithmic framework called weighted-Chebyshev multi-hyper-gradient-descent (WC-MHGD) for both deterministic and stochastic settings with finite-time Pareto-stationarity convergence rate guarantees, which not only implies low oracle complexity but also induces systematic Pareto front exploration. We further conduct extensive experiments to confirm our theoretical results.

</details>


### [35] [MURPHY: Multi-Turn GRPO for Self Correcting Code Generation](https://arxiv.org/abs/2511.07833)
*Chanakya Ekbote,Vijay Lingam,Behrooz Omidvar-Tehrani,Jun Huan,Sujay Sanghavi,Anoop Deoras,Stefano Soatto*

Main category: cs.LG

TL;DR: Murphy是一个多轮反思优化框架，通过结合迭代自我修正来扩展GRPO，在代码生成基准测试中相比GRPO实现了最高8%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法如GRPO在推理基准测试中有效，但在需要迭代决策的代理任务中表现不佳，因此需要开发能够进行多轮自我修正的框架。

Method: 通过结合定量和定性执行反馈，Murphy在训练过程中引入迭代自我修正，使模型能够在多轮中逐步优化其推理过程。

Result: 在Qwen和OLMo等模型家族的代码生成基准测试中，Murphy持续提升性能，在相似计算预算下相比GRPO实现了最高8%的相对pass@1增益。

Conclusion: Murphy框架通过多轮反思优化有效提升了LLM在代理任务中的推理能力，证明了迭代自我修正策略的价值。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful framework for enhancing the reasoning capabilities of large language models (LLMs). However, existing approaches such as Group Relative Policy Optimization (GRPO) and its variants, while effective on reasoning benchmarks, struggle with agentic tasks that require iterative decision-making. We introduce Murphy, a multi-turn reflective optimization framework that extends GRPO by incorporating iterative self-correction during training. By leveraging both quantitative and qualitative execution feedback, Murphy enables models to progressively refine their reasoning across multiple turns. Evaluations on code generation benchmarks with model families such as Qwen and OLMo show that Murphy consistently improves performance, achieving up to a 8% relative gain in pass@1 over GRPO, on similar compute budgets.

</details>


### [36] [DP-AdamW: Investigating Decoupled Weight Decay and Bias Correction in Private Deep Learning](https://arxiv.org/abs/2511.07843)
*Jay Chooi,Kevin Cong,Russell Li,Lillian Sun*

Main category: cs.LG

TL;DR: 提出了DP-AdamW-BC，一种带有差分隐私偏差校正的AdamW优化器变体，在多个任务上优于现有DP优化器，但偏差校正反而降低了性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习使用敏感数据时需保护隐私，差分隐私提供形式化保证，但现有DP优化器性能仍有提升空间。

Method: 开发了DP-AdamW及其偏差校正版本DP-AdamW-BC，提供隐私和收敛理论保证，并在不同隐私预算下进行实证分析。

Result: DP-AdamW在文本分类上比现有DP优化器高15%以上，图像分类高5%，图节点分类高1%；但偏差校正反而降低了准确率。

Conclusion: DP-AdamW是有效的DP优化器，但偏差校正在该设置下不适用，与DP-AdamBC的改进效果相反。

Abstract: As deep learning methods increasingly utilize sensitive data on a widespread scale, differential privacy (DP) offers formal guarantees to protect against information leakage during model training. A significant challenge remains in implementing DP optimizers that retain strong performance while preserving privacy. Recent advances introduced ever more efficient optimizers, with AdamW being a popular choice for training deep learning models because of strong empirical performance. We study \emph{DP-AdamW} and introduce \emph{DP-AdamW-BC}, a differentially private variant of the AdamW optimizer with DP bias correction for the second moment estimator. We start by showing theoretical results for privacy and convergence guarantees of DP-AdamW and DP-AdamW-BC. Then, we empirically analyze the behavior of both optimizers across multiple privacy budgets ($ε= 1, 3, 7$). We find that DP-AdamW outperforms existing state-of-the-art differentially private optimizers like DP-SGD, DP-Adam, and DP-AdamBC, scoring over 15\% higher on text classification, up to 5\% higher on image classification, and consistently 1\% higher on graph node classification. Moreover, we empirically show that incorporating bias correction in DP-AdamW (DP-AdamW-BC) consistently decreases accuracy, in contrast to the improvement of DP-AdamBC improvement over DP-Adam.

</details>


### [37] [A General Method for Proving Networks Universal Approximation Property](https://arxiv.org/abs/2511.07857)
*Wei Wang*

Main category: cs.LG

TL;DR: 提出一个通用模块化框架来证明神经网络的通用逼近性质，通过定义通用逼近模块(UAM)来统一分析不同架构的逼近能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每种新架构单独构造证明，存在冗余且缺乏统一理论基础，阻碍了对不同网络家族的统一理论理解。

Method: 定义具有通用逼近性质的基本构建块为UAM，证明由这些模块组成的任何深度网络都保持通用逼近性质，并将逼近过程解释为跨模块的渐进细化。

Result: 建立了一个统一的分析框架，能够证明多种网络架构的通用逼近性质，避免了为每个新架构重新构造证明的冗余工作。

Conclusion: 该模块化框架不仅统一了对不同架构的分析，还使得能够逐步理解表达能力在网络中的演化过程。

Abstract: Deep learning architectures are highly diverse. To prove their universal approximation properties, existing works typically rely on model-specific proofs. Generally, they construct a dedicated mathematical formulation for each architecture (e.g., fully connected networks, CNNs, or Transformers) and then prove their universal approximability. However, this approach suffers from two major limitations: first, every newly proposed architecture often requires a completely new proof from scratch; second, these proofs are largely isolated from one another, lacking a common analytical foundation. This not only incurs significant redundancy but also hinders unified theoretical understanding across different network families. To address these issues, this paper proposes a general and modular framework for proving universal approximation. We define a basic building block (comprising one or multiple layers) that possesses the universal approximation property as a Universal Approximation Module (UAM). Under this condition, we show that any deep network composed of such modules inherently retains the universal approximation property. Moreover, the overall approximation process can be interpreted as a progressive refinement across modules. This perspective not only unifies the analysis of diverse architectures but also enables a step-by-step understanding of how expressive power evolves through the network.

</details>


### [38] [Algorithm-Relative Trajectory Valuation in Policy Gradient Control](https://arxiv.org/abs/2511.07878)
*Shihao Li,Jiachen Li,Jiamin Xu,Christopher Martin,Wei Li,Dongmei Chen*

Main category: cs.LG

TL;DR: 该论文研究了策略梯度控制中轨迹价值如何依赖于学习算法，发现在不确定LQR中轨迹Shapley值与持续激励(PE)呈负相关，但通过稳定化处理后相关性转为正。


<details>
  <summary>Details</summary>
Motivation: 探索轨迹价值与学习算法之间的关系，特别是持续激励对轨迹边际价值的影响机制。

Method: 使用轨迹Shapley分析不确定LQR系统，通过理论证明和实验验证方差调节机制，比较不同算法下的相关性变化。

Result: 发现REINFORCE算法中PE与边际价值负相关(r≈-0.38)，稳定化后转为正相关(r≈+0.29)；验证了方差调节机制并展示了不同评分方法的互补性。

Conclusion: 轨迹价值是算法相关的，决策对齐评分与Shapley值在剪枝和识别有害子集方面具有互补作用。

Abstract: We study how trajectory value depends on the learning algorithm in policy-gradient control. Using Trajectory Shapley in an uncertain LQR, we find a negative correlation between Persistence of Excitation (PE) and marginal value under vanilla REINFORCE ($r\approx-0.38$). We prove a variance-mediated mechanism: (i) for fixed energy, higher PE yields lower gradient variance; (ii) near saddles, higher variance increases escape probability, raising marginal contribution. When stabilized (state whitening or Fisher preconditioning), this variance channel is neutralized and information content dominates, flipping the correlation positive ($r\approx+0.29$). Hence, trajectory value is algorithm-relative. Experiments validate the mechanism and show decision-aligned scores (Leave-One-Out) complement Shapley for pruning, while Shapley identifies toxic subsets.

</details>


### [39] [Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding](https://arxiv.org/abs/2511.07884)
*Si-Hyun Kim,Heon-Gyu Kwak,Byoung-Hee Kwon,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 提出了一种用于四类运动想象分类的分层和元认知解码框架，通过多尺度分层信号处理模块和自省不确定性估计模块，提高了EEG信号解码的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于运动想象的脑机接口在实际部署中受到EEG信号噪声和变异性的限制，需要提高解码的可靠性和对受试者异质性的鲁棒性。

Method: 使用多尺度分层信号处理模块将骨干特征重组为时间多尺度表示，结合自省不确定性估计模块分配每个周期的可靠性分数并指导迭代优化。在三个标准EEG骨干网络(EEGNet、ShallowConvNet和DeepConvNet)上实例化该框架。

Result: 在所有骨干网络上，所提出的组件都提高了平均分类准确率并减少了受试者间方差，表明对受试者异质性和噪声试验的鲁棒性增强。

Conclusion: 结合分层多尺度处理与自省置信度估计可以增强基于运动想象的脑机接口系统的可靠性。

Abstract: Brain-computer interface (BCI) aims to decode motor intent from noninvasive neural signals to enable control of external devices, but practical deployment remains limited by noise and variability in motor imagery (MI)-based electroencephalogram (EEG) signals. This work investigates a hierarchical and meta-cognitive decoding framework for four-class MI classification. We introduce a multi-scale hierarchical signal processing module that reorganizes backbone features into temporal multi-scale representations, together with an introspective uncertainty estimation module that assigns per-cycle reliability scores and guides iterative refinement. We instantiate this framework on three standard EEG backbones (EEGNet, ShallowConvNet, and DeepConvNet) and evaluate four-class MI decoding using the BCI Competition IV-2a dataset under a subject-independent setting. Across all backbones, the proposed components improve average classification accuracy and reduce inter-subject variance compared to the corresponding baselines, indicating increased robustness to subject heterogeneity and noisy trials. These results suggest that combining hierarchical multi-scale processing with introspective confidence estimation can enhance the reliability of MI-based BCI systems.

</details>


### [40] [A Generalized Spectral Framework to Expain Neural Scaling and Compression Dynamics](https://arxiv.org/abs/2511.07892)
*Yizhou Zhang*

Main category: cs.LG

TL;DR: 本文提出了一个广义谱框架，统一了学习动态和压缩现象，通过推广谱演化函数为渐近多项式形式，并引入了有效谱-时间弹性参数。


<details>
  <summary>Details</summary>
Motivation: 现有的经验缩放定律在特定体系内一致，但在模型压缩等相关设置中表现出明显不同的缩放行为。受神经表示谱分析进展的启发，需要开发一个统一框架来整合这些现象。

Method: 开发了一个广义谱框架，将谱演化函数从线性核形式推广到渐近多项式函数，并引入有效谱-时间弹性参数来表征学习动态。

Result: 该框架恢复了现有的惰性学习和特征学习理论作为特例，并得出了学习与压缩之间的不变关系。

Conclusion: 提出的广义谱框架成功统一了学习动态和压缩现象，为理解不同缩放行为提供了理论基础。

Abstract: Empirical scaling laws describe how test loss and other performance metrics depend on model size, dataset size, and compute. While such laws are consistent within specific regimes, apparently distinct scaling behaviors have been reported for related settings such as model compression. Motivated by recent progress in spectral analyses of neural representations, this paper develops a \emph{generalized spectral framework} that unifies learning dynamics and compression phenomena under a common functional ansatz. We generalize the spectral evolution function from the linear kernel form $g(λt)=λt$ to an asymptotically polynomial function $g(λ,t;β)$, characterized by an effective spectral--temporal elasticity $ρ(β)$. This framework recovers existing lazy and feature-learning theories as special cases and yields an invariant relation between learning and compression

</details>


### [41] [Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction](https://arxiv.org/abs/2511.07899)
*Ihab Tabbara,Yuxuan Yang,Hussein Sibai*

Main category: cs.LG

TL;DR: 本文提出了一种基于共形预测的框架，为学习型Hamilton-Jacobi可达性分析提供概率安全保证，通过校准不安全标称控制器与学习的安全策略之间的切换来防止控制系统到达故障状态。


<details>
  <summary>Details</summary>
Motivation: Hamilton-Jacobi可达性分析虽然能形式化验证安全性，但计算HJ值函数计算成本高，特别是高维系统。使用强化学习近似值函数时，学习到的值函数和策略无法保证正确性，存在不确定性。

Method: 引入基于共形预测的框架来量化不确定性，使用CP校准不安全标称控制器与学习的安全策略之间的切换，并研究使用独立训练的HJ值函数集成作为安全过滤器。

Result: 该框架能够为使用学习型HJ值函数和策略提供概率安全保证，防止控制系统到达故障状态。

Conclusion: 基于共形预测的框架有效解决了学习型HJ可达性分析中的不确定性挑战，为自主系统的安全部署提供了可靠保障。

Abstract: Safety assurance is a fundamental requirement for deploying learning-enabled autonomous systems. Hamilton-Jacobi (HJ) reachability analysis is a fundamental method for formally verifying safety and generating safe controllers. However, computing the HJ value function that characterizes the backward reachable set (BRS) of a set of user-defined failure states is computationally expensive, especially for high-dimensional systems, motivating the use of reinforcement learning approaches to approximate the value function. Unfortunately, a learned value function and its corresponding safe policy are not guaranteed to be correct. The learned value function evaluated at a given state may not be equal to the actual safety return achieved by following the learned safe policy. To address this challenge, we introduce a conformal prediction-based (CP) framework that bounds such uncertainty. We leverage CP to provide probabilistic safety guarantees when using learned HJ value functions and policies to prevent control systems from reaching failure states. Specifically, we use CP to calibrate the switching between the unsafe nominal controller and the learned HJ-based safe policy and to derive safety guarantees under this switched policy. We also investigate using an ensemble of independently trained HJ value functions as a safety filter and compare this ensemble approach to using individual value functions alone.

</details>


### [42] [Test-driven Reinforcement Learning](https://arxiv.org/abs/2511.07904)
*Zhao Yu,Xiuping Wu,Liangjun Ke*

Main category: cs.LG

TL;DR: 提出了测试驱动的强化学习框架，用多个测试函数替代单一奖励函数来定义任务目标，简化了任务设计并支持多目标优化


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中的奖励函数需要同时定义最优目标和指导学习过程，手动设计困难且容易导致次优任务表示

Method: 使用通过-失败测试和指示性测试分别定义最优目标和指导学习过程，提出基于轨迹返回函数的策略优化方法，并开发了词典序启发式方法来学习轨迹返回函数

Result: 在DeepMind Control Suite基准测试中，TdRL方法在策略训练上达到或超过了手工设计奖励方法的表现，具有更简单的设计过程和固有的多目标优化支持

Conclusion: TdRL为表示任务目标提供了新的视角，有助于解决强化学习应用中的奖励设计挑战

Abstract: Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.

</details>


### [43] [CellARC: Measuring Intelligence with Cellular Automata](https://arxiv.org/abs/2511.07908)
*Miroslav Lžičař*

Main category: cs.LG

TL;DR: CellARC是一个基于多色一维元胞自动机的抽象推理合成基准，包含95k训练集和2k测试集，支持可控难度采样，用于研究模型在有限资源下快速推断新规则的能力。


<details>
  <summary>Details</summary>
Motivation: 创建可控制任务空间、解耦泛化与人类先验、支持无限难度控制采样的基准，以便可重复研究模型如何快速推断新规则。

Method: 使用多色一维元胞自动机构建基准，每个任务包含5个支持对和1个查询，序列化为256个token，可控制字母表大小、半径、规则族等参数。

Result: 10M参数的普通Transformer在插值/外推测试集上达到58.0%/32.4%的准确率，优于递归模型；GPT-5 High在100个测试任务子集上达到62.3%/48.1%；Transformer与符号基线的集成达到65.4%/35.5%。

Conclusion: CellARC为研究模型推理能力提供了可扩展的基准，展示了神经符号方法的互补性，小模型也能在有限资源下有效学习新规则。

Abstract: We introduce CellARC, a synthetic benchmark for abstraction and reasoning built from multicolor 1D cellular automata (CA). Each episode has five support pairs and one query serialized in 256 tokens, enabling rapid iteration with small models while exposing a controllable task space with explicit knobs for alphabet size k, radius r, rule family, Langton's lambda, query coverage, and cell entropy. We release 95k training episodes plus two 1k test splits (interpolation/extrapolation) and evaluate symbolic, recurrent, convolutional, transformer, recursive, and LLM baselines. CellARC decouples generalization from anthropomorphic priors, supports unlimited difficulty-controlled sampling, and enables reproducible studies of how quickly models infer new rules under tight budgets. Our strongest small-model baseline (a 10M-parameter vanilla transformer) outperforms recent recursive models (TRM, HRM), reaching 58.0%/32.4% per-token accuracy on the interpolation/extrapolation splits, while a large closed model (GPT-5 High) attains 62.3%/48.1% on subsets of 100 test tasks. An ensemble that chooses per episode between the Transformer and the best symbolic baseline reaches 65.4%/35.5%, highlighting neuro-symbolic complementarity. Leaderboard: https://cellarc.mireklzicar.com

</details>


### [44] [Rectified Noise: A Generative Model Using Positive-incentive Noise](https://arxiv.org/abs/2511.07911)
*Zhenyu Gu,Yanchen Xu,Sida Huang,Yubin Guo,Hongyuan Zhang*

Main category: cs.LG

TL;DR: 提出Rectified Noise (ΔRN)方法，通过在预训练Rectified Flow模型的速度场中注入π噪声，仅需0.39%额外参数就能显著提升生成性能，在ImageNet-1k上将FID从10.16降至9.05。


<details>
  <summary>Details</summary>
Motivation: 虽然Rectified Flow主要基于概率流ODE，但研究发现通过反向时间SDE注入噪声可以提升生成性能。受Positive-incentive Noise (π-noise)启发，希望开发一种能有效训练π噪声生成器的方法。

Method: 提出Rectified Noise (ΔRN)算法，在预训练RF模型的速度场中注入π噪声，将RF模型高效转化为π噪声生成器。

Result: 在多种模型架构和数据集上的实验验证：RF模型使用Rectified Noise后，在ImageNet-1k上将FID从10.16降至9.05；π噪声生成器仅需0.39%额外训练参数就能实现性能提升。

Conclusion: Rectified Noise是一种有效的生成算法，能够显著提升Rectified Flow模型的生成性能，且参数效率很高。

Abstract: Rectified Flow (RF) has been widely used as an effective generative model. Although RF is primarily based on probability flow Ordinary Differential Equations (ODE), recent studies have shown that injecting noise through reverse-time Stochastic Differential Equations (SDE) for sampling can achieve superior generative performance. Inspired by Positive-incentive Noise ($π$-noise), we propose an innovative generative algorithm to train $π$-noise generators, namely Rectified Noise ($Δ$RN), which improves the generative performance by injecting $π$-noise into the velocity field of pre-trained RF models. After introducing the Rectified Noise pipeline, pre-trained RF models can be efficiently transformed into $π$-noise generators. We validate Rectified Noise by conducting extensive experiments across various model architectures on different datasets. Notably, we find that: (1) RF models using Rectified Noise reduce FID from \textbf{10.16 to 9.05} on ImageNet-1k. (2) The models of $π$-noise generators achieve improved performance with only \textbf{0.39\%} additional training parameters.

</details>


### [45] [Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison](https://arxiv.org/abs/2511.07919)
*Yoonho Lee,Joseph Boen,Chelsea Finn*

Main category: cs.LG

TL;DR: Feedback Descent是一个通过结构化文本反馈优化文本产物的框架，相比传统依赖标量奖励的方法，它通过保留详细批评而非压缩为二元偏好来拓宽信息瓶颈，实现文本空间的定向优化。


<details>
  <summary>Details</summary>
Motivation: 传统偏好学习将复杂判断压缩为单一比特信息，造成信息瓶颈。作者希望通过保留结构化文本反馈来提供高带宽监督，实现更有效的文本产物优化。

Method: 利用上下文学习将结构化反馈转化为类似梯度的方向信息，实现针对性编辑。评估器为每个比较提供文本反馈，整个迭代过程在推理时完成，无需修改模型权重。

Result: 在三个不同领域评估中，Feedback Descent优于最先进的提示优化方法、强化学习方法以及专门的基于图的分子优化器。在DOCKSTRING分子发现基准测试中，发现了超过99.9百分位的新型类药物分子。

Conclusion: Feedback Descent通过结构化文本反馈实现了有效的文本产物优化，在多个领域超越了现有方法，展示了高带宽监督在优化任务中的优势。

Abstract: We introduce \textit{Feedback Descent}, a framework that optimizes text artifacts -- prompts, code, and molecules -- through structured textual feedback, rather than relying solely on scalar rewards. By preserving detailed critiques instead of compressing them to binary preferences, Feedback Descent widens the information bottleneck in preference learning, enabling directed optimization in text space rather than weight space. We show that in-context learning can transform structured feedback into gradient-like directional information, enabling targeted edits. Unlike prior approaches that collapse judgments into single bits, our evaluators pair each comparison with textual feedback, which functions as high-bandwidth supervision. The iteration loop is done purely at inference time, without modifying any model weights, and is task-agnostic. We evaluate Feedback Descent on three diverse domains and find that it outperforms state-of-the-art prompt optimization (GEPA), reinforcement learning methods (GRPO, REINVENT), and even specialized graph-based molecular optimizers. In the DOCKSTRING molecule discovery benchmark, Feedback Descent identifies novel drug-like molecules surpassing the $99.9$th percentile of a database with more than $260{,}000$ compounds across six protein targets.

</details>


### [46] [SERL: Self-Examining Reinforcement Learning on Open-Domain](https://arxiv.org/abs/2511.07922)
*Weixuan Ou,Yanzhao Zheng,Shuoshuo Sun,Wei Zhang,Baohua Dong,Hangcheng Zhu,Ruohui Huang,Gang Yu,Pengwei Yan,Yifan Qiao*

Main category: cs.LG

TL;DR: 提出SERL框架，让大语言模型同时扮演行动者和评判者角色，通过两种内部奖励机制实现自我改进，无需外部信号。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在开放域任务中的两个关键挑战：主观性任务无法提供可验证奖励，以及RLHF依赖外部奖励机制。

Method: SERL框架包含两个协同的奖励机制：基于Copeland风格成对比较的行动者能力提升奖励，和鼓励一致判断的评判者可靠性提升奖励。

Result: 在AlpacaEval 2上，Qwen3-8B的LC胜率从52.37%提升至59.90%，达到自改进方法中的最先进水平，性能可与更大的Qwen3-32B模型相媲美。

Conclusion: SERL框架在开放域任务上展现出卓越的有效性和鲁棒性，为语言模型的自我改进提供了新的有效途径。

Abstract: Reinforcement Learning (RL) has been shown to improve the capabilities of large language models (LLMs). However, applying RL to open-domain tasks faces two key challenges: (1) the inherent subjectivity of these tasks prevents the verifiable rewards as required by Reinforcement Learning with Verifiable Rewards (RLVR); (2) Reinforcement Learning from Human Feedback (RLHF) relies on external reward mechanisms. To overcome these limitations, we propose Self-Examining Reinforcement Learning (SERL), a novel self-improving framework where the LLM serves as both Actor and Judge. SERL introduces two synergistic reward mechanisms without any external signals. On the one hand, to improve the Actor's capability, we derive rewards from Copeland-style pairwise comparison judgments across a group of generated responses. On the other hand, a self-consistency reward that encourages coherent judgments is proposed to improve the Judge's reliability. This process refines the Judge's capability, which in turn provides a more robust reward for Actor. Experiments show that our method outperforms existing self-improvement training methods. SERL improves the LC win rate of Qwen3-8B on AlpacaEval 2 from 52.37% to 59.90%. To the best of our knowledge, our method achieves state-of-the-art performance among self-improving approaches. Furthermore, it achieves a performance comparable to significantly larger models like Qwen3-32B, demonstrating superior effectiveness and robustness on open-domain tasks.

</details>


### [47] [IBMA: An Imputation-Based Mixup Augmentation Using Self-Supervised Learning for Time Series Data](https://arxiv.org/abs/2511.07930)
*Dang Nha Nguyen,Hai Dang Nguyen,Khoa Tho Anh Nguyen*

Main category: cs.LG

TL;DR: 提出了一种基于插值的Mixup数据增强方法(IBMA)，结合插值增强数据和Mixup增强，在时间序列预测中提升模型泛化能力和性能表现。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中的数据增强策略相对较少，特别是像Mixup这样的高级技术很少被使用，需要开发新的增强方法来提升模型性能。

Method: IBMA方法将插值增强数据与Mixup增强相结合，在多个预测模型(DLinear、TimesNet、iTrainformer)上进行评估，并与8种其他增强技术进行比较。

Result: 在4个数据集(ETTh1、ETTh2、ETTm1、ETTm2)上的实验表明，IBMA在24个实例中22次提升了性能，其中10次达到最佳表现，特别是与iTrainformer插值结合时效果最好。

Conclusion: IBMA方法能有效提升时间序列预测模型的性能，特别是在与iTrainformer插值结合时表现最优，为时间序列数据增强提供了新的有效策略。

Abstract: Data augmentation in time series forecasting plays a crucial role in enhancing model performance by introducing variability while maintaining the underlying temporal patterns. However, time series data offers fewer augmentation strategies compared to fields such as image or text, with advanced techniques like Mixup rarely being used. In this work, we propose a novel approach, Imputation-Based Mixup Augmentation (IBMA), which combines Imputation-Augmented data with Mixup augmentation to bolster model generalization and improve forecasting performance. We evaluate the effectiveness of this method across several forecasting models, including DLinear (MLP), TimesNet (CNN), and iTrainformer (Transformer), these models represent some of the most recent advances in time series forecasting. Our experiments, conducted on four datasets (ETTh1, ETTh2, ETTm1, ETTm2) and compared against eight other augmentation techniques, demonstrate that IBMA consistently enhances performance, achieving 22 improvements out of 24 instances, with 10 of those being the best performances, particularly with iTrainformer imputation.

</details>


### [48] [Predict-then-Optimize Method for Seaport Power-Logistics Scheduling: Generalization across Varying Tasks Stream](https://arxiv.org/abs/2511.07938)
*Chuanqing Pu,Feilong Fan,Nengling Tai,Yan Xu,Wentao Huang,Honglin Wen*

Main category: cs.LG

TL;DR: 提出了一种决策导向的持续学习框架，用于适应不断变化的港口船舶到达调度任务，通过Fisher信息正则化保持对先前任务的关键参数，并开发可微分凸代理来稳定梯度反向传播。


<details>
  <summary>Details</summary>
Motivation: 传统的预测-优化管道假设下游优化任务配置固定，无法很好地适应由变化港口船舶到达引起的任务结构演变。

Method: 使用基于Fisher信息的正则化来增强跨任务泛化能力，保留对先前任务关键的参数；开发可微分凸代理来稳定梯度反向传播。

Result: 在裕廊港校准的实验显示，该方法在决策性能和泛化能力上优于现有方法，且计算成本更低。

Conclusion: 所提出的方法能够为新的调度任务学习决策对齐的预测模型，同时保持对早期任务的泛化能力。

Abstract: Power-logistics scheduling in modern seaports typically follow a predict-then-optimize pipeline. To enhance decision quality, decision-focused learning has been proposed to align forecasting and optimization via end-to-end training. However, most formulations assume a fixed task configuration in downstream optimization, and thus generalize poorly to evolving task structures induced by varying seaport vessel arrivals. We address this gap with a decision-focused continual learning framework that adapts online to a stream of scheduling tasks. Specifically, we introduce Fisher information based regularization to enhance cross-task generalization by preserving parameters critical to prior tasks. A differentiable convex surrogate is also developed to stabilize gradient backpropagation. The proposed approach enables learning a decision-aligned forecasting model for new scheduling tasks while retaining generalization on earlier tasks. Experiments calibrated to the Jurong Port demonstrate superior decision performance and generalization over existing methods with reduced computational cost.

</details>


### [49] [Balance Equation-based Distributionally Robust Offline Imitation Learning](https://arxiv.org/abs/2511.07942)
*Rishabh Agrawal,Yusuf Alvi,Rahul Jain,Ashutosh Nayyar*

Main category: cs.LG

TL;DR: 提出基于平衡方程的分布鲁棒离线模仿学习框架，仅使用名义动态下的专家演示数据学习鲁棒策略，无需额外环境交互，在动态变化的环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习方法假设训练和部署时的环境动态保持不变，但实际中建模误差、参数变化和对抗扰动会导致动态偏移，造成性能严重下降。

Method: 将问题建模为在转移模型不确定性集上的分布鲁棒优化，寻找在最坏情况转移分布下最小化模仿损失的策略，并证明该鲁棒目标可完全用名义数据分布表示。

Result: 在连续控制基准测试中，该方法在扰动或偏移环境下相比最先进的离线模仿学习基线表现出更优的鲁棒性和泛化能力。

Conclusion: 所提出的框架能够仅从名义动态下的专家演示中学习鲁棒策略，有效应对环境动态变化带来的挑战。

Abstract: Imitation Learning (IL) has proven highly effective for robotic and control tasks where manually designing reward functions or explicit controllers is infeasible. However, standard IL methods implicitly assume that the environment dynamics remain fixed between training and deployment. In practice, this assumption rarely holds where modeling inaccuracies, real-world parameter variations, and adversarial perturbations can all induce shifts in transition dynamics, leading to severe performance degradation. We address this challenge through Balance Equation-based Distributionally Robust Offline Imitation Learning, a framework that learns robust policies solely from expert demonstrations collected under nominal dynamics, without requiring further environment interaction. We formulate the problem as a distributionally robust optimization over an uncertainty set of transition models, seeking a policy that minimizes the imitation loss under the worst-case transition distribution. Importantly, we show that this robust objective can be reformulated entirely in terms of the nominal data distribution, enabling tractable offline learning. Empirical evaluations on continuous-control benchmarks demonstrate that our approach achieves superior robustness and generalization compared to state-of-the-art offline IL baselines, particularly under perturbed or shifted environments.

</details>


### [50] [Continual Unlearning for Text-to-Image Diffusion Models: A Regularization Perspective](https://arxiv.org/abs/2511.07970)
*Justin Lee,Zheda Mai,Jinsu Yoo,Chongyu Fan,Cheng Zhang,Wei-Lun Chao*

Main category: cs.LG

TL;DR: 本文首次系统研究了文本到图像扩散模型中的持续遗忘问题，发现现有遗忘方法在连续请求下会导致模型性能快速退化，并提出基于正则化和梯度投影的解决方案来缓解参数漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法通常假设遗忘请求一次性到达，而实际应用中请求往往是连续到达的。本文旨在解决文本到图像扩散模型中持续遗忘的挑战，防止模型在连续遗忘过程中出现效用崩溃。

Method: 研究了一套附加正则化器来缓解参数漂移，并提出梯度投影方法约束参数在与目标子空间正交方向上的漂移。这些方法与现有遗忘方法兼容，并特别关注语义感知以保护接近遗忘目标的概念。

Result: 研究表明现有遗忘方法在连续请求下会导致快速效用崩溃，而提出的正则化和梯度投影方法显著改善了持续遗忘性能，特别是梯度投影方法与其他正则化器结合能获得进一步增益。

Conclusion: 本文确立了持续遗忘作为文本到图像生成中的基本挑战，为推进安全可靠的生成AI提供了见解、基准和开放方向。

Abstract: Machine unlearning--the ability to remove designated concepts from a pre-trained model--has advanced rapidly, particularly for text-to-image diffusion models. However, existing methods typically assume that unlearning requests arrive all at once, whereas in practice they often arrive sequentially. We present the first systematic study of continual unlearning in text-to-image diffusion models and show that popular unlearning methods suffer from rapid utility collapse: after only a few requests, models forget retained knowledge and generate degraded images. We trace this failure to cumulative parameter drift from the pre-training weights and argue that regularization is crucial to addressing it. To this end, we study a suite of add-on regularizers that (1) mitigate drift and (2) remain compatible with existing unlearning methods. Beyond generic regularizers, we show that semantic awareness is essential for preserving concepts close to the unlearning target, and propose a gradient-projection method that constrains parameter drift orthogonal to their subspace. This substantially improves continual unlearning performance and is complementary to other regularizers for further gains. Taken together, our study establishes continual unlearning as a fundamental challenge in text-to-image generation and provides insights, baselines, and open directions for advancing safe and accountable generative AI.

</details>


### [51] [Low-Rank Curvature for Zeroth-Order Optimization in LLM Fine-Tuning](https://arxiv.org/abs/2511.07971)
*Hyunseok Seung,Jaewoo Lee,Hyunsuk Ko*

Main category: cs.LG

TL;DR: LOREN是一种曲率感知的零阶优化方法，通过自适应估计各向异性扰动分布、使用自然进化策略框架捕获曲率、应用REINFORCE留一法梯度估计器来减少方差，在LLM微调中实现了更高的准确性和更快的收敛。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶方法通过随机扰动的有限差分来估计梯度，通常存在高方差和次优搜索方向的问题，需要改进梯度估计的质量和效率。

Method: 1) 将梯度预处理问题重新表述为自适应估计各向异性扰动分布；2) 使用自然进化策略框架通过低秩块对角预处理器捕获曲率；3) 应用REINFORCE留一法梯度估计器减少方差。

Result: 在标准LLM基准测试中，LOREN优于最先进的零阶方法，实现了更高的准确性和更快的收敛，相比MeZO-Adam峰值内存使用减少了27.3%。

Conclusion: LOREN通过曲率感知的零阶优化方法有效解决了现有方法的局限性，在LLM微调中表现出优越的性能和内存效率。

Abstract: We introduce LOREN, a curvature-aware zeroth-order (ZO) optimization method for fine-tuning large language models (LLMs). Existing ZO methods, which estimate gradients via finite differences using random perturbations, often suffer from high variance and suboptimal search directions. Our approach addresses these challenges by: (i) reformulating the problem of gradient preconditioning as that of adaptively estimating an anisotropic perturbation distribution for gradient estimation, (ii) capturing curvature through a low-rank block diagonal preconditioner using the framework of natural evolution strategies, and (iii) applying a REINFORCE leave-one-out (RLOO) gradient estimator to reduce variance. Experiments on standard LLM benchmarks show that our method outperforms state-of-the-art ZO methods by achieving higher accuracy and faster convergence, while cutting peak memory usage by up to 27.3% compared with MeZO-Adam.

</details>


### [52] [Generalizable Insights for Graph Transformers in Theory and Practice](https://arxiv.org/abs/2511.08028)
*Timo Stoll,Luis Müller,Christopher Morris*

Main category: cs.LG

TL;DR: 提出了广义距离变换器(GDT)，通过标准注意力机制整合了图变换器的多项进展，并在大规模实验中验证了其表示能力和设计选择的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前图变换器架构在注意力机制、位置嵌入和表达能力方面差异很大，现有理论结果往往与特定设计绑定，缺乏在大规模数据上的实证验证，理论与实践之间存在鸿沟。

Method: 提出GDT架构，使用标准注意力机制，整合近年图变换器的多项进展，通过大规模实验评估不同设计选择在多种应用、任务和模型规模下的表现。

Result: 在超过800万张图、约2.7亿个token的多样化领域实验中，识别出在各种应用中表现一致良好的设计选择，在少样本迁移设置中表现出色且无需微调。

Conclusion: 将理论和实践发现提炼为关于图变换器有效设计、训练和推理的多个可推广见解。

Abstract: Graph Transformers (GTs) have shown strong empirical performance, yet current architectures vary widely in their use of attention mechanisms, positional embeddings (PEs), and expressivity. Existing expressivity results are often tied to specific design choices and lack comprehensive empirical validation on large-scale data. This leaves a gap between theory and practice, preventing generalizable insights that exceed particular application domains. Here, we propose the Generalized-Distance Transformer (GDT), a GT architecture using standard attention that incorporates many advancements for GTs from recent years, and develop a fine-grained understanding of the GDT's representation power in terms of attention and PEs. Through extensive experiments, we identify design choices that consistently perform well across various applications, tasks, and model scales, demonstrating strong performance in a few-shot transfer setting without fine-tuning. Our evaluation covers over eight million graphs with roughly 270M tokens across diverse domains, including image-based object detection, molecular property prediction, code summarization, and out-of-distribution algorithmic reasoning. We distill our theoretical and practical findings into several generalizable insights about effective GT design, training, and inference.

</details>


### [53] [From Sequential to Recursive: Enhancing Decision-Focused Learning with Bidirectional Feedback](https://arxiv.org/abs/2511.08035)
*Xinyu Wang,Jinxiao Du,Yiyang Peng,Wei Ma*

Main category: cs.LG

TL;DR: 提出了递归决策聚焦学习（R-DFL）框架，通过双向反馈机制提升决策质量，相比传统顺序方法在闭环决策问题中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有顺序决策聚焦学习（S-DFL）无法捕捉预测与优化之间的双向交互，限制了在复杂场景下的决策性能。

Method: 提出R-DFL框架，引入双向反馈机制，并开发了两种微分方法：基于自动微分的显式展开和基于定点方法的隐式微分。

Result: 在报童问题和二分匹配问题上的实验表明，R-DFL显著提升了最终决策质量，并在不同场景下展现出鲁棒适应性。

Conclusion: R-DFL通过双向反馈机制有效解决了传统方法的局限性，在闭环决策问题中具有显著优势。

Abstract: Decision-focused learning (DFL) has emerged as a powerful end-to-end alternative to conventional predict-then-optimize (PTO) pipelines by directly optimizing predictive models through downstream decision losses. Existing DFL frameworks are limited by their strictly sequential structure, referred to as sequential DFL (S-DFL). However, S-DFL fails to capture the bidirectional feedback between prediction and optimization in complex interaction scenarios. In view of this, we first time propose recursive decision-focused learning (R-DFL), a novel framework that introduces bidirectional feedback between downstream optimization and upstream prediction. We further extend two distinct differentiation methods: explicit unrolling via automatic differentiation and implicit differentiation based on fixed-point methods, to facilitate efficient gradient propagation in R-DFL. We rigorously prove that both methods achieve comparable gradient accuracy, with the implicit method offering superior computational efficiency. Extensive experiments on both synthetic and real-world datasets, including the newsvendor problem and the bipartite matching problem, demonstrate that R-DFL not only substantially enhances the final decision quality over sequential baselines but also exhibits robust adaptability across diverse scenarios in closed-loop decision-making problems.

</details>


### [54] [DynaAct: Large Language Model Reasoning with Dynamic Action Spaces](https://arxiv.org/abs/2511.08043)
*Xueliang Zhao,Wei Wu,Jian Guan,Qintong Li,Lingpeng Kong*

Main category: cs.LG

TL;DR: 提出了DynaAct框架，用于自动构建紧凑的动作空间以增强复杂问题解决场景中的顺序推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖缺乏可扩展性的手动定义动作空间，要么使用非结构化空间导致穷举搜索计算成本过高。

Method: 首先通过大型语言模型从涵盖多样化复杂推理问题的语料库中提取通用草图来估计完整动作空间的代理；然后制定一个子模函数，联合评估候选动作对当前状态的效用和多样性，并使用贪心算法选择最优候选集。

Result: 在六个多样化标准基准测试上的广泛实验表明，该方法显著提高了整体性能，同时保持了高效推理而不引入显著延迟。

Conclusion: DynaAct框架能够有效构建紧凑的动作空间，提升顺序决策系统的推理效率。

Abstract: In modern sequential decision-making systems, the construction of an optimal candidate action space is critical to efficient inference. However, existing approaches either rely on manually defined action spaces that lack scalability or utilize unstructured spaces that render exhaustive search computationally prohibitive. In this paper, we propose a novel framework named \textsc{DynaAct} for automatically constructing a compact action space to enhance sequential reasoning in complex problem-solving scenarios. Our method first estimates a proxy for the complete action space by extracting general sketches observed in a corpus covering diverse complex reasoning problems using large language models. We then formulate a submodular function that jointly evaluates candidate actions based on their utility to the current state and their diversity, and employ a greedy algorithm to select an optimal candidate set. Extensive experiments on six diverse standard benchmarks demonstrate that our approach significantly improves overall performance, while maintaining efficient inference without introducing substantial latency. The implementation is available at https://github.com/zhaoxlpku/DynaAct.

</details>


### [55] [Online Linear Regression with Paid Stochastic Features](https://arxiv.org/abs/2511.08073)
*Nadav Merlis,Kyoungseok Jang,Nicolò Cesa-Bianchi*

Main category: cs.LG

TL;DR: 该论文研究在线线性回归问题，其中特征向量被噪声污染，学习者可以通过支付来降低噪声水平。当噪声协方差已知时，最优遗憾率为√T；当未知时，最优遗憾率变为T^{2/3}。


<details>
  <summary>Details</summary>
Motivation: 研究在特征向量被噪声污染的情况下，学习者可以通过支付成本来降低噪声水平，这在实践中很常见（如使用更昂贵的测量设备或激励数据提供者发布隐私性较低的特征）。

Method: 使用矩阵鞅集中性分析，证明经验损失对所有支付和线性预测器一致收敛到期望损失。

Result: 当噪声协方差映射已知时，忽略对数因子的最优遗憾率为√T；当噪声协方差未知时，最优遗憾率为T^{2/3}（忽略对数因子）。

Conclusion: 该研究为在线线性回归中噪声降低支付问题提供了理论保证，确定了不同信息设定下的最优遗憾率。

Abstract: We study an online linear regression setting in which the observed feature vectors are corrupted by noise and the learner can pay to reduce the noise level. In practice, this may happen for several reasons: for example, because features can be measured more accurately using more expensive equipment, or because data providers can be incentivized to release less private features. Assuming feature vectors are drawn i.i.d. from a fixed but unknown distribution, we measure the learner's regret against the linear predictor minimizing a notion of loss that combines the prediction error and payment. When the mapping between payments and noise covariance is known, we prove that the rate $\sqrt{T}$ is optimal for regret if logarithmic factors are ignored. When the noise covariance is unknown, we show that the optimal regret rate becomes of order $T^{2/3}$ (ignoring log factors). Our analysis leverages matrix martingale concentration, showing that the empirical loss uniformly converges to the expected one for all payments and linear predictors.

</details>


### [56] [An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models](https://arxiv.org/abs/2511.08077)
*Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding*

Main category: cs.LG

TL;DR: 提出了一种集成融合框架，将梯度提升与模糊规则模型相结合，通过动态控制因子优化模型贡献，防止过拟合并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 模糊规则模型具有良好的可解释性但面临复杂设计和大数据集扩展性问题，梯度提升能够克服这些限制，两者融合可提升模型性能和可解释性。

Method: 构建集成融合框架，在每次迭代中构建模糊规则模型，通过动态控制因子优化其贡献，并加入基于样本的校正机制进行自适应调整。

Result: 实验结果表明该框架有效提升了性能，特别是在减轻过拟合和规则复杂性方面，同时保持了模型的可解释性。

Conclusion: 该框架通过优化控制因子成功结合了梯度提升和模糊规则模型的优势，实现了性能提升、可解释性保持和模型维护简化。

Abstract: The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.

</details>


### [57] [Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing](https://arxiv.org/abs/2511.08080)
*Ziyu Fan,Zhijian Huang,Yahan Li,Xiaowen Hu,Siyuan Shen,Yunliang Wang,Zeyu Zhong,Shuhong Liu,Shuning Yang,Shangqian Wu,Min Wu,Lei Deng*

Main category: cs.LG

TL;DR: HSPAG是一个数据高效的分层结构-性质对齐框架，用于解决分子生成和编辑中的两个关键挑战：捕获分子结构与多个性质之间的复杂关系，以及在稀疏标注下提高模型有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于性质的分子生成和编辑面临两个主要障碍：(i)难以捕获分子结构与多个性质之间的复杂关系；(ii)分子性质标注覆盖范围窄且不完整，削弱了基于性质模型的有效性。

Method: 将SMILES和分子性质视为互补模态，在原子、子结构和整个分子三个层次上学习它们的关系；通过骨架聚类选择代表性样本，通过辅助变分自编码器选择困难样本，大幅减少预训练数据需求；引入性质相关性感知掩码机制和多样化扰动策略来增强稀疏标注下的生成质量。

Result: 实验证明HSPAG能够捕获细粒度的结构-性质关系，并支持在多个性质约束下的可控生成。两个真实世界案例研究进一步验证了HSPAG的编辑能力。

Conclusion: HSPAG框架通过分层结构-性质对齐和数据高效策略，成功解决了分子生成和编辑中的关键挑战，为AI驱动的药物发现提供了有效工具。

Abstract: Property-constrained molecular generation and editing are crucial in AI-driven drug discovery but remain hindered by two factors: (i) capturing the complex relationships between molecular structures and multiple properties remains challenging, and (ii) the narrow coverage and incomplete annotations of molecular properties weaken the effectiveness of property-based models. To tackle these limitations, we propose HSPAG, a data-efficient framework featuring hierarchical structure-property alignment. By treating SMILES and molecular properties as complementary modalities, the model learns their relationships at atom, substructure, and whole-molecule levels. Moreover, we select representative samples through scaffold clustering and hard samples via an auxiliary variational auto-encoder (VAE), substantially reducing the required pre-training data. In addition, we incorporate a property relevance-aware masking mechanism and diversified perturbation strategies to enhance generation quality under sparse annotations. Experiments demonstrate that HSPAG captures fine-grained structure-property relationships and supports controllable generation under multiple property constraints. Two real-world case studies further validate the editing capabilities of HSPAG.

</details>


### [58] [HipKittens: Fast and Furious AMD Kernels](https://arxiv.org/abs/2511.08083)
*William Hu,Drew Wadsworth,Sean Siddens,Stanley Winata,Daniel Y. Fu,Ryann Swann,Muhammad Osama,Christopher Ré,Simran Arora*

Main category: cs.LG

TL;DR: HipKittens (HK) 是一个针对 AMD GPU 的编程框架，将 tile-based 抽象从 NVIDIA 扩展到 AMD 平台，在 GEMM 和注意力计算中与手动优化的汇编内核竞争，并在某些场景下超越所有可用内核基准。


<details>
  <summary>Details</summary>
Motivation: AMD GPU 提供先进的算力和内存带宽，但高性能 AMD 内核通常需要汇编编写。现有 DSL（如 ThunderKittens）主要针对 NVIDIA 硬件，需要探索这些编程原语在 AMD 平台上的通用性。

Method: 开发 HipKittens 框架，研究在 AMD GPU 上实现高性能 AI 内核的编程原语，采用显式的 tile-based 编程、优化的内存访问和细粒度异步执行。

Result: HK 内核在 CDNA3 和 CDNA4 AMD 平台上与手动优化的汇编内核竞争，在 GEMM 和注意力计算中表现优异，在某些设置下（如 d=64 注意力、GQA 反向、内存受限内核）比所有可用内核基准快 1.2-2.4 倍。

Conclusion: tile-based 抽象可以扩展到 AMD GPU，但需要重新思考实现这些抽象的算法。这些发现为跨 GPU 厂商的统一高性能 AI 内核软件层铺平了道路。

Abstract: AMD GPUs offer state-of-the-art compute and memory bandwidth; however, peak performance AMD kernels are written in raw assembly. To address the difficulty of mapping AI algorithms to hardware, recent work proposes C++ embedded and PyTorch-inspired domain-specific languages like ThunderKittens (TK) to simplify high performance AI kernel development on NVIDIA hardware. We explore the extent to which such primitives -- for explicit tile-based programming with optimized memory accesses and fine-grained asynchronous execution across workers -- are NVIDIA-specific or general. We provide the first detailed study of the programming primitives that lead to performant AMD AI kernels, and we encapsulate these insights in the HipKittens (HK) programming framework. We find that tile-based abstractions used in prior DSLs generalize to AMD GPUs, however we need to rethink the algorithms that instantiate these abstractions for AMD. We validate the HK primitives across CDNA3 and CDNA4 AMD platforms. In evaluations, HK kernels compete with AMD's hand-optimized assembly kernels for GEMMs and attention, and consistently outperform compiler baselines. Moreover, assembly is difficult to scale to the breadth of AI workloads; reflecting this, in some settings HK outperforms all available kernel baselines by $1.2-2.4\times$ (e.g., $d=64$ attention, GQA backwards, memory-bound kernels). These findings help pave the way for a single, tile-based software layer for high-performance AI kernels that translates across GPU vendors. HipKittens is released at: https://github.com/HazyResearch/HipKittens.

</details>


### [59] [Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks](https://arxiv.org/abs/2511.08086)
*Muthukumar Pandaram,Jakob Hollenstein,David Drexel,Samuele Tosatto,Antonio Rodríguez-Sánchez,Justus Piater*

Main category: cs.LG

TL;DR: 本文通过分析MuJoCo Playground基准套件中的机器人强化学习环境，检验了动态模型中状态稀疏性和时间稀疏性的假设，发现全局稀疏性很少见，但存在局部、状态依赖的稀疏性，且这种稀疏性呈现特定的时间聚类模式。


<details>
  <summary>Details</summary>
Motivation: 检验动态模型中因果图稀疏性和时间稀疏性假设是否在典型强化学习任务中成立，为动态学习提供更合理的归纳偏置。

Method: 分析MuJoCo Playground基准套件中机器人强化学习环境的真实动态，研究(i)环境动态的因果图是否稀疏，(ii)这种稀疏性是否状态依赖，(iii)局部系统动态是否稀疏变化。

Result: 全局稀疏性很少见，但任务在其动态中表现出局部、状态依赖的稀疏性，这种稀疏性呈现特定的时间聚类模式（如接触事件期间），并影响特定的状态维度子集。

Conclusion: 研究结果挑战了动态学习中常见的稀疏性先验假设，强调需要基于真实世界动态的状态依赖稀疏性结构来构建有根据的归纳偏置。

Abstract: The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.
  In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.
  We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.
  Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.

</details>


### [60] [Stuart-Landau Oscillatory Graph Neural Network](https://arxiv.org/abs/2511.08094)
*Kaicheng Zhang,David N. Reynolds,Piero Deidda,Francesco Tudisco*

Main category: cs.LG

TL;DR: 提出了基于Stuart-Landau振荡器动力学的复值图神经网络SLGNN，通过保留振幅和相位动态来缓解深度GNN中的过平滑和梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 现有振荡图神经网络主要基于相位中心模型，缺乏振幅动态调节能力。Stuart-Landau振荡器作为极限环行为的规范模型，能够提供更丰富的动态现象，如振幅调节和多稳态同步。

Method: 将Stuart-Landau振荡器动力学引入图神经网络，节点特征振幅和相位都动态演化，通过可调超参数（如Hopf参数和耦合强度）控制特征振幅与网络结构的相互作用。

Result: 在节点分类、图分类和图回归任务上的广泛实验表明，SLGNN优于现有OGNN，为深度振荡图架构提供了新颖、表达力强且理论基础扎实的框架。

Conclusion: SLGNN通过引入Stuart-Landau振荡器动力学，扩展了现有基于Kuramoto模型的振荡图神经网络，提供了更丰富的动态特性和更好的性能表现。

Abstract: Oscillatory Graph Neural Networks (OGNNs) are an emerging class of physics-inspired architectures designed to mitigate oversmoothing and vanishing gradient problems in deep GNNs. In this work, we introduce the Complex-Valued Stuart-Landau Graph Neural Network (SLGNN), a novel architecture grounded in Stuart-Landau oscillator dynamics. Stuart-Landau oscillators are canonical models of limit-cycle behavior near Hopf bifurcations, which are fundamental to synchronization theory and are widely used in e.g. neuroscience for mesoscopic brain modeling. Unlike harmonic oscillators and phase-only Kuramoto models, Stuart-Landau oscillators retain both amplitude and phase dynamics, enabling rich phenomena such as amplitude regulation and multistable synchronization. The proposed SLGNN generalizes existing phase-centric Kuramoto-based OGNNs by allowing node feature amplitudes to evolve dynamically according to Stuart-Landau dynamics, with explicit tunable hyperparameters (such as the Hopf-parameter and the coupling strength) providing additional control over the interplay between feature amplitudes and network structure. We conduct extensive experiments across node classification, graph classification, and graph regression tasks, demonstrating that SLGNN outperforms existing OGNNs and establishes a novel, expressive, and theoretically grounded framework for deep oscillatory architectures on graphs.

</details>


### [61] [A robust methodology for long-term sustainability evaluation of Machine Learning models](https://arxiv.org/abs/2511.08120)
*Jorge Paz-Ruza,João Gama,Amparo Alonso-Betanzos,Bertha Guijarro-Berdiñas*

Main category: cs.LG

TL;DR: 提出一个评估机器学习模型长期可持续性的综合协议，适用于批处理和流式学习场景，实验表明传统静态评估无法可靠反映数据演变和模型更新下的可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统评估缺乏标准化、模型无关的可持续性评估协议，当前方法只测量短期实验资源使用，过度强调批处理学习，无法反映真实世界长期AI生命周期。

Method: 提出综合评估协议，在多样化分类任务上使用多种模型类型进行实验，比较批处理和流式学习场景下的可持续性表现。

Result: 传统静态训练-测试评估无法可靠捕捉数据演变和重复模型更新下的可持续性；长期可持续性在不同模型间差异显著；在许多情况下，更高的环境成本带来的性能收益很小。

Conclusion: 需要采用更全面的评估方法来准确衡量AI系统的长期可持续性，避免资源浪费，确保AI发展与环境可持续性相协调。

Abstract: Sustainability and efficiency have become essential considerations in the development and deployment of Artificial Intelligence systems, yet existing regulatory and reporting practices lack standardized, model-agnostic evaluation protocols. Current assessments often measure only short-term experimental resource usage and disproportionately emphasize batch learning settings, failing to reflect real-world, long-term AI lifecycles. In this work, we propose a comprehensive evaluation protocol for assessing the long-term sustainability of ML models, applicable to both batch and streaming learning scenarios. Through experiments on diverse classification tasks using a range of model types, we demonstrate that traditional static train-test evaluations do not reliably capture sustainability under evolving data and repeated model updates. Our results show that long-term sustainability varies significantly across models, and in many cases, higher environmental cost yields little performance benefit.

</details>


### [62] [SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories](https://arxiv.org/abs/2511.08136)
*Returaj Burnwal,Nirav Pravinbhai Bhatt,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 提出SafeMIL方法，通过多示例学习从非偏好轨迹中学习风险成本函数，实现离线安全模仿学习，在满足安全约束的同时保持奖励性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中在线交互存在风险，且难以精确指定每个时间步的奖励和安全成本信息，但可以收集反映不良或风险行为的轨迹来传达应避免的行为。

Method: 使用多示例学习从非偏好轨迹中学习参数化成本函数，预测状态-动作对是否具有风险，然后利用学习到的成本来避免非偏好行为。

Result: 实验证明该方法能够学习满足成本约束的更安全策略，且不会降低奖励性能，优于多个基线方法。

Conclusion: SafeMIL方法通过从非偏好轨迹中学习风险成本，有效实现了离线安全模仿学习，在保证安全的同时维持了良好的性能表现。

Abstract: In this work, we study the problem of offline safe imitation learning (IL). In many real-world settings, online interactions can be risky, and accurately specifying the reward and the safety cost information at each timestep can be difficult. However, it is often feasible to collect trajectories reflecting undesirable or risky behavior, implicitly conveying the behavior the agent should avoid. We refer to these trajectories as non-preferred trajectories. Unlike standard IL, which aims to mimic demonstrations, our agent must also learn to avoid risky behavior using non-preferred trajectories. In this paper, we propose a novel approach, SafeMIL, to learn a parameterized cost that predicts if the state-action pair is risky via \textit{Multiple Instance Learning}. The learned cost is then used to avoid non-preferred behaviors, resulting in a policy that prioritizes safety. We empirically demonstrate that our approach can learn a safer policy that satisfies cost constraints without degrading the reward performance, thereby outperforming several baselines.

</details>


### [63] [BIPPO: Budget-Aware Independent PPO for Energy-Efficient Federated Learning Services](https://arxiv.org/abs/2511.08142)
*Anna Lackinger,Andrea Morichetta,Pantelis A. Frangoudis,Schahram Dustdar*

Main category: cs.LG

TL;DR: BIPPO是一种基于多智能体强化学习的节能客户端选择方法，用于联邦学习中的物联网系统，在资源受限环境下提高性能并保持预算稳定。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保证负载分布和隐私，但未考虑基础设施效率问题。现有基于强化学习的客户端选择方法忽略了资源限制、设备流失等基础设施挑战，且缺乏通用性和能效优化。

Method: 提出BIPPO（预算感知独立近端策略优化），这是一种节能的多智能体强化学习解决方案，通过改进的采样器在高度预算受限设置下选择客户端。

Result: 在两个图像分类任务上评估，BIPPO在非IID数据上相比非RL机制、传统PPO和IPPO提高了平均准确率，且仅消耗可忽略的预算比例，即使客户端数量增加也能保持稳定。

Conclusion: BIPPO为物联网联邦学习中的客户端选择提供了一个高性能、稳定、可扩展且可持续的解决方案。

Abstract: Federated Learning (FL) is a promising machine learning solution in large-scale IoT systems, guaranteeing load distribution and privacy. However, FL does not natively consider infrastructure efficiency, a critical concern for systems operating in resource-constrained environments. Several Reinforcement Learning (RL) based solutions offer improved client selection for FL; however, they do not consider infrastructure challenges, such as resource limitations and device churn. Furthermore, the training of RL methods is often not designed for practical application, as these approaches frequently do not consider generalizability and are not optimized for energy efficiency. To fill this gap, we propose BIPPO (Budget-aware Independent Proximal Policy Optimization), which is an energy-efficient multi-agent RL solution that improves performance. We evaluate BIPPO on two image classification tasks run in a highly budget-constrained setting, with FL clients training on non-IID data, a challenging context for vanilla FL. The improved sampler of BIPPO enables it to increase the mean accuracy compared to non-RL mechanisms, traditional PPO, and IPPO. In addition, BIPPO only consumes a negligible proportion of the budget, which stays consistent even if the number of clients increases. Overall, BIPPO delivers a performant, stable, scalable, and sustainable solution for client selection in IoT-FL.

</details>


### [64] [Deep (Predictive) Discounted Counterfactual Regret Minimization](https://arxiv.org/abs/2511.08174)
*Hang Xu,Kai Li,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Main category: cs.LG

TL;DR: 提出了一种高效的模型无关神经CFR算法，能够有效近似高级CFR变体，在典型不完全信息游戏中表现出更快的收敛速度和更强的对抗性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于基础CFR，难以有效整合更高级的CFR变体，限制了在大规模游戏中的应用。

Method: 使用价值网络收集方差减少的采样优势，通过自助法拟合累积优势，并应用折扣和裁剪操作来模拟高级CFR变体的更新机制。

Result: 实验结果显示，相比模型无关神经算法，在典型不完全信息游戏中收敛更快，在大型扑克游戏中表现出更强的对抗性能。

Conclusion: 该算法成功克服了现有方法在近似高级CFR变体方面的局限性，为大规模不完全信息游戏提供了有效的解决方案。

Abstract: Counterfactual regret minimization (CFR) is a family of algorithms for effectively solving imperfect-information games. To enhance CFR's applicability in large games, researchers use neural networks to approximate its behavior. However, existing methods are mainly based on vanilla CFR and struggle to effectively integrate more advanced CFR variants. In this work, we propose an efficient model-free neural CFR algorithm, overcoming the limitations of existing methods in approximating advanced CFR variants. At each iteration, it collects variance-reduced sampled advantages based on a value network, fits cumulative advantages by bootstrapping, and applies discounting and clipping operations to simulate the update mechanisms of advanced CFR variants. Experimental results show that, compared with model-free neural algorithms, it exhibits faster convergence in typical imperfect-information games and demonstrates stronger adversarial performance in a large poker game.

</details>


### [65] [Improving Long-Range Interactions in Graph Neural Simulators via Hamiltonian Dynamics](https://arxiv.org/abs/2511.08185)
*Tai Hoang,Alessandro Trenta,Alessio Gravina,Niklas Freymuth,Philipp Becker,Davide Bacciu,Gerhard Neumann*

Main category: cs.LG

TL;DR: 提出了信息保持图神经网络模拟器（IGNS），基于哈密顿动力学原理，能够更好地捕捉长程相互作用并减少自回归展开中的误差累积。


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器计算成本高，而现有图神经网络模拟器在捕捉长程相互作用和减少误差累积方面存在困难。

Method: 基于哈密顿动力学原理构建图神经网络模拟器，包含预热阶段初始化全局上下文、几何编码处理不规则网格、多步训练目标减少展开误差。

Result: 在所有任务中，IGNS始终优于最先进的图神经网络模拟器，在挑战性和复杂动力系统中实现了更高的准确性和稳定性。

Conclusion: IGNS通过哈密顿动力学框架有效解决了图神经网络模拟器在长程相互作用和误差累积方面的局限性，为复杂物理系统模拟提供了更优的解决方案。

Abstract: Learning to simulate complex physical systems from data has emerged as a promising way to overcome the limitations of traditional numerical solvers, which often require prohibitive computational costs for high-fidelity solutions. Recent Graph Neural Simulators (GNSs) accelerate simulations by learning dynamics on graph-structured data, yet often struggle to capture long-range interactions and suffer from error accumulation under autoregressive rollouts. To address these challenges, we propose Information-preserving Graph Neural Simulators (IGNS), a graph-based neural simulator built on the principles of Hamiltonian dynamics. This structure guarantees preservation of information across the graph, while extending to port-Hamiltonian systems allows the model to capture a broader class of dynamics, including non-conservative effects. IGNS further incorporates a warmup phase to initialize global context, geometric encoding to handle irregular meshes, and a multi-step training objective to reduce rollout error. To evaluate these properties systematically, we introduce new benchmarks that target long-range dependencies and challenging external forcing scenarios. Across all tasks, IGNS consistently outperforms state-of-the-art GNSs, achieving higher accuracy and stability under challenging and complex dynamical systems.

</details>


### [66] [The Online Patch Redundancy Eliminator (OPRE): A novel approach to online agnostic continual learning using dataset compression](https://arxiv.org/abs/2511.08226)
*Raphaël Bayle,Martial Mermillod,Robert M. French*

Main category: cs.LG

TL;DR: 本文提出OPRE算法，一种在线数据集压缩方法，用于解决持续学习中的灾难性遗忘问题，并在CIFAR数据集上取得了优于现有在线持续学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数持续学习方法都引入了对数据的先验信息，无法被认为是无先验的。特别是依赖预训练特征提取器的方法会限制模型能够学习的数据范围，失去通用性。

Method: 提出了在线补丁冗余消除器(OPRE)，这是一种在线数据集压缩算法，结合测试时分类器训练，仅需对数据做出最小且可解释的假设。

Result: OPRE在CIFAR-10和CIFAR-100数据集上的表现优于多个其他最先进的在线持续学习方法。

Conclusion: 在线数据集压缩可能是实现完全无先验持续学习的必要手段。

Abstract: In order to achieve Continual Learning (CL), the problem of catastrophic forgetting, one that has plagued neural networks since their inception, must be overcome. The evaluation of continual learning methods relies on splitting a known homogeneous dataset and learning the associated tasks one after the other. We argue that most CL methods introduce a priori information about the data to come and cannot be considered agnostic. We exemplify this point with the case of methods relying on pretrained feature extractors, which are still used in CL. After showing that pretrained feature extractors imply a loss of generality with respect to the data that can be learned by the model, we then discuss other kinds of a priori information introduced in other CL methods. We then present the Online Patch Redundancy Eliminator (OPRE), an online dataset compression algorithm, which, along with the training of a classifier at test time, yields performance on CIFAR-10 and CIFAR-100 superior to a number of other state-of-the-art online continual learning methods. Additionally, OPRE requires only minimal and interpretable hypothesis on the data to come. We suggest that online dataset compression could well be necessary to achieve fully agnostic CL.

</details>


### [67] [Towards Non-Stationary Time Series Forecasting with Temporal Stabilization and Frequency Differencing](https://arxiv.org/abs/2511.08229)
*Junkai Lu,Peng Chen,Chenjuan Guo,Yang Shu,Meng Wang,Bin Yang*

Main category: cs.LG

TL;DR: DTAF是一个双分支框架，通过时域稳定融合和频域波建模来处理时间序列中的非平稳性，在多个真实基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列常表现出非平稳性（包括时间分布偏移和频谱变异性），这对长期时间序列预测构成重大挑战。

Method: 提出DTAF双分支框架：时域分支使用非平稳混合专家滤波器来解耦和抑制时间非平稳模式；频域分支应用频率差分来动态突出显示具有显著频谱偏移的组件；最后融合两个分支的输出。

Result: 在真实世界基准测试上的广泛实验表明，DTAF在非平稳条件下显著优于最先进的基线方法，提高了预测准确性。

Conclusion: DTAF通过同时处理时域和频域的非平稳性，能够生成适应非平稳条件的鲁棒预测，代码已开源。

Abstract: Time series forecasting is critical for decision-making across dynamic domains such as energy, finance, transportation, and cloud computing. However, real-world time series often exhibit non-stationarity, including temporal distribution shifts and spectral variability, which pose significant challenges for long-term time series forecasting. In this paper, we propose DTAF, a dual-branch framework that addresses non-stationarity in both the temporal and frequency domains. For the temporal domain, the Temporal Stabilizing Fusion (TFS) module employs a non-stationary mix of experts (MOE) filter to disentangle and suppress temporal non-stationary patterns while preserving long-term dependencies. For the frequency domain, the Frequency Wave Modeling (FWM) module applies frequency differencing to dynamically highlight components with significant spectral shifts. By fusing the complementary outputs of TFS and FWM, DTAF generates robust forecasts that adapt to both temporal and frequency domain non-stationarity. Extensive experiments on real-world benchmarks demonstrate that DTAF outperforms state-of-the-art baselines, yielding significant improvements in forecasting accuracy under non-stationary conditions. All codes are available at https://github.com/PandaJunk/DTAF.

</details>


### [68] [PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore](https://arxiv.org/abs/2511.08241)
*Zhihao Lin,Lin Wu,Zhen Tian,Jianglin Lan*

Main category: cs.LG

TL;DR: PrefPoE是一个新颖的偏好专家乘积框架，通过优势引导的智能探索来解决强化学习中的探索挑战，在连续和离散动作空间中均表现出显著的性能提升和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的探索仍然是一个关键挑战，朴素熵最大化通常导致高方差和低效的策略更新。需要一种智能的探索方法来平衡探索与利用。

Method: 提出PrefPoE框架，训练偏好网络将概率质量集中在高优势动作上，并通过专家乘积(PoE)融合将其与主策略结合，创建软信任区域来稳定策略更新同时保持定向探索。

Result: 在多样化控制任务中表现优异：HalfCheetah-v4提升321%(1276→5375)，Ant-v4提升69%，LunarLander-v2提升276%，训练稳定性和样本效率均显著增强。

Conclusion: 通过优势引导偏好学习探索位置与学习如何行动同等重要，为增强策略梯度方法提供了一个通用框架。

Abstract: Exploration in reinforcement learning remains a critical challenge, as naive entropy maximization often results in high variance and inefficient policy updates. We introduce \textbf{PrefPoE}, a novel \textit{Preference-Product-of-Experts} framework that performs intelligent, advantage-guided exploration via the first principled application of product-of-experts (PoE) fusion for single-task exploration-exploitation balancing. By training a preference network to concentrate probability mass on high-advantage actions and fusing it with the main policy through PoE, PrefPoE creates a \textbf{soft trust region} that stabilizes policy updates while maintaining targeted exploration. Across diverse control tasks spanning both continuous and discrete action spaces, PrefPoE demonstrates consistent improvements: +321\% on HalfCheetah-v4 (1276~$\rightarrow$~5375), +69\% on Ant-v4, +276\% on LunarLander-v2, with consistently enhanced training stability and sample efficiency. Unlike standard PPO, which suffers from entropy collapse, PrefPoE sustains adaptive exploration through its unique dynamics, thereby preventing premature convergence and enabling superior performance. Our results establish that learning \textit{where to explore} through advantage-guided preferences is as crucial as learning how to act, offering a general framework for enhancing policy gradient methods across the full spectrum of reinforcement learning domains. Code and pretrained models are available in supplementary materials.

</details>


### [69] [A Unified Geometric Field Theory Framework for Transformers: From Manifold Embeddings to Kernel Modulation](https://arxiv.org/abs/2511.08243)
*Xianshuai Shi,Jianfeng Zhu,Leibo Liu*

Main category: cs.LG

TL;DR: 提出一个统一的理论框架，将Transformer的位置编码、核积分算子和注意力机制整合起来进行理论分析。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在多个领域取得了巨大成功，但其核心组件（位置编码和注意力机制）缺乏统一的物理或数学解释。

Method: 将离散位置映射到连续流形上的空间函数，将Transformer层解释为在嵌入流形上作用的核调制算子。

Result: 建立了一个结构理论框架，为Transformer组件提供了场论解释。

Conclusion: 该框架为Transformer架构提供了统一的数学和物理解释，有助于深入理解其工作机制。

Abstract: The Transformer architecture has achieved tremendous success in natural language processing, computer vision, and scientific computing through its self-attention mechanism. However, its core components-positional encoding and attention mechanisms-have lacked a unified physical or mathematical interpretation. This paper proposes a structural theoretical framework that integrates positional encoding, kernel integral operators, and attention mechanisms for in-depth theoretical investigation. We map discrete positions (such as text token indices and image pixel coordinates) to spatial functions on continuous manifolds, enabling a field-theoretic interpretation of Transformer layers as kernel-modulated operators acting over embedded manifolds.

</details>


### [70] [Data-Driven Discovery of Feature Groups in Clinical Time Series](https://arxiv.org/abs/2511.08260)
*Fedor Sergeev,Manuel Burger,Polina Leshetkina,Vincent Fortuin,Gunnar Rätsch,Rita Kuznetsova*

Main category: cs.LG

TL;DR: 提出了一种通过聚类特征嵌入层权重来自动学习特征分组的新方法，该方法可无缝集成到标准监督训练中，提升临床时间序列预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 临床时间序列数据通常包含数百个异构特征，基于相似性和任务相关性的特征分组已被证明能提升深度学习架构性能，但仅凭语义知识先验定义这些分组对领域专家来说具有挑战性。

Method: 通过聚类特征嵌入层的权重来学习特征分组，该方法可无缝集成到标准监督训练流程中，自动发现能直接提升下游任务性能的特征组。

Result: 在合成数据上优于静态聚类方法，在真实医疗数据上达到与专家定义分组相当的性能，且学习到的特征组具有临床可解释性。

Conclusion: 该方法能够数据驱动地发现任务相关的变量关系，为临床时间序列分析提供了一种有效的特征分组学习方案。

Abstract: Clinical time series data are critical for patient monitoring and predictive modeling. These time series are typically multivariate and often comprise hundreds of heterogeneous features from different data sources. The grouping of features based on similarity and relevance to the prediction task has been shown to enhance the performance of deep learning architectures. However, defining these groups a priori using only semantic knowledge is challenging, even for domain experts. To address this, we propose a novel method that learns feature groups by clustering weights of feature-wise embedding layers. This approach seamlessly integrates into standard supervised training and discovers the groups that directly improve downstream performance on clinically relevant tasks. We demonstrate that our method outperforms static clustering approaches on synthetic data and achieves performance comparable to expert-defined groups on real-world medical data. Moreover, the learned feature groups are clinically interpretable, enabling data-driven discovery of task-relevant relationships between variables.

</details>


### [71] [Rethinking Explanation Evaluation under the Retraining Scheme](https://arxiv.org/abs/2511.08281)
*Yi Cai,Thibaud Ardoin,Mayank Gulati,Gerhard Wunder*

Main category: cs.LG

TL;DR: 本文分析了基于再训练的归因评估方法ROAR存在的问题，发现符号问题是导致评估结果与理论预期不符的关键因素，并提出改进方案来提升解释器评估的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前特征归因评估面临挑战，因为缺乏真实解释作为基准。基于推理的评估方法存在分布偏移问题，而基于再训练的ROAR方法虽然解决了分布偏移，但其评估结果与理论预期存在矛盾。

Method: 识别了ROAR评估中的符号问题，提出通过重构评估过程来解决该问题。在现有框架基础上，开发了新的变体方法，共同构建了全面的解释评估视角，显著提高了评估效率。

Result: 提出的改进方案有效解决了符号问题，新变体方法大幅提升了评估效率。在不同数据规模下的实证结果提供了对选定解释器性能的深入洞察。

Conclusion: 研究揭示了归因评估中的关键挑战，提出的改进方案增强了评估的实用性和可靠性，为解释器选择和基准测试提供了更好的工具，同时指出了可解释性研究的未来方向。

Abstract: Feature attribution has gained prominence as a tool for explaining model decisions, yet evaluating explanation quality remains challenging due to the absence of ground-truth explanations. To circumvent this, explanation-guided input manipulation has emerged as an indirect evaluation strategy, measuring explanation effectiveness through the impact of input modifications on model outcomes during inference. Despite the widespread use, a major concern with inference-based schemes is the distribution shift caused by such manipulations, which undermines the reliability of their assessments. The retraining-based scheme ROAR overcomes this issue by adapting the model to the altered data distribution. However, its evaluation results often contradict the theoretical foundations of widely accepted explainers. This work investigates this misalignment between empirical observations and theoretical expectations. In particular, we identify the sign issue as a key factor responsible for residual information that ultimately distorts retraining-based evaluation. Based on the analysis, we show that a straightforward reframing of the evaluation process can effectively resolve the identified issue. Building on the existing framework, we further propose novel variants that jointly structure a comprehensive perspective on explanation evaluation. These variants largely improve evaluation efficiency over the standard retraining protocol, thereby enhancing practical applicability for explainer selection and benchmarking. Following our proposed schemes, empirical results across various data scales provide deeper insights into the performance of carefully selected explainers, revealing open challenges and future directions in explainability research.

</details>


### [72] [Dual-Kernel Graph Community Contrastive Learning](https://arxiv.org/abs/2511.08287)
*Xiang Chen,Kun Yue,Wenjie Liu,Zhenyu Zhang,Liang Duan*

Main category: cs.LG

TL;DR: 提出了一种高效的图对比学习框架，通过将输入图转换为紧凑的节点集网络来提升可扩展性，同时保持社区间的结构信息。


<details>
  <summary>Details</summary>
Motivation: 解决图对比学习在大规模图上的可扩展性问题，包括GNN消息传递机制的计算密集性和对比损失在正负节点对上的二次计算复杂度。

Method: 1. 引入线性复杂度的核化图社区对比损失；2. 在解耦GNN架构中融入知识蒸馏技术；3. 将输入图转换为紧凑的节点集网络。

Result: 在16个不同规模的真实数据集上的实验表明，该方法在效果和可扩展性方面均优于最先进的图对比学习基线方法。

Conclusion: 提出的高效图对比学习框架成功解决了大规模图上的可扩展性问题，同时保持了强大的泛化性能。

Abstract: Graph Contrastive Learning (GCL) has emerged as a powerful paradigm for training Graph Neural Networks (GNNs) in the absence of task-specific labels. However, its scalability on large-scale graphs is hindered by the intensive message passing mechanism of GNN and the quadratic computational complexity of contrastive loss over positive and negative node pairs. To address these issues, we propose an efficient GCL framework that transforms the input graph into a compact network of interconnected node sets while preserving structural information across communities. We firstly introduce a kernelized graph community contrastive loss with linear complexity, enabling effective information transfer among node sets to capture hierarchical structural information of the graph. We then incorporate a knowledge distillation technique into the decoupled GNN architecture to accelerate inference while maintaining strong generalization performance. Extensive experiments on sixteen real-world datasets of varying scales demonstrate that our method outperforms state-of-the-art GCL baselines in both effectiveness and scalability.

</details>


### [73] [Test-time Diverse Reasoning by Riemannian Activation Steering](https://arxiv.org/abs/2511.08305)
*Ly Tran Ho Khanh,Dongxuan Zhu,Man-Chung Yue,Viet Anh Nguyen*

Main category: cs.LG

TL;DR: 提出了一种基于黎曼优化的无监督激活导向策略，通过最大化推理路径的多样性来提升语言模型在复杂任务中的准确性


<details>
  <summary>Details</summary>
Motivation: 解决Best-of-N推理策略中的输出多样性限制问题，当模型生成相似输出时无法纠正相同错误

Method: 在测试时同步锚点处，通过黎曼块坐标下降算法求解黎曼优化问题，找到最大化所有可能干预激活子集总体积的导向向量

Result: 在数学基准测试中，该方法在生成多样性和解决方案准确性方面优于普通采样技术

Conclusion: 测试时黎曼激活导向策略能有效提升推理路径的多样性，从而提高语言模型解决复杂任务的性能

Abstract: Best-of-$N$ reasoning improves the accuracy of language models in solving complex tasks by sampling multiple candidate solutions and then selecting the best one based on some criteria. A critical bottleneck for this strategy is the output diversity limit, which occurs when the model generates similar outputs despite stochastic sampling, and hence recites the same error. To address this lack of variance in reasoning paths, we propose a novel unsupervised activation steering strategy that simultaneously optimizes the steering vectors for multiple reasoning trajectories at test time. At any synchronization anchor along the batch generation process, we find the steering vectors that maximize the total volume spanned by all possible intervened activation subsets. We demonstrate that these steering vectors can be determined by solving a Riemannian optimization problem over the product of spheres with a log-determinant objective function. We then use a Riemannian block-coordinate descent algorithm with a well-tuned learning rate to obtain a stationary point of the problem, and we apply these steering vectors until the generation process reaches the subsequent synchronization anchor. Empirical evaluations on popular mathematical benchmarks demonstrate that our test-time Riemannian activation steering strategy outperforms vanilla sampling techniques in terms of generative diversity and solution accuracy.

</details>


### [74] [Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework](https://arxiv.org/abs/2511.08314)
*Xiaoyu Fan,Lin Guo,Ruizhen Jia,Yang Tian,Zhihao Yang,Boxue Tian*

Main category: cs.LG

TL;DR: MolRuleLoss是一个基于子结构替换规则的框架，通过将SSR的偏导数约束整合到分子性质回归模型的损失函数中，显著提升了多种分子性质预测任务的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: AI辅助药物发现中，分子性质预测模型在回归任务中准确性较差，特别是对于分布外分子表现灾难性差，需要提高模型的准确性和泛化能力。

Method: MolRuleLoss框架将子结构替换规则的偏导数约束整合到分子性质回归模型的损失函数中，通过SSR的数量和质量来提升预测性能。

Result: 在多个分子性质预测任务中，MolRuleLoss显著降低了RMSE值（提升2.6-33.3%），改善了分布外分子和"活性悬崖"分子的泛化能力，在分子量预测任务中RMSE从29.507降至0.007。

Conclusion: MolRuleLoss作为即插即用框架，能够显著提升多种分子性质回归模型的预测准确性和泛化能力，支持化学信息学和AI辅助药物发现等领域的应用。

Abstract: Artificial Intelligence (AI)-aided drug discovery is an active research field, yet AI models often exhibit poor accuracy in regression tasks for molecular property prediction, and perform catastrophically poorly for out-of-distribution (OOD) molecules. Here, we present MolRuleLoss, a substructure-substitution-rule-informed framework that improves the accuracy and generalizability of multiple molecular property regression models (MPRMs) such as GEM and UniMol for diverse molecular property prediction tasks. MolRuleLoss incorporates partial derivative constraints for substructure substitution rules (SSRs) into an MPRM's loss function. When using GEM models for predicting lipophilicity, water solubility, and solvation-free energy (using lipophilicity, ESOL, and freeSolv datasets from MoleculeNet), the root mean squared error (RMSE) values with and without MolRuleLoss were 0.587 vs. 0.660, 0.777 vs. 0.798, and 1.252 vs. 1.877, respectively, representing 2.6-33.3% performance improvements. We show that both the number and the quality of SSRs contribute to the magnitude of prediction accuracy gains obtained upon adding MolRuleLoss to an MPRM. MolRuleLoss improved the generalizability of MPRMs for "activity cliff" molecules in a lipophilicity prediction task and improved the generalizability of MPRMs for OOD molecules in a melting point prediction task. In a molecular weight prediction task for OOD molecules, MolRuleLoss reduced the RMSE value of a GEM model from 29.507 to 0.007. We also provide a formal demonstration that the upper bound of the variation for property change of SSRs is positively correlated with an MPRM's error. Together, we show that using the MolRuleLoss framework as a bolt-on boosts the prediction accuracy and generalizability of multiple MPRMs, supporting diverse applications in areas like cheminformatics and AI-aided drug discovery.

</details>


### [75] [Adversarial Bias: Data Poisoning Attacks on Fairness](https://arxiv.org/abs/2511.08331)
*Eunice Chan,Hanghang Tong*

Main category: cs.LG

TL;DR: 本文提出了一种针对朴素贝叶斯分类器的对抗性投毒攻击方法，通过向训练集注入少量精心设计的对抗数据点，可以显著降低模型的公平性，同时保持整体性能。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在现实应用中的广泛采用，确保其公平性变得至关重要。目前大多数研究关注评估和改进机器学习系统的公平性，但关于公平性脆弱性（即AI系统公平性如何被故意破坏）的研究相对较少。

Method: 提出一种简单的对抗性投毒策略，通过向训练集战略性地注入少量精心设计的对抗数据点，偏置模型的决策边界，使其对受保护群体产生不成比例的影响，同时保持可泛化的性能。

Result: 实验表明，该方法在多个基准数据集和模型上显著优于现有方法，在降低公平性指标方面表现突出，通常能以相当或仅稍差的准确度影响实现显著更高的不公平水平。该方法在广泛模型范围内都有效。

Conclusion: 该研究展示了一种强大有效的方法来破坏机器学习系统的公平性，揭示了当前AI系统在公平性方面的潜在脆弱性。

Abstract: With the growing adoption of AI and machine learning systems in real-world applications, ensuring their fairness has become increasingly critical. The majority of the work in algorithmic fairness focus on assessing and improving the fairness of machine learning systems. There is relatively little research on fairness vulnerability, i.e., how an AI system's fairness can be intentionally compromised. In this work, we first provide a theoretical analysis demonstrating that a simple adversarial poisoning strategy is sufficient to induce maximally unfair behavior in naive Bayes classifiers. Our key idea is to strategically inject a small fraction of carefully crafted adversarial data points into the training set, biasing the model's decision boundary to disproportionately affect a protected group while preserving generalizable performance. To illustrate the practical effectiveness of our method, we conduct experiments across several benchmark datasets and models. We find that our attack significantly outperforms existing methods in degrading fairness metrics across multiple models and datasets, often achieving substantially higher levels of unfairness with a comparable or only slightly worse impact on accuracy. Notably, our method proves effective on a wide range of models, in contrast to prior work, demonstrating a robust and potent approach to compromising the fairness of machine learning systems.

</details>


### [76] [LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration](https://arxiv.org/abs/2511.08339)
*Ruiyu Qiu,Rui Wang,Guanghui Yang,Xiang Li,Zhijiang Shao*

Main category: cs.LG

TL;DR: 提出了LPPG-RL框架，使用顺序梯度投影解决连续空间中的词典序多目标强化学习问题，避免了启发式阈值调整，并引入子问题探索来加速收敛。


<details>
  <summary>Details</summary>
Motivation: 传统安全RL和多目标RL方法难以有效处理具有明确优先级的词典序多目标问题，现有LMORL方法要么依赖启发式阈值调整，要么仅限于离散域。

Method: 利用顺序梯度投影识别可行的策略更新方向，将投影步骤重新表述为优化问题，使用Dykstra投影而非通用求解器，并引入子问题探索防止梯度消失。

Result: 在2D导航环境中实验证明，LPPG-RL优于现有最先进的连续LMORL方法，理论保证了收敛性并建立了策略改进的下界。

Conclusion: LPPG-RL是一个与所有策略梯度算法兼容的通用LMORL框架，在连续空间中有效解决了词典序多目标强化学习问题。

Abstract: Lexicographic multi-objective problems, which consist of multiple conflicting subtasks with explicit priorities, are common in real-world applications. Despite the advantages of Reinforcement Learning (RL) in single tasks, extending conventional RL methods to prioritized multiple objectives remains challenging. In particular, traditional Safe RL and Multi-Objective RL (MORL) methods have difficulty enforcing priority orderings efficiently. Therefore, Lexicographic Multi-Objective RL (LMORL) methods have been developed to address these challenges. However, existing LMORL methods either rely on heuristic threshold tuning with prior knowledge or are restricted to discrete domains. To overcome these limitations, we propose Lexicographically Projected Policy Gradient RL (LPPG-RL), a novel LMORL framework which leverages sequential gradient projections to identify feasible policy update directions, thereby enabling LPPG-RL broadly compatible with all policy gradient algorithms in continuous spaces. LPPG-RL reformulates the projection step as an optimization problem, and utilizes Dykstra's projection rather than generic solvers to deliver great speedups, especially for small- to medium-scale instances. In addition, LPPG-RL introduces Subproblem Exploration (SE) to prevent gradient vanishing, accelerate convergence and enhance stability. We provide theoretical guarantees for convergence and establish a lower bound on policy improvement. Finally, through extensive experiments in a 2D navigation environment, we demonstrate the effectiveness of LPPG-RL, showing that it outperforms existing state-of-the-art continuous LMORL methods.

</details>


### [77] [HN-MVTS: HyperNetwork-based Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.08340)
*Andrey Savchenko,Oleg Kachan*

Main category: cs.LG

TL;DR: 提出了HN-MVTS架构，通过超网络生成目标预测网络最后一层的权重，作为数据自适应正则化器，提高多变量时间序列预测的泛化能力和长程预测精度。


<details>
  <summary>Details</summary>
Motivation: 解决多变量时间序列预测中复杂通道依赖模型性能下降的问题，同时保持通道独立模型的高鲁棒性优势。

Method: 将基于超网络的生成先验与任意神经网络预测模型集成，超网络输入为时间序列组件的可学习嵌入矩阵，仅生成目标网络最后一层权重，训练时使用但不增加推理时间。

Result: 在8个基准数据集上的实验表明，将HN-MVTS应用于最先进模型（DLinear、PatchTST、TSMixer等）通常能提高其性能。

Conclusion: 超网络驱动的参数化为在复杂场景中增强现有预测技术提供了有前景的方向。

Abstract: Accurate forecasting of multivariate time series data remains a formidable challenge, particularly due to the growing complexity of temporal dependencies in real-world scenarios. While neural network-based models have achieved notable success in this domain, complex channel-dependent models often suffer from performance degradation compared to channel-independent models that do not consider the relationship between components but provide high robustness due to small capacity. In this work, we propose HN-MVTS, a novel architecture that integrates a hypernetwork-based generative prior with an arbitrary neural network forecasting model. The input of this hypernetwork is a learnable embedding matrix of time series components. To restrict the number of new parameters, the hypernetwork learns to generate the weights of the last layer of the target forecasting networks, serving as a data-adaptive regularizer that improves generalization and long-range predictive accuracy. The hypernetwork is used only during the training, so it does not increase the inference time compared to the base forecasting model. Extensive experiments on eight benchmark datasets demonstrate that application of HN-MVTS to the state-of-the-art models (DLinear, PatchTST, TSMixer, etc.) typically improves their performance. Our findings suggest that hypernetwork-driven parameterization offers a promising direction for enhancing existing forecasting techniques in complex scenarios.

</details>


### [78] [From Confusion to Clarity: ProtoScore - A Framework for Evaluating Prototype-Based XAI](https://arxiv.org/abs/2511.08361)
*Helena Monke,Benjamin Sae-Chew,Benjamin Fresz,Marco F. Huber*

Main category: cs.LG

TL;DR: ProtoScore是一个用于评估基于原型的可解释AI方法的标准化框架，特别关注时间序列数据，旨在解决该领域缺乏客观基准的问题。


<details>
  <summary>Details</summary>
Motivation: 神经网络在医疗、金融和法律等高风险领域的复杂性和不透明性带来了挑战，而基于原型的解释方法虽然很有前景，但缺乏标准化基准来进行客观比较，特别是在时间序列数据方面。

Method: 开发了ProtoScore框架，整合了Nauta等人的Co-12属性，用于在不同数据类型上评估基于原型的XAI方法，特别关注时间序列数据。

Result: ProtoScore框架能够有效比较原型方法之间以及与其他XAI方法的性能，帮助从业者选择合适的解释方法，同时减少用户研究的成本。

Conclusion: ProtoScore为基于原型的XAI方法提供了一个稳健的评估框架，促进了该领域的公平和全面评估，所有代码已公开可用。

Abstract: The complexity and opacity of neural networks (NNs) pose significant challenges, particularly in high-stakes fields such as healthcare, finance, and law, where understanding decision-making processes is crucial. To address these issues, the field of explainable artificial intelligence (XAI) has developed various methods aimed at clarifying AI decision-making, thereby facilitating appropriate trust and validating the fairness of outcomes. Among these methods, prototype-based explanations offer a promising approach that uses representative examples to elucidate model behavior. However, a critical gap exists regarding standardized benchmarks to objectively compare prototype-based XAI methods, especially in the context of time series data. This lack of reliable benchmarks results in subjective evaluations, hindering progress in the field. We aim to establish a robust framework, ProtoScore, for assessing prototype-based XAI methods across different data types with a focus on time series data, facilitating fair and comprehensive evaluations. By integrating the Co-12 properties of Nauta et al., this framework allows for effectively comparing prototype methods against each other and against other XAI methods, ultimately assisting practitioners in selecting appropriate explanation methods while minimizing the costs associated with user studies. All code is publicly available at https://github.com/HelenaM23/ProtoScore .

</details>


### [79] [Multi-objective Hyperparameter Optimization in the Age of Deep Learning](https://arxiv.org/abs/2511.08371)
*Soham Basu,Frank Hutter,Danny Stoll*

Main category: cs.LG

TL;DR: PriMO是首个能够整合多目标用户信念的超参数优化算法，在8个深度学习基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习专家通常具有关于哪些超参数设置能产生强性能的先验知识，但现有的超参数优化算法很少能利用这种先验知识，且没有算法能整合多目标的先验知识。

Method: 提出了PriMO算法，这是首个能够整合多目标用户信念的超参数优化算法。

Result: 在8个深度学习基准测试中，PriMO在多目标和单目标设置下都实现了最先进的性能。

Conclusion: PriMO明确地将自己定位为深度学习从业者的新首选超参数优化算法。

Abstract: While Deep Learning (DL) experts often have prior knowledge about which hyperparameter settings yield strong performance, only few Hyperparameter Optimization (HPO) algorithms can leverage such prior knowledge and none incorporate priors over multiple objectives. As DL practitioners often need to optimize not just one but many objectives, this is a blind spot in the algorithmic landscape of HPO. To address this shortcoming, we introduce PriMO, the first HPO algorithm that can integrate multi-objective user beliefs. We show PriMO achieves state-of-the-art performance across 8 DL benchmarks in the multi-objective and single-objective setting, clearly positioning itself as the new go-to HPO algorithm for DL practitioners.

</details>


### [80] [EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting](https://arxiv.org/abs/2511.08396)
*Zhiwei Zhang,Xinyi Du,Xuanchi Guo,Weihao Wang,Wenjuan Han*

Main category: cs.LG

TL;DR: EMAformer通过引入全局稳定性、相位敏感性和跨轴特异性三个关键归纳偏置，增强了Transformer在多元时间序列预测中的性能，在12个真实世界基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer架构在多元时间序列预测中取得了显著进展，但iTransformer仍然落后于最新的基于MLP的模型，作者认为这种性能差距源于不稳定的通道间关系。

Method: 提出EMAformer模型，通过引入三个关键归纳偏置（全局稳定性、相位敏感性和跨轴特异性）来增强Transformer，类似于为其配备增强能力的辅助嵌入套件。

Result: 在12个真实世界基准测试中实现了最先进的性能，平均将预测误差降低了2.73%（MSE）和5.15%（MAE）。

Conclusion: EMAformer显著推进了基于Transformer的方法在多元时间序列预测中的实际适用性。

Abstract: Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on https://github.com/PlanckChang/EMAformer.

</details>


### [81] [Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment](https://arxiv.org/abs/2511.08399)
*Hua Ye,Hang Ding,Siyuan Chen,Yiyang Jiang,Changyuan Zhang,Xuan Zhang*

Main category: cs.LG

TL;DR: BACL是一个轻量级的多模态模型增强模块，通过边界感知课程学习和局部注意力对比损失，有效处理模糊负样本对，显著提升跨模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型将所有负样本对同等对待，忽略了与正样本仅存在微小差异的模糊负样本对，这些边界情况对模型学习至关重要。

Method: 提出边界感知课程学习与局部注意力对比损失（BACL），包含边界感知负采样器和对比局部注意力损失两个模块，可微分且兼容现有双编码器架构。

Result: 理论分析预测O(1/n)的快速误差收敛率；实验在四个大规模基准测试上达到新SOTA，R@1指标相比CLIP提升高达32%，且无需额外标注。

Conclusion: BACL通过有效利用模糊负样本作为课程信号，显著提升了多模态表示学习性能，证明了边界案例在模型训练中的重要性。

Abstract: Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two modules are fully differentiable and work with any off-the-shelf dual encoder. Theory predicts a fast O(1/n) error rate; practice shows up to +32% R@1 over CLIP and new SOTA on four large-scale benchmarks, all without extra labels.

</details>


### [82] [ARAC: Adaptive Regularized Multi-Agent Soft Actor-Critic in Graph-Structured Adversarial Games](https://arxiv.org/abs/2511.08412)
*Ruochuan Shi,Runyu Lu,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: ARAC是一个用于图结构多智能体强化学习的自适应正则化方法，结合注意力图神经网络和自适应散度正则化机制，解决稀疏奖励问题并提升策略学习效率。


<details>
  <summary>Details</summary>
Motivation: 在图结构多智能体对抗任务中，智能体需要在高度动态的交互中协调，稀疏奖励问题严重阻碍了策略学习的效率。

Method: 提出ARAC框架，集成注意力图神经网络建模智能体依赖关系，并引入自适应散度正则化机制，早期利用参考策略进行高效探索，后期减少依赖以避免继承其局限性。

Result: 在追捕和对抗场景中的实验表明，ARAC相比基线方法实现了更快的收敛速度、更高的最终成功率以及更强的跨智能体数量可扩展性。

Conclusion: ARAC在复杂图结构环境中表现出色，有效解决了稀疏奖励问题并提升了多智能体协调学习的效果。

Abstract: In graph-structured multi-agent reinforcement learning (MARL) adversarial tasks such as pursuit and confrontation, agents must coordinate under highly dynamic interactions, where sparse rewards hinder efficient policy learning. We propose Adaptive Regularized Multi-Agent Soft Actor-Critic (ARAC), which integrates an attention-based graph neural network (GNN) for modeling agent dependencies with an adaptive divergence regularization mechanism. The GNN enables expressive representation of spatial relations and state features in graph environments. Divergence regularization can serve as policy guidance to alleviate the sparse reward problem, but it may lead to suboptimal convergence when the reference policy itself is imperfect. The adaptive divergence regularization mechanism enables the framework to exploit reference policies for efficient exploration in the early stages, while gradually reducing reliance on them as training progresses to avoid inheriting their limitations. Experiments in pursuit and confrontation scenarios demonstrate that ARAC achieves faster convergence, higher final success rates, and stronger scalability across varying numbers of agents compared with MARL baselines, highlighting its effectiveness in complex graph-structured environments.

</details>


### [83] [NeuCLIP: Efficient Large-Scale CLIP Training with Neural Normalizer Optimization](https://arxiv.org/abs/2511.08417)
*Xiyuan Wei,Chih-Jen Lin,Tianbao Yang*

Main category: cs.LG

TL;DR: NeuCLIP提出了一种新的对比学习优化框架，通过凸分析和变分分析将对比损失重新表述，使用紧凑神经网络预测对数归一化项，解决了传统方法在大数据集或小批量训练时的优化误差问题。


<details>
  <summary>Details</summary>
Motivation: 传统CLIP训练方法依赖大批次来估计归一化项，计算资源需求高。现有方法在更新编码器时会产生与数据集大小/批次大小比例相关的优化误差，限制了在大数据集或小批次下的有效性。

Method: 通过凸分析将每个样本的对比损失重新表述为带有辅助变量的最小化问题，然后通过变分分析将n个辅助变量的最小化转换为紧凑神经网络的最小化，设计交替优化算法联合训练CLIP模型和辅助网络。

Result: 在从百万到数十亿样本的大规模CLIP训练实验中，NeuCLIP相比之前方法实现了更准确的归一化项估计，获得了更好的性能表现。

Conclusion: NeuCLIP通过创新的优化框架解决了CLIP训练中的归一化项估计问题，在大规模数据集上表现出优越性能。

Abstract: Accurately estimating the normalization term (also known as the partition function) in the contrastive loss is a central challenge for training Contrastive Language-Image Pre-training (CLIP) models. Conventional methods rely on large batches for approximation, demanding substantial computational resources. To mitigate this issue, prior works introduced per-sample normalizer estimators, which are updated at each epoch in a blockwise coordinate manner to keep track of updated encoders. However, this scheme incurs optimization error that scales with the ratio of dataset size to batch size, limiting effectiveness for large datasets or small batches. To overcome this limitation, we propose NeuCLIP, a novel and elegant optimization framework based on two key ideas: (i) $\textbf{reformulating}$ the contrastive loss for each sample $\textbf{via convex analysis}$ into a minimization problem with an auxiliary variable representing its log-normalizer; and (ii) $\textbf{transforming}$ the resulting minimization over $n$ auxiliary variables (where $n$ is the dataset size) via $\textbf{variational analysis}$ into the minimization over a compact neural network that predicts the log-normalizers. We design an alternating optimization algorithm that jointly trains the CLIP model and the auxiliary network. By employing a tailored architecture and acceleration techniques for the auxiliary network, NeuCLIP achieves more accurate normalizer estimation, leading to improved performance compared with previous methods. Extensive experiments on large-scale CLIP training, spanning datasets from millions to billions of samples, demonstrate that NeuCLIP outperforms previous methods.

</details>


### [84] [Physics-Informed Neural Operators for Cardiac Electrophysiology](https://arxiv.org/abs/2511.08418)
*Hannah Lydon,Milad Kazemi,Martin Bishop,Nicola Paoletti*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的神经算子(PINO)方法来解决心脏电生理学中的偏微分方程问题，相比传统数值求解器和PINNs方法，PINO能够泛化到多种网格分辨率和初始条件，实现长期准确预测。


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器计算成本高且对离散化敏感，而深度学习模型需要大量数据且难以处理混沌动力学和长期预测。PINNs虽然通过物理约束缓解了部分问题，但仍受限于网格分辨率和长期预测稳定性。

Method: 使用物理信息神经算子(PINO)方法，学习函数空间之间的映射关系，能够泛化到不同网格分辨率和初始条件，支持零样本评估未见过的场景。

Result: PINO模型能够准确再现心脏电生理动力学，在长期滚动预测中保持高质量，可将预测分辨率扩展到训练分辨率的10倍，相比数值PDE求解器显著减少模拟时间。

Conclusion: PINO方法为高效、可扩展的心脏电生理模拟提供了有前景的解决方案，具有长期预测稳定性和分辨率可扩展性优势。

Abstract: Accurately simulating systems governed by PDEs, such as voltage fields in cardiac electrophysiology (EP) modelling, remains a significant modelling challenge. Traditional numerical solvers are computationally expensive and sensitive to discretisation, while canonical deep learning methods are data-hungry and struggle with chaotic dynamics and long-term predictions. Physics-Informed Neural Networks (PINNs) mitigate some of these issues by incorporating physical constraints in the learning process, yet they remain limited by mesh resolution and long-term predictive stability. In this work, we propose a Physics-Informed Neural Operator (PINO) approach to solve PDE problems in cardiac EP. Unlike PINNs, PINO models learn mappings between function spaces, allowing them to generalise to multiple mesh resolutions and initial conditions. Our results show that PINO models can accurately reproduce cardiac EP dynamics over extended time horizons and across multiple propagation scenarios, including zero-shot evaluations on scenarios unseen during training. Additionally, our PINO models maintain high predictive quality in long roll-outs (where predictions are recursively fed back as inputs), and can scale their predictive resolution by up to 10x the training resolution. These advantages come with a significant reduction in simulation time compared to numerical PDE solvers, highlighting the potential of PINO-based approaches for efficient and scalable cardiac EP simulations.

</details>


### [85] [HardFlow: Hard-Constrained Sampling for Flow-Matching Models via Trajectory Optimization](https://arxiv.org/abs/2511.08425)
*Zeyang Li,Kaveh Alim,Navid Azizan*

Main category: cs.LG

TL;DR: 提出了HardFlow框架，将硬约束采样重新表述为轨迹优化问题，利用数值最优控制在终端时间精确满足约束条件，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于投影的方法在整个采样路径上施加约束过于严格且会降低样本质量，需要一种能够在终端时间精确满足硬约束的新方法。

Method: 利用流匹配模型的结构和模型预测控制技术，将复杂约束优化问题转化为可高效求解的替代问题，通过轨迹优化实现约束满足。

Result: 在机器人规划、偏微分方程边界控制和文本引导图像编辑等多个领域的实验表明，HardFlow在约束满足和样本质量方面显著优于现有方法。

Conclusion: 提出的轨迹优化框架不仅能够精确满足硬约束，还能通过积分成本最小化分布偏移和终端目标增强样本质量，为约束生成提供了统一的解决方案。

Abstract: Diffusion and flow-matching have emerged as powerful methodologies for generative modeling, with remarkable success in capturing complex data distributions and enabling flexible guidance at inference time. Many downstream applications, however, demand enforcing hard constraints on generated samples (for example, robot trajectories must avoid obstacles), a requirement that goes beyond simple guidance. Prevailing projection-based approaches constrain the entire sampling path to the constraint manifold, which is overly restrictive and degrades sample quality. In this paper, we introduce a novel framework that reformulates hard-constrained sampling as a trajectory optimization problem. Our key insight is to leverage numerical optimal control to steer the sampling trajectory so that constraints are satisfied precisely at the terminal time. By exploiting the underlying structure of flow-matching models and adopting techniques from model predictive control, we transform this otherwise complex constrained optimization problem into a tractable surrogate that can be solved efficiently and effectively. Furthermore, this trajectory optimization perspective offers significant flexibility beyond mere constraint satisfaction, allowing for the inclusion of integral costs to minimize distribution shift and terminal objectives to further enhance sample quality, all within a unified framework. We provide a control-theoretic analysis of our method, establishing bounds on the approximation error between our tractable surrogate and the ideal formulation. Extensive experiments across diverse domains, including robotics (planning), partial differential equations (boundary control), and vision (text-guided image editing), demonstrate that our algorithm, which we name $\textit{HardFlow}$, substantially outperforms existing methods in both constraint satisfaction and sample quality.

</details>


### [86] [An update to PYRO-NN: A Python Library for Differentiable CT Operators](https://arxiv.org/abs/2511.08427)
*Linda-Sophie Schneider,Yipeng Sun,Chengze Ye,Markus Michen,Andreas Maier*

Main category: cs.LG

TL;DR: PYRO-NN是一个基于Python的可微分CT重建库的更新版本，扩展了对PyTorch的兼容性，并引入了原生CUDA内核支持，用于高效投影和反投影操作。


<details>
  <summary>Details</summary>
Motivation: 深度学习为X射线计算机断层扫描（CT）重建带来了显著进步，但需要将经典重建技术与数据驱动方法相结合。可微分算子在实现端到端优化和将物理建模融入神经网络中起着关键作用。

Method: 更新PYRO-NN库，扩展对PyTorch的兼容性，引入原生CUDA内核支持，支持并行、扇形和锥形束几何的高效投影和反投影操作，并提供模拟成像伪影、建模任意采集轨迹的工具。

Result: 开发了一个灵活的、端到端可训练的管道，通过高级Python API实现，代码已在GitHub上公开。

Conclusion: PYRO-NN的更新版本为CT重建提供了一个强大的工具，将经典重建技术与深度学习相结合，支持高效的端到端优化。

Abstract: Deep learning has brought significant advancements to X-ray Computed Tomography (CT) reconstruction, offering solutions to challenges arising from modern imaging technologies. These developments benefit from methods that combine classical reconstruction techniques with data-driven approaches. Differentiable operators play a key role in this integration by enabling end-to-end optimization and the incorporation of physical modeling within neural networks.
  In this work, we present an updated version of PYRO-NN, a Python-based library for differentiable CT reconstruction. The updated framework extends compatibility to PyTorch and introduces native CUDA kernel support for efficient projection and back-projection operations across parallel, fan, and cone-beam geometries. Additionally, it includes tools for simulating imaging artifacts, modeling arbitrary acquisition trajectories, and creating flexible, end-to-end trainable pipelines through a high-level Python API. Code is available at: https://github.com/csyben/PYRO-NN

</details>


### [87] [Coherence Mechanisms for Provable Self-Improvement](https://arxiv.org/abs/2511.08440)
*Mehryar Mohri,Jon Schneider,Yifan Wu*

Main category: cs.LG

TL;DR: 提出基于一致性的自改进理论框架，通过投影机制确保模型在任务保持变换下输出一致，并提供单调改进的理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有自改进方法依赖经验启发式而缺乏理论保证，需要建立具有严格理论保证的自改进框架。

Method: 使用投影机制更新基线模型，使其满足一致性要求同时保持与原始行为的接近度，包括直接和两步投影方法。

Result: 建立了单调改进的理论保证，适用于不可实现设置、经验分布和松弛一致性约束，并证明一致性是提供自改进保证的必要原则。

Conclusion: 一致性是提供可证明自改进的基本且必要的原则，任何具有类似改进保证的机制都必须符合基于一致性的结构。

Abstract: Self-improvement is a critical capability for large language models and other intelligent systems, enabling them to refine their behavior and internal consistency without external supervision. Despite its importance, prior approaches largely rely on empirical heuristics and lack formal guarantees. In this paper, we propose a principled framework for self-improvement based on the concept of \emph{coherence}, which requires that a model's outputs remain consistent under task-preserving transformations of the input.
  We formalize this concept using projection-based mechanisms that update a baseline model to be coherent while remaining as close as possible to its original behavior. We provide rigorous theoretical guarantees that these mechanisms achieve \emph{monotonic improvement}, measured by a reduction in expected Bregman divergence. Our analysis is comprehensive, covering both \emph{direct} and \emph{two-step} projection methods, and robustly extends these guarantees to non-realizable settings, empirical (finite-sample) distributions, and relaxed coherence constraints.
  Furthermore, we establish a general \emph{characterization theorem}, showing that any mechanism with similar provable improvement guarantees must inherently conform to a coherence-based structure. This culminates in rigidity results under the demand for universal improvement, establishing coherence as a fundamental and, in a formal sense, necessary principle for provable self-improvement.

</details>


### [88] [One Model for All: Universal Pre-training for EEG based Emotion Recognition across Heterogeneous Datasets and Paradigms](https://arxiv.org/abs/2511.08444)
*Xiang Li,You Li,Yazhou Zhang*

Main category: cs.LG

TL;DR: 提出'One Model for All'通用预训练框架，通过两阶段学习解决EEG数据集异质性问题，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: EEG情感识别面临严重的数据集异质性（通道/受试者变异性），阻碍了通用模型的发展，现有方法难以有效迁移知识

Method: 两阶段学习：1）基于统一通道模式的单变量自监督对比预训练；2）使用ART和GAT架构的多变量微调，捕捉复杂时空依赖

Result: 在SEED（99.27%）、DEAP（93.69%）和DREAMER（93.93%）上达到新的SOTA性能，跨数据集迁移在DREAMER上达到94.08%（交集）和93.05%（UCS）

Conclusion: 该框架为多样化的EEG分析任务开辟了更通用、可扩展和有效的预训练模型之路

Abstract: EEG-based emotion recognition is hampered by profound dataset heterogeneity (channel/subject variability), hindering generalizable models. Existing approaches struggle to transfer knowledge effectively. We propose 'One Model for All', a universal pre-training framework for EEG analysis across disparate datasets. Our paradigm decouples learning into two stages: (1) Univariate pre-training via self-supervised contrastive learning on individual channels, enabled by a Unified Channel Schema (UCS) that leverages the channel union (e.g., SEED-62ch, DEAP-32ch); (2) Multivariate fine-tuning with a novel 'ART' (Adaptive Resampling Transformer) and 'GAT' (Graph Attention Network) architecture to capture complex spatio-temporal dependencies. Experiments show universal pre-training is an essential stabilizer, preventing collapse on SEED (vs. scratch) and yielding substantial gains on DEAP (+7.65%) and DREAMER (+3.55%). Our framework achieves new SOTA performance on all within-subject benchmarks: SEED (99.27%), DEAP (93.69%), and DREAMER (93.93%). We also show SOTA cross-dataset transfer, achieving 94.08% (intersection) and 93.05% (UCS) on the unseen DREAMER dataset, with the former surpassing the within-domain pre-training benchmark. Ablation studies validate our architecture: the GAT module is critical, yielding a +22.19% gain over GCN on the high-noise DEAP dataset, and its removal causes a catastrophic -16.44% performance drop. This work paves the way for more universal, scalable, and effective pre-trained models for diverse EEG analysis tasks.

</details>


### [89] [Binary Split Categorical feature with Mean Absolute Error Criteria in CART](https://arxiv.org/abs/2511.08470)
*Peng Yu,Yike Chen,Chao Xu,Albert Bifet,Jesse Read*

Main category: cs.LG

TL;DR: 本文提出了一种新的高效分裂算法，用于在CART算法中使用MAE准则处理分类特征，证明了无监督数值编码方法在MAE准则下不可行。


<details>
  <summary>Details</summary>
Motivation: 传统上使用MAE准则处理分类特征依赖于各种数值编码方法，但这些方法存在局限性，需要更有效的解决方案。

Method: 提出了一种新颖高效的分裂算法，专门针对MAE准则下分类特征处理的挑战。

Result: 证明了无监督数值编码方法在MAE准则下不可行，新算法提供了有前景的解决方案。

Conclusion: 现有方法在处理分类特征时存在局限性，新算法能够增强CART算法中分类数据的处理能力。

Abstract: In the context of the Classification and Regression Trees (CART) algorithm, the efficient splitting of categorical features using standard criteria like GINI and Entropy is well-established. However, using the Mean Absolute Error (MAE) criterion for categorical features has traditionally relied on various numerical encoding methods. This paper demonstrates that unsupervised numerical encoding methods are not viable for the MAE criteria. Furthermore, we present a novel and efficient splitting algorithm that addresses the challenges of handling categorical features with the MAE criterion. Our findings underscore the limitations of existing approaches and offer a promising solution to enhance the handling of categorical data in CART algorithms.

</details>


### [90] [Clustering Guided Residual Neural Networks for Multi-Tx Localization in Molecular Communications](https://arxiv.org/abs/2511.08513)
*Ali Sonmez,Erencem Ozbey,Efe Feyzi Mantaroglu,H. Birkan Yilmaz*

Main category: cs.LG

TL;DR: 提出基于聚类的质心校正方法和两种聚类引导的残差神经网络，用于分子通信中多发射器的精确定位，相比K-means方法显著降低定位误差。


<details>
  <summary>Details</summary>
Motivation: 分子通信中多发射器定位是一个关键但具有挑战性的问题，主要由于扩散的随机性和接收器表面分子分布的重叠。

Method: 引入基于聚类的质心校正方法增强对密度变化和异常值的鲁棒性；提出两种聚类引导的残差神经网络：AngleNN用于方向细化，SizeNN用于簇大小估计。

Result: 实验结果显示，相比K-means方法，定位误差显著降低，在2-Tx情况下减少69%，在4-Tx情况下减少43%。

Conclusion: 所提出的方法在分子通信多发射器定位中表现出显著性能提升，为解决扩散随机性和分子分布重叠问题提供了有效解决方案。

Abstract: Transmitter localization in Molecular Communication via Diffusion is a critical topic with many applications. However, accurate localization of multiple transmitters is a challenging problem due to the stochastic nature of diffusion and overlapping molecule distributions at the receiver surface. To address these issues, we introduce clustering-based centroid correction methods that enhance robustness against density variations, and outliers. In addition, we propose two clusteringguided Residual Neural Networks, namely AngleNN for direction refinement and SizeNN for cluster size estimation. Experimental results show that both approaches provide significant improvements with reducing localization error between 69% (2-Tx) and 43% (4-Tx) compared to the K-means.

</details>


### [91] [LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics](https://arxiv.org/abs/2511.08544)
*Randall Balestriero,Yann LeCun*

Main category: cs.LG

TL;DR: LeJEPA是一个理论完备、轻量级的联合嵌入预测架构训练目标，通过SIGReg正则化约束嵌入分布为各向同性高斯分布，实现高效稳定的自监督预训练。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA方法缺乏理论指导和实用规范，导致研发过程随意。需要建立完整的JEPA理论框架并提供简单有效的实现方案。

Method: 提出Sketched Isotropic Gaussian Regularization (SIGReg)作为正则化项，将JEPA预测损失与SIGReg结合形成LeJEPA目标，约束嵌入分布达到理想状态。

Result: 在10+数据集、60+架构上验证，LeJEPA在ImageNet-1k预训练和线性评估中达到79%准确率（ViT-H/14），具有超参数稳定、线性复杂度、无需启发式技巧等优势。

Conclusion: LeJEPA的简洁性和理论完备性使其成为自监督预训练的核心支柱，为AI研究提供了理论友好的生态系统。

Abstract: Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&D. We present a comprehensive theory of JEPAs and instantiate it in {\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\href{git@github.com:rbalestr-lab/lejepa.git}{GitHub repo}).

</details>


### [92] [FMMI: Flow Matching Mutual Information Estimation](https://arxiv.org/abs/2511.08552)
*Ivan Butakov,Alexander Semenenko,Alexey Frolov,Ivan Oseledets*

Main category: cs.LG

TL;DR: 提出了一种新的互信息估计器，通过使用归一化流将联合分布转换为边际分布，而不是训练分类器来区分它们。


<details>
  <summary>Details</summary>
Motivation: 传统的互信息估计方法使用分类器来区分联合分布和边际分布，这种方法在高维和广泛互信息值范围内存在局限性。

Method: 学习一个归一化流，将联合分布转换为边际分布，从而计算互信息。

Result: 该方法计算效率高、精度好，能够很好地扩展到高维和广泛的真实互信息值范围。

Conclusion: 提出的归一化流方法为互信息估计提供了一种新颖且有效的替代方案。

Abstract: We introduce a novel Mutual Information (MI) estimator that fundamentally reframes the discriminative approach. Instead of training a classifier to discriminate between joint and marginal distributions, we learn a normalizing flow that transforms one into the other. This technique produces a computationally efficient and precise MI estimate that scales well to high dimensions and across a wide range of ground-truth MI values.

</details>


### [93] [The Path Not Taken: RLVR Provably Learns Off the Principals](https://arxiv.org/abs/2511.08567)
*Hanqing Zhu,Zhenyu Zhang,Hanxian Huang,DiJia Su,Zechun Liu,Jiawei Zhao,Igor Fedorov,Hamed Pirsiavash,Zhizhou Sha,Jinwon Lee,David Z. Pan,Zhangyang Wang,Yuandong Tian,Kai Sheng Tai*

Main category: cs.LG

TL;DR: RLVR（带可验证奖励的强化学习）通过非主方向权重更新实现性能提升，其参数稀疏性是模型条件优化偏差的表面现象，而非真实稀疏性。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR中看似参数稀疏但性能提升显著的矛盾，揭示其背后的优化机制，理解RL与SFT在参数空间中的本质差异。

Method: 提出三门理论：KL锚定门、模型几何门和精度门，通过参数级分析验证RLVR在权重空间中的学习动态。

Result: RLVR通过最小化谱漂移、减少主空间旋转和非主方向更新对齐实现性能提升，而SFT则针对主权重并扭曲频谱。

Conclusion: RL在优化机制上与SFT存在本质差异，直接套用SFT时代的参数高效微调方法存在缺陷，需要设计几何感知的RLVR原生学习算法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.
  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.

</details>


### [94] [Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms](https://arxiv.org/abs/2511.08570)
*Jamison Moody,James Usevitch*

Main category: cs.LG

TL;DR: AdaptKAN是一种改进的Kolmogorov-Arnold网络，通过自动调整域网格来消除手动调整需求，同时保持KAN的优势如可解释性和高精度。


<details>
  <summary>Details</summary>
Motivation: 原始KAN架构需要手动调整域网格，给训练过程带来额外负担，且缺乏根据前层输出范围自动更新域的能力。

Method: 提出AdaptKAN，使用直方图算法自动调整域网格，该算法也可用于检测分布外输入。

Result: 在四个任务上表现优于或匹配先前KAN架构和MLP：Feynman数据集学习科学方程、图像分类、学习控制Lyapunov函数、OpenOOD v1.5基准上的分布外输入检测。

Conclusion: AdaptKAN通过自动域网格调整简化了KAN训练，同时保持了性能优势，并在多个任务上验证了有效性。

Abstract: Kolmogorov-Arnold Networks (KANs) are a class of neural networks that have received increased attention in recent literature. In contrast to MLPs, KANs leverage parameterized, trainable activation functions and offer several benefits including improved interpretability and higher accuracy on learning symbolic equations. However, the original KAN architecture requires adjustments to the domain discretization of the network (called the "domain grid") during training, creating extra overhead for the user in the training process. Typical KAN layers are not designed with the ability to autonomously update their domains in a data-driven manner informed by the changing output ranges of previous layers. As an added benefit, this histogram algorithm may also be applied towards detecting out-of-distribution (OOD) inputs in a variety of settings. We demonstrate that AdaptKAN exceeds or matches the performance of prior KAN architectures and MLPs on four different tasks: learning scientific equations from the Feynman dataset, image classification from frozen features, learning a control Lyapunov function, and detecting OOD inputs on the OpenOOD v1.5 benchmark.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [95] [Quasi-Periodic Oscillations and Parameter Constraints in ModMax Black Holes](https://arxiv.org/abs/2511.07487)
*Mozib Bin Awal,Bidyut Hazarika,Prabwal Phukon*

Main category: gr-qc

TL;DR: 研究ModMax参数对黑洞周围测试粒子动力学和准周期振荡(QPOs)特征的影响，发现增加η参数会导致从RN黑洞向史瓦西黑洞的连续过渡，并对最内稳定圆轨道(ISCO)和开普勒频率产生显著改变。


<details>
  <summary>Details</summary>
Motivation: 探索ModMax参数在黑洞物理中的作用，特别是其对测试粒子轨道动力学和QPOs观测特征的影响，为理解黑洞周围的强引力场效应提供新视角。

Method: 使用有效势、角动量和圆形轨道能量分析ModMax参数的影响，并在PR、RP、WD和ER模型框架下研究QPO半径对η参数的依赖性，最后使用MCMC方法分析多尺度黑洞源的QPO观测数据。

Result: 增加ModMax参数η会导致ISCO半径减小，开普勒频率发生变化，QPO特征半径对η参数表现出明显依赖性，MCMC分析为η参数提供了观测约束。

Conclusion: ModMax参数在黑洞动力学中起重要作用，通过影响粒子轨道和QPO特征，为理解黑洞周围的引力效应提供了新的理论框架和观测约束。

Abstract: We analyze the impact of ModMax parameter on the dynamics of test particles around black holes and its effect on the characteristics of Quasi-Periodic Oscillations (QPOs). The effect of the ModMax parameter $η$ is studied using the effective potential, angular momentum and the energy of the circular orbits of the test particles. Our analysis shows that increasing $η$ brings about a continuous transition from the RN regime toward the Schwarzschild limit, accompanied by noticeable modifications in the Innermost Stable Circular Orbit (ISCO) and the corresponding Keplerian frequencies. We also explore the dependence of QPO radii on the ModMax parameter $η$ within the framework of the PR, RP, WD, and ER models. Finally, to place observational constraints, we perform a Markov Chain Monte Carlo (MCMC) analysis using QPO data from a range of black hole sources spanning stellar-mass, intermediate-mass, and supermassive scales.

</details>


### [96] [Quasinormal Mode Spectroscopy via Horizon-Brightened Quantum Optics](https://arxiv.org/abs/2511.07488)
*Ali Övgün*

Main category: gr-qc

TL;DR: 该论文开发了一个量子光学框架，利用两级原子探测黑洞准正规模，将黑洞准正规模解释为非厄米腔模，并建立了类似迪克激光的模型。


<details>
  <summary>Details</summary>
Motivation: 建立黑洞准正规模与量子光学系统之间的联系，为黑洞光谱学提供一个统一的理论框架，连接黑洞环降、近视界共形量子力学和量子光学。

Method: 从静态球对称黑洞背景中标量场的Wightman函数出发，推导Unruh-DeWitt探测器的响应函数；将主导准正规模视为有效非厄米腔模，与驱动两级原子系综耦合，推导迪克激光型主方程。

Result: 准正规模在探测器谱中产生一组洛伦兹共振，共振位置由准正规模频率的实部决定，宽度由虚部决定；激光阈值条件明确依赖于准正规模阻尼率。

Conclusion: 该框架为黑洞光谱学提供了统一的量子光学语言，在引力波时代丰富了黑洞光谱学的研究方法，建立了黑洞准正规模与量子光学系统之间的直接联系。

Abstract: We develop a quantum optical framework for probing black hole quasinormal modes (QNMs) using two-level atoms in the spirit of the horizon-brightened acceleration radiation (HBAR) program. Starting from the QNM contribution to the Wightman function of a scalar field on a static, spherically symmetric black hole background, we derive the response function of a two-level Unruh--DeWitt detector following simple trajectories (static at fixed radius, with comments on radial free fall). The QNM sector imprints a set of Lorentzian resonances in the detector spectrum at the redshifted real parts of the QNM frequencies, with widths determined by the imaginary parts. We then treat a single dominant QNM as an effective non-Hermitian cavity mode coupled to an ensemble of driven two-level atoms, and derive a master equation of Dicke laser type. The resulting lasing threshold condition depends explicitly on the QNM damping rate, providing a direct quantum optical interpretation of the imaginary part of the QNM frequency. Specializing to the Schwarzschild geometry, we express the resonant frequencies, linewidths, and threshold in terms of photon-sphere data in the eikonal limit. We discuss several extensions and propose our framework as a unifying language connecting black hole ringdown, near-horizon conformal quantum mechanics, and quantum optics, thereby enriching the emerging program of black hole spectroscopy in the gravitational-wave era.

</details>


### [97] [Tests of General Relativity with Einstein Telescope](https://arxiv.org/abs/2511.07520)
*Andrea Begnoni,Walter Del Pozzo,Matteo Pegorin,Joachim Pomper,Angelo Ricciardone*

Main category: gr-qc

TL;DR: 使用第三代引力波探测器（爱因斯坦望远镜）通过费希尔矩阵方法预测对广义相对论的测试精度，预计可达到10^-7量级的偶极辐射项精度和10^-3量级的高阶后牛顿系数精度。


<details>
  <summary>Details</summary>
Motivation: 利用紧凑双星并合产生的引力波信号作为广义相对论的有力探测工具，解决第三代引力波探测器高探测率带来的计算挑战。

Method: 采用费希尔矩阵方法模拟参数估计，通过贝叶斯层次分析方法联合分析事件，研究不同探测器配置下的约束能力。

Result: 爱因斯坦望远镜可达到偶极辐射项10^-7精度和高阶后牛顿系数10^-3精度，需要10^4个目录事件。

Conclusion: 第三代引力波探测器能够以前所未有的精度测试广义相对论，为识别与广义相对论的偏差提供了可靠手段。

Abstract: Gravitational wave signals from compact binary coalescences offer a powerful and reliable probe of General Relativity. To date, the LIGO-Virgo-KAGRA collaboration has provided stringent consistency tests of General Relativity predictions. In this work, we present forecasts for the accuracy with which General Relativity can be tested using third-generation ground-based interferometers, focusing on Einstein Telescope (ET) and binary black hole mergers. Given the expected high detection rate, performing full Bayesian analyses for each event becomes computationally challenging. To overcome this, we adopt a Fisher matrix approach, simulating parameter estimation in an idealized observation scenario, which allows us to study large populations of compact binary coalescences with feasible computational efforts. Within this framework, we investigate the constraints that ET, in its different configurations, can impose on inspiral post-Newtonian coefficients, by jointly analyzing events using a Bayesian hierarchical methodology. Our results indicate that ET could in principle achieve an accuracy of $\mathcal{O}(10^{-7})$ on the dipole radiation term and $\mathcal{O}(10^{-3})$ on higher-order post-Newtonian coefficients, for both the triangular and the two L-shaped designs, with $10^4$ catalog events. We also assess the number of detections required to confidently identify deviations from General Relativity at various post-Newtonian orders and for different detector configurations.

</details>


### [98] [Algebraic classification of 2+1 geometries](https://arxiv.org/abs/2511.07621)
*Matus Papajcik,Jiri Podolsky*

Main category: gr-qc

TL;DR: 提出了一种基于五个实标量的2+1维几何代数分类新方法，通过Cotton张量在零基上的投影来分类时空，并建立了与先前分类方法的等价性。


<details>
  <summary>Details</summary>
Motivation: 开发更有效的2+1维时空代数分类方法，简化分类过程并提供框架无关的算法。

Method: 使用五个实标量（Cotton张量在合适零基上的特定投影）来分类时空，通过这些标量的逐步消失确定代数类型，并基于多项式曲率不变量提供框架无关的分类算法。

Result: 推导了Bel-Debever判据和Cotton对齐零方向的多重性，建立了与先前分类方法的等价性。

Conclusion: 该方法提供了一种简单有效的2+1维时空代数分类方案，具有框架无关性和与现有方法的兼容性。

Abstract: We present a new effective method of algebraic classification of 2+1 geometries. Our approach simply classifies spacetimes using five real scalars, defined as specific projections of the Cotton tensor onto a suitable null basis. The algebraic type of a spacetime is determined by gradual vanishing of these scalars. We derive the Bel-Debever criteria, together with the multiplicity of the Cotton aligned null directions (CANDs). Additionally, we provide a frame-independent algorithm for classification based on the polynomial curvature invariants and show the equivalence to previous methods of classification.

</details>


### [99] [From harmonic to Newman-Unti coordinates at the second post-Minkowskian order](https://arxiv.org/abs/2511.07647)
*Pujian Mao,Baijun Zeng*

Main category: gr-qc

TL;DR: 本文提供了从谐和坐标到Newman-Unti坐标的完整度规变换，直至二阶后Minkowskian阶(G²)，并确定了渐近剪切、Bondi质量方面和角动量方面。


<details>
  <summary>Details</summary>
Motivation: 研究广义相对论中不同坐标系之间的变换，特别是在后Minkowskian近似下，这对于理解引力波的渐近行为和守恒量至关重要。

Method: 使用从谐和坐标到Newman-Unti坐标的度规变换方法，计算至二阶后Minkowskian阶(G²)。

Result: 成功确定了渐近剪切、Bondi质量方面和角动量方面在两个阶次上的表达式。

Conclusion: 该工作为研究引力波的渐近性质和守恒定律提供了重要的数学工具和结果。

Abstract: In this paper, we present the complete transformations of a generic metric from harmonic to Newman-Unti coordinates up to the second post-Minkowskian order $(G^2)$. This allows us to determine the asymptotic shear, the Bondi mass aspect, and the angular-momentum aspect at both orders.

</details>


### [100] [Anomaly in canonical semiclassical gravity](https://arxiv.org/abs/2511.07753)
*Viqar Husain,Irfan Javed*

Main category: gr-qc

TL;DR: 经典半经典爱因斯坦方程的标准表述存在不一致性，因为相应的约束代数不封闭。


<details>
  <summary>Details</summary>
Motivation: 研究半经典爱因斯坦方程在量子引力背景下的数学一致性，特别是约束代数的闭合性问题。

Method: 分析半经典爱因斯坦方程中物质项被量子态算符期望值替代后的约束代数结构。

Result: 发现约束代数不封闭，表明标准表述存在内在不一致性。

Conclusion: 标准半经典爱因斯坦方程表述在数学上不一致，需要重新考虑其理论基础。

Abstract: We show that the canonical formulation of the semiclassical Einstein equation, where the matter terms in the constraints are replaced by expectation values of the corresponding operators in quantum states, is inconsistent due to the non-closure of the resulting constraint algebra.

</details>


### [101] [Ringdown of a black hole embedded in a Burkert dark matter halo](https://arxiv.org/abs/2511.07858)
*Yi Yang,Gaetano Lambiase,Ali Ovgun,Dong Liu,Zheng-Wen Long*

Main category: gr-qc

TL;DR: 构建了嵌入Burkert暗物质晕的静态球对称黑洞时空，研究了标量、矢量和张量场的线性扰动及其准正规模谱，发现暗物质晕参数会改变黑洞环降的频率和阻尼特性。


<details>
  <summary>Details</summary>
Motivation: 研究暗物质晕如何影响中心黑洞的引力波环降信号，为未来通过引力波探测暗物质晕性质提供理论基础。

Method: 从旋转曲线关系确定暗物质晕几何，求解爱因斯坦方程并施加Schwarzschild边界条件，获得闭合形式的度规函数；使用高阶WKB方法和连分式方法计算准正规模谱，辅以时域演化验证。

Result: 增加Burkert核心半径或中心密度会提高准正规模实部频率并增强阻尼；多极指数主要增加振荡频率而对衰减率影响较小；两种频率提取方法在参数空间内具有良好一致性。

Conclusion: 暗物质晕环境会在黑洞环降信号中留下可观测的印记，为未来引力波测试暗物质晕性质提供了基准参考。

Abstract: We construct a new static, spherically symmetric black hole spacetime embedded in a dark matter halo whose density follows the cored Burkert profile. Starting from the halo-only geometry determined by the rotation curve relation, we solve the Einstein equations with the Burkert stress-energy and enforce a Schwarzschild boundary condition, obtaining closed form metric functions in which the halo contribution deforms the redshift or shape functions and reduces to the Schwarzschild limit when the halo parameters vanish. On this background we study linear perturbations of test fields with spins $s=0,1,2$ and compute their quasinormal spectra using both a high order WKB scheme and continued fraction method, complemented by time domain evolutions. We find that increasing either the Burkert core radius $r_0$ or the central density $ρ_0$ generically shifts the real part of the frequencies upward and enhances damping, while the multipole index $l$ primarily increases the oscillation frequency with a milder impact on the decay rate. The two frequency extraction methods agree to within small, systematic offsets across the explored parameter space. Our results quantify how a cored dark matter environment imprints itself on the ringdown of a central black hole and provide benchmarks for future gravitational wave tests of halo properties.

</details>


### [102] [The Influence of Stable Photon Sphere Advent on Orbital Precession in moving towards the Extremality: Periapsis Shift as a Gateway to the Weak Gravity Conjecture](https://arxiv.org/abs/2511.07902)
*Mohammad Ali S. Afshar,Jafar Sadeghi*

Main category: gr-qc

TL;DR: 本文研究了黑洞质量变化对测试粒子近日点进动的影响，探讨了极值极限下的近日点进动能否作为弱引力猜想的证据，并分析了在Aschenbach条件下稳定光子球对相对论进动的动力学影响。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞动态质量变化对轨道动力学的影响，特别是检验弱引力猜想在黑洞蒸发过程中保持黑洞完整性的作用，以及稳定光子球对相对论进动的动力学效应。

Method: 采用静态逐帧方法，假设单帧内质量恒定但允许帧间质量演化，研究质量损失对轨道动力学的影响。分析极值极限和Aschenbach条件下的近日点进动。

Result: 研究发现近日点进动不仅其大小，其定性轨道行为（包括顺行到逆行的转变和径向依赖性）为强场区域中的弱引力猜想提供了有意义的实验探针。

Conclusion: 近日点进动可以作为弱引力猜想在强场区域的有力实验验证工具，揭示了极值性和稳定光子球共同作用下对进动特性的深刻改变。

Abstract: While the effects of solar mass change can be neglected in studies of solar periapsis shifts-given the relevant timescales and magnitude of change-the influence of a black hole's dynamic and chaotic mass variation on the Periapsis Shift of test particles in its surrounding spacetime demands a detailed and meticulous investigation. Recognizing that black hole mass variation is inherently a continuous and dynamic process, but the extended timescales required for such variations allow us, to employ a static, frame-by-frame approach. We're assuming constant mass within individual frames, while permitting inter-frame mass evolution to prob the effects of mass loss on orbital dynamics. Using this method, we investigate whether the Periapsis Shift in the extremal limit can serve as evidence for the Weak Gravity Conjecture (WGC), addressing the conjecture's role in preserving black hole integrity during evaporation. Subsequently, we analyze the Periapsis Shift under Aschenbach-like conditions, where a stable photon sphere generates non-monotonic orbital velocity profiles, to assess its dynamical impact on relativistic precession. Finally, we synthesize the combined effects of extremality and the presence of stable photon sphere, revealing profound modifications to the Periapsis Shift profile, including prograde-to-retrograde transitions and radial dependencies. Our results demonstrate that the Periapsis Shift--not merely its magnitude but its qualitative orbital behavior--allows a meaningful experimental probe for the WGC in strong-field regimes.

</details>


### [103] [Detecting Parity-Violating Gravitational Wave Backgrounds with Pulsar Polarization Arrays](https://arxiv.org/abs/2511.07956)
*Qiuyue Liang,Kimihiro Nomura,Hidetoshi Omiya*

Main category: gr-qc

TL;DR: 该论文研究了利用脉冲星偏振阵列探测各向同性随机引力波背景的圆偏振分量，该方法能够表征宇称破坏。通过几何光学推导了电磁波偏振在引力波背景传播中的旋转效应，并展示了时序-偏振关联能够分离出引力波的圆偏振分量。


<details>
  <summary>Details</summary>
Motivation: 脉冲星时序阵列对纳赫兹频段的各向同性随机引力波背景敏感，但无法探测其宇称破坏分量。最近脉冲星偏振阵列的进展为探测引力波的圆偏振提供了可能，这有助于研究宇称破坏现象。

Method: 基于几何光学理论，推导了电磁波偏振在引力波背景传播中的旋转效应。通过分析脉冲星时序信号与偏振信号的交叉关联，分离出引力波的圆偏振分量。该方法具有与Hellings-Downs角模式相同的关联模式。

Result: 研究表明，时序-偏振关联能够有效分离引力波的圆偏振分量。未来设施如SKA可使该方法达到与当前天体测量方法相当的灵敏度。

Conclusion: 脉冲星偏振阵列为探测各向同性随机引力波背景的圆偏振分量提供了新途径，有望在宇称破坏研究方面取得重要进展，未来观测设施将进一步提升探测灵敏度。

Abstract: Pulsar timing arrays probe isotropic stochastic gravitational wave (GW) backgrounds in the nanohertz band but are insensitive to its parity-violating component. Motivated by recent progress in pulsar polarization arrays, we study the response of pulsar polarimetry to GWs and evaluate its potential to detect circular polarization in isotropic stochastic GW backgrounds, which characterizes parity violation. Based on geometric optics, we derive the rotation of the polarization of electromagnetic waves induced by propagation through a GW background. We show that the cross-correlation between pulsar timing and polarimetry signals isolates the circular polarization component from the GW intensity, sharing the same Hellings-Downs angular pattern. With future facilities such as the SKA, timing-polarimetry correlations could reach sensitivities to the circular polarization of GWs comparable to those of the current astrometric methods.

</details>


### [104] [Decoding Horizonless Spacetime: Plasma-Induced Features in a Rotating Wormhole Shadow](https://arxiv.org/abs/2511.07967)
*Pabitra Gayen,Ratna Koley*

Main category: gr-qc

TL;DR: 研究旋转虫洞在等离子体环境下的阴影特性，分析几何参数、等离子体参数和观测角度对阴影形态的影响，并与Kerr黑洞进行对比以识别区分特征。


<details>
  <summary>Details</summary>
Motivation: 在现实天体物理条件下，特别是等离子体环境中，研究旋转虫洞的阴影特性，为区分虫洞与黑洞提供观测特征。

Method: 使用Hamilton-Jacobi形式推导轨道方程，考虑等离子体作为色散介质，分析均匀和非均匀等离子体对阴影的影响，并与Kerr黑洞进行对比。

Result: 基于观测数据对虫洞参数施加严格约束，发现阴影边界偏离圆度参数ΔC对约束参数作用有限，而平均阴影半径偏离参数δ能提供有效约束。

Conclusion: 旋转虫洞在等离子体环境下的阴影特征与Kerr黑洞存在可区分的差异，这些特征可用于识别类似类型的致密天体。

Abstract: We investigate the shadow properties in a recently proposed geometry of a rotating wormhole under realistic astrophysical conditions, particularly in the presence of a cold and non magnetized plasma environment surrounding the wormhole throat. Using the Hamilton Jacobi formalism, we derive the orbit equation under specific plasma density profiles, where we consider plasma as dispersive medium and disregard its influence on the background geometry. The electron density distribution is chosen to preserve a generalized Carter constant. We explore the shadow cast by this class of rotating wormhole in the presence of both homogeneous and non homogeneous plasma as seen by an asymptotic observer. The photon regions are visualized, and the influence of geometric parameters, plasma parameters, and the observer inclination angle with the rotation axis on the resulting shadow morphology is analyzed. We tried to implement constraints on the plasma and the geometrical parameters of the wormhole such as the spin parameter and the deviation (from Kerr) parameter in the back drop of recent observational bounds coming from the deviation from circularity of the shadow boundary ($ΔC$) and deviation of the average shadow radius from Schwarzschild ($δ$). The bound on $ΔC$ is satisfied by the theoretically allowed range of parameters thus not found very useful to put any constraint, we could impose stringent constraints on the parameters based on the observed value of $δ$. By comparing the optical characteristics of the image of these wormholes with those of Kerr black holes under analogous plasma conditions, we identify the features that could serve as discriminants for similar types of compact objects.

</details>


### [105] [Solar-system experimental constraints on nonlocal gravity](https://arxiv.org/abs/2511.07981)
*Yunlong Liu,Yongbin Du*

Main category: gr-qc

TL;DR: 本文通过四类高精度太阳系实验（星光偏折、夏皮罗时延、近日点进动、测地线进动）对Deser-Woodard非局部引力模型的参数(ζ,b)施加约束，发现不同实验对参数的敏感度不同，最终得到参数空间的明确允许区域。


<details>
  <summary>Details</summary>
Motivation: 研究Deser-Woodard非局部引力模型在静态球对称背景下的参数约束，验证该理论模型与高精度太阳系观测数据的一致性。

Method: 从测地线方程推导可直接与VLBI/VLBA天体测量、卡西尼时延测量、MESSENGER数据和GP-B/LLR结果比较的几何可观测量，分析四类太阳系实验对模型参数的约束能力。

Result: 发现较大的b值会更快地抑制非局部效应，从而削弱对ζ的约束。近日点进动在b≈1.06附近对ζ最敏感，提供最严格的单实验界限，而远离此区域时夏皮罗时延主导联合约束。

Conclusion: 结合所有四个实验可以得到参数空间(ζ,b)的明确定义和严格界限的允许区域，为验证非局部引力模型提供了重要约束。

Abstract: In this work, we study the constraints on the characteristic parameters $(ζ,b)$ of the Deser-Woodard nonlocal gravity model in a static and spherically symmetric background, using four classes of high-precision Solar-System experiments: stellar light deflection, Shapiro time delay, perihelion advance, and geodetic precession. From geodesic equations, we derive observable geometric quantities that can be directly compared with VLBI/VLBA astrometry, the Cassini time-delay measurement, MESSENGER data and the GP-B/LLR results. Our results show that a larger value of $b$ suppresses the nonlocal effect more rapidly with radius, thereby weakening the overall constraints on $ζ$. The perihelion advance exhibits the strongest sensitivity to $ζ$ around $b\simeq 1.06$, providing the tightest single experiment bound, whereas away from this region the combined constraint becomes dominated by the Shapiro time delay. Incorporating all four experiments yields a well-defined and sharply bounded allowed region for the parameter space $(ζ,b)$.

</details>


### [106] [Gravitational-wave dispersion over inhomogeneous space-times: General relativity, screened theories of gravity and non-minimal dark energy](https://arxiv.org/abs/2511.08023)
*Nicola Menadeo,Serena Giardino,Miguel Zumalacárregui*

Main category: gr-qc

TL;DR: 论文研究了引力波在非最小引力理论中的色散效应，特别是透镜诱导色散(LID)，发现在对称子引力等修正理论中会产生增强的色散效应，甚至可能使某些天体成为引力波反射器。


<details>
  <summary>Details</summary>
Motivation: 引力波是探测宇宙引力的直接工具，能够探测传播路径上的时空不均匀性。通过研究引力波在不同引力理论中的色散效应，可以测试修正引力理论，特别是与暗能量相关的理论。

Method: 计算了广义相对论中球对称物质分布的引力波色散，然后扩展到标量-张量理论，重点关注对称子引力作为筛选理论的例子。

Result: 发现对称子引力参数空间的大区域中引力波色散增强，某些情况下天体可能成为引力波反射器。地球在未受约束的参数空间区域会成为有效的引力波屏蔽体，导致约50%的事件无法观测或探测器响应发生显著改变。

Conclusion: 非最小理论中色散现象的丰富性和普遍性为测试动态暗能量理论开辟了新途径，这对于挑战ΛCDM范式的最新观测结果具有重要意义。

Abstract: Gravitational waves (GWs) are direct probes of cosmological gravity, sensitive to space-time inhomogeneities along their propagation. The presence of massive objects breaks homogeneity and isotropy, allowing for new interactions between different GW polarizations, and opening up the intriguing opportunity to test modified gravity theories. This setup generalizes the notion of gravitational deflection and lensing, revealing novel phenomena in modified theories. Any non-minimal theory introduces effective mass terms for GWs, causing \textit{lens-induced dispersion} (LID), a frequency-dependent phase shift on the waveform. We compute GW dispersion in Einstein's general relativity (GR) for a spherical matter distribution, finding a small but non-zero phasing that is potentially accessible to next-generation detectors. We then extend our analysis to scalar-tensor theories, focusing on symmetron gravity as an example of screened theory, combining cosmological deviations and consistency with local gravity tests. We find enhanced GW dispersion in a large region of the symmetron parameter space, compared to both GR and Brans-Dicke theory. We argue that dispersion, associated to an effective mass for the metric fluctuations, can in some cases prevent the propagation of GWs through some astrophysical bodies, turning them into reflectors. Our analysis shows that the Earth becomes an efficient GW shield for a hitherto unconstrained region of the symmetron parameter space, leading to a $\sim 50\%$ fraction of events becoming unobservable or at least displaying a dramatic modification of the detector antenna response. The richness and universality of dispersive phenomena in non-minimal theories open a new avenue to test theories of dynamical dark-energy, relevant in light of recent observational results challenging the $Λ$CDM paradigm.

</details>


### [107] [Extreme mass ratio inspirals into black holes surrounded by matter: Resonance crossings](https://arxiv.org/abs/2511.08057)
*Michal Stratený,Georgios Lukes-Gerakopoulos,Ondřej Zelenka*

Main category: gr-qc

TL;DR: 本文系统比较了三种计算极端质量比旋进引力波通量的方法，发现四极矩公式与Teukolsky方程结果在广泛轨道配置下保持一致，并开发了新的数值方法来研究共振穿越动力学。


<details>
  <summary>Details</summary>
Motivation: 为LISA探测极端质量比旋进系统做准备，需要精确建模引力波形，特别是处理轨道共振期间两个基本轨道频率成比例的情况。

Method: 比较了四极矩公式、后牛顿近似和Teukolsky方程时域解三种通量计算方法，并引入了新的数值方法来降低计算成本。

Result: 四极矩通量与Teukolsky结果在包括扰动轨道在内的广泛轨道配置下保持良好一致性，揭示了共振穿越的多样化行为。

Conclusion: 这些结果有助于理论上理解和充分建模EMRI过程中的共振穿越现象，为LISA观测提供支持。

Abstract: The forthcoming space-based gravitational-wave observatory Laser Interferometer Space Antenna (LISA) should enable the detection of Extreme Mass Ratio Inspirals (EMRIs), in which a stellar-mass compact object gradually inspirals into a supermassive black hole while emitting gravitational waves. Modeling the waveforms of such systems is a challenging task, requiring precise computation of energy and angular momentum fluxes as well as proper treatment of orbital resonances, during which two fundamental orbital frequencies become commensurate. In this work, we perform a systematic comparison of fluxes derived from three approaches: the quadrupole formula, post-Newtonian approximations, and time-domain solutions of the Teukolsky equation. We show that quadrupole-based fluxes remain in good agreement with Teukolsky results across a broad range of orbital configurations, including perturbed orbits. Building on these insights, we explore the dynamical impact of resonance crossings within the adiabatic approximation. By introducing novel numerical methods, we reduce computational costs and uncover diverse resonance-crossing behaviors. These results contribute to the effort to understand theoretically and model adequately resonance crossings during an EMRI.

</details>


### [108] [Directional Quantum Singularities in Curzon Spacetime](https://arxiv.org/abs/2511.08190)
*M. Mangut,O. Gurtug,M. Halilsoy*

Main category: gr-qc

TL;DR: 将Horowitz-Marolf标量量子探针方法应用于柱对称Curzon解，发现不带电Curzon时空的经典强奇点在量子场论中变得正则，而带电版本由于出现额外奇点而无法量子正则化。


<details>
  <summary>Details</summary>
Motivation: Curzon解是研究方向性奇点的经典例子，作者希望探索量子场论如何影响这类奇点的行为，特别是比较经典和量子视角下的奇点性质。

Method: 应用Horowitz和Marolf开发的标量量子探针方法分析柱对称Curzon解，分别研究不带电和带电（电、磁、双荷）版本。

Result: 不带电Curzon时空在r=0处的经典强奇点（发散率~1/r^10）在量子场论中变得正则；而所有三种带电版本由于在r=0奇点外出现第二个奇点，无法实现量子正则化。

Conclusion: 量子场论可以正则化某些经典强奇点，但带电情况下的额外奇点结构阻碍了这种正则化过程，表明奇点的量子行为依赖于具体的时空结构。

Abstract: The scalar quantum probe method developed by Horowitz and Marolf is applied to the cylindrically symmetric Curzon solution. The main cause for choosing the Curzon solution is that it is the best known example that exhibits directional singularity. Interestingly the singularity at $r=0$, for the uncharged Curzon spacetime, which is classically very strong with a divergence rate of the order $\frac{1}{r^{10}}$ becomes regular when examined using scalar quantum field. The charged Curzon spacetime, however, due to the emergence of a second singularity off the $r=0$ singularity does not regularize quantum mechanically. All three different charged versions, i.e. electric, magnetic and dyonic share the same feature.

</details>


### [109] [Constraining modified theories of gravity through the detection of one extremely large mass-ratio inspiral](https://arxiv.org/abs/2511.08221)
*Hui-Min Fan,Alejandro Torres-Orjuela,Verónica Vázquez-Aceves,Tian-Xiao Wang,Tai-Fu Feng*

Main category: gr-qc

TL;DR: 该论文研究了利用超大质量比螺旋系统(XMRIs)的引力波来约束Chern-Simons引力理论。XMRIs由褐矮星围绕超大质量黑洞螺旋形成，其引力波可被未来空间探测器探测，用于精确测量银河系中心黑洞性质并探测强场引力。


<details>
  <summary>Details</summary>
Motivation: 超大质量比螺旋系统(XMRIs)的引力波探测能够以前所未有的精度测量银河系中心超大质量黑洞的天体物理性质，并为强场引力理论提供独特探测手段。本研究旨在利用XMRI信号来约束Chern-Simons引力理论参数。

Method: 使用时间频率马尔可夫链蒙特卡洛方法，获得XMRIs在Chern-Simons理论中的后验分布，分析不同偏心率源对Chern-Simons参数ζ的约束能力。

Result: 对于低偏心率源，XMRIs可将Chern-Simons参数ζ在10^{-1}水平约束到10^{-3}精度；对于高偏心率源，约束精度可达10^{-6}。几乎所有参数都能在1σ置信区间内恢复，大多数内禀参数估计精度达10^{-3}，褐矮星质量估计精度达10^{-1}。

Conclusion: XMRI信号特别是演化后期阶段对Chern-Simons理论与广义相对论的差异非常敏感，能够有效约束Chern-Simons引力理论参数，为强场引力探测提供重要工具。

Abstract: Extremely large mass-ratio inspirals (XMRIs), formed by brown dwarfs inspiraling into a massive black hole, emit gravitational waves (GWs) that fall within the detection band of future space-borne detectors such as LISA, TianQin, and Taiji. Their detection will measure the astrophysical properties of the MBH in the center of our galaxy (SgrA$^\ast$) with unprecedented accuracy and provide a unique probe of gravity in the strong field regime. Here, we estimate the benefit of using the GWs from XMRIs to constrain the Chern-Simons theory. Our results show that XMRI signals radiated from the late stages of the evolution are particularly sensitive to differences between Chern-Simons theory and general relativity. For low-eccentricity sources, XMRIs can put bounds on the Chern-Simons parameter $ζ$ at the level of $10^{-1}$ to an accuracy of $10^{-3}$. For high-eccentricity sources, XMRIs can put bounds on the parameter $ζ$ at the level of $10^{-1}$ to an accuracy of $10^{-6}$. Furthermore, using the time-frequency MCMC method, we obtain the posterior distribution of XMRIs in the Chern-Simons theory. Our results show that almost all the parameters can be recovered within $1σ$ confidence interval. For most of the intrinsic parameters, the estimation accuracy reaches $10^{-3}$. For the brown dwarf mass, the estimation accuracy reaches $10^{-1}$, while for $ζ$, the estimation accuracy reaches $Δ\log_{10}ζ=0.08$ for high eccentricity sources and 1.27 for low eccentricity sources.

</details>


### [110] [Chaotic motion of particles around a dyonic Kerr-Newman black hole immersed in the Melvin-swirling universe](https://arxiv.org/abs/2511.08415)
*Deshui Cao,Lina Zhang,Songbai Chen,Qiyuan Pan,Jiliang Jing*

Main category: gr-qc

TL;DR: 研究了在Melvin-swirling宇宙中的新型dyonic Kerr-Newman黑洞周围粒子运动的动力学行为，发现旋涡参数j和磁场强度B导致运动方程不可分离，并确认了混沌行为的存在。


<details>
  <summary>Details</summary>
Motivation: 探索在Melvin-swirling宇宙背景下的dyonic Kerr-Newman黑洞周围粒子运动的动力学特性，特别是旋涡参数和磁场对运动行为的影响。

Method: 使用庞加莱截面、快速李雅普诺夫指标、递归分析、分岔图和吸引域等多种动力学分析方法。

Result: 发现混沌轨道数量和混沌区域随j和B的增加而增加，但随电荷Q、磁荷H或自旋参数a的增加而减少。旋涡参数j改变了混沌运动出现的参数范围。

Conclusion: 旋涡参数与磁场强度、电荷、磁荷和自旋参数共同作用，在dyonic Kerr-Newman黑洞周围的粒子运动中产生了更丰富的物理现象。

Abstract: We employ the Poincaré section, fast Lyapunov indicator, recurrence analysis, bifurcation diagram and basins of attraction to investigate the dynamical behaviors of the motion of particles around a new dyonic Kerr-Newman black hole immersed in the Melvin-swirling universe presented in [A. Di Pinto, S. Klemm, and A. Viganò, J. High Energy Phys. {\bf 06}, 150 (2025)]. We note that the swirling parameter $j$ and magnetic field strength $B$ make the equations of motion for particles nonseparable, and confirm the presence of chaotic behavior in the motion in this dyonic Kerr-Newman-Melvin-swirling spacetime and its sub-cases by removing the conical singularities and removing both the conical singularities and the Dirac strings. We observe that both the number of chaotic orbits and the chaotic region increase with the increase of the parameters $j$ and $B$, but decrease as the electric charge $Q$, magnetic charge $H$ or spin parameter $a$ increases. Moreover, we find that the presence of $j$ changes the ranges of $B$, $Q$, $H$ and $a$ where the chaotic motion appears for particles. The swirling parameter together with the magnetic field strength, electric charge, magnetic charge and spin parameter yields richer physics in the motion of particles for the spacetime of a dyonic Kerr-Newman black hole immersed in the Melvin-swirling universe.

</details>


### [111] [Earth-orbit bounds on screened dark energy](https://arxiv.org/abs/2511.08448)
*Fabiano Feleppa,Welmoed Marit de Graaf,Philippe Brax,Gaetano Lambiase*

Main category: gr-qc

TL;DR: 通过近地空间测量测试暗能量驱动的屏蔽机制，利用后牛顿处理计算对三个观测量的主要修正：测地进动、LAGEOS-2的近心点进动和萨格纳克时延，并将这些修正映射到变色龙、对称子和膨胀子模型的约束上。


<details>
  <summary>Details</summary>
Motivation: 测试暗能量驱动的屏蔽机制，利用低密度空间实验作为敏感探测器，排除先前允许的参数空间区域。

Method: 在后牛顿处理框架内，计算对三个观测量的主要修正：Gravity Probe B的测地进动、LAGEOS-2的近心点进动和萨格纳克时延，并将这些修正映射到变色龙、对称子和膨胀子模型上。

Result: LAGEOS-2数据为对称子和膨胀子模型提供了最强的地球轨道限制，而预期的萨格纳克设置为变色龙模型提供了最严格的约束。

Conclusion: 低密度空间实验是探测屏蔽暗能量的敏感工具，这些结果排除了先前允许的参数空间区域，突显了空间实验在测试暗能量模型中的重要性。

Abstract: We test dark-energy-motivated screening mechanisms with near-Earth space-based measurements. Within a post-Newtonian treatment, we compute leading corrections to three observables, namely geodetic precession (Gravity Probe B), pericenter advance of LAGEOS-2, and Sagnac time delay in a prospective orbital configuration. We then map these corrections to bounds on chameleon, symmetron, and dilaton models. LAGEOS-2 data yield the strongest Earth-orbit limits for symmetron and dilaton models, while a prospective Sagnac setup provides the tightest constraint for chameleons. These results highlight the relevance of low-density, space-based experiments as sensitive probes of screened dark energy and exclude previously allowed regions of parameter space.

</details>


### [112] [Gravitational Wave Signatures from Periodic Orbits around a non-commutative inspired black hole surrounded by quintessence](https://arxiv.org/abs/2511.08456)
*Fazlay Ahmed,Qiang Wu,Sushant G Ghosh,Tao Zhu*

Main category: gr-qc

TL;DR: 研究非对易黑洞与quintessence场中测试粒子周期轨道的引力波发射，发现非对易参数Θ和quintessence场显著改变轨道结构和波形特征，这些效应可被未来空间引力波探测器探测。


<details>
  <summary>Details</summary>
Motivation: 探索非对易引力和quintessence场对黑洞周围粒子轨道及引力波发射的影响，为未来空间引力波探测器提供理论预测。

Method: 使用zoom-whirl分类法（由三个拓扑数(z,w,v)表征）对周期轨道进行分类，并计算代表性引力波形。

Result: 非对易参数Θ增加导致波形相位偏移和振幅变化，高zoom数产生更复杂的子结构；特征应变谱峰值在毫赫兹范围，位于LISA探测器敏感带内；quintessence场引入显著波形修正。

Conclusion: 未来空间引力波任务可能探测或约束强引力场中的非对易效应，quintessence场引起的波形偏差可被测量和约束。

Abstract: We study gravitational wave emission from periodic orbits of a test particle around a noncommutative-inspired black hole surrounded by quintessence. Using the zoom-whirl taxonomy, which is characterized by three topological numbers $(z, w, v)$, we classify these orbits and calculate several representative gravitational waveforms for certain periodic orbits. We find that the noncommutative parameter $Θ$ and the quintessence field significantly modify both the orbital structure and the emitted waveforms. In particular, increasing $Θ$ leads to a phase shift and a change in amplitude in the waveform, while higher zoom numbers produce more complicated substructures. The characteristic strain spectra peak in the millihertz range, lying within the sensitivity band of the LISA detector. Moreover, the presence of the quintessence field introduces significant modifications to these waveforms, imprinting measurable deviations that could be tested or constrained by future space-based gravitational wave detectors. These results suggest that future space-based gravitational wave missions could probe or constrain noncommutative effects in strong gravitational fields.

</details>


### [113] [Nonlinear Gravitational Wave Memory : Universal Low-Frequency Background](https://arxiv.org/abs/2511.08514)
*Caner Ünal,Doğa Veske*

Main category: gr-qc

TL;DR: 本文研究了引力波红外区域普遍存在的非线性记忆效应，计算了各种宇宙学和天体物理起源随机背景的非线性记忆信号，并探讨了通过记忆谱探测宇宙热状态和未来实验探测前景。


<details>
  <summary>Details</summary>
Motivation: 非线性记忆是引力波中普遍存在的低频成分，由线性引力波产生，存在于任何引力波背景中。研究这一效应有助于理解引力波的完整频谱特性。

Method: 计算了各种随机背景的非线性记忆信号，包括宇宙学起源（标量诱导、再加热、相变、拓扑缺陷、湍流）和天体物理起源（不同质量黑洞并合）的背景。

Result: 得到了宇宙学和天体物理随机引力波背景的完整频率谱，发现可以通过记忆谱的斜率来探测宇宙的热状态（状态方程）。

Conclusion: 非线性记忆效应为研究引力波背景提供了重要信息，未来实验有望在不同频段探测到这一效应，从而揭示宇宙的热状态和演化历史。

Abstract: A universal contribution exists in the infrared (low frequency) regime of all gravitational waves, which results from nonlinear memory. Nonlinear memory is sourced by linear order gravitational waves and exists for any gravitational-wave background. We calculate the stochastic nonlinear memory signal of various stochastic backgrounds of cosmological (scalar induced, reheating, phase transition, topological defect, turbulence) and astrophysical (binary mergers of stellar-mass, intermediate mass, supermassive, and primordial black holes) origins. These results allow us to derive the complete frequency spectrum of cosmological and astrophysical SGWB. We calculate how to probe the thermal state of the universe, i.e. the equation of the state, via the memory spectrum's slope and also discuss the detection prospects at various frequency bands with future experiments.

</details>


### [114] [Stability of spherical thin-shell wormholes in scalar-tensor theories](https://arxiv.org/abs/2511.08527)
*Ernesto F. Eiroa,Griselda Figueroa-Aguirre,Vasiliki Karanasou*

Main category: gr-qc

TL;DR: 在标量-张量引力理论中构建球对称薄壳虫洞，研究对称虫洞的物质含量和径向扰动下的稳定性，并在两个爱因斯坦-麦克斯韦引力与共形标量场耦合的具体例子中证明稳定配置的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究标量-张量引力理论中薄壳虫洞的构造和稳定性，探索在特定参数下实现稳定虫洞配置的可能性。

Method: 构建球对称薄壳虫洞模型，分析虫洞喉部的对称性，研究物质含量，并通过径向扰动分析静态配置的稳定性。

Result: 在两个爱因斯坦-麦克斯韦引力与共形标量场耦合的具体例子中，证明了在合适的参数取值下可以实现稳定的虫洞配置。

Conclusion: 标量-张量引力理论中确实存在稳定的薄壳虫洞配置，这为虫洞物理研究提供了新的理论可能性。

Abstract: In this article, we construct a family of spherically symmetric thin-shell wormholes within scalar-tensor theories of gravity. In the case of wormholes symmetric across the throat, we study the matter content and analyze the stability of the static configurations under radial perturbations. We apply the formalism to two particular examples involving Einstein-Maxwell gravity coupled to a conformal scalar field. In both scenarios, we show that stable configurations are possible for suitable values of the parameters involved.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [115] [An Improved High-order Adaptive Mesh Refinement Framework for Shock-turbulence Interaction Problems based on cell-centered finite difference schemes](https://arxiv.org/abs/2511.08335)
*Yuqi Wang,Yadong Zeng,Ralf Deiterding,Jinhui Yang,Jianhan Liang*

Main category: physics.comp-ph

TL;DR: 提出了一种用于激波-湍流相互作用问题的高阶有限差分自适应网格细化框架，采用交错网格布局解决边界守恒问题，并开发了混合插值策略来避免非守恒插值引起的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决先前研究中遇到的边界守恒问题，以及非守恒插值在间断单元中可能引发的不稳定性问题，从而更稳健地模拟激波-湍流相互作用问题。

Method: 采用交错网格布局，在高阶非线性插值方法基础上开发了高阶限制方法，并首次提出混合插值策略：在光滑区域使用非守恒WENO插值，在激波处使用二阶守恒插值，通过尺度无关黎曼求解器实现无缝耦合。

Result: 标准测试表明，该方法能够准确解析各种复杂的激波-湍流相互作用问题，这些问题对现有方法来说一直很棘手。

Conclusion: 所提出的方法显著减轻了非守恒插值和逐点替换引入的数值不稳定性，为激波-湍流相互作用的稳健模拟提供了有效解决方案。

Abstract: This work presents a high-order finite-difference adaptive mesh refinement (AMR) framework for robust simulation of shock-turbulence interaction problems. A staggered-grid arrangement, in which solution points are stored at cell centers instead of at the vertices, is presented to address the boundary conservation issues encountered in previous studies. The key ingredient in the AMR framework, i.e., the high-order nonlinear interpolation method applied in the prolongation step together with the determination of fine-grid boundary conditions, are re-derived for staggered grids following the procedures in prior work [1] and are thus used here. Meanwhile, a high-order restriction method is developed in the present study as the coarse and fine grid solutions are non-collocated in this configuration. To avoid non-conservative interpolation at discontinuous cells that could incur instabilities, a hybrid interpolation strategy is proposed in this work for the first time, where the non-conservative WENO interpolation is applied in smooth regions whereas the second-order conservative interpolation is applied at shocks. This significantly mitigates the numerical instabilities introduced by non-conservative interpolation and pointwise replacement. The two interpolation approaches are seamlessly coupled through a troubled-cell detector achieved by a scale-irrelevant Riemann solver in a robust way. The present work is developed on a publicly available block-structured adaptive mesh refinement framework AMReX [2]. The canonical tests demonstrate that the proposed method is capable of accurately resolving a wide range of complex shock-turbulence interaction problems that have been proven intricate for existing approaches

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [116] [Optimizing quantum violation for multipartite facet Bell inequalities](https://arxiv.org/abs/2511.07523)
*Jin-Fu Chen,Mengyao Hu,Jordi Tura*

Main category: quant-ph

TL;DR: 提出基于梯度的优化方法来最大化贝尔不等式的量子值与经典界限之比，发现局部最大值通常对应局部多面体的面贝尔不等式，可用于迭代搜索紧致且鲁棒的贝尔不等式。


<details>
  <summary>Details</summary>
Motivation: 在多体系统中，随着系统规模增大，表征局部多面体变得难以处理，需要优化贝尔不等式以理解多体非局域性。

Method: 使用基于梯度的优化方法，最大化贝尔不等式的量子值与经典界限之比，并通过迭代搜索寻找紧致的贝尔不等式。

Result: 数值结果表明该方法的局部最大值通常对应局部多面体的面贝尔不等式，应用于置换不变场景可获得具有大量子违反的紧致贝尔不等式。

Conclusion: 该方法能够有效寻找紧致且鲁棒的贝尔不等式，便于实验验证贝尔相关性，无需完全了解局部多面体。

Abstract: Nonlocality shapes quantum correlations, revealed through the violation of Bell inequalities. The intersection of all valid Bell inequalities is the so-called local polytope. In multipartite systems, characterizing the local polytope quickly becomes an intractable task as the system size increases. Optimizing Bell inequalities to maximize the ratio between their quantum value and classical bound is key to understanding multipartite nonlocality. We propose a gradient-based method for this optimization. Numerical results indicate that local maxima of this ratio typically correspond to facet Bell inequalities of the local polytope. This enables an iterative search for tight and robust Bell inequalities. Applied to permutation-invariant scenarios, the method provides tight Bell inequalities with large quantum violations and facilitates experimental certification of Bell correlations without full knowledge of the local polytope.

</details>


### [117] [Measuring multipartite entanglement efficiently by testing symmetries](https://arxiv.org/abs/2511.07537)
*Xiaoyu Liu,Jordi Tura,Albert Rico*

Main category: quant-ph

TL;DR: 本文提出了一种基于对称性测试的纠缠度量方法，能够定量测量双体和多体量子纠缠，并开发了高效的估计策略和采样方案。


<details>
  <summary>Details</summary>
Motivation: 量子对称性测试已被用于检测纯量子态中的双体纠缠，但需要超越定性检测，发展定量纠缠度量方法。

Method: 利用对称性测试构建纠缠度量家族，提出多种高效估计方法，推导近最优采样策略，并分析采样误差缩放行为。

Result: 尽管方法具有非线性，但采样误差随总拷贝数N_tot以O(N_tot^{-1/2})缩放，证明了实验可行性。通过对称性计算了大拷贝数下的纠缠度量，并推导了多体系统中相关态的渐近衰减指数。

Conclusion: 识别了所提出纠缠度量在估计复杂性和灵敏度之间的权衡关系，为实际应用提供了指导。

Abstract: Recently, a technique known as quantum symmetry test has gained increasing attention for detecting bipartite entanglement in pure quantum states. In this work we show that, beyond qualitative detection, a family of well-defined measures of bipartite and multipartite entanglement can be obtained with symmetry tests. We propose and benchmark several efficient methods to estimate these measures, and derive near-optimal sampling strategies for each. Despite the nonlinearity of the methods, we demonstrate that the sampling error scales no worse than $O(N_{\mathrm{tot}}^{-1/2})$ with the total number of copies $N_{\mathrm{tot}}$, which suggests experimental feasibility. By exploiting symmetries we compute our measures for large number of copies, and derive the asymptotic decay exponents for relevant states in many-body systems. Using these results we identify tradeoffs between estimation complexity and sensitivity of the presented entanglement measures, oriented to practical implementations.

</details>


### [118] [Nonclassical State Generation and Quantum Metrology in the Double-Morse Potential](https://arxiv.org/abs/2511.07591)
*Firoz Chogle,Berihu Teklu,Jorge Zubelli,Ernesto Damiani*

Main category: quant-ph

TL;DR: 本文研究了双莫斯势的非线性特性作为单模量子态资源的潜力，分析了其双阱结构和非谐性对非高斯性、非经典性和计量性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索双莫斯势作为可控非高斯性源的可能性，研究其双阱结构和非谐性如何影响量子态的非经典特性和计量应用。

Method: 解析推导基态波函数和能谱，使用不对称参数α作为主要控制参数，评估非高斯性和非经典性度量，计算相关Fisher信息并构建可行估计器。

Result: 发现非高斯性和非经典性度量随α单调增加，浅阱中的简单位置测量即可实现高精度估计，最优策略可达到Cramér-Rao界。

Conclusion: 双莫斯势是真正的可控非高斯性源，其非经典性和计量应用随α增加而增强，在连续变量量子信息处理和计算中具有实际应用潜力。

Abstract: In this paper, we investigate the nonlinear properties of the double-Morse potential as a possible resource for single-mode quantum states because of its double-well structure and anharmonicity. We derive the ground state wave function and the associated energy spectrum analytically, using the asymmetry (width parameter) $α$ as the primary control parameter. These results show a systematic and evident influence on $α$. We assess the non-Gaussianity and non-classicality measures, quantifying their nonlinearity and quantum behavior. In particular, we discover that both metrics rise monotonically with $α$. Furthermore, we examine the metrological performance for estimating $α$. By calculating the pertinent Fisher information and building workable estimators, we show that optimal strategies can saturate the Cramér-Rao bound, with straightforward position measurements on shallow wells already producing high precision. These results collectively demonstrate that the double-Morse potential is a genuine, controllable source of non-Gaussianity, whose non-classicality and metrological applications increase with $α$. We highlight the potential applications of this model in real-world quantum technologies and discuss the implications for continuous-variable quantum information processing and computation.

</details>


### [119] [The three kinds of three-qubit entanglement](https://arxiv.org/abs/2511.07617)
*Szilárd Szalay*

Main category: quant-ph

TL;DR: 该论文构建了三比特纯态纠缠理论中缺失的重要部分——W纠缠的多项式度量，与GHZ纠缠的三纠缠度和二分纠缠的并发度并行工作，并证明这些纠缠度量是有序的。


<details>
  <summary>Details</summary>
Motivation: 填补三比特纯态纠缠理论中的重要空白，为W纠缠建立多项式度量，以完善与GHZ纠缠和二分纠缠度量的平行理论框架。

Method: 构建W纠缠的多项式度量，并与三纠缠度（GHZ纠缠度量）和二分并发度进行并行分析和比较。

Result: 成功建立了W纠缠的多项式度量，并证明三种纠缠度量存在有序关系：二分度量 > W度量 > GHZ度量，对应三种纠缠类型的强度顺序。

Conclusion: 三比特纠缠的三种类型（二分、W、GHZ）及其相应度量形成了有序的层次结构，这与三比特纠缠态的三种等价类的顺序相平行。

Abstract: We construct an important missing piece in the entanglement theory of pure three-qubit states, which is a polynomial measure of W entanglement, working in parallel to the three-tangle, which is a polynomial measure of GHZ entanglement, and to the bipartite concurrence, which is a polynomial measure of bipartite entanglement. We also show that these entanglement measures are ordered, the bipartite measure is larger than the W measure, which is larger than the GHZ measure. It is meaningful then to consider these three types of three-qubit entanglement, which are also ordered, bipartite is weaker than W, which is weaker than GHZ, in parallel to the order of the three equivalence classes of entangled three-qubit states.

</details>


### [120] [Quantum Approximate Walk Algorithm](https://arxiv.org/abs/2511.07676)
*Ziqing Guo,Jan Balewski,Wenshuo Hu,Alex Khan,Ziwen Pan*

Main category: quant-ph

TL;DR: 提出了一种可追踪经典数据的量子预言机，通过浅层量子电路学习近似结果模式，并结合经典预处理增强QAOA输出的可解释性，在IBM硬件上实现了多项式时间验证的混合框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于算术的量子计算算法中，经典到量子数据映射方法无法保证结果相关性，现有方法不适用于该问题。

Method: 设计线性电路深度的经典数据可追踪量子预言机，采用浅层量子电路布局学习近似模式，结合经典预处理增强量子测量数据的可解释性。

Result: 在IBM Pittsburgh硬件上获得实验结果，实现了多项式时间验证的解决方案质量，建立了经典输入与量子电路结果之间的可推断映射。

Conclusion: 该混合框架弥合了近量子能力与实用优化需求之间的差距，为工业应用提供了可靠的量子-经典算法路径。

Abstract: The encoding of classical to quantum data mapping through trigonometric functions within arithmetic-based quantum computation algorithms leads to the exploitation of multivariate distributions. The studied variational quantum gate learning mechanism, which relies on agnostic gradient optimization, does not offer algorithmic guarantees for the correlation of results beyond the measured bitstring outputs. Consequently, existing methodologies are inapplicable to this problem. In this study, we present a classical data-traceable quantum oracle characterized by a circuit depth that increases linearly with the number of qubits. This configuration facilitates the learning of approximate result patterns through a shallow quantum circuit (SQC) layout. Moreover, our approach demonstrates that the classical preprocessing of mid-quantum measurement data enhances the interpretability of quantum approximate optimization algorithm (QAOA) outputs without requiring full quantum state tomography. By establishing an inferable mapping between the classical input and quantum circuit outcomes, we obtained experimental results on the state-of-the-art IBM Pittsburgh hardware, which yielded polynomial-time verification of the solution quality. This hybrid framework bridges the gap between near-term quantum capabilities and practical optimization requirements, offering a pathway toward reliable quantum-classical algorithms for industrial applications.

</details>


### [121] [Multipartite steering verification with imprecise measurements](https://arxiv.org/abs/2511.07708)
*Zeyang Lu,Chan Li,Gang Wang,Zhu Cao*

Main category: quant-ph

TL;DR: 提出了一种在测量不精确条件下验证多方量子导引的定量方法，有效消除由测量不精确引起的假阳性结果，并能在特殊情况下验证多方量子纠缠。


<details>
  <summary>Details</summary>
Motivation: 量子导引是量子技术中的基本量子关联，但其验证严重依赖精确测量，而实际中的测量不精确会破坏这一假设。

Method: 开发了一种定量方法，在测量不精确条件下验证多方量子导引，并与设备无关方法进行比较以确定有效验证范围。

Result: 该方法能准确界定有效验证的范围，在特殊情况下还能验证多方量子纠缠，显著提高了对测量不精确的鲁棒性。

Conclusion: 这些结果大大增强了多方量子导引和纠缠验证对测量不精确的鲁棒性，促进了它们在现实量子技术中的应用。

Abstract: Quantum steering is a fundamental quantum correlation that plays a pivotal role in quantum technologies, but its verification crucially relies on precise measurements -- an assumption often undermined by practical imperfections. Here, we investigate multipartite steering verification under imprecise measurements and develop a quantitative method that effectively eliminates false positives induced by measurement imprecision. A comparison with a device-independent approach demonstrates that our method accurately delineates the scope of valid verification. In a special case, our method also enables the verification of multipartite entanglement under nonideal conditions. These results substantially enhance the robustness of multipartite steering and entanglement verification against measurement imprecision, thereby promoting their applicability in realistic quantum technologies.

</details>


### [122] [Quantum annealing for lattice models with competing long-range interactions](https://arxiv.org/abs/2511.08336)
*Jan Alexander Koziol,Kai Phillip Schmidt*

Main category: quant-ph

TL;DR: 使用超导量子退火设备通过单元胞优化方案确定具有代数衰减长程相互作用的Ising模型的基态，应用于三角晶格、Kagome晶格和受挫Ising化合物等系统。


<details>
  <summary>Details</summary>
Motivation: 为量子模拟平台和材料科学提供解决具有长程相互作用的晶格问题的方法，特别是针对原子分子量子模拟器和人工自旋冰超材料等应用场景。

Method: 采用单元胞优化方案，在商业量子退火硬件上对每个单元胞进行有限优化，处理具有可求和长程相互作用的晶格问题。

Result: 成功计算了三角晶格长程Ising模型在纵向场中的磁化平台魔鬼阶梯，评估了Kagome晶格无场模型的基态，并研究了具有近邻相互作用的受挫Ising化合物模型。

Conclusion: 该方法为现有量子退火技术提供了一个实用且现实的应用，适用于许多涉及可求和长程相互作用晶格问题的研究领域。

Abstract: We use superconducting qubit quantum annealing devices to determine the ground state of Ising models with algebraically decaying competing long-range interactions in the thermodynamic limit. This is enabled by a unit-cell-based optimization scheme, in which the finite optimizations on each unit cell are performed using commercial quantum annealing hardware. To demonstrate the capabilities of the approach, we choose three exemplary problems relevant for other quantum simulation platforms and material science: (i) the calculation of devil's staircases of magnetization plateaux of the long-range Ising model in a longitudinal field on the triangular lattice, motivated by atomic and molecular quantum simulators; (ii) the evaluation of the ground state of the same model on the Kagome lattice in the absence of a field, motivated by artificial spin ice metamaterials; (iii) the study of models with additional few-nearest-neighbor interactions relevant for frustrated Ising compounds with potential long-range interactions. The approach discussed in this work provides a useful and realistic application of existing quantum annealing technology, applicable across many research areas in which lattice problems with resummable long-range interactions are relevant.

</details>


### [123] [Optical spectroscopy of single- and two-ion transitions in an antiferromagnetic stoichiometric rare-earth crystal](https://arxiv.org/abs/2511.07747)
*Masaya Hiraishi,Gabrielle A. Hunter-Smith,Gavin G. G. King,Alexandra A. Turrini,J. -R. Soh,Henrik M. Rønnow,Luke S. Trainor,Jevon J. Longdell*

Main category: quant-ph

TL;DR: 研究了钕镓酸盐(NdGaO3)中钕离子(Nd3+)在高达3T磁场下的光学跃迁特性，发现了三种磁相并分类了单离子和双离子吸收跃迁。


<details>
  <summary>Details</summary>
Motivation: 稀土反铁磁晶体在微波-光学量子转换领域具有重要应用前景，但相关光学跃迁特性研究相对缺乏。

Method: 在高达3T磁场下测量NdGaO3的光谱，使用单离子晶体场哈密顿量与晶格平均磁化相互作用模型，并扩展到离子对模型。

Result: 识别出三种磁相(反铁磁、中间相、顺磁)，中间相具有不同于典型自旋翻转相的结构；成功解释了单离子和双离子光学跃迁的起源。

Conclusion: 该研究深化了对稀土反铁磁晶体光学跃迁的理解，为微波-光学量子转换应用提供了理论基础。

Abstract: We characterise optical transitions of neodymium ions (Nd3+) in antiferromagnetic neodymium gallate (NdGaO3) with applied fields up to 3 T. The magnetic phase of this material has not previously been studied with the field along its magnetisation axis. The measured optical spectra indicate three magnetic phases -- antiferromagnetic, intermediate, and paramagnetic -- where the intermediate phase likely forms a different magnetic structure from typical spin-flop phases. The observed absorptions were classified into two distinct families of optical transitions: single-Nd and two-Nd absorptions. We demonstrate that the optical transitions in the antiferromagnetic and paramagnetic phases can be modelled using a standard single-ion crystal-field Hamiltonian that interacts with a mean magnetisation from the rest of the lattice, and we expand that model to encompass pairs of ions, explaining the origins of the two-Nd transitions. This study offers a deeper understanding of the optical transitions in rare-earth antiferromagnetic crystals, which have been recently attracting significant interest for microwave-to-optical quantum transduction, despite being relatively unexplored to date.

</details>


### [124] [Quantum Semantic Communication Beyond the Shannon-Wyner Channel Capacity](https://arxiv.org/abs/2511.07760)
*Min Wang,Gui-Fa Zhu,Guo-Fei Long,Jianxing Guo,Yu-Chen Liu,Dong Pan,Li-Ping Nong,Gui-Lu Long*

Main category: quant-ph

TL;DR: 本文提出并实验验证了一种量子语义通信方案，应用于3D点云传输，实现了46.30倍的效率提升，超越了Wyner和Shannon容量极限，为大规模QSDC部署铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 量子安全直接通信(QSDC)虽然能提供无条件安全通信，但其实际可扩展性受到传输速率不足的限制；而语义通信虽能大幅提升传输效率，但仍易受恶意入侵。将这两种范式结合有望同时提升等效数据速率和安全性。

Method: 提出并实验验证了一种量子语义通信方案，将其应用于3D点云传输，通过提取核心信息特征来提升传输效率。

Result: 该方案实现了46.30倍的效率提升，超越了Wyner和Shannon容量极限，在商用光纤上达到了千比特每秒的传输速率。

Conclusion: 这一突破不仅为大规模QSDC部署清除了障碍，也标志着量子信息科学的一个重要里程碑，证明了量子语义通信在同时提升安全性和传输效率方面的巨大潜力。

Abstract: Quantum Secure Direct Communication (QSDC), a paradigm-shifting breakthrough in quantum communication, exploits quantum states for unmediated information transmission. Rooted in the inviolable fundamental laws of quantum mechanics, QSDC enables ultrasensitive detection of even the faintest eavesdropping attempts, guaranteeing true communication security solely when no interference exists. If eavesdropping or intrusion is detected mid-transmission, the system instantly alerts users and severs data flow, shielding them from unauthorized tracking and mitigating hacker threats. Over two decades, QSDC has seen extraordinary advancements, currently attaining kilobit-per-second transmission over 100 km of commercial optical fiber. However, its practical scalability remains constrained by insufficient transmission rates, a critical bottleneck. Semantic communication, which drastically boosts transmission efficiency by extracting core information features, nevertheless stays vulnerable to malicious intrusions. Integrating these paradigms promises to simultaneously enhance equivalent data rate and security. Herein, we propose and experimentally validate a quantum semantic communication scheme, applying it to 3D point clouds. It achieves a 46.30-fold efficiency gain over direct transmission, surpassing both Wyner and Shannon capacity limits. This breakthrough not only clears the path for large-scale QSDC deployment but also marks a pivotal milestone in quantum information science.

</details>


### [125] [Local spreading of stabilizer Rényi entropy in a brickwork random Clifford circuit](https://arxiv.org/abs/2511.07769)
*Somnath Maity,Ryusuke Hamazaki*

Main category: quant-ph

TL;DR: 本文研究了在砖墙随机Clifford电路下，单量子比特稳定子Rényi熵的扩散传播特性，发现其表现出扩散结构，并在受限Clifford电路中展现出超扩散传播行为。


<details>
  <summary>Details</summary>
Motivation: 非稳定化性（魔法）是量子计算的基本资源和量子优势的关键要素。稳定子Rényi熵作为可计算且实验可访问的度量，需要研究其在多体量子系统中的传播特性。

Method: 使用砖墙随机Clifford电路，初始为包含局部魔法的乘积态，通过单量子比特约化密度矩阵分析稳定子Rényi熵的传播。研究了Haar随机局部Clifford门和受限Clifford电路两种情况。

Result: 在Haar随机局部Clifford门情况下，归一化单量子比特SRE在弹道光锥内表现出扩散结构；在受限Clifford电路中，归一化单量子比特SRE展现出超扩散传播行为。

Conclusion: 归一化单量子比特稳定子Rényi熵的传播表现出非弹道特性，即使在缺乏显式守恒量的情况下也呈现扩散和超扩散行为，这揭示了魔法传播的独特动力学特征。

Abstract: Nonstabilizerness, or magic, constitutes a fundamental resource for quantum computation and a crucial ingredient for quantum advantage. Recent progress has substantially advanced the characterization of magic in many-body quantum systems, with stabilizer Rényi entropy (SRE) emerging as a computable and experimentally accessible measure. In this work, we investigate the spreading of SRE in terms of single-qubit reduced density matrices, where an initial product state that contains magic in a local region evolves under brickwork random Clifford circuits. For the case with Haar-random local Clifford gates, we find that the spreading profile exhibits a diffusive structure within a ballistic light cone when viewed through a normalized version of single-qubit SRE, despite the absence of explicit conserved charges. We further examine the robustness of this non-ballistic behavior of the normalized single-qubit SRE spreading by extending the analysis to a restricted Clifford circuit, where we unveil a superdiffusive spreading.

</details>


### [126] [On the role of induced electric field in the time-dependent Aharonov-Bohm effect](https://arxiv.org/abs/2511.07775)
*Masashi Wakamatsu*

Main category: quant-ph

TL;DR: 本文重新研究了含时Aharonov-Bohm效应的存在性问题，重点关注感应电场的作用，发现感应电场具有高度非平凡效应，可用于验证含时AB效应的存在。


<details>
  <summary>Details</summary>
Motivation: 含时Aharonov-Bohm效应是否存在一直是长期争议的问题，主要困难在于如何处理时变矢势的闭合时空线积分，以及时变磁通量在螺线管外产生的感应电场。

Method: 基于Gao最近的工作，本文极其仔细地重新研究了感应电场在含时AB效应中的作用。

Result: 分析揭示了感应电场具有高度非平凡的效应，这一发现对于验证含时AB效应的存在具有重要意义。

Conclusion: 感应电场的非平凡效应为验证含时Aharonov-Bohm效应的存在提供了有效途径。

Abstract: Whether the time-dependent Aharonov-Bohm (AB) effect even exists or not has been the subject of long-standing debate. There are two factors complicating the problem. First, in the closed spacetime line integral of the vector potential that is thought to give the AB-phase shift, how to treat the time-varying vector potential is highly nontrivial. Second, the time-varying magnetic flux generates induced electric field even outside the solenoid. In the present paper, motivated by a recent work by Gao, we re-investigate the role of the induced electric field with the utmost care. This analysis reveals a highly nontrivial effect of the induced electric field, which turns out to be useful for verifying the very existence of the time-dependent AB-effect.

</details>


### [127] [Emergent Decoherence Dynamics in Doubly Disordered Spin Networks](https://arxiv.org/abs/2511.07785)
*Cooper M. Selco,Christian Bengs,Chaitali Shah,Zhuorui Zhang,Ashok Ajoy*

Main category: quant-ph

TL;DR: 在双无序电子-核自旋网络中发现了核极化的新兴退相干定律 e^{-√(R_p t)}e^{-R_d t}，该定律在广泛参数范围内具有鲁棒性，源于电子网络介导的长程相互作用和核网络中反常亚扩散自旋输运两个相互依赖的退相干通道。


<details>
  <summary>Details</summary>
Motivation: 阐明从可逆量子多体动力学中不可逆宏观定律的出现是量子科学中的一个重要问题，连接微观动力学与新兴宏观行为具有挑战性。

Method: 通过Floquet工程和（光学）环境调制的组合，在双无序电子-核自旋网络中控制甚至消除单个退相干通道，研究退相干机制。

Result: 发现了稳健的核极化退相干定律，无序性在此具有保护作用，产生孤立的无电子团簇，能够局域化极化并延长相干寿命。

Conclusion: 这些发现建立了操纵退相干途径的微观框架，并建议将工程化无序作为实现长寿命量子存储器和传感器的新设计原则。

Abstract: Elucidating the emergence of irreversible macroscopic laws from reversible quantum many-body dynamics is a question of broad importance across all quantum science. Many-body decoherence plays a key role in this transition, yet connecting microscopic dynamics to emergent macroscopic behavior remains challenging. Here, in a doubly disordered electron-nuclear spin network, we uncover an emergent decoherence law for nuclear polarization, $e^{-\sqrt{R_{p}t}}e^{-R_{d}t}$, that is robust across broad parameter regimes. We trace its microscopic origins to two interdependent decoherence channels: long-range interactions mediated by the electron network and spin transport within the nuclear network exhibiting anomalous, sub-diffusive dynamics. We demonstrate the capacity to control--and even eliminate--either channel individually through a combination of Floquet engineering and (optical) environment modulation. We find that disorder, typically viewed as detrimental, here proves protective, generating isolated electron-free clusters that localize polarization and prolong coherence lifetimes. These findings establish a microscopic framework for manipulating decoherence pathways and suggests engineered disorder as a new design principle for realizing long-lived quantum memories and sensors.

</details>


### [128] [Secure and Efficient n-Qubit Entangled State Teleportation Using Partially Entangled GHZ Channels and Optimal POVM](https://arxiv.org/abs/2511.07848)
*Animesh Banik,Md. Shihab Khan,Rafid Masrur Khan,Syed Emad Uddin Shubha,Mahdy Rahman Chowdhury*

Main category: quant-ph

TL;DR: 提出了一种高效通用的量子隐形传态协议，用于特定类型的n量子比特纠缠态，采用部分纠缠GHZ态作为量子通道和基于改进互易态的最优POVM，实现无歧义态区分。


<details>
  <summary>Details</summary>
Motivation: 降低量子隐形传态中的经典通信成本，增强量子逐跳通信的安全性，通过战略选择量子通道和传态策略来提升协议性能。

Method: 使用部分纠缠GHZ态作为量子通道，基于改进互易态的最优POVM进行无歧义态区分，支持多种纠缠态配置，可与传统协议集成。

Result: 相比标准Bell基隐形传态，显著降低了这些纠缠态的经典通信成本，增强了量子通信安全性。

Conclusion: 该协议在量子通信中具有高效性和通用性，通过优化量子通道和测量策略实现了成本降低和安全性提升。

Abstract: We introduce an efficient and versatile quantum teleportation protocol for specific types of n-qubit entangled states. By employing a partially entangled Greenberger-Horne-Zeilinger (GHZ) state as the quantum channel and an optimal Positive Operator-Valued Measure (POVM) based on an improved reciprocal state formulation, we achieve unambiguous state discrimination. The scheme has been generalized to support various entangled state configurations and demonstrates a notable reduction in classical communication costs for these states compared to standard Bell-basis teleportation. Its capacity for integration with conventional protocols is pivotal, enhancing quantum hop-by-hop communication security by allowing strategic choices in quantum channel and teleportation strategy

</details>


### [129] [Sufficient conditions for hardness of lossy Gaussian boson sampling](https://arxiv.org/abs/2511.07853)
*Byeongseon Go,Changhun Oh,Hyunseok Jeong*

Main category: quant-ph

TL;DR: 该论文研究了高斯玻色子采样(GBS)在光子损失噪声下的经典计算难解性，确定了保持理想GBS计算复杂度的损失阈值，并首次严格表征了有损GBS的经典难解区域。


<details>
  <summary>Details</summary>
Motivation: 当前GBS实验实现不可避免地受到噪声影响，但GBS对噪声鲁棒性的经典难解性研究仍很缺乏，特别是光子损失这一主要噪声源。

Method: 通过建立噪声GBS的复杂性理论基础，识别光子损失阈值，并直接量化理想与有损GBS之间的统计距离来推导难解性判据。

Result: 发现当最多有对数比例的光子损失时，有损GBS保持与理想GBS相同的计算复杂度水平，并推导出了损失率的难解性判据。

Conclusion: 这项工作首次严格表征了有损GBS的经典难解区域，为在近期实现中展示量子优势迈出了关键一步。

Abstract: Gaussian boson sampling (GBS) is a prominent candidate for the experimental demonstration of quantum advantage. However, while the current implementations of GBS are unavoidably subject to noise, the robustness of the classical intractability of GBS against noise remains largely unexplored. In this work, we establish the complexity-theoretic foundations for the classical intractability of noisy GBS under photon loss, which is a dominant source of imperfection in current implementations. We identify the loss threshold below which lossy GBS maintains the same complexity-theoretic level as ideal GBS, and show that this holds when at most a logarithmic fraction of photons is lost. We additionally derive an intractability criterion for the loss rate through a direct quantification of the statistical distance between ideal and lossy GBS. This work presents the first rigorous characterization of classically intractable regimes of lossy GBS, thereby serving as a crucial step toward demonstrating quantum advantage with near-term implementations.

</details>


### [130] [Enhancing Remote Magnon-Magnon Entanglement with Quantum Interference](https://arxiv.org/abs/2511.07872)
*Yuan Gong,Yan-Xue Cheng,Wei Xiong,Jiaojiao Chen*

Main category: quant-ph

TL;DR: 提出了一种通过注入压缩真空场来增强腔磁子系统中宏观纠缠的方案，利用双压缩场干涉实现相位控制的纠缠增强，显著提高了对腔耗散和热噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 腔磁子学因其强磁子-光子耦合和优异可调性在量子信息科学中备受关注，但由于光束分离器相互作用的线性特性，实现强健的宏观纠缠仍是一个长期挑战。

Method: 通过向耦合微波腔中注入压缩真空场来生成和增强两个远程磁子模式之间的纠缠，采用单压缩场和双压缩场配置，利用量子干涉实现相位控制的纠缠增强。

Result: 单压缩场可诱导稳态磁子-磁子纠缠，双压缩场配置能选择性激活两个独立的纠缠通道，在现实参数下量子纠缠的存活温度从约260mK提高到450mK。

Conclusion: 该方案为在腔磁子系统中实现可控和热鲁棒的宏观纠缠开辟了有前景的途径，为研究仅具有光束分离器相互作用的腔磁子系统中的宏观量子物理提供了新方法。

Abstract: Cavity magnonics, owing to its strong magnon-photon coupling and excellent tunability, has attracted significant interest in quantum information science. However, achieving strong and robust macroscopic entanglement remains a long-standing challenge due to the inherently linear nature of the beam-splitter interaction. Here, we propose an experimentally feasible scheme to generate and enhance macroscopic entanglement between two remote magnon modes by injecting squeezed vacuum fields (SVFs) into coupled microwave cavities. We demonstrate that even a single SVF applied to one cavity can induce steady magnon-magnon entanglement, while applying two SVFs (the double-squeezed configuration) enables selective activation of two independent entanglement channels associated with the cavity supermodes. Remarkably, quantum interference between the two SVFs allows for phase-controlled enhancement of entanglement, resulting in significantly improved robustness against cavity dissipation and thermal noise. Under realistic parameters, the survival temperature of quantum entanglement increases from approximately $260$ mK to $450$ mK. Our results open a promising route toward controllable and thermally resilient macroscopic entanglement in cavity magnonics. Our results establish a versatile and controllable approach to generating and enhancing quantum entanglement through double-squeezed-field interference, opening new avenues to study and enhance macroscopic quantum physics in cavity-magnon systems with only beam-splitter interactions.

</details>


### [131] [Collective Vibronic Cascade in Cavity-Coupled Jahn-Teller Active Molecules](https://arxiv.org/abs/2511.07880)
*Suraj Kumar Pandit,Abhinay Pandey,Athreya Shankar,Krishna R. Nandipati*

Main category: quant-ph

TL;DR: 该论文研究了多个Jahn-Teller活性分子与法布里-珀罗腔模式耦合时的极化子态和动力学，发现集体效应显著改变了电子、振动和腔角动量的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究集体耦合对Jahn-Teller分子极化子态的影响，探索集体效应如何改变极化子光谱和动力学行为。

Method: 通过分析多个Jahn-Teller活性分子与法布里-珀罗腔模式的耦合，研究集体效应下的极化子态和动力学。

Result: 发现集体耦合使分子能够访问高角动量振动状态，导致极化子光谱展宽和光子偏振动力学抑制。

Conclusion: 集体分子极化子学为振动角动量转移开辟了新途径，对腔辅助光物理和光化学具有潜在意义。

Abstract: We study the polaritonic states and dynamics of multiple Jahn-Teller (JT) active molecules coupled to the modes of a Fabry-Perot cavity. We find that collective effects dramatically alter the interplay of electronic, vibrational and cavity angular momenta, giving rise to markedly different polaritonic spectra and dynamics even when going from one to two JT molecules. Starting from the ground vibronic state, we find that JT molecules collectively coupled to a common cavity can access a cascade of high-angular-momentum vibronic states in the presence of a single cavity photon, in sharp contrast to the single molecule case where the range of accessible vibronic angular momentum values are bounded. The observable consequences are a broadening of the cavity-molecular polariton spectrum and a suppression of photon polarization dynamics under broadband excitation of the system. Our results uncover new pathways for vibronic angular momentum transfer unique to collective molecular polaritonics with potential implications for cavity-assisted photo-physics and photo-chemistry.

</details>


### [132] [Mutual Mana: Converting Local Magic into Correlations via Discrete Beamsplitters](https://arxiv.org/abs/2511.08004)
*Linshuai Zhang,Huihui Li*

Main category: quant-ph

TL;DR: 本文提出了相互魔力(mutual mana)作为衡量多体系统中魔法关联的新指标，基于离散Wigner函数负性，研究了离散分束器产生的魔法相关性。


<details>
  <summary>Details</summary>
Motivation: 魔法(非稳定子性)是实现超越经典计算的通用容错量子计算的关键资源，但之前的研究主要关注单系统魔法，其在多体系统中的相互作用和分布仍未被充分探索。

Method: 基于魔力(mana)构建相互魔力的定义，通过离散分束器耦合魔法态和稳定子真空态，分析魔法资源的重新分布机制。

Result: 发现离散分束器能将局部魔法完全转化为相互魔力，建立了魔法资源重新分布为魔法关联的机制，并推导了多个原型qutrit态在离散分束器作用下的显式表达式。

Conclusion: 相互魔力是量化魔法关联的有效指标，与量子互信息、相互L1-范数魔法和相互稳定子2-Rényi熵等其他关联度量相比具有独特性质。

Abstract: Magic (non-stabilizerness) is a key resource for achieving universal fault-tolerant quantum computation beyond classical computation. While previous studies have primarily focused on magic in single systems, its interactions and distribution in multipartite settings remain largely unexplored. In this work, we introduce mutual mana as a measure of magic correlations defined in close analogy with quantum mutual information. Our definition builds upon mana, which is the established quantifier of magic based on discrete Wigner function negativity. We characterize magic correlations generated by discrete beamsplitters, whose Gaussian counterparts are fundamental components in quantum optics and quantum technologies. We show that coupling a magic state with a stabilizer vacuum state via a discrete beamsplitter will induce a full conversion of local magic into mutual mana, thereby establishing a mechanism for redistributing magic resources as magic correlations. We reveal the fundamental properties of mutual mana and derive its explicit expressions for several prototypical qutrit states subject to a discrete beamsplitter. We make a comparative study of mutual mana with several established quantifiers of correlations generated by the qutrit beamsplitter, including quantum mutual information, mutual $L^1$-norm magic, and mutual stabilizer 2-Rényi entropy.

</details>


### [133] [Realization of an all-optical effective negative-mass oscillator for coherent quantum noise cancellation](https://arxiv.org/abs/2511.08056)
*Nived Johny,Jonas Junker,Bernd Schulte,Dennis Wilken,Klemens Hammerer,Michèle Heurs*

Main category: quant-ph

TL;DR: 实现了桌面级全光学有效负质量振荡器，能够与易受量子辐射压力噪声影响的光机械传感器级联使用，实现量子噪声抵消。该系统通过下转换和分束过程实现光机械相互作用的等效光学实现，具有宽带抵消能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种紧凑、可调谐且波长灵活的系统，用于抵消光机械传感器中的量子辐射压力噪声，为量子信息处理提供新的应用前景。

Method: 采用光学等效的光机械相互作用方案，通过下转换和分束过程实现。开发了原位表征方案来表征系统的相互依赖参数。

Result: 获得的参数符合先前研究中设定的相干量子噪声抵消目标。当前实现预计可在最佳频率处实现3.6 dB的宽带量子噪声降低，相当于量子反作用噪声减少77%。

Conclusion: 有效负质量振荡器已具备应用准备状态，为量子信息和通信领域的新应用提供了前景。

Abstract: We report the realization of an all-optical, tabletop effective-negative-mass oscillator (ENMO) scheme capable of canceling quantum noise when cascaded with an opto-mechanical sensor susceptible to (quantum) radiation pressure noise. Our coherent quantum noise cancellation (CQNC) scheme offers a broadband cancellation capability with a tunable, wavelength-flexible, and compact system. This is achieved through the implementation of an optical equivalent of an opto-mechanical interaction, facilitated by a down-conversion and a beam-splitting process. The intricate nature of the system and its multiple interacting components made characterizing the interdependent parameters with conventional methods ineffective, leading to the development of an in-situ characterization scheme. The obtained parameters meet the targets for CQNC set in previous studies. With our current realization, we project a broadband quantum noise reduction of 3.6 dB, corresponding to a 77% reduction in quantum back-action noise at the optimal frequency of maximum reduction, indicating the readiness of the ENMO for application. We discuss the prospects for new applications in quantum information and communication using the same platform.

</details>


### [134] [Coherence in the Leak and Storage Kurtosis control Ergotropy in Quantum Batteries](https://arxiv.org/abs/2511.08063)
*Bitap Raj Thakuria,Trishna Kalita,Manash Jyoti Sarmah,Himangshu Prabal Goswami*

Main category: quant-ph

TL;DR: 该论文介绍了一种利用噪声诱导相干性的腔耦合有限量子系统作为量子电池，并应用全计数统计方法分析存储站中量子交换的高阶涨落，结合热力学参数构建预测各态历经性的机器学习平台。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池中各态历经性的预测问题，发现传统的量子变量和热力学变量在识别高各态历经性区域方面存在不足，需要寻找更有效的预测特征。

Method: 使用腔耦合有限量子系统作为量子电池模型，应用全计数统计方法分析量子交换的高阶涨落，结合热力学参数构建无监督和有监督的机器学习模型来预测各态历经性。

Result: 识别出存储站中量子交换的峰度和泄漏模式中的噪声诱导相干性是控制各态历经性大小的主要特征，能够以高准确度对各态历经性进行分类。

Conclusion: 量子电池中各态历经性的预测需要关注量子交换的峰度和噪声诱导相干性等非传统特征，而非仅依赖通常的量子变量和热力学变量。

Abstract: We introduce a cavity-coupled finite quantum system which can act as a quantum battery by harnessing noise induced coherences. We apply the methodology of full counting statistics to capture higher-order fluctuations of quanta exchange in the storage station. Together with the thermodynamic parameters, the fluctuations constitute a training platform for unsupervised as well as supervised learning models in predicting ergotropy. We identify a minimal predictive feature set from the battery's operating parameters that can classify the ergotropy into different regimes with great accuracy.Our results show that the usual quantum and thermodynamic variables are inadequate for the purpose of identifying high ergotropy regimes in isolation. Rather, it is the kurtosis of quanta exchange in the storage and the noise-induced coherence in the leakage mode that become the dominant quantities in controlling the magnitude of ergotropy.

</details>


### [135] [Repulsive Inverse-Distance Interatomic Interaction from Many-Body Quantum Electrodynamics](https://arxiv.org/abs/2511.08069)
*Loris Di Cairano,Matteo Gori,Reza Karimpour,Alexandre Tkatchenko*

Main category: quant-ph

TL;DR: 本文揭示了多体量子电动力学系统中存在持续的1/R相互作用，这种相互作用源于虚光子与分子等离激元的耦合，可能在未来微观尺度量子引力实验中显著超越引力吸引。


<details>
  <summary>Details</summary>
Motivation: 研究物体间相互作用的基本分类，特别是探索量子van der Waals和Casimir相互作用之外的潜在新型相互作用机制。

Method: 应用微扰量子电动力学理论到多体原子系统，将原子建模为带电谐振子，分析虚光子与分子等离激元在非延迟区域中的耦合。

Result: 发现了一种持续的1/R距离依赖的多体QED相互作用，该相互作用与精细结构常数的三次方成正比，类似于单原子的Lamb位移。

Conclusion: 虽然比van der Waals力弱，但这种多体QED的1/R相互作用可能在微观尺度量子引力实验中显著超越引力吸引，为研究量子引力提供了新的可能性。

Abstract: Interactions between objects can be classified as fundamental or emergent. Fundamental interactions are either extremely short-range or decay inversely with the separation distance, such as the Coulomb potential between charges or the gravitational attraction between masses. In contrast, emergent quantum van der Waals (vdW) and Casimir interactions decay considerably faster ($R^{-6}$ or $R^{-7}$) with distance $R$. Here we apply perturbative quantum electrodynamics (QED) to a many-body (MB) system of atoms modeled as charged harmonic oscillators, and reveal a persistent inverse-distance MB-QED interaction stemming from the coupling between virtual photons and molecular plasmons in the non-retarded regime. This interaction, scaling with the third power of the fine-structure constant, is reminiscent of the Lamb shift for a single atom. Although weaker than vdW forces, this MB-QED $R^{-1}$ interaction may substantially surpass gravitational attraction in future experiments probing quantum gravity at microscopic scales.

</details>


### [136] [Mixed-state phase structure of gauge-Higgs subsystem codes under logical-preserving decoherence](https://arxiv.org/abs/2511.08076)
*Yoshihito Kuno,Ikuo Ichinose*

Main category: quant-ph

TL;DR: 该研究从子系统码的角度研究了规范-希格斯模型中的局域规范对称退相干效应，揭示了子系统码的全局相图，发现了退相干诱导的非传统临界混合态，并分析了子系统码逻辑空间的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究规范-希格斯模型作为子系统码时，局域规范对称退相干对系统的影响，特别是理解退相干如何影响子系统码的相图和逻辑信息保护能力。

Method: 通过将规范-希格斯模型映射到受退相干影响的环面码来理解子系统码的性质，采用"规范化"处方分析退相干子系统码，并考虑特定幺正扰动来检验存储量子信息的鲁棒性。

Result: 发现退相干诱导了非传统临界混合态，其中逻辑信息被保留但系统其余部分呈现混合态临界性；子系统码的鲁棒性强烈依赖于规范量子比特的初始混合态。

Conclusion: 虽然任何规范-希格斯模型中的体混合态都可以产生这类子系统码，但由于混合临界规范量子比特的存在，其鲁棒性是一个微妙问题，逻辑量子比特与规范量子比特之间的相互作用会显著影响子系统码的形变。

Abstract: Some of lattice-gauge-theory models, in particular gauge-Higgs model (GHM), can be regarded and work as a subsystem code. This work studies the effect of local-gauge-symmetric decoherence on the GHM from the perspective of the subsystem code. We clarify the global phase diagram of the subsystem code. In particular, the decoherence induces an unconventional critical mixed state, where the logical information is preserved but the rest of the system exhibits mixed state criticality. For a fixed point, the decohered subsystem code is understood by the ``gauging out" prescription. By mapping the GHM to the toric code subject to decoherence, we can understand the properties of the subsystem code. We further discuss and investigate the robustness of the logical space of the subsystem code. Although this kind of subsystem code can be produced by using any bulk mixed state in the GHM, its robustness is a subtle problem due to the mixed critical gauge qubits. We consider some specific unitary for examining the robustness of the stored quantum information. For dynamical unitary perturbations described by interactions between the logical qubit and gauge qubits, the deformation of the subsystem code drastically depends on the initial mixed state of the gauge qubits.

</details>


### [137] [Gate Sequence Optimization for Parameterized Quantum Circuits using Reinforcement Learning](https://arxiv.org/abs/2511.08096)
*Tom R. Rieckmann,Stefan Scheel,A. Douglas K. Plato*

Main category: quant-ph

TL;DR: 使用强化学习优化量子态制备中的纠缠门序列，在相同CNOT门数量下比硬件高效ansatz获得更高的保真度


<details>
  <summary>Details</summary>
Motivation: 当前量子计算设备受限于噪声，主要来自纠缠门。如果不知道高效的门序列，通常使用固定纠缠层结构的参数化量子电路，但这种方法不够优化

Method: 提出强化学习算法来优化纠缠门序列，考虑量子比特连接架构，限制所需的CNOT门数量，并将方法扩展到参数化门集，包含通用单量子比特幺正门

Result: 与硬件高效ansatz相比，在相同CNOT门数量下能够持续达到更高的态制备保真度

Conclusion: 强化学习可以有效地优化量子电路中的纠缠门序列，提高量子态制备的性能

Abstract: Current experimental quantum computing devices are limited by noise, mainly originating from entangling gates. If an efficient gate sequence for an operation is unknown, one often employs layered parameterized quantum circuits, especially hardware-efficient ansätze, with fixed entangling layer structures. We demonstrate a reinforcement learning algorithm to improve on these by optimizing the entangling gate sequence in the task of quantum state preparation. This allows us to restrict the required number of CNOT gates while taking the qubit connectivity architecture into account. Recent advancements using reinforcement learning have already demonstrated the power of this technique when optimizing the circuit for a sequence of non-parameterized gates. We extend this approach to parameterized gate sets by incorporating general single-qubit unitaries, thus allowing us to consistently reach higher state preparation fidelities at the same number of CNOT gates compared to a hardware-efficient ansatz.

</details>


### [138] [Enhanced quantum correlations from joint pump and photon pair scattering](https://arxiv.org/abs/2511.08105)
*Mamoon Safadi,Nir Kuchuk,Ohad Lib,Yaron Bromberg,Arthur Goetschy*

Main category: quant-ph

TL;DR: 本文研究了在动态散射介质中产生的纠缠光子对如何保持尖锐的相关性峰值，即使泵浦光和下转换光子都经过散射。


<details>
  <summary>Details</summary>
Motivation: 当前非经典光散射研究通常对量子光的产生和光源做简化假设，本文旨在放松这些假设，探索在复杂介质中产生的纠缠光子对的行为。

Method: 通过实验和理论分析，研究由随机散射泵浦通过自发参量下转换产生的纠缠光子对在通过无序层后的行为，详细分析角相关形状与泵浦散射的关系。

Result: 实验证明即使泵浦和下转换光子都经过动态散射介质传播，光子对仍保持尖锐的相关性峰值，理论分析表明这些相关性不受光子对生成时机的影响。

Conclusion: 这些发现是理解复杂介质中量子光生成的关键步骤，并可能为量子技术应用提供新的可能性。

Abstract: Scattering of non-classical light is enabling new ways to study and control photon transport. However, advances in this field often rely on simplifying assumptions regarding the quantum light's generation and its source. In this work, we relax some of these assumptions and probe the behavior of entangled photon pairs passing through a disordered layer after being generated by a randomly scattered pump via spontaneous parametric down conversion. We experimentally demonstrate that, even when both the pump and the down-converted photons propagate through a dynamic scattering medium, the pairs maintain a sharp peak in their correlations. A comprehensive theoretical and numerical analysis shows that these correlations persist regardless of when the pairs are generated, whether immediately after the pump is scattered or under other conditions. More specifically, we detail how the shape of the angular correlation depends on the pump's scattering and how it varies with the distance between the pair-generation region and the entrance of the disordered medium. These findings represent a crucial step toward understanding quantum light generation in complex media, and potentially exploiting it for quantum technologies.

</details>


### [139] [Quantum Markov Chains: Hub-Pruned Estimation for Fashion Recommenders](https://arxiv.org/abs/2511.08200)
*Or Peretz,Tai Dinh,Michal Koren*

Main category: quant-ph

TL;DR: 研究浅层量子电路能否准确再现时尚电商推荐链接中离散时间马尔可夫链的短期动态，发现通过剪除颜色类别中的枢纽节点（如黑色和白色）可以显著提升量子与经典方法的一致性。


<details>
  <summary>Details</summary>
Motivation: 探索在浅层量子电路条件下，如何有效模拟电商推荐系统的马尔可夫链动态，特别关注枢纽节点对概率流的主导作用及其对量子模拟精度的影响。

Method: 将转移算子编译为块编码电路，使用固定点遗忘振幅放大进行迭代，采用振幅编码边缘分布估计经典前向传播，并评估三种链变体（完整网络、无黑色网络、无黑白网络）在现实电路深度和测量预算下的表现。

Result: 枢纽剪除在不同零售商聚合网络中一致改善量子与经典方法的一致性：总变差距离和KL散度通常减少约一半，状态保真度保持接近1。偏差-收缩分析显示增益源于减少交叉项和有效拓宽谱间隙。

Conclusion: 枢纽剪除的块编码是使用小型量子寄存器进行推荐动态近端实验的实用启发式方法，提供了一个可复现的基准测试协议，报告总变差距离、KL散度和状态保真度随电路深度和预测范围的变化。

Abstract: We investigate whether shallow quantum circuits can accurately reproduce the short-horizon dynamics of discrete-time Markov chains derived from fashion electronic-commerce recommendation links. Transition operators are compiled into block-encoded circuits and iterated using fixed-point oblivious amplitude amplification, and amplitude-encoded marginals are used to estimate the classical push-forward. Empirically, colour categories such as black and, to a lesser extent, white function as high-degree hubs that dominate probability flow. Consequently, we assess three chain variants: the full network including all colours, a network without black, and a network without black and white, to quantify the effect of hub pruning under realistic circuit depths and measurement budgets. Across networks aggregated from multiple retailers, hub pruning consistently improves quantum and classical agreement at shallow depth; total-variation distance and Kullback-Leibler divergence typically decrease by approximately a factor of two relative to the full network, while state fidelities remain close to unity. A bias-and-contraction analysis explains these gains through reduced cross-terms and an effectively widened spectral gap. The results identify hub-pruned block-encodings as a practical heuristic for near-term experiments on recommendation dynamics using small quantum registers, and they provide a reproducible benchmarking protocol that reports total-variation distance, Kullback-Leibler divergence, and state fidelity as functions of circuit depth and prediction horizon.

</details>


### [140] [From Classical to Hybrid: A Practical Framework for Quantum-Enhanced Learning](https://arxiv.org/abs/2511.08205)
*Silvie Illésová,Tomáš Bezděk,Vojtěch Novák,Ivan Zelinka,Stefano Cacciatore,Martin Beseda*

Main category: quant-ph

TL;DR: 提出了一个三阶段框架，帮助非量子专家从经典机器学习过渡到混合量子-经典机器学习工作流，通过诊断反馈优化混合架构，在Iris数据集上准确率从0.31提升到0.87。


<details>
  <summary>Details</summary>
Motivation: 解决非量子专家难以从经典机器学习过渡到混合量子-经典机器学习工作流的挑战，为经典机器学习从业者提供利用量子增强方法的实用途径。

Method: 三阶段框架：从经典自训练模型开始，引入最小混合量子变体，然后通过QMetric应用诊断反馈来优化混合架构。

Result: 在Iris数据集实验中，优化后的混合模型准确率从经典方法的0.31提高到量子方法的0.87。

Conclusion: 即使适度的量子组件，在适当诊断指导下也能增强混合学习中的类别分离和表示能力，为经典机器学习从业者提供了利用量子增强方法的实用路径。

Abstract: This work addresses the challenge of enabling practitioners without quantum expertise to transition from classical to hybrid quantum-classical machine learning workflows. We propose a three-stage framework: starting with a classical self-training model, then introducing a minimal hybrid quantum variant, and finally applying diagnostic feedback via QMetric to refine the hybrid architecture. In experiments on the Iris dataset, the refined hybrid model improved accuracy from 0.31 in the classical approach to 0.87 in the quantum approach. These results suggest that even modest quantum components, when guided by proper diagnostics, can enhance class separation and representation capacity in hybrid learning, offering a practical pathway for classical machine learning practitioners to leverage quantum-enhanced methods.

</details>


### [141] [Fidelity sweet spot in transmon qubit rings under strong connectivity noise](https://arxiv.org/abs/2511.08267)
*Quan Fu,Xin Wang,Rui Xiong*

Main category: quant-ph

TL;DR: 研究超导量子比特系统中SWAP和通用门操作的保真度，发现即使在强噪声下也存在保真度最佳点，特定初始状态能达到量子纠错阈值，并开发了机器学习框架来预测最佳点位置。


<details>
  <summary>Details</summary>
Motivation: 研究量子门操作在噪声环境下的保真度特性，探索如何优化电路深度和初始状态来提高门操作性能，为量子纠错提供基础。

Method: 分析超导量子比特系统中的SWAP和通用门操作，研究不同电路深度和初始状态对保真度的影响，并开发监督机器学习框架来预测保真度最佳点。

Result: 发现即使在强噪声下也存在保真度最佳点，特定对称性或纠缠结构的初始状态能达到量子纠错阈值级别的保真度，机器学习框架能有效预测最佳点位置。

Conclusion: 通过优化电路深度和选择合适的初始状态，可以在噪声环境中显著提高量子门操作的保真度，机器学习方法为跨设备配置的电路优化提供了有效工具。

Abstract: We investigate the fidelity of quantum operations in transmon qubit systems, focusing on both SWAP and general gate operations. Our results reveal a distinct fidelity sweet spot that emerges even under strong noise, indicating that optimal circuit depth can enhance gate performance. We further demonstrate that specific initial states, particularly those with favorable symmetry or entanglement structure, yield higher fidelity, reaching levels compatible with quantum error-correction thresholds. Finally, we introduce a supervised machine-learning framework capable of predicting the positions of fidelity sweet spots, enabling efficient optimization of circuit durations across different device configurations.

</details>


### [142] [Exact-factorization framework for electron-nuclear dynamics in electromagnetic fields](https://arxiv.org/abs/2511.08268)
*Vladimir U. Nazarov,E. K. U. Gross*

Main category: quant-ph

TL;DR: 将精确因子化理论扩展到电磁场作用下的系统，揭示了物理磁场与贝里曲率场之间的重要相互作用，并严格证明了中性原子在均匀磁场中核运动方程中磁场与贝里曲率场的补偿性质。


<details>
  <summary>Details</summary>
Motivation: 将精确因子化理论扩展到电磁场作用下的系统，研究物理磁场与贝里曲率场之间的相互作用，验证中性原子在均匀磁场中核运动方程中磁场补偿的猜想。

Method: 扩展精确因子化理论框架，纳入电磁场作用，通过严格数学证明分析核运动方程中物理磁场与贝里曲率场的补偿机制。

Result: 揭示了物理磁场与贝里曲率场之间的重要相互作用，并严格证明了中性原子在均匀磁场中核运动方程中磁场与贝里曲率场的补偿性质。

Conclusion: 精确因子化理论成功扩展到电磁场系统，为理解非绝热理论中磁场与贝里曲率场的相互作用提供了严格的理论基础，验证了先前关于磁场补偿的猜想。

Abstract: The Exact Factorization (EF) theory aims at the separation of the nuclear and electronic degrees of freedom in the many-body (MB) quantum mechanical problem. Being formally equivalent to the solution of the MB Schrödinger equation, EF sets up a strategy for the construction of efficient approximations in the theory of the correlated electronic-nuclear motion. Here we extend the EF formalism to incorporate the case of a system under the action of an electromagnetic field. An important interplay between the physical magnetic and the Berry-curvature fields is revealed and discussed within the fully non-adiabatic theory. In particular, it is a known property of the Born-Oppenheimer approximation that, for a neutral atom in a uniform magnetic field, the latter is compensated by the Berry-curvature field in the nuclear equation of motion (\citet{Yin-92}). From an intuitive argument that the atom must not be deflected by the Lorentz force from a straight line trajectory, it has been conjectured that the same compensation should occur within the EF theory as well. We give a rigorous proof of this property.

</details>


### [143] [Nonexistence of maximally entangled mixed states for a fixed spectrum](https://arxiv.org/abs/2511.08285)
*Gonzalo Camacho,Julio I. de Vicente*

Main category: quant-ph

TL;DR: 本文扩展了关于固定谱下最大纠缠态不可能存在的证明，覆盖了所有秩2和秩3的两量子比特态，以及秩4情况下的广泛特征值分布类别。


<details>
  <summary>Details</summary>
Motivation: 探索在给定谱分布下是否存在最大纠缠态的概念，这是纯态最大纠缠概念的自然推广。

Method: 扩展了先前在特定谱分布下的不可能性证明，将其推广到更广泛的秩和特征值分布情况。

Result: 证明在所有秩2和秩3的两量子比特态中，以及秩4情况下的广泛特征值分布类别中，都不存在固定谱下的最大纠缠态。

Conclusion: 除了纯态（秩1）这一特例外，在固定谱分布下不存在最大纠缠态，这一结论适用于两量子比特系统的绝大多数情况。

Abstract: The existence of a maximally entangled pure state is a cornerstone result of entanglement theory that has paramount consequences in quantum information theory. A natural generalization of this property is to consider whether a notion of maximal entanglement is possible among all states with the same spectrum (where the aforementioned case of pure states corresponds to the particular choice in which the spectrum is a delta distribution, i.e., rank-1 states). Despite positive evidence in the past that such a notion might exist at least in the case of two-qubit states, it was recently shown in [Phys. Rev. Lett. 133, 050202 (2024)] that the answer to the above question is negative. This reference proved this for particular choices of the spectrum in the case of rank-2 two-qubit density matrices. While this settles the problem in general, it still leaves open whether there are other choices of the spectrum outside the case of pure states where a maximally entangled state for a fixed spectrum might exist. In this work we extend this impossibility result to all rank-2 and rank-3 two-qubit states as well as for a large class of eigenvalue distributions in the case where the rank equals four.

</details>


### [144] [Reliable Optimization Under Noise in Quantum Variational Algorithms](https://arxiv.org/abs/2511.08289)
*Vojtěch Novák,Silvie Illésová,Tomáš Bezděk,Ivan Zelinka,Martin Beseda*

Main category: quant-ph

TL;DR: 该论文研究了变分量子本征求解器(VQE)在有限采样噪声下的优化挑战，通过比较8种经典优化器发现自适应元启发式算法(特别是CMA-ES和iL-SHADE)在噪声环境下表现最优，并提出了基于种群均值校正偏差的实用优化指南。


<details>
  <summary>Details</summary>
Motivation: VQE优化受到有限采样噪声的严重影响，这种噪声会扭曲代价函数景观、产生虚假变分极小值，并引发统计偏差（赢家诅咒）。研究旨在找到在噪声环境下最有效的优化策略。

Method: 在量子化学哈密顿量(H2、H4链、LiH)上对8种经典优化器（包括梯度法、无梯度法和元启发式方法）进行基准测试，使用截断变分哈密顿量ansatz，并扩展到硬件高效电路和凝聚态模型。

Result: 梯度法在噪声环境中发散或停滞，而基于种群的优化器通过跟踪种群均值而非有偏差的最佳个体可以校正估计器偏差。自适应元启发式算法(CMA-ES和iL-SHADE)被证明是最有效和鲁棒的策略。

Conclusion: 提出了可靠的VQE噪声优化实用指南，核心是物理动机ansatz的协同设计和自适应优化器的使用，强调基于种群的优化方法在噪声环境中的优势。

Abstract: The optimization of Variational Quantum Eigensolver is severely challenged by finite-shot sampling noise, which distorts the cost landscape, creates false variational minima, and induces statistical bias called winner's curse. We investigate this phenomenon by benchmarking eight classical optimizers spanning gradient-based, gradient-free, and metaheuristic methods on quantum chemistry Hamiltonians H$_2$, H$_4$ chain, LiH (in both full and active spaces) using the truncated Variational Hamiltonian Ansatz. We analyze difficulties of gradient-based methods (e.g., SLSQP, BFGS) in noisy regimes, where they diverge or stagnate. We show that the bias of estimator can be corrected by tracking the \textit{population mean}, rather than the biased best individual when using population based optimizer. Our findings, which are shown to generalize to hardware-efficient circuits and condensed matter models, identify adaptive metaheuristics (specifically CMA-ES and iL-SHADE) as the most effective and resilient strategies. We conclude by presenting a set of practical guidelines for reliable VQE optimization under noise, centering on the co-design of physically motivated ansatz and the use of adaptive optimizers.

</details>


### [145] [Quantum-driven sampling of the quasi-uniform distribution via quantum walks](https://arxiv.org/abs/2511.08293)
*Marco Radaelli,Claudia Benedetti,Stefano Olivares*

Main category: quant-ph

TL;DR: 使用离散时间量子行走在无外部随机源情况下生成近似均匀分布的随机数序列，通过分析量子行走的转移概率和遍历定理证明渐近收敛到均匀分布。


<details>
  <summary>Details</summary>
Motivation: 研究在没有外部随机源的情况下，利用量子行走的内在随机性来生成近似均匀分布的随机数序列。

Method: 在循环图上编码整数，量子行走者演化固定步数后测量位置并记录，然后重置到测量位置并迭代该过程生成随机数序列。

Result: 当量子行走参数满足有限群上随机行走遍历定理条件时，生成的序列渐近收敛到均匀分布，通过选择合适的演化时间可以显著减少连续结果间的相关性。

Conclusion: 量子行走可以有效地生成近似均匀分布的随机数序列，其收敛性通过遍历定理和转移概率的迭代卷积分析得到证明。

Abstract: We investigate the use of discrete-time quantum walks to sample from an almost-uniform distribution, in the absence of any external source of randomness. Integers are encoded on the vertices of a cycle graph, and a quantum walker evolves for a fixed number of steps before its position is measured and recorded. The walker is then reset to the measured site, and the procedure is iterated to produce the sequence of random numbers. We show that when the quantum walk parameters, such as the coin operator and initial state, satisfy the conditions of the ergodic theorem for random walks on finite groups, the resulting sequence converges asymptotically to the uniform distribution. Although correlations between successive outcomes are unavoidable, they can be significantly reduced by a suitable choice of the evolution time. By analyzing the iterated convolution of the quantum walk transition probability and exploiting the ergodic theorem, we demonstrate convergence of the marginal distributions toward the uniform distribution in the asymptotic limit.

</details>


### [146] [Comprehensive Analysis of Geometric Phase for SU(3) Representations](https://arxiv.org/abs/2511.08323)
*Abhirup Chatterjee,Sobhan Kumar Sounda*

Main category: quant-ph

TL;DR: 该论文探讨了三能级开放系统中混合态的几何相位，利用八维庞加莱球和SU(2)极化图景，在纯态极限下与Pancharatnam相、Berry相和Aharonov-Anandan相一致。


<details>
  <summary>Details</summary>
Motivation: 利用复希尔伯特空间的几何结构来研究混合态中的几何相位，特别是在三能级开放系统经历去极化过程的情况。

Method: 使用八维庞加莱球在SU(2)极化图景中描述混合态，并在纯态极限下分析非单位向量射线在H3空间中的行为。

Result: 在纯态极限下，该方法得到的几何相位与Pancharatnam相、Berry相和Aharonov-Anandan相吻合。

Conclusion: 几何相位可以在混合态系统中通过适当的几何结构进行描述，且在纯态极限下与已知的几何相位理论一致。

Abstract: Geometric Phase in Quantum Mechanics is generally formulated entirely in terms of geometric structure of the Complex Hilbert Space. We will exploit this fact in case of mixed states for three level open systems undergoing depolarization using the eight dimensional Poincare sphere in the SU(2) Polarisation picture and non unit vector rays in H3 within the limit of pure state approach may be found to be in agreement with the Pancharatnam Phase, Berry Phase and Aharonov-Anandan Phase.

</details>


### [147] [Hybrid Quantum-Classical Selective State Space Artificial Intelligence](https://arxiv.org/abs/2511.08349)
*Amin Ebrahimi,Farzan Haddadi*

Main category: quant-ph

TL;DR: 提出了一种混合量子经典选择机制用于Mamba架构，通过变分量子电路作为量子门控模块来增强特征提取和抑制无关信息，在时序序列分类任务中实现了比纯经典方法更高的准确率和表达能力。


<details>
  <summary>Details</summary>
Motivation: 利用量子系统在高维希尔伯特空间中的计算优势，解决机器学习特别是自然语言处理中大规模矩阵乘法和高维优化带来的计算瓶颈问题。

Method: 将变分量子电路作为量子门控模块集成到Mamba架构中，用于时序序列分类任务，通过量子子程序增强特征提取和抑制无关信息。

Result: 在重构的MNIST数据集上，前4个epoch中混合模型达到24.6%的准确率，而纯经典选择机制为21.6%，同时使用更少的量子层实现了更高的表达能力。

Conclusion: 量子增强的门控机制为构建可扩展、资源高效的NLP模型提供了一条可行路径，在有限模拟步骤中展现了量子经典混合方法的潜力。

Abstract: Hybrid Quantum Classical (HQC) algorithms constitute one of the most effective paradigms for exploiting the computational advantages of quantum systems in large-scale numerical tasks. By operating in high-dimensional Hilbert spaces, quantum circuits enable exponential speed-ups and provide access to richer representations of cost landscapes compared to purely classical methods. These capabilities are particularly relevant for machine learning, where state-of-the-art models especially in Natural Language Processing (NLP) suffer from prohibitive time complexity due to massive matrix multiplications and high-dimensional optimization.
  In this manuscript, we propose a Hybrid Quantum Classical selection mechanism for the Mamba architecture, designed specifically for temporal sequence classification problems. Our approach leverages Variational Quantum Circuits (VQCs) as quantum gating modules that both enhance feature extraction and improve suppression of irrelevant information. This integration directly addresses the computational bottlenecks of deep learning architectures by exploiting quantum resources for more efficient representation learning.
  We analyze how introducing quantum subroutines into large language models (LLMs) impacts their generalization capability, expressivity, and parameter efficiency. The results highlight the potential of quantum-enhanced gating mechanisms as a path toward scalable, resource-efficient NLP models, in a limited simulation step. Within the first four epochs on a reshaped MNIST dataset with input format (batch, 784, d_model), our hybrid model achieved 24.6% accuracy while using one quantum layer and achieve higher expressivity, compared to 21.6% obtained by a purely classical selection mechanism. we state No founding

</details>


### [148] [An Information-Minimal Geometry for Qubit-Efficient Optimization](https://arxiv.org/abs/2511.08362)
*Gordon Ma,Dimitris G. Angelakis*

Main category: quant-ph

TL;DR: 提出了一种量子比特高效的优化方法，将N变量组合问题表示为比2^N更小的希尔伯特空间，通过几何方法匹配二次目标的结构，使用Sherali-Adams level-2多面体显式处理局部一致性，仅需对数宽度量子比特即可实现接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 标准量子电路探索指数级大的状态空间，但二次无约束二进制优化(QUBO)问题仅依赖于二元变量之间的成对信息，因此需要更高效的量子比特表示方法。

Method: 将量子比特高效优化重新表述为几何问题，使用SA(2)多面体显式处理局部一致性，通过可微迭代比例拟合(IPF)步骤进行投影，并通过最大熵吉布斯采样器进行解码。

Result: 在Gset Max-Cut实例(N=800-2000)上，深度2-3的电路达到接近最优的比率(r*≈0.99)，超越了直接的SA(2)基线方法。

Conclusion: 该框架通过具体的凸几何和最小可微投影解决了局部一致性差距，建立了清晰的多面体基线，为超越SA(2)的自然扩展铺平了道路。

Abstract: Qubit-efficient optimization seeks to represent an $N$-variable combinatorial problem within a Hilbert space smaller than $2^N$, using only as much quantum structure as the objective itself requires. Quadratic unconstrained binary optimization (QUBO) problems, for example, depend only on pairwise information -- expectations and correlations between binary variables -- yet standard quantum circuits explore exponentially large state spaces. We recast qubit-efficient optimization as a geometry problem: the minimal representation should match the $O(N^2)$ structure of quadratic objectives. The key insight is that the local-consistency problem -- ensuring that pairwise marginals correspond to a realizable global distribution -- coincides exactly with the Sherali-Adams level-2 polytope $\mathrm{SA}(2)$, the tightest convex relaxation expressible at the two-body level. Previous qubit-efficient approaches enforced this consistency only implicitly. Here we make it explicit: (a) anchoring learning to the $\mathrm{SA}(2)$ geometry, (b) projecting via a differentiable iterative-proportional-fitting (IPF) step, and (c) decoding through a maximum-entropy Gibbs sampler. This yields a logarithmic-width pipeline ($2\lceil\log_2 N\rceil + 2$ qubits) that is classically simulable yet achieves strong empirical performance. On Gset Max-Cut instances (N=800--2000), depth-2--3 circuits reach near-optimal ratios ($r^* \approx 0.99$), surpassing direct $\mathrm{SA}(2)$ baselines. The framework resolves the local-consistency gap by giving it a concrete convex geometry and a minimal differentiable projection, establishing a clean polyhedral baseline. Extending beyond $\mathrm{SA}(2)$ naturally leads to spectrahedral geometries, where curvature encodes global coherence and genuine quantum structure becomes necessary.

</details>


### [149] [Exploring the performance of superposition of product states: from 1D to 3D quantum spin systems](https://arxiv.org/abs/2511.08407)
*Apimuk Sornsaeng,Itai Arad,Dario Poletti*

Main category: quant-ph

TL;DR: 本文研究了叠加乘积态(SPS)变分框架的性能，该框架与规范多线性张量分解结构相关，相比张量网络具有信息提取准确、几何结构独立、易于并行化和允许解析捷径等优势，并在倾斜伊辛模型中验证了其高精度性能。


<details>
  <summary>Details</summary>
Motivation: 张量网络(TNs)在研究多体量子系统时存在局限性，特别是在通用几何结构中受到表达能力和信息近似提取的限制。SPS框架虽然信息压缩效率不如张量网络，但具有几何结构独立性等优势，值得研究其性能。

Method: 采用叠加乘积态(SPS)变分框架，首先研究自旋-1/2系统中SPS的典型性质，包括纠缠熵和可训练性，然后将其应用于倾斜伊辛模型的基态搜索，包括一维和三维系统以及具有短程和长程相互作用的随机网络。

Result: 研究表明SPS框架能够达到高精度，在多种几何结构的倾斜伊辛模型中表现出色，验证了其在量子多体系统研究中的有效性。

Conclusion: SPS变分框架为研究多体量子系统提供了一种有前景的替代方法，特别是在处理复杂几何结构时具有独特优势，虽然信息压缩效率不如张量网络，但其几何结构独立性和准确信息提取能力使其成为有价值的工具。

Abstract: Tensor networks (TNs) are one of the best available tools to study many-body quantum systems. TNs are particularly suitable for one-dimensional local Hamiltonians, while their performance for generic geometries is mainly limited by two aspects: the limitation in expressive power and the approximate extraction of information. Here we investigate the performance of superposition-of-product-states (SPS) ansatz, a variational framework structurally related to canonical polyadic tensor decomposition. The ansatz does not compress information as effectively as tensor networks, but it has the advantages (i) of allowing accurate extraction of information, (ii) of being structurally independent of the geometry of the system, (iii) of being readily parallelizable, and (iv) of allowing analytical shortcuts. We first study the typical properties of the SPS ansatz for spin-$1/2$ systems, including its entanglement entropy, and its trainability. We then use this ansatz for ground state search in tilted Ising models--including one-dimensional and three-dimensional with short- and long-range interaction, and a random network--demonstrating that SPS can attain high accuracy.

</details>


### [150] [Surprising applications of Newton's hyperbolism transform of curves in Fourier-transform spectroscopy](https://arxiv.org/abs/2511.08434)
*Dennis Huber,Steffen J. Glaser*

Main category: quant-ph

TL;DR: 本文研究并推广了牛顿发现的几何变换——曲线双曲变换，该变换可将椭圆转换为洛伦兹线形，反之亦然，揭示了布洛赫图像与洛伦兹线形的直接几何联系，并提出了新的连续参数化方法和变迹技术。


<details>
  <summary>Details</summary>
Motivation: 傅里叶变换是现代光谱学中的关键工具，但传统方法主要关注洛伦兹线形。本文旨在探索布洛赫图像与洛伦兹线形之间的几何联系，并开发新的线形变换方法。

Method: 研究并推广牛顿的曲线双曲几何变换，引入连续参数化方法，开发新的变迹技术来复制截断抛物线线形。

Result: 发现布洛赫图像与洛伦兹线形存在直接几何关系，通过半变换可获得有限支撑的截断抛物线线形，并成功在核磁共振光谱中应用新的变迹方法。

Conclusion: 牛顿的几何变换为光谱线形分析提供了新的视角，建立了布洛赫图像与洛伦兹线形的几何联系，开发的新方法在核磁共振光谱中有实际应用价值。

Abstract: The Fourier transform (FT) represents a key tool in modern spectroscopy which drastically reduces measurement times and helps to improve the signal-to-noise ratio in spectra. Fourier transforming exponentially decaying time domain signals gives Lorentzian line shapes which can be manipulated by apodization methods. The underlying transitions of spectral lines can be visualized by a Bloch vector or equivalent phase-space representations. Here, we study and generalize a surprisingly elegant geometric transform, the hyperbolism of curves originally found by Isaac Newton, which allows to transform ellipses into Lorentzian lines, and vice versa. With this, we show that the Bloch picture and especially corresponding phase-space representations are directly geometrically related to the Lorentzian line shape. We also introduce a novel continuous parametrization of Newton's transform which results in further interesting line shapes. In particular, we find that truncated parabolic lines with finite support can be obtained by the half transform and introduce a new apodization approach to replicate this line shape in experimental spectra. We discuss concrete applications in nuclear magnetic resonance spectroscopy.

</details>


### [151] [Comparison of Two Optimization Methods for a Rydberg Quantum Gate](https://arxiv.org/abs/2511.08450)
*Luis S. Yagüe Bosch,Sandro Wimberger*

Main category: quant-ph

TL;DR: 比较了两种实现里德堡原子高保真量子门的方法：反绝热捷径方法和数值优化方法，发现数值优化方法在保持类似鲁棒性的同时能达到更高保真度。


<details>
  <summary>Details</summary>
Motivation: 比较分析性反绝热捷径协议与暴力数值优化技术在先进量子计算平台上的性能表现，研究优化脉冲在时间和幅度上的约束对优化方法质量的关键作用。

Method: 使用反绝热方法通过快速振荡场模拟反绝热哈密顿量的时间演化来加速高保真门，同时使用Boulder Opal平台进行数值优化门设计。

Result: 数值优化门实现了更高的保真度，同时展现出与有效反绝热门相似的抗误差鲁棒性。

Conclusion: 研究强调了优化脉冲在时间和幅度上的约束在决定优化方法质量方面的重要作用，为分析性捷径协议与数值优化技术的比较提供了实例。

Abstract: A shortcut-to-adiabaticity is compared with a numerically optimized protocol for implementing a high-fidelity quantum gate on Rydberg atoms. The counterdiabatic method offers an analytical framework for accelerating high-fidelity gates by mimicking the time evolution of a counterdiabatic Hamiltonian using fast-oscillating fields. This approach is contrasted with a numerically optimized gate designed using the Boulder Opal platform. The numerically optimized gate achieves higher fidelities while demonstrating robustness against errors similar to that of the effective counterdiabatic gate. The study serves as an example of the performance of analytic shortcut-to-adiabatic-inspired protocols compared to brute-force numerical optimization techniques for state-of-the-art quantum computing platforms. It stresses the important role played by constraints on the optimized pulses in time and in amplitude that are crucial in determining the quality of the optimization method.

</details>


### [152] [Comment on "Role of Matter Interactions in Superradiant Phenomena"](https://arxiv.org/abs/2511.08452)
*Max Hörmann,Anja Langheld,Jonas Leibig,Andreas Schellenberger,Kai Phillip Schmidt*

Main category: quant-ph

TL;DR: 本文回应了Mendonça等人的研究，证明Dicke-Ising模型中确实存在具有超辐射和反铁磁序的中间相以及相变线阶数的变化。


<details>
  <summary>Details</summary>
Motivation: Mendonça等人的研究声称Dicke-Ising模型中不存在具有超辐射和反铁磁序的中间相，且相变线阶数没有变化，这与先前研究结果相矛盾。本文旨在验证这些特征确实存在于该模型中。

Method: 通过分析Dicke-Ising模型在Mendonça等人研究的参数范围内的性质，验证中间相和相变线阶数变化的特征。

Result: 研究证实Dicke-Ising模型中确实存在具有超辐射和反铁磁序的中间相，并且相变线的阶数确实会发生变化。

Conclusion: Mendonça等人的结论需要修正，Dicke-Ising模型在研究的参数范围内确实展现出先前观察到的中间相和相变线阶数变化的特征。

Abstract: Recently, Mendonça et al. [arXiv:2503.04961] investigated the Dicke-XXZ model and the Dicke-Ising model. For the latter model, their calculated quantum phase diagram contradicts claims about the existence of an intermediate phase with superradiant and antiferromagnetic order and the change in order of some phase transition lines, observed in other studies. In this comment we demonstrate that both features are indeed present in the Dicke-Ising model for the investigated parameter range in [arXiv:2503.04961].

</details>


### [153] [A Quantum Non-Gaussianity Criterion Based on Photon Correlations $g^{(2)}$ and $g^{(3)}$](https://arxiv.org/abs/2511.08488)
*Christoph Hotter,Clara Henke,Cornelis Jacobus van Diepen,Peter Lodahl,Anders Søndberg Sørensen*

Main category: quant-ph

TL;DR: 提出了基于二阶和三阶关联函数g^(2)和g^(3)的抗衰减量子非高斯态充分判据，实验验证了量子点单光子源产生的态违反该判据，证实了量子非高斯性。


<details>
  <summary>Details</summary>
Motivation: 量子非高斯态在连续变量系统中是实现量子优势的必要条件，是先进量子光源的重要基准，因为它们无法通过简单的位移和压缩操作产生。

Method: 引入基于二阶和三阶关联函数g^(2)和g^(3)的抗衰减充分判据，对于经典高斯态混合有√g^(3)+3√g^(2)≥2的不等式约束，违反该不等式即证实量子非高斯性。

Result: 实验测得量子点单光子源产生的态满足√g^(3)+3√g^(2)=0.174(13)，统计显著性超过100个标准差，明确违反了高斯态混合的界限。

Conclusion: 成功建立了抗衰减的量子非高斯态判据，并通过实验验证了量子点单光子源能够产生量子非高斯态，为先进量子光源的基准测试提供了有效工具。

Abstract: Quantum non-Gaussian states, which cannot be written as mixtures of Gaussian states, are necessary to achieve a quantum advantage in continuous variable systems. They represent an important benchmark for the realization of an advanced quantum light source, as they cannot be made by simple means such as displacement and squeezing. We introduce an attenuation-resistant sufficient criterion for quantum non-Gaussian states based on the second- and third-order correlation functions, $g^{(2)}$ and $g^{(3)}$. The general non-linear bound for classical mixtures of Gaussian states is $\sqrt{g^{(3)}} + 3 \sqrt{g^{(2)}} \geq 2$. Any mixture of Gaussian states must fulfill this inequality, thus, the violation of it represents a direct confirmation of quantum non-Gaussianity. We experimentally show the non-Gaussianity of the state produced by a quantum dot single-photon source, where we obtain $\sqrt{g^{(3)}} + 3 \sqrt{g^{(2)}} = 0.174 (13)$, which represents a statistical significance of more than $100$ standard deviations.

</details>


### [154] [Reinforcement Learning Control of Quantum Error Correction](https://arxiv.org/abs/2511.08493)
*Volodymyr Sivak,Alexis Morvan,Michael Broughton,Matthew Neeley,Alec Eickbusch,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Aghababaie Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Trond I. Andersen,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Bigdeli Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Alexandre Bourassa,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Roberto Collins,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Ilya Drozdov,Andrew Dunsworth,Valerie Ehimhen,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Vinicius S. Ferreira,Marcos Flores,Leslie Flores Burgos,Ebrahim Forati,Jeremiah Ford,Austin G. Fowler,Brooks Foxen,Masaya Fukami,Alan Wing Lun Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,Élie Genois,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. de Graaf,Alejandro Grajales Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Le Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Dvir Kafri,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Tanuj Khattar,Mostafa Khezri,Seon Kim,Can M. Knaut,Bryce Kobrin,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Nathan Lacroix,David Landhuis,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Justin Ledford,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Ming Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Aditya Locharla,Laura De Lorenzo,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Masih Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Logan Oas,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Di Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Gabrielle Roberts,Roberto Rodriguez,Emma Ropes,Lucia B. De Rose,Eliott Rosenberg,Emma Rosenfeld,Dario Rosenstock,Elizabeth Rossi,Pedram Roushan,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Kevin J. Satzinger,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Noah Shutty,Vladimir Shvarts,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Catherine Vollgraff Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. K. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Ryan Babbush,Dave Bacon,Sergio Boixo,Yu Chen,Zijun Chen,Michel Devoret,Monica Hansen,Jeremy Hilton,Cody Jones,Julian Kelly,Alexander N. Korotkov,Erik Lucero,Anthony Megrant,Hartmut Neven,William D. Oliver,Ganesh Ramachandran,Vadim Smelyanskiy,Paul V. Klimov*

Main category: quant-ph

TL;DR: 提出了一种将校准与计算统一的方法，利用量子纠错过程中的错误检测事件作为强化学习信号，持续调整物理控制参数以稳定量子系统，无需停止计算进行重新校准。


<details>
  <summary>Details</summary>
Motivation: 解决环境漂移持续降低量子操作质量的问题，避免传统方法需要停止整个量子计算进行重新校准的不可持续做法。

Method: 将量子纠错过程赋予双重角色：不仅用于纠正逻辑量子态，还将其错误检测事件重新用作强化学习代理的学习信号，持续引导物理控制参数。

Result: 在超导处理器上实验证明，将表面码的逻辑错误率稳定性提高了3.5倍，性能超过了最先进的传统校准和人工专家调优。距离-15的表面码模拟证实了方法的可扩展性。

Conclusion: 实现了一种新范式：量子计算机能够直接从其错误中学习自我改进，并且永不停止计算。

Abstract: The promise of fault-tolerant quantum computing is challenged by environmental drift that relentlessly degrades the quality of quantum operations. The contemporary solution, halting the entire quantum computation for recalibration, is unsustainable for the long runtimes of the future algorithms. We address this challenge by unifying calibration with computation, granting the quantum error correction process a dual role: its error detection events are not only used to correct the logical quantum state, but are also repurposed as a learning signal, teaching a reinforcement learning agent to continuously steer the physical control parameters and stabilize the quantum system during the computation. We experimentally demonstrate this framework on a superconducting processor, improving the logical error rate stability of the surface code 3.5-fold against injected drift and pushing the performance beyond what is achievable with state-of-the-art traditional calibration and human-expert tuning. Simulations of surface codes up to distance-15 confirm the scalability of our method, revealing an optimization speed that is independent of the system size. This work thus enables a new paradigm: a quantum computer that learns to self-improve directly from its errors and never stops computing.

</details>


### [155] [Dynamical Chaos in a Dissipative Driven Quantum Soft Impact Oscillator](https://arxiv.org/abs/2511.08497)
*Titir Mukherjee,Arnab Acharya,Soumitro Banerjee,Deb Shankar Ray*

Main category: quant-ph

TL;DR: 使用复数量子朗之万方程研究周期性驱动耗散软碰撞振子中的量子混沌动力学，发现通过改变壁位置会引发丰富的动力学转变和擦边分岔，从周期性运动发展到混沌行为。


<details>
  <summary>Details</summary>
Motivation: 研究量子耗散环境下碰撞诱导混沌的持续性，阐明环境涨落对开放量子系统中非线性动力学的影响。

Method: 采用复数量子朗之万方程分析周期性驱动的耗散软碰撞振子，使用分岔图、李雅普诺夫指数、傅里叶谱和0-1测试等时间序列诊断工具。

Result: 系统性地改变壁位置揭示了从周期性到多周期性运动，最终发展为混沌行为的丰富动力学转变序列和擦边分岔。

Conclusion: 证明了在量子耗散条件下碰撞诱导混沌的持续性，阐明了环境涨落对开放量子系统非线性动力学的影响机制。

Abstract: Dynamical chaos in a periodically driven, dissipative soft impact oscillator is investigated in the quantum regime using the complex-number quantum Langevin equation (c-number QLE). The averaged system dynamics are analyzed through a comprehensive suite of time-series diagnostics, including bifurcation diagrams, Lyapunov exponents, Fourier spectra, and the 0-1 test. Systematic variation of the wall position reveals a rich sequence of dynamical transitions and grazing bifurcations, progressing from periodic to multiperiodic motion and culminating in chaotic behavior. These results demonstrate the persistence of impact-induced chaos under quantum dissipation and elucidate how environmental fluctuations influence non-linear dynamics in open quantum systems.

</details>


### [156] [The FLuid Allocation of Surface code Qubits (FLASQ) cost model for early fault-tolerant quantum algorithms](https://arxiv.org/abs/2511.08508)
*William J. Huggins,Tanuj Khattar,Amanda Xu,Matthew Harrigan,Christopher Kang,Guang Hao Low,Austin Fowler,Nicholas C. Rubin,Ryan Babbush*

Main category: quant-ph

TL;DR: 提出了FLASQ成本模型，用于在二维表面码架构上更准确地估计量子算法的时空成本，特别关注早期容错设备的约束条件。


<details>
  <summary>Details</summary>
Motivation: 现有的简单指标（如电路深度或T计数）无法捕捉关键开销，如Clifford操作和路由的时空成本，或遗漏关键优化。需要更全面的资源估算来指导容错量子算法开发。

Method: FLASQ成本模型假设辅助量子比特空间和时间可以灵活重新排列，从而在保持可处理性的同时捕获重要细节，并强制执行电路测量深度和处理器响应时间的约束。

Result: 应用FLASQ分析二维晶格模型模拟成本，发现现代进展（如魔术态培育和量子纠错与缓解结合）相比先前估计将所需时间和空间减少一个数量级。

Conclusion: FLASQ成本模型有助于更好地将早期容错算法设计与实际硬件实现成本对齐，而无需量子算法专家具备过多量子纠错知识。

Abstract: Holistic resource estimates are essential for guiding the development of fault-tolerant quantum algorithms and the computers they will run on. This is particularly true when we focus on highly-constrained early fault-tolerant devices. Many attempts to optimize algorithms for early fault-tolerance focus on simple metrics, such as the circuit depth or T-count. These metrics fail to capture critical overheads, such as the spacetime cost of Clifford operations and routing, or miss they key optimizations. We propose the FLuid Allocation of Surface code Qubits (FLASQ) cost model, tailored for architectures that use a two-dimensional lattice of qubits to implement the two-dimensional surface code. FLASQ abstracts away the complexity of routing by assuming that ancilla space and time can be fluidly rearranged, allowing for the tractable estimation of spacetime volume while still capturing important details neglected by simpler approaches. At the same time, it enforces constraints imposed by the circuit's measurement depth and the processor's reaction time. We apply FLASQ to analyze the cost of a standard two-dimensional lattice model simulation, finding that modern advances (such as magic state cultivation and the combination of quantum error correction and mitigation) reduce both the time and space required for this task by an order of magnitude compared with previous estimates. We also analyze the Hamming weight phasing approach to synthesizing parallel rotations, revealing that despite its low T-count, the overhead from imposing a 2D layout and from its use of additional ancilla qubits will make it challenging to benefit from in early fault-tolerance. We hope that the FLASQ cost model will help to better align early fault-tolerant algorithmic design with actual hardware realization costs without demanding excessive knowledge of quantum error correction from quantum algorithmists.

</details>


### [157] [Design boosters: from constant-time quantum chaos to $\infty$-designs and beyond](https://arxiv.org/abs/2511.08543)
*Soumik Ghosh,Arjun Mirani,Yihui Quek,Michelle Xu*

Main category: quant-ph

TL;DR: 量子态子系统测量后的条件化可以提升设计质量，代价是增加系统规模。在量子混沌动力学中，即使全局态只是低阶设计，投影后的系综在热力学极限下可达到Haar随机性（无限阶设计）。


<details>
  <summary>Details</summary>
Motivation: 研究量子态子系统测量后的条件化如何改变设计随机性质量，探索量子混沌动力学中设计提升现象。

Method: 使用高斯酉系综（GUE）哈密顿量建模量子混沌动力学，分析子系统测量后剩余态的投影系综设计质量。

Result: 量子混沌动力学在常数时间生成的态只是O(1)阶设计，但投影系综在热力学极限下达到Haar随机性（无限阶设计）。无生成假设时，k-设计会降级为⌊k/2⌋-设计。

Conclusion: 设计提升是量子混沌的结果，展示了生成高质量设计的新机制，对深度热化研究有重要改进。

Abstract: We study a counterintuitive property of 'conditioning' on the result of measuring a subsystem of a quantum state: such conditioning can boost design quality, at the cost of increased system size. We work in the setting of deep thermalization from many-body physics: starting from a bipartite state on a global system $(A,B)$ drawn from a $k$-design, we measure system $B$ in the computational basis, keep the outcome and examine the state that remains in system $A$, approximating the overall ensemble (the 'projected ensemble') by a $k'$-design. We ask: how does the design quality change due to this procedure, or how does $k'$ compare to $k$? We give the first rigorous example of unitary dynamics generating a state such that, projection at very early (constant) times can boost design randomness. These dynamics are those of quantum chaos, modeled by the evolution of a Hamiltonian drawn from the Gaussian Unitary Ensemble (GUE). We show that, even though a state generated by such dynamics at constant time only forms a $k=\mathcal{O}(1)$ design, the projected ensemble is Haar-random (or a $k'=\infty$ design) in the thermodynamic limit (i.e. when $N_B=\infty$). This phenomenon persists even with weaker and more physically realistic assumptions; our results can be appropriately applied to non-GUE Hamiltonians that nevertheless show likely chaotic signatures in their eigenbases. Moreover, we show that with no assumption on how the global state was generated, a $k$-design experiences a degradation in design quality to $k' = \lfloor k/2 \rfloor$. This improves upon best prior results on the deep thermalization of designs. Together, our contributions argue for design boosting as a result of chaos and showcase a novel mechanism to generate good designs.

</details>


### [158] [Beyond critical coupling: optimal design considerations for spontaneous four-wave mixing in microring resonators](https://arxiv.org/abs/2511.08563)
*Joseph M. Lukens,Karthik V. Myilswamy,Alexander Miloshevsky,Hsuan-Hao Lu*

Main category: quant-ph

TL;DR: 提出了一个用于微环谐振器中双光子生成的自包含分析模型，涵盖多种几何结构和泵浦条件，揭示了时间-频率双光子相关性并预测绝对生成速率。


<details>
  <summary>Details</summary>
Motivation: 为集成光子源的实际设计提供有价值的理论框架，将灵活直观的双光子描述与实验参数紧密关联的定量预测相结合。

Method: 基于相互作用图像的方法，涵盖全通和加-降几何结构、相同和不同的泵浦与双光子耦合系数、连续波和脉冲泵浦。

Result: 在连续波泵浦下，发现泵浦和双光子的临界耦合可最大化单光子提取速率，而泵浦临界耦合但双光子过耦合可最大化双光子速率。在脉冲泵浦下，泵浦和双光子的不同程度过耦合可最大化光子提取概率，但与光谱可分解性存在权衡。

Conclusion: 该形式主义为集成光子源的实际设计提供了有价值的工具，将灵活直观的双光子中心描述与紧密联系实验参数的定量预测相结合。

Abstract: We present a self-contained analytical model for biphoton generation in microring resonators. Encompassing both all-pass and add-drop geometries, identical and distinct pump and biphoton coupling coefficients, and continuous-wave and pulsed pumping, our interaction-picture-based approach reveals time-frequency biphoton correlations while also predicting absolute generation rates. Under continuous-wave excitation, we find critical coupling of both the pump and biphoton to maximize the rate of single photons extracted from the microring, whereas critical coupling of the pump but overcoupling of the biphoton maximize the two-photon rate. Under pulsed pumping, overcoupling of both pump and biphoton (to different degrees) maximizes photon extraction probabilities, albeit under a tradeoff with spectral factorability that we quantify via parameter scans over a range of coupler pairings. As a whole, our formalism should prove valuable for the practical design of integrated photon sources, merging a flexible and intuitive biphoton-centric depiction with quantitative predictions closely tied to experimental parameters.

</details>


### [159] [Fluctuation amplification engineering in multimode Raman-cavity systems](https://arxiv.org/abs/2511.08586)
*H. P. Ojeda Collado,Ludwig Mathey*

Main category: quant-ph

TL;DR: 该研究将涨落工程推广到多模场景，展示了通过调控光子和声子能带色散可以实现对集体涨落的非互易控制，并发现了超越√N标度的涨落放大效应。


<details>
  <summary>Details</summary>
Motivation: 虽然参量放大已在非平衡系统中得到证实，但将其用于涨落工程在拉曼-腔体混合系统中是最近才提出的。本研究旨在将涨落工程推广到多模相互作用场景。

Method: 研究多模拉曼活性模式与多模腔体模式之间的非线性相互作用，通过工程化光子和声子的能带色散来控制集体涨落。

Result: 发现了共振和非共振集体涨落的出现，拉曼涨落可以通过调控光子带隙选择性衰减或非共振放大，并识别出腔体涨落在特定模式中的放大效应超越√N标度。

Conclusion: 多模相互作用在非线性腔体-物质混合系统的涨落中起着关键作用，通过不同光子和声子色散的噪声工程可用于设计新型量子传感平台和太赫兹先进光谱学。

Abstract: Parametric amplification is a key ingredient of a wide range of phenomena, from the classical to the quantum domain. Although such phenomena have been demonstrated in non-equilibrium settings, their use for fluctuation engineering has been put forth in Raman-cavity hybrids only recently. In this work, we generalize fluctuation engineering to a multi-mode scenario in which multiple Raman-active modes interact nonlinearly with multiple cavity modes. We demonstrate the emergence of resonant and non-resonant collective fluctuations that can be non-reciprocally controlled by engineering the band dispersion of photons and phonons. As an example we show how Raman fluctuations can be selectively attenuated by tuning the photonic bandgap or even nonresonantly amplified, in marked contrast to the single-mode scenario. We also identify a regime in which the amplification of cavity fluctuations in a specific mode is boosted, surpassing a $\sqrt{N}$ scaling with increasing number of $N$ Raman and cavity modes. Our study reveals the key role of multi-mode interactions on fluctuations in nonlinear cavity-matter hybrids. Noise engineering through different photon and phonon dispersions, as demonstrated here, could be leveraged for the design of novel quantum sensing platforms and advanced spectroscopy in the THz regime.

</details>
