<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 112]
- [quant-ph](#quant-ph) [Total: 54]
- [gr-qc](#gr-qc) [Total: 12]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks](https://arxiv.org/abs/2602.09980)
*Enzo Nicolas Spotorno,Josafat Ribeiro Leal,Antonio Augusto Frohlich*

Main category: cs.LG

TL;DR: 提出TAPINN方法，通过监督度量正则化构建潜在空间，解决PINNs在参数化动力系统（如分岔）中面临的谱偏置和模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 标准PINNs在处理具有尖锐状态转换（如分岔）的参数化动力系统时面临挑战，连续的参数到解映射会导致谱偏置或"模式崩溃"，网络会平均不同的物理行为。

Method: 提出拓扑感知PINN（TAPINN），通过监督度量正则化构建潜在空间，使用基于阶段的交替优化（AO）调度来管理度量和物理目标之间的梯度冲突。

Result: 在Duffing振子上的实验显示，TAPINN比标准基线物理残差降低约49%（0.082 vs. 0.160），梯度方差比多输出Sobolev误差基线低2.18倍，参数比基于超网络的替代方案少5倍。

Conclusion: TAPINN通过结构化潜在空间有效缓解了PINNs在参数化动力系统中的谱偏置问题，相比现有方法在精度、稳定性和参数效率方面都有显著提升。

Abstract: Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or "mode collapse", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims to mitigate this challenge by structuring the latent space via Supervised Metric Regularization. Unlike standard parametric PINNs that map physical parameters directly to solutions, our method conditions the solver on a latent state optimized to reflect the metric-based separation between regimes, showing ~49% lower physics residual (0.082 vs. 0.160). We train this architecture using a phase-based Alternating Optimization (AO) schedule to manage gradient conflicts between the metric and physics objectives. Preliminary experiments on the Duffing Oscillator demonstrate that while standard baselines suffer from spectral bias and high-capacity Hypernetworks overfit (memorizing data while violating physics), our approach achieves stable convergence with 2.18x lower gradient variance than a multi-output Sobolev Error baseline, and 5x fewer parameters than a hypernetwork-based alternative.

</details>


### [2] [Enhanced Graph Transformer with Serialized Graph Tokens](https://arxiv.org/abs/2602.09065)
*Ruixiang Wang,Yuyang Hong,Shiming Xiang,Chunhong Pan*

Main category: cs.LG

TL;DR: 提出新的序列化令牌范式来解决图级表示中的信息瓶颈问题，通过聚合节点信号为序列化图令牌，利用自注意力层编码令牌序列，在多个图级基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer方法在图级表示生成中存在信息瓶颈。流行的单令牌范式未能充分利用自注意力编码令牌序列的优势，退化为节点信号的加权和。

Method: 设计序列化令牌范式：提出图序列化方法将节点信号聚合为序列化图令牌（自动包含位置编码），然后应用堆叠的自注意力层编码令牌序列并捕获其内部依赖关系。

Result: 在多个图级基准测试中达到最先进的结果，消融研究验证了所提出模块的有效性。

Conclusion: 通过建模多个图令牌之间的复杂交互，该方法能够生成更具表达力的图表示，解决了现有方法的信息瓶颈问题。

Abstract: Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully leverage the inherent strength of self-attention in encoding token sequences, and degenerates into a weighted sum of node signals. To address this issue, we design a novel serialized token paradigm to encapsulate global signals more effectively. Specifically, a graph serialization method is proposed to aggregate node signals into serialized graph tokens, with positional encoding being automatically involved. Then, stacked self-attention layers are applied to encode this token sequence and capture its internal dependencies. Our method can yield more expressive graph representations by modeling complex interactions among multiple graph tokens. Experimental results show that our method achieves state-of-the-art results on several graph-level benchmarks. Ablation studies verify the effectiveness of the proposed modules.

</details>


### [3] [Empirical Stability Analysis of Kolmogorov-Arnold Networks in Hard-Constrained Recurrent Physics-Informed Discovery](https://arxiv.org/abs/2602.09988)
*Enzo Nicolas Spotorno,Josafat Leal Filho,Antonio Augusto Medeiros Frohlich*

Main category: cs.LG

TL;DR: 研究将KANs集成到硬约束循环物理信息架构中评估振荡系统学习残差流形的保真度，发现KANs在小规模单变量多项式残差上具有竞争力，但在深层配置中不稳定，在乘法项上表现不佳，通常被标准MLPs超越。


<details>
  <summary>Details</summary>
Motivation: 基于Kolmogorov-Arnold表示定理和初步灰盒结果，假设KANs相比MLPs能更高效地恢复未知项，探索其在硬约束循环物理信息架构中的应用潜力。

Method: 将KANs集成到HRPINN架构中，通过对配置敏感性、参数尺度和训练范式的初始敏感性分析，评估其在Duffing和Van der Pol等振荡系统上的表现。

Result: 小型KANs在单变量多项式残差（Duffing）上具有竞争力，但表现出严重的超参数脆弱性、深层配置不稳定性和在乘法项（Van der Pol）上的一致失败，通常被标准MLPs超越。

Conclusion: 原始KAN公式中的加性归纳偏置在状态耦合方面存在局限性，为未来混合建模提供了初步经验证据，表明需要改进KANs的归纳偏置设计。

Abstract: We investigate the integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) to evaluate the fidelity of learned residual manifolds in oscillatory systems. Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, we hypothesized that KANs would enable efficient recovery of unknown terms compared to MLPs. Through initial sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, we found that while small KANs are competitive on univariate polynomial residuals (Duffing), they exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs. These empirical challenges highlight limitations of the additive inductive bias in the original KAN formulation for state coupling and provide preliminary empirical evidence of inductive bias limitations for future hybrid modeling.

</details>


### [4] [Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning](https://arxiv.org/abs/2602.09066)
*Jinjin Guo,Yexin Li,Zhichao Huang,Jun Fang,Zhiyuan Liu,Chao Liu,Pengzhang Liu,Qixia Jiang*

Main category: cs.LG

TL;DR: SDE框架通过谱分解和增强解决多模态对比学习中特征维度均匀处理和谱结构忽略的问题，提升表示鲁棒性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 大规模多模态对比学习虽然成功，但存在两个根本限制：1) 对特征维度的均匀处理；2) 忽略学习特征的固有谱结构。经验证据表明高维嵌入倾向于坍缩到窄锥中，任务相关语义集中在小子空间，而多数维度被噪声和虚假相关性占据，这种谱不平衡和纠缠损害模型泛化能力。

Method: 提出谱解缠和增强(SDE)框架：1) 使用奇异值分解自适应地将特征维度划分为强信号(任务关键语义)、弱信号(辅助相关性)和噪声(无关扰动)；2) 应用基于课程的谱增强策略，选择性放大信息成分并保证训练稳定性；3) 引入双域对比损失，在特征空间和谱空间联合优化对齐，将谱正则化整合到训练过程中。

Result: 在大规模多模态基准测试上的广泛实验表明，SDE持续提升表示鲁棒性和泛化能力，优于最先进方法。SDE能与现有对比学习管道无缝集成。

Conclusion: SDE通过桥接嵌入空间几何与谱特性之间的差距，为多模态表示学习提供了有效解决方案，解决了谱不平衡和纠缠问题，鼓励学习更丰富、更鲁棒的表示。

Abstract: Large-scale multimodal contrastive learning has recently achieved impressive success in learning rich and transferable representations, yet it remains fundamentally limited by the uniform treatment of feature dimensions and the neglect of the intrinsic spectral structure of the learned features. Empirical evidence indicates that high-dimensional embeddings tend to collapse into narrow cones, concentrating task-relevant semantics in a small subspace, while the majority of dimensions remain occupied by noise and spurious correlations. Such spectral imbalance and entanglement undermine model generalization. We propose Spectral Disentanglement and Enhancement (SDE), a novel framework that bridges the gap between the geometry of the embedded spaces and their spectral properties. Our approach leverages singular value decomposition to adaptively partition feature dimensions into strong signals that capture task-critical semantics, weak signals that reflect ancillary correlations, and noise representing irrelevant perturbations. A curriculum-based spectral enhancement strategy is then applied, selectively amplifying informative components with theoretical guarantees on training stability. Building upon the enhanced features, we further introduce a dual-domain contrastive loss that jointly optimizes alignment in both the feature and spectral spaces, effectively integrating spectral regularization into the training process and encouraging richer, more robust representations. Extensive experiments on large-scale multimodal benchmarks demonstrate that SDE consistently improves representation robustness and generalization, outperforming state-of-the-art methods. SDE integrates seamlessly with existing contrastive pipelines, offering an effective solution for multimodal representation learning.

</details>


### [5] [Learning to Remember, Learn, and Forget in Attention-Based Models](https://arxiv.org/abs/2602.09075)
*Djohan Bonnet,Jamie Lohoff,Jan Finkbeiner,Elidona Skhikerujah,Emre Neftci*

Main category: cs.LG

TL;DR: Palimpsa是一个基于贝叶斯元可塑性的自注意力模型，将上下文学习视为需要解决稳定性-可塑性困境的持续学习问题，显著扩展了记忆容量并优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 门控线性注意力模型中的上下文学习记忆容量固定且容易受到干扰，特别是在长序列处理中。需要解决稳定性-可塑性困境来改善记忆能力。

Method: 提出Palimpsa模型，使用贝叶斯元可塑性方法，将每个注意力状态的可塑性与其重要性状态绑定，重要性状态基于捕获累积知识的先验分布。将非元可塑性模型转化为元可塑性模型。

Result: Palimpsa在Multi-Query Associative Recall基准测试和常识推理任务中始终优于基线模型。理论分析表明Mamba2是Palimpsa的一个特例（遗忘占主导）。

Conclusion: Palimpsa通过贝叶斯元可塑性方法有效解决了上下文学习中的稳定性-可塑性困境，显著扩展了记忆容量，为改进注意力模型提供了理论框架。

Abstract: In-Context Learning (ICL) in transformers acts as an online associative memory and is believed to underpin their high performance on complex sequence processing tasks. However, in gated linear attention models, this memory has a fixed capacity and is prone to interference, especially for long sequences. We propose Palimpsa, a self-attention model that views ICL as a continual learning problem that must address a stability-plasticity dilemma. Palimpsa uses Bayesian metaplasticity, where the plasticity of each attention state is tied to an importance state grounded by a prior distribution that captures accumulated knowledge. We demonstrate that various gated linear attention models emerge as specific architecture choices and posterior approximations, and that Mamba2 is a special case of Palimpsa where forgetting dominates. This theoretical link enables the transformation of any non-metaplastic model into a metaplastic one, significantly expanding its memory capacity. Our experiments show that Palimpsa consistently outperforms baselines on the Multi-Query Associative Recall (MQAR) benchmark and on Commonsense Reasoning tasks.

</details>


### [6] [Patient foundation model for risk stratification in low-risk overweight patients](https://arxiv.org/abs/2602.09079)
*Zachary N. Flamholz,Dillon Tracy,Ripple Khera,Jordan Wolinsky,Nicholas Lee,Nathaniel Tann,Xiao Yin Zhu,Harry Phillips,Jeffrey Sherman*

Main category: cs.LG

TL;DR: PatientTPP是一个神经时间点过程模型，用于从真实世界临床轨迹中学习患者表征，以改进超重或肥胖患者的风险分层，特别是在心血管相关医疗成本和肥胖相关结局预测方面。


<details>
  <summary>Details</summary>
Motivation: 准确的风险分层对于超重或肥胖患者至关重要，可以指导预防性护理和分配高成本治疗（如GLP-1受体激动剂）。现有方法如体重指数在风险分层方面存在局限性，需要更精确的预测工具。

Method: 开发了PatientTPP神经时间点过程模型，基于超过50万条真实世界临床轨迹训练。扩展了现有TPP方法，包含静态和数值特征，并整合临床知识进行事件编码。模型学习诊断、实验室检查和药物序列的患者表征。

Result: PatientTPP表征支持下游预测任务，包括对低风险个体中肥胖相关结局的分类，即使对于训练期间未明确建模的事件也能预测。在健康经济评估中，PatientTPP在按未来心血管相关医疗成本分层患者方面优于体重指数，能更有效地识别高风险患者。

Conclusion: 通过建模临床事件的类型和时间，PatientTPP为患者风险建模提供了一个可解释的通用基础框架，在肥胖相关护理和成本目标方面具有直接应用价值。

Abstract: Accurate risk stratification in patients with overweight or obesity is critical for guiding preventive care and allocating high-cost therapies such as GLP-1 receptor agonists. We present PatientTPP, a neural temporal point process (TPP) model trained on over 500,000 real-world clinical trajectories to learn patient representations from sequences of diagnoses, labs, and medications. We extend existing TPP modeling approaches to include static and numeric features and incorporate clinical knowledge for event encoding. PatientTPP representations support downstream prediction tasks, including classification of obesity-associated outcomes in low-risk individuals, even for events not explicitly modeled during training. In health economic evaluation, PatientTPP outperformed body mass index in stratifying patients by future cardiovascular-related healthcare costs, identifying higher-risk patients more efficiently. By modeling both the type and timing of clinical events, PatientTPP offers an interpretable, general-purpose foundation for patient risk modeling with direct applications to obesity-related care and cost targeting.

</details>


### [7] [Looping Back to Move Forward: Recursive Transformers for Efficient and Flexible Large Multimodal Models](https://arxiv.org/abs/2602.09080)
*Ruihan Xu,Yuting Gao,Lan Wang,Jianing Li,Weihao Chen,Qingpei Guo,Ming Yang,Shiliang Zhang*

Main category: cs.LG

TL;DR: RecursiveVLM：通过递归细化重用参数，无需增加模型规模即可提升多模态表示能力


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型参数庞大但训练和推理时未充分利用，希望通过递归细化重用参数来提取更强的多模态表示

Method: 提出RecursiveVLM递归Transformer架构，包含递归连接器（对齐跨递归步骤特征）和单调递归损失（监督每一步并保证性能随深度单调提升）

Result: 相比标准Transformer提升3%，相比普通递归基线提升7%，证明策略性循环是通向高效、部署自适应LMM的强大路径

Conclusion: 递归细化可作为按需优化机制，在资源受限设备上少量循环即可获得强结果，在更多计算资源下可渐进改进输出

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in vision-language tasks, yet their vast parameter counts are often underutilized during both training and inference. In this work, we embrace the idea of looping back to move forward: reusing model parameters through recursive refinement to extract stronger multimodal representations without increasing model size. We propose RecursiveVLM, a recursive Transformer architecture tailored for LMMs. Two key innovations enable effective looping: (i) a Recursive Connector that aligns features across recursion steps by fusing intermediate-layer hidden states and applying modality-specific projections, respecting the distinct statistical structures of vision and language tokens; (ii) a Monotonic Recursion Loss that supervises every step and guarantees performance improves monotonically with recursion depth. This design transforms recursion into an on-demand refinement mechanism: delivering strong results with few loops on resource-constrained devices and progressively improving outputs when more computation resources are available. Experiments show consistent gains of +3% over standard Transformers and +7% over vanilla recursive baselines, demonstrating that strategic looping is a powerful path toward efficient, deployment-adaptive LMMs.

</details>


### [8] [DMamba: Decomposition-enhanced Mamba for Time Series Forecasting](https://arxiv.org/abs/2602.09081)
*Ruxuan Chen,Fang Sun*

Main category: cs.LG

TL;DR: DMamba：一种新颖的时序预测模型，通过季节性-趋势分解，分别用不同复杂度的模块处理季节性成分（变量方向Mamba编码器）和趋势成分（简单MLP），在非平稳数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Mamba的架构在处理具有非平稳模式的时序数据集时存在困难。时序理论表明，趋势成分和季节性成分的变量间关系统计特性存在根本差异：趋势关系通常由少数共同随机因素驱动，存在于低维流形；而季节性关系涉及动态的高维相互作用，需要更具表达力的建模。

Method: DMamba采用季节性-趋势分解，为不同成分设计专门化、复杂度不同的模块：1）使用变量方向Mamba编码器捕捉季节性成分中丰富的跨变量动态；2）使用简单的多层感知机（MLP）学习趋势成分中的低维变量间关系。

Result: 在多样化数据集上的大量实验表明，DMamba实现了新的最先进（SOTA）性能，持续优于最近的基于Mamba的架构和领先的基于分解的模型。

Conclusion: 通过将架构复杂度与成分特定特性明确对齐，DMamba有效解决了非平稳时序预测问题，证明了针对不同时序成分采用差异化建模策略的有效性。

Abstract: State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time series theory is that the statistical nature of inter-variable relationships differs fundamentally between the trend and seasonal components of a decomposed series. Trend relationships are often driven by a few common stochastic factors or long-run equilibria, suggesting that they reside on a lower-dimensional manifold. In contrast, seasonal relationships involve dynamic, high-dimensional interactions like phase shifts and amplitude co-movements, requiring more expressive modeling. In this paper, we propose DMamba, a novel forecasting model that explicitly aligns architectural complexity with this component-specific characteristic. DMamba employs seasonal-trend decomposition and processes the components with specialized, differentially complex modules: a variable-direction Mamba encoder captures the rich, cross-variable dynamics within the seasonal component, while a simple Multi-Layer Perceptron (MLP) suffices to learn from the lower-dimensional inter-variable relationships in the trend component. Extensive experiments on diverse datasets demonstrate that DMamba sets a new state-of-the-art (SOTA), consistently outperforming both recent Mamba-based architectures and leading decomposition-based models.

</details>


### [9] [From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics](https://arxiv.org/abs/2602.09101)
*Carlos Heredia*

Main category: cs.LG

TL;DR: 提出Adam的加速连续时间公式，通过二阶积分微分动力系统建模，建立与一阶非局部Adam流的关系，提供稳定性分析和变分视角。


<details>
  <summary>Details</summary>
Motivation: 为Adam优化器建立连续时间理论框架，从动力系统角度理解其收敛行为，提供更严谨的数学分析基础。

Method: 将Adam建模为二阶积分微分动力系统，通过α-细化极限建立与一阶非局部Adam流的关系，使用Lyapunov方法进行稳定性分析，并引入非局部Lagrangian变分公式。

Result: 提出的连续时间动力学与离散Adam在Rosenbrock型问题上表现一致，理论分析为Adam的收敛性提供了数学保证。

Conclusion: 成功建立了Adam的连续时间理论框架，为理解Adam优化器的动力学行为提供了新的数学视角和分析工具。

Abstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $α$-refinement limit, and we provide Lyapunov-based stability and convergence analyses. We also introduce an Adam-inspired nonlocal Lagrangian formulation, offering a variational viewpoint. Numerical simulations on Rosenbrock-type examples show agreement between the proposed dynamics and discrete Adam.

</details>


### [10] [Distributed Hybrid Parallelism for Large Language Models: Comparative Study and System Design Guide](https://arxiv.org/abs/2602.09109)
*Hossam Amer,Rezaul Karim,Ali Pourranjbar,Weiwei Zhang,Walid Ahmed,Boxing Chen*

Main category: cs.LG

TL;DR: 本文对大型语言模型的分布式并行策略进行了系统性综述，包括集体操作、混合并行化设计、通信计算重叠等，并通过数学公式、案例研究和成本模型分析，为分布式系统设计提供理论指导和实践参考。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，出现了多种分布式计算和内存分配方法。现有综述多为描述性概述，缺乏对技术利弊的系统分析，以及如何基于这些洞察指导设计最优分布式系统的原则性方法。本文旨在填补这一空白。

Method: 1. 全面回顾集体操作和分布式并行策略，辅以数学公式加深理论理解；2. 研究混合并行化设计，强调训练和推理不同阶段的通信计算重叠；3. 讨论基于成本模型的自动搜索最优混合并行策略的最新进展；4. 通过主流架构类别的案例研究提供实证洞察。

Result: 提供了对LLM分布式并行策略的系统性分析框架，包括理论公式、混合设计原则和自动优化方法。案例研究揭示了不同架构下的实践经验，为研究者和从业者选择并行策略提供了指导。

Conclusion: 本文系统梳理了LLM分布式并行技术，建立了理论分析框架并提供了实践指导。同时指出了当前LLM训练范式的局限性和挑战，为下一代大规模模型开发指明了有前景的研究方向。

Abstract: With the rapid growth of large language models (LLMs), a wide range of methods have been developed to distribute computation and memory across hardware devices for efficient training and inference. While existing surveys provide descriptive overviews of these techniques, systematic analysis of their benefits and trade offs and how such insights can inform principled methodology for designing optimal distributed systems remain limited. This paper offers a comprehensive review of collective operations and distributed parallel strategies, complemented by mathematical formulations to deepen theoretical understanding. We further examine hybrid parallelization designs, emphasizing communication computation overlap across different stages of model deployment, including both training and inference. Recent advances in automated search for optimal hybrid parallelization strategies using cost models are also discussed. Moreover, we present case studies with mainstream architecture categories to reveal empirical insights to guide researchers and practitioners in parallelism strategy selection. Finally, we highlight open challenges and limitations of current LLM training paradigms and outline promising directions for the next generation of large scale model development.

</details>


### [11] [Benchmarking the Energy Savings with Speculative Decoding Strategies](https://arxiv.org/abs/2602.09113)
*Rohit Dutta,Paramita Koley,Soham Poddar,Janardan Misra,Sanjay Podder,Naveen Balani,Saptarshi Ghosh,Niloy Ganguly*

Main category: cs.LG

TL;DR: 对推测解码策略能量需求的全面调查，分析模型大小、解码策略和数据集特征对能量优化的影响


<details>
  <summary>Details</summary>
Motivation: 推测解码虽然能降低LLM推理延迟和成本，但现有研究对其能量需求关注不足，需要填补这一空白

Method: 采用系统性调查方法，详细分析模型大小与家族、推测解码策略、数据集特征等因素对能量优化的影响

Result: 提供了推测解码能量需求的全面分析框架，识别了影响能量优化的关键因素

Conclusion: 需要更全面地考虑推测解码的能量效率，为开发更节能的LLM推理方法提供指导

Abstract: Speculative decoding has emerged as an effective method to reduce latency and inference cost of LLM inferences. However, there has been inadequate attention towards the energy requirements of these models. To address this gap, this paper presents a comprehensive survey of energy requirements of speculative decoding strategies, with detailed analysis on how various factors -- model size and family, speculative decoding strategies, and dataset characteristics -- influence the energy optimizations.

</details>


### [12] [Importance inversion transfer identifies shared principles for cross-domain learning](https://arxiv.org/abs/2602.09116)
*Daniele Caligiore*

Main category: cs.LG

TL;DR: 提出X-CDTL框架，通过识别跨领域的结构不变性，在数据稀缺和噪声环境下实现可解释的跨领域知识迁移


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法难以在数据稀缺、噪声严重的异构系统间进行知识迁移，需要一种能够识别跨领域共享组织结构的方法

Method: 提出Explainable Cross-Domain Transfer Learning (X-CDTL)框架，结合网络科学和可解释AI，引入Importance Inversion Transfer (IIT)机制，优先考虑领域不变的结构锚点而非特定领域特征

Result: 在异常检测任务中，基于该框架的模型在极端噪声下决策稳定性相对提升56%，显著优于传统基线方法

Conclusion: 发现了跨异构领域的共享组织结构特征，建立了跨学科知识传播的原则性范式，通过从隐式表征转向显式结构规律，推动了机器学习作为科学发现工具的发展

Abstract: The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invariants that generalize across biological, linguistic, molecular, and social networks. By introducing the Importance Inversion Transfer (IIT) mechanism, the framework prioritizes domain-invariant structural anchors over idiosyncratic, highly discriminative features. In anomaly detection tasks, models guided by these principles achieve significant performance gains - exhibiting a 56\% relative improvement in decision stability under extreme noise - over traditional baselines. These results provide evidence for a shared organizational signature across heterogeneous domains, establishing a principled paradigm for cross-disciplinary knowledge propagation. By shifting from opaque latent representations to explicit structural laws, this work advances machine learning as a robust engine for scientific discovery.

</details>


### [13] [SpinCastML an Open Decision-Making Application for Inverse Design of Electrospinning Manufacturing: A Machine Learning, Optimal Sampling and Inverse Monte Carlo Approach](https://arxiv.org/abs/2602.09120)
*Elisa Roldan,Tasneem Sabir*

Main category: cs.LG

TL;DR: SpinCastML是一个开源、分布感知、化学信息化的机器学习软件，用于电纺丝的逆向设计，能够预测完整的纤维直径分布而非仅平均值。


<details>
  <summary>Details</summary>
Motivation: 传统电纺丝工艺依赖试错法，溶液或操作条件的微小变化会导致纤维直径分布偏离高斯分布。现有框架无法整合聚合物溶剂化学约束或预测完整分布，也无法实现针对期望纤维结果的逆向设计。

Method: 基于16种聚合物、1,778个数据集、68,480个纤维直径的严格策划数据集，集成三种结构化采样方法、11种高性能学习器、化学感知约束和逆向蒙特卡洛(IMC)方法，预测完整纤维直径分布。

Result: Cubist模型结合聚合物平衡Sobol D最优采样获得最高全局性能(R2 > 0.92)。IMC准确捕获纤维分布，R2 > 0.90，预测与实验成功率误差<1%。IMC引擎支持回顾性分析和前瞻性逆向设计。

Conclusion: SpinCastML将电纺丝从试错法转变为可重复的数据驱动设计过程，减少实验浪费，加速发现，民主化高级建模访问，为可持续纳米纤维制造建立分布感知逆向设计新标准。

Abstract: Electrospinning is a powerful technique for producing micro to nanoscale fibers with application specific architectures. Small variations in solution or operating conditions can shift the jet regime, generating non Gaussian fiber diameter distributions. Despite substantial progress, no existing framework enables inverse design toward desired fiber outcomes while integrating polymer solvent chemical constraints or predicting full distributions. SpinCastML is an open source, distribution aware, chemically informed machine learning and Inverse Monte Carlo (IMC) software for inverse electrospinning design. Built on a rigorously curated dataset of 68,480 fiber diameters from 1,778 datasets across 16 polymers, SpinCastML integrates three structured sampling methods, a suite of 11 high-performance learners, and chemistry aware constraints to predict not only mean diameter but the entire distribution. Cubist model with a polymer balanced Sobol D optimal sampling provides the highest global performance (R2 > 0.92). IMC accurately captures the fiber distributions, achieving R2 > 0.90 and <1% error between predicted and experimental success rates. The IMC engine supports both retrospective analysis and forward-looking inverse design, generating physically and chemically feasible polymer solvent parameter combinations with quantified success probabilities for user-defined targets. SpinCastML reframes electrospinning from trial and error to a reproducible, data driven design process. As an open source executable, it enables laboratories to analyze their own datasets and co create an expanding community software. SpinCastML reduces experimental waste, accelerates discovery, and democratizes access to advanced modeling, establishing distribution aware inverse design as a new standard for sustainable nanofiber manufacturing across biomedical, filtration, and energy applications.

</details>


### [14] [Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference](https://arxiv.org/abs/2602.09127)
*Lei You*

Main category: cs.LG

TL;DR: 论文提出注意力约束推理（ACI）框架，研究在有限验证能力下如何通过廉价筛选放大稀缺验证资源，发现信息杠杆项按√(JKB)缩放，其中J代表筛选质量，B是验证预算，K是筛选记录数。


<details>
  <summary>Details</summary>
Motivation: 现代生成式AI和工具使用系统能以低成本产生大量候选记录，但只有少数能被仔细检查，这形成了解码端瓶颈：下游决策者需要在稀缺注意力下从众多公开记录中形成可靠后验。

Method: 提出注意力约束推理（ACI）框架：廉价筛选阶段处理K条记录，昂贵验证阶段最多跟进B条记录。在贝叶斯对数损失下，研究每窗口可实现的后验不确定性减少最大值（认知吞吐量）。

Result: 发现"JaKoB"缩放定律：认知吞吐量包含随验证和流行度线性增长的基线项，以及按√(JKB)缩放的信息杠杆项（J总结筛选质量）。在弱筛选极限下该缩放是紧的，在稀疏验证机制下，显著杠杆需要重尾分数分布。

Conclusion: 扩展廉价筛选可以非线性地放大稀缺验证能力，即使信息丰富的记录很罕见。在稀疏验证机制中，重尾分数分布是实现显著信息杠杆的关键。

Abstract: Recent generative and tool-using AI systems can surface a large volume of candidates at low marginal cost, yet only a small fraction can be checked carefully. This creates a decoder-side bottleneck: downstream decision-makers must form reliable posteriors from many public records under scarce attention. We formalize this regime via Attention-Constrained Inference (ACI), in which a cheap screening stage processes $K$ records and an expensive verification stage can follow up on at most $B$ of them. Under Bayes log-loss, we study the maximum achievable reduction in posterior uncertainty per window, which we call \emph{epistemic throughput}. Our main result is a ``JaKoB'' scaling law showing that epistemic throughput has a baseline term that grows linearly with verification and prevalence, and an additional \emph{information-leverage} term that scales as $\sqrt{JKB}$, where $J$ summarizes screening quality. Thus, expanding cheap screening can nonlinearly amplify scarce verification, even when informative records are rare. We further show that this scaling is tight in a weak-screening limit, and that in the sparse-verification regime ($B \ll K$), substantial leverage requires heavy-tailed score distributions; for light-tailed scores the amplification is only logarithmic.

</details>


### [15] [Counterfactual Maps: What They Are and How to Find Them](https://arxiv.org/abs/2602.09128)
*Awa Khouna,Julien Ferry,Thibaut Vidal*

Main category: cs.LG

TL;DR: 本文提出了一种基于最近邻区域搜索的精确反事实解释方法，通过将树集成模型压缩为带标签的超矩形分区，将反事实搜索转化为广义Voronoi单元识别问题，实现了毫秒级延迟的全局最优反事实生成。


<details>
  <summary>Details</summary>
Motivation: 反事实解释是可解释机器学习中的核心工具，但对于复杂模型（特别是树集成模型）的精确计算仍然具有挑战性。现有方法要么缺乏最优性保证，要么计算复杂度高，无法满足交互式使用需求。

Method: 将树集成模型压缩为等价的带标签超矩形分区，将反事实搜索转化为识别最近替代标签矩形对应的广义Voronoi单元问题。提出基于体积k维树的精确摊销算法，通过分支定界最近区域查询实现最优性保证。

Result: 在多个高风险应用领域的真实数据集上，该方法能够以毫秒级延迟提供全局最优的反事实解释，查询时间比现有精确冷启动优化方法快几个数量级。

Conclusion: 通过将反事实生成重新构建为最近邻区域搜索问题，本文提出的方法能够为树集成模型提供高效、精确的反事实解释，解决了现有方法在可扩展性和最优性保证方面的局限性。

Abstract: Counterfactual explanations are a central tool in interpretable machine learning, yet computing them exactly for complex models remains challenging. For tree ensembles, predictions are piecewise constant over a large collection of axis-aligned hyperrectangles, implying that an optimal counterfactual for a point corresponds to its projection onto the nearest rectangle with an alternative label under a chosen metric. Existing methods largely overlook this geometric structure, relying either on heuristics with no optimality guarantees or on mixed-integer programming formulations that do not scale to interactive use.
  In this work, we revisit counterfactual generation through the lens of nearest-region search and introduce counterfactual maps, a global representation of recourse for tree ensembles. Leveraging the fact that any tree ensemble can be compressed into an equivalent partition of labeled hyperrectangles, we cast counterfactual search as the problem of identifying the generalized Voronoi cell associated with the nearest rectangle of an alternative label. This leads to an exact, amortized algorithm based on volumetric k-dimensional (KD) trees, which performs branch-and-bound nearest-region queries with explicit optimality certificates and sublinear average query time after a one-time preprocessing phase.
  Our experimental analyses on several real datasets drawn from high-stakes application domains show that this approach delivers globally optimal counterfactual explanations with millisecond-level latency, achieving query times that are orders of magnitude faster than existing exact, cold-start optimization methods.

</details>


### [16] [UniComp: A Unified Evaluation of Large Language Model Compression via Pruning, Quantization and Distillation](https://arxiv.org/abs/2602.09130)
*Jonathan von Rad,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: UniComp是一个统一的模型压缩评估框架，通过性能、可靠性和效率三个维度评估剪枝、量化和知识蒸馏等压缩技术，发现量化提供最佳综合权衡，压缩存在知识偏见，任务特定校准可显著提升剪枝模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩评估方法覆盖有限，主要关注知识中心基准，缺乏对压缩技术（剪枝、量化、知识蒸馏）的统一评估框架，需要更全面的评估维度来指导实际部署。

Method: 提出UniComp统一评估框架，从性能、可靠性和效率三个维度评估压缩技术，使用多样化的能力和安全导向基准测试，结合硬件感知的效率分析，在6种压缩技术和40多个数据集上进行广泛评估。

Result: 1) 压缩存在一致的知识偏见：知识密集型任务相对保留，而推理、多语言和指令跟随能力显著下降；2) 量化提供最佳性能与效率权衡，蒸馏在高计算成本下提供强运行时加速；3) 任务特定校准可将剪枝模型的推理能力提升达50%。

Conclusion: UniComp为模型压缩提供了全面的评估框架，揭示了不同压缩技术的特点和局限性，量化是最佳综合选择，任务特定校准可有效提升剪枝性能，为实际部署提供重要指导。

Abstract: Model compression is increasingly essential for deploying large language models (LLMs), yet existing evaluations are limited in method coverage and focus primarily on knowledge-centric benchmarks. Thus, we introduce UniComp, a unified evaluation framework for comparing pruning, quantization, and knowledge distillation. UniComp evaluates compressed models along three dimensions: performance, reliability, and efficiency, using a diverse set of capability- and safety-oriented benchmarks together with a hardware-aware efficiency analysis. Through extensive evaluation of six compression techniques on modern LLMs across more than 40 datasets, we find that (i) compression exhibits a consistent knowledge bias, where knowledge-intensive tasks are relatively preserved while reasoning, multilingual, and instruction-following capabilities degrade substantially; (ii) quantization provides the best overall trade-off between retained performance and efficiency, whereas distillation yields strong runtime acceleration gains at high computational cost; and (iii) task-specific calibration can significantly improve the reasoning ability of pruned models by up to 50%.

</details>


### [17] [What do Geometric Hallucination Detection Metrics Actually Measure?](https://arxiv.org/abs/2602.09158)
*Eric Yeats,John Buckheit,Sarah Scullen,Brendan Kennedy,Loc Truong,Davis Brown,Bill Kay,Cliff Joslyn,Tegan Emerson,Michael J. Henry,John Emanuello,Henry Kvinge*

Main category: cs.LG

TL;DR: 本文研究了LLM内部几何信号与不同类型幻觉之间的关系，发现不同几何统计量捕捉不同类型的幻觉，并提出一种简单的归一化方法来减轻领域偏移对几何统计量的影响。


<details>
  <summary>Details</summary>
Motivation: 幻觉是生成模型在高风险应用中部署的主要障碍，特别是在缺乏外部真实数据验证模型输出的情况下。现有研究关注LLM内部状态的几何信号来预测幻觉，但不同因素（如不相关性与不连贯性）都可能导致幻觉，因此需要明确这些几何统计量具体捕捉了幻觉的哪些特性。

Method: 生成一个合成数据集，系统性地改变与幻觉相关的输出特性：正确性、置信度、相关性、连贯性和完整性。通过分析不同几何统计量与这些特性的关系，评估现有几何检测方法对任务领域偏移的敏感性，并提出一种简单的归一化方法来减轻领域偏移的影响。

Result: 研究发现不同几何统计量捕捉不同类型的幻觉。同时发现许多现有几何检测方法对任务领域偏移（如数学问题与历史问题）具有显著的敏感性。提出的归一化方法在多领域设置中将AUROC提升了34个百分点。

Conclusion: LLM内部几何信号确实能够捕捉不同类型的幻觉特性，但现有方法对领域偏移敏感。通过简单的归一化处理可以显著提高几何统计量在多领域环境中的鲁棒性和检测性能，为幻觉检测提供了更可靠的工具。

Abstract: Hallucination remains a barrier to deploying generative models in high-consequence applications. This is especially true in cases where external ground truth is not readily available to validate model outputs. This situation has motivated the study of geometric signals in the internal state of an LLM that are predictive of hallucination and require limited external knowledge. Given that there are a range of factors that can lead model output to be called a hallucination (e.g., irrelevance vs incoherence), in this paper we ask what specific properties of a hallucination these geometric statistics actually capture. To assess this, we generate a synthetic dataset which varies distinct properties of output associated with hallucination. This includes output correctness, confidence, relevance, coherence, and completeness. We find that different geometric statistics capture different types of hallucinations. Along the way we show that many existing geometric detection methods have substantial sensitivity to shifts in task domain (e.g., math questions vs. history questions). Motivated by this, we introduce a simple normalization method to mitigate the effect of domain shift on geometric statistics, leading to AUROC gains of +34 points in multi-domain settings.

</details>


### [18] [Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines](https://arxiv.org/abs/2602.09162)
*Aditya Choudhary,Saaketh Desai,Prasad Iyer*

Main category: cs.LG

TL;DR: BRAIN框架利用变分强化学习近似玻尔兹曼分布，通过聚合多个噪声测量信息，在模拟伊辛机上实现抗噪声的组合优化，相比传统MCMC方法在3%高斯噪声下保持98%基态保真度，速度提升192倍。


<details>
  <summary>Details</summary>
Motivation: 模拟伊辛机在组合优化中具有高能效优势，但其性能常受固有测量噪声限制。传统优化和采样算法在噪声环境下性能下降，需要开发抗噪声的分布学习框架。

Method: 提出BRAIN框架，使用变分强化学习近似玻尔兹曼分布。通过从逐状态采样转向聚合多个噪声测量信息，增强对模拟伊辛机典型高斯噪声的鲁棒性。在多种组合拓扑结构（包括Curie-Weiss和2D最近邻伊辛系统）上评估。

Result: 在3%高斯测量噪声下，BRAIN保持98%基态保真度，而MCMC方法降至51%。BRAIN达到MCMC等效解的速度快192倍。扩展到65,536自旋时呈现O(N^1.55)缩放，在高达40%的严重测量不确定性下保持鲁棒性。能准确捕捉热力学相变和亚稳态。

Conclusion: BRAIN为利用模拟计算架构进行复杂优化提供了可扩展且抗噪声的方法，超越了基态优化，能准确捕捉热力学相变和亚稳态，展示了在噪声环境下模拟伊辛机的实用价值。

Abstract: Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inherent measurement noise. We introduce BRAIN (Boltzmann Reinforcement for Analog Ising Networks), a distribution learning framework that utilizes variational reinforcement learning to approximate the Boltzmann distribution. By shifting from state-by-state sampling to aggregating information across multiple noisy measurements, BRAIN is resilient to Gaussian noise characteristic of AIMs. We evaluate BRAIN across diverse combinatorial topologies, including the Curie-Weiss and 2D nearest-neighbor Ising systems. We find that under realistic 3\% Gaussian measurement noise, BRAIN maintains 98\% ground state fidelity, whereas Markov Chain Monte Carlo (MCMC) methods degrade to 51\% fidelity. Furthermore, BRAIN reaches the MCMC-equivalent solution up to 192x faster under these conditions. BRAIN exhibits $\mathcal{O}(N^{1.55})$ scaling up to 65,536 spins and maintains robustness against severe measurement uncertainty up to 40\%. Beyond ground state optimization, BRAIN accurately captures thermodynamic phase transitions and metastable states, providing a scalable and noise-resilient method for utilizing analog computing architectures in complex optimizations.

</details>


### [19] [Faster Rates For Federated Variational Inequalities](https://arxiv.org/abs/2602.09164)
*Guanghui Wang,Satyen Kale*

Main category: cs.LG

TL;DR: 本文针对联邦随机变分不等式优化问题，改进了现有收敛率，提出了新的LIPPAX算法以减少客户端漂移，并在多个场景下获得更好的收敛保证。


<details>
  <summary>Details</summary>
Motivation: 联邦变分不等式优化的现有收敛率与联邦凸优化的最优边界存在显著差距，需要改进算法以减少客户端漂移并提升收敛性能。

Method: 首先对经典Local Extra SGD算法进行精细化分析获得更紧的收敛保证；然后提出新的Local Inexact Proximal Point Algorithm with Extra Step (LIPPAX)算法来缓解客户端漂移问题。

Result: 在一般光滑单调变分不等式问题上获得了改进的收敛率，在有限Hessian、有限算子、低方差等多种场景下LIPPAX算法都表现出更好的性能，并将结果扩展到联邦复合变分不等式问题。

Conclusion: 通过精细化分析和新算法设计，显著缩小了联邦变分不等式优化与联邦凸优化之间的收敛率差距，为解决客户端漂移问题提供了有效方案。

Abstract: In this paper, we study federated optimization for solving stochastic variational inequalities (VIs), a problem that has attracted growing attention in recent years. Despite substantial progress, a significant gap remains between existing convergence rates and the state-of-the-art bounds known for federated convex optimization. In this work, we address this limitation by establishing a series of improved convergence rates. First, we show that, for general smooth and monotone variational inequalities, the classical Local Extra SGD algorithm admits tighter guarantees under a refined analysis. Next, we identify an inherent limitation of Local Extra SGD, which can lead to excessive client drift. Motivated by this observation, we propose a new algorithm, the Local Inexact Proximal Point Algorithm with Extra Step (LIPPAX), and show that it mitigates client drift and achieves improved guarantees in several regimes, including bounded Hessian, bounded operator, and low-variance settings. Finally, we extend our results to federated composite variational inequalities and establish improved convergence guarantees.

</details>


### [20] [Train Less, Infer Faster: Efficient Model Finetuning and Compression via Structured Sparsity](https://arxiv.org/abs/2602.09169)
*Jonathan Svirsky,Yehonathan Refael,Ofir Lindenbaum*

Main category: cs.LG

TL;DR: 提出一种通过稀疏化特定模型行列进行高效任务适配的方法，使用训练随机门实现最小可训练参数、降低推理时间，并能移除20-40%参数而不显著损失精度。


<details>
  <summary>Details</summary>
Motivation: 完全微调数十亿参数的基础语言模型计算成本高、内存需求大且容易过拟合。现有方法如低秩适配器虽然通过添加小型可训练模块来应对挑战，但会增加内存使用且无法减少推理延迟。

Method: 发现稀疏化特定模型行列可实现高效任务适配而无需权重调整。提出使用训练随机门进行稀疏化的有效微调方案，该方法需要最少的可训练参数，减少推理时间，并能移除20-40%的模型参数。

Result: 经验结果显示该方法在效率和性能上优于最近的微调基线。提供了随机门过程收敛的理论保证，并证明该方法相比LoRA具有更简单且条件更好的优化景观。

Conclusion: 稀疏化是语言模型中任务特定适配的一个有前景的机制，能够在保持性能的同时显著提高效率。

Abstract: Fully finetuning foundation language models (LMs) with billions of parameters is often impractical due to high computational costs, memory requirements, and the risk of overfitting. Although methods like low-rank adapters help address these challenges by adding small trainable modules to the frozen LM, they also increase memory usage and do not reduce inference latency. We uncover an intriguing phenomenon: sparsifying specific model rows and columns enables efficient task adaptation without requiring weight tuning. We propose a scheme for effective finetuning via sparsification using training stochastic gates, which requires minimal trainable parameters, reduces inference time, and removes 20--40\% of model parameters without significant accuracy loss. Empirical results show it outperforms recent finetuning baselines in efficiency and performance. Additionally, we provide theoretical guarantees for the convergence of this stochastic gating process, and show that our method admits a simpler and better-conditioned optimization landscape compared to LoRA. Our results highlight sparsity as a compelling mechanism for task-specific adaptation in LMs.

</details>


### [21] [$n$-Musketeers: Reinforcement Learning Shapes Collaboration Among Language Models](https://arxiv.org/abs/2602.09173)
*Ryozo Masukawa,Sanggeon Yun,Hyunwoo Oh,SuhgHeon Jeong,Raheeb Hassa,Hanning Chen,Wenjun Huang,Mahdi Imani,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: 该论文提出了一种软隐藏状态协作方法，通过可训练的注意力接口整合多个异构冻结专家模型的内部表示，在强化学习可验证奖励框架下实现结构化推理，无需依赖大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，具有可验证奖励的强化学习（RLVR）可以让小型专业化语言模型（SLMs）展现结构化推理能力，而无需依赖大型单体LLMs。本文旨在探索如何有效整合多个异构冻结专家模型，以进一步提升推理性能。

Method: 提出软隐藏状态协作方法：使用可训练的注意力接口，通过内部表示（隐藏状态）整合多个异构冻结的SLM专家模型。该方法在Reasoning Gym和GSM8K基准上进行实验验证。

Result: 实验表明，这种潜在整合方法与强大的单模型RLVR基线具有竞争力。消融研究揭示了专家利用的双重机制：对于简单算术领域，性能提升主要来自静态专家偏好；而在更具挑战性的设置中，训练过程中专家注意力越来越集中和结构化，表明路由器在连接相关专家时出现了专业化涌现。

Conclusion: 隐藏状态协作为利用冻结专家模型提供了一种紧凑机制，同时为观察专家利用模式及其在RLVR下的演化提供了窗口。该方法展示了如何通过整合小型专业化模型实现高效推理，而无需依赖大型语言模型。

Abstract: Recent progress in reinforcement learning with verifiable rewards (RLVR) shows that small, specialized language models (SLMs) can exhibit structured reasoning without relying on large monolithic LLMs. We introduce soft hidden-state collaboration, where multiple heterogeneous frozen SLM experts are integrated through their internal representations via a trainable attention interface. Experiments on Reasoning Gym and GSM8K show that this latent integration is competitive with strong single-model RLVR baselines. Ablations further reveal a dual mechanism of expert utilization: for simpler arithmetic domains, performance gains can largely be explained by static expert preferences, whereas more challenging settings induce increasingly concentrated and structured expert attention over training, indicating emergent specialization in how the router connects to relevant experts. Overall, hidden-state collaboration provides a compact mechanism for leveraging frozen experts, while offering an observational window into expert utilization patterns and their evolution under RLVR.

</details>


### [22] [Weighted Wasserstein Barycenter of Gaussian Processes for exotic Bayesian Optimization tasks](https://arxiv.org/abs/2602.09181)
*Antonio Candelieri,Francesco Archetti*

Main category: cs.LG

TL;DR: 提出基于高斯过程加权Wasserstein重心(W2BGP)的统一框架，用于处理多种贝叶斯优化任务，包括协作/联邦BO、批量BO和多保真度BO。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯优化方法针对不同任务需要专门设计，缺乏统一框架。本文旨在利用高斯过程与高斯分布之间的类比关系，建立一个能统一处理多种贝叶斯优化任务的通用框架。

Method: 利用高斯过程后验与高斯分布之间的类比，提出加权Wasserstein重心高斯过程(W2BGP)框架。通过不同的加权方案适应不同任务：协作/联邦BO、批量BO和多保真度BO。框架保持统一，仅需调整权重分配。

Result: 实证分析表明，该框架能统一处理三种贝叶斯优化任务，仅需调整权重方案。同时证明主流BO采集函数可在该框架下重新解释，且计算Wasserstein重心的方法比现有机器学习方法更高效。

Conclusion: W2BGP为多种贝叶斯优化任务提供了统一框架，通过简单调整权重即可适应不同应用场景，计算效率优于现有方法，并为未来研究提供了新的方向。

Abstract: Exploiting the analogy between Gaussian Distributions and Gaussian Processes' posterior, we present how the weighted Wasserstein Barycenter of Gaussian Processes (W2BGP) can be used to unify, under a common framework, different exotic Bayesian Optimization (BO) tasks. Specifically, collaborative/federated BO, (synchronous) batch BO, and multi-fidelity BO are considered in this paper. Our empirical analysis proves that each one of these tasks requires just an appropriate weighting schema for the W2BGP, while the entire framework remains untouched. Moreover, we demonstrate that the most well-known BO acquisition functions can be easily re-interpreted under the proposed framework and also enable a more computationally efficient way to deal with the computation of the Wasserstein Barycenter, compared with state-of-the-art methods from the Machine Learning literature. Finally, research perspectives branching from the proposed approach are presented.

</details>


### [23] [Gradient Residual Connections](https://arxiv.org/abs/2602.09190)
*Yangchen Pan,Qizhen Ying,Philip Torr,Bo Liu*

Main category: cs.LG

TL;DR: 提出基于梯度的残差连接，改进神经网络对高频函数的逼近能力，在超分辨率等任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有研究表明函数梯度特性与函数逼近难度相关，梯度信息有助于区分输入并逼近快速变化的行为。传统残差连接在处理高频函数时存在困难，需要利用梯度信息来提升逼近能力。

Method: 提出基于梯度的残差连接作为标准恒等跳跃连接的补充，提供梯度信息帮助网络区分输入。引入标准残差和梯度残差的凸组合，让网络灵活控制对梯度信息的依赖程度。

Result: 在高频正弦回归任务中，传统残差连接难以捕捉高频模式，而梯度残差显著提升逼近质量。在单图像超分辨率任务中，该方法对高频函数处理有效。在图像分类和分割等标准任务中，性能与标准残差网络相当。

Conclusion: 梯度信息能有效提升神经网络对高频函数的逼近能力，提出的梯度残差连接在保持标准任务性能的同时，特别适用于处理高频函数，具有广泛实用性。

Abstract: Existing work has linked properties of a function's gradient to the difficulty of function approximation. Motivated by these insights, we study how gradient information can be leveraged to improve neural network's ability to approximate high-frequency functions, and we propose a gradient-based residual connection as a complement to the standard identity skip connection used in residual networks. We provide simple theoretical intuition for why gradient information can help distinguish inputs and improve the approximation of functions with rapidly varying behaviour. On a synthetic regression task with a high-frequency sinusoidal ground truth, we show that conventional residual connections struggle to capture high-frequency patterns. In contrast, our gradient residual substantially improves approximation quality. We then introduce a convex combination of the standard and gradient residuals, allowing the network to flexibly control how strongly it relies on gradient information. After validating the design choices of our proposed method through an ablation study, we further validate our approach's utility on the single-image super-resolution task, where the underlying function may be high-frequency. Finally, on standard tasks such as image classification and segmentation, our method achieves performance comparable to standard residual networks, suggesting its broad utility.

</details>


### [24] [ML-DCN: Masked Low-Rank Deep Crossing Network Towards Scalable Ads Click-through Rate Prediction at Pinterest](https://arxiv.org/abs/2602.09194)
*Jiacheng Li,Yixiong Meng,Yi wu,Yun Zhao,Sharare Zehtabian,Jiayin Jin,Degao Peng,Jinfeng Zhuang,Qifei Shen,Kungang Li*

Main category: cs.LG

TL;DR: 提出ML-DCN特征交互模块，在固定计算预算下通过实例条件掩码和低秩交叉层实现更高效的特征交互建模，在Pinterest广告排序系统中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大规模广告排序系统中，模型容量增加能提升预测性能和业务效果，但生产环境对延迟和计算量有严格限制。现有DCNv2和MaskNet等特征交互模块在增加计算时收益递减，需要更高效的特征交互模块。

Method: 提出ML-DCN（Masked Low-rank DCN）模块，将实例条件掩码集成到低秩交叉层中，实现每个样本对重要交互方向的选择和放大，同时保持高效计算。

Result: 在Pinterest内部广告数据集上，ML-DCN在相同FLOPs下比DCNv2、MaskNet和近期其他方法获得更高AUC，在增加计算时展现出更好的AUC-FLOPs权衡。在线A/B测试显示CTR和点击质量指标显著提升，已部署到生产系统且服务成本中性。

Conclusion: ML-DCN结合了DCNv2和MaskNet的优势，在固定计算预算下能更有效地扩展特征交互模块，为大规模推荐系统提供了更高效的特征交互解决方案。

Abstract: Deep learning recommendation systems rely on feature interaction modules to model complex user-item relationships across sparse categorical and dense features. In large-scale ad ranking, increasing model capacity is a promising path to improving both predictive performance and business outcomes, yet production serving budgets impose strict constraints on latency and FLOPs. This creates a central tension: we want interaction modules that both scale effectively with additional compute and remain compute-efficient at serving time. In this work, we study how to scale feature interaction modules under a fixed serving budget. We find that naively scaling DCNv2 and MaskNet, despite their widespread adoption in industry, yields rapidly diminishing offline gains in the Pinterest ads ranking system. To overcome aforementioned limitations, we propose ML-DCN, an interaction module that integrates an instance-conditioned mask into a low-rank crossing layer, enabling per-example selection and amplification of salient interaction directions while maintaining efficient computation. This novel architecture combines the strengths of DCNv2 and MaskNet, scales efficiently with increased compute, and achieves state-of-the-art performance. Experiments on a large internal Pinterest ads dataset show that ML-DCN achieves higher AUC than DCNv2, MaskNet, and recent scaling-oriented alternatives at matched FLOPs, and it scales more favorably overall as compute increases, exhibiting a stronger AUC-FLOPs trade-off. Finally, online A/B tests demonstrate statistically significant improvements in key ads metrics (including CTR and click-quality measures) and ML-DCN has been deployed in the production system with neutral serving cost.

</details>


### [25] [Fair Feature Importance Scores via Feature Occlusion and Permutation](https://arxiv.org/abs/2602.09196)
*Camille Little,Madeline Navarro,Santiago Segarra,Genevera Allen*

Main category: cs.LG

TL;DR: 提出两种模型无关的特征重要性评估方法，用于衡量特征对模型公平性的贡献，包括基于置换的干预方法和基于特征遮挡的简化方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型对社会影响日益增大，其不透明性给公平性场景下的信任和问责带来挑战。虽然准确性的特征重要性评估方法已很成熟，但评估特征对公平性贡献的方法仍待探索。

Method: 提出两种模型无关的特征重要性评估方法：1）基于置换的方法：通过比较特征值置换前后模型公平性的变化来评估特征贡献；2）基于遮挡的方法：通过比较包含与不包含特定特征时训练模型的公平性差异来评估，利用minipatch学习实现计算简化。

Result: 实证结果表明，提出的两种方法在多种预测任务中表现出简单性和有效性，能够量化特征对公平性的影响。

Conclusion: 两种方法提供了简单、可扩展且可解释的解决方案，用于量化特征对公平性的影响，为负责任的机器学习开发提供了新工具。

Abstract: As machine learning models increasingly impact society, their opaque nature poses challenges to trust and accountability, particularly in fairness contexts. Understanding how individual features influence model outcomes is crucial for building interpretable and equitable models. While feature importance metrics for accuracy are well-established, methods for assessing feature contributions to fairness remain underexplored. We propose two model-agnostic approaches to measure fair feature importance. First, we propose to compare model fairness before and after permuting feature values. This simple intervention-based approach decouples a feature and model predictions to measure its contribution to training. Second, we evaluate the fairness of models trained with and without a given feature. This occlusion-based score enjoys dramatic computational simplification via minipatch learning. Our empirical results reflect the simplicity and effectiveness of our proposed metrics for multiple predictive tasks. Both methods offer simple, scalable, and interpretable solutions to quantify the influence of features on fairness, providing new tools for responsible machine learning development.

</details>


### [26] [CausalGDP: Causality-Guided Diffusion Policies for Reinforcement Learning](https://arxiv.org/abs/2602.09207)
*Xiaofeng Xiao,Xiao Hu,Yang Ye,Xubo Yue*

Main category: cs.LG

TL;DR: CausalGDP：将因果推理融入扩散策略的强化学习框架，通过因果引导提升策略性能


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略主要依赖统计关联，未能显式考虑状态、动作和奖励之间的因果关系，限制了识别真正导致高回报的动作组件的能力

Method: 提出因果引导扩散策略(CausalGDP)：1)从离线数据学习基础扩散策略和初始因果动态模型；2)实时交互中持续更新因果信息作为引导信号，指导扩散过程生成能因果影响未来状态和奖励的动作

Result: CausalGDP在复杂高维控制任务中，始终达到或优于最先进的扩散基和离线RL方法

Conclusion: 通过显式考虑因果关系而不仅仅是关联，CausalGDP将策略优化集中在真正驱动性能改进的动作组件上，提升了扩散策略的效能

Abstract: Reinforcement learning (RL) has achieved remarkable success in a wide range of sequential decision-making problems. Recent diffusion-based policies further improve RL by modeling complex, high-dimensional action distributions. However, existing diffusion policies primarily rely on statistical associations and fail to explicitly account for causal relationships among states, actions, and rewards, limiting their ability to identify which action components truly cause high returns. In this paper, we propose Causality-guided Diffusion Policy (CausalGDP), a unified framework that integrates causal reasoning into diffusion-based RL. CausalGDP first learns a base diffusion policy and an initial causal dynamical model from offline data, capturing causal dependencies among states, actions, and rewards. During real-time interaction, the causal information is continuously updated and incorporated as a guidance signal to steer the diffusion process toward actions that causally influence future states and rewards. By explicitly considering causality beyond association, CausalGDP focuses policy optimization on action components that genuinely drive performance improvements. Experimental results demonstrate that CausalGDP consistently achieves competitive or superior performance over state-of-the-art diffusion-based and offline RL methods, especially in complex, high-dimensional control tasks.

</details>


### [27] [A Lightweight Multi-View Approach to Short-Term Load Forecasting](https://arxiv.org/abs/2602.09220)
*Julien Guité-Vinet,Alexandre Blondin Massé,Éric Beaudry*

Main category: cs.LG

TL;DR: 提出一种轻量级多视角短期负荷预测方法，使用单值嵌入和缩放时间范围输入高效捕捉时序特征，通过嵌入dropout防止过拟合并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 虽然基于Transformer的大参数模型在时间序列预测中取得了SOTA结果，但其复杂性容易导致过拟合和不稳定预测，特别是当历史数据相关性降低时。需要更轻量、稳健的方法。

Method: 采用轻量级多视角方法，使用单值嵌入和缩放时间范围输入高效捕捉时序相关特征，引入嵌入dropout机制防止对特定特征的过度依赖并增强可解释性。

Result: 该方法在显著减少参数量的情况下实现了有竞争力的性能，在多个数据集上表现出鲁棒性，包括噪声或稀疏数据场景，并能提供特征贡献度的洞察。

Conclusion: 提出的轻量级多视角方法在短期负荷预测中实现了参数效率与性能的良好平衡，为复杂模型提供了一种更稳健、可解释的替代方案。

Abstract: Time series forecasting is a critical task across domains such as energy, finance, and meteorology, where accurate predictions enable informed decision-making. While transformer-based and large-parameter models have recently achieved state-of-the-art results, their complexity can lead to overfitting and unstable forecasts, especially when older data points become less relevant. In this paper, we propose a lightweight multi-view approach to short-term load forecasting that leverages single-value embeddings and a scaled time-range input to capture temporally relevant features efficiently. We introduce an embedding dropout mechanism to prevent over-reliance on specific features and enhance interpretability. Our method achieves competitive performance with significantly fewer parameters, demonstrating robustness across multiple datasets, including scenarios with noisy or sparse data, and provides insights into the contributions of individual features to the forecast.

</details>


### [28] [Barycentric alignment for instance-level comparison of neural representations](https://arxiv.org/abs/2602.09225)
*Shreya Saha,Zoe Wanying He,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 论文提出了一种基于重心对齐的框架，用于在个体刺激层面比较神经网络表示，解决了传统集合级相似性度量无法捕捉的表示收敛与分歧现象。


<details>
  <summary>Details</summary>
Motivation: 神经网络表示比较面临挑战，因为表示存在对称性（如单元重排、激活空间旋转），这些对称性掩盖了模型间的本质等价性。现有相似性度量仅在刺激集合层面总结关系，无法揭示哪些具体输入会引发模型间的表示收敛或分歧。

Method: 引入重心对齐框架，通过商掉这些冗余对称性，构建跨模型的通用嵌入空间。该方法能够在个体刺激层面定义相似性，识别导致表示收敛与分歧的系统性输入属性。应用于视觉和语言模型家族、跨个体和皮层区域的脑表示，以及跨模态对齐。

Result: 1）识别出预测视觉和语言模型间表示收敛与分歧的系统性输入属性；2）构建了跨个体和视觉层次阶段的脑表示通用嵌入空间；3）发现独立学习的单模态视觉和语言模型经过对齐后，其跨模态相似性分数与人类判断高度一致，接近对比训练的多模态模型性能。

Conclusion: 在个体刺激层面解析表示相似性能够揭示集合级比较度量无法检测的现象。独立学习的表示已经共享足够的几何结构，支持人类对齐的跨模态比较，这表明对比训练可能不是实现人类对齐跨模态相似性的必要条件。

Abstract: Comparing representations across neural networks is challenging because representations admit symmetries, such as arbitrary reordering of units or rotations of activation space, that obscure underlying equivalence between models. We introduce a barycentric alignment framework that quotients out these nuisance symmetries to construct a universal embedding space across many models. Unlike existing similarity measures, which summarize relationships over entire stimulus sets, this framework enables similarity to be defined at the level of individual stimuli, revealing inputs that elicit convergent versus divergent representations across models. Using this instance-level notion of similarity, we identify systematic input properties that predict representational convergence versus divergence across vision and language model families. We also construct universal embedding spaces for brain representations across individuals and cortical regions, enabling instance-level comparison of representational agreement across stages of the human visual hierarchy. Finally, we apply the same barycentric alignment framework to purely unimodal vision and language models and find that post-hoc alignment into a shared space yields image text similarity scores that closely track human cross-modal judgments and approach the performance of contrastively trained vision-language models. This strikingly suggests that independently learned representations already share sufficient geometric structure for human-aligned cross-modal comparison. Together, these results show that resolving representational similarity at the level of individual stimuli reveals phenomena that cannot be detected by set-level comparison metrics.

</details>


### [29] [Beyond the Unit Hypersphere: Embedding Magnitude in Contrastive Learning](https://arxiv.org/abs/2602.09229)
*Xincan Feng,Taro Watanabe*

Main category: cs.LG

TL;DR: 论文系统研究了对比学习中余弦相似度与点积的区别，发现嵌入向量的大小（magnitude）携带重要信息，其作用取决于任务对称性：非对称任务（如文本检索）受益于点积，对称任务（如语义相似度）适合余弦相似度。


<details>
  <summary>Details</summary>
Motivation: 余弦相似度在对比学习中普遍使用，但它隐含假设嵌入向量的大小是噪声。先前工作偶尔发现点积和余弦相似度效果相当，但未回答：大小携带什么信息、何时有帮助、如何利用它。

Method: 通过2×2消融实验独立控制输入侧和输出侧的归一化，在文本和视觉模型上进行系统研究，分析大小在不同任务中的作用。

Result: 1. 文本检索中输出（文档）大小与相关性强相关（Cohen's d高达1.80），在推理密集型任务中收益最大；2. 输入和输出大小作用不对称：输出大小直接缩放相似度分数，输入大小调节训练动态；3. 大小学习对非对称任务（文本检索、RAG）有益，但对对称任务（STS、文本-图像对齐）有害。

Conclusion: 提出任务对称性原则：选择余弦相似度还是点积取决于任务是否具有不同的输入角色。通过移除不必要的约束（归一化），可以在非对称任务中获得免费的性能提升。

Abstract: Cosine similarity is prevalent in contrastive learning, yet it makes an implicit assumption: embedding magnitude is noise. Prior work occasionally found dot product and cosine similarity comparable, but left unanswered WHAT information magnitude carries, WHEN it helps, and HOW to leverage it. We conduct a systematic study through a $2 \times 2$ ablation that independently controls input-side and output-side normalization across text and vision models. Our findings reveal three key insights. First, in text retrieval, output (document) magnitude strongly correlates with relevance (Cohen's $d$ up to 1.80), yielding the largest gains on reasoning-intensive tasks. Second, input and output magnitudes serve asymmetric roles: output magnitude directly scales similarity scores while input magnitude modulates training dynamics. Third, magnitude learning benefits asymmetric tasks (text retrieval, RAG) but harms symmetric tasks (STS, text-image alignment). These findings establish a task symmetry principle: the choice between cosine and dot product depends on whether the task has distinct input roles, enabling cost-free improvements by simply removing an unnecessary constraint.

</details>


### [30] [Do Neural Networks Lose Plasticity in a Gradually Changing World?](https://arxiv.org/abs/2602.09234)
*Tianhui Liu,Lili Mou*

Main category: cs.LG

TL;DR: 研究发现损失可塑性现象主要是由环境任务突变造成的，在逐渐变化的环境中该问题可被显著缓解。


<details>
  <summary>Details</summary>
Motivation: 现有可塑性研究多基于人为设计的突变任务切换场景，这与真实世界环境不符。本文旨在研究逐渐变化环境中的可塑性问题。

Method: 通过输入/输出插值和任务采样来模拟逐渐变化的环境，并进行理论和实证分析。

Result: 损失可塑性是环境任务突变的产物，如果世界变化是渐进的，该问题可被大幅缓解。

Conclusion: 逐渐变化的环境能有效维持神经网络的持续学习能力，为真实世界应用提供了更现实的解决方案。

Abstract: Continual learning has become a trending topic in machine learning. Recent studies have discovered an interesting phenomenon called loss of plasticity, referring to neural networks gradually losing the ability to learn new tasks. However, existing plasticity research largely relies on contrived settings with abrupt task transitions, which often do not reflect real-world environments. In this paper, we propose to investigate a gradually changing environment, and we simulate this by input/output interpolation and task sampling. We perform theoretical and empirical analysis, showing that the loss of plasticity is an artifact of abrupt tasks changes in the environment and can be largely mitigated if the world changes gradually.

</details>


### [31] [RAPID: Risk of Attribute Prediction-Induced Disclosure in Synthetic Microdata](https://arxiv.org/abs/2602.09235)
*Matthias Templ,Oscar Thees,Roman Müller*

Main category: cs.LG

TL;DR: RAPID是一个新的隐私风险度量方法，直接量化合成数据下敏感属性推断的漏洞，通过攻击者在合成数据上训练预测模型并应用于真实个体的准标识符来评估风险。


<details>
  <summary>Details</summary>
Motivation: 传统身份披露度量对合成数据的隐私风险评估不够有效，需要更直接衡量攻击者从发布数据中推断敏感属性的能力。

Method: 提出RAPID度量：攻击者仅使用发布的合成数据训练预测模型，然后应用于真实个体的准标识符。对于连续属性，计算预测值在相对误差容忍度内的记录比例；对于分类属性，提出基线归一化置信度分数，衡量攻击者对真实类别的置信度超出类别普遍预期的程度。

Result: RAPID提供了可解释、有界、对类别不平衡鲁棒的风险度量，独立于特定合成器，适用于任意学习算法，能够为属性推断披露风险提供实用的、攻击者现实的上界。

Conclusion: RAPID是一个实用的隐私风险度量方法，补充了现有的效用诊断和披露控制框架，能够有效评估合成数据下敏感属性推断的漏洞。

Abstract: Statistical data anonymization increasingly relies on fully synthetic microdata, for which classical identity disclosure measures are less informative than an adversary's ability to infer sensitive attributes from released data. We introduce RAPID (Risk of Attribute Prediction--Induced Disclosure), a disclosure risk measure that directly quantifies inferential vulnerability under a realistic attack model. An adversary trains a predictive model solely on the released synthetic data and applies it to real individuals' quasi-identifiers. For continuous sensitive attributes, RAPID reports the proportion of records whose predicted values fall within a specified relative error tolerance. For categorical attributes, we propose a baseline-normalized confidence score that measures how much more confident the attacker is about the true class than would be expected from class prevalence alone, and we summarize risk as the fraction of records exceeding a policy-defined threshold. This construction yields an interpretable, bounded risk metric that is robust to class imbalance, independent of any specific synthesizer, and applicable with arbitrary learning algorithms. We illustrate threshold calibration, uncertainty quantification, and comparative evaluation of synthetic data generators using simulations and real data. Our results show that RAPID provides a practical, attacker-realistic upper bound on attribute-inference disclosure risk that complements existing utility diagnostics and disclosure control frameworks.

</details>


### [32] [Feature salience -- not task-informativeness -- drives machine learning model explanations](https://arxiv.org/abs/2602.09238)
*Benedict Clark,Marta Oliveira,Rick Wilming,Stefan Haufe*

Main category: cs.LG

TL;DR: XAI方法可能更多受到特征显著性而非信息量的驱动，水印实验显示重要性归因主要基于测试时图像结构的显著性而非模型学习的统计关联


<details>
  <summary>Details</summary>
Motivation: 研究XAI方法是否真正识别信息特征，还是受到其他数据属性（如统计抑制、测试时新颖性、高特征显著性）的影响，以验证XAI假设的有效性

Method: 在三种变体的二值图像分类任务上训练深度学习模型：无水印、类相关混淆水印、类无关噪声水印，使用五种流行归因方法分析水印区域相对重要性

Result: 所有训练设置下水印区域相对重要性显著升高（R²≥0.45），而水印是否类相关对重要性影响很小（R²≤0.03），XAI方法行为类似边缘检测滤波器，重要性归因主要受测试时图像结构显著性驱动

Conclusion: XAI重要性归因主要受特征显著性而非信息量驱动，先前XAI成功应用研究需重新评估特征显著性与信息量可能虚假并发的可能性，使用特征归因方法的工作流程需仔细审查

Abstract: Explainable AI (XAI) promises to provide insight into machine learning models' decision processes, where one goal is to identify failures such as shortcut learning. This promise relies on the field's assumption that input features marked as important by an XAI must contain information about the target variable. However, it is unclear whether informativeness is indeed the main driver of importance attribution in practice, or if other data properties such as statistical suppression, novelty at test-time, or high feature salience substantially contribute. To clarify this, we trained deep learning models on three variants of a binary image classification task, in which translucent watermarks are either absent, act as class-dependent confounds, or represent class-independent noise. Results for five popular attribution methods show substantially elevated relative importance in watermarked areas (RIW) for all models regardless of the training setting ($R^2 \geq .45$). By contrast, whether the presence of watermarks is class-dependent or not only has a marginal effect on RIW ($R^2 \leq .03$), despite a clear impact impact on model performance and generalisation ability. XAI methods show similar behaviour to model-agnostic edge detection filters and attribute substantially less importance to watermarks when bright image intensities are encoded by smaller instead of larger feature values. These results indicate that importance attribution is most strongly driven by the salience of image structures at test time rather than statistical associations learned by machine learning models. Previous studies demonstrating successful XAI application should be reevaluated with respect to a possibly spurious concurrency of feature salience and informativeness, and workflows using feature attribution methods as building blocks should be scrutinised.

</details>


### [33] [Generalizing GNNs with Tokenized Mixture of Experts](https://arxiv.org/abs/2602.09258)
*Xiaoguang Guo,Zehong Wang,Jiazheng Li,Shawn Spitzel,Qi Yang,Kaize Ding,Jundong Li,Chuxu Zhang*

Main category: cs.LG

TL;DR: STEM-GNN框架通过专家混合编码器、向量量化接口和Lipschitz正则化头，解决了图神经网络在部署时面临的稳定性、分布偏移和扰动之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 部署的图神经网络需要同时满足：适应干净数据、在分布偏移下泛化、对扰动保持稳定。静态推理存在根本性权衡：提高稳定性需要减少对偏移敏感特征的依赖，导致无法避免的最坏情况泛化下限。

Method: 提出STEM-GNN框架，采用预训练-微调范式：1) 专家混合编码器提供多样化计算路径；2) 向量量化令牌接口稳定编码器到头的信号；3) Lipschitz正则化头限制输出放大。

Result: 在九个节点、链接和图基准测试中，STEM-GNN实现了更强的三方面平衡：提高了对度/同质性偏移的鲁棒性，对特征/边扰动的鲁棒性，同时在干净图上保持竞争力。

Conclusion: 通过分解覆盖vs选择和基础敏感性vs波动放大，STEM-GNN打破了静态推理的权衡限制，为图神经网络部署提供了更鲁棒的解决方案。

Abstract: Deployed graph neural networks (GNNs) are frozen at deployment yet must fit clean data, generalize under distribution shifts, and remain stable to perturbations. We show that static inference induces a fundamental tradeoff: improving stability requires reducing reliance on shift-sensitive features, leaving an irreducible worst-case generalization floor. Instance-conditional routing can break this ceiling, but is fragile because shifts can mislead routing and perturbations can make routing fluctuate. We capture these effects via two decompositions separating coverage vs selection, and base sensitivity vs fluctuation amplification. Based on these insights, we propose STEM-GNN, a pretrain-then-finetune framework with a mixture-of-experts encoder for diverse computation paths, a vector-quantized token interface to stabilize encoder-to-head signals, and a Lipschitz-regularized head to bound output amplification. Across nine node, link, and graph benchmarks, STEM-GNN achieves a stronger three-way balance, improving robustness to degree/homophily shifts and to feature/edge corruptions while remaining competitive on clean graphs.

</details>


### [34] [The effect of whitening on explanation performance](https://arxiv.org/abs/2602.09278)
*Benedict Clark,Stoyan Karastoyanov,Rick Wilming,Stefan Haufe*

Main category: cs.LG

TL;DR: 该研究探讨了数据白化（去相关预处理）能否改善特征归因方法的可靠性，通过XAI-TRIS基准测试和理论分析发现，特定白化技术能提升解释性能，但效果因XAI方法和模型架构而异。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，许多特征归因方法经常错误地将重要性分配给非信息性变量（如抑制变量），导致根本性误解。由于统计抑制是由特征依赖性引起的，本研究旨在探究数据白化（一种常见的去相关预处理技术）是否能减轻此类错误。

Method: 使用XAI-TRIS基准测试（提供合成真实数据和解释正确性的定量测量），对16种流行的特征归因方法与5种不同的白化变换进行组合评估。同时，分析一个最小线性二维分类问题，从理论上评估白化是否能从贝叶斯最优模型中消除抑制特征的影响。

Result: 结果表明，虽然特定的白化技术可以改善解释性能，但改进程度在XAI方法和模型架构之间存在显著差异。白化效果受到数据非线性、预处理质量和归因保真度之间复杂关系的影响。

Conclusion: 预处理技术在增强模型可解释性方面起着至关重要的作用，但需要根据具体的XAI方法和模型架构谨慎选择白化技术。研究强调了数据非线性、预处理质量和归因保真度之间的复杂关系。

Abstract: Explainable Artificial Intelligence (XAI) aims to provide transparent insights into machine learning models, yet the reliability of many feature attribution methods remains a critical challenge. Prior research (Haufe et al., 2014; Wilming et al., 2022, 2023) has demonstrated that these methods often erroneously assign significant importance to non-informative variables, such as suppressor variables, leading to fundamental misinterpretations. Since statistical suppression is induced by feature dependencies, this study investigates whether data whitening, a common preprocessing technique for decorrelation, can mitigate such errors. Using the established XAI-TRIS benchmark (Clark et al., 2024b), which offers synthetic ground-truth data and quantitative measures of explanation correctness, we empirically evaluate 16 popular feature attribution methods applied in combination with 5 distinct whitening transforms. Additionally, we analyze a minimal linear two-dimensional classification problem (Wilming et al., 2023) to theoretically assess whether whitening can remove the impact of suppressor features from Bayes-optimal models. Our results indicate that, while specific whitening techniques can improve explanation performance, the degree of improvement varies substantially across XAI methods and model architectures. These findings highlight the complex relationship between data non-linearities, preprocessing quality, and attribution fidelity, underscoring the vital role of pre-processing techniques in enhancing model interpretability.

</details>


### [35] [Measuring Privacy Risks and Tradeoffs in Financial Synthetic Data Generation](https://arxiv.org/abs/2602.09288)
*Michael Zuo,Inwon Kang,Stacy Patterson,Oshani Seneviratne*

Main category: cs.LG

TL;DR: 论文探讨了金融表格数据合成生成方案中的隐私-效用权衡，针对高监管风险和严重类别不平衡的特点，比较了多种生成方法，并提出了新的隐私保护实现。


<details>
  <summary>Details</summary>
Motivation: 金融领域表格数据具有高监管风险和严重类别不平衡的特点，需要探索如何在生成合成数据时平衡隐私保护和数据效用。

Method: 考虑了多种表格数据生成器（自编码器、生成对抗网络、扩散模型、copula合成器），针对金融领域挑战提供了GAN和自编码器合成器的新隐私保护实现，并在平衡和不平衡输入数据集上评估性能。

Result: 研究结果揭示了从具有严重类别不平衡和混合类型属性的数据集中生成合成数据的独特挑战，为不同生成方法在数据质量、下游效用和隐私保护方面的表现提供了见解。

Conclusion: 金融领域的合成数据生成面临特殊挑战，需要专门考虑类别不平衡和混合类型属性，研究为这一领域的隐私-效用权衡提供了重要参考。

Abstract: We explore the privacy-utility tradeoff of synthetic data generation schemes on tabular financial datasets, a domain characterized by high regulatory risk and severe class imbalance. We consider representative tabular data generators, including autoencoders, generative adversarial networks, diffusion, and copula synthesizers. To address the challenges of the financial domain, we provide novel privacy-preserving implementations of GAN and autoencoder synthesizers. We evaluate whether and how well the generators simultaneously achieve data quality, downstream utility, and privacy, with comparison across balanced and imbalanced input datasets. Our results offer insight into the distinct challenges of generating synthetic data from datasets that exhibit severe class imbalance and mixed-type attributes.

</details>


### [36] [Positive-Unlabelled Active Learning to Curate a Dataset for Orca Resident Interpretation](https://arxiv.org/abs/2602.09295)
*Bret Nestor,Bohan Yao,Jasmine Moore,Jasper Kanes*

Main category: cs.LG

TL;DR: 本研究构建了迄今为止最大的南方居留型虎鲸声学数据集，包含超过30年的音频数据，开发了基于Transformer的检测器，在多个数据集上超越了现有方法，并提供了大量标注的海洋哺乳动物音频数据。


<details>
  <summary>Details</summary>
Motivation: 南方居留型虎鲸是濒危物种，需要大规模声学数据来支持保护工作。现有数据集有限，需要更全面的数据集来支持机器翻译、栖息地使用调查和保护工作。

Method: 采用弱监督、正样本未标记的主动学习策略，系统搜索SRKW栖息地内所有可用的公共档案水听器数据，开发基于Transformer的检测器和分类器。

Result: 构建了包含919小时SRKW数据、230小时Bigg's虎鲸数据、1374小时未标记生态型虎鲸数据等的大规模数据集，检测器在DEEPAL、DCLDE-2026等数据集上表现优于现有方法，特异性达到0-28.8%（95%灵敏度）。

Conclusion: 本研究创建了最大的SRKW声学数据集，为濒危物种保护提供了重要资源，适用于无监督机器翻译、栖息地使用调查和保护工作，数据已公开可用。

Abstract: This work presents the largest curation of Southern Resident Killer Whale (SRKW) acoustic data to date, also containing other marine mammals in their environment. We systematically search all available public archival hydrophone data within the SRKW habitat (over 30 years of audio data). The search consists of a weakly-supervised, positive-unlabelled, active learning strategy to identify all instances of marine mammals. The resulting transformer-based detectors outperform state-of-the-art detectors on the DEEPAL, DCLDE-2026, and two newly introduced expert-annotated datasets in terms of accuracy, energy efficiency, and speed. The detection model has a specificity of 0-28.8% at 95% sensitivity. Our multiclass species classifier obtains a top-1 accuracy of 42.1% (11 train classes, 4 test classes) and our ecotype classifier obtains a top-1 accuracy of 43.0% (4 train classes, 5 test classes) on the DCLDE-2026 dataset.
  We yield 919 hours of SRKW data, 230 hours of Bigg's orca data, 1374 hours of orca data from unlabelled ecotypes, 1501 hours of humpback data, 88 hours of sea lion data, 246 hours of pacific white-sided dolphin data, and over 784 hours of unspecified marine mammal data. This SRKW dataset is larger than DCLDE-2026, Ocean Networks Canada, and OrcaSound combined. The curated species labels are available under CC-BY 4.0 license, and the corresponding audio data are available under the licenses of the original owners. The comprehensive nature of this dataset makes it suitable for unsupervised machine translation, habitat usage surveys, and conservation endeavours for this critically endangered ecotype.

</details>


### [37] [The Laplacian Mechanism Improves Transformers by Reshaping Token Geometry](https://arxiv.org/abs/2602.09297)
*Yuchong Zhang,Vardan Papyan*

Main category: cs.LG

TL;DR: 提出Laplacian机制替代注意力机制，让Transformer更直接控制token方差，实现理想token几何结构，提升视觉和语言任务性能。


<details>
  <summary>Details</summary>
Motivation: Transformer通过注意力、残差连接和层归一化控制token表示的方差，但缺乏对token方差的直接控制。作者认为这限制了模型实现理想的token几何结构，因此提出Laplacian机制来更直接地控制token方差。

Method: 将注意力机制修改为Laplacian机制，该机制能更直接控制token方差。通过多种分析工具研究其对token表示几何结构的影响：1)主成分分析，2)余弦相似度度量，3)方差分析，4)神经崩溃度量。

Result: 在计算机视觉和语言基准测试中，Laplacian机制带来了一致的性能提升。分析表明该机制重塑token嵌入向最大可分性几何结构：token按类别崩溃，类均值呈现神经崩溃现象。

Conclusion: Laplacian机制通过更直接控制token方差，帮助Transformer实现理想的token几何结构，即token按类别分离，类均值呈现神经崩溃，从而提升模型性能。

Abstract: Transformers leverage attention, the residual connection, and layer normalization to control the variance of token representations. We propose to modify attention into a Laplacian mechanism that gives the model more direct control over token variance. We conjecture that this helps transformers achieve the ideal token geometry. To investigate our conjecture, we first show that incorporating the Laplacian mechanism into transformers induces consistent improvements across benchmarks in computer vision and language. Next, we study how the Laplacian mechanism impacts the geometry of token representations using various tools: 1) principal component analysis, 2) cosine similarity metric, 3) analysis of variance, and 4) Neural Collapse metrics. Our investigation shows that the Laplacian mechanism reshapes token embeddings toward a geometry of maximal separability: tokens collapse according to their classes, and the class means exhibit Neural Collapse.

</details>


### [38] [Risk-sensitive reinforcement learning using expectiles, shortfall risk and optimized certainty equivalent risk](https://arxiv.org/abs/2602.09300)
*Sumedh Gupte,Shrey Rakeshkumar Patel,Soumen Pachal,Prashanth L. A.,Sanjay P. Bhat*

Main category: cs.LG

TL;DR: 提出三种风险敏感强化学习算法，分别针对期望分位数、效用不足风险和优化确定性等价风险，推导了策略梯度定理并设计了估计器，建立了理论收敛保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习主要关注期望回报，但在实际应用中需要考虑风险因素。本文旨在开发能够处理不同风险度量的强化学习算法，使智能体能够在风险敏感的环境中进行决策。

Method: 针对三种风险度量（期望分位数、效用不足风险、优化确定性等价风险），在有限时域马尔可夫决策过程框架下，首先推导了策略梯度定理，然后设计了相应的风险敏感策略梯度估计器，并建立了均方误差界限。在标准假设下，证明了风险敏感目标函数的平滑性，从而得到算法的收敛速率保证。

Result: 理论分析表明，提出的估计器具有O(1/m)的均方误差界限（m为轨迹数）。在标准假设下，算法能够达到平稳收敛速率。数值实验在流行的强化学习基准上验证了理论结果。

Conclusion: 本文成功开发了针对三种重要风险度量的风险敏感强化学习算法，建立了完整的理论框架，包括策略梯度定理、估计器设计和收敛性分析，并通过实验验证了方法的有效性。

Abstract: We propose risk-sensitive reinforcement learning algorithms catering to three families of risk measures, namely expectiles, utility-based shortfall risk and optimized certainty equivalent risk. For each risk measure, in the context of a finite horizon Markov decision process, we first derive a policy gradient theorem. Second, we propose estimators of the risk-sensitive policy gradient for each of the aforementioned risk measures, and establish $\mathcal{O}\left(1/m\right)$ mean-squared error bounds for our estimators, where $m$ is the number of trajectories. Further, under standard assumptions for policy gradient-type algorithms, we establish smoothness of the risk-sensitive objective, in turn leading to stationary convergence rate bounds for the overall risk-sensitive policy gradient algorithm that we propose. Finally, we conduct numerical experiments to validate the theoretical findings on popular RL benchmarks.

</details>


### [39] [Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training](https://arxiv.org/abs/2602.09303)
*Che-Chia Chang,Chen-Yang Dai,Te-Sheng Lin,Ming-Chih Lai,Chieh-Hsin Lai*

Main category: cs.LG

TL;DR: 提出物理信息一致性建模框架，通过快速、少步生成推理求解偏微分方程，解决物理约束训练中的稳定性问题，实现计算成本大幅降低的高保真推理。


<details>
  <summary>Details</summary>
Motivation: 传统物理约束一致性训练存在稳定性问题，PDE残差可能导致模型趋向平凡或退化解，从而损害学习的数据分布质量。需要开发稳定的训练策略来同时保持生成质量和物理一致性。

Method: 提出结构保持的两阶段训练策略：1) 解耦分布学习和物理约束，在物理信息微调期间冻结系数解码器；2) 提出两步残差目标，在精炼的、结构有效的生成轨迹上而非噪声单步预测上强制执行物理一致性。

Result: 框架实现了稳定、高保真的无条件生成和前向问题推理。前向解可通过基于投影的零样本修复过程获得，在保持扩散基线一致精度的同时，计算成本降低了数个数量级。

Conclusion: 提出的物理信息一致性建模框架成功解决了物理约束训练中的稳定性挑战，实现了快速、少步的PDE求解，为生成建模与物理约束的融合提供了有效解决方案。

Abstract: We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degenerate solutions, degrading the learned data distribution. To address this, we introduce a structure-preserving two-stage training strategy that decouples distribution learning from physics enforcement by freezing the coefficient decoder during physics-informed fine-tuning. We further propose a two-step residual objective that enforces physical consistency on refined, structurally valid generative trajectories rather than noisy single-step predictions. The resulting framework enables stable, high-fidelity inference for both unconditional generation and forward problems. We demonstrate that forward solutions can be obtained via a projection-based zero-shot inpainting procedure, achieving consistent accuracy of diffusion baselines with orders of magnitude reduction in computational cost.

</details>


### [40] [Statistical Roughness-Informed Machine Unlearning](https://arxiv.org/abs/2602.09304)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: SRAGU是一种基于统计粗糙度自适应梯度更新的机器学习遗忘算法，通过层间统计粗糙度重新分配遗忘更新，提高大规模或对抗性删除下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现代深度网络中，近似遗忘方法在大规模或对抗性删除时经常失败，因为网络层间存在显著异质性：有些层表现出稳定、良好正则化的表示，而其他层则脆弱、训练不足或过拟合，导致朴素更新分配可能引发灾难性遗忘或不稳定动态。

Method: 提出统计粗糙度自适应梯度遗忘（SRAGU）算法，通过层间统计粗糙度重新分配遗忘更新。使用权重矩阵的重尾谱诊断计算层间统计粗糙度，估计每个层的重尾指数，映射到有界谱稳定性权重，然后使用该稳定性信号对AGU敏感度进行谱重加权，最后应用相同的小批量更新形式。

Result: 该方法将遗忘运动集中在谱稳定的层中，同时抑制不稳定或过拟合层的更新，提高了硬删除下的稳定性。通过行为对齐到在保留数据上从头训练的金标准参考模型进行评估，使用经验预测差异和KL到金标准的代理指标，并报告成员推断审计作为补充泄漏信号。

Conclusion: SRAGU通过谱稳定性重新分配遗忘更新，有效解决了深度网络中层间异质性导致的遗忘稳定性问题，提高了在大规模或对抗性删除场景下的机器遗忘性能。

Abstract: Machine unlearning aims to remove the influence of a designated forget set from a trained model while preserving utility on the retained data. In modern deep networks, approximate unlearning frequently fails under large or adversarial deletions due to pronounced layer-wise heterogeneity: some layers exhibit stable, well-regularized representations while others are brittle, undertrained, or overfit, so naive update allocation can trigger catastrophic forgetting or unstable dynamics. We propose Statistical-Roughness Adaptive Gradient Unlearning (SRAGU), a mechanism-first unlearning algorithm that reallocates unlearning updates using layer-wise statistical roughness operationalized via heavy-tailed spectral diagnostics of layer weight matrices. Starting from an Adaptive Gradient Unlearning (AGU) sensitivity signal computed on the forget set, SRAGU estimates a WeightWatcher-style heavy-tailed exponent for each layer, maps it to a bounded spectral stability weight, and uses this stability signal to spectrally reweight the AGU sensitivities before applying the same minibatch update form. This concentrates unlearning motion in spectrally stable layers while damping updates in unstable or overfit layers, improving stability under hard deletions. We evaluate unlearning via behavioral alignment to a gold retrained reference model trained from scratch on the retained data, using empirical prediction-divergence and KL-to-gold proxies on a forget-focused query set; we additionally report membership inference auditing as a complementary leakage signal, treating forget-set points as should-be-forgotten members during evaluation.

</details>


### [41] [Reward Modeling for Reinforcement Learning-Based LLM Reasoning: Design, Challenges, and Evaluation](https://arxiv.org/abs/2602.09305)
*Pei-Chi Pan,Yingbin Liang,Sen Lin*

Main category: cs.LG

TL;DR: 本文提出推理对齐强化学习(RARL)框架，系统化多步推理的奖励机制，分析奖励建模对LLM推理能力的关键作用，并指出当前基准测试的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习微调是改进大型语言模型的关键机制，但奖励设计的效果与LLM核心挑战（如评估偏差、幻觉、分布偏移和高效学习）之间的关系尚未得到充分理解。奖励建模不仅是实现细节，而是推理对齐的核心架构。

Method: 提出推理对齐强化学习(RARL)统一框架，系统化多步推理的奖励范式，建立奖励机制分类法，分析奖励黑客作为普遍失效模式，并研究奖励信号如何统一从推理时缩放到幻觉缓解等挑战。

Result: 通过整合碎片化研究线索，阐明了奖励设计与基本推理能力之间的相互作用，为构建稳健、可验证和可信赖的推理模型提供了基础路线图。

Conclusion: 奖励建模是推理对齐的核心架构，塑造了模型的学习内容、泛化方式以及输出的可信度。本文通过RARL框架为构建更可靠的推理模型提供了系统化方法和评估方向。

Abstract: Large Language Models (LLMs) demonstrate transformative potential, yet their reasoning remains inconsistent and unreliable. Reinforcement learning (RL)-based fine-tuning is a key mechanism for improvement, but its effectiveness is fundamentally governed by reward design. Despite its importance, the relationship between reward modeling and core LLM challenges--such as evaluation bias, hallucination, distribution shift, and efficient learning--remains poorly understood. This work argues that reward modeling is not merely an implementation detail but a central architect of reasoning alignment, shaping what models learn, how they generalize, and whether their outputs can be trusted. We introduce Reasoning-Aligned Reinforcement Learning (RARL), a unifying framework that systematizes diverse reward paradigms for multi-step reasoning. Within this framework, we present a taxonomy of reward mechanisms, analyze reward hacking as a pervasive failure mode, and examine how reward signals unify challenges ranging from inference-time scaling to hallucination mitigation. We further critically evaluate existing benchmarks, highlighting vulnerabilities such as data contamination and reward misalignment, and outline directions for more robust evaluation. By integrating fragmented research threads and clarifying the interplay between reward design and fundamental reasoning capabilities, this work provides a foundational roadmap for building reasoning models that are robust, verifiable, and trustworthy.

</details>


### [42] [Empowering Contrastive Federated Sequential Recommendation with LLMs](https://arxiv.org/abs/2602.09306)
*Thi Minh Chau Nguyen,Minh Hieu Nguyen,Duc Anh Nguyen,Xuan Huong Tran,Thanh Trung Huynh,Quoc Viet Hung Nguyen*

Main category: cs.LG

TL;DR: LUMOS：一种联邦序列推荐框架，利用本地LLM生成三种序列变体（未来轨迹、语义重述、反事实负例），通过三视图对比优化提升推荐性能，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 联邦序列推荐面临数据碎片化、噪声和同质化的挑战，现有方法通过手动数据增强或服务器端约束效果有限。需要一种既能丰富语义多样性又不增加系统开销的解决方案。

Method: 提出LUMOS框架：1）本地调用LLM生成三种序列变体：未来轨迹、语义重述、反事实负例；2）采用参数隔离架构，不共享梯度或辅助参数；3）通过三视图对比优化方案联合编码合成序列。

Result: 在三个公开基准测试中，LUMOS在HR@20和NDCG@20指标上均优于集中式和联邦式基线方法。在噪声和对抗环境下表现出更强的鲁棒性，无需专用服务器端保护模块。

Conclusion: LLM驱动的语义生成为隐私保护的联邦推荐提供了新范式，通过本地生成多样化语义信号，有效解决了数据碎片化和同质化问题，同时保护了用户隐私。

Abstract: Federated sequential recommendation (FedSeqRec) aims to perform next-item prediction while keeping user data decentralised, yet model quality is frequently constrained by fragmented, noisy, and homogeneous interaction logs stored on individual devices. Many existing approaches attempt to compensate through manual data augmentation or additional server-side constraints, but these strategies either introduce limited semantic diversity or increase system overhead. To overcome these challenges, we propose \textbf{LUMOS}, a parameter-isolated FedSeqRec architecture that integrates large language models (LLMs) as \emph{local semantic generators}. Instead of sharing gradients or auxiliary parameters, LUMOS privately invokes an on-device LLM to construct three complementary sequence variants from each user history: (i) \emph{future-oriented} trajectories that infer plausible behavioural continuations, (ii) \emph{semantically equivalent rephrasings} that retain user intent while diversifying interaction patterns, and (iii) \emph{preference-inconsistent counterfactuals} that serve as informative negatives. These synthesized sequences are jointly encoded within the federated backbone through a tri-view contrastive optimisation scheme, enabling richer representation learning without exposing sensitive information. Experimental results across three public benchmarks show that LUMOS achieves consistent gains over competitive centralised and federated baselines on HR@20 and NDCG@20. In addition, the use of semantically grounded positive signals and counterfactual negatives improves robustness under noisy and adversarial environments, even without dedicated server-side protection modules. Overall, this work demonstrates the potential of LLM-driven semantic generation as a new paradigm for advancing privacy-preserving federated recommendation.

</details>


### [43] [Clarifying Shampoo: Adapting Spectral Descent to Stochasticity and the Parameter Trajectory](https://arxiv.org/abs/2602.09314)
*Runa Eschenhagen,Anna Cai,Tsung-Hsien Lee,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: Shampoo优化器在语言模型训练中比Muon具有更高的token效率，类似于Adam相对于Signum的优势。Shampoo的更新可以分解为适应性的Muon更新，其优势主要源于对权重矩阵的应用而非参数形状无关的解释。


<details>
  <summary>Details</summary>
Motivation: 虽然Shampoo和Muon等利用矩阵结构的优化器比Adam和Signum等逐元素算法更数据高效，但它们在受控设置下的通用关系和相对数据效率仍不清楚。需要明确这些优化器之间的理论关系和实际性能差异。

Method: 通过语言模型上的大量实验，比较Shampoo和Muon的token效率。分析Shampoo更新应用于权重矩阵时的数学分解，将其分解为适应性的Muon更新。从时间平均半正交性角度提供新的理论解释。

Result: 实验显示Shampoo比Muon具有更高的token效率，类似于Adam相对于Signum的优势。Shampoo的更新可以分解为适应性的Muon更新，其优势完全归因于对权重矩阵的应用，挑战了与参数形状无关的解释。

Conclusion: Shampoo的优势源于其对权重矩阵的特定应用，而非基于方差适应和白化的传统解释。Shampoo的更新在期望上是时间平均半正交的，这提供了新的理论视角，避免了相关解释的缺点。

Abstract: Optimizers leveraging the matrix structure in neural networks, such as Shampoo and Muon, are more data-efficient than element-wise algorithms like Adam and Signum. While in specific settings, Shampoo and Muon reduce to spectral descent analogous to how Adam and Signum reduce to sign descent, their general relationship and relative data efficiency under controlled settings remain unclear. Through extensive experiments on language models, we demonstrate that Shampoo achieves higher token efficiency than Muon, mirroring Adam's advantage over Signum. We show that Shampoo's update applied to weight matrices can be decomposed into an adapted Muon update. Consistent with this, Shampoo's benefits can be exclusively attributed to its application to weight matrices, challenging interpretations agnostic to parameter shapes. This admits a new perspective that also avoids shortcomings of related interpretations based on variance adaptation and whitening: rather than enforcing semi-orthogonality as in spectral descent, Shampoo's updates are time-averaged semi-orthogonal in expectation.

</details>


### [44] [Effective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density](https://arxiv.org/abs/2602.09316)
*Zhendong Mi,Yixiao Chen,Pu Zhao,Xiaodong Yu,Hao Wang,Yanzhi Wang,Shaoyi Huang*

Main category: cs.LG

TL;DR: RFID-MoE：基于路由频率和信息密度的MoE压缩框架，通过自适应分配秩和稀疏投影机制，在保持性能的同时显著减少参数


<details>
  <summary>Details</summary>
Motivation: MoE大语言模型虽然性能优越，但存储多个专家网络导致巨大内存开销，阻碍实际部署。现有SVD压缩方法采用均匀秩分配或仅依赖静态权重特性，忽略了MoE模型中专家利用的显著异质性，即不同专家的路由频率和信息密度差异很大。

Method: 提出RFID-MoE框架：1）融合专家激活频率和有效秩来度量专家重要性，在固定预算下自适应地为关键专家组分配更高秩；2）通过参数高效的稀疏投影机制重构压缩残差，以最小参数开销恢复丢失信息。

Result: 在多个压缩比下对代表性MoE LLM（如Qwen3、DeepSeekMoE）的实验表明，RFID-MoE始终优于最先进方法。在60%压缩比下，Qwen3-30B模型在PTB上困惑度达到16.92，比基线降低超过8.0，在HellaSwag上的零样本准确率提高约8%。

Conclusion: RFID-MoE通过利用路由频率和信息密度的异质性，实现了高效的MoE模型压缩，在保持性能的同时显著减少内存开销，为MoE大语言模型的实际部署提供了有效解决方案。

Abstract: Mixture-of-Experts (MoE) based Large Language Models (LLMs) have achieved superior performance, yet the massive memory overhead caused by storing multiple expert networks severely hinders their practical deployment. Singular Value Decomposition (SVD)-based compression has emerged as a promising post-training technique; however, most existing methods apply uniform rank allocation or rely solely on static weight properties. This overlooks the substantial heterogeneity in expert utilization observed in MoE models, where frequent routing patterns and intrinsic information density vary significantly across experts. In this work, we propose RFID-MoE, an effective framework for MoE compression by exploiting heterogeneous Routing Frequency and Information Density. We first introduce a fused metric that combines expert activation frequency with effective rank to measure expert importance, adaptively allocating higher ranks to critical expert groups under a fixed budget. Moreover, instead of discarding compression residuals, we reconstruct them via a parameter-efficient sparse projection mechanism to recover lost information with minimal parameter overhead. Extensive experiments on representative MoE LLMs (e.g., Qwen3, DeepSeekMoE) across multiple compression ratios demonstrate that RFID-MoE consistently outperforms state-of-the-art methods like MoBE and D2-MoE. Notably, RFID-MoE achieves a perplexity of 16.92 on PTB with the Qwen3-30B model at a 60% compression ratio, reducing perplexity by over 8.0 compared to baselines, and improves zero-shot accuracy on HellaSwag by approximately 8%.

</details>


### [45] [SnareNet: Flexible Repair Layers for Neural Networks with Hard Constraints](https://arxiv.org/abs/2602.09317)
*Ya-Chi Chu,Alkiviades Boukas,Madeleine Udell*

Main category: cs.LG

TL;DR: SnareNet：一种可行性控制架构，通过可微修复层和自适应松弛技术，确保神经网络输出满足输入相关的非线性约束


<details>
  <summary>Details</summary>
Motivation: 神经网络作为替代求解器和控制策略时，无约束的预测可能违反物理、操作或安全要求。需要确保神经网络输出满足输入相关的非线性约束。

Method: 1. 添加可微修复层，在约束映射的范围内导航，迭代引导输出满足可行性；2. 引入自适应松弛技术，设计松弛可行集，在初始化时捕获神经网络，训练后期收缩到严格可行集。

Result: 在优化学习和轨迹规划基准测试中，SnareNet相比先前工作，在满足约束更可靠的同时，持续获得改进的目标质量。

Conclusion: SnareNet提供了一种有效的架构，能够可靠地生成满足输入相关约束的神经网络输出，在保持高质量目标的同时确保可行性。

Abstract: Neural networks are increasingly used as surrogate solvers and control policies, but unconstrained predictions can violate physical, operational, or safety requirements. We propose SnareNet, a feasibility-controlled architecture for learning mappings whose outputs must satisfy input-dependent nonlinear constraints. SnareNet appends a differentiable repair layer that navigates in the constraint map's range space, steering iterates toward feasibility and producing a repaired output that satisfies constraints to a user-specified tolerance. To stabilize end-to-end training, we introduce adaptive relaxation, which designs a relaxed feasible set that snares the neural network at initialization and shrinks it into the feasible set, enabling early exploration and strict feasibility later in training. On optimization-learning and trajectory planning benchmarks, SnareNet consistently attains improved objective quality while satisfying constraints more reliably than prior work.

</details>


### [46] [Priority-Aware Shapley Value](https://arxiv.org/abs/2602.09326)
*Kiljae Lee,Ziqi Liu,Weijing Tang,Yuan Zhang*

Main category: cs.LG

TL;DR: 提出了Priority-Aware Shapley Value (PASV)，在传统Shapley值的基础上加入了硬性优先级约束和软性贡献者特定权重，用于处理依赖关系和优先级调整。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值假设贡献者是可互换的，这在处理依赖关系（如重复/增强数据或因果特征顺序）或需要根据信任、风险等因素调整贡献时存在问题。

Method: 提出PASV方法，结合硬性优先级约束和软性贡献者特定权重；开发了高效的相邻交换Metropolis-Hastings采样器进行可扩展的蒙特卡洛估计；分析了极端优先级权重下的极限情况。

Result: 在数据估值（MNIST/CIFAR10）和特征归因（Census Income）实验中，PASV展示了更符合结构特征的分配结果，并通过"优先级扫描"实现了实用的敏感性分析。

Conclusion: PASV为处理贡献者依赖关系和优先级调整提供了通用框架，恢复了仅优先级和仅权重的Shapley变体作为特例，并由自然公理唯一刻画。

Abstract: Shapley values are widely used for model-agnostic data valuation and feature attribution, yet they implicitly assume contributors are interchangeable. This can be problematic when contributors are dependent (e.g., reused/augmented data or causal feature orderings) or when contributions should be adjusted by factors such as trust or risk. We propose Priority-Aware Shapley Value (PASV), which incorporates both hard precedence constraints and soft, contributor-specific priority weights. PASV is applicable to general precedence structures, recovers precedence-only and weight-only Shapley variants as special cases, and is uniquely characterized by natural axioms. We develop an efficient adjacent-swap Metropolis-Hastings sampler for scalable Monte Carlo estimation and analyze limiting regimes induced by extreme priority weights. Experiments on data valuation (MNIST/CIFAR10) and feature attribution (Census Income) demonstrate more structure-faithful allocations and a practical sensitivity analysis via our proposed "priority sweeping".

</details>


### [47] [In-Hospital Stroke Prediction from PPG-Derived Hemodynamic Features](https://arxiv.org/abs/2602.09328)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.LG

TL;DR: 利用住院期间连续监测的PPG数据，首次在大规模真实临床数据中验证了PPG信号在卒中发生前数小时具有预测价值，实现了从卒中后识别到主动生理监测的转变。


<details>
  <summary>Details</summary>
Motivation: 标准临床数据集中缺乏院前生理数据，限制了卒中的早期预测。患者通常在卒中发生后才就诊，使得连续监测信号（如PPG）的预测价值无法验证。

Method: 1) 聚焦住院期间发生卒中且已接受连续监测的罕见但关键患者队列；2) 使用LLM辅助数据挖掘流程从非结构化临床记录中提取精确的院内卒中发生时间戳，并进行医生验证；3) 从MIMIC-III和MC-MED数据库中识别高质量同步的卒中前PPG数据；4) 从PPG中提取血流动力学特征，使用ResNet-1D模型在多个预警时间窗口预测即将发生的卒中。

Result: 模型在MIMIC-III上，卒中发生前4、5、6小时的F1分数分别为0.7956、0.8759和0.9406；在MC-MED上（无需重新调参）分别达到0.9256、0.9595和0.9888。这是首次从真实世界临床数据中获得PPG在卒中发生前数小时包含预测信号的实证证据。

Conclusion: 被动获取的生理信号可以支持可靠的早期预警，支持从卒中后识别转向主动的、基于生理学的监测，这可能显著改善常规临床护理中的患者预后。

Abstract: The absence of pre-hospital physiological data in standard clinical datasets fundamentally constrains the early prediction of stroke, as patients typically present only after stroke has occurred, leaving the predictive value of continuous monitoring signals such as photoplethysmography (PPG) unvalidated. In this work, we overcome this limitation by focusing on a rare but clinically critical cohort - patients who suffered stroke during hospitalization while already under continuous monitoring - thereby enabling the first large-scale analysis of pre-stroke PPG waveforms aligned to verified onset times. Using MIMIC-III and MC-MED, we develop an LLM-assisted data mining pipeline to extract precise in-hospital stroke onset timestamps from unstructured clinical notes, followed by physician validation, identifying 176 patients (MIMIC) and 158 patients (MC-MED) with high-quality synchronized pre-onset PPG data, respectively. We then extract hemodynamic features from PPG and employ a ResNet-1D model to predict impending stroke across multiple early-warning horizons. The model achieves F1-scores of 0.7956, 0.8759, and 0.9406 at 4, 5, and 6 hours prior to onset on MIMIC-III, and, without re-tuning, reaches 0.9256, 0.9595, and 0.9888 on MC-MED for the same horizons. These results provide the first empirical evidence from real-world clinical data that PPG contains predictive signatures of stroke several hours before onset, demonstrating that passively acquired physiological signals can support reliable early warning, supporting a shift from post-event stroke recognition to proactive, physiology-based surveillance that may materially improve patient outcomes in routine clinical care.

</details>


### [48] [MacrOData: New Benchmarks of Thousands of Datasets for Tabular Outlier Detection](https://arxiv.org/abs/2602.09329)
*Xueying Ding,Simon Klüttermann,Haomin Wen,Yilong Chen,Leman Akoglu*

Main category: cs.LG

TL;DR: MacrOData是一个大规模表格异常检测基准套件，包含2446个数据集，旨在解决现有基准规模小、多样性不足的问题，提供更全面、统计稳健的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测基准（如AdBench）仅包含57个数据集，规模小、多样性有限，严重限制了评估的统计功效和公平性，无法准确跟踪科学进展和指导方法选择。

Method: 构建了三个精心策划的组件：OddBench（790个包含真实语义异常的数据集）、OvrBench（856个包含真实统计异常的数据集）和SynBench（800个合成生成的数据集，涵盖多样数据先验和异常类型）。

Result: MacrOData包含2446个数据集，提供了标准化训练/测试分割、公开/私有基准分区、语义元数据标注。通过广泛实验评估了经典、深度和基础模型，提供了详细的实证结果和实践指南。

Conclusion: MacrOData以其规模和多样性为表格异常检测方法提供了全面且统计稳健的评估框架，所有基准数据集已开源，并建立了公开可访问的排行榜，为未来研究提供参考。

Abstract: Quality benchmarks are essential for fairly and accurately tracking scientific progress and enabling practitioners to make informed methodological choices. Outlier detection (OD) on tabular data underpins numerous real-world applications, yet existing OD benchmarks remain limited. The prominent OD benchmark AdBench is the de facto standard in the literature, yet comprises only 57 datasets. In addition to other shortcomings discussed in this work, its small scale severely restricts diversity and statistical power. We introduce MacrOData, a large-scale benchmark suite for tabular OD comprising three carefully curated components: OddBench, with 790 datasets containing real-world semantic anomalies; OvrBench, with 856 datasets featuring real-world statistical outliers; and SynBench, with 800 synthetically generated datasets spanning diverse data priors and outlier archetypes. Owing to its scale and diversity, MacrOData enables comprehensive and statistically robust evaluation of tabular OD methods. Our benchmarks further satisfy several key desiderata: We provide standardized train/test splits for all datasets, public/private benchmark partitions with held-out test labels for the latter reserved toward an online leaderboard, and annotate our datasets with semantic metadata. We conduct extensive experiments across all benchmarks, evaluating a broad range of OD methods comprising classical, deep, and foundation models, over diverse hyperparameter configurations. We report detailed empirical findings, practical guidelines, as well as individual performances as references for future research. All benchmarks containing 2,446 datasets combined are open-sourced, along with a publicly accessible leaderboard hosted at https://huggingface.co/MacrOData-CMU.

</details>


### [49] [Large Language Models for Designing Participatory Budgeting Rules](https://arxiv.org/abs/2602.09349)
*Nguyen Thach,Xingchen Sha,Hau Chan*

Main category: cs.LG

TL;DR: 本文提出LLMRule框架，利用大语言模型结合进化搜索自动设计参与式预算分配规则，在600多个真实PB实例上验证了其优于人工设计规则的效果。


<details>
  <summary>Details</summary>
Motivation: 参与式预算(PB)规则设计需要在效用和公平性之间权衡，传统方法需要大量领域知识且难以优化两者平衡。大语言模型在算法设计方面的潜力为解决这一问题提供了新思路。

Method: 提出LLMRule框架，将大语言模型集成到进化搜索过程中，自动生成PB分配规则。该方法借鉴了经典背包问题算法设计，通过LLM生成候选规则，进化搜索优化规则性能。

Result: 在来自美国、加拿大、波兰和荷兰的600多个真实PB实例上测试，LLM生成的规则在整体效用方面普遍优于现有手工设计规则，同时保持相似的公平性水平。

Conclusion: LLMRule框架成功实现了参与式预算规则的自动化设计，证明了LLM在算法设计领域的应用潜力，为平衡效用和公平性的PB规则设计提供了有效解决方案。

Abstract: Participatory budgeting (PB) is a democratic paradigm for deciding the funding of public projects given the residents' preferences, which has been adopted in numerous cities across the world. The main focus of PB is designing rules, functions that return feasible budget allocations for a set of projects subject to some budget constraint. Designing PB rules that optimize both utility and fairness objectives based on agent preferences had been challenging due to the extensive domain knowledge required and the proven trade-off between the two notions. Recently, large language models (LLMs) have been increasingly employed for automated algorithmic design. Given the resemblance of PB rules to algorithms for classical knapsack problems, in this paper, we introduce a novel framework, named LLMRule, that addresses the limitations of existing works by incorporating LLMs into an evolutionary search procedure for automating the design of PB rules. Our experimental results, evaluated on more than 600 real-world PB instances obtained from the U.S., Canada, Poland, and the Netherlands with different representations of agent preferences, demonstrate that the LLM-generated rules generally outperform existing handcrafted rules in terms of overall utility while still maintaining a similar degree of fairness.

</details>


### [50] [Latent Poincaré Shaping for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.09375)
*Hanchen Xia,Baoyou Chen,Zelin Zang,Yutang Ge,Guojiang Zhao,Siyu Zhu*

Main category: cs.LG

TL;DR: LaPha是一种在庞加莱潜在空间中训练AlphaZero风格LLM代理的方法，通过双曲几何距离定义节点潜力，使用轻量级价值头实现自引导测试时扩展，显著提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统AlphaZero方法在欧几里得空间中搜索效率有限，而双曲空间（庞加莱球）的负曲率特性可以提供随半径指数增长的容量，更适合表示层次化搜索树结构。

Method: 在庞加莱潜在空间中构建搜索树，使用双曲测地线距离定义节点潜力并分配密集过程奖励，同时在同一共享潜在空间上附加轻量级价值头，实现几乎无额外开销的自引导测试时扩展。

Result: 在MATH-500上，LaPha将Qwen2.5-Math-1.5B从66.0%提升到88.2%；在AIME'24上，LaPha-1.5B达到56.7%准确率，LaPha-7B达到60.0%；在AIME'25上，LaPha-7B达到53.3%准确率。

Conclusion: LaPha通过在双曲潜在空间中训练AlphaZero风格LLM代理，有效提升了数学推理能力，证明了双曲几何在增强LLM搜索和推理方面的潜力。

Abstract: We propose LaPha, a method for training AlphaZero-like LLM agents in a Poincaré latent space. Under LaPha, the search process can be visualized as a tree rooted at the prompt and growing outward from the origin toward the boundary of the Poincaré ball, where negative curvature provides exponentially increasing capacity with radius. Using hyperbolic geodesic distance to rule-verified correctness, we define a node potential and assign dense process rewards by potential differences. We further attach a lightweight value head on the same shared latent space, enabling self-guided test-time scaling with almost no additional overhead. On MATH-500, LaPha improves Qwen2.5-Math-1.5B from 66.0% to 88.2%. With value-head-guided search, LaPha-1.5B reaches 56.7% accuracy on AIME'24, and LaPha-7B further achieves 60.0% on AIME'24 and 53.3% on AIME'25.

</details>


### [51] [Sparse Layer Sharpness-Aware Minimization for Efficient Fine-Tuning](https://arxiv.org/abs/2602.09395)
*Yifei Cheng,Xianglin Yang,Guoxia Wang,Chao Huang,Fei Ma,Dianhai Yu,Xiaochun Cao,Li Shen*

Main category: cs.LG

TL;DR: SL-SAM：通过层稀疏化技术减少SAM计算开销，将层选择建模为多臂老虎机问题，在保持性能的同时显著降低反向传播中的活跃参数比例。


<details>
  <summary>Details</summary>
Motivation: SAM（锐度感知最小化）通过寻找平坦损失景观来提升泛化性能，但其额外的参数扰动步骤使计算成本翻倍，成为实际应用中的瓶颈。

Method: 提出SL-SAM，将层稀疏化技术引入SAM。将梯度上升（扰动）和下降（更新）步骤中的层动态选择建模为多臂老虎机问题，每轮迭代根据梯度范数采样部分层参与反向传播，减少计算复杂度。

Result: 在多个任务的模型微调实验中，SL-SAM达到与最先进基线相当的性能（包括LLM微调排名第一）。同时显著降低反向传播中的活跃参数比例（视觉模型47%，中等模型22%，大语言模型21%，而原始SAM始终为100%）。

Conclusion: SL-SAM通过层稀疏化技术有效解决了SAM的计算瓶颈问题，在保持性能的同时大幅提升计算效率，为SAM的实际应用提供了可行的解决方案。

Abstract: Sharpness-aware minimization (SAM) seeks the minima with a flat loss landscape to improve the generalization performance in machine learning tasks, including fine-tuning. However, its extra parameter perturbation step doubles the computation cost, which becomes the bottleneck of SAM in the practical implementation. In this work, we propose an approach SL-SAM to break this bottleneck by introducing the sparse technique to layers. Our key innovation is to frame the dynamic selection of layers for both the gradient ascent (perturbation) and descent (update) steps as a multi-armed bandit problem. At the beginning of each iteration, SL-SAM samples a part of the layers of the model according to the gradient norm to participate in the backpropagation of the following parameter perturbation and update steps, thereby reducing the computation complexity. We then provide the analysis to guarantee the convergence of SL-SAM. In the experiments of fine-tuning models in several tasks, SL-SAM achieves the performances comparable to the state-of-the-art baselines, including a \#1 rank on LLM fine-tuning. Meanwhile, SL-SAM significantly reduces the ratio of active parameters in backpropagation compared to vanilla SAM (SL-SAM activates 47\%, 22\% and 21\% parameters on the vision, moderate and large language model respectively while vanilla SAM always activates 100\%), verifying the efficiency of our proposed algorithm.

</details>


### [52] [Squeezing More from the Stream : Learning Representation Online for Streaming Reinforcement Learning](https://arxiv.org/abs/2602.09396)
*Nilaksh,Antoine Clavaud,Mathieu Reymond,François Rivest,Sarath Chandar*

Main category: cs.LG

TL;DR: 将自预测表示(SPR)扩展到流式强化学习，通过正交梯度更新解决训练不稳定问题，在多个基准测试中显著超越现有流式基线


<details>
  <summary>Details</summary>
Motivation: 流式强化学习中，数据在单次更新后立即丢弃，导致样本效率低下。值函数损失难以从瞬态数据中提取有意义的表示，需要最大化每个观察帧的效用

Method: 将自预测表示(SPR)扩展到流式管道，引入相对于动量目标的正交梯度更新，解决流式特定优化器引起的梯度冲突问题

Result: 在Atari、MinAtar和Octax套件中系统性地超越现有流式基线。潜在空间分析（t-SNE可视化和有效秩测量）证实方法学习到更丰富的表示

Conclusion: 该方法弥补了因缺少回放缓冲区造成的性能差距，同时保持足够高效，仅需少量CPU核心即可训练，显著提升了流式强化学习的样本效率

Abstract: In streaming Reinforcement Learning (RL), transitions are observed and discarded immediately after a single update. While this minimizes resource usage for on-device applications, it makes agents notoriously sample-inefficient, since value-based losses alone struggle to extract meaningful representations from transient data. We propose extending Self-Predictive Representations (SPR) to the streaming pipeline to maximize the utility of every observed frame. However, due to the highly correlated samples induced by the streaming regime, naively applying this auxiliary loss results in training instabilities. Thus, we introduce orthogonal gradient updates relative to the momentum target and resolve gradient conflicts arising from streaming-specific optimizers. Validated across the Atari, MinAtar, and Octax suites, our approach systematically outperforms existing streaming baselines. Latent-space analysis, including t-SNE visualizations and effective-rank measurements, confirms that our method learns significantly richer representations, bridging the performance gap caused by the absence of a replay buffer, while remaining efficient enough to train on just a few CPU cores.

</details>


### [53] [Learning with Multiple Correct Answers -- A Trichotomy of Regret Bounds under Different Feedback Models](https://arxiv.org/abs/2602.09402)
*Alireza F. Pour,Farnam Mansouri,Shai Ben-David*

Main category: cs.LG

TL;DR: 研究多正确答案的在线学习问题，每个实例有多个有效标签，学习者每轮必须为查询示例输出有效标签。该设置受语言生成任务启发，其中提示可能有多个可接受补全，但并非所有补全都可接受。


<details>
  <summary>Details</summary>
Motivation: 动机源于语言生成任务，其中提示可能有多个可接受的补全（如不同但合理的句子续写），但并非所有补全都可接受。传统在线学习通常假设单一正确答案，而实际应用中存在多个有效答案的情况需要新的理论框架。

Method: 研究三种反馈模型下的问题：1）在可实现设置中，使用适当的组合维度来表征最优错误界限；2）在不可知设置中，建立三种模型之间的遗憾界限三分法；3）推导批量设置中依赖于相应组合维度的样本复杂度界限。

Result: 1）在可实现设置中，为每个反馈模型找到了最优错误界限，并用组合维度表征；2）在不可知设置中，建立了三种模型之间的遗憾界限三分法；3）推导了批量设置的样本复杂度界限，这些界限依赖于相应的组合维度。

Conclusion: 该研究为多正确答案的在线学习问题提供了系统的理论分析框架，通过组合维度表征了不同反馈模型下的性能界限，为语言生成等实际应用中的学习问题提供了理论基础。

Abstract: We study an online learning problem with multiple correct answers, where each instance admits a set of valid labels, and in each round the learner must output a valid label for the queried example. This setting is motivated by language generation tasks, in which a prompt may admit many acceptable completions, but not every completion is acceptable. We study this problem under three feedback models. For each model, we characterize the optimal mistake bound in the realizable setting using an appropriate combinatorial dimension. We then establish a trichotomy of regret bounds across the three models in the agnostic setting. Our results also imply sample complexity bounds for the batch setup that depend on the respective combinatorial dimensions.

</details>


### [54] [Effectiveness of Binary Autoencoders for QUBO-Based Optimization Problems](https://arxiv.org/abs/2602.10037)
*Tetsuro Abe,Masashi Yamashita,Shu Tanaka*

Main category: cs.LG

TL;DR: 本文研究黑盒组合优化中二进制编码对搜索效率的影响，提出使用二进制自编码器学习紧凑的潜在表示，以改善FMQA算法的性能。


<details>
  <summary>Details</summary>
Motivation: 在黑盒组合优化中，目标函数评估成本高昂，需要在有限预算内找到高质量解。FMQA方法需要二进制决策变量，但对于非二进制结构（如整数排列），二进制编码的选择会严重影响搜索效率。如果编码不能反映原始邻域结构，小的汉明移动可能不对应于原始解空间中有意义的修改，并且约束问题可能产生许多不可行候选解，浪费评估资源。

Method: 使用二进制自编码器（bAE）从可行解中学习紧凑的二进制潜在编码，结合FMQA方法。通过小型旅行商问题作为可解释的测试平台，分析bAE如何准确重建可行路径，并与手动设计的编码进行比较。

Result: bAE相比类似压缩率的手动设计编码，能更好地对齐路径距离与潜在汉明距离，在小比特翻转下产生更平滑的邻域，并产生更少的局部最优解。这些几何特性解释了为什么bAE+FMQA能更快地提高近似比，同时在优化过程中保持可行性。

Conclusion: 二进制自编码器学习的潜在表示改善了FMQA在黑盒组合优化中的性能，其几何特性为设计黑盒优化的潜在表示提供了指导。

Abstract: In black-box combinatorial optimization, objective evaluations are often expensive, so high quality solutions must be found under a limited budget. Factorization machine with quantum annealing (FMQA) builds a quadratic surrogate model from evaluated samples and optimizes it on an Ising machine. However, FMQA requires binary decision variables, and for nonbinary structures such as integer permutations, the choice of binary encoding strongly affects search efficiency. If the encoding fails to reflect the original neighborhood structure, small Hamming moves may not correspond to meaningful modifications in the original solution space, and constrained problems can yield many infeasible candidates that waste evaluations. Recent work combines FMQA with a binary autoencoder (bAE) that learns a compact binary latent code from feasible solutions, yet the mechanism behind its performance gains is unclear. Using a small traveling salesman problem as an interpretable testbed, we show that the bAE reconstructs feasible tours accurately and, compared with manually designed encodings at similar compression, better aligns tour distances with latent Hamming distances, yields smoother neighborhoods under small bit flips, and produces fewer local optima. These geometric properties explain why bAE+FMQA improves the approximation ratio faster while maintaining feasibility throughout optimization, and they provide guidance for designing latent representations for black-box optimization.

</details>


### [55] [Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design](https://arxiv.org/abs/2602.09424)
*Prin Phunyaphibarn,Minhyuk Sung*

Main category: cs.LG

TL;DR: 提出CSMC采样器，用于离散扩散模型的奖励引导采样，避免使用噪声中间奖励，通过构建清洁样本的马尔可夫链实现有效局部搜索


<details>
  <summary>Details</summary>
Motivation: 在化学和生物学数据生成中，需要生成具有高奖励的样本（如药物相似性）。现有方法依赖中间奖励进行引导，但由于科学领域奖励函数的非平滑特性，中间奖励噪声大，导致性能不佳

Method: 提出清洁样本马尔可夫链（CSMC）采样器，使用Metropolis-Hastings算法构建清洁样本的马尔可夫链，使其平稳分布为目标分布。通过顺序应用前向和后向扩散过程设计提议分布，使接受概率可计算

Result: 在分子和生物序列生成任务中，使用多种奖励函数进行实验，CSMC方法始终优于依赖中间奖励的先前方法

Conclusion: CSMC采样器为离散扩散模型提供了有效的测试时奖励引导采样方法，避免了中间奖励的噪声问题，在科学数据生成任务中表现出优越性能

Abstract: Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards.

</details>


### [56] [Diffusion-Guided Pretraining for Brain Graph Foundation Models](https://arxiv.org/abs/2602.09437)
*Xinxu Wei,Rong Zhou,Lifang He,Yu Zhang*

Main category: cs.LG

TL;DR: 提出统一的扩散式预训练框架，通过结构感知的丢弃/掩码策略和拓扑感知的图级读出/节点级全局重建，解决脑图预训练中的语义破坏和全局结构信息缺失问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比学习和掩码自编码器的脑图预训练方法存在两个主要问题：1）使用随机丢弃或掩码会破坏脑图中有语义意义的连接模式；2）常用的图级读出和重建方案无法捕获全局结构信息，限制了学习表示的鲁棒性。

Method: 提出统一的扩散式预训练框架：1）利用扩散过程指导结构感知的丢弃和掩码策略，在保持脑图语义的同时维持预训练多样性；2）通过扩散实现拓扑感知的图级读出和节点级全局重建，使图嵌入和掩码节点能从全局相关区域聚合信息。

Result: 在包含超过25,000名受试者和60,000次扫描的多个神经影像数据集上进行广泛实验，涉及多种精神障碍和脑图谱，结果显示该方法带来了持续的性能提升。

Conclusion: 提出的扩散式预训练框架有效解决了脑图预训练中的关键限制，通过结构感知的增强策略和全局信息聚合机制，显著提升了学习表示的鲁棒性和可迁移性。

Abstract: With the growing interest in foundation models for brain signals, graph-based pretraining has emerged as a promising paradigm for learning transferable representations from connectome data. However, existing contrastive and masked autoencoder methods typically rely on naive random dropping or masking for augmentation, which is ill-suited for brain graphs and hypergraphs as it disrupts semantically meaningful connectivity patterns. Moreover, commonly used graph-level readout and reconstruction schemes fail to capture global structural information, limiting the robustness of learned representations. In this work, we propose a unified diffusion-based pretraining framework that addresses both limitations. First, diffusion is designed to guide structure-aware dropping and masking strategies, preserving brain graph semantics while maintaining effective pretraining diversity. Second, diffusion enables topology-aware graph-level readout and node-level global reconstruction by allowing graph embeddings and masked nodes to aggregate information from globally related regions. Extensive experiments across multiple neuroimaging datasets with over 25,000 subjects and 60,000 scans involving various mental disorders and brain atlases demonstrate consistent performance improvements.

</details>


### [57] [Taming the Monster Every Context: Complexity Measure and Unified Framework for Offline-Oracle Efficient Contextual Bandits](https://arxiv.org/abs/2602.09456)
*Hao Qin,Chicheng Zhang*

Main category: cs.LG

TL;DR: 提出OE2D框架，将上下文赌博机问题简化为离线回归，通过O(log(T))次离线回归调用实现接近最优的遗憾


<details>
  <summary>Details</summary>
Motivation: 解决具有大动作空间的上下文赌博机问题，减少对在线回归的依赖，通过离线回归实现高效学习

Method: 设计OE2D算法框架，采用"exploitative F-design"动作分布，平衡探索与利用，定义新的复杂度度量DOEC

Result: 在T轮中仅需O(log(T))次离线回归调用，当T已知时仅需O(loglog(T))次，在有限Eluder维度和平滑遗憾设置下DOEC有界

Conclusion: OE2D框架成功将上下文赌博机学习简化为离线回归，建立了DOEC与DEC的联系，统一了离线与在线高效算法的设计原则

Abstract: We propose an algorithmic framework, Offline Estimation to Decisions (OE2D), that reduces contextual bandit learning with general reward function approximation to offline regression. The framework allows near-optimal regret for contextual bandits with large action spaces with $O(log(T))$ calls to an offline regression oracle over $T$ rounds, and makes $O(loglog(T))$ calls when $T$ is known. The design of OE2D algorithm generalizes Falcon~\citep{simchi2022bypassing} and its linear reward version~\citep[][Section 4]{xu2020upper} in that it chooses an action distribution that we term ``exploitative F-design'' that simultaneously guarantees low regret and good coverage that trades off exploration and exploitation. Central to our regret analysis is a new complexity measure, the Decision-Offline Estimation Coefficient (DOEC), which we show is bounded in bounded Eluder dimension per-context and smoothed regret settings. We also establish a relationship between DOEC and Decision Estimation Coefficient (DEC)~\citep{foster2021statistical}, bridging the design principles of offline- and online-oracle efficient contextual bandit algorithms for the first time.

</details>


### [58] [Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies](https://arxiv.org/abs/2602.09461)
*Lihao Mai,Chenhan Xiao,Yang Weng*

Main category: cs.LG

TL;DR: 提出基于条件扩散模型和图神经网络的N-k故障推断框架，无需枚举组合空间即可生成高风险故障场景，并提供可控覆盖保证，显著降低计算负担。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器资源渗透率提高、柔性负荷增加和运行条件快速变化，高阶N-k故障评估变得日益重要但计算成本过高。传统枚举方法不可行，启发式筛选方法无法保证捕获所有关键故障，需要可扩展的解决方案。

Method: 1) 使用条件扩散模型根据当前运行状态生成候选故障场景；2) 仅基于基态和N-1故障训练拓扑感知图神经网络，离线构建高风险训练样本；3) 提供可控覆盖保证机制，在有限AC潮流评估预算下管理风险。

Result: 在IEEE基准系统上的实验表明，在相同评估预算下，该方法比均匀采样能持续评估更高严重性的故障，以更少的计算量更可靠地识别关键故障。

Conclusion: 该框架为N-k故障评估提供了可扩展的解决方案，通过智能生成高风险故障场景而非枚举组合空间，显著降低计算负担，同时提供可控的风险覆盖保证，适用于实际运行环境。

Abstract: Increasing penetration of inverter-based resources, flexible loads, and rapidly changing operating conditions make higher-order $N\!-\!k$ contingency assessment increasingly important but computationally prohibitive. Exhaustive evaluation of all outage combinations using AC power-flow or ACOPF is infeasible in routine operation. This fact forces operators to rely on heuristic screening methods whose ability to consistently retain all critical contingencies is not formally established. This paper proposes a scalable, state-aware contingency inference framework designed to directly generate high-impact $N\!-\!k$ outage scenarios without enumerating the combinatorial contingency space. The framework employs a conditional diffusion model to produce candidate contingencies tailored to the current operating state, while a topology-aware graph neural network trained only on base and $N\!-\!1$ cases efficiently constructs high-risk training samples offline. Finally, the framework is developed to provide controllable coverage guarantees for severe contingencies, allowing operators to explicitly manage the risk of missing critical events under limited AC power-flow evaluation budgets. Experiments on IEEE benchmark systems show that, for a given evaluation budget, the proposed approach consistently evaluates higher-severity contingencies than uniform sampling. This allows critical outages to be identified more reliably with reduced computational effort.

</details>


### [59] [Online Learning in MDPs with Partially Adversarial Transitions and Losses](https://arxiv.org/abs/2602.09474)
*Ofir Schlisselberg,Tal Lancewicki,Yishay Mansour*

Main category: cs.LG

TL;DR: 研究在大多数步骤随机但最多有Λ个步骤可能对抗的MDP中的强化学习，提出两种算法处理对抗性步骤，并分析完全对抗设置下的遗憾边界。


<details>
  <summary>Details</summary>
Motivation: 现实环境中大多数时候是稳定的，但可能存在少数脆弱点表现出对抗性行为。现有RL算法假设完全随机或完全对抗，无法有效处理这种混合设置。

Method: 引入条件占用度量，即使在对抗性转移下也能保持稳定。提出两种算法：第一种处理任意对抗步骤，第二种假设对抗步骤连续以改进对状态数的依赖。还提出无需知道对抗步骤位置的K^{2/3}遗憾减少方法。

Result: 第一种算法遗憾为Õ(H S^Λ√(K S A^{Λ+1}))，第二种算法（对抗步骤连续）遗憾为Õ(H√(K S^3 A^{Λ+1}))。在完全对抗设置下，给出了全信息和bandit反馈的几乎匹配的上下界。

Conclusion: 该研究为混合随机-对抗MDP提供了理论框架和算法，填补了完全随机和完全对抗设置之间的空白，并阐明了不同反馈结构对学习难度的影响。

Abstract: We study reinforcement learning in MDPs whose transition function is stochastic at most steps but may behave adversarially at a fixed subset of $Λ$ steps per episode. This model captures environments that are stable except at a few vulnerable points. We introduce \emph{conditioned occupancy measures}, which remain stable across episodes even with adversarial transitions, and use them to design two algorithms. The first handles arbitrary adversarial steps and achieves regret $\tilde{O}(H S^Λ\sqrt{K S A^{Λ+1}})$, where $K$ is the number of episodes, $S$ is the number of state, $A$ is the number of actions and $H$ is the episode's horizon. The second, assuming the adversarial steps are consecutive, improves the dependence on $S$ to $\tilde{O}(H\sqrt{K S^{3} A^{Λ+1}})$. We further give a $K^{2/3}$-regret reduction that removes the need to know which steps are the $Λ$ adversarial steps. We also characterize the regret of adversarial MDPs in the \emph{fully adversarial} setting ($Λ=H-1$) both for full-information and bandit feedback, and provide almost matching upper and lower bounds (slightly strengthen existing lower bounds, and clarify how different feedback structures affect the hardness of learning).

</details>


### [60] [Adaptive recurrent flow map operator learning for reaction diffusion dynamics](https://arxiv.org/abs/2602.09487)
*Huseyin Tunc*

Main category: cs.LG

TL;DR: 提出DDOL-ART方法，通过自适应循环训练学习反应-扩散方程的稳定算子，无需物理残差约束，实现长时稳定预测和零样本泛化


<details>
  <summary>Details</summary>
Motivation: 传统神经算子自回归预测存在误差累积漂移问题，物理约束方法引入额外假设和计算成本，需要纯数据驱动的稳定算子学习方法

Method: 开发DDOL-ART方法，采用鲁棒循环策略和轻量验证里程碑，提前退出无效滚动段并重定向优化，仅用短时数据训练单步算子

Result: 在FitzHugh-Nagumo、Gray-Scott和Lambda-Omega系统上实现零样本泛化，比物理约束方法快数倍，保持竞争性的稳定性和鲁棒性

Conclusion: 反馈控制的循环训练能生成鲁棒的流映射替代模型，无需PDE残差，显著降低训练成本的同时保持与物理约束方法相当的竞争力

Abstract: Reaction-diffusion (RD) equations underpin pattern formation across chemistry, biology, and physics, yet learning stable operators that forecast their long-term dynamics from data remains challenging. Neural-operator surrogates provide resolution-robust prediction, but autoregressive rollouts can drift due to the accumulation of error, and out-of-distribution (OOD) initial conditions often degrade accuracy. Physics-based numerical residual objectives can regularize operator learning, although they introduce additional assumptions, sensitivity to discretization and loss design, and higher training cost. Here we develop a purely data-driven operator learner with adaptive recurrent training (DDOL-ART) using a robust recurrent strategy with lightweight validation milestones that early-exit unproductive rollout segments and redirect optimization. Trained only on a single in-distribution toroidal Gaussian family over short horizons, DDOL-ART learns one-step operators that remain stable under long rollouts and generalize zero-shot to strong morphology shifts across FitzHugh-Nagumo (FN), Gray-Scott (GS), and Lambda-Omega (LO) systems. Across these benchmarks, DDOL-ART delivers a strong accuracy and cost trade-off. It is several-fold faster than a physics-based numerical-loss operator learner (NLOL) under matched settings, and it remains competitive on both in-distribution stability and OOD robustness. Training-dynamics diagnostics show that adaptivity strengthens the correlation between validation error and OOD test error performance, acting as a feedback controller that limits optimization drift. Our results indicate that feedback-controlled recurrent training of DDOL-ART generates robust flow-map surrogates without PDE residuals, while simultaneously maintaining competitiveness with NLOL at significantly reduced training costs.

</details>


### [61] [Beware of the Batch Size: Hyperparameter Bias in Evaluating LoRA](https://arxiv.org/abs/2602.09492)
*Sangyoon Lee,Jaeho Lee*

Main category: cs.LG

TL;DR: 研究发现LoRA变体性能矛盾源于批量大小的忽视，适当调整后普通LoRA常能匹配复杂变体表现，批量大小应成为首要设计参数而非次要实现细节。


<details>
  <summary>Details</summary>
Motivation: 低秩适应（LoRA）是微调大语言模型的标准方法，但其众多变体在相同基准测试中报告了相互矛盾的实证增益。本研究旨在揭示这些矛盾的根本原因。

Method: 通过系统实验分析批量大小对LoRA性能的影响，提出基于代理的成本高效批量大小调优策略，并研究秩、数据集大小和模型容量对最优批量大小的影响。

Result: 研究发现批量大小是导致LoRA变体性能矛盾的关键因素，当适当调优时，普通LoRA通常能匹配更复杂变体的性能。批量大小应被视为首要设计参数而非次要实现细节。

Conclusion: 批量大小是影响LoRA性能的关键因素，应作为首要设计参数考虑。研究提出的调优策略能帮助更可靠地评估LoRA变体，调和先前的不一致性。

Abstract: Low-rank adaptation (LoRA) is a standard approach for fine-tuning large language models, yet its many variants report conflicting empirical gains, often on the same benchmarks. We show that these contradictions arise from a single overlooked factor: the batch size. When properly tuned, vanilla LoRA often matches the performance of more complex variants. We further propose a proxy-based, cost-efficient strategy for batch size tuning, revealing the impact of rank, dataset size, and model capacity on the optimal batch size. Our findings elevate batch size from a minor implementation detail to a first-order design parameter, reconciling prior inconsistencies and enabling more reliable evaluations of LoRA variants.

</details>


### [62] [Computationally Efficient Replicable Learning of Parities](https://arxiv.org/abs/2602.09499)
*Moshe Noivirt,Jessica Sorrell,Eliad Tsfadia*

Main category: cs.LG

TL;DR: 本文研究了可复制学习与差分隐私、统计查询模型之间的计算关系，首次提出了针对任意分布上奇偶性概念的高效可复制学习算法，突破了SQ模型的限制。


<details>
  <summary>Details</summary>
Motivation: 虽然统计上已知差分隐私学习和可复制学习是等价的，并且比SQ学习更强大，但计算上所有已知的高效可复制学习算法都局限于SQ可学习任务或受限分布。本文旨在探索高效可复制学习是否能在计算上超越SQ学习，更接近差分隐私学习的能力。

Method: 主要贡献是提出了第一个计算高效的可复制算法，用于在任意分布上实现奇偶性概念的学习。核心构建模块是一个新的高效可复制算法，给定一组向量，输出覆盖其中大多数向量的线性子空间。

Result: 成功实现了针对任意分布上奇偶性概念的高效可复制学习，这是SQ模型中已知困难但差分隐私下可能完成的任务。这首次证明了高效可复制学习在一般分布上严格扩展了高效SQ学习的能力。

Conclusion: 高效可复制学习在计算能力上比高效SQ学习更强大，更接近高效差分隐私学习，尽管可复制性和隐私性之间存在计算分离。这为可复制学习与稳定性概念之间的计算关系提供了新的见解。

Abstract: We study the computational relationship between replicability (Impagliazzo et al. [STOC `22], Ghazi et al. [NeurIPS `21]) and other stability notions. Specifically, we focus on replicable PAC learning and its connections to differential privacy (Dwork et al. [TCC 2006]) and to the statistical query (SQ) model (Kearns [JACM `98]). Statistically, it was known that differentially private learning and replicable learning are equivalent and strictly more powerful than SQ-learning. Yet, computationally, all previously known efficient (i.e., polynomial-time) replicable learning algorithms were confined to SQ-learnable tasks or restricted distributions, in contrast to differentially private learning.
  Our main contribution is the first computationally efficient replicable algorithm for realizable learning of parities over arbitrary distributions, a task that is known to be hard in the SQ-model, but possible under differential privacy. This result provides the first evidence that efficient replicable learning over general distributions strictly extends efficient SQ-learning, and is closer in power to efficient differentially private learning, despite computational separations between replicability and privacy. Our main building block is a new, efficient, and replicable algorithm that, given a set of vectors, outputs a subspace of their linear span that covers most of them.

</details>


### [63] [Improved Approximate Regret for Decentralized Online Continuous Submodular Maximization via Reductions](https://arxiv.org/abs/2602.09502)
*Yuanyu Wan,Yu Shen,Dingzhi Yu,Bo Xue,Mingli Song*

Main category: cs.LG

TL;DR: 本文提出两种从去中心化在线连续次模最大化到去中心化在线凸优化的归约方法，显著改善了现有算法的近似遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化在线连续次模最大化算法存在两个问题：1) 近似遗憾界与凸设置下的遗憾界存在较大差距；2) 无投影算法无法达到集中式设置的近似遗憾界。本文旨在同时解决这两个问题。

Method: 提出两种归约方法：1) 针对一般凸决策集，将D-OCSM归约到D-OCO；2) 针对向下封闭决策集，将D-OCSM归约到D-OCO。利用D-OCO算法来改进D-OCSM的近似遗憾。

Result: 对于一般凸决策集，同时解决了上述两个问题；对于向下封闭决策集，解决了第二个问题并显著缓解了第一个问题。

Conclusion: 通过将D-OCSM归约到D-OCO，本文显著改善了去中心化在线连续次模最大化的近似遗憾界，填补了与凸设置之间的性能差距。

Abstract: To expand the applicability of decentralized online learning, previous studies have proposed several algorithms for decentralized online continuous submodular maximization (D-OCSM) -- a non-convex/non-concave setting with continuous DR-submodular reward functions. However, there exist large gaps between their approximate regret bounds and the regret bounds achieved in the convex setting. Moreover, if focusing on projection-free algorithms, which can efficiently handle complex decision sets, they cannot even recover the approximate regret bounds achieved in the centralized setting. In this paper, we first demonstrate that for D-OCSM over general convex decision sets, these two issues can be addressed simultaneously. Furthermore, for D-OCSM over downward-closed decision sets, we show that the second issue can be addressed while significantly alleviating the first issue. Our key techniques are two reductions from D-OCSM to decentralized online convex optimization (D-OCO), which can exploit D-OCO algorithms to improve the approximate regret of D-OCSM in these two cases, respectively.

</details>


### [64] [Towards Uniformity and Alignment for Multimodal Representation Learning](https://arxiv.org/abs/2602.09507)
*Wenzhe Yin,Pan Zhou,Zehao Xiao,Jie Liu,Shujian Yu,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.LG

TL;DR: 该论文提出了一种解耦对齐和均匀性的多模态表示学习方法，解决了InfoNCE目标中固有的对齐-均匀性冲突和内部对齐冲突，减少了模态间的分布差距。


<details>
  <summary>Details</summary>
Motivation: 多模态表示学习旨在构建异构模态语义对齐的共享嵌入空间。尽管InfoNCE目标取得了良好的经验结果，但它引入了固有的冲突，导致模态间存在分布差距。随着模态数量增加，两种冲突加剧：(1)对齐-均匀性冲突：均匀性的排斥力破坏成对对齐；(2)内部对齐冲突：对齐多个模态会产生竞争性的对齐方向。

Method: 提出了一种原则性的多模态表示对齐和均匀性解耦方法。该方法为多模态学习提供了无冲突的解决方案，同时支持判别性和生成性用例，无需特定任务模块。理论证明该方法可作为多个模态分布全局Hölder散度的有效代理，从而减少模态间的分布差距。

Result: 在检索和UnCLIP风格生成任务上的大量实验表明，该方法取得了持续的性能提升。

Conclusion: 通过解耦对齐和均匀性，提出了一种有效的多模态表示学习方法，解决了InfoNCE目标中的固有冲突，减少了模态间分布差距，在多种任务上表现出色。

Abstract: Multimodal representation learning aims to construct a shared embedding space in which heterogeneous modalities are semantically aligned. Despite strong empirical results, InfoNCE-based objectives introduce inherent conflicts that yield distribution gaps across modalities. In this work, we identify two conflicts in the multimodal regime, both exacerbated as the number of modalities increases: (i) an alignment-uniformity conflict, whereby the repulsion of uniformity undermines pairwise alignment, and (ii) an intra-alignment conflict, where aligning multiple modalities induces competing alignment directions. To address these issues, we propose a principled decoupling of alignment and uniformity for multimodal representations, providing a conflict-free recipe for multimodal learning that simultaneously supports discriminative and generative use cases without task-specific modules. We then provide a theoretical guarantee that our method acts as an efficient proxy for a global Hölder divergence over multiple modality distributions, and thus reduces the distribution gap among modalities. Extensive experiments on retrieval and UnCLIP-style generation demonstrate consistent gains.

</details>


### [65] [Beyond Student: An Asymmetric Network for Neural Network Inheritance](https://arxiv.org/abs/2602.09509)
*Yiyun Zhou,Jingwei Shi,Mingjing Xu,Zhonghua Jiang,Jingyuan Chen*

Main category: cs.LG

TL;DR: 提出InherNet方法，通过非对称低秩分解教师网络权重，重构轻量级网络，在继承教师结构的同时最大化知识继承，性能优于传统知识蒸馏的学生网络。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏存在容量差距限制学生网络性能，需要探索既能继承教师网络结构又能最大化知识继承的网络类型，并比较其与传统学生网络的性能差异。

Method: 提出InherNet方法：对教师网络权重进行非对称低秩分解，使用奇异值分解初始化以确保继承主要知识，重构轻量级网络而不显著破坏架构，平衡深度、宽度和压缩效率。

Result: 在单模态和多模态任务上的实验结果表明，InherNet在相似参数量下比传统知识蒸馏的学生网络获得更高性能。

Conclusion: InherNet为超越传统蒸馏的高效模型压缩提供了有前景的研究方向，通过继承教师网络结构和知识实现更好的性能表现。

Abstract: Knowledge Distillation (KD) has emerged as a powerful technique for model compression, enabling lightweight student networks to benefit from the performance of redundant teacher networks. However, the inherent capacity gap often limits the performance of student networks. Inspired by the expressiveness of pretrained teacher networks, a compelling research question arises: is there a type of network that can not only inherit the teacher's structure but also maximize the inheritance of its knowledge? Furthermore, how does the performance of such an inheriting network compare to that of student networks, all benefiting from the same teacher network? To further explore this question, we propose InherNet, a neural network inheritance method that performs asymmetric low-rank decomposition on the teacher's weights and reconstructs a lightweight yet expressive network without significant architectural disruption. By leveraging Singular Value Decomposition (SVD) for initialization to ensure the inheritance of principal knowledge, InherNet effectively balances depth, width, and compression efficiency. Experimental results across unimodal and multimodal tasks demonstrate that InherNet achieves higher performance compared to student networks of similar parameter sizes. Our findings reveal a promising direction for future research in efficient model compression beyond traditional distillation.

</details>


### [66] [Rashomon Sets and Model Multiplicity in Federated Learning](https://arxiv.org/abs/2602.09520)
*Xenia Heilmann,Luca Corbucci,Mattia Cerrato*

Main category: cs.LG

TL;DR: 首次将Rashomon集合概念引入联邦学习，提出三种联邦Rashomon集合定义，并开发了隐私保护的多重性度量方法


<details>
  <summary>Details</summary>
Motivation: 现有Rashomon集合和多重性度量定义假设集中式学习，无法自然扩展到联邦学习等去中心化多参与方设置。在联邦学习中，选择单一最佳模型可能同质化不同客户端的预测行为、放大偏见或破坏公平性保证

Method: 1) 将Rashomon集合定义适配到联邦学习，提出三种视角：全局Rashomon集合、t-协议Rashomon集合和个体Rashomon集合；2) 展示如何在联邦学习的隐私约束下估计标准多重性度量；3) 引入多重性感知的联邦学习流程

Result: 在标准联邦学习基准数据集上的实证研究表明，所有三种提出的联邦Rashomon集合定义都能提供有价值的见解，使客户端能够部署更符合其本地数据、公平性考虑和实际需求的模型

Conclusion: 这是首次在联邦学习中形式化Rashomon集合的工作，提出的三种联邦Rashomon集合定义能够揭示决策边界的不稳定性，帮助客户端选择更适合其特定需求的模型，提升模型透明度、公平性和鲁棒性

Abstract: The Rashomon set captures the collection of models that achieve near-identical empirical performance yet may differ substantially in their decision boundaries. Understanding the differences among these models, i.e., their multiplicity, is recognized as a crucial step toward model transparency, fairness, and robustness, as it reveals decision boundaries instabilities that standard metrics obscure. However, the existing definitions of Rashomon set and multiplicity metrics assume centralized learning and do not extend naturally to decentralized, multi-party settings like Federated Learning (FL). In FL, multiple clients collaboratively train models under a central server's coordination without sharing raw data, which preserves privacy but introduces challenges from heterogeneous client data distribution and communication constraints. In this setting, the choice of a single best model may homogenize predictive behavior across diverse clients, amplify biases, or undermine fairness guarantees. In this work, we provide the first formalization of Rashomon sets in FL.First, we adapt the Rashomon set definition to FL, distinguishing among three perspectives: (I) a global Rashomon set defined over aggregated statistics across all clients, (II) a t-agreement Rashomon set representing the intersection of local Rashomon sets across a fraction t of clients, and (III) individual Rashomon sets specific to each client's local distribution.Second, we show how standard multiplicity metrics can be estimated under FL's privacy constraints. Finally, we introduce a multiplicity-aware FL pipeline and conduct an empirical study on standard FL benchmark datasets. Our results demonstrate that all three proposed federated Rashomon set definitions offer valuable insights, enabling clients to deploy models that better align with their local data, fairness considerations, and practical requirements.

</details>


### [67] [Learning to Discover Iterative Spectral Algorithms](https://arxiv.org/abs/2602.09530)
*Zihang Liu,Oleg Balabanov,Yaoqing Yang,Michael W. Mahoney*

Main category: cs.LG

TL;DR: AutoSpec是一个神经网络框架，用于发现大规模数值线性代数和数值优化的迭代谱算法，通过学习预测矩阵多项式系数，在真实矩阵上实现数量级精度提升或迭代次数减少。


<details>
  <summary>Details</summary>
Motivation: 传统数值线性代数算法在处理大规模问题时可能效率不高，需要针对特定算子特性的自适应算法。AutoSpec旨在通过机器学习自动发现针对下游任务优化的迭代谱算法。

Method: AutoSpec采用自监督神经网络框架，利用粗粒度谱信息（如特征值估计和残差范数）预测递归系数，生成针对特定任务的矩阵多项式。关键要素包括：实现可执行数值线性代数递归的架构、在小合成问题上高效训练并迁移到大规模真实算子、任务定义的目标函数确保在训练集谱分布范围内的期望近似或预处理行为。

Result: 在真实矩阵上，学习到的算法相比基础基线实现了数量级的精度提升和/或迭代次数减少。诱导的多项式表现出接近等波纹、接近极小极大值的特性，与切比雪夫多项式特征相似。

Conclusion: AutoSpec成功展示了机器学习可以自动发现高效的数值线性代数算法，学习到的多项式表现出与经典理论（如切比雪夫多项式）的明显联系，为自适应数值算法设计提供了新途径。

Abstract: We introduce AutoSpec, a neural network framework for discovering iterative spectral algorithms for large-scale numerical linear algebra and numerical optimization. Our self-supervised models adapt to input operators using coarse spectral information (e.g., eigenvalue estimates and residual norms), and they predict recurrence coefficients for computing or applying a matrix polynomial tailored to a downstream task. The effectiveness of AutoSpec relies on three ingredients: an architecture whose inference pass implements short, executable numerical linear algebra recurrences; efficient training on small synthetic problems with transfer to large-scale real-world operators; and task-defined objectives that enforce the desired approximation or preconditioning behavior across the range of spectral profiles represented in the training set. We apply AutoSpec to discovering algorithms for representative numerical linear algebra tasks: accelerating matrix-function approximation; accelerating sparse linear solvers; and spectral filtering/preconditioning for eigenvalue computations. On real-world matrices, the learned procedures deliver orders-of-magnitude improvements in accuracy and/or reductions in iteration count, relative to basic baselines. We also find clear connections to classical theory: the induced polynomials often exhibit near-equiripple, near-minimax behavior characteristic of Chebyshev polynomials.

</details>


### [68] [ECG-IMN: Interpretable Mesomorphic Neural Networks for 12-Lead Electrocardiogram Interpretation](https://arxiv.org/abs/2602.09566)
*Vajira Thambawita,Jonas L. Isaksen,Jørgen K. Kanters,Hugo L. Hammer,Pål Halvorsen*

Main category: cs.LG

TL;DR: 提出ECG-IMN模型，通过超网络架构实现心电图分类的内在可解释性，在保持与黑盒模型相当性能的同时提供精确的特征归因图。


<details>
  <summary>Details</summary>
Motivation: 深度学习在心电图诊断中已达到专家水平，但其"黑盒"特性阻碍了临床部署。医学AI需要高准确性和对驱动预测的生理特征的透明度。现有可解释性方法存在不稳定、计算成本高、不忠实于模型实际决策过程等问题。

Method: 提出ECG-IMN（可解释性中胚层神经网络），采用超网络架构：深度卷积主干网络为每个输入样本生成严格线性模型的参数。该架构强制内在可解释性，决策逻辑在数学上透明，生成的权重作为精确的高分辨率特征归因图。引入转换解码器将潜在特征映射到样本特定权重，实现病理证据在时间和导联维度的精确定位。

Result: 在PTB-XL数据集上评估，ECG-IMN实现了有竞争力的预测性能（AUROC与黑盒基线相当），同时提供忠实、实例特定的解释。通过明确分离参数生成和预测执行，该框架弥合了深度学习能力和临床可信度之间的差距。

Conclusion: ECG-IMN为"白盒"心脏诊断提供了原则性路径，通过内在可解释性架构实现了深度学习能力与临床可信度的平衡，有望促进医学AI的临床部署。

Abstract: Deep learning has achieved expert-level performance in automated electrocardiogram (ECG) diagnosis, yet the "black-box" nature of these models hinders their clinical deployment. Trust in medical AI requires not just high accuracy but also transparency regarding the specific physiological features driving predictions. Existing explainability methods for ECGs typically rely on post-hoc approximations (e.g., Grad-CAM and SHAP), which can be unstable, computationally expensive, and unfaithful to the model's actual decision-making process. In this work, we propose the ECG-IMN, an Interpretable Mesomorphic Neural Network tailored for high-resolution 12-lead ECG classification. Unlike standard classifiers, the ECG-IMN functions as a hypernetwork: a deep convolutional backbone generates the parameters of a strictly linear model specific to each input sample. This architecture enforces intrinsic interpretability, as the decision logic is mathematically transparent and the generated weights (W) serve as exact, high-resolution feature attribution maps. We introduce a transition decoder that effectively maps latent features to sample-wise weights, enabling precise localization of pathological evidence (e.g., ST-elevation, T-wave inversion) in both time and lead dimensions. We evaluate our approach on the PTB-XL dataset for classification tasks, demonstrating that the ECG-IMN achieves competitive predictive performance (AUROC comparable to black-box baselines) while providing faithful, instance-specific explanations. By explicitly decoupling parameter generation from prediction execution, our framework bridges the gap between deep learning capability and clinical trustworthiness, offering a principled path toward "white-box" cardiac diagnostics.

</details>


### [69] [Training deep physical neural networks with local physical information bottleneck](https://arxiv.org/abs/2602.09569)
*Hao Wang,Ziao Wang,Xiangpeng Liang,Han Zhao,Jianqi Hu,Junjie Jiang,Xing Fu,Jianshi Tang,Huaqiang Wu,Sylvain Gigan,Qiang Liu*

Main category: cs.LG

TL;DR: 提出物理信息瓶颈(PIB)框架，将信息论与局部学习结合，为深度物理神经网络提供通用训练方法，兼容各种物理平台和硬件缺陷


<details>
  <summary>Details</summary>
Motivation: 深度学习面临能耗和延迟限制，物理神经网络利用模拟动力学实现高效快速AI，但需要针对物理特性的通用训练方法

Method: 物理信息瓶颈(PIB)框架，结合信息论和局部学习，为每个单元分配基于矩阵的信息瓶颈，支持监督、无监督和强化学习

Result: 在电子忆阻芯片和光学计算平台上成功演示，适应硬件故障，支持地理分布式并行训练，无需辅助数字模型和对比测量

Conclusion: PIB将物理神经网络训练重构为内在、可扩展的信息论过程，兼容多种物理基底，为高效AI硬件提供通用解决方案

Abstract: Deep learning has revolutionized modern society but faces growing energy and latency constraints. Deep physical neural networks (PNNs) are interconnected computing systems that directly exploit analog dynamics for energy-efficient, ultrafast AI execution. Realizing this potential, however, requires universal training methods tailored to physical intricacies. Here, we present the Physical Information Bottleneck (PIB), a general and efficient framework that integrates information theory and local learning, enabling deep PNNs to learn under arbitrary physical dynamics. By allocating matrix-based information bottlenecks to each unit, we demonstrate supervised, unsupervised, and reinforcement learning across electronic memristive chips and optical computing platforms. PIB also adapts to severe hardware faults and allows for parallel training via geographically distributed resources. Bypassing auxiliary digital models and contrastive measurements, PIB recasts PNN training as an intrinsic, scalable information-theoretic process compatible with diverse physical substrates.

</details>


### [70] [Rollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.09578)
*Zhida Jiang,Zhaolong Xing,Jiawei Lu,Yipei Niu,Qingyuan Sang,Liangxu Zhang,Wenquan Dai,Junhua Shu,Jiaxing Wang,Qiangyu Pei,Qiong Chen,Xinyu Liu,Fangming Liu,Ai Han,Zhen Chen,Ke Zhang*

Main category: cs.LG

TL;DR: FlexMARL是一个专为大规模多智能体强化学习设计的端到端训练框架，通过解耦rollout和训练架构、异步流水线、负载均衡等技术，解决了现有框架在系统层面的瓶颈，实现了7.3倍加速和5.6倍的硬件利用率提升。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习训练框架主要针对单智能体场景优化，无法有效处理多智能体强化学习的系统级挑战，包括rollout-training同步屏障、rollout负载不均衡和训练资源利用率低下等问题。

Method: 1) 采用rollout-training解耦架构，通过联合协调器管理数据流；2) 基于经验存储的微批量驱动异步流水线消除同步屏障；3) rollout引擎采用并行采样和分层负载均衡；4) 训练引擎通过智能体中心资源分配实现按需硬件绑定；5) 统一的位置无关通信交换不同智能体的训练状态。

Result: 在大规模生产集群上的实证结果显示，FlexMARL相比现有框架实现了最高7.3倍的加速，并将硬件利用率提升了最高5.6倍。

Conclusion: FlexMARL是首个端到端优化大规模LLM-based多智能体强化学习训练的系统框架，通过系统级创新有效解决了MARL特有的挑战，显著提升了训练效率和资源利用率。

Abstract: Despite algorithm-level innovations for multi-agent reinforcement learning (MARL), the underlying networked infrastructure for large-scale MARL training remains underexplored. Existing training frameworks primarily optimize for single-agent scenarios and fail to address the unique system-level challenges of MARL, including rollout-training synchronization barriers, rollout load imbalance, and training resource underutilization. To bridge this gap, we propose FlexMARL, the first end-to-end training framework that holistically optimizes rollout, training, and their orchestration for large-scale LLM-based MARL. Specifically, FlexMARL introduces the joint orchestrator to manage data flow under the rollout-training disaggregated architecture. Building upon the experience store, a novel micro-batch driven asynchronous pipeline eliminates the synchronization barriers while providing strong consistency guarantees. Rollout engine adopts a parallel sampling scheme combined with hierarchical load balancing, which adapts to skewed inter/intra-agent request patterns. Training engine achieves on-demand hardware binding through agent-centric resource allocation. The training states of different agents are swapped via unified and location-agnostic communication. Empirical results on a large-scale production cluster demonstrate that FlexMARL achieves up to 7.3x speedup and improves hardware utilization by up to 5.6x compared to existing frameworks.

</details>


### [71] [Mitigating the Likelihood Paradox in Flow-based OOD Detection via Entropy Manipulation](https://arxiv.org/abs/2602.09581)
*Donghwan Kim,Hyunsoo Yoon*

Main category: cs.LG

TL;DR: 提出一种通过控制输入熵来缓解归一化流等生成模型中OOD样本似然值过高问题的方法，基于语义相似性对输入施加扰动，提高ID与OOD样本的似然差距。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型（如归一化流）常给OOD样本分配过高的似然值，导致"似然悖论"，这影响了基于似然的OOD检测效果。

Method: 基于语义相似性控制输入熵：对与ID记忆库相似度较低的输入施加更强的扰动。该方法无需重新训练密度模型，通过理论分析证明能增加ID与OOD样本的期望对数似然差距。

Result: 在标准基准测试中，该方法相比基于似然的OOD检测基线，在AUROC指标上获得了一致的改进，验证了理论分析的有效性。

Conclusion: 通过控制输入熵来操纵似然值，可以有效缓解深度生成模型中的似然悖论问题，提高OOD检测性能，且无需重新训练模型。

Abstract: Deep generative models that can tractably compute input likelihoods, including normalizing flows, often assign unexpectedly high likelihoods to out-of-distribution (OOD) inputs. We mitigate this likelihood paradox by manipulating input entropy based on semantic similarity, applying stronger perturbations to inputs that are less similar to an in-distribution memory bank. We provide a theoretical analysis showing that entropy control increases the expected log-likelihood gap between in-distribution and OOD samples in favor of the in-distribution, and we explain why the procedure works without any additional training of the density model. We then evaluate our method against likelihood-based OOD detectors on standard benchmarks and find consistent AUROC improvements over baselines, supporting our explanation.

</details>


### [72] [Why the Counterintuitive Phenomenon of Likelihood Rarely Appears in Tabular Anomaly Detection with Deep Generative Models?](https://arxiv.org/abs/2602.09593)
*Donghwan Kim,Junghun Phee,Hyunsoo Yoon*

Main category: cs.LG

TL;DR: 论文表明，在表格数据中，基于似然的异常检测（使用归一化流等可计算似率的深度生成模型）很少出现反直觉现象（即异常数据获得更高似然），这与图像领域不同。通过大量实验和理论分析，证明了该方法在表格领域的实用性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在图像领域，深度生成模型经常出现反直觉现象：异常数据反而获得更高的似然值。这种现象在表格数据中是否同样普遍存在尚不明确。论文旨在系统研究表格数据中基于似然的异常检测是否可靠，特别是针对归一化流等可计算似率的模型。

Method: 1. 提出领域无关的公式化定义，用于一致地检测和评估反直觉现象；2. 在ADBench基准上进行了大规模实验，涵盖47个表格数据集和10个CV/NLP嵌入数据集，对比13个基线模型；3. 从理论和实证角度分析数据维度和特征相关性差异对现象的影响。

Result: 实验表明，在表格数据中，反直觉现象（如定义）普遍罕见。与图像领域不同，基于似然的异常检测在表格数据中表现稳定可靠。理论分析揭示了数据维度和特征相关性差异是影响该现象的关键因素。

Conclusion: 仅使用似然的异常检测（特别是基于归一化流的方法）在表格数据领域是实用且可靠的方法。反直觉现象在表格数据中很少发生，这为表格异常检测提供了坚实的理论基础。

Abstract: Deep generative models with tractable and analytically computable likelihoods, exemplified by normalizing flows, offer an effective basis for anomaly detection through likelihood-based scoring. We demonstrate that, unlike in the image domain where deep generative models frequently assign higher likelihoods to anomalous data, such counterintuitive behavior occurs far less often in tabular settings. We first introduce a domain-agnostic formulation that enables consistent detection and evaluation of the counterintuitive phenomenon, addressing the absence of precise definition. Through extensive experiments on 47 tabular datasets and 10 CV/NLP embedding datasets in ADBench, benchmarked against 13 baseline models, we demonstrate that the phenomenon, as defined, is consistently rare in general tabular data. We further investigate this phenomenon from both theoretical and empirical perspectives, focusing on the roles of data dimensionality and difference in feature correlation. Our results suggest that likelihood-only detection with normalizing flows offers a practical and reliable approach for anomaly detection in tabular domains.

</details>


### [73] [LLM-FS: Zero-Shot Feature Selection for Effective and Interpretable Malware Detection](https://arxiv.org/abs/2602.09634)
*Naveen Gill,Ajvad Haneef K,Madhu Kumar S D*

Main category: cs.LG

TL;DR: LLM引导的零样本特征选择在恶意软件检测中与传统方法表现相当，同时提供更好的可解释性和稳定性


<details>
  <summary>Details</summary>
Motivation: 传统特征选择方法主要依赖统计启发式或模型驱动的重要性分数，往往忽略特征的语义上下文。受LLM驱动特征选择的最新进展启发，研究LLM是否能在零样本设置下仅使用特征名称和任务描述来指导特征选择，作为传统方法的可行替代方案

Method: 在EMBOD数据集（EMBER和BODMAS基准数据集的融合）上评估多个LLM（GPT-5.0、GPT-4.0、Gemini-2.5等），与已建立的特征选择方法（Extra Trees、Variance Threshold、树模型、卡方检验、ANOVA、随机选择、顺序注意力）进行比较，使用多种分类器（随机森林、Extra Trees、MLP、KNN）进行测试

Result: LLM引导的零样本特征选择在准确率、精确率、召回率、F1、AUC、MCC和运行时间等指标上与传统特征选择方法表现相当，同时在可解释性、稳定性和减少对标记数据的依赖方面具有额外优势

Conclusion: 零样本LLM基础的特征选择是恶意软件检测中有效且可解释的有前景的替代策略，为安全关键应用中的知识引导特征选择铺平了道路

Abstract: Feature selection (FS) remains essential for building accurate and interpretable detection models, particularly in high-dimensional malware datasets. Conventional FS methods such as Extra Trees, Variance Threshold, Tree-based models, Chi-Squared tests, ANOVA, Random Selection, and Sequential Attention rely primarily on statistical heuristics or model-driven importance scores, often overlooking the semantic context of features. Motivated by recent progress in LLM-driven FS, we investigate whether large language models (LLMs) can guide feature selection in a zero-shot setting, using only feature names and task descriptions, as a viable alternative to traditional approaches. We evaluate multiple LLMs (GPT-5.0, GPT-4.0, Gemini-2.5 etc.) on the EMBOD dataset (a fusion of EMBER and BODMAS benchmark datasets), comparing them against established FS methods across several classifiers, including Random Forest, Extra Trees, MLP, and KNN. Performance is assessed using accuracy, precision, recall, F1, AUC, MCC, and runtime. Our results demonstrate that LLM-guided zero-shot feature selection achieves competitive performance with traditional FS methods while offering additional advantages in interpretability, stability, and reduced dependence on labeled data. These findings position zero-shot LLM-based FS as a promising alternative strategy for effective and interpretable malware detection, paving the way for knowledge-guided feature selection in security-critical applications

</details>


### [74] [Blind denoising diffusion models and the blessings of dimensionality](https://arxiv.org/abs/2602.09639)
*Zahra Kadkhodaie,Aram-Alexandre Pooladian,Sinho Chewi,Eero Simoncelli*

Main category: cs.LG

TL;DR: 盲去噪扩散模型(BDDMs)无需噪声幅度信息，能自动追踪隐式噪声调度，在多项式步数内准确采样，且比非盲模型生成质量更高


<details>
  <summary>Details</summary>
Motivation: 研究盲去噪扩散模型的性能，探索在训练和采样过程中都不提供噪声幅度信息的情况下，模型是否能有效学习数据分布并生成高质量样本

Method: 理论分析结合实证验证：假设数据分布具有低本征维度，证明BDDMs能自动追踪隐式噪声调度；在合成数据和图像数据上进行实验验证

Result: BDDMs能准确估计噪声方差，在多项式步数内采样数据分布；令人惊讶的是，无调度BDDMs比非盲对应模型产生更高质量的样本

Conclusion: 盲去噪扩散模型能有效工作，自动学习隐式噪声调度，且性能优于传统非盲模型，这归因于BDDMs能纠正真实残差噪声与调度假设噪声之间的不匹配

Abstract: We analyze, theoretically and empirically, the performance of generative diffusion models based on \emph{blind denoisers}, in which the denoiser is not given the noise amplitude in either the training or sampling processes. Assuming that the data distribution has low intrinsic dimensionality, we prove that blind denoising diffusion models (BDDMs), despite not having access to the noise amplitude, \emph{automatically} track a particular \emph{implicit} noise schedule along the reverse process. Our analysis shows that BDDMs can accurately sample from the data distribution in polynomially many steps as a function of the intrinsic dimension. Empirical results corroborate these mathematical findings on both synthetic and image data, demonstrating that the noise variance is accurately estimated from the noisy image. Remarkably, we observe that schedule-free BDDMs produce samples of higher quality compared to their non-blind counterparts. We provide evidence that this performance gain arises because BDDMs correct the mismatch between the true residual noise (of the image) and the noise assumed by the schedule used in non-blind diffusion models.

</details>


### [75] [Differentiable Modeling for Low-Inertia Grids: Benchmarking PINNs, NODEs, and DP for Identification and Control of SMIB System](https://arxiv.org/abs/2602.09667)
*Shinhoo Kang,Sangwook Kim,Sehyun Yun*

Main category: cs.LG

TL;DR: 比较PINNs、NODEs和DP在电力系统建模、辨识与控制中的性能，发现NODE在轨迹外推最优，DP在参数辨识收敛最快且控制性能接近理论最优，PINN泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 低惯量电力系统需要既准确预测状态又提供物理一致灵敏度的建模框架，但不同可微分范式对控制的影响尚不明确。

Method: 使用单机无穷大系统作为基准，比较物理信息神经网络(PINNs)、神经常微分方程(NODEs)和可微分编程(DP)在轨迹外推、参数估计和LQR控制综合中的性能。

Result: NODE在轨迹外推表现最优，能捕捉底层向量场；DP在参数辨识中收敛最快，控制性能接近理论最优；PINN因依赖时间相关解映射而泛化能力有限。

Conclusion: 存在数据驱动灵活性与物理结构之间的权衡：DP在控制综合中表现最佳，NODE可作为无控制方程时的数据驱动替代，PINN在泛化方面存在局限。

Abstract: The transition toward low-inertia power systems demands modeling frameworks that provide not only accurate state predictions but also physically consistent sensitivities for control. While scientific machine learning offers powerful nonlinear modeling tools, the control-oriented implications of different differentiable paradigms remain insufficiently understood. This paper presents a comparative study of Physics-Informed Neural Networks (PINNs), Neural Ordinary Differential Equations (NODEs), and Differentiable Programming (DP) for modeling, identification, and control of power system dynamics. Using the Single Machine Infinite Bus (SMIB) system as a benchmark, we evaluate their performance in trajectory extrapolation, parameter estimation, and Linear Quadratic Regulator (LQR) synthesis.
  Our results highlight a fundamental trade-off between data-driven flexibility and physical structure. NODE exhibits superior extrapolation by capturing the underlying vector field, whereas PINN shows limited generalization due to its reliance on a time-dependent solution map. In the inverse problem of parameter identification, while both DP and PINN successfully recover the unknown parameters, DP achieves significantly faster convergence by enforcing governing equations as hard constraints. Most importantly, for control synthesis, the DP framework yields closed-loop stability comparable to the theoretical optimum. Furthermore, we demonstrate that NODE serves as a viable data-driven surrogate when governing equations are unavailable.

</details>


### [76] [Resilient Class-Incremental Learning: on the Interplay of Drifting, Unlabelled and Imbalanced Data Streams](https://arxiv.org/abs/2602.09681)
*Jin Li,Kleanthis Malialis,Marios Polycarpou*

Main category: cs.LG

TL;DR: SCIL框架通过集成自编码器和多层感知器，结合双损失策略和队列管理，解决流数据中的概念漂移、类别不平衡和新类别出现等挑战。


<details>
  <summary>Details</summary>
Motivation: 在当今互联世界中，大规模流数据生成普遍存在，但面临概念漂移、类别不平衡、标签稀缺和新类别出现等挑战，这些因素共同降低了表示稳定性、使学习偏向过时分布，并削弱了动态环境中检测的鲁棒性和可靠性。

Method: SCIL框架集成自编码器与多层感知器进行多类别预测，采用分类和重构的双损失策略进行预测和新类别检测，使用修正伪标签进行在线训练，通过队列管理类别，并应用过采样处理不平衡问题。

Result: 实验结果表明，SCIL在包含类别不平衡、增量类别和概念漂移的真实世界和合成数据集上，均优于强基线和最先进方法。

Conclusion: SCIL有效解决了流数据学习中的关键挑战，作者基于开放科学承诺向社区公开代码和数据集。

Abstract: In today's connected world, the generation of massive streaming data across diverse domains has become commonplace. In the presence of concept drift, class imbalance, label scarcity, and new class emergence, they jointly degrade representation stability, bias learning toward outdated distributions, and reduce the resilience and reliability of detection in dynamic environments. This paper proposes SCIL (Streaming Class-Incremental Learning) to address these challenges. The SCIL framework integrates an autoencoder (AE) with a multi-layer perceptron for multi-class prediction, uses a dual-loss strategy (classification and reconstruction) for prediction and new class detection, employs corrected pseudo-labels for online training, manages classes with queues, and applies oversampling to handle imbalance. The rationale behind the method's structure is elucidated through ablation studies and a comprehensive experimental evaluation is performed using both real-world and synthetic datasets that feature class imbalance, incremental classes, and concept drifts. Our results demonstrate that SCIL outperforms strong baselines and state-of-the-art methods. Based on our commitment to Open Science, we make our code and datasets available to the community.

</details>


### [77] [Model soups need only one ingredient](https://arxiv.org/abs/2602.09689)
*Alireza Abdollahpoorrostam,Nikolaos Dimitriadis,Adam Hazimeh,Pascal Frossard*

Main category: cs.LG

TL;DR: MonoSoup是一种单检查点权重集成方法，通过SVD分解层更新并自动重加权组件，在保持ID性能的同时提升OOD鲁棒性，避免了多模型训练的计算开销。


<details>
  <summary>Details</summary>
Motivation: 微调大型预训练模型通常能提高分布内（ID）准确率，但会损害分布外（OOD）鲁棒性。现有的权重空间集成方法（如Model Soups）需要训练和存储多个模型，计算成本过高。

Method: MonoSoup使用奇异值分解（SVD）将每层的更新分解为高能量方向（任务特定适应）和低能量方向（噪声但可能包含鲁棒性信号），然后基于熵的有效秩自动重加权这些组件，考虑模型的谱和几何结构。

Result: 在CLIP模型（ImageNet微调，自然分布偏移评估）和Qwen语言模型（数学推理和多选基准测试）上的实验表明，该方法在ID-OOD平衡方面表现优异，接近多检查点方法的性能但计算成本低得多。

Conclusion: MonoSoup是一种简单、无需数据、无需超参数调整的后处理方法，仅需单个检查点即可实现强大的ID-OOD平衡，是多检查点方法的实用有效替代方案。

Abstract: Fine-tuning large pre-trained models on a target distribution often improves in-distribution (ID) accuracy, but at the cost of out-of-distribution (OOD) robustness as representations specialize to the fine-tuning data. Weight-space ensembling methods, such as Model Soups, mitigate this effect by averaging multiple checkpoints, but they are computationally prohibitive, requiring the training and storage of dozens of fine-tuned models. In this paper, we introduce MonoSoup, a simple, data-free, hyperparameter-free, post-hoc method that achieves a strong ID-OOD balance using only a single checkpoint. Our method applies Singular Value Decomposition (SVD) to each layer's update and decomposes it into high-energy directions that capture task-specific adaptation and low-energy directions that introduce noise but may still encode residual signals useful for robustness. MonoSoup then uses entropy-based effective rank to automatically re-weigh these components with layer-wise coefficients that account for the spectral and geometric structure of the model. Experiments on CLIP models fine-tuned on ImageNet and evaluated under natural distribution shifts, as well as on Qwen language models tested on mathematical reasoning and multiple-choice benchmarks, show that this plug-and-play approach is a practical and effective alternative to multi-checkpoint methods, retaining much of their benefits without their computational overhead.

</details>


### [78] [Contextual and Seasonal LSTMs for Time Series Anomaly Detection](https://arxiv.org/abs/2602.09690)
*Lingpei Zhang,Qingming Li,Yong Yang,Jiahao Chen,Rui Zeng,Chenyang Lyu,Shouling Ji*

Main category: cs.LG

TL;DR: 提出CS-LSTMs框架，结合上下文依赖和季节性模式，通过噪声分解策略增强对细微异常的检测能力，在单变量时间序列异常检测中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单变量时间序列异常检测在Web系统和云服务器中至关重要，但现有的重构基和预测基方法难以捕捉某些细微异常，特别是小点异常和缓慢上升异常。

Method: 提出CS-LSTMs框架，基于噪声分解策略，联合利用上下文依赖和季节性模式，整合时域和频域表示，实现对周期性趋势的更准确建模和异常定位。

Result: 在公共基准数据集上的广泛评估表明，CS-LSTMs始终优于最先进的方法，突显了其在鲁棒时间序列异常检测中的有效性和实用价值。

Conclusion: CS-LSTMs通过结合上下文依赖和季节性模式，有效解决了现有方法在检测细微异常方面的不足，为时间序列异常检测提供了更强大的解决方案。

Abstract: Univariate time series (UTS), where each timestamp records a single variable, serve as crucial indicators in web systems and cloud servers. Anomaly detection in UTS plays an essential role in both data mining and system reliability management. However, existing reconstruction-based and prediction-based methods struggle to capture certain subtle anomalies, particularly small point anomalies and slowly rising anomalies. To address these challenges, we propose a novel prediction-based framework named Contextual and Seasonal LSTMs (CS-LSTMs). CS-LSTMs are built upon a noise decomposition strategy and jointly leverage contextual dependencies and seasonal patterns, thereby strengthening the detection of subtle anomalies. By integrating both time-domain and frequency-domain representations, CS-LSTMs achieve more accurate modeling of periodic trends and anomaly localization. Extensive evaluations on public benchmark datasets demonstrate that CS-LSTMs consistently outperform state-of-the-art methods, highlighting their effectiveness and practical value in robust time series anomaly detection.

</details>


### [79] [Physics-informed diffusion models in spectral space](https://arxiv.org/abs/2602.09708)
*Davide Gallon,Philippe von Wurstemberger,Patrick Cheridito,Arnulf Jentzen*

Main category: cs.LG

TL;DR: 结合生成式潜在扩散模型与物理信息机器学习，通过谱表示降维处理参数化偏微分方程，在部分观测条件下生成解，支持正反问题求解。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的PDE求解器在处理稀疏观测时存在计算效率低和精度不足的问题，需要一种能在部分观测条件下高效生成PDE解的方法。

Method: 在缩放谱表示的潜在空间中学习PDE参数与解的联合分布，利用扩散过程；通过扩散后验采样在推理时强制执行物理约束和测量条件，在每个扩散步骤应用Adam更新。

Result: 在Poisson、Helmholtz和不可压缩Navier-Stokes方程上评估，相比现有最先进的基于扩散的PDE求解器，在稀疏观测条件下表现出更高的精度和计算效率。

Conclusion: 提出的谱潜在扩散方法为参数化PDE的正反问题求解提供了高效框架，特别适用于部分观测条件，代码已开源。

Abstract: We propose a methodology that combines generative latent diffusion models with physics-informed machine learning to generate solutions of parametric partial differential equations (PDEs) conditioned on partial observations, which includes, in particular, forward and inverse PDE problems. We learn the joint distribution of PDE parameters and solutions via a diffusion process in a latent space of scaled spectral representations, where Gaussian noise corresponds to functions with controlled regularity. This spectral formulation enables significant dimensionality reduction compared to grid-based diffusion models and ensures that the induced process in function space remains within a class of functions for which the PDE operators are well defined. Building on diffusion posterior sampling, we enforce physics-informed constraints and measurement conditions during inference, applying Adam-based updates at each diffusion step. We evaluate the proposed approach on Poisson, Helmholtz, and incompressible Navier--Stokes equations, demonstrating improved accuracy and computational efficiency compared with existing diffusion-based PDE solvers, which are state of the art for sparse observations. Code is available at https://github.com/deeplearningmethods/PISD.

</details>


### [80] [BRAVA-GNN: Betweenness Ranking Approximation Via Degree MAss Inspired Graph Neural Network](https://arxiv.org/abs/2602.09716)
*Justin Dachille,Aurora Rossi,Sunil Kumar Maurya,Frederik Mallmann-Trenn,Xin Liu,Frédéric Giroire,Tsuyoshi Murata,Emanuele Natale*

Main category: cs.LG

TL;DR: BRAVA-GNN：一种轻量级图神经网络，利用度质量与介数中心性的相关性，通过双曲随机图生成合成训练数据，在道路网络等高直径图上实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的介数中心性预测方法在道路网络等高直径图上泛化能力差，计算成本高，需要更轻量且能跨图族泛化的解决方案。

Method: 利用度质量与介数中心性的相关性，将度质量作为尺寸不变节点特征；使用双曲随机图模型生成匹配真实网络度分布的合成训练图；设计轻量级GNN架构。

Result: 在19个真实网络（社交、网页、邮件、道路网络）上，BRAVA-GNN比现有最佳GNN方法在Kendall-Tau相关性上提升达214%，推理时间加速70倍，参数减少54倍。

Conclusion: BRAVA-GNN通过利用度质量相关性、双曲随机图训练数据和轻量架构，实现了跨图族的高效介数中心性预测，特别在挑战性的道路网络上表现优异。

Abstract: Computing node importance in networks is a long-standing fundamental problem that has driven extensive study of various centrality measures. A particularly well-known centrality measure is betweenness centrality, which becomes computationally prohibitive on large-scale networks. Graph Neural Network (GNN) models have thus been proposed to predict node rankings according to their relative betweenness centrality. However, state-of-the-art methods fail to generalize to high-diameter graphs such as road networks. We propose BRAVA-GNN, a lightweight GNN architecture that leverages the empirically observed correlation linking betweenness centrality to degree-based quantities, in particular multi-hop degree mass. This correlation motivates the use of degree masses as size-invariant node features and synthetic training graphs that closely match the degree distributions of real networks. Furthermore, while previous work relies on scale-free synthetic graphs, we leverage the hyperbolic random graph model, which reproduces power-law exponents outside the scale-free regime, better capturing the structure of real-world graphs like road networks. This design enables BRAVA-GNN to generalize across diverse graph families while using 54x fewer parameters than the most lightweight existing GNN baseline. Extensive experiments on 19 real-world networks, spanning social, web, email, and road graphs, show that BRAVA-GNN achieves up to 214% improvement in Kendall-Tau correlation and up to 70x speedup in inference time over state-of-the-art GNN-based approaches, particularly on challenging road networks.

</details>


### [81] [ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm](https://arxiv.org/abs/2602.09726)
*Hanyong Wang,Menglong Yang*

Main category: cs.LG

TL;DR: 提出ExO-PPO算法，结合PPO的稳定性与离策略方法的样本效率，通过分段指数函数扩展裁剪机制，利用历史策略轨迹进行离策略训练，在多种任务上实现平衡的性能提升。


<details>
  <summary>Details</summary>
Motivation: PPO算法通过保守的在线策略更新确保稳定性，但牺牲了样本效率；离策略方法虽然样本利用率高，但存在方差和偏差问题。需要结合两者优势，在保持稳定性的同时提高样本效率。

Method: 1. 从广义策略改进下界的期望形式推导扩展的离策略改进；2. 使用分段指数函数扩展裁剪机制，构建合适的替代目标函数；3. 将过去M个策略生成的轨迹组织在回放缓冲区中进行离策略训练。

Result: 与PPO及其他先进变体相比，ExO-PPO在多种任务上表现出改进的性能，在样本效率和稳定性之间取得了更好的平衡。

Conclusion: ExO-PPO成功结合了在线策略的稳定性保证和离策略的数据利用效率，为深度强化学习提供了既稳定又高效的训练方法。

Abstract: Deep reinforcement learning has been able to solve various tasks successfully, however, due to the construction of policy gradient and training dynamics, tuning deep reinforcement learning models remains challenging. As one of the most successful deep reinforcement-learning algorithm, the Proximal Policy Optimization algorithm (PPO) clips the policy gradient within a conservative on-policy updates, which ensures reliable and stable policy improvement. However, this training pattern may sacrifice sample efficiency. On the other hand, off-policy methods make more adequate use of data through sample reuse, though at the cost of increased the estimation variance and bias. To leverage the advantages of both, in this paper, we propose a new PPO variant based on the stability guarantee from conservative on-policy iteration with a more efficient off-policy data utilization. Specifically, we first derive an extended off-policy improvement from an expectation form of generalized policy improvement lower bound. Then, we extend the clipping mechanism with segmented exponential functions for a suitable surrogate objective function. Third, the trajectories generated by the past $M$ policies are organized in the replay buffer for off-policy training. We refer to this method as Extended Off-policy Proximal Policy Optimization (ExO-PPO). Compared with PPO and some other state-of-the-art variants, we demonstrate an improved performance of ExO-PPO with balanced sample efficiency and stability on varied tasks in the empirical experiments.

</details>


### [82] [Towards Poisoning Robustness Certification for Natural Language Generation](https://arxiv.org/abs/2602.09757)
*Mihnea Ghitu,Matthew Wicker*

Main category: cs.LG

TL;DR: TPA是首个针对自回归语言生成任务的认证防御算法，通过计算诱导特定有害内容所需的最小投毒预算来认证有效性/针对性攻击，并利用MILP为多轮生成提供更紧的保证。


<details>
  <summary>Details</summary>
Motivation: 在安全敏感领域部署基础模型时，理解自然语言生成的可靠性至关重要。现有认证投毒防御方法主要针对分类任务，无法处理自回归生成的序列预测和指数级大的输出空间。

Method: 提出Targeted Partition Aggregation (TPA)算法，通过计算诱导特定有害类别、标记或短语所需的最小投毒预算来认证有效性/针对性攻击。使用混合整数线性规划(MILP)为多轮生成提供更紧的保证。

Result: TPA在多种场景中有效：当攻击者修改最多0.5%数据集时，能认证代理工具调用的有效性；在基于偏好的对齐中，能认证8个标记的稳定性范围。

Conclusion: 尽管推理时延仍是开放挑战，但TPA的贡献使得在安全关键应用中认证部署语言模型成为可能，为认证自然语言生成建立了首个框架。

Abstract: Understanding the reliability of natural language generation is critical for deploying foundation models in security-sensitive domains. While certified poisoning defenses provide provable robustness bounds for classification tasks, they are fundamentally ill-equipped for autoregressive generation: they cannot handle sequential predictions or the exponentially large output space of language models. To establish a framework for certified natural language generation, we formalize two security properties: stability (robustness to any change in generation) and validity (robustness to targeted, harmful changes in generation). We introduce Targeted Partition Aggregation (TPA), the first algorithm to certify validity/targeted attacks by computing the minimum poisoning budget needed to induce a specific harmful class, token, or phrase. Further, we extend TPA to provide tighter guarantees for multi-turn generations using mixed integer linear programming (MILP). Empirically, we demonstrate TPA's effectiveness across diverse settings including: certifying validity of agent tool-calling when adversaries modify up to 0.5% of the dataset and certifying 8-token stability horizons in preference-based alignment. Though inference-time latency remains an open challenge, our contributions enable certified deployment of language models in security-critical applications.

</details>


### [83] [Grounding LTL Tasks in Sub-Symbolic RL Environments for Zero-Shot Generalization](https://arxiv.org/abs/2602.09761)
*Matteo Pannacci,Andrea Fanti,Elena Umili,Roberto Capobianco*

Main category: cs.LG

TL;DR: 提出一种在子符号环境中联合训练多任务策略和符号接地器的方法，无需先验的观察-符号映射知识，通过神经奖励机实现半监督学习


<details>
  <summary>Details</summary>
Motivation: 解决在子符号环境中训练强化学习智能体遵循线性时序逻辑指令的问题。现有方法需要已知原始观察与公式符号之间的映射关系，这一假设不现实

Method: 联合训练多任务策略和符号接地器，使用相同的经验数据。符号接地器仅从原始观察和稀疏奖励中通过神经奖励机进行半监督训练

Result: 在基于视觉的环境中，该方法达到与使用真实符号接地相当的性能，并显著优于子符号环境中的最先进方法

Conclusion: 提出的联合训练框架能够在无需先验符号映射知识的情况下，有效处理子符号环境中的多任务时序逻辑指令跟随问题

Abstract: In this work we address the problem of training a Reinforcement Learning agent to follow multiple temporally-extended instructions expressed in Linear Temporal Logic in sub-symbolic environments. Previous multi-task work has mostly relied on knowledge of the mapping between raw observations and symbols appearing in the formulae. We drop this unrealistic assumption by jointly training a multi-task policy and a symbol grounder with the same experience. The symbol grounder is trained only from raw observations and sparse rewards via Neural Reward Machines in a semi-supervised fashion. Experiments on vision-based environments show that our method achieves performance comparable to using the true symbol grounding and significantly outperforms state-of-the-art methods for sub-symbolic environments.

</details>


### [84] [Explainability in Generative Medical Diffusion Models: A Faithfulness-Based Analysis on MRI Synthesis](https://arxiv.org/abs/2602.09781)
*Surjo Dey,Pallabi Saikia*

Main category: cs.LG

TL;DR: 本文研究了生成扩散模型在医学影像（MRI合成）中的可解释性，提出了基于忠实度的可解释性框架，分析原型方法如何连接生成特征与训练特征，发现EPPNet具有最高忠实度，使扩散模型更透明可信。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在生成逼真医学影像方面表现出色，但其内部决策过程仍然不透明。在医疗保健领域，需要使生成式AI更加透明和可信，以确保安全应用。

Method: 提出了基于忠实度的可解释性框架，分析原型可解释性方法（ProtoPNet、Enhanced ProtoPNet、ProtoPool）如何连接生成特征与训练特征。通过分析扩散模型的去噪轨迹来理解图像形成过程，然后进行原型可解释性分析和忠实度评估。

Result: 实验分析显示，Enhanced ProtoPNet（EPPNet）获得了最高的忠实度得分（0.1534），提供了更可靠的见解和对生成过程的可解释性。

Conclusion: 基于忠实度的解释可以使扩散模型更加透明和可信，有助于生成式AI在医疗保健领域更安全、更可解释的应用。

Abstract: This study investigates the explainability of generative diffusion models in the context of medical imaging, focusing on Magnetic resonance imaging (MRI) synthesis. Although diffusion models have shown strong performance in generating realistic medical images, their internal decision making process remains largely opaque. We present a faithfulness-based explainability framework that analyzes how prototype-based explainability methods like ProtoPNet (PPNet), Enhanced ProtoPNet (EPPNet), and ProtoPool can link the relationship between generated and training features. Our study focuses on understanding the reasoning behind image formation through denoising trajectory of diffusion model and subsequently prototype explainability with faithfulness analysis. Experimental analysis shows that EPPNet achieves the highest faithfulness (with score 0.1534), offering more reliable insights, and explainability into the generative process. The results highlight that diffusion models can be made more transparent and trustworthy through faithfulness-based explanations, contributing to safer and more interpretable applications of generative AI in healthcare.

</details>


### [85] [Flexible Entropy Control in RLVR with Gradient-Preserving Perspective](https://arxiv.org/abs/2602.09782)
*Kun Chen,Peng Shi,Fanfan Liu,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao*

Main category: cs.LG

TL;DR: 本文提出通过梯度保持裁剪的动态阈值机制来重塑强化学习中的熵控制，有效缓解策略熵崩溃问题，并在多个基准测试中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习与可验证奖励（RLVR）是提升大语言模型推理能力的关键方法，但持续训练常导致策略熵崩溃，表现为熵快速衰减、过早过度自信、输出多样性降低和梯度范数消失等问题。现有缓解策略多为静态方法，缺乏将裁剪机制与精确熵控制相连接的框架。

Method: 首先从理论和实证上验证特定重要性采样比率区域对熵增长和减少的贡献。基于这些发现，提出使用动态裁剪阈值的新型调节机制来精确管理熵。进一步设计和评估动态熵控制策略，包括先增后减、减-增-减和振荡衰减等模式。

Result: 实验结果表明，这些策略能有效缓解熵崩溃问题，并在多个基准测试中取得优越性能。

Conclusion: 通过梯度保持裁剪的动态阈值机制重塑熵控制，为解决RLVR训练中的熵崩溃问题提供了有效框架，实现了更好的策略多样性和学习稳定性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a critical method for enhancing the reasoning capabilities of Large Language Models (LLMs). However, continuous training often leads to policy entropy collapse, characterized by a rapid decay in entropy that results in premature overconfidence, reduced output diversity, and vanishing gradient norms that inhibit learning. Gradient-Preserving Clipping is a primary factor influencing these dynamics, but existing mitigation strategies are largely static and lack a framework connecting clipping mechanisms to precise entropy control. This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping. We first theoretically and empirically verify the contributions of specific importance sampling ratio regions to entropy growth and reduction. Leveraging these findings, we introduce a novel regulation mechanism using dynamic clipping threshold to precisely manage entropy. Furthermore, we design and evaluate dynamic entropy control strategies, including increase-then-decrease, decrease-increase-decrease, and oscillatory decay. Experimental results demonstrate that these strategies effectively mitigate entropy collapse, and achieve superior performance across multiple benchmarks.

</details>


### [86] [Why Linear Interpretability Works: Invariant Subspaces as a Result of Architectural Constraints](https://arxiv.org/abs/2602.09783)
*Andres Saurez,Yousung Lee,Dongsoo Har*

Main category: cs.LG

TL;DR: 论文提出"不变子空间必要性"定理，解释为何线性探针和稀疏自编码器能在深度非线性Transformer中成功恢复语义结构：因为Transformer通过线性接口通信，任何通过此类接口解码的语义特征必须占据上下文不变线性子空间。


<details>
  <summary>Details</summary>
Motivation: 解释为什么简单的线性方法（线性探针和稀疏自编码器）能够在深度非线性的Transformer系统中成功恢复有意义的语义结构，而不是仅仅将其视为经验规律。

Method: 提出"不变子空间必要性"定理，证明Transformer架构中信息通过线性接口（注意力OV电路、解嵌入矩阵）通信，导致语义特征必须占据上下文不变线性子空间。推导出"自引用属性"：token直接提供其相关特征的几何方向。

Result: 在8个分类任务和4个模型家族中进行实证验证，确认类别token与语义相关实例之间的对齐。实现了无需标注数据或学习探针的零样本语义结构识别。

Conclusion: 为线性可解释性方法为何有效提供了原则性的架构解释，统一了线性探针和稀疏自编码器的理论基础，证明这是Transformer架构的必然结果而非偶然现象。

Abstract: Linear probes and sparse autoencoders consistently recover meaningful structure from transformer representations -- yet why should such simple methods succeed in deep, nonlinear systems? We show this is not merely an empirical regularity but a consequence of architectural necessity: transformers communicate information through linear interfaces (attention OV circuits, unembedding matrices), and any semantic feature decoded through such an interface must occupy a context-invariant linear subspace. We formalize this as the \emph{Invariant Subspace Necessity} theorem and derive the \emph{Self-Reference Property}: tokens directly provide the geometric direction for their associated features, enabling zero-shot identification of semantic structure without labeled data or learned probes. Empirical validation in eight classification tasks and four model families confirms the alignment between class tokens and semantically related instances. Our framework provides \textbf{a principled architectural explanation} for why linear interpretability methods work, unifying linear probes and sparse autoencoders.

</details>


### [87] [Circuit Fingerprints: How Answer Tokens Encode Their Geometrical Path](https://arxiv.org/abs/2602.09784)
*Andres Saurez,Neha Sengar,Dongsoo Har*

Main category: cs.LG

TL;DR: 论文提出"电路指纹"假说：Transformer中答案token在孤立处理时编码了产生它们的方向，这统一了电路发现和激活转向两种方法。


<details>
  <summary>Details</summary>
Motivation: 电路发现和激活转向作为两个独立的研究方向，都操作在相同的表示空间上。作者想探究它们是否是同一底层结构的两种视角，并寻找统一的理论基础。

Method: 提出"电路指纹"假说：答案token在孤立处理时编码了产生它们的方向。基于此，仅通过几何对齐就能实现电路发现，无需梯度或因果干预。在IOI、SVA、MCQA等标准基准测试中，在四个模型家族上验证该方法。

Result: 1) 电路发现性能与基于梯度的方法相当；2) 识别电路组件的相同方向也能实现可控转向，在情感分类任务上达到69.8%的准确率（指令提示为53.1%），同时保持事实准确性。

Conclusion: Transformer电路本质上是几何结构：可解释性和可控性是同一对象的两个方面。这种读写二元性揭示了电路发现和激活转向的统一几何原理。

Abstract: Circuit discovery and activation steering in transformers have developed as separate research threads, yet both operate on the same representational space. Are they two views of the same underlying structure? We show they follow a single geometric principle: answer tokens, processed in isolation, encode the directions that would produce them. This Circuit Fingerprint hypothesis enables circuit discovery without gradients or causal intervention -- recovering comparable structure to gradient-based methods through geometric alignment alone. We validate this on standard benchmarks (IOI, SVA, MCQA) across four model families, achieving circuit discovery performance comparable to gradient-based methods. The same directions that identify circuit components also enable controlled steering -- achieving 69.8\% emotion classification accuracy versus 53.1\% for instruction prompting while preserving factual accuracy. Beyond method development, this read-write duality reveals that transformer circuits are fundamentally geometric structures: interpretability and controllability are two facets of the same object.

</details>


### [88] [When Less is More: The LLM Scaling Paradox in Context Compression](https://arxiv.org/abs/2602.09789)
*Ruishan Guo,Yibing Liu,Guoxin Ma,Yan Wang,Yueyang Zhang,Long Xia,Kecheng Chen,Zhiyuan Sun,Daiting Shi*

Main category: cs.LG

TL;DR: 研究发现模型参数规模扩大时会出现"规模-保真度悖论"：在压缩器-解码器设置中，更大的压缩器模型反而会降低上下文重建的忠实度，尽管训练损失下降。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型参数越大生成能力越强，但在上下文压缩任务中，作者观察到随着模型规模增大，重建的忠实度反而下降的悖论现象，需要探究其原因。

Method: 通过从0.6B到90B不同规模模型的广泛实验，分析规模扩大对上下文重建忠实度的影响，识别出知识覆盖和语义漂移两个主要因素，并探究其背后的机制。

Result: 发现规模扩大导致：1）知识覆盖：大模型更倾向于用自身先验知识替换源事实；2）语义漂移：大模型更倾向于意译或重组内容而非逐字复制。根本原因不是参数数量本身，而是伴随规模扩大而来的过度语义能力和放大的生成不确定性。

Conclusion: 在开放生成任务中，模型规模扩大反而会损害上下文忠实度保存，这补充了现有上下文压缩范式的评估，揭示了规模定律在忠实保存方面的失效。

Abstract: Scaling up model parameters has long been a prevalent training paradigm driven by the assumption that larger models yield superior generation capabilities. However, under lossy context compression in a compressor-decoder setup, we observe a Size-Fidelity Paradox: increasing the compressor size can lessen the faithfulness of reconstructed contexts though training loss decreases. Through extensive experiments across models from 0.6B to 90B, we coin this paradox arising from two dominant factors: 1) knowledge overwriting: larger models increasingly replace source facts with their own prior beliefs, e.g., ``the white strawberry'' $\to$ ``the red strawberry''; and 2) semantic drift: larger models tend to paraphrase or restructure content instead of reproducing it verbatim, e.g., ``Alice hit Bob'' $\to$ ``Bob hit Alice''. By holding model size fixed, we reflect on the emergent properties of compressed context representations. We show that the culprit is not parameter count itself, but the excessive semantic capacity and amplified generative uncertainty that accompany scaling. Specifically, the increased rank of context embeddings facilitates prior knowledge intrusion, whereas higher entropy over token prediction distributions promotes rewriting. Our results complement existing evaluations over context compression paradigm, underpinning a breakdown in scaling laws for faithful preservation in open-ended generation.

</details>


### [89] [Fully-automated sleep staging: multicenter validation of a generalizable deep neural network for Parkinson's disease and isolated REM sleep behavior disorder](https://arxiv.org/abs/2602.09793)
*Jesper Strøm,Casper Skjærbæk,Natasha Becker Bertelsen,Steffen Torpe Simonsen,Niels Okkels,David Bertram,Sinah Röttgen,Konstantin Kufer,Kaare B. Mikkelsen,Marit Otto,Poul Jørgen Jennum,Per Borghammer,Michael Sommerauer,Preben Kidmose*

Main category: cs.LG

TL;DR: 本研究针对帕金森病和孤立性REM睡眠行为障碍患者的睡眠分期挑战，通过微调U-Sleep深度学习模型，显著提升了在神经退行性疾病患者中的睡眠分期准确性，并采用置信度阈值优化了REM睡眠检测。


<details>
  <summary>Details</summary>
Motivation: 手动睡眠分期在神经退行性疾病中特别困难，因为EEG异常和碎片化睡眠，这成为大规模部署RBD筛查技术的瓶颈。需要开发能够准确分期PD和iRBD患者睡眠的自动化工具。

Method: 使用预训练的U-Sleep模型（基于19,236个非神经退行性PSG数据），在两个研究中心（PACE和CBC）的PD、iRBD和对照数据上进行微调。在独立数据集（DCSM）上评估，对模型与人工评分不一致的PSG进行二次盲评，并应用置信度阈值优化REM睡眠分期。

Result: 微调后模型在PACE/CBC上的κ值从0.66提升至0.74；在独立测试集DCSM上，平均κ值从0.60提升至0.64，中位数从0.64提升至0.69。置信度阈值使REM睡眠正确识别率从85%提升至95.5%，同时为95%的受试者保留了足够的REM睡眠时间。

Conclusion: 通过微调和置信度阈值优化，U-Sleep模型能够有效应用于PD和iRBD患者的睡眠分期，为解决神经退行性疾病中睡眠分期困难提供了可行的自动化解决方案。

Abstract: Isolated REM sleep behavior disorder (iRBD) is a key prodromal marker of Parkinson's disease (PD), and video-polysomnography (vPSG) remains the diagnostic gold standard. However, manual sleep staging is particularly challenging in neurodegenerative diseases due to EEG abnormalities and fragmented sleep, making PSG assessments a bottleneck for deploying new RBD screening technologies at scale. We adapted U-Sleep, a deep neural network, for generalizable sleep staging in PD and iRBD. A pretrained U-Sleep model, based on a large publicly available, multisite non-neurodegenerative dataset (PUB; 19,236 PSGs across 12 sites), was fine-tuned on research datasets from two centers (Lundbeck Foundation Parkinson's Disease Research Center (PACE) and the Cologne-Bonn Cohort (CBC); 112 PD, 138 iRBD, 89 age-matched controls. The resulting model was evaluated on an independent dataset from the Danish Center for Sleep Medicine (DCSM; 81 PD, 36 iRBD, 87 sleep-clinic controls). A subset of PSGs with low agreement between the human rater and the model (\k{appa} < 0.6) was re-scored by a second blinded human rater to identify sources of disagreement. Finally, we applied confidence-based thresholds to optimize REM sleep staging. The pretrained model achieved mean \k{appa} = 0.81 in PUB, but \k{appa} = 0.66 when applied directly to PACE/CBC. By fine-tuning the model, we developed a generalized model with \k{appa} = 0.74 on PACE/CBC (p < 0.001 vs. the pretrained model). In DCSM, mean and median \k{appa} increased from 0.60 to 0.64 (p < 0.001) and 0.64 to 0.69 (p < 0.001), respectively. In the interrater study, PSGs with low agreement between the model and the initial scorer showed similarly low agreement between human scorers. Applying a confidence threshold increased the proportion of correctly identified REM sleep epochs from 85% to 95.5%, while preserving sufficient (> 5 min) REM sleep for 95% of subjects.

</details>


### [90] [A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer](https://arxiv.org/abs/2602.09810)
*Azka Nasir,Fatima Dossa,Muhammad Ahmed Atif,Mohammad Ahmed Atif*

Main category: cs.LG

TL;DR: DDQN架构比Dueling DQN在跨环境迁移学习中更稳健，能避免负迁移，而Dueling DQN在相同条件下会出现性能下降和不稳定优化。


<details>
  <summary>Details</summary>
Motivation: 研究深度强化学习中迁移学习的稳定性问题，探索不同网络架构（DDQN vs Dueling DQN）在跨环境迁移时的表现差异，特别是当源任务（CartPole）和目标任务（LunarLander）存在结构差异时。

Method: 使用控制性实证研究，采用固定的分层表示迁移协议，在相同超参数和训练条件下比较DDQN和Dueling DQN。以CartPole为源任务，LunarLander为目标任务，使用从头训练的基线智能体作为参照。

Result: DDQN在测试设置下始终避免负迁移，在目标环境中保持与基线相当的学习动态；而Dueling DQN在相同条件下始终表现出负迁移，表现为奖励下降和优化行为不稳定。多随机种子的统计分析确认了显著的性能差距。

Conclusion: 网络架构的归纳偏置与基于价值的深度强化学习在跨环境迁移中的鲁棒性密切相关，DDQN比Dueling DQN在研究的迁移协议下表现出更好的迁移稳定性。

Abstract: Transfer learning in deep reinforcement learning is often motivated by improved stability and reduced training cost, but it can also fail under substantial domain shift. This paper presents a controlled empirical study examining how architectural differences between Double Deep Q-Networks (DDQN) and Dueling DQN influence transfer behavior across environments. Using CartPole as a source task and LunarLander as a structurally distinct target task, we evaluate a fixed layer-wise representation transfer protocol under identical hyperparameters and training conditions, with baseline agents trained from scratch used to contextualize transfer effects. Empirical results show that DDQN consistently avoids negative transfer under the examined setup and maintains learning dynamics comparable to baseline performance in the target environment. In contrast, Dueling DQN consistently exhibits negative transfer under identical conditions, characterized by degraded rewards and unstable optimization behavior. Statistical analysis across multiple random seeds confirms a significant performance gap under transfer. These findings suggest that architectural inductive bias is strongly associated with robustness to cross-environment transfer in value-based deep reinforcement learning under the examined transfer protocol.

</details>


### [91] [PlugSI: Plug-and-Play Test-Time Graph Adaptation for Spatial Interpolation](https://arxiv.org/abs/2602.09824)
*Xuhang Wu,Zhuoxuan Liang,Wei Li,Xiaohua Jia,Sumi Helal*

Main category: cs.LG

TL;DR: PlugSI是一个即插即用的时空插值框架，通过未知拓扑适配器和时序平衡适配器，在测试时动态适应新图结构，提升现有图基插值方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和边缘计算发展，大规模传感器部署成本高昂。现有基于图的时空插值方法依赖预训练模型，无法适应测试时更大、未见过的图结构，且忽视了测试数据的利用。

Method: 提出PlugSI框架：1) 未知拓扑适配器(UTA)，在测试时适应每个小批量的新图结构；2) 时序平衡适配器(TBA)，维护稳定的历史共识来指导UTA适应，防止当前批次噪声导致的漂移。

Result: 实验表明PlugSI可以无缝集成到现有基于图的时空插值方法中，并带来显著改进（如MAE降低10.81%）。

Conclusion: PlugSI解决了现有图基时空插值方法的局限性，通过测试时自适应机制实现了更好的泛化性能，为大规模传感器网络部署提供了更有效的解决方案。

Abstract: With the rapid advancement of IoT and edge computing, sensor networks have become indispensable, driving the need for large-scale sensor deployment. However, the high deployment cost hinders their scalability. To tackle the issues, Spatial Interpolation (SI) introduces virtual sensors to infer readings from observed sensors, leveraging graph structure. However, current graph-based SI methods rely on pre-trained models, lack adaptation to larger and unseen graphs at test-time, and overlook test data utilization. To address these issues, we propose PlugSI, a plug-and-play framework that refines test-time graph through two key innovations. First, we design an Unknown Topology Adapter (UTA) that adapts to the new graph structure of each small-batch at test-time, enhancing the generalization of SI pre-trained models. Second, we introduce a Temporal Balance Adapter (TBA) that maintains a stable historical consensus to guide UTA adaptation and prevent drifting caused by noise in the current batch. Empirically, extensive experiments demonstrate PlugSI can be seamlessly integrated into existing graph-based SI methods and provide significant improvement (e.g., a 10.81% reduction in MAE).

</details>


### [92] [CoFEH: LLM-driven Feature Engineering Empowered by Collaborative Bayesian Hyperparameter Optimization](https://arxiv.org/abs/2602.09851)
*Beicheng Xu,Keyao Ding,Wei Liu,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: CoFEH是一个协作框架，将基于LLM的特征工程与贝叶斯超参数优化交织进行，通过相互条件机制实现端到端的AutoML优化。


<details>
  <summary>Details</summary>
Motivation: 传统AutoML方法将特征工程视为黑盒搜索，局限于预定义搜索空间且缺乏领域意识。现有LLM方法无法构建自由形式的特征工程管道，且很少与超参数优化联合优化，导致贪婪的"先FE后HPO"工作流无法捕捉FE-HPO的强交互作用。

Method: CoFEH包含三个核心组件：1) 基于思维树(ToT)的LLM驱动FE优化器探索灵活的特征工程管道；2) 贝叶斯优化模块解决HPO；3) 动态优化器选择器通过自适应调度FE和HPO步骤实现交织优化。关键创新是引入LLM和BO之间的相互条件机制，共享上下文以实现相互知情的决策。

Result: 实验表明CoFEH不仅优于传统和基于LLM的特征工程基线方法，而且在联合优化下实现了更优的端到端性能。

Conclusion: CoFEH通过将LLM驱动的特征工程与贝叶斯超参数优化交织进行，并引入相互条件机制，有效解决了传统AutoML中特征工程的瓶颈问题，实现了更强大的端到端AutoML优化。

Abstract: Feature Engineering (FE) is pivotal in automated machine learning (AutoML) but remains a bottleneck for traditional methods, which treat it as a black-box search, operating within rigid, predefined search spaces and lacking domain awareness. While Large Language Models (LLMs) offer a promising alternative by leveraging semantic reasoning to generate unbounded operators, existing methods fail to construct free-form FE pipelines, remaining confined to isolated subtasks such as feature generation. Most importantly, they are rarely optimized jointly with hyperparameter optimization (HPO) of the ML model, leading to greedy "FE-then-HPO" workflows that cannot capture strong FE-HPO interactions. In this paper, we present CoFEH, a collaborative framework that interleaves LLM-based FE and Bayesian HPO for robust end-to-end AutoML. CoFEH uses an LLM-driven FE optimizer powered by Tree of Thought (ToT) to explore flexible FE pipelines, a Bayesian optimization (BO) module to solve HPO, and a dynamic optimizer selector that realizes interleaved optimization by adaptively scheduling FE and HPO steps. Crucially, we introduce a mutual conditioning mechanism that shares context between LLM and BO, enabling mutually informed decisions. Experiments show that CoFEH not only outperforms traditional and LLM-based FE baselines, but also achieves superior end-to-end performance under joint optimization.

</details>


### [93] [Differentiable Tripartite Modularity for Clustering Heterogeneous Graphs](https://arxiv.org/abs/2602.09864)
*Benoît Hurpeau*

Main category: cs.LG

TL;DR: 提出了可微分的三部图模块度目标，用于在包含三种节点类型的异构图上进行端到端的社区检测，避免了显式构建稠密三阶张量。


<details>
  <summary>Details</summary>
Motivation: 当前可微分模块度方法（如DMoN）主要针对同质图和二部图，难以扩展到包含三种以上实体类型的高阶关系结构中，而异构图聚类是图学习中的核心挑战。

Method: 提出了三部图模块度的可微分公式化，通过加权共路径定义社区结构，采用精确因子化计算避免显式构建稠密三阶张量，引入枢纽节点的结构归一化控制极端度异质性。

Result: 在大规模城市地籍数据上验证了该框架，表现出稳健的收敛行为和产生空间一致的划分，保持了边数量的线性复杂度。

Conclusion: 可微分三部图模块度可作为异构图无监督聚类的通用方法构建模块，能够与图神经网络联合优化实现端到端学习。

Abstract: Clustering heterogeneous relational data remains a central challenge in graph learning, particularly when interactions involve more than two types of entities. While differentiable modularity objectives such as DMoN have enabled end-to-end community detection on homogeneous and bipartite graphs, extending these approaches to higher-order relational structures remains non-trivial.
  In this work, we introduce a differentiable formulation of tripartite modularity for graphs composed of three node types connected through mediated interactions. Community structure is defined in terms of weighted co-paths across the tripartite graph, together with an exact factorized computation that avoids the explicit construction of dense third-order tensors. A structural normalization at pivot nodes is introduced to control extreme degree heterogeneity and ensure stable optimization.
  The resulting objective can be optimized jointly with a graph neural network in an end-to-end manner, while retaining linear complexity in the number of edges. We validate the proposed framework on large-scale urban cadastral data, where it exhibits robust convergence behavior and produces spatially coherent partitions. These results highlight differentiable tripartite modularity as a generic methodological building block for unsupervised clustering of heterogeneous graphs.

</details>


### [94] [Statistical benchmarking of transformer models in low signal-to-noise time-series forecasting](https://arxiv.org/abs/2602.09869)
*Cyril Garcia,Guillaume Remy*

Main category: cs.LG

TL;DR: 研究在低数据量下（仅几年日观测数据）的多元时间序列预测，发现双向注意力Transformer在多种设置下优于传统方法，特别是在低信噪比环境中，动态稀疏化训练能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer架构在低数据量多元时间序列预测中的性能，特别是在只有几年日观测数据的场景下，探索其在噪声环境中的表现和泛化能力。

Method: 使用已知时间与横截面依赖结构的合成生成过程，进行自助法实验，通过样本外与最优地面真实预测器的相关性直接评估。引入双向注意力Transformer（交替使用时间和横截面自注意力）和训练中应用的注意力矩阵动态稀疏化程序。

Result: 双向注意力Transformer在广泛设置下（包括低信噪比环境）优于Lasso、提升方法和全连接多层感知机等标准基线。动态稀疏化在噪声环境中特别有效，当目标变量与最优预测器相关性仅为几个百分点时效果显著。

Conclusion: Transformer架构在低数据量时间序列预测中表现优异，动态稀疏化能提升噪声环境下的性能。学习到的注意力模式显示出可解释结构，并与经典回归中的稀疏诱导正则化有联系，解释了这些模型在噪声下有效泛化的原因。

Abstract: We study the performance of transformer architectures for multivariate time-series forecasting in low-data regimes consisting of only a few years of daily observations. Using synthetically generated processes with known temporal and cross-sectional dependency structures and varying signal-to-noise ratios, we conduct bootstrapped experiments that enable direct evaluation via out-of-sample correlations with the optimal ground-truth predictor. We show that two-way attention transformers, which alternate between temporal and cross-sectional self-attention, can outperform standard baselines-Lasso, boosting methods, and fully connected multilayer perceptrons-across a wide range of settings, including low signal-to-noise regimes. We further introduce a dynamic sparsification procedure for attention matrices applied during training, and demonstrate that it becomes significantly effective in noisy environments, where the correlation between the target variable and the optimal predictor is on the order of a few percent. Analysis of the learned attention patterns reveals interpretable structure and suggests connections to sparsity-inducing regularization in classical regression, providing insight into why these models generalize effectively under noise.

</details>


### [95] [Safeguarding Privacy: Privacy-Preserving Detection of Mind Wandering and Disengagement Using Federated Learning in Online Education](https://arxiv.org/abs/2602.09904)
*Anna Bodonhelyi,Mengdi Wang,Efe Bozkir,Babette Bühler,Enkelejda Kasneci*

Main category: cs.LG

TL;DR: 提出基于联邦学习的视频注意力检测框架，用于在线学习中行为与认知脱离的隐私保护检测


<details>
  <summary>Details</summary>
Motivation: 在线课程缺乏教师直接支持，学习者容易走神和脱离，传统机器学习方法需要共享敏感数据引发隐私担忧

Method: 采用跨设备联邦学习框架，利用面部表情和注视特征构建认知脱离检测模型，并针对眼镜佩戴进行特征优化

Result: 在五个数据集上验证，联邦学习算法表现良好，为隐私保护的教育技术提供了有前景的解决方案

Conclusion: 联邦学习框架能有效保护用户隐私，同时实现实时学习者支持，促进在线学习参与度

Abstract: Since the COVID-19 pandemic, online courses have expanded access to education, yet the absence of direct instructor support challenges learners' ability to self-regulate attention and engagement. Mind wandering and disengagement can be detrimental to learning outcomes, making their automated detection via video-based indicators a promising approach for real-time learner support. However, machine learning-based approaches often require sharing sensitive data, raising privacy concerns. Federated learning offers a privacy-preserving alternative by enabling decentralized model training while also distributing computational load. We propose a framework exploiting cross-device federated learning to address different manifestations of behavioral and cognitive disengagement during remote learning, specifically behavioral disengagement, mind wandering, and boredom. We fit video-based cognitive disengagement detection models using facial expressions and gaze features. By adopting federated learning, we safeguard users' data privacy through privacy-by-design and introduce a novel solution with the potential for real-time learner support. We further address challenges posed by eyeglasses by incorporating related features, enhancing overall model performance. To validate the performance of our approach, we conduct extensive experiments on five datasets and benchmark multiple federated learning algorithms. Our results show great promise for privacy-preserving educational technologies promoting learner engagement.

</details>


### [96] [Drug Release Modeling using Physics-Informed Neural Networks](https://arxiv.org/abs/2602.09963)
*Daanish Aleem Qureshi,Khemraj Shukla,Vikas Srivastava*

Main category: cs.LG

TL;DR: 使用物理信息神经网络和贝叶斯物理信息神经网络预测药物释放，相比传统模型误差降低40%，仅需6%释放时间数据即可准确预测长期释放。


<details>
  <summary>Details</summary>
Motivation: 传统药物释放模型（如Fick、Higuchi、Peppas）基于简化假设，在复杂几何形状和释放机制中准确性有限。需要一种能结合物理定律和有限实验数据的方法，实现从短期测量准确预测长期释放。

Method: 提出基于物理信息神经网络和贝叶斯物理信息神经网络的新方法，将Fick第二扩散定律嵌入神经网络损失函数中，使用10,000个拉丁超立方配置点，结合已发表的实验数据集，评估平面、1D褶皱和2D皱褶薄膜的药物释放性能。

Result: 相比传统基线模型，该方法在所有薄膜类型中平均误差降低达40%。对于平面薄膜，仅使用前6%释放时间数据（减少94%实验时间）即可达到RMSE<0.05；对于褶皱和皱褶薄膜，仅需33%释放时间数据。贝叶斯物理信息神经网络在噪声条件下提供更可靠的不确定性量化。

Conclusion: 通过将物理定律与实验数据相结合，该框架能从短期测量实现高度准确的长期释放预测，为加速表征和早期药物释放系统配方提供了实用途径。

Abstract: Accurate modeling of drug release is essential for designing and developing controlled-release systems. Classical models (Fick, Higuchi, Peppas) rely on simplifying assumptions that limit their accuracy in complex geometries and release mechanisms. Here, we propose a novel approach using Physics-Informed Neural Networks (PINNs) and Bayesian PINNs (BPINNs) for predicting release from planar, 1D-wrinkled, and 2D-crumpled films. This approach uniquely integrates Fick's diffusion law with limited experimental data to enable accurate long-term predictions from short-term measurements, and is systematically benchmarked against classical drug release models. We embedded Fick's second law into PINN as loss with 10,000 Latin-hypercube collocation points and utilized previously published experimental datasets to assess drug release performance through mean absolute error (MAE) and root mean square error (RMSE), considering noisy conditions and limited-data scenarios. Our approach reduced mean error by up to 40% relative to classical baselines across all film types. The PINN formulation achieved RMSE <0.05 utilizing only the first 6% of the release time data (reducing 94% of release time required for the experiments) for the planar film. For wrinkled and crumpled films, the PINN reached RMSE <0.05 in 33% of the release time data. BPINNs provide tighter and more reliable uncertainty quantification under noise. By combining physical laws with experimental data, the proposed framework yields highly accurate long-term release predictions from short-term measurements, offering a practical route for accelerated characterization and more efficient early-stage drug release system formulation.

</details>


### [97] [Causal Identification in Multi-Task Demand Learning with Confounding](https://arxiv.org/abs/2602.09969)
*Varun Gupta,Vijay Kamble*

Main category: cs.LG

TL;DR: 提出DCMOML框架解决零售定价中多任务需求学习的因果识别问题，通过设计元学习器的信息集来处理价格内生性，在每任务样本有限的情况下实现因果参数估计。


<details>
  <summary>Details</summary>
Motivation: 零售定价中需要估计大量决策情境下的异质性价格响应函数，但每个情境的历史价格变化有限且存在内生性问题（价格由管理者或算法选择，可能与未观测的需求决定因素相关），传统方法如池化回归和元学习无法识别因果价格效应。

Method: 提出决策条件掩码结果元学习（DCMOML）框架，通过精心设计元学习器的信息集来利用跨任务异质性，同时考虑内生决策历史。在价格适应性限制下，该方法能够识别任务特定因果参数的条件均值。

Result: DCMOML方法能够在价格内生性和每任务样本有限的情况下实现因果识别，为大规模需求估计提供了理论保证，为在操作环境中部署因果数据驱动定价模型奠定了基础。

Conclusion: 该研究解决了多任务需求学习中的内生性问题，提出的DCMOML框架为零售定价等实际应用中的因果推断提供了新方法，特别适用于样本有限且存在价格内生性的场景。

Abstract: We study a canonical multi-task demand learning problem motivated by retail pricing, in which a firm seeks to estimate heterogeneous linear price-response functions across a large collection of decision contexts. Each context is characterized by rich observable covariates yet typically exhibits only limited historical price variation, motivating the use of multi-task learning to borrow strength across tasks. A central challenge in this setting is endogeneity: historical prices are chosen by managers or algorithms and may be arbitrarily correlated with unobserved, task-level demand determinants. Under such confounding by latent fundamentals, commonly used approaches, such as pooled regression and meta-learning, fail to identify causal price effects.
  We propose a new estimation framework that achieves causal identification despite arbitrary dependence between prices and latent task structure. Our approach, Decision-Conditioned Masked-Outcome Meta-Learning (DCMOML), involves carefully designing the information set of a meta-learner to leverage cross-task heterogeneity while accounting for endogenous decision histories. Under a mild restriction on price adaptivity in each task, we establish that this method identifies the conditional mean of the task-specific causal parameters given the designed information set. Our results provide guarantees for large-scale demand estimation with endogenous prices and small per-task samples, offering a principled foundation for deploying causal, data-driven pricing models in operational environments.

</details>


### [98] [Online Monitoring Framework for Automotive Time Series Data using JEPA Embeddings](https://arxiv.org/abs/2602.09985)
*Alexander Fertig,Karthikeyan Chandra Sekaran,Lakshman Balasubramanian,Michael Botsch*

Main category: cs.LG

TL;DR: 提出基于JEPA自监督嵌入的在线监控框架，用于无标签异常检测，在nuScenes数据集上验证有效


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要安全监控，但未知异常通常没有标签，需要无监督异常检测方法

Method: 使用JEPA自监督预测任务创建对象嵌入表示，然后将这些丰富嵌入输入到现有异常检测方法中

Result: 在公开的真实世界nuScenes数据集上验证了框架的有效性

Conclusion: 提出的基于JEPA自监督嵌入的在线监控框架能够有效检测对象状态表示中的异常，特别适用于现实环境中未知异常的检测

Abstract: As autonomous vehicles are rolled out, measures must be taken to ensure their safe operation. In order to supervise a system that is already in operation, monitoring frameworks are frequently employed. These run continuously online in the background, supervising the system status and recording anomalies. This work proposes an online monitoring framework to detect anomalies in object state representations. Thereby, a key challenge is creating a framework for anomaly detection without anomaly labels, which are usually unavailable for unknown anomalies. To address this issue, this work applies a self-supervised embedding method to translate object data into a latent representation space. For this, a JEPA-based self-supervised prediction task is constructed, allowing training without anomaly labels and the creation of rich object embeddings. The resulting expressive JEPA embeddings serve as input for established anomaly detection methods, in order to identify anomalies within object state representations. This framework is particularly useful for applications in real-world environments, where new or unknown anomalies may occur during operation for which there are no labels available. Experiments performed on the publicly available, real-world nuScenes dataset illustrate the framework's capabilities.

</details>


### [99] [Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions](https://arxiv.org/abs/2602.09987)
*J Rosser,Robert Kirk,Edward Grefenstette,Jakob Foerster,Laura Ruis*

Main category: cs.LG

TL;DR: Infusion框架使用影响函数近似计算训练文档的微小扰动，通过参数偏移诱导目标模型行为改变，在视觉和语言领域的数据投毒任务中有效。


<details>
  <summary>Details</summary>
Motivation: 探索反向问题：如何通过精心设计的训练数据来诱导模型行为，而不是像传统影响函数那样将模型行为归因于训练文档。这有助于理解训练数据可解释性对攻击者和防御者的重要性。

Method: 使用可扩展的影响函数近似方法计算训练文档的微小扰动，通过参数偏移诱导目标模型行为改变。在CIFAR-10和语言任务中评估，测试跨架构的迁移性。

Result: 在CIFAR-10上，仅修改0.2%训练文档（100/45,000）即可与插入少量显式行为示例的基线方法竞争。方法能跨架构迁移（ResNet↔CNN），单一投毒语料可影响多个独立训练模型。语言实验中，在模型已学习行为上最有效。

Conclusion: 微小、细微的训练数据编辑可以系统性地塑造模型行为，强调了训练数据可解释性对攻击者和防御者的重要性。代码已开源。

Abstract: Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.

</details>


### [100] [Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning](https://arxiv.org/abs/2602.10006)
*Shijie Zhang,Xiang Guo,Rujun Guo,Shaoyu Liu,Xiaozhao Wang,Guanjun Jiang,Kevin Zhang*

Main category: cs.LG

TL;DR: 提出AFRL范式：首token输出相关性分数，后续生成结构化解释，结合SFT+RL训练，通过模式平衡优化解决模式塌陷问题，实现高性能低延迟搜索相关性模型。


<details>
  <summary>Details</summary>
Motivation: 搜索相关性模型面临低延迟与高性能的矛盾：在线系统需要毫秒级响应，而大语言模型具有可解释推理能力但延迟高。需要同时满足响应速度和保持推理可解释性。

Method: 1) 提出AFRL范式：首token输出相关性分数，后续生成结构化逻辑解释；2) 采用SFT+RL训练流程；3) 提出模式平衡优化策略，在Stepwise-GRPO训练中加入SFT辅助损失；4) 构建自动化指令进化系统和多阶段课程学习确保数据质量。

Result: 32B教师模型达到最先进性能；AFRL架构支持高效知识蒸馏，成功将专家级逻辑迁移到0.6B模型，在推理深度和部署延迟之间取得平衡。

Conclusion: AFRL范式成功解决了搜索相关性模型的延迟与性能矛盾，通过模式平衡优化避免了RL训练中的模式塌陷问题，实现了高性能低延迟的搜索相关性模型，并支持高效的知识蒸馏。

Abstract: Building a search relevance model that achieves both low latency and high performance is a long-standing challenge in the search industry. To satisfy the millisecond-level response requirements of online systems while retaining the interpretable reasoning traces of Large Language Models (LLMs), we propose a novel \textbf{Answer-First, Reason Later (AFRL)} paradigm. This paradigm requires the model to output the definitive relevance score in the very first token, followed by a structured logical explanation. Inspired by the success of reasoning models, we adopt a "Supervised Fine-Tuning (SFT) + Reinforcement Learning (RL)" pipeline to achieve AFRL. However, directly applying existing RL training often leads to \textbf{mode collapse} in the search relevance task, where the model forgets complex long-tail rules in pursuit of high rewards. From an information theory perspective: RL inherently minimizes the \textbf{Reverse KL divergence}, which tends to seek probability peaks (mode-seeking) and is prone to "reward hacking." On the other hand, SFT minimizes the \textbf{Forward KL divergence}, forcing the model to cover the data distribution (mode-covering) and effectively anchoring expert rules. Based on this insight, we propose a \textbf{Mode-Balanced Optimization} strategy, incorporating an SFT auxiliary loss into Stepwise-GRPO training to balance these two properties. Furthermore, we construct an automated instruction evolution system and a multi-stage curriculum to ensure expert-level data quality. Extensive experiments demonstrate that our 32B teacher model achieves state-of-the-art performance. Moreover, the AFRL architecture enables efficient knowledge distillation, successfully transferring expert-level logic to a 0.6B model, thereby reconciling reasoning depth with deployment latency.

</details>


### [101] [A Task-Centric Theory for Iterative Self-Improvement with Easy-to-Hard Curricula](https://arxiv.org/abs/2602.10014)
*Chenruo Liu,Yijun Dong,Yiqiu Shen,Qi Lei*

Main category: cs.LG

TL;DR: 该论文为迭代自改进提供了理论分析，揭示了奖励过滤分布下的有限样本保证，并证明了简单到困难课程学习的优势


<details>
  <summary>Details</summary>
Motivation: 虽然迭代自改进在实践中取得了成功，但其在有限样本设置下的理论基础仍然有限。论文旨在为这种生成式迭代过程建立理论框架

Method: 将每轮自改进建模为在奖励过滤分布上的最大似然微调，推导期望奖励的有限样本保证。采用任务中心视角，考虑多难度级别的推理任务

Result: 分析揭示了明确的反馈循环：更好的模型每轮接受更多数据，支持持续自改进同时解释改进饱和。证明了模型初始化、任务难度和样本预算的量化条件，在这些条件下简单到困难课程学习优于固定任务混合训练

Conclusion: 该研究为迭代自改进提供了理论分析框架，揭示了其动态机制，并通过蒙特卡洛模拟和图基推理任务的受控实验验证了分析结果

Abstract: Iterative self-improvement fine-tunes an autoregressive large language model (LLM) on reward-verified outputs generated by the LLM itself. In contrast to the empirical success of self-improvement, the theoretical foundation of this generative, iterative procedure in a practical, finite-sample setting remains limited. We make progress toward this goal by modeling each round of self-improvement as maximum-likelihood fine-tuning on a reward-filtered distribution and deriving finite-sample guarantees for the expected reward. Our analysis reveals an explicit feedback loop where better models accept more data per iteration, supporting sustained self-improvement while explaining eventual saturation of such improvement. Adopting a task-centric view by considering reasoning tasks with multiple difficulty levels, we further prove quantifiable conditions on model initialization, task difficulty, and sample budget where easy-to-hard curricula provably achieve better guarantees than training on fixed mixtures of tasks. Our analyses are validated via Monte-Carlo simulations and controlled experiments on graph-based reasoning tasks.

</details>


### [102] [ADORA: Training Reasoning Models with Dynamic Advantage Estimation on Reinforcement Learning](https://arxiv.org/abs/2602.10019)
*Qingnan Ren,Shiting Huang,Zhen Fang,Zehui Chen,Lin Chen,Lijun Li,Feng Zhao*

Main category: cs.LG

TL;DR: ADORA框架通过动态调整优势函数权重，根据在线模型rollout中样本的演化效用自适应分类训练数据，实现更高效的政策优化。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用静态优势估计，忽略了训练样本效用的动态变化，导致信用分配效率低下、收敛速度慢和学习不稳定。

Method: 提出ADORA框架，通过在线rollout自适应地动态调整优势函数权重，将训练数据分类为暂时有利和不利样本，优先学习更有信息量的经验。

Result: 在多种模型家族和不同数据规模上的广泛评估表明，ADORA能显著提升几何和数学任务中的长推理能力，获得显著性能提升且无需敏感超参数调优。

Conclusion: ADORA是一个稳健高效的政策优化框架，能无缝集成到现有算法中，通过动态优势调整实现更高效的政策更新。

Abstract: Reinforcement learning has become a cornerstone technique for developing reasoning models in complex tasks, ranging from mathematical problem-solving to imaginary reasoning. The optimization of these models typically relies on policy gradient methods, whose efficacy hinges on the accurate estimation of an advantage function. However, prevailing methods typically employ static advantage estimation, a practice that leads to inefficient credit assignment by neglecting the dynamic utility of training samples over time. This limitation results in suboptimal policy updates, which in turn manifest as slower convergence rates and increased learning instability, as models fail to adapt to evolving sample utilities effectively. To address this problem, we introduce \textbf{ADORA} (\textbf{A}dvantage \textbf{D}ynamics via \textbf{O}nline \textbf{R}ollout \textbf{A}daptation), a novel framework for policy optimization. ADORA dynamically adjusts the advantage function's weighting by adaptively categorizing training data into temporarily advantageous and disadvantageous samples, based on their evolving utility during online model rollouts. This tailored data differentiation strategy allows ADORA to be seamlessly integrated into existing policy optimization algorithms without significant architectural modifications, enabling the policy to prioritize learning from more informative experiences and thereby achieve more efficient policy updates. Extensive evaluations across diverse model families and varying data scales demonstrate that ADORA is a robust and efficient framework. It significantly enhances long reasoning in both geometric and mathematical tasks, consistently achieving notable performance gains without requiring sensitive hyperparameter tuning.

</details>


### [103] [Position: Message-passing and spectral GNNs are two sides of the same coin](https://arxiv.org/abs/2602.10031)
*Antonis Vasileiou,Juan Cervino,Pascal Frossard,Charilaos I. Kanatsoulis,Christopher Morris,Michael T. Schaub,Pierre Vandergheynst,Zhiyang Wang,Guy Wolf,Ron Levie*

Main category: cs.LG

TL;DR: 该论文认为MPNNs和谱GNNs之间的区分是人为的，阻碍了领域发展，提出两者本质上是图信号上置换等变算子的不同参数化，具有互补优势，应统一框架而非对立。


<details>
  <summary>Details</summary>
Motivation: 当前图神经网络领域将MPNNs和谱GNNs划分为两个独立的研究传统，这种人为划分阻碍了领域进步。作者认为需要打破这种对立，建立统一的理论框架。

Method: 提出统一视角：将MPNNs和谱GNNs都理解为图信号上置换等变算子的不同参数化。从这一视角分析两者的表达能力和理论特性。

Result: 发现许多流行架构在表达能力上是等价的，真正的差异只出现在特定机制中。MPNNs擅长离散结构和表达能力分析，谱GNNs擅长平滑性、稳定性等谱特性分析。

Conclusion: 图学习领域的进步需要清晰理解这两类GNNs的关键异同，并在共同的理论框架下统一它们，而不是将它们视为竞争范式。两者具有互补优势，应协同发展。

Abstract: Graph neural networks (GNNs) are commonly divided into message-passing neural networks (MPNNs) and spectral graph neural networks, reflecting two largely separate research traditions in machine learning and signal processing. This paper argues that this divide is mostly artificial, hindering progress in the field. We propose a viewpoint in which both MPNNs and spectral GNNs are understood as different parametrizations of permutation-equivariant operators acting on graph signals. From this perspective, many popular architectures are equivalent in expressive power, while genuine gaps arise only in specific regimes. We further argue that MPNNs and spectral GNNs offer complementary strengths. That is, MPNNs provide a natural language for discrete structure and expressivity analysis using tools from logic and graph isomorphism research, while the spectral perspective provides principled tools for understanding smoothing, bottlenecks, stability, and community structure. Overall, we posit that progress in graph learning will be accelerated by clearly understanding the key similarities and differences between these two types of GNNs, and by working towards unifying these perspectives within a common theoretical and conceptual framework rather than treating them as competing paradigms.

</details>


### [104] [Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning](https://arxiv.org/abs/2602.10044)
*Akshay Mete,Shahid Aamir Sheikh,Tzu-Hsiang Lin,Dileep Kalathil,P. R. Kumar*

Main category: cs.LG

TL;DR: 提出乐观世界模型（OWMs），一种将乐观探索融入世界模型学习的可扩展框架，通过乐观动力学损失偏置想象转移至高回报结果，无需不确定性估计或约束优化。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的高效探索仍然是一个核心挑战，特别是在稀疏奖励环境中。现有方法如UCB需要不确定性估计或约束优化，限制了可扩展性。

Method: 将经典的自适应控制中的奖励偏置最大似然估计（RBMLE）引入深度RL，通过添加乐观动力学损失来偏置想象转移至高回报结果，完全基于梯度，无需不确定性估计或约束优化。

Result: 在两种最先进的世界模型架构（DreamerV3和STORM）中实例化OWMs，相比基线版本在样本效率和累积回报方面都有显著提升。

Conclusion: OWMs提供了一种原则性且可扩展的乐观探索框架，可与现有世界模型框架即插即用，仅需对标准训练流程进行最小修改，就能显著提升探索性能。

Abstract: Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation (RBMLE) from adaptive control into deep RL. In contrast to upper confidence bound (UCB)-style exploration methods, OWMs incorporate optimism directly into model learning by augmentation with an optimistic dynamics loss that biases imagined transitions toward higher-reward outcomes. This fully gradient-based loss requires neither uncertainty estimates nor constrained optimization. Our approach is plug-and-play with existing world model frameworks, preserving scalability while requiring only minimal modifications to standard training procedures. We instantiate OWMs within two state-of-the-art world model architectures, leading to Optimistic DreamerV3 and Optimistic STORM, which demonstrate significant improvements in sample efficiency and cumulative return compared to their baseline counterparts.

</details>


### [105] [Long Chain-of-Thought Compression via Fine-Grained Group Policy Optimization](https://arxiv.org/abs/2602.10048)
*Xinchen Han,Hossam Afifi,Michel Marot,Xilu Wang,Lu Yin*

Main category: cs.LG

TL;DR: FGO是一种强化学习算法，通过细粒度分组策略优化来压缩LLM的Chain-of-Thought推理，减少计算成本同时保持性能，并解决了GRPO的数据利用低效和熵崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的Chain-of-Thought推理往往过于冗长，增加了计算成本和延迟，但性能提升不成比例。现有方法如GRPO存在数据利用效率低和熵崩溃两个主要限制。

Method: 提出细粒度分组策略优化(FGO)，这是一种强化学习算法，通过将分组响应细分为更小的单元，并根据长度和熵分配适当权重，实现有效的CoT压缩。FGO作为GRPO的增强变体，解决了其两个主要限制。

Result: 在多个推理LLM和基准测试（包括MATH500、AIME24、AMC23和Minerva）上的实验结果表明，FGO实现了高效的CoT压缩而不降低性能，同时解决了GRPO的关键限制。

Conclusion: FGO能够有效压缩LLM的Chain-of-Thought推理，减少计算开销同时保持推理性能，为优化LLM推理效率提供了有效解决方案。

Abstract: Large Language Models (LLMs) often generate unnecessarily verbose Chain-of-Thought (CoT) reasoning that increases computational costs and latency without proportional performance gains. In this paper, we propose \textbf{F}ine-grained \textbf{G}roup policy \textbf{O}ptimization (\textbf{FGO}), a Reinforcement Learning (RL) algorithm that refines group responses by subdividing them and assigning appropriate weights based on length and entropy, thereby enabling effective CoT compression. Meanwhile, as an enhanced variant of Group Relative Policy Optimization (GRPO), FGO successfully addresses two major limitations of the GRPO: inefficient data utilization and entropy collapse. We evaluate FGO on multiple reasoning LLMs and benchmarks, including MATH500, AIME24, AMC23, and Minerva. Experimental results show that FGO achieves efficient CoT compression without degrading performance, and simultaneously resolves the key limitations of GRPO.

</details>


### [106] [WildCat: Near-Linear Attention in Theory and Practice](https://arxiv.org/abs/2602.10056)
*Tobias Schröder,Lester Mackey*

Main category: cs.LG

TL;DR: WildCat是一种通过核心集压缩注意力机制的高精度低成本方法，使用随机主元Cholesky算法选择核心集，在近线性时间内实现超多项式误差衰减。


<details>
  <summary>Details</summary>
Motivation: 注意力机制是现代神经网络架构的核心组件，但其计算成本随输入序列长度呈二次方增长，导致部署成本高昂。现有实用近似方法要么缺乏误差保证，要么需要二次方运行时间来保证高保真度。

Method: WildCat通过仅关注小型加权核心集来避免二次方成本。关键创新是使用快速但频谱精确的随机主元Cholesky子采样算法选择核心集，并优化权重元素以最小化重构误差。

Result: 在输入有界的情况下，WildCat以超多项式O(n^{-√log(log(n))})的误差衰减近似精确注意力，同时在近线性O(n^{1+o(1)})时间内运行。提供了GPU优化的PyTorch实现，并在图像生成、图像分类和语言模型KV缓存压缩等基准实验中展示了优势。

Conclusion: WildCat提供了一种既高效又具有理论保证的注意力压缩方法，在保持高精度的同时显著降低了计算成本，为大规模注意力模型的实际部署提供了可行方案。

Abstract: We introduce WildCat, a high-accuracy, low-cost approach to compressing the attention mechanism in neural networks. While attention is a staple of modern network architectures, it is also notoriously expensive to deploy due to resource requirements that scale quadratically with the input sequence length $n$. WildCat avoids these quadratic costs by only attending over a small weighted coreset. Crucially, we select the coreset using a fast but spectrally-accurate subsampling algorithm -- randomly pivoted Cholesky -- and weight the elements optimally to minimise reconstruction error. Remarkably, given bounded inputs, WildCat approximates exact attention with super-polynomial $O(n^{-\sqrt{\log(\log(n))}})$ error decay while running in near-linear $O(n^{1+o(1)})$ time. In contrast, prior practical approximations either lack error guarantees or require quadratic runtime to guarantee such high fidelity. We couple this advance with a GPU-optimized PyTorch implementation and a suite of benchmark experiments demonstrating the benefits of WildCat for image generation, image classification, and language model KV cache compression.

</details>


### [107] [Vendi Novelty Scores for Out-of-Distribution Detection](https://arxiv.org/abs/2602.10062)
*Amey P. Pasarkar,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出Vendi Novelty Score (VNS)，一种基于多样性视角的OOD检测新方法，通过量化测试样本对特征集多样性的增加程度来检测异常样本，无需密度建模，计算高效且性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法主要依赖模型置信度或特征空间似然估计，通常需要严格的分布假设。本文从多样性角度重新思考OOD检测问题，提出第三种检测范式。

Method: 基于Vendi Scores (VS)相似性多样性度量，提出VNS检测器。VNS量化测试样本如何增加in-distribution特征集的VS，提供无需密度建模的新颖性度量。方法具有线性时间复杂度、非参数特性，并能自然结合类别条件（局部）和数据集级别（全局）的新颖性信号。

Result: 在多个图像分类基准和网络架构上，VNS实现了最先进的OOD检测性能。特别值得注意的是，即使仅使用1%的训练数据计算，VNS仍能保持优异性能，适用于内存或访问受限的环境。

Conclusion: 从多样性视角提出的VNS为OOD检测提供了新的有效范式，该方法计算高效、无需密度建模，在资源受限场景下仍能保持强大性能，具有实际部署价值。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of machine learning systems. Existing post-hoc detectors typically rely on model confidence scores or likelihood estimates in feature space, often under restrictive distributional assumptions. In this work, we introduce a third paradigm and formulate OOD detection from a diversity perspective. We propose the Vendi Novelty Score (VNS), an OOD detector based on the Vendi Scores (VS), a family of similarity-based diversity metrics. VNS quantifies how much a test sample increases the VS of the in-distribution feature set, providing a principled notion of novelty that does not require density modeling. VNS is linear-time, non-parametric, and naturally combines class-conditional (local) and dataset-level (global) novelty signals. Across multiple image classification benchmarks and network architectures, VNS achieves state-of-the-art OOD detection performance. Remarkably, VNS retains this performance when computed using only 1% of the training data, enabling deployment in memory- or access-constrained settings.

</details>


### [108] [Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability](https://arxiv.org/abs/2602.10067)
*Aaditya Vikram Prasad,Connor Watts,Jack Merullo,Dhruvil Gala,Owen Lewis,Thomas McGrath,Ekdeep Singh Lubana*

Main category: cs.LG

TL;DR: 使用语言模型内部特征作为强化学习奖励信号，训练模型减少幻觉，在保持基准性能的同时将幻觉概率降低58%


<details>
  <summary>Details</summary>
Motivation: 传统方法使用语言模型内部特征进行测试时监控或引导，本文探索将这些特征作为开放任务的可扩展监督信号，特别是针对幻觉减少这一开放性问题

Method: 提出RLFR（基于特征奖励的强化学习）框架：1）通过探测框架识别候选幻觉声明；2）使用模型内部特征作为奖励函数训练模型干预和修正其完成内容；3）在测试时使用特征奖励指导可扩展计算

Result: 在Gemma-3-12B-IT模型上实施，得到的策略比原始模型产生幻觉的概率降低58%，同时保持标准基准测试的性能

Conclusion: 通过将监督建立在特征语言上，本文为使用可解释性学习开放任务引入了新范式，展示了内部特征作为可扩展监督信号的潜力

Abstract: Language models trained on large-scale datasets have been shown to learn features that encode abstract concepts such as factuality or intent. Such features are traditionally used for test-time monitoring or steering. We present an alternative affordance: features as scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet open-ended behavior and design a reinforcement learning (RL) pipeline, titled RLFR (Reinforcement Learning from Feature Rewards), that uses features as reward functions. Grounded in a novel probing framework that identifies candidate hallucinated claims, our pipeline teaches a model to intervene and correct its completions when it is uncertain of their factuality. Furthermore, the pipeline enables scalable test-time compute, guided once more by our reward features. This end-to-end process operationalized on Gemma-3-12B-IT results in a policy that is 58% less likely to hallucinate compared to the original model, while preserving performance on standard benchmarks. Taken together, by grounding supervision in the language of features, this paper introduces a novel paradigm in the use of interpretability for learning open-ended tasks.

</details>


### [109] [Step-resolved data attribution for looped transformers](https://arxiv.org/abs/2602.10097)
*Georgios Kaissis,David Mildenberger,Juan Felipe Gomez,Martin J. Menten,Eleni Triantafillou*

Main category: cs.LG

TL;DR: 提出Step-Decomposed Influence (SDI)方法，将训练数据影响力分解到循环transformer的每一步迭代，揭示训练样本在潜在推理过程中何时发挥作用


<details>
  <summary>Details</summary>
Motivation: 现有训练数据影响力估计方法（如TracIn）为每个训练样本生成单一标量分数，聚合了所有循环迭代的影响，无法揭示训练样本在循环计算的哪个阶段发挥作用

Method: 提出Step-Decomposed Influence (SDI)方法，通过展开循环计算图，将TracIn分解为长度为τ的影响力轨迹，将影响力归因到特定的循环迭代步骤。采用TensorSketch实现避免显式计算每个样本的梯度

Result: 在循环GPT风格模型和算法推理任务上的实验表明，SDI具有良好的扩展性，与全梯度基线匹配误差低，支持广泛的数据归因和可解释性任务，提供对潜在推理过程的每步洞察

Conclusion: SDI方法成功地将训练数据影响力分解到循环transformer的每一步迭代，为理解训练样本如何影响模型的内部计算提供了更细粒度的分析工具

Abstract: We study how individual training examples shape the internal computation of looped transformers, where a shared block is applied for $τ$ recurrent iterations to enable latent reasoning. Existing training-data influence estimators such as TracIn yield a single scalar score that aggregates over all loop iterations, obscuring when during the recurrent computation a training example matters. We introduce \textit{Step-Decomposed Influence (SDI)}, which decomposes TracIn into a length-$τ$ influence trajectory by unrolling the recurrent computation graph and attributing influence to specific loop iterations. To make SDI practical at transformer scale, we propose a TensorSketch implementation that never materialises per-example gradients. Experiments on looped GPT-style models and algorithmic reasoning tasks show that SDI scales excellently, matches full-gradient baselines with low error and supports a broad range of data attribution and interpretability tasks with per-step insights into the latent reasoning process.

</details>


### [110] [Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders](https://arxiv.org/abs/2602.10099)
*Amandeep Kumar,Vishal M. Patel*

Main category: cs.LG

TL;DR: 论文提出RJF方法，通过黎曼流匹配和雅可比正则化解决扩散变换器在表示编码器特征空间中的几何干扰问题，使标准DiT-B架构能有效收敛。


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器无法直接在表示编码器的特征空间上收敛。先前工作归因于容量瓶颈并提出计算昂贵的宽度扩展方案，但本文发现根本原因是几何干扰——欧几里得流匹配迫使概率路径通过特征空间的低密度内部而非流形表面。

Method: 提出黎曼流匹配与雅可比正则化(RJF)：1) 将生成过程约束到流形测地线；2) 校正曲率引起的误差传播。这使得标准扩散变换器架构无需宽度扩展即可收敛。

Result: RJF使标准DiT-B架构(1.31亿参数)有效收敛，达到FID 3.37，而先前方法无法收敛。该方法解决了几何干扰问题，避免了计算昂贵的宽度扩展。

Conclusion: 扩散变换器在表示编码器特征空间中的收敛失败本质上是几何问题而非容量问题。RJF通过黎曼流匹配和曲率校正成功解决了这一问题，为高效高保真生成建模提供了新途径。

Abstract: Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders, rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation, RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge. Code: https://github.com/amandpkr/RJF

</details>


### [111] [Towards Explainable Federated Learning: Understanding the Impact of Differential Privacy](https://arxiv.org/abs/2602.10100)
*Júlio Oliveira,Rodrigo Ferreira,André Riker,Glaucio H. S. Carvalho,Eirini Eleni Tsilopoulou*

Main category: cs.LG

TL;DR: 提出FEXT-DP框架，结合联邦学习、决策树和差分隐私，在保护数据隐私的同时提升模型可解释性，并分析差分隐私对可解释性的影响。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统需要同时满足数据隐私保护和可解释性要求。联邦学习增强隐私保护，差分隐私提供额外隐私层，但现有基于神经网络的联邦学习系统可解释性较差。决策树模型具有更好的可解释性，但需要与隐私保护技术结合。

Method: 提出FEXT-DP框架：1) 基于决策树构建联邦学习系统，利用决策树的轻量级和可解释性优势；2) 在树模型上应用差分隐私提供额外隐私保护；3) 分析差分隐私对模型可解释性的影响。

Result: 性能评估显示FEXT-DP在训练速度（轮次减少）、均方误差和可解释性方面均有改进。同时量化了差分隐私保护对系统可解释性的具体影响。

Conclusion: FEXT-DP成功实现了隐私保护与可解释性的结合，决策树为基础的联邦学习系统在保持隐私的同时提供了更好的可解释性，但差分隐私会对可解释性产生一定负面影响。

Abstract: Data privacy and eXplainable Artificial Intelligence (XAI) are two important aspects for modern Machine Learning systems. To enhance data privacy, recent machine learning models have been designed as a Federated Learning (FL) system. On top of that, additional privacy layers can be added, via Differential Privacy (DP). On the other hand, to improve explainability, ML must consider more interpretable approaches with reduced number of features and less complex internal architecture. In this context, this paper aims to achieve a machine learning (ML) model that combines enhanced data privacy with explainability. So, we propose a FL solution, called Federated EXplainable Trees with Differential Privacy (FEXT-DP), that: (i) is based on Decision Trees, since they are lightweight and have superior explainability than neural networks-based FL systems; (ii) provides additional layer of data privacy protection applying Differential Privacy (DP) to the Tree-Based model. However, there is a side effect adding DP: it harms the explainability of the system. So, this paper also presents the impact of DP protection on the explainability of the ML model. The carried out performance assessment shows improvements of FEXT-DP in terms of a faster training, i.e., numbers of rounds, Mean Squared Error and explainability.

</details>


### [112] [Biases in the Blind Spot: Detecting What LLMs Fail to Mention](https://arxiv.org/abs/2602.10117)
*Iván Arcuschin,David Chanin,Adrià Garriga-Alonso,Oana-Maria Camburu*

Main category: cs.LG

TL;DR: 提出自动化黑盒流水线检测LLM未表达偏见，无需预定义类别或人工标注数据集，在招聘、贷款、大学录取任务中发现新偏见并验证已知偏见


<details>
  <summary>Details</summary>
Motivation: LLM的思维链推理看似合理但可能隐藏内部偏见（未表达偏见），仅监控陈述推理不可靠，现有偏见评估需要预定义类别和人工标注数据集，缺乏自动化检测方法

Method: 全自动化黑盒流水线：1) 使用LLM自动评分器从任务数据生成候选偏见概念；2) 通过生成正负变体逐步测试每个概念；3) 应用多重测试和早期停止统计技术；4) 如果概念产生显著性能差异且未在思维链中被引用为理由，则标记为未表达偏见

Result: 在六个LLM和三个决策任务（招聘、贷款批准、大学录取）中评估，自动发现先前未知偏见（如西班牙语流利度、英语熟练度、写作正式性），同时验证先前工作中手动识别的偏见（性别、种族、宗教、民族）

Conclusion: 该方法为任务特定偏见发现提供了实用、可扩展的自动化路径，能够检测LLM中隐藏的未表达偏见，无需人工干预或预定义偏见类别

Abstract: Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipeline for detecting task-specific unverbalized biases. Given a task dataset, the pipeline uses LLM autoraters to generate candidate bias concepts. It then tests each concept on progressively larger input samples by generating positive and negative variations, and applies statistical techniques for multiple testing and early stopping. A concept is flagged as an unverbalized bias if it yields statistically significant performance differences while not being cited as justification in the model's CoTs. We evaluate our pipeline across six LLMs on three decision tasks (hiring, loan approval, and university admissions). Our technique automatically discovers previously unknown biases in these models (e.g., Spanish fluency, English proficiency, writing formality). In the same run, the pipeline also validates biases that were manually identified by prior work (gender, race, religion, ethnicity). More broadly, our proposed approach provides a practical, scalable path to automatic task-specific bias discovery.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [113] [Empirical Evaluation of QAOA with Zero Noise Extrapolation on NISQ Hardware for Carbon Credit Portfolio Optimization in the Brazilian Cerrado](https://arxiv.org/abs/2602.09047)
*Hugo José Ribeiro*

Main category: quant-ph

TL;DR: 量子近似优化算法(QAOA)结合零噪声外推(ZNE)在巴西塞拉多地区碳信用组合优化中显著优于经典贪婪算法，实现31.6%的性能提升，证明了NISQ时代量子硬件在环境科学中的实际效用。


<details>
  <summary>Details</summary>
Motivation: 优化碳信用组合对气候减缓至关重要，特别是在巴西塞拉多等高生物多样性地区。传统经典方法难以处理多目标规划中的复杂协同效应，需要探索量子计算方法在环境科学中的实际应用。

Method: 采用量子近似优化算法(QAOA)结合零噪声外推(ZNE)技术，在IBM量子硬件(ibm_torino和ibm_fez)上执行88变量的多目标组合优化，考虑碳封存、生物多样性连通性和社会影响指标，并与经典贪婪基线方法进行比较。

Result: 量子方法平均组合得分为58.47±6.98，比经典启发式方法(44.42)提升31.6%，具有高度统计显著性(p=0.0009)和大效应量(Cohen's d=2.01)。13天后验证运行确认了方法的时间稳定性。

Conclusion: 当前NISQ时代量子设备结合严格误差缓解技术能够识别经典短视方法忽略的复杂地域协同效应，为高精度环境保护政策提供了可扩展的方法模板，确立了量子计算在环境科学中的实证效用。

Abstract: Optimizing carbon credit portfolios is a critical challenge for climate mitigation, particularly in high-biodiversity biomes such as the Brazilian Cerrado. This study explores the practical application of the Quantum Approximate Optimization Algorithm (QAOA) combined with Zero Noise Extrapolation (ZNE) to address a multi-objective territorial planning problem. We model an 88-variable portfolio optimization involving carbon sequestration, biodiversity connectivity, and social impact metrics, executed on intermediate-scale IBM Quantum hardware (ibm_torino and ibm_fez). The results of seven independent hardware runs demonstrate that the QAOA+ZNE workflow consistently outperforms a classical greedy baseline. The quantum method achieves a mean portfolio score of 58.47 +/- 6.98, corresponding to a 31.6% improvement over the classical heuristic (44.42), with high statistical significance (p = 0.0009) and a large effect size (Cohen's d = 2.01), where ZNE yields extrapolated expectation values of the portfolio objective rather than a discrete portfolio solution without noise. A validation run conducted after a 13-day interval confirms the temporal stability of the methodology against hardware calibration drifts. These findings establish empirical quantum utility in an environmental science context, showing that current NISQ-era devices, when coupled with rigorous error mitigation, can identify complex territorial synergies that myopic classical approaches overlook. The proposed workflow provides a scalable methodological template for high-precision environmental conservation policies.

</details>


### [114] [Almost all graphs are vertex-minor universal](https://arxiv.org/abs/2602.09049)
*Ruben Ascoli,Bryce Frederickson,Sarah Frederickson,Caleb McFarland,Logan Post*

Main category: quant-ph

TL;DR: 随机图 G(n,1/2) 以高概率是 Ω(√n)-顶点次通用图，即任何 α√n 个指定顶点上的图都可以作为 G 的顶点次图获得


<details>
  <summary>Details</summary>
Motivation: 回答Claudet的问题，研究随机图的顶点次通用性，这在量子通信网络中有直接应用：n-顶点k-顶点次通用图对应n-量子比特k-稳定子通用图态

Method: 通过概率方法分析随机图 G(n,1/2) 的顶点次图性质，证明对于常数 α≈0.911，任何在 α√n 个指定顶点上的图都可以作为 G 的顶点次图获得

Result: 证明了 G(n,1/2) 以高概率是 Ω(√n)-顶点次通用图；引入了顶点次Ramsey数 R_vm(k)，证明了 Ω(k²) ≤ R_vm(k) ≤ 2^k - 1

Conclusion: 随机图具有强顶点次通用性，这对量子网络有重要意义；提出了顶点次Ramsey数的多项式猜想，并给出了上下界证明

Abstract: Answering a question of Claudet, we prove that the uniformly random graph $G\sim \mathbb G(n, 1/2)$ is $Ω(\sqrt n)$-vertex-minor universal with high probability. That is, for some constant $α\approx 0.911$, any graph on any $α\sqrt n$ specified vertices of $G$ can be obtained as a vertex-minor of $G$. This has direct implications for quantum communications networks: an $n$-vertex $k$-vertex-minor universal graph corresponds to an $n$-qubit $k$-stabilizer universal graph state, which has the property that one can induce any stabilizer state on any $k$ qubits using only local operations and classical communications.
  We further employ our methods in two other contexts. We obtain a bipartite pivot-minor version of our main result, and we use it to derive a universality statement for minors in random binary matroids. We also introduce the vertex-minor Ramsey number $R_{\mathrm{vm}}(k)$ to be the smallest value $n$ such that every $n$-vertex graph contains an independent set of size $k$ as a vertex-minor. Supported by our main result, we conjecture that $R_{\mathrm{vm}}(k)$ is polynomial in $k$. We prove $Ω(k^2) \leq R_{\mathrm{vm}}(k) \leq 2^k - 1$.

</details>


### [115] [TC/TCL and NETFD Correspondence Principles for Information Backflow: A Structural Monotonicity Theorem and Minimal Phase Diagrams](https://arxiv.org/abs/2602.09054)
*Koichi Nakagawa*

Main category: quant-ph

TL;DR: 该论文提出了一个统一的结构框架来分析最小非马尔可夫弛豫过程中的信息回流现象，将非马尔可夫性解释为可观测自由度与隐藏辅助自由度之间的嵌入现象。


<details>
  <summary>Details</summary>
Motivation: 建立统一的理论框架来理解非马尔可夫弛豫过程中的信息回流机制，将非马尔可夫性系统性地解释为嵌入现象，并区分经典和量子贡献。

Method: 结合两种非平衡物理标准形式：(1)时间卷积(TC)和时间无卷积(TCL)投影算符主方程；(2)非平衡热场动力学(NETFD)的对偶原理，在扩展空间中建立密度算符演化的向量表示。

Result: 定义了信息回流泛函N_I，推导了无回流的充分条件，提出了回流分解为经典和本征热场纠缠贡献的方法，建立了TC到TCL的构造算法，并分析了最小二态模型。

Conclusion: 该框架为理解非马尔可夫弛豫过程中的信息回流提供了统一的结构化方法，能够模型无关地分类瞬态过冲和恢复现象，并揭示了Mittag-Leffler分数弛豫作为普适包络。

Abstract: We propose a unified structural framework for information backflow in minimal non-Markovian relaxation processes. The central idea is to interpret non-Markovianity as an embedding phenomenon in which observable degrees of freedom exchange information with hidden auxiliary sectors. Our approach is based on two standard formalisms in nonequilibrium physics: (i) the time-convolution (TC) and time-convolutionless (TCL) projection-operator master equations, and (ii) the correspondence principle of non-equilibrium thermo field dynamics (NETFD), which provides a doubling construction equivalent to an embedding of density-operator dynamics into a vector evolution in an enlarged space. We define a general information-backflow functional N_I associated with an information quantity I(t) and derive sufficient conditions for the absence of backflow (N_I = 0) in terms of divisibility properties of the instantaneous TCL generator. We further introduce a decomposition of backflow into classical and intrinsic thermo-field entanglement contributions, leading to a classification of transient overshoot and revival phenomena in a model-independent manner. Minimal classical and quantum two-state models are discussed as analytically tractable examples, recovering Mittag-Leffler fractional relaxation as a universal envelope. We also provide a constructive TC-to-TCL algorithm for extracting effective rates and producing phase diagrams of backflow.

</details>


### [116] [Causal Rigidity of Born-Type Probability Rules in Infinite-Dimensional Operational Theories](https://arxiv.org/abs/2602.09056)
*Enso O. Torres Alegre*

Main category: quant-ph

TL;DR: 该论文证明在无限维量子理论中，满足无超光速信号、正态纯化可及性、σ-仿射性三个操作要求时，概率规则必须简化为Born规则，排除了非线性修改的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究无限维量子理论中概率规则的刚性，探索Born规则是否在更广泛的概率理论框架中具有唯一性，为连续变量和量子场论中的后量子修改提供理论限制。

Method: 从拓扑广义概率理论出发，考虑纯态间操作转移概率的函数定义的概率分配，在三个操作要求下（无超光速信号、正态纯化可及性、σ-仿射性）分析概率规则的刚性。

Result: 证明在此类概率规则中，任何可接受的规则必须简化为恒等映射，即Born规则是唯一与无信号要求兼容的概率分配，非线性偏差通常会在操控场景中产生可操作信号区分。

Conclusion: 在满足三个操作要求的无限维量子理论中，Born规则是唯一的因果固定点，这为连续变量和量子场论中的后量子修改提供了严格的限制，并通过冯·诺依曼代数的正态态空间和GNS表示与标准无限维量子力学建立了联系。

Abstract: We establish an operational rigidity result for a broad class of probability rules in infinite-dimensional settings, applicable under normality and steering assumptions. Starting from a topological generalization of generalized probabilistic theories, we consider probability assignments defined as functions of an operational transition probability between pure states. We show that under three operationally motivated requirements: no superluminal signaling, availability of normal steering via purification in a sigma additive sense, and sigma affinity of probabilities under countable preparation mixtures, any admissible rule within this class must reduce to the identity. In particular, nonlinear deviations generically enable operational signaling distinctions in steering scenarios, while continuity combined with sigma affinity excludes non affine alternatives. This identifies a unique causal fixed point. Within this class of probability rules, the Born rule emerges as the only assignment compatible with no signaling in operational theories admitting normal steering. We connect the operational result to standard infinite-dimensional quantum mechanics through the normal state space of von Neumann algebras and the GNS representation, recovering the conventional Born rule for projective and generalized measurements. We discuss the scope of the assumptions and implications for proposed post quantum modifications in continuous variable and quantum field theoretic regimes.

</details>


### [117] [Quantum Estimation of Delay Tail Probabilities in Scheduling and Load Balancing](https://arxiv.org/abs/2602.09059)
*R. Srikant*

Main category: quant-ph

TL;DR: 提出基于截断再生模拟的量子框架，用于估计排队系统中的延迟尾概率，解决了量子电路深度有限与无限状态空间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 调度和负载均衡系统中延迟尾概率估计至关重要，但传统方法计算成本高。量子振幅估计(QAE)提供平方级样本复杂度降低，但应用于稳态排队网络面临挑战：经典模拟涉及无限状态空间和随机再生周期，而量子电路深度固定、寄存器有限。

Method: 开发基于截断再生模拟的量子模拟框架：1) 将再生罕见事件估计器重新表述为有限随机种子的确定性可逆函数；2) 使用Lyapunov漂移和集中论证推导再生时间的指数尾界；3) 通过控制截断水平使偏差可忽略于统计误差；4) 避免直接有限时域模拟所需的混合时间确定问题。

Result: 该框架使量子估计能够在可数无限状态空间模型中实现，为GI-GI-1队列、MaxWeight调度下的无线网络和JSQ路由的多服务器系统提供了量子比特和电路复杂度的界限。

Conclusion: 提出的截断再生模拟框架成功解决了量子电路有限深度与排队系统无限状态空间之间的矛盾，为量子计算在排队网络延迟尾概率估计中的应用提供了理论基础和实用方法。

Abstract: Estimating delay tail probabilities in scheduling and load balancing systems is a critical but computationally prohibitive task due to the rarity of violation events. Quantum Amplitude Estimation (QAE) offers a generic quadratic reduction in sample complexity 1/sqrt(p) vs 1/p, but applying it to steady-state queueing networks in challenging: classical simulations involve unbounded state spaces and random regeneration cycles, whereas quantum circuits have fixed depth and finite registers.
  In this paper, we develop a framework for quantum simulation of delay tail probabilities based on truncated regenerative simulation. We show that regenerative rare-event estimators can be reformulated as deterministic, reversible functions of finite random seeds by truncating regeneration cycles. To control the resulting bias, we use Lyapunov drift and concentration arguments to derive exponential tail bounds on regeneration times. This allows the truncation horizon--and hence the quantum circuit depth--to be chosen such that the bias is provably negligible compared to the statistical error. The proposed framework enables quantum estimation in models with countably infinite state spaces, avoiding the challenge of determining the sufficient mixing time required for direct finite-horizon simulation. We provide bounds on qubit and circuit complexity for a GI-GI-1 queue, a wireless network under MaxWeight scheduling, and a multi-server system with Join-the-Shortest-Queue (JSQ) routing.

</details>


### [118] [Quantum thermodynamics in nonequilibrium](https://arxiv.org/abs/2602.09074)
*Md Manirul Ali,Po-Wen Chen*

Main category: quant-ph

TL;DR: 该论文提出了一个非平衡量子热力学的第一性原理框架，将量子相干性的资源理论与热力学定律相结合，明确了量子相干性在热力学中的基本作用。


<details>
  <summary>Details</summary>
Motivation: 理解远离平衡态的量子尺度热力学，特别是在存在量子相干性的情况下，仍然是一个基本挑战。需要建立一个统一的操作性基础来研究非平衡量子热力学。

Method: 将量子相干性的资源理论与热力学定律整合，推导出新的熵平衡关系，明确分离热交换引起的熵流和量子相干性损失引起的熵产生。将非平衡量子过程中的热力学熵定义为与能量测量相关的能量熵。

Result: 建立了统一的非平衡量子热力学框架，明确了热力学熵应为能量熵而非冯·诺依曼熵，定义了动力学温度、自由能、功和热等概念，证明第一和第二定律在远离平衡态时仍然成立。通过可精确求解的开放量子系统，展示了在弱耦合极限下平衡热力学如何动态出现。

Conclusion: 该研究为非平衡量子热力学建立了统一的操作性基础，阐明了量子相干性在热力学中的基本作用，解决了远离平衡态时热力学熵的适当定义问题。

Abstract: Understanding thermodynamics far from equilibrium at the quantum scale remains a fundamental challenge, particularly in the presence of quantum coherence. Here we develop a first-principles framework for nonequilibrium quantum thermodynamics by integrating quantum resource theory of coherence with thermodynamic laws. We derive a previously unexplored entropy balance relation that explicitly separates entropy flux due to heat exchange from entropy production arising from the loss of quantum coherence. This formulation identifies the appropriate thermodynamic entropy in nonequilibrium quantum processes as the energy entropy associated with energy measurements, demonstrating that the von Neumann entropy does not, in general, represent thermodynamic entropy away from equilibrium. Within this framework, dynamical temperature, free energy, work, and heat are consistently defined, and both the first and second laws are shown to hold far from equilibrium. Applying the theory to an exactly solvable open quantum system, we reveal how equilibrium thermodynamics emerges dynamically in the weak-coupling limit. Our results establish a unified and operational foundation for nonequilibrium quantum thermodynamics and clarify the fundamental thermodynamic role of quantum coherence.

</details>


### [119] [Volume-law protection of metrological advantage](https://arxiv.org/abs/2602.09086)
*Piotr Wysocki,Jan Chwedeńczuk,Marcin Płodzień*

Main category: quant-ph

TL;DR: 纠缠可提升计量精度，但粒子损失会破坏优势。研究发现量子加扰可将参数信息分散到多体关联中，当剩余子系统大于N/2时能恢复全部量子费舍尔信息，小于N/2时信息可忽略。


<details>
  <summary>Details</summary>
Motivation: 虽然纠缠能突破标准量子极限提升计量精度，但粒子损失通常会破坏这种优势。需要找到在粒子损失情况下仍能保持计量精度的方法。

Method: 使用Haar随机加扰幺正演化，推导出粒子损失后约化态的平均量子费舍尔信息精确公式。分析加扰引起的纠缠从面积律到体积律的转变及施密特秩增长。通过砖墙电路和混沌XX链演化两种实现方案验证。

Result: 发现阈值现象：任何大于N/2的剩余子系统都能恢复全部量子费舍尔信息，而小于N/2的子系统包含可忽略信息。成功保护单轴扭曲探针抵抗高达一半粒子的损失。

Conclusion: 量子加扰通过将参数信息分散到多体关联中，能够保护计量精度免受粒子损失影响。剩余子系统大小超过N/2的阈值与加扰引起的纠缠转变相关，为实际量子计量应用提供了新策略。

Abstract: Although entanglement can boost metrological precision beyond the standard quantum limit, the advantage often disappears with particle loss. We demonstrate that scrambling safeguards precision by dispersing information about the encoded parameter into many-body correlations. For Haar-random scrambling unitaries, we derive exact formulas for the average quantum Fisher information (QFI) of the reduced state after tracing out lost particles. The result exhibits a threshold; any remaining subsystem larger than $N/2$ recovers the full QFI, while smaller subsystems contain negligible information. We link this threshold to the scrambling-induced transition from area-law to volume-law entanglement and the associated growth of the Schmidt rank. We outline two realizations -- a brickwork circuit and chaotic XX-chain evolution -- and demonstrate the protection of one-axis-twisted probes against the loss of up to half of the particles.

</details>


### [120] [Eigenstate Thermalization for Local versus Translationally Invariant Observables](https://arxiv.org/abs/2602.09087)
*Rohit Patil,Marcos Rigol*

Main category: quant-ph

TL;DR: 本文探讨了局域可观测量与平移不变可观测量在实验测量预测中的差异，特别是在自旋-1倾斜场伊辛链中研究它们的对角矩阵元和谱函数，揭示了平移不变系统中的一种新型非对角本征态热化形式。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为局域可观测量和平移不变可观测量在实验测量中提供相同的预测，这种观点适用于期望值（在清洁系统中确实相同），但不一定适用于关联函数。本文旨在从本征态热化假说的角度检验这一直觉。

Method: 研究在周期边界条件和开放边界条件下，自旋-1倾斜场伊辛链中局域和平移不变观测量的对角矩阵元和谱函数。通过比较这些可观测量在不同边界条件下的表现，分析它们的异同。

Result: 揭示了局域可观测量和平移不变可观测量在多个方面的差异，特别是在关联函数方面。同时发现了一种适用于具有不同准动量能量本征态对的新型非对角本征态热化形式。

Conclusion: 局域可观测量和平移不变可观测量在某些方面可以视为相同，但在其他方面存在重要差异。特别是在平移不变系统中，存在一种新的非对角本征态热化机制，这对理解量子多体系统的热化行为具有重要意义。

Abstract: Local observables and their translationally invariant counterparts are generally thought as providing the same predictions for experimental measurements. This is used in the context of their expectation values, which are indeed the same in clean systems (up to finite-size effects), but also in the context of their correlation functions, which need not be the same. We examine this intuition from the perspective of the eigenstate thermalization hypothesis. Specifically, we explore the diagonal matrix elements and the spectral functions of local and translationally invariant observables in the spin-1 tilted field Ising chain with periodic and open boundary conditions. We discuss in which ways those observables are different and in which contexts they can be thought as being the same. Furthermore, we unveil a novel form of off-diagonal eigenstate thermalization in translationally invariant systems that applies to pairs of energy eigenstates with different quasimomenta.

</details>


### [121] [Universality classes split by strong and weak symmetries](https://arxiv.org/abs/2602.09090)
*Jongjun M. Lee,Myung-Joong Hwang,Igor Boettcher*

Main category: quant-ph

TL;DR: 弱对称性和强对称性在耗散相变中导致不同的动力学普适类，尽管它们来自封闭系统中的相同对称群。


<details>
  <summary>Details</summary>
Motivation: 耗散相变受刘维尔算符对称性的强烈影响，但弱对称性和强对称性对临界行为的定量影响尚不清楚。需要研究这两种对称性如何塑造耗散临界性。

Method: 研究具有单光子和双光子损耗的压缩光子模型，在尽可能简单的设置中实现弱对称性和强对称性。采用单回路Keldysh分析和累积展开数值计算。

Result: 两种对称性表现出相同的高斯静态涨落，但序参数和渐近衰减率显示出不同的标度行为。临界标度相对于热力学标度参数存在显著差异。

Conclusion: 弱对称性和强对称性导致不同的动力学普适类，尽管它们起源于封闭系统中的相同对称群。强对称性从根本上重塑了耗散临界性。

Abstract: Dissipative phase transitions are strongly shaped by the symmetries of the Liouvillian, yet the quantitative impact of weak and strong symmetries on critical behavior has remained unclear. We study a squeezed-photon model with single- and two-photon losses, realizing weak and strong symmetries in the simplest possible setting. The two symmetries exhibit identical Gaussian static fluctuations, whereas the order parameter and the asymptotic decay rate display distinct scaling behaviors. Our one-loop Keldysh analysis, together with cumulant-expansion numerics, reveals sharply different critical scaling with respect to the thermodynamic scaling parameter. This establishes that weak and strong symmetries lead to distinct dynamical universality classes despite originating from the same symmetry group in the closed system. Our results provide a clear quantitative demonstration that strong symmetries fundamentally reshape dissipative criticality.

</details>


### [122] [Surface code off-the-hook: diagonal syndrome-extraction scheduling](https://arxiv.org/abs/2602.09099)
*Gilad Kishony,Austin Fowler*

Main category: quant-ph

TL;DR: 提出对角线调度方案，通过将钩子错误定向到每个plaquette的对角线方向，避免与逻辑算符对齐，实现完整代码距离，简化电路构造。


<details>
  <summary>Details</summary>
Motivation: 传统N形和Z形调度在旋转表面码中，钩子错误可能导致电路级代码距离减半，且在格点手术原语中随着边界几何变化变得复杂，需要7步调度避免门冲突。

Method: 提出对角线调度方案，将所有X型plaquette使用一种调度，所有Z型plaquette使用另一种调度，使钩子错误始终沿plaquette对角线方向，不与逻辑算符对齐。

Result: 对角线调度在支持并行测量、重置和门操作的硬件上实现最小6步周期（传统方法需7步），在内存实验、空间连接、空间Hadamard门和补丁旋转中显示等效或改进的逻辑错误率。

Conclusion: 对角线调度方案通过全局均匀的调度策略，避免钩子错误与逻辑算符对齐，实现完整代码距离，简化电路构造，同时提高性能。

Abstract: In the rotated surface code, hook errors (errors on auxiliary qubits midway through syndrome extraction that propagate to correlated two-qubit data errors) can reduce the circuit-level code distance by a factor of two if the extraction schedule is poorly chosen. The traditional approach uses N-shaped and Z-shaped schedules, selecting the orientation in each plaquette to avoid hook errors aligned with logical operators. However, this becomes increasingly complex within lattice surgery primitives with varied boundary geometries, and requires a 7-step schedule to avoid gate collisions. We propose the diagonal schedule, which orients hook errors along the diagonal of each plaquette. These diagonal errors crucially never align with logical operators regardless of boundary orientation, achieving full code distance. The diagonal schedule is globally uniform: all X-type plaquettes use one schedule and all Z-type plaquettes use another, eliminating geometry-dependent planning. On hardware supporting parallel measurement, reset, and gate operations, the schedule achieves a minimal period of 6 time steps, compared to 7 for the traditional approach. We demonstrate effectiveness for memory experiments, spatial junctions, spatial Hadamard gates, and patch rotation, showing equivalent or improved logical error rates while simplifying circuit construction.

</details>


### [123] [Constant-space-overhead fault-tolerant quantum input/output and communication](https://arxiv.org/abs/2602.09103)
*Paula Belzig,Hayata Yamasaki*

Main category: quant-ph

TL;DR: 提出基于量子汉明码级联的容错通信新方法，相比单逻辑量子位级联码，能以恒定空间开销编码多个逻辑量子位，获得更高的通信速率。


<details>
  <summary>Details</summary>
Motivation: 现有容错通信方法主要基于单逻辑量子位的级联码，存在空间开销大、通信速率有限的问题。需要开发能够同时编码多个逻辑量子位、具有恒定空间开销的容错通信方案。

Method: 使用量子汉明码的级联编码，开发模块化技术实现具有量子输入/输出接口的容错电路。利用量子汉明码的高码率和校验位噪声相关性有限的特点。

Result: 新方法不仅分析更简单，而且相比先前方法能获得显著更高的可实现通信速率，得益于高码率量子汉明码校验位噪声相关性有限的优势。

Conclusion: 基于量子汉明码级联的容错通信方法提供了一种更高效、更简单的容错通信方案，能够以恒定空间开销实现更高的通信速率。

Abstract: Fault-tolerant capacities quantify the ability of a quantum channel to reliably transmit information when every component of the encoding and decoding procedure is noisy. Earlier work analyzed achievable communication rates under such noise using fault-tolerant implementations based on concatenated codes with a single logical qubit. In this work, we develop an alternative approach using concatenations of quantum Hamming codes, which offer constant space overhead by encoding many logical qubits simultaneously. We introduce modular techniques for implementing fault-tolerant circuits with quantum input/output interfaces using the concatenated quantum Hamming code. These tools enable an analysis of fault-tolerant entanglement-assisted communication that is not only simpler, but also yields substantially higher achievable communication rates than previous methods, owing to the limited noise correlations in syndrome qubits of high-rate quantum Hamming codes.

</details>


### [124] [Quantum Phaselift](https://arxiv.org/abs/2602.09119)
*Dhrumil Patel,Laura Clinton,Steven T. Flammia,Raúl García-Patrón*

Main category: quant-ph

TL;DR: Quantum Phaselift：通过估计矩阵Z=ff†而非直接估计f(t)来降低量子时间序列估计的电路深度，将受控电路深度与最大演化时间解耦，实现近量子硬件的有效实现。


<details>
  <summary>Details</summary>
Motivation: 量子时间序列估计（如Loschmidt振幅）在光谱学、哈密顿量分析和相位估计算法中至关重要。传统的Hadamard测试需要受控的e^{-iHt}实现，其电路深度随t增长，在近量子硬件上难以进行长时间估计。

Method: 提出Quantum Phaselift框架，估计秩一矩阵Z=ff†而非直接估计f。设计简单量子电路估计Z的矩阵元素，仅需测量矩阵对角线附近的窄带即可唯一恢复f。将受控电路深度与最大演化时间解耦，使其仅与测量带宽相关。

Result: 证明O(1)带宽足以处理一般信号，相比直接估计方法大幅减少受控操作。开发了三种恢复算法，在无噪声情况下可精确恢复，对测量噪声具有稳定性。数值模拟显示，对于超过100个时间点的2D Fermi-Hubbard和2D横向场Ising模型信号，仅需几百万次测量和合理后处理时间即可高质量恢复。

Conclusion: Quantum Phaselift为近量子硬件提供了高效有效的量子时间序列估计技术，通过矩阵提升框架解决了传统方法中电路深度随演化时间增长的问题，实现了高质量信号恢复。

Abstract: Estimating quantum time-series such as the Loschmidt amplitude $f(t)=\langleψ|\mathrm{e}^{-\mathrm{i}Ht}|ψ\rangle$ is central to spectroscopy, Hamiltonian analysis, and many phase-estimation algorithms. Direct estimation via the Hadamard test requires controlled implementations of $\mathrm{e}^{-\mathrm{i}Ht}$, and the depth of these controlled circuits grows with $t$, making long-time estimation challenging on near-term hardware. We introduce Quantum Phaselift, a lifting-based framework that estimates the rank-one matrix $Z = f f^\dagger$ rather than estimating $f$ directly. We propose simple quantum circuits for estimating the entries of $Z$ and show that measuring only a narrow band of this matrix around the diagonal is sufficient to uniquely recover $f$. Crucially, this reformulation decouples the controlled circuit depth from the maximum evolution time to scale instead with the width of the measured band. We prove that a $O(1)$ bandwidth suffices for generic signals, leading to substantial savings in controlled operations compared to direct estimation methods. We develop three recovery algorithms with provable exact recovery in the noiseless setting and stability under measurement noise. Finally, we numerically demonstrate that high-quality recovery is possible for the 2D Fermi-Hubbard and 2D transverse-field Ising model signals of size exceeding 100 time points using only a few million measurement shots and reasonable post-processing time, making our time-series estimation techniques efficient and effective for near-term implementations.

</details>


### [125] [Quantum State Characterization of Gravitational Waves via Graviton Counting Statistics](https://arxiv.org/abs/2602.09125)
*Kristian Toccacelo,Thomas Beitel,Ulrik Lund Andersen,Igor Pikovski*

Main category: quant-ph

TL;DR: 单引力子探测器不仅能探测引力子，还能测量引力波的量子态和粒子统计特性，实现量子态层析


<details>
  <summary>Details</summary>
Motivation: 虽然引力波已被常规观测，但单个引力子的探测一直被认为不可能。最近研究表明单引力子探测可以实现，但需要进一步探索其量子特性测量能力

Method: 利用单引力子探测器测量探测概率和二阶关联函数，基于量子光学技术实现量子态层析

Result: 探测器能够区分压缩态、相干态和热辐射，并能直接测量引力波的二阶关联函数，实现高斯态的完整量子态层析

Conclusion: 单引力子探测不仅具有基础科学意义，还具有实用价值，能够表征引力辐射场的量子统计特性和量子态，这些目前仍是未知的

Abstract: Although gravitational waves are now routinely observed, the detection of individual gravitons has long been regarded as impossible. Recent work, however, has demonstrated that single-graviton detection can be achieved and may be feasible in the near future. Here we show that beyond mere particle detection, these detectors provide access to the quantum state and particle statistics of gravitational waves. We show that graviton detection probabilities enable the discrimination between squeezed, coherent, and thermal radiation. We further demonstrate that the full quantum statistics contained in the second-order correlation function of the passing wave can be directly measured at the detector, independent of the weak gravitational interaction strength. Building on recent quantum-optical techniques, this capability opens the way to full quantum state tomography of Gaussian states. Our results demonstrate that single-graviton detection is not only of foundational significance but also of practical value, allowing for the characterization of quantum statistics and the states of the gravitational radiation field, which remain currently unknown.

</details>


### [126] [Quantum annealing and condensed matter physics](https://arxiv.org/abs/2602.09149)
*Viv Kendon,Nicholas Chancellor*

Main category: quant-ph

TL;DR: 本文是一篇面向凝聚态物理学家的量子退火综述，旨在促进量子退火与凝聚态物理之间的交叉研究，实现相互促进与共同发展。


<details>
  <summary>Details</summary>
Motivation: 量子退火硬件的发展使其不仅可用于解决优化问题，还能用于研究凝聚态物理问题。本文旨在搭建量子退火与凝聚态物理之间的桥梁，促进两个领域的合作与相互启发。

Method: 本文采用综述性方法，系统介绍量子退火的基本原理、技术现状及其在凝聚态物理中的应用潜力，为凝聚态物理学家提供入门指南。

Result: 通过综述分析，展示了量子退火硬件在解决凝聚态物理问题方面的潜力，并指出了两个领域合作可以带来的双向收益。

Conclusion: 量子退火与凝聚态物理之间存在天然的交叉点，通过加强两个领域的合作，既能改进量子退火器的工作原理，又能推动凝聚态物理的进展，实现互利共赢。

Abstract: Quantum annealing leverages the properties of interacting quantum spin systems to solve computational problems, typically optimisation problems. Current hardware now has capabilities that can be used to solve condensed matter physics problems, too. In this topical review, we provide an overview of quantum annealing aimed at condensed matter physicists, to show the mutual benefits of working together to understand and improve how quantum annealers work, and to use them to advance condensed matter physics.

</details>


### [127] [The Quantum Many-Worlds Interpretation, Simply Told](https://arxiv.org/abs/2602.09272)
*Brian C. Odom*

Main category: quant-ph

TL;DR: 本文探讨量子力学多世界解释(MWI)如何通过原子干涉仪中的路径测量实验来验证其预测与观测的一致性，并讨论MWI如何避免超距作用问题。


<details>
  <summary>Details</summary>
Motivation: 多世界解释(MWI)提出将所有系统（微观物体、测量设备和观察者）都用相同的量子方程描述，但需要验证这种一致性是否与我们的观测相符。本文旨在通过具体实验模型检验MWI的预测能力。

Method: 构建一个用于原子干涉仪中进行路径测量的测辐射热计探测器模型，分析MWI声称的"虽然每次实验迭代中两个测量结果都发生，但观察者只会经历其中一个结果"的论断。

Result: MWI能够提供与实验一致的概率预测，同时避免了超距作用问题。文章展示了MWI如何解释观察者只经历单一结果的现象，即使所有可能结果都在不同分支中实现。

Conclusion: 多世界解释为量子力学提供了一个自洽的框架，将所有系统统一用相同量子方程描述，其预测与观测相符且避免了超距作用问题，为理解量子现实提供了有价值的视角。

Abstract: The many-worlds interpretation (MWI) of quantum mechanics poses a simple question. What would reality look like if everything evolved in time according to the same quantum equations? There is an attractive consistency to treating microscopic objects, measuring devices, and observers all on the same footing, but do the predictions match our observations? Here, we build a model for a bolometer detector making a which-path measurement in an atom interferometer. We discuss the MWI claim that, while both measurement outcomes occur in each experimental iteration, an observer will experience only one outcome or the other, with a probability consistent with experiment. Finally, we discuss how MWI does not have action at a distance. This article is written to be accessible to anyone with an undergraduate course in quantum mechanics.

</details>


### [128] [How to Classically Verify a Quantum Cat without Killing It](https://arxiv.org/abs/2602.09282)
*Yael Tauman Kalai,Dakshita Khurana,Justin Raizes*

Main category: quant-ph

TL;DR: 提出首个使用单份QMA见证态且不破坏见证态的经典可验证量子计算协议，基于后量子LWE假设，具有可忽略的完备性和可靠性误差


<details>
  <summary>Details</summary>
Motivation: 现有CVQC协议会消耗证明者的见证态，每次调用都需要新的见证态。由于QMA见证态通常不可克隆，破坏输入见证态意味着通过重复来放大可靠性和完备性需要多份见证态副本。构建仅使用单份见证态且具有低可靠性误差的CVQC一直是个未解决的问题

Method: 基于后量子LWE假设，构造了两个原语：1) 保持状态的NP经典论证；2) 具有状态恢复能力的双模陷门函数。利用这些原语构建了不破坏见证态的CVQC协议

Result: 成功构建了仅使用单份QMA见证态、具有可忽略完备性和可靠性误差、且不破坏见证态的CVQC协议，解决了长期存在的开放问题

Conclusion: 该工作首次实现了使用单份见证态且不破坏见证态的CVQC协议，基于后量子LWE假设，为量子计算验证提供了更高效的解决方案，所提出的两个原语也具有独立的研究价值

Abstract: Existing protocols for classical verification of quantum computation (CVQC) consume the prover's witness state, requiring a new witness state for each invocation. Because QMA witnesses are not generally clonable, destroying the input witness means that amplifying soundness and completeness via repetition requires many copies of the witness. Building CVQC with low soundness error that uses only *one* copy of the witness has remained an open problem so far.
  We resolve this problem by constructing a CVQC that uses a single copy of the QMA witness, has negligible completeness and soundness errors, and does *not* destroy its witness. The soundness of our CVQC is based on the post-quantum Learning With Errors (LWE) assumption.
  To obtain this result, we define and construct two primitives (under the post-quantum LWE assumption) for non-destructively handling superpositions of classical data, which we believe are of independent interest:
  - A *state preserving* classical argument for NP.
  - Dual-mode trapdoor functions with *state recovery*.

</details>


### [129] [A Trainable-Embedding Quantum Physics-Informed Framework for Multi-Species Reaction-Diffusion Systems](https://arxiv.org/abs/2602.09291)
*Ban Q. Tran,Nahid Binandeh Dehaghani,A. Pedro Aguiar,Rafal Wisniewski,Susan Mengel*

Main category: quant-ph

TL;DR: 该研究提出了扩展的可训练嵌入量子物理信息神经网络（x-TE-QPINN），用于求解非线性反应-扩散方程，比较了经典前馈神经网络嵌入与参数化量子电路嵌入的性能差异。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）及其量子-经典混合扩展为求解偏微分方程提供了有前景的框架。本研究旨在探索在非线性反应-扩散系统中，可训练嵌入量子物理信息神经网络（TE-QPINNs）的嵌入策略，比较经典与量子嵌入的性能差异。

Method: 提出扩展的TE-QPINN（x-TE-QPINN）架构，支持经典和完全量子嵌入。包括经典前馈神经网络嵌入的FNN-TE-QPINN和纯量子嵌入的QNN-TE-QPINN。使用硬件高效的变分量子电路和物种特异性读出算子来近似耦合多场动力学，通过物理信息损失函数强制执行控制方程、边界条件和初始条件。

Result: 在一维和二维反应-扩散方程上的数值实验表明，量子嵌入可以替代经典嵌入而不会降低求解精度，在某些情况下甚至表现出比经典PINNs和具有固定嵌入的混合量子模型更好的优化行为。

Conclusion: 量子嵌入能够有效替代经典嵌入，为混合量子PDE求解器提供了架构洞察，并为设计资源高效的量子物理信息学习方法提供了指导。

Abstract: Physics-informed neural networks (PINNs) and hybrid quantum-classical extensions provide a promising framework for solving partial differential equations (PDEs) by embedding physical laws directly into the learning process. In this work, we study embedding strategies for trainable embedding quantum physics-informed neural networks (TE-QPINNs) in the context of nonlinear reaction-diffusion (RD) systems. We introduce an extended TE-QPINN (x-TE-QPINN) architecture that supports both classical and fully quantum embeddings, enabling a controlled comparison between feedforward neural network-based feature maps and parameterized quantum circuit embeddings. The first architecture is the classical embedding feed-forward neural network-based TE-QPINN (FNN-TE-QPINN), while the latter variant is a purely quantum one, referred to as quantum embedding neural network-based TE-QPINN (QNN-TE-QPINN). The proposed framework employs hardware-efficient variational quantum circuits and species-specific readout operators to approximate coupled multi-field dynamics while enforcing governing equations, boundary conditions, and initial conditions through a physics-informed loss function. By isolating the embedding mechanism while keeping the variational ansatz, loss formulation, and optimization procedure fixed, we analyze the impact of embedding design on gradient structure, parameter scaling, and quantum resource requirements. Numerical experiments on one- and two-dimensional RD equations demonstrate that quantum embeddings can replace classical embeddings without degradation in solution accuracy and, in certain regimes, exhibit improved optimization behavior compared to classical PINNs and hybrid quantum models with fixed embeddings. These results provide architectural insight into hybrid quantum PDE solvers and inform the design of resource-efficient quantum physics-informed learning methods.

</details>


### [130] [Architectural Foundations for Checkpointing and Restoration in Quantum HPC Systems](https://arxiv.org/abs/2602.09325)
*Qiang Guan,Qinglei Cao,Xiaoyi Lu,Siyuan Niu*

Main category: quant-ph

TL;DR: 提出一种利用动态电路技术实现量子HPC可重启和容错执行的检查点与恢复设计，将检查点重新定义为控制流和算法状态问题而非量子态检查点。


<details>
  <summary>Details</summary>
Motivation: 量子HPC需要容错和可重启的执行机制，但传统量子态检查点面临量子态不可克隆定理的挑战，需要新的检查点方法。

Method: 利用动态电路技术，包括中间电路测量、经典前馈和条件执行，捕获程序状态（控制流和算法状态）而非量子态，实现量子工作流的正确恢复。

Result: 设计了一种适用于迭代和分阶段量子算法（如变分本征求解器、量子近似优化、量子模拟中的时间步进方法）的自然检查点恢复机制。

Conclusion: 通过重新定义检查点为控制流和算法状态问题，利用动态电路技术实现了量子HPC的可重启和容错执行，为量子科学计算提供了实用的检查点恢复解决方案。

Abstract: In this work, we explore the design of the checkpointing and restoration for quantum HPC that leverages dynamic circuit technology to enable restartable and resilient quantum execution. Rather than attempting to checkpoint quantum states, our approach redefines checkpointing as a control flow and algorithmic state problem. By exploiting mid-circuit measurements, classical feed forward, and conditional execution supported by dynamic circuits, we capture sufficient program state to allow correct restoration of quantum workflows after interruption or failure. This design aligns naturally with iterative and staged quantum algorithms such as variational eigensolvers, quantum approximate optimization, and time-stepping methods commonly used in quantum simulation and scientific computing.

</details>


### [131] [Spin-entanglement of an atomic pair through coupling to their thermal motion](https://arxiv.org/abs/2602.09327)
*Poramaporn Ruksasakchai,Lucile Sanchez,Marvin Weyland,Mikkel F. Andersen,Scott Parkins,Stuart S. Szigeti*

Main category: quant-ph

TL;DR: 热态相对运动下，两个碱金属原子通过自旋交换碰撞可以产生纠缠态，突破了热环境通常破坏纠缠的常规认知


<details>
  <summary>Details</summary>
Motivation: 研究在热态相对运动条件下（k_B T远大于自旋态能量），两个原子通过自旋交换碰撞能否产生纠缠，挑战热环境通常破坏量子纠缠的常规认知

Method: 使用光学镊子囚禁两个碱金属原子，通过自旋交换碰撞耦合原子的自旋态和相对运动，在热态相对运动条件下（k_B T >> 自旋态能量）实验研究自旋态的演化

Result: 实验发现初始非纠缠的自旋态可以演化成纠缠态，这与通常热环境破坏纠缠的预期相反；生成的纠缠态在技术上具有应用价值，原则上可以超越标准量子极限提高测量灵敏度

Conclusion: 热态相对运动下的自旋交换碰撞可以产生有用的纠缠态，这为未来技术中的鲁棒纠缠生成提供了有前景的途径

Abstract: The spin-dynamics of two alkali atoms in an optical tweezer is driven by spin-changing collisions that couple the spin-state of the atoms to their relative motion. This paper experimentally studies the resulting spin-states when the relative motion is in a thermal state with k B T much larger than the energies of the spin-states that take part in the dynamics. We find that an initially unentangled spin-state can evolve into an entangled state. This is contrary to the common case when coupling a quantum system to hot degrees of freedom leads to loss of entanglement and not its generation. Moreover, we show that the generated entanglement is technologically useful as it, in principle, can enhance the sensitivity of measurements beyond the standard quantum limit. This may provide a promising avenue for robust entanglement generation for future technologies.

</details>


### [132] [Quantum Correlation Dynamics Subjected to Quantum Reset-Driven Environment](https://arxiv.org/abs/2602.09348)
*R. Jafari,Ali Asadian,Mehdi Biderang,Alireza Akbari*

Main category: quant-ph

TL;DR: 研究两个中心量子比特与横向场伊辛链环境的相互作用，环境通过量子临界点(QCPs)线性驱动，并在演化过程中随机重置(QR)。分析QR如何改变量子比特间的纠缠和量子不和谐(discord)动力学。


<details>
  <summary>Details</summary>
Motivation: 探索在量子临界环境中，量子重置过程如何影响量子比特间的量子关联动力学。研究环境重置对量子纠缠和不和谐的影响机制，特别是在强耦合和弱耦合不同情况下的表现差异。

Method: 建立两个中心量子比特与横向场伊辛链环境的相互作用模型。环境通过量子临界点线性驱动，并在演化过程中引入随机量子重置(QR)过程，将环境重置到初始状态。分析强耦合和弱耦合两种情况下，量子纠缠(concurrence)和量子不和谐(discord)的动力学行为。

Result: 强耦合情况下，纠缠和不和谐在伊辛QCPs区间内出现显著复苏，但随QR率增加而减弱。弱耦合情况下量子关联单调减少。数值发现纠缠复苏峰随QR率呈指数衰减，而不和谐无明确标度行为。无QR时，弱耦合下关联在驱动场跨越第二个QCP时单调衰减；有QR时，纠缠和不和谐都经历振荡抑制，振荡周期随QR率或斜坡时间尺度减小而增加。

Conclusion: 量子重置过程显著影响量子比特间的关联动力学，在不同耦合强度下表现出不同行为。强耦合时QR抑制关联复苏，弱耦合时QR引入振荡抑制模式。纠缠和不和谐对QR的响应不同，纠缠表现出明确的指数标度行为，而不和谐则无此规律。

Abstract: We study two central qubits interacting with a transverse-field Ising chain that serves as their environment. The environment is driven linearly in time across its quantum critical points (QCPs) and, during the evolution, is subjected to quantum reset (QR), where it is returned at random times to its initial state. We investigate how such QR of the environmental spin chain modifies the dynamics of entanglement and quantum discord between the qubits. Our results show that in the strong-coupling regime, entanglement and discord exhibit pronounced revivals within the interval bounded by the Ising QCPs, but these revivals diminish as the QR rate increases. In contrast, weak coupling leads to a monotonic reduction of quantum correlations. Numerically, we find that the revival peaks of concurrence decay and scale exponentially with the QR rate, while quantum discord shows no clear scaling behavior. In the weak-coupling regime without QR, the correlations decay monotonically as the driven field crosses the second QCP. When QR is applied, however, both entanglement and discord undergo oscillatory suppression, with the oscillation period increasing as either the QR rate or the ramp time scale is reduced.

</details>


### [133] [Compressing Quantum Fisher Information](https://arxiv.org/abs/2602.09358)
*Rui Jie Tang,Jeremy Guenza Marcus,Noah Lupu-Gladstein,Arthur O. T. Pang,C. Pria Dobney,Giulio Chiribella,Aephraim M. Steinberg,Y. Batuhan Yilmaz*

Main category: quant-ph

TL;DR: 量子Fisher信息可以被压缩到单个量子比特中，仅需对数级经典比特辅助


<details>
  <summary>Details</summary>
Motivation: 研究量子信息压缩的可能性，探索如何将编码在纯量子态族中的相位参数信息高效压缩

Method: 提出两种压缩策略：基于Type-I融合门和基于后选择实现的CNOT门，通过迭代压缩量子比特对实现信息压缩

Result: 成功在光子实验平台上演示了压缩构建模块，证明量子Fisher信息可以被压缩到单个量子比特中

Conclusion: 量子相位参数信息可以被高效压缩，这为量子信息处理和量子计量学提供了新的可能性

Abstract: We show that the quantum Fisher information about any phase parameter encoded in a family of pure quantum states can be faithfully compressed into a single qubit, accompanied by a logarithmic amount of classical bits. When the phase is encoded into many identical copies of a qubit state on the equator of the Bloch sphere, we show that the compression can be implemented sequentially, by iteratively compressing pairs of qubits into a single qubit. We experimentally demonstrate this building block in a photonic setup, developing two alternative compression strategies, based on Type-I fusion gate and a postselected implementation of the CNOT gate.

</details>


### [134] [Surrogate-Guided Quantum Discovery in Black-Box Landscapes with Latent-Quadratic Interaction Embedding Transformers](https://arxiv.org/abs/2602.09374)
*Saisubramaniam Gopalakrishnan,Dagnachew Birru*

Main category: quant-ph

TL;DR: 提出一种将高阶变量依赖建模为二次哈密顿量的方法，用于量子辅助黑盒发现，在保持竞争力的效用同时显著提升结构多样性和极端情况发现


<details>
  <summary>Details</summary>
Motivation: 传统优化器倾向于集中在主导模式，质量多样性方法需要大量评估预算，而QAOA需要显式问题哈密顿量（在黑盒设置中不可用）。现有二次代理模型（如因子分解机）仅限于成对结构，无法捕捉高阶变量依赖。

Method: 通过自注意力建模高阶变量依赖，并将其投影到有效的正半定二次形式中，使其与QAOA兼容。这使得能够从学习的能量景观中进行多样性导向的量子采样，同时捕捉超越成对项的交互结构。

Result: 在企业文档处理系统的风险发现任务中，量子引导采样器在保持竞争力的效用同时，持续改善结构多样性和独家发现。该方法恢复的结构性尾部风险异常值大约是大多数经典基线的两倍，并识别出竞争方法未发现的高效用配置的独家非重叠部分。

Conclusion: 通过将高阶交互结构学习并投影到二次代理哈密顿量中，为量子辅助黑盒发现提供了有效机制，能够在严格查询预算下实现高效用和结构多样性的配置发现。

Abstract: Discovering configurations that are both high-utility and structurally diverse under expensive black-box evaluation and strict query budgets remains a central challenge in data-driven discovery. Many classical optimizers concentrate on dominant modes, while quality-diversity methods require large evaluation budgets to populate high-dimensional archives. Quantum Approximate Optimization Algorithm (QAOA) provides distributional sampling but requires an explicit problem Hamiltonian, which is unavailable in black-box settings. Practical quantum circuits favor quadratic Hamiltonians since higher-order interaction terms are costly to realize. Learned quadratic surrogates such as Factorization Machines (FM) have been used as proxies, but are limited to pairwise structure. We extend this surrogate-to-Hamiltonian approach by modelling higher-order variable dependencies via self-attention and projects them into a valid Positive Semi-Definite quadratic form compatible with QAOA. This enables diversity-oriented quantum sampling from learned energy landscapes while capturing interaction structure beyond pairwise terms. We evaluate on risk discovery for enterprise document processing systems against diverse classical optimizers. Quantum-guided samplers achieve competitive utility while consistently improving structural diversity and exclusive discovery. FM surrogates provide stronger early coverage, whereas ours yields higher-fidelity surrogate landscapes and better extreme-case discovery. Our method recovers roughly twice as many structurally tail-risk outliers as most classical baselines and identify an exclusive non-overlapping fraction of high-utility configurations not found by competing methods, highlighting that an effective mechanism for learning higher-order interaction structure and projecting it into quadratic surrogate Hamiltonians for quantum-assisted black-box discovery.

</details>


### [135] [The Trouble with Weak Values](https://arxiv.org/abs/2602.09380)
*Jacob A. Barandes*

Main category: quant-ph

TL;DR: 该论文挑战了弱值的单系统解释和奇异主张，认为这些解释涉及多种形式的谬误推理。


<details>
  <summary>Details</summary>
Motivation: 弱值在量子理论中具有技术性定义，最初作为特殊实验协议的结果出现。虽然弱值产生了重要的实际应用（如信号放大和量子态层析），但本文关注的是历史性和持续性的尝试：为弱值赋予透明的单系统解释，以及利用弱值对单个量子系统的性质和行为提出奇异主张。作者认为这些解释性主张存在问题。

Method: 通过论证分析的方法，指出这些解释性主张涉及多种形式的谬误推理。论文不关注弱值的实际应用，而是专注于批判性地分析其解释性主张。

Result: 论文挑战了将弱值解释为单个量子系统透明属性的观点，认为这些解释存在逻辑谬误。作者论证了这些解释性主张在推理上的缺陷。

Conclusion: 弱值的单系统解释和相关的奇异主张基于谬误推理，不应被接受为对单个量子系统性质和行为的有效描述。弱值虽然在实际应用中很有价值，但其解释需要更加谨慎和批判性的分析。

Abstract: In quantum theory, a weak value is a complex number with a somewhat technical definition: it is a ratio whose numerator is the matrix element of a self-adjoint operator and whose denominator is the inner product of a corresponding pair of state vectors. Weak values first appeared in the research literature in a pair of papers in 1987 and 1988, and were originally defined as the results of a special kind of experimental protocol involving non-disturbing measurements combined with an explicit form of post-selection. In the years since, subsequent papers on weak values have produced a number of important practical spin-offs, including new methods for signal amplification and quantum-state tomography. The present work is not concerned with those practical spin-offs, but with historical and ongoing attempts to assign weak values a transparent, single-system interpretation, as well as efforts that invoke weak values to make a number of exotic claims about the properties and behavior of individual quantum systems. This paper challenges these interpretational claims by arguing that they involve several forms of fallacious reasoning.

</details>


### [136] [Separating Quantum and Classical Advice with Good Codes](https://arxiv.org/abs/2602.09385)
*John Bostanci,Andrew Huang,Vinod Vaikuntanathan*

Main category: quant-ph

TL;DR: 该论文展示了QMA和QCMA之间的无条件经典预言分离，技术比先前工作更简单，并能扩展到其他分离，特别是首次实现了BQP/qpoly和BQP/poly之间的无条件经典预言分离。


<details>
  <summary>Details</summary>
Motivation: 证明量子证明验证类(QMA)和经典证明验证类(QCMA)之间存在无条件分离，改进先前工作的复杂技术，并扩展到其他重要的量子计算类分离问题。

Method: 基于Yamakawa和Zhandry提出的代码交集问题，结合具有极好列表恢复性质的编码，构建经典预言来实现分离。

Result: 成功展示了QMA和QCMA之间的无条件经典预言分离，并且首次实现了BQP/qpoly和BQP/poly之间的无条件经典预言分离，改进了先前工作的量子预言分离结果。

Conclusion: 该工作提供了更简单、更通用的技术来证明量子计算类之间的预言分离，为理解量子证明和经典证明、量子建议和经典建议之间的根本差异提供了新工具。

Abstract: We show an unconditional classical oracle separation between the class of languages that can be verified using a quantum proof ($\mathsf{QMA}$) and the class of languages that can be verified with a classical proof ($\mathsf{QCMA}$). Compared to the recent work of Bostanci, Haferkamp, Nirkhe, and Zhandry (STOC 2026), our proof is conceptually and technically simpler, and readily extends to other oracle separations. In particular, our techniques yield the first unconditional classical oracle separation between the class of languages that can be decided with quantum advice ($\mathsf{BQP}/\mathsf{qpoly}$) and the class of languages that can be decided with classical advice ($\mathsf{BQP}/\mathsf{poly}$), improving on the quantum oracle separation of Aaronson and Kuperberg (CCC 2007) and the classically-accessible classical oracle separation of Li, Liu, Pelecanos and Yamakawa (ITCS 2024).
  Our oracles are based on the code intersection problem introduced by Yamakawa and Zhandry (FOCS 2022), combined with codes that have extremely good list-recovery properties.

</details>


### [137] [Efficient and deterministic high-dimensional controlled-swap gates on hybrid linear optical systems with high fidelity](https://arxiv.org/abs/2602.09393)
*Gui-Long Jiang,Jun-Bin Yuan,Wen-Qiang Liu,Hai-Rui Wei*

Main category: quant-ph

TL;DR: 提出仅使用线性光学元件实现CNOT门和Fredkin门的方案，通过偏振和空间自由度编码，无需辅助光子或测量诱导非线性，光学深度为1且维度无关。


<details>
  <summary>Details</summary>
Motivation: 线性光学元件在量子计算中易于操控和实现，但传统方案需要辅助光子或测量诱导非线性，复杂度高。需要更简单高效的线性光学量子门实现方案。

Method: 采用混合编码：控制量子比特编码在光子偏振自由度（二维），目标量子比特编码在空间自由度（d维）。仅使用偏振分束器（PBS）构建CNOT门（1个PBS）和广义Fredkin门（d个PBS），无需辅助光子或测量诱导非线性。

Result: CNOT门仅需1个PBS，Fredkin门仅需d个PBS，光学深度均为1且与维度无关。三量子比特Fredkin门在现实条件下保真度高于99.7%，优于先前方案。

Conclusion: 该方案实现了高效、确定性的线性光学量子门，显著减少了元件数量和光学深度，保真度高，为线性光学量子计算提供了更实用的实现途径。

Abstract: Implementation of quantum logic gates with linear optical elements plays a prominent role in quantum computing due to the relatively easier manipulation and realization. We present efficient schemes to implement controlled-NOT (CNOT) gate and controlled-swap (Fredkin) gate by solely using linear optics. We encode the control qubits and target qudits in photonic polarization (two-level) and spatial degrees of freedom ($d$-level), respectively. Based on the hybrid encoding, CNOT and Fredkin gates are constructed in a deterministic way without any borrowed ancillary photons or measurement-induced nonlinearities. Remarkably, the number of linear optics required to implement a CNOT gate has been reduced to one polarization beam splitter (PBS), while only $d$ PBSs are necessary to implement a generalized Fredkin gate. The optical depths of all schemes are reduced to one and dimension-independent. Besides, the fidelity of our three-qubit Fredkin gate is higher than 99.7\% under realistic conditions, which is higher than the previous schemes.

</details>


### [138] [Near-optimal entanglement-communication tradeoffs for remote state preparation](https://arxiv.org/abs/2602.09428)
*Srijita Kundu,Olivier Lalonde*

Main category: quant-ph

TL;DR: 该论文研究了远程态制备(RSP)任务，针对秩k投影子P/k态给出了几乎匹配的上下界，首次为混合态RSP提供紧界，并改进了纯态RSP的下界。


<details>
  <summary>Details</summary>
Motivation: 研究远程态制备(RSP)任务的资源消耗，特别是对于秩k投影子P/k这类态。现有研究对混合态RSP的资源消耗缺乏紧致的上下界，需要建立更精确的理论框架。

Method: 通过理论分析建立RSP任务的纠缠消耗和通信消耗的上下界。使用信息论工具和纠缠蒸馏理论，证明纠缠消耗和通信消耗之间的权衡关系。

Result: 获得了几乎匹配的上下界：任何能以o(d)比特通信实现RSP的纠缠态可蒸馏出log d ebits纠缠；反之，任何能蒸馏log d ebits纠缠的态可高效实现RSP。还给出了新的等式函数通信协议。

Conclusion: 建立了RSP任务中纠缠和通信资源的基本关系，为混合态RSP提供了首个紧致界限，并展示了在通信复杂度中的应用价值。

Abstract: We study the following task: Alice is given a classical description of a rank-$k$ projector $P$ on $\mathbb{C}^d$, and Alice and Bob want to prepare the quantum state $P/k$ on Bob's side using shared entanglement and classical communication. The general form of this task is known as remote state preparation (RSP). We give nearly-matching lower and upper bounds for the entanglement cost and communication cost for RSP of the states $P/k$. Ours are the first nearly matching upper and lower bounds for RSP of mixed states, and in the special case of pure states, our lower bound outperforms the best previously known lower bound. Our results show that any pure entangled state that can be used to do RSP of these states with $o(d)$ bits of communication, can distill $\log d$ ebits of entanglement, and conversely, any state that can distill $\log d$ ebits of entanglement can be used to do RSP of these states efficiently. As applications of our results, we rederive a previously-known incompressibility result for states of the form $P/k$, and give a new entanglement-assisted communication protocol for the equality function that uses $\frac{1}{2}\log n + O(1)$ many ebits, and $O(1)$ communication.

</details>


### [139] [Resources of the advantage in quantum Illumination: Discord and entanglement](https://arxiv.org/abs/2602.09468)
*Mojtaba Asadollahi,Mohammad Hossein Zarei*

Main category: quant-ph

TL;DR: 量子照明中，两比特混合态的量子优势由初始纠缠和量子失谐共同决定，优势大小等于消耗的失谐量，高噪声下优势与失谐呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 研究量子照明协议中量子优势的来源，探究初始纠缠和量子失谐这两种量子关联如何共同影响照明性能，特别是在噪声环境下的表现。

Method: 使用两比特混合态作为初始资源，通过条件极值分析研究优势与纠缠、失谐的关系。对具有相同优势和初始失谐的状态聚类，计算每个簇内最大和最小初始纠缠；对具有相同优势和初始纠缠的状态，计算最大和最小初始失谐。

Result: 量子优势等于消耗的失谐量；相同初始失谐的状态可产生不同优势；固定初始失谐时，最大纠缠随优势增加而增加；固定初始纠缠时，最小失谐随优势单调增加；高噪声下优势与初始失谐呈线性依赖关系。

Conclusion: 对于给定初始失谐，更高的纠缠是获得更高优势的充分但不必要条件；对于给定初始纠缠，更高的失谐是获得更高优势的必要但不总是充分条件；失谐是协议抵抗噪声的关键资源。

Abstract: We investigate the quantum advantage in quantum illumination using two-qubit mixed states as the initial resource. We show that in quantum illumination, the achievable advantage is determined by an interplay between initial entanglement and discord. First, we rigorously show that the quantum advantage for a given state equals the amount of discord consumed for illumination. Subsequently, we find that states with identical initial discord can lead to varying advantages, indicating that the usable portion of discord for illumination depends on additional structural features of the state. Then, we consider the relation between the advantage and both entanglement and discord by performing a conditional extremal analysis. To this end, for states clustered by identical advantage and initial discord, we compute the maximum and minimum initial entanglement within each cluster. We demonstrate that, for states with fixed initial discord, the maximum (and not minimum) entanglement increases by increment of the advantage. We conclude that for any given initial discord, higher entanglement is a sufficient (but not necessary) resource for higher advantage. On the other hand, for states clustered by identical advantage and initial entanglement, we compute the maximum and minimum initial discord in each group. Here, the minimum (and not always maximum) discord scales monotonically with advantage. It shows that, for fixed initial entanglement, higher discord is a necessary (but not always sufficient) resource for higher advantage. This result provides a refined, operational perspective on how different forms of quantum correlations govern the performance of the illumination protocol. We finally find a persistent linear dependence of the advantage on initial discord in the high-noise regime, highlighting discord as the key resource for resilience to noise in the protocol.

</details>


### [140] [Rigorous no-go theorems for heralded linear-optical state generation tasks](https://arxiv.org/abs/2602.09495)
*Deepesh Singh,Ryan J. Marshman,Luis Villegas-Aguilar,Jens Eisert,Nora Tischler*

Main category: quant-ph

TL;DR: 该论文提出使用代数几何中的零点定理线性代数算法来解决光子量子态制备中的可行性判定问题，能够提供确定性的不可行证明，并用于验证和建立光学态和门实现所需物理资源的下界。


<details>
  <summary>Details</summary>
Motivation: 光子量子技术面临的主要挑战是如何利用简单输入态、线性光学和辅助光子测量来制备合适的离散变量量子态。由于单光子水平上缺乏强非线性，光子态制备无法像其他物理平台那样采用确定性的门基方法，只能通过单光子、线性光学网络和光子检测进行概率性实现。然而，判断特定测量模式能否将输入态转换为目标态是一个复杂的多项式方程组可行性判定问题。

Method: 应用代数几何中的零点定理线性代数算法来解决量子态生成问题。该算法通过证明不可行性，为量子态制备任务提供确定性的"不可能"结果。将量子态制备问题映射到多项式方程组的可行性判定，然后使用该算法进行分析。

Result: 该方法能够提供确定性的不可行证明，当量子态制备任务无解时能够证明其不可行性。作者展示了该能力，验证并建立了实现几种常见光学态和门所需的物理资源的下界。

Conclusion: 零点定理线性代数算法为解决光子量子态制备中的可行性判定问题提供了有效的数学工具，能够为量子态制备任务提供确定性的不可行证明，有助于优化和验证光子量子技术的资源需求。

Abstract: A major challenge in photonic quantum technologies is developing strategies to prepare suitable discrete-variable quantum states using simple input states, linear optics, and auxiliary photon measurements to identify successful outcomes. Fundamentally, this challenge arises from the lack of strong non-linearities on the single-photon level, meaning that photonic state preparation based on linear optics cannot benefit from the deterministic gate-based approach available to other physical platforms. Instead, the preparation of quantum states can be probabilistically implemented using single photons, linear-optical networks, and photon detection. However, determining whether an input state can be transformed into a target state using a specific measurement pattern - a problem that can be mapped to deciding the feasibility of a system of polynomial equations - is a complex problem in general. To solve it, we apply the Nullstellensatz Linear Algebra algorithm from algebraic geometry to quantum state generation; this can provide definitive no-go results by proving infeasibility when the state preparation task in question has no solution. We demonstrate this capability to validate and establish lower bounds on the physical resource requirements for the realization of several ubiquitous optical states and gates.

</details>


### [141] [Fidelity-Age-Aware Scheduling in Quantum Repeater Networks](https://arxiv.org/abs/2602.09562)
*Ozgur Ercetin,Zafer Gedik*

Main category: quant-ph

TL;DR: 提出Fidelity-Age(FA)指标来衡量量子网络中纠缠态的新鲜度，开发轻量级调度器FA-THR和FA-INDEX来最小化FA，在保持吞吐量的同时将极端老化事件减少两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有量子中继器网络研究主要关注吞吐量和保真度，但忽视了纠缠态的新鲜度（从上次交付可用贝尔对到现在的时间）。新鲜度对量子通信的可靠性至关重要，需要新的指标和调度策略来平衡保真度、延迟和资源竞争。

Method: 1. 提出Fidelity-Age(FA)指标，测量保真度超过阈值Fmin的状态的时间间隔；2. 采用更新理论将时隙级成功概率与长期平均FA联系起来；3. 建立随机控制问题，在预算和内存限制下最小化FA；4. 开发两个轻量级调度器FA-THR和FA-INDEX，近似Lyapunov漂移最优控制。

Result: 在时隙中继器网格上的仿真显示：FA感知调度在保持吞吐量的同时，将极端老化事件减少高达两个数量级。FA指标为量子网络提供了可处理的、物理基础的可靠及时纠缠交付度量。

Conclusion: Fidelity-Age(FA)是一个可处理的、物理基础的指标，能够有效衡量量子网络中纠缠态的新鲜度。FA感知调度策略在保持吞吐量的同时显著改善了纠缠交付的及时性，为量子网络的可靠运行提供了新方法。

Abstract: Quantum repeater networks distribute entanglement over long distances but must balance fidelity, delay, and resource contention. Prior work optimized throughput and end-to-end fidelity, yet little attention has been paid to the freshness of entanglement-the time since a usable Bell pair was last delivered. We introduce the Fidelity-Age (FA) metric, which measures this interval for states whose fidelity exceeds a threshold Fmin. A renewal formulation links slot-level success probability to long-run average FA, enabling a stochastic control problem that minimizes FA under budget and memory limits. Two lightweight schedulers, FA-THR and FA-INDEX, approximate Lyapunov-drift-optimal control. Simulations on slotted repeater grids show that FA-aware scheduling preserves throughput while reducing extreme-age events by up to two orders of magnitude. Fidelity-Age thus provides a tractable, physically grounded metric for reliable and timely entanglement delivery in quantum networks.

</details>


### [142] [Amplitude-Phase Separation toward Optimal and Fast-Forwardable Simulation of Non-Unitary Dynamics](https://arxiv.org/abs/2602.09575)
*Qitong Hu,Shi Jin*

Main category: quant-ph

TL;DR: APS方法将非幺正演化分解为幺正算符和厄米算符的分别模拟，利用移位Dyson级数实现最优查询复杂度，并通过平方根依赖关系实现快速推进，优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 量子模拟线性非幺正动力学在科学计算中至关重要，但现有方法不够高效，需要开发能够充分利用幺正和厄米演化算法优势的通用框架。

Method: 提出振幅-相位分离（APS）方法，将非幺正演化分解为幺正算符和厄米算符的分别模拟。采用两种技术：1）通过移位Dyson级数实现最优查询复杂度；2）打破传统线性依赖，通过平方根依赖实现快速推进。

Result: APS方法为通用非幺正动力学提供了有效且通用的量子算法开发途径，能够实现最优查询复杂度或快速推进特性，优于相同问题的现有算法。现有方法如LCHS和NDME可以从APS推导出来。

Conclusion: APS框架为量子模拟非幺正动力学提供了通用且高效的解决方案，能够充分利用现有幺正和厄米演化算法的优势，并在查询复杂度和快速推进方面实现显著改进。

Abstract: Quantum simulation of the linear non-unitary dynamics is crucial in scientific computing. In this work, we establish a generic framework, referred to as the Amplitude-Phase Separation (APS) methods, which formulates any non-unitary evolution into separate simulation of a unitary operator and a Hermitian operator, thus allow one to take best advantage of, and to even improve existing algorithms, developed for unitary or Hermitian evolution respectively. We utilize two techniques: the first achieves a provably optimal query complexity via a shifted Dyson series; the second breaks the conventional linear dependency, achieving fast-forwarding by exhibiting a square-root dependence on the norm of the dissipative part. Furthermore, one can derive existing methods such as the LCHS (Linear Combination of Hamiltonian Simulation) and the NDME (Non-Diagonal Density Matrix Encoding) methods from APS. The APS provides an effective and generic pathway for developing efficient quantum algorithms for general non-unitary dynamics to achieve either optimal query complexity or fast-forwarding property, outperforming the existing algorithms for the same problems.

</details>


### [143] [Device-independent quantum key distribution over 100 km with single atoms](https://arxiv.org/abs/2602.09596)
*Bo-Wei Lu,Chao-Wei Yang,Run-Qi Wang,Bo-Feng Gao,Yi-Zheng Zhen,Zhen-Gang Wang,Jia-Kai Shi,Zhong-Qi Ren,Thomas A. Hahn,Ernest Y. -Z. Tan,Xiu-Ping Xie,Ming-Yang Zheng,Xiao Jiang,Jun Zhang,Feihu Xu,Qiang Zhang,Xiao-Hui Bao,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 实现了100公里光纤连接的设备无关量子密钥分发，通过单光子干涉和量子频率转换提高纠缠速率，在11公里距离上获得了0.112比特/事件的安全密钥率。


<details>
  <summary>Details</summary>
Motivation: 设备无关量子密钥分发是量子互联网的关键应用，但现有实验与真实世界应用之间存在差距，需要实现长距离、高纠缠速率的实际系统。

Method: 采用单光子干涉进行纠缠预示，利用量子频率转换降低光纤损耗，设计基于里德堡的发射方案抑制光子反冲效应，在两个单原子节点间建立连接。

Result: 实现了100公里光纤距离的高保真度原子-原子纠缠和正渐近密钥率；在11公里距离上，624小时内制备了120万个预示贝尔对，获得了0.112比特/事件的可提取有限尺寸安全密钥率。

Conclusion: 该工作填补了原理验证量子网络实验与实际应用之间的空白，为设备无关量子密钥分发的实际部署奠定了基础。

Abstract: Device-independent quantum key distribution (DI-QKD) is a key application of the quantum internet. We report the realization of DI-QKD between two single-atom nodes linked by 100-km fibers. To improve the entangling rate, single-photon interference is leveraged for entanglement heralding, and quantum frequency conversion is used to reduce fiber loss. A tailored Rydberg-based emission scheme suppresses the photon recoil effect on the atom without introducing noise. We achieved high-fidelity atom-atom entanglement and positive asymptotic key rates for fiber lengths up to 100 km. At 11 km, 1.2 million heralded Bell pairs were prepared over 624 hours, yielding an estimated extractable finite-size secure key rate of 0.112 bits per event against general attacks. Our results close the gap between proof-of-principle quantum network experiments and real-world applications.

</details>


### [144] [Strategy optimization for Bayesian quantum parameter estimation with finite copies: Adaptive greedy, parallel, sequential, and general strategies](https://arxiv.org/abs/2602.09655)
*Erik L. André,Jessica Bavaresco,Mohammad Mehboudi*

Main category: quant-ph

TL;DR: 提出基于高阶操作的算法，通过半正定规划寻找贝叶斯量子参数估计的最优策略，比较并行、顺序和不定因果顺序等不同协议类别的性能。


<details>
  <summary>Details</summary>
Motivation: 研究在有限次使用编码未知物理量的过程时，如何确定贝叶斯量子参数估计的最优策略，包括输入态、控制操作、测量和估计器的选择。

Method: 使用高阶操作形式主义开发算法，基于半正定规划实现高效数值计算，并探索基于经典前馈的贪婪自适应策略。

Result: 算法在基准测试中表现出强大而精确的性能，发现不同协议类别之间存在严格层次结构，量子记忆辅助类别的性能相近但显著优于贪婪自适应策略。

Conclusion: 提出的算法能有效寻找贝叶斯量子参数估计的最优策略，揭示了不同量子计量协议类别的性能差异，为量子计量学提供了有力的数值工具。

Abstract: In this work, we study Bayesian quantum parameter estimation given a finite number of uses of the process encoding one or more unknown physical quantities. For multiple uses, it is conventional to classify quantum metrological protocols as parallel, sequential, or indefinite causal order. Within each class, the central question is to determine the optimal strategy -- namely, the choice of optimal input state, control operations, measurement, and estimator(s) -- to perform the estimation task. Using the formalism of higher-order operations, we develop an algorithm that looks for the optimal solution, and we provide an efficient numerical implementation based on semidefinite programming. Our benchmark examples, specifically those against existing analytical solutions, demonstrate how powerful and precise our method is. We further explore the potential of greedy adaptive strategies, which are based on classical feedforward to design the optimal protocol for the next round. Using this framework, we compare the optimal achievable Bayesian score across classes. We demonstrate the strength of our algorithm in several examples, from single to multiparameter estimation and with various prior distributions. Particularly, we find examples in which there is a strict hierarchy between different classes. Nonetheless, the performance of the different quantum memory-assisted classes are not significantly different, while they may significantly outperform the adaptive greedy strategy.

</details>


### [145] [Tunable many-body burst in isolated quantum systems](https://arxiv.org/abs/2602.09665)
*Shozo Yamada,Akihiro Hokkyo,Masahito Ueda*

Main category: quant-ph

TL;DR: 提出一种数值方法构造低纠缠初态，可在指定时间产生磁化爆发现象，并在量子混沌时间尺度上实现，同时伴随缓慢或负纠缠增长。


<details>
  <summary>Details</summary>
Motivation: 研究孤立量子多体系统中的非单调热化过程，探索如何通过精心设计的初态在特定时间产生瞬态偏离热平衡的现象（爆发现象）。

Method: 提出数值方法构造低纠缠初态，使其在指定时间产生磁化爆发现象；应用于非可积混合场Ising链，分析量子混沌时间尺度上的动力学行为。

Result: 成功在非可积混合场Ising链中实现磁化爆发现象，时间尺度与量子混沌起始相当；爆发现象伴随缓慢甚至负的纠缠增长；理论上证明长时间后爆发现象概率稀有。

Conclusion: 通过适当选择初态，可在量子混沌主导前维持非平衡态；这些预测可通过可编程量子模拟器实验验证，为控制量子多体系统非平衡动力学提供新途径。

Abstract: Thermalization in isolated quantum many-body systems can be nonmonotonic, with its process dependent on an initial state. We propose a numerical method to construct a low-entangled initial state that creates a ``burst''$\unicode{x2013}\unicode{x2013}$a transient deviation of an observable from its thermal equilibrium value$\unicode{x2013}\unicode{x2013}$at a designated time. We apply this method to demonstrate that a burst of magnetization can be realized for a nonintegrable mixed-field Ising chain on a timescale comparable to the onset of quantum scrambling. Contrary to the typical spreading of information in this regime, the created burst is accompanied by a slow or even negative entanglement growth. Analytically, we show that a burst becomes probabilistically rare after a long time. Our results suggest that a nonequilibrium state is maintained for an appropriately chosen initial state until scrambling becomes dominant. These predictions can be tested with programmable quantum simulators.

</details>


### [146] [Quantum-accelerated conjugate gradient methods via spectral initialization](https://arxiv.org/abs/2602.09696)
*Shigetora Miyashita,Yoshi-aki Shimada*

Main category: quant-ph

TL;DR: 提出量子加速共轭梯度框架，用量子算法生成谱信息初始猜测来加速经典CG求解器，而非完全替代经典计算


<details>
  <summary>Details</summary>
Motivation: 大规模线性系统求解在科学和工业计算中至关重要。经典迭代求解器在未知数增多时面临困难，而完全量子线性求解器需要容错资源，短期内难以实现。需要探索量子-经典混合方法，利用量子计算作为经典HPC工作流的加速器

Method: 提出量子加速共轭梯度框架：使用容错量子算法专门构造具有谱信息的初始猜测，供经典共轭梯度求解器使用。量子子程序作为合作加速器，选择性抑制导致经典收敛缓慢的低能谱分量。通过可控的条件数分解，在量子和经典求解器之间灵活分配计算资源

Result: 分析了3D泊松方程的总运行时间和资源需求。在明确的架构假设下，识别出该合作策略比纯经典方法具有运行时间优势，同时比端到端量子线性求解器需要更少的量子资源

Conclusion: 为早期容错量子计算在科学和工业应用提供了具体路径，指向可扩展的混合范式：量子设备作为高性能计算工作流中的加速器，而非独立替代品

Abstract: Solving large-scale linear systems problems is a central task in scientific and industrial computing. Classical iterative solvers face increasing difficulty as the number of unknowns becomes large, while fully quantum linear solvers require fault-tolerant resources that remain far beyond near-term feasibility. Here we propose a quantum-accelerated conjugate gradient (QACG) framework in which a fault-tolerant quantum algorithm is used exclusively to construct a spectrally informed initial guess for a classical conjugate gradient (CG) solver. Rather than replacing classical kernels, the quantum subroutine functions as a cooperative accelerator that selectively suppresses low-energy spectral components responsible for slow classical convergence. We analyze the total runtime and resource requirements of this integrated quantum-HPC platform for the 3D Poisson equation. A central feature of QACG is a controllable decomposition of the condition number between the quantum and the classical solver, enabling flexible allocation of computational effort across quantum and classical resources. Under explicit architectural assumptions, we identify regimes in which this cooperative strategy yields a runtime advantage over purely classical approaches while requiring substantially fewer quantum resources than end-to-end quantum linear solvers. These results illustrate a concrete pathway toward the scientific and industrial use of early-stage fault-tolerant quantum computing and point to a scalable hybrid paradigm in which quantum devices act as accelerators within high-performance computing workflows rather than as standalone replacements.

</details>


### [147] [Sample- and Hardware-Efficient Fidelity Estimation by Stripping Phase-Dominated Magic](https://arxiv.org/abs/2602.09710)
*Guedong Park,Jaekwon Chang,Yosep Kim,Yong Siah Teo,Hyunseok Jeong*

Main category: quant-ph

TL;DR: 提出了一种样本和门高效的保真度估计算法，通过相位剥离技术显著降低目标态魔法性，仅需多项式样本和单个扇出门即可估计接近相位态结构的纯态保真度。


<details>
  <summary>Details</summary>
Motivation: 传统的直接保真度估计（DFE）方法由于目标态的高魔法性通常需要指数级样本，这在实际量子设备中难以实现。需要开发在有限量子资源下可行的保真度估计算法。

Method: 提出相位剥离技术，通过非线性经典后处理将复杂的对角门资源转化为泡利测量，仅需单个n-量子比特扇出门。还提出了传统DFE的非线性扩展方案。

Result: 对于接近相位态结构的纯态，仅需O(poly(n))样本即可估计保真度；当目标态为相位态时，样本复杂度降至O(1)。相比传统DFE显著降低了采样开销。

Conclusion: 该工作通过相位剥离和非线性后处理实现了在受限门资源下的高效保真度估计，有助于建立噪声弹性量子算法，并澄清理解复杂物理性质与生成它们所需资源开销之间的基本差距。

Abstract: Direct fidelity estimation (DFE) is a famous tool for estimating the fidelity with a target pure state. However, such a method generally requires exponentially many sampling copies due to the large magic of the target state. This work proposes a sample- and gate-efficient fidelity estimation algorithm that is affordable within feasible quantum devices. We show that the fidelity estimation with pure states close to the structure of phase states, for which sample-efficient DFE is limited by their strong entanglement and magic, can be done by using $\mathcal{O}(\mathrm{poly}(n))$ sampling copies, with a single $n$-qubit fan-out gate. As the target state becomes a phase state, the sampling complexity reaches $\mathcal{O}(1)$. Such a drastic improvement stems from a crucial step in our scheme, the so-called phase stripping, which can significantly reduce the target-state magic. Furthermore, we convert a complex diagonal gate resource, which is needed to design a phase-stripping-adapted algorithm, into nonlinear classical post-processing of Pauli measurements so that we only require a single fan-out gate. Additionally, as another variant using the nonlinear post-processing, we propose a nonlinear extension of the conventional DFE scheme. Here, the sampling reduction compared to DFE is also guaranteed, while preserving the Pauli measurement as the only circuit resource. We expect our work to contribute to establishing noise-resilient quantum algorithms by enabling a significant reduction in sampling overhead for fidelity estimation under the restricted gate resources, and ultimately to clarifying a fundamental gap between the resource overhead required to understand complex physical properties and that required to generate them.

</details>


### [148] [SAQNN: Spectral Adaptive Quantum Neural Network as a Universal Approximator](https://arxiv.org/abs/2602.09718)
*Jialiang Tang,Jialin Zhang,Xiaoming Sun*

Main category: quant-ph

TL;DR: 该论文提出了一种构造性量子神经网络模型，证明了其具有通用逼近性质，能够以任意精度逼近任何平方可积函数，并在电路规模和参数复杂度方面优于经典前馈神经网络。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习领域目前面临量子神经网络表达能力理论基础不完整的挑战。现有的量子神经网络模型缺乏对通用逼近性质的严格理论保证，这限制了其在实际应用中的可靠性和性能评估。

Method: 提出了一种构造性量子神经网络模型，该模型支持切换函数基，能够适应数值逼近和机器学习中的各种场景。通过理论分析证明了该模型具有通用逼近性质。

Result: 该量子神经网络模型在电路规模方面具有渐近优势，优于最佳经典前馈神经网络。在L2范数下逼近Sobolev函数时，实现了最优参数复杂度。

Conclusion: 该研究为量子神经网络提供了坚实的理论基础，证明了其通用逼近能力，并为量子机器学习在数值逼近和机器学习任务中的应用开辟了新的可能性。

Abstract: Quantum machine learning (QML), as an interdisciplinary field bridging quantum computing and machine learning, has garnered significant attention in recent years. Currently, the field as a whole faces challenges due to incomplete theoretical foundations for the expressivity of quantum neural networks (QNNs). In this paper we propose a constructive QNN model and demonstrate that it possesses the universal approximation property (UAP), which means it can approximate any square-integrable function up to arbitrary accuracy. Furthermore, it supports switching function bases, thus adaptable to various scenarios in numerical approximation and machine learning. Our model has asymptotic advantages over the best classical feed-forward neural networks in terms of circuit size and achieves optimal parameter complexity when approximating Sobolev functions under $L_2$ norm.

</details>


### [149] [Error-mitigated quantum state tomography using neural networks](https://arxiv.org/abs/2602.09733)
*Yixuan Hu,Mengru Ma,Jiangwei Shang*

Main category: quant-ph

TL;DR: 提出基于多层感知机网络的量子态层析方法，通过监督学习缓解未知噪声，无需对噪声模型或测量做显式假设，适用于一般量子系统。


<details>
  <summary>Details</summary>
Motivation: 量子态层析是量子信息科学中表征量子态的基本任务，但实验噪声会降低层析精度。在现实环境中，缓解噪声对于准确估计量子态至关重要。

Method: 基于多层感知机网络的监督学习方法，数据驱动，不依赖对噪声模型或测量的显式假设，具有可扩展性。

Result: 数值模拟（从特殊纯态到随机混合态）表明，相比无缓解的情况，该方法在多种场景下都能有效缓解噪声。

Conclusion: 该方法为量子态层析提供了一种可扩展的噪声缓解方案，适用于一般量子系统，在现实实验条件下具有应用潜力。

Abstract: The reliable characterization of quantum states is a fundamental task in quantum information science. For this purpose, quantum state tomography provides a standard framework for reconstructing quantum states from measurement data, yet it is often degraded by experimental noise. Mitigating such noise is therefore essential for the accurate estimation of the states in realistic settings. In this work, we propose a scalable tomography method based on multilayer perceptron networks that mitigate unknown noise through supervised learning. This approach is data-driven and thus does not rely on explicit assumptions about the noise model or measurement, making it readily extendable to general quantum systems. Numerical simulations, ranging from special pure states to random mixed states, demonstrate that the proposed method effectively mitigates noise across a broad range of scenarios, compared with the case without mitigation.

</details>


### [150] [Beyond Sparsity: Quantum Block Encoding for Dense Matrices via Hierarchically Low Rank Compression](https://arxiv.org/abs/2602.09745)
*Kun Tang,Jun Lai*

Main category: quant-ph

TL;DR: 将量子线性方程求解算法从稀疏矩阵扩展到层次块可分离(HBS)稠密矩阵，提出了两种方法：预处理转化为稀疏格式和直接块编码方案。


<details>
  <summary>Details</summary>
Motivation: 现有量子线性方程求解算法主要局限于稀疏矩阵，而许多实际应用（如势理论、协方差建模、计算物理）中出现的稠密矩阵无法直接应用这些算法。需要扩展量子算法的适用范围到层次块可分离(HBS)这类结构化稠密矩阵。

Method: 提出了两种方法：1) 预处理方法：将稠密矩阵转换为更大但稀疏的格式；2) 直接块编码方案：利用HBS结构递归构建必要的oracle。两种方法都提供了详细的复杂度分析和严格的误差界。

Result: 通过数值实验验证了两种方法的有效性，成功将量子线性方程求解算法扩展到HBS稠密矩阵，为量子算法在更广泛的实际问题中应用提供了途径。

Conclusion: 该工作成功扩展了量子线性方程求解算法的适用范围，使其能够处理层次块可分离稠密矩阵，为量子计算在科学计算和工程应用中的实际部署提供了重要工具。

Abstract: While quantum algorithms for solving large scale systems of linear equations offer potential speedups, their application has largely been confined to sparse matrices. This work extends the scope of these algorithms to a broad class of structured dense matrices arise in potential theory, covariance modeling, and computational physics, namely, hierarchically block separable (HBS) matrices. We develop two distinct methods to make these systems amenable to quantum solvers. The first is a pre-processing approach that transforms the dense matrix into a larger but sparse format. The second is a direct block encoding scheme that recursively constructs the necessary oracles from the HBS structure. We provide a detailed complexity analysis and rigorous error bounds for both methods. Numerical experiments are presented to validate the effectiveness of our approaches.

</details>


### [151] [Questioning the reasonableness of the quantum nonlocality debate](https://arxiv.org/abs/2602.09758)
*Justo Pastor Lambare*

Main category: quant-ph

TL;DR: 该论文批判性地讨论了量子非定域性辩论中普遍存在的逻辑严谨性缺失问题，指出强烈信念常压倒理性评估，导致松散观念成为根深蒂固的教条。


<details>
  <summary>Details</summary>
Motivation: 作者观察到量子非定域性辩论中存在逻辑严谨性不足的问题，强烈信念往往压倒理性评估，松散观念被接受并成为根深蒂固的教条，缺乏合理理据和逻辑推理规则的遵守导致广泛接受的自相矛盾观点很少受到概念性审视。

Method: 采用批判性讨论和逻辑分析方法，审视量子非定域性辩论中的论证结构，强调逻辑推理规则的重要性，揭示辩论中存在的逻辑缺陷和自相矛盾。

Result: 识别出量子非定域性辩论中普遍存在的逻辑严谨性缺失现象，揭示了强烈信念如何导致理性评估被压倒，松散观念如何成为教条，以及缺乏逻辑推理规则如何产生被广泛接受但很少受到审视的自相矛盾观点。

Conclusion: 量子非定域性辩论需要更强的逻辑严谨性，必须回归理性评估和逻辑推理规则，避免让强烈信念和教条化观念主导科学讨论，以促进对这一基础物理概念的更清晰理解。

Abstract: We critically discuss the apparent lack of logical rigor pervading the debate on quantum nonlocality. Strong convictions often prevail over rational assessment, leading to the acceptance of loose ideas that become entrenched dogmas. The lack of sound rationales and adherence to the rules of logical inference lead to widely adopted antinomies that receive little conceptual scrutiny.

</details>


### [152] [Construction of the full logical Clifford group for high-rate quantum Reed-Muller codes using only transversal and fold-transversal gates](https://arxiv.org/abs/2602.09788)
*Theerapat Tansuwannont,Tim Chan,Ryuji Takagi*

Main category: quant-ph

TL;DR: 该论文为高码率量子Reed-Muller码族构建了完整的逻辑Clifford群生成集，仅使用横向和折叠横向门，无需辅助量子比特，实现了可寻址的逻辑门操作。


<details>
  <summary>Details</summary>
Motivation: 构建大规模量子计算机需要高码率量子纠错码以高效编码信息，但在高码率码中实现可寻址的逻辑门面临挑战，通常需要辅助量子比特。横向和折叠横向门可提供无需辅助量子比特的容错实现，但可用门类型受限于具体编码。

Method: 研究一族自对偶量子Reed-Muller码（参数为[[n=2^m, k≈n/√(πlog₂(n)/2), d=√n]]），为该码族构造完整的逻辑Clifford群生成集，仅使用横向和折叠横向门。

Result: 成功为该码族构建了完整的逻辑Clifford群生成集，实现了任何可寻址Clifford门的实现，这是首个在k随n近线性增长（相差1/√log n因子）的码族中仅使用横向和折叠横向门构建完整逻辑Clifford群的工作。

Conclusion: 该工作展示了在高码率量子纠错码中仅使用横向和折叠横向门实现完整逻辑Clifford群的可能性，为大规模量子计算提供了无需辅助量子比特的容错逻辑门实现方案。

Abstract: To build large-scale quantum computers while minimizing resource requirements, one may want to use high-rate quantum error-correcting codes that can efficiently encode information. However, realizing an addressable gate$\unicode{x2014}$a logical gate on a subset of logical qubits within a high-rate code$\unicode{x2014}$in a fault-tolerant manner can be challenging and may require ancilla qubits. Transversal and fold-transversal gates could provide a means to fault-tolerantly implement logical gates using a constant-depth circuit without ancilla qubits, but available gates of these types could be limited depending on the code and might not be addressable. In this work, we study a family of $[\![n=2^m,k={m \choose m/2}\approx n/\sqrt{π\log_2(n)/2},d=2^{m/2}=\sqrt{n}]\!]$ self-dual quantum Reed$\unicode{x2013}$Muller codes, where $m$ is a positive even number. For any code in this family, we construct a generating set of the full logical Clifford group comprising only transversal and fold-transversal gates, thus enabling the implementation of any addressable Clifford gate. To our knowledge, this is the first known construction of the full logical Clifford group for a family of codes in which $k$ grows near-linearly in $n$ up to a $1/\sqrt{\log n}$ factor that uses only transversal and fold-transversal gates without requiring ancilla qubits.

</details>


### [153] [$k$-Positivity and high-dimensional bound entanglement under symplectic group symmetry](https://arxiv.org/abs/2602.09860)
*Sang-Jun Park*

Main category: quant-ph

TL;DR: 该论文研究了具有辛群对称性的线性映射和二分量子态的k-正性和Schmidt数结构，完全刻画了相关条件，构造了最优k-正不可分解映射，并发现了大量Schmidt数为d/2的PPT纠缠态。


<details>
  <summary>Details</summary>
Motivation: 研究具有辛群对称性的量子映射和态的结构，为系统研究正不可分解性和高程度PPT纠缠提供自然且解析可处理的框架。

Method: 考虑两类对象：(1)在酉辛矩阵S共轭作用下协变的线性映射；(2)在S⊗S或S⊗S̅作用下不变的d⊗d二分态。通过两个实参数参数化这些对象，分析其k-正性、可分解性和Schmidt数。

Result: 完全刻画了所有k-正性和可分解性条件；显式计算了对应二分态的Schmidt数；构造了Schmidt数为d/2的PPT态类；首次显式构造了任意k=1,...,d/2-1的最优k-正不可分解线性映射；证明了PPT平方猜想在辛协变类中成立；解决了Pal和Vertesi关于PPT纠缠半定规划下界的猜想。

Conclusion: 辛群对称性为研究量子信息中的正不可分解映射和PPT纠缠提供了系统框架，获得了多个重要理论结果，包括最优k-正映射构造和高Schmidt数PPT态的发现。

Abstract: We investigate the structure of $k$-positivity and Schmidt numbers for classes of linear maps and bipartite quantum states exhibiting symplectic group symmetry. Specifically, we consider (1) linear maps on $M_d(\mathbb{C})$ which are covariant under conjugation by unitary symplectic matrices $S$, and (2) $d\otimes d$ bipartite states which are invariant under $S\otimes S$ or $S\otimes \overline{S}$ actions, each parametrized by two real variables. We provide a complete characterization of all $k$-positivity and decomposability conditions for these maps and explicitly compute the Schmidt numbers for the corresponding bipartite states. In particular, our analysis yields a broad class of PPT states with Schmidt number $d/2$ and the first explicit constructions of (optimal) $k$-positive indecomposable linear maps for arbitrary $k=1,\ldots, d/2-1$, achieving the best-known bounds. Overall, our results offer a natural and analytically tractable framework in which both strong forms of positive indecomposability and high degrees of PPT entanglement can be studied systematically.
  We present two further applications of symplectic group symmetry. First, we show that the PPT-squared conjecture holds within the class of PPT linear maps that are either symplectic-covariant or conjugate-symplectic-covariant. Second, we resolve a conjecture of Pal and Vertesi concerning the optimal lower bound of the Sindici-Piani semidefinite program for PPT entanglement.

</details>


### [154] [Polycontrolled PROPs for Qudit Circuits: A Uniform Complete Equational Theory For Arbitrary Finite Dimension](https://arxiv.org/abs/2602.09873)
*Colin Blake*

Main category: quant-ph

TL;DR: 提出了一种针对任意有限维度d≥2的量子电路有限模式公理化方法，通过控制函子作为原始构造子，实现了维度统一的电路完备性证明。


<details>
  <summary>Details</summary>
Motivation: 将量子比特电路的完备性结果扩展到任意有限维度，为量子电路重写和优化提供统一的等式基础，同时实例化控制作为构造子的方法。

Method: 为每个维度d定义配备控制函子的PROP，通过量子电路与基于d进制格雷码的线性光学演算之间的转换，获得最多涉及三根线的有限公理模式集。

Result: 获得了对任意有限维度d≥2的量子电路完备性：两个电路表示相同酉算子当且仅当它们可通过最多三根线的公理相互推导，且生成元与标准通用量子门族兼容。

Conclusion: 成功将量子比特电路完备性扩展到任意有限维度，实现了维度统一的公理形状，为量子电路重写和优化提供了坚实的理论基础。

Abstract: We present a finite schematic axiomatisation of quantum circuits over d-level systems (qudits), uniform in every finite dimension d >= 2. For each d we define a PROP equipped with a family of control functors, treating control as a primitive categorical constructor. Using a translation between qudit circuits and the LOPP calculus for linear optics based on d-ary Gray codes, we obtain for each d a finite set of local axiom schemata that is sound and complete for unitary d-level circuits: two circuits denote the same unitary if and only if they are inter-derivable using axioms involving at most three wires. The generators are compatible with standard universal qudit gate families, yielding a sound equational basis for circuit rewriting and optimisation-by-rewriting. Conceptually, this extends the qubit circuit completeness results of Clément et al.\ to arbitrary finite dimension, and instantiates the control-as-constructor approach of Delorme and Perdrix in this setting, while keeping the axiom shapes uniform in d.

</details>


### [155] [Simpler Presentations for Many Fragments of Quantum Circuits](https://arxiv.org/abs/2602.09874)
*Colin Blake*

Main category: quant-ph

TL;DR: 本文提出了一种基于对称幺半范畴（PROP）的框架，用于构建量子电路片段的完备且最小化的重写系统，显著减少了规则数量。


<details>
  <summary>Details</summary>
Motivation: 量子电路优化和验证中的等式推理通常使用固定的重写规则集，但现有方法缺乏统一的框架来构建完备且最小化的规则系统，特别是对于近Clifford片段。

Method: 使用对称幺半范畴（PROP）框架，将线置换作为结构部分与片段特定的门公理分离，为六个近Clifford片段构建重写系统，并使用统一的分离解释到简单语义目标来证明最小性。

Result: 成功将先前工作的完备性结果转移到PROP框架中，证明了多个片段的公理独立性（最小性），包括所有位数的量子比特Clifford、实数Clifford和CNOT-dihedral片段，显著减少了规则数量。

Conclusion: 提出的PROP框架为构建量子电路片段的完备且通常最小化的重写系统提供了可重用的范畴论框架，显著改进了现有方法。

Abstract: Equational reasoning is central to quantum circuit optimisation and verification: one replaces subcircuits by provably equivalent ones using a fixed set of rewrite rules viewed as equations. We study such reasoning through finite equational theories, presenting restricted quantum gate fragments as symmetric monoidal categories (PROPs), where wire permutations are treated as structural and separated cleanly from fragment-specific gate axioms. For six widely used near-Clifford fragments: qubit Clifford, real Clifford, Clifford+T (up to two qubits), Clifford+CS (up to three qubits) and CNOT-dihedral, we transfer the completeness results of prior work into our PROP framework. Beyond completeness, we address minimality (axiom independence). Using uniform separating interpretations into simple semantic targets, we prove minimality for several fragments (including all arities for qubit Clifford, real Clifford, and CNOT-dihedral), and bounded minimality for the remaining cases. Overall, our presentations significantly reduce rule counts compared to prior work and provide a reusable categorical framework for constructing complete and often minimal rewrite systems for quantum circuit fragments.

</details>


### [156] [Framework for (non-)adiabatic chiral state conversion: from non-Hermitian Hamiltonians to Liouvillians](https://arxiv.org/abs/2602.09881)
*Elna Svegborn,Shishir Khandelwal*

Main category: quant-ph

TL;DR: 提出一个统一框架解释非厄米系统中的手性态转换现象，涵盖非厄米哈密顿量、Lindblad和混合设置，通过微扰非绝热修正预测转换保真度，并揭示非微扰动力学可增强态转换。


<details>
  <summary>Details</summary>
Motivation: 尽管量子系统中已有许多工作证明了绝热手性态转换现象，但其物理机制一直存在争议。本文旨在提供一个统一的理论框架来解释任何非厄米系统中的手性态转换现象。

Method: 提出一个基于微扰非绝热修正的统一框架，该框架仅需最低阶修正就能一致预测手性态转换。通过单量子比特和耦合耗散量子比特模型验证框架有效性，获得转换保真度的解析解。

Result: 框架成功解释了非厄米系统中的手性态转换现象，揭示了即使在看似缓慢的轨迹中也存在非微扰动力学，这一特性可用于显著增强态转换。同时证明了手性态转换可以在没有异常点的模型中观察到。

Conclusion: 该研究提供了一个统一的理论框架来解释非厄米系统中的手性态转换现象，揭示了非微扰动力学在增强转换效率中的作用，并扩展了手性态转换现象的适用范围。

Abstract: Adiabatic chiral state conversion (CSC) is one of the many counterintuitive effects associated with non-Hermitian physics. In quantum systems, numerous works have demonstrated this phenomenon under both non-Hermitian Hamiltonian and Lindblad evolution. However, despite considerable progress, the physical mechanism behind it has been a subject of debate. In this work, we present a unified framework that explains CSC in any non-Hermitian system, encompassing non-Hermitian Hamiltonian, Lindblad, and hybrid settings. Our framework relies on perturbative, non-adiabatic corrections to adiabatic evolution and consistently predicts CSC with only the lowest-order corrections. We demonstrate its efficacy with models of single and coupled dissipative qubits, obtaining analytical solutions for the conversion fidelity. Our analysis further reveals the role of non-perturbative dynamics, which can be present even in apparently slow trajectories. We show that this property can be utilised to considerably enhance state conversion. Finally, we demonstrate that CSC can be observed in a model without the presence of exceptional points.

</details>


### [157] [The quantum multinomial distribution: a combinatorial formulation of multiphoton interference](https://arxiv.org/abs/2602.09894)
*Alfonso Martinez,Josep Font-Segura*

Main category: quant-ph

TL;DR: 该论文提出了光子线性光学干涉仪中多光子跃迁概率的量子化多项分布，通过相干振幅求和引入量子干涉效应，为玻色采样验证提供了低阶统计见证方法。


<details>
  <summary>Details</summary>
Motivation: 研究多光子在线性光学干涉仪中的量子统计特性，建立超越经典多项分布的量子化分布，为玻色采样实验验证提供无需完整永久计算的统计检测方法。

Method: 提出量子化多项分布公式：两个多项式系数乘以相干振幅求和的模平方，加权多元超几何分布。分析阶乘矩、累积量等统计特性，特别关注分束器和多端口干涉仪中的量子干涉效应。

Result: 发现量子分布与经典多项分布形成平行家族，相干振幅求和引入量子干涉效应。三阶累积量在分束器中保持经典值，四阶累积量出现负超额峰度；多端口干涉仪中三体干涉破坏不变性，量子偏离在三阶累积量即出现。交叉模式协方差包含散射矩阵相位信息，增强输出反相关性。

Conclusion: 量子化多项分布通过相干振幅求和捕捉量子干涉效应，其平方系数特征和增强的反相关性为玻色采样验证提供了低阶统计见证，无需计算完整永久，简化了实验验证过程。

Abstract: This paper presents a quantum generalization of the multinomial distribution for the transition probabilities of $m$ identical photons in a $k$-port linear optical interferometer: two multinomial coefficients (one for the input configuration, one for the output) times the squared modulus of a coherent sum over routing matrices, weighted by the multivariate hypergeometric distribution; no Hilbert space formalism is needed to state or evaluate it. The classical multinomial is recovered when all photons enter through a single port, the coherent sum degenerating to a single term with no interference; the quantum family is not a generalization in the Askey sense but a parallel family that departs from classical statistics through the coherence of the amplitude summation. The $r$-th factorial moment carries a squared multinomial coefficient in place of the classical single one, the extra factor arising from the two copies of the amplitude expansion whose indices the Fock state forces to agree; for the beam splitter, the third cumulant is invariant under bosonic interference and the quantum departure first appears in the fourth cumulant as negative excess kurtosis; for multiport interferometers, however, three-body interference breaks this invariance and the departure enters already at the third cumulant. Cross-mode covariances involve the phases of the scattering matrix through coherence terms that strengthen output anti-correlations beyond the classical value; together with the squared-coefficient signature in the single-mode moments, these provide low-order statistical witnesses for boson sampling verification without requiring the full permanent computation.

</details>


### [158] [Gravitationally-induced Conversion of Local Coherence to Entanglement](https://arxiv.org/abs/2602.09900)
*Hazhir Dolatkhah,Shahriar Salimi,Soroush Haseli*

Main category: quant-ph

TL;DR: 该论文从量子资源理论角度分析引力诱导纠缠机制，证明引力作为相干性到纠缠的转换通道，初始相干性是产生纠缠的必要条件。


<details>
  <summary>Details</summary>
Motivation: 近年来，引力的量子性质成为现代物理学最重要问题之一。本文旨在从量子资源理论角度分析引力诱导纠缠的机制，为即将进行的实验测试提供更精确的解释基础。

Method: 基于Bose等人的框架，将引力相互作用建模为酉通道，分析两个空间叠加质量之间的量子资源重新分布。推导精确的解析互补关系，量化相干性到纠缠的转换，并通过数值模拟支持这些发现。

Result: 证明引力作为相干性到纠缠的转换通道，产生的双体纠缠源于局部量子相干性向共享非局域关联的相干转换。推导出量化这种转换的互补关系，将局部相干性衰减与纠缠增长直接联系起来。

Conclusion: 阐明了引力诱导纠缠的底层机制，确立引力作为相干性到纠缠的转换通道。关键发现是初始相干性是产生纠缠的必要条件，其程度限制了最大可达到的纠缠度，最大纠缠需要初始最大相干性。

Abstract: In recent years, the quantum nature of gravity has attracted significant attention as one of the most important problems in modern physics. Here, we analyze the mechanism of gravitationally-induced entanglement from the perspective of quantum resource theory. Building on the framework of Bose et al. [Phys. Rev. Lett. 119, 240401 (2017)], we show that the gravitational interaction acts as a unitary channel, redistributing quantum resources between two spatially superposed masses. Specifically, we demonstrate that the resulting bipartite entanglement originates from the coherent conversion of local quantum coherence -- initially present in each subsystem -- into shared non-local correlations. We derive exact, analytical complementarity relations quantifying this conversion, link the decay of local coherence directly to the growth of entanglement, and support these findings with numerical simulations. Our results clarify the underlying mechanism and establish gravity as a coherence-to-entanglement conversion channel, offering a refined interpretive basis for forthcoming experimental tests. Crucially, we show that initial coherence is a necessary condition for entanglement generation and that its degree bounds the maximum achievable entanglement, with maximal entanglement requiring initial maximal coherence.

</details>


### [159] [Protection of quantum steering ellipsoids in non-Markovian environments](https://arxiv.org/abs/2602.09903)
*Wen-Jie Zhang,Jun-Hong An*

Main category: quant-ph

TL;DR: 量子导引椭球(QSE)在开放系统中受环境耗散影响，其几何特性与系统-环境能谱中束缚态的形成密切相关，量子储层工程可成为调控量子导引的有效策略。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统在实际环境中不可避免地与环境耦合，导致退相干和量子导引椭球退化的问题，探索如何在开放系统中保护和调控量子导引。

Method: 在精确的非马尔可夫框架下，研究局域耗散环境对双量子比特系统中量子导引椭球的影响，分析系统-环境能谱中束缚态的形成与QSE几何特性的关系。

Result: 发现QSE的几何特性与系统-环境能谱中束缚态的形成密切相关：双边束缚态、单边束缚态和无束缚态三种情况下，量子导引表现出不同类型的特性。

Conclusion: 量子储层工程可作为调控开放系统中量子导引的可调策略，为实现稳健的基于量子导引的量子技术提供了实用途径。

Abstract: The quantum steering ellipsoid (QSE) provides a geometric representation, within the Bloch picture, of all possible states to which one qubit can be steered through measurements performed on another correlated qubit. However, in most realistic settings, quantum systems are inevitably coupled to their surrounding environment, resulting in decoherence and the consequent degradation of the QSE. Here, by investigating how local dissipative environments coupled separately to each qubit affect the steering properties geometrized by the QSE within an exact non-Markovian framework, we find that the geometry of each party's QSE is closely tied to whether a bound state forms in the energy spectrum of the total qubit-environment system. We systematically examine the characteristics of QSEs under three distinct scenarios: two-sided bound states, one-sided bound states, and no bound state, revealing a diverse range of steering types. Our work establishes quantum reservoir engineering as a tunable strategy for protecting and controlling quantum steering in open systems, offering a practical pathway toward robust steering-based quantum technologies.

</details>


### [160] [Tucker iterative quantum state preparation](https://arxiv.org/abs/2602.09909)
*Carsten Blank,Israel F. Araujo*

Main category: quant-ph

TL;DR: 提出Q-Tucker方法，利用Tucker分解构建浅层确定性量子电路，用于量子态制备


<details>
  <summary>Details</summary>
Motivation: 量子态制备是量子算法的基础，现有振幅编码技术要么产生深度电路，要么缺乏实用的电路构建指导

Method: 基于Tucker分解，将目标量子态分解为核心张量和模式特定算子，实现跨多个子系统的直接分解

Result: 提出Q-Tucker方法，能够自适应构建浅层、确定性的量子电路

Conclusion: 通过利用目标态的全局纠缠结构，提供了一种有效的量子态制备方法

Abstract: Quantum state preparation is a fundamental component of quantum algorithms, particularly in quantum machine learning and data processing, where classical data must be encoded efficiently into quantum states. Existing amplitude encoding techniques often rely on recursive bipartitions or tensor decompositions, which either lead to deep circuits or lack practical guidance for circuit construction. In this work, we introduce Tucker Iterative Quantum State Preparation (Q-Tucker), a novel method that adaptively constructs shallow, deterministic quantum circuits by exploiting the global entanglement structure of target states. Building upon the Tucker decomposition, our method factors the target quantum state into a core tensor and mode-specific operators, enabling direct decompositions across multiple subsystems.

</details>


### [161] [Dissipative phase transitions of the Dicke-Ising model](https://arxiv.org/abs/2602.09912)
*Jun-Ling Wang,Jiong Li,Qing-Hu Chen*

Main category: quant-ph

TL;DR: 研究开放横向和纵向Dicke-Ising模型中的耗散相变，发现耗散在纵向模型中稳定双稳态非平衡态并诱导一阶相变，将基态三相点转化为四临界点。


<details>
  <summary>Details</summary>
Motivation: 探索在开放量子系统中，自旋相互作用、光-物质耦合和耗散之间的相互作用如何影响非平衡相变，为研究现实固体量子系统中的非平衡物理提供理论基础。

Method: 采用平均场方法研究Dicke-Ising模型（在Dicke框架中加入最近邻Ising型自旋相互作用），并通过详细的稳定性分析进行验证。

Result: 横向DIM的耗散相图仅轻微上移，而纵向DIM中的耗散稳定了双稳态非平衡稳态，诱导一阶相变，将基态三相点转化为四临界点，支持超辐射和反铁磁序共存。

Conclusion: 自旋相互作用、光-物质耦合和耗散的相互作用支持多种非平衡相变，为相图提供了广泛的可调性，为探索现实开放固体量子系统中的非平衡物理奠定了理论基础。

Abstract: The dissipative phase transitions in the open transverse and longitudinal Dicke-Ising model (DIM), which incorporates nearest-neighbor Ising-type spin interactions into the Dicke framework, are investigated within a mean-field approach and further validated by detailed stability analysis. While the dissipative phase diagram of the transverse DIM is only slightly shifted upward compared with its ground-state counterpart, dissipation in the longitudinal DIM stabilizes bistable nonequilibrium steady states and induces first-order phase transitions that are absent in the ground-state phase diagram. This bistable phase is characterized by the coexistence of superradiant and antiferromagnetic orders, and it converts a ground-state triple point into a tetracritical point, at which the boundaries of the first- and second-order transitions intersect. Our results reveal that the interplay among spin interactions, light-matter coupling, and dissipation supports a diverse set of nonequilibrium phase transitions and provides broad tunability of the phase diagram. These findings offer a theoretical foundation for exploring nonequilibrium physics in realistic open solid-state quantum systems.

</details>


### [162] [Information Theory of Action : Reconstructing Quantum Dynamics from Inference over Action Space](https://arxiv.org/abs/2602.09984)
*Fabricio Souza Luiz,Marcos César de Oliveira*

Main category: quant-ph

TL;DR: 量子动力学信息论重构：基于作用量空间推断，通过最大熵推断引入有限分辨率尺度，推导出复数振幅、幺正演化、量子干涉等量子力学核心概念作为必然结果而非独立假设。


<details>
  <summary>Details</summary>
Motivation: 从信息论和推断的角度重构量子力学基础，试图将量子力学的核心概念（复数振幅、幺正演化、量子干涉）推导为更基本原理（作用量可加性、概率归一化、有限分辨率推断）的必然结果，而非独立的公设。

Method: 基于作用量空间的推断方法，引入作用量密度状态描述动力学替代路径的多重性。通过最大熵推断引入有限分辨率尺度，使得足够接近的作用量贡献在操作上不可区分。结合作用量可加性、概率归一化等约束，推导出最小连续表示。

Result: 证明了复数振幅和幺正演化是满足作用量可加性、概率归一化和有限分辨率推断的最小连续表示。量子干涉和幺正性成为这些假设的推论而非独立公设。从得到的传播子可以推导出拉格朗日量、希尔伯特空间结构和薛定谔方程。作用量尺度的数值由经验固定为普朗克常数ħ。

Conclusion: 量子力学的核心特征可以从信息论推断原理中自然涌现：有限分辨率的作用量空间推断必然导致复数振幅、幺正演化和量子干涉。这为量子力学提供了新的基础理解框架，将传统公设降级为更基本原理的推导结果。

Abstract: We develop an information-theoretic reconstruction of quantum dynamics based on inference over action space. The fundamental object is a density of action states encoding the multiplicity of dynamical alternatives between configurations. Maximum-entropy inference introduces a finite resolution scale in action, implying that sufficiently close action contributions are operationally indistinguishable. We show that this indistinguishability, together with probability normalization and action additivity, selects complex amplitudes and unitary evolution as the minimal continuous representation compatible with action additivity, probability normalization, and inference under finite resolution. Quantum interference and unitarity therefore emerge as consequences of these assumptions rather than independent postulates. From the resulting propagator, the Lagrangian, Hilbert-space structure, and Schrödinger equation follow as derived consequences. In the infinitesimal-time limit, action differences universally fall below the resolution scale, making coherent summation the minimal consistent description at every step. The numerical value of the action scale is fixed empirically and identified with $\hbar$.

</details>


### [163] [Universal Foundations of Thermodynamics: Entropy and Energy Beyond Equilibrium and Without Extensivity](https://arxiv.org/abs/2602.09986)
*Gian Paolo Beretta*

Main category: quant-ph

TL;DR: 提出一个普适的热力学基础框架，适用于所有系统（无论大小、粒子多少）和所有状态（平衡与非平衡），不依赖于宏观理想化假设，统一了热力学概念。


<details>
  <summary>Details</summary>
Motivation: 传统热力学通常基于宏观系统、稳定平衡、广延性和系统尺寸缩放等假设，限制了其在非平衡态、小系统和复杂系统中的应用。需要建立一个更普适的基础框架。

Method: 采用操作定义和存在原理，而非宏观理想化。定义熵和能量的普适概念，使用能量-熵图表示非平衡态，分析非功相互作用中的熵传递，推导热相互作用和热扩散相互作用的精确定义。

Result: 建立了适用于所有系统和状态的热力学普适框架，推导出克劳修斯不等式和克劳修斯第二定律表述的非平衡扩展形式，为教学和现代应用提供了连贯基础。

Conclusion: 热力学可以作为一个普适理论，其概念统一适用于所有系统（无论大小），为教学和现代应用提供了连贯的基础框架。

Abstract: Thermodynamics is commonly presented as a theory of macroscopic systems in stable equilibrium, built upon assumptions of extensivity and scaling with system size. In this paper, we present a universal formulation of the elementary foundations of thermodynamics, in which entropy and energy are defined and employed beyond equilibrium and without assuming extensivity. The formulation applies to all systems -- large and small, with many or few particles -- and to all states, whether equilibrium or nonequilibrium, by relying on carefully stated operational definitions and existence principles rather than macroscopic idealizations. Key thermodynamic concepts, including adiabatic availability and available energy, are developed and illustrated using the energy-entropy diagram representation of nonequilibrium states, which provides geometric insight into irreversibility and the limits of work extraction for systems of any size. A substantial part of the paper is devoted to the analysis of entropy transfer in non-work interactions, leading to precise definitions of heat interactions and heat-and-diffusion interactions of central importance in mesoscopic continuum theories of nonequilibrium behavior in simple and complex solids and fluids. As a direct consequence of this analysis, Clausius inequalities and the Clausius statement of the second law are derived in forms explicitly extended to nonequilibrium processes. The resulting framework presents thermodynamics as a universal theory whose concepts apply uniformly to all systems, large and small, and provides a coherent foundation for both teaching and modern applications.

</details>


### [164] [Emergence of a Luttinger Liquid Phase in an Array of Chiral Molecules](https://arxiv.org/abs/2602.10002)
*Muhammad Arsalan Ali Akbar,Bretislav Friedrich,Sabre Kais*

Main category: quant-ph

TL;DR: 利用1,2-丙二醇分子阵列模拟手性量子磁性，通过分子立体化学自发产生Dzyaloshinskii-Moriya相互作用，实现可调的手性Luttinger液体相。


<details>
  <summary>Details</summary>
Motivation: 传统固态模型中DMI是唯象引入的，缺乏微观机制。本文旨在建立分子手性与拓扑多体相之间的直接微观联系，利用分子立体化学自发产生DMI。

Method: 使用线性阵列的1,2-丙二醇不对称顶分子，将Stark修饰的转动态映射到有效自旋-1/2子空间，推导出广义XXZ海森堡哈密顿量。通过异手性对映体对的跃迁偶极矩干涉产生可调DMI。

Result: 确定了最佳实验参数：分子间距约1.5nm，中等电场强度dε/B≈2.5。在此窗口内系统受到保护，避免平庸场极化相，表现出鲁棒的无能隙自旋螺旋纹理，稳定了手性Luttinger液体相。

Conclusion: 1,2-丙二醇阵列可作为多功能量子模拟器，建立了分子手性与拓扑多体相之间的直接微观联系，为研究手性量子磁性提供了新平台。

Abstract: We propose a robust platform for simulating chiral quantum magnetism using linear arrays of trapped asymmetric top molecules, specifically 1,2-propanediol ($\mathrm{C_{3}H_{8}O_{2}}$). By mapping the Stark-dressed rotational states onto an effective spin-$1/2$ subspace, we rigorously derive a generalized $XXZ$ Heisenberg Hamiltonian governing the underlying many-body dynamics. Unlike standard solid-state models where the topological Dzyaloshinskii-Moriya Interaction (DMI) is introduced phenomenologically, we demonstrate that DMI emerges \textit{ab initio} from the molecular stereochemistry. Specifically, the interference between the transition dipole moments of heterochiral enantiomer pairs (L-R), which breaks inversion symmetry, generates a tunable DMI that stabilizes a Chiral Luttinger Liquid phase. Through a comprehensive phase-diagram analysis, we identify an optimal experimental regime characterized by intermolecular separations of \( r \approx 1.5~\mathrm{nm} \) and intermediate electric-field strengths \( d\varepsilon/B \approx 2.5 \). In this window, the system is protected from trivial field-polarized phases and exhibits a robust gapless spin-spiral texture. Our results establish 1,2-propanediol arrays as a versatile quantum simulator, providing a direct microscopic link between molecular chirality and topological many-body phases.

</details>


### [165] [Preventing Barren Plateaus in Continuous Quantum Generative Models](https://arxiv.org/abs/2602.10049)
*Olli Hirviniemi,Afrad Basheer,Thomas Cope*

Main category: quant-ph

TL;DR: 论文提出了一种无贫瘠高原的变分量子电路模型，该模型对经典模拟技术具有鲁棒性，适用于NISQ设备和量子-经典混合模型。


<details>
  <summary>Details</summary>
Motivation: 当前变分量子电路（VQC）的可训练性前提已转移到数据编码状态，许多无贫瘠高原模型依赖于输入到经典可训练幺正算符的数据编码状态。需要开发一种既无贫瘠高原问题，又能抵抗当前经典模拟技术（如张量网络收缩和泡利传播）的完整电路模型。

Method: 通过强化与小角度初始化相关的证明，构建了一个完整的电路模型。该模型使用数据编码状态作为输入，结合经典可训练的幺正算符，确保不会出现贫瘠高原问题，同时对张量网络收缩和泡利传播等经典模拟技术具有鲁棒性。

Result: 成功开发了一种无贫瘠高原的量子电路模型，该模型能够抵抗当前主流的经典模拟技术。该模型特别适用于NISQ设备和量子-经典混合模型，可作为量子生成模型使用。

Conclusion: 提出的量子电路模型解决了VQC中的贫瘠高原问题，同时具备对经典模拟的鲁棒性，为NISQ时代的量子-经典混合计算提供了新的可能性，重新引发了关于VQC实用性的讨论。

Abstract: Recent developments in the field of variational quantum circuits (VQCs) have shifted the prerequisites for trainability for many barren plateau-free models onto the data encoding state fed into a classically trainable unitary. By strengthening proofs relating to small-angle initialisation, we provide a full circuit model which does not suffer from barren plateaus and is robust against current classical simulation techniques, specifically tensor network contraction and Pauli propagation. We propose this as a quantum generative model amenable towards NISQ devices and quantum-classical hybrid models, raising new questions in the debate regarding usefulness of VQCs.

</details>


### [166] [Anyon Permutations in Quantum Double Models through Constant-depth Circuits](https://arxiv.org/abs/2602.10110)
*Yabo Li,Zijian Song*

Main category: quant-ph

TL;DR: 提出显式常数深度局域幺正电路实现Kitaev量子双模型中的任意子置换，通过二维拓扑序与一维系统自对偶性的全息对应关系来理解。


<details>
  <summary>Details</summary>
Motivation: 研究如何在二维拓扑序中实现任意子置换，这对于拓扑量子计算和拓扑相的分类具有重要意义。传统方法通常需要复杂的操作，本文旨在提供更简洁的常数深度电路实现。

Method: 通过建立二维拓扑序的任意子置换对称性与一维系统自对偶性的对应关系，将任意子置换分解为三类一维自对偶性的组合：G子群的规范化、G对称保护拓扑相的堆叠、以及群G的外自同构。分别使用自对偶幺正规范映射和横向电路实现这三类操作。

Result: 成功构造了显式常数深度局域幺正电路，能够实现D(G)量子双模型中的一般任意子置换。通过全息视角，将任意子置换分解为三类基本操作，并提供了相应的电路实现方案。

Conclusion: 本文建立了二维拓扑序任意子置换与一维系统自对偶性的深刻联系，提供了一种系统构造任意子置换电路的方法，为拓扑量子计算和拓扑相研究提供了新工具。

Abstract: We provide explicit constant-depth local unitary circuits that realize general anyon permutations in Kitaev's quantum double models. This construction can be naturally understood through a correspondence between anyon permutation symmetries of two-dimensional topological orders and self-dualities in one-dimensional systems, where local gates implement self-duality transformations on the boundaries of microscopic regions. From this holographic perspective, general anyon permutations in the $D(G)$ quantum double correspond to compositions of three classes of one-dimensional self-dualities, including gauging of certain subgroups of $G$, stacking with $G$ symmetry-protected topological phases, and outer automorphisms of the group $G$. We construct circuits realizing the first class by employing self-dual unitary gauging maps, and present transversal circuits for the latter two classes.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [167] [Systematic biases in parameter estimation on LISA binaries. II. The effect of excluding higher harmonics for spin-aligned, high-mass binaries](https://arxiv.org/abs/2602.09088)
*Sophia Yi,Francesco Iacovelli,Emanuele Berti,Rohit S. Chandramouli,Sylvain Marsat,Digvijay Wadekar,Nicolás Yunes*

Main category: gr-qc

TL;DR: LISA观测超大质量黑洞双星时，忽略高阶模式会导致系统误差，特别是对于质量高达10^8太阳质量且具有自旋的系统，其中(2,2)模式可能不再是主导模式。


<details>
  <summary>Details</summary>
Motivation: LISA将观测信噪比极高的超大质量黑洞双星，参数估计对这些信号的小波形误差非常敏感。特别是忽略高阶模式导致的误差，对于具有自旋且质量高达10^8太阳质量的系统尤为关注。

Method: 扩展Yi等人的工作，研究忽略高阶模式对具有非零（对齐）前身自旋且总质量高达10^8太阳质量的MBHB系统的影响。提出改进的似然优化方案，以计算高效的方式预测这些效应。

Result: 对于这些超大质量系统，参数空间中存在(2,2)模式不再主导高阶模式的区域。系统偏差的程度随双星前身自旋的变化而显著改变。对于最重、最短的MBHB信号，轻微的系统误差可能导致天空定位参数的严重错误推断。

Conclusion: 在LISA观测超大质量黑洞双星时，必须考虑高阶模式的影响，特别是对于具有自旋的大质量系统。提出的改进似然优化方案有助于高效预测这些系统误差效应。

Abstract: The Laser Interferometer Space Antenna (LISA) will observe massive black hole binaries (MBHBs) with astoundingly high signal-to-noise ratio, leaving parameter estimation with these signals susceptible to seemingly small waveform errors. Of particular concern for MBHBs are errors due to neglected higher-order modes. We extend Yi et al. [arXiv:2502.12237] to examine errors due to neglected higher-order modes for MBHBs with nonzero (aligned) progenitor spins and total mass up to $10^8\,M_\odot$. For these very massive systems, there can be regions of parameter space in which the $(\ell, |m|)=(2,\,2)$ modes are no longer dominant with respect to higher-order ones. We find that the extent of systematic bias can change significantly when varying the progenitor spins of the binary. We also find that for the heaviest, and therefore shortest, MBHB signals, slight systematic errors can cause severe mis-inference of the sky localization parameters. We propose an improved likelihood optimization scheme with respect to previous work as a way to predict these effects in a computationally efficient manner.

</details>


### [168] [Optical Signatures of a Schwarzschild Black Hole in a Dehnen-Type Dark Matter Halo](https://arxiv.org/abs/2602.09168)
*Javokhir Sharipov,Jonibek Khasanov,Pankaj Sheoran,Sanjar Shaymatov,Bobomurat Ahmedov*

Main category: gr-qc

TL;DR: 研究带Dehnen型暗物质晕的类史瓦西黑洞附近的光学效应，包括弱场和强场下的偏转角、黑洞阴影、引力透镜，以及等离子体环境的影响。


<details>
  <summary>Details</summary>
Motivation: 探索暗物质晕和等离子体如何共同影响黑洞附近的光学现象，特别是引力透镜效应，这对于理解暗物质性质和黑洞观测特征具有重要意义。

Method: 1. 推导光子球半径；2. 用高斯-博内定理计算弱场偏转角；3. 强场下进行光线追踪计算轨道数；4. 计算黑洞阴影和等离子体中的引力透镜；5. 分析均匀和SIS等离子体分布下的弱引力透镜。

Result: 获得了暗物质晕参数和等离子体特性如何共同改变可观测透镜特征的定量结果，包括偏转角解析表达式和图像放大效应。

Conclusion: 暗物质晕性质和等离子体特征共同显著影响黑洞的光学观测特征，为通过引力透镜观测约束暗物质参数提供了理论基础。

Abstract: In this paper, the optical effects that occur near a Schwarzschild-like black hole (BH) with a Dehnen-type $(1,4,2)$ dark matter (DM) halo are explored. We first derive the photon sphere radius and obtain an analytical expression for the deflection angle in the weak-field regime by applying the Gauss-Bonnet theorem (GBT). For the strong-field regime, we perform ray-tracing calculations to examine the behavior of light trajectories and determine the corresponding number of orbits. We further compute the BH shadow and gravitational lensing in a plasma medium and provide constraints arising from the DM halo parameters. We also extend our analysis to weak gravitational lensing within plasma environments, considering both uniform and singular isothermal sphere (SIS) distributions. We find the analytical expressions for the deflection angle in the presence of plasma and examine the resulting effects on image magnification. The overall results highlight how DM halo properties and plasma characteristics jointly alter observable lensing signatures.

</details>


### [169] [Gravitational waves in a minimal gravitational SME](https://arxiv.org/abs/2602.09183)
*A. A. Araújo Filho,N. Heidari,Iarley P. Lobo*

Main category: gr-qc

TL;DR: 研究最小引力SME中的引力波生成与传播，分析偏振特性、构建推迟格林函数，研究双黑洞系统的引力波发射，发现洛伦兹破坏效应仅通过推迟时间修正影响波形相位。


<details>
  <summary>Details</summary>
Motivation: 研究标准模型扩展(SME)框架下引力波的生成和传播特性，探索洛伦兹对称性破坏对引力波物理的影响。

Method: 从线性化引力区推导的修正引力子色散关系出发，分析横向无迹张量区的偏振特性；构建洛伦兹破坏波动算符的推迟格林函数；研究双黑洞系统的引力波发射。

Result: 引力波形保持标准四极振幅和偏振结构，洛伦兹破坏效应仅通过推迟时间修正进入；空间度规扰动分量获得由SME系数决定的相位移动；建立了理论因果结构并识别了张量模式的修正传播速度。

Conclusion: 在最小引力SME中，洛伦兹破坏效应主要影响引力波的传播相位而不改变振幅和偏振结构，这为通过引力波观测约束洛伦兹对称性破坏提供了理论基础。

Abstract: In this work, we investigate the generation and propagation of gravitational waves within a minimal gravitational SME (Standard Model Extension). Starting from the modified graviton dispersion relation derived in the linearized gravity sector, we analyze the polarization properties of gravitational waves in the transverse-traceless tensor sector. We then construct the retarded Green function associated with the Lorentz-violating wave operator, explicitly verifying the causal structure of the theory and identifying the modified propagation speeds of the tensorial modes. In addition, we study the source-induced emission of gravitational waves from a binary black-hole system. We show that the gravitational waveform preserves the standard quadrupolar amplitude and polarization structure, while Lorentz-violating effects enter exclusively through a modification of the retarded time. As a result, the spatial components of the metric perturbation $h_{ij}(t,r)$ acquire a phase shift determined by the SME coefficients. Finally, we estimate phenomenological bounds to the model under consideration.

</details>


### [170] [Temperature of a spinning black hole via a simple derivation](https://arxiv.org/abs/2602.09244)
*Ronald J. Adler*

Main category: gr-qc

TL;DR: 使用经典广义相对论和热力学推导克尔旋转黑洞的温度，方法更简单、自包含，主要目的是教学，让更多学生和非专家能够理解。


<details>
  <summary>Details</summary>
Motivation: 黑洞具有非零温度并像黑体一样辐射是霍金的重要发现，但现有推导通常需要量子场论。本文旨在仅使用经典广义相对论和热力学来推导克尔旋转黑洞的温度，使推导更简单易懂，便于教学。

Method: 仅使用经典广义相对论和热力学，不依赖量子场论，通过更简单、自包含的数学方法推导克尔旋转黑洞的温度。与参考文献11类似但更简化。

Result: 成功推导出克尔旋转黑洞的温度，验证了霍金辐射的温度公式，但使用的方法更简洁，更适合教学目的。

Conclusion: 本文提供了一个更易理解的黑洞温度推导方法，有助于教学和普及。同时讨论了小黑洞爆炸性蒸发的潜在观测意义，以及原始黑洞残余可能构成宇宙暗物质的可能性。

Abstract: According to current theory a black hole has a nonzero temperature and thus radiates like any black body. This remarkable result was first shown by Hawking for a non-spinning black hole using general relativity to describe the black hole gravitational field and quantum field theory to describe the radiation. Since then the temperature of a spinning Kerr black hole has been calculated. There have also been many heuristic derivations for the temperature. In this work we derive the temperature of a Kerr spinning black hole using only classical general relativity and thermodynamics. It is very similar to Ref. 11 but is mathematically simpler and more self-contained. Our purpose is mainly pedagogical, to be more accessible to students and non-specialists with a knowledge of general relativity. We also call further attention to the expected explosive evaporation of small black holes, not yet observed, which would be an almost unique window into Planck scale physics. Finally, we discuss the idea that the cosmological dark matter, whose nature is currently unknown, may be composed of small primordial black hole remnants.

</details>


### [171] [Towards a quantitative characterization of gravitational universality classes for order-4 random tensor models](https://arxiv.org/abs/2602.09257)
*Alicia Castro,Astrid Eichhorn,Razvan Gurau*

Main category: gr-qc

TL;DR: 随机张量模型可作为组合工具生成欧几里得动力学三角剖分，其物理连续极限需要类似随机矩阵双标度极限的推广。作者在4维动力学三角剖分的4阶随机张量模型中寻找重整化群固定点，发现与连续量子引力中的Reuter固定点可能属于不同普适类。


<details>
  <summary>Details</summary>
Motivation: 研究随机张量模型作为生成欧几里得动力学三角剖分的组合工具，探索其物理连续极限，并与连续量子引力中的重整化群固定点进行比较，以理解不同量子引力方法之间的关系。

Method: 使用4阶随机张量模型研究4维动力学三角剖分，在O(N)^4对称性设置下分析相图，优化参数选择使结果对参数变化最不敏感，寻找重整化群固定点候选。

Result: 发现三个固定点候选：只有一个在整个参数范围内是实数，但只有两个相关方向。这与连续量子引力中Reuter固定点（很可能有三个相关方向）形成对比。

Conclusion: 简单的欧几里得三角剖分组合模型与Reuter固定点很可能属于不同的普适类，表明这两种量子引力方法在重整化群意义上可能不相关。

Abstract: Random tensor models can be used as combinatorial devices to generate Euclidean dynamical triangulations. A physical continuum limit of dynamical triangulations requires a suitable generalization of the double-scaling limit of random matrices. This limit corresponds to a fixed point of a pregeometric Renormalization Group flow in which the tensor size $N$ serves as the Renormalization Group scale. We search for corresponding fixed points in order-4 random tensor models associated to dynamical triangulations in 4 dimensions. In a $O(N)^{\otimes 4}$ symmetric setting, we discuss the resulting phase portrait as a function of the regulator parameters. We optimize our results, identifying parameter values for which the results are minimally sensitive to parameter changes. We find three fixed-point candidates: only one of them is real across the entire parameter range, but only has two relevant directions. This should be contrasted with the university class of the Reuter fixed point in continuum quantum gravity, very likely characterized by three relevant directions. We conclude that simple combinatorial models of Euclidean triangulations and the Reuter fixed point most likely lie in different universality classes.

</details>


### [172] [A Small Patch Hypothesis in Cosmology](https://arxiv.org/abs/2602.09420)
*Meir Shimon*

Main category: gr-qc

TL;DR: 论文提出"小补丁假说"：我们观测到的宇宙可能只是更大、更古老时空中的一个小因果区域，宇宙学常数Λ决定了可观测宇宙的尺度上限，这为理解平坦度和视界问题提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 重新解释经典平坦度问题和视界问题，认为它们可能是观测选择效应的表现。如果可观测宇宙只是更大因果连接时空中的一个小区域，那么这些"问题"可能只是我们有限观测能力的产物。

Method: 提出"小补丁假说"，基于宇宙学常数Λ设定可观测宇宙的未来渐近视界尺度。考虑一个非暴胀替代方案，其中原初谱在大尺度上对数增长并在某个有限k_c处发散，如果k_c远小于Λ^{-1/2}，则局部宇宙区域只探测线性机制。

Result: 可观测宇宙的最大可及尺度由Λ固定，与暴胀动力学、人择论证或全局时空假设无关。在有限观测窗口内，这种功率谱模拟了轻微红倾的暴胀式谱，解释了宇宙的大尺度均匀性、各向同性等特征。

Conclusion: 大尺度均匀性、各向同性、高斯性、绝热性和观测到的时间热力学箭头可能不是早期宇宙独特机制的标志，而是我们对更大平衡宇宙受限观测访问的结果。暴胀成为小补丁假说的一种可行实现方式。

Abstract: If our observable Universe is only a tiny region of a vastly larger and conformally older spacetime, then the usual formulations of the classical flatness and horizon problems of the Hot Big Bang can be reinterpreted as artifacts manifesting an observational selection effect; we occupy a small causal domain of a much larger causally-connected and possibly non-flat spacetime. A sufficiently large positive cosmological constant, $Λ$, sets the future asymptotic horizon scale of the observable Universe, $\sim$$Λ^{-1/2}$, thereby implying that the observable Universe may simply be a minute patch of a far larger pre-existing one, hereafter a Small Patch Hypothesis. Importantly, this observational bound is purely geometric; regardless of when the Universe is observed, the maximum accessible scale is finite and fixed by $Λ$, independent of inflationary dynamics, anthropic arguments, or assumptions about the global hosting spacetime. In this sense, inflation becomes one viable realization of the proposed Small Patch Hypothesis. Here, one particular non-inflationary alternative is considered for illustrative purposes in which a primordial spectrum grows logarithmically toward large scales, and in fact diverges at some finite $k_{c}$. If $k_{c}\ll Λ^{-1/2}$, then our local cosmic patch probes only the linear regime and appears exceptionally smooth. Over the comparatively narrow observable window, this power spectrum mimics a slightly red-tilted, inflation-like spectrum. Rather than introducing high-energy new fields, this perspective frames large-scale homogeneity, isotropy, Gaussianity, adiabaticity, and the observed thermodynamic Arrow of Time as possible consequences of restricted observational access to a much larger Universe in equilibrium, rather than signatures of a unique early-Universe mechanism. [abridged]

</details>


### [173] [Gravitational wave signatures from periodic orbits around a Schwarzschild-Bertotti-Robinson black hole](https://arxiv.org/abs/2602.09453)
*Tursunali Xamidov,Sanjar Shaymatov,Qiang Wu,Tao Zhu*

Main category: gr-qc

TL;DR: 研究Schwarzschild-Bertotti-Robinson时空中周期性束缚轨道和引力波辐射，分析背景磁场如何改变黑洞动力学和引力波信号特征


<details>
  <summary>Details</summary>
Motivation: 研究均匀磁场中的静态黑洞（Schwarzschild-BR时空）如何影响引力动力学和引力波发射，探索磁场对极端质量比旋进引力波的观测印记

Method: 1. 分析Schwarzschild-BR时空中的类时测地线，研究MBO和ISCO轨道；2. 使用频率比ω_φ/ω_r表征周期性束缚轨道；3. 基于数值kludge方法计算超大质量Schwarzschild-BR黑洞周围周期性轨道发射的引力波形；4. 通过离散傅里叶变换计算特征应变，与LISA、Taiji、TianQin等空间引力波探测器灵敏度曲线比较

Result: 背景磁场显著改变轨道频率、共振条件、zoom-whirl结构以及产生的引力波形；磁场通过改变时空结构在极端质量比旋进引力波中留下可观测印记

Conclusion: 内在磁场会修改时空结构，并在极端质量比旋进引力波中留下可观测的印记，这些效应可能通过未来的空间引力波观测得到验证

Abstract: In this paper, we investigate periodic bound orbits and gravitational wave (GW) emission in the Schwarzschild-Bertotti-Robinson (Schwarzschild-BR) spacetime-an exact electrovacuum solution describing a static black hole (BH) immersed in a uniform magnetic field. We explore how the background magnetic field qualitatively alters the BH's gravitational dynamics, affecting timelike geodesics such as the marginally bound orbit (MBO) and the innermost stable circular orbit (ISCO). We then analyze periodic bound orbits using the frequency ratio ${ω_{\varphi}}/{ω_{r}}$, which characterizes the orbits by their azimuthal and radial motions. Based on the numerical kludge method we further compute the gravitational waveforms emitted from periodic orbits around a supermassive Schwarzschild-BR BH. We show that the background magnetic field significantly changes orbital frequencies, resonance conditions, zoom-whirl structures, and the resulting waveforms. Finally, we examine the frequency spectra in the mHz range and the detectability of these GW signals by computing the characteristic strain via a discrete Fourier transform on the time-domain waveforms, comparing the results with the sensitivity curves of space-based GW detectors such as LISA, Taiji, and TianQin. Our results show that intrinsically magnetic fields modify spacetime and leave observable imprints on extreme mass-ratio inspiral GWs, which may be tested by future observations.

</details>


### [174] [Constraints on Interacting Early Dark Energy from a Modified Temperature-Redshift Relation and CMB Acoustic Scales](https://arxiv.org/abs/2602.09498)
*Y Bisabr*

Main category: gr-qc

TL;DR: 论文研究早期暗能量标量场与辐射的耦合如何修改宇宙微波背景温度红移关系，通过改变复合时期的声视界来影响哈勃张力的解释，但观测数据对耦合强度有严格约束。


<details>
  <summary>Details</summary>
Motivation: 哈勃张力（早期和晚期哈勃常数测量之间的差异）促使人们扩展标准宇宙学模型，特别是修改复合前的物理过程。本文研究早期暗能量标量场与辐射的耦合如何影响宇宙演化。

Method: 研究早期暗能量标量场与辐射的耦合，推导修改后的温度演化方程，解释为有效光子非守恒。在紧耦合机制下研究线性标量扰动，分析耦合对背景演化的影响而不引入新的扰动自由度。

Result: 耦合主要通过改变复合时期的声视界来影响观测效应，从而修改角声学尺度。利用普朗克卫星对声学尺度的约束，得到对耦合强度的一致性界限，表明标准温度红移关系的偏差受到严格限制。

Conclusion: 早期暗能量与辐射的耦合可以修改背景演化并影响哈勃张力的解释，但观测数据对耦合强度有严格约束，标准温度红移关系的偏差被紧密限制。

Abstract: The Hubble tension, reflecting a persistent discrepancy between early- and late-time determinations of the Hubble constant, continues to motivate extensions of the standard cosmological model The Hubble tension motivates extensions of the standard cosmological model that modify pre-recombination physics. In this work we study an early dark energy scalar field coupled to radiation prior to recombination. The interaction leads to energy exchange between the two components and modifies the standard cosmic microwave background temperature redshift relation.
  We derive the modified temperature evolution from the background equations and interpret it in terms of effective photon non-conservation. We also study linear scalar perturbations in the tight-coupling regime relevant for cosmic microwave background acoustic physics. We show that the interaction affects the background evolution without introducing new dynamical degrees of freedom at the perturbation level.
  The dominant observational effect arises through a shift in the sound horizon at recombination, which modifies the angular acoustic scale. Using the Planck constraint on the acoustic scale we obtain a consistency bound on the coupling strength and show that deviations from the standard temperature redshift relation are tightly constrained.

</details>


### [175] [Dynamical Dark Energy Signatures from a New Transition $Om(z)$ Parametrization in Flat FLRW Cosmology](https://arxiv.org/abs/2602.09525)
*Manish Yadav,Archana Dixit,Anirudh Pradhan,M. S. Barak*

Main category: gr-qc

TL;DR: 提出新的Om(z)诊断参数化形式Om(z)=z^l/(1+z)^m，用于探测宇宙演化中暗能量的动力学行为，发现从精质相到幽灵相的转变


<details>
  <summary>Details</summary>
Motivation: 研究宇宙演化中暗能量的动力学行为，探测标准ΛCDM模型的偏差，通过新的Om(z)参数化形式更好地描述宇宙演化过程

Method: 使用新的Om(z)=z^l/(1+z)^m参数化形式，在平坦FLRW框架下，利用OHD、Pantheon Plus和SH0ES观测数据，通过MCMC分析约束参数空间{H₀, l, m}

Result: 发现Om(z)斜率从负到正的转变，转变红移分别为z_t≈1.41、0.65、0.33；得到H₀=73.01±0.36 km/s/Mpc；宇宙当前年龄约13-14 Gyr；减速到加速转变发生在z_t∈[0.5,0.8]区间

Conclusion: 新的Om(z)参数化成功捕捉了宇宙演化的渐进变化，揭示了暗能量从精质相到幽灵相的动力学转变，支持了暗能量动力学演化的可能性

Abstract: We investigate a cosmic scenario using a new transition parameterization of the $Om(z)$ diagnostic, $Om(z) = \frac{z^l}{(1+z)^m}$, in the spatially flat Friedmann Lemaître Robertson-Walker (FLRW) framework. Using observational datasets such as Observational Hubble Data (OHD), Pantheon Plus (PP), and SH0ES, we analyze the evolution of the $Om(z)$ function to probe deviations from the standard $Λ$CDM model and constrain free parameter space {$H_0$, l, m } using Markov Chain Monte Carlo (MCMC) analysis with the emcee sampler. Our analysis reveals a clear transition in the slope of $Om(z)$ from negative to positive at transition redshift values $z_t \approx 1.41$, $0.65$, and $0.33$ for the OHD, OHD+PP, and OHD+PP$\&$SH0ES datasets, respectively. This behavior suggests a dynamical evolution of dark energy, indicating a transition from a quintessence-like phase to a phantom regime. From the combined OHD+PP$\&$SH0ES dataset, we obtain a best-fit value of the Hubble constant \( H_0 = 73.01 \pm 0.36 \, \mathrm{km\,s^{-1}\,Mpc^{-1}} \), which is consistent with the SH0ES calibration and supports the viability of our model. Additionally, our analysis indicates that the current age of the Universe is approximately $13 \sim 14$ Gyr from all available combinations of datasets, which is consistent with observational expectations. Further, we find that the deceleration-to-acceleration transition, which marks the beginning of cosmic acceleration, is inferred to occur within the redshift interval $z_t \in [0.5, 0.8]$, highlighting the emergence of dark energy as the dominant component in the Universe's recent expansion history. Our transition $Om(z)$ parameterization captured progressive cosmological changes and enabled seamless interpolation over cosmic epochs.

</details>


### [176] [Revisiting critical orbits of test particles traveling in a black hole background](https://arxiv.org/abs/2602.09568)
*Ping Li,Jun Cheng,Jiang-he Yang*

Main category: gr-qc

TL;DR: 系统研究各种黑洞背景下测试粒子的临界轨道，包括史瓦西、RN、克尔和克尔-纽曼时空，从径向方程的根结构直接识别临界轨道情况，并提供参数与临界半径的显式关系


<details>
  <summary>Details</summary>
Motivation: 系统性地重新审视不同黑洞背景下测试粒子的临界轨道问题，特别是光子球、黑洞阴影与临界零测地线之间的关系，为黑洞物理研究提供统一的理论框架

Method: 从径向方程的根结构直接识别临界轨道情况，推导能量、角动量、荷质比等参数与临界半径的显式关系表达式，并对每种黑洞场景提供临界轨道的显式表达式

Result: 获得了各种黑洞背景下临界轨道的完整解析表达式，提供了光子球、黑洞阴影与临界零测地线之间关系的详细分析，并给出了广泛的数值计算结果

Conclusion: 系统建立了不同黑洞背景下临界轨道的统一理论框架，为黑洞阴影观测和强引力场测试粒子动力学研究提供了重要的理论基础

Abstract: This paper systematically revisits the critical orbits of test particles moving in various black hole backgrounds, including the Schwarzschild, Reissner-Nordström, Kerr, and Kerr-Newman spacetimes. We identify the critical orbit cases directly from the root structure of the radial equation, and provide explicit expressions relating the relevant parameters -- energy, angular momentum, and charge-to-mass ratio -- to the critical radius, as well as explicit expressions for the critical orbits in each scenario. Special attention is given to the relationship between the photon spheres, black hole shadows and the critical null geodesics. Extensive numerical results are also provided.

</details>


### [177] [Thermodynamic Interpretation of the Kompanneets-Chernov-Kantowski-Sachs Solutions](https://arxiv.org/abs/2602.09682)
*Salvador Mengual,Joan Josep Ferrando*

Main category: gr-qc

TL;DR: 该论文将Kompanneets-Chernov-Kantowski-Sachs时空均匀理想流体解解释为热力学理想流体的等熵演化，即非均匀T-模型的等熵极限，并分析了特定理想气体解及其热力学变量。


<details>
  <summary>Details</summary>
Motivation: 研究Kompanneets-Chernov-Kantowski-Sachs时空均匀理想流体解的热力学解释，将其与更一般的非均匀T-模型联系起来，并分析理想气体在广义相对论框架下的行为。

Method: 将时空均匀解解释为非均匀T-模型的等熵极限；分析特定理想气体解并推导热力学变量；建立经典理想气体的场方程并分析解的行为；研究满足相对论γ定律的模型。

Result: 证明了在广泛时空区域内满足物理现实的宏观条件；获得了特定情况下的解；建立了经典理想气体的场方程并分析了其行为。

Conclusion: Kompanneets-Chernov-Kantowski-Sachs解可以解释为热力学理想流体的等熵演化，为理解相对论框架下的理想气体行为提供了理论框架。

Abstract: The spatially homogeneous perfect fluid solutions by Kompanneets-Chernov-Kantowski-Sachs are interpreted as a thermodynamic perfect fluid in isentropic evolution, namely, the isentropic limit of their non-homogeneous generalizations, the T-models. Some specific solutions that model a generic ideal gas are examined, and the associated thermodynamic variables are obtained. We show that the necessary macroscopic conditions for physical reality are fulfilled in wide spacetime domains. The field equations for a classical ideal gas are established, and the behavior of the solution is analyzed. The models fulfilling a relativistic $γ$-law are also examined, and the solutions for some particular cases are obtained.

</details>


### [178] [Resummed energy loss in extreme-mass-ratio scattering using critical orbits](https://arxiv.org/abs/2602.10089)
*Leor Barack,Riccardo Gonzo,Benjamin Leather,Oliver Long,Niels Warburton*

Main category: gr-qc

TL;DR: 提出一种结合弱场和强场描述黑洞双星动力学的重求和方案，针对极端质量比散射中的辐射可观测量，推导出总引力波能量的普适插值公式。


<details>
  <summary>Details</summary>
Motivation: 为了弥合黑洞双星动力学中弱场描述（后牛顿近似）和强场描述（后闵可夫斯基近似）之间的差距，特别是在极端质量比散射情况下。

Method: 利用散射与坠入参数空间分界线附近辐射能量发散形式作为强场诊断工具，通过不稳定圆形测地线瞬时能量通量的插值来获得对数发散主导项，结合后闵可夫斯基和后牛顿项进行重求和。

Result: 推导出适用于小质量比极限的总引力波能量（辐射到无穷远和进入大黑洞视界）的普适插值公式，并通过黑洞微扰理论的数值计算结果进行验证。

Conclusion: 该方法成功建立了弱场和强场描述之间的桥梁，同样的思路可通过无束缚到束缚映射或直接重求和束缚轨道后牛顿表达式，应用于束缚轨道的辐射可观测量。

Abstract: Motivated by recent efforts to bridge between weak-field and strong-field descriptions of black-hole binary dynamics, we develop a resummation scheme for post-Minkowskian radiative observables in extreme-mass-ratio scattering, augmented with post-Newtonian terms. Specifically, we derive universal interpolation formulas for the total energy emitted in gravitational waves out to infinity and down the event horizon of the large black hole, valid to leading order in the small mass ratio. We test our formulas using numerical results from direct calculations in black hole perturbation theory. The central idea of our approach is to utilize as a strong-field diagnostic the known form of divergence in the radiated energy along geodesics near the parameter-space separatrix between scattering and plunge. The dominant, logarithmic term of this divergence can be expressed in terms of instantaneous energy fluxes calculated along the unstable circular geodesics that form the separatrix, fluxes that we obtain using interpolation of highly accurate numerical data. The same idea could be applied to bound-orbit radiative observables via either unbound-to-bound mapping or a direct resummation of bound-orbit post-Newtonian expressions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [179] [UniPhy: Unifying Riemannian-Clifford Geometry and Biorthogonal Dynamics for Planetary-Scale Continuous Weather Modeling](https://arxiv.org/abs/2602.09030)
*Ruiqing Yan,Haoyu Deng,Yuhang Shao,Xingbo Du,Jingyuan Wang,Zhengyi Yang*

Main category: physics.comp-ph

TL;DR: UniPhy是一个连续时间非厄米神经随机偏微分方程求解器，通过几何变换、动态建模和计算优化，解决了传统数据驱动天气模型在多尺度连续动力学和热力学开放性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的天气模型虽然取得了显著的确定性精度，但依赖于离散时间映射和封闭系统假设，无法捕捉大气多尺度连续动力学和热力学开放性，需要新的物理完整基础模型架构。

Method: 1) 几何上使用黎曼-克利福德规范变换平坦化行星异质性；2) 动态上构建非厄米双正交谱算子结合全局通量追踪器；3) 计算上通过识别解析解的代数结合性，将自适应物理积分重构为并行前缀和问题。

Result: UniPhy建立了一个物理完整的基础模型架构，统一了几何适应性、热力学一致性和计算效率，实现了对数线性序列并行性。

Conclusion: UniPhy通过连续时间非厄米神经SPDE求解器，为天气建模提供了更物理完整的解决方案，克服了传统数据驱动模型的局限性，代码已开源。

Abstract: While data-driven weather models have achieved remarkable deterministic accuracy, they fundamentally rely on discrete-time mappings and closed-system assumptions, failing to capture the multi-scale continuous dynamics and thermodynamic openness of the atmosphere. To address these limitations, we propose UniPhy, a continuous-time non-Hermitian neural stochastic partial differential equation (SPDE) solver. Geometrically, we employ Riemannian-Clifford gauge transformations to flatten planetary heterogeneity, enabling globally consistent operations. Dynamically, we construct non-Hermitian biorthogonal spectral operators integrated with a global flux tracker to capture transient energy growth and open-system exchange. Computationally, by identifying the algebraic associativity of the analytic solution, we reformulate adaptive physical integration as a parallel prefix-sum problem, achieving log-linear sequence parallelism. UniPhy establishes a physically complete foundation model architecture that unifies geometric adaptivity, thermodynamic consistency, and computational efficiency. Our code is available at <https://github.com/yrqUni/UniPhy>.

</details>


### [180] [A complete phase-field fracture model for brittle materials subjected to thermal shocks](https://arxiv.org/abs/2602.09031)
*Bo Zeng,John E. Dolbow*

Main category: physics.comp-ph

TL;DR: 提出完整的相场断裂模型处理热-力耦合问题，能够统一处理热冲击下从裂纹扩展到裂纹萌生的多种断裂场景，超越经典方法。


<details>
  <summary>Details</summary>
Motivation: 脆性材料在热冲击下会产生强烈的温度梯度，进而引发足以导致断裂的机械应力。现有方法难以统一处理热-力耦合断裂问题中的不同断裂场景。

Method: 开发完整的相场断裂模型，其中材料体积特性、材料强度和断裂韧性可以独立指定。模型能够处理热-力耦合问题，涵盖从大预存裂纹扩展到均匀应力状态下裂纹萌生的各种场景。

Result: 模型成功再现了玻璃板受控淬火实验中的裂纹模式、陶瓷圆盘红外辐射下的直裂纹和分支裂纹，以及陶瓷颗粒快速功率脉冲下的断裂转变。模型能够解释材料强度在断裂过程中的重要作用。

Conclusion: 完整的相场模型统一了热冲击下不同断裂场景的处理方法，超越了经典方法，能够在极端环境下更可靠地预测脆性断裂行为。

Abstract: Brittle materials subjected to thermal shocks experience strong temperature gradients that in turn give rise to mechanical stresses that can be large enough to induce fracture. This work presents a complete model for phase-field fracture for coupled thermo-mechanical problems, wherein the bulk material properties, the material strength, and the fracture toughness are specified independently. The capabilities of the model are assessed across a wide span of scenarios in thermo-mechanical fracture, from the propagation of large pre-existing cracks to crack nucleation under spatially uniform states of stress. In particular, we revisit the controlled quenching of glass plates, and demonstrate how the model captures experimentally observed crack patterns across a range of thermal loads. Ceramic disks subjected to infrared radiation are also examined, with the model reproducing both straight cracks in notched specimens and branching in intact specimens. Finally, ceramic pellets subjected to rapid power pulses are examined, with the model explaining experimental transitions from intact to fractured pellets and the important role of material strength. The results demonstrate that the complete phase-field model unifies the treatment of distinct fracture scenarios under thermal shock, surpassing classical approaches and enabling more reliable prediction of brittle fracture in extreme environments.

</details>


### [181] [A single-stage high-order compact gas-kinetic scheme in arbitrary Lagrangian-Eulerian formulation](https://arxiv.org/abs/2602.09482)
*Yue Zhang,Xing Ji,Yibing Chen,Fengxiang Zhao,Kun Xu*

Main category: physics.comp-ph

TL;DR: 开发了一种基于任意拉格朗日-欧拉(ALE)框架的紧凑气体动力学格式，通过单步重构和简化高阶重构矩阵，在保持高精度同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: ALE方法能有效追踪激波和接触间断等流动不连续性，但网格运动改变几何形状并增加计算成本，需要开发更高效的计算方法。

Method: 1) 使用气体动力学格式构建三阶时间精度的通量，单步完成重构和通量计算；2) 采用简化的四阶紧凑重构，使用小矩阵减少计算量；3) 结合广义ENO方法处理间断。

Result: 重构速度比之前方法快2.4-3.0倍，通过黎曼问题、Sedov问题、Noh问题和Saltzmann问题验证了方法的鲁棒性和精度。

Conclusion: 提出的紧凑气体动力学ALE格式在保持高分辨率的同时显著提高了计算效率，为复杂流动模拟提供了有效的数值工具。

Abstract: This study presents the development of a compact gas-kinetic scheme using an arbitrary Lagrangian-Eulerian (ALE) formulation for structured meshes. Unlike the Eulerian formulation, the ALE approach effectively tracks flow discontinuities, such as shock waves and contact discontinuities. However, mesh motion alters the geometry and increases computational costs. To address this, two key strategies were introduced to reduce costs and enhance accuracy. The first strategy is to use the gas-kinetic scheme to construct a third-order gas-kinetic flux, rather than the Runge-Kutta method to achieve high-order time accuracy, which allows a single reconstruction and flux calculation per time step. This approach enables direct updates of both cell-averaged flow variables and their gradients using a time-accurate flux function, facilitating compact reconstruction. Second, the significant computational expense is spent on reconstruction, which requires recalculating the reconstruction matrix at each time step due to mesh changes. A simplified fourth-order compact reconstruction using a small matrix was used to mitigate this cost. The combination of fourth-order spatial reconstruction and third-order time-accurate flux evolution ensures both high resolution and computational efficiency in the ALE framework. The tests shows that the current reconstruction is 2.4x to 3.0x faster than the previous reconstruction. Additionally, a generalized ENO(GENO) method for handling discontinuities enhances the scheme's robustness. The numerical test cases, such as the Riemann problem, Sedov problem, Noh problem, and Saltzmann problem, demonstrated the robustness and accuracy of our method.

</details>
