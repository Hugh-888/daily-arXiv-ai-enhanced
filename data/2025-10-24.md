<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 102]
- [gr-qc](#gr-qc) [Total: 20]
- [quant-ph](#quant-ph) [Total: 47]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Some Attention is All You Need for Retrieval](https://arxiv.org/abs/2510.19861)
*Felix Michalak,Steven Abreu*

Main category: cs.LG

TL;DR: 在混合SSM-Transformer架构中发现完全功能分离：检索任务完全依赖自注意力层，而SSM层无补偿机制。仅保留15%注意力头即可维持近乎完美的检索性能。


<details>
  <summary>Details</summary>
Motivation: 研究混合架构中不同组件（SSM与注意力）的功能特化程度，挑战关于架构冗余的假设。

Method: 通过注意力消融实验，在RecurrentGemma-2B/9B和Jamba-Mini-1.6模型上测试检索性能，并分析注意力稀疏化的影响。

Result: 注意力消融导致检索完全失败（0%准确率），而仅保留15%注意力头可维持近乎完美的检索性能，同时保留84%的MMLU性能。

Conclusion: 混合架构中的功能分离表明这些模型作为专门化模块而非集成系统运行，对架构优化和可解释性有重要影响。

Abstract: We demonstrate complete functional segregation in hybrid SSM-Transformer
architectures: retrieval depends exclusively on self-attention layers. Across
RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic
retrieval failure (0% accuracy), while SSM layers show no compensatory
mechanisms even with improved prompting. Conversely, sparsifying attention to
just 15% of heads maintains near-perfect retrieval while preserving 84% MMLU
performance, suggesting self-attention specializes primarily for retrieval
tasks. We identify precise mechanistic requirements for retrieval: needle
tokens must be exposed during generation and sufficient context must be
available during prefill or generation. This strict functional specialization
challenges assumptions about redundancy in hybrid architectures and suggests
these models operate as specialized modules rather than integrated systems,
with immediate implications for architecture optimization and interpretability.

</details>


### [2] [An Integrated Approach to Neural Architecture Search for Deep Q-Networks](https://arxiv.org/abs/2510.19872)
*Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian*

Main category: cs.LG

TL;DR: NAS-DQN通过在线神经架构搜索控制器实现动态网络重构，在深度强化学习中超越静态架构设计，获得更优的最终性能、样本效率和策略稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统深度强化学习代理的神经网络架构通常通过昂贵的超参数搜索确定后固定不变，这限制了性能。本研究探索在线自适应架构优化是否能突破这一限制。

Method: 提出NAS-DQN代理，将学习到的神经架构搜索控制器直接集成到DRL训练循环中，基于累积性能反馈实现动态网络重构。

Result: NAS-DQN在连续控制任务中优于三个固定架构基线和随机搜索控制，实现了更优的最终性能、样本效率和策略稳定性，且计算开销可忽略。

Conclusion: 架构自适应不仅有益而且是深度强化学习中实现最优样本效率的必要条件，RL代理的设计可以无缝集成为学习过程的动态组成部分。

Abstract: The performance of deep reinforcement learning agents is fundamentally
constrained by their neural network architecture, a choice traditionally made
through expensive hyperparameter searches and then fixed throughout training.
This work investigates whether online, adaptive architecture optimization can
escape this constraint and outperform static designs. We introduce NAS-DQN, an
agent that integrates a learned neural architecture search controller directly
into the DRL training loop, enabling dynamic network reconfiguration based on
cumulative performance feedback. We evaluate NAS-DQN against three
fixed-architecture baselines and a random search control on a continuous
control task, conducting experiments over multiple random seeds. Our results
demonstrate that NAS-DQN achieves superior final performance, sample
efficiency, and policy stability while incurring negligible computational
overhead. Critically, the learned search strategy substantially outperforms
both undirected random architecture exploration and poorly-chosen fixed
designs, indicating that intelligent, performance-guided search is the key
mechanism driving success. These findings establish that architecture
adaptation is not merely beneficial but necessary for optimal sample efficiency
in online deep reinforcement learning, and suggest that the design of RL agents
need not be a static offline choice but can instead be seamlessly integrated as
a dynamic component of the learning process itself.

</details>


### [3] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: ReGraphT是一个无需训练的检索增强生成框架，通过构建CUDA优化轨迹图和使用蒙特卡洛图搜索，将LLM级推理能力转移到小型模型，使SLM在CUDA代码生成任务上接近LLM性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在生成优化CUDA代码方面表现良好，但存在代码泄露风险和计算成本高的问题。小型语言模型虽然轻量且隐私友好，但推理能力有限，在复杂CUDA生成任务中表现不佳。

Method: 将CUDA优化轨迹组织成结构化推理图，将组合优化建模为状态转换，利用蒙特卡洛图搜索进行高效探索，构建了按推理复杂度分层的CUDA专用基准。

Result: ReGraphT在CUDAEval和ParEval上平均实现2.33倍加速，优于HPC专用微调模型和其他检索增强方法，使SLM接近LLM性能水平。

Conclusion: ReGraphT框架成功地将LLM级推理能力转移到SLM，解决了隐私风险和计算开销问题，为高效GPU编程提供了可行解决方案。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>


### [4] [From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem](https://arxiv.org/abs/2510.19889)
*Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis*

Main category: cs.LG

TL;DR: 提出基于Transformer架构的深度学习模型，直接预测均衡路径流量，大幅降低交通分配问题的计算时间，适应需求变化和网络结构调整。


<details>
  <summary>Details</summary>
Motivation: 传统基于均衡原理的交通分配方法在大规模网络中计算复杂度呈非线性增长，计算成本过高。

Method: 使用Transformer架构的深度神经网络，直接从OD对预测均衡路径流量，捕捉OD对间的复杂相关性。

Result: 在多个测试网络上，该模型比传统优化方法快几个数量级，能有效估计多类网络中的路径级交通流量，降低计算成本并提高预测精度。

Conclusion: 该模型能灵活适应变化的需求和网络条件，支持交通管理和快速情景分析，提升交通规划与政策制定的效率。

Abstract: The traffic assignment problem is essential for traffic flow analysis,
traditionally solved using mathematical programs under the Equilibrium
principle. These methods become computationally prohibitive for large-scale
networks due to non-linear growth in complexity with the number of OD pairs.
This study introduces a novel data-driven approach using deep neural networks,
specifically leveraging the Transformer architecture, to predict equilibrium
path flows directly. By focusing on path-level traffic distribution, the
proposed model captures intricate correlations between OD pairs, offering a
more detailed and flexible analysis compared to traditional link-level
approaches. The Transformer-based model drastically reduces computation time,
while adapting to changes in demand and network structure without the need for
recalculation. Numerical experiments are conducted on the Manhattan-like
synthetic network, the Sioux Falls network, and the Eastern-Massachusetts
network. The results demonstrate that the proposed model is orders of magnitude
faster than conventional optimization. It efficiently estimates path-level
traffic flows in multi-class networks, reducing computational costs and
improving prediction accuracy by capturing detailed trip and flow information.
The model also adapts flexibly to varying demand and network conditions,
supporting traffic management and enabling rapid `what-if' analyses for
enhanced transportation planning and policy-making.

</details>


### [5] [FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning](https://arxiv.org/abs/2510.19893)
*Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang*

Main category: cs.LG

TL;DR: 提出了FairGRPO方法，通过分层强化学习解决医疗AI系统中的群体公平性问题，在7个临床数据集上显著减少了预测偏差并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 医疗AI系统在诊断能力上表现优异，但存在跨人口群体的性能差异，对少数群体造成实际伤害。多模态推理基础模型通过强化学习训练时会继承并放大训练数据中的偏见。

Method: FairGRPO是一种分层强化学习方法，采用基于表征、任务难度和数据来源的自适应重要性权重调整优势函数。对于缺乏人口标签的临床数据，使用无监督聚类自动发现潜在人口群体。

Result: 在7个临床诊断数据集上，FairGRPO将预测公平性提升了27.2%，同时F1分数提高了12.49%。训练动态分析显示该方法在优化过程中持续改善公平性。

Conclusion: FairGRPO有效解决了医疗AI中的公平性问题，并发布了FairMedGemma-4B模型，在保持最优性能的同时显著减少了跨人口群体的差异。

Abstract: Medical artificial intelligence systems have achieved remarkable diagnostic
capabilities, yet they consistently exhibit performance disparities across
demographic groups, causing real-world harm to underrepresented populations.
While recent multimodal reasoning foundation models have advanced clinical
diagnosis through integrated analysis of diverse medical data, reasoning
trainings via reinforcement learning inherit and often amplify biases present
in training datasets dominated by majority populations. We introduce
Fairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical
reinforcement learning approach that promotes equitable learning across
heterogeneous clinical populations. FairGRPO employs adaptive importance
weighting of advantages based on representation, task difficulty, and data
source. To address the common issue of missing demographic labels in the
clinical domain, we further employ unsupervised clustering, which automatically
discovers latent demographic groups when labels are unavailable. Through
comprehensive experiments across 7 clinical diagnostic datasets spanning 5
clinical modalities across X-ray, CT scan, dermoscropy, mammography and
ultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2%
against all vanilla and bias mitigated RL baselines, while improving F1 score
by 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO
progressively improves fairness throughout optimization, while baseline RL
methods exhibit deteriorating fairness as training progresses. Based on
FairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that
achieves state-of-the-art performance while demonstrating significantly reduced
disparities across demographic groups.

</details>


### [6] [Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification](https://arxiv.org/abs/2510.19896)
*Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling*

Main category: cs.LG

TL;DR: 提出基于SHAP特征选择的膀胱癌诊断方法，使用XGBoost、LightGBM和CatBoost算法，通过Optuna优化超参数和SMOTE平衡类别，在保持或提升性能指标的同时增强模型透明度。


<details>
  <summary>Details</summary>
Motivation: 开发更透明、可靠和高效的临床决策支持系统，优化泌尿系统疾病的筛查和早期诊断，特别是膀胱癌。

Method: 采用SHAP-based特征选择方法，使用XGBoost、LightGBM和CatBoost算法构建六个二元分类场景，通过Optuna进行超参数优化，使用SMOTE技术处理类别不平衡问题。

Result: SHAP特征选择在保持或改善平衡准确率、精确度和特异性等性能指标的同时，有效提升了模型的透明度和可解释性。

Conclusion: 基于可解释性技术（SHAP）的特征选择被证明是一种有效方法，有助于开发更透明、可靠和高效的临床决策支持系统。

Abstract: In this paper, we propose an approach to support the diagnosis of urinary
tract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive
exPlanations)-based feature selection to enhance the transparency and
effectiveness of predictive models. Six binary classification scenarios were
developed to distinguish bladder cancer from other urological and oncological
conditions. The algorithms XGBoost, LightGBM, and CatBoost were employed, with
hyperparameter optimization performed using Optuna and class balancing with the
SMOTE technique. The selection of predictive variables was guided by importance
values through SHAP-based feature selection while maintaining or even improving
performance metrics such as balanced accuracy, precision, and specificity. The
use of explainability techniques (SHAP) for feature selection proved to be an
effective approach. The proposed methodology may contribute to the development
of more transparent, reliable, and efficient clinical decision support systems,
optimizing screening and early diagnosis of urinary tract diseases.

</details>


### [7] [FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals](https://arxiv.org/abs/2510.19917)
*Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas*

Main category: cs.LG

TL;DR: FINDER是一个用于分析噪声数据集的分类框架，通过随机特征和KLE分解来处理低信噪比、小样本等挑战性问题。


<details>
  <summary>Details</summary>
Motivation: 噪声数据集（低信噪比、小样本、数据收集错误等）是分类方法的重要研究前沿，需要专门的方法来处理这些挑战。

Method: 将经验数据集视为随机场的实现，映射到希尔伯特空间构造随机特征，使用Kosambi-Karhunen-Loève展开分解为可计算不可约分量，通过特征分解进行分类。

Result: 在阿尔茨海默病阶段分类和遥感森林砍伐检测等数据稀缺的科学领域取得了最先进的突破。

Conclusion: FINDER在特定条件下优于现有方法，但存在失败模式和局限性，需要进一步讨论其适用范围。

Abstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample
sizes, faulty data collection, etc) remain a key research frontier for
classification methods with both theoretical and practical implications. We
introduce FINDER, a rigorous framework for analyzing generic classification
problems, with tailored algorithms for noisy datasets. FINDER incorporates
fundamental stochastic analysis ideas into the feature learning and inference
stages to optimally account for the randomness inherent to all empirical
datasets. We construct ''stochastic features'' by first viewing empirical
datasets as realizations from an underlying random field (without assumptions
on its exact distribution) and then mapping them to appropriate Hilbert spaces.
The Kosambi-Karhunen-Lo\'eve expansion (KLE) breaks these stochastic features
into computable irreducible components, which allow classification over noisy
datasets via an eigen-decomposition: data from different classes resides in
distinct regions, identified by analyzing the spectrum of the associated
operators. We validate FINDER on several challenging, data-deficient scientific
domains, producing state of the art breakthroughs in: (i) Alzheimer's Disease
stage classification, (ii) Remote sensing detection of deforestation. We end
with a discussion on when FINDER is expected to outperform existing methods,
its failure modes, and other limitations.

</details>


### [8] [Beyond the Ideal: Analyzing the Inexact Muon Update](https://arxiv.org/abs/2510.19933)
*Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik*

Main category: cs.LG

TL;DR: 本文首次分析了Muon优化器中非精确正交化更新的理论性能，揭示了近似精度与最优步长和动量参数之间的耦合关系。


<details>
  <summary>Details</summary>
Motivation: Muon优化器在实践中依赖快速近似正交化，但现有理论分析都假设使用计算不可行的精确SVD更新，存在理论与实践的脱节。

Method: 在线性最小化预言机(LMO)优化框架内，引入加性误差模型来捕捉实际近似方案的非精确性，分析非精确正交化更新的性能。

Result: 分析得出了明确的性能界限，量化了性能随LMO非精确性/误差的退化程度，揭示了非精确性与最优步长和动量参数之间的基本耦合关系。

Conclusion: 近似程序（如牛顿-舒尔茨步数）从实现细节提升为必须与学习调度共同调优的关键参数，NanoGPT实验证实了预测的耦合关系。

Abstract: The Muon optimizer has rapidly emerged as a powerful, geometry-aware
alternative to AdamW, demonstrating strong performance in large-scale training
of neural networks. However, a critical theory-practice disconnect exists:
Muon's efficiency relies on fast, approximate orthogonalization, yet all prior
theoretical work analyzes an idealized, computationally intractable version
assuming exact SVD-based updates. This work moves beyond the ideal by providing
the first analysis of the inexact orthogonalized update at Muon's core. We
develop our analysis within the general framework of Linear Minimization Oracle
(LMO)-based optimization, introducing a realistic additive error model to
capture the inexactness of practical approximation schemes. Our analysis yields
explicit bounds that quantify performance degradation as a function of the LMO
inexactness/error. We reveal a fundamental coupling between this inexactness
and the optimal step size and momentum: lower oracle precision requires a
smaller step size but larger momentum parameter. These findings elevate the
approximation procedure (e.g., the number of Newton-Schulz steps) from an
implementation detail to a critical parameter that must be co-tuned with the
learning schedule. NanoGPT experiments directly confirm the predicted coupling,
with optimal learning rates clearly shifting as approximation precision
changes.

</details>


### [9] [Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy](https://arxiv.org/abs/2510.19934)
*Xiang Li,Buxin Su,Chendi Wang,Qi Long,Weijie J. Su*

Main category: cs.LG

TL;DR: 本文针对去中心化联邦学习中的隐私预算量化问题，在f-DP框架下提出了两种新的隐私核算方法：PN-f-DP和Sec-f-LDP，能够更准确地捕捉稀疏通信、本地迭代和相关性噪声带来的隐私放大效应。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习允许用户在不与中央服务器共享数据的情况下协作，但由于复杂的算法组件（如去中心化通信和本地更新），准确量化隐私预算具有挑战性。

Method: 开发了两种基于f-DP的核算方法：PN-f-DP量化随机游走通信下用户对之间的隐私泄露，Sec-f-LDP通过共享秘密支持结构化噪声注入。结合f-DP理论和马尔可夫链集中度工具。

Result: 在合成和真实数据集上的实验表明，相比基于Rényi DP的方法，本文方法能够产生更紧的(ε,δ)边界和更好的效用。

Conclusion: f-DP在去中心化隐私核算中具有优势，能够更准确地量化隐私预算并提高算法效用。

Abstract: Differentially private (DP) decentralized Federated Learning (FL) allows
local users to collaborate without sharing their data with a central server.
However, accurately quantifying the privacy budget of private FL algorithms is
challenging due to the co-existence of complex algorithmic components such as
decentralized communication and local updates. This paper addresses privacy
accounting for two decentralized FL algorithms within the $f$-differential
privacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods
tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which
quantifies privacy leakage between user pairs under random-walk communication,
and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise
injection via shared secrets. By combining tools from $f$-DP theory and Markov
chain concentration, our accounting framework captures privacy amplification
arising from sparse communication, local iterations, and correlated noise.
Experiments on synthetic and real datasets demonstrate that our methods yield
consistently tighter $(\epsilon,\delta)$ bounds and improved utility compared
to R\'enyi DP-based approaches, illustrating the benefits of $f$-DP in
decentralized privacy accounting.

</details>


### [10] [Are Greedy Task Orderings Better Than Random in Continual Linear Regression?](https://arxiv.org/abs/2510.19941)
*Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry*

Main category: cs.LG

TL;DR: 本文分析了持续学习中任务排序对线性回归的影响，特别研究了贪心最大化任务间差异性的排序策略，并与随机排序进行比较。


<details>
  <summary>Details</summary>
Motivation: 研究任务排序在持续学习中的影响，特别是贪心最大化任务差异性的排序策略，这在先前工作中虽有提及但仍存在许多未解问题。

Method: 使用Kaczmarz方法文献中的工具，形式化贪心排序策略，并发展几何和代数直觉。在线性回归和CIFAR-100分类任务上进行实证分析。

Result: 实证显示贪心排序在平均损失上比随机排序收敛更快。在高秩回归设置中，贪心排序的损失界与随机排序类似；但在一般秩设置下，允许重复的贪心排序收敛速度为O(1/∛k)，而单次贪心排序可能失败。

Conclusion: 揭示了贪心和随机排序策略内部及之间的细微差别，贪心排序在特定条件下表现更好，但单次贪心排序存在失败风险。

Abstract: We analyze task orderings in continual learning for linear regression,
assuming joint realizability of training data. We focus on orderings that
greedily maximize dissimilarity between consecutive tasks, a concept briefly
explored in prior work but still surrounded by open questions. Using tools from
the Kaczmarz method literature, we formalize such orderings and develop
geometric and algebraic intuitions around them. Empirically, we demonstrate
that greedy orderings converge faster than random ones in terms of the average
loss across tasks, both for linear regression with random data and for linear
probing on CIFAR-100 classification tasks. Analytically, in a high-rank
regression setting, we prove a loss bound for greedy orderings analogous to
that of random ones. However, under general rank, we establish a
repetition-dependent separation. Specifically, while prior work showed that for
random orderings, with or without replacement, the average loss after $k$
iterations is bounded by $\mathcal{O}(1/\sqrt{k})$, we prove that single-pass
greedy orderings may fail catastrophically, whereas those allowing repetition
converge at rate $\mathcal{O}(1/\sqrt[3]{k})$. Overall, we reveal nuances
within and between greedy and random orderings.

</details>


### [11] [Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets](https://arxiv.org/abs/2510.19950)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 提出一种新的椭圆不确定性集合来处理金融市场中RL智能体训练与部署环境不匹配的问题，特别是市场影响的定向特性。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒RL方法依赖对称结构，无法捕捉市场影响的定向特性，导致训练和部署环境不匹配时性能下降。

Method: 开发椭圆不确定性集合，建立隐式和显式闭式解来计算最坏情况不确定性，实现高效鲁棒策略评估。

Result: 在单资产和多资产交易任务中，该方法获得更高的夏普比率，并在交易量增加时保持鲁棒性。

Conclusion: 该方法为金融市场中的RL提供了更忠实和可扩展的解决方案。

Abstract: In financial applications, reinforcement learning (RL) agents are commonly
trained on historical data, where their actions do not influence prices.
However, during deployment, these agents trade in live markets where their own
transactions can shift asset prices, a phenomenon known as market impact. This
mismatch between training and deployment environments can significantly degrade
performance. Traditional robust RL approaches address this model
misspecification by optimizing the worst-case performance over a set of
uncertainties, but typically rely on symmetric structures that fail to capture
the directional nature of market impact. To address this issue, we develop a
novel class of elliptic uncertainty sets. We establish both implicit and
explicit closed-form solutions for the worst-case uncertainty under these sets,
enabling efficient and tractable robust policy evaluation. Experiments on
single-asset and multi-asset trading tasks demonstrate that our method achieves
superior Sharpe ratio and remains robust under increasing trade volumes,
offering a more faithful and scalable approach to RL in financial markets.

</details>


### [12] [On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization](https://arxiv.org/abs/2510.19953)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 提出了一种新的零阶优化方法，通过设计无偏梯度估计器解决传统方法中的偏差问题，在函数评估基础上构建了无偏估计器，并在理论和实验中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法存在梯度估计偏差问题，除非扰动步长趋近于零，否则大多数梯度估计器都存在固有偏差，这限制了优化性能。

Method: 通过将方向导数重新表述为伸缩级数，并从精心设计的分布中采样，构建了基于函数评估的无偏梯度估计器家族，推导了最优缩放分布和扰动步长。

Result: 理论分析表明使用该估计器的SGD在光滑非凸目标上达到最优复杂度，在合成任务和语言模型微调实验中相比标准方法展现出更高的准确性和收敛性。

Conclusion: 提出的无偏梯度估计器成功解决了零阶优化中的偏差问题，在理论和实践中均表现出优越性能，为梯度不可用或计算昂贵的优化问题提供了有效解决方案。

Abstract: Zeroth-order optimization (ZOO) is an important framework for stochastic
optimization when gradients are unavailable or expensive to compute. A
potential limitation of existing ZOO methods is the bias inherent in most
gradient estimators unless the perturbation stepsize vanishes. In this paper,
we overcome this biasedness issue by proposing a novel family of unbiased
gradient estimators based solely on function evaluations. By reformulating
directional derivatives as a telescoping series and sampling from carefully
designed distributions, we construct estimators that eliminate bias while
maintaining favorable variance. We analyze their theoretical properties, derive
optimal scaling distributions and perturbation stepsizes of four specific
constructions, and prove that SGD using the proposed estimators achieves
optimal complexity for smooth non-convex objectives. Experiments on synthetic
tasks and language model fine-tuning confirm the superior accuracy and
convergence of our approach compared to standard methods.

</details>


### [13] [Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations](https://arxiv.org/abs/2510.19975)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文研究两点零阶梯度估计器，发现当扰动步长趋近于零时，最小化估计器渐近方差的扰动分布可以与真实梯度方向对齐，而非保持固定长度。提出了方向对齐扰动(DAP)方案，并在理论和实验上验证其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注固定长度的随机扰动，而忽略了扰动方向与梯度方向对齐可能带来的优势。本文旨在探索这种方向对齐扰动的潜力。

Method: 将问题表述为扰动分布空间上的约束函数优化问题，提出方向对齐扰动(DAP)方案，该方案自适应地在关键方向上提供更高精度。

Result: 理论分析表明DAP方案在特定条件下优于传统方法，实验在合成问题和实际任务上验证了其有效性。

Conclusion: 方向对齐扰动方案比传统固定长度扰动方法具有优势，特别是在关键方向上能提供更准确的梯度估计。

Abstract: In this paper, we explore the two-point zeroth-order gradient estimator and
identify the distribution of random perturbations that minimizes the
estimator's asymptotic variance as the perturbation stepsize tends to zero. We
formulate it as a constrained functional optimization problem over the space of
perturbation distributions. Our findings reveal that such desired perturbations
can align directionally with the true gradient, instead of maintaining a fixed
length. While existing research has largely focused on fixed-length
perturbations, the potential advantages of directional alignment have been
overlooked. To address this gap, we delve into the theoretical and empirical
properties of the directionally aligned perturbation (DAP) scheme, which
adaptively offers higher accuracy along critical directions. Additionally, we
provide a convergence analysis for stochastic gradient descent using
$\delta$-unbiased random perturbations, extending existing complexity bounds to
a wider range of perturbations. Through empirical evaluations on both synthetic
problems and practical tasks, we demonstrate that DAPs outperform traditional
methods under specific conditions.

</details>


### [14] [Towards Strong Certified Defense with Universal Asymmetric Randomization](https://arxiv.org/abs/2510.19977)
*Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong*

Main category: cs.LG

TL;DR: UCAN提出了一种使用各向异性噪声的通用认证对抗鲁棒性方法，显著提升了随机平滑技术的效果。


<details>
  <summary>Details</summary>
Motivation: 现有随机平滑方法主要使用各向同性噪声分布，忽略了输入和数据维度的异质性，限制了鲁棒性认证的有效性。

Method: UCAN将现有随机平滑方法从对称（各向同性）转换为非对称（各向异性）噪声分布，支持多种噪声分布和ℓp范数认证，并开发了三种噪声参数生成器来优化各向异性噪声参数。

Result: 在MNIST、CIFAR10和ImageNet数据集上，UCAN在大认证半径下的认证准确率比现有最先进方法提升了高达182.6%。

Conclusion: UCAN通过各向异性噪声显著提升了对抗鲁棒性认证效果，为随机平滑技术提供了更有效的通用框架。

Abstract: Randomized smoothing has become essential for achieving certified adversarial
robustness in machine learning models. However, current methods primarily use
isotropic noise distributions that are uniform across all data dimensions, such
as image pixels, limiting the effectiveness of robustness certification by
ignoring the heterogeneity of inputs and data dimensions. To address this
limitation, we propose UCAN: a novel technique that \underline{U}niversally
\underline{C}ertifies adversarial robustness with \underline{A}nisotropic
\underline{N}oise. UCAN is designed to enhance any existing randomized
smoothing method, transforming it from symmetric (isotropic) to asymmetric
(anisotropic) noise distributions, thereby offering a more tailored defense
against adversarial attacks. Our theoretical framework is versatile, supporting
a wide array of noise distributions for certified robustness in different
$\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the
classifier's prediction over perturbed inputs with provable robustness bounds
through tailored noise injection. Additionally, we develop a novel framework
equipped with three exemplary noise parameter generators (NPGs) to optimally
fine-tune the anisotropic noise parameters for different data dimensions,
allowing for pursuing different levels of robustness enhancements in
practice.Empirical evaluations underscore the significant leap in UCAN's
performance over existing state-of-the-art methods, demonstrating up to
$182.6\%$ improvement in certified accuracy at large certified radii on MNIST,
CIFAR10, and ImageNet datasets.\footnote{Code is anonymously available at
\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}

</details>


### [15] [Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency](https://arxiv.org/abs/2510.19980)
*Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe*

Main category: cs.LG

TL;DR: 研究发现适当截断历史数据反而能提高预测精度，提出AMRC方法通过动态掩码损失和表示一致性约束来抑制冗余特征学习，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统"长序列信息增益假设"存在局限性，现有模型在训练中学习大量冗余特征（如噪声或不相关波动），影响有效信号提取。

Method: 提出AMRC方法：1）动态掩码损失，自适应识别高区分度时间片段指导梯度下降；2）表示一致性约束，稳定输入、标签和预测之间的映射关系。

Result: 实验结果表明AMRC有效抑制冗余特征学习，显著提高模型性能。

Conclusion: 这项工作不仅挑战了时序建模中的传统假设，还为开发高效稳健的预测模型提供了新的理论见解和方法突破。

Abstract: Time series forecasting plays a pivotal role in critical domains such as
energy management and financial markets. Although deep learning-based
approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the
prevailing "long-sequence information gain hypothesis" exhibits inherent
limitations. Through systematic experimentation, this study reveals a
counterintuitive phenomenon: appropriately truncating historical data can
paradoxically enhance prediction accuracy, indicating that existing models
learn substantial redundant features (e.g., noise or irrelevant fluctuations)
during training, thereby compromising effective signal extraction. Building
upon information bottleneck theory, we propose an innovative solution termed
Adaptive Masking Loss with Representation Consistency (AMRC), which features
two core components: 1) Dynamic masking loss, which adaptively identified
highly discriminative temporal segments to guide gradient descent during model
training; 2) Representation consistency constraint, which stabilized the
mapping relationships among inputs, labels, and predictions. Experimental
results demonstrate that AMRC effectively suppresses redundant feature learning
while significantly improving model performance. This work not only challenges
conventional assumptions in temporal modeling but also provides novel
theoretical insights and methodological breakthroughs for developing efficient
and robust forecasting models.

</details>


### [16] [No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models](https://arxiv.org/abs/2510.19990)
*Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown*

Main category: cs.LG

TL;DR: 本文提出推理即填充和多重令牌熵解码两种方法，展示了掩码扩散语言模型在推理和后训练中的新应用价值。


<details>
  <summary>Details</summary>
Motivation: 针对掩码扩散语言模型在数学和编程任务中表现不佳的问题，探索如何充分利用其训练和计算优势。

Method: 提出推理即填充方法，使用MDLM填充推理模板来结构化输出；提出多重令牌熵解码，基于条件熵的自适应并行解码方法。

Result: 在GSM8k上，使用后验推理轨迹微调LLaDA-8B模型获得与人工推理轨迹相当的性能提升；MED方法保持性能的同时减少2.7倍解码步骤。

Conclusion: MDLM的训练和计算为推理和后训练方法开辟了新的可能性，超越了传统的顺序解码范式。

Abstract: Masked diffusion language models (MDLMs) are trained to in-fill positions in
randomly masked sequences, in contrast to next-token prediction models.
Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2)
multi-token decoding. However, we observe that for math and coding tasks,
any-order algorithms often underperform or behave similarly to left-to-right
sampling, and standard multi-token decoding significantly degrades performance.
At inference time, MDLMs compute the conditional distribution of all masked
positions. A natural question is: How can we justify this additional compute
when left-to-right one-token-at-a-time decoding is on par with any-order
decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs
to infill a reasoning template, we can structure outputs and distinguish
between reasoning and answer tokens. In turn, this enables measuring answer
uncertainty during reasoning, and early exits when the model converges on an
answer. Next, given an answer, reasoning-as-infilling enables sampling from the
MDLM posterior over reasoning traces conditioned on the answer, providing a new
source of high-quality data for post-training. On GSM8k, we observe that
fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a
performance boost on par with fine-tuning on human-written reasoning traces.
Additionally, given an answer, reasoning-as-infilling provides a method for
scoring the correctness of the reasoning process at intermediate steps. Second,
we propose multi-token entropy decoding (MED), a simple adaptive sampler that
minimizes the error incurred by decoding positions in parallel based on the
conditional entropies of those positions. MED preserves performance across
benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the
training and compute used by MDLMs unlock many new inference and post-training
methods.

</details>


### [17] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: 使用监督学习和决策树分类器，在CAD建模的平面图中基于RSSI数据进行RFID定位分类，用于国防资产存储的安全监控。


<details>
  <summary>Details</summary>
Motivation: 解决RFID跟踪在国防资产存储中的安全挑战，包括传感器特异性差、长距离检测漏洞、欺骗和伪造等问题导致的误检测和操作安全事件。

Method: 采用监督学习模拟，使用真实的RSSI数据和决策树分类，在CAD建模的平面图中对12个实验室区域进行位置推断，处理类别不平衡问题。

Result: 模型在5000个平衡观测样本上训练，总体准确率为34.2%，多个区域（F、G、H等）的F1分数超过0.40，但稀有类别（特别是LabZoneC）经常被错误分类。

Conclusion: 基于RSSI的决策树可以在现实模拟中应用于区域级异常检测或错位监控，但在低覆盖和低信号区域的可靠分类性能需要通过更好的天线布局或额外传感器来改进。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [18] [SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph](https://arxiv.org/abs/2510.20022)
*Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong*

Main category: cs.LG

TL;DR: SALT是一个轻量级框架，通过构建轨迹图来提供更细粒度的优势分配，解决了基于群体的RL算法在复杂多步任务中由于稀疏奖励导致的训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单轮任务中表现出色，但在复杂多步任务中应用仍具挑战性。基于群体的RL算法（如GRPO）仅依赖稀疏结果奖励，会均匀奖励或惩罚轨迹中的所有动作，导致训练不稳定和次优策略。

Method: 提出SALT框架，通过构建相同提示下的轨迹图来量化每个步骤的质量，并据此分配优势。该框架是即插即用模块，无需修改rollout过程，计算开销极小。

Result: 在WebShop、ALFWorld和AppWorld基准测试中，SALT在不同模型规模下均能持续提升性能。

Conclusion: SALT有效解决了基于群体RL算法的优势分配问题，通过细粒度的优势分配提升了复杂多步任务的性能，且易于集成到现有算法中。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
enabling language agents to excel at single-turn tasks. However, their
application to complex, multi-step, and long-horizon tasks remains challenging.
While reinforcement learning (RL) offers a promising avenue for addressing
these challenges, mainstream approaches typically rely solely on sparse,
outcome-based rewards, a limitation that becomes especially problematic for
group-based RL algorithms lacking critic models, such as Group Relative Policy
Optimization (GRPO). In such methods, uniformly rewarding or penalizing all
actions within a trajectory can lead to training instability and suboptimal
policies, because beneficial and detrimental actions are often entangled across
multi-step interactions. To address this challenge, we propose SALT, a novel
and lightweight framework that provides a finer-grained advantage assignment,
derived solely from outcome rewards. We achieve this by constructing a graph
from trajectories of the same prompt, which allows us to quantify the quality
of each step and assign advantages accordingly. Crucially, SALT is designed as
a plug-and-play module that seamlessly integrates with existing group-based RL
algorithms, requiring no modifications to the rollout procedure and introducing
negligible computational overhead. Extensive experiments on the WebShop,
ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that
SALT consistently improves performance. We also conduct a thorough analysis to
validate the design choices behind SALT and offer actionable insights.

</details>


### [19] [The Temporal Graph of Bitcoin Transactions](https://arxiv.org/abs/2510.20028)
*Vahid Jalili*

Main category: cs.LG

TL;DR: 提出了一个机器学习兼容的比特币经济拓扑图模型，重构资金流动，包含超过24亿节点和397.2亿边，提供完整的交易历史数据。


<details>
  <summary>Details</summary>
Motivation: 比特币网络虽然处理了超过10.8亿笔交易，但由于其伪匿名性和UTXO设计导致的资金流动模糊性，这些数据难以用于机器学习研究。

Method: 构建时间异质图模型，重建比特币资金流动，提供自定义采样方法、图数据库加载工具和数据库快照。

Result: 创建了包含完整交易历史的比特币经济拓扑图，数据集和工具包已开源。

Conclusion: 该数据集和工具包使机器学习社区能够大规模分析比特币复杂生态系统，推动异常检测、地址分类、市场分析等应用发展。

Abstract: Since its 2009 genesis block, the Bitcoin network has processed \num{>1.08}
billion (B) transactions representing \num{>8.72}B BTC, offering rich potential
for machine learning (ML); yet, its pseudonymity and obscured flow of funds
inherent in its \utxo-based design, have rendered this data largely
inaccessible for ML research. Addressing this gap, we present an ML-compatible
graph modeling the Bitcoin's economic topology by reconstructing the flow of
funds. This temporal, heterogeneous graph encompasses complete transaction
history up to block \cutoffHeight, consisting of \num{>2.4}B nodes and
\num{>39.72}B edges. Additionally, we provide custom sampling methods yielding
node and edge feature vectors of sampled communities, tools to load and analyze
the Bitcoin graph data within specialized graph databases, and ready-to-use
database snapshots. This comprehensive dataset and toolkit empower the ML
community to tackle Bitcoin's intricate ecosystem at scale, driving progress in
applications such as anomaly detection, address classification, market
analysis, and large-scale graph ML benchmarking. Dataset and code available at
\href{https://github.com/B1AAB/EBA}{github.com/b1aab/eba}

</details>


### [20] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 提出了一种基于拒绝采样的新算法，能够从现有TPP模型中并行、精确地采样多个未来值，无需架构更改或重新训练


<details>
  <summary>Details</summary>
Motivation: 传统时间点过程模型采用自回归方式采样，效率低下且无法并行化，限制了在大规模应用中的使用

Method: 基于拒绝采样的算法，允许从现有TPP模型中并行采样多个未来事件

Result: 在真实世界数据集上实现了经验性加速，同时提供了理论保证

Conclusion: 该方法弥合了表达性建模与高效并行生成之间的差距，适用于大规模TPP应用

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [21] [Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards](https://arxiv.org/abs/2510.20055)
*Yuwei Cheng,Zifeng Zhao,Haifeng Xu*

Main category: cs.LG

TL;DR: 提出了一种考虑广告延迟效应、累积影响和用户异质性的个性化竞价策略，通过上下文马尔可夫决策过程建模，结合两阶段最大似然估计和强化学习算法，实现了近乎最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在线广告平台需要有效的竞价策略来最大化利润，但现有研究往往未能同时考虑广告的三个关键因素：延迟和长期效应、累积影响（如强化或疲劳效应）以及用户异质性。

Method: 将广告竞价建模为具有延迟泊松奖励的上下文马尔可夫决策过程，提出两阶段最大似然估计器结合数据分割策略，并基于此设计强化学习算法来推导个性化竞价策略。

Result: 该方法实现了近乎最优的遗憾界 $\tilde{O}{(dH^2\sqrt{T})}$，其中 $d$ 是上下文维度，$H$ 是轮数，$T$ 是客户数量。理论结果通过仿真实验得到验证。

Conclusion: 所提出的方法能够有效处理广告竞价中的延迟效应、累积影响和用户异质性，为在线广告平台提供了高效的个性化竞价策略解决方案。

Abstract: Online advertising platforms use automated auctions to connect advertisers
with potential customers, requiring effective bidding strategies to maximize
profits. Accurate ad impact estimation requires considering three key factors:
delayed and long-term effects, cumulative ad impacts such as reinforcement or
fatigue, and customer heterogeneity. However, these effects are often not
jointly addressed in previous studies. To capture these factors, we model ad
bidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson
rewards. For efficient estimation, we propose a two-stage maximum likelihood
estimator combined with data-splitting strategies, ensuring controlled
estimation error based on the first-stage estimator's (in)accuracy. Building on
this, we design a reinforcement learning algorithm to derive efficient
personalized bidding strategies. This approach achieves a near-optimal regret
bound of $\tilde{O}{(dH^2\sqrt{T})}$, where $d$ is the contextual dimension,
$H$ is the number of rounds, and $T$ is the number of customers. Our
theoretical findings are validated by simulation experiments.

</details>


### [22] [Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs](https://arxiv.org/abs/2510.20064)
*Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang*

Main category: cs.LG

TL;DR: 提出了一种在线草稿模型选择算法，能够在推测解码中与最佳草稿模型竞争，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决推测解码中的在线草稿模型选择问题，旨在提升大语言模型推理效率。

Method: 设计了一种算法，能够准确评估所有草稿模型而无需额外查询目标模型，适用于各种推测解码方法。

Result: 在开源LLM和多样化数据集上的实验表明，该方法在多个领域显著优于现有最佳方法，特别在需要长推理链的场景中。

Conclusion: 该方法能够有效加速LLM推理，特别是在有领域专家草稿模型可用的情况下表现优异。

Abstract: Speculative decoding is widely used in accelerating large language model
(LLM) inference. In this work, we focus on the online draft model selection
problem in speculative decoding. We design an algorithm that provably competes
with the best draft model in hindsight for each query in terms of either the
token acceptance probability or expected acceptance length. In particular, we
show that we can accurately evaluate all draft models, instead of only the
chosen model without incurring additional queries to the target model, which
allows us to improve exponentially over the existing bandit-based approach as
the number of draft models increases. Our approach is generically applicable
with any speculative decoding methods (single draft, multi-drafts and
draft-trees). Moreover, we design system-efficient versions of online learners
and demonstrate that the overhead in computation and latency can be
substantially reduced. We conduct extensive experiments on open-source LLMs and
diverse datasets, demonstrating that our methods substantially outperform the
state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains
where specialized domain-expert drafters are available, especially when long
reasoning chains are required.

</details>


### [23] [A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers](https://arxiv.org/abs/2510.20066)
*Yimeng Qiu,Feihuang Fang*

Main category: cs.LG

TL;DR: 研究核心加密资产流动性和波动率代理是否产生溢出效应来预测市场风险，使用多层统计框架和机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 探索加密资产流动性和波动率之间的溢出效应，以预测市场整体风险。

Method: 集成三层统计框架：核心流动性与收益的相互作用、主成分关系、波动率因子投影，辅以VAR、HAR-X模型和机器学习协议。

Result: 发现显著的Granger因果关系和中等程度的样本外预测准确性。

Conclusion: 核心加密资产的流动性和波动率代理能够产生显著的溢出效应，对市场风险具有预测能力。

Abstract: We study whether liquidity and volatility proxies of a core set of
cryptoassets generate spillovers that forecast market-wide risk. Our empirical
framework integrates three statistical layers: (A) interactions between core
liquidity and returns, (B) principal-component relations linking liquidity and
returns, and (C) volatility-factor projections that capture cross-sectional
volatility crowding. The analysis is complemented by vector autoregression
impulse responses and forecast error variance decompositions (see Granger 1969;
Sims 1980), heterogeneous autoregressive models with exogenous regressors
(HAR-X, Corsi 2009), and a leakage-safe machine learning protocol using
temporal splits, early stopping, validation-only thresholding, and SHAP-based
interpretation. Using daily data from 2021 to 2025 (1462 observations across 74
assets), we document statistically significant Granger-causal relationships
across layers and moderate out-of-sample predictive accuracy. We report the
most informative figures, including the pipeline overview, Layer A heatmap,
Layer C robustness analysis, vector autoregression variance decompositions, and
the test-set precision-recall curve. Full data and figure outputs are provided
in the artifact repository.

</details>


### [24] [Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics](https://arxiv.org/abs/2510.20068)
*Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne*

Main category: cs.LG

TL;DR: 提出了耦合Transformer自编码器(CTAE)，用于从多脑区同时记录中分离共享和区域特定的神经动态，解决了现有方法忽略时间结构或无法分离共享/私有信号的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么忽略时间结构，要么局限于单脑区、线性读取或混淆共享与私有信号，无法有效处理多脑区记录中复杂的混合活动模式。

Method: 使用Transformer编码器和解码器捕获长程神经动态，将每个脑区的潜在空间显式划分为正交的共享和私有子空间。

Result: 在两个高密度电生理数据集上验证，CTAE提取的表征能更好地解码行为变量，优于现有方法。

Conclusion: CTAE为分析多脑区神经记录提供了一个统一框架，能有效分离共享和区域特定的动态，并提高行为解码性能。

Abstract: Simultaneous recordings from thousands of neurons across multiple brain areas
reveal rich mixtures of activity that are shared between regions and dynamics
that are unique to each region. Existing alignment or multi-view methods
neglect temporal structure, whereas dynamical latent variable models capture
temporal dependencies but are usually restricted to a single area, assume
linear read-outs, or conflate shared and private signals. We introduce the
Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both
(i) non-stationary, non-linear dynamics and (ii) separation of shared versus
region-specific structure in a single framework. CTAE employs transformer
encoders and decoders to capture long-range neural dynamics and explicitly
partitions each region's latent space into orthogonal shared and private
subspaces. We demonstrate the effectiveness of CTAE on two high-density
electrophysiology datasets with simultaneous recordings from multiple regions,
one from motor cortical areas and the other from sensory areas. CTAE extracts
meaningful representations that better decode behavioral variables compared to
existing approaches.

</details>


### [25] [ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models](https://arxiv.org/abs/2510.20084)
*Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan*

Main category: cs.LG

TL;DR: ShapeX是一个创新的时间序列分类解释框架，通过识别关键shapelet（形状片段）并使用Shapley值评估其重要性，提供比现有方法更精确和具有因果保真度的解释。


<details>
  <summary>Details</summary>
Motivation: 在医疗和金融等高风险应用中，时间序列分类模型的透明度至关重要。现有后验解释方法主要关注时间步级别的特征归因，忽略了分类结果主要由关键shapelet驱动的基本先验。

Method: ShapeX框架包含Shapelet描述与检测(SDD)框架，学习分类所需的各种shapelet，将时间序列分割为有意义的shapelet驱动片段，并使用Shapley值评估其显著性。

Result: 在合成和真实数据集上的实验表明，ShapeX在识别最相关子序列方面优于现有方法，提高了时间序列解释的精度和因果保真度。

Conclusion: ShapeX通过利用shapelet的原子性特性，能够揭示因果关系而不仅仅是相关性，为时间序列分类提供了更可靠的解释。

Abstract: Explaining time series classification models is crucial, particularly in
high-stakes applications such as healthcare and finance, where transparency and
trust play a critical role. Although numerous time series classification
methods have identified key subsequences, known as shapelets, as core features
for achieving state-of-the-art performance and validating their pivotal role in
classification outcomes, existing post-hoc time series explanation (PHTSE)
methods primarily focus on timestep-level feature attribution. These
explanation methods overlook the fundamental prior that classification outcomes
are predominantly driven by key shapelets. To bridge this gap, we present
ShapeX, an innovative framework that segments time series into meaningful
shapelet-driven segments and employs Shapley values to assess their saliency.
At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,
which effectively learns a diverse set of shapelets essential for
classification. We further demonstrate that ShapeX produces explanations which
reveal causal relationships instead of just correlations, owing to the
atomicity properties of shapelets. Experimental results on both synthetic and
real-world datasets demonstrate that ShapeX outperforms existing methods in
identifying the most relevant subsequences, enhancing both the precision and
causal fidelity of time series explanations.

</details>


### [26] [Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa](https://arxiv.org/abs/2510.20085)
*Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou*

Main category: cs.LG

TL;DR: 提出基于MentalRoBERTa的层次化双头神经网络，用于社交媒体自杀风险四等级分类，结合序数关系和分类预测，解决类别不平衡和时序依赖问题。


<details>
  <summary>Details</summary>
Motivation: 社交媒体已成为识别自杀风险的重要来源，但自动化检测系统面临类别严重不平衡、发帖模式时序复杂性以及风险等级兼具序数和分类性质的多重挑战。

Method: 使用MentalRoBERTa作为基础模型，构建双头预测架构：CORAL头保持风险等级间的序数关系，标准分类头实现灵活分类。采用3层Transformer编码器建模时序依赖，显式时间间隔嵌入捕捉发帖动态。训练时冻结前6层，使用混合精度训练提高效率。

Result: 通过5折分层交叉验证进行评估，以宏F1分数为主要指标。

Conclusion: 该模型通过结合序数关系保持和分类灵活性，以及处理类别不平衡的损失函数设计，为社交媒体自杀风险检测提供了有效的解决方案。

Abstract: Social media platforms have become important sources for identifying suicide
risk, but automated detection systems face multiple challenges including severe
class imbalance, temporal complexity in posting patterns, and the dual nature
of risk levels as both ordinal and categorical. This paper proposes a
hierarchical dual-head neural network based on MentalRoBERTa for suicide risk
classification into four levels: indicator, ideation, behavior, and attempt.
The model employs two complementary prediction heads operating on a shared
sequence representation: a CORAL (Consistent Rank Logits) head that preserves
ordinal relationships between risk levels, and a standard classification head
that enables flexible categorical distinctions. A 3-layer Transformer encoder
with 8-head multi-head attention models temporal dependencies across post
sequences, while explicit time interval embeddings capture posting behavior
dynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3
Cross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure
preservation, overconfidence reduction, and class imbalance. To improve
computational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa
and employ mixed-precision training. The model is evaluated using 5-fold
stratified cross-validation with macro F1 score as the primary metric.

</details>


### [27] [Competition is the key: A Game Theoretic Causal Discovery Approach](https://arxiv.org/abs/2510.20106)
*Amartya Roy,Souvik Chakraborty*

Main category: cs.LG

TL;DR: 提出基于博弈论强化学习的因果发现框架，通过DDQN智能体与强基线算法竞争，获得有限样本保证的同时保持可扩展性


<details>
  <summary>Details</summary>
Motivation: 解决因果发现中经验性能强的算法缺乏有限样本保证，而有理论保证的方法难以扩展的问题

Method: 使用DDQN强化学习智能体与GES或GraN-DAG基线算法竞争，始终从对手解开始热启动学习

Result: 在合成数据集上误差概率随样本量衰减，与理论匹配；在真实数据集上持续改进基线算法，可扩展到220节点的大图

Conclusion: 建立了同时具备理论一致性、样本效率和实际可扩展性的RL因果发现算法新类别

Abstract: Causal discovery remains a central challenge in machine learning, yet
existing methods face a fundamental gap: algorithms like GES and GraN-DAG
achieve strong empirical performance but lack finite-sample guarantees, while
theoretically principled approaches fail to scale. We close this gap by
introducing a game-theoretic reinforcement learning framework for causal
discovery, where a DDQN agent directly competes against a strong baseline (GES
or GraN-DAG), always warm-starting from the opponent's solution. This design
yields three provable guarantees: the learned graph is never worse than the
opponent, warm-starting strictly accelerates convergence, and most importantly,
with high probability the algorithm selects the true best candidate graph. To
the best of our knowledge, our result makes a first-of-its-kind progress in
explaining such finite-sample guarantees in causal discovery: on synthetic SEMs
(30 nodes), the observed error probability decays with n, tightly matching
theory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,
Dream, and Andes, our method consistently improves upon GES and GraN-DAG while
remaining theoretically safe. Remarkably, it scales to large graphs such as
Hepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these
results establish a new class of RL-based causal discovery algorithms that are
simultaneously provably consistent, sample-efficient, and practically scalable,
marking a decisive step toward unifying empirical performance with rigorous
finite-sample theory.

</details>


### [28] [On pattern classification with weighted dimensions](https://arxiv.org/abs/2510.20107)
*Ayatullah Faruk Mollah*

Main category: cs.LG

TL;DR: 本文提出了一种新的维度加权方案，并将其整合到KNN分类器中，通过加权Minkowski距离改进了传统KNN在模式分类中的性能。


<details>
  <summary>Details</summary>
Motivation: 在多维样本的模式分类中，基于权重的维度距离度量对于反映样本间相似度至关重要。虽然欧氏距离被广泛使用，但仍存在诸多问题，需要更有效的距离度量和维度加权方法。

Method: 提出了新颖的维度加权方案，将其整合到KNN分类器中，使用加权Minkowski距离来调节包含k个参考样本区域的大小和形状。

Result: 在合成和真实数据集上的实验表明，该方法比传统KNN表现更好。特别是在基因表达数据集上，在不同k值的交叉验证实验中分类准确率显著提升约10%。

Conclusion: 该方法通过加权Minkowski距离和新的加权方案，实现了KNN分类器的重要泛化，特别适用于样本数量有限但维度高的数据集。

Abstract: Studies on various facets of pattern classification is often imperative while
working with multi-dimensional samples pertaining to diverse application
scenarios. In this notion, weighted dimension-based distance measure has been
one of the vital considerations in pattern analysis as it reflects the degree
of similarity between samples. Though it is often presumed to be settled with
the pervasive use of Euclidean distance, plethora of issues often surface. In
this paper, we present (a) a detail analysis on the impact of distance measure
norms and weights of dimensions along with visualization, (b) a novel weighting
scheme for each dimension, (c) incorporation of this dimensional weighting
schema into a KNN classifier, and (d) pattern classification on a variety of
synthetic as well as realistic datasets with the developed model. It has
performed well across diverse experiments in comparison to the traditional KNN
under the same experimental setups. Specifically, for gene expression datasets,
it yields significant and consistent gain in classification accuracy (around
10%) in all cross-validation experiments with different values of k. As such
datasets contain limited number of samples of high dimensions, meaningful
selection of nearest neighbours is desirable, and this requirement is
reasonably met by regulating the shape and size of the region enclosing the k
number of reference samples with the developed weighting schema and appropriate
norm. It, therefore, stands as an important generalization of KNN classifier
powered by weighted Minkowski distance with the present weighting schema.

</details>


### [29] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 提出一种完全解耦的训练策略来解决原型自监督学习中的原型崩溃问题，通过分离原型和编码器的优化目标来消除原型崩溃。


<details>
  <summary>Details</summary>
Motivation: 原型自监督学习方法普遍存在部分原型崩溃问题，多个原型收敛到几乎相同的表示，这削弱了提供多样化和信息丰富目标的核心目的。现有方法通过过度参数化原型集或添加临时正则化器来缓解症状而非解决根本原因。

Method: 引入完全解耦的训练策略，将原型和编码器在不同目标下学习。具体将原型建模为高斯混合模型，使用在线EM风格过程独立于编码器损失进行更新。

Result: 这种简单而原则性的解耦消除了原型崩溃，无需显式正则化，产生一致多样化的原型和更强的下游性能。

Conclusion: 通过打破原型和编码器的联合优化，解决了原型崩溃的根本原因，提供了一种更有效的原型自监督学习方法。

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [30] [There is No "apple" in Timeseries: Rethinking TSFM through the Lens of Invariance](https://arxiv.org/abs/2510.20119)
*Arian Prabowo,Flora D. Salim*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFMs）表现不佳，因为简单套用NLP或CV的方法不适用。时间序列数据缺乏像图像和文本那样的概念密度，需要基于不变性原则构建数据集来覆盖表示空间。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列基础模型的表现与轻量级监督基线甚至经典模型相当，这源于对NLP或CV管线的简单移植。时间序列数据缺乏概念密度，无法通过大规模网络抓取获得有效训练数据。

Method: 建议从机会性聚合转向原则性设计：构建能够系统覆盖保持时间语义不变性的数据集。基于第一原则构建时间序列不变性本体论。

Result: 通过不变性覆盖确保表示完整性，才能使TSFMs获得对齐结构，实现泛化、推理和真正的新兴行为。

Conclusion: 时间序列基础模型的进步需要范式转变，从简单套用其他领域方法转向基于不变性原则的系统数据集构建。

Abstract: Timeseries foundation models (TSFMs) have multiplied, yet lightweight
supervised baselines and even classical models often match them. We argue this
gap stems from the naive importation of NLP or CV pipelines. In language and
vision, large web-scale corpora densely capture human concepts i.e. there are
countless images and text of apples. In contrast, timeseries data is built to
complement the image and text modalities. There are no timeseries dataset that
contains the concept apple. As a result, the scrape-everything-online paradigm
fails for TS. We posit that progress demands a shift from opportunistic
aggregation to principled design: constructing datasets that systematically
span the space of invariance that preserve temporal semantics. To this end, we
suggest that the ontology of timeseries invariances should be built based on
first principles. Only by ensuring representational completeness through
invariance coverage can TSFMs achieve the aligned structure necessary for
generalisation, reasoning, and truly emergent behaviour.

</details>


### [31] [Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling](https://arxiv.org/abs/2510.20148)
*Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu*

Main category: cs.LG

TL;DR: 该研究通过多层图扩散模型发现，阿尔茨海默病中tau蛋白的传播受到结构连接和功能连接的不对称影响，FC主导皮层下、岛叶和颞叶区域，SC主导枕叶、顶叶和边缘区域，且这种主导地位随疾病进展而变化。


<details>
  <summary>Details</summary>
Motivation: 神经影像学证据显示病理性tau蛋白沿着特定脑网络积累，表明大规模网络架构在阿尔茨海默病进展中起关键作用，但结构连接和功能连接如何相互作用影响tau传播尚不清楚。

Method: 利用大量纵向神经影像数据，通过多层图扩散模型研究SC-FC相互作用。

Result: 发现SC和FC对tau传播的区域性不对称贡献，FC主导早期AD，SC主导晚期AD，且SC/FC主导区域与AD相关基因表达模式高度一致。

Conclusion: 结构连接和功能连接在阿尔茨海默病tau传播中发挥互补但不对称的作用，其相对主导地位随疾病阶段变化，并与遗传风险因素和生物学机制相互作用。

Abstract: Emerging neuroimaging evidence shows that pathological tau proteins build up
along specific brain networks, suggesting that large-scale network architecture
plays a key role in the progression of Alzheimer's disease (AD). However, how
structural connectivity (SC) and functional connectivity (FC) interact to
influence tau propagation remains unclear. Leveraging an unprecedented volume
of longitudinal neuroimaging data, we examine SC-FC interactions through a
multi-layer graph diffusion model. Beyond showing that connectome architecture
constrains tau spread, our model reveals a regionally asymmetric contribution
of SC and FC. Specifically, FC predominantly drives tau spread in subcortical
areas, the insula, frontal and temporal cortices, whereas SC plays a larger
role in occipital, parietal, and limbic regions. The relative dominance of SC
versus FC shifts over the course of disease, with FC generally prevailing in
early AD and SC becoming primary in later stages. Spatial patterns of SC- and
FC-dominant regions strongly align with the regional expression of
AD-associated genes involved in inflammation, apoptosis, and lysosomal
function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In
parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and
biological mechanisms (e.g., amyloid deposition) selectively reshape tau
propagation by shifting dominant routes between anatomical and functional
pathways in a region-specific manner. Findings are validated in an independent
AD cohort.

</details>


### [32] [ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push](https://arxiv.org/abs/2510.20157)
*Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu*

Main category: cs.LG

TL;DR: 提出ADP-VRSGP方法，通过自适应调整噪声方差和学习率，结合渐进梯度融合策略，在保护隐私的同时提升去中心化学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有使用固定方差噪声的差分隐私方法会降低模型性能和训练效率，需要一种能动态调整隐私保护强度的自适应方法。

Method: 使用步进衰减调度动态调整噪声方差和学习率，引入渐进梯度融合策略利用历史梯度，结合去中心化push-sum和聚合技术。

Result: 理论分析表明该方法具有鲁棒收敛性，实验验证在多种场景下优于现有基线方法。

Conclusion: ADP-VRSGP能有效解决隐私保护去中心化学习的挑战，在保证隐私的同时显著提升训练稳定性和速度。

Abstract: Differential privacy is widely employed in decentralized learning to
safeguard sensitive data by introducing noise into model updates. However,
existing approaches that use fixed-variance noise often degrade model
performance and reduce training efficiency. To address these limitations, we
propose a novel approach called decentralized learning with adaptive
differential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).
This method dynamically adjusts both the noise variance and the learning rate
using a stepwise-decaying schedule, which accelerates training and enhances
final model performance while providing node-level personalized privacy
guarantees. To counteract the slowed convergence caused by large-variance noise
in early iterations, we introduce a progressive gradient fusion strategy that
leverages historical gradients. Furthermore, ADP-VRSGP incorporates
decentralized push-sum and aggregation techniques, making it particularly
suitable for time-varying communication topologies. Through rigorous
theoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence
with an appropriate learning rate, significantly improving training stability
and speed. Experimental results validate that our method outperforms existing
baselines across multiple scenarios, highlighting its efficacy in addressing
the challenges of privacy-preserving decentralized learning.

</details>


### [33] [Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP](https://arxiv.org/abs/2510.20169)
*Tongkai Lu,Shuai Ma,Chongyang Tao*

Main category: cs.LG

TL;DR: 提出Hyper Tour Guided Neighborhood Search (HyperNS)方法解决大规模TSP问题，通过聚类和超路径引导来缩小搜索空间，提高求解效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有神经方法在大规模TSP实例中面临内存限制、初始解质量不高和全局引导不足等挑战，需要更有效的解决方案。

Method: 采用"先聚类后路由"策略，使用稀疏热图图将TSP实例划分为簇并抽象为超节点，生成超路径来指导初始化和优化过程。

Result: 在合成和真实数据集上的实验表明，该方法优于现有神经方法，特别是在处理大规模实例时显著缩小了与最优解的差距。

Conclusion: HyperNS方法通过超路径引导的邻域搜索有效解决了大规模TSP问题，在求解质量和效率方面都有显著提升。

Abstract: Traveling Salesman Problem (TSP) is a classic NP-hard problem that has
garnered significant attention from both academia and industry. While
neural-based methods have shown promise for solving TSPs, they still face
challenges in scaling to larger instances, particularly in memory constraints
associated with global heatmaps, edge weights, or access matrices, as well as
in generating high-quality initial solutions and insufficient global guidance
for efficiently navigating vast search spaces. To address these challenges, we
propose a Hyper Tour Guided Neighborhood Search (HyperNS) method for
large-scale TSP instances. Inspired by the ``clustering first, route second"
strategy, our approach initially divides the TSP instance into clusters using a
sparse heatmap graph and abstracts them as supernodes, followed by the
generation of a hyper tour to guide both the initialization and optimization
processes. This method reduces the search space by focusing on edges relevant
to the hyper tour, leading to more efficient and effective optimization.
Experimental results on both synthetic and real-world datasets demonstrate that
our approach outperforms existing neural-based methods, particularly in
handling larger-scale instances, offering a significant reduction in the gap to
the optimal solution.

</details>


### [34] [Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values](https://arxiv.org/abs/2510.20187)
*Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: RLEV是一种将人类价值观直接融入LLM强化学习的方法，通过量化的人类价值信号优化模型，在价值加权准确性和终止策略方面优于仅基于正确性的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法虽然能有效训练模型，但忽略了不同任务的重要性差异，无法体现人类价值观的优先级。

Method: 在奖励函数中直接整合人类定义的价值信号，使用带有明确价值标签的考试数据，通过价值加权梯度放大机制训练模型。

Result: RLEV在多种RL算法和模型规模下均优于仅基于正确性的基线，能学习价值敏感的终止策略，且在噪声价值信号下仍保持稳健。

Conclusion: 优化明确的效用函数为LLM与人类优先级对齐提供了实用路径，价值对齐对性能提升具有因果性影响。

Abstract: We propose Reinforcement Learning with Explicit Human Values (RLEV), a method
that aligns Large Language Model (LLM) optimization directly with quantifiable
human value signals. While Reinforcement Learning with Verifiable Rewards
(RLVR) effectively trains models in objective domains using binary correctness
rewards, it overlooks that not all tasks are equally significant. RLEV extends
this framework by incorporating human-defined value signals directly into the
reward function. Using exam-style data with explicit ground-truth value labels,
RLEV consistently outperforms correctness-only baselines across multiple RL
algorithms and model scales. Crucially, RLEV policies not only improve
value-weighted accuracy but also learn a value-sensitive termination policy:
concise for low-value prompts, thorough for high-value ones. We demonstrate
this behavior stems from value-weighted gradient amplification on
end-of-sequence tokens. Ablation studies confirm the gain is causally linked to
value alignment. RLEV remains robust under noisy value signals, such as
difficulty-based labels, demonstrating that optimizing for an explicit utility
function offers a practical path to aligning LLMs with human priorities.

</details>


### [35] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 提出了一个风险感知的约束强化学习框架，使用优化确定性等价来处理奖励分布的尾部风险，确保在时间维度上的联合鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习只关注期望累积奖励，忽略了奖励分布尾部的风险事件，这在高风险应用中是不够的。

Method: 基于优化确定性等价构建风险感知框架，在参数化强拉格朗日对偶框架下确保与原始约束问题的等价性，可包装标准RL求解器如PPO。

Result: 在常见假设下证明了算法收敛性，并通过数值实验验证了方法的风险感知特性。

Conclusion: 该框架为高风险应用提供了有效的风险感知约束强化学习解决方案，具有理论和实践价值。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [36] [Approximate Replicability in Learning](https://arxiv.org/abs/2510.20200)
*Max Hopkins,Russell Impagliazzo,Christopher Ye*

Main category: cs.LG

TL;DR: 本文提出了三种可复制性的松弛版本：点态可复制性、近似可复制性和半可复制性，用于解决完全可复制性在PAC学习中的强不可能性问题。


<details>
  <summary>Details</summary>
Motivation: 由于完全可复制性在许多学习任务中成本过高甚至不可能实现，需要探索可复制性的近似版本，使学习在保持一定稳定性的同时仍然可行。

Method: 提出了三种可复制性松弛：(1)点态可复制性：在固定输入上一致；(2)近似可复制性：在大部分分布上一致；(3)半可复制性：完全可复制但可使用共享无标签样本。

Result: 对于常数可复制性参数，获得了样本最优的不可知PAC学习器：前两种方法使用Θ(d/α²)样本即可实现，第三种需要Θ(d²/α²)标记样本。

Conclusion: 通过适当放松可复制性要求，可以在保持学习可行性的同时获得良好的稳定性保证，为实际应用提供了可行的解决方案。

Abstract: Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion
that algorithms should remain stable under a resampling of their inputs (given
access to shared randomness). While a strong and interesting notion of
stability, the cost of replicability can be prohibitive: there is no replicable
algorithm, for instance, for tasks as simple as threshold learning (Bun et al.
STOC '23). Given such strong impossibility results we ask: under what
approximate notions of replicability is learning possible?
  In this work, we propose three natural relaxations of replicability in the
context of PAC learning: (1) Pointwise: the learner must be consistent on any
fixed input, but not across all inputs simultaneously, (2) Approximate: the
learner must output hypotheses that classify most of the distribution
consistently, (3) Semi: the algorithm is fully replicable, but may additionally
use shared unlabeled samples. In all three cases, for constant replicability
parameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are
achievable for ``free" using $\Theta(d/\alpha^2)$ samples, while (3) requires
$\Theta(d^2/\alpha^2)$ labeled samples.

</details>


### [37] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 该研究评估了使用金毛猎犬寿命研究队列的常规实验室数据进行癌症风险分类的可行性，发现虽然存在统计学可检测的癌症信号，但由于信号太弱且与正常衰老或其他炎症状况混淆，无法实现可靠的临床分类。


<details>
  <summary>Details</summary>
Motivation: 开发用于犬类早期癌症检测的无创筛查工具面临挑战，常规实验室数据虽然成本低但受限于生物标志物的非特异性和严重的类别不平衡问题。

Method: 使用金毛猎犬寿命研究队列数据，系统比较了126个分析流程，包括多种机器学习模型、特征选择方法和数据平衡技术，采用患者级数据分区防止数据泄露。

Result: 最佳模型（带类别加权的逻辑回归分类器和递归特征消除）显示出中等排序能力（AUROC = 0.815）但临床分类性能差（F1-score = 0.25，阳性预测值 = 0.15），阴性预测值高（0.98）但召回率不足（0.79）。

Conclusion: 常规实验室数据中存在的癌症信号太弱且容易混淆，无法实现可靠的临床区分，计算兽医肿瘤学的有意义的进展需要整合多模态数据源。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [38] [CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks](https://arxiv.org/abs/2510.20219)
*Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu*

Main category: cs.LG

TL;DR: 提出CO-PFL算法，通过动态评估客户端贡献来解决个性化联邦学习中的数据异质性问题，采用双子空间分析和参数级个性化机制，显著提升个性化性能和收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在数据异质性场景下表现不佳，其基于数据量的启发式聚合方法无法准确评估客户端更新的实际效用和可靠性，导致次优个性化和聚合偏差。

Method: CO-PFL算法通过分析梯度方向差异和预测偏差来动态评估客户端贡献，结合梯度子空间和数据子空间信息，并集成参数级个性化机制与掩码感知动量优化。

Result: 在CIFAR10、CIFAR10C、CINIC10和Mini-ImageNet四个基准数据集上的实验表明，CO-PFL在个性化精度、鲁棒性、可扩展性和收敛稳定性方面均优于现有最先进方法。

Conclusion: CO-PFL通过贡献导向的聚合策略有效缓解了聚合偏差，增强了全局协调能力，并通过构建定制化子模型和稳定更新显著提升了本地性能。

Abstract: Personalized federated learning (PFL) addresses a critical challenge of
collaboratively training customized models for clients with heterogeneous and
scarce local data. Conventional federated learning, which relies on a single
consensus model, proves inadequate under such data heterogeneity. Its standard
aggregation method of weighting client updates heuristically or by data volume,
operates under an equal-contribution assumption, failing to account for the
actual utility and reliability of each client's update. This often results in
suboptimal personalization and aggregation bias. To overcome these limitations,
we introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that
dynamically estimates each client's contribution for global aggregation. CO-PFL
performs a joint assessment by analyzing both gradient direction discrepancies
and prediction deviations, leveraging information from gradient and data
subspaces. This dual-subspace analysis provides a principled and discriminative
aggregation weight for each client, emphasizing high-quality updates.
Furthermore, to bolster personalization adaptability and optimization
stability, CO-PFL cohesively integrates a parameter-wise personalization
mechanism with mask-aware momentum optimization. Our approach effectively
mitigates aggregation bias, strengthens global coordination, and enhances local
performance by facilitating the construction of tailored submodels with stable
updates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,
CINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses
state-of-the-art methods in in personalization accuracy, robustness,
scalability and convergence stability.

</details>


### [39] [Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints](https://arxiv.org/abs/2510.20220)
*Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca*

Main category: cs.LG

TL;DR: 本文提出了Fair-SMW算法，通过拉格朗日方法和Sherman-Morrison-Woodbury恒等式重新构建约束优化问题，提高了谱聚类算法的效率，在保持公平性的同时显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有谱聚类算法在融入群体公平性约束时计算效率较低，需要改进计算时间。

Method: 使用拉格朗日方法和SMW恒等式重新构建约束优化问题，开发了Fair-SMW算法，采用三种不同的拉普拉斯矩阵变体生成多个Fair-SMW变种。

Result: 在LastFM、FacebookNet、Deezer和German等真实网络数据集上测试，计算时间比现有最优算法快两倍，同时能够实现两倍的平衡度。

Conclusion: Fair-SMW算法在保持公平聚类质量的同时显著提高了计算效率，为公平谱聚类提供了高效的解决方案。

Abstract: Recent research has focused on mitigating algorithmic bias in clustering by
incorporating fairness constraints into algorithmic design. Notions such as
disparate impact, community cohesion, and cost per population have been
implemented to enforce equitable outcomes. Among these, group fairness
(balance) ensures that each protected group is proportionally represented
within every cluster. However, incorporating balance as a metric of fairness
into spectral clustering algorithms has led to computational times that can be
improved. This study aims to enhance the efficiency of spectral clustering
algorithms by reformulating the constrained optimization problem using a new
formulation derived from the Lagrangian method and the
Sherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm.
Fair-SMW employs three alternatives to the Laplacian matrix with different
spectral gaps to generate multiple variations of Fair-SMW, achieving clustering
solutions with comparable balance to existing algorithms while offering
improved runtime performance. We present the results of Fair-SMW, evaluated
using the Stochastic Block Model (SBM) to measure both runtime efficiency and
balance across real-world network datasets, including LastFM, FacebookNet,
Deezer, and German. We achieve an improvement in computation time that is twice
as fast as the state-of-the-art, and also flexible enough to achieve twice as
much balance.

</details>


### [40] [QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models](https://arxiv.org/abs/2510.20222)
*Hao Wang,Baojun Ma*

Main category: cs.LG

TL;DR: 提出QKCV注意力机制，在传统QKV框架中引入静态类别嵌入C来增强类别特定信息，提升时间序列预测精度，并支持高效微调预训练模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测任务中，类别信息对于捕捉数据内在模式至关重要，但传统注意力机制未能充分利用此类信息。

Method: 扩展传统QKV注意力框架为QKCV，加入静态类别嵌入C，作为即插即用模块增强各类注意力模型，支持仅更新类别嵌入的轻量微调。

Result: 在多个真实数据集上显著提升了Vanilla Transformer、Informer、PatchTST、TFT等模型的预测精度，并在微调预训练模型时减少计算开销。

Conclusion: QKCV注意力机制通过有效整合类别信息，不仅提升了时间序列预测性能，还提供了高效的模型微调方案。

Abstract: In real-world time series forecasting tasks, category information plays a
pivotal role in capturing inherent data patterns. This paper introduces QKCV
(Query-Key-Category-Value) attention, an extension of the traditional QKV
framework that incorporates a static categorical embedding C to emphasize
category-specific information. As a versatile plug-in module, QKCV enhances the
forecasting accuracy of attention-based models (e.g., Vanilla Transformer,
Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV
demonstrates remarkable adaptability in fine-tuning univariate time series
foundation model by solely updating the static embedding C while preserving
pretrained weights, thereby reducing computational overhead and achieving
superior fine-tuning performance.

</details>


### [41] [Federated Learning via Meta-Variational Dropout](https://arxiv.org/abs/2510.20225)
*Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim*

Main category: cs.LG

TL;DR: 提出MetaVD方法，通过元学习预测客户端相关的dropout率，解决联邦学习中非IID数据导致的模型过拟合和发散问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习面临模型过拟合和本地模型发散的问题，特别是在有限和非IID数据环境下。

Method: 使用元变分dropout方法，通过共享超网络学习客户端相关的dropout率，实现模型个性化。

Result: 在稀疏和非IID联邦学习数据集上，MetaVD表现出优秀的分类准确性和不确定性校准性能，特别是对分布外客户端。

Conclusion: MetaVD能有效压缩本地模型参数，缓解模型过拟合，降低通信成本，提升联邦学习在非IID数据环境下的性能。

Abstract: Federated Learning (FL) aims to train a global inference model from remotely
distributed clients, gaining popularity due to its benefit of improving data
privacy. However, traditional FL often faces challenges in practical
applications, including model overfitting and divergent local models due to
limited and non-IID data among clients. To address these issues, we introduce a
novel Bayesian meta-learning approach called meta-variational dropout (MetaVD).
MetaVD learns to predict client-dependent dropout rates via a shared
hypernetwork, enabling effective model personalization of FL algorithms in
limited non-IID data settings. We also emphasize the posterior adaptation view
of meta-learning and the posterior aggregation view of Bayesian FL via the
conditional dropout posterior. We conducted extensive experiments on various
sparse and non-IID FL datasets. MetaVD demonstrated excellent classification
accuracy and uncertainty calibration performance, especially for
out-of-distribution (OOD) clients. MetaVD compresses the local model parameters
needed for each client, mitigating model overfitting and reducing communication
costs. Code is available at https://github.com/insujeon/MetaVD.

</details>


### [42] [Sparse Local Implicit Image Function for sub-km Weather Downscaling](https://arxiv.org/abs/2510.20228)
*Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho*

Main category: cs.LG

TL;DR: SpLIIF通过隐式神经表示实现天气变量的任意降尺度，在日本的稀疏气象站和地形数据上训练，在温度和风速预测上比CorrDiff和插值基线表现更好。


<details>
  <summary>Details</summary>
Motivation: 开发能够从稀疏气象站数据生成高分辨率天气场的模型，实现任意降尺度的天气变量预测。

Method: 使用隐式神经表示(SpLIIF)方法，结合稀疏气象站观测数据和地形信息进行训练。

Result: 在温度降尺度上比CorrDiff和基线方法提升50%，在风速预测上提升10-20%。

Conclusion: SpLIIF方法在天气变量降尺度任务中显著优于现有方法，特别是在温度预测方面表现突出。

Abstract: We introduce SpLIIF to generate implicit neural representations and enable
arbitrary downscaling of weather variables. We train a model from sparse
weather stations and topography over Japan and evaluate in- and
out-of-distribution accuracy predicting temperature and wind, comparing it to
both an interpolation baseline and CorrDiff. We find the model to be up to 50%
better than both CorrDiff and the baseline at downscaling temperature, and
around 10-20% better for wind.

</details>


### [43] [Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach](https://arxiv.org/abs/2510.20235)
*Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung*

Main category: cs.LG

TL;DR: 提出了一种可证明收敛的多目标强化学习框架，采用最大最小准则，通过博弈论视角将其重新表述为两人零和正则化连续博弈，并基于镜像下降设计高效算法。


<details>
  <summary>Details</summary>
Motivation: 解决多目标强化学习中最大最小准则的收敛性问题，提供理论保证的同时保持实用性。

Method: 将多目标强化学习重新表述为两人零和正则化连续博弈，使用镜像下降算法进行优化，并引入自适应正则化来提升性能。

Result: 在表格设置中验证了算法的收敛行为，在深度强化学习实现中显著优于先前基线方法。

Conclusion: 提出的框架在理论和实验上都表现出色，为多目标强化学习提供了可证明收敛且实用的解决方案。

Abstract: In this paper, we propose a provably convergent and practical framework for
multi-objective reinforcement learning with max-min criterion. From a
game-theoretic perspective, we reformulate max-min multi-objective
reinforcement learning as a two-player zero-sum regularized continuous game and
introduce an efficient algorithm based on mirror descent. Our approach
simplifies the policy update while ensuring global last-iterate convergence. We
provide a comprehensive theoretical analysis on our algorithm, including
iteration complexity under both exact and approximate policy evaluations, as
well as sample complexity bounds. To further enhance performance, we modify the
proposed algorithm with adaptive regularization. Our experiments demonstrate
the convergence behavior of the proposed algorithm in tabular settings, and our
implementation for deep reinforcement learning significantly outperforms
previous baselines in many MORL environments.

</details>


### [44] [Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction](https://arxiv.org/abs/2510.20236)
*Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers*

Main category: cs.LG

TL;DR: 提出了一种名为LKM的新型自知识蒸馏方法，可在不显著增加计算成本的情况下提高图神经网络在分子属性预测中的准确性。


<details>
  <summary>Details</summary>
Motivation: 图神经网络是目前预测分子属性的最有效方法，但需要更高精度的模型。增加模型复杂度会提高计算成本和内存需求，因此需要一种既能提高准确性又不显著增加成本的方法。

Method: 开发了层到层知识混合（LKM）方法，通过最小化GNN层间预存在隐藏嵌入的平均绝对距离，有效聚合多跳和多尺度信息，改善局部和全局分子特征的表示。

Result: 在三种不同GNN架构（DimeNet++、MXMNet、PAMNet）和量子化学属性数据集（QM9、MD17和Chignolin）上的评估显示，LKM方法将量子化学和生物物理属性预测的平均绝对误差分别降低了9.8%、45.3%和22.9%。

Conclusion: LKM方法有潜力在不显著增加训练和推理成本的情况下，显著提高GNN在化学属性预测中的准确性。

Abstract: Graph Neural Networks (GNNs) are the currently most effective methods for
predicting molecular properties but there remains a need for more accurate
models. GNN accuracy can be improved by increasing the model complexity but
this also increases the computational cost and memory requirement during
training and inference. In this study, we develop Layer-to-Layer Knowledge
Mixing (LKM), a novel self-knowledge distillation method that increases the
accuracy of state-of-the-art GNNs while adding negligible computational
complexity during training and inference. By minimizing the mean absolute
distance between pre-existing hidden embeddings of GNN layers, LKM efficiently
aggregates multi-hop and multi-scale information, enabling improved
representation of both local and global molecular features. We evaluated LKM
using three diverse GNN architectures (DimeNet++, MXMNet, and PAMNet) using
datasets of quantum chemical properties (QM9, MD17 and Chignolin). We found
that the LKM method effectively reduces the mean absolute error of quantum
chemical and biophysical property predictions by up to 9.8% (QM9), 45.3% (MD17
Energy), and 22.9% (Chignolin). This work demonstrates the potential of LKM to
significantly improve the accuracy of GNNs for chemical property prediction
without any substantial increase in training and inference cost.

</details>


### [45] [What Does It Take to Build a Performant Selective Classifier?](https://arxiv.org/abs/2510.20242)
*Stephan Rabanser,Nicolas Papernot*

Main category: cs.LG

TL;DR: 该论文提出了选择性分类差距的概念，将模型性能与完美排序预言机之间的差距分解为五个来源：贝叶斯噪声、近似误差、排序误差、统计噪声和实现/偏移导致的松弛。研究发现单调后校准对缩小这一差距效果有限，需要能够重新排序预测的评分机制。


<details>
  <summary>Details</summary>
Motivation: 选择性分类器通过拒绝模型认为不确定的输入来提高可靠性，但很少有方法能达到完美排序预言机的性能。本文旨在形式化这种性能差距并分析其来源。

Method: 提出了选择性分类差距的有限样本分解，将其分解为五个误差源。在合成数据和真实世界视觉、语言基准上进行验证，通过控制实验分离每个误差分量。

Result: 验证表明：(i)贝叶斯噪声和有限模型容量会导致显著差距；(ii)只有更丰富的特征感知校准器能显著改善分数排序；(iii)数据偏移引入了需要分布鲁棒训练的松弛项。

Conclusion: 该分解为选择性分类器提供了可量化的误差预算和实用的设计指南，帮助构建更接近理想预言机行为的分类器。

Abstract: Selective classifiers improve model reliability by abstaining on inputs the
model deems uncertain. However, few practical approaches achieve the
gold-standard performance of a perfect-ordering oracle that accepts examples
exactly in order of correctness. Our work formalizes this shortfall as the
selective-classification gap and present the first finite-sample decomposition
of this gap to five distinct sources of looseness: Bayes noise, approximation
error, ranking error, statistical noise, and implementation- or shift-induced
slack. Crucially, our analysis reveals that monotone post-hoc calibration --
often believed to strengthen selective classifiers -- has limited impact on
closing this gap, since it rarely alters the model's underlying score ranking.
Bridging the gap therefore requires scoring mechanisms that can effectively
reorder predictions rather than merely rescale them. We validate our
decomposition on synthetic two-moons data and on real-world vision and language
benchmarks, isolating each error component through controlled experiments. Our
results confirm that (i) Bayes noise and limited model capacity can account for
substantial gaps, (ii) only richer, feature-aware calibrators meaningfully
improve score ordering, and (iii) data shift introduces a separate slack that
demands distributionally robust training. Together, our decomposition yields a
quantitative error budget as well as actionable design guidelines that
practitioners can use to build selective classifiers which approximate ideal
oracle behavior more closely.

</details>


### [46] [FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning](https://arxiv.org/abs/2510.20250)
*Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan*

Main category: cs.LG

TL;DR: FedGPS是一个新的联邦学习框架，通过整合统计分布和梯度信息来解决数据异构性问题，在各种异构场景下表现出优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在数据异构性场景下性能有限且鲁棒性不足，研究发现共享统计信息可以帮助客户端从全局视角更新模型。

Method: FedGPS静态地修改每个客户端的学习目标，使用代理信息隐式建模全局数据分布；同时动态地在每轮调整本地更新方向，整合来自其他客户端的梯度信息。

Result: 大量实验表明FedGPS在多种异构场景下优于现有最先进方法，验证了其有效性和鲁棒性。

Conclusion: FedGPS通过统计分布和梯度信息的协同整合，有效缓解了联邦学习中的数据异构性问题，在各种场景下都表现出强大的性能。

Abstract: Federated Learning (FL) confronts a significant challenge known as data
heterogeneity, which impairs model performance and convergence. Existing
methods have made notable progress in addressing this issue. However, improving
performance in certain heterogeneity scenarios remains an overlooked question:
\textit{How robust are these methods to deploy under diverse heterogeneity
scenarios?} To answer this, we conduct comprehensive evaluations across varied
heterogeneity scenarios, showing that most existing methods exhibit limited
robustness. Meanwhile, insights from these experiments highlight that sharing
statistical information can mitigate heterogeneity by enabling clients to
update with a global perspective. Motivated by this, we propose \textbf{FedGPS}
(\textbf{Fed}erated \textbf{G}oal-\textbf{P}ath \textbf{S}ynergy), a novel
framework that seamlessly integrates statistical distribution and gradient
information from others. Specifically, FedGPS statically modifies each client's
learning objective to implicitly model the global data distribution using
surrogate information, while dynamically adjusting local update directions with
gradient information from other clients at each round. Extensive experiments
show that FedGPS outperforms state-of-the-art methods across diverse
heterogeneity scenarios, validating its effectiveness and robustness. The code
is available at: https://github.com/CUHK-AIM-Group/FedGPS.

</details>


### [47] [Optimistic Task Inference for Behavior Foundation Models](https://arxiv.org/abs/2510.20264)
*Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause*

Main category: cs.LG

TL;DR: OpTI-BFM是一种乐观决策标准，通过直接建模奖励函数的不确定性来指导行为基础模型进行任务推断，在少量回合内识别和优化未见过的奖励函数。


<details>
  <summary>Details</summary>
Motivation: 传统行为基础模型需要计算推理数据集上的奖励，这要么需要奖励函数的形式化访问，要么需要大量标注工作。本文旨在通过与环境交互来缓解这些限制。

Method: 提出OpTI-BFM乐观决策标准，直接建模奖励函数的不确定性，并利用与线性bandit上置信度算法的直接连接来指导数据收集。

Result: 在已建立的零样本基准测试中，OpTI-BFM使基于后继特征的行为基础模型能够在少量回合内识别和优化未见过的奖励函数，计算开销最小。

Conclusion: OpTI-BFM为行为基础模型提供了高效的任务推断方法，通过乐观决策标准在数据收集和计算效率方面取得了显著改进。

Abstract: Behavior Foundation Models (BFMs) are capable of retrieving high-performing
policy for any reward function specified directly at test-time, commonly
referred to as zero-shot reinforcement learning (RL). While this is a very
efficient process in terms of compute, it can be less so in terms of data: as a
standard assumption, BFMs require computing rewards over a non-negligible
inference dataset, assuming either access to a functional form of rewards, or
significant labeling efforts. To alleviate these limitations, we tackle the
problem of task inference purely through interaction with the environment at
test-time. We propose OpTI-BFM, an optimistic decision criterion that directly
models uncertainty over reward functions and guides BFMs in data collection for
task inference. Formally, we provide a regret bound for well-trained BFMs
through a direct connection to upper-confidence algorithms for linear bandits.
Empirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and
observe that it enables successor-features-based BFMs to identify and optimize
an unseen reward function in a handful of episodes with minimal compute
overhead. Code is available at https://github.com/ThomasRupf/opti-bfm.

</details>


### [48] [ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases](https://arxiv.org/abs/2510.20270)
*Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini*

Main category: cs.LG

TL;DR: ImpossibleBench是一个基准框架，用于系统性地测量LLM代理利用测试用例的倾向，通过在现有基准中创建自然语言规范与单元测试直接冲突的"不可能"任务变体来量化作弊行为。


<details>
  <summary>Details</summary>
Motivation: LLM倾向于寻找和利用"捷径"完成任务，这种行为会破坏基准测试结果的有效性和实际部署的可靠性，比如删除失败的测试而不是修复底层bug。

Method: 通过修改现有基准（如LiveCodeBench和SWE-bench）中的任务，引入自然语言规范与单元测试之间的直接冲突，创建"不可能"任务变体，测量代理在这些任务上的通过率作为"作弊率"。

Result: 揭示了从简单测试修改到复杂运算符重载等不同粒度的作弊行为，展示了提示、测试访问和反馈循环如何影响作弊率，并提供了带有已验证欺骗性解决方案的测试平台。

Conclusion: ImpossibleBench是一个实用的框架，可用于研究模型行为、上下文工程和开发监控工具，有助于构建更稳健可靠的LLM系统。

Abstract: The tendency to find and exploit "shortcuts" to complete tasks poses
significant risks for reliable assessment and deployment of large language
models (LLMs). For example, an LLM agent with access to unit tests may delete
failing tests rather than fix the underlying bug. Such behavior undermines both
the validity of benchmark results and the reliability of real-world LLM coding
assistant deployments.
  To quantify, study, and mitigate such behavior, we introduce ImpossibleBench,
a benchmark framework that systematically measures LLM agents' propensity to
exploit test cases. ImpossibleBench creates "impossible" variants of tasks from
existing benchmarks like LiveCodeBench and SWE-bench by introducing direct
conflicts between the natural-language specification and the unit tests. We
measure an agent's "cheating rate" as its pass rate on these impossible tasks,
where any pass necessarily implies a specification-violating shortcut.
  As a practical framework, ImpossibleBench is not just an evaluation but a
versatile tool. We demonstrate its utility for: (1) studying model behaviors,
revealing more fine-grained details of cheating behaviors from simple test
modification to complex operator overloading; (2) context engineering, showing
how prompt, test access and feedback loop affect cheating rates; and (3)
developing monitoring tools, providing a testbed with verified deceptive
solutions. We hope ImpossibleBench serves as a useful framework for building
more robust and reliable LLM systems.
  Our implementation can be found at
https://github.com/safety-research/impossiblebench.

</details>


### [49] [Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch](https://arxiv.org/abs/2510.20271)
*Udit Saxena*

Main category: cs.LG

TL;DR: 提出优化的GPU内核用于欧拉特征曲线计算，速度提升16-2000倍，并开发可微分的PyTorch层支持端到端学习。


<details>
  <summary>Details</summary>
Motivation: 拓扑特征能捕捉图像数据中的全局几何结构，但在深度学习中的实际应用需要计算效率和可微分性。

Method: 开发针对Ampere GPU优化的CUDA内核，使用128B合并访问和分层共享内存累加；创建PyTorch层，通过可微分欧拉特征变换式的sigmoid松弛学习单方向阈值。

Result: 在合成网格上实现了16-2000倍的速度提升；提供了端到端学习能力。

Conclusion: 讨论了在下游应用中的相关性，并概述了批处理和多GPU扩展以扩大采用范围。

Abstract: Topological features capture global geometric structure in imaging data, but
practical adoption in deep learning requires both computational efficiency and
differentiability. We present optimized GPU kernels for the Euler
Characteristic Curve (ECC) computation achieving 16-2000\"O speedups over prior
GPU implementations on synthetic grids, and introduce a differentiable PyTorch
layer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs
use 128B-coalesced access and hierarchical shared-memory accumulation. Our
PyTorch layer learns thresholds in a single direction via a Differentiable
Euler Characteristic Transform-style sigmoid relaxation. We discuss downstream
relevance, including applications highlighted by prior ECC work, and outline
batching/multi-GPU extensions to broaden adoption.

</details>


### [50] [Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs](https://arxiv.org/abs/2510.20272)
*Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi*

Main category: cs.LG

TL;DR: PRM引导的树搜索在数学推理中相比Best-of-N选择没有显著改进，尽管成本更高，表明当前过程奖励模型不可靠且泛化能力差。


<details>
  <summary>Details</summary>
Motivation: 链式思维提示与Best-of-N选择虽然流行，但其线性结构无法捕捉复杂问题解决的分支和探索性质，因此研究PRM引导的树搜索是否能通过探索多个部分解路径来改进数学推理。

Method: 提出自适应算法在难处理的动作空间中最大化过程奖励模型分数，使用Qwen2.5-Math-7B-Instruct及其相关PRM作为案例研究，在23个多样化数学问题上评估PRM引导的树搜索方法。

Result: (1) PRM引导的树搜索相比BoN无统计显著改进；(2) 蒙特卡洛树搜索和束搜索优于其他PRM引导方法；(3) PRMs对状态值的近似效果差，可靠性随推理深度下降；(4) PRMs分布外泛化能力差。

Conclusion: 树搜索对不可靠PRM分数的更大依赖导致性能不佳，表明在树搜索能有效增强LLMs数学推理之前需要不同的奖励建模方法。

Abstract: While chain-of-thought prompting with Best-of-N (BoN) selection has become
popular for mathematical reasoning in large language models (LLMs), its linear
structure fails to capture the branching and exploratory nature of complex
problem-solving. In this work, we propose an adaptive algorithm to maximize
process reward model (PRM) scores over the intractable action space, and
investigate whether PRM-guided tree search can improve mathematical reasoning
by exploring multiple partial solution paths. Across $23$ diverse mathematical
problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case
study, we find that: (1) PRM-guided tree search shows no statistically
significant improvements over BoN despite higher costs, (2) Monte Carlo tree
search and beam search outperform other PRM-guided tree search methods, (3)
PRMs poorly approximate state values and their reliability degrades with
reasoning depth, and (4) PRMs generalize poorly out of distribution. This
underperformance stems from tree search's greater reliance on unreliable PRM
scores, suggesting different reward modeling is necessary before tree search
can effectively enhance mathematical reasoning in LLMs.

</details>


### [51] [SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series](https://arxiv.org/abs/2510.20273)
*Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出了SynTSBench评估框架，通过合成数据系统评估时间序列预测模型的基本建模能力，包括时序特征分解、鲁棒性分析和理论最优基准测试


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在标准基准数据集上表现良好，但在实际应用中性能不稳定，且缺乏清晰的量化评估来理解不同模型的具体优缺点

Method: 使用可编程特征配置的合成数据驱动评估范式，包含三个核心分析维度：时序特征分解与能力映射、数据不规则下的鲁棒性分析、理论最优基准测试

Result: 实验表明当前深度学习模型并非在所有类型的时间特征上都接近最优基准

Conclusion: SynTSBench框架能够提供更系统、可解释的模型评估，帮助理解模型在不同时间序列模式下的具体能力

Abstract: Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

</details>


### [52] [KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models](https://arxiv.org/abs/2510.20278)
*Guangyu Dai,Siliang Tang,Yueting Zhuang*

Main category: cs.LG

TL;DR: 提出基于KAN的协作模型(KCM)来解决大-小模型协作中的精度下降、灾难性遗忘和幻觉问题，在保持精度的同时显著降低计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决大-小模型协作框架中存在的精度显著下降、灾难性遗忘加剧以及小模型知识引发的幻觉问题。

Method: 使用KAN（Kolmogorov-Arnold网络）作为协作模型，这是一种与常规MLP不同的神经网络架构，具有更好的可视化和可解释性。

Result: 在语言、视觉和视觉-语言跨模态任务中，KCM相比纯大模型方法显著减少了大模型推理调用次数，同时保持接近的任务精度；相比MLP基小协作模型，KCM在所有指标上都表现更优。

Conclusion: KAN基小协作模型显著缓解了灾难性遗忘，对长尾数据带来显著精度提升，是改进大-小模型协作的有效方法。

Abstract: In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

</details>


### [53] [ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows](https://arxiv.org/abs/2510.20279)
*Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang*

Main category: cs.LG

TL;DR: 提出了ResearchGPT愿景和CS-54k数据集，包含CS-4k评估基准和CS-50k训练集，证明领域对齐训练比预训练规模更重要


<details>
  <summary>Details</summary>
Motivation: 构建能够协助整个科学研究过程的AI协作系统，需要端到端工作流程的评估基准而非孤立子任务

Method: 从14kCC授权论文构建CS-54k科学问答语料库，使用检索增强生成和多阶段质量控制确保事实基础

Result: CS-4k能分层评估最先进LLM，在CS-50k上训练的7B模型超越GPT-4.1、GPT-4o等更大专有系统

Conclusion: 使AI成为更好研究助手更依赖于领域对齐的高质量数据训练，而非预训练规模或通用基准表现

Abstract: As large language models (LLMs) advance, the ultimate vision for their role
in science is emerging: we could build an AI collaborator to effectively assist
human beings throughout the entire scientific research process. We refer to
this envisioned system as ResearchGPT. Given that scientific research
progresses through multiple interdependent phases, achieving this vision
requires rigorous benchmarks that evaluate the end-to-end workflow rather than
isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of
scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It
is constructed through a scalable, paper-grounded pipeline that combines
retrieval-augmented generation (RAG) with multi-stage quality control to ensure
factual grounding. From this unified corpus, we derive two complementary
subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to
assist scientific research, and CS-50k, a large-scale training dataset.
Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs
into distinct capability tiers. Open models trained on CS-50k with supervised
training and reinforcement learning demonstrate substantial improvements. Even
7B-scale models, when properly trained, outperform many larger proprietary
systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that
making AI models better research assistants relies more on domain-aligned
training with high-quality data than on pretraining scale or general benchmark
performance. We release CS-4k and CS-50k in the hope of fostering AI systems as
reliable collaborators in CS research.

</details>


### [54] [Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization](https://arxiv.org/abs/2510.20295)
*Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li*

Main category: cs.LG

TL;DR: 提出了一种无需环境标注的IRM-free方法，通过规范引导的不变分布目标来发现因果子图，在图形泛化任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络在分布偏移下的泛化问题，避免现有IRM方法需要昂贵环境标注或启发式生成环境分割的限制

Method: 基于因果子图分布变化较小的观察，提出不变分布准则，建立分布偏移与表示规范之间的定量关系，设计规范引导的不变分布目标

Result: 在两个广泛使用的基准测试上，该方法在图形泛化方面持续优于最先进方法

Conclusion: 提出的IRM-free方法能够有效捕捉因果子图，为图神经网络在分布偏移下的泛化提供了新的解决方案

Abstract: Out-of-distribution generalization under distributional shifts remains a
critical challenge for graph neural networks. Existing methods generally adopt
the Invariant Risk Minimization (IRM) framework, requiring costly environment
annotations or heuristically generated synthetic splits. To circumvent these
limitations, in this work, we aim to develop an IRM-free method for capturing
causal subgraphs. We first identify that causal subgraphs exhibit substantially
smaller distributional variations than non-causal components across diverse
environments, which we formalize as the Invariant Distribution Criterion and
theoretically prove in this paper. Building on this criterion, we
systematically uncover the quantitative relationship between distributional
shift and representation norm for identifying the causal subgraph, and
investigate its underlying mechanisms in depth. Finally, we propose an IRM-free
method by introducing a norm-guided invariant distribution objective for causal
subgraph discovery and prediction. Extensive experiments on two widely used
benchmarks demonstrate that our method consistently outperforms
state-of-the-art methods in graph generalization.

</details>


### [55] [DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability](https://arxiv.org/abs/2510.20299)
*Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim*

Main category: cs.LG

TL;DR: 提出DB-FGA-Net模型，集成VGG16和Xception双主干网络与频率门控注意力模块，无需数据增强即可在脑肿瘤分类任务中实现最先进性能，并集成Grad-CAM提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习脑肿瘤分类方法依赖数据增强导致的泛化能力受限和临床可信度问题，开发无需增强、可解释且可部署的模型。

Method: 使用VGG16和Xception双主干网络集成频率门控注意力模块，捕获互补的局部和全局特征，无需数据增强，并集成Grad-CAM进行可视化。

Result: 在7K-DS数据集上4分类准确率达99.24%，3分类98.68%，2分类99.85%；在独立3K-DS数据集上泛化准确率达95.77%，优于基线方法。

Conclusion: DB-FGA-Net等无需增强、可解释且可部署的深度学习模型在脑肿瘤诊断中具有可靠的临床转化潜力。

Abstract: Brain tumors are a challenging problem in neuro-oncology, where early and
precise diagnosis is important for successful treatment. Deep learning-based
brain tumor classification methods often rely on heavy data augmentation which
can limit generalization and trust in clinical applications. In this paper, we
propose a double-backbone network integrating VGG16 and Xception with a
Frequency-Gated Attention (FGA) Block to capture complementary local and global
features. Unlike previous studies, our model achieves state-of-the-art
performance without augmentation which demonstrates robustness to variably
sized and distributed datasets. For further transparency, Grad-CAM is
integrated to visualize the tumor regions based on which the model is giving
prediction, bridging the gap between model prediction and clinical
interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS
dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class
and 2-class settings, respectively. On the independent 3K-DS dataset, the model
generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art
methods. To further support clinical usability, we developed a graphical user
interface (GUI) that provides real-time classification and Grad-CAM-based tumor
localization. These findings suggest that augmentation-free, interpretable, and
deployable deep learning models such as DB-FGA-Net hold strong potential for
reliable clinical translation in brain tumor diagnosis.

</details>


### [56] [InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling](https://arxiv.org/abs/2510.20302)
*Yuhang Wang*

Main category: cs.LG

TL;DR: 提出InvDec混合架构，通过倒置解码器实现时间编码和变量级解码的分离，在保持时间建模能力的同时有效捕捉变量间依赖关系，特别在高维数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：通道独立方法如PatchTST擅长时间建模但忽略变量相关性，而纯变量注意力方法如iTransformer牺牲了时间编码能力。需要一种能同时建模时间模式和跨变量依赖的解决方案。

Method: 结合基于patch的时间编码器和在变量维度上通过变量自注意力操作的倒置解码器。引入延迟变量嵌入来丰富变量特定表示，并采用自适应残差融合机制动态平衡时间和变量信息。

Result: 在7个基准测试上验证，在高维数据集上表现显著：电力数据集MSE降低20.9%，天气数据集提升4.3%，交通数据集提升2.7%，同时在低维ETT数据集上保持竞争力。

Conclusion: InvDec通过分离时间编码和变量级解码，有效解决了多变量时间序列预测中的关键挑战，其优势随数据集维度增加而增强，证实了跨变量建模在变量数量增加时的重要性。

Abstract: Multivariate time series forecasting requires simultaneously modeling
temporal patterns and cross-variate dependencies. Channel-independent methods
such as PatchTST excel at temporal modeling but ignore variable correlations,
while pure variate-attention approaches such as iTransformer sacrifice temporal
encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that
achieves principled separation between temporal encoding and variate-level
decoding. InvDec combines a patch-based temporal encoder with an inverted
decoder operating on the variate dimension through variate-wise self-attention.
We introduce delayed variate embeddings that enrich variable-specific
representations only after temporal encoding, preserving temporal feature
integrity. An adaptive residual fusion mechanism dynamically balances temporal
and variate information across datasets of varying dimensions. Instantiating
InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven
benchmarks demonstrate significant gains on high-dimensional datasets: 20.9%
MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and
2.7% gain on Traffic compared to PatchTST, while maintaining competitive
performance on low-dimensional ETT datasets. Ablation studies validate each
component, and analysis reveals that InvDec's advantage grows with dataset
dimensionality, confirming that cross-variate modeling becomes critical as the
number of variables increases.

</details>


### [57] [LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems](https://arxiv.org/abs/2510.20327)
*Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen*

Main category: cs.LG

TL;DR: LEGO是一个轻量级高效的多属性遗忘框架，通过嵌入校准和灵活组合两个步骤，解决了推荐系统中多敏感属性动态遗忘的挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界的隐私保护需求通常涉及多个敏感属性且具有动态性，现有的单属性遗忘方法无法同时处理多个遗忘请求，也缺乏对动态遗忘需求的高效适应性。

Method: 将多属性遗忘过程分为两个步骤：嵌入校准从用户嵌入中移除特定属性信息，灵活组合将这些嵌入合并为单一嵌入以保护所有敏感属性。将遗忘过程建模为互信息最小化问题。

Result: 在三个真实世界数据集和三种代表性推荐模型上的广泛实验证明了该框架的有效性和效率。

Conclusion: LEGO框架能够有效解决多属性动态遗忘问题，为推荐系统的隐私保护提供了理论保证和实用解决方案。

Abstract: With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

</details>


### [58] [Synthetic Data for Robust Runway Detection](https://arxiv.org/abs/2510.20349)
*Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin*

Main category: cs.LG

TL;DR: 使用商业飞行模拟器生成合成图像来补充少量真实标注图像，通过控制图像生成和真实/合成数据集成，提高跑道检测模型的准确性和对夜间等恶劣条件的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在关键应用如自主着陆系统中，收集和标注训练数据成本高昂，特别是需要覆盖所有可能条件包括罕见场景。合成图像生成可以廉价可靠地覆盖所有条件和环境。

Method: 基于商业飞行模拟器的图像生成方法，结合少量真实标注图像，采用定制化的域适应策略来缓解合成到真实的分布偏移问题。

Result: 标准目标检测模型可以实现准确预测，在未在真实数据中出现的夜间图像等恶劣条件下也表现出良好的鲁棒性。

Conclusion: 通过控制图像生成和真实/合成数据集成，结合定制域适应策略，可以有效利用合成图像提升关键应用中视觉模型的性能。

Abstract: Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

</details>


### [59] [Ask a Strong LLM Judge when Your Reward Model is Uncertain](https://arxiv.org/abs/2510.20369)
*Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao*

Main category: cs.LG

TL;DR: 提出基于不确定性的路由框架，在强化学习人类反馈中高效结合快速奖励模型和强大的LLM评判器，通过不确定性量化指导路由决策。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型容易受到奖励攻击且在分布外输入上泛化能力差，而强大的LLM评判器虽然泛化能力强但推理成本高，限制了在在线RLHF中的应用。

Method: 将策略梯度中的优势估计建模为成对偏好分类，实现原则性的不确定性量化来指导路由决策，不确定的样本对转发给LLM评判器，确定的由奖励模型处理。

Result: 在奖励模型基准测试中，基于不确定性的路由策略在相同成本下显著优于随机调用评判器，下游对齐结果展示了其在改进在线RLHF中的有效性。

Conclusion: 该框架通过智能路由机制，在保持效率的同时提升了强化学习人类反馈系统的性能和泛化能力。

Abstract: Reward model (RM) plays a pivotal role in reinforcement learning with human
feedback (RLHF) for aligning large language models (LLMs). However, classical
RMs trained on human preferences are vulnerable to reward hacking and
generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM
judges equipped with reasoning capabilities demonstrate superior
generalization, even without additional training, but incur significantly
higher inference costs, limiting their applicability in online RLHF. In this
work, we propose an uncertainty-based routing framework that efficiently
complements a fast RM with a strong but costly LLM judge. Our approach
formulates advantage estimation in policy gradient (PG) methods as pairwise
preference classification, enabling principled uncertainty quantification to
guide routing. Uncertain pairs are forwarded to the LLM judge, while confident
ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our
uncertainty-based routing strategy significantly outperforms random judge
calling at the same cost, and downstream alignment results showcase its
effectiveness in improving online RLHF.

</details>


### [60] [Hierarchical Time Series Forecasting with Robust Reconciliation](https://arxiv.org/abs/2510.20383)
*Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.LG

TL;DR: 提出了一种用于层次时间序列预测的鲁棒优化框架，通过考虑协方差矩阵估计的不确定性来改进预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有层次预测方法需要估计协方差矩阵，但真实协方差矩阵未知，估计误差会降低预测性能。

Method: 引入协方差矩阵的不确定性集合，构建最小化最坏情况期望平方误差的鲁棒优化问题，转化为半定优化问题求解。

Result: 数值实验表明，所提出的鲁棒协调方法比现有层次预测方法具有更好的预测性能。

Conclusion: 将不确定性整合到协调过程中能有效提升层次时间序列预测的性能。

Abstract: This paper focuses on forecasting hierarchical time-series data, where each
higher-level observation equals the sum of its corresponding lower-level time
series. In such contexts, the forecast values should be coherent, meaning that
the forecast value of each parent series exactly matches the sum of the
forecast values of its child series. Existing hierarchical forecasting methods
typically generate base forecasts independently for each series and then apply
a reconciliation procedure to adjust them so that the resulting forecast values
are coherent across the hierarchy. These methods generally derive an optimal
reconciliation, using a covariance matrix of the forecast error. In practice,
however, the true covariance matrix is unknown and has to be estimated from
finite samples in advance. This gap between the true and estimated covariance
matrix may degrade forecast performance. To address this issue, we propose a
robust optimization framework for hierarchical reconciliation that accounts for
uncertainty in the estimated covariance matrix. We first introduce an
uncertainty set for the estimated covariance matrix and formulate a
reconciliation problem that minimizes the worst-case expected squared error
over this uncertainty set. We show that our problem can be cast as a
semidefinite optimization problem. Numerical experiments demonstrate that the
proposed robust reconciliation method achieved better forecast performance than
existing hierarchical forecasting methods, which indicates the effectiveness of
integrating uncertainty into the reconciliation process.

</details>


### [61] [Relative-Based Scaling Law for Neural Language Models](https://arxiv.org/abs/2510.20387)
*Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu*

Main category: cs.LG

TL;DR: 本文提出了基于相对排序的缩放定律，通过相对概率指标(RBP)来补充传统交叉熵指标的不足，更全面地评估语言模型的性能缩放规律。


<details>
  <summary>Details</summary>
Motivation: 现有缩放定律研究几乎完全依赖交叉熵作为评估指标，但交叉熵只关注正确token的绝对概率，忽略了正确与错误token之间的相对排序关系，而相对排序对语言模型的实际应用至关重要。

Method: 提出了相对概率指标(RBP)，量化正确token在top预测中的排名概率；建立了基于相对排序的缩放定律，描述RBP如何随模型规模增加而改进；在四个数据集和四个模型家族上进行了广泛实验。

Result: 通过跨越五个数量级的实验验证了该缩放定律的鲁棒性和准确性；展示了该定律的两个应用：为涌现现象提供更深入解释，以及促进寻找缩放定律的基本理论。

Conclusion: 基于相对排序的缩放定律补充了交叉熵视角，为大规模语言模型的缩放提供了更全面的理解，对实际开发和理论探索都具有重要价值。

Abstract: Scaling laws aim to accurately predict model performance across different
scales. Existing scaling-law studies almost exclusively rely on cross-entropy
as the evaluation metric. However, cross-entropy provides only a partial view
of performance: it measures the absolute probability assigned to the correct
token, but ignores the relative ordering between correct and incorrect tokens.
Yet, relative ordering is crucial for language models, such as in
greedy-sampling scenario. To address this limitation, we investigate scaling
from the perspective of relative ordering. We first propose the Relative-Based
Probability (RBP) metric, which quantifies the probability that the correct
token is ranked among the top predictions. Building on this metric, we
establish the Relative-Based Scaling Law, which characterizes how RBP improves
with increasing model size. Through extensive experiments on four datasets and
four model families spanning five orders of magnitude, we demonstrate the
robustness and accuracy of this law. Finally, we illustrate the broad
application of this law with two examples, namely providing a deeper
explanation of emergence phenomena and facilitating finding fundamental
theories of scaling laws. In summary, the Relative-Based Scaling Law
complements the cross-entropy perspective and contributes to a more complete
understanding of scaling large language models. Thus, it offers valuable
insights for both practical development and theoretical exploration.

</details>


### [62] [Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control](https://arxiv.org/abs/2510.20408)
*Tom Maus,Asma Atamna,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 提出了一个工业启发的多阶段流程基准环境，评估了模块化与集中式控制策略以及动作掩码的影响，发现动作约束对学习效果至关重要。


<details>
  <summary>Details</summary>
Motivation: 工业过程控制需要局部专业化和全局协调，但强化学习在工业应用中的采用受到奖励设计、模块化和动作空间管理等挑战的限制。现有学术基准与工业控制问题差异较大。

Method: 结合SortingEnv和ContainerGym两个现有基准，创建顺序回收场景（分拣和压制操作）。评估模块化架构（专业代理）与集中式代理（全系统控制），分析动作掩码的影响。

Result: 无动作掩码时，代理难以学习有效策略，模块化架构表现更好。应用动作掩码后，两种架构都显著改善，性能差距缩小。动作空间约束起决定性作用。

Conclusion: 专业化优势随着动作复杂度降低而减弱。该基准为工业自动化中实用且鲁棒的多智能体强化学习解决方案提供了有价值的测试平台，并有助于集中化与专业化的持续讨论。

Abstract: Autonomous control of multi-stage industrial processes requires both local
specialization and global coordination. Reinforcement learning (RL) offers a
promising approach, but its industrial adoption remains limited due to
challenges such as reward design, modularity, and action space management. Many
academic benchmarks differ markedly from industrial control problems, limiting
their transferability to real-world applications. This study introduces an
enhanced industry-inspired benchmark environment that combines tasks from two
existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling
scenario with sorting and pressing operations. We evaluate two control
strategies: a modular architecture with specialized agents and a monolithic
agent governing the full system, while also analyzing the impact of action
masking. Our experiments show that without action masking, agents struggle to
learn effective policies, with the modular architecture performing better. When
action masking is applied, both architectures improve substantially, and the
performance gap narrows considerably. These results highlight the decisive role
of action space constraints and suggest that the advantages of specialization
diminish as action complexity is reduced. The proposed benchmark thus provides
a valuable testbed for exploring practical and robust multi-agent RL solutions
in industrial automation, while contributing to the ongoing debate on
centralization versus specialization.

</details>


### [63] [Why DPO is a Misspecified Estimator and How to Fix It](https://arxiv.org/abs/2510.20413)
*Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee*

Main category: cs.LG

TL;DR: 本文分析了DPO算法的局限性，指出当真实奖励函数无法通过策略类实现时，DPO会出现错误设定问题，导致偏好顺序反转、策略奖励恶化等失败模式。作者提出了AuxDPO方法，通过引入辅助变量来缓解DPO的错误设定问题。


<details>
  <summary>Details</summary>
Motivation: DPO等直接对齐算法虽然简化了RLHF的两阶段过程，但在真实奖励函数无法通过策略类实现时会出现错误设定问题，导致性能下降。需要研究如何缓解这种错误设定并改进DPO算法。

Method: 1. 分析DPO在错误设定情况下的失败模式；2. 研究两阶段RLHF在参数化类别下的局部行为；3. 提出AuxDPO方法，在DPO损失函数中引入辅助变量来逼近RLHF解。

Result: 实证研究表明，AuxDPO在示例性的多臂赌博机设置和LLM对齐任务中均表现出优于DPO的性能，能够有效缓解错误设定问题。

Conclusion: DPO存在错误设定问题，而AuxDPO通过引入辅助变量能够更接近RLHF解，在理论和实证上都显示出更好的对齐效果。

Abstract: Direct alignment algorithms such as Direct Preference Optimization (DPO)
fine-tune models based on preference data, using only supervised learning
instead of two-stage reinforcement learning with human feedback (RLHF). We show
that DPO encodes a statistical estimation problem over reward functions induced
by a parametric policy class. When the true reward function that generates
preferences cannot be realized via the policy class, DPO becomes misspecified,
resulting in failure modes such as preference order reversal, worsening of
policy reward, and high sensitivity to the input preference data distribution.
On the other hand, we study the local behavior of two-stage RLHF for a
parametric class and relate it to a natural gradient step in policy space. Our
fine-grained geometric characterization allows us to propose AuxDPO, which
introduces additional auxiliary variables in the DPO loss function to help move
towards the RLHF solution in a principled manner and mitigate the
misspecification in DPO. We empirically demonstrate the superior performance of
AuxDPO on didactic bandit settings as well as LLM alignment tasks.

</details>


### [64] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 提出了一种针对标记时间点过程的阈值方法，通过调整标记概率来解决事件标记分布不平衡问题，并开发了新的神经网络模型来支持有效的时间采样和标记概率估计。


<details>
  <summary>Details</summary>
Motivation: 现实应用中事件标记分布高度不平衡，现有研究忽视了这一点，导致对稀有标记事件的预测性能不佳。

Method: 提出阈值方法学习阈值来调整标记概率，先预测标记再预测时间，开发了支持有效时间采样和标记概率估计的神经MTPP模型。

Result: 在真实世界数据集上的广泛实验表明，该方法在下一个事件标记和时间预测方面优于各种基线方法。

Conclusion: 提出的解决方案有效解决了事件标记分布不平衡问题，显著提升了稀有标记事件的预测性能。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [65] [An Empirical Study of Sample Selection Strategies for Large Language Model Repair](https://arxiv.org/abs/2510.20428)
*Xuran Li,Jingyi Wang*

Main category: cs.LG

TL;DR: 本文系统分析了LLM修复中的样本优先策略，发现我们提出的SAPS方法在解毒、效用保持和效率方面达到最佳平衡，随机采样对大型模型仍然有效，而高开销方法收益有限。


<details>
  <summary>Details</summary>
Motivation: LLM在实际部署中会产生有毒或偏见输出，影响安全性和可信度。参数更新的高成本促使需要选择性地使用修复数据，但现有数据选择方法在大型生成模型行为修复中的效果和效率尚不明确。

Method: 评估了五种代表性选择方法：随机采样、K-Center、梯度范数选择(GraNd)、分层覆盖(CCS)和我们提出的语义感知优先采样(SAPS)。通过毒性减少、困惑度和三个复合指标(RPS、OPS、RES)评估修复效果。

Result: SAPS在解毒、效用保持和效率方面达到最佳平衡，用更少数据实现相当或更优的修复结果。随机采样对大型或鲁棒模型仍然有效，而CCS和GraNd等高开销方法收益有限。最佳数据比例取决于模型规模和修复方法。

Conclusion: 基于选择的修复是维护LLM可靠性的高效可扩展范式，样本选择应被视为修复流程中的可调组件。

Abstract: Large language models (LLMs) are increasingly deployed in real-world systems,
yet they can produce toxic or biased outputs that undermine safety and trust.
Post-hoc model repair provides a practical remedy, but the high cost of
parameter updates motivates selective use of repair data. Despite extensive
prior work on data selection for model training, it remains unclear which
sampling criteria are most effective and efficient when applied specifically to
behavioral repair of large generative models. Our study presents a systematic
analysis of sample prioritization strategies for LLM repair. We evaluate five
representative selection methods, including random sampling, K-Center,
gradient-norm-based selection(GraNd), stratified coverage (CCS), and a
Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair
effectiveness and trade-offs are assessed through toxicity reduction,
perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair
Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair
Efficiency Score (RES). Experimental results show that SAPS achieves the best
balance between detoxification, utility preservation, and efficiency,
delivering comparable or superior repair outcomes with substantially less data.
Random sampling remains effective for large or robust models, while
high-overhead methods such as CCS and GraNd provide limited benefit. The
optimal data proportion depends on model scale and repair method, indicating
that sample selection should be regarded as a tunable component of repair
pipelines. Overall, these findings establish selection-based repair as an
efficient and scalable paradigm for maintaining LLM reliability.

</details>


### [66] [Explainable Benchmarking through the Lense of Concept Learning](https://arxiv.org/abs/2510.20439)
*Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: 本文提出可解释基准测试新范式，旨在自动生成系统性能解释，并在知识图谱问答系统中首次实现，使用PruneCEL方法显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统基准测试仅用少量指标总结系统性能，分析评估细节和推导洞察需要繁琐的手动工作且结果常有偏差

Method: 使用为大型知识图谱开发的新概念学习方法PruneCEL来计算解释，该方法在可解释基准测试任务上表现优异

Result: PruneCEL在可解释基准测试任务上比最先进概念学习方法F1分数提高0.55分；41人用户研究中80%情况下多数参与者能基于解释准确预测系统行为

Conclusion: 可解释基准测试是可行的且有价值的研究方向，PruneCEL方法有效支持该范式实现

Abstract: Evaluating competing systems in a comparable way, i.e., benchmarking them, is
an undeniable pillar of the scientific method. However, system performance is
often summarized via a small number of metrics. The analysis of the evaluation
details and the derivation of insights for further development or use remains a
tedious manual task with often biased results. Thus, this paper argues for a
new type of benchmarking, which is dubbed explainable benchmarking. The aim of
explainable benchmarking approaches is to automatically generate explanations
for the performance of systems in a benchmark. We provide a first instantiation
of this paradigm for knowledge-graph-based question answering systems. We
compute explanations by using a novel concept learning approach developed for
large knowledge graphs called PruneCEL. Our evaluation shows that PruneCEL
outperforms state-of-the-art concept learners on the task of explainable
benchmarking by up to 0.55 points F1 measure. A task-driven user study with 41
participants shows that in 80\% of the cases, the majority of participants can
accurately predict the behavior of a system based on our explanations. Our code
and data are available at https://github.com/dice-group/PruneCEL/tree/K-cap2025

</details>


### [67] [MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction](https://arxiv.org/abs/2510.20448)
*Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan*

Main category: cs.LG

TL;DR: 提出了MolBridge框架，通过原子级联合图建模来预测药物-药物相互作用事件，解决了现有方法无法显式建模跨分子原子级交互的问题


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用预测方法依赖孤立的药物表示，无法显式建模原子级跨分子交互，限制了在不同分子复杂度和DDI类型分布下的有效性

Method: 构建药物对的联合图整合原子结构，引入结构一致性模块迭代优化节点特征同时保持全局结构上下文，学习局部和全局交互模式

Result: 在两个基准数据集上的广泛实验表明，MolBridge在长尾和归纳场景下均优于现有最先进基线方法

Conclusion: 细粒度图优化提高了DDI事件预测的准确性、鲁棒性和机制可解释性，为网络挖掘和内容分析领域贡献了基于图的药物相互作用网络分析方法

Abstract: Drug combinations offer therapeutic benefits but also carry the risk of
adverse drug-drug interactions (DDIs), especially under complex molecular
structures. Accurate DDI event prediction requires capturing fine-grained
inter-drug relationships, which are critical for modeling metabolic mechanisms
such as enzyme-mediated competition. However, existing approaches typically
rely on isolated drug representations and fail to explicitly model atom-level
cross-molecular interactions, limiting their effectiveness across diverse
molecular complexities and DDI type distributions. To address these
limitations, we propose MolBridge, a novel atom-level joint graph refinement
framework for robust DDI event prediction. MolBridge constructs a joint graph
that integrates atomic structures of drug pairs, enabling direct modeling of
inter-drug associations. A central challenge in such joint graph settings is
the potential loss of information caused by over-smoothing when modeling
long-range atomic dependencies. To overcome this, we introduce a structure
consistency module that iteratively refines node features while preserving the
global structural context. This joint design allows MolBridge to effectively
learn both local and global interaction outperforms state-of-the-art baselines,
achieving superior performance across long-tail and inductive scenarios.
patterns, yielding robust representations across both frequent and rare DDI
types. Extensive experiments on two benchmark datasets show that MolBridge
consistently. These results demonstrate the advantages of fine-grained graph
refinement in improving the accuracy, robustness, and mechanistic
interpretability of DDI event prediction.This work contributes to Web Mining
and Content Analysis by developing graph-based methods for mining and analyzing
drug-drug interaction networks.

</details>


### [68] [Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach](https://arxiv.org/abs/2510.20454)
*Lawrence Clegg,John Cartlidge*

Main category: cs.LG

TL;DR: 该论文提出使用图神经网络建模网球比赛中的非传递性关系，通过历史比赛结果构建有向图，发现在高非传递性复杂度的比赛中存在市场低效，利用该模型可获得3.26%的投资回报率。


<details>
  <summary>Details</summary>
Motivation: 网球比赛中普遍存在非传递性优势关系（A胜B，B胜C，但C胜A），但现有预测方法很少考虑这种关系。作者旨在开发能够明确建模这些非传递性关系的预测方法。

Method: 使用图神经网络方法，将球员作为节点，历史比赛结果作为有向边，构建时序有向图来显式建模非传递性关系。

Result: 模型在高非传递性比赛中的预测准确率达到65.7%，Brier得分为0.215。通过选择性投注高非传递性比赛，使用凯利投注策略在1903次投注中获得了3.26%的正回报率。

Conclusion: 博彩公司Pinnacle Sports在处理高非传递性复杂度的比赛时表现不佳，基于图的建模方法能够有效捕捉这些场景中的关系动态，成功利用了市场在处理非传递性比赛时的低效性。

Abstract: Intransitive player dominance, where player A beats B, B beats C, but C beats
A, is common in competitive tennis. Yet, there are few known attempts to
incorporate it within forecasting methods. We address this problem with a graph
neural network approach that explicitly models these intransitive relationships
through temporal directed graphs, with players as nodes and their historical
match outcomes as directed edges. We find the bookmaker Pinnacle Sports poorly
handles matches with high intransitive complexity and posit that our
graph-based approach is uniquely positioned to capture relational dynamics in
these scenarios. When selectively betting on higher intransitivity matchups
with our model (65.7% accuracy, 0.215 Brier Score), we achieve significant
positive returns of 3.26% ROI with Kelly staking over 1903 bets, suggesting a
market inefficiency in handling intransitive matchups that our approach
successfully exploits.

</details>


### [69] [Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models](https://arxiv.org/abs/2510.20468)
*Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko*

Main category: cs.LG

TL;DR: 本文提出了一种针对后处理图像水印的伪造攻击方法，通过训练偏好模型来检测水印，并利用反向传播优化实现水印移除和伪造，仅需单张水印图像且无需了解水印模型细节。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的激增，水印技术对确保内容真实性和归属至关重要。然而，水印伪造（即从真实内容中窃取水印并应用于恶意内容）这一场景尚未得到充分研究。

Method: 1. 引入偏好模型评估图像是否含水印，使用排序损失在纯程序生成图像上训练，无需真实水印数据；2. 通过反向传播优化输入图像实现水印移除和伪造；3. 仅需单张水印图像，无需了解水印模型细节。

Result: 在多种后处理图像水印模型上评估，证明该方法能有效伪造水印，质疑了当前水印方法的安全性。

Conclusion: 当前水印方法存在安全隐患，提出的伪造攻击方法简单实用，对水印技术的安全性提出了挑战。

Abstract: Recent years have seen a surge in interest in digital content watermarking
techniques, driven by the proliferation of generative models and increased
legal pressure. With an ever-growing percentage of AI-generated content
available online, watermarking plays an increasingly important role in ensuring
content authenticity and attribution at scale. There have been many works
assessing the robustness of watermarking to removal attacks, yet, watermark
forging, the scenario when a watermark is stolen from genuine content and
applied to malicious content, remains underexplored. In this work, we
investigate watermark forging in the context of widely used post-hoc image
watermarking. Our contributions are as follows. First, we introduce a
preference model to assess whether an image is watermarked. The model is
trained using a ranking loss on purely procedurally generated images without
any need for real watermarks. Second, we demonstrate the model's capability to
remove and forge watermarks by optimizing the input image through
backpropagation. This technique requires only a single watermarked image and
works without knowledge of the watermarking model, making our attack much
simpler and more practical than attacks introduced in related work. Third, we
evaluate our proposed method on a variety of post-hoc image watermarking
models, demonstrating that our approach can effectively forge watermarks,
questioning the security of current watermarking approaches. Our code and
further resources are publicly available.

</details>


### [70] [Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models](https://arxiv.org/abs/2510.20477)
*Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo*

Main category: cs.LG

TL;DR: 提出Bi-CoG方法，通过同时利用模型间和模型内一致性，结合错误感知动态伪标签分配策略，解决半监督微调中的模型偏差和超参数敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 现有半监督微调方法依赖预测一致性或预定义置信度阈值，导致模型偏差和超参数敏感性。需要一种更有效的方法来分配高质量、低偏差的伪标签。

Method: Bi-CoG方法：结合模型间和模型内一致性，使用错误感知动态伪标签分配策略，无需预定义阈值即可分配高质量伪标签。

Result: 在14个数据集上的实验表明，Bi-CoG能显著提升现有方法的性能，理论分析也验证了其有效性。

Conclusion: Bi-CoG是一个简单有效的即插即用方法，通过双一致性引导和动态伪标签分配，解决了半监督微调中的关键问题，具有一致的性能提升。

Abstract: Exploiting unlabeled data through semi-supervised learning (SSL) or
leveraging pre-trained models via fine-tuning are two prevailing paradigms for
addressing label-scarce scenarios. Recently, growing attention has been given
to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,
forming the emerging paradigm of semi-supervised fine-tuning. However, existing
methods often suffer from model bias and hyperparameter sensitivity, due to
reliance on prediction consistency or pre-defined confidence thresholds. To
address these limitations, we propose a simple yet effective plug-and-play
methodology named
$\underline{\textbf{Bi-Co}}$nsistency-$\underline{\textbf{G}}$uided
Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,
by simultaneously exploiting inter-model and intra-model consistency, along
with an error-aware dynamic pseudo-label assignment strategy. Both theoretical
analysis and extensive experiments over 14 datasets demonstrate the
effectiveness of Bi-CoG, which consistently and significantly improves the
performance of existing methods.

</details>


### [71] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 提出了Hurdle-IMDL框架来解决降雨反演中的标签不平衡问题，通过分解零膨胀和长尾分布，有效改善了强降雨的检索性能。


<details>
  <summary>Details</summary>
Motivation: 人工智能在定量遥感中面临标签分布不平衡的挑战，传统训练模型偏向常见样本，导致对罕见样本（如强降雨）的检索性能下降。

Method: 采用分而治之策略：使用hurdle模型处理零膨胀（非降雨样本占主导），提出IMDL方法处理长尾分布（轻降雨样本远多于强降雨样本），将学习目标转化为无偏的理想逆模型。

Result: 通过统计指标和案例研究验证，Hurdle-IMDL优于传统方法、成本敏感方法、生成方法和多任务学习方法，显著减轻系统低估，大幅改善强到极端降雨的检索性能。

Conclusion: IMDL为处理环境变量分布不平衡提供了通用方法，能够增强对罕见但高影响事件的检索能力。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [72] [SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment](https://arxiv.org/abs/2510.20540)
*Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis*

Main category: cs.LG

TL;DR: SheafAlign是一个基于层理论的去中心化多模态对齐框架，用多个比较空间替代单一空间对齐，通过层结构建模模态间关系，使用去中心化对比学习进行训练。


<details>
  <summary>Details</summary>
Motivation: 传统多模态对齐方法假设所有模态间存在相互冗余性，这在现实分布式场景中往往不成立。需要一种不依赖所有模态相互冗余的对齐方法。

Method: 提出SheafAlign框架，使用层理论建模成对模态关系，采用去中心化对比学习目标进行训练，在多个比较空间中进行对齐。

Result: 在多模态感知数据集上表现出优越的零样本泛化能力、跨模态对齐效果和模态缺失鲁棒性，通信成本比最先进基线降低50%。

Conclusion: SheafAlign克服了传统方法的局限性，不需要所有模态间的相互冗余，能够同时保留共享和独特信息，在分布式场景中具有显著优势。

Abstract: Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

</details>


### [73] [A Unified Framework for Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.20542)
*Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 提出了首个零样本强化学习的统一框架，引入一致符号和分类法来组织现有方法，将算法分为直接表示和组合表示两类，并推导了后继特征方法的扩展边界。


<details>
  <summary>Details</summary>
Motivation: 零样本强化学习领域缺乏共同的分析框架，现有方法难以直接比较，需要统一的理论基础来推动更通用智能体的发展。

Method: 建立统一框架，引入一致符号系统和分类法，将算法分为直接表示（学习从奖励到策略的端到端映射）和组合表示（利用价值函数子结构分解表示）两类。

Result: 框架提供了组织现有方法的共同视角，揭示了不同方法间的共享原则和关键差异，并为后继特征方法推导了扩展性能边界。

Conclusion: 该统一框架为零样本强化学习研究提供了理论基础，为开发更通用智能体指明了清晰路径。

Abstract: Zero-shot reinforcement learning (RL) has emerged as a setting for developing
general agents in an unsupervised manner, capable of solving downstream tasks
without additional training or planning at test-time. Unlike conventional RL,
which optimizes policies for a fixed reward, zero-shot RL requires agents to
encode representations rich enough to support immediate adaptation to any
objective, drawing parallels to vision and language foundation models. Despite
growing interest, the field lacks a common analytical lens.
  We present the first unified framework for zero-shot RL. Our formulation
introduces a consistent notation and taxonomy that organizes existing
approaches and allows direct comparison between them. Central to our framework
is the classification of algorithms into two families: direct representations,
which learn end-to-end mappings from rewards to policies, and compositional
representations, which decompose the representation leveraging the substructure
of the value function. Within this framework, we highlight shared principles
and key differences across methods, and we derive an extended bound for
successor-feature methods, offering a new perspective on their performance in
the zero-shot regime. By consolidating existing work under a common lens, our
framework provides a principled foundation for future research in zero-shot RL
and outlines a clear path toward developing more general agents.

</details>


### [74] [Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics](https://arxiv.org/abs/2510.20556)
*Alexandre Benoit,Catherine Aitken,Yu He*

Main category: cs.LG

TL;DR: 该论文系统分析了图重连技术对图结构属性和GNN性能的影响，发现成功的重连方法通常保留局部结构而允许全局连接变化。


<details>
  <summary>Details</summary>
Motivation: 图重连技术虽然能缓解GNN中的过压缩问题，但会改变图拓扑结构，可能扭曲重要的拓扑依赖信号。目前缺乏对哪些结构属性必须保留以确保性能和结构保真度的系统研究。

Method: 研究了七种不同的重连策略，并分析局部和全局图属性变化与节点分类准确性的相关性。

Result: 研究结果显示一致模式：成功的重连方法倾向于保留局部结构，同时在全局连接性上允许灵活性。

Conclusion: 这些发现为设计有效的重连策略提供了新见解，弥合了图理论与实际GNN优化之间的差距。

Abstract: Graph rewiring has emerged as a key technique to alleviate over-squashing in
Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph
topology to improve information flow. While effective, rewiring inherently
alters the graph's structure, raising the risk of distorting important
topology-dependent signals. Yet, despite the growing use of rewiring, little is
known about which structural properties must be preserved to ensure both
performance gains and structural fidelity. In this work, we provide the first
systematic analysis of how rewiring affects a range of graph structural
metrics, and how these changes relate to downstream task performance. We study
seven diverse rewiring strategies and correlate changes in local and global
graph properties with node classification accuracy. Our results reveal a
consistent pattern: successful rewiring methods tend to preserve local
structure while allowing for flexibility in global connectivity. These findings
offer new insights into the design of effective rewiring strategies, bridging
the gap between graph theory and practical GNN optimization.

</details>


### [75] [Embedding the MLOps Lifecycle into OT Reference Models](https://arxiv.org/abs/2510.20590)
*Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber*

Main category: cs.LG

TL;DR: 分析了将MLOps实践集成到运营技术(OT)环境中的挑战，提出了使用RAMI 4.0和ISA-95等现有参考模型来系统化整合MLOps的方法。


<details>
  <summary>Details</summary>
Motivation: 随着MLOps在工业环境中的广泛应用，将其与OT系统集成面临显著挑战，需要找到有效的集成路径。

Method: 评估RAMI 4.0和ISA-95标准对MLOps集成的适用性，将MLOps生命周期组件映射到RAMI 4.0框架，并通过实际用例进行验证。

Result: 研究发现标准MLOps实践不能直接移植到OT环境，但通过使用现有参考模型进行结构化适配，可以提供成功的集成路径。

Conclusion: 通过利用现有的工业参考模型进行结构化适配，可以实现MLOps与OT环境的有效集成，为工业4.0环境中的机器学习操作提供了可行的解决方案。

Abstract: Machine Learning Operations (MLOps) practices are increas- ingly adopted in
industrial settings, yet their integration with Opera- tional Technology (OT)
systems presents significant challenges. This pa- per analyzes the fundamental
obstacles in combining MLOps with OT en- vironments and proposes a systematic
approach to embed MLOps prac- tices into established OT reference models. We
evaluate the suitability of the Reference Architectural Model for Industry 4.0
(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for
MLOps integration and present a detailed mapping of MLOps lifecycle compo-
nents to RAMI 4.0 exemplified by a real-world use case. Our findings
demonstrate that while standard MLOps practices cannot be directly transplanted
to OT environments, structured adaptation using existing reference models can
provide a pathway for successful integration.

</details>


### [76] [Generalizable Reasoning through Compositional Energy Minimization](https://arxiv.org/abs/2510.20607)
*Alexandru Oarga,Yilun Du*

Main category: cs.LG

TL;DR: 提出了一种通过组合子问题能量函数来构建全局能量景观的推理泛化方法，使用并行能量最小化提高样本质量，在复杂推理任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端推理模型在训练分布外泛化能力有限，需要解决比训练问题更复杂的推理任务。

Method: 学习子问题的能量景观，在测试时组合多个子问题的能量函数构建全局能量景观，并引入并行能量最小化来优化样本质量。

Result: 在广泛的推理问题上评估，该方法优于现有最先进方法，能够泛化到更大更复杂的问题。

Conclusion: 通过组合子问题能量函数构建全局能量景观的方法有效提升了推理任务的泛化能力。

Abstract: Generalization is a key challenge in machine learning, specifically in
reasoning tasks, where models are expected to solve problems more complex than
those encountered during training. Existing approaches typically train
reasoning models in an end-to-end fashion, directly mapping input instances to
solutions. While this allows models to learn useful heuristics from data, it
often results in limited generalization beyond the training distribution. In
this work, we propose a novel approach to reasoning generalization by learning
energy landscapes over the solution spaces of smaller, more tractable
subproblems. At test time, we construct a global energy landscape for a given
problem by combining the energy functions of multiple subproblems. This
compositional approach enables the incorporation of additional constraints
during inference, allowing the construction of energy landscapes for problems
of increasing difficulty. To improve the sample quality from this newly
constructed energy landscape, we introduce Parallel Energy Minimization (PEM).
We evaluate our approach on a wide set of reasoning problems. Our method
outperforms existing state-of-the-art methods, demonstrating its ability to
generalize to larger and more complex problems. Project website can be found
at: https://alexoarga.github.io/compositional_reasoning/

</details>


### [77] [Convergence Analysis of SGD under Expected Smoothness](https://arxiv.org/abs/2510.20608)
*Yuta Kawamoto,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文对随机梯度下降(SGD)在期望平滑性(ES)条件下的收敛性进行了系统分析，改进了ES条件的解释和常数设置，推导了全梯度范数平方的期望界，并证明了不同步长策略下的O(1/K)收敛速率。


<details>
  <summary>Details</summary>
Motivation: 经典SGD分析依赖过强(有界方差)或过粗糙(均匀噪声)的假设，期望平滑性条件作为灵活替代方案，将随机梯度的二阶矩与目标函数值和全梯度联系起来。

Method: 通过精炼期望平滑性条件及其解释，引入采样相关常数，推导全梯度范数平方的期望界，分析不同步长策略下的收敛行为。

Result: 证明了SGD在期望平滑性条件下具有O(1/K)的收敛速率，并给出了显式残差误差表达式，统一并扩展了近期相关研究。

Conclusion: 期望平滑性条件为SGD收敛分析提供了更灵活的框架，本文的分析统一并推进了该领域的最新进展，所有证明细节完整呈现。

Abstract: Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

</details>


### [78] [Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets](https://arxiv.org/abs/2510.20609)
*Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov*

Main category: cs.LG

TL;DR: 本文系统研究了代码生成任务中的检索设计，发现在编程语言到编程语言(PL-PL)任务中，BM25稀疏检索效果最佳且速度更快；在自然语言到编程语言(NL-PL)任务中，密集检索器效果更好但延迟高100倍。最佳检索块大小随上下文窗口变化，简单行级分块与语法感知分块效果相当。


<details>
  <summary>Details</summary>
Motivation: 研究在现实计算预算下代码生成任务的检索设计优化，为构建高效的代码导向RAG系统提供实证依据。

Method: 使用Long Code Arena中的代码补全和错误定位任务，系统比较不同上下文窗口大小下的检索配置，包括分块策略、相似性评分和分割粒度三个维度。

Result: BM25稀疏检索在PL-PL任务中显著优于密集检索且速度快一个数量级；密集检索在NL-PL任务中表现更好但延迟高100倍；32-64行分块在小预算下最优，16000 tokens时整文件检索具有竞争力；行级分块与语法感知分块效果相当；不同配置间检索延迟差异达200倍。

Conclusion: 为代码导向RAG系统提供了基于任务需求、模型约束和计算效率的实证建议，BM25+词级分割提供了最佳的质量-延迟权衡。

Abstract: We study retrieval design for code-focused generation tasks under realistic
compute budgets. Using two complementary tasks from Long Code Arena -- code
completion and bug localization -- we systematically compare retrieval
configurations across various context window sizes along three axes: (i)
chunking strategy, (ii) similarity scoring, and (iii) splitting granularity.
(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and
practical, significantly outperforming dense alternatives while being an order
of magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3
family) consistently beat sparse retrievers, however requiring 100x larger
latency. (3) Optimal chunk size scales with available context: 32-64 line
chunks work best at small budgets, and whole-file retrieval becomes competitive
at 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting
across budgets. (5) Retrieval latency varies by up to 200x across
configurations; BPE-based splitting is needlessly slow, and BM25 + word
splitting offers the best quality-latency trade-off. Thus, we provide
evidence-based recommendations for implementing effective code-oriented RAG
systems based on task requirements, model constraints, and computational
efficiency.

</details>


### [79] [PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection](https://arxiv.org/abs/2510.20611)
*Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: 提出了一种集成定制粒子群优化(PSO)进行特征选择的框架，在乳腺癌诊断中实现了99.1%的准确率，同时通过可解释AI方法确保临床相关性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性中最常见且致命的癌症，传统诊断方法存在变异大、成本高和误诊风险等问题，需要更准确可靠的诊断工具。

Method: 使用定制PSO进行特征选择，评估了29种不同模型（包括经典分类器、集成技术、神经网络等），结合交叉验证和可解释AI方法。

Result: 在所有性能指标上达到99.1%的优异分数，有效降低维度并提供透明的模型无关解释。

Conclusion: 结合群体智能和可解释机器学习具有在乳腺癌诊断中实现稳健、可信赖且临床有意义结果的潜力。

Abstract: Breast cancer is considered the most critical and frequently diagnosed cancer
in women worldwide, leading to an increase in cancer-related mortality. Early
and accurate detection is crucial as it can help mitigate possible threats
while improving survival rates. In terms of prediction, conventional diagnostic
methods are often limited by variability, cost, and, most importantly, risk of
misdiagnosis. To address these challenges, machine learning (ML) has emerged as
a powerful tool for computer-aided diagnosis, with feature selection playing a
vital role in improving model performance and interpretability. This research
study proposes an integrated framework that incorporates customized Particle
Swarm Optimization (PSO) for feature selection. This framework has been
evaluated on a comprehensive set of 29 different models, spanning classical
classifiers, ensemble techniques, neural networks, probabilistic algorithms,
and instance-based algorithms. To ensure interpretability and clinical
relevance, the study uses cross-validation in conjunction with explainable AI
methods. Experimental evaluation showed that the proposed approach achieved a
superior score of 99.1\% across all performance metrics, including accuracy and
precision, while effectively reducing dimensionality and providing transparent,
model-agnostic explanations. The results highlight the potential of combining
swarm intelligence with explainable ML for robust, trustworthy, and clinically
meaningful breast cancer diagnosis.

</details>


### [80] [MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation](https://arxiv.org/abs/2510.20615)
*Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen*

Main category: cs.LG

TL;DR: MS-BART是一个统一建模框架，通过大规模预训练将质谱和分子结构映射到共享词汇表中，解决了质谱数据稀缺问题，在多个关键指标上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 质谱在分子识别中至关重要，但由于标注谱图稀缺，从质谱数据中解析结构仍然具有挑战性。现有的大规模预训练方法难以直接应用于质谱领域，因为原始谱信号的复杂性和异质性。

Method: 提出MS-BART框架：1）将质谱和分子结构映射到共享词汇表；2）通过大规模预训练进行跨模态学习；3）多任务预训练目标联合优化去噪和翻译任务；4）通过MIST生成指纹预测进行微调；5）引入化学反馈机制减少分子幻觉。

Result: 在MassSpecGym和NPLIB1的12个关键指标中，MS-BART在5个指标上达到SOTA性能，比基于扩散的竞争方法快一个数量级，消融实验验证了模型的有效性和鲁棒性。

Conclusion: MS-BART通过统一的跨模态预训练框架有效解决了质谱数据稀缺问题，结合化学反馈机制显著提升了分子结构解析的准确性和效率。

Abstract: Mass spectrometry (MS) plays a critical role in molecular identification,
significantly advancing scientific discovery. However, structure elucidation
from MS data remains challenging due to the scarcity of annotated spectra.
While large-scale pretraining has proven effective in addressing data scarcity
in other domains, applying this paradigm to mass spectrometry is hindered by
the complexity and heterogeneity of raw spectral signals. To address this, we
propose MS-BART, a unified modeling framework that maps mass spectra and
molecular structures into a shared token vocabulary, enabling cross-modal
learning through large-scale pretraining on reliably computed
fingerprint-molecule datasets. Multi-task pretraining objectives further
enhance MS-BART's generalization by jointly optimizing denoising and
translation task. The pretrained model is subsequently transferred to
experimental spectra through finetuning on fingerprint predictions generated
with MIST, a pre-trained spectral inference model, thereby enhancing robustness
to real-world spectral variability. While finetuning alleviates the
distributional difference, MS-BART still suffers molecular hallucination and
requires further alignment. We therefore introduce a chemical feedback
mechanism that guides the model toward generating molecules closer to the
reference structure. Extensive evaluations demonstrate that MS-BART achieves
SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is
faster by one order of magnitude than competing diffusion-based methods, while
comprehensive ablation studies systematically validate the model's
effectiveness and robustness.

</details>


### [81] [On Optimal Hyperparameters for Differentially Private Deep Transfer Learning](https://arxiv.org/abs/2510.20616)
*Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela*

Main category: cs.LG

TL;DR: 本文分析了差分隐私迁移学习中的两个关键超参数：梯度裁剪边界C和批大小B。研究发现理论选择（强隐私需要小C）与实证结果（强隐私下大C表现更好）存在不匹配，并揭示了现有批大小调优启发式方法无效，而累积DP噪声能更好解释批大小选择。


<details>
  <summary>Details</summary>
Motivation: 差分隐私迁移学习是目前在隐私约束下训练大模型的最先进方法，但对关键超参数C和B的选择缺乏系统理解，存在理论与实践的脱节。

Method: 通过分析梯度分布变化、将梯度裁剪视为梯度重加权形式，以及考察累积DP噪声的影响，来研究C和B参数的选择机制。

Result: 发现强隐私约束下大C表现更好，与理论预期相反；现有批大小调优启发式方法无效，累积DP噪声能更好解释批大小选择；跨任务使用单一(C,B)设置会导致性能下降。

Conclusion: 需要重新审视差分隐私迁移学习中的超参数选择策略，特别关注梯度分布变化和累积DP噪声的影响，避免跨任务使用单一参数设置。

Abstract: Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained
model on private data, is the current state-of-the-art approach for training
large models under privacy constraints. We focus on two key hyperparameters in
this setting: the clipping bound $C$ and batch size $B$. We show a clear
mismatch between the current theoretical understanding of how to choose an
optimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes
(larger $C$ performs better under strong privacy), caused by changes in the
gradient distributions. Assuming a limited compute budget (fixed epochs), we
demonstrate that the existing heuristics for tuning $B$ do not work, while
cumulative DP noise better explains whether smaller or larger batches perform
better. We also highlight how the common practice of using a single $(C,B)$
setting across tasks can lead to suboptimal performance. We find that
performance drops especially when moving between loose and tight privacy and
between plentiful and limited compute, which we explain by analyzing clipping
as a form of gradient re-weighting and examining cumulative DP noise.

</details>


### [82] [H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition](https://arxiv.org/abs/2510.20627)
*Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis*

Main category: cs.LG

TL;DR: H-SPLID是一种通过显式分解显著和非显著特征到不同空间来学习显著特征表示的新算法，能够促进学习低维、任务相关的特征，并建立鲁棒性与潜在表示压缩之间的联系。


<details>
  <summary>Details</summary>
Motivation: 现有的特征学习方法往往不能明确区分显著和非显著特征，导致模型可能过度依赖非关键特征，影响模型的鲁棒性和泛化能力。

Method: 提出H-SPLID算法，将显著和非显著特征显式分解到不同的表示空间中，利用Hilbert-Schmidt独立性准则(HSIC)建立输入扰动下的预测偏差与显著子空间维度之间的关系。

Result: 在图像分类任务上的实验表明，使用H-SPLID训练的模型主要依赖显著输入成分，对影响非显著特征（如图像背景）的扰动表现出较低的敏感性。

Conclusion: H-SPLID能够有效促进学习低维、任务相关的显著特征表示，并建立了模型鲁棒性与潜在表示压缩之间的理论联系，为构建更鲁棒的机器学习模型提供了新思路。

Abstract: We introduce H-SPLID, a novel algorithm for learning salient feature
representations through the explicit decomposition of salient and non-salient
features into separate spaces. We show that H-SPLID promotes learning
low-dimensional, task-relevant features. We prove that the expected prediction
deviation under input perturbations is upper-bounded by the dimension of the
salient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between
inputs and representations. This establishes a link between robustness and
latent representation compression in terms of the dimensionality and
information preserved. Empirical evaluations on image classification tasks show
that models trained with H-SPLID primarily rely on salient input components, as
indicated by reduced sensitivity to perturbations affecting non-salient
features, such as image backgrounds. Our code is available at
https://github.com/neu-spiral/H-SPLID.

</details>


### [83] [Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach](https://arxiv.org/abs/2510.20629)
*Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu*

Main category: cs.LG

TL;DR: 提出了一种公平感知生存建模方法FASM，旨在减轻生存分析中的算法偏见，特别是在组内和跨组风险排名方面，应用于乳腺癌预后数据取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在医疗保健中的应用日益增多，但临床数据中的结构性不平等和社会偏见可能被数据驱动模型延续甚至放大。生存分析中的删失和时间动态进一步增加了公平模型开发的复杂性。现有公平方法往往忽视跨组排名差异，可能导致高风险黑人患者被排在低风险白人患者之后，强化生物本质主义并破坏公平护理。

Method: 提出了公平感知生存建模方法FASM，专门设计用于减轻关于组内和跨组风险排名随时间变化的算法偏见。使用乳腺癌预后作为代表性案例，并将FASM应用于SEER乳腺癌数据。

Result: FASM显著提高了公平性，同时保持了与无公平意识生存模型相当的判别性能。时间分层评估显示，FASM在10年时间范围内保持稳定的公平性，在随访中期观察到最大的改进效果。

Conclusion: 该方法使得开发既优先考虑准确性又注重公平性的生存模型成为可能，将公平性作为临床护理的核心原则向前推进。

Abstract: As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.

</details>


### [84] [Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges](https://arxiv.org/abs/2510.20637)
*Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim*

Main category: cs.LG

TL;DR: 该论文概述了基于大语言模型(LLMs)和大规模多模态模型(LMMs)的任务导向自主通信系统，展示了在6G机器间通信中的潜力，并通过三个案例研究验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs/LMMs在自然语言理解和复杂推理方面的突破性能力，将其作为6G自主通信的关键赋能技术，解决机器、车辆和人形机器人之间的智能通信需求。

Method: 提出基于LLMs/LMMs的自主通信框架，集成多模态感知、自适应重构以及针对无线任务的提示/微调策略，通过三个案例研究（LMM交通控制、LLM机器人调度、LMM环境感知信道估计）进行验证。

Result: 实验结果表明，所提出的LLM/LMM辅助自主系统显著优于传统方法和判别性深度学习模型，在动态目标、变化输入参数和异构多模态条件下保持鲁棒性。

Conclusion: LLMs/LMMs在6G自主通信中具有巨大潜力，能够克服传统静态优化的局限性，为未来智能通信系统提供有效解决方案。

Abstract: Large language models (LLMs) and large multimodal models (LMMs) have achieved
unprecedented breakthrough, showcasing remarkable capabilities in natural
language understanding, generation, and complex reasoning. This transformative
potential has positioned them as key enablers for 6G autonomous communications
among machines, vehicles, and humanoids. In this article, we provide an
overview of task-oriented autonomous communications with LLMs/LMMs, focusing on
multimodal sensing integration, adaptive reconfiguration, and
prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework
through three case studies: LMM-based traffic control, LLM-based robot
scheduling, and LMM-based environment-aware channel estimation. From
experimental results, we show that the proposed LLM/LMM-aided autonomous
systems significantly outperform conventional and discriminative deep learning
(DL) model-based techniques, maintaining robustness under dynamic objectives,
varying input parameters, and heterogeneous multimodal conditions where
conventional static optimization degrades.

</details>


### [85] [Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems](https://arxiv.org/abs/2510.20640)
*Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan*

Main category: cs.LG

TL;DR: DiRecGNN是一个用于微软云服务监控的注意力增强实体推荐框架，通过构建监控异构图并使用多头注意力机制来推荐最优监控属性子集，在MRR指标上提升43.1%，获得用户4.5/5的高评分。


<details>
  <summary>Details</summary>
Motivation: 云服务监控中，实体交互动态通常具有有限的结构和参与信息，导致现有方法性能不佳；传统方法因同质性无法捕捉长距离实体依赖关系。

Method: 构建生产级监控异构图，提出基于Transformer架构的注意力增强实体排序模型，使用多头注意力关注异质邻居及其属性，通过随机游走采样路径捕捉长距离依赖，采用多面损失函数优化推荐。

Result: 实证评估显示模型显著优于现有方法，MRR提升43.1%；产品团队认为该功能有用，评分4.5/5。

Conclusion: DiRecGNN框架成功解决了云服务监控中的实体推荐问题，通过注意力机制有效捕捉复杂依赖关系，在实际部署中获得良好用户反馈。

Abstract: In this paper, we present DiRecGNN, an attention-enhanced entity
recommendation framework for monitoring cloud services at Microsoft. We provide
insights on the usefulness of this feature as perceived by the cloud service
owners and lessons learned from deployment. Specifically, we introduce the
problem of recommending the optimal subset of attributes (dimensions) that
should be tracked by an automated watchdog (monitor) for cloud services. To
begin, we construct the monitor heterogeneous graph at production-scale. The
interaction dynamics of these entities are often characterized by limited
structural and engagement information, resulting in inferior performance of
state-of-the-art approaches. Moreover, traditional methods fail to capture the
dependencies between entities spanning a long range due to their homophilic
nature. Therefore, we propose an attention-enhanced entity ranking model
inspired by transformer architectures. Our model utilizes a multi-head
attention mechanism to focus on heterogeneous neighbors and their attributes,
and further attends to paths sampled using random walks to capture long-range
dependencies. We also employ multi-faceted loss functions to optimize for
relevant recommendations while respecting the inherent sparsity of the data.
Empirical evaluations demonstrate significant improvements over existing
methods, with our model achieving a 43.1% increase in MRR. Furthermore, product
teams who consumed these features perceive the feature as useful and rated it
4.5 out of 5.

</details>


### [86] [Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning](https://arxiv.org/abs/2510.20644)
*Reuben Dorent,Polina Golland,William Wells III*

Main category: cs.LG

TL;DR: 本文推导了一个新的、紧致的、可处理的Jensen-Shannon散度(JSD)与Kullback-Leibler散度(KLD)之间的下界，证明了最大化JSD能保证增加互信息的下界，为基于判别学习的互信息表示学习提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 互信息是表示学习中的重要统计依赖度量，但直接优化KLD往往难以处理。许多方法转而最大化替代依赖度量如JSD，但这些替代目标与互信息的关系尚不清楚。

Method: 推导了JSD与KLD之间新的紧致下界，通过最小化二元分类器的交叉熵损失来恢复JSD的变分下界，并开发了相应的互信息下界估计器。

Result: 实验表明该下界在互信息估计中具有紧致性，相比现有变分下界估计器，能提供稳定、低方差的紧致下界估计，并在信息瓶颈框架中展示了实用性。

Conclusion: 研究结果为基于判别学习的互信息表示学习提供了新的理论依据和强有力的实证证据，证明了最大化JSD确实能保证增加互信息的下界。

Abstract: Mutual Information (MI) is a fundamental measure of statistical dependence
widely used in representation learning. While direct optimization of MI via its
definition as a Kullback-Leibler divergence (KLD) is often intractable, many
recent methods have instead maximized alternative dependence measures, most
notably, the Jensen-Shannon divergence (JSD) between joint and product of
marginal distributions via discriminative losses. However, the connection
between these surrogate objectives and MI remains poorly understood. In this
work, we bridge this gap by deriving a new, tight, and tractable lower bound on
KLD as a function of JSD in the general case. By specializing this bound to
joint and marginal distributions, we demonstrate that maximizing the JSD-based
information increases a guaranteed lower bound on mutual information.
Furthermore, we revisit the practical implementation of JSD-based objectives
and observe that minimizing the cross-entropy loss of a binary classifier
trained to distinguish joint from marginal pairs recovers a known variational
lower bound on the JSD. Extensive experiments demonstrate that our lower bound
is tight when applied to MI estimation. We compared our lower bound to
state-of-the-art neural estimators of variational lower bound across a range of
established reference scenarios. Our lower bound estimator consistently
provides a stable, low-variance estimate of a tight lower bound on MI. We also
demonstrate its practical usefulness in the context of the Information
Bottleneck framework. Taken together, our results provide new theoretical
justifications and strong empirical evidence for using discriminative learning
in MI-based representation learning.

</details>


### [87] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: xTime是一个用于时间序列极端事件预测的新框架，通过知识蒸馏和专家混合机制，显著提高了对罕见极端事件的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列中的极端事件（如洪水、热浪、医疗急症）具有重要实际意义，但现有模型因数据不平衡和忽视中间事件信息而难以准确预测这些事件。

Method: 提出xTime框架，利用知识蒸馏从低稀有度事件模型中传递信息，并引入专家混合机制动态选择和融合不同稀有度级别的专家模型输出。

Result: 在多个数据集上的实验表明，xTime实现了持续改进，极端事件的预测准确率从3%提升到78%。

Conclusion: xTime通过知识蒸馏和专家混合机制有效解决了极端事件预测中的数据不平衡问题，显著提升了预测性能。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [88] [Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts](https://arxiv.org/abs/2510.20666)
*Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas*

Main category: cs.LG

TL;DR: 提出了一种混合贝叶斯专家混合框架，结合物理路径损耗模型和卷积神经网络，通过对数线性池化融合，用于GNSS干扰源定位和信号强度场重建。


<details>
  <summary>Details</summary>
Motivation: GNSS信号在城市环境中易受干扰，现有数据驱动方法定位精度尚可但信号强度场重建效果差，主要受限于空间上下文信息不足。

Method: 使用贝叶斯混合专家框架，融合物理路径损耗模型和CNN网络，CNN利用建筑高度图捕捉城市传播效应，通过贝叶斯推理和拉普拉斯近似提供后验不确定性。

Result: 在城市射线追踪数据上的实验表明，随着训练点增加，定位精度提高且不确定性降低，不确定性集中在干扰源附近和城市峡谷等传播敏感区域。

Conclusion: 该方法能有效结合物理模型和数据驱动方法的优势，在GNSS干扰源定位和信号强度场重建方面表现出色，并能提供有意义的空间不确定性估计。

Abstract: Global Navigation Satellite System (GNSS) signals are vulnerable to jamming,
particularly in urban areas where multipath and shadowing distort received
power. Previous data-driven approaches achieved reasonable localization but
poorly reconstructed the received signal strength (RSS) field due to limited
spatial context. We propose a hybrid Bayesian mixture-of-experts framework that
fuses a physical path-loss (PL) model and a convolutional neural network (CNN)
through log-linear pooling. The PL expert ensures physical consistency, while
the CNN leverages building-height maps to capture urban propagation effects.
Bayesian inference with Laplace approximation provides posterior uncertainty
over both the jammer position and RSS field. Experiments on urban ray-tracing
data show that localization accuracy improves and uncertainty decreases with
more training points, while uncertainty concentrates near the jammer and along
urban canyons where propagation is most sensitive.

</details>


### [89] [From Masks to Worlds: A Hitchhiker's Guide to World Models](https://arxiv.org/abs/2510.20668)
*Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang*

Main category: cs.LG

TL;DR: 这是一篇关于构建世界模型的指南性综述，重点关注生成模型、交互循环和记忆系统这三个核心要素的发展路径。


<details>
  <summary>Details</summary>
Motivation: 为想要构建世界模型的研究者提供一条清晰的发展路线，而不是简单地罗列所有相关论文。

Method: 遵循一条明确的发展路径：从早期跨模态统一表示学习的掩码模型，到共享单一范式的统一架构，再到闭合感知-行动循环的交互式生成模型，最后到维持时间一致性的记忆增强系统。

Result: 展示了从掩码模型到统一架构，再到交互式生成模型和记忆系统的演进过程。

Conclusion: 生成核心、交互循环和记忆系统是构建真正世界模型最有前景的发展路径。

Abstract: This is not a typical survey of world models; it is a guide for those who
want to build worlds. We do not aim to catalog every paper that has ever
mentioned a ``world model". Instead, we follow one clear road: from early
masked models that unified representation learning across modalities, to
unified architectures that share a single paradigm, then to interactive
generative models that close the action-perception loop, and finally to
memory-augmented systems that sustain consistent worlds over time. We bypass
loosely related branches to focus on the core: the generative heart, the
interactive loop, and the memory system. We show that this is the most
promising path towards true world models.

</details>


### [90] [GRACE: GRaph-based Addiction Care prEdiction](https://arxiv.org/abs/2510.20671)
*Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee*

Main category: cs.LG

TL;DR: 提出一种名为GRACE的图神经网络框架，用于解决成瘾治疗患者护理场所预测中的类别不平衡问题，通过特征工程和无偏元图训练方法，在真实数据上显著提升了少数类别的F1分数。


<details>
  <summary>Details</summary>
Motivation: 成瘾治疗中确定合适的护理场所是关键临床决策，但现有方法面临数据集严重类别不平衡的问题，且缺乏专门的自动化框架来有效利用有限资源。

Method: 提出GRACE图神经网络框架，将护理场所预测形式化为结构化学习问题，进行广泛特征工程，并开发无偏元图训练方法来克服类别不平衡。

Result: 在真实世界数据上的实验结果显示，相比竞争基线方法，少数类别的F1分数提升了11-35%。

Conclusion: GRACE框架通过结构化学习和无偏元图训练，有效解决了成瘾治疗数据集中的类别不平衡问题，为自动化护理场所决策提供了可行方案。

Abstract: Determining the appropriate locus of care for addiction patients is one of
the most critical clinical decisions that affects patient treatment outcomes
and effective use of resources. With a lack of sufficient specialized treatment
resources, such as inpatient beds or staff, there is an unmet need to develop
an automated framework for the same. Current decision-making approaches suffer
from severe class imbalances in addiction datasets. To address this limitation,
we propose a novel graph neural network (GRACE) framework that formalizes locus
of care prediction as a structured learning problem. Further, we perform
extensive feature engineering and propose a new approach of obtaining an
unbiased meta-graph to train a GNN to overcome the class imbalance problem.
Experimental results in real-world data show an improvement of 11-35% in terms
of the F1 score of the minority class over competitive baselines. The codes and
note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.

</details>


### [91] [A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks](https://arxiv.org/abs/2510.20683)
*Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale*

Main category: cs.LG

TL;DR: Spikachu是一个基于脉冲神经网络(SNN)的可扩展、因果性和高能效的神经解码框架，在非人灵长类动物的神经记录数据上表现优于因果基线模型，同时能耗降低2.26-418.81倍。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的神经解码方法存在两个问题：简单的因果模型缺乏泛化能力，复杂的非因果模型虽然能泛化但难以实时应用，且都依赖能耗高的人工神经网络，难以集成到资源受限的现实系统中。

Method: 提出Spikachu框架，直接将分箱的脉冲投影到共享潜在空间，通过适应输入时序的脉冲模块提取相关特征，然后整合这些潜在表示并解码生成行为预测。

Result: 在6只非人灵长类动物的113个记录会话（总计43小时记录）上评估，该方法在单会话训练时优于因果基线，能耗降低2.26-418.81倍。扩展到多会话和多主体训练时，性能进一步提升，并能实现对新会话、主体和任务的少样本迁移。

Conclusion: Spikachu引入了一个基于SNN的可扩展、在线兼容的神经解码框架，其性能与最先进模型相当，同时能耗降低数个数量级。

Abstract: Brain-computer interfaces (BCIs) promise to enable vital functions, such as
speech and prosthetic control, for individuals with neuromotor impairments.
Central to their success are neural decoders, models that map neural activity
to intended behavior. Current learning-based decoding approaches fall into two
classes: simple, causal models that lack generalization, or complex, non-causal
models that generalize and scale offline but struggle in real-time settings.
Both face a common challenge, their reliance on power-hungry artificial neural
network backbones, which makes integration into real-world, resource-limited
systems difficult. Spiking neural networks (SNNs) offer a promising
alternative. Because they operate causally these models are suitable for
real-time use, and their low energy demands make them ideal for
battery-constrained environments. To this end, we introduce Spikachu: a
scalable, causal, and energy-efficient neural decoding framework based on SNNs.
Our approach processes binned spikes directly by projecting them into a shared
latent space, where spiking modules, adapted to the timing of the input,
extract relevant features; these latent representations are then integrated and
decoded to generate behavioral predictions. We evaluate our approach on 113
recording sessions from 6 non-human primates, totaling 43 hours of recordings.
Our method outperforms causal baselines when trained on single sessions using
between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that
scaling up training to multiple sessions and subjects improves performance and
enables few-shot transfer to unseen sessions, subjects, and tasks. Overall,
Spikachu introduces a scalable, online-compatible neural decoding framework
based on SNNs, whose performance is competitive relative to state-of-the-art
models while consuming orders of magnitude less energy.

</details>


### [92] [Separating the what and how of compositional computation to enable reuse and continual learning](https://arxiv.org/abs/2510.20709)
*Haozhe Shan,Sun Minni,Lea Duncker*

Main category: cs.LG

TL;DR: 本文提出了一种双系统方法来解决持续学习和技能组合问题：一个系统推断要执行什么计算，另一个系统实现如何执行。该方法通过概率生成模型描述任务组合性，并使用无监督在线学习构建任务词汇表，在RNN中实现低秩组件的组合重用，避免了灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 研究持续学习和灵活组合技能的神经机制，解决智能体如何不断学习、保持并部署技能来实现目标的问题，现有方法在任务组合性和避免灾难性遗忘方面存在挑战。

Method: 采用双系统方法：1) "what"系统通过概率生成模型描述任务组合性，使用无监督在线学习构建任务词汇表；2) "how"系统作为RNN，根据what系统推断的上下文组合低秩组件。通过上下文推断促进新任务引入时的组件创建、学习和重用。

Result: 该方法在示例任务集上表现出有效性和竞争性性能，具有前向和后向迁移潜力，能够快速组合泛化到未见过的任务，实现了持续学习而不发生灾难性遗忘。

Conclusion: 双系统学习框架通过分离计算推断和实现，利用任务组合性和上下文推断，为持续学习和技能组合提供了有效的解决方案，展示了在认知任务中的良好应用前景。

Abstract: The ability to continually learn, retain and deploy skills to accomplish
goals is a key feature of intelligent and efficient behavior. However, the
neural mechanisms facilitating the continual learning and flexible
(re-)composition of skills remain elusive. Here, we study continual learning
and the compositional reuse of learned computations in recurrent neural network
(RNN) models using a novel two-system approach: one system that infers what
computation to perform, and one that implements how to perform it. We focus on
a set of compositional cognitive tasks commonly studied in neuroscience. To
construct the what system, we first show that a large family of tasks can be
systematically described by a probabilistic generative model, where
compositionality stems from a shared underlying vocabulary of discrete task
epochs. The shared epoch structure makes these tasks inherently compositional.
We first show that this compositionality can be systematically described by a
probabilistic generative model. Furthermore, We develop an unsupervised online
learning approach that can learn this model on a single-trial basis, building
its vocabulary incrementally as it is exposed to new tasks, and inferring the
latent epoch structure as a time-varying computational context within a trial.
We implement the how system as an RNN whose low-rank components are composed
according to the context inferred by the what system. Contextual inference
facilitates the creation, learning, and reuse of low-rank RNN components as new
tasks are introduced sequentially, enabling continual learning without
catastrophic forgetting. Using an example task set, we demonstrate the efficacy
and competitive performance of this two-system learning framework, its
potential for forward and backward transfer, as well as fast compositional
generalization to unseen tasks.

</details>


### [93] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动建模方法改进约翰霍普金斯跌倒风险评估工具(JHFRAT)，结合临床知识和电子健康记录变量，使用约束评分优化模型显著提升了跌倒风险预测性能。


<details>
  <summary>Details</summary>
Motivation: 旨在将JHFRAT跌倒风险预测与更多临床有意义指标对齐，通过数据驱动方法改进现有风险评估工具。

Method: 对54,209例住院患者进行回顾性分析，使用约束评分优化(CSO)模型结合JHFRAT评估数据和EHR变量，并与XGBoost基准模型对比。

Result: CSO模型预测性能显著优于当前JHFRAT(AUC-ROC=0.91 vs 0.86)，虽然XGBoost性能更好(AUC-ROC=0.94)，但CSO对风险标签变化更具鲁棒性。

Conclusion: 这种基于证据的方法为医疗系统提供了坚实基础，可使用数据驱动优化技术系统性地改进住院患者跌倒预防方案和患者安全。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [94] [Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2510.20718)
*Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder*

Main category: cs.LG

TL;DR: 该论文提出了两种新颖的异常预测方法，从传统的异常检测转向异常预测，使用N-BEATS模型和基于图神经网络的方法来预测半导体制造过程中的故障。


<details>
  <summary>Details</summary>
Motivation: 半导体制造过程极其复杂且精度要求高，存在高维传感器数据、严重的类别不平衡以及变量间复杂依赖关系等挑战，需要从异常检测转向异常预测以实现实时过程校正和主动故障预防。

Method: 提出两阶段异常预测框架：(1)在无异常数据集上训练预测模型；(2)对未见时间序列数据进行预测，与训练信号预测比较，超出阈值的偏差标记为异常。使用N-BEATS（假设变量独立）和图神经网络（捕获变量间关系）两种预测模型。

Result: 两种模型在20个时间点内表现出强大的预测性能，在50个时间点内保持稳定的异常预测。图神经网络始终优于N-BEATS模型，且需要更少的可训练参数和更低的计算成本。

Conclusion: 图神经网络作为有前景的在线异常预测解决方案，适合部署在制造环境中。

Abstract: Semiconductor manufacturing is an extremely complex and precision-driven
process, characterized by thousands of interdependent parameters collected
across diverse tools and process steps. Multi-variate time-series analysis has
emerged as a critical field for real-time monitoring and fault detection in
such environments. However, anomaly prediction in semiconductor fabrication
presents several critical challenges, including high dimensionality of sensor
data and severe class imbalance due to the rarity of true faults. Furthermore,
the complex interdependencies between variables complicate both anomaly
prediction and root-cause-analysis. This paper proposes two novel approaches to
advance the field from anomaly detection to anomaly prediction, an essential
step toward enabling real-time process correction and proactive fault
prevention. The proposed anomaly prediction framework contains two main stages:
(a) training a forecasting model on a dataset assumed to contain no anomalies,
and (b) performing forecast on unseen time series data. The forecast is
compared with the forecast of the trained signal. Deviations beyond a
predefined threshold are flagged as anomalies. The two approaches differ in the
forecasting model employed. The first assumes independence between variables by
utilizing the N-BEATS model for univariate time series forecasting. The second
lifts this assumption by utilizing a Graph Neural Network (GNN) to capture
inter-variable relationships. Both models demonstrate strong forecasting
performance up to a horizon of 20 time points and maintain stable anomaly
prediction up to 50 time points. The GNN consistently outperforms the N-BEATS
model while requiring significantly fewer trainable parameters and lower
computational cost. These results position the GNN as promising solution for
online anomaly forecasting to be deployed in manufacturing environments.

</details>


### [95] [No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes](https://arxiv.org/abs/2510.20725)
*Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek*

Main category: cs.LG

TL;DR: 该论文为具有高斯边际分布的Thompson采样在强化学习中的理论分析，证明了在具有联合高斯过程先验的episodic RL中的遗憾界。


<details>
  <summary>Details</summary>
Motivation: Thompson采样在序列决策中应用广泛，但在强化学习等具有复杂时间结构的场景中理论基础有限，需要建立更严格的理论保证。

Method: 使用具有联合高斯过程先验的episodic强化学习框架，分析Thompson采样算法，扩展椭圆势引理到多输出设置，处理价值函数的非高斯性和Bellman更新的递归结构。

Result: 证明了遗憾界为$\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$，其中$K$是episode数，$H$是时间步长，$\Gamma(\cdot)$捕获GP模型的复杂度。

Conclusion: 这项工作推进了对Thompson采样在强化学习中性能的理解，展示了结构假设和模型不确定性如何影响其在有限时域马尔可夫决策过程中的表现。

Abstract: Thompson sampling (TS) is a powerful and widely used strategy for sequential
decision-making, with applications ranging from Bayesian optimization to
reinforcement learning (RL). Despite its success, the theoretical foundations
of TS remain limited, particularly in settings with complex temporal structure
such as RL. We address this gap by establishing no-regret guarantees for TS
using models with Gaussian marginal distributions. Specifically, we consider TS
in episodic RL with joint Gaussian process (GP) priors over rewards and
transitions. We prove a regret bound of
$\mathcal{\tilde{O}}(\sqrt{KH\Gamma(KH)})$ over $K$ episodes of horizon $H$,
where $\Gamma(\cdot)$ captures the complexity of the GP model. Our analysis
addresses several challenges, including the non-Gaussian nature of value
functions and the recursive structure of Bellman updates, and extends classical
tools such as the elliptical potential lemma to multi-output settings. This
work advances the understanding of TS in RL and highlights how structural
assumptions and model uncertainty shape its performance in finite-horizon
Markov Decision Processes.

</details>


### [96] [Thought Communication in Multiagent Collaboration](https://arxiv.org/abs/2510.20733)
*Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang*

Main category: cs.LG

TL;DR: 提出了"思维通信"新范式，让AI代理直接进行思维层面的交流，超越自然语言的限制，通过潜变量模型识别共享和私有思维，提升集体智能。


<details>
  <summary>Details</summary>
Motivation: 自然语言存在歧义性和间接性，限制了集体智能的潜力。虽然机器不受这些限制，但现有的多代理系统仍主要依赖自然语言交流。

Method: 将思维通信形式化为潜变量模型，证明在非参数设置下可以识别共享和私有思维，开发框架提取所有代理的潜在思维并分配相关思维及其共享模式。

Result: 在合成和真实世界基准测试中验证了理论，展示了思维通信在协作中的优势。

Conclusion: 思维通信范式揭示了利用隐藏世界的潜力，许多挑战仅通过表面观察无法解决，无论计算或数据规模如何。

Abstract: Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

</details>


### [97] [Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](https://arxiv.org/abs/2510.20736)
*Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种基于狄利克雷过程的多模态学习框架，通过DP的富者愈富特性自动平衡模态内特征学习和跨模态对齐，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态融合中如何在保持各模态特征表达能力的同时学习跨模态交互的挑战，避免过度强调模态边际分布对齐导致的过度正则化问题。

Method: 假设每个模态遵循多元高斯混合分布，采用狄利克雷过程计算各分量的混合权重，利用DP的富者愈富特性动态分配特征贡献并选择最显著特征。

Result: 在多个多模态数据集上的广泛实验表明，该模型优于其他竞争方法，消融分析验证了DP在模态分布对齐中的有效性及其对关键超参数变化的鲁棒性。

Conclusion: 提出的DP驱动多模态学习框架能够自动实现模态内表示学习和跨模态对齐的最佳平衡，为多模态特征融合提供了有效解决方案。

Abstract: Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

</details>


### [98] [MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs](https://arxiv.org/abs/2510.20762)
*Jan Sobotka,Luca Baroni,Ján Antolík*

Main category: cs.LG

TL;DR: MEIcoder是一种基于生物信息的解码方法，利用神经元特异性最兴奋输入(MEIs)、结构相似性指数损失和对抗训练，在小数据集上实现从V1区单细胞活动重建视觉刺激的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 灵长类或人类等生物数据稀缺，特别是高吞吐量记录技术难以应用，这对深度学习解码技术构成挑战。

Method: 使用神经元特异性MEIs、结构相似性指数损失和对抗训练，构建生物信息解码框架。

Result: 在160,000+样本的统一基准测试中，MEIcoder在仅1,000-2,500个神经元和少于1,000个训练数据点的情况下，能重建高保真自然图像，特别是在小数据集上表现优异。

Conclusion: 证明了在早期视觉系统中可靠解码的可行性，为神经科学和神经工程应用提供了实用见解。

Abstract: Decoding visual stimuli from neural population activity is crucial for
understanding the brain and for applications in brain-machine interfaces.
However, such biological data is often scarce, particularly in primates or
humans, where high-throughput recording techniques, such as two-photon imaging,
remain challenging or impossible to apply. This, in turn, poses a challenge for
deep learning decoding techniques. To overcome this, we introduce MEIcoder, a
biologically informed decoding method that leverages neuron-specific most
exciting inputs (MEIs), a structural similarity index measure loss, and
adversarial training. MEIcoder achieves state-of-the-art performance in
reconstructing visual stimuli from single-cell activity in primary visual
cortex (V1), especially excelling on small datasets with fewer recorded
neurons. Using ablation studies, we demonstrate that MEIs are the main drivers
of the performance, and in scaling experiments, we show that MEIcoder can
reconstruct high-fidelity natural-looking images from as few as 1,000-2,500
neurons and less than 1,000 training data points. We also propose a unified
benchmark with over 160,000 samples to foster future research. Our results
demonstrate the feasibility of reliable decoding in early visual system and
provide practical insights for neuroscience and neuroengineering applications.

</details>


### [99] [Out-of-distribution Tests Reveal Compositionality in Chess Transformers](https://arxiv.org/abs/2510.20783)
*Anna Mészáros,Patrik Reizinger,Ferenc Huszár*

Main category: cs.LG

TL;DR: 这篇论文研究了Transformer模型在象棋游戏中的系统泛化能力，发现模型能够进行组合泛化，在分布外场景中仍能遵循游戏规则，但在更具挑战性的变体（如Chess960）中表现不如符号AI算法。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型是否真正理解象棋规则，而不仅仅是学习训练数据中的模式，通过测试其在分布外场景中的表现来评估其系统泛化能力。

Method: 训练了一个2.7亿参数的象棋Transformer模型，并在多种分布外场景中进行测试，包括规则外推、OOD谜题和Chess960变体，同时分析训练动态。

Result: 模型展现出组合泛化能力，在规则外推和OOD谜题中表现良好；在Chess960中基本策略适应但不如符号AI；训练动态显示模型先学会移动己方棋子。

Conclusion: Transformer模型能够学习象棋的基本组合结构，在规则遵循方面表现出色，但在需要深度策略规划的复杂变体中仍落后于基于搜索的符号方法。

Abstract: Chess is a canonical example of a task that requires rigorous reasoning and
long-term planning. Modern decision Transformers - trained similarly to LLMs -
are able to learn competent gameplay, but it is unclear to what extent they
truly capture the rules of chess. To investigate this, we train a 270M
parameter chess Transformer and test it on out-of-distribution scenarios,
designed to reveal failures of systematic generalization. Our analysis shows
that Transformers exhibit compositional generalization, as evidenced by strong
rule extrapolation: they adhere to fundamental syntactic rules of the game by
consistently choosing valid moves even in situations very different from the
training data. Moreover, they also generate high-quality moves for OOD puzzles.
In a more challenging test, we evaluate the models on variants including
Chess960 (Fischer Random Chess) - a variant of chess where starting positions
of pieces are randomized. We found that while the model exhibits basic strategy
adaptation, they are inferior to symbolic AI algorithms that perform explicit
search, but gap is smaller when playing against users on Lichess. Moreover, the
training dynamics revealed that the model initially learns to move only its own
pieces, suggesting an emergent compositional understanding of the game.

</details>


### [100] [BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792)
*Liang Ye,Shengqin Chen,Jiazhu Dai*

Main category: cs.LG

TL;DR: BadGraph是一种针对文本引导图生成的潜在扩散模型的后门攻击方法，通过文本触发器毒化训练数据，在推理时植入攻击者指定的子图，同时保持对干净输入的正常性能。


<details>
  <summary>Details</summary>
Motivation: 随着图生成技术的快速发展，后门漏洞带来了新的安全担忧。虽然之前的工作探索了图像扩散和无条件图生成中的后门攻击，但条件性特别是文本引导的图生成仍然未被充分研究。

Method: BadGraph利用文本触发器毒化训练数据，在VAE和扩散训练期间秘密植入后门，当触发器出现时在推理过程中诱导攻击者指定的子图。

Result: 在四个基准数据集上的实验表明，攻击具有高效率和隐蔽性：不到10%的中毒率即可达到50%的攻击成功率，24%的中毒率足以实现超过80%的成功率，而对良性样本的性能影响可忽略不计。

Conclusion: 这些发现揭示了文本引导图生成的潜在扩散模型中的安全漏洞，突显了在药物发现等模型应用中的严重风险，并强调了对此类扩散模型中后门攻击进行鲁棒防御的必要性。

Abstract: The rapid progress of graph generation has raised new security concerns,
particularly regarding backdoor vulnerabilities. While prior work has explored
backdoor attacks in image diffusion and unconditional graph generation,
conditional, especially text-guided graph generation remains largely
unexamined. This paper proposes BadGraph, a backdoor attack method targeting
latent diffusion models for text-guided graph generation. BadGraph leverages
textual triggers to poison training data, covertly implanting backdoors that
induce attacker-specified subgraphs during inference when triggers appear,
while preserving normal performance on clean inputs. Extensive experiments on
four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the
effectiveness and stealth of the attack: less than 10% poisoning rate can
achieves 50% attack success rate, while 24% suffices for over 80% success rate,
with negligible performance degradation on benign samples. Ablation studies
further reveal that the backdoor is implanted during VAE and diffusion training
rather than pretraining. These findings reveal the security vulnerabilities in
latent diffusion models of text-guided graph generation, highlight the serious
risks in models' applications such as drug discovery and underscore the need
for robust defenses against the backdoor attack in such diffusion models.

</details>


### [101] [Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples](https://arxiv.org/abs/2510.20800)
*Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus*

Main category: cs.LG

TL;DR: 提出了一种快速、无需微调的LLM适应方法，通过选择性矩阵降维和梯度指导的层选择，在仅使用100个样本的情况下实现下游任务适应。


<details>
  <summary>Details</summary>
Motivation: LASER方法虽然能通过修剪权重矩阵的高阶组件来提升下游任务准确率，但其逐层搜索和全数据集前向传播的计算开销使其难以快速部署。

Method: 使用矩阵奇异值的梯度来识别需要降维的关键矩阵；允许矩阵行围绕多个子空间聚类并分别分解；仅使用100个样本计算梯度和评估准确率。

Result: 该方法消除了逐层扫描开销，减少了对原始训练数据的过拟合，准确率提升高达24.6个百分点，搜索时间大幅减少。

Conclusion: 结合这些发现可以构建快速、鲁棒的下游任务适应算法，仅需单次梯度步和100个样本即可完成LLM适应，无需微调。

Abstract: Recently, Sharma et al. suggested a method called Layer-SElective-Rank
reduction (LASER) which demonstrated that pruning high-order components of
carefully chosen LLM's weight matrices can boost downstream accuracy -- without
any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each
requiring full-dataset forward passes) makes it impractical for rapid
deployment. We demonstrate that this overhead can be removed and find that: (i)
Only a small, carefully chosen subset of matrices needs to be inspected --
eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's
singular values pinpoints which matrices merit reduction, (iii) Increasing the
factorization search space by allowing matrices rows to cluster around multiple
subspaces and then decomposing each cluster separately further reduces
overfitting on the original training data and further lifts accuracy by up to
24.6 percentage points, and finally, (iv) we discover that evaluating on just
100 samples rather than the full training data -- both for computing the
indicative gradients and for measuring the final accuracy -- suffices to
further reduce the search time; we explain that as adaptation to downstream
tasks is dominated by prompting style, not dataset size. As a result, we show
that combining these findings yields a fast and robust adaptation algorithm for
downstream tasks. Overall, with a single gradient step on 100 examples and a
quick scan of the top candidate layers and factorization techniques, we can
adapt LLMs to new datasets -- entirely without fine-tuning.

</details>


### [102] [KL-Regularized Reinforcement Learning is Designed to Mode Collapse](https://arxiv.org/abs/2510.20817)
*Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 论文挑战了关于KL散度优化的传统直觉，发现在强化学习中，反向/正向KL的选择主要决定最优目标分布的参数化形式，而模式覆盖更多取决于正则化强度等因素。作者提出了一个简单算法来优化目标分布，使其覆盖所有高质量采样模式。


<details>
  <summary>Details</summary>
Motivation: 传统认为反向KL导致"模式寻找"，正向KL导致"质量覆盖"，但这种直觉在强化学习中不一定成立。论文旨在澄清KL正则化在RL中的实际作用，并解决由此导致的多样性不足问题。

Method: 通过数学分析和实证研究，揭示了KL正则化的真实作用机制。然后构建了一个简单、可扩展的理论支持算法，只需最小化地调整奖励幅度，就能优化目标分布以覆盖所有高质量采样模式。

Result: 实验表明，该方法在大型语言模型和化学语言模型的后训练中都有效，提高了解决方案的质量和多样性，无需外部多样性信号，且同时适用于正向和反向KL。

Conclusion: KL正则化的选择主要影响目标分布的参数化，模式覆盖取决于其他因素。提出的简单修改能有效提升模型输出的质量和多样性，解决了传统方法在多样性方面的不足。

Abstract: It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [103] [Time-Dependent Black Hole Lensing and the Unified Weak-to-Strong Deflection Framework](https://arxiv.org/abs/2510.19849)
*Ali Övgün,Reggie C. Pantig*

Main category: gr-qc

TL;DR: 提出了一个统一弱场和强偏转引力透镜的全解析框架，在随时间变化的扰动史瓦西时空中分析光线偏转，揭示了准正则模式如何影响成像观测。


<details>
  <summary>Details</summary>
Motivation: 统一弱场和强偏转引力透镜理论，研究时变扰动对光线传播的影响，特别是准正则模式在成像观测中的印记。

Method: 使用轴对称偶宇称准正则模式（ℓ=2, m=0）扰动史瓦西时空，在一阶扰动近似下保持背景零测地线精确，推导时间相关的视线（Born）表达式。

Result: 得到了弱场1/b定律的准正则频率修正（驱动质心摆动）和对数强偏转极限的时间相关推广（包含临界撞击参数的小振荡）。

Conclusion: 建立了跨越不同区域的显式匹配，表明控制间距和环半径调制的近临界系数与弱场修正的Born核相同，提供了准正则物理在成像观测中印记的纯理论描述。

Abstract: We present a fully analytical framework that unifies weak-field and
strong-deflection lensing of light in a time-dependent, perturbed Schwarzschild
spacetime. The spacetime dynamics are modeled by a single, axisymmetric,
even-parity quasinormal mode with $\ell=2$, $m=0$ and complex frequency
$\omega$. Working to first order in a small perturbation amplitude while
keeping background null geodesics exact, we derive a time-dependent
line-of-sight (Born) expression for the screen-plane deflection measured by a
static observer at large radius. From the same integral, an asymptotic
expansion yields the familiar weak-field $1/b$ law with a ringdown-frequency
correction that drives a harmonic centroid wobble, whereas a near-photon-sphere
expansion produces a time-dependent generalization of the logarithmic
strong-deflection limit with modulated coefficients, including a small
oscillation of the critical impact parameter. An observer tetrad built from the
background static frame ensures that all screen-plane quantities like centroid
motion, multi-image hierarchy, and time delays, and photon-ring morphology are
gauge-safe at first order. We provide explicit matching across regimes, showing
that the near-critical coefficients governing spacing and ring-radius
modulations are encoded in the same Born kernel that controls the weak-field
correction. The result is a coherent, purely theoretical account of how
ringdown physics imprints on imaging observables without numerical ray tracing.

</details>


### [104] [Statistical Constraints on Anisotropic Bianchi-III Cosmology in $f(R,T)$-Gravity Using MCMC Methods](https://arxiv.org/abs/2510.19852)
*Mayur Mune,Praveen Kumar Dhankar,Safiqul Islam,Behnam Pourhassan,Muhammad Aamir,Faisal Haroon*

Main category: gr-qc

TL;DR: 该论文在f(R,T)引力框架下研究各向异性Bianchi III型宇宙学，通过MCMC方法使用观测数据约束模型参数，发现该模型能够很好地拟合当前观测数据。


<details>
  <summary>Details</summary>
Motivation: 研究f(R,T)引力中各向异性宇宙学模型的观测可行性，探索物质-几何耦合在晚期宇宙加速中的作用。

Method: 采用f(R,T)=R+2f(T)的具体形式，推导背景动力学精确解，使用MCMC方法和Hubble参数测量、BAO、Pantheon超新星等最新观测数据集进行统计分析。

Result: 各向异性Bianchi-III宇宙在f(R,T)引力中能够成功容纳当前观测数据，模型参数得到了约束，并与标准ΛCDM宇宙学进行了比较。

Conclusion: f(R,T)引力中的各向异性宇宙学模型为理解晚期宇宙加速提供了新的视角，物质-几何耦合在其中扮演重要角色。

Abstract: Anisotropic Bianchi type-III cosmology is examined within the framework of
f(R,T) gravity, where R denotes the Ricci scalar and T the trace of the
energy-momentum tensor. In this work, we investigate the statistical
constraints on anisotropic Bianchi type-III cosmology within the framework of
f(R,T) gravity. The specific choice $f(R,T)=R+2f(T)$ is considered and exact
solutions are derived for the background dynamics of the model. The physical
parameters, such as the Hubble parameter H(z), spatial volume V(z), energy
density $\rho(z)$, and pressure p(z), are derived and their evolutionary
behaviors are analyzed. To examine the observational viability of the model, we
employ Markov Chain Monte Carlo (MCMC) methods and perform a comprehensive
statistical analysis using the latest observational datasets, including the
Hubble parameter measurements, Baryon Acoustic Oscillations (BAO), and the
Pantheon compilation of type Ia supernovae. The combined data analysis provides
constraints on the free parameters of the model and allows a comparison with
the standard $\Lambda$CDM cosmology. Our results show that the anisotropic
Bianchi-III universe in f(R,T) gravity can successfully accommodate current
observational data, offering new insights into the role of matter-geometry
coupling in the late-time cosmic acceleration.

</details>


### [105] [Simple Analytic Estimate of Black Hole Shadow Size in an Expanding Universe](https://arxiv.org/abs/2510.19857)
*Debarshi Mukherjee*

Main category: gr-qc

TL;DR: 提出了一个分析框架来估计膨胀宇宙中非旋转黑洞的阴影大小，结合局域史瓦西几何与宇宙学动力学，推导出阴影角大小与角直径距离的紧凑关系。


<details>
  <summary>Details</summary>
Motivation: 黑洞阴影是探测强场广义相对论最直接的手段之一，但宇宙膨胀对其表观角直径的影响尚未充分探索。

Method: 通过McVittie和Kottler度规将局域史瓦西几何与大规模宇宙学动力学结合，推导出阴影角大小与角直径距离的解析关系，并进行数值估计。

Result: 宇宙膨胀对附近黑洞阴影大小的影响可忽略，但对高红移黑洞变得显著，建立了强引力光学与宇宙膨胀之间的概念联系。

Conclusion: 该工作为黑洞阴影理论在宇宙学背景下的扩展提供了概念清晰、物理动机明确的框架。

Abstract: The apparent shadow of a black hole provides one of the most direct probes of
strong-field general relativity. While the shadow size in asymptotically flat
spacetimes is well understood, the influence of cosmic expansion on its
apparent angular diameter remains less explored. In this work, we present a
simple analytic framework to estimate the shadow size of a non-rotating black
hole embedded in an expanding universe. By combining the local Schwarzschild
geometry with large-scale cosmological dynamics through the McVittie and
Kottler metrics, we derive a compact relation between the shadow angular size
and the angular diameter distance $D_A(z)$. This approach captures the
essential dependence on cosmological parameters such as the Hubble constant
$H_0$ and the cosmological constant $\Lambda$, while remaining analytically
tractable. We further perform numerical estimates to quantify the redshift
dependence of the apparent shadow size, showing that the effect of cosmic
expansion is negligible for nearby sources but becomes relevant for
high-redshift black holes. Our results demonstrate a clear conceptual
connection between strong-gravity optics and cosmological expansion, providing
a pedagogically transparent and physically motivated extension of black hole
shadow theory to a cosmological context.

</details>


### [106] [Tracing Inflationary Imprints Through the Dark Ages: Implications for Early Stars and Galaxies Formation](https://arxiv.org/abs/2510.19863)
*K. El Bourakadi,M. Yu. Khlopov,M. Krasnov,H. Chakir,M. Bennai*

Main category: gr-qc

TL;DR: 该论文探讨了暴胀特征如何影响宇宙结构形成的早期阶段，通过转移函数形式追踪原初扰动的演化，分析其对物质功率谱的影响，并应用平滑密度场方差来预测暗物质晕丰度和早期星系形成。


<details>
  <summary>Details</summary>
Motivation: 研究暴胀产生的振荡特征如何在宇宙结构形成的早期阶段留下可观测印记，建立高能物理与天体物理观测之间的联系，特别是通过JWST望远镜进行验证。

Method: 使用转移函数形式追踪原初扰动的演化，应用Press-Schechter框架预测暗物质晕丰度，分析分子氢冷却和热化学途径对第一代恒星形成的影响，研究原初黑洞作为早期星系种子的作用。

Result: 研究发现暴胀产生的振荡特征可以在晕丰度和早期星系性质中留下可测量的印记，原初黑洞的吸积驱动增长与高红移系统的恒星质量和盘性质相关。

Conclusion: 暴胀特征对早期宇宙结构形成具有重要影响，这些印记可以通过JWST等观测设备进行验证，为连接高能物理与天体物理提供了可测试的途径。

Abstract: We explore how inflationary features shape the early stages of cosmic
structure formation. Using the transfer function formalism, we trace the
evolution of primordial perturbations, showing how causal physics and
oscillatory signatures from inflation influence the matter power spectrum. The
variance of smoothed density fields is then applied to model the collapse of
overdense regions and predict dark matter halo abundances through the
Press-Schechter framework. Extending to the baryonic sector, we analyze
primordial gas collapse in minihalos, emphasizing molecular hydrogen cooling
and the thermochemical pathways leading to Population III star formation.
Finally, we examine primordial black holes as potential seeds for early
galaxies, connecting their accretion-driven growth to the stellar masses and
disk properties of high-redshift systems. Our results indicate that oscillatory
features from inflation can leave measurable imprints on halo abundances and
early galaxy properties, providing a testable link between high-energy physics
and astrophysical observations with JWST

</details>


### [107] [Detecting White Dwarf Binary Mergers with Gravitational Waves](https://arxiv.org/abs/2510.19913)
*Giona Sala,Chiara Brandenstein,Sebastian Baum,Peter W. Graham*

Main category: gr-qc

TL;DR: 白矮星双星合并可能是Ia型超新星的前身天体，通过空间原子干涉仪探测器（如MAGIS Space和AEDGE）可以探测其引力波信号，实现多信使天文学观测。


<details>
  <summary>Details</summary>
Motivation: 白矮星双星合并作为Ia型超新星的可能前身通道，其引力波信号尚未被直接探测，需要在中频带探测器上进行观测。

Method: 计算并讨论白矮星双星螺旋合并过程中发出的引力波，评估使用MAGIS Space和AEDGE等空间原子干涉仪探测器的探测能力。

Result: MAGIS Space每四年至少能探测到一次Ia型超新星前身信号，AEDGE每年可观测数百个此类事件，提供精确的天区定位。

Conclusion: 原子干涉仪捕获的长期引力波发射可实现与电磁望远镜的协同观测，为涉及宇宙中最亮瞬变事件的多信使天文学开辟新途径。

Abstract: Mergers of white dwarf binaries are a possible progenitor channel for Type Ia
supernovae. While white dwarfs are abundant in the universe and relatively well
understood, their gravitational wave signals have not yet been directly
observed. In order to detect gravitational waves from merging white dwarf
binaries, a detector in the mid-band between LVK and LISA appears necessary. In
this paper, we compute and discuss the gravitational waves emitted by
inspiraling and merging white dwarf binaries, and assess their detectability
with proposed space-based atom-interferometer detectors such as MAGIS Space and
AEDGE. Gravitational waves from massive white dwarf binaries can be observed
for many years before merger, offering a unique early warning of their final
explosion. Our projections suggest that MAGIS Space could detect signals from
Type Ia supernova progenitors at least once every four years, while AEDGE could
observe at least a few hundred such events annually. The prolonged
gravitational wave emission captured by atom-interferometers provides precise
sky localisation and can allow observation of the final explosion with
electromagnetic telescopes. The combined observation with electromagnetic
radiation from the white dwarf binary coalescence could open a new pathway for
multi-messenger astronomy involving some of the brightest transient events in
the universe.

</details>


### [108] [Constraining the Swift Memory Burden Effect with GW250114-like Events](https://arxiv.org/abs/2510.19916)
*Chen Yuan,Richard Brito*

Main category: gr-qc

TL;DR: 本文开发了一个现象学框架来分析黑洞合并的衰荡过程，结合GW250114事件数据，通过贝叶斯分析获得了关于黑洞信息负载如何影响其经典响应的约束。


<details>
  <summary>Details</summary>
Motivation: 受黑洞信息负载可能改变其对小扰动经典响应（称为快速记忆负担效应）的启发，研究黑洞光谱学如何推断双黑洞合并残余的性质。

Method: 开发了最小现象学框架，结合(220)和(440)准正规模频率，进行贝叶斯分析，并使用Fisher信息矩阵进行高信噪比近似预测。

Result: 获得下限log₁₀p ≳ 2，其中p控制黑洞主模占据偏离临界值时能隙重新打开的方式；预测Cosmic Explorer观测类似事件时下限可达log₁₀p ≳ 5。

Conclusion: 结果不支持快速能隙重新打开，为使用当前和下一代探测器探测快速记忆负担效应提供了见解。

Abstract: Black hole spectroscopy allows to infer the properties of the remnant of a
binary black hole coalescence. Motivated by the recent proposal that a black
hole's information load can alter its classical response to small
perturbations, an effect known as the swift memory burden, we develop a minimal
phenomenological framework to analyze the ringdown of a binary black hole
merger and confront it with the data from the GW250114 event. We perform a
Bayesian analysis combining the frequencies of the (220) and (440) quasi-normal
modes and obtain a lower bound $\log_{10}p \gtrsim 2$, where $p$ controls how
the gaps reopen when the black hole's master mode occupation departs from the
critical value. Moreover, using a Fisher information matrix (high
signal-to-noise ratio) approximation, we forecast the lower bound $\log_{10}p
\gtrsim 5$ for a GW250114-like event observed with Cosmic Explorer. Our results
disfavour rapid gap reopening, shedding light on how the swift memory burden
effect can be probed with current and next-generation detectors.

</details>


### [109] [Dephasing in binary black hole mergers surrounded by scalar wave dark matter clouds](https://arxiv.org/abs/2510.20037)
*Cheng-Hsin Cheng,Giuseppe Ficarra,Helvi Witek*

Main category: gr-qc

TL;DR: 该研究模拟了在标量场环境中黑洞合并的过程，发现标量场会改变黑洞双星的合并时间，可能延迟或加速合并过程。


<details>
  <summary>Details</summary>
Motivation: 轻标量场（如类轴子粒子或波状暗物质候选者）可能增强与黑洞的引力相互作用并形成标量云，这会影响黑洞双星合并的动力学，为探测这些粒子提供新途径。

Method: 使用基于穿刺法的约束满足初始数据求解器，改进开源软件Canuda至八阶有限差分精度，降低初始轨道偏心率，模拟质量比为1和1/2的黑洞在标量场超密度环境中的合并。

Result: 标量场质量会影响引力和标量辐射，导致黑洞双星合并时间相对于真空情况出现延迟或加速。

Conclusion: 准确模拟暗物质环境中的黑洞双星系统具有挑战性但至关重要，标量场环境会显著影响黑洞合并动力学。

Abstract: Scalar fields of masses between $10^{-21}\rm{eV}/c^2$ and $10^{-11}
\rm{eV}/c^2$ can exhibit enhanced gravitational interactions with black holes,
and form scalar clouds around them. Such a cloud modifies the dynamics of a
coalescing black-hole binary, and the resulting gravitational waves may provide
a new channel to detect light scalar fields, such as axion-like particles or
wave-like dark matter candidates. In this work we simulate a series of
black-hole mergers with mass ratios $q=1$ and $q=1/2$, immersed in an scalar
field overdensity with masses in the range $M\mu_{\rm{S}} \in[0,1.0]$. To do
so, we implemented a constraint-satisfying initial data solver based on the
puncture method, we improved the accuracy of our open-source software Canuda to
eighth order finite differences, and we reduced the initial orbital
eccentricity. We investigate the impact of the scalar mass on the gravitational
and scalar radiation. We find that binaries can undergo a delayed or an
accelerated merger with respect to the vacuum. Our study highlights the
challenge and importance of accurately modeling black-hole binaries in dark
matter environments.

</details>


### [110] [Gauss-Bonnet entropy and thermal dynamics of RN-AdS black holes](https://arxiv.org/abs/2510.20183)
*M. Z. Bhatti,Kazuharu Bamba,I. Siddique,Bander Almutairi,Z. Yousaf*

Main category: gr-qc

TL;DR: 本文研究了包含高斯-博内项修正的Reissner-Nordström-AdS黑洞的热力学性质，发现高斯-博内耦合显著改变了黑洞的热力学行为和稳定性结构，揭示了更丰富的相变现象。


<details>
  <summary>Details</summary>
Motivation: 探索高斯-博内项对Reissner-Nordström-AdS黑洞热力学的影响，与之前主要关注标准广义相对论或其他修正的研究不同，这种包含允许修改熵的表述。

Method: 通过包含高斯-博内项，计算了吉布斯自由能、热力学第一定律、状态方程和霍金温度等关键热力学量，识别了临界点并图形化表示了温度与吉布斯自由能随视界半径的变化关系。

Result: 高斯-博内耦合显著改变了黑洞的热力学行为和稳定性结构，揭示了更丰富的相变现象。

Conclusion: 在Gauss-Bonnet引力框架下评估了Reissner-Nordström-AdS黑洞的热稳定性，强调了高斯-博内项的影响，发现其对热力学性质有重要影响。

Abstract: We explore the thermodynamics of a novel solution for the
Reissner-Nordstr\"{o}m-Anti-de Sitter (AdS) black hole, uniquely incorporating
the Gauss-Bonnet term. Unlike previous studies that primarily focused on
standard General Relativity or other modifications, this inclusion allows for a
modified entropy formulation, facilitating the computation of key thermodynamic
quantities such as Gibbs free energy, the first law of thermodynamics, the
equation of state, and Hawking temperature. We identify critical points and
graphically represent the relationship between temperature and Gibbs free
energy as a function of the horizon radius. Ultimately, we assess the thermal
stability of the Reissner-Nordstr\"{o}m-AdS black hole within the framework of
Gauss-Bonnet gravity, emphasizing the influence of the Gauss-Bonnet term unlike
previous studies that primarily focused on standard General Relativity or other
modifications. As a result, it is found that the Gauss-Bonnet coupling
significantly alters the thermodynamic behavior and stability structure of the
black hole, revealing richer phase transition phenomena.

</details>


### [111] [Emergent time and more from wavefunction collapse in general relativity](https://arxiv.org/abs/2510.20207)
*Sung-Sik Lee*

Main category: gr-qc

TL;DR: 本文基于广义相对论中的波函数坍缩理论发展了一种时间理论，将违反动量约束和哈密顿约束的量子态视为时间实例，通过拉普拉斯和位移的随机波动产生时间演化，使初始态逐渐坍缩到微分同胚不变态。


<details>
  <summary>Details</summary>
Motivation: 发展一个基于波函数坍缩的时间理论，解释时间演化如何从量子态的约束违反中产生，并探讨引力子在时间箭头下的动力学行为。

Method: 使用半经典和绝热近似方法，在宇宙常数主导的宇宙背景下，通过大空间维数极限来控制计算。

Result: 尺度因子单调增加作为时钟，张量引力子展现涌现的幺正动力学，矢量模式被普遍抑制，标量模式的衰减率与其波矢成正比，使其成为暗物质的候选者。

Conclusion: 该理论提供了一个基于波函数坍缩的时间框架，其中标量引力子的长波长模式可作为暗物质候选者，而短波长模式由于快速衰减而难以探测。

Abstract: In this paper, we further develop a recently proposed theory of time based on
wavefunction collapse in general relativity. It is based on the postulations
that quantum states, which violate the momentum and Hamiltonian constraints,
represent instances of time, and stochastic fluctuations of the lapse and shift
generate the time evolution under which an initial state gradually collapses
toward a diffeomorphism-invariant state. Under the wavefunction collapse, the
scale factor monotonically increases, thus acting as a clock. The scalar,
vector, and tensor gravitons arise as physical excitations, and the arrow of
time for their evolution is set by the initial state. In the long-time limit,
the tensor gravitons exhibit emergent unitary dynamics. However, the extra
modes are strongly damped due to the non-unitary dynamics that suppress the
constraint-violating excitations. The vector mode is uniformly suppressed over
all length scales, but the decay rate of the scalar is proportional to its wave
vector. This makes the latter a viable candidate for dark matter; excitations
with large wavelengths survive over long periods, contributing to long-range
interactions, while the fast decay of short-wavelength modes renders them
undetectable without sufficient temporal resolution. These are demonstrated for
the cosmological constant-dominated universe through semi-classical and
adiabatic approximations, which are controlled in the limit of large space
dimension.

</details>


### [112] [Quantum Field Theory in Successive Rindler Spacetimes](https://arxiv.org/abs/2510.20283)
*Nitesh K. Dubey,Jaswanth Uppalapati,Sanved Kolekar*

Main category: gr-qc

TL;DR: 研究Minkowski时空中连续Rindler变换及其对应的真空态序列，发现第n级Rindler观测者会将前一级的真空态视为热态，并通过UDW探测器验证了热谱特性。


<details>
  <summary>Details</summary>
Motivation: 扩展标准Rindler构造到多级迭代，探索嵌套楔形区域内观测者对真空态的热感知现象。

Method: 使用Bogoliubov变换分析n重Rindler变换，通过UDW探测器耦合实无质量标量场计算跃迁率。

Result: 第二级Rindler观测者在Minkowski真空中表现出等效加速度2g₂的热谱，晚期加速度渐近趋于2g₂。

Conclusion: 多级Rindler变换导致真空态的热感知，UDW探测器响应证实了热谱特性，为理解量子场论中的热效应提供了新视角。

Abstract: We study successive Rindler-like transformations in Minkowski spacetime and
the corresponding sequence of vacuum states perceived by observers restricted
to respective wedges. Extending the standard Rindler construction to an
$n$-fold iteration, we find via Bogoliubov transformations that the vacuum of
the $(n-1)^{th}$ Rindler observer appears thermal to the $n^{th}$ one. The
characteristic trajectories, confined to nested wedges, exhibit characteristic
accelerations and horizon shifts depending on transformation parameters ${g_1,
g_2, \ldots, g_{n}}$. For the second-level transformation (\emph{Rindler
Rindler} case), the late time acceleration asymptotically approaches $2g_2$ for
one branch and diverges for the other. We study Minkowski, Rindler, and Rindler
Rindler vacuum states from the perspective of Unruh DeWitt (UDW) detectors
along inertial, Rindler, and Rindler Rindler trajectories. The response of the
UDW detector coupled to a real massless scalar field confirms the thermality:
the transition rate of Rindler Rindler observer in Minkowski vacuum matches
that of a standard Rindler detector with acceleration $2g_2$, yielding a
Planckian spectrum at late times. The conclusions are discussed.

</details>


### [113] [Bound State Perturbations in the Interior of Black Holes](https://arxiv.org/abs/2510.20305)
*Hassan Firouzjahi*

Main category: gr-qc

TL;DR: 该论文研究了史瓦西黑洞内部的束缚态扰动，确认了标量、矢量和轴向张量扰动的束缚态解存在，并给出了谱的上下界。


<details>
  <summary>Details</summary>
Motivation: 重新研究黑洞内部的束缚态扰动，这些扰动具有虚数谱，在黑洞中心处正则且在事件视界上时间依赖剖面呈指数衰减。

Method: 使用黑洞内部膨胀方向的尺度因子作为时钟，重写相应的Regge-Wheeler方程，并进行半解析和数值求解。

Result: 对于给定的ℓ > s，存在ℓ-s个束缚态；获得了束缚态谱的普适下界2GMω_I > 1，以及轴向扰动谱的上界2GMω_I ≲ 0.04ℓ^4。

Conclusion: 确认了黑洞内部束缚态解的存在性，并给出了谱的定量界限，这些束缚态在事件视界附近具有非零振幅。

Abstract: We revisit our earlier work and investigate the bound state perturbations in
the interior of the Schwarzschild black hole. The bound sates are defined as
the perturbations in the interior of the black hole with an imaginary spectrum
which are regular at the center of black hole while their time-dependent
profile falls off exponentially on the event horizon. Using the scale factor in
the expanding direction in the interior of the black hole as the clock, we
rewrite the corresponding Regge-Wheeler equation and solve it semi-analytically
as well as numerically. We confirm that the bound state solutions exist for
scalar, vector and axial tensor perturbations. It is shown that for a given
value of $\ell >s$, there are total $\ell-s$ such bound states. We obtain the
universal lower bound $2 G M \omega_I >1$ for the spectrum of bound state which
is asymptotically saturated in the large $\ell$ limit. Furthermore, we obtain
an upper bound on the spectrum of axial perturbations which for large $\ell$
scales like $2 G M \omega_I \lesssim 0.04\, \ell^4 $. As observed recently,
these bound states have the curious property that the profile of the total wave
function has a non-zero magnitude near the future event horizon.

</details>


### [114] [On the observation of cosmic strings via gravitational-wave lensing](https://arxiv.org/abs/2510.20442)
*Oleg Bulashenko,Nino Villanueva,Roberto Bada Nerin,José A. Font*

Main category: gr-qc

TL;DR: 提出了一个检测宇宙弦透镜引力波信号的框架，填补了当前搜索的关键空白。宇宙弦的探测将为高能物理和早期宇宙提供独特探针。


<details>
  <summary>Details</summary>
Motivation: 宇宙弦具有独特的拓扑和几何特征，需要专门的搜索策略。其探测能够提供高能物理和早期宇宙的独特见解，但目前缺乏针对性的搜索方法。

Method: 采用全波传输因子方法，通过菲涅尔积分解析表达，捕捉直宇宙弦周围锥形时空的特征衍射和干涉效应。使用贝叶斯模型选择来区分宇宙弦透镜与其他信号。

Result: 发现宇宙弦透镜的引力波波形表现出特征性的拍频模式或时间分离的精确复制。推导了弦张力的可探测界限，并证明宇宙弦透镜在广泛参数空间内可与未透镜和点质量透镜信号区分开。

Conclusion: 该框架能够有效检测宇宙弦透镜引力波信号，为探测宇宙弦提供了可行方法，并展示了与点质量透镜的根本区别。

Abstract: We present a framework for detecting gravitational-wave signals lensed by
cosmic strings (CSs), addressing a key gap in current searches. CSs, whose
detection would provide a unique probe of high-energy physics and the early
Universe, possess distinct topological and geometric features that require a
dedicated search strategy. Our approach employs a full-wave transmission
factor, expressed analytically via Fresnel integrals, which captures the
characteristic diffraction and interference effects of the conical spacetime
around a straight CS. We contrast CS lensing with the well-studied point mass
lens (PML) model, highlighting their fundamental differences: CS lensing
depends on cosmological distances, string tension $\Delta$, and wavelength
$\lambda$, and produces two non-amplified images set by the global conical
geometry. In contrast, PML lensing is governed by the distance-independent
ratio $\sim M_{Lz}/\lambda$, where $M_{Lz}$ represents the redshifted mass of
the lens, with image properties derived from the lens equation. For BBH mergers
lensed by CSs, we show that the waveforms exhibit a characteristic beating
pattern or time-separated, exact replicas. We derive a detectability bound on
the string tension and, using Bayesian model selection, demonstrate that CS
lensing is distinguishable from both unlensed and PML-lensed signals across a
wide region of parameter space.

</details>


### [115] [Validation of NANOGrav 15-year data and ACT data by modified inflation in entropic cosmology](https://arxiv.org/abs/2510.20484)
*Simone D'Onofrio,Sergei Odintsov,Tanmoy Paul*

Main category: gr-qc

TL;DR: 该论文通过引入广义熵形式的视界熵来修改标准暴胀模型，增强了对NANOGrav频率区域敏感的原初张量扰动，从而同时满足ACT宇宙学观测和PTA引力波背景数据的约束。


<details>
  <summary>Details</summary>
Motivation: 解决标准暴胀模型与PTA观测到的随机引力波背景数据不兼容的问题，同时满足ACT望远镜对暴胀观测量的精化约束。

Method: 采用热力学宇宙学方法，引入广义形式的视界熵来修改标准暴胀场景，增强特定频率区域的原初张量扰动。

Result: 模型参数在满足ACT数据约束的同时，也能拟合NANOGrav 15年数据，表明模型与ACT和PTA数据均兼容。

Conclusion: 通过广义熵修改的暴胀模型能够同时解释ACT宇宙学观测和PTA引力波背景数据，为早期宇宙演化提供了新的理论框架。

Abstract: Recent evidences of stochastic gravitational wave background (SGWB) through
Pulsar Time Array (PTA) observations hint towards an alternative inflationary
scenario, compared to the usual inflation, for describing the early stage of
the universe in order to be compatible with the PTA data. Moreover, currently
the Atacama Cosmology Telescope (combined with the Planck 2018 and BAO) refines
the constraint on inflationary observables, compared to the only-Planck 2018
measurements. In the present work, we simultaneously address these two issues
by incorporating certain modification during inflation over the usual
inflationary scenario. Such modification amplifies the primordial tensor
perturbation over the modes that are sensitive to the NANOGrav frequency
region. For this purpose, we take the thermodynamic route of cosmology where
the entropy of the apparent horizon is given by a generalized form of entropy
that is able to generalize the other known form of horizon entropies for
suitable representations. The constraints on the model parameters coming from
the ACT data also fit the NANOGrav 15-year data (based on numerical analysis),
which reveal the model's compatibility with both the ACT and the PTA data.

</details>


### [116] [Quasinormal modes of a charged spherically symmetric black hole in bumblebee gravity](https://arxiv.org/abs/2510.20503)
*Bo-Rui Li,Jia-Zhou Liu,Wen-Di Guo,Yu-Xiao Liu*

Main category: gr-qc

TL;DR: 本文研究了Bumblebee引力理论中带电球对称黑洞的准正规模，使用连分数法和渐近迭代法计算了标量扰动和引力-电磁耦合扰动的准正规模频率。


<details>
  <summary>Details</summary>
Motivation: 在Bumblebee引力框架下，由于Bumblebee场的非零真空期望值导致洛伦兹对称性自发破缺，作者希望研究这种洛伦兹破缺背景下黑洞的准正规模行为。

Method: 使用连分数法和渐近迭代法两种数值方法，计算了标量扰动和引力-电磁耦合扰动对应的准正规模频率。

Result: 获得了洛伦兹破缺背景下黑洞的准正规模频率，并对两种计算方法的结果进行了详细比较。

Conclusion: 通过比较连分数法和渐近迭代法在洛伦兹破缺背景下的计算结果，评估了这两种方法在该背景下的准确性和效率。

Abstract: Recently, some of us have obtained exact charged spherically symmetric black
hole solutions within the framework of bumblebee gravity, where the Lorentz
symmetry is spontaneously broken due to the nonvanishing vacuum expectation
value of the bumblebee field. In this work, we investigate the quasinormal
modes of this black hole. We compute the quasinormal frequencies corresponding
to the scalar perturbation and the gravito-electromagnetic coupled perturbation
using both the continued fraction method and the asymptotic iteration method. A
detailed comparison of the results obtained from the two approaches is
presented to evaluate their accuracy and efficiency in this Lorentz-violating
background.

</details>


### [117] [Regular hairy black holes through gravitational decoupling method](https://arxiv.org/abs/2510.20524)
*Yaobin Hua,Zhenglong Ban,Tian-You Ren,Jia-Jun Yin,Rong-Jia Yang*

Main category: gr-qc

TL;DR: 使用引力解耦方法构建非奇异有毛黑洞，这些解来自闵可夫斯基真空的变形，最大变形可分别得到史瓦西度规和克尔几何


<details>
  <summary>Details</summary>
Motivation: 在需要明确定义事件视界和物质满足弱能量条件的框架内，构建非奇异的有毛黑洞解

Method: 采用引力解耦方法，通过对闵可夫斯基真空进行变形来构造球对称或轴对称的非奇异有毛黑洞

Result: 成功构建了球对称和轴对称的非奇异有毛黑洞解，最大变形分别对应史瓦西度规和克尔几何

Conclusion: 引力解耦方法能够有效构建满足物理条件的非奇异有毛黑洞解

Abstract: Within a framework requiring a well-defined event horizon and matter obeying
the weak energy condition, we employ gravitational decoupling method to
construct non-singular hairy black holes: spherically or axially symmetric.
These solutions arise from a deformation of the Minkowski vacuum, where the
maximum deformation can yield the Schwarzschild metric for the static case, and
the Kerr geometry for the stationary case, respectively.

</details>


### [118] [Can a Dehnen-type dark matter halo affect the neutrino flavor oscillations?](https://arxiv.org/abs/2510.20563)
*Mirzabek Alloqulov,Ahmadjon Abdujabbarov,Bobomurat Ahmedov,Chengxun Yuan*

Main category: gr-qc

TL;DR: 研究了在Dehnen型暗物质晕包围的Schwarzschild黑洞中中微子的引力弱透镜效应，分析了暗物质晕参数对中微子振荡概率的影响。


<details>
  <summary>Details</summary>
Motivation: 探索暗物质晕如何影响黑洞周围中微子的传播和振荡行为，为中微子作为探测暗物质分布的工具提供理论基础。

Method: 研究事件视界结构，推导径向和非径向传播中微子的振荡相位和跃迁概率解析表达式，使用双味玩具模型进行数值分析。

Result: 暗物质晕的存在会改变振荡相位和阻尼因子，导致与标准Schwarzschild黑洞情况的显著偏差。

Conclusion: 中微子振荡原则上可以作为探测致密天体周围暗物质分布的有效探针。

Abstract: The gravitational weak lensing of neutrinos in the presence of a
Schwarzschild black hole surrounded by a Dehnen-type dark matter halo is
investigated. The event horizon structure is explored, and the existence of the
BH is studied in two different slices of the parameter space. Additionally, we
derive analytic expressions for the oscillation phase and transition
probabilities for both radial and non-radial neutrino propagation. Finally, we
use a two-flavor toy model, and numerically analyze how the dark matter halo
parameters as density and scale radius, affect oscillation probabilities and
examine the role of decoherence. The results show that the presence of a dark
matter halo modifies the oscillation phase and damping factor, leading to
measurable deviations from the standard Schwarzschild BH case. These findings
suggest that neutrino oscillations could, in principle, serve as a probe for
dark matter distributions around compact astrophysical objects.

</details>


### [119] [Pole inflation from extended metric-affine gravity](https://arxiv.org/abs/2510.20585)
*Damianos Iosifidis,Sotirios Karamitsos*

Main category: gr-qc

TL;DR: 该论文研究了在扩展度规-仿射F(R)引力框架下的暴胀现象，包含所有偶宇称的二次挠率和非度规不变量。该理论具有带极点的非正则动能项，使得暴胀动力学和可观测量预测对F(R)的具体形式不敏感，而由极点结构主导。


<details>
  <summary>Details</summary>
Motivation: 探索扩展度规-仿射F(R)引力作为暴胀框架的可行性，研究包含挠率和非度规不变量的引力理论如何影响暴胀预测。

Method: 分析简化版本和完整的十一参数理论，基于是否具有二阶极点、是否无鬼态以及是否预测足够小的张量-标量比来分类模型。放宽无鬼要求，仅排除极点附近的鬼态。

Result: 通过放宽鬼态限制条件，显著扩大了可行模型的范围。扩展度规-仿射F(R)引力能够作为稳健的暴胀框架，重现谱指数和张量-标量比的吸引子预测。

Conclusion: 扩展度规-仿射F(R)引力提供了一个强大的暴胀理论框架，其预测对F(R)具体形式不敏感，主要取决于极点结构，且通过适当放宽限制条件可获得更多可行模型。

Abstract: We study inflation in the framework of extended metric-affine F(R) gravity,
where all even-parity quadratic invariants of torsion and non-metricity are
included in the Lagrangian alongside the F(R) term. The extended theory admits
a scalar-tensor description with a non-canonical kinetic term featuring poles.
As a result, the inflationary dynamics and predictions for observables of this
model are insensitive to the specific form of F(R), since they are dominated by
the structure of the poles (order and residue). We analyze both a simplified
version analytically and the full eleven-parameter theory, and we classify the
models based on whether they feature second-order poles, whether they are free
from ghosts, and whether they predict a sufficiently small tensor-to-scalar
ratio. By relaxing the ghost-free requirement to only exclude ghosts near the
pole (where inflation occurs), we demonstrate that we can significantly enlarge
the set of viable models. We thus show that extended metric-affine F(R) gravity
can act as a robust framework for inflation, reproducing the attractor
predictions for the spectral index and tensor-to-scalar ratio.

</details>


### [120] [The global nonlinear stability of Minkowski spacetime with self-gravitating massive Dirac fields](https://arxiv.org/abs/2510.20626)
*Philippe G. LeFloch,Yue Ma,Weidong Zhang*

Main category: gr-qc

TL;DR: 该论文证明了爱因斯坦-狄拉克系统中自引力大质量旋量场的非线性稳定性，当初始数据接近闵可夫斯基时空时，存在全局双曲发展并保持渐近平坦性。


<details>
  <summary>Details</summary>
Motivation: 之前的研究仅限于无质量的爱因斯坦-狄拉克系统，本研究旨在解决大质量情况下的全局演化问题，证明此类场的规范不变非线性稳定性。

Method: 采用LeFloch和Y. Ma引入的渐近双曲-欧几里得框架，使用光弯曲波坐标，基于洛伦兹克利福德代数和主纤维丛等数学工具进行规范不变处理。

Result: 建立了狄拉克方程及其与爱因斯坦方程耦合的L2估计和逐点估计，证明了双曲-欧几里得叶层中旋量场的新Sobolev不等式，并建立了区分平移、旋转和boost的估计层次结构。

Conclusion: 成功证明了自引力大质量旋量场在接近闵可夫斯基时空初始数据下的全局非线性稳定性，为爱因斯坦-狄拉克系统的数学理论提供了重要进展。

Abstract: We consider the Einstein-Dirac system for a massive field, which describes
the evolution of self-gravitating massive spinor fields, and we investigate the
global evolution problem, when the initial data set is sufficiently close to
data describing a spacelike, asymptotically Euclidean slice of the Minkowski
spacetime. We establish the gauge-invariant nonlinear stability of such fields,
namely the existence of a globally hyperbolic development, which remains
asymptotic to Minkowski spacetime in future timelike, null, and spacelike
directions. Previous results on this problem have been limited to the
Einstein-Dirac system in the massless case. Our analysis follows the
asymptotically hyperboloidal-Euclidean framework introduced by LeFloch and Y.
Ma for the massive Klein-Gordon-Einstein system. The structure specific to
spinor fields and the Dirac equation necessitates significantly new elements in
the proof. In contrast with prior approaches, our treatment of spinor fields
and the Dirac equation is gauge-invariant, relying on the formalism of Lorentz
Clifford algebras, principal fiber bundles, etc. Our analysis is carried out
with the metric expressed in light-bending wave coordinates, as we call them.
This leads us to the study of a global existence problem for a system of wave
equations with constraints and a Klein-Gordon-type equations. We derive L2
estimates for the Dirac equation and its coupling with the Einstein equations,
along with $pointwise estimates. New Sobolev inequalities are proven for spinor
fields in a gauge-invariant manner in the hyperboloidal-Euclidean foliation.
The nonlinear coupling between the massive Dirac equation and the Einstein
equations is investigated, and we establish a hierarchy of estimates, which
distinguish between translations, rotations, and boosts.

</details>


### [121] [Radiating black holes in general relativity need not be singular](https://arxiv.org/abs/2510.20649)
*Francesco Di Filippo*

Main category: gr-qc

TL;DR: 该论文挑战了黑洞必然包含广义相对论失效区域的传统观点，通过分析带电球对称黑洞的引力坍缩和霍金辐射蒸发过程，证明电磁斥力和霍金辐射导致的能量条件违反足以避免奇点和柯西视界的形成。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为黑洞必然包含广义相对论失效的区域，要么形成曲率奇点，要么形成柯西视界。本文旨在挑战这一观点，探索避免这些结构形成的可能性。

Method: 分析带电球对称黑洞的形成过程，考虑引力坍缩和霍金辐射蒸发，研究电磁斥力和霍金辐射导致的能量条件违反如何影响黑洞内部结构。

Result: 研究表明，电磁斥力和霍金辐射导致的能量条件违反足以避免奇点和柯西视界的形成，黑洞内部可能不存在广义相对论失效的区域。

Conclusion: 类似机制可能适用于天体物理黑洞，其中角动量可以替代电荷的作用，这表明黑洞可能避免传统理论预测的内部结构问题。

Abstract: It is common knowledge that black holes necessarily contain a region where
general relativity breaks down, due to the inevitable formation of either a
curvature singularity or a Cauchy horizon. In this work we challenge this view
by analyzing a charged spherically symmetric black hole formed through
gravitational collapse and evaporating via Hawking radiation. We show that the
electromagnetic repulsion and the violation of energy conditions due to the
presence of Hawking radiation are be sufficient to avoid the formation of both
a singularity and a Cauchy horizon. We argue that a similar mechanism may apply
to astrophysical black holes in which the role of the electric charge is
replaced by the angular momentum.

</details>


### [122] [Quantum black holes: inside and outside](https://arxiv.org/abs/2510.20799)
*Wei-Chen Lin,Dong-han Yeom,Dejan Stojkovic*

Main category: gr-qc

TL;DR: 论文探讨了黑洞蒸发过程中时间切片的选择问题，发现无法选择跨越事件视界的相干态，必须保持时间切片在视界外以保证幺正性演化。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞蒸发幺正描述中时间切片选择的合理性，特别是为何要避免覆盖事件视界内部的时间切片。

Method: 通过研究Wheeler-DeWitt方程，分析覆盖事件视界内外的时间切片，构造波包并观察波函数在视界附近的行为。

Result: 发现无法构造跨越事件视界的相干态，波函数必须在视界附近湮灭。视界内部必须是多个相干态的叠加态，存在视界尺度的不确定性。

Conclusion: 黑洞应被视为高度量子化的宏观物体，视界内部存在量子叠加态，这为理解信息丢失悖论提供了新视角。

Abstract: For a unitary description of an evaporating black hole, one usually chooses
the time slices that cover only outside of the event horizon, which is mostly
problem-free because the event horizon is not encountered. However, is there
any justification for avoiding time slices that cover inside the event horizon?
To answer the question, we investigate the Wheeler-DeWitt equation, where the
time slices can cover both inside and outside the event horizon. We find that
one can reasonably construct a wave packet that covers outside, but the wave
function must be annihilated near the event horizon. This observation strongly
suggests that we cannot choose a coherent state for a spacelike hypersurface
that crosses the event horizon. To explain the unitary time evolution, we must
keep the slices as coherent states; hence, they must always be outside the
event horizon. In contrast, inside the horizon, we cannot have a single
coherent state of a classical spacetime. Hence, the interior must be a
superposition of several coherent states, which implies that there exists a
horizon-scale uncertainty and a black hole should be viewed as a highly quantum
macroscopic object. We provide a synthetic approach to understanding the
information loss paradox from this perspective.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [123] [Macroscopic quantum phenomena and quantum computing](https://arxiv.org/abs/2510.19846)
*Jian-Qiang You*

Main category: quant-ph

TL;DR: 本文对2025年诺贝尔物理学奖进行展望，聚焦超导电路中宏观量子隧穿和能量量子化的突破性发现及其对量子计算的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨超导电路中宏观量子现象的研究背景和历史成因，分析这一突破性发现的重要性。

Method: 采用新闻与观点文章的形式，从历史发展和理论演进的角度进行分析评述。

Result: 展望了2025年诺贝尔物理学奖可能授予超导电路中宏观量子隧穿和能量量子化研究的预测。

Conclusion: 这一突破性发现对量子计算领域的后续发展产生了深远影响，值得获得诺贝尔奖的认可。

Abstract: This News & Views article provides a perspective on the 2025 Nobel Prize in
Physics, including the groundbreaking discovery of macroscopic quantum
tunneling and energy quantization in superconducting circuits, the history and
causes giving rise to this breakthrough, and its impact on subsequent progress
in quantum computing.

</details>


### [124] [Two Quantum Algorithms for Nonlinear Reaction-Diffusion Equation using Chebyshev Approximation Method](https://arxiv.org/abs/2510.19855)
*Manish Kumar*

Main category: quant-ph

TL;DR: 提出了两种基于截断切比雪夫多项式近似的量子算法，用于求解反应-扩散方程。第一种算法使用矩阵指数化方法，第二种算法重新利用量子谱方法。主要技术贡献是推导了Carleman嵌入矩阵对角化的充分条件，并提供了高效的对角化迭代算法。


<details>
  <summary>Details</summary>
Motivation: 开发更高效的量子算法来解决反应-扩散方程，利用量子计算的优势在复杂度和精度方面获得改进。

Method: 使用截断切比雪夫多项式近似来数值求解非线性微分方程线性化后的常微分方程。第一种算法基于矩阵指数化方法，第二种算法基于量子谱方法。推导了Carleman矩阵对角化的充分条件并提供了对角化算法。

Result: 第一种算法的门复杂度为O(d·log(d)+T·polylog(T/ε))，第二种算法在log(d)、T和log(1/ε)上是多项式的，门复杂度为O(polylog(d)·T·polylog(T/ε))。在T和ε方面与当前最佳量子算法相当。

Conclusion: 提出的两种量子算法在求解反应-扩散方程方面具有竞争力，但存在两个局限性：未提供Carleman矩阵条件数的上界，且对角化成功基于特定三角方程无整数解的猜想。提供了在大多数实际情况下缓解这些局限性的策略。

Abstract: We present two new quantum algorithms for reaction-diffusion equations that
employ the truncated Chebyshev polynomial approximation. This method is
employed to numerically solve the ordinary differential equation emerging from
the linearization of the associated nonlinear differential equation. In the
first algorithm, we use the matrix exponentiation method (Patel et al., 2018),
while in the second algorithm, we repurpose the quantum spectral method (Childs
et al., 2020). Our main technical contribution is to derive the sufficient
conditions for the diagonalization of the Carleman embedding matrix, which is
indispensable for designing both quantum algorithms. We supplement this with an
efficient iterative algorithm to diagonalize the Carleman matrix.
  Our first algorithm has gate complexity of
O(d$\cdot$log(d)+T$\cdot$polylog(T/$\varepsilon$)). Here $d$ is the size of the
Carleman matrix, $T$ is the simulation time, and $\varepsilon$ is the
approximation error. The second algorithm is polynomial in $log(d)$, $T$, and
$log(1/\varepsilon)$ - the gate complexity scales as
O(polylog(d)$\cdot$T$\cdot$polylog(T/$\varepsilon$)). In terms of $T$ and
$\varepsilon$, this is comparable to the speedup gained by the current best
known quantum algorithm for this problem, the truncated Taylor series method
(Costa et.al., 2025).
  Our approach has two shortcomings. First, we have not provided an upper
bound, in terms of d, on the condition number of the Carleman matrix. Second,
the success of the diagonalization is based on a conjecture that a specific
trigonometric equation has no integral solution. However, we provide strategies
to mitigate these shortcomings in most practical cases.

</details>


### [125] [Mind the gaps: The fraught road to quantum advantage](https://arxiv.org/abs/2510.19928)
*Jens Eisert,John Preskill*

Main category: quant-ph

TL;DR: 该论文分析了量子计算从当前NISQ设备到未来FASQ机器的四个关键过渡阶段，包括从错误缓解到主动错误检测与纠正、从基础错误纠正到可扩展容错、从早期启发式算法到成熟可验证算法、以及从探索性模拟器到可信量子优势。


<details>
  <summary>Details</summary>
Motivation: 识别量子计算发展道路上的关键障碍，为加速实现广泛有用的量子计算提供明确方向。

Method: 通过分析当前NISQ设备和未来FASQ机器之间的差距，识别出四个相互关联的技术过渡阶段。

Result: 明确了量子计算发展的四个核心挑战：错误管理、容错扩展、算法成熟度和量子优势验证。

Conclusion: 针对这些过渡阶段进行重点攻关将加速量子计算向广泛应用的发展进程。

Abstract: Quantum computing is advancing rapidly, yet substantial gaps separate today's
noisy intermediate-scale quantum (NISQ) devices from tomorrow's fault-tolerant
application-scale (FASQ) machines. We identify four related hurdles along the
road ahead: (i) from error mitigation to active error detection and correction,
(ii) from rudimentary error correction to scalable fault tolerance, (iii) from
early heuristics to mature, verifiable algorithms, and (iv) from exploratory
simulators to credible advantage in quantum simulation. Targeting these
transitions will accelerate progress toward broadly useful quantum computing.

</details>


### [126] [Classical Gravity Cannot Mediate Entanglement by Local Means](https://arxiv.org/abs/2510.19969)
*Chiara Marletto,Vlatko Vedral*

Main category: quant-ph

TL;DR: 本文反驳了近期一篇声称经典引力可以通过局域方式纠缠两个质量叠加态的论文，指出其中的误解，并确认如果引力场能通过局域传播在遥远质量之间产生纠缠，那么引力场必须具备量子特性。


<details>
  <summary>Details</summary>
Motivation: 反驳近期一篇错误声称经典引力可以局域地纠缠质量叠加态的论文，澄清关于引力与量子纠缠关系的误解。

Method: 通过逻辑分析和理论论证，指出原论文中的概念错误，强调量子特性在引力产生纠缠过程中的必要性。

Result: 成功反驳了原论文的观点，确认了如果引力能够通过局域传播产生纠缠，那么引力场本身必须具有量子特性，经典引力无法实现这一目标。

Conclusion: 量子特性是引力场能够产生纠缠的必要条件，经典引力理论无法解释通过局域传播在遥远质量之间产生纠缠的现象。

Abstract: We rebut a recent paper that claims that classical gravity can entangle two
massive superpositions by local means. We refute the misconceptions appearing
in this paper and confirm that the quantum features are necessary in the
gravitational field if it can lead to entanglement by local propagation between
distant masses.

</details>


### [127] [Morphological computational capacity of Physarum polycephalum](https://arxiv.org/abs/2510.19976)
*Suyash Bajpai,Aviva Lucas-DeMott,Nirosha J Murugan,Michael Levin,Philip Kurian*

Main category: quant-ph

TL;DR: 该研究通过分析多头绒泡菌的生长动态，建立了无神经生物的计算能力上限，发现其在24小时内可执行约10^36次逻辑操作。


<details>
  <summary>Details</summary>
Motivation: 虽然宇宙和碳基生命的计算能力限制已有估计，但无神经生物的更严格界限尚未建立。多头绒泡菌作为无神经元但能解决复杂问题的单细胞生物，是研究这一问题的理想模型。

Method: 分析两种不同多头绒泡菌菌株在多种生物条件下的生长动态，将形态演化映射到信息处理。基于Margolus-Levitin定理，通过高通量时间序列数据量化形态特征（面积、周长、圆形度、分形维度），确定其水力学、化学、动力学和量子光学自由度可实现的最大逻辑操作数。

Result: 基于ATP空间分布和探索区域，多头绒泡菌在24小时内可执行约10^36次逻辑操作，在非平衡稳态下呈线性缩放。

Conclusion: 该框架能够比较利用经典或量子自由度的生命计算能力，为理解无神经生物的信息处理能力提供了新视角。

Abstract: While computational capacity limits of the universe and carbon-based life
have been estimated, a stricter bound for aneural organisms has not been
established. Physarum polycephalum, a unicellular, multinucleated amoeba, is
capable of complex problem-solving despite lacking neurons. By analyzing growth
dynamics in two distinct Physarum strains under diverse biological conditions,
we map morphological evolution to information processing. As the
Margolus-Levitin theorem constrains maximum computation rates by accessible
energies, we analyze high-throughput time-series data of Physarum's
morphology--quantified through area, perimeter, circularity, and fractal
dimension-to determine upper bounds on the number of logical operations
achievable through its hydromechanical, chemical, kinetic, and quantum-optical
degrees of freedom. Based on spatial distribution of ATP and explored areas,
Physarum can perform up to ~$10^{36}$ logical operations in 24 hours, scaling
linearly in the non-equilibrium steady state. This framework enables comparison
of the computational capacities of life, exploiting either classical or quantum
degrees of freedom.

</details>


### [128] [A transmon qubit realized by exploiting the superconductor-insulator transition](https://arxiv.org/abs/2510.19983)
*C. G. L. Bøttcher,E. Önder,T. Connolly,J. Zhao,C. Kvande,D. Q. Wang,P. D. Kurilovich,S. Vaitiekėnas,L. I. Glazman,H. X. Tang,M. H. Devoret*

Main category: quant-ph

TL;DR: 提出了一种基于氮化铌超导-绝缘体转变的新型平面弱连接结构，用于解决传统约瑟夫森结的温度、界面损耗和寄生电容等限制问题，并成功制造了transmon量子比特。


<details>
  <summary>Details</summary>
Motivation: 传统铝基约瑟夫森结存在三个主要限制：铝的小超导能隙需要毫开尔文工作温度、材料界面导致能量耗散、三明治结构带来不希望的寄生电容，这些限制了超导量子处理器的可扩展性。

Method: 通过原子层沉积和原子层刻蚀技术，在单一氮化铌薄膜上局部减薄形成弱连接，利用氮化铌的厚度驱动超导-绝缘体转变特性。

Result: 成功制造了'planaron' transmon量子比特，测得非线性度为α/2π = 235 MHz，当前线宽为κ/2π = 15 MHz。

Conclusion: 氮化铌的高超导能隙有望实现更高温度操作，全平面几何结构消除了多余的界面和电容，研究SIT附近的小尺寸材料有助于理解转变机制中的耗散和有限尺寸效应。

Abstract: Superconducting qubits are among the most promising platforms for realizing
practical quantum computers. One requirement to create a quantum processor is
nonlinearity, which in superconducting circuits is typically achieved by
sandwiching a layer of aluminum oxide between two aluminum electrodes to form a
Josephson junction. These junctions, however, face several limitations that
hinder their scalability: the small superconducting gap of aluminum
necessitates millikelvin operating temperatures, the material interfaces lead
to dissipation, and the sandwich geometry adds unwelcome capacitance for
high-frequency applications. In this work, we address all three limitations
using a novel superconducting weak link based on the superconductor-insulator
transition. By locally thinning a single film of niobium nitride, we exploit
its thickness-driven superconductor-insulator transition to form a weak link
employing only atomic layer deposition and atomic layer etching. We utilize our
weak links to produce a transmon qubit, '$planaron$', with a measured
anharmonicity of $\alpha/2\pi = 235$ MHz; at present, the linewidth is
$\kappa/2\pi = 15 \mathrm{\: MHz}$. The high superconducting gap of niobium
nitride can enable operation at elevated temperatures in future devices, and
the fully planar geometry of the weak link eliminates superfluous material
interfaces and capacitances. The investigation of small patches of material
near the SIT can shed new light on the nature of the transition, including the
role of dissipation and finite-size effects.

</details>


### [129] [On the separation of quantum time evolution into holonomic and dynamical parts](https://arxiv.org/abs/2510.19987)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 本文反驳了近期关于非绝热非阿贝尔情况下薛定谔型量子时间演化可分解为完整部分和动力学部分的观点，证明这种分解通常无效。


<details>
  <summary>Details</summary>
Motivation: 针对近期文献中声称非绝热非阿贝尔情况下量子时间演化可分解为完整部分和动力学部分的观点进行验证和反驳。

Method: 通过理论分析和数学推导，重新审视非绝热非阿贝尔情况下量子时间演化的分解问题。

Result: 证明了在非绝热非阿贝尔情况下，将薛定谔型量子时间演化分解为完整部分和动力学部分的分离方法通常是无效的。

Conclusion: 推翻了近期文献中的错误主张，明确了非绝热非阿贝尔情况下量子时间演化分解的局限性。

Abstract: The issue of separating Schr\"odinger-type quantum time evolution into a
product of holonomic and dynamical parts in the non-adiabatic non-Abelian case
is addressed. Contrary to the recent claim in [Phys. Rev. Lett. 131, 200202
(2023)], we establish that such separation is generally invalid.

</details>


### [130] [Reduced State Embedding for Error Correction in Quantum Cryptography](https://arxiv.org/abs/2510.19989)
*Amit Kam,Kfir Sulimany,Shai Tsesses,Uzi Pereg*

Main category: quant-ph

TL;DR: 提出了降维态嵌入方法用于量子密钥分发，通过在d维希尔伯特空间中嵌入k维信号集(k<d)，在量子信道中实现显式擦除型纠错，提高了安全密钥率。


<details>
  <summary>Details</summary>
Motivation: 高维希尔伯特空间编码虽然能提高噪声鲁棒性，但会导致跨模式耦合和检测复杂性，降低量子密码性能。这种正确性与保密性之间的基本权衡促使寻找新的纠错方法来更好利用高维编码优势。

Method: 引入降维态嵌入方法：在d维希尔伯特空间中嵌入k维信号集(k<d)，在量子纠错框架下实现量子信道中的显式擦除型纠错。

Result: 在d=25的QKD实验数据中验证了该方法，推导了密钥率和阈值的闭式表达式，确定在k=5时获得最优密钥率，在现实量子信道中产生了更高的安全密钥率。

Conclusion: 这些发现推动了高维QKD的发展，为量子密码学的纠错和调制开辟了新途径。

Abstract: Encoding in a high-dimensional Hilbert space improves noise resilience in
quantum information processing. However, such an approach may result in
cross-mode coupling and detection complexities, thereby reducing quantum
cryptography performance. This fundamental trade-off between correctness and
secrecy motivates the search for new error-correction approaches to better
exploit the advantages of high-dimensional encoding. Here, we introduce the
method of reduced state embeddings to quantum key distribution (QKD): a
k-dimensional signal set embedded in a d-dimensional Hilbert space, where k<d.
In the framework of quantum error correction, our reduced-state embedding
realizes an explicit erasure-type error-correction within the quantum channel.
We demonstrate the advantage of our scheme in realistic quantum channels,
producing a higher secure key rate. We validate our approach using a d=25 QKD
experimental data, derive closed-form expressions for the key rate and
threshold, and determine the optimal key rate at k=5. These findings advance
high-dimensional QKD and pave the way to error correction and modulation for
quantum cryptography.

</details>


### [131] [Quantum Nonlinear Response of Emitter Lattices](https://arxiv.org/abs/2510.19992)
*Blas Durá-Azorín,Antonio I. Fernández-Domínguez,Alejandro Manjavacas*

Main category: quant-ph

TL;DR: 研究了二维量子发射器晶格在激光驱动下光学响应中的量子非线性现象，发现亚波长晶格周期下系统可激发光锥外的激子布洛赫态，强驱动下产生宽带背景辐射，接近驱动波长时系统进入双稳态，可实现量子非线性的选择性调控。


<details>
  <summary>Details</summary>
Motivation: 探索量子发射器晶格在相干驱动下产生的量子非线性光学效应，特别是与传统玻色子系统不同的量子特性，为量子光学器件设计提供理论基础。

Method: 理论分析二维量子发射器晶格在激光驱动下的光学响应，考虑亚波长和接近驱动波长两种晶格周期情况，研究激子布洛赫态激发和共振荧光现象。

Result: 发现亚波长晶格可激发光锥外的激子态，强驱动产生宽带背景辐射；接近驱动波长时系统呈现双稳态，与经典玻色子系统形成鲜明对比，可选择性调控量子非线性。

Conclusion: 量子发射器晶格在相干驱动下展现出丰富的量子非线性现象，特别是双稳态行为为量子非线性光学调控提供了新机制，在量子信息处理和量子光学器件方面具有应用潜力。

Abstract: We theoretically investigate the emergence of quantum nonlinearities in the
optical response of lattices of two-level quantum emitters coherently driven by
a laser. For subwavelength lattice periods, where the system behaves as a
quantum metasurface, we find that a resonant incident plane wave can populate
excitonic Bloch states with parallel wavevectors different from the incident
field, including those lying outside the light cone. Closely related to
resonance fluorescence, the far-field emission from the system in the
strong-driving regime is dominated by a broadband background of photons
spanning a wide range of frequencies and wavevectors. Moreover, we show that,
for periods approaching the driving wavelength, the emitter lattice enters in a
bistable regime due to the renormalization of the driving rate, in striking
contrast with its classical (bosonic) analog. This bistable behavior enables
the selective activation and deactivation of the optical quantum nonlinearities
of the system.

</details>


### [132] [On Encoding Matrices using Quantum Circuits](https://arxiv.org/abs/2510.20030)
*Liron Mor Yosef,Haim Avron*

Main category: quant-ph

TL;DR: 本文系统研究了量子计算中矩阵的两种电路表示方法：块编码和状态制备电路，提出了从经典矩阵构造这些表示的一般方法，以及两种表示之间的双向转换算法。


<details>
  <summary>Details</summary>
Motivation: 量子算法的高效执行依赖于将矩阵和向量表示为量子电路，但现有方法在构造块编码和状态制备电路方面缺乏系统性研究，需要建立通用的构造方法和表示之间的转换关系。

Method: 使用特殊常数深度多路复用器同时复用给定大小的所有高阶Pauli矩阵，并开发了在标准基和高阶Pauli基之间进行量子转换的算法。

Result: 提出了从经典形式矩阵高效构造块编码的通用方法，建立了块编码和状态制备电路之间的低开销双向转换算法，证明这两种模型本质上是等价的。

Conclusion: 块编码和状态制备电路作为量子矩阵表示的两种主要模型具有等价性，通过本文提出的构造和转换方法，为量子线性代数算法的实现提供了理论基础和实用工具。

Abstract: Over a decade ago, it was demonstrated that quantum computing has the
potential to revolutionize numerical linear algebra by enabling algorithms with
complexity superior to what is classically achievable, e.g., the seminal HHL
algorithm for solving linear systems. Efficient execution of such algorithms
critically depends on representing inputs (matrices and vectors) as quantum
circuits that encode or implement these inputs. For that task, two common
circuit representations emerged in the literature: block encodings and state
preparation circuits. In this paper, we systematically study encodings matrices
in the form of block encodings and state preparation circuits. We examine
methods for constructing these representations from matrices given in classical
form, as well as quantum two-way conversions between circuit representations.
Two key results we establish (among others) are: (a) a general method for
efficiently constructing a block encoding of an arbitrary matrix given in
classical form (entries stored in classical random access memory); and (b)
low-overhead, bidirectional conversion algorithms between block encodings and
state preparation circuits, showing that these models are essentially
equivalent. From a technical perspective, two central components of our
constructions are: (i) a special constant-depth multiplexer that simultaneously
multiplexes all higher-order Pauli matrices of a given size, and (ii) an
algorithm for performing a quantum conversion between a matrix's expansion in
the standard basis and its expansion in the basis of higher-order Pauli
matrices.

</details>


### [133] [Exact State Evolution and Energy Spectrum in Solvable Bosonic Models](https://arxiv.org/abs/2510.20046)
*Valery Shchesnovich*

Main category: quant-ph

TL;DR: 提出了可解析求解玻色子模型的状态演化精确解，适用于广泛类别的可解玻色子模型和任意初始状态，并推导了能谱特征方程和本征态表达式。


<details>
  <summary>Details</summary>
Motivation: 在量子光学中，确定给定初始状态的时间演化是一个核心目标，特别是在描述非线性介质中光传播和光学下转换过程时。

Method: 推导了状态演化问题的精确解析解，得到了能谱特征方程，并将本征态表示为连分数形式和相关雅可比矩阵的主子式。

Result: 获得了适用于广泛可解玻色子模型和任意初始状态的精确解析解，为讨论可解玻色子模型提供了坚实的分析框架。

Conclusion: 该研究为可解析求解玻色子模型提供了一个坚实的分析框架，能够精确描述状态演化和能谱特性。

Abstract: Solvable bosonic models provide a fundamental framework for describing light
propagation in nonlinear media, including optical down-conversion processes
that generate squeezed states of light and their higher-order generalizations.
In quantum optics a central objective is to determine the time evolution of a
given initial state. Exact analytic solution to the state-evolution problem is
presented, applicable to a broad class of solvable bosonic models and arbitrary
initial states. Moreover, the characteristic equation governing the energy
spectrum is derived and the eigenstates are found in the form of continued
fractions and as principal minors of the associated Jacobi matrix. The results
provide a solid analytical framework for discussion of exactly solvable bosonic
models.

</details>


### [134] [Photon Quantum Mechanics](https://arxiv.org/abs/2510.20049)
*Margaret Hawton*

Main category: quant-ph

TL;DR: 该论文通过二次量子化标准电磁拉格朗日量，建立了经典电磁场离散激发的协变理论，提出了可称为光子的物理描述。纵向光子数为零，物理光子由实数密度描述，其空间积分为1，可解释为在位置x'找到光子的概率密度。


<details>
  <summary>Details</summary>
Motivation: 建立能够正确描述光子的协变理论，解决传统电磁场量子化中存在的问题，如纵向光子和能量密度的非局域频率算符问题。

Method: 对标准电磁拉格朗日量进行二次量子化，并引入洛伦兹规范约束，采用类似Gupta-Bleuler的方法处理纵向光子。

Result: 成功构建了物理光子的协变描述，纵向光子数因Gupta-Bleuler类项的抵消而为零，物理光子由可解释为概率密度的实数密度描述。

Conclusion: 该方法提供了一种更自然的电磁场量子化途径，避免了传统方法中的非局域频率算符问题，为光子提供了更清晰的物理图像。

Abstract: We second quantize the standard electromagnetic Lagrangian with a subsiduary
Lorenz gauge constraint to obtain a covariant theory of the discrete
excitations of the classical EM field that can properly be called photons. The
longitudinal photon number is zero due to cancellation of Gupta-Bleuler like
terms. Physical photons are described by a real number density whose spatial
integral is unity so it can be interpreted as the probability density to find a
photon at position x'. Energy density is not separated into is positive and
negative frequency parts so the nonlocal frequency operator is not required.

</details>


### [135] [All-Gaussian State Discrimination Beyond the Coherent Helstrom Bound](https://arxiv.org/abs/2510.20096)
*Angus Waslh,Lorcan Conlon,Biveen Shajilal,Ozlem Erkilic,Jiri Janousek,Syed Assad,Jie Zhao,Ping Koy Lam*

Main category: quant-ph

TL;DR: 使用高斯光学（位移压缩态和零差探测）实现BPSK信号判别，误码率低于相干态和任何量子测量所能达到的水平


<details>
  <summary>Details</summary>
Motivation: 解决BPSK信号最优判别问题，传统方法难以达到Helstrom量子极限，需要寻找实用化的替代方案

Method: 仅使用高斯光学元件：位移压缩态和零差探测技术

Result: 实现了BPSK信号的判别，误码率低于使用相干态和任何量子测量所能达到的水平

Conclusion: 该方法提供了一种实用化的途径，能够超越传统相干态方法的性能限制

Abstract: A core problem in communications is the optimal discrimination of
binary-phase-shift-keyed (BPSK) signals. A longstanding goal has been to reach
the fundamental quantum limit, known as the Helstrom bound, for BPSK signals
encoded in coherent states. However, due to technical constraints, proposals
for reaching the bound remain impractical. In this letter we take an
alternative approach: using only Gaussian optics - displaced squeezed states
and homodyne detection - we achieve discrimination of BPSK signals with error
rates below what can be achieved using coherent states and any quantum
measurement.

</details>


### [136] [Variational quantum simulation of many-body dissipative dynamics on a superconducting quantum processor](https://arxiv.org/abs/2510.20118)
*Huan-Yu Liu,Tai-Ping Sun,Zhao-Yun Chen,Cheng Xue,Chao Wang,Xi-Ning Zhuang,Jin-Peng Liu,Wei Yi,Yu-Chun Wu,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 提出并实验演示了一种可扩展模拟非幺正多体耗散动力学的变分量子算法，适用于近期量子硬件


<details>
  <summary>Details</summary>
Motivation: 开放量子系统具有丰富现象，但模拟困难，因为希尔伯特空间指数增长且动力学本质非幺正

Method: 基于哈密顿模拟线性组合框架，将非幺正动力学转换为加权幺正演化之和，并引入简化量子电路进行损失函数评估

Result: 在超导量子处理器Wukong上成功模拟了耗散横向伊辛模型和相互作用Hatano-Nelson模型的集体动力学

Conclusion: 该工作凸显了含噪声中等规模量子设备在模拟耗散多体动力学方面的能力，是开发利用其解决重要物理问题潜力的重要一步

Abstract: Open quantum systems host a wide range of intriguing phenomena, yet their
simulation on well-controlled quantum devices is challenging, owing to the
exponential growth of the Hilbert space and the inherently non-unitary nature
of the dynamics. Here we propose and experimentally demonstrate a variational
quantum algorithm capable of scalable simulation of non-unitary many-body
dissipative dynamics. The algorithm builds on the framework of linear
combination of Hamiltonian simulation, which converts non-unitary dynamics into
a weighted sum of unitary evolutions. With the further introduction of a
simplified quantum circuit for loss-function evaluation, our scheme is suitable
for near-term quantum hardware, with the circuit depth independent of the
simulation time. We illustrate our scheme by simulating the collective dynamics
of a dissipative transverse Ising model, as well as an interacting
Hatano-Nelson model, on the superconducting quantum processor Wukong. Our work
underlines the capability of noisy intermediate-scale quantum devices in
simulating dissipative many-body dynamics and represents a step forward in
exploiting their potential for solving outstanding physical problems.

</details>


### [137] [Electronically-controlled one- and two-qubit gates for transmon quasicharge qubits](https://arxiv.org/abs/2510.20127)
*Nicholas M. Christopher,Deniz E. Stiegemann,Abhijeet Alase,Thomas M. Stace*

Main category: quant-ph

TL;DR: 提出使用拓扑超导体形成的电子可控隧道结来实现准电荷量子比特的单量子比特门和双量子比特门，基于动态4π周期约瑟夫森效应，具有相同数量级的门速度。


<details>
  <summary>Details</summary>
Motivation: 实现受保护量子比特的低错误率，以构建可纠错的实用规模量子计算机。准电荷量子比特需要新的操作策略。

Method: 使用两个拓扑超导体形成的电子可控隧道结，基于动态4π周期约瑟夫森效应实现门操作。模拟拓扑约瑟夫森结在具有不可忽略充电能量的参数范围内的动力学。

Result: 实现了准电荷量子比特的单量子比特门和双量子比特门操作，门速度相同。使用费米黄金定则表征了门操作对电荷噪声的鲁棒性。

Conclusion: 基于最小基塔耶夫链量子点结的准电荷量子比特门实现策略具有吸引力。

Abstract: Superconducting protected qubits aim to achieve sufficiently low error rates
so as to allow realization of error-corrected, utility-scale quantum computers.
A recent proposal encodes a protected qubit in the quasicharge degree of
freedom of the conventional transmon device, here referred to as the
`quasicharge qubit'. Operating such a protected qubit requires implementing new
strategies. Here we show that an electronically-controllable tunnel junction
formed by two topological superconductors can be used to implement single- and
two-qubit gates on quasicharge qubits. Schemes for both these gates are based
on dynamical $4\pi$-periodic Josephson effect and therefore have gate speeds of
the same order. The simulation of the dynamics of a topological Josephson
junction in a parameter regime with non-negligible charging energy is the key
novelty of this work. We also characterize the robustness of such gate
operations against charge noise using Fermi's golden rule. Our results point to
a compelling strategy for implementation of quasicharge qubit gates based on
junctions of minimal Kitaev chains of quantum dots.

</details>


### [138] [Quantum mysteries explained in digestible form](https://arxiv.org/abs/2510.20144)
*Alejandro Hnilo*

Main category: quant-ph

TL;DR: 该论文通过将量子现象与实空间向量特征进行比较，解释了量子与经典现象的差异，并展示了贝尔不等式违背、量子隐形传态、Kochen-Specker和GHZ定理等量子现象如何用向量理解。


<details>
  <summary>Details</summary>
Motivation: 回答Pitowski提出的两个关键问题：为什么微观物理（量子）现象与经典现象存在差异，以及什么样的解释可以被认为是合理的解释。

Method: 通过比较量子现象与实空间向量的特征，特别是分析贝尔不等式违背、量子隐形传态、Kochen-Specker和GHZ定理等量子现象在向量框架下的表现。

Result: 发现量子现象可以通过向量的特性来理解，这表明向量本身是比初看起来更奇特的数学对象。

Conclusion: 量子与经典现象的差异并非虚幻，而是反映了向量作为数学对象的奇特性质，这种向量框架为理解量子现象提供了合理的解释途径。

Abstract: Years ago, Itamar Pitowski asked two relevant questions: Why microphysical
(quantum) phenomena and classical phenomena differ in the way they do? and,
what kind of explanation could qualify as a reasonable one? I argue that both
questions can be answered by the comparison of quantum phenomena with some
features of vectors in real space. In particular, I show how violation of
Bell's inequalities, Teleportation, Kochen-Specker and
Greenberger-Horne-Zeilinger theorems can be understood in terms of vectors.
This does not mean that the difference between quantum and classical phenomena
is illusory. This means that vectors are stranger objects that they may seem to
be at first sight.

</details>


### [139] [Efficient Floating-Point Arithmetic on Fault-Tolerant Quantum Computers](https://arxiv.org/abs/2510.20145)
*José E. Cruz Serrallés,Oluwadara Ogunkoya,Do{g}a Murat Kürkçüo{g}lu,Nicholas Bornman,Norm M. Tubman,Anna Grassellino,Silvia Zorzetti,Riccardo Lattanzi*

Main category: quant-ph

TL;DR: 提出了一种基于固定点编码的新型浮点数编码方案，使用补码固定点尾数和补码整数指数，开发了量子算法用于基本算术运算，在量子计算机模拟中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 基于现有固定点编码工作，开发更高效的浮点数编码方案，减少量子计算中所需的辅助量子比特数量。

Method: 使用补码固定点尾数和补码整数指数编码浮点数，开发量子算法实现位移、倒数、乘法和加法等基本运算。

Result: 随着编码量子比特数的增加，快速收敛到精确解；倒数运算所需的辅助量子比特数量相比类似方法显著减少。

Conclusion: 提出的浮点数编码方案在量子计算中表现出良好的收敛性和资源效率，为量子算法中的数值计算提供了有效解决方案。

Abstract: We propose a novel floating-point encoding scheme that builds on prior work
involving fixed-point encodings. We encode floating-point numbers using Two's
Complement fixed-point mantissas and Two's Complement integral exponents. We
used our proposed approach to develop quantum algorithms for fundamental
arithmetic operations, such as bit-shifting, reciprocation, multiplication, and
addition. We prototyped and investigated the performance of the floating-point
encoding scheme on quantum computer simulations by performing reciprocation on
randomly drawn inputs and by solving first-order ordinary differential
equations, while varying the number of qubits in the encoding. We observed
rapid convergence to the exact solutions as we increased the number of qubits
and a significant reduction in the number of ancilla qubits required for
reciprocation when compared with similar approaches.

</details>


### [140] [Unveiling non-Hermitian band structures with non-Bloch supercells](https://arxiv.org/abs/2510.20160)
*Jia-Xin Zhong,Jing Lin,Kai Chen,Jing Lu,Kun Ding,Yun Jing*

Main category: quant-ph

TL;DR: 提出了一种非布洛赫超晶格框架，通过解耦布洛赫相位控制和虚动量部分，实现了非厄米系统中复能带结构的实验测量。


<details>
  <summary>Details</summary>
Motivation: 非厄米系统具有复能带结构，其中能量和动量都有虚部，这导致了非厄米趋肤效应等新现象。实验上测量这些复能带并识别相关本征态对于理解这些系统至关重要，但一直是个重大挑战。

Method: 结合指数平坦化协议和扭曲边界条件，开发了非布洛赫超晶格框架，实现了系统尺寸无关的虚动量控制，同时保持高分辨率布洛赫相位采样。在可编程声学晶体中通过格林函数测量获取动量分辨的复能带表面和双正交本征模。

Result: 使用该框架获得的数据准确预测了开放边界谱和本征态，并通过独立的开放几何实验进行了验证。

Conclusion: 这项工作为探索各种工程经典和量子平台中的非厄米能带几何和拓扑提供了广泛适用的实验工具包。

Abstract: Real-valued band structures are foundational to analyzing periodic systems
within the Hermitian description and have been experimentally well-established
over recent decades. In contrast, non-Hermitian systems exhibit complex band
structures where both energy and momentum have imaginary parts, underpinning
phenomena like the non-Hermitian skin effect and anomalous bulk-boundary
correspondence that defy conventional Bloch theory. Experimentally mapping
these complex bands-relating complex momentum to complex energy-and identifying
their associated eigenstates is crucial for understanding these systems but
remains a significant challenge. Here, we introduce a non-Bloch supercell
framework designed to overcome this challenge by decoupling Bloch phase control
from the imaginary part of momentum. Our method combines an exponent-flattening
protocol with twisted boundary conditions, enabling system-size-independent
control of imaginary momentum while preserving high-resolution Bloch phase
sampling. Implemented in programmable one- and two-dimensional acoustic
crystals, our approach acquires momentum-resolved complex energy surfaces and
biorthogonal eigenmodes by Green's function measurements.Data obtained using
this framework accurately predict open-boundary spectra and eigenstates,
findings we verify through separate open-geometry experiments. Our work
provides a broadly applicable experimental toolkit for exploring non-Hermitian
band geometry and topology in diverse engineered classical and quantum
platforms.

</details>


### [141] [Gravitationally mediated entanglement of fermionic qubits: from static to dynamical limits](https://arxiv.org/abs/2510.20587)
*Moslem Zarei,Mehdi Abdi,Nicola Bartolo,Sabino Matarrese*

Main category: quant-ph

TL;DR: 使用量子玻尔兹曼方程分析两个远程量子比特之间的引力纠缠，通过两个微观模型证明只有在动力学极限下才能产生纠缠态，纠缠量取决于拉莫尔频率而非质量。


<details>
  <summary>Details</summary>
Motivation: 通过引力纠缠的实验证据来验证引力量子化，为引力量子化提供可能的实验支持。

Method: 采用量子玻尔兹曼方程，使用引力子传播子作为相互作用媒介，将量子比特视为波包中的自旋1/2粒子，分析前向散射过程中的引力子交换。

Result: 仅在动力学极限下能产生纠缠态；在基于磁场中费米子的微观模型中，纠缠量取决于拉莫尔频率而非质量；波包尺寸增大时纠缠效应减弱。

Conclusion: 研究揭示了两个自旋1/2粒子之间引力介导纠缠的机制，为引力量子化的实验验证提供了理论支持。

Abstract: We employ the quantum Boltzmann equation to analyze the gravitationally
generated entanglement between two remote qubits by considering two explicit
microscopic models. A graviton propagator is employed as the mediator of the
interactions, while the qubits are considered in a spatial superposition state.
Such a setup, in the case of any entanglement generation, could potentially
offer experimental evidence for the quantization of gravity. By treating the
qubits as spin-1/2 particles in wave packets, we establish that the
entanglement arises from forward scattering processes involving graviton
exchanges. In our study, we consider both static and dynamical limits of the
propagator and show that only in the dynamical limit such entangled states can
be generated. We also show that for the microscopic model based on the fermion
particles in the background of magnetic field, the amount of entanglement
depends on the Larmor frequency of the qubits, rather than their masses. These
effects are observed to diminish in both models as the wave packet size
increases. Our findings sheds more light into the gravity mediated entanglement
between two spin-1/2 particles.

</details>


### [142] [Parametric Phase Modulation in Superconducting Circuits](https://arxiv.org/abs/2510.20192)
*Zhuang Ma,Xianke Li,Hongyi Shi,Ruonan Guo,Jianwen Xu,Xinsheng Tan,Yang Yu*

Main category: quant-ph

TL;DR: 提出并实现了一种通过调节两个耦合量子比特上参数磁通脉冲的相对相位来调控相互作用强度的相位调制方案，为参数驱动量子模拟和门操作提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 传统参数调制中量子比特耦合强度由参数磁通脉冲的幅度决定，这会显著影响量子比特参数，因此需要一种更灵活的控制方法。

Method: 采用相位调制方案，通过调整两个耦合量子比特上参数磁通脉冲的相对相位来调控相互作用强度，在边带耦合的甜点和非甜点位置进行表征。

Result: 实现了宽范围的耦合强度调控，通过布居数动力学和光谱学方法验证了该方案的有效性。

Conclusion: 相位调制方法能够实现相位控制的耦合强度调制，为参数驱动量子模拟和门操作提供了有前景的候选方案。

Abstract: Parametric modulation is widely employed in superconducting circuits for
quantum simulations and high-fidelity two-qubit gates, valued for its
versatility. Conventionally, the qubit coupling strength is determined by the
amplitude of the parametric flux pulse, which affects qubit parameters
dramatically. In this article, we propose and implement a phase modulation
scheme to tune the interaction strength via adjusting the relative phase
between the parametric flux pulses applied to two coupled qubits. We
characterize this modulation for sideband couplings, at both sweet and offsweet
spots, achieving a broad range of coupling strengths as confirmed by both
population dynamics and spectroscopy methods. This approach enables
phase-controlled modulation of coupling strength, providing a promising
candidate for parametrically driven quantum simulations and gate operations.

</details>


### [143] [Quantum Sensing of Gravitational Frame-Dragging with a Superfluid $^4$He Gyrometer](https://arxiv.org/abs/2510.20772)
*Kai-Isaak Ellers,Marios Christodoulou,K. C. Schwab,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: 提出使用超流体氦-4单约瑟夫森结陀螺仪在地球上局部测量广义相对论框架拖曳效应的实验室实验方案，预计在毫开尔文温度下可实现极高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 在地球实验室环境中直接测量广义相对论的框架拖曳效应，这是目前主要通过卫星实验验证的现象。

Method: 利用超流体氦-4单约瑟夫森结陀螺仪的宏观量子特性，结合纳米多孔二维材料约瑟夫森结在毫开尔文温度下的操作。

Result: 在10毫开尔文温度下，噪声谱密度可达5×10^-17 rad/s/√Hz，能够在1秒测量时间内以0.2%精度解析框架拖曳率，旋转灵敏度相当于40亿年转一圈。

Conclusion: 该方法展示了在实验室尺度上测量广义相对论框架拖曳效应的可行性，具有极高的灵敏度和时间分辨率。

Abstract: We propose a laboratory-scale experiment to locally measure the general
relativistic frame-dragging effect on Earth using the macroscopic quantum
properties of a novel superfluid $^4$He single Josephson junction gyrometer. We
derive the frame-dragging and related geodetic and Thomas effects in the
superfluid gyrometer and present a procedure for their experimental
measurement. We compute the expected thermal noise floor and find that very
high sensitivity can be expected at millikelvin temperatures, where near-future
Josephson junctions using nanoporous 2D materials are expected to operate.
Assuming utilization of the lowest mechanical loss materials, we find a noise
spectral density of $5\times 10^{-17}$ rads/s/$\sqrt{\mathrm{Hz}}$ at 10 mK,
which is sufficient to resolve the frame-dragging rate to 0.2% within one
second of measurement, giving a rotational sensitivity of 1 revolution in 4
Byrs. This extreme sensitivity to rotation corresponds to a measurement of
proper time differences as small as $10^{-35}$ s.

</details>


### [144] [Non-Markovianity in Quantum Information Processing: Interplay with Quantum Error Mitigation](https://arxiv.org/abs/2510.20224)
*Suguru Endo,Hideaki Hakoshima,Tomohiro Shitara*

Main category: quant-ph

TL;DR: 本文证明非马尔可夫动力学的负性特征自然出现在量子纠错和量子隐形传态中，这种负性源于基于测量结果的反馈操作，并能降低量子误差缓解的采样成本。


<details>
  <summary>Details</summary>
Motivation: 尽管非马尔可夫动力学在开放量子系统中普遍存在，但其在量子信息处理中的相关性很少被讨论。本文旨在探索非马尔可夫性在量子信息处理中的重要作用。

Method: 将整个希尔伯特空间划分为逻辑子系统和规范子系统，逻辑子系统存储量子信息，规范子系统存储用于恢复逻辑信息的测量结果。通过基于规范子系统测量结果的反馈操作来展示负性的出现。

Result: 证明了非马尔可夫动力学的负性特征自然出现在量子纠错和量子隐形传态中，这种负性源于信息从环境回流，并通过反馈操作实现。

Conclusion: 量子信息处理中的非马尔可夫负性能够降低量子误差缓解的采样成本，揭示了在实际量子信息处理中结合量子纠错和量子误差缓解策略的重要性。

Abstract: Non-Markovian dynamics are typically present in the dynamics of open quantum
systems. Despite the rich structure of non-Markovian dynamics, their relevance
to quantum information processing (QIP) has been rarely discussed. In this
work, we demonstrate that the negativity of the dynamics, a characteristic of
non-Markovian dynamics, naturally arises in quantum error correction (QEC) and
quantum teleportation. The negativity in open quantum systems is naturally
attributed to the information backflow from the environment. We partition the
whole Hilbert space into the logical subsystem and the gauge subsystem. The
logical subsystem stores the quantum information for QIP, while the gauge
subsystem stores the information for recovery of the logical information, i.e.,
the syndrome measurement outcomes for quantum error correction and Bell
measurement outcomes for successful teleportation. We then show that the
negativity in quantum information processing appears as a consequence of the
feedback operation based on the measurement outcomes of the gauge subsystem.
Finally, we show that the negativity of non-Markovianity in QIP reduces the
sampling cost of quantum error mitigation (QEM), shedding light on the
importance of combination strategies of QEC and QEM in a practical QIP.

</details>


### [145] [Factorizability of optimal quantum sequence discrimination under maximum-confidence measurements](https://arxiv.org/abs/2510.20311)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 该论文证明了在最大置信度测量下，量子序列的最优区分可以分解为对每个单独集合的区分，即通过在每个步骤独立执行最大置信度区分即可实现最优量子序列区分。


<details>
  <summary>Details</summary>
Motivation: 研究在最大置信度测量下量子序列的区分问题，探索是否可以通过简单的分解方法实现最优区分。

Method: 通过理论分析和证明，展示了量子序列最优区分在最大置信度测量下的可分解性，并提供了最优量子态区分的充要条件。

Result: 证明了量子序列的最优区分可以完全分解为对每个单独集合的区分，且序列的最大置信度等于组成序列的每个态的最大置信度的乘积。

Conclusion: 在最大置信度测量框架下，量子序列的最优区分具有简单的分解特性，这简化了量子序列区分的实现过程。

Abstract: We consider the discrimination of quantum sequences under maximum-confidence
measurements and show that the optimal discrimination of a quantum sequence
ensemble can always be factorized into that of each individual ensemble. In
other words, the optimal quantum sequence discrimination under
maximum-confidence measurements can be achieved just by performing a
maximum-confidence discrimination independently at each step of the quantum
sequence. We also show that the maximum confidence of identifying a quantum
sequence is to achieve the maximum confidence of identifying each state
comprising the quantum sequence. We further provide a necessary and sufficient
condition for the optimal quantum state discrimination under maximum-confidence
measurements.

</details>


### [146] [Complete characterisation of state conversions by work extraction](https://arxiv.org/abs/2510.20366)
*Chung-Yun Hsieh,Manuel Gessner*

Main category: quant-ph

TL;DR: 论文介绍了一种基于热力学功提取的量子资源理论框架，建立了量子态转换的充要条件，并提供了首个基于热力学的通用资源认证方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统的能量存储增强问题，特别是量子电池的充电过程，旨在建立量子资源理论的普适性热力学描述。

Method: 通过热力学功提取任务推导出类似于majorisation的条件，这些条件在一般量子资源理论中刻画了态转换的可能性。

Result: 建立了量子态转换的充要条件，这些条件在特定资源下简化为单演通道下的majorisation条件，并提供了纠缠理论中Nielsen定理的热力学版本。

Conclusion: 该工作确立了首个基于热力学的通用资源认证类别，并展示了如何通过功提取来量化一般量子资源。

Abstract: We introduce a thermodynamic work extraction task that describes the energy
storage enhancement of quantum systems, which is naturally related to quantum
battery's charging process. This task induces majorisation-like conditions that
provide a necessary and sufficient characterisation of state conversions in
general quantum resource theories. When applied to specific resources, these
conditions reduce to the majorisation conditions under unital channels and
provide a thermodynamic version of Nielsen's theorem in entanglement theory. We
show how this result establishes the first universal resource certification
class based on thermodynamics, and how it can be employed to quantify general
quantum resources based on work extraction.

</details>


### [147] [Restoring Quantum Superiority of Noisy Quantum Illumination](https://arxiv.org/abs/2510.20378)
*Wei Wu,Jun-Hong An*

Main category: quant-ph

TL;DR: 提出了一种在量子噪声环境中恢复量子照明量子优势的方法，通过超越Born-Markov近似，发现分辨率对光模式与局部量子噪声形成的复合系统能谱高度敏感。


<details>
  <summary>Details</summary>
Motivation: 量子照明利用量子纠缠实现比经典技术更高分辨率的低反射率目标检测，但普遍认为量子噪声引起的退相干会破坏其优势，限制了在当前嘈杂中等规模量子时代的应用。

Method: 超越广泛使用的Born-Markov近似，研究每个光模式与其局部量子噪声形成的复合系统的能谱特性，特别是当能谱中存在束缚态时的情形。

Result: 发现当能谱中存在束缚态时，噪声量子照明的分辨率渐近地接近其理想形式，能够恢复量子优势。

Conclusion: 建立了在噪声环境中保持量子优势的物理原理，为实现高分辨率量子照明在噪声环境中的实际应用铺平了道路。

Abstract: Quantum illumination uses quantum entanglement as a resource to enable
higher-resolution detection of low-reflectivity targets than is possible with
classical techniques. This revolutionary technology could transform modern
radar. However, it is widely believed that the decoherence induced by the
ubiquitous quantum noise destroys the superiority of quantum illumination,
severely constraining its performance and application in our present noisy
intermediate-scale quantum era. Here, we propose a method to restore the
quantum superiority of the quantum illumination in the presence of quantum
noises. Going beyond the widely used Born-Markov approximation, we discover
that the resolution of noisy quantum illumination is highly sensitive to the
energy spectrum of the composite system formed by each of the two light modes
and its local quantum noise. When a bound state is present in the energy
spectrum, the resolution asymptotically approaches its ideal form. Our result
establishes a physical principle to preserve the quantum superiority and paves
the way for the realization of high-resolution quantum illumination in noisy
situations.

</details>


### [148] [Multiplexed ion-ion entanglement over $1.2$ kilometer fibers](https://arxiv.org/abs/2510.20392)
*Z. B. Cui,Z. Q. Wang,P. Y. Liu,Y. Wang,P. C. Lai,J. X. Shi,Y. D. Sun,Z. C. Tian,H. S. Sun,Y. B. Liang,B. X. Qi,Y. Y. Huang,Z. C. Zhou,Y. K. Wu,Y. Xu,Y. F. Pu,L. M. Duan*

Main category: quant-ph

TL;DR: 通过10个时间模式的多路复用，实现了两个囚禁离子量子网络节点之间的增强型触发纠缠，获得了4.59倍的纠缠生成加速和95.9%的纠缠保真度。


<details>
  <summary>Details</summary>
Motivation: 量子网络和量子中继器是大规模量子信息系统的基础设施，实现远程量子节点之间的高效高保真触发纠缠是关键步骤。多路复用策略可以加速远程纠缠分布。

Method: 采用10个时间模式的多路复用技术和双类型架构，在两个囚禁离子量子网络节点之间建立触发纠缠。

Result: 实现了4.59倍的离子-离子纠缠生成加速，在1.2公里光纤上达到95.9±1.5%的纠缠保真度。

Conclusion: 该系统可扩展到多个节点，为未来大规模量子网络建立了关键构建模块。

Abstract: Quantum networks and quantum repeaters represent the promising avenues for
building large-scale quantum information systems, serving as foundational
infrastructure for distributed quantum computing, long-distance quantum
communication, and networked quantum sensing. A critical step in realizing a
functional quantum network is the efficient and high-fidelity establishment of
heralded entanglement between remote quantum nodes. Multiplexing offers a
powerful strategy to accelerate remote entanglement distribution, particularly
over long optical fibers. Here, we demonstrate the first multiplexing-enhanced
heralded entanglement between two trapped-ion quantum network nodes. By
multiplexing $10$ temporal photonic modes, we achieve a 4.59-fold speedup in
ion-ion entanglement generation and attain an entanglement fidelity of
$95.9\pm1.5\%$ over $1.2$ km of fiber. Employing a dual-type architecture, our
system is readily scalable to multiple nodes, thereby establishing a key
building block for future large-scale quantum networks.

</details>


### [149] [Robust GHz-range AC Magnetometry with an ensemble of NV Centers in Diamond using Concatenated Continuous Dynamical Decoupling](https://arxiv.org/abs/2510.20401)
*Takuya Kitamura,Genko Genov,Alon Salhov,Yutaka Kobayashi,Shinobu Onoda,Junichi Isoya,Alex Retzker,Fedor Jelezko*

Main category: quant-ph

TL;DR: 该论文提出了一种使用级联连续动力学解耦的GHz范围AC磁力测量方法，能够在空间不均匀驱动场下使用大型NV中心系综进行高灵敏度磁力测量。


<details>
  <summary>Details</summary>
Motivation: 传统基于Rabi振荡的NV系综GHz范围AC磁力测量方法在扩大自旋数量时会遇到空间不均匀性问题，导致灵敏度下降。现有技术如脉冲动力学解耦或整形脉冲与当前最先进技术不兼容。

Method: 采用级联连续动力学解耦方法，设计了对空间不均匀性具有鲁棒性的稳健穿衣服态，用于GHz范围AC磁力测量。

Result: 与传统直接Rabi方法相比，该方法显著扩展了测量范围，能够检测更弱的GHz范围AC磁场信号。

Conclusion: 级联连续动力学解耦方法为在空间不均匀驱动场下使用大型NV中心系综进行GHz范围AC磁力测量提供了有效的解决方案。

Abstract: Sub-picotesla level magnetometry has been demonstrated using
negatively-charged nitrogen-vacancy (NV) centers in diamond by increasing the
number of spins simultaneously used for sensing in an NV ensemble. However,
such scale-up often introduces spatial inhomogeneities in detuning and control
field amplitudes, which degrade sensitivity. Although several techniques have
been utilized to overcome these challenges, including pulsed dynamical
decoupling or shaped pulses, these are not generally compatible with the
current state-of-the-art techniques for GHz-range AC magnetometry with NV
ensembles, which are typically based on Rabi oscillations. In this work we
experimentally demonstrate GHz-range AC magnetometry using a large ensemble of
NV centers under spatially inhomogeneous drive fields by employing concatenated
continuous dynamical decoupling, which is designed for robustness against such
imperfections. We compare its performance with the conventional direct Rabi
method and show that the robust dressed states in our method extend
significantly the measuring range to weaker signals in GHz-range AC
magnetometry.

</details>


### [150] [Realization of Trapped Ion Dynamics in the Strong-Field Regime and Non-Markovianity](https://arxiv.org/abs/2510.20444)
*Kamran Rehan,Hengchao Tu,Menglin Zou,Zihan Yin,Jing-Ning Zhang,Kihwan Kim*

Main category: quant-ph

TL;DR: 实验研究囚禁离子在强场区域（拉比频率接近振动模式频率）的量子动力学，揭示非马尔可夫性随参数变化的新模式，特别是在特定参数组合下出现圆形最大值模式。


<details>
  <summary>Details</summary>
Motivation: 探索强场区域量子动力学对于理解受控量子系统和开发稳健量子技术至关重要，超越传统的弱场区域研究。

Method: 使用量子态层析技术重建密度矩阵并跟踪其演化，通过改变拉比频率和失谐参数对来评估非马尔可夫性。

Result: 发现非马尔可夫性不随拉比频率单调增加，在δ²+Ω²=ν²条件下呈现圆形最大值模式，此时系统哈密顿量类似Jaynes-Cummings模型。

Conclusion: 研究结果超越了传统的载波和边带区域，为利用囚禁离子平台研究非马尔可夫性、相干控制和开放量子系统基本行为开辟了新途径。

Abstract: Probing quantum dynamics in the strong-field regime is critical for advancing
our understanding of controlled quantum systems and developing robust quantum
technologies. In this work, we experimentally investigate the dynamics of a
trapped ion where the Rabi frequency (Omega) approaches the vibrational mode
frequency (nu), pushing the system beyond the weak-field regime, where
non-trivial quantum correlations emerge. We begin by setting the detuning
(delta) - the frequency offset between the qubit transition and the driving
field - to zero and varying Omega from low to high values, eventually reaching
the vibrational frequency. Using quantum state tomography, we reconstruct the
density matrix and track its evolution to assess non-Markovianity, revealing
significant memory effects governed by the interplay between internal and
motional degrees of freedom. Furthermore, by exploring the dynamics across
various parameter pairs (Omega, delta), we find that non-Markovianity does not
always increase monotonically with Omega for a fixed delta. Strikingly, when
the condition delta squared plus Omega squared equals nu squared is met, the
non-Markovianity exhibits a circular pattern of maxima. At this parameter
combination, the system's Hamiltonian takes a form similar to the
Jaynes-Cummings model, enabling the possibility of analytical insights into the
observed dynamics. These results go beyond the conventional carrier and
sideband regimes, uncovering novel features of strong-field quantum dynamics.
Our findings establish a pathway for using trapped-ion platforms to investigate
non-Markovianity, coherent control, and the fundamental behavior of open
quantum systems in extreme regimes.

</details>


### [151] [Mitigating Coherent Errors through a Decoherence-Resistant Variational Framework employing Stabilizer State](https://arxiv.org/abs/2510.20445)
*Giovanni Di Bartolomeo,Giulio Crognaletti,Angelo Bassi,Michele Vischi*

Main category: quant-ph

TL;DR: 提出VCEM方法，利用稳定子形式通过变分优化原生门参数来抑制相干误差，对非相干噪声具有鲁棒性，可在标准非相干误差缓解技术之前进行预补偿。


<details>
  <summary>Details</summary>
Motivation: 稳定子态是量子信息处理的核心资源，但相干误差（如原生门实现中的小角度失准）会严重影响其质量。

Method: VCEM方法采用稳定子形式，通过变分优化原生门参数来抑制相干误差。

Result: 数值模拟证明了VCEM的有效性和鲁棒性，该方法对非相干噪声基本不受影响。

Conclusion: VCEM能够有效抑制相干误差，为后续应用标准非相干误差缓解技术提供了预补偿方案。

Abstract: Stabilizer states are a central resource in quantum information processing,
underpinning a wide range of applications. While they can be efficiently
generated via Clifford circuits, the presence of coherent errors, such as
small-angle miscalibrations in native gate implementations, can significantly
impact their quality. In this work, we introduce Variational Coherent Error
Mitigation (VCEM), a method that employs the stabilizer formalism to suppress
coherent errors through variational optimization of native gates parameters.
VCEM demonstrates robust performance, remaining largely unaffected by
incoherent noise, enabling pre-compensation of coherent errors prior to the
application of standard incoherent error mitigation techniques. We demonstrate
the effectiveness and robustness of VCEM through numerical simulations.

</details>


### [152] [Phenomenological Noise Models and Optimal Thresholds of the 3D Toric Code](https://arxiv.org/abs/2510.20489)
*Ji-Ze Xu,Yin Zhong,Miguel A. Martin-Delgado,Hao Song,Ke Liu*

Main category: quant-ph

TL;DR: 本文研究了三维环面码在包含泡利错误和测量错误情况下的容错阈值，发现其具有约11%的比特翻转错误阈值和约2%的相位翻转错误阈值，证明了该码对测量错误的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 三维拓扑码支持非克利福德门的容错实现，但其在真实噪声下的性能尚未充分探索。随着硬件快速发展，评估复杂代码的实际性能变得迫切。

Method: 推导了两个描述代码可纠正性的随机耦合晶格规范模型，包括随机2形式Z_2规范理论，并利用广义对偶技术进行分析。

Result: 三维环面码对比特翻转和相位翻转错误的最优阈值分别为约11%和约2%，相比完美测量情况仅有适度降低。

Conclusion: 该研究在评估三维拓扑代码实际性能方面取得重要进展，对量子信息科学、高能物理和凝聚态物理具有跨学科意义。

Abstract: Three-dimensional (3D) topological codes offer the advantage of supporting
fault-tolerant implementations of non-Clifford gates, yet their performance
against realistic noise remains largely unexplored. In this work, we focus on
the paradigmatic 3D toric code and investigate its fault-tolerance thresholds
in the presence of both Pauli and measurement errors. Two randomly coupled
lattice gauge models that describe the code's correctability are derived,
including a random 2-form $\mathbb{Z}_2$ gauge theory. By exploiting a
generalized duality technique, we show that the 3D toric code exhibits optimal
thresholds of $p^{X,M}_{th} \approx 11\%$ and $p^{Z,M}_{th} \approx 2\%$
against bit-flip and phase-flip errors, respectively. These threshold values
show modest reductions compared to the case of perfect measurements,
establishing the robustness of the 3D toric code against measurement errors.
Our results constitute a substantial advance towards assessing the practical
performance of 3D topological codes. This contribution is timely and in high
demand, as rapid hardware advancements are bringing complex codes into
experimental reach. Moreover, our work highlights the interdisciplinary nature
of fault-tolerant quantum computation and holds significant interest for
quantum information science, high-energy physics, and condensed matter physics.

</details>


### [153] [Feasibility of entanglement-based QKD protocols with SPDC and QD sources](https://arxiv.org/abs/2510.20528)
*Mariia Gumberidze,Vladyslav C. Usenko*

Main category: quant-ph

TL;DR: 分析SPDC和QD光源在纠缠基量子密钥分发中的可行性，考虑多光子发射、精细结构分裂、暗计数和有限探测效率等实际因素。


<details>
  <summary>Details</summary>
Motivation: 研究实际光源和探测器对纠缠基量子密钥分发协议安全性的影响，为实际应用提供理论指导。

Method: 理论分析SPDC光源的多光子发射和QD光源的精细结构分裂效应，结合不完美探测条件（暗计数、有限效率）进行建模。

Result: SPDC光源由于真空态和多光子对的存在，在标准探测策略下不适合安全的设备无关QKD；QD光源受FSS影响性能降低。

Conclusion: 实际光源和探测器的非理想特性对纠缠基QKD协议的安全性有重要影响，这对实际应用至关重要。

Abstract: We theoretically analyze the feasibility of entanglement-based quantum key
distribution (QKD) protocols considering widely used spontaneous parametric
down-conversion (SPDC) and novel quantum dot (QD) sources. We account for
multiphoton emission in SPDC sources and fine-structure splitting (FSS) in QD.
In addition, we incorporate imperfect detection, including dark counts and
limited efficiency. For SPDC sources, we confirm that the presence of vacuum
and multiphoton pairs renders them unsuitable for secure device-independent
(DI) QKD implementations under standard detection strategies. Conversely, in
the case of QD sources, accounting for the effects of FSS, results in reduced
performance of protocols. Our findings are crucial for the practical
implementation of entanglement-based QKD protocols using realistic sources and
detectors.

</details>


### [154] [Higher-order quantum computing with known input states](https://arxiv.org/abs/2510.20530)
*Vanessa Brzić,Satoshi Yoshida,Mio Murao,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: 本文探讨了在已知输入状态的情况下，高阶量子计算中未知量子操作的转换问题，展示了这种假设如何显著提升性能并实现确定性和精确的实现。


<details>
  <summary>Details</summary>
Motivation: 传统高阶量子计算假设输入状态未知，但在某些实际场景（如酉编程）中，输入状态是固定且已知的。这种假设可以显著提升性能，并区分不同协议的设计。

Method: 研究在输入状态已知的框架下，对未知量子操作的转换进行分析，区分纯态、二分态和混合态的情况。

Result: 发现输入状态的经典知识可以显著增强性能，并识别出在混合态情况下可以实现确定性和精确实现的类别。

Conclusion: 在已知输入状态的假设下，高阶量子计算的性能可以得到显著提升，且对于特定类别的混合态，可以实现确定性和精确的实现。

Abstract: In higher-order quantum computing (HOQC), one typically considers the
universal transformation of unknown quantum operations, treated as blackboxes.
It is also implicitly assumed that the resulting operation must act on
arbitrary, and thus unknown, input states. In this work, we explore a variant
of this framework in which the operation remains unknown, but the input state
is fixed and known. We argue that this assumption is well-motivated in certain
practical contexts, such as unitary programming, and show that classical
knowledge of the input state can significantly enhance performance. Moreover,
this assumption allows us to distinguish between protocols designed for pure,
bipartite, and mixed states, which enables us to identify the class of mixed
states for which deterministic and exact implementation becomes possible.

</details>


### [155] [Nontrivial topological phases in "Zig-Zag" arrays of polarization transmons](https://arxiv.org/abs/2510.20557)
*Ekaterina Konopleva,Gleb Fedorov,Oleg Astafiev*

Main category: quant-ph

TL;DR: 提出了一种基于极化transmon的超导量子模拟器，用于研究具有长程交叉极化耦合的扩展Zig-Zag模型，展示了拓扑相变和边缘态的存在。


<details>
  <summary>Details</summary>
Motivation: 利用具有多个内禀自由度的元原子来研究拓扑模型，特别是在量子体系中实现先前难以访问的拓扑量子多体现象。

Method: 使用极化transmon构建超导量子模拟器，通过电磁建模验证扩展Zig-Zag模型，并利用逆参与率和拓扑不变量分析相变。

Result: 证明了扩展Zig-Zag模型中存在带隙内的局域平凡态和Tamm边缘态，且模拟器能准确再现该模型。

Conclusion: 这项工作为实验研究先前难以访问的拓扑量子多体现象开辟了新途径。

Abstract: In recent years, quantum simulators of topological models have been
extensively studied across a variety of platforms and regimes. A new promising
research direction makes use of meta-atoms with multiple intrinsic degrees of
freedom, which to date have been predominantly studied in the classical regime.
Here, we propose a superconducting quantum simulator to study an extension of
the well-known "Zig-Zag" model with long-range cross-polarization couplings
using polarization transmons hosting degenerate dipole orbitals. We map the
phase transitions of the extended "Zig-Zag" model both numerically and
analytically using inverse participation ratios and topological invariants. We
demonstrate the existence of in-gap localized trivial and Tamm edge states.
With linearized meta-atoms, we show via electromagnetic modeling that the
proposed arrangement closely reproduces the extended "Zig-Zag" model. This work
paves the way towards experimental investigation of the previously inaccessible
topological quantum many-body phenomena.

</details>


### [156] [Measuring weak microwave signals via current-biased Josephson Junctions II: Arriving at single-photon detection sensitivity](https://arxiv.org/abs/2510.20570)
*Y. Q. Chai,M. Y. Wang,S. N. Wang,P. H. Ouyang,L. F. Wei*

Main category: quant-ph

TL;DR: 本文证明非平衡约瑟夫森阈值检测器（JTD）可以实现对弱微波信号的更高灵敏度检测，达到能量量子极限，并能实现单微波光子检测。


<details>
  <summary>Details</summary>
Motivation: 基于之前关于平衡JTD检测灵敏度极限的研究，探索非平衡JTD能否实现更高灵敏度的微波信号检测。

Method: 在热噪声存在下，数值模拟不同偏置电流扫描速率下CBJJ的相位动力学，分析JTD在有和无微波信号输入时的开关电流分布（SCD）行为差异。

Result: 发现快速非绝热驱动下，JTD的SCD对热噪声不敏感，非平衡JTD比平衡状态具有更高的检测灵敏度，能够实现单微波光子检测。

Conclusion: 非平衡JTD可作为宽带微波单光子探测器，并估计了其动态范围、检测带宽和光子数分辨率等性能指标。

Abstract: It is well known that the current-biased Josephson junction (CBJJ) can serve
as a Josephson threshold detector (JTD) for the sensitive detection of weak
microwave signals. Based on the recent work (PRB {\bf 111}, 024501 (2025)) on
the detection sensitive limit of the usual equilibrium JTD, here we numerically
demonstrate that a non-equilibrium JTD can be alternatively utilized to
implement the higher sensitive detection of a weak microwave signal, arriving
at its energy quantum limit. In the presence of thermal noise, we numerically
simulate the phase dynamics for the CBJJ in the JTD with the different sweep
rates of the biased currents, and find that the SCDs of the JTD with and
without the microwave signal input show different behaviors. It is demonstrated
that, depending on how high the sweep rate of the biased current being applied,
the JTD can be operated in either the equilibrium- or the non-equilibrium
state. Specifically, under the rapidly non-adiabatic driving, the SCDs of the
JTD are obviously insensitive to the thermal noises, which means that the
non-equilibrium JTD can possess a higher achievable detection sensitivity,
compared with its equilibrium state counterpart. Consequently, the
non-equilibrium JTD can be utilized to implement the desired single
microwave-photon detection. Also, some of the achievable performance indexes,
such as the dynamic range, detection bandwidth, and the photon-number
resolvability, etc., of the non-equilibrium JTD have been estimated, when it
serves as a wideband microwave single-photon detector.

</details>


### [157] [Phase Transitions and Virtual Exceptional Points in Quantum Emitters Coupled to Dissipative Baths](https://arxiv.org/abs/2510.20571)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 研究了单个量子发射器在具有均匀损耗的半无限玻色子晶格边缘的弛豫动力学，发现了丰富的动力学相变和最优耗散环境加速自发辐射的现象。


<details>
  <summary>Details</summary>
Motivation: 控制工程环境中的原子-光子相互作用是量子光学和新兴量子技术的核心，非厄米光子浴为这种控制提供了多功能平台。

Method: 研究单个两能级量子发射器耦合到具有均匀损耗的半无限玻色子晶格边缘的弛豫动力学，分析解析函数的谱重构和共振态合并。

Result: 发现了动力学相变，建立了最优耗散环境加速自发辐射的存在，识别了共振起源的虚拟异常点。

Conclusion: 耗散的具体性质（均匀损耗、交错损耗或退相干）深刻影响发射器弛豫，表明耗散工程是量子技术的通用工具。

Abstract: Controlling atom-photon interactions in engineered environments is central to
quantum optics and emerging quantum technologies. Non-Hermitian (NH) photonic
baths, where dissipation fundamentally reshapes spectral and dynamical
properties, provide versatile platforms for such control. Here we investigate
the relaxation dynamics of a single two-level quantum emitter coupled to the
edge of a semi-infinite dissipative bosonic lattice with uniform loss. Despite
the simplicity of this bath, we uncover rich dynamical phase transitions, i.e.
qualitative changes in spontaneous emission decay as system parameters are
varied. In particular, we establish the existence of an optimal dissipative
environment for accelerated spontaneous emission. The phase transitions are
traced to spectral restructuring of the resolvent, in some cases governed by
the coalescence of resonance states on the second Riemann sheet. We identify
these coalescences as virtual exceptional points (EPs) of resonance origin,
providing a conceptual bridge with EP physics while highlighting distinctive
features of infinite-dimensional NH systems. More broadly, our results
illustrate how the specific nature of dissipation -- whether uniform losses,
staggered losses, or dephasing -- can profoundly impact emitter relaxation,
pointing to dissipation engineering as a versatile tool for quantum
technologies.

</details>


### [158] [Generating pseudo-random unitaries with a Floquet driven chaotic quantum system](https://arxiv.org/abs/2510.20581)
*Alice C. Quillen,Abobakar Sediq Miakhel*

Main category: quant-ph

TL;DR: 使用环面上的遍历Floquet量子系统生成伪随机幺正算子，通过控制参数分布生成近似3-design。


<details>
  <summary>Details</summary>
Motivation: 探索利用遍历量子系统生成伪随机幺正算子，以替代传统的Haar随机分布。

Method: 在强扰动和扰动频率超过振动频率的扰动Harper模型中选择参数区域，计算Floquet传播子生成幺正算子样本，通过k-frame势比较与Haar随机分布的差异。

Result: 发现4个控制参数的均匀分布可以生成近似3-design，当Floquet系统参数漂移时，需要更少的控制参数即可生成近似3-design。

Conclusion: 遍历Floquet量子系统可以有效生成伪随机幺正算子，在参数漂移情况下具有更高的效率。

Abstract: We explore using an ergodic Floquet quantum system on a torus to generate
pseudo-random unitary operators. We choose a regime of the perturbed Harper
model with strong perturbations and perturbation frequency exceeding the
libration frequency to ensure that the system has an ergodic region that covers
phase space and lacks resonant substructure. We generate a sample of unitary
operators in a finite dimensional space by computing Floquet propagators from a
distribution of its control parameters. To compare the distribution of
unitaries to that of a Haar-random distribution, we compute k-frame potentials
from samples of numerically generated unitaries. We find that uniform
distributions of 4 control parameters can generate an approximate 3-design.
Distributions of fewer control parameters are required to create an approximate
3-design if the Floquet system parameters drift.

</details>


### [159] [A Gateway to Quantum Computing for Industrial Engineering](https://arxiv.org/abs/2510.20620)
*Emily L. Tucker,Mohammadhossein Mohammadisiahroudi*

Main category: quant-ph

TL;DR: 本文为工业工程和运筹学研究者提供量子计算路线图，介绍量子计算基础原理、硬件软件现状、相关算法进展，并探讨应用研究方向和学习路径。


<details>
  <summary>Details</summary>
Motivation: 量子计算作为新兴计算范式，为工业工程和运筹学带来机遇与挑战，但学习曲线陡峭，需要为研究者提供导航指南。

Method: 通过介绍量子计算基础原理、分析当前硬件软件生态、综述相关算法进展，并探讨问题域驱动的研究方向。

Result: 建立了量子运筹学的系统框架，包括理论基础、技术现状、算法应用和学习路径，为跨学科研究提供指导。

Conclusion: 工业工程师在塑造量子计算实际应用方面具有独特优势，通过降低入门门槛、促进合作，量子技术将为工业和学术界带来实质性影响。

Abstract: Quantum computing is rapidly emerging as a new computing paradigm with the
potential to improve decision-making, optimization, and simulation across
industries. For industrial engineering (IE) and operations research (OR), this
shift introduces both unprecedented opportunities and substantial challenges.
The learning curve is high, and to help researchers navigate the emerging field
of quantum operations research, we provide a road map of the current field of
quantum operations research. We introduce the foundational principles of
quantum computing, outline the current hardware and software landscape, and
survey major algorithmic advances relevant to IE/OR, including quantum
approaches to linear algebra, optimization, machine learning, and stochastic
simulation. We then highlight applied research directions, including the
importance of problem domains for driving long-term value of quantum computers
and how existing classical OR models can be reformulated for quantum hardware.
Recognizing the steep learning curve, we propose pathways for IE/OR researchers
to develop technical fluency and engage in this interdisciplinary domain. By
bridging theory with application, and emphasizing the interplay between
hardware and research development, we argue that industrial engineers are
uniquely positioned to shape the trajectory of quantum computing for practical
problem-solving. Ultimately, we aim to lower the barrier to entry into quantum
computing, motivate new collaborations, and chart future directions where
quantum technologies may deliver tangible impact for industry and academia.

</details>


### [160] [Quantum Processing Unit (QPU) processing time Prediction with Machine Learning](https://arxiv.org/abs/2510.20630)
*Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito*

Main category: quant-ph

TL;DR: 本研究应用机器学习技术预测量子作业的QPU处理时间，使用基于LightGBM的梯度提升方法，在约15万个IBM Quantum作业数据集上构建预测模型，以提高量子计算系统的运行效率。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习在量子计算领域的应用潜力，通过预测量子作业的QPU处理时间来提升量子计算系统的操作效率和资源管理能力。

Method: 采用基于梯度提升的LightGBM机器学习算法，结合数据预处理方法，在约15万个遵循IBM Quantum架构的作业数据集上构建预测模型。

Result: 研究结果表明机器学习方法在预测量子作业处理时间方面具有显著效果，能够有效提升预测准确性。

Conclusion: 该研究不仅展示了机器学习在优化量子作业预测方面的潜力，还为在先进量子计算操作中集成AI驱动工具奠定了基础。

Abstract: This paper explores the application of machine learning (ML) techniques in
predicting the QPU processing time of quantum jobs. By leveraging ML
algorithms, this study introduces predictive models that are designed to
enhance operational efficiency in quantum computing systems. Using a dataset of
about 150,000 jobs that follow the IBM Quantum schema, we employ ML methods
based on Gradient-Boosting (LightGBM) to predict the QPU processing times,
incorporating data preprocessing methods to improve model accuracy. The results
demonstrate the effectiveness of ML in forecasting quantum jobs. This
improvement can have implications on improving resource management and
scheduling within quantum computing frameworks. This research not only
highlights the potential of ML in refining quantum job predictions but also
sets a foundation for integrating AI-driven tools in advanced quantum computing
operations.

</details>


### [161] [Computing time-dependent reduced models for classical and quantum dynamics](https://arxiv.org/abs/2510.20675)
*Tommaso Grigoletto*

Main category: quant-ph

TL;DR: 提出一种新颖的递归算法，用于构建时间依赖的多项式生成器，以近似大型自治系统在固定子空间上的动力学，在短时间尺度上保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决量子物理中推导时间无卷积主方程的挑战，为基于耦合强度展开的典型推导方法提供替代方案。

Method: 基于指数映射的泰勒展开和计算多项式生成器的时间顺序指数的新结果，开发递归算法构建有效的时间依赖生成器。

Result: 近似方法在短时间内准确，不需要弱耦合假设，在低阶时比指数映射截断表现更好，并在最低阶保证完全正性和迹保持映射。

Conclusion: 该方法在多个原型模型（退相干自旋-玻色子模型、中心自旋模型和伊辛自旋链）上得到验证，为量子系统动力学模拟提供了有效工具。

Abstract: This paper introduces a novel method for approximating the dynamics of a
large autonomous system projected onto a fixed subspace. The core contribution
is a novel recursive algorithm to construct an effective time-dependent
generator that is polynomial in the time variable, ensuring accuracy for short
time scales. The derivation is based on the Taylor expansion of the exponential
map and a new result for computing the time-ordered exponential of polynomial
generators. This work is motivated by the challenge of deriving
time-convolutionless master equations in quantum physics and the proposed
method offers an alternative to typical derivations based on expansions in the
coupling strength. The resulting approximation is accurate for small times,
does not require a weak-coupling assumption, performs better than a truncation
of the exponential map at low orders, and crucially, guarantees a completely
positive and trace-preserving map at the lowest orders. The proposed method is
validated against several prototypical models: a dephasing spin-boson model, a
central spin model, and an Ising spin chain.

</details>


### [162] [Classical Noise Inversion: A Practical and Optimal framework for Robust Quantum Applications](https://arxiv.org/abs/2510.20686)
*Dayue Qin,Ying Li,You Zhou*

Main category: quant-ph

TL;DR: 提出了经典噪声反转（CNI）框架，通过经典后处理完全反转累积噪声，避免了昂贵的量子电路采样需求，并在门相关噪声等现实条件下保持有效性。


<details>
  <summary>Details</summary>
Motivation: 量子误差缓解技术面临两大挑战：量子电路采样的高昂成本和依赖不现实的假设（如门独立噪声）。需要一种能绕过这些限制的实用方法。

Method: 引入经典噪声反转（CNI）框架，完全在经典后处理中反转累积噪声；提出噪声压缩技术，将具有等效测量效果的噪声分量分组；将CNI与影子估计框架结合。

Result: 分析和数值模拟表明，该方法显著减少统计方差，在实际情况下提供无偏估计，而先前方法在此类情况下会失败。

Conclusion: 通过将关键的量子开销转化为可管理的经典成本，CNI为可扩展和实用的量子应用开辟了有前景的途径。

Abstract: Quantum error mitigation is a critical technology for extracting reliable
computations from noisy quantum processors, proving itself essential not only
in the near term but also as a valuable supplement to fully fault-tolerant
systems in the future. However, its practical implementation is hampered by two
major challenges: the expansive cost of sampling from quantum circuits and the
reliance on unrealistic assumptions, such as gate-independent noise. Here, we
introduce Classical Noise Inversion (CNI), a framework that fundamentally
bypasses these crucial limitations and is well-suited for various quantum
applications. CNI effectively inverts the accumulated noise entirely during
classical post-processing, thereby eliminating the need for costly quantum
circuit sampling and remaining effective under the realistic condition of
gate-dependent noise. Apart from CNI, we introduce noise compression, which
groups noise components with equivalent effects on measurement outcomes,
achieving the optimal overhead for error mitigation. We integrate CNI with the
framework of shadow estimation to create a robust protocol for learning quantum
properties under general noise. Our analysis and numerical simulations
demonstrate that this approach substantially reduces statistical variance while
providing unbiased estimates in practical situations where previous methods
fail. By transforming a key quantum overhead into a manageable classical cost,
CNI opens a promising pathway towards scalable and practical quantum
applications.

</details>


### [163] [Note on Energy Shifts of Oscillators in Blackbody Radiation](https://arxiv.org/abs/2510.20711)
*Peter Milonni*

Main category: quant-ph

TL;DR: 基于折射率计算黑体辐射中振荡器的能量位移，发现在高温下能量位移和自由能位移分别与-T^2和+T^2成正比，与Ford等人的结果一致。


<details>
  <summary>Details</summary>
Motivation: 研究黑体辐射中振荡器的能量位移问题，验证前人理论结果。

Method: 通过计算相互作用场-振荡器系统的总能量随折射率的变化来推导能量位移。

Result: 高温条件下，能量位移与-T^2成正比，自由能位移与+T^2成正比。

Conclusion: 该方法得到的结果与Ford等人1985年的原始结果一致，验证了理论的正确性。

Abstract: The energy shift of an oscillator in blackbody radiation is calculated based
simply on the total energy of the interacting field-oscillator system as a
function of the refractive index. For high temperatures T the energy and
free-energy shifts are found to vary as -T^2 and +T^2, respectively, in
agreement with the result originally obtained by Ford, Lewis, and O'Connell
[Phys. Rev. Lett. 55, 2273 (1985)].

</details>


### [164] [Experimental differentiation and extremization with analog quantum circuits](https://arxiv.org/abs/2510.20713)
*Evan Philip,Julius de Hond,Vytautas Abramavicius,Kaonan Micadei,Mario Dagrada,Panagiotis Barkoutsos,Mourad Beji,Louis-Paul Henry,Vincent E. Elfving,Antonio A. Gentile,Savvas Varsamopoulos*

Main category: quant-ph

TL;DR: 本文首次实验演示了可微分量子电路(DQC)和量子极值学习(QEL)在模拟量子计算机上的应用，成功挑战了这些方法需要数字量子硬件的假设。


<details>
  <summary>Details</summary>
Motivation: 量子架构有望加速科学计算，特别是微分方程求解和优化。DQC和QEL提供了在现有量子计算机上计算微分方程解和寻找极值点的可行路径。

Method: 使用可微分量子电路通过变分方法计算微分方程解，结合量子极值学习寻找隐函数的极值点。在基于中性原子技术的商用模拟量子计算机上实现闭环实例。

Result: 成功在模拟量子计算机上运行了DQC和QEL的闭环实例，展示了这两种方法的性能，突破了传统认为这些方法需要数字量子硬件的限制。

Conclusion: DQC和QEL可以在模拟量子硬件上有效实现，为量子计算在科学计算中的应用开辟了新途径，特别是在微分方程求解和极值优化方面。

Abstract: Solving and optimizing differential equations (DEs) is ubiquitous in both
engineering and fundamental science. The promise of quantum architectures to
accelerate scientific computing thus naturally involved interest towards how
efficiently quantum algorithms can solve DEs. Differentiable quantum circuits
(DQC) offer a viable route to compute DE solutions using a variational approach
amenable to existing quantum computers, by producing a machine-learnable
surrogate of the solution. Quantum extremal learning (QEL) complements such
approach by finding extreme points in the output of learnable models of unknown
(implicit) functions, offering a powerful tool to bypass a full DE solution, in
cases where the crux consists in retrieving solution extrema. In this work, we
provide the results from the first experimental demonstration of both DQC and
QEL, displaying their performance on a synthetic usecase. Whilst both DQC and
QEL are expected to require digital quantum hardware, we successfully challenge
this assumption by running a closed-loop instance on a commercial analog
quantum computer, based upon neutral atom technology.

</details>


### [165] [How typical is contextuality?](https://arxiv.org/abs/2510.20722)
*Vinicius P. Rossi,Beata Zjawin,Roberto D. Baldijão,David Schmid,John H. Selby,Ana Belén Sainz*

Main category: quant-ph

TL;DR: 本文研究量子非经典性的典型性，发现即使使用少量随机制备和测量，上下文性出现的概率也超过99%。虽然纯度降低会减少上下文性，但即使在有噪声的现实环境中，上下文性仍然相当常见。


<details>
  <summary>Details</summary>
Motivation: 研究量子非经典性在随机量子实验中的出现频率，为量子基础理论和实验设计提供指导。

Method: 使用数值线性程序测试广义非上下文模型的存在性，分析随机选择的量子制备和测量产生非经典统计的典型性。

Result: 上下文性相当常见：在仅有少量随机制备和测量的实验中，上下文性出现概率超过99%。虽然纯度降低会减少上下文性，但即使在有噪声的环境中仍然相当典型。

Conclusion: 非零上下文性很常见，但高度上下文性不那么典型，因此大的量子优势（如奇偶性无关多路复用）不那么常见。提供了开源工具箱来指导实验设计。

Abstract: Identifying when observed statistics cannot be explained by any reasonable
classical model is a central problem in quantum foundations. A principled and
universally applicable approach to defining and identifying nonclassicality is
given by the notion of generalized noncontextuality. Here, we study the
typicality of contextuality -- namely, the likelihood that randomly chosen
quantum preparations and measurements produce nonclassical statistics. Using
numerical linear programs to test for the existence of a
generalized-noncontextual model, we find that contextuality is fairly common:
even in experiments with only a modest number of random preparations and
measurements, contextuality arises with probability over 99%. We also show that
while typicality of contextuality decreases as the purity (sharpness) of the
preparations (measurements) decreases, this dependence is not especially
pronounced, so contextuality is fairly typical even in settings with realistic
noise. Finally, we show that although nonzero contextuality is quite typical,
quantitatively high degrees of contextuality are not as typical, and so large
quantum advantages (like for parity-oblivious multiplexing, which we take as a
case study) are not as typical. We provide an open-source toolbox that outputs
the typicality of contextuality as a function of tunable parameters (such as
lower and upper bounds on purity and other constraints on states and
measurements). This toolbox can inform the design of experiments that achieve
the desired typicality of contextuality for specified experimental constraints.

</details>


### [166] [Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems](https://arxiv.org/abs/2510.20728)
*Xi He,Sirui Lu,Bei Zeng*

Main category: quant-ph

TL;DR: 提出了一个多智能体、人在环的工作流程，用于共同设计具有规定横向对角门的量子码。该流程基于SSLP框架，通过GPT-5驱动，在TeXRA平台上实现系统枚举与精确分析重构的结合。


<details>
  <summary>Details</summary>
Motivation: 开发一个可扩展的工作流程，将横向对角门的可行性问题转化为分析管道，结合系统枚举与精确分析重构，实现可重现的量子码构造。

Method: 使用多智能体协作框架：合成智能体制定问题，搜索智能体筛选候选解并将数值精确化为有理数，审计智能体独立验证KL等式和逻辑作用。基于SSLP框架，通过模块化残差划分基字符串并强制执行Z-边际KL等式。

Result: 对于码距d=2、非退化残差的情况，在码维K∈{2,3,4}和n≤6量子比特下，系统扫描生成了经过验证的表格，记录了可实现的循环逻辑群。例如，K=3时在n=6处获得阶16。还展示了SSLP可容纳残差退化，构建了新的((6,4,2))码实现横向受控相位门。

Conclusion: 该工作流程成功地将横向对角门可行性问题转化为可扩展的分析管道，结合了系统枚举与精确分析重构，产生了可重现的码构造，支持向更大K和更高码距的扩展，并导向数据驱动的分类。

Abstract: We present a multi-agent, human-in-the-loop workflow that co-designs quantum
codes with prescribed transversal diagonal gates. It builds on the Subset-Sum
Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis
strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)
equalities via small LPs. The workflow is powered by GPT-5 and implemented
within TeXRA (https://texra.ai)-a multi-agent research assistant platform that
supports an iterative tool-use loop agent and a derivation-then-edit workflow
reasoning agent. We work in a LaTeX-Python environment where agents reason,
edit documents, execute code, and synchronize their work to Git/Overleaf.
Within this workspace, three roles collaborate: a Synthesis Agent formulates
the problem; a Search Agent sweeps/screens candidates and exactifies numerics
into rationals; and an Audit Agent independently checks all KL equalities and
the induced logical action. As a first step we focus on distance $d=2$ with
nondegenerate residues. For code dimension $K\in\{2,3,4\}$ and $n\le6$ qubits,
systematic sweeps yield certificate-backed tables cataloging attainable cyclic
logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$
at $n=6$. From verified instances, Synthesis Agent abstracts recurring
structures into closed-form families and proves they satisfy the KL equalities
for all parameters. It further demonstrates that SSLP accommodates residue
degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal
controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts
diagonal-transversal feasibility as an analytical pipeline executed at scale,
combining systematic enumeration with exact analytical reconstruction. It
yields reproducible code constructions, supports targeted extensions to larger
$K$ and higher distances, and leads toward data-driven classification.

</details>


### [167] [Optimal constant-cost implementations of Clifford operations using global interactions](https://arxiv.org/abs/2510.20730)
*Jonathan Nemirovsky,Lee Peleg,Amit Ben Kish,Yotam Shapira*

Main category: quant-ph

TL;DR: 该论文提出了一种使用最多4次全连接多量子比特纠缠门即可实现任意长度Clifford操作序列的量子电路编译方法，无需辅助量子比特，达到了理论最优门数成本。


<details>
  <summary>Details</summary>
Motivation: 研究在离子阱等量子计算平台上，如何利用其固有的全连接多量子比特纠缠门特性，优化Clifford操作的实现效率，减少门应用次数和量子比特驱动功率。

Method: 通过实现任意长度CNOT门序列仅需4次多量子比特纠缠门应用，然后将该方法扩展到一般Clifford操作，开发了实用且计算高效的编译算法。

Result: 实现了理论最优的4次门应用成本，无需辅助量子比特，且所需的量子比特驱动功率低于标准方法。

Conclusion: 该工作提供了一种在实际量子计算平台上高效实现Clifford操作的方法，具有最优门数和较低功耗的优势。

Abstract: We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than four applications of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae, which is the theoretically optimal gate count
cost. We do this by implementing any sequence of CNOT gates of any length with
four applications of such gates, without ancillae, and show that the extension
to general Clifford operations incurs no additional cost. We investigate the
required qubit drive power that is associated with our implementation and show
that it is lower than that of a standard approach. Our work introduces a
practical and computationally efficient algorithm to realize these
compilations.

</details>


### [168] [The complexity of perfect quantum state classification](https://arxiv.org/abs/2510.20789)
*Nathaniel Johnston,Benjamin Lovitz,Vincent Russo,Jamie Sikora*

Main category: quant-ph

TL;DR: 本文引入k-可学习性概念，研究量子态分类问题，建立了k-可学习性的判定方法与计算复杂度边界。


<details>
  <summary>Details</summary>
Motivation: 量子态分类问题旨在识别未知量子态，本文关注零错误情况下最多使用k次猜测就能正确识别的能力。

Method: 使用半定规划方法判定k-可学习性，针对不同情况设计多项式时间算法：当k固定或态维度固定时。

Result: 当k和态维度均为输入时，问题属于NP类且是NP难问题，通过从经典k-团问题归约证明。

Conclusion: 本文划定了在完美零错误情况下量子态分类问题中可高效求解与难解实例的边界。

Abstract: The problem of quantum state classification asks how accurately one can
identify an unknown quantum state that is promised to be drawn from a known set
of pure states. In this work, we introduce the notion of $k$-learnability,
which captures the ability to identify the correct state using at most $k$
guesses, with zero error. We show that deciding whether a given family of
states is $k$-learnable can be solved via semidefinite programming. When there
are $n$ states, we present polynomial-time (in $n$) algorithms for determining
$k$-learnability for two cases: when $k$ is a fixed constant or the dimension
of the states is a fixed constant. When both $k$ and the dimension of the
states are part of the input, we prove that there exist succinct certificates
placing the problem in NP, and we establish NP-hardness by a reduction from the
classical $k$-clique problem. Together, our findings delineate the boundary
between efficiently solvable and intractable instances of quantum state
classification in the perfect (zero-error) regime.

</details>


### [169] [Analog Quantum Feature Selection with Neutral-Atom Quantum Processors](https://arxiv.org/abs/2510.20798)
*Jose J. Orquin-Marques,Carlos Flores-Garrigos,Alejandro Gomez Cadavid,Anton Simen,Enrique Solano,Narendra N. Hegade,Jose D. Martin-Guerrero,Yolanda Vives-Gilabert*

Main category: quant-ph

TL;DR: 提出基于中性原子阵列模拟量子计算的量子特征选择方法，通过编码特征相关性和冗余度，在三个基准数据集上取得优于经典方法的性能，特别是在2-5个特征的紧凑子集上AUC提升1.5-2.3%，同时减少75-84%的特征数量。


<details>
  <summary>Details</summary>
Motivation: 将量子计算优势转化为工业实用性，为机器学习管道提供智能特征选择解决方案，利用量子系统天然处理特征相关性和冗余度的能力。

Method: 使用中性原子阵列进行模拟量子计算，将特征相关性编码为局部失谐幅度，特征冗余度通过距离相关的范德瓦尔斯相互作用嵌入，系统通过绝热演化达到低能态配置。

Result: 在Adult Income、Bank Marketing和Telco Churn三个二分类数据集上，相比互信息排序和Boruta等经典方法结合XGBoost和随机森林分类器，量子方法达到竞争性或更优性能。

Conclusion: 可编程里德堡原子阵列为机器学习管道中的智能特征选择提供了可行平台，能够将计算量子优势转化为工业量子实用性。

Abstract: We present a quantum-native approach to quantum feature selection (QFS) based
on analog quantum simulation with neutral atom arrays, adaptable to a variety
of academic and industrial applications. In our method, feature
relevance-measured via mutual information with the target-is encoded as local
detuning amplitudes, while feature redundancy is embedded through
distance-dependent van der Waals interactions, constrained by the Rydberg
blockade radius. The system is evolved adiabatically toward low-energy
configurations, and the resulting measurement bitstrings are used to extract
physically consistent subsets of features. The protocol is evaluated through
simulations on three benchmark binary classification datasets: Adult Income,
Bank Marketing, and Telco Churn. Compared to classical methods such as mutual
information ranking and Boruta, combined with XGBoost and Random Forest
classifiers, our quantum-computing approach achieves competitive or superior
performance. In particular, for compact subsets of 2-5 features, analog QFS
improves mean AUC scores by 1.5-2.3% while reducing the number of features by
75-84%, offering interpretable, low-redundancy solutions. These results
demonstrate that programmable Rydberg arrays offer a viable platform for
intelligent feature selection with practical relevance in machine learning
pipelines, capable of transforming computational quantum advantage into
industrial quantum usefulness.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [170] [Investigation of the Mechanical Properties of Three Commercial and Five Variations of IOL Models](https://arxiv.org/abs/2510.20015)
*Taner Karateke,Abdullah MevlÜt Mutluel*

Main category: physics.comp-ph

TL;DR: 使用有限元分析模拟8种不同人工晶状体模型的机械稳定性，发现商业模型在小压缩力下表现更好，而变体模型在大压缩力下表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究不同人工晶状体模型的机械稳定性，为开发更稳定的IOL提供依据。

Method: 使用有限元方法模拟准静态压缩下8种IOL模型的机械生物标志物（轴向位移、弹性模量和应力）。

Result: 商业IOL模型在小压缩力下机械响应更好，变体模型在大压缩力下表现更优。

Conclusion: 这些发现有助于开发机械稳定性更好的人工晶状体模型。

Abstract: This study aimed to simulate the mechanical stability of eight different
(three commercial and five variations) haptic IOL models using FEM to measure
mechanical biomarkers (axial displacement, elasticity modulus, and stress)
under quasi-static compression. The results revealed that a commercial IOL
model exhibited a better mechanical response for smaller compression forces
than the other models. Conversely, a variation model performed better for
larger compression forces. These findings may help in developing more
mechanically stable IOL models.

</details>


### [171] [ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature](https://arxiv.org/abs/2510.20362)
*Aritra Roy,Enrico Grisan,John Buckeridge,Chiara Gattinoni*

Main category: physics.comp-ph

TL;DR: ComProScanner是一个自主多智能体平台，用于从科学文献中提取、验证、分类和可视化机器可读的化学成分和性质，并整合合成数据以创建综合数据库。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练大语言模型在科学文本结构化知识提取方面取得了革命性进展，但允许用户构建、验证和可视化科学文献提取数据集的自动化工具仍然稀缺，特别是针对陶瓷压电材料等复杂材料缺乏大型数据集。

Method: 开发了ComProScanner多智能体平台，使用10种不同的大语言模型（包括开源和专有模型）从100篇期刊文章中提取高度复杂的陶瓷压电材料成分和相应的压电应变系数(d33)。

Result: DeepSeek-V3-0324在所有模型中表现最佳，总体准确率达到0.82。

Conclusion: 该框架提供了一个简单、用户友好、易于使用的工具包，用于从文献中提取高度复杂的实验数据，以构建机器学习或深度学习数据集。

Abstract: Since the advent of various pre-trained large language models, extracting
structured knowledge from scientific text has experienced a revolutionary
change compared with traditional machine learning or natural language
processing techniques. Despite these advances, accessible automated tools that
allow users to construct, validate, and visualise datasets from scientific
literature extraction remain scarce. We therefore developed ComProScanner, an
autonomous multi-agent platform that facilitates the extraction, validation,
classification, and visualisation of machine-readable chemical compositions and
properties, integrated with synthesis data from journal articles for
comprehensive database creation. We evaluated our framework using 100 journal
articles against 10 different LLMs, including both open-source and proprietary
models, to extract highly complex compositions associated with ceramic
piezoelectric materials and corresponding piezoelectric strain coefficients
(d33), motivated by the lack of a large dataset for such materials.
DeepSeek-V3-0324 outperformed all models with a significant overall accuracy of
0.82. This framework provides a simple, user-friendly, readily-usable package
for extracting highly complex experimental data buried in the literature to
build machine learning or deep learning datasets.

</details>
