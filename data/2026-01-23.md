<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [cs.LG](#cs.LG) [Total: 56]
- [gr-qc](#gr-qc) [Total: 8]
- [quant-ph](#quant-ph) [Total: 42]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Bayesian identification of fibrous insulation thermal conductivity towards design of spacecraft thermal protection systems](https://arxiv.org/abs/2601.15427)
*Alex Alberts,Akshay Jacob Thomas,Kamran Daryabeigi,Ilias Bilionis*

Main category: physics.comp-ph

TL;DR: 提出基于信息场理论的贝叶斯框架，从稀疏实验数据重建高温纤维隔热材料的热导率，并将其应用于火星和地球再入轨迹的热防护系统性能预测。


<details>
  <summary>Details</summary>
Motivation: 航天器热防护系统设计需要准确的热传输特性数据，但传统实验室测量技术温度范围有限，且通常只能获得温度测量值，需要通过逆问题间接推断热导率。

Method: 采用信息场理论的贝叶斯框架，将热导率表示为高斯过程，通过热方程推导的温度物理信息先验来强制执行物理约束，从稀疏实验数据重建热导率。

Result: 方法在合成和实验数据上成功重建了超出实验范围的热导率，验证结果与参考数据一致，并应用于火星和地球再入轨迹的柔性热防护系统数字孪生性能预测。

Conclusion: 信息场理论能够提供具有量化不确定性的准确预测，使热防护系统能够在无法直接测量的工况下进行稳健的尺寸设计。

Abstract: The design of spacecraft thermal protection systems (TPS) requires accurate knowledge of thermal transport properties across wide ranges of temperature and pressure. For fibrous insulation, conventional measurement techniques in laboratory settings are typically limited to temperatures much lower than what is reached in atmosphere entry scenarios. Moreover, it is often the case that only temperature measurements are available, meaning that the thermal conductivity of the insulation must be indirectly inferred as an inverse problem. We propose a Bayesian framework using information field theory (IFT) to reconstruct the thermal conductivity of high-temperature fibrous insulation from sparse experimental data. Under IFT, the conductivity is represented as a Gaussian process, and the physics is enforced via a physics-informed prior over the temperature derived from the heat equation. Bayes's rule produces an infinite-dimensional posterior distribution that quantifies uncertainty about the conductivity which can be evaluated in extrapolation regimes. We apply the method to Opacified Fibrous Insulation with both synthetic and experimental data to reconstruct the thermal conductivity beyond the experimental regime. The inferred conductivities are validated against reference data and then propagated into high-fidelity digital twins of flexible TPS performance under Mars and Earth entry trajectories. The results show that IFT yields accurate predictions with quantified uncertainty, enabling robust TPS sizing in regimes inaccessible to direct measurement.

</details>


### [2] [Equivariant Interatomic Potentials without Tensor Products](https://arxiv.org/abs/2601.15492)
*Thiago Reschützegger,Sarp Aykent,Gabriel Jacob Perin,Bruno Henrique Nunes,Flaviu Cipcigan,Rodrigo Neumann Barros Ferreira,Mathias Steiner,Fabian L. Thiemann*

Main category: physics.comp-ph

TL;DR: Geodite是一种新的等变消息传递架构，通过替代计算成本高昂的张量积操作，在保持物理先验的同时实现了3-5倍的推理速度提升，在材料稳定性预测、热导率等基准测试中达到领先方法的竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 现有最准确的等变架构依赖于Clebsch-Gordan张量积，其计算成本随角分辨率急剧增加，导致模型表达能力与推理速度之间存在权衡，限制了实际应用。需要一种既能保持物理准确性又具有计算效率的新架构。

Method: Geodite是一种等变消息传递架构，它替代了传统的张量积操作，同时结合物理先验来确保平滑、行为良好的势能表面。该方法在Materials Project轨迹数据集的无机晶体上进行训练。

Result: Geodite-MP在材料稳定性预测、热导率、声子衍生性质和纳秒尺度分子动力学等基准测试中，与领先方法达到竞争性精度，同时运行速度比性能相当的模型快3-5倍。

Conclusion: Geodite通过结合预测准确性、计算效率和物理性，实现了更快的大规模原子模拟和高通量筛选，这些应用原本在计算上是不可行的。该架构解决了等变模型中表达能力与速度之间的权衡问题。

Abstract: Foundational machine-learned interatomic potentials have emerged as powerful tools for atomistic simulations, promising near first-principles accuracy across diverse chemical spaces at a fraction of the cost of quantum-mechanical calculations. However, the most accurate equivariant architectures rely on Clebsch-Gordan tensor products whose computational cost scales steeply with angular resolution, creating a trade-off between model expressiveness and inference speed that ultimately limits practical applications. Here we introduce Geodite, an equivariant message-passing architecture that replaces tensor products while incorporating physical priors to ensure smooth, well-behaved potential energy surfaces. Trained on the Materials Project trajectories dataset of inorganic crystals, Geodite-MP achieves accuracy competitive with leading methods on benchmarks for materials stability prediction, thermal conductivity, phonon-derived properties, and nanosecond-scale molecular dynamics, while running $3\text{--}5\times$ faster than models performing similarly. By combining predictive accuracy, computational efficiency, and physicality, Geodite enables faster large-scale atomistic simulations and high-throughput screening that would otherwise be computationally prohibitive.

</details>


### [3] [Convolutional LSTM Surrogate for Mesoscale Hydrocode Simulations of Granular Wave Propagation](https://arxiv.org/abs/2601.15497)
*Kathleen Winona Vian Martinus,Sushan Nakarmi,Dawa Seo,Nitin Pandurang Daphalapurkar*

Main category: physics.comp-ph

TL;DR: 使用ConvLSTM神经网络作为时空替代模型，替代计算昂贵的细观尺度模拟，预测颗粒材料中的弱冲击波传播


<details>
  <summary>Details</summary>
Motivation: 细观尺度模拟能够解析颗粒材料在冲击载荷下的复杂动力学，但计算成本高昂，限制了参数研究和不确定性量化。需要开发高效的替代模型来加速参数空间探索。

Method: 开发卷积长短期记忆（ConvLSTM）神经网络作为时空替代模型。使用二维流体力学代码模拟作为训练数据，采用序列到序列架构，从短期历史预测未来压力场图像。比较了多种架构，最终采用相对紧凑的编码器-解码器ConvLSTM。

Result: ConvLSTM模型能够准确再现未见过的参数组合下的压力波传播和颗粒运动。在颗粒集合的弱冲击压实模拟中，即使完全未在训练中出现的活塞冲击速度，替代模型也能捕捉压实前沿的位置和形状及其对冲击速度的依赖性，同时平滑了高度压实区域的细观孔隙尺度细节。

Conclusion: ConvLSTM模型可以作为颗粒材料冲击波传播细观尺度模拟的满意替代模型，能够加速参数空间探索，并为物理信息增强的细观尺度模拟奠定基础。

Abstract: Granular materials subjected to impact loading exhibit highly heterogeneous spatiotemporal dynamics governed by wave propagation, pore collapse, and grain-scale rearrangements. Mesoscale hydrocodes resolve these processes but are computationally expensive, limiting their use in parametric studies and uncertainty quantification. In this work, we develop a convolutional Long Short-Term Memory (ConvLSTM) neural network as a spatiotemporal surrogate for mesoscale simulations of weak shock propagation in granular media. Using two-dimensional hydrocode simulations as training data, we first consider a simplified "billiard break" problem in which a cue ball impacts a cluster of nine circular balls, all deformable. Sequences of pressure-field images serve as input-output pairs for a sequence-to-sequence ConvLSTM, which is trained to predict future frames from a short history. We compare several architectures and show that a relatively compact encoder-decoder ConvLSTM accurately reproduces the propagation of the pressure wave and the resulting particle motion for an unseen combination of cue-ball position and impact velocity. As a proof-of-concept extension, we apply the same ConvLSTM framework to previously published mesoscale simulations of weak shock compaction in a granular ensemble. When evaluated at piston impact speeds that were completely withheld from training, the surrogate captures the position and shape of the compaction front and its dependence on impact speed, while smoothing fine pore-scale details in the highly compacted region as expected. These results demonstrate that ConvLSTM models can serve as satisfactory surrogates for spatiotemporal mesoscale simulations of granular wave propagation, enabling accelerated exploration of parameter space and laying the groundwork for physics-informed, mesoscale simulations of granular materials under shock loading.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference](https://arxiv.org/abs/2601.15333)
*Xuanning Hu,Anchen Li,Qianli Xing,Jinglong Ji,Hao Tuo,Bo Yang*

Main category: cs.LG

TL;DR: ELILLM框架通过将LLM生成过程重新解释为编码、潜在空间探索和解码工作流，增强LLM在基于结构的药物设计中的能力，实现化学有效且合成合理的分子生成。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型具有强大的表示和推理能力，但在基于结构的药物设计应用中受到限制，主要原因是：1）对蛋白质结构的理解不足；2）分子生成不可预测。需要解决这些挑战来提升LLM在药物设计中的实用性。

Method: 提出ELILLM框架，将LLM生成过程重新解释为编码、潜在空间探索和解码工作流。使用贝叶斯优化指导潜在嵌入的系统性探索，位置感知代理模型预测结合亲和力分布以指导搜索，知识引导解码减少随机性并施加化学有效性约束。

Result: 在CrossDocked2020基准测试中，ELILLM展现出强大的受控探索能力和高结合亲和力得分，优于七种基线方法，有效增强了LLM在基于结构的药物设计中的能力。

Conclusion: ELILLM框架通过重新解释LLM生成过程为编码-探索-解码工作流，成功解决了LLM在药物设计中对蛋白质结构理解不足和分子生成不可预测的问题，为基于结构的药物设计提供了有效的增强方案。

Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.

</details>


### [5] [Language Models Entangle Language and Culture](https://arxiv.org/abs/2601.15337)
*Shourya Jain,Paras Chopra*

Main category: cs.LG

TL;DR: LLMs在不同语言间的回答质量存在系统性差异，低资源语言获得更低质量回答，语言选择显著影响模型使用的文化背景


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否对不同语言用户存在系统性偏见，确保用户不会因使用不同语言而获得不同质量的回答，同时探索语言与文化在LLM中的纠缠关系

Method: 基于WildChat数据集创建真实开放性问题集，评估不同语言查询的回答质量差异；使用LLM-as-a-Judge方法识别回答中的文化背景；在CulturalBench基准的翻译子集上进行多语言评估

Result: LLMs在低资源语言的开放性问题回答质量上持续偏低；语言选择显著影响模型使用的文化背景；文化背景差异进一步影响下游回答质量

Conclusion: LLMs存在语言偏见问题，低资源语言用户获得更差回答，语言与文化背景紧密相关，影响回答质量，需要改进模型的多语言公平性

Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.

</details>


### [6] [Improving MoE Compute Efficiency by Composing Weight and Data Sparsity](https://arxiv.org/abs/2601.15370)
*Maciej Kilian,Oleg Mkrtchyan,Luke Zettlemoyer,Akshat Shrivastava,Armen Aghajanyan*

Main category: cs.LG

TL;DR: 提出在因果token-choice MoE中通过引入零计算(null)专家实现数据稀疏性，结合权重稀疏性获得更高的计算效率，在视觉语言模型中自动学习隐式的模态感知路由。


<details>
  <summary>Details</summary>
Motivation: 传统MoE通过权重稀疏性实现计算效率（每个token只激活部分专家），而数据稀疏性（每个专家只处理部分token）是另一个重要维度。但现有的专家选择路由在自回归模型中违反因果性，导致训练-推理不匹配。

Method: 在因果token-choice MoE的路由池中引入零计算(null)专家。当token路由到null专家时，这些槽位不消耗计算。通过标准的负载均衡目标训练模型均匀使用所有专家（包括null专家），从而在期望上实现数据稀疏性而不违反因果性。

Result: 在视觉语言模型训练中，权重稀疏性和数据稀疏性结合比单独使用权重稀疏性在相同期望FLOPs下获得更高的计算效率前沿，训练损失和下游性能都有提升。模型自动学习隐式的模态感知分配，视觉token比文本token更积极地路由到null专家。

Conclusion: 通过引入null专家在因果token-choice MoE中实现数据稀疏性，解决了专家选择路由的因果性问题，结合权重稀疏性获得更好的计算效率，模型能够自动适应数据异质性（如视觉-文本模态差异）。

Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.

</details>


### [7] [You Need Better Attention Priors](https://arxiv.org/abs/2601.15380)
*Elon Litman,Gabe Guo*

Main category: cs.LG

TL;DR: GOAT是一种基于熵最优运输的广义注意力机制，通过可学习的连续先验替代标准注意力中的隐式均匀先验，保持FlashAttention兼容性，解决注意力下沉问题，并实现长度泛化。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制存在隐式均匀先验假设，这限制了其表达能力并导致注意力下沉问题。作者希望通过熵最优运输框架重新审视注意力机制，引入更灵活的先验分布来克服这些限制。

Method: 将注意力机制重新解释为熵最优运输问题，提出GOAT（广义最优运输注意力）机制，使用可训练的连续先验替代标准注意力中的隐式均匀先验，同时保持与优化内核（如FlashAttention）的兼容性。

Result: GOAT不仅解决了注意力下沉问题，避免了标准注意力的表示权衡，还能通过将空间信息吸收到核心注意力计算中，学习可外推的先验，结合了学习位置嵌入的灵活性和固定编码的长度泛化能力。

Conclusion: 从熵最优运输角度重新审视注意力机制揭示了其内在局限性，GOAT通过引入可学习先验提供了更灵活、更强大的注意力机制，在保持计算效率的同时解决了现有注意力机制的多个问题。

Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.

</details>


### [8] [FedUMM: A General Framework for Federated Learning with Unified Multimodal Models](https://arxiv.org/abs/2601.15390)
*Zhaolong Su,Leheng Zhao,Xiaoying Wu,Ziyue Xu,Jindong Wang*

Main category: cs.LG

TL;DR: FedUMM是一个用于非IID多模态数据的联邦学习框架，通过轻量级LoRA适配器实现参数高效微调，显著降低通信成本，在隐私敏感场景下保持与集中式训练相当的性能。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型通常在集中式设置中训练，限制了在隐私敏感和地理分布式场景中的部署。需要开发能够在非IID多模态数据下工作的联邦学习框架。

Method: 基于NVIDIA FLARE构建FedUMM框架，使用BLIP3o作为骨干网络，通过参数高效微调：客户端训练轻量级LoRA适配器并冻结基础模型，服务器仅聚合适配器更新。

Result: 在VQA v2和GenEval组合生成基准测试中，随着客户端数量和异质性增加，性能略有下降，但仍与集中式训练保持竞争力。仅适配器联邦将每轮通信减少了一个数量级以上。

Conclusion: FedUMM为隐私保护的联邦统一多模态模型提供了实用的训练框架，通过适配器联邦显著降低了通信成本，为未来研究提供了实证经验。

Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.

</details>


### [9] [Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC](https://arxiv.org/abs/2601.15399)
*Ashna Nawar Ahmed,Banooqa Banday,Terry Jones,Tanzima Z. Islam*

Main category: cs.LG

TL;DR: 使用注意力嵌入的代理模型结合多目标贝叶斯优化，自动化HPC调度中的节点分配决策，在运行时和功耗之间找到更好的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: HPC调度器需要在用户性能和设施资源约束之间取得平衡，核心是选择作业的最佳节点数量。传统方法难以有效处理这一复杂决策，需要自动化且数据高效的方法。

Method: 提出基于注意力嵌入的代理辅助多目标贝叶斯优化框架：1）使用注意力机制嵌入作业遥测数据构建代理模型；2）结合智能样本采集策略确保数据效率；3）在运行时和功耗两个目标上进行联合优化。

Result: 在两个生产HPC数据集上，嵌入方法相比基线始终识别出更高质量的运行时-功耗权衡帕累托前沿。智能数据采样策略大幅降低训练成本，同时提高结果稳定性。

Conclusion: 这是首个成功将嵌入信息代理模型应用于HPC调度问题的多目标贝叶斯优化工作，能够联合优化生产工作负载的性能和功耗，为自动化HPC资源分配提供了有效解决方案。

Abstract: High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this complex decision. Our core hypothesis is that surrogate models informed by attention-based embeddings of job telemetry can capture performance dynamics more effectively than standard regression techniques. We pair this with an intelligent sample acquisition strategy to ensure the approach is data-efficient. On two production HPC datasets, our embedding-informed method consistently identified higher-quality Pareto fronts of runtime-power trade-offs compared to baselines. Furthermore, our intelligent data sampling strategy drastically reduced training costs while improving the stability of the results. To our knowledge, this is the first work to successfully apply embedding-informed surrogates in a MOBO framework to the HPC scheduling problem, jointly optimizing for performance and power on production workloads.

</details>


### [10] [Ambient Dataloops: Generative Models for Dataset Refinement](https://arxiv.org/abs/2601.15417)
*Adrián Rodríguez-Muñoz,William Daspit,Adam Klivans,Antonio Torralba,Constantinos Daskalakis,Giannis Daras*

Main category: cs.LG

TL;DR: Ambient Dataloops：一种通过数据集-模型协同进化的迭代框架，利用Ambient Diffusion技术逐步提升数据集质量，从而改善扩散模型性能


<details>
  <summary>Details</summary>
Motivation: 现代数据集包含质量差异很大的样本，直接在这样异质的数据上训练往往得到次优模型。需要一种方法来提升数据集质量，同时避免自消耗循环的破坏性影响

Method: 提出数据集-模型协同进化过程：每轮迭代中，将合成改进的样本视为噪声（但比前一轮噪声水平略低），使用Ambient Diffusion技术进行学习，逐步提升数据集质量

Result: 在无条件/文本条件图像生成和从头蛋白质设计中达到最先进性能，并提供了数据循环过程的理论依据

Conclusion: Ambient Dataloops框架通过迭代提升数据集质量有效改善了扩散模型的学习能力，避免了自消耗循环问题，在多个领域取得了优异表现

Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.

</details>


### [11] [Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes](https://arxiv.org/abs/2601.15423)
*Lorian Bannis*

Main category: cs.LG

TL;DR: Lattice是一个混合序列预测系统，使用二元置信度门控条件激活学习到的行为结构，在置信度高时使用原型评分，置信度低时回退到基线预测。


<details>
  <summary>Details</summary>
Motivation: 解决在序列预测中如何智能地管理认知不确定性的问题，特别是在安全关键应用中，需要系统能够识别何时可以应用学习到的行为模式，何时应该避免错误激活。

Method: 将行为窗口聚类为行为原型，使用二元置信度门控机制，当置信度超过阈值时激活基于原型的评分，否则回退到基线预测。在推荐系统、科学时间序列和金融市场数据上验证，使用LSTM和Transformer作为骨干网络。

Result: 在MovieLens数据集上，Lattice比LSTM基线在HR@10指标上提升31.9%，比SASRec和BERT4Rec分别提升109.4%和218.6%。在LIGO和金融数据上，系统能正确拒绝原型激活以防止分布偏移时的错误激活。在Transformer骨干网络上，Lattice保持中性（0.0%提升），优雅地推迟激活。

Conclusion: 置信度门控是一个有前景的架构原则，能够双向验证：在模式适用时激活，不适用时拒绝，冗余时推迟，特别适用于安全关键应用中的认知不确定性管理。

Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p < 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.

</details>


### [12] [CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models](https://arxiv.org/abs/2601.15441)
*Zhenghao He,Guangzhi Xiong,Boyang Wang,Sanchit Sinha,Aidong Zhang*

Main category: cs.LG

TL;DR: CASL：首个实现扩散模型潜在表示与语义概念监督对齐的框架，通过稀疏自编码器和轻量级线性映射，实现概念对齐的潜在维度，并引入CASL-Steer作为因果探针验证语义控制。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的内部激活编码了丰富的语义信息，但现有基于稀疏自编码器的方法都是无监督的，无法将稀疏特征与人类可理解的概念对齐，限制了语义控制的可靠性。

Method: CASL框架：1）在冻结的U-Net激活上训练稀疏自编码器获得解耦的潜在表示；2）学习轻量级线性映射，将每个概念与一小部分相关潜在维度关联；3）提出CASL-Steer作为因果探针，通过沿学习的概念轴移动激活来验证语义含义；4）引入编辑精度比（EPR）联合度量概念特异性和无关属性的保留。

Result: 实验表明，该方法在编辑精度和可解释性方面优于现有方法，首次实现了扩散模型中潜在表示与语义概念的监督对齐。

Conclusion: CASL成功实现了扩散模型潜在表示与语义概念的监督对齐，通过概念对齐的潜在维度提供了可靠的语义控制，为理解扩散模型内部表示开辟了新途径。

Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.

</details>


### [13] [Learning from Synthetic Data: Limitations of ERM](https://arxiv.org/abs/2601.15468)
*Kareem Amin,Alex Bie,Weiwei Kong,Umar Syed,Sergei Vassilvitskii*

Main category: cs.LG

TL;DR: 论文研究在合成数据污染环境下机器学习理论问题，发现传统ERM方法存在局限性，提出改进算法能更好处理混合数据


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成内容的普及和低成本，自然数据被合成数据污染的问题日益严重。从评论网站到法律文件，"自然"内容都混入了看似自然但实际是LLM生成的数据点。需要重新审视在这种普遍存在的数据污染环境下的基本学习理论问题。

Method: 将场景建模为一系列学习任务，输入是自然数据和合成数据的混合，学习算法不知道任何单个示例的来源。研究ERM在这种设置下的可能性和局限性，并与为不同代数据分配非均匀权重的算法进行比较。

Result: 对于估计任意d维分布均值的问题，ERM虽然收敛到真实均值，但被分配非均匀权重的算法超越。在PAC学习设置中，差异更加显著：ERM并不总是收敛到真实概念，但存在能够学习任意VC类和任意污染量的正确假设的算法。

Conclusion: 在LLM生成内容污染普遍存在的环境下，传统ERM方法存在根本性限制，但通过设计适当的算法（如为不同代数据分配不同权重），仍然能够从混合数据中学习到正确的概念，这为处理合成数据污染提供了理论保证。

Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.

</details>


### [14] [Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra](https://arxiv.org/abs/2601.15473)
*Fahd Seddik,Abdulrahman Elbedewy,Gaser Sami,Mohamed Abdelmoniem,Yahia Zakaria*

Main category: cs.LG

TL;DR: Panther是一个PyTorch兼容的RandNLA库，通过高效算法压缩深度学习模型，减少75%内存占用


<details>
  <summary>Details</summary>
Motivation: 现代深度学习训练受GPU内存和计算限制，RandNLA技术可压缩模型但缺乏统一的生产级库

Method: 开发Panther库，整合RandNLA算法，提供线性层、卷积、注意力等组件的优化实现，使用C++/CUDA后端

Result: 在BERT上替换标准PyTorch层，仅需几行代码即可节省75%内存，同时保持相近的损失

Conclusion: Panther提供了高效易用的RandNLA实现，显著降低深度学习训练的内存需求

Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.

</details>


### [15] [Multi-Targeted Graph Backdoor Attack](https://arxiv.org/abs/2601.15474)
*Md Nabi Newaz Khan,Abdullah Arafat Miah,Yu Bi*

Main category: cs.LG

TL;DR: 本文提出首个针对图分类任务的多目标后门攻击方法，通过子图注入而非替换的方式，在保持原始图结构的同时植入多个触发器，将预测重定向到不同目标标签。


<details>
  <summary>Details</summary>
Motivation: 现有图分类后门攻击研究仅限于使用子图替换机制的单目标攻击，只能植入一个触发器。本文旨在探索图神经网络在多目标后门攻击下的脆弱性，填补这一研究空白。

Method: 提出子图注入方法（而非子图替换）来保持原始图结构，同时植入多个触发器进行多目标后门攻击。攻击框架能够同时将预测重定向到不同目标标签。

Result: 在五个数据集上的实验表明，该方法在所有目标标签上均实现高攻击成功率，同时对干净准确率影响最小。相比传统子图替换攻击，性能更优，且对四种GNN模型架构和训练参数设置均有效。

Conclusion: 这项工作揭示了图神经网络在图分类任务中对多目标后门攻击的脆弱性。提出的攻击方法对现有防御技术（随机平滑和剪枝微调）具有鲁棒性，为GNN安全研究提供了重要洞见。

Abstract: Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.

</details>


### [16] [Early predicting of hospital admission using machine learning algorithms: Priority queues approach](https://arxiv.org/abs/2601.15481)
*Jakub Antczak,James Montgomery,Małgorzata O'Reilly,Zbigniew Palmowski,Richard Turner*

Main category: cs.LG

TL;DR: 该研究比较了SARIMAX、XGBoost和LSTM三种模型在预测急诊科每日到达患者方面的表现，发现XGBoost在预测总入院人数时最准确，SARIMAX在预测高复杂度病例时略优，但所有模型都低估了突发的患者激增。


<details>
  <summary>Details</summary>
Motivation: 急诊科过度拥挤是影响患者安全和运营效率的关键问题，需要准确的预测来优化资源配置。研究旨在评估不同预测模型在预测急诊需求方面的表现，特别关注按病房类别和临床复杂度分层的情况。

Method: 使用澳大利亚三级转诊医院2017-2021年的数据，比较SARIMAX、XGBoost和LSTM三种模型预测7天急诊到达量。将需求分解为8个病房类别并按临床复杂度分层。使用Prophet模型处理COVID-19期间的异常数据，生成合成反事实值。

Result: 三种模型均优于季节性朴素基线。XGBoost在预测每日总入院人数时表现最佳（MAE=6.63），SARIMAX在预测主要复杂度病例时略优（MAE=3.77）。所有模型都能成功复制日常模式，但都低估了突发的、不频繁的患者激增。

Conclusion: 虽然这些预测技术能有效再现常规日常模式，但都存在低估突发性患者激增的共同局限性。研究为急诊需求预测提供了有价值的模型比较，并指出了未来改进方向。

Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.

</details>


### [17] [Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding](https://arxiv.org/abs/2601.15482)
*Huayu Li,ZhengXiao He,Siyuan Tian,Jinghao Wen,Ao Li*

Main category: cs.LG

TL;DR: MFS将LLM解码重构为识别最优随机过程的问题，利用鞅理论设计理论基础的算法，在推理基准上超越SOTA方法，同时显著提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 标准自回归解码在LLMs中是短视的，无法找到全局最优推理路径。现有的推理时策略如前瞻采样依赖启发式方法进行路径评估和剪枝，缺乏理论依据。

Method: 提出鞅前瞻采样(MFS)框架，将LLM解码建模为识别最优随机过程的问题。利用鞅理论：1) 基于Doob分解定理进行步骤评估；2) 使用可选停止理论进行路径选择；3) 基于鞅收敛定理的自适应停止规则。

Result: 在六个推理基准测试中，MFS在准确性上超越了最先进的方法，同时显著提高了计算效率。

Conclusion: MFS为LLM解码提供了一个理论基础的框架，用概率论原理替代启发式机制，在推理任务中实现了更好的性能和效率。

Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

</details>


### [18] [MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498)
*Jingwei Song,Xinyu Wang,Hanbin Wang,Xiaoxuan Lei,Bill Shi,Shixin Han,Eric Yang,Xiao-Wen Chang,Lynn Ai*

Main category: cs.LG

TL;DR: 提出Margin-Aware Speculative Verification方法，通过自适应目标模型的局部决策稳定性来改进验证机制，在保持生成质量的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在验证机制上依赖严格的token级拒绝采样，但在现代LLM的低边际区域（目标模型对候选token偏好较弱）中，拒绝合理的次优token会带来微小信息增益却产生显著回滚成本，导致验证效率低下。

Method: 提出训练无关且领域无关的验证策略，根据目标模型logits直接测量的决策稳定性来条件化验证过程。当严格验证提供最小收益时，放宽拒绝标准。该方法仅修改验证规则，与现有目标耦合推测解码框架完全兼容。

Result: 在8B到235B不同规模的模型上进行广泛实验，证明该方法相比最先进基线能提供一致且显著的推理加速，同时在多样化基准测试中保持生成质量。

Conclusion: 通过自适应目标模型的局部决策稳定性来改进验证机制，Margin-Aware Speculative Verification方法解决了推测解码中的基本效率问题，在保持质量的同时显著提升推理速度。

Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.

</details>


### [19] [Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning](https://arxiv.org/abs/2601.15503)
*Rishit Chatterjee,Tahiya Chowdhury*

Main category: cs.LG

TL;DR: 针对志愿者湖泊监测数据缺失问题，研究Secchi Disk Depth预测，通过MICE处理缺失值，发现岭回归表现最佳，并确定了达到完整历史精度95%所需的最小样本量（约176个）和特征集（4个特征）。


<details>
  <summary>Details</summary>
Motivation: 志愿者湖泊监测产生不规则的季节性时间序列，存在大量数据缺口（冰盖、天气限制、人为错误），这给有害藻华预测和早期预警带来困难。

Method: 使用MICE处理缺失数据，在30个湖泊的30年现场记录中评估6种模型，采用归一化平均绝对误差(nMAE)进行跨湖可比性评估，通过岭回归确定最小样本量和特征集。

Result: 岭回归表现最佳；达到完整历史精度95%需要约176个训练样本和4个特征；联合可行性函数显示仅需64个近期样本和1个预测因子即可达到目标。

Conclusion: 提出的联合可行性策略将近期历史长度和特征选择统一在固定精度目标下，为湖泊研究者提供了简单高效的采样工作和测量优先级设置规则。

Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.

</details>


### [20] [SAGE-FM: A lightweight and interpretable spatial transcriptomics foundation model](https://arxiv.org/abs/2601.15504)
*Xianghao Zhan,Jingyu Xu,Yuanning Zheng,Zinaida Good,Olivier Gevaert*

Main category: cs.LG

TL;DR: SAGE-FM是一个基于图卷积网络的轻量级空间转录组学基础模型，通过掩码中心点预测目标训练，在416个人类Visium样本上学习空间一致嵌入，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学能够进行空间基因表达谱分析，需要计算模型来捕捉空间条件调控关系。现有方法在捕获空间关系和可扩展性方面存在局限。

Method: 提出SAGE-FM，基于图卷积网络（GCNs）的轻量级基础模型，使用掩码中心点预测目标进行训练。在416个人类Visium样本（涵盖15个器官）上训练，学习空间一致嵌入。

Result: 模型学习到空间一致的嵌入，91%的掩码基因显示显著相关性（p<0.05）。在无监督聚类和生物异质性保持方面优于MOFA和现有空间转录组学方法。在下游任务中，口咽鳞状细胞癌病理学家定义的点注释准确率达81%，胶质母细胞瘤亚型预测优于MOFA。计算扰动实验显示模型捕获了与真实情况一致的方向性配体-受体和上游-下游调控效应。

Conclusion: 简单、参数高效的图卷积网络可以作为生物学可解释且具有空间意识的大规模空间转录组学基础模型。

Abstract: Spatial transcriptomics enables spatial gene expression profiling, motivating computational models that capture spatially conditioned regulatory relationships. We introduce SAGE-FM, a lightweight spatial transcriptomics foundation model based on graph convolutional networks (GCNs) trained with a masked central spot prediction objective. Trained on 416 human Visium samples spanning 15 organs, SAGE-FM learns spatially coherent embeddings that robustly recover masked genes, with 91% of masked genes showing significant correlations (p < 0.05). The embeddings generated by SAGE-FM outperform MOFA and existing spatial transcriptomics methods in unsupervised clustering and preservation of biological heterogeneity. SAGE-FM generalizes to downstream tasks, enabling 81% accuracy in pathologist-defined spot annotation in oropharyngeal squamous cell carcinoma and improving glioblastoma subtype prediction relative to MOFA. In silico perturbation experiments further demonstrate that the model captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth. These results demonstrate that simple, parameter-efficient GCNs can serve as biologically interpretable and spatially aware foundation models for large-scale spatial transcriptomics.

</details>


### [21] [Machine learning-enhanced non-amnestic Alzheimer's disease diagnosis from MRI and clinical features](https://arxiv.org/abs/2601.15530)
*Megan A. Witherow,Michael L. Evans,Ahmed Temtam,Hamid Okhravi,Khan M. Iftekharuddin*

Main category: cs.LG

TL;DR: 提出机器学习方法，利用临床测试和MRI数据区分非典型阿尔茨海默病与非AD认知障碍，提高诊断准确率


<details>
  <summary>Details</summary>
Motivation: 非典型阿尔茨海默病（atAD）患者常被误诊，因为标准临床评估和海马体积测量主要针对典型AD有效。需要改进atAD的诊断方法。

Method: 使用机器学习方法，结合临床测试数据和MRI特征（包括海马体积和全脑MRI特征），通过Boruta统计方法识别重要脑区特征，在多个数据集上进行分类实验。

Result: 最佳性能通过加入重要MRI特征实现，优于仅使用海马体积。在NACC数据集中，atAD正确诊断率从52%提升到69%；在ADNI数据集中，从34%提升到77%，同时保持高精确度。

Conclusion: 提出的机器学习方法仅使用临床测试和MRI数据就能显著提高非典型阿尔茨海默病的诊断准确性，具有重要的临床应用价值。

Abstract: Alzheimer's disease (AD), defined as an abnormal buildup of amyloid plaques and tau tangles in the brain can be diagnosed with high accuracy based on protein biomarkers via PET or CSF analysis. However, due to the invasive nature of biomarker collection, most AD diagnoses are made in memory clinics using cognitive tests and evaluation of hippocampal atrophy based on MRI. While clinical assessment and hippocampal volume show high diagnostic accuracy for amnestic or typical AD (tAD), a substantial subgroup of AD patients with atypical presentation (atAD) are routinely misdiagnosed. To improve diagnosis of atAD patients, we propose a machine learning approach to distinguish between atAD and non-AD cognitive impairment using clinical testing battery and MRI data collected as standard-of-care. We develop and evaluate our approach using 1410 subjects across four groups (273 tAD, 184 atAD, 235 non-AD, and 685 cognitively normal) collected from one private data set and two public data sets from the National Alzheimer's Coordinating Center (NACC) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). We perform multiple atAD vs. non-AD classification experiments using clinical features and hippocampal volume as well as a comprehensive set of MRI features from across the brain. The best performance is achieved by incorporating additional important MRI features, which outperforms using hippocampal volume alone. Furthermore, we use the Boruta statistical approach to identify and visualize significant brain regions distinguishing between diagnostic groups. Our ML approach improves the percentage of correctly diagnosed atAD cases (the recall) from 52% to 69% for NACC and from 34% to 77% for ADNI, while achieving high precision. The proposed approach has important implications for improving diagnostic accuracy for non-amnestic atAD in clinical settings using only clinical testing battery and MRI.

</details>


### [22] [QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs](https://arxiv.org/abs/2601.15538)
*Himanshu Mishra,Kanwal Mehreen*

Main category: cs.LG

TL;DR: 量化会灾难性地恢复已遗忘的知识，本文提出量化感知的遗忘方法，通过logits空间铰链损失确保遗忘样本在量化后仍可区分。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘旨在从训练好的模型中移除特定知识（如受版权保护或私人数据），无需完全重新训练。然而，实际部署中模型常被量化（如4位），我们发现量化会灾难性地恢复已遗忘的信息。

Method: 首先分析权重变化统计和量化桶重叠，发现典型遗忘更新太小无法跨越量化阈值。基于此，提出logits空间铰链损失：对每个遗忘样本，强制未遗忘模型的输出logits与原模型至少相差一个边界值（量化步长的一半），确保遗忘样本在量化后仍可区分。

Result: 在语言和分类任务（包括Twitter虚假信息数据集）上评估，该方法在4位量化下能保持遗忘效果，而现有方法几乎完全恢复已遗忘的知识。

Conclusion: 量化会严重破坏机器遗忘效果，提出的量化感知遗忘方法能有效解决这一问题，确保模型在量化部署后仍能保持遗忘特性。

Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.

</details>


### [23] [PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction](https://arxiv.org/abs/2601.15540)
*Dongchen Huang*

Main category: cs.LG

TL;DR: 提出Prism架构，通过几何归纳偏置实现无监督功能解耦，将注意力头自发分离为低频长程因果依赖和高频局部句法约束，统一可解释性与性能


<details>
  <summary>Details</summary>
Motivation: 深度学习模型（特别是Transformer）常被视为"黑箱"缺乏可解释性，需要探索如何将可解释性与性能统一起来

Method: 提出Prism白盒注意力架构，基于最大化编码率降低原理，将注意力机制建模为信号-噪声流形上的梯度上升过程，引入过完备字典和π-RoPE无理频率分离两个物理约束

Result: 在TinyStories测试中，Prism的注意力头自发分离为频谱不同的机制：低频头捕获长程因果依赖（信号），高频头处理局部句法约束（噪声）

Conclusion: 可解释性与性能不是权衡关系，可以通过原则性的几何构造统一起来，几何归纳偏置足以诱导无监督功能解耦

Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($π$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.

</details>


### [24] [RDumb++: Drift-Aware Continual Test-Time Adaptation](https://arxiv.org/abs/2601.15544)
*Himanshu Mishra*

Main category: cs.LG

TL;DR: RDumb++通过引入两种漂移检测机制（基于熵和KL散度）和自适应重置策略，解决了持续测试时适应（CTTA）在长期部署中模型崩溃的问题，在CCC基准测试中相比RDumb获得了约3%的绝对准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的CTTA方法（如Tent、EATA等）在短期分布漂移下表现良好，但在测试分布快速变化或长期部署场景中容易失效，特别是在CCC基准测试中需要处理750万样本的连续变化数据流时，模型容易出现预测崩溃。

Method: 提出了RDumb++方法，作为RDumb的扩展，引入了两种漂移检测机制：1）基于熵的漂移评分，2）KL散度漂移评分，并结合自适应重置策略。这些机制使模型能够检测到累积适应何时变得有害，并在预测崩溃发生前进行恢复。

Result: 在CCC-medium基准测试的三个速度和三个种子（共9次运行，每次包含100万样本）中，RDumb++始终优于RDumb，获得了约3%的绝对准确率提升，同时在整个数据流中保持稳定的适应能力。消融实验进一步表明漂移感知重置对于防止崩溃和实现可靠的长期CTTA至关重要。

Conclusion: 漂移检测和自适应重置策略是解决长期CTTA中模型崩溃问题的关键，RDumb++通过系统性的漂移感知机制实现了在持续变化环境中的稳定适应，为长期部署场景提供了可靠的解决方案。

Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.

</details>


### [25] [Beyond validation loss: Clinically-tailored optimization metrics improve a model's clinical performance](https://arxiv.org/abs/2601.15546)
*Charles B. Delahunt,Courosh Mehanian,Daniel E. Shea,Matthew P. Horning*

Main category: cs.LG

TL;DR: 在医疗机器学习中，使用临床定制指标优化模型比传统验证损失方法更能提升临床任务表现


<details>
  <summary>Details</summary>
Motivation: 传统ML使用验证损失优化模型，但医疗ML的目标是满足特定临床需求而非训练损失函数。临床需求可以通过定制指标更精确地捕捉，而许多优化任务不需要指标可微分，这为使用临床相关指标提供了机会。

Method: 通过两个对照实验，比较使用临床定制指标与验证损失进行模型优化的效果，展示临床指标在优化过程中的优势。

Result: 实验表明，使用临床定制指标进行模型优化相比验证损失方法，在临床任务上表现更优，能更好地满足医疗ML的核心目标。

Conclusion: 虽然定义和编码临床相关指标需要额外努力，但这种方法能产生更符合临床需求的模型，更好地实现医疗ML的核心目标：在临床环境中表现优异。

Abstract: A key task in ML is to optimize models at various stages, e.g. by choosing hyperparameters or picking a stopping point. A traditional ML approach is to use validation loss, i.e. to apply the training loss function on a validation set to guide these optimizations. However, ML for healthcare has a distinct goal from traditional ML: Models must perform well relative to specific clinical requirements, vs. relative to the loss function used for training. These clinical requirements can be captured more precisely by tailored metrics. Since many optimization tasks do not require the driving metric to be differentiable, they allow a wider range of options, including the use of metrics tailored to be clinically-relevant. In this paper we describe two controlled experiments which show how the use of clinically-tailored metrics provide superior model optimization compared to validation loss, in the sense of better performance on the clinical task. The use of clinically-relevant metrics for optimization entails some extra effort, to define the metrics and to code them into the pipeline. But it can yield models that better meet the central goal of ML for healthcare: strong performance in the clinic.

</details>


### [26] [Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling](https://arxiv.org/abs/2601.15547)
*Jingren Hou,Hong Wang,Pengyu Xu,Chang Gao,Huafeng Liu,Liping Jing*

Main category: cs.LG

TL;DR: 提出了首个从部分观测数据学习神经算子的系统框架，通过掩码预测训练策略和物理感知潜在传播器解决部分观测问题，在多种PDE任务上实现显著误差降低。


<details>
  <summary>Details</summary>
Motivation: 现实科学应用中常遇到不完整的观测数据（传感器限制、地理约束、测量成本），而现有神经算子假设完全观测空间输入，严重限制了在实际应用中的适用性。

Method: 提出Latent Autoregressive Neural Operator (LARNO)，包含两个核心组件：(1) 掩码预测训练策略：通过战略性地掩码观测区域创建人工监督；(2) 物理感知潜在传播器：在潜在空间通过边界优先的自回归生成重建解。还开发了POBench-PDE基准测试。

Result: 在补丁式缺失率小于50%的所有基准测试中，实现了18-69%的相对L2误差降低，包括真实世界气候预测。方法能有效处理高达75%缺失率的实际场景。

Conclusion: 该框架首次系统解决了从部分观测学习神经算子的问题，通过创新的训练策略和潜在空间生成方法，在一定程度上弥合了理想化研究设置与现实世界科学计算复杂性之间的差距。

Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.

</details>


### [27] [BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations](https://arxiv.org/abs/2601.15552)
*Phuc Nguyen,Benjamin Zelditch,Joyce Chen,Rohit Patra,Changshuai Wei*

Main category: cs.LG

TL;DR: BanditLP：一个可扩展的多利益相关者上下文老虎机框架，结合神经Thompson采样和大规模线性规划，用于生产环境中的约束优化和探索


<details>
  <summary>Details</summary>
Motivation: 在真实生产环境中，需要同时处理多个利益相关者的目标、约束条件和不确定性。传统方法难以在web规模下有效整合探索（exploration）和约束优化（constrained optimization）

Method: 1. 使用神经Thompson采样学习特定目标的结果
2. 在服务时通过大规模线性规划进行约束动作选择
3. 框架与应用无关，兼容任意神经架构
4. LP求解器可处理数十亿变量

Result: 1. 在公共基准测试和合成数据上持续优于强基线
2. 在LinkedIn的电子邮件营销系统中成功应用并展示业务价值
3. 证明了在生产环境中整合探索和约束优化的价值

Conclusion: BanditLP是一个可扩展的框架，成功将神经Thompson采样与大规模线性规划结合，在web规模的生产环境中实现了有效的多利益相关者决策优化

Abstract: We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.

</details>


### [28] [Deep Learning for Perishable Inventory Systems with Human Knowledge](https://arxiv.org/abs/2601.15589)
*Xuan Liao,Zhenkang Peng,Ying Rong*

Main category: cs.LG

TL;DR: 研究提出基于深度学习的易腐品库存管理方法，结合边际成本核算和启发式策略结构，在有限数据下提升学习效率。


<details>
  <summary>Details</summary>
Motivation: 易腐品库存管理面临需求不确定、提前期随机且分布未知的挑战，传统方法在有限历史数据下效果不佳，需要结合现代数据分析技术提升决策质量。

Method: 采用边际成本核算方案，为每个订单分配单一生命周期成本，构建端到端学习损失函数。开发三种变体：纯黑盒方法(E2E-BB)、嵌入投影库存水平策略的结构化方法(E2E-PIL)，以及基于同质性提升的增强策略(E2E-BPIL)。

Result: 实验表明性能排序：E2E-BB < E2E-PIL < E2E-BPIL。嵌入启发式策略结构能降低有效模型复杂度，在有限灵活性损失下显著提升学习效率。

Conclusion: 深度学习决策工具在结合人类知识（库存理论）指导下更有效和稳健，强调了先进分析与库存理论整合的价值。

Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.

</details>


### [29] [Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization](https://arxiv.org/abs/2601.15597)
*Liusha Yang,Siqi Zhao,Shuqi Chai*

Main category: cs.LG

TL;DR: 提出一种基于神经网络的非线性收缩协方差矩阵估计器，用于最小方差投资组合优化，结合统计模型与机器学习，通过轻量级transformer网络学习特征值非线性收缩函数，直接以投资组合风险为损失函数进行训练。


<details>
  <summary>Details</summary>
Motivation: 传统协方差矩阵估计方法（如Ledoit-Wolf线性收缩）在最小方差投资组合优化中可能不是最优的，因为它们不是直接针对投资组合风险最小化目标设计的。需要一种能够直接优化投资组合风险、同时保持可扩展性的方法。

Method: 从Ledoit-Wolf收缩估计器出发，将其协方差矩阵分解为特征值和特征向量，使用轻量级transformer神经网络学习非线性特征值收缩函数。以投资组合风险作为损失函数训练网络，使得到的精度矩阵（协方差矩阵的逆）估计器直接针对风险最小化。通过条件化样本维度比，保持方法在不同样本规模和资产集合中的可扩展性。

Result: 在标准普尔500指数股票日收益率数据上的实证结果表明，该方法始终比基准方法获得更低的样本外实现风险，验证了将结构化统计模型与数据驱动学习相结合的有效性。

Conclusion: 该方法成功地将统计估计与机器学习相结合，通过神经网络学习非线性收缩函数，直接优化投资组合风险，在保持可扩展性的同时实现了更好的风险表现，展示了结构化统计模型与数据驱动学习整合的潜力。

Abstract: This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard & Poor's 500 Index (S&P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.

</details>


### [30] [When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards](https://arxiv.org/abs/2601.15609)
*Mingyuan Fan,Weiguang Han,Daixin Wang,Cen Chen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: 本文研究了RLVR中的过锐化现象，发现有限批次更新会导致策略坍缩到有限模式，提出了逆成功优势校准和分布级校准来改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管RLVR在逻辑密集型领域取得了经验成功，但尚不清楚它是否真正激发了新能力还是仅仅锐化了现有知识的分布。本文旨在研究RLVR中的过锐化现象，即策略坍缩到有限模式而抑制有效替代方案的问题。

Method: 1. 形式化过锐化现象；2. 发现有限批次更新内在偏向采样模式，通过语义耦合全局传播坍缩；3. 提出逆成功优势校准来优先处理困难查询；4. 提出分布级校准通过记忆网络多样化采样。

Result: 经验评估验证了所提策略能有效改善泛化能力，缓解过锐化问题。

Conclusion: RLVR中的过锐化现象是真实存在的，有限批次更新会导致策略坍缩。通过逆成功优势校准和分布级校准可以有效缓解这一问题，提高模型的泛化性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.

</details>


### [31] [Closing the Gap on the Sample Complexity of 1-Identification](https://arxiv.org/abs/2601.15620)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 本文研究1-identification多臂老虎机问题，提出新的下界和算法，填补了多个合格臂情况下期望总拉动次数分析的理论空白。


<details>
  <summary>Details</summary>
Motivation: 1-identification是纯探索多臂老虎机的基本问题，旨在判断是否存在平均奖励不低于已知阈值μ₀的合格臂。现有文献在多个合格臂情况下对期望总拉动次数𝔼τ的分析存在空白，需要填补这一理论缺口。

Method: (1) 使用优化公式推导当至少存在一个合格臂时𝔼τ的新下界；(2) 设计新算法，推导紧上界，与下界的差距在所有问题实例上最多为对数因子的多项式。

Result: 提出了1-identification问题的新下界和算法，获得了紧上界，与下界的差距最多为对数因子的多项式，填补了多个合格臂情况下期望总拉动次数分析的理论空白。

Conclusion: 本文通过优化公式推导下界和设计新算法，解决了1-identification问题中多个合格臂情况下期望总拉动次数的分析问题，为历史文献留下的开放问题提供了完整解决方案。

Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $μ_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-δ$, while making expected total pulling times $\mathbb{E}τ$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}τ$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}τ$ when there are multiple qualified arms, which is an open problem left by history literature.

</details>


### [32] [Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors](https://arxiv.org/abs/2601.15625)
*Zhiwei Zhang,Fei Zhao,Rui Wang,Zezhong Wang,Bin Liang,Jiakang Wang,Yao Hu,Shaosheng Cao,Kam-Fai Wong*

Main category: cs.LG

TL;DR: Fission-GRPO框架通过将执行错误转化为纠正性监督，在RL训练循环中实现自我纠错，显著提升LLM在多轮工具调用中的错误恢复能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多轮工具调用中存在脆弱性：遇到错误后容易陷入重复无效调用，无法有效解释错误反馈和自我纠正。现有方法如标准RL将错误视为稀疏负奖励，缺乏恢复指导；预收集的错误纠正数据集存在分布不匹配问题。

Method: 提出Fission-GRPO框架：核心机制是将每个失败轨迹通过微调的错误模拟器生成诊断反馈，分裂为新的训练实例，然后在策略上重新采样恢复轨迹。这使得模型能从探索过程中产生的具体错误中学习，而非静态预收集的错误案例。

Result: 在BFCL v4 Multi-Turn基准上，Fission-GRPO将Qwen3-8B的错误恢复率提升5.7%，整体准确率从42.75%提升至46.75%（相对GRPO提升4%），优于专用工具使用代理。

Conclusion: Fission-GRPO通过将执行错误转化为纠正性监督，有效解决了LLM在多轮工具调用中的脆弱性问题，为可靠的实际部署提供了解决方案。

Abstract: Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.

</details>


### [33] [An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types](https://arxiv.org/abs/2601.15640)
*Natasha Trinkle,Huong Ha,Jeffrey Chan*

Main category: cs.LG

TL;DR: 该研究对基于集成的迁移学习贝叶斯优化方法进行实证分析，提出正则化回归加权策略和正约束权重，并创建了三个新的实时迁移学习贝叶斯优化基准。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化是寻找昂贵黑盒目标函数全局最优值的样本高效方法，但可以利用相关问题的历史数据集通过迁移学习提升性能。需要系统分析不同迁移学习组件对贝叶斯优化性能的影响。

Method: 提出基于正则化回归的集成代理模型预测加权策略（权重约束为正），以及处理迁移学习无效情况的组件。扩展了文献中的管道组件，并创建了三个新的实时迁移学习贝叶斯优化基准进行实证分析。

Result: 研究发现，热启动初始化和约束集成代理模型权重为正的两个组件能有效提升迁移学习贝叶斯优化的性能。

Conclusion: 通过系统实证分析，确定了提升迁移学习贝叶斯优化性能的关键组件，为正则化回归加权策略和正约束权重提供了实证支持，为未来研究提供了新的基准。

Abstract: Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.

</details>


### [34] [Integrating Knowledge Distillation Methods: A Sequential Multi-Stage Framework](https://arxiv.org/abs/2601.15657)
*Yinxi Tian,Changwu Huang,Ke Tang,Xin Yao*

Main category: cs.LG

TL;DR: SMSKD提出了一种顺序多阶段知识蒸馏框架，通过分阶段集成异构蒸馏方法，使用冻结参考模型防止遗忘，并引入基于教师真实类别概率的自适应加权机制。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法（如基于响应、特征和关系的方法）各自捕获教师模型的不同知识方面。虽然集成多种方法或知识源有潜力，但实际应用中面临复杂实现、组合不灵活和灾难性遗忘等问题，限制了实际效果。

Method: SMSKD框架顺序集成异构知识蒸馏方法：每个阶段使用特定蒸馏方法训练学生模型，同时冻结前一个阶段的参考模型来锚定已学知识以防止遗忘。还引入了基于教师真实类别概率的自适应加权机制，动态调整每个样本的参考损失以平衡知识保留与集成。

Result: 实验表明SMSKD在各种师生架构和方法组合中都能持续提高学生模型的准确性，优于现有基线。消融研究证实分阶段蒸馏和参考模型监督是性能提升的主要贡献者，基于TCP的自适应加权提供补充效益。

Conclusion: SMSKD是一个实用且资源高效的解决方案，用于集成异构知识蒸馏方法，支持任意方法组合和阶段数量，计算开销可忽略。

Abstract: Knowledge distillation (KD) transfers knowledge from large teacher models to compact student models, enabling efficient deployment on resource constrained devices. While diverse KD methods, including response based, feature based, and relation based approaches, capture different aspects of teacher knowledge, integrating multiple methods or knowledge sources is promising but often hampered by complex implementation, inflexible combinations, and catastrophic forgetting, which limits practical effectiveness.
  This work proposes SMSKD (Sequential Multi Stage Knowledge Distillation), a flexible framework that sequentially integrates heterogeneous KD methods. At each stage, the student is trained with a specific distillation method, while a frozen reference model from the previous stage anchors learned knowledge to mitigate forgetting. In addition, we introduce an adaptive weighting mechanism based on the teacher true class probability (TCP) that dynamically adjusts the reference loss per sample to balance knowledge retention and integration.
  By design, SMSKD supports arbitrary method combinations and stage counts with negligible computational overhead. Extensive experiments show that SMSKD consistently improves student accuracy across diverse teacher student architectures and method combinations, outperforming existing baselines. Ablation studies confirm that stage wise distillation and reference model supervision are primary contributors to performance gains, with TCP based adaptive weighting providing complementary benefits. Overall, SMSKD is a practical and resource efficient solution for integrating heterogeneous KD methods.

</details>


### [35] [Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting](https://arxiv.org/abs/2601.15669)
*Jingjing Bai,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Dualformer是一个用于长期时间序列预测的双域Transformer框架，通过分层频率采样和周期性感知加权机制解决传统Transformer的低通滤波效应问题。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在长期时间序列预测中存在固有的低通滤波效应，导致高频信息在层间传播中逐渐衰减，无法捕捉细粒度的时间变化模式。

Method: 提出双分支架构同时建模时域和频域特征；分层频率采样模块为不同层分配不同频段；周期性感知加权机制基于输入谐波能量比动态平衡双分支贡献。

Result: 在8个广泛使用的基准测试上表现出鲁棒性和优越性能，特别是在异构或弱周期性数据上效果显著。

Conclusion: Dualformer通过结构化频率建模和自适应时频特征集成，有效解决了Transformer的低通滤波问题，提升了长期时间序列预测的性能。

Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.

</details>


### [36] [Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing](https://arxiv.org/abs/2601.15686)
*Xinyu Wang,Sicheng Lyu,Yu Gu,Jerry Huang,Peng Lu,Yufei Cui,Xiao-Wen Chang*

Main category: cs.LG

TL;DR: RLSEdit：一种基于递归最小二乘的模型编辑方法，通过在线二次优化处理长序列编辑，在10K次编辑下保持稳定，平衡编辑成功率和模型能力保留。


<details>
  <summary>Details</summary>
Motivation: 现有模型编辑方法面临可塑性-稳定性困境：硬写入方法会随时间累积干扰，硬保留方法只保留显式约束的内容，可能导致过去编辑被覆盖和未约束行为偏离。在现实部署中，编辑以长流形式到达，需要处理多编辑场景下的稳定性问题。

Method: 将编辑建模为带软约束的在线二次优化问题，最小化累积键值拟合目标，包含两个正则化项：控制与预训练权重的偏差，以及控制与指定锚映射的偏差。通过Woodbury恒等式实现高效在线递归，每次编辑成本与历史长度无关，仅与当前编辑规模相关。

Result: 在多个模型家族上的实验表明，RLSEdit能稳定扩展到10K次编辑，在编辑成功率和整体稳定性方面优于强基线方法，关键能保留早期编辑，并在GLUE和保留推理/代码基准上保持通用能力。

Conclusion: RLSEdit通过递归最小二乘优化框架有效解决了长序列模型编辑中的可塑性-稳定性困境，实现了大规模编辑下的稳定性能，为实际部署中的持续模型更新提供了可行方案。

Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.

</details>


### [37] [Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs](https://arxiv.org/abs/2601.15714)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 本文提出零错误视野（ZEH）作为评估LLM可信度的指标，通过测试GPT-5.2等模型发现其在简单任务上也会出错，这对安全关键应用有重要启示。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂任务上表现出色，但在简单问题上仍会出错，这给安全关键领域的应用带来风险。需要一种方法来评估模型在无错误情况下的可靠解决范围。

Method: 提出零错误视野（ZEH）概念，即模型能无错误解决的最大范围。通过测试GPT-5.2、Qwen2.5等模型在简单任务（如奇偶校验、括号平衡）上的表现来评估ZEH。

Result: GPT-5.2在简单任务上也会出错（如无法计算11000的奇偶性、无法判断括号平衡），ZEH与准确率相关但行为模式不同，ZEH能揭示算法能力的涌现。通过树结构和在线softmax可实现10倍加速。

Conclusion: ZEH为评估LLM可信度提供了重要指标，揭示了即使先进模型在简单问题上也会出错，这对安全关键应用有警示作用。同时提出了降低计算成本的方法。

Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.

</details>


### [38] [Communication-efficient Federated Graph Classification via Generative Diffusion Modeling](https://arxiv.org/abs/2601.15722)
*Xiuling Wang,Xin Huang,Haibo Hu,Jianliang Xu*

Main category: cs.LG

TL;DR: CeFGC是一种新颖的联邦图神经网络范式，通过生成扩散模型减少通信轮次至仅3轮，有效解决非IID数据下的通信开销问题。


<details>
  <summary>Details</summary>
Motivation: 联邦图神经网络面临两大挑战：1）多轮参数交换导致的高通信开销；2）客户端间的非IID数据特性。现有方法在这两方面存在不足，需要更高效的解决方案。

Method: CeFGC采用三阶段通信：1）客户端训练生成扩散模型捕获本地图分布并上传；2）服务器分发所有生成模型给客户端；3）客户端使用生成模型合成图数据与本地图结合训练本地GNN，最后上传权重进行聚合。

Result: 理论分析显示通信复杂度降低至仅3轮，实验在多个真实图数据集上验证了CeFGC的有效性和效率，在非IID图数据上表现优于现有方法，通过丰富训练集和协调本地-全局目标实现优越性能。

Conclusion: CeFGC通过生成扩散模型显著减少联邦图神经网络的通信开销，有效处理非IID数据，为分布式图学习提供了高效实用的解决方案。

Abstract: Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.

</details>


### [39] [Towards Automated Kernel Generation in the Era of LLMs](https://arxiv.org/abs/2601.15727)
*Yang Yu,Peiyu Zang,Chi Hsu Tsai,Haiming Wu,Yixin Shen,Jialing Zhang,Haoyu Wang,Zhiyou Xiao,Jingze Shi,Yuyu Luo,Wentao Zhang,Chunlei Men,Guang Liu,Yonghua Lin*

Main category: cs.LG

TL;DR: 这篇论文是关于利用大语言模型（LLMs）和基于LLM的智能体来自动化内核生成和优化的综述研究，旨在为这一新兴领域提供系统化的视角和参考框架。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统的性能受限于底层内核的质量，而内核开发需要硬件架构和编程模型的专家知识，这一过程耗时且难以规模化。LLMs和智能体系统为自动化内核生成和优化提供了新的可能性，但目前该领域缺乏系统化的视角。

Method: 通过综述研究的方法，系统梳理了现有基于LLM的内核生成方法和智能体优化工作流程，并整理了支撑该领域学习和评估的数据集与基准测试。

Result: 提供了该领域的结构化概述，包括LLM方法、智能体优化流程、数据集和基准测试的全面整理，并指出了关键开放挑战和未来研究方向。

Conclusion: LLM驱动的内核生成是一个有前景的研究方向，本文通过系统化的综述为该领域建立了全面的参考框架，并维护了开源GitHub仓库以跟踪该领域的最新进展。

Abstract: The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.

</details>


### [40] [Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning](https://arxiv.org/abs/2601.15771)
*Dong Xu,Jiantao Wu,Qihua Pan,Sisi Yuan,Zexuan Zhu,Junkai Ji*

Main category: cs.LG

TL;DR: GenRel-DDI提出了一种关系中心学习框架，将DDI预测重新定义为关系学习问题，通过独立于药物身份学习交互表示，显著提升了模型对未见药物和药物对的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有DDI预测方法虽然在标准基准上表现良好，但在实际部署场景中泛化能力不足，特别是面对未见药物和验证交互稀缺的情况。现有基于分子嵌入的方法中，嵌入空间中的邻近性并不能可靠对应交互标签，单纯增加模型容量无法改善泛化。

Method: 提出GenRel-DDI框架，将DDI预测重新定义为关系中心学习问题。该方法独立于药物身份学习交互表示，通过关系级抽象捕获可迁移的交互模式，从而能够泛化到未见药物和新药物对。

Result: 在多个基准测试中，GenRel-DDI始终显著优于现有最先进方法，特别是在严格的实体不相交评估中取得了特别大的性能提升，证明了关系学习对稳健DDI预测的有效性和实用性。

Conclusion: 关系中心学习框架能够有效解决DDI预测中的泛化问题，通过独立于药物身份学习交互表示，捕获可迁移的交互模式，为药物发现和临床开发提供了更实用的解决方案。

Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.

</details>


### [41] [Next Generation Active Learning: Mixture of LLMs in the Loop](https://arxiv.org/abs/2601.15773)
*Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Guoxiang Guo,Joanne Enticott,Gang Liu,Lan Du*

Main category: cs.LG

TL;DR: 提出MLLM-AL框架，用混合LLMs替代人工标注，通过集成多个LLM提升标注鲁棒性，并引入标注差异性和负学习处理噪声标签。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，人们开始将其用于主动学习以减少标注成本，但LLM生成的标注质量往往达不到实际应用要求，需要提升LLM标注的鲁棒性。

Method: 提出MLLM-AL框架：1）用基于混合LLMs的标注模型替代人工标注；2）引入标注差异性来识别不可靠标注；3）采用负学习增强学习效果。

Result: 实验表明该框架性能接近人工标注，优于单LLM基线和其他LLM集成方法，且基于轻量级LLM可在本地机器上运行。

Conclusion: MLLM-AL框架通过混合LLMs和噪声处理机制，有效提升了LLM标注的鲁棒性和实用性，为实际应用提供了可行的低成本标注方案。

Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.

</details>


### [42] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: 论文提出GOSV框架，通过全局优化识别LLM中的安全关键注意力头，发现恶意注入向量和安全抑制向量两种空间分离的安全向量，并基于此开发了新型白盒越狱攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全防护机制脆弱，容易受到越狱攻击。当前方法基于局部贪婪归因，假设组件独立贡献，忽视了注意力头等组件之间的协同交互作用对安全机制的影响。

Method: 提出GOSV框架，通过全局优化同时分析所有注意力头，采用有害补丁和零消融两种互补的激活重补丁策略，识别安全关键注意力头，发现两种空间分离的安全向量。

Result: 发现对齐LLM中存在空间分离的恶意注入向量和安全抑制向量；当约30%的总注意力头被重补丁时，模型安全完全崩溃；基于GOSV开发的白盒越狱攻击在所有测试模型上显著优于现有方法。

Conclusion: GOSV框架有效提升了LLM安全可解释性，揭示了LLM中分离的安全功能通路，为理解LLM安全机制提供了新视角，同时开发的高效越狱攻击证明了该框架的有效性。

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [43] [Uncertainty-guided Generation of Dark-field Radiographs](https://arxiv.org/abs/2601.15859)
*Lina Felsner,Henriette Bast,Tina Dorosti,Florian Schaff,Franz Pfeiffer,Daniela Pfeiffer,Julia Schnabel*

Main category: cs.LG

TL;DR: 提出首个从标准胸部X光生成暗场图像的框架，使用不确定性引导的渐进生成对抗网络，提高生成图像的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: X射线暗场成像能通过小角度散射可视化微观组织结构变化，提供补充诊断信息，但此类数据有限，限制了深度学习模型的开发。

Method: 使用不确定性引导的渐进生成对抗网络，结合偶然不确定性和认知不确定性，直接从标准衰减胸部X光生成暗场图像。

Result: 实验显示生成的图像具有高结构保真度，各阶段定量指标持续改善，分布外评估证实模型泛化能力强。

Conclusion: 不确定性引导的生成建模能实现逼真的暗场图像合成，为未来临床应用提供可靠基础。

Abstract: X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.

</details>


### [44] [Why Inference in Large Models Becomes Decomposable After Training](https://arxiv.org/abs/2601.15871)
*Jidong Jin*

Main category: cs.LG

TL;DR: 提出一种后训练统计准则和结构退火方法，通过移除未支持的参数依赖关系，在大型AI模型中揭示稳定、独立的子结构，实现结构化并行推理而不改变模型功能或接口。


<details>
  <summary>Details</summary>
Motivation: 当前大规模AI模型的推理通常在密集参数矩阵上进行，导致推理成本和系统复杂度随模型规模不可持续地增长。这种限制并非源于模型容量不足，而是由于将后训练推理系统视为整体算子而忽略了学习过程中形成的内部结构。

Method: 提出后训练统计准则和结构退火程序，基于观察到大型模型中的梯度更新事件高度局部化和选择性，许多参数依赖关系在训练后与其初始化分布在统计上无法区分。该方法移除未支持的依赖关系，揭示稳定、独立的子结构。

Result: 建立了后训练、模型无关的推理系统结构视图，实现了结构化并行推理，无需修改模型功能或接口。通过揭示模型固有的可分解性，降低了推理成本和系统复杂度。

Conclusion: 大型AI模型的推理系统在结构上具有非均匀性和固有的可分解性。通过后训练统计分析和结构退火方法，可以揭示模型的稳定子结构，实现高效的结构化并行推理，为解决大规模模型推理的可扩展性问题提供了新途径。

Abstract: Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.

</details>


### [45] [SoK: Challenges in Tabular Membership Inference Attacks](https://arxiv.org/abs/2601.15874)
*Cristina Pêra,Tânia Carvalho,Maxime Cordy,Luís Antunes*

Main category: cs.LG

TL;DR: 该论文对成员推理攻击(MIAs)进行了全面分析，特别关注表格数据，发现在表格数据中MIAs性能普遍较差，但能有效识别单例记录，且使用不同代理模型可提高攻击效果。


<details>
  <summary>Details</summary>
Motivation: 成员推理攻击是评估机器学习隐私的主要方法，但在表格数据方面存在未探索的担忧。论文旨在分析MIAs在集中式和联邦学习中的效果，特别关注表格数据的隐私风险。

Method: 1) 对集中式和联邦学习中的MIAs进行扩展分类；2) 在表格数据上测试多种攻击策略和防御方法；3) 在联邦学习中考虑外部对手威胁；4) 分析单例记录的脆弱性；5) 研究MIAs在不同模型架构间的迁移性。

Result: 1) MIAs在表格数据中表现普遍较差，与先前研究形成对比；2) 即使攻击性能有限，仍能成功暴露大量单例记录；3) 使用不同代理模型能提高MIAs效果；4) 联邦学习中的外部对手威胁值得关注。

Conclusion: MIAs在表格数据中的隐私评估效果有限，但单例记录特别脆弱。需要更全面的隐私评估方法，特别是在联邦学习环境中，且模型架构差异影响攻击效果。

Abstract: Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.

</details>


### [46] [Iterative Amortized Hierarchical VAE](https://arxiv.org/abs/2601.15894)
*Simon W. Penninga,Ruud J. G. van Sloun*

Main category: cs.LG

TL;DR: 提出IA-HVAE模型，结合摊销推理和迭代优化，通过可分离解码器实现35倍加速，在逆问题上表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统分层变分自编码器（HVAE）在推理时需要在摊销推理和迭代优化之间权衡。摊销推理速度快但精度有限，迭代优化精度高但计算成本大。需要一种结合两者优势的混合方法。

Method: 提出迭代摊销分层变分自编码器（IA-HVAE），采用混合推理方案：先进行摊销推理得到初始猜测，然后使用解码器梯度进行迭代优化。关键创新是在变换域（如傅里叶空间）创建线性可分离的解码器，实现高模型深度的实时应用。

Result: 1. 架构改进带来35倍加速；2. 混合方法在精度和速度上分别优于完全摊销和完全迭代方法；3. 在去模糊和去噪等逆问题上，IA-HVAE的重建质量优于传统HVAE。

Conclusion: IA-HVAE成功结合了摊销推理的速度优势和迭代优化的精度优势，通过可分离解码器设计实现了高效推理，在逆问题处理中表现出色，为实时应用提供了可行方案。

Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.

</details>


### [47] [Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data](https://arxiv.org/abs/2601.15977)
*Binbin Lin,Lei Zou,Hao Tian,Heng Cai,Yifan Yang,Bing Zhou*

Main category: cs.LG

TL;DR: 该研究整合医院属性、人口社会经济和空间因素，使用多种机器学习模型预测医疗访问流量，发现Deep Gravity模型表现最佳，不同因素对访问模式的影响随距离变化。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往孤立地考察医院属性、社会经济和空间因素对医疗访问模式的影响，缺乏对这些决定因素的综合分析。本研究旨在填补这一空白，通过整合多维度因素来预测访问流量并分析影响因素。

Method: 使用四年SafeGraph移动数据和Google Maps Reviews用户体验数据，训练五种流量预测模型：朴素回归、梯度提升、多层感知机、Deep Gravity和异构图神经网络。应用SHAP分析和PDP方法考察不同因素对访问模式的综合影响，在休斯顿进行模拟。

Result: Deep Gravity模型表现最优。医院容量、ICU占用率、评分和受欢迎程度显著影响访问模式，且影响随旅行距离变化：短距离访问主要受便利性驱动，长距离访问受医院评分影响。不同种族和教育水平人群对医院评分的敏感度不同，社会经济因素进一步影响访问频率。

Conclusion: 医疗访问模式受多因素综合影响，Deep Gravity模型能有效预测访问流量。医院属性和人口社会经济特征共同塑造访问行为，短距离和长距离访问的驱动因素不同，这为医疗资源规划和公平分配提供了重要见解。

Abstract: Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.

</details>


### [48] [Partially Lazy Gradient Descent for Smoothed Online Learning](https://arxiv.org/abs/2601.15984)
*Naram Mhaisen,George Iosifidis*

Main category: cs.LG

TL;DR: k-lazyGD算法在平滑在线凸优化中建立了一个从贪婪OGD到懒惰GD的连续谱系，证明懒惰性可以在不牺牲跟踪性能的情况下实现，达到最优动态遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在平滑在线凸优化中，学习器同时面临命中成本和移动成本。现有方法要么过于反应性（如OGD），要么过于稳定（如懒惰GD），缺乏一个可以根据比较器路径变化自适应调整懒惰程度的统一框架。

Method: 提出k-lazyGD算法，通过参数k在贪婪OGD（k=1）和懒惰GD/双重平均（k=T）之间建立连续谱系。基于FTRL框架进行分析，并使用不同k值的集成学习器来适应变化的比较器路径。

Result: 证明k-lazyGD在懒惰松弛度k达到Θ(√T/P_T)时，都能实现最优动态遗憾界O(√((P_T+1)T))，其中P_T是比较器路径长度。这意味着算法可以在保持懒惰方法小移动特性的同时不损失跟踪能力。

Conclusion: 懒惰性可以在不牺牲命中性能的情况下实现，允许的懒惰程度与比较器的变化程度相关。通过集成不同懒惰程度的多个学习器，可以得到一个在可能时保持稳定、在必要时保持敏捷的自适应方法。

Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $Θ(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.

</details>


### [49] [Data-Driven Conditional Flexibility Index](https://arxiv.org/abs/2601.16028)
*Moritz Wedemeyer,Eike Cramer,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: 提出条件灵活性指数(CFI)，通过从历史数据学习参数化可接受不确定性集，并利用上下文信息使其条件化，从而更准确地评估调度灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统灵活性指数使用简单超立方体近似不确定性区域，未考虑预测等上下文信息。随着过程柔性化，需要更稳健的调度决策，考虑数据驱动的条件化不确定性集。

Method: 使用归一化流学习从高斯基分布到数据分布的双射映射，在潜在空间构建超球面作为可接受潜在不确定性集，然后映射回数据空间。通过上下文信息使可接受不确定性集条件化。

Result: 数据驱动和条件化可接受不确定性集确保只考虑包含实际实现的参数空间区域。在安全约束机组组合案例中，CFI通过纳入时间信息提高了调度质量。

Conclusion: 条件灵活性指数(CFI)通过数据驱动学习和上下文条件化，提供了更信息化的灵活性估计，改进了传统方法，但需注意数据驱动集不一定总是优于简单集。

Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.

</details>


### [50] [CLASP: An online learning algorithm for Convex Losses And Squared Penalties](https://arxiv.org/abs/2601.16072)
*Ricardo N. Ferreira,Cláudia Soares,João Xavier*

Main category: cs.LG

TL;DR: 提出CLASP算法解决带约束的在线凸优化问题，首次在强凸情况下实现对数级遗憾和惩罚保证


<details>
  <summary>Details</summary>
Motivation: 研究带约束的在线凸优化问题，其中学习者在每次迭代中面临不可预见的凸损失和凸约束，需要最小化累积损失同时控制约束违反惩罚

Method: 提出CLASP算法，最小化累积损失和平方约束违反惩罚，创新性地利用凸投影算子的严格非扩张性进行理论分析

Result: 对于凸损失，CLASP实现遗憾O(T^{max{β,1-β}})和累积平方惩罚O(T^{1-β})；对于强凸问题，首次实现对数级遗憾O(log T)和累积平方惩罚O(log T)

Conclusion: CLASP算法在带约束的在线凸优化中取得突破性理论保证，特别是在强凸情况下首次实现对数级性能，为实际应用提供了有力工具

Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{β,1-β\}}\right)$ and cumulative squared penalty $O\left(T^{1-β}\right)$ for any $β\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.

</details>


### [51] [Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems](https://arxiv.org/abs/2601.16074)
*Annemarie Jutte,Uraz Odyurt*

Main category: cs.LG

TL;DR: 该论文应用可解释AI（XAI）技术分析工业信息物理系统中机器学习模型的预测行为，通过SHAP值分析时间序列分解组件对预测的影响，发现训练数据上下文信息不足的问题，并通过增加数据窗口大小来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 工业信息物理系统（CPS）对安全和经济效益至关重要，需要高度可靠性。虽然机器学习（特别是深度学习）越来越多地集成到工业CPS中，但ML模型的复杂性导致其操作不透明。需要严格评估以防止模型在未来未见数据上出现意外行为。可解释AI（XAI）可用于揭示模型推理过程，从而进行更全面的行为分析。

Method: 应用可解释AI（XAI）技术，具体使用SHAP值分析时间序列数据分解组件对模型预测的影响。通过XAI发现模型训练中上下文信息不足的问题，然后根据XAI的发现增加数据实例的窗口大小来改进模型。

Result: 通过XAI分析发现了模型训练中缺乏足够上下文信息的证据。根据XAI的发现增加数据窗口大小后，能够有效提升模型性能。

Conclusion: 可解释AI（XAI）不仅可以帮助理解工业CPS中机器学习模型的推理过程，还可以指导模型改进，通过分析SHAP值揭示的问题（如上下文信息不足），采取相应措施（如增加数据窗口大小）来提升预测性能。

Abstract: Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.

</details>


### [52] [Probably Approximately Correct Maximum A Posteriori Inference](https://arxiv.org/abs/2601.16083)
*Matthew Shorvon,Frederik Mallmann-Trenn,David S. Watson*

Main category: cs.LG

TL;DR: 提出用于MAP推理的PAC算法，在可变和固定计算预算下提供可证明的最优解，使用概率电路实现


<details>
  <summary>Details</summary>
Motivation: MAP估计是概率推理的基本任务，但通常难以计算，即使在许多常见的结构约束和近似方案下仍然困难。需要开发具有理论保证的MAP推理方法。

Method: 引入概率近似正确(PAC)算法进行MAP推理，使用信息论度量来表征可处理性条件，通过具有适当架构的概率电路高效实现，开发随机化策略

Result: 在可变和固定计算预算下提供可证明的最优解，通过有限样本估计信息论度量，实验证明该方法在多个基准测试中具有优势

Conclusion: 提出的PAC-MAP算法为MAP推理提供了具有理论保证的解决方案，既可以作为独立的推理技术，也可以改进现有启发式方法，增强其解的可靠性

Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.

</details>


### [53] [Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets](https://arxiv.org/abs/2601.16107)
*Adithya Sineesh,Akshita Kamsali*

Main category: cs.LG

TL;DR: 该研究首次系统性地比较了多个专门针对拉曼光谱的深度学习分类器，在统一训练协议下评估了5种代表性架构在3个开源数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 目前拉曼光谱深度学习分类器的评估往往孤立进行，或仅与传统机器学习方法比较，缺乏专门为拉曼光谱设计的深度学习模型之间的直接比较。现有研究缺少在共享开源数据集上的系统性基准测试。

Method: 在统一训练和超参数调优协议下，评估了5种代表性深度学习架构，使用3个开源拉曼数据集进行标准评估、微调和显式分布偏移测试。

Result: 报告了分类准确率和宏平均F1分数，为拉曼光谱分类的深度学习模型提供了公平且可复现的比较结果。

Conclusion: 该研究填补了拉曼光谱深度学习模型系统性比较的空白，为后续研究提供了可靠的基准测试框架和评估标准。

Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.

</details>


### [54] [Variable Splitting Binary Tree Models Based on Bayesian Context Tree Models for Time Series Segmentation](https://arxiv.org/abs/2601.16112)
*Yuta Nakahara,Shota Saito,Kohei Horinouchi,Koshi Shimada,Naoki Ichijo,Manabu Kobayashi,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 提出基于贝叶斯上下文树的变量分裂二叉树模型，用于时间序列分割，通过逻辑回归系数调整实现任意位置的分割，比传统方法更紧凑


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯上下文树模型在时间序列分割应用中，树结构通常表示状态转移，而不是时间域上的区间划分。需要一种能够灵活表示任意分割位置且结构紧凑的时间序列分割方法。

Method: 提出变量分裂二叉树模型，将树结构表示为时间域上的区间划分，通过递归逻辑回归模型表示区间划分，逻辑回归系数可调整分割位置。结合局部变分近似和上下文树加权算法进行同步估计。

Result: 在合成数据上的数值实验表明，该模型和算法能够有效进行时间序列分割，实现分割位置和树深度的同步估计，相比传统方法具有更紧凑的表示能力。

Conclusion: 提出的变量分裂二叉树模型为时间序列分割提供了一种灵活且紧凑的表示方法，通过逻辑回归系数调整和有效的推理算法，能够实现任意位置的分割和结构优化。

Abstract: We propose a variable splitting binary tree (VSBT) model based on Bayesian context tree (BCT) models for time series segmentation. Unlike previous applications of BCT models, the tree structure in our model represents interval partitioning on the time domain. Moreover, interval partitioning is represented by recursive logistic regression models. By adjusting logistic regression coefficients, our model can represent split positions at arbitrary locations within each interval. This enables more compact tree representations. For simultaneous estimation of both split positions and tree depth, we develop an effective inference algorithm that combines local variational approximation for logistic regression with the context tree weighting (CTW) algorithm. We present numerical examples on synthetic data demonstrating the effectiveness of our model and algorithm.

</details>


### [55] [On the Intrinsic Dimensions of Data in Kernel Learning](https://arxiv.org/abs/2601.16139)
*Rustem Takhanov*

Main category: cs.LG

TL;DR: 本文研究核岭回归(KRR)的泛化性能与输入分布内在维度的关系，提出了两种内在维度定义：基于Minkowski维度的d_ρ和基于Kolmogorov n-宽度的有效维度d_K，证明了d_K可以显著小于d_ρ，并给出了泛化误差界和估计算法。


<details>
  <summary>Details</summary>
Motivation: 流形假设认为当输入分布的内在维度较低时，机器学习方法的泛化性能会显著提升。本文旨在研究核岭回归(KRR)中内在维度的不同定义及其对泛化性能的影响，特别是探索基于Kolmogorov n-宽度的有效维度如何更好地刻画泛化行为。

Method: 1. 提出两种内在维度定义：基于Minkowski维度的d_ρ和基于Kolmogorov n-宽度的有效维度d_K；2. 分析n-宽度与积分算子特征值的关系，证明Kolmogorov n-宽度刻画了所有概率测度下的最坏特征值衰减；3. 提出基于有限样本估计n-宽度上界的算法；4. 计算各种分形集的有效维度并进行数值实验。

Result: 1. 证明了对于固定域Ω，Kolmogorov n-宽度刻画了所有概率测度下的最坏特征值衰减；2. 推导出约束KRR的泛化误差界为O(n^{-(2+d_K)/(2+2d_K)+ε})；3. 对于接近均匀的分布，证明了使用O(ε^{-d_ρ}log(1/ε))样本可以高概率计算所有n-宽度的ε-准确上界；4. 数值结果显示对于Laplace核等核函数，有效维度d_K可以显著小于Minkowski维度d_ρ。

Conclusion: 本文建立了核岭回归泛化性能与内在维度的理论联系，表明基于Kolmogorov n-宽度的有效维度d_K比传统的Minkowski维度d_ρ更能准确刻画泛化行为。即使在规则域上d_K = d_ρ成立，但在分形集等复杂结构上，d_K可以显著小于d_ρ，这为理解机器学习在低维流形上的泛化性能提供了新的理论视角。

Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(ε^{-d_ρ}\log\frac{1}ε\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.

</details>


### [56] [Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets](https://arxiv.org/abs/2601.16147)
*Muhammad Ilham Rizqyawan,Peter Macfarlane,Stathis Hadjidemetriou,Fani Deligianni*

Main category: cs.LG

TL;DR: Beat-SSL：一种针对ECG信号的双上下文对比学习框架，通过节奏级和心跳级对比与软目标，在有限标注数据下实现有效迁移学习


<details>
  <summary>Details</summary>
Motivation: 获取标注ECG数据用于监督学习具有挑战性。现有对比学习框架要么只关注全局上下文，要么未能充分利用ECG特定特征，且依赖硬对比目标，无法充分捕捉ECG信号特征相似性的连续特性。

Method: 提出Beat-SSL框架，通过节奏级和心跳级的双上下文对比学习，使用软目标而非硬目标，更好地适应ECG信号的连续特征相似性。

Result: 在两个下游任务中评估：1）多标签分类（全局节奏评估）达到ECG基础模型93%的性能；2）ECG分割任务超越所有其他方法4%。消融研究验证了方法的有效性。

Conclusion: Beat-SSL通过双上下文对比学习和软目标，在有限标注数据下实现了有效的ECG表示学习，在分割任务上表现优异，在分类任务上接近大规模预训练的基础模型性能。

Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.

</details>


### [57] [Learning to Discover at Test Time](https://arxiv.org/abs/2601.16175)
*Mert Yuksekgonul,Daniel Koceja,Xinhao Li,Federico Bianchi,Jed McCaleb,Xiaolong Wang,Jan Kautz,Yejin Choi,James Zou,Carlos Guestrin,Yu Sun*

Main category: cs.LG

TL;DR: TTT-Discover：一种通过测试时强化学习让LLM持续训练以发现科学问题最优解的方法，在多个领域刷新了SOTA


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法（如AlphaEvolve）使用冻结的LLM进行搜索，无法针对特定测试问题进行持续学习。需要一种方法让LLM在测试时继续训练，专门针对当前问题寻找最优解而非平均表现。

Method: 提出TTT-Discover方法，通过测试时强化学习让LLM持续训练，学习目标和搜索子程序专门设计为优先探索最有希望的解决方案。使用开放模型OpenAI gpt-oss-120b，在Tinker平台上运行，成本仅数百美元。

Result: 在数学、GPU内核工程、算法设计和生物学四个领域几乎所有尝试的问题上都刷新了SOTA：1) Erdős最小重叠问题和自相关不等式；2) GPUMode内核竞赛（比先前最佳快2倍）；3) 过去AtCoder算法竞赛；4) 单细胞分析去噪问题。所有结果都经过专家或组织者评审。

Conclusion: TTT-Discover通过测试时强化学习成功实现了让LLM针对特定科学问题持续训练并发现最优解的目标，使用开放模型和公开代码实现了可复现的SOTA结果，相比需要闭源前沿模型的方法更具优势。

Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.

</details>


### [58] [Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing](https://arxiv.org/abs/2601.16200)
*Song Xia,Meiwen Ding,Chenqi Kong,Wenhan Yang,Xudong Jiang*

Main category: cs.LG

TL;DR: 提出特征空间平滑（FS）方法，为多模态大语言模型提供理论认证鲁棒性保证，并通过纯化与平滑映射器（PSM）增强模型鲁棒性，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在多种应用中表现出强大能力，但对对抗性扰动仍然脆弱，这些扰动会扭曲特征表示并导致错误预测。需要一种能提供理论保证的鲁棒性方法。

Method: 提出特征空间平滑（FS）方法，将特征编码器转换为平滑变体，保证在ℓ₂有界攻击下保持干净与对抗特征表示之间的特征余弦相似度下界。进一步提出纯化与平滑映射器（PSM）作为即插即用模块，提升模型的高斯鲁棒性分数，从而增强FS下的认证鲁棒性。

Result: FS-PSM方法不仅提供强大的理论鲁棒性保证，而且在实证性能上优于对抗训练。在各种多模态大语言模型和下游任务中，将多种白盒攻击的成功率从近90%降低到约1%。

Conclusion: 特征空间平滑与纯化平滑映射器相结合，为多模态大语言模型提供了有效的认证鲁棒性解决方案，显著提升了模型对抗对抗性攻击的能力，且无需重新训练模型。

Abstract: Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\% to about 1\%.

</details>


### [59] [Counterfactual Training: Teaching Models Plausible and Actionable Explanations](https://arxiv.org/abs/2601.16205)
*Patrick Altmeyer,Aleksander Buszydlik,Arie van Deursen,Cynthia C. S. Liem*

Main category: cs.LG

TL;DR: 提出一种名为"反事实训练"的新训练方法，利用反事实解释来增强模型的可解释性，使模型能直接产生合理且可操作的反事实解释，同时提升对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法多为后处理技术，无法保证生成的解释符合数据分布和特征可变性约束。本文旨在让模型在训练阶段就直接学习产生高质量反事实解释的能力。

Method: 提出反事实训练方法，在训练阶段使用反事实解释来最小化学到的表示与合理、可操作解释之间的差异，使模型能直接产生符合要求的反事实解释。

Result: 通过实证和理论分析证明，该方法能训练出具有内在良好反事实解释能力的模型，同时还能提高模型的对抗鲁棒性。

Conclusion: 反事实训练是一种有效的训练范式，能让机器学习模型直接产生高质量的反事实解释，同时增强模型鲁棒性，优于传统的后处理方法。

Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [60] [Numerical investigation of the generalized Jang equation coupled to conformal flow of metrics](https://arxiv.org/abs/2601.15359)
*Hollis Williams*

Main category: gr-qc

TL;DR: 研究耦合广义Jang方程与共形流度规系统，发现与Jaracz研究的零散度系统不同，没有出现有限半径的Jang斜率崩溃现象，表明该系统可能仍适用于证明彭罗斯猜想。


<details>
  <summary>Details</summary>
Motivation: Jaracz最近的研究发现，耦合广义Jang方程与零散度系统在满足彭罗斯猜想证明所需的渐近条件下不存在全局解，因为Jang斜率在有限半径处会发生崩溃。本研究旨在探究当广义Jang方程与共形流度规耦合时，是否会出现类似的阻碍现象。

Method: 在球对称和时间对称初始数据的限制下，构建了数值可处理的Jang/共形流系统。通过数值模拟研究系统的行为，并对扭曲因子进行受控扰动以检验现象的鲁棒性。

Result: 数值结果显示没有出现类似Jaracz观察到的有限半径崩溃现象。Jang斜率保持正则性并渐近地趋近其极限值。这种现象在扭曲因子的受控扰动下仍然存在，表明观察到的现象具有鲁棒性。

Conclusion: 耦合到共形流度规改变了Jang/零散度系统中存在的阻碍机制，因此该系统可能仍然适用于证明彭罗斯猜想。

Abstract: A recent result of Jaracz has established nonexistence of global solutions to the coupled generalized Jang equation and zero divergence system which satisfy the asymptotic conditions needed to prove the Penrose conjecture by identifying a breakdown mechanism for the Jang slope at finite radius. In this work, we investigate whether a similar obstruction arises when the generalized Jang equation is instead coupled to the conformal flow of metrics. Restricting to spherical symmetry and time-symmetric initial data, we formulate a numerically tractable version of the Jang/conformal flow system. Our numerical results show no evidence of a finite radius breakdown analogous to that observed by Jaracz. Instead, the Jang slope remains regular and approaches its limiting value asymptotically. This behavior persists under controlled perturbations of the warping factor, indicating robustness of the observed phenomenon. These findings suggest that coupling to conformal flow of metrics alters the obstruction mechanism present in the Jang/zero divergence system, and hence that this system may still be viable for proving the Penrose conjecture.

</details>


### [61] [Compact Stars Sourced by Dark Matter Halos and Their Frozen States](https://arxiv.org/abs/2601.15415)
*Yuan Yue,Yong-Qiang Wang*

Main category: gr-qc

TL;DR: 论文研究了受暗物质晕启发的规则黑洞，通过放宽径向压力与密度关系条件，发现了一类无视界的致密星，这些天体在特定参数下能模拟黑洞特征。


<details>
  <summary>Details</summary>
Motivation: 受暗物质晕启发的规则黑洞研究，旨在探索更一般的各向异性能量-动量张量，放宽径向压力与密度的关系条件，寻找可能的黑洞模拟天体。

Method: 通过推广各向异性能量-动量张量，放宽P_r = -ρ的条件，研究更一般的径向压力与密度关系，分析由此产生的天体结构。

Result: 发现规则黑洞只是一个特例，更广泛的关系会产生无视界的致密星。在特定参数极限下，这些天体接近"冻结状态"，能模拟黑洞特征但没有事件视界。

Conclusion: 这些致密星解可能满足弱能量条件，为暗物质来源的黑洞模拟天体提供了稳健的机制，扩展了我们对黑洞替代模型的理解。

Abstract: Inspired by regular black holes (RBHs) sourced by dark matter halos, we generalize the anisotropic energy-momentum tensor by relaxing the $P_r = -ρ$ condition between radial pressure and density. We demonstrate that while RBHs are a unique special case, a broader class of relations yields horizonless compact stars. Under specific parameter limits, these objects approach a ``frozen state," mimicking black hole features without an event horizon. These compact star solutions could satisfy weak energy conditions and provide a robust mechanism for dark matter-sourced black hole mimickers.

</details>


### [62] [Gravitational equal-area law and critical phenomena of cuspy black hole shadow](https://arxiv.org/abs/2601.15612)
*Shao-Wen Wei,Chao-Hui Wang,Yu-Peng Zhang,Yu-Xiao Liu,Robert B. Mann*

Main category: gr-qc

TL;DR: 黑洞阴影尖点的形成是超越克尔黑洞物理学的显著特征，会导致拓扑电荷从1翻转为-1，并表现出临界现象和普适行为。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞阴影形态变化作为测试超越广义相对论物理的新框架，将寻找广义相对论偏差重新定义为对特定拓扑和临界现象的针对性探索。

Method: 引入引力等面积定律（类似于热力学中的麦克斯韦构造），分析黑洞阴影的拓扑转变，识别尖点形成的临界点，并研究临界点附近的普适行为。

Result: 发现黑洞阴影尖点形成会导致拓扑电荷从1翻转为-1，识别出尖点形成的临界点，并揭示临界指数为1/2的普适行为，表明该引力透镜系统属于平均场普适类。

Conclusion: 建立了一个测试黑洞阴影基础物理学的新框架，将寻找广义相对论偏差重新定义为对特定拓扑和临界现象的针对性探索，为黑洞物理学提供了新的研究视角。

Abstract: The formation of a cusp on a black hole shadow is a striking signature of physics beyond the Kerr paradigm. We demonstrate that this morphological change fundamentally alters the shadow's topology with the topological charge flipping from 1 to -1. To analyze this topological transition, we introduce a gravitational equal-area law, analogous to Maxwell's construction in thermodynamics, and identify a critical point for cusp formation. Near this point, we uncover universal behavior characterized by a critical exponent 1/2, which places this gravitational lensing system within the mean-field universality class. These results establish a new framework for testing fundamental physics of black hole shadows, reframing the search for deviations from general relativity as a targeted hunt for a distinct topological and critical phenomenon.

</details>


### [63] [Black hole based general relativistic limit of f(R) theory of gravity](https://arxiv.org/abs/2601.15825)
*Pranjali Bhattacharjee,Sanjeev Kalita,Debojit Paul*

Main category: gr-qc

TL;DR: 本文通过分析银河系中心黑洞的阴影形状，利用f(R)引力理论的精确解，研究标量子质量对黑洞物理的影响，并验证广义相对论极限。


<details>
  <summary>Details</summary>
Motivation: 利用银河系中心黑洞环境测试广义相对论的偏差和黑洞物理，通过f(R)引力理论研究标量子质量对黑洞阴影形状的影响。

Method: 使用f(R)引力理论的精确稳态、轴对称真空解，将标量子质量作为自由参数，分析黑洞阴影形状、位移和不对称性；利用克雷奇曼标量和引力势等引力标识符推断标量子质量。

Result: 发现黑洞阴影形状对标量子质量敏感，即使黑洞自旋较低；确定了与Kerr类四极矩兼容的标量子质量，符合黑洞"无毛"定理；该质量尺度能再现太阳系弱场极限下的PPN参数约束；S星区域的标量子质量限制与阴影尺度得到的限制一致。

Conclusion: f(R)引力理论中的标量子在黑洞视界尺度具有适当的广义相对论极限，并识别了广义相对论极限的尺度不变性可能性。

Abstract: The Galactic Center black hole environment gives us new opportunity to test deviation from General Relativity and black hole physics. In this work we analytically generate the shape of the Galactic Center black hole by using a recently developed exact stationary, axisymmetric and vacuum solution of $f(R)$ gravity theory. By using scalaron mass as a free parameter we find that the shadow shape along with displacement and asymmetry is sensitive to the scalaron mass, even after keeping the black hole spin low. We recognize scalaron mass which is compatible with Kerr like quadrupole moment and hence black hole "no-hair" theorem. The same mass scale is found to reproduce the PPN parameter ($γ$) constrained in the weak field limit of the solar system. Gravitational identifiers, the Kretschmann scalar ($κ$) and gravitational potential ($φ$) have been used to infer scalaron masses in the regime of S-stars which are found to be consistent with the limits obtained using shadow scales. We ensure that $f(R)$ gravity scalaron has an appropriate general relativistic limit in the horizon scale of the black hole. We also identify the possibility of scale invariance of the General Relativistic limit.

</details>


### [64] [Weyl-transverse gravity with boundaries](https://arxiv.org/abs/2601.15976)
*Gloria Odak,Salvatore Ribisi*

Main category: gr-qc

TL;DR: 本文发展了具有一般类时和类空边界的Weyl-横向引力（WTG）的协变相空间表述，推导了辛势、预辛流、哈密顿生成元，并建立了包含宇宙学常数变化贡献的第一定律关系。


<details>
  <summary>Details</summary>
Motivation: WTG在经典上与广义相对论等价，但具有缩小的规范对称性（Weyl变换和横向微分同胚），这改变了变分原理和守恒量的定义。需要建立WTG的协变相空间表述，明确边界条件，并理解宇宙学常数在守恒定律中的作用。

Method: 采用协变相空间方法，推导WTG的辛势、预辛流和哈密顿生成元；识别使WTG作用量可微的边界条件（包括Dirichlet、Neumann和York边界条件）；分析拉格朗日量模糊性，计算Noether流和表面电荷；在包含分叉Killing视界的时空上评估哈密顿恒等式。

Result: 建立了WTG的完整协变相空间表述；确定了使作用量可微的边界条件；推导了Noether流和表面电荷；获得了包含宇宙学常数变化贡献的第一定律关系，表明除非施加额外物理限制，否则宇宙学常数的变化会对热力学第一定律产生非平凡贡献。

Conclusion: WTG为研究引力理论提供了新的视角，特别是在边界条件和守恒量方面。宇宙学常数在热力学第一定律中的非平凡贡献揭示了理论结构的重要特性，需要进一步物理限制来消除这种模糊性。

Abstract: We develop the covariant phase space formulation of Weyl-transverse gravity (WTG) in the presence of general timelike and spacelike boundaries. WTG is classically equivalent to General Relativity (GR) but possesses a reduced gauge symmetry consisting of Weyl transformations and transverse diffeomorphisms, together with a fixed background volume form. This structure modifies the variational principle and the definition of conserved quantities relative to GR. We derive the symplectic potential, presymplectic current, and Hamiltonian generators associated with transverse diffeomorphisms, and we identify a set of boundary conditions under which the WTG action is differentiable. These include Dirichlet and Neumann conditions for both the auxiliary Weyl-invariant metric and the dynamical metric, as well as a natural implementation of York boundary conditions, for which WTG exhibits a particularly transparent geometric formulation. We obtain the Noether current and surface charge, clarify the role of the Lagrangian ambiguity related to the cosmological constant, and evaluate the Hamiltonian identity on spacetimes containing a bifurcate Killing horizon. The resulting first-law relation shows that variations of the cosmological constant can contribute nontrivially unless additional physical restrictions are imposed.

</details>


### [65] [Nonlinear tails of massive scalar fields around a black hole](https://arxiv.org/abs/2601.16016)
*Caiying Shao,Zhen-Tao He,Jiageng Jiao,Jingqi Lai,Jun-Xi Shi,Yu Tian,Dandan Yuan,Hongbao Zhang*

Main category: gr-qc

TL;DR: 研究黑洞晚期环降中非线性效应，特别是大质量标量场的非线性尾迹行为，发现与无质量场不同，大质量场的非线性尾迹在中间时间以与线性尾迹相同的速率衰减，但二次准正规模可作为探测大质量场非线性效应的探针。


<details>
  <summary>Details</summary>
Motivation: 非线性效应在黑洞晚期环降中起重要作用，直接影响引力波观测。对于大质量场，这些动力学更加丰富，但其非线性特征仍知之甚少，需要系统研究大质量标量扰动的非线性尾迹行为。

Method: 系统研究大质量标量扰动的非线性尾迹：1）从具有入射和出射源的玩具模型入手；2）扩展到自相互作用标量模型；3）将非线性结果与线性对应物进行对比分析。

Result: 发现大质量标量场的非线性尾迹与无质量场相反，在中间时间以与线性尾迹相同的速率衰减，且与源参数或初始条件无关。然而，二次准正规模可作为探测大质量场非线性效应的有效探针。

Conclusion: 大质量标量场的非线性尾迹在中间时间表现出与线性尾迹相同的衰减行为，但二次准正规模为探测大质量场的非线性效应提供了重要途径，这对理解黑洞晚期环降和引力波观测具有重要意义。

Abstract: Nonlinear effects play a fundamental role in the late-time ringdown of black holes, with direct implications for gravitational-wave observations. For massive fields, these dynamics become richer, yet their nonlinear signatures remain poorly understood. Here, we systematically study nonlinear tails of massive scalar perturbations, from a toy model with ingoing and outgoing sources to a self-interacting scalar model, revealing nonlinear tails and contrasting the results with their linear counterparts. We find that the nonlinear tails of massive scalar fields, opposite to massless ones, decay as the same rate as linear tails in the intermediate time, independent of source parameters or initial conditions. Nevertheless, quadratic quasinormal modes could serve as a probe to the nonlinear effects of massive fields.

</details>


### [66] [Exact Kerr-Newman-(A)dS and other spacetimes in bumblebee gravity: employing a novel generating technique](https://arxiv.org/abs/2601.16037)
*Hryhorii Ovcharenko*

Main category: gr-qc

TL;DR: 提出了一种从真空解构造爱因斯坦-大黄蜂引力精确解的生成技术，通过向度规张量添加项 ∼ b_μb_ν 实现，并应用于Kerr-Newman-Taub-NUT-(反-)de Sitter时空的扩展。


<details>
  <summary>Details</summary>
Motivation: 研究爱因斯坦-大黄蜂理论中，当大黄蜂场取真空期望值且非动力学时，如何系统地从真空解生成精确解，并探索该技术在含宇宙学常数和电磁场情况下的扩展。

Method: 提出生成技术：大黄蜂场正比于背景真空时空中的测地线切向量，可通过Hamilton-Jacobi方程求解找到。将项 ∼ b_μb_ν 添加到度规张量中，从真空解构造精确解。

Result: 成功构造了Kerr-Newman-Taub-NUT-(反-)de Sitter时空的大黄蜂扩展，发现扩展不唯一，取决于选择的测地线曲线。大黄蜂场全局实性条件限制了可关联的测地线集合。

Conclusion: 建立了一种从真空解生成爱因斯坦-大黄蜂引力精确解的通用技术，可处理含宇宙学常数和电磁场的情况，但解的非唯一性和全局实性条件对可关联测地线施加了限制。

Abstract: In this work, we show that if the bumblebee field in the Einstein-bumblebee theory is given by its vacuum expectation value ($B_μ=b_μ$) and it is not dynamical ($\partial_μB_ν-\partial_νB_μ=0$), then these conditions uniquely provide a generating technique, allowing us to construct exact solutions to bumblebee gravity from the vacuum solutions by adding a term $\sim b_μb_ν$ to the metric tensor. Also, we show that the bumblebee field within this technique is proportional to the tangential vector of the (timelike or spacelike) geodesic curve in the background vacuum spacetime, and can be easily found knowing the solution to the Hamilton-Jacobi equation. Moreover, we prove that this technique can be extended to the case of any non-zero cosmological constant and the presence of the electromagnetic field. We apply this generating technique and obtain the bumblebee extension of the Kerr-Newman-Taub-NUT-(anti-)de Sitter spacetime. We show that this extension is not unique, as it depends on the exact geodesic curve one chooses to associate a bumblebee field with. Then, by considering various special cases of this generic solution, we demonstrate that the condition of the global reality of the bumblebee field limits the set of geodesics with which we can associate it.

</details>


### [67] [Roche limit and stellar disruption in the Simpson--Visser spacetime](https://arxiv.org/abs/2601.16082)
*Marcos V. de S. Silva*

Main category: gr-qc

TL;DR: 研究Simpson-Visser黑洞反弹模型中的潮汐力及其对不同类型恒星（中子星、白矮星、类太阳恒星）的洛希极限影响，分析这些天体在M87*和Sgr A*等黑洞附近被潮汐撕裂的过程是否发生在事件视界之外从而可观测。


<details>
  <summary>Details</summary>
Motivation: 黑洞产生的潮汐力可能导致接近黑洞的致密天体发生撕裂（洛希极限）。研究Simpson-Visser黑洞反弹模型中的潮汐力效应，了解这种正则化如何影响天体物理对象的潮汐撕裂过程，并确定这些过程是否发生在事件视界之外从而可被观测。

Method: 分析了Simpson-Visser黑洞反弹模型产生的潮汐力，分别针对静态观测者和径向自由落体观测者进行计算。结合恒星束缚力来确定中子星、白矮星和类太阳恒星的洛希半径。研究了M87*和Sgr A*等天体物理黑洞附近恒星撕裂过程的位置关系。

Result: 潮汐力的表现取决于观测者的选择（静态或径向自由落体）。Simpson-Visser正则化会影响不同类型恒星的潮汐撕裂过程。对于M87*和Sgr A*等黑洞，需要确定恒星撕裂是否发生在事件视界之外，从而判断其可观测性。

Conclusion: Simpson-Visser黑洞反弹模型中的潮汐力特性会影响致密天体的洛希极限，这种正则化效应对于理解黑洞附近恒星的潮汐撕裂过程及其可观测性具有重要意义。

Abstract: Due to the tidal forces that a black hole can produce, certain types of compact objects may undergo disruption as they approach the black hole. This disruption point is known as the Roche limit (or Roche radius). In this work, we studied the tidal forces arising from the presence of the Simpson--Visser black bounce. We analyzed the tidal forces both for a static observer and for a radially infalling observer and showed that differences arise depending on the choice of observer. We used the tidal forces together with the stellar binding forces to determine the Roche radius for neutron stars, white dwarfs, and Sun-like stars, and to investigate how the Simpson--Visser regularization affects the tidal disruption of these astrophysical objects. We also examined whether, for astrophysical black holes such as M87* and Sgr~A*, these stellar disruption processes occur inside or outside the event horizon, and thus whether they are observable.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [68] [Precision limit under weak-coupling with ancillary qubit](https://arxiv.org/abs/2601.15354)
*Peng Chen,Jun Jing*

Main category: quant-ph

TL;DR: 提出基于测量的量子计量协议，通过优化探针-辅助系统耦合，实现量子费舍尔信息的二次标度增长，达到海森堡极限


<details>
  <summary>Details</summary>
Motivation: 传统量子计量需要GHZ态或压缩哈密顿量等资源，本文探索通过无条件测量辅助量子比特来超越标准量子极限

Method: 在复合模型中，探针系统（自旋系综）通过海森堡XXZ相互作用与辅助量子比特耦合，优化弱耦合强度和演化时间，通过无条件测量产生两条平行演化路径

Result: 量子费舍尔信息关于相位编码呈现精确或渐近的二次标度（与自旋数N^2成正比），相位灵敏度可接近海森堡极限，且对编码算符和耦合强度不完美具有鲁棒性

Conclusion: 对量子比特的无条件测量可以替代GHZ态和压缩哈密顿量，成为超越标准量子极限的有效资源

Abstract: We propose a measurement-based quantum metrology protocol in a composite model, where the probe system (a spin ensemble) is coupled to an ancillary two-level system (qubit) with a general Heisenberg XXZ interaction. With an optimized and weak probe-ancilla coupling strength and a proper duration of joint evolution, the two parallel evolution paths of the probe system induced by the unconditional measurement on qubit can transform an eigenstate of the collective angular momentum operator of spin ensemble to be a two-component state with a large distance in eigenspace. The quantum Fisher information about the phase encoded in the probe system of polarized states or their superposition, that could be relaxed to mixed states, can therefore manifest an exact or asymptotic quadratic scaling with respect to the probe size (spin number) $N$. The quadratic scaling behavior is found to be insensitive to the imperfect encoding operator and coupling strength. By virtue of the parity detection on the ancillary qubit or the probe system, the phase sensitivity can approach the Heisenberg limit. We suggest that the unconditional measurement on qubit could become an efficient resource to replace Greenberger-Horne-Zeilinger-like states and squeezing Hamiltonian for exceeding the standard quantum limit in metrology precision.

</details>


### [69] [USDs: A universal stabilizer decoder framework using symmetry](https://arxiv.org/abs/2601.15361)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: quant-ph

TL;DR: 该研究将针对Toric码的解码器重优化技术推广到任意稳定子码，通过多层感知机近似连续函数来补充校验子测量，解决了深度学习解码中标签简并性问题，在Color码和Golay码上分别实现了0.8%和0.1%的解码精度提升。


<details>
  <summary>Details</summary>
Motivation: 量子纠错是实现可靠量子计算的关键。当将深度学习应用于量子纠错码解码时，面临的主要挑战是校验子测量与对应错误模式之间的非唯一性（标签简并性）。先前研究针对Toric码通过利用奇偶校验结构的对称性进行解码器重优化解决了这一问题，本研究旨在将此方法推广到任意稳定子码。

Method: 采用多层感知机（MLP）来近似连续函数，这些函数补充了Color码和Golay码的校验子测量。基于这些模型，对每个码进行解码器重优化。通过评估每个码在连续函数近似中的几何和代数结构，分析广义连续函数设计对学习码固有几何结构的优势。

Result: 对于Color码，在物理错误率为5%时解码精度提高了约0.8%；对于Golay码，精度提高了约0.1%。研究还表明，能够忠实再现码结构的近似对重优化的有效性有显著影响，广义连续函数设计有利于学习码的几何结构。

Conclusion: 本研究证明，先前针对Toric码显示有效的重优化技术可以推广到解决稳定子码深度学习解码中的标签简并性挑战。忠实再现码结构的近似对重优化效果至关重要，这为量子纠错码的深度学习解码提供了通用框架。

Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.

</details>


### [70] [The computational two-way quantum capacity](https://arxiv.org/abs/2601.15393)
*Johannes Jakob Meyer,Jacopo Rizzo,Asad Raza,Lorenzo Leone,Sofiene Jerbi,Jens Eisert*

Main category: quant-ph

TL;DR: 计算量子容量研究：在要求编解码计算高效的情况下，量子信道的通信能力会发生根本性变化，存在信道在计算受限时容量为零而无限资源时接近最大值的分离现象。


<details>
  <summary>Details</summary>
Motivation: 传统量子信道容量定义未限制发送方和接收方的计算资源，但在实际应用中编解码必须计算高效。本文首次系统研究计算量子容量，探索计算效率要求如何改变量子通信的基本极限。

Method: 聚焦于计算双向量子容量，建立其与信道Choi态的计算可蒸馏纠缠之间的紧密联系。基于标准密码学假设，构造多项式复杂度量子信道，分析其在不同计算资源限制下的容量变化。

Result: 在标准密码学假设下，存在多项式复杂度的量子信道，其计算双向量子容量为零，而无限制容量接近最大值。当信道复杂度离开多项式领域时，计算量子容量会出现从接近最大值到零的急剧转变。

Conclusion: 计算效率要求能从根本上改变量子通信的极限，计算量子容量与传统容量存在显著分离，这为量子信息理论引入了新的计算复杂性维度。

Abstract: Quantum channel capacities are fundamental to quantum information theory. Their definition, however, does not limit the computational resources of sender and receiver. In this work, we initiate the study of computational quantum capacities. These quantify how much information can be reliably transmitted when imposing the natural requirement that en- and decoding have to be computationally efficient. We focus on the computational two-way quantum capacity and showcase that it is closely related to the computational distillable entanglement of the Choi state of the channel. This connection allows us to show a stark computational capacity separation. Under standard cryptographic assumptions, there exists a quantum channel of polynomial complexity whose computational two-way quantum capacity vanishes while its unbounded counterpart is nearly maximal. More so, we show that there exists a sharp transition in computational quantum capacity from nearly maximal to zero when the channel complexity leaves the polynomial realm. Our results demonstrate that the natural requirement of computational efficiency can radically alter the limits of quantum communication.

</details>


### [71] [Cost scaling of MPS and TTNS simulations for 2D and 3D systems with area-law entanglement](https://arxiv.org/abs/2601.08132)
*Thomas Barthel*

Main category: quant-ph

TL;DR: 树张量网络状态（TTNS）在降低物理自由度图距离方面优于矩阵乘积状态（MPS），但对于大系统低能态模拟，MPS反而更高效


<details>
  <summary>Details</summary>
Motivation: 张量网络状态是模拟强关联量子多体系统的重要工具。树张量网络状态（TTNS）已被成功用于二维系统，并在凝聚态、核物理和粒子物理的量子模拟基准测试中表现出色。然而，尽管TTNS在降低物理自由度图距离方面优于传统的矩阵乘积状态（MPS），但研究发现对于大系统的低能态模拟，MPS反而更高效，这一现象需要深入分析。

Method: 聚焦于D=2和3维空间，在不同边界条件下分析计算成本的标度行为。假设系统服从纠缠（对数）面积律，这意味着键维度与子系统表面积呈指数关系。

Result: 研究发现，对于大系统在D>1空间维度下的低能态模拟，MPS模拟比TTNS模拟更高效。尽管TTNS能显著降低物理自由度的图距离，但在实际计算效率上MPS表现更好。

Conclusion: 虽然树张量网络状态在理论上具有降低物理自由度图距离的优势，但对于大系统低能态模拟，传统的矩阵乘积状态方法在实际计算效率上更具优势。这一发现对选择合适张量网络方法进行量子多体系统模拟具有重要指导意义。

Abstract: Tensor network states are an indispensable tool for the simulation of strongly correlated quantum many-body systems. In recent years, tree tensor network states (TTNS) have been successfully used for two-dimensional systems and to benchmark quantum simulation approaches for condensed matter, nuclear, and particle physics. In comparison to the more traditional approach based on matrix product states (MPS), the graph distance of physical degrees of freedom can be drastically reduced in TTNS. Surprisingly, it turns out that, for large systems in $D>1$ spatial dimensions, MPS simulations of low-energy states are nevertheless more efficient than TTNS simulations. With a focus on $D=2$ and 3, the scaling of computational costs for different boundary conditions is determined under the assumption that the system obeys an entanglement (log-)area law, implying that bond dimensions scale exponentially in the surface area of the associated subsystems.

</details>


### [72] [Quadratic tensors as a unification of Clifford, Gaussian, and free-fermion physics](https://arxiv.org/abs/2601.15396)
*Andreas Bauer,Seth Lloyd*

Main category: quant-ph

TL;DR: 该论文提出了一种统一的代数框架，将多种可经典高效求解的量子模型（如Clifford电路、稳定子码、自由玻色/费米模型等）描述为阿贝尔群或超Hopf代数上的二次函数实例。


<details>
  <summary>Details</summary>
Motivation: 现有的多种可经典高效求解的量子模型（如Clifford电路、稳定子码、自由玻色/费米模型等）虽然看似不同，但具有相似的结构特征。论文旨在建立一个统一的数学框架来描述这些模型，揭示它们背后的共同代数结构。

Method: 使用阿贝尔群或超Hopf代数上的二次函数作为核心数学工具。将量子态、算符、超算符等对象表示为张量，对于可解模型，这些张量是基于二次函数的二次张量。通过二次函数的系数（O(n²)个）来完全描述系统，并开发了类似Schur补的高效张量网络收缩算法。

Result: 成功建立了统一的框架，将不同自由度（量子比特、量子dit、连续变量、转子、费米子等）纳入同一代数结构。该框架自然支持混合自由度系统，并能定义任意阿贝尔群的广义稳定子码和Clifford门。还从二次张量推广到i阶张量。

Conclusion: 论文展示了多种可经典高效求解的量子模型都可以统一描述为阿贝尔群或超Hopf代数上的二次函数实例。这一框架不仅揭示了这些模型背后的共同数学结构，还为处理混合自由度系统和推广到高阶张量提供了理论基础。

Abstract: Certain families of quantum mechanical models can be described and solved efficiently on a classical computer, including qubit or qudit Clifford circuits and stabilizer codes, free-boson or free-fermion models, and certain rotor and GKP codes. We show that all of these families can be described as instances of the same algebraic structure, namely quadratic functions over abelian groups, or more generally over (super) Hopf algebras. Different kinds of degrees of freedom correspond to different "elementary" abelian groups or Hopf algebras: $\mathbb{Z}_2$ for qubits, $\mathbb{Z}_d$ for qudits, $\mathbb{R}$ for continuous variables, both $\mathbb{Z}$ and $\mathbb{R}/\mathbb{Z}$ for rotors, and a super Hopf algebra $\mathcal F$ for fermionic modes. Objects such as states, operators, superoperators, or projection-operator valued measures, etc, are tensors. For the solvable models above, these tensors are quadratic tensors based on quadratic functions. Quadratic tensors with $n$ degrees of freedom are fully specified by only $O(n^2)$ coefficients. Tensor networks of quadratic tensors can be contracted efficiently on the level of these coefficients, using an operation reminiscent of the Schur complement. Our formalism naturally includes models with mixed degrees of freedom, such as qudits of different dimensions. We also use quadratic functions to define generalized stabilizer codes and Clifford gates for arbitrary abelian groups. Finally, we give a generalization from quadratic (or 2nd order) to $i$th order tensors, which are specified by $O(n^i)$ coefficients but cannot be contracted efficiently in general.

</details>


### [73] [Dissipative Quantum Dynamics in Static Network with Different Topologies](https://arxiv.org/abs/2601.15439)
*Wei-Yang Liu,Hsuan-Wei Lee*

Main category: quant-ph

TL;DR: 该研究通过量子自旋模型与热玻色子库耦合，分析了不同网络拓扑结构对量子耗散动力学的影响，包括量子布居和相干性的演化，并提出了适用于大规模网络的平均场方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解网络拓扑结构如何影响量子耗散动力学，特别是量子相干性在不同网络结构中的行为，为通过定制网络结构控制量子相干性提供理论基础。

Method: 研究采用两部分方法：首先使用Lindblad主方程分析小规模伊辛自旋网络在耗散浴中的动力学；其次提出平均场方法将分析扩展到大规模网络，捕捉复杂系统中的耗散动力学。

Result: 研究结果显示量子耗散动力学强烈依赖于网络拓扑结构，网络结构能够塑造量子相干性的演化，量子相干性对网络结构表现出敏感性，为控制纠缠态相干动力学提供了见解。

Conclusion: 网络拓扑结构是影响量子耗散动力学的关键因素，该研究为理解复杂系统中量子相干性提供了框架，结果可扩展到社会模型、流行病学和生物系统等复杂系统中的动力学研究。

Abstract: We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems.

</details>


### [74] [Check-weight-constrained quantum codes: Bounds and examples](https://arxiv.org/abs/2601.15446)
*Lily Wang,Andy Zeyi Liu,Ray Li,Aleksander Kubica,Shouzhen Gu*

Main category: quant-ph

TL;DR: 该论文研究了具有受限校验权重（check weight）的量子低密度奇偶校验（qLDPC）码的参数界限，证明了权重≤3的稳定子码不可能有非平凡距离，并对权重≤4的CSS码和权重≤2的子系综码建立了严格的率-距离权衡。


<details>
  <summary>Details</summary>
Motivation: 量子低密度奇偶校验（qLDPC）码因其只需测量低权重校验而兼容噪声量子硬件，是构建噪声弹性量子计算机的关键。然而，校验权重约束如何限制qLDPC码的可实现参数是一个基本未解问题。

Method: 结合分析论证与数值优化，研究具有受限校验权重的稳定子码和子系综码。使用线性规划技术推导数值上界，并通过显式码构造接近这些界限。

Result: 证明：1）校验权重≤3的稳定子码不可能有非平凡距离；2）对校验权重≤4的CSS稳定子码和权重≤2的子系综码建立了严格的率-距离权衡；3）这些界限适用于一般qLDPC码，不依赖于几何局域性或特殊图连通性；4）在有限尺寸下，通过线性规划得到数值上界并找到接近这些界限的码构造。

Conclusion: 该工作为具有受限校验权重的qLDPC码建立了严格的参数界限，揭示了校验权重约束对量子码性能的基本限制，为实际相关qLDPC码的设计提供了理论指导。

Abstract: Quantum low-density parity-check (qLDPC) codes can be implemented by measuring only low-weight checks, making them compatible with noisy quantum hardware and central to the quest to build noise-resilient quantum computers. A fundamental open question is how constraints on check weight limit the achievable parameters of qLDPC codes. Here, we study stabilizer and subsystem codes with constrained check weight, combining analytical arguments with numerical optimization to establish strong upper bounds on their parameters. We show that stabilizer codes with checks of weight at most three cannot have nontrivial distance. We also prove tight tradeoffs between rate and distance for broad families of CSS stabilizer and subsystem codes with checks of weight at most four and two, respectively. Notably, our bounds are applicable to general qLDPC codes, as they rely only on check-weight constraints without assuming geometric locality or special graph connectivity. In the finite-size regime, we derive numerical upper bounds using linear programming techniques and identify explicit code constructions that approach these limits, delineating the landscape of practically relevant qLDPC codes with tens or hundreds of physical qubits.

</details>


### [75] [NWQWorkflow: The Northwest Quantum Workflow](https://arxiv.org/abs/2601.15521)
*Ang Li*

Main category: quant-ph

TL;DR: NWQWorkflow是一个端到端的量子应用开发工作流，集成了编程环境、编译器、纠错、基准测试、模拟、控制等完整工具链，支持在超导测试平台上进行软硬件协同设计。


<details>
  <summary>Details</summary>
Motivation: 构建一个完整的量子计算开发工作流，支持从算法设计到硬件执行的完整流程，促进量子信息科学生态系统发展，推动向可扩展量子超级计算时代的过渡。

Method: 整合多个软件组件：NWQStudio（编程GUI环境）、NWQASM（中间表示）、QASMTrans（编译器）、NWQEC（量子纠错）、QASMBench（基准测试）、NWQSim（HPC模拟）、NWQLib（算法库）、NWQData（数据集）、NWQControl（量子控制）和NWQSC（超导测试平台），形成闭环的软硬件协同设计系统。

Result: 开发了一个完整的量子应用开发工作流，反映了作者在PNNL过去八年（2018-2026）的量子计算研究成果，大部分软件组件已开源或计划开源。

Conclusion: NWQWorkflow为量子应用开发提供了端到端的解决方案，通过开源策略促进量子信息科学生态系统的协作发展，支持向可扩展量子超级计算时代的过渡。

Abstract: This whitepaper presents NWQWorkflow, an end-to-end workflow for quantum application development, compilation, error correction, benchmarking, numerical simulation, control, and execution on a prototype superconducting testbed. NWQWorkflow integrates NWQStudio (programming GUI environment), NWQASM (intermediate representation), QASMTrans (compiler), NWQEC (quantum error correction), QASMBench (benchmarking and characterization), NWQSim (HPC simulation), NWQLib (algorithm library), NWQData (data sets), NWQControl (quantum control), and NWQSC (superconducting testbed). The system enables closed-loop software-hardware co-design and reflects the past eight years of quantum computing research the author has led at PNNL (2018-2026). By releasing most software components as open source or planning their open-source availability, we aim to cultivate a collaborative quantum information science (QIS) ecosystem and support the transition toward a scalable quantum supercomputing era.

</details>


### [76] [A Sublinear-Time Quantum Algorithm for High-Dimensional Reaction Rates](https://arxiv.org/abs/2601.15523)
*Tyler Kharazi,Ahmad M. Alkadri,Kranthi K. Mandadapu,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: 提出量子算法解决Fokker-Planck方程高维模拟问题，克服传统量子方法中指数衰减问题，在粒子数η、误差ε和时间t上实现量子加速


<details>
  <summary>Details</summary>
Motivation: Fokker-Planck方程在科学中广泛用于模拟罕见事件，但其高维特性对经典计算机构成挑战。现有量子算法模拟这种非幺正动力学时常常遭遇指数衰减的成功概率问题

Method: 使用平方和表示法，开发高斯线性组合哈密顿模拟(Gaussian-LCHS)来表示非幺正传播子，并配合新技术直接估计矩阵元素而避免指数衰减

Result: 对于η个成对相互作用粒子，每个自由度用N个平面波离散化，估计反应通量误差ε的量子门复杂度为Õ((η^{5/2}√(tβ)α_V + η^{3/2}√(t/β)N)/ε)。相比经典最坏情况分析边界O(te^{Ω(η)}/ε^4)，在粒子数η上实现指数分离，在ε上实现四次加速，在t上实现二次加速

Conclusion: 该工作展示了量子算法在高维耗散动力学模拟中实现量子优势的严格路径，尽管实践中专门的经典启发式方法可能超越这些边界，但为量子计算在复杂系统模拟中的应用提供了理论基础

Abstract: The Fokker-Planck equation models rare events across sciences, but its high-dimensional nature challenges classical computers. Quantum algorithms for such non-unitary dynamics often suffer from exponential {decay in} success probability. We introduce a quantum algorithm that overcomes this for computing reaction rates. Using a sum-of-squares representation, we develop a Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) to represent the non-unitary propagator with $O\left(\sqrt{t\|H\|\log(1/ε)}\right)$ queries to its block encoding. Crucially, we pair this with {a} novel technique to directly estimate matrix elements without exponential decay. For $η$ pairwise interacting particles discretized with $N$ plane waves per degree of freedom, we estimate reactive flux to error $ε$ using $\widetilde{O}\left((η^{5/2}\sqrt{tβ}α_V + η^{3/2}\sqrt{t/β}N)/ε\right)$ quantum gates, where $α_V = \max_{r}|V'(r)/r|$. For non-convex potentials, the {sharpest classical} worst-case analytical bounds to simulate the related overdamped Langevin {equation} scale as $O(te^{Ω(η)}/ε^4)$. This {implies} an exponential separation in particle number $η$, a quartic speedup in $ε$, and quadratic speedup in $t$. While specialized classical heuristics may outperform these bounds in practice, this demonstrates a rigorous route toward quantum advantage for high-dimensional dissipative dynamics.

</details>


### [77] [Bidirectional teleportation using scrambling dynamics: a practical protocol](https://arxiv.org/abs/2601.15536)
*Amit Vikram,Edwin Chaparro,Muhammad Miskeen Khan,Andrew Lucas,Chris Akers,Ana Maria Rey*

Main category: quant-ph

TL;DR: 量子信息加扰可实现无局域控制的集体自由度间的SWAP门，结合Hayden-Preskill恢复和量子隐形传态，通过全局相互作用实现双向量子态交换


<details>
  <summary>Details</summary>
Motivation: 在没有通用局域控制的系统中，如何实现集体自由度之间的量子门操作是一个挑战。传统方法需要精细的局域控制，而本文探索利用量子信息加扰这一全局现象来实现量子门

Method: 将Hayden-Preskill恢复方案与量子隐形传态相结合，并行且反向运行，通过全局相互作用实现双向量子态交换。利用Dicke模型作为实验实现平台

Result: 证明了量子信息加扰可以实现在没有通用局域控制的系统中，集体自由度之间的通用SWAP门操作。该方法清晰区分了信息传播、纠缠和混沌在实现相干态传输和恢复中的作用

Conclusion: 量子信息加扰为实现无局域控制的量子门提供了新途径，Dicke模型可在腔QED和囚禁离子平台实现，展示了全息原理在设计实用量子门中的价值

Abstract: We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates.

</details>


### [78] [Spectator-transition crosstalk in a spin-3/2 silicon vacancy qudit in silicon carbide revealed by broadband Ramsey interferometry](https://arxiv.org/abs/2601.15559)
*Jun-Jae Choi,Seung-Jae Hwang,Seoyoung Paik,Juhwan Kim,Jawad UI-Hassan,Nguyen Tien Son,Hiroshi Abe,Takeshi Oshima,Jaekwon Suk,Hyeon-Ho Jeong,Dong-Hee Kim,Sang-Yun Lee*

Main category: quant-ph

TL;DR: 利用宽带拉姆齐干涉法揭示并量化硅空位量子比特中的旁观者跃迁串扰，建立了包含旁观者效应的多能级控制框架


<details>
  <summary>Details</summary>
Motivation: 4H-SiC中的硅空位具有S=3/2基态，是天然的量子比特，支持紧凑编码和子空间选择性控制。然而，短脉冲可能相干驱动非寻址能级对，产生串扰，这需要被理解和控制。

Method: 采用宽带拉姆齐干涉法，通过拉姆齐傅里叶谱分析旁观者跃迁串扰。建立解析模型将谱线映射到旋转框架哈密顿量的能级对能量差，并通过数值时域传播验证实验结果。

Result: 拉姆齐傅里叶谱显示出超出寻址单量子跃迁的多条谱线，这些谱线位置与解析分支线完全吻合，无需频率拟合。实验揭示了确定性的六分支结构。

Conclusion: 该研究为硅空位量子比特中的多能级控制提供了实用的旁观者感知框架，既可指导抑制串扰，也可利用旁观者谱线进行脉冲校准和量子态估计。

Abstract: Color center spins in 4H-SiC offer a rare combination of wafer-scale materials maturity with long spin coherence and chip-level photonics, making them promising building blocks for scalable quantum technologies. In particular, the silicon vacancy hosts an S=3/2 ground state, a native qudit that enables compact encodings and subspace-selective control, but also introduces spectator transitions: short, detuned pulses can coherently drive non-addressed level pairs and create crosstalk. Here we use broadband Ramsey interferometry to reveal and quantify such spectator-transition crosstalk. Experimentally, the Ramsey Fourier spectra display multiple lines beyond the addressed single-quantum transition. Analytically, we map each line to a pairwise energy difference between qudit levels of the rotating-frame Hamiltonian and assign its weight via compact amplitudes set by the prepared state and the microwave pulse parameters, predicting a deterministic six-branch structure. Numerical time-domain propagation with the experimental sampling reproduces the detuning map, and the measured peak positions coincide with the analytic branch lines without frequency fitting. Together these results provide a practical, spectator-aware framework for multilevel control in the silicon vacancy qudit. The approach offers clear guidance to suppress crosstalk or, conversely, to exploit spectator lines, for example as additional constraints for in situ pulse calibration and for phase-sensitive quantum state and process estimation.

</details>


### [79] [Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy](https://arxiv.org/abs/2601.15565)
*Alex Terrasson,Lars Madsen,Joel Grim,Warwick Bowen*

Main category: quant-ph

TL;DR: 该论文提出了一种在波导中使用χ²光学参量放大过程高效产生高亮度皮秒脉冲压缩光的技术，实现了-3.2dB的亮度压缩和-3.6dB的真空压缩，经损耗校正后对应波导内产生-15.4dB的压缩，这是目前报道的最高亮度振幅脉冲压缩水平。


<details>
  <summary>Details</summary>
Motivation: 压缩光能够将噪声降低到标准量子极限以下，从而提高测量精度。在非线性显微镜应用中，现有技术受限于光损伤和量子极限噪声，需要明亮脉冲光以获得最佳性能，但产生和检测高水平的明亮脉冲压缩光仍然具有挑战性。

Method: 采用χ²光学参量放大过程在波导中高效产生高水平的明亮皮秒脉冲压缩光。通过波导结构实现非线性光学过程，产生与非线性显微镜兼容的光学功率水平的压缩光。

Result: 测量得到-3.2dB的亮度压缩（光学功率与非线性显微镜兼容）和-3.6dB的真空压缩。经损耗校正后，这些压缩水平对应波导内产生-15.4^{+2.7}_{-8.7}dB的压缩。这是目前报道的最高亮度振幅脉冲压缩水平。

Conclusion: 该技术实现了目前报道的最高亮度振幅脉冲压缩水平，将有助于量子增强非线性显微镜在生物学研究中得到更广泛的应用。

Abstract: Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies.

</details>


### [80] [Optimized Slice-Phase Control of Mirror Pulse in Cold-Atom Interferometry with Finite Response Time](https://arxiv.org/abs/2601.15586)
*Xueting Fang,Doudou Wang,Kun Yuan,Jie Deng,Qin Luo,Xiaochun Duan,Minkang Zhou,Lushuai Cao,Zhongkun Hu*

Main category: quant-ph

TL;DR: 使用量子最优控制设计的自适应切片结构镜脉冲，显著提升了原子干涉仪对实验不均匀性的鲁棒性和效率


<details>
  <summary>Details</summary>
Motivation: 原子干涉仪需要在高效率和实验不均匀性下保持镜脉冲的鲁棒性能，传统脉冲在这方面存在局限

Method: 采用梯度上升脉冲工程(GRAPE)算法，通过非均匀相位切片离散化控制，为Mach-Zehnder光脉冲原子干涉仪设计优化镜脉冲

Result: 优化脉冲显著拓宽了对失谐[-Ω₀,Ω₀]和拉比频率[0.1×Ω₀,1.9×Ω₀]的容忍度，在响应时间延迟达1.6μs时仍保持高转移效率，对耦合不均匀性和速度分布具有鲁棒性

Conclusion: 自适应脉冲切片方法提供了简约策略，在降低实验复杂度的同时增强了鲁棒性和可扩展性，为高精度原子干涉测量中的量子最优控制提供了创新方案

Abstract: Atom interferometers require both high efficiency and robust performance in their mirror pulses under experimental inhomogeneities. In this work, we demonstrated that quantum optimal control designed mirror pulse significantly enhance interferometer performance by using novel adaptive sliced structure. Using gradient ascent pulse engineering (GRAPE), optimized mirror pulse for a Mach-Zehnder light-pulse atom interferometer was designed by discretizing the control into non-uniform phase slices. This design broadened the tolerence to experimentally relevant variations in detuning $[-Ω_0,Ω_0]$ and Rabi frequency $[0.1\timesΩ_0,1.9\timesΩ_0]$ ($Ω_0=2π\times25$ kHz), while maintaining high transfer efficiency even when the response-time delays up to 1.6 $\rm{μs}$. The optimized pulse was found to be robust to coupling inhomogeneity and velocity spread, offering a significant improvement in robustness over conventional pulse. The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative scheme for quantum optimal control in high precision atom interferometry.

</details>


### [81] [Tensor-based phase difference estimation on time series analysis](https://arxiv.org/abs/2601.15616)
*Shu Kanno,Kenji Sugisaki,Rei Sakuma,Jumpei Kato,Hajime Nakamura,Naoki Yamamoto*

Main category: quant-ph

TL;DR: 提出基于张量网络电路压缩的相位差估计算法，利用时间演化数据实现可扩展且更高精度的量子相位估计算法，在8-52量子比特系统上验证了性能。


<details>
  <summary>Details</summary>
Motivation: 传统量子相位估计算法（QPE）需要大量量子比特和深度电路，难以在近期的含噪声量子设备上实现。需要开发可扩展且高精度的相位估计算法，为实用量子计算和未来纠错量子设备时代做准备。

Method: 1. 使用张量网络构建仅含最近邻门的电路；2. 通过四种电路测量提取时间演化数据；3. 提出基于算法误差缓解的技术增强时间演化精度；4. 结合矩阵乘积态合并的迭代电路优化改进态制备电路。

Result: 1. 在8量子比特一维Hubbard模型的无噪声模拟中，算法在适当时间步长下达到与真实能隙0.4-4.7%的误差；2. 观察到算法误差缓解带来的精度提升；3. 通过迭代优化确认了与矩阵乘积态重叠的增强；4. 在IBM Heron设备上成功演示了8、36、52量子比特模型，使用超过5000个双量子比特门。

Conclusion: 该算法不仅为近期量子计算的实用应用提供了重要进展，也为纠错量子设备时代的到来做好了准备。大规模演示代表了QPE类算法的显著进步，展示了在含噪声设备上实现可扩展量子算法的潜力。

Abstract: We propose a phase-difference estimation algorithm based on the tensor-network circuit compression, leveraging time-evolution data to pursue scalability and higher accuracy on a quantum phase estimation (QPE)-type algorithm. Using tensor networks, we construct circuits composed solely of nearest-neighbor gates and extract time-evolution data by four-type circuit measurements. In addition, to enhance the accuracy of time-evolution and state-preparation circuits, we propose techniques based on algorithmic error mitigation and on iterative circuit optimization combined with merging into matrix product states, respectively. Verifications using a noiseless simulator for the 8-qubit one-dimensional Hubbard model using an ancilla qubit show that the proposed algorithm achieves accuracies with 0.4--4.7\% error from a true energy gap on an appropriate time-step size, and that accuracy improvements due to the algorithmic error mitigation are observed. We also confirm the enhancement of the overlap with matrix product states through iterative optimization. Finally, the proposed algorithm is demonstrated on IBM Heron devices with Q-CTRL error suppression for 8-, 36-, and 52-qubit models using more than 5,000 2-qubit gates. These largest-scale demonstrations for the QPE-type algorithm represent significant progress not only toward practical applications of near-term quantum computing but also toward preparation for the era of error-corrected quantum devices.

</details>


### [82] [Machine Failure Detection Based on Projected Quantum Models](https://arxiv.org/abs/2601.15641)
*Larry Bowden,Qi Chu,Bernard Cena,Kentaro Ohno,Bob Parney,Deepak Sharma,Mitsuharu Takeori*

Main category: quant-ph

TL;DR: 提出基于量子计算和统计变点检测的故障检测算法，利用投影量子特征映射提升工业设备异常检测精度，在真实IoT传感器数据上验证有效性


<details>
  <summary>Details</summary>
Motivation: 工业中及时检测机器故障对维持效率和最小化停机时间至关重要，需要更精确的异常检测方法来处理复杂的多维时间序列数据

Method: 基于量子计算和统计变点检测的故障检测算法，利用投影量子特征映射增强异常检测精度，在IBM 133-qubit Heron量子处理器上执行

Result: 在基准多维时间序列数据集和真实世界IoT传感器数据集上验证有效，能够准确识别噪声时间序列数据中的异常，展示了量子计算在工业维护中的可行性

Conclusion: 量子计算在工业诊断中具有巨大潜力，为预测性维护领域更复杂的量子算法铺平了道路，展示了量子技术在实际工业应用中的可行性

Abstract: Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.

</details>


### [83] [Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations](https://arxiv.org/abs/2601.15654)
*Arman,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: 光子添加的猫态和小猫态相比原始态具有更好的相位空间灵敏度优势，但能耗更高。通过弱压缩和位移操作构建压缩态及其叠加态，并与奇偶匹配的猫态比较量子费舍尔信息和保真度，发现特定参数区域小猫态具有高保真度和大振幅，可通过高斯操作和光子添加制备。压缩和光子添加增强的猫态也显示出改进的计量性能，且增大振幅可减小干涉条纹尺寸，增强猫码的量子纠错效果。


<details>
  <summary>Details</summary>
Motivation: 研究光子添加操作如何改善猫态和小猫态的计量性能，探索通过可实现的非经典资源（弱压缩和位移）构建压缩叠加态，并与传统猫态比较量子费舍尔信息，寻找具有高保真度和大振幅的优化参数区域。

Method: 使用弱压缩和位移操作构建压缩态、压缩猫态和对称压缩态，然后制备它们的光子添加变体。通过量子费舍尔信息和保真度与奇偶匹配的猫态和小猫态进行比较分析，利用QFI等值线识别高保真度、大振幅的参数区域。

Result: 光子添加的猫态和小猫态相比原始态具有相位空间灵敏度优势，但能耗更高。小猫态在特定参数区域表现出高保真度和大振幅，可通过高斯操作和光子添加制备。压缩和光子添加增强的猫态也显示出改进的计量性能。增大振幅可减小干涉条纹尺寸，增强猫码的量子纠错效果。

Conclusion: 光子添加操作通过增加振幅和扩大相位空间面积，提高了猫态和小猫态的计量性能，同时减小了干涉条纹尺寸，有利于量子纠错应用。小猫态在特定参数区域具有制备优势，为量子计量和量子计算提供了优化方案。

Abstract: We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes.

</details>


### [84] [Quantum-HPC hybrid computation of biomolecular excited-state energies](https://arxiv.org/abs/2601.15677)
*Kentaro Yamamoto,Riku Masui,Takahito Nakajima,Miwako Tsuji,Mitsuhisa Sato,Peter Schow,Lukas Heidemann,Matthew Burke,Philipp Seitz,Oliver J. Backhouse,Juan W. Pedersen,John Children,Craig Holliman,Nathan Lysne,Daichi Okuno,Seyon Sivarajah,David Muñoz Ramo,Alex Chernoguzov,Ross Duncan*

Main category: quant-ph

TL;DR: 开发了ONIOM框架下的混合量子-经典计算工作流，结合Fugaku超级计算机和Quantinuum量子计算机，用于生物分子反应模拟


<details>
  <summary>Details</summary>
Motivation: 需要准确模拟复杂生物分子反应，特别是蛋白质等活性位点与大分子环境的相互作用

Method: 在ONIOM框架内开发工作流，结合Fugaku超级计算机（经典计算）和Quantinuum Reimei离子阱量子计算机（量子计算）的混合计算系统

Result: 成功实现了可扩展且准确的复杂生物分子反应模拟，标志着该领域的重要里程碑

Conclusion: 该混合平台扩展了分层方法，能够准确处理活性位点和大分子环境，为生物分子反应模拟提供了新途径

Abstract: We develop a workflow within the ONIOM framework and demonstrate it on the hybrid computing system consisting of the supercomputer Fugaku and the Quantinuum Reimei trapped-ion quantum computer. This hybrid platform extends the layered approach for biomolecular chemical reactions to accurately treat the active site, such as a protein, and the large and often weakly correlated molecular environment. Our result marks a significant milestone in enabling scalable and accurate simulation of complex biomolecular reactions

</details>


### [85] [Fractional squeezing: spectra and dynamics from generalized squeezing Hamiltonian with fractional orders](https://arxiv.org/abs/2601.15693)
*Sahel Ashhab*

Main category: quant-ph

TL;DR: 将广义压缩问题推广到分数阶压缩阶数n，用于识别临界点位置并预测临界行为，解决了传统计算方法难以处理的问题。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法在处理临界点行为时面临挑战，特别是在压缩问题中，需要更精确的方法来识别和预测临界点处的定性行为变化。

Method: 将广义压缩问题推广到分数阶压缩阶数n，通过数值计算识别临界点位置，并分析临界点处的行为特征。

Result: 成功识别了谱从连续到离散的转变点，以及振荡从渐近无限振幅到有限振幅的转变点；在n较大时提供了与数值结果一致的直观解释。

Conclusion: 分数阶压缩阶数方法能够有效识别临界点并准确预测临界行为，为传统计算方法难以处理的问题提供了解决方案。

Abstract: We generalize the generalized-squeezing problem to include fractional values of the squeezing order $n$. This approach allows us to determine the locations of critical points at which qualitative changes in behaviour occur and accurately predict the behaviour at these critical points, which are challenging for conventional computational methods. Based on our numerical calculations, we identify with a high degree of confidence the point at which the spectrum turns from continuous to discrete and the point at which oscillations turn from having asymptotically infinite amplitudes to finite amplitudes. Furthermore, we numerically investigate the behaviour in the large $n$ regime and provide an intuitive explanation that coincides with the numerical results.

</details>


### [86] [Unsplit Spreading: An Overlooked Signature of Long-Range Interaction](https://arxiv.org/abs/2601.15752)
*Jian-Feng Wu,Yi Huang,Yu-Xiang Zhang*

Main category: quant-ph

TL;DR: 论文证明传统晶格模型中平滑的色散关系会导致初始局域激发分裂为反向传播的波包，而只有色散关系出现奇异特征时才能实现不分裂的传播，这正是长程相互作用所实现的物理现象。


<details>
  <summary>Details</summary>
Motivation: 研究传统晶格模型中色散关系平滑性对波包传播行为的影响，解释为何某些量子模拟实验中观察到了不分裂的传播现象却未被识别为独特的物理效应。

Method: 通过理论证明平滑色散关系必然导致初始局域激发分裂为反向传播波包，分析长程相互作用如何产生奇异色散特征，并在一维和二维亚波长原子阵列等开放量子系统中验证不分裂传播现象。

Result: 证明不分裂传播只能发生在色散关系具有奇异特征的情况下，这种奇异特征由长程相互作用产生。在亚波长原子阵列的长寿命亚辐射态中确实存在这种奇异色散，支持不分裂传播现象。

Conclusion: 不分裂传播是长程物理诱导奇异能带结构的实验可观测特征，这一现象早在2014年的量子模拟实验中就已可见，但直到现在才被确认为独特的物理效应。

Abstract: In conventional lattice models, the dispersion relation $ω(k)$ is assumed to be a smooth function. We prove that this smoothness implies the splitting of an initially localized excitation into counter-propagating wave packets. Consequently, unsplit spreading can occur only when $ω(k)$ develops singular features, precisely what long-range interactions enable. Remarkably, this phenomenon was clearly visible in published quantum simulation experiments as early as 2014, yet it has remained unrecognized or discussed as a distinct physical effect. We show that unsplit spreading emerges in realistic open quantum systems, such as 1D and 2D subwavelength atomic arrays, where the long-lived subradiant states host effective dispersion with the required singularities. Our work establishes unsplit spreading as an experimentally accessible, smoking-gun signature of singular band structure induced by long-range physics.

</details>


### [87] [Improving the efficiency of QAOA using efficient parameter transfer initialization and targeted-single-layer regularized optimization with minimal performance degradation](https://arxiv.org/abs/2601.15760)
*Shubham Patel,Utkarsh Mishra*

Main category: quant-ph

TL;DR: QAOA参数转移初始化结合目标单层优化在MaxCut问题上取得接近全优化性能，计算速度提升8倍，但在加权图上效果有限，L2正则化可减少不一致性。


<details>
  <summary>Details</summary>
Motivation: 研究如何提高量子近似优化算法（QAOA）在组合优化问题中的效率，通过参数初始化和简化优化过程来减少计算成本，同时保持性能。

Method: 使用参数转移初始化方法，然后进行目标单层优化（而非全优化），在三种图结构（3正则、Erdos Renyi、Barabasi Albert）上测试MaxCut问题，并引入L2正则化平滑解空间。

Result: 在无权图上，目标单层优化达到全优化98.88%的性能，计算速度提升8.06倍；在加权图上效果较差（<90%），但某些加权3正则图例外；8.92%情况下目标优化优于全优化，L2正则化将此比例降至3.81%。

Conclusion: 有效的参数初始化和目标单层优化可以显著提高QAOA效率且性能损失最小，但在加权图上需要更谨慎；正则化有助于减少优化不一致性。

Abstract: Quantum approximate optimization algorithm (QAOA) have promising applications in combinatorial optimization problems (COPs). We investigated the MaxCut problem in three different families of graphs using QAOA ansats with parameter transfer initialization followed by targeted single layer optimization. For 3 regular (3R), Erdos Renyi (ER), and Barabasi Albert (BA) graphs, the parameter transfer approach achieved mean approximation ratios of 0.9443 for targeted-single layer optimization as compared to 0.9551 of full optimization. It represents 98.88 percent optimal performance, with 8.06 times computational speedup in unweighted graphs. But, in weighted graph families, optimal performance is relatively low (less than 90 percent) for higher nodes graph, suggesting parameter transfer followed by targeted-single-layer optimization is not ideal for weighted graph families, however, we find that for some weighted families (weighted 3-regular) this approach works perfectly. In 8.92 percent test cases, targeted single layer optimization outperformed the full optimization, indicating that complex parameter landscape can trap full optimization in sub-optimal local minima. To mitigate this inconsistency, ridge (L2) regularization is used to smoothen the solution landscape, which helps the optimizer to find better optimum parameters during full optimization and reduces these inconsistent test cases from 8.92 percent to 3.81 percent. This work demonstrates that efficient parameter initialization and targeted-single-layer optimization can improve the efficiency of QAOA with minimal performance degradation.

</details>


### [88] [Classical Simulation of Noiseless Quantum Dynamics without Randomness](https://arxiv.org/abs/2601.15770)
*Jue Xu,Chu Zhao,Xiangran Zhang,Shuchen Zhu,Qi Zhao*

Main category: quant-ph

TL;DR: LPD算法利用纠缠而非噪声，高效近似无噪声短时量子动力学中的局域可观测量，为经典模拟提供了新途径


<details>
  <summary>Details</summary>
Motivation: 传统经典模拟方法面临困境：张量网络方法在纠缠饱和时效率低下，而Pauli截断方法通常依赖噪声或随机性。需要一种不依赖噪声的高效模拟方法

Method: 提出低权重Pauli动力学(LPD)算法，通过截断高权重Pauli算符来近似局域可观测量，证明在状态充分纠缠时截断误差具有平均情况界限

Result: 纠缠反而减轻了经典模拟误差，这种纠缠态可通过张量网络经典模拟或近期量子设备生成，为量子模拟提供了减少电路深度的补充途径

Conclusion: LPD算法建立了经典模拟方法间的协同作用，扩展了量子动力学的可访问范围，为长时动力学模拟提供了新思路

Abstract: Simulating noiseless quantum dynamics classically faces a fundamental dilemma: tensor-network methods become inefficient as entanglement saturates, while Pauli-truncation approaches typically rely on noise or randomness. To close the gap, we propose the Low-weight Pauli Dynamics (LPD) algorithm that efficiently approximates local observables for short-time dynamics in the absence of noise. We prove that the truncation error admits an average-case bound without assuming randomness, provided that the state is sufficiently entangled. Counterintuitively, entanglement--usually an obstacle for classical simulation--alleviates classical simulation error. We further show that such entangled states can be generated either by tensor-network classical simulation or near-term quantum devices. Our results establish a rigorous synergy between existing classical simulation methods and provide a complementary route to quantum simulation that reduces circuit depth for long-time dynamics, thereby extending the accessible regime of quantum dynamics.

</details>


### [89] [Fermion Doubling in Dirac Quantum Walks](https://arxiv.org/abs/2601.15885)
*Chaitanya Gupta,Anthony J. Short*

Main category: quant-ph

TL;DR: 提出一种无加倍子和伪加倍子的量子行走模型，通过允许行走者停留在原点的概率非零来解决传统Dirac行走中的加倍问题。


<details>
  <summary>Details</summary>
Motivation: 量子行走模拟Dirac粒子时存在"加倍子"问题，高动量态会产生额外的低能解，这些解在量子元胞自动机中会导致虚假解，影响相互作用引入。同时伪加倍子虽然高能但行为类似低能Dirac粒子，可能引起真空稳定性问题。

Method: 提出一族量子行走模型，通过允许行走者停留在原点的概率非零（传统Dirac行走中该概率始终为零），从而消除加倍子和伪加倍子，同时在连续极限下仍能模拟Dirac方程。

Result: 成功构建了无加倍子和伪加倍子的量子行走模型，但仍存在少量额外的低能解，这些解不直接对应Dirac粒子。

Conclusion: 通过修改量子行走中行走者停留在原点的概率，可以有效解决加倍子和伪加倍子问题，为模拟Dirac粒子提供了更可靠的离散时空模型。

Abstract: We consider discrete spacetime models known as quantum walks, which can be used to simulate Dirac particles. In particular we look at fermion doubling in these models, in which high momentum states yield additional low energy solutions which behave like Dirac particles. The presence of doublers carries over to the `second quantised' version of the walks represented by quantum cellular automata, which may lead to spurious solutions when introducing interactions. Moreover, we also consider pseudo-doublers, which have high energy but behave like low energy Dirac particles, and cause potential problems regarding the stability of the vacuum. To address these issues, we propose a family of quantum walks, that are free of these doublers and pseudo-doublers, but still simulate the Dirac equation in the continuum limit. However, there remain a small number of additional low energy solutions which do not directly correspond to Dirac particles. While the conventional Dirac walk always has a zero probability for the walker staying at the same point, we obtain the family of walks by allowing this probability to be non-zero.

</details>


### [90] [Improved cryptographic security in teleportation with q-deformed non-maximal entangled states](https://arxiv.org/abs/2601.15902)
*Prabal Dasgupta,Debashis Gangopadhyay*

Main category: quant-ph

TL;DR: 使用q形变代数增强量子隐形传态中的密码安全性，通过q形变谐振子态构建新的隐形传态协议，利用形变参数中的任意函数提高安全性。


<details>
  <summary>Details</summary>
Motivation: 传统量子隐形传态协议在密码安全性方面存在局限，需要开发新的方法来增强安全性，特别是在非最大纠缠态的情况下。

Method: 1. 构建q形变的类贝尔态，当形变参数q→1时还原为传统贝尔态；2. 推广传统非最大纠缠态隐形传态协议；3. 使用q形变非最大纠缠态构建两个新协议，利用形变参数中的任意函数作为额外安全参数。

Result: 成功构建了q形变的纠缠态和相应的隐形传态协议，这些协议需要共享额外的形变参数才能解密，从而提高了密码安全性。

Conclusion: q形变代数为量子隐形传态提供了增强密码安全性的新框架，通过引入形变参数中的任意函数作为额外安全层，改进了传统协议的安全性。

Abstract: In this work the machinery of q-deformed algebras are used to enhance cryptographic security during teleportation. We use q-deformed harmonic oscillator states to develop a novel method of teleportation. The deformed states can be expressed in terms of standard oscillator states and the expressions contain certain arbitrary functions of $q$. It is the presence of these arbitrary functions that allows an enhancement of cryptographic security. The specifics are :
  (a) q-deformed Bell-like states are constructed which reduce to the usual Bell states when the deformation parameter $q\rightarrow 1$. These deformed states form an orthonormal basis for q-deformed entangled bipartite states when certain arbitrary functions of $q$ satisfy a constraint.
  (b) We discuss the generalisation of the usual teleportation protocol with non-maximally entangled states. This generalisation is then employed to construct two new protocols using q-deformed non-maximally entangled states. These states have additional parameters and these have to be shared for decryption after teleportation. Consequently, the cryptographic security is improved.

</details>


### [91] [Automated quantum circuit optimization with randomized replacements](https://arxiv.org/abs/2601.15934)
*Marcin Szyniszewski,Aleks Kissinger,Noah Linden,Paul Skrzypczyk*

Main category: quant-ph

TL;DR: 提出一种基于ZX演算的近似量子电路重写协议，通过允许近似局部变换和使用混合量子通道来近似纯电路，从而显著减少量子资源需求。


<details>
  <summary>Details</summary>
Motivation: 当前量子电路优化主要关注保持幺正变换的精确等价变换，但这种方法限制了资源减少的潜力。作者认为通过允许近似局部变换和使用混合量子通道，可以获得更大的资源减少机会。

Method: 基于ZX演算的自动优化技术，采用贪婪策略：选择性替换具有小相位角的ZX图，用随机混合的恒等变换和精心选择的过程转来替代，旨在减少总体门数量同时保持在严格误差预算内。

Result: 在随机量子电路中实现了适度的两量子比特门数量减少，在结构化电路（如量子傅里叶变换）中实现了显著减少。该方法将实验噪声转化为精心设计的随机噪声，在平均性能上优于许多其他近似方法。

Conclusion: 混合通道近似方法有潜力增强未来量子电路性能，为超越纯幺正通道的资源感知自动量子编译指出了新方向。

Abstract: Quantum circuit optimization - the process of transforming a quantum circuit into an equivalent one with reduced time and space requirements - is crucial for maximizing the utility of current and near-future quantum devices. While most automated optimization techniques focus on transforming circuits into equivalent ones that implement the same unitary, we show that substantial new opportunities for resource reduction can be achieved by (1) allowing approximate local transformations and (2) employing mixed quantum channels to approximate pure circuits. Our novel automated protocol for approximate circuit rewriting is a refined evolution of automated optimization techniques based on the ZX-calculus, where we add a greedy strategy that selectively replaces ZX-diagrams with small phase angles with stochastic mixtures of the identity and carefully chosen over-rotations, which are designed to reduce the overall gate count in expectation while staying within a strict error budget. This approach yields modest two-qubit gate count reduction in random quantum circuits, and achieves a substantial reduction in structured circuits such as the quantum Fourier transform. Fundamentally, our protocol converts experimental noise due to gate applications into deliberately engineered random noise, outperforming many other approximation methods on average. These results highlight the potential of mixed-channel approximations to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels.

</details>


### [92] [Frictional work and entropy production in integrable and non-integrable spin chains](https://arxiv.org/abs/2601.15941)
*Vishnu Muraleedharan Sajitha,Matthew J. Davis,L. A. Williamson*

Main category: quant-ph

TL;DR: 量子自旋链中摩擦功与对角熵产生的关系：非可积系统可用单一有效温度描述，而可积系统需要多个温度描述不同子空间


<details>
  <summary>Details</summary>
Motivation: 研究量子系统中摩擦功（非绝热驱动与绝热驱动之间的功差）与量子相干性积累产生的对角熵之间的关系，探索可积与非可积系统的差异

Method: 通过分析非可积自旋链和可积自旋链，比较不同驱动速度下摩擦功与对角熵产生的关系，引入有效温度概念描述绝热状态

Result: 在非可积自旋链中，慢到中等速度驱动下，摩擦功可用对角熵产生描述，由单一有效温度表征；快速驱动下，摩擦功由最终非绝热态与绝热态之间的量子相对熵描述。可积系统需要多个有效温度描述不同子空间

Conclusion: 可积性破缺在绝热极限下可增强功提取，但在足够非绝热区域会降低功提取效率，揭示了量子系统中摩擦功与量子相干性之间的基本关系

Abstract: The maximum work extractable from a quantum system is achieved when the system is driven adiabatically. Frictional work then quantifies the difference in work output between adiabatic and non-adiabatic driving. Here we show that frictional work in a non-integrable spin chain is well-described by the diagonal entropy production associated with the build up of quantum coherence. The relationship is characterized by an effective temperature of the final adiabatic state and holds for slow to moderate driving protocols. For fast protocols, the frictional work is instead described by the quantum relative entropy between the final non-adiabatic and adiabatic states. We compare our results to those obtained from an integrable spin chain, in which case the adiabatic state is no longer described by a single temperature. In this case, the frictional work is described by a sum of terms for each independent subspace of the spin chain, which are at different effective temperatures. We show how integrability breaking can enhance work extraction in the adiabatic limit, but degrade work extraction in sufficiently non-adiabatic regimes.

</details>


### [93] [Renormalization Treatment of IR and UV Cutoffs in Waveguide QED and Implications to Numerical Model Simulation](https://arxiv.org/abs/2601.15945)
*Romain Piron,Akihito Soeda*

Main category: quant-ph

TL;DR: 该论文提出了波导-QED模型中重整化关系的非微扰第一性原理推导，考虑了数值模拟中必要的红外和紫外截断，建立了裸模型参数与可观测物理量之间的联系，并展示了如何用最小频率带宽参数化模拟以降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在波导-QED模型的数值模拟中，必须引入红外和紫外截断，但如何将裸模型参数与可观测物理量（如原子频率和衰变率）正确关联起来，并确保模拟的物理准确性和计算效率，是一个重要问题。

Method: 采用时域方法描述原子动力学，推导出重整化关系的非微扰第一性原理表达式，验证其与散射理论的一致性，并与标准费曼图建立联系，提供透明的物理解释。

Result: 获得了连接裸模型参数与可观测物理量（原子频率和衰变率）的明确表达式，验证了与散射理论的一致性，并展示了如何用最小频率带宽参数化模拟，在保持物理准确性的同时显著降低计算成本。

Conclusion: 该研究为波导-QED模型提供了可靠的重整化框架，使得高效可靠的多光子光-物质相互作用模拟成为可能，为复杂量子光学系统的数值研究铺平了道路。

Abstract: We present a non-perturbative, first-principles derivation of renormalization relations for waveguide-QED models, explicitly accounting for the infrared (IR) and ultraviolet (UV) cutoffs that are necessarily introduced in numerical simulations. By formulating the atomic dynamics in the time domain, we obtain explicit expressions linking the bare model parameters to the physically observable atomic frequency and decay rate, and verify their consistency with scattering theory. We further connect these results to standard Feynman diagrams, providing a transparent physical interpretation and ensuring the generality of the approach. Finally, we show how these renormalization relations can be used to parameterize simulations with a minimal frequency bandwidth, simultaneously preserving physical accuracy and reducing computational cost, thereby paving the way for efficient and reliable multi-photon light-matter simulations.

</details>


### [94] [Universal Digitized Counterdiabatic Driving](https://arxiv.org/abs/2601.15972)
*Takuya Hatomura*

Main category: quant-ph

TL;DR: 提出一种数字化的反绝热驱动通用方法，通过数字方式构造绝热规范势，具有避免引入多体/非局域相互作用、能包含无限嵌套对易子、提供数字实现旋转角显式表达式三大优势。


<details>
  <summary>Details</summary>
Motivation: 反绝热驱动利用绝热规范势实现参数化哈密顿量能量本征态的参量位移，但现有通用反绝热驱动和/或数字化反绝热驱动方法存在引入多体/非局域相互作用、无法包含无限嵌套对易子、缺乏数字实现旋转角显式表达式等局限。

Method: 提出通用数字化反绝热驱动方法，基于通用反绝热驱动思想，以数字方式构造绝热规范势。该方法采用数字实现框架，能够处理构成绝热规范势的无限嵌套对易子，并提供旋转角的显式表达式。

Result: 通过解析方式证明了该方法与精确理论的一致性，并通过数值模拟验证了该方法的有效性。

Conclusion: 提出的通用数字化反绝热驱动方法克服了现有方法的局限性，在避免引入额外相互作用的同时，能够完全包含绝热规范势的数学结构，并为实际数字实现提供了明确的旋转角表达式。

Abstract: Counterdiabatic driving realizes parameter displacement of an energy eigenstate of a given parametrized Hamiltonian using the adiabatic gauge potential. In this paper, we propose a universal method of digitized counterdiabatic driving, constructing the adiabatic gauge potential in a digital way with the idea of universal counterdiabatic driving. This method has three advantages over existing universal counterdiabatic driving and/or digitized counterdiabatic driving: it does not introduce any many-body and/or nonlocal interactions to an original target Hamiltonian; it can incorporate infinite nested commutators, which constitute the adiabatic gauge potential; and it gives explicit expression of rotation angles for digital implementation. We show the consistency of our method to the exact theory in an analytical way and the effectiveness of our method with the aid of numerical simulations.

</details>


### [95] [Semiclassical entanglement entropy for spin-field interaction](https://arxiv.org/abs/2601.15986)
*Matheus V. Scherer,Lea F. Santos,Alexandre D. Ribeiro*

Main category: quant-ph

TL;DR: 该论文提出了一种半经典框架来描述自旋与玻色场之间的纠缠动力学，通过引入复轨迹显著提高了半经典描述的精度。


<details>
  <summary>Details</summary>
Motivation: 研究自旋与玻色场相互作用系统的纠缠动力学，发展能够超越Ehrenfest时间的半经典描述方法。

Method: 使用半经典近似推导纠缠熵表达式，将经典相空间解析延拓到复域，识别并包含复轨迹来改进精度。

Result: 复轨迹的引入显著提高了半经典描述的准确性，即使在Ehrenfest时间之外也能精确捕捉纠缠动力学。

Conclusion: 通过将经典相空间延拓到复域并包含复轨迹，可以建立精确描述量子纠缠动力学的半经典框架。

Abstract: We study a general bipartite quantum system consisting of a spin interacting with a bosonic field, with the initial state prepared as the product of a spin coherent state and a canonical coherent state. Our goal is to develop a semiclassical framework to describe the entanglement dynamics between these two subsystems. Using appropriate approximations, we derive a semiclassical expression for the entanglement entropy that depends exclusively on the trajectories of the underlying classical description. By analytically extending the classical phase space into the complex domain, we identify additional complex trajectories that significantly improve the accuracy of the semiclassical description. The inclusion of these complex trajectories allows us to capture the entanglement dynamics with remarkable precision, even well beyond the Ehrenfest time. The approach is illustrated with a representative example, where the role of real and complex trajectories in reproducing the quantum entanglement entropy is explicitly demonstrated.

</details>


### [96] [Engineering quantum Mpemba effect by Liouvillian skin effect](https://arxiv.org/abs/2601.16002)
*Xiang Zhang Chen Sun,Fuxiang Li*

Main category: quant-ph

TL;DR: 提出利用开放量子系统中的Liouvillian皮肤效应来工程化量子Mpemba效应，并发现了一种新型QME-III


<details>
  <summary>Details</summary>
Motivation: 量子Mpemba效应（QME）描述了初始状态离平衡态更远的系统反而比更近的初始状态更快弛豫的现象。本文旨在通过Liouvillian皮肤效应（LSE）来工程化实现QME，并探索其物理机制。

Method: 基于二次Lindblad方程，考虑两种具体案例设计初始状态。利用Liouvillian皮肤效应的空间分布特性为初始状态制备提供直接途径，从而在实验中实现QME。

Result: 成功利用LSE实现了QME，并发现了一种新型QME-III，其特征是在两个不同时间点出现希尔伯特-施密特距离的两次反转。LSE为理解QME提供了更直观的物理图像。

Conclusion: Liouvillian皮肤效应是工程化量子Mpemba效应的理想平台，其空间分布特性为初始状态制备提供了实验上易于实现的途径，同时为理解QME的物理机制提供了更直观的视角。

Abstract: We propose a new approach to engineer the quantum Mpemba effect (QME) -- wherein an initial state farther from system relaxes faster than a close one -- by the Liouvillian skin effect (LSE) in open quantum systems. Moreover, the LSE serves as an ideal platform for realizing the QME and the spatial profile of the LSE provides a straightforward pathway for the initial state preparation, thereby enabling readily accessible experimental preparation. Focusing on the quadratic Lindbladians, we consider two concrete cases to design the initial states, thereby realizing the QME. Interestingly, we uncover a new kind of QME (QME-III) that is distinct from the two typical scenarios, manifested as two reversals in the Hilbert-Schmidt distance at two different times. In particular, the LSE provides a physically more intuitive understanding of the QME.

</details>


### [97] [Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware](https://arxiv.org/abs/2601.16004)
*Christopher Altman*

Main category: quant-ph

TL;DR: 在IBM量子硬件上实现并基准测试了Violaris提出的电路家族，用于估计操作性的分支间通信见证，通过编译的Wigner朋友式电路产生的经典测量记录相关性来评估。实现了五量子比特协议实例，在真实设备噪声和编译约束下评估其行为。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一个可重复的操作性约束流程，用于评估非理想信道相对于校准设备噪声的可检测性，而不是测试或区分量子力学的不同解释。旨在为量子硬件上的分支间通信见证提供实际实现和基准测试。

Method: 在IBM量子硬件上实现Violaris提出的电路家族，将五量子比特协议实例化为单个电路内的寄存器间消息传输模式（而非物理信号）。电路编码观察者子系统的分支条件演化，其动力学依赖于控制量子比特，然后通过受控传输操作探测条件测量上下文之间的相关性。在ibm_fez后端执行20000次测量。

Result: 观察到基于布居数的可见度为0.877，沿正交轴的相干见证分别为0.840和-0.811，相位敏感幅度约为1.17。可见度度量对某些类型的退相干不敏感，而相干见证提供了对非对角噪声的互补敏感性。

Conclusion: 这项工作为评估非理想信道相对于校准设备噪声的可检测性提供了一个可重复的操作性约束流程。虽然不测试量子力学解释，但展示了在真实量子硬件上实现分支间通信见证协议的可行性，并量化了在设备噪声下的性能表现。

Abstract: We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.
  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.
  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise.

</details>


### [98] [Echoed Random Quantum Metrology](https://arxiv.org/abs/2601.16026)
*Dong-Sheng Liu,Zi-Jie Chen,Ziyue Hua,Yilong Zhou,Qing-Xuan Jie,Weizhou Cai,Ming Li,Luyan Sun,Chang-Ling Zou,Xi-Feng Ren,Guang-Can Guo*

Main category: quant-ph

TL;DR: 通过随机脉冲驱动Kerr非线性模式，无需复杂量子控制即可实现接近海森堡极限的测量灵敏度


<details>
  <summary>Details</summary>
Motivation: 传统量子计量学需要制备复杂的量子探针态（如纠缠态或压缩态），这需要精确校准系统参数和精细优化量子控制，限制了可扩展性和鲁棒性

Method: 引入回声随机过程，通过随机脉冲驱动Kerr非线性模式，产生亚普朗克相空间结构，无需复杂量子控制

Result: 实现了接近海森堡极限的灵敏度，对随机探针态保持"盲态"，在宽参数范围内保持高性能，对控制波动和光子损耗具有鲁棒性

Conclusion: 该方法为高维希尔伯特空间中的量子增强计量学提供了一条实用、硬件高效、可扩展且无需优化的新途径

Abstract: Quantum metrology typically demands the preparation of exotic quantum probe states, such as entangled or squeezed states, to surpass classical limits. However, the need for carefully calibrated system parameters and finely optimized quantum controls imposes limitations on scalability and robustness. Here, we circumvent these limitations by introducing an echoed random process that achieves sensitivity approaching the Heisenberg limit while remaining blind to the random probe state. We demonstrate that by simply driving a Kerr nonlinear mode with random pulses, the emergence of sub-Planck phase-space structures grants high sensitivity, eliminating the need for complex quantum control. The protocol is statistically robust, yielding high performance across broad driving parameter ranges while exhibiting resilience to control fluctuations and photon loss. Broadly applicable to both bosonic and qubit platforms, our work reveals a practical, hardware-efficient, scalable, and optimization-free route to quantum-enhanced metrology in high-dimensional Hilbert spaces.

</details>


### [99] [Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals](https://arxiv.org/abs/2601.16081)
*Aishwarya Majumdar,Yuan Liu*

Main category: quant-ph

TL;DR: 提出基于广义量子信号处理干涉仪(GQSPI)的框架，用于检测量子位移信号参数是否在任意阈值区间内，将二元假设检验转化为多项式逼近问题，实现低错误概率的单次或少次测量。


<details>
  <summary>Details</summary>
Motivation: 量子域中的信号常表现为相空间中的位移或相移算子。当需要判断位移参数是否在任意不对称阈值区间内时，这是一个二元决策问题。传统方法可能效率不高，需要一种能在单次或少次测量中实现低错误概率的通用框架。

Method: 采用广义量子信号处理干涉仪(GQSPI)在混合量子比特-玻色子振荡器系统上实现。将实际的二元假设检验问题转化为多项式逼近问题，通过电路深度d控制错误概率。分析了参数为确定性值和随机先验分布两种情况，并扩展到多阈值场景。

Result: 实现了错误概率p_err ≈ O(1/d·log(d))，其中d为电路深度。在退相干噪声下表现出鲁棒性。框架支持任意阈值区间的决策，适用于单次或少次测量场景。

Conclusion: 提出的GQSPI框架为量子位移信号的阈值检测提供了一种高效、通用的解决方案，能够以低错误概率在单次或少次测量中完成任意阈值区间的决策，且对噪声具有鲁棒性。

Abstract: A relevant signal in the quantum domain may manifest as a displacement or a phase shift operator in the bosonic phase space. For a real parameter $β$ embedded in such a displacement operator, the task of determining if $β\in [β_{-th}, β_{+th}]$ for real asymmetric thresholds $(β_{-th} \ne -β_{+th})$ is a binary decision problem. We propose a framework based on generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems that addresses this parameter detection problem by recasting the practical task of active binary hypothesis testing on quantum systems to that of a polynomial approximation. We achieve a small decision error probability $p_{err}$ on the order of $O(\frac{1}{d}\log{(d)})$, with $d$ as the circuit depth. We analyze the protocol when (i) $β$ is a deterministic parameter, and (ii) when $β$ is drawn randomly from a known prior distribution. The performance of the sensing protocol under dephasing noise is also shown to be robust. We further extend our protocol from two thresholds to more general multi-threshold cases as well. Overall, the proposed framework enables decision-making over arbitrary thresholds for any general displacement signal in a single or a few shots.

</details>


### [100] [Quantum Metrology under Coarse-Grained Measurement](https://arxiv.org/abs/2601.16106)
*Byeong-Yoon Go,Geunhee Gwak,Young-Do Yoon,Sungho Lee,Nicolas Treps,Jiyong Park,Young-Sik Ra*

Main category: quant-ph

TL;DR: 该论文研究了量子测量中的粗粒度效应，发现即使只有两个分箱的极端粗粒度测量也能实现超越标准量子极限的相位估计精度，并遵循海森堡标度。


<details>
  <summary>Details</summary>
Motivation: 量子计量学虽然能实现超越经典极限的测量精度，但其性能常受实验缺陷影响。以往研究多关注量子态和操作的缺陷，本文则专门研究量子测量中粗粒度效应的影响。

Method: 使用压缩真空和激光输入的干涉仪，分析零差检测中粗粒度对相位估计精度的影响。评估不同粗粒度条件下的Fisher信息，确定每种情况下的最优估计策略。实验上采用矩量法确定最优估计策略，并提出了适用于一般实验设置的校准程序。

Result: 即使只有两个分箱的极端粗粒度测量也能实现超越标准量子极限的相位估计，并遵循海森堡标度。实验中使用两个分箱观察到相比理想测量的经典方法有1.2 dB的量子增强，随着分箱数增加，量子增强可达3.8 dB。

Conclusion: 这些结果表明，即使在存在严重实验缺陷的情况下，通过粗粒度测量也能实现量子增强，为实际应用中实现量子增强提供了可行途径。

Abstract: While quantum metrology enables measurement precision beyond classical limits, its performance is often susceptible to experimental imperfections. Most prior studies have focused on imperfections in quantum states and operations. Here, we investigate the effect of coarse graining in quantum measurement through both theoretical analysis and experimental demonstration. Using an interferometer with a squeezed vacuum and a laser input, we analyze how coarse graining in homodyne detection affects the precision of phase estimation. We evaluate the Fisher information under various coarse-graining conditions and determine, in each case, an optimal estimation strategy that saturates the Cramér-Rao bound. Remarkably, even extremely coarse-grained measurement -- with only two bins -- enables phase estimation beyond the standard quantum limit and even achieves a precision that follows the Heisenberg scaling. We experimentally demonstrate quantum-enhanced phase estimation under coarse-grained homodyne detection. To determine an optimal estimation strategy, we employ the method of moments and present calibration procedures that enable its application to general experimental settings. Using only two bins, we observe a quantum enhancement of 1.2 dB compared to the classical method using the ideal measurement, improving towards 3.8 dB as the bin number increases. These results highlight a practical pathway to achieving quantum enhancement under the presence of severe experimental imperfections.

</details>


### [101] [Experimental prime factorization via a feedback quantum control](https://arxiv.org/abs/2601.16116)
*Hari Krishnan KB,Vishal Varma,T. S. Mahesh*

Main category: quant-ph

TL;DR: 提出一种基于测量的全量子反馈方法，通过迭代引导量子系统达到目标基态，实现素数分解，无需经典计算驱动参数。


<details>
  <summary>Details</summary>
Motivation: 现有量子素数分解方法存在局限：Shor算法需要高保真量子门，哈密顿优化方法需要大量经典后处理来确定控制参数。需要一种更高效、更全量子的方法。

Method: 采用基于测量的反馈方法，通过迭代引导量子系统达到目标基态（素数分解的退化基态）。一旦问题哈密顿量确定并实现，就不再需要经典计算驱动参数。

Result: 实验上使用三量子比特NMR量子寄存器成功分解双素数551；数值分析显示方法对控制场误差具有鲁棒性；数值模拟实现了更大双素数（9,167和2,106,287）的FALQON分解，分别使用5和9个量子比特。

Conclusion: 提出了一种全量子的测量反馈方法，成功实现了素数分解，展示了方法的实验可行性、鲁棒性和可扩展性，为量子计算中的素数分解问题提供了新途径。

Abstract: Prime factorization on quantum processors is typically implemented either via circuit-based approaches such as Shor's algorithm or through Hamiltonian optimization methods based on adiabatic, annealing, or variational techniques. While Shor's algorithm demands high-fidelity quantum gates, Hamiltonian optimization schemes, with prime factors encoded as degenerate ground states of a problem Hamiltonian, generally require substantial classical post-processing to determine control parameters. We propose an all-quantum, measurement-based feedback approach that iteratively steers a quantum system toward the target ground state, eliminating the need for classical computation of drive parameters once the problem Hamiltonian is determined and realized. As a proof of principle, we experimentally factor the biprime 551 using a three-qubit NMR quantum register and numerically analyze the robustness of the method against control field-errors. We further demonstrate scalability by numerically implementing the FALQON factorization of larger biprimes, 9,167 and 2,106,287, using 5 and 9 qubits, respectively.

</details>


### [102] [Exceptional points in Gaussian channels: diffusion gauging and drift-governed spectrum](https://arxiv.org/abs/2601.16121)
*Frank Ernesto Quintela Rodríguez*

Main category: quant-ph

TL;DR: 论文证明了线性开放量子系统中刘维尔谱与噪声强度无关的原理，并推广到离散时间的高斯通道


<details>
  <summary>Details</summary>
Motivation: 先前McDonald和Clerk的工作表明线性开放量子系统的刘维尔谱与噪声强度无关，本文旨在精确化这一噪声无关原理，并将其推广到更广泛的情况

Method: 1. 对多模玻色高斯马尔可夫半群，通过Lyapunov方程确定的高斯相似变换消除扩散项；2. 对稳定多模玻色高斯通道，构造显式高斯相似变换在通道参数化层面消除扩散

Result: 证明了特征值和不可对角化性完全由漂移项控制，而扩散项决定稳态和本征算符结构；将噪声无关原理推广到离散时间的高斯通道

Conclusion: 线性开放量子系统的谱特性与噪声强度无关，这一原理在连续和离散时间的高斯系统中都成立，为分析量子开放系统提供了新视角

Abstract: McDonald and Clerk [Phys.\ Rev.\ Research 5, 033107 (2023)] showed that for linear open quantum systems the Liouvillian spectrum is independent of the noise strength. We first make this noise-independence principle precise in continuous time for multimode bosonic Gaussian Markov semigroups: for Hurwitz drift, a time-independent Gaussian similarity fixed by the Lyapunov equation gauges away diffusion for all times, so eigenvalues and non-diagonalizability are controlled entirely by the drift, while diffusion determines steady states and the structure of eigenoperators. We then extend the same separation to discrete time for general stable multimode bosonic Gaussian channels: for any stable Gaussian channel, we construct an explicit Gaussian similarity transformation that gauges away diffusion at the level of the channel parametrization. We illustrate the method with a single-mode squeezed-reservoir Lindbladian and with a non-Markovian family of single-mode Gaussian channels, where the exceptional-point manifolds and the associated gauging covariances can be obtained analytically.

</details>


### [103] [Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments](https://arxiv.org/abs/2601.16123)
*Samuel Stein,Shuwen Kan,Chenxu Liu,Adrian Harkness,Sean Garner,Zefan Du,Yufei Ding,Ying Mao,Ang Li*

Main category: quant-ph

TL;DR: 提出硬件条件化神经解码器框架，利用超导处理器中校准漂移与纠错时间尺度的自然分离，通过FiLM调制实现低延迟高精度量子纠错解码


<details>
  <summary>Details</summary>
Motivation: 量子纠错的实时解码对容错量子计算至关重要，需要高精度、低延迟且能适应硬件噪声时空变化的解码器。超导处理器中校准漂移发生在小时尺度，而纠错需要微秒级响应，这提供了利用时间尺度分离的机会

Method: 引入硬件条件化神经解码器框架：1) 通过图编码器处理校准数据；2) 使用特征级线性调制(FiLM)条件化轻量卷积骨干网络；3) 将设备统计数据的重处理与低延迟症状解码解耦；4) 在IBM量子处理器上使用1D重复码作为测试平台

Result: 在IBM Fez、Kingston和Pittsburgh处理器上收集超过270万次实验数据：1) 单个训练模型可泛化到未见过的量子比特链和数天后获取的新校准数据；2) 在未见实验中，FiLM条件化解码器相比改进的最小权重完美匹配实现高达11.1倍的逻辑错误率降低；3) 相对于无条件基线，延迟开销可忽略

Conclusion: 通过利用系统校准与解码的高度异步特性，硬件条件化神经解码展示了有前景的自适应性能，为量子纠错解码提供了低延迟、高精度且能适应硬件变化的解决方案

Abstract: Real-time decoding of quantum error correction (QEC) is essential for enabling fault-tolerant quantum computation. A practical decoder must operate with high accuracy at low latency, while remaining robust to spatial and temporal variations in hardware noise. We introduce a hardware-conditioned neural decoder framework designed to exploit the natural separation of timescales in superconducting processors, where calibration drifts occur over hours while error correction requires microsecond-scale responses. By processing calibration data through a graph-based encoder and conditioning a lightweight convolutional backbone via feature-wise linear modulation (FiLM), we decouple the heavy processing of device statistics from the low-latency syndrome decoding.
  We evaluate this approach using the 1D repetition code as a testbed on IBM Fez, Kingston, and Pittsburgh processors, collecting over 2.7 million experimental shots spanning distances up to d = 11. We demonstrate that a single trained model generalizes to unseen qubit chains and new calibration data acquired days later without retraining. On these unseen experiments, the FiLM-conditioned decoder achieves up to an 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching. We observe that by employing a network architecture that exploits the highly asynchronous nature of system calibration and decoding, hardware-conditioned neural decoding demonstrates promising, adaptive performance with negligible latency overhead relative to unconditioned baselines.

</details>


### [104] [Quantum Dimension Reduction of Hidden Markov Models](https://arxiv.org/abs/2601.16126)
*Rishi Sundar,Thomas Elliott*

Main category: quant-ph

TL;DR: 提出一种将任意有限遍历隐马尔可夫模型压缩为量子隐马尔可夫模型的通用管道，相比经典压缩方法获得更好的内存-精度权衡


<details>
  <summary>Details</summary>
Motivation: 现有量子HMM压缩技术仅适用于确定性转移的受限HMM子集，需要一种能处理任意有限遍历HMM的通用压缩方法

Method: 引入一个通用管道，通过张量网络技术将任意有限遍历HMM压缩为量子HMM，实现有效的量子维度约简

Result: 在简单玩具模型和基于语音数据训练的HMM上验证方法，相比经典压缩方法获得更优的内存-精度权衡

Conclusion: 该方法为通用HMM的量子维度约简提供了有效途径，扩展了量子HMM压缩技术的适用范围

Abstract: Hidden Markov models (HMMs) are ubiquitous in time-series modelling, with applications ranging from chemical reaction modelling to speech recognition. These HMMs are often large, with high-dimensional memories. A recently-proposed application of quantum technologies is to execute quantum analogues of HMMs. Such quantum HMMs (QHMMs) are strictly more expressive than their classical counterparts, enabling the construction of more parsimonious models of stochastic processes. However, state-of-the-art techniques for QHMM compression, based on tensor networks, are only applicable for a restricted subset of HMMs, where the transitions are deterministic. In this work we introduce a pipeline by which \emph{any} finite, ergodic HMM can be compressed in this manner, providing a route for effective quantum dimension reduction of general HMMs. We demonstrate the method on both a simple toy model, and on a speech-derived HMM trained from data, obtaining favourable memory--accuracy trade-offs compared to classical compression approaches.

</details>


### [105] [Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory](https://arxiv.org/abs/2601.16144)
*Tetsuro Abe,Shu Tanaka*

Main category: quant-ph

TL;DR: 提出SBO-QAOA方法，使用温度相关哈密顿量编码吉布斯分布作为基态，解决标准QAOA在简并基态采样中的偏差问题，实现公平采样和温度控制。


<details>
  <summary>Details</summary>
Motivation: 在具有简并基态的组合优化问题中，公平采样简并解至关重要。然而，标准QAOA在电路深度增加时会在简并态之间引入偏差，影响采样公平性。

Method: 基于量子-经典对应理论，提出SBO-QAOA方法，使用温度相关的哈密顿量编码吉布斯分布作为基态，通过有限温度值收敛实现公平采样。

Result: 数值模拟显示，与标准QAOA不同，SBO-QAOA的基态概率收敛到有限温度值，在简并态之间实现均匀分布。即使在仅有4个变分参数和线性调度下，公平性和温度控制特性仍得以保持。

Conclusion: SBO-QAOA成功解决了QAOA在简并基态采样中的偏差问题，实现了公平采样和温度控制，为组合优化问题的量子算法提供了改进方案。

Abstract: In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule.

</details>


### [106] [Polynomial-time thermalization and Gibbs sampling from system-bath couplings](https://arxiv.org/abs/2601.16154)
*Samuel Slezak,Matteo Scandi,Álvaro M. Alhambra,Daniel Stilck França,Cambyse Rouzé*

Main category: quant-ph

TL;DR: 论文研究了弱耦合量子系统中Lindblad动力学收敛到稳态的速度，证明了两种非对易系统的多项式时间收敛性，为量子Gibbs态制备和热弛豫建模提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 理解Lindblad动力学收敛到稳态的速度对于限制算法运行时间和热化时间尺度至关重要，这关系到开放量子系统中的热化过程和量子Gibbs采样等物理现象。

Method: 研究了两类过程：重复相互作用的Gibbs采样算法和开放多体量子热化模型。通过将准局域Lindblad算子的谱隙下界外推到控制这些动力学的非局域生成元，证明了多项式时间收敛性。

Result: 证明了两种过程在多个非对易系统中多项式时间收敛，包括高温局域晶格、弱相互作用费米子和一维自旋链。这表明简单的耗散量子算法可以制备复杂的Gibbs态，且Lindblad动力学能准确描述热弛豫。

Conclusion: 该研究为量子Gibbs态的高效制备和Lindblad动力学在描述量子热弛豫方面的准确性提供了理论支持，通过谱隙外推技术为相关收敛性分析提供了新工具。

Abstract: Many physical phenomena, including thermalization in open quantum systems and quantum Gibbs sampling, are modeled by Lindbladians approximating a system weakly coupled to a bath. Understanding the convergence speed of these Lindbladians to their steady states is crucial for bounding algorithmic runtimes and thermalization timescales. We study two such families of processes: one characterizing a repeated-interaction Gibbs sampling algorithm, and another modeling open many-body quantum thermalization. We prove that both converge in polynomial time for several non-commuting systems, including high-temperature local lattices, weakly interacting fermions, and 1D spin chains. These results demonstrate that simple dissipative quantum algorithms can prepare complex Gibbs states and that Lindblad dynamics accurately capture thermal relaxation. Our proofs rely on a novel technical result that extrapolates spectral gap lower bounds from quasi-local Lindbladians to the non-local generators governing these dynamics.

</details>


### [107] [Stabilizer Thermal Eigenstates at Infinite Temperature](https://arxiv.org/abs/2601.16177)
*Akihiro Hokkyo*

Main category: quant-ph

TL;DR: 本文提出了一种基于稳定子的方法来构造非可积多体哈密顿量的解析能量本征态，证明了二体哈密顿量的稳定子本征态无法满足k≥4的微观热平衡，并通过构造展示了这一界限的紧致性。


<details>
  <summary>Details</summary>
Motivation: 理解高度纠缠的热本征态是量子多体系统研究的核心挑战，需要开发分析可处理的能量本征态构造方法。

Method: 采用基于稳定子的方法构造非可积多体哈密顿量的解析能量本征态，特别关注无限温度下的零能量本征态，通过理论证明和显式构造相结合。

Result: 证明了二体哈密顿量的稳定子本征态无法满足k≥4的微观热平衡，这一界限是紧致的，并构造了二体非可积哈密顿量，其稳定子本征态能重现所有二体和三体可观测量热期望值。

Conclusion: 揭示了稳定子态作为哈密顿量零能量本征态的结构条件，展现了相互作用少体性质所施加的基本约束，为理解量子热化机制提供了新视角。

Abstract: Understanding how to analyze highly entangled thermal eigenstates is a central challenge in the study of quantum many-body systems. In this Letter, we introduce a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians. Focusing on zero-energy eigenstates at infinite temperature, we prove a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy $k$-body microscopic thermal equilibrium for any $k\ge4$. We further show that this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables. Finally, we identify the structural origin of this limitation by characterizing the conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian, thereby revealing a fundamental constraint imposed by the few-body nature of interactions.

</details>


### [108] [Studying energy-resolved transport with wavepacket dynamics on quantum computers](https://arxiv.org/abs/2601.16180)
*Melody Lee,Roland C. Farrell*

Main category: quant-ph

TL;DR: 利用波包在量子计算机上探测能量依赖的输运性质，在安德森模型中观察到有限尺寸迁移率边，并开发了误差缓解和波包制备方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用简单初态（如计算基态）研究淬火动力学，这些态远离能量本征态，限制了能量分辨率。需要一种能够制备具有可调能量和小能量方差态的方法来探测能量依赖的输运。

Method: 提出使用波包来改善能量分辨率；在Quantinuum H2-2量子计算机上制备和演化波包；开发基于最大似然估计的误差缓解策略来推断无噪声输出分布；为多粒子体系开发制备准粒子波包的量子算法。

Result: 在8x7晶格的安德森模型中观察到能量依赖的局域化转变（有限尺寸迁移率边）：低能波包保持空间局域化，而高能波包发生离域化。误差缓解方法相比后选择减少了高达5倍的统计不确定性。

Conclusion: 波包方法为研究量子模拟器中的能量依赖输运提供了改进的能量分辨率，误差缓解策略显著提高了实验精度，波包制备算法为近期量子计算机研究多体系统中的输运性质提供了可行途径。

Abstract: Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.

</details>


### [109] [Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States](https://arxiv.org/abs/2601.16189)
*Xiaotian Yang,Santiago Zamora,Rafael Chaves,Ulrik L. Andersen,Jonatan Bohr Brask,A. de Oliveira Junior*

Main category: quant-ph

TL;DR: GKP编码可将零差探测转化为揭示贝尔非定域性的实用工具，但双粒子情形存在CHSH不可违逆的限制，而多粒子GKP编码态仍能展示强非定域性。


<details>
  <summary>Details</summary>
Motivation: 研究GKP编码是否能使零差探测成为连续变量系统中揭示贝尔非定域性的实用工具，解决传统零差探测在贝尔测试中的局限性。

Method: 采用物理激励模型：各方进行零差探测，通过固定周期性分箱将连续结果数字化（对应逻辑泡利测量）。分析双粒子情形（贝尔态）和多粒子情形（GKP编码的GHZ态和W态）。

Result: 双粒子情形存在不可行定理：贝尔态无法违反CHSH不等式。但多粒子情形中，有限压缩的GKP编码GHZ态和W态能违反多粒子贝尔不等式，展示了强非定域性。量化了所需压缩阈值和对损耗的鲁棒性。

Conclusion: GKP编码为零差探测在连续变量系统中进行贝尔测试提供了可行路径，虽然双粒子情形受限，但多粒子系统能展示强非定域性，为实验实现奠定了基础。

Abstract: Bell tests based on homodyne detection are strongly constrained in continuous-variable systems. Can Gottesman-Kitaev-Preskill (GKP) encoding turn homodyne detection into a practical tool for revealing Bell nonlocality? We consider a physically motivated model in which each party performs homodyne detection and digitizes the continuous outcome via a fixed periodic binning, corresponding to logical Pauli measurements. Within this framework, we derive a bipartite no-go: CHSH cannot be violated for Bell-pair states. Moving beyond two parties, we show that finitely squeezed GKP-encoded GHZ and W states nevertheless exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. We quantify the required squeezing thresholds and robustness to loss, providing a route toward homodyne-based Bell tests in continuous-variable systems.

</details>
