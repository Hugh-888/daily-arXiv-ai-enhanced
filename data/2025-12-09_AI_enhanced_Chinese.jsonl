{"id": "2512.06034", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.06034", "abs": "https://arxiv.org/abs/2512.06034", "authors": ["Niccol\u00f2 Covoni", "Carlo Rovelli"], "title": "Tractatus Quanticum", "comment": "16 pages", "summary": "This is a re-editing, which takes quantum mechanics into account, of Wittgenstein's famous Tractatus. The operation has a playful side in the form, but is a serious attempt to capture possible philosophical implications of the Relational Interpretation of Quantum Mechanics, and formalize the naturalistic third-way between realism and instrumentalism explored by this interpretation.", "AI": {"tldr": "\u5c06\u7ef4\u7279\u6839\u65af\u5766\u7684\u300a\u903b\u8f91\u54f2\u5b66\u8bba\u300b\u7528\u91cf\u5b50\u529b\u5b66\u91cd\u65b0\u8be0\u91ca\uff0c\u63a2\u7d22\u5173\u7cfb\u6027\u91cf\u5b50\u529b\u5b66\u89e3\u91ca\u7684\u54f2\u5b66\u610f\u6db5", "motivation": "\u63a2\u7d22\u5173\u7cfb\u6027\u91cf\u5b50\u529b\u5b66\u89e3\u91ca\u5728\u54f2\u5b66\u4e0a\u7684\u53ef\u80fd\u610f\u4e49\uff0c\u5f62\u5f0f\u5316\u8fd9\u79cd\u89e3\u91ca\u6240\u63a2\u8ba8\u7684\u4ecb\u4e8e\u5b9e\u5728\u8bba\u4e0e\u5de5\u5177\u4e3b\u4e49\u4e4b\u95f4\u7684\u7b2c\u4e09\u6761\u81ea\u7136\u4e3b\u4e49\u8def\u5f84", "method": "\u7528\u91cf\u5b50\u529b\u5b66\u91cd\u65b0\u7f16\u8f91\u7ef4\u7279\u6839\u65af\u5766\u7684\u300a\u903b\u8f91\u54f2\u5b66\u8bba\u300b\uff0c\u5f62\u5f0f\u4e0a\u5177\u6709\u6e38\u620f\u6027\uff0c\u4f46\u5b9e\u8d28\u4e0a\u662f\u4e25\u8083\u7684\u54f2\u5b66\u5206\u6790", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5173\u7cfb\u6027\u91cf\u5b50\u529b\u5b66\u89e3\u91ca\u7684\u54f2\u5b66\u6846\u67b6\uff0c\u8bd5\u56fe\u5728\u5b9e\u5728\u8bba\u548c\u5de5\u5177\u4e3b\u4e49\u4e4b\u95f4\u627e\u5230\u7b2c\u4e09\u6761\u81ea\u7136\u4e3b\u4e49\u8def\u5f84", "conclusion": "\u5173\u7cfb\u6027\u91cf\u5b50\u529b\u5b66\u89e3\u91ca\u4e3a\u54f2\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u80fd\u591f\u5f62\u5f0f\u5316\u4e00\u79cd\u4ecb\u4e8e\u4f20\u7edf\u5b9e\u5728\u8bba\u548c\u5de5\u5177\u4e3b\u4e49\u4e4b\u95f4\u7684\u81ea\u7136\u4e3b\u4e49\u7acb\u573a"}}
{"id": "2512.06043", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06043", "abs": "https://arxiv.org/abs/2512.06043", "authors": ["Yongjie Pan", "Baocheng Zhang", "Qingyu Cai"], "title": "Entanglement is protected by acceleration-induced transparency in thermal field", "comment": "will appear in Phys. Rev. D", "summary": "The acceleration-induced transparency (AIT) effect has been suggested recently to amply the transition probability of the two-level detctor and offers a potential avenue for the experimental detection of the Unruh effect. In this paper, we explore the influence of the AIT effect on quantum entanglement between two detectors accelerated in a thermal field background, since the thermal backgound field cannot be avoided completely in any experiments. Interestingly, we find that although the backgound thermal field generally degrade the entanglement between the detectors, the AIT effect can effectively protect it.", "AI": {"tldr": "\u7814\u7a76\u70ed\u573a\u80cc\u666f\u4e0b\u52a0\u901f\u63a2\u6d4b\u5668\u7684\u91cf\u5b50\u7ea0\u7f20\uff0c\u53d1\u73b0AIT\u6548\u5e94\u80fd\u6709\u6548\u4fdd\u62a4\u7ea0\u7f20\u514d\u53d7\u70ed\u573a\u9000\u76f8\u5e72\u5f71\u54cd", "motivation": "\u63a2\u7d22AIT\u6548\u5e94\u5bf9\u70ed\u573a\u80cc\u666f\u4e0b\u52a0\u901f\u63a2\u6d4b\u5668\u91cf\u5b50\u7ea0\u7f20\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u5b9e\u9a8c\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u70ed\u80cc\u666f\u573a", "method": "\u7814\u7a76\u4e24\u4e2a\u5728\u70ed\u573a\u80cc\u666f\u4e2d\u52a0\u901f\u7684\u63a2\u6d4b\u5668\u7684\u91cf\u5b50\u7ea0\u7f20\uff0c\u5206\u6790AIT\u6548\u5e94\u7684\u5f71\u54cd", "result": "\u867d\u7136\u70ed\u80cc\u666f\u573a\u901a\u5e38\u4f1a\u964d\u4f4e\u63a2\u6d4b\u5668\u95f4\u7684\u7ea0\u7f20\uff0c\u4f46AIT\u6548\u5e94\u80fd\u6709\u6548\u4fdd\u62a4\u7ea0\u7f20", "conclusion": "AIT\u6548\u5e94\u5728\u70ed\u573a\u73af\u5883\u4e2d\u5bf9\u91cf\u5b50\u7ea0\u7f20\u5177\u6709\u4fdd\u62a4\u4f5c\u7528\uff0c\u4e3a\u5b9e\u9a8c\u63a2\u6d4bUnruh\u6548\u5e94\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2512.06070", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06070", "abs": "https://arxiv.org/abs/2512.06070", "authors": ["Omar Alsheikh", "Efekan K\u00f6kc\u00fc", "Bojko N. Bakalov", "A. F. Kemper"], "title": "RedCarD: A Quantum Assisted Algorithm for Fixed-Depth Unitary Synthesis via Cartan Decomposition", "comment": "9+6 pages", "summary": "A critical step in developing circuits for quantum simulation is to synthesize a desired unitary operator using the circuit building blocks. Studying unitaries and their generators from the Lie algebraic perspective has given rise to several algorithms for synthesis based on a Cartan decomposition of the dynamical Lie algebra. For unitaries of the form $e^{-itH}$, such as time-independent Hamiltonian simulation, the resulting circuits have depth that does not depend on simulation time $t$. However, finding such circuits has a large classical overhead in the cost function evaluation and the high dimensional optimization problem. In this work, by further partitioning the dynamical Lie algebra, we break down the optimization problem into smaller independent subproblems. Moreover, the resulting algebraic structure allows us to easily shift the evaluation of the cost function to the quantum computer, further cutting the classical overhead of the algorithm. As an application of the new hybrid algorithm, we synthesize the time evolution unitary for the 4-site transverse field Ising model on several IBM devices and Quantinuum's H1-1 quantum computer.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u5212\u5206\u52a8\u529b\u5b66\u674e\u4ee3\u6570\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684\u72ec\u7acb\u5b50\u95ee\u9898\uff0c\u5e76\u5c06\u4ee3\u4ef7\u51fd\u6570\u8bc4\u4f30\u8f6c\u79fb\u5230\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\uff0c\u51cf\u5c11\u7ecf\u5178\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u91cf\u5b50\u6a21\u62df\u7535\u8def\u5408\u6210\u4e2d\uff0c\u57fa\u4e8e\u52a8\u529b\u5b66\u674e\u4ee3\u6570Cartan\u5206\u89e3\u7684\u7b97\u6cd5\u867d\u7136\u80fd\u4ea7\u751f\u4e0e\u6a21\u62df\u65f6\u95f4\u65e0\u5173\u7684\u7535\u8def\u6df1\u5ea6\uff0c\u4f46\u7ecf\u5178\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u5305\u62ec\u4ee3\u4ef7\u51fd\u6570\u8bc4\u4f30\u548c\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8fdb\u4e00\u6b65\u5212\u5206\u52a8\u529b\u5b66\u674e\u4ee3\u6570\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684\u72ec\u7acb\u5b50\u95ee\u9898\uff1b\u5229\u7528\u4ee3\u6570\u7ed3\u6784\u5c06\u4ee3\u4ef7\u51fd\u6570\u8bc4\u4f30\u8f6c\u79fb\u5230\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\uff0c\u5f62\u6210\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u4e2aIBM\u8bbe\u5907\u548cQuantinuum H1-1\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u6210\u529f\u5408\u6210\u4e864\u4f4d\u70b9\u6a2a\u5411\u573aIsing\u6a21\u578b\u7684\u65f6\u95f4\u6f14\u5316\u5e7a\u6b63\u7b97\u7b26\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u7ecf\u5178\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u91cf\u5b50\u7535\u8def\u5408\u6210\uff0c\u4e3a\u91cf\u5b50\u6a21\u62df\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.06076", "categories": ["quant-ph", "gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06076", "abs": "https://arxiv.org/abs/2512.06076", "authors": ["Matheus H. Zambianco", "T. Rick Perche"], "title": "The Twin Paradox in Quantum Field Theory", "comment": "5 pages, 2 figures + appendices", "summary": "Vacuum fluctuations in quantum field theory impose fundamental limitations on our ability to measure time in short scales. To investigate the impact of universal quantum field theory effects on observer-dependent time measurements, we introduce a clock model based on the vacuum decay probability of a finite-sized quantum system. Using this model, we study a microscopic twin paradox scenario and find that, in the smallest scales, time is not only dependent on the trajectory connecting two events, but also on how vacuum fluctuations interact with the microscopic details of the clocks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u91cf\u5b50\u7cfb\u7edf\u771f\u7a7a\u8870\u53d8\u6982\u7387\u7684\u65f6\u949f\u6a21\u578b\uff0c\u7814\u7a76\u5fae\u89c2\u53cc\u751f\u5b50\u4f6f\u8c2c\uff0c\u53d1\u73b0\u6700\u5c0f\u5c3a\u5ea6\u4e0b\u65f6\u95f4\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u4e8b\u4ef6\u95f4\u8f68\u8ff9\uff0c\u8fd8\u53d7\u771f\u7a7a\u6da8\u843d\u4e0e\u65f6\u949f\u5fae\u89c2\u7ec6\u8282\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u3002", "motivation": "\u91cf\u5b50\u573a\u8bba\u4e2d\u7684\u771f\u7a7a\u6da8\u843d\u5bf9\u77ed\u65f6\u95f4\u5c3a\u5ea6\u6d4b\u91cf\u65bd\u52a0\u4e86\u57fa\u672c\u9650\u5236\u3002\u4e3a\u4e86\u7814\u7a76\u666e\u904d\u91cf\u5b50\u573a\u8bba\u6548\u5e94\u5bf9\u89c2\u6d4b\u8005\u76f8\u5173\u65f6\u95f4\u6d4b\u91cf\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5efa\u7acb\u9002\u5f53\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6709\u9650\u5927\u5c0f\u91cf\u5b50\u7cfb\u7edf\u771f\u7a7a\u8870\u53d8\u6982\u7387\u7684\u65f6\u949f\u6a21\u578b\uff0c\u4f7f\u7528\u8be5\u6a21\u578b\u7814\u7a76\u5fae\u89c2\u53cc\u751f\u5b50\u4f6f\u8c2c\u573a\u666f\u3002", "result": "\u5728\u6700\u5c0f\u5c3a\u5ea6\u4e0b\uff0c\u65f6\u95f4\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u8fde\u63a5\u4e24\u4e2a\u4e8b\u4ef6\u7684\u8f68\u8ff9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u771f\u7a7a\u6da8\u843d\u5982\u4f55\u4e0e\u65f6\u949f\u7684\u5fae\u89c2\u7ec6\u8282\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u771f\u7a7a\u6da8\u843d\u5bf9\u5fae\u89c2\u65f6\u95f4\u6d4b\u91cf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u91cf\u5b50\u573a\u8bba\u6548\u5e94\u5728\u6700\u5c0f\u5c3a\u5ea6\u4e0a\u663e\u8457\u6539\u53d8\u4e86\u65f6\u95f4\u6d4b\u91cf\u7684\u6027\u8d28\uff0c\u65f6\u95f4\u6982\u5ff5\u5728\u5fae\u89c2\u5c3a\u5ea6\u4e0a\u5177\u6709\u66f4\u590d\u6742\u7684\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2512.05976", "categories": ["physics.comp-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05976", "abs": "https://arxiv.org/abs/2512.05976", "authors": ["Antonio Varagnolo", "Giuseppe Romano", "Rapha\u00ebl Pestourie"], "title": "Physics Enhanced Deep Surrogates for the Phonon Boltzmann Transport Equation", "comment": null, "summary": "Designing materials with controlled heat flow at the nano-scale is central to advances in microelectronics, thermoelectrics, and energy-conversion technologies. At these scales, phonon transport follows the Boltzmann Transport Equation (BTE), which captures non-diffusive (ballistic) effects but is too costly to solve repeatedly in inverse-design loops. Existing surrogate approaches trade speed for accuracy: fast macroscopic solvers can overestimate conductivities by hundreds of percent, while recent data-driven operator learners often require thousands of high-fidelity simulations. This creates a need for a fast, data-efficient surrogate that remains reliable across ballistic and diffusive regimes. We introduce a Physics-Enhanced Deep Surrogate (PEDS) that combines a differentiable Fourier solver with a neural generator and couples it with uncertainty-driven active learning. The Fourier solver acts as a physical inductive bias, while the network learns geometry-dependent corrections and a mixing coefficient that interpolates between macroscopic and nano-scale behavior. PEDS reduces training-data requirements by up to 70% compared with purely data-driven baselines, achieves roughly 5% fractional error with only 300 high-fidelity BTE simulations, and enables efficient design of porous geometries spanning 12-85 W m$^{-1}$ K$^{-1}$ with average design errors of 4%. The learned mixing parameter recovers the ballistic-diffusive transition and improves out of distribution robustness. These results show that embedding simple, differentiable low-fidelity physics can dramatically increase surrogate data-efficiency and interpretability, making repeated PDE-constrained optimization practical for nano-scale thermal-materials design.", "AI": {"tldr": "\u63d0\u51faPEDS\u65b9\u6cd5\uff0c\u7ed3\u5408\u53ef\u5fae\u5206\u5085\u91cc\u53f6\u6c42\u89e3\u5668\u548c\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u7269\u7406\u589e\u5f3a\u7684\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u7eb3\u7c73\u5c3a\u5ea6\u70ed\u6750\u6599\u8bbe\u8ba1\u4e2d\u7684\u8ba1\u7b97\u6210\u672c\u548c\u6570\u636e\u9700\u6c42\u3002", "motivation": "\u7eb3\u7c73\u5c3a\u5ea6\u70ed\u6d41\u63a7\u5236\u5bf9\u5fae\u7535\u5b50\u3001\u70ed\u7535\u548c\u80fd\u91cf\u8f6c\u6362\u6280\u672f\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u6743\u8861\uff1a\u5b8f\u89c2\u6c42\u89e3\u5668\u8bef\u5dee\u5927\uff0c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9ad8\u4fdd\u771f\u6a21\u62df\u3002\u9700\u8981\u4e00\u79cd\u5feb\u901f\u3001\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u4ee3\u7406\u6a21\u578b\u3002", "method": "PEDS\u65b9\u6cd5\u7ed3\u5408\u53ef\u5fae\u5206\u5085\u91cc\u53f6\u6c42\u89e3\u5668\uff08\u7269\u7406\u5f52\u7eb3\u504f\u7f6e\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u5668\uff0c\u5b66\u4e60\u51e0\u4f55\u4f9d\u8d56\u4fee\u6b63\u548c\u6df7\u5408\u7cfb\u6570\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u4e3b\u52a8\u5b66\u4e60\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u3002", "result": "\u76f8\u6bd4\u7eaf\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\u51cf\u5c1170%\u8bad\u7ec3\u6570\u636e\u9700\u6c42\uff0c\u4ec5\u7528300\u6b21\u9ad8\u4fdd\u771fBTE\u6a21\u62df\u5b9e\u73b0\u7ea65%\u5206\u6570\u8bef\u5dee\uff0c\u8bbe\u8ba1\u5b54\u9699\u51e0\u4f55\u7684\u5e73\u5747\u8bef\u5dee\u4e3a4%\uff0c\u6df7\u5408\u53c2\u6570\u80fd\u6355\u6349\u5f39\u9053-\u6269\u6563\u8f6c\u53d8\u3002", "conclusion": "\u5d4c\u5165\u7b80\u5355\u53ef\u5fae\u5206\u7684\u4f4e\u4fdd\u771f\u7269\u7406\u6a21\u578b\u80fd\u663e\u8457\u63d0\u9ad8\u4ee3\u7406\u6a21\u578b\u7684\u6570\u636e\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f7fPDE\u7ea6\u675f\u4f18\u5316\u5728\u7eb3\u7c73\u5c3a\u5ea6\u70ed\u6750\u6599\u8bbe\u8ba1\u4e2d\u53d8\u5f97\u5b9e\u7528\u3002"}}
{"id": "2512.06051", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06051", "abs": "https://arxiv.org/abs/2512.06051", "authors": ["Siddharth Kumar Sahoo", "Indrani Banerjee"], "title": "Investigating the interplay of the braneworld gravity and the plasma environment on the black hole shadow", "comment": "41 pages, 12 figures, 3 tables; Comments are welcome", "summary": "We investigate the shadow of a rotating braneworld black hole in dispersive plasma environments and assess the potential of the Event Horizon Telescope (EHT) observations to constrain braneworld gravity. The spacetime around a rotating braneworld black hole is modelled by a Kerr-Newman-like metric determined by its mass $M$, spin $a$, and tidal charge $q$, which encodes the gravitational effects of the bulk spacetime. We consider both inhomogeneous and homogeneous plasma environments characterized by plasma parameters $\u03b1_i$ ($i=1,2\\text{ and }3$) to study light propagation and the interplay of the background spacetime and the plasma environment in influencing the shadow size and shape. We find that as the plasma density increases, inhomogeneous plasma environments decrease the shadow size, however homogeneous plasma enlarges it. On studying the effect due to background spacetime we find that $q<0$ (negative tidal charge) increases the shadow diameter, while $q>0$ decreases it. Using the EHT measurements of M87* and Sgr A*, we constrain the $(q,\u03b1_i)$ parameter space. The EHT data constrains the tidal charge in the range $-1.15 \\lesssim q \\lesssim 0.45$ for M87* and $-0.65 \\lesssim q \\lesssim 0.8$ for Sgr A* in the low density plasma limit. As the plasma density increases, the data exhibits a preference towards negative tidal charge for inhomogeneous plasma environments and positive tidal charge for homogeneous plasma environments. Our study reveals that the size of the shadow is primarily governed by the background geometry in presence of low density plasma environments such as that observed in M87* and Sgr A*. However, if supermassive blackholes are surrounded by high density plasma then the shadow size is dictated by both the background metric and the plasma environment.", "AI": {"tldr": "\u7814\u7a76\u65cb\u8f6c\u819c\u4e16\u754c\u9ed1\u6d1e\u5728\u8272\u6563\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u4e2d\u7684\u9634\u5f71\uff0c\u5229\u7528EHT\u89c2\u6d4b\u6570\u636e\u7ea6\u675f\u819c\u4e16\u754c\u5f15\u529b\u53c2\u6570", "motivation": "\u63a2\u7d22\u819c\u4e16\u754c\u5f15\u529b\u7406\u8bba\u5728\u9ed1\u6d1e\u9634\u5f71\u89c2\u6d4b\u4e2d\u7684\u53ef\u68c0\u9a8c\u6027\uff0c\u7814\u7a76\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u5bf9\u9ed1\u6d1e\u9634\u5f71\u7684\u5f71\u54cd\uff0c\u5229\u7528EHT\u5bf9M87*\u548cSgr A*\u7684\u89c2\u6d4b\u6570\u636e\u7ea6\u675f\u819c\u4e16\u754c\u5f15\u529b\u53c2\u6570", "method": "\u91c7\u7528Kerr-Newman-like\u5ea6\u89c4\u63cf\u8ff0\u65cb\u8f6c\u819c\u4e16\u754c\u9ed1\u6d1e\uff0c\u8003\u8651\u6f6e\u6c50\u7535\u8377q\u53c2\u6570\u5316\u819c\u4e16\u754c\u5f15\u529b\u6548\u5e94\uff1b\u7814\u7a76\u975e\u5747\u5300\u548c\u5747\u5300\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u5bf9\u5149\u7ebf\u4f20\u64ad\u7684\u5f71\u54cd\uff1b\u5229\u7528EHT\u89c2\u6d4b\u6570\u636e\u7ea6\u675f(q,\u03b1_i)\u53c2\u6570\u7a7a\u95f4", "result": "\u7b49\u79bb\u5b50\u4f53\u5bc6\u5ea6\u589e\u52a0\u65f6\uff0c\u975e\u5747\u5300\u7b49\u79bb\u5b50\u4f53\u51cf\u5c0f\u9634\u5f71\u5c3a\u5bf8\uff0c\u5747\u5300\u7b49\u79bb\u5b50\u4f53\u589e\u5927\u9634\u5f71\u5c3a\u5bf8\uff1b\u8d1f\u6f6e\u6c50\u7535\u8377(q<0)\u589e\u5927\u9634\u5f71\u76f4\u5f84\uff0c\u6b63\u6f6e\u6c50\u7535\u8377(q>0)\u51cf\u5c0f\u9634\u5f71\u76f4\u5f84\uff1bEHT\u6570\u636e\u7ea6\u675f\u6f6e\u6c50\u7535\u8377\u8303\u56f4\uff1aM87*\u4e3a-1.15\u2272q\u22720.45\uff0cSgr A*\u4e3a-0.65\u2272q\u22720.8\uff08\u4f4e\u5bc6\u5ea6\u7b49\u79bb\u5b50\u4f53\u6781\u9650\uff09", "conclusion": "\u5728M87*\u548cSgr A*\u7b49\u4f4e\u5bc6\u5ea6\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u4e2d\uff0c\u9634\u5f71\u5c3a\u5bf8\u4e3b\u8981\u7531\u80cc\u666f\u51e0\u4f55\u51b3\u5b9a\uff1b\u4f46\u5728\u9ad8\u5bc6\u5ea6\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u4e2d\uff0c\u9634\u5f71\u5c3a\u5bf8\u540c\u65f6\u53d7\u80cc\u666f\u5ea6\u89c4\u548c\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u5171\u540c\u5f71\u54cd\uff1bEHT\u89c2\u6d4b\u6570\u636e\u53ef\u7528\u4e8e\u7ea6\u675f\u819c\u4e16\u754c\u5f15\u529b\u53c2\u6570"}}
{"id": "2512.05989", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.05989", "abs": "https://arxiv.org/abs/2512.05989", "authors": ["Selma Dahms", "Luca Torresi", "Shahbaz Tareq Bandesha", "Jan Hansmann", "Holger R\u00f6hm", "Alexander Colsmann", "Marco Schott", "Pascal Friederich"], "title": "A self-driving lab for solution-processed electrochromic thin films", "comment": null, "summary": "Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.", "AI": {"tldr": "\u5229\u7528\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u7ed3\u5408\u81ea\u52a8\u5316\u548c\u673a\u5668\u5b66\u4e60\u52a0\u901f\u7535\u81f4\u53d8\u8272\u6d82\u5c42\u5f00\u53d1\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u9ad8\u6548\u63a2\u7d22\u5de5\u827a\u53c2\u6570", "motivation": "\u6eb6\u6db2\u5904\u7406\u7684\u7535\u81f4\u53d8\u8272\u6750\u6599\u5728\u667a\u80fd\u7a97\u6237\u548c\u663e\u793a\u5668\u4e2d\u5177\u6709\u9ad8\u6f5c\u529b\uff0c\u4f46\u65cb\u6d82\u7535\u81f4\u53d8\u8272\u8584\u819c\u5c42\u7684\u4f18\u5316\u590d\u6742\uff0c\u963b\u788d\u4e86\u5feb\u901f\u5f00\u53d1", "method": "\u7ed3\u5408\u81ea\u52a8\u6570\u636e\u91c7\u96c6\u3001\u56fe\u50cf\u5904\u7406\u3001\u5149\u8c31\u5206\u6790\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u7cfb\u7edf\uff0c\u9ad8\u6548\u63a2\u7d22\u5904\u7406\u53c2\u6570", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u901a\u91cf\uff0c\u8fd8\u80fd\u6709\u9488\u5bf9\u6027\u5730\u641c\u7d22\u6700\u4f18\u5904\u7406\u53c2\u6570\uff0c\u53ef\u5e94\u7528\u4e8e\u5404\u79cd\u6eb6\u6db2\u5904\u7406\u6750\u6599", "conclusion": "\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u5728\u6750\u6599\u53d1\u73b0\u548c\u5de5\u827a\u4f18\u5316\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u52a0\u901f\u7535\u81f4\u53d8\u8272\u6d82\u5c42\u7b49\u6eb6\u6db2\u5904\u7406\u6750\u6599\u7684\u5f00\u53d1"}}
{"id": "2512.06081", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.06081", "abs": "https://arxiv.org/abs/2512.06081", "authors": ["Bo Xing", "Giuliano Chiriac\u00f2", "Paola Cappellaro", "Rosario Fazio", "Dario Poletti"], "title": "Entanglement transition in unitary system-bath dynamics", "comment": "5 pages, 4 figures main text", "summary": "The evolution of a system coupled to baths is commonly described by a master equation that, in the long-time limit, yields a steady-state density matrix. However, when the same evolution is unraveled into quantum trajectories, it is possible to observe a transition in the scaling of entanglement within the system as the system-bath coupling increases - a phenomenon that is invisible in the trajectory-averaged reduced density matrix of the system. Here, we go beyond the paradigm of trajectories from master equations and explore whether a qualitatively analogous entanglement-scaling transition emerges in the unitary evolution of the combined system-bath setup. We investigate the scaling of entanglement in a unitary quantum setup composed of a 2D lattice of free fermions, where each site is coupled to a fermionic bath. Varying the system-bath coupling reveals a transition from logarithmic-law to area-law scaling, visible in the logarithmic fermionic negativity, mutual information, and also in the correlations. This occurs while the system's steady-state properties are trivial, highlighting that the signatures of these different scalings are within the bath-bath correlations.", "AI": {"tldr": "\u5728\u7cfb\u7edf-\u6d74\u573a\u8026\u5408\u7684\u81ea\u7531\u8d39\u7c73\u5b50\u6a21\u578b\u4e2d\uff0c\u968f\u7740\u8026\u5408\u5f3a\u5ea6\u589e\u52a0\uff0c\u7ea0\u7f20\u6807\u5ea6\u4f1a\u4ece\u5bf9\u6570\u5f8b\u5411\u9762\u79ef\u5f8b\u8f6c\u53d8\uff0c\u8fd9\u79cd\u8f6c\u53d8\u5728\u8f68\u8ff9\u5e73\u5747\u7684\u7ea6\u5316\u5bc6\u5ea6\u77e9\u9635\u4e2d\u4e0d\u53ef\u89c1\uff0c\u4f46\u4f53\u73b0\u5728\u6d74\u573a-\u6d74\u573a\u5173\u8054\u4e2d\u3002", "motivation": "\u4f20\u7edf\u4e3b\u65b9\u7a0b\u65b9\u6cd5\u5728\u957f\u65f6\u95f4\u6781\u9650\u4e0b\u7ed9\u51fa\u7a33\u6001\u5bc6\u5ea6\u77e9\u9635\uff0c\u4f46\u91cf\u5b50\u8f68\u8ff9\u5c55\u5f00\u663e\u793a\u7cfb\u7edf\u7ea0\u7f20\u6807\u5ea6\u968f\u7cfb\u7edf-\u6d74\u573a\u8026\u5408\u589e\u5f3a\u4f1a\u53d1\u751f\u8f6c\u53d8\uff0c\u8fd9\u79cd\u8f6c\u53d8\u5728\u8f68\u8ff9\u5e73\u5747\u7684\u7ea6\u5316\u5bc6\u5ea6\u77e9\u9635\u4e2d\u4e0d\u53ef\u89c1\u3002\u672c\u6587\u63a2\u7d22\u5728\u7cfb\u7edf-\u6d74\u573a\u7684\u5e7a\u6b63\u6f14\u5316\u4e2d\u662f\u5426\u4e5f\u5b58\u5728\u7c7b\u4f3c\u7684\u7ea0\u7f20\u6807\u5ea6\u8f6c\u53d8\u73b0\u8c61\u3002", "method": "\u7814\u7a76\u4e00\u4e2a\u5e7a\u6b63\u91cf\u5b50\u7cfb\u7edf\uff1a\u4e8c\u7ef4\u81ea\u7531\u8d39\u7c73\u5b50\u6676\u683c\uff0c\u6bcf\u4e2a\u683c\u70b9\u8026\u5408\u5230\u4e00\u4e2a\u8d39\u7c73\u5b50\u6d74\u573a\u3002\u901a\u8fc7\u6539\u53d8\u7cfb\u7edf-\u6d74\u573a\u8026\u5408\u5f3a\u5ea6\uff0c\u5206\u6790\u5bf9\u6570\u8d39\u7c73\u5b50\u8d1f\u6027\u3001\u4e92\u4fe1\u606f\u548c\u5173\u8054\u7684\u6807\u5ea6\u884c\u4e3a\u3002", "result": "\u968f\u7740\u7cfb\u7edf-\u6d74\u573a\u8026\u5408\u589e\u5f3a\uff0c\u7ea0\u7f20\u6807\u5ea6\u4ece\u5bf9\u6570\u5f8b\u5411\u9762\u79ef\u5f8b\u8f6c\u53d8\u3002\u8fd9\u79cd\u8f6c\u53d8\u5728\u7cfb\u7edf\u7684\u7a33\u6001\u6027\u8d28\u662f\u5e73\u51e1\u7684\u60c5\u51b5\u4e0b\u53d1\u751f\uff0c\u8f6c\u53d8\u7684\u8ff9\u8c61\u4f53\u73b0\u5728\u6d74\u573a-\u6d74\u573a\u5173\u8054\u4e2d\u3002", "conclusion": "\u5728\u7cfb\u7edf-\u6d74\u573a\u7684\u5e7a\u6b63\u6f14\u5316\u4e2d\u786e\u5b9e\u5b58\u5728\u7ea0\u7f20\u6807\u5ea6\u8f6c\u53d8\uff0c\u8fd9\u79cd\u8f6c\u53d8\u5728\u8f68\u8ff9\u5e73\u5747\u7684\u7ea6\u5316\u5bc6\u5ea6\u77e9\u9635\u4e2d\u4e0d\u53ef\u89c1\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u6d74\u573a-\u6d74\u573a\u5173\u8054\u6765\u63a2\u6d4b\uff0c\u4e3a\u7406\u89e3\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u7ea0\u7f20\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.06173", "categories": ["physics.comp-ph", "physics.chem-ph", "physics.optics", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06173", "abs": "https://arxiv.org/abs/2512.06173", "authors": ["Xinwei Ji", "Andres Felipe Bocanegra Vargas", "Gang Meng", "Tao E. Li"], "title": "MaxwellLink: A unified framework for self-consistent light-matter simulations", "comment": "Associated source code in https://github.com/TaoELi/MaxwellLink", "summary": "A major challenge in light-matter simulations is bridging the disparate time and length scales of electrodynamics and molecular dynamics. Current computational approaches often rely on heuristic approximations of either the electromagnetic (EM) or material component, hindering the exploration of complex light-matter systems. Herein, MaxwellLink -- a modular, open-source Python framework -- is developed for the massively parallel, self-consistent propagation of classical EM fields interacting with a large heterogeneous molecular ensemble. The package utilizes a robust TCP/UNIX socket interface to couple EM solvers with a wide range of external molecular drivers. This decoupled architecture allows users to seamlessly switch between levels of theory of either the EM solver or molecules without modifying the counterpart. Crucially, MaxwellLink supports EM solvers spanning from single-mode cavities to full-feature three-dimensional finite-difference time-domain (FDTD) engines, and molecules described by multilevel open quantum systems, force-field and first-principles molecular dynamics, and nonadiabatic real-time Ehrenfest dynamics. Benefiting from the socket-based design, the EM engine and molecular drivers scale independently across multiple high-performance computing (HPC) nodes, facilitating large-scale simulations previously inaccessible to existing numerical schemes. The versatility and accuracy of this code are demonstrated through applications including superradiance, radiative energy transfer, vibrational strong coupling in Bragg resonators, and plasmonic heating of molecular gases. By providing a unified, extensible engine, MaxwellLink potentially offers a powerful platform for exploring emerging phenomena across the research fronts of spectroscopy, quantum optics, plasmonics, and polaritonics.", "AI": {"tldr": "MaxwellLink\u662f\u4e00\u4e2a\u5f00\u6e90Python\u6846\u67b6\uff0c\u901a\u8fc7TCP/UNIX\u5957\u63a5\u5b57\u63a5\u53e3\u8026\u5408\u7535\u78c1\u6c42\u89e3\u5668\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u5668\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u5e76\u884c\u3001\u81ea\u6d3d\u7684\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u6a21\u62df\u3002", "motivation": "\u5f53\u524d\u5149-\u7269\u8d28\u6a21\u62df\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u7535\u78c1\u52a8\u529b\u5b66\u548c\u5206\u5b50\u52a8\u529b\u5b66\u5728\u65f6\u95f4\u548c\u957f\u5ea6\u5c3a\u5ea6\u4e0a\u7684\u5de8\u5927\u5dee\u5f02\u3002\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5bf9\u7535\u78c1\u6216\u6750\u6599\u7ec4\u5206\u7684\u542f\u53d1\u5f0f\u8fd1\u4f3c\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u590d\u6742\u5149-\u7269\u8d28\u7cfb\u7edf\u7684\u63a2\u7d22\u3002", "method": "\u5f00\u53d1\u4e86\u6a21\u5757\u5316\u7684MaxwellLink\u6846\u67b6\uff0c\u91c7\u7528TCP/UNIX\u5957\u63a5\u5b57\u63a5\u53e3\u5c06\u7535\u78c1\u6c42\u89e3\u5668\u4e0e\u5916\u90e8\u5206\u5b50\u9a71\u52a8\u7a0b\u5e8f\u8026\u5408\u3002\u8fd9\u79cd\u89e3\u8026\u67b6\u6784\u5141\u8bb8\u7528\u6237\u5728\u4e0d\u4fee\u6539\u5bf9\u5e94\u7ec4\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u7531\u5207\u6362\u7535\u78c1\u6c42\u89e3\u5668\u6216\u5206\u5b50\u7684\u7406\u8bba\u7ea7\u522b\u3002\u652f\u6301\u4ece\u5355\u6a21\u8154\u5230\u4e09\u7ef4FDTD\u7684\u7535\u78c1\u6c42\u89e3\u5668\uff0c\u4ee5\u53ca\u591a\u7ea7\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u3001\u529b\u573a\u3001\u7b2c\u4e00\u6027\u539f\u7406\u5206\u5b50\u52a8\u529b\u5b66\u548c\u975e\u7edd\u70ed\u5b9e\u65f6Ehrenfest\u52a8\u529b\u5b66\u7b49\u5206\u5b50\u63cf\u8ff0\u65b9\u6cd5\u3002", "result": "\u5957\u63a5\u5b57\u8bbe\u8ba1\u4f7f\u7535\u78c1\u5f15\u64ce\u548c\u5206\u5b50\u9a71\u52a8\u7a0b\u5e8f\u80fd\u591f\u5728\u591a\u4e2a\u9ad8\u6027\u80fd\u8ba1\u7b97\u8282\u70b9\u4e0a\u72ec\u7acb\u6269\u5c55\uff0c\u5b9e\u73b0\u4e86\u73b0\u6709\u6570\u503c\u65b9\u6848\u65e0\u6cd5\u8fdb\u884c\u7684\u5927\u89c4\u6a21\u6a21\u62df\u3002\u901a\u8fc7\u8d85\u8f90\u5c04\u3001\u8f90\u5c04\u80fd\u91cf\u8f6c\u79fb\u3001\u5e03\u62c9\u683c\u8c10\u632f\u5668\u4e2d\u7684\u632f\u52a8\u5f3a\u8026\u5408\u4ee5\u53ca\u5206\u5b50\u6c14\u4f53\u7684\u7b49\u79bb\u5b50\u4f53\u52a0\u70ed\u7b49\u5e94\u7528\u5c55\u793a\u4e86\u4ee3\u7801\u7684\u591a\u529f\u80fd\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "MaxwellLink\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u5f15\u64ce\uff0c\u4e3a\u5149\u8c31\u5b66\u3001\u91cf\u5b50\u5149\u5b66\u3001\u7b49\u79bb\u5b50\u4f53\u5b66\u548c\u6781\u5316\u5b50\u5b66\u7b49\u7814\u7a76\u524d\u6cbf\u7684\u65b0\u5174\u73b0\u8c61\u63a2\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5e73\u53f0\u3002"}}
{"id": "2512.06055", "categories": ["gr-qc", "astro-ph.HE"], "pdf": "https://arxiv.org/pdf/2512.06055", "abs": "https://arxiv.org/abs/2512.06055", "authors": ["Martina Di Cesare", "Pia Astone", "Rosario De Rosa", "David Keitel", "Cristiano Palomba", "Marco Serra"], "title": "Investigating all-sky Frequency Hough performances for neutron stars", "comment": "24th International Conference on General Relativity and Gravitation (GR24) and 16th Edoardo Amaldi Conference on Gravitational Waves (Amaldi16)", "summary": "Between the estimated population of Neutron Stars (NSs) and the actual number present in the catalogs, there is a huge gap: O(10$^{8-9}$) vs O(10$^3$). Among the different search techniques for Continuous gravitational waves (CWs), the all-sky could help to reduce the discrepancy. We focus on the all-sky CW pipeline Frequency Hough (FH), which operates without prior knowledge of the source parameters ($f,\\dot{f}, \u03bb, \u03b2$). Here, we present a Machine Learning strategy, diverging from the standard follow-up(FU) of the FH pipeline. We study the performance with real interferometer data, until reaching $h$ value subthreshold for the standard FU procedure ($CR_{thr}=5$), with encouraging classification results.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5668\u5b66\u4e60\u7b56\u7565\uff0c\u7528\u4e8e\u6539\u8fdb\u9891\u7387\u970d\u592b\u53d8\u6362\u5168\u5929\u8fde\u7eed\u5f15\u529b\u6ce2\u641c\u7d22\u7ba1\u9053\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u540e\u7eed\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u5e72\u6d89\u4eea\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edf\u9608\u503c\u5206\u7c7b\u7684\u7075\u654f\u5ea6\u3002", "motivation": "\u4e2d\u5b50\u661f\u4f30\u8ba1\u6570\u91cf\uff0810^8-9\uff09\u4e0e\u5df2\u89c2\u6d4b\u6570\u91cf\uff0810^3\uff09\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\uff0c\u5168\u5929\u8fde\u7eed\u5f15\u529b\u6ce2\u641c\u7d22\u53ef\u80fd\u5e2e\u52a9\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002\u9891\u7387\u970d\u592b\u53d8\u6362\u7ba1\u9053\u867d\u7136\u6709\u6548\uff0c\u4f46\u5176\u4f20\u7edf\u540e\u7eed\u8ddf\u8e2a\u65b9\u6cd5\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u7075\u654f\u5ea6\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5668\u5b66\u4e60\u7b56\u7565\uff0c\u66ff\u4ee3\u9891\u7387\u970d\u592b\u53d8\u6362\u7ba1\u9053\u7684\u6807\u51c6\u540e\u7eed\u8ddf\u8e2a\u7a0b\u5e8f\u3002\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u5e72\u6d89\u4eea\u6570\u636e\u4e0a\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\uff0c\u80fd\u591f\u68c0\u6d4b\u5230\u4f4e\u4e8e\u4f20\u7edf\u540e\u7eed\u8ddf\u8e2a\u9608\u503c\uff08CR_thr=5\uff09\u7684\u4fe1\u53f7\u3002", "result": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u4ee4\u4eba\u9f13\u821e\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u80fd\u591f\u68c0\u6d4b\u5230\u4f4e\u4e8e\u4f20\u7edf\u540e\u7eed\u8ddf\u8e2a\u9608\u503c\u7684\u4fe1\u53f7\uff0c\u63d0\u9ad8\u4e86\u5168\u5929\u8fde\u7eed\u5f15\u529b\u6ce2\u641c\u7d22\u7684\u7075\u654f\u5ea6\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u7b56\u7565\u4e3a\u5168\u5929\u8fde\u7eed\u5f15\u529b\u6ce2\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u63d0\u9ad8\u4e2d\u5b50\u661f\u63a2\u6d4b\u6548\u7387\uff0c\u6709\u52a9\u4e8e\u7f29\u5c0f\u4e2d\u5b50\u661f\u4f30\u8ba1\u6570\u91cf\u4e0e\u5b9e\u9645\u89c2\u6d4b\u6570\u91cf\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002"}}
{"id": "2512.05990", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.05990", "abs": "https://arxiv.org/abs/2512.05990", "authors": ["Xin Li"], "title": "Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure", "comment": null, "summary": "Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \\textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \\textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \\textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \\textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \\textbf{Search $\\to$ Closure $\\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \\textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \\textit{Dynamic Programming} in P) via the mechanism of \\textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.", "AI": {"tldr": "\u63d0\u51faMAI\u6846\u67b6\uff0c\u7528\u4ee3\u6570\u62d3\u6251\u7edf\u4e00\u5b66\u4e60\u548c\u8bb0\u5fc6\uff0c\u901a\u8fc7\u540c\u8c03\u5947\u5076\u6027\u533a\u5206\u5185\u5bb9\u4e0e\u4e0a\u4e0b\u6587\uff0c\u5c06\u9ad8\u590d\u6742\u5ea6\u641c\u7d22\u8f6c\u5316\u4e3a\u4f4e\u590d\u6742\u5ea6\u67e5\u627e", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5c06\u53c2\u6570\u9759\u6001\u7ed3\u6784\u4e0e\u63a8\u7406\u52a8\u6001\u6d41\u7a0b\u5206\u79bb\uff0c\u7f3a\u4e4f\u751f\u7269\u8ba4\u77e5\u7684\u6837\u672c\u6548\u7387\u548c\u70ed\u529b\u5b66\u7ecf\u6d4e\u6027\uff0c\u9700\u8981\u7edf\u4e00\u7406\u8bba\u6846\u67b6", "method": "\u57fa\u4e8e\u4ee3\u6570\u62d3\u6251\u7684MAI\u6846\u67b6\uff0c\u63d0\u51fa\u540c\u8c03\u5947\u5076\u539f\u5219\uff1a\u5076\u7ef4\u540c\u8c03\u8868\u793a\u7a33\u5b9a\u5185\u5bb9\uff0c\u5947\u7ef4\u540c\u8c03\u8868\u793a\u52a8\u6001\u4e0a\u4e0b\u6587\u3002\u901a\u8fc7\u62d3\u6251\u4e09\u4f4d\u4e00\u4f53\u8f6c\u6362\uff08\u641c\u7d22\u2192\u95ed\u5408\u2192\u7ed3\u6784\uff09\u5b9e\u73b0\u8ba4\u77e5\u8fc7\u7a0b", "result": "\u5c06\u9ad8\u590d\u6742\u5ea6\u9012\u5f52\u641c\u7d22\uff08NPSPACE\uff09\u8f6c\u5316\u4e3a\u4f4e\u590d\u6742\u5ea6\u67e5\u627e\uff08P\uff09\uff0c\u901a\u8fc7\u62d3\u6251\u5faa\u73af\u95ed\u5408\u673a\u5236\uff0c\u7528\u62d3\u6251\u7248Wake-Sleep\u7b97\u6cd5\u534f\u8c03\u63a8\u7406\u4e0e\u5b66\u4e60", "conclusion": "MAI\u4e3a\u4ece\u6162\u601d\u8003\u5230\u5feb\u601d\u8003\u7684\u6d8c\u73b0\u63d0\u4f9b\u4e25\u683c\u89e3\u91ca\uff0c\u4e3a\u540e\u56fe\u7075\u67b6\u6784\u63d0\u4f9b\u84dd\u56fe\uff0c\u901a\u8fc7\u62d3\u6251\u5171\u632f\u8fdb\u884c\u8ba1\u7b97"}}
{"id": "2512.06117", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.06117", "abs": "https://arxiv.org/abs/2512.06117", "authors": ["Rohit Prasad", "Quirin Buchinger", "Fei Chi Kristy Yuen", "Yorick Reum", "Sven H\u00f6fling", "Tobias Huber-Loyola"], "title": "High-Performance Labyrinth Circular Bragg Grating Design for Charge and Stark-Tunable Quantum Light Sources Spanning Visible to Telecom Wavelengths", "comment": null, "summary": "Semiconductor quantum dots embedded in circular Bragg gratings (CBGs) are among the most efficient integrated single-photon sources. However, the fully etched rings of conventional CBGs restrict the implementation of charge and Stark tuning via electrical contacts. To overcome this limitation, a labyrinth CBG geometry with four bridges has been proposed, yet the added bridges significantly degraded optical performance. In this work, we numerically demonstrate that a periodic labyrinth CBG design preserves both high coupling efficiency and strong Purcell enhancement while enabling electrical integration if optimized after introducing the bridges. We show three optimized designs at emission wavelengths of 780 nm, 930 nm, and 1550 nm, because these wavelengths are among the most relevant for quantum dots and show the general applicability of our approach. At all three wavelengths collection efficiencies exceeding 90% into a numerical aperture of 0.7 and Purcell factors greater than 25 are achieved. Furthermore, we propose a device layout incorporating a barrier layer that separates p- and n-doped semiconductor regions, which is incorporated to prevent tunneling of one of the charge carriers for selective charging. Also this design can be reoptimized to retain the performance of a device without tunnel barrier. These results establish labyrinth CBGs as a platform for electrically tunable quantum dot single-photon sources with high efficiency and scalability.", "AI": {"tldr": "\u63d0\u51fa\u5468\u671f\u6027\u8ff7\u5bab\u5f0f\u5706\u5f62\u5e03\u62c9\u683c\u5149\u6805\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u9ad8\u5149\u5b66\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u7535\u5b66\u96c6\u6210\uff0c\u4e3a\u91cf\u5b50\u70b9\u5355\u5149\u5b50\u6e90\u63d0\u4f9b\u53ef\u7535\u8c03\u8c10\u5e73\u53f0\u3002", "motivation": "\u4f20\u7edf\u5706\u5f62\u5e03\u62c9\u683c\u5149\u6805\u7684\u5b8c\u5168\u8680\u523b\u73af\u9650\u5236\u4e86\u901a\u8fc7\u7535\u63a5\u89e6\u5b9e\u73b0\u7535\u8377\u548c\u65af\u5854\u514b\u8c03\u8c10\uff0c\u800c\u73b0\u6709\u7684\u8ff7\u5bab\u5f0f\u8bbe\u8ba1\u867d\u7136\u89e3\u51b3\u4e86\u7535\u96c6\u6210\u95ee\u9898\uff0c\u4f46\u4e25\u91cd\u964d\u4f4e\u4e86\u5149\u5b66\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5468\u671f\u6027\u8ff7\u5bab\u5f0f\u5706\u5f62\u5e03\u62c9\u683c\u5149\u6805\u8bbe\u8ba1\uff0c\u5728\u5f15\u5165\u7535\u8fde\u63a5\u6865\u540e\u91cd\u65b0\u4f18\u5316\u7ed3\u6784\uff0c\u5728780nm\u3001930nm\u548c1550nm\u4e09\u4e2a\u6ce2\u957f\u4e0b\u8fdb\u884c\u6570\u503c\u6a21\u62df\uff0c\u5e76\u8bbe\u8ba1\u5305\u542b\u52bf\u5792\u5c42\u7684\u5668\u4ef6\u5e03\u5c40\u4ee5\u5b9e\u73b0\u9009\u62e9\u6027\u5145\u7535\u3002", "result": "\u5728\u6240\u6709\u4e09\u4e2a\u6ce2\u957f\u4e0b\u5b9e\u73b0\u4e86\u8d85\u8fc790%\u7684\u6536\u96c6\u6548\u7387\uff08\u6570\u503c\u5b54\u5f840.7\uff09\u548c\u5927\u4e8e25\u7684\u73c0\u585e\u5c14\u56e0\u5b50\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u5149\u5b66\u6027\u80fd\u5e76\u5b9e\u73b0\u4e86\u7535\u5b66\u96c6\u6210\u80fd\u529b\u3002", "conclusion": "\u8ff7\u5bab\u5f0f\u5706\u5f62\u5e03\u62c9\u683c\u5149\u6805\u4e3a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u7535\u53ef\u8c03\u8c10\u91cf\u5b50\u70b9\u5355\u5149\u5b50\u6e90\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u5e73\u53f0\u3002"}}
{"id": "2512.07458", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07458", "abs": "https://arxiv.org/abs/2512.07458", "authors": ["Dmitrii Kapitan", "Pavel Ovchinnikov", "Konstantin Soldatov", "Petr Andriushchenko", "Vitalii Kapitan"], "title": "Optimized Machine Learning Methods for Studying the Thermodynamic Behavior of Complex Spin Systems", "comment": "16 pages, in Russian language, 8 figures, 2 tables", "summary": "This paper presents a systematic study of the application of convolutional neural networks (CNNs) as an efficient and versatile tool for the analysis of critical and low-temperature phase states in spin system models. The problem of calculating the dependence of the average energy on the spatial distribution of exchange integrals for the Edwards-Anderson model on a square lattice with frustrated interactions is considered. We further construct a single convolutional classifier of phase states of the ferromagnetic Ising model on square, triangular, honeycomb, and kagome lattices, trained on configurations generated by the Swendsen-Wang cluster algorithm. Computed temperature profiles of the averaged posterior probability of the high-temperature phase form clear S-shaped curves that intersect in the vicinity of the theoretical critical temperatures and allow one to determine the critical temperature for the kagome lattice without additional retraining. It is shown that convolutional models substantially reduce the root-mean-square error (RMSE) compared with fully connected architectures and efficiently capture complex correlations between thermodynamic characteristics and the structure of magnetic correlated systems.", "AI": {"tldr": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5206\u6790\u81ea\u65cb\u7cfb\u7edf\u7684\u4e34\u754c\u548c\u4f4e\u6e29\u76f8\u6001\uff0c\u6784\u5efa\u4e86\u9002\u7528\u4e8e\u591a\u79cd\u6676\u683c\u7684\u76f8\u6001\u5206\u7c7b\u5668\uff0c\u80fd\u51c6\u786e\u786e\u5b9a\u4e34\u754c\u6e29\u5ea6\u5e76\u964d\u4f4e\u8bef\u5dee\u3002", "motivation": "\u7814\u7a76\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u9ad8\u6548\u901a\u7528\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u81ea\u65cb\u7cfb\u7edf\u6a21\u578b\u7684\u4e34\u754c\u548c\u4f4e\u6e29\u76f8\u6001\uff0c\u7279\u522b\u662f\u8ba1\u7b97\u80fd\u91cf\u5bf9\u4ea4\u6362\u79ef\u5206\u7a7a\u95f4\u5206\u5e03\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u6784\u5efa\u9002\u7528\u4e8e\u4e0d\u540c\u6676\u683c\u7684\u76f8\u6001\u5206\u7c7b\u5668\u3002", "method": "\u9488\u5bf9Edwards-Anderson\u6a21\u578b\u8ba1\u7b97\u5e73\u5747\u80fd\u91cf\u5bf9\u4ea4\u6362\u79ef\u5206\u7a7a\u95f4\u5206\u5e03\u7684\u4f9d\u8d56\uff1b\u4f7f\u7528Swendsen-Wang\u56e2\u7c07\u7b97\u6cd5\u751f\u6210\u914d\u7f6e\uff0c\u8bad\u7ec3\u5355\u4e2a\u5377\u79ef\u5206\u7c7b\u5668\u6765\u5206\u6790\u65b9\u5f62\u3001\u4e09\u89d2\u5f62\u3001\u8702\u7a9d\u548ckagome\u6676\u683c\u7684\u94c1\u78c1Ising\u6a21\u578b\u76f8\u6001\u3002", "result": "\u9ad8\u6e29\u76f8\u5e73\u5747\u540e\u9a8c\u6982\u7387\u7684\u6e29\u5ea6\u5206\u5e03\u5f62\u6210\u6e05\u6670\u7684S\u5f62\u66f2\u7ebf\uff0c\u5728\u7406\u8bba\u4e34\u754c\u6e29\u5ea6\u9644\u8fd1\u76f8\u4ea4\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u786e\u5b9akagome\u6676\u683c\u7684\u4e34\u754c\u6e29\u5ea6\uff1b\u5377\u79ef\u6a21\u578b\u76f8\u6bd4\u5168\u8fde\u63a5\u67b6\u6784\u663e\u8457\u964d\u4f4e\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u80fd\u6709\u6548\u6355\u6349\u70ed\u529b\u5b66\u7279\u6027\u4e0e\u78c1\u5173\u8054\u7cfb\u7edf\u7ed3\u6784\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u5173\u6027\u3002", "conclusion": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f\u5206\u6790\u81ea\u65cb\u7cfb\u7edf\u76f8\u6001\u7684\u9ad8\u6548\u901a\u7528\u5de5\u5177\uff0c\u80fd\u591f\u51c6\u786e\u786e\u5b9a\u4e34\u754c\u6e29\u5ea6\uff0c\u6355\u6349\u590d\u6742\u76f8\u5173\u6027\uff0c\u5e76\u5728\u591a\u79cd\u6676\u683c\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.06082", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06082", "abs": "https://arxiv.org/abs/2512.06082", "authors": ["Valerio De Luca", "Brandon Khek", "Justin Khoury", "Mark Trodden"], "title": "Hidden symmetries for tidal Love numbers: generalities and applications to analogue black holes", "comment": "19 pages, 1 figure", "summary": "Tidal Love numbers characterize the conservative, static response of compact objects to external tidal fields. Remarkably, these quantities vanish identically for asymptotically flat black holes in four-dimensional General Relativity. This behavior has been attributed to hidden symmetries -- both geometric and algebraic -- governing perturbations in these space-times. Interestingly, a similar vanishing of selected multipolar Love numbers arises in the context of supersonic acoustic flows. These systems share several key features with black holes in General Relativity, such as the presence of an effective acoustic horizon and a wave equation describing linear excitations. In this work, we explore a symmetry-based connection between the two frameworks and demonstrate that the ladder symmetries observed in acoustic black holes can be traced to structural properties of the underlying wave equation, mirroring those found in general relativistic black hole space-times.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9ed1\u6d1e\u4e0e\u58f0\u5b66\u9ed1\u6d1e\u4e2d\u6f6e\u6c50Love\u6570\u7684\u6d88\u5931\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u8fd9\u4e24\u79cd\u7cfb\u7edf\u4e2d\u9690\u85cf\u7684\u5bf9\u79f0\u6027\u8054\u7cfb\u3002", "motivation": "\u7814\u7a76\u9ed1\u6d1e\u6f6e\u6c50Love\u6570\u5728\u56db\u7ef4\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u6d88\u5931\u7684\u73b0\u8c61\uff0c\u4ee5\u53ca\u7c7b\u4f3c\u73b0\u8c61\u5728\u8d85\u97f3\u901f\u58f0\u5b66\u6d41\u4e2d\u7684\u51fa\u73b0\uff0c\u65e8\u5728\u63a2\u7d22\u8fd9\u4e24\u79cd\u770b\u4f3c\u4e0d\u540c\u7269\u7406\u7cfb\u7edf\u80cc\u540e\u7684\u5171\u540c\u5bf9\u79f0\u6027\u539f\u7406\u3002", "method": "\u901a\u8fc7\u5206\u6790\u58f0\u5b66\u9ed1\u6d1e\u4e2d\u7684\u9636\u68af\u5bf9\u79f0\u6027\uff0c\u5e76\u5c06\u5176\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u9ed1\u6d1e\u65f6\u7a7a\u4e2d\u7684\u7ed3\u6784\u7279\u6027\u8fdb\u884c\u6bd4\u8f83\uff0c\u5efa\u7acb\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u7406\u8bba\u6846\u67b6\u8fde\u63a5\u3002", "result": "\u8bc1\u660e\u4e86\u58f0\u5b66\u9ed1\u6d1e\u4e2d\u89c2\u5bdf\u5230\u7684\u9636\u68af\u5bf9\u79f0\u6027\u53ef\u4ee5\u8ffd\u6eaf\u5230\u57fa\u7840\u6ce2\u52a8\u65b9\u7a0b\u7684\u7ed3\u6784\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u9ed1\u6d1e\u65f6\u7a7a\u4e2d\u7684\u7279\u6027\u76f8\u4f3c\u3002", "conclusion": "\u9ed1\u6d1e\u548c\u58f0\u5b66\u9ed1\u6d1e\u4e2d\u6f6e\u6c50Love\u6570\u7684\u6d88\u5931\u73b0\u8c61\u5171\u4eab\u5171\u540c\u7684\u5bf9\u79f0\u6027\u8d77\u6e90\uff0c\u8fd9\u4e3a\u7406\u89e3\u4e0d\u540c\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u9690\u85cf\u5bf9\u79f0\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2512.06059", "categories": ["cs.LG", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.06059", "abs": "https://arxiv.org/abs/2512.06059", "authors": ["Andrea Della Valle", "Annalisa D'Arco", "Tiziana Mancini", "Rosanna Mosetti", "Maria Chiara Paolozzi", "Stefano Lupi", "Sebastiano Pilati", "Andrea Perali"], "title": "Deep learning recognition and analysis of Volatile Organic Compounds based on experimental and synthetic infrared absorption spectra", "comment": null, "summary": "Volatile Organic Compounds (VOCs) are organic molecules that have low boiling points and therefore easily evaporate into the air. They pose significant risks to human health, making their accurate detection the crux of efforts to monitor and minimize exposure. Infrared (IR) spectroscopy enables the ultrasensitive detection at low-concentrations of VOCs in the atmosphere by measuring their IR absorption spectra. However, the complexity of the IR spectra limits the possibility to implement VOC recognition and quantification in real-time. While deep neural networks (NNs) are increasingly used for the recognition of complex data structures, they typically require massive datasets for the training phase. Here, we create an experimental VOC dataset for nine different classes of compounds at various concentrations, using their IR absorption spectra. To further increase the amount of spectra and their diversity in term of VOC concentration, we augment the experimental dataset with synthetic spectra created via conditional generative NNs. This allows us to train robust discriminative NNs, able to reliably identify the nine VOCs, as well as to precisely predict their concentrations. The trained NN is suitable to be incorporated into sensing devices for VOCs recognition and analysis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea2\u5916\u5149\u8c31\u548c\u795e\u7ecf\u7f51\u7edc\u7684VOC\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6570\u636e\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u4e86\u80fd\u591f\u53ef\u9760\u8bc6\u522b9\u79cdVOC\u5e76\u9884\u6d4b\u5176\u6d53\u5ea6\u7684\u5224\u522b\u6027\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u6325\u53d1\u6027\u6709\u673a\u5316\u5408\u7269(VOCs)\u5bf9\u5065\u5eb7\u6784\u6210\u91cd\u5927\u98ce\u9669\uff0c\u9700\u8981\u51c6\u786e\u68c0\u6d4b\u3002\u867d\u7136\u7ea2\u5916\u5149\u8c31\u80fd\u591f\u5b9e\u73b0\u8d85\u7075\u654f\u68c0\u6d4b\uff0c\u4f46\u590d\u6742\u7684\u5149\u8c31\u9650\u5236\u4e86\u5b9e\u65f6\u8bc6\u522b\u548c\u5b9a\u91cf\u5206\u6790\u7684\u53ef\u80fd\u6027\u3002\u6df1\u5ea6\u5b66\u4e60\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u5b9e\u9a8c\u6570\u636e\u6709\u9650\u3002", "method": "\u521b\u5efa\u4e869\u79cd\u4e0d\u540c\u7c7b\u522b\u5316\u5408\u7269\u7684\u5b9e\u9a8cVOC\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u5176\u7ea2\u5916\u5438\u6536\u5149\u8c31\u3002\u901a\u8fc7\u6761\u4ef6\u751f\u6210\u795e\u7ecf\u7f51\u7edc\u521b\u5efa\u5408\u6210\u5149\u8c31\u6765\u589e\u5f3a\u6570\u636e\u96c6\uff0c\u589e\u52a0\u5149\u8c31\u6570\u91cf\u548c\u6d53\u5ea6\u591a\u6837\u6027\u3002\u7136\u540e\u8bad\u7ec3\u5224\u522b\u6027\u795e\u7ecf\u7f51\u7edc\u8fdb\u884cVOC\u8bc6\u522b\u548c\u6d53\u5ea6\u9884\u6d4b\u3002", "result": "\u8bad\u7ec3\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u53ef\u9760\u8bc6\u522b9\u79cdVOC\uff0c\u5e76\u7cbe\u786e\u9884\u6d4b\u5176\u6d53\u5ea6\u3002\u8be5\u7f51\u7edc\u9002\u5408\u96c6\u6210\u5230VOC\u8bc6\u522b\u548c\u5206\u6790\u7684\u4f20\u611f\u8bbe\u5907\u4e2d\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5b9e\u9a8c\u6570\u636e\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u7684\u6570\u636e\u96c6\uff0c\u6210\u529f\u5f00\u53d1\u4e86\u80fd\u591f\u5b9e\u73b0VOC\u5b9e\u65f6\u8bc6\u522b\u548c\u5b9a\u91cf\u5206\u6790\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u4e3a\u73af\u5883\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2512.06157", "categories": ["quant-ph", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.06157", "abs": "https://arxiv.org/abs/2512.06157", "authors": ["Nour Dehaini", "Christia Chahoud", "Mahdi Chehimi"], "title": "Deadline-Aware Scheduling of Distributed Quantum Circuits in Near-Term Quantum Cloud", "comment": "8 pages, 5 figures, conference", "summary": "Distributed quantum computing (DQC) enables scalable quantum computations by distributing large quantum circuits on multiple quantum processing units (QPUs) in the quantum cloud. In DQC, after partitioning quantum circuits, they must be scheduled and executed on heterogenous QPUs while balancing latency, overhead, QPU communication resource limits. However, since fully functioning quantum communication networks have not been realized yet, near-term quantum clouds will only rely on local operations and classical communication settings between QPUs, without entangled quantum links. Additionally, existing DQC scheduling frameworks do not account for user-defined execution deadlines and adopt inefficient wire cutting techniques. Accordingly, in this work, a deadline aware DQC scheduling framework with efficient wire cutting for near-term quantum cloud is proposed. The proposed framework schedules partitioned quantum subcircuits while accounting for circuit deadlines and QPU capacity limits. It also captures dependencies between partitioned subcircuits and distributes the execution of the sampling shots on different QPUs to have efficient wire cutting and faster execution. In this regard, a deadline-aware circuit scheduling optimization problem is formulated, and solved using simulated annealing. Simulation results show a marked improvement over existing shot-agnostic frameworks under urgent deadlines, reaching a 12.8% increase in requests served before their deadlines. Additionally, the proposed framework serves 8.16% more requests, on average, compared to state-of-the-art dependency-agnostic baseline frameworks, and by 9.60% versus the dependency-and-shot-agnostic baseline, all while achieving a smaller makespan of the DQC execution. Moreover, the proposed framework serves 23.7%, 24.5%, and 25.38% more requests compared to greedy, list scheduling, and random schedulers, respectively.", "AI": {"tldr": "\u63d0\u51fa\u9762\u5411\u8fd1\u91cf\u5b50\u4e91\u7684\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u8c03\u5ea6\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u6548\u7ebf\u5207\u5272\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u622a\u6b62\u65f6\u95f4\u524d\u8bf7\u6c42\u670d\u52a1\u7387", "motivation": "\u5f53\u524d\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u8c03\u5ea6\u6846\u67b6\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u672a\u8003\u8651\u7528\u6237\u5b9a\u4e49\u7684\u6267\u884c\u622a\u6b62\u65f6\u95f4\uff1b2) \u91c7\u7528\u4f4e\u6548\u7684\u7ebf\u5207\u5272\u6280\u672f\uff1b3) \u8fd1\u91cf\u5b50\u4e91\u7f3a\u4e4f\u91cf\u5b50\u901a\u4fe1\u7f51\u7edc\uff0c\u53ea\u80fd\u4f9d\u8d56\u7ecf\u5178\u901a\u4fe1", "method": "\u63d0\u51fa\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u7684DQC\u8c03\u5ea6\u6846\u67b6\uff0c\u8003\u8651\u7535\u8def\u622a\u6b62\u65f6\u95f4\u548cQPU\u5bb9\u91cf\u9650\u5236\uff0c\u6355\u83b7\u5206\u533a\u5b50\u7535\u8def\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u4e0d\u540cQPU\u4e0a\u5206\u5e03\u91c7\u6837\u6267\u884c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7ebf\u5207\u5272\u548c\u5feb\u901f\u6267\u884c\u3002\u4f7f\u7528\u6a21\u62df\u9000\u706b\u7b97\u6cd5\u89e3\u51b3\u8c03\u5ea6\u4f18\u5316\u95ee\u9898", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\uff1a\u7d27\u6025\u622a\u6b62\u65f6\u95f4\u4e0b\u8bf7\u6c42\u670d\u52a1\u7387\u63d0\u9ad812.8%\uff1b\u5e73\u5747\u670d\u52a1\u8bf7\u6c42\u6570\u6bd4\u4f9d\u8d56\u611f\u77e5\u57fa\u7ebf\u9ad88.16%\uff0c\u6bd4\u4f9d\u8d56\u548c\u91c7\u6837\u611f\u77e5\u57fa\u7ebf\u9ad89.60%\uff1b\u6267\u884c\u65f6\u95f4\u66f4\u77ed\uff1b\u6bd4\u8d2a\u5fc3\u3001\u5217\u8868\u8c03\u5ea6\u548c\u968f\u673a\u8c03\u5ea6\u5206\u522b\u591a\u670d\u52a123.7%\u300124.5%\u548c25.38%\u7684\u8bf7\u6c42", "conclusion": "\u8be5\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u8c03\u5ea6\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u8fd1\u91cf\u5b50\u4e91\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u8c03\u5ea6\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u548c\u8bf7\u6c42\u670d\u52a1\u80fd\u529b"}}
{"id": "2512.07693", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.07693", "abs": "https://arxiv.org/abs/2512.07693", "authors": ["David Immel", "Ralf Drautz", "Godehard Sutmann"], "title": "Conservative adaptive-precision interatomic potentials", "comment": "8 pages, 5 figures, supplemental material attached", "summary": "Adaptive precision molecular dynamics simulations have developed along energy- and force-coupling approaches, which allow for a continuous transition between different particle descriptions or interaction potentials. Most approaches consider different (fixed) spatial regions, which control the transition between the descriptions and consequently avoid a consistent momentum-conserving Hamiltonian description. We present here a new approach to fully integrate the coupling into a Hamiltonian, therefore allowing for a conservative description, which, by design, guarantees both energy and momentum conservation. By coupling a fast EAM potential to a highly accurate ACE potential, we verify numerically the conservation properties and show that one can achieve - dependent on both the potential and the atomistic system - a speedup of one or two orders of magnitude compared to a pure ACE simulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u7cbe\u5ea6\u5206\u5b50\u52a8\u529b\u5b66\u65b9\u6cd5\uff0c\u901a\u8fc7\u54c8\u5bc6\u987f\u91cf\u63cf\u8ff0\u5b9e\u73b0\u80fd\u91cf\u548c\u52a8\u91cf\u5b88\u6052\uff0c\u76f8\u6bd4\u7eafACE\u6a21\u62df\u53ef\u83b7\u5f971-2\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u9002\u5e94\u7cbe\u5ea6\u5206\u5b50\u52a8\u529b\u5b66\u65b9\u6cd5\u5927\u591a\u57fa\u4e8e\u56fa\u5b9a\u7a7a\u95f4\u533a\u57df\uff0c\u65e0\u6cd5\u5b9e\u73b0\u4e00\u81f4\u7684\u52a8\u91cf\u5b88\u6052\u54c8\u5bc6\u987f\u63cf\u8ff0\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4fdd\u8bc1\u80fd\u91cf\u548c\u52a8\u91cf\u5b88\u6052\u7684\u4fdd\u5b88\u63cf\u8ff0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u54c8\u5bc6\u987f\u91cf\u8026\u5408\u65b9\u6cd5\uff0c\u5c06\u8026\u5408\u5b8c\u5168\u6574\u5408\u5230\u54c8\u5bc6\u987f\u91cf\u4e2d\uff0c\u5b9e\u73b0\u4fdd\u5b88\u63cf\u8ff0\u3002\u901a\u8fc7\u5c06\u5feb\u901fEAM\u52bf\u4e0e\u9ad8\u7cbe\u5ea6ACE\u52bf\u8026\u5408\u6765\u9a8c\u8bc1\u3002", "result": "\u6570\u503c\u9a8c\u8bc1\u4e86\u5b88\u6052\u7279\u6027\uff0c\u6839\u636e\u52bf\u51fd\u6570\u548c\u539f\u5b50\u7cfb\u7edf\u7684\u4e0d\u540c\uff0c\u76f8\u6bd4\u7eafACE\u6a21\u62df\u53ef\u83b7\u5f971-2\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u80fd\u91cf\u548c\u52a8\u91cf\u5b88\u6052\u7684\u81ea\u9002\u5e94\u7cbe\u5ea6\u5206\u5b50\u52a8\u529b\u5b66\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u591a\u5c3a\u5ea6\u6a21\u62df\u63d0\u4f9b\u4e86\u65b0\u7684\u4fdd\u5b88\u8026\u5408\u6846\u67b6\u3002"}}
{"id": "2512.06279", "categories": ["gr-qc", "astro-ph.CO", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06279", "abs": "https://arxiv.org/abs/2512.06279", "authors": ["Shin'ichi Nojiri", "Sergei D. Odintsov", "V. K Oikonomou"], "title": "Apparent Phantom Crossing in Gauss-Bonnet Gravity", "comment": "LaTeX 15 pages", "summary": "The recent observations of the Dark Energy Spectroscopic Instrument (DESI) indicated the possibility that the dark energy equation of state parameter $w$ might change from $w<-1$ to $w>-1$ when the redshift $z\\sim 0.5$, which is called the inverse phantom crossing. In this paper, we investigate the possibility of the phantom crossing, and we construct realistic models realizing the crossing in the framework of the scalar--Einstein--Gauss-Bonnet gravity and ghost-free $f(\\mathcal{G})$ gravity. We also investigate the scenario of the apparent phantom crossing, where dark matter energy density decreases more slowly than usually expected, which might explain the DESI observations. In the scenarios developed, the energy conditions are not violated by any component of the cosmic fluid. In the framework of the apparent phantom crossing, we also propose a new scenario, where the particle corresponding to the scalar field in the scalar--Einstein--Gauss-Bonnet gravity is dark matter. The mass of the particle might increase due to the coupling with the Gauss-Bonnet invariant, which makes the decrease of the dark matter energy density slower. This last scenario may suggest that the inverse phantom crossing might be related to the transition from the decelerating expansion of the Universe to the accelerating expansion.", "AI": {"tldr": "DESI\u89c2\u6d4b\u6697\u793a\u6697\u80fd\u91cf\u72b6\u6001\u53c2\u6570w\u53ef\u80fd\u4ecew<-1\u53d8\u4e3aw>-1\uff08\u9006\u5e7b\u5f71\u7a7f\u8d8a\uff09\uff0c\u672c\u6587\u5728\u6807\u91cf-\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u6846\u67b6\u4e0b\u6784\u5efa\u5b9e\u73b0\u8be5\u7a7f\u8d8a\u7684\u6a21\u578b\uff0c\u5e76\u7814\u7a76\u8868\u89c2\u5e7b\u5f71\u7a7f\u8d8a\u573a\u666f\uff0c\u5176\u4e2d\u6697\u7269\u8d28\u80fd\u91cf\u5bc6\u5ea6\u4e0b\u964d\u66f4\u6162\uff0c\u53ef\u80fd\u89e3\u91caDESI\u89c2\u6d4b\u3002", "motivation": "DESI\u89c2\u6d4b\u6570\u636e\u663e\u793a\u6697\u80fd\u91cf\u72b6\u6001\u53c2\u6570w\u53ef\u80fd\u5728\u7ea2\u79fbz~0.5\u65f6\u4ecew<-1\u53d8\u4e3aw>-1\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u9006\u5e7b\u5f71\u7a7f\u8d8a\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u79cd\u7a7f\u8d8a\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u6784\u5efa\u80fd\u591f\u5b9e\u73b0\u8be5\u73b0\u8c61\u7684\u7269\u7406\u6a21\u578b\u3002", "method": "\u5728\u6807\u91cf-\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u548c\u65e0\u9b3cf(\ud835\udca2)\u5f15\u529b\u6846\u67b6\u4e0b\u6784\u5efa\u5b9e\u73b0\u5e7b\u5f71\u7a7f\u8d8a\u7684\u73b0\u5b9e\u6a21\u578b\u3002\u540c\u65f6\u7814\u7a76\u8868\u89c2\u5e7b\u5f71\u7a7f\u8d8a\u573a\u666f\uff0c\u5176\u4e2d\u6697\u7269\u8d28\u80fd\u91cf\u5bc6\u5ea6\u4e0b\u964d\u6bd4\u901a\u5e38\u9884\u671f\u66f4\u6162\u3002\u8fd8\u63d0\u51fa\u65b0\u573a\u666f\uff1a\u6807\u91cf\u573a\u5bf9\u5e94\u7c92\u5b50\u4f5c\u4e3a\u6697\u7269\u8d28\uff0c\u5176\u8d28\u91cf\u56e0\u4e0e\u9ad8\u65af-\u535a\u5185\u4e0d\u53d8\u91cf\u8026\u5408\u800c\u589e\u52a0\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5b9e\u73b0\u5e7b\u5f71\u7a7f\u8d8a\u7684\u6a21\u578b\uff0c\u5728\u8868\u89c2\u5e7b\u5f71\u7a7f\u8d8a\u573a\u666f\u4e2d\uff0c\u5b87\u5b99\u6d41\u4f53\u7684\u4efb\u4f55\u5206\u91cf\u90fd\u4e0d\u8fdd\u53cd\u80fd\u91cf\u6761\u4ef6\u3002\u65b0\u63d0\u51fa\u7684\u573a\u666f\u4e2d\uff0c\u6807\u91cf\u573a\u7c92\u5b50\u4f5c\u4e3a\u6697\u7269\u8d28\uff0c\u5176\u8d28\u91cf\u589e\u52a0\u4f7f\u6697\u7269\u8d28\u80fd\u91cf\u5bc6\u5ea6\u4e0b\u964d\u53d8\u6162\uff0c\u8fd9\u53ef\u80fd\u5c06\u9006\u5e7b\u5f71\u7a7f\u8d8a\u4e0e\u5b87\u5b99\u4ece\u51cf\u901f\u81a8\u80c0\u5230\u52a0\u901f\u81a8\u80c0\u7684\u8f6c\u53d8\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "DESI\u89c2\u6d4b\u5230\u7684\u9006\u5e7b\u5f71\u7a7f\u8d8a\u73b0\u8c61\u53ef\u4ee5\u5728\u6807\u91cf-\u7231\u56e0\u65af\u5766-\u9ad8\u65af-\u535a\u5185\u5f15\u529b\u6846\u67b6\u4e0b\u5b9e\u73b0\u3002\u8868\u89c2\u5e7b\u5f71\u7a7f\u8d8a\u573a\u666f\u63d0\u4f9b\u4e86\u89e3\u91caDESI\u6570\u636e\u7684\u53ef\u80fd\u673a\u5236\uff0c\u5176\u4e2d\u6697\u7269\u8d28\u80fd\u91cf\u5bc6\u5ea6\u4e0b\u964d\u53d8\u6162\u662f\u5173\u952e\u3002\u65b0\u63d0\u51fa\u7684\u6697\u7269\u8d28-\u6807\u91cf\u573a\u7edf\u4e00\u6a21\u578b\u5c06\u5e7b\u5f71\u7a7f\u8d8a\u4e0e\u5b87\u5b99\u81a8\u80c0\u76f8\u53d8\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7406\u89e3\u6697\u80fd\u91cf\u548c\u6697\u7269\u8d28\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.06062", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06062", "abs": "https://arxiv.org/abs/2512.06062", "authors": ["S. M. Mustaqim", "Anantaa Kotal", "Paul H. Yi"], "title": "When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models", "comment": null, "summary": "Generative models are increasingly used to produce privacy-preserving synthetic data as a safe alternative to sharing sensitive training datasets. However, we demonstrate that such synthetic releases can still leak information about the underlying training samples through structural overlap in the data manifold. We propose a black-box membership inference attack that exploits this vulnerability without requiring access to model internals or real data. The attacker repeatedly queries the generative model to obtain large numbers of synthetic samples, performs unsupervised clustering to identify dense regions of the synthetic distribution, and then analyzes cluster medoids and neighborhoods that correspond to high-density regions in the original training data. These neighborhoods act as proxies for training samples, enabling the adversary to infer membership or reconstruct approximate records. Our experiments across healthcare, finance, and other sensitive domains show that cluster overlap between real and synthetic data leads to measurable membership leakage-even when the generator is trained with differential privacy or other noise mechanisms. The results highlight an under-explored attack surface in synthetic data generation pipelines and call for stronger privacy guarantees that account for distributional neighborhood inference rather than sample-level memorization alone, underscoring its role in privacy-preserving data publishing. Implementation and evaluation code are publicly available at:github.com/Cluster-Medoid-Leakage-Attack.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u4e2d\u4f4d\u6570\u548c\u90bb\u57df\u5206\u6790\u7684\u9ed1\u76d2\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u5229\u7528\u751f\u6210\u6a21\u578b\u5408\u6210\u6570\u636e\u4e0e\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u5728\u6d41\u5f62\u7ed3\u6784\u4e0a\u7684\u91cd\u53e0\u6765\u63a8\u65ad\u6210\u5458\u4fe1\u606f\uff0c\u5373\u4f7f\u5728\u5dee\u5206\u9690\u79c1\u7b49\u566a\u58f0\u673a\u5236\u4e0b\u4ecd\u5b58\u5728\u53ef\u6d4b\u91cf\u7684\u9690\u79c1\u6cc4\u9732\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u88ab\u5e7f\u6cdb\u7528\u4e8e\u751f\u6210\u9690\u79c1\u4fdd\u62a4\u7684\u5408\u6210\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6837\u672c\u7ea7\u522b\u7684\u8bb0\u5fc6\u5316\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u6d41\u5f62\u7ed3\u6784\u91cd\u53e0\u53ef\u80fd\u5bfc\u81f4\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u9ed1\u76d2\u6210\u5458\u63a8\u7406\u653b\u51fb\uff1a1) \u91cd\u590d\u67e5\u8be2\u751f\u6210\u6a21\u578b\u83b7\u53d6\u5927\u91cf\u5408\u6210\u6837\u672c\uff1b2) \u65e0\u76d1\u7763\u805a\u7c7b\u8bc6\u522b\u5408\u6210\u5206\u5e03\u4e2d\u7684\u5bc6\u96c6\u533a\u57df\uff1b3) \u5206\u6790\u805a\u7c7b\u4e2d\u4f4d\u6570\u548c\u90bb\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u5bf9\u5e94\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u7684\u9ad8\u5bc6\u5ea6\u533a\u57df\uff1b4) \u5229\u7528\u8fd9\u4e9b\u90bb\u57df\u4f5c\u4e3a\u8bad\u7ec3\u6837\u672c\u7684\u4ee3\u7406\u6765\u63a8\u65ad\u6210\u5458\u4fe1\u606f\u6216\u91cd\u5efa\u8fd1\u4f3c\u8bb0\u5f55\u3002", "result": "\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u654f\u611f\u9886\u57df\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u751f\u6210\u5668\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u6216\u5176\u4ed6\u566a\u58f0\u673a\u5236\u8bad\u7ec3\uff0c\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u4e4b\u95f4\u7684\u805a\u7c7b\u91cd\u53e0\u4ecd\u4f1a\u5bfc\u81f4\u53ef\u6d4b\u91cf\u7684\u6210\u5458\u4fe1\u606f\u6cc4\u9732\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u751f\u6210\u7ba1\u9053\u5b58\u5728\u672a\u5145\u5206\u63a2\u7d22\u7684\u653b\u51fb\u9762\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u8bc1\u673a\u5236\uff0c\u4e0d\u4ec5\u8981\u8003\u8651\u6837\u672c\u7ea7\u522b\u7684\u8bb0\u5fc6\u5316\uff0c\u8fd8\u8981\u8003\u8651\u5206\u5e03\u90bb\u57df\u63a8\u7406\u95ee\u9898\uff0c\u8fd9\u5bf9\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u53d1\u5e03\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.06170", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06170", "abs": "https://arxiv.org/abs/2512.06170", "authors": ["Haoqing Zhang", "Anjun Chu", "Chengyi Luo", "Chitose Maruko", "Eliot A. Bohr", "James K. Thompson", "Ana Maria Rey"], "title": "Collective three-body interactions enable a robust quantum speedup", "comment": "8+8 pages, 7+5 figures", "summary": "We show that collective three-body interactions (3BIs), implementable with $N$ atoms loaded inside an optical cavity, offer a significant advantage for preparing complex multipartite entangled states. Firstly, they enable a speedup of order $\\sim N$ in preparing generalized Greenberger-Horne-Zeilinger (GHZ) states, outperforming conventional methods based on all-to-all two-body Ising interactions. Secondly, they saturate the Heisenberg bound in phase estimation tasks using a time-reversal protocol realized through simple rotations and followed by experimentally accessible collective spin measurements. Lastly, compared with two-body interactions (2BIs), in the presence of cavity losses and single particle decoherence, 3BIs feature a high gain in sensitivity for moderate atom numbers and in large ensembles a fast entanglement generation despite constraints in parameter regimes where they are implementable.", "AI": {"tldr": "\u4e09\u4f53\u76f8\u4e92\u4f5c\u7528\u76f8\u6bd4\u4f20\u7edf\u4e8c\u4f53\u76f8\u4e92\u4f5c\u7528\u5728\u5236\u5907\u591a\u4f53\u7ea0\u7f20\u6001\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5305\u62ecN\u500d\u52a0\u901f\u5236\u5907GHZ\u6001\u3001\u8fbe\u5230\u6d77\u68ee\u5821\u6781\u9650\u7684\u76f8\u4f4d\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u4ee5\u53ca\u5728\u8154\u635f\u8017\u548c\u9000\u76f8\u5e72\u73af\u5883\u4e0b\u66f4\u597d\u7684\u7075\u654f\u5ea6\u589e\u76ca\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5168\u5bf9\u5168\u4e8c\u4f53\u4f0a\u8f9b\u76f8\u4e92\u4f5c\u7528\u7684\u65b9\u6cd5\u5728\u5236\u5907\u590d\u6742\u591a\u4f53\u7ea0\u7f20\u6001\u65b9\u9762\u5b58\u5728\u6548\u7387\u9650\u5236\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u76f8\u4e92\u4f5c\u7528\u673a\u5236\u6765\u52a0\u901f\u7ea0\u7f20\u5236\u5907\u5e76\u63d0\u5347\u91cf\u5b50\u4f20\u611f\u6027\u80fd\u3002", "method": "\u5229\u7528\u5149\u5b66\u8154\u4e2d\u88c5\u8f7d\u7684N\u4e2a\u539f\u5b50\u5b9e\u73b0\u96c6\u4f53\u4e09\u4f53\u76f8\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u65f6\u95f4\u53cd\u8f6c\u534f\u8bae\uff08\u5305\u542b\u7b80\u5355\u65cb\u8f6c\u548c\u96c6\u4f53\u81ea\u65cb\u6d4b\u91cf\uff09\u8fdb\u884c\u76f8\u4f4d\u4f30\u8ba1\uff0c\u5e76\u4e0e\u4e8c\u4f53\u76f8\u4e92\u4f5c\u7528\u5728\u8154\u635f\u8017\u548c\u5355\u7c92\u5b50\u9000\u76f8\u5e72\u6761\u4ef6\u4e0b\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u4e09\u4f53\u76f8\u4e92\u4f5c\u7528\u76f8\u6bd4\u4e8c\u4f53\u76f8\u4e92\u4f5c\u7528\uff1a1\uff09\u4ee5~N\u500d\u52a0\u901f\u5236\u5907\u5e7f\u4e49GHZ\u6001\uff1b2\uff09\u901a\u8fc7\u65f6\u95f4\u53cd\u8f6c\u534f\u8bae\u8fbe\u5230\u6d77\u68ee\u5821\u6781\u9650\u7684\u76f8\u4f4d\u4f30\u8ba1\u7cbe\u5ea6\uff1b3\uff09\u5728\u4e2d\u7b49\u539f\u5b50\u6570\u4e0b\u83b7\u5f97\u66f4\u9ad8\u7684\u7075\u654f\u5ea6\u589e\u76ca\uff0c\u5728\u5927\u7cfb\u7efc\u4e2d\u5b9e\u73b0\u5feb\u901f\u7ea0\u7f20\u751f\u6210\u3002", "conclusion": "\u96c6\u4f53\u4e09\u4f53\u76f8\u4e92\u4f5c\u7528\u4e3a\u5236\u5907\u590d\u6742\u591a\u4f53\u7ea0\u7f20\u6001\u63d0\u4f9b\u4e86\u663e\u8457\u4f18\u52bf\uff0c\u5728\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u548c\u91cf\u5b50\u4f20\u611f\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u5b9e\u9a8c\u7ea6\u675f\u7684\u6761\u4ef6\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u3002"}}
{"id": "2512.06520", "categories": ["cs.LG", "cond-mat.stat-mech", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.06520", "abs": "https://arxiv.org/abs/2512.06520", "authors": ["Zihan Pengmei", "Spencer C. Guo", "Chatipat Lorpaiboon", "Aaron R. Dinner"], "title": "Hierarchical geometric deep learning enables scalable analysis of molecular dynamics", "comment": "17 pages, 12 figures", "summary": "Molecular dynamics simulations can generate atomically detailed trajectories of complex systems, but analyzing these dynamics can be challenging when systems lack well-established quantitative descriptors (features). Graph neural networks (GNNs) in which messages are passed between nodes that represent atoms that are spatial neighbors promise to obviate manual feature engineering, but the use of GNNs with biomolecular systems of more than a few hundred residues has been limited in the context of analyzing dynamics by both difficulties in capturing the details of long-range interactions with message passing and the memory and runtime requirements associated with large graphs. Here, we show how local information can be aggregated to reduce memory and runtime requirements without sacrificing atomic detail. We demonstrate that this approach opens the door to analyzing simulations of protein-nucleic acid complexes with thousands of residues on single GPUs within minutes. For systems with hundreds of residues, for which there are sufficient data to make quantitative comparisons, we show that the approach improves performance and interpretability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u4fe1\u606f\u805a\u5408\u6765\u9ad8\u6548\u5206\u6790\u5927\u89c4\u6a21\u751f\u7269\u5206\u5b50\u7cfb\u7edf\u7684\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8f68\u8ff9\uff0c\u964d\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u5b50\u7ea7\u7ec6\u8282\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u80fd\u751f\u6210\u539f\u5b50\u7ea7\u7ec6\u8282\u7684\u590d\u6742\u7cfb\u7edf\u8f68\u8ff9\uff0c\u4f46\u5bf9\u4e8e\u7f3a\u4e4f\u5b9a\u91cf\u63cf\u8ff0\u7b26\u7684\u5927\u7cfb\u7edf\uff08\u5982\u8d85\u8fc7\u51e0\u767e\u4e2a\u6b8b\u57fa\u7684\u751f\u7269\u5206\u5b50\u7cfb\u7edf\uff09\uff0c\u5206\u6790\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5728\u5206\u6790\u5927\u89c4\u6a21\u7cfb\u7edf\u52a8\u529b\u5b66\u65f6\u9762\u4e34\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u6355\u83b7\u56f0\u96be\u4ee5\u53ca\u5927\u56fe\u5e26\u6765\u7684\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u9650\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5c40\u90e8\u4fe1\u606f\u805a\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u6548\u805a\u5408\u5c40\u90e8\u4fe1\u606f\u6765\u51cf\u5c11\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u5b50\u7ea7\u7ec6\u8282\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u5305\u542b\u6570\u5343\u4e2a\u6b8b\u57fa\u7684\u86cb\u767d\u8d28-\u6838\u9178\u590d\u5408\u7269\u7cfb\u7edf\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u5f97\u5728\u5355GPU\u4e0a\u51e0\u5206\u949f\u5185\u5206\u6790\u6570\u5343\u4e2a\u6b8b\u57fa\u7684\u86cb\u767d\u8d28-\u6838\u9178\u590d\u5408\u7269\u6a21\u62df\u6210\u4e3a\u53ef\u80fd\u3002\u5bf9\u4e8e\u6570\u767e\u4e2a\u6b8b\u57fa\u7684\u7cfb\u7edf\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u90fd\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u5c40\u90e8\u4fe1\u606f\u805a\u5408\u65b9\u6cd5\u4e3a\u5206\u6790\u5927\u89c4\u6a21\u751f\u7269\u5206\u5b50\u7cfb\u7edf\u7684\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u4e0a\u7684\u9650\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u6790\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2512.06361", "categories": ["gr-qc", "hep-ex"], "pdf": "https://arxiv.org/pdf/2512.06361", "abs": "https://arxiv.org/abs/2512.06361", "authors": ["Sareh Eslamzadeh", "Saheb Soroushfar"], "title": "A Brief Review of Quantum Tunneling: Computational Approaches and Experimental Evidence", "comment": "13 pages, 2 figures", "summary": "This paper presents a concise review of the quantum tunneling approach to Hawking radiation, covering its theoretical foundations, extensions, and experimental efforts. We begin by outlining the Hamilton-Jacobi and Parikh-Wilczek methods, which provide a semi-classical framework for deriving Hawking radiation from stationary black holes. The discussion is then extended to dynamical black holes, where evolving horizons require modified treatments incorporating trapping horizons, Kodama vectors, and dynamical surface gravity. We explored the possible tunneling paths for particles crossing the horizon in dynamical black holes and emphasized the crucial role of the imaginary part of the action in determining the Hawking temperature. In the second part, we review experimental investigations of Hawking radiation, including analogue black hole experiments, quantum simulations, and astrophysical searches for primordial black hole evaporation. While no direct detection of Hawking radiation has been achieved, recent advances in Bose-Einstein condensates, optical analogues, and superconducting qubits offer indirect support for the tunneling interpretation of black hole evaporation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u970d\u91d1\u8f90\u5c04\u7684\u91cf\u5b50\u96a7\u7a7f\u65b9\u6cd5\uff0c\u5305\u62ec\u7406\u8bba\u57fa\u7840\u3001\u6269\u5c55\u5230\u52a8\u6001\u9ed1\u6d1e\u4ee5\u53ca\u5b9e\u9a8c\u7814\u7a76\u8fdb\u5c55\u3002", "motivation": "\u970d\u91d1\u8f90\u5c04\u662f\u9ed1\u6d1e\u7406\u8bba\u7684\u6838\u5fc3\u6982\u5ff5\uff0c\u91cf\u5b50\u96a7\u7a7f\u65b9\u6cd5\u4e3a\u7406\u89e3\u9ed1\u6d1e\u84b8\u53d1\u63d0\u4f9b\u4e86\u534a\u7ecf\u5178\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u56de\u987e\u8be5\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\u3001\u6269\u5c55\u5230\u52a8\u6001\u9ed1\u6d1e\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u5f53\u524d\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u8fdb\u5c55\u3002", "method": "\u91c7\u7528Hamilton-Jacobi\u548cParikh-Wilczek\u65b9\u6cd5\u4f5c\u4e3a\u534a\u7ecf\u5178\u6846\u67b6\uff0c\u63a8\u5bfc\u9759\u6001\u9ed1\u6d1e\u7684\u970d\u91d1\u8f90\u5c04\u3002\u6269\u5c55\u5230\u52a8\u6001\u9ed1\u6d1e\u65f6\uff0c\u5f15\u5165\u6355\u83b7\u89c6\u754c\u3001Kodama\u77e2\u91cf\u548c\u52a8\u6001\u8868\u9762\u5f15\u529b\u7b49\u6982\u5ff5\uff0c\u5206\u6790\u7c92\u5b50\u7a7f\u8d8a\u52a8\u6001\u89c6\u754c\u7684\u53ef\u80fd\u96a7\u7a7f\u8def\u5f84\uff0c\u5f3a\u8c03\u4f5c\u7528\u91cf\u865a\u90e8\u5728\u786e\u5b9a\u970d\u91d1\u6e29\u5ea6\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "result": "\u5efa\u7acb\u4e86\u4ece\u9759\u6001\u5230\u52a8\u6001\u9ed1\u6d1e\u7684\u970d\u91d1\u8f90\u5c04\u96a7\u7a7f\u7406\u8bba\u6846\u67b6\uff0c\u9610\u660e\u4e86\u52a8\u6001\u9ed1\u6d1e\u4e2d\u96a7\u7a7f\u8fc7\u7a0b\u7684\u7279\u6b8a\u6027\u3002\u5b9e\u9a8c\u65b9\u9762\uff0c\u867d\u7136\u5c1a\u672a\u76f4\u63a5\u63a2\u6d4b\u5230\u970d\u91d1\u8f90\u5c04\uff0c\u4f46\u901a\u8fc7\u73bb\u8272-\u7231\u56e0\u65af\u5766\u51dd\u805a\u4f53\u3001\u5149\u5b66\u6a21\u62df\u548c\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u7b49\u7c7b\u6bd4\u5b9e\u9a8c\u83b7\u5f97\u4e86\u95f4\u63a5\u652f\u6301\u8bc1\u636e\u3002", "conclusion": "\u91cf\u5b50\u96a7\u7a7f\u65b9\u6cd5\u4e3a\u970d\u91d1\u8f90\u5c04\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u534a\u7ecf\u5178\u89e3\u91ca\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u9ed1\u6d1e\u60c5\u51b5\u4e0b\u9700\u8981\u4fee\u6b63\u5904\u7406\u3002\u5b9e\u9a8c\u7814\u7a76\u867d\u672a\u5b9e\u73b0\u76f4\u63a5\u63a2\u6d4b\uff0c\u4f46\u7c7b\u6bd4\u5b9e\u9a8c\u548c\u91cf\u5b50\u6a21\u62df\u4e3a\u96a7\u7a7f\u89e3\u91ca\u63d0\u4f9b\u4e86\u95f4\u63a5\u9a8c\u8bc1\uff0c\u672a\u6765\u5b9e\u9a8c\u6280\u672f\u53d1\u5c55\u6709\u671b\u5e26\u6765\u7a81\u7834\u3002"}}
{"id": "2512.06102", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06102", "abs": "https://arxiv.org/abs/2512.06102", "authors": ["Ufuk \u00c7ak\u0131r", "Victor-Alexandru Darvariu", "Bruno Lacerda", "Nick Hawes"], "title": "JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning", "comment": "To be presented at the NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences (ML4PS)", "summary": "Artificial intelligence methods are increasingly being explored for managing wildfires and other natural hazards. In particular, reinforcement learning (RL) is a promising path towards improving outcomes in such uncertain decision-making scenarios and moving beyond reactive strategies. However, training RL agents requires many environment interactions, and the speed of existing wildfire simulators is a severely limiting factor. We introduce $\\texttt{JaxWildfire}$, a simulator underpinned by a principled probabilistic fire spread model based on cellular automata. It is implemented in JAX and enables vectorized simulations using $\\texttt{vmap}$, allowing high throughput of simulations on GPUs. We demonstrate that $\\texttt{JaxWildfire}$ achieves 6-35x speedup over existing software and enables gradient-based optimization of simulator parameters. Furthermore, we show that $\\texttt{JaxWildfire}$ can be used to train RL agents to learn wildfire suppression policies. Our work is an important step towards enabling the advancement of RL techniques for managing natural hazards.", "AI": {"tldr": "JaxWildfire\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u9ad8\u6027\u80fd\u91ce\u706b\u6a21\u62df\u5668\uff0c\u4f7f\u7528\u6982\u7387\u7ec6\u80de\u81ea\u52a8\u673a\u6a21\u578b\uff0c\u901a\u8fc7GPU\u5411\u91cf\u5316\u5b9e\u73b06-35\u500d\u52a0\u901f\uff0c\u652f\u6301\u68af\u5ea6\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3", "motivation": "\u73b0\u6709\u91ce\u706b\u6a21\u62df\u5668\u901f\u5ea6\u6162\uff0c\u9650\u5236\u4e86\u5f3a\u5316\u5b66\u4e60\u7b49AI\u65b9\u6cd5\u5728\u81ea\u7136\u707e\u5bb3\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u8981\u9ad8\u6027\u80fd\u6a21\u62df\u5668\u6765\u652f\u6301\u5927\u91cf\u73af\u5883\u4ea4\u4e92\u8bad\u7ec3", "method": "\u57fa\u4e8e\u6982\u7387\u7ec6\u80de\u81ea\u52a8\u673a\u7684\u91ce\u706b\u4f20\u64ad\u6a21\u578b\uff0c\u4f7f\u7528JAX\u6846\u67b6\u5b9e\u73b0\uff0c\u901a\u8fc7vmap\u5b9e\u73b0\u5411\u91cf\u5316\u6a21\u62df\uff0c\u5145\u5206\u5229\u7528GPU\u5e76\u884c\u8ba1\u7b97\u80fd\u529b", "result": "\u76f8\u6bd4\u73b0\u6709\u8f6f\u4ef6\u5b9e\u73b06-35\u500d\u901f\u5ea6\u63d0\u5347\uff0c\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u6a21\u62df\u5668\u53c2\u6570\u4f18\u5316\uff0c\u5e76\u80fd\u7528\u4e8e\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5b66\u4e60\u91ce\u706b\u6291\u5236\u7b56\u7565", "conclusion": "JaxWildfire\u4e3a\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u5728\u81ea\u7136\u707e\u5bb3\u7ba1\u7406\u4e2d\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u62df\u5668\u901f\u5ea6\u74f6\u9888\u95ee\u9898"}}
{"id": "2512.06191", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06191", "abs": "https://arxiv.org/abs/2512.06191", "authors": ["Xin Chen"], "title": "Deterministic and Universal Frequency-Bin Gate for High-Dimensional Quantum Technologies", "comment": null, "summary": "High-dimensional photonic systems access large Hilbert spaces for quantum information processing. They offer proven advantages in quantum computation, communication, and sensing. However, implementing scalable, low-loss unitary gates across many modes remains a central challenge. Here we propose a deterministic, universal, and fully programmable high-dimensional quantum gate based on a cavity-assisted sum-frequency-generation process, achieving near-unity fidelity. The device implements an M-by-N truncated unitary transformation (with 1 <= M < N), or a full unitary when M = N, on frequency-bin modes. With current technology, the attainable dimensionality reaches M-by-N on the order of ten to the power of four, with N up to about one thousand, and can be further increased using multiple pulse shapers. Combined with compatible SPDC sources, high-efficiency detection, and fast feed-forward, this approach provides a scalable, fiber-compatible platform for high-dimensional frequency-bin quantum processing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8154\u8f85\u52a9\u548c\u9891\u4ea7\u751f\u8fc7\u7a0b\u7684\u786e\u5b9a\u6027\u3001\u901a\u7528\u3001\u53ef\u7f16\u7a0b\u9ad8\u7ef4\u91cf\u5b50\u95e8\uff0c\u5b9e\u73b0\u8fd1\u5355\u4f4d\u4fdd\u771f\u5ea6\uff0c\u53ef\u5728\u9891\u7387\u6a21\u5f0f\u4e0a\u6267\u884cM\u00d7N\u622a\u65ad\u9149\u53d8\u6362\uff0c\u7ef4\u5ea6\u53ef\u8fbe10^4\u91cf\u7ea7\u3002", "motivation": "\u9ad8\u7ef4\u5149\u5b50\u7cfb\u7edf\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u5927\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u5728\u91cf\u5b50\u8ba1\u7b97\u3001\u901a\u4fe1\u548c\u4f20\u611f\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5b9e\u73b0\u8de8\u591a\u6a21\u5f0f\u7684\u53ef\u6269\u5c55\u3001\u4f4e\u635f\u8017\u9149\u95e8\u4ecd\u662f\u6838\u5fc3\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u8154\u8f85\u52a9\u548c\u9891\u4ea7\u751f\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u3001\u901a\u7528\u3001\u53ef\u7f16\u7a0b\u7684\u9ad8\u7ef4\u91cf\u5b50\u95e8\uff0c\u5728\u9891\u7387\u6a21\u5f0f\u4e0a\u6267\u884cM\u00d7N\u622a\u65ad\u9149\u53d8\u6362\uff081\u2264M<N\uff09\uff0c\u5f53M=N\u65f6\u5b9e\u73b0\u5b8c\u6574\u9149\u53d8\u6362\u3002", "result": "\u8be5\u8bbe\u5907\u53ef\u5b9e\u73b0\u8fd1\u5355\u4f4d\u4fdd\u771f\u5ea6\uff0c\u5f53\u524d\u6280\u672f\u4e0b\u53ef\u8fbe\u7ef4\u5ea6M\u00d7N\u7ea610^4\u91cf\u7ea7\uff0cN\u53ef\u8fbe\u7ea61000\uff0c\u4f7f\u7528\u591a\u4e2a\u8109\u51b2\u6574\u5f62\u5668\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u7ef4\u5ea6\u3002", "conclusion": "\u7ed3\u5408\u517c\u5bb9\u7684SPDC\u6e90\u3001\u9ad8\u6548\u7387\u63a2\u6d4b\u548c\u5feb\u901f\u524d\u9988\uff0c\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u7ef4\u9891\u7387\u6a21\u5f0f\u91cf\u5b50\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u5149\u7ea4\u517c\u5bb9\u7684\u5e73\u53f0\u3002"}}
{"id": "2512.06382", "categories": ["gr-qc", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2512.06382", "abs": "https://arxiv.org/abs/2512.06382", "authors": ["Marco Mamone-Capria"], "title": "On Spavieri's conundrum or the shadow of the twin paradox -- A submission to the One-Way Linear Effect (OWLE) Award", "comment": "23 pages, 9 figures", "summary": "We deal with a problem concerning a supposed inconsistency in the special relativistic treatment of the so-called linear Sagnac effect. It is shown that, under modern clothes, the root of the difficulty perceived by some authors lies in their uneasiness with the standard solution of the twin paradox. In particular, since the linear Sagnac effect is an absolute effect, no tinkering with conventionality of simultaneity, so far as it preserves the physical content of special relativity, would get us out of the supposed trouble.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u7ebf\u6027\u8428\u5c3c\u4e9a\u514b\u6548\u5e94\u4e2d\u7684\u6240\u8c13\u4e0d\u4e00\u81f4\u6027\uff0c\u6307\u51fa\u5176\u6839\u6e90\u5728\u4e8e\u5bf9\u53cc\u751f\u5b50\u6096\u8bba\u6807\u51c6\u89e3\u6cd5\u7684\u7406\u89e3\u56f0\u96be\uff0c\u800c\u975e\u540c\u65f6\u6027\u7ea6\u5b9a\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7279\u6b8a\u76f8\u5bf9\u8bba\u4e2d\u7ebf\u6027\u8428\u5c3c\u4e9a\u514b\u6548\u5e94\u5904\u7406\u4e2d\u611f\u77e5\u5230\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u6f84\u6e05\u4e00\u4e9b\u4f5c\u8005\u5bf9\u6b64\u6548\u5e94\u7684\u56f0\u60d1\u6839\u6e90\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7ebf\u6027\u8428\u5c3c\u4e9a\u514b\u6548\u5e94\u7684\u7edd\u5bf9\u6027\u672c\u8d28\uff0c\u6307\u51fa\u95ee\u9898\u6839\u6e90\u5728\u4e8e\u5bf9\u53cc\u751f\u5b50\u6096\u8bba\u6807\u51c6\u89e3\u6cd5\u7684\u4e0d\u9002\u5e94\uff0c\u800c\u975e\u540c\u65f6\u6027\u7ea6\u5b9a\u7684\u9009\u62e9\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u7ebf\u6027\u8428\u5c3c\u4e9a\u514b\u6548\u5e94\u662f\u7edd\u5bf9\u6548\u5e94\uff0c\u4efb\u4f55\u4fdd\u6301\u7279\u6b8a\u76f8\u5bf9\u8bba\u7269\u7406\u5185\u5bb9\u7684\u540c\u65f6\u6027\u7ea6\u5b9a\u8c03\u6574\u90fd\u65e0\u6cd5\u89e3\u51b3\u611f\u77e5\u5230\u7684\u95ee\u9898\uff0c\u771f\u6b63\u56f0\u96be\u5728\u4e8e\u7406\u89e3\u53cc\u751f\u5b50\u6096\u8bba\u7684\u6807\u51c6\u89e3\u6cd5\u3002", "conclusion": "\u7ebf\u6027\u8428\u5c3c\u4e9a\u514b\u6548\u5e94\u4e2d\u7684\u6240\u8c13\u4e0d\u4e00\u81f4\u6027\u5b9e\u9645\u4e0a\u53cd\u6620\u4e86\u5bf9\u53cc\u751f\u5b50\u6096\u8bba\u6807\u51c6\u89e3\u6cd5\u7684\u7406\u89e3\u56f0\u96be\uff0c\u800c\u975e\u7279\u6b8a\u76f8\u5bf9\u8bba\u672c\u8eab\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6027\u7ea6\u5b9a\u7684\u8c03\u6574\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e00\u6839\u672c\u56f0\u96be\u3002"}}
{"id": "2512.06104", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06104", "abs": "https://arxiv.org/abs/2512.06104", "authors": ["Isaac Liao", "Albert Gu"], "title": "ARC-AGI Without Pretraining", "comment": null, "summary": "Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI \"training set\". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.", "AI": {"tldr": "76K\u53c2\u6570\u6a21\u578bCompressARC\u65e0\u9700\u9884\u8bad\u7ec3\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u6700\u5c0f\u5316\u63cf\u8ff0\u957f\u5ea6(MDL)\u89e3\u51b320%\u7684ARC-AGI\u89c6\u89c9\u8c1c\u9898\uff0c\u5c55\u73b0\u6781\u7aef\u6cdb\u5316\u80fd\u529b", "motivation": "\u6311\u6218\u4f20\u7edf\u89c2\u70b9\uff1a\u89e3\u51b3ARC-AGI\u89c6\u89c9\u8c1c\u9898\u901a\u5e38\u9700\u8981\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5728\u6781\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\uff08\u4ec5\u4f7f\u7528\u76ee\u6807\u8c1c\u9898\u672c\u8eab\uff09\u5b9e\u73b0\u667a\u80fd\u63a8\u7406\u7684\u66ff\u4ee3\u65b9\u6cd5", "method": "\u63d0\u51faCompressARC\u6a21\u578b\uff08\u4ec576K\u53c2\u6570\uff09\uff0c\u4e0d\u8fdb\u884c\u4efb\u4f55\u9884\u8bad\u7ec3\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u6700\u5c0f\u5316\u63cf\u8ff0\u957f\u5ea6(MDL)\u6765\u6c42\u89e3\u76ee\u6807\u8c1c\u9898\u3002\u6a21\u578b\u4ec5\u4f7f\u7528\u5355\u4e2a\u6837\u672c\uff08\u76ee\u6807\u63a8\u7406\u8c1c\u9898\u672c\u8eab\uff0c\u4e0d\u542b\u6700\u7ec8\u7b54\u6848\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e0d\u4f7f\u7528ARC-AGI\u63d0\u4f9b\u7684\u8bad\u7ec3\u96c6", "result": "\u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e8620%\u7684\u8bc4\u4f30\u8c1c\u9898\uff0c\u5728\u6781\u7aef\u6570\u636e\u9650\u5236\u6761\u4ef6\u4e0b\uff08\u901a\u5e38\u8ba4\u4e3a\u4e0d\u53ef\u80fd\u89e3\u51b3\u4efb\u4f55\u8c1c\u9898\uff09\u5c55\u73b0\u4e86\u591a\u6837\u5316\u7684\u521b\u9020\u6027\u8c1c\u9898\u89e3\u51b3\u80fd\u529b", "conclusion": "\u6700\u5c0f\u5316\u63cf\u8ff0\u957f\u5ea6(MDL)\u662f\u9664\u4f20\u7edf\u9884\u8bad\u7ec3\u5916\uff0c\u5b9e\u73b0\u667a\u80fd\u63a8\u7406\u7684\u53ef\u884c\u66ff\u4ee3\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u6781\u7aef\u6cdb\u5316\u80fd\u529b\uff0c\u6311\u6218\u4e86\u6df1\u5ea6\u5b66\u4e60\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u7684\u4f9d\u8d56"}}
{"id": "2512.06219", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.06219", "abs": "https://arxiv.org/abs/2512.06219", "authors": ["Luis Octavio Casta\u00f1os-Cervantes", "Manuel Calixto", "Julio Guerrero"], "title": "Highly robust logical qubit encoding in an ensemble of V-symmetrical qutrits", "comment": "19 pages, 3 figures, 2 apendices", "summary": "We propose using even and odd Sch\u00f6dinger cat states formed from coherent states of U(3) of an ensemble of qutrits with a symmetrical V-configuration (a qubit-disguised qutrit) to encode a logical qubit. These carefully engineered logical qubit states are parameter independent stationary states of the effective master equation governing the evolution of the ensemble and, consequently, constitute dark states and are invulnerable to dissipation and correlated collective dephasing. In particular, the logical qubit states are immune to single qutrit decay (the analogous of single photon loss process for qutrits) and simultaneous decay and driving of two qutrits (the analogous two-photon loss and driving processes for qutrits). In addition, we show how to implement the single-qubit quantum NOT gate and the Hadamard gate followed by either the phase gate or the phase and $Z$ gates. We study analytically the case of two qutrits and conclude that the logical qubit states exhibit parity-sensitive inhomogeneous broadening and local correlated dephasing: the even logical state is completely immune to these processes, while odd one is vulnerable. Nevertheless, in the presence of these interactions one can also define another odd state with mixed permutation symmetry that is immune to both inhomogeneous broadening and local correlated dephasing. We suggest that these results can be extrapolated to an arbitrary number of qutrits. The effective master equation is deduced from a physical system composed of two parametrically coupled cavities with one of them interacting dispersively with an ensemble of three-level atoms (the qutrits). In principle this physical system can be implemented by means of two coplanar waveguide resonators, a SQUID parametrically coupling them, and a cloud of alkali atoms close to one of the resonators.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528U(3)\u76f8\u5e72\u6001\u6784\u6210\u7684\u5076\u6570\u548c\u5947\u6570\u859b\u5b9a\u8c14\u732b\u6001\u6765\u7f16\u7801\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\uff0c\u8fd9\u4e9b\u6001\u5bf9\u8017\u6563\u548c\u96c6\u4f53\u9000\u76f8\u5e72\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u6784\u5efa\u5bf9\u8017\u6563\u548c\u9000\u76f8\u5e72\u5177\u6709\u9c81\u68d2\u6027\u7684\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u7f16\u7801\u65b9\u6848\uff0c\u7279\u522b\u662f\u9488\u5bf9qutrit\u7cfb\u7edf\u4e2d\u7684\u5355\u91cf\u5b50\u6bd4\u7279\u8870\u51cf\u548c\u53cc\u91cf\u5b50\u6bd4\u7279\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528U(3)\u76f8\u5e72\u6001\u6784\u6210\u7684\u5076\u6570\u548c\u5947\u6570\u859b\u5b9a\u8c14\u732b\u6001\u7f16\u7801\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\uff0c\u8fd9\u4e9b\u6001\u662f\u6709\u6548\u4e3b\u65b9\u7a0b\u7684\u7a33\u6001\u89e3\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u53c2\u6570\u8026\u5408\u8154\u4e0e\u4e09\u80fd\u7ea7\u539f\u5b50\u7cfb\u7efc\u7684\u7269\u7406\u7cfb\u7edf\u5b9e\u73b0\u3002", "result": "\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u6001\u5bf9\u5355qutrit\u8870\u51cf\u548c\u53ccqutrit\u8fc7\u7a0b\u5177\u6709\u514d\u75ab\u529b\uff0c\u5076\u6570\u903b\u8f91\u6001\u5b8c\u5168\u514d\u75ab\u4e8e\u975e\u5747\u5300\u5c55\u5bbd\u548c\u5c40\u90e8\u76f8\u5173\u9000\u76f8\u5e72\uff0c\u800c\u5947\u6570\u6001\u5219\u654f\u611f\uff0c\u4f46\u53ef\u4ee5\u5b9a\u4e49\u53e6\u4e00\u79cd\u5177\u6709\u6df7\u5408\u7f6e\u6362\u5bf9\u79f0\u6027\u7684\u5947\u6570\u6001\u6765\u514d\u75ab\u8fd9\u4e9b\u8fc7\u7a0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u7f16\u7801\u65b9\u6848\u4e3a\u6784\u5efa\u9c81\u68d2\u7684\u91cf\u5b50\u6bd4\u7279\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u7ed3\u679c\u53ef\u63a8\u5e7f\u5230\u4efb\u610f\u6570\u91cf\u7684qutrits\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5bb9\u9519\u7f16\u7801\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.06489", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06489", "abs": "https://arxiv.org/abs/2512.06489", "authors": ["Quentin Henry", "Anna Heffernan"], "title": "Adiabatic tides in compact binaries on quasi-elliptic orbits: Dynamics at the second-and-a-half relative post-Newtonian order", "comment": "29 pages", "summary": "GW200105 is the first gravitational wave detection to show signs of eccentricity, it also is a neutron star - blackhole binary. This raises the need for waveforms that incorporate tidal effects on quasi-elliptic orbits. We tackle the problem of finite size effects within the post-Newtonian framework, including the mass-type quadrupole and octupole, as well as the current-type quadrupole deformations in the adiabatic approximation. The computations are performed at the second-and-a-half relative post-Newtonian order. We first derive the quasi-Keplerian parametrization of the conservative motion; we then express the radial separation and phase with their time derivatives in terms of the orbital frequency, the time eccentricity and the eccentric anomaly. To obtain these as functions of time, we invert the generalized Kepler equation while also discussing the convergence of eccentricity expanded results. We provide those results to the fourteenth order in eccentricity. Finally, we exploit the already known radiation reaction term of the acceleration in order to derive the secular and oscillatory evolutions of the orbital elements. The companion paper contains the derivation of the radiated fluxes and the amplitude modes of the strain. All relevant results are provided in an ancillary file.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9GW200105\u8fd9\u4e00\u5177\u6709\u504f\u5fc3\u7279\u5f81\u7684\u4e2d\u5b50\u661f-\u9ed1\u6d1e\u53cc\u661f\u7cfb\u7edf\uff0c\u57282.5\u9636\u540e\u725b\u987f\u8fd1\u4f3c\u4e0b\u63a8\u5bfc\u4e86\u5305\u542b\u6f6e\u6c50\u6548\u5e94\u7684\u51c6\u692d\u5706\u8f68\u9053\u6ce2\u5f62\uff0c\u63d0\u4f9b\u4e86\u81f314\u9636\u504f\u5fc3\u7387\u7684\u5c55\u5f00\u7ed3\u679c\u3002", "motivation": "GW200105\u662f\u9996\u4e2a\u663e\u793a\u504f\u5fc3\u7279\u5f81\u4e14\u4e3a\u4e2d\u5b50\u661f-\u9ed1\u6d1e\u53cc\u661f\u7684\u5f15\u529b\u6ce2\u63a2\u6d4b\u4e8b\u4ef6\uff0c\u8fd9\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u51c6\u692d\u5706\u8f68\u9053\u4e0a\u6f6e\u6c50\u6548\u5e94\u7684\u6ce2\u5f62\u6a21\u578b\u3002", "method": "\u5728\u540e\u725b\u987f\u6846\u67b6\u4e0b\uff0c\u91c7\u7528\u7edd\u70ed\u8fd1\u4f3c\u5305\u542b\u8d28\u91cf\u578b\u56db\u6781\u77e9\u548c\u516b\u6781\u77e9\u4ee5\u53ca\u6d41\u578b\u56db\u6781\u77e9\u5f62\u53d8\uff0c\u57282.5\u9636\u76f8\u5bf9\u540e\u725b\u987f\u9636\u6570\u4e0b\u8fdb\u884c\u8ba1\u7b97\u3002\u63a8\u5bfc\u4e86\u4fdd\u5b88\u8fd0\u52a8\u7684\u51c6\u5f00\u666e\u52d2\u53c2\u6570\u5316\uff0c\u5c06\u5f84\u5411\u5206\u79bb\u548c\u76f8\u4f4d\u53ca\u5176\u65f6\u95f4\u5bfc\u6570\u8868\u793a\u4e3a\u8f68\u9053\u9891\u7387\u3001\u65f6\u95f4\u504f\u5fc3\u7387\u548c\u504f\u8fd1\u70b9\u89d2\u7684\u51fd\u6570\u3002", "result": "\u63d0\u4f9b\u4e86\u81f314\u9636\u504f\u5fc3\u7387\u7684\u5c55\u5f00\u7ed3\u679c\uff0c\u901a\u8fc7\u6c42\u89e3\u5e7f\u4e49\u5f00\u666e\u52d2\u65b9\u7a0b\u83b7\u5f97\u65f6\u95f4\u51fd\u6570\uff0c\u5e76\u5229\u7528\u5df2\u77e5\u7684\u8f90\u5c04\u53cd\u51b2\u52a0\u901f\u5ea6\u9879\u63a8\u5bfc\u4e86\u8f68\u9053\u5143\u7d20\u7684\u957f\u671f\u548c\u632f\u8361\u6f14\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u504f\u5fc3\u4e2d\u5b50\u661f-\u9ed1\u6d1e\u53cc\u661f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5305\u542b\u6f6e\u6c50\u6548\u5e94\u7684\u6ce2\u5f62\u8ba1\u7b97\u65b9\u6cd5\uff0c\u76f8\u5173\u7ed3\u679c\u5728\u8865\u5145\u6587\u4ef6\u4e2d\u63d0\u4f9b\uff0c\u8f90\u5c04\u901a\u91cf\u548c\u5e94\u53d8\u632f\u5e45\u6a21\u5f0f\u7684\u63a8\u5bfc\u5728\u914d\u5957\u8bba\u6587\u4e2d\u7ed9\u51fa\u3002"}}
{"id": "2512.06111", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06111", "abs": "https://arxiv.org/abs/2512.06111", "authors": ["Arthur Mukwaya", "Nancy Kasamala", "Nana Kankam Gyimah", "Judith Mwakalonge", "Gurcan Comert", "Saidi Siuhi", "Denis Ruganuza", "Mark Ngotonie"], "title": "A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts", "comment": null, "summary": "The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.", "AI": {"tldr": "\u63d0\u51fa\u673a\u5668\u5b66\u4e60\u6846\u67b6\u9009\u62e9\u6700\u4f18\u4ee3\u8868\u65e5\u8fdb\u884c\u77ed\u671f\u4ea4\u901a\u8ba1\u6570\uff0c\u63d0\u9ad8\u5e74\u5ea6\u65e5\u5747\u4ea4\u901a\u91cf\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u7f8e\u56fd\u5404\u5dde\u4ea4\u901a\u90e8\u95e8\u96be\u4ee5\u83b7\u53d6\u51c6\u786e\u7684\u5e74\u5ea6\u65e5\u5747\u4ea4\u901a\u91cf\u6570\u636e\uff0c\u7279\u522b\u662f\u672a\u76d1\u6d4b\u9053\u8def\u3002\u8fde\u7eed\u8ba1\u6570\u7ad9\u6210\u672c\u9ad8\u96be\u4ee5\u5e7f\u6cdb\u90e8\u7f72\uff0c\u9700\u8981\u4f9d\u8d56\u77ed\u671f\u8ba1\u6570\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u4f18\u5316\u9009\u62e9\u8ba1\u6570\u65e5\u671f\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u9009\u62e9\u5bf9AADT\u4f30\u8ba1\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6700\u4f18\u4ee3\u8868\u65e5\u3002\u4f7f\u7528\u5f97\u514b\u8428\u65af\u5dde2022-2023\u5e74\u4ea4\u901a\u91cf\u6570\u636e\uff0c\u6bd4\u8f83\"\u6700\u4f18\u65e5\"\u65b9\u6cd5\u548c\"\u975e\u6700\u4f18\u65e5\"\u57fa\u7ebf\u3002\u5229\u7528\u8fde\u7eed\u8ba1\u6570\u6570\u636e\u6a21\u62df24\u5c0f\u65f6\u77ed\u671f\u8ba1\u6570\uff0c\u91c7\u7528\u7559\u4e00\u6cd5\u751f\u6210\u65e0\u504f\u7684\u4ee3\u8868\u6027\u65e5\u4ea4\u901a\u7279\u5f81\u3002", "result": "\u6700\u4f18\u65e5\u65b9\u6cd5\u5728Top 5\u5929\u5747\u4f18\u4e8e\u57fa\u7ebf\uff0c\u6700\u4f73\u65e5\uff08\u7b2c186\u5929\uff09\u7684RMSE\uff087,871.15\uff09\u3001MAE\uff083,645.09\uff09\u3001MAPE\uff0811.95%\uff09\u5747\u4f4e\u4e8e\u57fa\u7ebf\uff0811,185.00\u30015,118.57\u300114.42%\uff09\uff0cR\u00b2\uff080.9756\uff09\u9ad8\u4e8e\u57fa\u7ebf\uff080.9499\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4ea4\u901a\u90e8\u95e8\u63d0\u4f9b\u4e86\u6539\u8fdb\u4f20\u7edf\u77ed\u671f\u8ba1\u6570\u5b9e\u8df5\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u63d0\u9ad8AADT\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u652f\u6301\u516c\u8def\u6027\u80fd\u76d1\u6d4b\u7cfb\u7edf\u5408\u89c4\u6027\uff0c\u5e76\u964d\u4f4e\u5168\u5dde\u4ea4\u901a\u6570\u636e\u6536\u96c6\u7684\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2512.06224", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06224", "abs": "https://arxiv.org/abs/2512.06224", "authors": ["Mohammadhossein Mohammadisiahroudi", "Zeguan Wu", "Pouya Sampourmahani", "Adrian Harkness", "Tam\u00e1s Terlaky"], "title": "Quantum Interior Point Methods: A Review of Developments and An Optimally Scaling Framework", "comment": "Gavriel Salvendy International Symposium on Frontiers in Industrial Engineering Purdue Quantum AI", "summary": "The growing demand for solving large-scale, data-intensive linear and conic optimization problems, particularly in applications such as artificial intelligence and machine learning, has highlighted the limitations of classical interior point methods (IPMs). Despite their favorable polynomial-time convergence, conventional IPMs often suffer from high per-iteration computational costs, especially for dense problem instances. Recent advances in quantum computing, particularly quantum linear system solvers, offer promising avenues to accelerate the most computationally intensive steps of IPMs. However, practical challenges such as quantum error, hardware noise, and sensitivity to poorly conditioned systems remain significant obstacles. In response, a series of Quantum IPMs (QIPMs) has been developed to address these challenges, incorporating techniques such as feasibility maintenance, iterative refinement, and preconditioning. In this work, we review this line of research with a focus on our recent contributions, including an almost-exact QIPM framework. This hybrid quantum-classical approach constructs and solves the Newton system entirely on a quantum computer, while performing solution updates classically. Crucially, all matrix-vector operations are executed on quantum hardware, enabling the method to achieve an optimal worst-case scalability w.r.t dimension, surpassing the scalability of existing classical and quantum IPMs.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u91cf\u5b50\u5185\u70b9\u6cd5(QIPMs)\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u4f5c\u8005\u63d0\u51fa\u7684\u51e0\u4e4e\u7cbe\u786e\u7684\u91cf\u5b50\u5185\u70b9\u6cd5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u52a0\u901f\u7ebf\u6027\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u7b49\u9886\u57df\u5bf9\u5927\u89c4\u6a21\u3001\u6570\u636e\u5bc6\u96c6\u578b\u7ebf\u6027\u548c\u9525\u4f18\u5316\u95ee\u9898\u7684\u9700\u6c42\u589e\u957f\uff0c\u7ecf\u5178\u5185\u70b9\u6cd5(IPMs)\u5728\u5904\u7406\u5bc6\u96c6\u95ee\u9898\u5b9e\u4f8b\u65f6\u9762\u4e34\u9ad8\u6602\u7684\u6bcf\u8fed\u4ee3\u8ba1\u7b97\u6210\u672c\u3002\u91cf\u5b50\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u5668\u4e3a\u52a0\u901fIPMs\u4e2d\u6700\u8017\u8ba1\u7b97\u91cf\u7684\u6b65\u9aa4\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u65b9\u6cd5\uff1a\u5728\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u5b8c\u5168\u6784\u5efa\u548c\u6c42\u89e3\u725b\u987f\u7cfb\u7edf\uff0c\u800c\u5728\u7ecf\u5178\u8ba1\u7b97\u673a\u4e0a\u6267\u884c\u89e3\u66f4\u65b0\u3002\u6240\u6709\u77e9\u9635-\u5411\u91cf\u64cd\u4f5c\u90fd\u5728\u91cf\u5b50\u786c\u4ef6\u4e0a\u6267\u884c\uff0c\u7ed3\u5408\u4e86\u53ef\u884c\u6027\u7ef4\u62a4\u3001\u8fed\u4ee3\u7ec6\u5316\u548c\u9884\u5904\u7406\u7b49\u6280\u672f\u6765\u5e94\u5bf9\u91cf\u5b50\u8bef\u5dee\u548c\u6761\u4ef6\u6570\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7ef4\u5ea6\u65b9\u9762\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u6700\u574f\u60c5\u51b5\u53ef\u6269\u5c55\u6027\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7ecf\u5178\u548c\u91cf\u5b50\u5185\u70b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u3002\u91cf\u5b50\u786c\u4ef6\u6267\u884c\u6240\u6709\u77e9\u9635-\u5411\u91cf\u64cd\u4f5c\uff0c\u4f7f\u5f97\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u4f18\u5316\u95ee\u9898\u3002", "conclusion": "\u91cf\u5b50\u5185\u70b9\u6cd5\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u901a\u8fc7\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u65b9\u6cd5\u514b\u670d\u4e86\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u6311\u6218\uff0c\u5728\u7ef4\u5ea6\u53ef\u6269\u5c55\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2512.06498", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06498", "abs": "https://arxiv.org/abs/2512.06498", "authors": ["D. Panigrahi", "S. Chatterjee", "B. C. Paul"], "title": "Emergent Universe Scenario in the Modified Chaplygin gas : Towards an Exact Solution and Observational Constraints", "comment": "28 pages, 25 figures", "summary": "The Modified Chaplygin Gas (MCG) model is revisited to examine its ability to describe the full cosmic evolution within a single framework. Because the field equations are highly nonlinear, no closed analytical solution for the scale factor in terms of cosmic time exists. To address this limitation and determine the flip time along with other physical characteristics, we introduce an alternative first order approximation that yields an exact analytical expression for the scale factor. This approach gives rise to an emergent, non singular cosmological scenario in which the universe begins with a finite minimum size and evolves smoothly from a quasi static phase to a de Sitter like expansion at late times, naturally approaching the LambdaCDM limit. Using Hubble observational data, we constrain the equation of state parameters and obtain the viable ranges 0 < alpha < 1 and 0 < A < 1/3. The effective equation of state parameter evolves from a positive value in the early matter dominated era to approximately minus one at late times, consistent with observations. A complementary analysis based on the Raychaudhuri equation further supports the robustness of the model.", "AI": {"tldr": "\u91cd\u65b0\u5ba1\u89c6\u4fee\u6b63Chaplygin\u6c14\u4f53\u6a21\u578b\uff0c\u901a\u8fc7\u4e00\u9636\u8fd1\u4f3c\u5f97\u5230\u5c3a\u5ea6\u56e0\u5b50\u7684\u7cbe\u786e\u89e3\u6790\u89e3\uff0c\u63d0\u51fa\u4e00\u4e2a\u4ece\u6709\u9650\u6700\u5c0f\u5c3a\u5bf8\u5f00\u59cb\u3001\u5e73\u6ed1\u6f14\u5316\u5230\u7c7bde Sitter\u81a8\u80c0\u7684\u975e\u5947\u5f02\u5b87\u5b99\u5b66\u573a\u666f\uff0c\u5e76\u7528\u89c2\u6d4b\u6570\u636e\u7ea6\u675f\u53c2\u6570\u3002", "motivation": "\u4fee\u6b63Chaplygin\u6c14\u4f53\u6a21\u578b\u80fd\u591f\u63cf\u8ff0\u5b8c\u6574\u5b87\u5b99\u6f14\u5316\uff0c\u4f46\u573a\u65b9\u7a0b\u9ad8\u5ea6\u975e\u7ebf\u6027\uff0c\u65e0\u6cd5\u5f97\u5230\u5c3a\u5ea6\u56e0\u5b50\u5173\u4e8e\u5b87\u5b99\u65f6\u95f4\u7684\u5c01\u95ed\u89e3\u6790\u89e3\u3002\u9700\u8981\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u786e\u5b9a\u7ffb\u8f6c\u65f6\u95f4\u548c\u5176\u4ed6\u7269\u7406\u7279\u5f81\u3002", "method": "\u5f15\u5165\u66ff\u4ee3\u7684\u4e00\u9636\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5f97\u5230\u5c3a\u5ea6\u56e0\u5b50\u7684\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u3002\u4f7f\u7528\u54c8\u52c3\u89c2\u6d4b\u6570\u636e\u7ea6\u675f\u72b6\u6001\u65b9\u7a0b\u53c2\u6570\uff0c\u5e76\u901a\u8fc7Raychaudhuri\u65b9\u7a0b\u8fdb\u884c\u8865\u5145\u5206\u6790\u9a8c\u8bc1\u6a21\u578b\u7a33\u5065\u6027\u3002", "result": "\u83b7\u5f97\u4e86\u4e00\u4e2a\u6d8c\u73b0\u7684\u975e\u5947\u5f02\u5b87\u5b99\u5b66\u573a\u666f\uff1a\u5b87\u5b99\u4ece\u6709\u9650\u6700\u5c0f\u5c3a\u5bf8\u5f00\u59cb\uff0c\u4ece\u51c6\u9759\u6001\u76f8\u5e73\u6ed1\u6f14\u5316\u5230\u665a\u671f\u7c7bde Sitter\u81a8\u80c0\uff0c\u81ea\u7136\u8d8b\u8fd1\u4e8e\u039bCDM\u6781\u9650\u3002\u53c2\u6570\u7ea6\u675f\u8303\u56f4\u4e3a0 < \u03b1 < 1\u548c0 < A < 1/3\uff0c\u6709\u6548\u72b6\u6001\u65b9\u7a0b\u53c2\u6570\u4ece\u65e9\u671f\u7269\u8d28\u4e3b\u5bfc\u65f6\u671f\u7684\u6b63\u503c\u6f14\u5316\u5230\u665a\u671f\u7ea6-1\u7684\u503c\u3002", "conclusion": "\u4fee\u6b63Chaplygin\u6c14\u4f53\u6a21\u578b\u901a\u8fc7\u4e00\u9636\u8fd1\u4f3c\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u63cf\u8ff0\u5b8c\u6574\u5b87\u5b99\u6f14\u5316\uff0c\u63d0\u4f9b\u89e3\u6790\u89e3\u5e76\u5f97\u5230\u89c2\u6d4b\u652f\u6301\uff0c\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u5b87\u5b99\u5b66\u6846\u67b6\u3002"}}
{"id": "2512.06134", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.06134", "abs": "https://arxiv.org/abs/2512.06134", "authors": ["Georgi Hrusanov", "Duy-Thanh Vu", "Duy-Cat Can", "Sophie Tascedda", "Margaret Ryan", "Julien Bodelet", "Katarzyna Koscielska", "Carsten Magnus", "Oliver Y. Ch\u00e9n"], "title": "Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting", "comment": null, "summary": "Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($\u03b1$) and biological ($\u03b2$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.", "AI": {"tldr": "\u63d0\u51faNeural Koopman Machine (NKM)\u67b6\u6784\uff0c\u7ed3\u5408\u52a8\u6001\u7cfb\u7edf\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u9884\u6d4b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8ba4\u77e5\u8870\u9000\u8f68\u8ff9\uff0c\u5728ADNI\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u8ba4\u77e5\u8870\u9000\u9884\u6d4b\u5bf9\u75be\u75c5\u8bc4\u4f30\u548c\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u7eb5\u5411\u4e2a\u6027\u5316\u9884\u6d4b\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faNeural Koopman Machine (NKM)\u67b6\u6784\uff0c\u7ed3\u5408\u52a8\u6001\u7cfb\u7edf\u7406\u8bba\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7Fusion Group-Aware Hierarchical Attention\u5728Koopman\u7b97\u5b50\u6846\u67b6\u5185\u5c06\u975e\u7ebf\u6027\u8f68\u8ff9\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u7ebf\u6027\u8868\u793a\uff0c\u6574\u5408\u5206\u6790\u77e5\u8bc6\u548c\u751f\u7269\u5b66\u77e5\u8bc6\u6307\u5bfc\u7279\u5f81\u5206\u7ec4\u3002", "result": "\u5728ADNI\u6570\u636e\u96c6\u4e0a\uff0cNKM\u5728\u9884\u6d4b\u8ba4\u77e5\u8870\u9000\u8f68\u8ff9\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u540c\u65f6\u9884\u6d4b\u591a\u4e2a\u8ba4\u77e5\u8bc4\u5206\u53d8\u5316\uff0c\u91cf\u5316\u4e0d\u540c\u751f\u7269\u6807\u5fd7\u7269\u5bf9\u7279\u5b9a\u8ba4\u77e5\u8bc4\u5206\u7684\u8d21\u732e\uff0c\u5e76\u8bc6\u522b\u4e0e\u8ba4\u77e5\u6076\u5316\u6700\u76f8\u5173\u7684\u5927\u8111\u533a\u57df\u3002", "conclusion": "NKM\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u663e\u5f0f\u7cfb\u7edf\u63a8\u8fdb\u4e86\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8ba4\u77e5\u8870\u9000\u7684\u4e2a\u6027\u5316\u9884\u6d4b\uff0c\u63ed\u793a\u4e86\u75be\u75c5\u8fdb\u5c55\u7684\u6f5c\u5728\u591a\u6a21\u6001\u751f\u7269\u5b66\u57fa\u7840\u3002"}}
{"id": "2512.06260", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06260", "abs": "https://arxiv.org/abs/2512.06260", "authors": ["Kaito Wada", "Hiroyuki Harada", "Yasunari Suzuki", "Yuuki Tokunaga", "Naoki Yamamoto", "Suguru Endo"], "title": "Tradeoffs between quantum and classical resources in linear combination of unitaries", "comment": "25 pages, 7 figures", "summary": "The linear combination of unitaries (LCU) algorithm is a building block of many quantum algorithms. However, because LCU generally requires an ancillary system and complex controlled unitary operators, it is not regarded as a hardware-efficient routine. Recently, a randomized LCU implementation with many applications to early FTQC algorithms has been proposed that computes the same expectation values as the original LCU algorithm using a shallower quantum circuit with a single ancilla qubit, at the cost of a quadratically larger sampling overhead. In this work, we propose a quantum algorithm intermediate between the original and randomized LCU that manages the tradeoff between sampling cost and the circuit size. Our algorithm divides the set of unitary operators into several groups and then randomly samples LCU circuits from these groups to evaluate the target expectation value. Notably, we analytically prove an underlying monotonicity: larger group sizes entail smaller sampling overhead, by introducing a quantity called the reduction factor, which determines the sampling overhead across all grouping strategies. Our hybrid algorithm not only enables substantial reductions in circuit depth and ancilla-qubit usage while nearly maintaining the sampling overhead of LCU-based non-Hermitian dynamics simulators, but also achieves intermediate scaling between virtual and coherent quantum linear system solvers. It further provides a virtual ground-state preparation scheme that requires only a resettable single-ancilla qubit and asymptotically shows advantages in both virtual and coherent LCU methods. Finally, by viewing quantum error detection as an LCU process, our approach clarifies when conventional and virtual detection should be applied selectively, thereby balancing sampling and hardware overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ecb\u4e8e\u539f\u59cbLCU\u548c\u968f\u673a\u5316LCU\u4e4b\u95f4\u7684\u6df7\u5408\u91cf\u5b50\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u7ec4\u7b56\u7565\u5728\u91c7\u6837\u5f00\u9500\u548c\u7535\u8def\u89c4\u6a21\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5e76\u8bc1\u660e\u5206\u7ec4\u5927\u5c0f\u4e0e\u91c7\u6837\u5f00\u9500\u7684\u5355\u8c03\u5173\u7cfb\u3002", "motivation": "\u7ebf\u6027\u7ec4\u5408\u5355\u5143(LCU)\u7b97\u6cd5\u662f\u8bb8\u591a\u91cf\u5b50\u7b97\u6cd5\u7684\u57fa\u7840\u6784\u4ef6\uff0c\u4f46\u901a\u5e38\u9700\u8981\u8f85\u52a9\u7cfb\u7edf\u548c\u590d\u6742\u7684\u53d7\u63a7\u5355\u5143\u64cd\u4f5c\uff0c\u4e0d\u591f\u786c\u4ef6\u9ad8\u6548\u3002\u968f\u673a\u5316LCU\u867d\u7136\u51cf\u5c11\u4e86\u7535\u8def\u6df1\u5ea6\u548c\u8f85\u52a9\u6bd4\u7279\u4f7f\u7528\uff0c\u4f46\u5e26\u6765\u4e86\u4e8c\u6b21\u589e\u957f\u7684\u91c7\u6837\u5f00\u9500\u3002\u9700\u8981\u5728\u7535\u8def\u590d\u6742\u5ea6\u548c\u91c7\u6837\u5f00\u9500\u4e4b\u95f4\u627e\u5230\u66f4\u597d\u7684\u5e73\u8861\u70b9\u3002", "method": "\u63d0\u51fa\u6df7\u5408LCU\u7b97\u6cd5\uff1a\u5c06\u5355\u5143\u64cd\u4f5c\u96c6\u5212\u5206\u4e3a\u82e5\u5e72\u7ec4\uff0c\u7136\u540e\u4ece\u8fd9\u4e9b\u7ec4\u4e2d\u968f\u673a\u91c7\u6837LCU\u7535\u8def\u6765\u8bc4\u4f30\u76ee\u6807\u671f\u671b\u503c\u3002\u5f15\u5165\"\u7f29\u51cf\u56e0\u5b50\"\u8fd9\u4e00\u91cf\u5ea6\uff0c\u5206\u6790\u8bc1\u660e\u5206\u7ec4\u5927\u5c0f\u4e0e\u91c7\u6837\u5f00\u9500\u4e4b\u95f4\u7684\u5355\u8c03\u5173\u7cfb\uff1a\u66f4\u5927\u7684\u5206\u7ec4\u5bf9\u5e94\u66f4\u5c0f\u7684\u91c7\u6837\u5f00\u9500\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u5c11\u7535\u8def\u6df1\u5ea6\u548c\u8f85\u52a9\u6bd4\u7279\u4f7f\u7528\uff0c\u540c\u65f6\u51e0\u4e4e\u4fdd\u6301\u57fa\u4e8eLCU\u7684\u975e\u5384\u7c73\u52a8\u529b\u5b66\u6a21\u62df\u5668\u7684\u91c7\u6837\u5f00\u9500\u3002\u5728\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u5668\u4e2d\u5b9e\u73b0\u4e86\u865a\u62df\u548c\u76f8\u5e72\u65b9\u6cd5\u4e4b\u95f4\u7684\u4e2d\u95f4\u7f29\u653e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ec5\u9700\u5355\u4e2a\u53ef\u91cd\u7f6e\u8f85\u52a9\u6bd4\u7279\u7684\u865a\u62df\u57fa\u6001\u5236\u5907\u65b9\u6848\u3002", "conclusion": "\u8be5\u6df7\u5408\u7b97\u6cd5\u5728\u91c7\u6837\u5f00\u9500\u548c\u786c\u4ef6\u5f00\u9500\u4e4b\u95f4\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u6743\u8861\u3002\u901a\u8fc7\u5c06\u91cf\u5b50\u9519\u8bef\u68c0\u6d4b\u89c6\u4e3aLCU\u8fc7\u7a0b\uff0c\u9610\u660e\u4e86\u4f55\u65f6\u5e94\u9009\u62e9\u6027\u5730\u5e94\u7528\u4f20\u7edf\u548c\u865a\u62df\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ece\u800c\u5e73\u8861\u91c7\u6837\u548c\u786c\u4ef6\u5f00\u9500\u3002"}}
{"id": "2512.06549", "categories": ["gr-qc", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.06549", "abs": "https://arxiv.org/abs/2512.06549", "authors": ["Sabbir A. Rahman"], "title": "The Two-Sheeted Topology of Extended Kerr-Type Spacetimes and a Parity-of-Crossings Property for Ring-Traversing Geodesics", "comment": "20 pages, submitted to Comm. Math. Phys", "summary": "We revisit the global structure of the extended Kerr spacetime and of a broader class of Kerr-type spacetimes possessing ring singularities. By working with the elementary analytic extension (the union of the interior and exterior regions glued across the disk), we show that excising the ring singularity yields a domain that can be realised as a branched double cover of an exterior Kerr region. The branch locus is the ring itself, and the associated deck transformation defines a non-trivial $\\mathbb{Z}_2$-action that exchanges the two sheets ($r>0$ and $r<0$) of the spacetime.\n  We give a covering-space characterisation of this double-sheeted structure and show that admissible geodesics which cross the ring singularity implement the non-trivial deck transformation. In particular, we prove a parity-of-crossings property: any admissible geodesic that traverses an even number of ring singularities returns to its original sheet, while an odd number of traversals terminates on the opposite sheet.\n  Generalising to $N$ disjoint ring singularities, we prove that the fundamental group of the excised manifold is the free group $F_N$ generated by simple loops around each ring, and we classify the associated double covers. Identifying the physically distinguished cover where every ring induces a sheet exchange, we extend the parity-of-crossings theorem to the multi-ring setting. We then formally extend these results to the maximal analytic extension (the infinite Carter--Penrose chain), proving that the sheet-exchange mechanism applies globally to this infinite structure.\n  Finally, applying the Novikov self-consistency principle to this topological framework, we demonstrate that the requirement of global consistency restricts admissible histories to discrete sectors labelled by ring-crossing parities.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5177\u6709\u73af\u5947\u70b9\u7684Kerr\u578b\u65f6\u7a7a\u7684\u5168\u5c40\u62d3\u6251\u7ed3\u6784\uff0c\u8bc1\u660e\u4e86\u79fb\u9664\u73af\u5947\u70b9\u540e\u65f6\u7a7a\u53ef\u8868\u793a\u4e3a\u5916\u90e8Kerr\u533a\u57df\u7684\u53cc\u53f6\u5206\u652f\u8986\u76d6\uff0c\u5e76\u5efa\u7acb\u4e86\u5947\u70b9\u7a7f\u8d8a\u7684\u5947\u5076\u6027\u5b9a\u7406\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u6269\u5c55Kerr\u65f6\u7a7a\u548c\u5177\u6709\u73af\u5947\u70b9\u7684Kerr\u578b\u65f6\u7a7a\u7684\u5168\u5c40\u7ed3\u6784\uff0c\u7406\u89e3\u73af\u5947\u70b9\u5982\u4f55\u5f71\u54cd\u65f6\u7a7a\u7684\u62d3\u6251\u6027\u8d28\u4ee5\u53ca\u6d4b\u5730\u7ebf\u7a7f\u8d8a\u5947\u70b9\u7684\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u57fa\u672c\u89e3\u6790\u5ef6\u62d3\uff08\u5185\u5916\u533a\u57df\u5728\u76d8\u9762\u4e0a\u7c98\u5408\uff09\uff0c\u79fb\u9664\u73af\u5947\u70b9\uff0c\u5c06\u65f6\u7a7a\u6784\u9020\u4e3a\u5916\u90e8Kerr\u533a\u57df\u7684\u5206\u652f\u53cc\u8986\u76d6\u3002\u4f7f\u7528\u8986\u76d6\u7a7a\u95f4\u7406\u8bba\u63cf\u8ff0\u53cc\u53f6\u7ed3\u6784\uff0c\u5206\u6790\u6d4b\u5730\u7ebf\u7a7f\u8d8a\u5947\u70b9\u7684\u884c\u4e3a\uff0c\u5e76\u63a8\u5e7f\u5230\u591a\u73af\u5947\u70b9\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u79fb\u9664\u73af\u5947\u70b9\u540e\u65f6\u7a7a\u662f\u5916\u90e8Kerr\u533a\u57df\u7684\u53cc\u53f6\u5206\u652f\u8986\u76d6\uff0c\u5206\u652f\u8f68\u8ff9\u662f\u73af\u672c\u8eab\u3002\u5efa\u7acb\u4e86\u5947\u70b9\u7a7f\u8d8a\u7684\u5947\u5076\u6027\u5b9a\u7406\uff1a\u5076\u6570\u6b21\u7a7f\u8d8a\u8fd4\u56de\u539f\u53f6\uff0c\u5947\u6570\u6b21\u7a7f\u8d8a\u5230\u8fbe\u5bf9\u4fa7\u53f6\u3002\u591a\u73af\u60c5\u51b5\u4e0b\u57fa\u672c\u7fa4\u662f\u81ea\u7531\u7fa4F_N\uff0c\u5e76\u63a8\u5e7f\u5230\u6700\u5927\u89e3\u6790\u5ef6\u62d3\u3002", "conclusion": "Kerr\u578b\u65f6\u7a7a\u5177\u6709\u4e30\u5bcc\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u73af\u5947\u70b9\u8bf1\u5bfc\u4e86\u975e\u5e73\u51e1\u7684Z_2\u4f5c\u7528\u3002\u5e94\u7528Novikov\u81ea\u6d3d\u539f\u7406\u8868\u660e\uff0c\u5168\u5c40\u4e00\u81f4\u6027\u8981\u6c42\u5c06\u53ef\u5bb9\u8bb8\u5386\u53f2\u9650\u5236\u5728\u7531\u73af\u7a7f\u8d8a\u5947\u5076\u6027\u6807\u8bb0\u7684\u79bb\u6563\u6247\u533a\u4e2d\u3002"}}
{"id": "2512.06143", "categories": ["cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.06143", "abs": "https://arxiv.org/abs/2512.06143", "authors": ["Marcus M. Noack", "Mark D. Risser", "Hengrui Luo", "Vardaan Tekriwal", "Ronald J. Pandolfi"], "title": "gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points", "comment": "None", "summary": "Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \\emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.", "AI": {"tldr": "\u63d0\u51fagp2Scale\u65b9\u6cd5\uff0c\u65e0\u9700\u8fd1\u4f3c\u6280\u672f\u5373\u53ef\u5c06\u7cbe\u786e\u9ad8\u65af\u8fc7\u7a0b\u6269\u5c55\u5230\u5343\u4e07\u7ea7\u6570\u636e\u70b9\uff0c\u5229\u7528\u7075\u6d3b\u6838\u51fd\u6570\u81ea\u7136\u4ea7\u751f\u7684\u7a00\u758f\u6027\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u9ad8\u65af\u8fc7\u7a0b\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u901f\u5ea6\u3001\u9884\u6d4b\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3b\u8981\u4f9d\u8d56\u5404\u79cd\u8fd1\u4f3c\u6280\u672f\uff0c\u964d\u4f4e\u4e86\u51c6\u786e\u6027\u5e76\u9650\u5236\u4e86\u6838\u51fd\u6570\u548c\u566a\u58f0\u6a21\u578b\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\uff0c\u7279\u522b\u662f\u5728\u8868\u8fbe\u6027\u975e\u5e73\u7a33\u6838\u51fd\u6570\u65e5\u76ca\u91cd\u8981\u7684\u80cc\u666f\u4e0b\u3002", "method": "\u63d0\u51fagp2Scale\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u8bf1\u5bfc\u70b9\u3001\u6838\u63d2\u503c\u6216\u90bb\u57df\u8fd1\u4f3c\uff0c\u800c\u662f\u5229\u7528\u7075\u6d3b\u3001\u7d27\u652f\u6491\u3001\u975e\u5e73\u7a33\u6838\u51fd\u6570\u5728\u534f\u65b9\u5dee\u77e9\u9635\u4e2d\u81ea\u7136\u4ea7\u751f\u7684\u7a00\u758f\u7ed3\u6784\uff0c\u9ad8\u6548\u8ba1\u7b97\u7ebf\u6027\u7cfb\u7edf\u89e3\u548c\u5bf9\u6570\u884c\u5217\u5f0f\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u8d85\u8fc71000\u4e07\u4e2a\u6570\u636e\u70b9\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u529f\u80fd\uff0c\u4e0e\u6700\u5148\u8fdb\u8fd1\u4f3c\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u8fd1\u4f3c\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u4efb\u610f\u9ad8\u65af\u8fc7\u7a0b\u5b9a\u5236\uff08\u6838\u8bbe\u8ba1\u3001\u566a\u58f0\u3001\u5747\u503c\u51fd\u6570\uff09\u548c\u8f93\u5165\u7a7a\u95f4\u7c7b\u578b\u7684\u4e0d\u53ef\u77e5\u6027\u3002", "conclusion": "gp2Scale\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u6838\u51fd\u6570\u8bbe\u8ba1\u81ea\u7136\u4ea7\u751f\u7684\u7a00\u758f\u6027\uff0c\u89e3\u51b3\u4e86\u9ad8\u65af\u8fc7\u7a0b\u6269\u5c55\u4e2d\u7684\u6838\u5fc3\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u9002\u5408\u73b0\u4ee3\u9ad8\u65af\u8fc7\u7a0b\u5e94\u7528\uff0c\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u540c\u65f6\u4fdd\u6301\u7075\u6d3b\u6027\u548c\u7cbe\u786e\u6027\u3002"}}
{"id": "2512.06263", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06263", "abs": "https://arxiv.org/abs/2512.06263", "authors": ["Tiange Xiang", "Yubo Zhang", "Joonas Keski-Rahkonen", "Anton M. Graf", "Eric J. Heller"], "title": "Adiabaticity Crossover: From Anderson Localization to Planckian Diffusion", "comment": "9 pages, 8 figures", "summary": "We investigate electron transport in one dimension from the quantum-acoustic perspective, where the coherent-state representation of lattice vibrations results in a time-dependent deformation potential whose rate is set by the sound speed, fluctuation spectrum is set by the temperature, and overall amplitude is set by the electron-lattice coupling strength. We introduce an acceleration-based adiabatic criterion, consistent with the adiabatic theorem and Landau-Zener theory, that separates adiabatic and diabatic dynamics across the $(T,v)$ plane. The discrete classification agrees with a continuous mean-squared acceleration scale and correlates with a coherence measure given by the ratio of coherence length to the initial packet width $L_\u03c6(t)/\u03c3_0$. We identify a broad Planckian domain in which the dimensionless diffusivity $\u03b1\\!=\\!Dm/\\hbar$ is of order unity and only weakly depends on the parameters. This domain is more prevalent in diabatic regions and in areas of reduced phase coherence, indicating a dephasing driven crossover from Anderson localization to Planckian diffusion. Using the Einstein relation together with nearly constant $\u03b1$, we directly obtain a low temperature tendency $1/\u03c4_{\\rm tr}\\propto T$, offering a insight to $T$-linear resistivity in strange metals. These results provide a unified picture that links adiabaticity, dephasing, and Planckian diffusion in dynamically disordered quantum-acoustics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u91cf\u5b50\u58f0\u5b66\u89d2\u5ea6\u7814\u7a76\u4e00\u7ef4\u7535\u5b50\u8f93\u8fd0\uff0c\u53d1\u73b0\u58f0\u901f\u3001\u6e29\u5ea6\u548c\u7535\u5b50-\u6676\u683c\u8026\u5408\u5171\u540c\u51b3\u5b9a\u5f62\u53d8\u52bf\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u52a0\u901f\u5ea6\u7684\u7edd\u70ed\u5224\u636e\uff0c\u8bc6\u522b\u51fa\u666e\u6717\u514b\u6269\u6563\u533a\u57df\uff0c\u5e76\u89e3\u91ca\u4e86\u5947\u5f02\u91d1\u5c5e\u4e2dT\u7ebf\u6027\u7535\u963b\u7387\u7684\u8d77\u6e90\u3002", "motivation": "\u7814\u7a76\u4e00\u7ef4\u7535\u5b50\u8f93\u8fd0\u4e2d\u7684\u91cf\u5b50\u58f0\u5b66\u6548\u5e94\uff0c\u7279\u522b\u662f\u6676\u683c\u632f\u52a8\u5982\u4f55\u901a\u8fc7\u5f62\u53d8\u52bf\u5f71\u54cd\u7535\u5b50\u52a8\u529b\u5b66\uff0c\u65e8\u5728\u7406\u89e3\u7edd\u70ed\u6027\u3001\u9000\u76f8\u5e72\u548c\u666e\u6717\u514b\u6269\u6563\u4e4b\u95f4\u7684\u7edf\u4e00\u5173\u7cfb\uff0c\u5e76\u4e3a\u5947\u5f02\u91d1\u5c5e\u4e2d\u7684T\u7ebf\u6027\u7535\u963b\u7387\u73b0\u8c61\u63d0\u4f9b\u89e3\u91ca\u3002", "method": "\u91c7\u7528\u6676\u683c\u632f\u52a8\u7684\u76f8\u5e72\u6001\u8868\u793a\uff0c\u5f97\u5230\u65f6\u95f4\u4f9d\u8d56\u7684\u5f62\u53d8\u52bf\uff1b\u5f15\u5165\u57fa\u4e8e\u52a0\u901f\u5ea6\u7684\u7edd\u70ed\u5224\u636e\u6765\u533a\u5206\u7edd\u70ed\u548c\u7a7f\u8d8a\u52a8\u529b\u5b66\uff1b\u901a\u8fc7\u76f8\u5e72\u957f\u5ea6\u4e0e\u521d\u59cb\u6ce2\u5305\u5bbd\u5ea6\u7684\u6bd4\u503c\u8861\u91cf\u76f8\u5e72\u6027\uff1b\u5728(T,v)\u5e73\u9762\u4e0a\u5206\u6790\u6269\u6563\u884c\u4e3a\u3002", "result": "\u8bc6\u522b\u51fa\u666e\u6717\u514b\u6269\u6563\u533a\u57df\uff0c\u5176\u4e2d\u65e0\u91cf\u7eb2\u6269\u6563\u7387\u03b1\u22481\u4e14\u5bf9\u53c2\u6570\u4f9d\u8d56\u5f31\uff1b\u8be5\u533a\u57df\u5728\u7a7f\u8d8a\u533a\u57df\u548c\u9000\u76f8\u5e72\u589e\u5f3a\u533a\u57df\u66f4\u666e\u904d\uff0c\u8868\u660e\u4ece\u5b89\u5fb7\u68ee\u5c40\u57df\u5316\u5230\u666e\u6717\u514b\u6269\u6563\u7684\u9000\u76f8\u5e72\u9a71\u52a8\u8f6c\u53d8\uff1b\u901a\u8fc7\u7231\u56e0\u65af\u5766\u5173\u7cfb\u5f97\u52301/\u03c4_tr\u221dT\u7684\u4f4e\u6e29\u8d8b\u52bf\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u7edd\u70ed\u6027\u3001\u9000\u76f8\u5e72\u548c\u666e\u6717\u514b\u6269\u6563\u5728\u52a8\u6001\u65e0\u5e8f\u91cf\u5b50\u58f0\u5b66\u4e2d\u7684\u7edf\u4e00\u56fe\u50cf\uff0c\u4e3a\u5947\u5f02\u91d1\u5c5e\u4e2d\u7684T\u7ebf\u6027\u7535\u963b\u7387\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\uff0c\u5efa\u7acb\u4e86\u7535\u5b50\u8f93\u8fd0\u4e2d\u91cf\u5b50\u58f0\u5b66\u6548\u5e94\u4e0e\u5b8f\u89c2\u8f93\u8fd0\u6027\u8d28\u4e4b\u95f4\u7684\u8054\u7cfb\u3002"}}
{"id": "2512.06790", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06790", "abs": "https://arxiv.org/abs/2512.06790", "authors": ["Lingyun Fu", "Hidetoshi Omiya", "Takahiro Tanaka", "Xi Tong", "Yi Wang", "Hui-Yu Zhu"], "title": "Quantum Treatment of Black Hole Superradiance", "comment": "20 pages, 3 figures", "summary": "Rotating black holes can form dense boson clouds through superradiant instability, making Kerr black holes a powerful probe of ultralight massive bosons. Previous studies of black hole superradiance have often treated bosonic fields classically, leaving open questions about how particles are produced and how the clouds grow over time. In this work, we canonically quantize a massive scalar field around a Kerr black hole, providing a fully quantum description of black hole superradiance. We show that the evolution of the particle number in the cloud, as well as the energy and angular momentum of the scalar field, can be consistently explained within the standard framework of quantum field theory in curved spacetime. Furthermore, we prove that the growth of the cloud occurs independently of the choice of initial state. We also explore several phenomena related to a massive scalar field in a rotating black hole spacetime, including Hawking radiation, adiabatic backreaction on the black hole spin, and the direction of level transitions in the presence of self-interactions of the field. Our analysis provides a consistent quantum-mechanical perspective that includes all these phenomena.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u514b\u5c14\u9ed1\u6d1e\u5468\u56f4\u7684\u6807\u91cf\u573a\u8fdb\u884c\u6b63\u5219\u91cf\u5b50\u5316\uff0c\u63d0\u4f9b\u4e86\u9ed1\u6d1e\u8d85\u8f90\u5c04\u7684\u5b8c\u6574\u91cf\u5b50\u63cf\u8ff0\uff0c\u8bc1\u660e\u4e86\u7c92\u5b50\u4e91\u7684\u6f14\u5316\u4e0e\u521d\u59cb\u6001\u65e0\u5173\uff0c\u5e76\u63a2\u8ba8\u4e86\u76f8\u5173\u91cf\u5b50\u73b0\u8c61\u3002", "motivation": "\u5148\u524d\u5173\u4e8e\u9ed1\u6d1e\u8d85\u8f90\u5c04\u7684\u7814\u7a76\u591a\u5c06\u73bb\u8272\u573a\u89c6\u4e3a\u7ecf\u5178\u573a\uff0c\u672a\u80fd\u89e3\u91ca\u7c92\u5b50\u5982\u4f55\u4ea7\u751f\u4ee5\u53ca\u4e91\u5982\u4f55\u968f\u65f6\u95f4\u589e\u957f\u3002\u9700\u8981\u4ece\u91cf\u5b50\u573a\u8bba\u89d2\u5ea6\u63d0\u4f9b\u5b8c\u6574\u7684\u91cf\u5b50\u63cf\u8ff0\u3002", "method": "\u5bf9\u514b\u5c14\u9ed1\u6d1e\u5468\u56f4\u7684\u6709\u8d28\u91cf\u6807\u91cf\u573a\u8fdb\u884c\u6b63\u5219\u91cf\u5b50\u5316\uff0c\u5728\u5f2f\u66f2\u65f6\u7a7a\u91cf\u5b50\u573a\u8bba\u6846\u67b6\u4e0b\u5206\u6790\u7c92\u5b50\u6570\u3001\u80fd\u91cf\u548c\u89d2\u52a8\u91cf\u7684\u6f14\u5316\u3002", "result": "\u8bc1\u660e\u4e86\u7c92\u5b50\u4e91\u7684\u589e\u957f\u4e0e\u521d\u59cb\u6001\u9009\u62e9\u65e0\u5173\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u89e3\u91ca\u6807\u91cf\u573a\u7684\u6f14\u5316\uff0c\u5e76\u63a2\u8ba8\u4e86\u970d\u91d1\u8f90\u5c04\u3001\u7edd\u70ed\u53cd\u51b2\u548c\u81ea\u76f8\u4e92\u4f5c\u7528\u4e0b\u7684\u80fd\u7ea7\u8dc3\u8fc1\u65b9\u5411\u7b49\u73b0\u8c61\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9ed1\u6d1e\u8d85\u8f90\u5c04\u63d0\u4f9b\u4e86\u81ea\u6d3d\u7684\u91cf\u5b50\u529b\u5b66\u89c6\u89d2\uff0c\u7edf\u4e00\u4e86\u5305\u62ec\u970d\u91d1\u8f90\u5c04\u5728\u5185\u7684\u591a\u79cd\u76f8\u5173\u73b0\u8c61\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u91cf\u5b50\u63cf\u8ff0\u6846\u67b6\u3002"}}
{"id": "2512.06154", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.06154", "abs": "https://arxiv.org/abs/2512.06154", "authors": ["Barproda Halder", "Pasan Dissanayake", "Sanghamitra Dutta"], "title": "Learning Invariant Graph Representations Through Redundant Information", "comment": null, "summary": "Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.", "AI": {"tldr": "\u63d0\u51faRIG\u6846\u67b6\uff0c\u5229\u7528\u90e8\u5206\u4fe1\u606f\u5206\u89e3(PID)\u8bc6\u522b\u5197\u4f59\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u7ea7\u4f18\u5316\u5b66\u4e60\u4e0d\u53d8\u56fe\u8868\u793a\uff0c\u63d0\u5347OOD\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ecf\u5178\u4fe1\u606f\u8bba\u7684\u65b9\u6cd5\u5728OOD\u56fe\u6cdb\u5316\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u5b66\u4e60\u5230\u7684\u8868\u793a\u5e38\u4fdd\u7559\u865a\u5047\u6210\u5206\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u5730\u8bc6\u522b\u865a\u5047\u5b50\u56fe\u548c\u4e0d\u53d8\u5b50\u56fe\u4e4b\u95f4\u7684\u5197\u4f59\u4fe1\u606f", "method": "\u63d0\u51faRIG\u6846\u67b6\uff1a1)\u4f7f\u7528PID\u8bc6\u522b\u865a\u5047\u5b50\u56feG_s\u548c\u4e0d\u53d8\u5b50\u56feG_c\u4e4b\u95f4\u7684\u5197\u4f59\u4fe1\u606f\uff1b2)\u91c7\u7528\u591a\u7ea7\u4f18\u5316\uff0c\u4ea4\u66ff\u4f30\u8ba1\u5197\u4f59\u4fe1\u606f\u4e0b\u754c\u5e76\u6700\u5927\u5316\u8be5\u4e0b\u754c\uff1b3)\u540c\u65f6\u9694\u79bb\u865a\u5047\u548c\u56e0\u679c\u5b50\u56fe", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRIG\u6846\u67b6\u5728\u5404\u79cd\u5206\u5e03\u504f\u79fb\u4e0b\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "PID\u4e3a\u4e0d\u53d8\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0cRIG\u6846\u67b6\u901a\u8fc7\u7cbe\u786e\u5904\u7406\u5197\u4f59\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u4e86OOD\u6cdb\u5316\u6027\u80fd"}}
{"id": "2512.06285", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.06285", "abs": "https://arxiv.org/abs/2512.06285", "authors": ["Md Sakibul Islam", "Kuldeep Singh", "Yunhe Zhao", "Nitesh Singh", "Wayesh Qarony"], "title": "Spin-photon Qubits for Scalable Quantum Network", "comment": "67 pages, 9 figures, Review", "summary": "Solid-state quantum light sources offer a scalable pathway for interfacing stationary spin qubits with flying photonic qubits, forming the backbone of future quantum networks. Telecom-band spin-photonic qubits, operating in the 1260-1675 nm wavelength range, are particularly well-suited for long-distance quantum communication due to minimal loss in standard optical fibers. Achieving scalability, however, hinges on fulfilling several stringent criteria: coherent spin-state control, deterministic and indistinguishable single-photon emission, and integration with nanophotonic structures that enhance radiative properties, such as lifetime, coherence, and photon indistinguishability. This study explores the state-of-the-art spin-photonic qubits across solid-state platforms, including diamond color centers, silicon carbide defect centers, quantum dots, and two-dimensional materials. Special attention is given to silicon-based emitters, particularly G, T, C- and Ci-centers, which promise monolithic integration with complementary metal-oxide-semiconductor (CMOS) technology and telecom-band operation. We classify these systems based on spin-photon interface availability, CMOS process compatibility, and emitter scalability. We also discuss recent advances in cavity quantum electrodynamics (cQED), including Purcell enhancement and quality factor engineering in integrated photonic (circuits) environments. The work highlights emerging demonstrations of quantum networking over metropolitan scales and outlines the trajectory toward chip-scale quantum photonic integrated circuits (QPICs). It combines deterministic emitter creation, coherent spin manipulation, and quantum information processing. These developments pave the way for global quantum networks, enabling secure communication, distributed quantum computing, and quantum-enhanced sensing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u56fa\u6001\u91cf\u5b50\u5149\u6e90\u5728\u6784\u5efa\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u7279\u522b\u5173\u6ce8\u7535\u4fe1\u6ce2\u6bb5\u81ea\u65cb-\u5149\u5b50\u91cf\u5b50\u6bd4\u7279\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6750\u6599\u5e73\u53f0\uff08\u91d1\u521a\u77f3\u3001\u78b3\u5316\u7845\u3001\u91cf\u5b50\u70b9\u3001\u4e8c\u7ef4\u6750\u6599\uff09\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u7845\u57fa\u53d1\u5c04\u5668\u4e0eCMOS\u6280\u672f\u7684\u96c6\u6210\u6f5c\u529b\uff0c\u5e76\u5c55\u671b\u4e86\u91cf\u5b50\u5149\u5b50\u96c6\u6210\u7535\u8def\u7684\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u6784\u5efa\u672a\u6765\u91cf\u5b50\u7f51\u7edc\u9700\u8981\u53ef\u6269\u5c55\u7684\u56fa\u6001\u91cf\u5b50\u5149\u6e90\uff0c\u8fd9\u4e9b\u5149\u6e90\u80fd\u591f\u5c06\u9759\u6b62\u7684\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u4e0e\u98de\u884c\u7684\u5149\u5b50\u91cf\u5b50\u6bd4\u7279\u8fde\u63a5\u8d77\u6765\u3002\u7535\u4fe1\u6ce2\u6bb5\uff081260-1675 nm\uff09\u7684\u81ea\u65cb-\u5149\u5b50\u91cf\u5b50\u6bd4\u7279\u7531\u4e8e\u5728\u6807\u51c6\u5149\u7ea4\u4e2d\u635f\u8017\u6700\u5c0f\uff0c\u7279\u522b\u9002\u5408\u957f\u8ddd\u79bb\u91cf\u5b50\u901a\u4fe1\u3002\u7136\u800c\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u9700\u8981\u6ee1\u8db3\u591a\u4e2a\u4e25\u683c\u8981\u6c42\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u56fa\u6001\u5e73\u53f0\uff08\u5305\u62ec\u91d1\u521a\u77f3\u8272\u5fc3\u3001\u78b3\u5316\u7845\u7f3a\u9677\u4e2d\u5fc3\u3001\u91cf\u5b50\u70b9\u3001\u4e8c\u7ef4\u6750\u6599\uff09\u4e2d\u6700\u5148\u8fdb\u7684\u81ea\u65cb-\u5149\u5b50\u91cf\u5b50\u6bd4\u7279\u6280\u672f\u3002\u7279\u522b\u5173\u6ce8\u7845\u57fa\u53d1\u5c04\u5668\uff08G\u3001T\u3001C-\u548cCi-\u4e2d\u5fc3\uff09\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u6709\u671b\u4e0eCMOS\u6280\u672f\u5355\u7247\u96c6\u6210\u5e76\u5728\u7535\u4fe1\u6ce2\u6bb5\u5de5\u4f5c\u3002\u7814\u7a76\u6839\u636e\u81ea\u65cb-\u5149\u5b50\u63a5\u53e3\u53ef\u7528\u6027\u3001CMOS\u5de5\u827a\u517c\u5bb9\u6027\u548c\u53d1\u5c04\u5668\u53ef\u6269\u5c55\u6027\u5bf9\u8fd9\u4e9b\u7cfb\u7edf\u8fdb\u884c\u5206\u7c7b\u3002\u540c\u65f6\u8ba8\u8bba\u4e86\u8154\u91cf\u5b50\u7535\u52a8\u529b\u5b66\uff08cQED\uff09\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ecPurcell\u589e\u5f3a\u548c\u96c6\u6210\u5149\u5b50\u73af\u5883\u4e2d\u7684\u54c1\u8d28\u56e0\u6570\u5de5\u7a0b\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u4e0d\u540c\u56fa\u6001\u5e73\u53f0\u5728\u5b9e\u73b0\u76f8\u5e72\u81ea\u65cb\u63a7\u5236\u3001\u786e\u5b9a\u6027\u4e0d\u53ef\u533a\u5206\u5355\u5149\u5b50\u53d1\u5c04\u4ee5\u53ca\u4e0e\u7eb3\u7c73\u5149\u5b50\u7ed3\u6784\u96c6\u6210\u65b9\u9762\u7684\u8fdb\u5c55\u3002\u7279\u522b\u5f3a\u8c03\u4e86\u7845\u57fa\u53d1\u5c04\u5668\u5728CMOS\u517c\u5bb9\u6027\u548c\u7535\u4fe1\u6ce2\u6bb5\u64cd\u4f5c\u65b9\u9762\u7684\u4f18\u52bf\u3002\u7814\u7a76\u8fd8\u603b\u7ed3\u4e86\u91cf\u5b50\u7f51\u7edc\u5728\u57ce\u57df\u5c3a\u5ea6\u4e0a\u7684\u65b0\u5174\u6f14\u793a\uff0c\u4ee5\u53ca\u5411\u82af\u7247\u7ea7\u91cf\u5b50\u5149\u5b50\u96c6\u6210\u7535\u8def\uff08QPICs\uff09\u53d1\u5c55\u7684\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u5168\u7403\u91cf\u5b50\u7f51\u7edc\u7684\u53d1\u5c55\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u8fd9\u4e9b\u7f51\u7edc\u5c06\u5b9e\u73b0\u5b89\u5168\u901a\u4fe1\u3001\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u548c\u91cf\u5b50\u589e\u5f3a\u4f20\u611f\u3002\u901a\u8fc7\u7ed3\u5408\u786e\u5b9a\u6027\u53d1\u5c04\u5668\u521b\u5efa\u3001\u76f8\u5e72\u81ea\u65cb\u64cd\u7eb5\u548c\u91cf\u5b50\u4fe1\u606f\u5904\u7406\uff0c\u56fa\u6001\u91cf\u5b50\u5149\u6e90\u6280\u672f\u6b63\u5728\u671d\u7740\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u5149\u5b50\u96c6\u6210\u7535\u8def\u65b9\u5411\u53d1\u5c55\uff0c\u8fd9\u5c06\u6210\u4e3a\u672a\u6765\u91cf\u5b50\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u7684\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u3002"}}
{"id": "2512.06807", "categories": ["gr-qc", "astro-ph.CO", "astro-ph.HE", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.06807", "abs": "https://arxiv.org/abs/2512.06807", "authors": ["Rajesh Karmakar", "Kaustubh Mukund Vispute", "Debaprasad Maity"], "title": "Extreme mass ratio inspirals in the cold vector dark matter environment", "comment": "33pages,7figures", "summary": "With regard to the observed dark matter density profile in galaxies and clusters, the scalar dark matter scenario has been previously studied for potential detectability through gravitational wave observations at measurable signal-to-noise ratios. In the present study, we consider the case of dark matter described by a massive vector field, also referred to as the Proca field. The density profile in the vicinity of the black hole is explicitly constructed for a broad range of dark matter mass, $\u03bc\\sim 10^{-10}-10^{-15}{\\mathrm eV}$, which allows it to exhibit both particle and wave-like characteristics. While in the particle regime, the computation of the DM density distribution is analytically tractable, we find it convenient to compute the same numerically in the wave regime. Nevertheless, in the outer region, the surrounding dark matter is assumed to follow a broken power-law distribution, represented by a Navarro-Frenk-White (NFW) profile with a central spike. For the purpose of investigating the detectability of the vector dark matter in the gravitational wave spectrum, we have modelled a stellar-mass black hole ($1M_{\\odot}$) inspiralling into a Schwarzschild black hole of mass $10^4M_{\\odot}$ within such a vector dark matter environment. With this setup, we analyzed the dephasing in the gravitational wave strain induced by vector dark matter and performed a Fisher forecast for upcoming LISA observations, with particular emphasis on the distinctive features in both the particle and wave regimes of the dark matter. Additionally, most of the important results have been compared with the scalar dark matter case.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u77e2\u91cf\u6697\u7269\u8d28\uff08Proca\u573a\uff09\u5bf9\u5f15\u529b\u6ce2\u89c2\u6d4b\u7684\u5f71\u54cd\uff0c\u5206\u6790\u5176\u5728\u7c92\u5b50\u6001\u548c\u6ce2\u52a8\u6001\u4e0b\u7684\u5bc6\u5ea6\u5206\u5e03\uff0c\u5e76\u901a\u8fc7LISA\u89c2\u6d4b\u9884\u6d4b\u63a2\u6d4b\u53ef\u80fd\u6027\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u5df2\u63a2\u8ba8\u6807\u91cf\u6697\u7269\u8d28\u901a\u8fc7\u5f15\u529b\u6ce2\u89c2\u6d4b\u7684\u53ef\u63a2\u6d4b\u6027\uff0c\u672c\u7814\u7a76\u6269\u5c55\u81f3\u77e2\u91cf\u6697\u7269\u8d28\uff08Proca\u573a\uff09\uff0c\u65e8\u5728\u5206\u6790\u5176\u5728\u9ed1\u6d1e\u9644\u8fd1\u7684\u5bc6\u5ea6\u5206\u5e03\u53ca\u5176\u5bf9\u5f15\u529b\u6ce2\u76f8\u4f4d\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u77e2\u91cf\u6697\u7269\u8d28\u5728\u9ed1\u6d1e\u9644\u8fd1\u7684\u5bc6\u5ea6\u5206\u5e03\uff08\u8d28\u91cf\u8303\u56f410^{-10}-10^{-15} eV\uff09\uff0c\u6570\u503c\u8ba1\u7b97\u6ce2\u52a8\u6001\u5206\u5e03\uff0c\u5047\u8bbe\u5916\u56f4\u6697\u7269\u8d28\u9075\u5faa\u5e26\u4e2d\u5fc3\u5c16\u5cf0\u7684NFW\u5206\u5e03\u3002\u5efa\u7acb\u6052\u661f\u8d28\u91cf\u9ed1\u6d1e\uff081M\u2299\uff09\u5411\u53f2\u74e6\u897f\u9ed1\u6d1e\uff0810^4M\u2299\uff09\u65cb\u8fdb\u7684\u6a21\u578b\uff0c\u5206\u6790\u5f15\u529b\u6ce2\u5e94\u53d8\u4e2d\u7684\u76f8\u4f4d\u504f\u79fb\uff0c\u5e76\u8fdb\u884cLISA\u89c2\u6d4b\u7684Fisher\u9884\u6d4b\u3002", "result": "\u8ba1\u7b97\u4e86\u77e2\u91cf\u6697\u7269\u8d28\u5728\u7c92\u5b50\u6001\u548c\u6ce2\u52a8\u6001\u4e0b\u7684\u5bc6\u5ea6\u5206\u5e03\uff0c\u5206\u6790\u4e86\u5176\u5bf9\u5f15\u529b\u6ce2\u76f8\u4f4d\u7684\u53bb\u76f8\u4f4d\u6548\u5e94\uff0c\u901a\u8fc7Fisher\u9884\u6d4b\u8bc4\u4f30\u4e86LISA\u89c2\u6d4b\u7684\u53ef\u63a2\u6d4b\u6027\uff0c\u5e76\u4e0e\u6807\u91cf\u6697\u7269\u8d28\u6848\u4f8b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u77e2\u91cf\u6697\u7269\u8d28\u5728\u5f15\u529b\u6ce2\u8c31\u4e2d\u5177\u6709\u53ef\u63a2\u6d4b\u7279\u5f81\uff0c\u7279\u522b\u662f\u5728\u7c92\u5b50\u6001\u548c\u6ce2\u52a8\u6001\u4e0b\u8868\u73b0\u51fa\u4e0d\u540c\u7279\u6027\uff0cLISA\u89c2\u6d4b\u6709\u671b\u63a2\u6d4b\u6b64\u7c7b\u4fe1\u53f7\uff0c\u4e3a\u6697\u7269\u8d28\u6027\u8d28\u7814\u7a76\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.06183", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06183", "abs": "https://arxiv.org/abs/2512.06183", "authors": ["Lindong Liu", "Zhixiong Jin", "Seongjin Choi"], "title": "PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations", "comment": null, "summary": "High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.", "AI": {"tldr": "PMA-Diffusion\uff1a\u4e00\u79cd\u7269\u7406\u5f15\u5bfc\u7684\u63a9\u7801\u611f\u77e5\u6269\u6563\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7a00\u758f\u89c2\u6d4b\u4e2d\u91cd\u5efa\u9ad8\u901f\u516c\u8def\u901f\u5ea6\u573a\uff0c\u57285%\u53ef\u89c1\u5ea6\u4e0b\u4ecd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u72b6\u6001\u4fe1\u606f\u5bf9\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6570\u636e\uff08\u5982\u73af\u5f62\u68c0\u6d4b\u5668\u548c\u63a2\u6d4b\u8f66\u8f86\uff09\u901a\u5e38\u8fc7\u4e8e\u7a00\u758f\u548c\u5608\u6742\uff0c\u65e0\u6cd5\u6355\u6349\u4ea4\u901a\u6d41\u7684\u8be6\u7ec6\u52a8\u6001\u3002", "method": "\u63d0\u51faPMA-Diffusion\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u79cd\u63a9\u7801\u611f\u77e5\u8bad\u7ec3\u7b56\u7565\uff08\u5355\u63a9\u7801\u548c\u53cc\u63a9\u7801\uff09\u76f4\u63a5\u5728\u7a00\u758f\u89c2\u6d4b\u7684\u901f\u5ea6\u573a\u4e0a\u8bad\u7ec3\u6269\u6563\u5148\u9a8c\u3002\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u7269\u7406\u5f15\u5bfc\u7684\u540e\u9a8c\u91c7\u6837\u5668\uff0c\u4ea4\u66ff\u8fdb\u884c\u53cd\u5411\u6269\u6563\u66f4\u65b0\u3001\u89c2\u6d4b\u6295\u5f71\u548c\u57fa\u4e8e\u81ea\u9002\u5e94\u5404\u5411\u5f02\u6027\u5e73\u6ed1\u7684\u7269\u7406\u5f15\u5bfc\u6295\u5f71\u3002", "result": "\u5728I-24 MOTION\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5373\u4f7f\u53ea\u67095%\u53ef\u89c1\u5ea6\u7684\u6781\u7aef\u7a00\u758f\u60c5\u51b5\u4e0b\uff0cPMA-Diffusion\u5728\u4e09\u4e2a\u91cd\u5efa\u8bef\u5dee\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002\u4f7f\u7528\u7a00\u758f\u89c2\u6d4b\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u57fa\u4e8e\u5b8c\u6574\u89c2\u6d4b\u8bad\u7ec3\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u5c06\u63a9\u7801\u611f\u77e5\u6269\u6563\u5148\u9a8c\u4e0e\u7269\u7406\u5f15\u5bfc\u540e\u9a8c\u91c7\u6837\u5668\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u9645\u4f20\u611f\u7a00\u758f\u6761\u4ef6\u4e0b\u7684\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.06295", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06295", "abs": "https://arxiv.org/abs/2512.06295", "authors": ["Angelina N. Mendoza Tavera", "Adrian M. Escobar Ruiz", "Robin P. Sagar"], "title": "Wigner-Husimi phase-space structure of quasi-exactly solvable sextic potential", "comment": "38 pages, 15 figures", "summary": "In this study, we compare the Wigner function $W$, its modulus, and the Husimi distribution $H$ in a one-dimensional quantum system exhibiting a transition from a single-well to a double-well configuration, using the quasi-exactly solvable sextic oscillator as a representative example. High-accuracy variational wavefunctions for the lowest states are used to compute two-dimensional phase-space structures, one-dimensional marginals, and the corresponding Shannon entropies, mutual information, and Cumulative Residual Jeffreys divergences. The analysis shows that the Wigner representation is uniquely responsive to interference effects and displays clear, nonmonotonic entropic behavior as the wells separate, whereas the modulus-Wigner and Husimi distributions account only for geometric splitting or coarse-grained delocalization. These findings establish a quantitative hierarchy in the ability of $W$, $|W|$, and $H$ to resolve structural changes in a quantum state and provide a general framework for assessing the descriptive power of different phase-space representations in systems with emerging bimodality or tunneling.", "AI": {"tldr": "\u6bd4\u8f83Wigner\u51fd\u6570\u3001\u5176\u6a21\u548cHusimi\u5206\u5e03\u5728\u5355\u9631\u5230\u53cc\u9631\u8f6c\u53d8\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Wigner\u51fd\u6570\u5bf9\u5e72\u6d89\u6548\u5e94\u6700\u654f\u611f\uff0c\u80fd\u663e\u793a\u975e\u5355\u8c03\u71b5\u884c\u4e3a\uff0c\u800c\u6a21Wigner\u548cHusimi\u5206\u5e03\u4ec5\u53cd\u6620\u51e0\u4f55\u5206\u88c2\u6216\u7c97\u7c92\u5316\u79bb\u57df\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u76f8\u7a7a\u95f4\u8868\u793a\uff08Wigner\u51fd\u6570\u3001\u5176\u6a21\u3001Husimi\u5206\u5e03\uff09\u5728\u91cf\u5b50\u7cfb\u7edf\u4ece\u5355\u9631\u5230\u53cc\u9631\u8f6c\u53d8\u8fc7\u7a0b\u4e2d\u63cf\u8ff0\u7ed3\u6784\u53d8\u5316\u7684\u80fd\u529b\u5dee\u5f02\uff0c\u5efa\u7acb\u8bc4\u4f30\u4e0d\u540c\u76f8\u7a7a\u95f4\u8868\u793a\u63cf\u8ff0\u80fd\u529b\u7684\u5b9a\u91cf\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u51c6\u7cbe\u786e\u53ef\u89e3\u516d\u6b21\u632f\u5b50\u4f5c\u4e3a\u4ee3\u8868\u7cfb\u7edf\uff0c\u91c7\u7528\u9ad8\u7cbe\u5ea6\u53d8\u5206\u6ce2\u51fd\u6570\u8ba1\u7b97\u6700\u4f4e\u6001\uff0c\u5206\u6790\u4e8c\u7ef4\u76f8\u7a7a\u95f4\u7ed3\u6784\u3001\u4e00\u7ef4\u8fb9\u9645\u5206\u5e03\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u9999\u519c\u71b5\u3001\u4e92\u4fe1\u606f\u548c\u7d2f\u79ef\u6b8b\u5deeJeffreys\u6563\u5ea6\u3002", "result": "Wigner\u8868\u793a\u5bf9\u5e72\u6d89\u6548\u5e94\u54cd\u5e94\u72ec\u7279\uff0c\u5728\u9631\u5206\u79bb\u65f6\u663e\u793a\u6e05\u6670\u975e\u5355\u8c03\u71b5\u884c\u4e3a\uff1b\u6a21Wigner\u548cHusimi\u5206\u5e03\u4ec5\u80fd\u63cf\u8ff0\u51e0\u4f55\u5206\u88c2\u6216\u7c97\u7c92\u5316\u79bb\u57df\u3002\u5efa\u7acb\u4e86W\u3001|W|\u548cH\u5728\u89e3\u6790\u91cf\u5b50\u6001\u7ed3\u6784\u53d8\u5316\u80fd\u529b\u4e0a\u7684\u5b9a\u91cf\u5c42\u6b21\u3002", "conclusion": "Wigner\u51fd\u6570\u5728\u63cf\u8ff0\u91cf\u5b50\u6001\u7ed3\u6784\u53d8\u5316\u65b9\u9762\u6700\u5177\u63cf\u8ff0\u529b\uff0c\u7279\u522b\u5bf9\u5e72\u6d89\u6548\u5e94\u654f\u611f\uff0c\u4e3a\u8bc4\u4f30\u4e0d\u540c\u76f8\u7a7a\u95f4\u8868\u793a\u5728\u53cc\u6a21\u6216\u96a7\u7a7f\u7cfb\u7edf\u4e2d\u7684\u63cf\u8ff0\u80fd\u529b\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2512.06903", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06903", "abs": "https://arxiv.org/abs/2512.06903", "authors": ["Libo Xie", "Li-Ming Cao", "Ming-Fei Ji", "Yu-Sen Zhou", "Liang-Bi Wu"], "title": "Quasinormal modes of Schwarzschild-de Sitter black holes in semi-open systems", "comment": "17 pages, 8 figures, 1 table", "summary": "We study perturbations of Schwarzschild-de Sitter black holes in semi-open systems by using the Heun functions. For the semi-open system, a partially reflective wall is added around the event horizon. Three aspects of this model are investigated, namely the quasinormal mode (QNM) spectra, the greybody factor (GF), and the exceptional point (EP). For the QNM aspect, we identify three distinct behaviors as the frequency-independent reflectivity $\\mathcal{K}$ increasing. The first-type modes approach the real axis and form long-lived quasi-bound states. The second-type modes move toward but do not reach the real axis and retain a finite decay rate. The third-type modes eventually lie on the imaginary axis becoming purely decaying modes. For the GF aspect, GFs exhibit strong oscillations controlled by the distance between the potential and the reflective wall with a real constant reflectivity. In contrast, a Boltzmann-type reflectivity produces only small corrections. Finally, by promoting $\\mathcal{K}$ to a complex parameter, the modified boundary conditions give rise to a second-order EP. Parameterizing the vicinity of such EP, we observe the mode exchange phenomenon, and the deviation of spectra scale with the square root of the deviation of the parameter, as predicted by a Puiseux series expansion.", "AI": {"tldr": "\u4f7f\u7528Heun\u51fd\u6570\u7814\u7a76\u534a\u5f00\u653e\u7cfb\u7edf\u4e2dSchwarzschild-de Sitter\u9ed1\u6d1e\u7684\u6270\u52a8\uff0c\u5206\u6790\u51c6\u6b63\u89c4\u6a21\u8c31\u3001\u7070\u4f53\u56e0\u5b50\u548c\u5f02\u5e38\u70b9\u4e09\u4e2a\u65b9\u9762\u7684\u884c\u4e3a\u7279\u5f81\u3002", "motivation": "\u7814\u7a76\u5728\u4e8b\u4ef6\u89c6\u754c\u9644\u8fd1\u6dfb\u52a0\u90e8\u5206\u53cd\u5c04\u58c1\u7684\u534a\u5f00\u653e\u7cfb\u7edf\u4e2d\u9ed1\u6d1e\u6270\u52a8\u7684\u7269\u7406\u7279\u6027\uff0c\u63a2\u7d22\u53cd\u5c04\u8fb9\u754c\u6761\u4ef6\u5bf9\u9ed1\u6d1e\u52a8\u529b\u5b66\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528Heun\u51fd\u6570\u5206\u6790Schwarzschild-de Sitter\u9ed1\u6d1e\u5728\u534a\u5f00\u653e\u7cfb\u7edf\u4e2d\u7684\u6270\u52a8\uff0c\u901a\u8fc7\u5f15\u5165\u9891\u7387\u65e0\u5173\u53cd\u5c04\u7387\u53c2\u6570\ud835\udca6\uff0c\u7814\u7a76\u51c6\u6b63\u89c4\u6a21\u8c31\u3001\u7070\u4f53\u56e0\u5b50\u548c\u5f02\u5e38\u70b9\u7684\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u51c6\u6b63\u89c4\u6a21\u884c\u4e3a\uff1a\u7b2c\u4e00\u7c7b\u6a21\u5f0f\u8d8b\u8fd1\u5b9e\u8f74\u5f62\u6210\u957f\u5bff\u547d\u51c6\u675f\u7f1a\u6001\uff1b\u7b2c\u4e8c\u7c7b\u6a21\u5f0f\u8d8b\u8fd1\u4f46\u4e0d\u63a5\u89e6\u5b9e\u8f74\u4fdd\u6301\u6709\u9650\u8870\u51cf\u7387\uff1b\u7b2c\u4e09\u7c7b\u6a21\u5f0f\u6700\u7ec8\u4f4d\u4e8e\u865a\u8f74\u6210\u4e3a\u7eaf\u8870\u51cf\u6a21\u5f0f\u3002\u7070\u4f53\u56e0\u5b50\u8868\u73b0\u51fa\u7531\u52bf\u5792\u4e0e\u53cd\u5c04\u58c1\u8ddd\u79bb\u63a7\u5236\u7684\u5f3a\u632f\u8361\uff0c\u800cBoltzmann\u578b\u53cd\u5c04\u7387\u4ec5\u4ea7\u751f\u5c0f\u4fee\u6b63\u3002\u901a\u8fc7\u5c06\ud835\udca6\u63a8\u5e7f\u4e3a\u590d\u53c2\u6570\uff0c\u89c2\u5bdf\u5230\u4e8c\u9636\u5f02\u5e38\u70b9\u9644\u8fd1\u7684\u6a21\u5f0f\u4ea4\u6362\u73b0\u8c61\u3002", "conclusion": "\u534a\u5f00\u653e\u7cfb\u7edf\u4e2d\u53cd\u5c04\u8fb9\u754c\u6761\u4ef6\u663e\u8457\u5f71\u54cd\u9ed1\u6d1e\u6270\u52a8\u7279\u6027\uff0c\u4ea7\u751f\u4e30\u5bcc\u7684\u7269\u7406\u73b0\u8c61\uff0c\u5305\u62ec\u51c6\u6b63\u89c4\u6a21\u8c31\u7684\u591a\u6837\u5316\u884c\u4e3a\u3001\u7070\u4f53\u56e0\u5b50\u7684\u632f\u8361\u7279\u6027\u4ee5\u53ca\u5f02\u5e38\u70b9\u9644\u8fd1\u7684\u6a21\u5f0f\u4ea4\u6362\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u9ed1\u6d1e\u7269\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.06200", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06200", "abs": "https://arxiv.org/abs/2512.06200", "authors": ["Tomohiro Yamashita", "Daichi Amagata", "Yusuke Matsui"], "title": "How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?", "comment": "4 pages, 4 figures. Accepted at NeurIPS 2025 Workshop on Machine Learning for Systems", "summary": "Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8bc4\u4f30ANNS\u7d22\u5f15\u6570\u636e\u5220\u9664\u6548\u7387\u7684\u5b9e\u9a8c\u6846\u67b6\u548c\u7efc\u5408\u8bc4\u4f30\u6307\u6807\uff0c\u5c06\u56fe\u57faANNS\u7684\u6570\u636e\u5220\u9664\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\u5e76\u6570\u5b66\u5f62\u5f0f\u5316\uff0c\u5e94\u7528\u4e8eHNSW\u5206\u6790\u5220\u9664\u6548\u679c\uff0c\u63d0\u51fa\u52a8\u6001\u9009\u62e9\u5220\u9664\u65b9\u6cd5\u7684Deletion Control\u65b9\u6cd5", "motivation": "\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u5728\u52a8\u6001\u6570\u636e\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u6570\u636e\u5220\u9664\u7684\u7efc\u5408\u8bc4\u4f30\u65b9\u6cd5\u3002\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30ANNS\u7d22\u5f15\u5728\u6570\u636e\u5220\u9664\u573a\u666f\u4e0b\u7684\u6027\u80fd", "method": "\u63d0\u51fa\u5b9e\u9a8c\u6846\u67b6\u548c\u7efc\u5408\u8bc4\u4f30\u6307\u6807\uff0c\u5c06\u56fe\u57faANNS\u7684\u6570\u636e\u5220\u9664\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\u5e76\u6570\u5b66\u5f62\u5f0f\u5316\uff0c\u5728\u51c6\u786e\u6027\u3001\u67e5\u8be2\u901f\u5ea6\u7b49\u6307\u6807\u4e0a\u8bc4\u4f30\u6027\u80fd\uff0c\u5e94\u7528\u4e8eHNSW\u5206\u6790\u5220\u9664\u6548\u679c\uff0c\u63d0\u51faDeletion Control\u65b9\u6cd5\u52a8\u6001\u9009\u62e9\u5220\u9664\u7b56\u7565", "result": "\u5efa\u7acb\u4e86ANNS\u6570\u636e\u5220\u9664\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u4e86\u4e09\u79cd\u5220\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7HNSW\u5b9e\u9a8c\u5206\u6790\u4e86\u6570\u636e\u5220\u9664\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u7684Deletion Control\u65b9\u6cd5\u80fd\u5728\u4fdd\u6301\u641c\u7d22\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u52a8\u6001\u9009\u62e9\u6700\u4f18\u5220\u9664\u7b56\u7565", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86ANNS\u6570\u636e\u5220\u9664\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u548cDeletion Control\u65b9\u6cd5\u4e3a\u52a8\u6001ANNS\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e73\u8861\u5220\u9664\u6548\u7387\u548c\u641c\u7d22\u6027\u80fd"}}
{"id": "2512.06298", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06298", "abs": "https://arxiv.org/abs/2512.06298", "authors": ["Fatemeh Lajevardi", "Azam Mani", "Ali Fahim"], "title": "Entanglement Witness Derived By Using Kolmogorov-Arnold Networks", "comment": "Published in: 2025 33rd International Conference on Electrical Engineering (ICEE), Publisher IEEE", "summary": "We utilize Kolmogorov-Arnold Networks to design an interpretable model capable of detecting quantum entanglement within a set of nine-parameter two-qubit states. This network serves as an entanglement witness, achieving an accuracy of $94\\%$ in distinguishing entangled states. Additionally, by analyzing the output functions of the KAN models, we explore the significance of each parameter (feature) in identifying the presence of entanglement. This analysis enables us to rank the features and eliminate the less significant ones, leading to the development of new entanglement witness functions that rely on fewer number of features, and hence do not require complete state tomography for their evaluation.", "AI": {"tldr": "\u4f7f\u7528Kolmogorov-Arnold\u7f51\u7edc\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684\u91cf\u5b50\u7ea0\u7f20\u68c0\u6d4b\u6a21\u578b\uff0c\u5728\u4e5d\u53c2\u6570\u53cc\u91cf\u5b50\u6bd4\u7279\u6001\u4e2d\u8fbe\u523094%\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u7279\u5f81\u5206\u6790\u5f00\u53d1\u51fa\u9700\u8981\u66f4\u5c11\u53c2\u6570\u7684\u65b0\u7ea0\u7f20\u89c1\u8bc1\u51fd\u6570\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u91cf\u5b50\u7ea0\u7f20\u68c0\u6d4b\u6a21\u578b\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5b8c\u6574\u6001\u5c42\u6790\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u53cc\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u7684\u7ea0\u7f20\u72b6\u6001\uff0c\u51cf\u5c11\u68c0\u6d4b\u6240\u9700\u7684\u53c2\u6570\u6570\u91cf\u3002", "method": "\u4f7f\u7528Kolmogorov-Arnold\u7f51\u7edc\uff08KAN\uff09\u4f5c\u4e3a\u7ea0\u7f20\u89c1\u8bc1\u5668\uff0c\u5206\u6790\u4e5d\u53c2\u6570\u53cc\u91cf\u5b50\u6bd4\u7279\u6001\u3002\u901a\u8fc7\u5206\u6790KAN\u6a21\u578b\u7684\u8f93\u51fa\u51fd\u6570\uff0c\u8bc4\u4f30\u6bcf\u4e2a\u53c2\u6570\u5728\u8bc6\u522b\u7ea0\u7f20\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u57fa\u4e8e\u7279\u5f81\u91cd\u8981\u6027\u6392\u540d\u5f00\u53d1\u65b0\u7684\u7ea0\u7f20\u89c1\u8bc1\u51fd\u6570\u3002", "result": "KAN\u6a21\u578b\u5728\u533a\u5206\u7ea0\u7f20\u6001\u65b9\u9762\u8fbe\u523094%\u7684\u51c6\u786e\u7387\u3002\u901a\u8fc7\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\uff0c\u80fd\u591f\u8bc6\u522b\u51fa\u5bf9\u7ea0\u7f20\u68c0\u6d4b\u6700\u5173\u952e\u7684\u7279\u5f81\uff0c\u4ece\u800c\u5f00\u53d1\u51fa\u4ec5\u9700\u8f83\u5c11\u53c2\u6570\u7684\u65b0\u7ea0\u7f20\u89c1\u8bc1\u51fd\u6570\uff0c\u65e0\u9700\u5b8c\u6574\u6001\u5c42\u6790\u5373\u53ef\u8bc4\u4f30\u3002", "conclusion": "Kolmogorov-Arnold\u7f51\u7edc\u4e3a\u91cf\u5b50\u7ea0\u7f20\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u8fd8\u80fd\u901a\u8fc7\u7279\u5f81\u5206\u6790\u7b80\u5316\u7ea0\u7f20\u89c1\u8bc1\u51fd\u6570\uff0c\u964d\u4f4e\u5b9e\u9a8c\u8981\u6c42\uff0c\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u7ea0\u7f20\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.06908", "categories": ["gr-qc", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.06908", "abs": "https://arxiv.org/abs/2512.06908", "authors": ["Philippe G. LeFloch", "Filipe C. Mena"], "title": "A first-order formulation of f(R) gravity in spherical symmetry", "comment": "24 pages", "summary": "We develop a first-order formulation of the field equations in f(R) gravity governing the global evolution of a (possibly massive) scalar field under spherical symmetry. Our formulation allows us to pose the characteristic initial value problem and to establish several properties of solutions. More precisely, we work in generalized Bondi-Sachs coordinates and prescribe initial data on an asymptotically Euclidean, future light cone with vertex at the center of symmetry, and we identify the precise regularity conditions required at the center. Following and extending Christodoulou's approach to the Einstein-massless scalar-field system, we recast the f(R) field equations as an integro-differential system of two coupled, first-order, nonlocal, nonlinear hyperbolic equations, whose principal unknowns are the scalar field and the spacetime scalar curvature. In deriving this reduced two-equation system, we identify the regularity conditions at the center of symmetry and impose natural assumptions on the scalar-field potential and on the function f(R) governing the gravitational Lagrangian density. As an application, we prove the monotonicity of the Hawking mass in this setting and formally analyze the singular limit in which the integrand f(R) of the action approaches R, corresponding to the Einstein-Hilbert action. Hence, the formulation isolates the essential evolution and constraint content on the future domain of dependence of two null hypersurfaces and is designed to facilitate subsequent advances in geometric analysis and robust numerical simulations of spherical collapse in modified gravity.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86f(R)\u5f15\u529b\u4e2d\u7403\u5bf9\u79f0\u6807\u91cf\u573a\u6f14\u5316\u7684\u9996\u9636\u5f62\u5f0f\uff0c\u63d0\u51fa\u4e86\u7279\u5f81\u521d\u503c\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u970d\u91d1\u8d28\u91cf\u7684\u5355\u8c03\u6027\u3002", "motivation": "\u7814\u7a76f(R)\u4fee\u6b63\u5f15\u529b\u7406\u8bba\u4e2d\u7403\u5bf9\u79f0\u6807\u91cf\u573a\u7684\u5168\u5c40\u6f14\u5316\uff0c\u5efa\u7acb\u9002\u5408\u51e0\u4f55\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u7684\u6570\u5b66\u6846\u67b6\u3002", "method": "\u5728\u5e7f\u4e49Bondi-Sachs\u5750\u6807\u7cfb\u4e2d\uff0c\u5c06f(R)\u573a\u65b9\u7a0b\u91cd\u94f8\u4e3a\u4e24\u4e2a\u8026\u5408\u7684\u4e00\u9636\u975e\u5c40\u90e8\u975e\u7ebf\u6027\u53cc\u66f2\u65b9\u7a0b\u7cfb\u7edf\uff0c\u5904\u7406\u7279\u5f81\u521d\u503c\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86f(R)\u5f15\u529b\u4e2d\u7403\u5bf9\u79f0\u6807\u91cf\u573a\u6f14\u5316\u7684\u9996\u9636\u5f62\u5f0f\uff0c\u8bc1\u660e\u4e86\u970d\u91d1\u8d28\u91cf\u7684\u5355\u8c03\u6027\uff0c\u5206\u6790\u4e86f(R)\u2192R\u7684\u5947\u5f02\u6781\u9650\u3002", "conclusion": "\u8be5\u5f62\u5f0f\u5316\u65b9\u6cd5\u5206\u79bb\u4e86\u6f14\u5316\u65b9\u7a0b\u548c\u7ea6\u675f\u65b9\u7a0b\uff0c\u4e3a\u4fee\u6b63\u5f15\u529b\u4e2d\u7403\u5bf9\u79f0\u584c\u7f29\u7684\u51e0\u4f55\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2512.06201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06201", "abs": "https://arxiv.org/abs/2512.06201", "authors": ["K2 Team", "Zhengzhong Liu", "Liping Tang", "Linghao Jin", "Haonan Li", "Nikhil Ranjan", "Desai Fan", "Shaurya Rohatgi", "Richard Fan", "Omkar Pangarkar", "Huijuan Wang", "Zhoujun Cheng", "Suqi Sun", "Seungwook Han", "Bowen Tan", "Gurpreet Gosal", "Xudong Han", "Varad Pimpalkhute", "Shibo Hao", "Ming Shan Hee", "Joel Hestness", "Haolong Jia", "Liqun Ma", "Aaryamonvikram Singh", "Daria Soboleva", "Natalia Vassilieva", "Renxi Wang", "Yingquan Wu", "Yuekai Sun", "Taylor Killian", "Alexander Moreno", "John Maggs", "Hector Ren", "Guowei He", "Hongyi Wang", "Xuezhe Ma", "Yuqi Wang", "Mikhail Yurochkin", "Eric P. Xing"], "title": "K2-V2: A 360-Open, Reasoning-Enhanced LLM", "comment": null, "summary": "We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.", "AI": {"tldr": "K2-V2\u662f\u4e00\u4e2a\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u7684360\u5ea6\u5f00\u653eLLM\uff0c\u4f5c\u4e3a\u63a8\u7406\u9002\u5e94\u7684\u4f18\u79c0\u57fa\u7840\u6a21\u578b\uff0c\u572872B\u89c4\u6a21\u7ea7\u522b\u4e2d\u8868\u73b0\u6700\u5f3a\uff0c\u8d85\u8d8aQwen2.5-72B\u5e76\u63a5\u8fd1Qwen3-235B\u7684\u6027\u80fd\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u4e13\u95e8\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4f18\u5316\u7684\u5f00\u653e\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u5f3a\u5927\u7684\u63a8\u7406\u4e2d\u5fc3\u5316\u57fa\u7840\uff0c\u540c\u65f6\u652f\u6301\u5bf9\u8bdd\u3001\u77e5\u8bc6\u68c0\u7d22\u7b49\u901a\u7528\u529f\u80fd\u3002", "method": "\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e3b\u52a8\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\u3001\u63a8\u7406\u80fd\u529b\u3001\u957f\u4e0a\u4e0b\u6587\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u76d1\u7763\u5fae\u8c03\u5efa\u7acb\u5f3a\u57fa\u7ebf\uff0c\u5e76\u53d1\u5e03\u5b8c\u6574\u7684\u8bad\u7ec3\u5386\u53f2\u548c\u6570\u636e\u7ec4\u6210\u3002", "result": "K2-V2\u6210\u4e3a\u6700\u5f3a\u7684\u5b8c\u5168\u5f00\u653e\u6a21\u578b\uff0c\u5728\u76f8\u540c\u89c4\u6a21\u7ea7\u522b\u4e2d\u4e0e\u5f00\u653e\u6743\u91cd\u9886\u5bfc\u8005\u76f8\u5ab2\u7f8e\uff0c\u8d85\u8d8aQwen2.5-72B\u5e76\u63a5\u8fd1Qwen3-235B\u7684\u6027\u80fd\u3002", "conclusion": "K2-V2\u4f5c\u4e3a\u4e00\u4e2a\u5f3a\u5927\u7684\u63a8\u7406\u4e2d\u5fc3\u5316\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u53d1\u5e03\u5b8c\u6574\u7684\u8bad\u7ec3\u5386\u53f2\u548c\u6570\u636e\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u6301\u7eed\u8bad\u7ec3\u7684\u6709\u6548\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5728\u9ad8\u7ea7\u5bf9\u9f50\u65b9\u9762\u4ecd\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2512.06311", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06311", "abs": "https://arxiv.org/abs/2512.06311", "authors": ["Hao-Long Zhang", "Yan Wang", "Wen Ning", "Shou-Bang Yang", "Jia-Hao L\u00fc", "Fan Wu", "Pei-Rong Han", "Zhen-Biao Yang", "Shi-Biao Zheng"], "title": "Exploring the topology induced by non-Markovian Liouvillian exceptional points", "comment": null, "summary": "Non-Hermitian (NH) systems can display exotic topological phenomena without Hermitian counterparts, enabled by exceptional points (EPs). So far, investigations of NH topology have been restricted to EPs of the NH Hamiltonian, which governs the system dynamics conditional upon no quantum jumps occurring. The Liouvillian superoperator, which combines the effects of quantum jumps with NH Hamiltonian dynamics, possesses EPs (LEPs) that are significantly different from those of the corresponding NH Hamiltonian. We here study the topological features of the LEPs in the system consisting of a qubit coupled to a non-Markovian reservoir. We find that two distinct winding numbers can be simultaneously produced by executing a single closed path encircling the twofold LEP2, formed by two coinciding LEP2s, each involving a pair of coalescing eigenvectors of the extended Liouvillian superoperator. We experimentally demonstrate this purely non-Markovian phenomenon with a circuit, where a superconducting qubit is coupled to a decaying resonator which acts as a reservoir with memory effects. The results push the exploration of exceptional topology from the Markovian to non-Markovian regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u975e\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2dLiouvillian\u8d85\u7b97\u5b50\u7684\u62d3\u6251\u7279\u6027\uff0c\u53d1\u73b0\u5355\u4e2a\u8def\u5f84\u73af\u7ed5\u53cc\u91cdLEP2\u53ef\u540c\u65f6\u4ea7\u751f\u4e24\u4e2a\u4e0d\u540c\u7684\u7ed5\u6570\uff0c\u5e76\u901a\u8fc7\u8d85\u5bfc\u91cf\u5b50\u7535\u8def\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u73b0\u6709\u975e\u5384\u7c73\u62d3\u6251\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8eNH\u54c8\u5bc6\u987f\u91cf\u7684\u5f02\u5e38\u70b9\uff0c\u800cLiouvillian\u8d85\u7b97\u5b50\uff08\u7ed3\u5408\u91cf\u5b50\u8dc3\u8fc1\u548cNH\u54c8\u5bc6\u987f\u91cf\u52a8\u529b\u5b66\uff09\u7684\u5f02\u5e38\u70b9\uff08LEPs\uff09\u4e0e\u5bf9\u5e94NH\u54c8\u5bc6\u987f\u91cf\u7684\u5f02\u5e38\u70b9\u6709\u663e\u8457\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u7531\u91cf\u5b50\u6bd4\u7279\u8026\u5408\u5230\u975e\u9a6c\u5c14\u53ef\u592b\u5e93\u7ec4\u6210\u7684\u7cfb\u7edf\uff0c\u5206\u6790\u6269\u5c55Liouvillian\u8d85\u7b97\u5b50\u7684\u62d3\u6251\u7279\u5f81\uff0c\u91cd\u70b9\u5173\u6ce8\u7531\u4e24\u4e2a\u91cd\u5408\u7684LEP2\u5f62\u6210\u7684\u53cc\u91cdLEP2\u7ed3\u6784\u3002\u901a\u8fc7\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u4e0e\u8870\u51cf\u8c10\u632f\u5668\uff08\u4f5c\u4e3a\u5177\u6709\u8bb0\u5fc6\u6548\u5e94\u7684\u5e93\uff09\u8026\u5408\u7684\u7535\u8def\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u5355\u4e2a\u95ed\u5408\u8def\u5f84\u73af\u7ed5\u53cc\u91cdLEP2\u53ef\u540c\u65f6\u4ea7\u751f\u4e24\u4e2a\u4e0d\u540c\u7684\u7ed5\u6570\uff0c\u8fd9\u4e00\u73b0\u8c61\u7eaf\u7cb9\u6e90\u4e8e\u975e\u9a6c\u5c14\u53ef\u592b\u6548\u5e94\u3002\u5b9e\u9a8c\u6210\u529f\u89c2\u6d4b\u5230\u8fd9\u4e00\u62d3\u6251\u7279\u5f81\uff0c\u5c06\u5f02\u5e38\u62d3\u6251\u7684\u7814\u7a76\u4ece\u9a6c\u5c14\u53ef\u592b\u533a\u57df\u6269\u5c55\u5230\u975e\u9a6c\u5c14\u53ef\u592b\u533a\u57df\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63ed\u793a\u4e86Liouvillian\u5f02\u5e38\u70b9\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\u7684\u72ec\u7279\u62d3\u6251\u7279\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5355\u4e2a\u8def\u5f84\u53ef\u540c\u65f6\u4ea7\u751f\u591a\u4e2a\u7ed5\u6570\u7684\u73b0\u8c61\uff0c\u4e3a\u975e\u5384\u7c73\u62d3\u6251\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u65b9\u5411\u3002"}}
{"id": "2512.06918", "categories": ["gr-qc", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.06918", "abs": "https://arxiv.org/abs/2512.06918", "authors": ["Da Xu"], "title": "Angular Momentum Penrose Inequality", "comment": null, "summary": "We prove the Angular Momentum Penrose Inequality for axisymmetric vacuum initial data satisfying the dominant energy condition. This inequality establishes a sharp lower bound on the ADM mass in terms of both the horizon area and the Komar angular momentum of a black hole, with equality achieved precisely by the Kerr solution. The proof combines four main ingredients: solving an axisymmetric Jang equation where twist enters as a lower-order perturbation, establishing conformal factor bounds via a divergence identity, proving angular momentum conservation along level sets using de Rham cohomology, and applying the proven Dain-Reiris area-angular momentum inequality for sub-extremality. The monotonicity of a combined area-angular momentum functional along the Agostiniani-Mazzieri-Oronzio flow yields the result. This provides the first geometric inequality incorporating both horizon area and angular momentum, with implications for cosmic censorship, black hole thermodynamics, and gravitational wave observations of spinning black holes.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u6ee1\u8db3\u4e3b\u5bfc\u80fd\u91cf\u6761\u4ef6\u7684\u8f74\u5bf9\u79f0\u771f\u7a7a\u521d\u59cb\u6570\u636e\u7684\u89d2\u52a8\u91cf\u5f6d\u7f57\u65af\u4e0d\u7b49\u5f0f\uff0c\u5efa\u7acb\u4e86ADM\u8d28\u91cf\u5173\u4e8e\u9ed1\u6d1e\u89c6\u754c\u9762\u79ef\u548c\u79d1\u9a6c\u89d2\u52a8\u91cf\u7684\u5c16\u9510\u4e0b\u754c\uff0c\u7b49\u53f7\u4ec5\u7531\u514b\u5c14\u89e3\u5b9e\u73b0\u3002", "motivation": "\u5efa\u7acb\u7b2c\u4e00\u4e2a\u540c\u65f6\u5305\u542b\u89c6\u754c\u9762\u79ef\u548c\u89d2\u52a8\u91cf\u7684\u51e0\u4f55\u4e0d\u7b49\u5f0f\uff0c\u5bf9\u5b87\u5b99\u5ba1\u67e5\u5047\u8bbe\u3001\u9ed1\u6d1e\u70ed\u529b\u5b66\u548c\u5f15\u529b\u6ce2\u89c2\u6d4b\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u7ed3\u5408\u56db\u4e2a\u4e3b\u8981\u8981\u7d20\uff1a\u6c42\u89e3\u8f74\u5bf9\u79f0Jang\u65b9\u7a0b\uff08\u5176\u4e2d\u626d\u8f6c\u4f5c\u4e3a\u4f4e\u9636\u6270\u52a8\uff09\u3001\u901a\u8fc7\u6563\u5ea6\u6052\u7b49\u5f0f\u5efa\u7acb\u5171\u5f62\u56e0\u5b50\u754c\u3001\u4f7f\u7528de Rham\u4e0a\u540c\u8c03\u8bc1\u660e\u6cbf\u6c34\u5e73\u96c6\u7684\u89d2\u52a8\u91cf\u5b88\u6052\u3001\u5e94\u7528\u5df2\u8bc1\u660e\u7684Dain-Reiris\u4e9a\u6781\u503c\u9762\u79ef-\u89d2\u52a8\u91cf\u4e0d\u7b49\u5f0f\u3002", "result": "\u8bc1\u660e\u4e86\u89d2\u52a8\u91cf\u5f6d\u7f57\u65af\u4e0d\u7b49\u5f0f\uff0c\u5efa\u7acb\u4e86ADM\u8d28\u91cf\u5173\u4e8e\u89c6\u754c\u9762\u79ef\u548c\u89d2\u52a8\u91cf\u7684\u5c16\u9510\u4e0b\u754c\uff0c\u7b49\u53f7\u4ec5\u7531\u514b\u5c14\u89e3\u5b9e\u73b0\u3002", "conclusion": "\u901a\u8fc7Agostiniani-Mazzieri-Oronzio\u6d41\u4e2d\u7ec4\u5408\u9762\u79ef-\u89d2\u52a8\u91cf\u6cdb\u51fd\u7684\u5355\u8c03\u6027\u5f97\u5230\u7ed3\u679c\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u540c\u65f6\u5305\u542b\u89c6\u754c\u9762\u79ef\u548c\u89d2\u52a8\u91cf\u7684\u51e0\u4f55\u4e0d\u7b49\u5f0f\uff0c\u5bf9\u591a\u4e2a\u7269\u7406\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002"}}
{"id": "2512.06204", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06204", "abs": "https://arxiv.org/abs/2512.06204", "authors": ["Rodney Lafuente-Mercado", "Daniela Rus", "T. Konstantin Rusch"], "title": "Quantifying Memory Use in Reinforcement Learning with Temporal Range", "comment": null, "summary": "How much does a trained RL policy actually use its past observations? We propose \\emph{Temporal Range}, a model-agnostic metric that treats first-order sensitivities of multiple vector outputs across a temporal window to the input sequence as a temporal influence profile and summarizes it by the magnitude-weighted average lag. Temporal Range is computed via reverse-mode automatic differentiation from the Jacobian blocks $\\partial y_s/\\partial x_t\\in\\mathbb{R}^{c\\times d}$ averaged over final timesteps $s\\in\\{t+1,\\dots,T\\}$ and is well-characterized in the linear setting by a small set of natural axioms. Across diagnostic and control tasks (POPGym; flicker/occlusion; Copy-$k$) and architectures (MLPs, RNNs, SSMs), Temporal Range (i) remains small in fully observed control, (ii) scales with the task's ground-truth lag in Copy-$k$, and (iii) aligns with the minimum history window required for near-optimal return as confirmed by window ablations. We also report Temporal Range for a compact Long Expressive Memory (LEM) policy trained on the task, using it as a proxy readout of task-level memory. Our axiomatic treatment draws on recent work on range measures, specialized here to temporal lag and extended to vector-valued outputs in the RL setting. Temporal Range thus offers a practical per-sequence readout of memory dependence for comparing agents and environments and for selecting the shortest sufficient context.", "AI": {"tldr": "\u63d0\u51faTemporal Range\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316RL\u7b56\u7565\u5bf9\u5386\u53f2\u89c2\u6d4b\u7684\u4f9d\u8d56\u7a0b\u5ea6\uff0c\u901a\u8fc7\u8ba1\u7b97\u8f93\u51fa\u5bf9\u8f93\u5165\u5e8f\u5217\u7684\u65f6\u95f4\u654f\u611f\u6027\u6765\u6d4b\u91cf\u5e73\u5747\u6ede\u540e", "motivation": "\u9700\u8981\u91cf\u5316\u8bad\u7ec3\u540e\u7684RL\u7b56\u7565\u5b9e\u9645\u4f7f\u7528\u5386\u53f2\u89c2\u6d4b\u7684\u7a0b\u5ea6\uff0c\u4ee5\u6bd4\u8f83\u4e0d\u540c\u667a\u80fd\u4f53\u548c\u73af\u5883\uff0c\u5e76\u9009\u62e9\u6700\u77ed\u7684\u8db3\u591f\u4e0a\u4e0b\u6587", "method": "\u63d0\u51faTemporal Range\u6307\u6807\uff0c\u901a\u8fc7\u53cd\u5411\u81ea\u52a8\u5fae\u5206\u8ba1\u7b97Jacobian\u5757\uff0c\u5c06\u591a\u4e2a\u5411\u91cf\u8f93\u51fa\u5bf9\u8f93\u5165\u5e8f\u5217\u7684\u4e00\u9636\u654f\u611f\u6027\u4f5c\u4e3a\u65f6\u95f4\u5f71\u54cd\u5256\u9762\uff0c\u7528\u5e45\u5ea6\u52a0\u6743\u5e73\u5747\u6ede\u540e\u8fdb\u884c\u603b\u7ed3", "result": "\u5728\u8bca\u65ad\u548c\u63a7\u5236\u4efb\u52a1\u4e2d\uff0cTemporal Range\uff1a(i)\u5728\u5b8c\u5168\u89c2\u6d4b\u63a7\u5236\u4e2d\u4fdd\u6301\u8f83\u5c0f\uff1b(ii)\u5728Copy-k\u4efb\u52a1\u4e2d\u968f\u4efb\u52a1\u771f\u5b9e\u6ede\u540e\u7f29\u653e\uff1b(iii)\u4e0e\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u56de\u62a5\u6240\u9700\u7684\u6700\u5c0f\u5386\u53f2\u7a97\u53e3\u5bf9\u9f50", "conclusion": "Temporal Range\u4e3a\u6bd4\u8f83\u667a\u80fd\u4f53\u548c\u73af\u5883\u4ee5\u53ca\u9009\u62e9\u6700\u77ed\u8db3\u591f\u4e0a\u4e0b\u6587\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6bcf\u5e8f\u5217\u5185\u5b58\u4f9d\u8d56\u8bfb\u6570\uff0c\u53ef\u4f5c\u4e3a\u4efb\u52a1\u7ea7\u5185\u5b58\u7684\u4ee3\u7406\u8bfb\u6570"}}
{"id": "2512.06333", "categories": ["quant-ph", "gr-qc", "hep-ph"], "pdf": "https://arxiv.org/pdf/2512.06333", "abs": "https://arxiv.org/abs/2512.06333", "authors": ["Roberto Onofrio", "Alexander R. H. Smith", "Lorenza Viola"], "title": "Testing the weak equivalence principle for nonclassical matter with torsion balances", "comment": "16 pager, 6 figures", "summary": "We propose tests of the weak equivalence principle (WEP) using a torsion balance, in which superposition of energy eigenstates are created in a controllable way for the test masses. After general considerations on the significance of tests of the WEP using quantum states and the need for considering inertial and gravitational masses as operators, we develop a model to derive the matrix elements of the free-fall operator, showing that the variance of the acceleration operator, in addition to its mean, enables estimation of violations of the WEP due to quantum coherence in a way that is robust with respect to shot-to-shot fluctuations. Building on this analysis, we demonstrate how the validity of the WEP may be tested in a torsion balance setup, by accessing the mean and variance of a torque operator we introduce and quantize. Due to the long acquisition times of the signal as compared to the timescale on which coherent superposition states may survive, we further propose a dynamical setting, where the torsion balance is subject to a time-dependent gravitational field, and measurements of angular acceleration encode possible violations of the WEP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u626d\u79e4\u6d4b\u8bd5\u5f31\u7b49\u6548\u539f\u7406\uff0c\u901a\u8fc7\u521b\u5efa\u53ef\u63a7\u7684\u91cf\u5b50\u53e0\u52a0\u6001\uff0c\u5e76\u8003\u8651\u60ef\u6027\u8d28\u91cf\u548c\u5f15\u529b\u8d28\u91cf\u4f5c\u4e3a\u7b97\u7b26\uff0c\u5229\u7528\u52a0\u901f\u5ea6\u7b97\u7b26\u7684\u5747\u503c\u548c\u65b9\u5dee\u6765\u68c0\u6d4b\u91cf\u5b50\u76f8\u5e72\u6027\u5bfc\u81f4\u7684WEP\u8fdd\u53cd\u3002", "motivation": "\u4f20\u7edf\u5f31\u7b49\u6548\u539f\u7406\u6d4b\u8bd5\u4e3b\u8981\u9488\u5bf9\u7ecf\u5178\u7269\u4f53\uff0c\u800c\u91cf\u5b50\u7cfb\u7edf\u7684WEP\u6d4b\u8bd5\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u3002\u4f5c\u8005\u8ba4\u4e3a\u9700\u8981\u8003\u8651\u60ef\u6027\u8d28\u91cf\u548c\u5f15\u529b\u8d28\u91cf\u4f5c\u4e3a\u7b97\u7b26\uff0c\u5e76\u5f00\u53d1\u80fd\u591f\u68c0\u6d4b\u91cf\u5b50\u76f8\u5e72\u6027\u5bfc\u81f4WEP\u8fdd\u53cd\u7684\u9c81\u68d2\u6d4b\u8bd5\u65b9\u6848\u3002", "method": "1. \u5efa\u7acb\u6a21\u578b\u63a8\u5bfc\u81ea\u7531\u843d\u4f53\u7b97\u7b26\u7684\u77e9\u9635\u5143\uff1b2. \u5229\u7528\u52a0\u901f\u5ea6\u7b97\u7b26\u7684\u5747\u503c\u548c\u65b9\u5dee\u6765\u4f30\u8ba1WEP\u8fdd\u53cd\uff1b3. \u5728\u626d\u79e4\u5b9e\u9a8c\u4e2d\u5f15\u5165\u5e76\u91cf\u5b50\u5316\u626d\u77e9\u7b97\u7b26\uff1b4. \u63d0\u51fa\u52a8\u6001\u8bbe\u7f6e\uff0c\u901a\u8fc7\u65f6\u95f4\u76f8\u5173\u5f15\u529b\u573a\u6d4b\u91cf\u89d2\u52a0\u901f\u5ea6\u6765\u7f16\u7801WEP\u8fdd\u53cd\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u68c0\u6d4b\u91cf\u5b50\u76f8\u5e72\u6027\u5bfc\u81f4\u5f31\u7b49\u6548\u539f\u7406\u8fdd\u53cd\u7684\u9c81\u68d2\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u52a0\u901f\u5ea6\u7b97\u7b26\u7684\u65b9\u5dee\uff08\u800c\u4e0d\u4ec5\u4ec5\u662f\u5747\u503c\uff09\u6765\u514b\u670d\u5b9e\u9a8c\u4e2d\u7684\u6da8\u843d\u5f71\u54cd\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5177\u4f53\u7684\u626d\u79e4\u5b9e\u9a8c\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u5c3a\u5ea6\u4e0b\u7684\u5f31\u7b49\u6548\u539f\u7406\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u91cf\u5b50\u76f8\u5e72\u6027\u548c\u7b97\u7b26\u5f62\u5f0f\u7684\u8d28\u91cf\u6982\u5ff5\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u63a2\u6d4b\u53ef\u80fd\u7684WEP\u8fdd\u53cd\uff0c\u7279\u522b\u662f\u5728\u91cf\u5b50\u53e0\u52a0\u6001\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2512.06930", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06930", "abs": "https://arxiv.org/abs/2512.06930", "authors": ["S. V. Bolokhov"], "title": "Revisiting black holes in dark-matter halos: on consistent solutions to the Einstein equations", "comment": "7 pages, 1 table", "summary": "A number of recent papers have claimed to construct solutions of Einstein's equations describing black holes surrounded by dark-matter halos with empirically motivated density profiles such as the Navarro-Frenk-White, Burkert, Einasto, pseudo-isothermal, and solitonic distributions. We show that the approach used to obtain many of these metrics generically does not lead to the correct solutions to the Einstein equations for the matter sources they purport to represent. This issue originates from applying the Newtonian relation between the tangential velocity and the enclosed mass directly within a relativistic framework, followed by the ad hoc assumption $g(r)=f(r)$ for the metric functions. This procedure leads to an anisotropic fluid with $P_r=-\u03c1$ and $P_t=-r\u03c1'/2-\u03c1$, whose density differs from the claimed halo profile and often becomes non-physical near the horizon, violating the weak energy condition. As a result, the obtained spacetimes do not describe black holes embedded in known galactic halos but rather distinct anisotropic configurations unrelated to the intended matter distribution. We demonstrate this problem on several representative examples from the literature, including metrics based on the NFW, Burkert, Einasto, solitonic, pseudo-isothermal, and Dehnen-(1,4,5/2) profiles, as well as the case of the NGC~4649 halo. For each case, the correct Einstein-consistent form of the metric and the associated physical interpretation are provided. Our analysis clarifies the limits of validity of the Newtonian approximation near compact objects and establishes a consistent framework for constructing dark-matter-inspired black-hole geometries within General Relativity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u8fd1\u671f\u8bb8\u591a\u58f0\u79f0\u6784\u5efa\u6697\u7269\u8d28\u6655\u73af\u7ed5\u9ed1\u6d1e\u7684\u7231\u56e0\u65af\u5766\u65b9\u7a0b\u89e3\u7684\u7814\u7a76\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u9519\u8bef\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u9519\u8bef\u5730\u5c06\u725b\u987f\u5173\u7cfb\u76f4\u63a5\u5e94\u7528\u4e8e\u76f8\u5bf9\u8bba\u6846\u67b6\uff0c\u5bfc\u81f4\u5f97\u5230\u7684\u89e3\u5e76\u975e\u771f\u6b63\u7684\u6697\u7269\u8d28\u5206\u5e03\uff0c\u800c\u662f\u5404\u5411\u5f02\u6027\u6d41\u4f53\u914d\u7f6e\u3002", "motivation": "\u8fd1\u671f\u591a\u7bc7\u8bba\u6587\u58f0\u79f0\u6784\u5efa\u4e86\u5177\u6709\u7ecf\u9a8c\u5bc6\u5ea6\u5206\u5e03\uff08\u5982NFW\u3001Burkert\u3001Einasto\u7b49\uff09\u7684\u6697\u7269\u8d28\u6655\u73af\u7ed5\u9ed1\u6d1e\u7684\u7231\u56e0\u65af\u5766\u65b9\u7a0b\u89e3\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u7684\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u6f84\u6e05\u8fd9\u4e9b\u89e3\u5e76\u975e\u771f\u6b63\u7684\u6697\u7269\u8d28\u5206\u5e03\uff0c\u800c\u662f\u5404\u5411\u5f02\u6027\u6d41\u4f53\u914d\u7f6e\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6587\u732e\u4e2d\u4ee3\u8868\u6027\u4f8b\u5b50\uff08\u5305\u62ec\u57fa\u4e8eNFW\u3001Burkert\u3001Einasto\u3001\u5b64\u5b50\u3001\u4f2a\u7b49\u6e29\u3001Dehnen-(1,4,5/2)\u5206\u5e03\u4ee5\u53caNGC 4649\u6655\u7684\u5ea6\u91cf\uff09\uff0c\u5c55\u793a\u8fd9\u4e9b\u65b9\u6cd5\u5982\u4f55\u9519\u8bef\u5730\u5c06\u725b\u987f\u5173\u7cfb\uff08\u5207\u5411\u901f\u5ea6\u4e0e\u5305\u56f4\u8d28\u91cf\u7684\u5173\u7cfb\uff09\u76f4\u63a5\u5e94\u7528\u4e8e\u76f8\u5bf9\u8bba\u6846\u67b6\uff0c\u5e76\u968f\u610f\u5047\u8bbe\u5ea6\u91cf\u51fd\u6570g(r)=f(r)\u3002", "result": "\u8be5\u65b9\u6cd5\u5bfc\u81f4\u5404\u5411\u5f02\u6027\u6d41\u4f53\uff0c\u5176\u5f84\u5411\u538b\u529bP_r=-\u03c1\uff0c\u5207\u5411\u538b\u529bP_t=-r\u03c1'/2-\u03c1\uff0c\u5bc6\u5ea6\u4e0e\u58f0\u79f0\u7684\u6655\u5206\u5e03\u4e0d\u540c\uff0c\u4e14\u5728\u89c6\u754c\u9644\u8fd1\u5e38\u53d8\u5f97\u975e\u7269\u7406\uff0c\u8fdd\u53cd\u5f31\u80fd\u91cf\u6761\u4ef6\u3002\u56e0\u6b64\u5f97\u5230\u7684\u65f6\u7a7a\u5e76\u975e\u63cf\u8ff0\u5df2\u77e5\u661f\u7cfb\u6655\u4e2d\u7684\u9ed1\u6d1e\uff0c\u800c\u662f\u4e0e\u9884\u671f\u7269\u8d28\u5206\u5e03\u65e0\u5173\u7684\u72ec\u7279\u5404\u5411\u5f02\u6027\u914d\u7f6e\u3002", "conclusion": "\u672c\u6587\u6f84\u6e05\u4e86\u725b\u987f\u8fd1\u4f3c\u5728\u81f4\u5bc6\u5929\u4f53\u9644\u8fd1\u7684\u9002\u7528\u8303\u56f4\uff0c\u5e76\u4e3a\u5728\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u6784\u5efa\u6697\u7269\u8d28\u542f\u53d1\u7684\u9ed1\u6d1e\u51e0\u4f55\u5efa\u7acb\u4e86\u81ea\u6d3d\u6846\u67b6\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u6848\u4f8b\uff0c\u63d0\u4f9b\u4e86\u6b63\u786e\u7684\u7231\u56e0\u65af\u5766\u4e00\u81f4\u5f62\u5f0f\u7684\u5ea6\u91cf\u548c\u76f8\u5173\u7269\u7406\u89e3\u91ca\u3002"}}
{"id": "2512.06218", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.06218", "abs": "https://arxiv.org/abs/2512.06218", "authors": ["Huizhen Yu", "Yi Wan", "Richard S. Sutton"], "title": "Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration", "comment": "24 pages. This paper presents the reinforcement-learning material previously contained in version 2 of arXiv:2409.03915, which is now being split into two stand-alone papers. Minor corrections and improvements to the main results have also been made in the course of this reformatting", "summary": "This paper applies the authors' recent results on asynchronous stochastic approximation (SA) in the Borkar-Meyn framework to reinforcement learning in average-reward semi-Markov decision processes (SMDPs). We establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. In particular, we show that the algorithm converges almost surely to a compact, connected subset of solutions to the average-reward optimality equation, with convergence to a unique, sample path-dependent solution under additional stepsize and asynchrony conditions. Moreover, to make full use of the SA framework, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework and are addressed through novel arguments in the stability and convergence analysis of RVI Q-learning.", "AI": {"tldr": "\u5c06\u5f02\u6b65\u968f\u673a\u903c\u8fd1\u7406\u8bba\u5e94\u7528\u4e8e\u5e73\u5747\u5956\u52b1\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86RVI Q-learning\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u5355\u8c03\u6027\u6761\u4ef6\u6765\u4f30\u8ba1\u6700\u4f18\u5956\u52b1\u7387\u3002", "motivation": "\u5c06\u4f5c\u8005\u6700\u8fd1\u5728Borkar-Meyn\u6846\u67b6\u4e0b\u7684\u5f02\u6b65\u968f\u673a\u903c\u8fd1\u7ed3\u679c\u5e94\u7528\u4e8e\u5e73\u5747\u5956\u52b1\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7b97\u6cd5\u6846\u67b6\u5e76\u89e3\u51b3\u6536\u655b\u6027\u95ee\u9898\u3002", "method": "\u5e94\u7528\u5f02\u6b65\u968f\u673a\u903c\u8fd1\u7406\u8bba\u5230Schweitzer\u7ecf\u5178\u76f8\u5bf9\u503c\u8fed\u4ee3\u7b97\u6cd5\u7684\u5f02\u6b65\u7248\u672c\u2014\u2014RVI Q-learning\uff0c\u9488\u5bf9\u6709\u9650\u72b6\u6001\u7a7a\u95f4\u3001\u5f31\u901a\u4fe1\u7684\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u5355\u8c03\u6027\u6761\u4ef6\u6765\u4f30\u8ba1\u6700\u4f18\u5956\u52b1\u7387\u3002", "result": "\u8bc1\u660e\u4e86\u7b97\u6cd5\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5e73\u5747\u5956\u52b1\u6700\u4f18\u65b9\u7a0b\u89e3\u7684\u7d27\u81f4\u8fde\u901a\u5b50\u96c6\uff0c\u5728\u989d\u5916\u6b65\u957f\u548c\u5f02\u6b65\u6761\u4ef6\u4e0b\u6536\u655b\u5230\u552f\u4e00\u7684\u6837\u672c\u8def\u5f84\u4f9d\u8d56\u89e3\uff0c\u65b0\u5355\u8c03\u6027\u6761\u4ef6\u663e\u8457\u6269\u5c55\u4e86\u5148\u524d\u8003\u8651\u7684\u7b97\u6cd5\u6846\u67b6\u3002", "conclusion": "\u6210\u529f\u5c06\u5f02\u6b65\u968f\u673a\u903c\u8fd1\u7406\u8bba\u5e94\u7528\u4e8e\u5e73\u5747\u5956\u52b1\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5efa\u7acb\u4e86RVI Q-learning\u7684\u6536\u655b\u6027\u7406\u8bba\uff0c\u5e76\u901a\u8fc7\u65b0\u9896\u7684\u7a33\u5b9a\u6027\u5206\u6790\u6269\u5c55\u4e86\u7b97\u6cd5\u6846\u67b6\u3002"}}
{"id": "2512.06365", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06365", "abs": "https://arxiv.org/abs/2512.06365", "authors": ["Xiang Guo", "Xiaojun Zhang", "Mingzhu Weng", "Qian Bin", "Hao-di Liu", "Hai-Jun Xing", "Xin-You L\u00fc", "Zhihai Wang"], "title": "Bound state in the continuum and multiple atom state transfer applications in a waveguide QED setup", "comment": "6+6 Pages, 3+3 Figures, Comments are welcommed", "summary": "Bound states in the continuum (BICs) have been extensively exploited to enhance light--matter interactions in metamaterials, yet their emergence and utility in multi-atom waveguide platforms remain far less explored. Here we study atom--waveguide-dressed BICs in a one-dimensional coupled-resonator waveguide, where two spatially separated atomic arrays couple to distinct resonators with time-dependent strengths. We show that these BICs support a standing-wave photonic mode and enable the transfer of an arbitrary unknown quantum state between the two arrays with fidelities exceeding $99\\%$. The protocol remains robust against both disorder and intrinsic dissipation. Our results establish BICs as long-lived resources for high-fidelity quantum information processing in waveguide-QED architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8026\u5408\u8c10\u632f\u5668\u6ce2\u5bfc\u4e2d\u539f\u5b50-\u6ce2\u5bfc\u4fee\u9970\u7684\u8fde\u7eed\u8c31\u675f\u7f1a\u6001\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e24\u4e2a\u7a7a\u95f4\u5206\u79bb\u7684\u539f\u5b50\u9635\u5217\u95f4\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cf\u5b50\u6001\u4f20\u8f93\u7684\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u8fde\u7eed\u8c31\u675f\u7f1a\u6001\u5728\u8d85\u6750\u6599\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7528\u4e8e\u589e\u5f3a\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\uff0c\u4f46\u5728\u591a\u539f\u5b50\u6ce2\u5bfc\u5e73\u53f0\u4e2d\u7684\u51fa\u73b0\u548c\u5e94\u7528\u4ecd\u8f83\u5c11\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u539f\u5b50-\u6ce2\u5bfc\u4fee\u9970\u7684BICs\u5728\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u4e00\u7ef4\u8026\u5408\u8c10\u632f\u5668\u6ce2\u5bfc\u7cfb\u7edf\uff0c\u5176\u4e2d\u4e24\u4e2a\u7a7a\u95f4\u5206\u79bb\u7684\u539f\u5b50\u9635\u5217\u4ee5\u65f6\u95f4\u4f9d\u8d56\u7684\u5f3a\u5ea6\u8026\u5408\u5230\u4e0d\u540c\u7684\u8c10\u632f\u5668\u3002\u901a\u8fc7\u5206\u6790\u539f\u5b50-\u6ce2\u5bfc\u4fee\u9970\u7684\u8fde\u7eed\u8c31\u675f\u7f1a\u6001\u7279\u6027\uff0c\u7279\u522b\u662f\u5176\u652f\u6301\u7684\u9a7b\u6ce2\u5149\u5b50\u6a21\u5f0f\u3002", "result": "BICs\u652f\u6301\u9a7b\u6ce2\u5149\u5b50\u6a21\u5f0f\uff0c\u80fd\u591f\u5b9e\u73b0\u4e24\u4e2a\u539f\u5b50\u9635\u5217\u95f4\u4efb\u610f\u672a\u77e5\u91cf\u5b50\u6001\u7684\u4f20\u8f93\uff0c\u4fdd\u771f\u5ea6\u8d85\u8fc799%\u3002\u8be5\u534f\u8bae\u5bf9\u65e0\u5e8f\u548c\u672c\u5f81\u8017\u6563\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fde\u7eed\u8c31\u675f\u7f1a\u6001\u53ef\u4f5c\u4e3a\u6ce2\u5bfc-QED\u67b6\u6784\u4e2d\u9ad8\u4fdd\u771f\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u7684\u957f\u5bff\u547d\u8d44\u6e90\uff0c\u4e3a\u91cf\u5b50\u6001\u4f20\u8f93\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.06931", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.06931", "abs": "https://arxiv.org/abs/2512.06931", "authors": ["M. Radomirov", "R. C. Rashkov", "G. S. Stoilov", "T. Vetsov"], "title": "Optimal Control Theory of the (2+1)-Dimensional BTZ Black Hole", "comment": "7 figures, 2 tables, 23 pages", "summary": "We apply a finite-time geometric optimization framework to investigate thermal fluctuations and (non)equilibrium optimal processes in the $(2+1)$-dimensional BTZ black hole. Employing Hessian thermodynamic information metrics, we construct geodesic trajectories that define optimal protocols connecting distinct thermodynamic configurations. Finite-time state transitions are described by paths that extremize entropy production or energy dissipation, depending on the chosen thermodynamic representation. This work presents the first formulation of a geometric optimal control theory for the BTZ black hole.", "AI": {"tldr": "\u5c06\u6709\u9650\u65f6\u95f4\u51e0\u4f55\u4f18\u5316\u6846\u67b6\u5e94\u7528\u4e8e(2+1)\u7ef4BTZ\u9ed1\u6d1e\u7684\u70ed\u6da8\u843d\u548c(\u975e)\u5e73\u8861\u6700\u4f18\u8fc7\u7a0b\u7814\u7a76", "motivation": "\u9996\u6b21\u4e3aBTZ\u9ed1\u6d1e\u6784\u5efa\u51e0\u4f55\u6700\u4f18\u63a7\u5236\u7406\u8bba\uff0c\u7814\u7a76\u9ed1\u6d1e\u70ed\u529b\u5b66\u4e2d\u7684\u6700\u4f18\u8fc7\u7a0b", "method": "\u4f7f\u7528Hessian\u70ed\u529b\u5b66\u4fe1\u606f\u5ea6\u91cf\u6784\u9020\u6d4b\u5730\u7ebf\u8f68\u8ff9\uff0c\u5b9a\u4e49\u8fde\u63a5\u4e0d\u540c\u70ed\u529b\u5b66\u6784\u578b\u7684\u6700\u4f18\u534f\u8bae", "result": "\u5efa\u7acb\u4e86BTZ\u9ed1\u6d1e\u7684\u51e0\u4f55\u6700\u4f18\u63a7\u5236\u7406\u8bba\u6846\u67b6\uff0c\u63cf\u8ff0\u4e86\u6709\u9650\u65f6\u95f4\u72b6\u6001\u8f6c\u79fb\u7684\u6700\u4f18\u8def\u5f84", "conclusion": "\u6210\u529f\u5c06\u6709\u9650\u65f6\u95f4\u51e0\u4f55\u4f18\u5316\u5e94\u7528\u4e8e\u9ed1\u6d1e\u70ed\u529b\u5b66\uff0c\u4e3a\u7814\u7a76\u9ed1\u6d1e\u70ed\u529b\u5b66\u8fc7\u7a0b\u7684\u6700\u4f18\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2512.06236", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06236", "abs": "https://arxiv.org/abs/2512.06236", "authors": ["Haiyang Yu", "Meng-Chieh Lee", "Xiang song", "Qi Zhu", "Christos Faloutsos"], "title": "Back to Author Console Empowering GNNs for Domain Adaptation via Denoising Target Graph", "comment": null, "summary": "We explore the node classification task in the context of graph domain adaptation, which uses both source and target graph structures along with source labels to enhance the generalization capabilities of Graph Neural Networks (GNNs) on target graphs. Structure domain shifts frequently occur, especially when graph data are collected at different times or from varying areas, resulting in poor performance of GNNs on target graphs. Surprisingly, we find that simply incorporating an auxiliary loss function for denoising graph edges on target graphs can be extremely effective in enhancing GNN performance on target graphs. Based on this insight, we propose our framework, GraphDeT, a framework that integrates this auxiliary edge task into GNN training for node classification under domain adaptation. Our theoretical analysis connects this auxiliary edge task to the graph generalization bound with -distance, demonstrating such auxiliary task can imposes a constraint which tightens the bound and thereby improves generalization. The experimental results demonstrate superior performance compared to the existing baselines in handling both time and regional domain graph shifts.", "AI": {"tldr": "\u63d0\u51faGraphDeT\u6846\u67b6\uff0c\u901a\u8fc7\u52a0\u5165\u8f85\u52a9\u8fb9\u53bb\u566a\u4efb\u52a1\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u57df\u9002\u5e94\u4e2d\u7684\u8282\u70b9\u5206\u7c7b\u6027\u80fd", "motivation": "\u56fe\u7ed3\u6784\u57df\u504f\u79fb\uff08\u5982\u4e0d\u540c\u65f6\u95f4\u6216\u533a\u57df\u6536\u96c6\u7684\u6570\u636e\uff09\u5bfc\u81f4GNN\u5728\u76ee\u6807\u56fe\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u63d0\u5347\u56fe\u57df\u9002\u5e94\u80fd\u529b", "method": "\u63d0\u51faGraphDeT\u6846\u67b6\uff0c\u5728GNN\u8bad\u7ec3\u4e2d\u52a0\u5165\u8f85\u52a9\u8fb9\u53bb\u566a\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8fde\u63a5\u8be5\u4efb\u52a1\u4e0e\u56fe\u6cdb\u5316\u8fb9\u754c", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u5904\u7406\u65f6\u95f4\u548c\u533a\u57df\u57df\u56fe\u504f\u79fb\u65f6\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u7b80\u5355\u7684\u8f85\u52a9\u8fb9\u53bb\u566a\u4efb\u52a1\u80fd\u6709\u6548\u63d0\u5347GNN\u5728\u76ee\u6807\u56fe\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0cGraphDeT\u6846\u67b6\u5728\u57df\u9002\u5e94\u4e2d\u8868\u73b0\u4f18\u5f02"}}
{"id": "2512.06389", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.06389", "abs": "https://arxiv.org/abs/2512.06389", "authors": ["Manuel Rieger", "Rubek Poudel", "Tobias Waldmann", "Lina M. Todenhagen", "Stefan Kresta", "Nori N. Chavira Leal", "Viviana Villafa\u00f1e", "Martin S. Brandt", "Kai M\u00fcller", "Jonathan J. Finley"], "title": "Mitigating the Transition of SiV$^-$ in Diamond to an Optically Dark State", "comment": null, "summary": "Negatively charged silicon vacancy centers in diamond (SiV$^-$) are promising for quantum photonic technologies. However, when subject to resonant optical excitation, they can inadvertently transfer into a zero-spin optically dark state. We show that this unwanted change of charge state can be quickly reversed by the resonant laser itself in combination with static electric fields. By defining interdigitated metallic contacts on the diamond surface, we increase the steady-state SiV$^-$ photoluminescence under resonant excitation by a factor $\\ge3$ for most emitters, making it practically constant for certain individual emitters. We electrically activate single \\sivs near the positively biased electrode, which are entirely dark without applying local electric fields. Using time-resolved 3-color experiments, we show that the resonant laser not only excites the SiV$^-$, but also creates free holes that convert SiV$^{2-}$ to SiV$^-$ on a timescale of milliseconds. Through analysis of several individual emitters, our results show that the degree of electrical charge state controllability differs between individual emitters, indicating that their local environment plays a key role. Our proposed electric-field-based stabilization scheme enhances deterministic charge state control in group-IV color centers and improves its understanding, offering a scalable path toward quantum applications such as entanglement generation and quantum key distribution.", "AI": {"tldr": "\u901a\u8fc7\u65bd\u52a0\u9759\u7535\u573a\u7ed3\u5408\u5171\u632f\u6fc0\u5149\uff0c\u53ef\u6709\u6548\u7a33\u5b9a\u91d1\u521a\u77f3\u4e2d\u7845\u7a7a\u4f4d\u4e2d\u5fc3(SiV\u207b)\u7684\u7535\u8377\u6001\uff0c\u63d0\u9ad8\u5176\u5149\u81f4\u53d1\u5149\u5f3a\u5ea6\u5e76\u5b9e\u73b0\u5355\u5149\u5b50\u6e90\u7684\u7535\u8377\u6001\u63a7\u5236\u3002", "motivation": "\u91d1\u521a\u77f3\u4e2d\u7684\u7845\u7a7a\u4f4d\u4e2d\u5fc3(SiV\u207b)\u5728\u91cf\u5b50\u5149\u5b50\u6280\u672f\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u5171\u632f\u5149\u6fc0\u53d1\u4e0b\u5bb9\u6613\u8f6c\u53d8\u4e3a\u96f6\u81ea\u65cb\u7684\u6697\u6001\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u627e\u5230\u65b9\u6cd5\u6765\u7a33\u5b9a\u548c\u63a7\u5236\u5176\u7535\u8377\u6001\u3002", "method": "\u5728\u91d1\u521a\u77f3\u8868\u9762\u5236\u5907\u53c9\u6307\u91d1\u5c5e\u7535\u6781\uff0c\u65bd\u52a0\u9759\u7535\u573a\u7ed3\u5408\u5171\u632f\u6fc0\u5149\u6fc0\u53d1\u3002\u901a\u8fc7\u65f6\u95f4\u5206\u8fa8\u4e09\u8272\u5b9e\u9a8c\u7814\u7a76\u7535\u8377\u6001\u8f6c\u6362\u52a8\u529b\u5b66\uff0c\u5206\u6790\u4e0d\u540c\u5355\u4e2a\u53d1\u5c04\u4f53\u7684\u7535\u8377\u6001\u53ef\u63a7\u6027\u5dee\u5f02\u3002", "result": "\u9759\u7535\u573a\u4f7f\u5927\u591a\u6570\u53d1\u5c04\u4f53\u7684\u7a33\u6001SiV\u207b\u5149\u81f4\u53d1\u5149\u5f3a\u5ea6\u63d0\u9ad8\u81f3\u5c113\u500d\uff0c\u67d0\u4e9b\u5355\u4e2a\u53d1\u5c04\u4f53\u51e0\u4e4e\u4fdd\u6301\u6052\u5b9a\u3002\u6210\u529f\u6fc0\u6d3b\u4e86\u539f\u672c\u5b8c\u5168\u6697\u6001\u7684\u5355\u4e2aSiV\u207b\u3002\u5171\u632f\u6fc0\u5149\u4e0d\u4ec5\u6fc0\u53d1SiV\u207b\uff0c\u8fd8\u80fd\u4ea7\u751f\u81ea\u7531\u7a7a\u7a74\uff0c\u5728\u6beb\u79d2\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5c06SiV\u00b2\u207b\u8f6c\u6362\u4e3aSiV\u207b\u3002", "conclusion": "\u57fa\u4e8e\u7535\u573a\u7684\u7a33\u5b9a\u65b9\u6848\u589e\u5f3a\u4e86IV\u65cf\u8272\u5fc3\u7684\u786e\u5b9a\u6027\u7535\u8377\u6001\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86\u5bf9\u5176\u7269\u7406\u673a\u5236\u7684\u7406\u89e3\uff0c\u4e3a\u91cf\u5b50\u7ea0\u7f20\u751f\u6210\u548c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2512.07187", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07187", "abs": "https://arxiv.org/abs/2512.07187", "authors": ["Olga Razina", "Dauren Rakhatov", "Pyotr Tsyba", "Emilio Elizalde"], "title": "Exact solution of the Einstein-scalar-Gauss-Bonnet model with Noether symmetry constraints", "comment": "21 pages, 4 figures", "summary": "By applying Noether symmetry methods, analytic solutions are obtained for a generalized Einstein-scalar-Gauss-Bonnet model with a $\u03be(\u03c6)f(G)$ component. Variation with respect to the metric, supplemented by small perturbations, produces the equations of motion and the terms that determine the propagation speed of tensor perturbations. The resulting Hubble parameter incorporates contributions from stiff matter and dark energy, the last originating from a scalar field non-minimally coupled to the Gauss-Bonnet invariant. The viability of the model is assessed by using Cosmic Chronometers, Baryon Acoustic Oscillations, and type Ia supernovae data. Best model selection based on information criteria indicates a slight preference for this new framework over the $\u039b$ Cold Dark Matter model. Stability of the model follows from the positive speed of sound and absence of ``Ostrogradsky ghosts''. The total equation of state parameter hints towards the presence of a transition from decelerated to accelerated expansion at $z\\approx 0.66$, corresponding to the transition from matter to dark energy dominance. Early Universe dynamics, derived from the slow-roll parameters, spectral indices, and the tensor-to-scalar ratio, are found to be perfectly consistent with observations from Planck 2018 and the Atacama Cosmology Telescope.", "AI": {"tldr": "\u5e94\u7528Noether\u5bf9\u79f0\u65b9\u6cd5\uff0c\u5728\u5e7f\u4e49\u7231\u56e0\u65af\u5766-\u6807\u91cf-\u9ad8\u65af-\u535a\u5185\u6a21\u578b\u4e2d\u83b7\u5f97\u4e86\u89e3\u6790\u89e3\uff0c\u8be5\u6a21\u578b\u5305\u542b\u03be(\u03c6)f(G)\u9879\u3002\u901a\u8fc7\u5b87\u5b99\u5b66\u89c2\u6d4b\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5\u6a21\u578b\u5728\u4fe1\u606f\u51c6\u5219\u4e0a\u7565\u4f18\u4e8e\u039bCDM\u6a21\u578b\uff0c\u4e14\u80fd\u89e3\u91ca\u4ece\u51cf\u901f\u5230\u52a0\u901f\u81a8\u80c0\u7684\u8f6c\u53d8\u3002", "motivation": "\u7814\u7a76\u5e7f\u4e49\u7231\u56e0\u65af\u5766-\u6807\u91cf-\u9ad8\u65af-\u535a\u5185\u6a21\u578b\uff0c\u63a2\u7d22\u5305\u542b\u6807\u91cf\u573a\u4e0e\u9ad8\u65af-\u535a\u5185\u4e0d\u53d8\u91cf\u975e\u6700\u5c0f\u8026\u5408\u7684\u6697\u80fd\u91cf\u6a21\u578b\uff0c\u4ee5\u89e3\u91ca\u5b87\u5b99\u52a0\u901f\u81a8\u80c0\u73b0\u8c61\u5e76\u8bc4\u4f30\u5176\u76f8\u5bf9\u4e8e\u6807\u51c6\u039bCDM\u6a21\u578b\u7684\u4f18\u8d8a\u6027\u3002", "method": "\u5e94\u7528Noether\u5bf9\u79f0\u65b9\u6cd5\u83b7\u5f97\u89e3\u6790\u89e3\uff1b\u901a\u8fc7\u53d8\u5206\u539f\u7406\u548c\u5fae\u6270\u7406\u8bba\u63a8\u5bfc\u8fd0\u52a8\u65b9\u7a0b\u548c\u5f20\u91cf\u6270\u52a8\u4f20\u64ad\u901f\u5ea6\uff1b\u4f7f\u7528\u5b87\u5b99\u8ba1\u65f6\u5668\u3001\u91cd\u5b50\u58f0\u5b66\u632f\u8361\u548cIa\u578b\u8d85\u65b0\u661f\u6570\u636e\u8fdb\u884c\u6a21\u578b\u9a8c\u8bc1\uff1b\u57fa\u4e8e\u4fe1\u606f\u51c6\u5219\u8fdb\u884c\u6a21\u578b\u9009\u62e9\uff1b\u5206\u6790\u6162\u6eda\u53c2\u6570\u3001\u8c31\u6307\u6570\u548c\u5f20\u91cf-\u6807\u91cf\u6bd4\u6765\u7814\u7a76\u65e9\u671f\u5b87\u5b99\u52a8\u529b\u5b66\u3002", "result": "\u54c8\u52c3\u53c2\u6570\u5305\u542b\u6765\u81ea\u521a\u4f53\u7269\u8d28\u548c\u6697\u80fd\u91cf\u7684\u8d21\u732e\uff1b\u4fe1\u606f\u51c6\u5219\u663e\u793a\u8be5\u65b0\u6846\u67b6\u7565\u4f18\u4e8e\u039bCDM\u6a21\u578b\uff1b\u6a21\u578b\u7a33\u5b9a\uff08\u58f0\u901f\u4e3a\u6b63\u4e14\u65e0Ostrogradsky\u9b3c\u6001\uff09\uff1b\u603b\u72b6\u6001\u53c2\u6570\u8868\u660e\u5728z\u22480.66\u5904\u5b58\u5728\u4ece\u51cf\u901f\u5230\u52a0\u901f\u81a8\u80c0\u7684\u8f6c\u53d8\uff1b\u65e9\u671f\u5b87\u5b99\u52a8\u529b\u5b66\u4e0ePlanck 2018\u548cACT\u89c2\u6d4b\u5b8c\u5168\u4e00\u81f4\u3002", "conclusion": "\u8be5\u5e7f\u4e49\u7231\u56e0\u65af\u5766-\u6807\u91cf-\u9ad8\u65af-\u535a\u5185\u6a21\u578b\u5728\u89c2\u6d4b\u4e0a\u53ef\u884c\uff0c\u7565\u4f18\u4e8e\u6807\u51c6\u039bCDM\u6a21\u578b\uff0c\u80fd\u89e3\u91ca\u5b87\u5b99\u52a0\u901f\u81a8\u80c0\u7684\u8f6c\u53d8\uff0c\u4e14\u65e9\u671f\u5b87\u5b99\u9884\u6d4b\u4e0e\u5f53\u524d\u89c2\u6d4b\u4e00\u81f4\uff0c\u4e3a\u6697\u80fd\u91cf\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2512.06243", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.06243", "abs": "https://arxiv.org/abs/2512.06243", "authors": ["Rohan Pandey", "Eric Ye"], "title": "Quantization Blindspots: How Model Compression Breaks Backdoor Defenses", "comment": "10 pages", "summary": "Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple question: how do existing backdoor defenses behave under standard quantization pipelines? We conduct a systematic empirical study of five representative defenses across three precision settings (FP32, INT8 dynamic, INT4 simulated) and two standard vision benchmarks using a canonical BadNet attack. We observe that INT8 quantization reduces the detection rate of all evaluated defenses to 0% while leaving attack success rates above 99%. For INT4, we find a pronounced dataset dependence: Neural Cleanse remains effective on GTSRB but fails on CIFAR-10, even though backdoors continue to survive quantization with attack success rates above 90%. Our results expose a mismatch between how defenses are commonly evaluated (on FP32 models) and how models are actually deployed (in quantized form), and they highlight quantization robustness as a necessary axis in future evaluations and designs of backdoor defenses.", "AI": {"tldr": "\u91cf\u5316\uff08INT8/INT4\uff09\u663e\u8457\u964d\u4f4e\u73b0\u6709\u540e\u95e8\u9632\u5fa1\u68c0\u6d4b\u7387\u81f30%\uff0c\u800c\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\u4ecd\u4fdd\u630190%\u4ee5\u4e0a\uff0c\u66b4\u9732\u4e86\u9632\u5fa1\u8bc4\u4f30\u4e0e\u6a21\u578b\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754cML\u7cfb\u7edf\u90e8\u7f72\u65f6\u666e\u904d\u91c7\u7528\u91cf\u5316\u6280\u672f\uff08INT8\u6216\u66f4\u4f4e\u7cbe\u5ea6\uff09\u6765\u51cf\u5c11\u5185\u5b58\u548c\u5ef6\u8fdf\uff0c\u4f46\u73b0\u6709\u7684\u540e\u95e8\u9632\u5fa1\u7814\u7a76\u4e3b\u8981\u5728FP32\u7cbe\u5ea6\u4e0b\u8bc4\u4f30\uff0c\u8fd9\u79cd\u8bc4\u4f30\u65b9\u5f0f\u4e0e\u5b9e\u9645\u90e8\u7f72\u60c5\u51b5\u5b58\u5728\u8131\u8282\u3002", "method": "\u5bf9\u4e94\u79cd\u4ee3\u8868\u6027\u540e\u95e8\u9632\u5fa1\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u5728\u4e09\u79cd\u7cbe\u5ea6\u8bbe\u7f6e\uff08FP32\u3001INT8\u52a8\u6001\u91cf\u5316\u3001INT4\u6a21\u62df\u91cf\u5316\uff09\u548c\u4e24\u4e2a\u6807\u51c6\u89c6\u89c9\u57fa\u51c6\uff08GTSRB\u3001CIFAR-10\uff09\u4e0a\uff0c\u4f7f\u7528\u7ecf\u5178\u7684BadNet\u653b\u51fb\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "INT8\u91cf\u5316\u5c06\u6240\u6709\u9632\u5fa1\u65b9\u6cd5\u7684\u68c0\u6d4b\u7387\u964d\u81f30%\uff0c\u800c\u653b\u51fb\u6210\u529f\u7387\u4ecd\u9ad8\u4e8e99%\u3002INT4\u91cf\u5316\u8868\u73b0\u51fa\u660e\u663e\u7684\u6570\u636e\u96c6\u4f9d\u8d56\u6027\uff1aNeural Cleanse\u5728GTSRB\u4e0a\u6709\u6548\u4f46\u5728CIFAR-10\u4e0a\u5931\u6548\uff0c\u800c\u540e\u95e8\u653b\u51fb\u5728\u91cf\u5316\u540e\u4ecd\u4fdd\u630190%\u4ee5\u4e0a\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u91cf\u5316\u9c81\u68d2\u6027\u5e94\u6210\u4e3a\u672a\u6765\u540e\u95e8\u9632\u5fa1\u8bc4\u4f30\u548c\u8bbe\u8ba1\u7684\u5fc5\u8981\u7ef4\u5ea6\uff0c\u9700\u8981\u89e3\u51b3\u9632\u5fa1\u8bc4\u4f30\uff08FP32\uff09\u4e0e\u6a21\u578b\u5b9e\u9645\u90e8\u7f72\uff08\u91cf\u5316\u5f62\u5f0f\uff09\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2512.06418", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06418", "abs": "https://arxiv.org/abs/2512.06418", "authors": ["Wen Zhou", "Zhong-Xi Shen", "Hong-Xing Wu", "Zhi-Xi Wang", "Shao-Ming Fei"], "title": "Generalized product-form monogamy relations in multi-qubit systems", "comment": "6 pages", "summary": "Monogamy of entanglement essentially characterizes the entanglement distributions among the subsystems. Generally it is given by summation-form monogamy inequalities. In this paper, we present the product-form monogamy inequalities satisfied by the $\u03bd$-th ($\u03bd\\geq2$) power of the concurrence. We show that they are tighter than the existing ones by detailed example. We then establish tighter product-form monogamy inequalities based on the negativity. We show that they are valid even for high dimensional states to which the well-known CKW inequality is violated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8econcurrence\u548cnegativity\u7684\u4e58\u79ef\u5f62\u5f0f\u7ea0\u7f20\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\uff0c\u6bd4\u73b0\u6709\u4e0d\u7b49\u5f0f\u66f4\u7d27\u81f4\uff0c\u4e14\u9002\u7528\u4e8e\u9ad8\u7ef4\u91cf\u5b50\u6001", "motivation": "\u7ea0\u7f20\u5355\u914d\u6027\u63cf\u8ff0\u4e86\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7ea0\u7f20\u7684\u5206\u5e03\u7279\u6027\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6c42\u548c\u5f62\u5f0f\u7684\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u66f4\u7d27\u81f4\u7684\u4e58\u79ef\u5f62\u5f0f\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u91cf\u5b50\u6001\u4e2d\u7684\u5e94\u7528", "method": "\u63d0\u51fa\u57fa\u4e8econcurrence\u7684\u03bd\u6b21\u5e42\uff08\u03bd\u22652\uff09\u7684\u4e58\u79ef\u5f62\u5f0f\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u4f8b\u5b50\u8bc1\u660e\u5176\u7d27\u81f4\u6027\uff1b\u8fdb\u4e00\u6b65\u5efa\u7acb\u57fa\u4e8enegativity\u7684\u4e58\u79ef\u5f62\u5f0f\u5355\u914d\u6027\u4e0d\u7b49\u5f0f", "result": "\u63d0\u51fa\u7684\u4e58\u79ef\u5f62\u5f0f\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\u6bd4\u73b0\u6709\u4e0d\u7b49\u5f0f\u66f4\u7d27\u81f4\uff1b\u57fa\u4e8enegativity\u7684\u4e58\u79ef\u5f62\u5f0f\u4e0d\u7b49\u5f0f\u5373\u4f7f\u5728CKW\u4e0d\u7b49\u5f0f\u5931\u6548\u7684\u9ad8\u7ef4\u91cf\u5b50\u6001\u4e2d\u4ecd\u7136\u6210\u7acb", "conclusion": "\u4e58\u79ef\u5f62\u5f0f\u7684\u5355\u914d\u6027\u4e0d\u7b49\u5f0f\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u6c42\u548c\u5f62\u5f0f\u66f4\u7d27\u81f4\u7684\u7ea0\u7f20\u5206\u5e03\u63cf\u8ff0\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5177\u6709\u66f4\u597d\u7684\u9002\u7528\u6027\uff0c\u4e3a\u7ea0\u7f20\u5355\u914d\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177"}}
{"id": "2512.07205", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07205", "abs": "https://arxiv.org/abs/2512.07205", "authors": ["Eunjung Lee", "Hee-Suk Cho", "Chang-Hwan Lee"], "title": "Systematic bias due to eccentricity in parameter estimation for merging binary neutron stars : spinning case", "comment": "9 pages, 11 figures, Submitted", "summary": "In our previous work [Phys. Rev. D {\\bf 105}. 124022 (2022)], we studied the impact of eccentricity on gravitational-wave parameter estimation for a nonspinning binary neutron star (BNS) system. We here extend the work to a more realistic case by including the spin parameter in the system. As in the previous work, we employ the analytic Fisher-Cutler-Vallisneri method to calculate the systematic bias that can be produced by using noneccentric waveforms in parameter estimation, and we verify the reliability of the method by comparing it with numerical Bayesian parameter estimation results. We generate $10^4$ BNS sources randomly distributed in the parameter space $m_1$-$m_2$-$\u03c7_{\\rm eff}$-$e_0$, where the nuetron star mass is in the range of $1 M_\\odot \\leq m_{1,2}\\leq 2M_\\odot (m_2 \\leq m_1)$, the effective spin is $-0.2 \\leq \u03c7_{\\rm eff} \\leq0 .2$, and the eccentricity (at the reference frequency 10 Hz) is $0 \\leq e_0 \\leq 0.024$. For the true value of the tidal deformability ($\u03bb$) of neutron stars, we assume the equation of state model APR4. For all gravitational-wave signals emitted from the sources, we calculate the systematic biases ($\u0394\u03b8$) for the chirp mass ($M_c$), symmetric mass ratio ($\u03b7$), effective spin ($\u03c7_{\\rm eff}$), and effective tidal deformability ($\\tilde\u03bb$), and obtain generalized distributions of the biases. The distribution of biases in $M_c, \u03b7$, and $\u03c7_{\\rm eff}$ shows narrow bands that increase or decrease quadratically with increasing $e_0$, indicating a weak dependence of biases on the three parameters. On the other hand, the biases of $\\tilde\u03bb$ are widely distributed depending on the values of the mass and spin parameters at a given $e_0$. We investigate the implications of biased parameters for the inference of neutron star properties by performing Bayesian parameter estimation for specific cases.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u5148\u524d\u5173\u4e8e\u504f\u5fc3\u53cc\u4e2d\u5b50\u661f\u5f15\u529b\u6ce2\u53c2\u6570\u4f30\u8ba1\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u52a0\u5165\u81ea\u65cb\u53c2\u6570\uff0c\u4f7f\u7528Fisher-Cutler-Vallisneri\u65b9\u6cd5\u5206\u6790\u4f7f\u7528\u975e\u504f\u5fc3\u6ce2\u5f62\u5bfc\u81f4\u7684\u7cfb\u7edf\u504f\u5dee\uff0c\u5e76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u5df2\u63a2\u8ba8\u4e86\u504f\u5fc3\u5bf9\u65e0\u81ea\u65cb\u53cc\u4e2d\u5b50\u661f\u7cfb\u7edf\u5f15\u529b\u6ce2\u53c2\u6570\u4f30\u8ba1\u7684\u5f71\u54cd\uff0c\u4f46\u5b9e\u9645\u53cc\u4e2d\u5b50\u661f\u7cfb\u7edf\u901a\u5e38\u5177\u6709\u81ea\u65cb\u3002\u56e0\u6b64\u9700\u8981\u5c06\u7814\u7a76\u6269\u5c55\u5230\u5305\u542b\u81ea\u65cb\u7684\u66f4\u73b0\u5b9e\u60c5\u51b5\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30\u504f\u5fc3\u5bf9\u53c2\u6570\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u89e3\u6790\u7684Fisher-Cutler-Vallisneri\u65b9\u6cd5\u8ba1\u7b97\u4f7f\u7528\u975e\u504f\u5fc3\u6ce2\u5f62\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\u65f6\u4ea7\u751f\u7684\u7cfb\u7edf\u504f\u5dee\uff0c\u5e76\u901a\u8fc7\u4e0e\u6570\u503c\u8d1d\u53f6\u65af\u53c2\u6570\u4f30\u8ba1\u7ed3\u679c\u6bd4\u8f83\u9a8c\u8bc1\u65b9\u6cd5\u53ef\u9760\u6027\u3002\u968f\u673a\u751f\u621010^4\u4e2a\u53cc\u4e2d\u5b50\u661f\u6e90\uff0c\u53c2\u6570\u7a7a\u95f4\u5305\u62ec\u8d28\u91cf(m1,m2)\u3001\u6709\u6548\u81ea\u65cb(\u03c7_eff)\u548c\u504f\u5fc3(e0)\uff0c\u5047\u8bbeAPR4\u72b6\u6001\u65b9\u7a0b\u7684\u6f6e\u6c50\u5f62\u53d8\u53c2\u6570\u4f5c\u4e3a\u771f\u503c\u3002", "result": "\u5bf9\u4e8eM_c\u3001\u03b7\u548c\u03c7_eff\u7684\u504f\u5dee\u5206\u5e03\u5448\u73b0\u7a84\u5e26\uff0c\u968fe0\u589e\u52a0\u5448\u4e8c\u6b21\u51fd\u6570\u589e\u51cf\uff0c\u8868\u660e\u504f\u5dee\u5bf9\u8fd9\u4e09\u4e2a\u53c2\u6570\u7684\u4f9d\u8d56\u6027\u8f83\u5f31\u3002\u800c~\u03bb\u7684\u504f\u5dee\u5206\u5e03\u5e7f\u6cdb\uff0c\u5728\u7ed9\u5b9ae0\u4e0b\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u8d28\u91cf\u548c\u81ea\u65cb\u53c2\u6570\u3002\u901a\u8fc7\u8d1d\u53f6\u65af\u53c2\u6570\u4f30\u8ba1\u9a8c\u8bc1\u4e86\u504f\u5dee\u5bf9\u4e2d\u5b50\u661f\u6027\u8d28\u63a8\u65ad\u7684\u5f71\u54cd\u3002", "conclusion": "\u504f\u5fc3\u5bf9\u53cc\u4e2d\u5b50\u661f\u5f15\u529b\u6ce2\u53c2\u6570\u4f30\u8ba1\u7684\u5f71\u54cd\u5728\u5305\u542b\u81ea\u65cb\u7684\u60c5\u51b5\u4e0b\u4f9d\u7136\u663e\u8457\uff0c\u7279\u522b\u662f\u5bf9\u6f6e\u6c50\u5f62\u53d8\u53c2\u6570\u7684\u4f30\u8ba1\u504f\u5dee\u8f83\u5927\u4e14\u4f9d\u8d56\u4e8e\u7cfb\u7edf\u53c2\u6570\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u5f15\u529b\u6ce2\u6570\u636e\u5206\u6790\u4e2d\u8003\u8651\u504f\u5fc3\u6548\u5e94\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e2d\u5b50\u661f\u72b6\u6001\u65b9\u7a0b\u7684\u7ea6\u675f\u7814\u7a76\u3002"}}
{"id": "2512.06244", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.06244", "abs": "https://arxiv.org/abs/2512.06244", "authors": ["Caleb Ju", "Guanghui Lan"], "title": "Auto-exploration for online reinforcement learning", "comment": "35 pages (9 appendix), 1 figure. Comments are welcome", "summary": "The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(\u03b5^{-2})$ sample complexity to solve to $\u03b5$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.", "AI": {"tldr": "\u63d0\u51fa\u5177\u6709\u81ea\u52a8\u63a2\u7d22\u529f\u80fd\u7684\u65b0RL\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u9a8c\u53c2\u6570\u77e5\u8bc6\uff0c\u5b9e\u73b0O(\u03b5\u207b\u00b2)\u6837\u672c\u590d\u6742\u5ea6", "motivation": "\u73b0\u6709RL\u7b97\u6cd5\u9700\u8981\u5047\u8bbe\u5145\u5206\u7684\u63a2\u7d22\uff0c\u5bfc\u81f4\u7b97\u6cd5\u4e0d\u53ef\u5b9e\u73b0\u4e14\u6027\u80fd\u6b21\u4f18\uff0c\u9700\u8981\u53c2\u6570\u65e0\u5173\u7684\u81ea\u52a8\u63a2\u7d22\u65b9\u6cd5", "method": "\u63d0\u51fa\u4e24\u79cd\u53d8\u4f53\uff1a\u8868\u683c\u8bbe\u7f6e\u548c\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\uff0c\u91c7\u7528\u52a8\u6001\u6df7\u5408\u65f6\u95f4\u3001\u6298\u6263\u72b6\u6001\u5206\u5e03\u91c7\u6837\u3001\u9c81\u68d2\u68af\u5ea6\u4f30\u8ba1\u5668\u548c\u4f18\u52bf\u5dee\u8ddd\u51fd\u6570", "result": "\u5728\u5b58\u5728\u63a2\u7d22\u6700\u4f18\u7b56\u7565\u7684\u5047\u8bbe\u4e0b\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u8fbe\u5230O(\u03b5\u207b\u00b2)\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4e14\u590d\u6742\u5ea6\u4e0d\u5305\u542b\u7b97\u6cd5\u4f9d\u8d56\u53c2\u6570", "conclusion": "\u65b0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u53c2\u6570\u65e0\u5173\u7684\u81ea\u52a8\u63a2\u7d22\uff0c\u7b80\u5355\u6613\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRL\u7b97\u6cd5\u7684\u63a2\u7d22-\u5229\u7528\u56f0\u5883"}}
{"id": "2512.06429", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2512.06429", "abs": "https://arxiv.org/abs/2512.06429", "authors": ["Jaeyong Hwang", "Tianrui Xu", "Sean R. Muleady", "Steven Pampel", "Gur Lubin", "Dawson Hewatt", "Cindy A. Regal", "Ana Maria Rey"], "title": "Hybrid qubit-oscillator module with motional states of two trapped interacting atoms", "comment": null, "summary": "We propose the use of motional states of two interacting atoms trapped in a potential stroboscopically engineered by an optical tweezer as a means to implement a qubit-oscillator system, in analogy to those implemented in circuit quantum electrodynamics and trapped ions. In our setting, the center of mass degree of freedom of the atoms plays the role of a photon or phonon mode, while the interacting, relative mode acts as a qubit. No internal state is involved in our system, which makes this motional qubit robust to spin-dependent noise. We show that a universal set of bosonic operations, including displacement, rotation, squeezing, and the corresponding set of gates controlled by the qubit, can be implemented through precise temporal modulation of the optical tweezers. We numerically check that these gates can be generated with high fidelity, and discuss possible schemes for initial state preparation and final state readout. While we restrict the discussion to a single qubit-oscillator module, scalability can be achieved by coupling arrays of atoms via dipolar or Rydberg-dressed interactions.", "AI": {"tldr": "\u5229\u7528\u53cc\u539f\u5b50\u5728\u5149\u5b66\u954a\u5b50\u52bf\u9631\u4e2d\u7684\u8fd0\u52a8\u72b6\u6001\u5b9e\u73b0\u7c7b\u7535\u8defQED\u548c\u79bb\u5b50\u9631\u7684\u91cf\u5b50\u6bd4\u7279-\u632f\u5b50\u7cfb\u7edf\uff0c\u5176\u4e2d\u8d28\u5fc3\u8fd0\u52a8\u4f5c\u4e3a\u632f\u5b50\u6a21\u5f0f\uff0c\u76f8\u5bf9\u8fd0\u52a8\u4f5c\u4e3a\u91cf\u5b50\u6bd4\u7279\uff0c\u65e0\u9700\u5185\u90e8\u6001\u53c2\u4e0e\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u7684\u91cf\u5b50\u6bd4\u7279-\u632f\u5b50\u7cfb\u7edf\u5b9e\u73b0\u65b9\u6848\uff0c\u5229\u7528\u539f\u5b50\u8fd0\u52a8\u72b6\u6001\u800c\u975e\u5185\u90e8\u6001\u6765\u6784\u5efa\u91cf\u5b50\u6bd4\u7279\uff0c\u4ece\u800c\u907f\u514d\u81ea\u65cb\u76f8\u5173\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u501f\u9274\u7535\u8def\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u548c\u79bb\u5b50\u9631\u7cfb\u7edf\u7684\u6210\u529f\u7ecf\u9a8c\u3002", "method": "\u901a\u8fc7\u5149\u5b66\u954a\u5b50\u7684\u7cbe\u786e\u65f6\u95f4\u8c03\u5236\u6765\u5de5\u7a0b\u5316\u52bf\u9631\uff0c\u5b9e\u73b0\u53cc\u539f\u5b50\u7cfb\u7edf\u7684\u8fd0\u52a8\u72b6\u6001\u63a7\u5236\u3002\u8d28\u5fc3\u81ea\u7531\u5ea6\u4f5c\u4e3a\u632f\u5b50\u6a21\u5f0f\uff0c\u76f8\u4e92\u4f5c\u7528\u7684\u76f8\u5bf9\u6a21\u5f0f\u4f5c\u4e3a\u91cf\u5b50\u6bd4\u7279\u3002\u901a\u8fc7\u8c03\u5236\u5149\u5b66\u954a\u5b50\u5b9e\u73b0\u4f4d\u79fb\u3001\u65cb\u8f6c\u3001\u538b\u7f29\u7b49\u73bb\u8272\u5b50\u64cd\u4f5c\u4ee5\u53ca\u91cf\u5b50\u6bd4\u7279\u63a7\u5236\u7684\u901a\u7528\u95e8\u96c6\u5408\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\u8fd9\u4e9b\u91cf\u5b50\u95e8\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\uff0c\u8ba8\u8bba\u4e86\u521d\u59cb\u6001\u5236\u5907\u548c\u6700\u7ec8\u6001\u8bfb\u53d6\u7684\u53ef\u80fd\u65b9\u6848\u3002\u7cfb\u7edf\u53ef\u4ee5\u6269\u5c55\u5230\u901a\u8fc7\u5076\u6781\u6216\u91cc\u5fb7\u5821\u4fee\u9970\u76f8\u4e92\u4f5c\u7528\u8026\u5408\u7684\u539f\u5b50\u9635\u5217\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u5b50\u8fd0\u52a8\u72b6\u6001\u7684\u65b0\u578b\u91cf\u5b50\u6bd4\u7279-\u632f\u5b50\u7cfb\u7edf\u5b9e\u73b0\u65b9\u6848\uff0c\u8be5\u7cfb\u7edf\u5bf9\u81ea\u65cb\u76f8\u5173\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u901a\u7528\u91cf\u5b50\u64cd\u4f5c\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u524d\u666f\u3002"}}
{"id": "2512.07364", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07364", "abs": "https://arxiv.org/abs/2512.07364", "authors": ["S. M. Holme", "H. S. Ramadhan", "I. Nurul Huda", "Leonardus B. Putra"], "title": "Orbital dynamics and spin-precession around a circular chiral vorton", "comment": "36 pages, 22 figures", "summary": "Vortons are of interest in high-energy physics as possible dark matter candidates and as probes of Grand Unified Theories. Using the recently derived weak-field metric for a chiral vorton, we study the dynamics of test particles by analyzing both timelike and null geodesics. We identify several classes of trajectories, including bound precessing orbits, circular orbits, toroidal, and crown-type oscillations, as well as unbound scattering paths. Poincare surfaces of section reveal transitions between regular and chaotic motions that depend sensitively on the vorton tension $G\u03bc$ and initial conditions. We further compute the Lense-Thirring and general spin-precession frequencies for gyroscopes along Killing trajectories. The resulting precession profiles exhibit several distinct features not present in Kerr black holes but reminiscent of Kerr naked singularities, such as: divergences near the ring core, and multi-minima structures. These dynamical and precessional signatures may offer potential observational pathways for detecting vortons.", "AI": {"tldr": "\u7814\u7a76\u624b\u5f81\u6da1\u65cb\u73af\uff08vorton\uff09\u7684\u5f31\u573a\u5ea6\u89c4\u4e0b\u6d4b\u8bd5\u7c92\u5b50\u7684\u52a8\u529b\u5b66\uff0c\u5305\u62ec\u7c7b\u65f6\u548c\u96f6\u6d4b\u5730\u7ebf\uff0c\u53d1\u73b0\u591a\u79cd\u8f68\u9053\u7c7b\u578b\u548c\u6df7\u6c8c\u8fd0\u52a8\uff0c\u5e76\u8ba1\u7b97\u9640\u87ba\u4eea\u8fdb\u52a8\u9891\u7387\uff0c\u8fd9\u4e9b\u7279\u5f81\u53ef\u80fd\u4e3a\u63a2\u6d4b\u6da1\u65cb\u73af\u63d0\u4f9b\u89c2\u6d4b\u9014\u5f84\u3002", "motivation": "\u6da1\u65cb\u73af\u5728\u9ad8\u80fd\u7269\u7406\u4e2d\u4f5c\u4e3a\u53ef\u80fd\u7684\u6697\u7269\u8d28\u5019\u9009\u8005\u548c\u5927\u7edf\u4e00\u7406\u8bba\u7684\u63a2\u9488\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u5176\u52a8\u529b\u5b66\u7279\u5f81\u6709\u52a9\u4e8e\u5bfb\u627e\u89c2\u6d4b\u8fd9\u4e9b\u7406\u8bba\u5b9e\u4f53\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6700\u8fd1\u63a8\u5bfc\u7684\u624b\u5f81\u6da1\u65cb\u73af\u5f31\u573a\u5ea6\u89c4\uff0c\u5206\u6790\u6d4b\u8bd5\u7c92\u5b50\u7684\u7c7b\u65f6\u548c\u96f6\u6d4b\u5730\u7ebf\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u5e9e\u52a0\u83b1\u622a\u9762\u7814\u7a76\u89c4\u5219\u4e0e\u6df7\u6c8c\u8fd0\u52a8\u7684\u8f6c\u53d8\uff0c\u5e76\u8ba1\u7b97\u6cbfKilling\u8f68\u8ff9\u7684\u9640\u87ba\u4eea\u7684Lense-Thirring\u548c\u81ea\u65cb\u8fdb\u52a8\u9891\u7387\u3002", "result": "\u8bc6\u522b\u51fa\u591a\u79cd\u8f68\u9053\u7c7b\u578b\uff1a\u675f\u7f1a\u8fdb\u52a8\u8f68\u9053\u3001\u5706\u5f62\u8f68\u9053\u3001\u73af\u9762\u548c\u51a0\u72b6\u632f\u8361\uff0c\u4ee5\u53ca\u975e\u675f\u7f1a\u6563\u5c04\u8def\u5f84\u3002\u5e9e\u52a0\u83b1\u622a\u9762\u663e\u793a\u89c4\u5219\u4e0e\u6df7\u6c8c\u8fd0\u52a8\u4e4b\u95f4\u7684\u8f6c\u53d8\u5bf9\u6da1\u65cb\u73af\u5f20\u529bG\u03bc\u548c\u521d\u59cb\u6761\u4ef6\u654f\u611f\u3002\u8fdb\u52a8\u5256\u9762\u663e\u793a\u51fa\u514b\u5c14\u9ed1\u6d1e\u4e2d\u4e0d\u5b58\u5728\u4f46\u7c7b\u4f3c\u514b\u5c14\u88f8\u5947\u70b9\u7684\u7279\u5f81\uff1a\u73af\u6838\u9644\u8fd1\u7684\u53d1\u6563\u548c\u591a\u6781\u5c0f\u503c\u7ed3\u6784\u3002", "conclusion": "\u8fd9\u4e9b\u52a8\u529b\u5b66\u548c\u8fdb\u52a8\u7279\u5f81\u53ef\u80fd\u4e3a\u63a2\u6d4b\u6da1\u65cb\u73af\u63d0\u4f9b\u6f5c\u5728\u7684\u89c2\u6d4b\u9014\u5f84\uff0c\u6da1\u65cb\u73af\u7684\u72ec\u7279\u7279\u5f81\u4e0e\u514b\u5c14\u9ed1\u6d1e\u4e0d\u540c\uff0c\u66f4\u7c7b\u4f3c\u4e8e\u514b\u5c14\u88f8\u5947\u70b9\u3002"}}
{"id": "2512.06250", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06250", "abs": "https://arxiv.org/abs/2512.06250", "authors": ["Chris Tava"], "title": "Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning", "comment": "7 pages", "summary": "Autonomous agents often require multiple strategies to solve complex tasks, but determining when to switch between strategies remains challenging. This research introduces a reinforcement learning technique to learn switching thresholds between two orthogonal navigation policies. Using maze navigation as a case study, this work demonstrates how an agent can dynamically transition between systematic exploration (coverage) and goal-directed pathfinding (convergence) to improve task performance. Unlike fixed-threshold approaches, the agent uses Q-learning to adapt switching behavior based on coverage percentage and distance to goal, requiring only minimal domain knowledge: maze dimensions and target location. The agent does not require prior knowledge of wall positions, optimal threshold values, or hand-crafted heuristics; instead, it discovers effective switching strategies dynamically during each run. The agent discretizes its state space into coverage and distance buckets, then adapts which coverage threshold (20-60\\%) to apply based on observed progress signals. Experiments across 240 test configurations (4 maze sizes from 16$\\times$16 to 128$\\times$128 $\\times$ 10 unique mazes $\\times$ 6 agent variants) demonstrate that adaptive threshold learning outperforms both single-strategy agents and fixed 40\\% threshold baselines. Results show 23-55\\% improvements in completion time, 83\\% reduction in runtime variance, and 71\\% improvement in worst-case scenarios. The learned switching behavior generalizes within each size class to unseen wall configurations. Performance gains scale with problem complexity: 23\\% improvement for 16$\\times$16 mazes, 34\\% for 32$\\times$32, and 55\\% for 64$\\times$64, demonstrating that as the space of possible maze structures grows, the value of adaptive policy selection over fixed heuristics increases proportionally.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u7b56\u7565\u5207\u6362\u65b9\u6cd5\uff0c\u8ba9\u667a\u80fd\u4f53\u5728\u8ff7\u5bab\u5bfc\u822a\u4e2d\u52a8\u6001\u5207\u6362\u7cfb\u7edf\u63a2\u7d22\u548c\u76ee\u6807\u5bfc\u5411\u7b56\u7565\uff0c\u76f8\u6bd4\u56fa\u5b9a\u9608\u503c\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u81ea\u4e3b\u667a\u80fd\u4f53\u9700\u8981\u591a\u79cd\u7b56\u7565\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u4f55\u65f6\u5207\u6362\u7b56\u7565\u662f\u6311\u6218\u3002\u73b0\u6709\u56fa\u5b9a\u9608\u503c\u65b9\u6cd5\u4e0d\u591f\u7075\u6d3b\uff0c\u9700\u8981\u8bbe\u8ba1\u542f\u53d1\u5f0f\u89c4\u5219\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528Q-learning\u5b66\u4e60\u4e24\u4e2a\u6b63\u4ea4\u5bfc\u822a\u7b56\u7565\uff08\u7cfb\u7edf\u63a2\u7d22\u548c\u76ee\u6807\u5bfc\u5411\uff09\u4e4b\u95f4\u7684\u5207\u6362\u9608\u503c\u3002\u5c06\u72b6\u6001\u7a7a\u95f4\u79bb\u6563\u5316\u4e3a\u8986\u76d6\u7387\u548c\u8ddd\u79bb\u6876\uff0c\u57fa\u4e8e\u8986\u76d6\u767e\u5206\u6bd4\u548c\u76ee\u6807\u8ddd\u79bb\u81ea\u9002\u5e94\u8c03\u6574\u5207\u6362\u9608\u503c\uff0820-60%\uff09\u3002\u4ec5\u9700\u8ff7\u5bab\u5c3a\u5bf8\u548c\u76ee\u6807\u4f4d\u7f6e\u7b49\u6700\u5c0f\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u5728240\u4e2a\u6d4b\u8bd5\u914d\u7f6e\u4e2d\uff0c\u81ea\u9002\u5e94\u9608\u503c\u5b66\u4e60\u4f18\u4e8e\u5355\u7b56\u7565\u667a\u80fd\u4f53\u548c\u56fa\u5b9a40%\u9608\u503c\u57fa\u7ebf\uff1a\u5b8c\u6210\u65f6\u95f4\u63d0\u534723-55%\uff0c\u8fd0\u884c\u65f6\u65b9\u5dee\u51cf\u5c1183%\uff0c\u6700\u574f\u60c5\u51b5\u6539\u558471%\u3002\u6027\u80fd\u589e\u76ca\u968f\u95ee\u9898\u590d\u6742\u5ea6\u589e\u52a0\u800c\u6269\u5927\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u7b56\u7565\u5207\u6362\u80fd\u6709\u6548\u63d0\u5347\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u6216\u624b\u5de5\u542f\u53d1\u5f0f\u89c4\u5219\u3002\u968f\u7740\u95ee\u9898\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u81ea\u9002\u5e94\u65b9\u6cd5\u76f8\u6bd4\u56fa\u5b9a\u542f\u53d1\u5f0f\u7684\u4f18\u52bf\u66f4\u52a0\u660e\u663e\u3002"}}
{"id": "2512.06453", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06453", "abs": "https://arxiv.org/abs/2512.06453", "authors": ["S. K. Singh", "Mohamed Amazioug", "Jia-Xin Peng", "Mohammad Khalid"], "title": "Nonreciprocal photon blockade in a spinning microwave magnomechanical system through kerr-magnon and optical parametric amplifier", "comment": "12 pages, 8 figures", "summary": "Unconventional quantum antibunching, arising from quantum interference effects, represents a notable form of quantum correlation that has attracted significant attention for its ability to generate high-quality single-quantum sources. In this work, we propose a scheme to achieve and actively control strong photon blockade in a spinning microwave magnomechanical system by leveraging the combined nonlinear effects of Kerr-induced magnon interactions and an optical parametric amplifier. By exploiting the Sagnac-Fizeau shift, we establish nonreciprocal photon blockade and verify this effect through a combination of analytical modelling and numerical simulations. To gain intuitive insight into the underlying nonreciprocity, we approximate the equal-time second-order correlation function using the analytical solution of the Schr\u00f6dinger equation. This analytical result is then compared with the full numerical solution derived from the Lindblad master equation. The influences of thermal noise, the probe field amplitude, and the magnetic-dipole coupling strength are investigated within the constraints of the weak-coupling regime. The system's nonclassicality is characterized using the Mandel parameter, complemented by an analysis of the time evolution of the second-order correlation function. Our work provides a pathway for realizing nonreciprocal photon blockade in a nonlinear spinning microwave magnomechanical system.", "AI": {"tldr": "\u63d0\u51fa\u5728\u65cb\u8f6c\u5fae\u6ce2\u78c1\u673a\u68b0\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u975e\u4e92\u6613\u5149\u5b50\u963b\u585e\u7684\u65b9\u6848\uff0c\u5229\u7528\u514b\u5c14\u8bf1\u5bfc\u78c1\u632f\u5b50\u76f8\u4e92\u4f5c\u7528\u548c\u5149\u5b66\u53c2\u91cf\u653e\u5927\u5668\u7684\u7ec4\u5408\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u901a\u8fc7\u8428\u5c3c\u4e9a\u514b-\u83f2\u4f50\u4f4d\u79fb\u5b9e\u73b0\u5f3a\u5149\u5b50\u963b\u585e\u7684\u4e3b\u52a8\u63a7\u5236\u3002", "motivation": "\u975e\u5e38\u89c4\u91cf\u5b50\u53cd\u805a\u675f\u6548\u5e94\u6e90\u4e8e\u91cf\u5b50\u5e72\u6d89\uff0c\u80fd\u4ea7\u751f\u9ad8\u8d28\u91cf\u5355\u91cf\u5b50\u6e90\uff0c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u6587\u65e8\u5728\u5b9e\u73b0\u5e76\u4e3b\u52a8\u63a7\u5236\u65cb\u8f6c\u5fae\u6ce2\u78c1\u673a\u68b0\u7cfb\u7edf\u4e2d\u7684\u5f3a\u5149\u5b50\u963b\u585e\u3002", "method": "\u5229\u7528\u514b\u5c14\u8bf1\u5bfc\u78c1\u632f\u5b50\u76f8\u4e92\u4f5c\u7528\u548c\u5149\u5b66\u53c2\u91cf\u653e\u5927\u5668\u7684\u7ec4\u5408\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u901a\u8fc7\u8428\u5c3c\u4e9a\u514b-\u83f2\u4f50\u4f4d\u79fb\u5efa\u7acb\u975e\u4e92\u6613\u5149\u5b50\u963b\u585e\u3002\u91c7\u7528\u859b\u5b9a\u8c14\u65b9\u7a0b\u89e3\u6790\u89e3\u8fd1\u4f3c\u7b49\u65f6\u4e8c\u9636\u76f8\u5173\u51fd\u6570\uff0c\u5e76\u4e0e\u6797\u5fb7\u5e03\u62c9\u5fb7\u4e3b\u65b9\u7a0b\u7684\u5168\u6570\u503c\u89e3\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u975e\u4e92\u6613\u5149\u5b50\u963b\u585e\uff0c\u5728\u5f31\u8026\u5408\u6761\u4ef6\u4e0b\u7814\u7a76\u4e86\u70ed\u566a\u58f0\u3001\u63a2\u6d4b\u573a\u632f\u5e45\u548c\u78c1\u5076\u6781\u8026\u5408\u5f3a\u5ea6\u7684\u5f71\u54cd\u3002\u4f7f\u7528\u66fc\u5fb7\u5c14\u53c2\u6570\u8868\u5f81\u7cfb\u7edf\u7684\u975e\u7ecf\u5178\u6027\uff0c\u5e76\u5206\u6790\u4e86\u4e8c\u9636\u76f8\u5173\u51fd\u6570\u7684\u65f6\u95f4\u6f14\u5316\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u975e\u7ebf\u6027\u65cb\u8f6c\u5fae\u6ce2\u78c1\u673a\u68b0\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u975e\u4e92\u6613\u5149\u5b50\u963b\u585e\u63d0\u4f9b\u4e86\u4e00\u6761\u9014\u5f84\uff0c\u4e3a\u9ad8\u8d28\u91cf\u5355\u5149\u5b50\u6e90\u7684\u4ea7\u751f\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2512.07485", "categories": ["gr-qc", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.07485", "abs": "https://arxiv.org/abs/2512.07485", "authors": ["Jose Luis Alvarez-Perez"], "title": "The equation of Binet in classical and relativistic orbital mechanics", "comment": "10 pages, 2 figures", "summary": "Binet's equation provides a direct way to obtain the geometric shape of orbits in a central force field. It is well known that in Newtonian gravitation Binet's equation leads to all the conic curves as solutions for an inverse-square force. In this work, we show how Binet's equation arises from the horizontal and vertical infinitesimal displacements of a body in free fall and in inertial motion. This derivation uses elementary concepts of infinitesimal calculus. Second, we derive the relativistic version of Binet's equation for the Schwarzschild-(anti-)de Sitter metric. This derivation, which is novel, directly relates the coordinates involved in Binet's equation without the need to introduce potentials or the use of Killing vectors. Finally, we tackle some controversies related to the role of the cosmological constant in the trajectory of photons in a Schwarzschild-(anti-)de Sitter or even in Reissner-Nordstr\u00f6m-(anti-)de Sitter spacetimes.", "AI": {"tldr": "\u672c\u6587\u4ece\u81ea\u7531\u843d\u4f53\u548c\u60ef\u6027\u8fd0\u52a8\u7684\u65e0\u7a77\u5c0f\u4f4d\u79fb\u63a8\u5bfc\u51fa\u6bd4\u5948\u65b9\u7a0b\uff0c\u5e76\u9996\u6b21\u63a8\u5bfc\u51fa\u53f2\u74e6\u897f-(\u53cd-)\u5fb7\u897f\u7279\u5ea6\u89c4\u7684\u76f8\u5bf9\u8bba\u7248\u6bd4\u5948\u65b9\u7a0b\uff0c\u6f84\u6e05\u4e86\u5b87\u5b99\u5e38\u6570\u5728\u5149\u5b50\u8f68\u8ff9\u4e2d\u7684\u4f5c\u7528\u4e89\u8bae\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u4ece\u57fa\u7840\u7269\u7406\u89d2\u5ea6\u91cd\u65b0\u63a8\u5bfc\u6bd4\u5948\u65b9\u7a0b\uff0c\u5e76\u6269\u5c55\u5230\u5e7f\u4e49\u76f8\u5bf9\u8bba\u6846\u67b6\u3002\u4f20\u7edf\u63a8\u5bfc\u901a\u5e38\u4f7f\u7528\u52bf\u80fd\u6216Killing\u77e2\u91cf\uff0c\u800c\u672c\u6587\u5bfb\u6c42\u66f4\u76f4\u63a5\u7684\u51e0\u4f55\u63a8\u5bfc\u65b9\u6cd5\uff0c\u540c\u65f6\u6f84\u6e05\u5b87\u5b99\u5e38\u6570\u5728\u9ed1\u6d1e\u65f6\u7a7a\u5149\u5b50\u8f68\u8ff9\u4e2d\u7684\u4e89\u8bae\u6027\u4f5c\u7528\u3002", "method": "1. \u4f7f\u7528\u65e0\u7a77\u5c0f\u5fae\u79ef\u5206\u7684\u57fa\u672c\u6982\u5ff5\uff0c\u4ece\u81ea\u7531\u843d\u4f53\u548c\u60ef\u6027\u8fd0\u52a8\u7684\u6c34\u5e73\u548c\u5782\u76f4\u65e0\u7a77\u5c0f\u4f4d\u79fb\u63a8\u5bfc\u7ecf\u5178\u6bd4\u5948\u65b9\u7a0b\uff1b2. \u9996\u6b21\u76f4\u63a5\u63a8\u5bfc\u53f2\u74e6\u897f-(\u53cd-)\u5fb7\u897f\u7279\u5ea6\u89c4\u7684\u76f8\u5bf9\u8bba\u7248\u6bd4\u5948\u65b9\u7a0b\uff0c\u65e0\u9700\u5f15\u5165\u52bf\u80fd\u6216\u4f7f\u7528Killing\u77e2\u91cf\uff1b3. \u5206\u6790\u53f2\u74e6\u897f-(\u53cd-)\u5fb7\u897f\u7279\u548cReissner-Nordstr\u00f6m-(\u53cd-)\u5fb7\u897f\u7279\u65f6\u7a7a\u4e2d\u5b87\u5b99\u5e38\u6570\u5bf9\u5149\u5b50\u8f68\u8ff9\u7684\u5f71\u54cd\u3002", "result": "1. \u6210\u529f\u4ece\u57fa\u672c\u7269\u7406\u539f\u7406\u63a8\u5bfc\u51fa\u7ecf\u5178\u6bd4\u5948\u65b9\u7a0b\uff1b2. \u9996\u6b21\u83b7\u5f97\u53f2\u74e6\u897f-(\u53cd-)\u5fb7\u897f\u7279\u5ea6\u89c4\u7684\u76f8\u5bf9\u8bba\u6bd4\u5948\u65b9\u7a0b\u7684\u76f4\u63a5\u63a8\u5bfc\uff1b3. \u6f84\u6e05\u4e86\u5b87\u5b99\u5e38\u6570\u5728\u9ed1\u6d1e\u65f6\u7a7a\u5149\u5b50\u8f68\u8ff9\u4e2d\u7684\u4f5c\u7528\uff0c\u89e3\u51b3\u4e86\u76f8\u5173\u4e89\u8bae\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u6bd4\u5948\u65b9\u7a0b\u7684\u65b0\u63a8\u5bfc\u65b9\u6cd5\uff0c\u65e2\u5305\u62ec\u7ecf\u5178\u6846\u67b6\u7684\u57fa\u7840\u63a8\u5bfc\uff0c\u4e5f\u5305\u62ec\u5e7f\u4e49\u76f8\u5bf9\u8bba\u6846\u67b6\u7684\u6269\u5c55\u3002\u65b0\u7684\u76f8\u5bf9\u8bba\u63a8\u5bfc\u65b9\u6cd5\u66f4\u52a0\u76f4\u63a5\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u6f84\u6e05\u4e86\u5b87\u5b99\u5e38\u6570\u5728\u9ed1\u6d1e\u65f6\u7a7a\u52a8\u529b\u5b66\u4e2d\u7684\u786e\u5207\u4f5c\u7528\u3002"}}
{"id": "2512.06252", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06252", "abs": "https://arxiv.org/abs/2512.06252", "authors": ["Homayoon Farrahi", "A. Rupam Mahmood"], "title": "Learning Without Time-Based Embodiment Resets in Soft-Actor Critic", "comment": "In Proceedings of the 4th Conference on Lifelong Learning Agents (CoLLAs)", "summary": "When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $\u03b3$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5728\u65e0\u7ec8\u6b62\u548c\u65e0\u91cd\u7f6e\u6761\u4ef6\u4e0b\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u51fa\u6301\u7eedSAC\u7b97\u6cd5\u5e76\u5206\u6790\u91cd\u7f6e\u5bf9\u63a2\u7d22\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u589e\u52a0\u7b56\u7565\u71b5\u6765\u8865\u507f\u65e0\u91cd\u7f6e\u7684\u6027\u80fd\u635f\u5931", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u5e38\u4f7f\u7528\u7ec8\u6b62\u548c\u91cd\u7f6e\u7b49\u8f85\u52a9\u7ec4\u4ef6\u52a0\u901f\u5b66\u4e60\uff0c\u4f46\u8fd9\u4e9b\u8bbe\u7f6e\u4e0d\u81ea\u7136\u4e14\u53ef\u80fd\u963b\u788d\u73b0\u5b9e\u4e16\u754c\u7684\u957f\u671f\u6027\u80fd\u3002\u7814\u7a76\u63a2\u7d22\u5728\u6ca1\u6709\u7ec8\u6b62\u548c\u673a\u5668\u4eba\u8eab\u4f53\u91cd\u7f6e\u6761\u4ef6\u4e0b\u7684\u5b66\u4e60\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6301\u7eedSAC\u7b97\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u4fee\u6539\u5956\u52b1\u51fd\u6570\u5b9e\u73b0\u65e0\u7ec8\u6b62\u5b66\u4e60\u3002\u5206\u6790\u65e0\u91cd\u7f6e\u6761\u4ef6\u4e0b\u7684\u5b66\u4e60\u5931\u8d25\u539f\u56e0\uff0c\u63d0\u51fa\u901a\u8fc7\u589e\u52a0\u7b56\u7565\u71b5\u6765\u6539\u5584\u63a2\u7d22\u3002", "result": "\u6301\u7eedSAC\u5728\u65e0\u7ec8\u6b62\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0e\u6216\u4f18\u4e8e\u5468\u671f\u6027SAC\uff0c\u4e14\u964d\u4f4e\u5bf9\u6298\u6263\u7387\u03b3\u7684\u654f\u611f\u6027\u3002\u65e0\u91cd\u7f6e\u4f1a\u5bfc\u81f4\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u548c\u5b66\u4e60\u5931\u8d25\uff0c\u589e\u52a0\u7b56\u7565\u71b5\u80fd\u6709\u6548\u6062\u590d\u6027\u80fd\u3002", "conclusion": "\u8eab\u4f53\u91cd\u7f6e\u5bf9SAC\u7b97\u6cd5\u7684\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u81f3\u5173\u91cd\u8981\uff0c\u65e0\u91cd\u7f6e\u6761\u4ef6\u4e0b\u901a\u8fc7\u589e\u52a0\u7b56\u7565\u71b5\u53ef\u4ee5\u8865\u507f\u63a2\u7d22\u4e0d\u8db3\uff0c\u4f7f\u5b66\u4e60\u5728\u65e0\u7ec8\u6b62\u548c\u65e0\u91cd\u7f6e\u6761\u4ef6\u4e0b\u4ecd\u80fd\u6709\u6548\u8fdb\u884c\u3002"}}
{"id": "2512.06484", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06484", "abs": "https://arxiv.org/abs/2512.06484", "authors": ["Steven Hofmeyr", "Mathias Weiden", "Justin Kalloor", "John Kubiatowicz", "Costin Iancu"], "title": "Scheduling Lattice Surgery with Magic State Cultivation", "comment": null, "summary": "Fault-tolerant quantum computation using surface codes relies on efficient scheduling of non-Clifford operations, realized via the injection of magic states produced through a probabilistic process that dominates spacetime costs. Existing scheduling approaches use dedicated bus qubits for routing and separate peripheral ancilla qubit factories for magic state preparation, leading to inefficient resource utilization. With the advent of magic state cultivation, preparation qubits can be placed anywhere within the surface code architecture. We introduce Pure Magic scheduling, which dynamically re-purposes magic state cultivation qubits for routing operations, eliminating dedicated bus infrastructure. By interrupting cultivation when qubits are needed for routing, Pure Magic naturally favors shorter cultivation times while ensuring no ancilla qubit remains idle. Our evaluation across 17 benchmark circuits improves scheduling efficiency by 19% to 223% compared to traditional bus routing and decreases average magic state preparation time by 2.6x to 9.7x. Benefits scale with circuit parallelism, making Pure Magic particularly valuable for highly parallel quantum algorithms. The Pure Magic architecture represents a paradigm shift from static to dynamic, demand-driven scheduling in fault-tolerant quantum architectures.", "AI": {"tldr": "Pure Magic\u8c03\u5ea6\u901a\u8fc7\u52a8\u6001\u91cd\u7528\u9b54\u6001\u57f9\u517b\u91cf\u5b50\u6bd4\u7279\u8fdb\u884c\u8def\u7531\uff0c\u6d88\u9664\u4e13\u7528\u603b\u7ebf\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u8868\u9762\u7801\u91cf\u5b50\u8ba1\u7b97\u7684\u8c03\u5ea6\u6548\u7387\u548c\u9b54\u6001\u51c6\u5907\u65f6\u95f4", "motivation": "\u4f20\u7edf\u8868\u9762\u7801\u91cf\u5b50\u8ba1\u7b97\u4e2d\uff0c\u9b54\u6001\u8c03\u5ea6\u4f7f\u7528\u4e13\u7528\u603b\u7ebf\u91cf\u5b50\u6bd4\u7279\u8fdb\u884c\u8def\u7531\uff0c\u5e76\u91c7\u7528\u5206\u79bb\u7684\u5916\u56f4\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u5de5\u5382\u8fdb\u884c\u9b54\u6001\u51c6\u5907\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u4e0b\u3002\u968f\u7740\u9b54\u6001\u57f9\u517b\u6280\u672f\u7684\u53d1\u5c55\uff0c\u51c6\u5907\u91cf\u5b50\u6bd4\u7279\u53ef\u4ee5\u653e\u7f6e\u5728\u8868\u9762\u7801\u67b6\u6784\u7684\u4efb\u4f55\u4f4d\u7f6e\uff0c\u8fd9\u4e3a\u6539\u8fdb\u8c03\u5ea6\u65b9\u6cd5\u521b\u9020\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51faPure Magic\u8c03\u5ea6\u65b9\u6cd5\uff0c\u52a8\u6001\u5730\u5c06\u9b54\u6001\u57f9\u517b\u91cf\u5b50\u6bd4\u7279\u91cd\u65b0\u7528\u4e8e\u8def\u7531\u64cd\u4f5c\uff0c\u6d88\u9664\u4e13\u7528\u603b\u7ebf\u57fa\u7840\u8bbe\u65bd\u3002\u901a\u8fc7\u5f53\u91cf\u5b50\u6bd4\u7279\u9700\u8981\u7528\u4e8e\u8def\u7531\u65f6\u4e2d\u65ad\u57f9\u517b\u8fc7\u7a0b\uff0c\u8be5\u65b9\u6cd5\u81ea\u7136\u5730\u503e\u5411\u4e8e\u8f83\u77ed\u7684\u57f9\u517b\u65f6\u95f4\uff0c\u540c\u65f6\u786e\u4fdd\u6ca1\u6709\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u4fdd\u6301\u7a7a\u95f2\u72b6\u6001\u3002", "result": "\u572817\u4e2a\u57fa\u51c6\u7535\u8def\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u603b\u7ebf\u8def\u7531\u76f8\u6bd4\uff0c\u8c03\u5ea6\u6548\u7387\u63d0\u9ad8\u4e8619%\u5230223%\uff0c\u5e73\u5747\u9b54\u6001\u51c6\u5907\u65f6\u95f4\u51cf\u5c11\u4e862.6\u500d\u52309.7\u500d\u3002\u4f18\u52bf\u968f\u7740\u7535\u8def\u5e76\u884c\u5ea6\u7684\u589e\u52a0\u800c\u6269\u5927\uff0c\u4f7f\u5f97Pure Magic\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u5ea6\u5e76\u884c\u7684\u91cf\u5b50\u7b97\u6cd5\u3002", "conclusion": "Pure Magic\u67b6\u6784\u4ee3\u8868\u4e86\u5bb9\u9519\u91cf\u5b50\u67b6\u6784\u4ece\u9759\u6001\u8c03\u5ea6\u5230\u52a8\u6001\u3001\u9700\u6c42\u9a71\u52a8\u8c03\u5ea6\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u901a\u8fc7\u6d88\u9664\u4e13\u7528\u603b\u7ebf\u57fa\u7840\u8bbe\u65bd\u548c\u52a8\u6001\u91cd\u7528\u9b54\u6001\u57f9\u517b\u91cf\u5b50\u6bd4\u7279\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u8c03\u5ea6\u6548\u7387\u3002"}}
{"id": "2512.07545", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07545", "abs": "https://arxiv.org/abs/2512.07545", "authors": ["Bal\u00e1zs Endre Szigeti", "Imre Ferenc Barna", "Gergely G\u00e1bor Barnaf\u00f6ldi"], "title": "Asymptotic evolution of bulk-viscous, spherically symmetric spacetimes", "comment": "15 pages and 2 figures", "summary": "The scale-free nature of gravitational interaction in both Newtonian gravity and the general theory of relativity gives rise to the concept of self-similarity, where solutions are scale invariant. As a result of this property, the governing partial differential equations are greatly simplified and can be transformed into ordinary ones. These solutions function as attractors, characterizing the asymptotic dynamics of more general solutions. There exist situations in which self-similarity is only partially realized, giving rise to kinematic self-similar solutions. Our study provides a systematic classification of kinematic self-similar solutions corresponding to the most general spherically symmetric spacetime in the presence of bulk viscous flows.", "AI": {"tldr": "\u5bf9\u5e7f\u4e49\u7403\u5bf9\u79f0\u65f6\u7a7a\u4e2d\u7684\u8fd0\u52a8\u5b66\u81ea\u76f8\u4f3c\u89e3\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\uff0c\u8003\u8651\u4f53\u7c98\u6027\u6d41\u7684\u5f71\u54cd", "motivation": "\u5f15\u529b\u76f8\u4e92\u4f5c\u7528\u7684\u65e0\u6807\u5ea6\u6027\u8d28\u5bfc\u81f4\u81ea\u76f8\u4f3c\u6027\uff0c\u4f46\u5b58\u5728\u4ec5\u90e8\u5206\u5b9e\u73b0\u81ea\u76f8\u4f3c\u7684\u60c5\u51b5\uff0c\u9700\u8981\u7814\u7a76\u8fd0\u52a8\u5b66\u81ea\u76f8\u4f3c\u89e3", "method": "\u7cfb\u7edf\u5206\u7c7b\u6700\u4e00\u822c\u7403\u5bf9\u79f0\u65f6\u7a7a\u4e2d\u7684\u8fd0\u52a8\u5b66\u81ea\u76f8\u4f3c\u89e3\uff0c\u8003\u8651\u4f53\u7c98\u6027\u6d41\u7684\u5b58\u5728", "result": "\u63d0\u4f9b\u4e86\u8fd0\u52a8\u5b66\u81ea\u76f8\u4f3c\u89e3\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u8fd9\u4e9b\u89e3\u4f5c\u4e3a\u5438\u5f15\u5b50\u63cf\u8ff0\u66f4\u4e00\u822c\u89e3\u7684\u6e10\u8fd1\u52a8\u529b\u5b66", "conclusion": "\u8fd0\u52a8\u5b66\u81ea\u76f8\u4f3c\u89e3\u5728\u5f15\u529b\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u7279\u522b\u662f\u5728\u4f53\u7c98\u6027\u6d41\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u7406\u89e3\u5f15\u529b\u7cfb\u7edf\u7684\u6e10\u8fd1\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177"}}
{"id": "2512.06274", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06274", "abs": "https://arxiv.org/abs/2512.06274", "authors": ["Hanmo Zhang", "Zenghui Sun", "Kai Wang"], "title": "Networked Restless Multi-Arm Bandits with Reinforcement Learning", "comment": null, "summary": "Restless Multi-Armed Bandits (RMABs) are a powerful framework for sequential decision-making, widely applied in resource allocation and intervention optimization challenges in public health. However, traditional RMABs assume independence among arms, limiting their ability to account for interactions between individuals that can be common and significant in a real-world environment. This paper introduces Networked RMAB, a novel framework that integrates the RMAB model with the independent cascade model to capture interactions between arms in networked environments. We define the Bellman equation for networked RMAB and present its computational challenge due to exponentially large action and state spaces. To resolve the computational challenge, we establish the submodularity of Bellman equation and apply the hill-climbing algorithm to achieve a $1-\\frac{1}{e}$ approximation guarantee in Bellman updates. Lastly, we prove that the approximate Bellman updates are guaranteed to converge by a modified contraction analysis. We experimentally verify these results by developing an efficient Q-learning algorithm tailored to the networked setting. Experimental results on real-world graph data demonstrate that our Q-learning approach outperforms both $k$-step look-ahead and network-blind approaches, highlighting the importance of capturing and leveraging network effects where they exist.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Networked RMAB\u6846\u67b6\uff0c\u5c06\u4f20\u7edf\u591a\u81c2\u8001\u864e\u673a\u4e0e\u72ec\u7acb\u7ea7\u8054\u6a21\u578b\u7ed3\u5408\u4ee5\u6355\u6349\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e2a\u4f53\u4ea4\u4e92\uff0c\u901a\u8fc7\u8bc1\u660eBellman\u65b9\u7a0b\u7684\u5b50\u6a21\u6027\u5e76\u5e94\u7528\u722c\u5c71\u7b97\u6cd5\u83b7\u5f97\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u7684Q\u5b66\u4e60\u7b97\u6cd5\u5e76\u5728\u771f\u5b9e\u56fe\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRestless Multi-Armed Bandits\uff08RMABs\uff09\u5047\u8bbe\u5404\u81c2\u72ec\u7acb\uff0c\u65e0\u6cd5\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e2a\u4f53\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u8fd9\u5728\u516c\u5171\u536b\u751f\u7b49\u8d44\u6e90\u5206\u914d\u548c\u5e72\u9884\u4f18\u5316\u5e94\u7528\u4e2d\u5c24\u4e3a\u91cd\u8981\u3002\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e2a\u4f53\u4e92\u52a8\u53ef\u80fd\u663e\u8457\u5f71\u54cd\u51b3\u7b56\u6548\u679c\u3002", "method": "\u63d0\u51faNetworked RMAB\u6846\u67b6\uff0c\u5c06RMAB\u6a21\u578b\u4e0e\u72ec\u7acb\u7ea7\u8054\u6a21\u578b\u7ed3\u5408\u4ee5\u5efa\u6a21\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e2a\u4f53\u4ea4\u4e92\u3002\u901a\u8fc7\u8bc1\u660eBellman\u65b9\u7a0b\u7684\u5b50\u6a21\u6027\uff0c\u5e94\u7528\u722c\u5c71\u7b97\u6cd5\u83b7\u5f971-1/e\u7684\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u5e76\u5f00\u53d1\u4e86\u9488\u5bf9\u7f51\u7edc\u8bbe\u7f6e\u7684Q\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eBellman\u66f4\u65b0\u5177\u67091-1/e\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u4e14\u4fdd\u8bc1\u6536\u655b\u3002\u5728\u771f\u5b9e\u56fe\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684Q\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8ek\u6b65\u524d\u77bb\u65b9\u6cd5\u548c\u5ffd\u7565\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6355\u6349\u7f51\u7edc\u6548\u5e94\u7684\u91cd\u8981\u6027\u3002", "conclusion": "Networked RMAB\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfRMAB\u5ffd\u7565\u7f51\u7edc\u4ea4\u4e92\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5c55\u793a\u4e86\u5728\u7f51\u7edc\u73af\u5883\u4e2d\u8003\u8651\u4e2a\u4f53\u4e92\u52a8\u80fd\u663e\u8457\u63d0\u5347\u51b3\u7b56\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u5206\u914d\u548c\u5e72\u9884\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2512.06488", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06488", "abs": "https://arxiv.org/abs/2512.06488", "authors": ["Judd Katz", "Gopikrishnan Muraleedharan", "Abhijeet Alase"], "title": "Efficient quantum algorithm for solving differential equations with Fourier nonlinearity via Koopman linearization", "comment": null, "summary": "Quantum algorithms offer an exponential advantage with respect to the number of dependent variables for solving certain nonlinear ordinary differential equations (ODEs). These algorithms typically begin by transforming the original nonlinear ODE into a higher-dimensional linear ODE using a linearization technique, most commonly Carleman linearization. Existing works restrict their analysis to ODEs where the nonlinearities are polynomial functions of the dependent variables, significantly limiting their applicability. In this work we construct an efficient quantum algorithm for solving ODEs with `Fourier' nonlinear terms expressible as $d{\\bf u}/dt = G_0 + G_1 e^{i{\\bf u}}$, where ${\\bf u}$ denotes a vector of $n$ complex variables evolving with $t$, $G_0$ is an $n$-dimensional complex vector, $G_1$ is an $n \\times n$ complex matrix and $e^{i{\\bf u}}$ denotes the vector with entries $\\{e^{iu_j}\\}$. To tackle the Fourier nonlinear term, which is not expressible as a finite sum of polynomials of ${\\bf u}$, our algorithm employs a generalization of the Carleman linearization technique known as Koopman linearization. We also make other methodological advances towards relaxing the stringent dissipativity condition required for efficient solution extraction and towards integrated readout of classical quantities from the solution state. Our results open avenues to the development of efficient quantum algorithms for a significantly wider class of high-dimensional nonlinear ODEs, thereby broadening the scope of their applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u7528\u4e8e\u6c42\u89e3\u5177\u6709\u5085\u91cc\u53f6\u975e\u7ebf\u6027\u9879\u7684\u5e38\u5fae\u5206\u65b9\u7a0b\uff0c\u901a\u8fc7\u63a8\u5e7fCarleman\u7ebf\u6027\u5316\u6280\u672f\uff08Koopman\u7ebf\u6027\u5316\uff09\u6765\u5904\u7406\u975e\u591a\u9879\u5f0f\u975e\u7ebf\u6027\u9879\uff0c\u5e76\u653e\u5bbd\u4e86\u8017\u6563\u6027\u6761\u4ef6\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7b97\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5904\u7406\u591a\u9879\u5f0f\u975e\u7ebf\u6027\u9879\u7684ODE\uff0c\u8fd9\u5927\u5927\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5177\u6709\u5085\u91cc\u53f6\u975e\u7ebf\u6027\u9879\uff08\u5982e^{iu}\u5f62\u5f0f\uff09\u7684ODE\uff0c\u8fd9\u7c7b\u975e\u7ebf\u6027\u9879\u65e0\u6cd5\u7528\u6709\u9650\u591a\u9879\u5f0f\u8868\u793a\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u5e38\u89c1\u3002", "method": "\u91c7\u7528Koopman\u7ebf\u6027\u5316\u6280\u672f\uff08Carleman\u7ebf\u6027\u5316\u7684\u63a8\u5e7f\uff09\u5c06\u5177\u6709\u5085\u91cc\u53f6\u975e\u7ebf\u6027\u9879\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027ODE\u8f6c\u5316\u4e3a\u66f4\u9ad8\u7ef4\u7684\u7ebf\u6027ODE\u3002\u540c\u65f6\u6539\u8fdb\u4e86\u89e3\u51b3\u65b9\u6848\u63d0\u53d6\u7684\u8017\u6563\u6027\u6761\u4ef6\u8981\u6c42\uff0c\u5e76\u96c6\u6210\u4e86\u4ece\u91cf\u5b50\u6001\u4e2d\u8bfb\u53d6\u7ecf\u5178\u91cf\u7684\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5904\u7406\u5085\u91cc\u53f6\u975e\u7ebf\u6027\u9879\u7684\u9ad8\u6548\u91cf\u5b50\u7b97\u6cd5\uff0c\u80fd\u591f\u6c42\u89e3\u5f62\u5f0f\u4e3ad\ud835\udc2e/dt = G\u2080 + G\u2081e^{i\ud835\udc2e}\u7684ODE\uff0c\u5176\u4e2d\ud835\udc2e\u662fn\u7ef4\u590d\u53d8\u91cf\u5411\u91cf\u3002\u7b97\u6cd5\u5728\u53d8\u91cf\u6570\u91cf\u4e0a\u5177\u6709\u6307\u6570\u4f18\u52bf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5904\u7406\u66f4\u5e7f\u6cdb\u7c7b\u522b\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027ODE\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u663e\u8457\u6269\u5c55\u4e86\u91cf\u5b50\u7b97\u6cd5\u5728\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u4e2d\u7684\u5e94\u7528\u8303\u56f4\uff0c\u7279\u522b\u662f\u9488\u5bf9\u975e\u591a\u9879\u5f0f\u975e\u7ebf\u6027\u9879\u7684\u60c5\u51b5\u3002"}}
{"id": "2512.07546", "categories": ["gr-qc", "astro-ph.IM", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2512.07546", "abs": "https://arxiv.org/abs/2512.07546", "authors": ["Yuandong Jia", "Yinbowen Zhang", "Suwen Wang", "Guozhi Chai", "Zemin Zhang", "Yi Zhang", "Hongxin Li", "Shuanglin Huang", "Hongqing Huo", "Zongfeng Li", "Yun Kau Lau"], "title": "Long-wavelength UV-LEDs and charge management in the detection of gravitational waves in space", "comment": null, "summary": "For the charge management system in gravitational wave detection missions, a continuous discharge strategy is considered by continuously illuminating a test mass (TM) with weak light in such a way to strike a balance between the charging and discharging rates and at the same time avoids the requirement for frequent activation of charge measurements. Built on experiments by one of us based on a simple parallel plate model for inertial sensor, in the present work a more sophisticated inertial sensor model that mimics the surface properties and work function of a cubical TM of an inertial sensor in space (like that of the LISA Pathfinder) is employed to study bipolar charge management system that utilizes UV-LEDs with peak wavelengths of 269 nm, 275 nm, 280 nm, and 295 nm that are longer than the standard 255 nm commonly employed for direct TM illumination. Experimental results indicate that the 275 nm UV-LED achieves optimal performance, maintaining the TM potential closer to zero and at the same time accommodates both rapid discharge and continuous discharge strategies. The present work provides useful input in the future study of system design and optimization for the charge management system.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5f15\u529b\u6ce2\u63a2\u6d4b\u4efb\u52a1\u4e2d\u7684\u7535\u8377\u7ba1\u7406\u7cfb\u7edf\uff0c\u91c7\u7528275nm UV-LED\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u80fd\u5728\u4fdd\u6301\u6d4b\u8bd5\u8d28\u91cf\u5757\u7535\u4f4d\u63a5\u8fd1\u96f6\u7684\u540c\u65f6\u652f\u6301\u5feb\u901f\u653e\u7535\u548c\u8fde\u7eed\u653e\u7535\u7b56\u7565\u3002", "motivation": "\u5f15\u529b\u6ce2\u63a2\u6d4b\u4efb\u52a1\u4e2d\u7684\u7535\u8377\u7ba1\u7406\u7cfb\u7edf\u9700\u8981\u5e73\u8861\u5145\u7535\u548c\u653e\u7535\u901f\u7387\uff0c\u540c\u65f6\u907f\u514d\u9891\u7e41\u6fc0\u6d3b\u7535\u8377\u6d4b\u91cf\u3002\u4f20\u7edf\u4f7f\u7528255nm\u6ce2\u957f\u76f4\u63a5\u7167\u5c04\u6d4b\u8bd5\u8d28\u91cf\u5757\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u957f\u6ce2\u957f\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u66f4\u590d\u6742\u7684\u60ef\u6027\u4f20\u611f\u5668\u6a21\u578b\uff0c\u6a21\u62df\u7acb\u65b9\u4f53\u6d4b\u8bd5\u8d28\u91cf\u5757\u7684\u8868\u9762\u7279\u6027\u548c\u529f\u51fd\u6570\uff08\u7c7b\u4f3cLISA Pathfinder\uff09\u3002\u7814\u7a76\u4f7f\u7528269nm\u3001275nm\u3001280nm\u548c295nm\u56db\u79cd\u957f\u4e8e\u6807\u51c6255nm\u6ce2\u957f\u7684UV-LED\uff0c\u7814\u7a76\u53cc\u6781\u7535\u8377\u7ba1\u7406\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c275nm UV-LED\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u80fd\u4fdd\u6301\u6d4b\u8bd5\u8d28\u91cf\u5757\u7535\u4f4d\u66f4\u63a5\u8fd1\u96f6\uff0c\u540c\u65f6\u652f\u6301\u5feb\u901f\u653e\u7535\u548c\u8fde\u7eed\u653e\u7535\u4e24\u79cd\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u7535\u8377\u7ba1\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u7528\u53c2\u8003\uff0c\u7279\u522b\u662f275nm UV-LED\u5728\u5e73\u8861\u6027\u80fd\u548c\u7b56\u7565\u7075\u6d3b\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.06288", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.06288", "abs": "https://arxiv.org/abs/2512.06288", "authors": ["Houssam El Cheairi", "David Gamarnik", "Rahul Mazumder"], "title": "Theoretical Compression Bounds for Wide Multilayer Perceptrons", "comment": null, "summary": "Pruning and quantization techniques have been broadly successful in reducing the number of parameters needed for large neural networks, yet theoretical justification for their empirical success falls short. We consider a randomized greedy compression algorithm for pruning and quantization post-training and use it to rigorously show the existence of pruned/quantized subnetworks of multilayer perceptrons (MLPs) with competitive performance. We further extend our results to structured pruning of MLPs and convolutional neural networks (CNNs), thus providing a unified analysis of pruning in wide networks. Our results are free of data assumptions, and showcase a tradeoff between compressibility and network width. The algorithm we consider bears some similarities with Optimal Brain Damage (OBD) and can be viewed as a post-training randomized version of it. The theoretical results we derive bridge the gap between theory and application for pruning/quantization, and provide a justification for the empirical success of compression in wide multilayer perceptrons.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u8d2a\u5fc3\u538b\u7f29\u7b97\u6cd5\uff0c\u7528\u4e8e\u540e\u8bad\u7ec3\u526a\u679d\u548c\u91cf\u5316\uff0c\u5e76\u7406\u8bba\u8bc1\u660e\u4e86\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u4e2d\u5b58\u5728\u6027\u80fd\u4f18\u5f02\u7684\u526a\u679d/\u91cf\u5316\u5b50\u7f51\u7edc\u3002", "motivation": "\u5c3d\u7ba1\u526a\u679d\u548c\u91cf\u5316\u6280\u672f\u5728\u5b9e\u8df5\u4e2d\u80fd\u6709\u6548\u51cf\u5c11\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u91cf\uff0c\u4f46\u5176\u7406\u8bba\u4f9d\u636e\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u4e3a\u8fd9\u4e9b\u538b\u7f29\u6280\u672f\u7684\u7ecf\u9a8c\u6210\u529f\u63d0\u4f9b\u7406\u8bba\u652f\u6301\uff0c\u5f25\u5408\u7406\u8bba\u4e0e\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u8d2a\u5fc3\u538b\u7f29\u7b97\u6cd5\uff0c\u53ef\u89c6\u4e3a\u540e\u8bad\u7ec3\u968f\u673a\u7248\u672c\u7684Optimal Brain Damage\uff08OBD\uff09\u3002\u8be5\u7b97\u6cd5\u7528\u4e8e\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u7684\u7ed3\u6784\u5316\u526a\u679d\u548c\u91cf\u5316\uff0c\u5e76\u6269\u5c55\u5230\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5728\u5bbd\u795e\u7ecf\u7f51\u7edc\u4e2d\u5b58\u5728\u6027\u80fd\u5177\u6709\u7ade\u4e89\u529b\u7684\u526a\u679d/\u91cf\u5316\u5b50\u7f51\u7edc\uff0c\u5c55\u793a\u4e86\u538b\u7f29\u6027\u4e0e\u7f51\u7edc\u5bbd\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002\u7ed3\u679c\u4e0d\u4f9d\u8d56\u4e8e\u6570\u636e\u5047\u8bbe\uff0c\u4e3a\u538b\u7f29\u6280\u672f\u5728\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u7684\u7ecf\u9a8c\u6210\u529f\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u672c\u6587\u4e3a\u526a\u679d\u548c\u91cf\u5316\u6280\u672f\u7684\u7ecf\u9a8c\u6210\u529f\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u652f\u6301\uff0c\u8bc1\u660e\u4e86\u5728\u5bbd\u795e\u7ecf\u7f51\u7edc\u4e2d\u5b58\u5728\u9ad8\u6027\u80fd\u7684\u538b\u7f29\u5b50\u7f51\u7edc\uff0c\u5f25\u5408\u4e86\u538b\u7f29\u6280\u672f\u7684\u7406\u8bba\u4e0e\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.06523", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06523", "abs": "https://arxiv.org/abs/2512.06523", "authors": ["Daniel Goldsmith", "Xing Liang", "Dimitrios Makris", "Hongwei Wu"], "title": "Solving larger Travelling Salesman Problem networks with a penalty-free Variational Quantum Algorithm", "comment": "59 pages and 11 figures", "summary": "The Travelling Salesman Problem (TSP) is a well-known NP-Hard combinatorial optimisation problem, with industrial use cases such as last-mile delivery. Although TSP has been studied extensively on quantum computers, it is rare to find quantum solutions of TSP network with more than a dozen locations. In this paper, we present high quality solutions in noise-free Qiskit simulations of networks with up to twelve locations using a hybrid penalty-free, circuit-model, Variational Quantum Algorithm (VQA). Noisy qubits are also simulated. To our knowledge, this is the first successful VQA simulation of a twelve-location TSP on circuit-model devices. Multiple encoding strategies, including factorial, non-factorial, and Gray encoding are evaluated. Our formulation scales as $\\mathcal{O}(nlog_2(n))$ qubits, requiring only 29 qubits for twelve locations, compared with over 100 qubits for conventional approaches scaling as $\\mathcal{O}(n^2)$. Computational time is further reduced by almost two orders of magnitude through the use of Simultaneous Perturbation Stochastic Approximation (SPSA) gradient estimation and cost-function caching. We also introduce a novel machine-learning model, and benchmark both quantum and classical approaches against a Monte Carlo baseline. The VQA outperforms the classical machine-learning approach, and performs similarly to Monte Carlo for the small networks simulated. Additionally, the results indicate a trend toward improved performance with problem size, outlining a pathway to solving larger TSP instances on quantum devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65e0\u60e9\u7f5a\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff0c\u5728\u65e0\u566a\u58f0Qiskit\u6a21\u62df\u4e2d\u6210\u529f\u6c42\u89e3\u4e86\u6700\u591a12\u4e2a\u5730\u70b9\u7684\u65c5\u884c\u5546\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5927\u5e45\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u9700\u6c42\u3002", "motivation": "\u65c5\u884c\u5546\u95ee\u9898\u662f\u8457\u540d\u7684NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5728\u7269\u6d41\u914d\u9001\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002\u867d\u7136\u91cf\u5b50\u8ba1\u7b97\u5df2\u5e7f\u6cdb\u7814\u7a76TSP\uff0c\u4f46\u73b0\u6709\u91cf\u5b50\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u53ea\u80fd\u5904\u7406\u5341\u51e0\u4e2a\u5730\u70b9\u7684\u5c0f\u89c4\u6a21\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u5904\u7406\u66f4\u5927\u89c4\u6a21TSP\u7684\u91cf\u5b50\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65e0\u60e9\u7f5a\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff0c\u4f7f\u7528\u591a\u79cd\u7f16\u7801\u7b56\u7565\uff08\u9636\u4e58\u3001\u975e\u9636\u4e58\u3001\u683c\u96f7\u7f16\u7801\uff09\uff0c\u901a\u8fc7\u540c\u65f6\u6270\u52a8\u968f\u673a\u903c\u8fd1\u68af\u5ea6\u4f30\u8ba1\u548c\u6210\u672c\u51fd\u6570\u7f13\u5b58\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002\u7b97\u6cd5\u590d\u6742\u5ea6\u4e3aO(nlog\u2082(n))\u91cf\u5b50\u6bd4\u7279\uff0c\u76f8\u6bd4\u4f20\u7edfO(n\u00b2)\u65b9\u6cd5\u5927\u5e45\u51cf\u5c11\u8d44\u6e90\u9700\u6c42\u3002", "result": "\u5728\u65e0\u566a\u58f0\u6a21\u62df\u4e2d\u6210\u529f\u6c42\u89e312\u4e2a\u5730\u70b9\u7684TSP\uff0c\u4ec5\u970029\u4e2a\u91cf\u5b50\u6bd4\u7279\uff08\u4f20\u7edf\u65b9\u6cd5\u9700100+\uff09\u3002\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u8fd1\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002VQA\u6027\u80fd\u4f18\u4e8e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e0e\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u76f8\u5f53\uff0c\u4e14\u968f\u7740\u95ee\u9898\u89c4\u6a21\u589e\u5927\u5448\u73b0\u6027\u80fd\u63d0\u5347\u8d8b\u52bf\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u65c5\u884c\u5546\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\uff0c\u4e3a\u5728\u91cf\u5b50\u8bbe\u5907\u4e0a\u6c42\u89e3\u66f4\u5927\u89c4\u6a21TSP\u5b9e\u4f8b\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u91cf\u5b50\u65b9\u6cd5\u5728\u8d44\u6e90\u6548\u7387\u548c\u6027\u80fd\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.07610", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07610", "abs": "https://arxiv.org/abs/2512.07610", "authors": ["Hao-Ran Sun", "Jing-Kang Bin", "Li Zhao"], "title": "Chains of rotating boson stars with quartic or sextic self-interaction", "comment": "26 pages, 21 figures", "summary": "This paper investigates chains of rotating boson stars (BSs) within Einstein gravity coupled to a complex scalar field. The model incorporates quartic or sextic self-interactions in the scalar Lagrangian, which support the existence of stationary, solitonic, gravitationally bound solutions. We numerically construct these multi-component systems and investigate how the self-interactions alter their global properties -- specifically the Arnowitt-Deser-Misner (ADM) mass $M$, the angular momentum $J$ and the morphology of their ergospheres. A central result is the distinct dependence of the $(\u03c9, M)$ and $(\u03c9, J)$ relations on the parity of the chains. Specifically, systems with an even number of constituents display spiraling curves, while those with an odd number exhibit loop structures. Moreover, we observe that two initially distinct ergospheres merge into a single one as the frequency $\u03c9$ increases. Our analysis also indicates that the quartic interaction imposes more restrictive existence bounds, particularly for odd-numbered chains, thereby restricting stable configurations to the weak-coupling regime. In contrast, the sextic interaction has a weaker effect and enables stable solutions at substantially stronger couplings.", "AI": {"tldr": "\u7814\u7a76\u7231\u56e0\u65af\u5766\u5f15\u529b\u4e2d\u590d\u6807\u91cf\u573a\u81ea\u76f8\u4e92\u4f5c\u7528\u5bf9\u65cb\u8f6c\u73bb\u8272\u661f\u94fe\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5947\u5076\u94fe\u6570\u5728\u8d28\u91cf-\u9891\u7387\u548c\u89d2\u52a8\u91cf-\u9891\u7387\u5173\u7cfb\u4e0a\u5448\u73b0\u4e0d\u540c\u6a21\u5f0f\uff0c\u4e14\u56db\u9636\u4e0e\u516d\u9636\u76f8\u4e92\u4f5c\u7528\u5bf9\u7a33\u5b9a\u6027\u7684\u9650\u5236\u4e0d\u540c\u3002", "motivation": "\u63a2\u7d22\u7231\u56e0\u65af\u5766\u5f15\u529b\u4e2d\u590d\u6807\u91cf\u573a\u81ea\u76f8\u4e92\u4f5c\u7528\u5bf9\u65cb\u8f6c\u73bb\u8272\u661f\u94fe\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u81ea\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u6539\u53d8\u7cfb\u7edf\u7684\u5168\u5c40\u6027\u8d28\u548c\u5f62\u6001\u7279\u5f81\u3002", "method": "\u5728\u7231\u56e0\u65af\u5766\u5f15\u529b\u8026\u5408\u590d\u6807\u91cf\u573a\u6a21\u578b\u4e2d\u5f15\u5165\u56db\u9636\u6216\u516d\u9636\u81ea\u76f8\u4e92\u4f5c\u7528\uff0c\u6570\u503c\u6784\u9020\u591a\u7ec4\u5206\u7cfb\u7edf\uff0c\u5206\u6790\u81ea\u76f8\u4e92\u4f5c\u7528\u5bf9ADM\u8d28\u91cf\u3001\u89d2\u52a8\u91cf\u548c\u80fd\u5c42\u5f62\u6001\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u94fe\u7684\u5947\u5076\u6027\u5bfc\u81f4\u4e0d\u540c\u6a21\u5f0f\uff1a\u5076\u6570\u94fe\u5448\u73b0\u87ba\u65cb\u66f2\u7ebf\uff0c\u5947\u6570\u94fe\u5448\u73b0\u73af\u72b6\u7ed3\u6784\uff1b\u80fd\u5c42\u968f\u9891\u7387\u589e\u52a0\u800c\u5408\u5e76\uff1b\u56db\u9636\u76f8\u4e92\u4f5c\u7528\u5bf9\u5947\u6570\u94fe\u5b58\u5728\u66f4\u4e25\u683c\u9650\u5236\uff0c\u516d\u9636\u76f8\u4e92\u4f5c\u7528\u5141\u8bb8\u66f4\u5f3a\u8026\u5408\u4e0b\u7684\u7a33\u5b9a\u89e3\u3002", "conclusion": "\u81ea\u76f8\u4e92\u4f5c\u7528\u7c7b\u578b\u5bf9\u65cb\u8f6c\u73bb\u8272\u661f\u94fe\u7684\u7a33\u5b9a\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u56db\u9636\u76f8\u4e92\u4f5c\u7528\u9650\u5236\u66f4\u591a\uff0c\u800c\u516d\u9636\u76f8\u4e92\u4f5c\u7528\u5141\u8bb8\u66f4\u5e7f\u6cdb\u7684\u7a33\u5b9a\u53c2\u6570\u7a7a\u95f4\uff0c\u5947\u5076\u94fe\u6570\u5728\u7cfb\u7edf\u884c\u4e3a\u4e0a\u8868\u73b0\u51fa\u6839\u672c\u6027\u5dee\u5f02\u3002"}}
{"id": "2512.06293", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06293", "abs": "https://arxiv.org/abs/2512.06293", "authors": ["Fatima Ashraf", "Muhammad Ayub Sabir", "Jiaxin Deng", "Junbiao Pang", "Haitao Yu"], "title": "Importance-aware Topic Modeling for Discovering Public Transit Risk from Noisy Social Media", "comment": null, "summary": "Urban transit agencies increasingly turn to social media to monitor emerging service risks such as crowding, delays, and safety incidents, yet the signals of concern are sparse, short, and easily drowned by routine chatter. We address this challenge by jointly modeling linguistic interactions and user influence. First, we construct an influence-weighted keyword co-occurrence graph from cleaned posts so that socially impactful posts contributes proportionally to the underlying evidence. The core of our framework is a Poisson Deconvolution Factorization (PDF) that decomposes this graph into a low-rank topical structure and topic-localized residual interactions, producing an interpretable topic--keyword basis together with topic importance scores. A decorrelation regularizer \\emph{promotes} distinct topics, and a lightweight optimization procedure ensures stable convergence under nonnegativity and normalization constraints. Finally, the number of topics is selected through a coherence-driven sweep that evaluates the quality and distinctness of the learned topics. On large-scale social streams, the proposed model achieves state-of-the-art topic coherence and strong diversity compared with leading baselines. The code and dataset are publicly available at https://github.com/pangjunbiao/Topic-Modeling_ITS.git", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684\u57ce\u5e02\u4ea4\u901a\u670d\u52a1\u98ce\u9669\u76d1\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u8bed\u8a00\u4ea4\u4e92\u548c\u7528\u6237\u5f71\u54cd\u529b\uff0c\u6784\u5efa\u5f71\u54cd\u529b\u52a0\u6743\u7684\u5173\u952e\u8bcd\u5171\u73b0\u56fe\uff0c\u5e76\u4f7f\u7528\u6cca\u677e\u53cd\u5377\u79ef\u5206\u89e3\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u4e3b\u9898\u7ed3\u6784\u3002", "motivation": "\u57ce\u5e02\u4ea4\u901a\u673a\u6784\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u793e\u4ea4\u5a92\u4f53\u76d1\u6d4b\u670d\u52a1\u98ce\u9669\uff08\u5982\u62e5\u6324\u3001\u5ef6\u8bef\u3001\u5b89\u5168\u4e8b\u6545\uff09\uff0c\u4f46\u76f8\u5173\u4fe1\u53f7\u7a00\u758f\u3001\u7b80\u77ed\u4e14\u5bb9\u6613\u88ab\u65e5\u5e38\u804a\u5929\u6df9\u6ca1\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u53d6\u6709\u610f\u4e49\u7684\u4e3b\u9898\u3002", "method": "\u9996\u5148\u6784\u5efa\u5f71\u54cd\u529b\u52a0\u6743\u7684\u5173\u952e\u8bcd\u5171\u73b0\u56fe\uff0c\u4f7f\u6709\u793e\u4f1a\u5f71\u54cd\u529b\u7684\u5e16\u5b50\u6309\u6bd4\u4f8b\u8d21\u732e\u8bc1\u636e\uff1b\u7136\u540e\u4f7f\u7528\u6cca\u677e\u53cd\u5377\u79ef\u5206\u89e3\u5c06\u56fe\u5206\u89e3\u4e3a\u4f4e\u79e9\u4e3b\u9898\u7ed3\u6784\u548c\u4e3b\u9898\u5c40\u90e8\u6b8b\u5dee\u4ea4\u4e92\uff1b\u52a0\u5165\u53bb\u76f8\u5173\u6b63\u5219\u5316\u5668\u4fc3\u8fdb\u4e3b\u9898\u533a\u5206\uff1b\u901a\u8fc7\u4e00\u81f4\u6027\u9a71\u52a8\u7684\u626b\u63cf\u9009\u62e9\u4e3b\u9898\u6570\u91cf\u3002", "result": "\u5728\u5927\u89c4\u6a21\u793e\u4ea4\u6570\u636e\u6d41\u4e0a\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u4e3b\u9898\u4e00\u81f4\u6027\uff0c\u4e0e\u9886\u5148\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u5f3a\u591a\u6837\u6027\uff0c\u80fd\u591f\u6709\u6548\u63d0\u53d6\u57ce\u5e02\u4ea4\u901a\u670d\u52a1\u98ce\u9669\u76f8\u5173\u7684\u4e3b\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u4ece\u7a00\u758f\u3001\u5608\u6742\u7684\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e2d\u6709\u6548\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u4e3b\u9898\uff0c\u4e3a\u57ce\u5e02\u4ea4\u901a\u673a\u6784\u63d0\u4f9b\u66f4\u597d\u7684\u670d\u52a1\u98ce\u9669\u76d1\u6d4b\u5de5\u5177\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2512.06602", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2512.06602", "abs": "https://arxiv.org/abs/2512.06602", "authors": ["Juan M. Gonz\u00e1lez-Monge", "Johannes Feist"], "title": "High-harmonic generation driven by temporal-mode quantum states of light", "comment": null, "summary": "We develop a theoretical framework for high-harmonic generation (HHG) driven by quantum states of light based on a temporal-mode expansion of the electromagnetic field. This approach extends previous single plane-wave mode treatments to realistic pulse configurations, resolving conceptual inconsistencies arising from non-normalizable infinite plane waves and establishing consistency between analytical and numerical methods. We derive a correction factor that quantifies deviations from the single-mode approximation and show that it remains below $10^{-4}$ for intensities typical of HHG ($\\sim 10^{14}~$W/cm$^2$). This result confirms that free-space HHG driven by any quantum state of light is accurately described by averaging semi-classical calculations over the Husimi distribution, with no observable genuine quantum effects. The absence of such effects is attributed to the large photon numbers ($\\sim 10^{11}$) required to reach HHG intensities in free space, which render quantum fluctuations negligible. We discuss nanophotonic environments with ultrasmall mode volumes as potential platforms where few-photon strong-field processes could exhibit genuine quantum signatures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u57fa\u4e8e\u5149\u573a\u65f6\u95f4\u6a21\u5f0f\u5c55\u5f00\u7684\u9ad8\u6b21\u8c10\u6ce2\u751f\u6210\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5e73\u9762\u6ce2\u975e\u5f52\u4e00\u5316\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u81ea\u7531\u7a7a\u95f4HHG\u4e2d\u91cf\u5b50\u6548\u5e94\u53ef\u5ffd\u7565\uff0c\u5e76\u6307\u51fa\u7eb3\u7c73\u5149\u5b50\u73af\u5883\u53ef\u80fd\u5c55\u73b0\u91cf\u5b50\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u9ad8\u6b21\u8c10\u6ce2\u751f\u6210\u7406\u8bba\u4e3b\u8981\u57fa\u4e8e\u5355\u5e73\u9762\u6ce2\u6a21\u5f0f\u5904\u7406\uff0c\u5b58\u5728\u975e\u5f52\u4e00\u5316\u65e0\u9650\u5e73\u9762\u6ce2\u7684\u6982\u5ff5\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4e14\u9700\u8981\u6269\u5c55\u5230\u5b9e\u9645\u8109\u51b2\u914d\u7f6e\u3002\u540c\u65f6\u9700\u8981\u6f84\u6e05\u91cf\u5b50\u5149\u573a\u5728HHG\u4e2d\u662f\u5426\u4f1a\u4ea7\u751f\u53ef\u89c2\u6d4b\u7684\u91cf\u5b50\u6548\u5e94\u3002", "method": "\u91c7\u7528\u7535\u78c1\u573a\u7684\u65f6\u95f4\u6a21\u5f0f\u5c55\u5f00\u65b9\u6cd5\uff0c\u5c06\u7406\u8bba\u4ece\u5355\u5e73\u9762\u6ce2\u6a21\u5f0f\u6269\u5c55\u5230\u5b9e\u9645\u8109\u51b2\u914d\u7f6e\u3002\u63a8\u5bfc\u4e86\u91cf\u5316\u5355\u6a21\u8fd1\u4f3c\u504f\u5dee\u7684\u4fee\u6b63\u56e0\u5b50\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u5178\u578bHHG\u5f3a\u5ea6\u4e0b\u7684\u5149\u5b50\u6570\u6765\u8bc4\u4f30\u91cf\u5b50\u6548\u5e94\u7684\u91cd\u8981\u6027\u3002", "result": "\u4fee\u6b63\u56e0\u5b50\u5728\u5178\u578bHHG\u5f3a\u5ea6\uff08~10^14 W/cm^2\uff09\u4e0b\u4f4e\u4e8e10^-4\uff0c\u8868\u660e\u5355\u6a21\u8fd1\u4f3c\u975e\u5e38\u51c6\u786e\u3002\u81ea\u7531\u7a7a\u95f4HHG\u4e2d\u91cf\u5b50\u6548\u5e94\u53ef\u5ffd\u7565\uff0c\u56e0\u4e3a\u6240\u9700\u5149\u5b50\u6570\u5de8\u5927\uff08~10^11\uff09\uff0c\u91cf\u5b50\u6da8\u843d\u5fae\u4e0d\u8db3\u9053\u3002HHG\u53ef\u901a\u8fc7Husimi\u5206\u5e03\u5bf9\u534a\u7ecf\u5178\u8ba1\u7b97\u8fdb\u884c\u5e73\u5747\u6765\u51c6\u786e\u63cf\u8ff0\u3002", "conclusion": "\u81ea\u7531\u7a7a\u95f4\u9ad8\u6b21\u8c10\u6ce2\u751f\u6210\u4e2d\u4efb\u4f55\u91cf\u5b50\u5149\u6001\u90fd\u4e0d\u4f1a\u4ea7\u751f\u53ef\u89c2\u6d4b\u7684\u91cf\u5b50\u6548\u5e94\uff0c\u56e0\u4e3a\u6240\u9700\u7684\u9ad8\u5149\u5b50\u6570\u4f7f\u91cf\u5b50\u6da8\u843d\u53ef\u5ffd\u7565\u3002\u7eb3\u7c73\u5149\u5b50\u73af\u5883\u56e0\u5176\u8d85\u5c0f\u6a21\u5f0f\u4f53\u79ef\u53ef\u80fd\u6210\u4e3a\u5c55\u793a\u5c11\u5149\u5b50\u5f3a\u573a\u8fc7\u7a0b\u91cf\u5b50\u7279\u5f81\u7684\u6f5c\u5728\u5e73\u53f0\u3002"}}
{"id": "2512.07641", "categories": ["gr-qc", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.07641", "abs": "https://arxiv.org/abs/2512.07641", "authors": ["Corentin Vitel"], "title": "Black Hole Scattering and Integrability: A Hyperboloidal Approach", "comment": "4 pages, no figure. Prepared for the proceedings of the 24th International Conference on General Relativity and Gravitation (GR24), Glasgow, 14-18 July 2025", "summary": "Integrability structures are known to play a key role in one-dimensional scattering. In the Schwarzschild gravitational context, the analysis emphasizing the role of the so-called Darboux covariance and its intimate connection with KdV conserved quantities was recently introduced by Lenzi & Sopuerta. In a second stage, together with Jaramillo, this led in particular to the identification of the structural role of the \"KdV-Virasoro-Schwarzian derivative\" triangle in this problem. Such a gravitational scattering description dwells naturally on a Cauchy foliation of the spacetime. In the following, we first review--for the Schwarzschild background--this problem in a hyperboloidal foliation scheme, where the infinitesimal time generator of the dynamics is a non-selfadjoint operator. Then, we explore the underlying integrability features through a Lax-pair formulation. Specifically, the main results presented here are i) the explicit proposal of a weak Lax-pair, valid under suitable conditions involving fields at null infinity, with ii) the construction of the associated infinite sequence of isospectral flows. From a broader perspective, the very form of the non-selfadjoint infinitesimal time operator, which neatly separates into two components corresponding to bulk and boundary structures, paves the way for the description of the gravitational dynamics in terms of a \"semi-direct action\" of bulk degrees of freedom onto boundary degrees of freedom. This is akin to the \"wave-mean flow\" approach for black hole strong-gravity dynamics recently proposed in this line of research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86Schwarzschild\u5f15\u529b\u80cc\u666f\u4e0b\u6563\u5c04\u95ee\u9898\u7684\u53ef\u79ef\u7ed3\u6784\uff0c\u5728\u53cc\u66f2\u53f6\u5c42\u5316\u65b9\u6848\u4e2d\u901a\u8fc7Lax\u5bf9\u6784\u5efa\u7b49\u8c31\u6d41\uff0c\u63ed\u793a\u4e86\u4f53-\u8fb9\u754c\u7ed3\u6784\u7684\u534a\u76f4\u79ef\u4f5c\u7528", "motivation": "\u7814\u7a76Schwarzschild\u5f15\u529b\u80cc\u666f\u4e0b\u6563\u5c04\u95ee\u9898\u7684\u53ef\u79ef\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u53cc\u66f2\u53f6\u5c42\u5316\u65b9\u6848\u4e2d\uff0c\u63a2\u7d22\u975e\u81ea\u4f34\u65f6\u95f4\u751f\u6210\u7b97\u5b50\u7684\u6027\u8d28\u53ca\u5176\u4e0e\u4f53-\u8fb9\u754c\u7ed3\u6784\u7684\u5173\u7cfb", "method": "\u91c7\u7528\u53cc\u66f2\u53f6\u5c42\u5316\u65b9\u6848\uff0c\u6784\u5efa\u5f31Lax\u5bf9\uff08\u5728\u96f6\u65e0\u7a77\u8fdc\u6761\u4ef6\u4e0b\u6709\u6548\uff09\uff0c\u63a8\u5bfc\u76f8\u5173\u7684\u65e0\u9650\u7b49\u8c31\u6d41\u5e8f\u5217\uff0c\u5206\u6790\u975e\u81ea\u4f34\u65f6\u95f4\u7b97\u5b50\u7684\u4f53-\u8fb9\u754c\u5206\u89e3\u7ed3\u6784", "result": "\u63d0\u51fa\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u6548\u7684\u5f31Lax\u5bf9\uff0c\u6784\u9020\u4e86\u76f8\u5e94\u7684\u65e0\u9650\u7b49\u8c31\u6d41\u5e8f\u5217\uff0c\u63ed\u793a\u4e86\u65f6\u95f4\u7b97\u5b50\u53ef\u5206\u89e3\u4e3a\u4f53\u7ed3\u6784\u548c\u8fb9\u754c\u7ed3\u6784\u4e24\u90e8\u5206\uff0c\u4e3a\u5f15\u529b\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u534a\u76f4\u79ef\u4f5c\u7528\u63cf\u8ff0\u6846\u67b6", "conclusion": "Schwarzschild\u5f15\u529b\u6563\u5c04\u95ee\u9898\u5728\u53cc\u66f2\u53f6\u5c42\u5316\u65b9\u6848\u4e2d\u5c55\u73b0\u51fa\u4e30\u5bcc\u7684\u53ef\u79ef\u7ed3\u6784\uff0cLax\u5bf9\u548c\u7b49\u8c31\u6d41\u7684\u6784\u5efa\u4e3a\u7406\u89e3\u9ed1\u6d1e\u5f3a\u5f15\u529b\u52a8\u529b\u5b66\u4e2d\u7684\"\u6ce2-\u5e73\u5747\u6d41\"\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840"}}
{"id": "2512.06297", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.06297", "abs": "https://arxiv.org/abs/2512.06297", "authors": ["Luca Di Carlo", "Chase Goddard", "David J. Schwab"], "title": "Entropic Confinement and Mode Connectivity in Overparameterized Neural Networks", "comment": "Under Review", "summary": "Modern neural networks exhibit a striking property: basins of attraction in the loss landscape are often connected by low-loss paths, yet optimization dynamics generally remain confined to a single convex basin and rarely explore intermediate points. We resolve this paradox by identifying entropic barriers arising from the interplay between curvature variations along these paths and noise in optimization dynamics. Empirically, we find that curvature systematically rises away from minima, producing effective forces that bias noisy dynamics back toward the endpoints - even when the loss remains nearly flat. These barriers persist longer than energetic barriers, shaping the late-time localization of solutions in parameter space. Our results highlight the role of curvature-induced entropic forces in governing both connectivity and confinement in deep learning landscapes.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u51fd\u6570\u666f\u89c2\u4e2d\u7684\u5438\u5f15\u76c6\u901a\u8fc7\u4f4e\u635f\u5931\u8def\u5f84\u8fde\u63a5\uff0c\u4f46\u4f18\u5316\u52a8\u6001\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u4e2a\u51f8\u76c6\uff0c\u5f88\u5c11\u63a2\u7d22\u4e2d\u95f4\u70b9\u3002\u8be5\u7814\u7a76\u901a\u8fc7\u8bc6\u522b\u66f2\u7387\u53d8\u5316\u4e0e\u4f18\u5316\u566a\u58f0\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u7684\u71b5\u52bf\u5792\u6765\u89e3\u91ca\u8fd9\u4e00\u6096\u8bba\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6096\u8bba\uff1a\u867d\u7136\u635f\u5931\u666f\u89c2\u4e2d\u7684\u5438\u5f15\u76c6\u901a\u8fc7\u4f4e\u635f\u5931\u8def\u5f84\u8fde\u63a5\uff0c\u4f46\u4f18\u5316\u7b97\u6cd5\u901a\u5e38\u53ea\u505c\u7559\u5728\u5355\u4e2a\u51f8\u76c6\u5185\uff0c\u5f88\u5c11\u63a2\u7d22\u4e2d\u95f4\u533a\u57df\u3002\u9700\u8981\u7406\u89e3\u8fd9\u79cd\u8fde\u63a5\u6027\u4e0e\u5b9e\u9645\u4f18\u5316\u884c\u4e3a\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5206\u6790\u66f2\u7387\u53d8\u5316\u4e0e\u4f18\u5316\u52a8\u6001\u566a\u58f0\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u8bc6\u522b\u71b5\u52bf\u5792\u7684\u5f62\u6210\u673a\u5236\u3002\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\uff0c\u6cbf\u7740\u8fde\u63a5\u8def\u5f84\u8fdc\u79bb\u6700\u5c0f\u503c\u65f6\u66f2\u7387\u7cfb\u7edf\u6027\u4e0a\u5347\uff0c\u4ea7\u751f\u5c06\u566a\u58f0\u52a8\u6001\u504f\u8f6c\u56de\u7aef\u70b9\u7684\u6709\u6548\u529b\u3002", "result": "\u53d1\u73b0\u66f2\u7387\u53d8\u5316\u4ea7\u751f\u7684\u71b5\u52bf\u5792\u6bd4\u80fd\u91cf\u52bf\u5792\u6301\u7eed\u66f4\u957f\u65f6\u95f4\uff0c\u4e3b\u5bfc\u4e86\u53c2\u6570\u7a7a\u95f4\u4e2d\u89e3\u7684\u540e\u671f\u5b9a\u4f4d\u3002\u5373\u4f7f\u635f\u5931\u4fdd\u6301\u5e73\u5766\uff0c\u8fd9\u4e9b\u52bf\u5792\u4ecd\u7136\u5b58\u5728\u5e76\u9650\u5236\u4f18\u5316\u52a8\u6001\u7684\u63a2\u7d22\u3002", "conclusion": "\u66f2\u7387\u8bf1\u5bfc\u7684\u71b5\u529b\u5728\u6df1\u5ea6\u5b66\u4e60\u666f\u89c2\u4e2d\u540c\u65f6\u63a7\u5236\u7740\u8fde\u63a5\u6027\u548c\u9650\u5236\u6027\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u4f18\u5316\u7b97\u6cd5\u5f88\u5c11\u63a2\u7d22\u8fde\u63a5\u8def\u5f84\u4e0a\u7684\u4e2d\u95f4\u70b9\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u8def\u5f84\u5728\u635f\u5931\u666f\u89c2\u4e2d\u662f\u8fde\u901a\u7684\u3002"}}
{"id": "2512.06619", "categories": ["quant-ph", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.06619", "abs": "https://arxiv.org/abs/2512.06619", "authors": ["Qi Song", "Hongjing Li", "Chengxi Yu", "Jingzheng Huang", "Ding Wang", "Peng Huang", "Guihua Zeng"], "title": "Fault-Tolerant Information Processing with Quantum Weak Measurement", "comment": null, "summary": "Noise is an important factor that influences the reliability of information acquisition, transmission, processing, and storage. In order to suppress the inevitable noise effects, a fault-tolerant information processing approach via quantum weak measurement is proposed, where pairwise orthogonal postselected measurement bases with various tiny angles and optimal compositions of measured results are chosen as a decoding rule. The signal to be protected can be retrieved with a minimal distortion after having been transmitted through a noisy channel. Demonstrated by typical examples of encoding signal on two-level superposition state or Einstein-Podolsky-Rossen state transmitted through random telegraph noise and decoherence noises channel, the mean squared error distortion may be close to $0$ and the fault-tolerant capability could reach $1$ with finite quantum resources. To verify the availability of the proposed approach, classic coherent light and quantum coherent state are used for encoding information in the experiment. Potentially, the proposed approach may provide a solution for suppressing noise effects in long-distance quantum communication, high-sensitivity quantum sensing, and accurate quantum computation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u91cf\u5b50\u5f31\u6d4b\u91cf\u7684\u5bb9\u9519\u4fe1\u606f\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u5fae\u5c0f\u89d2\u5ea6\u7684\u6b63\u4ea4\u540e\u9009\u62e9\u6d4b\u91cf\u57fa\u548c\u4f18\u5316\u6d4b\u91cf\u7ed3\u679c\u7ec4\u5408\u4f5c\u4e3a\u89e3\u7801\u89c4\u5219\uff0c\u5728\u566a\u58f0\u4fe1\u9053\u4e2d\u6700\u5c0f\u5316\u4fe1\u53f7\u5931\u771f\u3002", "motivation": "\u566a\u58f0\u4e25\u91cd\u5f71\u54cd\u4fe1\u606f\u83b7\u53d6\u3001\u4f20\u8f93\u3001\u5904\u7406\u548c\u5b58\u50a8\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6291\u5236\u566a\u58f0\u5f71\u54cd\u7684\u5bb9\u9519\u4fe1\u606f\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u5f31\u6d4b\u91cf\u6280\u672f\uff0c\u9009\u62e9\u6210\u5bf9\u6b63\u4ea4\u7684\u540e\u9009\u62e9\u6d4b\u91cf\u57fa\uff08\u5177\u6709\u5404\u79cd\u5fae\u5c0f\u89d2\u5ea6\uff09\u548c\u6d4b\u91cf\u7ed3\u679c\u7684\u6700\u4f18\u7ec4\u5408\u4f5c\u4e3a\u89e3\u7801\u89c4\u5219\uff0c\u4f7f\u53d7\u4fdd\u62a4\u4fe1\u53f7\u5728\u901a\u8fc7\u566a\u58f0\u4fe1\u9053\u4f20\u8f93\u540e\u80fd\u4ee5\u6700\u5c0f\u5931\u771f\u6062\u590d\u3002", "result": "\u901a\u8fc7\u4e24\u80fd\u7ea7\u53e0\u52a0\u6001\u6216EPR\u6001\u5728\u968f\u673a\u7535\u62a5\u566a\u58f0\u548c\u9000\u76f8\u5e72\u566a\u58f0\u4fe1\u9053\u4e2d\u4f20\u8f93\u7684\u5178\u578b\u793a\u4f8b\uff0c\u5747\u65b9\u8bef\u5dee\u5931\u771f\u53ef\u63a5\u8fd10\uff0c\u5bb9\u9519\u80fd\u529b\u53ef\u8fbe1\uff0c\u4e14\u4ec5\u9700\u6709\u9650\u91cf\u5b50\u8d44\u6e90\u3002\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u7ecf\u5178\u76f8\u5e72\u5149\u548c\u91cf\u5b50\u76f8\u5e72\u6001\u7f16\u7801\u4fe1\u606f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u957f\u8ddd\u79bb\u91cf\u5b50\u901a\u4fe1\u3001\u9ad8\u7075\u654f\u5ea6\u91cf\u5b50\u4f20\u611f\u548c\u7cbe\u786e\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u566a\u58f0\u6291\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07643", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07643", "abs": "https://arxiv.org/abs/2512.07643", "authors": ["Ganesh Subramaniam", "Avik De", "Jackson Levi Said"], "title": "Density contrast in the scalar-tensor extension of non-metricity gravity", "comment": null, "summary": "We present a novel derivation of scalar cosmological perturbations in the scalar-tensor extension of non-metricity gravity, where the non-metricity scalar $Q$ is non-minimally coupled to a dynamical scalar field. While previous investigations of symmetric teleparallel gravity focused primarily on background evolution or specialised gauge choices, a complete treatment of scalar perturbations in this non-minimally coupled framework has remained unexplored. In this work, we derive the full set of perturbed field equations, impose the quasi-static approximation, and obtain the effective Poisson equation together with the corresponding modified gravitational constant $G_{\\rm eff}$. These ingredients allow us to construct the density contrast evolution equation and analyse the matter growth rate and growth index. Through numerical analysis, we showed that the scalar non-metricity theory is comparable to the well-known $\u039bCDM$ model to some extent. The results provide a foundation for testing scalar non-metricity theories against large-scale structure observations and open new avenues for constraining non-minimally coupled non-metricity cosmologies.", "AI": {"tldr": "\u672c\u6587\u5728\u6807\u91cf-\u5f20\u91cf\u6269\u5c55\u7684\u975e\u5ea6\u91cf\u6027\u5f15\u529b\u7406\u8bba\u4e2d\uff0c\u9996\u6b21\u5b8c\u6574\u63a8\u5bfc\u4e86\u6807\u91cf\u5b87\u5b99\u5b66\u6270\u52a8\uff0c\u83b7\u5f97\u4e86\u6709\u6548\u6cca\u677e\u65b9\u7a0b\u548c\u4fee\u6b63\u5f15\u529b\u5e38\u6570\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5206\u6790\u8868\u660e\u8be5\u7406\u8bba\u4e0e\u039bCDM\u6a21\u578b\u6709\u4e00\u5b9a\u53ef\u6bd4\u6027\u3002", "motivation": "\u5148\u524d\u5bf9\u5bf9\u79f0\u8fdc\u5e73\u884c\u5f15\u529b\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u80cc\u666f\u6f14\u5316\u6216\u7279\u6b8a\u89c4\u8303\u9009\u62e9\uff0c\u800c\u5728\u975e\u6700\u5c0f\u8026\u5408\u6846\u67b6\u4e0b\u5bf9\u6807\u91cf\u6270\u52a8\u7684\u5b8c\u6574\u5904\u7406\u5c1a\u672a\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u6d4b\u8bd5\u6807\u91cf\u975e\u5ea6\u91cf\u6027\u7406\u8bba\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u5728\u6807\u91cf-\u5f20\u91cf\u6269\u5c55\u7684\u975e\u5ea6\u91cf\u6027\u5f15\u529b\u7406\u8bba\u4e2d\uff0c\u63a8\u5bfc\u5b8c\u6574\u7684\u6270\u52a8\u573a\u65b9\u7a0b\uff0c\u65bd\u52a0\u51c6\u9759\u6001\u8fd1\u4f3c\uff0c\u83b7\u5f97\u6709\u6548\u6cca\u677e\u65b9\u7a0b\u548c\u4fee\u6b63\u5f15\u529b\u5e38\u6570G_eff\uff0c\u6784\u5efa\u5bc6\u5ea6\u5bf9\u6bd4\u6f14\u5316\u65b9\u7a0b\uff0c\u5206\u6790\u7269\u8d28\u589e\u957f\u7387\u4e0e\u589e\u957f\u6307\u6570\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5206\u6790\u8868\u660e\uff0c\u6807\u91cf\u975e\u5ea6\u91cf\u6027\u7406\u8bba\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u4e0e\u039bCDM\u6a21\u578b\u53ef\u6bd4\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5229\u7528\u5927\u5c3a\u5ea6\u7ed3\u6784\u89c2\u6d4b\u6d4b\u8bd5\u6807\u91cf\u975e\u5ea6\u91cf\u6027\u7406\u8bba\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5728\u975e\u6700\u5c0f\u8026\u5408\u7684\u975e\u5ea6\u91cf\u6027\u5b87\u5b99\u5b66\u4e2d\u5b8c\u6210\u4e86\u6807\u91cf\u6270\u52a8\u7684\u5b8c\u6574\u5904\u7406\uff0c\u4e3a\u7ea6\u675f\u8fd9\u7c7b\u7406\u8bba\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u89c2\u6d4b\u6570\u636e\u5bf9\u6bd4\u7684\u6846\u67b6\u3002"}}
{"id": "2512.06301", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06301", "abs": "https://arxiv.org/abs/2512.06301", "authors": ["Jihun Ahn", "Gabriella Pasya Irianti", "Vikram Thapar", "Su-Mi Hur"], "title": "Chemistry Integrated Language Model using Hierarchical Molecular Representation for Polymer Informatics", "comment": null, "summary": "Machine learning has transformed material discovery for inorganic compounds and small molecules, yet polymers remain largely inaccessible to these methods. While data scarcity is often cited as the primary bottleneck, we demonstrate that strategic molecular representations can overcome this limitation. We introduce CI-LLM (Chemically Informed Language Model), a framework combining HAPPY (Hierarchically Abstracted rePeat unit of PolYmer), which encodes chemical substructures as tokens, with numerical descriptors within transformer architectures. For property prediction, De$^3$BERTa, our descriptor-enriched encoder, achieves 3.5x faster inference than SMILES-based models with improved accuracy ($R^2$ score gains of 0.9-4.1 percent across four properties), while providing interpretable structure-property insights at the subgroup level. For inverse design, our GPT-based generator produces polymers with targeted properties, achieving 100 percent scaffold retention and successful multi-property optimization for negatively correlated objectives. This comprehensive framework demonstrates both forward prediction and inverse design capabilities, showcasing how strategic molecular representation advances machine learning applications in polymer science.", "AI": {"tldr": "CI-LLM\u6846\u67b6\u7ed3\u5408HAPPY\u5206\u5b50\u8868\u793a\u548c\u6570\u503c\u63cf\u8ff0\u7b26\uff0c\u5b9e\u73b0\u4e86\u805a\u5408\u7269\u6027\u8d28\u9884\u6d4b\u548c\u9006\u5411\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u805a\u5408\u7269\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u65e0\u673a\u5316\u5408\u7269\u548c\u5c0f\u5206\u5b50\u6750\u6599\u53d1\u73b0\uff0c\u4f46\u805a\u5408\u7269\u9886\u57df\u4ecd\u96be\u4ee5\u5e94\u7528\u8fd9\u4e9b\u65b9\u6cd5\u3002\u867d\u7136\u6570\u636e\u7a00\u7f3a\u5e38\u88ab\u8ba4\u4e3a\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u4f46\u7814\u7a76\u8868\u660e\u901a\u8fc7\u7b56\u7565\u6027\u5206\u5b50\u8868\u793a\u53ef\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51faCI-LLM\u6846\u67b6\uff0c\u7ed3\u5408HAPPY\uff08\u5206\u5c42\u62bd\u8c61\u805a\u5408\u7269\u91cd\u590d\u5355\u5143\uff09\u8868\u793a\u6cd5\uff0c\u5c06\u5316\u5b66\u5b50\u7ed3\u6784\u7f16\u7801\u4e3atoken\uff0c\u5e76\u4e0e\u6570\u503c\u63cf\u8ff0\u7b26\u4e00\u8d77\u96c6\u6210\u5230transformer\u67b6\u6784\u4e2d\u3002\u4f7f\u7528De$^3$BERTa\u8fdb\u884c\u6027\u8d28\u9884\u6d4b\uff0c\u57fa\u4e8eGPT\u7684\u751f\u6210\u5668\u8fdb\u884c\u9006\u5411\u8bbe\u8ba1\u3002", "result": "De$^3$BERTa\u6bd4\u57fa\u4e8eSMILES\u7684\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u5feb3.5\u500d\uff0c\u5728\u56db\u4e2a\u6027\u8d28\u4e0a\u7684R\u00b2\u5206\u6570\u63d0\u53470.9-4.1%\u3002GPT\u751f\u6210\u5668\u5b9e\u73b0100%\u9aa8\u67b6\u4fdd\u7559\uff0c\u6210\u529f\u4f18\u5316\u8d1f\u76f8\u5173\u76ee\u6807\u7684\u591a\u6027\u8d28\u8bbe\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u7b56\u7565\u6027\u5206\u5b50\u8868\u793a\uff0cCI-LLM\u6846\u67b6\u5c55\u793a\u4e86\u805a\u5408\u7269\u79d1\u5b66\u4e2d\u673a\u5668\u5b66\u4e60\u7684\u524d\u5411\u9884\u6d4b\u548c\u9006\u5411\u8bbe\u8ba1\u80fd\u529b\uff0c\u4e3a\u805a\u5408\u7269\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u5168\u9762\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.06650", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06650", "abs": "https://arxiv.org/abs/2512.06650", "authors": ["Zherui Jerry Wang", "Joshua Carlo A. Casapao", "Naphan Benchasattabuse", "Ananda G. Maity", "Jordi Tura", "Akihito Soeda", "Michal Hajdu\u0161ek", "Rodney Van Meter", "David Elkouss"], "title": "Efficient graph-diagonal characterization of noisy states distributed over quantum networks via Bell sampling", "comment": "21 pages, 7 figures; comments welcome!", "summary": "Graph states are an important class of entangled states that serve as a key resource for distributed information processing and communication in quantum networks. In this work, we propose a protocol that utilizes a Bell sampling subroutine to characterize the diagonal elements in the graph basis of noisy graph states distributed across a network. Our approach offers significant advantages over direct diagonal estimation using unentangled single-qubit measurements in terms of scalability. Specifically, we prove that estimating the full vector of diagonal elements requires a sample complexity that scales linearly with the number of qubits ($\\mathcal{O}(n)$), providing an exponential reduction in resource overhead compared to the best known $\\mathcal{O}(2^n)$ scaling of direct estimation. Furthermore, we demonstrate that global properties, such as state fidelity, can be estimated with a sample complexity independent of the network size. Finally, we present numerical results indicating that the estimation in practice is more efficient than the derived theoretical bounds. Our work thus establishes a promising technique for efficiently estimating noisy graph states in large networks under realistic experimental conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u8d1d\u5c14\u91c7\u6837\u5b50\u7a0b\u5e8f\u6765\u8868\u5f81\u7f51\u7edc\u4e2d\u566a\u58f0\u56fe\u6001\u5bf9\u89d2\u5143\u7d20\u7684\u534f\u8bae\uff0c\u76f8\u6bd4\u76f4\u63a5\u5bf9\u89d2\u4f30\u8ba1\u5177\u6709\u6307\u6570\u7ea7\u8d44\u6e90\u8282\u7701\u4f18\u52bf\u3002", "motivation": "\u56fe\u6001\u662f\u91cf\u5b50\u7f51\u7edc\u4e2d\u5206\u5e03\u5f0f\u4fe1\u606f\u5904\u7406\u548c\u901a\u4fe1\u7684\u5173\u952e\u8d44\u6e90\uff0c\u4f46\u5728\u5b9e\u9645\u7f51\u7edc\u4e2d\u4f1a\u53d7\u566a\u58f0\u5f71\u54cd\u3002\u9700\u8981\u9ad8\u6548\u8868\u5f81\u566a\u58f0\u56fe\u6001\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u7684\u72b6\u6001\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u8d1d\u5c14\u91c7\u6837\u5b50\u7a0b\u5e8f\u6765\u8868\u5f81\u56fe\u57fa\u4e2d\u7684\u5bf9\u89d2\u5143\u7d20\uff0c\u907f\u514d\u4e86\u76f4\u63a5\u5bf9\u89d2\u4f30\u8ba1\u6240\u9700\u7684\u5355\u91cf\u5b50\u6bd4\u7279\u6d4b\u91cf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u91cf\u8d1d\u5c14\u6001\u6765\u63d0\u53d6\u56fe\u6001\u7684\u5bf9\u89d2\u4fe1\u606f\u3002", "result": "1. \u4f30\u8ba1\u5b8c\u6574\u5bf9\u89d2\u5143\u7d20\u5411\u91cf\u6240\u9700\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e3aO(n)\uff0c\u76f8\u6bd4\u5df2\u77e5\u6700\u4f73\u76f4\u63a5\u4f30\u8ba1\u7684O(2^n)\u5b9e\u73b0\u6307\u6570\u7ea7\u51cf\u5c11\uff1b2. \u5168\u5c40\u6027\u8d28\uff08\u5982\u72b6\u6001\u4fdd\u771f\u5ea6\uff09\u7684\u4f30\u8ba1\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u7f51\u7edc\u89c4\u6a21\u65e0\u5173\uff1b3. \u6570\u503c\u7ed3\u679c\u663e\u793a\u5b9e\u9645\u4f30\u8ba1\u6548\u7387\u4f18\u4e8e\u7406\u8bba\u754c\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u4e00\u79cd\u5728\u73b0\u5b9e\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u9ad8\u6548\u4f30\u8ba1\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u566a\u58f0\u56fe\u6001\u7684\u6709\u524d\u666f\u6280\u672f\uff0c\u4e3a\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u72b6\u6001\u8868\u5f81\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07677", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07677", "abs": "https://arxiv.org/abs/2512.07677", "authors": ["Lars Andersson", "Finnian Gray", "Marius A. Oancea"], "title": "Conserved quantities and integrability for massless spinning particles in general relativity", "comment": null, "summary": "In general relativity, the dynamics of spinning particles is governed by the Mathisson-Papapetrou-Dixon equations, which are most commonly applied to massive bodies, but the framework also works in the massless case. Such massless versions naturally arise, for example, in the description of energy centroids of high-frequency wave packets. In this work, we consider massless spinning particles in spacetimes with hidden symmetries and we derive the generalized conservation laws associated with conformal Killing-Yano tensors. We then show that the spin Hall equations, a particular case of the Mathisson-Papapetrou-Dixon equations restricted to massless particles with longitudinal angular momentum, are completely integrable in a large class of type D spacetimes. Additionally, we also show that for massive spinning particles, the generalized Carter constant associated with Killing-Yano tensors is conserved independently of the choice of spin supplementary condition.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u65e0\u8d28\u91cf\u81ea\u65cb\u7c92\u5b50\u7684\u52a8\u529b\u5b66\uff0c\u63a8\u5bfc\u4e86\u4e0e\u5171\u5f62Killing-Yano\u5f20\u91cf\u76f8\u5173\u7684\u5e7f\u4e49\u5b88\u6052\u5b9a\u5f8b\uff0c\u8bc1\u660e\u4e86\u5728D\u578b\u65f6\u7a7a\u4e2d\u7684\u53ef\u79ef\u6027\u3002", "motivation": "\u7814\u7a76\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u65e0\u8d28\u91cf\u81ea\u65cb\u7c92\u5b50\u7684\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662fMathisson-Papapetrou-Dixon\u65b9\u7a0b\u5728\u65e0\u8d28\u91cf\u60c5\u51b5\u4e0b\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u65b9\u7a0b\u5728\u5177\u6709\u9690\u85cf\u5bf9\u79f0\u6027\u7684\u65f6\u7a7a\u4e2d\u7684\u884c\u4e3a\u3002", "method": "\u4f7f\u7528Mathisson-Papapetrou-Dixon\u65b9\u7a0b\u6846\u67b6\uff0c\u8003\u8651\u5177\u6709\u9690\u85cf\u5bf9\u79f0\u6027\u7684\u65f6\u7a7a\uff0c\u63a8\u5bfc\u4e0e\u5171\u5f62Killing-Yano\u5f20\u91cf\u76f8\u5173\u7684\u5e7f\u4e49\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u5206\u6790\u81ea\u65cbHall\u65b9\u7a0b\u5728D\u578b\u65f6\u7a7a\u4e2d\u7684\u53ef\u79ef\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u65e0\u8d28\u91cf\u81ea\u65cb\u7c92\u5b50\u7684\u81ea\u65cbHall\u65b9\u7a0b\u5728\u4e00\u5927\u7c7bD\u578b\u65f6\u7a7a\u4e2d\u662f\u5b8c\u5168\u53ef\u79ef\u7684\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6709\u8d28\u91cf\u81ea\u65cb\u7c92\u5b50\uff0c\u4e0eKilling-Yano\u5f20\u91cf\u76f8\u5173\u7684\u5e7f\u4e49Carter\u5e38\u6570\u72ec\u7acb\u4e8e\u81ea\u65cb\u8865\u5145\u6761\u4ef6\u7684\u9009\u62e9\u800c\u5b88\u6052\u3002", "conclusion": "\u5728\u5177\u6709\u9690\u85cf\u5bf9\u79f0\u6027\u7684\u65f6\u7a7a\u4e2d\uff0c\u65e0\u8d28\u91cf\u81ea\u65cb\u7c92\u5b50\u7684\u52a8\u529b\u5b66\u53ef\u4ee5\u901a\u8fc7\u5171\u5f62Killing-Yano\u5f20\u91cf\u83b7\u5f97\u5e7f\u4e49\u5b88\u6052\u5b9a\u5f8b\uff0c\u81ea\u65cbHall\u65b9\u7a0b\u5728D\u578b\u65f6\u7a7a\u4e2d\u53ef\u79ef\uff0c\u8fd9\u4e3a\u7406\u89e3\u9ad8\u80fd\u7269\u7406\u4e2d\u7684\u7c92\u5b50\u8fd0\u52a8\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2512.06303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06303", "abs": "https://arxiv.org/abs/2512.06303", "authors": ["Preksha Girish", "Rachana Mysore", "Kiran K. N.", "Hiranmayee R.", "Shipra Prashanth", "Shrey Kumar"], "title": "Multimodal Graph Neural Networks for Prognostic Modeling of Brain Network Reorganization", "comment": "5 pages, 2 figures. IEEE conference-style format", "summary": "Understanding the dynamic reorganization of brain networks is critical for predicting cognitive decline, neurological progression, and individual variability in clinical outcomes. This work proposes a multimodal graph neural network framework that integrates structural MRI, diffusion tensor imaging, and functional MRI to model spatiotemporal brain network reorganization. Brain regions are represented as nodes and structural and functional connectivity as edges, forming longitudinal brain graphs for each subject. Temporal evolution is captured via fractional stochastic differential operators embedded within graph-based recurrent networks, enabling the modeling of long-term dependencies and stochastic fluctuations in network dynamics. Attention mechanisms fuse multimodal information and generate interpretable biomarkers, including network energy entropy, graph curvature, fractional memory indices, and modality-specific attention scores. These biomarkers are combined into a composite prognostic index to quantify individual risk of network instability or cognitive decline. Experiments on longitudinal neuroimaging datasets demonstrate both predictive accuracy and interpretability. The results highlight the potential of mathematically rigorous, multimodal graph-based approaches for deriving clinically meaningful biomarkers from existing imaging data without requiring new data collection.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u6574\u5408\u7ed3\u6784MRI\u3001\u6269\u6563\u5f20\u91cf\u6210\u50cf\u548c\u529f\u80fdMRI\uff0c\u5efa\u6a21\u8111\u7f51\u7edc\u7684\u65f6\u7a7a\u91cd\u7ec4\u52a8\u6001\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u7684\u751f\u7269\u6807\u5fd7\u7269\u7528\u4e8e\u9884\u6d4b\u8ba4\u77e5\u8870\u9000\u98ce\u9669\u3002", "motivation": "\u7406\u89e3\u8111\u7f51\u7edc\u7684\u52a8\u6001\u91cd\u7ec4\u5bf9\u4e8e\u9884\u6d4b\u8ba4\u77e5\u8870\u9000\u3001\u795e\u7ecf\u75be\u75c5\u8fdb\u5c55\u548c\u4e2a\u4f53\u4e34\u5e8a\u7ed3\u679c\u53d8\u5f02\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u65b0\u7684\u6570\u636e\u6536\u96c6\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u4ece\u73b0\u6709\u5f71\u50cf\u6570\u636e\u4e2d\u63d0\u53d6\u4e34\u5e8a\u610f\u4e49\u7684\u751f\u7269\u6807\u5fd7\u7269\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff1a\u5c06\u8111\u533a\u8868\u793a\u4e3a\u8282\u70b9\uff0c\u7ed3\u6784\u548c\u529f\u80fd\u8fde\u63a5\u8868\u793a\u4e3a\u8fb9\uff0c\u6784\u5efa\u7eb5\u5411\u8111\u56fe\u3002\u4f7f\u7528\u5206\u6570\u968f\u673a\u5fae\u5206\u7b97\u5b50\u5d4c\u5165\u56fe\u5faa\u73af\u7f51\u7edc\uff0c\u6355\u6349\u957f\u671f\u4f9d\u8d56\u548c\u968f\u673a\u6ce2\u52a8\u3002\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u751f\u6210\u7f51\u7edc\u80fd\u91cf\u71b5\u3001\u56fe\u66f2\u7387\u3001\u5206\u6570\u8bb0\u5fc6\u6307\u6570\u7b49\u53ef\u89e3\u91ca\u751f\u7269\u6807\u5fd7\u7269\uff0c\u7ec4\u5408\u6210\u9884\u540e\u6307\u6570\u3002", "result": "\u5728\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u73b0\u6709\u5f71\u50cf\u6570\u636e\u4e2d\u63d0\u53d6\u4e34\u5e8a\u610f\u4e49\u7684\u751f\u7269\u6807\u5fd7\u7269\uff0c\u65e0\u9700\u65b0\u6570\u636e\u6536\u96c6\u3002", "conclusion": "\u6570\u5b66\u4e25\u8c28\u7684\u591a\u6a21\u6001\u56fe\u65b9\u6cd5\u5177\u6709\u4ece\u73b0\u6709\u5f71\u50cf\u6570\u636e\u4e2d\u63d0\u53d6\u4e34\u5e8a\u610f\u4e49\u751f\u7269\u6807\u5fd7\u7269\u7684\u6f5c\u529b\uff0c\u4e3a\u9884\u6d4b\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u8ba4\u77e5\u8870\u9000\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2512.06661", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06661", "abs": "https://arxiv.org/abs/2512.06661", "authors": ["Haotao Zhu", "Zhenhua Li", "Shuai Zhao", "Xiaodan Lyu", "Shihao Ru", "Yizhi Huang", "Zitong Xu", "Rui Qu", "Weibo Gao"], "title": "Experimental demonstration of scalable quantum cryptographic conferencing", "comment": null, "summary": "Quantum network enables a variety of quantum information processing tasks, where multi-user quantum communication is one of the important objectives. Quantum cryptographic conferencing serves as an essential solution to establish secure keys to realize secure multi-user communications. However, existing QCC implementations have been fundamentally limited by the low probability of multi-user coincidence detection to measure or construct the Greenberger-Horne-Zeilinger (GHZ) entangled state. In this work, we report the experimental realization of QCC eliminating the need for coincidence detection, where the GHZ state is constructed by correlating detection events occurring within the coherence time, thereby greatly enhancing the success probability of GHZ-state measurement. Meanwhile, to establish and maintain high-visibility GHZ measurement among three independent users, we developed a three-party phase compensation scheme combined with precise temporal and polarization alignment within a time-bin-phase encoding framework. Furthermore, we designed an efficient pairing strategy to simplify subsequent data processing and enhance processing efficiency. Based on these techniques, we successfully performed QCC experiments over total channel losses of 66.3 dB, corresponding to 331.5 km of commercial fiber (0.2 dB/km), achieving secure key rates of 5.4 bit/s, whereas previous QCC experiments have been limited to 100 km. The results surpass the multi-user repeaterless bound in quantum networks, establishing a new regime of scalable, multi-user quantum communication and paving the way for metropolitan quantum networks.", "AI": {"tldr": "\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u65e0\u9700\u7b26\u5408\u63a2\u6d4b\u7684\u91cf\u5b50\u5bc6\u7801\u4f1a\u8bae\uff0c\u901a\u8fc7\u5173\u8054\u76f8\u5e72\u65f6\u95f4\u5185\u7684\u63a2\u6d4b\u4e8b\u4ef6\u6784\u5efaGHZ\u6001\uff0c\u663e\u8457\u63d0\u9ad8\u6210\u529f\u7387\uff0c\u5728331.5\u516c\u91cc\u5149\u7ea4\u4e0a\u5b9e\u73b05.4\u6bd4\u7279/\u79d2\u7684\u5bc6\u94a5\u7387\uff0c\u8d85\u8d8a\u591a\u7528\u6237\u65e0\u4e2d\u7ee7\u754c\u9650\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u5bc6\u7801\u4f1a\u8bae(QCC)\u5b9e\u73b0\u53d7\u9650\u4e8e\u591a\u7528\u6237\u7b26\u5408\u63a2\u6d4b\u7684\u4f4e\u6982\u7387\uff0c\u9650\u5236\u4e86GHZ\u7ea0\u7f20\u6001\u7684\u6d4b\u91cf\u6216\u6784\u5efa\uff0c\u963b\u788d\u4e86\u91cf\u5b50\u7f51\u7edc\u4e2d\u591a\u7528\u6237\u5b89\u5168\u901a\u4fe1\u7684\u53d1\u5c55\u3002", "method": "1. \u6d88\u9664\u7b26\u5408\u63a2\u6d4b\u9700\u6c42\uff0c\u901a\u8fc7\u5173\u8054\u76f8\u5e72\u65f6\u95f4\u5185\u7684\u63a2\u6d4b\u4e8b\u4ef6\u6784\u5efaGHZ\u6001\uff1b2. \u5f00\u53d1\u4e09\u65b9\u76f8\u4f4d\u8865\u507f\u65b9\u6848\uff0c\u7ed3\u5408\u7cbe\u786e\u7684\u65f6\u95f4\u548c\u504f\u632f\u5bf9\u51c6\uff1b3. \u8bbe\u8ba1\u9ad8\u6548\u914d\u5bf9\u7b56\u7565\u7b80\u5316\u6570\u636e\u5904\u7406\uff1b4. \u5728\u65f6\u95f4-\u76f8\u4f4d\u7f16\u7801\u6846\u67b6\u4e0b\u5b9e\u73b0\u3002", "result": "\u5728\u603b\u4fe1\u9053\u635f\u801766.3 dB\uff08\u5bf9\u5e94331.5\u516c\u91cc\u5546\u7528\u5149\u7ea4\uff09\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u4e865.4\u6bd4\u7279/\u79d2\u7684\u5b89\u5168\u5bc6\u94a5\u7387\uff0c\u8fdc\u8d85\u4e4b\u524dQCC\u5b9e\u9a8c\u7684100\u516c\u91cc\u9650\u5236\uff0c\u8d85\u8d8a\u4e86\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u591a\u7528\u6237\u65e0\u4e2d\u7ee7\u754c\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f00\u521b\u4e86\u53ef\u6269\u5c55\u7684\u591a\u7528\u6237\u91cf\u5b50\u901a\u4fe1\u65b0\u8303\u5f0f\uff0c\u4e3a\u57ce\u57df\u91cf\u5b50\u7f51\u7edc\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u901a\u8fc7\u6d88\u9664\u7b26\u5408\u63a2\u6d4b\u9650\u5236\u548c\u5f00\u53d1\u9ad8\u6548\u76f8\u4f4d\u8865\u507f\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5b50\u5bc6\u7801\u4f1a\u8bae\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.07708", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07708", "abs": "https://arxiv.org/abs/2512.07708", "authors": ["Quentin Vigneron", "Hamed Barzegar"], "title": "Bianchi Cosmologies in a Thurston-Based Theory of Gravity", "comment": "44+13 pages, 7 tables", "summary": "The strong interplay between Bianchi--Kantowski--Sachs (BKS) spacetimes and Thurston geometries motivates the exploration of the role of topology in our understanding of gravity. As such, we study non-tilted BKS solutions of a theory of gravity that explicitly depends on Thurston geometries. We show that shear-free solutions with perfect fluid, as well as static vacuum solutions, exist for all topologies. Moreover, we prove that, aside from non-rotationally-symmetric Bianchi II models, all BKS metrics isotropize in the presence of a positive cosmological constant, and that recollapse is never possible when the weak energy condition is satisfied. This contrasts with General Relativity (GR), where these two properties fail for Bianchi IX and KS metrics. No additional parameters compared to GR are required for these results. We discuss, in particular, how this framework might allow for simple inflationary models in any topology.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f9d\u8d56\u4e8eThurston\u51e0\u4f55\u7684\u5f15\u529b\u7406\u8bba\u4e2d\u7684Bianchi-Kantowski-Sachs\u65f6\u7a7a\u89e3\uff0c\u8bc1\u660e\u4e86\u5728\u6b63\u5b87\u5b99\u5e38\u6570\u4e0b\u6240\u6709BKS\u5ea6\u91cf\u90fd\u4f1a\u5404\u5411\u540c\u6027\u5316\uff0c\u4e14\u5f31\u80fd\u91cf\u6761\u4ef6\u6ee1\u8db3\u65f6\u4e0d\u4f1a\u53d1\u751f\u518d\u574d\u7f29\uff0c\u8fd9\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u5f62\u6210\u5bf9\u6bd4\u3002", "motivation": "\u63a2\u7d22\u62d3\u6251\u7ed3\u6784\u5728\u7406\u89e3\u5f15\u529b\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662fBianchi-Kantowski-Sachs\u65f6\u7a7a\u4e0eThurston\u51e0\u4f55\u4e4b\u95f4\u7684\u5f3a\u76f8\u4e92\u4f5c\u7528\uff0c\u7814\u7a76\u4f9d\u8d56\u4e8eThurston\u51e0\u4f55\u7684\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u975e\u503e\u659cBKS\u89e3\u3002", "method": "\u7814\u7a76\u4f9d\u8d56\u4e8eThurston\u51e0\u4f55\u7684\u5f15\u529b\u7406\u8bba\u4e2d\u7684\u975e\u503e\u659cBianchi-Kantowski-Sachs\u89e3\uff0c\u5206\u6790\u526a\u5207\u81ea\u7531\u5b8c\u7f8e\u6d41\u4f53\u89e3\u548c\u9759\u6001\u771f\u7a7a\u89e3\u7684\u5b58\u5728\u6027\uff0c\u5e76\u8bc1\u660e\u5728\u6b63\u5b87\u5b99\u5e38\u6570\u4e0b\u7684\u5404\u5411\u540c\u6027\u5316\u6027\u8d28\u3002", "result": "1. \u6240\u6709\u62d3\u6251\u7ed3\u6784\u90fd\u5b58\u5728\u526a\u5207\u81ea\u7531\u5b8c\u7f8e\u6d41\u4f53\u89e3\u548c\u9759\u6001\u771f\u7a7a\u89e3\uff1b2. \u9664\u975e\u65cb\u8f6c\u5bf9\u79f0Bianchi II\u6a21\u578b\u5916\uff0c\u6240\u6709BKS\u5ea6\u91cf\u5728\u6b63\u5b87\u5b99\u5e38\u6570\u4e0b\u90fd\u4f1a\u5404\u5411\u540c\u6027\u5316\uff1b3. \u5f31\u80fd\u91cf\u6761\u4ef6\u6ee1\u8db3\u65f6\u4e0d\u4f1a\u53d1\u751f\u518d\u574d\u7f29\uff1b4. \u8fd9\u4e9b\u7ed3\u679c\u4e0d\u9700\u8981\u6bd4\u5e7f\u4e49\u76f8\u5bf9\u8bba\u66f4\u591a\u7684\u53c2\u6570\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u4efb\u4f55\u62d3\u6251\u7ed3\u6784\u4e2d\u6784\u5efa\u7b80\u5355\u7684\u66b4\u80c0\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u76f8\u6bd4\uff0c\u5728\u6b63\u5b87\u5b99\u5e38\u6570\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u5404\u5411\u540c\u6027\u5316\u884c\u4e3a\uff0c\u4e14\u907f\u514d\u4e86\u518d\u574d\u7f29\u95ee\u9898\u3002"}}
{"id": "2512.06341", "categories": ["cs.LG", "cs.IR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.06341", "abs": "https://arxiv.org/abs/2512.06341", "authors": ["Ronald Katende"], "title": "Interpretive Efficiency: Information-Geometric Foundations of Data Usefulness", "comment": null, "summary": "Interpretability is central to trustworthy machine learning, yet existing metrics rarely quantify how effectively data support an interpretive representation. We propose Interpretive Efficiency, a normalized, task-aware functional that measures the fraction of task-relevant information transmitted through an interpretive channel. The definition is grounded in five axioms ensuring boundedness, Blackwell-style monotonicity, data-processing stability, admissible invariance, and asymptotic consistency. We relate the functional to mutual information and derive a local Fisher-geometric expansion, then establish asymptotic and finite-sample estimation guarantees using standard empirical-process tools. Experiments on controlled image and signal tasks demonstrate that the measure recovers theoretical orderings, exposes representational redundancy masked by accuracy, and correlates with robustness, making it a practical, theory-backed diagnostic for representation design.", "AI": {"tldr": "\u63d0\u51faInterpretive Efficiency\uff08\u89e3\u91ca\u6548\u7387\uff09\u8fd9\u4e00\u65b0\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u89e3\u91ca\u6027\u8868\u793a\u5982\u4f55\u6709\u6548\u4f20\u9012\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u6307\u6807\u5f88\u5c11\u80fd\u6709\u6548\u91cf\u5316\u6570\u636e\u5bf9\u89e3\u91ca\u6027\u8868\u793a\u7684\u652f\u6301\u7a0b\u5ea6\uff0c\u9700\u8981\u4e00\u79cd\u7406\u8bba\u4e25\u8c28\u4e14\u5b9e\u7528\u7684\u5ea6\u91cf\u65b9\u6cd5\u6765\u8bc4\u4f30\u89e3\u91ca\u6027\u8868\u793a\u7684\u8bbe\u8ba1\u8d28\u91cf\u3002", "method": "\u63d0\u51faInterpretive Efficiency\u8fd9\u4e00\u5f52\u4e00\u5316\u3001\u4efb\u52a1\u611f\u77e5\u7684\u51fd\u6570\uff0c\u57fa\u4e8e\u4e94\u4e2a\u516c\u7406\uff08\u6709\u754c\u6027\u3001Blackwell\u5f0f\u5355\u8c03\u6027\u3001\u6570\u636e\u5904\u7406\u7a33\u5b9a\u6027\u3001\u5bb9\u8bb8\u4e0d\u53d8\u6027\u3001\u6e10\u8fd1\u4e00\u81f4\u6027\uff09\uff0c\u5c06\u5176\u4e0e\u4e92\u4fe1\u606f\u5173\u8054\uff0c\u63a8\u5bfc\u5c40\u90e8Fisher\u51e0\u4f55\u5c55\u5f00\uff0c\u5e76\u4f7f\u7528\u7ecf\u9a8c\u8fc7\u7a0b\u5de5\u5177\u5efa\u7acb\u6e10\u8fd1\u548c\u6709\u9650\u6837\u672c\u4f30\u8ba1\u4fdd\u8bc1\u3002", "result": "\u5728\u53d7\u63a7\u56fe\u50cf\u548c\u4fe1\u53f7\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u5ea6\u91cf\u80fd\u6062\u590d\u7406\u8bba\u6392\u5e8f\u3001\u63ed\u793a\u88ab\u51c6\u786e\u6027\u63a9\u76d6\u7684\u8868\u793a\u5197\u4f59\uff0c\u5e76\u4e0e\u9c81\u68d2\u6027\u76f8\u5173\uff0c\u6210\u4e3a\u8868\u793a\u8bbe\u8ba1\u7684\u5b9e\u7528\u7406\u8bba\u652f\u6301\u8bca\u65ad\u5de5\u5177\u3002", "conclusion": "Interpretive Efficiency\u662f\u4e00\u4e2a\u7406\u8bba\u4e25\u8c28\u3001\u5b9e\u7528\u7684\u89e3\u91ca\u6027\u8868\u793a\u8bc4\u4f30\u6307\u6807\uff0c\u4e3a\u8868\u793a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7406\u8bba\u652f\u6301\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2512.06707", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.06707", "abs": "https://arxiv.org/abs/2512.06707", "authors": ["Xin-Hai Tong", "Kohei Yoshimura", "Tan Van Vu", "Naruo Ohga"], "title": "Interplay between Standard Quantum Detailed Balance and Thermodynamically Consistent Entropy Production", "comment": "14 pages", "summary": "We demonstrate that if a quantum Markovian semigroup satisfies the standard quantum detailed balance condition, its generator admits a special representation that yields a vanishing entropy production rate. Conversely, if the generator admits a special representation adhering to the condition of thermodynamic consistency and leading to a vanishing entropy production rate, then the corresponding quantum Markovian semigroup must satisfy the standard quantum detailed balance condition. In this context, we adopt the definition of entropy production rate that is motivated by the physics literature and standard for thermodynamically consistent Lindbladians.", "AI": {"tldr": "\u91cf\u5b50\u9a6c\u5c14\u53ef\u592b\u534a\u7fa4\u6ee1\u8db3\u6807\u51c6\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u5f53\u4e14\u4ec5\u5f53\u5176\u751f\u6210\u5143\u5177\u6709\u7279\u6b8a\u8868\u793a\u5f62\u5f0f\uff0c\u5bfc\u81f4\u71b5\u4ea7\u751f\u7387\u4e3a\u96f6", "motivation": "\u7814\u7a76\u91cf\u5b50\u5f00\u653e\u7cfb\u7edf\u4e2d\u70ed\u529b\u5b66\u4e00\u81f4\u6027\u4e0e\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u8ba8\u71b5\u4ea7\u751f\u7387\u5728\u91cf\u5b50\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528", "method": "\u901a\u8fc7\u5206\u6790\u91cf\u5b50\u9a6c\u5c14\u53ef\u592b\u534a\u7fa4\u7684\u751f\u6210\u5143\u8868\u793a\uff0c\u5efa\u7acb\u6807\u51c6\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u4e0e\u7279\u6b8a\u751f\u6210\u5143\u8868\u793a\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb", "result": "\u8bc1\u660e\u4e86\u6807\u51c6\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u7b49\u4ef7\u4e8e\u751f\u6210\u5143\u5177\u6709\u70ed\u529b\u5b66\u4e00\u81f4\u7684\u7279\u6b8a\u8868\u793a\uff0c\u4e14\u8be5\u8868\u793a\u5bfc\u81f4\u71b5\u4ea7\u751f\u7387\u4e3a\u96f6", "conclusion": "\u91cf\u5b50\u7ec6\u81f4\u5e73\u8861\u6761\u4ef6\u4e0e\u70ed\u529b\u5b66\u4e00\u81f4\u6027\u5bc6\u5207\u76f8\u5173\uff0c\u71b5\u4ea7\u751f\u7387\u4e3a\u96f6\u662f\u4e24\u8005\u7b49\u4ef7\u7684\u5173\u952e\u5224\u636e"}}
{"id": "2512.07786", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07786", "abs": "https://arxiv.org/abs/2512.07786", "authors": ["Vinayak Joshi", "Ashok B. Joshi"], "title": "Thermodynamic Phase Transitions and Quantum Entropy Corrections in the Simpson-Visser Regular Black Hole", "comment": null, "summary": "Regular black holes offer a compelling framework to explore the consequences of resolving the central singularity of standard black holes. Using the Simpson-Visser \"black-bounce\" geometry as an elegant, analytically tractable framework, we explore the intricate thermodynamic behavior in such models. We demonstrate that this regular spacetime exhibits a critical instability, marked by a phase transition where the heat capacity is discontinuous. This transition signals a fundamental change in the black hole's evaporation state, which depends on the regularization parameter. Pushing beyond the semiclassical limit, we then derive the leading-order quantum corrections to the entropy via the Hamilton-Jacobi tunneling formalism. Our analysis provides a refined statistical basis for the entropy of non-singular spacetimes and offers a quantitative analysis of the nature of the black hole end-state. These results reveal that singularity resolution is not merely a geometric modification but a profound thermodynamic event, with direct implications for the stability and ultimate fate of evaporating black holes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6b63\u5219\u9ed1\u6d1e\u7684\u70ed\u529b\u5b66\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u4e34\u754c\u4e0d\u7a33\u5b9a\u6027\u76f8\u53d8\uff0c\u5e76\u63a8\u5bfc\u4e86\u71b5\u7684\u91cf\u5b50\u4fee\u6b63\uff0c\u63ed\u793a\u4e86\u5947\u70b9\u6d88\u9664\u4e0d\u4ec5\u662f\u51e0\u4f55\u4fee\u6b63\uff0c\u66f4\u662f\u6df1\u523b\u7684\u70ed\u529b\u5b66\u4e8b\u4ef6\u3002", "motivation": "\u6b63\u5219\u9ed1\u6d1e\u4e3a\u89e3\u51b3\u6807\u51c6\u9ed1\u6d1e\u4e2d\u5fc3\u5947\u70b9\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u6846\u67b6\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u8fd9\u7c7b\u975e\u5947\u5f02\u65f6\u7a7a\u7684\u70ed\u529b\u5b66\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5947\u70b9\u6d88\u9664\u5982\u4f55\u5f71\u54cd\u9ed1\u6d1e\u7684\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u547d\u8fd0\u3002", "method": "\u4f7f\u7528Simpson-Visser\u7684\"black-bounce\"\u51e0\u4f55\u4f5c\u4e3a\u5206\u6790\u53ef\u5904\u7406\u7684\u6846\u67b6\uff0c\u7814\u7a76\u6b63\u5219\u65f6\u7a7a\u7684\u70ed\u529b\u5b66\u884c\u4e3a\u3002\u901a\u8fc7\u70ed\u5bb9\u91cf\u5206\u6790\u8bc6\u522b\u76f8\u53d8\uff0c\u5e76\u5229\u7528Hamilton-Jacobi\u96a7\u7a7f\u5f62\u5f0f\u63a8\u5bfc\u71b5\u7684\u91cf\u5b50\u4fee\u6b63\u3002", "result": "\u53d1\u73b0\u6b63\u5219\u65f6\u7a7a\u5b58\u5728\u4e34\u754c\u4e0d\u7a33\u5b9a\u6027\uff0c\u8868\u73b0\u4e3a\u70ed\u5bb9\u91cf\u4e0d\u8fde\u7eed\u7684\u76f8\u53d8\uff0c\u6807\u5fd7\u7740\u9ed1\u6d1e\u84b8\u53d1\u72b6\u6001\u7684\u6839\u672c\u53d8\u5316\u3002\u63a8\u5bfc\u4e86\u71b5\u7684\u91cf\u5b50\u4fee\u6b63\uff0c\u4e3a\u975e\u5947\u5f02\u65f6\u7a7a\u7684\u71b5\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u7edf\u8ba1\u57fa\u7840\u3002", "conclusion": "\u5947\u70b9\u6d88\u9664\u4e0d\u4ec5\u662f\u51e0\u4f55\u4fee\u6b63\uff0c\u66f4\u662f\u6df1\u523b\u7684\u70ed\u529b\u5b66\u4e8b\u4ef6\uff0c\u76f4\u63a5\u5f71\u54cd\u84b8\u53d1\u9ed1\u6d1e\u7684\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u547d\u8fd0\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u9ed1\u6d1e\u672b\u6001\u63d0\u4f9b\u4e86\u5b9a\u91cf\u5206\u6790\u3002"}}
{"id": "2512.06343", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06343", "abs": "https://arxiv.org/abs/2512.06343", "authors": ["Tong Xie", "Andrew Bai", "Yuanhao Ban", "Yunqi Hong", "Haoyu Li", "Cho-jui Hsieh"], "title": "When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models", "comment": null, "summary": "Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86Bradley-Terry\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u95ee\u9898\uff0c\u53d1\u73b0\u5176\u53d7\u8868\u793a\u8ddd\u79bb\u5f71\u54cd\uff0c\u5bfc\u81f4\u5c0f\u8ddd\u79bb\u5bf9\u66f4\u65b0\u5f31\u3001\u5927\u8ddd\u79bb\u5bf9\u66f4\u65b0\u5f3a\uff0c\u63d0\u51fa\u4e86NormBT\u5f52\u4e00\u5316\u65b9\u6848\u6765\u5e73\u8861\u8fd9\u79cd\u6548\u5e94\u3002", "motivation": "\u6807\u51c6Bradley-Terry\u635f\u5931\u51fd\u6570\u5728\u5956\u52b1\u5efa\u6a21\u4e2d\u5b58\u5728\u68af\u5ea6\u95ee\u9898\uff1a\u68af\u5ea6\u8303\u6570\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u9884\u6d4b\u8bef\u5dee\uff08\u9009\u62e9\u7684\u4e0e\u62d2\u7edd\u7684\u54cd\u5e94\u4e4b\u95f4\u7684\u5956\u52b1\u5dee\uff09\uff0c\u8fd8\u53d7\u6700\u540e\u4e00\u5c42\u8868\u793a\u7a7a\u95f4\u4e2d\u8868\u793a\u8ddd\u79bb\u7684\u5f71\u54cd\u3002\u8fd9\u5bfc\u81f4\u5c0f\u8ddd\u79bb\u5bf9\u5373\u4f7f\u88ab\u9519\u8bef\u6392\u5e8f\u4e5f\u83b7\u5f97\u5f31\u66f4\u65b0\uff0c\u800c\u5927\u8ddd\u79bb\u5bf9\u83b7\u5f97\u8fc7\u5f3a\u66f4\u65b0\uff0c\u5f71\u54cd\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51faNormBT\u65b9\u6cd5\uff0c\u4e00\u79cd\u81ea\u9002\u5e94\u6210\u5bf9\u5f52\u4e00\u5316\u65b9\u6848\u3002\u901a\u8fc7\u5e73\u8861\u8868\u793a\u9a71\u52a8\u6548\u5e94\uff0c\u5c06\u5b66\u4e60\u4fe1\u53f7\u96c6\u4e2d\u5728\u9884\u6d4b\u8bef\u5dee\u4e0a\u3002NormBT\u662f\u8f7b\u91cf\u7ea7\u7684\uff0c\u53ef\u76f4\u63a5\u96c6\u6210\u5230BT\u635f\u5931\u4e2d\uff0c\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "result": "\u5728\u5404\u79cdLLM\u9aa8\u5e72\u7f51\u7edc\u548c\u6570\u636e\u96c6\u4e0a\uff0cNormBT\u6301\u7eed\u63d0\u5347\u5956\u52b1\u6a21\u578b\u6027\u80fd\u3002\u5728RewardBench\u7684\u63a8\u7406\u7c7b\u522b\u4e2d\uff08\u5305\u542b\u8bb8\u591a\u5c0f\u8ddd\u79bb\u5bf9\uff09\u83b7\u5f97\u4e86\u8d85\u8fc75%\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684BT\u76ee\u6807\u51fd\u6570\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u4fee\u6b63\u65b9\u6848\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u8868\u793a\u8ddd\u79bb\u6548\u5e94\u6765\u6539\u5584\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u3002"}}
{"id": "2512.06718", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.06718", "abs": "https://arxiv.org/abs/2512.06718", "authors": ["Zecheng Shen", "Shuhan Ding", "Zijun Zhao", "Francesco A. Evangelista", "Yao Wang"], "title": "Witnessing Spin-Orbital Entanglement using Resonant Inelastic X-Ray Scattering", "comment": "6 pages, 3 figures", "summary": "Entanglement plays a central role in quantum technologies, yet its characterization and control in materials remain challenging. Recent developments in spectrum-based entanglement witnesses have enabled new strategies for quantifying many-body entanglement in macroscopic materials. Here, we develop a protocol for detecting spin--orbital entanglement using experiment-accessible resonant inelastic x-ray scattering (RIXS). Central to our approach is the construction of a Hermitian generator from experimentally measurable spectra, which allows us to compute the quantum Fisher information (QFI) available in spin--orbital systems. The resulting QFI provides upper bounds for $k$-producible states and thus serves as a robust witness of spin--orbital entanglement. To account for realistic experimental limitations, we further extend our framework to include relaxed QFI bounds applicable to measurements lacking full polarization resolution.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u5171\u632f\u975e\u5f39\u6027X\u5c04\u7ebf\u6563\u5c04(RIXS)\u68c0\u6d4b\u81ea\u65cb-\u8f68\u9053\u7ea0\u7f20\u7684\u534f\u8bae\uff0c\u901a\u8fc7\u6784\u5efa\u5384\u7c73\u751f\u6210\u5143\u8ba1\u7b97\u91cf\u5b50\u8d39\u5e0c\u5c14\u4fe1\u606f(QFI)\uff0c\u4f5c\u4e3a\u81ea\u65cb-\u8f68\u9053\u7ea0\u7f20\u7684\u7a33\u5065\u89c1\u8bc1", "motivation": "\u7ea0\u7f20\u5728\u91cf\u5b50\u6280\u672f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u6750\u6599\u4e2d\u7684\u8868\u5f81\u548c\u63a7\u5236\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u5f00\u53d1\u5b9e\u9a8c\u53ef\u8bbf\u95ee\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u91cf\u5316\u81ea\u65cb-\u8f68\u9053\u7ea0\u7f20", "method": "\u5f00\u53d1\u57fa\u4e8eRIXS\u7684\u534f\u8bae\uff0c\u4ece\u5b9e\u9a8c\u53ef\u6d4b\u91cf\u7684\u5149\u8c31\u6784\u5efa\u5384\u7c73\u751f\u6210\u5143\uff0c\u8ba1\u7b97\u81ea\u65cb-\u8f68\u9053\u7cfb\u7edf\u7684\u91cf\u5b50\u8d39\u5e0c\u5c14\u4fe1\u606f(QFI)\uff0cQFI\u4e3ak-\u53ef\u4ea7\u751f\u6001\u63d0\u4f9b\u4e0a\u754c\uff0c\u4ece\u800c\u4f5c\u4e3a\u7ea0\u7f20\u89c1\u8bc1\u3002\u8fd8\u6269\u5c55\u6846\u67b6\u4ee5\u5904\u7406\u7f3a\u4e4f\u5b8c\u5168\u504f\u632f\u5206\u8fa8\u7387\u7684\u5b9e\u9a8c\u9650\u5236", "result": "\u5efa\u7acb\u4e86\u901a\u8fc7RIXS\u68c0\u6d4b\u81ea\u65cb-\u8f68\u9053\u7ea0\u7f20\u7684\u5b8c\u6574\u534f\u8bae\uff0cQFI\u63d0\u4f9b\u4e86\u7ea0\u7f20\u7684\u7a33\u5065\u89c1\u8bc1\uff0c\u5e76\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u5b9e\u9645\u5b9e\u9a8c\u9650\u5236\u7684\u677e\u5f1bQFI\u754c\u9650", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u6750\u6599\u4e2d\u5b9e\u9a8c\u8868\u5f81\u81ea\u65cb-\u8f68\u9053\u7ea0\u7f20\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u5c06\u8c31\u57fa\u7ea0\u7f20\u89c1\u8bc1\u6269\u5c55\u5230\u81ea\u65cb-\u8f68\u9053\u7cfb\u7edf\uff0c\u5e76\u8003\u8651\u4e86\u5b9e\u9645\u5b9e\u9a8c\u7ea6\u675f"}}
{"id": "2512.07791", "categories": ["gr-qc"], "pdf": "https://arxiv.org/pdf/2512.07791", "abs": "https://arxiv.org/abs/2512.07791", "authors": ["Miguel Cruz", "Samuel Lepe", "Joel Saavedra"], "title": "The holographic origin of future singularities and the role of spatial curvature in cosmic expansion", "comment": "9 pages, 1 figure", "summary": "In this work, we investigate the cosmological implications of holographic dark energy (HDE) when the infrared cutoff is defined through the Granda-Oliveros (GO) model and the entropy-area is generalized in the context of Kaniadakis statistics. For the GO model, we showed that a spatially flat universe inevitably evolves toward a big rip singularity. At the same time, the inclusion of spatial curvature modifies the expansion rate without removing the finite-time divergence: positive curvature speeds up the formation of the singularity, whereas negative curvature induces transitions between quintessence, de Sitter, and phantom-like regimes. When Kaniadakis entropy corrections are incorporated, the qualitative behavior changes substantially. The modified HDE density admits a stable de Sitter critical point and evolves toward a little rip singularity, in which the Hubble rate diverges only at infinite cosmic time. We further demonstrate that spatial curvature acts solely as a quantitative deformation in this scenario. Although it alters the detailed expansion history, it does not alter the little-rip character of the future singularity. Our results reveal that the asymptotic fate of holographic cosmologies is highly sensitive to the underlying entropy-area relation: the GO model robustly predicts a big rip. At the same time, its Kaniadakis deformation consistently softens the singularity into a little rip, even in curved universes.", "AI": {"tldr": "\u7814\u7a76\u5168\u606f\u6697\u80fd\u91cf\u5728Granda-Oliveros\u7ea2\u5916\u622a\u65ad\u548cKaniadakis\u71b5\u4fee\u6b63\u4e0b\u7684\u5b87\u5b99\u5b66\u5f71\u54cd\uff0c\u53d1\u73b0GO\u6a21\u578b\u5bfc\u81f4\u5927\u6495\u88c2\u5947\u70b9\uff0c\u800cKaniadakis\u4fee\u6b63\u5c06\u5176\u8f6f\u5316\u4e3a\u5c0f\u6495\u88c2\u5947\u70b9\u3002", "motivation": "\u63a2\u7d22\u5168\u606f\u6697\u80fd\u91cf\u5728\u4e0d\u540c\u7ea2\u5916\u622a\u65ad\u6a21\u578b\u548c\u71b5\u4fee\u6b63\u4e0b\u7684\u5b87\u5b99\u5b66\u884c\u4e3a\uff0c\u7279\u522b\u662f\u7814\u7a76\u7a7a\u95f4\u66f2\u7387\u548c\u71b5\u4fee\u6b63\u5982\u4f55\u5f71\u54cd\u5b87\u5b99\u7684\u6700\u7ec8\u547d\u8fd0\u548c\u5947\u70b9\u7c7b\u578b\u3002", "method": "\u91c7\u7528Granda-Oliveros\u6a21\u578b\u5b9a\u4e49\u7ea2\u5916\u622a\u65ad\uff0c\u5e76\u5f15\u5165Kaniadakis\u7edf\u8ba1\u4e2d\u7684\u5e7f\u4e49\u71b5-\u9762\u79ef\u5173\u7cfb\uff0c\u5206\u6790\u5e73\u76f4\u548c\u5f2f\u66f2\u5b87\u5b99\u4e2d\u7684\u5168\u606f\u6697\u80fd\u91cf\u6f14\u5316\u3002", "result": "GO\u6a21\u578b\u4e0b\u5e73\u76f4\u5b87\u5b99\u5fc5\u7136\u6f14\u5316\u81f3\u5927\u6495\u88c2\u5947\u70b9\uff1b\u6b63\u66f2\u7387\u52a0\u901f\u5947\u70b9\u5f62\u6210\uff0c\u8d1f\u66f2\u7387\u5f15\u8d77\u72b6\u6001\u8f6c\u53d8\u3002Kaniadakis\u4fee\u6b63\u540e\u51fa\u73b0\u7a33\u5b9ade Sitter\u4e34\u754c\u70b9\u5e76\u6f14\u5316\u81f3\u5c0f\u6495\u88c2\u5947\u70b9\uff0c\u7a7a\u95f4\u66f2\u7387\u4ec5\u5b9a\u91cf\u5f71\u54cd\u800c\u4e0d\u6539\u53d8\u5947\u70b9\u7c7b\u578b\u3002", "conclusion": "\u5168\u606f\u5b87\u5b99\u5b66\u7684\u6e10\u8fd1\u547d\u8fd0\u5bf9\u71b5-\u9762\u79ef\u5173\u7cfb\u9ad8\u5ea6\u654f\u611f\uff1aGO\u6a21\u578b\u9884\u6d4b\u5927\u6495\u88c2\u5947\u70b9\uff0c\u800cKaniadakis\u4fee\u6b63\u5c06\u5176\u8f6f\u5316\u4e3a\u5c0f\u6495\u88c2\u5947\u70b9\uff0c\u5373\u4f7f\u5728\u5f2f\u66f2\u5b87\u5b99\u4e2d\u4e5f\u662f\u5982\u6b64\u3002"}}
{"id": "2512.06347", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.06347", "abs": "https://arxiv.org/abs/2512.06347", "authors": ["Naoki Yoshida", "Isao Ishikawa", "Masaaki Imaizumi"], "title": "Zero Generalization Error Theorem for Random Interpolators via Algebraic Geometry", "comment": null, "summary": "We theoretically demonstrate that the generalization error of interpolators for machine learning models under teacher-student settings becomes 0 once the number of training samples exceeds a certain threshold. Understanding the high generalization ability of large-scale models such as deep neural networks (DNNs) remains one of the central open problems in machine learning theory. While recent theoretical studies have attributed this phenomenon to the implicit bias of stochastic gradient descent (SGD) toward well-generalizing solutions, empirical evidences indicate that it primarily stems from properties of the model itself. Specifically, even randomly sampled interpolators, which are parameters that achieve zero training error, have been observed to generalize effectively. In this study, under a teacher-student framework, we prove that the generalization error of randomly sampled interpolators becomes exactly zero once the number of training samples exceeds a threshold determined by the geometric structure of the interpolator set in parameter space. As a proof technique, we leverage tools from algebraic geometry to mathematically characterize this geometric structure.", "AI": {"tldr": "\u5728\u5e08\u751f\u6846\u67b6\u4e0b\uff0c\u968f\u673a\u91c7\u6837\u63d2\u503c\u5668\u7684\u6cdb\u5316\u8bef\u5dee\u5728\u8bad\u7ec3\u6837\u672c\u8d85\u8fc7\u9608\u503c\u540e\u4f1a\u53d8\u4e3a\u96f6\uff0c\u8be5\u9608\u503c\u7531\u53c2\u6570\u7a7a\u95f4\u4e2d\u63d2\u503c\u5668\u96c6\u5408\u7684\u51e0\u4f55\u7ed3\u6784\u51b3\u5b9a\u3002", "motivation": "\u7406\u89e3\u5927\u89c4\u6a21\u6a21\u578b\uff08\u5982\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09\u7684\u9ad8\u6cdb\u5316\u80fd\u529b\u662f\u673a\u5668\u5b66\u4e60\u7406\u8bba\u7684\u6838\u5fc3\u5f00\u653e\u95ee\u9898\u3002\u867d\u7136\u73b0\u6709\u7406\u8bba\u5c06\u8fd9\u79cd\u73b0\u8c61\u5f52\u56e0\u4e8eSGD\u5411\u826f\u597d\u6cdb\u5316\u89e3\u7684\u9690\u5f0f\u504f\u7f6e\uff0c\u4f46\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\u8fd9\u4e3b\u8981\u6e90\u4e8e\u6a21\u578b\u672c\u8eab\u7684\u6027\u8d28\u2014\u2014\u5373\u4f7f\u662f\u968f\u673a\u91c7\u6837\u7684\u63d2\u503c\u5668\uff08\u8fbe\u5230\u96f6\u8bad\u7ec3\u8bef\u5dee\u7684\u53c2\u6570\uff09\u4e5f\u80fd\u6709\u6548\u6cdb\u5316\u3002", "method": "\u5728\u5e08\u751f\u6846\u67b6\u4e0b\uff0c\u4f7f\u7528\u4ee3\u6570\u51e0\u4f55\u5de5\u5177\u6570\u5b66\u523b\u753b\u63d2\u503c\u5668\u96c6\u5408\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u8bc1\u660e\u968f\u673a\u91c7\u6837\u63d2\u503c\u5668\u7684\u6cdb\u5316\u8bef\u5dee\u5728\u8bad\u7ec3\u6837\u672c\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\u540e\u4f1a\u53d8\u4e3a\u96f6\u3002", "result": "\u8bc1\u660e\u4e86\u968f\u673a\u91c7\u6837\u63d2\u503c\u5668\u7684\u6cdb\u5316\u8bef\u5dee\u5728\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u8d85\u8fc7\u7531\u63d2\u503c\u5668\u96c6\u5408\u51e0\u4f55\u7ed3\u6784\u51b3\u5b9a\u7684\u9608\u503c\u540e\u4f1a\u7cbe\u786e\u53d8\u4e3a\u96f6\u3002", "conclusion": "\u6a21\u578b\u672c\u8eab\u7684\u6027\u8d28\uff08\u800c\u975e\u4f18\u5316\u7b97\u6cd5\uff09\u662f\u5bfc\u81f4\u9ad8\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u56e0\u7d20\uff0c\u968f\u673a\u63d2\u503c\u5668\u5728\u8db3\u591f\u6837\u672c\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u5b8c\u7f8e\u6cdb\u5316\uff0c\u8fd9\u4e3a\u7406\u89e3\u5927\u89c4\u6a21\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002"}}
{"id": "2512.06739", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06739", "abs": "https://arxiv.org/abs/2512.06739", "authors": ["Zhichao Dong", "Xiaolin Zhou", "Yongkang Chen", "Wei Ni", "Ekram Hossain", "Xin Wang"], "title": "Non-Orthogonal Multiple-Access for Coherent-State Optical Quantum Communications Under Lossy Photon Channels", "comment": null, "summary": "Coherent states have been increasingly considered in optical quantum communications (OQCs). With the inherent non-orthogonality of coherent states, non-orthogonal multiple-access (NOMA) naturally lends itself to the implementation of multi-user OQC. However, this remains unexplored in the literature. This paper proposes a novel successive interference cancellation (SIC)-based Kennedy receiver for uplink NOMA-OQC systems, along with a new approach for power allocation of the coherent states emitted by users. The key idea is to rigorously derive the asymptotic sum-rate of the considered systems, taking into account the impact of atmospheric turbulence, background noise, and lossy photon channel. With the asymptotic sum-rate, we optimize the average number of photons (or powers) of the coherent states emitted by the users. Variable substitution and successive convex approximation (SCA) are employed to convexify and maximize the asymptotic sum-rate iteratively. A new coherent-state power allocation algorithm is developed for a small-to-medium number of users. We further develop its low-complexity variant using adaptive importance sampling, which is suitable for scenarios with a medium-to-large number of users. Simulations demonstrate that our algorithms significantly enhance the sum-rate of uplink NOMA-OQC systems using coherent states by over 20\\%, compared to their alternatives.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSIC\u7684Kennedy\u63a5\u6536\u673a\u548c\u65b0\u7684\u529f\u7387\u5206\u914d\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347NOMA-OQC\u7cfb\u7edf\u6027\u80fd", "motivation": "\u76f8\u5e72\u6001\u5728\u5149\u91cf\u5b50\u901a\u4fe1\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u975e\u6b63\u4ea4\u7279\u6027\u5728NOMA\u591a\u7528\u6237\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u63a2\u7d22", "method": "\u63d0\u51faSIC-based Kennedy\u63a5\u6536\u673a\uff0c\u63a8\u5bfc\u6e10\u8fd1\u548c\u901f\u7387\uff0c\u8003\u8651\u5927\u6c14\u6e4d\u6d41\u3001\u80cc\u666f\u566a\u58f0\u548c\u5149\u5b50\u4fe1\u9053\u635f\u8017\uff0c\u4f7f\u7528\u53d8\u91cf\u66ff\u6362\u548cSCA\u4f18\u5316\u529f\u7387\u5206\u914d", "result": "\u7b97\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u63d0\u5347NOMA-OQC\u7cfb\u7edf\u548c\u901f\u7387\u8d85\u8fc720%\uff0c\u9002\u7528\u4e8e\u4e2d\u5c0f\u7528\u6237\u6570\u548c\u5927\u7528\u6237\u6570\u573a\u666f", "conclusion": "\u6210\u529f\u5c06\u76f8\u5e72\u6001\u7684\u975e\u6b63\u4ea4\u7279\u6027\u5e94\u7528\u4e8eNOMA-OQC\u7cfb\u7edf\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u591a\u7528\u6237\u5149\u91cf\u5b50\u901a\u4fe1\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.07812", "categories": ["gr-qc", "math-ph", "math.AP", "math.DG"], "pdf": "https://arxiv.org/pdf/2512.07812", "abs": "https://arxiv.org/abs/2512.07812", "authors": ["David Bick"], "title": "Caustics in the spherically symmetric Einstein-dust system", "comment": "66 pages, 14 figures", "summary": "Caustics-envelopes formed by the trajectories of fluid particles-arise in proposed dynamical extensions for shell-crossing singularities occurring in the Einstein-dust system. In this study, a local existence result is established, describing the dynamics in a neighbourhood of such caustics. Specifically, we obtain spherically symmetric spacetimes $(M,g_{\u03bc\u03bd})$ containing a caustic $\\mathcal{C}$, which, in the quotient $M/SO(3)$, is a timelike curve forming a singular boundary between a 2-dust region and a vacuum region. The spacetimes are constructed from solutions to a PDE problem posed with a spacelike direction of evolution. Curvature invariants and energy densities diverge as the caustic is approached. Consequently the metric has limited regularity $g\\in C^{1,1/2}$ and is shown to satisfy Einstein's equation weakly. On the complement of the caustic, the metric is smooth and satisfies Einstein's equation classically. A (degenerate) coordinate system is identified in which the dynamical variables are smooth with extension to the caustic. Finally, a novel family of static, spherically symmetric spacetimes is identified, complementing the local construction above. Each spacetime contains an eternal annular 2-dust region bounded by a pair of caustics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7231\u56e0\u65af\u5766-\u5c18\u57c3\u7cfb\u7edf\u4e2d\u58f3\u4ea4\u53c9\u5947\u70b9\u9644\u8fd1\u7684\u52a8\u529b\u5b66\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u7126\u6563\u7ebf\u7684\u5c40\u90e8\u5b58\u5728\u6027\u7ed3\u679c\uff0c\u6784\u9020\u4e86\u7403\u5bf9\u79f0\u65f6\u7a7a\uff0c\u5176\u4e2d\u7126\u6563\u7ebf\u4f5c\u4e3a2-\u5c18\u57c3\u533a\u57df\u4e0e\u771f\u7a7a\u533a\u57df\u7684\u5947\u5f02\u8fb9\u754c\u3002", "motivation": "\u7814\u7a76\u7231\u56e0\u65af\u5766-\u5c18\u57c3\u7cfb\u7edf\u4e2d\u58f3\u4ea4\u53c9\u5947\u70b9\uff08\u7126\u6563\u7ebf\uff09\u9644\u8fd1\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u8fd9\u4e9b\u7126\u6563\u7ebf\u5728\u6d41\u4f53\u7c92\u5b50\u8f68\u8ff9\u4e2d\u5f62\u6210\uff0c\u662f\u7406\u89e3\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u5947\u5f02\u7ed3\u6784\u7684\u91cd\u8981\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6c42\u89e3\u5177\u6709\u7c7b\u7a7a\u6f14\u5316\u65b9\u5411\u7684PDE\u95ee\u9898\uff0c\u6784\u9020\u5305\u542b\u7126\u6563\u7ebf\u7684\u7403\u5bf9\u79f0\u65f6\u7a7a\uff0c\u8bc1\u660e\u5ea6\u89c4\u5177\u6709\u6709\u9650\u6b63\u5219\u6027\uff08C^{1,1/2}\uff09\uff0c\u5e76\u6ee1\u8db3\u5f31\u5f62\u5f0f\u7684\u7231\u56e0\u65af\u5766\u65b9\u7a0b\u3002", "result": "\u5efa\u7acb\u4e86\u7126\u6563\u7ebf\u9644\u8fd1\u7684\u5c40\u90e8\u5b58\u5728\u6027\u5b9a\u7406\uff0c\u6784\u9020\u4e86\u7403\u5bf9\u79f0\u65f6\u7a7a\uff0c\u5176\u4e2d\u7126\u6563\u7ebf\u662f2-\u5c18\u57c3\u533a\u57df\u4e0e\u771f\u7a7a\u533a\u57df\u7684\u5947\u5f02\u8fb9\u754c\uff1b\u66f2\u7387\u4e0d\u53d8\u91cf\u548c\u80fd\u91cf\u5bc6\u5ea6\u5728\u63a5\u8fd1\u7126\u6563\u7ebf\u65f6\u53d1\u6563\uff1b\u5ea6\u89c4\u6ee1\u8db3\u5f31\u7231\u56e0\u65af\u5766\u65b9\u7a0b\uff1b\u8bc6\u522b\u4e86\u65b0\u7684\u9759\u6001\u7403\u5bf9\u79f0\u65f6\u7a7a\u65cf\u3002", "conclusion": "\u6210\u529f\u63cf\u8ff0\u4e86\u7231\u56e0\u65af\u5766-\u5c18\u57c3\u7cfb\u7edf\u4e2d\u7126\u6563\u7ebf\u9644\u8fd1\u7684\u52a8\u529b\u5b66\uff0c\u5efa\u7acb\u4e86\u5c40\u90e8\u5b58\u5728\u6027\u7ed3\u679c\uff0c\u6784\u9020\u4e86\u5177\u6709\u6709\u9650\u6b63\u5219\u6027\u7684\u5ea6\u89c4\u89e3\uff0c\u5e76\u53d1\u73b0\u4e86\u65b0\u7684\u9759\u6001\u65f6\u7a7a\u65cf\uff0c\u4e3a\u7406\u89e3\u58f3\u4ea4\u53c9\u5947\u70b9\u63d0\u4f9b\u4e86\u6570\u5b66\u6846\u67b6\u3002"}}
{"id": "2512.06351", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06351", "abs": "https://arxiv.org/abs/2512.06351", "authors": ["Zhiying Yang", "Fang Liu", "Wei Zhang", "Xin Lou", "Malcolm Yoke Hean Low", "Boon Ping Gan"], "title": "LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing", "comment": null, "summary": "This paper presents \\textsc{Luca}, a \\underline{l}arge language model (LLM)-\\underline{u}pgraded graph reinforcement learning framework for \\underline{c}arbon-\\underline{a}ware flexible job shop scheduling. \\textsc{Luca} addresses the challenges of dynamic and sustainable scheduling in smart manufacturing systems by integrating a graph neural network and an LLM, guided by a carefully designed in-house prompting strategy, to produce a fused embedding that captures both structural characteristics and contextual semantics of the latest scheduling state. This expressive embedding is then processed by a deep reinforcement learning policy network, which generates real-time scheduling decisions optimized for both makespan and carbon emission objectives. To support sustainability goals, \\textsc{Luca} incorporates a dual-objective reward function that encourages both energy efficiency and scheduling timeliness. Experimental results on both synthetic and public datasets demonstrate that \\textsc{Luca} consistently outperforms comparison algorithms. For instance, on the synthetic dataset, it achieves an average of 4.1\\% and up to 12.2\\% lower makespan compared to the best-performing comparison algorithm while maintaining the same emission level. On public datasets, additional gains are observed for both makespan and emission. These results demonstrate that \\textsc{Luca} is effective and practical for carbon-aware scheduling in smart manufacturing.", "AI": {"tldr": "LUCA\u662f\u4e00\u4e2a\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u78b3\u611f\u77e5\u67d4\u6027\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\uff0c\u5728\u4fdd\u6301\u76f8\u540c\u6392\u653e\u6c34\u5e73\u4e0b\u663e\u8457\u964d\u4f4e\u5236\u9020\u5468\u671f", "motivation": "\u89e3\u51b3\u667a\u80fd\u5236\u9020\u7cfb\u7edf\u4e2d\u52a8\u6001\u548c\u53ef\u6301\u7eed\u8c03\u5ea6\u7684\u6311\u6218\uff0c\u9700\u8981\u540c\u65f6\u4f18\u5316\u5236\u9020\u5468\u671f\u548c\u78b3\u6392\u653e\u76ee\u6807", "method": "\u96c6\u6210\u56fe\u795e\u7ecf\u7f51\u7edc\u548cLLM\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7b56\u7565\u751f\u6210\u878d\u5408\u5d4c\u5165\uff0c\u6355\u6349\u8c03\u5ea6\u72b6\u6001\u7684\u7ed3\u6784\u7279\u5f81\u548c\u4e0a\u4e0b\u6587\u8bed\u4e49\uff0c\u7136\u540e\u7531\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7f51\u7edc\u751f\u6210\u5b9e\u65f6\u8c03\u5ea6\u51b3\u7b56", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u964d\u4f4e4.1%\uff0c\u6700\u9ad8\u964d\u4f4e12.2%\u7684\u5236\u9020\u5468\u671f\uff08\u76f8\u540c\u6392\u653e\u6c34\u5e73\uff09\uff1b\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u5bf9\u5236\u9020\u5468\u671f\u548c\u6392\u653e\u90fd\u6709\u989d\u5916\u589e\u76ca", "conclusion": "LUCA\u5728\u667a\u80fd\u5236\u9020\u78b3\u611f\u77e5\u8c03\u5ea6\u4e2d\u65e2\u6709\u6548\u53c8\u5b9e\u7528\uff0c\u80fd\u591f\u540c\u65f6\u4f18\u5316\u80fd\u6e90\u6548\u7387\u548c\u8c03\u5ea6\u53ca\u65f6\u6027"}}
{"id": "2512.06748", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06748", "abs": "https://arxiv.org/abs/2512.06748", "authors": ["Zhichao Dong", "Xiaolin Zhou", "Huang Peng", "Wei Ni", "Ekram Hossain", "Xin Wang"], "title": "Non-Orthogonal Multiple Access-Based Continuous-Variable Quantum Key Distribution: Secret Key Rate Analysis and Power Allocation", "comment": null, "summary": "We address the multi-user quantum key distribution (QKD) problem under malicious quantum attacks, which is critical for realizing a large-scale quantum Internet. This paper maximizes the sum secret key rate (SKR) of a novel uplink non-orthogonal multiple access based continuous-variable QKD (NOMA-CVQKD) system under collective attacks. The proposed system uses Gaussian-modulated coherent states and a quantum successive interference cancellation based heterodyne receiver. We derive closed-form asymptotic bounds for the legitimate users' achievable key rates via the entropy power inequality and maximum entropy principle, as well as for the eavesdropper's intercepted information based on Holevo information. A successive convex approximation based power allocation algorithm is developed to maximize the asymptotic sum SKR of the NOMA-CVQKD system under collective attacks, with guaranteed convergence to a locally optimal Karush-Kuhn-Tucker solution. Simulation results show that the proposed NOMA-CVQKD system with the power allocation algorithm achieves up to 23% higher sum SKR than quantum-orthogonal multiple access, supports 16 users at excess noise variance 0.1, and remains robust under varying turbulence intensities and transmission distances.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165\u7684\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7cfb\u7edf\uff0c\u901a\u8fc7\u529f\u7387\u5206\u914d\u7b97\u6cd5\u5728\u6076\u610f\u91cf\u5b50\u653b\u51fb\u4e0b\u6700\u5927\u5316\u603b\u5bc6\u94a5\u7387\uff0c\u76f8\u6bd4\u6b63\u4ea4\u591a\u5740\u65b9\u6848\u63d0\u534723%\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u91cf\u5b50\u4e92\u8054\u7f51\u4e2d\u7684\u591a\u7528\u6237\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6076\u610f\u91cf\u5b50\u653b\u51fb\u4e0b\u5982\u4f55\u6700\u5927\u5316\u7cfb\u7edf\u603b\u5bc6\u94a5\u7387\uff0c\u8fd9\u662f\u5b9e\u73b0\u5927\u89c4\u6a21\u91cf\u5b50\u7f51\u7edc\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u9ad8\u65af\u8c03\u5236\u76f8\u5e72\u6001\u548c\u57fa\u4e8e\u91cf\u5b50\u8fde\u7eed\u5e72\u6270\u6d88\u9664\u7684\u5916\u5dee\u63a5\u6536\u5668\uff0c\u901a\u8fc7\u71b5\u529f\u7387\u4e0d\u7b49\u5f0f\u548c\u6700\u5927\u71b5\u539f\u7406\u63a8\u5bfc\u5408\u6cd5\u7528\u6237\u53ef\u8fbe\u5bc6\u94a5\u7387\u7684\u95ed\u5f0f\u6e10\u8fd1\u754c\uff0c\u57fa\u4e8eHolevo\u4fe1\u606f\u5206\u6790\u7a83\u542c\u8005\u622a\u83b7\u4fe1\u606f\uff0c\u5f00\u53d1\u57fa\u4e8e\u8fde\u7eed\u51f8\u8fd1\u4f3c\u7684\u529f\u7387\u5206\u914d\u7b97\u6cd5\u3002", "result": "\u6240\u63d0NOMA-CVQKD\u7cfb\u7edf\u5728\u96c6\u4f53\u653b\u51fb\u4e0b\u6bd4\u91cf\u5b50\u6b63\u4ea4\u591a\u5740\u65b9\u6848\u63d0\u534723%\u603b\u5bc6\u94a5\u7387\uff0c\u652f\u630116\u4e2a\u7528\u6237\u57280.1\u8fc7\u91cf\u566a\u58f0\u65b9\u5dee\u4e0b\u5de5\u4f5c\uff0c\u5728\u4e0d\u540c\u6e4d\u6d41\u5f3a\u5ea6\u548c\u4f20\u8f93\u8ddd\u79bb\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684NOMA-CVQKD\u7cfb\u7edf\u4e0e\u529f\u7387\u5206\u914d\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u591a\u7528\u6237\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u91cf\u5b50\u4e92\u8054\u7f51\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07825", "categories": ["gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.07825", "abs": "https://arxiv.org/abs/2512.07825", "authors": ["Hamid R. Bakhtiarizadeh"], "title": "Novel thermodynamic inequality for charged and rotating AdS black holes", "comment": "12 pages, no figure, LaTex file", "summary": "We propose a new thermodynamic inequality for stationary and asymptotically Anti-de Sitter charged and rotating black holes, $ 4\u03c0J^2/(3MV)<1 $. This inequality is derived through an analysis of the roots of the identity which holds among the thermodynamic variables to avoid a naked singularity. We have analyzed the Kerr-AdS black hole and the asymptotically AdS uncharged and rotating black strings and find strong supporting evidence for different horizon topologies. Using this inequality we verify the validity of reverse isoperimetric inequality in its conventional form ($ {\\cal R}\\geq 1 $) in the presence of rotation. By examining a wide range of black hole solutions, we confirm the validity of the proposed inequality. Assuming that reverse isoperimetric inequality continues to hold in higher dimensions, and employing the intermediate refined reverse isoperimetric inequalities introduced in [\\href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.241401}{Phys. Rev. Lett. {\\bf 131}, 241401}] as guiding principles, we extend the inequality to higher-dimensional spacetimes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u70ed\u529b\u5b66\u4e0d\u7b49\u5f0f $4\u03c0J^2/(3MV)<1$\uff0c\u9002\u7528\u4e8e\u7a33\u6001\u6e10\u8fd1AdS\u5e26\u7535\u65cb\u8f6c\u9ed1\u6d1e\uff0c\u901a\u8fc7\u5206\u6790\u70ed\u529b\u5b66\u53d8\u91cf\u5173\u7cfb\u907f\u514d\u88f8\u5947\u70b9\uff0c\u9a8c\u8bc1\u4e86\u4f20\u7edf\u5f62\u5f0f($\\mathcal{R}\\geq 1$)\u7684\u53cd\u7b49\u5468\u4e0d\u7b49\u5f0f\u5728\u65cb\u8f6c\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u7a33\u6001\u6e10\u8fd1AdS\u5e26\u7535\u65cb\u8f6c\u9ed1\u6d1e\u7684\u70ed\u529b\u5b66\u6027\u8d28\uff0c\u5efa\u7acb\u907f\u514d\u88f8\u5947\u70b9\u7684\u70ed\u529b\u5b66\u7ea6\u675f\u6761\u4ef6\uff0c\u9a8c\u8bc1\u53cd\u7b49\u5468\u4e0d\u7b49\u5f0f\u5728\u65cb\u8f6c\u9ed1\u6d1e\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u70ed\u529b\u5b66\u53d8\u91cf\u4e4b\u95f4\u7684\u6052\u7b49\u5f0f\u6839\u6765\u63a8\u5bfc\u4e0d\u7b49\u5f0f\uff0c\u68c0\u9a8cKerr-AdS\u9ed1\u6d1e\u548c\u6e10\u8fd1AdS\u4e0d\u5e26\u7535\u65cb\u8f6c\u9ed1\u6d1e\u5f26\uff0c\u7814\u7a76\u4e0d\u540c\u89c6\u754c\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u4e2d\u95f4\u7cbe\u5316\u53cd\u7b49\u5468\u4e0d\u7b49\u5f0f\u5c06\u7ed3\u679c\u63a8\u5e7f\u5230\u9ad8\u7ef4\u65f6\u7a7a\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u70ed\u529b\u5b66\u4e0d\u7b49\u5f0f $4\u03c0J^2/(3MV)<1$\uff0c\u9a8c\u8bc1\u4e86\u8be5\u4e0d\u7b49\u5f0f\u5728\u591a\u79cd\u9ed1\u6d1e\u89e3\u4e2d\u7684\u6709\u6548\u6027\uff0c\u786e\u8ba4\u4e86\u4f20\u7edf\u5f62\u5f0f\u53cd\u7b49\u5468\u4e0d\u7b49\u5f0f($\\mathcal{R}\\geq 1$)\u5728\u65cb\u8f6c\u60c5\u51b5\u4e0b\u7684\u6b63\u786e\u6027\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u9ad8\u7ef4\u65f6\u7a7a\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u9002\u7528\u4e8e\u7a33\u6001\u6e10\u8fd1AdS\u5e26\u7535\u65cb\u8f6c\u9ed1\u6d1e\u7684\u65b0\u70ed\u529b\u5b66\u4e0d\u7b49\u5f0f\uff0c\u4e3a\u9ed1\u6d1e\u70ed\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u652f\u6301\u4e86\u53cd\u7b49\u5468\u4e0d\u7b49\u5f0f\u5728\u66f4\u5e7f\u6cdb\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c06\u7ed3\u679c\u63a8\u5e7f\u5230\u9ad8\u7ef4\u60c5\u51b5\u3002"}}
{"id": "2512.06356", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.06356", "abs": "https://arxiv.org/abs/2512.06356", "authors": ["Yifan Song", "Fenglin Yu", "Yihong Luo", "Xingjian Tao", "Siya Qiu", "Kai Han", "Jing Tang"], "title": "DDFI: Diverse and Distribution-aware Missing Feature Imputation via Two-step Reconstruction", "comment": null, "summary": "Incomplete node features are ubiquitous in real-world scenarios, e.g., the attributes of web users may be partly private, which causes the performance of Graph Neural Networks (GNNs) to decline significantly. Feature propagation (FP) is a well-known method that performs well for imputation of missing node features on graphs, but it still has the following three issues: 1) it struggles with graphs that are not fully connected, 2) imputed features face the over-smoothing problem, and 3) FP is tailored for transductive tasks, overlooking the feature distribution shift in inductive tasks. To address these challenges, we introduce DDFI, a Diverse and Distribution-aware Missing Feature Imputation method that combines feature propagation with a graph-based Masked AutoEncoder (MAE) in a nontrivial manner. It first designs a simple yet effective algorithm, namely Co-Label Linking (CLL), that randomly connects nodes in the training set with the same label to enhance the performance on graphs with numerous connected components. Then we develop a novel two-step representation generation process at the inference stage. Specifically, instead of directly using FP-imputed features as input during inference, DDFI further reconstructs the features through the whole MAE to reduce feature distribution shift in the inductive tasks and enhance the diversity of node features. Meanwhile, since existing feature imputation methods for graphs only evaluate by simulating the missing scenes with manually masking the features, we collect a new dataset called Sailing from the records of voyages that contains naturally missing features to help better evaluate the effectiveness. Extensive experiments conducted on six public datasets and Sailing show that DDFI outperforms the state-of-the-art methods under both transductive and inductive settings.", "AI": {"tldr": "DDFI\uff1a\u4e00\u79cd\u7ed3\u5408\u7279\u5f81\u4f20\u64ad\u548c\u56fe\u63a9\u7801\u81ea\u7f16\u7801\u5668\u7684\u591a\u6837\u5316\u3001\u5206\u5e03\u611f\u77e5\u7f3a\u5931\u7279\u5f81\u586b\u8865\u65b9\u6cd5\uff0c\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u8282\u70b9\u7279\u5f81\u4e0d\u5b8c\u6574\u95ee\u9898", "motivation": "\u73b0\u5b9e\u4e16\u754c\u56fe\u4e2d\u8282\u70b9\u7279\u5f81\u666e\u904d\u4e0d\u5b8c\u6574\uff08\u5982\u7528\u6237\u9690\u79c1\u5c5e\u6027\uff09\uff0c\u5bfc\u81f4GNN\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u73b0\u6709\u7279\u5f81\u4f20\u64ad\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u95ee\u9898\uff1a1\uff09\u96be\u4ee5\u5904\u7406\u975e\u5168\u8fde\u63a5\u56fe\uff1b2\uff09\u586b\u8865\u7279\u5f81\u9762\u4e34\u8fc7\u5e73\u6ed1\u95ee\u9898\uff1b3\uff09\u4ec5\u9002\u7528\u4e8e\u76f4\u63a8\u5f0f\u4efb\u52a1\uff0c\u5ffd\u7565\u5f52\u7eb3\u5f0f\u4efb\u52a1\u4e2d\u7684\u7279\u5f81\u5206\u5e03\u504f\u79fb\u3002", "method": "\u63d0\u51faDDFI\u65b9\u6cd5\uff1a1\uff09\u8bbe\u8ba1CLL\u7b97\u6cd5\uff0c\u968f\u673a\u8fde\u63a5\u8bad\u7ec3\u96c6\u4e2d\u76f8\u540c\u6807\u7b7e\u7684\u8282\u70b9\u4ee5\u589e\u5f3a\u591a\u8fde\u901a\u5206\u91cf\u56fe\u7684\u6027\u80fd\uff1b2\uff09\u5728\u63a8\u7406\u9636\u6bb5\u91c7\u7528\u65b0\u9896\u7684\u4e24\u6b65\u8868\u793a\u751f\u6210\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6574\u4e2aMAE\u91cd\u6784\u7279\u5f81\u800c\u975e\u76f4\u63a5\u4f7f\u7528FP\u586b\u8865\u7279\u5f81\uff0c\u51cf\u5c11\u5f52\u7eb3\u4efb\u52a1\u4e2d\u7684\u7279\u5f81\u5206\u5e03\u504f\u79fb\u5e76\u589e\u5f3a\u7279\u5f81\u591a\u6837\u6027\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u65b0\u6536\u96c6\u7684Sailing\u6570\u636e\u96c6\uff08\u5305\u542b\u81ea\u7136\u7f3a\u5931\u7279\u5f81\u7684\u822a\u6d77\u8bb0\u5f55\uff09\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0cDDFI\u5728\u76f4\u63a8\u5f0f\u548c\u5f52\u7eb3\u5f0f\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "DDFI\u901a\u8fc7\u7ed3\u5408\u7279\u5f81\u4f20\u64ad\u548c\u56fe\u63a9\u7801\u81ea\u7f16\u7801\u5668\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7f3a\u5931\u7279\u5f81\u586b\u8865\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u548c\u6a21\u62df\u7f3a\u5931\u573a\u666f\u4e2d\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.06756", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2512.06756", "abs": "https://arxiv.org/abs/2512.06756", "authors": ["Abed Semre", "Steven Frankel"], "title": "Virtual Qudits for Simon's Problem: Dimension-Lifted Algorithms on Qubit Hardware", "comment": null, "summary": "Simon's problem admits an exponential quantum speedup, but current quantum devices support only qubits. This work introduces a general construction for simulating qudit versions of Simon's algorithm on qubit hardware by defining virtual qudits implemented through controlled permutations and qudit phase operations. We build a dimension lifted oracle that encodes the hidden shift in dimension d and show how to realize its action using only qubit gates. We mathematically verify that the lifted circuit reproduces the correct measurement statistics, analyze the depth overhead tradeoffs as a function of d, and provide numerical simulations in QuTiP for example values. Our approach demonstrates how higher-dimensional structures can be embedded into qubit devices and provides a general method for extending qudit algorithms to current hardware.", "AI": {"tldr": "\u5c06Simon\u95ee\u9898\u7684\u9ad8\u7ef4\u91cf\u5b50\u7b97\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u6bd4\u7279\u786c\u4ef6\u4e0a\uff0c\u901a\u8fc7\u865a\u62df\u91cf\u5b50\u6bd4\u7279\u5b9e\u73b0\u7ef4\u5ea6\u63d0\u5347\u7684oracle\uff0c\u5728\u73b0\u6709\u8bbe\u5907\u4e0a\u8fd0\u884c\u9ad8\u7ef4\u91cf\u5b50\u7b97\u6cd5\u3002", "motivation": "Simon\u95ee\u9898\u867d\u7136\u5b58\u5728\u6307\u6570\u7ea7\u91cf\u5b50\u52a0\u901f\uff0c\u4f46\u5f53\u524d\u91cf\u5b50\u8bbe\u5907\u4ec5\u652f\u6301\u91cf\u5b50\u6bd4\u7279\u3002\u4e3a\u4e86\u5728\u73b0\u6709\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u7ef4\u91cf\u5b50\u7b97\u6cd5\u7684\u4f18\u52bf\uff0c\u9700\u8981\u5c06\u91cf\u5b50\u6bd4\u7279\u7b97\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u6bd4\u7279\u786c\u4ef6\u4e0a\u3002", "method": "\u63d0\u51fa\u901a\u7528\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d7\u63a7\u7f6e\u6362\u548c\u91cf\u5b50\u6bd4\u7279\u76f8\u4f4d\u64cd\u4f5c\u5b9e\u73b0\u865a\u62df\u91cf\u5b50\u6bd4\u7279\uff0c\u6784\u5efa\u7ef4\u5ea6\u63d0\u5347\u7684oracle\u6765\u7f16\u7801\u9690\u85cf\u4f4d\u79fb\uff0c\u4ec5\u4f7f\u7528\u91cf\u5b50\u6bd4\u7279\u95e8\u5b9e\u73b0\u5176\u4f5c\u7528\u3002", "result": "\u6570\u5b66\u9a8c\u8bc1\u63d0\u5347\u540e\u7684\u7535\u8def\u80fd\u4ea7\u751f\u6b63\u786e\u7684\u6d4b\u91cf\u7edf\u8ba1\uff0c\u5206\u6790\u7ef4\u5ea6d\u4e0e\u6df1\u5ea6\u5f00\u9500\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7QuTiP\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u793a\u4f8b\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u9ad8\u7ef4\u7ed3\u6784\u5d4c\u5165\u91cf\u5b50\u6bd4\u7279\u8bbe\u5907\uff0c\u4e3a\u5c06\u91cf\u5b50\u6bd4\u7279\u7b97\u6cd5\u6269\u5c55\u5230\u5f53\u524d\u786c\u4ef6\u63d0\u4f9b\u901a\u7528\u65b9\u6cd5\uff0c\u5f25\u5408\u4e86\u7406\u8bba\u9ad8\u7ef4\u7b97\u6cd5\u4e0e\u5b9e\u9645\u786c\u4ef6\u9650\u5236\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.06357", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.06357", "abs": "https://arxiv.org/abs/2512.06357", "authors": ["Tony Sallooma", "Okyay Kaynak", "Xinbo Yub", "Wei He"], "title": "Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction", "comment": "Engineering Applications of Artificial Intelligence 2022", "summary": "Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional-integral-derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePID\u63a7\u5236\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u6b65\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u590d\u6742\u5ea6\u57fa\u672c\u4e0d\u53d8\u3002", "motivation": "\u591a\u6b65\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u5de5\u4e1a\u51b3\u7b56\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u7ed3\u6784\u590d\u6742\uff0c\u5f71\u54cd\u9884\u6d4b\u7cbe\u5ea6\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u5347\u6027\u80fd\u53c8\u4e0d\u663e\u8457\u589e\u52a0\u7cfb\u7edf\u590d\u6742\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u53d7PID\u63a7\u5236\u65b9\u6cd5\u542f\u53d1\uff0c\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u5bf9\u795e\u7ecf\u7f51\u7edc\u7684\u9884\u6d4b\u503c\u8fdb\u884cPID\u6821\u6b63\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u771f\u5b9e\u503c\u3002\u8be5\u65b9\u6cd5\u4f5c\u4e3a\"\u589e\u5f3a\u5668\"\u5e94\u7528\u4e8e\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e0a\u3002", "result": "\u5728\u6c34\u9700\u6c42\u9884\u6d4b\u548c\u5c0f\u65f6\u80fd\u8017\u9884\u6d4b\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u5e94\u7528PID\u589e\u5f3a\u65b9\u6cd5\u540e\u7684\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u539f\u59cb\u6a21\u578b\uff0c\u540c\u65f6\u7cfb\u7edf\u590d\u6742\u5ea6\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "PID\u589e\u5f3a\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u6b65\u5468\u671f\u6027\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u4e14\u4e0d\u663e\u8457\u589e\u52a0\u7cfb\u7edf\u590d\u6742\u5ea6\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2512.06760", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06760", "abs": "https://arxiv.org/abs/2512.06760", "authors": ["Y. Wei", "M. Artoni", "G. C. La Rocca", "J. H. Wu", "X. Q. Shao"], "title": "Enhancing ground-state interaction strength of neutral atoms via Floquet stroboscopic dynamics", "comment": "9 figures, 14 pages, comments are welcome", "summary": "Neutral atom systems are promising platforms for quantum simulation and computation, owing to their long coherence times. However, their intrinsically weak ground-state interactions pose a major limitation to the advancement of scalable quantum simulation and computation. To address this challenge, we propose an approach to enhancing the ground-state interaction strength of neutral atoms via Floquet modulation of a Rydberg atomic ensemble. Each Floquet period consists of ground-state coupling followed by a pulse driving the transition from the ground state to the Rydberg state. Theoretical analysis and numerical simulations demonstrate that after a defined evolution time, neutral atoms within Rydberg ensembles can collectively form a $W$ state in the ground-state manifold. Even when the Rydberg interaction strength is far below the blockade regime, the fidelity remains remarkably high. Finally, we analyze the application of this scheme in the preparation of single-photon sources. In general, our proposed mechanism offers an efficient and highly controllable method for quantum state preparation within the Rydberg atomic ensembles, significantly enhancing the accuracy and stability of quantum state engineering while providing a well-controlled quantum environment for single-photon generation.", "AI": {"tldr": "\u901a\u8fc7Floquet\u8c03\u5236\u589e\u5f3a\u4e2d\u6027\u539f\u5b50\u57fa\u6001\u76f8\u4e92\u4f5c\u7528\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6W\u6001\u5236\u5907\u548c\u5355\u5149\u5b50\u6e90\u5e94\u7528", "motivation": "\u4e2d\u6027\u539f\u5b50\u7cfb\u7edf\u5177\u6709\u957f\u76f8\u5e72\u65f6\u95f4\uff0c\u4f46\u57fa\u6001\u76f8\u4e92\u4f5c\u7528\u5f31\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u91cf\u5b50\u6a21\u62df\u548c\u8ba1\u7b97\u7684\u53d1\u5c55\u3002\u9700\u8981\u589e\u5f3a\u57fa\u6001\u76f8\u4e92\u4f5c\u7528\u5f3a\u5ea6\u3002", "method": "\u63d0\u51fa\u901a\u8fc7Floquet\u8c03\u5236\u91cc\u5fb7\u5821\u539f\u5b50\u7cfb\u7efc\u6765\u589e\u5f3a\u57fa\u6001\u76f8\u4e92\u4f5c\u7528\u3002\u6bcf\u4e2aFloquet\u5468\u671f\u5305\u542b\u57fa\u6001\u8026\u5408\u548c\u4ece\u57fa\u6001\u5230\u91cc\u5fb7\u5821\u6001\u7684\u8109\u51b2\u9a71\u52a8\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u8868\u660e\uff0c\u7ecf\u8fc7\u7279\u5b9a\u6f14\u5316\u65f6\u95f4\uff0c\u91cc\u5fb7\u5821\u7cfb\u7efc\u4e2d\u7684\u4e2d\u6027\u539f\u5b50\u53ef\u4ee5\u5728\u57fa\u6001\u6d41\u5f62\u4e2d\u96c6\u4f53\u5f62\u6210W\u6001\u3002\u5373\u4f7f\u5728\u91cc\u5fb7\u5821\u76f8\u4e92\u4f5c\u7528\u8fdc\u4f4e\u4e8e\u963b\u585e\u533a\u57df\u65f6\uff0c\u4fdd\u771f\u5ea6\u4ecd\u7136\u5f88\u9ad8\u3002", "conclusion": "\u8be5\u673a\u5236\u4e3a\u91cc\u5fb7\u5821\u539f\u5b50\u7cfb\u7efc\u4e2d\u7684\u91cf\u5b50\u6001\u5236\u5907\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u63a7\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u91cf\u5b50\u6001\u5de5\u7a0b\u7684\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5355\u5149\u5b50\u751f\u6210\u63d0\u4f9b\u4e86\u826f\u597d\u63a7\u5236\u7684\u91cf\u5b50\u73af\u5883\u3002"}}
{"id": "2512.06370", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.06370", "abs": "https://arxiv.org/abs/2512.06370", "authors": ["Jaerin Lee", "Kyoung Mu Lee"], "title": "Optimizing Optimizers for Fast Gradient-Based Learning", "comment": "49 pages, 5 figures", "summary": "We lay the theoretical foundation for automating optimizer design in gradient-based learning. Based on the greedy principle, we formulate the problem of designing optimizers as maximizing the instantaneous decrease in loss. By treating an optimizer as a function that translates loss gradient signals into parameter motions, the problem reduces to a family of convex optimization problems over the space of optimizers. Solving these problems under various constraints not only recovers a wide range of popular optimizers as closed-form solutions, but also produces the optimal hyperparameters of these optimizers with respect to the problems at hand. This enables a systematic approach to design optimizers and tune their hyperparameters according to the gradient statistics that are collected during the training process. Furthermore, this optimization of optimization can be performed dynamically during training.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u68af\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u5668\u81ea\u52a8\u5316\u8bbe\u8ba1\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u8d2a\u5a6a\u539f\u5219\u5c06\u4f18\u5316\u5668\u8bbe\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u6700\u5927\u5316\u635f\u5931\u77ac\u65f6\u4e0b\u964d\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u80fd\u591f\u63a8\u5bfc\u51fa\u591a\u79cd\u6d41\u884c\u4f18\u5316\u5668\u53ca\u5176\u6700\u4f18\u8d85\u53c2\u6570\u3002", "motivation": "\u5f53\u524d\u4f18\u5316\u5668\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u7406\u8bba\u57fa\u7840\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u81ea\u52a8\u5316\u4f18\u5316\u5668\u8bbe\u8ba1\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4f7f\u4f18\u5316\u5668\u8bbe\u8ba1\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u80fd\u591f\u57fa\u4e8e\u6570\u5b66\u539f\u7406\u800c\u975e\u7ecf\u9a8c\u3002", "method": "\u57fa\u4e8e\u8d2a\u5a6a\u539f\u5219\uff0c\u5c06\u4f18\u5316\u5668\u8bbe\u8ba1\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6700\u5927\u5316\u635f\u5931\u77ac\u65f6\u4e0b\u964d\u3002\u5c06\u4f18\u5316\u5668\u89c6\u4e3a\u5c06\u68af\u5ea6\u4fe1\u53f7\u6620\u5c04\u4e3a\u53c2\u6570\u66f4\u65b0\u7684\u51fd\u6570\uff0c\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u51f8\u4f18\u5316\u95ee\u9898\u3002\u5728\u4e0d\u540c\u7ea6\u675f\u6761\u4ef6\u4e0b\u6c42\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u4f18\u5316\u5668\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u6062\u590d\u591a\u79cd\u6d41\u884c\u4f18\u5316\u5668\uff08\u5982SGD\u3001Adam\u7b49\uff09\u4f5c\u4e3a\u95ed\u5f0f\u89e3\uff0c\u8fd8\u80fd\u81ea\u52a8\u63a8\u5bfc\u51fa\u9488\u5bf9\u5177\u4f53\u95ee\u9898\u7684\u6700\u4f18\u8d85\u53c2\u6570\u3002\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6536\u96c6\u7684\u68af\u5ea6\u7edf\u8ba1\u4fe1\u606f\u6765\u7cfb\u7edf\u5316\u8bbe\u8ba1\u4f18\u5316\u5668\u548c\u8c03\u4f18\u8d85\u53c2\u6570\u3002", "conclusion": "\u5efa\u7acb\u4e86\u81ea\u52a8\u5316\u4f18\u5316\u5668\u8bbe\u8ba1\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\"\u4f18\u5316\u7684\u4f18\u5316\"\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u4f18\u5316\u5668\u8bbe\u8ba1\uff0c\u4e3a\u68af\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u4f18\u5316\u5668\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2512.06775", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06775", "abs": "https://arxiv.org/abs/2512.06775", "authors": ["Han-Ze Li", "Ching Hua Lee", "Shuo Liu", "Shi-Xin Zhang", "Jian-Xin Zhong"], "title": "Quantum Mpemba effect in long-ranged U(1)-symmetric random circuits", "comment": null, "summary": "The Mpemba effect, where a state prepared farther from equilibrium relaxes faster to equilibrium than one prepared closer, has a quantum counterpart where relaxation is resolved by conserved charge. However, the fate of the quantum Mpemba effect in systems with long-range interactions remains an open question. Here, we study the quantum Mpemba effect in long-ranged, U(1)-symmetric random unitary circuits. Using annealed R\u00e9nyi-2 entanglement asymmetry computed via replica tensor networks and exact diagonalization, we track the symmetry restoration from three types of tilted product states: ferromagnetic, antiferromagnetic, and ferromagnetic with a central domain wall. The quantum Mpemba effect is present for tilted ferromagnetic states at all interaction ranges, but absent for tilted antiferromagnetic states, and occurs for the domain-wall state only in effectively short-ranged circuits, where the Mpemba time $t_{\\rm M}$ is found to scale with the subsystem size $N_A$ as $t_{\\rm M}\\!\\sim\\!N_{A}^{\\,z}$, with the dynamical exponent $z=\\min(\u03b1-1,2)$. These results reveal how the quantum Mpemba effect is governed by the interplay between interaction range and initial-state charge bias in long-ranged chaotic systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50Mpemba\u6548\u5e94\uff0c\u53d1\u73b0\u5728\u503e\u659c\u94c1\u78c1\u6001\u4e2d\u59cb\u7ec8\u5b58\u5728\u8be5\u6548\u5e94\uff0c\u800c\u5728\u503e\u659c\u53cd\u94c1\u78c1\u6001\u4e2d\u4e0d\u5b58\u5728\uff0c\u5bf9\u4e8e\u7574\u58c1\u6001\u4ec5\u5728\u6709\u6548\u77ed\u7a0b\u7535\u8def\u4e2d\u5b58\u5728\uff0c\u5e76\u63ed\u793a\u4e86\u76f8\u4e92\u4f5c\u7528\u8303\u56f4\u4e0e\u521d\u59cb\u6001\u7535\u8377\u504f\u7f6e\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u8c03\u63a7\u91cf\u5b50Mpemba\u6548\u5e94\u3002", "motivation": "\u91cf\u5b50Mpemba\u6548\u5e94\u5728\u5b88\u6052\u7535\u8377\u7cfb\u7edf\u4e2d\u5df2\u88ab\u89c2\u5bdf\u5230\uff0c\u4f46\u5728\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4e2d\u7684\u547d\u8fd0\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u5f71\u54cd\u91cf\u5b50Mpemba\u6548\u5e94\u7684\u5b58\u5728\u6027\u548c\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u957f\u7a0bU(1)\u5bf9\u79f0\u968f\u673a\u5e7a\u6b63\u7535\u8def\uff0c\u901a\u8fc7\u526f\u672c\u5f20\u91cf\u7f51\u7edc\u8ba1\u7b97\u9000\u706bR\u00e9nyi-2\u7ea0\u7f20\u4e0d\u5bf9\u79f0\u6027\uff0c\u5e76\u7ed3\u5408\u7cbe\u786e\u5bf9\u89d2\u5316\u65b9\u6cd5\uff0c\u8ffd\u8e2a\u4e09\u79cd\u503e\u659c\u4e58\u79ef\u6001\uff08\u94c1\u78c1\u3001\u53cd\u94c1\u78c1\u3001\u5e26\u4e2d\u5fc3\u7574\u58c1\u7684\u94c1\u78c1\u6001\uff09\u7684\u5bf9\u79f0\u6027\u6062\u590d\u8fc7\u7a0b\u3002", "result": "\u91cf\u5b50Mpemba\u6548\u5e94\u5728\u503e\u659c\u94c1\u78c1\u6001\u4e2d\u5b58\u5728\u4e8e\u6240\u6709\u76f8\u4e92\u4f5c\u7528\u8303\u56f4\uff0c\u5728\u503e\u659c\u53cd\u94c1\u78c1\u6001\u4e2d\u4e0d\u5b58\u5728\uff0c\u5728\u7574\u58c1\u6001\u4e2d\u4ec5\u5b58\u5728\u4e8e\u6709\u6548\u77ed\u7a0b\u7535\u8def\u4e2d\u3002\u5728\u6709\u6548\u77ed\u7a0b\u7535\u8def\u4e2d\uff0cMpemba\u65f6\u95f4t_M\u4e0e\u5b50\u7cfb\u7edf\u5c3a\u5bf8N_A\u7684\u6807\u5ea6\u5173\u7cfb\u4e3at_M\u223cN_A^z\uff0c\u5176\u4e2d\u52a8\u529b\u5b66\u6307\u6570z=min(\u03b1-1,2)\u3002", "conclusion": "\u91cf\u5b50Mpemba\u6548\u5e94\u5728\u957f\u7a0b\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u53d7\u5230\u76f8\u4e92\u4f5c\u7528\u8303\u56f4\u4e0e\u521d\u59cb\u6001\u7535\u8377\u504f\u7f6e\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u8c03\u63a7\uff0c\u63ed\u793a\u4e86\u8be5\u6548\u5e94\u5728\u4e0d\u540c\u521d\u59cb\u6001\u548c\u76f8\u4e92\u4f5c\u7528\u8303\u56f4\u4e0b\u7684\u4e0d\u540c\u8868\u73b0\u3002"}}
{"id": "2512.06392", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06392", "abs": "https://arxiv.org/abs/2512.06392", "authors": ["Runlong Zhou", "Lefan Zhang", "Shang-Chen Wu", "Kelvin Zou", "Hanzhi Zhou", "Ke Ye", "Yihao Feng", "Dong Yin", "Alex Guillen Garcia", "Dmytro Babych", "Rohit Chatterjee", "Matthew Hopkins", "Xiang Kong", "Chang Lan", "Lezhi Li", "Yiping Ma", "Daniele Molinari", "Senyu Tong", "Yanchao Sun", "Thomas Voice", "Jianyu Wang", "Chong Wang", "Simon Wang", "Floris Weers", "Yechen Xu", "Guolin Yin", "Muyang Yu", "Yi Zhang", "Zheng Zhou", "Danyang Zhuo", "Ruoming Pang", "Cheng Leong"], "title": "RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs", "comment": "14 pages, 6 figures", "summary": "Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.", "AI": {"tldr": "RLAX\u662f\u4e00\u4e2a\u5728TPU\u4e0a\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u53c2\u6570\u670d\u52a1\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u7cfb\u7edf\u4f18\u5316\u548c\u6570\u636e\u96c6\u6280\u672f\uff0c\u572812\u5c0f\u65f6\u5185\u5c06QwQ-32B\u7684pass@8\u51c6\u786e\u7387\u63d0\u534712.8%", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5df2\u6210\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u4e3b\u6d41\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u53ef\u6269\u5c55\u4e14\u80fd\u5904\u7406\u8bad\u7ec3\u4e2d\u65ad\u7684\u6846\u67b6\u6765\u52a0\u901f\u6536\u655b\u548c\u63d0\u9ad8\u6a21\u578b\u8d28\u91cf", "method": "\u91c7\u7528\u53c2\u6570\u670d\u52a1\u5668\u67b6\u6784\uff0c\u4e3b\u8bad\u7ec3\u5668\u5b9a\u671f\u63a8\u9001\u66f4\u65b0\u6743\u91cd\uff0c\u63a8\u7406\u5de5\u4f5c\u5668\u62c9\u53d6\u6700\u65b0\u6743\u91cd\u751f\u6210\u65b0\u6570\u636e\uff1b\u5f15\u5165\u7cfb\u7edf\u6280\u672f\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u53ef\u4e2d\u65ad\u7684RL\uff1b\u5f00\u53d1\u65b0\u7684\u6570\u636e\u96c6\u6574\u7406\u548c\u5bf9\u9f50\u6280\u672f", "result": "\u57281024\u4e2av5p TPU\u4e0a\uff0c\u4ec5\u752812\u5c0f\u65f648\u5206\u949f\u5c31\u5c06QwQ-32B\u7684pass@8\u51c6\u786e\u7387\u63d0\u534712.8%\uff0c\u540c\u65f6\u5728\u8bad\u7ec3\u4e2d\u65ad\u65f6\u4fdd\u6301\u9c81\u68d2\u6027", "conclusion": "RLAX\u662f\u4e00\u4e2a\u9ad8\u6548\u53ef\u6269\u5c55\u7684RL\u6846\u67b6\uff0c\u80fd\u663e\u8457\u52a0\u901fLLM\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u540c\u65f6\u5177\u5907\u5904\u7406\u8bad\u7ec3\u4e2d\u65ad\u7684\u9c81\u68d2\u6027"}}
{"id": "2512.06778", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06778", "abs": "https://arxiv.org/abs/2512.06778", "authors": ["Federico Dell'Anna", "Matteo Grotti", "Vito Giardinelli"], "title": "Maximum Independent Set via Probabilistic and Quantum Cellular Automata", "comment": "16 pages, 8 figures", "summary": "We study probabilistic cellular automata (PCA) and quantum cellular automata (QCA) as frameworks for solving the Maximum Independent Set (MIS) problem. We first introduce a synchronous PCA whose dynamics drives the system toward the manifold of maximal independent sets. Numerical evidence shows that the MIS convergence probability increases significantly as the activation probability p tends to 1, and we characterize how the steps required to reach the absorbing state scale with system size and graph connectivity. Motivated by this behavior, we construct a QCA combining a pure dissipative phase with a constraint-preserving unitary evolution that redistributes probability within this manifold. Tensor Network simulations reveal that repeated dissipative--unitary cycles concentrate population on MIS configurations. We also provide an empirical estimate of how the convergence time scales with graph size, suggesting that QCA dynamics can provide an efficient alternative to adiabatic and variational quantum optimization methods based exclusively on local and translationally invariant rules.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6982\u7387\u5143\u80de\u81ea\u52a8\u673a(PCA)\u548c\u91cf\u5b50\u5143\u80de\u81ea\u52a8\u673a(QCA)\u5728\u89e3\u51b3\u6700\u5927\u72ec\u7acb\u96c6(MIS)\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u6709\u6548\u6536\u655b\u5230MIS\u89e3\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u5c40\u90e8\u548c\u5e73\u79fb\u4e0d\u53d8\u89c4\u5219\u7684\u5143\u80de\u81ea\u52a8\u673a\u65b9\u6cd5\u6765\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u4f18\u5316\u63d0\u4f9b\u66ff\u4ee3\u65b9\u6848\u3002\u4f20\u7edf\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\u5982\u7edd\u70ed\u91cf\u5b50\u8ba1\u7b97\u548c\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u7684\u91cf\u5b50\u8ba1\u7b97\u8303\u5f0f\u3002", "method": "1. \u9996\u5148\u8bbe\u8ba1\u540c\u6b65PCA\uff0c\u5176\u52a8\u529b\u5b66\u9a71\u52a8\u7cfb\u7edf\u8d8b\u5411\u6700\u5927\u72ec\u7acb\u96c6\u6d41\u5f62\uff1b2. \u57fa\u4e8ePCA\u884c\u4e3a\u6784\u5efaQCA\uff0c\u7ed3\u5408\u7eaf\u8017\u6563\u76f8\u548c\u7ea6\u675f\u4fdd\u6301\u7684\u5e7a\u6b63\u6f14\u5316\uff0c\u5728\u6d41\u5f62\u5185\u91cd\u65b0\u5206\u5e03\u6982\u7387\uff1b3. \u4f7f\u7528\u5f20\u91cf\u7f51\u7edc\u6a21\u62df\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "1. PCA\u7684MIS\u6536\u655b\u6982\u7387\u968f\u6fc0\u6d3b\u6982\u7387p\u8d8b\u8fd11\u800c\u663e\u8457\u589e\u52a0\uff1b2. \u8868\u5f81\u4e86\u5230\u8fbe\u5438\u6536\u6001\u6240\u9700\u6b65\u6570\u4e0e\u7cfb\u7edf\u89c4\u6a21\u548c\u56fe\u8fde\u901a\u6027\u7684\u6807\u5ea6\u5173\u7cfb\uff1b3. QCA\u7684\u8017\u6563-\u5e7a\u6b63\u5faa\u73af\u80fd\u5c06\u6982\u7387\u96c6\u4e2d\u5728MIS\u6784\u578b\u4e0a\uff1b4. \u63d0\u4f9b\u4e86\u6536\u655b\u65f6\u95f4\u4e0e\u56fe\u5927\u5c0f\u7684\u7ecf\u9a8c\u4f30\u8ba1\u3002", "conclusion": "QCA\u52a8\u529b\u5b66\u4e3a\u57fa\u4e8e\u5c40\u90e8\u548c\u5e73\u79fb\u4e0d\u53d8\u89c4\u5219\u7684\u7edd\u70ed\u91cf\u5b50\u8ba1\u7b97\u548c\u53d8\u5206\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5143\u80de\u81ea\u52a8\u673a\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.06417", "categories": ["cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.06417", "abs": "https://arxiv.org/abs/2512.06417", "authors": ["Yifan Sun", "Lei Cheng", "Jianlong Li", "Peter Gerstoft"], "title": "Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator", "comment": null, "summary": "Fast and accurate underwater acoustic charting is crucial for downstream tasks such as environment-aware sensor placement optimization and autonomous vehicle path planning. Conventional methods rely on computationally expensive while accurate numerical solvers, which are not scalable for large-scale or real-time applications. Although deep learning-based surrogate models can accelerate these computations, they often suffer from limitations such as fixed-resolution constraints or dependence on explicit partial differential equation formulations. These issues hinder their applicability and generalization across diverse environments. We propose Hankel-FNO, a Fourier Neural Operator (FNO)-based model for efficient and accurate acoustic charting. By incorporating sound propagation knowledge and bathymetry, our method has high accuracy while maintaining high computational speed. Results demonstrate that Hankel-FNO outperforms traditional solvers in speed and surpasses data-driven alternatives in accuracy, especially in long-range predictions. Experiments show the model's adaptability to diverse environments and sound source settings with minimal fine-tuning.", "AI": {"tldr": "Hankel-FNO\uff1a\u57fa\u4e8e\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u7684\u9ad8\u6548\u6c34\u4e0b\u58f0\u5b66\u5236\u56fe\u65b9\u6cd5\uff0c\u7ed3\u5408\u58f0\u4f20\u64ad\u77e5\u8bc6\u548c\u5730\u5f62\u6570\u636e\uff0c\u5728\u4fdd\u6301\u9ad8\u8ba1\u7b97\u901f\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b", "motivation": "\u4f20\u7edf\u6c34\u4e0b\u58f0\u5b66\u5236\u56fe\u65b9\u6cd5\u4f9d\u8d56\u8ba1\u7b97\u6602\u8d35\u7684\u6570\u503c\u6c42\u89e3\u5668\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u6216\u5b9e\u65f6\u5e94\u7528\u9700\u6c42\u3002\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u5b58\u5728\u56fa\u5b9a\u5206\u8fa8\u7387\u9650\u5236\u6216\u4f9d\u8d56\u663e\u5f0f\u504f\u5fae\u5206\u65b9\u7a0b\u516c\u5f0f\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faHankel-FNO\u6a21\u578b\uff0c\u57fa\u4e8e\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNO\uff09\uff0c\u7ed3\u5408\u58f0\u4f20\u64ad\u77e5\u8bc6\u548c\u6c34\u6df1\u5730\u5f62\u6570\u636e\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u6c34\u4e0b\u58f0\u5b66\u5236\u56fe\u3002", "result": "Hankel-FNO\u5728\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6c42\u89e3\u5668\uff0c\u5728\u7cbe\u5ea6\u4e0a\u8d85\u8d8a\u6570\u636e\u9a71\u52a8\u66ff\u4ee3\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u957f\u8ddd\u79bb\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u73af\u5883\u548c\u58f0\u6e90\u8bbe\u7f6e\uff0c\u53ea\u9700\u5c11\u91cf\u5fae\u8c03\u3002", "conclusion": "Hankel-FNO\u4e3a\u6c34\u4e0b\u58f0\u5b66\u5236\u56fe\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u652f\u6301\u73af\u5883\u611f\u77e5\u4f20\u611f\u5668\u90e8\u7f72\u4f18\u5316\u548c\u81ea\u4e3b\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002"}}
{"id": "2512.06858", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06858", "abs": "https://arxiv.org/abs/2512.06858", "authors": ["Chayan Patra", "Dibyendu Mondal", "Sonaldeep Halder", "Dipanjali Halder", "Mostafizur Rahaman Laskar", "Richa Goel", "Rahul Maitra"], "title": "Physics Informed Generative Machine Learning for Accelerated Quantum-centric Supercomputing", "comment": "19 pages, 9 figures", "summary": "Quantum centric supercomputing (QCSC) framework, such as sample-based quantum diagonalization (SQD) holds immense promise toward achieving practical quantum utility to solve challenging problems. QCSC leverages quantum computers to perform the classically intractable task of sampling the dominant fermionic configurations from the Hilbert space that have substantial support to a target state, followed by Hamiltonian diagonalization on a classical processor. However, noisy quantum hardware produces erroneous samples upon measurements, making robust and efficient configuration-recovery strategies essential for a scalable QCSC pipeline. Toward this, in this work, we introduce PIGen-SQD, an efficiently designed QCSC workflow that utilizes the capability of generative machine learning (ML) along with physics-informed configuration screening via implicit low-rank tensor decompositions for accurate fermionic state reconstruction. The physics-informed pruning is based on a class of efficient perturbative measures that, in conjunction with hardware samples, provide a substantial overlap with the target state. This distribution induces an anchoring effect on the generative ML models to stochastically explore only the dominant sector of the Hilbert space for effective identification of additional important configurations in a self-consistent manner. Our numerical experiments performed on IBM Heron R2 quantum processors demonstrate this synergistic workflow produces compact, high-fidelity subspaces that substantially reduce diagonalization cost while maintaining chemical accuracy under strong electronic correlations. By embedding classical many body intuitions directly into the generative ML model, PIGen-SQD advances the robustness and scalability of QCSC algorithms, offering a promising pathway toward chemically reliable quantum simulations on utility-scale quantum hardware.", "AI": {"tldr": "PIGen-SQD\uff1a\u7ed3\u5408\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u548c\u7269\u7406\u4fe1\u606f\u526a\u679d\u7684\u91cf\u5b50\u4e2d\u5fc3\u8d85\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u566a\u58f0\u91cf\u5b50\u786c\u4ef6\u4e2d\u51c6\u786e\u91cd\u5efa\u8d39\u7c73\u5b50\u6001\uff0c\u663e\u8457\u964d\u4f4e\u5bf9\u89d2\u5316\u6210\u672c\u5e76\u4fdd\u6301\u5316\u5b66\u7cbe\u5ea6\u3002", "motivation": "\u91cf\u5b50\u4e2d\u5fc3\u8d85\u8ba1\u7b97\u6846\u67b6\uff08\u5982SQD\uff09\u5728\u89e3\u51b3\u6311\u6218\u6027\u95ee\u9898\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u566a\u58f0\u91cf\u5b50\u786c\u4ef6\u4f1a\u4ea7\u751f\u9519\u8bef\u7684\u91c7\u6837\u7ed3\u679c\uff0c\u9700\u8981\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u914d\u7f6e\u6062\u590d\u7b56\u7565\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684QCSC\u6d41\u7a0b\u3002", "method": "\u63d0\u51faPIGen-SQD\u5de5\u4f5c\u6d41\uff1a\u7ed3\u5408\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u4e0e\u57fa\u4e8e\u9690\u5f0f\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u7684\u7269\u7406\u4fe1\u606f\u914d\u7f6e\u7b5b\u9009\u3002\u901a\u8fc7\u6270\u52a8\u5ea6\u91cf\u4e0e\u786c\u4ef6\u91c7\u6837\u63d0\u4f9b\u4e0e\u76ee\u6807\u6001\u7684\u91cd\u53e0\uff0c\u5f15\u5bfc\u751f\u6210\u6a21\u578b\u5728\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u4e3b\u5bfc\u533a\u57df\u8fdb\u884c\u968f\u673a\u63a2\u7d22\uff0c\u4ee5\u81ea\u6d3d\u65b9\u5f0f\u8bc6\u522b\u91cd\u8981\u914d\u7f6e\u3002", "result": "\u5728IBM Heron R2\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u534f\u540c\u5de5\u4f5c\u6d41\u80fd\u4ea7\u751f\u7d27\u51d1\u3001\u9ad8\u4fdd\u771f\u5ea6\u7684\u5b50\u7a7a\u95f4\uff0c\u5728\u5f3a\u7535\u5b50\u5173\u8054\u4e0b\u663e\u8457\u964d\u4f4e\u5bf9\u89d2\u5316\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u5316\u5b66\u7cbe\u5ea6\u3002", "conclusion": "PIGen-SQD\u901a\u8fc7\u5c06\u7ecf\u5178\u591a\u4f53\u76f4\u89c9\u5d4c\u5165\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u5347\u4e86QCSC\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5728\u5b9e\u7528\u89c4\u6a21\u91cf\u5b50\u786c\u4ef6\u4e0a\u5b9e\u73b0\u5316\u5b66\u53ef\u9760\u7684\u91cf\u5b50\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2512.06427", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06427", "abs": "https://arxiv.org/abs/2512.06427", "authors": ["Andrea Combette", "Antoine Venaille", "Nelly Pustelnik"], "title": "A new initialisation to Control Gradients in Sinusoidal Neural network", "comment": null, "summary": "Proper initialisation strategy is of primary importance to mitigate gradient explosion or vanishing when training neural networks. Yet, the impact of initialisation parameters still lacks a precise theoretical understanding for several well-established architectures. Here, we propose a new initialisation for networks with sinusoidal activation functions such as \\texttt{SIREN}, focusing on gradients control, their scaling with network depth, their impact on training and on generalization. To achieve this, we identify a closed-form expression for the initialisation of the parameters, differing from the original \\texttt{SIREN} scheme. This expression is derived from fixed points obtained through the convergence of pre-activation distribution and the variance of Jacobian sequences. Controlling both gradients and targeting vanishing pre-activation helps preventing the emergence of inappropriate frequencies during estimation, thereby improving generalization. We further show that this initialisation strongly influences training dynamics through the Neural Tangent Kernel framework (NTK). Finally, we benchmark \\texttt{SIREN} with the proposed initialisation against the original scheme and other baselines on function fitting and image reconstruction. The new initialisation consistently outperforms state-of-the-art methods across a wide range of reconstruction tasks, including those involving physics-informed neural networks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684SIREN\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u68af\u5ea6\u548c\u9884\u6fc0\u6d3b\u5206\u5e03\u6765\u6539\u5584\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u80fd", "motivation": "\u73b0\u6709\u521d\u59cb\u5316\u7b56\u7565\u5bf9\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\u95ee\u9898\u7f3a\u4e4f\u7cbe\u786e\u7406\u8bba\u7406\u89e3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6b63\u5f26\u6fc0\u6d3b\u51fd\u6570\u7684\u7f51\u7edc\uff0c\u9700\u8981\u66f4\u597d\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u6765\u63a7\u5236\u68af\u5ea6\u5e76\u6539\u5584\u6cdb\u5316", "method": "\u63a8\u5bfc\u51fa\u53c2\u6570\u521d\u59cb\u5316\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u57fa\u4e8e\u9884\u6fc0\u6d3b\u5206\u5e03\u6536\u655b\u7684\u56fa\u5b9a\u70b9\u548cJacobian\u5e8f\u5217\u65b9\u5dee\uff0c\u63a7\u5236\u68af\u5ea6\u5e76\u5b9e\u73b0\u9884\u6fc0\u6d3b\u6d88\u5931\uff0c\u9632\u6b62\u4e0d\u9002\u5f53\u9891\u7387\u51fa\u73b0", "result": "\u65b0\u521d\u59cb\u5316\u65b9\u6cd5\u5728\u51fd\u6570\u62df\u5408\u548c\u56fe\u50cf\u91cd\u5efa\u4efb\u52a1\u4e2d\u4e00\u81f4\u4f18\u4e8e\u539f\u59cbSIREN\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4efb\u52a1", "conclusion": "\u63d0\u51fa\u7684\u521d\u59cb\u5316\u7b56\u7565\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u68af\u5ea6\u548c\u9884\u6fc0\u6d3b\u5206\u5e03\uff0c\u663e\u8457\u6539\u5584\u4e86SIREN\u7f51\u7edc\u7684\u8bad\u7ec3\u52a8\u6001\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u79cd\u91cd\u5efa\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02"}}
{"id": "2512.06895", "categories": ["quant-ph", "cond-mat.supr-con", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.06895", "abs": "https://arxiv.org/abs/2512.06895", "authors": ["Jason Walter", "Adam C. Weis", "Kan-Ting Tsai", "Meng-Ju Yu", "Naveen Katam", "Alex F. Kirichenko", "Oleg A. Mukhanov", "Shu-Jen Han", "Igor V. Vernik"], "title": "Single Flux Quantum Circuit Operation at Millikelvin Temperatures", "comment": "6 pages, 7 figures, presented at 17th European Conference on Applied Superconductivity, EUCAS 2025, 21-25 September 2025, Porto, Portugal. Accepted for publication in IEEE Trans. on Appl. Supercond", "summary": "As quantum computing processors increase in size, there is growing interest in developing cryogenic electronics to overcome significant challenges to system scaling. Single flux-quantum (SFQ) circuits offer a promising alternative to remote, bulky, and power-hungry room temperature electronics. To meet the need for digital qubit control, readout, and co-processing, SFQ circuits must be adapted to operate at millikelvin temperatures near quantum processors. SEEQC's SFQuClass digital quantum management approach proximally places energy-efficient SFQ (ERSFQ) circuits and qubits in a multi-chip module. This enables extremely low power dissipation, compatible with a typical dilution cryostat's limited cooling power, while maintaining high processing speed and low error rates. We report on systematic testing from 4 K to 10 mK of a comprehensive set of ERSFQ cells, as well as more complex circuits such as programmable counters and demultiplexers used in digital qubit control. We compare the operating margins and error rates of these circuits and find that, at millikelvin, bias margins decrease and the center of the margins (i.e., the optimal bias current value) increases by ~15%, compared to 4.2 K. The margins can be restored by thermal annealing by reducing Josephson junction (JJ) critical current Ic. To provide guidance for how circuit parameters vary from 4.2 K to millikelvin, relevant analog process control monitors (PCMs) were tested in the temperature range of interest. The measured JJ critical current (of the PCM JJ arrays) increases by ~15% when decreasing temperature from 4.2 K to millikelvin, in good agreement with both theory and the empirically measured change in the center of bias margins for the tested digital circuits.", "AI": {"tldr": "SFQ\u7535\u8def\u5728\u6beb\u5f00\u5c14\u6587\u6e29\u5ea6\u4e0b\u7528\u4e8e\u91cf\u5b50\u6bd4\u7279\u63a7\u5236\uff0c\u6d4b\u8bd5\u663e\u793a\u5de5\u4f5c\u88d5\u5ea6\u4e0b\u964d\u4f46\u53ef\u901a\u8fc7\u70ed\u9000\u706b\u6062\u590d\uff0c\u7ea6\u745f\u592b\u68ee\u7ed3\u4e34\u754c\u7535\u6d41\u589e\u52a0\u7ea615%", "motivation": "\u968f\u7740\u91cf\u5b50\u5904\u7406\u5668\u89c4\u6a21\u6269\u5927\uff0c\u9700\u8981\u5f00\u53d1\u4f4e\u6e29\u7535\u5b50\u5b66\u6765\u89e3\u51b3\u7cfb\u7edf\u6269\u5c55\u7684\u6311\u6218\u3002\u5355\u78c1\u901a\u91cf\u5b50(SFQ)\u7535\u8def\u6709\u671b\u66ff\u4ee3\u5e9e\u5927\u3001\u9ad8\u529f\u8017\u7684\u5ba4\u6e29\u7535\u5b50\u8bbe\u5907\uff0c\u7528\u4e8e\u91cf\u5b50\u6bd4\u7279\u7684\u6570\u5b57\u63a7\u5236\u3001\u8bfb\u53d6\u548c\u534f\u540c\u5904\u7406\u3002", "method": "\u91c7\u7528SEEQC\u7684SFQuClass\u6570\u5b57\u91cf\u5b50\u7ba1\u7406\u65b9\u6cd5\uff0c\u5c06\u80fd\u91cf\u9ad8\u6548\u7684ERSFQ\u7535\u8def\u548c\u91cf\u5b50\u6bd4\u7279\u96c6\u6210\u5728\u591a\u82af\u7247\u6a21\u5757\u4e2d\u3002\u57284K\u523010mK\u6e29\u5ea6\u8303\u56f4\u5185\u7cfb\u7edf\u6d4b\u8bd5ERSFQ\u5355\u5143\u7535\u8def\u3001\u53ef\u7f16\u7a0b\u8ba1\u6570\u5668\u548c\u89e3\u590d\u7528\u5668\u7b49\u590d\u6742\u7535\u8def\uff0c\u5e76\u6d4b\u8bd5\u76f8\u5173\u7684\u6a21\u62df\u5de5\u827a\u63a7\u5236\u76d1\u6d4b\u5668(PCMs)\u3002", "result": "\u5728\u6beb\u5f00\u5c14\u6587\u6e29\u5ea6\u4e0b\uff0c\u504f\u7f6e\u88d5\u5ea6\u4e0b\u964d\uff0c\u6700\u4f73\u504f\u7f6e\u7535\u6d41\u503c\u589e\u52a0\u7ea615%\u3002\u901a\u8fc7\u70ed\u9000\u706b\u964d\u4f4e\u7ea6\u745f\u592b\u68ee\u7ed3\u4e34\u754c\u7535\u6d41\u53ef\u4ee5\u6062\u590d\u88d5\u5ea6\u3002PCM\u6d4b\u8bd5\u663e\u793a\u7ea6\u745f\u592b\u68ee\u7ed3\u4e34\u754c\u7535\u6d41\u4ece4.2K\u5230\u6beb\u5f00\u5c14\u6587\u589e\u52a0\u7ea615%\uff0c\u4e0e\u7406\u8bba\u548c\u6570\u5b57\u7535\u8def\u6d4b\u8bd5\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "SFQ\u7535\u8def\u53ef\u4ee5\u5728\u6beb\u5f00\u5c14\u6587\u6e29\u5ea6\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u4e3a\u91cf\u5b50\u5904\u7406\u5668\u7684\u6570\u5b57\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6e29\u5ea6\u53d8\u5316\u5bf9\u7535\u8def\u53c2\u6570\u7684\u5f71\u54cd\u53ef\u4ee5\u901a\u8fc7\u70ed\u9000\u706b\u7b49\u65b9\u6cd5\u8fdb\u884c\u8865\u507f\uff0c\u786e\u4fdd\u7cfb\u7edf\u7a33\u5b9a\u8fd0\u884c\u3002"}}
{"id": "2512.06440", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06440", "abs": "https://arxiv.org/abs/2512.06440", "authors": ["Angelos-Christos Maroudis", "Sotirios Xydis"], "title": "Neural expressiveness for beyond importance model compression", "comment": null, "summary": "Neural Network Pruning has been established as driving force in the exploration of memory and energy efficient solutions with high throughput both during training and at test time. In this paper, we introduce a novel criterion for model compression, named \"Expressiveness\". Unlike existing pruning methods that rely on the inherent \"Importance\" of neurons' and filters' weights, ``Expressiveness\" emphasizes a neuron's or group of neurons ability to redistribute informational resources effectively, based on the overlap of activations. This characteristic is strongly correlated to a network's initialization state, establishing criterion autonomy from the learning state stateless and thus setting a new fundamental basis for the expansion of compression strategies in regards to the \"When to Prune\" question. We show that expressiveness is effectively approximated with arbitrary data or limited dataset's representative samples, making ground for the exploration of Data-Agnostic strategies. Our work also facilitates a \"hybrid\" formulation of expressiveness and importance-based pruning strategies, illustrating their complementary benefits and delivering up to 10x extra gains w.r.t. weight-based approaches in parameter compression ratios, with an average of 1% in performance degradation. We also show that employing expressiveness (independently) for pruning leads to an improvement over top-performing and foundational methods in terms of compression efficiency. Finally, on YOLOv8, we achieve a 46.1% MACs reduction by removing 55.4\\% of the parameters, with an increase of 3% in the mean Absolute Precision ($mAP_{50-95}$) for object detection on COCO dataset.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\"\u8868\u8fbe\u529b\"\u7684\u65b0\u526a\u679d\u51c6\u5219\uff0c\u5f3a\u8c03\u795e\u7ecf\u5143\u6fc0\u6d3b\u91cd\u53e0\u7684\u4fe1\u606f\u91cd\u5206\u914d\u80fd\u529b\uff0c\u5b9e\u73b0\u6570\u636e\u65e0\u5173\u526a\u679d\uff0c\u76f8\u6bd4\u6743\u91cd\u91cd\u8981\u6027\u65b9\u6cd5\u83b7\u5f9710\u500d\u53c2\u6570\u538b\u7f29\u589e\u76ca\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6743\u91cd\"\u91cd\u8981\u6027\"\uff0c\u4f46\u5ffd\u7565\u4e86\u795e\u7ecf\u5143\u6fc0\u6d3b\u91cd\u53e0\u6240\u4f53\u73b0\u7684\u4fe1\u606f\u91cd\u5206\u914d\u80fd\u529b\u3002\u9700\u8981\u5efa\u7acb\u4e0e\u5b66\u4e60\u72b6\u6001\u65e0\u5173\u7684\u526a\u679d\u51c6\u5219\uff0c\u89e3\u51b3\"\u4f55\u65f6\u526a\u679d\"\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u6570\u636e\u65e0\u5173\u7b56\u7565\u3002", "method": "\u63d0\u51fa\"\u8868\u8fbe\u529b\"\u526a\u679d\u51c6\u5219\uff0c\u57fa\u4e8e\u795e\u7ecf\u5143\u6216\u795e\u7ecf\u5143\u7ec4\u6fc0\u6d3b\u91cd\u53e0\u7684\u4fe1\u606f\u91cd\u5206\u914d\u80fd\u529b\u3002\u8be5\u51c6\u5219\u4e0e\u7f51\u7edc\u521d\u59cb\u5316\u72b6\u6001\u5f3a\u76f8\u5173\uff0c\u72ec\u7acb\u4e8e\u5b66\u4e60\u72b6\u6001\uff0c\u53ef\u7528\u4efb\u610f\u6570\u636e\u6216\u6709\u9650\u4ee3\u8868\u6027\u6837\u672c\u8fd1\u4f3c\u8ba1\u7b97\u3002\u652f\u6301\u4e0e\u91cd\u8981\u6027\u526a\u679d\u7684\u6df7\u5408\u7b56\u7565\u3002", "result": "\u76f8\u6bd4\u6743\u91cd\u65b9\u6cd5\u83b7\u5f9710\u500d\u53c2\u6570\u538b\u7f29\u589e\u76ca\uff0c\u6027\u80fd\u4ec5\u4e0b\u964d1%\u3002\u5728YOLOv8\u4e0a\u5b9e\u73b055.4%\u53c2\u6570\u79fb\u9664\u548c46.1%MACs\u51cf\u5c11\uff0cCOCO\u6570\u636e\u96c6\u4e0amAP50-95\u63d0\u53473%\u3002\u8868\u8fbe\u529b\u72ec\u7acb\u526a\u679d\u5728\u538b\u7f29\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8868\u8fbe\u529b\u51c6\u5219\u4e3a\u526a\u679d\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\"\u4f55\u65f6\u526a\u679d\"\u95ee\u9898\uff0c\u652f\u6301\u6570\u636e\u65e0\u5173\u7b56\u7565\uff0c\u4e0e\u91cd\u8981\u6027\u526a\u679d\u4e92\u8865\uff0c\u663e\u8457\u63d0\u5347\u538b\u7f29\u6548\u7387\u3002"}}
{"id": "2512.06940", "categories": ["quant-ph", "math-ph", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.06940", "abs": "https://arxiv.org/abs/2512.06940", "authors": ["Bernadette Lessel"], "title": "Optimal Transport of a Free Quantum Particle and its Shape Space Interpretation", "comment": "26 pages", "summary": "A solution of the free Schr\u00f6dinger equation is investigated by means of Optimal transport. The curve of probability measures $\u03bc_t$ this solution defines is shown to be an absolutely continuous curve in the Wasserstein space $W_2(\\mathbb{R}^3)$. The optimal transport map from $\u03bc_t$ to $\u03bc_s$, the cost for this transport (i.e. the Wasserstein distance) and the value of the Fisher information along $\u03bc_t$ are being calculated. It is finally shown that this solution of the free Schr\u00f6dinger equation can naturally be interpreted as a curve in so-called Shape space, which forgets any positioning in space but only describes properties of shapes. In Shape space, $\u03bc_t$ continues to be a shortest path geodesic.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5206\u6790\u81ea\u7531\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u89e3\uff0c\u8bc1\u660e\u5176\u5b9a\u4e49\u7684\u6d4b\u5ea6\u66f2\u7ebf\u5728Wasserstein\u7a7a\u95f4\u4e2d\u7edd\u5bf9\u8fde\u7eed\uff0c\u5e76\u8ba1\u7b97\u4e86\u6700\u4f18\u4f20\u8f93\u6620\u5c04\u3001Wasserstein\u8ddd\u79bb\u548cFisher\u4fe1\u606f\uff0c\u6700\u540e\u5c06\u8be5\u89e3\u89e3\u91ca\u4e3a\u5f62\u72b6\u7a7a\u95f4\u4e2d\u7684\u6d4b\u5ea6\u66f2\u7ebf\u3002", "motivation": "\u7814\u7a76\u81ea\u7531\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u89e3\u4e0e\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63a2\u7d22\u91cf\u5b50\u529b\u5b66\u4e2d\u7684\u6982\u7387\u6d4b\u5ea6\u6f14\u5316\u5982\u4f55\u5728Wasserstein\u51e0\u4f55\u6846\u67b6\u4e0b\u63cf\u8ff0\uff0c\u5e76\u5efa\u7acb\u4e0e\u5f62\u72b6\u7a7a\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5206\u6790\u81ea\u7531\u859b\u5b9a\u8c14\u65b9\u7a0b\u89e3\u5b9a\u4e49\u7684\u6d4b\u5ea6\u66f2\u7ebf\uff0c\u8bc1\u660e\u5176\u5728Wasserstein\u7a7a\u95f4\u4e2d\u7684\u7edd\u5bf9\u8fde\u7eed\u6027\uff0c\u8ba1\u7b97\u6700\u4f18\u4f20\u8f93\u6620\u5c04\u3001Wasserstein\u8ddd\u79bb\u548cFisher\u4fe1\u606f\uff0c\u5e76\u5c06\u8be5\u89e3\u89e3\u91ca\u4e3a\u5f62\u72b6\u7a7a\u95f4\u4e2d\u7684\u6d4b\u5ea6\u66f2\u7ebf\u3002", "result": "\u8bc1\u660e\u4e86\u81ea\u7531\u859b\u5b9a\u8c14\u65b9\u7a0b\u89e3\u5b9a\u4e49\u7684\u6d4b\u5ea6\u66f2\u7ebf\u5728Wasserstein\u7a7a\u95f4W\u2082(\u211d\u00b3)\u4e2d\u662f\u7edd\u5bf9\u8fde\u7eed\u66f2\u7ebf\uff0c\u8ba1\u7b97\u4e86\u6700\u4f18\u4f20\u8f93\u6620\u5c04\u3001Wasserstein\u8ddd\u79bb\u548cFisher\u4fe1\u606f\uff0c\u5e76\u8868\u660e\u8be5\u89e3\u5728\u5f62\u72b6\u7a7a\u95f4\u4e2d\u4ecd\u7136\u662f\u6700\u77ed\u8def\u5f84\u6d4b\u5730\u7ebf\u3002", "conclusion": "\u81ea\u7531\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u89e3\u53ef\u4ee5\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5728Wasserstein\u51e0\u4f55\u6846\u67b6\u4e0b\u5206\u6790\uff0c\u8be5\u89e3\u4e0d\u4ec5\u63cf\u8ff0\u4e86\u91cf\u5b50\u6982\u7387\u6d4b\u5ea6\u7684\u6f14\u5316\uff0c\u8fd8\u53ef\u4ee5\u81ea\u7136\u5730\u89e3\u91ca\u4e3a\u5f62\u72b6\u7a7a\u95f4\u4e2d\u7684\u6d4b\u5ea6\u66f2\u7ebf\uff0c\u4e14\u5728\u5f62\u72b6\u7a7a\u95f4\u4e2d\u4fdd\u6301\u6d4b\u5730\u7ebf\u6027\u8d28\u3002"}}
{"id": "2512.06457", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.06457", "abs": "https://arxiv.org/abs/2512.06457", "authors": ["Huizheng Wang", "Hongbin Wang", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination", "comment": null, "summary": "Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency.", "AI": {"tldr": "BitStopper\uff1a\u4e00\u79cd\u65e0\u9700\u7a00\u758f\u9884\u6d4b\u5668\u7684\u7ec6\u7c92\u5ea6\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6bd4\u7279\u7ea7\u7a00\u758f\u63a8\u6d4b\u3001\u6bd4\u7279\u4e32\u884c\u4f7f\u80fd\u9636\u6bb5\u878d\u5408\u548c\u6bd4\u7279\u7ea7\u5f02\u6b65\u5904\u7406\uff0c\u663e\u8457\u964d\u4f4eTransformer\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u5185\u5b58\u8bbf\u95ee\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e8c\u6b21\u65b9\u8ba1\u7b97\u6210\u672c\uff0c\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u867d\u7136\u80fd\u7f13\u89e3\u4f46\u53d7\u9650\u4e8e\u9884\u6d4b\u9636\u6bb5\u5f00\u9500\u548c\u5185\u5b58\u6d41\u91cf\u3002\u73b0\u6709\u65b9\u6cd5\u786c\u4ef6\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u6bd4\u7279\u4e32\u884c\u4f7f\u80fd\u9636\u6bb5\u878d\u5408(BESF)\uff1a\u91cd\u7528\u5e76\u6700\u5c0f\u5316\u5185\u5b58\u8bbf\u95ee\uff0c\u9010\u6b65\u7ec8\u6b62\u4e0d\u91cd\u8981token\uff0c\u5c06\u9884\u6d4b\u9636\u6bb5\u5408\u5e76\u5230\u6267\u884c\u9636\u6bb5\uff1b2) \u8f7b\u91cf\u81ea\u9002\u5e94token\u9009\u62e9(LATS)\uff1a\u4e0e\u6bd4\u7279\u7ea7\u7a00\u758f\u63a8\u6d4b\u534f\u540c\u5de5\u4f5c\uff1b3) \u6bd4\u7279\u7ea7\u5f02\u6b65\u5904\u7406(BAP)\uff1a\u5728\u6309\u9700\u6bd4\u7279\u7c92\u5ea6\u5185\u5b58\u83b7\u53d6\u65f6\u63d0\u9ad8\u8ba1\u7b97\u5229\u7528\u7387\uff1b4) \u7cbe\u5fc3\u8bbe\u8ba1\u7684\u67b6\u6784\u5b9e\u73b0\u7406\u8bba\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u5b9e\u9645\u6027\u80fd\u63d0\u5347\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684Transformer\u52a0\u901f\u5668\uff0cBitStopper\u5728Sanger\u4e0a\u5b9e\u73b02.03\u500d\u52a0\u901f\uff0cSOFA\u4e0a\u5b9e\u73b01.89\u500d\u52a0\u901f\uff0c\u540c\u65f6\u80fd\u6548\u5206\u522b\u63d0\u53472.4\u500d\u548c2.1\u500d\u3002", "conclusion": "BitStopper\u901a\u8fc7\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u65e0\u9700\u7a00\u758f\u9884\u6d4b\u5668\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u7684\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u663e\u8457\u63d0\u5347Transformer\u52a0\u901f\u5668\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2512.06948", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06948", "abs": "https://arxiv.org/abs/2512.06948", "authors": ["Jaime Garc\u00eda Oliv\u00e1n", "Ainitze Biteri-Uribarren", "Oliver T. Whaites", "Jorge Casanova"], "title": "Suppressing Fast Dipolar Noise in Solid-State Spin Qubits", "comment": "6 pages, 3 figures and Supplementary Information", "summary": "Spin qubit coherence is a fundamental resource for the realization of quantum technologies. For solid-state platforms, spin decoherence is dominated by the magneto-active environment in the lattice, limiting their applicability. While standard dynamical decoupling techniques, such as the Hahn echo, extend central spin coherence, they fail to suppress the fast noise arising from strong dipolar interactions within the bath. Here, we present a decoupling mechanism, Hybrid-LG, that suppresses intra-bath dipolar interactions -- thus, fast noise acting on spin qubits- and demonstrate its effectiveness in extending spin coherence through efficient in-house CCE simulations. Specifically, we investigate one of the most widely exploited solid-state quantum platforms: an ensemble of nitrogen-vacancy (NV) centers in diamond coupled to a large and dense bath of substitutional nitrogen paramagnetic impurities (P1 centers). Our results reveal at least a twofold enhancement in NV coherence time relative to standard techniques including P1 center driving, without requiring additional control power.", "AI": {"tldr": "\u63d0\u51faHybrid-LG\u89e3\u8026\u673a\u5236\uff0c\u6291\u5236\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u4e2d\u7684\u5feb\u901f\u566a\u58f0\uff0c\u5728NV\u8272\u5fc3\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u76f8\u5e72\u65f6\u95f4\u81f3\u5c11\u4e24\u500d\u63d0\u5347", "motivation": "\u56fa\u6001\u5e73\u53f0\u4e2d\u7684\u81ea\u65cb\u9000\u76f8\u5e72\u4e3b\u8981\u53d7\u6676\u683c\u4e2d\u78c1\u6d3b\u6027\u73af\u5883\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u91cf\u5b50\u6280\u672f\u7684\u5e94\u7528\u3002\u4f20\u7edf\u7684\u52a8\u6001\u89e3\u8026\u6280\u672f\uff08\u5982Hahn\u56de\u6ce2\uff09\u867d\u7136\u80fd\u5ef6\u957f\u4e2d\u5fc3\u81ea\u65cb\u76f8\u5e72\u6027\uff0c\u4f46\u65e0\u6cd5\u6291\u5236\u7531\u6d74\u4e2d\u5f3a\u5076\u6781\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u7684\u5feb\u901f\u566a\u58f0\u3002", "method": "\u63d0\u51faHybrid-LG\u89e3\u8026\u673a\u5236\uff0c\u901a\u8fc7\u6291\u5236\u6d74\u5185\u5076\u6781\u76f8\u4e92\u4f5c\u7528\u6765\u51cf\u5c11\u5feb\u901f\u566a\u58f0\u3002\u4f7f\u7528\u9ad8\u6548\u7684\u5185\u90e8CCE\u6a21\u62df\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7814\u7a76\u91d1\u521a\u77f3\u4e2d\u6c2e\u7a7a\u4f4d\uff08NV\uff09\u8272\u5fc3\u4e0e\u5927\u91cf\u5bc6\u96c6\u7684\u66ff\u4ee3\u6c2e\u987a\u78c1\u6742\u8d28\uff08P1\u4e2d\u5fc3\uff09\u6d74\u8026\u5408\u7684\u7cfb\u7edf\u3002", "result": "Hybrid-LG\u673a\u5236\u76f8\u5bf9\u4e8e\u5305\u62ecP1\u4e2d\u5fc3\u9a71\u52a8\u7684\u6807\u51c6\u6280\u672f\uff0c\u81f3\u5c11\u5b9e\u73b0\u4e86NV\u76f8\u5e72\u65f6\u95f4\u7684\u4e24\u500d\u589e\u5f3a\uff0c\u4e14\u65e0\u9700\u989d\u5916\u7684\u63a7\u5236\u529f\u7387\u3002", "conclusion": "Hybrid-LG\u89e3\u8026\u673a\u5236\u80fd\u6709\u6548\u6291\u5236\u56fa\u6001\u91cf\u5b50\u5e73\u53f0\u4e2d\u7684\u5feb\u901f\u566a\u58f0\uff0c\u663e\u8457\u5ef6\u957f\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u7684\u76f8\u5e72\u65f6\u95f4\uff0c\u4e3a\u91cf\u5b50\u6280\u672f\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2512.06471", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06471", "abs": "https://arxiv.org/abs/2512.06471", "authors": ["Nathan P. Lawrence", "Ali Mesbah"], "title": "Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control", "comment": "IFAC preprint", "summary": "Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7684\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\uff0c\u63a8\u5bfc\u4e86\u4f20\u7edf\u4e8c\u6b21\u76ee\u6807\u4e0e\u76ee\u6807\u6761\u4ef6\u5956\u52b1\u4e4b\u95f4\u7684\u6700\u4f18\u6027\u5dee\u8ddd\uff0c\u5e76\u5c06\u72b6\u6001\u4f30\u8ba1\u4e0e\u6982\u7387\u5956\u52b1\u8054\u7cfb\u8d77\u6765\uff0c\u9a8c\u8bc1\u4e86\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u5728\u975e\u7ebf\u6027\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u65e8\u5728\u8bad\u7ec3\u667a\u80fd\u4f53\u6700\u5927\u5316\u5230\u8fbe\u76ee\u6807\u72b6\u6001\u7684\u6982\u7387\uff0c\u4f46\u4f20\u7edf\u5bc6\u96c6\u5956\u52b1\uff08\u5982\u4e8c\u6b21\u578b\uff09\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u53ef\u80fd\u5931\u6548\u3002\u672c\u6587\u65e8\u5728\u4ece\u6700\u4f18\u63a7\u5236\u89d2\u5ea6\u5206\u6790\u76ee\u6807\u6761\u4ef6\u8bbe\u7f6e\uff0c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4f20\u7edf\u5956\u52b1\u65b9\u6cd5\u4f1a\u5931\u8d25\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u76ee\u6807\u6761\u4ef6RL\u80fd\u6210\u529f\u3002", "method": "\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7406\u8bba\uff0c\u63a8\u5bfc\u4e86\u4f20\u7edf\u4e8c\u6b21\u76ee\u6807\u4e0e\u76ee\u6807\u6761\u4ef6\u5956\u52b1\u4e4b\u95f4\u7684\u6700\u4f18\u6027\u5dee\u8ddd\u3002\u8003\u8651\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5c06\u72b6\u6001\u4f30\u8ba1\u4e0e\u6982\u7387\u5956\u52b1\u8054\u7cfb\u8d77\u6765\uff0c\u4f7f\u76ee\u6807\u6761\u4ef6\u5956\u52b1\u9002\u7528\u4e8e\u53cc\u91cd\u63a7\u5236\u95ee\u9898\u3002\u5728\u975e\u7ebf\u6027\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u9884\u6d4b\u63a7\u5236\u6280\u672f\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u9610\u660e\u4e86\u76ee\u6807\u6761\u4ef6RL\u6210\u529f\u7684\u539f\u56e0\u4ee5\u53ca\u4f20\u7edf\u5bc6\u96c6\u5956\u52b1\u5931\u8d25\u7684\u539f\u56e0\u3002\u5efa\u7acb\u4e86\u72b6\u6001\u4f30\u8ba1\u4e0e\u6982\u7387\u5956\u52b1\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u4f7f\u76ee\u6807\u6761\u4ef6\u5956\u52b1\u9002\u7528\u4e8e\u53cc\u91cd\u63a7\u5236\u95ee\u9898\u3002\u5728\u975e\u7ebf\u6027\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u7684\u4f18\u52bf\u3002", "conclusion": "\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u5728\u5230\u8fbe\u76ee\u6807\u72b6\u6001\u7684\u4efb\u52a1\u4e2d\u5177\u6709\u7406\u8bba\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u3002\u901a\u8fc7\u6700\u4f18\u63a7\u5236\u5206\u6790\u63ed\u793a\u4e86\u4f20\u7edf\u5956\u52b1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u76ee\u6807\u6761\u4ef6RL\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u53cc\u91cd\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.06964", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06964", "abs": "https://arxiv.org/abs/2512.06964", "authors": ["Yiruo Lin"], "title": "On possible extensions of quantum mechanics", "comment": "10 pages", "summary": "It was argued [1] that there can be no extension of quantum mechanics with improved predictive power on a measurement freely chosen, independently of any event that is not in its future light cone. The assumption of measurement choice was criticized [2] to be too strong to be physically necessary and extensions of quantum mechanics were shown [3] to be possible under a more relaxed measurement assumption. Here I point out an error in the criticism and observe that the actual mistake of the no-go theorem lies in an unwarranted assumption implicitly made in the proof of [1]. Hence, quantum mechanics is guaranteed to have the maximal predictive power only in situations of complete certainty and complete uncertainty about measurement outcomes. I then show that the measurement assumption can be further relaxed without affecting the conclusion on the predictive power of quantum mechanics versus alternative theories. I further study the optimal predicative improvement over quantum mechanics of local spin measurements on a pair of entangled qubits by any alternative theory and conjecture a strict upper bound.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa[1]\u4e2d\u5173\u4e8e\u91cf\u5b50\u529b\u5b66\u9884\u6d4b\u80fd\u529b\u6781\u9650\u7684no-go\u5b9a\u7406\u5b58\u5728\u9519\u8bef\uff0c\u8ba4\u4e3a\u91cf\u5b50\u529b\u5b66\u4ec5\u5728\u5b8c\u5168\u786e\u5b9a\u548c\u5b8c\u5168\u4e0d\u786e\u5b9a\u6d4b\u91cf\u7ed3\u679c\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u6700\u5927\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u7814\u7a76\u4e86\u7ea0\u7f20\u91cf\u5b50\u6bd4\u7279\u5bf9\u5c40\u90e8\u81ea\u65cb\u6d4b\u91cf\u7684\u6700\u4f18\u9884\u6d4b\u6539\u8fdb\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u91cf\u5b50\u529b\u5b66\u9884\u6d4b\u80fd\u529b\u7684\u6781\u9650\u95ee\u9898\uff0c\u7ea0\u6b63\u5148\u524d\u6587\u732e\u4e2d\u7684\u9519\u8bef\uff0c\u63a2\u8ba8\u5728\u66f4\u5bbd\u677e\u7684\u6d4b\u91cf\u5047\u8bbe\u4e0b\u91cf\u5b50\u529b\u5b66\u4e0e\u66ff\u4ee3\u7406\u8bba\u4e4b\u95f4\u7684\u9884\u6d4b\u80fd\u529b\u5173\u7cfb\u3002", "method": "\u5206\u6790\u5148\u524d\u6587\u732e[1]\u8bc1\u660e\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u9519\u8bef\uff0c\u63d0\u51fa\u66f4\u5bbd\u677e\u7684\u6d4b\u91cf\u5047\u8bbe\u6846\u67b6\uff0c\u7814\u7a76\u7ea0\u7f20\u91cf\u5b50\u6bd4\u7279\u5bf9\u5c40\u90e8\u81ea\u65cb\u6d4b\u91cf\u7684\u6700\u4f18\u9884\u6d4b\u6539\u8fdb\uff0c\u5e76\u63a8\u6d4b\u4e25\u683c\u4e0a\u754c\u3002", "result": "\u6307\u51fa[1]\u7684no-go\u5b9a\u7406\u5b58\u5728\u9519\u8bef\uff0c\u91cf\u5b50\u529b\u5b66\u4ec5\u5728\u5b8c\u5168\u786e\u5b9a\u548c\u5b8c\u5168\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u5177\u6709\u6700\u5927\u9884\u6d4b\u80fd\u529b\uff1b\u5728\u66f4\u5bbd\u677e\u6d4b\u91cf\u5047\u8bbe\u4e0b\u7ed3\u8bba\u4e0d\u53d8\uff1b\u5bf9\u7ea0\u7f20\u91cf\u5b50\u6bd4\u7279\u7684\u5c40\u90e8\u81ea\u65cb\u6d4b\u91cf\uff0c\u63a8\u6d4b\u4e86\u66ff\u4ee3\u7406\u8bba\u9884\u6d4b\u6539\u8fdb\u7684\u4e25\u683c\u4e0a\u754c\u3002", "conclusion": "\u91cf\u5b50\u529b\u5b66\u7684\u9884\u6d4b\u80fd\u529b\u5e76\u975e\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u662f\u6700\u5927\u7684\uff0c\u53ea\u6709\u5728\u5b8c\u5168\u786e\u5b9a\u548c\u5b8c\u5168\u4e0d\u786e\u5b9a\u6d4b\u91cf\u7ed3\u679c\u7684\u60c5\u51b5\u4e0b\u624d\u8fbe\u5230\u6781\u9650\uff1b\u5bf9\u7ea0\u7f20\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\uff0c\u66ff\u4ee3\u7406\u8bba\u7684\u9884\u6d4b\u6539\u8fdb\u5b58\u5728\u4e25\u683c\u9650\u5236\u3002"}}
{"id": "2512.06490", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06490", "abs": "https://arxiv.org/abs/2512.06490", "authors": ["Agatsya Yadav", "Renta Chintala Bhargavi"], "title": "Optimizing LLMs Using Quantization for Mobile Execution", "comment": "11 pages, 1 equation, 2 tables. Author Accepted Manuscript (AAM) of a paper published in Springer LNNS, ICT4SD 2025. DOI: 10.1007/978-3-032-06697-8_33", "summary": "Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using the BitsAndBytes library with the Hugging Face Transformers framework to Meta's Llama 3.2 3B model. The quantized model is converted to GGUF format using llama.cpp tools for optimized mobile inference. The PTQ workflow achieves a 68.66% reduction in model size through 4-bit quantization, enabling the Llama 3.2 3B model to run efficiently on an Android device. Qualitative validation shows that the 4-bit quantized model can perform inference tasks successfully. We demonstrate the feasibility of running the quantized GGUF model on an Android device using the Termux environment and the Ollama framework. PTQ, especially at 4-bit precision combined with mobile-optimized formats like GGUF, provides a practical pathway for deploying capable LLMs on mobile devices, balancing model size and performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u75284\u4f4d\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u6210\u529f\u5c06Llama 3.2 3B\u6a21\u578b\u91cf\u5316\u5e76\u90e8\u7f72\u5230Android\u8bbe\u5907\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u5de8\u5927\u7684\u6a21\u578b\u89c4\u6a21\u548c\u8ba1\u7b97\u9700\u6c42\u963b\u788d\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\uff0c\u9700\u8981\u5bfb\u627e\u6709\u6548\u7684\u538b\u7f29\u548c\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528BitsAndBytes\u5e93\u548cHugging Face Transformers\u6846\u67b6\u5bf9Meta\u7684Llama 3.2 3B\u6a21\u578b\u8fdb\u884c4\u4f4d\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\uff0c\u7136\u540e\u5c06\u91cf\u5316\u6a21\u578b\u8f6c\u6362\u4e3aGGUF\u683c\u5f0f\uff0c\u6700\u540e\u5728Android\u8bbe\u5907\u7684Termux\u73af\u5883\u548cOllama\u6846\u67b6\u4e2d\u90e8\u7f72\u8fd0\u884c\u3002", "result": "\u901a\u8fc74\u4f4d\u91cf\u5316\u5b9e\u73b0\u4e8668.66%\u7684\u6a21\u578b\u5927\u5c0f\u7f29\u51cf\uff0c\u91cf\u5316\u540e\u7684\u6a21\u578b\u80fd\u591f\u5728Android\u8bbe\u5907\u4e0a\u6210\u529f\u6267\u884c\u63a8\u7406\u4efb\u52a1\uff0c\u8bc1\u660e\u4e86\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8fd0\u884c\u91cf\u5316LLM\u7684\u53ef\u884c\u6027\u3002", "conclusion": "4\u4f4dPTQ\u7ed3\u5408GGUF\u7b49\u79fb\u52a8\u4f18\u5316\u683c\u5f0f\uff0c\u4e3a\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u90e8\u7f72\u529f\u80fd\u5f3a\u5927\u7684LLMs\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u5728\u6a21\u578b\u5927\u5c0f\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2512.06996", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.06996", "abs": "https://arxiv.org/abs/2512.06996", "authors": ["Daryoosh Vashaee", "Jahanfar Abouie"], "title": "Quantum Correlation Assisted Cooling of Microwave Cavities Below the Ambient Temperature", "comment": null, "summary": "We develop a theoretical framework for cooling a microwave cavity mode using a Poisson stream of internally correlated pairs of two-level systems and analyze its performance under realistic dissipation. Starting from a Lindblad model of a phonon-tethered cavity interacting with sequentially injected atom pairs, we derive closed-form expressions for the steady-state cavity occupation and effective temperature. Two coupling geometries are examined: a one-atom configuration, where only one member of each pair interacts with the cavity, and a two-atom configuration, where both atoms couple collectively. The single-atom model enables cooling below the phonon bath but not below the reservoir temperature, whereas the two-atom scheme exhibits enhanced refrigeration - pair correlations modify the cavity's upward and downward transition rates so that the steady-state temperature can fall well below that of the reservoir for weak phonon damping. We map the parameter space including detuning, coupling strength, damping, and intra-pair exchange, identifying cooling valleys near resonance and the crossover between reservoir- and phonon-dominated regimes. The two-atom configuration thus realizes a genuine quantum-enhanced cooling mechanism absent in the single-atom case. We further outline an experimental implementation using two superconducting qubits repeatedly prepared, coupled, and reset inside a 3D cavity. Realistic reset and flux-tuning protocols support MHz-rate interaction cycles, enabling engineered reservoirs to impose cavity temperatures of 50-120 mK even when the cryostat is at ~1 K, offering a pathway to autonomous, on-chip refrigeration of microwave modes in scalable quantum hardware.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u76f8\u5173\u539f\u5b50\u5bf9\u6d41\u51b7\u5374\u5fae\u6ce2\u8154\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e86\u4e24\u79cd\u8026\u5408\u6784\u578b\uff0c\u53d1\u73b0\u53cc\u539f\u5b50\u6784\u578b\u80fd\u5b9e\u73b0\u91cf\u5b50\u589e\u5f3a\u51b7\u5374\uff0c\u53ef\u5c06\u8154\u6e29\u964d\u81f3\u8fdc\u4f4e\u4e8e\u50a8\u5c42\u6e29\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u5b9e\u9a8c\u5b9e\u73b0\u65b9\u6848\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u5728\u91cf\u5b50\u786c\u4ef6\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u3001\u7247\u4e0a\u5fae\u6ce2\u6a21\u5f0f\u5236\u51b7\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u76f8\u5173\u539f\u5b50\u5bf9\u6d41\u7684\u91cf\u5b50\u7279\u6027\u6765\u589e\u5f3a\u51b7\u5374\u6548\u679c\uff0c\u514b\u670d\u4f20\u7edf\u51b7\u5374\u65b9\u6cd5\u7684\u9650\u5236\u3002", "method": "\u4eceLindblad\u6a21\u578b\u51fa\u53d1\uff0c\u63a8\u5bfc\u4e86\u7a33\u6001\u8154\u5360\u636e\u6570\u548c\u6709\u6548\u6e29\u5ea6\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002\u7814\u7a76\u4e86\u4e24\u79cd\u8026\u5408\u6784\u578b\uff1a\u5355\u539f\u5b50\u6784\u578b\uff08\u6bcf\u5bf9\u4e2d\u53ea\u6709\u4e00\u4e2a\u539f\u5b50\u4e0e\u8154\u76f8\u4e92\u4f5c\u7528\uff09\u548c\u53cc\u539f\u5b50\u6784\u578b\uff08\u4e24\u4e2a\u539f\u5b50\u96c6\u4f53\u8026\u5408\uff09\u3002\u5206\u6790\u4e86\u53c2\u6570\u7a7a\u95f4\u5305\u62ec\u5931\u8c10\u3001\u8026\u5408\u5f3a\u5ea6\u3001\u963b\u5c3c\u548c\u539f\u5b50\u5bf9\u5185\u4ea4\u6362\u3002", "result": "\u5355\u539f\u5b50\u6a21\u578b\u80fd\u51b7\u5374\u5230\u4f4e\u4e8e\u58f0\u5b50\u6d74\u6e29\u5ea6\u4f46\u65e0\u6cd5\u4f4e\u4e8e\u50a8\u5c42\u6e29\u5ea6\uff0c\u800c\u53cc\u539f\u5b50\u65b9\u6848\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u5236\u51b7\u6548\u679c\u2014\u2014\u539f\u5b50\u5bf9\u76f8\u5173\u6027\u6539\u53d8\u4e86\u8154\u7684\u4e0a\u4e0b\u8dc3\u8fc1\u901f\u7387\uff0c\u4f7f\u5f97\u5728\u5f31\u58f0\u5b50\u963b\u5c3c\u4e0b\u7a33\u6001\u6e29\u5ea6\u53ef\u8fdc\u4f4e\u4e8e\u50a8\u5c42\u6e29\u5ea6\u3002\u8bc6\u522b\u4e86\u5171\u632f\u9644\u8fd1\u7684\u51b7\u5374\u8c37\u4ee5\u53ca\u50a8\u5c42\u4e3b\u5bfc\u548c\u58f0\u5b50\u4e3b\u5bfc\u673a\u5236\u4e4b\u95f4\u7684\u4ea4\u53c9\u533a\u57df\u3002", "conclusion": "\u53cc\u539f\u5b50\u6784\u578b\u5b9e\u73b0\u4e86\u5355\u539f\u5b50\u60c5\u51b5\u4e0b\u4e0d\u5b58\u5728\u7684\u771f\u6b63\u91cf\u5b50\u589e\u5f3a\u51b7\u5374\u673a\u5236\u3002\u901a\u8fc7\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u57283D\u8154\u4e2d\u91cd\u590d\u5236\u5907\u3001\u8026\u5408\u548c\u91cd\u7f6e\u7684\u5b9e\u9a8c\u65b9\u6848\uff0c\u53ef\u5b9e\u73b0MHz\u901f\u7387\u7684\u76f8\u4e92\u4f5c\u7528\u5faa\u73af\uff0c\u5373\u4f7f\u4f4e\u6e29\u6052\u6e29\u5668\u5728~1K\u65f6\u4e5f\u80fd\u5c06\u8154\u6e29\u964d\u81f350-120mK\uff0c\u4e3a\u53ef\u6269\u5c55\u91cf\u5b50\u786c\u4ef6\u4e2d\u7684\u5fae\u6ce2\u6a21\u5f0f\u81ea\u4e3b\u7247\u4e0a\u5236\u51b7\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2512.06511", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.06511", "abs": "https://arxiv.org/abs/2512.06511", "authors": ["Mengqi Xu", "Subha Maity", "Joel Dubin"], "title": "Diagnosis-based mortality prediction for intensive care unit patients via transfer learning", "comment": null, "summary": "In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5728ICU\u8bca\u65ad\u7279\u5f02\u6027\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u5e94\u7528\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u53d1\u73b0\u8fc1\u79fb\u5b66\u4e60\u4f18\u4e8e\u4ec5\u4f7f\u7528\u8bca\u65ad\u7279\u5f02\u6027\u6570\u636e\u6216APACHE IVa\u8bc4\u5206\u7684\u6a21\u578b\uff0c\u4e14\u5728\u4e0d\u540c\u51b3\u7b56\u9608\u503c\u4e0b\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "ICU\u4e2d\u5371\u91cd\u75be\u75c5\u7684\u75c5\u56e0\u5728\u4e0d\u540c\u8bca\u65ad\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u73b0\u6709\u9884\u6d4b\u6a21\u578b\u672a\u80fd\u7cfb\u7edf\u6027\u5730\u8003\u8651\u8bca\u65ad\u5f02\u8d28\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u8bca\u65ad\u7279\u5f02\u6027\u5dee\u5f02\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528eICU\u534f\u4f5c\u7814\u7a76\u6570\u636e\u5e93\uff0c\u8bc4\u4f30\u57fa\u4e8eGLM\u548cXGBoost\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bca\u65ad\u7279\u5f02\u6027\u6b7b\u4ea1\u7387\u9884\u6d4b\uff0c\u5e76\u4e0e\u4ec5\u4f7f\u7528\u8bca\u65ad\u7279\u5f02\u6027\u6570\u636e\u3001APACHE IVa\u8bc4\u5206\u4ee5\u53ca\u5408\u5e76\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u8bca\u65ad\u7279\u5f02\u6027\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4ec5\u4f7f\u7528\u8bca\u65ad\u7279\u5f02\u6027\u6570\u636e\u7684\u6a21\u578b\u548cAPACHE IVa\u8bc4\u5206\uff0c\u540c\u65f6\u6bd4\u5408\u5e76\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u6821\u51c6\u6027\u3002Youden\u622a\u65ad\u503c\u6bd4\u4f20\u7edf\u76840.5\u9608\u503c\u66f4\u9002\u5408\u4e8c\u5143\u7ed3\u679c\u9884\u6d4b\u3002", "conclusion": "\u8fc1\u79fb\u5b66\u4e60\u662f\u5904\u7406ICU\u8bca\u65ad\u5f02\u8d28\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u9ad8\u6b7b\u4ea1\u7387\u9884\u6d4b\u6027\u80fd\uff0c\u4e14\u5728\u4e0d\u540c\u51b3\u7b56\u9608\u503c\u4e0b\u4fdd\u6301\u7a33\u5b9a\u7684\u9884\u6d4b\u80fd\u529b\u3002Youden\u622a\u65ad\u503c\u5e94\u4f5c\u4e3a\u4e8c\u5143\u7ed3\u679c\u9884\u6d4b\u7684\u66f4\u5408\u9002\u51b3\u7b56\u9608\u503c\u3002"}}
{"id": "2512.07007", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07007", "abs": "https://arxiv.org/abs/2512.07007", "authors": ["Tulsi Dass"], "title": "Bohmian Trajectories Within Hilbert Space Based Quantum Mechanics. Solution of the Measurement Problem", "comment": "33 pages", "summary": "de Broglie-Bohm theory (dBBT), treating quantum particles as point objects moving along well defined (Bohmian) trajectories, offers an appealing solution of the measurement problem in quantum mechanics; it has, however, problems relating to spin, relativity and lack of proper integration with the Hilbert space based framework. In this work, we present a consistent formalism which has the traditional state-observable framework integrated with the desirable features of dBBT. We adopt ensemble interpretation for the Schrodinger wave function $\u03c8$. Given a Schrodinger wave function $\u03c8$, we use its value $\u03c8_0$ at some fixed time (say, $t = 0$) to define the probability measure $|\u03c8_0|^2 {\\rm d}x$ on the system configuration space $M$ ($=\\mathbb{R}^n$). On the resulting probability space $\\mathcal{M}_0$, we introduce a stochastic process $\u03be(t)$ corresponding to the Heisenberg position operator $X_H(t)$ such that, in the Heisenberg state $|\u03c8_h\\rangle$ corresponding to $\u03c8_0$, the expectation value of $X_H(t)$ equals that of $\u03be(t)$ in $\\mathcal{M}_0$. This condition leads to the de Broglie-Bohm guidance equation for the sample paths of the process $\u03be(t)$ which are, therefore, Bohmian trajectories supposedly representing time-evolutions of individual members of the $\u03c8_0$-ensemble. Stochastic processes and Bohmian trajectories corresponding to observables with discrete eigenvalues (in particular spin) are treated by extending the configuration space to the spectral space of the commutative algebra obtained by adding appropriate discrete observables to the position observables. Pauli's equation is treated as an example. A straightforward derivation of von Neumann's projection rule employing the Schrodinger-Bohm evolution of individual systems along their Bohmian trajectories is given. Some comments on the potential application of the formalism developed here to quantum mechanics of the universe are included.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4f20\u7edf\u91cf\u5b50\u529b\u5b66\u72b6\u6001-\u53ef\u89c2\u6d4b\u91cf\u6846\u67b6\u4e0e\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\u76f8\u7ed3\u5408\u7684\u5f62\u5f0f\u4f53\u7cfb\uff0c\u901a\u8fc7\u5f15\u5165\u968f\u673a\u8fc7\u7a0b\u548c\u6269\u5c55\u6784\u578b\u7a7a\u95f4\u6765\u5904\u7406\u81ea\u65cb\u7b49\u79bb\u6563\u53ef\u89c2\u6d4b\u91cf\u3002", "motivation": "\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\u867d\u7136\u80fd\u89e3\u51b3\u91cf\u5b50\u6d4b\u91cf\u95ee\u9898\uff0c\u4f46\u5728\u5904\u7406\u81ea\u65cb\u3001\u76f8\u5bf9\u8bba\u6027\u4ee5\u53ca\u4e0e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6846\u67b6\u7684\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u4e00\u81f4\u7684\u5f62\u5f0f\u4f53\u7cfb\uff0c\u5c06\u4f20\u7edf\u91cf\u5b50\u529b\u5b66\u6846\u67b6\u4e0e\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\u7684\u4f18\u70b9\u76f8\u7ed3\u5408\u3002", "method": "\u91c7\u7528\u859b\u5b9a\u8c14\u6ce2\u51fd\u6570\u7684\u7cfb\u7efc\u89e3\u91ca\uff0c\u5728\u6982\u7387\u7a7a\u95f4\u4e0a\u5f15\u5165\u4e0e\u6d77\u68ee\u5821\u4f4d\u7f6e\u7b97\u7b26\u5bf9\u5e94\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u51fa\u73bb\u59c6\u8f68\u8ff9\u7684\u5f15\u5bfc\u65b9\u7a0b\u3002\u901a\u8fc7\u6269\u5c55\u6784\u578b\u7a7a\u95f4\u5230\u8c31\u7a7a\u95f4\u6765\u5904\u7406\u79bb\u6563\u672c\u5f81\u503c\u7684\u53ef\u89c2\u6d4b\u91cf\uff08\u5982\u81ea\u65cb\uff09\uff0c\u5e76\u4ee5\u6ce1\u5229\u65b9\u7a0b\u4e3a\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u4f20\u7edf\u91cf\u5b50\u529b\u5b66\u72b6\u6001-\u53ef\u89c2\u6d4b\u91cf\u6846\u67b6\u4e0e\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\u6574\u5408\u7684\u5f62\u5f0f\u4f53\u7cfb\uff0c\u80fd\u591f\u5904\u7406\u8fde\u7eed\u548c\u79bb\u6563\u53ef\u89c2\u6d4b\u91cf\uff0c\u7ed9\u51fa\u4e86\u51af\u00b7\u8bfa\u4f9d\u66fc\u6295\u5f71\u89c4\u5219\u7684\u76f4\u63a5\u63a8\u5bfc\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5e94\u7528\u4e8e\u5b87\u5b99\u91cf\u5b50\u529b\u5b66\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u4e00\u81f4\u7684\u5f62\u5f0f\u4f53\u7cfb\uff0c\u5c06\u4f20\u7edf\u91cf\u5b50\u529b\u5b66\u6846\u67b6\u4e0e\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u540e\u8005\u5728\u81ea\u65cb\u5904\u7406\u548c\u4e0e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6574\u5408\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u6d4b\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07045", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07045", "abs": "https://arxiv.org/abs/2512.07045", "authors": ["Violetta Sharoglazova", "Marius Puplauskis", "Lotte Hof", "Jan Klaers"], "title": "From Quantum Chaos to Classical Chaos via Gain-Induced Measurement Dynamics in a Photon Gas", "comment": "7 pages, 4 figures", "summary": "How classical chaos emerges from quantum mechanics remains a central open question, as the unitary evolution of isolated quantum systems forbids exponential sensitivity to initial conditions. A key insight is that this quantum-classical link is provided by measurement processes. In this work, we identify gain competition in a chaotic photon gas as an operational quantum measurement that selects single motional modes from an initial superposition through stochastic, nonlinear amplification. We show that this mechanism naturally gives rise to classical chaotic behavior, most notably sensitivity to initial conditions. Our results provide a concrete physical mechanism for the quantum-classical transition in a chaotic system and demonstrate that essential aspects of quantum measurement-state projection, Born-rule-like selection, and irreversibility-can naturally emerge from intrinsic gain dynamics.", "AI": {"tldr": "\u91cf\u5b50\u6df7\u6c8c\u5149\u5b50\u6c14\u4f53\u4e2d\u7684\u589e\u76ca\u7ade\u4e89\u4f5c\u4e3a\u91cf\u5b50\u6d4b\u91cf\u673a\u5236\uff0c\u4ece\u521d\u59cb\u53e0\u52a0\u6001\u4e2d\u968f\u673a\u9009\u62e9\u5355\u6a21\uff0c\u81ea\u7136\u4ea7\u751f\u7ecf\u5178\u6df7\u6c8c\u884c\u4e3a", "motivation": "\u63a2\u7d22\u91cf\u5b50\u529b\u5b66\u5982\u4f55\u6d8c\u73b0\u7ecf\u5178\u6df7\u6c8c\u884c\u4e3a\uff0c\u89e3\u51b3\u91cf\u5b50\u7cfb\u7edf\u5982\u4f55\u4ea7\u751f\u5bf9\u521d\u59cb\u6761\u4ef6\u6307\u6570\u654f\u611f\u6027\u7684\u6838\u5fc3\u95ee\u9898", "method": "\u5229\u7528\u6df7\u6c8c\u5149\u5b50\u6c14\u4f53\u4e2d\u7684\u589e\u76ca\u7ade\u4e89\u4f5c\u4e3a\u91cf\u5b50\u6d4b\u91cf\u673a\u5236\uff0c\u901a\u8fc7\u968f\u673a\u975e\u7ebf\u6027\u653e\u5927\u4ece\u521d\u59cb\u53e0\u52a0\u6001\u4e2d\u9009\u62e9\u5355\u6a21", "result": "\u8be5\u673a\u5236\u81ea\u7136\u4ea7\u751f\u7ecf\u5178\u6df7\u6c8c\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5bf9\u521d\u59cb\u6761\u4ef6\u7684\u654f\u611f\u6027\uff0c\u4e3a\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50-\u7ecf\u5178\u8f6c\u53d8\u63d0\u4f9b\u4e86\u5177\u4f53\u7269\u7406\u673a\u5236", "conclusion": "\u589e\u76ca\u52a8\u529b\u5b66\u53ef\u4ee5\u81ea\u7136\u5730\u6d8c\u73b0\u91cf\u5b50\u6d4b\u91cf\u7684\u5173\u952e\u65b9\u9762\uff08\u6001\u6295\u5f71\u3001\u73bb\u6069\u89c4\u5219\u9009\u62e9\u3001\u4e0d\u53ef\u9006\u6027\uff09\uff0c\u4e3a\u91cf\u5b50-\u7ecf\u5178\u8fc7\u6e21\u63d0\u4f9b\u4e86\u5177\u4f53\u7269\u7406\u673a\u5236"}}
{"id": "2512.06533", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06533", "abs": "https://arxiv.org/abs/2512.06533", "authors": ["Ming Chen", "Sheng Tang", "Rong-Xi Tan", "Ziniu Li", "Jiacheng Chen", "Ke Xue", "Chao Qian"], "title": "Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning", "comment": null, "summary": "Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6539\u8fdb\u57fa\u4e8e\u89e3\u7801\u7684\u56de\u5f52\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u5217\u7ea7\u5956\u52b1\u6765\u589e\u5f3a\u6570\u503c\u9884\u6d4b\u7684\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u5728\u8868\u683c\u56de\u5f52\u548c\u4ee3\u7801\u5ea6\u91cf\u56de\u5f52\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u57fa\u4e8e\u89e3\u7801\u7684\u56de\u5f52\u5c06\u56de\u5f52\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5e8f\u5217\u751f\u6210\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u79bb\u6563token\u7ea7\u76ee\u6807\uff08\u5982\u4ea4\u53c9\u71b5\uff09\u4e0e\u8fde\u7eed\u6570\u503c\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0ctoken\u7ea7\u7ea6\u675f\u96be\u4ee5\u6355\u6349\u76ee\u6807\u503c\u7684\u5168\u5c40\u5e45\u5ea6\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u751f\u6210\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5e8f\u5217\u7ea7\u5956\u52b1\u6765\u5f3a\u5236\u5168\u5c40\u6570\u503c\u4e00\u81f4\u6027\uff0c\u5177\u4f53\u91c7\u7528ReMax\u548cGRPO\u7b49\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u5217\u7ea7\u4fe1\u53f7\u6765\u4f18\u5316\u89e3\u7801\u8fc7\u7a0b\u3002", "result": "\u5728\u8868\u683c\u56de\u5f52\u548c\u4ee3\u7801\u5ea6\u91cf\u56de\u5f52\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\uff08\u7279\u522b\u662f\u4f7f\u7528ReMax\u548cGRPO\uff09\u4e00\u81f4\u4f18\u4e8e\u6700\u5148\u8fdb\u7684token\u7ea7\u57fa\u7ebf\u548c\u4f20\u7edf\u56de\u5f52\u5934\uff0c\u663e\u793a\u51fa\u5f15\u5165\u5e8f\u5217\u7ea7\u4fe1\u53f7\u7684\u4f18\u52bf\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\u548c\u9884\u6d4b\u7cbe\u5ea6\uff0c\u786e\u7acb\u4e86\u57fa\u4e8e\u89e3\u7801\u7684\u56de\u5f52\u4f5c\u4e3a\u901a\u7528\u6570\u503c\u9884\u6d4b\u7684\u7a33\u5065\u4e14\u51c6\u786e\u7684\u8303\u5f0f\uff0c\u4e3a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u6570\u503c\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07048", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07048", "abs": "https://arxiv.org/abs/2512.07048", "authors": ["Matthias Ernzerhof", "Mohamed Loutis", "Pierre-Olivier Roy", "Didier Mayou"], "title": "The uncharted space of non-Hermitian solutions to the Hartree-Fock and Kohn-Sham equations", "comment": "This is the author's peer-reviewed accepted manuscript preprint version of the article published in The Journal of Chemical Physics", "summary": "Many problems in physical chemistry involve systems that are coupled to an environment, such as a molecule interacting with an adjacent surface, possibly resulting in meta-stable molecular states where electron density is transferred to the surface. Such systems can be described by non-Hermitian quantum mechanics (NHQM), where the Hamiltonian includes dissipative terms. Within NHQM, one can also formulate the Hartree-Fock (HF) and Kohn-Sham (KS) methods and, as in the conventional theory, an effective independent-particle picture is employed. The crucial observation of the present work is that even for systems that are not coupled to an environment, in the HF or KS equation a single electron is coupled to a bath of the remaining electrons which can act as an environment, opening up the possibility for the exchange of current density between the one-electron and the remaining N-1 electron system. The corresponding self-consistent states represent a new uncharted space of solutions to the HF and KS equations. We show that the additional solutions can have a physical interpretation and thus extend the range of problems HF and KS can be applied to. If open-system HF and KS calculations are performed, the new class of solutions is always encountered but this has also not been noted previously.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728Hartree-Fock\u548cKohn-Sham\u65b9\u7a0b\u4e2d\u5b58\u5728\u4e00\u7c7b\u65b0\u7684\u975e\u5384\u7c73\u7279\u89e3\uff0c\u8fd9\u4e9b\u89e3\u5bf9\u5e94\u5355\u7535\u5b50\u4e0e\u5176\u4f59N-1\u7535\u5b50\u7cfb\u7edf\u4e4b\u95f4\u7684\u7535\u6d41\u5bc6\u5ea6\u4ea4\u6362\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u91cf\u5b50\u5316\u5b66\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4\u3002", "motivation": "\u4f20\u7edf\u91cf\u5b50\u5316\u5b66\u65b9\u6cd5\u4e3b\u8981\u5904\u7406\u5c01\u95ed\u7cfb\u7edf\uff0c\u4f46\u8bb8\u591a\u7269\u7406\u5316\u5b66\u95ee\u9898\u6d89\u53ca\u7cfb\u7edf\u4e0e\u73af\u5883\u8026\u5408\uff08\u5982\u5206\u5b50\u4e0e\u8868\u9762\u76f8\u4e92\u4f5c\u7528\uff09\u3002\u4f5c\u8005\u53d1\u73b0\u5373\u4f7f\u5728\u65e0\u5916\u90e8\u73af\u5883\u8026\u5408\u7684\u7cfb\u7edf\u4e2d\uff0cHF\u548cKS\u65b9\u7a0b\u4e2d\u7684\u5355\u7535\u5b50\u4e0e\u5176\u4f59\u7535\u5b50\u4e4b\u95f4\u4e5f\u5b58\u5728\u7c7b\u4f3c\u73af\u5883\u8026\u5408\uff0c\u53ef\u80fd\u4ea7\u751f\u65b0\u7684\u7269\u7406\u72b6\u6001\u3002", "method": "\u91c7\u7528\u975e\u5384\u7c73\u7279\u91cf\u5b50\u529b\u5b66\u6846\u67b6\u91cd\u65b0\u8868\u8ff0Hartree-Fock\u548cKohn-Sham\u65b9\u6cd5\uff0c\u8003\u8651\u5355\u7535\u5b50\u4e0e\u5176\u4f59N-1\u7535\u5b50\u7cfb\u7edf\u4e4b\u95f4\u7684\u7535\u6d41\u5bc6\u5ea6\u4ea4\u6362\uff0c\u5bfb\u627e\u81ea\u6d3d\u65b9\u7a0b\u7684\u65b0\u89e3\u3002", "result": "\u53d1\u73b0\u4e86HF\u548cKS\u65b9\u7a0b\u4e2d\u4e00\u7c7b\u5148\u524d\u672a\u88ab\u6ce8\u610f\u7684\u65b0\u89e3\uff0c\u8fd9\u4e9b\u89e3\u5bf9\u5e94\u5f00\u653e\u7cfb\u7edf\u6761\u4ef6\u4e0b\u7684\u7269\u7406\u72b6\u6001\uff0c\u5728\u5f00\u653e\u7cfb\u7edf\u8ba1\u7b97\u4e2d\u603b\u662f\u4f1a\u51fa\u73b0\u8fd9\u7c7b\u89e3\u3002", "conclusion": "\u975e\u5384\u7c73\u7279HF\u548cKS\u65b9\u6cd5\u80fd\u591f\u63cf\u8ff0\u66f4\u5e7f\u6cdb\u7684\u7269\u7406\u5316\u5b66\u73b0\u8c61\uff0c\u5305\u62ec\u7535\u5b50\u5bc6\u5ea6\u8f6c\u79fb\u8fc7\u7a0b\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u91cf\u5b50\u5316\u5b66\u65b9\u6cd5\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u7814\u7a76\u5206\u5b50-\u8868\u9762\u76f8\u4e92\u4f5c\u7528\u7b49\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2512.06547", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.06547", "abs": "https://arxiv.org/abs/2512.06547", "authors": ["Xiaocan Li", "Shiliang Wu", "Zheng Shen"], "title": "A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation", "comment": null, "summary": "Decoupled loss has been a successful reinforcement learning (RL) algorithm to deal with the high data staleness under the asynchronous RL setting. Decoupled loss improves coupled-loss style of algorithms' (e.g., PPO, GRPO) learning stability by introducing a proximal policy to decouple the off-policy corrections (importance weight) from the controlling policy updates (trust region). However, the proximal policy requires an extra forward pass through the network at each training step, creating a computational bottleneck for large language models. We observe that since the proximal policy only serves as a trust region anchor between the behavior and target policies, we can approximate it through simple interpolation without explicit computation. We call this approach A-3PO (APproximated Proximal Policy Optimization). A-3PO eliminates this overhead, reducing training time by 18% while maintaining comparable performance. Code & off-the-shelf example are available at: https://github.com/inclusionAI/AReaL/blob/main/docs/algorithms/prox_approx.md", "AI": {"tldr": "A-3PO\u901a\u8fc7\u8fd1\u4f3c\u8ba1\u7b97\u89e3\u8026\u635f\u5931\u4e2d\u7684\u8fd1\u7aef\u7b56\u7565\uff0c\u6d88\u9664\u4e86\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u4e2d\u989d\u5916\u7684\u524d\u5411\u4f20\u64ad\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c1118%\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u89e3\u8026\u635f\u5931\u5728\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u4e2d\u80fd\u5904\u7406\u6570\u636e\u9648\u65e7\u6027\u95ee\u9898\uff0c\u4f46\u5176\u4e2d\u7684\u8fd1\u7aef\u7b56\u7565\u9700\u8981\u5728\u6bcf\u4e2a\u8bad\u7ec3\u6b65\u9aa4\u4e2d\u8fdb\u884c\u989d\u5916\u7684\u7f51\u7edc\u524d\u5411\u4f20\u64ad\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9020\u6210\u8ba1\u7b97\u74f6\u9888\u3002", "method": "\u63d0\u51faA-3PO\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u63d2\u503c\u8fd1\u4f3c\u8fd1\u7aef\u7b56\u7565\uff0c\u907f\u514d\u663e\u5f0f\u8ba1\u7b97\u3002\u8fd1\u7aef\u7b56\u7565\u4ec5\u4f5c\u4e3a\u884c\u4e3a\u7b56\u7565\u548c\u76ee\u6807\u7b56\u7565\u4e4b\u95f4\u7684\u4fe1\u4efb\u533a\u57df\u951a\u70b9\uff0c\u53ef\u4ee5\u901a\u8fc7\u63d2\u503c\u6709\u6548\u8fd1\u4f3c\u3002", "result": "A-3PO\u6d88\u9664\u4e86\u8fd1\u7aef\u7b56\u7565\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u51cf\u5c1118%\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "A-3PO\u901a\u8fc7\u8fd1\u4f3c\u8fd1\u7aef\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u4e2d\u89e3\u8026\u635f\u5931\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2512.07055", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07055", "abs": "https://arxiv.org/abs/2512.07055", "authors": ["Nur Fadhillah Binti Rahimi", "Norman Koo Tze Wei", "Daniel Schumayer", "Christopher Gies", "Leong Chuan Kwek", "David. A. W. Hutchinson"], "title": "Timing quantum emission: coherence, superradiance, and entanglement in order", "comment": "5 pages, 5 figures", "summary": "We investigate the short-term temporal dynamics of superradiance in closely spaced quantum emitters. Building on Dicke's 1954 framework, we analyze the sequential emergence of coherence, superradiance, and entanglement, revealing a distinct temporal hierarchy in their extremal values: relative coherence develops first, followed by the peak of correlated emission, then minimal entanglement, and finally correlated dephasing. These findings suggest that enhanced relative coherence initiates correlated emission and when correlated dephasing is negligible, entanglement and correlated emission become tightly linked in time.", "AI": {"tldr": "\u7814\u7a76\u7d27\u5bc6\u6392\u5217\u91cf\u5b50\u53d1\u5c04\u4f53\u7684\u8d85\u8f90\u5c04\u77ed\u671f\u65f6\u95f4\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u76f8\u5e72\u6027\u3001\u8d85\u8f90\u5c04\u548c\u7ea0\u7f20\u4e4b\u95f4\u5b58\u5728\u660e\u786e\u7684\u65f6\u95f4\u5c42\u6b21\uff1a\u76f8\u5bf9\u76f8\u5e72\u6027\u6700\u5148\u51fa\u73b0\uff0c\u7136\u540e\u662f\u76f8\u5173\u53d1\u5c04\u5cf0\u503c\uff0c\u63a5\u7740\u662f\u6700\u5c0f\u7ea0\u7f20\uff0c\u6700\u540e\u662f\u76f8\u5173\u9000\u76f8\u5e72\u3002", "motivation": "\u57fa\u4e8eDicke 1954\u5e74\u7684\u6846\u67b6\uff0c\u7814\u7a76\u7d27\u5bc6\u6392\u5217\u91cf\u5b50\u53d1\u5c04\u4f53\u4e2d\u8d85\u8f90\u5c04\u7684\u77ed\u671f\u65f6\u95f4\u52a8\u529b\u5b66\uff0c\u63a2\u7d22\u76f8\u5e72\u6027\u3001\u8d85\u8f90\u5c04\u548c\u7ea0\u7f20\u4e4b\u95f4\u7684\u65f6\u95f4\u6f14\u5316\u5173\u7cfb\u3002", "method": "\u5728Dicke\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u5206\u6790\u7d27\u5bc6\u6392\u5217\u91cf\u5b50\u53d1\u5c04\u4f53\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u7814\u7a76\u76f8\u5bf9\u76f8\u5e72\u6027\u3001\u76f8\u5173\u53d1\u5c04\u3001\u7ea0\u7f20\u548c\u76f8\u5173\u9000\u76f8\u5e72\u7684\u987a\u5e8f\u51fa\u73b0\u8fc7\u7a0b\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u660e\u786e\u7684\u65f6\u95f4\u5c42\u6b21\uff1a\u76f8\u5bf9\u76f8\u5e72\u6027\u6700\u5148\u53d1\u5c55\uff0c\u968f\u540e\u662f\u76f8\u5173\u53d1\u5c04\u5cf0\u503c\uff0c\u7136\u540e\u662f\u6700\u5c0f\u7ea0\u7f20\uff0c\u6700\u540e\u662f\u76f8\u5173\u9000\u76f8\u5e72\u3002\u589e\u5f3a\u7684\u76f8\u5bf9\u76f8\u5e72\u6027\u4f1a\u5f15\u53d1\u76f8\u5173\u53d1\u5c04\uff0c\u5f53\u76f8\u5173\u9000\u76f8\u5e72\u53ef\u5ffd\u7565\u65f6\uff0c\u7ea0\u7f20\u548c\u76f8\u5173\u53d1\u5c04\u5728\u65f6\u95f4\u4e0a\u7d27\u5bc6\u5173\u8054\u3002", "conclusion": "\u7d27\u5bc6\u6392\u5217\u91cf\u5b50\u53d1\u5c04\u4f53\u7684\u8d85\u8f90\u5c04\u8fc7\u7a0b\u5b58\u5728\u660e\u786e\u7684\u65f6\u95f4\u5c42\u6b21\uff0c\u76f8\u5bf9\u76f8\u5e72\u6027\u5728\u5f15\u53d1\u76f8\u5173\u53d1\u5c04\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u5f53\u9000\u76f8\u5e72\u6548\u5e94\u8f83\u5c0f\u65f6\uff0c\u7ea0\u7f20\u548c\u76f8\u5173\u53d1\u5c04\u8868\u73b0\u51fa\u7d27\u5bc6\u7684\u65f6\u95f4\u5173\u8054\u3002"}}
{"id": "2512.06563", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06563", "abs": "https://arxiv.org/abs/2512.06563", "authors": ["Max Y. Ma", "Gen-Hua Shi"], "title": "Deep Manifold Part 2: Neural Network Mathematics", "comment": null, "summary": "This work develops the global equations of neural networks through stacked piecewise manifolds, fixed-point theory, and boundary-conditioned iteration. Once fixed coordinates and operators are removed, a neural network appears as a learnable numerical computation shaped by manifold complexity, high-order nonlinearity, and boundary conditions. Real-world data impose strong data complexity, near-infinite scope, scale, and minibatch fragmentation, while training dynamics produce learning complexity through shifting node covers, curvature accumulation, and the rise and decay of plasticity. These forces constrain learnability and explain why capability emerges only when fixed-point regions stabilize. Neural networks do not begin with fixed points; they construct them through residual-driven iteration. This perspective clarifies the limits of monolithic models under geometric and data-induced plasticity and motivates architectures and federated systems that distribute manifold complexity across many elastic models, forming a coherent world-modeling framework grounded in geometry, algebra, fixed points, and real-data complexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4ece\u6d41\u5f62\u51e0\u4f55\u3001\u4e0d\u52a8\u70b9\u7406\u8bba\u548c\u8fb9\u754c\u6761\u4ef6\u8fed\u4ee3\u7684\u89d2\u5ea6\u91cd\u65b0\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u89c6\u4e3a\u7531\u6570\u636e\u590d\u6742\u6027\u548c\u5b66\u4e60\u52a8\u6001\u5851\u9020\u7684\u53ef\u5b66\u4e60\u6570\u503c\u8ba1\u7b97\uff0c\u800c\u975e\u56fa\u5b9a\u5750\u6807\u548c\u7b97\u5b50\u7684\u7ec4\u5408\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u57fa\u4e8e\u56fa\u5b9a\u5750\u6807\u548c\u7b97\u5b50\uff0c\u65e0\u6cd5\u5145\u5206\u89e3\u91ca\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u7684\u9ad8\u590d\u6742\u6027\u3001\u65e0\u9650\u8303\u56f4\u548c\u8bad\u7ec3\u52a8\u6001\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u51e0\u4f55\u548c\u4e0d\u52a8\u70b9\u7406\u8bba\uff0c\u5efa\u7acb\u66f4\u7b26\u5408\u5b9e\u9645\u6570\u636e\u548c\u5b66\u4e60\u8fc7\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u6846\u67b6\u3002", "method": "\u91c7\u7528\u5806\u53e0\u5206\u6bb5\u6d41\u5f62\u3001\u4e0d\u52a8\u70b9\u7406\u8bba\u548c\u8fb9\u754c\u6761\u4ef6\u8fed\u4ee3\u7684\u65b9\u6cd5\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u89c6\u4e3a\u7531\u6570\u636e\u590d\u6742\u6027\u3001\u5b66\u4e60\u52a8\u6001\u548c\u8fb9\u754c\u6761\u4ef6\u5171\u540c\u5851\u9020\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5f3a\u8c03\u4e0d\u52a8\u70b9\u533a\u57df\u5728\u80fd\u529b\u6d8c\u73b0\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "result": "\u63d0\u51fa\u795e\u7ecf\u7f51\u7edc\u4e0d\u662f\u4ece\u4e0d\u52a8\u70b9\u5f00\u59cb\uff0c\u800c\u662f\u901a\u8fc7\u6b8b\u5dee\u9a71\u52a8\u8fed\u4ee3\u6784\u5efa\u4e0d\u52a8\u70b9\u3002\u53ea\u6709\u5f53\u4e0d\u52a8\u70b9\u533a\u57df\u7a33\u5b9a\u65f6\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u80fd\u529b\u624d\u4f1a\u6d8c\u73b0\u3002\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5355\u4e00\u6a21\u578b\u5728\u51e0\u4f55\u548c\u6570\u636e\u8bf1\u5bfc\u53ef\u5851\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "conclusion": "\u8be5\u89c6\u89d2\u63ed\u793a\u4e86\u5355\u4e00\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6fc0\u52b1\u8bbe\u8ba1\u5206\u5e03\u5f0f\u6d41\u5f62\u590d\u6742\u6027\u7684\u67b6\u6784\u548c\u8054\u90a6\u7cfb\u7edf\uff0c\u5f62\u6210\u57fa\u4e8e\u51e0\u4f55\u3001\u4ee3\u6570\u3001\u4e0d\u52a8\u70b9\u548c\u771f\u5b9e\u6570\u636e\u590d\u6742\u6027\u7684\u8fde\u8d2f\u4e16\u754c\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2512.07057", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.07057", "abs": "https://arxiv.org/abs/2512.07057", "authors": ["Min Ye", "Dave Wecker", "Nicolas Delfosse"], "title": "Beam search decoder for quantum LDPC codes", "comment": null, "summary": "We propose a decoder for quantum low density parity check (LDPC) codes based on a beam search heuristic guided by belief propagation (BP). Our beam search decoder applies to all quantum LDPC codes and achieves different speed-accuracy tradeoffs by tuning its parameters such as the beam width. We perform numerical simulations under circuit level noise for the $[[144, 12, 12]]$ bivariate bicycle (BB) code at noise rate $p=10^{-3}$ to estimate the logical error rate and the 99.9 percentile runtime and we compare with the BP-OSD decoder which has been the default quantum LDPC decoder for the past six years. A variant of our beam search decoder with a beam width of 64 achieves a $17\\times$ reduction in logical error rate. With a beam width of 8, we reach the same logical error rate as BP-OSD with a $26.2\\times$ reduction in the 99.9 percentile runtime. We identify the beam search decoder with beam width of 32 as a promising candidate for trapped ion architectures because it achieves a $5.6\\times$ reduction in logical error rate with a 99.9 percentile runtime per syndrome extraction round below 1ms at $p=5 \\times10^{-4}$. Remarkably, this is achieved in software on a single core, without any parallelization or specialized hardware (FPGA, ASIC), suggesting one might only need three 32-core CPUs to decode a trapped ion quantum computer with 1000 logical qubits.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce2\u675f\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u91cf\u5b50LDPC\u7801\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u8c03\u6574\u6ce2\u675f\u5bbd\u5ea6\u5b9e\u73b0\u901f\u5ea6-\u51c6\u786e\u7387\u6743\u8861\uff0c\u5728\u7279\u5b9a\u53c2\u6570\u4e0b\u76f8\u6bd4BP-OSD\u89e3\u7801\u5668\u663e\u8457\u964d\u4f4e\u903b\u8f91\u9519\u8bef\u7387\u6216\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50LDPC\u7801\u89e3\u7801\u5668\uff08\u5982BP-OSD\uff09\u5728\u6027\u80fd\u548c\u901f\u5ea6\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u89e3\u7801\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u5728\u901f\u5ea6\u548c\u51c6\u786e\u7387\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce2\u675f\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u89e3\u7801\u5668\uff0c\u4f7f\u7528\u7f6e\u4fe1\u4f20\u64ad\uff08BP\uff09\u4f5c\u4e3a\u5f15\u5bfc\uff0c\u9002\u7528\u4e8e\u6240\u6709\u91cf\u5b50LDPC\u7801\u3002\u901a\u8fc7\u8c03\u6574\u6ce2\u675f\u5bbd\u5ea6\u7b49\u53c2\u6570\u5b9e\u73b0\u4e0d\u540c\u7684\u901f\u5ea6-\u51c6\u786e\u7387\u6743\u8861\u3002", "result": "\u5728[[144,12,12]]\u53cc\u53d8\u91cf\u81ea\u884c\u8f66\u7801\u7684\u7535\u8def\u7ea7\u566a\u58f0\u6a21\u62df\u4e2d\uff1a\u6ce2\u675f\u5bbd\u5ea664\u65f6\u903b\u8f91\u9519\u8bef\u7387\u964d\u4f4e17\u500d\uff1b\u6ce2\u675f\u5bbd\u5ea68\u65f6\u8fbe\u5230\u4e0eBP-OSD\u76f8\u540c\u7684\u903b\u8f91\u9519\u8bef\u7387\uff0c\u4f4699.9\u767e\u5206\u4f4d\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1126.2\u500d\uff1b\u6ce2\u675f\u5bbd\u5ea632\u65f6\u903b\u8f91\u9519\u8bef\u7387\u964d\u4f4e5.6\u500d\uff0c\u8fd0\u884c\u65f6\u95f4\u4f4e\u4e8e1ms\uff0c\u9002\u5408\u79bb\u5b50\u9631\u67b6\u6784\u3002", "conclusion": "\u6ce2\u675f\u641c\u7d22\u89e3\u7801\u5668\u4e3a\u91cf\u5b50LDPC\u7801\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u901f\u5ea6-\u51c6\u786e\u7387\u6743\u8861\u65b9\u6848\uff0c\u5728\u8f6f\u4ef6\u5355\u6838\u4e0a\u5373\u53ef\u5b9e\u73b0\u9ad8\u6027\u80fd\u89e3\u7801\uff0c\u6709\u671b\u4ec5\u7528\u4e09\u4e2a32\u6838CPU\u89e3\u78011000\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u7684\u79bb\u5b50\u9631\u91cf\u5b50\u8ba1\u7b97\u673a\u3002"}}
{"id": "2512.06582", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.06582", "abs": "https://arxiv.org/abs/2512.06582", "authors": ["Isaac Kofi Nti"], "title": "QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling", "comment": null, "summary": "Recurrent neural architectures such as LSTM and GRU remain widely used in sequence modeling, but they continue to face two core limitations: redundant gate-specific parameters and reduced ability to retain information across long temporal distances. This paper introduces the Quantum-Leap LSTM (QL-LSTM), a recurrent architecture designed to address both challenges through two independent components. The Parameter-Shared Unified Gating mechanism replaces all gate-specific transformations with a single shared weight matrix, reducing parameters by approximately 48 percent while preserving full gating behavior. The Hierarchical Gated Recurrence with Additive Skip Connections component adds a multiplication-free pathway that improves long-range information flow and reduces forget-gate degradation. We evaluate QL-LSTM on sentiment classification using the IMDB dataset with extended document lengths, comparing it to LSTM, GRU, and BiLSTM reference models. QL-LSTM achieves competitive accuracy while using substantially fewer parameters. Although the PSUG and HGR-ASC components are more efficient per time step, the current prototype remains limited by the inherent sequential nature of recurrent models and therefore does not yet yield wall-clock speed improvements without further kernel-level optimization.", "AI": {"tldr": "QL-LSTM\u901a\u8fc7\u53c2\u6570\u5171\u4eab\u7edf\u4e00\u95e8\u63a7\u548c\u5206\u5c42\u95e8\u63a7\u9012\u5f52\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u5728\u51cf\u5c1148%\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRNN\u53c2\u6570\u5197\u4f59\u548c\u957f\u8ddd\u79bb\u4fe1\u606f\u4fdd\u7559\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfLSTM\u548cGRU\u7b49\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u9650\u5236\uff1a1\uff09\u95e8\u63a7\u673a\u5236\u4e2d\u7684\u53c2\u6570\u5197\u4f59\u95ee\u9898\uff0c\u6bcf\u4e2a\u95e8\u90fd\u6709\u72ec\u7acb\u7684\u53c2\u6570\u77e9\u9635\uff1b2\uff09\u957f\u8ddd\u79bb\u4fe1\u606f\u4fdd\u7559\u80fd\u529b\u4e0b\u964d\uff0c\u5bb9\u6613\u53d1\u751f\u9057\u5fd8\u95e8\u9000\u5316\u3002", "method": "\u63d0\u51faQL-LSTM\u67b6\u6784\uff0c\u5305\u542b\u4e24\u4e2a\u72ec\u7acb\u7ec4\u4ef6\uff1a1\uff09\u53c2\u6570\u5171\u4eab\u7edf\u4e00\u95e8\u63a7\u673a\u5236\uff0c\u7528\u5355\u4e00\u5171\u4eab\u6743\u91cd\u77e9\u9635\u66ff\u4ee3\u6240\u6709\u95e8\u7279\u5b9a\u53d8\u6362\uff1b2\uff09\u5206\u5c42\u95e8\u63a7\u9012\u5f52\u4e0e\u52a0\u6cd5\u8df3\u8dc3\u8fde\u63a5\uff0c\u6dfb\u52a0\u65e0\u4e58\u6cd5\u8def\u5f84\u6539\u5584\u957f\u8ddd\u79bb\u4fe1\u606f\u6d41\u3002", "result": "\u5728IMDB\u6570\u636e\u96c6\u7684\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cQL-LSTM\u5728\u663e\u8457\u51cf\u5c11\u53c2\u6570\uff08\u7ea648%\uff09\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u7ade\u4e89\u6027\u51c6\u786e\u7387\u3002\u4f46\u53d7\u9650\u4e8e\u5faa\u73af\u6a21\u578b\u7684\u987a\u5e8f\u7279\u6027\uff0c\u5f53\u524d\u539f\u578b\u5c1a\u672a\u5b9e\u73b0\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u6539\u8fdb\u3002", "conclusion": "QL-LSTM\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRNN\u7684\u53c2\u6570\u5197\u4f59\u548c\u957f\u8ddd\u79bb\u4fe1\u606f\u4fdd\u7559\u95ee\u9898\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u6838\u7ea7\u4f18\u5316\u624d\u80fd\u5728\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u4e0a\u83b7\u5f97\u6539\u8fdb\u3002"}}
{"id": "2512.07095", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07095", "abs": "https://arxiv.org/abs/2512.07095", "authors": ["Prachi Garg", "Danqing Wang", "Hong X. Tang", "Baishakhi Mazumder"], "title": "Hidden Structural Variants in ALD NbN Superconducting Trilayers Revealed by Atomistic Analysis", "comment": null, "summary": "Microscopic inhomogeneity within superconducting films is a critical bottleneck hindering the performance and scalability of quantum circuits. All-nitride Josephson Junctions (JJs) have attracted substantial attention for their potential to provide enhanced coherence times and enable higher temperature operation. However, their performance is often limited by local variations caused by polymorphism, impurities, and interface quality. This work diagnoses atomic-scale limitations preventing superconducting NbN/AlN/NbN JJs from reaching their full potential. Electrical measurements reveal suppressed critical current density and soft onset of quasiparticle current. However, inverse proportionality between resistance and junction area confirms homogenous barrier thickness. This isolates structural and chemical variations in electrodes and barrier as the source of performance limitation. The observed characteristics are attributed to complex materials problems: NbN polymorphism, phase coexistence, and oxygen impurities. Using advanced microscopy and machine learning integrated approach, nanoscale inclusions of epsilon-Nb2N2 are found to coexist within dominant delta-NbN electrodes. DC performance of JJs may be affected by these defects, leading to unresolved supercurrent and soft transition to normal state. By identifying specific atomic scale defects, tracing its origin to initial film nucleation, and linking to its detrimental electrical signature, this work establishes a material-to-device correlation and provides targeted strategy for phase engineering towards reproducible, high coherence and scalable quantum devices.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5148\u8fdb\u663e\u5fae\u6280\u672f\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e86NbN/AlN/NbN\u7ea6\u745f\u592b\u68ee\u7ed3\u4e2d\u9650\u5236\u6027\u80fd\u7684\u539f\u5b50\u5c3a\u5ea6\u7f3a\u9677\uff0c\u53d1\u73b0\u7535\u6781\u4e2d\u03b5-Nb\u2082N\u2082\u7eb3\u7c73\u5939\u6742\u7269\u4e0e\u03b4-NbN\u76f8\u5171\u5b58\u662f\u5bfc\u81f4\u8d85\u5bfc\u7535\u6d41\u6291\u5236\u548c\u8f6f\u8f6c\u53d8\u7684\u4e3b\u8981\u539f\u56e0\u3002", "motivation": "\u8d85\u5bfc\u8584\u819c\u7684\u5fae\u89c2\u4e0d\u5747\u5300\u6027\u662f\u9650\u5236\u91cf\u5b50\u7535\u8def\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u7684\u5173\u952e\u74f6\u9888\u3002\u5168\u6c2e\u5316\u7269\u7ea6\u745f\u592b\u68ee\u7ed3\u56e0\u5176\u6f5c\u5728\u7684\u9ad8\u76f8\u5e72\u65f6\u95f4\u548c\u9ad8\u6e29\u64cd\u4f5c\u80fd\u529b\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u5176\u6027\u80fd\u5e38\u53d7\u591a\u6676\u578b\u3001\u6742\u8d28\u548c\u754c\u9762\u8d28\u91cf\u7b49\u5c40\u90e8\u53d8\u5316\u9650\u5236\u3002", "method": "\u7ed3\u5408\u7535\u5b66\u6d4b\u91cf\uff08\u4e34\u754c\u7535\u6d41\u5bc6\u5ea6\u3001\u51c6\u7c92\u5b50\u7535\u6d41\uff09\u548c\u5148\u8fdb\u663e\u5fae\u6280\u672f\uff08\u8bc6\u522b\u7eb3\u7c73\u5c3a\u5ea6\u7f3a\u9677\uff09\uff0c\u91c7\u7528\u673a\u5668\u5b66\u4e60\u96c6\u6210\u65b9\u6cd5\u5206\u6790NbN\u7535\u6781\u4e2d\u7684\u76f8\u5171\u5b58\u73b0\u8c61\uff0c\u5efa\u7acb\u6750\u6599\u7f3a\u9677\u4e0e\u5668\u4ef6\u6027\u80fd\u7684\u5173\u8054\u3002", "result": "\u7535\u5b66\u6d4b\u91cf\u663e\u793a\u4e34\u754c\u7535\u6d41\u5bc6\u5ea6\u88ab\u6291\u5236\u4e14\u51c6\u7c92\u5b50\u7535\u6d41\u5448\u8f6f\u8f6c\u53d8\uff0c\u4f46\u7535\u963b\u4e0e\u7ed3\u9762\u79ef\u7684\u53cd\u6bd4\u5173\u7cfb\u8bc1\u5b9e\u52bf\u5792\u539a\u5ea6\u5747\u5300\u3002\u7814\u7a76\u53d1\u73b0\u7535\u6781\u4e2d\u03b5-Nb\u2082N\u2082\u7eb3\u7c73\u5939\u6742\u7269\u4e0e\u4e3b\u8981\u03b4-NbN\u76f8\u5171\u5b58\uff0c\u8fd9\u4e9b\u7f3a\u9677\u5bfc\u81f4\u672a\u89e3\u6790\u7684\u8d85\u7535\u6d41\u548c\u5411\u6b63\u5e38\u6001\u7684\u8f6f\u8f6c\u53d8\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u7279\u5b9a\u539f\u5b50\u5c3a\u5ea6\u7f3a\u9677\u3001\u8ffd\u6eaf\u5176\u8d77\u6e90\u4e8e\u8584\u819c\u521d\u59cb\u6210\u6838\u8fc7\u7a0b\uff0c\u5e76\u5c06\u5176\u4e0e\u6709\u5bb3\u7535\u5b66\u7279\u5f81\u5173\u8054\uff0c\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u6750\u6599\u4e0e\u5668\u4ef6\u7684\u76f8\u5173\u6027\uff0c\u4e3a\u76f8\u5de5\u7a0b\u63d0\u4f9b\u4e86\u9488\u5bf9\u6027\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u53ef\u91cd\u590d\u3001\u9ad8\u76f8\u5e72\u548c\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u5668\u4ef6\u3002"}}
{"id": "2512.06592", "categories": ["cs.LG", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2512.06592", "abs": "https://arxiv.org/abs/2512.06592", "authors": ["James King", "Lewis Cornwall", "Andrei Cristian Nica", "James Day", "Aaron Sim", "Neil Dalchau", "Lilly Wollman", "Joshua Meyers"], "title": "On fine-tuning Boltz-2 for protein-protein affinity prediction", "comment": "MLSB 2025", "summary": "Accurate prediction of protein-protein binding affinity is vital for understanding molecular interactions and designing therapeutics. We adapt Boltz-2, a state-of-the-art structure-based protein-ligand affinity predictor, for protein-protein affinity regression and evaluate it on two datasets, TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based alternatives in both small- and larger-scale data regimes. Combining embeddings from Boltz-2-PPI with sequence-based embeddings yields complementary improvements, particularly for weaker sequence models, suggesting different signals are learned by sequence- and structure-based models. Our results echo known biases associated with training with structural data and suggest that current structure-based representations are not primed for performant affinity prediction.", "AI": {"tldr": "\u5c06\u86cb\u767d\u8d28-\u914d\u4f53\u4eb2\u548c\u529b\u9884\u6d4b\u6a21\u578bBoltz-2\u9002\u914d\u7528\u4e8e\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\u56de\u5f52\uff0c\u4f46\u5728TCR3d\u548cPPB-affinity\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u5982\u5e8f\u5217\u6a21\u578b\uff0c\u7ed3\u5408\u4e24\u8005\u53ef\u4e92\u8865\u63d0\u5347", "motivation": "\u51c6\u786e\u9884\u6d4b\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u7ed3\u5408\u4eb2\u548c\u529b\u5bf9\u4e8e\u7406\u89e3\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u548c\u8bbe\u8ba1\u6cbb\u7597\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u8bc4\u4f30\u7ed3\u6784\u57fa\u65b9\u6cd5\u5728\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\u9884\u6d4b\u4e2d\u7684\u8868\u73b0", "method": "\u5c06\u6700\u5148\u8fdb\u7684\u7ed3\u6784\u57fa\u86cb\u767d\u8d28-\u914d\u4f53\u4eb2\u548c\u529b\u9884\u6d4b\u6a21\u578bBoltz-2\u9002\u914d\u4e3a\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\u56de\u5f52\u6a21\u578b(Boltz-2-PPI)\uff0c\u5728TCR3d\u548cPPB-affinity\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5e8f\u5217\u57fa\u65b9\u6cd5\u6bd4\u8f83\uff0c\u8fd8\u5c1d\u8bd5\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u5d4c\u5165\u8868\u793a", "result": "\u5c3d\u7ba1\u7ed3\u6784\u51c6\u786e\u6027\u9ad8\uff0c\u4f46Boltz-2-PPI\u5728\u5c0f\u89c4\u6a21\u548c\u8f83\u5927\u89c4\u6a21\u6570\u636e\u4f53\u7cfb\u4e0b\u90fd\u8868\u73b0\u4e0d\u5982\u5e8f\u5217\u57fa\u66ff\u4ee3\u65b9\u6cd5\u3002\u5c06Boltz-2-PPI\u7684\u5d4c\u5165\u4e0e\u5e8f\u5217\u57fa\u5d4c\u5165\u7ed3\u5408\u53ef\u4ea7\u751f\u4e92\u8865\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5f31\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u8868\u660e\u5e8f\u5217\u548c\u7ed3\u6784\u57fa\u6a21\u578b\u5b66\u4e60\u4e86\u4e0d\u540c\u7684\u4fe1\u53f7", "conclusion": "\u7ed3\u679c\u547c\u5e94\u4e86\u4e0e\u7ed3\u6784\u6570\u636e\u8bad\u7ec3\u76f8\u5173\u7684\u5df2\u77e5\u504f\u5dee\uff0c\u8868\u660e\u5f53\u524d\u7684\u7ed3\u6784\u57fa\u8868\u793a\u5c1a\u672a\u51c6\u5907\u597d\u7528\u4e8e\u9ad8\u6027\u80fd\u7684\u4eb2\u548c\u529b\u9884\u6d4b\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u7ed3\u6784\u57fa\u65b9\u6cd5"}}
{"id": "2512.07101", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.07101", "abs": "https://arxiv.org/abs/2512.07101", "authors": ["Emily Adlam"], "title": "Wigner's Frame", "comment": null, "summary": "This article suggests that thinking about the role of reference frames can provide new insight into Extended Wigner's Friend scenarios. This involves appealing to symmetries to make a principled distinction between properties of a system which are meaningful only relative to an external reference system and properties which are meaningful without further relativization. Thus we may propose that there are always well-defined facts about what observers have observed, but there are not necessarily well-defined facts about the relations between their reference frames, so there will not always exist a joint distribution over their outcomes which can meaningfully be compared to the predictions of quantum mechanics. In addition, this approach also offers a general argument against the idea that there should be a regress of relativization.", "AI": {"tldr": "\u901a\u8fc7\u53c2\u8003\u7cfb\u89c6\u89d2\u5206\u6790\u6269\u5c55\u7ef4\u683c\u7eb3\u670b\u53cb\u573a\u666f\uff0c\u533a\u5206\u7cfb\u7edf\u5c5e\u6027\u7684\u76f8\u5bf9\u6027\u4e0e\u7edd\u5bf9\u6027\uff0c\u6311\u6218\u91cf\u5b50\u529b\u5b66\u4e2d\u89c2\u5bdf\u8005\u7ed3\u679c\u8054\u5408\u5206\u5e03\u7684\u5fc5\u7136\u6027", "motivation": "\u4e3a\u6269\u5c55\u7ef4\u683c\u7eb3\u670b\u53cb\u573a\u666f\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u89c6\u89d2\uff0c\u901a\u8fc7\u53c2\u8003\u7cfb\u6982\u5ff5\u89e3\u51b3\u91cf\u5b50\u529b\u5b66\u4e2d\u89c2\u5bdf\u8005\u76f8\u5bf9\u6027\u95ee\u9898\uff0c\u907f\u514d\u65e0\u9650\u76f8\u5bf9\u5316\u56de\u5f52", "method": "\u8fd0\u7528\u5bf9\u79f0\u6027\u539f\u7406\u533a\u5206\u7cfb\u7edf\u5c5e\u6027\u7684\u76f8\u5bf9\u6027\u4e0e\u7edd\u5bf9\u6027\uff0c\u63d0\u51fa\u89c2\u5bdf\u8005\u89c2\u6d4b\u4e8b\u5b9e\u59cb\u7ec8\u660e\u786e\uff0c\u4f46\u53c2\u8003\u7cfb\u95f4\u5173\u7cfb\u4e0d\u4e00\u5b9a\u660e\u786e\u7684\u7406\u8bba\u6846\u67b6", "result": "\u89c2\u5bdf\u8005\u89c2\u6d4b\u7ed3\u679c\u5b58\u5728\u660e\u786e\u4e8b\u5b9e\uff0c\u4f46\u53c2\u8003\u7cfb\u95f4\u5173\u7cfb\u53ef\u80fd\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u4e0d\u4e00\u5b9a\u5b58\u5728\u53ef\u6bd4\u8f83\u7684\u8054\u5408\u5206\u5e03\uff0c\u53cd\u5bf9\u65e0\u9650\u76f8\u5bf9\u5316\u56de\u5f52", "conclusion": "\u53c2\u8003\u7cfb\u5206\u6790\u4e3a\u6269\u5c55\u7ef4\u683c\u7eb3\u670b\u53cb\u573a\u666f\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u533a\u5206\u76f8\u5bf9\u4e0e\u7edd\u5bf9\u5c5e\u6027\uff0c\u89e3\u51b3\u91cf\u5b50\u89c2\u6d4b\u4e2d\u7684\u76f8\u5bf9\u6027\u95ee\u9898"}}
{"id": "2512.06607", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06607", "abs": "https://arxiv.org/abs/2512.06607", "authors": ["Humzah Merchant", "Bradford Levy"], "title": "A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs", "comment": null, "summary": "Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u63a8\u7406\u65f6\u8c03\u6574\u5927\u6a21\u578blogits\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u5bf9\u4e13\u95e8\u7684\u5c0f\u6a21\u578b\u6765\u79fb\u9664\u91d1\u878d\u9884\u6d4b\u4e2d\u7684\u524d\u77bb\u504f\u5dee\uff0c\u907f\u514d\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u5c06LLMs\u5e94\u7528\u4e8e\u91d1\u878d\u9884\u6d4b\u4efb\u52a1\u65f6\u9762\u4e34\u524d\u77bb\u504f\u5dee\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u5927\u6a21\u578b\u5728\u957f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u65e0\u6cd5\u8fdb\u884c\u91d1\u878d\u4e2d\u5e38\u7528\u7684\u56de\u6d4b\uff0c\u800c\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u524d\u6cbf\u6a21\u578b\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u8c03\u6574\u5927\u57fa\u7840\u6a21\u578b\u7684logits\u6765\u5f15\u5bfc\u751f\u6210\uff0c\u4f7f\u7528\u4e00\u5bf9\u4e13\u95e8\u7684\u5c0f\u6a21\u578b\uff1a\u4e00\u4e2a\u5728\u8981\u9057\u5fd8\u7684\u4fe1\u606f\u4e0a\u5fae\u8c03\uff0c\u53e6\u4e00\u4e2a\u5728\u8981\u4fdd\u7559\u7684\u4fe1\u606f\u4e0a\u5fae\u8c03\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u79fb\u9664\u9010\u5b57\u548c\u8bed\u4e49\u77e5\u8bc6\uff0c\u7ea0\u6b63\u504f\u5dee\uff0c\u5e76\u4e14\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u3001\u6709\u6548\u4e14\u4f4e\u6210\u672c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u91d1\u878d\u9884\u6d4b\u4e2d\u7684\u524d\u77bb\u504f\u5dee\u95ee\u9898\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2512.07108", "categories": ["quant-ph", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.07108", "abs": "https://arxiv.org/abs/2512.07108", "authors": ["Ashutosh Jayant Dikshit", "Naga Lakshmi Anipeddi", "Prajit Dhara", "Saikat Guha", "Deirdre Kilbane", "Leandros Tassiulas", "Don Towsley", "Nitish K. Panigrahy"], "title": "Scheduling in Quantum Satellite Networks: Fairness and Performance Optimization", "comment": null, "summary": "Quantum satellite networks offer a promising solution for achieving long-distance quantum communication by enabling entanglement distribution across global scales. This work formulates and solves the quantum satellite network scheduling problem by optimizing satellite-to-ground station pair assignments under realistic system and environmental constraints. Our framework accounts for limited satellite and ground station resources, fairness, entanglement fidelity thresholds, and real world non-idealities including atmospheric losses, weather and background noise. In addition, we incorporate the complexities of multi-satellite relays enabled via inter-satellite links. We propose an integer linear programming (ILP) based optimization framework that supports multiple scheduling objectives, allowing us to analyze tradeoffs between maximizing total entanglement distribution rate and ensuring fairness across ground station pairs. Our framework can also be used as a benchmark tool to measure the performance of other potential transmission scheduling policies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u91cf\u5b50\u536b\u661f\u7f51\u7edc\u8c03\u5ea6\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u536b\u661f-\u5730\u9762\u7ad9\u914d\u5bf9\u95ee\u9898\uff0c\u8003\u8651\u8d44\u6e90\u9650\u5236\u3001\u516c\u5e73\u6027\u3001\u4fdd\u771f\u5ea6\u9608\u503c\u53ca\u5b9e\u9645\u73af\u5883\u56e0\u7d20", "motivation": "\u91cf\u5b50\u536b\u661f\u7f51\u7edc\u662f\u5b9e\u73b0\u957f\u8ddd\u79bb\u91cf\u5b50\u901a\u4fe1\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u9700\u8981\u6709\u6548\u8c03\u5ea6\u536b\u661f\u4e0e\u5730\u9762\u7ad9\u4e4b\u95f4\u7684\u914d\u5bf9\uff0c\u4ee5\u5e94\u5bf9\u8d44\u6e90\u9650\u5236\u3001\u73af\u5883\u56e0\u7d20\u548c\u591a\u536b\u661f\u4e2d\u7ee7\u7b49\u590d\u6742\u6311\u6218", "method": "\u91c7\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u4f18\u5316\u6846\u67b6\uff0c\u7efc\u5408\u8003\u8651\u536b\u661f\u548c\u5730\u9762\u7ad9\u8d44\u6e90\u9650\u5236\u3001\u516c\u5e73\u6027\u3001\u7ea0\u7f20\u4fdd\u771f\u5ea6\u9608\u503c\u3001\u5927\u6c14\u635f\u8017\u3001\u5929\u6c14\u3001\u80cc\u666f\u566a\u58f0\u4ee5\u53ca\u591a\u536b\u661f\u4e2d\u7ee7\u94fe\u8def\u7b49\u5b9e\u9645\u7ea6\u675f", "result": "\u5f00\u53d1\u4e86\u652f\u6301\u591a\u79cd\u8c03\u5ea6\u76ee\u6807\u7684\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5206\u6790\u6700\u5927\u5316\u603b\u7ea0\u7f20\u5206\u5e03\u7387\u4e0e\u786e\u4fdd\u5730\u9762\u7ad9\u5bf9\u4e4b\u95f4\u516c\u5e73\u6027\u7684\u6743\u8861\uff0c\u5e76\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u5176\u4ed6\u4f20\u8f93\u8c03\u5ea6\u7b56\u7565\u6027\u80fd\u7684\u57fa\u51c6\u5de5\u5177", "conclusion": "\u8be5ILP\u4f18\u5316\u6846\u67b6\u4e3a\u91cf\u5b50\u536b\u661f\u7f51\u7edc\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5b9e\u9645\u73af\u5883\u7ea6\u675f\uff0c\u5e73\u8861\u4e0d\u540c\u6027\u80fd\u6307\u6807\uff0c\u5e76\u4e3a\u672a\u6765\u8c03\u5ea6\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u57fa\u51c6\u53c2\u8003"}}
{"id": "2512.06609", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.06609", "abs": "https://arxiv.org/abs/2512.06609", "authors": ["Tongda Xu", "Wendi Zheng", "Jiajun He", "Jose Miguel Hernandez-Lobato", "Yan Wang", "Ya-Qin Zhang", "Jie Tang"], "title": "Vector Quantization using Gaussian Variational Autoencoder", "comment": null, "summary": "Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.", "AI": {"tldr": "\u63d0\u51faGaussian Quant (GQ)\u6280\u672f\uff0c\u5c06\u9ad8\u65afVAE\u8f6c\u6362\u4e3aVQ-VAE\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u8df5\u9a8c\u8bc1\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "VQ-VAE\u7531\u4e8e\u79bb\u6563\u5316\u96be\u4ee5\u8bad\u7ec3\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u7b80\u5355\u6709\u6548\u7684\u79bb\u6563\u5316\u65b9\u6cd5", "method": "\u63d0\u51faGaussian Quant (GQ)\uff1a\u4f7f\u7528\u968f\u673a\u9ad8\u65af\u566a\u58f0\u4f5c\u4e3a\u7801\u672c\uff0c\u5bfb\u627e\u4e0e\u540e\u9a8c\u5747\u503c\u6700\u63a5\u8fd1\u7684\u566a\u58f0\uff1b\u5e76\u63d0\u51fa\u76ee\u6807\u6563\u5ea6\u7ea6\u675f(TDC)\u6765\u8bad\u7ec3\u9ad8\u65afVAE\u4ee5\u4f18\u5316GQ\u6548\u679c", "result": "GQ\u5728UNet\u548cViT\u67b6\u6784\u4e0a\u4f18\u4e8eVQGAN\u3001FSQ\u3001LFQ\u3001BSQ\u7b49\u73b0\u6709VQ-VAE\u65b9\u6cd5\uff1bTDC\u4e5f\u4f18\u4e8eTokenBridge\u7b49\u9ad8\u65afVAE\u79bb\u6563\u5316\u65b9\u6cd5", "conclusion": "GQ\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684VQ-VAE\u6784\u5efa\u65b9\u6cd5\uff0c\u7406\u8bba\u4e0a\u6709\u4fdd\u8bc1\uff0c\u5b9e\u8df5\u4e0a\u8868\u73b0\u4f18\u5f02"}}
{"id": "2512.07127", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07127", "abs": "https://arxiv.org/abs/2512.07127", "authors": ["Daniel Lidar"], "title": "Digital-Analog-Digital Quantum Supremacy", "comment": "10 pages", "summary": "Quantum supremacy has been explored extensively in gate-model settings. Here, we introduce a quantum-supremacy framework for a hybrid digital-analog-digital quantum computing (DADQC) model. We consider a device that applies an initial layer of single-qubit gates, a single transverse-field Ising analog block, and a final single-qubit layer before $Z$-basis readout. The analog block approximates $Z$-diagonal Ising evolution, and we prove that the resulting output distribution is within constant total-variation (TV) distance of an Instantaneous Quantum Polynomial-time (IQP) circuit. Our bounds and constructions are established for fully connected as well as bounded-degree hardware graphs, matching a variety of architectures, including trapped-ion, neutral atom, and superconducting platforms. Assuming anticoncentration (which we prove for all-to-all hardware graphs and conjecture for bounded-degree hardware graphs) and an average-case hardness conjecture for the associated complex-temperature Ising partition functions, standard reductions imply that any efficient classical sampler achieving constant TV error collapses the polynomial hierarchy. Our results imply that quantum-supremacy tests are possible on today's quantum annealers, as well as other devices capable of hybrid digital-analog quantum evolution.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6df7\u5408\u6570\u5b57-\u6a21\u62df-\u6570\u5b57\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\u7684\u91cf\u5b50\u9738\u6743\u6846\u67b6\uff0c\u8bc1\u660e\u5176\u8f93\u51fa\u5206\u5e03\u4e0eIQP\u7535\u8def\u76f8\u8fd1\uff0c\u5e76\u8868\u660e\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\uff0c\u7ecf\u5178\u8ba1\u7b97\u673a\u65e0\u6cd5\u6709\u6548\u6a21\u62df\uff0c\u4e3a\u5f53\u524d\u91cf\u5b50\u9000\u706b\u5668\u7b49\u8bbe\u5907\u63d0\u4f9b\u4e86\u91cf\u5b50\u9738\u6743\u6d4b\u8bd5\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u91cf\u5b50\u9738\u6743\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u95e8\u6a21\u578b\u8bbe\u7f6e\u4e2d\uff0c\u4f46\u8bb8\u591a\u5b9e\u9645\u91cf\u5b50\u8bbe\u5907\uff08\u5982\u91cf\u5b50\u9000\u706b\u5668\uff09\u91c7\u7528\u6df7\u5408\u6570\u5b57-\u6a21\u62df\u67b6\u6784\u3002\u9700\u8981\u4e3a\u8fd9\u7c7b\u8bbe\u5907\u5efa\u7acb\u91cf\u5b50\u9738\u6743\u6846\u67b6\uff0c\u4ee5\u8bc4\u4f30\u5176\u8ba1\u7b97\u80fd\u529b\u5e76\u8bc1\u660e\u5176\u76f8\u5bf9\u4e8e\u7ecf\u5178\u8ba1\u7b97\u673a\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6570\u5b57-\u6a21\u62df-\u6570\u5b57\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\uff1a\u521d\u59cb\u5355\u91cf\u5b50\u6bd4\u7279\u95e8\u5c42 + \u6a2a\u5411\u573a\u4f0a\u8f9b\u6a21\u62df\u5757 + \u6700\u7ec8\u5355\u91cf\u5b50\u6bd4\u7279\u95e8\u5c42 + Z\u57fa\u6d4b\u91cf\u3002\u8bc1\u660e\u8be5\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u4e0eIQP\u7535\u8def\u5728\u5e38\u6570\u603b\u53d8\u5dee\u8ddd\u79bb\u5185\u76f8\u8fd1\u3002\u8003\u8651\u5168\u8fde\u63a5\u548c\u6709\u754c\u5ea6\u786c\u4ef6\u56fe\uff0c\u5339\u914d\u591a\u79cd\u91cf\u5b50\u5e73\u53f0\u67b6\u6784\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u53cd\u96c6\u4e2d\u5047\u8bbe\uff08\u5168\u8fde\u63a5\u56fe\u5df2\u8bc1\u660e\uff0c\u6709\u754c\u5ea6\u56fe\u63a8\u6d4b\uff09\u548c\u76f8\u5173\u590d\u6e29\u5ea6\u4f0a\u8f9b\u914d\u5206\u51fd\u6570\u7684\u5e73\u5747\u60c5\u51b5\u786c\u5ea6\u731c\u60f3\u4e0b\uff0c\u4efb\u4f55\u5b9e\u73b0\u5e38\u6570TV\u8bef\u5dee\u7684\u9ad8\u6548\u7ecf\u5178\u91c7\u6837\u5668\u5c06\u5bfc\u81f4\u591a\u9879\u5f0f\u5c42\u6b21\u7ed3\u6784\u574d\u584c\u3002\u8fd9\u610f\u5473\u7740\u91cf\u5b50\u9738\u6743\u6d4b\u8bd5\u5728\u5f53\u524d\u91cf\u5b50\u9000\u706b\u5668\u7b49\u8bbe\u5907\u4e0a\u662f\u53ef\u884c\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6df7\u5408\u6570\u5b57-\u6a21\u62df\u91cf\u5b50\u8bbe\u5907\u5efa\u7acb\u4e86\u91cf\u5b50\u9738\u6743\u6846\u67b6\uff0c\u8868\u660e\u91cf\u5b50\u9738\u6743\u6d4b\u8bd5\u4e0d\u4ec5\u9650\u4e8e\u95e8\u6a21\u578b\u91cf\u5b50\u8ba1\u7b97\u673a\uff0c\u4e5f\u53ef\u5728\u5f53\u4eca\u7684\u91cf\u5b50\u9000\u706b\u5668\u548c\u5176\u4ed6\u6df7\u5408\u6570\u5b57-\u6a21\u62df\u91cf\u5b50\u6f14\u5316\u8bbe\u5907\u4e0a\u5b9e\u73b0\uff0c\u6269\u5c55\u4e86\u91cf\u5b50\u9738\u6743\u5b9e\u9a8c\u7684\u5e73\u53f0\u8303\u56f4\u3002"}}
{"id": "2512.06630", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06630", "abs": "https://arxiv.org/abs/2512.06630", "authors": ["Chi-Sheng Chen", "Xinyu Zhang", "Rong Fu", "Qiuzhe Xie", "Fan Zhang"], "title": "Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction: A Comparative Benchmark Study", "comment": null, "summary": "Quantum machine learning offers a promising pathway for enhancing stock market prediction, particularly under complex, noisy, and highly dynamic financial environments. However, many classical forecasting models struggle with noisy input, regime shifts, and limited generalization capacity. To address these challenges, we propose a Quantum Temporal Convolutional Neural Network (QTCNN) that combines a classical temporal encoder with parameter-efficient quantum convolution circuits for cross-sectional equity return prediction. The temporal encoder extracts multi-scale patterns from sequential technical indicators, while the quantum processing leverages superposition and entanglement to enhance feature representation and suppress overfitting. We conduct a comprehensive benchmarking study on the JPX Tokyo Stock Exchange dataset and evaluate predictions through long-short portfolio construction using out-of-sample Sharpe ratio as the primary performance metric. QTCNN achieves a Sharpe ratio of 0.538, outperforming the best classical baseline by approximately 72\\%. These results highlight the practical potential of quantum-enhanced forecasting model, QTCNN, for robust decision-making in quantitative finance.", "AI": {"tldr": "\u91cf\u5b50\u65f6\u95f4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(QTCNN)\u7ed3\u5408\u7ecf\u5178\u65f6\u95f4\u7f16\u7801\u5668\u548c\u53c2\u6570\u9ad8\u6548\u7684\u91cf\u5b50\u5377\u79ef\u7535\u8def\uff0c\u7528\u4e8e\u80a1\u7968\u6536\u76ca\u9884\u6d4b\uff0c\u5728JPX\u4e1c\u4eac\u8bc1\u5238\u4ea4\u6613\u6240\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e860.538\u7684\u590f\u666e\u6bd4\u7387\uff0c\u6bd4\u6700\u4f73\u7ecf\u5178\u57fa\u51c6\u63d0\u9ad8\u4e86\u7ea672%\u3002", "motivation": "\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u5728\u5904\u7406\u566a\u58f0\u8f93\u5165\u3001\u5236\u5ea6\u8f6c\u6362\u548c\u6709\u9650\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u3001\u566a\u58f0\u5927\u3001\u52a8\u6001\u6027\u5f3a\u7684\u91d1\u878d\u73af\u5883\u4e2d\u3002\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e3a\u589e\u5f3a\u80a1\u7968\u5e02\u573a\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002", "method": "\u63d0\u51fa\u91cf\u5b50\u65f6\u95f4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(QTCNN)\uff0c\u7ed3\u5408\u7ecf\u5178\u65f6\u95f4\u7f16\u7801\u5668\u63d0\u53d6\u65f6\u5e8f\u6280\u672f\u6307\u6807\u7684\u591a\u5c3a\u5ea6\u6a21\u5f0f\uff0c\u4ee5\u53ca\u91cf\u5b50\u5377\u79ef\u7535\u8def\u5229\u7528\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u589e\u5f3a\u7279\u5f81\u8868\u793a\u5e76\u6291\u5236\u8fc7\u62df\u5408\u3002", "result": "\u5728JPX\u4e1c\u4eac\u8bc1\u5238\u4ea4\u6613\u6240\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6784\u5efa\u591a\u7a7a\u6295\u8d44\u7ec4\u5408\u5e76\u4f7f\u7528\u6837\u672c\u5916\u590f\u666e\u6bd4\u7387\u4f5c\u4e3a\u4e3b\u8981\u6027\u80fd\u6307\u6807\u3002QTCNN\u5b9e\u73b0\u4e860.538\u7684\u590f\u666e\u6bd4\u7387\uff0c\u6bd4\u6700\u4f73\u7ecf\u5178\u57fa\u51c6\u63d0\u9ad8\u4e86\u7ea672%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u91cf\u5b50\u589e\u5f3a\u9884\u6d4b\u6a21\u578bQTCNN\u5728\u91cf\u5316\u91d1\u878d\u4e2d\u7a33\u5065\u51b3\u7b56\u7684\u5b9e\u9645\u6f5c\u529b\uff0c\u8868\u660e\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u80fd\u591f\u6709\u6548\u5904\u7406\u91d1\u878d\u73af\u5883\u4e2d\u7684\u590d\u6742\u6027\u548c\u566a\u58f0\u3002"}}
{"id": "2512.07131", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07131", "abs": "https://arxiv.org/abs/2512.07131", "authors": ["Jason D. Chadwick", "Willers Yang", "Joshua Viszlai", "Frederic T. Chong"], "title": "A manufacturable surface code architecture for spin qubits with fast transversal logic", "comment": null, "summary": "Spin qubits in silicon quantum dot arrays are a promising quantum computation platform for long-term scalability due to their small qubit footprint and compatibility with advanced semiconductor manufacturing. However, spin qubit devices face a key architectural bottleneck: the large physical footprint of readout components relative to qubits prevents a dense layout where all qubits can be measured simultaneously, complicating the implementation of quantum error correction. This challenge is offset by the platform's unique rapid shuttling capability, which can be used to transport qubits to distant readout ports. In this work, we explore the design constraints and capabilities of spin qubits in silicon and propose the SNAQ (Shuttling-capable Narrow Array of spin Qubits) surface code architecture, which relaxes the 1:1 readout-to-qubit assumption by leveraging spin shuttling to time-multiplex ancilla qubit initialization and readout. Our analysis shows that, given sufficiently high (experimentally demonstrated) qubit coherence times, SNAQ delivers an orders-of-magnitude reduction in chip area per logical qubit. Additionally, by using a denser grid of physical qubits, SNAQ enables fast transversal logic for short-distance logical operations, achieving 4.0-22.3x improvement in local logical clock speed while still supporting global operations via lattice surgery. This translates to a 57-60% reduction in spacetime cost of 15-to-1 magic state distillation, a key fault-tolerant subroutine. Our work pinpoints critical hardware metrics and provides a compelling path toward high-performance fault-tolerant computation on near-term-manufacturable spin qubit arrays.", "AI": {"tldr": "\u63d0\u51faSNAQ\u67b6\u6784\uff0c\u5229\u7528\u7845\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u7684\u5feb\u901f\u7a7f\u68ad\u80fd\u529b\uff0c\u901a\u8fc7\u65f6\u95f4\u590d\u7528\u51cf\u5c11\u8bfb\u51fa\u7ec4\u4ef6\u6570\u91cf\uff0c\u663e\u8457\u964d\u4f4e\u82af\u7247\u9762\u79ef\u5e76\u63d0\u5347\u903b\u8f91\u65f6\u949f\u901f\u5ea6\u3002", "motivation": "\u7845\u91cf\u5b50\u70b9\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u5e73\u53f0\u9762\u4e34\u8bfb\u51fa\u7ec4\u4ef6\u7269\u7406\u5c3a\u5bf8\u8fdc\u5927\u4e8e\u91cf\u5b50\u6bd4\u7279\u7684\u67b6\u6784\u74f6\u9888\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5b9e\u73b0\u6240\u6709\u91cf\u5b50\u6bd4\u7279\u540c\u65f6\u6d4b\u91cf\u7684\u5bc6\u96c6\u5e03\u5c40\uff0c\u8fd9\u963b\u788d\u4e86\u91cf\u5b50\u7ea0\u9519\u7684\u5b9e\u65bd\u3002", "method": "\u63d0\u51faSNAQ\uff08Shuttling-capable Narrow Array of spin Qubits\uff09\u8868\u9762\u7801\u67b6\u6784\uff0c\u5229\u7528\u81ea\u65cb\u7a7f\u68ad\u80fd\u529b\u65f6\u95f4\u590d\u7528\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u7684\u521d\u59cb\u5316\u548c\u8bfb\u51fa\uff0c\u653e\u677e\u4e861:1\u8bfb\u51fa-\u91cf\u5b50\u6bd4\u7279\u6bd4\u4f8b\u5047\u8bbe\u3002", "result": "SNAQ\u67b6\u6784\u5728\u8db3\u591f\u9ad8\u7684\u91cf\u5b50\u6bd4\u7279\u76f8\u5e72\u65f6\u95f4\u4e0b\uff0c\u53ef\u5b9e\u73b0\u82af\u7247\u9762\u79ef\u6bcf\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u7ea7\u51cf\u5c11\uff0c\u901a\u8fc7\u66f4\u5bc6\u96c6\u7684\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u7f51\u683c\u5b9e\u73b04.0-22.3\u500d\u7684\u672c\u5730\u903b\u8f91\u65f6\u949f\u901f\u5ea6\u63d0\u5347\uff0c15-to-1\u9b54\u6cd5\u6001\u84b8\u998f\u7684\u65f6\u7a7a\u6210\u672c\u964d\u4f4e57-60%\u3002", "conclusion": "SNAQ\u67b6\u6784\u4e3a\u8fd1\u671f\u53ef\u5236\u9020\u7684\u7845\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u9635\u5217\u63d0\u4f9b\u4e86\u5b9e\u73b0\u9ad8\u6027\u80fd\u5bb9\u9519\u8ba1\u7b97\u7684\u6709\u529b\u8def\u5f84\uff0c\u5e76\u786e\u5b9a\u4e86\u5173\u952e\u786c\u4ef6\u6307\u6807\u3002"}}
{"id": "2512.06638", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06638", "abs": "https://arxiv.org/abs/2512.06638", "authors": ["Isha Karn", "David Jensen"], "title": "The Impact of Data Characteristics on GNN Evaluation for Detecting Fake News", "comment": "Preprint. Approximately 15 pages, 5 figures, 3 tables", "summary": "Graph neural networks (GNNs) are widely used for the detection of fake news by modeling the content and propagation structure of news articles on social media. We show that two of the most commonly used benchmark data sets - GossipCop and PolitiFact - are poorly suited to evaluating the utility of models that use propagation structure. Specifically, these data sets exhibit shallow, ego-like graph topologies that provide little or no ability to differentiate among modeling methods. We systematically benchmark five GNN architectures against a structure-agnostic multilayer perceptron (MLP) that uses the same node features. We show that MLPs match or closely trail the performance of GNNs, with performance gaps often within 1-2% and overlapping confidence intervals. To isolate the contribution of structure in these datasets, we conduct controlled experiments where node features are shuffled or edge structures randomized. We find that performance collapses under feature shuffling but remains stable under edge randomization. This suggests that structure plays a negligible role in these benchmarks. Structural analysis further reveals that over 75% of nodes are only one hop from the root, exhibiting minimal structural diversity. In contrast, on synthetic datasets where node features are noisy and structure is informative, GNNs significantly outperform MLPs. These findings provide strong evidence that widely used benchmarks do not meaningfully test the utility of modeling structural features, and they motivate the development of datasets with richer, more diverse graph topologies.", "AI": {"tldr": "\u73b0\u6709\u5047\u65b0\u95fb\u68c0\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\uff08GossipCop\u548cPolitiFact\uff09\u7684\u56fe\u7ed3\u6784\u8fc7\u4e8e\u7b80\u5355\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30GNN\u6a21\u578b\u7684\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\uff0c\u5bfc\u81f4GNN\u4e0e\u7b80\u5355MLP\u6027\u80fd\u76f8\u8fd1\u3002", "motivation": "\u5f53\u524d\u5047\u65b0\u95fb\u68c0\u6d4b\u9886\u57df\u5e7f\u6cdb\u4f7f\u7528GNN\u6a21\u578b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u57fa\u51c6\u6570\u636e\u96c6\u662f\u5426\u771f\u6b63\u80fd\u8bc4\u4f30\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\u7684\u9a8c\u8bc1\u3002\u7814\u7a76\u8005\u53d1\u73b0\u5e38\u7528\u6570\u636e\u96c6\u53ef\u80fd\u5b58\u5728\u7ed3\u6784\u8fc7\u4e8e\u7b80\u5355\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u533a\u5206\u4e0d\u540c\u5efa\u6a21\u65b9\u6cd5\u7684\u4f18\u52a3\u3002", "method": "1) \u7cfb\u7edf\u6bd4\u8f835\u79cdGNN\u67b6\u6784\u4e0e\u4f7f\u7528\u76f8\u540c\u8282\u70b9\u7279\u5f81\u7684\u7ed3\u6784\u65e0\u5173MLP\uff1b2) \u901a\u8fc7\u7279\u5f81\u6253\u4e71\u548c\u8fb9\u7ed3\u6784\u968f\u673a\u5316\u7684\u63a7\u5236\u5b9e\u9a8c\u5206\u79bb\u7ed3\u6784\u548c\u7279\u5f81\u7684\u8d21\u732e\uff1b3) \u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u7ed3\u6784\u5206\u6790\uff0c\u8ba1\u7b97\u8282\u70b9\u8ddd\u79bb\u5206\u5e03\uff1b4) \u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1GNN\u7684\u771f\u6b63\u4f18\u52bf\u3002", "result": "1) MLP\u4e0eGNN\u6027\u80fd\u76f8\u8fd1\uff08\u5dee\u8ddd1-2%\uff0c\u7f6e\u4fe1\u533a\u95f4\u91cd\u53e0\uff09\uff1b2) \u7279\u5f81\u6253\u4e71\u5bfc\u81f4\u6027\u80fd\u5d29\u6e83\uff0c\u4f46\u8fb9\u968f\u673a\u5316\u540e\u6027\u80fd\u7a33\u5b9a\uff0c\u8868\u660e\u7ed3\u6784\u8d21\u732e\u53ef\u5ffd\u7565\uff1b3) \u8d85\u8fc775%\u7684\u8282\u70b9\u8ddd\u79bb\u6839\u8282\u70b9\u4ec5\u4e00\u8df3\uff0c\u7ed3\u6784\u591a\u6837\u6027\u6781\u4f4e\uff1b4) \u5728\u7279\u5f81\u566a\u58f0\u5927\u3001\u7ed3\u6784\u4fe1\u606f\u4e30\u5bcc\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cGNN\u663e\u8457\u4f18\u4e8eMLP\u3002", "conclusion": "\u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5047\u65b0\u95fb\u68c0\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30GNN\u7684\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\uff0c\u56e0\u4e3a\u5b83\u4eec\u5177\u6709\u6d45\u5c42\u3001\u81ea\u6211\u4e2d\u5fc3\u5f0f\u7684\u56fe\u62d3\u6251\u7ed3\u6784\u3002\u8fd9\u547c\u5401\u5f00\u53d1\u5177\u6709\u66f4\u4e30\u5bcc\u3001\u66f4\u591a\u6837\u5316\u56fe\u62d3\u6251\u7ed3\u6784\u7684\u6570\u636e\u96c6\u3002"}}
{"id": "2512.07160", "categories": ["quant-ph", "math.OA"], "pdf": "https://arxiv.org/pdf/2512.07160", "abs": "https://arxiv.org/abs/2512.07160", "authors": ["Ranyiliu Chen", "Laura Man\u010dinska", "Jurij Vol\u010di\u010d"], "title": "Beyond real: Investigating the role of complex numbers in self-testing", "comment": "31 pages. Comments are welcome!", "summary": "We investigate complex self-testing, a generalization of standard self-testing that accounts for quantum strategies whose statistics is indistinguishable from their complex conjugate's. We show that many structural results from standard self-testing extend to the complex setting, including lifting of common assumptions. Our main result is an operator-algebraic characterization: complex self-testing is equivalent to uniqueness of the real parts of higher moments, leading to a basis-independent formulation in terms of real C* algebras. This leads to a classification of non-local strategies, and a tight boundary where standard self-testing do not apply and complex self-testing is necessary. We further construct a strategy involving quaternions, establishing the first standard self-test for genuinely complex strategy. Our work clarifies the structure of complex self-testing and highlights the subtle role of complex numbers in bipartite Bell non-locality.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u590d\u6742\u81ea\u6d4b\u8bd5\uff0c\u8fd9\u662f\u6807\u51c6\u81ea\u6d4b\u8bd5\u7684\u63a8\u5e7f\uff0c\u8003\u8651\u4e86\u91cf\u5b50\u7b56\u7565\u7684\u7edf\u8ba1\u7279\u6027\u4e0e\u5176\u590d\u5171\u8f6d\u4e0d\u53ef\u533a\u5206\u7684\u60c5\u51b5\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\u5c06\u6807\u51c6\u81ea\u6d4b\u8bd5\u7684\u7ed3\u6784\u7ed3\u679c\u6269\u5c55\u5230\u590d\u6742\u8bbe\u7f6e\uff0c\u7ed9\u51fa\u4e86\u7b97\u5b50\u4ee3\u6570\u7279\u5f81\u63cf\u8ff0\uff0c\u5efa\u7acb\u4e86\u975e\u5c40\u57df\u7b56\u7565\u7684\u5206\u7c7b\uff0c\u5e76\u6784\u9020\u4e86\u6d89\u53ca\u56db\u5143\u6570\u7684\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u590d\u6742\u81ea\u6d4b\u8bd5\u7684\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u91cf\u5b50\u7b56\u7565\u4e2d\u590d\u6570\u7684\u5fae\u5999\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5f53\u7b56\u7565\u7684\u7edf\u8ba1\u7279\u6027\u4e0e\u5176\u590d\u5171\u8f6d\u4e0d\u53ef\u533a\u5206\u65f6\u7684\u60c5\u51b5\u3002\u8fd9\u6269\u5c55\u4e86\u6807\u51c6\u81ea\u6d4b\u8bd5\u7684\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5728\u6807\u51c6\u81ea\u6d4b\u8bd5\u4e0d\u9002\u7528\u65f6\u9700\u8981\u590d\u6742\u81ea\u6d4b\u8bd5\u7684\u8fb9\u754c\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u7b97\u5b50\u4ee3\u6570\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u590d\u6742\u81ea\u6d4b\u8bd5\u7b49\u4ef7\u4e8e\u9ad8\u9636\u77e9\u5b9e\u90e8\u7684\u552f\u4e00\u6027\uff0c\u4ece\u800c\u5f97\u5230\u4e86\u57fa\u4e8e\u5b9eC*\u4ee3\u6570\u7684\u57fa\u65e0\u5173\u8868\u8ff0\u3002\u901a\u8fc7\u6784\u9020\u6d89\u53ca\u56db\u5143\u6570\u7684\u7b56\u7565\u6765\u5efa\u7acb\u9996\u4e2a\u771f\u6b63\u590d\u6742\u7b56\u7565\u7684\u6807\u51c6\u81ea\u6d4b\u8bd5\u3002", "result": "1) \u5c06\u6807\u51c6\u81ea\u6d4b\u8bd5\u7684\u7ed3\u6784\u7ed3\u679c\u6269\u5c55\u5230\u590d\u6742\u8bbe\u7f6e\uff1b2) \u7ed9\u51fa\u4e86\u590d\u6742\u81ea\u6d4b\u8bd5\u7684\u7b97\u5b50\u4ee3\u6570\u7279\u5f81\u63cf\u8ff0\uff1b3) \u5efa\u7acb\u4e86\u975e\u5c40\u57df\u7b56\u7565\u7684\u5206\u7c7b\uff1b4) \u786e\u5b9a\u4e86\u6807\u51c6\u81ea\u6d4b\u8bd5\u4e0d\u9002\u7528\u800c\u9700\u8981\u590d\u6742\u81ea\u6d4b\u8bd5\u7684\u7d27\u8fb9\u754c\uff1b5) \u6784\u9020\u4e86\u9996\u4e2a\u771f\u6b63\u590d\u6742\u7b56\u7565\u7684\u6807\u51c6\u81ea\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9610\u660e\u4e86\u590d\u6742\u81ea\u6d4b\u8bd5\u7684\u7ed3\u6784\uff0c\u7a81\u51fa\u4e86\u590d\u6570\u5728\u53cc\u7c92\u5b50\u8d1d\u5c14\u975e\u5c40\u57df\u6027\u4e2d\u7684\u5fae\u5999\u4f5c\u7528\u3002\u901a\u8fc7\u7b97\u5b50\u4ee3\u6570\u7279\u5f81\u63cf\u8ff0\u548c\u7b56\u7565\u5206\u7c7b\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u7b56\u7565\u4e2d\u590d\u6570\u7684\u5fc5\u8981\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5efa\u7acb\u4e86\u6807\u51c6\u81ea\u6d4b\u8bd5\u4e0e\u590d\u6742\u81ea\u6d4b\u8bd5\u4e4b\u95f4\u7684\u660e\u786e\u8fb9\u754c\u3002"}}
{"id": "2512.06648", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.06648", "abs": "https://arxiv.org/abs/2512.06648", "authors": ["Xiao Li"], "title": "Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network", "comment": "in Chinese language", "summary": "Since the emergence of joint-stock companies, financial fraud by listed firms has repeatedly undermined capital markets. Fraud is difficult to detect because of covert tactics and the high labor and time costs of audits. Traditional statistical models are interpretable but struggle with nonlinear feature interactions, while machine learning models are powerful but often opaque. In addition, most existing methods judge fraud only for the current year based on current year data, limiting timeliness.\n  This paper proposes a financial fraud detection framework for Chinese A-share listed companies based on convolutional neural networks (CNNs). We design a feature engineering scheme that transforms firm-year panel data into image like representations, enabling the CNN to capture cross-sectional and temporal patterns and to predict fraud in advance. Experiments show that the CNN outperforms logistic regression and LightGBM in accuracy, robustness, and early-warning performance, and that proper tuning of the classification threshold is crucial in high-risk settings.\n  To address interpretability, we analyze the model along the dimensions of entity, feature, and time using local explanation techniques. We find that solvency, ratio structure, governance structure, and internal control are general predictors of fraud, while environmental indicators matter mainly in high-pollution industries. Non-fraud firms share stable feature patterns, whereas fraud firms exhibit heterogeneous patterns concentrated in short time windows. A case study of Guanong Shares in 2022 shows that cash flow analysis, social responsibility, governance structure, and per-share indicators are the main drivers of the model's fraud prediction, consistent with the company's documented misconduct.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u4e2d\u56fdA\u80a1\u4e0a\u5e02\u516c\u53f8\u8d22\u52a1\u821e\u5f0a\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9762\u677f\u6570\u636e\u8f6c\u6362\u4e3a\u7c7b\u56fe\u50cf\u8868\u793a\u6765\u6355\u6349\u6a2a\u622a\u9762\u548c\u65f6\u95f4\u6a21\u5f0f\uff0c\u5b9e\u73b0\u63d0\u524d\u9884\u6d4b\uff0c\u5e76\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9884\u8b66\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e0a\u5e02\u516c\u53f8\u8d22\u52a1\u821e\u5f0a\u5c61\u7981\u4e0d\u6b62\uff0c\u4f20\u7edf\u7edf\u8ba1\u6a21\u578b\u96be\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u7279\u5f81\u4ea4\u4e92\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u591a\u57fa\u4e8e\u5f53\u5e74\u6570\u636e\u5224\u65ad\u5f53\u5e74\u821e\u5f0a\uff0c\u65f6\u6548\u6027\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u7279\u5f81\u5de5\u7a0b\u65b9\u6848\uff0c\u5c06\u516c\u53f8\u5e74\u5ea6\u9762\u677f\u6570\u636e\u8f6c\u6362\u4e3a\u7c7b\u56fe\u50cf\u8868\u793a\uff0c\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u6a2a\u622a\u9762\u548c\u65f6\u95f4\u6a21\u5f0f\uff0c\u5b9e\u73b0\u63d0\u524d\u9884\u6d4b\u821e\u5f0a\uff1b\u91c7\u7528\u5c40\u90e8\u89e3\u91ca\u6280\u672f\u4ece\u5b9e\u4f53\u3001\u7279\u5f81\u548c\u65f6\u95f4\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u6a21\u578b\u3002", "result": "CNN\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9884\u8b66\u6027\u80fd\u4e0a\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u548cLightGBM\uff1b\u53d1\u73b0\u507f\u503a\u80fd\u529b\u3001\u6bd4\u7387\u7ed3\u6784\u3001\u6cbb\u7406\u7ed3\u6784\u548c\u5185\u90e8\u63a7\u5236\u662f\u821e\u5f0a\u7684\u901a\u7528\u9884\u6d4b\u56e0\u5b50\uff1b\u975e\u821e\u5f0a\u516c\u53f8\u7279\u5f81\u6a21\u5f0f\u7a33\u5b9a\uff0c\u821e\u5f0a\u516c\u53f8\u7279\u5f81\u6a21\u5f0f\u5f02\u8d28\u4e14\u96c6\u4e2d\u5728\u77ed\u671f\u7a97\u53e3\u3002", "conclusion": "\u57fa\u4e8eCNN\u7684\u8d22\u52a1\u821e\u5f0a\u68c0\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u63d0\u524d\u8bc6\u522b\u821e\u5f0a\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u5206\u7c7b\u9608\u503c\u8c03\u6574\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u4e3a\u9ad8\u98ce\u9669\u73af\u5883\u4e0b\u7684\u821e\u5f0a\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6a21\u578b\u9884\u6d4b\u4e0e\u5b9e\u9645\u821e\u5f0a\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.07182", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07182", "abs": "https://arxiv.org/abs/2512.07182", "authors": ["Hai Wei", "Chengjun Ai", "Putuo Guo", "Bingjie Jia", "Lixin Yuan", "Hanquan Song", "Shaobo Chen", "Chongyu Cao", "Jie Wu", "Chao Ju", "Yin Ma", "Jintao Fan", "Minglie Hu", "Chuan Wang", "Kai Wen"], "title": "A versatile coherent Ising computing platform", "comment": "37 pages, 7 figures, comments are welcome", "summary": "Coherent Ising Machines (CIMs) have emerged as a hybrid form of quantum computing devices designed to solve NP-complete problems, offering an exciting opportunity for discovering optimal solutions. Despite challenges such as susceptibility to noise-induced local minima, we achieved notable advantages in improving the computational accuracy and stability of CIMs. We conducted a successful experimental demonstration of CIM via femto-second laser pumping that integrates optimization strategies across optical and structural dimensions, resulting in significant performance enhancements. The results are particularly promising. An average success rate of 55% was achieved to identify optimal solutions within a Mobius Ladder graph comprising 100 vertices. Compared with other alternatives, the femto-second pulse results in significantly higher peak power, leading to more pronounced quantum effects and lower pump power in optical fiber based CIMs. In addition, we have maintained an impressive success rate for a continuous period of 8 hours, emphasizing the practical applicability of CIMs in real-world scenarios. Furthermore, our research extends to the application of these principles in practical applications such as molecular docking and credit scoring. The results presented substantiate the theoretical promise of CIMs, paving the way for their integration into large-scale practical applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u901a\u8fc7\u98de\u79d2\u6fc0\u5149\u6cf5\u6d66\u5b9e\u73b0\u7684\u76f8\u5e72\u4f0a\u8f9b\u673a\u5728\u89e3\u51b3NP\u5b8c\u5168\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728100\u8282\u70b9\u83ab\u6bd4\u4e4c\u65af\u68af\u56fe\u4e0a\u8fbe\u523055%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u5e76\u4fdd\u63018\u5c0f\u65f6\u7a33\u5b9a\u8fd0\u884c\u3002", "motivation": "\u76f8\u5e72\u4f0a\u8f9b\u673a\u4f5c\u4e3a\u89e3\u51b3NP\u5b8c\u5168\u95ee\u9898\u7684\u6df7\u5408\u91cf\u5b50\u8ba1\u7b97\u8bbe\u5907\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u566a\u58f0\u8bf1\u5bfc\u5c40\u90e8\u6781\u5c0f\u503c\u7b49\u6311\u6218\u3002\u7814\u7a76\u65e8\u5728\u63d0\u9ad8CIM\u7684\u8ba1\u7b97\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u63a2\u7d22\u5176\u5728\u5206\u5b50\u5bf9\u63a5\u548c\u4fe1\u7528\u8bc4\u5206\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u98de\u79d2\u6fc0\u5149\u6cf5\u6d66\u6280\u672f\u5b9e\u73b0\u76f8\u5e72\u4f0a\u8f9b\u673a\uff0c\u5728\u5149\u5b66\u548c\u7ed3\u6784\u7ef4\u5ea6\u96c6\u6210\u4f18\u5316\u7b56\u7565\u3002\u98de\u79d2\u8109\u51b2\u4ea7\u751f\u66f4\u9ad8\u5cf0\u503c\u529f\u7387\uff0c\u589e\u5f3a\u91cf\u5b50\u6548\u5e94\u5e76\u964d\u4f4e\u5149\u7ea4CIM\u7684\u6cf5\u6d66\u529f\u7387\u3002", "result": "\u5728100\u4e2a\u9876\u70b9\u7684\u83ab\u6bd4\u4e4c\u65af\u68af\u56fe\u4e0a\u8fbe\u523055%\u7684\u5e73\u5747\u6700\u4f18\u89e3\u8bc6\u522b\u6210\u529f\u7387\uff0c\u76f8\u6bd4\u5176\u4ed6\u65b9\u6848\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u7cfb\u7edf\u80fd\u8fde\u7eed8\u5c0f\u65f6\u4fdd\u6301\u9ad8\u6210\u529f\u7387\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u98de\u79d2\u6fc0\u5149\u6cf5\u6d66\u7684\u76f8\u5e72\u4f0a\u8f9b\u673a\u5728\u89e3\u51b3NP\u5b8c\u5168\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86CIM\u7684\u7406\u8bba\u6f5c\u529b\uff0c\u4e3a\u5176\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2512.06649", "categories": ["cs.LG", "cs.CV", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.06649", "abs": "https://arxiv.org/abs/2512.06649", "authors": ["Camellia Zakaria", "Aryan Sadeghi", "Weaam Jaafar", "Junshi Xu", "Alex Mariakakis", "Marianne Hatzopoulou"], "title": "Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning", "comment": "12 pages, 16 figures, 4 tables, 4 pages Appendix, in submission and under review for ACM MobiSys 2026 as of December 6th, 2025", "summary": "Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.", "AI": {"tldr": "\u5229\u7528\u4ea4\u901a\u76d1\u63a7\u89c6\u9891\u548c\u5929\u6c14\u6570\u636e\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f30\u8ba1\u8857\u9053\u7ea7\u9ed1\u78b3\u6d53\u5ea6\uff0c\u586b\u8865\u4ea4\u901a\u4e0e\u73af\u5883\u5f71\u54cd\u6570\u636e\u7f3a\u53e3", "motivation": "\u57ce\u5e02\u9ed1\u78b3\u6392\u653e\u4e3b\u8981\u6765\u81ea\u4ea4\u901a\uff0c\u4f46\u76d1\u6d4b\u6210\u672c\u9ad8\u5bfc\u81f4\u6570\u636e\u7f3a\u4e4f\uff0c\u800c\u4ea4\u901a\u76d1\u63a7\u7cfb\u7edf\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5b58\u5728\u4ea4\u901a\u72b6\u51b5\u4e0e\u73af\u5883\u5f71\u54cd\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898", "method": "\u4ece\u4ea4\u901a\u89c6\u9891\u4e2d\u63d0\u53d6\u8f66\u8f86\u884c\u4e3a\u548c\u72b6\u51b5\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u7ed3\u5408\u5929\u6c14\u6570\u636e\uff0c\u6784\u5efa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f30\u8ba1\u8857\u9053\u7ea7\u9ed1\u78b3\u6d53\u5ea6", "result": "\u6a21\u578b\u8fbe\u5230R\u5e73\u65b9\u503c0.72\uff0cRMSE\u4e3a129.42 ng/m\u00b3\uff0c\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u8857\u9053\u7ea7\u9ed1\u78b3\u6d53\u5ea6", "conclusion": "\u5229\u7528\u73b0\u6709\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\u548c\u5efa\u6a21\u6280\u672f\uff0c\u4e3a\u6c61\u67d3\u51cf\u6392\u3001\u57ce\u5e02\u89c4\u5212\u3001\u516c\u5171\u536b\u751f\u548c\u73af\u5883\u6b63\u4e49\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u9ed1\u78b3\u6d53\u5ea6\u6570\u636e"}}
{"id": "2512.07250", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.07250", "abs": "https://arxiv.org/abs/2512.07250", "authors": ["Miloslav Znojil"], "title": "Non-Hermitian Bose-Hubbard-like quantum models", "comment": "talk presented to the XXIX Int. Conf. on Integrable Systems and Quantum Symmetries (Prague, CTU, July 7 - 11, 2025)", "summary": "Among all of the non-Hermitian large-tridiagonal-matrix quantum Hamiltonians we choose a subclass with the structure resembling the ``benchmark'' realistic Bose-Hubbard model. We demonstrate that this choice can be declared user-friendly in the sense that the underlying singular values can be specified via a ``Hermitized'' Schr\u00f6dinger-like equation. In particular, the related ``Hermitized'' Green's functions is shown given the two alternative compact and numerically efficient matrix continued fraction forms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u7c7b\u975e\u5384\u7c73\u5927\u4e09\u89d2\u77e9\u9635\u91cf\u5b50\u54c8\u5bc6\u987f\u91cf\uff0c\u5176\u7ed3\u6784\u7c7b\u4f3c\u4e8eBose-Hubbard\u6a21\u578b\uff0c\u53ef\u901a\u8fc7\"\u5384\u7c73\u5316\"\u859b\u5b9a\u8c14\u65b9\u7a0b\u8ba1\u7b97\u5947\u5f02\u503c\uff0c\u5e76\u7ed9\u51fa\u4e24\u79cd\u7d27\u51d1\u7684\u77e9\u9635\u8fde\u5206\u5f0f\u5f62\u5f0f\u7684\u683c\u6797\u51fd\u6570\u3002", "motivation": "\u7814\u7a76\u975e\u5384\u7c73\u5927\u4e09\u89d2\u77e9\u9635\u91cf\u5b50\u54c8\u5bc6\u987f\u91cf\uff0c\u7279\u522b\u662f\u4e0eBose-Hubbard\u6a21\u578b\u7ed3\u6784\u76f8\u4f3c\u7684\u5b50\u7c7b\uff0c\u65e8\u5728\u5f00\u53d1\u7528\u6237\u53cb\u597d\u7684\u6570\u503c\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u9009\u62e9\u4e00\u7c7b\u7ed3\u6784\u7c7b\u4f3c\u4e8eBose-Hubbard\u6a21\u578b\u7684\u975e\u5384\u7c73\u5927\u4e09\u89d2\u77e9\u9635\u54c8\u5bc6\u987f\u91cf\uff0c\u901a\u8fc7\"\u5384\u7c73\u5316\"\u859b\u5b9a\u8c14\u65b9\u7a0b\u8ba1\u7b97\u5947\u5f02\u503c\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e24\u79cd\u7d27\u51d1\u7684\u77e9\u9635\u8fde\u5206\u5f0f\u5f62\u5f0f\u7684\u683c\u6797\u51fd\u6570\u3002", "result": "\u6210\u529f\u5c06\u8fd9\u7c7b\u975e\u5384\u7c73\u54c8\u5bc6\u987f\u91cf\u7684\u5947\u5f02\u503c\u8ba1\u7b97\u8f6c\u5316\u4e3a\"\u5384\u7c73\u5316\"\u859b\u5b9a\u8c14\u65b9\u7a0b\u95ee\u9898\uff0c\u5e76\u83b7\u5f97\u4e86\u4e24\u79cd\u6570\u503c\u9ad8\u6548\u7684\u77e9\u9635\u8fde\u5206\u5f0f\u683c\u6797\u51fd\u6570\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u7279\u5b9a\u7c7b\u578b\u7684\u975e\u5384\u7c73\u5927\u4e09\u89d2\u77e9\u9635\u54c8\u5bc6\u987f\u91cf\u63d0\u4f9b\u4e86\u7528\u6237\u53cb\u597d\u7684\u6570\u503c\u8ba1\u7b97\u6846\u67b6\uff0c\u7279\u522b\u662f\u5176\u683c\u6797\u51fd\u6570\u7684\u77e9\u9635\u8fde\u5206\u5f0f\u5f62\u5f0f\u5177\u6709\u8ba1\u7b97\u6548\u7387\u4f18\u52bf\u3002"}}
{"id": "2512.06652", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06652", "abs": "https://arxiv.org/abs/2512.06652", "authors": ["Xiaolei Lu", "Shamim Nemati"], "title": "Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts", "comment": null, "summary": "Accurate prediction of the need for invasive mechanical ventilation (IMV) in intensive care units (ICUs) patients is crucial for timely interventions and resource allocation. However, variability in patient populations, clinical practices, and electronic health record (EHR) systems across institutions introduces domain shifts that degrade the generalization performance of predictive models during deployment. Test-Time Training (TTT) has emerged as a promising approach to mitigate such shifts by adapting models dynamically during inference without requiring labeled target-domain data. In this work, we introduce Adaptive Test-Time Training (AdaTTT), an enhanced TTT framework tailored for EHR-based IMV prediction in ICU settings. We begin by deriving information-theoretic bounds on the test-time prediction error and demonstrate that it is constrained by the uncertainty between the main and auxiliary tasks. To enhance their alignment, we introduce a self-supervised learning framework with pretext tasks: reconstruction and masked feature modeling optimized through a dynamic masking strategy that emphasizes features critical to the main task. Additionally, to improve robustness against domain shifts, we incorporate prototype learning and employ Partial Optimal Transport (POT) for flexible, partial feature alignment while maintaining clinically meaningful patient representations. Experiments across multi-center ICU cohorts demonstrate competitive classification performance on different test-time adaptation benchmarks.", "AI": {"tldr": "AdaTTT\uff1a\u4e00\u79cd\u9488\u5bf9ICU\u60a3\u8005\u6709\u521b\u673a\u68b0\u901a\u6c14\u9884\u6d4b\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u5206\u6790\u3001\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u539f\u578b\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u5728\u8de8\u673a\u6784\u90e8\u7f72\u65f6\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "ICU\u60a3\u8005\u6709\u521b\u673a\u68b0\u901a\u6c14\u9884\u6d4b\u6a21\u578b\u5728\u8de8\u673a\u6784\u90e8\u7f72\u65f6\uff0c\u7531\u4e8e\u60a3\u8005\u7fa4\u4f53\u3001\u4e34\u5e8a\u5b9e\u8df5\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u7684\u5dee\u5f02\u5bfc\u81f4\u9886\u57df\u504f\u79fb\uff0c\u5f71\u54cd\u6a21\u578b\u6cdb\u5316\u6027\u80fd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9002\u5e94\u3001\u65e0\u9700\u76ee\u6807\u57df\u6807\u6ce8\u6570\u636e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u6846\u67b6AdaTTT\uff1a1) \u57fa\u4e8e\u4fe1\u606f\u8bba\u5206\u6790\u4e3b\u4efb\u52a1\u4e0e\u8f85\u52a9\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\u5173\u7cfb\uff1b2) \u5f15\u5165\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u91cd\u5efa\u548c\u63a9\u7801\u7279\u5f81\u5efa\u6a21\u4efb\u52a1\uff0c\u91c7\u7528\u52a8\u6001\u63a9\u7801\u7b56\u7565\u5f3a\u8c03\u4e3b\u4efb\u52a1\u5173\u952e\u7279\u5f81\uff1b3) \u7ed3\u5408\u539f\u578b\u5b66\u4e60\u548c\u90e8\u5206\u6700\u4f18\u4f20\u8f93\u8fdb\u884c\u7075\u6d3b\u7684\u7279\u5f81\u5bf9\u9f50\uff0c\u4fdd\u6301\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u60a3\u8005\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2d\u5fc3ICU\u961f\u5217\u5b9e\u9a8c\u4e2d\uff0c\u5728\u4e0d\u540c\u6d4b\u8bd5\u65f6\u9002\u5e94\u57fa\u51c6\u4e0a\u5c55\u793a\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "AdaTTT\u6846\u67b6\u901a\u8fc7\u4fe1\u606f\u8bba\u6307\u5bfc\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\u65f6\u8bad\u7ec3\uff0c\u6709\u6548\u7f13\u89e3\u4e86ICU\u9884\u6d4b\u6a21\u578b\u5728\u8de8\u673a\u6784\u90e8\u7f72\u65f6\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6709\u521b\u673a\u68b0\u901a\u6c14\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.07264", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.07264", "abs": "https://arxiv.org/abs/2512.07264", "authors": ["Anton Montag", "Tomoki Ozawa"], "title": "Quantum geometrical effects in non-Hermitian systems", "comment": "14 pages, 3 figures", "summary": "We explore the relation between quantum geometry in non-Hermitian systems and physically measurable phenomena. We highlight various situations in which the behavior of a non-Hermitian system is best understood in terms of quantum geometry, namely the notion of adiabatic potentials in non-Hermitian systems and the localization of Wannier states in periodic non-Hermitian systems. Further, we show that the non-Hermitian quantum metric appears in the response of the system upon time-periodic modulation, which one can use to experimentally measure the non-Hermitian quantum metric. We validate our results by providing numerical simulations of concrete exemplary systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u91cf\u5b50\u51e0\u4f55\u4e0e\u7269\u7406\u53ef\u89c2\u6d4b\u73b0\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u51e0\u4f55\u5982\u4f55\u89e3\u91ca\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u65f6\u95f4\u5468\u671f\u8c03\u5236\u5b9e\u9a8c\u6d4b\u91cf\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u7684\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u91cf\u5b50\u51e0\u4f55\u4e0e\u7269\u7406\u53ef\u89c2\u6d4b\u73b0\u8c61\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u91cf\u5b50\u51e0\u4f55\u6982\u5ff5\u66f4\u597d\u5730\u7406\u89e3\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u884c\u4e3a\uff0c\u5e76\u5bfb\u627e\u5b9e\u9a8c\u6d4b\u91cf\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u7684\u7edd\u70ed\u52bf\u548c\u5468\u671f\u975e\u5384\u7c73\u7cfb\u7edf\u4e2dWannier\u6001\u7684\u5c40\u57df\u5316\u884c\u4e3a\uff0c\u5efa\u7acb\u91cf\u5b50\u51e0\u4f55\u6846\u67b6\uff1b\u63d0\u51fa\u901a\u8fc7\u65f6\u95f4\u5468\u671f\u8c03\u5236\u6765\u63a2\u6d4b\u7cfb\u7edf\u54cd\u5e94\uff0c\u5176\u4e2d\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u4f1a\u663e\u73b0\uff1b\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u7cfb\u7edf\u7684\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u53d1\u73b0\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u884c\u4e3a\u53ef\u4ee5\u901a\u8fc7\u91cf\u5b50\u51e0\u4f55\u6982\u5ff5\u5f97\u5230\u6700\u4f73\u7406\u89e3\uff1b\u8bc1\u660e\u4e86\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u5728\u7cfb\u7edf\u5bf9\u65f6\u95f4\u5468\u671f\u8c03\u5236\u7684\u54cd\u5e94\u4e2d\u51fa\u73b0\uff0c\u8fd9\u4e3a\u5b9e\u9a8c\u6d4b\u91cf\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff1b\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u91cf\u5b50\u51e0\u4f55\u4e3a\u975e\u5384\u7c73\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u6846\u67b6\uff0c\u975e\u5384\u7c73\u91cf\u5b50\u5ea6\u91cf\u53ef\u4ee5\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u91cf\uff0c\u8fd9\u4e3a\u7406\u89e3\u548c\u8868\u5f81\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u51e0\u4f55\u7279\u6027\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.06655", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06655", "abs": "https://arxiv.org/abs/2512.06655", "authors": ["Jehyeok Yeon", "Federico Cinus", "Yifan Wu", "Luca Luceri"], "title": "GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering", "comment": null, "summary": "Large language models (LLMs) face critical safety challenges, as they can be manipulated to generate harmful content through adversarial prompts and jailbreak attacks. Many defenses are typically either black-box guardrails that filter outputs, or internals-based methods that steer hidden activations by operationalizing safety as a single latent feature or dimension. While effective for simple concepts, this assumption is limiting, as recent evidence shows that abstract concepts such as refusal and temporality are distributed across multiple features rather than isolated in one. To address this limitation, we introduce Graph-Regularized Sparse Autoencoders (GSAEs), which extends SAEs with a Laplacian smoothness penalty on the neuron co-activation graph. Unlike standard SAEs that assign each concept to a single latent feature, GSAEs recover smooth, distributed safety representations as coherent patterns spanning multiple features. We empirically demonstrate that GSAE enables effective runtime safety steering, assembling features into a weighted set of safety-relevant directions and controlling them with a two-stage gating mechanism that activates interventions only when harmful prompts or continuations are detected during generation. This approach enforces refusals adaptively while preserving utility on benign queries. Across safety and QA benchmarks, GSAE steering achieves an average 82% selective refusal rate, substantially outperforming standard SAE steering (42%), while maintaining strong task accuracy (70% on TriviaQA, 65% on TruthfulQA, 74% on GSM8K). Robustness experiments further show generalization across LLaMA-3, Mistral, Qwen, and Phi families and resilience against jailbreak attacks (GCG, AutoDAN), consistently maintaining >= 90% refusal of harmful content.", "AI": {"tldr": "GSAE\u901a\u8fc7\u56fe\u6b63\u5219\u5316\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u5b89\u5168\u6982\u5ff5\u7684\u5206\u5e03\u5f0f\u8868\u793a\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u95e8\u63a7\u673a\u5236\u5b9e\u73b0\u8fd0\u884c\u65f6\u5b89\u5168\u5f15\u5bfc\uff0c\u5728\u4fdd\u6301\u826f\u6027\u67e5\u8be2\u6548\u7528\u7684\u540c\u65f6\u6709\u6548\u62d2\u7edd\u6709\u5bb3\u5185\u5bb9\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u901a\u5e38\u5c06\u5b89\u5168\u6982\u5ff5\u89c6\u4e3a\u5355\u4e00\u6f5c\u5728\u7279\u5f81\uff0c\u4f46\u7814\u7a76\u8868\u660e\u62bd\u8c61\u6982\u5ff5\uff08\u5982\u62d2\u7edd\u3001\u65f6\u95f4\u6027\uff09\u5b9e\u9645\u4e0a\u662f\u5206\u5e03\u5728\u591a\u4e2a\u7279\u5f81\u4e2d\u7684\u3002\u8fd9\u79cd\u7b80\u5316\u5047\u8bbe\u9650\u5236\u4e86\u5b89\u5168\u9632\u5fa1\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u56fe\u6b63\u5219\u5316\u7a00\u758f\u81ea\u7f16\u7801\u5668(GSAE)\uff0c\u5728\u6807\u51c6SAE\u57fa\u7840\u4e0a\u589e\u52a0\u795e\u7ecf\u5143\u5171\u6fc0\u6d3b\u56fe\u7684\u62c9\u666e\u62c9\u65af\u5e73\u6ed1\u60e9\u7f5a\uff0c\u5b66\u4e60\u5e73\u6ed1\u7684\u5206\u5e03\u5f0f\u5b89\u5168\u8868\u793a\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u95e8\u63a7\u673a\u5236\uff1a\u68c0\u6d4b\u5230\u6709\u5bb3\u63d0\u793a\u6216\u751f\u6210\u5185\u5bb9\u65f6\u6fc0\u6d3b\u5e72\u9884\uff0c\u5c06\u591a\u4e2a\u7279\u5f81\u7ec4\u88c5\u6210\u52a0\u6743\u5b89\u5168\u76f8\u5173\u65b9\u5411\u8fdb\u884c\u63a7\u5236\u3002", "result": "GSAE\u5f15\u5bfc\u5728\u5b89\u5168\u57fa\u51c6\u4e0a\u5e73\u5747\u8fbe\u523082%\u7684\u9009\u62e9\u6027\u62d2\u7edd\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6SAE\u5f15\u5bfc(42%)\uff0c\u540c\u65f6\u5728TriviaQA(70%)\u3001TruthfulQA(65%)\u3001GSM8K(74%)\u7b49\u4efb\u52a1\u4e0a\u4fdd\u6301\u826f\u597d\u51c6\u786e\u6027\u3002\u5728LLaMA-3\u3001Mistral\u3001Qwen\u3001Phi\u7b49\u6a21\u578b\u5bb6\u65cf\u4e0a\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff0c\u5bf9GCG\u3001AutoDAN\u7b49\u8d8a\u72f1\u653b\u51fb\u4fdd\u6301\u226590%\u7684\u6709\u5bb3\u5185\u5bb9\u62d2\u7edd\u7387\u3002", "conclusion": "GSAE\u80fd\u591f\u5b66\u4e60\u5b89\u5168\u6982\u5ff5\u7684\u5206\u5e03\u5f0f\u8868\u793a\uff0c\u901a\u8fc7\u6709\u6548\u7684\u8fd0\u884c\u65f6\u5f15\u5bfc\u673a\u5236\u5728\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\uff0c\u4e3aLLM\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2512.07304", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07304", "abs": "https://arxiv.org/abs/2512.07304", "authors": ["Mark Myers", "Mariesa H. Teo", "Rajesh Mishra", "Jing Hao Chai", "Hui Khoon Ng"], "title": "Simulating general noise nearly as cheaply as Pauli noise", "comment": null, "summary": "Stabilizer simulation of Clifford quantum circuits - error-correction circuits, Clifford subroutines, etc. - on classical computers has played a central role in our understanding of circuit performance. The stabilizer description, however, restricts the accessible noise one can incorporate into the simulation to Pauli-type noise. More general noise, including coherent errors, may have more severe impact on circuit performance than Pauli noise; yet, such general noise have been difficult to access, much less investigate fully, in numerical simulations. Here, through the use of stratified importance sampling, we show how general noise can be simulated within the stabilizer formalism in reasonable time, with non-unitary noise being nearly as cheap as Pauli noise. Unitary (or coherent) noise can require an order of magnitude more time for the simulation, but nevertheless completes in very reasonable times, a drastic improvement over past approaches that typically fail to converge altogether. Our work thus enables detailed beyond-Pauli understanding of circuit performance in the presence of real device noise, which is rarely Pauli in nature. Among other examples, we present direct simulation results for the performance of the popular rotated planar surface codes under circuit-level general noise, previously available only in limited situations and/or through mappings to efficiently simulatable physical models.", "AI": {"tldr": "\u901a\u8fc7\u5206\u5c42\u91cd\u8981\u6027\u91c7\u6837\uff0c\u5728\u7a33\u5b9a\u5b50\u5f62\u5f0f\u4e2d\u9ad8\u6548\u6a21\u62df\u4e00\u822c\u566a\u58f0\uff08\u5305\u62ec\u76f8\u5e72\u8bef\u5dee\uff09\uff0c\u663e\u8457\u6539\u8fdb\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u7a33\u5b9a\u5b50\u6a21\u62df\u53ea\u80fd\u5904\u7406\u6ce1\u5229\u578b\u566a\u58f0\uff0c\u4f46\u5b9e\u9645\u8bbe\u5907\u566a\u58f0\u901a\u5e38\u662f\u975e\u6ce1\u5229\u7684\uff0c\u5305\u62ec\u76f8\u5e72\u8bef\u5dee\u53ef\u80fd\u5bf9\u7535\u8def\u6027\u80fd\u4ea7\u751f\u66f4\u4e25\u91cd\u5f71\u54cd", "method": "\u91c7\u7528\u5206\u5c42\u91cd\u8981\u6027\u91c7\u6837\u65b9\u6cd5\uff0c\u5728\u7a33\u5b9a\u5b50\u5f62\u5f0f\u6846\u67b6\u5185\u6a21\u62df\u4e00\u822c\u566a\u58f0\uff0c\u975e\u9149\u566a\u58f0\u6a21\u62df\u6210\u672c\u63a5\u8fd1\u6ce1\u5229\u566a\u58f0\uff0c\u9149\u566a\u58f0\uff08\u76f8\u5e72\u8bef\u5dee\uff09\u6a21\u62df\u65f6\u95f4\u589e\u52a0\u4f46\u4ecd\u5728\u5408\u7406\u8303\u56f4\u5185", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u4e00\u822c\u566a\u58f0\u7684\u9ad8\u6548\u6a21\u62df\uff0c\u975e\u9149\u566a\u58f0\u6a21\u62df\u6210\u672c\u63a5\u8fd1\u6ce1\u5229\u566a\u58f0\uff0c\u9149\u566a\u58f0\u6a21\u62df\u65f6\u95f4\u589e\u52a0\u4e00\u4e2a\u6570\u91cf\u7ea7\u4f46\u4ecd\u5728\u5408\u7406\u8303\u56f4\u5185\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u5f97\u5728\u7a33\u5b9a\u5b50\u5f62\u5f0f\u4e2d\u8be6\u7ec6\u7814\u7a76\u8d85\u8d8a\u6ce1\u5229\u566a\u58f0\u7684\u7535\u8def\u6027\u80fd\u6210\u4e3a\u53ef\u80fd\uff0c\u4e3a\u7406\u89e3\u771f\u5b9e\u8bbe\u5907\u566a\u58f0\u5bf9\u7535\u8def\u6027\u80fd\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177"}}
{"id": "2512.06665", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.06665", "abs": "https://arxiv.org/abs/2512.06665", "authors": ["Panagiota Kiourti", "Anu Singh", "Preeti Duraipandian", "Weichao Zhou", "Wenchao Li"], "title": "Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods", "comment": null, "summary": "This paper studies the robustness of feature attribution methods for deep neural networks. It challenges the current notion of attributional robustness that largely ignores the difference in the model's outputs and introduces a new way of evaluating the robustness of attribution methods. Specifically, we propose a new definition of similar inputs, a new robustness metric, and a novel method based on generative adversarial networks to generate these inputs. In addition, we present a comprehensive evaluation with existing metrics and state-of-the-art attribution methods. Our findings highlight the need for a more objective metric that reveals the weaknesses of an attribution method rather than that of the neural network, thus providing a more accurate evaluation of the robustness of attribution methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u9c81\u68d2\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u6311\u6218\u4e86\u73b0\u6709\u5ffd\u7565\u6a21\u578b\u8f93\u51fa\u5dee\u5f02\u7684\u8bc4\u4f30\u65b9\u5f0f\uff0c\u901a\u8fc7\u5b9a\u4e49\u76f8\u4f3c\u8f93\u5165\u3001\u65b0\u9c81\u68d2\u6027\u6307\u6807\u548cGAN\u751f\u6210\u65b9\u6cd5\uff0c\u4e3a\u5f52\u56e0\u65b9\u6cd5\u63d0\u4f9b\u66f4\u5ba2\u89c2\u7684\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7684\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u9c81\u68d2\u6027\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8f93\u5165\u6270\u52a8\u4e0b\u7684\u5f52\u56e0\u56fe\u53d8\u5316\uff0c\u4f46\u5ffd\u7565\u4e86\u6a21\u578b\u8f93\u51fa\u672c\u8eab\u7684\u5dee\u5f02\u3002\u8fd9\u79cd\u8bc4\u4f30\u65b9\u5f0f\u53ef\u80fd\u5bfc\u81f4\u5bf9\u5f52\u56e0\u65b9\u6cd5\u9c81\u68d2\u6027\u7684\u8bef\u5224\uff0c\u9700\u8981\u66f4\u5ba2\u89c2\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u63ed\u793a\u5f52\u56e0\u65b9\u6cd5\u672c\u8eab\u7684\u5f31\u70b9\u800c\u975e\u795e\u7ecf\u7f51\u7edc\u7684\u5f31\u70b9\u3002", "method": "\u63d0\u51fa\u4e09\u65b9\u9762\u521b\u65b0\uff1a1) \u65b0\u7684\u76f8\u4f3c\u8f93\u5165\u5b9a\u4e49\uff1b2) \u65b0\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u6307\u6807\uff1b3) \u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc(GAN)\u7684\u65b9\u6cd5\u6765\u751f\u6210\u8fd9\u4e9b\u76f8\u4f3c\u8f93\u5165\u3002\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\u73b0\u6709\u6307\u6807\u548c\u6700\u5148\u8fdb\u7684\u5f52\u56e0\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u65b0\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65b0\u63d0\u51fa\u7684\u8bc4\u4f30\u6846\u67b6\u80fd\u591f\u66f4\u51c6\u786e\u5730\u63ed\u793a\u5f52\u56e0\u65b9\u6cd5\u7684\u5f31\u70b9\u3002\u901a\u8fc7GAN\u751f\u6210\u7684\u76f8\u4f3c\u8f93\u5165\u548c\u65b0\u7684\u9c81\u68d2\u6027\u6307\u6807\uff0c\u63d0\u4f9b\u4e86\u5bf9\u5f52\u56e0\u65b9\u6cd5\u9c81\u68d2\u6027\u66f4\u5ba2\u89c2\u7684\u8bc4\u4f30\u3002", "conclusion": "\u9700\u8981\u66f4\u5ba2\u89c2\u7684\u8bc4\u4f30\u6307\u6807\u6765\u51c6\u786e\u8bc4\u4f30\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u65b0\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u5173\u6ce8\u5f52\u56e0\u65b9\u6cd5\u672c\u8eab\u7684\u5f31\u70b9\u800c\u975e\u795e\u7ecf\u7f51\u7edc\u7684\u5f31\u70b9\uff0c\u4e3a\u5f52\u56e0\u65b9\u6cd5\u9c81\u68d2\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.07307", "categories": ["quant-ph", "physics.bio-ph", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2512.07307", "abs": "https://arxiv.org/abs/2512.07307", "authors": ["Zhiyuan Zhao", "Qian Shi", "Shaoyi Xu", "Xiangyu Ye", "Mengze Shen", "Jia Su", "Ya Wang", "Tianyu Xie", "Qingsong Hu", "Fazhan Shi", "Jiangfeng Du"], "title": "Single-cell identification with quantum-enhanced nuclear magnetic resonance", "comment": "23 pages, 4 figures", "summary": "Identification of individual cells within heterogeneous populations is essential for biomedical research and clinical diagnostics. Conventional labeling-based sorting methods, such as fluorescence-activated cell sorting and magnetic-activated cell sorting, enable precise sorting when reliable markers are available. However, their applicability is limited in cells lacking defined markers or sensitive to labeling, as labeling can compromise cellular viability and function. We present a single-cell identification approach using quantum-enhanced NMR with diamond nitrogen-vacancy centers for label-free detection of intracellular proton ($^1$H) signals. Using this method, we distinguish two human tumor cell lines by their proton spin-lattice ($T_1$) relaxation times, which serve as a cell-intrinsic physicochemical signature. It lays the groundwork for label-free sorting applications in rare cell analysis, personalized medicine, and single-cell diagnostics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u589e\u5f3aNMR\u548c\u91d1\u521a\u77f3\u6c2e\u7a7a\u4f4d\u4e2d\u5fc3\u7684\u5355\u7ec6\u80de\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u7ec6\u80de\u5185\u8d28\u5b50\u4fe1\u53f7\u5b9e\u73b0\u65e0\u6807\u8bb0\u7ec6\u80de\u533a\u5206\u3002", "motivation": "\u4f20\u7edf\u6807\u8bb0\u5206\u9009\u65b9\u6cd5\uff08\u5982\u8367\u5149\u6fc0\u6d3b\u7ec6\u80de\u5206\u9009\u548c\u78c1\u6fc0\u6d3b\u7ec6\u80de\u5206\u9009\uff09\u5728\u7f3a\u4e4f\u660e\u786e\u6807\u8bb0\u7269\u6216\u5bf9\u6807\u8bb0\u654f\u611f\u7684\u7ec6\u80de\u4e2d\u5e94\u7528\u53d7\u9650\uff0c\u56e0\u4e3a\u6807\u8bb0\u53ef\u80fd\u635f\u5bb3\u7ec6\u80de\u6d3b\u6027\u548c\u529f\u80fd\u3002\u9700\u8981\u5f00\u53d1\u65e0\u6807\u8bb0\u7684\u7ec6\u80de\u8bc6\u522b\u6280\u672f\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u589e\u5f3a\u6838\u78c1\u5171\u632f\u6280\u672f\uff0c\u5229\u7528\u91d1\u521a\u77f3\u6c2e\u7a7a\u4f4d\u4e2d\u5fc3\u68c0\u6d4b\u7ec6\u80de\u5185\u8d28\u5b50\uff08\u00b9H\uff09\u4fe1\u53f7\uff0c\u901a\u8fc7\u6d4b\u91cf\u8d28\u5b50\u81ea\u65cb-\u6676\u683c\uff08T\u2081\uff09\u5f1b\u8c6b\u65f6\u95f4\u6765\u533a\u5206\u4e0d\u540c\u7ec6\u80de\u7cfb\u3002", "result": "\u6210\u529f\u533a\u5206\u4e86\u4e24\u79cd\u4eba\u7c7b\u80bf\u7624\u7ec6\u80de\u7cfb\uff0c\u5229\u7528\u5176\u8d28\u5b50T\u2081\u5f1b\u8c6b\u65f6\u95f4\u4f5c\u4e3a\u7ec6\u80de\u56fa\u6709\u7684\u7269\u7406\u5316\u5b66\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u65e0\u6807\u8bb0\u7ec6\u80de\u8bc6\u522b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u6807\u8bb0\u7ec6\u80de\u5206\u9009\u5728\u7a00\u6709\u7ec6\u80de\u5206\u6790\u3001\u4e2a\u6027\u5316\u533b\u7597\u548c\u5355\u7ec6\u80de\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.06666", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06666", "abs": "https://arxiv.org/abs/2512.06666", "authors": ["Urav Maniar"], "title": "The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification", "comment": "Link to the repository: https://github.com/urav06/research", "summary": "Time series classification faces a fundamental trade-off between accuracy and computational efficiency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR benchmark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two efficient algorithms from complementary paradigms can capture ensemble benefits while maintaining computational feasibility. Combining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble configurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest configuration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimization gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows moderate correlation with ensemble gains. The central finding: the challenge has shifted from ensuring algorithms are different to learning how to combine them effectively. Current meta-learning strategies struggle to exploit the complementarity that oracle analysis confirms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classification applications.", "AI": {"tldr": "\u7ed3\u5408Hydra\u548cQuant\u4e24\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u901a\u8fc7\u516d\u79cd\u96c6\u6210\u914d\u7f6e\u5728\u5927\u578b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u53d1\u73b0\u7279\u5f81\u62fc\u63a5\u65b9\u6cd5\u4f18\u4e8e\u9884\u6d4b\u7ec4\u5408\uff0c\u5f53\u524d\u5143\u5b66\u4e60\u7b56\u7565\u672a\u80fd\u5145\u5206\u5229\u7528\u7b97\u6cd5\u4e92\u8865\u6027\uff0c\u6539\u8fdb\u7ec4\u5408\u7b56\u7565\u53ef\u663e\u8457\u63d0\u5347\u96c6\u6210\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\u3002\u867d\u7136\u50cfHIVE-COTE 2.0\u8fd9\u6837\u7684\u5168\u9762\u96c6\u6210\u80fd\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u4f46\u5176\u5728UCR\u57fa\u51c6\u6d4b\u8bd5\u4e0a340\u5c0f\u65f6\u7684\u8bad\u7ec3\u65f6\u95f4\u5bf9\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6765\u8bf4\u4e0d\u5207\u5b9e\u9645\u3002\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u6765\u81ea\u4e92\u8865\u8303\u5f0f\u7684\u9ad8\u6548\u7b97\u6cd5\u6765\u83b7\u5f97\u96c6\u6210\u4f18\u52bf\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "method": "\u7ed3\u5408Hydra\uff08\u7ade\u4e89\u5377\u79ef\u6838\uff09\u548cQuant\uff08\u5206\u5c42\u533a\u95f4\u5206\u4f4d\u6570\uff09\u4e24\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u516d\u79cd\u96c6\u6210\u914d\u7f6e\u3002\u572810\u4e2a\u5927\u89c4\u6a21MONSTER\u6570\u636e\u96c6\uff087,898\u52301,168,774\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\uff09\u4e0a\u8bc4\u4f30\u6027\u80fd\uff0c\u5305\u62ec\u9884\u6d4b\u7ec4\u5408\u548c\u7279\u5f81\u62fc\u63a5\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\u3002", "result": "\u6700\u5f3a\u914d\u7f6e\u5c06\u5e73\u5747\u51c6\u786e\u7387\u4ece0.829\u63d0\u9ad8\u52300.836\uff0c\u572810\u4e2a\u6570\u636e\u96c6\u4e2d\u76847\u4e2a\u4e0a\u53d6\u5f97\u6210\u529f\u3002\u4f46\u9884\u6d4b\u7ec4\u5408\u96c6\u6210\u4ec5\u6355\u6349\u523011%\u7684\u7406\u8bbaoracle\u6f5c\u529b\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u5143\u5b66\u4e60\u4f18\u5316\u5dee\u8ddd\u3002\u7279\u5f81\u62fc\u63a5\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u65b0\u7684\u51b3\u7b56\u8fb9\u754c\u8d85\u8fc7\u4e86oracle\u754c\u9650\uff0c\u800c\u9884\u6d4b\u7ea7\u4e92\u8865\u6027\u4e0e\u96c6\u6210\u589e\u76ca\u5448\u4e2d\u7b49\u76f8\u5173\u6027\u3002", "conclusion": "\u6838\u5fc3\u53d1\u73b0\uff1a\u6311\u6218\u5df2\u4ece\u786e\u4fdd\u7b97\u6cd5\u4e0d\u540c\u8f6c\u53d8\u4e3a\u5b66\u4e60\u5982\u4f55\u6709\u6548\u7ec4\u5408\u5b83\u4eec\u3002\u5f53\u524d\u7684\u5143\u5b66\u4e60\u7b56\u7565\u96be\u4ee5\u5229\u7528oracle\u5206\u6790\u786e\u8ba4\u5b58\u5728\u7684\u4e92\u8865\u6027\u3002\u6539\u8fdb\u7684\u7ec4\u5408\u7b56\u7565\u53ef\u80fd\u4f7f\u96c6\u6210\u589e\u76ca\u5728\u591a\u6837\u5316\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u5e94\u7528\u4e2d\u7ffb\u500d\u6216\u4e09\u500d\u589e\u957f\u3002"}}
{"id": "2512.07311", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07311", "abs": "https://arxiv.org/abs/2512.07311", "authors": ["Bob Wold", "Venkateswaran Kasirajan"], "title": "Revisiting Quantum Supremacy: Simulating Sycamore-Class Circuits Using Hybrid CPU/GPU HPC Workloads", "comment": null, "summary": "We present a framework for effectively simulating the execution of quantum circuits originally designed to demonstrate quantum supremacy using accessible high-performance computing (HPC) infrastructure. Building on prior CPU-only approaches, our pipeline combines a single NVIDIA A100 GPU for quantum state construction, followed by N parallel CPU jobs that perform distributed measurement sampling. We validate the fidelity by simulating the 53-qubit, 14-cycle Sycamore circuit and achieving a linear cross-entropy benchmarking (XEB) score of 0.549, exceeding the published XEB score of 0.002 from Google's reference data. We then evaluate execution time performance with the more complex 53-qubit, 20-cycle circuit, completing the full 2.5 million-shot workload over 100 CPU jobs in 01:15:36, representing a 6.95 x 10^7 speedup compared to Google's original classical estimate. Further, we show that if 1,000 CPU jobs were employed, the estimated duration would be approximately 00:17:35, only 12 minutes slower than the time taken by the original QPU-based experiment. These results illustrate that 'quantum supremacy' is not fixed and continues to be a moving target. In addition, hybrid classical-quantum strategies may provide broader near-term quantum utility than once thought.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u6709\u6548\u6a21\u62df\u539f\u672c\u7528\u4e8e\u5c55\u793a\u91cf\u5b50\u9738\u6743\u7684\u91cf\u5b50\u7535\u8def\uff0c\u572853\u6bd4\u7279Sycamore\u7535\u8def\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8d8a\u8c37\u6b4c\u91cf\u5b50\u5904\u7406\u5668\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u91cf\u5b50\u9738\u6743\u58f0\u79f0\u91cf\u5b50\u8ba1\u7b97\u673a\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u7ecf\u5178\u8ba1\u7b97\u673a\uff0c\u4f46\u8fd9\u4e00\u754c\u9650\u662f\u52a8\u6001\u7684\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c55\u793a\u5229\u7528\u73b0\u6709\u9ad8\u6027\u80fd\u8ba1\u7b97\u8d44\u6e90\u53ef\u4ee5\u6a21\u62df\u539f\u672c\u88ab\u8ba4\u4e3a\u9700\u8981\u91cf\u5b50\u8ba1\u7b97\u673a\u624d\u80fd\u9ad8\u6548\u6267\u884c\u7684\u4efb\u52a1\uff0c\u6311\u6218\u91cf\u5b50\u9738\u6743\u7684\u56fa\u5b9a\u89c2\u5ff5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df7\u5408\u8ba1\u7b97\u6846\u67b6\uff1a\u4f7f\u7528\u5355\u4e2aNVIDIA A100 GPU\u8fdb\u884c\u91cf\u5b50\u6001\u6784\u5efa\uff0c\u7136\u540e\u901a\u8fc7N\u4e2a\u5e76\u884cCPU\u4f5c\u4e1a\u8fdb\u884c\u5206\u5e03\u5f0f\u6d4b\u91cf\u91c7\u6837\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86GPU\u7684\u9ad8\u6548\u8ba1\u7b97\u548cCPU\u7684\u5206\u5e03\u5f0f\u5904\u7406\u80fd\u529b\u3002", "result": "\u6210\u529f\u6a21\u62df\u4e8653\u6bd4\u7279\u300114\u5468\u671f\u7684Sycamore\u7535\u8def\uff0c\u83b7\u5f97\u7ebf\u6027\u4ea4\u53c9\u71b5\u57fa\u51c6\u5206\u65700.549\uff0c\u8fdc\u8d85\u8c37\u6b4c\u53c2\u8003\u6570\u636e\u76840.002\u3002\u5728\u66f4\u590d\u6742\u768453\u6bd4\u7279\u300120\u5468\u671f\u7535\u8def\u4e0a\uff0c\u4f7f\u7528100\u4e2aCPU\u4f5c\u4e1a\u57281\u5c0f\u65f615\u5206\u949f\u5185\u5b8c\u6210250\u4e07\u6b21\u91c7\u6837\uff0c\u76f8\u6bd4\u8c37\u6b4c\u539f\u59cb\u7ecf\u5178\u4f30\u8ba1\u52a0\u901f\u4e866.95\u00d710^7\u500d\u3002\u5982\u679c\u4f7f\u75281000\u4e2aCPU\u4f5c\u4e1a\uff0c\u9884\u8ba1\u65f6\u95f4\u4ec5\u6bd4\u539f\u59cb\u91cf\u5b50\u5b9e\u9a8c\u616212\u5206\u949f\u3002", "conclusion": "\u91cf\u5b50\u9738\u6743\u4e0d\u662f\u56fa\u5b9a\u4e0d\u53d8\u7684\uff0c\u800c\u662f\u6301\u7eed\u79fb\u52a8\u7684\u76ee\u6807\u3002\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u7b56\u7565\u53ef\u80fd\u6bd4\u4ee5\u5f80\u8ba4\u4e3a\u7684\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u8fd1\u671f\u91cf\u5b50\u5b9e\u7528\u6027\uff0c\u7ecf\u5178\u8ba1\u7b97\u65b9\u6cd5\u4ecd\u80fd\u901a\u8fc7\u4f18\u5316\u4e0d\u65ad\u6311\u6218\u91cf\u5b50\u4f18\u52bf\u7684\u754c\u9650\u3002"}}
{"id": "2512.06678", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06678", "abs": "https://arxiv.org/abs/2512.06678", "authors": ["Shrihari Sridharan", "Deepak Ravikumar", "Anand Raghunathan", "Kaushik Roy"], "title": "GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning", "comment": null, "summary": "Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.", "AI": {"tldr": "GradientSpace\uff1a\u901a\u8fc7\u5728\u5168\u7ef4\u68af\u5ea6\u7a7a\u95f4\u805a\u7c7b\u6837\u672c\uff0c\u8bad\u7ec3\u4e13\u7528LoRA\u4e13\u5bb6\u548c\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\uff0c\u89e3\u51b3\u6307\u4ee4\u8c03\u4f18\u4e2d\u7684\u68af\u5ea6\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u901a\u5e38\u5f02\u6784\uff0c\u5305\u542b\u591a\u6837\u4fe1\u606f\uff0c\u5bfc\u81f4\u68af\u5ea6\u5e72\u6270\uff08\u51b2\u7a81\u68af\u5ea6\u5c06\u6a21\u578b\u62c9\u5411\u76f8\u53cd\u65b9\u5411\uff09\uff0c\u964d\u4f4e\u6027\u80fd\u3002\u73b0\u6709\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u805a\u7c7b\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u6570\u636e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u53c2\u6570\u5b66\u4e60\uff0c\u800c\u57fa\u4e8e\u68af\u5ea6\u805a\u7c7b\u7684\u65b9\u6cd5\u56e0\u968f\u673a\u964d\u7ef4\u5bfc\u81f4\u7cbe\u5ea6\u635f\u5931\uff0c\u4e14\u4f9d\u8d56\u4e13\u5bb6\u96c6\u6210\u589e\u52a0\u63a8\u7406\u6210\u672c\u3002", "method": "\u63d0\u51faGradientSpace\u6846\u67b6\uff1a1\uff09\u5728\u5168\u7ef4\u68af\u5ea6\u7a7a\u95f4\u76f4\u63a5\u805a\u7c7b\u6837\u672c\uff1b2\uff09\u5f15\u5165\u57fa\u4e8e\u5728\u7ebfSVD\u7684\u7b97\u6cd5\uff0c\u5728LoRA\u68af\u5ea6\u4e0a\u64cd\u4f5c\uff0c\u8bc6\u522b\u6f5c\u5728\u6280\u80fd\uff0c\u907f\u514d\u5b58\u50a8\u6240\u6709\u6837\u672c\u68af\u5ea6\u7684\u4e0d\u53ef\u884c\u6210\u672c\uff1b3\uff09\u4e3a\u6bcf\u4e2a\u805a\u7c7b\u8bad\u7ec3\u4e13\u7528LoRA\u4e13\u5bb6\uff1b4\uff09\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u5728\u63a8\u7406\u65f6\u9009\u62e9\u6700\u4f73\u4e13\u5bb6\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u3001\u91d1\u878d\u548c\u521b\u610f\u5199\u4f5c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1aGradientSpace\u4ea7\u751f\u8fde\u8d2f\u7684\u4e13\u5bb6\u4e13\u4e1a\u5316\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u65b9\u6cd5\u548c\u5fae\u8c03\u6280\u672f\u83b7\u5f97\u4e00\u81f4\u7684\u7cbe\u5ea6\u63d0\u5347\u3002\u8def\u7531\u5230\u5355\u4e2a\u5408\u9002\u4e13\u5bb6\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u7684\u4e13\u5bb6\u96c6\u6210\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "GradientSpace\u901a\u8fc7\u5728\u5168\u7ef4\u68af\u5ea6\u7a7a\u95f4\u805a\u7c7b\u6709\u6548\u89e3\u51b3\u4e86\u6307\u4ee4\u8c03\u4f18\u4e2d\u7684\u68af\u5ea6\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4e13\u5bb6\u4e13\u4e1a\u5316\u548c\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u901a\u8fc7\u5355\u4e13\u5bb6\u8def\u7531\u800c\u975e\u4e13\u5bb6\u96c6\u6210\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2512.07319", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07319", "abs": "https://arxiv.org/abs/2512.07319", "authors": ["Marius Cizauskas", "Hamid Tebyanian", "Mark Fox", "Manfred Bayer", "Marc Assmann", "Alex Greilich"], "title": "33 Gbit/s source-device-independent quantum random number generator based on heterodyne detection with real-time FPGA-integrated extraction", "comment": null, "summary": "We present a high-speed continuous-variable quantum random number generator (QRNG) based on heterodyne detection of vacuum fluctuations. The scheme follows a source-device-independent (SDI) security model in which the entropy originates from quantum measurement uncertainty and no model of the source is required; security depends only on the trusted measurement device and the calibrated discretization, and thus remains valid even under adversarial state preparation. The optical field is split by a 90$^\\circ$ optical hybrid and measured by two balanced photodiodes to obtain both quadratures of the vacuum state simultaneously. The analog outputs are digitized using a dual-channel 12-bit analog-to-digital converter operating at a sampling rate of 3.2 GS/s per channel, and processed in real time by an FPGA implementing Toeplitz hashing for randomness extraction. The quantum-to-classical noise ratio was verified through calibrated power spectral density measurements and cross-checked in the time domain, confirming vacuum-noise dominance within the 1.6 GHz detection bandwidth. After extraction, the system achieves a sustained generation rate of $R_{\\rm net}= 33.92~\\mathrm{Gbit/s}$ of uniformly distributed random bits, which pass all NIST and Dieharder statistical tests. The demonstrated platform provides a compact, FPGA-based realization of a practical heterodyne continuous-variable source-independent QRNG suitable for high-rate quantum communication and secure key distribution systems.", "AI": {"tldr": "\u57fa\u4e8e\u771f\u7a7a\u6da8\u843d\u5916\u5dee\u68c0\u6d4b\u7684\u9ad8\u901f\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u968f\u673a\u6570\u53d1\u751f\u5668\uff0c\u91c7\u7528\u6e90\u8bbe\u5907\u65e0\u5173\u5b89\u5168\u6a21\u578b\uff0c\u901a\u8fc7FPGA\u5b9e\u65f6\u5904\u7406\u5b9e\u73b033.92 Gbit/s\u7684\u6301\u7eed\u751f\u6210\u901f\u7387\u3002", "motivation": "\u5f00\u53d1\u9ad8\u901f\u3001\u5b89\u5168\u7684\u91cf\u5b50\u968f\u673a\u6570\u53d1\u751f\u5668\uff0c\u6ee1\u8db3\u91cf\u5b50\u901a\u4fe1\u548c\u5bc6\u94a5\u5206\u53d1\u7cfb\u7edf\u5bf9\u9ad8\u8d28\u91cf\u968f\u673a\u6570\u7684\u9700\u6c42\u3002\u4f20\u7edfQRNG\u53ef\u80fd\u53d7\u5230\u6e90\u7aef\u653b\u51fb\uff0c\u9700\u8981\u66f4\u5b89\u5168\u7684\u6e90\u8bbe\u5907\u65e0\u5173\u6a21\u578b\u3002", "method": "\u91c7\u7528\u771f\u7a7a\u6da8\u843d\u5916\u5dee\u68c0\u6d4b\u6280\u672f\uff0c\u4f7f\u752890\u00b0\u5149\u5b66\u6df7\u5408\u5668\u5c06\u5149\u573a\u5206\u6210\u4e24\u8def\uff0c\u7531\u5e73\u8861\u5149\u7535\u4e8c\u6781\u7ba1\u540c\u65f6\u6d4b\u91cf\u771f\u7a7a\u6001\u7684\u4e24\u4e2a\u6b63\u4ea4\u5206\u91cf\u3002\u4f7f\u7528\u53cc\u901a\u905312\u4f4dADC\u4ee53.2 GS/s\u91c7\u6837\u7387\u6570\u5b57\u5316\uff0cFPGA\u5b9e\u65f6\u5b9e\u73b0Toeplitz\u54c8\u5e0c\u8fdb\u884c\u968f\u673a\u6027\u63d0\u53d6\u3002", "result": "\u7cfb\u7edf\u57281.6 GHz\u68c0\u6d4b\u5e26\u5bbd\u5185\u786e\u8ba4\u4e86\u771f\u7a7a\u566a\u58f0\u4e3b\u5bfc\uff0c\u901a\u8fc7\u529f\u7387\u8c31\u5bc6\u5ea6\u6d4b\u91cf\u548c\u65f6\u57df\u4ea4\u53c9\u9a8c\u8bc1\u3002\u63d0\u53d6\u540e\u5b9e\u73b033.92 Gbit/s\u7684\u6301\u7eed\u751f\u6210\u901f\u7387\uff0c\u6240\u6709\u968f\u673a\u6bd4\u7279\u901a\u8fc7NIST\u548cDieharder\u7edf\u8ba1\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u5e73\u53f0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u3001\u57fa\u4e8eFPGA\u7684\u5b9e\u7528\u5916\u5dee\u8fde\u7eed\u53d8\u91cf\u6e90\u65e0\u5173QRNG\u5b9e\u73b0\uff0c\u9002\u7528\u4e8e\u9ad8\u901f\u91cf\u5b50\u901a\u4fe1\u548c\u5b89\u5168\u5bc6\u94a5\u5206\u53d1\u7cfb\u7edf\uff0c\u5177\u6709\u6e90\u8bbe\u5907\u65e0\u5173\u7684\u5b89\u5168\u4f18\u52bf\u3002"}}
{"id": "2512.06692", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06692", "abs": "https://arxiv.org/abs/2512.06692", "authors": ["Shiye Lei", "Zhihao Cheng", "Dacheng Tao"], "title": "State Diversity Matters in Offline Behavior Distillation", "comment": "12 pages, 5 figures, 5 tables", "summary": "Offline Behavior Distillation (OBD), which condenses massive offline RL data into a compact synthetic behavioral dataset, offers a promising approach for efficient policy training and can be applied across various downstream RL tasks. In this paper, we uncover a misalignment between original and distilled datasets, observing that a high-quality original dataset does not necessarily yield a superior synthetic dataset. Through an empirical analysis of policy performance under varying levels of training loss, we show that datasets with greater state diversity outperforms those with higher state quality when training loss is substantial, as is often the case in OBD, whereas the relationship reverses under minimal loss, which contributes to the misalignment. By associating state quality and diversity in reducing pivotal and surrounding error, respectively, our theoretical analysis establishes that surrounding error plays a more crucial role in policy performance when pivotal error is large, thereby highlighting the importance of state diversity in OBD scenario. Furthermore, we propose a novel yet simple algorithm, state density weighted (SDW) OBD, which emphasizes state diversity by weighting the distillation objective using the reciprocal of state density, thereby distilling a more diverse state information into synthetic data. Extensive experiments across multiple D4RL datasets confirm that SDW significantly enhances OBD performance when the original dataset exhibits limited state diversity.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u79bb\u7ebf\u884c\u4e3a\u84b8\u998f\u4e2d\u539f\u59cb\u6570\u636e\u96c6\u4e0e\u5408\u6210\u6570\u636e\u96c6\u5b58\u5728\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u72b6\u6001\u591a\u6837\u6027\u5728\u8bad\u7ec3\u635f\u5931\u8f83\u5927\u65f6\u6bd4\u72b6\u6001\u8d28\u91cf\u66f4\u91cd\u8981\uff0c\u5e76\u8bbe\u8ba1\u4e86\u72b6\u6001\u5bc6\u5ea6\u52a0\u6743\u7b97\u6cd5\u6765\u63d0\u5347\u84b8\u998f\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u884c\u4e3a\u84b8\u998f\u5c06\u5927\u91cf\u79bb\u7ebfRL\u6570\u636e\u538b\u7f29\u6210\u7d27\u51d1\u7684\u5408\u6210\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u9ad8\u8d28\u91cf\u539f\u59cb\u6570\u636e\u96c6\u4e0d\u4e00\u5b9a\u4ea7\u751f\u4f18\u8d28\u5408\u6210\u6570\u636e\u96c6\uff0c\u5b58\u5728\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u5f71\u54cd\u84b8\u998f\u6548\u679c\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u4e0d\u540c\u8bad\u7ec3\u635f\u5931\u4e0b\u7684\u7b56\u7565\u6027\u80fd\uff0c\u7406\u8bba\u5206\u6790\u72b6\u6001\u8d28\u91cf\u548c\u591a\u6837\u6027\u5bf9\u5173\u952e\u8bef\u5dee\u548c\u5468\u56f4\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u72b6\u6001\u5bc6\u5ea6\u52a0\u6743\u7b97\u6cd5\uff0c\u4f7f\u7528\u72b6\u6001\u5bc6\u5ea6\u7684\u5012\u6570\u52a0\u6743\u84b8\u998f\u76ee\u6807\u4ee5\u589e\u5f3a\u72b6\u6001\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u8bad\u7ec3\u635f\u5931\u5927\u65f6\u72b6\u6001\u591a\u6837\u6027\u66f4\u91cd\u8981\uff0c\u635f\u5931\u5c0f\u65f6\u72b6\u6001\u8d28\u91cf\u66f4\u91cd\u8981\uff1b2\uff09\u5468\u56f4\u8bef\u5dee\u5728\u5173\u952e\u8bef\u5dee\u5927\u65f6\u5bf9\u7b56\u7565\u6027\u80fd\u5f71\u54cd\u66f4\u5927\uff1b3\uff09SDW\u7b97\u6cd5\u5728\u539f\u59cb\u6570\u636e\u96c6\u72b6\u6001\u591a\u6837\u6027\u6709\u9650\u65f6\u663e\u8457\u63d0\u5347OBD\u6027\u80fd\u3002", "conclusion": "\u72b6\u6001\u591a\u6837\u6027\u5728\u79bb\u7ebf\u884c\u4e3a\u84b8\u998f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u635f\u5931\u8f83\u5927\u65f6\u3002\u63d0\u51fa\u7684SDW\u7b97\u6cd5\u901a\u8fc7\u5f3a\u8c03\u72b6\u6001\u591a\u6837\u6027\u6709\u6548\u89e3\u51b3\u4e86\u539f\u59cb\u4e0e\u5408\u6210\u6570\u636e\u96c6\u7684\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u72b6\u6001\u591a\u6837\u6027\u6709\u9650\u7684\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2512.07325", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07325", "abs": "https://arxiv.org/abs/2512.07325", "authors": ["J. Ramya Parkavi", "R. Muthuganesan", "V. K. Chandrasekar"], "title": "Tunable Dynamics of a Dipolar Quantum Battery: Role of Spin-Spin Interactions and Coherence", "comment": "20 pages, 8 Figures", "summary": "This study explores the energy storage dynamics of a quantum battery (QB) modeled using a dipolar spin system with Dzyaloshinskii-Moriya (DM) interaction. We examine the performance of this system in terms of ergotropy, instantaneous power, capacity, and quantum coherence using a two-qubit model. By solving the system's time evolution under cyclic unitary processes, we analyze how external parameters such as temperature, magnetic field, and DM interaction influence the charging behavior and quantum resources of the battery. The findings demonstrate that quantum coherence and DM interaction significantly enhance the energy storage efficiency and power output of the quantum battery, offering promising strategies for designing high-performance quantum energy storage devices. Furthermore, we investigate the performance of quantum battery under the influence of a common dephasing environment, which limits the long-term work-extraction capability of dipolar quantum batteries.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u5177\u6709Dzyaloshinskii-Moriya\u76f8\u4e92\u4f5c\u7528\u7684\u5076\u6781\u81ea\u65cb\u7cfb\u7edf\u91cf\u5b50\u7535\u6c60\u7684\u80fd\u91cf\u5b58\u50a8\u52a8\u529b\u5b66\uff0c\u5206\u6790\u5916\u90e8\u53c2\u6570\u5bf9\u5145\u7535\u884c\u4e3a\u548c\u91cf\u5b50\u8d44\u6e90\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5b50\u76f8\u5e72\u6027\u548cDM\u76f8\u4e92\u4f5c\u7528\u80fd\u663e\u8457\u63d0\u5347\u91cf\u5b50\u7535\u6c60\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u7535\u6c60\u7684\u80fd\u91cf\u5b58\u50a8\u6027\u80fd\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u91cf\u5b50\u76f8\u5e72\u6027\u548cDM\u76f8\u4e92\u4f5c\u7528\u6765\u63d0\u5347\u91cf\u5b50\u80fd\u91cf\u5b58\u50a8\u8bbe\u5907\u7684\u6548\u7387\u548c\u529f\u7387\u8f93\u51fa\uff0c\u4e3a\u8bbe\u8ba1\u9ad8\u6027\u80fd\u91cf\u5b50\u80fd\u91cf\u5b58\u50a8\u8bbe\u5907\u63d0\u4f9b\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u5177\u6709Dzyaloshinskii-Moriya\u76f8\u4e92\u4f5c\u7528\u7684\u5076\u6781\u81ea\u65cb\u7cfb\u7edf\u4f5c\u4e3a\u91cf\u5b50\u7535\u6c60\u6a21\u578b\uff0c\u91c7\u7528\u53cc\u91cf\u5b50\u6bd4\u7279\u6a21\u578b\uff0c\u901a\u8fc7\u6c42\u89e3\u7cfb\u7edf\u5728\u5faa\u73af\u5e7a\u6b63\u8fc7\u7a0b\u4e0b\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u5206\u6790\u6e29\u5ea6\u3001\u78c1\u573a\u548cDM\u76f8\u4e92\u4f5c\u7528\u7b49\u5916\u90e8\u53c2\u6570\u7684\u5f71\u54cd\u3002", "result": "\u91cf\u5b50\u76f8\u5e72\u6027\u548cDM\u76f8\u4e92\u4f5c\u7528\u663e\u8457\u589e\u5f3a\u4e86\u91cf\u5b50\u7535\u6c60\u7684\u80fd\u91cf\u5b58\u50a8\u6548\u7387\u548c\u529f\u7387\u8f93\u51fa\uff1b\u5728\u5171\u540c\u9000\u76f8\u5e72\u73af\u5883\u5f71\u54cd\u4e0b\uff0c\u5076\u6781\u91cf\u5b50\u7535\u6c60\u7684\u957f\u671f\u529f\u63d0\u53d6\u80fd\u529b\u53d7\u5230\u9650\u5236\u3002", "conclusion": "\u91cf\u5b50\u76f8\u5e72\u6027\u548cDM\u76f8\u4e92\u4f5c\u7528\u662f\u63d0\u5347\u91cf\u5b50\u7535\u6c60\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u8bbe\u8ba1\u9ad8\u6027\u80fd\u91cf\u5b50\u80fd\u91cf\u5b58\u50a8\u8bbe\u5907\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u7b56\u7565\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u9000\u76f8\u5e72\u73af\u5883\u5bf9\u957f\u671f\u6027\u80fd\u7684\u9650\u5236\u3002"}}
{"id": "2512.06695", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.06695", "abs": "https://arxiv.org/abs/2512.06695", "authors": ["Haipeng Cao", "Kaining Zhang", "Dacheng Tao", "Zhaofeng Su"], "title": "Mitigating Barren plateaus in quantum denoising diffusion probabilistic models", "comment": "22 pages, 9 figures", "summary": "Quantum generative models leverage quantum superposition and entanglement to enhance learning efficiency for both classical and quantum data. The quantum denoising diffusion probabilistic model (QuDDPM), inspired by its classical counterpart, has been proposed as a promising framework for quantum generative learning. QuDDPM is capable of efficiently learning and generating quantum data, and it demonstrates excellent performance in learning correlated quantum noise models, quantum many-body phases, and the topological structure of quantum data. However, we show that barren plateaus emerge in QuDDPMs due to the use of 2-design states as the input for the denoising process, which severely undermines the performance of QuDDPM. Through theoretical analysis and experimental validation, we confirm the presence of barren plateaus in the original QuDDPM. To address this issue, we introduce an improved QuDDPM that utilizes a distribution maintaining a certain distance from the Haar distribution, ensuring better trainability. Experimental results demonstrate that our approach effectively mitigates the barren plateau problem and generates samples with higher quality, paving the way for scalable and efficient quantum generative learning.", "AI": {"tldr": "\u91cf\u5b50\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(QuDDPM)\u5b58\u5728\u8d2b\u7620\u9ad8\u539f\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u901a\u8fc7\u4f7f\u7528\u4e0eHaar\u5206\u5e03\u4fdd\u6301\u8ddd\u79bb\u7684\u8f93\u5165\u5206\u5e03\u6765\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u679c\u548c\u6837\u672c\u8d28\u91cf\u3002", "motivation": "\u91cf\u5b50\u751f\u6210\u6a21\u578b\u5229\u7528\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u63d0\u5347\u5b66\u4e60\u6548\u7387\uff0cQuDDPM\u4f5c\u4e3a\u91cf\u5b50\u751f\u6210\u5b66\u4e60\u6846\u67b6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5176\u5b58\u5728\u8d2b\u7620\u9ad8\u539f\u95ee\u9898\uff0c\u4e25\u91cd\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u8bad\u7ec3\u96be\u9898\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u786e\u8ba4\u539f\u59cbQuDDPM\u5b58\u5728\u8d2b\u7620\u9ad8\u539f\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u7684QuDDPM\uff0c\u4f7f\u7528\u4e0eHaar\u5206\u5e03\u4fdd\u6301\u4e00\u5b9a\u8ddd\u79bb\u7684\u5206\u5e03\u4f5c\u4e3a\u53bb\u566a\u8fc7\u7a0b\u7684\u8f93\u5165\uff0c\u786e\u4fdd\u66f4\u597d\u7684\u53ef\u8bad\u7ec3\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6539\u8fdb\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u8d2b\u7620\u9ad8\u539f\u95ee\u9898\uff0c\u751f\u6210\u7684\u6837\u672c\u8d28\u91cf\u66f4\u9ad8\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u91cf\u5b50\u751f\u6210\u5b66\u4e60\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86QuDDPM\u4e2d\u8d2b\u7620\u9ad8\u539f\u95ee\u9898\u7684\u6839\u6e90\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8c03\u6574\u8f93\u5165\u5206\u5e03\u7279\u6027\u6765\u6539\u5584\u91cf\u5b50\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\uff0c\u63a8\u52a8\u4e86\u91cf\u5b50\u751f\u6210\u5b66\u4e60\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.07356", "categories": ["quant-ph", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2512.07356", "abs": "https://arxiv.org/abs/2512.07356", "authors": ["A. M. Kozodaev", "I. S. Cojocaru", "S. M. Drofa", "P. G. Vilyuzhanina", "A. Chernyavskiy", "V. G. Vins", "A. N. Smolyaninov", "S. Ya. Kilin", "S. V. Bolshedvorskii", "V. V. Soshenko", "A. V. Akimov"], "title": "Dispersive readout with two orthogonal modes of a dielectric cavity", "comment": null, "summary": "Nitrogen-vacancy color centers in diamond have proven themselves as a good, sensitive element for the measurement of magnetic fields. While the mainstream of magnetometers based on NV centers uses so-called optically detected magnetic resonance, there has recently been a suggestion to use dispersive readout of a dielectric cavity to enhance the sensitivity of magnetometers. Here, we demonstrate that the dispersive readout approach can be significantly improved if a two-channel scheme is considered.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u91d1\u521a\u77f3\u6c2e\u7a7a\u4f4d\u8272\u5fc3\u7684\u53cc\u901a\u9053\u8272\u6563\u8bfb\u51fa\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u78c1\u529b\u8ba1\u7075\u654f\u5ea6", "motivation": "\u4f20\u7edfNV\u4e2d\u5fc3\u78c1\u529b\u8ba1\u4e3b\u8981\u91c7\u7528\u5149\u63a2\u6d4b\u78c1\u5171\u632f\u6280\u672f\uff0c\u8fd1\u671f\u6709\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u4ecb\u7535\u8154\u7684\u8272\u6563\u8bfb\u51fa\u65b9\u6cd5\u6765\u589e\u5f3a\u7075\u654f\u5ea6\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4", "method": "\u91c7\u7528\u53cc\u901a\u9053\u8272\u6563\u8bfb\u51fa\u65b9\u6848\uff0c\u76f8\u6bd4\u5355\u901a\u9053\u65b9\u6848\u8fdb\u884c\u6539\u8fdb\uff0c\u5229\u7528\u91d1\u521a\u77f3\u6c2e\u7a7a\u4f4d\u8272\u5fc3\u4f5c\u4e3a\u78c1\u654f\u611f\u5143\u4ef6", "result": "\u53cc\u901a\u9053\u8272\u6563\u8bfb\u51fa\u65b9\u6848\u76f8\u6bd4\u5355\u901a\u9053\u65b9\u6848\u80fd\u663e\u8457\u63d0\u5347\u78c1\u529b\u8ba1\u7684\u7075\u654f\u5ea6", "conclusion": "\u53cc\u901a\u9053\u8272\u6563\u8bfb\u51fa\u65b9\u6848\u662f\u63d0\u5347\u57fa\u4e8eNV\u4e2d\u5fc3\u7684\u78c1\u529b\u8ba1\u7075\u654f\u5ea6\u7684\u6709\u6548\u6539\u8fdb\u65b9\u6cd5"}}
{"id": "2512.06702", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06702", "abs": "https://arxiv.org/abs/2512.06702", "authors": ["Xiangjun Meng", "Zhongjian Wang"], "title": "Pathway to $O(\\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models", "comment": null, "summary": "We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\\sqrt{d})$. We show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.\n  These assumptions are valid in the flow-based generative model associated with the F\u00f6llmer process and $1$-rectified flow under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.", "AI": {"tldr": "\u8bba\u6587\u4e3a\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u5728Wasserstein\u5ea6\u91cf\u4e0b\u4f30\u8ba1\u8bef\u5dee\u7684\u5206\u6790\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u6700\u4f18\u91c7\u6837\u8fed\u4ee3\u590d\u6742\u5ea6\u4e3aO(\u221ad)\uff0c\u8bef\u5dee\u7531\u4e24\u90e8\u5206\u63a7\u5236\uff1a\u4e0e\u7ef4\u5ea6\u65e0\u5173\u7684\u53cd\u5411\u6d41\u63a8\u524d\u6620\u5c04\u7684Lipschitz\u6027\uff0c\u4ee5\u53ca\u7ef4\u5ea6\u76f8\u5173\u7684\u5c40\u90e8\u79bb\u6563\u8bef\u5deeO(\u221ad)\u3002", "motivation": "\u4e3a\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u53ef\u5b9e\u73b0\u7684\u8bef\u5dee\u4f30\u8ba1\u5206\u6790\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u7406\u89e3\u91c7\u6837\u8fed\u4ee3\u590d\u6742\u5ea6\u4e0e\u7ef4\u5ea6\u7684\u5173\u7cfb\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u5728Wasserstein\u5ea6\u91cf\u4e0b\u7684\u8bef\u5dee\uff0c\u5c06\u8bef\u5dee\u5206\u89e3\u4e3a\u4e24\u90e8\u5206\uff1a\u53cd\u5411\u6d41\u63a8\u524d\u6620\u5c04\u7684Lipschitz\u6027\uff08\u4e0e\u7ef4\u5ea6\u65e0\u5173\uff09\u548c\u5c40\u90e8\u79bb\u6563\u8bef\u5dee\uff08\u4e0e\u7ef4\u5ea6\u76f8\u5173O(\u221ad)\uff09\u3002\u8fd9\u4e9b\u5206\u6790\u9002\u7528\u4e8eF\u00f6llmer\u8fc7\u7a0b\u548c1-\u6574\u6d41\u6d41\u76f8\u5173\u7684\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u3002", "result": "\u8bc1\u660e\u4e86\u91c7\u6837\u8fed\u4ee3\u590d\u6742\u5ea6\u968f\u534f\u65b9\u5dee\u7b97\u5b50\u8ff9\u7684\u5e73\u65b9\u6839\u7ebf\u6027\u589e\u957f\uff0c\u8fd9\u4e0e\u524d\u5411\u8fc7\u7a0b\u4e0d\u53d8\u5206\u5e03\u76f8\u5173\u3002\u5728F\u00f6llmer\u8fc7\u7a0b\u548c1-\u6574\u6d41\u6d41\u4e0b\uff0c\u6700\u4f18\u91c7\u6837\u8fed\u4ee3\u590d\u6742\u5ea6\u4e3aO(\u221ad)\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u8bef\u5dee\u5206\u6790\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u91c7\u6837\u590d\u6742\u5ea6\u4e0e\u7ef4\u5ea6\u7684\u5e73\u65b9\u6839\u5173\u7cfb\uff0c\u4e3a\u9ad8\u7ef4\u751f\u6210\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2512.07378", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.07378", "abs": "https://arxiv.org/abs/2512.07378", "authors": ["Felix Hartmann", "Vivek Unikandanunni", "Matias Bargheer", "Eric E. Fullerton", "Stefano Bonetti", "Janet Anders"], "title": "Intrinsic non-Markovian magnetisation dynamics", "comment": "13 pages, 12 figures, comments are welcome", "summary": "Memory effects arise in many complex systems, from protein folding, to the spreading of epidemics and financial decisions. While so-called non-Markovian dynamics is common in larger systems with interacting components, observations in fundamental physical systems have been confined to specifically engineered cases. Here, we report the experimental observation of non-Markovian dynamics in an elemental material, crystalline cobalt. By driving this material with an intense terahertz electromagnetic field, we bring its magnetisation into a non-equilibrium state and follow its evolution. We measure the sample's low temperature magnetic response in the time domain which leads to an unexpectedly rich multi-peaked spectrum in the Fourier domain, that cannot be explained by established models. We use open quantum system theory, which predicts a non-Markovian memory kernel in the dynamical equations to capture the fundamental interaction between the spin system and the phonon bath. Simulations based on this theory produce a multi-peaked spectrum, which matches the measured one. Our non-Markovian approach is also able to reproduce the modification of the spectrum at higher temperatures. Our findings demonstrate that non-Markovian effects are observable at a much more fundamental level than previously thought, opening the door to their exploration and control in a broad range of condensed matter systems.", "AI": {"tldr": "\u5728\u94b4\u6676\u4f53\u4e2d\u9996\u6b21\u89c2\u6d4b\u5230\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u592a\u8d6b\u5179\u7535\u78c1\u573a\u9a71\u52a8\u78c1\u5316\u5e76\u6d4b\u91cf\u54cd\u5e94\uff0c\u53d1\u73b0\u591a\u5cf0\u8c31\u7ed3\u6784\uff0c\u7528\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7406\u8bba\u6210\u529f\u89e3\u91ca", "motivation": "\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5728\u57fa\u7840\u7269\u7406\u7cfb\u7edf\u4e2d\u4ec5\u9650\u4e8e\u7279\u5b9a\u8bbe\u8ba1\u6848\u4f8b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5143\u7d20\u6750\u6599\u4e2d\u662f\u5426\u5b58\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u6548\u5e94", "method": "\u4f7f\u7528\u5f3a\u592a\u8d6b\u5179\u7535\u78c1\u573a\u9a71\u52a8\u94b4\u6676\u4f53\u78c1\u5316\u8fdb\u5165\u975e\u5e73\u8861\u6001\uff0c\u6d4b\u91cf\u4f4e\u6e29\u78c1\u54cd\u5e94\u65f6\u57df\u4fe1\u53f7\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u5f97\u5230\u9891\u8c31\uff0c\u91c7\u7528\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7406\u8bba\u5efa\u7acb\u975e\u9a6c\u5c14\u53ef\u592b\u8bb0\u5fc6\u6838\u6a21\u578b", "result": "\u89c2\u6d4b\u5230\u610f\u5916\u7684\u591a\u5cf0\u9891\u8c31\u7ed3\u6784\uff0c\u4f20\u7edf\u6a21\u578b\u65e0\u6cd5\u89e3\u91ca\uff1b\u57fa\u4e8e\u975e\u9a6c\u5c14\u53ef\u592b\u8bb0\u5fc6\u6838\u7684\u6a21\u62df\u6210\u529f\u590d\u73b0\u6d4b\u91cf\u8c31\uff0c\u5e76\u80fd\u89e3\u91ca\u9ad8\u6e29\u4e0b\u8c31\u7684\u53d8\u5316", "conclusion": "\u975e\u9a6c\u5c14\u53ef\u592b\u6548\u5e94\u5728\u6bd4\u9884\u671f\u66f4\u57fa\u7840\u7684\u5c42\u9762\u53ef\u89c2\u6d4b\uff0c\u4e3a\u5728\u51dd\u805a\u6001\u7cfb\u7edf\u4e2d\u63a2\u7d22\u548c\u63a7\u5236\u8fd9\u7c7b\u6548\u5e94\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84"}}
{"id": "2512.06708", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06708", "abs": "https://arxiv.org/abs/2512.06708", "authors": ["Waleed Razzaq", "Yun-Bo Zhao"], "title": "A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations", "comment": null, "summary": "Estimating the Remaining Useful Life (RUL) of mechanical systems is pivotal in Prognostics and Health Management (PHM). Rolling-element bearings are among the most frequent causes of machinery failure, highlighting the need for robust RUL estimation methods. Existing approaches often suffer from poor generalization, lack of robustness, high data demands, and limited interpretability. This paper proposes a novel multimodal-RUL framework that jointly leverages image representations (ImR) and time-frequency representations (TFR) of multichannel, nonstationary vibration signals. The architecture comprises three branches: (1) an ImR branch and (2) a TFR branch, both employing multiple dilated convolutional blocks with residual connections to extract spatial degradation features; and (3) a fusion branch that concatenates these features and feeds them into an LSTM to model temporal degradation patterns. A multi-head attention mechanism subsequently emphasizes salient features, followed by linear layers for final RUL regression. To enable effective multimodal learning, vibration signals are converted into ImR via the Bresenham line algorithm and into TFR using Continuous Wavelet Transform. We also introduce multimodal Layer-wise Relevance Propagation (multimodal-LRP), a tailored explainability technique that significantly enhances model transparency. The approach is validated on the XJTU-SY and PRONOSTIA benchmark datasets. Results show that our method matches or surpasses state-of-the-art baselines under both seen and unseen operating conditions, while requiring ~28 % less training data on XJTU-SY and ~48 % less on PRONOSTIA. The model exhibits strong noise resilience, and multimodal-LRP visualizations confirm the interpretability and trustworthiness of predictions, making the framework highly suitable for real-world industrial deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u878d\u5408\u7684\u8f74\u627f\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u50cf\u8868\u793a\u548c\u65f6\u95f4\u9891\u7387\u8868\u793a\uff0c\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6eda\u52a8\u8f74\u627f\u662f\u673a\u68b0\u6545\u969c\u7684\u5e38\u89c1\u539f\u56e0\uff0c\u73b0\u6709RUL\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u6027\u5dee\u3001\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u6570\u636e\u9700\u6c42\u9ad8\u3001\u53ef\u89e3\u91ca\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001RUL\u6846\u67b6\uff1a1) \u56fe\u50cf\u8868\u793a\u5206\u652f(ImR)\u4f7f\u7528Bresenham\u7ebf\u7b97\u6cd5\u8f6c\u6362\u632f\u52a8\u4fe1\u53f7\uff1b2) \u65f6\u95f4\u9891\u7387\u8868\u793a\u5206\u652f(TFR)\u4f7f\u7528\u8fde\u7eed\u5c0f\u6ce2\u53d8\u6362\uff1b3) \u878d\u5408\u5206\u652f\u901a\u8fc7\u6b8b\u5dee\u8fde\u63a5\u7684\u591a\u5c42\u6269\u5f20\u5377\u79ef\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff0cLSTM\u5efa\u6a21\u65f6\u95f4\u6a21\u5f0f\uff0c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7a81\u51fa\u91cd\u8981\u7279\u5f81\uff0c\u6700\u540e\u7ebf\u6027\u5c42\u56de\u5f52RUL\u3002\u8fd8\u63d0\u51fa\u591a\u6a21\u6001\u5c42\u76f8\u5173\u4f20\u64ad(multimodal-LRP)\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728XJTU-SY\u548cPRONOSTIA\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff0c\u5728\u672a\u89c1\u5de5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\u3002XJTU-SY\u4e0a\u51cf\u5c11\u7ea628%\u8bad\u7ec3\u6570\u636e\uff0cPRONOSTIA\u4e0a\u51cf\u5c11\u7ea648%\u3002\u6a21\u578b\u5177\u6709\u5f3a\u566a\u58f0\u9c81\u68d2\u6027\uff0cmultimodal-LRP\u53ef\u89c6\u5316\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u8be5\u591a\u6a21\u6001RUL\u6846\u67b6\u5728\u6027\u80fd\u3001\u6570\u636e\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u6709\u4f18\u52bf\uff0c\u975e\u5e38\u9002\u5408\u5b9e\u9645\u5de5\u4e1a\u90e8\u7f72\u3002"}}
{"id": "2512.07455", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07455", "abs": "https://arxiv.org/abs/2512.07455", "authors": ["Ge Sun", "Hongzheng Wu", "Jing Lu", "Lan Zhou"], "title": "Resonator-assisted single-photon frequency convertion in a conventional waveguide with a giant V-type atom", "comment": "10 pages, 7 figures", "summary": "We propose a scheme to achieve efficient frequency conversion for a single photon propagating in a 1D conventional waveguide by exploiting the quantum interference induced by the scale of a V-type giant atom (GA) characterized by the distance between the two coupling points as well as single-photon transition pathways originated from the coupling between the GA and the resonator. The presence of photons in the resonator triggers the frequency conversion of photons. The scattering spectra and the conversion contrast are studied in both the Markovian and the non-Markovian regimes. The disappearance of frequency conversion is rooted in the complete suppression of the emission from the excited state to either of lower states in the $n+1$ subspace where $n$ is the photon number of the resonator, and the non-Markovicity-induced nonreciprocity is found under specific conditions. Altering the photon number $n$ induces the non-reciprocal transmission of single photons in the waveguide, hence, enhance the conversion probability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528V\u578b\u5de8\u539f\u5b50\u91cf\u5b50\u5e72\u6d89\u5b9e\u73b0\u5355\u5149\u5b50\u9891\u7387\u8f6c\u6362\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u8c10\u632f\u5668\u4e2d\u7684\u5149\u5b50\u6570\u8c03\u63a7\u8f6c\u6362\u6548\u7387\u548c\u5355\u5411\u4f20\u8f93\u7279\u6027", "motivation": "\u4f20\u7edf\u6ce2\u5bfc\u4e2d\u5355\u5149\u5b50\u9891\u7387\u8f6c\u6362\u6548\u7387\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u91cf\u5b50\u5e72\u6d89\u6548\u5e94\u7684\u65b0\u65b9\u6848\u6765\u63d0\u5347\u8f6c\u6362\u6548\u7387\u548c\u53ef\u63a7\u6027", "method": "\u5229\u7528V\u578b\u5de8\u539f\u5b50\u4e0e\u8c10\u632f\u5668\u8026\u5408\u4ea7\u751f\u7684\u91cf\u5b50\u5e72\u6d89\u6548\u5e94\uff0c\u901a\u8fc7\u8c03\u8282\u4e24\u4e2a\u8026\u5408\u70b9\u8ddd\u79bb\u548c\u5355\u5149\u5b50\u8dc3\u8fc1\u8def\u5f84\uff0c\u5b9e\u73b0\u9891\u7387\u8f6c\u6362", "result": "\u5728\u9a6c\u5c14\u53ef\u592b\u548c\u975e\u9a6c\u5c14\u53ef\u592b\u533a\u57df\u7814\u7a76\u4e86\u6563\u5c04\u8c31\u548c\u8f6c\u6362\u5bf9\u6bd4\u5ea6\uff0c\u53d1\u73b0\u5149\u5b50\u6570n\u80fd\u8bf1\u5bfc\u975e\u4e92\u6613\u4f20\u8f93\uff0c\u589e\u5f3a\u8f6c\u6362\u6982\u7387", "conclusion": "\u8be5\u65b9\u6848\u901a\u8fc7\u91cf\u5b50\u5e72\u6d89\u548c\u5149\u5b50\u6570\u8c03\u63a7\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5355\u5149\u5b50\u9891\u7387\u8f6c\u6362\uff0c\u4e3a\u975e\u4e92\u6613\u91cf\u5b50\u5668\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2512.06714", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.06714", "abs": "https://arxiv.org/abs/2512.06714", "authors": ["Tony Salloom", "Okyay Kaynak", "Wei He"], "title": "A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting", "comment": null, "summary": "Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6570\u636e\u6269\u5c55\u548c\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u77ed\u671f\u7528\u6c34\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d2\u5165\u865a\u62df\u6570\u636e\u7f13\u89e3\u6781\u7aef\u70b9\u8bef\u5dee\uff0c\u4f7f\u7528GRU\u548cK-means\u7279\u5f81\u5de5\u7a0b\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u77ed\u671f\u7528\u6c34\u9700\u6c42\u9884\u6d4b\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u6a21\u578b\u53c2\u6570\u8fc7\u591a\u5bfc\u81f4\u590d\u6742\u5ea6\u9ad8\uff1b2) \u5728\u6781\u7aef\u70b9\uff08\u5cf0\u503c/\u8c37\u503c\uff09\u9884\u6d4b\u8bef\u5dee\u8f83\u5927\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u964d\u4f4e\u590d\u6742\u5ea6\u53c8\u80fd\u63d0\u9ad8\u6781\u7aef\u70b9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u4e24\u79cd\u521b\u65b0\u65b9\u6cd5\uff1a1) \u6570\u636e\u6269\u5c55\u6280\u672f\uff1a\u5728\u5b9e\u9645\u6570\u636e\u4e2d\u63d2\u5165\u865a\u62df\u6570\u636e\u4ee5\u7f13\u89e3\u6781\u7aef\u70b9\u5468\u56f4\u7684\u975e\u7ebf\u6027\u95ee\u9898\uff1b2) \u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1a\u4f7f\u7528GRU\u5904\u7406\u65f6\u5e8f\u5173\u7cfb\uff0c\u7ed3\u5408K-means\u65e0\u76d1\u7763\u5206\u7c7b\u521b\u5efa\u65b0\u7279\u5f81\uff0c\u51cf\u5c11\u53c2\u6570\u6570\u91cf", "result": "1) \u6a21\u578b\u590d\u6742\u5ea6\u964d\u4f4e\u81f3\u6587\u732e\u4e2d\u65b9\u6cd5\u7684\u516d\u5206\u4e4b\u4e00\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7cbe\u5ea6\uff1b2) \u6570\u636e\u6269\u5c55\u4f7f\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u7ea630%\uff1b3) \u4f7f\u7528\u4e2d\u56fd\u4e24\u4e2a\u4e0d\u540c\u6c34\u5382\u7684\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u77ed\u671f\u7528\u6c34\u9700\u6c42\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u5ea6\u548c\u6781\u7aef\u70b9\u8bef\u5dee\u95ee\u9898\uff0c\u867d\u7136\u6570\u636e\u6269\u5c55\u589e\u52a0\u4e86\u8bad\u7ec3\u65f6\u95f4\uff0c\u4f46\u5728\u964d\u4f4e\u8bef\u5dee\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u4e3a\u6c34\u4f9b\u5e94\u7cfb\u7edf\u4f18\u5316\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.07468", "categories": ["quant-ph", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.07468", "abs": "https://arxiv.org/abs/2512.07468", "authors": ["Antoine Soulas", "Guilherme Franzmann", "Andrea Di Biagio"], "title": "On the emergence of preferred structures in quantum theory", "comment": null, "summary": "We assess the possibilities offered by Hilbert space fundamentalism, an attitude towards quantum physics according to which all physical structures (e.g. subsystems, locality, spacetime, preferred observables) should emerge from minimal quantum ingredients (typically a Hilbert space, Hamiltonian, and state). As a case study, we first mainly focus on the specific question of whether the Hamiltonian can uniquely determine a tensor product structure, a crucial challenge in the growing field of quantum mereology. The present paper reviews, clarifies, and critically examines two apparently conflicting theorems by Cotler et al. and Stoica. We resolve the tension, show how the former has been widely misinterpreted and why the latter is correct only in some weaker version. We then propose a correct mathematical way to address the general problem of preferred structures in quantum theory, relative to the characterization of emergent objects by unitary-invariant properties. Finally, we apply this formalism in the particular case we started with, and show that a Hamiltonian and a state are enough structure to uniquely select a preferred tensor product structure.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u57fa\u672c\u4e3b\u4e49\uff0c\u7814\u7a76\u54c8\u5bc6\u987f\u91cf\u662f\u5426\u80fd\u552f\u4e00\u786e\u5b9a\u5f20\u91cf\u79ef\u7ed3\u6784\uff0c\u8c03\u548c\u4e86\u4e24\u4e2a\u770b\u4f3c\u51b2\u7a81\u7684\u5b9a\u7406\uff0c\u5e76\u63d0\u51fa\u7528\u54c8\u5bc6\u987f\u91cf\u548c\u6001\u6765\u552f\u4e00\u9009\u62e9\u5f20\u91cf\u79ef\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u57fa\u672c\u4e3b\u4e49\u7684\u53ef\u80fd\u6027\uff0c\u5373\u6240\u6709\u7269\u7406\u7ed3\u6784\uff08\u5b50\u7cfb\u7edf\u3001\u5c40\u57df\u6027\u3001\u65f6\u7a7a\u3001\u9996\u9009\u53ef\u89c2\u6d4b\u91cf\uff09\u90fd\u5e94\u4ece\u6700\u5c0f\u91cf\u5b50\u6210\u5206\uff08\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u3001\u54c8\u5bc6\u987f\u91cf\u3001\u6001\uff09\u4e2d\u6d8c\u73b0\u3002\u7279\u522b\u5173\u6ce8\u54c8\u5bc6\u987f\u91cf\u662f\u5426\u80fd\u552f\u4e00\u786e\u5b9a\u5f20\u91cf\u79ef\u7ed3\u6784\u8fd9\u4e00\u91cf\u5b50\u90e8\u5206\u5b66\u5173\u952e\u95ee\u9898\u3002", "method": "1. \u56de\u987e\u3001\u6f84\u6e05\u5e76\u6279\u5224\u6027\u68c0\u9a8cCotler\u7b49\u4eba\u548cStoica\u7684\u4e24\u4e2a\u770b\u4f3c\u51b2\u7a81\u7684\u5b9a\u7406\uff1b2. \u8c03\u548c\u4e24\u8005\u7684\u7d27\u5f20\u5173\u7cfb\uff0c\u6307\u51fa\u524d\u8005\u7684\u5e7f\u6cdb\u8bef\u89e3\u548c\u540e\u8005\u7684\u5c40\u9650\u6027\uff1b3. \u63d0\u51fa\u89e3\u51b3\u91cf\u5b50\u7406\u8bba\u4e2d\u9996\u9009\u7ed3\u6784\u95ee\u9898\u7684\u6b63\u786e\u6570\u5b66\u65b9\u6cd5\uff0c\u57fa\u4e8e\u9149\u4e0d\u53d8\u6027\u8d28\u6765\u8868\u5f81\u6d8c\u73b0\u5bf9\u8c61\uff1b4. \u5c06\u8be5\u5f62\u5f0f\u5e94\u7528\u4e8e\u5f20\u91cf\u79ef\u7ed3\u6784\u95ee\u9898\u3002", "result": "1. \u89e3\u51b3\u4e86\u4e24\u4e2a\u5b9a\u7406\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\uff0c\u8868\u660eCotler\u7b49\u4eba\u7684\u5b9a\u7406\u88ab\u5e7f\u6cdb\u8bef\u89e3\uff0c\u800cStoica\u7684\u5b9a\u7406\u53ea\u5728\u8f83\u5f31\u7248\u672c\u4e2d\u6b63\u786e\uff1b2. \u5efa\u7acb\u4e86\u5904\u7406\u91cf\u5b50\u7406\u8bba\u4e2d\u9996\u9009\u7ed3\u6784\u95ee\u9898\u7684\u6b63\u786e\u6570\u5b66\u6846\u67b6\uff1b3. \u8bc1\u660e\u54c8\u5bc6\u987f\u91cf\u548c\u6001\u8db3\u4ee5\u552f\u4e00\u9009\u62e9\u9996\u9009\u5f20\u91cf\u79ef\u7ed3\u6784\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u8c03\u548c\u4e86\u5173\u4e8e\u54c8\u5bc6\u987f\u91cf\u786e\u5b9a\u5f20\u91cf\u79ef\u7ed3\u6784\u7684\u4e24\u4e2a\u51b2\u7a81\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u9149\u4e0d\u53d8\u6027\u8d28\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u54c8\u5bc6\u987f\u91cf\u548c\u6001\u7684\u7ec4\u5408\u80fd\u591f\u552f\u4e00\u786e\u5b9a\u5f20\u91cf\u79ef\u7ed3\u6784\uff0c\u4e3a\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u57fa\u672c\u4e3b\u4e49\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2512.06725", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.06725", "abs": "https://arxiv.org/abs/2512.06725", "authors": ["Tian Lan"], "title": "Decoding Motor Behavior Using Deep Learning and Reservoir Computing", "comment": "10 pages, 3 figures", "summary": "We present a novel approach to EEG decoding for non-invasive brain machine interfaces (BMIs), with a focus on motor-behavior classification. While conventional convolutional architectures such as EEGNet and DeepConvNet are effective in capturing local spatial patterns, they are markedly less suited for modeling long-range temporal dependencies and nonlinear dynamics. To address this limitation, we integrate an Echo State Network (ESN), a prominent paradigm in reservoir computing into the decoding pipeline. ESNs construct a high-dimensional, sparsely connected recurrent reservoir that excels at tracking temporal dynamics, thereby complementing the spatial representational power of CNNs. Evaluated on a skateboard-trick EEG dataset preprocessed via the PREP pipeline and implemented in MNE-Python, our ESNNet achieves 83.2% within-subject and 51.3% LOSO accuracies, surpassing widely used CNN-based baselines. Code is available at https://github.com/Yutiankunkun/Motion-Decoding-Using-Biosignals", "AI": {"tldr": "\u63d0\u51faESNNet\uff0c\u7ed3\u5408CNN\u4e0e\u56de\u58f0\u72b6\u6001\u7f51\u7edc(ESN)\u6765\u6539\u8fdbEEG\u89e3\u7801\uff0c\u7279\u522b\u9488\u5bf9\u8fd0\u52a8\u884c\u4e3a\u5206\u7c7b\uff0c\u80fd\u66f4\u597d\u5730\u5efa\u6a21\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u975e\u7ebf\u6027\u52a8\u6001\u3002", "motivation": "\u4f20\u7edf\u5377\u79ef\u67b6\u6784\u5982EEGNet\u548cDeepConvNet\u80fd\u6709\u6548\u6355\u6349\u5c40\u90e8\u7a7a\u95f4\u6a21\u5f0f\uff0c\u4f46\u4e0d\u9002\u5408\u5efa\u6a21\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u9650\u5236\u4e86EEG\u89e3\u7801\u6027\u80fd\u3002", "method": "\u5c06\u56de\u58f0\u72b6\u6001\u7f51\u7edc(ESN)\u6574\u5408\u5230\u89e3\u7801\u6d41\u7a0b\u4e2d\uff0cESN\u6784\u5efa\u9ad8\u7ef4\u7a00\u758f\u8fde\u63a5\u7684\u5faa\u73af\u50a8\u5907\u6c60\uff0c\u64c5\u957f\u8ffd\u8e2a\u65f6\u95f4\u52a8\u6001\uff0c\u4e0eCNN\u7684\u7a7a\u95f4\u8868\u5f81\u80fd\u529b\u4e92\u8865\u3002", "result": "\u5728\u6ed1\u677f\u6280\u5de7EEG\u6570\u636e\u96c6\u4e0a\uff0cESNNet\u8fbe\u523083.2%\u7684\u53d7\u8bd5\u8005\u5185\u51c6\u786e\u7387\u548c51.3%\u7684\u7559\u4e00\u53d7\u8bd5\u8005\u5916\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u57fa\u4e8eCNN\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ESNNet\u901a\u8fc7\u7ed3\u5408CNN\u7684\u7a7a\u95f4\u8868\u5f81\u80fd\u529b\u548cESN\u7684\u65f6\u95f4\u52a8\u6001\u5efa\u6a21\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86EEG\u89e3\u7801\u6027\u80fd\uff0c\u4e3a\u8111\u673a\u63a5\u53e3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07475", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07475", "abs": "https://arxiv.org/abs/2512.07475", "authors": ["Rei Kawano", "Shin Nishio", "Hideaki Kawaguchi", "Shota Nagayama", "Takahiko Satoh"], "title": "RuleSet Generation Framework for Application Layer Integration in Quantum Internet", "comment": "11 pages, 16 figures", "summary": "Layered architectures for the Quantum Internet have been proposed, inspired by that of the classical Internet, which has demonstrated high maintainability even in large-scale systems. While lower layers in the Quantum Internet, such as entanglement generation and distribution, have been extensively studied, the application layer - responsible for translating user requests into executable quantum-network operations - remains largely unexplored. A significant challenge is translating application-level requests into the concrete instructions executable at lower layers. In this work, we introduce a RuleSet-based framework that explicitly incorporates the application layer into the layered architecture of the Quantum Internet. Our framework builds on a RuleSet-based protocol, clarifying communication procedures, organizing application request information, and introducing new Rules for application execution by embedding application specifications into RuleSets. To evaluate feasibility, we constructed state machines from the generated RuleSets. This approach enables a transparent integration from the application layer down to the physical layer, thereby lowering barriers to deploying new applications on the Quantum Internet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eRuleSet\u7684\u91cf\u5b50\u4e92\u8054\u7f51\u5e94\u7528\u5c42\u6846\u67b6\uff0c\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u91cf\u5b50\u7f51\u7edc\u64cd\u4f5c\uff0c\u5b9e\u73b0\u4ece\u5e94\u7528\u5c42\u5230\u7269\u7406\u5c42\u7684\u900f\u660e\u96c6\u6210", "motivation": "\u91cf\u5b50\u4e92\u8054\u7f51\u7684\u5e95\u5c42\u6280\u672f\uff08\u5982\u7ea0\u7f20\u751f\u6210\u548c\u5206\u53d1\uff09\u5df2\u5f97\u5230\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5e94\u7528\u5c42\uff08\u8d1f\u8d23\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u91cf\u5b50\u7f51\u7edc\u64cd\u4f5c\uff09\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u5982\u4f55\u5c06\u5e94\u7528\u7ea7\u8bf7\u6c42\u8f6c\u6362\u4e3a\u5e95\u5c42\u53ef\u6267\u884c\u7684\u5177\u4f53\u6307\u4ee4", "method": "\u5f15\u5165\u57fa\u4e8eRuleSet\u7684\u6846\u67b6\uff0c\u5c06\u5e94\u7528\u5c42\u660e\u786e\u7eb3\u5165\u91cf\u5b50\u4e92\u8054\u7f51\u7684\u5206\u5c42\u67b6\u6784\u3002\u8be5\u6846\u67b6\u5efa\u7acb\u5728RuleSet\u534f\u8bae\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u5c06\u5e94\u7528\u89c4\u8303\u5d4c\u5165RuleSets\u6765\u6f84\u6e05\u901a\u4fe1\u6d41\u7a0b\u3001\u7ec4\u7ec7\u5e94\u7528\u8bf7\u6c42\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u5e94\u7528\u6267\u884c\u89c4\u5219\u3002\u901a\u8fc7\u4ece\u751f\u6210\u7684RuleSets\u6784\u5efa\u72b6\u6001\u673a\u6765\u8bc4\u4f30\u53ef\u884c\u6027", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u4ece\u5e94\u7528\u5c42\u5230\u7269\u7406\u5c42\u7684\u900f\u660e\u96c6\u6210\uff0c\u964d\u4f4e\u4e86\u5728\u91cf\u5b50\u4e92\u8054\u7f51\u4e0a\u90e8\u7f72\u65b0\u5e94\u7528\u7684\u95e8\u69db", "conclusion": "\u57fa\u4e8eRuleSet\u7684\u6846\u67b6\u6210\u529f\u5c06\u5e94\u7528\u5c42\u6574\u5408\u5230\u91cf\u5b50\u4e92\u8054\u7f51\u7684\u5206\u5c42\u67b6\u6784\u4e2d\uff0c\u901a\u8fc7\u660e\u786e\u901a\u4fe1\u6d41\u7a0b\u548c\u5d4c\u5165\u5e94\u7528\u89c4\u8303\uff0c\u4e3a\u91cf\u5b50\u4e92\u8054\u7f51\u7684\u5e94\u7528\u5f00\u53d1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5"}}
{"id": "2512.06727", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06727", "abs": "https://arxiv.org/abs/2512.06727", "authors": ["Sourjya Roy", "Shrihari Sridharan", "Surya Selvam", "Anand Raghunathan"], "title": "KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model itself and limiting achievable batch sizes and context windows. To address this challenge, we present KV CAR, a unified and architecture agnostic framework that significantly reduces KV cache storage while maintaining model fidelity. KV CAR combines two complementary techniques. First, a lightweight autoencoder learns compact representations of key and value tensors along the embedding dimension, compressing them before they are stored in the KV cache and restoring them upon retrieval. Second, a similarity driven reuse mechanism identifies opportunities to reuse KV tensors of specific attention heads across adjacent layers. Together, these methods reduce the dimensional and structural redundancy in KV tensors without requiring changes to the transformer architecture. Evaluations on GPT 2 and TinyLLaMA models across Wikitext, C4, PIQA, and Winogrande datasets demonstrate that KV CAR achieves up to 47.85 percent KV cache memory reduction with minimal impact on perplexity and zero shot accuracy. System level measurements on an NVIDIA A40 GPU show that the reduced KV footprint directly translates into longer sequence lengths and larger batch sizes during inference. These results highlight the effectiveness of KV CAR in enabling memory efficient LLM inference.", "AI": {"tldr": "KV CAR\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684\u67b6\u6784\u65e0\u5173\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u7f16\u7801\u5668\u548c\u76f8\u4f3c\u6027\u9a71\u52a8\u91cd\u7528\u673a\u5236\uff0c\u663e\u8457\u51cf\u5c11KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\uff0c\u5b9e\u73b0\u9ad8\u8fbe47.85%\u7684\u538b\u7f29\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u589e\u52a0\uff0cKV\u7f13\u5b58\u5728\u81ea\u56de\u5f52\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u5185\u5b58\u9700\u6c42\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002KV\u7f13\u5b58\u968f\u5e8f\u5217\u957f\u5ea6\u548c\u5d4c\u5165\u7ef4\u5ea6\u589e\u957f\uff0c\u5e38\u5e38\u8d85\u8fc7\u6a21\u578b\u672c\u8eab\u7684\u5185\u5b58\u5360\u7528\uff0c\u9650\u5236\u4e86\u53ef\u5b9e\u73b0\u7684\u6279\u5904\u7406\u5927\u5c0f\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002", "method": "KV CAR\u7ed3\u5408\u4e24\u79cd\u4e92\u8865\u6280\u672f\uff1a1\uff09\u8f7b\u91cf\u7ea7\u81ea\u7f16\u7801\u5668\u6cbf\u5d4c\u5165\u7ef4\u5ea6\u5b66\u4e60\u952e\u503c\u5f20\u91cf\u7684\u7d27\u51d1\u8868\u793a\uff0c\u5728\u5b58\u50a8\u5230KV\u7f13\u5b58\u524d\u538b\u7f29\u5e76\u5728\u68c0\u7d22\u65f6\u6062\u590d\uff1b2\uff09\u76f8\u4f3c\u6027\u9a71\u52a8\u91cd\u7528\u673a\u5236\u8bc6\u522b\u8de8\u76f8\u90bb\u5c42\u91cd\u7528\u7279\u5b9a\u6ce8\u610f\u529b\u5934KV\u5f20\u91cf\u7684\u673a\u4f1a\u3002\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u9700\u6539\u53d8Transformer\u67b6\u6784\u5373\u53ef\u51cf\u5c11KV\u5f20\u91cf\u7684\u7ef4\u5ea6\u548c\u7ed3\u6784\u5197\u4f59\u3002", "result": "\u5728GPT-2\u548cTinyLLaMA\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cKV CAR\u5728Wikitext\u3001C4\u3001PIQA\u548cWinogrande\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u8fbe47.85%\u7684KV\u7f13\u5b58\u5185\u5b58\u51cf\u5c11\uff0c\u5bf9\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u7387\u5f71\u54cd\u6781\u5c0f\u3002\u5728NVIDIA A40 GPU\u4e0a\u7684\u7cfb\u7edf\u7ea7\u6d4b\u91cf\u8868\u660e\uff0c\u51cf\u5c11\u7684KV\u5360\u7528\u76f4\u63a5\u8f6c\u5316\u4e3a\u63a8\u7406\u65f6\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\u548c\u66f4\u5927\u7684\u6279\u5904\u7406\u5927\u5c0f\u3002", "conclusion": "KV CAR\u901a\u8fc7\u6709\u6548\u51cf\u5c11KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u4e3a\u89e3\u51b3KV\u7f13\u5b58\u74f6\u9888\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07496", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07496", "abs": "https://arxiv.org/abs/2512.07496", "authors": ["Shuo Dai", "Ran Qi"], "title": "Mediated Transmission of Quantum Synchronization in Star Networks", "comment": null, "summary": "Synchronization transmission describes the emergence of coherence between two uncoupled oscillators mediated by their mutual coupling to an intermediate one. In classical star networks, such mediated coupling gives rise to remote synchronization--where nonadjacent leaf nodes synchronize through a nonsynchronous hub--and to explosive synchronization, characterized by an abrupt collective transition to coherence. In the quantum regime, analogous effects can arise from the interplay between 1:1 phase locking and 2:1 phase-locking blockade in coupled spin-1 oscillators. In this work, we investigate a star network composed of spin-1 oscillators. For identical oscillators, symmetric and asymmetric dissipation lead to distinct transmission behaviors: remote synchronization and quasi-explosive synchronization appear in different coupling regimes, a phenomenon absent in classical counterparts. For nonidentical networks, we find that at large detuning remote synchronization emerges in the weak-coupling regime and evolves into quasi-explosive synchronization as the coupling increases, consistent with classical star-network dynamics. These findings reveal the rich dynamical characteristics of mediated quantum synchronization and point toward new possibilities for exploring synchronization transmission in larger and more complex quantum systems.", "AI": {"tldr": "\u91cf\u5b50\u661f\u5f62\u7f51\u7edc\u4e2d\u901a\u8fc7\u4e2d\u95f4\u8282\u70b9\u5b9e\u73b0\u8fdc\u7a0b\u540c\u6b65\u4e0e\u51c6\u7206\u70b8\u540c\u6b65\uff0c\u63ed\u793a\u4e86\u7ecf\u5178\u7cfb\u7edf\u4e2d\u4e0d\u5b58\u5728\u7684\u91cf\u5b50\u540c\u6b65\u4f20\u8f93\u65b0\u7279\u6027", "motivation": "\u7814\u7a76\u91cf\u5b50\u661f\u5f62\u7f51\u7edc\u4e2d\u901a\u8fc7\u4e2d\u95f4\u8282\u70b9\u4ecb\u5bfc\u7684\u540c\u6b65\u4f20\u8f93\u73b0\u8c61\uff0c\u63a2\u7d22\u91cf\u5b50\u7cfb\u7edf\u4e2d\u8fdc\u7a0b\u540c\u6b65\u548c\u7206\u70b8\u540c\u6b65\u7684\u65b0\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u5728\u7ecf\u5178\u5bf9\u5e94\u7cfb\u7edf\u4e2d\u4e0d\u5b58\u5728", "method": "\u6784\u5efa\u7531spin-1\u632f\u8361\u5668\u7ec4\u6210\u7684\u661f\u5f62\u7f51\u7edc\uff0c\u5206\u6790\u76f8\u540c\u548c\u975e\u76f8\u540c\u632f\u8361\u5668\u5728\u4e0d\u540c\u8026\u5408\u673a\u5236\u4e0b\u7684\u884c\u4e3a\uff0c\u7814\u7a76\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u8017\u6563\u5bf9\u540c\u6b65\u4f20\u8f93\u7684\u5f71\u54cd", "result": "\u76f8\u540c\u632f\u8361\u5668\u4e2d\uff0c\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u8017\u6563\u5bfc\u81f4\u4e0d\u540c\u4f20\u8f93\u884c\u4e3a\uff1a\u8fdc\u7a0b\u540c\u6b65\u548c\u51c6\u7206\u70b8\u540c\u6b65\u51fa\u73b0\u5728\u4e0d\u540c\u8026\u5408\u533a\u57df\uff1b\u975e\u76f8\u540c\u7f51\u7edc\u4e2d\uff0c\u5927\u5931\u8c10\u4e0b\u5f31\u8026\u5408\u51fa\u73b0\u8fdc\u7a0b\u540c\u6b65\uff0c\u5f3a\u8026\u5408\u6f14\u53d8\u4e3a\u51c6\u7206\u70b8\u540c\u6b65", "conclusion": "\u91cf\u5b50\u4ecb\u5bfc\u540c\u6b65\u5c55\u73b0\u51fa\u4e30\u5bcc\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4e3a\u63a2\u7d22\u66f4\u5927\u66f4\u590d\u6742\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u540c\u6b65\u4f20\u8f93\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u6027"}}
{"id": "2512.06730", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.06730", "abs": "https://arxiv.org/abs/2512.06730", "authors": ["Lin Yang", "Xiang Li", "Xin Ma", "Xinxin Zhao"], "title": "Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data", "comment": null, "summary": "Patients with motor dysfunction show low subjective engagement in rehabilitation training. Traditional SSVEP-based brain-computer interface (BCI) systems rely heavily on external visual stimulus equipment, limiting their practicality in real-world settings. This study proposes an augmented reality steady-state visually evoked potential (AR-SSVEP) system to address the lack of patient initiative and the high workload on therapists. Firstly, we design four HoloLens 2-based EEG classes and collect EEG data from seven healthy subjects for analysis. Secondly, we build upon the conventional CNN-BiLSTM architecture by integrating a multi-head attention mechanism (MACNN-BiLSTM). We extract ten temporal-spectral EEG features and feed them into a CNN to learn high-level representations. Then, we use BiLSTM to model sequential dependencies and apply a multi-head attention mechanism to highlight motor-intention-related patterns. Finally, the SHAP (SHapley Additive exPlanations) method is applied to visualize EEG feature contributions to the neural network's decision-making process, enhancing the model's interpretability. These findings enhance real-time motor intention recognition and support recovery in patients with motor impairments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u589e\u5f3a\u73b0\u5b9e\u7684SSVEP-BCI\u7cfb\u7edf\uff0c\u7ed3\u5408\u591a\u6ce8\u610f\u529bCNN-BiLSTM\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u8fd0\u52a8\u529f\u80fd\u969c\u788d\u60a3\u8005\u7684\u5eb7\u590d\u8bad\u7ec3\u53c2\u4e0e\u5ea6\u548c\u8fd0\u52a8\u610f\u56fe\u8bc6\u522b", "motivation": "\u89e3\u51b3\u8fd0\u52a8\u529f\u80fd\u969c\u788d\u60a3\u8005\u5eb7\u590d\u8bad\u7ec3\u4e3b\u89c2\u53c2\u4e0e\u5ea6\u4f4e\u7684\u95ee\u9898\uff0c\u4f20\u7edfSSVEP-BCI\u7cfb\u7edf\u4f9d\u8d56\u5916\u90e8\u89c6\u89c9\u523a\u6fc0\u8bbe\u5907\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d7\u9650\uff0c\u4e14\u6cbb\u7597\u5e08\u5de5\u4f5c\u8d1f\u62c5\u91cd", "method": "1. \u8bbe\u8ba1\u57fa\u4e8eHoloLens 2\u7684\u56db\u79cdEEG\u7c7b\u522b\uff0c\u6536\u96c67\u540d\u5065\u5eb7\u53d7\u8bd5\u8005\u6570\u636e\uff1b2. \u5728\u4f20\u7edfCNN-BiLSTM\u67b6\u6784\u57fa\u7840\u4e0a\u96c6\u6210\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff08MACNN-BiLSTM\uff09\uff1b3. \u63d0\u53d610\u4e2a\u65f6\u9891EEG\u7279\u5f81\uff0c\u901a\u8fc7CNN\u5b66\u4e60\u9ad8\u7ea7\u8868\u5f81\uff1b4. \u4f7f\u7528BiLSTM\u5efa\u6a21\u5e8f\u5217\u4f9d\u8d56\uff0c\u5e94\u7528\u591a\u5934\u6ce8\u610f\u529b\u7a81\u51fa\u8fd0\u52a8\u610f\u56fe\u76f8\u5173\u6a21\u5f0f\uff1b5. \u5e94\u7528SHAP\u65b9\u6cd5\u53ef\u89c6\u5316EEG\u7279\u5f81\u5bf9\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u8d21\u732e", "result": "\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u5b9e\u65f6\u8fd0\u52a8\u610f\u56fe\u8bc6\u522b\u80fd\u529b\uff0c\u652f\u6301\u8fd0\u52a8\u969c\u788d\u60a3\u8005\u7684\u5eb7\u590d\u6062\u590d", "conclusion": "AR-SSVEP\u7cfb\u7edf\u7ed3\u5408MACNN-BiLSTM\u6a21\u578b\u80fd\u6709\u6548\u63d0\u9ad8\u60a3\u8005\u5eb7\u590d\u8bad\u7ec3\u53c2\u4e0e\u5ea6\uff0c\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8fd0\u52a8\u969c\u788d\u5eb7\u590d\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.07561", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07561", "abs": "https://arxiv.org/abs/2512.07561", "authors": ["Emerson Lima Caldas", "Diego Paiva Pires"], "title": "Exponentially accelerated relaxation and quantum Mpemba effect in open quantum systems", "comment": "12 pages, 3 figures. Comments are welcome", "summary": "We investigate the quantum Mpemba effect in the relaxation of open quantum systems whose effective dynamics is described by Davies maps. We present a class of unitary transformations based on permutation matrices that, acting on the initial state of the system, (i) suppress the contribution of slowest decaying modes of the nonunitary dynamics; (ii) ensure that it is as distinguishable as possible from the steady state. The first requirement guarantees an exponentially accelerating convergence to the steady state, while the second implies that a quantum system initially farther from equilibrium approaches it more rapidly than an initial state closer to it. This protocol provides a genuine Mpemba effect, and its numerical simulation requires low computational effort. We prove that, for any initial state, there always exists a permutation matrix that maximizes its distance from the equilibrium for a given information-theoretic distinguishability measure. We illustrate our findings for the nonunitary dynamics of the transverse field Ising chain and XXZ chain, each weakly coupled to a bosonic thermal bath, showing the quantum Mpemba effect captured by the Hilbert-Schmidt distance, quantum relative entropy, and trace distance. Our results provide a universal and versatile framework to engineer the genuine quantum Mpemba effect in open quantum systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f6e\u6362\u77e9\u9635\u7684\u9149\u53d8\u6362\u534f\u8bae\uff0c\u80fd\u591f\u52a0\u901f\u7cfb\u7edf\u5411\u7a33\u6001\u7684\u5f1b\u8c6b\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\u3002", "motivation": "\u7814\u7a76\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\uff0c\u5373\u521d\u59cb\u72b6\u6001\u79bb\u5e73\u8861\u6001\u66f4\u8fdc\u7684\u7cfb\u7edf\u53cd\u800c\u6bd4\u79bb\u5e73\u8861\u6001\u66f4\u8fd1\u7684\u7cfb\u7edf\u66f4\u5feb\u5f1b\u8c6b\u5230\u7a33\u6001\u7684\u73b0\u8c61\u3002\u65e8\u5728\u4e3a\u91cf\u5b50\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u901a\u7528\u7684\u52a0\u901f\u5f1b\u8c6b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7f6e\u6362\u77e9\u9635\u7684\u9149\u53d8\u6362\u534f\u8bae\uff0c\u4f5c\u7528\u4e8e\u7cfb\u7edf\u521d\u59cb\u72b6\u6001\uff1a(1)\u6291\u5236\u975e\u5e7a\u6b63\u52a8\u529b\u5b66\u4e2d\u6700\u6162\u8870\u51cf\u6a21\u5f0f\u7684\u8d21\u732e\uff1b(2)\u786e\u4fdd\u521d\u59cb\u72b6\u6001\u4e0e\u7a33\u6001\u5c3d\u53ef\u80fd\u53ef\u533a\u5206\u3002\u8bc1\u660e\u5bf9\u4e8e\u4efb\u4f55\u521d\u59cb\u72b6\u6001\uff0c\u603b\u5b58\u5728\u7f6e\u6362\u77e9\u9635\u80fd\u5728\u7ed9\u5b9a\u4fe1\u606f\u8bba\u53ef\u533a\u5206\u5ea6\u91cf\u4e0b\u6700\u5927\u5316\u5176\u4e0e\u5e73\u8861\u6001\u7684\u8ddd\u79bb\u3002", "result": "\u8be5\u534f\u8bae\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\uff0c\u6570\u503c\u6a21\u62df\u8ba1\u7b97\u91cf\u4f4e\u3002\u5728\u6a2a\u5411\u573a\u4f0a\u8f9b\u94fe\u548cXXZ\u94fe\u7684\u975e\u5e7a\u6b63\u52a8\u529b\u5b66\u4e2d\u5c55\u793a\u4e86\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\uff0c\u901a\u8fc7\u5e0c\u5c14\u4f2f\u7279-\u65bd\u5bc6\u7279\u8ddd\u79bb\u3001\u91cf\u5b50\u76f8\u5bf9\u71b5\u548c\u8ff9\u8ddd\u79bb\u7b49\u5ea6\u91cf\u6355\u83b7\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u771f\u6b63\u91cf\u5b50\u59c6\u6f58\u5df4\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u591a\u529f\u80fd\u7684\u5de5\u7a0b\u6846\u67b6\uff0c\u80fd\u591f\u6307\u6570\u52a0\u901f\u7cfb\u7edf\u5411\u7a33\u6001\u7684\u6536\u655b\u3002"}}
{"id": "2512.06737", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.06737", "abs": "https://arxiv.org/abs/2512.06737", "authors": ["Nikhil Verma", "Joonas Linnosmaa", "Espinosa-Leal Leonardo", "Napat Vajragupta"], "title": "Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics", "comment": "80 pages, 6 tables, 2 figures, 5 appendices, proof-of-concept", "summary": "The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.", "AI": {"tldr": "ArcGD\u4f18\u5316\u5668\u5728\u975e\u51f8\u57fa\u51c6\u51fd\u6570\u548c\u771f\u5b9eML\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8eAdam\u7b49\u5148\u8fdb\u4f18\u5316\u5668\uff0c\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6297\u8fc7\u62df\u5408\u7279\u6027", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668\uff0c\u80fd\u591f\u5728\u9ad8\u7ef4\u975e\u51f8\u95ee\u9898\u548c\u771f\u5b9e\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u8d85\u8d8a\u73b0\u6709\u4f18\u5316\u5668\uff0c\u7279\u522b\u662f\u5728\u6cdb\u5316\u80fd\u529b\u548c\u6297\u8fc7\u62df\u5408\u65b9\u9762", "method": "\u63d0\u51faArcGD\u4f18\u5316\u5668\uff0c\u9996\u5148\u5728\u5177\u6709\u6311\u6218\u6027\u7684Rosenbrock\u51fd\u6570\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff082D\u523050,000D\uff09\uff0c\u7136\u540e\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\u4f7f\u75288\u79cd\u4e0d\u540cMLP\u67b6\u6784\u4e0eAdam\u3001AdamW\u3001Lion\u3001SGD\u8fdb\u884c\u6bd4\u8f83", "result": "ArcGD\u5728Rosenbrock\u51fd\u6570\u4e0a\u4f18\u4e8eAdam\uff1b\u5728CIFAR-10\u4e0a\u83b7\u5f97\u6700\u9ad8\u5e73\u5747\u6d4b\u8bd5\u51c6\u786e\u7387\uff0850.7%\uff09\uff0c\u57288\u79cd\u67b6\u6784\u4e2d6\u79cd\u83b7\u80dc\u6216\u6301\u5e73\uff0c\u4e14\u80fd\u6301\u7eed\u6539\u8fdb\u800c\u4e0d\u50cfAdam/W\u4f1a\u56de\u5f52", "conclusion": "ArcGD\u5728\u51e0\u4f55\u538b\u529b\u6d4b\u8bd5\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e14\u4e0eLion\u4f18\u5316\u5668\u5b58\u5728\u7406\u8bba\u8054\u7cfb\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22"}}
{"id": "2512.07567", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.07567", "abs": "https://arxiv.org/abs/2512.07567", "authors": ["Rahul Shastri"], "title": "Uniform relativistic motion through a thermal bath as a thermodynamic resource", "comment": "7 pages, 3 figures, Comments are welcome!", "summary": "We show that a quantum system undergoing motion with uniform relativistic velocity through a thermal bath consisting of a massless scalar field is generically driven into a non-equilibrium steady-state (NESS) solely due to its motion, even in the absence of external driving or multiple baths. The relative motion between the system and the bath breaks detailed balance, preventing thermalization to a Gibbs state. We find that the resulting steady-states fall into two distinct classes: (i) NESSs with persistent probability currents, and (ii) current-free non-Gibbs steady states characterized by a frequency-dependent effective inverse temperature. We demonstrate, using a three-level system, that NESSs with probability current can function as noisy stochastic clock, while current-free non-Gibbs steady states possess non-zero non-equilibrium free energy, indicating their potential as a quantum battery for work extraction or storage.", "AI": {"tldr": "\u91cf\u5b50\u7cfb\u7edf\u5728\u70ed\u6d74\u4e2d\u4ee5\u76f8\u5bf9\u8bba\u901f\u5ea6\u8fd0\u52a8\u65f6\uff0c\u5373\u4f7f\u6ca1\u6709\u5916\u90e8\u9a71\u52a8\u6216\u591a\u4e2a\u70ed\u6d74\uff0c\u4e5f\u4f1a\u8fdb\u5165\u975e\u5e73\u8861\u7a33\u6001\uff0c\u8fd9\u6e90\u4e8e\u76f8\u5bf9\u8fd0\u52a8\u7834\u574f\u4e86\u7ec6\u81f4\u5e73\u8861\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u7cfb\u7edf\u5728\u76f8\u5bf9\u8bba\u8fd0\u52a8\u4e0b\u4e0e\u70ed\u6d74\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63a2\u7d22\u76f8\u5bf9\u8fd0\u52a8\u5982\u4f55\u7834\u574f\u70ed\u5e73\u8861\u5e76\u4ea7\u751f\u975e\u5e73\u8861\u7a33\u6001\u3002", "method": "\u5206\u6790\u91cf\u5b50\u7cfb\u7edf\u5728\u8d28\u91cf\u4e3a\u96f6\u7684\u6807\u91cf\u573a\u70ed\u6d74\u4e2d\u4ee5\u5747\u5300\u76f8\u5bf9\u8bba\u901f\u5ea6\u8fd0\u52a8\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u5176\u7a33\u6001\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u4e24\u7c7b\u975e\u5e73\u8861\u7a33\u6001\uff1a1) \u5177\u6709\u6301\u7eed\u6982\u7387\u6d41\u7684NESS\uff1b2) \u65e0\u7535\u6d41\u7684\u975e\u5409\u5e03\u65af\u7a33\u6001\uff0c\u5177\u6709\u9891\u7387\u4f9d\u8d56\u7684\u6709\u6548\u9006\u6e29\u5ea6\u3002", "conclusion": "\u5177\u6709\u6982\u7387\u6d41\u7684NESS\u53ef\u4f5c\u4e3a\u566a\u58f0\u968f\u673a\u65f6\u949f\uff0c\u800c\u65e0\u7535\u6d41\u7684\u975e\u5409\u5e03\u65af\u7a33\u6001\u5177\u6709\u975e\u96f6\u975e\u5e73\u8861\u81ea\u7531\u80fd\uff0c\u53ef\u4f5c\u4e3a\u91cf\u5b50\u7535\u6c60\u7528\u4e8e\u529f\u7684\u63d0\u53d6\u6216\u5b58\u50a8\u3002"}}
{"id": "2512.06752", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06752", "abs": "https://arxiv.org/abs/2512.06752", "authors": ["Chang Liu", "Vivian Li", "Linus Leong", "Vladimir Radenkovic", "Pietro Li\u00f2", "Chaitanya K. Joshi"], "title": "Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets", "comment": "Presented at Machine Learning in Structural Biology, 2025. Open-source code: https://github.com/VirtualProteins/GNN_UNet", "summary": "Geometric Graph Neural Networks (GNNs) and Transformers have become state-of-the-art for learning from 3D protein structures. However, their reliance on message passing prevents them from capturing the hierarchical interactions that govern protein function, such as global domains and long-range allosteric regulation. In this work, we argue that the network architecture itself should mirror this biological hierarchy. We introduce Geometric Graph U-Nets, a new class of models that learn multi-scale representations by recursively coarsening and refining the protein graph. We prove that this hierarchical design can theoretically more expressive than standard Geometric GNNs. Empirically, on the task of protein fold classification, Geometric U-Nets substantially outperform invariant and equivariant baselines, demonstrating their ability to learn the global structural patterns that define protein folds. Our work provides a principled foundation for designing geometric deep learning architectures that can learn the multi-scale structure of biomolecules.", "AI": {"tldr": "\u63d0\u51faGeometric Graph U-Nets\uff0c\u4e00\u79cd\u7528\u4e8e3D\u86cb\u767d\u8d28\u7ed3\u6784\u5b66\u4e60\u7684\u5c42\u6b21\u5316\u51e0\u4f55\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u9012\u5f52\u7c97\u5316\u548c\u7ec6\u5316\u86cb\u767d\u8d28\u56fe\u6765\u5b66\u4e60\u591a\u5c3a\u5ea6\u8868\u793a\uff0c\u5728\u86cb\u767d\u8d28\u6298\u53e0\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u51e0\u4f55GNN\u548cTransformer\u4f9d\u8d56\u6d88\u606f\u4f20\u9012\uff0c\u65e0\u6cd5\u6355\u6349\u86cb\u767d\u8d28\u529f\u80fd\u6240\u9700\u7684\u5c42\u6b21\u5316\u76f8\u4e92\u4f5c\u7528\uff08\u5982\u5168\u5c40\u7ed3\u6784\u57df\u548c\u957f\u7a0b\u53d8\u6784\u8c03\u8282\uff09\uff0c\u9700\u8981\u7f51\u7edc\u67b6\u6784\u672c\u8eab\u53cd\u6620\u8fd9\u79cd\u751f\u7269\u5c42\u6b21\u7ed3\u6784\u3002", "method": "\u5f15\u5165Geometric Graph U-Nets\uff0c\u901a\u8fc7\u9012\u5f52\u7c97\u5316\u548c\u7ec6\u5316\u86cb\u767d\u8d28\u56fe\u6765\u5b66\u4e60\u591a\u5c3a\u5ea6\u8868\u793a\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u67b6\u6784\uff0c\u7406\u8bba\u4e0a\u6bd4\u6807\u51c6\u51e0\u4f55GNN\u66f4\u5177\u8868\u8fbe\u529b\u3002", "result": "\u5728\u86cb\u767d\u8d28\u6298\u53e0\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cGeometric U-Nets\u663e\u8457\u4f18\u4e8e\u4e0d\u53d8\u548c\u7b49\u53d8\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u5b66\u4e60\u5b9a\u4e49\u86cb\u767d\u8d28\u6298\u53e0\u7684\u5168\u5c40\u7ed3\u6784\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8bbe\u8ba1\u80fd\u591f\u5b66\u4e60\u751f\u7269\u5206\u5b50\u591a\u5c3a\u5ea6\u7ed3\u6784\u7684\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c42\u6b21\u5316\u8bbe\u8ba1\u80fd\u66f4\u597d\u5730\u6355\u6349\u86cb\u767d\u8d28\u7684\u751f\u7269\u5b66\u5c42\u6b21\u7ed3\u6784\u3002"}}
{"id": "2512.07589", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07589", "abs": "https://arxiv.org/abs/2512.07589", "authors": ["Ying Hu", "Sheng-Yong Li", "En-Qi Chen", "Jing Zhang", "Yu-xi Liu", "Jia-Gui Feng", "Zhihui Peng"], "title": "On-Demand Microwave Single-Photon Source Based on Tantalum Thin Film", "comment": "9 pages, 5 figures", "summary": "Single-photon sources are crucial for quantum information technologies. Here, we demonstrate a microwave single-photon source fabricated using a tantalum-based thin film, whose favorable material properties enable high-quality and stable photon emission. The antibunching behavior of the emitted radiation is revealed by second-order correlation measurements. Furthermore, traveling-wave parametric amplifiers are used as the pre-amplifier in the detection chains, we substantially improve the signal-to-noise ratio and thereby greatly reduce the acquisition time required for second-order correlation measurements. These results demonstrate the viability of tantalum-based superconducting devices as reliable platforms for microwave quantum photonics.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u57fa\u4e8e\u94bd\u8584\u819c\u7684\u5fae\u6ce2\u5355\u5149\u5b50\u6e90\uff0c\u5229\u7528\u94bd\u7684\u4f18\u826f\u6750\u6599\u7279\u6027\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7a33\u5b9a\u7684\u5149\u5b50\u53d1\u5c04\uff0c\u5e76\u901a\u8fc7\u4e8c\u9636\u76f8\u5173\u6d4b\u91cf\u9a8c\u8bc1\u4e86\u53cd\u805a\u675f\u884c\u4e3a\uff0c\u540c\u65f6\u4f7f\u7528\u884c\u6ce2\u53c2\u91cf\u653e\u5927\u5668\u4f5c\u4e3a\u524d\u7f6e\u653e\u5927\u5668\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u566a\u6bd4\u548c\u6d4b\u91cf\u6548\u7387\u3002", "motivation": "\u5355\u5149\u5b50\u6e90\u662f\u91cf\u5b50\u4fe1\u606f\u6280\u672f\u7684\u5173\u952e\u7ec4\u4ef6\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u94bd\u8d85\u5bfc\u5668\u4ef6\u7684\u53ef\u9760\u5fae\u6ce2\u5355\u5149\u5b50\u6e90\u5e73\u53f0\uff0c\u5229\u7528\u94bd\u7684\u4f18\u826f\u6750\u6599\u7279\u6027\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7a33\u5b9a\u7684\u5149\u5b50\u53d1\u5c04\u3002", "method": "\u4f7f\u7528\u94bd\u57fa\u8584\u819c\u5236\u9020\u5fae\u6ce2\u5355\u5149\u5b50\u6e90\uff0c\u901a\u8fc7\u4e8c\u9636\u76f8\u5173\u6d4b\u91cf\u9a8c\u8bc1\u5149\u5b50\u53d1\u5c04\u7684\u53cd\u805a\u675f\u884c\u4e3a\u3002\u5728\u68c0\u6d4b\u94fe\u4e2d\u4f7f\u7528\u884c\u6ce2\u53c2\u91cf\u653e\u5927\u5668\u4f5c\u4e3a\u524d\u7f6e\u653e\u5927\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4fe1\u566a\u6bd4\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u94bd\u8584\u819c\u7684\u5fae\u6ce2\u5355\u5149\u5b50\u6e90\uff0c\u89c2\u5bdf\u5230\u660e\u663e\u7684\u53cd\u805a\u675f\u884c\u4e3a\u3002\u4f7f\u7528\u884c\u6ce2\u53c2\u91cf\u653e\u5927\u5668\u540e\uff0c\u4fe1\u566a\u6bd4\u5927\u5e45\u63d0\u5347\uff0c\u4e8c\u9636\u76f8\u5173\u6d4b\u91cf\u7684\u91c7\u96c6\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "\u94bd\u57fa\u8d85\u5bfc\u5668\u4ef6\u662f\u5fae\u6ce2\u91cf\u5b50\u5149\u5b50\u5b66\u7684\u53ef\u9760\u5e73\u53f0\uff0c\u5176\u4f18\u826f\u7684\u6750\u6599\u7279\u6027\u80fd\u591f\u652f\u6301\u9ad8\u8d28\u91cf\u7684\u5355\u5149\u5b50\u53d1\u5c04\uff0c\u7ed3\u5408\u5148\u8fdb\u7684\u68c0\u6d4b\u6280\u672f\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u91cf\u5b50\u5149\u5b50\u6d4b\u91cf\u3002"}}
{"id": "2512.06758", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06758", "abs": "https://arxiv.org/abs/2512.06758", "authors": ["Zilong Wang", "Shuai Li"], "title": "Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship", "comment": null, "summary": "The problem of two-sided matching markets is well-studied in computer science and economics, owing to its diverse applications across numerous domains. Since market participants are usually uncertain about their preferences in various online matching platforms, an emerging line of research is dedicated to the online setting where one-side participants (players) learn their unknown preferences through multiple rounds of interactions with the other side (arms). Sankararaman et al. provide an $\u03a9\\left( \\frac{N\\log(T)}{\u0394^2} + \\frac{K\\log(T)}\u0394 \\right)$ regret lower bound for this problem under serial dictatorship assumption, where $N$ is the number of players, $K (\\geq N)$ is the number of arms, $\u0394$ is the minimum reward gap across players and arms, and $T$ is the time horizon. Serial dictatorship assumes arms have the same preferences, which is common in reality when one side participants have a unified evaluation standard. Recently, the work of Kong and Li proposes the ET-GS algorithm and achieves an $O\\left( \\frac{K\\log(T)}{\u0394^2} \\right)$ regret upper bound, which is the best upper bound attained so far. Nonetheless, a gap between the lower and upper bounds, ranging from $N$ to $K$, persists. It remains unclear whether the lower bound or the upper bound needs to be improved. In this paper, we propose a multi-level successive selection algorithm that obtains an $O\\left( \\frac{N\\log(T)}{\u0394^2} + \\frac{K\\log(T)}\u0394 \\right)$ regret bound when the market satisfies serial dictatorship. To the best of our knowledge, we are the first to propose an algorithm that matches the lower bound in the problem of matching markets with bandits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ea7\u8fde\u7eed\u9009\u62e9\u7b97\u6cd5\uff0c\u5728\u5e8f\u5217\u72ec\u88c1\u5047\u8bbe\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u5df2\u77e5\u4e0b\u754c\u5339\u914d\u7684\u9057\u61be\u4e0a\u754c\uff0c\u89e3\u51b3\u4e86\u53cc\u8fb9\u5339\u914d\u5e02\u573a\u4e2d\u5728\u7ebf\u5b66\u4e60\u504f\u597d\u95ee\u9898\u7684\u9057\u61be\u4e0a\u4e0b\u754c\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u53cc\u8fb9\u5339\u914d\u5e02\u573a\u4e2d\u7684\u5728\u7ebf\u5b66\u4e60\u504f\u597d\u95ee\u9898\u5b58\u5728\u5df2\u77e5\u7684\u9057\u61be\u4e0b\u754c\u548c\u4e0a\u754c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff08\u4eceN\u5230K\uff09\uff0c\u4e0d\u6e05\u695a\u662f\u9700\u8981\u6539\u8fdb\u4e0b\u754c\u8fd8\u662f\u4e0a\u754c\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u591a\u7ea7\u8fde\u7eed\u9009\u62e9\u7b97\u6cd5\uff0c\u5728\u5e8f\u5217\u72ec\u88c1\u5047\u8bbe\u4e0b\u5de5\u4f5c\uff0c\u8be5\u5047\u8bbe\u8ba4\u4e3a\u6240\u6709\u53c2\u4e0e\u8005\uff08arms\uff09\u5177\u6709\u76f8\u540c\u7684\u504f\u597d\u6807\u51c6\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86O(Nlog(T)/\u0394\u00b2 + Klog(T)/\u0394)\u7684\u9057\u61be\u4e0a\u754c\uff0c\u4e0e\u5df2\u77e5\u7684\u03a9(Nlog(T)/\u0394\u00b2 + Klog(T)/\u0394)\u4e0b\u754c\u5b8c\u5168\u5339\u914d\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u5e26\u8d4c\u535a\u673a\u7684\u5339\u914d\u5e02\u573a\u95ee\u9898\u4e2d\u8fbe\u5230\u5df2\u77e5\u4e0b\u754c\u7684\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u7406\u8bba\u5dee\u8ddd\u95ee\u9898\u3002"}}
{"id": "2512.07616", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07616", "abs": "https://arxiv.org/abs/2512.07616", "authors": ["Simon Friederich"], "title": "Sharp values for all dynamical variables via Anti-Wick quantization", "comment": "19 pages, no figures", "summary": "This paper proposes an approach to interpreting quantum expectation values that may help address the quantum measurement problem. Quantum expectation values are usually calculated via Hilbert space inner products and, thereby, differently from expectation values in classical mechanics, which are weighted phase-space integrals. It is shown that, by using Anti-Wick quantization to associate dynamical variables with self-adjoint linear operators, quantum expectation values can be interpreted as genuine weighted averages over phase space, paralleling their classical counterparts. This interpretation arises naturally in the Segal-Bargmann space, where creation and annihilation operators act as simple multiplication and differentiation operators. In this setting, the Husimi Q-function - the coherent-state representation of the quantum state - can be seen as a true probability density in phase space. Unlike Bohmian mechanics, the present approach retains the standard correspondence between dynamical variables and self-adjoint operators while paving the way for a classical-like probabilistic interpretation of quantum statistics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u53cdWick\u91cf\u5b50\u5316\u5c06\u91cf\u5b50\u671f\u671b\u503c\u89e3\u91ca\u4e3a\u76f8\u7a7a\u95f4\u4e0a\u7684\u52a0\u6743\u5e73\u5747\uff0c\u4ece\u800c\u4e3a\u91cf\u5b50\u6d4b\u91cf\u95ee\u9898\u63d0\u4f9b\u4e00\u79cd\u7ecf\u5178\u6982\u7387\u89e3\u91ca", "motivation": "\u89e3\u51b3\u91cf\u5b50\u6d4b\u91cf\u95ee\u9898\uff0c\u5f25\u5408\u91cf\u5b50\u671f\u671b\u503c\u4e0e\u7ecf\u5178\u671f\u671b\u503c\u4e4b\u95f4\u7684\u89e3\u91ca\u5dee\u5f02\u3002\u91cf\u5b50\u671f\u671b\u503c\u901a\u5e38\u901a\u8fc7\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u5185\u79ef\u8ba1\u7b97\uff0c\u800c\u7ecf\u5178\u671f\u671b\u503c\u5219\u662f\u76f8\u7a7a\u95f4\u4e0a\u7684\u52a0\u6743\u79ef\u5206\uff0c\u4e24\u8005\u89e3\u91ca\u65b9\u5f0f\u4e0d\u540c\u3002", "method": "\u4f7f\u7528\u53cdWick\u91cf\u5b50\u5316\u5c06\u52a8\u529b\u5b66\u53d8\u91cf\u4e0e\u81ea\u4f34\u7ebf\u6027\u7b97\u5b50\u5173\u8054\uff0c\u5728Segal-Bargmann\u7a7a\u95f4\u4e2d\uff0c\u91cf\u5b50\u671f\u671b\u503c\u53ef\u89e3\u91ca\u4e3a\u76f8\u7a7a\u95f4\u4e0a\u7684\u52a0\u6743\u5e73\u5747\u3002\u5728\u6b64\u6846\u67b6\u4e0b\uff0cHusimi Q\u51fd\u6570\uff08\u91cf\u5b50\u6001\u7684\u76f8\u5e72\u6001\u8868\u793a\uff09\u53ef\u89c6\u4e3a\u76f8\u7a7a\u95f4\u4e2d\u7684\u771f\u5b9e\u6982\u7387\u5bc6\u5ea6\u3002", "result": "\u91cf\u5b50\u671f\u671b\u503c\u53ef\u88ab\u89e3\u91ca\u4e3a\u76f8\u7a7a\u95f4\u4e0a\u7684\u771f\u6b63\u52a0\u6743\u5e73\u5747\uff0c\u4e0e\u7ecf\u5178\u5bf9\u5e94\u7269\u5e73\u884c\u3002Husimi Q\u51fd\u6570\u53ef\u4f5c\u4e3a\u76f8\u7a7a\u95f4\u4e2d\u7684\u6982\u7387\u5bc6\u5ea6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u5178\u6982\u7387\u89e3\u91ca\u91cf\u5b50\u7edf\u8ba1\u7684\u9014\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fdd\u7559\u4e86\u52a8\u529b\u5b66\u53d8\u91cf\u4e0e\u81ea\u4f34\u7b97\u5b50\u7684\u6807\u51c6\u5bf9\u5e94\u5173\u7cfb\uff0c\u540c\u65f6\u4e3a\u91cf\u5b50\u7edf\u8ba1\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7ecf\u5178\u7684\u6982\u7387\u89e3\u91ca\uff0c\u4e0e\u73bb\u59c6\u529b\u5b66\u4e0d\u540c\uff0c\u4e3a\u91cf\u5b50\u6d4b\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u601d\u8def\u3002"}}
{"id": "2512.06782", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06782", "abs": "https://arxiv.org/abs/2512.06782", "authors": ["Weiqi Guan", "Zihao Shi"], "title": "Measuring Over-smoothing beyond Dirichlet energy", "comment": "17 pages, 1 figure", "summary": "While Dirichlet energy serves as a prevalent metric for quantifying over-smoothing, it is inherently restricted to capturing first-order feature derivatives. To address this limitation, we propose a generalized family of node similarity measures based on the energy of higher-order feature derivatives. Through a rigorous theoretical analysis of the relationships among these measures, we establish the decay rates of Dirichlet energy under both continuous heat diffusion and discrete aggregation operators. Furthermore, our analysis reveals an intrinsic connection between the over-smoothing decay rate and the spectral gap of the graph Laplacian. Finally, empirical results demonstrate that attention-based Graph Neural Networks (GNNs) suffer from over-smoothing when evaluated under these proposed metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u9ad8\u9636\u7279\u5f81\u5bfc\u6570\u7684\u8282\u70b9\u76f8\u4f3c\u6027\u5ea6\u91cf\u5bb6\u65cf\uff0c\u7528\u4e8e\u66f4\u5168\u9762\u91cf\u5316\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\uff0c\u5efa\u7acb\u4e86\u8fc7\u5e73\u6ed1\u8870\u51cf\u7387\u4e0e\u56fe\u62c9\u666e\u62c9\u65af\u8c31\u9699\u7684\u5185\u5728\u8054\u7cfb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eDirichlet\u80fd\u91cf\u7684\u8fc7\u5e73\u6ed1\u5ea6\u91cf\u4ec5\u6355\u83b7\u4e00\u9636\u7279\u5f81\u5bfc\u6570\uff0c\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u5ea6\u91cf\u65b9\u6cd5\u6765\u91cf\u5316\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u9636\u7279\u5f81\u5bfc\u6570\u80fd\u91cf\u7684\u5e7f\u4e49\u8282\u70b9\u76f8\u4f3c\u6027\u5ea6\u91cf\u5bb6\u65cf\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5efa\u7acb\u8fd9\u4e9b\u5ea6\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5206\u6790\u8fde\u7eed\u70ed\u6269\u6563\u548c\u79bb\u6563\u805a\u5408\u7b97\u5b50\u4e0bDirichlet\u80fd\u91cf\u7684\u8870\u51cf\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u8fc7\u5e73\u6ed1\u8870\u51cf\u7387\u4e0e\u56fe\u62c9\u666e\u62c9\u65af\u8c31\u9699\u7684\u5185\u5728\u8054\u7cfb\uff0c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8fd9\u4e9b\u65b0\u5ea6\u91cf\u4e0b\u786e\u5b9e\u5b58\u5728\u8fc7\u5e73\u6ed1\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u9ad8\u9636\u7279\u5f81\u5bfc\u6570\u80fd\u91cf\u5ea6\u91cf\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8fc7\u5e73\u6ed1\u91cf\u5316\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8fc7\u5e73\u6ed1\u73b0\u8c61\u4e0e\u56fe\u7ed3\u6784\u8c31\u7279\u6027\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3\u56fe\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.07619", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07619", "abs": "https://arxiv.org/abs/2512.07619", "authors": ["Bartu Bisgin", "Marwa Garsi", "Andreas Welscher", "Michael Hanke", "Fleming Bruckmaier"], "title": "Quantum Diamond Microscopy for Non-Destructive Failure Analysis of an Integrated Fan-Out Package-on-Package iPhone Chip", "comment": "12 pages, 5 figures", "summary": "The increasing complexity of advanced semiconductor packages, driven by chiplet architectures and 2.5D/3D integration, challenges conventional failure localization methods such as lock-in thermography (LIT) and complicates current Failure Analysis (FA) workflows. Dense redistribution layers and buried interconnects limit the ability of established techniques to understand failure mechanisms non-destructively. In this work, we validate quantum diamond microscopy (QDM) based on nitrogen-vacancy (NV) centers in diamond as a non-destructive localization method through magnetic current path imaging at the package level. Using commercial Integrated Fan-Out Package-on- Package (InFO-PoP) devices from iPhones, we showcase a complete FA workflow that includes QDM to localize a short-type failure at an Integrated Passive Device (IPD) at the package backside. We showcase that the QDM results provide invaluable information on top of conventional techniques and can significantly enhance root-cause identification in package-level FA workflows. This work demonstrates the potential of QDM for broader integration into semiconductor chip and package analysis workflows.", "AI": {"tldr": "\u91cf\u5b50\u94bb\u77f3\u663e\u5fae\u955c\uff08QDM\uff09\u4f5c\u4e3a\u975e\u7834\u574f\u6027\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u78c1\u7535\u6d41\u8def\u5f84\u6210\u50cf\u5728\u5c01\u88c5\u7ea7\u522b\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u5148\u8fdb\u534a\u5bfc\u4f53\u5c01\u88c5\u7684\u6545\u969c\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u5148\u8fdb\u534a\u5bfc\u4f53\u5c01\u88c5\uff08\u5982\u5c0f\u82af\u7247\u67b6\u6784\u548c2.5D/3D\u96c6\u6210\uff09\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff08\u5982\u9501\u76f8\u70ed\u6210\u50cf\uff09\uff0c\u5bc6\u96c6\u7684\u518d\u5206\u5e03\u5c42\u548c\u57cb\u5165\u5f0f\u4e92\u8fde\u9650\u5236\u4e86\u975e\u7834\u574f\u6027\u7406\u89e3\u6545\u969c\u673a\u5236\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u91d1\u521a\u77f3\u4e2d\u6c2e\u7a7a\u4f4d\uff08NV\uff09\u4e2d\u5fc3\u7684\u91cf\u5b50\u94bb\u77f3\u663e\u5fae\u955c\uff08QDM\uff09\u8fdb\u884c\u975e\u7834\u574f\u6027\u78c1\u7535\u6d41\u8def\u5f84\u6210\u50cf\u5b9a\u4f4d\u3002\u91c7\u7528iPhone\u7684\u5546\u4e1a\u96c6\u6210\u6247\u51fa\u578b\u5c01\u88c5\u4e0a\u5c01\u88c5\uff08InFO-PoP\uff09\u5668\u4ef6\uff0c\u5c55\u793a\u5b8c\u6574\u7684\u6545\u969c\u5206\u6790\u6d41\u7a0b\uff0c\u5305\u62ec\u4f7f\u7528QDM\u5728\u5c01\u88c5\u80cc\u9762\u5b9a\u4f4d\u96c6\u6210\u65e0\u6e90\u5668\u4ef6\uff08IPD\uff09\u7684\u77ed\u8def\u6545\u969c\u3002", "result": "QDM\u7ed3\u679c\u63d0\u4f9b\u4e86\u8d85\u8d8a\u4f20\u7edf\u6280\u672f\u7684\u5b9d\u8d35\u4fe1\u606f\uff0c\u80fd\u663e\u8457\u589e\u5f3a\u5c01\u88c5\u7ea7\u522b\u6545\u969c\u5206\u6790\u6d41\u7a0b\u4e2d\u7684\u6839\u672c\u539f\u56e0\u8bc6\u522b\u3002\u6210\u529f\u5b9a\u4f4d\u4e86IPD\u7684\u77ed\u8def\u6545\u969c\uff0c\u5c55\u793a\u4e86QDM\u5728\u534a\u5bfc\u4f53\u82af\u7247\u548c\u5c01\u88c5\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u91cf\u5b50\u94bb\u77f3\u663e\u5fae\u955c\uff08QDM\uff09\u4f5c\u4e3a\u975e\u7834\u574f\u6027\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u53ef\u66f4\u5e7f\u6cdb\u5730\u96c6\u6210\u5230\u534a\u5bfc\u4f53\u82af\u7247\u548c\u5c01\u88c5\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u89e3\u51b3\u5148\u8fdb\u534a\u5bfc\u4f53\u5c01\u88c5\u7684\u6545\u969c\u5206\u6790\u6311\u6218\u3002"}}
{"id": "2512.06785", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06785", "abs": "https://arxiv.org/abs/2512.06785", "authors": ["Vasileios Sevetlidis", "George Pavlidis", "Antonios Gasteratos"], "title": "Angular Regularization for Positive-Unlabeled Learning on the Hypersphere", "comment": "Featured Certification, J2C Certification. Transactions on Machine Learning Research, 2025", "summary": "Positive-Unlabeled (PU) learning addresses classification problems where only a subset of positive examples is labeled and the remaining data is unlabeled, making explicit negative supervision unavailable. Existing PU methods often rely on negative-risk estimation or pseudo-labeling, which either require strong distributional assumptions or can collapse in high-dimensional settings. We propose AngularPU, a novel PU framework that operates on the unit hypersphere using cosine similarity and angular margin. In our formulation, the positive class is represented by a learnable prototype vector, and classification reduces to thresholding the cosine similarity between an embedding and this prototype-eliminating the need for explicit negative modeling. To counteract the tendency of unlabeled embeddings to cluster near the positive prototype, we introduce an angular regularizer that encourages dispersion of the unlabeled set over the hypersphere, improving separation. We provide theoretical guarantees on the Bayes-optimality of the angular decision rule, consistency of the learned prototype, and the effect of the regularizer on the unlabeled distribution. Experiments on benchmark datasets demonstrate that AngularPU achieves competitive or superior performance compared to state-of-the-art PU methods, particularly in settings with scarce positives and high-dimensional embeddings, while offering geometric interpretability and scalability.", "AI": {"tldr": "AngularPU\uff1a\u4e00\u79cd\u57fa\u4e8e\u89d2\u5ea6\u76f8\u4f3c\u5ea6\u548c\u539f\u578b\u5411\u91cf\u7684PU\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e0\u9700\u663e\u5f0f\u8d1f\u6837\u672c\u5efa\u6a21\uff0c\u901a\u8fc7\u89d2\u5ea6\u6b63\u5219\u5316\u9632\u6b62\u672a\u6807\u8bb0\u6837\u672c\u805a\u96c6", "motivation": "\u73b0\u6709PU\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5f3a\u5206\u5e03\u5047\u8bbe\uff0c\u8981\u4e48\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u5bb9\u6613\u5d29\u6e83\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u3001\u65e0\u9700\u663e\u5f0f\u8d1f\u6837\u672c\u5efa\u6a21\u7684\u65b9\u6cd5", "method": "\u5728\u5355\u4f4d\u8d85\u7403\u9762\u4e0a\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u548c\u89d2\u5ea6\u95f4\u9694\uff0c\u6b63\u7c7b\u7531\u53ef\u5b66\u4e60\u7684\u539f\u578b\u5411\u91cf\u8868\u793a\uff0c\u5206\u7c7b\u7b80\u5316\u4e3a\u6bd4\u8f83\u5d4c\u5165\u5411\u91cf\u4e0e\u539f\u578b\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u9608\u503c\uff0c\u5e76\u5f15\u5165\u89d2\u5ea6\u6b63\u5219\u5316\u5668\u5206\u6563\u672a\u6807\u8bb0\u6837\u672c", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u6216\u4f18\u4e8e\u73b0\u6709PU\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6b63\u6837\u672c\u7a00\u7f3a\u548c\u9ad8\u7ef4\u5d4c\u5165\u8bbe\u7f6e\u4e2d\uff0c\u540c\u65f6\u63d0\u4f9b\u51e0\u4f55\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "AngularPU\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u663e\u5f0f\u8d1f\u6837\u672c\u5efa\u6a21\u7684\u7a33\u5065PU\u5b66\u4e60\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u4f18\u52bf"}}
{"id": "2512.07626", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.07626", "abs": "https://arxiv.org/abs/2512.07626", "authors": ["Qi-Yin Lin", "Guang-Zheng Ye", "Can Li", "Wan-Jun Su", "Huai-Zhi Wu"], "title": "Enhanced charging power in nonreciprocal quantum battery by reservoir engineering", "comment": "4 pages", "summary": "We propose a scheme to achieve a nonreciprocal quantum battery (QB) in the non-Hermitian (NH) system, which can overcome the intrinsic dissipation and reverse flow constraints. The design is based on a charger and a battery, which are coherently coupled and jointly interact with a bad cavity. By introducing the auxiliary bad cavity and exploiting the nonreciprocal condition, this model can harness the environmental dissipation to suppress the reverse energy transfer. Under resonant conditions, we have achieved a four ratio of the battery energy to the charger energy; in contrast, this ratio is significantly reduced under large detuning. Through damping optimization, high efficiency of the short-time charging power is attained. In comparison to the fully nonreciprocal scheme, the QB operating at the exceptional point (EP) exhibits greater resilience to parameter fluctuations. These findings highlight the potential of NH quantum engineering for advancing QB technology, particularly in regimes involving directional energy transfer, controlled dissipation, and entropy management in open quantum systems.", "AI": {"tldr": "\u63d0\u51fa\u5728\u975e\u5384\u7c73\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u975e\u4e92\u6613\u91cf\u5b50\u7535\u6c60\u7684\u65b9\u6848\uff0c\u5229\u7528\u73af\u5883\u8017\u6563\u6291\u5236\u53cd\u5411\u80fd\u91cf\u4f20\u8f93\uff0c\u5728\u5171\u632f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7535\u6c60\u80fd\u91cf\u4e0e\u5145\u7535\u5668\u80fd\u91cf4:1\u7684\u6bd4\u4f8b\uff0c\u5e76\u5728\u5f02\u5e38\u70b9\u64cd\u4f5c\u65f6\u8868\u73b0\u51fa\u66f4\u597d\u7684\u53c2\u6570\u6ce2\u52a8\u9c81\u68d2\u6027\u3002", "motivation": "\u514b\u670d\u91cf\u5b50\u7535\u6c60\u7cfb\u7edf\u4e2d\u7684\u56fa\u6709\u8017\u6563\u548c\u53cd\u5411\u80fd\u91cf\u6d41\u9650\u5236\uff0c\u5229\u7528\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u7279\u6027\u5b9e\u73b0\u975e\u4e92\u6613\u80fd\u91cf\u4f20\u8f93\uff0c\u4e3a\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u5b9a\u5411\u80fd\u91cf\u8f6c\u79fb\u3001\u53ef\u63a7\u8017\u6563\u548c\u71b5\u7ba1\u7406\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u5145\u7535\u5668\u548c\u7535\u6c60\u7684\u7cfb\u7edf\uff0c\u4e24\u8005\u76f8\u5e72\u8026\u5408\u5e76\u5171\u540c\u4e0e\u574f\u8154\u76f8\u4e92\u4f5c\u7528\u3002\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u574f\u8154\u5e76\u5229\u7528\u975e\u4e92\u6613\u6761\u4ef6\uff0c\u5229\u7528\u73af\u5883\u8017\u6563\u6291\u5236\u53cd\u5411\u80fd\u91cf\u8f6c\u79fb\u3002\u5728\u5171\u632f\u6761\u4ef6\u4e0b\u4f18\u5316\u963b\u5c3c\u53c2\u6570\uff0c\u5b9e\u73b0\u9ad8\u6548\u7387\u7684\u77ed\u65f6\u5145\u7535\u529f\u7387\u3002", "result": "\u5728\u5171\u632f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u7535\u6c60\u80fd\u91cf\u4e0e\u5145\u7535\u5668\u80fd\u91cf4:1\u7684\u6bd4\u4f8b\uff1b\u901a\u8fc7\u963b\u5c3c\u4f18\u5316\u83b7\u5f97\u4e86\u9ad8\u6548\u7387\u7684\u77ed\u65f6\u5145\u7535\u529f\u7387\uff1b\u4e0e\u5b8c\u5168\u975e\u4e92\u6613\u65b9\u6848\u76f8\u6bd4\uff0c\u5728\u5f02\u5e38\u70b9\u64cd\u4f5c\u7684\u91cf\u5b50\u7535\u6c60\u5bf9\u53c2\u6570\u6ce2\u52a8\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u975e\u5384\u7c73\u91cf\u5b50\u5de5\u7a0b\u5728\u63a8\u8fdb\u91cf\u5b50\u7535\u6c60\u6280\u672f\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5b9a\u5411\u80fd\u91cf\u8f6c\u79fb\u3001\u53ef\u63a7\u8017\u6563\u548c\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u71b5\u7ba1\u7406\u7684\u9886\u57df\uff0c\u4e3a\u514b\u670d\u4f20\u7edf\u91cf\u5b50\u7535\u6c60\u7684\u9650\u5236\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.06791", "categories": ["cs.LG", "cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.06791", "abs": "https://arxiv.org/abs/2512.06791", "authors": ["Vedansh Sharma"], "title": "Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games", "comment": null, "summary": "Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.", "AI": {"tldr": "\u63d0\u51faSGN\uff08Small-Gain Nash\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u5757\u52a0\u6743\u51e0\u4f55\u4e2d\u7684\u5757\u5c0f\u589e\u76ca\u6761\u4ef6\uff0c\u4e3a\u68af\u5ea6\u5b66\u4e60\u5728\u975e\u5355\u8c03\u535a\u5f08\u4e2d\u63d0\u4f9b\u6536\u655b\u4fdd\u8bc1\uff0c\u5373\u4f7f\u4f2a\u68af\u5ea6\u5728\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u4e2d\u4e0d\u6ee1\u8db3\u5355\u8c03\u6027\u6761\u4ef6\u3002", "motivation": "\u4f20\u7edf\u535a\u5f08\u4e2d\u68af\u5ea6\u5b66\u4e60\u7684\u6536\u655b\u4fdd\u8bc1\u9700\u8981\u4f2a\u68af\u5ea6\u5728\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u4e2d\u6ee1\u8db3\uff08\u5f3a\uff09\u5355\u8c03\u6027\u6761\u4ef6\uff08Rosen, 1965\uff09\uff0c\u4f46\u8fd9\u4e00\u6761\u4ef6\u5728\u5177\u6709\u5f3a\u8de8\u73a9\u5bb6\u8026\u5408\u7684\u7b80\u5355\u535a\u5f08\u4e2d\u7ecf\u5e38\u5931\u6548\uff0c\u9650\u5236\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4\u3002", "method": "\u5f15\u5165SGN\uff08Small-Gain Nash\uff09\u65b9\u6cd5\uff0c\u5728\u81ea\u5b9a\u4e49\u5757\u52a0\u6743\u51e0\u4f55\u4e2d\u5efa\u7acb\u5757\u5c0f\u589e\u76ca\u6761\u4ef6\u3002\u8be5\u65b9\u6cd5\u5c06\u5c40\u90e8\u66f2\u7387\u548c\u8de8\u73a9\u5bb6Lipschitz\u8026\u5408\u8fb9\u754c\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u6536\u7f29\u8bc1\u4e66\uff0c\u6784\u9020\u52a0\u6743\u5757\u5ea6\u91cf\u4f7f\u4f2a\u68af\u5ea6\u5728\u6ee1\u8db3\u8fd9\u4e9b\u8fb9\u754c\u7684\u4efb\u4f55\u533a\u57df\u90fd\u53d8\u5f97\u5f3a\u5355\u8c03\uff0c\u5373\u4f7f\u5b83\u5728\u6b27\u51e0\u91cc\u5f97\u610f\u4e49\u4e0b\u662f\u975e\u5355\u8c03\u7684\u3002", "result": "\u8fde\u7eed\u6d41\u5728\u8bbe\u8ba1\u7684\u51e0\u4f55\u4e2d\u6307\u6570\u6536\u7f29\uff0c\u6295\u5f71\u6b27\u62c9\u548cRK4\u79bb\u6563\u5316\u5728\u663e\u5f0f\u6b65\u957f\u8fb9\u754c\u4e0b\u6536\u655b\u3002\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\"\u65f6\u95f4\u5c3a\u5ea6\u5e26\"\u8bc1\u4e66\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u6e10\u8fd1\u7684\u3001\u57fa\u4e8e\u5ea6\u91cf\u7684\u8bc1\u4e66\uff0c\u7c7b\u4f3c\u4e8eTTUR\u7684\u4f5c\u7528\u3002\u5728\u4e8c\u6b21\u535a\u5f08\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u6269\u5c55\u5230\u955c\u50cf/Fisher\u51e0\u4f55\u7528\u4e8e\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u7684\u71b5\u6b63\u5219\u5316\u7b56\u7565\u68af\u5ea6\u3002", "conclusion": "SGN\u63d0\u4f9b\u4e86\u4e00\u4e2a\u79bb\u7ebf\u8ba4\u8bc1\u6d41\u7a0b\uff0c\u53ef\u5728\u7d27\u51d1\u533a\u57df\u4f30\u8ba1\u66f2\u7387\u3001\u8026\u5408\u548cLipschitz\u53c2\u6570\uff0c\u4f18\u5316\u5757\u6743\u91cd\u4ee5\u6269\u5927SGN\u8fb9\u754c\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u3001\u53ef\u8ba1\u7b97\u7684\u6536\u655b\u8bc1\u4e66\uff0c\u5305\u62ec\u5ea6\u91cf\u3001\u6536\u7f29\u7387\u548c\u5b89\u5168\u6b65\u957f\uff0c\u9002\u7528\u4e8e\u975e\u5355\u8c03\u535a\u5f08\u3002"}}
{"id": "2512.07656", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07656", "abs": "https://arxiv.org/abs/2512.07656", "authors": ["Sebastian C. Carrasco", "Jabir Chathanathil", "Svetlana A. Malinovskaya", "Ignacio Sola", "Vladimir S. Malinovsky"], "title": "Single-Operation Rydberg Phase Gates via Dynamic Population Suppression", "comment": null, "summary": "We propose a versatile control protocol based on modulated zero-pulse-area fields that dynamically suppresses Rydberg excitation while retaining Rydberg-Rydberg interactions as an entangling phase resource. This mechanism enables single-step, perfectly entangling phase gates for arbitrary blockade strengths, eliminating finite-blockade errors even when the Rabi frequency approaches or exceeds the interaction energy. The approach defines a new operational regime for Rydberg-blockade quantum logic in which speed, fidelity, and robustness are achieved simultaneously within a simple dynamical framework. Owing to its simplicity and generality, the technique is compatible with a wide range of neutral-atom architectures and offers a promising route toward scalable, high-fidelity quantum computation and simulation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8c03\u5236\u96f6\u8109\u51b2\u9762\u79ef\u573a\u7684\u901a\u7528\u63a7\u5236\u534f\u8bae\uff0c\u52a8\u6001\u6291\u5236\u91cc\u5fb7\u5821\u6fc0\u53d1\u540c\u65f6\u4fdd\u7559\u91cc\u5fb7\u5821-\u91cc\u5fb7\u5821\u76f8\u4e92\u4f5c\u7528\u4f5c\u4e3a\u7ea0\u7f20\u76f8\u4f4d\u8d44\u6e90\uff0c\u5b9e\u73b0\u5355\u6b65\u5b8c\u7f8e\u7ea0\u7f20\u76f8\u4f4d\u95e8", "motivation": "\u4f20\u7edf\u91cc\u5fb7\u5821\u963b\u585e\u91cf\u5b50\u903b\u8f91\u5728\u6709\u9650\u963b\u585e\u5f3a\u5ea6\u4e0b\u5b58\u5728\u8bef\u5dee\uff0c\u5f53\u62c9\u6bd4\u9891\u7387\u63a5\u8fd1\u6216\u8d85\u8fc7\u76f8\u4e92\u4f5c\u7528\u80fd\u65f6\u6027\u80fd\u53d7\u9650\uff0c\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u901f\u5ea6\u3001\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027\u7684\u65b0\u64cd\u4f5c\u673a\u5236", "method": "\u4f7f\u7528\u8c03\u5236\u96f6\u8109\u51b2\u9762\u79ef\u573a\u52a8\u6001\u6291\u5236\u91cc\u5fb7\u5821\u6fc0\u53d1\uff0c\u540c\u65f6\u4fdd\u7559\u91cc\u5fb7\u5821-\u91cc\u5fb7\u5821\u76f8\u4e92\u4f5c\u7528\u4f5c\u4e3a\u7ea0\u7f20\u76f8\u4f4d\u8d44\u6e90\uff0c\u5b9e\u73b0\u5355\u6b65\u5b8c\u7f8e\u7ea0\u7f20\u76f8\u4f4d\u95e8", "result": "\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u6709\u9650\u963b\u585e\u8bef\u5dee\uff0c\u5373\u4f7f\u62c9\u6bd4\u9891\u7387\u63a5\u8fd1\u6216\u8d85\u8fc7\u76f8\u4e92\u4f5c\u7528\u80fd\u4e5f\u80fd\u5de5\u4f5c\uff0c\u4e3a\u91cc\u5fb7\u5821\u963b\u585e\u91cf\u5b50\u903b\u8f91\u5b9a\u4e49\u4e86\u65b0\u7684\u64cd\u4f5c\u673a\u5236\uff0c\u540c\u65f6\u5b9e\u73b0\u901f\u5ea6\u3001\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027", "conclusion": "\u8be5\u6280\u672f\u7b80\u5355\u901a\u7528\uff0c\u517c\u5bb9\u591a\u79cd\u4e2d\u6027\u539f\u5b50\u67b6\u6784\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u9ad8\u4fdd\u771f\u5ea6\u7684\u91cf\u5b50\u8ba1\u7b97\u548c\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84"}}
{"id": "2512.06813", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06813", "abs": "https://arxiv.org/abs/2512.06813", "authors": ["Agung Nugraha", "Heungjun Im", "Jihwan Lee"], "title": "Partial Inverse Design of High-Performance Concrete Using Cooperative Neural Networks for Constraint-Aware Mix Generation", "comment": "19 pages, 12 figures", "summary": "High-performance concrete offers exceptional strength and durability but requires complex mix designs involving many interdependent variables and practical constraints. While data-driven methods have advanced predictive modeling for forward design, inverse design, which focuses on determining mix compositions that achieve target performance, remains limited, particularly in design situations where some mix variables are fixed by constraints and only the remaining variables must be determined. This study proposes a cooperative neural network framework for the partial inverse design of high-performance concrete. The framework combines two coupled neural network models, an imputation model that infers the undetermined variables and a surrogate model that predicts compressive strength. Through cooperative learning, the model generates valid and performance-consistent mix designs in a single forward pass while accommodating different constraint combinations without retraining. Its performance is compared with both probabilistic and generative approaches, including Bayesian inference based on a Gaussian process surrogate and autoencoder-based models. Evaluated on a benchmark dataset, the proposed model achieves stable and higher R-squared values of 0.87-0.92 and reduces mean squared error by an average of 50 percent compared with autoencoder baselines and by an average of 70 percent compared with Bayesian inference. The results demonstrate that the cooperative neural network provides an accurate, robust, and computationally efficient foundation for constraint-aware, data-driven mix proportioning in concrete engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u9ad8\u6027\u80fd\u6df7\u51dd\u571f\u90e8\u5206\u9006\u5411\u8bbe\u8ba1\u7684\u534f\u4f5c\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u8026\u5408\u7684\u63d2\u8865\u6a21\u578b\u548c\u4ee3\u7406\u6a21\u578b\uff0c\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u751f\u6210\u6ee1\u8db3\u7ea6\u675f\u4e14\u6027\u80fd\u4e00\u81f4\u7684\u914d\u5408\u6bd4\u8bbe\u8ba1\u3002", "motivation": "\u9ad8\u6027\u80fd\u6df7\u51dd\u571f\u914d\u5408\u6bd4\u8bbe\u8ba1\u6d89\u53ca\u4f17\u591a\u76f8\u4e92\u4f9d\u8d56\u7684\u53d8\u91cf\u548c\u5b9e\u9645\u7ea6\u675f\u3002\u867d\u7136\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6b63\u5411\u8bbe\u8ba1\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u9006\u5411\u8bbe\u8ba1\uff08\u786e\u5b9a\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u7684\u914d\u5408\u6bd4\uff09\u4ecd\u7136\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u67d0\u4e9b\u53d8\u91cf\u88ab\u7ea6\u675f\u56fa\u5b9a\u3001\u53ea\u9700\u786e\u5b9a\u5269\u4f59\u53d8\u91cf\u7684\u90e8\u5206\u9006\u5411\u8bbe\u8ba1\u573a\u666f\u3002", "method": "\u63d0\u51fa\u534f\u4f5c\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u8026\u5408\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a1\uff09\u63d2\u8865\u6a21\u578b\u63a8\u65ad\u672a\u786e\u5b9a\u7684\u53d8\u91cf\uff1b2\uff09\u4ee3\u7406\u6a21\u578b\u9884\u6d4b\u6297\u538b\u5f3a\u5ea6\u3002\u901a\u8fc7\u534f\u4f5c\u5b66\u4e60\uff0c\u6a21\u578b\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u751f\u6210\u6709\u6548\u4e14\u6027\u80fd\u4e00\u81f4\u7684\u914d\u5408\u6bd4\u8bbe\u8ba1\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u7684\u7ea6\u675f\u7ec4\u5408\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u6a21\u578b\u83b7\u5f97\u7a33\u5b9a\u7684R\u5e73\u65b9\u503c0.87-0.92\uff0c\u4e0e\u81ea\u7f16\u7801\u5668\u57fa\u7ebf\u76f8\u6bd4\u5e73\u5747\u51cf\u5c1150%\u5747\u65b9\u8bef\u5dee\uff0c\u4e0e\u8d1d\u53f6\u65af\u63a8\u7406\u76f8\u6bd4\u5e73\u5747\u51cf\u5c1170%\u5747\u65b9\u8bef\u5dee\u3002", "conclusion": "\u534f\u4f5c\u795e\u7ecf\u7f51\u7edc\u4e3a\u6df7\u51dd\u571f\u5de5\u7a0b\u4e2d\u7ea6\u675f\u611f\u77e5\u3001\u6570\u636e\u9a71\u52a8\u7684\u914d\u5408\u6bd4\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u9c81\u68d2\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u57fa\u7840\u3002"}}
{"id": "2512.07670", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07670", "abs": "https://arxiv.org/abs/2512.07670", "authors": ["Renn\u00e9 Medeiros de Ara\u00fajo", "Raphael C\u00e9sar Souza Pimenta", "Lucas Marques Fagundes", "Gustavo Henrique dos Santos", "Nara Rubiano da Silva", "Stephen Patrick Walborn", "Paulo Henrique Souto Ribeiro"], "title": "Brazilian Twin Photons 32nd anniversary", "comment": "32 pages; 19 figures; to appear in the Special Issue \"100 years of Quantum Mechanics\" of the Brazilian Journal of Physics", "summary": "We present a historical review of the development and impact of spontaneous parametric down-conversion (SPDC) in Brazil, marking over three decades since the first twin-photon experiments were performed in the country. This article traces the pioneering efforts that initiated the field, highlighting key experiments, institutions, and researchers who contributed to its growth. We discuss seminal works that established SPDC as a fundamental tool in the Brazilian Quantum Optics community, including studies on spatial correlations, entanglement, and decoherence. By presenting a curated sequence of experiments, we offer an overview of how Brazilian research in twin-photon systems has explored profound concepts through fundamental demonstrations, leading to significant international impact. This review also highlights the formation of a strong scientific community and its ongoing efforts to turn fundamental knowledge into quantum applications.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u5df4\u897f\u81ea\u53d1\u53c2\u91cf\u4e0b\u8f6c\u6362\uff08SPDC\uff09\u9886\u57df\u4e09\u5341\u591a\u5e74\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u5173\u952e\u5b9e\u9a8c\u3001\u7814\u7a76\u673a\u6784\u548c\u5b66\u8005\uff0c\u5c55\u793a\u4e86\u5df4\u897f\u91cf\u5b50\u5149\u5b66\u793e\u533a\u5982\u4f55\u5c06\u57fa\u7840\u7814\u7a76\u8f6c\u5316\u4e3a\u91cf\u5b50\u5e94\u7528\u3002", "motivation": "\u8bb0\u5f55\u5df4\u897f\u5728\u81ea\u53d1\u53c2\u91cf\u4e0b\u8f6c\u6362\uff08SPDC\uff09\u9886\u57df\u4e09\u5341\u591a\u5e74\u7684\u53d1\u5c55\u5386\u53f2\uff0c\u5c55\u793a\u8be5\u56fd\u5728\u91cf\u5b50\u5149\u5b66\u9886\u57df\u7684\u8d21\u732e\u548c\u5f71\u54cd\u529b\uff0c\u5f3a\u8c03\u4ece\u57fa\u7840\u7814\u7a76\u5230\u91cf\u5b50\u5e94\u7528\u7684\u8f6c\u5316\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u5386\u53f2\u56de\u987e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u68b3\u7406\u5173\u952e\u5b9e\u9a8c\u3001\u7814\u7a76\u673a\u6784\u548c\u5b66\u8005\u7684\u8d21\u732e\uff0c\u5448\u73b0\u5df4\u897fSPDC\u7814\u7a76\u7684\u53d1\u5c55\u8109\u7edc\uff0c\u5305\u62ec\u7a7a\u95f4\u5173\u8054\u3001\u7ea0\u7f20\u548c\u9000\u76f8\u5e72\u7b49\u57fa\u7840\u7814\u7a76\u3002", "result": "\u5c55\u793a\u4e86\u5df4\u897f\u5728SPDC\u9886\u57df\u5f62\u6210\u4e86\u5f3a\u5927\u7684\u79d1\u5b66\u793e\u533a\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u57fa\u7840\u5b9e\u9a8c\u63a2\u7d22\u4e86\u91cf\u5b50\u529b\u5b66\u7684\u6df1\u523b\u6982\u5ff5\uff0c\u5e76\u5728\u56fd\u9645\u4e0a\u4ea7\u751f\u4e86\u91cd\u8981\u5f71\u54cd\uff0c\u540c\u65f6\u6b63\u5728\u5c06\u57fa\u7840\u77e5\u8bc6\u8f6c\u5316\u4e3a\u91cf\u5b50\u5e94\u7528\u3002", "conclusion": "\u5df4\u897f\u7684SPDC\u7814\u7a76\u7ecf\u8fc7\u4e09\u5341\u591a\u5e74\u53d1\u5c55\uff0c\u5df2\u4ece\u57fa\u7840\u5b9e\u9a8c\u6210\u957f\u4e3a\u5177\u6709\u56fd\u9645\u5f71\u54cd\u529b\u7684\u91cf\u5b50\u5149\u5b66\u9886\u57df\uff0c\u5f62\u6210\u4e86\u5f3a\u5927\u7684\u79d1\u5b66\u793e\u533a\uff0c\u5e76\u6b63\u5728\u5411\u5b9e\u9645\u91cf\u5b50\u5e94\u7528\u8f6c\u5316\u3002"}}
{"id": "2512.06837", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06837", "abs": "https://arxiv.org/abs/2512.06837", "authors": ["Zhenhao Li", "Xu Cheng", "Yi Zhou"], "title": "Neural Factorization-based Bearing Fault Diagnosis", "comment": null, "summary": "This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u5206\u89e3\u7684\u5206\u7c7b\u6846\u67b6NFC\u7528\u4e8e\u9ad8\u94c1\u8f74\u627f\u6545\u969c\u8bca\u65ad\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6f5c\u5728\u7279\u5f81\u5d4c\u5165\u548c\u795e\u7ecf\u5206\u89e3\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u6761\u4ef6\u4e0b\u7684\u8bca\u65ad\u7cbe\u5ea6", "motivation": "\u9ad8\u94c1\u8f74\u627f\u4f5c\u4e3a\u5217\u8f66\u8fd0\u884c\u7cfb\u7edf\u7684\u6838\u5fc3\u90e8\u4ef6\uff0c\u5176\u5065\u5eb7\u72b6\u51b5\u76f4\u63a5\u5173\u7cfb\u5230\u8fd0\u884c\u5b89\u5168\u3002\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u5728\u590d\u6742\u6761\u4ef6\u4e0b\u9762\u4e34\u8bca\u65ad\u7cbe\u5ea6\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u5206\u89e3\u5206\u7c7b\u6846\u67b6NFC\uff1a1\uff09\u5c06\u632f\u52a8\u65f6\u95f4\u5e8f\u5217\u5d4c\u5165\u5230\u591a\u4e2a\u6a21\u6001\u6f5c\u5728\u7279\u5f81\u5411\u91cf\u4e2d\uff0c\u6355\u6349\u4e0d\u540c\u7684\u6545\u969c\u76f8\u5173\u6a21\u5f0f\uff1b2\uff09\u5229\u7528\u795e\u7ecf\u5206\u89e3\u539f\u7406\u5c06\u8fd9\u4e9b\u5411\u91cf\u878d\u5408\u6210\u7edf\u4e00\u7684\u632f\u52a8\u8868\u793a\u3002\u57fa\u4e8eCP\u548cTucker\u878d\u5408\u65b9\u6848\u5206\u522b\u5b9e\u4f8b\u5316\u4e3aCP-NFC\u548cTucker-NFC\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u79cd\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u90fd\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8bca\u65ad\u6027\u80fd\u3002\u6bd4\u8f83\u5206\u6790\u4e3a\u9ad8\u94c1\u8f74\u627f\u76d1\u6d4b\u4e2d\u9009\u62e9\u6709\u6548\u8bca\u65ad\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5b9e\u8bc1\u8bc1\u636e\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "conclusion": "\u63d0\u51fa\u7684NFC\u6846\u67b6\u80fd\u591f\u4ece\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u6709\u6548\u6316\u6398\u590d\u6742\u7684\u6f5c\u5728\u6545\u969c\u7279\u5f81\uff0c\u4e3a\u89e3\u51b3\u9ad8\u94c1\u8f74\u627f\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07737", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07737", "abs": "https://arxiv.org/abs/2512.07737", "authors": ["Andrew W. Senior", "Thomas Edlich", "Francisco J. H. Heras", "Lei M. Zhang", "Oscar Higgott", "James S. Spencer", "Taylor Applebaum", "Sam Blackwell", "Justin Ledford", "Akvil\u0117 \u017demgulyt\u0117", "Augustin \u017d\u00eddek", "Noah Shutty", "Andrew Cowie", "Yin Li", "George Holland", "Peter Brooks", "Charlie Beattie", "Michael Newman", "Alex Davies", "Cody Jones", "Sergio Boixo", "Hartmut Neven", "Pushmeet Kohli", "Johannes Bausch"], "title": "A scalable and real-time neural decoder for topological quantum codes", "comment": null, "summary": "Fault-tolerant quantum computing will require error rates far below those achievable with physical qubits. Quantum error correction (QEC) bridges this gap, but depends on decoders being simultaneously fast, accurate, and scalable. This combination of requirements has not yet been met by a machine-learning decoder, nor by any decoder for promising resource-efficient codes such as the colour code. Here we introduce AlphaQubit 2, a neural-network decoder that achieves near-optimal logical error rates for both surface and colour codes at large scales under realistic noise. For the colour code, it is orders of magnitude faster than other high-accuracy decoders. For the surface code, we demonstrate real-time decoding faster than 1 microsecond per cycle up to distance 11 on current commercial accelerators with better accuracy than leading real-time decoders. These results support the practical application of a wider class of promising QEC codes, and establish a credible path towards high-accuracy, real-time neural decoding at the scales required for fault-tolerant quantum computation.", "AI": {"tldr": "AlphaQubit 2 \u662f\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u89e3\u7801\u5668\uff0c\u5728\u771f\u5b9e\u566a\u58f0\u4e0b\u5bf9\u8868\u9762\u7801\u548c\u989c\u8272\u7801\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u903b\u8f91\u9519\u8bef\u7387\uff0c\u901f\u5ea6\u6bd4\u5176\u4ed6\u9ad8\u7cbe\u5ea6\u89e3\u7801\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u652f\u6301\u5b9e\u65f6\u89e3\u7801\u3002", "motivation": "\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u9700\u8981\u8fdc\u4f4e\u4e8e\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u53ef\u5b9e\u73b0\u7684\u9519\u8bef\u7387\uff0c\u91cf\u5b50\u7ea0\u9519\uff08QEC\uff09\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u5feb\u901f\u3001\u51c6\u786e\u548c\u53ef\u6269\u5c55\u7684\u89e3\u7801\u5668\u8981\u6c42\uff0c\u4f46\u76ee\u524d\u673a\u5668\u5b66\u4e60\u89e3\u7801\u5668\u6216\u8d44\u6e90\u9ad8\u6548\u7f16\u7801\uff08\u5982\u989c\u8272\u7801\uff09\u7684\u89e3\u7801\u5668\u5c1a\u672a\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002", "method": "\u5f00\u53d1\u4e86AlphaQubit 2\u795e\u7ecf\u7f51\u7edc\u89e3\u7801\u5668\uff0c\u9488\u5bf9\u8868\u9762\u7801\u548c\u989c\u8272\u7801\u8fdb\u884c\u4f18\u5316\uff0c\u80fd\u591f\u5728\u5f53\u524d\u5546\u7528\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u89e3\u7801\u3002", "result": "\u5bf9\u989c\u8272\u7801\u6bd4\u5176\u4ed6\u9ad8\u7cbe\u5ea6\u89e3\u7801\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff1b\u5bf9\u8868\u9762\u7801\u5728\u8ddd\u79bb11\u65f6\u5b9e\u73b0\u6bcf\u5468\u671f\u5c0f\u4e8e1\u5fae\u79d2\u7684\u5b9e\u65f6\u89e3\u7801\uff0c\u51c6\u786e\u7387\u4f18\u4e8e\u9886\u5148\u7684\u5b9e\u65f6\u89e3\u7801\u5668\u3002", "conclusion": "AlphaQubit 2\u652f\u6301\u66f4\u591a\u6709\u524d\u666f\u7684QEC\u7801\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u4e3a\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u6240\u9700\u89c4\u6a21\u7684\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u795e\u7ecf\u89e3\u7801\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.06917", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06917", "abs": "https://arxiv.org/abs/2512.06917", "authors": ["Clifford F", "Devika Jay", "Abhishek Sarkar", "Satheesh K Perepu", "Santhosh G S", "Kaushik Dey", "Balaraman Ravindran"], "title": "Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis", "comment": "Accepted at 4th Deployable AI Workshop at AAAI 2026", "summary": "As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a \"radical term\" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful \"Why this, and not that?\" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u8f68\u8ff9\u7ea7\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408Q\u503c\u5dee\u5f02\u548c\"\u6fc0\u8fdb\u9879\"\u7684\u72b6\u6001\u91cd\u8981\u6027\u5ea6\u91cf\u6765\u6392\u540d\u8f68\u8ff9\uff0c\u8bc6\u522b\u6700\u4f18\u884c\u4e3a\u5e76\u63d0\u4f9b\u5bf9\u6bd4\u89e3\u91ca\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u5c40\u90e8\u5355\u6b65\u51b3\u7b56\uff0c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u957f\u671f\u884c\u4e3a\u7684\u89e3\u91ca\u3002\u4e3a\u786e\u4fddRL\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u900f\u660e\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u9700\u8981\u80fd\u591f\u89e3\u91ca\u8f68\u8ff9\u7ea7\u884c\u4e3a\u7684\u6846\u67b6\u3002", "method": "\u5f15\u5165\u65b0\u7684\u72b6\u6001\u91cd\u8981\u6027\u5ea6\u91cf\uff0c\u7ed3\u5408\u7ecf\u5178Q\u503c\u5dee\u5f02\u548c\u6355\u6349\u667a\u80fd\u4f53\u5230\u8fbe\u76ee\u6807\u4eb2\u548c\u529b\u7684\"\u6fc0\u8fdb\u9879\"\u3002\u901a\u8fc7\u805a\u5408\u8fd9\u4e9b\u5ea6\u91cf\u6765\u6392\u540d\u6574\u4e2a\u8f68\u8ff9\uff0c\u5e76\u4ece\u5173\u952e\u72b6\u6001\u751f\u6210\u53cd\u4e8b\u5b9e\u63a8\u6f14\u6765\u63d0\u4f9b\u5bf9\u6bd4\u89e3\u91ca\u3002", "result": "\u65b9\u6cd5\u6210\u529f\u4ece\u5f02\u6784\u667a\u80fd\u4f53\u7ecf\u9a8c\u4e2d\u8bc6\u522b\u51fa\u6700\u4f18\u8f68\u8ff9\uff0c\u8bc1\u660e\u667a\u80fd\u4f53\u9009\u62e9\u7684\u8def\u5f84\u660e\u663e\u4f18\u4e8e\u66ff\u4ee3\u65b9\u6848\u3002\u5728\u6807\u51c6OpenAI Gym\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u91cd\u8981\u6027\u5ea6\u91cf\u6bd4\u7ecf\u5178\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u8bc6\u522b\u6700\u4f18\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u4fe1\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ea7\u5206\u6790\u548c\"\u4e3a\u4ec0\u4e48\u662f\u8fd9\u4e2a\u800c\u4e0d\u662f\u90a3\u4e2a\"\u7684\u89e3\u91ca\uff0c\u589e\u5f3a\u4e86RL\u667a\u80fd\u4f53\u7684\u900f\u660e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.07748", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07748", "abs": "https://arxiv.org/abs/2512.07748", "authors": ["Alan Kahan", "Pablo Vi\u00f1as", "Torsten V. Zache", "Alejandro Bermudez"], "title": "Real-time collisions of fractional charges in a trapped-ion Jackiw-Rebbi field theory", "comment": "29 pages, 16 figures", "summary": "We propose and analyze a trapped-ion quantum simulator of the Jackiw-Rebbi model, a paradigmatic quantum field theory in (1+1) dimensions where solitonic excitations of a scalar field can bind fermionic zero modes leading to fractionally charged excitations. In our approach, the scalar field is a coarse-grained description of the planar zigzag ion displacements in the vicinity of a structural phase transition. The internal electronic states of the ions encode spins with interactions mediated by the transverse phonons and in-plane spin-phonon couplings with a zigzag pattern, which together correspond to a Yukawa-coupled Dirac field. Instead of assuming a fixed soliton background, we study the effect of back-reaction and quantum fluctuations on the coupled dynamics of the full fermion-boson system. We start by applying a Born-Oppenheimer approximation to obtain an effective Peierls-Nabarro potential for the topological kink, unveiling how the fermionic back-reaction can lead to localization of the kink. Beyond this limit, a truncated Wigner approximation combined with fermionic Gaussian states captures the quantum spreading and localization of a kink and kink-antikink scattering. Our results reveal how back-reaction and quantum fluctuations modify the stability and real-time evolution of fractionalized fermions, predicting experimentally accessible signatures in current trapped-ion architectures.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u57fa\u4e8e\u56da\u7981\u79bb\u5b50\u7684Jackiw-Rebbi\u6a21\u578b\u91cf\u5b50\u6a21\u62df\u5668\uff0c\u7814\u7a76\u6807\u91cf\u573a\u5b64\u5b50\u4e0e\u8d39\u7c73\u5b50\u96f6\u6a21\u8026\u5408\u7cfb\u7edf\u4e2d\u7684\u80cc\u53cd\u5e94\u548c\u91cf\u5b50\u6da8\u843d\u6548\u5e94\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u573a\u8bba\u4e2d\u5b64\u5b50\u6fc0\u53d1\u4e0e\u8d39\u7c73\u5b50\u96f6\u6a21\u8026\u5408\u7cfb\u7edf\u7684\u80cc\u53cd\u5e94\u548c\u91cf\u5b50\u6da8\u843d\u6548\u5e94\uff0c\u8fd9\u4e9b\u6548\u5e94\u5728\u4f20\u7edf\u7406\u8bba\u4e2d\u901a\u5e38\u88ab\u5ffd\u7565\uff0c\u4f46\u5728\u5b9e\u9645\u7269\u7406\u7cfb\u7edf\u4e2d\u53ef\u80fd\u663e\u8457\u5f71\u54cd\u5206\u6570\u5316\u6fc0\u53d1\u7684\u7a33\u5b9a\u6027\u548c\u52a8\u529b\u5b66\u3002", "method": "\u91c7\u7528\u56da\u7981\u79bb\u5b50\u91cf\u5b50\u6a21\u62df\u5668\u5b9e\u73b0Jackiw-Rebbi\u6a21\u578b\uff1a\u6807\u91cf\u573a\u7531\u79bb\u5b50\u4f4d\u79fb\u7684\u952f\u9f7f\u5f62\u7ed3\u6784\u63cf\u8ff0\uff0c\u8d39\u7c73\u5b50\u573a\u7531\u79bb\u5b50\u5185\u90e8\u7535\u5b50\u6001\u7f16\u7801\u3002\u4f7f\u7528Born-Oppenheimer\u8fd1\u4f3c\u83b7\u5f97\u6709\u6548Peierls-Nabarro\u52bf\uff0c\u7ed3\u5408\u622a\u65adWigner\u8fd1\u4f3c\u548c\u8d39\u7c73\u5b50\u9ad8\u65af\u6001\u65b9\u6cd5\u7814\u7a76\u91cf\u5b50\u52a8\u529b\u5b66\u3002", "result": "\u8d39\u7c73\u5b50\u80cc\u53cd\u5e94\u53ef\u5bfc\u81f4\u62d3\u6251\u626d\u7ed3\u7684\u5c40\u57df\u5316\uff0c\u91cf\u5b50\u6da8\u843d\u5f71\u54cd\u626d\u7ed3\u7684\u91cf\u5b50\u6269\u6563\u548c\u626d\u7ed3-\u53cd\u626d\u7ed3\u6563\u5c04\u3002\u9884\u6d4b\u4e86\u5728\u73b0\u6709\u56da\u7981\u79bb\u5b50\u67b6\u6784\u4e2d\u53ef\u89c2\u6d4b\u7684\u5b9e\u9a8c\u4fe1\u53f7\u3002", "conclusion": "\u80cc\u53cd\u5e94\u548c\u91cf\u5b50\u6da8\u843d\u663e\u8457\u6539\u53d8\u5206\u6570\u5316\u8d39\u7c73\u5b50\u7684\u7a33\u5b9a\u6027\u548c\u5b9e\u65f6\u6f14\u5316\uff0c\u56da\u7981\u79bb\u5b50\u5e73\u53f0\u4e3a\u7814\u7a76\u91cf\u5b50\u573a\u8bba\u4e2d\u8026\u5408\u7cfb\u7edf\u7684\u5b8c\u6574\u91cf\u5b50\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2512.06920", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06920", "abs": "https://arxiv.org/abs/2512.06920", "authors": ["Alexandr Plashchinsky"], "title": "Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models", "comment": null, "summary": "We introduce the Parent-Guided Semantic Reward Model (PGSRM), a lightweight reward framework for reinforcement learning (RL) of transformer language models. PGSRM replaces binary correctness signals, human preference data, and trained reward models with a simple signal: cosine similarity between a parent model's reference output embedding and a child model's generated output for the same input. This yields a dense, semantically meaningful reward with no human annotation or additional model training. We apply PGSRM on five language tasks and find that it produces smoother reward improvement and more stable PPO dynamics than a binary reward baseline, suggesting that embedding-based semantic rewards are a practical alternative to RLHF-style reward modeling for parent-guided alignment in smaller transformer models.", "AI": {"tldr": "PGSRM\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u6846\u67b6\uff0c\u4f7f\u7528\u7236\u6a21\u578b\u53c2\u8003\u8f93\u51fa\u5d4c\u5165\u4e0e\u5b50\u6a21\u578b\u751f\u6210\u8f93\u51fa\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u8bed\u4e49\u5956\u52b1\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u989d\u5916\u8bad\u7ec3", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u4e8c\u5143\u6b63\u786e\u6027\u4fe1\u53f7\u3001\u4eba\u7c7b\u504f\u597d\u6570\u636e\u6216\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u590d\u6742\u3002PGSRM\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u7b80\u5355\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u907f\u514d\u8fd9\u4e9b\u9650\u5236", "method": "\u4f7f\u7528\u7236\u6a21\u578b\u7684\u53c2\u8003\u8f93\u51fa\u5d4c\u5165\u4e0e\u5b50\u6a21\u578b\u751f\u6210\u8f93\u51fa\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5f62\u6210\u5bc6\u96c6\u7684\u8bed\u4e49\u5956\u52b1\u3002\u5728\u4e94\u4e2a\u8bed\u8a00\u4efb\u52a1\u4e0a\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4e8c\u5143\u5956\u52b1\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83", "result": "PGSRM\u76f8\u6bd4\u4e8c\u5143\u5956\u52b1\u57fa\u7ebf\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u5956\u52b1\u6539\u8fdb\u548c\u66f4\u7a33\u5b9a\u7684PPO\u52a8\u6001\uff0c\u8868\u660e\u57fa\u4e8e\u5d4c\u5165\u7684\u8bed\u4e49\u5956\u52b1\u662fRLHF\u98ce\u683c\u5956\u52b1\u5efa\u6a21\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848", "conclusion": "\u5d4c\u5165\u8bed\u4e49\u5956\u52b1\u4e3a\u5c0f\u578btransformer\u6a21\u578b\u7684\u7236\u5f15\u5bfc\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u989d\u5916\u6a21\u578b\u8bad\u7ec3\uff0c\u7b80\u5316\u4e86\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b"}}
{"id": "2512.07754", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.07754", "abs": "https://arxiv.org/abs/2512.07754", "authors": ["Th. K. Mavrogordatos"], "title": "Statistical properties of quantum jumps between macroscopic states of light: reading an operational coherence record", "comment": "11 pages, 4 figures, Letter format", "summary": "We propose an experimental apparatus to reveal the quantum coherence manifested in downward quantum jumps of amplitude bistability. The underlying coherent superposition of macroscopic quantum states is translated into the statistical properties of the integrated charge deposited in the detector circuit of a mode-matched heterodyne/homodyne detection scheme. At first, the dynamical evolution of a signal transmitted from an auxiliary cavity is employed to pinpoint a macroscopic switching event in a bistable main cavity subject to direct photodetection. Once the decision is made on the occurrence of a downward switch, the main cavity mode is let to freely decay to the vacuum, monitored to the production of an integrated charge. In the long-time limit, the charge distribution over an identical collection of pure states generated during the jumps converges to the Q function (heterodyne detection) or marginals of the Wigner function (homodyne detection) dictated by the phase of the local oscillator. When fluctuations over the ensemble step in, we connect the statistical properties of several switching events and the ensuing production of current records, to the cavity field correlations associated with the breakdown of photon blockade.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b9e\u9a8c\u88c5\u7f6e\uff0c\u901a\u8fc7\u632f\u5e45\u53cc\u7a33\u6001\u7684\u4e0b\u8dc3\u8fc1\u91cf\u5b50\u8df3\u8dc3\u63ed\u793a\u91cf\u5b50\u76f8\u5e72\u6027\uff0c\u5c06\u5b8f\u89c2\u91cf\u5b50\u6001\u7684\u76f8\u5e72\u53e0\u52a0\u8f6c\u5316\u4e3a\u63a2\u6d4b\u5668\u7535\u8def\u4e2d\u79ef\u5206\u7535\u8377\u7684\u7edf\u8ba1\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u632f\u5e45\u53cc\u7a33\u6001\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u76f8\u5e72\u73b0\u8c61\uff0c\u7279\u522b\u662f\u4e0b\u8dc3\u8fc1\u91cf\u5b50\u8df3\u8dc3\u4e2d\u5b8f\u89c2\u91cf\u5b50\u6001\u7684\u76f8\u5e72\u53e0\u52a0\u7279\u6027\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u68c0\u6d4b\u7edf\u8ba1\u7279\u6027\u6765\u63ed\u793a\u8fd9\u4e9b\u91cf\u5b50\u6548\u5e94\u3002", "method": "\u91c7\u7528\u6a21\u5f0f\u5339\u914d\u7684\u5916\u5dee/\u96f6\u5dee\u68c0\u6d4b\u65b9\u6848\uff0c\u9996\u5148\u5229\u7528\u8f85\u52a9\u8154\u4f20\u8f93\u4fe1\u53f7\u7684\u52a8\u6001\u6f14\u5316\u5b9a\u4f4d\u53cc\u7a33\u6001\u4e3b\u8154\u4e2d\u7684\u5b8f\u89c2\u5207\u6362\u4e8b\u4ef6\uff0c\u7136\u540e\u8ba9\u4e3b\u8154\u6a21\u5f0f\u81ea\u7531\u8870\u51cf\u5230\u771f\u7a7a\u6001\uff0c\u76d1\u6d4b\u4ea7\u751f\u7684\u79ef\u5206\u7535\u8377\u5206\u5e03\u3002", "result": "\u5728\u957f\u65f6\u95f4\u6781\u9650\u4e0b\uff0c\u8df3\u8dc3\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u7eaf\u6001\u96c6\u5408\u7684\u7535\u8377\u5206\u5e03\u6536\u655b\u4e8eQ\u51fd\u6570\uff08\u5916\u5dee\u68c0\u6d4b\uff09\u6216Wigner\u51fd\u6570\u7684\u8fb9\u7f18\u5206\u5e03\uff08\u96f6\u5dee\u68c0\u6d4b\uff09\uff0c\u7edf\u8ba1\u7279\u6027\u4e0e\u8154\u573a\u5173\u8054\u76f8\u5173\uff0c\u53cd\u6620\u4e86\u5149\u5b50\u963b\u585e\u7684\u7834\u574f\u3002", "conclusion": "\u8be5\u5b9e\u9a8c\u88c5\u7f6e\u80fd\u591f\u63ed\u793a\u632f\u5e45\u53cc\u7a33\u6001\u4e0b\u8dc3\u8fc1\u91cf\u5b50\u8df3\u8dc3\u4e2d\u7684\u91cf\u5b50\u76f8\u5e72\u6027\uff0c\u5c06\u5b8f\u89c2\u91cf\u5b50\u6001\u7684\u76f8\u5e72\u53e0\u52a0\u8f6c\u5316\u4e3a\u53ef\u89c2\u6d4b\u7684\u7535\u8377\u7edf\u8ba1\u7279\u6027\uff0c\u4e3a\u7814\u7a76\u5149\u5b50\u963b\u585e\u7834\u574f\u76f8\u5173\u7684\u8154\u573a\u5173\u8054\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2512.06925", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.06925", "abs": "https://arxiv.org/abs/2512.06925", "authors": ["Aseer Al Faisal"], "title": "Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features", "comment": null, "summary": "Phishing is a cybercrime in which individuals are deceived into revealing personal information, often resulting in financial loss. These attacks commonly occur through fraudulent messages, misleading advertisements, and compromised legitimate websites. This study proposes a Quantile Regression Deep Q-Network (QR-DQN) approach that integrates RoBERTa semantic embeddings with handcrafted lexical features to enhance phishing detection while accounting for uncertainties. Unlike traditional DQN methods that estimate single scalar Q-values, QR-DQN leverages quantile regression to model the distribution of returns, improving stability and generalization on unseen phishing data. A diverse dataset of 105,000 URLs was curated from PhishTank, OpenPhish, Cloudflare, and other sources, and the model was evaluated using an 80/20 train-test split. The QR-DQN framework achieved a test accuracy of 99.86%, precision of 99.75%, recall of 99.96%, and F1-score of 99.85%, demonstrating high effectiveness. Compared to standard DQN with lexical features, the hybrid QR-DQN with lexical and semantic features reduced the generalization gap from 1.66% to 0.04%, indicating significant improvement in robustness. Five-fold cross-validation confirmed model reliability, yielding a mean accuracy of 99.90% with a standard deviation of 0.04%. These results suggest that the proposed hybrid approach effectively identifies phishing threats, adapts to evolving attack strategies, and generalizes well to unseen data.", "AI": {"tldr": "\u63d0\u51faQR-DQN\u65b9\u6cd5\uff0c\u7ed3\u5408RoBERTa\u8bed\u4e49\u5d4c\u5165\u548c\u624b\u5de5\u7279\u5f81\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u56de\u5f52\u5efa\u6a21\u56de\u62a5\u5206\u5e03\uff0c\u5728105,000\u4e2aURL\u6570\u636e\u96c6\u4e0a\u5b9e\u73b099.86%\u7684\u9493\u9c7c\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u901a\u8fc7\u6b3a\u8bc8\u6d88\u606f\u3001\u8bef\u5bfc\u5e7f\u544a\u548c\u7f51\u7ad9\u52ab\u6301\u7a83\u53d6\u4e2a\u4eba\u4fe1\u606f\u9020\u6210\u7ecf\u6d4e\u635f\u5931\uff0c\u4f20\u7edfDQN\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u6807\u91cfQ\u503c\u4f30\u8ba1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7a33\u5b9a\u3001\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faQuantile Regression Deep Q-Network (QR-DQN)\u65b9\u6cd5\uff0c\u6574\u5408RoBERTa\u8bed\u4e49\u5d4c\u5165\u548c\u624b\u5de5\u8bcd\u6c47\u7279\u5f81\uff0c\u4f7f\u7528\u5206\u4f4d\u6570\u56de\u5f52\u5efa\u6a21\u56de\u62a5\u5206\u5e03\u800c\u975e\u5355\u4e00\u6807\u91cf\u503c\uff0c\u5728105,000\u4e2aURL\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6d4b\u8bd5\u3002", "result": "\u6d4b\u8bd5\u51c6\u786e\u738799.86%\uff0c\u7cbe\u786e\u738799.75%\uff0c\u53ec\u56de\u738799.96%\uff0cF1\u5206\u657099.85%\uff1b\u76f8\u6bd4\u4f20\u7edfDQN\uff0c\u6cdb\u5316\u5dee\u8ddd\u4ece1.66%\u964d\u81f30.04%\uff1b\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747\u51c6\u786e\u738799.90%\u00b10.04%\u3002", "conclusion": "\u6df7\u5408QR-DQN\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u9493\u9c7c\u5a01\u80c1\uff0c\u9002\u5e94\u653b\u51fb\u7b56\u7565\u6f14\u53d8\uff0c\u5bf9\u672a\u89c1\u6570\u636e\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.07788", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07788", "abs": "https://arxiv.org/abs/2512.07788", "authors": ["Xuxin Wang", "Jiahe Pan", "Tobias J. Kippenberg", "Shingo Kono"], "title": "Strongly driven cavity quantum electrodynamical-optomechanical hybrid system", "comment": null, "summary": "Hybrid quantum systems harness the distinct advantages of different physical platforms, yet their integration is not always trivial due to potential incompatibilities in operational principles. Here, we theoretically propose and demonstrate a scheme for generating non-Gaussian mechanical states using a strongly driven hybrid system that combines cavity quantum electrodynamics (QED) and cavity optomechanics. Our protocol prepares a non-Gaussian cavity state in the dispersive regime of cavity QED and subsequently transfers it to a mechanical oscillator using the optomechanical interaction enhanced by a coherent cavity drive. While non-Gaussian cavity state control in cavity QED is well established in the dispersive regime, its behavior under strong cavity drive, essential for cavity optomechanics, remains largely unexplored. To bridge this gap, we develop an efficient simulation framework to model cavity QED dynamics in the high-photon-number regime. We show that a strong cavity drive can coherently displace the cavity state with minimal perturbations, effectively decoupling it from the qubit. The resulting large coherent cavity field enhances the optomechanical coupling strength, enabling high-fidelity transfer of non-Gaussian cavity states to the mechanical mode. These results reveal new dynamical features of driven cavity QED and open a pathway toward realizing non-Gaussian mechanical quantum memories and sensors.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u6f14\u793a\u4e86\u4e00\u79cd\u5229\u7528\u5f3a\u9a71\u52a8\u6df7\u5408\u7cfb\u7edf\uff08\u8154QED+\u8154\u5149\u529b\u5b66\uff09\u751f\u6210\u975e\u9ad8\u65af\u673a\u68b0\u6001\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u8154QED\u5236\u5907\u975e\u9ad8\u65af\u8154\u6001\uff0c\u518d\u5229\u7528\u5149\u529b\u5b66\u76f8\u4e92\u4f5c\u7528\u5c06\u5176\u8f6c\u79fb\u5230\u673a\u68b0\u632f\u5b50\u3002", "motivation": "\u6df7\u5408\u91cf\u5b50\u7cfb\u7edf\u7ed3\u5408\u4e0d\u540c\u7269\u7406\u5e73\u53f0\u7684\u4f18\u52bf\uff0c\u4f46\u96c6\u6210\u9762\u4e34\u64cd\u4f5c\u539f\u7406\u4e0d\u517c\u5bb9\u7684\u6311\u6218\u3002\u8154QED\u4e2d\u975e\u9ad8\u65af\u8154\u6001\u63a7\u5236\u5df2\u6709\u57fa\u7840\uff0c\u4f46\u5728\u5f3a\u8154\u9a71\u52a8\u4e0b\u7684\u884c\u4e3a\uff08\u5bf9\u8154\u5149\u529b\u5b66\u81f3\u5173\u91cd\u8981\uff09\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5728\u8154QED\u7684\u8272\u6563\u533a\u5236\u5907\u975e\u9ad8\u65af\u8154\u6001\uff0c\u7136\u540e\u5229\u7528\u76f8\u5e72\u8154\u9a71\u52a8\u589e\u5f3a\u7684\u5149\u529b\u5b66\u76f8\u4e92\u4f5c\u7528\u5c06\u5176\u8f6c\u79fb\u5230\u673a\u68b0\u632f\u5b50\u3002\u5f00\u53d1\u4e86\u9ad8\u6548\u6a21\u62df\u6846\u67b6\u6765\u5efa\u6a21\u9ad8\u5149\u5b50\u6570\u533a\u57df\u7684\u8154QED\u52a8\u529b\u5b66\u3002", "result": "\u5f3a\u8154\u9a71\u52a8\u53ef\u4ee5\u76f8\u5e72\u5730\u4f4d\u79fb\u8154\u6001\u4e14\u6270\u52a8\u6700\u5c0f\uff0c\u6709\u6548\u5730\u4f7f\u5176\u4e0e\u91cf\u5b50\u6bd4\u7279\u89e3\u8026\u3002\u4ea7\u751f\u7684\u5927\u76f8\u5e72\u8154\u573a\u589e\u5f3a\u4e86\u5149\u529b\u5b66\u8026\u5408\u5f3a\u5ea6\uff0c\u5b9e\u73b0\u4e86\u975e\u9ad8\u65af\u8154\u6001\u5230\u673a\u68b0\u6a21\u5f0f\u7684\u9ad8\u4fdd\u771f\u5ea6\u8f6c\u79fb\u3002", "conclusion": "\u63ed\u793a\u4e86\u9a71\u52a8\u8154QED\u7684\u65b0\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4e3a\u5b9e\u73b0\u975e\u9ad8\u65af\u673a\u68b0\u91cf\u5b50\u5b58\u50a8\u5668\u548c\u4f20\u611f\u5668\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.06926", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06926", "abs": "https://arxiv.org/abs/2512.06926", "authors": ["Salma Albelali", "Moataz Ahmed"], "title": "Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise", "comment": null, "summary": "Deep learning (DL) models, a specialized class of multilayer neural networks, have become central to time-series forecasting in critical domains such as environmental monitoring and the Internet of Things (IoT). Among these, Bidirectional Long Short-Term Memory (BiLSTM) architectures are particularly effective in capturing complex temporal dependencies. However, the robustness and generalization of such models are highly sensitive to input data characteristics - an aspect that remains underexplored in existing literature. This study presents a systematic empirical analysis of two key data-centric factors: input sequence length and additive noise. To support this investigation, a modular and reproducible forecasting pipeline is developed, incorporating standardized preprocessing, sequence generation, model training, validation, and evaluation. Controlled experiments are conducted on three real-world datasets with varying sampling frequencies to assess BiLSTM performance under different input conditions. The results yield three key findings: (1) longer input sequences significantly increase the risk of overfitting and data leakage, particularly in data-constrained environments; (2) additive noise consistently degrades predictive accuracy across sampling frequencies; and (3) the simultaneous presence of both factors results in the most substantial decline in model stability. While datasets with higher observation frequencies exhibit greater robustness, they remain vulnerable when both input challenges are present. These findings highlight important limitations in current DL-based forecasting pipelines and underscore the need for data-aware design strategies. This work contributes to a deeper understanding of DL model behavior in dynamic time-series environments and provides practical insights for developing more reliable and generalizable forecasting systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86BiLSTM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u4e24\u4e2a\u5173\u952e\u6570\u636e\u56e0\u7d20\uff1a\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u548c\u52a0\u6027\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u957f\u5e8f\u5217\u589e\u52a0\u8fc7\u62df\u5408\u98ce\u9669\uff0c\u566a\u58f0\u964d\u4f4e\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e24\u8005\u540c\u65f6\u5b58\u5728\u65f6\u6a21\u578b\u7a33\u5b9a\u6027\u4e0b\u964d\u6700\u663e\u8457\u3002", "motivation": "\u5c3d\u7ba1\u53cc\u5411LSTM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u5bf9\u8f93\u5165\u6570\u636e\u7279\u5f81\u9ad8\u5ea6\u654f\u611f\uff0c\u800c\u73b0\u6709\u6587\u732e\u5bf9\u6b64\u7814\u7a76\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u548c\u52a0\u6027\u566a\u58f0\u8fd9\u4e24\u4e2a\u5173\u952e\u6570\u636e\u56e0\u7d20\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u590d\u73b0\u7684\u9884\u6d4b\u6d41\u7a0b\uff0c\u5305\u542b\u6807\u51c6\u5316\u9884\u5904\u7406\u3001\u5e8f\u5217\u751f\u6210\u3001\u6a21\u578b\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u8bc4\u4f30\u3002\u5728\u4e09\u4e2a\u5177\u6709\u4e0d\u540c\u91c7\u6837\u9891\u7387\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u63a7\u5236\u5b9e\u9a8c\uff0c\u8bc4\u4f30BiLSTM\u5728\u4e0d\u540c\u8f93\u5165\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a1) \u957f\u8f93\u5165\u5e8f\u5217\u663e\u8457\u589e\u52a0\u8fc7\u62df\u5408\u548c\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u5c24\u5176\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e2d\uff1b2) \u52a0\u6027\u566a\u58f0\u5728\u4e0d\u540c\u91c7\u6837\u9891\u7387\u4e0b\u90fd\u6301\u7eed\u964d\u4f4e\u9884\u6d4b\u7cbe\u5ea6\uff1b3) \u4e24\u4e2a\u56e0\u7d20\u540c\u65f6\u5b58\u5728\u65f6\u6a21\u578b\u7a33\u5b9a\u6027\u4e0b\u964d\u6700\u663e\u8457\u3002\u9ad8\u91c7\u6837\u9891\u7387\u6570\u636e\u96c6\u867d\u66f4\u9c81\u68d2\uff0c\u4f46\u5728\u4e24\u4e2a\u6311\u6218\u540c\u65f6\u5b58\u5728\u65f6\u4ecd\u5f88\u8106\u5f31\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9884\u6d4b\u6d41\u7a0b\u7684\u91cd\u8981\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u6570\u636e\u611f\u77e5\u7684\u8bbe\u8ba1\u7b56\u7565\u3002\u4e3a\u6df1\u5165\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u52a8\u6001\u65f6\u95f4\u5e8f\u5217\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u53ef\u6cdb\u5316\u7684\u9884\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.07808", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07808", "abs": "https://arxiv.org/abs/2512.07808", "authors": ["M. A. Farooq", "G. Di Guglielmo", "A. Rajagopala", "N. Tran", "V. A. Chhabria", "A. Arora"], "title": "LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout", "comment": null, "summary": "Qubit readout is a critical operation in quantum computing systems, which maps the analog response of qubits into discrete classical states. Deep neural networks (DNNs) have recently emerged as a promising solution to improve readout accuracy . Prior hardware implementations of DNN-based readout are resource-intensive and suffer from high inference latency, limiting their practical use in low-latency decoding and quantum error correction (QEC) loops. This paper proposes LUNA, a fast and efficient superconducting qubit readout accelerator that combines low-cost integrator-based preprocessing with Look-Up Table (LUT) based neural networks for classification. The architecture uses simple integrators for dimensionality reduction with minimal hardware overhead, and employs LogicNets (DNNs synthesized into LUT logic) to drastically reduce resource usage while enabling ultra-low-latency inference. We integrate this with a differential evolution based exploration and optimization framework to identify high-quality design points. Our results show up to a 10.95x reduction in area and 30% lower latency with little to no loss in fidelity compared to the state-of-the-art. LUNA enables scalable, low-footprint, and high-speed qubit readout, supporting the development of larger and more reliable quantum computing systems.", "AI": {"tldr": "LUNA\uff1a\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\uff0c\u7528\u4e8e\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u8bfb\u53d6\uff0c\u901a\u8fc7\u79ef\u5206\u5668\u9884\u5904\u7406\u548cLUT\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u91cf\u5b50\u6bd4\u7279\u72b6\u6001\u5206\u7c7b\u3002", "motivation": "\u91cf\u5b50\u6bd4\u7279\u8bfb\u53d6\u662f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5173\u952e\u64cd\u4f5c\uff0c\u9700\u8981\u5c06\u6a21\u62df\u54cd\u5e94\u6620\u5c04\u4e3a\u79bb\u6563\u7ecf\u5178\u72b6\u6001\u3002\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bfb\u53d6\u65b9\u6848\u786c\u4ef6\u5b9e\u73b0\u8d44\u6e90\u5bc6\u96c6\u3001\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u4f4e\u5ef6\u8fdf\u89e3\u7801\u548c\u91cf\u5b50\u7ea0\u9519\u5faa\u73af\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faLUNA\u67b6\u6784\uff1a1\uff09\u4f7f\u7528\u4f4e\u6210\u672c\u79ef\u5206\u5668\u8fdb\u884c\u9884\u5904\u7406\u548c\u7ef4\u5ea6\u7f29\u51cf\uff1b2\uff09\u91c7\u7528\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u795e\u7ecf\u7f51\u7edc\uff08LogicNets\uff09\u8fdb\u884c\u5206\u7c7b\uff1b3\uff09\u7ed3\u5408\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u8fdb\u884c\u8bbe\u8ba1\u548c\u4f18\u5316\u63a2\u7d22\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6848\uff0cLUNA\u5b9e\u73b0\u4e8610.95\u500d\u9762\u79ef\u7f29\u51cf\u548c30%\u5ef6\u8fdf\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u51e0\u4e4e\u65e0\u635f\u7684\u4fdd\u771f\u5ea6\u3002", "conclusion": "LUNA\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u4f4e\u8d44\u6e90\u5360\u7528\u3001\u9ad8\u901f\u7684\u91cf\u5b50\u6bd4\u7279\u8bfb\u53d6\uff0c\u652f\u6301\u6784\u5efa\u66f4\u5927\u89c4\u6a21\u3001\u66f4\u53ef\u9760\u7684\u91cf\u5b50\u8ba1\u7b97\u7cfb\u7edf\u3002"}}
{"id": "2512.06929", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06929", "abs": "https://arxiv.org/abs/2512.06929", "authors": ["MinCheol Jeon"], "title": "Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding", "comment": null, "summary": "Time series forecasting in real world environments faces significant challenges non stationarity, multi scale temporal patterns, and distributional shifts that degrade model stability and accuracy. This study propose AdaMamba, a unified forecasting architecture that integrates adaptive normalization, multi scale trend extraction, and contextual sequence modeling to address these challenges. AdaMamba begins with an Adaptive Normalization Block that removes non stationary components through multi scale convolutional trend extraction and channel wise recalibration, enabling consistent detrending and variance stabilization. The normalized sequence is then processed by a Context Encoder that combines patch wise embeddings, positional encoding, and a Mamba enhanced Transformer layer with a mixture of experts feed forward module, allowing efficient modeling of both long range dependencies and local temporal dynamics. A lightweight prediction head generates multi horizon forecasts, and a denormalization mechanism reconstructs outputs by reintegrating local trends to ensure robustness under varying temporal conditions. AdaMamba provides strong representational capacity with modular extensibility, supporting deterministic prediction and compatibility with probabilistic extensions. Its design effectively mitigates covariate shift and enhances predictive reliability across heterogeneous datasets. Experimental evaluations demonstrate that AdaMamba's combination of adaptive normalization and expert augmented contextual modeling yields consistent improvements in stability and accuracy over conventional Transformer based baselines.", "AI": {"tldr": "AdaMamba\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u3001\u591a\u5c3a\u5ea6\u8d8b\u52bf\u63d0\u53d6\u548c\u4e0a\u4e0b\u6587\u5e8f\u5217\u5efa\u6a21\u6765\u89e3\u51b3\u975e\u5e73\u7a33\u6027\u3001\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edfTransformer\u57fa\u7ebf\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9762\u4e34\u975e\u5e73\u7a33\u6027\u3001\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\u548c\u5206\u5e03\u504f\u79fb\u7b49\u6311\u6218\uff0c\u8fd9\u4e9b\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u52a8\u6001\u65f6\u5b58\u5728\u4e0d\u8db3\u3002", "method": "AdaMamba\u5305\u542b\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u5757\uff08\u901a\u8fc7\u591a\u5c3a\u5ea6\u5377\u79ef\u8d8b\u52bf\u63d0\u53d6\u548c\u901a\u9053\u7ea7\u91cd\u65b0\u6821\u51c6\u53bb\u9664\u975e\u5e73\u7a33\u6210\u5206\uff09\u3001\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\uff08\u7ed3\u5408\u8865\u4e01\u5d4c\u5165\u3001\u4f4d\u7f6e\u7f16\u7801\u548cMamba\u589e\u5f3a\u7684Transformer\u5c42\uff09\u4ee5\u53ca\u8f7b\u91cf\u7ea7\u9884\u6d4b\u5934\u3002\u4f7f\u7528\u53bb\u5f52\u4e00\u5316\u673a\u5236\u901a\u8fc7\u91cd\u65b0\u6574\u5408\u5c40\u90e8\u8d8b\u52bf\u6765\u91cd\u5efa\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cAdaMamba\u7684\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u548c\u4e13\u5bb6\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u5728\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u76f8\u6bd4\u4f20\u7edfTransformer\u57fa\u7ebf\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u534f\u53d8\u91cf\u504f\u79fb\u5e76\u589e\u5f3a\u4e86\u9884\u6d4b\u53ef\u9760\u6027\u3002", "conclusion": "AdaMamba\u901a\u8fc7\u96c6\u6210\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u3001\u591a\u5c3a\u5ea6\u8d8b\u52bf\u63d0\u53d6\u548c\u4e0a\u4e0b\u6587\u5e8f\u5217\u5efa\u6a21\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u5f3a\u5927\u8868\u793a\u80fd\u529b\u548c\u6a21\u5757\u5316\u53ef\u6269\u5c55\u6027\u7684\u7edf\u4e00\u9884\u6d4b\u67b6\u6784\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6311\u6218\u3002"}}
{"id": "2512.07815", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07815", "abs": "https://arxiv.org/abs/2512.07815", "authors": ["Alicia B. Magann", "Nathan E. Miller", "Robin Blume-Kohout", "Peter Maunz", "Kevin C. Young"], "title": "Fast-feedback protocols for calibration and drift control in quantum computers", "comment": null, "summary": "We introduce two classes of lightweight, adaptive calibration protocols for quantum computers that leverage fast feedback. The first enables shot-by-shot updates to device parameters using measurement outcomes from simple, indefinite-outcome quantum circuits. This low-latency approach supports rapid tuning of one or more parameters in real time to mitigate drift. The second protocol updates parameters after collecting measurements from definite-outcome circuits (e.g.~syndrome extraction circuits for quantum error correction), balancing efficiency with classical control overheads. We use numerical simulations to demonstrate that both methods can calibrate 1- and 2-qubit gates rapidly and accurately even in the presence of decoherence, state preparation and measurement (SPAM) errors, and parameter drift. We propose and demonstrate effective adaptive strategies for tuning the hyperparameters of both protocols. Finally, we demonstrate the feasibility of real-time in-situ calibration of qubits performing quantum error correction, using only syndrome data, via numerical simulations of syndrome extraction in the [[5,1,3]] code.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u5feb\u901f\u53cd\u9988\u7684\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u91cf\u5b50\u8ba1\u7b97\u673a\u6821\u51c6\u534f\u8bae\uff0c\u5206\u522b\u652f\u6301\u57fa\u4e8e\u4e0d\u786e\u5b9a\u7ed3\u679c\u7535\u8def\u7684\u5b9e\u65f6\u53c2\u6570\u66f4\u65b0\u548c\u57fa\u4e8e\u786e\u5b9a\u7ed3\u679c\u7535\u8def\u7684\u9ad8\u6548\u6821\u51c6\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u5728\u9000\u76f8\u5e72\u3001SPAM\u8bef\u5dee\u548c\u53c2\u6570\u6f02\u79fb\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u673a\u9700\u8981\u9891\u7e41\u6821\u51c6\u6765\u7ef4\u6301\u6027\u80fd\uff0c\u4f46\u4f20\u7edf\u6821\u51c6\u65b9\u6cd5\u8017\u65f6\u4e14\u65e0\u6cd5\u5b9e\u65f6\u5e94\u5bf9\u53c2\u6570\u6f02\u79fb\u3002\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u3001\u81ea\u9002\u5e94\u7684\u6821\u51c6\u534f\u8bae\uff0c\u80fd\u591f\u5229\u7528\u5feb\u901f\u53cd\u9988\u5728\u91cf\u5b50\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u8c03\u6574\u8bbe\u5907\u53c2\u6570\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u6821\u51c6\u534f\u8bae\uff1a1) \u57fa\u4e8e\u7b80\u5355\u4e0d\u786e\u5b9a\u7ed3\u679c\u91cf\u5b50\u7535\u8def\u7684\u6d4b\u91cf\u7ed3\u679c\u8fdb\u884c\u9010\u6b21\u53c2\u6570\u66f4\u65b0\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u8c03\u8c10\uff1b2) \u57fa\u4e8e\u786e\u5b9a\u7ed3\u679c\u7535\u8def\uff08\u5982\u91cf\u5b50\u7ea0\u9519\u7801\u7684\u6821\u9a8c\u5b50\u63d0\u53d6\u7535\u8def\uff09\u7684\u6d4b\u91cf\u7ed3\u679c\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u5e73\u8861\u6548\u7387\u4e0e\u7ecf\u5178\u63a7\u5236\u5f00\u9500\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u5305\u542b\u81ea\u9002\u5e94\u8d85\u53c2\u6570\u8c03\u4f18\u7b56\u7565\u3002", "result": "\u6570\u503c\u6a21\u62df\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u5728\u5b58\u5728\u9000\u76f8\u5e72\u3001\u72b6\u6001\u5236\u5907\u548c\u6d4b\u91cf\u8bef\u5dee\u4ee5\u53ca\u53c2\u6570\u6f02\u79fb\u7684\u60c5\u51b5\u4e0b\uff0c\u5feb\u901f\u51c6\u786e\u5730\u6821\u51c61-\u548c2-\u91cf\u5b50\u6bd4\u7279\u95e8\u3002\u7279\u522b\u5c55\u793a\u4e86\u4ec5\u4f7f\u7528\u6821\u9a8c\u5b50\u6570\u636e\u5bf9[[5,1,3]]\u7801\u8fdb\u884c\u5b9e\u65f6\u539f\u4f4d\u91cf\u5b50\u7ea0\u9519\u6821\u51c6\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u6821\u51c6\u534f\u8bae\u4e3a\u91cf\u5b50\u8ba1\u7b97\u673a\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7684\u6821\u51c6\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u65f6\u5e94\u5bf9\u53c2\u6570\u6f02\u79fb\uff0c\u7279\u522b\u9002\u7528\u4e8e\u91cf\u5b50\u7ea0\u9519\u7b49\u9700\u8981\u6301\u7eed\u7a33\u5b9a\u64cd\u4f5c\u7684\u5e94\u7528\u573a\u666f\uff0c\u4e3a\u5b9e\u73b0\u53ef\u9760\u7684\u91cf\u5b50\u8ba1\u7b97\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.06932", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06932", "abs": "https://arxiv.org/abs/2512.06932", "authors": ["Salma Albelali", "Moataz Ahmed"], "title": "Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies", "comment": null, "summary": "Deep learning models, particularly Long Short-Term Memory (LSTM) networks, are widely used in time series forecasting due to their ability to capture complex temporal dependencies. However, evaluation integrity is often compromised by data leakage, a methodological flaw in which input-output sequences are constructed before dataset partitioning, allowing future information to unintentionally influence training. This study investigates the impact of data leakage on performance, focusing on how validation design mediates leakage sensitivity. Three widely used validation techniques (2-way split, 3-way split, and 10-fold cross-validation) are evaluated under both leaky (pre-split sequence generation) and clean conditions, with the latter mitigating leakage risk by enforcing temporal separation during data splitting prior to sequence construction. The effect of leakage is assessed using RMSE Gain, which measures the relative increase in RMSE caused by leakage, computed as the percentage difference between leaky and clean setups. Empirical results show that 10-fold cross-validation exhibits RMSE Gain values of up to 20.5% at extended lag steps. In contrast, 2-way and 3-way splits demonstrate greater robustness, typically maintaining RMSE Gain below 5% across diverse configurations. Moreover, input window size and lag step significantly influence leakage sensitivity: smaller windows and longer lags increase the risk of leakage, whereas larger windows help reduce it. These findings underscore the need for configuration-aware, leakage-resistant evaluation pipelines to ensure reliable performance estimation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u6570\u636e\u6cc4\u9732\u5bf9LSTM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9a8c\u8bc1\u8bbe\u8ba1\uff08\u7279\u522b\u662f10\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff09\u5bf9\u6cc4\u9732\u654f\u611f\uff0c\u800c2\u8def\u548c3\u8def\u5206\u5272\u66f4\u7a33\u5065\uff0c\u8f93\u5165\u7a97\u53e3\u5927\u5c0f\u548c\u6ede\u540e\u6b65\u957f\u663e\u8457\u5f71\u54cd\u6cc4\u9732\u654f\u611f\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662fLSTM\uff09\u5e38\u56e0\u6570\u636e\u6cc4\u9732\u800c\u8bc4\u4f30\u5931\u771f\u3002\u6570\u636e\u6cc4\u9732\u53d1\u751f\u5728\u6570\u636e\u96c6\u5212\u5206\u524d\u6784\u5efa\u8f93\u5165\u8f93\u51fa\u5e8f\u5217\u65f6\uff0c\u5bfc\u81f4\u672a\u6765\u4fe1\u606f\u65e0\u610f\u4e2d\u5f71\u54cd\u8bad\u7ec3\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u6570\u636e\u6cc4\u9732\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u9a8c\u8bc1\u8bbe\u8ba1\u5982\u4f55\u8c03\u8282\u6cc4\u9732\u654f\u611f\u6027\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u5e38\u7528\u9a8c\u8bc1\u6280\u672f\uff082\u8def\u5206\u5272\u30013\u8def\u5206\u5272\u548c10\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff09\u5728\u6cc4\u9732\uff08\u5206\u5272\u524d\u5e8f\u5217\u751f\u6210\uff09\u548c\u5e72\u51c0\uff08\u5206\u5272\u540e\u5e8f\u5217\u751f\u6210\uff09\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002\u4f7f\u7528RMSE\u589e\u76ca\u8861\u91cf\u6cc4\u9732\u5f71\u54cd\uff0c\u8ba1\u7b97\u6cc4\u9732\u4e0e\u5e72\u51c0\u8bbe\u7f6e\u4e4b\u95f4\u7684\u76f8\u5bf9RMSE\u589e\u52a0\u767e\u5206\u6bd4\u3002\u5206\u6790\u4e86\u8f93\u5165\u7a97\u53e3\u5927\u5c0f\u548c\u6ede\u540e\u6b65\u957f\u5bf9\u6cc4\u9732\u654f\u611f\u6027\u7684\u5f71\u54cd\u3002", "result": "10\u6298\u4ea4\u53c9\u9a8c\u8bc1\u5728\u8f83\u957f\u6ede\u540e\u6b65\u957f\u4e0b\u8868\u73b0\u51fa\u9ad8\u8fbe20.5%\u7684RMSE\u589e\u76ca\uff0c\u800c2\u8def\u548c3\u8def\u5206\u5272\u901a\u5e38\u4fdd\u6301RMSE\u589e\u76ca\u4f4e\u4e8e5%\u3002\u8f83\u5c0f\u7684\u8f93\u5165\u7a97\u53e3\u548c\u8f83\u957f\u7684\u6ede\u540e\u6b65\u957f\u4f1a\u589e\u52a0\u6cc4\u9732\u98ce\u9669\uff0c\u800c\u8f83\u5927\u7684\u7a97\u53e3\u6709\u52a9\u4e8e\u51cf\u5c11\u6cc4\u9732\u3002", "conclusion": "\u9a8c\u8bc1\u8bbe\u8ba1\u5bf9\u6570\u636e\u6cc4\u9732\u654f\u611f\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c10\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7279\u522b\u5bb9\u6613\u53d7\u5230\u6cc4\u9732\u5f71\u54cd\u3002\u9700\u8981\u914d\u7f6e\u611f\u77e5\u3001\u6297\u6cc4\u9732\u7684\u8bc4\u4f30\u6d41\u7a0b\u6765\u786e\u4fdd\u53ef\u9760\u7684\u6027\u80fd\u4f30\u8ba1\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u8f83\u5c0f\u7a97\u53e3\u548c\u8f83\u957f\u6ede\u540e\u6b65\u957f\u65f6\u3002"}}
{"id": "2512.07822", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07822", "abs": "https://arxiv.org/abs/2512.07822", "authors": ["Arindam Mitra", "Jatin Ghai"], "title": "Comparing quantum channels using Hermitian-preserving trace-preserving linear maps: A physically meaningful approach", "comment": "10 pages, 1 figure", "summary": "In quantum technologies, quantum channels are essential elements for the transmission of quantum states. The action of a quantum channel usually introduces noise in the quantum state and thereby reduces the information contained in it. Concatenating a quantum channel with another quantum channel makes it more noisy and degrades its information and resource preservability. These are mathematically described by completely positive trace-preserving linear maps that represent the generic evolution of quantum systems. These are special cases of Hermitian-preserving trace-preserving linear maps. In this work, we demonstrate a physically meaningful way to compare a pair of quantum channels using Hermitian-preserving trace-preserving linear maps. More precisely, given a pair of quantum channels and an arbitrary unknown input state, we show that if the output state of one quantum channel from the pair can be obtained from the output statistics of the other channel from the pair using some quantum measurement, then the latter channel from the pair can be obtained from the former channel by concatenating it with a Hermitian-preserving trace-preserving linear map. This relation between these two channels is a preorder, and we try to study its characterization in this work. We also illustrate the implications of our results for the incompatibility of quantum devices through an example.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHermitian\u4fdd\u6301\u8ff9\u4fdd\u6301\u7ebf\u6027\u6620\u5c04\u7684\u91cf\u5b50\u901a\u9053\u6bd4\u8f83\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u91cf\u5b50\u901a\u9053\u95f4\u7684\u9884\u5e8f\u5173\u7cfb\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5bf9\u91cf\u5b50\u8bbe\u5907\u4e0d\u517c\u5bb9\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u91cf\u5b50\u901a\u9053\u5728\u4f20\u8f93\u91cf\u5b50\u6001\u65f6\u901a\u5e38\u4f1a\u5f15\u5165\u566a\u58f0\uff0c\u964d\u4f4e\u4fe1\u606f\u542b\u91cf\u3002\u9700\u8981\u4e00\u79cd\u7269\u7406\u4e0a\u6709\u610f\u4e49\u7684\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u91cf\u5b50\u901a\u9053\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5f53\u4e24\u4e2a\u901a\u9053\u7684\u8f93\u51fa\u72b6\u6001\u53ef\u4ee5\u901a\u8fc7\u91cf\u5b50\u6d4b\u91cf\u76f8\u4e92\u8f6c\u6362\u65f6\u3002", "method": "\u4f7f\u7528Hermitian\u4fdd\u6301\u8ff9\u4fdd\u6301\u7ebf\u6027\u6620\u5c04\u6765\u6bd4\u8f83\u91cf\u5b50\u901a\u9053\u5bf9\u3002\u8bc1\u660e\u5982\u679c\u4e00\u5bf9\u91cf\u5b50\u901a\u9053\u4e2d\uff0c\u4e00\u4e2a\u901a\u9053\u7684\u8f93\u51fa\u72b6\u6001\u53ef\u4ee5\u901a\u8fc7\u91cf\u5b50\u6d4b\u91cf\u4ece\u53e6\u4e00\u4e2a\u901a\u9053\u7684\u8f93\u51fa\u7edf\u8ba1\u4e2d\u83b7\u5f97\uff0c\u90a3\u4e48\u540e\u8005\u53ef\u4ee5\u901a\u8fc7\u524d\u8005\u4e0e\u4e00\u4e2aHermitian\u4fdd\u6301\u8ff9\u4fdd\u6301\u7ebf\u6027\u6620\u5c04\u7684\u4e32\u8054\u5f97\u5230\u3002", "result": "\u5efa\u7acb\u4e86\u91cf\u5b50\u901a\u9053\u95f4\u7684\u9884\u5e8f\u5173\u7cfb\uff0c\u8fd9\u79cd\u5173\u7cfb\u53ef\u4ee5\u901a\u8fc7Hermitian\u4fdd\u6301\u8ff9\u4fdd\u6301\u7ebf\u6027\u6620\u5c04\u6765\u63cf\u8ff0\u3002\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u4e86\u8be5\u7ed3\u679c\u5bf9\u91cf\u5b50\u8bbe\u5907\u4e0d\u517c\u5bb9\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHermitian\u4fdd\u6301\u8ff9\u4fdd\u6301\u6620\u5c04\u7684\u91cf\u5b50\u901a\u9053\u6bd4\u8f83\u6846\u67b6\uff0c\u4e3a\u91cf\u5b50\u901a\u9053\u7684\u6027\u80fd\u8bc4\u4f30\u548c\u91cf\u5b50\u8bbe\u5907\u4e0d\u517c\u5bb9\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u5de5\u5177\u3002"}}
{"id": "2512.06944", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.06944", "abs": "https://arxiv.org/abs/2512.06944", "authors": ["Munshi Mahbubur Rahman", "Shimei Pan", "James R. Foulds"], "title": "A Unifying Human-Centered AI Fairness Framework", "comment": null, "summary": "The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, creating barriers to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual and group fairness, infra-marginal and intersectional assumptions, and outcome-based and equality-of-opportunity (EOO) perspectives. This structure allows stakeholders to align fairness interventions with their values and contextual considerations. The framework uses a consistent and easy-to-understand formulation for all metrics to reduce the learning curve for non-experts. Rather than privileging a single fairness notion, the framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and facilitating multi-stakeholder compromises. We apply this approach to four real-world datasets: the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism, the German Credit dataset for credit risk assessment, and the MEPS dataset for healthcare utilization. We show that adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through case studies in judicial decision-making and healthcare, we demonstrate how the framework can inform practical and value-sensitive deployment of fair AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u4eba\u7c7b\u4e2d\u5fc3\u516c\u5e73\u6027\u6846\u67b6\uff0c\u7cfb\u7edf\u8986\u76d6\u516b\u79cd\u516c\u5e73\u6027\u6307\u6807\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u6839\u636e\u4ef7\u503c\u89c2\u548c\u60c5\u5883\u8003\u8651\u8c03\u6574\u516c\u5e73\u6027\u5e72\u9884\uff0c\u5e76\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u6743\u91cd\u8c03\u6574\u5982\u4f55\u63ed\u793a\u4e0d\u540c\u516c\u5e73\u6027\u6307\u6807\u95f4\u7684\u6743\u8861\u3002", "motivation": "AI\u5728\u5173\u952e\u793e\u4f1a\u9886\u57df\u5e94\u7528\u7684\u589e\u52a0\u52a0\u5267\u4e86\u5bf9\u516c\u5e73\u6027\u7684\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u5728\u79cd\u65cf\u3001\u6027\u522b\u548c\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u7b49\u654f\u611f\u5c5e\u6027\u4e0a\u7684\u4e0d\u5e73\u7b49\u5bf9\u5f85\u3002\u73b0\u6709\u7814\u7a76\u5728\u5e73\u8861\u4e0d\u540c\u516c\u5e73\u6027\u6982\u5ff5\u4e0e\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u963b\u788d\u4e86\u516c\u5e73AI\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u4eba\u7c7b\u4e2d\u5fc3\u516c\u5e73\u6027\u6846\u67b6\uff0c\u7cfb\u7edf\u8986\u76d6\u516b\u79cd\u516c\u5e73\u6027\u6307\u6807\uff08\u7ed3\u5408\u4e2a\u4f53\u4e0e\u7fa4\u4f53\u516c\u5e73\u3001\u8fb9\u9645\u5185\u4e0e\u4ea4\u53c9\u5047\u8bbe\u3001\u7ed3\u679c\u5bfc\u5411\u4e0e\u673a\u4f1a\u5747\u7b49\u89c6\u89d2\uff09\uff0c\u91c7\u7528\u4e00\u81f4\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u516c\u5f0f\uff0c\u5141\u8bb8\u5229\u76ca\u76f8\u5173\u8005\u4e3a\u591a\u4e2a\u516c\u5e73\u6027\u76ee\u6807\u5206\u914d\u6743\u91cd\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff08UCI Adult\u6536\u5165\u9884\u6d4b\u3001COMPAS\u72af\u7f6a\u518d\u72af\u3001\u5fb7\u56fd\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u3001MEPS\u533b\u7597\u4fdd\u5065\u5229\u7528\uff09\u4e0a\u5e94\u7528\u8be5\u6846\u67b6\uff0c\u5c55\u793a\u8c03\u6574\u6743\u91cd\u5982\u4f55\u63ed\u793a\u4e0d\u540c\u516c\u5e73\u6027\u6307\u6807\u95f4\u7684\u7ec6\u5fae\u6743\u8861\uff0c\u5e76\u901a\u8fc7\u53f8\u6cd5\u51b3\u7b56\u548c\u533b\u7597\u4fdd\u5065\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u6846\u67b6\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u80fd\u591f\u6839\u636e\u5177\u4f53\u60c5\u5883\u548c\u4ef7\u503c\u89c2\u8c03\u6574\u516c\u5e73\u6027\u5e72\u9884\uff0c\u4fc3\u8fdb\u591a\u5229\u76ca\u76f8\u5173\u8005\u59a5\u534f\uff0c\u652f\u6301\u516c\u5e73AI\u7cfb\u7edf\u7684\u5b9e\u9645\u548c\u4ef7\u503c\u654f\u611f\u90e8\u7f72\u3002"}}
{"id": "2512.06969", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06969", "abs": "https://arxiv.org/abs/2512.06969", "authors": ["Adrian Przybysz", "Miko\u0142aj Ko\u0142ek", "Franciszek Sobota", "Jarek Duda"], "title": "Comparing BFGS and OGR for Second-Order Optimization", "comment": null, "summary": "Estimating the Hessian matrix, especially for neural network training, is a challenging problem due to high dimensionality and cost. In this work, we compare the classical Sherman-Morrison update used in the popular BFGS method (Broy-den-Fletcher-Goldfarb-Shanno), which maintains a positive definite Hessian approximation under a convexity assumption, with a novel approach called Online Gradient Regression (OGR). OGR performs regression of gradients against positions using an exponential moving average to estimate second derivatives online, without requiring Hessian inversion. Unlike BFGS, OGR allows estimation of a general (not necessarily positive definite) Hessian and can thus handle non-convex structures. We evaluate both methods across standard test functions and demonstrate that OGR achieves faster convergence and improved loss, particularly in non-convex settings.", "AI": {"tldr": "\u6bd4\u8f83BFGS\u7684Sherman-Morrison\u66f4\u65b0\u4e0e\u65b0\u578b\u5728\u7ebf\u68af\u5ea6\u56de\u5f52(OGR)\u65b9\u6cd5\u5728Hessian\u77e9\u9635\u4f30\u8ba1\u4e0a\u7684\u8868\u73b0\uff0cOGR\u5728\u975e\u51f8\u4f18\u5316\u4e2d\u8868\u73b0\u66f4\u4f18", "motivation": "\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2dHessian\u77e9\u9635\u4f30\u8ba1\u9762\u4e34\u9ad8\u7ef4\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u7684\u6311\u6218\uff0c\u4f20\u7edfBFGS\u65b9\u6cd5\u57fa\u4e8e\u51f8\u6027\u5047\u8bbe\u4fdd\u6301\u6b63\u5b9aHessian\u8fd1\u4f3c\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u975e\u51f8\u7ed3\u6784", "method": "\u63d0\u51fa\u5728\u7ebf\u68af\u5ea6\u56de\u5f52(OGR)\u65b9\u6cd5\uff0c\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5bf9\u68af\u5ea6\u4e0e\u4f4d\u7f6e\u8fdb\u884c\u56de\u5f52\uff0c\u5728\u7ebf\u4f30\u8ba1\u4e8c\u9636\u5bfc\u6570\u800c\u65e0\u9700Hessian\u6c42\u9006\uff0c\u53ef\u5904\u7406\u975e\u6b63\u5b9aHessian", "result": "\u5728\u6807\u51c6\u6d4b\u8bd5\u51fd\u6570\u4e0a\u8bc4\u4f30\u4e24\u79cd\u65b9\u6cd5\uff0cOGR\u5728\u975e\u51f8\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u635f\u5931", "conclusion": "OGR\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edfBFGS\u5728\u975e\u51f8\u4f18\u5316\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u5904\u7406\u66f4\u4e00\u822c\u7684Hessian\u7ed3\u6784\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u66f4\u597d\u7684\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5"}}
{"id": "2512.06971", "categories": ["cs.LG", "cs.CR", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.06971", "abs": "https://arxiv.org/abs/2512.06971", "authors": ["Ben Jacobsen", "Kassem Fawaz"], "title": "Prediction with Expert Advice under Local Differential Privacy", "comment": "19 pages, 3 figures", "summary": "We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \\textit{central} DP algorithm by 1.5-3$\\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u4e13\u5bb6\u5efa\u8bae\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6539\u8fdb\u7b97\u6cd5RW-AdaBatch\u548cRW-Meta\uff0c\u5728\u771f\u5b9eCOVID-19\u533b\u9662\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u7ecf\u5178\u57fa\u7ebf\u548c\u6700\u5148\u8fdb\u7684\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u3002", "motivation": "\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\uff0c\u4f20\u7edf\u7684\u4e13\u5bb6\u5efa\u8bae\u9884\u6d4b\u7b97\u6cd5\u6027\u80fd\u53d7\u9650\u3002\u4f5c\u8005\u65e8\u5728\u8bbe\u8ba1\u65b0\u7684\u7b97\u6cd5\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff08\u5982COVID-19\u533b\u9662\u62a5\u544a\u6570\u636e\uff09\u65f6\u3002", "method": "1. \u9996\u5148\u8bc1\u660e\u7ecf\u5178\u7b97\u6cd5\u81ea\u7136\u6ee1\u8db3LDP\uff1b2. \u63d0\u51faRW-AdaBatch\u7b97\u6cd5\uff0c\u5229\u7528LDP\u8bf1\u5bfc\u7684\u6709\u9650\u5207\u6362\u884c\u4e3a\u5b9e\u73b0\u9690\u79c1\u653e\u5927\uff0c\u7c7b\u4f3c\u4e8e\u79bb\u7ebf\u5b66\u4e60\u4e2d\u7684\u6df7\u6d17\u6a21\u578b\uff1b3. \u63d0\u51faRW-Meta\u7b97\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u975e\u5e73\u51e1\u5b66\u4e60\u7b97\u6cd5\u4e13\u5bb6\u4e4b\u95f4\u8fdb\u884c\u79c1\u6709\u9009\u62e9\u7684\u65b9\u6cd5\uff0c\u4e14\u4e0d\u589e\u52a0\u989d\u5916\u9690\u79c1\u6210\u672c\uff1b4. \u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7406\u8bba\u8fdb\u884c\u5206\u6790\u3002", "result": "1. RW-AdaBatch\u5728\u66f4\u7b80\u5355\u7684\u6570\u636e\u4e0a\u9690\u79c1\u653e\u5927\u6548\u679c\u66f4\u5f3a\uff0c\u4e14\u51e0\u4e4e\u6ca1\u6709\u6548\u7528\u635f\u5931\uff1b2. RW-Meta\u80fd\u591f\u5904\u7406\u975e\u5e73\u51e1\u5b66\u4e60\u7b97\u6cd5\u4e13\u5bb6\uff0c\u800c\u5148\u524d\u5de5\u4f5c\u4ec5\u8003\u8651\u6570\u636e\u65e0\u5173\u4e13\u5bb6\uff1b3. \u63a8\u5bfc\u4e86\u4e0e\u4e13\u5bb6\u72ec\u7acb\u6027\u7a0b\u5ea6\u6210\u53cd\u6bd4\u7684\u9057\u61be\u754c\u9650\uff1b4. \u5728COVID-19\u533b\u9662\u6570\u636e\u4e0a\uff0cRW-Meta\u6bd4\u7ecf\u5178\u57fa\u7ebf\u548c\u6700\u5148\u8fdb\u7684\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u6027\u80fd\u63d0\u53471.5-3\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u4e13\u5bb6\u5efa\u8bae\u9884\u6d4b\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u63d0\u51fa\u7684RW-AdaBatch\u548cRW-Meta\u7b97\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u9884\u6d4b\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6570\u636e\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2512.06982", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.06982", "abs": "https://arxiv.org/abs/2512.06982", "authors": ["Yu Yu", "Qian Xie", "Nairen Cao", "Li Jin"], "title": "LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding", "comment": "NeurIPS 2025 Workshop on Bridging Language, Agent, and World Models for Reasoning and Planning", "summary": "Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u6e90\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u72b6\u6001\u7f16\u7801\u5668\u8bbe\u8ba1\uff0c\u76f8\u6bd4\u4f20\u7edfNAS\u548cGENIUS\u6846\u67b6\uff0c\u5728\u4ea4\u901a\u63a7\u5236\u4efb\u52a1\u4e2d\u80fd\u4ee5\u66f4\u5c11\u7684\u5019\u9009\u8bc4\u4f30\u53d1\u73b0\u6027\u80fd\u66f4\u9ad8\u7684\u67b6\u6784\u3002", "motivation": "\u591a\u6e90\u5f3a\u5316\u5b66\u4e60\uff08\u5305\u542b\u4f20\u611f\u5668\u6d4b\u91cf\u3001\u65f6\u5e8f\u4fe1\u53f7\u3001\u56fe\u50cf\u89c2\u6d4b\u548c\u6587\u672c\u6307\u4ee4\u7b49\u591a\u79cd\u4fe1\u606f\u6e90\uff09\u7684\u72b6\u6001\u7f16\u7801\u5668\u8bbe\u8ba1\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u4e14\u901a\u5e38\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\uff0c\u73b0\u6709NAS\u65b9\u6cd5\u5ffd\u7565\u4e86\u6a21\u5757\u4e2d\u95f4\u8f93\u51fa\u7684\u6709\u7528\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u591a\u6e90RL\u8bbe\u7f6e\u4e2d\u7684\u6837\u672c\u6548\u7387\u3002", "method": "\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u590d\u5408\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8eLLM\u7684NAS\u6d41\u7a0b\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\u548c\u4e2d\u95f4\u8f93\u51fa\u4fe1\u53f7\u6765\u6307\u5bfc\u9ad8\u6548\u641c\u7d22\u9ad8\u6027\u80fd\u590d\u5408\u72b6\u6001\u7f16\u7801\u5668\u3002", "result": "\u5728\u6df7\u5408\u81ea\u4e3b\u4ea4\u901a\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edfNAS\u57fa\u7ebf\u548c\u57fa\u4e8eLLM\u7684GENIUS\u6846\u67b6\u4ee5\u66f4\u5c11\u7684\u5019\u9009\u8bc4\u4f30\u53d1\u73b0\u4e86\u6027\u80fd\u66f4\u9ad8\u7684\u67b6\u6784\u3002", "conclusion": "\u63d0\u51fa\u7684LLM\u9a71\u52a8NAS\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u6e90RL\u4e2d\u7684\u72b6\u6001\u7f16\u7801\u5668\u8bbe\u8ba1\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\u548c\u4e2d\u95f4\u8f93\u51fa\u4fe1\u53f7\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u7684\u67b6\u6784\u641c\u7d22\u3002"}}
{"id": "2512.06987", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.06987", "abs": "https://arxiv.org/abs/2512.06987", "authors": ["Emily Jin", "Andrei Cristian Nica", "Mikhail Galkin", "Jarrid Rector-Brooks", "Kin Long Kelvin Lee", "Santiago Miret", "Frances H. Arnold", "Michael Bronstein", "Avishek Joey Bose", "Alexander Tong", "Cheng-Hao Liu"], "title": "OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction", "comment": null, "summary": "Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\\text{RMSD}_1<0.5$ \u00c5 and attains over 80\\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.", "AI": {"tldr": "OXtal\u662f\u4e00\u4e2a100M\u53c2\u6570\u7684\u5168\u539f\u5b50\u6269\u6563\u6a21\u578b\uff0c\u76f4\u63a5\u4ece2D\u5316\u5b66\u56fe\u9884\u6d4b3D\u5206\u5b50\u6676\u4f53\u7ed3\u6784\uff0c\u5728\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb", "motivation": "\u51c6\u786e\u9884\u6d4b\u5206\u5b50\u6676\u4f53\u7ed3\u6784\u662f\u8ba1\u7b97\u5316\u5b66\u4e2d\u957f\u671f\u5b58\u5728\u7684\u5f00\u653e\u6311\u6218\uff0c\u5bf9\u5236\u836f\u548c\u6709\u673a\u534a\u5bfc\u4f53\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u6676\u4f53\u5806\u79ef\u76f4\u63a5\u5f71\u54cd\u6709\u673a\u56fa\u4f53\u7684\u7269\u7406\u5316\u5b66\u6027\u8d28", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u6269\u6563\u6a21\u578b\u76f4\u63a5\u5b66\u4e60\u5206\u5b50\u5185\u6784\u8c61\u548c\u5468\u671f\u6027\u5806\u79ef\u7684\u6761\u4ef6\u8054\u5408\u5206\u5e03\uff1b\u653e\u5f03\u663e\u5f0f\u7b49\u53d8\u67b6\u6784\uff0c\u4f7f\u7528\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff1b\u63d0\u51fa\u65b0\u7684\u6676\u5316\u8bad\u7ec3\u65b9\u6848S^4\uff0c\u907f\u514d\u663e\u5f0f\u6676\u683c\u53c2\u6570\u5316", "result": "\u572860\u4e07\u5b9e\u9a8c\u9a8c\u8bc1\u6676\u4f53\u7ed3\u6784\u6570\u636e\u96c6\u4e0a\uff0cOXtal\u6bd4\u5148\u524d\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u63d0\u9ad8\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u6bd4\u4f20\u7edf\u91cf\u5b50\u5316\u5b66\u65b9\u6cd5\u4fbf\u5b9c\u6570\u4e2a\u6570\u91cf\u7ea7\uff1b\u6062\u590d\u5b9e\u9a8c\u7ed3\u6784\u7684RMSD<0.5\u00c5\uff0c\u8fbe\u523080%\u4ee5\u4e0a\u5806\u79ef\u76f8\u4f3c\u7387", "conclusion": "OXtal\u80fd\u591f\u6709\u6548\u5efa\u6a21\u5206\u5b50\u6676\u5316\u7684\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\u89c4\u5f8b\uff0c\u4e3a\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.06989", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06989", "abs": "https://arxiv.org/abs/2512.06989", "authors": ["Minshen Zhang", "Xiang Hu", "Jianguo Li", "Wei Wu", "Kewei Tu"], "title": "Flash Multi-Head Feed-Forward Network", "comment": "17 pages, 8 figures", "summary": "We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To address these challenges, we propose Flash Multi-Head FFN (FlashMHF), with two key innovations: an I/O-aware fused kernel computing outputs online in SRAM akin to FlashAttention, and a design using dynamically weighted parallel sub-networks to maintain a balanced ratio between intermediate and head dimensions. Validated on models from 128M to 1.3B parameters, FlashMHF consistently improves perplexity and downstream task accuracy over SwiGLU FFNs, while reducing peak memory usage by 3-5x and accelerating inference by up to 1.08x. Our work establishes the multi-head design as a superior architectural principle for FFNs, presenting FlashMHF as a powerful, efficient, and scalable alternative to FFNs in Transformers.", "AI": {"tldr": "FlashMHF\u63d0\u51fa\u7528\u591a\u5934FFN\u66ff\u4ee3\u4f20\u7edfFFN\uff0c\u901a\u8fc7\u878d\u5408\u5185\u6838\u548c\u52a8\u6001\u52a0\u6743\u5e76\u884c\u5b50\u7f51\u7edc\u8bbe\u8ba1\uff0c\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u548c\u52a0\u901f\u63a8\u7406\u3002", "motivation": "\u53d7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u542f\u53d1\uff0c\u63a2\u7d22\u7528\u591a\u5934FFN\u66ff\u4ee3\u4f20\u7edfFFN\u3002\u4f46\u76f4\u63a5\u5e94\u7528\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u5185\u5b58\u6d88\u8017\u968f\u5934\u6570\u7ebf\u6027\u589e\u957f\uff0c\u4ee5\u53ca\u6a21\u578b\u6269\u5c55\u65f6\u4e2d\u95f4\u7ef4\u5ea6\u4e0e\u5934\u7ef4\u5ea6\u6bd4\u4f8b\u5931\u8861\uff0c\u5f71\u54cd\u53ef\u6269\u5c55\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u63d0\u51faFlash Multi-Head FFN (FlashMHF)\uff1a1) \u7c7b\u4f3cFlashAttention\u7684I/O\u611f\u77e5\u878d\u5408\u5185\u6838\uff0c\u5728SRAM\u4e2d\u5728\u7ebf\u8ba1\u7b97\u8f93\u51fa\uff1b2) \u4f7f\u7528\u52a8\u6001\u52a0\u6743\u5e76\u884c\u5b50\u7f51\u7edc\u8bbe\u8ba1\uff0c\u4fdd\u6301\u4e2d\u95f4\u7ef4\u5ea6\u4e0e\u5934\u7ef4\u5ea6\u7684\u5e73\u8861\u6bd4\u4f8b\u3002", "result": "\u5728128M\u52301.3B\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0cFlashMHF\u76f8\u6bd4SwiGLU FFNs\u6301\u7eed\u6539\u8fdb\u56f0\u60d1\u5ea6\u548c\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u5cf0\u503c\u5185\u5b58\u4f7f\u75283-5\u500d\uff0c\u63a8\u7406\u52a0\u901f\u6700\u9ad8\u8fbe1.08\u500d\u3002", "conclusion": "\u591a\u5934\u8bbe\u8ba1\u662fFFN\u7684\u4f18\u8d8a\u67b6\u6784\u539f\u5219\uff0cFlashMHF\u4f5c\u4e3aTransformer\u4e2dFFN\u7684\u5f3a\u5927\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2512.06993", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06993", "abs": "https://arxiv.org/abs/2512.06993", "authors": ["Ali Ebrahimpour-Boroojeny"], "title": "Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation", "comment": null, "summary": "We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above.\n  Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\uff1aAMUN\u7528\u4e8e\u6837\u672c\u9057\u5fd8\uff0cTRW\u7528\u4e8e\u7c7b\u522b\u9057\u5fd8\uff0c\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002AMUN\u901a\u8fc7\u5bf9\u6297\u6837\u672c\u5fae\u8c03\u964d\u4f4e\u6a21\u578b\u5bf9\u9057\u5fd8\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\uff0cTRW\u901a\u8fc7\u4f30\u8ba1\u7c7b\u95f4\u76f8\u4f3c\u6027\u8c03\u6574\u76ee\u6807\u5206\u5e03\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\u5728\u5b9e\u73b0\u6a21\u578b\u5bf9\u7279\u5b9a\u6837\u672c\u6216\u7c7b\u522b\u7684\u9057\u5fd8\u65f6\u6548\u679c\u6709\u9650\uff0c\u65e0\u6cd5\u5b8c\u5168\u6a21\u62df\u4ece\u5934\u8bad\u7ec3\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9057\u5fd8\u65b9\u6cd5\u6765\u4fdd\u62a4\u9690\u79c1\u5e76\u6ee1\u8db3\u6cd5\u89c4\u8981\u6c42\u3002", "method": "1. AMUN\u65b9\u6cd5\uff1a\u901a\u8fc7\u751f\u6210\u5bf9\u6297\u6837\u672c\u6765\u5fae\u8c03\u6a21\u578b\uff0c\u964d\u4f4e\u5bf9\u9057\u5fd8\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u4fdd\u7559\u6837\u672c\u7684\u6027\u80fd\u30022. FastClip\u65b9\u6cd5\uff1a\u901a\u8fc7\u5c42\u8c31\u8303\u6570\u88c1\u526a\u63a7\u5236\u6a21\u578b\u5e73\u6ed1\u5ea6\u30023. TRW\u65b9\u6cd5\uff1a\u9488\u5bf9\u7c7b\u522b\u9057\u5fd8\uff0c\u4f30\u8ba1\u7c7b\u95f4\u76f8\u4f3c\u6027\uff0c\u8c03\u6574\u76ee\u6807\u5206\u5e03\u4ee5\u6a21\u62df\u4ece\u5934\u8bad\u7ec3\u6a21\u578b\u7684\u884c\u4e3a\u3002", "result": "AMUN\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709SOTA\u65b9\u6cd5\uff0c\u57fa\u4e8eMIA\u5f97\u5206\u8bc4\u4f30\u3002TRW\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u6a21\u578b\u5e73\u6ed1\u5ea6\u662f\u5f71\u54cdAMUN\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684AMUN\u548cTRW\u65b9\u6cd5\u4e3a\u673a\u5668\u5b66\u4e60\u7684\u6837\u672c\u9057\u5fd8\u548c\u7c7b\u522b\u9057\u5fd8\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u4fdd\u62a4\u9690\u79c1\u5e76\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002\u6a21\u578b\u5e73\u6ed1\u5ea6\u548c\u5bf9\u6297\u6837\u672c\u8fc1\u79fb\u6027\u662f\u5f71\u54cd\u9057\u5fd8\u6548\u679c\u7684\u91cd\u8981\u56e0\u7d20\u3002"}}
{"id": "2512.07010", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07010", "abs": "https://arxiv.org/abs/2512.07010", "authors": ["Kevin Lee", "Pablo Millan Arias"], "title": "Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation", "comment": "Work in progress, (12 pages manuscript, 6 figures, 6 tables, 3 pages references, 14 pages appendix)", "summary": "Layer-wise Relevance Propagation (LRP) provides principled attribution for neural networks through conservation properties and foundations in Deep Taylor Decomposition. However, existing implementations operate at the module level, requiring architecture-specific propagation rules and modifications. These limit the generality of target model and sustainability of implementations as architectures evolve. We introduce DynamicLRP, a model-agnostic LRP framework operating at the tensor operation level. By decomposing attribution to individual operations within computation graphs and introducing a novel mechanism for deferred activation resolution, named the Promise System, our approach achieves true architecture agnosticity while maintaining LRP's theoretical guarantees. This design operates independently of backpropagation machinery, enabling operation on arbitrary computation graphs without model modification and side-by-side execution with gradient backpropagation. Being based on computation graphs, this method is theoretically extensible to other deep learning libraries that support auto-differentiation. We demonstrate faithfulness matching or exceeding specialized implementations (1.77 vs 1.69 ABPC on VGG, equivalent performance on ViT, 93.70\\% and 95.06\\% top-1 attribution accuracy for explaining RoBERTa-large and Flan-T5-large answers on SQuADv2, respectively) while maintaining practical efficiency on models with hundreds of millions of parameters. We achieved 99.92\\% node coverage across 31,465 computation graph nodes from 15 diverse architectures, including state-space models (Mamba), audio transformers (Whisper), and multimodal systems (DePlot) without any model-specific code with rules for 47 fundamental operations implemented. Our operation-level decomposition and Promise System establish a sustainable, extensible foundation for LRP across evolving architectures.", "AI": {"tldr": "DynamicLRP\uff1a\u9996\u4e2a\u6a21\u578b\u65e0\u5173\u7684LRP\u6846\u67b6\uff0c\u901a\u8fc7\u5f20\u91cf\u64cd\u4f5c\u7ea7\u5206\u89e3\u548cPromise\u7cfb\u7edf\u5b9e\u73b0\u67b6\u6784\u65e0\u5173\u6027\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u5373\u53ef\u5e94\u7528\u4e8e\u4efb\u610f\u8ba1\u7b97\u56fe", "motivation": "\u73b0\u6709LRP\u5b9e\u73b0\u57fa\u4e8e\u6a21\u5757\u7ea7\u522b\uff0c\u9700\u8981\u67b6\u6784\u7279\u5b9a\u7684\u4f20\u64ad\u89c4\u5219\u548c\u4fee\u6539\uff0c\u9650\u5236\u4e86\u76ee\u6807\u6a21\u578b\u7684\u901a\u7528\u6027\u548c\u5b9e\u73b0\u7684\u53ef\u6301\u7eed\u6027\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u65ad\u6f14\u8fdb\u7684\u67b6\u6784", "method": "\u63d0\u51faDynamicLRP\u6846\u67b6\uff1a1\uff09\u5728\u8ba1\u7b97\u56fe\u5185\u5c06\u5f52\u56e0\u5206\u89e3\u5230\u5355\u4e2a\u5f20\u91cf\u64cd\u4f5c\u7ea7\u522b\uff1b2\uff09\u5f15\u5165Promise\u7cfb\u7edf\u5b9e\u73b0\u5ef6\u8fdf\u6fc0\u6d3b\u89e3\u6790\uff1b3\uff09\u72ec\u7acb\u4e8e\u53cd\u5411\u4f20\u64ad\u673a\u5236\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u5373\u53ef\u5728\u4efb\u610f\u8ba1\u7b97\u56fe\u4e0a\u8fd0\u884c", "result": "\u572831,465\u4e2a\u8ba1\u7b97\u56fe\u8282\u70b9\u4e0a\u5b9e\u73b099.92%\u7684\u8282\u70b9\u8986\u76d6\u7387\uff0c\u6db5\u76d615\u79cd\u4e0d\u540c\u67b6\u6784\uff08\u5305\u62ecMamba\u3001Whisper\u3001DePlot\u7b49\uff09\uff0c\u4ec5\u970047\u4e2a\u57fa\u7840\u64cd\u4f5c\u89c4\u5219\u3002\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4e13\u7528\u5b9e\u73b0\uff0c\u5728VGG\u4e0aABPC\u4e3a1.77 vs 1.69\uff0c\u5728SQuADv2\u4e0aRoBERTa-large\u548cFlan-T5-large\u7684top-1\u5f52\u56e0\u51c6\u786e\u7387\u5206\u522b\u4e3a93.70%\u548c95.06%", "conclusion": "DynamicLRP\u901a\u8fc7\u64cd\u4f5c\u7ea7\u5206\u89e3\u548cPromise\u7cfb\u7edf\u5efa\u7acb\u4e86\u53ef\u6301\u7eed\u3001\u53ef\u6269\u5c55\u7684LRP\u57fa\u7840\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u65ad\u6f14\u8fdb\u7684\u67b6\u6784\uff0c\u540c\u65f6\u4fdd\u6301LRP\u7684\u7406\u8bba\u4fdd\u8bc1"}}
{"id": "2512.07011", "categories": ["cs.LG", "cs.CL", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.07011", "abs": "https://arxiv.org/abs/2512.07011", "authors": ["Daniel Ohayon", "Itay Lamprecht", "Itay Hubara", "Israel Cohen", "Daniel Soudry", "Noam Elata"], "title": "Block Sparse Flash Attention", "comment": "10 pages, 5 figures. Code: https://github.com/Danielohayon/Block-Sparse-Flash-Attention", "summary": "Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention", "AI": {"tldr": "BSFA\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u957f\u4e0a\u4e0b\u6587\u6ce8\u610f\u529b\u52a0\u901f\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u7cbe\u786e\u7684\u67e5\u8be2-\u952e\u76f8\u4f3c\u5ea6\u9009\u62e9\u6700\u91cd\u8981\u7684\u503c\u5757\uff0c\u8df3\u8fc7\u7ea650%\u8ba1\u7b97\u548c\u5185\u5b58\u4f20\u8f93\uff0c\u5728\u4fdd\u630199%\u4ee5\u4e0a\u57fa\u7ebf\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b01.10-1.24\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u4f46\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u9020\u6210\u4e25\u91cd\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u8981\u9ad8\u6548\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u6765\u52a0\u901f\u63a8\u7406\u3002", "method": "BSFA\u901a\u8fc7\u8ba1\u7b97\u7cbe\u786e\u7684\u67e5\u8be2-\u952e\u76f8\u4f3c\u5ea6\uff0c\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u9009\u62e9top-k\u6700\u91cd\u8981\u7684\u503c\u5757\uff0c\u901a\u8fc7\u6bd4\u8f83\u6bcf\u5757\u6700\u5927\u5206\u6570\u4e0e\u6821\u51c6\u9608\u503c\u6765\u8df3\u8fc7\u7ea650%\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u4f20\u8f93\u3002\u53ea\u9700\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e00\u6b21\u6027\u9608\u503c\u6821\u51c6\u6765\u5b66\u4e60\u6bcf\u5c42\u6bcf\u5934\u7684\u6ce8\u610f\u529b\u5206\u6570\u5206\u5e03\u3002", "result": "\u5728Llama-3.1-8B\u4e0a\uff0cBSFA\u5728\u771f\u5b9e\u4e16\u754c\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u9ad81.10\u500d\u52a0\u901f\uff0c\u5728needle-in-a-haystack\u68c0\u7d22\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u9ad81.24\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u630199%\u4ee5\u4e0a\u57fa\u7ebf\u51c6\u786e\u7387\uff0c\u67d0\u4e9b\u914d\u7f6e\u751a\u81f3\u901a\u8fc7\u5173\u6ce8\u6700\u76f8\u5173\u5185\u5bb9\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u3002", "conclusion": "BSFA\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u53ef\u4f5c\u4e3aFlashAttention\u7684\u5373\u63d2\u5373\u7528\u66ff\u4ee3\uff0c\u663e\u8457\u52a0\u901f\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u8d85\u8d8a\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002"}}
{"id": "2512.07021", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07021", "abs": "https://arxiv.org/abs/2512.07021", "authors": ["Jose Geraldo Fernandes", "Luiz Facury de Souza", "Pedro Robles Dutenhefner", "Gisele L. Pappa", "Wagner Meira"], "title": "Transferring Clinical Knowledge into ECGs Representation", "comment": null, "summary": "Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \\emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u5c06\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u77e5\u8bc6\u8fc1\u79fb\u5230\u5355\u6a21\u6001ECG\u7f16\u7801\u5668\uff0c\u63d0\u5347ECG\u5206\u7c7b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728ECG\u5206\u7c7b\u4e2d\u51c6\u786e\u6027\u9ad8\uff0c\u4f46\u9ed1\u76d2\u7279\u6027\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u963b\u788d\u4e34\u5e8a\u91c7\u7528\u3002\u9700\u8981\u5efa\u7acb\u66f4\u53ef\u4fe1\u3001\u53ef\u89e3\u91ca\u7684ECG\u5206\u7c7b\u6a21\u578b", "method": "\u4e09\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a1\uff09\u81ea\u76d1\u7763\u8054\u5408\u5d4c\u5165\u9884\u8bad\u7ec3\uff0c\u521b\u5efa\u5bcc\u542b\u4e34\u5e8a\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684ECG\u8868\u793a\uff1b2\uff09\u4ec5\u9700ECG\u4fe1\u53f7\u8fdb\u884c\u63a8\u7406\uff1b3\uff09\u8bad\u7ec3\u6a21\u578b\u4eceECG\u5d4c\u5165\u9884\u6d4b\u76f8\u5173\u5b9e\u9a8c\u5ba4\u5f02\u5e38\uff0c\u4f5c\u4e3a\u95f4\u63a5\u89e3\u91ca\u673a\u5236", "result": "\u5728MIMIC-IV-ECG\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u591a\u6807\u7b7e\u8bca\u65ad\u5206\u7c7b\u4e2d\u4f18\u4e8e\u6807\u51c6\u4fe1\u53f7\u57fa\u7ebf\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u9700\u8981\u6240\u6709\u6570\u636e\u63a8\u7406\u7684\u5168\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u521b\u5efa\u66f4\u51c6\u786e\u3001\u53ef\u4fe1\u7684ECG\u5206\u7c7b\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u62bd\u8c61\u9884\u6d4b\u8f6c\u5316\u4e3a\u57fa\u4e8e\u751f\u7406\u5b66\u7684\u89e3\u91ca\uff0c\u4e3aAI\u5b89\u5168\u96c6\u6210\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84"}}
{"id": "2512.07040", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07040", "abs": "https://arxiv.org/abs/2512.07040", "authors": ["Sakib Mostafa", "Lei Xing", "Md. Tauhidul Islam"], "title": "Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis", "comment": null, "summary": "Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes > 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.", "AI": {"tldr": "Graph2Image\u5c06\u5927\u578b\u751f\u7269\u7f51\u7edc\u8f6c\u6362\u4e3a\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5229\u7528CNN\u8fdb\u884c\u9ad8\u6548\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u3001\u957f\u7a0b\u4f9d\u8d56\u548c\u591a\u6a21\u6001\u96c6\u6210\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u751f\u7269\u7f51\u7edc\u5bf9\u751f\u7269\u533b\u5b66\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff09\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6709\u9650\u3001\u957f\u7a0b\u4f9d\u8d56\u6355\u6349\u56f0\u96be\u3001\u591a\u6a21\u6001\u96c6\u6210\u6311\u6218\u3001\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "Graph2Image\u6846\u67b6\u5c06\u5927\u578b\u751f\u7269\u7f51\u7edc\u8f6c\u6362\u4e3a\u4e8c\u7ef4\u56fe\u50cf\u96c6\uff0c\u901a\u8fc7\u57282D\u7f51\u683c\u4e0a\u7a7a\u95f4\u6392\u5217\u4ee3\u8868\u6027\u7f51\u7edc\u8282\u70b9\uff0c\u5c06\u8282\u70b9\u89e3\u8026\u4e3a\u56fe\u50cf\uff0c\u4ece\u800c\u80fd\u591f\u5229\u7528\u5177\u6709\u5168\u5c40\u611f\u53d7\u91ce\u548c\u591a\u5c3a\u5ea6\u91d1\u5b57\u5854\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u751f\u7269\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\uff0cGraph2Image\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5c06\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u9ad8\u8fbe67.2%\uff0c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u53ef\u89c6\u5316\uff0c\u63ed\u793a\u4e86\u751f\u7269\u5b66\u4e0a\u4e00\u81f4\u7684\u89c4\u5f8b\uff0c\u5e76\u80fd\u5728\u4e2a\u4eba\u8ba1\u7b97\u673a\u4e0a\u5206\u6790\u8d85\u8fc710\u4ebf\u8282\u70b9\u7684\u8d85\u5927\u89c4\u6a21\u7f51\u7edc\u3002", "conclusion": "Graph2Image\u4e3a\u751f\u7269\u7f51\u7edc\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u652f\u6301\u591a\u6a21\u6001\u7684\u65b9\u6cd5\uff0c\u4e3a\u75be\u75c5\u8bca\u65ad\u548c\u590d\u6742\u751f\u7269\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002"}}
{"id": "2512.07064", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.07064", "abs": "https://arxiv.org/abs/2512.07064", "authors": ["Jiannan Yang", "Veronika Thost", "Tengfei Ma"], "title": "Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design", "comment": null, "summary": "Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6982\u7387\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u5206\u5b50\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u63a9\u7801\u7b56\u7565\uff0c\u53d1\u73b0\u5bf9\u4e8e\u5e38\u89c1\u8282\u70b9\u7ea7\u9884\u6d4b\u4efb\u52a1\uff0c\u590d\u6742\u63a9\u7801\u5206\u5e03\u76f8\u6bd4\u5747\u5300\u91c7\u6837\u5e76\u65e0\u4f18\u52bf\uff0c\u800c\u9884\u6d4b\u76ee\u6807\u548c\u7f16\u7801\u5668\u67b6\u6784\u7684\u534f\u540c\u66f4\u4e3a\u5173\u952e\u3002", "motivation": "\u5f53\u524d\u5206\u5b50\u8868\u793a\u5b66\u4e60\u4e2d\uff0c\u8bb8\u591a\u57fa\u4e8e\u63a9\u7801\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\u90fd\u662f\u542f\u53d1\u5f0f\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\uff0c\u96be\u4ee5\u786e\u5b9a\u54ea\u4e9b\u8bbe\u8ba1\u9009\u62e9\u771f\u6b63\u6709\u6548\u3002\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u900f\u660e\u6bd4\u8f83\u548c\u7406\u89e3\u63a9\u7801\u7b56\u7565\u3002", "method": "\u5c06\u9884\u8bad\u7ec3-\u5fae\u8c03\u6d41\u7a0b\u7edf\u4e00\u5230\u6982\u7387\u6846\u67b6\u4e2d\uff0c\u5728\u4e25\u683c\u63a7\u5236\u7684\u8bbe\u7f6e\u4e0b\u7cfb\u7edf\u7814\u7a76\u4e09\u4e2a\u6838\u5fc3\u8bbe\u8ba1\u7ef4\u5ea6\uff1a\u63a9\u7801\u5206\u5e03\u3001\u9884\u6d4b\u76ee\u6807\u548c\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5e76\u4f7f\u7528\u4fe1\u606f\u8bba\u6307\u6807\u8bc4\u4f30\u9884\u8bad\u7ec3\u4fe1\u53f7\u7684\u4fe1\u606f\u91cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u5bf9\u4e8e\u5e38\u89c1\u8282\u70b9\u7ea7\u9884\u6d4b\u4efb\u52a1\uff0c\u590d\u6742\u63a9\u7801\u5206\u5e03\u76f8\u6bd4\u5747\u5300\u91c7\u6837\u6ca1\u6709\u4e00\u81f4\u4f18\u52bf\uff1b2) \u9884\u6d4b\u76ee\u6807\u7684\u9009\u62e9\u53ca\u5176\u4e0e\u7f16\u7801\u5668\u67b6\u6784\u7684\u534f\u540c\u66f4\u4e3a\u5173\u952e\uff1b3) \u4f7f\u7528\u8bed\u4e49\u66f4\u4e30\u5bcc\u7684\u9884\u6d4b\u76ee\u6807\u80fd\u5e26\u6765\u663e\u8457\u4e0b\u6e38\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u4e0e\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u56feTransformer\u7f16\u7801\u5668\u7ed3\u5408\u65f6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5206\u5b50\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff1a\u5e94\u66f4\u5173\u6ce8\u9884\u6d4b\u76ee\u6807\u548c\u7f16\u7801\u5668\u67b6\u6784\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u800c\u975e\u8fc7\u5ea6\u4f18\u5316\u63a9\u7801\u5206\u5e03\u7b56\u7565\uff0c\u8fd9\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5206\u5b50\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2512.07079", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07079", "abs": "https://arxiv.org/abs/2512.07079", "authors": ["Anton Morgunov", "Victor S. Batista"], "title": "Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation", "comment": "11 pages + 7 pages of SI. RetroCast is available on GitHub, see https://github.com/ischemist/project-procrustes. SynthArena is publicly available, see https://syntharena.ischemist.com/", "summary": "Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between \"solvability\" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a \"complexity cliff\" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.", "AI": {"tldr": "RetroCast\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u5957\u4ef6\uff0c\u7528\u4e8e\u6807\u51c6\u5316\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\uff08CASP\uff09\u6a21\u578b\u7684\u8bc4\u4f30\uff0c\u63ed\u793a\u9ad8\"\u53ef\u89e3\u6027\"\u5206\u6570\u5e38\u63a9\u76d6\u5316\u5b66\u65e0\u6548\u6027\uff0c\u4e14\u641c\u7d22\u65b9\u6cd5\u5728\u91cd\u5efa\u957f\u7a0b\u5408\u6210\u8ba1\u5212\u65f6\u5b58\u5728\"\u590d\u6742\u6027\u60ac\u5d16\"\u3002", "motivation": "\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u7840\u8bbe\u65bd\uff0c\u73b0\u6709\u6307\u6807\u8fc7\u4e8e\u5173\u6ce8\u62d3\u6251\u5b8c\u6210\u5ea6\u800c\u5ffd\u89c6\u5316\u5b66\u6709\u6548\u6027\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u900f\u660e\u548c\u53ef\u91cd\u590d\u53d1\u5c55\u3002", "method": "\u5f00\u53d1RetroCast\u8bc4\u4f30\u5957\u4ef6\uff0c\u5305\u62ec\uff1a1\uff09\u7edf\u4e00\u6a21\u5f0f\u6807\u51c6\u5316\u5f02\u6784\u6a21\u578b\u8f93\u51fa\uff1b2\uff09\u53ef\u91cd\u590d\u57fa\u51c6\u6d4b\u8bd5\u6d41\u7a0b\uff08\u5206\u5c42\u62bd\u6837\u548c\u81ea\u4e3e\u7f6e\u4fe1\u533a\u95f4\uff09\uff1b3\uff09SynthArena\u4ea4\u4e92\u5f0f\u5e73\u53f0\u7528\u4e8e\u5b9a\u6027\u8def\u7ebf\u68c0\u67e5\uff1b4\uff09\u5728\u65b0\u6807\u51c6\u5316\u57fa\u51c6\u4e0a\u8bc4\u4f30\u9886\u5148\u7684\u641c\u7d22\u5f0f\u548c\u5e8f\u5217\u5f0f\u7b97\u6cd5\u3002", "result": "\u53d1\u73b0\"\u53ef\u89e3\u6027\"\uff08\u5e93\u5b58\u7ec8\u6b62\u7387\uff09\u4e0e\u8def\u7ebf\u8d28\u91cf\u5b58\u5728\u5206\u6b67\uff1a\u9ad8\u53ef\u89e3\u6027\u5206\u6570\u5e38\u63a9\u76d6\u5316\u5b66\u65e0\u6548\u6027\uff0c\u4e14\u4e0e\u5b9e\u9a8c\u771f\u5b9e\u60c5\u51b5\u518d\u73b0\u4e0d\u76f8\u5173\u3002\u8bc6\u522b\u51fa\"\u590d\u6742\u6027\u60ac\u5d16\"\u73b0\u8c61\uff1a\u641c\u7d22\u65b9\u6cd5\u5c3d\u7ba1\u53ef\u89e3\u6027\u9ad8\uff0c\u4f46\u5728\u91cd\u5efa\u957f\u7a0b\u5408\u6210\u8ba1\u5212\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u800c\u5e8f\u5217\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "RetroCast\u6846\u67b6\u4e3aCASP\u9886\u57df\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u57fa\u7840\u8bbe\u65bd\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u5b8c\u6574\u6846\u67b6\u3001\u57fa\u51c6\u5b9a\u4e49\u548c\u6807\u51c6\u5316\u6a21\u578b\u9884\u6d4b\u6570\u636e\u5e93\u4ee5\u652f\u6301\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2512.07082", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07082", "abs": "https://arxiv.org/abs/2512.07082", "authors": ["Yuan-Ting Zhong", "Ting Huang", "Xiaolin Xiao", "Yue-Jiao Gong"], "title": "TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization", "comment": "Accepted by AAAI 2026", "summary": "Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRACE\u65b9\u6cd5\uff0c\u4e00\u79cd\u53ef\u8fc1\u79fb\u7684\u6982\u5ff5\u6f02\u79fb\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u68c0\u6d4b\u6d41\u6570\u636e\u4e2d\u7684\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u6d41\u4f18\u5316\u5668\u4e2d\u5b9e\u73b0\u81ea\u9002\u5e94\u4f18\u5316\u3002", "motivation": "\u6d41\u6570\u636e\u9a71\u52a8\u4f18\u5316\u9762\u4e34\u672a\u77e5\u6982\u5ff5\u6f02\u79fb\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u56fa\u5b9a\u6f02\u79fb\u95f4\u9694\u548c\u5b8c\u5168\u73af\u5883\u53ef\u89c2\u6d4b\u6027\u7b49\u9650\u5236\u6027\u5047\u8bbe\uff0c\u96be\u4ee5\u9002\u5e94\u591a\u6837\u5316\u7684\u52a8\u6001\u73af\u5883\u3002", "method": "TRACE\u91c7\u7528\u539f\u5219\u6027\u6807\u8bb0\u5316\u7b56\u7565\u4ece\u6570\u636e\u6d41\u4e2d\u63d0\u53d6\u7edf\u8ba1\u7279\u5f81\uff0c\u5229\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5e8f\u5217\u5b66\u4e60\u5efa\u6a21\u6f02\u79fb\u6a21\u5f0f\uff0c\u5b9e\u73b0\u672a\u89c1\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u68c0\u6d4b\uff0c\u5c55\u793a\u5b66\u4e60\u6f02\u79fb\u6a21\u5f0f\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTRACE\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3001\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u68c0\u6d4b\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u5206\u5e03\u53d8\u5316\u3002", "conclusion": "TRACE\u4f5c\u4e3a\u4e00\u79cd\u53ef\u63d2\u62d4\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u5668\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u6d41\u6570\u636e\u4e2d\u7684\u672a\u77e5\u6982\u5ff5\u6f02\u79fb\uff0c\u63d0\u5347\u6d41\u6570\u636e\u9a71\u52a8\u4f18\u5316\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2512.07092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07092", "abs": "https://arxiv.org/abs/2512.07092", "authors": ["Zhixiang Wang"], "title": "The Geometry of Persona: Disentangling Personality from Reasoning in Large Language Models", "comment": "10 pages, 3 figures, 1 table. Code and dataset available at https://huggingface.co/Zx93/Soul-Engine-Qwen2.5-0.5B", "summary": "Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an \"alignment tax\" -- degrading general reasoning capabilities.\n  Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introduce SoulBench, a dataset constructed via dynamic contextual sampling. Using a dual-head architecture on a frozen Qwen-2.5 base, we extract disentangled personality vectors without modifying the backbone weights.\n  Results: Our experiments demonstrate three breakthroughs. First, High-Precision Profiling: The model achieves a Mean Squared Error (MSE) of 0.011 against psychological ground truth. Second, Geometric Orthogonality: T-SNE visualization confirms that personality manifolds are distinct and continuous, allowing for \"Zero-Shot Personality Injection\" that maintains original model intelligence. Third, Deterministic Steering: We achieve robust control over behavior via vector arithmetic, validated through extensive ablation studies.\n  Conclusion: This work challenges the necessity of fine-tuning for personalization. By transitioning from probabilistic prompting to deterministic latent intervention, we provide a mathematically rigorous foundation for safe, controllable AI personalization.", "AI": {"tldr": "\u63d0\u51faSoul Engine\u6846\u67b6\uff0c\u57fa\u4e8e\u7ebf\u6027\u8868\u793a\u5047\u8bbe\uff0c\u901a\u8fc7\u63d0\u53d6\u89e3\u8026\u7684\u4eba\u683c\u5411\u91cf\u5b9e\u73b0\u4e2a\u6027\u5316LLM\uff0c\u65e0\u9700\u5fae\u8c03\u4e3b\u5e72\u6743\u91cd\uff0c\u907f\u514d\u5bf9\u9f50\u7a0e\u3002", "motivation": "\u5f53\u524d\u4e2a\u6027\u5316LLM\u90e8\u7f72\u53d7\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u56f0\u5883\u7ea6\u675f\uff0c\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982SFT\uff09\u4f9d\u8d56\u968f\u673a\u6743\u91cd\u66f4\u65b0\uff0c\u5e38\u5bfc\u81f4\"\u5bf9\u9f50\u7a0e\"\u2014\u2014\u964d\u4f4e\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u7ebf\u6027\u8868\u793a\u5047\u8bbe\uff08\u4eba\u683c\u7279\u5f81\u5b58\u5728\u4e8e\u6b63\u4ea4\u7ebf\u6027\u5b50\u7a7a\u95f4\uff09\uff0c\u63d0\u51faSoul Engine\u6846\u67b6\uff0c\u4f7f\u7528SoulBench\u6570\u636e\u96c6\uff08\u52a8\u6001\u4e0a\u4e0b\u6587\u91c7\u6837\u6784\u5efa\uff09\uff0c\u5728\u51bb\u7ed3\u7684Qwen-2.5\u57fa\u7840\u4e0a\u91c7\u7528\u53cc\u5934\u67b6\u6784\u63d0\u53d6\u89e3\u8026\u4eba\u683c\u5411\u91cf\uff0c\u4e0d\u4fee\u6539\u4e3b\u5e72\u6743\u91cd\u3002", "result": "\u4e09\u4e2a\u7a81\u7834\uff1a1) \u9ad8\u7cbe\u5ea6\u753b\u50cf\uff1aMSE\u4e3a0.011\uff1b2) \u51e0\u4f55\u6b63\u4ea4\u6027\uff1aT-SNE\u53ef\u89c6\u5316\u786e\u8ba4\u4eba\u683c\u6d41\u5f62\u79bb\u6563\u8fde\u7eed\uff0c\u5b9e\u73b0\"\u96f6\u6837\u672c\u4eba\u683c\u6ce8\u5165\"\u4fdd\u6301\u539f\u59cb\u667a\u80fd\uff1b3) \u786e\u5b9a\u6027\u5f15\u5bfc\uff1a\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u5b9e\u73b0\u884c\u4e3a\u9c81\u68d2\u63a7\u5236\u3002", "conclusion": "\u6311\u6218\u4e86\u5fae\u8c03\u5bf9\u4e2a\u6027\u5316\u7684\u5fc5\u8981\u6027\uff0c\u4ece\u6982\u7387\u63d0\u793a\u8f6c\u5411\u786e\u5b9a\u6027\u6f5c\u5728\u5e72\u9884\uff0c\u4e3a\u5b89\u5168\u53ef\u63a7\u7684AI\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u6570\u5b66\u4e25\u8c28\u7684\u57fa\u7840\u3002"}}
{"id": "2512.07100", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07100", "abs": "https://arxiv.org/abs/2512.07100", "authors": ["Hong Wang", "Yinglong Zhang", "Hanhan Guo", "Xuewen Xia", "Xing Xu"], "title": "Dual Refinement Cycle Learning: Unsupervised Text Classification of Mamba and Community Detection on Text Attributed Graph", "comment": null, "summary": "Pretrained language models offer strong text understanding capabilities but remain difficult to deploy in real-world text-attributed networks due to their heavy dependence on labeled data. Meanwhile, community detection methods typically ignore textual semantics, limiting their usefulness in downstream applications such as content organization, recommendation, and risk monitoring. To overcome these limitations, we present Dual Refinement Cycle Learning (DRCL), a fully unsupervised framework designed for practical scenarios where no labels or category definitions are available.\n  DRCL integrates structural and semantic information through a warm-start initialization and a bidirectional refinement cycle between a GCN-based Community Detection Module (GCN-CDM) and a Text Semantic Modeling Module (TSMM). The two modules iteratively exchange pseudo-labels, allowing semantic cues to enhance structural clustering and structural patterns to guide text representation learning without manual supervision.\n  Across several text-attributed graph datasets, DRCL consistently improves the structural and semantic quality of discovered communities. Moreover, a Mamba-based classifier trained solely from DRCL's community signals achieves accuracy comparable to supervised models, demonstrating its potential for deployment in large-scale systems where labeled data are scarce or costly.", "AI": {"tldr": "DRCL\u662f\u4e00\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5411\u7cbe\u70bc\u5faa\u73af\u6574\u5408\u56fe\u7ed3\u6784\u548c\u6587\u672c\u8bed\u4e49\u4fe1\u606f\uff0c\u7528\u4e8e\u6587\u672c\u5c5e\u6027\u7f51\u7edc\u4e2d\u7684\u793e\u533a\u53d1\u73b0\uff0c\u65e0\u9700\u6807\u7b7e\u6216\u7c7b\u522b\u5b9a\u4e49\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96be\u4ee5\u90e8\u7f72\u5230\u771f\u5b9e\u6587\u672c\u5c5e\u6027\u7f51\u7edc\u4e2d\uff0c\u800c\u4f20\u7edf\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u7565\u6587\u672c\u8bed\u4e49\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u53cc\u7cbe\u70bc\u5faa\u73af\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542bGCN\u793e\u533a\u68c0\u6d4b\u6a21\u5757\u548c\u6587\u672c\u8bed\u4e49\u5efa\u6a21\u6a21\u5757\uff0c\u901a\u8fc7\u70ed\u542f\u52a8\u521d\u59cb\u5316\u548c\u53cc\u5411\u4f2a\u6807\u7b7e\u4ea4\u6362\uff0c\u5b9e\u73b0\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u76f8\u4e92\u589e\u5f3a\u3002", "result": "\u5728\u591a\u4e2a\u6587\u672c\u5c5e\u6027\u56fe\u6570\u636e\u96c6\u4e0a\uff0cDRCL\u6301\u7eed\u63d0\u5347\u53d1\u73b0\u793e\u533a\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u8d28\u91cf\uff1b\u57fa\u4e8eDRCL\u793e\u533a\u4fe1\u53f7\u8bad\u7ec3\u7684Mamba\u5206\u7c7b\u5668\u8fbe\u5230\u4e0e\u76d1\u7763\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "conclusion": "DRCL\u5c55\u793a\u4e86\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u6216\u6602\u8d35\u7684\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u5f0f\u6709\u6548\u6574\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07112", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07112", "abs": "https://arxiv.org/abs/2512.07112", "authors": ["Ziqing Wen", "Jiahuan Wang", "Ping Luo", "Dongsheng Li", "Tao Sun"], "title": "FOAM: Blocked State Folding for Memory-Efficient LLM Training", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\\%, eliminates up to 90\\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.", "AI": {"tldr": "FOAM\u662f\u4e00\u79cd\u5185\u5b58\u9ad8\u6548\u7684\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5757\u7ea7\u68af\u5ea6\u5747\u503c\u548c\u6b8b\u5dee\u6821\u6b63\u538b\u7f29\u4f18\u5316\u5668\u72b6\u6001\uff0c\u51cf\u5c1150%\u8bad\u7ec3\u5185\u5b58\uff0c\u6d88\u966490%\u4f18\u5316\u5668\u72b6\u6001\u5185\u5b58\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eAdam\u76f8\u5f53\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65f6\u9762\u4e34\u4e25\u91cd\u7684\u5185\u5b58\u74f6\u9888\uff0c\u7279\u522b\u662f\u4f7f\u7528Adam\u7b49\u5185\u5b58\u5bc6\u96c6\u578b\u4f18\u5316\u5668\u65f6\u3002\u73b0\u6709\u5185\u5b58\u9ad8\u6548\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u9700\u8981\u989d\u5916\u5185\u5b58\u6216\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faFOAM\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u8ba1\u7b97\u5757\u7ea7\u68af\u5ea6\u5747\u503c\u538b\u7f29\u4f18\u5316\u5668\u72b6\u6001\uff1b2) \u5f15\u5165\u6b8b\u5dee\u6821\u6b63\u6062\u590d\u4e22\u5931\u7684\u4fe1\u606f\uff1b3) \u4fdd\u6301\u4e0evanilla Adam\u7684\u7406\u8bba\u6536\u655b\u7b49\u4ef7\u6027\u3002", "result": "FOAM\u51cf\u5c11\u7ea650%\u603b\u8bad\u7ec3\u5185\u5b58\uff0c\u6d88\u9664\u9ad8\u8fbe90%\u7684\u4f18\u5316\u5668\u72b6\u6001\u5185\u5b58\u5f00\u9500\uff0c\u52a0\u901f\u6536\u655b\uff0c\u4e14\u4e0e\u5176\u4ed6\u5185\u5b58\u9ad8\u6548\u4f18\u5316\u5668\u517c\u5bb9\uff0c\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "FOAM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3LLM\u8bad\u7ec3\u5185\u5b58\u74f6\u9888\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.07113", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2512.07113", "abs": "https://arxiv.org/abs/2512.07113", "authors": ["Kepeng Lin", "Qizhe Zhang", "Rui Wang", "Xuehai Hu", "Wei Xu"], "title": "PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes", "comment": "6 pages, 5 figures, accept to BIBM", "summary": "Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of DNA strands respectively. To address these limitations, we propose PlantBiMoE, a lightweight and expressive plant genome language model that integrates bidirectional Mamba and a Sparse Mixture-of-Experts (SparseMoE) framework. The bidirectional Mamba enables the model to effectively capture structural dependencies across both the forward and reverse DNA strands, while SparseMoE significantly reduces the number of active parameters, improving computational efficiency without sacrificing modeling capacity. We evaluated and tested our model on the Modified Plants Genome Benchmark (MPGB), an enhanced genomic benchmark, which consolidates 31 datasets across 11 representative tasks, with input sequence lengths ranging from 50 to 6,000 bp. Experimental results demonstrate that PlantBiMoE achieves the best performance on 20 out of 31 datasets and the average best when comparing with existing models. In summary, all above results demonstrate that our model can effectively represent plant genomic sequences, serving as a robust computational tool for diverse genomic tasks, while making substantive contributions to plant genomics, gene editing, and synthetic biology. The code is available at: https://github.com/HUST-Keep-Lin/PlantBiMoE", "AI": {"tldr": "PlantBiMoE\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u690d\u7269\u57fa\u56e0\u7ec4\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u53cc\u5411Mamba\u548c\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff0c\u5728MPGB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u572831\u4e2a\u6570\u636e\u96c6\u768420\u4e2a\u4e0a\u53d6\u5f97\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u690d\u7269\u57fa\u56e0\u7ec4\u6a21\u578b\u5982AgroNT\u548cPDLLMs\u5b58\u5728\u53c2\u6570\u8fc7\u5927\u6216\u65e0\u6cd5\u6709\u6548\u5efa\u6a21DNA\u53cc\u94fe\u53cc\u5411\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u80fd\u6355\u6349DNA\u53cc\u5411\u7ed3\u6784\u4f9d\u8d56\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faPlantBiMoE\u6a21\u578b\uff0c\u6574\u5408\u53cc\u5411Mamba\u6765\u6355\u6349DNA\u6b63\u53cd\u94fe\u7684\u7ed3\u6784\u4f9d\u8d56\uff0c\u91c7\u7528\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u51cf\u5c11\u6d3b\u8dc3\u53c2\u6570\u6570\u91cf\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u800c\u4e0d\u727a\u7272\u5efa\u6a21\u80fd\u529b\u3002", "result": "\u5728MPGB\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u542b31\u4e2a\u6570\u636e\u96c6\u300111\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\uff09\u4e2d\uff0cPlantBiMoE\u572820\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u5e73\u5747\u6027\u80fd\u4e5f\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "PlantBiMoE\u80fd\u6709\u6548\u8868\u793a\u690d\u7269\u57fa\u56e0\u7ec4\u5e8f\u5217\uff0c\u4e3a\u690d\u7269\u57fa\u56e0\u7ec4\u5b66\u3001\u57fa\u56e0\u7f16\u8f91\u548c\u5408\u6210\u751f\u7269\u5b66\u63d0\u4f9b\u5f3a\u5927\u7684\u8ba1\u7b97\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.07142", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.07142", "abs": "https://arxiv.org/abs/2512.07142", "authors": ["Tanay Arora", "Christof Teuscher"], "title": "Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search", "comment": "This work plans to be submitted to the IEEE for possible publication", "summary": "The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.", "AI": {"tldr": "CTS\u7b97\u6cd5\u901a\u8fc7\u7ec4\u5408\u4f18\u5316\u548c\u68af\u5ea6\u5e73\u8861\uff0c\u5728\u521d\u59cb\u5316\u9636\u6bb5\u9ad8\u6548\u627e\u5230\u9ad8\u6027\u80fd\u7a00\u758f\u5b50\u7f51\u7edc\uff0c\u6027\u80fd\u8d85\u8d8a\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\uff0c\u8ba1\u7b97\u6210\u672c\u8fdc\u4f4e\u4e8e\u5f69\u7968\u7968\u8bc1\u91cd\u7ed5\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5f69\u7968\u7968\u8bc1\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\uff08\u5982LTR\uff09\u6216\u7cbe\u5ea6-\u7a00\u758f\u5ea6\u6743\u8861\u5dee\uff08\u5982PaI\uff09\u7684\u95ee\u9898\uff0cPaI\u65b9\u6cd5\u4f9d\u8d56\u4e00\u9636\u663e\u8457\u6027\u6307\u6807\u5ffd\u7565\u4e86\u6743\u91cd\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5c24\u5176\u5728\u7a00\u758f\u533a\u57df\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faConcrete Ticket Search (CTS)\u7b97\u6cd5\uff0c\u5c06\u5b50\u7f51\u7edc\u53d1\u73b0\u5efa\u6a21\u4e3a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528Concrete\u677e\u5f1b\u79bb\u6563\u641c\u7d22\u7a7a\u95f4\uff0c\u91c7\u7528GRADBALANCE\u68af\u5ea6\u5e73\u8861\u65b9\u6848\u63a7\u5236\u7a00\u758f\u5ea6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u526a\u679d\u76ee\u6807\uff08\u7279\u522b\u662f\u6700\u5c0f\u5316\u7a00\u758f\u4e0e\u5bc6\u96c6\u7f51\u7edc\u8f93\u51fa\u7684\u53cd\u5411KL\u6563\u5ea6CTS-KL\uff09\u3002", "result": "CTS\u4ea7\u751f\u7684\u5b50\u7f51\u7edc\u80fd\u7a33\u5065\u901a\u8fc7\u5408\u7406\u6027\u68c0\u67e5\uff0c\u5728\u7cbe\u5ea6\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7LTR\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002\u4f8b\u5982\u5728ResNet-20/CIFAR10\u4e0a\uff0c\u8fbe\u523099.3%\u7a00\u758f\u5ea6\u65f6\u7cbe\u5ea674.0%\uff08LTR\u4e3a68.3%\uff09\uff0c\u8ba1\u7b97\u65f6\u95f4\u4ec57.9\u5206\u949f\uff08LTR\u970095.2\u5206\u949f\uff09\u3002", "conclusion": "CTS\u901a\u8fc7\u6574\u4f53\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u521d\u59cb\u5316\u526a\u679d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u9ad8\u5ea6\u7a00\u758f\u533a\u57df\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0c\u4e3a\u9ad8\u6548\u53d1\u73b0\u9ad8\u6027\u80fd\u5f69\u7968\u7968\u8bc1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.07150", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07150", "abs": "https://arxiv.org/abs/2512.07150", "authors": ["Jonghyun Park", "Jong Chul Ye"], "title": "FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers", "comment": null, "summary": "Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.", "AI": {"tldr": "FlowLPS\uff1a\u57fa\u4e8e\u9884\u8bad\u7ec3\u6d41\u6a21\u578b\u89e3\u51b3\u9006\u95ee\u9898\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6717\u4e4b\u4e07\u8fd1\u7aef\u91c7\u6837\u7b56\u7565\uff0c\u5728FFHQ\u548cDIV2K\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u6d41\u6a21\u578b\u65f6\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u96be\u4ee5\u6536\u655b\u5230\u540e\u9a8c\u6a21\u5f0f\uff1b2) \u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b58\u5728\u6d41\u5f62\u504f\u5dee\u3002\u9700\u8981\u4e00\u79cd\u65b0\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "FlowLPS\u6846\u67b6\u7ed3\u5408\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u8fdb\u884c\u6d41\u5f62\u4e00\u81f4\u63a2\u7d22\u548c\u8fd1\u7aef\u4f18\u5316\u8fdb\u884c\u7cbe\u786e\u6a21\u5f0f\u641c\u7d22\u3002\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u786e\u4fdd\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u4e00\u81f4\u63a2\u7d22\uff0c\u800c\u8fd1\u7aef\u4f18\u5316\u5219\u4e13\u6ce8\u4e8e\u5bfb\u627e\u7cbe\u786e\u7684\u540e\u9a8c\u6a21\u5f0f\u3002", "result": "\u5728FFHQ\u548cDIV2K\u6570\u636e\u96c6\u4e0a\u7684\u591a\u4e2a\u9006\u95ee\u9898\u4efb\u52a1\u4e2d\uff0cFlowLPS\u5728\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u611f\u77e5\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u9006\u95ee\u9898\u6c42\u89e3\u5668\u3002", "conclusion": "FlowLPS\u901a\u8fc7\u6717\u4e4b\u4e07\u8fd1\u7aef\u91c7\u6837\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u6a21\u578b\u5728\u9006\u95ee\u9898\u5e94\u7528\u4e2d\u7684\u6536\u655b\u548c\u6d41\u5f62\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u9884\u8bad\u7ec3\u6d41\u6a21\u578b\u7684\u9006\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\u3002"}}
{"id": "2512.07173", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07173", "abs": "https://arxiv.org/abs/2512.07173", "authors": ["Jucheng Shen", "Gaurav Sarkar", "Yeonju Ro", "Sharath Nittur Sridhar", "Zhangyang Wang", "Aditya Akella", "Souvik Kundu"], "title": "Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration", "comment": "8 pages, 3 figures. Preprint under review", "summary": "We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.", "AI": {"tldr": "CadLLM\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u751f\u6210\u5757\u5927\u5c0f\u3001\u6b65\u957f\u548c\u9608\u503c\u6765\u52a0\u901f\u57fa\u4e8e\u6269\u6563\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u5b9e\u73b0\u6700\u9ad82.28\u500d\u541e\u5410\u91cf\u63d0\u5347", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6269\u6563\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u52a0\u901f\u63a8\u7406\u541e\u5410\u91cf\u3002\u4f5c\u8005\u89c2\u5bdf\u5230token unmasking\u7f6e\u4fe1\u5ea6\u5728\u4e0d\u540c\u5757\u548c\u6b65\u9aa4\u4e2d\u5177\u6709\u52a8\u6001\u7279\u6027\uff0c\u8fd9\u4e3a\u4f18\u5316\u63d0\u4f9b\u4e86\u673a\u4f1a", "method": "1. \u5206\u6790token unmasking\u7f6e\u4fe1\u5ea6\u5728\u4e0d\u540c\u5757\u548c\u6b65\u9aa4\u4e2d\u7684\u52a8\u6001\u7279\u6027\uff1b2. \u63d0\u51fa\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u6839\u636e\u672amask token\u7684\u5e73\u5747\u7f6e\u4fe1\u5ea6\u63a7\u5236\u751f\u6210\u5757\u5927\u5c0f\u3001\u6b65\u957f\u548c\u9608\u503c\uff1b3. \u901a\u8fc7\u52a8\u6001\u5229\u7528\u8bcd\u6c47\u8868\u5b50\u96c6\u6765\u51cf\u5c11softmax\u5f00\u9500\uff0c\u8c03\u8282\u91c7\u6837\u5e7f\u5ea6", "result": "\u5728\u56db\u4e2a\u6d41\u884c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCadLLM\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad82.28\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027", "conclusion": "CadLLM\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u517c\u5bb9\u57fa\u4e8eKV\u7f13\u5b58\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u800c\u4e0d\u635f\u5931\u51c6\u786e\u6027"}}
{"id": "2512.07175", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07175", "abs": "https://arxiv.org/abs/2512.07175", "authors": ["Yibo Wang", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang", "Lijun Zhang"], "title": "SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models", "comment": "NeurIPS 2025", "summary": "Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely Self-PlAy via Noise Contrastive Estimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.", "AI": {"tldr": "SPACE\u662f\u4e00\u79cd\u57fa\u4e8e\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u7684\u81ea\u5bf9\u5f08\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5408\u6210\u6837\u672c\u4f5c\u4e3a\u8f85\u52a9\u6210\u5206\uff0c\u4ee5\u4e8c\u5206\u7c7b\u65b9\u5f0f\u533a\u5206\u771f\u5b9e\u6570\u636e\uff0c\u907f\u514d\u4f20\u7edf\u57fa\u4e8e\u5956\u52b1\u5dee\u8ddd\u65b9\u6cd5\u7684\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5b9e\u73b0\u7a33\u5b9a\u6536\u655b\u5230\u771f\u5b9e\u6570\u636e\u5206\u5e03\u3002", "motivation": "\u73b0\u6709\u81ea\u5bf9\u5f08\u5fae\u8c03\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u771f\u5b9e\u6570\u636e\u548c\u5408\u6210\u6570\u636e\u4e4b\u95f4\u7684\u5956\u52b1\u5dee\u8ddd\uff0c\u5ffd\u7565\u4e86\u7edd\u5bf9\u5956\u52b1\u503c\uff0c\u5bfc\u81f4\u76ee\u6807\u51fd\u6570\u53ef\u80fd\u9000\u5316\uff0c\u9020\u6210\u4e0d\u7a33\u5b9a\u6f14\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7a33\u5b9a\u6536\u655b\u5230\u771f\u5b9e\u6570\u636e\u5206\u5e03\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSPACE\u65b9\u6cd5\uff0c\u4f7f\u7528\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u6355\u6349\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5206\u5e03\u3002\u5c06\u5408\u6210\u6837\u672c\u4f5c\u4e3a\u8f85\u52a9\u6210\u5206\uff0c\u901a\u8fc7\u4e8c\u5206\u7c7b\u65b9\u5f0f\u533a\u5206\u771f\u5b9e\u6837\u672c\u548c\u5408\u6210\u6837\u672c\uff0c\u72ec\u7acb\u4f18\u5316\u6bcf\u79cd\u6570\u636e\u7684\u7edd\u5bf9\u5956\u52b1\u503c\uff0c\u786e\u4fdd\u76ee\u6807\u51fd\u6570\u59cb\u7ec8\u6709\u610f\u4e49\u3002", "result": "\u7406\u8bba\u8bc1\u660eSPACE\u7684\u6700\u4f18\u89e3\u4e0e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u57fa\u7840\u5206\u5e03\u4e00\u81f4\uff0c\u5e76\u80fd\u4fdd\u8bc1\u7a33\u5b9a\u6536\u655b\u5230\u6700\u4f18\u5206\u5e03\u3002\u5b9e\u8bc1\u8868\u660eSPACE\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347LLM\u6027\u80fd\uff0c\u4f18\u4e8e\u4f7f\u7528\u66f4\u591a\u771f\u5b9e\u6837\u672c\u7684\u76d1\u7763\u5fae\u8c03\uff0c\u76f8\u6bd4\u57fa\u4e8e\u5dee\u8ddd\u7684\u81ea\u5bf9\u5f08\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u548c\u7a33\u5b9a\u6f14\u5316\u3002", "conclusion": "SPACE\u901a\u8fc7\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u89e3\u51b3\u4e86\u4f20\u7edf\u81ea\u5bf9\u5f08\u5fae\u8c03\u7684\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u80fd\u591f\u7a33\u5b9a\u5730\u5b66\u4e60\u771f\u5b9e\u6570\u636e\u5206\u5e03\uff0c\u5728\u6709\u9650\u771f\u5b9e\u6570\u636e\u60c5\u51b5\u4e0b\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3aLLM\u5fae\u8c03\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.07184", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07184", "abs": "https://arxiv.org/abs/2512.07184", "authors": ["Da Zhang", "Bingyu Li", "Zhuyuan Zhao", "Junyu Gao", "Feiping Nie", "Xuelong Li"], "title": "UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting", "comment": null, "summary": "As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.", "AI": {"tldr": "UniDiff\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u7edf\u4e00\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u878d\u5408\u6a21\u5757\u6574\u5408\u6587\u672c\u548c\u65f6\u95f4\u6233\u4fe1\u606f\uff0c\u5728\u591a\u9886\u57df\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u6570\u636e\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u6fc0\u589e\uff0c\u5229\u7528\u6587\u672c\u548c\u65f6\u95f4\u6233\u7b49\u5f02\u6784\u4fe1\u606f\u8fdb\u884c\u51c6\u786e\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u6a21\u6001\u6570\u503c\u5e8f\u5217\u5efa\u6a21\uff0c\u5ffd\u7565\u4e86\u590d\u6742\u5f02\u6784\u6570\u636e\u4e2d\u4e30\u5bcc\u7684\u8de8\u6a21\u6001\u4fe1\u53f7\u3002", "method": "\u63d0\u51faUniDiff\u7edf\u4e00\u6269\u6563\u6846\u67b6\uff1a1) \u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u5757\u5e76\u6620\u5c04\u5230\u5d4c\u5165\u7a7a\u95f4\uff1b2) \u6838\u5fc3\u662f\u7edf\u4e00\u7684\u5e76\u884c\u878d\u5408\u6a21\u5757\uff0c\u4f7f\u7528\u5355\u4e00\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u4e00\u6b65\u6574\u5408\u65f6\u95f4\u6233\u7684\u7ed3\u6784\u4fe1\u606f\u548c\u6587\u672c\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\uff1b3) \u5f15\u5165\u9488\u5bf9\u591a\u6e90\u6761\u4ef6\u7684\u65b0\u578b\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u673a\u5236\uff0c\u53ef\u5728\u63a8\u7406\u65f6\u5206\u522b\u63a7\u5236\u6587\u672c\u548c\u65f6\u95f4\u4fe1\u606f\u7684\u5f15\u5bfc\u5f3a\u5ea6\u3002", "result": "\u5728\u516b\u4e2a\u9886\u57df\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660eUniDiff\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "UniDiff\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u6269\u6563\u6846\u67b6\u6709\u6548\u6574\u5408\u5f02\u6784\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2512.07200", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07200", "abs": "https://arxiv.org/abs/2512.07200", "authors": ["Zhen Huang", "Jiaxin Deng", "Jiayu Xu", "Junbiao Pang", "Haitao Yu"], "title": "Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction", "comment": null, "summary": "In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-regressive-based approaches. Traditional methods typically employ a uniform segmentation strategy, which fails to account for varying physical constraints along roads, such as road conditions, intersections, and points of interest, thereby limiting prediction efficiency. In this paper, we propose a Reinforcement Learning (RL)-based approach to efficiently and adaptively learn non-uniform road segments for arrival time prediction. Our method decouples the prediction process into two stages: 1) Non-uniform road segments are extracted based on their impact scores using the proposed RL framework; and 2) A linear prediction model is applied to the selected segments to make predictions. This method ensures optimal segment selection while maintaining computational efficiency, offering a significant improvement over traditional uniform approaches. Furthermore, our experimental results suggest that the linear approach can even achieve better performance than more complex methods. Extensive experiments demonstrate the superiority of the proposed method, which not only enhances efficiency but also improves learning performance on large-scale benchmarks. The dataset and the code are publicly accessible at: https://github.com/pangjunbiao/Less-is-More.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u975e\u5747\u5300\u9053\u8def\u5206\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u516c\u4ea4\u8f66\u5230\u8fbe\u65f6\u95f4\u9884\u6d4b\uff0c\u76f8\u6bd4\u4f20\u7edf\u5747\u5300\u5206\u6bb5\u7b56\u7565\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u516c\u4ea4\u8f66\u5230\u8fbe\u65f6\u95f4\u9884\u6d4b\u7cfb\u7edf\u91c7\u7528\u5747\u5300\u9053\u8def\u5206\u6bb5\u7b56\u7565\uff0c\u65e0\u6cd5\u8003\u8651\u9053\u8def\u6761\u4ef6\u3001\u4ea4\u53c9\u53e3\u3001\u5174\u8da3\u70b9\u7b49\u7269\u7406\u7ea6\u675f\u7684\u5dee\u5f02\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6548\u7387\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u9002\u5e94\u5b66\u4e60\u975e\u5747\u5300\u9053\u8def\u5206\u6bb5\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6839\u636e\u5f71\u54cd\u5206\u6570\u63d0\u53d6\u975e\u5747\u5300\u9053\u8def\u5206\u6bb5\uff1b2) \u5728\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\u4e2d\u5bf9\u9009\u5b9a\u5206\u6bb5\u8fdb\u884c\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u5206\u6bb5\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u8fd8\u6539\u5584\u4e86\u5b66\u4e60\u6027\u80fd\u3002\u7ebf\u6027\u65b9\u6cd5\u751a\u81f3\u80fd\u6bd4\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u975e\u5747\u5300\u9053\u8def\u5206\u6bb5\u65b9\u6cd5\u5728\u516c\u4ea4\u8f66\u5230\u8fbe\u65f6\u95f4\u9884\u6d4b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5747\u5300\u5206\u6bb5\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u53cc\u91cd\u63d0\u5347\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.07208", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07208", "abs": "https://arxiv.org/abs/2512.07208", "authors": ["Fei Luo", "Ziwei Zhao", "Mingxuan Wang", "Duoyang Li", "Zhe Qian", "Jiayi Tuo", "Chenyue Zhou", "Yanbiao Ma"], "title": "Geometric Prior-Guided Federated Prompt Calibration", "comment": null, "summary": "Federated Prompt Learning (FPL) offers a parameter-efficient solution for collaboratively training large models, but its performance is severely hindered by data heterogeneity, which causes locally trained prompts to become biased. Existing methods, focusing on aggregation or regularization, fail to address this root cause of local training bias. To this end, we propose Geometry-Guided Text Prompt Calibration (GGTPC), a novel framework that directly corrects this bias by providing clients with a global geometric prior. This prior, representing the shape of the global data distribution derived from the covariance matrix, is reconstructed on the server in a privacy-preserving manner. Clients then use a novel Geometry-Prior Calibration Layer (GPCL) to align their local feature distributions with this global prior during training. Extensive experiments show GGTPC's effectiveness. On the label-skewed CIFAR-100 dataset ($\u03b2$=0.1), it outperforms the state-of-the-art by 2.15\\%. Under extreme skew ($\u03b2$=0.01), it improves upon the baseline by 9.17\\%. Furthermore, as a plug-and-play module on the domain-skewed Office-Home dataset, it boosts FedAvg's performance by 4.60\\%. These results demonstrate that GGTPC effectively mitigates data heterogeneity by correcting the fundamental local training bias, serving as a versatile module to enhance various FL algorithms.", "AI": {"tldr": "GGTPC\u63d0\u51fa\u51e0\u4f55\u5f15\u5bfc\u7684\u6587\u672c\u63d0\u793a\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u51e0\u4f55\u5148\u9a8c\u6821\u6b63\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u5bfc\u81f4\u7684\u672c\u5730\u8bad\u7ec3\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u63d0\u793a\u5b66\u4e60(FPL)\u5728\u6570\u636e\u5f02\u6784\u573a\u666f\u4e0b\u6027\u80fd\u4e25\u91cd\u53d7\u9650\uff0c\u672c\u5730\u8bad\u7ec3\u7684\u63d0\u793a\u4f1a\u53d8\u5f97\u6709\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u805a\u7126\u4e8e\u805a\u5408\u6216\u6b63\u5219\u5316\uff0c\u672a\u80fd\u89e3\u51b3\u672c\u5730\u8bad\u7ec3\u504f\u5dee\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u5f15\u5bfc\u7684\u6587\u672c\u63d0\u793a\u6821\u51c6(GGTPC)\u6846\u67b6\uff1a1) \u670d\u52a1\u5668\u7aef\u901a\u8fc7\u534f\u65b9\u5dee\u77e9\u9635\u91cd\u6784\u5168\u5c40\u6570\u636e\u5206\u5e03\u7684\u51e0\u4f55\u5f62\u72b6\u4f5c\u4e3a\u5168\u5c40\u51e0\u4f55\u5148\u9a8c\uff1b2) \u5ba2\u6237\u7aef\u4f7f\u7528\u51e0\u4f55\u5148\u9a8c\u6821\u51c6\u5c42(GPCL)\u5728\u8bad\u7ec3\u65f6\u5c06\u672c\u5730\u7279\u5f81\u5206\u5e03\u4e0e\u5168\u5c40\u5148\u9a8c\u5bf9\u9f50\u3002", "result": "\u5728\u6807\u7b7e\u503e\u659c\u7684CIFAR-100\u6570\u636e\u96c6\u4e0a(\u03b2=0.1)\uff0c\u6bd4SOTA\u63d0\u53472.15%\uff1b\u5728\u6781\u7aef\u503e\u659c(\u03b2=0.01)\u65f6\u6bd4\u57fa\u7ebf\u63d0\u53479.17%\uff1b\u5728\u9886\u57df\u503e\u659c\u7684Office-Home\u6570\u636e\u96c6\u4e0a\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u5c06FedAvg\u6027\u80fd\u63d0\u53474.60%\u3002", "conclusion": "GGTPC\u901a\u8fc7\u6821\u6b63\u672c\u5730\u8bad\u7ec3\u504f\u5dee\u6709\u6548\u7f13\u89e3\u6570\u636e\u5f02\u6784\u95ee\u9898\uff0c\u53ef\u4f5c\u4e3a\u901a\u7528\u6a21\u5757\u589e\u5f3a\u5404\u79cd\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5168\u5c40\u51e0\u4f55\u5148\u9a8c\u5728\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.07222", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07222", "abs": "https://arxiv.org/abs/2512.07222", "authors": ["Qiwei Tian", "Chenhao Lin", "Zhengyu Zhao", "Chao Shen"], "title": "Pay Less Attention to Function Words for Free Robustness of Vision-Language Models", "comment": null, "summary": "To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.", "AI": {"tldr": "\u63d0\u51faFunction-word De-Attention (FDA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u529f\u80fd\u8bcd\u5728\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e2d\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9c81\u68d2\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9c81\u68d2\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u529f\u80fd\u8bcd\u662f\u6a21\u578b\u5728\u8de8\u6a21\u6001\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u70b9\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u51cf\u8f7b\u529f\u80fd\u8bcd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faFunction-word De-Attention (FDA)\u65b9\u6cd5\uff0c\u7c7b\u4f3c\u4e8e\u5dee\u5206\u653e\u5927\u5668\uff0c\u8ba1\u7b97\u539f\u59cb\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u548c\u529f\u80fd\u8bcd\u8de8\u6a21\u6001\u6ce8\u610f\u529b\uff0c\u7136\u540e\u5c06\u540e\u8005\u4ece\u524d\u8005\u4e2d\u5dee\u5206\u51cf\u53bb\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u5bf9\u9f50\u548c\u9c81\u68d2\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u57286\u79cd\u4e0d\u540c\u653b\u51fb\u30012\u4e2a\u4e0b\u6e38\u4efb\u52a1\u30013\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u6a21\u578b\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u663e\u793a\uff1a\u5728\u68c0\u7d22\u4efb\u52a1\u4e0a\uff0cFDA\u4f7f3\u4e2a\u6d4b\u8bd5\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u5e73\u5747\u4e0b\u964d18%/13%/53%\uff0c\u6027\u80fd\u4ec5\u4e0b\u964d0.2%/0.3%/0.6%\uff1b\u5728\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u4e0a\uff0c\u653b\u51fb\u6210\u529f\u7387\u4e0b\u964d90%\uff0c\u6027\u80fd\u53cd\u800c\u63d0\u53470.3%\u3002", "conclusion": "FDA\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u96f6\u6837\u672c\u6027\u80fd\u3002"}}
{"id": "2512.07244", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07244", "abs": "https://arxiv.org/abs/2512.07244", "authors": ["Elizaveta Kovtun", "Maksim Makarenko", "Natalia Semenova", "Alexey Zaytsev", "Semen Budennyy"], "title": "PINE: Pipeline for Important Node Exploration in Attributed Networks", "comment": null, "summary": "A graph with semantically attributed nodes are a common data structure in a wide range of domains. It could be interlinked web data or citation networks of scientific publications. The essential problem for such a data type is to determine nodes that carry greater importance than all the others, a task that markedly enhances system monitoring and management. Traditional methods to identify important nodes in networks introduce centrality measures, such as node degree or more complex PageRank. However, they consider only the network structure, neglecting the rich node attributes. Recent methods adopt neural networks capable of handling node features, but they require supervision. This work addresses the identified gap--the absence of approaches that are both unsupervised and attribute-aware--by introducing a Pipeline for Important Node Exploration (PINE). At the core of the proposed framework is an attention-based graph model that incorporates node semantic features in the learning process of identifying the structural graph properties. The PINE's node importance scores leverage the obtained attention distribution. We demonstrate the superior performance of the proposed PINE method on various homogeneous and heterogeneous attributed networks. As an industry-implemented system, PINE tackles the real-world challenge of unsupervised identification of key entities within large-scale enterprise graphs.", "AI": {"tldr": "PINE\u662f\u4e00\u4e2a\u7528\u4e8e\u65e0\u76d1\u7763\u8bc6\u522b\u5c5e\u6027\u56fe\u4e2d\u91cd\u8981\u8282\u70b9\u7684\u7ba1\u9053\u6846\u67b6\uff0c\u7ed3\u5408\u8282\u70b9\u8bed\u4e49\u7279\u5f81\u548c\u7f51\u7edc\u7ed3\u6784\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u8282\u70b9\u91cd\u8981\u6027\u5206\u6570\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u5ea6\u4e2d\u5fc3\u6027\u3001PageRank\uff09\u4ec5\u8003\u8651\u7f51\u7edc\u7ed3\u6784\u800c\u5ffd\u7565\u8282\u70b9\u5c5e\u6027\uff0c\u800c\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u9700\u8981\u76d1\u7763\u5b66\u4e60\u3002\u7f3a\u4e4f\u65e2\u65e0\u76d1\u7763\u53c8\u80fd\u5229\u7528\u8282\u70b9\u5c5e\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPINE\u7ba1\u9053\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u56fe\u6a21\u578b\uff0c\u5728\u5b66\u4e60\u56fe\u7ed3\u6784\u7279\u6027\u7684\u8fc7\u7a0b\u4e2d\u878d\u5165\u8282\u70b9\u8bed\u4e49\u7279\u5f81\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5206\u5e03\u8ba1\u7b97\u8282\u70b9\u91cd\u8981\u6027\u5206\u6570\u3002", "result": "\u5728\u591a\u79cd\u540c\u8d28\u548c\u5f02\u8d28\u5c5e\u6027\u7f51\u7edc\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u4f5c\u4e3a\u5de5\u4e1a\u5b9e\u73b0\u7cfb\u7edf\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u4f01\u4e1a\u56fe\u4e2d\u5173\u952e\u5b9e\u4f53\u7684\u65e0\u76d1\u7763\u8bc6\u522b\u3002", "conclusion": "PINE\u586b\u8865\u4e86\u65e0\u76d1\u7763\u4e14\u5c5e\u6027\u611f\u77e5\u7684\u91cd\u8981\u8282\u70b9\u8bc6\u522b\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u6709\u6548\u7ed3\u5408\u8282\u70b9\u8bed\u4e49\u7279\u5f81\u548c\u7f51\u7edc\u7ed3\u6784\uff0c\u5177\u6709\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.07249", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07249", "abs": "https://arxiv.org/abs/2512.07249", "authors": ["Jingran Yang", "Min Zhang", "Lingfeng Zhang", "Zhaohui Wang", "Yonggang Zhang"], "title": "IFFair: Influence Function-driven Sample Reweighting for Fair Classification", "comment": null, "summary": "Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f71\u54cd\u51fd\u6570\u7684\u9884\u5904\u7406\u65b9\u6cd5IFFair\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6837\u672c\u6743\u91cd\u6765\u51cf\u8f7b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u504f\u89c1\uff0c\u65e0\u9700\u4fee\u6539\u7f51\u7edc\u7ed3\u6784\u6216\u6570\u636e\u7279\u5f81\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u51b3\u7b56\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u57fa\u4e8e\u6570\u636e\u7684\u6a21\u5f0f\u4f1a\u5b66\u4e60\u751a\u81f3\u52a0\u5267\u6837\u672c\u4e2d\u7684\u504f\u89c1\uff0c\u5bfc\u81f4\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u6b67\u89c6\u6027\u51b3\u7b56\uff0c\u635f\u5bb3\u793e\u4f1a\u798f\u7949\u5e76\u963b\u788d\u5e94\u7528\u53d1\u5c55\u3002", "method": "\u57fa\u4e8e\u5f71\u54cd\u51fd\u6570\u7684\u9884\u5904\u7406\u65b9\u6cd5IFFair\uff0c\u5229\u7528\u4e0d\u540c\u7fa4\u4f53\u8bad\u7ec3\u6837\u672c\u7684\u5f71\u54cd\u5dee\u5f02\u4f5c\u4e3a\u6307\u5bfc\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u6837\u672c\u6743\u91cd\uff0c\u4e0d\u4fee\u6539\u7f51\u7edc\u7ed3\u6784\u3001\u6570\u636e\u7279\u5f81\u548c\u51b3\u7b56\u8fb9\u754c\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6307\u6807\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIFFair\u80fd\u51cf\u8f7b\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u591a\u79cd\u504f\u89c1\u6307\u6807\uff08\u4eba\u53e3\u7edf\u8ba1\u5747\u7b49\u3001\u673a\u4f1a\u5747\u7b49\u3001\u9519\u8bef\u7387\u5747\u7b49\uff09\uff0c\u4e14\u6bd4\u73b0\u6709\u9884\u5904\u7406\u65b9\u6cd5\u5728\u6548\u7528\u4e0e\u516c\u5e73\u6027\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u5e73\u8861\u3002", "conclusion": "IFFair\u662f\u4e00\u79cd\u6709\u6548\u7684\u516c\u5e73\u6027\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6837\u672c\u6743\u91cd\u6765\u51cf\u8f7b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u504f\u89c1\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6548\u7528\u7684\u540c\u65f6\u63d0\u5347\u516c\u5e73\u6027\u3002"}}
{"id": "2512.07287", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07287", "abs": "https://arxiv.org/abs/2512.07287", "authors": ["Sijia Li", "Yuchen Huang", "Zifan Liu", "Zijian Li", "Jingjing fu", "Lei Song", "Jiang Bian", "Jun Zhang", "Rui Wang"], "title": "SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents", "comment": null, "summary": "Despite impressive advances in agent systems, multi-turn tool-use scenarios remain challenging. It is mainly because intent is clarified progressively and the environment evolves with each tool call. While reusing past experience is natural, current LLM agents either treat entire trajectories or pre-defined subtasks as indivisible units, or solely exploit tool-to-tool dependencies, hindering adaptation as states and information evolve across turns. In this paper, we propose a State Integrated Tool Graph (SIT-Graph), which enhances multi-turn tool use by exploiting partially overlapping experience. Inspired by human decision-making that integrates episodic and procedural memory, SIT-Graph captures both compact state representations (episodic-like fragments) and tool-to-tool dependencies (procedural-like routines) from historical trajectories. Specifically, we first build a tool graph from accumulated tool-use sequences, and then augment each edge with a compact state summary of the dialog and tool history that may shape the next action. At inference time, SIT-Graph enables a human-like balance between episodic recall and procedural execution: when the next decision requires recalling prior context, the agent retrieves the state summaries stored on relevant edges and uses them to guide its next action; when the step is routine, it follows high-confidence tool dependencies without explicit recall. Experiments across multiple stateful multi-turn tool-use benchmarks show that SIT-Graph consistently outperforms strong memory- and graph-based baselines, delivering more robust tool selection and more effective experience transfer.", "AI": {"tldr": "SIT-Graph\uff1a\u4e00\u79cd\u589e\u5f3a\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u7684\u72b6\u6001\u96c6\u6210\u5de5\u5177\u56fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u90e8\u5206\u91cd\u53e0\u7ecf\u9a8c\uff0c\u7ed3\u5408\u60c5\u666f\u8bb0\u5fc6\u548c\u7a0b\u5e8f\u8bb0\u5fc6\uff0c\u5728\u9700\u8981\u65f6\u53ec\u56de\u4e0a\u4e0b\u6587\uff0c\u5728\u5e38\u89c4\u6b65\u9aa4\u4e2d\u9075\u5faa\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u5728\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u610f\u56fe\u662f\u9010\u6b65\u6f84\u6e05\u7684\uff0c\u73af\u5883\u968f\u7740\u6bcf\u6b21\u5de5\u5177\u8c03\u7528\u800c\u6f14\u53d8\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5c06\u6574\u4e2a\u8f68\u8ff9\u6216\u9884\u5b9a\u4e49\u5b50\u4efb\u52a1\u89c6\u4e3a\u4e0d\u53ef\u5206\u5272\u5355\u5143\uff0c\u8981\u4e48\u4ec5\u5229\u7528\u5de5\u5177\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u96be\u4ee5\u9002\u5e94\u72b6\u6001\u548c\u4fe1\u606f\u968f\u8f6e\u6b21\u53d8\u5316\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u72b6\u6001\u96c6\u6210\u5de5\u5177\u56fe(SIT-Graph)\uff0c\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u6784\u5efa\u5de5\u5177\u56fe\uff0c\u5e76\u5728\u6bcf\u6761\u8fb9\u4e0a\u6dfb\u52a0\u5bf9\u8bdd\u548c\u5de5\u5177\u5386\u53f2\u7684\u7d27\u51d1\u72b6\u6001\u6458\u8981\u3002\u63a8\u7406\u65f6\uff0c\u5f53\u9700\u8981\u56de\u5fc6\u5148\u524d\u4e0a\u4e0b\u6587\u65f6\u68c0\u7d22\u72b6\u6001\u6458\u8981\u6307\u5bfc\u884c\u52a8\uff0c\u5f53\u6b65\u9aa4\u5e38\u89c4\u65f6\u5219\u9075\u5faa\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u591a\u4e2a\u6709\u72b6\u6001\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSIT-Graph\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u8bb0\u5fc6\u548c\u56fe\u7684\u57fa\u7840\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u5de5\u5177\u9009\u62e9\u548c\u66f4\u6709\u6548\u7684\u7ecf\u9a8c\u8f6c\u79fb\u3002", "conclusion": "SIT-Graph\u901a\u8fc7\u7ed3\u5408\u60c5\u666f\u8bb0\u5fc6\u548c\u7a0b\u5e8f\u8bb0\u5fc6\u7684\u7c7b\u4eba\u51b3\u7b56\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u4e2d\u7684\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u7ecf\u9a8c\u590d\u7528\u80fd\u529b\u3002"}}
{"id": "2512.07310", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07310", "abs": "https://arxiv.org/abs/2512.07310", "authors": ["Andrei V. Konstantinov", "Valerii A. Zuev", "Lev V. Utkin"], "title": "Towards a Relationship-Aware Transformer for Tabular Data", "comment": null, "summary": "Deep learning models for tabular data typically do not allow for imposing a graph of external dependencies between samples, which can be useful for accounting for relatedness in tasks such as treatment effect estimation. Graph neural networks only consider adjacent nodes, making them difficult to apply to sparse graphs. This paper proposes several solutions based on a modified attention mechanism, which accounts for possible relationships between data points by adding a term to the attention matrix. Our models are compared with each other and the gradient boosting decision trees in a regression task on synthetic and real-world datasets, as well as in a treatment effect estimation task on the IHDP dataset.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u8868\u683c\u6570\u636e\u4e2d\u7684\u6837\u672c\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u56de\u5f52\u548c\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u8868\u683c\u6570\u636e\u4e2d\u7684\u6837\u672c\u95f4\u4f9d\u8d56\u5173\u7cfb\u56fe\uff0c\u800c\u56fe\u795e\u7ecf\u7f51\u7edc\u53ea\u8003\u8651\u76f8\u90bb\u8282\u70b9\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u7a00\u758f\u56fe\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6709\u6548\u5229\u7528\u5916\u90e8\u4f9d\u8d56\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u7b49\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u6ce8\u610f\u529b\u77e9\u9635\u4e2d\u6dfb\u52a0\u989d\u5916\u9879\u6765\u8003\u8651\u6570\u636e\u70b9\u4e4b\u95f4\u7684\u53ef\u80fd\u5173\u7cfb\u3002\u8bbe\u8ba1\u4e86\u591a\u79cd\u6a21\u578b\u53d8\u4f53\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u56de\u5f52\u4efb\u52a1\u8bc4\u4f30\uff0c\u4ee5\u53ca\u5728IHDP\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4efb\u52a1\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u76f8\u4e92\u6bd4\u8f83\u5e76\u4e0e\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u5bf9\u6bd4\uff0c\u5728\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4efb\u52a1\u4e2d\u5728IHDP\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u5728\u5904\u7406\u6837\u672c\u95f4\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u8868\u683c\u6570\u636e\u4e2d\u7684\u6837\u672c\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3a\u9700\u8981\u8003\u8651\u6570\u636e\u70b9\u76f8\u5173\u6027\u7684\u4efb\u52a1\uff08\u5982\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\uff09\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07313", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2512.07313", "abs": "https://arxiv.org/abs/2512.07313", "authors": ["Bosun Kang", "Hyejun Park", "Chenglin Fan"], "title": "Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach", "comment": "7 pages", "summary": "We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u51b3\u7b56\u548c\u673a\u5668\u5b66\u4e60\u7684\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ef4\u62a4\u7cbe\u786e\u540e\u9a8c\u5206\u5e03\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728\u51c6\u786e\u5148\u9a8c\u4e0b\u63a5\u8fd1\u6700\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u9c81\u68d2\u6027\u4fdd\u8bc1", "motivation": "\u4f20\u7edf\u7b97\u6cd5\u53ea\u8003\u8651\u6700\u574f\u60c5\u51b5\u6210\u672c\uff0c\u800c\u8fd1\u671f\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\u5229\u7528\u566a\u58f0\u9884\u6d4b\u4f46\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u672c\u6587\u65e8\u5728\u7edf\u4e00\u8fd9\u4e24\u79cd\u89c6\u89d2\uff0c\u4e3a\u5e26\u6709\u4e0d\u5b8c\u7f8e\u9884\u6d4b\u7684\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6", "method": "\u63d0\u51fa\u79bb\u6563\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7ef4\u62a4\u65f6\u95f4\u8303\u56f4\u7684\u7cbe\u786e\u540e\u9a8c\u5206\u5e03\uff0c\u5141\u8bb8\u7eb3\u5165\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\u3002\u7b97\u6cd5\u5b9e\u73b0\u5148\u9a8c\u4f9d\u8d56\u7684\u7ade\u4e89\u6027\u4fdd\u8bc1\uff0c\u5e73\u6ed1\u63d2\u503c\u4e8e\u6700\u574f\u60c5\u51b5\u548c\u5b8c\u5168\u77e5\u60c5\u8bbe\u7f6e\u4e4b\u95f4", "result": "\u7b97\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u5728\u51c6\u786e\u5148\u9a8c\u4e0b\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u9c81\u68d2\u7684\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\u3002\u6846\u67b6\u53ef\u6269\u5c55\u81f3\u591a\u9884\u6d4b\u3001\u975e\u5747\u5300\u5148\u9a8c\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f", "conclusion": "\u8d1d\u53f6\u65af\u63a8\u7406\u4e3a\u5e26\u6709\u4e0d\u5b8c\u7f8e\u9884\u6d4b\u7684\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u4f18\u52bf\uff0c\u7edf\u4e00\u4e86\u4f20\u7edf\u6700\u574f\u60c5\u51b5\u5206\u6790\u548c\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u7684\u5e73\u8861"}}
{"id": "2512.07332", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07332", "abs": "https://arxiv.org/abs/2512.07332", "authors": ["Zhengquan Luo", "Guy Tadmor", "Or Amar", "David Zeevi", "Zhiqiang Xu"], "title": "Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach", "comment": null, "summary": "Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.", "AI": {"tldr": "RicciKGE\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u51e0\u4f55\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u635f\u5931\u68af\u5ea6\u4e0e\u5c40\u90e8\u66f2\u7387\u8026\u5408\u5728\u6269\u5c55\u7684Ricci\u6d41\u4e2d\uff0c\u4f7f\u5b9e\u4f53\u5d4c\u5165\u4e0e\u5e95\u5c42\u6d41\u5f62\u51e0\u4f55\u5171\u540c\u6f14\u5316\uff0c\u4ee5\u89e3\u51b3\u9884\u5b9a\u4e49\u9f50\u6b21\u6d41\u5f62\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u56fe\u8c31\u5c40\u90e8\u66f2\u7387\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5\u5c06\u6240\u6709\u5b9e\u4f53\u653e\u7f6e\u5728\u4e00\u4e2a\u9f50\u6b21\u6d41\u5f62\u4e0a\uff08\u6b27\u51e0\u91cc\u5f97\u3001\u7403\u9762\u3001\u53cc\u66f2\u6216\u5176\u4e58\u79ef/\u591a\u66f2\u7387\u53d8\u4f53\uff09\uff0c\u4f46\u9884\u5b9a\u4e49\u7684\u9f50\u6b21\u6d41\u5f62\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u56fe\u8c31\u5728\u4e0d\u540c\u5c40\u90e8\u533a\u57df\u8868\u73b0\u51fa\u7684\u6025\u5267\u53d8\u5316\u7684\u66f2\u7387\u3002\u8fd9\u79cd\u51e0\u4f55\u4e0d\u5339\u914d\u4f1a\u626d\u66f2\u5b9e\u4f53\u95f4\u7684\u8ddd\u79bb\uff0c\u635f\u5bb3\u5d4c\u5165\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u63d0\u51faRicciKGE\u65b9\u6cd5\uff0c\u5c06KGE\u635f\u5931\u68af\u5ea6\u4e0e\u5c40\u90e8\u66f2\u7387\u8026\u5408\u5728\u6269\u5c55\u7684Ricci\u6d41\u4e2d\uff0c\u4f7f\u5b9e\u4f53\u5d4c\u5165\u4e0e\u5e95\u5c42\u6d41\u5f62\u51e0\u4f55\u52a8\u6001\u5171\u540c\u6f14\u5316\uff0c\u5b9e\u73b0\u76f8\u4e92\u9002\u5e94\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5f53\u8026\u5408\u7cfb\u6570\u6709\u754c\u4e14\u9002\u5f53\u9009\u62e9\u65f6\uff0c\u6240\u6709\u8fb9\u66f2\u7387\u5448\u6307\u6570\u8870\u51cf\uff08\u6d41\u5f62\u8d8b\u5411\u6b27\u51e0\u91cc\u5f97\u5e73\u5766\uff09\uff0c\u4e14KGE\u8ddd\u79bb\u4e25\u683c\u6536\u655b\u5230\u5168\u5c40\u6700\u4f18\u3002", "result": "\u5728\u94fe\u63a5\u9884\u6d4b\u548c\u8282\u70b9\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u5b9e\u9a8c\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86RicciKGE\u5728\u9002\u5e94\u5f02\u6784\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "RicciKGE\u901a\u8fc7\u52a8\u6001\u51e0\u4f55\u9002\u5e94\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfKGE\u65b9\u6cd5\u4e2d\u9884\u5b9a\u4e49\u9f50\u6b21\u6d41\u5f62\u4e0e\u771f\u5b9e\u56fe\u8c31\u5c40\u90e8\u66f2\u7387\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6d41\u5f62\u51e0\u4f55\u4e0e\u5d4c\u5165\u4f18\u5316\u7684\u76f8\u4e92\u4fc3\u8fdb\uff0c\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2512.07374", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07374", "abs": "https://arxiv.org/abs/2512.07374", "authors": ["Yezi Liu", "Hanning Chen", "Wenjun Huang", "Yang Ni", "Mohsen Imani"], "title": "Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning", "comment": null, "summary": "Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.", "AI": {"tldr": "R2F\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLoRA\u9002\u914d\u5668\u91cd\u5efa\u5b8c\u6574\u6a21\u578b\u68af\u5ea6\u65b9\u5411\u7684\u9ad8\u6548\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u65b9\u6cd5\uff0c\u65e0\u9700\u5b8c\u6574\u6a21\u578b\u5fae\u8c03\u6216\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u5927\u578b\u57fa\u7840\u6a21\u578b\uff08\u5982LLMs\uff09\u7684\u9057\u5fd8\u5bf9\u4e8e\u52a8\u6001\u77e5\u8bc6\u66f4\u65b0\u3001\u6570\u636e\u5220\u9664\u6743\u5229\u6267\u884c\u548c\u6a21\u578b\u884c\u4e3a\u4fee\u6b63\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5b8c\u6574\u6a21\u578b\u5fae\u8c03\u6216\u8bbf\u95ee\u539f\u59cb\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "R2F\u6846\u67b6\u901a\u8fc7\u4ece\u4f4e\u79e9LoRA\u9002\u914d\u5668\u66f4\u65b0\u91cd\u5efa\u5b8c\u6574\u6a21\u578b\u68af\u5ea6\u65b9\u5411\u3002\u4f7f\u7528\u591a\u4e2a\u6539\u5199\u63d0\u793a\u8ba1\u7b97LoRA\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u8bad\u7ec3\u68af\u5ea6\u89e3\u7801\u5668\u6765\u8fd1\u4f3c\u76f8\u5e94\u7684\u5b8c\u6574\u6a21\u578b\u68af\u5ea6\u3002\u89e3\u7801\u5668\u5728\u4ee3\u7406\u6a21\u578b\u4e0a\u8bad\u7ec3\u540e\u8fc1\u79fb\u5230\u76ee\u6807\u6a21\u578b\u3002", "result": "\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u9057\u5fd8\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u4e00\u822c\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eR2F\u4e3a\u9884\u8bad\u7ec3LLMs\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u8f7b\u91cf\u7ea7\u7684\u9057\u5fd8\u66ff\u4ee3\u65b9\u6848\uff0c\u65e0\u9700\u5b8c\u6574\u91cd\u65b0\u8bad\u7ec3\u6216\u8bbf\u95ee\u5185\u90e8\u53c2\u6570\u3002", "conclusion": "R2F\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u91cd\u5efa\u6280\u672f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u7684\u9650\u5236\u3002"}}
{"id": "2512.07375", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07375", "abs": "https://arxiv.org/abs/2512.07375", "authors": ["Yezi Liu", "Hanning Chen", "Wenjun Huang", "Yang Ni", "Mohsen Imani"], "title": "LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples", "comment": null, "summary": "Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.", "AI": {"tldr": "LUNE\uff1a\u57fa\u4e8eLoRA\u7684\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u66f4\u65b0\u4f4e\u79e9\u9002\u914d\u5668\u5b9e\u73b0\u9ad8\u6548\u77e5\u8bc6\u9057\u5fd8\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u79fb\u9664\u7279\u5b9a\u4fe1\u606f\uff0c\u5728\u5904\u7406\u9690\u79c1\u3001\u504f\u89c1\u7f13\u89e3\u548c\u77e5\u8bc6\u4fee\u6b63\u65f6\u5b58\u5728\u56f0\u96be\u3002\u4f20\u7edf\u9057\u5fd8\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u5fae\u8c03\u6216\u6743\u91cd\u7f16\u8f91\uff0c\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72", "method": "\u63d0\u51faLoRA-based Unlearning with Negative Examples (LUNE)\u6846\u67b6\uff0c\u4ec5\u66f4\u65b0\u4f4e\u79e9\u9002\u914d\u5668\u5e76\u51bb\u7ed3\u4e3b\u5e72\u7f51\u7edc\uff0c\u901a\u8fc7\u8d1f\u4f8b\u8bad\u7ec3\u5b9a\u4f4d\u4e2d\u95f4\u8868\u793a\u6765\u6291\u5236\u6216\u66ff\u6362\u76ee\u6807\u77e5\u8bc6", "result": "\u5728\u591a\u4e2a\u4e8b\u5b9e\u9057\u5fd8\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09LUNE\u6548\u679c\u4e0e\u5168\u5fae\u8c03\u548c\u5185\u5b58\u7f16\u8f91\u65b9\u6cd5\u76f8\u5f53\uff1b2\uff09\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7", "conclusion": "LUNE\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7684\u6a21\u578b\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c40\u90e8\u5316\u7f16\u8f91\u907f\u514d\u5168\u5c40\u7834\u574f\u6027\u53d8\u5316\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2512.07390", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07390", "abs": "https://arxiv.org/abs/2512.07390", "authors": ["Gilhyun Nam", "Taewon Kim", "Joonhyun Jeong", "Eunho Yang"], "title": "Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood", "comment": "Accepted to WACV 2026", "summary": "Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.", "AI": {"tldr": "SICL\u6846\u67b6\u5229\u7528\u98ce\u683c\u4e0d\u53d8\u6027\u8fdb\u884c\u9c81\u68d2\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u901a\u8fc7\u6d4b\u91cf\u98ce\u683c\u53d8\u5316\u53d8\u4f53\u95f4\u7684\u9884\u6d4b\u4e00\u81f4\u6027\u6765\u4f30\u8ba1\u5b9e\u4f8b\u7ea7\u6b63\u786e\u6027\u6982\u7387\uff0c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\uff0c\u53ef\u4e0e\u4efb\u4f55TTA\u65b9\u6cd5\u517c\u5bb9\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u9002\u5e94\uff08TTA\uff09\u65b9\u6cd5\u867d\u7136\u80fd\u9ad8\u6548\u9002\u5e94\u90e8\u7f72\u6a21\u578b\uff0c\u4f46\u5f80\u5f80\u5bfc\u81f4\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u4e0d\u4f73\uff0c\u8fd9\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u91d1\u878d\u548c\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u662f\u4e25\u91cd\u95ee\u9898\u3002\u73b0\u6709\u6821\u51c6\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u56fa\u5b9a\u6a21\u578b\u6216\u9759\u6001\u5206\u5e03\uff0c\u5728\u73b0\u5b9e\u52a8\u6001\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u6027\u80fd\u4f1a\u4e0b\u964d\u3002", "method": "\u63d0\u51faSICL\u6846\u67b6\uff0c\u5229\u7528\u98ce\u683c\u4e0d\u53d8\u6027\u8fdb\u884c\u9c81\u68d2\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u901a\u8fc7\u6d4b\u91cf\u9884\u6d4b\u5728\u98ce\u683c\u53d8\u5316\u53d8\u4f53\u95f4\u7684\u4e00\u81f4\u6027\u6765\u4f30\u8ba1\u5b9e\u4f8b\u7ea7\u6b63\u786e\u6027\u6982\u7387\uff0c\u4ec5\u9700\u6a21\u578b\u524d\u5411\u4f20\u64ad\uff0c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u6821\u51c6\u6a21\u5757\u4e0e\u4efb\u4f55TTA\u65b9\u6cd5\u517c\u5bb9\u3002", "result": "\u57284\u4e2a\u57fa\u7ebf\u30015\u79cdTTA\u65b9\u6cd5\u548c2\u4e2a\u73b0\u5b9e\u573a\u666f\u30013\u79cd\u6a21\u578b\u67b6\u6784\u7684\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0cSICL\u76f8\u6bd4\u4f20\u7edf\u6821\u51c6\u65b9\u6cd5\u5e73\u5747\u51cf\u5c11\u4e8613\u4e2a\u767e\u5206\u70b9\u7684\u6821\u51c6\u8bef\u5dee\u3002", "conclusion": "SICL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u98ce\u683c\u4e0d\u53d8\u6027\u539f\u7406\u6539\u5584TTA\u65b9\u6cd5\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u95ee\u9898\uff0c\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.07393", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07393", "abs": "https://arxiv.org/abs/2512.07393", "authors": ["Yann Bourdin", "Pierrick Legrand", "Fanny Roche"], "title": "Empirical Results for Adjusting Truncated Backpropagation Through Time while Training Neural Audio Effects", "comment": null, "summary": "This paper investigates the optimization of Truncated Backpropagation Through Time (TBPTT) for training neural networks in digital audio effect modeling, with a focus on dynamic range compression. The study evaluates key TBPTT hyperparameters -- sequence number, batch size, and sequence length -- and their influence on model performance. Using a convolutional-recurrent architecture, we conduct extensive experiments across datasets with and without conditionning by user controls. Results demonstrate that carefully tuning these parameters enhances model accuracy and training stability, while also reducing computational demands. Objective evaluations confirm improved performance with optimized settings, while subjective listening tests indicate that the revised TBPTT configuration maintains high perceptual quality.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f18\u5316\u4e86TBPTT\u5728\u97f3\u9891\u6548\u679c\u5efa\u6a21\u4e2d\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u901a\u8fc7\u8c03\u6574\u5e8f\u5217\u6570\u3001\u6279\u6b21\u5927\u5c0f\u548c\u5e8f\u5217\u957f\u5ea6\uff0c\u63d0\u5347\u4e86\u52a8\u6001\u8303\u56f4\u538b\u7f29\u6a21\u578b\u7684\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5728\u6570\u5b57\u97f3\u9891\u6548\u679c\u5efa\u6a21\u4e2d\uff0c\u7279\u522b\u662f\u52a8\u6001\u8303\u56f4\u538b\u7f29\u65b9\u9762\uff0c\u9700\u8981\u4f18\u5316TBPTT\u8bad\u7ec3\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3001\u8bad\u7ec3\u7a33\u5b9a\u6027\u5e76\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5377\u79ef-\u5faa\u73af\u67b6\u6784\uff0c\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc4\u4f30TBPTT\u7684\u5173\u952e\u8d85\u53c2\u6570\uff08\u5e8f\u5217\u6570\u3001\u6279\u6b21\u5927\u5c0f\u3001\u5e8f\u5217\u957f\u5ea6\uff09\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u6709\u65e0\u7528\u6237\u63a7\u5236\u6761\u4ef6\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u7cbe\u5fc3\u8c03\u6574TBPTT\u53c2\u6570\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7cbe\u5ea6\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u9700\u6c42\u3002\u5ba2\u89c2\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u6539\u8fdb\uff0c\u4e3b\u89c2\u542c\u529b\u6d4b\u8bd5\u8868\u660e\u4f18\u5316\u914d\u7f6e\u4fdd\u6301\u4e86\u9ad8\u611f\u77e5\u8d28\u91cf\u3002", "conclusion": "TBPTT\u8d85\u53c2\u6570\u7684\u4f18\u5316\u5bf9\u4e8e\u6570\u5b57\u97f3\u9891\u6548\u679c\u5efa\u6a21\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u5e73\u8861\u6027\u80fd\u3001\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u97f3\u9891\u5904\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2512.07400", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07400", "abs": "https://arxiv.org/abs/2512.07400", "authors": ["Giulia Lanzillotta", "Damiano Meier", "Thomas Hofmann"], "title": "Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse", "comment": null, "summary": "A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the \"strong collapse\" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u6df1\u5ea6\u7279\u5f81\u9057\u5fd8\u4e0e\u6d45\u5c42\u5206\u7c7b\u5668\u9057\u5fd8\u7684\u533a\u522b\uff0c\u53d1\u73b0\u5c0f\u7f13\u51b2\u533a\u80fd\u9632\u6b62\u7279\u5f81\u9057\u5fd8\u4f46\u9700\u8981\u5927\u7f13\u51b2\u533a\u7f13\u89e3\u5206\u7c7b\u5668\u9057\u5fd8\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u4fee\u6b63\u7edf\u8ba1\u4f2a\u5f71\u53ef\u5728\u5c0f\u7f13\u51b2\u533a\u4e0b\u83b7\u5f97\u9c81\u68d2\u6027\u80fd\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u6301\u4e45\u6096\u8bba\u662f\uff1a\u795e\u7ecf\u7f51\u7edc\u5373\u4f7f\u5728\u8f93\u51fa\u9884\u6d4b\u5931\u8d25\u65f6\uff0c\u4e5f\u7ecf\u5e38\u4fdd\u7559\u8fc7\u53bb\u4efb\u52a1\u7684\u7ebf\u6027\u53ef\u5206\u8868\u793a\u3002\u672c\u6587\u65e8\u5728\u5f62\u5f0f\u5316\u8fd9\u79cd\u6df1\u5ea6\u7279\u5f81\u7a7a\u95f4\u4e0e\u6d45\u5c42\u5206\u7c7b\u5668\u7ea7\u522b\u9057\u5fd8\u7684\u533a\u522b\uff0c\u5e76\u89e3\u91ca\u4e3a\u4ec0\u4e48\u7ecf\u9a8c\u56de\u653e\u4e2d\u9700\u8981\u4e0d\u540c\u5927\u5c0f\u7684\u7f13\u51b2\u533a\u6765\u5e94\u5bf9\u8fd9\u4e24\u79cd\u9057\u5fd8\u3002", "method": "\u5c06\u795e\u7ecf\u574d\u7f29\u6846\u67b6\u6269\u5c55\u5230\u987a\u5e8f\u8bbe\u7f6e\uff0c\u5c06\u6df1\u5ea6\u9057\u5fd8\u5f62\u5f0f\u5316\u4e3a\u5411\u5206\u5e03\u5916\u5b50\u7a7a\u95f4\u7684\u51e0\u4f55\u6f02\u79fb\uff0c\u8bc1\u660e\u4efb\u4f55\u975e\u96f6\u56de\u653e\u5206\u6570\u90fd\u80fd\u4fdd\u8bc1\u7ebf\u6027\u53ef\u5206\u6027\u7684\u4fdd\u7559\u3002\u540c\u65f6\u8bc6\u522b\u5c0f\u7f13\u51b2\u533a\u5bfc\u81f4\u7684\"\u5f3a\u574d\u7f29\"\u4f1a\u4ea7\u751f\u79e9\u4e0d\u8db3\u534f\u65b9\u5dee\u548c\u81a8\u80c0\u7684\u7c7b\u5747\u503c\uff0c\u4f7f\u5206\u7c7b\u5668\u65e0\u6cd5\u8bc6\u522b\u771f\u5b9e\u603b\u4f53\u8fb9\u754c\u3002", "result": "\u63ed\u793a\u4e86\u7ecf\u9a8c\u56de\u653e\u4e2d\u7684\u5173\u952e\u4e0d\u5bf9\u79f0\u6027\uff1a\u6700\u5c0f\u7f13\u51b2\u533a\u80fd\u6210\u529f\u951a\u5b9a\u7279\u5f81\u51e0\u4f55\u5e76\u9632\u6b62\u6df1\u5ea6\u9057\u5fd8\uff0c\u4f46\u7f13\u89e3\u6d45\u5c42\u9057\u5fd8\u901a\u5e38\u9700\u8981\u66f4\u5927\u7684\u7f13\u51b2\u533a\u5bb9\u91cf\u3002\u901a\u8fc7\u5c06\u6301\u7eed\u5b66\u4e60\u4e0e\u5206\u5e03\u5916\u68c0\u6d4b\u7edf\u4e00\uff0c\u6311\u6218\u4e86\u5bf9\u5927\u7f13\u51b2\u533a\u7684\u4f9d\u8d56\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u4fee\u6b63\u7edf\u8ba1\u4f2a\u5f71\uff08\u79e9\u4e0d\u8db3\u534f\u65b9\u5dee\u548c\u81a8\u80c0\u7684\u7c7b\u5747\u503c\uff09\uff0c\u53ef\u4ee5\u5728\u6700\u5c0f\u56de\u653e\u4e0b\u5b9e\u73b0\u9c81\u68d2\u6027\u80fd\uff0c\u8fd9\u4e3a\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u51cf\u5c11\u4e86\u5bf9\u5927\u7f13\u51b2\u533a\u7684\u4f9d\u8d56\u3002"}}
{"id": "2512.07417", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07417", "abs": "https://arxiv.org/abs/2512.07417", "authors": ["Giray \u00d6n\u00fcr", "Azita Dabiri", "Bart De Schutter"], "title": "Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u72b6\u6001\u53cd\u9988\u4ea4\u901a\u63a7\u5236\u5668\u53c2\u6570\uff0c\u7ed3\u5408\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5668\u7684\u53cd\u5e94\u6027\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u4ea4\u901a\u7ba1\u7406\u7b56\u7565\uff08\u5982\u8def\u5f84\u5f15\u5bfc\u3001\u531d\u9053\u63a7\u5236\u548c\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff09\u901a\u5e38\u4f9d\u8d56\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5668\uff0c\u867d\u7136\u7b80\u5355\u53cd\u5e94\u5feb\uff0c\u4f46\u7f3a\u4e4f\u5e94\u5bf9\u590d\u6742\u65f6\u53d8\u4ea4\u901a\u52a8\u6001\u7684\u9002\u5e94\u6027\u3002\u9700\u8981\u7ed3\u5408\u72b6\u6001\u53cd\u9988\u63a7\u5236\u7684\u53cd\u5e94\u6027\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u8c03\u6574\u72b6\u6001\u53cd\u9988\u4ea4\u901a\u63a7\u5236\u5668\u7684\u53c2\u6570\uff08\u800c\u975e\u76f4\u63a5\u9ad8\u9891\u63a7\u5236\u52a8\u4f5c\uff09\u3002\u91c7\u7528\u8f83\u4f4e\u9891\u7387\u7684\u53c2\u6570\u8c03\u6574\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u591a\u667a\u80fd\u4f53\u7ed3\u6784\u589e\u5f3a\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u5c40\u90e8\u63a7\u5236\u5668\u5728\u90e8\u5206\u6545\u969c\u65f6\u53ef\u72ec\u7acb\u8fd0\u884c\u3002", "result": "\u5728\u6a21\u62df\u7684\u591a\u7c7b\u522b\u4ea4\u901a\u7f51\u7edc\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4f18\u4e8e\u65e0\u63a7\u5236\u548c\u56fa\u5b9a\u53c2\u6570\u72b6\u6001\u53cd\u9988\u63a7\u5236\uff0c\u4e0e\u5355\u667a\u80fd\u4f53RL\u81ea\u9002\u5e94\u72b6\u6001\u53cd\u9988\u63a7\u5236\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u5bf9\u90e8\u5206\u6545\u969c\u5177\u6709\u66f4\u597d\u7684\u6062\u590d\u80fd\u529b\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u72b6\u6001\u53cd\u9988\u63a7\u5236\u7684\u53cd\u5e94\u6027\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u53c2\u6570\u8c03\u6574\u800c\u975e\u76f4\u63a5\u52a8\u4f5c\u63a7\u5236\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u591a\u667a\u80fd\u4f53\u7ed3\u6784\u589e\u5f3a\u4e86\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u5bf9\u90e8\u5206\u6545\u969c\u7684\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2512.07419", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07419", "abs": "https://arxiv.org/abs/2512.07419", "authors": ["Haidong Kang", "Jun Du", "Lihong Lin"], "title": "Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models", "comment": null, "summary": "Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learned a quantized DNN from the proxy (i.e., HAWQ) manually designed by human experts, which is labor-intensive and requires huge expert knowledge. Can we design a proxy without involving any human experts and training? In this paper, we provide an affirmative answer by proposing a novel Large Language Models (LLMs)-driven Training-free Automatic Proxy (dubbed TAP) discovery framework, which reforms the design paradigm of MPQ by utilizing LLMs to find superior TAP tailored for MPQ, automatically. In addition, to bridge the gap between black-box LLMs and the tough MPQ task, we ingeniously propose simple Direct Policy Optimization (DPO) based reinforcement learning to enhance LLMs' reasoning by optimizing prompts, which can construct a positive feedback loop between the LLM and the MPQ task, enabling LLMs to generate better TAP in the next evolution. Extensive experiments on mainstream benchmarks demonstrate that TAP achieves state-of-the-art performance. Finally, we truly believe that our TAP will significantly contribute to the MPQ community by providing a new perspective on LLM-driven design algorithms.", "AI": {"tldr": "\u63d0\u51faTAP\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u53d1\u73b0\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u7684\u8bad\u7ec3\u514d\u8d39\u4ee3\u7406\uff0c\u65e0\u9700\u4eba\u5de5\u4e13\u5bb6\u53c2\u4e0e\u6216\u8bad\u7ec3\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u7684\u53ef\u5fae\u5206\u4f18\u5316\u641c\u7d22\uff08\u6548\u7387\u4f4e\u4e14\u4e0d\u7075\u6d3b\uff09\uff0c\u8981\u4e48\u9700\u8981\u4eba\u5de5\u4e13\u5bb6\u8bbe\u8ba1\u4ee3\u7406\uff08\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff09\u3002\u80fd\u5426\u8bbe\u8ba1\u4e00\u4e2a\u65e0\u9700\u4eba\u5de5\u4e13\u5bb6\u53c2\u4e0e\u548c\u8bad\u7ec3\u7684\u4ee3\u7406\uff1f", "method": "\u63d0\u51faLLM\u9a71\u52a8\u7684\u8bad\u7ec3\u514d\u8d39\u81ea\u52a8\u4ee3\u7406\u53d1\u73b0\u6846\u67b6TAP\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3aMPQ\u5bfb\u627e\u5b9a\u5236\u5316\u4ee3\u7406\u3002\u91c7\u7528\u57fa\u4e8e\u76f4\u63a5\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u63d0\u793a\uff0c\u5728LLM\u548cMPQ\u4efb\u52a1\u95f4\u5efa\u7acb\u6b63\u53cd\u9988\u5faa\u73af\u3002", "result": "\u5728\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTAP\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "TAP\u4e3aMPQ\u793e\u533a\u63d0\u4f9b\u4e86LLM\u9a71\u52a8\u8bbe\u8ba1\u7b97\u6cd5\u7684\u65b0\u89c6\u89d2\uff0c\u5c06\u663e\u8457\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2512.07430", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07430", "abs": "https://arxiv.org/abs/2512.07430", "authors": ["Yangle Li", "Danli Luo", "Haifeng Hu"], "title": "MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis", "comment": null, "summary": "Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.", "AI": {"tldr": "\u63d0\u51faMIDG\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u4e0d\u53d8\u4e13\u5bb6\u6a21\u578b\u63d0\u53d6\u9886\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u7ed3\u5408\u8de8\u6a21\u6001\u9002\u914d\u5668\u6ce8\u5165\u77e5\u8bc6\uff0c\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5728\u63d0\u53d6\u4e0d\u53d8\u7279\u5f81\u65f6\u5ffd\u7565\u4e86\u6a21\u6001\u95f4\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e14\u77e5\u8bc6\u6ce8\u5165\u6280\u672f\u5b58\u5728\u8de8\u6a21\u6001\u77e5\u8bc6\u788e\u7247\u5316\u95ee\u9898\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u6001\u95f4\u7684\u7279\u5b9a\u8868\u793a\u3002", "method": "1. \u6df7\u5408\u4e0d\u53d8\u4e13\u5bb6\u6a21\u578b\u63d0\u53d6\u9886\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u589e\u5f3a\u6a21\u6001\u95f4\u534f\u540c\u5173\u7cfb\u5b66\u4e60\uff1b2. \u8de8\u6a21\u6001\u9002\u914d\u5668\u901a\u8fc7\u8de8\u6a21\u6001\u77e5\u8bc6\u6ce8\u5165\u589e\u5f3a\u591a\u6a21\u6001\u8868\u793a\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u9886\u57df\u5b9e\u9a8c\u8868\u660e\uff0cMIDG\u6846\u67b6\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684MIDG\u6846\u67b6\u901a\u8fc7\u6709\u6548\u63d0\u53d6\u9886\u57df\u4e0d\u53d8\u7279\u5f81\u548c\u8de8\u6a21\u6001\u77e5\u8bc6\u6ce8\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.07433", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.07433", "abs": "https://arxiv.org/abs/2512.07433", "authors": ["Yezi Liu", "William Youngwoo Chung", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Mitigating Bias in Graph Hyperdimensional Computing", "comment": null, "summary": "Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\\approx 10\\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFairGHDC\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u8d85\u7ef4\u8ba1\u7b97\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u504f\u5dee\u6821\u6b63\u9879\u6765\u51cf\u5c11\u7fa4\u4f53\u95f4\u7684\u4e0d\u516c\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u4f18\u52bf\u3002", "motivation": "\u56fe\u8d85\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u4f5c\u4e3a\u8ba4\u77e5\u4efb\u52a1\u7684\u8111\u542f\u53d1\u8ba1\u7b97\u8303\u5f0f\uff0c\u867d\u7136\u5177\u6709\u9c81\u68d2\u6027\u548c\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u5176\u516c\u5e73\u6027\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u636e\u8868\u793a\u548c\u51b3\u7b56\u89c4\u5219\u4e2d\u53ef\u80fd\u5b58\u5728\u504f\u89c1\uff0c\u5bfc\u81f4\u5bf9\u4e0d\u540c\u7fa4\u4f53\u7684\u4e0d\u5e73\u7b49\u5bf9\u5f85\u3002", "method": "\u63d0\u51faFairGHDC\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u5dee\u8ddd\u7684\u4eba\u53e3\u7edf\u8ba1\u5947\u5076\u6b63\u5219\u5316\u5668\u7684\u504f\u5dee\u6821\u6b63\u9879\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u6807\u91cf\u516c\u5e73\u56e0\u5b50\uff0c\u7528\u4e8e\u7f29\u653e\u771f\u5b9e\u6807\u7b7e\u7c7b\u8d85\u5411\u91cf\u7684\u66f4\u65b0\u3002\u8be5\u65b9\u6cd5\u76f4\u63a5\u5728\u8d85\u5411\u91cf\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53bb\u504f\uff0c\u65e0\u9700\u4fee\u6539\u56fe\u7f16\u7801\u5668\u6216\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFairGHDC\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u53e3\u7edf\u8ba1\u5947\u5076\u548c\u673a\u4f1a\u5747\u7b49\u5dee\u8ddd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u6807\u51c6GNN\u548c\u516c\u5e73\u611f\u77e5GNN\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u5728GPU\u8bad\u7ec3\u65f6\u95f4\u4e0a\u5b9e\u73b0\u4e86\u7ea610\u500d\u7684\u52a0\u901f\u3002", "conclusion": "FairGHDC\u6709\u6548\u89e3\u51b3\u4e86\u56feHDC\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u4f18\u52bf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u516c\u5e73\u6027\u6539\u8fdb\uff0c\u4e3a\u8111\u542f\u53d1\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u516c\u5e73\u6027\u4fdd\u969c\u3002"}}
{"id": "2512.07437", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.07437", "abs": "https://arxiv.org/abs/2512.07437", "authors": ["Chenwei Shi", "Xueyu Luan"], "title": "KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models", "comment": "23 pages, 8 figures, 3 tables", "summary": "DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.", "AI": {"tldr": "KAN-Dreamer\uff1a\u5c06KAN\u67b6\u6784\u96c6\u6210\u5230DreamerV3\u4e2d\uff0c\u7528KAN/FastKAN\u66ff\u6362\u90e8\u5206MLP\u548c\u5377\u79ef\u7ec4\u4ef6\uff0c\u5728DeepMind Control Suite\u4e0a\u5b9e\u73b0\u4e0e\u539f\u59cbMLP\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "KANs\u4f5c\u4e3aMLPs\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u66f4\u597d\u7684\u53c2\u6570\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u8f83\u5927\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c06KAN\u67b6\u6784\u96c6\u6210\u5230DreamerV3\u8fd9\u4e00\u5148\u8fdb\u7684MBRL\u7b97\u6cd5\u4e2d\uff0c\u4ee5\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u3002", "method": "\u5f00\u53d1KAN-Dreamer\uff0c\u5c06DreamerV3\u4e2d\u7684\u7279\u5b9aMLP\u548c\u5377\u79ef\u7ec4\u4ef6\u66ff\u6362\u4e3aKAN\u548cFastKAN\u5c42\u3002\u5728JAX-based World Model\u4e2d\u5b9e\u73b0\u5b8c\u5168\u5411\u91cf\u5316\u7248\u672c\uff0c\u7b80\u5316\u7f51\u683c\u7ba1\u7406\u3002\u7814\u7a76\u5206\u4e3a\u4e09\u4e2a\u5b50\u7cfb\u7edf\uff1a\u89c6\u89c9\u611f\u77e5\u3001\u6f5c\u5728\u9884\u6d4b\u548c\u884c\u4e3a\u5b66\u4e60\u3002", "result": "\u5728DeepMind Control Suite (walker_walk)\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u9002\u914d\u7684FastKAN\u4f5c\u4e3a\u5956\u52b1\u548c\u7ee7\u7eed\u9884\u6d4b\u5668\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u6837\u672c\u6548\u7387\u3001\u8bad\u7ec3\u901f\u5ea6\u548c\u6e10\u8fdb\u6027\u80fd\u65b9\u9762\u4e0e\u539f\u59cbMLP\u67b6\u6784\u76f8\u5f53\u3002", "conclusion": "KAN\u67b6\u6784\u53ef\u4ee5\u4f5c\u4e3aDreamerV3\u4e2dMLP\u7ec4\u4ef6\u7684\u6709\u6548\u66ff\u4ee3\uff0c\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u53ef\u80fd\u5e26\u6765\u53c2\u6570\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u7684\u4f18\u52bf\u3002\u672c\u7814\u7a76\u4e3a\u672a\u6765\u57fa\u4e8eKAN\u7684\u4e16\u754c\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u521d\u6b65\u63a2\u7d22\u3002"}}
{"id": "2512.07450", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07450", "abs": "https://arxiv.org/abs/2512.07450", "authors": ["Imran Ahsan", "Hyunwook Yu", "Jinsung Kim", "Mucheol Kim"], "title": "Forget and Explain: Transparent Verification of GNN Unlearning", "comment": "To appear in WSDM 2026 (ACM International Conference on Web Search and Data Mining). Code is available at https://github.com/ImranAhsan23/F-E", "summary": "Graph neural networks (GNNs) are increasingly used to model complex patterns in graph-structured data. However, enabling them to \"forget\" designated information remains challenging, especially under privacy regulations such as the GDPR. Existing unlearning methods largely optimize for efficiency and scalability, yet they offer little transparency, and the black-box nature of GNNs makes it difficult to verify whether forgetting has truly occurred. We propose an explainability-driven verifier for GNN unlearning that snapshots the model before and after deletion, using attribution shifts and localized structural changes (for example, graph edit distance) as transparent evidence. The verifier uses five explainability metrics: residual attribution, heatmap shift, explainability score deviation, graph edit distance, and a diagnostic graph rule shift. We evaluate two backbones (GCN, GAT) and four unlearning strategies (Retrain, GraphEditor, GNNDelete, IDEA) across five benchmarks (Cora, Citeseer, Pubmed, Coauthor-CS, Coauthor-Physics). Results show that Retrain and GNNDelete achieve near-complete forgetting, GraphEditor provides partial erasure, and IDEA leaves residual signals. These explanation deltas provide the primary, human-readable evidence of forgetting; we also report membership-inference ROC-AUC as a complementary, graph-wide privacy signal.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u53ef\u89e3\u91ca\u6027\u7684GNN\u9057\u5fd8\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5220\u9664\u524d\u540e\u7684\u6a21\u578b\u5feb\u7167\uff0c\u4f7f\u7528\u5f52\u56e0\u504f\u79fb\u548c\u5c40\u90e8\u7ed3\u6784\u53d8\u5316\u4f5c\u4e3a\u900f\u660e\u8bc1\u636e\u6765\u9a8c\u8bc1\u9057\u5fd8\u662f\u5426\u771f\u6b63\u53d1\u751f\u3002", "motivation": "\u73b0\u6709GNN\u9057\u5fd8\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u4e14GNN\u7684\u9ed1\u76d2\u7279\u6027\u4f7f\u5f97\u96be\u4ee5\u9a8c\u8bc1\u9057\u5fd8\u662f\u5426\u771f\u6b63\u53d1\u751f\uff0c\u7279\u522b\u662f\u5728GDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\u4e0b\u3002", "method": "\u63d0\u51fa\u53ef\u89e3\u91ca\u6027\u9a71\u52a8\u7684\u9a8c\u8bc1\u5668\uff0c\u5728\u5220\u9664\u524d\u540e\u5bf9\u6a21\u578b\u8fdb\u884c\u5feb\u7167\uff0c\u4f7f\u7528\u4e94\u79cd\u53ef\u89e3\u91ca\u6027\u6307\u6807\uff1a\u6b8b\u5dee\u5f52\u56e0\u3001\u70ed\u56fe\u504f\u79fb\u3001\u53ef\u89e3\u91ca\u6027\u5206\u6570\u504f\u5dee\u3001\u56fe\u7f16\u8f91\u8ddd\u79bb\u548c\u8bca\u65ad\u56fe\u89c4\u5219\u504f\u79fb\u3002", "result": "\u8bc4\u4f30\u4e86\u4e24\u79cd\u9aa8\u5e72\u7f51\u7edc\uff08GCN\u3001GAT\uff09\u548c\u56db\u79cd\u9057\u5fd8\u7b56\u7565\uff08Retrain\u3001GraphEditor\u3001GNNDelete\u3001IDEA\uff09\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793aRetrain\u548cGNNDelete\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u5168\u7684\u9057\u5fd8\uff0cGraphEditor\u63d0\u4f9b\u90e8\u5206\u64e6\u9664\uff0cIDEA\u7559\u4e0b\u6b8b\u5dee\u4fe1\u53f7\u3002", "conclusion": "\u89e3\u91ca\u6027\u5dee\u5f02\u63d0\u4f9b\u4e86\u4e3b\u8981\u7684\u4eba\u7c7b\u53ef\u8bfb\u9057\u5fd8\u8bc1\u636e\uff0c\u540c\u65f6\u6210\u5458\u63a8\u65adROC-AUC\u4f5c\u4e3a\u8865\u5145\u7684\u56fe\u8303\u56f4\u9690\u79c1\u4fe1\u53f7\uff0c\u4e3aGNN\u9057\u5fd8\u63d0\u4f9b\u4e86\u900f\u660e\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2512.07463", "categories": ["cs.LG", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.07463", "abs": "https://arxiv.org/abs/2512.07463", "authors": ["Rongmei Liang", "Zizheng Liu", "Xiaofei Wu", "Jingwen Tu"], "title": "Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification", "comment": null, "summary": "In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5171\u8bc6\u7ed3\u6784\u7684\u7edf\u4e00\u4f18\u5316\u6846\u67b6\uff0c\u5f00\u53d1\u5206\u5e03\u5f0f\u5e76\u884cADMM\u7b97\u6cd5\u5904\u7406\u5206\u5e03\u5f0f\u5b58\u50a8\u5927\u6570\u636e\u4e2d\u7684\u7ec4\u5408\u6b63\u5219\u5316\u652f\u6301\u5411\u91cf\u673a\uff0c\u5f15\u5165\u9ad8\u65af\u56de\u4ee3\u6cd5\u786e\u4fdd\u6536\u655b\uff0c\u5e76\u5728\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u4e2d\u5e94\u7528\u7a00\u758f\u7ec4\u5957\u7d22SVM\u3002", "motivation": "\u5728\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u53d1\u5c55\u7684\u65f6\u4ee3\uff0c\u7ec4\u5408\u6b63\u5219\u5316\u652f\u6301\u5411\u91cf\u673a\uff08CR-SVMs\uff09\u80fd\u6709\u6548\u5904\u7406\u6570\u636e\u7279\u5f81\u95f4\u7684\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5728\u5206\u5e03\u5f0f\u5b58\u50a8\u7684\u5927\u6570\u636e\u573a\u666f\u4e2d\u7f3a\u4e4f\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5171\u8bc6\u7ed3\u6784\u7684\u7edf\u4e00\u4f18\u5316\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u635f\u5931\u51fd\u6570\u548c\u7ec4\u5408\u6b63\u5219\u5316\u9879\uff0c\u53ef\u6269\u5c55\u5230\u975e\u51f8\u6b63\u5219\u5316\u3002\u57fa\u4e8e\u8be5\u6846\u67b6\u5f00\u53d1\u5206\u5e03\u5f0f\u5e76\u884cADMM\u7b97\u6cd5\uff0c\u5f15\u5165\u9ad8\u65af\u56de\u4ee3\u6cd5\u786e\u4fdd\u6536\u655b\uff0c\u5e76\u63d0\u51fa\u7a00\u758f\u7ec4\u5957\u7d22\u652f\u6301\u5411\u91cf\u673a\uff08SGL-SVM\uff09\u6a21\u578b\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u7b97\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0d\u53d7\u4e0d\u540c\u6b63\u5219\u5316\u9879\u548c\u635f\u5931\u51fd\u6570\u5f71\u54cd\uff0c\u5177\u6709\u666e\u9002\u6027\u3002\u5728\u5408\u6210\u548c\u514d\u8d39\u97f3\u4e50\u6863\u6848\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u53ef\u9760\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u4f18\u5316\u6846\u67b6\u548c\u5206\u5e03\u5f0f\u5e76\u884cADMM\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5b58\u50a8\u5927\u6570\u636e\u4e2dCR-SVMs\u7684\u8ba1\u7b97\u95ee\u9898\uff0c\u5728\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\uff0c\u5177\u6709\u5f3a\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.07486", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.07486", "abs": "https://arxiv.org/abs/2512.07486", "authors": ["Niklas Dobberstein", "Jan Hamaekers"], "title": "Materium: An Autoregressive Approach for Material Generation", "comment": null, "summary": "We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.", "AI": {"tldr": "Materium\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u6676\u4f53\u7ed3\u6784\u7684\u81ea\u56de\u5f52Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u5c063D\u6750\u6599\u8868\u793a\u8f6c\u6362\u4e3a\u5305\u542b\u5143\u7d20\u3001\u6c27\u5316\u6001\u3001\u5206\u6570\u5750\u6807\u548c\u6676\u683c\u53c2\u6570\u7684token\u5e8f\u5217\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u6676\u4f53\u7ed3\u6784\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u53bb\u566a\u6b65\u9aa4\u8fed\u4ee3\u7ec6\u5316\u539f\u5b50\u4f4d\u7f6e\uff0c\u751f\u6210\u901f\u5ea6\u6162\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5feb\u901f\u751f\u6210\u7cbe\u786e\u6676\u4f53\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u80fd\u591f\u57fa\u4e8e\u591a\u79cd\u6750\u6599\u5c5e\u6027\u8fdb\u884c\u6761\u4ef6\u751f\u6210\u3002", "method": "\u91c7\u7528\u81ea\u56de\u5f52Transformer\u67b6\u6784\uff0c\u5c063D\u6676\u4f53\u7ed3\u6784\u8f6c\u6362\u4e3a\u5305\u542b\u5143\u7d20\uff08\u5e26\u6c27\u5316\u6001\uff09\u3001\u5206\u6570\u5750\u6807\u548c\u6676\u683c\u53c2\u6570\u7684token\u5e8f\u5217\u3002\u6a21\u578b\u901a\u8fc7\u6761\u4ef6\u751f\u6210\u652f\u6301\u591a\u79cd\u6750\u6599\u5c5e\u6027\u4f5c\u4e3a\u8f93\u5165\u6761\u4ef6\uff0c\u5305\u62ec\u57fa\u672c\u5c5e\u6027\uff08\u5bc6\u5ea6\u3001\u7a7a\u95f4\u7fa4\uff09\u548c\u5b9e\u7528\u76ee\u6807\uff08\u5e26\u9699\u3001\u78c1\u5bc6\u5ea6\uff09\u3002", "result": "\u6a21\u578b\u5728\u5355\u4e2aGPU\u4e0a\u4ec5\u9700\u51e0\u5c0f\u65f6\u5373\u53ef\u5b8c\u6210\u8bad\u7ec3\uff0c\u5728GPU\u548cCPU\u4e0a\u751f\u6210\u901f\u5ea6\u8fdc\u8d85\u6269\u6563\u65b9\u6cd5\u3002\u5728\u5355\u4e00\u6761\u4ef6\u548c\u7ec4\u5408\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u4e00\u81f4\u826f\u597d\uff0c\u751f\u6210\u7684\u5019\u9009\u7ed3\u6784\u80fd\u591f\u51c6\u786e\u5339\u914d\u8bf7\u6c42\u7684\u8f93\u5165\u6761\u4ef6\u3002", "conclusion": "Materium\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5feb\u901f\u7684\u6676\u4f53\u7ed3\u6784\u751f\u6210\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u6269\u6563\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u540c\u65f6\u652f\u6301\u591a\u79cd\u6750\u6599\u5c5e\u6027\u7684\u6761\u4ef6\u751f\u6210\uff0c\u4e3a\u6750\u6599\u53d1\u73b0\u548c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2512.07490", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.07490", "abs": "https://arxiv.org/abs/2512.07490", "authors": ["Zhiyu Liu", "Zhi Han", "Yandong Tang", "Jun Fan", "Yao Wang"], "title": "Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent", "comment": null, "summary": "The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.", "AI": {"tldr": "\u63d0\u51fa\u4ea4\u66ff\u9884\u6761\u4ef6\u68af\u5ea6\u4e0b\u964d\uff08APGD\uff09\u7b97\u6cd5\uff0c\u89e3\u51b3\u4f4e\u7ba1\u79e9\u5f20\u91cf\u4f30\u8ba1\u4e2d\u8fc7\u53c2\u6570\u5316\u5bfc\u81f4\u7684\u6536\u655b\u7f13\u6162\u95ee\u9898\uff0c\u5373\u4f7f\u5728\u9ad8\u4f30\u79e9\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u7ebf\u6027\u6536\u655b\u3002", "motivation": "\u4f4e\u7ba1\u79e9\u5f20\u91cf\u4f30\u8ba1\u662f\u4fe1\u53f7\u5904\u7406\u3001\u673a\u5668\u5b66\u4e60\u548c\u56fe\u50cf\u79d1\u5b66\u4e2d\u7684\u57fa\u7840\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u5f20\u91cf\u5947\u5f02\u503c\u5206\u89e3\u8ba1\u7b97\u91cf\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5f20\u91cf\u3002\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u56e0\u5b50\u5206\u89e3\u65b9\u6cd5\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u5f20\u91cf\u79e9\uff0c\u5f53\u79e9\u88ab\u9ad8\u4f30\u65f6\u6536\u655b\u663e\u8457\u53d8\u6162\u751a\u81f3\u53d1\u6563\u3002", "method": "\u63d0\u51fa\u4ea4\u66ff\u9884\u6761\u4ef6\u68af\u5ea6\u4e0b\u964d\uff08APGD\uff09\u7b97\u6cd5\uff1a1\uff09\u5728\u539f\u59cb\u68af\u5ea6\u4e0a\u6dfb\u52a0\u9884\u6761\u4ef6\u9879\uff1b2\uff09\u4ea4\u66ff\u66f4\u65b0\u4e24\u4e2a\u56e0\u5b50\u5f20\u91cf\uff1b3\uff09\u57fa\u4e8e\u76ee\u6807\u51fd\u6570\u7684\u51e0\u4f55\u5047\u8bbe\u5efa\u7acb\u7ebf\u6027\u6536\u655b\u4fdd\u8bc1\uff1b4\uff09\u5206\u6790\u4f4e\u7ba1\u79e9\u5f20\u91cf\u5206\u89e3\u548c\u6062\u590d\u7684\u5177\u4f53\u60c5\u51b5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eAPGD\u5373\u4f7f\u5728\u8fc7\u53c2\u6570\u5316\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u7ebf\u6027\u6536\u655b\uff0c\u4e14\u6536\u655b\u7387\u4e0e\u5f20\u91cf\u6761\u4ef6\u6570\u65e0\u5173\u3002\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u5927\u91cf\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u65ad\u8a00\u3002", "conclusion": "APGD\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u7ba1\u79e9\u5f20\u91cf\u4f30\u8ba1\u4e2d\u8fc7\u53c2\u6570\u5316\u5bfc\u81f4\u7684\u6536\u655b\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u5f20\u91cf\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u9a8c\u8bc1\u3002"}}
{"id": "2512.07509", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07509", "abs": "https://arxiv.org/abs/2512.07509", "authors": ["Nikita Gabdullin"], "title": "Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces", "comment": "9 pages, 5 figures, 1 table, 4 equations", "summary": "The overall neural network (NN) performance is closely related to the properties of its embedding distribution in latent space (LS). It has recently been shown that predefined vector systems, specifically An root system vectors, can be used as targets for latent space configurations (LSC) to ensure the desired LS structure. One of the main LSC advantage is the possibility of training classifier NNs without classification layers, which facilitates training NNs on datasets with extremely large numbers of classes. This paper provides a more general overview of possible vector systems for NN training along with their properties and methods for vector system construction. These systems are used to configure LS of encoders and visual transformers to significantly speed up ImageNet-1K and 50k-600k classes LSC training. It is also shown that using the minimum number of LS dimensions for a specific number of classes results in faster convergence. The latter has potential advantages for reducing the size of vector databases used to store NN embeddings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u9884\u5b9a\u4e49\u5411\u91cf\u7cfb\u7edf\uff08\u5982An\u6839\u7cfb\u7edf\uff09\u4f5c\u4e3a\u6f5c\u5728\u7a7a\u95f4\u914d\u7f6e\u76ee\u6807\uff0c\u4ee5\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u5206\u5e03\uff0c\u4ece\u800c\u52a0\u901f\u5927\u89c4\u6a21\u5206\u7c7b\u4efb\u52a1\u7684\u8bad\u7ec3\uff0c\u5e76\u51cf\u5c11\u5411\u91cf\u6570\u636e\u5e93\u7684\u5b58\u50a8\u9700\u6c42\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u4e0e\u5176\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5d4c\u5165\u5206\u5e03\u7279\u6027\u5bc6\u5207\u76f8\u5173\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u6781\u591a\u7c7b\u522b\u6570\u636e\u96c6\u65f6\u9762\u4e34\u5206\u7c7b\u5c42\u8bad\u7ec3\u56f0\u96be\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6f5c\u5728\u7a7a\u95f4\u914d\u7f6e\u65b9\u6cd5\u6765\u52a0\u901f\u8bad\u7ec3\u5e76\u4f18\u5316\u5b58\u50a8\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u9884\u5b9a\u4e49\u5411\u91cf\u7cfb\u7edf\uff08\u7279\u522b\u662fAn\u6839\u7cfb\u7edf\uff09\u4f5c\u4e3a\u6f5c\u5728\u7a7a\u95f4\u914d\u7f6e\u76ee\u6807\uff0c\u6784\u5efa\u7cfb\u7edf\u5316\u7684\u5411\u91cf\u7cfb\u7edf\u7528\u4e8e\u7f16\u7801\u5668\u548c\u89c6\u89c9\u53d8\u6362\u5668\u7684\u8bad\u7ec3\uff0c\u63a2\u7d22\u6700\u5c0f\u6f5c\u5728\u7a7a\u95f4\u7ef4\u5ea6\u914d\u7f6e\u4ee5\u52a0\u901f\u6536\u655b\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u52a0\u901f\u4e86ImageNet-1K\u548c50k-600k\u7c7b\u522b\u6570\u636e\u96c6\u7684\u8bad\u7ec3\uff0c\u4f7f\u7528\u6700\u5c0f\u6f5c\u5728\u7a7a\u95f4\u7ef4\u5ea6\u80fd\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\uff0c\u5e76\u6709\u671b\u51cf\u5c11\u5b58\u50a8\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u7684\u5411\u91cf\u6570\u636e\u5e93\u5927\u5c0f\u3002", "conclusion": "\u9884\u5b9a\u4e49\u5411\u91cf\u7cfb\u7edf\u4e3a\u795e\u7ecf\u7f51\u7edc\u6f5c\u5728\u7a7a\u95f4\u914d\u7f6e\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u7c7b\u4efb\u52a1\uff0c\u65e2\u80fd\u52a0\u901f\u8bad\u7ec3\u53c8\u80fd\u4f18\u5316\u5b58\u50a8\u6548\u7387\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.07519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07519", "abs": "https://arxiv.org/abs/2512.07519", "authors": ["Alexander Gammerman"], "title": "Machine Learning: Progress and Prospects", "comment": "Inaugural Lecture. 18 pages, 13 figures, Published in 1997 by Royal Holloway, University of London, ISBN 0 900145 93 5", "summary": "This Inaugural Lecture was given at Royal Holloway University of London in 1996. It covers an introduction to machine learning and describes various theoretical advances and practical projects in the field. The Lecture here is presented in its original format, but a few remarks have been added in 2025 to reflect recent developments, and the list of references has been updated to enhance the convenience and accuracy for readers.\n  When did machine learning start? Maybe a good starting point is 1949, when Claude Shannon proposed a learning algorithm for chess-playing programs. Or maybe we should go back to the 1930s when Ronald Fisher developed discriminant analysis - a type of learning where the problem is to construct a decision rule that separates two types of vectors. Or could it be the 18th century when David Hume discussed the idea of induction? Or the 14th century, when William of Ockham formulated the principle of \"simplicity\" known as \"Ockham's razor\" (Ockham, by the way, is a small village not far from Royal Holloway). Or it may be that, like almost everything else in Western civilisation and culture, the origin of these ideas lies in the Mediterranean. After all, it was Aristotle who said that \"we learn some things only by doing things\".\n  The field of machine learning has been greatly influenced by other disciplines and the subject is in itself not a very homogeneous discipline, but includes separate, overlapping subfields. There are many parallel lines of research in ML: inductive learning, neural networks, clustering, and theories of learning. They are all part of the more general field of machine learning.", "AI": {"tldr": "\u8fd9\u7bc71996\u5e74\u7684\u5c31\u804c\u8bb2\u5ea7\u56de\u987e\u4e86\u673a\u5668\u5b66\u4e60\u7684\u5386\u53f2\u8d77\u6e90\uff0c\u4ece14\u4e16\u7eaa\u7684\u5965\u5361\u59c6\u5243\u5200\u523020\u4e16\u7eaa\u4e2d\u53f6\u7684\u7b97\u6cd5\u53d1\u5c55\uff0c\u5e76\u8ba8\u8bba\u4e86\u673a\u5668\u5b66\u4e60\u4f5c\u4e3a\u591a\u5b66\u79d1\u4ea4\u53c9\u9886\u57df\u7684\u73b0\u72b6\u3002", "motivation": "\u8bb2\u5ea7\u65e8\u5728\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u7684\u8d77\u6e90\u548c\u53d1\u5c55\u5386\u7a0b\uff0c\u5c55\u793a\u8fd9\u4e00\u9886\u57df\u6df1\u539a\u7684\u5386\u53f2\u6839\u57fa\u548c\u591a\u5143\u7684\u5b66\u79d1\u80cc\u666f\uff0c\u5e2e\u52a9\u542c\u4f17\u7406\u89e3\u673a\u5668\u5b66\u4e60\u5e76\u975e\u65b0\u5174\u6280\u672f\uff0c\u800c\u662f\u6709\u7740\u60a0\u4e45\u7684\u601d\u60f3\u6e0a\u6e90\u3002", "method": "\u91c7\u7528\u5386\u53f2\u56de\u987e\u548c\u601d\u60f3\u6eaf\u6e90\u7684\u65b9\u6cd5\uff0c\u4ece\u54f2\u5b66\u3001\u7edf\u8ba1\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u7b49\u591a\u4e2a\u89d2\u5ea6\u8ffd\u6eaf\u673a\u5668\u5b66\u4e60\u601d\u60f3\u7684\u8d77\u6e90\uff0c\u5305\u62ec\u5965\u5361\u59c6\u5243\u5200\u3001\u5f52\u7eb3\u6cd5\u3001\u5224\u522b\u5206\u6790\u7b49\u6838\u5fc3\u6982\u5ff5\u7684\u53d1\u5c55\u8109\u7edc\u3002", "result": "\u660e\u786e\u4e86\u673a\u5668\u5b66\u4e60\u7684\u601d\u60f3\u6839\u6e90\u53ef\u4ee5\u8ffd\u6eaf\u5230\u53e4\u4ee3\u54f2\u5b66\uff08\u4e9a\u91cc\u58eb\u591a\u5fb7\uff09\u3001\u4e2d\u4e16\u7eaa\u903b\u8f91\uff08\u5965\u5361\u59c6\uff09\u3001\u8fd1\u4ee3\u7edf\u8ba1\u5b66\uff08\u8d39\u820d\u5c14\uff09\u548c\u73b0\u4ee3\u8ba1\u7b97\u673a\u79d1\u5b66\uff08\u9999\u519c\uff09\uff0c\u5c55\u793a\u4e86\u8be5\u9886\u57df\u4f5c\u4e3a\u591a\u5b66\u79d1\u878d\u5408\u7684\u7279\u70b9\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u662f\u4e00\u4e2a\u5386\u53f2\u60a0\u4e45\u3001\u601d\u60f3\u6e0a\u6e90\u6df1\u539a\u7684\u9886\u57df\uff0c\u5b83\u878d\u5408\u4e86\u54f2\u5b66\u3001\u7edf\u8ba1\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u7b49\u591a\u4e2a\u5b66\u79d1\uff0c\u5305\u542b\u5f52\u7eb3\u5b66\u4e60\u3001\u795e\u7ecf\u7f51\u7edc\u3001\u805a\u7c7b\u7b49\u591a\u4e2a\u7814\u7a76\u65b9\u5411\uff0c\u6784\u6210\u4e86\u4e00\u4e2a\u4e30\u5bcc\u800c\u591a\u5143\u7684\u5b66\u672f\u9886\u57df\u3002"}}
{"id": "2512.07528", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07528", "abs": "https://arxiv.org/abs/2512.07528", "authors": ["Nishanth Venkatesh", "Andreas A. Malikopoulos"], "title": "Model-Based Reinforcement Learning Under Confounding", "comment": "9 pages, 2 figures - decompressed draft", "summary": "We investigate model-based reinforcement learning in contextual Markov decision processes (C-MDPs) in which the context is unobserved and induces confounding in the offline dataset. In such settings, conventional model-learning methods are fundamentally inconsistent, as the transition and reward mechanisms generated under a behavioral policy do not correspond to the interventional quantities required for evaluating a state-based policy. To address this issue, we adapt a proximal off-policy evaluation approach that identifies the confounded reward expectation using only observable state-action-reward trajectories under mild invertibility conditions on proxy variables. When combined with a behavior-averaged transition model, this construction yields a surrogate MDP whose Bellman operator is well defined and consistent for state-based policies, and which integrates seamlessly with the maximum causal entropy (MaxCausalEnt) model-learning framework. The proposed formulation enables principled model learning and planning in confounded environments where contextual information is unobserved, unavailable, or impractical to collect.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u4e0a\u4e0b\u6587\u672a\u89c2\u6d4b\u7684\u6df7\u6dc6\u73af\u5883\u4e2d\u8fdb\u884c\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ee3\u7406\u53d8\u91cf\u8bc6\u522b\u5956\u52b1\u671f\u671b\uff0c\u7ed3\u5408\u884c\u4e3a\u5e73\u5747\u8f6c\u79fb\u6a21\u578b\u6784\u5efa\u66ff\u4ee3MDP\uff0c\u5b9e\u73b0\u4e00\u81f4\u7684\u653f\u7b56\u8bc4\u4f30", "motivation": "\u5728\u4e0a\u4e0b\u6587\u672a\u89c2\u6d4b\u7684C-MDPs\u4e2d\uff0c\u4f20\u7edf\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u4e0d\u4e00\u81f4\u6027\uff0c\u56e0\u4e3a\u884c\u4e3a\u653f\u7b56\u4e0b\u7684\u8f6c\u79fb\u548c\u5956\u52b1\u673a\u5236\u4e0e\u8bc4\u4f30\u72b6\u6001\u653f\u7b56\u6240\u9700\u7684\u5e72\u9884\u91cf\u4e0d\u5bf9\u5e94\uff0c\u9700\u8981\u89e3\u51b3\u6df7\u6dc6\u73af\u5883\u4e0b\u7684\u6a21\u578b\u5b66\u4e60\u548c\u89c4\u5212\u95ee\u9898", "method": "\u91c7\u7528\u8fd1\u7aef\u79bb\u653f\u7b56\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u7528\u4ee3\u7406\u53d8\u91cf\u7684\u6e29\u548c\u53ef\u9006\u6027\u6761\u4ef6\u8bc6\u522b\u6df7\u6dc6\u5956\u52b1\u671f\u671b\uff1b\u7ed3\u5408\u884c\u4e3a\u5e73\u5747\u8f6c\u79fb\u6a21\u578b\u6784\u5efa\u66ff\u4ee3MDP\uff0c\u5176\u8d1d\u5c14\u66fc\u7b97\u5b50\u5bf9\u72b6\u6001\u653f\u7b56\u5b9a\u4e49\u826f\u597d\u4e14\u4e00\u81f4\uff1b\u4e0e\u6700\u5927\u56e0\u679c\u71b5\u6a21\u578b\u5b66\u4e60\u6846\u67b6\u65e0\u7f1d\u96c6\u6210", "result": "\u63d0\u51fa\u7684\u516c\u5f0f\u80fd\u591f\u5728\u4e0a\u4e0b\u6587\u4fe1\u606f\u672a\u89c2\u6d4b\u3001\u4e0d\u53ef\u7528\u6216\u6536\u96c6\u4e0d\u5207\u5b9e\u9645\u7684\u6df7\u6dc6\u73af\u5883\u4e2d\u5b9e\u73b0\u539f\u5219\u6027\u6a21\u578b\u5b66\u4e60\u548c\u89c4\u5212\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6df7\u6dc6\u73af\u5883\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7406\u53d8\u91cf\u8bc6\u522b\u548c\u66ff\u4ee3MDP\u6784\u5efa\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0a\u4e0b\u6587\u4fe1\u606f\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6a21\u578b\u5b66\u4e60\u548c\u653f\u7b56\u8bc4\u4f30"}}
{"id": "2512.07539", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07539", "abs": "https://arxiv.org/abs/2512.07539", "authors": ["Qingyuan Yang", "Shizhuo", "Dongyue Chen", "Da Teng", "Zehua Gan"], "title": "FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting", "comment": null, "summary": "Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.", "AI": {"tldr": "FRWKV\uff1a\u7ed3\u5408\u7ebf\u6027\u6ce8\u610f\u529b\u4e0e\u9891\u57df\u5206\u6790\u7684\u65f6\u5e8f\u9884\u6d4b\u6846\u67b6\uff0c\u5b9e\u73b0O(T)\u590d\u6742\u5ea6\u5e76\u57288\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u6700\u4f73\u5e73\u5747\u6392\u540d", "motivation": "\u4f20\u7edfTransformer\u5728\u957f\u5e8f\u5217\u65f6\u5e8f\u9884\u6d4b\u4e2d\u5b58\u5728\u4e24\u5927\u74f6\u9888\uff1a1\uff09\u4e8c\u6b21\u590d\u6742\u5ea6O(T\u00b2)\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\uff1b2\uff09\u5bf9\u9891\u57df\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u53c8\u80fd\u6709\u6548\u5229\u7528\u9891\u57df\u4fe1\u606f\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFRWKV\u6846\u67b6\uff0c\u7ed3\u5408RWKV\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff08O(T)\u590d\u6742\u5ea6\uff09\u4e0e\u9891\u57df\u5206\u6790\uff0c\u901a\u8fc7\u9891\u57df\u7f16\u7801\u5668\u589e\u5f3a\u65f6\u5e8f\u7279\u5f81\u8868\u793a\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u957f\u5e8f\u5217\u5efa\u6a21\u3002", "result": "\u57288\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cFRWKV\u53d6\u5f97\u4e86\u7b2c\u4e00\u7684\u5e73\u5747\u6392\u540d\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u9891\u57df\u7f16\u7801\u5668\u4e24\u4e2a\u7ec4\u4ef6\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u7ebf\u6027\u6ce8\u610f\u529b\u4e0e\u9891\u57df\u5206\u6790\u7684\u7ed3\u5408\u4e3a\u53ef\u6269\u5c55\u65f6\u5e8f\u5efa\u6a21\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u8fd9\u4e24\u79cd\u6280\u672f\u7684\u5f3a\u5927\u534f\u540c\u6548\u5e94\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.07542", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07542", "abs": "https://arxiv.org/abs/2512.07542", "authors": ["Jad Mounayer", "Sebastian Rodriguez", "Jerome Tomezyk", "Chady Ghnatios", "Francisco Chinesta"], "title": "RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems", "comment": null, "summary": "Most existing latent-space models for dynamical systems require fixing the latent dimension in advance, they rely on complex loss balancing to approximate linear dynamics, and they don't regularize the latent variables. We introduce RRAEDy, a model that removes these limitations by discovering the appropriate latent dimension, while enforcing both regularized and linearized dynamics in the latent space. Built upon Rank-Reduction Autoencoders (RRAEs), RRAEDy automatically rank and prune latent variables through their singular values while learning a latent Dynamic Mode Decomposition (DMD) operator that governs their temporal progression. This structure-free yet linearly constrained formulation enables the model to learn stable and low-dimensional dynamics without auxiliary losses or manual tuning. We provide theoretical analysis demonstrating the stability of the learned operator and showcase the generality of our model by proposing an extension that handles parametric ODEs. Experiments on canonical benchmarks, including the Van der Pol oscillator, Burgers' equation, 2D Navier-Stokes, and Rotating Gaussians, show that RRAEDy achieves accurate and robust predictions. Our code is open-source and available at https://github.com/JadM133/RRAEDy. We also provide a video summarizing the main results at https://youtu.be/ox70mSSMGrM.", "AI": {"tldr": "RRAEDy\u662f\u4e00\u79cd\u81ea\u52a8\u53d1\u73b0\u5408\u9002\u6f5c\u5728\u7ef4\u5ea6\u3001\u540c\u65f6\u5f3a\u5236\u6f5c\u5728\u7a7a\u95f4\u6b63\u5219\u5316\u548c\u7ebf\u6027\u5316\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u8f85\u52a9\u635f\u5931\u51fd\u6570", "motivation": "\u73b0\u6709\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u9700\u8981\u9884\u5148\u56fa\u5b9a\u6f5c\u5728\u7ef4\u5ea6\uff0c\u4f9d\u8d56\u590d\u6742\u7684\u635f\u5931\u5e73\u8861\u6765\u8fd1\u4f3c\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u4e14\u4e0d\u5bf9\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u6b63\u5219\u5316", "method": "\u57fa\u4e8e\u79e9\u7ea6\u51cf\u81ea\u7f16\u7801\u5668(RRAE)\uff0c\u901a\u8fc7\u5947\u5f02\u503c\u81ea\u52a8\u6392\u5e8f\u548c\u526a\u679d\u6f5c\u5728\u53d8\u91cf\uff0c\u540c\u65f6\u5b66\u4e60\u63a7\u5236\u65f6\u95f4\u6f14\u5316\u7684\u6f5c\u5728\u52a8\u6001\u6a21\u6001\u5206\u89e3(DMD)\u7b97\u5b50", "result": "\u5728Van der Pol\u632f\u8361\u5668\u3001Burgers\u65b9\u7a0b\u30012D Navier-Stokes\u548c\u65cb\u8f6c\u9ad8\u65af\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u51c6\u786e\u548c\u9c81\u68d2\u7684\u9884\u6d4b", "conclusion": "RRAEDy\u901a\u8fc7\u65e0\u7ed3\u6784\u4f46\u7ebf\u6027\u7ea6\u675f\u7684\u516c\u5f0f\uff0c\u80fd\u591f\u5b66\u4e60\u7a33\u5b9a\u4e14\u4f4e\u7ef4\u7684\u52a8\u529b\u5b66\uff0c\u65e0\u9700\u8f85\u52a9\u635f\u5931\u6216\u624b\u52a8\u8c03\u53c2"}}
{"id": "2512.07558", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07558", "abs": "https://arxiv.org/abs/2512.07558", "authors": ["Shimin Zhang", "Xianwei Chen", "Yufan Shen", "Ziyuan Ye", "Jibin Wu"], "title": "ReLaX: Reasoning with Latent Exploration for Large Reasoning Models", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faReLaX\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u52a8\u6001\u6765\u8c03\u63a7\u63a2\u7d22\u4e0e\u5229\u7528\u5e73\u8861\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u5956\u52b1\u4e2d\u7684\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u867d\u7136\u80fd\u63d0\u5347\u5927\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5e38\u5bfc\u81f4\u71b5\u5d29\u6e83\uff0c\u9020\u6210\u7b56\u7565\u8fc7\u65e9\u6536\u655b\u548c\u6027\u80fd\u9971\u548c\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u64cd\u7eb5token\u7ea7\u71b5\u6765\u4fc3\u8fdb\u63a2\u7d22\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u6f5c\u5728\u52a8\u6001\u7f16\u7801\u4e86\u66f4\u4e30\u5bcc\u7684\u8ba1\u7b97\u7ed3\u6784\uff0c\u80fd\u66f4\u597d\u5730\u6307\u5bfc\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "method": "\u63d0\u51faReLaX\uff08Reasoning with Latent eXploration\uff09\u8303\u5f0f\uff1a1\uff09\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\u83b7\u5f97\u9690\u85cf\u72b6\u6001\u52a8\u6001\u7684\u7ebf\u6027\u5316\u8868\u793a\uff1b2\uff09\u5f15\u5165\u52a8\u6001\u8c31\u5206\u6563\uff08DSD\uff09\u6307\u6807\u91cf\u5316\u6f5c\u5728\u52a8\u6001\u7684\u5f02\u8d28\u6027\uff0c\u4f5c\u4e3a\u7b56\u7565\u63a2\u7d22\u7684\u76f4\u63a5\u6307\u6807\uff1b3\uff09\u5728\u7b56\u7565\u4f18\u5316\u4e2d\u663e\u5f0f\u7eb3\u5165\u6f5c\u5728\u52a8\u6001\u6765\u8c03\u63a7\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u548c\u7eaf\u6587\u672c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReLaX\u663e\u8457\u7f13\u89e3\u4e86\u8fc7\u65e9\u6536\u655b\u95ee\u9898\uff0c\u5e76\u6301\u7eed\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u52a8\u6001\u6765\u8c03\u63a7\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u662f\u6709\u6548\u7684\uff0cReLaX\u65b9\u6cd5\u4e3a\u89e3\u51b3RLVR\u4e2d\u7684\u71b5\u5d29\u6e83\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2512.07569", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07569", "abs": "https://arxiv.org/abs/2512.07569", "authors": ["Joel Ekstrand", "Tor Mattsson", "Zahra Taghiyarrenani", "Slawomir Nowaczyk", "Jens Lundstr\u00f6m", "Mikael Lind\u00e9n"], "title": "Weighted Contrastive Learning for Anomaly-Aware Time-Series Forecasting", "comment": null, "summary": "Reliable forecasting of multivariate time series under anomalous conditions is crucial in applications such as ATM cash logistics, where sudden demand shifts can disrupt operations. Modern deep forecasters achieve high accuracy on normal data but often fail when distribution shifts occur. We propose Weighted Contrastive Adaptation (WECA), a Weighted contrastive objective that aligns normal and anomaly-augmented representations, preserving anomaly-relevant information while maintaining consistency under benign variations. Evaluations on a nationwide ATM transaction dataset with domain-informed anomaly injection show that WECA improves SMAPE on anomaly-affected data by 6.1 percentage points compared to a normally trained baseline, with negligible degradation on normal data. These results demonstrate that WECA enhances forecasting reliability under anomalies without sacrificing performance during regular operations.", "AI": {"tldr": "WECA\u65b9\u6cd5\u901a\u8fc7\u52a0\u6743\u5bf9\u6bd4\u9002\u5e94\u63d0\u5347\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5728\u5f02\u5e38\u6761\u4ef6\u4e0b\u7684\u9884\u6d4b\u53ef\u9760\u6027\uff0c\u5728ATM\u73b0\u91d1\u7269\u6d41\u7b49\u5e94\u7528\u4e2d\u663e\u8457\u6539\u5584\u5f02\u5e38\u6570\u636e\u9884\u6d4b\u6027\u80fd", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u9884\u6d4b\u6a21\u578b\u5728\u6b63\u5e38\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5206\u5e03\u504f\u79fb\uff08\u5982\u5f02\u5e38\u6761\u4ef6\uff09\u4e0b\u5f80\u5f80\u5931\u6548\u3002\u5728ATM\u73b0\u91d1\u7269\u6d41\u7b49\u5e94\u7528\u4e2d\uff0c\u7a81\u53d1\u9700\u6c42\u53d8\u5316\u4f1a\u4e25\u91cd\u5e72\u6270\u8fd0\u8425\uff0c\u56e0\u6b64\u9700\u8981\u53ef\u9760\u7684\u5f02\u5e38\u6761\u4ef6\u4e0b\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u52a0\u6743\u5bf9\u6bd4\u9002\u5e94\uff08WECA\uff09\uff0c\u4f7f\u7528\u52a0\u6743\u5bf9\u6bd4\u76ee\u6807\u5bf9\u9f50\u6b63\u5e38\u548c\u5f02\u5e38\u589e\u5f3a\u7684\u8868\u793a\uff0c\u5728\u4fdd\u6301\u5f02\u5e38\u76f8\u5173\u4fe1\u606f\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u5728\u826f\u6027\u53d8\u5316\u4e0b\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5168\u56fdATM\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u5f02\u5e38\uff0cWECA\u5c06\u5f02\u5e38\u5f71\u54cd\u6570\u636e\u7684SMAPE\u63d0\u9ad8\u4e866.1\u4e2a\u767e\u5206\u70b9\uff0c\u800c\u5bf9\u6b63\u5e38\u6570\u636e\u7684\u6027\u80fd\u4e0b\u964d\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "WECA\u80fd\u591f\u5728\u4fdd\u6301\u6b63\u5e38\u64cd\u4f5c\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u589e\u5f3a\u5f02\u5e38\u6761\u4ef6\u4e0b\u7684\u9884\u6d4b\u53ef\u9760\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07624", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07624", "abs": "https://arxiv.org/abs/2512.07624", "authors": ["Yongbo Yu", "Jari Peeperkorn", "Johannes De Smedt", "Jochen De Weerdt"], "title": "Time Series Foundation Models for Process Model Forecasting", "comment": null, "summary": "Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u8fc7\u7a0b\u6a21\u578b\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u8de8\u9886\u57df\u65f6\u95f4\u7ed3\u6784\u8fc1\u79fb\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8fc7\u7a0b\u6a21\u578b\u9884\u6d4b\u65e8\u5728\u9884\u6d4b\u8fc7\u7a0b\u63a7\u5236\u6d41\u7ed3\u6784\u968f\u65f6\u95f4\u7684\u53d8\u5316\uff0c\u4f46\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7531\u4e8e\u76f4\u63a5\u8ddf\u968f\u5173\u7cfb\u65f6\u95f4\u5e8f\u5217\u7684\u7a00\u758f\u6027\u548c\u5f02\u8d28\u6027\uff0c\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002\u672c\u6587\u63a2\u7d22\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u5229\u7528\u5176\u9884\u8bad\u7ec3\u77e5\u8bc6\u6765\u6539\u8fdb\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u751f\u6210\u7684\u76f4\u63a5\u8ddf\u968f\u5173\u7cfb\u65f6\u95f4\u5e8f\u5217\uff0c\u6bd4\u8f83\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u96f6\u6837\u672c\u4f7f\u7528\uff08\u65e0\u989d\u5916\u8bad\u7ec3\uff09\u4e0e\u5728PMF\u7279\u5b9a\u6570\u636e\u4e0a\u5fae\u8c03\u7684\u53d8\u4f53\u3002\u4e0e\u4f20\u7edf\u548c\u4e13\u95e8\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8bc4\u4f30MAE\u548cRMSE\u7b49\u9884\u6d4b\u8bef\u5dee\u6307\u6807\u3002", "result": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u901a\u5e38\u6bd4\u4f20\u7edf\u65b9\u6cd5\u548c\u4e13\u95e8\u6a21\u578b\u83b7\u5f97\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u8868\u660e\u4ece\u975e\u8fc7\u7a0b\u9886\u57df\u6709\u6548\u8fc1\u79fb\u4e86\u65f6\u95f4\u7ed3\u6784\u77e5\u8bc6\u3002\u5fae\u8c03\u867d\u7136\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u589e\u76ca\u901a\u5e38\u8f83\u5c0f\uff0c\u5728\u8f83\u5c0f\u6216\u66f4\u590d\u6742\u7684\u6570\u636e\u96c6\u4e0a\u53ef\u80fd\u6d88\u5931\uff0c\u56e0\u6b64\u96f6\u6837\u672c\u4f7f\u7528\u4ecd\u662f\u5f3a\u5927\u7684\u9ed8\u8ba4\u9009\u62e9\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u8fc7\u7a0b\u76f8\u5173\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6570\u636e\u6548\u7387\uff0c\u4e3a\u8fc7\u7a0b\u6a21\u578b\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u662f\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u65f6\u95f4\u57fa\u7840\u6a21\u578b\u5728PMF\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2512.07647", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07647", "abs": "https://arxiv.org/abs/2512.07647", "authors": ["Georgios Tzachristas", "Lei Deng", "Ioannis Tzachristas", "Gong Zhang", "Renhai Chen"], "title": "A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance", "comment": null, "summary": "We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\\mathrm{TV}(P,\\hat P)=1-e^{-\\mathrm{KL}(\\hat P\\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\\mathrm{TV}(P,\\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\\|\\mathrm{Attn}(q,K,V)-\\mathrm{Attn}_k(q,K,V)\\|_2=\u03c4\\|\u03bc_{\\mathrm{tail}}-\u03bc_{\\mathrm{head}}\\|_2$ with $\u03c4=\\mathrm{TV}(P,\\hat P)$, yielding a new head-tail diameter bound $\\|\\mathrm{Attn}(q,K,V)-\\mathrm{Attn}_k(q,K,V)\\|_2\\le\u03c4\\,\\mathrm{diam}_{H,T}$ and refinements linking the error to $\\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\\sim\\mathcal N(\u03bc,\u03c3^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\\varepsilon$ ensuring $\\mathrm{TV}(P,\\hat P)\\le\\varepsilon$, namely $k_\\varepsilon/n\\approx\u03a6_c(\u03c3+\u03a6^{-1}(\\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\\times$ on average while meeting the prescribed total-variation budget.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8ba4\u8bc1Top-k\u6ce8\u610f\u529b\u622a\u65ad\u7684\u7edf\u4e00\u6570\u5b66\u6846\u67b6\uff0c\u91cf\u5316\u4e86\u5206\u5e03\u548c\u8f93\u51fa\u5c42\u9762\u7684\u8fd1\u4f3c\u8bef\u5dee\uff0c\u63a8\u5bfc\u51fa\u975e\u6e10\u8fd1\u786e\u5b9a\u6027\u8fb9\u754c\uff0c\u5e76\u5728\u9ad8\u65af\u8bc4\u5206\u6a21\u578b\u4e0b\u5f97\u5230\u95ed\u5f0f\u89e3\u3002", "motivation": "\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684Top-k\u622a\u65ad\u867d\u7136\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u4e25\u683c\u7684\u8bef\u5dee\u91cf\u5316\u7406\u8bba\u6846\u67b6\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u7ecf\u9a8c\u89c4\u5219\uff0c\u65e0\u6cd5\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u8bef\u5dee\u4fdd\u8bc1\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5206\u6790\u6ce8\u610f\u529b\u5206\u5e03P\u4e0e\u5176Top-k\u622a\u65adP\u0302\u4e4b\u95f4\u7684\u603b\u53d8\u5dee\u8ddd\u79bb\uff0c\u63a8\u5bfc\u51fa\u4e0eKL\u6563\u5ea6\u7684\u7cbe\u786e\u5173\u7cfb\u3002\u63d0\u51fa\u8fb9\u754c\u95f4\u9699\u3001\u591a\u95f4\u9699\u548c\u5206\u5757\u53d8\u4f53\u7b49\u975e\u6e10\u8fd1\u786e\u5b9a\u6027\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u5934\u5c3e\u5206\u89e3\u5206\u6790\u8f93\u51fa\u8bef\u5dee\u3002", "result": "\u8bc1\u660e\u4e86\u603b\u53d8\u5dee\u8ddd\u79bb\u7b49\u4e8e\u4e22\u5f03\u7684softmax\u5c3e\u90e8\u8d28\u91cf\uff0c\u8f93\u51fa\u8bef\u5dee\u53ef\u5206\u89e3\u4e3a\u03c4\u2225\u03bc_tail-\u03bc_head\u2225\u2082\u3002\u5728\u9ad8\u65af\u8bc4\u5206\u6a21\u578b\u4e0b\u5f97\u5230\u95ed\u5f0f\u5c3e\u90e8\u8d28\u91cf\u548c\u6700\u5c0fk_\u03b5\u7684\u6e10\u8fd1\u89c4\u5219\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aTop-k\u6ce8\u610f\u529b\u622a\u65ad\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u8bef\u5dee\u8ba4\u8bc1\uff0c\u80fd\u591f\u5728\u6ee1\u8db3\u603b\u53d8\u5dee\u9884\u7b97\u7684\u540c\u65f6\u5e73\u5747\u51cf\u5c112-4\u500d\u7684\u8bc4\u5206\u952e\u6570\u91cf\uff0c\u4e3a\u9ad8\u6548\u6ce8\u610f\u529b\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2512.07667", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07667", "abs": "https://arxiv.org/abs/2512.07667", "authors": ["Gracjan G\u00f3ral", "Marysia Winkels", "Steven Basart"], "title": "Depth-Wise Activation Steering for Honest Language Models", "comment": "See \\url{https://github.com/marysia/gaussian-activation-steering}. for code and experiments", "summary": "Large language models sometimes assert falsehoods despite internally representing the correct answer, failures of honesty rather than accuracy, which undermines auditability and safety. Existing approaches largely optimize factual correctness or depend on retraining and brittle single-layer edits, offering limited leverage over truthful reporting. We present a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, we evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no finetuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u65af\u8c03\u5ea6\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u7f51\u7edc\u6df1\u5ea6\u5206\u914d\u5f15\u5bfc\u5f3a\u5ea6\u6765\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u7684\u8bda\u5b9e\u6027\uff0c\u800c\u975e\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u65f6\u4f1a\u9648\u8ff0\u9519\u8bef\u4fe1\u606f\uff0c\u5c3d\u7ba1\u5185\u90e8\u77e5\u9053\u6b63\u786e\u7b54\u6848\uff0c\u8fd9\u662f\u8bda\u5b9e\u6027\u800c\u975e\u51c6\u786e\u6027\u7684\u5931\u8d25\uff0c\u4f1a\u524a\u5f31\u53ef\u5ba1\u8ba1\u6027\u548c\u5b89\u5168\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u4e8b\u5b9e\u6b63\u786e\u6027\u6216\u4f9d\u8d56\u91cd\u65b0\u8bad\u7ec3\u548c\u8106\u5f31\u7684\u5355\u5c42\u7f16\u8f91\uff0c\u5bf9\u771f\u5b9e\u62a5\u544a\u7684\u63a7\u5236\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\uff0c\u4f7f\u7528\u9ad8\u65af\u8c03\u5ea6\u5728\u591a\u4e2a\u7f51\u7edc\u6df1\u5ea6\u4e0a\u52a0\u6743\u5f15\u5bfc\u5f3a\u5ea6\u3002\u8be5\u65b9\u6cd5\u7b80\u5355\u3001\u6a21\u578b\u65e0\u5173\u3001\u65e0\u9700\u5fae\u8c03\uff0c\u4e3a\u4ece\u6a21\u578b\u73b0\u6709\u80fd\u529b\u4e2d\u5f15\u51fa\u771f\u5b9e\u62a5\u544a\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u63a7\u5236\u624b\u6bb5\u3002", "result": "\u5728MASK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff08\u5206\u79bb\u8bda\u5b9e\u6027\u4e0e\u77e5\u8bc6\uff09\uff0c\u8bc4\u4f30\u4e86LLaMA\u3001Qwen\u548cMistral\u5bb6\u65cf\u7684\u4e03\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u9ad8\u65af\u8c03\u5ea6\u5728\u516d\u4e2a\u6a21\u578b\u4e2d\u6bd4\u65e0\u5f15\u5bfc\u548c\u5355\u5c42\u57fa\u7ebf\u63d0\u9ad8\u4e86\u8bda\u5b9e\u6027\u3002\u5728LLaMA-3.1-8B-Instruct\u548cQwen-2.5-7B-Instruct\u4e0a\u7684\u7b49\u9884\u7b97\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff0c\u9ad8\u65af\u8c03\u5ea6\u4f18\u4e8e\u968f\u673a\u3001\u5747\u5300\u548c\u76d2\u6ee4\u6ce2\u5668\u6df1\u5ea6\u5206\u914d\u3002", "conclusion": "\u9ad8\u65af\u8c03\u5ea6\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u8868\u660e\uff0c\u5982\u4f55\u5728\u6df1\u5ea6\u4e0a\u5206\u914d\u5e72\u9884\u5bf9\u7ed3\u679c\u6709\u5b9e\u8d28\u6027\u5f71\u54cd\uff0c\u8d85\u8d8a\u4e86\u603b\u5f3a\u5ea6\u7684\u5f71\u54cd\u3002\u8be5\u65b9\u6cd5\u4e3a\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u5f15\u51fa\u771f\u5b9e\u62a5\u544a\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u63a7\u5236\u624b\u6bb5\u3002"}}
{"id": "2512.07676", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.07676", "abs": "https://arxiv.org/abs/2512.07676", "authors": ["Hongjian Lan", "Yucong Liu", "Florian Sch\u00e4fer"], "title": "A Bootstrap Perspective on Stochastic Gradient Descent", "comment": null, "summary": "Machine learning models trained with \\emph{stochastic} gradient descent (SGD) can generalize better than those trained with deterministic gradient descent (GD). In this work, we study SGD's impact on generalization through the lens of the statistical bootstrap: SGD uses gradient variability under batch sampling as a proxy for solution variability under the randomness of the data collection process. We use empirical results and theoretical analysis to substantiate this claim. In idealized experiments on empirical risk minimization, we show that SGD is drawn to parameter choices that are robust under resampling and thus avoids spurious solutions even if they lie in wider and deeper minima of the training loss. We prove rigorously that by implicitly regularizing the trace of the gradient covariance matrix, SGD controls the algorithmic variability. This regularization leads to solutions that are less sensitive to sampling noise, thereby improving generalization. Numerical experiments on neural network training show that explicitly incorporating the estimate of the algorithmic variability as a regularizer improves test performance. This fact supports our claim that bootstrap estimation underpins SGD's generalization advantages.", "AI": {"tldr": "SGD\u901a\u8fc7\u68af\u5ea6\u534f\u65b9\u5dee\u77e9\u9635\u7684\u8ff9\u6b63\u5219\u5316\u63a7\u5236\u7b97\u6cd5\u53d8\u5f02\u6027\uff0c\u5229\u7528\u6279\u6b21\u91c7\u6837\u7684\u68af\u5ea6\u53d8\u5f02\u6027\u4f5c\u4e3a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u968f\u673a\u6027\u7684\u4ee3\u7406\uff0c\u4ece\u800c\u907f\u514d\u865a\u5047\u89e3\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7814\u7a76SGD\u76f8\u6bd4\u786e\u5b9a\u6027\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u5177\u6709\u66f4\u597d\u6cdb\u5316\u80fd\u529b\u7684\u539f\u56e0\u3002\u4f5c\u8005\u8ba4\u4e3aSGD\u7684\u6cdb\u5316\u4f18\u52bf\u6e90\u4e8e\u5176\u901a\u8fc7\u6279\u6b21\u91c7\u6837\u7684\u68af\u5ea6\u53d8\u5f02\u6027\u6765\u8fd1\u4f3c\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u7684\u968f\u673a\u6027\uff0c\u7c7b\u4f3c\u4e8e\u7edf\u8ba1bootstrap\u65b9\u6cd5\u3002", "method": "1. \u5728\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u7684\u7406\u60f3\u5316\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1SGD\u503e\u5411\u4e8e\u9009\u62e9\u5bf9\u91cd\u91c7\u6837\u9c81\u68d2\u7684\u89e3\uff1b2. \u7406\u8bba\u8bc1\u660eSGD\u901a\u8fc7\u9690\u5f0f\u6b63\u5219\u5316\u68af\u5ea6\u534f\u65b9\u5dee\u77e9\u9635\u7684\u8ff9\u6765\u63a7\u5236\u7b97\u6cd5\u53d8\u5f02\u6027\uff1b3. \u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\uff0c\u5c06\u7b97\u6cd5\u53d8\u5f02\u6027\u4f30\u8ba1\u4f5c\u4e3a\u663e\u5f0f\u6b63\u5219\u5668\u6765\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "1. SGD\u80fd\u591f\u907f\u514d\u8bad\u7ec3\u635f\u5931\u4e2d\u66f4\u5bbd\u66f4\u6df1\u7684\u865a\u5047\u89e3\uff1b2. \u7406\u8bba\u5206\u6790\u8868\u660eSGD\u901a\u8fc7\u63a7\u5236\u7b97\u6cd5\u53d8\u5f02\u6027\u4f7f\u89e3\u5bf9\u91c7\u6837\u566a\u58f0\u4e0d\u654f\u611f\uff1b3. \u795e\u7ecf\u7f51\u7edc\u5b9e\u9a8c\u4e2d\uff0c\u663e\u5f0f\u52a0\u5165\u7b97\u6cd5\u53d8\u5f02\u6027\u6b63\u5219\u5668\u80fd\u591f\u63d0\u5347\u6d4b\u8bd5\u6027\u80fd\u3002", "conclusion": "SGD\u7684\u6cdb\u5316\u4f18\u52bf\u6e90\u4e8e\u5176bootstrap\u4f30\u8ba1\u673a\u5236\uff1a\u901a\u8fc7\u6279\u6b21\u91c7\u6837\u7684\u68af\u5ea6\u53d8\u5f02\u6027\u4f5c\u4e3a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u968f\u673a\u6027\u7684\u4ee3\u7406\uff0c\u9690\u5f0f\u6b63\u5219\u5316\u68af\u5ea6\u534f\u65b9\u5dee\u77e9\u9635\u7684\u8ff9\uff0c\u4ece\u800c\u63a7\u5236\u7b97\u6cd5\u53d8\u5f02\u6027\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.07705", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07705", "abs": "https://arxiv.org/abs/2512.07705", "authors": ["Saroj Gopali", "Bipin Chhetri", "Deepika Giri", "Sima Siami-Namini", "Akbar Siami Namin"], "title": "In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models", "comment": null, "summary": "Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.\n  This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.\n  These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u4f20\u7edf\u65b9\u6cd5\uff08ARIMA\u3001LSTM\u3001TCN\uff09\u4e0e\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff08TimesFM\u3001LLMs\uff09\u7684\u6027\u80fd\uff0c\u53d1\u73b0TimesFM\u5728RMSE\u548c\u63a8\u7406\u65f6\u95f4\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff08\u5982LLMs\u548cTimesFM\uff09\u7684\u53d1\u5c55\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u80fd\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\uff08ARIMA\u3001LSTM\u3001TCN\u7b49\uff09\uff0c\u7279\u522b\u662f\u5728\u5b9e\u65f6\u9884\u6d4b\u573a\u666f\u4e2d\u3002", "method": "\u7814\u7a76\u4e86LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u63a2\u7d22\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u96f6\u6837\u672c\u5b66\u4e60\u548c\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u3002\u4f7f\u7528\u4e86OpenAI o4-mini\u3001Gemini 2.5 Flash Lite\u3001Google\u7684TimesFM\uff0c\u4ee5\u53caTCN\u548cLSTM\u7f51\u7edc\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "TimesFM\u8868\u73b0\u6700\u4f73\uff0c\u5177\u6709\u6700\u4f4e\u7684RMSE\u503c\uff080.3023\uff09\u548c\u7ade\u4e89\u529b\u7684\u63a8\u7406\u65f6\u95f4\uff08266\u79d2\uff09\u3002OpenAI\u7684o4-mini\u5728\u96f6\u6837\u672c\u5b66\u4e60\u4e2d\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u9884\u8bad\u7ec3\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u662f\u5b9e\u65f6\u9884\u6d4b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u6a21\u578b\u9002\u5e94\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u90e8\u7f72\u3002"}}
{"id": "2512.07723", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07723", "abs": "https://arxiv.org/abs/2512.07723", "authors": ["Yonggeon Lee", "Jibin Hwang", "Alfred Malengo Kondoro", "Juhyun Song", "Youngtae Noh"], "title": "Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity", "comment": "16 pages, 9 figures, AAAI'26 (accepted)", "summary": "Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \\ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \\ours algorithm and its contribution to sustainable transportation systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5230\u4e8b\u4ef6\u6a21\u578b\uff0c\u7528\u4e8e\u51c6\u786e\u9884\u6d4b\u7535\u52a8\u6c7d\u8f66\u7528\u6237\u7684\u51fa\u53d1\u65f6\u95f4\uff0c\u4ee5\u4f18\u5316\u5145\u7535\u7b56\u7565\u5ef6\u957f\u7535\u6c60\u5bff\u547d", "motivation": "\u7535\u52a8\u6c7d\u8f66\u9502\u79bb\u5b50\u7535\u6c60\u5728\u957f\u65f6\u95f4\u9ad8\u7535\u91cf\u72b6\u6001\u4e0b\u4f1a\u52a0\u901f\u9000\u5316\uff0c\u53ef\u4ee5\u901a\u8fc7\u5ef6\u8fdf\u5145\u6ee1\u7535\u76f4\u5230\u51fa\u53d1\u524d\u7f13\u89e3\uff0c\u8fd9\u9700\u8981\u51c6\u786e\u9884\u6d4b\u7528\u6237\u51fa\u53d1\u65f6\u95f4", "method": "\u4f7f\u7528Transformer\u67b6\u6784\u7684\u5b9e\u65f6\u5230\u4e8b\u4ef6\u6a21\u578b\uff0c\u5c06\u6bcf\u5929\u8868\u793a\u4e3aTTE\u5e8f\u5217\uff0c\u901a\u8fc7\u65f6\u95f4\u79bb\u6563\u5316\u4e3a\u57fa\u4e8e\u7f51\u683c\u7684token\uff0c\u5229\u7528\u6d41\u5f0f\u4e0a\u4e0b\u6587\u4fe1\u606f\u800c\u975e\u4ec5\u4f9d\u8d56\u5386\u53f2\u6a21\u5f0f", "result": "\u572893\u540d\u7528\u6237\u7684\u771f\u5b9e\u4e16\u754c\u7814\u7a76\u4e2d\uff0c\u4f7f\u7528\u88ab\u52a8\u667a\u80fd\u624b\u673a\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u4e2a\u4eba\u65e5\u5e38\u4e2d\u7684\u4e0d\u89c4\u5219\u51fa\u53d1\u6a21\u5f0f\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u53ef\u6301\u7eed\u4ea4\u901a\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u4f18\u5316\u5145\u7535\u7b56\u7565\u5ef6\u957f\u7535\u6c60\u5bff\u547d"}}
{"id": "2512.07741", "categories": ["cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.07741", "abs": "https://arxiv.org/abs/2512.07741", "authors": ["Agnes Norbury", "George Fairs", "Alexandra L. Georgescu", "Matthew M. Nour", "Emilia Molimpakis", "Stefano Goria"], "title": "A multimodal Bayesian Network for symptom-level depression and anxiety prediction from voice and speech data", "comment": null, "summary": "During psychiatric assessment, clinicians observe not only what patients report, but important nonverbal signs such as tone, speech rate, fluency, responsiveness, and body language. Weighing and integrating these different information sources is a challenging task and a good candidate for support by intelligence-driven tools - however this is yet to be realized in the clinic. Here, we argue that several important barriers to adoption can be addressed using Bayesian network modelling. To demonstrate this, we evaluate a model for depression and anxiety symptom prediction from voice and speech features in large-scale datasets (30,135 unique speakers). Alongside performance for conditions and symptoms (for depression, anxiety ROC-AUC=0.842,0.831 ECE=0.018,0.015; core individual symptom ROC-AUC>0.74), we assess demographic fairness and investigate integration across and redundancy between different input modality types. Clinical usefulness metrics and acceptability to mental health service users are explored. When provided with sufficiently rich and large-scale multimodal data streams and specified to represent common mental conditions at the symptom rather than disorder level, such models are a principled approach for building robust assessment support tools: providing clinically-relevant outputs in a transparent and explainable format that is directly amenable to expert clinical supervision.", "AI": {"tldr": "\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u6a21\u578b\u4ece\u8bed\u97f3\u7279\u5f81\u9884\u6d4b\u6291\u90c1\u548c\u7126\u8651\u75c7\u72b6\uff0c\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027", "motivation": "\u4e34\u5e8a\u8bc4\u4f30\u4e2d\u9700\u8981\u6574\u5408\u8bed\u8a00\u548c\u975e\u8bed\u8a00\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u667a\u80fd\u5de5\u5177\u5c1a\u672a\u5b9e\u73b0\u4e34\u5e8a\u5e94\u7528\u3002\u8d1d\u53f6\u65af\u7f51\u7edc\u53ef\u4ee5\u89e3\u51b3\u91c7\u7528\u969c\u788d\uff0c\u63d0\u4f9b\u900f\u660e\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u652f\u6301", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u6a21\u578b\uff0c\u57fa\u4e8e30,135\u540d\u72ec\u7279\u8bf4\u8bdd\u8005\u7684\u8bed\u97f3\u7279\u5f81\u9884\u6d4b\u6291\u90c1\u548c\u7126\u8651\u75c7\u72b6\uff0c\u8bc4\u4f30\u6027\u80fd\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u516c\u5e73\u6027\u3001\u591a\u6a21\u6001\u6574\u5408\u548c\u5197\u4f59\u6027", "result": "\u6a21\u578b\u8868\u73b0\u826f\u597d\uff1a\u6291\u90c1\u548c\u7126\u8651\u7684ROC-AUC\u5206\u522b\u4e3a0.842\u548c0.831\uff0cECE\u5206\u522b\u4e3a0.018\u548c0.015\uff1b\u6838\u5fc3\u75c7\u72b6ROC-AUC>0.74\uff1b\u8bc4\u4f30\u4e86\u516c\u5e73\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027", "conclusion": "\u57fa\u4e8e\u4e30\u5bcc\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\uff0c\u5728\u75c7\u72b6\u5c42\u9762\u800c\u975e\u75be\u75c5\u5c42\u9762\u6784\u5efa\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u6a21\u578b\uff0c\u662f\u6784\u5efa\u7a33\u5065\u8bc4\u4f30\u652f\u6301\u5de5\u5177\u7684\u5408\u7406\u65b9\u6cd5\uff0c\u63d0\u4f9b\u900f\u660e\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\uff0c\u9002\u5408\u4e34\u5e8a\u4e13\u5bb6\u76d1\u7763"}}
{"id": "2512.07766", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.07766", "abs": "https://arxiv.org/abs/2512.07766", "authors": ["Matteo Cipollina", "Michail Karatarakis", "Freek Wiedijk"], "title": "Formalized Hopfield Networks and Boltzmann Machines", "comment": null, "summary": "Neural networks are widely used, yet their analysis and verification remain challenging. In this work, we present a Lean 4 formalization of neural networks, covering both deterministic and stochastic models. We first formalize Hopfield networks, recurrent networks that store patterns as stable states. We prove convergence and the correctness of Hebbian learning, a training rule that updates network parameters to encode patterns, here limited to the case of pairwise-orthogonal patterns. We then consider stochastic networks, where updates are probabilistic and convergence is to a stationary distribution. As a canonical example, we formalize the dynamics of Boltzmann machines and prove their ergodicity, showing convergence to a unique stationary distribution using a new formalization of the Perron-Frobenius theorem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728Lean 4\u4e2d\u5f62\u5f0f\u5316\u795e\u7ecf\u7f51\u7edc\uff0c\u5305\u62ec\u786e\u5b9a\u6027\u548c\u968f\u673a\u6a21\u578b\uff0c\u8bc1\u660e\u4e86Hopfield\u7f51\u7edc\u7684\u6536\u655b\u6027\u548cHebbian\u5b66\u4e60\u7684\u6b63\u786e\u6027\uff0c\u4ee5\u53caBoltzmann\u673a\u5668\u7684\u904d\u5386\u6027\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5206\u6790\u548c\u9a8c\u8bc1\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u4e3a\u4e86\u63d0\u4f9b\u4e25\u683c\u7684\u6570\u5b66\u4fdd\u8bc1\uff0c\u9700\u8981\u5728\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316\u795e\u7ecf\u7f51\u7edc\u53ca\u5176\u6027\u8d28\u3002", "method": "\u4f7f\u7528Lean 4\u5b9a\u7406\u8bc1\u660e\u5668\u5f62\u5f0f\u5316\u795e\u7ecf\u7f51\u7edc\u3002\u9996\u5148\u5f62\u5f0f\u5316Hopfield\u7f51\u7edc\uff08\u786e\u5b9a\u6027\u9012\u5f52\u7f51\u7edc\uff09\uff0c\u8bc1\u660e\u5176\u6536\u655b\u6027\u548cHebbian\u5b66\u4e60\u7684\u6b63\u786e\u6027\uff08\u9650\u4e8e\u4e24\u4e24\u6b63\u4ea4\u6a21\u5f0f\uff09\u3002\u7136\u540e\u5f62\u5f0f\u5316\u968f\u673a\u7f51\u7edc\uff0c\u4ee5Boltzmann\u673a\u5668\u4e3a\u4f8b\uff0c\u4f7f\u7528Perron-Frobenius\u5b9a\u7406\u7684\u65b0\u5f62\u5f0f\u5316\u8bc1\u660e\u5176\u904d\u5386\u6027\u548c\u6536\u655b\u5230\u552f\u4e00\u5e73\u7a33\u5206\u5e03\u3002", "result": "\u6210\u529f\u5728Lean 4\u4e2d\u5f62\u5f0f\u5316\u4e86\u786e\u5b9a\u6027\u548c\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\u8bc1\u660e\u4e86Hopfield\u7f51\u7edc\u7684\u6536\u655b\u6027\u548cHebbian\u5b66\u4e60\u7684\u6b63\u786e\u6027\u3002\u5bf9\u4e8eBoltzmann\u673a\u5668\uff0c\u8bc1\u660e\u4e86\u5176\u904d\u5386\u6027\u5e76\u5c55\u793a\u4e86\u6536\u655b\u5230\u552f\u4e00\u5e73\u7a33\u5206\u5e03\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u5728\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316\u795e\u7ecf\u7f51\u7edc\u53ca\u5176\u6027\u8d28\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u4e25\u683c\u5206\u6790\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\u5f62\u5f0f\u5316\u7684Perron-Frobenius\u5b9a\u7406\u4e5f\u53ef\u7528\u4e8e\u5176\u4ed6\u968f\u673a\u7cfb\u7edf\u7684\u5206\u6790\u3002"}}
{"id": "2512.07782", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07782", "abs": "https://arxiv.org/abs/2512.07782", "authors": ["Jiaxu Liu", "Yuhe Bai", "Christos-Savvas Bouganis"], "title": "GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory", "comment": null, "summary": "Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \\textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \\emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \\emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\\underline{Gated} (\\underline{F}lash) \\underline{W}indowed \\underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.", "AI": {"tldr": "\u63d0\u51faGatedFWA\uff1a\u4e00\u79cd\u5185\u5b58\u95e8\u63a7\u7684\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301SWA\u6548\u7387\u7684\u540c\u65f6\u7a33\u5b9a\u5185\u5b58\u66f4\u65b0\u5e76\u63a7\u5236\u68af\u5ea6\u6d41\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8870\u51cf\u504f\u7f6e\u5b9e\u73b0\u5185\u5b58\u9012\u5f52\u4e2d\u7684\u53ef\u63a7\u6536\u7f29\u3002", "motivation": "\u4f20\u7edfSoftmax\u5168\u6ce8\u610f\u529b\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3a\u5e8f\u5217\u957f\u5ea6\u7684\u5e73\u65b9\uff0c\u800c\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b(SWA)\u867d\u7136\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4\u7f16\u7801/\u89e3\u7801\uff0c\u4f46\u5728\u5173\u8054\u5185\u5b58\u89e3\u91ca\u4e0b\uff0c\u5176\u5dee\u5206\u5f0f\u66f4\u65b0\u5bfc\u81f4\u8bad\u7ec3\u76ee\u6807\u65e0\u754c\u3002Softmax\u6ce8\u610f\u529b\u5219\u5b58\u5728\u5185\u5b58\u6536\u7f29\u548c\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002", "method": "GatedFWA\u901a\u8fc7\u5728\u6bcf\u4e2atoken/head\u4e0a\u7d2f\u79ef\u95e8\u63a7\u503c\u4f5c\u4e3a\u8870\u51cf\u504f\u7f6e\u6dfb\u52a0\u5230\u6ce8\u610f\u529blogits\u4e2d\uff0c\u5b9e\u73b0\u5185\u5b58\u9012\u5f52\u4e2d\u7684\u53ef\u5b66\u4e60\u6536\u7f29\u3002\u91c7\u7528\u878d\u5408\u7684\u5355\u901a\u9053\u95e8\u9884\u5904\u7406\u548c\u4e0eFlashAttention\u517c\u5bb9\u7684\u5185\u6838\uff0c\u5728\u6ed1\u52a8\u63a9\u7801\u4e0b\u6ce8\u5165\u95e8\u63a7\uff0c\u786e\u4fddI/O\u6548\u7387\u548c\u6570\u503c\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGatedFWA\u4ee5\u53ef\u5ffd\u7565\u7684\u5f00\u9500\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u541e\u5410\u91cf\uff0c\u66f4\u597d\u5730\u5229\u7528\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u5e76\u80fd\u4e0eNSA\u7b49token\u538b\u7f29/\u9009\u62e9\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u6cdb\u5316\u5230\u5404\u79cd\u81ea\u56de\u5f52\u9886\u57df\u3002", "conclusion": "GatedFWA\u6210\u529f\u89e3\u51b3\u4e86SWA\u7684\u5185\u5b58\u66f4\u65b0\u4e0d\u7a33\u5b9a\u548cSoftmax\u6ce8\u610f\u529b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u8ba1\u7b97\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u63a7\u7684\u5185\u5b58\u66f4\u65b0\u548c\u68af\u5ea6\u6d41\uff0c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002"}}
{"id": "2512.07805", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07805", "abs": "https://arxiv.org/abs/2512.07805", "authors": ["Yifan Zhang", "Zixiang Chen", "Yifeng Liu", "Zhen Qin", "Huizhuo Yuan", "Kangping Xu", "Yang Yuan", "Quanquan Gu", "Andrew Chi-Chih Yao"], "title": "Group Representational Position Encoding", "comment": "Project Page: https://github.com/model-architectures/GRAPE", "summary": "We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n)=\\exp(n\\,\u03c9\\,\\mathbf{L})$ with a rank-2 skew generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.", "AI": {"tldr": "GRAPE\u662f\u4e00\u4e2a\u57fa\u4e8e\u7fa4\u4f5c\u7528\u7684\u7edf\u4e00\u4f4d\u7f6e\u7f16\u7801\u6846\u67b6\uff0c\u5305\u542b\u4e58\u6cd5\u65cb\u8f6c\uff08SO(d)\uff09\u548c\u52a0\u6cd5logit\u504f\u7f6e\uff08GL\uff09\u4e24\u79cd\u673a\u5236\uff0c\u7edf\u4e00\u4e86RoPE\u548cALiBi\u7b49\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5982RoPE\u548cALiBi\u7b49\u5404\u81ea\u72ec\u7acb\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002GRAPE\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u57fa\u4e8e\u7fa4\u4f5c\u7528\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u4e0d\u540c\u7684\u4f4d\u7f6e\u7f16\u7801\u673a\u5236\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u4e0b\u3002", "method": "\u57fa\u4e8e\u7fa4\u4f5c\u7528\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u4f4d\u7f6e\u7f16\u7801\u673a\u5236\uff1a1\uff09\u4e58\u6cd5GRAPE\uff1a\u5728SO(d)\u7fa4\u4e2d\u4f7f\u7528\u4e58\u6cd5\u65cb\u8f6c\uff0c\u4f4d\u7f6en\u4f5c\u7528\u4e3aG(n)=exp(n\u03c9L)\uff0c\u5176\u4e2dL\u662f\u79e92\u659c\u5bf9\u79f0\u751f\u6210\u5143\uff1b2\uff09\u52a0\u6cd5GRAPE\uff1a\u5728GL\u7fa4\u4e2d\u4f7f\u7528\u5355\u80fd\u4f5c\u7528\u4ea7\u751f\u52a0\u6cd5logit\u504f\u7f6e\u3002\u4e24\u79cd\u673a\u5236\u5206\u522b\u7edf\u4e00\u4e86RoPE\u548cALiBi\u7b49\u73b0\u6709\u65b9\u6cd5\u3002", "result": "GRAPE\u6846\u67b6\u80fd\u591f\u7cbe\u786e\u6062\u590dRoPE\uff08\u5f53d/2\u5e73\u9762\u4e3a\u89c4\u8303\u5750\u6807\u5bf9\u4e14\u5177\u6709\u5bf9\u6570\u5747\u5300\u8c31\u65f6\uff09\u548cALiBi\u3001Forgetting Transformer\u7b49\u73b0\u6709\u65b9\u6cd5\u3002\u901a\u8fc7\u5b66\u4e60\u7684\u4ea4\u6362\u5b50\u7a7a\u95f4\u548c\u7d27\u51d1\u975e\u4ea4\u6362\u6df7\u5408\uff0c\u53ef\u4ee5\u6269\u5c55\u51e0\u4f55\u7ed3\u6784\u4ee5\u6355\u6349\u8de8\u5b50\u7a7a\u95f4\u7279\u5f81\u8026\u5408\u3002", "conclusion": "GRAPE\u4e3a\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u4e2d\u7684\u4f4d\u7f6e\u51e0\u4f55\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5c06RoPE\u548cALiBi\u7b49\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u7edf\u4e00\u4e3a\u7279\u4f8b\uff0c\u4e3a\u4f4d\u7f6e\u7f16\u7801\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u6846\u67b6\u548c\u6269\u5c55\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.07818", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.07818", "abs": "https://arxiv.org/abs/2512.07818", "authors": ["Xinyuan Cao", "Santosh S. Vempala"], "title": "Provable Long-Range Benefits of Next-Token Prediction", "comment": "66 pages, 5 figures", "summary": "Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\uff1a\u901a\u8fc7\u4f18\u5316RNN\u7684\u4e0b\u4e00\u8bcd\u9884\u6d4b\uff0c\u53ef\u4ee5\u5b66\u4e60\u5230\u8bad\u7ec3\u5206\u5e03\u7684\u8fd1\u4f3c\uff0c\u4f7f\u5f97\u5728\u4efb\u610fk\u4e2a\u8fde\u7eed\u8bcd\u4e0a\uff0c\u5b66\u4e60\u5230\u7684\u8bed\u8a00\u6a21\u578b\u4e0e\u771f\u5b9e\u5206\u5e03\u65e0\u6cd5\u533a\u5206\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4ec0\u4e48\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\uff08\u8bad\u7ec3\u7528\u4e8e\u4e0b\u4e00\u8bcd\u9884\u6d4b\uff09\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u6587\u6863\u5e76\u6355\u83b7\u957f\u7a0b\u7ed3\u6784\uff0c\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e0b\u4e00\u8bcd\u9884\u6d4b\u5bf9\u4e8e\u5b66\u4e60\u957f\u7a0b\u7ed3\u6784\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u4f18\u5316\u4e0b\u4e00\u8bcd\u9884\u6d4b\uff0c\u8bc1\u660e\u5b66\u4e60\u5230\u7684\u6a21\u578b\u80fd\u591f\u8fd1\u4f3c\u8bad\u7ec3\u5206\u5e03\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5bf9\u4e8e\u4ece\u8bad\u7ec3\u5206\u5e03\u91c7\u6837\u7684\u6587\u6863\uff0c\u4efb\u4f55\u6709\u754c\u63cf\u8ff0\u957f\u5ea6\u7684\u7b97\u6cd5\u90fd\u65e0\u6cd5\u533a\u5206\u771f\u5b9e\u6587\u6863\u7684k\u4e2a\u8fde\u7eed\u8bcd\u548c\u6a21\u578b\u751f\u6210\u7684k\u4e2a\u8bcd\u3002", "result": "\u63d0\u4f9b\u4e86\u5b9e\u73b0k\u8bcd\u4e0d\u53ef\u533a\u5206\u6027\u6240\u9700\u6a21\u578b\u5927\u5c0f\u7684\u591a\u9879\u5f0f\u8fb9\u754c\uff08\u4e0e\u6587\u6863\u957f\u5ea6\u65e0\u5173\uff09\uff0c\u4e3a\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u957f\u7a0b\u8fde\u8d2f\u6027\u63d0\u4f9b\u4e86\u590d\u6742\u6027\u7406\u8bba\u89e3\u91ca\u3002", "conclusion": "\u4e0b\u4e00\u8bcd\u9884\u6d4b\u5728\u7406\u8bba\u4e0a\u5177\u6709\u5b66\u4e60\u957f\u7a0b\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u57fa\u4e8e\u4e0b\u4e00\u8bcd\u9884\u6d4b\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u6587\u6863\u5e76\u6355\u83b7\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2512.07828", "categories": ["cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.07828", "abs": "https://arxiv.org/abs/2512.07828", "authors": ["Jeremy Yang", "Noah Yonack", "Kate Zyskowski", "Denis Yarats", "Johnny Ho", "Jerry Ma"], "title": "The Adoption and Usage of AI Agents: Early Evidence from Perplexity", "comment": null, "summary": "This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.", "AI": {"tldr": "\u9996\u4e2a\u5927\u89c4\u6a21AI\u667a\u80fd\u4f53\u5728\u5f00\u653e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u5b9e\u5730\u7814\u7a76\uff0c\u5206\u6790\u4e86Perplexity\u7684Comet\u6d4f\u89c8\u5668\u53ca\u5176AI\u52a9\u624b\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u7528\u6237\u7fa4\u4f53\u3001\u4f7f\u7528\u5f3a\u5ea6\u548c\u7528\u4f8b\u7684\u5f02\u8d28\u6027\u3002", "motivation": "\u4e86\u89e3\u901a\u7528AI\u667a\u80fd\u4f53\u5728\u5f00\u653e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u91c7\u7528\u60c5\u51b5\u3001\u4f7f\u7528\u5f3a\u5ea6\u548c\u5177\u4f53\u7528\u4f8b\uff0c\u586b\u8865\u5927\u89c4\u6a21\u5b9e\u5730\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u8005\u3001\u4f01\u4e1a\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u57fa\u4e8ePerplexity\u7684Comet\u6d4f\u89c8\u5668\u53ca\u5176Comet Assistant\u667a\u80fd\u4f53\uff0c\u5206\u6790\u6570\u4ebf\u6761\u533f\u540d\u7528\u6237\u4ea4\u4e92\u6570\u636e\uff0c\u5f15\u5165\u5206\u5c42\u667a\u80fd\u4f53\u5206\u7c7b\u6cd5\uff08\u4e3b\u9898\u3001\u5b50\u4e3b\u9898\u3001\u4efb\u52a1\u4e09\u4e2a\u5c42\u6b21\uff09\u7cfb\u7edf\u5316\u8868\u5f81\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u65e9\u671f\u91c7\u7528\u8005\u3001\u9ad8GDP\u56fd\u5bb6\u7528\u6237\u3001\u9ad8\u6559\u80b2\u6c34\u5e73\u4eba\u7fa4\u4ee5\u53ca\u6570\u5b57/\u77e5\u8bc6\u5bc6\u96c6\u578b\u884c\u4e1a\u4ece\u4e1a\u8005\u66f4\u53ef\u80fd\u91c7\u7528AI\u667a\u80fd\u4f53\uff1b\u751f\u4ea7\u529b\u4e0e\u5de5\u4f5c\u6d41\u3001\u5b66\u4e60\u4e0e\u7814\u7a76\u4e24\u5927\u4e3b\u9898\u536057%\u67e5\u8be2\uff1b\u4e2a\u4eba\u4f7f\u7528\u536055%\uff0c\u4e13\u4e1a\u548c\u6559\u5b66\u4f7f\u7528\u5206\u522b\u536030%\u548c16%\uff1b\u77ed\u671f\u4f7f\u7528\u5177\u6709\u7c98\u6027\uff0c\u957f\u671f\u7528\u6237\u8f6c\u5411\u8ba4\u77e5\u5bfc\u5411\u4e3b\u9898\u3002", "conclusion": "AI\u667a\u80fd\u4f53\u7684\u6269\u6563\u5bf9\u7814\u7a76\u8005\u3001\u4f01\u4e1a\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8fd9\u4e00\u65b0\u5174AI\u80fd\u529b\u7c7b\u522b\uff0c\u7279\u522b\u662f\u7528\u6237\u4f7f\u7528\u6a21\u5f0f\u7684\u6f14\u53d8\u548c\u4e0d\u540c\u7fa4\u4f53\u7684\u91c7\u7528\u5dee\u5f02\u3002"}}
