<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 90]
- [quant-ph](#quant-ph) [Total: 39]
- [gr-qc](#gr-qc) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 6]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [A Koopman-Bayesian Framework for High-Fidelity, Perceptually Optimized Haptic Surgical Simulation](https://arxiv.org/abs/2602.15834)
*Rohit Kaushik,Eva Kaushik*

Main category: cs.LG

TL;DR: 提出结合非线性动力学、感知心理物理学和高频触觉渲染的统一框架，通过Koopman算子将手术器械与软组织交互提升到增强状态空间，实现线性预测与控制，并基于贝叶斯校准模块使渲染力与人类感知极限一致，显著提升手术模拟真实感。


<details>
  <summary>Details</summary>
Motivation: 当前手术模拟系统在触觉渲染方面存在局限性，难以同时处理非线性组织动力学和人类感知特性。需要开发一个统一框架来增强手术模拟的真实感，结合非线性动力学建模、人类感知心理物理学和高频触觉渲染技术。

Method: 1. 使用Koopman算子将非线性手术器械与软组织交互提升到增强状态空间，实现线性预测和控制；2. 基于Weber-Fechner和Stevens标度定律的贝叶斯校准模块，根据个体辨别阈值逐步塑造力信号；3. 高频触觉渲染架构，支持多种手术任务模拟。

Result: 系统平均渲染延迟4.3毫秒，力误差小于2.8%，感知辨别能力提升20%。多元统计分析（MANOVA和回归）显示系统性能显著优于传统的弹簧阻尼器和基于能量的渲染方法。

Conclusion: 该框架成功整合了非线性动力学、感知心理物理学和高频触觉渲染，显著提升了手术模拟的真实感。对手术培训和VR医学教育具有潜在影响，未来可向触觉界面的闭环神经反馈方向发展。

Abstract: We introduce a unified framework that combines nonlinear dynamics, perceptual psychophysics and high frequency haptic rendering to enhance realism in surgical simulation. The interaction of the surgical device with soft tissue is elevated to an augmented state space with a Koopman operator formulation, allowing linear prediction and control of the dynamics that are nonlinear by nature. To make the rendered forces consistent with human perceptual limits, we put forward a Bayesian calibration module based on WeberFechner and Stevens scaling laws, which progressively shape force signals relative to each individual's discrimination thresholds. For various simulated surgical tasks such as palpation, incision, and bone milling, the proposed system attains an average rendering latency of 4.3 ms, a force error of less than 2.8% and a 20% improvement in perceptual discrimination. Multivariate statistical analyses (MANOVA and regression) reveal that the system's performance is significantly better than that of conventional spring-damper and energy, based rendering methods. We end by discussing the potential impact on surgical training and VR, based medical education, as well as sketching future work toward closed, loop neural feedback in haptic interfaces.

</details>


### [2] [Memes-as-Replies: Can Models Select Humorous Manga Panel Responses?](https://arxiv.org/abs/2602.15842)
*Ryosuke Kohita,Seiichiro Yoshioka*

Main category: cs.LG

TL;DR: 该论文提出了Meme Reply Selection任务和MaMe-Re基准，包含10万个人工标注的漫画面板与社交媒体帖子配对，用于研究表情包在对话中的幽默回复选择。研究发现LLMs能捕捉复杂社交线索但视觉信息无帮助，区分细微幽默差异仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 表情包是现代网络交流的重要元素，但现有研究主要关注表情包的内在属性，而忽略了表情包在对话中作为互动回复的动态和语境化使用。为了填补这一研究空白，需要研究表情包如何被用于创造语境幽默。

Method: 提出了Meme Reply Selection任务，并创建了MaMe-Re基准数据集，包含10万个人工标注的配对（来自2,325名标注者的50万次标注），使用开放许可的日本漫画面板和社交媒体帖子。通过该基准评估大型语言模型在表情包回复选择任务上的表现。

Result: 研究发现：(1) LLMs初步显示出捕捉复杂社交线索（如夸张）的能力，超越了表面语义匹配；(2) 视觉信息的加入并未提升性能，表明模型在理解视觉内容与有效利用其创造语境幽默之间存在差距；(3) LLMs在受控环境中能匹配人类判断，但难以区分语义相似候选回复之间的微妙幽默差异。

Conclusion: 选择语境幽默的回复对当前模型仍是一个开放挑战。研究强调了理解表情包动态使用的重要性，并为未来研究表情包在对话中的语境化幽默应用提供了基准和方向。

Abstract: Memes are a popular element of modern web communication, used not only as static artifacts but also as interactive replies within conversations. While computational research has focused on analyzing the intrinsic properties of memes, the dynamic and contextual use of memes to create humor remains an understudied area of web science. To address this gap, we introduce the Meme Reply Selection task and present MaMe-Re (Manga Meme Reply Benchmark), a benchmark of 100,000 human-annotated pairs (500,000 total annotations from 2,325 unique annotators) consisting of openly licensed Japanese manga panels and social media posts. Our analysis reveals three key insights: (1) large language models (LLMs) show preliminary evidence of capturing complex social cues such as exaggeration, moving beyond surface-level semantic matching; (2) the inclusion of visual information does not improve performance, revealing a gap between understanding visual content and effectively using it for contextual humor; (3) while LLMs can match human judgments in controlled settings, they struggle to distinguish subtle differences in wit among semantically similar candidates. These findings suggest that selecting contextually humorous replies remains an open challenge for current models.

</details>


### [3] [Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems](https://arxiv.org/abs/2602.15855)
*Barak Or*

Main category: cs.LG

TL;DR: 论文提出从卡尔曼滤波视角研究混合推理系统的运行时稳定性，引入认知漂移作为可测量的运行时现象，并提出监控创新信号统计量、检测不稳定性、触发恢复感知控制机制的框架。


<details>
  <summary>Details</summary>
Motivation: 当前结合学习组件和基于模型推理的混合推理系统在工具增强决策循环中广泛应用，但其在部分可观测性和持续证据不匹配下的运行时行为理解不足。实践中，故障往往表现为内部推理动态的逐渐发散而非孤立预测错误。

Method: 从卡尔曼滤波视角将推理建模为受内部创新信号驱动的随机推理过程，引入认知漂移作为可测量的运行时现象。提出运行时稳定性框架，监控创新统计量、检测新兴不稳定性、触发恢复感知控制机制。

Result: 在多步工具增强推理任务上的实验表明，该方法能在任务失败前可靠检测不稳定性，并在可行时通过恢复机制在有限时间内重建有界的内部行为。

Conclusion: 运行时稳定性应作为不确定性下可靠推理的系统级要求，该框架为混合推理系统提供了实用的稳定性监控和恢复机制。

Abstract: Hybrid reasoning systems that combine learned components with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime behavior under partial observability and sustained evidence mismatch remains poorly understood. In practice, failures often arise as gradual divergence of internal reasoning dynamics rather than as isolated prediction errors. This work studies runtime stability in hybrid reasoning systems from a Kalman-inspired perspective. We model reasoning as a stochastic inference process driven by an internal innovation signal and introduce cognitive drift as a measurable runtime phenomenon. Stability is defined in terms of detectability, bounded divergence, and recoverability rather than task-level correctness. We propose a runtime stability framework that monitors innovation statistics, detects emerging instability, and triggers recovery-aware control mechanisms. Experiments on multi-step, tool-augmented reasoning tasks demonstrate reliable instability detection prior to task failure and show that recovery, when feasible, re-establishes bounded internal behavior within finite time. These results emphasize runtime stability as a system-level requirement for reliable reasoning under uncertainty.

</details>


### [4] [Genetic Generalized Additive Models](https://arxiv.org/abs/2602.15877)
*Kaaustaaub Shankar,Kelly Cohen*

Main category: cs.LG

TL;DR: 使用多目标遗传算法NSGA-II自动优化广义可加模型，在预测误差和模型复杂度之间取得平衡，生成更简单、更平滑、更可解释的模型。


<details>
  <summary>Details</summary>
Motivation: 广义可加模型在预测准确性和可解释性之间提供了良好平衡，但手动配置其结构具有挑战性。需要一种自动化方法来优化GAMs，同时考虑预测性能和模型复杂度。

Method: 提出使用多目标遗传算法NSGA-II来自动优化广义可加模型，联合最小化预测误差（RMSE）和复杂度惩罚项（包含稀疏性、平滑性和不确定性）。

Result: 在加州住房数据集上的实验表明，NSGA-II发现的GAMs在准确性上优于基线LinearGAMs，或者以显著更低的复杂度匹配其性能。生成的模型更简单、更平滑，置信区间更窄，增强了可解释性。

Conclusion: 该框架为自动化优化透明、高性能模型提供了一种通用方法，能够自动发现平衡预测准确性和可解释性的广义可加模型。

Abstract: Generalized Additive Models (GAMs) balance predictive accuracy and interpretability, but manually configuring their structure is challenging. We propose using the multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly minimizing prediction error (RMSE) and a Complexity Penalty that captures sparsity, smoothness, and uncertainty. Experiments on the California Housing dataset show that NSGA-II discovers GAMs that outperform baseline LinearGAMs in accuracy or match performance with substantially lower complexity. The resulting models are simpler, smoother, and exhibit narrower confidence intervals, enhancing interpretability. This framework provides a general approach for automated optimization of transparent, high-performing models. The code can be found at https://github.com/KaaustaaubShankar/GeneticAdditiveModels.

</details>


### [5] [Graph neural network for colliding particles with an application to sea ice floe modeling](https://arxiv.org/abs/2602.16213)
*Ruibiao Zhu*

Main category: cs.LG

TL;DR: 提出使用图神经网络(GNN)进行海冰建模的新方法，将海冰视为自然图结构，节点代表冰片，边模拟物理相互作用，在一维框架中开发碰撞捕获网络(CN)，结合数据同化技术，相比传统数值方法更高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法虽然有效但计算密集且可扩展性差，需要更高效的海冰建模工具，特别是在边缘冰区(MIZ)的预测中。利用海冰的自然图结构特性，结合机器学习和数据同化技术，可以开发更高效准确的模型。

Method: 采用图神经网络(GNN)框架，将海冰建模为图结构：节点代表单个冰片，边模拟物理相互作用（包括碰撞）。在一维框架中开发碰撞捕获网络(CN)，结合数据同化(DA)技术学习海冰动力学。使用合成数据进行验证，包括有观测数据点和无观测数据点的情况。

Result: 模型在保持准确性的同时显著加速了轨迹模拟。验证表明，该模型能够有效学习和预测各种条件下的海冰动力学，为边缘冰区(MIZ)预测提供了更高效的工具。

Conclusion: 该方法展示了机器学习与数据同化结合在海冰建模中的潜力，提供了比传统数值方法更高效且可扩展的解决方案，为边缘冰区预测开辟了新途径。

Abstract: This paper introduces a novel approach to sea ice modeling using Graph Neural Networks (GNNs), utilizing the natural graph structure of sea ice, where nodes represent individual ice pieces, and edges model the physical interactions, including collisions. This concept is developed within a one-dimensional framework as a foundational step. Traditional numerical methods, while effective, are computationally intensive and less scalable. By utilizing GNNs, the proposed model, termed the Collision-captured Network (CN), integrates data assimilation (DA) techniques to effectively learn and predict sea ice dynamics under various conditions. The approach was validated using synthetic data, both with and without observed data points, and it was found that the model accelerates the simulation of trajectories without compromising accuracy. This advancement offers a more efficient tool for forecasting in marginal ice zones (MIZ) and highlights the potential of combining machine learning with data assimilation for more effective and efficient modeling.

</details>


### [6] [IT-OSE: Exploring Optimal Sample Size for Industrial Data Augmentation](https://arxiv.org/abs/2602.15878)
*Mingchun Sun,Rongqiang Zhao,Zhennan Huang,Songyu Ding,Jie Liu*

Main category: cs.LG

TL;DR: 提出信息论最优样本量估计(IT-OSE)方法，为工业数据增强提供可靠的最优样本量估计，并设计ICD评分指标进行评估，显著提升模型性能并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 工业场景中数据增强能提升模型性能，但缺乏最优样本量的理论研究和估计方法，也没有评估最优样本量准确性的指标。

Method: 提出信息论最优样本量估计(IT-OSE)方法，设计区间覆盖与偏差(ICD)评分指标来直观评估估计的最优样本量，从理论上分析并公式化最优样本量与主导因素的关系。

Result: 相比经验估计，IT-OSE在分类任务中平均提升4.38%准确率，在回归任务中平均降低18.80%的MAPE；相比穷举搜索，在达到相同最优样本量的同时平均降低83.97%计算成本和93.46%数据成本；ICD评分中的ICDdev平均降低49.30%。

Conclusion: IT-OSE方法能可靠估计工业数据增强的最优样本量，显著提升下游模型性能的稳定性，大幅降低计算和数据成本，并在代表性传感器工业场景中展现出良好的通用性。

Abstract: In industrial scenarios, data augmentation is an effective approach to improve model performance. However, its benefits are not unidirectionally beneficial. There is no theoretical research or established estimation for the optimal sample size (OSS) in augmentation, nor is there an established metric to evaluate the accuracy of OSS or its deviation from the ground truth. To address these issues, we propose an information-theoretic optimal sample size estimation (IT-OSE) to provide reliable OSS estimation for industrial data augmentation. An interval coverage and deviation (ICD) score is proposed to evaluate the estimated OSS intuitively. The relationship between OSS and dominant factors is theoretically analyzed and formulated, thereby enhancing the interpretability. Experiments show that, compared to empirical estimation, the IT-OSE increases accuracy in classification tasks across baseline models by an average of 4.38%, and reduces MAPE in regression tasks across baseline models by an average of 18.80%. The improvements in downstream model performance are more stable. ICDdev in the ICD score is also reduced by an average of 49.30%. The determinism of OSS is enhanced. Compared to exhaustive search, the IT-OSE achieves the same OSS while reducing computational and data costs by an average of 83.97% and 93.46%. Furthermore, practicality experiments demonstrate that the IT-OSE exhibits generality across representative sensor-based industrial scenarios.

</details>


### [7] [BamaER: A Behavior-Aware Memory-Augmented Model for Exercise Recommendation](https://arxiv.org/abs/2602.15879)
*Qing Yang,Yuhao Jiang,Rui Wang,Jipeng Guo,Yejiang Wang,Xinghe Cheng,Zezheng Wu,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: BamaER是一个行为感知的记忆增强型习题推荐框架，通过三向混合编码捕获学生交互行为，使用动态记忆矩阵建模知识状态，并采用河马优化算法进行多样性感知的习题筛选，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有习题推荐方法主要将学生学习表示为习题序列，忽略了丰富的交互行为信息，导致学习进度估计存在偏差。同时，固定长度的序列分割限制了早期学习经验的纳入，阻碍了长期依赖建模和知识掌握度的准确估计。

Method: BamaER包含三个核心模块：1) 学习进度预测模块，通过三向混合编码方案捕获异构的学生交互行为；2) 记忆增强的知识追踪模块，维护动态记忆矩阵联合建模历史和当前知识状态；3) 习题筛选模块，将候选选择制定为多样性感知优化问题，使用河马优化算法减少冗余并提高推荐覆盖率。

Result: 在五个真实世界教育数据集上的实验表明，BamaER在一系列评估指标上持续优于最先进的基线方法。

Conclusion: BamaER通过整合行为感知编码、记忆增强知识追踪和多样性感知优化，有效解决了现有习题推荐方法的局限性，提供了更准确可靠的学习进度估计和个性化推荐。

Abstract: Exercise recommendation focuses on personalized exercise selection conditioned on students' learning history, personal interests, and other individualized characteristics. Despite notable progress, most existing methods represent student learning solely as exercise sequences, overlooking rich behavioral interaction information. This limited representation often leads to biased and unreliable estimates of learning progress. Moreover, fixed-length sequence segmentation limits the incorporation of early learning experiences, thereby hindering the modeling of long-term dependencies and the accurate estimation of knowledge mastery. To address these limitations, we propose BamaER, a Behavior-aware memory-augmented Exercise Recommendation framework that comprises three core modules: (i) the learning progress prediction module that captures heterogeneous student interaction behaviors via a tri-directional hybrid encoding scheme; (ii) the memory-augmented knowledge tracing module that maintains a dynamic memory matrix to jointly model historical and current knowledge states for robust mastery estimation; and (iii) the exercise filtering module that formulates candidate selection as a diversity-aware optimization problem, solved via the Hippopotamus Optimization Algorithm to reduce redundancy and improve recommendation coverage. Experiments on five real-world educational datasets show that BamaER consistently outperforms state-of-the-art baselines across a range of evaluation metrics.

</details>


### [8] [Distributed physics-informed neural networks via domain decomposition for fast flow reconstruction](https://arxiv.org/abs/2602.15883)
*Yixiao Qian,Jiaxu Liu,Zewei Xia,Song Chen,Chao Xu,Shengze Cai*

Main category: cs.LG

TL;DR: 提出一个基于时空域分解的分布式PINNs框架，通过参考锚点归一化和解耦非对称加权解决压力不确定性，实现高效流场重建


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在大规模时空域流场重建中存在计算瓶颈和优化不稳定性，分布式求解器面临压力不确定性挑战

Method: 采用时空域分解的分布式PINNs框架，引入参考锚点归一化策略和解耦非对称加权，通过单向信息流消除规范自由度，并使用CUDA图和JIT编译加速训练

Result: 在复杂流场基准测试中实现近线性强扩展性和高保真重建，确保全局压力唯一性和时间连续性

Conclusion: 建立了一个可扩展且物理严谨的流场重建框架，为复杂流体动力学理解提供有效途径

Abstract: Physics-Informed Neural Networks (PINNs) offer a powerful paradigm for flow reconstruction, seamlessly integrating sparse velocity measurements with the governing Navier-Stokes equations to recover complete velocity and latent pressure fields. However, scaling such models to large spatiotemporal domains is hindered by computational bottlenecks and optimization instabilities. In this work, we propose a robust distributed PINNs framework designed for efficient flow reconstruction via spatiotemporal domain decomposition. A critical challenge in such distributed solvers is pressure indeterminacy, where independent sub-networks drift into inconsistent local pressure baselines. We address this issue through a reference anchor normalization strategy coupled with decoupled asymmetric weighting. By enforcing a unidirectional information flow from designated master ranks where the anchor point lies to neighboring ranks, our approach eliminates gauge freedom and guarantees global pressure uniqueness while preserving temporal continuity. Furthermore, to mitigate the Python interpreter overhead associated with computing high-order physics residuals, we implement a high-performance training pipeline accelerated by CUDA graphs and JIT compilation. Extensive validation on complex flow benchmarks demonstrates that our method achieves near-linear strong scaling and high-fidelity reconstruction, establishing a scalable and physically rigorous pathway for flow reconstruction and understanding of complex hydrodynamics.

</details>


### [9] [Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort](https://arxiv.org/abs/2602.15955)
*Shumeng Chen,Jane E. Huggins,Tianwen Ma*

Main category: cs.LG

TL;DR: 提出基于半监督EM-GMM的自适应P300拼写器框架，减少校准需求，在有限标记数据下提升拼写效率


<details>
  <summary>Details</summary>
Motivation: 传统P300 BCI拼写器需要冗长的校准过程来构建二分类器，降低了整体效率，需要减少校准工作量

Method: 提出统一框架，使用少量标记校准数据，采用自适应半监督EM-GMM算法更新二分类器

Result: 15名参与者中，9人达到0.7的最低字符级准确率，其中7人显示自适应方法优于基准方法

Conclusion: 提出的半监督学习框架为实时BCI拼写系统提供了实用高效的选择，特别适用于标记数据有限的情况

Abstract: A P300 ERP-based Brain-Computer Interface (BCI) speller is an assistive communication tool. It searches for the P300 event-related potential (ERP) elicited by target stimuli, distinguishing it from the neural responses to non-target stimuli embedded in electroencephalogram (EEG) signals. Conventional methods require a lengthy calibration procedure to construct the binary classifier, which reduced overall efficiency. Thus, we proposed a unified framework with minimum calibration effort such that, given a small amount of labeled calibration data, we employed an adaptive semi-supervised EM-GMM algorithm to update the binary classifier. We evaluated our method based on character-level prediction accuracy, information transfer rate (ITR), and BCI utility. We applied calibration on training data and reported results on testing data. Our results indicate that, out of 15 participants, 9 participants exceed the minimum character-level accuracy of 0.7 using either on our adaptive method or the benchmark, and 7 out of these 9 participants showed that our adaptive method performed better than the benchmark. The proposed semi-supervised learning framework provides a practical and efficient alternative to improve the overall spelling efficiency in the real-time BCI speller system, particularly in contexts with limited labeled data.

</details>


### [10] [R$^2$Energy: A Large-Scale Benchmark for Robust Renewable Energy Forecasting under Diverse and Extreme Conditions](https://arxiv.org/abs/2602.15961)
*Zhi Sheng,Yuan Yuan,Guozhen Zhang,Yong Li*

Main category: cs.LG

TL;DR: R²Energy是一个用于可再生能源预测的大规模基准数据集，包含中国4个省份902个风能和太阳能站点的1070万小时记录，采用标准化、无泄漏的NWP辅助预测范式，揭示了极端天气下模型鲁棒性与复杂性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源（特别是风能和太阳能）的快速扩张，可靠的预测对电力系统运行变得至关重要。虽然深度学习模型在平均精度上表现良好，但气候驱动的极端天气事件频率和强度不断增加，对电网稳定性和运行安全构成严重威胁，因此开发能够在波动条件下保持稳健的预测模型成为首要挑战。

Method: 提出了R²Energy基准数据集，包含超过1070万小时的高保真记录，来自中国4个省份的902个风能和太阳能站点。建立了标准化的、无泄漏的预测范式，确保所有模型都能平等访问未来的数值天气预报信号。采用基于专家标注极端天气的分区评估方法，揭示模型鲁棒性差距。

Result: 研究发现了一个关键的"鲁棒性差距"，这一差距通常被平均指标所掩盖。揭示了鲁棒性与复杂性之间的权衡关系：在极端条件下，模型的可靠性取决于其气象集成策略，而非架构复杂性。R²Energy为评估和开发安全关键电力系统应用的预测模型提供了原则性基础。

Conclusion: R²Energy基准为可再生能源预测提供了大规模、多样化的数据集和标准化评估框架，特别关注极端天气条件下的模型鲁棒性评估。研究发现模型鲁棒性主要取决于气象集成策略而非架构复杂性，为开发更可靠的电力系统预测模型提供了重要指导。

Abstract: The rapid expansion of renewable energy, particularly wind and solar power, has made reliable forecasting critical for power system operations. While recent deep learning models have achieved strong average accuracy, the increasing frequency and intensity of climate-driven extreme weather events pose severe threats to grid stability and operational security. Consequently, developing robust forecasting models that can withstand volatile conditions has become a paramount challenge. In this paper, we present R$^2$Energy, a large-scale benchmark for NWP-assisted renewable energy forecasting. It comprises over 10.7 million high-fidelity hourly records from 902 wind and solar stations across four provinces in China, providing the diverse meteorological conditions necessary to capture the wide-ranging variability of renewable generation. We further establish a standardized, leakage-free forecasting paradigm that grants all models identical access to future Numerical Weather Prediction (NWP) signals, enabling fair and reproducible comparison across state-of-the-art representative forecasting architectures. Beyond aggregate accuracy, we incorporate regime-wise evaluation with expert-aligned extreme weather annotations, uncovering a critical ``robustness gap'' typically obscured by average metrics. This gap reveals a stark robustness-complexity trade-off: under extreme conditions, a model's reliability is driven by its meteorological integration strategy rather than its architectural complexity. R$^2$Energy provides a principled foundation for evaluating and developing forecasting models for safety-critical power system applications.

</details>


### [11] [B-DENSE: Branching For Dense Ensemble Network Learning](https://arxiv.org/abs/2602.15971)
*Cherish Puniani,Tushar Kumar,Arnav Bendre,Gaurav Kumar,Shree Singhi*

Main category: cs.LG

TL;DR: B-DENSE：通过多分支轨迹对齐解决扩散模型蒸馏中的稀疏监督问题，提高采样速度同时保持生成质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成效果好，但迭代采样导致推理延迟高。现有蒸馏技术加速采样时丢弃中间轨迹步骤，造成结构信息丢失和显著离散化误差。

Method: 提出B-DENSE框架，采用多分支轨迹对齐。修改学生架构输出K倍扩展通道，每个子集对应教师轨迹中的特定中间步骤。训练这些分支同时映射到教师目标时间步的整个序列，实现密集中间轨迹对齐。

Result: 学生模型从训练早期就能学习在解空间中导航，相比基线蒸馏框架展现出更优的图像生成质量。

Conclusion: B-DENSE通过密集中间轨迹对齐有效解决了扩散模型蒸馏中的稀疏监督问题，在加速采样的同时保持了生成质量。

Abstract: Inspired by non-equilibrium thermodynamics, diffusion models have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature results in high inference latency. While recent distillation techniques accelerate sampling, they discard intermediate trajectory steps. This sparse supervision leads to a loss of structural information and introduces significant discretization errors. To mitigate this, we propose B-DENSE, a novel framework that leverages multi-branch trajectory alignment. We modify the student architecture to output $K$-fold expanded channels, where each subset corresponds to a specific branch representing a discrete intermediate step in the teacher's trajectory. By training these branches to simultaneously map to the entire sequence of the teacher's target timesteps, we enforce dense intermediate trajectory alignment. Consequently, the student model learns to navigate the solution space from the earliest stages of training, demonstrating superior image generation quality compared to baseline distillation frameworks.

</details>


### [12] [Fast Online Learning with Gaussian Prior-Driven Hierarchical Unimodal Thompson Sampling](https://arxiv.org/abs/2602.15972)
*Tianchi Zhao,He Liu,Hongyin Shi,Jinliang Li*

Main category: cs.LG

TL;DR: 提出针对高斯奖励反馈且具有聚类结构的MAB问题的两种算法：TSCG（利用2层层次结构）和UTSCG（针对单峰奖励），均能获得比传统TSG更低的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现实世界中许多问题（如毫米波通信、风险资产组合管理）中的奖励反馈呈现高斯分布且具有聚类结构，需要针对这种特殊结构设计更高效的MAB算法。

Method: 基于高斯先验的Thompson Sampling（TSG）算法，提出TSCG算法利用2层层次结构，以及针对单峰奖励的UTSCG算法，通过聚类结构优化臂选择策略。

Result: 理论证明TSCG能获得比普通TSG更低的遗憾界，UTSCG在单峰奖励下能达到更低的遗憾界。数值实验验证了所提算法的优势。

Conclusion: 通过利用奖励的聚类结构信息，可以显著提升多臂赌博机算法的性能，降低遗憾界，这在具有高斯分布和聚类特性的实际问题中具有重要应用价值。

Abstract: We study a type of Multi-Armed Bandit (MAB) problems in which arms with a Gaussian reward feedback are clustered. Such an arm setting finds applications in many real-world problems, for example, mmWave communications and portfolio management with risky assets, as a result of the universality of the Gaussian distribution. Based on the Thompson Sampling algorithm with Gaussian prior (TSG) algorithm for the selection of the optimal arm, we propose our Thompson Sampling with Clustered arms under Gaussian prior (TSCG) specific to the 2-level hierarchical structure. We prove that by utilizing the 2-level structure, we can achieve a lower regret bound than we do with ordinary TSG. In addition, when the reward is Unimodal, we can reach an even lower bound on the regret by our Unimodal Thompson Sampling algorithm with Clustered Arms under Gaussian prior (UTSCG). Each of our proposed algorithms are accompanied by theoretical evaluation of the upper regret bound, and our numerical experiments confirm the advantage of our proposed algorithms.

</details>


### [13] [Verifier-Constrained Flow Expansion for Discovery Beyond the Data](https://arxiv.org/abs/2602.15984)
*Riccardo De Santi,Kimon Protopapas,Ya-Ping Hsieh,Andreas Krause*

Main category: cs.LG

TL;DR: 提出Flow Expander方法，通过验证器约束的熵最大化来扩展预训练流模型，使其生成超出原始数据分布的多样化有效样本


<details>
  <summary>Details</summary>
Motivation: 现有流和扩散模型通常在有限数据上预训练，只能覆盖设计空间的一小部分，导致生成的样本仅来自可行域的狭窄区域。这对于科学发现应用（如分子设计）是一个根本限制，因为目标通常是采样超出可用数据分布的有效设计。

Method: 1. 引入强验证器和弱验证器的形式化概念；2. 提出全局和局部流扩展的算法框架；3. 开发Flow Expander（FE）方法，通过验证器约束的熵最大化在流过程加噪状态空间上进行镜像下降优化；4. 提供理论分析和收敛保证。

Result: 理论分析表明方法在理想化和一般假设下都有收敛保证。实验评估显示FE能够扩展预训练流模型，在分子设计任务中增加构象多样性同时保持有效性。

Conclusion: Flow Expander方法成功解决了预训练流模型生成范围狭窄的问题，通过验证器引导的熵最大化实现了设计空间的扩展，为科学发现应用提供了有效的样本生成工具。

Abstract: Flow and diffusion models are typically pre-trained on limited available data (e.g., molecular samples), covering only a fraction of the valid design space (e.g., the full molecular space). As a consequence, they tend to generate samples from only a narrow portion of the feasible domain. This is a fundamental limitation for scientific discovery applications, where one typically aims to sample valid designs beyond the available data distribution. To this end, we address the challenge of leveraging access to a verifier (e.g., an atomic bonds checker), to adapt a pre-trained flow model so that its induced density expands beyond regions of high data availability, while preserving samples validity. We introduce formal notions of strong and weak verifiers and propose algorithmic frameworks for global and local flow expansion via probability-space optimization. Then, we present Flow Expander (FE), a scalable mirror descent scheme that provably tackles both problems by verifier-constrained entropy maximization over the flow process noised state space. Next, we provide a thorough theoretical analysis of the proposed method, and state convergence guarantees under both idealized and general assumptions. Ultimately, we empirically evaluate our method on both illustrative, yet visually interpretable settings, and on a molecular design task showcasing the ability of FE to expand a pre-trained flow model increasing conformer diversity while preserving validity.

</details>


### [14] [Anatomy of Capability Emergence: Scale-Invariant Representation Collapse and Top-Down Reorganization in Neural Networks](https://arxiv.org/abs/2602.15997)
*Jayadev Billa*

Main category: cs.LG

TL;DR: 研究通过几何测量追踪神经网络训练中的能力涌现现象，发现表示几何先于能力涌现，但预测能力有限


<details>
  <summary>Details</summary>
Motivation: 神经网络训练中能力涌现的机制仍然不透明，需要系统性地研究表示几何与能力涌现之间的关系

Method: 在5个模型规模（405K-85M参数）、8个算法任务、3个Pythia语言模型（160M-2.8B）上追踪5种几何测量，分析120多个涌现事件

Result: 发现训练开始时表示会普遍坍塌到任务特定的尺度不变水平；坍塌自上而下传播；表示几何是能力涌现的先导（硬任务75-100%先导率），而局部学习系数同步，Hessian测量滞后

Conclusion: 研究揭示了能力涌现的几何解剖学及其边界条件，但表示几何只能编码粗略任务难度，不能预测精细时间，且先导关系需要任务训练对齐

Abstract: Capability emergence during neural network training remains mechanistically opaque. We track five geometric measures across five model scales (405K-85M parameters), 120+ emergence events in eight algorithmic tasks, and three Pythia language models (160M-2.8B). We find: (1) training begins with a universal representation collapse to task-specific floors that are scale-invariant across a 210X parameter range (e.g., modular arithmetic collapses to RANKME ~ 2.0 regardless of model size); (2) collapse propagates top-down through layers (32/32 task X model consistency), contradicting bottom-up feature-building intuition; (3) a geometric hierarchy in which representation geometry leads emergence (75-100% precursor rate for hard tasks), while the local learning coefficient is synchronous (0/24 precursor) and Hessian measures lag. We also delineate prediction limits: geometric measures encode coarse task difficulty but not fine-grained timing (within-class concordance 27%; when task ordering reverses across scales, prediction fails at 26%). On Pythia, global geometric patterns replicate but per-task precursor signals do not -- the precursor relationship requires task-training alignment that naturalistic pre-training does not provide. Our contribution is the geometric anatomy of emergence and its boundary conditions, not a prediction tool.

</details>


### [15] [Geometry-Aware Uncertainty Quantification via Conformal Prediction on Manifolds](https://arxiv.org/abs/2602.16015)
*Marzieh Amiri Shahbazi,Ali Baheri*

Main category: cs.LG

TL;DR: 提出自适应测地线保形预测框架，用测地线非保形分数替代欧氏残差，通过交叉验证难度估计器处理异方差噪声，在球面上生成位置无关且适应局部预测难度的测地线帽预测区域。


<details>
  <summary>Details</summary>
Motivation: 现有保形预测方法假设欧氏输出空间，当响应位于黎曼流形上时预测区域校准不佳。特别是球面等流形上的异方差噪声问题需要专门处理。

Method: 提出自适应测地线保形预测框架：1) 用测地线距离替代欧氏残差作为非保形分数；2) 引入交叉验证难度估计器归一化分数以处理异方差噪声；3) 在球面上生成测地线帽作为预测区域。

Result: 在合成球面实验（强异方差性）和真实世界地磁场预测任务（IGRF-14卫星数据）中，自适应方法显著减少条件覆盖变异性，将最坏情况覆盖提升至接近名义水平，而基于坐标的基线方法因图表扭曲浪费大量覆盖面积。

Conclusion: 自适应测地线保形预测为流形上的回归问题提供分布自由的覆盖保证，通过测地线距离和自适应难度估计产生位置无关、适应局部难度的预测区域，显著优于传统欧氏方法。

Abstract: Conformal prediction provides distribution-free coverage guaranties for regression; yet existing methods assume Euclidean output spaces and produce prediction regions that are poorly calibrated when responses lie on Riemannian manifolds. We propose \emph{adaptive geodesic conformal prediction}, a framework that replaces Euclidean residuals with geodesic nonconformity scores and normalizes them by a cross-validated difficulty estimator to handle heteroscedastic noise. The resulting prediction regions, geodesic caps on the sphere, have position-independent area and adapt their size to local prediction difficulty, yielding substantially more uniform conditional coverage than non-adaptive alternatives. In a synthetic sphere experiment with strong heteroscedasticity and a real-world geomagnetic field forecasting task derived from IGRF-14 satellite data, the adaptive method markedly reduces conditional coverage variability and raises worst-case coverage much closer to the nominal level, while coordinate-based baselines waste a large fraction of coverage area due to chart distortion.

</details>


### [16] [MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching](https://arxiv.org/abs/2602.16020)
*Cheng Zeng,Harry W. Sullivan,Thomas Egg,Maya M. Martirossyan,Philipp Höllmer,Jirui Jin,Richard G. Hennig,Adrian Roitberg,Stefano Martiniani,Ellad B. Tadmor,Mingjie Liu*

Main category: cs.LG

TL;DR: MolCrystalFlow：一种基于流的生成模型，用于分子晶体结构预测，通过将分子作为刚体嵌入，在黎曼流形上表示质心和方向，解决了周期性分子晶体的生成难题。


<details>
  <summary>Details</summary>
Motivation: 分子晶体结构预测是计算化学的重大挑战，因为分子尺寸大且存在复杂的分子内和分子间相互作用。虽然生成模型已在分子、无机固体和金属有机框架的结构发现中取得突破，但将其扩展到完全周期性的分子晶体仍然困难。

Method: 提出MolCrystalFlow框架，将分子作为刚体嵌入，分离分子内复杂性和分子间堆积。联合学习晶格矩阵、分子取向和质心位置。质心和取向在其本征黎曼流形上表示，允许构建测地流和图神经网络操作，保持几何对称性。

Result: 在两个开源分子晶体数据集上，与最先进的周期性晶体生成模型和基于规则的结构生成方法进行基准测试。展示了将MolCrystalFlow模型与通用机器学习势能结合，加速分子晶体结构预测。

Conclusion: MolCrystalFlow为分子晶体的数据驱动生成发现铺平了道路，通过流式生成模型成功解决了周期性分子晶体结构预测的挑战。

Abstract: Molecular crystal structure prediction represents a grand challenge in computational chemistry due to large sizes of constituent molecules and complex intra- and intermolecular interactions. While generative modeling has revolutionized structure discovery for molecules, inorganic solids, and metal-organic frameworks, extending such approaches to fully periodic molecular crystals is still elusive. Here, we present MolCrystalFlow, a flow-based generative model for molecular crystal structure prediction. The framework disentangles intramolecular complexity from intermolecular packing by embedding molecules as rigid bodies and jointly learning the lattice matrix, molecular orientations, and centroid positions. Centroids and orientations are represented on their native Riemannian manifolds, allowing geodesic flow construction and graph neural network operations that respects geometric symmetries. We benchmark our model against state-of-the-art generative models for large-size periodic crystals and rule-based structure generation methods on two open-source molecular crystal datasets. We demonstrate an integration of MolCrystalFlow model with universal machine learning potential to accelerate molecular crystal structure prediction, paving the way for data-driven generative discovery of molecular crystals.

</details>


### [17] [AI-CARE: Carbon-Aware Reporting Evaluation Metric for AI Models](https://arxiv.org/abs/2602.16042)
*KC Santosh,Srikanth Baride,Rodrigue Rizk*

Main category: cs.LG

TL;DR: AI-CARE：一个评估机器学习模型能耗和碳排放的工具，引入碳-性能权衡曲线，推动多目标评估范式转变


<details>
  <summary>Details</summary>
Motivation: 机器学习快速发展带来的环境成本已成为关键社会问题，现有基准测试主要关注准确性等性能指标，而忽视了能耗和碳排放。这种单目标评估范式与大规模部署的实际需求（特别是在移动设备、发展中地区和气候敏感企业等能源受限环境中）日益脱节。

Method: 提出AI-CARE评估工具，用于报告机器学习模型的能耗和碳排放。引入碳-性能权衡曲线，这是一种可视化性能与碳成本之间帕累托前沿的可解释工具。

Result: 通过代表性机器学习工作负载的理论分析和实证验证表明，碳感知基准测试改变了模型的相对排名，并鼓励同时具备准确性和环境责任感的架构设计。

Conclusion: 该提案旨在推动研究社区向透明、多目标评估转变，使机器学习进步与全球可持续发展目标保持一致。工具和文档已在GitHub上开源。

Abstract: As machine learning (ML) continues its rapid expansion, the environmental cost of model training and inference has become a critical societal concern. Existing benchmarks overwhelmingly focus on standard performance metrics such as accuracy, BLEU, or mAP, while largely ignoring energy consumption and carbon emissions. This single-objective evaluation paradigm is increasingly misaligned with the practical requirements of large-scale deployment, particularly in energy-constrained environments such as mobile devices, developing regions, and climate-aware enterprises. In this paper, we propose AI-CARE, an evaluation tool for reporting energy consumption, and carbon emissions of ML models. In addition, we introduce the carbon-performance tradeoff curve, an interpretable tool that visualizes the Pareto frontier between performance and carbon cost. We demonstrate, through theoretical analysis and empirical validation on representative ML workloads, that carbon-aware benchmarking changes the relative ranking of models and encourages architectures that are simultaneously accurate and environmentally responsible. Our proposal aims to shift the research community toward transparent, multi-objective evaluation and align ML progress with global sustainability goals. The tool and documentation are available at https://github.com/USD-AI-ResearchLab/ai-care.

</details>


### [18] [MoE-Spec: Expert Budgeting for Efficient Speculative Decoding](https://arxiv.org/abs/2602.16052)
*Bradley McDanel,Steven Li,Sruthikesh Surineni,Harshit Khaitan*

Main category: cs.LG

TL;DR: MoE-Spec：一种针对MoE模型的无训练验证时专家预算方法，通过固定专家容量限制解耦推测深度与内存成本，提升推测解码吞吐量10-30%


<details>
  <summary>Details</summary>
Motivation: 针对MoE模型的推测解码存在瓶颈：大量推测token会激活许多独特专家，显著增加内存压力，降低相对于自回归解码的加速效果

Method: 提出MoE-Spec方法，在验证时实施固定专家容量限制，仅加载对验证贡献最大的专家，丢弃使用频率低的专家尾部，从而解耦推测深度与内存成本

Result: 在多个模型规模和数据集上的实验表明，该方法在保持可比质量的同时，比最先进的推测解码基线（EAGLE-3）提供10-30%更高的吞吐量

Conclusion: MoE-Spec通过专家预算策略有效解决了MoE模型推测解码的内存瓶颈问题，在吞吐量和延迟之间提供了灵活的权衡

Abstract: Speculative decoding accelerates Large Language Model (LLM) inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts (MoE) models, this parallelism introduces a severe bottleneck: large draft trees activate many unique experts, significantly increasing memory pressure and diminishing speedups from speculative decoding relative to autoregressive decoding. Prior methods reduce speculation depth when MoE verification becomes expensive. We propose MoE-Spec, a training-free verification-time expert budgeting method that decouples speculation depth from memory cost by enforcing a fixed expert capacity limit at each layer, loading only the experts that contribute most to verification and dropping the long tail of rarely used experts that drive bandwidth overhead. Experiments across multiple model scales and datasets show that this method yields 10--30\% higher throughput than state-of-the-art speculative decoding baselines (EAGLE-3) at comparable quality, with flexibility to trade accuracy for further latency reductions through tighter budgets.

</details>


### [19] [Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053)
*Mehrab Beikzadeh,Yasaman Asadollah Salmanpour,Ashima Suvarna,Sriram Sankararaman,Matteo Malgaroli,Majid Sarrafzadeh,Saadia Gabriel*

Main category: cs.LG

TL;DR: 提出多目标对齐框架MODPO，通过直接偏好优化平衡心理健康AI治疗中的多个临床维度，相比单目标优化获得更好的平衡表现。


<details>
  <summary>Details</summary>
Motivation: 全球超过10亿人受心理健康问题影响，但护理资源有限且成本高昂。现有AI系统在治疗对齐中通常独立优化单一目标，无法平衡患者偏好与临床安全性之间的复杂关系。

Method: 1) 调查335名有心理健康经历的个人收集偏好排名；2) 开发多目标对齐框架，使用直接偏好优化训练六个维度的奖励模型（共情、安全性、积极倾听、自我激励改变、信任/融洽关系、患者自主性）；3) 系统比较多目标方法与单目标优化、监督微调和参数合并方法。

Result: 多目标DPO（MODPO）在平衡性上表现优异（77.6%共情，62.6%安全性），优于单目标优化（93.6%共情，47.8%安全性）。治疗标准比一般沟通原则高出17.2%。盲法临床评估确认MODPO始终被偏好，LLM评估者一致性接近临床医生间可靠性。

Conclusion: 多目标对齐框架能够有效平衡心理健康AI治疗中的多个关键维度，为开发更安全、有效且符合患者偏好的AI治疗系统提供了可行方案。

Abstract: Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.

</details>


### [20] [Extracting and Analyzing Rail Crossing Behavior Signatures from Videos using Tensor Methods](https://arxiv.org/abs/2602.16057)
*Dawon Ahn,Het Patel,Aemal Khattak,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 提出多视角张量分解框架分析铁路道口行为模式，发现道口位置比时间对行为影响更大，接近阶段行为最具区分性


<details>
  <summary>Details</summary>
Motivation: 铁路道口安全面临复杂挑战，传统方法单独分析每个道口，无法发现跨位置的共享行为模式，需要能够捕捉多个道口行为相似性的自动化框架

Method: 使用多视角张量分解框架，将道口行为分为三个阶段（接近、等待、通过），利用TimeSformer嵌入表示每个阶段，构建阶段特定相似性矩阵并应用非负对称CP分解发现潜在行为成分

Result: 张量分析显示道口位置比时间对行为模式影响更大，接近阶段行为提供特别有区分性的特征，可视化确认基于位置的聚类，某些道口形成独特的行为集群

Conclusion: 该自动化框架能够跨多个道口进行可扩展的模式发现，为按行为相似性分组道口提供基础，有助于制定有针对性的安全干预措施

Abstract: Railway crossings present complex safety challenges where driver behavior varies by location, time, and conditions. Traditional approaches analyze crossings individually, limiting the ability to identify shared behavioral patterns across locations. We propose a multi-view tensor decomposition framework that captures behavioral similarities across three temporal phases: Approach (warning activation to gate lowering), Waiting (gates down to train passage), and Clearance (train passage to gate raising). We analyze railway crossing videos from multiple locations using TimeSformer embeddings to represent each phase. By constructing phase-specific similarity matrices and applying non-negative symmetric CP decomposition, we discover latent behavioral components with distinct temporal signatures. Our tensor analysis reveals that crossing location appears to be a stronger determinant of behavior patterns than time of day, and that approach-phase behavior provides particularly discriminative signatures. Visualization of the learned component space confirms location-based clustering, with certain crossings forming distinct behavioral clusters. This automated framework enables scalable pattern discovery across multiple crossings, providing a foundation for grouping locations by behavioral similarity to inform targeted safety interventions.

</details>


### [21] [Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated Recursive Training](https://arxiv.org/abs/2602.16065)
*Kevin Wang,Hongqian Niu,Didong Li*

Main category: cs.LG

TL;DR: 该论文研究了生成式AI递归训练中的数据污染问题，证明了在最小假设下递归训练仍然收敛，收敛速率等于基线模型收敛速率与每轮真实数据比例的最小值。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的普及，网络数据中AI生成内容与人类生成内容日益混合，导致后续模型训练时不可避免地使用包含早期AI生成数据的混合数据，形成递归训练循环。现有理论工作仅研究了离散或高斯分布等简化场景，而真实数据分布和现代生成模型要复杂得多。

Method: 在最小假设的一般框架下研究递归训练，不对真实数据分布做特定假设，允许底层生成模型是通用的通用逼近器。分析递归训练的收敛性，并扩展到数据收集存在采样偏差的情况。

Result: 证明在数据污染的情况下，递归训练仍然收敛，收敛速率等于基线模型收敛速率与每轮真实数据比例的最小值。这是首个在没有数据分布假设下关于递归训练的正向理论结果。通过实证研究支持了所有理论结果。

Conclusion: 该研究填补了复杂真实数据分布下递归训练理论分析的空白，证明了即使在数据污染的情况下，只要每轮训练中包含一定比例的真实数据，递归训练仍然可以收敛，为理解生成式AI的长期发展提供了理论基础。

Abstract: Generative Artificial Intelligence (AI), such as large language models (LLMs), has become a transformative force across science, industry, and society. As these systems grow in popularity, web data becomes increasingly interwoven with this AI-generated material and it is increasingly difficult to separate them from naturally generated content. As generative models are updated regularly, later models will inevitably be trained on mixtures of human-generated data and AI-generated data from earlier versions, creating a recursive training process with data contamination. Existing theoretical work has examined only highly simplified settings, where both the real data and the generative model are discrete or Gaussian, where it has been shown that such recursive training leads to model collapse. However, real data distributions are far more complex, and modern generative models are far more flexible than Gaussian and linear mechanisms. To fill this gap, we study recursive training in a general framework with minimal assumptions on the real data distribution and allow the underlying generative model to be a general universal approximator. In this framework, we show that contaminated recursive training still converges, with a convergence rate equal to the minimum of the baseline model's convergence rate and the fraction of real data used in each iteration. To the best of our knowledge, this is the first (positive) theoretical result on recursive training without distributional assumptions on the data. We further extend the analysis to settings where sampling bias is present in data collection and support all theoretical results with empirical studies.

</details>


### [22] [Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research](https://arxiv.org/abs/2602.16072)
*Chenda Duan,Yipeng Zhang,Sotaro Kanai,Yuanyi Ding,Atsuro Daida,Pengyue Yu,Tiancheng Zheng,Naoto Kuroda,Shaun A. Hussain,Eishi Asano,Hiroki Nariai,Vwani Roychowdhury*

Main category: cs.LG

TL;DR: Omni-iEEG是一个大规模、标准化的颅内脑电图数据集，包含302名患者、178小时高分辨率记录，提供超过36,000个专家验证的病理事件标注，旨在解决癫痫研究中数据格式不一致、缺乏标准化基准的问题。


<details>
  <summary>Details</summary>
Motivation: 癫痫影响全球超过5000万人，其中三分之一患者对药物耐药，手术是最佳治疗选择。当前临床工作流程依赖劳动密集型的手动分析，而现有数据驱动方法通常基于单中心数据集，存在格式不一致、缺乏标准化基准、很少发布病理事件标注等问题，阻碍了研究的可重复性、跨中心验证和临床相关性。

Method: 通过整合多个公开来源的异质iEEG数据，统一格式、元数据和记录，创建了包含302名患者、178小时高分辨率记录的Omni-iEEG数据集。数据集包含癫痫发作区、切除区域、手术结果等临床元数据，以及超过36,000个专家验证的病理事件标注。定义了基于临床先验的统一评估指标，支持端到端建模和跨领域表示迁移。

Result: 成功构建了大规模、标准化的iEEG数据集，包含302名患者、178小时记录和36,000多个专家验证标注。建立了临床相关任务的统一评估框架，展示了在长iEEG片段上进行端到端建模的潜力，以及从非神经生理学领域预训练表示的可迁移性。

Conclusion: Omni-iEEG为可重复、可泛化和临床可转化的癫痫研究奠定了基础，架起了机器学习与癫痫研究之间的桥梁。该数据集支持系统性的模型评估，促进临床相关研究的发展。

Abstract: Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\textbf{302 patients}$ and $\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at omni-ieeg.github.io/omni-ieeg.

</details>


### [23] [Why Any-Order Autoregressive Models Need Two-Stream Attention: A Structural-Semantic Tradeoff](https://arxiv.org/abs/2602.16092)
*Patrick Pynadath,Ruqi Zhang*

Main category: cs.LG

TL;DR: 研究发现两流注意力在任意顺序自回归模型中的成功不仅源于位置与内容的分离，而是为了规避任意顺序生成中固有的结构-语义权衡问题。


<details>
  <summary>Details</summary>
Motivation: 任意顺序自回归模型（AO-ARMs）通过启用原生键值缓存为高效掩码扩散提供了有前景的路径，但竞争性性能需要两流注意力，通常被解释为分离标记内容与位置的手段。本研究认为两流注意力可能扮演更微妙的角色。

Method: 提出了解耦RoPE（Decoupled RoPE），这是一种对旋转位置嵌入的修改，提供目标位置信息而不泄露目标内容。通过这种方法将结构-语义权衡与位置-内容分离隔离开来。

Result: 解耦RoPE在短序列长度下表现具有竞争力（此时语义和结构邻近性重合），但随着序列长度增加和两种顺序的分离而性能下降。

Conclusion: 两流注意力的成功不仅源于分离位置与内容，而是为了规避任意顺序生成中固有的更深层次的结构-语义权衡问题。

Abstract: Any-order autoregressive models (AO-ARMs) offer a promising path toward efficient masked diffusion by enabling native key-value caching, but competitive performance has so far required two-stream attention, typically motivated as a means of decoupling token content from position. In this work, we argue that two-stream attention may be serving a more subtle role. We identify a structural-semantic tradeoff in any-order generation: the hidden representation at each step must simultaneously attend to semantically informative tokens for prediction and structurally recent tokens for summarization, objectives that compete for attention capacity in a single stream but can specialize across two streams. To isolate this tradeoff from position-content separation, we propose Decoupled RoPE, a modification to rotary position embeddings that provides target position information without revealing target content. Decoupled RoPE performs competitively at short sequence lengths--where semantic and structural proximity coincide--but degrades as sequence length increases and the two orderings diverge. These results suggest that the success of two-stream attention stems not merely from separating position from content, but from circumventing the deeper structural-semantic tradeoff inherent to any-order generation.

</details>


### [24] [Axle Sensor Fusion for Online Continual Wheel Fault Detection in Wayside Railway Monitoring](https://arxiv.org/abs/2602.16101)
*Afonso Lourenço,Francisca Osório,Diogo Risca,Goreti Marreiros*

Main category: cs.LG

TL;DR: 提出一种语义感知、标签高效的持续学习框架，用于铁路故障诊断，结合无监督VAE编码、语义元数据融合和持续学习策略，适应不断变化的运营条件。


<details>
  <summary>Details</summary>
Motivation: 铁路轮轨界面易磨损和故障，传统预测维护方法需要手动特征工程，深度学习模型在在线设置中性能会因运营模式变化而下降，需要能适应未知运营条件的鲁棒故障诊断方法。

Method: 使用变分自编码器(VAE)无监督编码加速度计信号，通过AI驱动的峰值检测从光纤布拉格光栅传感器提取语义元数据（轴数、车轮索引、应变变形），将元数据与VAE嵌入融合，采用轻量级梯度提升监督分类器稳定异常评分，使用基于回放的持续学习策略适应演化领域。

Result: 模型能够检测由平面缺陷和多边形化引起的微小缺陷，同时适应不断变化的运营条件（如列车类型、速度、载荷和轨道剖面变化），仅使用单个加速度计和应变计进行路边监测。

Conclusion: 该框架通过语义元数据融合和持续学习，实现了在未知运营条件下的鲁棒故障诊断，解决了传统方法需要手动特征工程和深度学习模型在在线设置中性能下降的问题。

Abstract: Reliable and cost-effective maintenance is essential for railway safety, particularly at the wheel-rail interface, which is prone to wear and failure. Predictive maintenance frameworks increasingly leverage sensor-generated time-series data, yet traditional methods require manual feature engineering, and deep learning models often degrade in online settings with evolving operational patterns. This work presents a semantic-aware, label-efficient continual learning framework for railway fault diagnostics. Accelerometer signals are encoded via a Variational AutoEncoder into latent representations capturing the normal operational structure in a fully unsupervised manner. Importantly, semantic metadata, including axle counts, wheel indexes, and strain-based deformations, is extracted via AI-driven peak detection on fiber Bragg grating sensors (resistant to electromagnetic interference) and fused with the VAE embeddings, enhancing anomaly detection under unknown operational conditions. A lightweight gradient boosting supervised classifier stabilizes anomaly scoring with minimal labels, while a replay-based continual learning strategy enables adaptation to evolving domains without catastrophic forgetting. Experiments show the model detects minor imperfections due to flats and polygonization, while adapting to evolving operational conditions, such as changes in train type, speed, load, and track profiles, captured using a single accelerometer and strain gauge in wayside monitoring.

</details>


### [25] [Feature-based morphological analysis of shape graph data](https://arxiv.org/abs/2602.16120)
*Murad Hossen,Demetrio Labate,Nicolas Charon*

Main category: cs.LG

TL;DR: 提出用于形状图数据集统计分析的完整计算流程，通过提取拓扑、几何和方向特征来同时捕捉网络连通性和分支几何差异


<details>
  <summary>Details</summary>
Motivation: 传统抽象图分析只关注连通性结构，无法捕捉嵌入在2D/3D空间中的几何网络的几何差异，需要同时分析拓扑和几何特征的方法

Method: 提取精心设计的拓扑、几何和方向特征集，满足关键不变性性质，利用特征表示进行群体比较、聚类和分类任务

Result: 在多个真实数据集（城市道路网络、神经元追踪、星形胶质细胞成像）上验证了方法的有效性，并与其他特征和非特征方法进行了基准比较

Conclusion: 提出的计算流程能够有效分析形状图数据集，同时捕捉拓扑连通性和几何差异，在多种应用场景中表现出色

Abstract: This paper introduces and demonstrates a computational pipeline for the statistical analysis of shape graph datasets, namely geometric networks embedded in 2D or 3D spaces. Unlike traditional abstract graphs, our purpose is not only to retrieve and distinguish variations in the connectivity structure of the data but also geometric differences of the network branches. Our proposed approach relies on the extraction of a specifically curated and explicit set of topological, geometric and directional features, designed to satisfy key invariance properties. We leverage the resulting feature representation for tasks such as group comparison, clustering and classification on cohorts of shape graphs. The effectiveness of this representation is evaluated on several real-world datasets including urban road/street networks, neuronal traces and astrocyte imaging. These results are benchmarked against several alternative methods, both feature-based and not.

</details>


### [26] [On the Power of Source Screening for Learning Shared Feature Extractors](https://arxiv.org/abs/2602.16125)
*Leo,Wang,Connor Mclaughlin,Lili Su*

Main category: cs.LG

TL;DR: 论文研究了在多源学习中如何选择最佳数据源子集进行联合训练，发现精心选择部分源而非全部源可以达到统计最优性能，即使丢弃大量数据。


<details>
  <summary>Details</summary>
Motivation: 传统多源学习通常同时训练所有相关数据源，但低相关性或低质量的数据源可能阻碍表示学习。即使对于传统认为"好"的数据源集合（各源具有相似相关性和质量），也需要进一步探究哪些源应该联合学习。

Method: 在线性设置下，假设源共享低维子空间。提出源筛选方法，识别信息丰富的子群体。开发算法和实用启发式方法来选择最优源子集，即使这意味着丢弃大量数据。

Result: 理论分析表明，对于广泛的问题实例，在精心选择的源子集上训练足以达到极小极大最优性。在合成和真实数据集上的实证评估验证了方法的有效性。

Conclusion: 源筛选在多源学习的统计最优子空间估计中起关键作用。选择信息丰富的源子集而非使用所有源，可以实现更好的表示学习效果，即使丢弃大量数据。

Abstract: Learning with shared representation is widely recognized as an effective way to separate commonalities from heterogeneity across various heterogeneous sources. Most existing work includes all related data sources via simultaneously training a common feature extractor and source-specific heads. It is well understood that data sources with low relevance or poor quality may hinder representation learning. In this paper, we further dive into the question of which data sources should be learned jointly by focusing on the traditionally deemed ``good'' collection of sources, in which individual sources have similar relevance and qualities with respect to the true underlying common structure. Towards tractability, we focus on the linear setting where sources share a low-dimensional subspace. We find that source screening can play a central role in statistically optimal subspace estimation. We show that, for a broad class of problem instances, training on a carefully selected subset of sources suffices to achieve minimax optimality, even when a substantial portion of data is discarded. We formalize the notion of an informative subpopulation, develop algorithms and practical heuristics for identifying such subsets, and validate their effectiveness through both theoretical analysis and empirical evaluations on synthetic and real-world datasets.

</details>


### [27] [Investigating GNN Convergence on Large Randomly Generated Graphs with Realistic Node Feature Correlations](https://arxiv.org/abs/2602.16145)
*Mohammed Zain Ali Ahmed*

Main category: cs.LG

TL;DR: 本文提出了一种生成具有相关节点特征的随机图的新方法，挑战了现有研究中GNN收敛行为的局限性，表明在真实图上GNN可能比先前研究认为的更具表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究分析GNN在大随机图上的收敛行为时，大多未考虑节点特征之间的相关性，而这种相关性在现实网络中自然存在。因此，这些研究得出的GNN局限性并不能真实反映GNN在现实图上的表达能力。

Method: 提出了一种生成具有相关节点特征的随机图的新方法。节点特征的采样方式确保相邻节点之间存在相关性，采样方案的设计灵感来源于现实图（特别是Barabási-Albert模型）所表现出的特性。

Result: 理论分析强烈表明在某些情况下可以避免收敛，这在大规模随机图上得到了实证验证。观察到的发散行为表明，GNN可能比最初研究认为的更具表达能力，尤其是在现实图上。

Conclusion: 通过引入节点特征相关性的建模，本文挑战了现有GNN收敛研究的局限性，表明在更现实的图设置下，GNN可能具有更强的表达能力，为理解GNN在实际应用中的潜力提供了新视角。

Abstract: There are a number of existing studies analysing the convergence behaviour of graph neural networks on large random graphs. Unfortunately, the majority of these studies do not model correlations between node features, which would naturally exist in a variety of real-life networks. Consequently, the derived limitations of GNNs, resulting from such convergence behaviour, is not truly reflective of the expressive power of GNNs when applied to realistic graphs. In this paper, we will introduce a novel method to generate random graphs that have correlated node features. The node features will be sampled in such a manner to ensure correlation between neighbouring nodes. As motivation for our choice of sampling scheme, we will appeal to properties exhibited by real-life graphs, particularly properties that are captured by the Barabási-Albert model. A theoretical analysis will strongly indicate that convergence can be avoided in some cases, which we will empirically validate on large random graphs generated using our novel method. The observed divergent behaviour provides evidence that GNNs may be more expressive than initial studies would suggest, especially on realistic graphs.

</details>


### [28] [ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding](https://arxiv.org/abs/2602.16147)
*Megan Lee,Seung Ha Hwang,Inhyeok Choi,Shreyas Darade,Mengchun Zhang,Kateryna Shapovalenko*

Main category: cs.LG

TL;DR: 研究发现脑电信号的频谱特征比时域特征在跨被试间更稳定，提出ASPEN混合架构通过乘法融合频谱和时域特征流，在多个脑机接口数据集上实现了优秀的跨被试泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑机接口中由于个体神经信号的变异性，跨被试泛化仍然具有挑战性。研究旨在探索频谱表示是否比时域波形提供更稳定的跨被试迁移特征。

Method: 通过三种脑电范式（SSVEP、P300和运动想象）的相关性分析，发现频谱特征比时域信号具有更高的跨被试相似性。基于此观察，提出了ASPEN混合架构，通过乘法融合结合频谱和时域特征流，要求跨模态一致性才能传播特征。

Result: 在六个基准数据集上的实验表明，ASPEN能够根据范式动态实现最优的频谱-时域平衡。在六个数据集中的三个上取得了最佳未见被试准确率，在其他数据集上也有竞争力表现。

Conclusion: 乘法多模态融合能够实现有效的跨被试泛化，频谱特征确实比时域特征在跨被试脑机接口中更稳定，ASPEN架构展示了这一优势。

Abstract: Cross-subject generalization in EEG-based brain-computer interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features exhibit consistently higher cross-subject similarity than temporal signals. Motivated by this observation, we introduce ASPEN, a hybrid architecture that combines spectral and temporal feature streams via multiplicative fusion, requiring cross-modal agreement for features to propagate. Experiments across six benchmark datasets reveal that ASPEN is able to dynamically achieve the optimal spectral-temporal balance depending on the paradigm. ASPEN achieves the best unseen-subject accuracy on three of six datasets and competitive performance on others, demonstrating that multiplicative multimodal fusion enables effective cross-subject generalization.

</details>


### [29] [Differentially Private Non-convex Distributionally Robust Optimization](https://arxiv.org/abs/2602.16155)
*Difei Xu,Meng Ding,Zebin Ma,Huanyi Xie,Youming Tao,Aicha Slaitane,Di Wang*

Main category: cs.LG

TL;DR: 本文研究了差分隐私下的分布鲁棒优化（DP-DRO），针对非凸损失和ψ-散度，提出了DP Double-Spider和DP Recursive-Spider方法，在保护隐私的同时实现了与DP-ERM相当的效用保证。


<details>
  <summary>Details</summary>
Motivation: 现实部署面临分布偏移、群体不平衡和对抗扰动，传统经验风险最小化（ERM）在这些情况下性能严重下降。分布鲁棒优化（DRO）通过优化不确定性分布集上的最坏情况期望损失提供鲁棒性，但训练数据包含敏感信息需要差分隐私保护。现有研究主要关注DP-ERM，而DP-DRO由于具有不确定性约束的极小极大优化结构研究较少。

Method: 1. 针对一般ψ-散度的DRO，通过重新表述为最小化问题，提出DP Double-Spider方法；2. 针对KL散度的DRO，通过转化为组合有限和优化问题，提出DP Recursive-Spider方法。两种方法都采用差分隐私机制保护数据。

Result: DP Double-Spider在梯度范数上达到O(1/√n + (√d log(1/δ)/nε)^{2/3})的效用界；DP Recursive-Spider针对KL散度达到O((√d log(1/δ)/nε)^{2/3})，与非凸DP-ERM的最佳已知结果匹配。实验表明所提方法优于现有的DP极小极大优化方法。

Conclusion: 本文填补了DP-DRO研究的空白，提出了针对不同散度的高效差分隐私优化方法，在保护隐私的同时保持了与DP-ERM相当的效用性能，为实际部署中的鲁棒机器学习提供了隐私保护解决方案。

Abstract: Real-world deployments routinely face distribution shifts, group imbalances, and adversarial perturbations, under which the traditional Empirical Risk Minimization (ERM) framework can degrade severely.
  Distributionally Robust Optimization (DRO) addresses this issue by optimizing the worst-case expected loss over an uncertainty set of distributions, offering a principled approach to robustness.
  Meanwhile, as training data in DRO always involves sensitive information, safeguarding it against leakage under Differential Privacy (DP) is essential.
  In contrast to classical DP-ERM, DP-DRO has received much less attention due to its minimax optimization structure with uncertainty constraint.
  To bridge the gap, we provide a comprehensive study of DP-(finite-sum)-DRO with $ψ$-divergence and non-convex loss.
  First, we study DRO with general $ψ$-divergence by reformulating it as a minimization problem, and develop a novel $(\varepsilon, δ)$-DP optimization method, called DP Double-Spider, tailored to this structure.
  Under mild assumptions, we show that it achieves a utility bound of $\mathcal{O}(\frac{1}{\sqrt{n}}+ (\frac{\sqrt{d \log (1/δ)}}{n \varepsilon})^{2/3})$ in terms of the gradient norm, where $n$ denotes the data size and $d$ denotes the model dimension.
  We further improve the utility rate for specific divergences.
  In particular, for DP-DRO with KL-divergence, by transforming the problem into a compositional finite-sum optimization problem, we develop a DP Recursive-Spider method and show that it achieves a utility bound of $\mathcal{O}((\frac{\sqrt{d \log(1/δ)}}{n\varepsilon})^{2/3} )$, matching the best-known result for non-convex DP-ERM.
  Experimentally, we demonstrate that our proposed methods outperform existing approaches for DP minimax optimization.

</details>


### [30] [HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents](https://arxiv.org/abs/2602.16165)
*Jiangweizhi Peng,Yuanxin Liu,Ruida Zhou,Charles Fleming,Zhaoran Wang,Alfredo Garcia,Mingyi Hong*

Main category: cs.LG

TL;DR: HiPER：分层计划-执行强化学习框架，通过高层规划与底层执行分离，解决LLM智能体在稀疏奖励长时任务中的信用分配问题


<details>
  <summary>Details</summary>
Motivation: 现有RL方法将LLM智能体建模为单时间尺度的平面策略，在稀疏奖励的长时任务中难以进行有效的信用分配，导致优化不稳定和效率低下

Method: 提出HiPER分层框架，将策略分解为高层规划器（提出子目标）和底层执行器（执行多个动作步骤），并引入分层优势估计技术协调两个层级的信用分配

Result: 在ALFWorld上达到97.4%成功率，WebShop上达到83.3%（分别比之前最佳方法提升6.6%和8.3%），在需要多个依赖子任务的长时任务上表现尤为突出

Conclusion: 显式的分层分解对于可扩展的多轮LLM智能体RL训练至关重要，HiPER框架通过分离规划与执行有效解决了稀疏奖励环境中的信用分配问题

Abstract: Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajectory without explicit temporal abstraction, which often leads to unstable optimization and inefficient credit assignment.
  We propose HiPER, a novel Hierarchical Plan-Execute RL framework that explicitly separates high-level planning from low-level execution. HiPER factorizes the policy into a high-level planner that proposes subgoals and a low-level executor that carries them out over multiple action steps. To align optimization with this structure, we introduce a key technique called hierarchical advantage estimation (HAE), which carefully assigns credit at both the planning and execution levels. By aggregating returns over the execution of each subgoal and coordinating updates across the two levels, HAE provides an unbiased gradient estimator and provably reduces variance compared to flat generalized advantage estimation.
  Empirically, HiPER achieves state-of-the-art performance on challenging interactive benchmarks, reaching 97.4\% success on ALFWorld and 83.3\% on WebShop with Qwen2.5-7B-Instruct (+6.6\% and +8.3\% over the best prior method), with especially large gains on long-horizon tasks requiring multiple dependent subtasks. These results highlight the importance of explicit hierarchical decomposition for scalable RL training of multi-turn LLM agents.

</details>


### [31] [Muon with Spectral Guidance: Efficient Optimization for Scientific Machine Learning](https://arxiv.org/abs/2602.16167)
*Binghang Lu,Jiahao Zhang,Guang Lin*

Main category: cs.LG

TL;DR: 提出SpecMuon优化器，结合Muon的正交几何与模式松弛标量辅助变量机制，改善物理信息神经网络中的优化问题


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络和神经算子常面临优化困难，包括病态梯度、多尺度谱行为和物理约束引起的刚度问题。Muon优化器通过正交化更新在梯度奇异向量基中表现良好，但单位奇异值更新可能导致过于激进的步长，且缺乏显式稳定性保证。

Method: 提出SpecMuon优化器，将矩阵值梯度分解为奇异模式，沿主导谱方向单独应用RSAV更新。通过全局损失能量自适应调节步长，同时保留Muon的尺度平衡特性，将优化解释为多模式梯度流。

Result: 建立了SpecMuon的严格理论性质，包括修正的能量耗散定律、辅助变量的正性和有界性，以及在Polyak-Lojasiewicz条件下的全局收敛性。在一维Burgers方程和分数偏微分方程等基准问题上，SpecMuon相比Adam、AdamW和原始Muon优化器实现了更快的收敛和更好的稳定性。

Conclusion: SpecMuon通过谱感知优化有效解决了物理信息学习中的优化困难，结合了正交几何和自适应稳定性控制，为物理信息神经网络提供了更稳定高效的优化方案。

Abstract: Physics-informed neural networks and neural operators often suffer from severe optimization difficulties caused by ill-conditioned gradients, multi-scale spectral behavior, and stiffness induced by physical constraints. Recently, the Muon optimizer has shown promise by performing orthogonalized updates in the singular-vector basis of the gradient, thereby improving geometric conditioning. However, its unit-singular-value updates may lead to overly aggressive steps and lack explicit stability guarantees when applied to physics-informed learning. In this work, we propose SpecMuon, a spectral-aware optimizer that integrates Muon's orthogonalized geometry with a mode-wise relaxed scalar auxiliary variable (RSAV) mechanism. By decomposing matrix-valued gradients into singular modes and applying RSAV updates individually along dominant spectral directions, SpecMuon adaptively regulates step sizes according to the global loss energy while preserving Muon's scale-balancing properties. This formulation interprets optimization as a multi-mode gradient flow and enables principled control of stiff spectral components. We establish rigorous theoretical properties of SpecMuon, including a modified energy dissipation law, positivity and boundedness of auxiliary variables, and global convergence with a linear rate under the Polyak-Lojasiewicz condition. Numerical experiments on physics-informed neural networks, DeepONets, and fractional PINN-DeepONets demonstrate that SpecMuon achieves faster convergence and improved stability compared with Adam, AdamW, and the original Muon optimizer on benchmark problems such as the one-dimensional Burgers equation and fractional partial differential equations.

</details>


### [32] [Discrete Stochastic Localization for Non-autoregressive Generation](https://arxiv.org/abs/2602.16169)
*Yunshu Wu,Jiayi Cheng,Partha Thakuria,Rob Brekelmans,Evangelos E. Papalexakis,Greg Ver Steeg*

Main category: cs.LG

TL;DR: DSL方法通过训练单一SNR不变的降噪器，在连续噪声水平上优化掩码扩散语言模型，显著提升采样效率，在4倍少步数下超越基线，并在高步数时达到自回归质量。


<details>
  <summary>Details</summary>
Motivation: 非自回归生成虽然能并行预测多个token减少解码延迟，但迭代精炼常面临错误累积和自生成草稿下的分布偏移问题。掩码扩散语言模型及其重掩码采样器可视为现代NAR迭代精炼，但现有方法在采样效率方面仍有改进空间。

Method: 提出DSL（离散随机定位）方法，训练单一SNR不变的降噪器，使其能在连续噪声水平上工作，将中间草稿噪声和掩码式端点损坏统一在一个扩散变换器中。

Result: 在OpenWebText数据集上，DSL微调在低步数预算下获得显著MAUVE提升，以约4倍少的降噪器评估超越MDLM+ReMDM基线，在高预算时匹配自回归质量。分析显示改进了自校正和不确定性校准。

Conclusion: 仅通过训练就能显著提升MDLM/ReMDM采样的步数效率，使重掩码采样在计算效率上大幅提升，为高效非自回归生成提供了新途径。

Abstract: Non-autoregressive (NAR) generation reduces decoding latency by predicting many tokens in parallel, but iterative refinement often suffers from error accumulation and distribution shift under self-generated drafts. Masked diffusion language models (MDLMs) and their remasking samplers (e.g., ReMDM) can be viewed as modern NAR iterative refinement, where generation repeatedly revises a partially observed draft. In this work we show that \emph{training alone} can substantially improve the step-efficiency of MDLM/ReMDM sampling. We propose \textsc{DSL} (Discrete Stochastic Localization), which trains a single SNR-invariant denoiser across a continuum of corruption levels, bridging intermediate draft noise and mask-style endpoint corruption within one Diffusion Transformer. On OpenWebText, \textsc{DSL} fine-tuning yields large MAUVE gains at low step budgets, surpassing the MDLM+ReMDM baseline with \(\sim\)4$\times$ fewer denoiser evaluations, and matches autoregressive quality at high budgets. Analyses show improved self-correction and uncertainty calibration, making remasking markedly more compute-efficient.

</details>


### [33] [Towards Secure and Scalable Energy Theft Detection: A Federated Learning Approach for Resource-Constrained Smart Meters](https://arxiv.org/abs/2602.16181)
*Diego Labate,Dipanwita Thakur,Giancarlo Fortino*

Main category: cs.LG

TL;DR: 提出基于联邦学习的隐私保护能源盗窃检测框架，使用轻量级MLP模型和差分隐私技术，在保护用户隐私的同时实现高效的盗窃检测。


<details>
  <summary>Details</summary>
Motivation: 能源盗窃对智能电网稳定性和效率构成重大威胁，传统集中式机器学习方法需要聚合用户数据，存在隐私和安全问题，且智能电表设备资源受限无法运行复杂模型。

Method: 提出隐私保护的联邦学习框架，采用轻量级多层感知器（MLP）模型适应低功耗智能电表，集成基础差分隐私技术，在本地模型更新时注入高斯噪声后再聚合。

Result: 在真实智能电表数据集上评估，在IID和非IID数据分布下均取得有竞争力的准确率、精确率、召回率和AUC分数，同时保持隐私保护和计算效率。

Conclusion: 该解决方案在保护隐私和满足计算约束的同时实现了有效的能源盗窃检测，具有实用性和可扩展性，适用于下一代智能电网基础设施。

Abstract: Energy theft poses a significant threat to the stability and efficiency of smart grids, leading to substantial economic losses and operational challenges. Traditional centralized machine learning approaches for theft detection require aggregating user data, raising serious concerns about privacy and data security. These issues are further exacerbated in smart meter environments, where devices are often resource-constrained and lack the capacity to run heavy models. In this work, we propose a privacy-preserving federated learning framework for energy theft detection that addresses both privacy and computational constraints. Our approach leverages a lightweight multilayer perceptron (MLP) model, suitable for deployment on low-power smart meters, and integrates basic differential privacy (DP) by injecting Gaussian noise into local model updates before aggregation. This ensures formal privacy guarantees without compromising learning performance. We evaluate our framework on a real-world smart meter dataset under both IID and non-IID data distributions. Experimental results demonstrate that our method achieves competitive accuracy, precision, recall, and AUC scores while maintaining privacy and efficiency. This makes the proposed solution practical and scalable for secure energy theft detection in next-generation smart grid infrastructures.

</details>


### [34] [Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting](https://arxiv.org/abs/2602.16188)
*Filippos Bellos,NaveenJohn Premkumar,Yannis Avrithis,Nam H. Nguyen,Jason J. Corso*

Main category: cs.LG

TL;DR: TPC通过将时间作为首要模态，在多个深度层面对模型进行条件化，解决了传统LLM-for-TS方法中时间信息在层间衰减的问题，在长期预测中实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-for-TS方法通常只在输入层注入时间信息（如位置编码或提示），导致时间信息在深层网络中衰减，限制了模型的时间推理能力。

Method: 提出Temporal-Prior Conditioning (TPC)：1) 将可学习的时间序列token附加到patch流中；2) 在选定层中，这些token通过交叉注意力机制关注由冻结LLM编码的紧凑、人类可读时间描述符生成的时间嵌入；3) 通过自注意力将时间上下文反馈给模型，实现时间序列信号与时间信息的解耦。

Result: TPC在仅训练交叉注意力模块的情况下，在多个数据集上的长期预测任务中，一致优于完全微调和浅层条件化策略，达到了最先进的性能。

Conclusion: 将时间提升为首要模态，通过深度条件化和解耦时间序列信号与时间信息，能够显著提升LLM在时间序列预测中的性能，同时保持较低的参数预算。

Abstract: LLM-for-time series (TS) methods typically treat time shallowly, injecting positional or prompt-based cues once at the input of a largely frozen decoder, which limits temporal reasoning as this information degrades through the layers. We introduce Temporal-Prior Conditioning (TPC), which elevates time to a first-class modality that conditions the model at multiple depths. TPC attaches a small set of learnable time series tokens to the patch stream; at selected layers these tokens cross-attend to temporal embeddings derived from compact, human-readable temporal descriptors encoded by the same frozen LLM, then feed temporal context back via self-attention. This disentangles time series signal and temporal information while maintaining a low parameter budget. We show that by training only the cross-attention modules and explicitly disentangling time series signal and temporal information, TPC consistently outperforms both full fine-tuning and shallow conditioning strategies, achieving state-of-the-art performance in long-term forecasting across diverse datasets. Code available at: https://github.com/fil-mp/Deep_tpc

</details>


### [35] [Rethinking Input Domains in Physics-Informed Neural Networks via Geometric Compactification Mappings](https://arxiv.org/abs/2602.16193)
*Zhenzhen Huang,Haoyu Bian,Jiaquan Zhang,Yibei Liu,Kuien Liu,Caiyan Qin,Guoqing Wang,Yang Yang,Chaoning Zhang*

Main category: cs.LG

TL;DR: GC-PINN通过几何紧化映射重塑输入坐标，解决PINN中多尺度PDE的梯度刚性问题，提高训练稳定性和收敛速度


<details>
  <summary>Details</summary>
Motivation: 多尺度偏微分方程同时包含平滑低频分量和局部高频结构，传统PINN使用固定坐标系输入时，几何错位会导致梯度刚性和病态问题，阻碍收敛

Method: 提出几何紧化映射范式，通过可微几何紧化映射重塑输入坐标，将PDE的几何结构与残差算子的谱特性耦合。提出GC-PINN框架，包含三种映射策略：周期性边界、远场尺度扩展和局部奇异结构，无需修改底层PINN架构

Result: 在代表性1D和2D PDE上的广泛实验表明，该方法能产生更均匀的残差分布和更高的求解精度，同时改善训练稳定性和收敛速度

Conclusion: 几何紧化映射能有效解决PINN在多尺度PDE中的梯度刚性问题，通过输入坐标的几何变换改善训练性能，为复杂物理系统的数值求解提供新思路

Abstract: Several complex physical systems are governed by multi-scale partial differential equations (PDEs) that exhibit both smooth low-frequency components and localized high-frequency structures. Existing physics-informed neural network (PINN) methods typically train with fixed coordinate system inputs, where geometric misalignment with these structures induces gradient stiffness and ill-conditioning that hinder convergence. To address this issue, we introduce a mapping paradigm that reshapes the input coordinates through differentiable geometric compactification mappings and couples the geometric structure of PDEs with the spectral properties of residual operators. Based on this paradigm, we propose Geometric Compactification (GC)-PINN, a framework that introduces three mapping strategies for periodic boundaries, far-field scale expansion, and localized singular structures in the input domain without modifying the underlying PINN architecture. Extensive empirical evaluation demonstrates that this approach yields more uniform residual distributions and higher solution accuracy on representative 1D and 2D PDEs, while improving training stability and convergence speed.

</details>


### [36] [Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16196)
*Emile Anand,Richard Hoffmann,Sarah Liaw,Adam Wierman*

Main category: cs.LG

TL;DR: 提出GMFS框架，通过子采样方法解决异构多智能体强化学习的可扩展性问题，在保持理论保证的同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，联合状态-动作空间随智能体数量指数增长，传统均值场方法假设同质交互，而图论方法虽能处理异质性但计算成本高。

Method: 提出图论均值场子采样框架(GMFS)，根据交互强度子采样κ个智能体，近似图论加权的均值场，实现多项式样本复杂度。

Result: 理论证明样本复杂度为poly(κ)，最优性差距为O(1/√κ)，在机器人协调任务中数值模拟显示达到接近最优性能。

Conclusion: GMFS框架为具有异构交互的可扩展合作多智能体强化学习提供了有效解决方案，平衡了计算效率与性能。

Abstract: Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\texttt{GMFS}$, a $\textbf{G}$raphon $\textbf{M}$ean-$\textbf{F}$ield $\textbf{S}$ubsampling framework for scalable cooperative MARL with heterogeneous agent interactions. By subsampling $κ$ agents according to interaction strength, we approximate the graphon-weighted mean-field and learn a policy with sample complexity $\mathrm{poly}(κ)$ and optimality gap $O(1/\sqrtκ)$. We verify our theory with numerical simulations in robotic coordination, showing that $\texttt{GMFS}$ achieves near-optimal performance.

</details>


### [37] [ModalImmune: Immunity Driven Unlearning via Self Destructive Training](https://arxiv.org/abs/2602.16197)
*Rong Fu,Jia Yee Tan,Wenxin Zhang,Zijian Zhang,Ziming Wang,Zhaolu Kang,Muge Qi,Shuning Zhang,Simon Fong*

Main category: cs.LG

TL;DR: ModalImmune训练框架通过可控地破坏模态信息来增强多模态系统对输入通道丢失的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 多模态系统在部署时容易受到部分或完全输入通道丢失的影响，这会削弱其在真实场景中的可靠性

Method: 结合频谱自适应崩溃正则化、信息增益引导控制器、曲率感知梯度掩码和认证的Neumann截断超梯度过程

Result: 在标准多模态基准测试中，ModalImmune提高了对模态移除和损坏的弹性，同时保持了收敛稳定性和重建能力

Conclusion: ModalImmune通过强制模态免疫性，使多模态模型能够学习对破坏性模态影响具有鲁棒性的联合表示

Abstract: Multimodal systems are vulnerable to partial or complete loss of input channels at deployment, which undermines reliability in real-world settings. This paper presents ModalImmune, a training framework that enforces modality immunity by intentionally and controllably collapsing selected modality information during training so the model learns joint representations that are robust to destructive modality influence. The framework combines a spectrum-adaptive collapse regularizer, an information-gain guided controller for targeted interventions, curvature-aware gradient masking to stabilize destructive updates, and a certified Neumann-truncated hyper-gradient procedure for automatic meta-parameter adaptation. Empirical evaluation on standard multimodal benchmarks demonstrates that ModalImmune improves resilience to modality removal and corruption while retaining convergence stability and reconstruction capacity.

</details>


### [38] [Training-Free Adaptation of Diffusion Models via Doob's $h$-Transform](https://arxiv.org/abs/2602.16198)
*Qijie Zhu,Zeqi Ye,Han Liu,Zhaoran Wang,Minshuo Chen*

Main category: cs.LG

TL;DR: DOIT是一种无需训练、计算高效的扩散模型适应方法，通过Doob's h-transform实现生成分布到高奖励目标分布的传输，适用于不可微分的通用奖励函数。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型适应方法通常需要额外训练（计算开销大）或要求奖励函数可微，且缺乏理论保证。需要一种训练免费、计算高效、适用于不可微分奖励函数的方法。

Method: 提出DOIT方法，基于测度传输框架，利用Doob's h-transform将预训练生成分布传输到高奖励目标分布。该方法在扩散采样过程中引入动态校正，无需修改预训练模型，通过模拟计算实现高效适应。

Result: 理论方面：建立了高概率收敛保证，通过分析动态Doob校正的近似误差来表征收敛性。实验方面：在D4RL离线RL基准测试中，DOIT始终优于现有最优方法，同时保持采样效率。

Conclusion: DOIT是一种训练免费、计算高效的扩散模型适应方法，适用于不可微分的通用奖励函数，具有理论保证和实证优势，为扩散模型在多样化应用中的适应提供了新思路。

Abstract: Adaptation methods have been a workhorse for unlocking the transformative power of pre-trained diffusion models in diverse applications. Existing approaches often abstract adaptation objectives as a reward function and steer diffusion models to generate high-reward samples. However, these approaches can incur high computational overhead due to additional training, or rely on stringent assumptions on the reward such as differentiability. Moreover, despite their empirical success, theoretical justification and guarantees are seldom established. In this paper, we propose DOIT (Doob-Oriented Inference-time Transformation), a training-free and computationally efficient adaptation method that applies to generic, non-differentiable rewards. The key framework underlying our method is a measure transport formulation that seeks to transport the pre-trained generative distribution to a high-reward target distribution. We leverage Doob's $h$-transform to realize this transport, which induces a dynamic correction to the diffusion sampling process and enables efficient simulation-based computation without modifying the pre-trained model. Theoretically, we establish a high probability convergence guarantee to the target high-reward distribution via characterizing the approximation error in the dynamic Doob's correction. Empirically, on D4RL offline RL benchmarks, our method consistently outperforms state-of-the-art baselines while preserving sampling efficiency.

</details>


### [39] [Linked Data Classification using Neurochaos Learning](https://arxiv.org/abs/2602.16204)
*Pooja Honna,Ayush Patravali,Nithin Nagaraj,Nanjangud C. Narendra*

Main category: cs.LG

TL;DR: 该论文将神经混沌学习应用于知识图谱数据，通过节点聚合将图数据输入ChaosNet架构，在同性图和异性图数据集上测试性能。


<details>
  <summary>Details</summary>
Motivation: 神经混沌学习在小样本学习和低计算需求方面优于传统深度学习，但之前主要应用于可分数据和时序数据。本研究旨在将NL扩展到链接数据，特别是知识图谱。

Method: 在知识图谱上实现节点聚合，将聚合后的节点特征输入最简单的NL架构ChaosNet。在同性图和不同异性程度的异性图数据集上进行测试。

Result: 该方法在同性图上的效果优于异性图。论文提供了结果分析并提出了未来工作建议。

Conclusion: 成功将神经混沌学习扩展到知识图谱数据，验证了其在图数据上的可行性，特别是在同性图上的良好表现，为NL在图学习领域的应用奠定了基础。

Abstract: Neurochaos Learning (NL) has shown promise in recent times over traditional deep learning due to its two key features: ability to learn from small sized training samples, and low compute requirements. In prior work, NL has been implemented and extensively tested on separable and time series data, and demonstrated its superior performance on both classification and regression tasks. In this paper, we investigate the next step in NL, viz., applying NL to linked data, in particular, data that is represented in the form of knowledge graphs. We integrate linked data into NL by implementing node aggregation on knowledge graphs, and then feeding the aggregated node features to the simplest NL architecture: ChaosNet. We demonstrate the results of our implementation on homophilic graph datasets as well as heterophilic graph datasets of verying heterophily. We show better efficacy of our approach on homophilic graphs than on heterophilic graphs. While doing so, we also present our analysis of the results, as well as suggestions for future work.

</details>


### [40] [Geometric Neural Operators via Lie Group-Constrained Latent Dynamics](https://arxiv.org/abs/2602.16209)
*Jiaquan Zhang,Fachrina Dewi Puspitasari,Songbo Zhang,Yibei Liu,Kuien Liu,Caiyan Qin,Fan Mo,Peng Wang,Yang Yang,Chaoning Zhang*

Main category: cs.LG

TL;DR: 提出MCL方法，通过低秩李代数参数化约束流形，为神经算子添加几何归纳偏置，提高长期预测稳定性，在多种PDE上降低30-50%相对误差


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在多层迭代和长期推演中存在不稳定性，源于欧几里得潜在空间更新违反几何和守恒定律，需要引入几何约束

Method: 提出基于李群的流形约束方法(MCL)，使用低秩李代数参数化约束流形，在潜在表示上执行群作用更新，作为即插即用模块增强现有神经算子

Result: 在1-D Burgers和2-D Navier-Stokes等多种PDE上，在广泛参数和步长范围内，相对预测误差降低30-50%，仅增加2.26%参数

Conclusion: MCL方法通过解决神经算子更新中缺失的几何约束，为改善长期预测保真度提供了可扩展解决方案

Abstract: Neural operators offer an effective framework for learning solutions of partial differential equations for many physical systems in a resolution-invariant and data-driven manner. Existing neural operators, however, often suffer from instability in multi-layer iteration and long-horizon rollout, which stems from the unconstrained Euclidean latent space updates that violate the geometric and conservation laws. To address this challenge, we propose to constrain manifolds with low-rank Lie algebra parameterization that performs group action updates on the latent representation. Our method, termed Manifold Constraining based on Lie group (MCL), acts as an efficient \emph{plug-and-play} module that enforces geometric inductive bias to existing neural operators. Extensive experiments on various partial differential equations, such as 1-D Burgers and 2-D Navier-Stokes, over a wide range of parameters and steps demonstrate that our method effectively lowers the relative prediction error by 30-50\% at the cost of 2.26\% of parameter increase. The results show that our approach provides a scalable solution for improving long-term prediction fidelity by addressing the principled geometric constraints absent in the neural operator updates.

</details>


### [41] [Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study](https://arxiv.org/abs/2602.16523)
*Gerhard Stenzel,Isabella Debelic,Michael Kölle,Tobias Rohe,Leo Sünkel,Julian Hager,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 论文扩展了DQCS强化学习方法，从离散门选择到包含连续单量子比特旋转的参数化量子态制备，比较了单阶段和两阶段训练策略，发现PPO在稳定超参数下表现良好，但可扩展性在λ≈3-4时饱和。


<details>
  <summary>Details</summary>
Motivation: 将强化学习应用于量子电路合成时，现有方法主要关注离散门选择，而实际量子态制备需要连续旋转参数。研究旨在扩展DQCS方法以处理连续参数优化问题，并比较不同训练策略的效果。

Method: 1) 单阶段代理：联合选择门类型、作用量子比特和旋转角度；2) 两阶段变体：先提出离散电路，再用Adam和参数偏移梯度优化旋转角度。使用Gymnasium和PennyLane平台，评估PPO和A2C算法在2-10量子比特系统上的表现，目标复杂度λ=1-5。

Result: A2C在此设置下无法学习有效策略，PPO在稳定超参数下成功（单阶段：学习率≈5×10⁻⁴，自保真度误差阈值0.01；两阶段：学习率≈10⁻⁴）。两种方法能可靠重构计算基态（成功率83%-99%）和贝尔态（成功率61%-77%），但可扩展性在λ≈3-4时饱和，无法扩展到10量子比特目标（即使λ=2）。两阶段方法仅提供边际精度提升，但需要约3倍运行时间。

Conclusion: 在固定计算预算下，推荐使用单阶段PPO策略。论文提供了明确的合成电路，并与经典变分基线对比，为改进可扩展性指明了方向。两阶段方法虽然理论上更精确，但计算成本过高，实用性有限。

Abstract: We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations \(R_x\), \(R_y\), and \(R_z\). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with \(λ\) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately \(5\times10^{-4}\) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately \(10^{-4}\)). Both approaches reliably reconstruct computational basis states (between 83\% and 99\% success) and Bell states (between 61\% and 77\% success). However, scalability saturates for \(λ\) of approximately three to four and does not extend to ten-qubit targets even at \(λ=2\). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability.

</details>


### [42] [Illustration of Barren Plateaus in Quantum Computing](https://arxiv.org/abs/2602.16558)
*Gerhard Stenzel,Tobias Rohe,Michael Kölle,Leo Sünkel,Jonas Stein,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 参数共享在变分量子电路中虽然能减少参数维度并可能缓解贫瘠高原现象，但会通过欺骗性梯度改变优化景观，增加优化难度，导致传统梯度优化器性能下降。


<details>
  <summary>Details</summary>
Motivation: 研究参数共享在变分量子电路中的复杂权衡，尽管参数共享能减少参数空间维度并可能缓解贫瘠高原现象，但其对优化景观的影响被长期忽视，特别是可能引入欺骗性梯度问题。

Method: 通过系统实验分析，研究不同参数共享程度对优化景观的影响；引入梯度欺骗性检测算法和量子电路优化难度量化框架；评估传统梯度优化器（Adam、SGD）在不同参数共享程度下的性能。

Result: 增加参数共享程度会产生更复杂的解景观，梯度幅度增加且欺骗性比率显著提高；传统梯度优化器性能随参数共享增加而下降，性能高度依赖超参数选择；参数共享能提高电路表达能力几个数量级，但代价是显著增加景观欺骗性。

Conclusion: 参数共享在变分量子电路中存在根本性权衡：虽然能提高表达能力和减少参数，但会显著增加优化景观的欺骗性，导致经典优化策略与量子参数景观之间的不匹配，这对实际应用中的量子电路设计具有重要启示。

Abstract: Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.

</details>


### [43] [UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection](https://arxiv.org/abs/2602.16216)
*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.LG

TL;DR: UCTECG-Net：结合一维卷积和Transformer编码器的混合架构，用于ECG分类和不确定性量化，在MIT-BIH和PTB数据集上达到98.58%和99.14%的准确率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在ECG分类中已有改进，但预测可靠性缺乏洞察，阻碍了其在安全关键场景中的应用。需要不确定性感知的ECG分类模型。

Method: 提出UCTECG-Net混合架构，结合一维卷积和Transformer编码器，同时处理原始ECG信号和其频谱图。集成三种不确定性量化方法：蒙特卡洛Dropout、深度集成和集成蒙特卡洛Dropout。

Result: 在MIT-BIH和PTB数据集上分别达到98.58%和99.14%的准确率，优于LSTM、CNN1D和Transformer基线。UCTECG-Net（特别是使用集成或EMCD方法）提供更可靠、对齐更好的不确定性估计。

Conclusion: UCTECG-Net为风险感知的ECG决策支持提供了更强基础，其不确定性感知架构在ECG分类中表现出优越性能。

Abstract: Deep learning has improved automated electrocardiogram (ECG) classification, but limited insight into prediction reliability hinders its use in safety-critical settings. This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outperforms LSTM, CNN1D, and Transformer baselines in terms of accuracy, precision, recall and F1 score, achieving up to 98.58% accuracy on MIT-BIH and 99.14% on PTB. To assess predictive reliability, we integrate three uncertainty quantification methods (Monte Carlo Dropout, Deep Ensembles, and Ensemble Monte Carlo Dropout) into all models and analyze their behavior using an uncertainty-aware confusion matrix and derived metrics. The results show that UCTECG-Net, particularly with Ensemble or EMCD, provides more reliable and better-aligned uncertainty estimates than competing architectures, offering a stronger basis for risk-aware ECG decision support.

</details>


### [44] [Multi-Class Boundary Extraction from Implicit Representations](https://arxiv.org/abs/2602.16217)
*Jash Vira,Andrew Myers,Simon Ratcliffe*

Main category: cs.LG

TL;DR: 提出一种用于多类别隐式神经表示的2D边界提取算法，保证拓扑一致性和水密性，支持细节约束设置


<details>
  <summary>Details</summary>
Motivation: 目前缺乏从多类别隐式表示中提取边界的方法，无法保证拓扑正确性和无孔洞特性

Method: 开发2D边界提取算法，专注于拓扑一致性和水密性，允许设置最小细节约束

Result: 使用地质建模数据评估算法，展示其适应性和处理复杂拓扑的能力

Conclusion: 为多类别隐式表示的表面提取奠定了基础，提供拓扑正确且无孔洞的边界提取方法

Abstract: Surface extraction from implicit neural representations modelling a single class surface is a well-known task. However, there exist no surface extraction methods from an implicit representation of multiple classes that guarantee topological correctness and no holes. In this work, we lay the groundwork by introducing a 2D boundary extraction algorithm for the multi-class case focusing on topological consistency and water-tightness, which also allows for setting minimum detail restraint on the approximation. Finally, we evaluate our algorithm using geological modelling data, showcasing its adaptiveness and ability to honour complex topology.

</details>


### [45] [Bayesian Quadrature: Gaussian Processes for Integration](https://arxiv.org/abs/2602.16218)
*Maren Mahsereci,Toni Karvonen*

Main category: cs.LG

TL;DR: 这篇论文是关于贝叶斯求积法的系统性综述，涵盖了其数学基础、分类体系、理论保证、数值研究以及实际应用挑战。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯求积法是一种基于模型的概率数值积分方法，虽然自1980年代就已出现，但缺乏系统全面的综述。本文旨在填补这一空白，提供对这一方法的全面审视。

Method: 论文从多个角度回顾贝叶斯求积法的数学基础，提出基于建模、推断和采样三个维度的分类体系，收集理论保证，并进行受控数值研究来探索不同选择的影响。

Result: 论文提供了贝叶斯求积法的系统性综述，包括分类框架、理论结果和数值分析，同时评估了实际应用中的挑战和限制。

Conclusion: 这篇综述填补了贝叶斯求积法文献的空白，为研究人员提供了全面的参考框架，包括分类体系、理论保证和实际应用指导，并附有几乎穷尽的跨学科参考文献。

Abstract: Bayesian quadrature is a probabilistic, model-based approach to numerical integration, the estimation of intractable integrals, or expectations. Although Bayesian quadrature was popularised already in the 1980s, no systematic and comprehensive treatment has been published. The purpose of this survey is to fill this gap. We review the mathematical foundations of Bayesian quadrature from different points of view; present a systematic taxonomy for classifying different Bayesian quadrature methods along the three axes of modelling, inference, and sampling; collect general theoretical guarantees; and provide a controlled numerical study that explores and illustrates the effect of different choices along the axes of the taxonomy. We also provide a realistic assessment of practical challenges and limitations to application of Bayesian quadrature methods and include an up-to-date and nearly exhaustive bibliography that covers not only machine learning and statistics literature but all areas of mathematics and engineering in which Bayesian quadrature or equivalent methods have seen use.

</details>


### [46] [SEMixer: Semantics Enhanced MLP-Mixer for Multiscale Mixing and Long-term Time Series Forecasting](https://arxiv.org/abs/2602.16220)
*Xu Zhang,Qitong Wang,Peng Wang,Wei Wang*

Main category: cs.LG

TL;DR: SEMixer：一种用于长期时间序列预测的轻量级多尺度模型，通过随机注意力机制和多尺度渐进混合链解决多尺度模式建模的挑战


<details>
  <summary>Details</summary>
Motivation: 时间序列中的冗余和噪声，以及非相邻尺度之间的语义鸿沟，使得多尺度时间依赖性的高效对齐和整合变得困难。需要一种能够有效建模多尺度模式的方法来进行长期时间序列预测。

Method: 提出SEMixer模型，包含两个关键组件：1) 随机注意力机制(RAM)：在训练中捕获多样化的时间片段交互，在推理时通过dropout集成进行聚合，增强片段级语义；2) 多尺度渐进混合链(MPMC)：以内存高效的方式堆叠RAM和MLP-Mixer，实现更有效的时间混合。

Result: 在10个公共数据集上验证了SEMixer的有效性，并在基于21GB真实无线网络数据的2025 CCF AlOps挑战赛中获得第三名。

Conclusion: SEMixer通过创新的随机注意力机制和多尺度渐进混合链，有效解决了多尺度时间序列建模中的挑战，在长期预测任务中表现出色，并在实际工业场景中得到验证。

Abstract: Modeling multiscale patterns is crucial for long-term time series forecasting (TSF). However, redundancy and noise in time series, together with semantic gaps between non-adjacent scales, make the efficient alignment and integration of multi-scale temporal dependencies challenging. To address this, we propose SEMixer, a lightweight multiscale model designed for long-term TSF. SEMixer features two key components: a Random Attention Mechanism (RAM) and a Multiscale Progressive Mixing Chain (MPMC). RAM captures diverse time-patch interactions during training and aggregates them via dropout ensemble at inference, enhancing patch-level semantics and enabling MLP-Mixer to better model multi-scale dependencies. MPMC further stacks RAM and MLP-Mixer in a memory-efficient manner, achieving more effective temporal mixing. It addresses semantic gaps across scales and facilitates better multiscale modeling and forecasting performance. We not only validate the effectiveness of SEMixer on 10 public datasets, but also on the \textit{2025 CCF AlOps Challenge} based on 21GB real wireless network data, where SEMixer achieves third place. The code is available at the link https://github.com/Meteor-Stars/SEMixer.

</details>


### [47] [Amortized Predictability-aware Training Framework for Time Series Forecasting and Classification](https://arxiv.org/abs/2602.16224)
*Xu Zhang,Peng Wang,Yichen Li,Wei Wang*

Main category: cs.LG

TL;DR: 提出了APTF框架，通过分层可预测性感知损失和摊销模型，让时间序列模型专注于高可预测性样本，同时适当学习低可预测性样本，提升预测和分类性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据常包含噪声和低可预测性模式，这些样本会偏离正常数据分布，导致训练不稳定或收敛到差的局部最优解。现有深度学习模型很少考虑如何识别和惩罚低可预测性样本来从训练角度提升性能。

Method: 提出APTF框架，包含两个关键设计：1) 分层可预测性感知损失(HPL)：动态识别低可预测性样本，并随着训练进展逐步扩大其损失惩罚；2) 摊销模型：减轻模型偏差导致的可预测性估计误差，增强HPL效果。

Result: APTF是一个通用框架，适用于时间序列预测(TSF)和时间序列分类(TSC)，代码已开源。

Conclusion: APTF通过关注高可预测性样本同时适当学习低可预测性样本，有效提升了时间序列分析任务的性能，填补了现有研究在训练视角处理低可预测性样本的空白。

Abstract: Time series data are prone to noise in various domains, and training samples may contain low-predictability patterns that deviate from the normal data distribution, leading to training instability or convergence to poor local minima. Therefore, mitigating the adverse effects of low-predictability samples is crucial for time series analysis tasks such as time series forecasting (TSF) and time series classification (TSC). While many deep learning models have achieved promising performance, few consider how to identify and penalize low-predictability samples to improve model performance from the training perspective. To fill this gap, we propose a general Amortized Predictability-aware Training Framework (APTF) for both TSF and TSC. APTF introduces two key designs that enable the model to focus on high-predictability samples while still learning appropriately from low-predictability ones: (i) a Hierarchical Predictability-aware Loss (HPL) that dynamically identifies low-predictability samples and progressively expands their loss penalty as training evolves, and (ii) an amortization model that mitigates predictability estimation errors caused by model bias, further enhancing HPL's effectiveness. The code is available at https://github.com/Meteor-Stars/APTF.

</details>


### [48] [Factored Latent Action World Models](https://arxiv.org/abs/2602.16229)
*Zizhao Wang,Chang Shi,Jiaheng Hu,Kevin Rohling,Roberto Martín-Martín,Amy Zhang,Peter Stone*

Main category: cs.LG

TL;DR: FLAM提出因子化潜在动作模型，将场景分解为独立因子，每个因子推断自己的潜在动作并预测下一步因子值，在复杂多实体环境中优于传统单体模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用单体逆动力学和前向动力学模型，学习单一潜在动作控制整个场景，在多个实体同时行动的复杂环境中表现不佳。

Method: 提出因子化潜在动作模型(FLAM)，将场景分解为独立因子，每个因子推断自己的潜在动作并预测自己的下一步因子值，实现因子化动态建模。

Result: 在仿真和真实世界多实体数据集上的实验表明，FLAM在预测精度和表示质量上优于先前工作，并促进下游策略学习。

Conclusion: 因子化潜在动作模型能更准确建模复杂多实体动态，提高无动作视频设置下的视频生成质量，展示了因子化方法的优势。

Abstract: Learning latent actions from action-free video has emerged as a powerful paradigm for scaling up controllable world model learning. Latent actions provide a natural interface for users to iteratively generate and manipulate videos. However, most existing approaches rely on monolithic inverse and forward dynamics models that learn a single latent action to control the entire scene, and therefore struggle in complex environments where multiple entities act simultaneously. This paper introduces Factored Latent Action Model (FLAM), a factored dynamics framework that decomposes the scene into independent factors, each inferring its own latent action and predicting its own next-step factor value. This factorized structure enables more accurate modeling of complex multi-entity dynamics and improves video generation quality in action-free video settings compared to monolithic models. Based on experiments on both simulation and real-world multi-entity datasets, we find that FLAM outperforms prior work in prediction accuracy and representation quality, and facilitates downstream policy learning, demonstrating the benefits of factorized latent action models.

</details>


### [49] [Online Prediction of Stochastic Sequences with High Probability Regret Bounds](https://arxiv.org/abs/2602.16236)
*Matthias Frey,Jonathan H. Manton,Jingge Zhu*

Main category: cs.LG

TL;DR: 该论文研究了有限时间T已知情况下随机序列的通用预测问题，提出了高概率的遗憾界，与现有期望界形式相似，并证明了δ指数的最优性。


<details>
  <summary>Details</summary>
Motivation: 重新审视随机序列通用预测的经典问题，研究是否能在高概率下获得消失的遗憾界，以补充文献中已有的期望界。

Method: 针对可数字母表上的随机过程通用预测，提出了高概率遗憾界，其形式与先前的期望界非常相似，并提供了不可能性结果证明。

Result: 获得了收敛率为O(T^{-1/2}δ^{-1/2})的高概率遗憾界，概率至少为1-δ，而先前期望界的阶为O(T^{-1/2})。

Conclusion: 证明了高概率遗憾界的存在性和最优性，表明在不做额外假设的情况下，无法改进δ的指数，为随机序列预测提供了更全面的理论保证。

Abstract: We revisit the classical problem of universal prediction of stochastic sequences with a finite time horizon $T$ known to the learner. The question we investigate is whether it is possible to derive vanishing regret bounds that hold with high probability, complementing existing bounds from the literature that hold in expectation. We propose such high-probability bounds which have a very similar form as the prior expectation bounds. For the case of universal prediction of a stochastic process over a countable alphabet, our bound states a convergence rate of $\mathcal{O}(T^{-1/2} δ^{-1/2})$ with probability as least $1-δ$ compared to prior known in-expectation bounds of the order $\mathcal{O}(T^{-1/2})$. We also propose an impossibility result which proves that it is not possible to improve the exponent of $δ$ in a bound of the same form without making additional assumptions.

</details>


### [50] [Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge](https://arxiv.org/abs/2602.16264)
*Zixian Wu,Xuebao Li,Yanfang Zheng,Rui Wang,Shunhuang Zhang,Jinfang Wei,Yongshang Lv,Liang Dong,Zamri Zainal Abidin,Noraisyah Mohamed Shah,Hongwei Ye,Pengchao Yan,Xuefeng Li,Xiaojia Ji,Xusheng Huang,Xiaotian Wang,Honglei Jin*

Main category: cs.LG

TL;DR: 首次开发基于类别依赖奖励（CDR）的监督分类框架，用于预测24小时内≥M级太阳耀斑，比较多种深度学习模型和特征组合的性能。


<details>
  <summary>Details</summary>
Motivation: 开发更准确的太阳耀斑预测方法，通过结合类别依赖奖励机制提升模型性能，并与现有NASA/CCMC系统进行比较。

Method: 构建多个数据集（知识特征和LOS磁图），应用三种深度学习模型（CNN、CNN-BiLSTM、Transformer）及其CDR版本，进行特征重要性分析、性能比较、奖励工程敏感性分析和SHAP可解释性分析。

Result: 1) R_VALUE和AREA_ACR是最重要的LOS特征；2) Transformer在结合LOS和矢量磁场数据时表现最佳；3) 知识特征模型优于磁图模型；4) CDR-Transformer在所有模型中表现最好；5) CDR模型对奖励选择不敏感；6) SHAP显示CDR更重视TOTUSJH，Transformer更重视R_VALUE；7) CDR-Transformer优于NASA/CCMC。

Conclusion: CDR-Transformer框架在太阳耀斑预测中表现出色，特别是在使用知识特征时，其性能超越了传统深度学习模型和现有NASA/CCMC系统，为耀斑预测提供了有效的新方法。

Abstract: In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.

</details>


### [51] [Regret and Sample Complexity of Online Q-Learning via Concentration of Stochastic Approximation with Time-Inhomogeneous Markov Chains](https://arxiv.org/abs/2602.16274)
*Rahul Singh,Siddharth Chandak,Eric Moulines,Vivek S. Borkar,Nicholas Bambos*

Main category: cs.LG

TL;DR: 首次提出无乐观项或奖励项的经典在线Q-learning在高概率下的遗憾界，针对无限时域折扣马尔可夫决策过程，分析了Boltzmann Q-learning和Smoothed ε-Greedy探索策略的遗憾性能。


<details>
  <summary>Details</summary>
Motivation: 传统在线Q-learning的遗憾分析通常依赖于乐观方法或奖励项，本文旨在为经典Q-learning（无乐观项）提供首个高概率遗憾界，特别是在无限时域折扣MDP中，探索不同探索策略对遗憾的影响。

Method: 1. 分析温度衰减的Boltzmann Q-learning，研究其遗憾对MDP次优性间隙的依赖性；2. 提出结合ε-greedy和Boltzmann探索的Smoothed ε-Greedy探索方案；3. 开发了具有迭代和时间相关转移动态的收缩马尔可夫随机逼近的高概率集中界。

Result: 1. Boltzmann Q-learning的遗憾严重依赖于MDP的次优性间隙：对于足够大的间隙，遗憾是次线性的；对于小间隙，遗憾会恶化并可能接近线性增长；2. Smoothed ε-Greedy探索方案实现了接近O(N^{9/10})的间隙鲁棒遗憾界；3. 提出的集中界具有独立价值，其收缩因子由混合时间控制并允许渐近收敛到1。

Conclusion: 本文为经典在线Q-learning提供了首个高概率遗憾界，揭示了探索策略对遗憾性能的关键影响，并开发了适用于更广泛随机逼近问题的分析工具。Smoothed ε-Greedy探索方案在间隙鲁棒性方面优于纯Boltzmann探索。

Abstract: We present the first high-probability regret bound for classical online Q-learning in infinite-horizon discounted Markov decision processes, without relying on optimism or bonus terms. We first analyze Boltzmann Q-learning with decaying temperature and show that its regret depends critically on the suboptimality gap of the MDP: for sufficiently large gaps, the regret is sublinear, while for small gaps it deteriorates and can approach linear growth. To address this limitation, we study a Smoothed $ε_n$-Greedy exploration scheme that combines $ε_n$-greedy and Boltzmann exploration, for which we prove a gap-robust regret bound of near-$\tilde{O}(N^{9/10})$. To analyze these algorithms, we develop a high-probability concentration bound for contractive Markovian stochastic approximation with iterate- and time-dependent transition dynamics. This bound may be of independent interest as the contraction factor in our bound is governed by the mixing time and is allowed to converge to one asymptotically.

</details>


### [52] [Fast KV Compaction via Attention Matching](https://arxiv.org/abs/2602.16284)
*Adam Zweiger,Xinghong Fu,Han Guo,Yoon Kim*

Main category: cs.LG

TL;DR: 提出Attention Matching方法，通过匹配注意力输出来构建紧凑的KV缓存，实现快速上下文压缩，在保持性能的同时大幅减少KV缓存大小。


<details>
  <summary>Details</summary>
Motivation: 长上下文语言模型的KV缓存大小成为瓶颈，现有基于摘要的压缩方法损失严重，而Cartridges方法虽然效果好但训练成本高，需要更高效的压缩方法。

Method: 提出Attention Matching框架，通过构建紧凑的键值来复现注意力输出并保持注意力质量，该方法可分解为简单子问题，部分有闭式解，实现快速压缩。

Result: 在压缩时间与质量之间显著推进Pareto前沿，在某些数据集上实现50倍压缩且质量损失很小，压缩过程仅需数秒。

Conclusion: Attention Matching提供了一种高效的长上下文压缩方法，在保持性能的同时大幅减少KV缓存大小，解决了现有方法的效率与质量权衡问题。

Abstract: Scaling language models to long contexts is often bottlenecked by the size of the key-value (KV) cache. In deployed settings, long contexts are typically managed through compaction in token space via summarization. However, summarization can be highly lossy, substantially harming downstream performance. Recent work on Cartridges has shown that it is possible to train highly compact KV caches in latent space that closely match full-context performance, but at the cost of slow and expensive end-to-end optimization. This work describes an approach for fast context compaction in latent space through Attention Matching, which constructs compact keys and values to reproduce attention outputs and preserve attention mass at a per-KV-head level. We show that this formulation naturally decomposes into simple subproblems, some of which admit efficient closed-form solutions. Within this framework, we develop a family of methods that significantly push the Pareto frontier of compaction time versus quality, achieving up to 50x compaction in seconds on some datasets with little quality loss.

</details>


### [53] [A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.16316)
*Guy Bar-Shalom,Ami Tavory,Itay Evron,Maya Bechler-Speicher,Ido Guy,Haggai Maron*

Main category: cs.LG

TL;DR: 提出了首个针对KANs的权重空间架构WS-KAN，通过KAN-graph表示和对称性处理，在多种任务上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有权重空间模型主要针对标准神经网络设计，缺乏对Kolmogorov-Arnold Networks (KANs)的专门架构。虽然先前工作利用标准网络的置换对称性，但KANs的类似分析和定制架构尚不存在。

Method: 1) 证明KANs与MLPs具有相同的置换对称性；2) 提出KAN-graph作为计算图表示；3) 开发WS-KAN架构，自然考虑KANs的对称性；4) 分析WS-KAN的表达能力；5) 构建包含多种任务的KANs训练"动物园"作为基准。

Result: WS-KAN在所有任务上都一致优于结构无关的基线方法，通常优势显著。代码已开源。

Conclusion: 成功开发了首个针对KANs的权重空间架构WS-KAN，通过利用KANs的对称性，在KANs的元学习任务上取得了显著改进。

Abstract: Weight-space models learn directly from the parameters of neural networks, enabling tasks such as predicting their accuracy on new datasets. Naive methods -- like applying MLPs to flattened parameters -- perform poorly, making the design of better weight-space architectures a central challenge. While prior work leveraged permutation symmetries in standard networks to guide such designs, no analogous analysis or tailored architecture yet exists for Kolmogorov-Arnold Networks (KANs). In this work, we show that KANs share the same permutation symmetries as MLPs, and propose the KAN-graph, a graph representation of their computation. Building on this, we develop WS-KAN, the first weight-space architecture that learns on KANs, which naturally accounts for their symmetry. We analyze WS-KAN's expressive power, showing it can replicate an input KAN's forward pass - a standard approach for assessing expressiveness in weight-space architectures. We construct a comprehensive ``zoo'' of trained KANs spanning diverse tasks, which we use as benchmarks to empirically evaluate WS-KAN. Across all tasks, WS-KAN consistently outperforms structure-agnostic baselines, often by a substantial margin. Our code is available at https://github.com/BarSGuy/KAN-Graph-Metanetwork.

</details>


### [54] [Guide-Guard: Off-Target Predicting in CRISPR Applications](https://arxiv.org/abs/2602.16327)
*Joseph Bingham,Netanel Arussy,Saman Zonouz*

Main category: cs.LG

TL;DR: 提出Guide-Guard机器学习模型，用于预测CRISPR基因编辑中gRNA的脱靶行为，准确率达84%


<details>
  <summary>Details</summary>
Motivation: 随着CRISPR等基因编辑技术的发展，研究人员需要更好的工具来预测脱靶效应，这是基因编辑安全性的关键问题

Method: 从数据驱动的角度探索生物学和化学模型，开发名为Guide-Guard的机器学习解决方案

Result: Guide-Guard模型在预测CRISPR基因编辑过程中gRNA行为方面达到84%的准确率，能够同时训练多个不同基因并保持准确性

Conclusion: Guide-Guard为CRISPR基因编辑的脱靶行为预测提供了有效的机器学习解决方案，有助于提高基因编辑的安全性和可靠性

Abstract: With the introduction of cyber-physical genome sequencing and editing technologies, such as CRISPR, researchers can more easily access tools to investigate and create remedies for a variety of topics in genetics and health science (e.g. agriculture and medicine). As the field advances and grows, new concerns present themselves in the ability to predict the off-target behavior. In this work, we explore the underlying biological and chemical model from a data driven perspective. Additionally, we present a machine learning based solution named \textit{Guide-Guard} to predict the behavior of the system given a gRNA in the CRISPR gene-editing process with 84\% accuracy. This solution is able to be trained on multiple different genes at the same time while retaining accuracy.

</details>


### [55] [HAWX: A Hardware-Aware FrameWork for Fast and Scalable ApproXimation of DNNs](https://arxiv.org/abs/2602.16336)
*Samira Nazari,Mohammad Saeed Almasi,Mahdi Taheri,Ali Azarpeyvand,Ali Mokhtari,Ali Mahani,Christian Herglotz*

Main category: cs.LG

TL;DR: HAWX是一个硬件感知的可扩展探索框架，通过多级灵敏度评分指导异构近似计算块的集成，利用预测模型加速配置评估，在保持精度的同时实现指数级加速。


<details>
  <summary>Details</summary>
Motivation: 传统DNN硬件加速中近似计算块的集成需要大量搜索空间探索，计算成本高昂，需要一种高效的硬件感知框架来加速这一过程。

Method: 采用多级灵敏度评分（算子、滤波器、层、模型级）指导异构近似计算块的选择性集成，结合精度、功耗和面积的预测模型，支持空间和时间加速器架构。

Result: 在LeNet-5上实现层级搜索23倍加速和滤波器级搜索超过3×10^6倍加速，在VGG-11、ResNet-18、EfficientNetLite等基准测试中显示效率随网络规模指数级提升。

Conclusion: HAWX框架能够高效探索近似计算块集成，在保持精度的同时显著加速搜索过程，适用于各种DNN架构和加速器设计。

Abstract: This work presents HAWX, a hardware-aware scalable exploration framework that employs multi-level sensitivity scoring at different DNN abstraction levels (operator, filter, layer, and model) to guide selective integration of heterogeneous AxC blocks. Supported by predictive models for accuracy, power, and area, HAWX accelerates the evaluation of candidate configurations, achieving over 23* speedup in a layer-level search with two candidate approximate blocks and more than (3*106)* speedup at the filter-level search only for LeNet-5, while maintaining accuracy comparable to exhaustive search. Experiments across state-of-the-art DNN benchmarks such as VGG-11, ResNet-18, and EfficientNetLite demonstrate that the efficiency benefits of HAWX scale exponentially with network size. The HAWX hardware-aware search algorithm supports both spatial and temporal accelerator architectures, leveraging either off-the-shelf approximate components or customized designs.

</details>


### [56] [The Implicit Bias of Adam and Muon on Smooth Homogeneous Neural Networks](https://arxiv.org/abs/2602.16340)
*Eitan Gronich,Gal Vardi*

Main category: cs.LG

TL;DR: 研究动量优化器在齐次模型中的隐式偏差，证明动量梯度下降、Signum、Adam等算法近似于最速下降轨迹，具有最大化对应范数边界的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注最速下降在齐次模型中的隐式偏差，但对动量优化器在齐次模型中的隐式偏差理解不足。本文旨在将隐式偏差分析扩展到动量优化器，理解不同优化器如何最大化不同范数边界。

Method: 首先将齐次模型中最速下降的隐式偏差结果扩展到带可选学习率调度的归一化最速下降。然后证明对于光滑齐次模型，动量最速下降算法（如Muon、MomentumGD、Signum）在衰减学习率调度下近似于最速下降轨迹。进一步将分析扩展到Adam（无稳定性常数）以及混合范数优化的Muon-Signum和Muon-Adam。

Result: 证明了动量优化器在齐次模型中具有隐式偏差，趋向于对应边界最大化问题的KKT点：Muon最大化谱范数边界，MomentumGD最大化ℓ₂边界，Signum和Adam最大化ℓ_∞边界，混合算法最大化混合范数边界。实验验证了理论结果，显示优化的边界类型取决于优化器选择。

Conclusion: 动量优化器在齐次模型中的隐式偏差可以理解为近似最速下降轨迹，具有最大化特定范数边界的特性。这扩展了齐次模型中最速下降和线性模型中动量优化器的现有研究，为理解不同优化器的隐式正则化提供了理论框架。

Abstract: We study the implicit bias of momentum-based optimizers on homogeneous models. We first extend existing results on the implicit bias of steepest descent in homogeneous models to normalized steepest descent with an optional learning rate schedule. We then show that for smooth homogeneous models, momentum steepest descent algorithms like Muon (spectral norm), MomentumGD ($\ell_2$ norm), and Signum ($\ell_\infty$ norm) are approximate steepest descent trajectories under a decaying learning rate schedule, proving that these algorithms too have a bias towards KKT points of the corresponding margin maximization problem. We extend the analysis to Adam (without the stability constant), which maximizes the $\ell_\infty$ margin, and to Muon-Signum and Muon-Adam, which maximize a hybrid norm. Our experiments corroborate the theory and show that the identity of the margin maximized depends on the choice of optimizer. Overall, our results extend earlier lines of work on steepest descent in homogeneous models and momentum-based optimizers in linear models.

</details>


### [57] [Explainability for Fault Detection System in Chemical Processes](https://arxiv.org/abs/2602.16341)
*Georgios Gravanis,Dimitrios Kyriakou,Spyros Voutetakis,Simira Papadopoulou,Konstantinos Diamantaras*

Main category: cs.LG

TL;DR: 比较IG和SHAP两种XAI方法在LSTM故障诊断模型中的解释效果，应用于田纳西伊士曼化工过程，发现XAI能帮助定位故障子系统，SHAP在某些情况下更接近故障根源。


<details>
  <summary>Details</summary>
Motivation: 研究如何应用可解释人工智能方法解释LSTM分类器在化工过程故障诊断中的决策，帮助识别故障发生的子系统，提高诊断系统的透明度和可信度。

Method: 使用两种先进的XAI方法（集成梯度IG和SHAP）解释高精度LSTM分类器的故障诊断决策，应用于田纳西伊士曼过程基准非线性化工过程。

Result: 在大多数情况下，两种方法指示的最重要特征相同，但SHAP方法在某些情况下提供更多信息且更接近故障根源；XAI方法能有效识别故障发生的子系统。

Conclusion: XAI方法有助于理解LSTM故障诊断模型的决策过程，SHAP在某些情况下表现更好；由于所用XAI方法是模型无关的，该方法可推广到类似问题。

Abstract: In this work, we apply and compare two state-of-the-art eXplainability Artificial Intelligence (XAI) methods, the Integrated Gradients (IG) and the SHapley Additive exPlanations (SHAP), that explain the fault diagnosis decisions of a highly accurate Long Short-Time Memory (LSTM) classifier. The classifier is trained to detect faults in a benchmark non-linear chemical process, the Tennessee Eastman Process (TEP). It is highlighted how XAI methods can help identify the subsystem of the process where the fault occurred. Using our knowledge of the process, we note that in most cases the same features are indicated as the most important for the decision, while insome cases the SHAP method seems to be more informative and closer to the root cause of the fault. Finally, since the used XAI methods are model-agnostic, the proposed approach is not limited to the specific process and can also be used in similar problems.

</details>


### [58] [Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks](https://arxiv.org/abs/2602.16357)
*Sarkis Ter Martirosyan,Xinyue Huang,David Qin,Anthony Yu,Stanislav Emelianov*

Main category: cs.LG

TL;DR: SPOI-AE是一种用于光谱光声成像的自动编码器，无需假设线性关系即可解决光学反演和光谱解混问题，在活体小鼠淋巴结成像中优于传统算法。


<details>
  <summary>Details</summary>
Motivation: 光谱光声成像中准确估计发色团相对浓度对于揭示生理过程的结构、功能和分子信息至关重要，但由于非线性性和病态性，浓度估计变得困难。

Method: 开发了光谱光声光学反演自动编码器（SPOI-AE），在未知真实发色团浓度的情况下，使用活体小鼠淋巴结sPA图像进行训练和测试。

Result: SPOI-AE比传统算法更好地重建输入sPA像素，同时提供生物学上一致的光学参数、发色团浓度和组织氧饱和度估计，通过模拟小鼠淋巴结幻影验证了解混准确性。

Conclusion: SPOI-AE能够有效解决光谱光声成像中的非线性光学反演和光谱解混问题，为生理过程研究提供更准确的结构和功能信息。

Abstract: Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth.

</details>


### [59] [Improved Bounds for Reward-Agnostic and Reward-Free Exploration](https://arxiv.org/abs/2602.16363)
*Oran Ridel,Alon Cohen*

Main category: cs.LG

TL;DR: 本文研究了无奖励和奖励不可知探索问题，提出了新算法显著放宽了对精度参数ε的限制，并建立了无奖励探索的紧下界。


<details>
  <summary>Details</summary>
Motivation: 在有限时域马尔可夫决策过程中，研究无外部奖励观察情况下的探索问题。现有奖励不可知探索方法虽然达到极小极大样本复杂度，但仅适用于限制性小的精度参数ε，需要显著放宽这一限制。

Method: 提出新算法，采用精心设计奖励的在线学习过程构建探索策略，收集足够数据用于准确动态估计，在奖励揭示后计算ε最优策略。

Result: 新算法显著放宽了对精度参数ε的要求，建立了无奖励探索的紧下界，填补了已知上下界之间的空白。

Conclusion: 提出的新算法在技术上有创新性，成功解决了奖励不可知探索中对ε参数的限制问题，同时为无奖励探索建立了理论上的紧下界。

Abstract: We study reward-free and reward-agnostic exploration in episodic finite-horizon Markov decision processes (MDPs), where an agent explores an unknown environment without observing external rewards. Reward-free exploration aims to enable $ε$-optimal policies for any reward revealed after exploration, while reward-agnostic exploration targets $ε$-optimality for rewards drawn from a small finite class. In the reward-agnostic setting, Li, Yan, Chen, and Fan achieve minimax sample complexity, but only for restrictively small accuracy parameter $ε$. We propose a new algorithm that significantly relaxes the requirement on $ε$. Our approach is novel and of technical interest by itself. Our algorithm employs an online learning procedure with carefully designed rewards to construct an exploration policy, which is used to gather data sufficient for accurate dynamics estimation and subsequent computation of an $ε$-optimal policy once the reward is revealed. Finally, we establish a tight lower bound for reward-free exploration, closing the gap between known upper and lower bounds.

</details>


### [60] [Easy Data Unlearning Bench](https://arxiv.org/abs/2602.16400)
*Roy Rinberg,Pol Puigdemont,Martin Pawelczyk,Volkan Cevher*

Main category: cs.LG

TL;DR: 提出一个统一的机器遗忘评估基准套件，使用KLoM指标简化算法评估，提供预计算模型和基础设施，促进可复现和公平的比较。


<details>
  <summary>Details</summary>
Motivation: 当前机器遗忘方法的评估存在技术挑战，现有基准需要复杂设置和大量工程开销，阻碍了研究的可复现性和公平比较。

Method: 开发统一的基准套件，采用KLoM（边缘KL散度）指标，提供预计算的模型集成、预言机输出和流线化基础设施，实现开箱即用的评估。

Result: 创建了标准化的评估框架，简化了机器遗忘算法的评估过程，支持可复现、可扩展和公平的方法比较，代码和数据已公开。

Conclusion: 该基准套件为机器遗忘研究提供了实用的基础，旨在加速研究进展并促进最佳实践，通过标准化设置和指标解决了当前评估挑战。

Abstract: Evaluating machine unlearning methods remains technically challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and streamlined infrastructure for running evaluations out of the box. By standardizing setup and metrics, it enables reproducible, scalable, and fair comparison across unlearning methods. We aim for this benchmark to serve as a practical foundation for accelerating research and promoting best practices in machine unlearning. Our code and data are publicly available.

</details>


### [61] [Learning with Locally Private Examples by Inverse Weierstrass Private Stochastic Gradient Descent](https://arxiv.org/abs/2602.16436)
*Jean Dufraiche,Paul Mangold,Michaël Perrot,Marc Tommasi*

Main category: cs.LG

TL;DR: 提出IWP-SGD算法，利用Weierstrass变换逆变换校正LDP噪声偏差，实现无偏非线性函数估计，在二分类任务中收敛到真实总体风险最小化器。


<details>
  <summary>Details</summary>
Motivation: 非交互式本地差分隐私(LDP)一次性发布数据可实现完全数据重用，但噪声会在后续分析中引入偏差。需要解决LDP噪声在二分类任务中的偏差问题。

Method: 利用Weierstrass变换刻画LDP噪声偏差，证明其逆变换可校正偏差得到非线性函数的无偏估计。基于此构建IWP-SGD算法，通过随机梯度下降收敛到真实总体风险最小化器。

Result: IWP-SGD以O(1/n)速率收敛到真实总体风险最小化器，其中n为样本数。在合成和真实二分类数据集上验证了算法有效性。

Conclusion: 通过Weierstrass变换逆变换校正LDP噪声偏差是可行的，IWP-SGD算法能够有效处理LDP下的二分类问题，实现无偏估计和快速收敛。

Abstract: Releasing data once and for all under noninteractive Local Differential Privacy (LDP) enables complete data reusability, but the resulting noise may create bias in subsequent analyses. In this work, we leverage the Weierstrass transform to characterize this bias in binary classification. We prove that inverting this transform leads to a bias-correction method to compute unbiased estimates of nonlinear functions on examples released under LDP. We then build a novel stochastic gradient descent algorithm called Inverse Weierstrass Private SGD (IWP-SGD). It converges to the true population risk minimizer at a rate of $\mathcal{O}(1/n)$, with $n$ the number of examples. We empirically validate IWP-SGD on binary classification tasks using synthetic and real-world datasets.

</details>


### [62] [Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment](https://arxiv.org/abs/2602.16438)
*Eva Paraschou,Line Harder Clemmensen,Sneha Das*

Main category: cs.LG

TL;DR: 研究发现针对单一性别属性的LLM公平性对齐会导致其他敏感属性上的偏见溢出，特别是在模糊语境下，物理外貌、性取向和残疾状况等属性公平性显著恶化。


<details>
  <summary>Details</summary>
Motivation: 当前LLM公平性对齐主要关注单一敏感属性，忽视了公平性本质上是多维度和情境特定的价值。这种方法可能导致系统在改善目标属性公平性的同时，在其他未针对的属性上加剧偏见，即偏见溢出现象。偏见溢出在机器学习中已有研究，但在LLM对齐中尚未充分探索。

Method: 使用直接偏好优化(DPO)和BBQ基准，在三个最先进的LLM(Mistral 7B、Llama 3.1 8B、Qwen 2.5 7B)上评估针对性别对齐如何影响九个敏感属性的公平性。评估包含模糊和明确两种语境。

Result: 研究发现明显的偏见溢出：虽然总体结果有所改善，但情境感知分析显示在模糊语境下公平性显著恶化，特别是物理外貌(p<0.001)、性取向和残疾状况。改善一个属性的公平性可能在不确定性下无意中恶化其他属性的公平性。

Conclusion: 针对单一属性的公平性对齐可能导致偏见溢出，特别是在模糊语境下。这强调了需要开发情境感知、多属性公平性评估框架的必要性，以确保LLM公平性对齐的全面性和有效性。

Abstract: Conventional large language model (LLM) fairness alignment largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While extensively studied in machine learning, bias spillover remains critically underexplored in LLM alignment. In this work, we investigate how targeted gender alignment affects fairness across nine sensitive attributes in three state-of-the-art LLMs (Mistral 7B, Llama 3.1 8B, Qwen 2.5 7B). Using Direct Preference Optimization and the BBQ benchmark, we evaluate fairness under ambiguous and disambiguous contexts. Our findings reveal noticeable bias spillover: while aggregate results show improvements, context-aware analysis exposes significant degradations in ambiguous contexts, particularly for physical appearance ($p< 0.001$ across all models), sexual orientation, and disability status. We demonstrate that improving fairness along one attribute can inadvertently worsen disparities in others under uncertainty, highlighting the necessity of context-aware, multi-attribute fairness evaluation frameworks.

</details>


### [63] [Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA](https://arxiv.org/abs/2602.16442)
*Kamil Jeziorek,Piotr Wzorek,Krzysztof Blachut,Hiroshi Nakano,Manon Dampfhoffer,Thomas Mesquida,Hiroaki Nishi,Thomas Dalgaty,Tomasz Kryjak*

Main category: cs.LG

TL;DR: FPGA实现的事件图神经网络用于音频处理，通过人工耳蜗将时域信号转换为稀疏事件数据，在SHD数据集上达到92.7%准确率，资源消耗和延迟显著降低，并首次实现端到端FPGA关键词检测系统。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式边缘传感器数据量增加，特别是神经形态设备产生离散事件流，需要硬件感知的神经架构来实现高效、低延迟和节能的本地处理。

Method: 采用FPGA实现事件图神经网络，使用人工耳蜗将时域信号转换为稀疏事件数据，结合图卷积层和循环序列建模，在SoC FPGA上实现量化模型。

Result: 在SHD数据集上达到92.7%准确率（仅比SOTA低2.4%），参数减少10-67倍；量化模型达到92.3%准确率，优于FPGA SNN达19.3%；关键词检测系统达到95%词尾检测准确率，延迟仅10.53微秒，功耗1.18W。

Conclusion: 该工作展示了事件图神经网络在FPGA上的高效实现，为节能的事件驱动音频处理建立了强大基准，特别适用于边缘计算场景。

Abstract: As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.

</details>


### [64] [GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation](https://arxiv.org/abs/2602.16449)
*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

Main category: cs.LG

TL;DR: GICDM方法解决生成模型评估中嵌入空间的hubness现象，修正最近邻关系偏差，提高评估指标可靠性


<details>
  <summary>Details</summary>
Motivation: 生成模型评估通常依赖高维嵌入空间计算样本距离，但这些空间存在hubness现象，扭曲最近邻关系并偏置基于距离的评估指标

Method: 基于经典ICDM方法，提出Generative ICDM (GICDM)，修正真实数据和生成数据的邻域估计，并引入多尺度扩展改进经验行为

Result: 在合成和真实基准上的广泛实验表明，GICDM解决了hubness引起的失败，恢复了可靠的度量行为，并提高了与人类判断的一致性

Conclusion: GICDM有效解决了生成模型评估中的hubness问题，为更准确可靠的评估提供了解决方案

Abstract: Generative model evaluation commonly relies on high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we introduce Generative ICDM (GICDM), a method to correct neighborhood estimation for both real and generated data. We introduce a multi-scale extension to improve empirical behavior. Extensive experiments on synthetic and real benchmarks demonstrate that GICDM resolves hubness-induced failures, restores reliable metric behavior, and improves alignment with human judgment.

</details>


### [65] [Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC](https://arxiv.org/abs/2602.16456)
*Abdulla Jasem Almansoori,Maria Ivanova,Andrey Veprikov,Aleksandr Beznosikov,Samuel Horváth,Martin Takáč*

Main category: cs.LG

TL;DR: LoRSum：一种内存高效的LoRA优化方法，通过近端子问题和交替最小二乘更新，避免全矩阵SVD投影，保持参数效率的同时匹配或改进LoRA基线。


<details>
  <summary>Details</summary>
Motivation: 解决使用低秩投影（SVDLoRA）进行全步长训练与LoRA微调之间的差距，同时保持LoRA的参数效率和内存优势。

Method: 提出LoRSum方法，将LoRA优化转化为近端子问题，使用交替最小二乘更新（证明为隐式块幂方法），并扩展到使用K-FAC和Shampoo等结构化度量的缩放变体。

Result: 在合成任务、CIFAR-100以及GLUE、SQuAD v2、WikiText-103上的语言模型微调实验中，LoRSum能够匹配或改进LoRA基线，计算开销适中，避免全矩阵SVD投影，保持参数效率。

Conclusion: LoRSum填补了全步长低秩投影训练与LoRA微调之间的差距，提供了一种内存高效的优化方法，可恢复多种最近提出的LoRA预处理方法作为特例，并支持低秩动量更新。

Abstract: Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. In this work, we address the gap between training with full steps with low-rank projections (SVDLoRA) and LoRA fine-tuning. We propose LoRSum, a memory-efficient subroutine that closes this gap for gradient descent by casting LoRA optimization as a proximal sub-problem and solving it efficiently with alternating least squares updates, which we prove to be an implicit block power method. We recover several recently proposed preconditioning methods for LoRA as special cases, and show that LoRSum can also be used for updating a low-rank momentum. In order to address full steps with preconditioned gradient descent, we propose a scaled variant of LoRSum that uses structured metrics such as K-FAC and Shampoo, and we show that storing the diagonal of these metrics still allows them to perform well while remaining memory-efficient. Experiments on a synthetic task, CIFAR-100, and language-model fine-tuning on GLUE, SQuAD v2, and WikiText-103, show that our method can match or improve LoRA baselines given modest compute overhead, while avoiding full-matrix SVD projections and retaining LoRA-style parameter efficiency.

</details>


### [66] [HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting](https://arxiv.org/abs/2602.16468)
*Jung Min Choi,Vijaya Krishna Yalavarthi,Lars Schmidt-Thieme*

Main category: cs.LG

TL;DR: HPMixer：一种用于长期多元时间序列预测的分层补丁混合模型，通过解耦的周期性建模和结构化多尺度残差学习，在标准基准测试中取得竞争性或最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在长期多元时间序列预测中，有效捕捉周期性模式和残差动态至关重要。现有方法在标准深度学习基准设置下需要更有效的解决方案来同时处理这两种模式。

Method: 提出分层补丁混合器（HPMixer），以解耦但互补的方式建模周期性和残差。周期性组件使用可学习循环模块增强非线性通道MLP；残差组件通过可学习平稳小波变换提取稳定频域表示；通道混合编码器建模显式通道间依赖；两级非重叠分层补丁机制捕捉粗粒度和细粒度残差变化。

Result: 在标准多元基准测试上的广泛实验表明，HPMixer相比近期基线实现了竞争性或最先进的性能。

Conclusion: 通过将解耦的周期性建模与结构化多尺度残差学习相结合，HPMixer为长期多元时间序列预测提供了一个有效的框架。

Abstract: In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.

</details>


### [67] [Synthesis and Verification of Transformer Programs](https://arxiv.org/abs/2602.16473)
*Hongjian Jiang,Matthew Hague,Philipp Rümmer,Anthony Widjaja Lin*

Main category: cs.LG

TL;DR: 本文提出C-RASP编程语言的自动验证和学习算法，连接Lustre数据流程序验证，并实现基于局部搜索的C-RASP学习，应用于Transformer程序优化和约束学习。


<details>
  <summary>Details</summary>
Motivation: C-RASP是一种能表达Transformer概念的编程语言，但缺乏自动验证和学习方法。本文旨在开发C-RASP的自动验证技术，并解决从示例中学习C-RASP程序的问题。

Method: 1. 建立C-RASP与Lustre同步数据流程序的连接，利用现有模型检查器和优化SMT求解器进行验证。2. 提出基于局部搜索的算法，从示例中学习C-RASP程序。

Result: 实现了C-RASP验证和学习系统，在文献中的C-RASP基准测试中展示了有效性，特别是在Transformer程序优化和基于部分规范的约束学习两个应用场景中。

Conclusion: 本文成功开发了C-RASP的自动验证和学习方法，通过连接现有验证工具和提出新学习算法，为Transformer程序的形式化分析和合成提供了实用工具。

Abstract: C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).

</details>


### [68] [Fast and Scalable Analytical Diffusion](https://arxiv.org/abs/2602.16498)
*Xinyi Shang,Peng Sun,Jingyu Lin,Zhiqiang Shen*

Main category: cs.LG

TL;DR: GoldDiff提出了一种训练免费的分析扩散模型框架，通过动态识别"黄金子集"来避免每次推理时扫描整个数据集，实现了71倍加速并成功扩展到ImageNet-1K。


<details>
  <summary>Details</summary>
Motivation: 传统分析扩散模型虽然数学透明，但每次推理都需要扫描整个数据集，计算成本随数据集规模线性增长，这严重限制了其可扩展性。

Method: 提出GoldDiff框架，基于"后验渐进集中"现象，使用粗到细机制动态识别每个时间步的"黄金子集"，将推理复杂度与数据集大小解耦。

Result: 在AFHQ上实现71倍加速，性能匹配或优于全扫描基线，首次成功将分析扩散模型扩展到ImageNet-1K规模。

Conclusion: GoldDiff为大规模生成建模提供了一个可扩展、训练免费的范式，突破了分析扩散模型的计算瓶颈。

Abstract: Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is necessary, uncovering the phenomenon of Posterior Progressive Concentration: the effective golden support of the denoising score is not static but shrinks asymptotically from the global manifold to a local neighborhood as the signal-to-noise ratio increases. Capitalizing on this, we propose Dynamic Time-Aware Golden Subset Diffusion (GoldDiff), a training-free framework that decouples inference complexity from dataset size. Instead of static retrieval, GoldDiff uses a coarse-to-fine mechanism to dynamically pinpoint the ''Golden Subset'' for inference. Theoretically, we derive rigorous bounds guaranteeing that our sparse approximation converges to the exact score. Empirically, GoldDiff achieves a $\bf 71 \times$ speedup on AFHQ while matching or achieving even better performance than full-scan baselines. Most notably, we demonstrate the first successful scaling of analytical diffusion to ImageNet-1K, unlocking a scalable, training-free paradigm for large-scale generative modeling.

</details>


### [69] [Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects](https://arxiv.org/abs/2602.16503)
*Vasilis Gkolemis,Loukas Kavouras,Dimitrios Kyriakopoulos,Konstantinos Tsopelas,Dimitrios Rontogiannis,Giuseppe Casalicchio,Theodore Dalamagas,Christos Diou*

Main category: cs.LG

TL;DR: CALMs是一种新的模型类别，通过在输入空间的不同区域使用多个单变量形状函数来平衡GAMs的可解释性和GA²Ms的准确性，实现局部可加性同时捕捉交互作用。


<details>
  <summary>Details</summary>
Motivation: 广义可加模型(GAMs)通过独立的单变量特征效应提供可解释性，但当数据中存在交互作用时会欠拟合。GA²Ms添加了选定的成对交互作用提高了准确性，但牺牲了可解释性并限制了模型审计。需要一种既能保持可解释性又能提高准确性的模型。

Method: 提出条件可加局部模型(CALMs)，允许每个特征有多个单变量形状函数，每个函数在输入空间的不同区域激活。这些区域由特征与之交互的其他特征的简单逻辑条件（阈值）定义。采用基于蒸馏的训练流程，识别交互作用有限的同质区域，并通过区域感知的反向拟合拟合可解释的形状函数。

Result: 在多样化的分类和回归任务上的实验表明，CALMs始终优于GAMs，并且达到与GA²Ms相当的准确性。

Conclusion: CALMs在预测准确性和可解释性之间提供了令人信服的权衡，平衡了GAMs的可解释性和GA²Ms的准确性。

Abstract: Generalized additive models (GAMs) offer interpretability through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model auditing. We propose \emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs allow multiple univariate shape functions per feature, each active in different regions of the input space. These regions are defined independently for each feature as simple logical conditions (thresholds) on the features it interacts with. As a result, effects remain locally additive while varying across subregions to capture interactions. We further propose a principled distillation-based training pipeline that identifies homogeneous regions with limited interactions and fits interpretable shape functions via region-aware backfitting. Experiments on diverse classification and regression tasks show that CALMs consistently outperform GAMs and achieve accuracy comparable with GA$^2$Ms. Overall, CALMs offer a compelling trade-off between predictive accuracy and interpretability.

</details>


### [70] [Small molecule retrieval from tandem mass spectrometry: what are we optimizing for?](https://arxiv.org/abs/2602.16507)
*Gaetan De Waele,Marek Wydmuch,Krzysztof Dembczyński,Wojciech Kotłowski,Willem Waegeman*

Main category: cs.LG

TL;DR: 该研究分析了LC-MS/MS谱图识别中深度学习模型的不同损失函数，揭示了分子指纹预测准确性与分子检索效果之间存在根本性权衡，无法同时优化两者。


<details>
  <summary>Details</summary>
Motivation: 在LC-MS/MS数据分析中，使用深度学习预测分子指纹来识别化合物已成为常见策略，但不同损失函数对模型性能的影响尚不清楚。需要理解这些损失函数如何影响指纹预测准确性和分子检索效果。

Method: 研究调查了常用的损失函数，推导了新颖的遗憾界限（regret bounds）来描述这些目标的贝叶斯最优决策何时必须分叉。理论分析考虑了候选集的相似性结构。

Result: 研究发现指纹相似性和分子检索之间存在根本性权衡：优化更准确的指纹预测通常会恶化检索结果，反之亦然。这种权衡取决于候选集的相似性结构。

Conclusion: 研究为损失函数和指纹选择提供了理论指导，表明在LC-MS/MS化合物识别中需要根据具体应用需求在指纹预测准确性和分子检索效果之间做出权衡。

Abstract: One of the central challenges in the computational analysis of liquid chromatography-tandem mass spectrometry (LC-MS/MS) data is to identify the compounds underlying the output spectra. In recent years, this problem is increasingly tackled using deep learning methods. A common strategy involves predicting a molecular fingerprint vector from an input mass spectrum, which is then used to search for matches in a chemical compound database. While various loss functions are employed in training these predictive models, their impact on model performance remains poorly understood. In this study, we investigate commonly used loss functions, deriving novel regret bounds that characterize when Bayes-optimal decisions for these objectives must diverge. Our results reveal a fundamental trade-off between the two objectives of (1) fingerprint similarity and (2) molecular retrieval. Optimizing for more accurate fingerprint predictions typically worsens retrieval results, and vice versa. Our theoretical analysis shows this trade-off depends on the similarity structure of candidate sets, providing guidance for loss function and fingerprint selection.

</details>


### [71] [Capacity-constrained demand response in smart grids using deep reinforcement learning](https://arxiv.org/abs/2602.16525)
*Shafagh Abband Pashaki,Sepehr Maleki,Amir Badiee*

Main category: cs.LG

TL;DR: 提出基于容量约束的激励型需求响应方法，通过深度强化学习优化实时激励费率，有效降低住宅智能电网的峰值负荷和平滑负荷曲线。


<details>
  <summary>Details</summary>
Motivation: 住宅智能电网中需要维持电网容量限制并防止拥塞，同时考虑服务提供商和终端用户的经济利益，需要一种能够处理异质用户偏好的需求响应方法。

Method: 采用分层架构，服务提供商根据批发电价和聚合住宅负荷调整小时激励费率；使用深度强化学习在明确容量约束下学习最优实时激励费率；通过设备级家庭能源管理系统和不满意成本建模异质用户偏好。

Result: 使用三个家庭的实际用电和价格数据进行仿真，结果显示该方法有效降低峰值需求并平滑聚合负荷曲线，相比无需求响应情况，峰均比降低约22.82%。

Conclusion: 提出的容量约束激励型需求响应方法能够有效管理住宅智能电网负荷，平衡服务提供商和用户利益，显著改善电网运行效率。

Abstract: This paper presents a capacity-constrained incentive-based demand response approach for residential smart grids. It aims to maintain electricity grid capacity limits and prevent congestion by financially incentivising end users to reduce or shift their energy consumption. The proposed framework adopts a hierarchical architecture in which a service provider adjusts hourly incentive rates based on wholesale electricity prices and aggregated residential load. The financial interests of both the service provider and end users are explicitly considered. A deep reinforcement learning approach is employed to learn optimal real-time incentive rates under explicit capacity constraints. Heterogeneous user preferences are modelled through appliance-level home energy management systems and dissatisfaction costs. Using real-world residential electricity consumption and price data from three households, simulation results show that the proposed approach effectively reduces peak demand and smooths the aggregated load profile. This leads to an approximately 22.82% reduction in the peak-to-average ratio compared to the no-demand-response case.

</details>


### [72] [FEKAN: Feature-Enriched Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.16530)
*Sidharth S. Menon,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: FEKAN是一种改进的Kolmogorov-Arnold网络，通过特征增强在保持KAN所有优点的同时，显著提高了计算效率和预测精度，不增加可训练参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有KAN架构（样条、小波、径向基等变体）存在计算成本高、收敛速度慢的问题，限制了其可扩展性和实际应用性，需要一种更高效的替代方案。

Method: 提出特征增强的Kolmogorov-Arnold网络（FEKAN），通过引入额外的特征来丰富表示能力，同时不增加可训练参数数量，从而加速收敛并提高计算效率。

Result: 在函数逼近、物理信息偏微分方程求解和神经算子等多个基准测试中，FEKAN相比各种KAN变体（FastKAN、WavKAN等）都表现出显著更快的收敛速度和更高的逼近精度。

Conclusion: FEKAN在保持KAN可解释性的同时，通过特征增强有效解决了现有KAN架构的计算效率问题，具有更好的表示能力和实际应用前景。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc., suffer from high computational cost and slow convergence, limiting scalability and practical applicability. Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a simple yet effective extension that preserves all the advantages of KAN while improving computational efficiency and predictive accuracy through feature enrichment, without increasing the number of trainable parameters. By incorporating these additional features, FEKAN accelerates convergence, increases representation capacity, and substantially mitigates the computational overhead characteristic of state-of-the-art KAN architectures. We investigate FEKAN across a comprehensive set of benchmarks, including function-approximation tasks, physics-informed formulations for diverse partial differential equations (PDEs), and neural operator settings that map between input and output function spaces. For function approximation, we systematically compare FEKAN against a broad family of KAN variants, FastKAN, WavKAN, ReLUKAN, HRKAN, ChebyshevKAN, RBFKAN, and the original SplineKAN. Across all tasks, FEKAN demonstrates substantially faster convergence and consistently higher approximation accuracy than the underlying baseline architectures. We also establish the theoretical foundations for FEKAN, showing its superior representation capacity compared to KAN, which contributes to improved accuracy and efficiency.

</details>


### [73] [Transfer Learning of Linear Regression with Multiple Pretrained Models: Benefiting from More Pretrained Models via Overparameterization Debiasing](https://arxiv.org/abs/2602.16531)
*Daniel Boharon,Yehuda Dar*

Main category: cs.LG

TL;DR: 该论文研究线性回归任务的迁移学习，使用多个可能过参数化的最小二乘预训练模型，分析何时使用更多预训练模型能改善迁移学习效果。


<details>
  <summary>Details</summary>
Motivation: 研究在过参数化预训练模型背景下，如何有效进行迁移学习，特别是探索使用多个预训练模型对目标学习任务的影响。

Method: 将目标学习任务公式化为优化问题：最小化目标数据集上的平方误差，同时惩罚学习模型与预训练模型之间的距离。提出简单的去偏方法，通过乘法校正因子减少过参数化偏差。

Result: 如果预训练模型是过参数化的，使用足够多的预训练模型对有益的迁移学习很重要。但学习可能受到预训练模型过参数化偏差的影响，即最小ℓ2范数解在高维参数空间中限制在训练示例张成的小子空间内。

Conclusion: 提出的去偏方法可以减少过参数化偏差，使学习能够利用更多预训练模型来学习目标预测器。研究阐明了何时使用更多预训练模型可以改善迁移学习。

Abstract: We study transfer learning for a linear regression task using several least-squares pretrained models that can be overparameterized.
  We formulate the target learning task as optimization that minimizes squared errors on the target dataset with penalty on the distance of the learned model from the pretrained models. We analytically formulate the test error of the learned target model and provide the corresponding empirical evaluations.
  Our results elucidate when using more pretrained models can improve transfer learning. Specifically, if the pretrained models are overparameterized, using sufficiently many of them is important for beneficial transfer learning. However, the learning may be compromised by overparameterization bias of pretrained models, i.e., the minimum $\ell_2$-norm solution's restriction to a small subspace spanned by the training examples in the high-dimensional parameter space. We propose a simple debiasing via multiplicative correction factor that can reduce the overparameterization bias and leverage more pretrained models to learn a target predictor.

</details>


### [74] [Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning](https://arxiv.org/abs/2602.16543)
*Jialiang Fan,Shixiong Jiang,Mengyu Liu,Fanxin Kong*

Main category: cs.LG

TL;DR: 提出一个针对安全强化学习的对抗攻击框架，利用专家演示和黑盒环境交互学习约束模型和代理策略，无需受害者策略的内部梯度或真实安全约束即可进行梯度攻击优化。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法假设环境友好，容易受到现实世界中常见的对抗扰动攻击。现有基于梯度的对抗攻击通常需要访问策略的梯度信息，这在现实场景中往往不切实际。

Method: 使用专家演示和黑盒环境交互学习约束模型和代理（学习者）策略，从而能够在不需要受害者策略内部梯度或真实安全约束的情况下进行基于梯度的攻击优化。

Result: 在多个安全强化学习基准测试中验证了该方法的有效性，特别是在有限特权访问的情况下。

Conclusion: 提出的对抗攻击框架能够有效揭示安全强化学习策略的脆弱性，为实际部署中的安全风险评估提供了实用工具。

Abstract: Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.

</details>


### [75] [RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion](https://arxiv.org/abs/2602.16548)
*Tianmeng Hu,Yongzheng Cui,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: RIDER：基于强化学习的RNA三维结构逆设计框架，直接优化结构相似性而非序列恢复率


<details>
  <summary>Details</summary>
Motivation: 现有RNA三维结构逆设计的深度学习方法通常使用原生序列恢复率作为优化和评估指标，但这存在局限性：不同序列可以折叠成相似的三维结构，高恢复率不一定代表正确折叠。需要直接优化三维结构相似性。

Method: 提出RIDER框架：1）预训练基于GNN的条件扩散生成模型，以目标三维结构为条件；2）使用改进的策略梯度算法进行微调，基于四个三维自一致性度量的任务特定奖励函数。

Result: 1）预训练模型在原生序列恢复率上比现有方法提高9%；2）RIDER在所有三维结构相似性指标上提升超过100%；3）能够发现与原生序列不同的设计。

Conclusion: RIDER通过直接优化三维结构相似性，显著提高了RNA逆设计的结构保真度，超越了传统基于序列恢复率的方法，为合成生物学和治疗应用中的功能RNA工程提供了更有效的工具。

Abstract: The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.

</details>


### [76] [A Scalable Approach to Solving Simulation-Based Network Security Games](https://arxiv.org/abs/2602.16564)
*Michael Lanier,Yevgeniy Vorobeychik*

Main category: cs.LG

TL;DR: MetaDOAR是一个轻量级元控制器，通过分区感知过滤层和Q值缓存增强Double Oracle/PSRO范式，实现大规模网络环境下的可扩展多智能体强化学习。


<details>
  <summary>Details</summary>
Motivation: 解决在非常大的网络环境中进行多智能体强化学习时的可扩展性问题，传统方法在内存使用和训练时间上存在显著扩展问题。

Method: 1) 学习紧凑的状态投影从节点结构嵌入；2) 快速评分并选择设备子集（top-k分区）；3) 低层智能体在选定分区上执行聚焦波束搜索；4) 使用批处理评估候选动作并存储在LRU缓存中；5) 通过保守的k跳缓存失效保持决策质量。

Result: 在大型网络拓扑上获得比SOTA基线更高的玩家收益，在内存使用和训练时间上没有显著扩展问题。

Conclusion: MetaDOAR为大规模网络决策问题提供了一个实用、理论上有依据的高效分层策略学习路径。

Abstract: We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.

</details>


### [77] [Steering diffusion models with quadratic rewards: a fine-grained analysis](https://arxiv.org/abs/2602.16570)
*Ankur Moitra,Andrej Risteski,Dhruv Rohatgi*

Main category: cs.LG

TL;DR: 本文分析了从奖励倾斜扩散模型中采样的计算复杂性，重点关注二次奖励函数。研究发现线性奖励总是可高效采样，低秩正定二次奖励也可高效处理，但负定二次奖励即使秩为1也是难解的。


<details>
  <summary>Details</summary>
Motivation: 当前推理时算法在实践中采用启发式方法，存在各种失败模式，且对这些启发式何时能高效改进缺乏理解。本文旨在对奖励倾斜扩散模型的采样任务提供细粒度的计算复杂性分析。

Method: 研究从奖励倾斜扩散模型 $p^{\star}(x) \propto p(x) \exp(r(x))$ 中采样的计算复杂性，其中 $r$ 是奖励函数，$p$ 是预训练扩散模型。特别关注二次奖励 $r(x) = x^\top A x + b^\top x$，使用线性奖励作为构建块，并引入Hubbard-Stratonovich变换作为新概念工具。

Result: 1. 线性奖励倾斜总是可高效采样（文献中似乎未被注意到）。2. 对于低秩正定二次倾斜（$A$ 正定且秩为 $O(1)$），提供了高效采样算法。3. 对于负定二次倾斜（$r(x) = - x^\top A x$，$A$ 正定），证明即使 $A$ 秩为1（尽管具有指数级大条目），问题也是难解的。

Conclusion: 本文为奖励倾斜扩散模型的采样任务提供了细粒度的计算复杂性分析，揭示了不同奖励函数结构下的可解性边界，为推理时算法的理论理解提供了重要进展。

Abstract: Inference-time algorithms are an emerging paradigm in which pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of when these heuristics can be efficiently improved.
  In this paper, we consider the task of sampling from a reward-tilted diffusion model -- that is, sampling from $p^{\star}(x) \propto p(x) \exp(r(x))$ -- given a reward function $r$ and pre-trained diffusion oracle for $p$. We provide a fine-grained analysis of the computational tractability of this task for quadratic rewards $r(x) = x^\top A x + b^\top x$. We show that linear-reward tilts are always efficiently sampleable -- a simple result that seems to have gone unnoticed in the literature. We use this as a building block, along with a conceptually new ingredient -- the Hubbard-Stratonovich transform -- to provide an efficient algorithm for sampling from low-rank positive-definite quadratic tilts, i.e. $r(x) = x^\top A x$ where $A$ is positive-definite and of rank $O(1)$. For negative-definite tilts, i.e. $r(x) = - x^\top A x$ where $A$ is positive-definite, we prove that the problem is intractable even if $A$ is of rank 1 (albeit with exponentially-large entries).

</details>


### [78] [MoDE-Boost: Boosting Shared Mobility Demand with Edge-Ready Prediction Models](https://arxiv.org/abs/2602.16573)
*Antonios Tziorvas,George S. Theodoropoulos,Yannis Theodoridis*

Main category: cs.LG

TL;DR: 该论文提出了两种梯度提升模型变体（分类和回归），用于城市需求预测，能够生成5分钟到1小时的不同时间范围预测，应用于共享微出行服务优化。


<details>
  <summary>Details</summary>
Motivation: 城市需求预测在智能交通系统中对优化路线、调度和拥堵管理至关重要。通过数据融合和分析技术，交通需求预测是识别新兴时空需求模式的关键中间措施。快速城市化带来的挑战需要更可持续、高效和宜居的城市解决方案。

Method: 提出两种梯度提升模型变体：一个用于分类，一个用于回归。两种模型都能生成不同时间范围（5分钟到1小时）的需求预测。方法有效整合了时间和上下文特征，适用于共享微出行服务（电动滑板车和电动自行车）的需求预测。

Result: 使用五个大都市区的共享微出行数据（电动滑板车和电动自行车网络）进行评估。与最先进方法和基于生成式AI的模型进行比较，证明该方法能有效捕捉现代城市移动的复杂性。

Conclusion: 该方法为城市微出行管理提供了新颖见解，有助于应对快速城市化带来的挑战，从而促进更可持续、高效和宜居的城市发展。

Abstract: Urban demand forecasting plays a critical role in optimizing routing, dispatching, and congestion management within Intelligent Transportation Systems. By leveraging data fusion and analytics techniques, traffic demand forecasting serves as a key intermediate measure for identifying emerging spatial and temporal demand patterns. In this paper, we tackle this challenge by proposing two gradient boosting model variations, one for classiffication and one for regression, both capable of generating demand forecasts at various temporal horizons, from 5 minutes up to one hour. Our overall approach effectively integrates temporal and contextual features, enabling accurate predictions that are essential for improving the efficiency of shared (micro-) mobility services. To evaluate its effectiveness, we utilize open shared mobility data derived from e-scooter and e-bike networks in five metropolitan areas. These real-world datasets allow us to compare our approach with state-of-the-art methods as well as a Generative AI-based model, demonstrating its effectiveness in capturing the complexities of modern urban mobility. Ultimately, our methodology offers novel insights on urban micro-mobility management, helping to tackle the challenges arising from rapid urbanization and thus, contributing to more sustainable, efficient, and livable cities.

</details>


### [79] [AIFL: A Global Daily Streamflow Forecasting Model Using Deterministic LSTM Pre-trained on ERA5-Land and Fine-tuned on IFS](https://arxiv.org/abs/2602.16579)
*Maria Luisa Taccari,Kenza Tazi,Oisín M. Morrison,Andreas Grafberger,Juan Colonese,Corentin Carton de Wiart,Christel Prudhomme,Cinzia Mazzetti,Matthew Chantry,Florian Pappenberger*

Main category: cs.LG

TL;DR: AIFL是一个基于LSTM的确定性全球日径流预报模型，采用两阶段训练策略解决再分析到预报的领域偏移问题，在CARAVAN数据集上训练，在独立测试集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 数据驱动模型从历史再分析数据过渡到业务预报产品时存在性能差距，需要可靠的全球径流预报系统用于洪水准备和水资源管理。

Method: 基于LSTM的确定性模型，采用两阶段训练策略：先在ERA5-Land再分析数据（1980-2019）上预训练，然后在业务IFS控制预报（2016-2019）上微调，使用CARAVAN数据集的18,588个流域。

Result: 在独立测试集（2021-2024）上，AIFL取得中位数修改KGE'为0.66，中位数NSE为0.53，与当前最先进的全球系统竞争力相当，在极端事件检测方面表现出色。

Conclusion: AIFL是第一个在CARAVAN生态系统中端到端训练的全球模型，为全球水文社区提供了一个透明、可复现且业务稳健的基线系统。

Abstract: Reliable global streamflow forecasting is essential for flood preparedness and water resource management, yet data-driven models often suffer from a performance gap when transitioning from historical reanalysis to operational forecast products. This paper introduces AIFL (Artificial Intelligence for Floods), a deterministic LSTM-based model designed for global daily streamflow forecasting. Trained on 18,588 basins curated from the CARAVAN dataset, AIFL utilises a novel two-stage training strategy to bridge the reanalysis-to-forecast domain shift. The model is first pre-trained on 40 years of ERA5-Land reanalysis (1980-2019) to capture robust hydrological processes, then fine-tuned on operational Integrated Forecasting System (IFS) control forecasts (2016-2019) to adapt to the specific error structures and biases of operational numerical weather prediction. To our knowledge, this is the first global model trained end-to-end within the CARAVAN ecosystem. On an independent temporal test set (2021-2024), AIFL achieves high predictive skill with a median modified Kling-Gupta Efficiency (KGE') of 0.66 and a median Nash-Sutcliffe Efficiency (NSE) of 0.53. Benchmarking results show that AIFL is highly competitive with current state-of-the-art global systems, achieving comparable accuracy while maintaining a transparent and reproducible forcing pipeline. The model demonstrates exceptional reliability in extreme-event detection, providing a streamlined and operationally robust baseline for the global hydrological community.

</details>


### [80] [Sequential Membership Inference Attacks](https://arxiv.org/abs/2602.16596)
*Thomas Michel,Debabrota Basu,Emilie Kaufmann*

Main category: cs.LG

TL;DR: 提出SeMI*攻击方法，利用模型更新序列进行成员推理攻击，相比仅使用最终模型的现有方法能获得更强的攻击效果和更严格的隐私审计。


<details>
  <summary>Details</summary>
Motivation: 现代AI模型会经历多次更新，现有成员推理攻击主要针对静态模型且分析限于无限样本情况。需要开发能利用模型动态更新序列的"最优"攻击方法，以增强攻击能力和隐私审计效果。

Method: 开发SeMI*攻击方法，利用模型更新序列识别在特定更新步骤插入的目标数据。针对经验均值计算，推导了在有限样本下（无论是否使用隐私保护）的最优攻击能力。

Result: SeMI*避免了现有攻击方法中随着训练数据积累而消失的成员推理信号。攻击者可以调整插入时间和测试数据来获得更严格的隐私审计。实验表明SeMI*在不同数据分布和DP-SGD训练模型上都优于基线方法。

Conclusion: 利用模型更新序列的SeMI*攻击方法能显著增强成员推理攻击能力，提供比现有方法更严格的隐私审计，为动态模型的隐私分析提供了新工具。

Abstract: Modern AI models are not static. They go through multiple updates in their lifecycles. Thus, exploiting the model dynamics to create stronger Membership Inference (MI) attacks and tighter privacy audits are timely questions. Though the literature empirically shows that using a sequence of model updates can increase the power of MI attacks, rigorous analysis of the `optimal' MI attacks is limited to static models with infinite samples. Hence, we develop an `optimal' MI attack, SeMI*, that uses the sequence of model updates to identify the presence of a target inserted at a certain update step. For the empirical mean computation, we derive the optimal power of SeMI*, while accessing a finite number of samples with or without privacy. Our results retrieve the existing asymptotic analysis. We observe that having access to the model sequence avoids the dilution of MI signals unlike the existing attacks on the final model, where the MI signal vanishes as training data accumulates. Furthermore, an adversary can use SeMI* to tune both the insertion time and the canary to yield tighter privacy audits. Finally, we conduct experiments across data distributions and models trained or fine-tuned with DP-SGD demonstrating that practical variants of SeMI* lead to tighter privacy audits than the baselines.

</details>


### [81] [Predicting The Cop Number Using Machine Learning](https://arxiv.org/abs/2602.16600)
*Meagan Mann,Christian Muise,Erin Meger*

Main category: cs.LG

TL;DR: 机器学习方法（特别是树模型和图神经网络）能够准确预测图的警察数，无需显式特征工程，且可识别影响预测的关键图结构特征。


<details>
  <summary>Details</summary>
Motivation: 警察与强盗游戏中的警察数计算在计算上很困难，传统算法通常限于小图族。研究旨在探索机器学习和图神经网络是否能从图的结构特性准确预测警察数，并识别哪些特性对预测影响最大。

Method: 使用经典机器学习方法（特别是树模型）和图神经网络，基于图的结构特性预测警察数，并进行可解释性分析以识别最具预测性的特征。

Result: 树模型在类别不平衡情况下仍能实现高精度预测，图神经网络无需显式特征工程也能达到可比结果。可解释性分析显示最具预测性的特征与节点连通性、聚类、团结构和宽度参数相关。

Conclusion: 机器学习方法可以作为现有警察数算法的补充，在计算不可行时提供可扩展的近似解，且识别的关键特征与已知理论结果一致。

Abstract: Cops and Robbers is a pursuit evasion game played on a graph, first introduced independently by Quilliot \cite{quilliot1978jeux} and Nowakowski and Winkler \cite{NOWAKOWSKI1983235} over four decades ago. A main interest in recent the literature is identifying the cop number of graph families. The cop number of a graph, $c(G)$, is defined as the minimum number of cops required to guarantee capture of the robber. Determining the cop number is computationally difficult and exact algorithms for this are typically restricted to small graph families. This paper investigates whether classical machine learning methods and graph neural networks can accurately predict a graph's cop number from its structural properties and identify which properties most strongly influence this prediction. Of the classical machine learning models, tree-based models achieve high accuracy in prediction despite class imbalance, whereas graph neural networks achieve comparable results without explicit feature engineering. The interpretability analysis shows that the most predictive features are related to node connectivity, clustering, clique structure, and width parameters, which aligns with known theoretical results. Our findings suggest that machine learning approaches can be used in complement with existing cop number algorithms by offering scalable approximations where computation is infeasible.

</details>


### [82] [A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models](https://arxiv.org/abs/2602.16626)
*SungJun Cho,Chetan Gohil,Rukuang Huang,Oiwi Parker Jones,Mark W. Woolrich*

Main category: cs.LG

TL;DR: 本文系统评估了神经影像数据（MEG）的tokenization策略，比较了可学习和不可学习方法，发现简单固定tokenization策略在神经基础模型开发中足够有效。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理成功推动神经影像大规模基础模型发展，连续神经时间序列数据的离散化（tokenization）策略影响尚不明确，需要系统评估不同tokenization方法对神经基础模型性能的影响。

Method: 提出基于自编码器的新型可学习tokenizer，并与不可学习方法对比，通过信号重建保真度、基础建模性能（token预测、生成数据生物学合理性、主体特异性信息保留、下游任务表现）等指标，在三个公开MEG数据集上进行系统评估。

Result: 可学习和不可学习离散化方案均实现高重建精度，在大多数评估标准上表现相当，表明简单固定样本级tokenization策略可用于神经基础模型开发。

Conclusion: 神经影像基础模型开发中，简单固定的样本级tokenization策略已足够有效，无需复杂可学习方法，为神经基础模型构建提供了实用指导。

Abstract: Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.

</details>


### [83] [Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes](https://arxiv.org/abs/2602.16629)
*Ethan Blaser,Jiuqi Wang,Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文证明了在标准递减学习率下，无需局部时钟的n步差分TD算法的几乎必然收敛，为平均奖励强化学习提供了更实用的理论保证。


<details>
  <summary>Details</summary>
Motivation: 差分TD学习算法是平均奖励强化学习的重要进展，但现有收敛保证需要基于状态访问计数的局部时钟学习率，这与实际应用不符且无法扩展到非表格设置。

Method: 证明了在标准递减学习率下，无需局部时钟的on-policy n步差分TD算法的几乎必然收敛，并推导了off-policy n步差分TD收敛的三个充分条件。

Result: 成功证明了on-policy n步差分TD算法在标准递减学习率下的收敛性，并建立了off-policy收敛的理论框架，消除了对局部时钟的依赖。

Conclusion: 这些结果加强了差分TD学习的理论基础，使其收敛分析更接近实际实现，为平均奖励RL提供了更实用的理论支持。

Abstract: The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.

</details>


### [84] [Optimizer choice matters for the emergence of Neural Collapse](https://arxiv.org/abs/2602.16642)
*Jim Zhao,Tin Sum Cheng,Wojciech Masarczyk,Aurelien Lucchi*

Main category: cs.LG

TL;DR: 本文挑战了神经坍缩（NC）在所有优化器中普遍存在的假设，证明优化器选择对NC出现起关键作用，并首次理论解释了优化器依赖的NC现象。


<details>
  <summary>Details</summary>
Motivation: 现有NC理论分析大多忽略优化器的作用，认为NC在所有优化方法中普遍存在。本文挑战这一假设，旨在揭示优化器选择对NC现象出现的关键影响。

Method: 引入新诊断指标NC0（其收敛到零是NC的必要条件），理论分析不同优化器的NC0动态，并进行3900次训练实验验证理论结果。

Result: 证明：1）解耦权重衰减的AdamW无法产生NC；2）SGD、带耦合权重衰减的SignGD（Adam特例）和解耦权重衰减的SignGD（AdamW特例）具有不同的NC0动态；3）动量在SGD中加速NC出现。

Conclusion: 优化器选择对NC出现起关键作用，权重衰减耦合方式塑造优化器的隐式偏置，首次为优化器依赖的NC现象提供理论解释。

Abstract: Neural Collapse (NC) refers to the emergence of highly symmetric geometric structures in the representations of deep neural networks during the terminal phase of training. Despite its prevalence, the theoretical understanding of NC remains limited. Existing analyses largely ignore the role of the optimizer, thereby suggesting that NC is universal across optimization methods. In this work, we challenge this assumption and demonstrate that the choice of optimizer plays a critical role in the emergence of NC. The phenomenon is typically quantified through NC metrics, which, however, are difficult to track and analyze theoretically. To overcome this limitation, we introduce a novel diagnostic metric, NC0, whose convergence to zero is a necessary condition for NC. Using NC0, we provide theoretical evidence that NC cannot emerge under decoupled weight decay in adaptive optimizers, as implemented in AdamW. Concretely, we prove that SGD, SignGD with coupled weight decay (a special case of Adam), and SignGD with decoupled weight decay (a special case of AdamW) exhibit qualitatively different NC0 dynamics. Also, we show the accelerating effect of momentum on NC (beyond convergence of train loss) when trained with SGD, being the first result concerning momentum in the context of NC. Finally, we conduct extensive empirical experiments consisting of 3,900 training runs across various datasets, architectures, optimizers, and hyperparameters, confirming our theoretical results. This work provides the first theoretical explanation for optimizer-dependent emergence of NC and highlights the overlooked role of weight-decay coupling in shaping the implicit biases of optimizers.

</details>


### [85] [Factorization Machine with Quadratic-Optimization Annealing for RNA Inverse Folding and Evaluation of Binary-Integer Encoding and Nucleotide Assignment](https://arxiv.org/abs/2602.16643)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 提出基于因子分解机和二次优化退火（FMQA）的RNA逆折叠方法，系统研究了核苷酸到整数分配和二进制编码对优化性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有RNA逆折叠方法需要大量序列评估，实验验证成本高。FMQA作为离散黑盒优化方法能以有限评估获得高质量解，但核苷酸到二进制变量的转换策略（整数分配和编码方法）对性能的影响尚未深入研究。

Method: 建立FMQA框架用于RNA逆折叠，系统评估24种核苷酸到整数(0-3)的分配方式与四种二进制编码方法（one-hot、domain-wall、binary、unary）的组合效果。

Result: one-hot和domain-wall编码在归一化集成缺陷值上优于binary和unary编码。domain-wall编码中，分配到边界整数(0和3)的核苷酸出现频率更高。将鸟嘌呤(G)和胞嘧啶(C)分配到边界整数能促进茎区富集，获得比one-hot编码更热力学稳定的二级结构。

Conclusion: 成功建立了FMQA框架用于RNA逆折叠，并揭示了核苷酸分配和编码方法对优化性能的重要影响。domain-wall编码结合特定核苷酸分配策略能生成更稳定的RNA结构，为高效RNA设计提供了新方法。

Abstract: The RNA inverse folding problem aims to identify nucleotide sequences that preferentially adopt a given target secondary structure. While various heuristic and machine learning-based approaches have been proposed, many require a large number of sequence evaluations, which limits their applicability when experimental validation is costly. We propose a method to solve the problem using a factorization machine with quadratic-optimization annealing (FMQA). FMQA is a discrete black-box optimization method reported to obtain high-quality solutions with a limited number of evaluations. Applying FMQA to the problem requires converting nucleotides into binary variables. However, the influence of integer-to-nucleotide assignments and binary-integer encoding on the performance of FMQA has not been thoroughly investigated, even though such choices determine the structure of the surrogate model and the search landscape, and thus can directly affect solution quality. Therefore, this study aims both to establish a novel FMQA framework for RNA inverse folding and to analyze the effects of these assignments and encoding methods. We evaluated all 24 possible assignments of the four nucleotides to the ordered integers (0-3), in combination with four binary-integer encoding methods. Our results demonstrated that one-hot and domain-wall encodings outperform binary and unary encodings in terms of the normalized ensemble defect value. In domain-wall encoding, nucleotides assigned to the boundary integers (0 and 3) appeared with higher frequency. In the RNA inverse folding problem, assigning guanine and cytosine to these boundary integers promoted their enrichment in stem regions, which led to more thermodynamically stable secondary structures than those obtained with one-hot encoding.

</details>


### [86] [Neighborhood Stability as a Measure of Nearest Neighbor Searchability](https://arxiv.org/abs/2602.16673)
*Thomas Vecchiato,Sebastian Bruch*

Main category: cs.LG

TL;DR: 提出了两种衡量高维数据聚类搜索能力的指标：聚类邻域稳定性度量（clustering-NSM）和点邻域稳定性度量（point-NSM），用于预测聚类近似最近邻搜索的准确性和数据集的可搜索性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏分析工具来确定聚类近似最近邻搜索（ANNS）对特定数据集的适用性（即"可搜索性"）。现有方法无法预测聚类ANNS在给定数据集上的表现，这限制了该技术的有效应用。

Method: 提出了两种基于邻域关系的度量：1) clustering-NSM：衡量聚类质量的内部指标，预测ANNS准确性；2) point-NSM：衡量数据集可聚类性的指标，预测clustering-NSM。两种度量都基于点之间的最近邻关系而非距离，适用于包括内积在内的各种距离函数。

Result: 这两种度量能够仅通过数据点本身确定数据集是否适合聚类ANNS搜索。clustering-NSM能够预测ANNS准确性，point-NSM能够预测clustering-NSM，共同构成了完整的可搜索性评估框架。

Conclusion: 该研究填补了聚类ANNS可搜索性分析工具的空白，提出的两种度量指标为高维数据集的聚类搜索适用性评估提供了理论基础和实用工具，且不依赖于具体距离度量，具有广泛适用性。

Abstract: Clustering-based Approximate Nearest Neighbor Search (ANNS) organizes a set of points into partitions, and searches only a few of them to find the nearest neighbors of a query. Despite its popularity, there are virtually no analytical tools to determine the suitability of clustering-based ANNS for a given dataset -- what we call "searchability." To address that gap, we present two measures for flat clusterings of high-dimensional points in Euclidean space. First is Clustering-Neighborhood Stability Measure (clustering-NSM), an internal measure of clustering quality -- a function of a clustering of a dataset -- that we show to be predictive of ANNS accuracy. The second, Point-Neighborhood Stability Measure (point-NSM), is a measure of clusterability -- a function of the dataset itself -- that is predictive of clustering-NSM. The two together allow us to determine whether a dataset is searchable by clustering-based ANNS given only the data points. Importantly, both are functions of nearest neighbor relationships between points, not distances, making them applicable to various distance functions including inner product.

</details>


### [87] [Retrieval-Augmented Foundation Models for Matched Molecular Pair Transformations to Recapitulate Medicinal Chemistry Intuition](https://arxiv.org/abs/2602.16684)
*Bo Pan,Peter Zhiping Zhang,Hao-Wei Pang,Alex Zhu,Xiang Yu,Liying Zhang,Liang Zhao*

Main category: cs.LG

TL;DR: 提出基于大规模MMP变换的生成模型，通过提示机制和检索增强框架实现可控的类似物生成


<details>
  <summary>Details</summary>
Motivation: 现有方法要么在分子层面操作编辑可控性有限，要么从小规模数据学习MMP式编辑，需要更灵活可控的类似物生成方法

Method: 采用变量到变量的生成框架，在大规模MMP变换上训练基础模型，开发提示机制控制变换模式，并引入MMPT-RAG检索增强框架利用外部参考类似物

Result: 在通用化学语料库和专利数据集上展示出更好的多样性、新颖性和可控性，能在实际发现场景中恢复真实的类似物结构

Conclusion: 该方法为药物化学家提供了灵活可控的类似物生成工具，通过MMP变换和检索增强实现了实用的分子设计

Abstract: Matched molecular pairs (MMPs) capture the local chemical edits that medicinal chemists routinely use to design analogs, but existing ML approaches either operate at the whole-molecule level with limited edit controllability or learn MMP-style edits from restricted settings and small models. We propose a variable-to-variable formulation of analog generation and train a foundation model on large-scale MMP transformations (MMPTs) to generate diverse variables conditioned on an input variable. To enable practical control, we develop prompting mechanisms that let the users specify preferred transformation patterns during generation. We further introduce MMPT-RAG, a retrieval-augmented framework that uses external reference analogs as contextual guidance to steer generation and generalize from project-specific series. Experiments on general chemical corpora and patent-specific datasets demonstrate improved diversity, novelty, and controllability, and show that our method recovers realistic analog structures in practical discovery scenarios.

</details>


### [88] [Protecting the Undeleted in Machine Unlearning](https://arxiv.org/abs/2602.16697)
*Aloni Cohen,Refael Kohen,Kobbi Nissim,Uri Stemmer*

Main category: cs.LG

TL;DR: 论文揭示机器遗忘追求完美重训练存在隐私风险，攻击者可利用删除请求重建几乎整个数据集，提出新安全定义保护未删除数据


<details>
  <summary>Details</summary>
Motivation: 机器遗忘旨在从训练模型中删除特定数据点，通常追求"完美重训练"（即模拟从未包含删除数据的情况）。然而，这种方法和支持它的安全定义对剩余（未删除）数据点存在重大隐私风险。

Method: 1. 展示重建攻击：证明对于某些任务，遵循完美重训练的机制允许攻击者仅控制少量数据点，通过发出删除请求就能重建几乎整个数据集。2. 调查现有机器遗忘定义，显示它们要么易受此类攻击，要么过于严格无法支持基本功能。3. 提出新的安全定义，专门保护未删除数据免受其他点删除导致的泄漏。

Result: 发现完美重训练方法存在严重隐私漏洞，攻击者可通过少量数据点和删除请求重建大部分数据集。现有安全定义要么不安全要么不实用。提出的新安全定义能够保护未删除数据，同时支持公告板、求和、统计学习等基本功能。

Conclusion: 机器遗忘的完美重训练方法存在根本性隐私风险，需要重新思考安全定义。提出的新安全定义在保护未删除数据隐私的同时，仍能支持实际应用所需的基本功能，为机器遗忘提供了更安全实用的框架。

Abstract: Machine unlearning aims to remove specific data points from a trained model, often striving to emulate "perfect retraining", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $ω(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.

</details>


### [89] [Causality is Key for Interpretability Claims to Generalise](https://arxiv.org/abs/2602.16698)
*Shruti Joshi,Aaron Mueller,David Klindt,Wieland Brendel,Patrik Reizinger,Dhanya Sridhar*

Main category: cs.LG

TL;DR: 论文提出使用因果推理框架指导大语言模型可解释性研究，强调区分观察、干预和反事实三个层次，避免过度推断证据，并引入因果表示学习来操作化这一框架。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型可解释性研究存在两个主要问题：1) 研究发现缺乏泛化性；2) 因果解释超出证据支持范围。需要建立更严谨的框架来确保可解释性研究的有效性和可靠性。

Method: 采用Pearl的因果层次结构，区分观察（关联）、干预（如消融或激活修补）和反事实三个推理层次。引入因果表示学习来具体化哪些变量可以从激活中恢复以及在什么假设下可恢复。提出诊断框架帮助研究者选择与证据匹配的方法和评估。

Result: 建立了基于因果推理的可解释性研究框架，明确了不同层次推理所需的证据类型：观察建立关联，干预支持行为指标变化，反事实需要受控监督。因果表示学习提供了操作化这一框架的具体方法。

Conclusion: 因果推理为LLM可解释性研究提供了严谨的理论基础，帮助研究者避免过度推断，确保研究发现具有泛化性。诊断框架能够指导方法选择和评估设计，使研究主张与证据水平相匹配。

Abstract: Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies what an interpretability study can justify. Observations establish associations between model behaviour and internal components. Interventions (e.g., ablations or activation patching) support claims how these edits affect a behavioural metric (\eg, average change in token probabilities) over a set of prompts. However, counterfactual claims -- i.e., asking what the model output would have been for the same prompt under an unobserved intervention -- remain largely unverifiable without controlled supervision. We show how causal representation learning (CRL) operationalises this hierarchy, specifying which variables are recoverable from activations and under what assumptions. Together, these motivate a diagnostic framework that helps practitioners select methods and evaluations matching claims to evidence such that findings generalise.

</details>


### [90] [Knowledge-Embedded Latent Projection for Robust Representation Learning](https://arxiv.org/abs/2602.16709)
*Weijing Tang,Ming Yuan,Zongqi Xia,Tianxi Cai*

Main category: cs.LG

TL;DR: 提出知识嵌入的潜在投影模型，利用外部语义嵌入（如临床概念预训练嵌入）来正则化表示学习，解决电子健康记录中维度不平衡问题的估计挑战。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录等离散数据矩阵存在维度不平衡问题：队列规模受疾病流行率限制较小，而特征空间因医疗编码系统庞大而极大。传统潜在空间模型在这种不平衡情况下估计困难，而外部语义嵌入（如临床概念预训练嵌入）的可用性为解决此问题提供了机会。

Method: 提出知识嵌入潜在投影模型：将列嵌入建模为语义嵌入在再生核希尔伯特空间中的平滑函数映射。开发计算高效的两步估计流程：1) 通过核主成分分析进行语义引导的子空间构建；2) 可扩展的投影梯度下降优化。

Result: 建立了估计误差界限，刻画了统计误差与核投影引起的近似误差之间的权衡。为非凸优化过程提供了局部收敛保证。广泛的模拟研究和真实电子健康记录应用证明了该方法的有效性。

Conclusion: 该方法通过利用外部语义嵌入来正则化表示学习，有效解决了高维离散数据矩阵在维度不平衡情况下的估计挑战，特别适用于电子健康记录等应用场景。

Abstract: Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [91] [On the possibility of differential algebraic elimination of the spinor field from the Maxwell-Dirac electrodynamics](https://arxiv.org/abs/2602.15907)
*Andrey Akhmeteli*

Main category: quant-ph

TL;DR: 该研究通过微分代数方法探讨能否从Maxwell-Dirac方程中消除旋量场，结果表明电磁场及其导数通常能唯一确定旋量分量，暗示旋量场可被微分代数消除。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索是否可以通过微分代数方法从Maxwell-Dirac方程中消除旋量场，简化理论描述。

Method: 方法包括：构造截断幂级数解，线性化Maxwell-Dirac电动力学的延拓系统，计算相关系数矩阵的秩。

Result: 结果表明，在一般情况下，旋量分量可由电磁场及其导数唯一确定，这强烈暗示旋量场可通过微分代数方法消除。

Conclusion: 结论是微分代数消除旋量场是可能的，这为简化Maxwell-Dirac理论提供了数学基础。

Abstract: We investigate whether the spinor field can be eliminated from the Maxwell-Dirac equations by differential algebraic methods. A generic truncated power series solution is constructed, the prolonged system of the Maxwell-Dirac electrodynamics is linearized about the solution, and the ranks of the associated coefficient matrices are computed. The results indicate that, generically, the spinor components are uniquely determined by the electromagnetic field and its derivatives. This strongly suggests that differential-algebraic elimination of the spinor field is possible.

</details>


### [92] [Experimental Characterization and Model Validation of Interference in Classical-QKD Coexistence Transmission](https://arxiv.org/abs/2602.15910)
*Lucas Alves Zischler,Amirhossein Ghazisaeidi,Carina Castiñeiras Carrero,Tristan Vosshenrich,Jeremie Renaudier,Antonio Mecozzi,Cristian Antonelli*

Main category: quant-ph

TL;DR: 实验表征了QKD传输中由SpRS和FWM引起的共存干扰，验证了用于准确噪声估计的半解析模型


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)系统在实际部署中需要与经典光通信系统共存，但共存会引入非线性干扰（如自发拉曼散射和四波混频），影响QKD性能，需要准确建模和表征这些干扰

Method: 提出并验证了一个综合的半解析模型，用于估计QKD传输中的共存干扰噪声；通过实验表征了自发拉曼散射(SpRS)和四波混频(FWM)引起的干扰

Result: 实验结果与理论预测表现出良好的一致性，验证了半解析模型在准确估计共存干扰噪声方面的有效性

Conclusion: 该研究为QKD与经典光通信系统共存时的干扰建模提供了有效工具，有助于优化QKD系统设计和部署

Abstract: We present an experimental characterization of coexistence-induced interference in QKD transmission arising from SpRS and FWM, validating a comprehensive semi-analytical model for accurate noise estimation. Experimental results show good agreement with theoretical predictions.

</details>


### [93] [Entanglement-assisted Hamiltonian dynamics learning](https://arxiv.org/abs/2602.15931)
*Ayaka Usui,Guillermo Abad-López,Hari krishnan SV,Anna Sanpera,Some Sankar Bhattacharya*

Main category: quant-ph

TL;DR: 提出一种纠缠辅助学习策略，通过随机初始化的辅助量子比特增强量子生成对抗网络的训练性能


<details>
  <summary>Details</summary>
Motivation: 量子生成对抗网络在近似复杂多体哈密顿量动力学时，随着系统规模增大，训练过程容易出现平台期和局部最小值问题，限制了学习性能

Method: 提出纠缠辅助学习策略：在训练过程中间阶段，将单个随机初始化的辅助量子比特耦合到学习系统，利用随机化和纠缠的相互作用来增强学习性能

Result: 该方法显著提升了协议的学习性能，克服了传统QGAN训练中的平台期和局部最小值问题

Conclusion: 纠缠辅助学习策略为量子哈密顿量学习和量子模拟提供了有效的训练增强方法，特别是在大规模系统中表现出优越性能

Abstract: Approximating the dynamics given by a complex many-body Hamiltonian with a simpler effective model lies at the interface of quantum Hamiltonian learning and quantum simulation. In this context, quantum generative adversarial networks (QGANs) have been shown to outperform standard Trotter-based approximations. However, their performance is often hindered by training plateaus and local minima that become increasingly severe with system size. To overcome these limitations, we propose an entanglement-assisted learning strategy that couples a single randomly initialized auxiliary qubit to the learning system at an intermediate stage of the training process. The interplay between randomization and entanglement significantly enhances the learning performance of the protocol.

</details>


### [94] [Dynamic Synaptic Modulation of LMG Qubits populations in a Bio-Inspired Quantum Brain](https://arxiv.org/abs/2602.16003)
*J. J. Torres,E. Romera*

Main category: quant-ph

TL;DR: 提出一种受生物学启发的量子神经网络，将神经元群体编码为全连接量子比特，使用LMG量子哈密顿量控制，并通过突触效能反馈实现稳态控制。


<details>
  <summary>Details</summary>
Motivation: 将量子计算与生物神经系统原理结合，探索量子大脑架构的可能性。通过量子多体系统模拟神经元群体的集体行为，实现生物启发的计算原语。

Method: 使用Lipkin-Meshkov-Glick量子哈密顿量描述全连接量子比特系统，引入突触效能反馈机制实现活动依赖的稳态控制，将量子多体模式与吸引子结构关联。

Result: 实现了可扩展的计算原语：稳定设定点、可控振荡和尺寸依赖的鲁棒性，为未来量子硬件上的生物启发量子大脑提供了有前景的架构蓝图。

Conclusion: LMG量子哈密顿量为基础的架构有望成为未来量子硬件上生物启发量子大脑的有力候选方案，将量子多体物理与神经计算原理有机结合。

Abstract: We present a biologically inspired quantum neural network that encodes neuronal populations as fully connected qubits governed by the Lipkin-Meshkov-Glick (LMG) quantum Hamiltonian and stabilized by a synaptic-efficacy feedback implementing activity-dependent homeostatic control. The framework links collective quantum many-body modes and attractor structure to population homeostasis and rhythmogenesis, outlining scalable computational primitives -- stable set points, controllable oscillations, and size-dependent robustness -- that position LMG-based architectures as promising blueprints for bio-inspired quantum brains on future quantum hardware.

</details>


### [95] [KPZ-like transport in long-range interacting spin chains proximate to integrability](https://arxiv.org/abs/2602.15933)
*Sajant Anand,Jack Kemp,Julia Wei,Christopher David White,Michael P. Zaletel,Norman Y. Yao*

Main category: quant-ph

TL;DR: 研究长程海森堡模型中的自旋输运，发现即使在非可积模型中，也存在长寿命的KPZ类超扩散输运，这与可积伊诺泽姆采夫模型有关，并可在实验系统中观测到。


<details>
  <summary>Details</summary>
Motivation: 各向同性可积自旋链（如海森堡模型）表现出超扩散自旋输运，属于与KPZ相关的动力学普适类。研究目的是确定这些结果是否适用于更一般的非可积一维模型，特别是量子模拟器中可实现的模型。

Method: 使用最先进的张量网络方法研究非可积长程海森堡模型中的自旋和能量输运。分析幂律模型（指数2<α<∞）的输运行为，并与可积的伊诺泽姆采夫模型进行比较。

Result: 在幂律模型中观察到长寿命的z=3/2超扩散自旋输运，两点关联函数与KPZ标度函数一致，时间尺度可达t~10^3/J。伊诺泽姆采夫模型在所有相互作用范围内都表现出KPZ类自旋输运。

Conclusion: KPZ类输运源于幂律相互作用模型与可积伊诺泽姆采夫模型族的邻近性。在里德堡原子阵列和超冷极性分子等实验系统中，可以观测到广泛的非扩散输运现象。

Abstract: Isotropic integrable spin chains such as the Heisenberg model feature superdiffusive spin transport belonging to an as-yet-unidentified dynamical universality class closely related to that of Kardar, Parisi, and Zhang (KPZ). To determine whether these results extend to more generic one-dimensional models, particularly those realizable in quantum simulators, we investigate spin and energy transport in non-integrable, long-range Heisenberg models using state-of-the-art tensor network methods. Despite the lack of integrability and the asymptotic expectation of diffusion, for power-law models (with exponent $2 < α< \infty$) we observe long-lived $z=3/2$ superdiffusive spin transport and two-point correlators consistent with KPZ scaling functions, up to times $t \sim 10^3/J$. We conjecture that this KPZ-like transport is due to the proximity of such power-law-interacting models to the integrable family of Inozemtsev models, which we show to also exhibit KPZ-like spin transport across all interaction ranges. Finally, we consider anisotropic spin models naturally realized in Rydberg atom arrays and ultracold polar molecules, demonstrating that a wide range of long-lived, non-diffusive transport can be observed in experimental settings.

</details>


### [96] [Limits of Clifford Disentangling in Tensor Network States](https://arxiv.org/abs/2602.15942)
*Sergi Masot-Llima,Piotr Sierant,Paolo Stornati,Artur Garcia-Saez*

Main category: quant-ph

TL;DR: Clifford张量网络结合了Clifford电路和张量网络的优点，通过Clifford变换降低张量网络描述的复杂度，但存在对非Clifford资源积累时的根本限制


<details>
  <summary>Details</summary>
Motivation: 研究如何结合Clifford电路和张量网络的优势，利用Clifford变换降低量子态张量网络描述的经典计算复杂度，提高模拟效率

Method: 研究Clifford变换在张量网络中的解纠缠能力，特别关注纠缠冷却策略，分析精确和启发式Clifford解纠缠器的有效性，并证明在非Clifford设置下的根本限制

Result: 确定了Clifford解纠缠器有效的机制，解释了精确和启发式方法之间的联系，表征了非Clifford资源积累时的失效情况，并证明在非Clifford旋转下，没有Clifford操作能普遍解纠缠单个量子比特

Conclusion: Clifford张量网络方法在特定机制下能有效降低模拟复杂度，但对非Clifford资源存在根本限制，这阐明了Clifford基模拟方法的能力和基本局限性

Abstract: Tensor network methods leverage the limited entanglement of quantum states to efficiently simulate many-body systems. Alternatively, Clifford circuits provide a framework for handling highly entangled stabilizer states, which have low magic and are thus also classically tractable. Clifford tensor networks combine the benefits of both approaches, exploiting Clifford circuits to reduce the classical complexity of the tensor network description of states, with promising effects on simulation approaches. We study the disentangling power of Clifford transformations acting on tensor networks, with a particular emphasis on entanglement cooling strategies. We identify regimes where exact or heuristic Clifford disentanglers are effective, explain the link between the two approaches, and characterize their breakdown as non-Clifford resources accumulate. Additionally, we prove that, beyond stabilizer settings, no Clifford operation can universally disentangle even a single qubit from an arbitrary non-Clifford rotation. Our results clarify both the capabilities and fundamental limitations of Clifford-based simulation methods.

</details>


### [97] [Enhanced Superconducting Nanowire Single Photon Detector Performances using Silicon Capping](https://arxiv.org/abs/2602.15948)
*C. Klein,S. Cohen,T. Descamps,A. Iovan,P. Zolotov,P. Vennéguès,I. Florea,F. Semond,V. Zwiller*

Main category: quant-ph

TL;DR: 硅覆盖层能抑制NbTiN超导薄膜氧化，提高超导转变温度，使3nm薄膜在3K下保持超导性，并显著扩展SNSPD的饱和平台至近红外（2050nm），同时保持亚50ps时间抖动。


<details>
  <summary>Details</summary>
Motivation: NbTiN基超导纳米线单光子探测器在宽光谱范围内性能优异，但薄膜厚度小于5nm时面临表面氧化和不均匀性问题，导致性能下降和制造困难。

Method: 研究硅覆盖层对NbTiN薄膜特性和SNSPD性能的影响，通过硅覆盖层抑制氧化，提高超导转变温度，实现更薄薄膜（3nm）的超导性。

Result: 硅覆盖层有效抑制氧化，提高超导转变温度，使3nm薄膜在3K下保持超导性；增加纳米线临界电流；将饱和平台从可见光扩展至近红外（2050nm）；保持亚50ps时间抖动，即使纳米线宽度达250nm、探测面积20x20μm²。

Conclusion: 硅覆盖层保护的更薄薄膜允许制造更宽的纳米线，减少纳米制造挑战，扩展高效单光子探测的工作温度范围。

Abstract: Niobium Titanium nitride (NbTiN) based superconducting nanowire single photon detectors (SNSPDs) are known for their high performance across a wide spectral range, from the X-ray to the mid-infrared. Nonetheless, fabrication challenges and performance degradation attributable to surface oxidation and lack of uniformity in films thinner than 5 nm remain a significant barrier for achieving high-quality detectors. In this work, we study the influence of a Silicon capping layer on film properties and on the performance of SNSPDs. A Silicon capping layer effectively suppresses oxidation and increases the superconducting transition temperature. This enables superconductivity in films as thin as 3 nm at 3 K, increases critical current in patterned nanowires and significantly extends the saturation plateau from the visible to the near infrared (up to 2050 nm): These detectors maintain sub-50 ps timing jitter, even for nanowires as wide as 250 nm and with detection areas of 20x20μm2. Our results establish that thinner films protected by a capping layer allow for the fabrication of wider wires, decreasing nanofabrication challenges and extending the operating temperature range for efficient single photon detection.

</details>


### [98] [Hardware-Agnostic Modeling of Quantum Side-Channel Leakage via Conditional Dynamics and Learning from Full Correlation Data](https://arxiv.org/abs/2602.15966)
*Brennan Bell,Andreas Trügler,Konstantin Beyer,Paul Erker*

Main category: quant-ph

TL;DR: 研究序列相干侧信道模型，其中对抗探针量子比特在隐藏门序列期间与目标量子比特交互。通过机器学习解码器从经验相关记录中恢复隐藏门序列，发现存在"Goldilocks"耦合带可实现最佳恢复。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算中的侧信道攻击问题，特别是当攻击者使用探针量子比特与目标系统交互时，如何从有限的观测数据中恢复隐藏的量子门序列。传统方法在电路深度增加时面临观测空间指数增长和解析可区分性难以处理的问题。

Method: 提出序列探针框架，采用耦合和测量无关的形式。具体实例化使用受控旋转探针耦合与固定投影测量和交换Rx门字母表。推导深度相关的泄漏包络，预测"Goldilocks"耦合带。开发基于机器学习的操作解码器，从经验相关记录映射到每步门标签。

Result: 实验表明，严格的序列恢复集中在预测的耦合带附近，在退相干和有限次估计下可预测地退化。机器学习解码器能够泛化到不同的耦合和噪声设置而无需重新训练。

Conclusion: 序列相干侧信道攻击在特定耦合条件下是可行的，机器学习方法能够有效解码隐藏门序列。这揭示了量子计算中侧信道漏洞的存在，并为量子安全分析提供了新工具。

Abstract: We study a sequential coherent side-channel model in which an adversarial probe qubit interacts with a target qubit during a hidden gate sequence. Repeating the same hidden sequence for $N$ shots yields an empirical full-correlation record: the joint histogram $\widehat{P}_g(b)$ over probe bit-strings $b\in\{0,1\}^k$, which is a sufficient statistic for classical post-processing under identically and independently distributed (i.i.d.) shots but grows exponentially with circuit depth. We first describe this sequential probe framework in a coupling- and measurement-agnostic form, emphasizing the scaling of the observation space and why exact analytic distinguishability becomes intractable with circuit depth.
  We then specialize to a representative instantiation (a controlled-rotation probe coupling with fixed projective readout and a commuting $R_x$ gate alphabet) where we (i) derive a depth-dependent leakage envelope whose maximizer predicts a "Goldilocks" coupling band as a function of depth, and (ii) provide an operational decoder, via machine learning, a single parameter-conditioned map from $\widehat{P}_g$ to Alice's per-step gate labels, generalizing across coupling and noise settings without retraining. Experiments over broad coupling and noise grids show that strict sequence recovery concentrates near the predicted coupling band and degrades predictably under decoherence and finite-shot estimation.

</details>


### [99] [Benchmarking the Lights Out Problem on Real Quantum Hardware](https://arxiv.org/abs/2602.16014)
*Maksims Dimitrijevs,Maria Palchiha,Abuzer Yakaryilmaz*

Main category: quant-ph

TL;DR: 论文在IBM和IQM量子硬件上实现了Lights Out问题，评估了Grover搜索性能，发现IBM硬件在Heron r1到r2代有明显改进，IQM设备输出接近均匀分布，并观察到设备校准对性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究量子硬件上Grover搜索算法的实际性能，评估不同量子计算平台（IBM和IQM）在解决Lights Out问题时的表现，分析硬件进步和校准对性能的影响。

Method: 在2D网格和Mobius阶梯图上实现Lights Out问题，使用9和16量子比特实例，在IBM和IQM的公开量子硬件上运行实验，包括Heron r1/r2代设备，并运行小型Grover SAT基准测试进行诊断。

Result: IBM硬件在2023-2024年间从Heron r1到r2代有明显性能改进；IQM设备上Lights Out电路输出接近均匀分布；IQM Garnet比其他IQM设备更可靠；相同制造版本的量子处理器性能差异显著；校准质量对设备性能有重要影响。

Conclusion: 量子硬件性能不仅取决于制造代际，校准质量同样关键；设备选择应综合考虑制造版本和校准状态；IBM硬件在短时间内取得显著进步，但实际量子计算仍需关注设备特定特性。

Abstract: We implement the Lights Out problem on a 2D grid and on Mobius ladder graphs and evaluate the performance of Grover's search on real quantum hardware. We use two instances using 9 and 16 qubits, and implement them on publicly available quantum hardware by IBM and IQM. Our experiments show improvements in IBM hardware between the Heron r1 and Heron r2 generations, highlighting progress in IBM hardware during the 2023-2024 period. The Lights Out circuits produced output distributions close to uniform on IQM devices. To diagnose device limitations, we additionally ran a small Grover SAT baseline, finding that IQM Garnet performs more reliably than other tested IQM devices. We also observed that QPUs of the same manufacturing revision can differ significantly in performance (a newer device is not guaranteed to be better), and that calibration has a significant impact on the performance of quantum devices, so the choice of device strongly depends on calibration quality.

</details>


### [100] [Edge-Local and Qubit-Efficient Quantum Graph Learning for the NISQ Era](https://arxiv.org/abs/2602.16018)
*Armin Ahmadkhaniha,Jake Doliskani*

Main category: quant-ph

TL;DR: 提出了一种专为NISQ量子设备设计的全量子图卷积架构，用于无监督学习，通过边局部和量子比特高效的消息传递机制，将量子比特需求从O(Nn)降低到O(n)。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在量子硬件上实现面临电路深度、多量子比特交互和量子比特可扩展性等挑战，需要设计适合NISQ时代的量子图学习架构。

Method: 结合变分量子特征提取层和基于QAOA框架启发的边局部量子比特高效消息传递机制，将消息传递分解为仅使用硬件原生单量子比特和双量子比特门的成对交互。

Result: 在Cora引文网络和大规模基因组SNP数据集上的实验表明，该模型与现有量子及混合方法相比具有竞争力，同时显著减少了量子比特需求。

Conclusion: 提出了一种适合NISQ设备的全量子图卷积架构，通过边局部设计实现了量子比特效率，为在量子硬件上实现图神经网络提供了可行方案。

Abstract: Graph neural networks (GNNs) are a powerful framework for learning representations from graph-structured data, but their direct implementation on near-term quantum hardware remains challenging due to circuit depth, multi-qubit interactions, and qubit scalability constraints. In this work, we introduce a fully quantum graph convolutional architecture designed explicitly for unsupervised learning in the noisy intermediate-scale quantum (NISQ) regime. Our approach combines a variational quantum feature extraction layer with an edge-local and qubit-efficient quantum message-passing mechanism inspired by the Quantum Alternating Operator Ansatz (QAOA) framework. Unlike prior models that rely on global operations or multi-controlled unitaries, our model decomposes message passing into pairwise interactions along graph edges using only hardware-native single- and two-qubit gates. This design reduces the qubit requirement from $O(Nn)$ to $O(n)$ for a graph with $N$ nodes and $n$-qubit feature registers, enabling implementation on current quantum devices regardless of graph size. We train the model using the Deep Graph Infomax objective to perform unsupervised node representation learning. Experiments on the Cora citation network and a large-scale genomic SNP dataset demonstrate that our model remains competitive with prior quantum and hybrid approaches.

</details>


### [101] [Device for MHz-rate rastering of arbitrary 2D optical potentials](https://arxiv.org/abs/2602.16025)
*Edita Bytyqi,Josiah Sinclair,Joshua Ramette,Vladan Vuletić*

Main category: quant-ph

TL;DR: 提出一种光学光栅设备，能以1MHz刷新率产生任意2D图案，突破现有中性原子阵列中AOD和SLM设备的动态控制限制。


<details>
  <summary>Details</summary>
Motivation: 当前中性原子阵列使用AOD和SLM设备，动态控制受限于AOD响应时间，且几何结构受限（只能行列移动）。需要更灵活、高速的控制方案来提升量子比特连接性和电路效率。

Method: 提出光学光栅设备设计，能产生任意2D图案（不限于网格），刷新率达1MHz。设计分辨率为40×40，可扩展至100×100以匹配现有和未来中性原子设备。

Result: 该设备能同时以任意方向传输原子量子比特，将增强量子比特连接性，实现更高效的量子电路，并在LiDAR、荧光显微镜等领域有广泛应用潜力。

Conclusion: 光学光栅设备解决了中性原子量子计算中的动态控制瓶颈，为量子比特的灵活操控提供了新方案，有望推动量子计算和相关光学应用的发展。

Abstract: Current architectures for neutral-atom arrays utilize devices such as acousto-optic deflectors (AODs) and spatial light modulators (SLMs) to multiplex a single classical control line into N qubit control lines. Dynamic control is speed-limited by the response time of AODs, and geometrically constrained to respect a product structure, limiting motion to row-by-row or column-by-column moves. We propose an optical rastering device that can produce any 2D pattern, not limited to grids, at 1 MHz refresh rates. We demonstrate a design with a resolution of 40 x 40 that can be further scaled up to 100 x 100 to match existing and future neutral atom devices. The ability to simultaneously transport atomic qubits in arbitrary directions will enhance qubit connectivity, enable more efficient circuits, and may have broader applications ranging from LiDAR to fluorescence microscopy.

</details>


### [102] [Multi-emitter oscillating bound states in Waveguide QED](https://arxiv.org/abs/2602.16032)
*Sergi Terradas-Briansó,Carlos A. González-Gutiérrez,Iván Huarte,David Zueco,Luis Martin-Moreno*

Main category: quant-ph

TL;DR: 研究腔阵列波导中两个量子发射器与光子束缚态叠加的形成与动力学，发现自发辐射可驱动系统进入非局域平衡态，产生持续振荡的混合模式。


<details>
  <summary>Details</summary>
Motivation: 探索波导量子电动力学平台中的非马尔可夫量子现象，特别是研究两个空间分离量子发射器与腔阵列波导耦合系统中束缚态叠加的形成机制和动力学特性。

Method: 通过调节系统参数，分析推导束缚态叠加态出现的条件，数值模拟自发辐射驱动的形成过程，并预测其长时间行为。

Result: 发现自发辐射可将系统驱动到非局域平衡态，光子和发射器布居数均呈现持续振荡；这些态源于能量连续谱内外的束缚态共存，形成混合振荡模式；束缚态叠加支持发射器间通过自由演化产生相互作用，同时支持光子密度在发射器间的振荡呼吸模式。

Conclusion: 束缚态叠加态能够实现发射器间相互作用的生成，并支持光子密度的振荡呼吸模式，为波导量子电动力学平台中的非马尔可夫量子现象提供了新的实现途径。

Abstract: Waveguide quantum electrodynamics platforms have emerged as promising candidates for exploring and implementing non-Markovian quantum phenomena. In this work, we investigate the formation and dynamics of superpositions of bound states in a cavity array waveguide coupled to two spatially separated quantum emitters. By tuning the system parameters, we show that spontaneous emission can drive the system into non-local equilibrium states in which both photonic and emitter populations exhibit persistent oscillations. These states arise from the coexistence of bound states embedded in the energy continuum and bound states outside it, leading to hybrid oscillatory modes. We analytically derive the conditions required for the emergence of these states, numerically simulate their formation through spontaneous emission, and predict their long-time behaviour. Our results demonstrate that such bound-state superpositions enable the generation of emitter-emitter interaction through free evolution, while supporting oscillatory breathing modes of the photon density between the emitters.

</details>


### [103] [Strong-to-Weak Symmetry Breaking in Open Quantum Systems: From Discrete Particles to Continuum Hydrodynamics](https://arxiv.org/abs/2602.16045)
*Jacob Hauser,Kaixiang Su,Hyunsoo Ha,Jerome Lloyd,Thomas G. Kiely,Romain Vasseur,Sarang Gopalakrishnan,Cenke Xu,Matthew P. A. Fisher*

Main category: quant-ph

TL;DR: 该论文研究了U(1)对称开放系统动力学中强对称性到弱对称性的自发破缺现象，在一维系统中发现有限时间内不会发生破缺，但相关函数在长度尺度上线性增长；在二维系统中存在有限时间的BKT类相变。


<details>
  <summary>Details</summary>
Motivation: 研究在保持电荷守恒的开放系统动力学中，强对称性如何自发破缺为弱对称性，探索这一现象在不同维度下的行为特征和时间尺度。

Method: 通过三种互补模型进行研究，包括数值模拟、场论分析和流体动力学描述，构建显式解码协议来理解对称性破缺的起源。

Result: 一维系统中强对称性在有限时间内不会破缺，但相关函数在长度尺度上线性增长，快于电荷扩散；二维系统存在有限时间的BKT类相变；连续流体动力学中二维及以上维度在无穷小时间内发生破缺。

Conclusion: SW-SSB转变时间标志着连续流体动力学描述的出现，即超过该时间尺度后，非流体动力学信息（如离散粒子世界线）无法再被推断，为从量子动力学推导经典随机流体动力学描述提供了框架。

Abstract: We explore the onset of spontaneous strong-to-weak symmetry breaking (SW-SSB) under U(1)-symmetric (i.e., charge-conserving) open-system dynamics. We define this phenomenon for quantum states and classical probability distributions, and explore it in three complementary models, one of which exhibits nontrivial quantum coherence at short times. Our main conclusions are as follows. In one dimension, the strong symmetry is not spontaneously broken at any finite time; however, correlators probing strong-to-weak symmetry breaking develop order on length scales that grow linearly in time, parametrically faster than charge diffusion. We provide numerical evidence for this scaling in multiple distinct probes of SW-SSB, and derive it from a field-theory analysis. Moreover, we relate this scaling to the problem of inferring the charge inside a subregion by measuring its surroundings, and construct explicit decoding protocols that illustrate its origin. In two dimensions, field theory and numerical simulations support a finite-time Berezinskii-Kosterlitz-Thouless-like SW-SSB transition. Within continuum hydrodynamics, by contrast, SW-SSB happens at infinitesimal time in two or more dimensions. The SW-SSB transition time can thus be interpreted as marking the emergence of a continuum hydrodynamic description, or (more precisely) the timescale beyond which non-hydrodynamic information such as discrete particle worldlines can no longer be inferred. We support this picture by analyzing a model in which we exploit SW-SSB to derive a classical stochastic hydrodynamic description from the underlying quantum dynamics.

</details>


### [104] [Contractivity of time-dependent driven-dissipative systems](https://arxiv.org/abs/2602.16067)
*Lasse H. Wolff,Daniel Malz,Rahul Trivedi*

Main category: quant-ph

TL;DR: 研究具有固定耗散器和时变驱动哈密顿量的Lindblad主方程的收缩性，发现在足够小或足够慢的驱动下系统保持指数收缩，但大或快驱动可能导致非收缩动力学。


<details>
  <summary>Details</summary>
Motivation: 在量子系统与环境相互作用并受时变控制的实际物理场景中，需要理解系统何时会失去关于初始状态的信息（即动力学是指数收缩的）。虽然对时无关Lindblad算子的收缩性已有广泛研究，但对时变情况的理解还很有限。

Method: 研究具有固定耗散器（描述环境相互作用）但具有时变驱动哈密顿量的Lindblad主方程。分析在足够小或足够慢驱动下的指数收缩性，并提供固定耗散器的充分条件以保证哈密顿量无关的收缩性。

Result: 证明了在足够小或足够慢驱动下系统保持指数收缩，但给出了即使固定耗散器本身是指数收缩的，足够大或足够快的哈密顿量仍可导致非收缩动力学的具体例子。为固定耗散器提供了若干充分条件，可完全表征幺正耗散器和两能级系统的哈密顿量无关收缩性。

Conclusion: 时变驱动哈密顿量可以显著影响量子系统的收缩性：小或慢驱动保持收缩性，但大或快驱动可能破坏收缩性。为固定耗散器建立的充分条件有助于识别哈密顿量无关的收缩情况，特别对幺正耗散器和两能级系统给出了完整表征。

Abstract: In a number of physically relevant contexts, a quantum system interacting with a decohering environment is simultaneously subjected to time-dependent controls and its dynamics is thus described by a time-dependent Lindblad master equation. Of particular interest in such systems is to understand the circumstances in which, despite the ability to apply time-dependent controls, they lose information about their initial state exponentially with time i.e., their dynamics are exponentially contractive. While there exists an extensive framework to study contractivity for time-independent Lindbladians, their time-dependent counterparts are far less well understood. In this paper, we study the contractivity of Lindbladians, which have a fixed dissipator (describing the interaction with an environment), but with a time-dependent driving Hamiltonian. We establish exponential contractivity in the limit of sufficiently small or sufficiently slow drives together with explicit examples showing that, even when the fixed dissipator is exponentially contractive by itself, a sufficiently large or a sufficiently fast Hamiltonian can result in non-contractive dynamics. Furthermore, we provide a number of sufficient conditions on the fixed dissipator that imply exponential contractivity independently of the Hamiltonian. These sufficient conditions allow us to completely characterize Hamiltonian-independent contractivity for unital dissipators and for two-level systems.

</details>


### [105] [Lie-Algebraic Analysis of Generators: Approximation-Error Bounds and Barren-Plateau Heuristics](https://arxiv.org/abs/2602.16094)
*Hiroshi Ohno*

Main category: quant-ph

TL;DR: 该论文从李代数视角分析量子机器学习，推导了量子电路在Sobolev空间中的逼近误差上下界，提出了基于非对易生成元扩大频率集的生成元选择规则，并设计了基于迹分量的启发式度量来表征训练中的贫瘠高原现象。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中，参数化量子电路的期望值可以视为三角多项式，其可访问的傅里叶模式由生成元的谱决定。本文旨在从李代数框架出发，分析量子电路的函数逼近能力，特别是研究生成元选择对频率集扩展和训练动态的影响。

Method: 1) 理论分析：推导了当电路有效频率集包含在半径K球内时，Sobolev球上L²逼近误差的极小极大下界；同时推导了Sobolev正则性下量子电路逼近误差的Jackson型上界。2) 生成元选择规则：基于非对易生成元扩大有效频率集的动机。3) 启发式度量：设计基于生成元迹分量的简单度量来表征贫瘠高原相关的训练行为。

Result: 1) 当目标函数属于Sobolev空间W₂ʳ(𝕋ᵈ)且r>d/2时，逼近误差下界为Ω(K^{d/2 - r})；上界由生成元谱隙决定的有效带宽表达。2) 提出了扩大有效频率集的生成元选择规则。3) 设计了基于迹分量的启发式度量。仿真实验验证了频率谱视角和所提启发式方法的实际意义。

Conclusion: 李代数为量子机器学习提供了有用的理论分析框架。通过频率谱视角，可以深入理解量子电路的逼近能力、生成元选择对频率集扩展的影响，以及训练动态中的贫瘠高原现象。所提理论界限和启发式方法为量子电路设计和训练提供了指导。

Abstract: Lie algebras provide a useful framework for theoretical analysis in quantum machine learning, particularly in hybrid quantum-classical learning. From the viewpoint of function approximation, expectation values of parameterized quantum circuits can be viewed as trigonometric polynomials whose accessible Fourier modes are determined by the spectra of the generators. In this study, we describe: (1) a minimax lower bound on the $ L^{2} $-approximation error over a Sobolev ball when the circuit's effective frequency set is contained in a radius-$K$ ball, which yields a scaling law of the form $ Ω(K^{\frac{d}{2} - r}) $ for $ r > \frac{d}{2} $ (assuming the target function belongs to the Sobolev space $ W_2^{r}(\mathbb{T}^{d}) $), and we also derive a Jackson-type upper bound on the approximation error of quantum circuits under Sobolev regularity of the target function, expressed in terms of an effective bandwidth determined by generator spectral gaps; (2) a generator-selection rule motivated by enlarging the effective frequency set via non-commuting generators; and (3) a simple heuristic metric based on the trace component of generators, aimed at characterizing training behaviors related to barren plateaus. Simulation experiments on toy problems illustrate the practical implications of the frequency-spectrum perspective and the proposed heuristics.

</details>


### [106] [Local and Multi-Scale Strategies to Mitigate Exponential Concentration in Quantum Kernels](https://arxiv.org/abs/2602.16097)
*Claudia Zendejas-Morales,Debashis Saikia,Utkarsh Singh*

Main category: quant-ph

TL;DR: 量子保真度核在系统规模增大时会出现指数集中问题，本文研究了两种缓解策略：局部核和多尺度核，并通过实验验证它们能有效缓解集中问题并提升核谱丰富度。


<details>
  <summary>Details</summary>
Motivation: 基于保真度的量子核在系统规模增加或电路表达能力增强时会出现指数集中问题，导致格拉姆矩阵趋近于单位矩阵，从而抑制了有信息的相似性结构。需要研究有效的缓解策略。

Method: 提出了两种缓解策略：1) 局部核（块状核），通过聚合子系统相似性；2) 多尺度核，混合局部和全局相似性。在多个表格数据集上进行基准测试，比较基线、局部和多尺度核的性能。

Result: 局部和多尺度构造能一致地缓解集中问题，相对于全局保真度基线产生更丰富的核谱。分类准确性的影响取决于具体数据集和维度。

Conclusion: 局部和多尺度量子核能有效缓解指数集中问题，提升核方法的实用性，但分类性能提升与具体应用场景相关。

Abstract: Fidelity-based quantum kernels provide a direct interface between quantum feature maps and classical kernel methods, but they can exhibit exponential concentration: with increasing system size or circuit expressivity, the Gram matrix approaches the identity and suppresses informative similarity structure. We present an empirical study of two mitigation strategies implemented in Qiskit: (i) local (patch-wise) kernels that aggregate subsystem similarities, and (ii) multi-scale kernels that mix local and global similarity across patch granularities.
  We benchmark baseline, local, and multi-scale kernels under matched preprocessing, splits, and SVM protocols on several tabular datasets, sweeping the feature dimension $d\in\{4,6,\dots,20\}$. We report concentration diagnostics based on off-diagonal kernel statistics, spectral richness via effective rank, and centered alignment with labels. Across datasets, local and multi-scale constructions consistently mitigate concentration and yield richer kernel spectra relative to the global fidelity baseline, while the impact on classification accuracy depends on the dataset and dimension.

</details>


### [107] [Reductions of QAOA Induced by Classical Symmetries: Theoretical Insights and Practical Implications](https://arxiv.org/abs/2602.16141)
*Boris Tsvelikhovskiy,Bao Bach,Jose Falla,Ilya Safro*

Main category: quant-ph

TL;DR: 该研究利用经典对称性作为QAOA的设计原则，通过固定变量分析MaxCut问题的简化QAOA实例，发现DLA维度可从指数级坍缩到二次方，从而改善可训练性。


<details>
  <summary>Details</summary>
Motivation: 量子近似优化算法（QAOA）的性能与其哈密顿量生成的动态李代数（DLA）结构密切相关，这决定了算法的表达能力和可训练性。研究旨在探索如何利用经典对称性作为设计原则来改进QAOA。

Method: 聚焦于具有全局比特翻转对称性的MaxCut问题，分析通过固定单个变量得到的简化QAOA实例，研究这种选择如何影响相关的DLA结构。通过数值实验验证不对称图上的DLA维度减小现象，并证明任何图都可以嵌入到稍大的图中，使得标准简化DLA与自由简化DLA重合。

Result: 研究发现DLA结构会因固定哪个变量而发生显著变化，构造了DLA维度从指数级坍缩到二次方的具体示例。数值实验表明，在不对称图上，这种简化通常产生维度小得多的DLA，暗示着改善的可训练性。理论证明任何图都可以嵌入到稍大的图中（仅需二次方开销），使得标准简化DLA在大多数情况下具有指数维度和在希尔伯特空间上的不可约性。

Conclusion: 这些结果确立了对称感知简化作为一种原则性工具，可用于设计表达能力强且可能具有良好可训练性的QAOA电路，为优化量子算法提供了新的设计思路。

Abstract: The performance of the Quantum Approximate Optimization Algorithm (QAOA) is closely tied to the structure of the dynamical Lie algebra (DLA) generated by its Hamiltonians, which determines both its expressivity and trainability. In this work, we show that classical symmetries can be systematically exploited as a design principle for QAOA. Focusing on the MaxCut problem with global bit-flip symmetry, we analyze reduced QAOA instances obtained by fixing a single variable and study how this choice affects the associated DLAs. We show that the structure of the DLAs can change dramatically depending on which variable is held fixed. In particular, we construct explicit examples where the dimension collapses from exponential to quadratic, uncovering phenomena that do not appear in the original formulation.
  Numerical experiments on asymmetric graphs indicate that such reductions often produce DLAs of much smaller dimension, suggesting improved trainability. We also prove that any graph can be embedded into a slightly larger one (requiring only quadratic overhead) such that the standard reduced DLA coincides with the free reduced DLA, in most cases implying exponential dimension and irreducibility on the Hilbert space for reduced QAOA instances. These results establish symmetry-aware reduction as a principled tool for designing expressive and potentially trainable QAOA circuits.

</details>


### [108] [Reinforcement learning for path integrals in quantum statistical physics](https://arxiv.org/abs/2602.16176)
*Timour Ichmoukhamedov,Dries Sels*

Main category: quant-ph

TL;DR: 提出一种结合强化学习与变分近似的两步法，用于计算量子系统的欧几里得路径积分，从而获得热密度矩阵、自由能等热力学量。


<details>
  <summary>Details</summary>
Motivation: 机器学习在计算量子物理中的应用主要集中在哈密顿量框架下的神经网络量子态方法，而路径积分框架下的机器学习应用相对较少。本文旨在探索强化学习在计算欧几里得路径积分方面的潜力。

Method: 提出两步法：第一步通过强化学习获得变分近似；第二步利用该近似高效计算精确结果。该方法专门用于计算产生量子系统热密度矩阵的欧几里得路径积分。

Result: 在多个简单系统上验证了方法的有效性，并成功应用于量子转子链系统。

Conclusion: 强化学习为路径积分框架下的量子物理计算提供了新途径，提出的两步法结合了变分近似的高效性和精确计算的可靠性。

Abstract: Machine learning is rapidly finding its way into the field of computational quantum physics. One of the most popular and widely studied approaches in this direction is to use neural networks to model quantum states (NQS) in the Hamiltonian formulation of quantum mechanics. However, an alternative angle of attack to leverage machine learning in physics is through the path integral formulation, which has so far received far more limited attention. In this paper, we explore how reinforcement learning can be used to compute a class of Euclidean path integrals that yield the thermal density matrix of a quantum system, thereby enabling the computation of the free energy or other thermal expectation values. In particular, we propose a two-step approach with the unique feature that after a variational approximation for a quantity is obtained in a first step, it can then be used to efficiently compute the exact result in a second step. We benchmark this method on several simple systems and then apply it to the quantum rotor chain.

</details>


### [109] [Squeezed superradiant lasing of a quantum many-body emitter](https://arxiv.org/abs/2602.16215)
*Da-Wu Xiao,Chong Chen,Ren-Bao Liu*

Main category: quant-ph

TL;DR: 提出量子多体激光器概念，其中相互作用的发射器集体辐射，将多体相互作用产生的压缩通过超辐射激光转移到光子


<details>
  <summary>Details</summary>
Motivation: 传统激光器发射器非相干独立辐射，超辐射激光器发射器集体辐射但不相互作用。需要研究相互作用的发射器集体辐射的量子多体激光器

Method: 考虑腔耦合到多个泵浦的自旋-1/2发射器，具有全对全相互作用，研究多体相互作用诱导的压缩如何通过超辐射激光转移到光子

Result: 发现相干多体相互作用产生的压缩可以通过超辐射激光从自旋转移到光子，实现超越传统光学相干性的量子关联

Conclusion: 量子多体系统可用于产生具有超越传统相干性的量子关联的明亮量子光，促进量子技术和量子领域非线性光学研究

Abstract: In conventional lasers, the emitters are typically incoherent, radiating photons independently; in superradiant lasers, many coherent emitters radiate photons collectively, but they essentially do not interact with each other. Here, we present the concept of quantum many-body lasers, in which the emitters interact coherently and radiate collectively. In this proof-of-concept study, we consider a cavity coupled to many pumped spin-1/2 emitters with all-to-all interaction. We find that the squeezing induced by the coherent many-body interaction can be transferred from the spins to photons through superradiant lasing. This work illustrates the concept of using a pumped quantum many-body system to generate bright quantum light with quantum correlations beyond conventional optical coherence, which can facilitate quantum technologies and the study of nonlinear optics in the quantum realm.

</details>


### [110] [Structured Unitary Tensor Network Representations for Circuit-Efficient Quantum Data Encoding](https://arxiv.org/abs/2602.16266)
*Guang Lin,Toshihisa Tanaka,Qibin Zhao*

Main category: quant-ph

TL;DR: TNQE：基于张量网络分解的量子数据编码框架，通过结构化酉张量网络表示构建电路高效的量子编码，深度仅为振幅编码的0.04倍，支持高分辨率图像处理


<details>
  <summary>Details</summary>
Motivation: 传统量子数据编码方法存在电路效率低的问题，需要深层电路和大量量子资源，限制了在量子硬件上的可扩展性。需要开发电路高效的编码方案来解决这一瓶颈。

Method: 提出TNQE框架：1）将经典输入通过张量网络分解表示；2）通过两种互补的核心到电路策略将张量核心编译为编码电路；3）引入酉感知约束，将张量核心参数化为可学习的块酉矩阵，使其可直接优化并编码为量子算子

Result: TNQE实现了极浅的编码电路（深度仅为振幅编码的0.04倍），能够自然扩展到高分辨率图像（256×256），并在真实量子硬件上展示了实际可行性

Conclusion: TNQE提供了一种电路高效的量子数据编码框架，通过结构化酉张量网络表示实现了对电路深度和量子比特资源的显式控制，为量子机器学习中的可扩展数据编码提供了实用解决方案

Abstract: Encoding classical data into quantum states is a central bottleneck in quantum machine learning: many widely used encodings are circuit-inefficient, requiring deep circuits and substantial quantum resources, which limits scalability on quantum hardware. In this work, we propose TNQE, a circuit-efficient quantum data encoding framework built on structured unitary tensor network (TN) representations. TNQE first represents each classical input via a TN decomposition and then compiles the resulting tensor cores into an encoding circuit through two complementary core-to-circuit strategies. To make this compilation trainable while respecting the unitary nature of quantum operations, we introduce a unitary-aware constraint that parameterizes TN cores as learnable block unitaries, enabling them to be directly optimized and directly encoded as quantum operators. The proposed TNQE framework enables explicit control over circuit depth and qubit resources, allowing the construction of shallow, resource-efficient circuits. Across a range of benchmarks, TNQE achieves encoding circuits as shallow as $0.04\times$ the depth of amplitude encoding, while naturally scaling to high-resolution images ($256 \times 256$) and demonstrating practical feasibility on real quantum hardware.

</details>


### [111] [Tomographically-nonlocal entanglement](https://arxiv.org/abs/2602.16280)
*Roberto D. Baldijão,Marco Erba,David Schmid,John H. Selby,Ana Belén Sainz*

Main category: quant-ph

TL;DR: 论文研究了在非局域层析理论中纠缠的两种形式：层析局域纠缠和层析非局域纠缠，并分析了它们的操作特性。


<details>
  <summary>Details</summary>
Motivation: 研究在存在物理约束（如对称性或超选择规则）时纠缠结构的变化，这些约束会导致反直觉现象（如纠缠态的局域广播和纠缠一夫一妻制的失效），特别是在层析非局域理论中。

Method: 在广义概率理论框架下研究纠缠，区分两种纠缠形式：层析局域纠缠和层析非局域纠缠，并分析它们的操作后果。

Result: 证明层析非局域纠缠对Bell非局域性、导引和隐形传态无用，但对密集编码和完美安全数据隐藏足够有效。

Conclusion: 该框架澄清了当层析局域性失效时（即使在考虑费米子或基本超选择规则的量子理论中）出现的几个先前令人困惑的纠缠特征。

Abstract: Entanglement is a central and subtle feature of quantum theory, whose structure and operational behavior can change dramatically when additional physical constraints, such as symmetries or superselection rules, are imposed. Such constraints can give rise to striking and counter-intuitive phenomena, including local broadcasting of entangled states and failures of entanglement monogamy. These effects naturally arise in tomographically nonlocal theories (like real quantum theory, twirled worlds, or fermionic quantum theory), where composite systems possess holistic degrees of freedom that are inaccessible to local measurements. In this work, we study entanglement in such theories within the framework of generalized probabilistic theories. We show that the failure of tomographic locality leads to two qualitatively distinct forms of entanglement, which we term $\textit{tomographically-local}$ entanglement and $\textit{tomographically-nonlocal}$ entanglement. We analyze the operational consequences of this distinction, proving that tomographically-nonlocal entanglement is useless for Bell nonlocality, steering, and teleportation, but sufficient for dense coding and perfectly secure data hiding. This framework clarifies the origin of several previously puzzling features of entanglement that arise when tomographic locality fails, as can happen even in quantum theory when one considers fermions or fundamental superselection rules.

</details>


### [112] [What Kind of World Supports Darwinian Evolution? Quantum Foundational Options](https://arxiv.org/abs/2602.16286)
*Partha Ghose*

Main category: quant-ph

TL;DR: 论文探讨量子力学中达尔文进化条件（可遗传记录、可复制变异、常规不可逆性）的实现，分析量子复制/删除限制，提出解决测量问题的本体论选项，并讨论随机力学作为量子-经典连续桥梁的可能性。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的达尔文进化条件难以实现，因为量子系统缺乏经典数据扇区所需的复制和删除操作。量子测量问题（指针基选择、结果唯一性）需要更清晰的本体论框架，特别是在扩展维格纳朋友实验中，系统同时作为量子对象和具有稳定记录的代理。

Method: 使用范畴量子力学分析量子操作限制；提出四种本体论选项（唯一历史、退相干多重性、代理相对事实性、随机基础）；应用扩展维格纳朋友场景作为压力测试；探索随机力学（可变扩散）作为量子-经典连续桥梁。

Result: 量子复制/删除仅存在于经典数据扇区；退相干选择指针基但不保证唯一结果；扩展维格纳朋友场景揭示量子系统与代理角色的冲突；随机力学提供连续过渡框架，支持测量更新作为条件化加时间对称最小变化规则。

Conclusion: 达尔文进化需要经典资源支持记录过程；测量问题需要明确的本体论选择；随机力学为量子-经典连续过渡提供原则性框架，可能统一测量更新机制。

Abstract: Darwinian evolution requires (i) heritable records, (ii) repeatable copying with variation, and (iii) routine irreversibility. Categorical quantum mechanics (CQM) makes precise why ``copy'' and ``delete'' are not generic quantum operations: they exist only for a realized \emph{classical data} sector (a preferred basis/observable; a commutative structure). Decoherence explains how a pointer basis can be selected dynamically, but it does not by itself select a unique outcome. This motivates a neutral presentation of the main ontological options (unique-history, decohered multiplicity, agent-relative facticity, and a stochastic foundation with variable diffusion). We also note the relevance of the ``agency constraint'' argued by Adlam-McQueen-Waegell: in a strictly coherent, basis-unselected ``purely quantum'' regime, minimal agency fails due to no-cloning and linearity, which sharpens the role of classical resources for record-based processes. Extended Wigner's Friend scenarios then serve as a stress test, since they treat ``friends'' simultaneously as coherent quantum systems and as agents possessing stable records. Finally, a stochastic-mechanics foundation (with variable diffusion) offers a continuous bridge between quantum and classical regimes, and suggests a principled way to implement measurement update as conditioning plus a time-symmetric minimal-change rule.

</details>


### [113] [A resolution of the Ito-Stratonovich debate in quantum stochastic processes](https://arxiv.org/abs/2602.16314)
*Aritro Mukherjee*

Main category: quant-ph

TL;DR: 提出量子噪声均匀化方案，将非马尔可夫彩色噪声驱动的量子随机过程粗粒化为有效的白噪声（马尔可夫）极限，解决了Ito-Stratonovich歧义问题。


<details>
  <summary>Details</summary>
Motivation: 量子随机过程在描述开放量子系统和量子基础理论中广泛应用，但由乘性彩色噪声驱动的物理相关过程通常是非马尔可夫且解析不可处理的。此外，对于同一量子随机过程，使用Ito或Stratonovich约定得到的马尔可夫极限通常不等价。

Method: 引入量子噪声均匀化方案，通过新颖的相空间增广将非马尔可夫动力学映射到高维马尔可夫系统，然后在噪声特征时间尺度上应用受控的微扰粗粒化方案。

Result: 建立了显式解析算法来推导具有重整化系数的有效马尔可夫生成元，能够施加各种物理约束。证明了乘性彩色噪声驱动量子随机过程的一致马尔可夫极限对应于具有重整化系数和Ito修正项的Stratonovich约定。

Conclusion: 通过假设马尔可夫极限展开为完全正、保迹映射，进一步表征了由乘性彩色噪声驱动的物理相关非马尔可夫量子随机过程家族，解决了Ito-Stratonovich歧义问题。

Abstract: Quantum stochastic processes are widely used in describing open quantum systems and in the context of quantum foundations. Physically relevant quantum stochastic processes driven by multiplicative colored noise are generically non-Markovian and analytically intractable. Further, their Markovian limits are generically inequivalent when using either the Ito or Stratonovich conventions for the same quantum stochastic processes. We introduce a quantum noise homogenization scheme that temporally coarse-grains non-Markovian, colored-noise driven quantum stochastic processes and connects them to their effective white-noise (Markovian) limits. Our approach uses a novel phase-space augmentation that maps the non-Markovian dynamics into a higher dimensional Markovian system and then applies a controlled perturbative coarse-graining scheme in the characteristic time scales of the noise. This allows an explicit analytical algorithm to derive effective Markovian generators with renormalized coefficients and enables imposing various physical constraints on them. We thus resolve the Ito-Stratonovich ambiguity for multiplicative colored noise driven quantum stochastic processes, wherein we show that their consistent Markovian limit corresponds to the Stratonovich convention with renormalized coefficients as well as Ito correction terms. By assuming their Markovian limit unravels completely positive, trace-preserving maps, we further characterize a physically relevant family of non-Markovian quantum stochastic processes driven by multiplicative colored noise.

</details>


### [114] [Quantum-enhanced sensing via spectral noise reduction](https://arxiv.org/abs/2602.16350)
*Romain Dalidet,Sébastien Tanzilli,Audrey Dot,Inès Ghorbel,Loïc Morvan,Laurent Labonté,Anthony Martin*

Main category: quant-ph

TL;DR: 该研究通过比较单光子和双光子干涉，在严格相同的噪声条件下直接证明了傅里叶域量子增强传感，展示了3dB的信噪比提升。


<details>
  <summary>Details</summary>
Motivation: 需要直接、公平地证明量子增强传感的优势，特别是在傅里叶域中，通过消除噪声条件差异的影响来提供明确的量子优势基准。

Method: 使用光纤干涉仪，在严格相同的噪声条件下同时采集单光子和双光子干涉信号，通过频谱分析比较两者的性能差异。

Result: 量子关联不增加调制峰幅度，而是降低噪声基底，实现预期的3dB信噪比提升；在亚散粒噪声区域，经典信号被背景噪声淹没而双光子信号仍可分辨。

Conclusion: 傅里叶域量子超灵敏度是一种可操作且广泛适用的资源，可用于精密干涉传感，为量子增强传感提供了明确的实验验证。

Abstract: We report a direct demonstration of quantum-enhanced sensing in the Fourier domain by comparing single- and two-photon interference in a fiber-based interferometer under strictly identical noise conditions. The simultaneous acquisition of both signals provides a common-mode reference that enables a fair and unambiguous benchmark of quantum advantage. Spectral analysis of the interferometric outputs reveals that quantum correlations do not increase the amplitude of the modulation peak, but instead lower the associated noise floor, resulting in the expected 3 dB improvement in signal-to-noise ratio. This enhancement persists in the sub-shot-noise regime, where the classical signal becomes buried in the spectral background while the two-photon contribution remains resolvable. These observations establish Fourier-domain quantum super-sensitivity as an operational and broadly applicable resource for precision interferometric sensing.

</details>


### [115] [A Formal Theory for Finite-Dimensional Possibilistic Quantum Mechanics](https://arxiv.org/abs/2602.16368)
*Olivier Brunet*

Main category: quant-ph

TL;DR: 提出基于经典一阶逻辑的量子系统形式化理论，证明其完备性并刻画模型特征


<details>
  <summary>Details</summary>
Motivation: 传统量子逻辑方法存在局限，需要基于经典一阶逻辑的形式化理论，以便利用模型论工具研究量子系统

Method: 构建基于经典一阶逻辑的量子系统形式化理论，运用模型论方法分析该理论的性质

Result: 证明该形式理论具有完备性，完全决定量子系统行为；提供理论模型的完整刻画，为量子理论隐变量模型研究提供新视角

Conclusion: 基于经典一阶逻辑的量子系统形式化理论是可行的，为量子逻辑研究提供了新框架，对理解量子理论基础有重要意义

Abstract: In this work, we present a logical formalism for reasoning about quantum systems in finite dimension. Contrary to the usual approach in quantum logic, our formalism is based classical first-order logic, which allows us to use the tools of model theory in our study. In particular, we show that our formal theory is complete, meaning that it entirely determines the behaviour of quantum systems. Moreover, we provide a characterization of the models of our formal theory, thus providing new insights in the study of hidden variable models of quantum theory.

</details>


### [116] [Why the Casimir Force for Magnetic Metals Computed by the Lifshitz Theory Using the Drude Model Disagrees with the Measurement Data](https://arxiv.org/abs/2602.16370)
*G. L. Klimchitskaya,C. C. Korikov,V. M. Mostepanenko*

Main category: quant-ph

TL;DR: 分析磁性金属板卡西米尔力中Drude模型与实验数据不一致的原因，发现横向电场贡献是差异来源，且磁性质仅通过横向电场贡献中的传播波部分影响卡西米尔力。


<details>
  <summary>Details</summary>
Motivation: 研究磁性金属板卡西米尔力中Lifshitz理论使用Drude模型预测与实验数据不一致的原因，探索更准确的磁性金属电磁响应理论描述。

Method: 使用Lifshitz理论在纯虚Matsubara频率下计算横向磁性和横向电极化电磁波对卡西米尔力的贡献，并在实频率轴上分析渐逝波和传播波在这些贡献中的比例。对Au-Ni和Ni-Ni板在0.5-6μm间距范围内，分别使用Drude模型和实验一致的等离子体模型进行计算。

Result: 横向磁性贡献不依赖于介电常数模型，总差异完全由横向电场贡献决定。与无磁性金属不同，横向电场贡献中渐逝波和传播波的比例都依赖于介电常数模型，而金属的磁性质仅通过横向电场贡献中的传播波部分影响卡西米尔力。

Conclusion: 需要更准确的磁性金属电磁响应理论描述，特别是横向电场贡献中传播波和渐逝波的行为，以解决Drude模型预测与实验数据的不一致问题。

Abstract: We consider the Casimir force in configurations with magnetic metal plates and analyze the reasons why the predictions of the Lifshitz theory using the dielectric permittivity of the Drude model are inconsistent with the measurement data. For this purpose, the contributions of the electromagnetic waves with the transverse magnetic and transverse electric polarizations to the Casimir force are computed using the Lifshitz theory expressed in terms of the pure imaginary Matsubara frequencies. Furthermore, the fractions of the evanescent and propagating waves in these contributions are found using an equivalent formulation of the Lifshitz theory along the real frequency axis. All computations are performed for Au-Ni and Ni-Ni plates using the Drude model and the experimentally consistent plasma model over the separation region from 0.5 to 6~mum, where the total force value is determined by conduction electrons. It is shown that the transverse magnetic contribution to the Casimir force does not depend on the used model of the dielectric permittivity, so that the total difference between the predictions of the Lifshitz theory using the Drude model and the measurement data is determined by the transverse electric contribution. In doing so, as opposed to the case of nonmagnetic metals, both fractions of the evanescent and propagating waves in this contribution depend on the model of the dielectric permittivity used in computations, whereas the magnetic properties of the plate metal influence the Casimir force solely through the fraction of propagating waves in the transverse electric contribution. The issue of a more adequate theoretical description of the electromagnetic response of magnetic metals is discussed.

</details>


### [117] [Solving the Mysteries of Quantum Mechanics: Why Nature Abhors a Continuum](https://arxiv.org/abs/2602.16382)
*Tim Palmer*

Main category: quant-ph

TL;DR: 论文提出有理量子力学(RaQM)，通过引力离散化希尔伯特空间来解决量子力学中的干涉等核心谜题，利用余弦函数的数论性质解释量子世界的不可分割性和整体性。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的干涉、互补性、可观测量不对易、不确定性原理和贝尔不等式违反等核心谜题，源于希尔伯特空间的连续性假设被认为是不物理的。作者旨在通过离散化希尔伯特空间来解决这些根本问题。

Method: 发展有理量子力学(RaQM)，通过引力离散化希尔伯特空间，利用余弦函数的数论性质（在角度连续时被隐藏），从数学上描述量子世界的不可分割性，建立整体性的物理定律。

Result: RaQM通过离散化解决了量子力学的核心谜题，将贝尔不等式违反解释为整体性而非非定域性，解释了自然为何使用复数，并区分了整体性与非定域性的概念。

Conclusion: 量子力学的谜题源于希尔伯特空间的连续性假设，通过引力离散化建立的有理量子力学(RaQM)用整体性概念解决了这些谜题，解释了复数在自然中的作用，提供了比非定域性更物理的理解框架。

Abstract: Feynman famously asserted that interference is the only real mystery in quantum mechanics (QM). It is concluded that the reason for this mystery, and thereby the related mysteries of complementarity, non-commutativity of observables, the uncertainty principle and violation of Bell's equality, is that the axioms of QM depend vitally on the continuum nature of Hilbert Space, deemed unphysical. We develop a theory of quantum physics - Rational Quantum Mechanics (RaQM) - in which Hilbert Space is gravitationally discretised. The key to solving the mysteries of QM in RaQM is a number-theoretic property of the cosine function, concealed in QM when angles range over the continuum. This number-theoretic property describes mathematically the utter indivisibility of the quantum world and implies that the laws of physics are profoundly holistic. We contrast holism with nonlocality. In theories which embrace the continuum, the violation of Bell's inequality requires the laws of physics to be either nonlocal or not realistic; both incomprehensible concepts. By contrast, holism, as embodied in Mach's Principle or in the fractal geometry of a chaotic attractor, is neither incomprehensible nor unphysical. As part of this, we solve the deepest mystery of all; why nature makes use of complex numbers.

</details>


### [118] [Enhancing delocalization and entanglement in asymmetric discrete-time quantum walks](https://arxiv.org/abs/2602.16391)
*Hao Zhao,Qiyan He,Fengzhi Yang,Cui Kong,Huiyun Cao,Tianqi Yan,Bingrui Zhong,Kaikun Tian,Jiguo Wang,Chuanjia Shan,Jibing Liu*

Main category: quant-ph

TL;DR: 本文研究了非对称离散时间量子行走中离域化和硬币-位置纠缠的增强，通过实验实现了16步非对称量子行走，发现特定条件下纠缠和离域化对偏振相关损耗具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究非对称离散时间量子行走中离域化和硬币-位置纠缠的增强机制，探索量子行走作为研究光子离域化和混合纠缠的理想平台。

Method: 通过数值计算分析非对称硬币操作、非对称初始态和非对称偏振相关损耗对逆参与率和纠缠熵的影响；实验上使用时域复用光纤环结构实现16步非对称量子行走。

Result: 在特定硬币参数下，非对称初始态能同时增强硬币-位置纠缠和离域化；有限非对称偏振相关损耗使左侧光子概率显著降低，右侧概率增加且更局域化；特定条件下纠缠和离域化对偏振相关损耗表现出更好的鲁棒性。

Conclusion: 离散时间量子行走是研究光子离域化和混合纠缠的理想平台，非对称因素可以增强量子行走的纠缠和离域化特性，并在特定条件下表现出对损耗的鲁棒性。

Abstract: In this paper, we investigate the enhancement of delocalization and coin-position entanglement in asymmetric discrete-time quantum walks (DTQWs). The asymmetry results from asymmetric coin operations, asymmetric initial states, and asymmetric polarization-dependent losses. By varying these asymmetry factors, the inverse participation ratio and entanglement entropy of the walker are numerically calculated for different coin and loss parameters, both for symmetric and asymmetric initial states. We then experimentally implement a 16-step asymmetric DTQW using a time-multiplexing fiber loop structure. By choosing an asymmetric initial state, both coin-position entanglement and delocalization are simultaneously enhanced under specific coin parameters. Moreover, we observe that with finite asymmetric polarization-dependent loss, the photon probability on the left side decreases significantly, while that on the right side increases and becomes more localized. Interestingly, under specific coin parameters, the entanglement and delocalization exhibit improved robustness against polarization-dependent loss. These results demonstrate that the DTQWs constitute an ideal platform for investigating photonic delocalization and hybrid entanglement.

</details>


### [119] [Measurement Induced Subradiance](https://arxiv.org/abs/2602.16413)
*Ipsita Bar,Aditi Thakar,B. Prasanna Venkatesh*

Main category: quant-ph

TL;DR: 提出基于单量子二能级发射体投影测量的平台无关协议，用于制备集体发射系统的亚辐射稳态


<details>
  <summary>Details</summary>
Motivation: 集体发射量子二能级发射体的亚辐射稳态难以制备，因为其暗态特性导致相互作用弱。现有方法依赖图案化驱动、局域控制或结构化环境，需要更通用的解决方案。

Method: 提出平台无关协议：通过对单个二能级发射体进行投影测量。对于置换对称系综，单次测量即可获得单激发亚辐射稳态的显著占据；对于一般阵列，重复测量单个发射体可将未测量的发射体驱动到接近纯态，与亚辐射Dicke子空间有大量重叠。

Result: 协议能有效制备亚辐射稳态：置换对称系综中单次测量即可实现；一般阵列中通过重复测量可获得接近纯态的亚辐射态。

Conclusion: 基于单发射体投影测量的协议为制备集体发射系统的亚辐射稳态提供了平台无关的通用方法，克服了传统方法的局限性。

Abstract: Preparing subradiant steady states of collectively emitting quantum two-level emitters (TLEs) is hindered by their dark, weakly interacting nature. Existing approaches rely on patterned driving, local control, or structured environments. We propose a platform-independent protocol based on projective measurements on a single TLE. For permutation-symmetric ensembles, a single measurement yields appreciable occupation of single-excitation subradiant steady states. For generic arrays, repeated measurements on one emitter drive the unmeasured TLEs into a nearly pure state with large overlap with the subradiant Dicke subspace.

</details>


### [120] [Nonlocal prediction of quantum measurement outcomes](https://arxiv.org/abs/2602.16426)
*Chirag Srivastava,Aparajita Bhattacharyya,Ujjwal Sen*

Main category: quant-ph

TL;DR: 论文定义了非局域可预测性概念，证明纠缠态和某些经典相关态能超越局部界限，展示了测量后结果可预测性增加的非局域现象，并发现去相位噪声在某些情况下反而能增强非局域可预测性。


<details>
  <summary>Details</summary>
Motivation: 研究在无经典通信条件下，一个观测者预测另一个观测者测量结果的能力，探索量子非局域性与可预测性之间的关系，特别是纠缠态在此方面的特殊性质。

Method: 定义非局域可预测性概念及其局部界限，分析不同量子态（乘积态、纠缠态、经典相关态）在该界限下的表现，研究去相位噪声对非局域可预测性的影响。

Result: 乘积态总是满足局部界限；所有纯纠缠态和某些经典相关态能超越该界限；最大纠缠态在所有纯态中对任意投影测量都能实现完美非局域可预测性；去相位噪声能增强一大类态和测量的非局域可预测性。

Conclusion: 非局域可预测性揭示了量子测量结果可预测性在测量后增加的非经典现象，最大纠缠态在此方面具有特殊地位，而噪声在某些情况下反而能提供优势，这为理解量子非局域性提供了新视角。

Abstract: We define nonlocal predictability as how well one observer can predict another's measurement outcomes without classical communication, given full knowledge of the shared quantum state and measurement settings. The local bound on nonlocal predictability is defined as the maximum probability with which one observer can correctly predict the other's measurement outcome prior to measurement. We show that product states always meet this bound, while all pure entangled states and some classically correlated states can exceed it. This demonstrates a nonlocal phenomenon since the predictability of measurement outcomes increases after the measurement. Perfect nonlocal predictability for arbitrary projective measurements occurs only for maximally entangled states among all pure states, underscoring their special role. Comparing pure entangled states with their dephased versions, we find that dephasing on one subsystem can enhance nonlocal predictability for a broad class of states and measurements - a counterintuitive, noise-induced advantage that vanishes for maximally entangled states under any projective measurement.

</details>


### [121] [Edge states and quantum optical high-harmonic generation from topological insulators](https://arxiv.org/abs/2602.16454)
*Christian Saugbjerg Lange,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: 该研究填补了拓扑非平庸材料高次谐波产生量子光学处理的空白，发现SSH模型中拓扑平庸和非平庸相的高次谐波在带隙频率处都存在压缩，但压缩程度仅在小系统尺寸下能区分拓扑相。


<details>
  <summary>Details</summary>
Motivation: 当前强场量子光学研究已表明高次谐波产生通常处于非经典光态，但对拓扑非平庸材料的高次谐波产生的量子光学处理尚属空白。本研究旨在填补这一知识缺口。

Method: 采用Su-Schrieffer-Heeger模型，研究有限原子链在拓扑平庸和非平庸绝缘相（后者支持边缘态）中的量子光学高次谐波响应。

Result: 发现两种拓扑相的高次谐波在带隙频率处都存在压缩。有趣的是，虽然谐波谱能区分系统的两个拓扑相，但压缩程度仅在小链长情况下能区分拓扑相。这归因于小系统中拓扑非平庸相中体态和边缘态相对重叠的增加。

Conclusion: 研究揭示了偶极耦合强度如何控制非经典高次谐波响应，并为强场物理中拓扑保护量子光产生定义了新的研究问题。

Abstract: The strong-field process of high-harmonic generation (HHG) has, in recent years, been treated from a quantum optical perspective in the emerging research area of strong-field quantum optics. These investigations show that HHG radiation is, in general, in a nonclassical state of light. However, the quantum optical treatment of HHG from topological nontrivial materials is missing. Here, we aim to address this gap in current knowledge and consider the quantum optical HHG response from the Su-Schrieffer-Heeger model, a finite chain of atoms with both a topologically trivial and nontrivial insulating phase, the latter supporting edge states. We find that HHG from both topological phases is squeezed at the band-gap frequency. Interestingly, while the harmonic spectrum discriminates the two topological phases of the system, the degree of squeezing only discriminates the phases for smaller chain lengths. We attribute this difference to a relative increase in overlap between bulk and edge states in the topological nontrivial phase for smaller systems. Our findings reveal how the strength of dipole couplings governs the nonclassical HHG response and define new research questions on topologically protected generation of quantum light in strong-field physics.

</details>


### [122] [Quantitative study of Silicon Waveguides for the Generation of Quantum Correlated Photon Pairs Bridging Mid-Infrared and Telecom Bands](https://arxiv.org/abs/2602.16464)
*Abhishek Kumar Pandey,Deepak Jain,Catherine Baskiotis*

Main category: quant-ph

TL;DR: 该研究提出利用硅基波导中的自发四波混频技术，实现3-4μm中红外波段与电信C波段之间的量子关联光子对源，为大气量子密钥分发和气体传感提供新方案。


<details>
  <summary>Details</summary>
Motivation: 传统基于自发参量下转换的量子光源需要昂贵的实现平台且灵活性有限。研究旨在开发一种更经济、灵活的光源，能够桥接中红外波段与电信/近红外/可见光波段，这对量子技术应用至关重要。

Method: 采用全固态硅基绝缘体波导中的自发四波混频技术，通过实验验证的模型进行设计。选择2100-2210nm波长范围的泵浦光（5ps脉冲），针对0.05的每脉冲光子对生成概率进行定量模拟，使用2cm长直波导和基模TE00模式。

Result: 提出了三种设计：wCOM设计达到3.905μm信号波长（位于大气透明窗口），闲频光在电信C波段，适用于大气量子密钥分发；wCH4和wNO2设计分别针对CH4和NO2气体传感，信号波长为3265nm和3461nm。wCOM实现了2364nm的信号/闲频波长分离，远超现有记录。

Conclusion: 该研究证明了硅基波导中自发四波混频技术能够高效产生桥接中红外与电信波段的量子关联光子对，为大气量子密钥分发和气体传感等应用提供了实用且经济的解决方案。

Abstract: Sources of quantum correlated photons pairs bridging the 3um-4um Mid-infrared (MIR) band and Telecom/Near-Infrared/Visible band are of high importance for quantum technologies. Spontaneous Parametric Down Conversion is generally used for realizing such sources, but requires costly implementation platforms with reduced versatility. Here, we explore the potentialities of Spontaneous Four-Wave Mixing (SFWM) in all-solid Silicon On Insulator (SOI) waveguides thanks to an experimentally validated model and propose designs ensuring the production of correlated photon pairs bridging the 3um-4um Mid-infrared band and Telecom C-band. Choosing a pump with a wavelength in the range 2100nm-2210nm and a pulse duration of 5ps, we quantitatively performed simulations targeting a probability of photon pair generation per pulse of 0.05, and we found realistic conditions of utilization (2cm-length straight waveguides, intra-modal Four Wave Mixing with the fundamental TE00 mode) with a pump peak power in between 9.2mW and 32mW. A first design (wCOM) reaches a signal wavelength as high as 3.905um, which is situated in an atmospheric transparency window, while maintaining an idler in the Telecom C-band, making it of high interest for atmospheric Quantum Key Distribution. Two other designs wCH4 and wNO2 aim precise CH4 and NO2 gas sensing with a signal wavelength of 3265nm and 3461nm respectively. In terms of signal/idler wavelength separation, wCOM attains the value of 2364nm which is well above the current record of ~1125nm obtained in quantum regime with SFWM in all-solid SOI waveguides.

</details>


### [123] [Nonequilibrium Casimir-Polder Force: Motion-induced Thermal-like Effect](https://arxiv.org/abs/2602.16483)
*D. Reiche,B. Beverungen,K. Busch,F. Intravaia*

Main category: quant-ph

TL;DR: 分析原子以恒定速度相对于宏观物体运动时的卡西米尔-波尔德力，揭示非平衡和非保守相互作用的新特性，包括运动诱导的有效温度现象。


<details>
  <summary>Details</summary>
Motivation: 研究原子在宏观物体附近以恒定速度运动时的卡西米尔-波尔德力，特别关注之前被忽视的非平衡和非保守相互作用特性，探索与Fulling-Davies-Unruh效应相关的物理现象。

Method: 采用一种精确处理原子-场耦合的方法，考虑环境对运动粒子的反作用，分析原子相对于具有平移不变性的宏观物体集合的运动情况。

Result: 揭示了之前被忽视的非平衡和非保守相互作用特性，发现了一种可以通过运动诱导的有效温度来理解的物理行为，该现象与Fulling-Davies-Unruh效应有相似之处。

Conclusion: 这项工作为理解系统中非平衡物理现象提供了新视角，特别是运动诱导的有效温度现象与Fulling-Davies-Unruh效应的相似性，开辟了研究非平衡物理的新途径。

Abstract: The Casimir-Polder force is analyzed when an atom is moving at a constant velocity relative to a collection of translationally invariant macroscopic bodies with generic shapes and compositions. The interaction is described within an approach that accurately treats the atom-field coupling and accounts for the backaction from the environment onto the moving particle. Previously overlooked aspects are uncovered and linked to the nonequilibrium and nonconservative nature of the interaction. Specifically, we examine a behavior that can be understood by characterizing the underlying physical processes in terms of a motional-induced effective temperature. This phenomenon shares similarities with the Fulling-Davies-Unruh effect, opening new perspectives for the understanding of nonequilibrium physics at work in the system.

</details>


### [124] [Port-based teleportation under pure-dephasing decoherence](https://arxiv.org/abs/2602.16513)
*Rajendra S. Bhati,Michał Studziński,Jarosław K. Korbicz*

Main category: quant-ph

TL;DR: 研究噪声环境下确定性端口基量子隐形传态，分析资源态和测量过程同时受噪声影响的情况，发现噪声适应测量反而不如无噪声测量


<details>
  <summary>Details</summary>
Motivation: 研究实际物理系统中量子隐形传态协议在噪声环境下的性能，特别是当纠缠资源态和测量过程都受到噪声影响时的表现

Method: 采用两种噪声场景分析：1）仅资源态受退相干影响，理想测量；2）资源态和测量都受噪声影响，使用噪声适应测量。结合解析方法（推导纠缠保真度下界和闭式表达式）与半解析数值方法，并将协议嵌入自旋玻色子模型研究环境记忆和温度影响

Result: 发现噪声适应测量性能反而比无噪声测量更差；推导了隐形传态通道纠缠保真度的解析下界和闭式表达式；不同环境（浴记忆和温度）对隐形传态保真度产生定性差异影响

Conclusion: 噪声环境下确定性端口基量子隐形传态的性能受环境特性显著影响，噪声适应测量策略不一定能提高性能，需要根据具体噪声模型和环境特性进行优化设计

Abstract: We study deterministic port based teleportation in the presence of noise affecting both the entangled resource state and the measurement process. We focus on a physically motivated model in which each Bell pair constituting the resource interacts with an identical local environment, corresponding to independently distributed entangled links. Two noisy scenarios are analyzed: one with decoherence acting solely on the resource state and ideal measurements, and another with noisy, noise adapted measurements optimised for the given noise model. In the first case, we derive an analytical lower bound and later a closed-form expression for the entanglement fidelity of the teleportation channel and analyze its asymptotic behaviour. In the second, we combine semi analytical and numerical methods. Surprisingly, we find that noise-adapted measurements perform worse than the noiseless ones. To connect the abstract noise description with microscopic physics, we embed the protocol in a spin boson model and investigate the influence of bath memory and temperature on the teleportation fidelity, highlighting qualitative differences between different environments.

</details>


### [125] [Bichromatic Quantum Teleportation of Weak Coherent Polarization States on a Metropolitan Fiber](https://arxiv.org/abs/2602.16613)
*Zofia A. Borowska,Shane Andrewski,Giorgio De Pascalis,Olivia Brasher,Mael Flament,Alexander N. Craddock,Niccolò Bigagli,Ronny Döring,Michaela Ritter,Ralf-Peter Braun,Klaus Jons,Marc Geitz,Oliver Holschke,Matheus Sena,Mehdi Namazi*

Main category: quant-ph

TL;DR: 在柏林电信基础设施上实现量子隐形传态，平均保真度90%，与现有光通信系统兼容


<details>
  <summary>Details</summary>
Motivation: 随着量子技术成熟，电信运营商有机会通过提供连接量子设备的网络层来扩展新服务，这需要在真实电信基础设施上演示量子网络协议

Method: 使用商业组件在柏林电信数据中心部署系统，通过本地贝尔态测量实现条件态传输，将795nm光子态转移到O波段光子，通过30公里现场光纤环路传输

Result: 在部署链路上实现平均90%的隐形传态保真度，系统在有无C波段经典流量共存的情况下均表现良好，证明与承载实时数据信道的波分复用电信基础设施兼容

Conclusion: 成功在真实电信基础设施上演示了量子隐形传态，为量子网络在现有电信架构中的实际应用铺平了道路

Abstract: As quantum technologies mature, telecommunication operators have a clear opportunity to unlock and scale new services by providing the connectivity layer that links quantum computers, sensors, clocks, and other quantum devices. Realizing this opportunity requires demonstrating quantum networking protocols, including quantum teleportation, under real-world conditions on existing telecom infrastructure. In this work, we demonstrate quantum teleportation over Deutsche Telekom's metropolitan fiber testbed in Berlin using commercial components deployed at the telecom datacenter. A local Bell-state measurement between 795 nm photons from a weak coherent source and from a bichromatic warm-atom entangled photon source enables conditional state transfer onto an O-band photon, which is transmitted through a 30-km field-deployed fiber loop under real-world environmental conditions. The teleported state is reconstructed after propagation via state tomography, achieving an average teleportation fidelity of 90\% on the deployed link. System performance is evaluated in both the absence and the presence of co-propagating C-band classical traffic within the same fiber, demonstrating compatibility with wavelength-division multiplexed telecom infrastructure carrying live data channels.

</details>


### [126] [Beyond the Classical Ceiling: Multi-Layer Fully-Connected Variational Quantum Circuits](https://arxiv.org/abs/2602.16623)
*Howard Su,Chen-Yu Liu,Samuel Yen-Chi Chen,Kuan-Cheng Chen,Huan-Hsin Tseng*

Main category: quant-ph

TL;DR: 提出FC-VQC架构，通过限制局部希尔伯特空间维度但实现全局特征交互，实现线性可扩展性，在300资产期权组合定价任务中超越经典梯度提升方法。


<details>
  <summary>Details</summary>
Motivation: 传统VQC面临维度灾难问题，计算成本呈指数增长且存在贫瘠高原问题。现有解决方案依赖经典神经网络进行特征压缩，掩盖了真正的量子能力。

Method: 提出多层全连接VQC架构，通过限制局部希尔伯特空间维度，同时通过结构化块混合实现全局特征交互，实现端到端量子学习，无需可训练经典编码器。

Result: 在标准基准测试和高维工业任务（300资产期权组合定价）中验证了方法的有效性。FC-VQC打破了"经典天花板"，超越了最先进的梯度提升方法（XGBoost/CatBoost），同时比深度神经网络具有约17倍的参数效率。

Conclusion: 纯模块化量子架构能够有效学习工业规模的特征空间，这些空间对于单体ansatz是不可处理的，为量子机器学习在高维工业应用中的可行性提供了具体证据。

Abstract: Standard Variational Quantum Circuits (VQCs) struggle to scale to high-dimensional data due to the ``curse of dimensionality,'' which manifests as exponential simulation costs ($\mathcal{O}(2^d)$) and untrainable Barren Plateaus. Existing solutions often bypass this by relying on classical neural networks for feature compression, obscuring the true quantum capability. In this work, we propose the \textbf{Multi-Layer Fully-Connected VQC (FC-VQC)}, a modular architecture that performs \textbf{end-to-end quantum learning} without trainable classical encoders. By restricting local Hilbert space dimensions while enabling global feature interaction via structured block mixing, our framework achieves \textbf{linear scalability $\mathcal{O}(d)$}. We empirically validate this approach on standard benchmarks and a high-dimensional industrial task: \textbf{300-asset Option Portfolio Pricing}. In this regime, the FC-VQC breaks the ``Classical Ceiling,'' outperforming state-of-the-art Gradient Boosting baselines (XGBoost/CatBoost) while exhibiting \textbf{$\approx 17\times$ greater parameter efficiency} than Deep Neural Networks. These results provide concrete evidence that pure, modular quantum architectures can effectively learn industrial-scale feature spaces that are intractable for monolithic ansatzes.

</details>


### [127] [Amplification of bosonic interactions through squeezing in the presence of decoherence](https://arxiv.org/abs/2602.16655)
*Ankit Tiwari,Cecilia Cormick,Christian Arenz*

Main category: quant-ph

TL;DR: 通过正交压缩的参量控制增强玻色子相互作用，在噪声环境中实现更快的量子态制备和纠缠门


<details>
  <summary>Details</summary>
Motivation: 在存在噪声和退相干的情况下，需要更快的复杂量子态制备和纠缠门实现方法

Method: 利用正交压缩的参量控制来增强玻色子相互作用，包括二次和四次哈密顿量，同时抑制噪声影响

Result: 该方法能增强所需相互作用，同时减少有害过程的放大，提高两个玻色模式间贝尔型纠缠态的保真度

Conclusion: 该方法促进了在退相干机制存在下更快地制备复杂量子态和实现纠缠门

Abstract: We consider the amplification of bosonic interactions through parametric control that implements squeezing along orthogonal quadratures. We show that bosonic interactions described by certain classes of quadratic and quartic Hamiltonians can be enhanced in this way while simultaneously overcoming noise and decoherence. In general, the amplification method enhances both desired and undesired interactions present in the system. Depending on the case, however, detrimental processes can be less amplified than the desired couplings. We leverage this observation to improve the fidelity for preparing Bell-type entangled states between two bosonic modes in the presence of noise and losses. We also investigate noise models for which the protocol either fails or partially achieves a loss-tolerant state preparation speedup. Our work facilitates faster preparation of complex quantum states and implementation of entangling gates in the presence of decoherence mechanisms.

</details>


### [128] [Intermodal quantum key distribution over an 18 km free-space channel with adaptive optics and room-temperature detectors](https://arxiv.org/abs/2602.16680)
*Edoardo Rossi,Ilektra Karakosta-Amarantidou,Matteo Padovan,Marco Nardi,Marco Avesani,Francesco Bruno Leonardo Santagiustina,Marco Taffarello,Antonio Vanzo,Stefano Bonora,Giuseppe Vallone,Paolo Villoresi,Francesco Vedovato*

Main category: quant-ph

TL;DR: 在18公里自由空间链路上实现了实时跨模态量子密钥分发现场试验，通过自适应光学系统校正湍流畸变，实现了200比特/秒的安全密钥生成


<details>
  <summary>Details</summary>
Motivation: 跨模态量子密钥分发在电信波长下可提供光纤与自由空间链路的混合接口，这对实现可扩展、互操作的量子网络至关重要。然而，长距离实现面临湍流引起的波前畸变挑战，限制了接收端单模光纤的高效耦合

Method: 采用自适应光学系统，实施直接波前传感和高阶畸变校正，实现高效单模光纤耦合。使用配备室温探测器的紧凑状态分析器，在18公里自由空间链路上连接远程终端与城市光学地面站（配备40厘米级望远镜）

Result: 成功实现了200比特/秒的安全密钥生成，并通过实验数据验证了基于湍流的单模光纤耦合效率预测模型

Conclusion: 该工作为未来跨模态量子网络提供了实用的设计指导，证明了自适应光学系统在长距离自由空间量子密钥分发中的关键作用

Abstract: Intermodal quantum key distribution at telecom wavelengths provides a hybrid interface between fiber connections and free-space links, both essential for the realization of scalable and interoperable quantum networks. Although demonstrated over short-range free-space links, long-distance implementations of intermodal quantum key distribution remain challenging, due to turbulence-induced wavefront aberrations which limit efficient single-mode fiber coupling at the optical receiver. Here, we demonstrate a real-time intermodal quantum key distribution field trial over an 18 km free-space link, connecting a remote terminal to an urban optical ground station equipped with a 40 cm-class telescope. An adaptive optics system, implementing direct wavefront sensing and high-order aberration correction, enables efficient single-mode fiber coupling and allows secure key generation of 200 bit/s using a compact state analyzer equipped with room-temperature detectors. We further validate through experimental data a turbulence-based model for predicting fiber coupling efficiency, providing practical design guidelines for future intermodal quantum networks.

</details>


### [129] [Numerical study of non-relativistic quantum systems and small oscillations induced in a helically twisted geometry](https://arxiv.org/abs/2602.16693)
*C. F. S. Pereira,R. L. L. Vitória,A. R. Soares,B. B. Silva,H. Belich,Edilberto O. Silva*

Main category: quant-ph

TL;DR: 研究非相对论标量粒子在三维螺旋扭曲几何中的束缚态，考虑自由情况和外部径向相互作用，通过数值方法计算能谱和本征函数，分析四种代表性场景。


<details>
  <summary>Details</summary>
Motivation: 研究几何曲率（特别是螺旋扭曲）如何影响量子粒子的束缚态，探索几何耦合本身是否能产生有效约束，即使在没有外部相互作用的情况下。

Method: 将薛定谔方程在弯曲空间背景上求解，考虑阿哈罗诺夫-玻姆磁通量最小耦合。通过变量分离将问题简化为一维径向本征值方程，采用自伴Sturm-Liouville问题的有限差分离散化方法进行数值求解，并控制收敛性。

Result: 分析了四种场景：(i)无外部势，(ii)康奈尔型约束，(iii)克拉策型相互作用，(iv)莫尔斯势极小值附近的小振荡区域。展示了低能级随扭曲参数、磁场和方位角扇区的系统趋势，发现几何耦合本身可以在没有外部相互作用时产生有效约束。

Conclusion: 螺旋扭曲几何中的曲率效应可以产生有效的量子约束机制，几何耦合与外部势场相互作用共同决定了束缚态的特性，为量子系统在非平凡几何背景中的行为提供了新见解。

Abstract: We investigate bound states of a non-relativistic scalar particle in a three-dimensional helically twisted (torsional) geometry, considering both the free case and the presence of external radial interactions. The dynamics is described by the Schrödinger equation on a curved spatial background and, when included, by minimal coupling to a magnetic vector potential incorporating an Aharonov--Bohm flux. After separation of variables, the problem reduces to a one-dimensional radial eigenvalue equation governed by an effective potential that combines torsion-induced Coulomb-like and centrifugal-like structures with magnetic/flux-dependent terms and optional model interactions. Because closed-form analytic solutions are not reliable over the parameter ranges required for systematic scans, we compute spectra and eigenfunctions numerically by formulating the radial equation as a self-adjoint Sturm--Liouville problem and solving it with a finite-difference discretization on a truncated radial domain, with explicit convergence control. We analyze four representative scenarios: (i) no external potential, (ii) Cornell-type confinement, (iii) Kratzer-type interaction, and (iv) the small-oscillation regime around the minimum of a Morse potential. We present systematic trends of the low-lying levels as functions of the torsion parameter, magnetic field, and azimuthal sector, and we show that geometric couplings alone can produce effective confinement even in the absence of an external interaction.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [130] [Cosmic Hysteresis in Reconstructed $f(T)$ Bounce Models A Torsion-Based Thermodynamic Perspective](https://arxiv.org/abs/2602.15924)
*Aritra Sanyal,Praveen Kumar Dhankar,Albert Munyeshyaka,Safiqul Islam,Farook Rahaman,Behnam Pourhassan*

Main category: gr-qc

TL;DR: 在重构的f(T)引力框架下研究循环宇宙和反弹宇宙中的宇宙滞后现象，发现标量场动力学在膨胀和收缩相中的不对称性导致非零热力学功积分，表现为(w_φ,a)平面上的闭合回路。


<details>
  <summary>Details</summary>
Motivation: 研究在修改引力理论中循环宇宙和反弹宇宙是否会出现宇宙滞后现象，特别是在基于挠率的f(T)引力框架下，探索这种滞后现象对宇宙时间箭头的意义。

Method: 通过重构与解析规定的非奇异反弹标度因子对应的可行f(T)函数，将几何与最小相互作用的典型标量场耦合，推导修改的弗里德曼方程，建立精确的反弹和转向条件。

Result: 标量场在膨胀和收缩相中的不对称动力学导致完整周期上的非零热力学功积分，在(w_φ,a)平面上形成闭合回路，表明热力学记忆和不可逆性，确认宇宙滞后是修改引力中循环宇宙的普遍特征。

Conclusion: 宇宙滞后是修改引力理论中循环宇宙的普遍特征，不仅限于曲率基理论，在f(T)引力框架下同样存在，这种滞后现象对宇宙时间箭头有重要启示。

Abstract: We investigate the emergence of cosmic hysteresis in cyclic and bouncing cosmologies within the framework of reconstructed $f(T)$ gravity. In contrast to curvature-based modifications of General Relativity, teleparallel gravity attributes gravitation to spacetime torsion encoded in the torsion scalar $T$. By reconstructing viable $f(T)$ functions corresponding to analytically prescribed nonsingular bouncing scale factors and coupling the geometry to a minimally interacting canonical scalar field, we demonstrate that asymmetric scalar field dynamics between expansion and contraction phases give rise to a non-vanishing thermodynamic work integral $\oint p_φ\, dV$ over complete cycles. This hysteresis manifests as closed loops in the $(w_φ,a)$ plane, signifying thermodynamic memory and irreversibility. We derive the modified Friedmann equations, establish exact bounce and turnaround conditions, and discuss the implications of torsion-induced hysteresis for the cosmological arrow of time. Our results confirm that cosmic hysteresis is a generic feature of cyclic universes in modified gravity, extending beyond curvature-based theories.

</details>


### [131] [Power-Law Inflation in n-Dimensional Fractional Scalar Field Cosmology: Observational Constraints and Dynamical Analysis](https://arxiv.org/abs/2602.15991)
*Daniel Oliveira,Seyed Rasouli,Joao Marto,Paulo Moniz*

Main category: gr-qc

TL;DR: 分数阶标量场宇宙学通过引入分数阶α修正标准幂律暴胀，在保持标量谱指数ns与观测一致的同时，显著压低张标比r，解决了传统幂律暴胀r过大的问题。


<details>
  <summary>Details</summary>
Motivation: 传统四维爱因斯坦引力中的幂律暴胀（a(t)∝t^m）虽然能给出与CMB数据兼容的标量谱指数ns=1-2/m，但预测的张标比r=16/m过大，不符合当前观测限制。需要一种机制在保持ns不变的同时压低r。

Method: 引入分数阶标量场宇宙学，通过分数阶α≠1在弗里德曼和克莱因-戈登动力学中产生非局域（记忆）修正。推导出α(n,m)的显式映射关系，并自洽地得到指数型标量势。通过动力系统分析验证分数阶幂律解的稳定性。

Result: 对于观测偏好的α≈0.8-0.9，在四维情况下得到ns≈0.965且r≲0.04，使幂律暴胀与观测数据一致。当α→1时恢复标准幂律暴胀极限。分数阶幂律解在可行参数范围内形成稳定的暴胀吸引子。

Conclusion: 分数阶幂律暴胀建立了一个可预测且可检验的理论框架，为即将到来的CMB偏振测量提供了明确的目标，成功解决了传统幂律暴胀中张标比过大的问题。

Abstract: Power-law inflation with $a(t) \propto t^m$ is conceptually simple and predicts a scalar tilt $n_s = 1 - 2/m$ compatible with CMB data, but in four-dimensional Einstein gravity it typically yields a tensor-to-scalar ratio $r = 16/m$ that is too large to satisfy current bounds. We show that a minimal extension based on fractional scalar-field cosmology resolves this tension. Introducing a fractional order $α\neq 1$ generates non-local (memory) corrections in the Friedmann and Klein-Gordon dynamics that suppress $r$ while keeping $n_s$ essentially unchanged. We derive an explicit mapping $α(n,m)$ and recover the standard power-law limit as $α\to 1$. For observationally favored values $α\approx 0.8$-$0.9$ in four dimensions we obtain $n_s \approx 0.965$ and $r \lesssim 0.04$, bringing power-law inflation into agreement with data. The scalar potential follows self-consistently as an exponential, and a dynamical-systems analysis shows the fractional power-law solutions form stable inflationary attractors over the viable parameter range. These results establish fractional power-law inflation as a predictive and testable framework, with clear targets for forthcoming CMB polarization measurements.

</details>


### [132] [The most general four-derivative Unitary String Effective Action with Torsion and Stringy-Running-Vacuum-Model Inflation: Old ideas from a modern perspective](https://arxiv.org/abs/2602.16076)
*Nick E. Mavromatos,George Panagopoulos*

Main category: gr-qc

TL;DR: 该论文重新审视了弦理论启发的运行真空模型（StRVM）的有效作用量，通过场重定义分析四阶导数项，证明了StRVM框架在宇宙学应用中的完备性。


<details>
  <summary>Details</summary>
Motivation: 研究弦理论启发的运行真空模型（StRVM）的有效作用量，特别是在(3+1)维时空中的四阶导数项，以确保模型同时满足幺正性和挠率解释的要求，并验证StRVM在弦理论框架中的可嵌入性。

Method: 通过适当的局域场重定义方法，保持微扰弦散射矩阵不变，分析(3+1)维时空中的曲率平方项有效作用量，特别关注幺正性和Kalb-Ramond反对称张量场强的挠率解释要求。

Result: 研究发现幺正性和挠率解释要求导致一种新的四阶导数项，但该项与StRVM框架中的主要项相比小很多数量级，对暴胀和暴胀后物理没有实际影响，从而证明了StRVM宇宙学场景的完备性。

Conclusion: StRVM宇宙学场景在现象学上是完备的，可以完全嵌入UV完备的弦理论框架中，新发现的四阶导数项对相关物理没有实际影响。

Abstract: The string-inspired running vacuum model (StRVM) of inflation is based on a Chern-Simons (CS) gravity effective action, in which the only four-spacetime-derivative-order term is a gravitational anomalous CS Pontryagin density coupled to an axion. In this work, we revisit curvature-squared string-inspired effective actions, from the point of view of appropriate local field redefinitions, leaving the perturbative string scattering matrices invariant. We require simultaneously unitarity and torsion interpretation of the field strength of the Kalb-Ramond antisymmetric tensor, features characterising the (3+1)-dimensional StRVM Cosmology. Unlike the higher dimensional case, the above feature is possible in the context of (3+1)-dimensional spacetimes, obtained after string compactification. We demonstrate that the unitarity and torsion-interpretation requirements lead to a single-type of extra four-derivative terms in the effective gravitational action, not discussed in the previous literature of StRVM, which however is shown to be subleading by many orders of magnitude, compared to the terms of the StRVM framework. Hence, its presence has no practical implications for the relevant inflationary (and, hence, postinflationary) physics of the StRVM. This demonstrates the phenomenological completeness of the StRVM cosmological scenario, which is thus fully embeddable in the UV complete (quantum-gravity compatible) string theory framework.

</details>


### [133] [A Brief Review of Wormhole Cosmic Censorship](https://arxiv.org/abs/2602.16116)
*Leonel Bixano,I. A. Sarmiento-Alvarado,Tonatiuh Matos*

Main category: gr-qc

TL;DR: 论文提出了"虫洞宇宙审查"概念，通过精确解展示环形奇点被虫洞喉部隔离，无法被观测到


<details>
  <summary>Details</summary>
Motivation: 扩展彭罗斯的宇宙审查猜想，探索另一种类型的宇宙审查机制：虫洞喉部能够"吸入"测地线，阻止它们接触奇点，从而将时空奇点与宇宙因果断开

Method: 构建爱因斯坦-麦克斯韦-伸缩子方程的一系列精确解，这些解具有环形奇点特征，但奇点被虫洞结构因果隔离

Result: 获得了具有环形奇点的精确解，其中曲率不变量在环形区域奇异，但该环形奇点与宇宙因果断开，没有测地线能够触及它

Conclusion: 提出了"虫洞宇宙审查"作为宇宙审查猜想的扩展，展示了虫洞结构能够有效隐藏奇点，使其无法被观测

Abstract: Spacetime singularities, in the sense that curvature invariants are infinite at some point or region, are thought to be impossible to observe, and must be hidden within an event horizon. This conjecture is called Cosmic Censorship (CC), and was formulated by Penrose. Here we review another type of CC where spacetime singularities are causally disconnected from the universe, because the throat of a wormhole ``sucks in'' the geodesics and prevents them from making contact with the singularity. In this work, we present a series of exact solutions to the Einstein--Maxwell--Dilaton equations that feature a ring singularity; that is, the curvature invariants are singular in this ring, but the ring is causally disconnected from the universe so that no geodesics can touch it. This extension of CC is called Wormhole Cosmic Censorship.

</details>


### [134] [Comments on Entire Functions of the Derivative Operator](https://arxiv.org/abs/2602.16190)
*R. P. Woodard*

Main category: gr-qc

TL;DR: 论文证明指数微分算符并非正定，存在无限振荡解，挑战了非局域场论的基础假设


<details>
  <summary>Details</summary>
Motivation: 许多非局域场论研究假设指数d'Alembertian算符是正定的，可以避免高阶导数拉格朗日量的Ostrogradskian不稳定性。本文旨在检验这一基本假设的正确性。

Method: 使用一维点粒子q(t)的简单模型，分析方程exp[T² d²/dt²] q(t) = 0的解的性质。通过数学分析证明该方程存在无限多个振荡解。

Result: 证明指数微分算符并非正定，方程存在无限多个快速振荡、指数增长和衰减的解。这些解与在任意有限区间内任意指定"初始值数据"的能力一一对应。

Conclusion: 非局域场论中关于指数d'Alembertian算符正定性的基本假设是错误的，这对其理论基础提出了重要挑战。

Abstract: Many attempts to introduce fundamental nonlocality into quantum (or classical) field theory are based on the assumption that exponentials of the d'Alembertian are positive-definite, so that these operators can be employed without engendering the Ostrogradskian instability associated with higher derivative Lagrangians. {\bf This assumption is false.} Working in the simple context of a 1-dimensional, point particle $q(t)$, I demonstrate that the equation $\exp[T^2 \tfrac{d^2}{dt^2}] q(t) = 0$ has an infinite number of rapidly oscillating, exponentially rising and falling solutions. This infinite kernel is in one-to-one correspondence with the ability to specify ``initial value data'' {\it arbitrarily} over {\it any} finite interval $t_1 < t < t_2$.

</details>


### [135] [On the Possibility of Quantum Gravity Emerging from Geometry](https://arxiv.org/abs/2602.16219)
*Jaume Gine*

Main category: gr-qc

TL;DR: 该论文探讨了从几何中诱导出有效的广义不确定性原理(GUP)的可能性，并将引力GUP重新解释为由微观视界几何诱导的有效不确定性关系，最终提出了从几何中涌现量子引力的概念。


<details>
  <summary>Details</summary>
Motivation: 论文旨在探索量子引力与几何之间的深层联系，试图回答：是否可以从纯粹的几何结构中涌现出有效的广义不确定性原理？特别是，引力GUP是否可以被重新解释为由微观视界几何诱导的有效不确定性关系？更广泛地说，是否可能发展出一种从几何中涌现量子引力的理论框架？

Method: 作者提出了一种几何诱导的方法，将广义不确定性原理(GUP)重新解释为从微观视界几何中涌现的有效不确定性关系。这种方法试图建立几何结构与量子引力效应之间的直接联系，通过几何构造来推导出类似于GUP的关系。

Result: 论文给出了肯定的答案，但带有重要的警告。作者成功展示了从几何中诱导出有效GUP的可能性，并将引力GUP重新解释为由微观视界几何诱导的有效不确定性关系，为从几何中涌现量子引力提供了理论基础。

Conclusion: 该研究支持了从几何中涌现量子引力的可能性，但强调了这一结论的重要限制条件。这表明几何结构可能在量子引力理论中扮演更基础的角色，为理解量子引力与几何之间的深层联系开辟了新途径。

Abstract: Is it possible to induce an effective generalized uncertainty principle (GUP) emerging from geometry and reinterpret the gravitational GUP as the effective uncertainty relation induced by microscopic horizon geometry? More broadly, is it possible to develop a notion of quantum gravity emerging from geometry? We will give a positive answer, but with important caveats.

</details>


### [136] [Rotating Black Holes with Primary Scalar Hair: Shadow Signatures in Beyond Horndeski Gravity](https://arxiv.org/abs/2602.16237)
*Kourosh Nozari,Milad Hajebrahimi,Sara Saghafi,G. Mustafa,Emmanuel N. Saridakis*

Main category: gr-qc

TL;DR: EHT观测M87*黑洞为强场引力提供直接测试，本文在超越Horndeski引力理论中构建具有原初标量毛的旋转黑洞解，分析其光子区域和阴影特征，发现标量毛参数Q会特征性地改变阴影形状，负Q使阴影变大且更圆，正Q使阴影变小且更扁。将M87*建模在此框架下并施加EHT观测约束，确定了可行的(a,Q)参数空间，发现当前观测不排除具有原初标量毛的旋转黑洞，但Q>0时允许区域显著受限。


<details>
  <summary>Details</summary>
Motivation: 事件视界望远镜(EHT)对M87*的观测为强场引力提供了直接测试，测量了阴影直径和圆度偏差。这些观测允许对Kerr范式和无毛定理的可能偏离进行定量测试。在标量-张量引力扩展中，黑洞可能具有原初标量毛，引入超越质量和自旋的额外独立参数。本文旨在研究超越Horndeski引力中具有原初标量毛的旋转黑洞解，分析其光子区域和阴影形成，并利用EHT观测约束来限制标量毛参数。

Method: 在超越Horndeski引力理论中构建具有原初标量毛的旋转黑洞解，分析这些解的光子区域和阴影形成机制。研究标量毛参数Q如何特征性地修改黑洞阴影：负Q使阴影变大并减少其扁率，正Q使阴影变小并增强其扭曲。将M87*建模在此理论框架下，施加EHT观测的阴影直径(42±3 μas)和圆度偏差(ΔC≤0.1)约束，确定可行的自旋参数a和标量毛参数Q的参数空间。

Result: 研究发现标量毛参数Q会特征性地改变黑洞阴影：负Q使阴影变大且更圆，正Q使阴影变小且更扁。将M87*建模在此框架下并施加EHT观测约束后，确定了可行的(a,Q)参数空间。当前观测不排除具有原初标量毛的旋转黑洞，但Q>0时的允许区域显著受限。标量毛引起的偏差约为O(μas)量级，接近当前仪器的灵敏度阈值，但在下一代视界尺度成像的探测范围内。

Conclusion: EHT对M87*的观测为测试超越Kerr黑洞的引力理论提供了有力工具。在超越Horndeski引力中，具有原初标量毛的旋转黑洞可以产生特征性的阴影修改，这些修改受到当前观测的限制。虽然Q>0的参数空间显著受限，但当前观测不排除这类解的存在。标量毛引起的μas量级偏差接近当前仪器的探测极限，但有望被下一代视界尺度成像技术探测到，为测试无毛定理和探索超越广义相对论的引力理论开辟了新途径。

Abstract: The Event Horizon Telescope (EHT) image of M87* provides a direct test of strong-field gravity, measuring an angular shadow diameter $θ_d = 42 \pm 3~μ\mathrm{as}$ and a circularity deviation $ΔC \leq 0.1$. Such observations allow quantitative tests of the Kerr paradigm and of possible deviations from the no-hair theorem. In scalar-tensor extensions of gravity, black holes may possess primary scalar hair, introducing an additional independent parameter beyond mass and spin. In this work, we construct rotating black hole solutions with primary scalar hair in beyond Horndeski gravity and analyze their photon regions and shadow formation. We show that the scalar hair parameter $Q$ induces characteristic modifications of the shadow, and in particular negative $Q$ enlarges the shadow and reduces its oblateness, while positive $Q$ shrinks and enhances its distortion. Modeling M87* within this framework and imposing the EHT bounds on $θ_d$ and $ΔC$, we determine the viable $(a,Q)$ parameter space. We find that current observations do not exclude rotating black holes with primary scalar hair, although the allowed region is significantly restricted for $Q>0$. Finally, the scalar-hair-induced deviations are of order $\mathcal{O}(μ\mathrm{as})$, placing them near the sensitivity threshold of present instruments and within reach of next-generation horizon-scale imaging.

</details>


### [137] [Tidal Deformation Bounds and Perturbation Transfer in Bounded Curvature Spacetimes](https://arxiv.org/abs/2602.16285)
*Martin Drobczyk*

Main category: gr-qc

TL;DR: 论文推导了潮汐场全局有界时空的两个模型无关结果：1) 累积测地线偏差的严格上界，由τ*控制；2) 临界波数k*分离绝热与非绝热扰动转移，Bogoliubov系数在kτ*≫1时指数抑制。


<details>
  <summary>Details</summary>
Motivation: 研究在潮汐场有界条件下，局部惯性近似的操作分辨率和潮汐动力学，不涉及时空离散性。旨在建立与具体度规细节无关的普适结果。

Method: 给定沿自由下落世界线的电Riemann特征值上界λ_max，推导：1) 通过有界曲率内部的累积测地线偏差上界；2) 临界波数k*~τ*^{-1}分离绝热与非绝热扰动转移。验证了四维共形平坦核心的基准比τ*/L*=24^{1/4}，并通过Weyl-to-Kretschmann比ε_C量化对最大对称性偏离的鲁棒性。在极端Hayward几何中进行数值验证。

Result: 证明了两个关键结果：1) 累积测地线偏差的严格上界由τ*≡λ_max^{-1/2}控制；2) 存在临界波数k*~τ*^{-1}，将绝热与非绝热扰动转移分开，当kτ*≫1时Bogoliubov系数指数抑制。这些结果仅依赖于潮汐界和温和的时标假设，对度规细节不敏感。

Conclusion: 建立了潮汐场有界时空的普适框架，提供了与具体度规无关的操作分辨率尺度和扰动转移特性。结果对偏离最大对称性的情况具有鲁棒性，为研究高曲率区域中的物理过程提供了模型无关的工具。

Abstract: We derive two model-independent results for spacetimes with globally bounded tidal fields. These are operational resolution scales of the local-inertial approximation and tidal dynamics; no spacetime discreteness is implied. Given an invariant bound $λ_{\max}\leλ_{\rm bound}$ on the electric Riemann eigenvalues $E_{ij}\equiv R_{\hat{0}i\hat{0}j}$ along freely falling worldlines, we prove (i)~a rigorous upper bound on accumulated geodesic deviation through any bounded curvature interior, controlled by $τ_*\equivλ_{\max}^{-1/2}$, and (ii)~the existence of a critical wavenumber $k_*\simτ_*^{-1}$ separating adiabatic from non-adiabatic perturbation transfer through high-curvature epochs, with Bogoliubov coefficients exponentially suppressed for $k\,τ_*\gg 1$. Both results depend only on the tidal bound (and, for mode transfer, on a mild timescale assumption for the curvature-driven effective potential) and are otherwise insensitive to metric details. For preparation, we collect the standard operational consequences of bounded curvature, including the accuracy-dependent local-inertial domain $L_{\rm LI}(\varepsilon)\sim\sqrt{\varepsilon}\, λ_{\max}^{-1/2}$ and, for conformally flat cores in four dimensions, the benchmark ratio $τ_*/L_*=24^{1/4}$ with $L_*\equiv K_{\max}^{-1/4}$. We quantify the robustness of this coefficient under departures from maximal symmetry via the Weyl-to-Kretschmann ratio $ε_C$. The general framework is validated numerically in the extremal Hayward geometry.

</details>


### [138] [Gravitational Waves from Primordial Black Holes formed by Null Energy Condition Violation during Inflation](https://arxiv.org/abs/2602.16292)
*Dong-Hui Yu,Jia-Zuo Zhang,Yong Cai*

Main category: gr-qc

TL;DR: 通过计算PBH形成环降阶段和后续双星合并的引力波贡献，扩展了研究，展示了多组分引力波谱，为通过多波段引力波观测探测或约束暴胀期间的NEC违反提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 暴胀期间零能量条件（NEC）的瞬时违反为产生原初黑洞（PBHs）和随机引力波背景提供了新机制。先前研究主要关注PBH形成，但需要更全面地计算引力波贡献，包括PBH形成环降阶段和后续双星合并的引力波。

Method: 扩展先前研究，计算PBH形成环降阶段和后续双星合并的引力波贡献。分析多组分引力波谱，包括原初引力波、标量诱导引力波、PBH环降和双星合并的引力波发射。

Result: 该情景产生丰富的多组分引力波谱，包含原初引力波、标量诱导引力波、PBH环降和双星合并的引力波。不同频率波段的相关特征为通过未来多波段引力波观测探测或约束暴胀期间的NEC违反提供了新途径。

Conclusion: 暴胀期间NEC违反产生的多组分引力波谱具有独特的跨波段相关特征，这为通过未来多波段引力波观测探测或约束NEC违反提供了强大而新颖的方法。

Abstract: A transient violation of the null energy condition (NEC) during inflation provides a novel mechanism for producing primordial black holes (PBHs) and stochastic gravitational wave (GW) backgrounds. In this work, we extend previous studies by computing the GW contributions from both the ringdown phase of PBH formation and subsequent binary mergers. Our results show that this scenario produces a rich, multi-component GW spectrum consisting of primordial GWs, scalar-induced GWs, and GW emissions from PBH ringdown and binary mergers. We demonstrate that these correlated signatures across different frequency bands provide a novel and powerful avenue to probe or constrain NEC violation during inflation through future multi-band GW observations.

</details>


### [139] [Entropy Modifications from Stochastic Metric Fluctuations](https://arxiv.org/abs/2602.16294)
*Amir A. Khodahami,Ahmad Sheykhi*

Main category: gr-qc

TL;DR: 通过引入时空度量的随机涨落，从动力学角度推导出修正的弗里德曼方程，将熵-面积关系的偏离解释为微观随机自由度的宏观表现。


<details>
  <summary>Details</summary>
Motivation: 传统上，宇宙学中视界熵对面积律的偏离通常通过唯象方式引入修正的弗里德曼方程。本文旨在证明这种修正不必是唯象的，而是可以从时空度量的随机涨落中动态地涌现出来。

Method: 考虑一个受共形、时间依赖性噪声因子扰动的FRW宇宙，该噪声的系综平均为零，保持平均背景几何不变。通过对爱因斯坦方程进行涨落振幅的二阶平均，推导出包含有效修正项的修正弗里德曼方程。

Result: 推导出的修正项等价于从任意熵-面积关系变形得到的一般表达式。通过指定共形噪声的统计特性（特别是方差），成功再现了与多个著名广义熵框架相关的弗里德曼方程修正，包括Rényi、(对偶)Kaniadakis、Barrow、对数和MOND启发的超几何熵。

Conclusion: 面积律的偏离可以解释为时空微观随机自由度未解析的宏观粗粒化印记，为理解广义熵框架提供了新的物理解释。

Abstract: Deviations from the area law of the horizon entropy, in the cosmological setup, are known to lead to modified Friedmann equations governing the evolution of the universe. In this work, we propose that such modifications need not be introduced phenomenologically but can emerge dynamically from stochastic fluctuations of the spacetime metric. We consider a Friedmann-Robertson-Walker (FRW) universe perturbed by a conformal, time-dependent noise factor, whose ensemble average vanishes, leaving the mean background geometry unchanged. By averaging the Einstein equations to second order in the fluctuation amplitude, we derive a modified Friedmann equation that includes an effective correction term. This correction is shown to be equivalent to the general expression obtained from an arbitrary deformation of the entropy-area relation. By specifying the statistical properties, particularly the variance of the conformal noise, we successfully reproduce the Friedmann equation corrections associated with several well-known generalized entropy frameworks, including Rényi, (dual) Kaniadakis, Barrow, logarithmic, and MOND inspired hypergeometric entropies. Our results suggest that deviations from the area law can be interpreted as the macroscopic, coarse-grained imprint of unresolved, microscopic stochastic degrees of freedom in spacetime.

</details>


### [140] [The Penrose-Rindler equation and horizon thermodynamics of stationary black holes](https://arxiv.org/abs/2602.16428)
*Diego Fernández-Silvestre,Alberto Guilabert,Pedro Bargueño,Juan A. Miralles*

Main category: gr-qc

TL;DR: 本文使用Newman-Penrose和Geroch-Held-Penrose形式体系，在视界热力学框架下重新表述Penrose-Rindler方程，得到包含旋转压力的类Smarr公式，并通过视界平均物质压力实现准局域化。


<details>
  <summary>Details</summary>
Motivation: 黑洞是研究引力与热力学相互作用的自然场所。虽然黑洞力学与热力学之间的联系已确立，但热力学变量的全面几何表述仍需进一步研究。

Method: 在视界热力学框架下考虑Newman-Penrose和Geroch-Held-Penrose形式体系。NP形式将视界条件重新表述为Penrose-Rindler方程，GHP形式进一步发展了该方程的几何重新解释。

Result: NP形式将Penrose-Rindler方程重新解释为包含旋转压力的视界压力平衡，恢复了稳态黑洞的类Smarr公式。GHP形式引入了视界平均物质压力及其共轭体积，实现了稳态黑洞类Smarr公式的准局域化。

Conclusion: 这种几何表述阐明了视界动力学与热力学之间的联系，为将黑洞热力学扩展到球对称之外提供了统一框架。

Abstract: Black holes are the natural arena for exploring the interplay between gravity and thermodynamics. Although the association between black hole mechanics and black hole thermodynamics is well-established, the comprehensive geometric formulation of thermodynamic variables deserves further investigation. In this work, both Newman-Penrose (NP) and Geroch-Held-Penrose (GHP) formalisms are considered within the framework of horizon thermodynamics. We show that the NP formalism reformulates the horizon condition as the Penrose-Rindler equation. In this context, a Smarr-like formula for stationary black holes is recovered from the Penrose-Rindler equation reinterpreted as a horizon equilibrium of pressures, which includes a pressure associated with the horizon rotation. A complete geometric reformulation of this reinterpretation of the Penrose-Rindler equation evaluated at the horizon is developed within the GHP formalism. The GHP approach further inspires the introduction of the horizon-averaged matter pressure and its conjugate volume, thereby enabling a quasi-local realization of the Smarr-like formula for stationary black holes. This geometric formulation clarifies the connection between horizon dynamics and thermodynamics and offers a unified setting for extending black hole thermodynamics beyond spherical symmetry.

</details>


### [141] [General formalism, classification, and demystification of the current warp-drive spacetimes](https://arxiv.org/abs/2602.16495)
*Hamed Barzegar,Thomas Buchert,Quentin Vigneron*

Main category: gr-qc

TL;DR: 对曲速驱动时空模型进行批判性分析，基于广义相对论框架进行分类，揭示文献中的误解和错误，证明新的"不可行"定理，表明曲速驱动模型在物理上难以实现。


<details>
  <summary>Details</summary>
Motivation: 曲速驱动时空模型在科幻和理论物理中备受关注，但文献中存在许多误解和错误，导致对这类模型物理可行性的错误主张。本文旨在系统分析这些模型，澄清误解，并提供严格的广义相对论框架下的评估。

Method: 1. 在广义相对论框架下对曲速驱动时空模型进行分类；2. 为每类模型提供一般形式化描述；3. 识别和纠正文献中的误解、误解和错误；4. 证明新的"不可行"定理；5. 正确应用广义相对论原理重新评估这些模型。

Result: 1. 建立了曲速驱动模型的分类体系；2. 揭示了支持这些模型物理可行性的文献中的多个错误；3. 证明了几个新的"不可行"定理；4. 表明当正确应用广义相对论原理时，大多数关于物理曲速驱动的主张需要重新评估；5. 曲速驱动模型的可行性不仅因为能量条件违反而受到挑战，还存在更深层次的理论困难。

Conclusion: 曲速驱动模型在广义相对论框架下的物理可行性极低。文献中支持这些模型的主张大多基于误解和错误应用。即使不考虑能量条件违反问题，这些模型的理论基础也存在严重缺陷，难以在物理上实现。

Abstract: We critically examine proposals for the so-called warp-drive spacetimes and classify these models based on their various restrictions within the framework of General Relativity. We then provide a summary of general formalism for each class, and in the process, we highlight some misconceptions, misunderstandings, and errors in the literature that have been used to support claims about the physicality and feasibility of these models. On the way, we prove several new no-go theorems. Our analysis shows that when the principles of General Relativity are applied correctly, most claims regarding physical warp drives must be reassessed, and it becomes highly challenging to justify or support the viability of such models, not merely due to the violation of energy conditions.

</details>


### [142] [Testing non-circular black hole spacetime with X-ray reflection](https://arxiv.org/abs/2602.16562)
*Leda Gao,Swarnim Shashank,Cosimo Bambi*

Main category: gr-qc

TL;DR: 使用X射线反射光谱测试黑洞周围的非圆形时空度量，应用于EXO 1846-031黑洞双星系统，结果与Kerr黑洞假设一致。


<details>
  <summary>Details</summary>
Motivation: 大多数广义相对论测试假设黑洞时空是圆形的（如Kerr解），但许多修正引力理论和非真空广义相对论解预测了非圆形度量的存在。需要开发方法来测试这种非圆形性。

Method: 基于局域性原理构建非圆形度量，在视界穿透（ingoing Kerr）坐标中实现相对论性光线追踪代码来精确模拟反射光谱，应用于EXO 1846-031的NuSTAR高质量光谱数据。

Result: 发现EXO 1846-031具有高倾角（约76°）和近极端自旋参数（约0.98）。虽然参数空间存在全局最小值表明非零形变（约0.12），但99%置信区间完全包含Kerr极限（形变为0）。

Conclusion: 当前EXO 1846-031的X射线反射数据与Kerr假设一致。这项工作证明了使用X射线反射光谱约束非圆形度量的可行性，并为未来测试建立了框架。

Abstract: X-ray reflection spectroscopy is a powerful tool for testing the Kerr hypothesis and probing the strong gravity regime around accreting black holes. Most tests of General Relativity (GR) assume that the spacetime around a black hole is circular, meaning the metric possesses a specific symmetry structure common to the Kerr solution. However, deviations from circularity are predicted by various modified gravity theories and non-vacuum General Relativity solutions. In this work, we test a specific non-circular metric constructed based on a locality principle, where the deviation from the Kerr spacetime is driven by the local spacetime curvature. To accurately model the reflection spectrum in this background, we implement a relativistic ray-tracing code in horizon-penetrating (ingoing Kerr) coordinates, which are favored for their ability to avoid introducing curvature singularities at the horizon in non-circular spacetimes. We apply this model to the high-quality \textit{NuSTAR} spectrum of the Galactic black hole binary EXO 1846--031. Our spectral analysis reveals a source with a high inclination angle ($ι\approx 76^{\circ}$) and a near-extremal spin parameter ($a_* \approx 0.98$). While we identify a global minimum in the parameter space suggesting a non-zero deformation ($\ell_{\mathrm{NP}} \approx 0.12$), the 99\% confidence interval fully encompasses the Kerr limit ($\ell_{\mathrm{NP}}=0$). We conclude that the current X-ray reflection data for EXO 1846--031 are consistent with the Kerr hypothesis. This work demonstrates the feasibility of using X-ray reflection spectroscopy to constrain non-circular metrics and establishes a framework for future tests.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [143] [Development of a single-parameter spring-dashpot rolling friction model for coarse-grained DEM](https://arxiv.org/abs/2602.15887)
*Putri Mustika Widartiningsih,Yoshiharu Tsugeno,Toshiki Imatani,Yuki Tsunazawa,Mikio Sakai*

Main category: physics.comp-ph

TL;DR: 提出一种新的弹簧-阻尼器型滚动摩擦模型，将参数简化为单一物理量——临界滚动角，简化了非球形颗粒DEM模拟的校准过程。


<details>
  <summary>Details</summary>
Motivation: 非球形颗粒的DEM模拟面临接触检测和旋转动力学复杂、大规模计算困难的问题。现有弹簧-阻尼器型滚动摩擦模型需要多个经验参数，校准过程相互依赖，增加了实验工作量、参数模糊性和应用不确定性。

Method: 提出新的弹簧-阻尼器型滚动摩擦模型，将参数集简化为单一物理量——临界滚动角。该参数基于理论推导，表征颗粒接触处从静态到滚动运动的转变。模型进一步集成到粗粒化DEM框架中，适用于大规模应用。

Result: 稳定性分析表明，该模型能使颗粒达到物理一致的平衡状态，无虚假旋转振荡。通过DEM-CFD模拟焚烧炉系统的验证，证实该方法能成功再现原始颗粒系统的宏观行为。

Conclusion: 该研究提出的单参数滚动摩擦模型简化了实现和校准过程，增强了DEM在涉及非球形颗粒的工业规模模拟中的适用性。

Abstract: Simulating granular materials composed of non-spherical particles remains a major challenge in discrete element method (DEM) simulations due to the complexity of contact detection and rotational dynamics, rendering large-scale simulations computationally prohibitive. To address this limitation, rolling friction is commonly introduced as an approximation to account for particle shape effects by applying a resistive torque to spherical particles. Among existing rolling friction formulations, the spring-dashpot (S-D) type model is widely recognized for its numerical stability and realistic representation of rolling resistance. However, conventional S-D models require multiple empirical parameters that must be calibrated in an interdependent manner, leading to increased experimental effort, parameter ambiguity, and uncertainty in practical applications. To overcome these issues, this study proposes a new S-D type rolling friction model that reduces the parameter set to a single physically meaningful quantity: the critical rolling angle. Derived from theoretical considerations, this parameter characterizes the transition from static to rolling motion at particle contacts. The use of a single parameter simplifies implementation and eliminates the need for extensive calibration. Stability analysis demonstrates that the proposed model allows particles to reach a physically consistent equilibrium state without spurious rotational oscillations. For large-scale applications, the model is further integrated into a coarse-grained DEM framework. Validation using DEM-CFD simulations of an incinerator system confirms that the proposed approach successfully reproduces the macroscopic behavior of the original particle system. Overall, this study enhances the applicability of DEM for industrial-scale simulations involving non-spherical particles.

</details>


### [144] [Surrogate Modeling for Neutron Transport: A Neural Operator Approach](https://arxiv.org/abs/2602.15890)
*Md Hossain Sahadath,Qiyun Cheng,Shaowu Pan,Wei Ji*

Main category: physics.comp-ph

TL;DR: 该研究提出了一种基于神经算子的中子输运计算代理建模框架，使用DeepONet和FNO两种架构学习从各向异性中子源到角通量的映射，在S_N特征值求解器中实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 传统中子输运计算（如S_N方法）计算成本高昂，限制了实时数字孪生应用和设计优化中的重复评估。需要开发高效准确的代理模型来加速计算。

Method: 使用DeepONet和FNO两种神经算子架构，在一维平板几何中训练固定源问题模型，学习从各向异性中子源Q(x,μ)到角通量ψ(x,μ)的映射。针对三种散射比（c=0.1,0.5,1.0）分别训练模型，覆盖吸收主导、中等和散射主导的不同输运机制。

Result: FNO通常获得更高的预测精度，而DeepONet计算效率更高。两种模型都实现了显著加速，散射比增加时加速效果更明显，运行时间不到传统S_N求解器的0.3%。在S_N特征值求解器中，两种神经算子求解器都能复现参考特征值，DeepONet偏差达135 pcm，FNO偏差达112 pcm，在较细网格上运行时间减少到S_N求解器的<0.1%。

Conclusion: 神经算子框架作为中子输运的准确、高效且可推广的代理模型具有强大潜力，为实时数字孪生应用和设计优化等重复评估任务铺平了道路。

Abstract: This work introduces a neural operator based surrogate modeling framework for neutron transport computation. Two architectures, the Deep Operator Network (DeepONet) and the Fourier Neural Operator (FNO), were trained for fixed source problems to learn the mapping from anisotropic neutron sources, Q(x,μ), to the corresponding angular fluxes, ψ(x,μ), in a one-dimensional slab geometry. Three distinct models were trained for each neural operator, corresponding to different scattering ratios (c = 0.1, 0.5, & 1.0), providing insight into their performance across distinct transport regimes (absorption-dominated, moderate, and scattering-dominated). The models were subsequently evaluated on a wide range of previously unseen source configurations, demonstrating that FNO generally achieves higher predictive accuracy, while DeepONet offers greater computational efficiency. Both models offered significant speedups that become increasingly pronounced as the scattering ratio increases, requiring <0.3% of the runtime of a conventional S_N solver. The surrogate models were further incorporated into the S_N k-eigenvalue solver, replacing the computationally intensive transport sweep loop with a single forward pass. Across varying fission cross sections and spatial-angular grids, both neural operator solvers reproduced reference eigenvalues with deviations up to 135 pcm for DeepONet and 112 pcm for FNO, while reducing runtime to <0.1% of that of the S_N solver on relatively fine grids. These results demonstrate the strong potential of neural operator frameworks as accurate, efficient, and generalizable surrogates for neutron transport, paving the way for real-time digital twin applications and repeated evaluations, such as in design optimization.

</details>


### [145] [The Beauty of Mathematics in Helfrich's Biomembrane Theory](https://arxiv.org/abs/2602.16002)
*Tao Xu,Zhong-Can Ou-Yang*

Main category: physics.comp-ph

TL;DR: 这篇纪念Helfrich教授的综述文章探讨了生物膜形状问题，从软物质物理和液晶理论角度分析膜形态，发现圆柱、球体、环面等形状具有内在几何特征，与膜方程无关。


<details>
  <summary>Details</summary>
Motivation: 纪念膜液晶模型创始人Wolfgang Helfrich教授，并探讨生物膜形状形成的物理原理。生物膜不仅是被动屏障，而是受软物质物理原理支配的动态复杂材料。

Method: 从材料科学和液晶理论视角，应用Helfrich弹性模型解释红细胞双凹形状，扩展到多层系统，类比近晶液晶的焦锥结构、富勒烯和碳纳米管几何、肽组装的可逆转变。

Result: 发现圆柱、球体、环面、双凹圆盘和Delaunay曲面等形状形成一组，这是这些形状的内在几何特征，与生物膜方程无关。当膜压力、表面张力和弯曲模量满足特定条件时，生物膜会呈现这些形状。

Conclusion: 连续弹性理论在描述生物和合成系统中各种膜形态方面具有统一力量，展现了软物质物理在理解生物膜形状形成中的重要性。

Abstract: It is with great regret that Prof. Wolfgang Helfrich passed away on 28 September 2025 in Berlin. As the founder of the membrane liquid crystal model, Prof. Helfrich made outstanding contributions to membrane physics and liquid crystal display technology. This review article is written in his memory. Biomembranes, primarily composed of lipid bilayers, are not merely passive barriers but dynamic and complex materials whose shapes are governed by the principles of soft matter physics. This review explores the shape problem in biomembranes through the lens of material science and liquid crystal theory. Beginning with classical analogies to crystals and soap bubbles, it details the application of the Helfrich elastic model to explain the biconcave shape of red blood cells. The discussion extends to multi-layer systems, drawing parallels between the focal conic structures of smectic liquid crystals, the geometries of fullerenes and carbon nanotubes, and the reversible transitions in peptide assemblies. Furthermore, it examines icosahedral self-assemblies and shape formation in two-dimensional lipid monolayers at air/water interfaces. At the end of the paper, we find that the shapes such as cylinders, spheres, tori, bicocave discoids and Delaunay surfaces form a group. This result is merely an intrinsic geometric feature of these shapes and is independent of the biomembrane equation. When the pressure on the membrane, surface tension, and bending modules meet certain conditions, the biomembrane will take on these shapes. The review concludes by highlighting the unifying power of continuum elastic theories in describing a vast array of membrane morphologies across biological and synthetic systems.

</details>


### [146] [Multi-Objective Evolutionary Design of Molecules with Enhanced Nonlinear Optical Properties](https://arxiv.org/abs/2602.16044)
*Dominic Mashak,Jacob Schrum,S. A. Alexander*

Main category: physics.comp-ph

TL;DR: 比较多种进化算法用于非线性光学分子设计，NSGA-II在各项指标上表现最佳，但MOME在探索多样性方面更优


<details>
  <summary>Details</summary>
Motivation: 非线性光学材料在光子学、通信和激光技术中至关重要，但发现更好的NLO分子面临计算挑战，因为化学空间巨大且存在竞争性目标

Method: 使用SMILES字符串编码分子，通过量子化学计算评估性质，比较NSGA-II、MAP-Elites、MOME、单目标(μ+λ)进化算法和模拟退火算法

Result: NSGA-II在所有目标上获得高分，产生高质量分子；MOME在探索广泛可能性方面表现更好，获得更高的全局超体积和MOQD分数；每种方法都有优缺点，都产生了许多有前景的分子

Conclusion: 质量多样性方法在原子和键数定义的测量空间中维护档案，能够发现结构多样的分子，不同算法各有优势，为非线性光学分子设计提供了多种有效方法

Abstract: Nonlinear optical (NLO) materials are essential for many photonic, telecommunication, and laser technologies, yet discovering better NLO molecules is computationally challenging due to the vast chemical space and competing objectives. We compare evolutionary algorithms for molecular design, targeting four objectives: maximizing the ratio of first-to-second hyperpolarizability $(β/γ)$, optimizing HOMO-LUMO gap and linear polarizability to target ranges, and minimizing energy per atom. We encode molecules as SMILES strings and evaluate their properties using quantum-chemical calculations. We compare NSGA-II, MAP-Elites, MOME, a single-objective $(μ+λ)$ evolutionary algorithm, and simulated annealing. Quality diversity methods maintain archives across a measure space defined by atom and bond count, enabling the discovery of structurally diverse molecules. Our results demonstrate that NSGA-II consistently earns high scores in every objective, leading to high-quality molecules, but MOME does a better job exploring a wide range of possibilities, resulting in higher global hypervolume and MOQD scores. However, each method has strengths and weaknesses, and produced many promising molecules.

</details>


### [147] [Finding Molecules with Specific Properties: Simulated Annealing vs. Evolution](https://arxiv.org/abs/2602.16058)
*Dominic Mashak,S. A. Alexander*

Main category: physics.comp-ph

TL;DR: 比较模拟退火和进化算法在寻找具有大分子平均超极化率分子方面的能力，两种方法都使用SMILES字符串表示分子结构


<details>
  <summary>Details</summary>
Motivation: 分子平均超极化率是非线性光学材料的重要性质，需要高效的方法来寻找具有该性质的分子

Method: 使用模拟退火程序和进化算法，两种方法都采用SMILES字符串表示分子结构，这是一种化学家广泛使用的用短ASCII字符串描述分子结构的方法

Result: 两种优化方法的表现相当，都能有效寻找具有大分子平均超极化率的分子

Conclusion: 模拟退火和进化算法都可以用于解决化学家和材料科学家感兴趣的各种更现实的问题

Abstract: We compare the ability of a simulated annealing program and an evolutionary algorithm to find molecules with large molecular average hyperpolarizabilities. This property is an important component of nonlinear optical materials. Both optimization programs represent molecules as SMILES strings, a method that is widely used by chemists to describe molecular structure using short ASCII strings. Our results suggest that both approaches are comparable and can be used to solve a variety of more realistic problems of interest to chemists and material scientists.

</details>


### [148] [Inverse Engineering of Optical Constants in Photochromic Micron-Scale Hybrid Films](https://arxiv.org/abs/2602.16180)
*Bahrem Serhat Danis,Amin Tabatabaei Mohseni,Smagul Karazhanov,Esra Zayim*

Main category: physics.comp-ph

TL;DR: 提出数据驱动框架，从最小实验透射率测量中提取混合光致变色薄膜的有效光学常数，克服传统模拟的计算成本和分布差异问题


<details>
  <summary>Details</summary>
Motivation: 微米级光致变色混合薄膜在智能窗户、自适应光学等领域有广泛应用前景，但其理性设计受限于缺乏明确的光学常数。传统第一性原理电磁模拟计算成本高，且模拟与实验粒子分布存在差异

Method: 提出数据驱动框架，通过双态有效模型将复杂非均匀光致变色层近似为压缩均匀介质，用伪折射率和伪消光系数表征原始态和UV辐照态，通过系统优化实验数据确定波长依赖的伪光学常数和压缩比

Result: 通过优化氧化钨-聚乙烯吡咯烷酮混合薄膜的实验数据，确定了波长依赖的伪光学常数和压缩比，能够在测试厚度范围内准确预测光学调制性能

Conclusion: 该方法为工程化混合光致变色系统建立了框架，展示了数据驱动建模如何克服复杂纳米结构材料表征的局限性

Abstract: Photochromic materials enable dynamic optical modulation through reversible transitions between distinct absorption states, with broad potential for smart windows, adaptive optics, and reconfigurable photonic devices. Micron-scale photochromic hybrid films present a particularly attractive platform for these applications, combining straightforward preparation with substantial optical modulation and scalability for high-volume fabrication. However, rational design of such films remains fundamentally constrained by the absence of well-defined optical constants. Unlike homogeneous thin films, micron-scale hybrid photochromic materials comprise active particles dispersed non-uniformly within polymer matrices. Conventional first-principles electromagnetic simulations face substantial computational costs and discrepancies between simulated and experimental particle distributions. Here, we introduce a data-driven framework that extracts effective optical constants directly from minimal experimental transmittance measurements. Our dual-state effective model approximates the complex inhomogeneous photochromic layer as a compressed homogeneous medium characterized by pseudo-refractive indices and pseudo-extinction coefficients for both pristine and UV-irradiated states. Through systematic optimization against experimental data from tungsten oxide-polyvinylpyrrolidone hybrid films, we determine wavelength-dependent pseudo-optical constants and compression ratios that enable accurate prediction of optical modulation within the tested thickness range. Our methodology establishes a framework for engineering hybrid photochromic systems and demonstrates how data-driven modeling can overcome limitations in characterizing complex nanostructured materials.

</details>
