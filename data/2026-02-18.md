<div id=toc></div>

# Table of Contents

- [gr-qc](#gr-qc) [Total: 14]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [cs.LG](#cs.LG) [Total: 69]
- [quant-ph](#quant-ph) [Total: 38]


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [1] [May Negative Mass Objects exist in the sky?](https://arxiv.org/abs/2602.15058)
*Shin'ichi Nojiri,S. D. Odintsov*

Main category: gr-qc

TL;DR: 论文提出负质量天体可能存在的猜想，并证明在特定引力理论框架下它们可以作为标准引力方程的解存在，同时研究了光子和大质量粒子在负质量天体背景下的轨道运动。


<details>
  <summary>Details</summary>
Motivation: 探索负质量天体存在的可能性，挑战传统对负质量物体的"奇异"认知，研究其在标准引力理论框架下的理论基础和可观测性。

Method: 1. 在考虑致密正质量天体、宇宙学流体和负宇宙学常数的系统中求解标准引力方程；2. 在双标量理论和受弦理论启发的标量-爱因斯坦-高斯-博内引力理论中构造负质量天体的解；3. 研究光子和有质量粒子在负质量天体背景下的轨道运动。

Result: 1. 负质量天体可以作为标准引力方程的解存在；2. 正质量天体与负质量天体可以形成束缚系统，尽管正质量天体受到负质量天体的排斥力；3. 发现了零质量非平凡天体的性质；4. 提出了负质量天体可能质量范围的简单猜想。

Conclusion: 负质量天体可能存在于宇宙中，它们不像通常认为的那样奇异，可以在标准引力理论框架下作为方程解存在，并且可能通过观测被探测到，这为天体物理学开辟了新的研究方向。

Abstract: We conjecture the possibility of negative mass objects (NMOs) existing in the sky. It is shown that they may not be so exotic as usually expected. We show that NMOs appear as solutions of standard gravitational equations if we consider the system of a compact positive mass object, cosmological fluid and negative cosmological constant. We also construct models which generate such NMOs as solutions within the two-scalar theory and scalar-Einstein-Gauss-Bonnet gravity inspired by string theory. The orbits of the photon and massive particles are investigated in the background, where there is a negative mass object which realises a kind of effective anti-gravity. It is explicitly found that the bound system consisting of a positive mass object and a negative mass object can be formed in spite that a positive mass object suffers the repulsive force from the NMO. The possibility that such exotic objects might be observed is discussed. A simple conjecture about their possible masses is made, too. As an even more exotic object, we consider a non-trivial object with vanishing mass and investigate its properties.

</details>


### [2] [Horizon-Brightened Acceleration Radiation and Optical Signatures of Generic Regular Black Holes from Nonlinear Electrodynamics](https://arxiv.org/abs/2602.15077)
*Uktamjon Uktamov,Ali Övgün,Reggie C. Pantig,Bobomurat Ahmedov*

Main category: gr-qc

TL;DR: 本文研究了由非线性电动力学产生的规则黑洞的视界增亮加速辐射（HBAR）和光学特征，包括Bardeen-like和Hayward-like黑洞，结合EHT和GRAVITY观测数据约束模型参数，并建立了HBAR谱的维恩位移定律。


<details>
  <summary>Details</summary>
Motivation: 研究非线性电动力学产生的规则黑洞的量子辐射和光学特征，探索黑洞视界附近的量子效应与观测数据之间的联系，为理解规则黑洞的量子性质和热力学提供新视角。

Method: 1) 分析静态球对称非奇异时空的视界结构和热力学性质；2) 计算光子球位置和阴影大小等光学可观测量；3) 利用EHT和GRAVITY对SgrA*和M87*的角尺寸约束进行MCMC分析；4) 发展近视界约化理论，建立Lindblad主方程描述辐射场；5) 推导HBAR熵-能关系和维恩位移定律。

Result: 1) 确定了模型参数的可容许范围，量化了黑洞质量与非线性电动力学参数之间的简并性；2) 发现主导探测器响应的扇区具有共形行为，产生由视界温度控制的热激发谱；3) 建立了与克劳修斯型第一定律一致的HBAR熵-能关系；4) 提出了HBAR谱的维恩位移定律，将峰值波长与视界热力学联系起来。

Conclusion: 该研究建立了非线性电动力学、规则性和近视界量子辐射之间的观测联系，为通过光学观测和量子辐射特征约束规则黑洞模型提供了理论框架，并揭示了视界热力学与HBAR谱之间的深刻联系。

Abstract: We investigate horizon-brightened acceleration radiation (HBAR) and optical signatures for a broad class of regular black holes sourced by nonlinear electrodynamics. The spacetimes considered are static, spherically symmetric, and nonsingular, and they include Bardeen-like, and Hayward-like regular black-hole limits as spacial cases. We characterize the horizon structure and thermodynamics properties, and we compute key optical observables by determining the photon-sphere location and the corresponding shadow size as seen by distant observers, including controlled perturbative limits and full numerical solutions. Using angular-size constraints for SgrA* and M87* from the Event Horizon Telescope and the GRAVITY collaboration, we perform a Markov Chain Monte Carlo analysis to infer the admissible parameter ranges of the model and to quantify degeneracies among the black-hole mass and nonlinear-electrodynimcs parameters. On the quantum side, we develop the near-horizon reduction relevant for HBAR, showing that the dominant sector governing the detector response exhibits conformal behavior and leads to a thermal excitation spectrum governed by the horizon temperature. We formulate a Lindblad master-equation description of the radiation field, identify the thermal steady state, and derive an HBAR entropy-energy relation consistent with a Clausius-type first law. Finally, we establish a Wien-type displacement law for the HBAR spectrum, expressing the peak wavelength in terms of the horizon thermodynamics, thereby providing an additional observable link between nonlinear electrodynamics, regularity, and near-horizon quantum radiation.

</details>


### [3] [Black-hole thermodynamics in doubly special relativity: local-frame MDRs and rainbow metrics](https://arxiv.org/abs/2602.15216)
*Abdelmalek Boumali*

Main category: gr-qc

TL;DR: 该论文研究了双狭义相对论（DSR）在弯曲时空中的扩展，比较了两种不同的实现方法，发现当使用相同的变形能量尺度时，两种方法得到相同的霍金温度修正。


<details>
  <summary>Details</summary>
Motivation: 双狭义相对论（DSR）通过引入普朗克能量作为第二个不变尺度来修正狭义相对论运动学，但将其扩展到弯曲时空面临挑战，因为变形能量的模糊定义可能导致重新引入优先参考系。

Method: 回顾了三种常见的弯曲时空扩展方法：局部正交标架中的修正色散关系、相空间/哈密顿几何与相对局域性、彩虹度规。使用静态球对称黑洞的热力学，比较了两种实现：(A) 能量无关背景与局部标架MDR，(B) 能量依赖的彩虹度规。

Result: 当使用相同的变形能量尺度E_*时，两种方法得到完全相同的霍金温度修正：T(E_*) = T_0 * g(E_*/E_Pl)/f(E_*/E_Pl)，其中T_0是经典霍金温度。对于Amelino-Camelia型MDR，温度修正为T(E_*) ≃ T_0(1 - η/2 * E_*/E_Pl)；对于Magueijo-Smolin不变式，温度不变。

Conclusion: 文献中的差异主要源于对E_*的不同选择（无穷远能量vs局部标架能量）。对于宏观黑洞，修正被T_0/E_Pl抑制，只有在接近普朗克尺度时才变得相关，而那时全量子引力效应将占主导地位。

Abstract: Doubly Special Relativity (DSR) deforms special-relativistic kinematics while preserving the relativity principle by introducing a second invariant scale, typically the Planck energy $E_{\rm Pl}$. Extending DSR-inspired modified dispersion relations (MDRs) to curved spacetimes is challenging, as ambiguous definitions of the deformation energy risk reintroducing preferred frames.
  We review three common extensions beyond flat spacetime: (i) MDRs in local orthonormal frames on fixed backgrounds, (ii) phase-space/Hamiltonian geometry with relative locality, and (iii) rainbow metrics. Using black-hole thermodynamics for static spherically symmetric horizons, we compare two implementations: (A) energy-independent background with local-frame MDR, and (B) energy-dependent rainbow metric.
  When the same prescription is used for the deformation energy scale $E_\star$, both approaches yield identical Hawking temperatures: \begin{equation} T(E_\star)=T_0\,\frac{g(E_\star/E_{\rm Pl})}{f(E_\star/E_{\rm Pl})}\,,\qquad T_0=\frac{κ_0}{2π}\,, \end{equation} where $κ_0$ is the classical surface gravity.
  This $g/f$ scaling holds for examples such as Amelino--Camelia-type MDRs (leading correction $\propto E p^2/E_{\rm Pl}$, giving $T(E_\star)\simeq T_0(1-\fracη{2}E_\star/E_{\rm Pl})$ for $η>0$) and the Magueijo--Smolin invariant ($f=g$, so $T(E_\star)=T_0$).
  Further DSR effects on evaporation (thresholds, phase space, greybody factors, composition laws) are discussed. Discrepancies in the literature arise mainly from different choices of $E_\star$ (energy at infinity vs.\ local frame). For macroscopic black holes, corrections are suppressed by $T_0/E_{\rm Pl}$ and become relevant only near the Planck regime, where full quantum gravity dominates.

</details>


### [4] [Investigation of the gravitational dust collapse of the LQG-inspired effective asymmetric bounce model](https://arxiv.org/abs/2602.15227)
*Kristina Giesel,Hongguang Liu,Eric Rullit*

Main category: gr-qc

TL;DR: 本文研究了有效圈量子引力启发的非对称反弹模型中引力尘埃塌缩，发现中心奇点被解决，但在反弹相中真空区域会出现壳交叉奇点，且反弹前后动力学存在定性差异。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注对称反弹模型或仅限于均匀尘埃配置的非对称反弹模型。本文旨在扩展研究范围，探索边际束缚情况下具有非对称反弹的有效圈量子引力启发模型中的引力尘埃塌缩现象。

Method: 采用解析和数值研究相结合的方法，特别关注奇点解决和陷获面形成。分析非对称反弹模型在尘埃塌缩过程中的表现，并与对称反弹模型进行对比。

Result: 1. 塌缩尘埃云内部中心曲率奇点被解决；2. 反弹相中在聚合真空区域出现壳交叉奇点，曲率标量呈现预期的幂律行为；3. 反弹前相中内、外视界形成存在临界质量阈值；4. 反弹后相中内视界形成没有类似的临界质量限制。

Conclusion: 非对称反弹模型在解决中心奇点的同时，在真空区域引入了新的奇点类型。反弹前后动力学存在显著定性差异，特别是临界质量限制仅出现在反弹前相中，这为圈量子引力启发的引力塌缩模型提供了新的物理见解。

Abstract: We investigate gravitational dust collapse within an effective loop quantum gravity (LQG)-inspired model exhibiting an asymmetric bounce in the marginally bound case. This work extends previous studies, which have predominantly focused on models with either symmetric bounces or asymmetric bounces restricted to homogeneous dust configurations. Our analysis emphasises the phenomenological implications of the model through a combination of analytical and numerical investigations, with particular attention to singularity resolution and the formation of trapped surfaces. As in symmetric bounce models, the central curvature singularity inside the collapsing dust cloud is resolved. However, in contrast to the symmetric case, we find that a singularity emerges in the polymerised vacuum region during the bounce phase. This singularity can be identified as a shell-crossing singularity and exhibits the expected power-law behaviour of curvature scalars. Furthermore, likewise to the symmetric bounce models, we find a critical mass threshold governing the formation of inner and outer horizons in the pre-bounce phase. No analogous critical mass restriction arises for the formation of the inner horizon in the post-bounce phase, highlighting a qualitative difference between the pre- and post-bounce dynamics.

</details>


### [5] [Particle production, absorption, scattering, and geodesics in a Schwarzschild--Hernquist black hole](https://arxiv.org/abs/2602.15420)
*N. Heidari,A. A. Araújo Filho,P. H. M. Barros*

Main category: gr-qc

TL;DR: 研究嵌入Hernquist暗物质晕中的史瓦西黑洞的量子与经典特征，包括霍金辐射、粒子产生、波散射和测地线运动。


<details>
  <summary>Details</summary>
Motivation: 探索暗物质晕如何影响黑洞的量子效应（如霍金辐射）和经典特征（如波散射和粒子运动），理解暗物质参数对黑洞物理的修正。

Method: 使用半经典技术分析玻色子和费米子场的粒子产生；通过Bogoliubov变换和隧穿方法推导霍金辐射；采用分波分析计算质量标量波的吸收和散射截面；研究零测地线和类时测地线描述光传播和粒子运动。

Result: 暗物质参数（尺度半径和密度）会抑制粒子产生，修改有效温度、发射谱和蒸发时间；散射截面和相移受暗物质晕影响；测地线运动在暗物质存在下发生显著变化。

Conclusion: 暗物质晕显著改变黑洞的量子辐射和经典动力学特征，为通过观测黑洞特性探测暗物质提供了理论框架。

Abstract: We investigate quantum and classical signatures of a Schwarzschild black hole embedded in a Hernquist dark matter halo. Starting from the exact spherically symmetric solution describing this composite system, we analyze particle production for both bosonic and fermionic fields using semiclassical techniques. Hawking radiation is derived through Bogoliubov transformations and independently via the tunneling method with energy conservation, allowing us to identify the effective temperature, emission spectrum, and the role of dark matter parameters in suppressing particle creation. The evaporation process is examined in the high-frequency regime, leading to modified evaporation times and emission rates relative to the vacuum Schwarzschild case. We further study absorption and scattering of massless scalar waves employing a partial-wave analysis, computing phase shifts, partial and total cross sections, and assessing the impact of the Hernquist scale radius and density on these observables. Finally, null and timelike geodesics are explored to characterize light propagation and particle motion in the presence of the dark matter halo.

</details>


### [6] [Static black holes in an external uniform electromagnetic field: Reissner-Nordstrom accelerating in Bertotti-Robinson](https://arxiv.org/abs/2602.15462)
*Hryhorii Ovcharenko,Jiri Podolsky*

Main category: gr-qc

TL;DR: 该论文详细分析了非扭曲的D型黑洞在非对齐电磁场中的子情况，揭示了这类精确解可分为两个主要子类：要么是未带电的Schwarzschild或C度规在Bertotti-Robinson时空中的解，要么是带电的Reissner-Nordstrom黑洞在BR电磁场中加速的解。


<details>
  <summary>Details</summary>
Motivation: 研究非对齐电磁场中D型黑洞的非扭曲子情况，旨在深入理解这类复杂时空结构的物理本质，特别是外部BR电磁场与黑洞自身电荷产生的电磁场之间的相互作用关系。

Method: 通过对参数r0的分析，将解分为两个主要子类：当r0=0时，电磁场完全由外部BR场决定；当r0≠0时，电磁场由外部BR场和黑洞自身电荷产生的场共同决定。通过重新参数化和详细分析，建立了与已知解的联系。

Result: 成功将这类精确解系统分类为两个物理上可解释的子类：Schwarzschild/C度规在BR宇宙中的解，以及Reissner-Nordstrom黑洞在BR时空中加速的解。揭示了参数r0在区分这两种情况中的关键作用，并详细研究了各种极限情况和微妙之处。

Conclusion: 该研究为理解非对齐电磁场中D型黑洞的非扭曲解提供了清晰的物理图像和分类框架，建立了与先前已知解的联系，揭示了这类复杂时空结构的本质特征和物理意义。

Abstract: We provide a detailed analysis of the non-twisting subcase of the large class of type D black holes with a non-aligned electromagnetic field, presented recently in [H. Ovcharenko and J. Podolsky, Phys. Rev. D 112 (2025) 064076]. We show that such exact solutions split into two main subclasses that (after a suitable re-parametrization) can be interpreted as either the uncharged Schwarzschild or C-metric in the external Bertotti-Robinson (BR) spacetime with geometry ${\mathrm{AdS}_2\times\mathrm{S}_2}$, or as the charged Reissner-Nordstrom black hole accelerating in the external BR electromagnetic field. The distinction between these two subclasses is determined by the parameter $r_0$ that encodes relations between the external Maxwell field (given by the non-aligned components of the Faraday tensor ${Φ_0=Φ_2}$) and the Maxwell field created by the charge of the black hole (given by the aligned component $Φ_1$). Namely, if ${r_0=0}$ then the electromagnetic field is fully determined by ${Φ_0=Φ_2}$, and one gets the C-metric in the BR universe (including also the non-accelerating Schwarzschild-BR black hole). But if ${r_0\neq 0}$ then the electromagnetic field is independently determined by both the external BR field and the field of a black hole itself, and this can be interpreted as the Reissner-Nordstrom black hole accelerating in the Bertotti-Robinson spacetime. Even though such an interpretation of the spacetime family is quite simple, it contains a lot of subtleties (e.g. the no-charge limit of the RN-BR spacetime, the non-trivial dependence on the signs of the mass and charge of a black hole, extreme black holes, and others) which we carefully investigate in this work. We also show the explicit relation to solutions previously found by Van den Bergh and Carminati, and we discuss the connection to the Alekseev-Garcia and Alexeev solutions.

</details>


### [7] [A fresh look at boundary terms in Einstein-Hilbert gravity via an initial value variational principle](https://arxiv.org/abs/2602.15469)
*Songmin Ha,Alexander Rothkopf*

Main category: gr-qc

TL;DR: 论文提出了爱因斯坦-希尔伯特引力的变分表述作为初值问题，通过构建Schwinger-Keldysh-Galley作用量，包括边界项的仔细处理，使引力变分原理成为适定问题。


<details>
  <summary>Details</summary>
Motivation: 广义相对论的核心是时空的动力学性质，通常表示为初值问题。然而，经典爱因斯坦-希尔伯特引力的变分表述作为初值问题需要仔细处理边界项，以确保变分原理的适定性。

Method: 构建爱因斯坦-希尔伯特引力的Schwinger-Keldysh-Galley作用量，包括自由度加倍和边界项的仔细处理。该方法不依赖于叶状结构，作用量自然分解为给出爱因斯坦方程的体项和与守恒量相关的边界项。

Result: 发现由于只需要在边界上指定平凡的连接条件，引力作为初值问题的变分作用原理变得适定，无需添加额外的边界项。SKG方法为直接从作用量求解时空度规提供了新途径。

Conclusion: SKG方法为引力理论提供了新颖且互补的途径，可以直接从作用量求解时空度规，绕过控制方程，使引力变分原理作为初值问题变得适定。

Abstract: A key tenet of general relativity is the dynamical nature of space-time, ideally represented as an initial value problem. Here we explore the variational formulation of classical Einstein-Hilbert gravity as initial value problem by constructing its Schwinger-Keldysh-Galley (SKG) action, including a careful treatment of boundary terms. The construction is based on a doubling of degrees of freedom and independent of a foliation. The action naturally decomposes into a bulk term furnishing Einstein's equations and a boundary term, which is related to conserved quantities, such as the Komar mass. We find that since only trivial connecting conditions must be specified on boundaries, the variational action principle for gravity as an initial value problem is rendered well-posed without the need to add additional boundary terms. The SKG approach to gravity offers a novel and complementary avenue to solve for the metric of spacetime directly from the action, bypassing the governing equations.

</details>


### [8] [On the Limitations of Karmarkar's Condition in Static, Conformally Flat Spacetimes](https://arxiv.org/abs/2602.15486)
*Samstuti Chanda,Ranjan Sharma,Sunil D. Maharaj*

Main category: gr-qc

TL;DR: 论文研究了同时满足Karmarkar条件和Weyl张量为零的静态球对称时空精确解，发现这导致共形平坦的嵌入类I解，即Schwarzschild内解和de Sitter解。


<details>
  <summary>Details</summary>
Motivation: 研究同时施加两个基本几何约束（Karmarkar条件和Weyl张量为零）时产生的精确解，探索这些几何条件如何限制时空结构和物质组成。

Method: 在静态球对称时空中同时施加Karmarkar条件和共形平坦条件（Weyl张量为零），推导由此产生的精确解，并分析其物理性质。

Result: 得到两个已知解：Schwarzschild内解（描述不可压缩流体球）和de Sitter解（真空能主导配置）。压力各向异性和"复杂度因子"在这些条件下恒为零。

Conclusion: 这两个几何约束足以唯一确定背景时空，因此在共形平坦时空中，Karmarkar条件可能不适合构建现实的恒星模型，除非引入其他因素如时间依赖的度规势。

Abstract: For a static and spherically symmetric spacetime, we investigate the class of exact solutions that arise when two fundamental geometric constraints are imposed simultaneously: the Karmarkar's condition and the vanishing of the Weyl tensor. These conditions restrict the curvature in such a way that the spacetime becomes conformally flat and belongs to the family of embedding class-I solutions. Even though the subsequent solutions namely, the Schwarzschild interior solution and the de Sitter solution are well known, the novelty of our presentation is that these solutions are shown to be a direct consequence of the imposed geometric constraints. The physical matter composition becomes highly constrained by the associated geometry under such conditions. The Schwarzschild interior solution describes the spacetime of an incompressible fluid sphere while the de Sitter solution corresponds to a vacuum energy dominated configuration. Interestingly, pressure anisotropy as well as `complexity factor' vanish identically once the Karmarkar's condition and the conformal flatness conditions are applied simultaneously. As these two geometric constraints alone are sufficient to determine the background spacetime uniquely, Karmarkar's condition might not be a suitable method for the development of realistic stellar models in a conformally flat spacetime unless one invokes other factors into consideration such as time-dependent metric potentials.

</details>


### [9] [Displacement memory in regular black hole spacetimes](https://arxiv.org/abs/2602.15523)
*Ritwik Acharyya,Sayan Kar*

Main category: gr-qc

TL;DR: 研究正则黑洞时空中波脉冲引起的位移记忆效应，通过测地线分离和测地线偏差分析，发现位移记忆效应依赖于正则化参数g和脉冲高度，且正则黑洞与奇异黑洞的位移记忆幅度存在明显差异。


<details>
  <summary>Details</summary>
Motivation: 研究波脉冲在正则黑洞时空中引起的位移记忆效应，探索正则黑洞与奇异黑洞在位移记忆效应方面的差异，理解正则化参数对记忆效应的影响。

Method: 使用Bondi-Sachs型线元中的H(u)函数建模波脉冲，选择sech-squared脉冲轮廓，通过数值方法研究平坦背景和黑洞背景下的测地线分离和测地线偏差，重点关注远离视界的区域。

Result: 发现了明显的位移记忆效应，其依赖于正则化参数g和脉冲高度；不同正则黑洞类型间的净位移记忆随参数变化而变化；正则黑洞与奇异黑洞在大u值处的位移记忆幅度存在明显差异。

Conclusion: 正则黑洞时空中存在独特的位移记忆效应，该效应受正则化参数和脉冲特性的影响，且与奇异黑洞的位移记忆效应有显著区别，这为区分正则黑洞和奇异黑洞提供了可能的观测特征。

Abstract: Displacement memory, induced by a wave pulse in a regular black hole spacetime, is studied using geodesic (timelike) separation and geodesic deviation. The presence of the wave pulse in such a black hole is modeled via a function $H(u)$ appearing in a restricted version of a generic Bondi-Sachs type line element. Choosing a sech-squared profile for $H(u)$, we first study (numerically) geodesic separation and geodesic deviation in a flat background. Thereafter, similar investigations are carried out in the presence of the black hole, but in regions far away from the vicinity of the horizon. Our results suggest the presence of a distinct displacement memory effect, which depends on the value of the regularisation parameter $g$ as well as the pulse height. Between different types of regular black holes, one notices parameter-dependent changes in the net displacement memory. Further, a clear difference in the magnitude of displacement memory (at large $u$) in regular and singular black holes is also visible in our numerical results.

</details>


### [10] [Some phenomenological aspects of a quantum-corrected Reissner-Nordström black hole: quasi-periodic oscillations, scalar perturbations and thermal fluctuations](https://arxiv.org/abs/2602.15551)
*Faizuddin Ahmed,Ahmad Al-Badawi,Mohsen Fathi*

Main category: gr-qc

TL;DR: 该论文研究了具有量子修正的协变Reissner-Nordström黑洞的多种现象学特征，包括轨道频率分析、准周期振荡约束、标量扰动、灰体因子、热涨落对熵的影响等，发现量子修正参数对时空的动力学和热力学性质产生可观测影响。


<details>
  <summary>Details</summary>
Motivation: 研究量子修正的Reissner-Nordström黑洞的现象学特征，探索量子修正参数如何影响黑洞的动力学和热力学性质，并通过观测数据约束这些参数。

Method: 1) 推导中性测试粒子的基本轨道和环向频率；2) 使用不同质量黑洞的QPO观测数据进行贝叶斯参数估计和MCMC分析；3) 推导标量扰动的薛定谔型径向方程和有效势；4) 计算高频区域的灰体因子和能量发射率；5) 分析热涨落对黑洞熵的影响。

Result: 量子修正显著影响QPO半径位置和与ISCO的分离；参数Q和ζ影响扰动势和时空稳定性；量子修正改变吸收概率和辐射谱；小黑洞的热涨落导致熵的对数修正，而大黑洞恢复标准热力学行为。

Conclusion: 量子修正参数在时空的动力学和热力学性质上留下可观测印记，可通过QPO观测进行约束，为量子引力效应提供了潜在的观测检验途径。

Abstract: In this work, we investigate several phenomenological aspects of a covariant quantum-corrected Reissner-Nordström black hole characterized by the mass $M$, electric charge $Q$, and the quantum correction parameter $ζ$. We first study the motion of neutral test particles and derive the fundamental orbital and epicyclic frequencies, which are then employed to analyze different quasi-periodic oscillation (QPO) models. Using observational QPO data from stellar-mass, intermediate-mass, and supermassive black hole candidates, we perform a Bayesian parameter estimation through a Markov Chain Monte Carlo (MCMC) analysis and obtain constraints on the black hole parameters. The results show that the presence of the quantum correction significantly affects the location of the QPO radii and the separation between the QPO orbit and the ISCO. We then examine the scalar perturbations by deriving the Schrödinger-like radial equation and the corresponding effective potential. The influence of the parameters $Q$ and $ζ$ on the perturbation potential and stability of the spacetime is discussed. Furthermore, we compute the greybody factor and the energy emission rate in the high-frequency (geometric-optics) regime, showing how the quantum correction modifies the absorption probability and radiation spectrum. Finally, we study the effect of thermal fluctuations on the black hole entropy and obtain the logarithmic corrections to the Bekenstein-Hawking area law. We show that these corrections become important for small black holes, while for large horizon radius the standard thermodynamic behavior is recovered. Our analysis demonstrates that the quantum correction parameter leaves observable imprints on both dynamical and thermodynamical properties of the spacetime and can be constrained through QPO observations.

</details>


### [11] [ModMax-AdS Black Hole with Global Monopole as Source in Kalb-Ramond Gravity](https://arxiv.org/abs/2602.15570)
*Faizuddin Ahmed,Ahmad Al-Badawi,Edilberto O. Silva*

Main category: gr-qc

TL;DR: 研究Kalb-Ramond引力中带全局单极子的球形对称ModMax-AdS黑洞的热力学性质，包括热力学量、临界性、反转温度、霍金辐射稀疏性和光学特性。


<details>
  <summary>Details</summary>
Motivation: 探索Kalb-Ramond引力框架下，带有全局单极子的ModMax-AdS黑洞的热力学行为，理解几何参数如何影响黑洞的热力学性质和光学特征。

Method: 推导霍金温度、吉布斯自由能、比热容等关键热力学量，验证热力学第一定律和Smarr公式，分析临界点、反转温度，研究霍金辐射稀疏性和熵修正，最后分析光子球和阴影半径等光学特性。

Result: 几何参数显著影响黑洞的热力学性质：修改了最小反转温度，影响熵修正，并改变了光子球和阴影半径等光学特征。热力学第一定律和Smarr公式在该系统中成立。

Conclusion: Kalb-Ramond引力中的ModMax-AdS黑洞具有丰富的热力学行为，几何参数对热力学临界性、反转温度、熵修正和光学特性都有重要影响，为理解这类黑洞的物理性质提供了新见解。

Abstract: In this work, we investigate in detail the thermodynamic properties of a spherically symmetric ModMax-AdS black hole sourced by a global monopole within the Kalb-Ramond gravity. We derive the key thermodynamic quantities, including the Hawking temperature, Gibbs free energy, and specific heat capacity, and analyze how the geometric parameters influence these physical quantities. The first law of thermodynamics and the corresponding Smarr formula are explicitly verified. Furthermore, we study the thermodynamic criticality of the system by deriving the critical points and examining the effects of the space-time geometric parameters. We also obtain the inversion temperature and demonstrate that the minimum inversion temperature is modified by the space-time parameters. In addition, the sparsity of Hawking radiation and thermal fluctuations of the system are investigated, highlighting the effects of the parameters on the entropy corrections. Finally, we analyze the optical properties of the black hole, in particular the photon sphere and shadow radius, showing how these parameters influence these features.

</details>


### [12] [Periodic orbits and gravitational waveforms of spinning particles in nonlocal Gravity](https://arxiv.org/abs/2602.15609)
*Moisés Bravo-Gaete,Jianhui Lin,Yunlong Liu,Xiangdong Zhang*

Main category: gr-qc

TL;DR: 研究在Deser-Woodard非局部引力框架下，自旋测试粒子在静态球对称黑洞赤道面内周期轨道的动力学和引力波特征，发现非局部引力参数ζ和b对轨道动力学和引力波相位有显著影响，当b=2且ζ≈10⁻⁶时，与广义相对论的引力波形差异达到可观测区分阈值。


<details>
  <summary>Details</summary>
Motivation: 研究非局部引力理论（Deser-Woodard理论）下自旋测试粒子在黑洞周围的轨道动力学和引力波特征，探索通过引力波观测区分广义相对论和非局部引力的可能性。

Method: 基于Mathisson-Papapetrou-Dixon方程结合Tulczyjew自旋补充条件，推导自旋粒子在赤道面内的轨道动力学方程，施加类时约束排除超光速轨迹，分析非局部引力参数ζ和b对有效势和最小稳定圆轨道的影响，模拟极端质量比旋进系统的引力波波形。

Result: 非局部引力参数显著影响粒子动力学：ζ增加导致引力波相位延迟，b增加导致相位提前。当b=2且ζ≈10⁻⁶时，非局部引力黑洞与史瓦西黑洞的引力波形不匹配度达到可区分阈值（M=0.0125），为观测区分两种理论提供了依据。

Conclusion: Deser-Woodard非局部引力理论的自旋粒子轨道动力学和引力波特征与广义相对论存在可观测差异，通过分析极端质量比旋进系统的引力波波形，有望在观测上区分这两种引力理论，为非局部引力的实验验证提供了新途径。

Abstract: In this paper, we investigate the dynamics and gravitational-wave signatures of periodic orbits of spinning test particles moving in the equatorial plane around static, spherically symmetric black holes within the framework of Deser-Woodard nonlocal gravity. Based on the Mathisson-Papapetrou-Dixon equations, combined with the Tulczyjew spin supplementary condition, we derive the orbital dynamic equations for spinning particles moving in the equatorial plane and impose a timelike constraint to exclude unphysical superluminal trajectories. By comparing with the classical Schwarzschild black hole, we systematically analyze the effects of the nonlocal gravitational parameters $ζ$ and $b$ on the effective potential governing the radial motion of particles and the innermost stable circular orbit. In addition, gravitational waveforms exhibit significant phase differences: an increase in $ζ$ induces a phase delay, whereas an increase in $b$ results in a phase advance. A one-year simulation of the orbital evolution of an extreme mass ratio inspiral demonstrates that when $b=2$ and $ζ\approx10^{-6}$, the mismatch between the gravitational waveforms predicted for the nonlocal gravity black hole and those for the Schwarzschild black hole reaches the distinguishable threshold ($\mathcal{M}=0.0125$), providing a basis for observational discrimination between general relativity and nonlocal gravity.

</details>


### [13] [Expansion operators in spherically symmetric loop quantum gravity](https://arxiv.org/abs/2602.15628)
*Xiaotian Fei,Gaoping Long,Yongge Ma,Cong Zhang*

Main category: gr-qc

TL;DR: 在球对称圈量子引力模型中，对与空间2-球相关的向内和向外零膨胀进行量子化，得到自伴的膨胀算符，其谱分析揭示了奇点避免和量子视界的新见解。


<details>
  <summary>Details</summary>
Motivation: 研究球对称圈量子引力模型中零膨胀的量子化，旨在理解经典广义相对论中奇点避免的机制，并为量子视界概念建立理论基础。

Method: 在球对称圈量子引力模型中，对与空间2-球相关的向内和向外零膨胀进行量子化，在运动学希尔伯特空间中构造自伴的膨胀算符，并分析其谱特性。

Result: 得到的膨胀算符在运动学希尔伯特空间中是自伴的，具有广义本征态。向外和向内膨胀算符共享连续的谱部分，但具有不同的孤立本征值。

Conclusion: 这些结果为经典广义相对论中奇点避免提供了新见解，并为建立某种量子视界概念奠定了基础。

Abstract: The ingoing and outgoing null expansions associated to a spatial 2-sphere are quantized in the spherically symmetric model of loop quantum gravity. It is shown that the resulting expansion operators are self-adjoint in the kinematical Hilbert space with generalized eigenstates. It turns out that the outgoing and ingoing expansion operators share the common continuous part of their spectra but have different additional isolated eigenvalues. These results provide new insights on the avoidance of the singularities in classical general relativity and the establishment of certain notion of quantum horizons.

</details>


### [14] [Timelike bounce hypersurfaces in charged null dust collapse](https://arxiv.org/abs/2602.15786)
*David Bick*

Main category: gr-qc

TL;DR: 研究带电零质量流体在广义相对论中的反弹动力学，特别是时间类反弹超曲面在球对称时空中的存在性和构造问题。


<details>
  <summary>Details</summary>
Motivation: 研究[Ori91]提出的反弹延续模型中带电零质量粒子的动力学行为，这些粒子在静电斥力作用下可能瞬间改变方向，为黑洞形成研究提供重要案例。

Method: 在球对称性下研究时间类反弹超曲面，识别运动方程的新解耦方法，构造包含Reissner-Nordström和Vaidya区域的时空，并解决自由边界问题。

Result: 证明了在Minkowski或Reissner-Nordström时空的球对称商中，任何时间类曲线段都可以作为来自过去零无穷远的带电零质量粒子束的反弹超曲面，构造了满足Einstein方程的时空，度规具有C^{2,1}正则性。

Conclusion: 建立了带电零质量流体在广义相对论中反弹动力学的基本框架，证明了时间类反弹超曲面的存在性，为研究黑洞形成和带电粒子动力学提供了新的数学工具和物理见解。

Abstract: We establish results on the dynamics of interacting charged null fluids in general relativity, specifically in the context of the bouncing continuation proposed in [Ori91]. In this model - the setting for a number of prominent case studies on black hole formation - charged massless particles may instantaneously change direction (bounce) after losing all their 4-momentum due to electrostatic repulsion. We initiate the study of timelike bounce hypersurfaces in spherical symmetry: scenarios in which an incoming beam of charged null dust changes direction along a timelike surface $\mathcal{B}$, which is the (free) boundary of an interacting 2-dust region. We identify a novel decoupling of the equations of motion in this region. First, it is shown that every timelike curve segment $γ$ in the spherically symmetric quotient of Minkowski or Reissner-Nordström spacetimes arises as the bounce hypersurface $\mathcal{B}$ of a charged null dust beam incident from past null infinity $\mathcal{I}^-$. We construct a spacetime $(\mathcal{M},g_{μν})$ describing the full trajectory of the beam, which includes gluing to Reissner-Nordström and Vaidya regions. Across $\mathcal{B}$ the metric has regularity $g_{μν}\in C^{2,1}$ and satisfies Einstein's equation classically, while $C^\infty$ gluing may be achieved across all other interfaces. We also obtain examples of timelike bounce hypersurfaces terminating in a null point. Since these constructions are teleological, we secondly consider a given charged incoming beam from past null infinity. We formulate and solve a free boundary problem which represents the formation of a timelike bounce hypersurface. The result is conditional, applying only in the exterior region of a Reissner-Nordström spacetime, and subject to a technical regularity condition.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [15] [VR-PIC: An entropic variance-reduction method for particle-in-cell solutions of the Vlasov-Poisson equation](https://arxiv.org/abs/2602.15041)
*Victor Windhab,Andreas Adelmann,Mohsen Sadr*

Main category: physics.comp-ph

TL;DR: 将熵保守方差减少框架扩展到Vlasov-Poisson方程的PIC方法，提出权重修正方案以保持守恒律并最小化偏差


<details>
  <summary>Details</summary>
Motivation: 将最近发展的熵保守方差减少框架扩展到粒子云(PIC)方法，解决Vlasov-Poisson方程在低信号区域计算效率低的问题

Method: 1) 使用零阶近似冻结重要性权重；2) 提出基于最大交叉熵公式的权重分布修正，确保守恒律同时最小化偏差

Result: 在Sod激波管和Landau阻尼等多个测试案例中，该方法在低信号区域相比传统PIC模拟保持显著的加速效果，且对模拟代码改动最小

Conclusion: 成功将方差减少框架扩展到PIC方法，提出的权重修正方案能有效保持守恒律并最小化偏差，在低信号区域实现显著计算加速

Abstract: We extend the recently developed entropic and conservative variance reduction framework [M. Sadr, N. G. Hadjiconstantinou, A variance-reduced direct Monte Carlo simulation method for solving the Boltzmann equation over a wide range of rarefaction, Journal of Computational Physics 472 (2023) 111677.] to the particle-in-cell (PIC) method of solving Vlasov-Poisson equation. We show that a zeroth-order approximation that freezes the importance weights during the velocity-space kick is stable at the expense of introducing bias. Then, we propose a correction for the weight distribution using maximum cross-entropy formulation to ensure conservation laws while minimizing the introduced bias. In several test cases including Sod's shock tube and Landau damping we show that the proposed method maintains the substantial speed-up of variance reduction method compared to the PIC simulations in the low signal regime with minimal changes to the simulation code.

</details>


### [16] [Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions](https://arxiv.org/abs/2602.15130)
*Brian A. Freno,William J. McDoniel,Christopher H. Moore,Neil R. Matula*

Main category: physics.comp-ph

TL;DR: 提出一种用于验证含随机碰撞模型的粒子网格代码的方法，通过构造解来分离空间/时间离散误差、统计采样噪声和碰撞算法随机性，可直接计算粒子位置和速度误差。


<details>
  <summary>Details</summary>
Motivation: 含随机碰撞模型的粒子网格方法广泛应用于等离子体模拟，但代码验证困难，因为空间/时间离散误差、统计采样噪声和碰撞算法随机性相互耦合，传统验证方法难以分离这些误差源。

Method: 1) 对粒子运动方程应用构造解方法，通过反查累积分布函数获得已知的粒子位置和速度，避免修改粒子权重；2) 对碰撞算法，在每个时间步平均独立结果并推导相应的制造源项；3) 直接计算粒子位置和速度误差而非分布函数差异。

Result: 该方法在三维情况下有效验证了不同粒子-场耦合、有无弹性碰撞、有无编码错误的粒子网格模拟，能够分离不同误差源并推导相应的收敛速率。

Conclusion: 提出的验证方法能够有效验证含随机碰撞模型的粒子网格代码，适用于等离子体模拟的粒子网格-蒙特卡洛碰撞方法和中性气体流动的直接模拟蒙特卡洛方法，为这类复杂随机模拟提供了可靠的验证框架。

Abstract: Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors.

</details>


### [17] [Analysis of Fission Matrix Databases using Temperature Profiles obtained from High-Fidelity Multiphysics Simulations](https://arxiv.org/abs/2602.15244)
*Maximiliano Dalinger,Elia Merzari,Saya Lee,Alex Nellis*

Main category: physics.comp-ph

TL;DR: 研究分析温度剖面选择对裂变矩阵法数据库构建的影响，比较基于高保真多物理场模拟温度剖面与均匀温度剖面的差异


<details>
  <summary>Details</summary>
Motivation: 裂变矩阵法依赖预计算的蒙特卡罗模拟数据库，需要多个数据库来表示反应堆的各种状态。温度剖面选择对数据库质量有重要影响，但缺乏系统分析。

Method: 以熔盐快堆为研究对象，构建两组数据库：第一组使用Cardinal高保真多物理场模拟获得的温度剖面，第二组使用均匀温度剖面。比较两组数据库在裂变矩阵求解中的表现。

Result: 使用与裂变矩阵求解时预期温度剖面相似的数据库时，倍增系数和裂变源分布得到显著改善。

Conclusion: 温度剖面选择对裂变矩阵法数据库质量有重要影响，使用与实际工况相似的温度剖面能提高模拟精度。

Abstract: The Fission Matrix method is used to perform fast and still accurate neutronics simulations. It relies on precalculated databases obtained through a Monte Carlo simulation. To represent every state of the reactor, multiple databases are required. The actual state of the reactor is obtained from those databases. In this paper, we analyze the effect of the temperature profiles selected to construct the databases. To do so, the Molten Salt Fast reactor is selected. Two sets of databases are studied: the first uses temperature profiles obtained from high-fidelity Multiphysics simulations with Cardinal, and the second uses uniform temperature profiles. Results showed improved multiplication factor and fission source distribution when the temperature profiles used to generate the databases were similar to those expected when solving the fission matrix.

</details>


### [18] [Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition](https://arxiv.org/abs/2602.15632)
*Changhong Mou,Binghang Lu,Guang Lin*

Main category: physics.comp-ph

TL;DR: 提出Neural-POD框架，用神经网络构建无限维空间中的非线性正交基函数，解决AI for Science中的离散化限制问题，相比经典POD具有分辨率不变性、可优化任意范数、捕获非线性结构等优势。


<details>
  <summary>Details</summary>
Motivation: AI for Science的发展常受"离散化"限制，学习到的表示局限于训练时使用的特定网格或分辨率。经典POD仅限于通过SVD获得的线性子空间近似，无法处理非线性结构。

Method: 将基函数构建建模为通过神经网络训练解决的残差最小化序列问题。每个基函数通过学习表示数据中的剩余结构获得，类似于Gram-Schmidt正交化过程。构建非线性正交基函数，实现无限维函数空间间的映射。

Result: Neural-POD在Burgers和Navier-Stokes等复杂时空系统中表现出鲁棒性。能够作为经典Galerkin投影和算子学习之间的高性能即插即用桥梁，与投影型降阶模型和DeepONet框架兼容。

Conclusion: Neural-POD克服了经典POD的局限性，提供分辨率不变、可优化任意范数、能捕获非线性结构的正交基函数，为降阶建模和算子学习提供了灵活强大的框架。

Abstract: The rapid development of AI for Science is often hindered by the "discretization", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [19] [Near-Optimal Sample Complexity for Online Constrained MDPs](https://arxiv.org/abs/2602.15076)
*Chang Liu,Yunfan Li,Lin F. Yang*

Main category: cs.LG

TL;DR: 提出一种基于模型的原对偶算法，用于安全强化学习中的约束马尔可夫决策过程，在允许小违规和严格可行两种设置下都能高效学习，样本复杂度与无约束MDP下界匹配。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习方法存在严重安全违规或高样本复杂度问题，难以在实际应用中平衡安全性和性能优化。

Method: 提出基于模型的原对偶算法，结合在线强化学习和约束优化技术，平衡遗憾和约束违规。

Result: 在允许小违规设置下，算法以高概率返回ε最优策略且违规有界，样本复杂度与无约束MDP下界匹配；在严格可行设置下，返回零违规的ε最优策略，样本复杂度与生成模型下界匹配。

Conclusion: 在线学习CMDP与使用生成模型学习同样容易，当允许小违规时，学习CMDP并不比学习无约束MDP更困难。

Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with $\varepsilon$-bounded violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^3}{\varepsilon^2}\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^5}{\varepsilon^2ζ^2}\right)$ learning episodes, where $ζ$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model.
  Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.

</details>


### [20] [Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction](https://arxiv.org/abs/2602.15089)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出了一种结合深度学习时间序列嵌入与统计特征的混合方法，用于HVAC设备异常预测，在64台设备上实现了高精度检测


<details>
  <summary>Details</summary>
Motivation: 纯深度学习方法在真实世界设备异常检测中精度不足，需要结合领域知识来提升预测性能

Method: 结合Granite TinyTimeMixer的64维时间序列嵌入（使用LoRA微调）和28维统计特征（趋势、波动性、回撤指标），使用LightGBM分类器进行学习

Result: 在64台设备、51,564个样本上，30/60/90天预测的精度达91-95%，ROC-AUC为0.995，误报率≤1.1%，检测率88-94%

Conclusion: 通过结合深度学习的表征学习能力和统计特征工程的互补优势，可以实现实用的异常检测系统

Abstract: In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\% or less and a detection rate of 88--94\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.

</details>


### [21] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: PolyNODEs：首个可变维度的流模型，将神经常微分方程扩展到M-多流形，解决了传统NODE模型固定维度的限制


<details>
  <summary>Details</summary>
Motivation: 现有神经常微分方程(NODE)模型受限于流形维度，只能处理固定维度的动态系统。需要扩展NODE到可变维度空间，以适应更灵活的几何深度学习任务

Method: 将NODE扩展到M-多流形（同时容纳可变维度和可微概念的空间），提出PolyNODEs模型。构建具有维度瓶颈的M-多流形，并基于参数化向量场实现PolyNODE自编码器

Result: 实验证明PolyNODE模型能够训练解决重构任务，并能提取输入的潜在表示用于下游分类任务

Conclusion: PolyNODEs是几何深度学习中首个可变维度的流模型，成功扩展了NODE的能力，为处理可变维度数据提供了新框架

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .

</details>


### [22] [Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields](https://arxiv.org/abs/2602.15155)
*Tianyu Xiong,Skylar Wurster,Han-Wei Shen*

Main category: cs.LG

TL;DR: DRR-Net通过解耦表示精炼架构解决INRs的保真度-速度困境，使用深度精炼网络和离线处理将丰富表示编码到紧凑嵌入结构中，实现高保真且快速推理。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）作为大型3D科学仿真的替代模型很有前景，但面临保真度-速度困境：深度MLP推理成本高，而高效的嵌入模型表达能力不足。

Method: 提出解耦表示精炼（DRR）架构范式，使用深度精炼网络和非参数变换在离线过程中将丰富表示编码到紧凑嵌入结构中，将慢速高容量网络与快速推理路径解耦。引入DRR-Net验证该范式，并提出变分对（VP）数据增强策略提升高维代理建模性能。

Result: 在多个集成仿真数据集上实现最先进的保真度，推理速度比高保真基线快27倍，同时与最快模型保持竞争力。

Conclusion: DRR范式为构建强大实用的神经场替代模型和INRs提供了有效策略，在速度和质量之间实现最小妥协。

Abstract: Implicit Neural Representations (INRs) have emerged as promising surrogates for large 3D scientific simulations due to their ability to continuously model spatial and conditional fields, yet they face a critical fidelity-speed dilemma: deep MLPs suffer from high inference cost, while efficient embedding-based models lack sufficient expressiveness. To resolve this, we propose the Decoupled Representation Refinement (DRR) architectural paradigm. DRR leverages a deep refiner network, alongside non-parametric transformations, in a one-time offline process to encode rich representations into a compact and efficient embedding structure. This approach decouples slow neural networks with high representational capacity from the fast inference path. We introduce DRR-Net, a simple network that validates this paradigm, and a novel data augmentation strategy, Variational Pairs (VP) for improving INRs under complex tasks like high-dimensional surrogate modeling. Experiments on several ensemble simulation datasets demonstrate that our approach achieves state-of-the-art fidelity, while being up to 27$\times$ faster at inference than high-fidelity baselines and remaining competitive with the fastest models. The DRR paradigm offers an effective strategy for building powerful and practical neural field surrogates and \rev{INRs in broader applications}, with a minimal compromise between speed and quality.

</details>


### [23] [Learning Representations from Incomplete EHR Data with Dual-Masked Autoencoding](https://arxiv.org/abs/2602.15159)
*Xiao Xiang,David Restrepo,Hyewon Jeong,Yugang Jia,Leo Anthony Celi*

Main category: cs.LG

TL;DR: AID-MAE：一种双掩码自编码器，直接从不完整时间序列学习，通过内在缺失掩码和增强掩码处理电子健康记录数据，在多个临床任务上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录时间序列数据存在不规则采样、异质性缺失和观测稀疏性等问题。现有自监督方法要么先插补再学习，要么通过专用输入信号表示缺失，要么仅优化插补任务，限制了学习支持临床下游任务表示的能力。

Method: 提出增强-内在双掩码自编码器（AID-MAE），直接从不完整时间序列学习。使用内在缺失掩码表示自然缺失值，增强掩码隐藏部分观测值用于训练重建。模型仅处理未掩码的token子集。

Result: 在两个数据集上的多个临床任务中，AID-MAE持续优于XGBoost和DuETT等强基线方法。学习到的嵌入在表示空间中自然地对患者队列进行分层。

Conclusion: AID-MAE通过双掩码策略有效处理电子健康记录时间序列的不完整性和稀疏性，学习到的表示在临床下游任务中表现优异，并能自然地对患者进行分层。

Abstract: Learning from electronic health records (EHRs) time series is challenging due to irregular sam- pling, heterogeneous missingness, and the resulting sparsity of observations. Prior self-supervised meth- ods either impute before learning, represent missingness through a dedicated input signal, or optimize solely for imputation, reducing their capacity to efficiently learn representations that support clinical downstream tasks. We propose the Augmented-Intrinsic Dual-Masked Autoencoder (AID-MAE), which learns directly from incomplete time series by applying an intrinsic missing mask to represent naturally missing values and an augmented mask that hides a subset of observed values for reconstruction during training. AID-MAE processes only the unmasked subset of tokens and consistently outperforms strong baselines, including XGBoost and DuETT, across multiple clinical tasks on two datasets. In addition, the learned embeddings naturally stratify patient cohorts in the representation space.

</details>


### [24] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: VLMs在纯文本任务上表现优于其底层LLMs，特别是在长上下文信息检索中。研究发现视觉训练改变了模型的内部绑定策略，使其更鲁棒，这种改进能持续到纯文本任务中。


<details>
  <summary>Details</summary>
Motivation: 观察到一个令人惊讶的现象：视觉语言模型（VLMs）在纯文本任务上表现优于其底层的大语言模型（LLMs），特别是在长上下文信息检索中。研究者想要探究这一现象背后的原因和机制。

Method: 构建了一个受控的合成检索任务，比较了仅文本训练的transformer和后续在图像标记化版本上训练的模型。使用机制可解释性分析来揭示内部绑定策略的变化。

Result: 仅文本训练的模型在分布内表现完美但分布外泛化失败，而图像训练后的模型在纯文本OOD性能上几乎翻倍。视觉训练通过空间平移不变性破坏了位置捷径，迫使模型采用更鲁棒的符号绑定机制。

Conclusion: 跨模态训练可以增强推理和泛化能力，即使对于单模态任务也是如此。视觉训练改变了模型的内部表示策略，使其在纯文本任务上表现更好。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [25] [Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge](https://arxiv.org/abs/2602.15184)
*Siying Ma,Mehrdad M. Zadeh,Mauricio Soroco,Wuyang Chen,Jiguo Cao,Vijay Ganesh*

Main category: cs.LG

TL;DR: 提出多物理训练框架，通过联合学习原始PDE及其简化基本形式，提升神经算子的数据效率、预测精度和分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法主要关注从目标PDE学习模拟，但忽略了更基础的物理原理。受数值求解器能与不同PDE设置兼容的启发，需要将基础物理知识显式融入训练过程。

Method: 提出多物理训练框架，同时从原始PDE及其简化基本形式中联合学习。该方法与架构无关，通过显式融入基础物理知识来增强神经算子的泛化能力。

Result: 在广泛的1D/2D/3D PDE问题上，该方法在归一化均方根误差(nRMSE)上表现出一致的改进，显著提升了数据效率、预测精度和分布外泛化能力，特别是在物理参数偏移和合成到真实转移场景中。

Conclusion: 显式融入基础物理知识能显著增强神经算子的泛化能力，多物理训练框架为科学机器学习提供了更有效的方法。

Abstract: Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from the target PDE, they often overlook more fundamental physical principles underlying these equations. Inspired by how numerical solvers are compatible with simulations of different settings of PDEs, we propose a multiphysics training framework that jointly learns from both the original PDEs and their simplified basic forms. Our framework enhances data efficiency, reduces predictive errors, and improves out-of-distribution (OOD) generalization, particularly in scenarios involving shifts of physical parameters and synthetic-to-real transfer. Our method is architecture-agnostic and demonstrates consistent improvements in normalized root mean square error (nRMSE) across a wide range of 1D/2D/3D PDE problems. Through extensive experiments, we show that explicit incorporation of fundamental physics knowledge significantly strengthens the generalization ability of neural operators. We will release models and codes at https://sites.google.com/view/sciml-fundemental-pde.

</details>


### [26] [COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression](https://arxiv.org/abs/2602.15200)
*Denis Makhov,Dmitriy Shopkhoev,Magauiya Zhussip,Ammar Ali,Baher Mohammad,Stamatios Lefkimmiatis*

Main category: cs.LG

TL;DR: COMPOT是一种无需训练的后训练压缩框架，通过正交字典和Procrustes更新实现Transformer模型的高效压缩，优于传统低秩和稀疏方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于截断SVD的Transformer压缩方法在中等压缩率下就会导致精度显著下降，而现有的稀疏字典学习方法需要迭代优化，计算效率低。

Method: 使用小规模校准数据集估计稀疏权重分解，采用正交字典实现闭式Procrustes更新和单步稀疏编码，无需迭代优化。引入一次性动态分配策略自适应调整各层压缩率。

Result: 在多种架构和任务上的实验表明，COMPOT在质量-压缩权衡方面始终优于强基线方法，且完全兼容后训练量化以实现极端压缩。

Conclusion: COMPOT提供了一种高效、无需训练的后训练压缩框架，通过正交字典和自适应层压缩分配，在保持精度的同时实现更好的压缩效果。

Abstract: Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but existing approaches often suffer from iterative dictionary and coefficient updates. We propose COMPOT (Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers), a training-free compression framework that uses a small calibration dataset to estimate a sparse weight factorization. COMPOT employs orthogonal dictionaries that enable closed-form Procrustes updates for the dictionary and analytical single-step sparse coding for the coefficients, eliminating iterative optimization. To handle heterogeneous layer sensitivity under a global compression budget, COMPOT further introduces a one-shot dynamic allocation strategy that adaptively redistributes layer-wise compression rates. Extensive experiments across diverse architectures and tasks show that COMPOT consistently delivers a superior quality-compression trade-off over strong low-rank and sparse baselines, while remaining fully compatible with post-training quantization for extreme compression. Code is available $\href{https://github.com/mts-ai/COMPOT}{here}$.

</details>


### [27] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 提出贝叶斯推理框架，联合学习来自多种反馈类型（演示、比较、评分、停止）的奖励函数，避免手动损失平衡，提高策略鲁棒性


<details>
  <summary>Details</summary>
Motivation: 当前奖励学习通常依赖单一反馈类型或手动加权组合多种反馈，缺乏有效方法联合学习来自异构反馈类型（演示、比较、评分、停止）的奖励函数，这些反馈提供性质不同的信号

Method: 将多反馈类型奖励学习建模为共享潜在奖励函数的贝叶斯推理，每个反馈类型通过显式似然函数贡献信息。提出可扩展的摊销变分推理方法，学习共享奖励编码器和反馈特定似然解码器，通过优化单一证据下界进行训练

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单类型基线，利用跨反馈类型的互补信息，产生对环境扰动更鲁棒的策略。推断的奖励不确定性进一步提供可解释信号，用于分析模型置信度和跨反馈类型一致性

Conclusion: 通过贝叶斯推理框架有效联合学习来自多种异构反馈类型的奖励函数，避免手动损失平衡，提高策略鲁棒性，并提供不确定性估计增强可解释性

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [28] [ÜberWeb: Insights from Multilingual Curation for a 20-Trillion-Token Dataset](https://arxiv.org/abs/2602.15210)
*DatologyAI,:,Aldo Gael Carranza,Kaleigh Mentzer,Ricardo Pio Monti,Alex Fang,Alvin Deng,Amro Abbas,Anshuman Suri,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Diego Kiner,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 通过针对性的多语言数据筛选，可以显著缓解多语言训练中的性能干扰问题，实现计算效率更高的多语言模型扩展。


<details>
  <summary>Details</summary>
Motivation: 多语言性是现代基础模型的核心能力，但多语言训练面临数据分布不均和"多语言诅咒"（性能干扰）的挑战。研究发现许多性能下降并非多语言扩展的固有缺陷，而是数据质量和组成问题所致。

Method: 在13种语言中进行多语言数据筛选研究，通过双语对照实验验证数据质量改进的跨语言效益。将发现扩展到大规模通用训练混合中，使用仅占总量8%的筛选多语言数据。构建了20T token的预训练语料库，训练3B和8B参数模型。

Result: 筛选英语数据在13种语言中的12种提升了非英语性能，筛选非英语数据也提升了英语性能。针对特定语言的筛选产生更大的语言内改进。使用筛选数据训练的模型仅用1T token就达到了竞争性的多语言准确性，比基线节省4-10倍训练FLOPs。400B/A13B模型也展现出相对于训练FLOPs的强大多语言性能。

Conclusion: 针对性的、按语言的数据筛选能够缓解多语言干扰，实现计算效率更高的多语言扩展，为多语言模型训练建立了新的帕累托前沿。

Abstract: Multilinguality is a core capability for modern foundation models, yet training high-quality multilingual models remains challenging due to uneven data availability across languages. A further challenge is the performance interference that can arise from joint multilingual training, commonly referred to as the "curse of multilinguality". We study multilingual data curation across thirteen languages and find that many reported regressions are not inherent to multilingual scaling but instead stem from correctable deficiencies in data quality and composition rather than fundamental capacity limits. In controlled bilingual experiments, improving data quality for any single language benefits others: curating English improves non-English performance in 12 of 13 languages, while curating non-English yields reciprocal improvements in English. Bespoke per-language curation produces substantially larger within-language improvements. Extending these findings to large-scale general-purpose training mixtures, we show that curated multilingual allocations comprising under 8% of total tokens remain remarkably effective. We operationalize this approach within an effort that produced a 20T-token pretraining corpus derived entirely from public sources. Models with 3B and 8B parameters trained on a 1T-token random subset achieve competitive multilingual accuracy with 4-10x fewer training FLOPs than strong public baselines, establishing a new Pareto frontier in multilingual performance versus compute. Moreover, these benefits extend to frontier model scale: the 20T-token corpus served as part of the pretraining dataset for Trinity Large (400B/A13B), which exhibits strong multilingual performance relative to its training FLOPs. These results show that targeted, per-language data curation mitigates multilingual interference and enables compute-efficient multilingual scaling.

</details>


### [29] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 提出自动发现奖励模型偏见的框架，通过LLM迭代生成和优化候选偏见，成功识别已知和新偏见（如冗余空格和幻觉内容），证明进化迭代优于平面搜索


<details>
  <summary>Details</summary>
Motivation: 奖励模型在LLM后训练中至关重要，但现有研究表明它们可能奖励虚假或不良属性（如长度、格式、幻觉、奉承）。需要自动检测这些偏见的方法来改进奖励模型

Method: 使用LLM迭代提出和优化候选偏见的简单方法，采用进化迭代策略而非平面最佳N搜索，并通过合成注入偏见验证召回率

Result: 方法能恢复已知偏见并发现新偏见：例如发现Skywork-V2-8B奖励模型经常错误地偏好包含冗余空格和幻觉内容的响应。进化迭代优于平面搜索，验证了管道的召回能力

Conclusion: 该工作为通过自动可解释性方法改进奖励模型的研究做出贡献，展示了自动发现奖励模型偏见的可行性

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [30] [tensorFM: Low-Rank Approximations of Cross-Order Feature Interactions](https://arxiv.org/abs/2602.15229)
*Alessio Mazzetto,Mohammad Mahdi Khalili,Laura Fee Nern,Michael Viderman,Alex Shtoff,Krzysztof Dembczyński*

Main category: cs.LG

TL;DR: TensorFM：一种用于表格分类数据预测的新模型，通过低秩张量近似高效捕捉高阶特征交互，在保持低延迟的同时达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 表格分类数据（如点击率预测、社会科学）中，实例通常由多个分类属性（字段）定义，每个属性有有限取值（特征）。现有方法在捕捉高阶特征交互方面存在效率问题，需要一种既能有效建模高阶交互又保持低延迟的模型。

Method: 提出tensorFM模型，通过低秩张量近似来高效表示特征间的高阶交互强度。该方法推广了场加权分解机（field-weighted factorization machines），能够捕捉更复杂的高阶特征交互模式。

Result: tensorFM在实证研究中表现出与最先进方法相竞争的性能，同时具有低延迟特性，特别适合在线广告等时间敏感的应用场景。

Conclusion: tensorFM是一种有效的表格分类数据预测模型，既能通过低秩张量近似高效捕捉高阶特征交互，又保持低延迟，在实际应用中具有良好前景。

Abstract: We address prediction problems on tabular categorical data, where each instance is defined by multiple categorical attributes, each taking values from a finite set. These attributes are often referred to as fields, and their categorical values as features. Such problems frequently arise in practical applications, including click-through rate prediction and social sciences. We introduce and analyze {tensorFM}, a new model that efficiently captures high-order interactions between attributes via a low-rank tensor approximation representing the strength of these interactions. Our model generalizes field-weighted factorization machines. Empirically, tensorFM demonstrates competitive performance with state-of-the-art methods. Additionally, its low latency makes it well-suited for time-sensitive applications, such as online advertising.

</details>


### [31] [BindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening](https://arxiv.org/abs/2602.15236)
*Anjie Qiao,Zhen Wang,Yaliang Li,Jiahua Rao,Yuedong Yang*

Main category: cs.LG

TL;DR: BindCLIP通过结合对比学习和生成式姿态监督，改进虚拟筛选中的口袋-配体表示学习，提升对真实结合相互作用的敏感性


<details>
  <summary>Details</summary>
Motivation: 现有CLIP风格模型（如DrugCLIP）的表示对精细结合相互作用不敏感，可能依赖训练数据中的捷径相关性，限制了按真实结合兼容性对配体进行排序的能力

Method: 提出BindCLIP统一对比-生成表示学习框架：联合训练口袋和配体编码器，使用CLIP风格对比学习结合口袋条件扩散目标进行结合姿态生成，姿态级监督直接塑造检索嵌入空间朝向相互作用相关特征；引入困难负样本增强和配体-配体锚定正则化器防止表示崩溃

Result: 在两个公共基准测试中表现优于强基线；在具有挑战性的分布外虚拟筛选中取得显著提升；在FEP+基准测试中改进配体类似物排序

Conclusion: 将生成式姿态级监督与对比学习相结合，产生更具相互作用感知的嵌入表示，在现实筛选场景中改善泛化能力，使虚拟筛选更接近实际应用

Abstract: Virtual screening aims to efficiently identify active ligands from massive chemical libraries for a given target pocket. Recent CLIP-style models such as DrugCLIP enable scalable virtual screening by embedding pockets and ligands into a shared space. However, our analyses indicate that such representations can be insensitive to fine-grained binding interactions and may rely on shortcut correlations in training data, limiting their ability to rank ligands by true binding compatibility. To address these issues, we propose BindCLIP, a unified contrastive-generative representation learning framework for virtual screening. BindCLIP jointly trains pocket and ligand encoders using CLIP-style contrastive learning together with a pocket-conditioned diffusion objective for binding pose generation, so that pose-level supervision directly shapes the retrieval embedding space toward interaction-relevant features. To further mitigate shortcut reliance, we introduce hard-negative augmentation and a ligand-ligand anchoring regularizer that prevents representation collapse. Experiments on two public benchmarks demonstrate consistent improvements over strong baselines. BindCLIP achieves substantial gains on challenging out-of-distribution virtual screening and improves ligand-analogue ranking on the FEP+ benchmark. Together, these results indicate that integrating generative, pose-level supervision with contrastive learning yields more interaction-aware embeddings and improves generalization in realistic screening settings, bringing virtual screening closer to real-world applicability.

</details>


### [32] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 提出分布对抗训练（DAT），利用扩散LLM近似真实数据分布，生成多样高似然样本，显著提升对抗鲁棒性


<details>
  <summary>Details</summary>
Motivation: 当前对抗训练方法存在根本性局限：仅在训练集上最小化对抗损失，未能充分覆盖数据分布，导致模型对简单的分布内攻击（如时态改写、语言翻译）仍然脆弱

Method: 提出分布对抗训练（DAT）：1）利用扩散LLM近似真实提示-响应的联合分布；2）生成多样且高似然的样本来解决泛化失败问题；3）将扩散模型提供的数据分布优化与连续对抗训练相结合

Result: DAT相比先前方法实现了显著更高的对抗鲁棒性

Conclusion: 通过更好地覆盖数据分布，DAT解决了当前对抗训练的根本局限，为提升LLM对抗鲁棒性提供了有效方法

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [33] [Size Transferability of Graph Transformers with Convolutional Positional Encodings](https://arxiv.org/abs/2602.15239)
*Javier Porras-Valenzuela,Zhiyang Wang,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 图Transformer通过GNN位置编码继承可迁移性，能在小图上训练后迁移到大图，理论证明与流形神经网络相关，实验验证了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 研究图Transformer(GT)如何通过GNN位置编码融入结构信息，并探索其在不同规模图之间的可迁移性，为大规模图上的高效训练提供理论指导。

Method: 从流形极限模型角度分析图序列，建立GT与GNN位置编码和流形神经网络的理论联系，基于GNN在流形收敛下的可迁移性结果，证明GT继承位置编码的可迁移性。

Result: 理论证明GT在小图上训练后可迁移到大图，实验验证GT在标准图基准上表现出与GNN相当的可扩展性，并在真实场景（地形最短路径距离估计）中展示高效性。

Conclusion: GT通过GNN位置编码获得可迁移性保证，为理解GT提供了新视角，并为大规模图上的高效训练提供了实用方向。

Abstract: Transformers have achieved remarkable success across domains, motivating the rise of Graph Transformers (GTs) as attention-based architectures for graph-structured data. A key design choice in GTs is the use of Graph Neural Network (GNN)-based positional encodings to incorporate structural information. In this work, we study GTs through the lens of manifold limit models for graph sequences and establish a theoretical connection between GTs with GNN positional encodings and Manifold Neural Networks (MNNs). Building on transferability results for GNNs under manifold convergence, we show that GTs inherit transferability guarantees from their positional encodings. In particular, GTs trained on small graphs provably generalize to larger graphs under mild assumptions. We complement our theory with extensive experiments on standard graph benchmarks, demonstrating that GTs exhibit scalable behavior on par with GNNs. To further show the efficiency in a real-world scenario, we implement GTs for shortest path distance estimation over terrains to better illustrate the efficiency of the transferable GTs. Our results provide new insights into the understanding of GTs and suggest practical directions for efficient training of GTs in large-scale settings.

</details>


### [34] [Scaling Laws for Masked-Reconstruction Transformers on Single-Cell Transcriptomics](https://arxiv.org/abs/2602.15253)
*Ihor Kendiukhov*

Main category: cs.LG

TL;DR: 该研究首次系统探索了单细胞RNA测序数据中掩码重建Transformer的神经缩放规律，发现数据充足时存在类似NLP的幂律缩放，数据稀缺时缩放效应可忽略。


<details>
  <summary>Details</summary>
Motivation: 神经缩放规律在语言和视觉Transformer中已被广泛证实，但在单细胞基因组学领域尚未被系统探索。本研究旨在填补这一空白，探究单细胞转录组学数据中是否存在类似的缩放规律。

Method: 使用CELLxGENE Census的表达谱数据，构建两个实验体系：数据丰富体系（512个高变异基因，20万个细胞）和数据有限体系（1,024个基因，1万个细胞）。在7个模型规模（参数数量跨越三个数量级，从533到3.4×10^8）上训练掩码重建Transformer，并拟合验证均方误差的缩放规律。

Result: 数据丰富体系显示出清晰的幂律缩放规律，不可约损失下限c~1.44；数据有限体系则缩放效应可忽略，表明数据稀缺时模型容量不是主要限制因素。初步将数据丰富体系的渐近下限转换为信息论单位，估计每个掩码基因位置约2.30比特的熵。

Conclusion: 单细胞转录组学在数据充足时确实存在类似NLP的缩放规律，数据与参数的比例是缩放行为的关键决定因素。这为单细胞基础模型的设计提供了重要指导，并指出了进一步精确熵估计所需的测量。

Abstract: Neural scaling laws -- power-law relationships between loss, model size, and data -- have been extensively documented for language and vision transformers, yet their existence in single-cell genomics remains largely unexplored. We present the first systematic study of scaling behaviour for masked-reconstruction transformers trained on single-cell RNA sequencing (scRNA-seq) data. Using expression profiles from the CELLxGENE Census, we construct two experimental regimes: a data-rich regime (512 highly variable genes, 200,000 cells) and a data-limited regime (1,024 genes, 10,000 cells). Across seven model sizes spanning three orders of magnitude in parameter count (533 to 3.4 x 10^8 parameters), we fit the parametric scaling law to validation mean squared error (MSE). The data-rich regime exhibits clear power-law scaling with an irreducible loss floor of c ~ 1.44, while the data-limited regime shows negligible scaling, indicating that model capacity is not the binding constraint when data are scarce. These results establish that scaling laws analogous to those observed in natural language processing do emerge in single-cell transcriptomics when sufficient data are available, and they identify the data-to-parameter ratio as a critical determinant of scaling behaviour. A preliminary conversion of the data-rich asymptotic floor to information-theoretic units yields an estimate of approximately 2.30 bits of entropy per masked gene position. We discuss implications for the design of single-cell foundation models and outline the additional measurements needed to refine this entropy estimate.

</details>


### [35] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 提出一种改进的在线蒸馏方法——在线前缀蒸馏，通过仅对学生模型生成输出的前缀应用蒸馏目标并提前终止采样，大幅降低训练成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统在线蒸馏需要昂贵的实时学生策略采样，尤其对于长响应训练成本很高。研究发现训练信号通常集中在输出前缀，即使短的前缀也能显著帮助学生生成正确答案。

Method: 提出在线前缀蒸馏：仅对学生生成输出的前缀应用蒸馏目标，并在蒸馏过程中提前终止每个采样。相比完整在线蒸馏，这种方法大幅减少计算量。

Result: 在AI-for-Math和领域外基准测试中，在线前缀蒸馏与完整在线蒸馏性能相当，同时将训练FLOP减少2-47倍。

Conclusion: 在线前缀蒸馏是一种简单有效的在线蒸馏改进方法，通过关注输出前缀的关键训练信号，在保持性能的同时显著降低训练成本。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [36] [Complex-Valued Unitary Representations as Classification Heads for Improved Uncertainty Quantification in Deep Neural Networks](https://arxiv.org/abs/2602.15283)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.LG

TL;DR: 提出量子启发的分类头架构，通过复值希尔伯特空间中的酉变换改善神经网络校准，在CIFAR-10上实现2.4倍校准误差降低。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络预测准确率高但校准性差，置信度不能可靠反映正确概率。需要改善模型校准以提高安全关键应用中的可靠性。

Method: 提出量子启发的分类头架构：将骨干网络特征投影到复值希尔伯特空间，通过Cayley映射参数化的酉变换演化特征。采用酉幅度头（复特征经酉变换后通过幅度和softmax读出）和波函数头（Born规则测量层）两种变体。

Result: 在CIFAR-10上，酉幅度头获得0.0146的ECE，比标准softmax头（0.0355）改善2.4倍，比温度缩放（0.0510）改善3.5倍。波函数头在CIFAR-10H人类不确定性基准上获得最低KL散度（0.336），表明复值表示能更好捕捉人类感知模糊性。

Conclusion: 复值酉表示能显著改善神经网络校准，但Born规则测量层会降低校准性能。该方法在安全关键应用中具有实用价值，但在分布外检测和情感分析等任务中效果有限。

Abstract: Modern deep neural networks achieve high predictive accuracy but remain poorly calibrated: their confidence scores do not reliably reflect the true probability of correctness. We propose a quantum-inspired classification head architecture that projects backbone features into a complex-valued Hilbert space and evolves them under a learned unitary transformation parameterised via the Cayley map. Through a controlled hybrid experimental design - training a single shared backbone and comparing lightweight interchangeable heads - we isolate the effect of complex-valued unitary representations on calibration. Our ablation study on CIFAR-10 reveals that the unitary magnitude head (complex features evolved under a Cayley unitary, read out via magnitude and softmax) achieves an Expected Calibration Error (ECE) of 0.0146, representing a 2.4x improvement over a standard softmax head (0.0355) and a 3.5x improvement over temperature scaling (0.0510). Surprisingly, replacing the softmax readout with a Born rule measurement layer - the quantum-mechanically motivated approach - degrades calibration to an ECE of 0.0819. On the CIFAR-10H human-uncertainty benchmark, the wave function head achieves the lowest KL-divergence (0.336) to human soft labels among all compared methods, indicating that complex-valued representations better capture the structure of human perceptual ambiguity. We provide theoretical analysis connecting norm-preserving unitary dynamics to calibration through feature-space geometry, report negative results on out-of-distribution detection and sentiment analysis to delineate the method's scope, and discuss practical implications for safety-critical applications. Code is publicly available.

</details>


### [37] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: 论文探讨AI系统如何将语义结构编码到表示空间的几何结构中，提出信息几何是表示空间的自然几何，并开发了"双重引导"方法用于概念操控。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是理解AI系统如何将语义结构编码到表示空间的几何结构中。核心观察是：表示空间的自然几何应该反映模型如何使用这些表示来产生行为。特别关注定义softmax分布的表示，认为在这种情况下自然几何应该是信息几何。

Method: 论文聚焦于信息几何在语义编码和线性表示假设中的作用。作为应用示例，开发了"双重引导"方法，该方法使用线性探针稳健地引导表示以展示特定概念。该方法基于信息几何理论，能够最优地修改目标概念，同时最小化对非目标概念的改变。

Result: 理论上证明了双重引导能够最优地修改目标概念，同时最小化对非目标概念的改变。实证研究发现，双重引导增强了概念操控的可控性和稳定性。

Conclusion: 信息几何是AI表示空间的自然几何结构，特别适用于定义softmax分布的表示。双重引导方法基于信息几何理论，为概念操控提供了稳健、可控的解决方案，验证了信息几何在语义编码中的重要性。

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [38] [Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization](https://arxiv.org/abs/2602.15304)
*Farzana Akter,Rakib Hossain,Deb Kanna Roy Toushi,Mahmood Menon Khan,Sultana Amin,Lisan Al Amin*

Main category: cs.LG

TL;DR: 提出结合联邦学习与分割学习的混合隐私保护框架，用于医疗决策支持，无需共享原始数据，在性能、隐私、通信成本间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 医疗临床决策支持常受治理和隐私规则限制，无法跨机构共享患者级记录，需要在不共享原始数据的情况下实现协作建模。

Method: 结合联邦学习与分割学习的混合框架：客户端保留特征提取主干，协调服务器托管预测头，通过成员推理审计泄漏风险，采用激活裁剪和高斯噪声作为轻量级防御。

Result: 混合FL-SL变体在三个公共临床数据集上实现竞争性预测性能，提供可调隐私-效用权衡，减少审计泄漏，同时保持决策优先排序能力。

Conclusion: 混合FL-SL为隐私保护医疗决策支持提供了实用设计空间，可在效用、泄漏风险和部署成本间进行显式平衡。

Abstract: Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.

</details>


### [39] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 随机掩码参数更新可以替代复杂的自适应优化器，Magma通过动量梯度对齐调节掩码更新，在LLM预训练中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型训练几乎完全依赖复杂的自适应优化器，作者挑战这一现状，发现随机掩码参数更新可以非常有效

Method: 提出Momentum-aligned gradient masking (Magma)，通过动量梯度对齐来调节随机掩码的更新，分析显示随机掩码会引入曲率相关的几何正则化

Result: Magma在LLM预训练实验中作为自适应优化器的简单替代方案，带来一致性能提升且计算开销可忽略。对于10亿参数模型，相比Adam和Muon分别降低困惑度19%和9%

Conclusion: 随机掩码优化器是自适应优化器的有效替代方案，Magma通过动量对齐进一步提升性能，为LLM训练提供了简单高效的优化器选择

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [40] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 该论文提出了一种通过平滑分位数回归估计模型能力边界的方法，用于预测给定预训练计算预算下的下游任务性能，并验证了时间稳定性，同时发布了Proteus 2k数据集和高效评估算法。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的部署，实践者需要预测性的缩放定律：给定预训练计算预算，在当代后训练实践下可获得的下游准确率是多少？这种映射关系随着领域发展有多稳定？

Method: 使用大规模观测评估（5k观测数据和2k新采样数据），通过具有单调饱和sigmoid参数化的平滑分位数回归来估计能力边界（即基准分数的高条件分位数作为预训练FLOPs对数的函数）。验证时间可靠性：在早期模型上拟合，在后期发布上评估。扩展方法分析任务相关饱和度和数学推理任务中的污染相关偏移。引入高效算法，用约20%的评估预算恢复接近完整的数据边界。

Result: 估计的能力边界在大多数任务中基本稳定，但数学推理任务显示出随时间持续推进的边界。方法能够分析任务相关饱和度和污染相关偏移。高效算法能以约20%的评估预算恢复接近完整的数据边界。

Conclusion: 该工作发布了最新的模型性能评估数据集Proteus 2k，并引入了一种实用方法，用于将计算预算转化为可靠的性能预期，并监测能力边界随时间的变化。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [41] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 提出CD-GTMLL框架，将长尾多标签分类重构为多玩家博弈，通过好奇心奖励机制自适应增强尾部标签学习，无需手动平衡


<details>
  <summary>Details</summary>
Motivation: 现实世界数据挖掘中，多标签分类面临长尾分布挑战，现有重采样和重加权方法会破坏标签间依赖关系或需要脆弱的超参数调优，特别是在标签空间扩展到数万个标签时

Method: 提出好奇心驱动的博弈论多标签学习框架，将长尾多标签分类重构为多玩家博弈，每个子预测器专门处理标签空间的一个分区，通过合作最大化全局准确性，同时基于尾部标签稀有性和玩家间分歧获得内在好奇心奖励

Result: 在7个基准测试（包括超过30,000个标签的极端多标签分类数据集）上，CD-GTMLL始终优于最先进方法，在Wiki10-31K上P@3指标提升高达+1.6%。理论分析表明收敛到尾部感知均衡

Conclusion: 通过整合博弈论和好奇心机制，CD-GTMLL不仅提高了资源受限环境中的模型效率，还为电子商务和医疗等行业的不平衡数据场景中的自适应学习开辟了新途径

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [42] [Directional Reasoning Trajectory Change (DRTC): Identifying Critical Trace Segments in Reasoning Models](https://arxiv.org/abs/2602.15332)
*Waldemar Chang*

Main category: cs.LG

TL;DR: DRTC是一个因果解释框架，用于分析语言模型的长程推理过程，通过检测关键决策点并测量干预对推理轨迹方向的影响。


<details>
  <summary>Details</summary>
Motivation: 现有解释方法通常只突出与答案相关的token或文本片段，但很少揭示模型在何处做出关键推理转折、哪些早期上下文因果触发了这些转折，或者突出文本是否真正引导了推理过程。

Method: DRTC框架：1) 使用不确定性和分布偏移信号检测关键决策点；2) 应用接收端干预，在保持实际推理轨迹的同时阻断选定早期信息块的信息流；3) 测量干预是否改变模型对数概率轨迹的方向，产生带符号的归属分数；4) 计算原始logits的曲率变化作为补充诊断。

Result: 方向性影响在四个推理模型中高度集中（Gini系数0.50-0.58，前5%质量占比0.23-0.28）；学习到的关键片段比随机匹配片段产生更强的干预效果；在500个MATH问题上的扩展研究中，学习片段显著优于随机片段（中位数差异0.409，355/500为正，符号检验p=2.3e-21）。

Conclusion: DRTC提供了一个因果基础的、轨迹层面的视角，揭示了特定上下文元素如何在策略动态下引导推理过程。

Abstract: Understanding how language models carry out long-horizon reasoning remains an open challenge. Existing interpretability methods often highlight tokens or spans correlated with an answer, but they rarely reveal where the model makes consequential reasoning turns, which earlier context causally triggers those turns, or whether the highlighted text actually steers the reasoning process. We introduce Directional Reasoning Trajectory Change (DRTC), a process-causal framework for interpreting long-form reasoning from a single on-policy rollout. DRTC detects pivot decision points using uncertainty and distribution-shift signals, then applies receiver-side interventions that preserve the realized rollout without resampling the continuation while blocking information flow from selected earlier chunks only at a pivot. It measures whether each intervention redirects the direction of the model's log-probability trajectory relative to the realized rollout direction, producing a signed per-chunk attribution score. We also compute turning-angle curvature changes on raw logits as a complementary diagnostic and introduce curvature signatures to summarize shared intervention-response geometry. Empirically, directional influence is sharply concentrated across four reasoning models (per-example |DRTC| shares yield Gini 0.50 to 0.58 and top-5 percent mass 0.23 to 0.28), and learned pivots induce stronger intervention magnitudes than matched random spans. In a scaling study on 500 MATH problems with R1-Distill-Qwen-1.5B, learned spans outperform matched random spans (median delta = 0.409, 355 of 500 positive; sign test p = 2.3e-21). Overall, DRTC provides a causally grounded, trajectory-level view of how specific context elements steer reasoning under on-policy dynamics.

</details>


### [43] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: FedPSA：基于参数敏感性的异步联邦学习框架，通过细粒度模型过时度量和动态动量队列，提升异步联邦学习性能


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习(AFL)虽然能加速训练，但异步过程引入的陈旧性(staleness)会导致性能下降。现有方法仅使用轮次差异作为陈旧性度量，这种粗粒度方法缺乏对模型本身的观察，限制了异步方法的性能上限。

Method: 提出FedPSA框架：1) 利用参数敏感性来度量模型过时程度，提供更细粒度的陈旧性评估；2) 建立动态动量队列实时评估当前训练阶段，动态调整对过时信息的容忍度。

Result: 在多个数据集上的实验表明，FedPSA相比基线方法提升高达6.37%，相比当前最先进方法提升1.93%，表现出优越性能。

Conclusion: FedPSA通过细粒度的参数敏感性度量和动态调整机制，有效解决了异步联邦学习中的陈旧性问题，显著提升了异步联邦学习的性能。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [44] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: Obj-Disco框架自动将LLM对齐奖励信号分解为可解释的自然语言目标，揭示隐式目标以提升AI透明度和安全性


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法依赖复杂奖励信号，但信号背后的具体行为激励不透明，存在错位和奖励攻击风险。现有解释方法要么依赖预定义标准可能遗漏未知因素，要么无法全面识别因果性目标。

Method: 提出Obj-Disco框架，使用迭代贪婪算法分析训练检查点的行为变化，识别并验证最能解释剩余奖励信号的候选目标，将对齐奖励信号分解为稀疏、加权组合的可解释自然语言目标。

Result: 在不同任务、模型规模和算法上的评估显示框架稳健性。实验表明能捕获>90%的奖励行为，人类评估进一步证实。案例研究显示能成功识别伴随预期行为出现的潜在错位激励。

Conclusion: Obj-Disco为揭示LLM对齐中的隐式目标提供了关键工具，为更透明、更安全的AI发展铺平道路。

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [45] [ER-MIA: Black-Box Adversarial Memory Injection Attacks on Long-Term Memory-Augmented Large Language Models](https://arxiv.org/abs/2602.15344)
*Mitchell Piehl,Zhaohan Xi,Zuobin Xiong,Pan He,Muchao Ye*

Main category: cs.LG

TL;DR: ER-MIA：首个针对长时记忆增强LLM的黑盒对抗性记忆注入攻击框架，通过相似性检索机制漏洞实现高成功率攻击


<details>
  <summary>Details</summary>
Motivation: LLM通过长时记忆系统扩展有限上下文窗口，但研究发现记忆系统增加了攻击面。目前缺乏对基于相似性检索机制的系统性安全研究，需要揭示这一根本性漏洞

Method: 提出ER-MIA统一框架，形式化两种现实攻击场景：基于内容的攻击和问题目标攻击。包含可组合的攻击原语和集成攻击方法，在最小攻击者假设下实现高成功率

Result: 在多个LLM和长时记忆系统上的广泛实验表明，基于相似性检索构成根本性系统级漏洞，该安全风险在不同记忆设计和应用场景中持续存在

Conclusion: 相似性检索机制是长时记忆增强LLM的严重安全漏洞，需要重新设计记忆系统以抵御此类对抗性攻击，确保AI系统的安全性

Abstract: Large language models (LLMs) are increasingly augmented with long-term memory systems to overcome finite context windows and enable persistent reasoning across interactions. However, recent research finds that LLMs become more vulnerable because memory provides extra attack surfaces. In this paper, we present the first systematic study of black-box adversarial memory injection attacks that target the similarity-based retrieval mechanism in long-term memory-augmented LLMs. We introduce ER-MIA, a unified framework that exposes this vulnerability and formalizes two realistic attack settings: content-based attacks and question-targeted attacks. In these settings, ER-MIA includes an arsenal of composable attack primitives and ensemble attacks that achieve high success rates under minimal attacker assumptions. Extensive experiments across multiple LLMs and long-term memory systems demonstrate that similarity-based retrieval constitutes a fundamental and system-level vulnerability, revealing security risks that persist across memory designs and application scenarios.

</details>


### [46] [CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies](https://arxiv.org/abs/2602.15367)
*Sibo Zhang,Rui Jing,Liangfu Lv,Jian Zhang,Yunliang Zang*

Main category: cs.LG

TL;DR: 提出受小脑结构启发的强化学习架构，通过大规模扩展、稀疏连接、稀疏激活和树突级调制，在噪声高维任务中提升样本效率、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在高维序列决策任务中表现出色，但存在样本效率低、对噪声敏感、部分可观测下泛化能力弱的问题。现有方法主要通过优化策略解决这些问题，而架构先验在表征学习和决策动态中的作用较少被探索。受小脑结构原理启发，研究生物基础架构对强化学习的价值。

Method: 提出受小脑启发的强化学习架构，包含四个关键特征：大规模扩展、稀疏连接、稀疏激活和树突级调制。在噪声高维强化学习基准上进行实验，分析架构参数敏感性。

Result: 实验表明，小脑架构和树突调制相比传统设计，在样本效率、鲁棒性和泛化能力上均有显著提升。架构参数敏感性分析显示，小脑启发的结构能在有限模型参数下提供优化性能。

Conclusion: 小脑结构先验可作为强化学习的有效归纳偏置，生物启发的架构设计为解决强化学习现有局限性提供了新途径。

Abstract: Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.

</details>


### [47] [Fractional-Order Federated Learning](https://arxiv.org/abs/2602.15380)
*Mohammad Partohaghighi,Roummel Marcia,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出了一种基于分数阶随机梯度下降的联邦平均算法FOFedAvg，通过引入记忆感知的分数阶更新来改善通信效率和收敛速度，在多个基准数据集上优于现有联邦优化算法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护客户端隐私，但存在收敛慢、通信成本高、非独立同分布数据等问题。需要一种能捕获长期关系和历史信息的方法来改善这些问题。

Method: 提出了FOFedAvg算法，将分数阶随机梯度下降（FOSGD）融入联邦平均框架，通过分数阶更新来捕捉长期依赖关系和历史信息，提高通信效率和收敛稳定性。

Result: 在MNIST、FEMNIST、CIFAR-10、CIFAR-100、EMNIST等多个基准数据集上，FOFedAvg在非独立同分布数据划分下，在测试性能和收敛速度方面优于或与现有基线算法相当。

Conclusion: 分数阶记忆感知更新能显著提高联邦学习的鲁棒性和有效性，为异构数据上的分布式训练提供了实用路径，并在理论上证明了算法在分数阶0<α≤1条件下的收敛性。

Abstract: Federated learning (FL) allows remote clients to train a global model collaboratively while protecting client privacy. Despite its privacy-preserving benefits, FL has significant drawbacks, including slow convergence, high communication cost, and non-independent-and-identically-distributed (non-IID) data. In this work, we present a novel FedAvg variation called Fractional-Order Federated Averaging (FOFedAvg), which incorporates Fractional-Order Stochastic Gradient Descent (FOSGD) to capture long-range relationships and deeper historical information. By introducing memory-aware fractional-order updates, FOFedAvg improves communication efficiency and accelerates convergence while mitigating instability caused by heterogeneous, non-IID client data. We compare FOFedAvg against a broad set of established federated optimization algorithms on benchmark datasets including MNIST, FEMNIST, CIFAR-10, CIFAR-100, EMNIST, the Cleveland heart disease dataset, Sent140, PneumoniaMNIST, and Edge-IIoTset. Across a range of non-IID partitioning schemes, FOFedAvg is competitive with, and often outperforms, these baselines in terms of test performance and convergence speed. On the theoretical side, we prove that FOFedAvg converges to a stationary point under standard smoothness and bounded-variance assumptions for fractional order $0<α\le 1$. Together, these results show that fractional-order, memory-aware updates can substantially improve the robustness and effectiveness of federated learning, offering a practical path toward distributed training on heterogeneous data.

</details>


### [48] [Doubly Stochastic Mean-Shift Clustering](https://arxiv.org/abs/2602.15393)
*Tom Trigano,Yann Sepulcre,Itshak Lapidot*

Main category: cs.LG

TL;DR: 提出DSMS算法，通过随机化带宽参数解决传统Mean-Shift算法对带宽超参数敏感的问题，在数据稀缺时防止过分割


<details>
  <summary>Details</summary>
Motivation: 传统Mean-Shift算法对带宽超参数非常敏感，特别是在数据稀缺情况下，固定尺度的密度估计会导致碎片化和虚假模式

Method: 提出双重随机Mean-Shift（DSMS），在轨迹更新和核带宽中都引入随机性，每次迭代从连续均匀分布中采样数据点和半径

Result: 在合成高斯混合数据上的实验显示，DSMS显著优于标准和随机Mean-Shift基线，表现出更好的稳定性，防止稀疏聚类场景中的过分割

Conclusion: 随机带宽策略作为隐式正则化机制，能更好地探索密度景观，提供收敛理论结果，在数据稀缺情况下保持性能

Abstract: Standard Mean-Shift algorithms are notoriously sensitive to the bandwidth hyperparameter, particularly in data-scarce regimes where fixed-scale density estimation leads to fragmentation and spurious modes. In this paper, we propose Doubly Stochastic Mean-Shift (DSMS), a novel extension that introduces randomness not only in the trajectory updates but also in the kernel bandwidth itself. By drawing both the data samples and the radius from a continuous uniform distribution at each iteration, DSMS effectively performs a better exploration of the density landscape. We show that this randomized bandwidth policy acts as an implicit regularization mechanism, and provide convergence theoretical results. Comparative experiments on synthetic Gaussian mixtures reveal that DSMS significantly outperforms standard and stochastic Mean-Shift baselines, exhibiting remarkable stability and preventing over-segmentation in sparse clustering scenarios without other performance degradation.

</details>


### [49] [Joint Enhancement and Classification using Coupled Diffusion Models of Signals and Logits](https://arxiv.org/abs/2602.15405)
*Gilad Nurko,Roi Benita,Yehoshua Dissen,Tomohiro Nakatani,Marc Delcroix,Shoko Araki,Joseph Keshet*

Main category: cs.LG

TL;DR: 提出一个联合增强框架，通过两个交互的扩散模型同时处理输入信号和分类器输出，实现信号增强与分类的相互指导，提升噪声环境下的分类鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将信号增强和分类作为分离的串行阶段，无法在去噪过程中利用分类器的语义信息。这种分离方法限制了在噪声环境下的分类性能。

Method: 提出一个领域无关的框架，集成两个交互的扩散模型：一个处理输入信号，另一个处理分类器输出logits。引入三种策略来有效建模输入和logit的联合分布，无需重新训练或微调分类器。

Result: 在图像分类和自动语音识别任务上评估，提出的联合增强方法超越了传统的串行增强基线，在不同噪声条件下实现了鲁棒且灵活的分类准确率提升。

Conclusion: 通过耦合信号增强和分类决策的扩散过程，实现了相互指导的联合优化，为噪声环境下的鲁棒分类提供了一个有效且通用的框架。

Abstract: Robust classification in noisy environments remains a fundamental challenge in machine learning. Standard approaches typically treat signal enhancement and classification as separate, sequential stages: first enhancing the signal and then applying a classifier. This approach fails to leverage the semantic information in the classifier's output during denoising. In this work, we propose a general, domain-agnostic framework that integrates two interacting diffusion models: one operating on the input signal and the other on the classifier's output logits, without requiring any retraining or fine-tuning of the classifier. This coupled formulation enables mutual guidance, where the enhancing signal refines the class estimation and, conversely, the evolving class logits guide the signal reconstruction towards discriminative regions of the manifold. We introduce three strategies to effectively model the joint distribution of the input and the logit. We evaluated our joint enhancement method for image classification and automatic speech recognition. The proposed framework surpasses traditional sequential enhancement baselines, delivering robust and flexible improvements in classification accuracy under diverse noise conditions.

</details>


### [50] [Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas](https://arxiv.org/abs/2602.15407)
*Alper Demir,Hüseyin Aydın,Kale-ab Abebe Tessera,David Abel,Stefano V. Albrecht*

Main category: cs.LG

TL;DR: 该论文针对传统公平性方法在非对称社会困境中的局限性，提出了三种改进：考虑奖励范围重新定义公平性、引入基于智能体的加权机制、以及本地化社会反馈，从而在非对称场景中更有效地促进合作。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多假设智能体在社会困境中面临相同的激励，并需要持续访问全局信息来评估公平性。然而，现实中的智能体往往存在自然差异，导致传统公平性方法在非对称条件下表现不佳，强制执行原始平等反而会错误地激励背叛行为。

Method: 提出了三种关键改进：1) 重新定义公平性，考虑智能体的奖励范围；2) 引入基于智能体的加权机制，更好地处理固有的非对称性；3) 本地化社会反馈，使方法在部分可观测性下有效，无需全局信息共享。

Result: 实验结果表明，在非对称场景中，该方法比现有方法更快地促进合作策略的出现，同时不牺牲可扩展性或实用性。

Conclusion: 该研究强调了在非对称社会困境中重新思考公平性概念的重要性，提出的改进方法能够更好地适应智能体间的自然差异，促进更有效的合作行为。

Abstract: Sequential Social Dilemmas (SSDs) provide a key framework for studying how cooperation emerges when individual incentives conflict with collective welfare. In Multi-Agent Reinforcement Learning, these problems are often addressed by incorporating intrinsic drives that encourage prosocial or fair behavior. However, most existing methods assume that agents face identical incentives in the dilemma and require continuous access to global information about other agents to assess fairness. In this work, we introduce asymmetric variants of well-known SSD environments and examine how natural differences between agents influence cooperation dynamics. Our findings reveal that existing fairness-based methods struggle to adapt under asymmetric conditions by enforcing raw equality that wrongfully incentivize defection. To address this, we propose three modifications: (i) redefining fairness by accounting for agents' reward ranges, (ii) introducing an agent-based weighting mechanism to better handle inherent asymmetries, and (iii) localizing social feedback to make the methods effective under partial observability without requiring global information sharing. Experimental results show that in asymmetric scenarios, our method fosters faster emergence of cooperative policies compared to existing approaches, without sacrificing scalability or practicality.

</details>


### [51] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 论文研究了判别模型表示相似性问题，发现KL散度相近不能保证线性表示相似性，而logit距离相近则能保证线性表示相似性，这对知识蒸馏有重要影响。


<details>
  <summary>Details</summary>
Motivation: 在判别模型中，当两个模型的条件分布完全相同时，它们的内部表示在线性变换下是等价的。但实际中模型分布通常只是相近而非相同，需要研究这种近似情况下的表示相似性保证。

Method: 基于logit差异定义分布距离，证明该距离相近能保证线性表示相似性。定义基于模型可识别性类的表示差异度量，证明其受logit距离约束。分析KL散度与logit距离的关系。

Result: logit距离相近能保证线性表示相似性，而KL散度相近不能提供有意义的控制。在知识蒸馏实验中，基于logit距离的蒸馏能获得更高线性表示相似性和更好保留教师模型的可线性恢复概念。

Conclusion: KL散度蒸馏可能匹配教师预测但无法保持线性表示特性，而logit距离蒸馏能更好地保持线性表示相似性和概念可恢复性，这对模型蒸馏和表示学习有重要意义。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [52] [Benchmarking IoT Time-Series AD with Event-Level Augmentations](https://arxiv.org/abs/2602.15457)
*Dmitry Zhevnenko,Ilya Makarov,Aleksandr Kovalenko,Fedor Meshchaninov,Anton Kozhukhov,Vladislav Travnikov,Makar Ippolitov,Kirill Yashunin,Iurii Katser*

Main category: cs.LG

TL;DR: 本文提出一个针对物联网时间序列异常检测的评估协议，包含事件级增强和传感器级探测，评估14个模型在7个数据集上的表现，发现没有通用最佳模型，不同模型在不同场景下各有优势。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测研究过于关注点级结果和精心整理的基础数据集，缺乏对实际应用中可靠性、及时性和抗干扰能力的评估，限制了模型在实际应用中的选择价值。

Method: 引入统一的评估协议，包含事件级增强（传感器丢失、线性/对数漂移、加性噪声、窗口偏移）和传感器级探测（掩码缺失归零和通道影响估计），在5个公共数据集和2个工业数据集上评估14个代表性模型。

Result: 没有通用最佳模型：图结构模型在传感器丢失和长事件下表现最好；密度/流模型在清洁稳定工厂中表现良好但对单调漂移敏感；谱CNN在周期性强的场景领先；重构自编码器在基本传感器筛选后变得有竞争力；预测/混合动态模型在故障破坏时间依赖时有效但对窗口敏感。

Conclusion: 评估协议为实际模型选择提供了实用指导，揭示了不同模型在不同扰动场景下的优势和脆弱性，并帮助识别设计选择的影响，如将归一化流替换为高斯密度会显著降低性能，固定学习DAG会提高漂移敏感性。

Abstract: Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations. Yet many studies still emphasize point-level results on curated base datasets, limiting value for model selection in practice. We introduce an evaluation protocol with unified event-level augmentations that simulate real-world issues: calibrated sensor dropout, linear and log drift, additive noise, and window shifts. We also perform sensor-level probing via mask-as-missing zeroing with per-channel influence estimation to support root-cause analysis. We evaluate 14 representative models on five public anomaly datasets (SWaT, WADI, SMD, SKAB, TEP) and two industrial datasets (steam turbine, nuclear turbogenerator) using unified splits and event aggregation. There is no universal winner: graph-structured models transfer best under dropout and long events (e.g., on SWaT under additive noise F1 drops 0.804->0.677 for a graph autoencoder, 0.759->0.680 for a graph-attention variant, and 0.762->0.756 for a hybrid graph attention model); density/flow models work well on clean stationary plants but can be fragile to monotone drift; spectral CNNs lead when periodicity is strong; reconstruction autoencoders become competitive after basic sensor vetting; predictive/hybrid dynamics help when faults break temporal dependencies but remain window-sensitive. The protocol also informs design choices: on SWaT under log drift, replacing normalizing flows with Gaussian density reduces high-stress F1 from ~0.75 to ~0.57, and fixing a learned DAG gives a small clean-set gain (~0.5-1.0 points) but increases drift sensitivity by ~8x.

</details>


### [53] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 本文提出一个评估框架，系统检验CoT推理方法在简单规划任务上的泛化能力，发现CoT能改善分布内泛化，但分布外泛化有限，多格式文本推理表现最佳，纯文本模型优于图像输入模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和大视觉语言模型中的推理能力显著提升，但推理模型的泛化能力仍定义模糊且理解不足。需要系统评估CoT方法在简单规划任务上的泛化表现。

Method: 使用基于网格的导航任务作为评估框架，模型接收地图并输出从起点到终点的移动序列。通过不同输入表示（视觉和文本）和CoT推理策略微调模型变体，系统评估其在分布内和分布外测试条件下的表现。

Result: CoT推理能改善所有表示下的分布内泛化，但分布外泛化（如更大地图）在控制与分布内数据简单匹配后仍非常有限。结合多种文本格式的推理轨迹表现出最佳（且非平凡）的分布外泛化。纯文本模型始终优于使用图像输入的模型。

Conclusion: CoT推理在分布内任务上有效，但分布外泛化能力有限；多格式文本推理策略能提升泛化性能；纯文本表示在简单规划任务上优于视觉表示，包括潜在空间推理方法。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [54] [POP: Prior-fitted Optimizer Policies](https://arxiv.org/abs/2602.15473)
*Jan Kobiolka,Christian Frey,Gresa Shala,Arlind Kadra,Erind Bedalli,Josif Grabocka*

Main category: cs.LG

TL;DR: POP是一种元学习优化器，通过从包含凸和非凸目标的先验分布中学习，预测基于优化轨迹上下文信息的坐标步长，在47个优化函数基准测试中优于传统梯度方法、进化策略、贝叶斯优化和其他元学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的优化器对超参数选择高度敏感，在高度非凸设置中性能依赖于精心调整的学习率、动量和梯度累积。需要一种更鲁棒、无需任务特定调优的优化方法。

Method: 提出POP（Prior-fitted Optimizer Policies），一种元学习优化器，从包含凸和非凸目标的合成优化问题先验分布中学习，预测基于优化轨迹上下文信息的坐标步长。

Result: 在包含47个不同复杂度优化函数的基准测试中，POP在相同预算约束下一致优于一阶梯度方法、非凸优化方法（如进化策略）、贝叶斯优化和最近的元学习竞争对手，展示了强大的泛化能力。

Conclusion: POP通过元学习从广泛的先验分布中学习优化策略，提供了一种无需任务特定调优的高性能优化方法，在多种优化问题上表现出优越的泛化性能。

Abstract: Optimization refers to the task of finding extrema of an objective function. Classical gradient-based optimizers are highly sensitive to hyperparameter choices. In highly non-convex settings their performance relies on carefully tuned learning rates, momentum, and gradient accumulation. To address these limitations, we introduce POP (Prior-fitted Optimizer Policies), a meta-learned optimizer that predicts coordinate-wise step sizes conditioned on the contextual information provided in the optimization trajectory. Our model is learned on millions of synthetic optimization problems sampled from a novel prior spanning both convex and non-convex objectives. We evaluate POP on an established benchmark including 47 optimization functions of various complexity, where it consistently outperforms first-order gradient-based methods, non-convex optimization approaches (e.g., evolutionary strategies), Bayesian optimization, and a recent meta-learned competitor under matched budget constraints. Our evaluation demonstrates strong generalization capabilities without task-specific tuning.

</details>


### [55] [Evaluating Federated Learning for Cross-Country Mood Inference from Smartphone Sensing Data](https://arxiv.org/abs/2602.15478)
*Sharmad Kalpande,Saurabh Shirke,Haroon R. Lone*

Main category: cs.LG

TL;DR: FedFAP是一个特征感知的个性化联邦学习框架，用于从智能手机传感数据中推断情绪，在跨国家联邦学习设置中实现了0.744的AUROC，优于集中式方法和现有基线。


<details>
  <summary>Details</summary>
Motivation: 情绪不稳定是心理健康的关键行为指标，但传统评估依赖不频繁的回顾性报告，无法捕捉其连续性。基于智能手机的移动传感能够从日常行为中被动推断情绪，但在大规模部署时面临隐私约束、传感可用性不均和行为模式变异等挑战。

Method: 提出FedFAP（特征感知个性化联邦框架），在跨国家联邦学习设置中工作，每个国家作为独立客户端保留本地数据。该框架设计用于适应不同地区的异构传感模态，通过特征感知的个性化方法处理行为模式的变异性。

Result: 在跨地理和文化多样人群的评估中，FedFAP实现了0.744的AUROC，优于集中式方法和现有的个性化联邦基线。该框架不仅提高了情绪推断性能，还为情绪感知系统提供了设计见解。

Conclusion: FedFAP展示了基于人口感知的个性化和隐私保护学习如何实现可扩展的情绪感知移动传感技术。该工作为处理跨地区异构传感数据提供了有效的联邦学习解决方案，平衡了隐私保护与模型性能。

Abstract: Mood instability is a key behavioral indicator of mental health, yet traditional assessments rely on infrequent and retrospective reports that fail to capture its continuous nature. Smartphone-based mobile sensing enables passive, in-the-wild mood inference from everyday behaviors; however, deploying such systems at scale remains challenging due to privacy constraints, uneven sensing availability, and substantial variability in behavioral patterns.
  In this work, we study mood inference using smartphone sensing data in a cross-country federated learning setting, where each country participates as an independent client while retaining local data. We introduce FedFAP, a feature-aware personalized federated framework designed to accommodate heterogeneous sensing modalities across regions. Evaluations across geographically and culturally diverse populations show that FedFAP achieves an AUROC of 0.744, outperforming both centralized approaches and existing personalized federated baselines. Beyond inference, our results offer design insights for mood-aware systems, demonstrating how population-aware personalization and privacy-preserving learning can enable scalable and mood-aware mobile sensing technologies.

</details>


### [56] [LLM-as-Judge on a Budget](https://arxiv.org/abs/2602.15481)
*Aadirupa Saha,Aniket Wagde,Branislav Kveton*

Main category: cs.LG

TL;DR: 提出一种基于多臂老虎机理论和集中不等式的方差自适应方法，用于在固定计算预算下优化LLM评估中的查询分配，以最小化估计误差。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge评估技术需要多次查询每个提示-响应对以获得准确的平均分数，但在固定计算预算下，如何最优分配查询次数以最小化估计误差成为一个关键挑战。

Method: 基于多臂老虎机理论和集中不等式的方差自适应方法，动态分配查询资源到不确定性最高的地方，根据估计的分数方差进行预算分配。

Result: 在Summarize-From-Feedback和HelpSteer2数据集上的实验表明，该方法显著优于均匀分配，在相同预算下减少了最坏情况估计误差，实现了接近最优的预算分配。

Conclusion: 为高效LLM评估建立了理论基础，对AI安全、模型对齐和大规模自动评估具有实际意义，提供了一种在固定计算预算下优化评估质量的方法。

Abstract: LLM-as-a-judge has emerged as a cornerstone technique for evaluating large language models by leveraging LLM reasoning to score prompt-response pairs. Since LLM judgments are stochastic, practitioners commonly query each pair multiple times to estimate mean scores accurately. This raises a critical challenge: given a fixed computational budget $B$, how to optimally allocate queries across $K$ prompt-response pairs to minimize estimation error? %
We present a principled variance-adaptive approach leveraging multi-armed bandit theory and concentration inequalities. Our method dynamically allocates queries based on estimated score variances, concentrating resources where uncertainty is highest. Further, our algorithm is shown to achieve a worst-case score-estimation error of $\tilde{O}\left(\sqrt{\frac{\sum_{i=1}^K σ_i^2}{B}}\right)$, $σ_i^2$ being the unknown score variance for pair $i \in [K]$ with near-optimal budget allocation. %
Experiments on \emph{Summarize-From-Feedback} and \emph{HelpSteer2} demonstrate that our method significantly outperforms uniform allocation, reducing worst-case estimation error while maintaining identical budgets. Our work establishes a theoretical foundation for efficient LLM evaluation with practical implications for AI safety, model alignment, and automated assessment at scale.

</details>


### [57] [ExLipBaB: Exact Lipschitz Constant Computation for Piecewise Linear Neural Networks](https://arxiv.org/abs/2602.15499)
*Tom A. Splittgerber*

Main category: cs.LG

TL;DR: 本文提出了一种扩展LipBaB算法的方法，用于精确计算任意分段线性神经网络在p-范数下的Lipschitz常数，支持ReLU、LeakyReLU、GroupSort、MinMax、FullSort和MaxPool等多种激活函数。


<details>
  <summary>Details</summary>
Motivation: 神经网络Lipschitz常数在鲁棒性保证、正则化提升泛化能力和构建可逆网络等方面有重要应用。现有精确计算方法仅限于ReLU激活网络，而ReLU在Lipschitz约束网络中具有严重缺陷。需要一种能处理更广泛激活函数的精确计算方法。

Method: 扩展LipBaB算法，使其能够处理任意分段线性神经网络和p-范数。该方法支持传统激活函数（ReLU、LeakyReLU）以及近年来在Lipschitz约束网络中备受关注的GroupSort、MinMax、FullSort等激活函数，还包括MaxPool等其他分段线性函数。

Result: 提出了第一个能够精确计算任意分段线性神经网络Lipschitz常数的算法，突破了现有方法仅限于ReLU激活网络的限制，为更广泛的神经网络架构提供了精确Lipschitz常数计算能力。

Conclusion: 该扩展算法填补了精确Lipschitz常数计算领域的空白，使得在需要精确计算的场景（如新方法基准测试、敏感数据小模型鲁棒性保证）中能够使用更优的激活函数，推动了Lipschitz约束网络的发展。

Abstract: It has been shown that a neural network's Lipschitz constant can be leveraged to derive robustness guarantees, to improve generalizability via regularization or even to construct invertible networks. Therefore, a number of methods varying in the tightness of their bounds and their computational cost have been developed to approximate the Lipschitz constant for different classes of networks. However, comparatively little research exists on methods for exact computation, which has been shown to be NP-hard. Nonetheless, there are applications where one might readily accept the computational cost of an exact method. These applications could include the benchmarking of new methods or the computation of robustness guarantees for small models on sensitive data. Unfortunately, existing exact algorithms restrict themselves to only ReLU-activated networks, which are known to come with severe downsides in the context of Lipschitz-constrained networks. We therefore propose a generalization of the LipBaB algorithm to compute exact Lipschitz constants for arbitrary piecewise linear neural networks and $p$-norms. With our method, networks may contain traditional activations like ReLU or LeakyReLU, activations like GroupSort or the related MinMax and FullSort, which have been of increasing interest in the context of Lipschitz constrained networks, or even other piecewise linear functions like MaxPool.

</details>


### [58] [Approximation Theory for Lipschitz Continuous Transformers](https://arxiv.org/abs/2602.15503)
*Takashi Furuya,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 提出一种通过梯度流构造的Lipschitz连续Transformer，在保持表达能力的同时确保稳定性，并证明了其在Lipschitz约束函数空间中的通用逼近定理。


<details>
  <summary>Details</summary>
Motivation: 在安全敏感场景中部署Transformer需要稳定性和鲁棒性，但目前缺乏对显式保持Lipschitz连续性的架构的理论保证。

Method: 将MLP和注意力块实现为负梯度流的显式欧拉步，构造Lipschitz连续的梯度下降型上下文Transformer，并采用测度论形式将Transformer解释为概率测度上的算子。

Result: 证明了此类Lipschitz连续Transformer在Lipschitz约束函数空间中的通用逼近定理，且逼近保证与token数量无关。

Conclusion: 为设计鲁棒的Lipschitz连续Transformer架构提供了严格的理论基础，在保持表达能力的同时确保了稳定性。

Abstract: Stability and robustness are critical for deploying Transformers in safety-sensitive settings. A principled way to enforce such behavior is to constrain the model's Lipschitz constant. However, approximation-theoretic guarantees for architectures that explicitly preserve Lipschitz continuity have yet to be established. In this work, we bridge this gap by introducing a class of gradient-descent-type in-context Transformers that are Lipschitz-continuous by construction. We realize both MLP and attention blocks as explicit Euler steps of negative gradient flows, ensuring inherent stability without sacrificing expressivity. We prove a universal approximation theorem for this class within a Lipschitz-constrained function space. Crucially, our analysis adopts a measure-theoretic formalism, interpreting Transformers as operators on probability measures, to yield approximation guarantees independent of token count. These results provide a rigorous theoretical foundation for the design of robust, Lipschitz continuous Transformer architectures.

</details>


### [59] [On the Geometric Coherence of Global Aggregation in Federated GNN](https://arxiv.org/abs/2602.15510)
*Chethana Prasad Kabgere,Shylaja SS*

Main category: cs.LG

TL;DR: 该论文提出GGRS框架，解决联邦图神经网络中由于客户端图结构异质性导致全局聚合时关系变换几何特性破坏的问题。


<details>
  <summary>Details</summary>
Motivation: 在跨域联邦图神经网络中，客户端图具有异构的结构和传播特性。当标准聚合机制应用于这些异构更新时，全局模型可能在数值上收敛，但关系行为会退化。作者识别出全局聚合的几何失效模式：GNN参数虽然数值上表示为向量，但编码了控制图邻域信息流方向、强度和敏感性的关系变换。来自不兼容传播机制的更新聚合会在这个变换空间中引入破坏性干扰。

Method: 提出GGRS（全局几何参考结构），这是一个服务器端框架，基于几何可容许性准则在聚合前调节客户端更新。GGRS保持关系变换的方向一致性，维护可容许传播子空间的多样性，并稳定邻域交互的敏感性，同时不访问客户端数据或图拓扑。

Result: 在异构的GNN原生数据集和Amazon Co-purchase数据集上的实验表明，GGRS在训练轮次中保持了全局消息传递的连贯性，突出了联邦图学习中几何感知调节的必要性。

Conclusion: 该工作强调了联邦图神经网络中几何感知调节的重要性，提出的GGRS框架能有效解决由于客户端图结构异质性导致的全局聚合几何失效问题，保持关系变换的连贯性而不损害隐私。

Abstract: Federated Learning (FL) enables distributed training across multiple clients without centralized data sharing, while Graph Neural Networks (GNNs) model relational data through message passing. In federated GNN settings, client graphs often exhibit heterogeneous structural and propagation characteristics. When standard aggregation mechanisms are applied to such heterogeneous updates, the global model may converge numerically while exhibiting degraded relational behavior.Our work identifies a geometric failure mode of global aggregation in Cross- Domain Federated GNNs. Although GNN parameters are numerically represented as vectors, they encode relational transformations that govern the direction, strength, and sensitivity of information flow across graph neighborhoods. Aggregating updates originating from incompatible propagation regimes can therefore introduce destructive interference in this transformation space.This leads to loss of coherence in global message passing. Importantly, this degradation is not necessarily reflected in conventional metrics such as loss or accuracy.To address this issue, we propose GGRS (Global Geometric Reference Structure), a server-side framework that regulates client updates prior to aggregation based on geometric admissibility criteria. GGRS preserves directional consistency of relational transformations as well as maintains diversity of admissible propagation subspaces. It also stabilizes sensitivity to neighborhood interactions, without accessing client data or graph topology. Experiments on heterogeneous GNN-native, Amazon Co-purchase datasets demonstrate that GGRS preserves global message-passing coherence across training rounds by highlighting the necessity of geometry-aware regulation in federated graph learning.

</details>


### [60] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 训练AI系统对抗白盒欺骗检测器可能导致模型学会混淆其欺骗行为以逃避检测。研究在真实编码环境中发现，当存在通过硬编码测试用例进行奖励黑客攻击时，混淆策略会自然出现。


<details>
  <summary>Details</summary>
Motivation: 研究训练AI系统对抗白盒欺骗检测器的实际效果，担心这种训练可能导致模型学会混淆欺骗行为而非真正变得诚实。先前研究只在人工环境中考察混淆现象，本研究旨在更真实的环境中验证这一风险。

Method: 构建真实的编码环境，其中通过硬编码测试用例进行奖励黑客攻击自然发生。引入训练对抗欺骗检测器可能结果的分类法，包括诚实行为、混淆激活和混淆策略三种情况。通过实证研究分析混淆激活和混淆策略的出现条件。

Result: 在真实编码环境中确实出现了混淆现象。混淆激活主要来自强化学习过程中的表示漂移，无论是否有检测器惩罚都会发生。检测器惩罚只激励混淆策略；理论上证明这在策略梯度方法中是预期的。足够高的KL正则化和检测器惩罚可以产生诚实策略。

Conclusion: 白盒欺骗检测器可以作为易受奖励黑客攻击任务的可行训练信号，但需要足够高的KL正则化和检测器惩罚来确保模型保持诚实，而不是学会混淆欺骗行为。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [61] [CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals](https://arxiv.org/abs/2602.15546)
*Tomàs Garriga,Gerard Sanz,Eduard Serrahima de Cambra,Axel Brando*

Main category: cs.LG

TL;DR: 本文提出了一种针对时间序列数据的反事实推理方法CEPAE，通过熵惩罚损失促进潜在空间解耦表示，在合成和真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在金融、医疗和营销等领域，准确的时间序列反事实推理对于决策至关重要，可以帮助理解事件或干预对时间序列结果的影响。本文受工业应用驱动，针对受市场事件影响的时间序列数据开发反事实推理方法。

Method: 基于结构因果模型框架和溯因-行动-预测程序，首先将变分自编码器和对抗自编码器方法适配到时间序列设置。然后提出条件熵惩罚自编码器（CEPAE），通过在潜在空间使用熵惩罚损失来鼓励解耦的数据表示。

Result: 在合成、半合成和真实世界数据集上的实验验证表明，CEPAE在评估指标上通常优于其他方法。

Conclusion: CEPAE是一种有效的自编码器基础反事实推理方法，通过熵惩罚机制促进潜在空间解耦，在时间序列反事实推理任务中表现出优越性能。

Abstract: The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.

</details>


### [62] [1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization](https://arxiv.org/abs/2602.15563)
*Sohir Maskey,Constantin Eichenberg,Johannes Messner,Douglas Orr*

Main category: cs.LG

TL;DR: 本文通过实证研究发现，在低比特量化中，k-means权重量化优于整数格式，且在固定推理内存预算下，1比特量化权重在生成式下游任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 量化感知训练(QAT)能大幅减少LLMs内存占用，但实际应用中量化格式和比特宽度的最优选择存在挑战。现有研究未充分探索QAT的完整设计空间，量化与下游性能的权衡关系理解不足，比较通常仅基于困惑度评估。

Method: 在低比特量化范围内进行QAT的实证研究，比较k-means权重量化与整数格式的性能差异，并在标准硬件上实现高效部署。

Result: k-means权重量化优于整数格式，可在标准硬件上高效实现。在固定推理内存预算下，生成式下游任务的最佳性能通过1比特量化权重实现。

Conclusion: k-means量化是低比特QAT的有效方法，1比特量化权重在内存受限场景下能为生成式任务提供最佳性能权衡。

Abstract: Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.

</details>


### [63] [Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment](https://arxiv.org/abs/2602.15571)
*Davide Casnici,Martin Lefebvre,Justin Dauwels,Charlotte Frenkel*

Main category: cs.LG

TL;DR: DKP-PC是一种改进的预测编码算法，通过引入可学习的反馈连接，将误差传播的时间复杂度从O(L)降低到O(1)，解决了传统PC算法中误差信号传播延迟和指数衰减的问题。


<details>
  <summary>Details</summary>
Motivation: 传统预测编码(PC)算法虽然基于局部更新实现并行学习，但在实际应用中存在两个关键限制：1）误差信号需要通过多个推理步骤从输出层传播到早期层，2）反馈信号在传播过程中呈指数衰减，导致早期层更新消失。这些问题限制了PC算法的效率和可扩展性。

Method: 提出直接Kolen-Pollack预测编码(DKP-PC)，结合直接反馈对齐和直接Kolen-Pollack算法，引入从输出层到所有隐藏层的可学习反馈连接，建立误差传输的直接路径。这种方法保持了更新的局部性，同时显著改善了误差传播效率。

Result: DKP-PC将误差传播的时间复杂度从O(L)降低到O(1)，消除了深度相关的误差信号延迟。实验结果表明，DKP-PC的性能至少与标准PC相当，甚至常常超过标准PC，同时提供了更低的延迟和更好的计算性能。

Conclusion: DKP-PC通过解决传统PC算法的反馈延迟和指数衰减问题，提供了一个更高效、可扩展的预测编码变体，特别适合定制硬件的高效实现，为生物启发式学习算法在实际应用中的部署提供了有前景的解决方案。

Abstract: Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.

</details>


### [64] [Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model](https://arxiv.org/abs/2602.15572)
*M Lopes Alves,Joel Dyer,Doyne Farmer,Michael Wooldridge,Anisoara Calinescu*

Main category: cs.LG

TL;DR: 该研究评估了基于神经网络的模拟推理框架在大型劳动力市场ABM参数估计中的应用，相比传统贝叶斯方法提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然基于代理的建模（ABM）在模拟复杂系统方面应用广泛，但大规模ABM的参数估计面临计算限制，这限制了其作为决策支持工具的使用。需要更高效的参数估计方法来克服这一挑战。

Method: 研究评估了最先进的基于神经网络的模拟推理（SBI）框架，应用于基于工作转换网络的劳动力市场ABM。使用合成数据集和真实美国劳动力市场数据初始化ABM，并比较了传统统计度量生成的摘要统计量与神经网络学习到的摘要统计量的效果。

Result: 结果表明，基于神经网络的方法在不同数据集规模下都能通过后验分布恢复原始参数，并且相比传统贝叶斯方法提高了效率。

Conclusion: 基于神经网络的模拟推理框架为大规模ABM的参数估计提供了有效的解决方案，能够克服传统方法的计算限制，提高参数估计的效率和准确性。

Abstract: Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.

</details>


### [65] [Uniform error bounds for quantized dynamical models](https://arxiv.org/abs/2602.15586)
*Abdelkader Metakalard,Fabien Lauer,Kevin Colin,Marion Gilson*

Main category: cs.LG

TL;DR: 该论文为从依赖数据序列学习动态模型的准确性提供统计保证，开发了适用于量化模型和不完美优化算法的统一误差界，通过块分解和间隔点策略获得两种边界，边界规模与编码模型所需比特数相关。


<details>
  <summary>Details</summary>
Motivation: 在实际系统辨识（特别是混合系统辨识）中，通常使用量化模型和不完美的优化算法，需要为这些实际场景中的动态模型学习提供统计保证。

Method: 开发统一误差界，通过块分解获得慢速率边界，通过新颖的间隔点策略获得快速率、方差自适应边界。边界规模与编码模型所需比特数相关，将硬件约束转化为可解释的统计复杂度。

Result: 获得两种边界族：通过块分解的慢速率边界和通过间隔点策略的快速率、方差自适应边界。这些边界能够将硬件约束（如量化比特数）转化为统计复杂性度量。

Conclusion: 该研究为从依赖数据学习动态模型提供了统计保证框架，特别适用于实际系统辨识中的量化模型和优化算法，通过编码比特数将硬件限制与统计性能联系起来。

Abstract: This paper provides statistical guarantees on the accuracy of dynamical models learned from dependent data sequences. Specifically, we develop uniform error bounds that apply to quantized models and imperfect optimization algorithms commonly used in practical contexts for system identification, and in particular hybrid system identification. Two families of bounds are obtained: slow-rate bounds via a block decomposition and fast-rate, variance-adaptive, bounds via a novel spaced-point strategy. The bounds scale with the number of bits required to encode the model and thus translate hardware constraints into interpretable statistical complexities.

</details>


### [66] [A unified theory of feature learning in RNNs and DNNs](https://arxiv.org/abs/2602.15593)
*Jan P. Bauer,Kirsten Fischer,Moritz Helias,Agostina Palmigiano*

Main category: cs.LG

TL;DR: 该论文通过统一的平均场理论，揭示了RNN和DNN在权重共享方面的结构相似性如何导致不同的功能特性，识别了相变阈值并解释了RNN在序列任务中的归纳偏置优势。


<details>
  <summary>Details</summary>
Motivation: 尽管RNN和DNN在结构上仅通过权重共享区分（通过时间展开可见），但它们表现出不同的功能特性。研究者希望理解这种结构相似性如何与功能差异相协调，探究权重共享对网络功能的影响。

Method: 开发了RNN和DNN的统一平均场理论，使用表征核描述在特征学习（μP）机制下完全训练的网络。该理论将训练视为对序列和模式的贝叶斯推断，直接揭示RNN权重共享引起的功能含义。

Result: 在DNN典型任务中，识别了一个相变阈值：当学习信号克服权重随机性产生的噪声时，低于阈值RNN和DNN行为相同；高于阈值时，只有RNN能在时间步之间发展相关表征。对于序列任务，RNN的权重共享诱导了归纳偏置，通过插值无监督时间步来帮助泛化。

Conclusion: 该理论提供了一种将架构结构与功能偏置连接的方法，揭示了权重共享如何使RNN在序列处理中发展时间相关表征，并解释了RNN在泛化方面的优势。

Abstract: Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.

</details>


### [67] [Multi-Objective Coverage via Constraint Active Search](https://arxiv.org/abs/2602.15595)
*Zakaria Shams Siam,Xuefeng Liu,Chong Liu*

Main category: cs.LG

TL;DR: 提出多目标覆盖（MOC）问题，旨在识别能广泛覆盖可行多目标空间的小规模代表性样本集，并开发MOC-CAS算法解决该问题，在蛋白质靶点数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和材料设计等关键应用中，需要快速评估代表性样本集以加速科学发现过程。现有方法无法直接应用，因为它们要么关注样本空间覆盖，要么专注于帕累托前沿的多目标优化，而化学多样性样本常产生相同的目标分布，且安全约束通常定义在目标上。

Method: 提出MOC-CAS搜索算法，采用基于上置信界的采集函数，在高斯过程后验预测指导下选择乐观样本。为高效优化，开发了硬可行性测试的平滑松弛方法并推导近似优化器。

Result: 在SARS-CoV-2和癌症相关的大规模蛋白质靶点数据集上，与竞争基线相比，MOC-CAS在基于SMILES特征的五个目标评估中取得了优越性能。

Conclusion: MOC-CAS算法能有效解决多目标覆盖问题，识别出能广泛覆盖可行多目标空间的小规模代表性样本集，显著加速药物发现等科学过程。

Abstract: In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse samples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predictions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features.

</details>


### [68] [Certified Per-Instance Unlearning Using Individual Sensitivity Bounds](https://arxiv.org/abs/2602.15602)
*Hanna Benarroch,Jamal Atif,Olivier Cappé*

Main category: cs.LG

TL;DR: 提出一种基于自适应逐实例噪声校准的认证机器遗忘方法，相比传统基于最坏情况敏感性的差分隐私方法，能显著减少噪声注入并保持性能


<details>
  <summary>Details</summary>
Motivation: 传统基于差分隐私的认证机器遗忘方法采用最坏情况敏感性校准噪声，导致性能显著下降，限制了实际应用。需要一种更精细的噪声校准方法，根据每个数据点对学习解的个体贡献来调整噪声

Method: 提出基于逐实例差分隐私的自适应噪声校准方法，针对岭回归的Langevin动力学训练，推导出高概率的逐实例敏感性边界，实现认证遗忘

Result: 理论分析表明该方法能显著减少噪声注入，在线性设置实验中验证了理论发现，并在深度学习设置中提供了进一步实证证据

Conclusion: 通过逐实例敏感性分析和自适应噪声校准，实现了更高效的认证机器遗忘，在保持隐私保证的同时减少了性能损失，为实际应用提供了可行方案

Abstract: Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.

</details>


### [69] [Symbolic recovery of PDEs from measurement data](https://arxiv.org/abs/2602.15603)
*Erion Morina,Philipp Scholl,Martin Holler*

Main category: cs.LG

TL;DR: 该论文提出使用基于有理函数的神经网络架构进行PDE模型符号化重建，证明了在无噪声完整测量下可唯一重建最简单的物理定律，并通过ParFam架构进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: PDE模型能描述自然科学中的复杂关系，但传统方法难以从间接噪声测量中重建符号表达式，阻碍了模型的可解释性。需要开发能生成符号表达式的专门方法。

Method: 采用基于有理函数的神经网络架构进行物理定律的符号表示，利用有理函数的逼近能力和算术运算灵活性。通过可识别性理论证明，在无噪声完整测量下能唯一重建最简单的物理定律。

Result: 理论证明符号网络能唯一重建物理定律，重建定律保持符号网络架构内的可表达性，L1正则化促进可解释性和稀疏性。通过ParFam架构的实证验证支持理论发现。

Conclusion: 基于有理函数的符号网络架构能有效重建PDE模型的物理定律，在理论可识别性和实际重建性方面都表现出色，为物理定律的符号化重建提供了可行方案。

Abstract: Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.

</details>


### [70] [DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness](https://arxiv.org/abs/2602.15617)
*Kaifeng Lu,Markus Rupp,Stefan Schwarz*

Main category: cs.LG

TL;DR: 提出基于无线Transformer架构的优化无监督学习方法，通过拉格朗日乘子自动更新机制，在保证预设公平性的同时最大化总速率，实现帕累托前沿上的可控权衡。


<details>
  <summary>Details</summary>
Motivation: 无线通信中用户公平性保障是一个基本挑战，公平性与总速率之间的权衡导致非凸、多目标优化问题，其复杂度随网络规模增长而增加。

Method: 基于无线Transformer架构的优化无监督学习方法，通过拉格朗日乘子将总速率和公平性目标结合，采用对偶上升算法自动更新乘子，实现可控的公平性约束。

Result: 该方法能够在规定公平性要求下灵活管理权衡优化，有效实现两个冲突目标之间的帕累托前沿追踪。

Conclusion: 所提出的方法为在预设公平性条件下管理权衡优化提供了灵活解决方案，解决了无线通信中公平性与总速率之间的复杂权衡问题。

Abstract: Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.

</details>


### [71] [Beyond ReLU: Bifurcation, Oversmoothing, and Topological Priors](https://arxiv.org/abs/2602.15634)
*Erkan Turan,Gaspard Abel,Maysam Behmanesh,Emery Pierson,Maks Ovsjanikov*

Main category: cs.LG

TL;DR: 论文从分岔理论角度重新定义GNN过平滑问题，提出通过替换激活函数引发分岔来破坏均匀稳定状态，从而抵抗过平滑。


<details>
  <summary>Details</summary>
Motivation: 深度图神经网络存在过平滑问题，节点特征收敛到同质化、无信息状态。现有方法未能从动力系统角度深入理解这一现象的本质。

Method: 采用分岔理论框架，将过平滑重新定义为向稳定"均匀固定点"的收敛。通过Lyapunov-Schmidt约简分析，证明用特定函数类替换单调激活函数可引发分岔，破坏均匀状态的稳定性，产生稳定的非均匀模式。

Result: 理论预测了新兴模式振幅的精确非平凡标度律，并通过实验定量验证。推导出闭式分岔感知初始化方法，在真实基准实验中显示出实用性。

Conclusion: 从分岔理论视角为GNN过平滑问题提供了新的理论框架，不仅解释了现象本质，还提出了实用的解决方案，为设计抗过平滑的深度GNN提供了理论基础。

Abstract: Graph Neural Networks (GNNs) learn node representations through iterative network-based message-passing. While powerful, deep GNNs suffer from oversmoothing, where node features converge to a homogeneous, non-informative state. We re-frame this problem of representational collapse from a \emph{bifurcation theory} perspective, characterizing oversmoothing as convergence to a stable ``homogeneous fixed point.'' Our central contribution is the theoretical discovery that this undesired stability can be broken by replacing standard monotone activations (e.g., ReLU) with a class of functions. Using Lyapunov-Schmidt reduction, we analytically prove that this substitution induces a bifurcation that destabilizes the homogeneous state and creates a new pair of stable, non-homogeneous \emph{patterns} that provably resist oversmoothing. Our theory predicts a precise, nontrivial scaling law for the amplitude of these emergent patterns, which we quantitatively validate in experiments. Finally, we demonstrate the practical utility of our theory by deriving a closed-form, bifurcation-aware initialization and showing its utility in real benchmark experiments.

</details>


### [72] [The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems](https://arxiv.org/abs/2602.15637)
*Amirreza Dolatpour Fathkouhi,Alireza Namazi,Heman Shakeri*

Main category: cs.LG

TL;DR: 论文揭示时间序列插补基准存在"平稳性偏差"，提出分层压力测试方法，发现线性插值在平稳区间表现优异，但在关键瞬态区间深度学习方法能更好地保持信号形态完整性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列插补基准使用均匀随机掩码和形状无关指标（如MSE、RMSE），在具有主导吸引子的系统中（如稳态生理学、工业操作、网络流量）会产生系统性"平稳性偏差"——简单方法因主要在低熵的平稳区间采样而显得优越，掩盖了在关键瞬态区间的性能缺陷。

Method: 提出"分层压力测试"方法，将评估划分为平稳和瞬态两种状态；使用连续血糖监测作为测试平台，利用其精确的地面真实强制函数（饮食、胰岛素）进行精确状态识别；从临床试验中推导经验缺失分布并应用于完整训练数据，防止模型利用不现实的干净观测。

Result: 发现三个关键结果：1）线性插值在平稳区间达到最先进的重建效果；2）在关键瞬态期间，线性方法表现出严重退化的形态保真度，出现"RMSE幻象"现象；3）深度学习模型在瞬态期间能同时保持点精度和形态完整性。

Conclusion: 该框架适用于任何常规平稳性主导关键瞬态的受调节系统，强调需要基于状态的条件模型选择，深度学习模型对于安全关键的下游任务至关重要，特别是在需要保持信号形态完整性的瞬态区间。

Abstract: Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systematic \emph{Stationarity Bias}: simple methods appear superior because the benchmark predominantly samples the easy, low-entropy regime where they trivially succeed. We formalize this bias and propose a \emph{Stratified Stress-Test} that partitions evaluation into Stationary and Transient regimes. Using Continuous Glucose Monitoring (CGM) as a testbed -- chosen for its rigorous ground-truth forcing functions (meals, insulin) that enable precise regime identification -- we establish three findings with broad implications:(i)~Stationary Efficiency: Linear interpolation achieves state-of-the-art reconstruction during stable intervals, confirming that complex architectures are computationally wasteful in low-entropy regimes.(ii)~Transient Fidelity: During critical transients (post-prandial peaks, hypoglycemic events), linear methods exhibit drastically degraded morphological fidelity (DTW), disproportionate to their RMSE -- a phenomenon we term the \emph{RMSE Mirage}, where low pointwise error masks the destruction of signal shape.(iii)~Regime-Conditional Model Selection: Deep learning models preserve both pointwise accuracy and morphological integrity during transients, making them essential for safety-critical downstream tasks. We further derive empirical missingness distributions from clinical trials and impose them on complete training data, preventing models from exploiting unrealistically clean observations and encouraging robustness under real-world missingness. This framework generalizes to any regulated system where routine stationarity dominates critical transients.

</details>


### [73] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 提出基于扩散模型的逆设计方法，通过连续网格表示和可微分仿真实现梯度优化，用于复合材料设计，能生成满足目标体积模量的多样化设计方案。


<details>
  <summary>Details</summary>
Motivation: 逆设计问题在工程和材料科学中常见，但设计空间结构复杂（离散参数、约束条件）阻碍了基于梯度的优化方法。许多设计参数可能产生相同或相似的输出值，需要多模态概率方法获得多样化解决方案。

Method: 1. 将原始设计空间松弛为连续网格表示，通过隐式微分计算梯度；2. 在松弛参数空间上训练扩散模型作为先验；3. 使用可微分仿真的梯度进行引导扩散采样；4. 通过反向投影获得原始参数空间的设计样本。

Result: 在复合材料设计问题中（前向过程为线性FEM），该方法能在2D和3D设置中为中高目标体积模量生成相对误差在1%以内的多样化设计。通过多目标损失函数还能同时最小化材料密度。

Conclusion: 提出的基于扩散模型的逆设计方法能有效处理复杂设计空间，生成满足性能要求的多样化设计方案，为工程和材料科学中的逆设计问题提供了新解决方案。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [74] [Continuous-Time Piecewise-Linear Recurrent Neural Networks](https://arxiv.org/abs/2602.15649)
*Alena Brändle,Lukas Eisenmann,Florian Götz,Daniel Durstewitz*

Main category: cs.LG

TL;DR: 提出连续时间分段线性循环神经网络(cPLRNN)，解决现有离散时间PLRNN无法处理连续时间过程和不规则时间间隔数据的问题，同时保持数学可分析性。


<details>
  <summary>Details</summary>
Motivation: 现有PLRNN虽然具有数学可分析性且在动态系统重建中表现优异，但都是离散时间模型，这与大多数物理和生物过程的连续时间本质不符，也难以处理不规则时间间隔的数据。神经ODE虽然处理连续时间，但性能不如PLRNN且缺乏可分析性。

Method: 开发连续时间PLRNN(cPLRNN)理论，提出新的训练和模拟算法，通过有效利用分段线性结构绕过数值积分。同时展示如何半解析地确定训练模型中重要的拓扑对象（如平衡点、极限环）。

Result: 在动态系统重建基准测试中，将cPLRNN与离散时间PLRNN和神经ODE进行比较，包括具有硬阈值的不连续系统。

Conclusion: cPLRNN结合了连续时间建模的优势和PLRNN的数学可分析性，为处理不规则时间间隔数据和连续时间过程提供了更好的解决方案。

Abstract: In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In scientific and medical areas, in particular, these models need to be mechanistically tractable -- through their mathematical analysis we would like to obtain insight into the recovered system's workings. Piecewise-linear (PL), ReLU-based RNNs (PLRNNs) have a strong track-record in this regard, representing SOTA DSR models while allowing mathematical insight by virtue of their PL design. However, all current PLRNN variants are discrete-time maps. This is in disaccord with the assumed continuous-time nature of most physical and biological processes, and makes it hard to accommodate data arriving at irregular temporal intervals. Neural ODEs are one solution, but they do not reach the DSR performance of PLRNNs and often lack their tractability. Here we develop theory for continuous-time PLRNNs (cPLRNNs): We present a novel algorithm for training and simulating such models, bypassing numerical integration by efficiently exploiting their PL structure. We further demonstrate how important topological objects like equilibria or limit cycles can be determined semi-analytically in trained models. We compare cPLRNNs to both their discrete-time cousins as well as Neural ODEs on DSR benchmarks, including systems with discontinuities which come with hard thresholds.

</details>


### [75] [Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry](https://arxiv.org/abs/2602.15676)
*Deniz Kucukahmetler,Maximilian Jean Hemmann,Julian Mosig von Aehrenfeld,Maximilian Amthor,Christian Deubel,Nico Scherf,Diaaeldin Taha*

Main category: cs.LG

TL;DR: 研究通过相对几何嵌入分析神经网络在预测复杂动力系统时如何内部表示潜在几何结构，发现不同模型家族（MLP、RNN、Transformer等）在表示对齐上呈现家族级模式，对齐度与预测精度相关但不完全一致。


<details>
  <summary>Details</summary>
Motivation: 神经网络能够准确预测复杂动力系统，但其内部如何表示底层潜在几何结构仍不清楚。研究旨在通过表示对齐的视角，理解不同神经网络模型家族如何内部化并表示动力系统的结构。

Method: 引入基于锚点的、几何无关的相对嵌入方法，消除潜在空间中的旋转和缩放歧义。将该框架应用于七个典型动力系统（从周期性到混沌系统），分析多层感知机、循环神经网络、Transformer和回声状态网络等不同模型家族的表示对齐特性。

Result: 发现可复现的家族级结构：多层感知机与MLP对齐，循环网络与RNN对齐，而Transformer和回声状态网络虽然能实现强预测，但对齐度较弱。对齐度通常与预测精度相关，但高精度也可能与低对齐共存。

Conclusion: 相对几何为比较不同模型家族如何内部化和表示动力结构提供了一个简单、可复现的基础框架，揭示了神经网络表示动力系统的内在模式。

Abstract: Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.

</details>


### [76] [CAMEL: An ECG Language Model for Forecasting Cardiac Events](https://arxiv.org/abs/2602.15677)
*Neelay Velingker,Alaia Solko-Breslin,Mayank Keoliya,Seewon Choi,Jiayi Xin,Anika Marathe,Alireza Oraii,Rajat Deo,Sameed Khatana,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAMEL是首个能够进行心电图长期信号推理和未来心脏事件预测的心电图语言模型，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前的心电图语言模型虽然能进行分类和报告生成，但无法预测未来心脏事件，而这对早期干预具有重要临床价值。

Method: 提出专门的心电图编码器实现心电图与文本的跨模态理解，采用LoRA适配和课程学习流程训练，包括心电图分类、指标计算和多轮对话推理。

Result: 在6个任务和9个数据集上表现出强大的零样本性能，在ECGBench上获得+7.0%绝对平均增益，在ECGForecastBench上比全监督模型高+12.4%，比零样本ELMs高+21.1%。

Conclusion: CAMEL是首个能够进行长期信号推理和心律失常预测的心电图语言模型，在分布内和分布外都表现出优异性能，为临床早期干预提供了新工具。

Abstract: Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).

</details>


### [77] [Controlled oscillation modeling using port-Hamiltonian neural networks](https://arxiv.org/abs/2602.15704)
*Maximino Linares,Guillaume Doras,Thomas Hélie*

Main category: cs.LG

TL;DR: 本文提出将二阶离散梯度方法嵌入端口哈密顿神经网络中学习动力系统，相比同阶Runge-Kutta方法表现更优，并在三个不同动力学行为的受控系统中验证了效果。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动方法学习动力系统难以掌握守恒定律，现有端口哈密顿神经网络方法虽基于功率平衡原理，但通常不考虑功率保持离散化，且依赖Runge-Kutta数值方法。

Method: 在端口哈密顿神经网络学习动力系统时嵌入二阶离散梯度方法，该方法能保持功率守恒特性。实验比较了两种理论上等效的端口哈密顿系统表述，并分析了训练期间正则化雅可比矩阵的影响。

Result: 在三个受控动力系统（基线谐振子、Duffing振子、自持振子）上的数值结果表明，离散梯度方法优于同阶Runge-Kutta方法，能更好地处理不同范围的动力学行为。

Conclusion: 将离散梯度方法嵌入端口哈密顿神经网络能提高学习效果，特别是在保持功率守恒特性方面，为学习具有复杂动力学行为的受控系统提供了更优的数值框架。

Abstract: Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training.

</details>


### [78] [Random Wavelet Features for Graph Kernel Machines](https://arxiv.org/abs/2602.15711)
*Valentin de Bassompierre,Jean-Charles Delvenne,Laurent Jacques*

Main category: cs.LG

TL;DR: 该论文提出了一种基于随机特征方法的随机谱节点嵌入，用于高效近似图核，在保持结构信息的同时实现可扩展的图表示学习。


<details>
  <summary>Details</summary>
Motivation: 图核提供了定义节点相似度的原则性方法，但直接计算在大规模网络上计算成本过高。需要设计能够高效近似图核的节点嵌入方法。

Method: 受欧几里得空间中核近似的随机特征方法启发，提出了随机谱节点嵌入，其点积能够估计特定图核的低秩近似。

Result: 理论和实证结果表明，该方法比现有方法实现了更准确的核近似，特别是在谱局部化核方面表现优异。

Conclusion: 随机谱构造为可扩展且原则性的图表示学习提供了有效方法，能够高效近似图核并保持结构信息。

Abstract: Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.

</details>


### [79] [MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740)
*Fatemeh Khalvandi,Saadat Izadi,Abdolah Chalechale*

Main category: cs.LG

TL;DR: 提出MRC-GAT模型，通过copula相似性对齐、关系注意力和节点融合，结合元学习进行阿尔茨海默病多模态分类，在TADPOLE和NACC数据集上达到96.87%和92.31%的准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病需要早期精确诊断，现有图模型大多依赖固定结构设计，缺乏灵活性且难以泛化到异质患者数据。

Method: 提出Meta-Relational Copula-Based Graph Attention Network (MRC-GAT)，整合copula相似性对齐、关系注意力和节点融合作为元学习核心组件，将风险因素、认知测试分数和MRI特征等多模态数据在统一统计空间对齐后通过多关系注意力机制融合。

Result: 在TADPOLE和NACC数据集上分别达到96.87%和92.31%的准确率，优于现有诊断模型，并展示了模型在不同疾病阶段的解释性。

Conclusion: MRC-GAT模型通过灵活的图结构和多模态融合机制，在阿尔茨海默病分类任务中表现出优越性能和泛化能力，同时提供可解释性验证了方法的鲁棒性和适用性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.

</details>


### [80] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse：一个用于跨城市表示学习和跨任务分析的通用城市分析基础模型，通过图结构随机游走和条件扩散模块实现城市和任务间的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有城市区域表示学习方法在城市间和任务间的泛化能力有限，需要建立一个类似基础模型的城市分析框架，能够适应不同城市和多种分析任务。

Method: 1) 将区域建模为图节点，通过随机游走生成反映局部和邻域结构特征的"区域序列"；2) 提出HCondDiffCT跨任务学习模块，将区域条件先验知识和任务条件语义集成到扩散过程中，联合建模多个下游预测任务。

Result: 在真实世界数据集上的实验表明，UrbanVerse在跨城市设置的六个任务中始终优于最先进方法，预测准确率提升高达35.89%。

Conclusion: UrbanVerse成功实现了跨城市和跨任务的城市表示学习，为城市分析提供了一个通用基础模型，其模块化设计也能增强现有模型的性能。

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [81] [Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching](https://arxiv.org/abs/2602.15752)
*Ren Kishimoto,Rikiya Takehi,Koichi Tanaka,Masahiro Nomura,Riku Togashi,Yoji Tomita,Yuta Saito*

Main category: cs.LG

TL;DR: 提出MRet算法，通过个性化留存曲线建模，在双边匹配平台中最大化用户留存而非匹配数量或公平性


<details>
  <summary>Details</summary>
Motivation: 传统双边匹配平台（如在线约会、招聘）通常以最大化匹配数量为目标，但这会导致用户匹配分布不均：部分用户获得过多匹配，而许多用户获得很少匹配并最终流失。对于依赖订阅的平台，用户留存至关重要。虽然公平性目标可以解决匹配最大化的问题，但公平性本身并非平台的最终目标，用户不会仅仅因为曝光均等就奖励平台。在实践中，用户留存往往是最终目标，盲目依赖公平性会让留存优化变得随机。

Method: 提出MRet（Matching for Retention）算法，这是一种动态学习排序方法。不同于传统的双边匹配算法，MRet通过学习每个用户的个人资料和交互历史来建模个性化留存曲线。基于这些曲线，MRet动态调整推荐策略，联合考虑接收推荐用户和被推荐用户的留存收益，从而将有限的匹配机会分配到最能提升整体留存的地方。

Result: 在合成数据集和来自主要在线约会平台的真实数据集上的实证评估表明，MRet实现了更高的用户留存率，因为传统方法优化的是匹配数量或公平性，而不是留存。

Conclusion: 在双边匹配平台中，直接优化用户留存比传统方法（最大化匹配或公平性）更有效。MRet算法通过建模个性化留存曲线并动态调整推荐策略，能够显著提升平台的整体用户留存。

Abstract: On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck.
  In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.

</details>


### [82] [GLM-5: from Vibe Coding to Agentic Engineering](https://arxiv.org/abs/2602.15763)
*GLM-5 Team,:,Aohan Zeng,Xin Lv,Zhenyu Hou,Zhengxiao Du,Qinkai Zheng,Bin Chen,Da Yin,Chendi Ge,Chengxing Xie,Cunxiang Wang,Gengzheng Pan,Hao Zeng,Haoke Zhang,Haoran Wang,Huilong Chen,Jiajie Zhang,Jian Jiao,Jiaqi Guo,Jingsen Wang,Jingzhao Du,Jinzhu Wu,Kedong Wang,Lei Li,Lin Fan,Lucen Zhong,Mingdao Liu,Mingming Zhao,Pengfan Du,Qian Dong,Rui Lu,Shuang-Li,Shulin Cao,Song Liu,Ting Jiang,Xiaodong Chen,Xiaohan Zhang,Xuancheng Huang,Xuezhen Dong,Yabo Xu,Yao Wei,Yifan An,Yilin Niu,Yitong Zhu,Yuanhao Wen,Yukuo Cen,Yushi Bai,Zhongpei Qiao,Zihan Wang,Zikang Wang,Zilin Zhu,Ziqiang Liu,Zixuan Li,Bojie Wang,Bosi Wen,Can Huang,Changpeng Cai,Chao Yu,Chen Li,Chen Li,Chenghua Huang,Chengwei Hu,Chenhui Zhang,Chenzheng Zhu,Congfeng Yin,Daoyan Lin,Dayong Yang,Di Wang,Ding Ai,Erle Zhu,Fangzhou Yi,Feiyu Chen,Guohong Wen,Hailong Sun,Haisha Zhao,Haiyi Hu,Hanchen Zhang,Hanrui Liu,Hanyu Zhang,Hao Peng,Hao Tai,Haobo Zhang,He Liu,Hongwei Wang,Hongxi Yan,Hongyu Ge,Huan Liu,Huan Liu,Huanpeng Chu,Jia'ni Zhao,Jiachen Wang,Jiajing Zhao,Jiamin Ren,Jiapeng Wang,Jiaxin Zhang,Jiayi Gui,Jiayue Zhao,Jijie Li,Jing An,Jing Li,Jingwei Yuan,Jinhua Du,Jinxin Liu,Junkai Zhi,Junwen Duan,Kaiyue Zhou,Kangjian Wei,Ke Wang,Keyun Luo,Laiqiang Zhang,Leigang Sha,Liang Xu,Lindong Wu,Lintao Ding,Lu Chen,Minghao Li,Nianyi Lin,Pan Ta,Qiang Zou,Rongjun Song,Ruiqi Yang,Shangqing Tu,Shangtong Yang,Shaoxiang Wu,Shengyan Zhang,Shijie Li,Shuang Li,Shuyi Fan,Wei Qin,Wei Tian,Weining Zhang,Wenbo Yu,Wenjie Liang,Xiang Kuang,Xiangmeng Cheng,Xiangyang Li,Xiaoquan Yan,Xiaowei Hu,Xiaoying Ling,Xing Fan,Xingye Xia,Xinyuan Zhang,Xinze Zhang,Xirui Pan,Xunkai Zhang,Yandong Wu,Yanfu Li,Yidong Wang,Yifan Zhu,Yijun Tan,Yilin Zhou,Yiming Pan,Ying Zhang,Yinpei Su,Yipeng Geng,Yipeng Geng,Yong Yan,Yonglin Tan,Yuean Bi,Yuhan Shen,Yuhao Yang,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yurong Wu,Yutao Zhang,Yuxi Duan,Yuxuan Zhang,Zezhen Liu,Zhengtao Jiang,Zhenhe Yan,Zheyu Zhang,Zhixiang Wei,Zhuo Chen,Zhuoer Feng,Zijun Yao,Ziwei Chai,Ziyuan Wang,Zuzhou Zhang,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.LG

TL;DR: GLM-5是一个下一代基础模型，旨在将"氛围编码"范式转向"代理工程"，通过DSA降低训练推理成本，采用异步强化学习提升对齐和自主性，在主要开放基准上达到SOTA，在真实世界编码任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 将当前的"氛围编码"范式转向更先进的"代理工程"范式，解决现有模型在训练成本、推理效率、长上下文保持以及复杂长期交互学习方面的局限性。

Method: 1. 采用DSA技术显著降低训练和推理成本同时保持长上下文保真度；2. 实现新的异步强化学习基础设施，通过解耦生成和训练提高后训练效率；3. 提出新颖的异步代理RL算法，提升RL质量，使模型能更有效地从复杂长期交互中学习。

Result: 在主要开放基准上达到最先进性能；在真实世界编码任务中展现出前所未有的能力，在处理端到端软件工程挑战方面超越了之前的基线模型。

Conclusion: GLM-5成功实现了从氛围编码到代理工程的范式转变，通过技术创新在效率、对齐和实际应用能力方面取得了显著突破，为下一代基础模型的发展提供了重要参考。

Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.

</details>


### [83] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 微调对齐的语言模型即使在良性任务上也会意外破坏安全护栏，这是由于对齐几何的低维子空间具有尖锐曲率，导致梯度下降的二阶加速效应将优化轨迹推入安全敏感区域。


<details>
  <summary>Details</summary>
Motivation: 当前的安全微调方法存在结构性盲点：即使训练数据无害且开发者无对抗意图，微调对齐的语言模型仍会不可预测地降低安全护栏。主流解释认为微调更新在高维参数空间中应与安全关键方向正交，但这种正交性在梯度下降动态下是结构不稳定的。

Method: 通过新颖的几何分析，证明对齐集中在具有尖锐曲率的低维子空间中，形成一阶方法无法检测或防御的脆弱结构。提出对齐不稳定性条件（Alignment Instability Condition）——三个几何特性共同满足时会导致安全退化。建立四次方缩放定律，描述对齐损失随训练时间的四次方增长。

Result: 揭示了安全退化的机制：初始微调更新可能避开对齐子空间，但微调损失的曲率产生二阶加速，系统性地将优化轨迹引导至对齐敏感区域。对齐损失的增长由对齐几何的尖锐度和微调任务与安全关键参数之间的曲率耦合强度控制。

Conclusion: 对齐脆弱性不是可以修补的错误，而是梯度下降在弯曲流形上的固有几何特性。当前安全微调方法只解决了基本动态问题的初始快照，需要开发曲率感知方法，推动对齐安全分析从被动红队测试转向开放权重模型部署的预测性诊断。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>


### [84] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 提出Feasibility-Guided Exploration (FGE)方法，通过同时识别可行初始条件子集和学习安全策略，解决强化学习在可达性问题中的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在高维控制任务中表现出色，但应用于可达性问题时存在根本性不匹配：可达性寻求最大化系统保持安全的状态集合，而RL优化用户指定分布上的期望回报。这种不匹配可能导致策略在低概率但仍在安全集中的状态上表现不佳。

Method: 提出可行性引导探索(FGE)方法，同时识别存在安全策略的可行初始条件子集，并学习解决该初始条件集合上可达性问题的策略。

Result: 在MuJoCo模拟器和Kinetix模拟器（像素观测）的挑战性初始条件任务中，FGE学习的策略比现有最佳方法覆盖范围提高50%以上。

Conclusion: FGE通过同时探索可行性和学习安全策略，有效解决了RL在可达性问题中的不匹配问题，显著提高了策略的覆盖范围。

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [85] [Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics](https://arxiv.org/abs/2602.15820)
*Anna Zimmel,Paul Setinek,Gianluca Galletti,Johannes Brandstetter,Werner Zellinger*

Main category: cs.LG

TL;DR: 提出基于D-最优统计量的测试时自适应框架，解决机器学习代理模型在工程仿真中因分布偏移导致的性能下降问题，首次系统性地实现了高维仿真回归的有效TTA。


<details>
  <summary>Details</summary>
Motivation: 机器学习代理模型在工程仿真中广泛应用，但训练与部署间的分布偏移（如未见过的几何形状或配置）会导致严重的性能下降。现有的测试时自适应方法主要针对低维分类问题设计，不适用于高维、非结构化的仿真回归问题。

Method: 提出基于存储最大化信息（D-最优）统计量的TTA框架，该框架能够实现稳定的自适应，并在测试时进行有原则的参数选择。将方法应用于预训练的仿真代理模型。

Result: 在SIMSHIFT和EngiBench基准测试中验证，方法在分布外场景下实现了高达7%的性能提升，且计算成本可忽略不计。这是首次系统性地证明高维仿真回归和生成设计优化中有效TTA的可行性。

Conclusion: 提出的基于D-最优统计量的TTA框架成功解决了高维仿真回归中的分布偏移问题，为工程仿真中的机器学习代理模型提供了稳定、高效的测试时自适应解决方案。

Abstract: Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.

</details>


### [86] [CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing](https://arxiv.org/abs/2602.15823)
*Zarif Ikram,Arad Firouzkouhi,Stephen Tu,Mahdi Soltanolkotabi,Paria Rashidinejad*

Main category: cs.LG

TL;DR: CrispEdit是一种可扩展的二阶编辑算法，通过将能力保持作为显式约束，在成功编辑目标行为的同时最小化能力退化


<details>
  <summary>Details</summary>
Motivation: 大型语言模型编辑中的一个核心挑战是能力保持：成功改变目标行为的方法可能会悄悄"欺骗"编辑代理并损害通用能力，产生类似代理/奖励攻击的退化行为

Method: 将编辑问题形式化为约束优化，通过将编辑更新投影到能力损失景观的低曲率子空间来强制执行约束；使用Bregman散度表达能力约束，其二次形式精确产生高斯-牛顿Hessian；使用Kronecker分解近似曲率(K-FAC)和新型矩阵自由投影器实现高效二阶计算

Result: 在标准模型编辑基准测试中，CrispEdit实现了高编辑成功率，同时在数据集上平均保持能力退化低于1%，显著优于先前编辑方法

Conclusion: CrispEdit通过将能力保持作为显式约束的统一框架，提供了一种可扩展且原则性的LLM编辑方法，有效解决了编辑过程中的能力退化问题

Abstract: A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.

</details>


### [87] [Operationalising the Superficial Alignment Hypothesis via Task Complexity](https://arxiv.org/abs/2602.15829)
*Tomás Vergara-Browne,Darshan Patil,Ivan Titov,Siva Reddy,Tiago Pimentel,Marius Mosbach*

Main category: cs.LG

TL;DR: 论文提出"任务复杂度"新指标来量化SAH，发现预训练模型大幅降低任务复杂度，而微调进一步将复杂度降低数个数量级，表明任务适应通常只需极少信息。


<details>
  <summary>Details</summary>
Motivation: 表面对齐假说(SAH)缺乏精确定义，导致不同甚至矛盾的解释和批评。需要量化框架来统一理解预训练和微调在知识获取中的作用。

Method: 提出"任务复杂度"指标：实现目标任务性能的最短程序长度。通过该框架重新解释SAH，并在数学推理、机器翻译和指令跟随任务上实验估计复杂度。

Result: 预训练模型能显著降低任务复杂度，但达到高性能可能需要GB级程序长度；微调能将复杂度降低数个数量级，任务适应通常只需几KB信息。

Conclusion: 任务复杂度框架为SAH提供了量化基础，表明预训练提供知识基础，而微调通过极少信息就能有效访问这些知识，统一了先前看似矛盾的观点。

Abstract: The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [88] [A general theory of quantum measurements](https://arxiv.org/abs/2602.15075)
*Shizhong Mei*

Main category: quant-ph

TL;DR: 提出普适能量本征值方程，证明非孤立子系统存在唯一本征函数集（优先基），应用于氢原子相对运动得到精细结构修正，应用于电子双缝干涉测量分析自发发射率，发现确定子系统、优先基和跃迁率的共同机制，形成量子测量新理论基础。


<details>
  <summary>Details</summary>
Motivation: 建立普适的量子测量理论框架，解决非孤立子系统的本征函数唯一性问题，为量子测量提供一致的理论基础。

Method: 提出普适能量本征值方程，应用于氢原子相对运动（考虑质子质量对精细结构的影响）和电子双缝干涉测量（分析光子包、子系统域和态密度对自发发射率的影响）。

Result: 得到精细结构修正（相对运动与质心运动纠缠的结果），获得跃迁率的闭合表达式，数值结果与位置测量实验良好相关，发现确定子系统、优先基和跃迁率的共同机制。

Conclusion: 提出的新原理为量子测量提供了通用一致的理论基础，发现的共同机制形成了新的量子测量理论框架。

Abstract: A universal energy eigenvalue equation is proposed in this paper. It is proven that the unique set of eigenfunctions or preferred basis exists for any non-isolated sub-system. Applying the new eigenvalue equation to the relative motion of a hydrogen atom together with the derived relativistic Hamiltonian to quantify the impact of finite proton mass to the fine structure, correction to the fine structure is obtained as a result of the entanglement of the relative motion and the center-of-mass motion, which can be used to verify the correctness of the proposed eigenvalue equation. Applying the equation to the measurement of electron double-slit interference, it is analyzed that the photon packets with Lorentzian spectral lineshape, the domain and state density of the sub-system, and the energy of the incident electron together determines the spontaneous emission rate of the incident electron. Photons generated in this process excite electrons from the valence band to the conduction band of the detector. Corresponding to any emitted or absorbed photon, the sub-system is found to be uniquely determined by maximizing the transition rate. This new principle is valid for atoms too. Closed-form expressions are obtained for the transition rates and example numerical results show good correlation between calculation and the position measurement experiment. The discovered common mechanisms that determine the sub-systems, the preferred bases, and transition rates form the foundation of a new, general, and consistent theory of quantum measurement.

</details>


### [89] [Fundamental questions on robustness and accuracy for classical and quantum learning algorithms](https://arxiv.org/abs/2602.15079)
*Nana Liu*

Main category: quant-ph

TL;DR: 该论文研究了经典和量子分类算法在噪声和对抗条件下准确性与鲁棒性之间的基本关系，澄清了不同类型的鲁棒性和准确性定义，并通过理论分析和玩具模型探索了它们之间的权衡条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于深入理解在噪声和对抗条件下，分类算法的准确性与鲁棒性之间的基本关系。特别是在量子计算领域，需要澄清各种鲁棒性和准确性的定义，并探索在什么条件下会出现准确性与鲁棒性之间的权衡，以及如何避免这种权衡。

Method: 通过理论分析和构建玩具模型进行研究。引入了新的鲁棒性和准确性定义，包括"corrupted-instance robustness accuracy"和"prediction-change robustness"，并与传统的准确性和鲁棒性度量进行区分。建立了分析模型偏差、噪声特征和扰动类型之间相互作用的框架。

Result: 建立了准确性与鲁棒性之间权衡出现的条件，并识别了可以避免这种权衡的场景。研究揭示了模型偏差、噪声特征和扰动类型（包括相关和不相关扰动）之间的微妙相互作用。结果对不相容噪声、对抗性量子扰动、无免费午餐定理等具有启示意义。

Conclusion: 该研究为理解经典和量子分类算法中准确性与鲁棒性的关系提供了系统框架。通过澄清定义和建立理论条件，揭示了权衡出现的机制，并提出了从动力系统角度进一步研究这些问题的未来方向，为设计更鲁棒的量子机器学习算法奠定了基础。

Abstract: This chapter introduces and investigates some fundamental questions on the relationship between accuracy and robustness in both classical and quantum classification algorithms under noisy and adversarial conditions. We introduce and clarify various definitions of robustness and accuracy, including corrupted-instance robustness accuracy and prediction-change robustness, distinguishing them from conventional accuracy and robustness measures. Through theoretical analysis and toy models, we establish conditions under which trade-offs between accuracy and robustness accuracy arise and identify scenarios where such trade-offs can be avoided. The framework developed highlights the nuanced interplay between model bias, noise characteristics, and perturbation types, including relevant and irrelevant perturbations. We explore the implications of some of these results for incompatible noise, adversarial quantum perturbations, the no free lunch theorem, and suggest future methods to examine these problems from the lens of dynamical systems.

</details>


### [90] [Geometry of Quantum Logic Gates](https://arxiv.org/abs/2602.15080)
*M. W. AlMasri*

Main category: quant-ph

TL;DR: 论文在量子力学的全纯表示框架下，研究量子逻辑门的几何结构，将物理量子比特嵌入到全纯函数空间，推导出通用量子门集的微分算子表示，并揭示其在环面空间上的辛几何特性。


<details>
  <summary>Details</summary>
Motivation: 探索量子逻辑门在全纯表示中的几何结构，将量子计算操作与微分几何、辛几何等数学框架联系起来，为量子计算提供新的几何视角和理解。

Method: 将物理量子比特子空间嵌入到Schwinger玻色子对的全纯函数空间，推导出Pauli算子、Hadamard、CNOT、CZ、SWAP等通用量子门的闭式微分算子表示，并限制在单位模变量上研究环面空间上的几何作用。

Result: 量子门在全纯表示中保持物理子空间不变；在环面空间上，Pauli算子生成哈密顿流，Hadamard门诱导非线性自同构，纠缠门产生耦合不同环面因子的相关微分同胚；纠缠通过Segre嵌入在复射影空间中几何表征，拓扑保护源于Jordan-Schwinger约束相关的U(1)^N纤维丛结构。

Conclusion: 量子逻辑门在全纯表示框架下具有丰富的几何结构：在环面空间上表现为正则变换，在Segal-Bargmann空间中受Kähler几何支配，纠缠和拓扑保护都有明确的几何解释，为量子计算的几何理解提供了系统框架。

Abstract: In this work, we investigate the geometry of quantum logic gates within the holomorphic representation of quantum mechanics. We begin by embedding the physical qubit subspace into the space of holomorphic functions that are homogeneous of degree one in each Schwinger boson pair $(z_{a_{j}}, z_{b_{j}})$. Within this framework, we derive explicit closed-form differential operator representations for a universal set of quantum gates--including the Pauli operators, Hadamard, CNOT, CZ, and SWAP--and demonstrate that they preserve the physical subspace exactly. Restricting to unit-magnitude variables ($|z| = 1$) reveals a toroidal space $\mathbb{T}^{2N}$, on which quantum gates act as canonical transformations: Pauli operators generate Hamiltonian flows, the Hadamard gate induces a nonlinear automorphism, and entangling gates produce correlated diffeomorphisms that couple distinct toroidal factors. Beyond the torus, the full Segal--Bargmann space carries a natural Kaehler geometry that governs amplitude dynamics. Entanglement is geometrically characterized via the Segre embedding into complex projective space, while topological protection arises from the $U(1)^{N}$ fiber bundle structure associated with the Jordan--Schwinger constraint.

</details>


### [91] [Experimental characterization of the hierarchy of quantum correlations in top quark pairs](https://arxiv.org/abs/2602.15115)
*Yoav Afik,Regina Demina,Alan Herrera,Otto Hindrichs,Juan Ramón Muñoz de Nova,Baptiste Ravina*

Main category: quant-ph

TL;DR: LHC实验首次在顶夸克-反顶夸克系统中观测到量子不和谐和量子导引，验证了量子关联的完整层次结构，其中不和谐是最基本的量子关联形式，随后是纠缠、导引和贝尔关联。


<details>
  <summary>Details</summary>
Motivation: 利用LHC实验数据研究高能系统中顶夸克-反顶夸克对的量子关联特性，特别是验证量子关联的完整层次结构（不和谐→纠缠→导引→贝尔关联），并首次在如此高能系统中观测这些量子现象。

Method: 基于CMS合作组在螺旋度和束流基中测量的顶夸克和反顶夸克自旋密度矩阵的双微分测量，评估一系列量子可观测量：不和谐、导引、贝尔关联和魔法度。

Result: 不和谐大于零的显著性超过5σ，首次在高能系统中观测到不和谐；导引的显著性超过3σ，首次发现导引证据；在当前探测的相空间内未观测到贝尔关联，与理论预测一致；魔法度在多个相空间区域的显著性超过5σ。

Conclusion: 实验结果证实了顶夸克中完整的量子关联层次结构，其中不和谐是最基本的量子关联形式，随后是纠缠、导引和贝尔关联。魔法度作为量子关联层次结构的补充可观测量，在多个相空间区域表现出显著的非零值。

Abstract: Recent results from the Large Hadron Collider have demonstrated quantum entanglement of top quark-antiquark pairs using the spin degree of freedom. Based on the doubly differential measurement of the spin density matrix of the top quark and antiquark performed by the CMS collaboration in the helicity and beam bases, we evaluate a set of quantum observables, including discord, steering, Bell correlation, and magic. These observables allow for a quantitative characterization of the quantum correlations present in a top quark--antiquark system, thus enabling an interpretation of collider data in terms of quantum states and their properties. Discord is observed to be greater than zero with a significance of more than 5 standard deviations ($σ$). Evidence for steering is found with a significance of more than 3$σ$. This is the first evidence for steering, and the first observation of discord in a high-energy system. No Bell correlation is observed within the currently probed phase space, in agreement with the theoretical prediction. These results experimentally corroborate the full hierarchy of quantum correlations in top quarks with discord being the most basic form of quantum correlation, followed by entanglement, steering and Bell correlation. The significance of nonzero magic, which is a complementary observable to the quantum-correlation hierarchy, is found to exceed 5$σ$ in several regions of phase space.

</details>


### [92] [Spectral signatures of nonstabilizerness and criticality in infinite matrix product states](https://arxiv.org/abs/2602.15116)
*Andrew Hallam,Ryan Smith,Zlatko Papić*

Main category: quant-ph

TL;DR: 该论文开发了无限矩阵乘积态中稳定子Rényi熵的谱转移矩阵框架，发现其谱包含普适的次领头阶信息，并识别出在连续相变点发散且不同于标准关联长度的SRE关联长度。


<details>
  <summary>Details</summary>
Motivation: 非稳定子性（"魔法"）是通用量子计算的关键资源，但其在多体量子系统中的行为，特别是在临界点附近，仍然知之甚少。需要理解非稳定子性如何捕捉临界性和局部扰动的特征。

Method: 开发了无限矩阵乘积态中稳定子Rényi熵的谱转移矩阵框架，推导了cluster-Ising模型键维数χ=2 MPS骨架的精确SRE表达式，并数值探测了相图中ℤ₂临界线上的普适标度行为。

Result: 识别出SRE关联长度，该长度在连续相变点发散且不同于标准关联长度，控制着SRE对局部扰动的空间响应。在cluster-Ising模型中获得了精确的SRE表达式，并数值验证了其沿临界线的普适标度行为。

Conclusion: 非稳定子性能够捕捉临界性和局部扰动的特征，为理解量子多体系统中计算资源与涌现现象之间的相互作用提供了新的视角。

Abstract: While nonstabilizerness (''magic'') is a key resource for universal quantum computation, its behavior in many-body quantum systems, especially near criticality, remains poorly understood. We develop a spectral transfer-matrix framework for the stabilizer Rényi entropy (SRE) in infinite matrix product states, showing that its spectrum contains universal subleading information. In particular, we identify an SRE correlation length -- distinct from the standard correlation length -- which diverges at continuous phase transitions and governs the spatial response of the SRE to local perturbations. We derive exact SRE expressions for the bond dimension $χ=2$ MPS ''skeleton'' of the cluster-Ising model, and we numerically probe its universal scaling along the $\mathbb{Z}_2$ critical lines in the phase diagram. These results demonstrate that nonstabilizerness captures signatures of criticality and local perturbations, providing a new lens on the interplay between computational resources and emergent phenomena in quantum many-body systems.

</details>


### [93] [GKP-inspired high-dimensional superdense coding with energy-time entanglement](https://arxiv.org/abs/2602.15125)
*Kai-Chi Chang,Arjun Mirani,Murat Can Sarihan,Xiang Cheng,Michelle Harasimowicz,Patrick Hayden,Chee Wei Wong*

Main category: quant-ph

TL;DR: 提出基于能量-时间纠缠态的高维超密编码协议，利用双光子频率梳实现约8.91比特/光子的传输速率，比现有最佳方案提高一倍以上。


<details>
  <summary>Details</summary>
Motivation: 超密编码是量子通信的基石，但现有方案容量有限。本文旨在利用能量-时间纠缠态（双光子频率梳）的大希尔伯特空间特性，实现更高容量的超密编码。

Method: 提出基于时间-频率网格态的高维超密编码协议：1）将连续时间和频率自由度离散化；2）通过时间-频率位移编码信息；3）使用标准电信组件、时间分辨单光子探测器和频率分束器实现实验方案。

Result: 协议实现约8.91比特/光子的传输速率（相当于481个可区分消息），比Kwiat-Weinfurter方案的4比特提高一倍以上，比相同参数的单光子频率梳方案快4.6倍，且具有竞争性的光学损耗。

Conclusion: 该协议展示了时间-频率网格态在纠缠辅助通信中的实验可行应用，为连续变量和高维量子信息领域做出贡献，当代技术已满足实现该超密编码方案的要求。

Abstract: Superdense coding, the application of entanglement to boost classical communication capacity, is a cornerstone of quantum communication. In this paper, we propose a high-dimensional superdense coding protocol using energy-time entangled states. These states are biphoton frequency combs, an example of entangled time-frequency Gottesman-Kitaev-Preskill (TFGKP) states or time-frequency grid states. Inspired by GKP codes, our protocol involves discretizing the continuous time and frequency degrees of freedom and encoding information by time-frequency displacements. This approach leverages the inherently large Hilbert space found in quantum frequency combs, with resilience against both temporal and spectral errors. In addition to describing the theoretical structure of the protocol, we propose an experimental implementation using standard telecommunication components, time-resolving single-photon detectors and a frequency beamsplitter. We also analyze the effect of experimental noise and errors on the channel capacity of the protocol. We demonstrate that for realistic experimental parameters, contemporary technologies satisfy the prerequisites for superdense coding with biphoton frequency combs, achieving a transmission rate of approximately 8.91 bits per transmitted photon (equivalent to 481 distinguishable messages with asymptotically vanishing errors). This more than doubles the previously highest transmission rate of 4 bits achieved by the Kwiat-Weinfurter scheme, while also having competitive optical loss. Furthermore, our results beat the rate achievable using a single-photon frequency comb with identical parameters by 4.6 times. Our protocol thus represents an experimentally feasible application of time-frequency grid states to entanglement-assisted communication, contributing to the active fields of continuous-variable and high-dimensional quantum information.

</details>


### [94] [Quantum Theory for General Observers](https://arxiv.org/abs/2602.15134)
*Juanca Carrasco-Martinez*

Main category: quant-ph

TL;DR: 将相对性原理扩展到具有量子特性的观察者，提出包含相对量子化规则和新型不确定关系的新理论，并解决量子力学现有表述中的一些解释问题。


<details>
  <summary>Details</summary>
Motivation: 当前相对论和量子力学的结合存在观察者角色的局限性，传统相对论假设观察者是经典的。将相对性原理扩展到量子观察者可以更全面地理解量子现象，解决量子力学中的一些解释难题。

Method: 扩展相对性原理以容纳具有量子特性的观察者，建立包含相对量子化规则的理论框架，推导出新型的不确定关系。

Result: 提出了一个能够描述量子观察者的新理论，该理论包含相对量子化规则和新型不确定关系，同时澄清了量子力学现有表述中的一些解释问题。

Conclusion: 通过将相对性原理扩展到量子观察者，我们获得了一个更全面的理论框架，不仅统一了相对论和量子力学的某些方面，还解决了量子力学中的一些基本解释问题，为理解量子现象提供了新视角。

Abstract: The principle of relativity is extended to accommodate observers with quantum properties. This results in a new theory that introduces relative quantization rules and novel uncertainty relations, while also elucidating some interpretational problems present in the current formulation of quantum mechanics.

</details>


### [95] [Beyond Reinforcement Learning: Fast and Scalable Quantum Circuit Synthesis](https://arxiv.org/abs/2602.15146)
*Lukas Theissinger,Thore Gerlach,David Berghaus,Christian Bauckhage*

Main category: quant-ph

TL;DR: 使用监督学习估计残差酉矩阵的最小描述长度，结合随机束搜索寻找近最优量子门序列，实现零样本泛化的轻量级量子酉合成方法


<details>
  <summary>Details</summary>
Motivation: 量子酉合成面临指数级搜索空间、现有方法优化目标不匹配、训练成本高、泛化能力有限等问题，需要更高效的解决方案

Method: 采用监督学习近似残差酉矩阵的最小描述长度，结合随机束搜索寻找近最优门序列，使用轻量级模型实现零样本泛化

Result: 在多个基准测试中，实现了更快的实际合成时间，在复杂电路的成功率方面超过现有最先进方法

Conclusion: 提出的方法显著降低了训练开销，提高了量子酉合成的效率和泛化能力，为量子算法到硬件可执行门序列的转换提供了更优解决方案

Abstract: Quantum unitary synthesis addresses the problem of translating abstract quantum algorithms into sequences of hardware-executable quantum gates. Solving this task exactly is infeasible in general due to the exponential growth of the underlying combinatorial search space. Existing approaches suffer from misaligned optimization objectives, substantial training costs and limited generalization across different qubit counts. We mitigate these limitations by using supervised learning to approximate the minimum description length of residual unitaries and combining this estimate with stochastic beam search to identify near optimal gate sequences. Our method relies on a lightweight model with zero-shot generalization, substantially reducing training overhead compared to prior baselines. Across multiple benchmarks, we achieve faster wall-clock synthesis times while exceeding state-of-the-art methods in terms of success rate for complex circuits.

</details>


### [96] [Phases of matrix-product states with symmetries and measurements: Finite nilpotent groups](https://arxiv.org/abs/2602.15168)
*David Gunn,Georgios Styliaris,Barbara Kraus,Tristan Kraft*

Main category: quant-ph

TL;DR: 该论文将矩阵乘积态在一维对称电路、测量和前馈下的相分类，从阿贝尔和2类幂零群扩展到所有有限幂零群，证明所有SPT相在这些操作下坍缩为单一相。


<details>
  <summary>Details</summary>
Motivation: 先前研究只考虑了阿贝尔和2类幂零群的对称性保护拓扑相，需要扩展到所有有限幂零群，以全面理解对称测量和前馈对相分类的影响。

Method: 利用幂零群的不可约表示的层次结构，构建显式的G对称电路和带前馈的测量协议，通过有限轮测量将SPT态转化为平凡相，反之亦然。

Result: 对于所有有限幂零对称群，对称测量和前馈导致所有SPT相坍缩为单一相，包括具有长程关联的非正规MPS（如GHZ型态），成功概率在热力学极限下趋近于1。

Conclusion: 对称测量和前馈完全破坏了有限幂零群保护的相结构，所有对称保护拓扑相和非正规MPS相在这些操作下等价，为量子信息处理提供了新的资源态转换方法。

Abstract: We classify phases of one-dimensional matrix-product states (MPS) under symmetric circuits augmented with symmetric measurements and feedforward. Building on the framework introduced in Gunn et al., Phys. Rev. B 111, 115110 (2025), we extend the analysis from abelian and class-2 nilpotent groups to all finite nilpotent groups. For any such symmetry group $G$, we construct explicit protocols composed of $G$-symmetric circuits and measurements with feedforward that transform symmetry-protected topological (SPT) states into the trivial phase and vice versa using a finite number of measurement rounds determined by the nilpotency class of $G$. Although these transformations are approximate, we prove that their success probability converges to unity in the thermodynamic limit, establishing asymptotically deterministic equivalence. Consequently, all SPT phases protected by finite nilpotent groups collapse to a single phase once symmetric measurements and feedforward are allowed. We further show that the same holds for non-normal MPS with long-range correlations, including GHZ-type states. The central technical ingredient is a hierarchical structure of irreducible representations of nilpotent groups, which enables a recursive reduction of non-abelian components to abelian ones. Our results demonstrate that symmetric measurements lead to a complete collapse of both symmetry-protected and non-normal MPS phases for all finite nilpotent symmetry groups.

</details>


### [97] [Efficient quantum circuits for high-dimensional representations of SU(n) and Ramanujan quantum expanders](https://arxiv.org/abs/2602.15180)
*Vishnu Iyer,Siddhartha Jain,Stephen Jordan,Rolando Somma*

Main category: quant-ph

TL;DR: 提出高效量子电路实现SU(n)高维不可约表示，门数量在log(N)和log(1/ε)上多项式，可用于构建Ramanujan量子扩展器和加速量子系统演化


<details>
  <summary>Details</summary>
Motivation: 实现SU(n)群的高维不可约表示在量子计算中具有重要意义，但传统方法效率低下。本文旨在开发高效量子电路来实现这些表示，解决长期存在的Ramanujan量子扩展器构造问题，并为加速某些量子系统的演化提供工具。

Method: 基于Jordan-Schwinger表示，将SU(n)的不可约表示实现在n个量子谐振子的希尔伯特空间中。结合最近的高效量子Hermite变换，将计算基态映射到量子谐振子的本征态，从而高效实现这些表示。

Result: 成功构建了高效量子电路，对于维度N和误差ε，量子门数量在log(N)和log(1/ε)上是多项式的。这些电路能够实现SU(n)的高维不可约表示。

Conclusion: 本文提出的高效量子电路不仅解决了构造Ramanujan量子扩展器这一长期开放问题，还能用于加速某些量子系统的演化，为量子计算中的群表示实现提供了新方法。

Abstract: We present efficient quantum circuits that implement high-dimensional unitary irreducible representations (irreps) of $SU(n)$, where $n \ge 2$ is constant. For dimension $N$ and error $ε$, the number of quantum gates in our circuits is polynomial in $\log(N)$ and $\log(1/ε)$. Our construction relies on the Jordan-Schwinger representation, which allows us to realize irreps of $SU(n)$ in the Hilbert space of $n$ quantum harmonic oscillators. Together with a recent efficient quantum Hermite transform, which allows us to map the computational basis states to the eigenstates of the quantum harmonic oscillator, this allows us to implement these irreps efficiently. Our quantum circuits can be used to construct explicit Ramanujan quantum expanders, a longstanding open problem. They can also be used to fast-forward the evolution of certain quantum systems.

</details>


### [98] [Intractability of Witnessing Entangled Measurements Device Independently](https://arxiv.org/abs/2602.15199)
*Peter Bierhorst*

Main category: quant-ph

TL;DR: 该论文证明了一类设备无关场景中，纠缠测量总是可以被替换为纠缠态，因此没有黑盒测量场景真正需要纠缠测量来复制其行为。


<details>
  <summary>Details</summary>
Motivation: 先前已有协议提出在完全设备无关的方式下认证纠缠测量的存在。本文旨在挑战这一观点，证明这些协议中声称的纠缠测量实际上可以被非纠缠测量替代。

Method: 为这些协议提供模型，其中声称的测量并非纠缠测量，并证明对于一类设备无关场景，总是可以将纠缠从测量转移到被测量的态上。

Result: 证明了没有黑盒测量场景需要纠缠测量来复制其行为，因为总是可以将纠缠从测量转移到态上。

Conclusion: 这一发现对我们理解纠缠测量的基本性质以及如何见证这一现象具有重要意义，表明设备无关场景中声称的纠缠测量可能并非真正必要。

Abstract: Protocols have been previously proposed to certify the presence of an entangled measurement in a fully device-independent manner. Here, I provide models for these protocols in which the claimed measurement is not entangled, and demonstrate it is always possible to displace entanglement from measurements to measured states for a general class of device-independent scenarios. This indicates that no black-box measurement scenario requires entangled measurements to replicate its behavior, which is relevant to our fundamental understanding of this phenomenon and how to witness it.

</details>


### [99] [Tomography by Design: An Algebraic Approach to Low-Rank Quantum States](https://arxiv.org/abs/2602.15202)
*Shakir Showkat Sofi,Charlotte Vermeylen,Lieven De Lathauwer*

Main category: quant-ph

TL;DR: 提出一种代数量子态层析算法，利用特定可观测量测量估计密度矩阵的结构化条目，在低秩假设下通过标准数值线性代数操作补全其余条目


<details>
  <summary>Details</summary>
Motivation: 传统量子态层析方法计算复杂度高，需要大量测量。本文旨在开发一种计算高效且具有确定性恢复保证的代数方法，适用于广泛的低秩混合量子态

Method: 代数矩阵补全框架：首先测量特定可观测量以估计密度矩阵的结构化条目，然后在低秩假设下，利用标准数值线性代数操作（如奇异值分解、矩阵补全等）补全剩余条目

Result: 相比现有方法，该方法计算效率更高，提供确定性恢复保证，适用于广泛的通用低秩混合量子态

Conclusion: 提出的代数量子态层析算法为低秩量子态提供了一种计算高效且具有理论保证的层析方法，通过结合测量和代数补全技术，显著降低了传统方法的计算复杂度

Abstract: We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.

</details>


### [100] [Near-Infrared and Telecommunication-Wavelength Photon-Pair Source in Optical Fiber](https://arxiv.org/abs/2602.15207)
*Keshav Kapoor,Dong Beom Kim,Kriti Shetty,Virginia O. Lorenz*

Main category: quant-ph

TL;DR: 提出一种在商用光纤中产生电信波段和近红外波段光子对的源，具有高度非简并性（700nm波长差），可在室温下工作且远离拉曼噪声。


<details>
  <summary>Details</summary>
Motivation: 开发一种实用化的光子对源，能够在室温下工作，使用商用材料，并具有在量子网络中部署的潜力，同时解决传统源中拉曼噪声干扰的问题。

Method: 利用商用光纤中的非线性过程产生高度非简并的光子对（电信波段1500nm和近红外波段830nm），通过光谱和空间模式的分离来降低串扰，利用高非简并性远离拉曼噪声。

Result: 成功实现了在室温下工作的光子对源，具有高巧合-偶然比，产生两个光谱和空间上不同的相位匹配过程，电信波段为单基模，近红外波段具有不同的横向空间模式。

Conclusion: 该光子对源具有室温操作、使用商用材料、多路复用潜力等优势，为量子网络的部署提供了有前景的实用化解决方案。

Abstract: We present a photon-pair source in commercially available optical fiber that produces paired photons at telecommunication and near-infrared (NIR) wavelengths. The highly nondegenerate pairs are 700 nm apart: one in the 1500 nm E- and S-band telecommunication range and the other in the 830 nm NIR range. The high non-degeneracy means the photon pairs are far-detuned from Raman noise, resulting in a high coincidence-to-accidental ratio even while operating at room temperature. The source produces two spectrally and spatially distinct phase-matched processes with low spectral cross-talk, distinct transverse spatial modes in the NIR, and a single fundamental spatial mode in the telecommunication range. The source's room-temperature operation, off-the-shelf materials, and multiplexing potential make it promising for deployment in quantum networks.

</details>


### [101] [Dissipative Quantum Battery in the Ultrastrong Coupling Regime Between Two Oscillators](https://arxiv.org/abs/2602.15235)
*Yu-qiang Liu,Yi-jia Yang,Zheng Liu,Bao-qing Guo,Ting-ting Ma,Zunlue Zhu,Wuming Liu,Xingdong Zhao,Chang-shui Yu*

Main category: quant-ph

TL;DR: 本文提出了一种基于双模超强耦合玻色系统的开放量子电池，通过控制初始态实现单向能量流，在超强耦合和宽温范围内显著提升充电能量和功提取能力。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子电池的能量存储和释放机制，探索在超强耦合条件下如何增强量子电池的充电能量和功提取能力，并理解不同耦合相互作用对量子电池性能的影响。

Method: 采用双模超强耦合玻色系统，其中一个模式（充电器）耦合到独立热库。通过控制系统的初始态为双模压缩基态来实现单向能量流。分析束分离器和参量放大（压缩）耦合的联合效应，并考虑电磁矢势平方项的影响。

Result: 在超强耦合区域和宽温度范围内，量子电池的充电能量和功提取能力在瞬态时显著增强。稳态存储能量及其功提取能力在更高温度和更强耦合强度下得到提升。纯束分离器或双模压缩相互作用产生零功提取，表明增强效应主要来自两种耦合的联合作用。电磁矢势平方项可防止相变并在深强耦合区域实现显著充电能量和高功提取。

Conclusion: 开放玻色量子电池的性能增强主要源于束分离器和参量放大耦合的联合效应，通过控制初始态和利用超强耦合特性，可以在宽温度范围内实现高效能量存储和提取，这深化了对开放量子电池工作原理的理解。

Abstract: In this work, we propose an open quantum battery that stores and releases energy by employing a two-mode ultrastrongly coupled bosonic system, with one mode (the charger) coupled to an independent heat reservoir. Our results demonstrate that both the charging energy and ergotropy of the quantum batteries can be significantly enhanced within the ultra-strong coupling regime and across a broader temperature range in transient time. A unidirectional energy flow is achieved by controlling the system's initial state through its two-mode squeezed ground state. Furthermore, we show that the steady-state stored energy, along with its corresponding ergotropy, can be enhanced at larger temperatures and stronger coupling strengths. Notably, a purely beam-splitter or two-mode squeezing interaction yields zero ergotropy. These findings indicate that the enhanced stored energy and ergotropy of the quantum battery arises principally from the combined effects of beam-splitter and parametric amplification (squeezing) couplings. In addition, the presence of the squared electromagnetic vector potential term can prevent a phase transition and achieve a significant charging energy and high ergotropy in the deep-strong coupling regime. The results presented herein enhance our understanding of the operating principles of open bosonic quantum batteries.

</details>


### [102] [Tensor Decomposition for Non-Clifford Gate Minimization](https://arxiv.org/abs/2602.15285)
*Kirill Khoruzhii,Patrick Gelß,Sebastian Pokutta*

Main category: quant-ph

TL;DR: 开发代数方法直接最小化Toffoli门数量，通过张量分解技术显著提升量子电路优化效率


<details>
  <summary>Details</summary>
Motivation: 容错量子计算需要最小化非Clifford门，传统方法专注于T门数量最小化，但专用CCZ工厂的出现使得直接优化Toffoli门成为更自然的目标

Method: 基于Toffoli门数量与有限域F2上张量分解的联系，开发代数方法进行Toffoli门最小化

Result: 在标准基准测试中，该方法匹配或改进了所有已报道的Toffoli门和T门数量优化结果，大多数电路在单CPU上不到一分钟完成，而先前工作需要数千个TPU

Conclusion: 提出的代数方法在Toffoli门最小化方面表现出色，显著提升了优化效率，为容错量子计算的资源优化提供了有效工具

Abstract: Fault-tolerant quantum computation requires minimizing non-Clifford gates, whose implementation via magic state distillation dominates the resource costs. While $T$-count minimization is well-studied, dedicated $CCZ$ factories shift the natural target to direct Toffoli minimization. We develop algebraic methods for this problem, building on a connection between Toffoli count and tensor decomposition over $\mathbb{F}_2$. On standard benchmarks, these methods match or improve all reported results for both Toffoli and $T$-count, with most circuits completing in under a minute on a single CPU instead of thousands of TPUs used by prior work.

</details>


### [103] [Realizing a Universal Quantum Gate Set via Double-Braiding of SU(2)k Anyon Models](https://arxiv.org/abs/2602.15324)
*Jiangwei Long,Zihui Liu,Yizhi Li,Jianxin Zhong,Lijun Meng*

Main category: quant-ph

TL;DR: 该论文研究了在SU(2)k任意子模型中通过双编织实现通用量子门集，使用遗传算法增强的Solovay-Kitaev算法合成单量子比特门，并通过遗传算法找到近似CNOT门的双量子比特纠缠门编织序列。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在SU(2)k任意子模型中通过双编织实现通用量子计算的可能性，同时寻求减少实际需要物理操纵的非阿贝尔任意子数量的新策略，以推动基于编织的拓扑量子计算发展。

Method: 从SU(2)的q变形表示论推导F矩阵和R符号，得到双基本编织矩阵的显式形式。使用遗传算法增强的Solovay-Kitaev算法合成单量子比特门（仅需2级分解），通过遗传算法寻找近似CNOT门的30次编织操作序列。理论证明在三任意子（六任意子）编码中，双编织在拓扑上等价于仅需物理操纵一个（三个）任意子的协议。

Result: 成功合成了达到容错量子计算精度要求的单量子比特门，找到了近似CNOT门的双量子比特纠缠门编织序列。理论证明了双编织协议能显著减少需要物理操纵的任意子数量，数值结果为SU(2)k任意子模型能够实现通用量子计算提供了有力证据。

Conclusion: SU(2)k任意子模型中的双编织能够实现通用量子计算，所提出的协议为未来基于编织的拓扑量子计算提供了显著减少需要物理操纵的非阿贝尔任意子数量的新策略，具有重要的理论和实践意义。

Abstract: We systematically investigate the implementation of a universal gate set via double-braiding within SU(2)k anyon models. The explicit form of the double elementary braiding matrices (DEBMs) in these models are derived from the F-matrices and R-symbols obtained via the q-deformed representation theory of SU(2). Using these EBMs, standard single-qubit gates are synthesized up to a global phase by a Genetic Algorithm-enhanced Solovay-Kitaev Algorithm (GA-enhanced SKA), achieving the accuracy required for fault-tolerant quantum computation with only 2-level decomposition. For two-qubit entangling gates, Genetic Algorithm (GA) yields braidwords of 30 braiding operations that approximate the local equivalence class [CNOT]. Theoretically, we demonstrate that performing double-braiding in a three-anyon (six-anyon) encoding of single-qubit (two-qubit) is topologically equivalent to a protocol requiring the physical manipulation of only one (three) anyons to execute arbitrary braids. Our numerical results provide strong evidence that double-braiding in SU(2)k anyons models is capable of universal quantum computation. Moreover, the proposed protocol offers a potential new strategy for significantly reducing the number of non-Abelian anyons that need to be physically manipulated in future braiding-based topological quantum computations (TQC).

</details>


### [104] [Self-dual Stacked Quantum Low-Density Parity-Check Codes](https://arxiv.org/abs/2602.15372)
*Ze-Chuan Liu,Chong-Yuan Xu,Yong Xu*

Main category: quant-ph

TL;DR: 提出通过堆叠非自对偶qLDPC码构建自对偶qLDPC码的方法，开发了多种双链/双层结构码，这些码具有良好的参数，在电路级噪声下作为量子存储器表现出高伪阈值。


<details>
  <summary>Details</summary>
Motivation: qLDPC码因其高编码率和距离成为容错量子计算的有力候选，但实现逻辑操作面临挑战。自对偶qLDPC码便于实现横向Clifford门，因此需要构建自对偶qLDPC码的方法。

Method: 通过堆叠非自对偶qLDPC码来构造自对偶qLDPC码。具体开发了四种结构：双链自行车码、双层双变量自行车码、双层扭曲BB码和双层反射码。

Result: 构建的许多码具有有利的编码参数。数值计算表明，在电路级噪声模型下，这些码作为量子存储器能显著降低逻辑失败率，并具有高伪阈值。

Conclusion: 提出的堆叠方法能有效构造自对偶qLDPC码，为qLDPC码的逻辑操作实现提供了新途径，在容错量子计算中具有应用潜力。

Abstract: Quantum low-density parity-check (qLDPC) codes are promising candidates for fault-tolerant quantum computation due to their high encoding rates and distances. However, implementing logical operations using qLDPC codes presents significant challenges. Previous research has demonstrated that self-dual qLDPC codes facilitate the implementation of transversal Clifford gates. Here we introduce a method for constructing self-dual qLDPC codes by stacking non-self-dual qLDPC codes. Leveraging this methodology, we develop double-chain bicycle codes, double-layer bivariate bicycle (BB) codes, double-layer twisted BB codes, and double-layer reflection codes, many of which exhibit favorable code parameters. Additionally, we conduct numerical calculations to assess the performance of these codes as quantum memory under the circuit-level noise model, revealing that the logical failure rate can be significantly reduced with high pseudo-thresholds.

</details>


### [105] [Giant atoms coupled to waveguide: Continuous coupling and multiple excitations](https://arxiv.org/abs/2602.15389)
*Shiying Lin,Xinyu Zhao,Yan Xia*

Main category: quant-ph

TL;DR: 提出随机薛定谔方程方法研究波导耦合巨原子动力学，解决了连续耦合和多激发态研究的空白，发现连续耦合会削弱干涉效应，方法能直接反映光子发射/吸收过程和时间延迟效应。


<details>
  <summary>Details</summary>
Motivation: 现有研究对巨原子与波导耦合系统的连续耦合和多激发态探索不足，需要开发能处理这些复杂情况的理论工具。

Method: 采用随机薛定谔方程方法，该方法能直接计算自相关和互相关函数，反映光子发射/吸收过程和时间延迟效应，且能自然处理多激发态而不增加方程复杂度。

Result: 发现连续耦合会破坏恒定相位差条件，从而削弱巨原子-波导系统中的干涉效应；方法能有效研究波导的热态和压缩态等多激发初始态。

Conclusion: 随机薛定谔方程方法为研究波导耦合巨原子动力学提供了强大工具，特别适用于连续耦合和多激发态系统。

Abstract: We propose a stochastic Schrödinger equation (SSE) approach to investigate the dynamics of giant atoms coupled to a waveguide, addressing two critical gaps in existing research, namely insufficient exploration on continuous coupling and multiple excitations. A key finding is that continuous coupling, unlike discrete coupling at finite points, breaks the constant phase difference condition, thereby weakening the interference effects in giant atom-waveguide systems. In addition, a key technical advantage of the SSE approach is that auto- and cross-correlation functions can directly reflect the complex photon emission/absorption processes and time-delay effects in giant atom-waveguide systems. Moreover, the SSE approach also naturally handles multiple excitations, without increasing equation complexity as the number of excitations grows. This feature enables the investigation of multi-excitation initial states of the waveguide, such as thermal and squeezed initial states. Overall, our approach provides a powerful tool for studying the dynamics of giant atoms coupled to waveguide, particularly for continuous coupling and multi-excitation systems.

</details>


### [106] [Non-Markovian environment induced chaos in optomechanical system](https://arxiv.org/abs/2602.15402)
*You-Lin Xiang,Xinyu Zhao,Yan Xia*

Main category: quant-ph

TL;DR: 该论文发现非马尔可夫环境中的非线性后反应可以单独引发混沌行为，无需传统非线性相互作用或外部驱动。


<details>
  <summary>Details</summary>
Motivation: 传统研究中混沌通常伴随非线性相互作用或外部驱动力，本文旨在探索非马尔可夫环境本身能否作为混沌的唯一诱因。

Method: 推导光机械系统的动力学方程，分析时间域卷积项（由非马尔可夫修正引入）如何引入非线性，并在马尔可夫条件下对比研究。

Result: 证明混沌行为完全源于非马尔可夫环境的时间域卷积项，这些项在马尔可夫条件下退化为常数，导致非线性消失和混沌消失。甚至在无光机械耦合时也能观察到混沌生成。

Conclusion: 非马尔可夫效应是混沌的唯一诱因，环境参数在混沌生成中起重要作用，这为研究纯粹由非马尔可夫环境引起的混沌动力学开辟了新方向。

Abstract: In traditional research, chaos is frequently accompanied by non-linearity, which typically stems from non-linear interactions or external driving forces. However, in this paper, we present the chaotic behavior that is completely attributed to the non-linear back-reaction of non-Markovian environment. To be specific, we derive the dynamical equations of an optomechanical system and demonstrate that the non-linearity (cause of chaos) in the equations arises entirely from the time-domain convolutions (TDCs) induced by non-Markovian corrections. Under Markovian conditions, these TDCs are reduced into constants, thereby losing the nonlinearity and ultimately leading to the disappearance of chaos. Furthermore, we also observe chaos generation in the absence of optomechanical couplings, which further confirms that the non-Markovian effect is the sole inducement of chaos and the environmental parameters play important roles in the generation of chaos. We hope these results may open a new direction to investigate chaotic dynamics purely caused by non-Markovian environments.

</details>


### [107] [Non-Markovian environment induced Schrödinger cat state transfer in an optical Newton's cradle](https://arxiv.org/abs/2602.15430)
*Xinyu Zhao,Yan Xia*

Main category: quant-ph

TL;DR: 研究非马尔可夫环境中量子光学牛顿摇篮的薛定谔猫态传输，发现即使腔间无直接耦合，仅通过非马尔可夫共同环境的记忆效应也能实现猫态传输


<details>
  <summary>Details</summary>
Motivation: 探索非马尔可夫环境与马尔可夫环境的本质区别，研究环境记忆效应对量子态传输的影响，特别是在无直接耦合情况下能否实现量子态传输

Method: 基于非马尔可夫主方程，通过解析和数值分析研究量子光学牛顿摇篮系统中薛定谔猫态的传输机制，考察环境参数的影响

Result: 发现猫态可以仅通过非马尔可夫共同环境的记忆效应实现传输，无需相邻腔之间的直接耦合；非马尔可夫环境表现出有限剩余相干性，与马尔可夫环境的零剩余相干性形成鲜明对比

Conclusion: 非马尔可夫环境在量子态传输中具有独特作用，其记忆效应能实现无直接耦合的猫态传输，这揭示了非马尔可夫与马尔可夫环境的根本区别

Abstract: In this manuscript, we study the Schrödinger cat state transfer in a quantum optical version of Newton's cradle in non-Markovian environment. Based on a non-Markovian master equation, we show that the cat state can be transferred purely through the memory effect of the non-Markovian common environment, even without any direct couplings between neighbor cavities. The mechanism of the environment induced cat state transfer is analyzed both analytically and numerically to demonstrate that the transfer is a unique phenomenon in non-Markovian regime. From this example, the non-Markovian environment is shown to be qualitatively different from the Markovian environment reflected by the finite versus zero residue coherence. Besides, we also show the influence of environmental parameters are crucial for the transfer. We hope the cat state transfer studied in this work may shed more light on the fundamental difference between non-Markovian and Markovian environments.

</details>


### [108] [Nonlocality without entanglement in exclusion of quantum states](https://arxiv.org/abs/2602.15452)
*Satyaki Manna,Anandamay Das Bhowmik*

Main category: quant-ph

TL;DR: 该论文研究量子态排除任务，重点关注反可区分性及其推广到x-反可区分性，在全局测量和LOCC操作下。发现了态排除与态区分之间的显著差异，证明了三体乘积态存在"无纠缠的非局域性"现象。


<details>
  <summary>Details</summary>
Motivation: 研究量子态排除任务，特别是反可区分性及其推广，探索在全局测量和LOCC操作下的差异。动机在于理解态排除与更熟悉的态区分任务之间的根本区别，并揭示量子非局域性的新表现形式。

Method: 引入弱和强反可区分性（x-反可区分性）概念，研究全局测量和LOCC操作下的态排除。分析多体乘积态的对称性，构建具体的量子态实例，证明全局可反区分但LOCC不可反区分的现象。

Result: 发现LOCC反可区分性对多体乘积态具有对称性，但高阶x-反可区分性会破坏这种对称性。证明了三个双体乘积态可以全局反可区分但LOCC不可反区分，这是该现象所需的最小态数。进一步将这种分离扩展到2-反可区分性，并提供了三体乘积态在任何二分下都不可LOCC反区分的实例。

Conclusion: 该研究在态排除框架中建立了"无纠缠的非局域性"的新表现形式，证明了三个量子态是实现该现象的最小数目，并展示了这种非局域性可以扩展到多体系统和更高阶的反可区分性任务中。

Abstract: We study the task of quantum state exclusion, focusing on antidistinguishability and its generalization to $x$-antidistinguishability, under global measurements and local operations with classical communication (LOCC). We also introduce weak and strong notions of antidistinguiahbaility ($x$-antidistinguishability) depending on whether all states or all $x$-tuples are exhaustively eliminated. Our results reveal striking differences between state exclusion and the more familiar task of state discrimination. In particular, we show that LOCC antidistinguishability of multipartite product states is symmetric with respect to the initiating party but this symmetry breaks down for higher-order $x$-antidistinguishability. Most notably, we establish a manifestation of \emph{nonlocality without entanglement} in the context of state exclusion: we prove that three bipartite product states can be globally antidistinguishable while failing to be LOCC antidistinguishable, demonstrating that three is the minimal number of states required for this phenomenon. We further extend this separation to $2$-antidistinguishability and present example exhibiting the same type of nonlocality. At last, we provide an antidistinguishable tripartite product states that are not LOCC antidistinguishable across any bipartition, which ensures the phenomenon of \emph{genuine nonlocality without entanglement} in this framework.

</details>


### [109] [Cluster Ising quantum batteries can mimic super-extensive charging power](https://arxiv.org/abs/2602.15467)
*Anna Pavone,Federico Luigi Cavagnaro,Matteo Carrega,Riccardo Grazi,Dario Ferraro,Niccolò Traverso Ziani*

Main category: quant-ph

TL;DR: 量子电池在扩展簇-伊辛模型中表现出超扩展充电功率，尽管属于Wigner-Jordan可积自旋链，这在之前被认为是不可能的。


<details>
  <summary>Details</summary>
Motivation: 量子电池作为能够按需存储和释放能量的微型设备很有前景，因为它们的内在能量和时间尺度可以匹配其他量子技术，并且有可能实现超扩展充电功率。然而，在Wigner-Jordan可积自旋链中，这种增强的缩放通常被认为是禁止的。

Method: 研究扩展簇-伊辛模型，该模型属于Wigner-Jordan可积自旋链类别，通过量子淬灭协议进行充电。在适当的参数范围内分析系统尺寸（最多达一千个自旋）下的充电功率。

Result: 扩展簇-伊辛模型在广泛的系统尺寸范围内表现出超扩展充电功率，这种异常的缩放是由于存储能量的超扩展增长所致。这种现象在有限温度效应下仍然稳健，但无法在热力学极限下持续。

Conclusion: 即使在之前被认为不可能实现超扩展充电功率的Wigner-Jordan可积自旋链中，扩展簇-伊辛模型也展示了这种能力，为量子电池设计提供了新的可能性。

Abstract: Quantum batteries, miniaturized devices able to store and release energy on demand, are promising both because their intrinsic energy and time scales can match those of other quantum technologies and due to the intriguing possibility of achieving super-extensive charging power. While this enhanced scaling is known to appear in several settings, it is generally believed to be forbidden in Wigner-Jordan integrable spin chains charged via quantum-quench protocols. Here, we show that an extended cluster-Ising model, despite belonging to the above category, exhibits super-extensive charging power over wide ranges of system sizes, reaching up to a thousand spins, in proper parameter regimes. This remarkable anomalous scaling is due to a corresponding super-extensive growth of the stored energy, implying that it occurs at large but finite size and cannot persist in the thermodynamic limit. This phenomenon appears robust against finite-temperature effects.

</details>


### [110] [Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit](https://arxiv.org/abs/2602.15474)
*J. J. Prieto-Garcia,A. G. del Pozo-Martín,M. Pino*

Main category: quant-ph

TL;DR: 量子储层计算在统计金融问题上表现出色，能准确分类复杂概率分布和识别相关时间序列中的高波动期，在信息有限时优于经典方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子储层计算在统计和金融问题中的应用潜力，探索其在当前可用超导平台上解决实际问题的能力，特别是针对信息有限的情况。

Method: 使用由两个通过电荷自由度耦合的超导岛组成的储层，每个岛通过约瑟夫森结接地作为关键非线性元件，实现丰富复杂的动力学特性。

Result: QRC能准确分类包括重尾分布在内的复杂概率分布，识别标准计量经济学模型生成的高波动期，在信息有限时优于最佳经典方法。

Conclusion: 量子储层计算是一种噪声弹性量子学习方法，具有在当前超导硬件中解决实际问题的潜力，可通过利用更大希尔伯特空间进一步改进。

Abstract: We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.

</details>


### [111] [Drone delivery packing problem on a neutral-atom quantum computer](https://arxiv.org/abs/2602.15487)
*Sara Tarquini,Matteo Vandelli,Francesco Ferrari,Daniele Dragoni,Francesco Tudisco*

Main category: quant-ph

TL;DR: 该论文提出了一种基于中性原子量子处理器的混合量子-经典框架，用于解决无人机配送装箱问题，通过将优化任务重新表述为基于调度图独立集的图划分问题，并在Pasqal的Fresnel量子处理器上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 中性原子量子架构因其能够利用里德堡阻塞机制直接在图上编码独立集约束而受到关注，作者希望利用这一特性解决无人机配送装箱这一实际优化问题。

Method: 将无人机配送装箱问题重新表述为基于调度图独立集的图划分问题，每个划分对应分配给单个无人机的配送任务。使用混合量子-经典框架：量子处理器寻找独立集（时间可行的调度），经典后处理程序强制执行电池续航约束。

Result: 通过数值模拟和Pasqal Fresnel量子处理器的硬件实验验证了混合工作流的有效性，报告了多达100个原子的配置实验，能够恢复最优配送调度方案。

Conclusion: 中性原子量子处理器能够有效解决无人机配送装箱问题，混合量子-经典框架结合了量子计算的优势和经典后处理，为解决实际优化问题提供了有前景的途径。

Abstract: Quantum architectures based on neutral atoms have gained significant attention in recent years as specialized computational machines due to their ability to directly encode the independent set constraint on graphs, exploiting the Rydberg blockade mechanism. In this work, we address the Drone Delivery Packing Problem via a hybrid quantum-classical framework leveraging a neutral-atom quantum processing unit (QPU). We reformulate the optimization task as a graph-partitioning problem based on the independent sets (ISs) of a scheduling graph that encodes delivery incompatibilities. Each partition corresponds to deliveries assigned to a single drone, with the objective of minimizing the total number of partitions. While the ISs represent time-feasible schedules, battery-duration constraints are enforced through a classical post-processing routine. This methodology enables the recovery of optimal delivery schedules, provided a sufficient number of samples is collected from the QPU to resolve the solution space. We benchmark the hybrid workflow through numerical emulations and demonstrate its effectiveness on Pasqal's Fresnel QPU, reporting hardware experiments with configurations of up to 100 atoms.

</details>


### [112] [Universal entanglement-inspired correlations](https://arxiv.org/abs/2602.15520)
*Elizabeth Agudelo,Laura Ares,Jan Sperling*

Main category: quant-ph

TL;DR: 该论文提出了一种广义的量子关联概念，通过任意乘积来定义相关性，建立了广义乘积与张量积之间的联系，并构建了适用于广义乘积的资源理论框架。


<details>
  <summary>Details</summary>
Motivation: 量子关联在量子科学与技术中至关重要，但传统上仅通过张量积分解来定义纠缠。作者希望建立一个更广义的关联概念，能够涵盖更广泛的乘积结构，从而统一处理不同类型的量子相关性。

Method: 1. 提出广义的关联概念，通过任意乘积（而非仅限于张量积）来定义相关性；2. 建立广义乘积与张量积之间的普遍联系；3. 扩展LOCC范式，构建适用于广义乘积的自由操作集合；4. 建立广义乘积的资源理论；5. 将理论推广到多因子情况，并与多体纠缠建立联系。

Result: 成功建立了广义乘积与张量积之间的普遍联系，使得任意非乘积态都能与传统的纠缠态相关联。构建了完整的广义乘积资源理论框架，并展示了该理论在多个领域的应用潜力。

Conclusion: 该研究提供了一个统一的框架来处理广义的量子关联，将传统的纠缠理论推广到更广泛的乘积结构。这一理论不仅深化了对量子相关性的理解，还在费米子态分解、多光子态分解、甚至素数作为单方纠缠等方面展现出应用价值。

Abstract: Quantum correlations, crucial for the advantage and advancement of quantum science and technology, arise from the impossibility of expressing a quantum state as a tensor product over a given set of parties. In this work, a generalized notion of correlations via arbitrary products is formulated. Remarkably, as a universal property, the connection between such general products and tensor products is established, allowing one to relate generic non-product states to the common notion of entangled states. We construct the set of free operations for general types of products by extending the local-operation-and-classical-communication paradigm, familiar from standard entanglement theory, thereby establishing a resource theory of correlations for general products. A generalization is provided beyond two factors that can be universally related to multipartite entanglement. Applications that highlight the usefulness of the approach are discussed, such as the factorization of fermionic states, the non-local factorization of multi-photon states into single-photon states, and the interesting possibility of understanding prime numbers as a form of single-party entanglement.

</details>


### [113] [Observing quantum many-body dynamics in emergent curved spacetime using programmable quantum processors](https://arxiv.org/abs/2602.15524)
*Brendan Rhyno,Bastien Lapierre,Smitha Vishveshwara,Khadijeh Najafi,Ramasubramanian Chitra*

Main category: quant-ph

TL;DR: 使用80个超导量子比特在IBM Heron处理器上数字模拟量子多体动力学，通过工程化空间变化的耦合实现弯曲时空背景下的激发传播


<details>
  <summary>Details</summary>
Motivation: 探索在可调谐和合成弯曲时空中量子多体动力学的详细控制研究，建立大规模数字量子处理器作为灵活平台

Method: 在自旋-1/2 XXZ链中工程化空间变化的耦合，与不均匀Tomonaga-Luttinger液体的低能描述一致，使用80个超导量子比特在IBM Heron处理器上进行数字模拟

Result: 观察到弯曲光锥传播、视界诱导的局域磁化冻结、由工程化空间变形设定的位置依赖振荡频率，尽管存在强空间不均匀性，不等时关联函数显示自旋链中的弹道准粒子传播

Conclusion: 大规模数字量子处理器为在可调谐和合成弯曲时空中进行详细控制的多体动力学探索建立了灵活平台

Abstract: We digitally simulate quantum many-body dynamics in emergent curved backgrounds using 80 superconducting qubits on IBM Heron processors. By engineering spatially varying couplings in the spin-$\frac12$ XXZ chain, consistent with the low energy description of the model in terms of an inhomogeneous Tomonaga-Luttinger liquid, we realize excitations that follow geodesics of an effective metric inherited from the underlying spatial deformation. Following quenches from Néel and few-spin-flip states, we observe curved light-cone propagation, horizon-induced freezing in the local magnetization, and position-dependent oscillation frequencies set by the engineered spatial deformation. Despite strong spatial inhomogeneity, unequal-time correlators reveal ballistic quasiparticle propagation in the spin chain. These results establish large-scale digital quantum processors as a flexible platform for detailed and controlled exploration of many-body dynamics in tunable and synthetic curved spacetimes.

</details>


### [114] [Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model](https://arxiv.org/abs/2602.15529)
*Fabien Dufoulon,Frédéric Magniez,Gopal Pandurangan*

Main category: quant-ph

TL;DR: 本文提出了分布式量子算法，在量子路由模型中实现了近乎最优的消息复杂度，解决了领导者选举、广播、最小生成树和广度优先搜索树等基本分布式计算问题。


<details>
  <summary>Details</summary>
Motivation: 研究量子路由模型在分布式计算中的通信优势，相比经典分布式算法需要Ω(m)消息下界，量子算法有望实现通信成本的二次加速。

Method: 基于电网路的量子游走技术，构建了一个在分布式环境中设计通信高效量子算法的框架，可作为黑盒使用来显著降低通信成本。

Result: 实现了领导者选举、广播和MST的Õ(n)消息复杂度，BFS的Õ(√mn)消息复杂度，这些边界在量子路由模型中近乎紧致，相比先前工作Õ(√mn)的领导者选举算法有显著改进。

Conclusion: 量子路由在分布式计算中具有显著的通信优势，相比经典算法可实现通信成本的二次加速，提出的量子游走框架和量子消息下界技术具有独立的研究价值。

Abstract: We present new distributed quantum algorithms for fundamental distributed computing problems, namely, leader election, broadcast, Minimum Spanning Tree (MST), and Breadth-First Search (BFS) tree, in arbitrary networks. These algorithms are (essentially) optimal with respect to their communication (message) complexity in the {\em quantum routing model} introduced in [PODC 2025]. The message complexity of our algorithms is $\tilde{O}(n)$ for leader election, broadcast, and MST, and $\tilde{O}(\sqrt{mn})$ for BFS ($n$ and $m$ are the number of nodes and edges of the network, respectively). These message bounds are nearly tight in the quantum routing model since we show almost matching corresponding quantum message lower bounds. Our results significantly improve on the prior work of [PODC 2025], who presented distributed quantum algorithms under the same model that had a message complexity of $\tilde{O}(\sqrt{mn})$ for leader election.
  Our algorithms demonstrate the significant communication advantage that quantum routing has over classical in distributed computing, since $Ω(m)$ is a well-established classical message lower bound for leader election, broadcast, MST, and BFS that applies even to randomized Monte-Carlo algorithms [JACM 2015]. Thus, our quantum algorithms can, in general, give a quadratic advantage in the communication cost for these fundamental problems.
  A main technical tool we use to design our distributed algorithms is quantum walks based on electric networks. We posit a framework for using quantum walks in the distributed setting to design communication-efficient distributed quantum algorithms. Our framework can be used as a black box to significantly reduce communication costs and may be of independent interest. Additionally, our lower-bound technique for establishing distributed quantum message lower bounds can also be applied to other problems.

</details>


### [115] [Optimal Classification of Three-Qubit Entanglement with Cascaded Support Vector Machine](https://arxiv.org/abs/2602.15545)
*Fatemeh Sadat Lajevardi,Azam Mani,Ali Fahim*

Main category: quant-ph

TL;DR: 提出基于级联SVM分类器的三量子比特纠缠分类框架，通过三个顺序模型区分四个纠缠类别，达到95%准确率，并具有抗噪声和特征优化能力。


<details>
  <summary>Details</summary>
Motivation: 三量子比特系统具有明确的纠缠结构（S、B、W、GHZ四个嵌套类别），需要一种系统化的分类方法。现有方法可能缺乏鲁棒性或效率不高，因此需要开发一个既能准确分类又能抵抗量子噪声的框架。

Method: 采用级联SVM分类器架构，构建三个顺序模型（ℳ_B、ℳ_W、ℳ_GHZ）来区分四个纠缠类别。通过系统化的特征重要性分析进行优化，减少所需特征数量，同时保持模型准确性。

Result: 在混合态数据集上达到95%的整体分类准确率。模型在分布外纠缠态和各种量子噪声通道下保持高性能，证明了其鲁棒性和泛化能力。特征优化协议显著减少了所需特征数量。

Conclusion: 该级联SVM框架为三量子比特纠缠分类提供了一种高效、鲁棒且可调的系统化方法，在量子噪声环境下仍能保持高准确率，并通过特征优化提高了计算效率。

Abstract: We introduce a systematic framework for three-qubit entanglement classification using a cascaded architecture of Support Vector Machine (SVM) classifiers. Leveraging the well defined three-qubit structure with the four nested entanglement classes (S, B, W, and GHZ), we construct three distinct witness models ($\mathcal{M}_{B}$, $\mathcal{M}_{W}$, and $\mathcal{M}_{GHZ}$) that sequentially discriminate between these classes. The proposed Cascaded model achieves an overall classification accuracy of $95\%$ on a comprehensive dataset of mixed states. The framework's robustness and generalization capabilities are confirmed through rigorous testing against out-of-distribution (OOD) entangled states and various quantum noise channels, where the model maintains high performance. A key contribution of this research is an optimization protocol based on systematic feature importance analysis. This approach yields a tunable framework that significantly reduces the number of required features, while maintaining reliable model accuracy.

</details>


### [116] [Theory of temporal three-photon interference](https://arxiv.org/abs/2602.15573)
*Nilakshi Senapati,Girish Kulkarni,Anand K. Jha*

Main category: quant-ph

TL;DR: 三光子干涉理论框架：将三光子干涉表述为"每个三光子只与自身干涉"，揭示了仅需三个独立参数即可完全表征，比双光子干涉更复杂，为三光子纠缠实验提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 级联参量下转换(CPDC)和三阶参量下转换(TOPDC)的实验进展为研究真正的三光子干涉创造了条件。需要建立三光子干涉的理论框架来理解三光子纠缠的丰富量子关联，并为实验提供指导。

Method: 将三光子干涉表述为"每个三光子只与自身干涉"的概念框架。基于CPDC或TOPDC的广义双替代三光子干涉设置涉及八个不同长度参数，但证明仅需三个独立参数即可完全表征：三光子路径长度差和两个路径不对称长度参数。

Result: 三光子干涉需要两个独立参数来量化路径不对称性（双光子干涉只需一个），这导致更广泛的非经典三光子效应，包括三光子HOM型效应。建立了三光子干涉的完整参数化描述。

Conclusion: 该工作为现有和未来的三光子干涉实验提供了理论基础，能够探索与三粒子纠缠相关的丰富复杂量子关联，并可能开发利用这些关联的新协议。

Abstract: The recent demonstrations of cascaded PDC (CPDC) and the hopeful prospects of realizing third-order PDC (TOPDC) for the generation of three-photon entangled states are paving the way for experimental studies on genuine three-photon interference. In this article, we formulate three-photon interference in terms of ``each three-photon interfering only with itself.'' We show that although a generalized two-alternative three-photon interference setup based on CPDC or TOPDC involves eight different length parameters, the interference can be fully characterized in terms of only three independent parameters. The first parameter is the three-photon path-length difference, which has a direct analog in the one-photon and two-photon cases, and the other two parameters quantify the path-asymmetry length. Unlike two-photon interference, which requires only one parameter to quantify path-asymmetry, two independent parameters are needed in three-photon interference. This results in a broader class of nonclassical three-photon effects, including three-photon HOM-type effects. Our work provides the theoretical basis for existing and future three-photon interference experiments exploring the rich and complex quantum correlations associated with three-particle entanglement and potentially enabling the development of novel protocols for harnessing those correlations.

</details>


### [117] [Magnetically assisted spin-resolved electron diffraction: Coherent control of spin population and spatial filtering](https://arxiv.org/abs/2602.15615)
*Sushanta Barman,Kuldeep Godara,Sudeep Bhattacharjee*

Main category: quant-ph

TL;DR: 该研究开发了自洽的Maxwell-Pauli框架来研究纳米光栅中自旋分辨电子衍射，发现电子概率电流产生的本征磁场太弱无法引起可测量的自旋混合，但外部磁场可以实现相干自旋控制和空间分离。


<details>
  <summary>Details</summary>
Motivation: 纳米光栅中的电子衍射为自由电子干涉提供了平台，但电子自旋在这种几何结构中的受控操纵尚未充分探索。特别是电子运动产生的自生磁场的作用，以及在不破坏衍射相干性的情况下实现相干自旋控制的可行性，尚未得到定量研究。

Method: 开发了自洽的Maxwell-Pauli框架来研究存在磁场时纳米光栅中的自旋分辨电子衍射。该模型结合了几何约束、镜像电荷相互作用、自生静磁场和外部施加的磁场。使用数值模拟分析自旋混合效应，并通过Husimi Q函数相空间图可视化自旋相关的动力学。

Result: 电子概率电流产生的本征磁场比引起可测量自旋混合所需的磁场弱几个数量级，表明纳米光栅在无场条件下可作为自旋守恒的分束器。上游均匀磁场可实现相干拉莫尔进动，实现受控自旋旋转而不改变衍射几何或降低相干性。下游非均匀磁场产生空间变化的塞曼相位，导致两个自旋分量的相反横向动量偏移。

Conclusion: 该方法实现了自旋分辨自由电子束的可调空间分离，建立了相干自旋旋转、控制和干涉的全磁学途径，为纳米光栅中的自旋分辨电子衍射提供了定量框架。

Abstract: Electron diffraction from nanogratings provides a platform for free-electron interferometry, yet controlled manipulation of electron spin in such geometries remains largely unexplored. In particular, the role of the self-generated magnetic field arising from electron motion and the feasibility of coherent spin control without disrupting diffraction coherence have not been quantitatively investigated. In this article, a self-consistent Maxwell-Pauli framework is developed to study spin-resolved electron diffraction from nanogratings in the presence of magnetic fields. The model incorporates geometric confinement, image-charge interactions, self-generated magnetostatic fields, and externally applied magnetic fields. Numerical simulations show that the intrinsic magnetic self-field produced by the electron probability current is several orders of magnitude too weak to induce measurable spin mixing, demonstrating that nanogratings act as spin-conserving beam splitters under field-free conditions. When a uniform magnetic field is applied upstream of the nanograting, coherent Larmor precession enables controlled spin rotation without modifying the diffraction geometry or degrading coherence. The magnetic field required for a $π$ spin rotation scales inversely with the interaction length and electron de Broglie wavelength $λ_{dB}$. Furthermore, a downstream nonuniform magnetic field applied after the nanograting imparts a spatially varying Zeeman phase, producing opposite transverse momentum shifts for the two spin components. The spin-dependent transverse dynamics is analyzed using Husimi Q-function phase-space maps, which visualize spin-dependent population redistribution and momentum separation. The proposed approach enables tunable spatial separation of spin-resolved free electron beams and establishes an all-magnetic route for coherent spin rotation, control, and interferometry.

</details>


### [118] [Nonlinear Phase Gates Beyond the Lamb-Dicke Regime](https://arxiv.org/abs/2602.15619)
*Akram Kasri,Kimin Park,Radim Filip*

Main category: quant-ph

TL;DR: 利用离子阱系统中的双音边带驱动实现非线性相位门，通过利用高阶相互作用项，相比现有理论方案减少近三分之二的控制脉冲


<details>
  <summary>Details</summary>
Motivation: 非线性相位门是实现连续变量量子处理通用性的关键，但现有方法通常需要复杂的控制脉冲

Method: 在离子阱系统中使用超越兰姆-迪克区域的双音边带驱动，利用通常被忽略或抑制的高阶相互作用项来构建非线性相位门

Result: 实现了高保真度的门工程，相比最先进的理论方案减少了近三分之二的控制脉冲

Conclusion: 该方法为连续变量量子处理提供了一种高效的非线性相位门实现方案，通过利用高阶相互作用简化了控制复杂度

Abstract: Nonlinear phase gates are essential to achieve the universality of continuous-variable quantum processing and its applications. We present a deterministic protocol for generating nonlinear phase gates in trapped ion systems using simultaneous two-tone sideband drives beyond the Lamb-Dicke regime. Our approach harnesses higher-order interaction terms typically neglected or suppressed to construct nonlinear phase gates. This methodology enables high-fidelity gate engineering with a near three-fold reduction in control pulses compared to state-of-the-art theoretical proposals.

</details>


### [119] [Controlling correlations of a polaritonic Luttinger liquid by engineered cross-Kerr nonlinearity](https://arxiv.org/abs/2602.15630)
*Nabaneet Sharma,Anushree Dey,Bimalendu Deb*

Main category: quant-ph

TL;DR: 在超导电路量子电动力学平台上，通过设计交叉克尔非线性模拟吸引性最近邻相互作用，研究了多连接Jaynes-Cummings晶格中零温极化子的关联特性，推导出扩展的双模玻色-哈伯德模型，并利用玻色化方法得到有效Luttinger液体描述。


<details>
  <summary>Details</summary>
Motivation: 研究多连接Jaynes-Cummings晶格中极化子的关联特性，特别是在超导电路平台中通过工程化交叉克尔非线性来模拟吸引性最近邻相互作用，探索这种系统在量子模拟和量子信息处理中的潜力。

Method: 采用多连接Jaynes-Cummings晶格模型，通过阶梯型qutrits实现最近邻谐振子模式间的交叉克尔耦合。投影到低极化子流形，推导出扩展的双模玻色-哈伯德模型，然后使用连续玻色化方法将哈密顿量表示为对称和反对称集体模式。

Result: 在反对称模式获得有限能隙的区域，系统可简化为对称模式的有效单分量Luttinger液体模型。交叉克尔项降低了对称模式的压缩性，从而增大了相应的Luttinger参数K+，导致单粒子关联函数以更慢的代数衰减：G(x)∝|x|^{-1/(4K+)}。

Conclusion: 在超导电路平台上实现的多连接Jaynes-Cummings晶格系统能够有效模拟具有吸引性最近邻相互作用的扩展玻色-哈伯德模型，交叉克尔相互作用增强了系统的量子关联特性，表现为更慢衰减的单粒子关联函数。

Abstract: We study correlation properties of polaritons at zero temperature in a multiconnected Jaynes--Cummings (MCJC) lattice on a superconducting circuit quantum electrodynamics platform with engineered cross-Kerr nonlinearity that mimics attractive nearest-neighbour interaction. A multi-connected Jaynes--Cummings lattice is a one-dimensional lattice constructed from alternating qubits and resonators with different left and right couplings. The nearest-neighbour interaction or cross-Kerr coupling is implemented dispersively through ladder-type qutrits between each nearest neighboring pair of resonator modes. Projecting onto the lower-polaritonic manifold, we derive an extended two-mode (bipartite) Bose--Hubbard-like model featuring on-site and attractive nearest-neighbor interactions. Employing a continuum bosonization approach, we express the Hamiltonian in terms of symmetric ($+$) and antisymmetric ($-$) collective modes. In the regime where the ($-$) sector acquires a finite gap, one can reduce the system to an effective single-component Luttinger liquid model for the $+$ sector. The cross-Kerr term reduces the compressibility of the ($+$) mode, thereby enhancing the corresponding Luttinger parameter $K_{+}$, resulting in the slower algebraic decay of single-particle correlations, $G(x)\propto|x|^{-1/(4K_{+})}$.

</details>


### [120] [High-rate Scalable Entanglement Swapping Between Remote Entanglement Sources on Deployed New York City Fibers](https://arxiv.org/abs/2602.15653)
*Alexander N. Craddock,Tyler Cowan,Niccolò Bigagli,Suresh Yekasiri,Dylan Robinson,Gabriel Bello Portmann,Ziyu Guo,Michael Kilzer,Jiapeng Zhao,Mael Flament,Javad Shabani,Reza Nejabati,Mehdi Namazi*

Main category: quant-ph

TL;DR: 利用基于热原子蒸气池的自然不可区分纠缠源，在电信光纤基础设施上实现了可扩展的纠缠交换实验，无需节点间共享激光或光频参考，也不需要对源进行脉冲调制，实现了近500对/秒的交换速率，并在纽约市17.6公里已部署光纤上展示了方法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在物理分离节点之间通过电信光纤基础设施进行纠缠交换是实现量子互联网的关键步骤，支持量子中继器、盲量子计算、分布式量子计算和分布式量子传感等应用。然而，大多数先前演示仅限于实验室环境或需要复杂方法来维持必要的不可区分性。

Method: 使用基于热原子蒸气池的自然不可区分纠缠源，无需节点间共享激光或光频参考，也不需要对源进行脉冲调制。在纽约市17.6公里已部署光纤上进行了实验，在辐条节点使用商用SPADs，在中心节点使用SNSPDs，并采用标准时间同步技术。

Result: 实现了近500对/秒的纠缠交换速率，同时保持CHSH参数高于2。在17.6公里已部署光纤上成功展示了纠缠交换的质量保持，证明了方法的可扩展性。

Conclusion: 这项工作为在城市和数据中心内部实际部署大规模中心辐射型量子网络铺平了道路，展示了使用自然不可区分纠缠源进行可扩展纠缠交换的可行性。

Abstract: Entanglement swapping between photon pairs generated at physically separated nodes over telecommunication fiber infrastructure is an essential step towards the quantum internet, enabling applications such as quantum repeaters, blind quantum computing, distributed quantum computing, and distributed quantum sensing. However, successful networked entanglement swapping relies on generating indistinguishable pairs of photons and preserving them over deployed fibers. This has limited most previous demonstrations to laboratory settings or relied on sophisticated methods to maintain the necessary indistinguishability. Here, we demonstrate a scalable entanglement swapping experiment using naturally indistinguishable entanglement sources based on warm atomic vapor cells. Without sharing lasers or optical frequency references between nodes, nor the need for pulsing the sources, we achieve a swapping rate of nearly 500 pairs/s while maintaining the CHSH parameter above 2. Additionally, we demonstrate the scalability of our method by maintaining the quality of the entanglement swapping on 17.6-km of deployed fibers in NYC, relying on commercially available SPADs at the spoke nodes, SNSPDs at the hub and standard time-synchronization techniques. Our work paves the way for the practical deployment of large-scale hub-and-spoke quantum networks within cities and data centers.

</details>


### [121] [Generating quantum entanglement from sunlight](https://arxiv.org/abs/2602.15655)
*Cheng Li,Jasvinder Brar,Michael Küblböck,Jeremy Upham,Hanieh Fattahi,Robert W. Boyd*

Main category: quant-ph

TL;DR: 利用自然阳光替代激光，通过自发参量下转换产生量子纠缠态，实现了可持续的量子技术应用


<details>
  <summary>Details</summary>
Motivation: 量子技术集成到现有信息基础设施面临严重的能耗瓶颈，传统激光器的高相干性被认为是量子态制备的必要条件，但带来了巨大的能量开销

Method: 使用自然、非相干阳光替代激光，通过自发参量下转换过程产生偏振纠缠光子对

Result: 检测到纠缠度为0.905±0.053的偏振纠缠光子对，贝尔态保真度为0.939±0.027，违反贝尔不等式S=2.5408±0.2171（超过经典阈值2），生成速率与激光系统相当

Conclusion: 自然阳光可以成功产生量子纠缠态，这为资源受限环境（如星际任务）中的可持续量子应用开辟了新途径

Abstract: Energy consumption is becoming a serious bottleneck for integrating quantum technologies within the existing global information infrastructure. In photonic architectures, considerable energy overheads stem from using lasers, whose high coherence was long considered indispensable for quantum state preparation. Here, we demonstrate that natural, incoherent sunlight can successfully produce quantum-entangled states via spontaneous parametric down-conversion. We detect polarization-entangled photon pairs with a concurrence of $0.905\pm0.053$ and a Bell state fidelity of $0.939\pm0.027$. Importantly, the system violates Bell's inequality with $S=2.5408\pm0.2171$, exceeding the classical threshold of 2, while maintaining generation rates comparable to laser-based setups. These findings pave the way for sustainable quantum applications in resource-limited environments like interplanetary missions.

</details>


### [122] [Meta-Learning for GPU-Accelerated Quantum Many-Body Problems](https://arxiv.org/abs/2602.15706)
*Yun-Hsuan Chen,Jen-Yu Chang,Tsung-Wei Huang,En-Jui Kuo*

Main category: quant-ph

TL;DR: VQE-LSTM框架通过元学习和GPU加速量子模拟，在化学和物理领域实现高效变分量子计算，达到近FCI精度并保持O(N²)复杂度。


<details>
  <summary>Details</summary>
Motivation: 探索VQE-LSTM框架在工业和科学应用中的潜力，通过集成元学习和GPU加速量子模拟，扩展变分量子本征求解器在化学和物理领域的实际应用范围。

Method: 结合LSTM-FC元初始化模块与NVIDIA CUDA-Q平台，在GPU加速量子模拟中应用VQE和VQD方法。化学领域使用PySCF生成分子哈密顿量，物理领域应用于量子化简谐运动系统。

Result: 化学领域：预测分子基态能量达到近FCI精度，保持O(N²)的分子尺寸缩放。物理领域：成功再现简谐运动系统的基态和激发态。GPU实现相比CPU显著加速，验证了CUDA-Q处理大规模变分工作负载的能力。

Conclusion: VQE-LSTM是一个可行且可扩展的GPU加速量子模拟方法，通过统一的元学习初始化策略，桥接了量子化学和凝聚态物理领域。

Abstract: We explore the industrial and scientific applicability of the VQE-LSTM framework by integrating meta-learning with GPU accelerated quantum simulation using NVIDIA's CUDA-Q (CUDAQ) platform. This work demonstrates how an LSTM-FC meta-initialization module can extend the practical reach of the Variational Quantum Eigensolver (VQE) in both chemistry and physics domains. In the chemical regime, the framework predicts ground-state energies of molecular Hamiltonians derived from PySCF, achieving near FCI accuracy while maintaining favorable O(N^2) scaling with molecular size. In the physical counterpart, we applied the same model to quantized Simple Harmonic Motion systems (SHM), successfully reproducing its ground and excited states through VQE and Variational Quantum Deflation (VQD) methods. Benchmark results on NVIDIA GPUs reveal significant speedups over CPU-based implementations, validating CUDAQ's capability to handle large-scale variational workloads efficiently. Overall, this study establishes VQE-LSTM as a viable and scalable approach for GPU accelerated quantum simulation, bridging quantum chemistry and condensed-matter physics through a unified, meta-learned initialization strategy.

</details>


### [123] [Steady state coherence in a qubit is incompatible with a quantum map](https://arxiv.org/abs/2602.15790)
*Hans C. Fogedby*

Main category: quant-ph

TL;DR: 该论文重新分析了单量子比特在复合系统-环境相互作用下的稳态相干性问题，发现Redfield方法会产生负概率问题，而Lindblad方程虽然符合量子映射但无法产生稳态相干性，最终得出结论：量子比特的稳态相干性与量子映射不相容。


<details>
  <summary>Details</summary>
Motivation: 重新分析Guarnieri18提出的复合系统-环境相互作用下量子比特的稳态相干性问题，检验不同理论方法的有效性。

Method: 采用场论方法重新分析问题，在Redfield描述框架内进行研究，并与Lindblad方程进行对比。

Result: Redfield方法虽然能产生稳态相干性，但违反了量子映射性质并导致负概率；Lindblad方程符合量子映射性质，但无法产生稳态相干性。

Conclusion: 量子比特的稳态相干性与量子映射不相容，这意味着在保持量子映射性质的前提下，无法实现量子比特的稳态相干性。

Abstract: We consider the issue of steady state coherences in a single qubit in the case of a composite system-bath interaction as proposed in \cite{Guarnieri18}. Based on a field theoretical approach we reanalyse the issue within a Redfield description. We find that the Redfield approach in accordance with \cite{Guarnieri18} yields steady state coherences but violating the properties of a quantum map also gives rise to negative populations. The issue is resolved by applying the Lindblad equation which is in accordance with a proper quantum map. The Lindblad equation, however, also implies the absence of steady state coherence. We conclude that steady state coherence in a a qubit is incompatible with a quantum map.

</details>


### [124] [Entanglement in the Dicke subspace](https://arxiv.org/abs/2602.15800)
*Aabhas Gulati,Ion Nechita,Clément Pellegrini*

Main category: quant-ph

TL;DR: 本文为Dicke态混合态的纠缠提供了完整的数学理论，建立了纠缠性质与张量凸锥的直接对应关系，构造了多体系统中PPT纠缠态的存在性证明，并提出了基于半定规划的纠缠检测方法。


<details>
  <summary>Details</summary>
Motivation: 研究Dicke态混合态的纠缠理论，这类量子态在不可区分粒子的研究中具有重要意义。需要建立系统的数学框架来分析这类特殊玻色子态的纠缠性质。

Method: 引入基于张量的参数化方法，将Dicke态的对角项编码为对称张量，建立纠缠性质与张量凸锥的对应关系。利用半代数几何和完全正/余正张量理论，构建分离性、PPT性质、纠缠见证等概念的张量对应。

Result: 证明了在三体或更多qutrit系统中存在PPT纠缠态，反驳了近期的一个猜想。建立了Dicke态混合态中PPT性质在平衡二分划下的传递性。将玻色子可扩展性与非负多项式层次结构联系起来，提出了基于半定规划的纠缠检测松弛方法。

Conclusion: 本文为Dicke态混合态的纠缠提供了完整的数学理论框架，建立了多体纠缠理论与半代数几何、张量理论之间的桥梁，为纠缠检测提供了有效的计算工具，并解决了相关领域的重要猜想。

Abstract: In this paper, we provide a complete mathematical theory for the entanglement of mixtures of Dicke states. These quantum states form an important subclass of bosonic states arising in the study of indistinguishable particles. We introduce a tensor-based parametrization where the diagonal entries of these states are encoded as a symmetric tensor, enabling a direct translation between entanglement properties and well-studied convex cones of tensors. Our results bridge multipartite entanglement theory with semialgebraic geometry and the theory of completely positive and copositive tensors. This dictionary maps separability to completely positive tensors, the PPT property to moment tensors, entanglement witnesses to copositive tensors, and decomposable witnesses to sum of squares tensors. Using this framework, we construct explicit PPT entangled states in three or more qutrits. In this class of states, we establish that PPT entanglement exists for all multipartite systems with three qutrits or more, disproving a recent conjecture in [J. Math. Phys. 66, 022203 (2025)]. We also show that, for mixtures of Dicke states, the PPT condition with respect to the most balanced bipartition implies PPT with respect to any other bipartition. We further connect bosonic extendibility of mixtures of Dicke states to the duals of known hierarchies for non-negative polynomials, such as the ones by Reznick and Polya. We thus provide semidefinite programming relaxations for separability and entanglement testing in the Dicke subspace.

</details>


### [125] [QwaveMPS: An efficient open-source Python package for simulating non-Markovian waveguide-QED using matrix product states](https://arxiv.org/abs/2602.15826)
*Sofia Arranz Regidor,Matthew Kozma,Stephen Hughes*

Main category: quant-ph

TL;DR: QwaveMPS是一个用于模拟一维量子多体波导系统的开源Python库，使用矩阵乘积态方法，能够高效研究波导QED系统中的量子动力学


<details>
  <summary>Details</summary>
Motivation: 传统全希尔伯特空间方法在模拟波导QED系统时计算成本过高，特别是对于非马尔可夫时延反馈效应和深度非线性系统。需要一种能够高效、可扩展地模拟一维量子波导系统的方法，同时能够平等处理量子化原子和量子化光子

Method: 开发基于矩阵乘积态的开源Python库QwaveMPS，提供用户友好的接口来构建、演化和分析量子态和算符。该方法通过将计算资源集中在量子系统最相关的部分来实现高效、可扩展的模拟

Result: QwaveMPS能够以远低于全希尔伯特空间方法的计算成本研究复杂的动力学相互作用，包括非马尔可夫区域的时间延迟反馈效应和深度非线性系统。该库使得模拟各种开放波导-QED系统（马尔可夫和非马尔可夫区域）变得实用且方便

Conclusion: QwaveMPS为研究一维量子波导系统提供了一个强大而高效的工具，特别适用于波导QED系统中的量子物理和量子信息研究，能够平等处理量子化原子和光子，显著降低了计算成本

Abstract: QwaveMPS is an open-source Python library for simulating one-dimensional quantum many-body waveguide systems using matrix product states (MPS). It provides a user-friendly interface for constructing, evolving, and analyzing quantum states and operators, facilitating studies in quantum physics and quantum information with waveguide QED systems. This approach enables efficient, scalable simulations by focusing computational resources on the most relevant parts of the quantum system. Thus, one can study a wide range of complex dynamical interactions, including time-delayed feedback effects in the non-Markovian regime and deeply non-linear systems, at a highly reduced computational cost compared to full Hilbert space approaches, making it both practical and convenient to model a variety of open waveguide-QED systems (in Markovian and non-Markovian regimes), treating quantized atoms and quantized photons on an equal footing.

</details>
