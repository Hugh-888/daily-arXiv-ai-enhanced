<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 73]
- [quant-ph](#quant-ph) [Total: 45]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [gr-qc](#gr-qc) [Total: 11]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: 提出基于条件扩散模型的电磁逆向设计方法，直接从目标散射截面生成介质几何结构，无需迭代优化，显著提升设计效率。


<details>
  <summary>Details</summary>
Motivation: 传统电磁逆向设计依赖昂贵的迭代优化过程，耗时长且效率低，需要开发能够直接从目标性能生成结构的高效方法。

Method: 使用1D U-Net架构结合特征线性调制，训练条件扩散模型学习从目标角散射模式到2x2介电球结构的映射，处理逆向问题的非唯一性。

Result: 在11,000个模拟超表面数据集上训练，对未见目标的MPE中位数低于19%（最佳1.39%），优于CMA-ES进化优化，设计时间从小时级降至秒级。

Conclusion: 扩散模型在电磁逆向设计中具有巨大潜力，能够快速探索复杂超表面架构，加速下一代光子和无线通信系统开发。

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


### [2] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: KV缓存管理策略与模型架构限制的交互影响：当累积KV缓存接近或超过模型训练上下文窗口时，LLM生成质量急剧下降，位置编码完整性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 在状态化多轮对话场景中，KV缓存的无限制增长带来重大挑战，需要研究缓存管理策略与模型架构限制的相互作用。

Method: 使用状态化基准测试框架进行实证分析，比较不同缓存逐出策略（包括高保留率策略如AttentionTop）对生成质量的影响。

Result: 当KV缓存接近模型训练上下文窗口（如Llama 3的8192 tokens）时，生成质量急剧下降；位置不连贯的缓存压缩会扰乱位置信号导致退化输出；保持连续上下文块的简单策略比复杂策略产生更连贯的生成结果。

Conclusion: 缓存逐出技术应尊重架构限制、保持位置结构，并将"缓存健康"视为超越单纯大小的整体概念。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [3] [Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2511.04718)
*Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang*

Main category: cs.LG

TL;DR: 提出了一个自适应频率分解框架，用于从静息态fMRI数据中学习任务相关的频率子带，并通过频率耦合连接学习捕获跨频带交互，从而提升脑部疾病诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了神经元振荡的多频率特性，将BOLD信号视为单一时间序列处理，这限制了诊断敏感性和特异性。神经疾病通常在特定频率带表现出异常，但现有方法使用预定义频率带，无法适应个体差异和疾病特异性改变。

Method: 提出自适应级联分解学习每个脑区的任务相关频率子带，频率耦合连接学习捕获频带内和跨频带交互，构建统一功能网络，并设计统一图卷积网络进行消息传递生成节点表示用于诊断预测。

Result: 在ADNI和ABIDE数据集上的实验结果表明，该方法优于现有方法。

Conclusion: 该框架通过自适应频率分解和频率耦合连接学习，有效提升了脑部疾病诊断的准确性和特异性。

Abstract: Resting-state fMRI has become a valuable tool for classifying brain disorders
and constructing brain functional connectivity networks
  by tracking BOLD signals across brain regions. However, existing mod els
largely neglect the multi-frequency nature of neuronal oscillations,
  treating BOLD signals as monolithic time series. This overlooks the cru cial
fact that neurological disorders often manifest as disruptions within
  specific frequency bands, limiting diagnostic sensitivity and specificity.
  While some methods have attempted to incorporate frequency informa tion, they
often rely on predefined frequency bands, which may not be
  optimal for capturing individual variability or disease-specific alterations.
  To address this, we propose a novel framework featuring Adaptive Cas cade
Decomposition to learn task-relevant frequency sub-bands for each
  brain region and Frequency-Coupled Connectivity Learning to capture
  both intra- and nuanced cross-band interactions in a unified functional
  network. This unified network informs a novel message-passing mecha nism
within our Unified-GCN, generating refined node representations
  for diagnostic prediction. Experimental results on the ADNI and ABIDE
  datasets demonstrate superior performance over existing methods. The
  code is available at https://github.com/XXYY20221234/Ada-FCN.

</details>


### [4] [AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting](https://arxiv.org/abs/2511.04722)
*Qianyang Li,Xingjun Zhang,Peng Tao,Shaoxun Wang,Yancheng Pan,Jia Wei*

Main category: cs.LG

TL;DR: AWEMixer是一种自适应小波增强混合网络，用于解决IoT环境中长期时间序列预测的挑战，通过频率路由器和相干门控融合块实现精确的时频定位，在七个公共基准测试中优于现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: IoT环境中的传感器信号具有非平稳和多尺度特性，传统方法局限于时域操作，而傅里叶变换获得的全局频率信息被视为平稳信号，会模糊瞬态事件的时间模式。误差累积导致预测质量随预测时间增加而下降。

Method: 提出AWEMixer网络，包含两个创新组件：1）频率路由器，利用快速傅里叶变换获得的全局周期性模式自适应加权局部小波子带；2）相干门控融合块，通过交叉注意力和门控机制实现突出频率特征与多尺度时间表示的选择性集成。

Result: 在七个公共基准测试中验证了模型的有效性，相比基于Transformer和MLP的最先进模型，在长序列时间序列预测中持续实现性能提升。

Conclusion: AWEMixer能够实现精确的时频定位，同时对噪声保持鲁棒性，在长期时间序列预测任务中表现出色。

Abstract: Forecasting long-term time series in IoT environments remains a significant
challenge due to the non-stationary and multi-scale characteristics of sensor
signals. Furthermore, error accumulation causes a decrease in forecast quality
when predicting further into the future. Traditional methods are restricted to
operate in time-domain, while the global frequency information achieved by
Fourier transform would be regarded as stationary signals leading to blur the
temporal patterns of transient events. We propose AWEMixer, an Adaptive
Wavelet-Enhanced Mixer Network including two innovative components: 1) a
Frequency Router designs to utilize the global periodicity pattern achieved by
Fast Fourier Transform to adaptively weight localized wavelet subband, and 2) a
Coherent Gated Fusion Block to achieve selective integration of prominent
frequency features with multi-scale temporal representation through
cross-attention and gating mechanism, which realizes accurate time-frequency
localization while remaining robust to noise. Seven public benchmarks validate
that our model is more effective than recent state-of-the-art models.
Specifically, our model consistently achieves performance improvement compared
with transformer-based and MLP-based state-of-the-art models in long-sequence
time series forecasting. Code is available at
https://github.com/hit636/AWEMixer

</details>


### [5] [Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction](https://arxiv.org/abs/2511.04723)
*Mohamadreza Akbari Pour,Mohamad Sadeq Karimi,Amir Hossein Mazloumi*

Main category: cs.LG

TL;DR: 提出了一种结合TCN和改良TFT的框架，用于工业系统剩余使用寿命预测，通过多时间窗口方法提高适应性，在基准数据集上平均RMSE降低5.5%。


<details>
  <summary>Details</summary>
Motivation: 现有RUL预测模型难以捕捉细粒度时间依赖性，且无法动态优先处理关键特征，需要更鲁棒的预测方法。

Method: 集成时间卷积网络(TCN)进行局部时间特征提取，结合改良的时间融合变换器(TFT)和Bi-LSTM编码器-解码器，采用多时间窗口方法。

Result: 在基准数据集上评估显示，该模型平均RMSE降低高达5.5%，预测精度优于现有最先进方法。

Conclusion: 该框架弥补了现有方法的不足，提升了工业预测系统的有效性，展示了先进时间序列变换器在RUL预测中的潜力。

Abstract: Health prediction is crucial for ensuring reliability, minimizing downtime,
and optimizing maintenance in industrial systems. Remaining Useful Life (RUL)
prediction is a key component of this process; however, many existing models
struggle to capture fine-grained temporal dependencies while dynamically
prioritizing critical features across time for robust prognostics. To address
these challenges, we propose a novel framework that integrates Temporal
Convolutional Networks (TCNs) for localized temporal feature extraction with a
modified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.
This architecture effectively bridges short- and long-term dependencies while
emphasizing salient temporal patterns. Furthermore, the incorporation of a
multi-time-window methodology improves adaptability across diverse operating
conditions. Extensive evaluations on benchmark datasets demonstrate that the
proposed model reduces the average RMSE by up to 5.5%, underscoring its
improved predictive accuracy compared to state-of-the-art methods. By closing
critical gaps in current approaches, this framework advances the effectiveness
of industrial prognostic systems and highlights the potential of advanced
time-series transformers for RUL prediction.

</details>


### [6] [Regularized GLISp for sensor-guided human-in-the-loop optimization](https://arxiv.org/abs/2511.04751)
*Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin*

Main category: cs.LG

TL;DR: 提出了传感器引导的GLISp扩展方法，通过物理信息假设函数和最小二乘正则化项将可测量描述符整合到偏好学习循环中，在车辆悬架调校任务中显示出比基线GLISp更快的收敛速度和更优的最终解。


<details>
  <summary>Details</summary>
Motivation: 现有的基于偏好的优化方法（如Preferential Bayesian Optimization或GLISp）将系统视为黑箱，忽略了信息丰富的传感器测量数据。

Method: 传感器引导的正则化GLISp扩展，通过物理信息假设函数和最小二乘正则化项将可测量描述符整合到偏好学习循环中，结合主观反馈与定量传感器信息。

Result: 在分析基准和人在环车辆悬架调校任务上的数值评估显示，相比基线GLISp具有更快的收敛速度和更优的最终解。

Conclusion: 该方法通过注入灰箱结构，在保持基于偏好搜索灵活性的同时，结合了主观反馈与定量传感器信息，提高了优化性能。

Abstract: Human-in-the-loop calibration is often addressed via preference-based
optimization, where algorithms learn from pairwise comparisons rather than
explicit cost evaluations. While effective, methods such as Preferential
Bayesian Optimization or Global optimization based on active preference
learning with radial basis functions (GLISp) treat the system as a black box
and ignore informative sensor measurements. In this work, we introduce a
sensor-guided regularized extension of GLISp that integrates measurable
descriptors into the preference-learning loop through a physics-informed
hypothesis function and a least-squares regularization term. This injects
grey-box structure, combining subjective feedback with quantitative sensor
information while preserving the flexibility of preference-based search.
Numerical evaluations on an analytical benchmark and on a human-in-the-loop
vehicle suspension tuning task show faster convergence and superior final
solutions compared to baseline GLISp.

</details>


### [7] [When Data Falls Short: Grokking Below the Critical Threshold](https://arxiv.org/abs/2511.04760)
*Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi*

Main category: cs.LG

TL;DR: 知识蒸馏可以从已grokking的模型诱导和加速新分布上的grokking，即使在数据稀缺情况下也能实现泛化，并在持续学习中缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 研究在数据稀缺和分布偏移场景下，如何利用知识蒸馏来诱导和加速grokking现象，解决实际部署中模型需要适应新分布但数据有限的问题。

Method: 使用知识蒸馏从已在分布p1上grokking的模型，转移到新分布p2；研究联合分布训练和持续预训练设置，比较标准监督训练与蒸馏方法的效果。

Result: 知识蒸馏能在数据低于临界阈值时诱导grokking，加速新分布上的泛化；在联合分布训练中，蒸馏能实现泛化而标准训练失败；在持续学习中，蒸馏加速泛化并缓解遗忘，仅需10%数据就能获得强性能。

Conclusion: 知识蒸馏在低数据和分布演化场景中对实现泛化具有核心作用，为grokking机制在知识转移下的运作提供了新见解。

Abstract: In this paper, we investigate the phenomenon of grokking, where models
exhibit delayed generalization following overfitting on training data. We focus
on data-scarce regimes where the number of training samples falls below the
critical threshold, making grokking unobservable, and on practical scenarios
involving distribution shift. We first show that Knowledge Distillation (KD)
from a model that has already grokked on a distribution (p1) can induce and
accelerate grokking on a different distribution (p2), even when the available
data lies below the critical threshold. This highlights the value of KD for
deployed models that must adapt to new distributions under limited data. We
then study training on the joint distribution (p1, p2) and demonstrate that
while standard supervised training fails when either distribution has
insufficient data, distilling from models grokked on the individual
distributions enables generalization. Finally, we examine a continual
pretraining setup, where a grokked model transitions from p1 to p2, and find
that KD both accelerates generalization and mitigates catastrophic forgetting,
achieving strong performance even with only 10% of the data. Together, our
results provide new insights into the mechanics of grokking under knowledge
transfer and underscore the central role of KD in enabling generalization in
low-data and evolving distribution settings.

</details>


### [8] [FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow](https://arxiv.org/abs/2511.04768)
*Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu*

Main category: cs.LG

TL;DR: FuseFlow是一个将PyTorch稀疏模型转换为融合稀疏数据流图的编译器，支持跨表达式融合、并行化等优化，针对可重构数据流架构，在真实ML应用中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模扩大，稀疏计算和专用数据流硬件成为提升效率的重要方案，但缺乏支持通用跨表达式稀疏操作融合的编译器。

Method: 开发FuseFlow编译器，支持跨内核融合、并行化、数据流排序和稀疏分块等优化，针对周期精确的数据流模拟器进行微架构分析。

Result: 在四个真实世界机器学习应用中，FuseFlow实现性能提升，包括GPT-3与BigBird块稀疏注意力相比未融合基线获得约2.7倍加速。

Conclusion: 完全融合并非总是稀疏模型的最优选择，融合粒度取决于模型本身，FuseFlow提供了识别和剪枝次优配置的启发式方法。

Abstract: As deep learning models scale, sparse computation and specialized dataflow
hardware have emerged as powerful solutions to address efficiency. We propose
FuseFlow, a compiler that converts sparse machine learning models written in
PyTorch to fused sparse dataflow graphs for reconfigurable dataflow
architectures (RDAs). FuseFlow is the first compiler to support general
cross-expression fusion of sparse operations. In addition to fusion across
kernels (expressions), FuseFlow also supports optimizations like
parallelization, dataflow ordering, and sparsity blocking. It targets a
cycle-accurate dataflow simulator for microarchitectural analysis of fusion
strategies. We use FuseFlow for design-space exploration across four real-world
machine learning applications with sparsity, showing that full fusion (entire
cross-expression fusion across all computation in an end-to-end model) is not
always optimal for sparse models-fusion granularity depends on the model
itself. FuseFlow also provides a heuristic to identify and prune suboptimal
configurations. Using Fuseflow, we achieve performance improvements, including
a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse
attention.

</details>


### [9] [SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices](https://arxiv.org/abs/2511.04774)
*Liu Jiang,Zerui Bao,Shiqi Sheng,Di Zhu*

Main category: cs.LG

TL;DR: 提出一种针对云工作负载的指令预取设计，通过压缩条目、分层元数据存储和在线ML控制器来优化尾延迟和能效


<details>
  <summary>Details</summary>
Motivation: 大规模网络服务依赖深度软件栈和微服务编排，增加了指令足迹并造成前端停顿，从而提高了尾延迟和能耗

Method: 基于纠缠指令预取器(EIP)，引入压缩条目(36位捕获8个目标)、分层元数据存储(片上保留L1常驻和频繁查询条目)，以及轻量级在线ML控制器评估预取收益

Result: 在数据中心应用中保持类似EIP的加速效果，同时减少片上状态，提升网络服务在ML时代的效率

Conclusion: 该设计为面向SLO驱动和自优化系统的云工作负载提供了有效的指令预取解决方案

Abstract: Large-scale networked services rely on deep soft-ware stacks and microservice
orchestration, which increase instruction footprints and create frontend stalls
that inflate tail latency and energy. We revisit instruction prefetching for
these cloud workloads and present a design that aligns with SLO driven and self
optimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we
introduce a Compressed Entry that captures up to eight destinations around a
base using 36 bits by exploiting spatial clustering, and a Hierarchical
Metadata Storage scheme that keeps only L1 resident and frequently queried
entries on chip while virtualizing bulk metadata into lower levels. We further
add a lightweight Online ML Controller that scores prefetch profitability using
context features and a bandit adjusted threshold. On data center applications,
our approach preserves EIP like speedups with smaller on chip state and
improves efficiency for networked services in the ML era.

</details>


### [10] [Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting](https://arxiv.org/abs/2511.04789)
*Xiaoda Wang,Yuji Zhao,Kaiqiao Han,Xiao Luo,Sanne van Rooij,Jennifer Stevens,Lifang He,Liang Zhan,Yizhou Sun,Wei Wang,Carl Yang*

Main category: cs.LG

TL;DR: 提出CNODE框架，使用神经ODE模型连续建模帕金森病脑形态变化，通过联合学习患者特异性初始时间和进展速度来对齐个体轨迹，在PPMI数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖离散、规则采样的数据，难以处理帕金森病队列中不规则和稀疏的MRI数据，且难以捕捉个体异质性（如发病时间、进展速度和症状严重程度的差异）。

Method: 使用神经ODE模型将脑形态变化建模为连续时间过程，联合学习患者特异性初始时间和进展速度，将个体轨迹对齐到共享进展轨迹中。

Result: 在PPMI数据集上的实验结果表明，该方法在预测帕金森病纵向进展方面优于现有最先进的基线方法。

Conclusion: CNODE框架能够有效建模帕金森病的异质性和演化模式，为机制理解、治疗开发和个体化预测提供了新方法。

Abstract: Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry
patterns. Modeling these longitudinal trajectories enables mechanistic insight,
treatment development, and individualized 'digital-twin' forecasting. However,
existing methods usually adopt recurrent neural networks and transformer
architectures, which rely on discrete, regularly sampled data while struggling
to handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.
Moreover, these methods have difficulty capturing individual heterogeneity
including variations in disease onset, progression rate, and symptom severity,
which is a hallmark of PD. To address these challenges, we propose CNODE
(Conditional Neural ODE), a novel framework for continuous, individualized PD
progression forecasting. The core of CNODE is to model morphological brain
changes as continuous temporal processes using a neural ODE model. In addition,
we jointly learn patient-specific initial time and progress speed to align
individual trajectories into a shared progression trajectory. We validate CNODE
on the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental
results show that our method outperforms state-of-the-art baselines in
forecasting longitudinal PD progression.

</details>


### [11] [Causal Structure and Representation Learning with Biomedical Applications](https://arxiv.org/abs/2511.04790)
*Caroline Uhler,Jiaqi Zhang*

Main category: cs.LG

TL;DR: 该论文提出将表示学习与因果推断相结合，利用多模态数据（观察性和扰动性）进行因果结构学习，以解决生物医学中的因果发现问题。


<details>
  <summary>Details</summary>
Motivation: 表示学习在预测任务中很成功，但在因果任务中表现不佳，特别是在预测干预效果时。多模态数据的可用性为结合表示学习和因果推断提供了机会。

Method: 提出了一个统计和计算框架，利用观察性和扰动性数据执行因果发现，使用多模态视图学习因果变量，并设计最优扰动。

Result: 论文概述了一个能够处理多模态数据的因果结构和表示学习框架，但未提供具体实验结果。

Conclusion: 表示学习与因果推断的结合对于理解复杂生物医学现象和做出更好决策具有重要意义，特别是在多模态数据环境下。

Abstract: Massive data collection holds the promise of a better understanding of
complex phenomena and, ultimately, better decisions. Representation learning
has become a key driver of deep learning applications, as it allows learning
latent spaces that capture important properties of the data without requiring
any supervised annotations. Although representation learning has been hugely
successful in predictive tasks, it can fail miserably in causal tasks including
predicting the effect of a perturbation/intervention. This calls for a marriage
between representation learning and causal inference. An exciting opportunity
in this regard stems from the growing availability of multi-modal data
(observational and perturbational, imaging-based and sequencing-based, at the
single-cell level, tissue-level, and organism-level). We outline a statistical
and computational framework for causal structure and representation learning
motivated by fundamental biomedical questions: how to effectively use
observational and perturbational data to perform causal discovery on observed
causal variables; how to use multi-modal views of the system to learn causal
variables; and how to design optimal perturbations.

</details>


### [12] [DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive GPU Multiplexing](https://arxiv.org/abs/2511.04791)
*Lei Gao,Chaoyi Jiang,Hossein Entezari Zarch,Daniel Wong,Murali Annavaram*

Main category: cs.LG

TL;DR: DuetServe是一个统一的LLM服务框架，通过在单个GPU内实现解耦级别的隔离，动态激活SM级GPU空间多路复用，以解决预填充和解码阶段的干扰问题，提高吞吐量同时保持低延迟。


<details>
  <summary>Details</summary>
Motivation: 现代LLM服务系统需要在计算密集的预填充阶段和内存受限的解码阶段之间维持高吞吐量和严格的延迟SLOs。现有方法要么在共享GPU上聚合两个阶段导致干扰，要么跨GPU解耦但浪费资源。

Method: DuetServe默认在聚合模式下运行，当预测到TBT退化时动态激活SM级GPU空间多路复用。通过细粒度的自适应SM分区仅在需要时解耦预填充和解码执行，提供阶段隔离。集成注意力感知屋顶线模型预测迭代延迟、分区优化器选择最优SM分割、无中断执行引擎消除CPU-GPU同步开销。

Result: 评估显示DuetServe相比最先进框架，总吞吐量提升高达1.3倍，同时保持低生成延迟。

Conclusion: DuetServe成功实现了在单个GPU内解耦级别的隔离，通过动态SM分区策略有效解决了预填充和解码阶段的干扰问题，在保持低延迟的同时显著提升了系统吞吐量。

Abstract: Modern LLM serving systems must sustain high throughput while meeting strict
latency SLOs across two distinct inference phases: compute-intensive prefill
and memory-bound decode phases. Existing approaches either (1) aggregate both
phases on shared GPUs, leading to interference between prefill and decode
phases, which degrades time-between-tokens (TBT); or (2) disaggregate the two
phases across GPUs, improving latency but wasting resources through duplicated
models and KV cache transfers. We present DuetServe, a unified LLM serving
framework that achieves disaggregation-level isolation within a single GPU.
DuetServe operates in aggregated mode by default and dynamically activates
SM-level GPU spatial multiplexing when TBT degradation is predicted. Its key
idea is to decouple prefill and decode execution only when needed through
fine-grained, adaptive SM partitioning that provides phase isolation only when
contention threatens latency service level objectives (SLOs). DuetServe
integrates (1) an attention-aware roofline model to forecast iteration latency,
(2) a partitioning optimizer that selects the optimal SM split to maximize
throughput under TBT constraints, and (3) an interruption-free execution engine
that eliminates CPU-GPU synchronization overhead. Evaluations show that
DuetServe improves total throughput by up to 1.3x while maintaining low
generation latency compared to state-of-the-art frameworks.

</details>


### [13] [Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator](https://arxiv.org/abs/2511.04804)
*Chaymae Yahyati,Ismail Lamaakal,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SiFEN是一种基于有限元方法的神经网络，通过学习三角网格和分段多项式来表示函数，具有显式局部性、可控平滑度和缓存友好的稀疏性。


<details>
  <summary>Details</summary>
Motivation: 提出一种紧凑、可解释且理论基础的替代方案，以替代密集MLP和边缘样条网络，同时提供更好的校准和推理效率。

Method: 使用度数为m的Bernstein-Bezier多项式与轻量可逆扭曲配对，通过形状正则化、半离散OT覆盖和可微分边翻转进行端到端训练。

Result: 在合成逼近任务、表格回归/分类以及作为紧凑CNN的头部时，SiFEN在相同参数预算下匹配或超越MLP和KAN，改善了校准并降低了推理延迟。

Conclusion: SiFEN是一个紧凑、可解释且理论基础的函数逼近器，具有显式局部性和可控平滑度，适用于各种机器学习任务。

Abstract: We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial
predictor that represents f: R^d -> R^k as a globally C^r finite-element field
on a learned simplicial mesh in an optionally warped input space. Each query
activates exactly one simplex and at most d+1 basis functions via barycentric
coordinates, yielding explicit locality, controllable smoothness, and
cache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with
a light invertible warp and trains end-to-end with shape regularization,
semi-discrete OT coverage, and differentiable edge flips. Under standard
shape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic
FEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic
approximation tasks, tabular regression/classification, and as a drop-in head
on compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter
budgets, improves calibration (lower ECE/Brier), and reduces inference latency
due to geometric locality. These properties make SiFEN a compact,
interpretable, and theoretically grounded alternative to dense MLPs and
edge-spline networks.

</details>


### [14] [PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference](https://arxiv.org/abs/2511.04805)
*Yushu Zhao,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: PuzzleMoE是一种无需训练的MoE模型压缩方法，通过稀疏专家合并和位压缩编码实现高达50%的压缩率，同时保持准确性并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: MoE模型虽然能高效扩展语言模型，但由于存储所有专家参数导致内存开销大，限制了其广泛部署。现有专家丢弃和合并方法在高压缩比下性能下降严重。

Method: 1. 稀疏专家合并：识别权重冗余和专业化，使用双重掩码捕获共享和专家特定参数
2. 位压缩编码：重用未充分利用的指数位，避免存储二进制掩码和符号的开销

Result: 压缩MoE模型高达50%，在MMLU任务上比现有方法提升16.7%，推理速度提升1.28倍，在各种任务中保持准确性。

Conclusion: PuzzleMoE有效解决了MoE模型内存开销问题，实现了高压缩比下的高性能，为MoE模型的广泛部署提供了可行方案。

Abstract: Mixture-of-Experts (MoE) models have shown strong potential in scaling
language models efficiently by activating only a small subset of experts per
input. However, their widespread deployment remains limited due to the high
memory overhead associated with storing all expert parameters, particularly as
the number of experts increases. To address this challenge, prior works have
explored expert dropping and merging strategies, yet they often suffer from
performance drop at high compression ratios. In this paper, we introduce
PuzzleMoE, a training-free MoE compression method that achieves both high
accuracy and efficient inference through two key innovations: First, PuzzleMoE
performs sparse expert merging by identifying element-wise weight redundancy
and specialization. It uses a dual-mask to capture both shared and
expert-specific parameters. Second, to avoid the overhead of storing binary
masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses
underutilized exponent bits, enabling efficient MoE inference on GPUs.
Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up
to 50% while maintaining accuracy across various tasks. Specifically, it
outperforms prior MoE compression methods by up to 16.7% on MMLU at 50%
compression ratio, and achieves up to 1.28\times inference speedup.

</details>


### [15] [Autoencoding Dynamics: Topological Limitations and Capabilities](https://arxiv.org/abs/2511.04807)
*Matthew D. Kvalheim,Eduardo D. Sontag*

Main category: cs.LG

TL;DR: 本文探讨了自动编码器在数据流形上的拓扑限制和能力，以及其在动力系统自动编码中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究自动编码器在数据流形上的拓扑特性，理解其在表示学习和动力系统建模中的基本限制和可能性。

Method: 通过分析自动编码器的数学结构，特别是编码器E和解码器D的连续映射性质，研究其在数据流形M上的拓扑约束。

Result: 发现了自动编码器在数据流形表示上的各种拓扑限制，同时描述了其在动力系统自动编码中的能力。

Conclusion: 自动编码器的拓扑特性对其表示能力有重要影响，这些发现对理解深度学习的理论基础和动力系统建模具有重要意义。

Abstract: Given a "data manifold" $M\subset \mathbb{R}^n$ and "latent space"
$\mathbb{R}^\ell$, an autoencoder is a pair of continuous maps consisting of an
"encoder" $E\colon \mathbb{R}^n\to \mathbb{R}^\ell$ and "decoder" $D\colon
\mathbb{R}^\ell\to \mathbb{R}^n$ such that the "round trip" map $D\circ E$ is
as close as possible to the identity map $\mbox{id}_M$ on $M$. We present
various topological limitations and capabilites inherent to the search for an
autoencoder, and describe capabilities for autoencoding dynamical systems
having $M$ as an invariant manifold.

</details>


### [16] [Sharp Minima Can Generalize: A Loss Landscape Perspective On Data](https://arxiv.org/abs/2511.04808)
*Raymond Fan,Bryce Sandlund,Lin Myat Ko*

Main category: cs.LG

TL;DR: 研究发现，虽然平坦最小值理论解释了深度学习有效性，但无法说明大数据在泛化中的作用。实验表明，存在泛化良好的尖锐最小值，但由于体积小难以找到。增加数据会改变损失景观，使原本小的泛化最小值相对变大。


<details>
  <summary>Details</summary>
Motivation: 探讨体积假设（认为深度学习有效是因为容易找到平坦最小值）的局限性，特别是该理论无法解释大数据在模型泛化中的关键作用。

Method: 通过在不同训练数据量下测量最小值体积，分析损失景观的变化，研究泛化良好的最小值如何随数据量增加而变化。

Result: 发现存在泛化良好的尖锐最小值，但由于体积小难以被找到。增加训练数据会改变损失景观，使得原本体积小的泛化最小值相对变大。

Conclusion: 大数据的作用不仅仅是提供更多训练样本，更重要的是改变了损失景观的结构，使得泛化良好的最小值更容易被找到，这补充了传统的平坦最小值理论。

Abstract: The volume hypothesis suggests deep learning is effective because it is
likely to find flat minima due to their large volumes, and flat minima
generalize well. This picture does not explain the role of large datasets in
generalization. Measuring minima volumes under varying amounts of training data
reveals sharp minima which generalize well exist, but are unlikely to be found
due to their small volumes. Increasing data changes the loss landscape, such
that previously small generalizing minima become (relatively) large.

</details>


### [17] [A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification](https://arxiv.org/abs/2511.04814)
*Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez*

Main category: cs.LG

TL;DR: ESCAPE是一个标准化的抗菌肽评估框架，整合了来自27个验证数据库的80,000多个肽序列，提供了多标签分类基准和基于transformer的预测模型。


<details>
  <summary>Details</summary>
Motivation: 解决抗菌肽研究中数据集碎片化、注释不一致和缺乏标准化基准的问题，以促进计算方法和新候选肽的发现。

Method: 构建ESCAPE数据集，整合多个来源的肽序列，建立生物一致的多标签层次结构；开发基于transformer的模型，利用序列和结构信息预测肽的多功能活性。

Result: 模型在平均精度均值上相比第二佳方法实现了2.56%的相对改进，建立了多标签肽分类的最新技术水平。

Conclusion: ESCAPE提供了一个全面且可重复的评估框架，推动AI驱动的抗菌肽研究发展。

Abstract: Antimicrobial peptides have emerged as promising molecules to combat
antimicrobial resistance. However, fragmented datasets, inconsistent
annotations, and the lack of standardized benchmarks hinder computational
approaches and slow down the discovery of new candidates. To address these
challenges, we present the Expanded Standardized Collection for Antimicrobial
Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000
peptides from 27 validated repositories. Our dataset separates antimicrobial
peptides from negative sequences and incorporates their functional annotations
into a biologically coherent multilabel hierarchy, capturing activities across
antibacterial, antifungal, antiviral, and antiparasitic classes. Building on
ESCAPE, we propose a transformer-based model that leverages sequence and
structural information to predict multiple functional activities of peptides.
Our method achieves up to a 2.56% relative average improvement in mean Average
Precision over the second-best method adapted for this task, establishing a new
state-of-the-art multilabel peptide classification. ESCAPE provides a
comprehensive and reproducible evaluation framework to advance AI-driven
antimicrobial peptide research.

</details>


### [18] [Persistent reachability homology in machine learning applications](https://arxiv.org/abs/2511.04825)
*Luigi Caputi,Nicholas Meadows,Henri Riihimäki*

Main category: cs.LG

TL;DR: 本文研究了持久可达性同调（PRH）在有向图数据网络分类任务中的有效性，特别是在癫痫检测这一神经科学问题中的应用。PRH相比传统的基于有向旗复形（DPH）的方法具有优势，因为它考虑了持续过滤中出现的图凝聚，从而从更小的有向图计算。


<details>
  <summary>Details</summary>
Motivation: 探索PRH在有向图数据分析中的有效性，特别是在癫痫检测这一重要神经科学问题中，比较PRH与传统DPH方法在网络分类任务中的表现。

Method: 使用Betti曲线及其积分作为拓扑特征，在支持向量机上实现分类管道。PRH方法考虑了持续过滤中出现的图凝聚，从更小的有向图进行计算。

Result: PRH在分类任务中优于传统的DPH方法，显示出更好的性能表现。

Conclusion: 持久可达性同调（PRH）是分析有向图数据的一种有效方法，在癫痫检测等神经科学应用中具有优势，能够提供比传统方法更好的分类性能。

Abstract: We explore the recently introduced persistent reachability homology (PRH) of
digraph data, i.e. data in the form of directed graphs. In particular, we study
the effectiveness of PRH in network classification task in a key neuroscience
problem: epilepsy detection. PRH is a variation of the persistent homology of
digraphs, more traditionally based on the directed flag complex (DPH). A main
advantage of PRH is that it considers the condensations of the digraphs
appearing in the persistent filtration and thus is computed from smaller
digraphs. We compare the effectiveness of PRH to that of DPH and we show that
PRH outperforms DPH in the classification task. We use the Betti curves and
their integrals as topological features and implement our pipeline on support
vector machine.

</details>


### [19] [Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.04834)
*Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon*

Main category: cs.LG

TL;DR: 本文提出了一种简单有效的方法，通过概念反转获得隐式负嵌入来替代训练自由方法中的负提示，解决了文本到图像生成模型中两种防御方法（微调模型和训练自由引导方法）结合时性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成模型可能产生有害内容，现有两种防御方法（模型微调和训练自由引导）结合使用时效果不佳，存在兼容性问题。

Method: 使用概念反转获得隐式负嵌入来替代训练自由方法中的负提示，无需修改现有方法即可集成到现有流程中。

Result: 在色情和暴力基准测试中验证了方法的有效性，显示防御成功率持续提升，同时保持输入提示的核心语义。

Conclusion: 提出的方法成功解决了两种防御范式的兼容性问题，在保持语义完整性的同时显著提升了防御效果。

Abstract: Recent advances in text-to-image generative models have raised concerns about
their potential to produce harmful content when provided with malicious input
text prompts. To address this issue, two main approaches have emerged: (1)
fine-tuning the model to unlearn harmful concepts and (2) training-free
guidance methods that leverage negative prompts. However, we observe that
combining these two orthogonal approaches often leads to marginal or even
degraded defense performance. This observation indicates a critical
incompatibility between two paradigms, which hinders their combined
effectiveness. In this work, we address this issue by proposing a conceptually
simple yet experimentally robust method: replacing the negative prompts used in
training-free methods with implicit negative embeddings obtained through
concept inversion. Our method requires no modification to either approach and
can be easily integrated into existing pipelines. We experimentally validate
its effectiveness on nudity and violence benchmarks, demonstrating consistent
improvements in defense success rate while preserving the core semantics of
input prompts.

</details>


### [20] [SPECTRA: Spectral Target-Aware Graph Augmentation for Imbalanced Molecular Property Regression](https://arxiv.org/abs/2511.04838)
*Brenda Nogueira,Meng Jiang,Nitesh V. Chawla,Nuno Moniz*

Main category: cs.LG

TL;DR: SPECTRA是一个光谱目标感知的图增强框架，通过在光谱域生成真实的分子图来解决分子属性预测中稀有化合物预测性能差的问题。


<details>
  <summary>Details</summary>
Motivation: 在分子属性预测中，最有价值的化合物（如高效力）通常占据目标空间的稀疏区域。标准的图神经网络通常优化平均误差，在这些罕见但关键的情况下表现不佳，现有的过采样方法常常扭曲分子拓扑结构。

Method: SPECTRA框架：(i)从SMILES重建多属性分子图；(ii)通过（融合）Gromov-Wasserstein耦合对齐分子对以获得节点对应关系；(iii)在稳定共享基中插值拉普拉斯特征值、特征向量和节点特征；(iv)重建边以合成具有插值目标的物理上合理的中间体。采用基于标签核密度估计的稀有感知预算方案，将增强集中在数据稀缺区域。

Result: 在基准测试中，SPECTRA在相关目标范围内持续改善误差，同时保持竞争力的整体MAE，并生成可解释的合成分子，其结构反映了底层的光谱几何。

Conclusion: 结果表明，光谱、几何感知的增强是处理不平衡分子属性回归的有效且高效策略。

Abstract: In molecular property prediction, the most valuable compounds (e.g., high
potency) often occupy sparse regions of the target space. Standard Graph Neural
Networks (GNNs) commonly optimize for the average error, underperforming on
these uncommon but critical cases, with existing oversampling methods often
distorting molecular topology. In this paper, we introduce SPECTRA, a Spectral
Target-Aware graph augmentation framework that generates realistic molecular
graphs in the spectral domain. SPECTRA (i) reconstructs multi-attribute
molecular graphs from SMILES; (ii) aligns molecule pairs via (Fused)
Gromov-Wasserstein couplings to obtain node correspondences; (iii) interpolates
Laplacian eigenvalues, eigenvectors and node features in a stable share-basis;
and (iv) reconstructs edges to synthesize physically plausible intermediates
with interpolated targets. A rarity-aware budgeting scheme, derived from a
kernel density estimation of labels, concentrates augmentation where data are
scarce. Coupled with a spectral GNN using edge-aware Chebyshev convolutions,
SPECTRA densifies underrepresented regions without degrading global accuracy.
On benchmarks, SPECTRA consistently improves error in relevant target ranges
while maintaining competitive overall MAE, and yields interpretable synthetic
molecules whose structure reflects the underlying spectral geometry. Our
results demonstrate that spectral, geometry-aware augmentation is an effective
and efficient strategy for imbalanced molecular property regression.

</details>


### [21] [Sublinear iterations can suffice even for DDPMs](https://arxiv.org/abs/2511.04844)
*Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: SDE-based methods such as denoising diffusion probabilistic models (DDPMs)
have shown remarkable success in real-world sample generation tasks. Prior
analyses of DDPMs have been focused on the exponential Euler discretization,
showing guarantees that generally depend at least linearly on the dimension or
initial Fisher information. Inspired by works in log-concave sampling (Shen and
Lee, 2019), we analyze an integrator -- the denoising diffusion randomized
midpoint method (DDRaM) -- that leverages an additional randomized midpoint to
better approximate the SDE. Using a recently-developed analytic framework
called the "shifted composition rule", we show that this algorithm enjoys
favorable discretization properties under appropriate smoothness assumptions,
with sublinear $\widetilde{O}(\sqrt{d})$ score evaluations needed to ensure
convergence. This is the first sublinear complexity bound for pure DDPM
sampling -- prior works which obtained such bounds worked instead with
ODE-based sampling and had to make modifications to the sampler which deviate
from how they are used in practice. We also provide experimental validation of
the advantages of our method, showing that it performs well in practice with
pre-trained image synthesis models.

</details>


### [22] [Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches](https://arxiv.org/abs/2511.04845)
*Jingchen Bi,Rodrigo Mesa-Arango*

Main category: cs.LG

TL;DR: 使用机器学习模型分析美国消费者对具有创新运输证书食品的偏好，重点关注运输安全、能源等证书对购买决策的影响。


<details>
  <summary>Details</summary>
Motivation: 基于先前研究发现运输因素在消费者食品购买选择中具有显著影响，需要具体识别消费者重视的运输属性。

Method: 采用机器学习模型分析消费者偏好实验数据，提出五种创新运输证书：运输模式、物联网、安全措施、能源来源和必须到达日期。

Result: 研究发现消费者在运输领域明显偏好安全和能源证书，同时价格、产品类型、证书和决策者因素都会影响购买选择。

Conclusion: 研究为改进食品供应链系统提供了数据驱动的建议，强调运输安全和能源证书的重要性。

Abstract: This paper utilizes a machine learning model to estimate the consumer's
behavior for food products with innovative transportation certificates in the
U.S. Building on previous research that examined demand for food products with
supply chain traceability using stated preference analysis, transportation
factors were identified as significant in consumer food purchasing choices.
Consequently, a second experiment was conducted to pinpoint the specific
transportation attributes valued by consumers. A machine learning model was
applied, and five innovative certificates related to transportation were
proposed: Transportation Mode, Internet of Things (IoT), Safety measures,
Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also
incorporated product-specific and decision-maker factors for control purposes.
The findings reveal a notable inclination toward safety and energy certificates
within the transportation domain of the U.S. food supply chain. Additionally,
the study examined the influence of price, product type, certificates, and
decision-maker factors on purchasing choices. Ultimately, the study offers
data-driven recommendations for improving food supply chain systems.

</details>


### [23] [Grounded Test-Time Adaptation for LLM Agents](https://arxiv.org/abs/2511.04847)
*Arthur Chen,Zuxin Liu,Jianguo Zhang,Akshara Prabhakar,Zhiwei Liu,Shelby Heinecke,Silvio Savarese,Victor Zhong,Caiming Xiong*

Main category: cs.LG

TL;DR: 提出了两种互补的策略来提升LLM智能体在新环境中的泛化能力：在线分布适应和部署时动态基础化，显著提高了在复杂环境中的成功率。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在新颖复杂环境（如未见过的网站或新功能集）中泛化能力不足，存在语法误解和语义误解两种失败模式。

Method: 1. 在线分布适应：学习轻量级适应向量来偏置模型输出分布，快速与环境响应格式对齐；2. 部署时动态基础化：通过角色驱动探索阶段系统性地探测和学习环境的因果动态，构建非参数化世界模型。

Result: 在函数调用和网页导航等多样化智能体基准测试中，两种策略都表现出有效性且计算成本最小。在WebArena多站点分割测试中，动态基础化方法将成功率从2%提升到23%。

Conclusion: 动态基础化在复杂环境中特别有效，为构建更通用和强大的LLM智能体提供了稳健路径。

Abstract: Large language model (LLM)-based agents struggle to generalize to novel and
complex environments, such as unseen websites or new sets of functions, due to
a fundamental mismatch between their pre-training and test-time conditions.
This challenge stems from two distinct failure modes: a syntactic
misunderstanding of environment-specific components like observation formats,
and a semantic misunderstanding of state-transition dynamics, which are only
revealed at test time. To address these issues, we propose two distinct and
complementary strategies for adapting LLM agents by leveraging
environment-specific information available during deployment. First, an online
distributional adaptation method parameterizes environmental nuances by
learning a lightweight adaptation vector that biases the model's output
distribution, enabling rapid alignment with an environment response format.
Second, a deployment-time dynamics grounding method employs a persona-driven
exploration phase to systematically probe and learn the environment's causal
dynamics before task execution, equipping the agent with a nonparametric world
model. We evaluate these strategies across diverse agentic benchmarks,
including function calling and web navigation. Our empirical results show the
effectiveness of both strategies across all benchmarks with minimal
computational cost. We find that dynamics grounding is particularly effective
in complex environments where unpredictable dynamics pose a major obstacle,
demonstrating a robust path toward more generalizable and capable LLM-based
agents. For example, on the WebArena multi-site split, this method increases
the agent's success rate from 2% to 23%.

</details>


### [24] [SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion](https://arxiv.org/abs/2511.04854)
*Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris*

Main category: cs.LG

TL;DR: SigmaDock是一种基于SE(3)黎曼扩散模型的分子对接方法，通过将配体分解为刚性片段并学习在结合口袋中重新组装这些片段，实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统的生成式分子对接方法存在化学不合理输出、泛化性差和计算成本高等问题，需要一种更可靠、高效的解决方案。

Method: 提出了一种新的片段化方案，将配体分解为刚性片段，并开发了SE(3)黎曼扩散模型来学习在结合口袋中重新组装这些片段。

Result: 在PoseBusters数据集上达到79.9%的Top-1成功率，显著优于现有深度学习方法(12.7-30.8%)，并且首次超越经典物理基对接方法。

Conclusion: SigmaDock代表了深度学习在分子建模可靠性和可行性方面的重大突破，为药物发现提供了更可靠的分子对接工具。

Abstract: Determining the binding pose of a ligand to a protein, known as molecular
docking, is a fundamental task in drug discovery. Generative approaches promise
faster, improved, and more diverse pose sampling than physics-based methods,
but are often hindered by chemically implausible outputs, poor
generalisability, and high computational cost. To address these challenges, we
introduce a novel fragmentation scheme, leveraging inductive biases from
structural chemistry, to decompose ligands into rigid-body fragments. Building
on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion
model that generates poses by learning to reassemble these rigid bodies within
the binding pocket. By operating at the level of fragments in SE(3), SigmaDock
exploits well-established geometric priors while avoiding overly complex
diffusion processes and unstable training dynamics. Experimentally, we show
SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates
(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%
reported by recent deep learning approaches, whilst demonstrating consistent
generalisation to unseen proteins. SigmaDock is the first deep learning
approach to surpass classical physics-based docking under the PB train-test
split, marking a significant leap forward in the reliability and feasibility of
deep learning for molecular modelling.

</details>


### [25] [Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2511.04856)
*Thore Gerlach,Michael Schenk,Verena Kain*

Main category: cs.LG

TL;DR: 提出理论基础的连续半量子玻尔兹曼机(CSQBMs)，支持连续动作强化学习，通过结合可见单元的指数族先验和隐藏单元的量子玻尔兹曼分布，构建混合量子经典模型，减少量子比特需求同时保持强表达能力。


<details>
  <summary>Details</summary>
Motivation: 解决连续控制中不稳定性问题，开发能够支持连续动作强化学习的量子增强模型，同时降低量子资源需求。

Method: 结合指数族先验和量子玻尔兹曼分布构建混合量子经典模型，推导连续变量的解析梯度，提出连续Q学习框架，用CSQBM分布采样替代全局最大化。

Result: 开发出理论基础的CSQBMs模型，能够计算连续变量的解析梯度，直接集成到Actor-Critic算法中，克服连续控制中的不稳定性问题。

Conclusion: CSQBMs为连续动作强化学习提供了可行的量子增强解决方案，在减少量子资源需求的同时保持了模型的表达能力，为解决连续控制问题提供了新途径。

Abstract: We introduce theoretically grounded Continuous Semi-Quantum Boltzmann
Machines (CSQBMs) that supports continuous-action reinforcement learning. By
combining exponential-family priors over visible units with quantum Boltzmann
distributions over hidden units, CSQBMs yield a hybrid quantum-classical model
that reduces qubit requirements while retaining strong expressiveness.
Crucially, gradients with respect to continuous variables can be computed
analytically, enabling direct integration into Actor-Critic algorithms.
Building on this, we propose a continuous Q-learning framework that replaces
global maximization by efficient sampling from the CSQBM distribution, thereby
overcoming instability issues in continuous control.

</details>


### [26] [FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting](https://arxiv.org/abs/2511.04865)
*Esha Sharma,Lauren Davis,Julie Ivy,Min Chi*

Main category: cs.LG

TL;DR: FoodRL是一个基于强化学习的元学习框架，通过聚类和动态加权多种预测模型来改进食品银行的捐赠预测准确性，特别是在自然灾害等干扰时期表现优异。


<details>
  <summary>Details</summary>
Motivation: 食品银行在解决粮食不安全问题中至关重要，但传统预测模型难以应对捐赠量的高度波动性和概念漂移（如季节性变化、飓风、野火等自然灾害）。

Method: 提出FoodRL框架，使用强化学习进行元学习，基于近期性能和上下文信息对不同的预测模型进行聚类和动态加权。

Result: 在两个结构不同的美国食品银行数据上评估，FoodRL始终优于基线方法，特别是在干扰或衰退时期。每年可额外重新分配相当于170万餐的食物。

Conclusion: FoodRL展示了在改善人道主义供应链预测方面的显著潜力，既能产生社会影响，又能实现自适应集成学习。

Abstract: Food banks are crucial for alleviating food insecurity, but their
effectiveness hinges on accurately forecasting highly volatile in-kind
donations to ensure equitable and efficient resource distribution. Traditional
forecasting models often fail to maintain consistent accuracy due to
unpredictable fluctuations and concept drift driven by seasonal variations and
natural disasters such as hurricanes in the Southeastern U.S. and wildfires in
the West Coast. To address these challenges, we propose FoodRL, a novel
reinforcement learning (RL) based metalearning framework that clusters and
dynamically weights diverse forecasting models based on recent performance and
contextual information. Evaluated on multi-year data from two structurally
distinct U.S. food banks-one large regional West Coast food bank affected by
wildfires and another state-level East Coast food bank consistently impacted by
hurricanes, FoodRL consistently outperforms baseline methods, particularly
during periods of disruption or decline. By delivering more reliable and
adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent
to 1.7 million additional meals annually, demonstrating its significant
potential for social impact as well as adaptive ensemble learning for
humanitarian supply chains.

</details>


### [27] [Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning](https://arxiv.org/abs/2511.04883)
*Di Chen,Jia Li,Michael Zhang*

Main category: cs.LG

TL;DR: 该研究探讨在混合自动驾驶交通系统中，自利的自动驾驶车辆是否能为所有驾驶主体带来集体利益，通过深度强化学习验证了集体理性的存在。


<details>
  <summary>Details</summary>
Motivation: 理解在混合自动驾驶交通中，当所有驾驶主体（包括人类和自动驾驶车辆）都出于自利行为时，是否仍能实现整体交通系统的性能提升。

Method: 使用深度强化学习训练自利的交通主体，采用简单的奖励设计，不直接包含系统级目标，验证集体理性的涌现。

Result: 在各种场景中集体理性持续涌现，表明该特性的鲁棒性，并通过仿真证据验证了微观动态环境中集体理性涌现的机制。

Conclusion: 研究表明可以利用先进学习方法（如联邦学习）在混合自动驾驶系统中实现自利驾驶主体间的集体合作。

Abstract: Autonomous vehicles (AVs) are expected to be commercially available in the
near future, leading to mixed autonomy traffic consisting of both AVs and
human-driven vehicles (HVs). Although numerous studies have shown that AVs can
be deployed to benefit the overall traffic system performance by incorporating
system-level goals into their decision making, it is not clear whether the
benefits still exist when agents act out of self-interest -- a trait common to
all driving agents, both human and autonomous. This study aims to understand
whether self-interested AVs can bring benefits to all driving agents in mixed
autonomy traffic systems. The research is centered on the concept of collective
rationality (CR). This concept, originating from game theory and behavioral
economics, means that driving agents may cooperate collectively even when
pursuing individual interests. Our recent research has proven the existence of
CR in an analytical game-theoretical model and empirically in mixed
human-driven traffic. In this paper, we demonstrate that CR can be attained
among driving agents trained using deep reinforcement learning (DRL) with a
simple reward design. We examine the extent to which self-interested traffic
agents can achieve CR without directly incorporating system-level objectives.
Results show that CR consistently emerges in various scenarios, which indicates
the robustness of this property. We also postulate a mechanism to explain the
emergence of CR in the microscopic and dynamic environment and verify it based
on simulation evidence. This research suggests the possibility of leveraging
advanced learning methods (such as federated learning) to achieve collective
cooperation among self-interested driving agents in mixed-autonomy systems.

</details>


### [28] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 本文系统研究了无标签强化学习方法在不同规模模型（0.5B-7B参数）上的表现，发现该方法严重依赖基础模型的推理能力，对较弱模型效果不佳。作者提出基于课程学习和数据筛选的改进方法，在所有模型规模上均取得一致改进。


<details>
  <summary>Details</summary>
Motivation: 探索无监督强化学习方法在推理能力有限的小型基础模型上的泛化能力，填补现有研究主要关注大型模型的空白。

Method: 提出基于课程学习的无标签强化学习方法：1）渐进式引入更难问题；2）训练时屏蔽无多数投票的rollout；3）数据筛选流程生成预定义难度的样本。

Result: 改进方法在所有模型规模和推理能力上均实现一致提升，为资源受限模型推理能力的自举提供可行路径。

Conclusion: 无标签强化学习的成功高度依赖基础模型的推理能力，通过课程学习和数据筛选可以显著提升其在小型模型上的表现，为实现更鲁棒的无监督强化学习提供方向。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [29] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: 提出了Craftax-MA和Craftax-Coop两个多智能体强化学习基准环境，评估长期依赖和泛化能力，现有算法在这些环境中面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有MARL基准主要针对短期挑战，无法充分评估长期依赖和泛化能力，需要更全面的基准来推动MARL研究。

Method: 扩展流行的开放环境Craftax，支持多智能体，引入异构智能体、交易等机制，使用JAX实现以获得高性能。

Result: Craftax-MA训练2.5亿次交互仅需不到1小时，现有算法在长期信用分配、探索和合作方面表现不佳。

Conclusion: Craftax基准环境为MARL研究提供了有挑战性的测试平台，有望推动长期研究发展。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [30] [Efficient Swap Multicalibration of Elicitable Properties](https://arxiv.org/abs/2511.04907)
*Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文提出了一种针对可引出属性的广义多校准方法，从群组成员函数扩展到任意有界假设类，并引入了更强的交换多校准概念。作者设计了一个oracle高效算法，在给定在线不可知学习器的情况下，以高概率实现T^{1/(r+1)}的ℓ_r-交换多校准误差。


<details>
  <summary>Details</summary>
Motivation: 多校准是算法公平性的重要视角，要求预测器在自身预测值和群体成员资格条件下的预测是准确的。之前的工作建立了多校准与属性引出性之间的深刻联系，但现有算法效率较低，特别是在在线设置中。

Method: 将多校准从群组成员函数推广到任意有界假设类，引入交换多校准概念。提出oracle高效算法，利用在线不可知学习器，对有界顺序Rademacher复杂度的假设类和可引出属性实现多校准。

Result: 对于r≥2，算法以高概率实现T^{1/(r+1)}的ℓ_r-交换多校准误差。特别地，当r=2时，实现T^{1/3}的ℓ_2-交换多校准误差，显著改进了现有界限。

Conclusion: 该工作完全解决了[GJRR24]中提出的关于oracle高效算法能否实现√T ℓ_2-均值多校准误差的开放性问题，给出了强烈肯定的答案，为多校准理论提供了重要的算法进展。

Abstract: Multicalibration [HJKRR18] is an algorithmic fairness perspective that
demands that the predictions of a predictor are correct conditional on
themselves and membership in a collection of potentially overlapping subgroups
of a population. The work of [NR23] established a surprising connection between
multicalibration for an arbitrary property $\Gamma$ (e.g., mean or median) and
property elicitation: a property $\Gamma$ can be multicalibrated if and only if
it is elicitable, where elicitability is the notion that the true property
value of a distribution can be obtained by solving a regression problem over
the distribution. In the online setting, [NR23] proposed an inefficient
algorithm that achieves $\sqrt T$ $\ell_2$-multicalibration error for a
hypothesis class of group membership functions and an elicitable property
$\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.
  In this paper, we generalize multicalibration for an elicitable property
$\Gamma$ from group membership functions to arbitrary bounded hypothesis
classes and introduce a stronger notion -- swap multicalibration, following
[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when
given access to an online agnostic learner, achieves $T^{1/(r+1)}$
$\ell_r$-swap multicalibration error with high probability (for $r\ge2$) for a
hypothesis class with bounded sequential Rademacher complexity and an
elicitable property $\Gamma$. For the special case of $r=2$, this implies an
oracle-efficient algorithm that achieves $T^{1/3}$ $\ell_2$-swap
multicalibration error, which significantly improves on the previously
established bounds for the problem [NR23, GMS25, LSS25a], and completely
resolves an open question raised in [GJRR24] on the possibility of an
oracle-efficient algorithm that achieves $\sqrt{T}$ $\ell_2$-mean
multicalibration error by answering it in a strongly affirmative sense.

</details>


### [31] [A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates](https://arxiv.org/abs/2511.04909)
*Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson*

Main category: cs.LG

TL;DR: 提出了Dual-Guided Loss (DGL)，一种简单可扩展的目标函数，通过利用下游问题的对偶变量来指导学习，减少对求解器的依赖，同时保持决策对齐。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多决策都是在不确定性下通过使用预测数量解决优化问题做出的。现有的决策聚焦学习方法要么需要频繁调用求解器，要么依赖特定任务的代理函数，都存在扩展性挑战。

Method: 利用下游问题的对偶变量来指导学习，构建DGL目标函数，专门针对具有自然多选一约束的组合选择问题。该方法将优化与梯度更新解耦，仅定期解决下游问题，在刷新间隔期间使用对偶调整目标进行训练。

Result: 在两个问题类别上的实验表明，DGL匹配或超过了最先进的DFL方法，同时使用了更少的求解器调用和显著减少的训练时间。

Conclusion: DGL方法在保持强决策对齐的同时，将训练成本驱动向标准监督学习，具有渐近递减的决策遗憾，为决策聚焦学习提供了更高效的解决方案。

Abstract: Many real-world decisions are made under uncertainty by solving optimization
problems using predicted quantities. This predict-then-optimize paradigm has
motivated decision-focused learning, which trains models with awareness of how
the optimizer uses predictions, improving the performance of downstream
decisions. Despite its promise, scaling is challenging: state-of-the-art
methods either differentiate through a solver or rely on task-specific
surrogates, both of which require frequent and expensive calls to an optimizer,
often a combinatorial one. In this paper, we leverage dual variables from the
downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a
simple, scalable objective that preserves decision alignment while reducing
solver dependence. We construct DGL specifically for combinatorial selection
problems with natural one-of-many constraints, such as matching, knapsack, and
shortest path. Our approach (a) decouples optimization from gradient updates by
solving the downstream problem only periodically; (b) between refreshes, trains
on dual-adjusted targets using simple differentiable surrogate losses; and (c)
as refreshes become less frequent, drives training cost toward standard
supervised learning while retaining strong decision alignment. We prove that
DGL has asymptotically diminishing decision regret, analyze runtime complexity,
and show on two problem classes that DGL matches or exceeds state-of-the-art
DFL methods while using far fewer solver calls and substantially less training
time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.

</details>


### [32] [Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application](https://arxiv.org/abs/2511.04918)
*A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi*

Main category: cs.LG

TL;DR: 本文探讨了机器学习算法与传统统计模型结合的新方法，展示了混合模型在预测准确性、鲁棒性和可解释性方面的显著改进


<details>
  <summary>Details</summary>
Motivation: 研究机器学习与统计模型之间的连接，探索现代ML算法如何丰富传统模型，提升数据分析、预测分析和决策制定的方式

Method: 通过研究ML算法与传统统计模型的集成方式，分析混合模型如何结合两者的优势

Result: 混合模型在预测准确性、鲁棒性、可扩展性、灵活性和可解释性方面都有显著提升

Conclusion: 机器学习与传统统计模型的集成创造了性能更优越的混合模型，为数据分析领域带来了革命性的进步

Abstract: It involves the completely novel ways of integrating ML algorithms with
traditional statistical modelling that has changed the way we analyze data, do
predictive analytics or make decisions in the fields of the data. In this
paper, we study some ML and statistical model connections to understand ways in
which some modern ML algorithms help 'enrich' conventional models; we
demonstrate how new algorithms improve performance, scale, flexibility and
robustness of the traditional models. It shows that the hybrid models are of
great improvement in predictive accuracy, robustness, and interpretability

</details>


### [33] [Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding](https://arxiv.org/abs/2511.04934)
*Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong*

Main category: cs.LG

TL;DR: 现有的大语言模型遗忘方法在确定性解码下看似成功，但在概率性解码下敏感信息会重新出现，表明这些方法未能实现真正的遗忘。


<details>
  <summary>Details</summary>
Motivation: 大语言模型遗忘对于合规性和构建伦理AI系统至关重要，但现有方法在实践中无法实现真正的知识移除。

Method: 引入leak@k元评估指标，量化在概率性解码下被遗忘知识重新出现的可能性，并在TOFU、MUSE和WMDP三个基准上进行了大规模系统研究。

Result: 研究发现知识泄露在所有方法和任务中持续存在，表明当前最先进的遗忘技术仅提供有限的遗忘效果。

Conclusion: 当前的大语言模型遗忘方法存在严重漏洞，迫切需要开发更鲁棒的遗忘方法。

Abstract: Unlearning in large language models (LLMs) is critical for regulatory
compliance and for building ethical generative AI systems that avoid producing
private, toxic, illegal, or copyrighted content. Despite rapid progress, in
this work we show that \textit{almost all} existing unlearning methods fail to
achieve true forgetting in practice. Specifically, while evaluations of these
`unlearned' models under deterministic (greedy) decoding often suggest
successful knowledge removal using standard benchmarks (as has been done in the
literature), we show that sensitive information reliably resurfaces when models
are sampled with standard probabilistic decoding. To rigorously capture this
vulnerability, we introduce \texttt{leak@$k$}, a new meta-evaluation metric
that quantifies the likelihood of forgotten knowledge reappearing when
generating $k$ samples from the model under realistic decoding strategies.
Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the
first large-scale, systematic study of unlearning reliability using our newly
defined \texttt{leak@$k$} metric. Our findings demonstrate that knowledge
leakage persists across methods and tasks, underscoring that current
state-of-the-art unlearning techniques provide only limited forgetting and
highlighting the urgent need for more robust approaches to LLM unlearning.

</details>


### [34] [Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression](https://arxiv.org/abs/2511.04937)
*Zhankun Luo,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: 本文分析了EM算法在二分量混合线性回归中的结构特性、摆线轨迹和非渐进收敛保证，揭示了在不同信噪比下的收敛阶数。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究在已知平衡权重和高信噪比情况下建立了EM算法的全局收敛性，但在完全未知参数设置下的理论行为仍不清楚，其轨迹和收敛阶数尚未完全表征。

Method: 推导了未知混合权重和回归参数情况下EM更新的显式表达式，分析了其结构特性和摆线轨迹，建立了子最优角度的递推关系。

Result: 在无噪声情况下，回归参数的EM迭代轨迹形成摆线；在高信噪比下量化了与摆线轨迹的偏差。分析显示：当估计与真实值几乎正交时线性收敛，当角度较小时二次收敛。

Conclusion: 这项工作为分析混合线性回归中的EM算法提供了一个基于轨迹的新框架，建立了有限样本级别的非渐进收敛保证。

Abstract: This work investigates the structural properties, cycloid trajectories, and
non-asymptotic convergence guarantees of the Expectation-Maximization (EM)
algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing
weights and regression parameters. Recent studies have established global
convergence for 2MLR with known balanced weights and super-linear convergence
in noiseless and high signal-to-noise ratio (SNR) regimes. However, the
theoretical behavior of EM in the fully unknown setting remains unclear, with
its trajectory and convergence order not yet fully characterized. We derive
explicit EM update expressions for 2MLR with unknown mixing weights and
regression parameters across all SNR regimes and analyze their structural
properties and cycloid trajectories. In the noiseless case, we prove that the
trajectory of the regression parameters in EM iterations traces a cycloid by
establishing a recurrence relation for the sub-optimality angle, while in high
SNR regimes we quantify its discrepancy from the cycloid trajectory. The
trajectory-based analysis reveals the order of convergence: linear when the EM
estimate is nearly orthogonal to the ground truth, and quadratic when the angle
between the estimate and ground truth is small at the population level. Our
analysis establishes non-asymptotic guarantees by sharpening bounds on
statistical errors between finite-sample and population EM updates, relating
EM's statistical accuracy to the sub-optimality angle, and proving convergence
with arbitrary initialization at the finite-sample level. This work provides a
novel trajectory-based framework for analyzing EM in Mixed Linear Regression.

</details>


### [35] [Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques](https://arxiv.org/abs/2511.04971)
*Esha Chowdhury*

Main category: cs.LG

TL;DR: 本研究针对糖尿病与心血管疾病的强关联性，提出使用机器学习和混合深度学习方法来预测糖尿病患者的心血管疾病风险。XGBoost和LSTM模型均达到最高准确率0.9050，部分模型实现了完美的召回率。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病风险预测对医疗机构至关重要。糖尿病患病率不断增长且与心脏病有强关联，需要为糖尿病患者开发有效的CVD风险预测模型。

Method: 使用BRFSS数据集，进行数据预处理（去重、处理缺失值、识别分类和数值特征）、主成分分析特征提取。实施多种机器学习模型（决策树、随机森林、KNN、SVM、AdaBoost、XGBoost）和深度学习模型（ANN、DNN、RNN、CNN、LSTM、BiLSTM、GRU）以及CNN与LSTM、BiLSTM、GRU的混合模型。

Result: XGBoost和LSTM模型均达到最高准确率0.9050，部分模型实现了完美的召回率（1.00）。高准确率和F1分数证明了这些模型的有效性。

Conclusion: 机器学习和深度学习模型在预测糖尿病患者心血管疾病风险方面具有显著效果，能够自动化和增强临床决策制定，有望改善个性化风险管理和预防策略。

Abstract: Accurate prediction of cardiovascular disease (CVD) risk is crucial for
healthcare institutions. This study addresses the growing prevalence of
diabetes and its strong link to heart disease by proposing an efficient CVD
risk prediction model for diabetic patients using machine learning (ML) and
hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by
removing duplicates, handling missing values, identifying categorical and
numerical features, and applying Principal Component Analysis (PCA) for feature
extraction. Several ML models, including Decision Trees (DT), Random Forest
(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and
XGBoost, were implemented, with XGBoost achieving the highest accuracy of
0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep
Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural
Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and
Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,
BiLSTM, and GRU, were also explored. Some of these models achieved perfect
recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.
Our research highlights the effectiveness of ML and DL models in predicting CVD
risk among diabetic patients, automating and enhancing clinical
decision-making. High accuracy and F1 scores demonstrate these models'
potential to improve personalized risk management and preventive strategies.

</details>


### [36] [Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces](https://arxiv.org/abs/2511.04973)
*Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang*

Main category: cs.LG

TL;DR: FAR-TS是一个用于多变量时间序列生成的框架，通过解耦因子化和自回归Transformer在离散量化潜在空间中实现快速、可控的任意长度序列生成。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的方法生成速度慢且仅限于固定长度窗口，需要一种更快速、灵活的时间序列生成方法。

Method: 将时间序列分解为捕获静态跨通道相关性的数据自适应基和时序系数，后者被向量量化为离散标记，然后使用LLaMA风格的自回归Transformer建模这些标记序列。

Result: FAR-TS比Diffusion-TS快几个数量级，同时保持跨通道相关性和可解释的潜在空间，实现高质量灵活的时间序列合成。

Conclusion: FAR-TS提供了一个简单有效的框架，能够快速生成任意长度的多变量时间序列，同时保持数据质量和可解释性。

Abstract: Generative models for multivariate time series are essential for data
augmentation, simulation, and privacy preservation, yet current
state-of-the-art diffusion-based approaches are slow and limited to
fixed-length windows. We propose FAR-TS, a simple yet effective framework that
combines disentangled factorization with an autoregressive Transformer over a
discrete, quantized latent space to generate time series. Each time series is
decomposed into a data-adaptive basis that captures static cross-channel
correlations and temporal coefficients that are vector-quantized into discrete
tokens. A LLaMA-style autoregressive Transformer then models these token
sequences, enabling fast and controllable generation of sequences with
arbitrary length. Owing to its streamlined design, FAR-TS achieves
orders-of-magnitude faster generation than Diffusion-TS while preserving
cross-channel correlations and an interpretable latent space, enabling
high-quality and flexible time series synthesis.

</details>


### [37] [Scaling Up ROC-Optimizing Support Vector Machines](https://arxiv.org/abs/2511.04979)
*Gimun Bae,Seung Jun Shin*

Main category: cs.LG

TL;DR: 提出了一种可扩展的ROC-SVM变体，通过不完全U统计量和低秩核近似大幅降低计算复杂度，同时保持与原始ROC-SVM相当的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 原始ROC-SVM虽然能直接最大化AUC且对类别不平衡问题具有吸引力，但其O(n²)的计算成本限制了实际应用。

Method: 使用不完全U统计量减少计算复杂度，并通过低秩核近似扩展到非线性分类，在再生核希尔伯特空间中进行高效训练。

Result: 理论分析建立了误差界证明近似合理性，实证结果表明在合成和真实数据集上，该方法能达到与原始ROC-SVM相当的AUC性能，同时训练时间大幅减少。

Conclusion: 该方法成功解决了ROC-SVM的计算瓶颈问题，使其在实际应用中更加可行。

Abstract: The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the
area under the ROC curve (AUC) and has become an attractive alternative of the
conventional binary classification under the presence of class imbalance.
However, its practical use is limited by high computational cost, as training
involves evaluating all $O(n^2)$. To overcome this limitation, we develop a
scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby
substantially reducing computational complexity. We further extend the
framework to nonlinear classification through a low-rank kernel approximation,
enabling efficient training in reproducing kernel Hilbert spaces. Theoretical
analysis establishes an error bound that justifies the proposed approximation,
and empirical results on both synthetic and real datasets demonstrate that the
proposed method achieves comparable AUC performance to the original ROC-SVM
with drastically reduced training time.

</details>


### [38] [Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk](https://arxiv.org/abs/2511.04980)
*Rongbin Ye,Jiaqi Chen*

Main category: cs.LG

TL;DR: 论文提出一个五维框架来评估复杂机器学习模型的可解释性，证明通过SHAP和LIME等解释性框架，高预测性能的"黑盒"模型可以在受监管的金融环境中达到与传统模型相同的可解释性水平。


<details>
  <summary>Details</summary>
Motivation: 解决金融行业在应用先进机器学习模型时面临的预测能力与监管要求的可解释性之间的平衡问题，填补"黑盒"模型与可解释性框架之间的应用空白。

Method: 应用SHAP和LIME解释性框架对不同模型进行分析，并提出包含固有可解释性、全局解释、局部解释、一致性和复杂度的五维评估框架。

Result: 研究表明，具有更好预测能力的复杂模型通过现代可解释性技术可以达到与传统模型相同的可解释性水平，证明了在受监管金融环境中应用高性能ML模型的可行性。

Conclusion: 通过现代可解释性技术和结构化评估方法，可以在模型性能与可解释性之间找到平衡，使复杂的高性能ML模型能够在受监管的金融环境中有效应用。

Abstract: The financial industry faces a significant challenge modeling and risk
portfolios: balancing the predictability of advanced machine learning models,
neural network models, and explainability required by regulatory entities (such
as Office of the Comptroller of the Currency, Consumer Financial Protection
Bureau). This paper intends to fill the gap in the application between these
"black box" models and explainability frameworks, such as LIME and SHAP.
Authors elaborate on the application of these frameworks on different models
and demonstrates the more complex models with better prediction powers could be
applied and reach the same level of the explainability, using SHAP and LIME.
Beyond the comparison and discussion of performances, this paper proposes a
novel five dimensional framework evaluating Inherent Interpretability, Global
Explanations, Local Explanations, Consistency, and Complexity to offer a
nuanced method for assessing and comparing model explainability beyond simple
accuracy metrics. This research demonstrates the feasibility of employing
sophisticated, high performing ML models in regulated financial environments by
utilizing modern explainability techniques and provides a structured approach
to evaluate the crucial trade offs between model performance and
interpretability.

</details>


### [39] [Deep Progressive Training: scaling up depth capacity of zero/one-layer models](https://arxiv.org/abs/2511.04981)
*Zhiqi Bu*

Main category: cs.LG

TL;DR: 提出了零/一层渐进训练方法，通过优化理论分析模型深度扩展，在保持性能的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 模型深度在深度学习中存在权衡：更深的模型精度更高但计算成本也更高。渐进训练通过在训练过程中逐步扩展模型容量来有效降低计算成本。

Method: 基于优化理论和特征学习研究深度扩展，提出零/一层渐进训练方法，关注新层初始化、超参数传递、学习率调度和模型扩展时机。

Result: 在GPT2上应用零/一层渐进训练可节省约80%计算量，相当于加速约5倍，同时达到与60层7B参数模型几乎相同的损失。

Conclusion: 渐进训练是实现计算效率与性能平衡的有效策略，特别适用于大规模模型训练。

Abstract: Model depth is a double-edged sword in deep learning: deeper models achieve
higher accuracy but require higher computational cost. To efficiently train
models at scale, an effective strategy is the progressive training, which
scales up model capacity during training, hence significantly reducing
computation with little to none performance degradation. In this work, we study
the depth expansion of large models through the lens of optimization theory and
feature learning, offering insights on the initialization of new layers,
hyperparameter transfer, learning rate schedule, and timing of model expansion.
Specifically, we propose zero/one-layer progressive training for the optimal
tradeoff between computation and loss. For example, zero/one-layer progressive
training on GPT2 can save $\approx 80\%$ compute, or equivalently accelerate
$\approx 5\times$ while achieving almost the same loss, compared to to a fully
trained 60-layer model with 7B parameters.

</details>


### [40] [Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding](https://arxiv.org/abs/2511.04984)
*Xinheng He,Yijia Zhang,Haowei Lin,Xingang Peng,Xiangzhe Kong,Mingyu Li,Jianzhu Ma*

Main category: cs.LG

TL;DR: Peptide2Mol是一个E(3)-等变图神经网络扩散模型，通过参考原始肽结合剂及其周围蛋白口袋环境来生成小分子，在非自回归生成任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 大多数AI驱动的药物设计方法忽略了内源性蛋白与肽相互作用的重要性，导致分子设计不理想。

Method: 使用E(3)-等变图神经网络扩散模型，结合原始肽结合剂和蛋白口袋环境信息，通过部分扩散过程进行分子优化和肽模拟设计。

Result: 模型不仅实现了最先进的非自回归生成性能，还生成了与原始肽结合剂相似的分子，支持分子优化和肽模拟设计。

Conclusion: Peptide2Mol是从蛋白结合口袋生成和优化生物活性小分子的有效深度生成模型。

Abstract: Structure-based drug design has seen significant advancements with the
integration of artificial intelligence (AI), particularly in the generation of
hit and lead compounds. However, most AI-driven approaches neglect the
importance of endogenous protein interactions with peptides, which may result
in suboptimal molecule designs. In this work, we present Peptide2Mol, an
E(3)-equivariant graph neural network diffusion model that generates small
molecules by referencing both the original peptide binders and their
surrounding protein pocket environments. Trained on large datasets and
leveraging sophisticated modeling techniques, Peptide2Mol not only achieves
state-of-the-art performance in non-autoregressive generative tasks, but also
produces molecules with similarity to the original peptide binder.
Additionally, the model allows for molecule optimization and peptidomimetic
design through a partial diffusion process. Our results highlight Peptide2Mol
as an effective deep generative model for generating and optimizing bioactive
small molecules from protein binding pockets.

</details>


### [41] [Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models](https://arxiv.org/abs/2511.04988)
*Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang*

Main category: cs.LG

TL;DR: 提出一个综合混合框架，集成结构断点检测、小波信号去噪和三种深度学习模型，用于碳价格预测，显著提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 准确预测碳价格对能源市场决策、可持续能源规划和脱碳策略至关重要，但由于政策干预和市场冲击导致的结构断点和高频噪声，现有方法存在局限性。

Method: 集成Bai-Perron、ICSS和PELT算法进行结构断点检测，使用小波信号去噪，结合LSTM、GRU和TCN三种深度学习模型构建混合框架。

Result: 提出的PELT-WT-TCN模型在RMSE和MAE上分别比现有最佳基线模型降低22.35%和18.63%，比原始LSTM降低70.55%和74.42%。

Conclusion: 将结构意识和多尺度分解集成到深度学习架构中，能显著提升碳价格预测及其他非平稳金融时间序列的准确性和可解释性。

Abstract: Accurately forecasting carbon prices is essential for informed energy market
decision-making, guiding sustainable energy planning, and supporting effective
decarbonization strategies. However, it remains challenging due to structural
breaks and high-frequency noise caused by frequent policy interventions and
market shocks. Existing studies, including the most recent baseline approaches,
have attempted to incorporate breakpoints but often treat denoising and
modeling as separate processes and lack systematic evaluation across advanced
deep learning architectures, limiting the robustness and the generalization
capability. To address these gaps, this paper proposes a comprehensive hybrid
framework that integrates structural break detection (Bai-Perron, ICSS, and
PELT algorithms), wavelet signal denoising, and three state-of-the-art deep
learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot
prices from 2007 to 2024 and exogenous features such as energy prices and
policy indicators, the framework constructs univariate and multivariate
datasets for comparative evaluation. Experimental results demonstrate that our
proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing
forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the
state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by
70.55% in RMSE and 74.42% in MAE compared to the original LSTM without
decomposition from the same baseline study. These findings underscore the value
of integrating structural awareness and multiscale decomposition into deep
learning architectures to enhance accuracy and interpretability in carbon price
forecasting and other nonstationary financial time series.

</details>


### [42] [BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records](https://arxiv.org/abs/2511.04998)
*Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang*

Main category: cs.LG

TL;DR: 提出BiPETE模型用于单疾病预测，结合旋转位置嵌入和正弦嵌入处理EHR数据中的时间依赖性，在抑郁和PTSD队列中显著提升ASUD风险预测性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在EHR疾病风险预测中表现出潜力，但由于就诊间隔不规则和缺乏统一结构，建模时间依赖性仍是关键挑战。

Method: 提出Bi-Positional Embedding Transformer Encoder (BiPETE)，集成旋转位置嵌入编码相对就诊时间，正弦嵌入保持就诊顺序，不依赖大规模预训练。

Result: 在抑郁和PTSD队列中，BiPETE优于基线模型，AUPRC分别提高34%和50%。消融研究证实双位置编码策略的有效性。

Conclusion: 研究提出了一个实用且可解释的EHR疾病风险预测框架，能够实现强性能，并通过归因方法识别关键临床特征，有助于风险评估过程的理解和风险缓解。

Abstract: Transformer-based deep learning models have shown promise for disease risk
prediction using electronic health records(EHRs), but modeling temporal
dependencies remains a key challenge due to irregular visit intervals and lack
of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder
or BiPETE for single-disease prediction, which integrates rotary positional
embeddings to encode relative visit timing and sinusoidal embeddings to
preserve visit order. Without relying on large-scale pretraining, BiPETE is
trained on EHR data from two mental health cohorts-depressive disorder and
post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and
substance use disorders (ASUD). BiPETE outperforms baseline models, improving
the area under the precision-recall curve (AUPRC) by 34% and 50% in the
depression and PTSD cohorts, respectively. An ablation study further confirms
the effectiveness of the dual positional encoding strategy. We apply the
Integrated Gradients method to interpret model predictions, identifying key
clinical features associated with ASUD risk and protection, such as abnormal
inflammatory, hematologic, and metabolic markers, as well as specific
medications and comorbidities. Overall, these key clinical features identified
by the attribution methods contribute to a deeper understanding of the risk
assessment process and offer valuable clues for mitigating potential risks. In
summary, our study presents a practical and interpretable framework for disease
risk prediction using EHR data, which can achieve strong performance.

</details>


### [43] [Multi-agent Coordination via Flow Matching](https://arxiv.org/abs/2511.05005)
*Dongsu Lee,Daehee Lee,Amy Zhang*

Main category: cs.LG

TL;DR: MAC-Flow是一个简单而富有表现力的多智能体协调框架，通过学习联合行为的流式表示并将其蒸馏为去中心化的一步策略，解决了性能与计算成本之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在有效协调的两个需求之间存在权衡：扩散方法能捕捉复杂协调但计算慢，高斯策略方法速度快但处理多智能体交互脆弱。

Method: 首先学习联合行为的流式表示，然后将其蒸馏为去中心化的一步策略，既保持协调能力又实现快速执行。

Result: 在4个基准测试（12个环境和34个数据集）中，MAC-Flow实现了约14.5倍于扩散方法的推理速度，同时保持良好性能，推理速度与高斯策略方法相当。

Conclusion: MAC-Flow成功缓解了性能与计算成本之间的权衡，为多智能体协调提供了高效实用的解决方案。

Abstract: This work presents MAC-Flow, a simple yet expressive framework for
multi-agent coordination. We argue that requirements of effective coordination
are twofold: (i) a rich representation of the diverse joint behaviors present
in offline data and (ii) the ability to act efficiently in real time. However,
prior approaches often sacrifice one for the other, i.e., denoising
diffusion-based solutions capture complex coordination but are computationally
slow, while Gaussian policy-based solutions are fast but brittle in handling
multi-agent interaction. MAC-Flow addresses this trade-off by first learning a
flow-based representation of joint behaviors, and then distilling it into
decentralized one-step policies that preserve coordination while enabling fast
execution. Across four different benchmarks, including $12$ environments and
$34$ datasets, MAC-Flow alleviates the trade-off between performance and
computational cost, specifically achieving about $\boldsymbol{\times14.5}$
faster inference compared to diffusion-based MARL methods, while maintaining
good performance. At the same time, its inference speed is similar to that of
prior Gaussian policy-based offline multi-agent reinforcement learning (MARL)
methods.

</details>


### [44] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: OvA-LP是一个用于联邦微调的简约框架，通过在PEFT范式中从源头抑制客户端漂移，结合线性探测和一对多头部，在异构数据下保持95.9%的IID准确率。


<details>
  <summary>Details</summary>
Motivation: 现有联邦微调方法在异构客户端分布下容易受到局部漂移影响，导致系统偏差和方差放大，现有的事后校正方法在极端非IID条件下表现脆弱。

Method: OvA-LP结合冻结编码器上的线性探测和一对多头部，采用两阶段程序，保留预训练特征几何并解耦逻辑以防止漂移放大机制。

Result: 在CIFAR-100的100个客户端上，OvA-LP保持95.9%的IID准确率，而最先进的基线方法仅保持10.1%和34.5%。在对称和非对称标签噪声下均保持弹性。

Conclusion: OvA-LP为异构条件下的鲁棒联邦微调提供了原则性和高效的基础。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [45] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 测试三种大型语言模型（Claude、DeepSeek和ChatGPT）创建棋盘游戏代码及变体的能力


<details>
  <summary>Details</summary>
Motivation: 创建棋盘游戏程序耗时，LLMs能根据简单上下文信息高效生成代码，有望加速这一过程

Method: 提出方法测试三种LLMs创建棋盘游戏代码和新变体的能力

Result: 论文未提供具体测试结果

Conclusion: 未提供结论

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


### [46] [QuAnTS: Question Answering on Time Series](https://arxiv.org/abs/2511.05124)
*Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.LG

TL;DR: 提出了一个新颖的时间序列问答数据集QuAnTS，专注于人体运动骨架轨迹数据，填补了时间序列问答研究的空白。


<details>
  <summary>Details</summary>
Motivation: 文本信息可以补充数值时间序列的密度，改善与时间序列模型的交互，增强可访问性和决策能力。当前问答研究主要集中在视觉和文本领域，时间序列问答研究不足。

Method: 创建了大规模的时间序列问答数据集QuAnTS，包含关于人体运动骨架轨迹的各种问答对，并通过广泛实验验证数据集的质量和完整性。

Result: 建立了全面的时间序列问答基准，评估了现有和新提出的基线方法，并提供了人类表现作为参考标准。

Conclusion: 希望鼓励未来通过文本与时间序列模型交互的研究，实现更好的决策制定和更透明的系统。

Abstract: Text offers intuitive access to information. This can, in particular,
complement the density of numerical time series, thereby allowing improved
interactions with time series models to enhance accessibility and
decision-making. While the creation of question-answering datasets and models
has recently seen remarkable growth, most research focuses on question
answering (QA) on vision and text, with time series receiving minute attention.
To bridge this gap, we propose a challenging novel time series QA (TSQA)
dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we
pose a wide variety of questions and answers about human motion in the form of
tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is
well-formed and comprehensive through extensive experiments. Thoroughly
evaluating existing and newly proposed baselines then lays the groundwork for a
deeper exploration of TSQA using QuAnTS. Additionally, we provide human
performances as a key reference for gauging the practical usability of such
models. We hope to encourage future research on interacting with time series
models through text, enabling better decision-making and more transparent
systems.

</details>


### [47] [DL101 Neural Network Outputs and Loss Functions](https://arxiv.org/abs/2511.05131)
*Fernando Berzal*

Main category: cs.LG

TL;DR: 该技术报告分析了神经网络输出层激活函数与损失函数之间的统计联系，通过最大似然估计原理将常见损失函数与概率分布假设联系起来。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络输出层激活函数与损失函数之间的统计联系，为选择合适的损失函数提供理论依据。

Method: 分析常见激活函数（线性、sigmoid、ReLU、softmax）的数学特性，通过最大似然估计原理将损失函数（MSE、MAE、交叉熵）与概率分布假设联系起来。

Result: 建立了损失函数选择与概率分布假设的等价关系，揭示了神经网络输出层与广义线性模型的联系。

Conclusion: 选择合适的损失函数等价于假设特定的输出概率分布，这为深度学习模型的损失函数选择提供了统计理论基础。

Abstract: The loss function used to train a neural network is strongly connected to its
output layer from a statistical point of view. This technical report analyzes
common activation functions for a neural network output layer, like linear,
sigmoid, ReLU, and softmax, detailing their mathematical properties and their
appropriate use cases. A strong statistical justification exists for the
selection of the suitable loss function for training a deep learning model.
This report connects common loss functions such as Mean Squared Error (MSE),
Mean Absolute Error (MAE), and various Cross-Entropy losses to the statistical
principle of Maximum Likelihood Estimation (MLE). Choosing a specific loss
function is equivalent to assuming a specific probability distribution for the
model output, highlighting the link between these functions and the Generalized
Linear Models (GLMs) that underlie network output layers. Additional scenarios
of practical interest are also considered, such as alternative output
encodings, constrained outputs, and distributions with heavy tails.

</details>


### [48] [Consecutive Preferential Bayesian Optimization](https://arxiv.org/abs/2511.05163)
*Aras Erarslan,Carlos Sevilla Salcedo,Ville Tanskanen,Anni Nisov,Eero Päiväkumpu,Heikki Aisala,Kaisu Honkapää,Arto Klami,Petrus Mikkola*

Main category: cs.LG

TL;DR: 提出Consecutive Preferential Bayesian Optimization方法，通过约束比较涉及先前生成的候选方案来降低生产成本，并考虑反馈的感知模糊性，在具有高生产成本或感知模糊反馈的设置中显著提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好贝叶斯优化方法忽略了生成候选解决方案的成本，且未考虑反馈提供者的感知模糊性。

Method: 通过约束比较涉及先前生成的候选方案来降低生产成本，并引入Just-Noticeable Difference阈值到概率偏好模型中，以捕捉对小效用差异的感知模糊性。

Result: 在具有高生产成本或感知模糊反馈的设置中，该方法显著提高了准确性。

Conclusion: 提出的方法能够有效降低生产成本并处理感知模糊反馈，在相关设置中表现优于现有方法。

Abstract: Preferential Bayesian optimization allows optimization of objectives that are
either expensive or difficult to measure directly, by relying on a minimal
number of comparative evaluations done by a human expert. Generating candidate
solutions for evaluation is also often expensive, but this cost is ignored by
existing methods. We generalize preference-based optimization to explicitly
account for production and evaluation costs with Consecutive Preferential
Bayesian Optimization, reducing production cost by constraining comparisons to
involve previously generated candidates. We also account for the perceptual
ambiguity of the oracle providing the feedback by incorporating a
Just-Noticeable Difference threshold into a probabilistic preference model to
capture indifference to small utility differences. We adapt an
information-theoretic acquisition strategy to this setting, selecting new
configurations that are most informative about the unknown optimum under a
preference model accounting for the perceptual ambiguity. We empirically
demonstrate a notable increase in accuracy in setups with high production costs
or with indifference feedback.

</details>


### [49] [Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy](https://arxiv.org/abs/2511.05169)
*Simon Baur,Tristan Ruhwedel,Ekin Böke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich*

Main category: cs.LG

TL;DR: 本研究评估了实验室、影像和多模态深度学习模型在预测PRRT治疗患者无进展生存期(PFS)的表现。多模态融合模型结合实验室值、SR-PET和CT数据，性能最佳(AUROC 0.72)。


<details>
  <summary>Details</summary>
Motivation: 肽受体放射性核素治疗(PRRT)是转移性神经内分泌肿瘤的成熟疗法，但仅部分患者能获得长期疾病控制。预测PFS可支持个体化治疗规划。

Method: 回顾性单中心研究纳入116例接受177Lu-DOTATOC治疗的转移性神经内分泌肿瘤患者。收集临床特征、实验室值和治疗前生长抑素受体PET/CT数据。训练7个模型分类低vs高PFS组，包括单模态和多种多模态融合方法。

Result: 42例(36%)患者PFS短(<1年)，74例PFS长(>1年)。仅基于实验室生物标志物的随机森林模型AUROC为0.59，单模态3D CNN使用SR-PET或CT性能较差。多模态融合模型性能最佳(AUROC 0.72, AUPRC 0.80)。

Conclusion: 结合SR-PET、CT和实验室生物标志物的多模态深度学习在PRRT后PFS预测中优于单模态方法。经外部验证后，此类模型可能支持风险适应的随访策略。

Abstract: Peptide receptor radionuclide therapy (PRRT) is an established treatment for
metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs
only in a subset of patients. Predicting progression-free survival (PFS) could
support individualized treatment planning. This study evaluates laboratory,
imaging, and multimodal deep learning models for PFS prediction in PRRT-treated
patients. In this retrospective, single-center study 116 patients with
metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical
characteristics, laboratory values, and pretherapeutic somatostatin receptor
positron emission tomography/computed tomographies (SR-PET/CT) were collected.
Seven models were trained to classify low- vs. high-PFS groups, including
unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.
Explainability was evaluated by feature importance analysis and gradient maps.
Forty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1
year). Groups were similar in most characteristics, except for higher baseline
chromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT
cycles (p < 0.001) in short-PFS patients. The Random Forest model trained only
on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal
three-dimensional convolutional neural networks using SR-PET or CT performed
worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion
model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch
- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).
Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers
outperformed unimodal approaches for PFS prediction after PRRT. Upon external
validation, such models may support risk-adapted follow-up strategies.

</details>


### [50] [Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models](https://arxiv.org/abs/2511.05171)
*Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi*

Main category: cs.LG

TL;DR: NatureLM在生物声学任务上表现优异，但在指令跟随灵活性上存在权衡。通过简单的模型融合策略，将NatureLM与其基础语言模型插值，可以恢复指令跟随能力，同时保持领域专业知识，并在零样本分类上实现显著改进。


<details>
  <summary>Details</summary>
Motivation: NatureLM在生物声学领域表现出色，但发现其在指令跟随灵活性方面存在局限，特别是当同时请求多个信息时性能下降。

Method: 应用简单的模型融合策略，将NatureLM与其基础语言模型进行插值融合。

Result: 融合后的模型恢复了指令跟随能力，同时保持了领域专业知识，在零样本分类上实现了超过200%的相对改进，创造了新的最先进水平。

Conclusion: 模型融合策略能够有效平衡领域专业知识和指令跟随灵活性，为生物声学基础模型的发展提供了有前景的方向。

Abstract: Foundation models capable of generalizing across species and tasks represent
a promising new frontier in bioacoustics, with NatureLM being one of the most
prominent examples. While its domain-specific fine-tuning yields strong
performance on bioacoustic benchmarks, we observe that it also introduces
trade-offs in instruction-following flexibility. For instance, NatureLM
achieves high accuracy when prompted for either the common or scientific name
individually, but its accuracy drops significantly when both are requested in a
single prompt. We address this by applying a simple model merging strategy that
interpolates NatureLM with its base language model, recovering
instruction-following capabilities with minimal loss of domain expertise.
Finally, we show that the merged model exhibits markedly stronger zero-shot
generalization, achieving over a 200% relative improvement and setting a new
state-of-the-art in closed-set zero-shot classification of unseen species.

</details>


### [51] [Associative Poisoning to Generative Machine Learning](https://arxiv.org/abs/2511.05177)
*Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang*

Main category: cs.LG

TL;DR: 提出了一种名为关联性投毒的新型数据投毒技术，通过扰动训练数据来操纵生成输出中特定特征对之间的统计关联，无需控制训练过程。


<details>
  <summary>Details</summary>
Motivation: 生成模型如Stable Diffusion和ChatGPT的广泛应用使其成为恶意利用的目标，现有投毒攻击要么导致生成数据质量普遍下降，要么需要控制训练过程，限制了实际应用。

Method: 关联性投毒攻击仅扰动训练数据来操纵生成输出中特征对之间的统计关联，提供了数学公式化并证明了理论可行性和隐蔽性。

Result: 在两个最先进生成模型上的实证评估表明，关联性投毒能有效诱导或抑制特征关联，同时保持目标特征的边缘分布和高质量输出，从而逃避视觉检测。

Conclusion: 生成系统在图像合成、合成数据集生成和自然语言处理中容易受到这种隐蔽操纵，威胁其统计完整性，需要新的防御策略。

Abstract: The widespread adoption of generative models such as Stable Diffusion and
ChatGPT has made them increasingly attractive targets for malicious
exploitation, particularly through data poisoning. Existing poisoning attacks
compromising synthesised data typically either cause broad degradation of
generated data or require control over the training process, limiting their
applicability in real-world scenarios. In this paper, we introduce a novel data
poisoning technique called associative poisoning, which compromises
fine-grained features of the generated data without requiring control of the
training process. This attack perturbs only the training data to manipulate
statistical associations between specific feature pairs in the generated
outputs. We provide a formal mathematical formulation of the attack and prove
its theoretical feasibility and stealthiness. Empirical evaluations using two
state-of-the-art generative models demonstrate that associative poisoning
effectively induces or suppresses feature associations while preserving the
marginal distributions of the targeted features and maintaining high-quality
outputs, thereby evading visual detection. These results suggest that
generative systems used in image synthesis, synthetic dataset generation, and
natural language processing are susceptible to subtle, stealthy manipulations
that compromise their statistical integrity. To address this risk, we examine
the limitations of existing defensive strategies and propose a novel
countermeasure strategy.

</details>


### [52] [No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models](https://arxiv.org/abs/2511.05179)
*Ragini Gupta,Naman Raina,Bo Chen,Li Chen,Claudiu Danilov,Josh Eckhardt,Keyshla Bernard,Klara Nahrstedt*

Main category: cs.LG

TL;DR: 本研究系统评估了不同时空预测模型在传感器密度和采样频率变化下的表现，发现STGNN在稀疏部署时表现最佳，而TSFM在高频采样时竞争力强，Moirai模型因学习跨传感器依赖关系而表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有物联网环境感知技术主要关注边缘数据收集优化，但忽视了采样频率和空间覆盖变化对下游预测模型性能的影响，特别是不同模型架构与这些因素的相互作用尚未得到充分研究。

Method: 使用真实世界无线传感器网络的温度数据，系统研究经典模型(VAR)、神经网络(GRU、Transformer)、时空图神经网络(STGNN)和时间序列基础模型(TSFM: Chronos、Moirai、TimesFM)在不同空间传感器节点密度和采样间隔下的表现。

Result: STGNN在传感器部署稀疏且采样率适中时最有效，通过编码图结构利用空间相关性补偿有限覆盖；TSFM在高频时竞争力强但在空间覆盖减少时性能下降；多元TSFM Moirai通过学习跨传感器依赖关系在所有模型中表现最佳。

Conclusion: 研究结果为构建高效的时空系统预测管道提供了可行见解，所有模型配置、训练、数据集和日志均已开源以确保可复现性。

Abstract: Modern IoT deployments for environmental sensing produce high volume
spatiotemporal data to support downstream tasks such as forecasting, typically
powered by machine learning models. While existing filtering and strategic
deployment techniques optimize collected data volume at the edge, they overlook
how variations in sampling frequencies and spatial coverage affect downstream
model performance. In many forecasting models, incorporating data from
additional sensors denoise predictions by providing broader spatial contexts.
This interplay between sampling frequency, spatial coverage and different
forecasting model architectures remain underexplored. This work presents a
systematic study of forecasting models - classical models (VAR), neural
networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs),
and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under
varying spatial sensor nodes density and sampling intervals using real-world
temperature data in a wireless sensor network. Our results show that STGNNs are
effective when sensor deployments are sparse and sampling rate is moderate,
leveraging spatial correlations via encoded graph structure to compensate for
limited coverage. In contrast, TSFMs perform competitively at high frequencies
but degrade when spatial coverage from neighboring sensors is reduced.
Crucially, the multivariate TSFM Moirai outperforms all models by natively
learning cross-sensor dependencies. These findings offer actionable insights
for building efficient forecasting pipelines in spatio-temporal systems. All
code for model configurations, training, dataset, and logs are open-sourced for
reproducibility:
https://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models

</details>


### [53] [Linear Gradient Prediction with Control Variates](https://arxiv.org/abs/2511.05187)
*Kamil Ciosek,Nicolò Felicioni,Juan Elenter Litwin*

Main category: cs.LG

TL;DR: 提出一种使用近似预测梯度替代完整梯度的神经网络训练方法，通过控制变量技术确保更新是无偏估计，并基于神经正切核理论推导梯度预测器，在视觉Transformer分类任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 减少神经网络训练成本，避免昂贵的反向传播计算。

Method: 使用近似预测梯度替代完整梯度，基于控制变量技术确保无偏估计，利用神经正切核理论推导梯度预测器。

Result: 在视觉Transformer分类任务中验证了方法的有效性。

Conclusion: 该方法能够有效降低训练成本，同时保持模型性能。

Abstract: We propose a new way of training neural networks, with the goal of reducing
training cost. Our method uses approximate predicted gradients instead of the
full gradients that require an expensive backward pass. We derive a
control-variate-based technique that ensures our updates are unbiased estimates
of the true gradient. Moreover, we propose a novel way to derive a predictor
for the gradient inspired by the theory of the Neural Tangent Kernel. We
empirically show the efficacy of the technique on a vision transformer
classification task.

</details>


### [54] [ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy](https://arxiv.org/abs/2511.05221)
*David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,Noémie Moreau,Michael Sommerauer,Katarzyna Bozek*

Main category: cs.LG

TL;DR: 开发了ActiTect，一个全自动开源机器学习工具，通过腕戴式活动记录仪检测快速眼动睡眠行为障碍(RBD)，在多个数据集上验证了其良好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: iRBD是α-突触核蛋白病的早期标志，腕戴式活动记录仪有潜力用于大规模筛查RBD，但缺乏可靠高效的分析流程。

Method: 开发包含稳健预处理和自动睡眠-觉醒检测的流程，提取生理可解释的运动特征，使用机器学习模型识别RBD。

Result: 在78人队列中AUROC=0.95，本地测试集(n=31)AUROC=0.86，两个外部队列分别达到AUROC=0.84和0.94，跨数据集验证表现稳定。

Conclusion: ActiTect作为开源易用工具，促进了广泛采用和独立验证，推动了使用可穿戴设备的统一且可泛化的RBD检测模型发展。

Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major
prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical
onset of Parkinson's disease, dementia with Lewy bodies, or multiple system
atrophy. While wrist-worn actimeters hold significant potential for detecting
RBD in large-scale screening efforts by capturing abnormal nocturnal movements,
they become inoperable without a reliable and efficient analysis pipeline. This
study presents ActiTect, a fully automated, open-source machine learning tool
to identify RBD from actigraphy recordings. To ensure generalizability across
heterogeneous acquisition settings, our pipeline includes robust preprocessing
and automated sleep-wake detection to harmonize multi-device data and extract
physiologically interpretable motion features characterizing activity patterns.
Model development was conducted on a cohort of 78 individuals, yielding strong
discrimination under nested cross-validation (AUROC = 0.95). Generalization was
confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two
independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To
assess real-world robustness, leave-one-dataset-out cross-validation across the
internal and external cohorts demonstrated consistent performance (AUROC range
= 0.84-0.89). A complementary stability analysis showed that key predictive
features remained reproducible across datasets, supporting the final pooled
multi-center model as a robust pre-trained resource for broader deployment. By
being open-source and easy to use, our tool promotes widespread adoption and
facilitates independent validation and collaborative improvements, thereby
advancing the field toward a unified and generalizable RBD detection model
using wearable devices.

</details>


### [55] [The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](https://arxiv.org/abs/2511.05236)
*Rui Wu,Lizheng Wang,Yongjun Li*

Main category: cs.LG

TL;DR: 提出了BELM-MDCM框架，通过消除结构重建误差(SRE)实现因果信息守恒，为基于扩散模型的因果推理提供了严谨的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决结构因果模型中忠实溯因的计算挑战，特别是扩散模型在因果推理中的信息丢失问题。

Method: 设计BELM-MDCM框架，采用分析可逆机制消除SRE，结合目标建模策略和混合训练目标。

Result: 实现了零SRE，在个体层面获得高保真反事实推理，达到最先进精度。

Conclusion: 为现代生成模型与经典因果理论的结合提供了基础蓝图，为该新兴领域设立了更严谨的标准。

Abstract: Judea Pearl's vision of Structural Causal Models (SCMs) as engines for
counterfactual reasoning hinges on faithful abduction: the precise inference of
latent exogenous noise. For decades, operationalizing this step for complex,
non-linear mechanisms has remained a significant computational challenge. The
advent of diffusion models, powerful universal function approximators, offers a
promising solution. However, we argue that their standard design, optimized for
perceptual generation over logical inference, introduces a fundamental flaw for
this classical problem: an inherent information loss we term the Structural
Reconstruction Error (SRE). To address this challenge, we formalize the
principle of Causal Information Conservation (CIC) as the necessary condition
for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based
framework engineered to be causally sound by eliminating SRE by construction
through an analytically invertible mechanism. To operationalize this framework,
a Targeted Modeling strategy provides structural regularization, while a Hybrid
Training Objective instills a strong causal inductive bias. Rigorous
experiments demonstrate that our Zero-SRE framework not only achieves
state-of-the-art accuracy but, more importantly, enables the high-fidelity,
individual-level counterfactuals required for deep causal inquiries. Our work
provides a foundational blueprint that reconciles the power of modern
generative models with the rigor of classical causal theory, establishing a new
and more rigorous standard for this emerging field.

</details>


### [56] [An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](https://arxiv.org/abs/2511.05265)
*Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji*

Main category: cs.LG

TL;DR: 提出了一种基于分层Actor-Critic深度强化学习的TSP-D求解框架，结合Transformer编码器和最小门控单元解码器，在计算时间和训练效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 卡车-无人机协同系统在最后一公里物流中具有重要应用价值，但TSP-D问题具有NP难组合复杂性，传统优化方法难以有效解决，需要新的深度强化学习方法来应对这一挑战。

Method: 采用分层Actor-Critic深度强化学习框架，包含Transformer风格的编码器（使用优化的k近邻稀疏注意力机制）和高效的最小门控单元解码器，在异步优势演员-评论家范式下运行。

Result: 在不同规模的基准TSP-D实例上（N=10到100），与高性能启发式算法和现有强化学习方法相比，该模型能以更短的平均计算时间获得竞争性甚至更优的解。

Conclusion: 所提出的框架在显著减少总训练时间的同时实现了更优的最终性能，在训练效率方面具有显著优势，为TSP-D问题提供了有效的深度强化学习解决方案。

Abstract: The emergence of truck-drone collaborative systems in last-mile logistics has
positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal
extension of classical routing optimization, where synchronized vehicle
coordination promises substantial operational efficiency and reduced
environmental impact, yet introduces NP-hard combinatorial complexity beyond
the reach of conventional optimization paradigms. Deep reinforcement learning
offers a theoretically grounded framework to address TSP-D's inherent
challenges through self-supervised policy learning and adaptive
decision-making. This study proposes a hierarchical Actor-Critic deep
reinforcement learning framework for solving the TSP-D problem. The
architecture consists of two primary components: a Transformer-inspired encoder
and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,
optimized k-nearest neighbors sparse attention mechanism specifically for
focusing on relevant spatial relationships, further enhanced by the integration
of global node features. The Minimal Gated Unit decoder processes these encoded
representations to efficiently generate solution sequences. The entire
framework operates within an asynchronous advantage actor-critic paradigm.
Experimental results show that, on benchmark TSP-D instances of various scales
(N=10 to 100), the proposed model can obtain competitive or even superior
solutions in shorter average computation times compared to high-performance
heuristic algorithms and existing reinforcement learning methods. Moreover,
compared to advanced reinforcement learning algorithm benchmarks, the proposed
framework significantly reduces the total training time required while
achieving superior final performance, highlighting its notable advantage in
training efficiency.

</details>


### [57] [Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage](https://arxiv.org/abs/2511.05266)
*Gabriel Serrão Seabra,Nikolaj T. Mücke,Vinicius Luiz Santos Silva,Alexandre A. Emerick,Denis Voskov,Femke Vossepoel*

Main category: cs.LG

TL;DR: 本文提出了一种将基于分数的扩散模型与机器学习增强定位相结合的框架，用于地质碳储存项目中通道化储层的CO₂注入数据同化。


<details>
  <summary>Details</summary>
Motivation: 准确表征地下非均质性对于安全有效地实施地质碳储存项目至关重要，需要改进数据同化方法来增强不确定性量化。

Method: 采用机器学习增强定位框架，使用扩散模型生成渗透率场，通过简单ML算法计算状态，改进ESMDA的协方差估计。

Result: 基于机器学习的定位方法比未应用定位时保持了显著更多的集合方差，同时实现了相当的数据匹配质量。

Conclusion: 该框架对地质碳储存项目具有实际意义，有助于提高风险评估中不确定性量化的可靠性。

Abstract: Accurate characterization of subsurface heterogeneity is important for the
safe and effective implementation of geological carbon storage (GCS) projects.
This paper explores how machine learning methods can enhance data assimilation
for GCS with a framework that integrates score-based diffusion models with
machine learning-enhanced localization in channelized reservoirs during CO$_2$
injection. We employ a machine learning-enhanced localization framework that
uses large ensembles ($N_s = 5000$) with permeabilities generated by the
diffusion model and states computed by simple ML algorithms to improve
covariance estimation for the Ensemble Smoother with Multiple Data Assimilation
(ESMDA). We apply ML algorithms to a prior ensemble of channelized permeability
fields, generated with the geostatistical model FLUVSIM. Our approach is
applied on a CO$_2$ injection scenario simulated using the Delft Advanced
Research Terra Simulator (DARTS). Our ML-based localization maintains
significantly more ensemble variance than when localization is not applied,
while achieving comparable data-matching quality. This framework has practical
implications for GCS projects, helping improve the reliability of uncertainty
quantification for risk assessment.

</details>


### [58] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 研究探索数据增强如何减轻时间序列预测模型中的成员推理攻击，发现使用ZOO-PCA方法生成合成数据能有效降低攻击成功率且不牺牲预测性能。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录的时间序列预测任务中，需要在强隐私保护和高预测性能之间取得平衡。成员推理攻击会泄露训练数据隐私，因此需要找到有效防御方法。

Method: 采用多种数据增强策略：Zeroth-Order Optimization (ZOO)、ZOO-PCA（受主成分分析约束的ZOO变体）和MixUp，通过生成合成样本来增强模型对成员推理攻击的抵御能力。

Result: 实验结果显示，ZOO-PCA方法在降低成员推理攻击的TPR/FPR比率方面表现最佳，同时不会影响测试数据的预测性能。

Conclusion: 数据增强特别是ZOO-PCA方法能有效防御成员推理攻击，在保护隐私的同时保持模型预测性能，为时间序列预测任务提供了实用的隐私保护方案。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


### [59] [Attention and Compression is all you need for Controllably Efficient Language Models](https://arxiv.org/abs/2511.05313)
*Jatin Prakash,Aahlad Puli,Rajesh Ranganath*

Main category: cs.LG

TL;DR: CAT是一种高效的Transformer架构，通过压缩和分块注意力机制，在保持密集注意力质量的同时显著降低计算和内存需求，并能通过调整块大小在测试时动态控制质量-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 现有高效注意力方法（稀疏注意力、滑动窗口、卷积等）往往需要在质量和效率之间进行权衡，且需要复杂的启发式设计或混合架构。这些方法无法根据下游应用需求灵活调整质量-效率平衡。

Method: 提出Compress & Attend Transformer (CAT)，仅使用两个简单组件：密集注意力和压缩。通过将序列分块，在解码时仅关注压缩后的历史块，从而减少序列长度实现计算和内存节省。支持多块大小训练，实现测试时自适应调整。

Result: 在语言建模、上下文回忆和长上下文理解任务中，单一自适应CAT模型在不同计算-内存预算下均优于现有高效基线。与密集Transformer相比，CAT在保持相同语言建模性能的同时，速度提升1.4-3倍，总内存使用降低2-9倍。

Conclusion: CAT提供了一种简单而有效的解决方案，通过压缩和分块注意力机制实现了质量与效率的良好平衡，且支持测试时自适应调整，避免了复杂的混合架构设计。

Abstract: The quadratic cost of attention in transformers motivated the development of
efficient approaches: namely sparse and sliding window attention, convolutions
and linear attention. Although these approaches result in impressive reductions
in compute and memory, they often trade-off with quality, specifically
in-context recall performance. Moreover, apriori fixing this quality-compute
tradeoff means being suboptimal from the get-go: some downstream applications
require more memory for in-context recall, while others require lower latency
and memory. Further, these approaches rely on heuristic choices that
artificially restrict attention, or require handcrafted and complex recurrent
state update rules, or they must be carefully composed with attention at
specific layers to form a hybrid architecture that complicates the design
process, especially at scale. To address above issues, we propose Compress &
Attend Transformer (CAT), a conceptually simple architecture employing two
simple ingredients only: dense attention and compression. CAT decodes chunks of
tokens by attending to compressed chunks of the sequence so far. Compression
results in decoding from a reduced sequence length that yields compute and
memory savings, while choosing a particular chunk size trades-off quality for
efficiency. Moreover, CAT can be trained with multiple chunk sizes at once,
unlocking control of quality-compute trade-offs directly at test-time without
any retraining, all in a single adaptive architecture. In exhaustive
evaluations on common language modeling tasks, in-context recall, and
long-context understanding, a single adaptive CAT model outperforms existing
efficient baselines, including hybrid architectures, across different
compute-memory budgets. Further, a single CAT matches dense transformer in
language modeling across model scales while being 1.4-3x faster and requiring
2-9x lower total memory usage.

</details>


### [60] [Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](https://arxiv.org/abs/2511.05325)
*Janet Jenq,Hongda Shen*

Main category: cs.LG

TL;DR: 提出一种通过在商品图像上渲染相关文本内容来增强视觉-文本对齐的方法，提升多模态商品检索性能


<details>
  <summary>Details</summary>
Motivation: 多模态商品检索系统依赖视觉和文本信号的结合，但现有视觉语言模型容易受到排版攻击的影响，导致预测偏差

Method: 将商品标题、描述等文本内容直接渲染到商品图像上，进行视觉-文本压缩，强化图像-文本对齐

Result: 在三个垂直电商数据集上评估，使用六个最先进的视觉基础模型，在单模态和多模态检索准确率上均获得一致提升

Conclusion: 在商品图像上视觉化渲染产品元数据是电商应用中零样本多模态检索的简单而有效的增强方法

Abstract: Multimodal product retrieval systems in e-commerce platforms rely on
effectively combining visual and textual signals to improve search relevance
and user experience. However, vision-language models such as CLIP are
vulnerable to typographic attacks, where misleading or irrelevant text embedded
in images skews model predictions. In this work, we propose a novel method that
reverses the logic of typographic attacks by rendering relevant textual content
(e.g., titles, descriptions) directly onto product images to perform
vision-text compression, thereby strengthening image-text alignment and
boosting multimodal product retrieval performance. We evaluate our method on
three vertical-specific e-commerce datasets (sneakers, handbags, and trading
cards) using six state-of-the-art vision foundation models. Our experiments
demonstrate consistent improvements in unimodal and multimodal retrieval
accuracy across categories and model families. Our findings suggest that
visually rendering product metadata is a simple yet effective enhancement for
zero-shot multimodal retrieval in e-commerce applications.

</details>


### [61] [Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes](https://arxiv.org/abs/2511.05330)
*Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel*

Main category: cs.LG

TL;DR: 本文提出了一种基于非保守哈密顿高斯过程的动力学学习方法，能够在仅有输入-输出数据的情况下构建物理一致的模型，无需依赖速度或动量数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要速度或动量数据，但在实际应用中这些数据很少可用。本文旨在解决从输入-输出数据学习动力学的问题，同时保持物理一致性。

Method: 采用非保守哈密顿高斯过程，结合降秩GP近似，提供完全贝叶斯方案来估计隐藏状态、GP超参数和结构超参数的概率密度。

Result: 在非线性仿真案例中评估了所提方法，并与依赖动量测量的最先进方法进行了比较。

Conclusion: 该方法能够在仅有输入-输出数据的情况下有效学习物理一致的动力学模型，计算效率高，适用于实际应用场景。

Abstract: Embedding non-restrictive prior knowledge, such as energy conservation laws,
in learning-based approaches is a key motive to construct physically consistent
models from limited data, relevant for, e.g., model-based control. Recent work
incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to
obtain uncertainty-quantifying models that adhere to the underlying physical
principles. However, these works rely on velocity or momentum data, which is
rarely available in practice. In this paper, we consider dynamics learning with
non-conservative Hamiltonian GPs, and address the more realistic problem
setting of learning from input-output data. We provide a fully Bayesian scheme
for estimating probability densities of unknown hidden states, of GP
hyperparameters, as well as of structural hyperparameters, such as damping
coefficients. Considering the computational complexity of GPs, we take
advantage of a reduced-rank GP approximation and leverage its properties for
computationally efficient prediction and training. The proposed method is
evaluated in a nonlinear simulation case study and compared to a
state-of-the-art approach that relies on momentum measurements.

</details>


### [62] [SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](https://arxiv.org/abs/2511.05355)
*Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche*

Main category: cs.LG

TL;DR: 提出SAD-Flower框架，通过虚拟控制输入增强流匹配，为状态约束、动作约束和动态一致性提供形式化保证，无需重新训练即可满足未见约束。


<details>
  <summary>Details</summary>
Motivation: 流匹配在数据驱动规划中表现良好，但缺乏对状态和动作约束的形式化保证，且现有方法不确保动态一致性，可能导致轨迹不可执行。

Method: 通过虚拟控制输入增强流匹配，利用非线性控制理论推导原则性指导，为约束满足和动态一致性提供形式化保证。

Result: 在多个任务上的实验表明，SAD-Flower在确保约束满足方面优于各种基于生成模型的基线方法。

Conclusion: SAD-Flower框架能够生成安全、可接受且动态一致的轨迹，无需重新训练即可满足未见约束，在约束满足方面优于现有方法。

Abstract: Flow matching (FM) has shown promising results in data-driven planning.
However, it inherently lacks formal guarantees for ensuring state and action
constraints, whose satisfaction is a fundamental and crucial requirement for
the safety and admissibility of planned trajectories on various systems.
Moreover, existing FM planners do not ensure the dynamical consistency, which
potentially renders trajectories inexecutable. We address these shortcomings by
proposing SAD-Flower, a novel framework for generating Safe, Admissible, and
Dynamically consistent trajectories. Our approach relies on an augmentation of
the flow with a virtual control input. Thereby, principled guidance can be
derived using techniques from nonlinear control theory, providing formal
guarantees for state constraints, action constraints, and dynamic consistency.
Crucially, SAD-Flower operates without retraining, enabling test-time
satisfaction of unseen constraints. Through extensive experiments across
several tasks, we demonstrate that SAD-Flower outperforms various
generative-model-based baselines in ensuring constraint satisfaction.

</details>


### [63] [Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](https://arxiv.org/abs/2511.05396)
*Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 本文研究了在线鲁棒马尔可夫决策过程（RMDP）中的强化学习问题，提出了首个计算高效的算法，在具有f-散度转移不确定性的在线RMDP中实现了次线性遗憾，并建立了匹配的遗憾下界。


<details>
  <summary>Details</summary>
Motivation: 现有文献大多假设可以访问生成模型或预收集的数据集，绕过了探索的挑战。本文研究更现实和具有挑战性的设置：智能体仅限于与训练环境进行在线交互。

Method: 引入了上确界访问比率来衡量训练动态与部署动态之间的不匹配，提出了首个计算高效的算法，在具有f-散度转移不确定性的在线RMDP中实现了次线性遗憾。

Result: 证明了如果上确界访问比率无界，在线学习会变得指数级困难。提出的算法在在线RMDP中实现了次线性遗憾，并建立了匹配的遗憾下界。

Conclusion: 通过全面的数值实验验证了理论结果，表明所提出的算法在上确界访问比率和交互回合数方面达到了最优依赖关系。

Abstract: Off-dynamics reinforcement learning (RL), where training and deployment
transition dynamics are different, can be formulated as learning in a robust
Markov decision process (RMDP) where uncertainties in transition dynamics are
imposed. Existing literature mostly assumes access to generative models
allowing arbitrary state-action queries or pre-collected datasets with a good
state coverage of the deployment environment, bypassing the challenge of
exploration. In this work, we study a more realistic and challenging setting
where the agent is limited to online interaction with the training environment.
To capture the intrinsic difficulty of exploration in online RMDPs, we
introduce the supremal visitation ratio, a novel quantity that measures the
mismatch between the training dynamics and the deployment dynamics. We show
that if this ratio is unbounded, online learning becomes exponentially hard. We
propose the first computationally efficient algorithm that achieves sublinear
regret in online RMDPs with $f$-divergence based transition uncertainties. We
also establish matching regret lower bounds, demonstrating that our algorithm
achieves optimal dependence on both the supremal visitation ratio and the
number of interaction episodes. Finally, we validate our theoretical results
through comprehensive numerical experiments.

</details>


### [64] [ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids](https://arxiv.org/abs/2511.05420)
*Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo*

Main category: cs.LG

TL;DR: 提出了一种用于智能电网故障预测的持续学习框架ProDER，通过原型特征正则化、logit蒸馏和原型引导重放机制，在四种现实评估场景中实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI故障预测模型在动态环境中难以适应新故障类型和运行区域，需要持续学习框架来应对智能电网的演进需求。

Method: 设计了基于类增量和域增量学习的四种现实评估场景，提出了ProDER方法，整合原型特征正则化、logit蒸馏和原型引导重放内存。

Result: ProDER在测试的CL技术中表现最佳，故障类型预测准确率仅下降0.045，故障区域预测准确率仅下降0.015。

Conclusion: 证明了持续学习在智能电网可扩展、实际故障预测中的实用性。

Abstract: As smart grids evolve to meet growing energy demands and modern operational
challenges, the ability to accurately predict faults becomes increasingly
critical. However, existing AI-based fault prediction models struggle to ensure
reliability in evolving environments where they are required to adapt to new
fault types and operational zones. In this paper, we propose a continual
learning (CL) framework in the smart grid context to evolve the model together
with the environment. We design four realistic evaluation scenarios grounded in
class-incremental and domain-incremental learning to emulate evolving grid
conditions. We further introduce Prototype-based Dark Experience Replay
(ProDER), a unified replay-based approach that integrates prototype-based
feature regularization, logit distillation, and a prototype-guided replay
memory. ProDER achieves the best performance among tested CL techniques, with
only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone
prediction. These results demonstrate the practicality of CL for scalable,
real-world fault prediction in smart grids.

</details>


### [65] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 提出加速路径修补(APP)方法，结合对比性注意力头剪枝技术，大幅减少电路发现的计算成本，在保持电路质量的同时实现59.63%-93.27%的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法如路径修补计算成本高，限制了在小模型上进行深入电路分析的能力。

Method: APP采用混合方法：首先使用对比性FLAP剪枝算法减少搜索空间，然后在剩余注意力头上应用传统路径修补。

Result: APP平均减少56%的搜索空间，速度提升59.63%-93.27%，发现的电路与原始路径修补电路有显著重叠且性能相似。

Conclusion: APP在保持电路发现质量的同时，显著降低了计算成本，为机制解释性研究提供了更高效的解决方案。

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


### [66] [Adversarially Robust Multitask Adaptive Control](https://arxiv.org/abs/2511.05444)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: cs.LG

TL;DR: 该论文提出了一种对抗性鲁棒的多任务自适应线性二次控制方法，通过聚类和系统识别结合弹性聚合来减轻被破坏的模型更新。


<details>
  <summary>Details</summary>
Motivation: 研究多个系统在模型不确定性和对抗性破坏下协作学习控制策略的问题，需要解决对抗性系统对模型更新的破坏。

Method: 采用聚类多任务方法，将聚类和系统识别与弹性聚合相结合，以减轻被破坏的模型更新。

Result: 分析表明，后悔值随每个聚类中诚实系统数量的增加而减少，并且在每个聚类内对抗性系统比例有界的情况下，这种减少效果得以保持。

Conclusion: 所提出的聚类多任务方法能够有效应对对抗性破坏，在保证控制性能的同时提高系统的鲁棒性。

Abstract: We study adversarially robust multitask adaptive linear quadratic control; a
setting where multiple systems collaboratively learn control policies under
model uncertainty and adversarial corruption. We propose a clustered multitask
approach that integrates clustering and system identification with resilient
aggregation to mitigate corrupted model updates. Our analysis characterizes how
clustering accuracy, intra-cluster heterogeneity, and adversarial behavior
affect the expected regret of certainty-equivalent (CE) control across LQR
tasks. We establish non-asymptotic bounds demonstrating that the regret
decreases inversely with the number of honest systems per cluster and that this
reduction is preserved under a bounded fraction of adversarial systems within
each cluster.

</details>


### [67] [Parameter-Efficient Conditioning for Material Generalization in Graph-Based Simulators](https://arxiv.org/abs/2511.05456)
*Naveen Raj Manoharan,Hassan Iqbal,Krishna Kumar*

Main category: cs.LG

TL;DR: 提出了一种参数高效的FiLM条件机制，使图网络模拟器能够适应不同材料参数，仅需少量数据即可实现对新材料的准确长期模拟，并成功应用于逆问题求解。


<details>
  <summary>Details</summary>
Motivation: 现有图网络模拟器通常针对单一材料类型训练，无法泛化到不同本构行为，限制了在真实工程场景中的应用。

Method: 发现材料属性敏感性集中在早期消息传递层，提出针对这些层的FiLM条件机制，仅需微调前1-5层即可达到全网络微调的效果。

Result: 在未见、插值或适度外推的材料参数上实现准确长期模拟，仅需12个短轨迹数据，相比基线多任务学习方法减少5倍数据需求。

Conclusion: 该方法使GNS能够用于逆设计和闭环控制任务，其中材料属性可作为设计变量。

Abstract: Graph network-based simulators (GNS) have demonstrated strong potential for
learning particle-based physics (such as fluids, deformable solids, and
granular flows) while generalizing to unseen geometries due to their inherent
inductive biases. However, existing models are typically trained for a single
material type and fail to generalize across distinct constitutive behaviors,
limiting their applicability in real-world engineering settings. Using granular
flows as a running example, we propose a parameter-efficient conditioning
mechanism that makes the GNS model adaptive to material parameters. We identify
that sensitivity to material properties is concentrated in the early
message-passing (MP) layers, a finding we link to the local nature of
constitutive models (e.g., Mohr-Coulomb) and their effects on information
propagation. We empirically validate this by showing that fine-tuning only the
first few (1-5) of 10 MP layers of a pretrained model achieves comparable test
performance as compared to fine-tuning the entire network. Building on this
insight, we propose a parameter-efficient Feature-wise Linear Modulation (FiLM)
conditioning mechanism designed to specifically target these early layers. This
approach produces accurate long-term rollouts on unseen, interpolated, or
moderately extrapolated values (e.g., up to 2.5 degrees for friction angle and
0.25 kPa for cohesion) when trained exclusively on as few as 12 short
simulation trajectories from new materials, representing a 5-fold data
reduction compared to a baseline multi-task learning method. Finally, we
validate the model's utility by applying it to an inverse problem, successfully
identifying unknown cohesion parameters from trajectory data. This approach
enables the use of GNS in inverse design and closed-loop control tasks where
material properties are treated as design variables.

</details>


### [68] [Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models](https://arxiv.org/abs/2511.05460)
*Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister*

Main category: cs.LG

TL;DR: 提出了Synapse框架，通过动态仲裁多个预训练时间序列基础模型的输出来提升预测性能，解决了不同模型在不同任务中表现不均的问题。


<details>
  <summary>Details</summary>
Motivation: 预训练时间序列基础模型在不同预测任务、领域和时域中表现差异很大，但利用这种互补专业知识的仲裁策略研究尚不充分。

Method: 提出Synapse框架，动态利用TSFM池，根据上下文相关性能分配和调整预测权重，并通过自适应采样组成模型的输出分位数来构建稳健的预测分布。

Result: 实验结果表明Synapse在时间序列预测中始终优于其他流行的集成技术以及单个TSFM。

Conclusion: Synapse框架通过有效仲裁多个预训练时间序列基础模型的输出，显著提升了时间序列预测的性能和稳健性。

Abstract: Pre-trained Time Series Foundational Models (TSFMs) represent a significant
advance, capable of forecasting diverse time series with complex
characteristics, including varied seasonalities, trends, and long-range
dependencies. Despite their primary goal of universal time series forecasting,
their efficacy is far from uniform; divergent training protocols and data
sources cause individual TSFMs to exhibit highly variable performance across
different forecasting tasks, domains, and horizons. Leveraging this
complementary expertise by arbitrating existing TSFM outputs presents a
compelling strategy, yet this remains a largely unexplored area of research. In
this paper, we conduct a thorough examination of how different TSFMs exhibit
specialized performance profiles across various forecasting settings, and how
we can effectively leverage this behavior in arbitration between different time
series models. We specifically analyze how factors such as model selection and
forecast horizon distribution can influence the efficacy of arbitration
strategies. Based on this analysis, we propose Synapse, a novel arbitration
framework for TSFMs. Synapse is designed to dynamically leverage a pool of
TSFMs, assign and adjust predictive weights based on their relative,
context-dependent performance, and construct a robust forecast distribution by
adaptively sampling from the output quantiles of constituent models.
Experimental results demonstrate that Synapse consistently outperforms other
popular ensembling techniques as well as individual TSFMs, demonstrating
Synapse's efficacy in time series forecasting.

</details>


### [69] [SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning](https://arxiv.org/abs/2511.05462)
*Xiaodong Wang,Jing Huang,Kevin J Liang*

Main category: cs.LG

TL;DR: 本文通过将无监督聚类方法与经典统计混合模型建立联系，提出了SiamMM模型，在自监督学习基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法在自监督和无监督学习中应用广泛但缺乏理论基础，且最优方法尚不明确。

Method: 建立无监督聚类方法与经典混合模型的联系框架，开发了SiamMM模型。

Result: 在多个自监督学习基准测试中达到最先进性能，学习到的聚类结果与真实标签高度相似，甚至能发现可能的错误标注。

Conclusion: 通过统计框架增强聚类方法能显著提升性能，并揭示数据中潜在的标注错误。

Abstract: Recent studies have demonstrated the effectiveness of clustering-based
approaches for self-supervised and unsupervised learning. However, the
application of clustering is often heuristic, and the optimal methodology
remains unclear. In this work, we establish connections between these
unsupervised clustering methods and classical mixture models from statistics.
Through this framework, we demonstrate significant enhancements to these
clustering methods, leading to the development of a novel model named SiamMM.
Our method attains state-of-the-art performance across various self-supervised
learning benchmarks. Inspection of the learned clusters reveals a strong
resemblance to unseen ground truth labels, uncovering potential instances of
mislabeling.

</details>


### [70] [Precipitation nowcasting of satellite data using physically conditioned neural networks](https://arxiv.org/abs/2511.05471)
*Antônio Catão,Melvin Poveda,Leonardo Voltarelli,Paulo Orenstein*

Main category: cs.LG

TL;DR: TUPANN是一个基于卫星数据的降水临近预报模型，通过物理对齐的深度学习架构，将预报分解为运动场和强度场等物理分量，在多个气候区域和不同降水阈值下表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统短期降水预报依赖密集的天气雷达网络，但在气候极端地区覆盖不足。本文旨在开发仅使用卫星数据的通用降水临近预报模型，解决雷达网络限制问题。

Method: TUPANN采用物理对齐架构：变分编码器-解码器推断运动场和强度场，lead-time条件化的MaxViT演化潜在状态，可微分平流算子重建未来帧。模型在GOES-16 RRQPE数据上训练。

Result: 在四个不同气候区域（里约热内卢、马瑙斯、迈阿密、拉巴斯）的评估显示，TUPANN在10-180分钟预报时效内，在4-64mm/h阈值上使用CSI和HSS指标，在大多数设置中达到最佳或次佳性能，特别是在高阈值下优势明显。多城市训练进一步提升性能。

Conclusion: 物理对齐学习能够提供技能优异、可迁移且全球适用的临近预报，模型生成平滑可解释的运动场，并由于GOES-16的低延迟而能近实时运行。

Abstract: Accurate short-term precipitation forecasts predominantly rely on dense
weather-radar networks, limiting operational value in places most exposed to
climate extremes. We present TUPANN (Transferable and Universal Physics-Aligned
Nowcasting Network), a satellite-only model trained on GOES-16 RRQPE. Unlike
most deep learning models for nowcasting, TUPANN decomposes the forecast into
physically meaningful components: a variational encoder-decoder infers motion
and intensity fields from recent imagery under optical-flow supervision, a
lead-time-conditioned MaxViT evolves the latent state, and a differentiable
advection operator reconstructs future frames. We evaluate TUPANN on both
GOES-16 and IMERG data, in up to four distinct climates (Rio de Janeiro,
Manaus, Miami, La Paz) at 10-180min lead times using the CSI and HSS metrics
over 4-64 mm/h thresholds. Comparisons against optical-flow, deep learning and
hybrid baselines show that TUPANN achieves the best or second-best skill in
most settings, with pronounced gains at higher thresholds. Training on multiple
cities further improves performance, while cross-city experiments show modest
degradation and occasional gains for rare heavy-rain regimes. The model
produces smooth, interpretable motion fields aligned with numerical optical
flow and runs in near real time due to the low latency of GOES-16. These
results indicate that physically aligned learning can provide nowcasts that are
skillful, transferable and global.

</details>


### [71] [On Flow Matching KL Divergence](https://arxiv.org/abs/2511.05480)
*Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu*

Main category: cs.LG

TL;DR: 本文推导了流匹配分布近似的KL散度的确定性非渐近上界，证明了当L2流匹配损失有界时，真实数据分布与估计分布之间的KL散度也有界，从而确立了流匹配在总变差距离下的统计收敛率。


<details>
  <summary>Details</summary>
Motivation: 研究流匹配方法的统计效率，将其与扩散模型在总变差距离下的性能进行比较，证明流匹配在估计平滑分布时能达到近乎极小极大最优效率。

Method: 通过推导流匹配分布近似的KL散度的确定性非渐近上界，建立L2流匹配损失与KL散度之间的定量关系，并分析其在总变差距离下的统计收敛性质。

Result: 如果L2流匹配损失有界于ε²>0，则真实数据分布与估计分布之间的KL散度有界于A₁ε + A₂ε²，其中常数A₁和A₂仅依赖于数据和速度场的正则性。

Conclusion: 流匹配在总变差距离下具有与扩散模型相当的统计效率，在估计平滑分布时能达到近乎极小极大最优效率，数值研究验证了理论结果。

Abstract: We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler
(KL) divergence of the flow-matching distribution approximation. In particular,
if the $L_2$ flow-matching loss is bounded by $\epsilon^2 > 0$, then the KL
divergence between the true data distribution and the estimated distribution is
bounded by $A_1 \epsilon + A_2 \epsilon^2$. Here, the constants $A_1$ and $A_2$
depend only on the regularities of the data and velocity fields. Consequently,
this bound implies statistical convergence rates of Flow Matching Transformers
under the Total Variation (TV) distance. We show that, flow matching achieves
nearly minimax-optimal efficiency in estimating smooth distributions. Our
results make the statistical efficiency of flow matching comparable to that of
diffusion models under the TV distance. Numerical studies on synthetic and
learned velocities corroborate our theory.

</details>


### [72] [SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning](https://arxiv.org/abs/2511.05482)
*Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du*

Main category: cs.LG

TL;DR: SoilX是一个无需校准的土壤传感系统，可同时测量土壤水分、氮、磷、钾、有机碳和铝硅酸盐六个关键成分，通过对比交叉成分学习和新型天线设计消除土壤质地变化的影响。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要持续监测土壤水分和关键养分，但现有无线土壤传感解决方案需要针对不同土壤质地重新校准，限制了实用性。

Method: 采用对比交叉成分学习（3CL）和正交正则化与分离损失，设计新型四面体天线阵列和天线切换机制来稳健测量土壤介电常数。

Result: 实验表明SoilX比基线方法减少23.8%至31.5%的估计误差，并在未见过的田地中表现出良好的泛化能力。

Conclusion: SoilX通过显式建模有机碳和铝硅酸盐，成功实现了无需重新校准的土壤传感，解决了土壤质地变化带来的实用性问题。

Abstract: Precision agriculture demands continuous and accurate monitoring of soil
moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),
and potassium (K), to optimize yields and conserve resources. Wireless soil
sensing has been explored to measure these four components; however, current
solutions require recalibration (i.e., retraining the data processing model) to
handle variations in soil texture, characterized by aluminosilicates (Al) and
organic carbon (C), limiting their practicality. To address this, we introduce
SoilX, a calibration-free soil sensing system that jointly measures six key
components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX
eliminates texture- and carbon-dependent recalibration. SoilX incorporates
Contrastive Cross-Component Learning (3CL), with two customized terms: the
Orthogonality Regularizer and the Separation Loss, to effectively disentangle
cross-component interference. Additionally, we design a novel tetrahedral
antenna array with an antenna-switching mechanism, which can robustly measure
soil dielectric permittivity independent of device placement. Extensive
experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%
over baselines and generalizes well to unseen fields.

</details>


### [73] [DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction](https://arxiv.org/abs/2511.05483)
*Abigail Lin*

Main category: cs.LG

TL;DR: DGTN是一种新颖的扩散图-Transformer网络，通过双向扩散机制协同学习结构先验和序列模式，在酶热力学稳定性预测(DDG)上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法通常独立处理序列和结构信息，未能捕捉局部结构几何与全局序列模式之间的复杂耦合关系。

Method: 提出DGTN架构，通过双向扩散过程：GNN结构嵌入通过可学习扩散核指导transformer注意力，transformer表示通过注意力调制图更新来精炼GNN消息传递。

Result: 在ProTherm和SKEMPI基准测试中，DGTN达到最先进性能(Pearson Rho = 0.87, RMSE = 1.21 kcal/mol)，比最佳基线提升6.2%。扩散机制贡献4.8个相关点。

Conclusion: 该工作建立了通过可学习扩散整合异构蛋白质表示的原则性框架，理论分析证明扩散注意力收敛到最优结构-序列耦合。

Abstract: Predicting the effect of amino acid mutations on enzyme thermodynamic
stability (DDG) is fundamental to protein engineering and drug design. While
recent deep learning approaches have shown promise, they often process sequence
and structure information independently, failing to capture the intricate
coupling between local structural geometry and global sequential patterns. We
present DGTN (Diffused Graph-Transformer Network), a novel architecture that
co-learns graph neural network (GNN) weights for structural priors and
transformer attention through a diffusion mechanism. Our key innovation is a
bidirectional diffusion process where: (1) GNN-derived structural embeddings
guide transformer attention via learnable diffusion kernels, and (2)
transformer representations refine GNN message passing through
attention-modulated graph updates. We provide rigorous mathematical analysis
showing this co-learning scheme achieves provably better approximation bounds
than independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves
state-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with
6.2% improvement over best baselines. Ablation studies confirm the diffusion
mechanism contributes 4.8 points to correlation. Our theoretical analysis
proves the diffused attention converges to optimal structure-sequence coupling,
with convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work
establishes a principled framework for integrating heterogeneous protein
representations through learnable diffusion.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [74] [From single-particle to many-body chaos in Yukawa--SYK: theory and a cavity-QED proposal](https://arxiv.org/abs/2511.04762)
*David Pascual Solis,Alex Windey,Soumik Bandyopadhyay,Andrea Legramandi,Philipp Hauke*

Main category: quant-ph

TL;DR: Yukawa-SYK模型通过玻色场介导的随机费米子相互作用，在单粒子混沌和多体混沌之间架起桥梁，揭示了中间区域的独特动力学行为。


<details>
  <summary>Details</summary>
Motivation: 理解量子系统从可积到混沌的转变是物理学核心问题，传统SYK模型只描述强关联极限，缺乏对中间区域的研究。

Method: 使用谱和动力学混沌标记，对YSYK模型进行全面的有限尺寸表征，建立与SYK2和SYK4基准模型的直接定量比较框架。

Result: 发现相互作用强度可调谐控制参数，在中间区域观察到部分遍历性破坏、预热化平台和不完全信息扰乱等独特动力学机制。

Conclusion: YSYK模型成为连接单粒子和多体混沌的统一平台，并提出了可行的光学腔实现方案，为实验观测这些现象铺平道路。

Abstract: Understanding how quantum systems transition from integrable to fully chaotic
behavior remains a central open problem in physics. The Sachdev--Ye--Kitaev
(SYK) model provides a paradigmatic framework for studying many-body chaos and
holography, yet it captures only the strongly correlated limit, leaving
intermediate regimes unexplored. Here, we investigate the Yukawa--SYK (YSYK)
model, where bosonic fields mediate random fermionic interactions, and
demonstrate that it naturally bridges single-particle and many-body chaos.
Using spectral and dynamical chaos markers, we perform a comprehensive
finite-size characterization of the YSYK model. We show that the interaction
strength acts as a tunable control parameter interpolating between the SYK$_2$
and SYK$_4$ limits, and introduce a framework enabling direct and quantitative
comparison with these benchmark models. In the intermediate regimes, we uncover
distinct dynamical regimes marked by partial ergodicity breaking,
prethermalization plateaus, and incomplete scrambling. Finally, we propose a
feasible optical-cavity implementation of the YSYK model using ultra-cold
atoms. Our results establish the YSYK model as a unifying platform connecting
single-particle and many-body chaos, paving the way for experimental
observation of these phenomena.

</details>


### [75] [Real-time magnetic field noise correction using trapped-ion monitor qubits](https://arxiv.org/abs/2511.04767)
*Kyle DeBry,Agustin Valdes-Martinez,David Reens,Colin D. Bruzewicz,John Chiaverini*

Main category: quant-ph

TL;DR: 提出了一种使用监测量子比特实时追踪磁场漂移的囚禁离子协议，在不中断数据量子比特操作的情况下实现前馈校正，显著延长了相干时间和实验占空比。


<details>
  <summary>Details</summary>
Motivation: 量子处理器中的磁场漂移会破坏量子比特的相干性，传统校准方法需要中断实验，限制了系统性能和实验效率。

Method: 使用两个$^{40}\mathrm{Ca}^+$离子，将数据量子比特编码在基态能级，监测量子比特编码在亚稳态能级实现光谱分离，监测量子比特感知磁场波动并前馈校正控制驱动。

Result: 在$1/f^{2}$噪声谱下，协议保持相干性，相比交错校准方法，可用数据量子比特探测时间延长约$\sqrt{2}$倍，实验占空比翻倍。

Conclusion: 监测量子比特是量子信息处理器中实现实时重新校准的可扩展工具。

Abstract: We demonstrate a trapped-ion protocol in which a nearby, dedicated "monitor"
qubit tracks magnetic-field drifts in real time without interrupting data-qubit
operations. Using two $^{40}\mathrm{Ca}^+$ ions and the
optical--metastable--ground architecture, we encode the data qubit in the
ground-state manifold and the monitor qubit in a metastable-state manifold to
achieve spectral separation. The monitor qubit senses common magnetic
fluctuations during data-qubit experiments, enabling feedforward corrections to
the qubit-control drives. Under applied magnetic noise with a realistic
spectrum ($1/f^{2}$), the protocol maintains coherence and, when compared with
interleaved calibration, it extends usable data-qubit probe times by up to a
factor of ${\sim}\sqrt{2}$ and doubles the experimental duty cycle. These
results establish monitor qubits as a scalable tool for real-time recalibration
in quantum information processors.

</details>


### [76] [Security Evaluation of Quantum Circuit Split Compilation under an Oracle-Guided Attack](https://arxiv.org/abs/2511.04842)
*Hongyu Zhang,Yuntao Liu*

Main category: quant-ph

TL;DR: 本文对量子电路混淆技术（特别是分割编译）进行了首次全面的安全评估，提出了基于预言机引导的攻击框架，能够有效恢复隐藏的分割连接并重构完整电路。


<details>
  <summary>Details</summary>
Motivation: 量子电路是量子算法的核心知识产权，现有量子电路混淆技术缺乏彻底的安全评估，需要验证其实际防护能力。

Method: 提出预言机引导的安全评估框架，通过系统测试候选连接并迭代修剪不一致的映射，利用量子门的可逆性减少搜索空间。

Result: 在RevLib基准测试中，仅需少量输入输出对即可恢复正确的分割间连接并重构完整电路。

Conclusion: 这是量子IP保护领域的首次全面安全评估，强调了在新保护方案开发中进行此类评估的必要性。

Abstract: Quantum circuits are the fundamental representation of quantum algorithms and
constitute valuable intellectual property (IP). Multiple quantum circuit
obfuscation (QCO) techniques have been proposed in prior research to protect
quantum circuit IP against malicious compilers. However, there has not been a
thorough security evaluation of these schemes. In this work, we investigate the
resilience of split compilation against an oracle-guided attack. Split
compilation is one of the most studied QCO techniques, where the circuit to be
compiled is split into two disjoint partitions. Each split circuit is known to
the compiler, but the interconnections between them are hidden. We propose an
oracle-guided security evaluation framework in which candidate connections are
systematically tested against input-output observations, with iteratively
pruned inconsistent mappings. This hierarchical matching process exploits the
reversibility of quantum gates and reduces the search space compared to
brute-force enumeration. Experimental evaluation in the RevLib benchmark suite
shows that only a small number of I/O pairs are sufficient to recover the
correct inter-split connections and reconstruct the entire circuits. Our study
marks the first thorough security evaluations in quantum IP protection and
highlights the necessity of such evaluations in the development of new
protection schemes.

</details>


### [77] [Ballistic bosonic noise suppression with hybrid qumode-qubit rotation gates](https://arxiv.org/abs/2511.04888)
*Saurabh U. Shringarpure,Siheon Park,Sungjoo Cho,Yong Siah Teo,Hyukjoon Kwon,Srikrishna Omkar,Hyunseok Jeong*

Main category: quant-ph

TL;DR: 提出了一种基于混合连续-离散变量干涉仪的热噪声抑制方案，仅需单个量子比特辅助和两个受控傅里叶门，可将热噪声效应抑制到二阶，无需主动纠错或破坏性测量，成功概率高于0.5。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理中噪声抑制至关重要，特别是针对热噪声对单模玻色编码的影响，需要开发高效且资源友好的噪声抑制方法。

Method: 使用混合连续-离散变量干涉仪，包含单个量子比特辅助和两个受控傅里叶门，通过条件监测光子数宇称来实现噪声抑制。对于同宇称编码，方案简化为使用qumode旋转门和单个受控傅里叶门。

Result: 成功将热噪声效应抑制到O(η²)，当η(1+ṅ)<0.5时成功概率>0.5。同宇称编码对离散变量振幅和相位阻尼噪声完全鲁棒。扩展方案在双实验室通信中实现类似性能但更强的辅助噪声鲁棒性。

Conclusion: 该方案为资源高效的多量子比特编码提供了一种有效的噪声抑制方法，相比现有旁路协议具有明显优势，特别适用于依赖少量长程相互作用的编码方案。

Abstract: Noise suppression is of paramount importance for reliable quantum information
processing and computation. We show that for any single-mode bosonic code
(qumode) corrupted by thermal~noise at rate~$\eta$ and mean
\mbox{excitation}~$\bar{n}$, a hybrid continuous-discrete-variable~(CV-DV)
interferometer using only a single qubit ancilla~(DV) and two
controlled~Fourier~(CF) gates sandwiching the noise channel suppresses its
effects to $\mathcal{O}(\eta^2)$ \emph{without} any active error correction or
destructive measurements of the encoded state and with high success
probabilities~$>0.5$ if~$\eta(1+\bar{n})<0.5$. This suppression scheme works by
conditionally monitoring the photon-number parities after the interferometer.
Bosonic codes with two logical states of the same photon-number parity
(like-parity codes) are \emph{completely resilient} to DV amplitude- and
phase-damping ancilla noise. For such codes, the interferometer simplifies to
the use of a qumode rotation gate and a \emph{single} CF~gate. This presents a
clear advantage of our CF-gate-based error suppression scheme over
previously-proposed ``bypass'' protocols, where qubit information transferred
to the DV mode is readily corrupted by damping~noise. Finally, we present a
simple extension to direct communication of qumode states between two parties
over a noisy channel using a preshared DV entangled state, by implementing a CF
gate in the first laboratory and its inverse in the other. Such a communication
protocol achieves a similar fidelity performance at the same success rate as
the single-party case, but with greater resilience to the ancilla noise than
DV~teleportation. Resource-efficient multi-qubit codes that depend on a few
essential long-range interactions can benefit from it.

</details>


### [78] [Programmable Adiabatic Rapid Passage laser pulses for Ultra-fast Gates on trapped ions](https://arxiv.org/abs/2511.04893)
*En-Teng An,Hao-Qing Zhang,Yun-Feng Huang,Chuan-Feng Li,Jin-Ming Cui*

Main category: quant-ph

TL;DR: 提出了一种可编程脉冲源，通过灵活控制脉冲强度、波形和相位轮廓来改进超快量子门的保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 超快量子门的扩展是量子信息科学的核心挑战，现有脉冲源难以实现高时间可调性和稳定性。

Method: 使用可编程脉冲源控制脉冲序列，实现精确操纵，并采用STIRARP协议进行绝热快速通道。

Result: 模拟结果显示，该系统可实现超过99.99%的量子门保真度，对脉冲强度和单光子失谐变化具有强鲁棒性。

Conclusion: 可编程脉冲源为改进超快量子门的性能提供了一种有前景的方法。

Abstract: Scaling of quantum gates remains a central challenge in quantum information
science. Ultrafast gates based on spin-dependent kicks provide a promising
approach for trapped-ion systems. However, these gates require laser pulses
with both high temporal tunability and stability, which are difficult to
achieve with existing pulsed sources. Here, we propose a programmable pulsed
source that allows flexible control of pulse intensity, waveform, and phase
profiles. This enables precise manipulation of pulse sequences, thereby
improving the fidelity of entangling gates. Furthermore, since the pulse
parameters can be conveniently tuned, various coherent population-transfer
schemes can be implemented adiabatic SDKs, thereby improving both the fidelity
and robustness of fast quantum gate. Simulation results show that our
programmable pulse system can achieve gate fidelities above 99.99% with strong
robustness against variations in pulse intensity and single-photon detuning
using stimulated Raman adiabatic rapid passage (STIRARP) protocols.

</details>


### [79] [Spin-Network Quantum Reservoir Computing with Distributed Inputs: The Role of Entanglement](https://arxiv.org/abs/2511.04900)
*Sareh Askari,Youssef Kora,Christoph Simon*

Main category: quant-ph

TL;DR: 本文研究了量子自旋网络储层计算中纠缠对短期记忆性能的影响，发现适度的纠缠（特别是两个输入量子比特之间的纠缠）对提升短期记忆能力起关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究分布式场景下，两个独立输入时间序列注入自旋网络储层时，整体纠缠及其在系统中的局域化如何影响储层性能。

Method: 使用自旋网络储层计算，评估双线性记忆任务中的短期记忆容量，并与对数负性作为二分纠缠度量进行关联分析。

Result: 短期记忆容量在较小耦合强度时达到最大值，而平均纠缠在较大耦合时达到峰值；两个输入量子比特之间的纠缠最强且与任务性能最相关；在小耦合强度下储层表现出延长的记忆尾迹。

Conclusion: 适度的纠缠，特别是两个输入量子比特之间的纠缠，在增强短期记忆性能中起关键作用，信息需要有限传播时间才能在储层中有效召回。

Abstract: Reservoir computing is a promising neuromorphic paradigm, and its quantum
implementation using spin networks has shown some advantage when entanglement
is present. Here, we consider a distributed scenario in which two distinct
input time series are injected into separate qubits of a spin-network
reservoir. We investigate how the overall entanglement, as well as its
localization in the system, influence the performance of the reservoir.
Focusing on bilinear memory tasks that require computing the product of the two
inputs, we evaluate the short-term memory capacity and correlate it with
logarithmic negativity as a measure of bipartite entanglement. We find that
short-term memory capacity reaches its maximum at relatively small coupling
strengths. In contrast, average entanglement peaks at larger couplings.
Analyzing entanglement across all bipartitions, we find that the entanglement
between the two input qubits is consistently the strongest and most relevant
for task performance. In the small coupling strength regime where the
short-term memory capacity is maximized, the reservoir exhibits an extended
memory tail: performance remains high for a long time. Finally, a pronounced
dip in performance at zero time delay, observed across frequencies, indicates
that information requires a finite propagation time through the reservoir
before it can be effectively recalled. In summary, our results show that
moderate entanglement, particularly between the two input qubits, plays a key
role in enhancing short-term memory performance.

</details>


### [80] [On the Origin of the Hidden Symmetry in the Asymmetric Quantum Rabi Model](https://arxiv.org/abs/2511.04916)
*Yun-Tong Yang,Song-Ming Chen,Hong-Gang Luo*

Main category: quant-ph

TL;DR: 本文研究了非对称量子拉比模型中的隐藏对称性起源，发现在特定参数条件下能级简并重新出现，这种隐藏对称性源于非对称双势阱中的能级匹配，并在强耦合区域出现激发态量子相变。


<details>
  <summary>Details</summary>
Motivation: 非对称量子拉比模型在特定参数下会出现能级简并现象，即隐藏对称性。理解这种隐藏对称性的起源及其显式算子形式是该系统的核心研究任务。

Method: 采用两次连续对角化方法，重点研究两能级分裂与模式频率比值Δ/ω ≫ 1的强耦合区域，通过分析基态和激发态的波函数来支持物理图像。

Result: 发现隐藏对称性源于非对称双势阱中的能级匹配，识别出激发态量子相变的出现，该相变源于隐藏对称性在不同耦合区域的破缺和恢复。

Conclusion: 研究结果提供了对非对称量子拉比模型物理的更深层次理解，特别是在先前较少探索的强耦合区域Δ/ω ≫ 1。

Abstract: The introduction of an asymmetric term into the quantum Rabi model generally
lifts energy-level degeneracies. However, when the asymmetry parameter takes
specific multiples of the bosonic mode frequency, level degeneracies
reappear$-$a phenomenon referred to as the hidden symmetry in the asymmetric
quantum Rabi model. Identifying the origin of this hidden symmetry and its
explicit operator form constitutes two central tasks in studying this system.
Here, we investigate the origin of this hidden symmetry using the method of two
successive diagonalizations, with a focus on physics in the regime where the
ratio between the two-level splitting $\Delta$ and the mode frequency $\omega$
satisfies $\Delta/\omega \gg 1$. We find that the hidden symmetry stems from
energy-level matching within the asymmetric double-well potential, a picture
strongly supported by the wavefunctions of both the ground and excited states.
Moreover, the emergence of an excited-state quantum phase transition is
identified and qualitatively discussed, which arises from the breaking and
restoration of this hidden symmetry across different coupling regimes. Our
results provide deeper insight into the physics of the asymmetric quantum Rabi
model, particularly in the previously less-explored strong-coupling regime
where $\Delta/\omega \gg 1$.

</details>


### [81] [Universal and Tunable Sudden Freezing of Entanglement Volume](https://arxiv.org/abs/2511.04927)
*Luchang Niu,Joseph H. Eberly*

Main category: quant-ph

TL;DR: 该研究将两原子系统中的纠缠冻结现象推广到任意N量子比特系统，发现了控制纠缠冻结时间和值的方法，并揭示了这种现象的几何机制和普遍性。


<details>
  <summary>Details</summary>
Motivation: 将Ding等人发现的二原子系统中纠缠突然冻结的现象扩展到更一般的量子系统，探索这种现象的普遍性和控制方法。

Method: 通过几何解释分析纠缠动力学，将原子-腔场相互作用系统中的纠缠冻结行为推广到任意N量子比特系统，并开发控制冻结时间和值的方法。

Result: 成功将纠缠冻结现象推广到任意N量子比特系统，发现了永久冻结纠缠的非平凡动力学，并证明了这种现象在各种系统中的普遍性。

Conclusion: 纠缠冻结不是巧合现象，而是各种量子系统中普遍存在的特征，具有几何机制解释，并且可以通过特定方法进行控制和调节。

Abstract: In a system where two identical two-level atoms interact with their common
one-mode cavity field, it is shown that entanglement can become abruptly frozen
in time, remaining at a constant value for a period of time until it begins to
thaw from this value from the entanglement sharing perspective [Ding et al.,
Phys. Rev. A 103, 032418 (2021)]. We generalize this exotic behavior of
entanglement sharing dynamics to more general systems with arbitrary N qubits,
instead of restricting to the atom-cavity mode interaction system. We also
demonstrate methods to control the entanglement freezing time and freezing
value, and we discover a nontrivial dynamics where entanglement is frozen
permanently. In addition, we show that this phenomenon is not a coincidence but
a universal feature in a variety of systems with a geometric explanation of the
mechanisms.

</details>


### [82] [Representational power of selected neural network quantum states in second quantization](https://arxiv.org/abs/2511.04932)
*Zhendong Li,Tong Zhao,Bohan Zhang*

Main category: quant-ph

TL;DR: 本文提出了一种称为神经元乘积态（NPS）的新方法，用于表示费米子系统的量子态，并证明了其通用逼近能力。


<details>
  <summary>Details</summary>
Motivation: 神经网络量子态在解决量子多体问题中显示出潜力，但对于具有复杂符号结构的费米子系统，其成功和局限性尚未得到充分理解。

Method: 将受限玻尔兹曼机推广到更一般的费米子态类别，即神经元乘积态（NPS），通过简单非局域关联器的乘积来构建关联。

Result: 证明了在激活函数满足某些温和条件下，这种简单非局域关联器的乘积可以任意逼近任何波函数。

Conclusion: 这些结果为第二量子化中多体波函数的神经网络表示提供了更深入的见解。

Abstract: Neural network quantum states emerge as a promising tool for solving quantum
many-body problems. However, its successes and limitations are still not
well-understood in particular for Fermions with complex sign structures. Based
on our recent work [J. Chem. Theory Comput. 21, 10252-10262 (2025)], we
generalizes the restricted Boltzmann machine to a more general class of states
for Fermions, formed by product of `neurons' and hence will be referred to as
neuron product states (NPS). NPS builds correlation in a very different way,
compared with the closely related correlator product states (CPS) [H. J.
Changlani, et al. Phys. Rev. B, 80, 245116 (2009)], which use full-rank local
correlators. In constrast, each correlator in NPS contains long-range
correlations across all the sites, with its representational power constrained
by the simple function form. We prove that products of such simple nonlocal
correlators can approximate any wavefunction arbitrarily well under certain
mild conditions on the form of activation functions. In addition, we also
provide elementary proofs for the universal approximation capabilities of
feedforward neural network (FNN) and neural network backflow (NNBF) in second
quantization. Together, these results provide a deeper insight into the neural
network representation of many-body wavefunctions in second quantization.

</details>


### [83] [Quantum Algorithm for Local-Volatility Option Pricing via the Kolmogorov Equation](https://arxiv.org/abs/2511.04942)
*Nikita Guseynov,Mikel Sanz,Ángel Rodríguez-Rozas,Nana Liu,Javier Gonzalez-Conde*

Main category: quant-ph

TL;DR: 提出了一种端到端的量子算法框架，通过求解Kolmogorov前向偏微分方程来定价期权，利用Schrödingerisation技术将问题映射到哈密顿模拟，在维度上实现指数级加速。


<details>
  <summary>Details</summary>
Motivation: 传统期权定价方法在非线性、路径依赖、高维资产和复杂价格模型下计算成本高昂，量子计算被提出作为解决这些挑战的高效手段。

Method: 使用Schrödingerisation技术将Kolmogorov前向偏微分方程映射为哈密顿模拟问题，包括初始量子态制备、哈密顿模拟和通过交换测试高效恢复期权价格。

Result: 算法在单维度离散化上获得多项式优势，在高维系统（如期权篮子）中实现相对于维度的指数级加速，克服经典方法的维度诅咒。

Conclusion: 该端到端量子框架为解决挑战性期权定价任务提供了实现量子优势的潜在路径，特别适用于高维系统定价。

Abstract: The solution of option-pricing problems may turn out to be computationally
demanding due to non-linear and path-dependent payoffs, the high dimensionality
arising from multiple underlying assets, and sophisticated models of price
dynamics. In this context, quantum computing has been proposed as a means to
address these challenges efficiently. Prevailing approaches either simulate the
stochastic differential equations governing the forward dynamics of underlying
asset prices or directly solve the backward pricing partial differential
equation. Here, we present an end-to-end quantum algorithmic framework that
solves the Kolmogorov forward (Fokker-Planck) partial differential equation for
local-volatility models by mapping it to a Hamiltonian-simulation problem via
the Schr\"odingerisation technique. The algorithm specifies how to prepare the
initial quantum state, perform Hamiltonian simulation, and how to efficiently
recover the option price via a swap test. In particular, the efficiency of the
final solution recovery is an important advantage of solving the forward versus
the backward partial differential equation. Thus, our end-to-end framework
offers a potential route toward quantum advantage for challenging
option-pricing tasks. In particular, we obtain a polynomial advantage in grid
size for the discretization of a single dimension. Nevertheless, the true power
of our methodology lies in pricing high-dimensional systems, such as baskets of
options, because the quantum framework admits an exponential speedup with
respect to dimension, overcoming the classical curse of dimensionality.

</details>


### [84] [Distributed quantum approximate counting algorithm](https://arxiv.org/abs/2511.04945)
*Huaijing Huang,Daowen Qiu*

Main category: quant-ph

TL;DR: 提出了一种分布式量子算法，使用Grover算子和经典后处理解决计数问题，应用于估计内积和汉明距离，在NISQ时代具有优势。


<details>
  <summary>Details</summary>
Motivation: 开发适合NISQ（含噪声中等规模量子）时代的量子计数算法，减少量子资源需求。

Method: 结合Grover算子和经典后处理的分布式量子算法，在Qisikit平台上进行模拟验证。

Result: 与现有计数算法相比，在量子比特数、电路深度和量子门数量方面具有优势。

Conclusion: 该算法在NISQ时代具有实际应用价值，为量子计数问题提供了更高效的解决方案。

Abstract: In this article, we propose a distributed quantum algorithm for solving
counting problem using Grover operator and a classical post-processing
procedure. We apply the proposed algorithm to estimate inner products and
Hamming distances. Simulations are conducted on the Qisikit platform, further
demonstrating the effectiveness of our algorithm and its suitability for the
NISQ era. Compared to existing counting algorithms, the proposed algorithm has
advantages in terms of the number of qubits, circuit depth, and the number of
quantum gates.

</details>


### [85] [Hybrid action Reinforcement Learning for quantum architecture search](https://arxiv.org/abs/2511.04967)
*Jiayang Niu,Yan Wang,Jie Li,Ke Deng,Azadeh Alavi,Mark Sanderson,Yongli Ren*

Main category: quant-ph

TL;DR: HyRLQAS是一个混合动作强化学习框架，用于量子架构搜索，能够联合优化量子电路结构和参数，在VQE环境中实现更低的能量误差和更短的电路。


<details>
  <summary>Details</summary>
Motivation: 设计表达性强且可训练的量子电路架构是变分量子算法的主要挑战，手动或启发式设计往往导致次优性能。

Method: 提出HyRLQAS框架，在混合动作空间中耦合离散门放置和连续参数生成，通过强化学习联合学习电路拓扑和初始化，并动态优化已放置的门。

Result: 实验表明HyRLQAS比离散和连续基线方法获得更低的能量误差和更短的电路，混合动作空间不仅产生更好的电路结构，还提供有利的参数初始化。

Conclusion: 混合动作强化学习为自动化、硬件高效的量子电路设计提供了原则性途径。

Abstract: Designing expressive yet trainable quantum circuit architectures remains a
major challenge for variational quantum algorithms, where manual or heuristic
designs often lead to suboptimal performance. We propose HyRLQAS (Hybrid-Action
Reinforcement Learning for Quantum Architecture Search), a unified framework
that couples discrete gate placement and continuous parameter generation within
a hybrid action space. Unlike existing approaches that treat structure and
parameter optimization separately, HyRLQAS jointly learns circuit topology and
initialization while dynamically refining previously placed gates through a
reinforcement learning process. Trained in a variational quantum eigensolver
(VQE) environment, the agent constructs circuits that minimize molecular
ground-state energy. Experiments show that HyRLQAS achieves consistently lower
energy errors and shorter circuits than both discrete-only and continuous-only
baselines. Furthermore, the hybrid action space not only leads to better
circuit structures but also provides favorable parameter initializations,
resulting in post-optimization energy distributions with consistently lower
minima. These results suggest that hybrid action reinforcement learning
provides a principled pathway toward automated, hardware-efficient quantum
circuit design.

</details>


### [86] [Single and Double-click High-Rate Entanglement Generation Between Distant Ions Using Multiplexed Atomic Ensembles](https://arxiv.org/abs/2511.04987)
*Benedikt Tissot,Soubhadra Maiti,Emil R. Hellebek,Anders Søndberg Sørensen*

Main category: quant-ph

TL;DR: 本文扩展了离子阱量子处理器与系综量子存储器接口协议，比较了双点击和单点击方法在离子边缘节点的性能差异。


<details>
  <summary>Details</summary>
Motivation: 在先前研究基础上，进一步优化离子阱量子处理器与系综量子存储器之间的接口协议，提高长距离纠缠生成效率。

Method: 比较双点击和单点击两种方法：双点击方法放宽了相位稳定性要求但受限于有限效率，单点击方法效率更高但需要更严格的相位控制。

Result: 协议选择取决于相位稳定性的可用性以及离子与系综存储器接口的效率，双点击方法在相位稳定性受限时更优。

Conclusion: 根据具体实验条件（相位稳定性和接口效率）选择最优协议，双点击方法在相位控制困难时具有优势，而单点击方法在效率要求高时更合适。

Abstract: In an accompanying paper [1], we introduced an approach to interface
trapped-ion quantum processors with ensemble-based quantum memories by matching
a spontaneous parametric down conversion source to both the ions and the
memories. This enables rapid entanglement generation between single trapped
ions separated by distances of hundreds of kilometers. In this article, we
extend the protocol and provide additional details of the analysis.
Particularly, we compare a double-click and single-click approaches for the ion
edge nodes. The double-click approach relaxes the phase stability requirement
but is strongly affected by finite efficiencies. Choosing the optimal protocol
thus depends on the access to the phase stabilization as well as the efficiency
of interface of the ions and ensemble-based memories.

</details>


### [87] [Several kinds of Gaussian quantum channels](https://arxiv.org/abs/2511.05003)
*Ruifen Ma,Yanjing Sun,Xiaofei Qi*

Main category: quant-ph

TL;DR: 本文研究了高斯通道与量子导引的关系，定义了四类高斯导引相关通道，推导了各类通道的充要条件，并探索了它们之间的内在联系，同时详细描述了高斯不可导引超通道的结构。


<details>
  <summary>Details</summary>
Motivation: 量子导引是介于纠缠和贝尔非定域性之间的重要量子资源，而高斯通道在量子协议和安全通信中具有基础性作用。研究高斯通道与量子导引的关系对于理解连续变量系统中的量子资源至关重要。

Method: 定义了高斯导引湮灭通道、高斯导引破坏通道、高斯不可导引通道和最大高斯不可导引通道四类通道，推导了每类通道的充要条件，并分析了它们之间的内在关系。同时详细描述了高斯不可导引超通道和最大高斯不可导引超通道的结构。

Result: 获得了各类高斯导引相关通道的充要条件，揭示了它们之间的内在联系，并提供了高斯不可导引超通道的详细特征描述。

Conclusion: 这项工作为理解高斯通道在量子导引中的作用提供了系统框架，对于量化连续变量系统中高斯通道的导引能力和理解自由超通道结构具有重要意义。

Abstract: Quantum steering is a crucial quantum resource that lies intermediate between
entanglement and Bell nonlocality. Gaussian channels, meanwhile, play a
foundational role in diverse quantum protocols, secure communication, and
related fields. In this paper, we focus on several classes of Gaussian channels
associated with quantum steering: Gaussian steering-annihilating channels,
Gaussian steering-breaking channels, Gaussian unsteerable channels, and maximal
Gaussian unsteerable channels. We give the concepts of these channels, derive
the necessary and sufficient conditions for a Gaussian channel to belong to
each class, and explore the intrinsic relationships among them. Additionally,
since quantifying the steering capability of Gaussian channels in
continuous-variable systems requires an understanding of the structure of free
superchannels, we also provide a detailed characterization of Gaussian
unsteerable superchannels and maximal Gaussian unsteerable superchannels.

</details>


### [88] [Continuous-variable Measurement Device Independent MIMO Quantum Key Distribution for THz Communications](https://arxiv.org/abs/2511.05021)
*Leixin Wu,Congtian Deng,Jiayu Pan,Lingtao Zhang,Yanyan Feng,Runbo Zhao,Yang Shen,Yuying Zhang,Jian Zhou*

Main category: quant-ph

TL;DR: 本文提出了一种基于MIMO的太赫兹连续变量测量设备无关量子密钥分发系统，通过将测量委托给不可信的第三方来消除所有探测器攻击，显著提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: 虽然MIMO太赫兹CVQKD在理论上是安全的，但由于探测器缺陷可能产生实际漏洞，需要设计能够抵御探测器攻击的实用安全系统。

Method: 采用测量设备无关协议，将测量委托给第三方Charlie，使用收发波束成形技术将MIMO信道转换为多个并行损耗量子信道，研究纠缠基和制备测量两种协议。

Result: 仿真表明多天线配置和高效零差检测在缓解自由空间路径损耗和最大化密钥率方面起关键作用，系统性能在长距离传输时在较低太赫兹频率优化，短距离应用在较高频率优化。

Conclusion: 该协议为下一代无线网络中的安全量子通信提供了可扩展解决方案，展示了在室内外环境中部署的潜力。

Abstract: Although multiple-input multiple-output (MIMO) terahertz (THz)
continuous-variable quantum key distribution (CVQKD) is theoretically secure,
practical vulnerabilities may arise due to detector imperfections. This paper
explores a CV measurement-device-independent (MDI) QKD system operating at THz
frequencies within a MIMO framework. In this system, measurement is delegated
to an untrusted third party, Charlie, rather than the receiver, eliminating all
detector attacks and significantly enhancing the system's practical security.
Using transmit-receive beamforming techniques, the system transforms MIMO
channels into multiple parallel lossy quantum channels, enabling robust key
distribution between Alice and Bob. This study examines entanglement-based and
prepare-and-measure protocols, deriving secret key rates for both asymptotic
and finite code scenarios. Simulations reveal the critical role of multiple
antenna configurations and efficient homodyne detection in mitigating
free-space path loss and maximizing key rates. Results indicate that system
performance is optimized at lower THz frequencies for long-range transmissions
and higher frequencies for short-range applications. The proposed protocol
offers a scalable solution for secure quantum communications in next-generation
wireless networks, demonstrating potential for deployment in both indoor and
outdoor environments.

</details>


### [89] [Analysis of Frequency Collisions in Parametrically Modulated Superconducting Circuits](https://arxiv.org/abs/2511.05031)
*Zhuang Ma,Peng Zhao,Xinsheng Tan,Yang Yu*

Main category: quant-ph

TL;DR: 开发了一个基于Floquet理论的数值框架，用于分析和缓解超导电路中参数调制引起的寄生耦合和频率碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 超导电路中的参数调制技术会产生密集的寄生耦合景观，导致有害的频率碰撞，限制处理器性能。

Method: 结合数值分析和新推导的解析模型，表征寄生边带相互作用及其错误预算，并开发基于约束的优化方法来识别避免有害相互作用的参数配置。

Result: 该框架能够预测性地共同设计设备参数和控制协议，系统性地抑制串扰。

Conclusion: 这项工作为大规模高性能量子处理器的发展提供了系统工具，能够有效抑制串扰问题。

Abstract: Superconducting circuits are a leading platform for scalable quantum
computing, where parametric modulation is a widely used technique for
implementing high-fidelity multi-qubit operations. A critical challenge,
however, is that this modulation can induce a dense landscape of parasitic
couplings, leading to detrimental frequency collisions that constrain processor
performance. In this work, we develop a comprehensive numerical framework,
grounded in Floquet theory, to systematically analyze and mitigate these
collisions. Our approach integrates this numerical analysis with newly derived
analytical models for both qubit-modulated and coupler-modulated schemes,
allowing us to characterize the complete map of parasitic sideband interactions
and their distinct error budgets. This analysis forms the basis of a
constraint-based optimization methodology designed to identify parameter
configurations that satisfy the derived physical constraints, thereby avoiding
detrimental parasitic interactions. We illustrate the utility of this framework
with applications to analog quantum simulation and gate design. Our work
provides a predictive tool for co-engineering device parameters and control
protocols, enabling the systematic suppression of crosstalk and paving the way
for large-scale, high-performance quantum processors.

</details>


### [90] [Bounds on quantum Fisher information and uncertainty relations for thermodynamically conjugate variables](https://arxiv.org/abs/2511.05042)
*Ye-Ming Meng,Zhe-Yu Shi*

Main category: quant-ph

TL;DR: 该论文建立了热力学共轭变量的不确定性关系，类似于量子力学中的不确定性原理，为热平衡系统中的量子传感和计量学设定了基本精度限制。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的不确定性关系为力学共轭变量（如位置和动量）设定了同时测量的精度限制。本文旨在为热力学共轭变量建立类似的不确定性关系，扩展不确定性原理到热力学领域。

Method: 开发了一个基于精确积分表示的框架，将量子Fisher信息与算符的自相关函数联系起来。通过这个表示，推导出量子Fisher信息的紧上界，从而得到热力学不确定性关系。

Result: 推导出热力学不确定性关系：Δθ·ΔO ≥ k_BT，其中Δθ是经典强度参数的不确定性，ΔO是相应扩展量子算符的不确定性，T是系统温度。

Conclusion: 该工作建立了热力学共轭变量的基本不确定性关系，为热平衡系统中的量子传感和计量学设定了基本精度限制，并将精度限制与线性响应和涨落的热力学性质直接联系起来。

Abstract: Uncertainty relations represent a foundational principle in quantum
mechanics, imposing inherent limits on the precision with which
\textit{mechanically} conjugate variables such as position and momentum can be
simultaneously determined. This work establishes analogous relations for
\textit{thermodynamically} conjugate variables -- specifically, a classical
intensive parameter $\theta$ and its corresponding extensive quantum operator
$\hat{O}$ -- in equilibrium states. We develop a framework to derive a rigorous
thermodynamic uncertainty relation for such pairs, where the uncertainty of the
classical parameter $\theta$ is quantified by its quantum Fisher information
$\mathcal{F}_\theta$. The framework is based on an exact integral
representation that relates $\mathcal{F}_{\theta}$ to the autocorrelation
function of operator $\hat{O}$. From this representation, we derive a tight
upper bound for the quantum Fisher information, which yields a thermodynamic
uncertainty relation: $\Delta\theta\,\overline{\Delta O} \ge k_\text{B}T$ with
$\overline{\Delta O}\equiv\partial_\theta\langle\hat{O}\rangle\,\Delta\theta$
and $T$ is the system temperature. The result establishes a fundamental
precision limit for quantum sensing and metrology in thermal systems, directly
connecting it to the thermodynamic properties of linear response and
fluctuations.

</details>


### [91] [Channel Superposition Mitigates Photon Loss Errors in Quantum Illumination](https://arxiv.org/abs/2511.05125)
*Fei Li,Xiao-Wei Li,Oscar Dahlsten*

Main category: quant-ph

TL;DR: 本文提出使用通道叠加框架（包括不定因果序和路径叠加）来增强量子照明协议在光子损失情况下的性能，其中不定因果序协议显示出更强的鲁棒性优势。


<details>
  <summary>Details</summary>
Motivation: 量子照明中探针光子与辅助光子之间的纠缠能增强检测性能，但光子损失严重限制了这种协议的实际优势。

Method: 采用通道叠加框架，包括不定因果序和路径叠加两种协议，基于量子Chernoff边界进行解析和数值分析。

Result: 两种通道叠加协议原则上都能获得优势，只要存在非零干涉。不定因果序协议显著更鲁棒，能维持比标准量子照明和路径叠加更紧的错误概率上界。

Conclusion: 不定因果序协议通过共享环境产生更强的量子干涉，而路径叠加协议虽然实验上更易实现但效果较弱，性能差异源于其基本结构差异。

Abstract: In quantum illumination, the probe photon is entangled with an ancilla
photon, and both are jointly measured at the end. The entanglement between the
probe and ancilla photons enhances the detection performance per unit average
photon number in the probe mode, particularly in low-reflectivity and
high-noise scenarios. However, photon loss severely limits the practical
advantage of such protocols. To address this, we employ a channel superposition
framework, which encompasses two kinds of channel superposition protocols:
indefinite causal order (ICO) and path superposition with disjoint environment
(PS-DE). Our analytical and numerical analysis based on the quantum Chernoff
bound shows that both ICO and PS-DE can, in principle, achieve an advantage.
The advantage persists as long as non-zero interference remains, reverting to
the performance of standard quantum illumination once the interference is
completely suppressed. Crucially, the ICO protocol is significantly more
robust, maintaining a tighter upper bound on the error probability than
standard quantum illumination and the PS-DE approach. This performance
hierarchy is rooted in their fundamental structures: ICO exploits a shared
environment to generate stronger quantum interference, while PS-DE, relying on
disjoint environments, offers a more experimentally tractable albeit less
potent alternative.

</details>


### [92] [Robust Quantum Teleportation Against Noise Using Weak Measurement and Flip Operations](https://arxiv.org/abs/2511.05155)
*Mohit Dhanik,Shraddha Sharma,Pitamber Mahanandia*

Main category: quant-ph

TL;DR: 提出改进的量子隐形传态协议，结合弱测量和翻转反转操作，在噪声环境中提高保真度。


<details>
  <summary>Details</summary>
Motivation: 量子通信信道易受噪声影响导致退相干，需要增强协议在噪声环境下的鲁棒性。

Method: 使用四量子比特纠缠态作为量子信道，在传输前对共享量子比特进行弱测量和翻转操作，传输后进行反转操作来恢复原始量子态。

Result: 与现有WM-flip-reversal方法相比，改进的WMR协议在三种常见噪声模型（ADC、PFC、BFC）下获得显著更高的隐形传态保真度，尤其在比特翻转噪声环境中表现更优。

Conclusion: 优化的弱测量策略有潜力开发更可靠和抗噪声的量子通信协议。

Abstract: This study presents an improved quantum teleportation protocol designed to
enhance fidelity in noisy environments by combining weak measurements (WMs)
with flip and reversal operations. In our scheme, Alice prepares a four-qubit
entangled state and shares one of the entangled qubits with Bob, which serves
as the quantum channel for teleporting an arbitrary single-qubit state. Since
the communication channel is subject to noise, Alice performs a weak
measurement on the shared qubit before transmission to reduce the impact of
decoherence. Building upon existing WM-flip-reversal frameworks, we propose a
modified weak measurement and reversal (WMR) protocol tailored for different
noises in a four-qubit entangled system. The approach applies WM and flip
operations prior to transmission to enhance resilience against noise, followed
by corresponding reversal operations after transmission to recover the original
quantum state. We systematically compare the performance of our proposed WMR
protocol with the previously proposed WM-flip-reversal method under three
common noise models: amplitude damping channel (ADC), phase flip channel (PFC),
and bit flip channel (BFC). Our analysis reveals that the modified WMR scheme
achieves significantly higher teleportation fidelity and improved robustness,
particularly in bit flip noise environments. These findings highlight the
potential of optimized weak measurement strategies for developing more reliable
and noise-tolerant quantum communication protocols.

</details>


### [93] [Coherent control of quantum states by quadratically chirped short laser pulses](https://arxiv.org/abs/2511.05161)
*G. P. Djotyan,A. A. Avetisyan,A. P. Djotyan*

Main category: quant-ph

TL;DR: 提出了一种使用二次啁啾激光脉冲在λ型能级系统中相干操控粒子布居和创建任意相干叠加态的新方案


<details>
  <summary>Details</summary>
Motivation: 需要在量子系统中实现相干叠加态的可靠创建和操控，特别是在宽带激光脉冲条件下

Method: 使用载波频率二次啁啾的激光脉冲，通过修饰态分析和数值模拟来研究单宽带激光脉冲的情况

Result: 证明了通过改变激光脉冲参数可以可靠且鲁棒地创建任意相干叠加态

Conclusion: 该方案为量子系统中相干叠加态的操控提供了一种有效方法

Abstract: We present a novel scheme for coherent manipulation of populations and robust
creation of arbitrary coherent superposition of metastable states of a quantum
system with lambda configuration of operating energy levels using laser pulses
with a quadratically chirped carrier frequency. The case of a single broadband
laser pulse is considered, when the frequency spectrum of the pulse exceeds the
frequency distance between the metastable energy levels of the system. The
results of the dressed state analysis and numerical simulation are presented,
demonstrating reliable and robust creation of an arbitrary coherent
superposition of metastable states by changing the parameters of laser pulses.

</details>


### [94] [Performance Analysis of One- and Two-way DV-QKD with MIMO FSO Communication Systems](https://arxiv.org/abs/2511.05173)
*Sushil Kumar,Soumya P. Dash,George C. Alexandropoulos*

Main category: quant-ph

TL;DR: 本文研究了MIMO无线系统中通过自由空间光信道交换密钥的方法，提出了基于弱相干脉冲和诱骗态的单向和双向离散变量量子密钥分发协议框架，分析了光子数分离攻击下的安全密钥率和量子比特错误率。


<details>
  <summary>Details</summary>
Motivation: 在MIMO自由空间光通信系统中实现安全密钥交换，解决量子密钥分发在自由空间信道中的实际应用问题，特别是针对多天线接收器和光子数分离攻击的安全性能分析。

Method: 提出了基于弱相干脉冲和诱骗态的单向和双向DV-QKD协议框架，推导了在光子数分离攻击和多天线阈值检测条件下的安全密钥率和量子比特错误率的数学表达式。

Result: 数值评估表明，更大的MIMO配置能带来性能增益，单向和双向协议在传输距离上存在性能权衡关系。

Conclusion: 该研究为MIMO自由空间光通信系统中的量子密钥分发提供了理论框架和性能分析，展示了MIMO技术和不同QKD协议在自由空间信道中的适用性。

Abstract: This paper considers a multiple-input multiple-output (MIMO) wireless system
wherein two legitimate users attempt to exchange secret keys over free-space
optical (FSO) channels. Novel frameworks for the use of the one- and two-way
discrete-variable quantum key distribution (DV-QKD) protocols, employing weak
coherent pulses and decoy states, are presented. Focusing on the case where a
photon-number-splitting attack is adopted by the eavesdropper and the
legitimate multi-antenna receiver using threshold detection for the key
extraction, novel expressions for the secret key rate and quantum bit error
rate for both one- and two-way protocols are derived. The performance gain with
larger MIMO configurations and the tradeoff between the performances with the
one- and the two-way protocols with respect to the transmission distance of the
legitimate FSO link are numerically assessed.

</details>


### [95] [Optimization of Information Reconciliation for Decoy-State Quantum Key Distribution over a Satellite Downlink Channel](https://arxiv.org/abs/2511.05196)
*Thomas Scarinzi,Davide Orsucci,Marco Ferrari,Luca Barletta*

Main category: quant-ph

TL;DR: 本文研究了卫星量子密钥分发中信息协调步骤的优化，通过建立精确的下行链路信号和量子比特错误率模型，利用瞬时QBER的先验信息提高信息协调效率，在现实场景中使安全密钥长度增加近3%。


<details>
  <summary>Details</summary>
Motivation: 卫星QKD链路持续时间短，只能生成少量安全密钥。为了最大化安全密钥生成量，需要优化信息协调步骤。

Method: 建立包含三个效应（链路几何变化、闪烁效应、诱骗态协议不同信号强度）的完整卫星通过期间下行链路信号和QBER的精确时变模型，利用瞬时QBER先验信息改进Decoy-State BB84协议中的信息协调效率。

Result: 在现实场景中，安全密钥长度增加了近3%。

Conclusion: 通过利用瞬时QBER的先验信息优化信息协调步骤，可以有效提高卫星QKD系统的安全密钥生成效率。

Abstract: Quantum key distribution (QKD) is a cryptographic solution that leverages the
properties of quantum mechanics to be resistant and secure even against an
attacker with unlimited computational power. Satellite-based links are
important in QKD because they can reach distances that the best fiber systems
cannot. However, links between satellites in low Earth orbit (LEO) and ground
stations have a duration of only a few minutes, resulting in the generation of
a small amount of secure keys. In this context, we investigate the optimization
of the information reconciliation step of the QKD post-processing in order to
generate as much secure key as possible. As a first step, we build an accurate
model of the downlink signal and quantum bit error rate (QBER) during a
complete satellite pass, which are time-varying due to three effects: (i) the
varying link geometry over time, (ii) the scintillation effect, and (iii) the
different signal intensities adopted in the Decoy-State protocol. Leveraging
the a-priori information on the instantaneous QBER, we improve the efficiency
of information reconciliation (IR) (i.e., the error correction phase) in the
Decoy-State BB84 protocol, resulting in a secure key that is almost 3\% longer
for realistic scenarios.

</details>


### [96] [Revivals and quantum carpets for the relativistic Schrödinger equation](https://arxiv.org/abs/2511.05200)
*Benoît Zumer,Florent Daem,Alexandre Matzkin*

Main category: quant-ph

TL;DR: 研究相对论性薛定谔方程下无限深势阱中波包动力学，推导解析解并分析波包复兴时间和量子地毯模式，探讨从非相对论到超相对论极限的能级间距统计。


<details>
  <summary>Details</summary>
Motivation: 研究相对论性薛定谔方程在无限深势阱中的波包动力学，因为与标准相对论波动方程不同，该方程在无限深势阱中能获得明确定义的解，这为研究相对论量子动力学提供了独特平台。

Method: 推导相对论性薛定谔方程在无限深势阱中的解析解，构造波包并分析其动力学行为，计算波包复兴时间，绘制量子地毯（时空概率密度图），并分析不同动力学区域的能级间距统计。

Result: 获得了相对论性薛定谔方程在无限深势阱中的明确定义解，发现了波包复兴现象，观察到量子地毯在不同相对论区域呈现不同模式，能级间距统计随相对论参数变化而演变。

Conclusion: 相对论性薛定谔方程为研究无限深势阱中的相对论量子动力学提供了可行的理论框架，其波包动力学和能级统计在从非相对论到超相对论极限的过渡中展现出丰富的物理行为。

Abstract: We investigate wavepacket dynamics for a relativistic particle in a box
evolving according to the relativistic Schr\"odinger (also known as the
Salpeter) equation. We derive the solutions for an infinite well -- which
contrary to the standard relativistic wave equations (such as the Klein-Gordon
or Dirac equations) -- are well defined, and use these solutions to construct
wavepackets. We obtain expressions for the wavepacket revival times and explore
the corresponding quantum carpets (the space-time probability density plots)
for different dynamical regimes. We further analyze level spacing statistics as
the dynamics goes from the non-relativistic regime to the ultra-relativistic
limit.

</details>


### [97] [CUNQA: a Distributed Quantum Computing emulator for HPC](https://arxiv.org/abs/2511.05209)
*Jorge Vázquez-Pérez,Daniel Expósito-Patiño,Marta Losada,Álvaro Carballido,Andrés Gómez,Tomás F. Pena*

Main category: quant-ph

TL;DR: CUNQA是一个用于高性能计算环境的开源分布式量子计算模拟器，支持三种DQC模型（无通信、经典通信和量子通信），使用量子相位估计算法进行演示分析。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机向多量子处理单元架构发展，需要在高性能计算环境中集成量子计算加速器，CUNQA旨在在真实DQC实现之前提供一个测试和评估平台。

Method: 开发了CUNQA开源模拟器，实现三种分布式量子计算模型，包含编程考虑、模拟细节和具体实现，使用量子相位估计算法进行验证。

Result: CUNQA是首个专为HPC环境设计的工具，能够模拟三种DQC方案，为分布式量子计算在高性能计算环境中的研究提供了实验平台。

Conclusion: CUNQA填补了分布式量子计算在高性能计算环境中模拟工具的空白，为未来量子计算架构的发展提供了重要的测试和评估手段。

Abstract: The challenge of scaling quantum computers to gain computational power is
expected to lead to architectures with multiple connected quantum processing
units (QPUs), commonly referred to as Distributed Quantum Computing (DQC). In
parallel, there is a growing momentum toward treating quantum computers as
accelerators, integrating them into the heterogeneous architectures of
high-performance computing (HPC) environments. This work combines these two
foreseeable futures in CUNQA, an open-source DQC emulator designed for HPC
environments that allows testing, evaluating and studying DQC in HPC before it
even becomes real. It implements the three DQC models of no-communication,
classical-communication and quantum-communication; which will be examined in
this work. Addressing programming considerations, explaining emulation and
simulation details, and delving into the specifics of the implementation will
be part of the effort. The well-known Quantum Phase Estimation (QPE) algorithm
is used to demonstrate and analyze the emulation of the models. To the best of
our knowledge, CUNQA is the first tool designed to emulate the three DQC
schemes in an HPC environment.

</details>


### [98] [Revocation and Reconstruction of Shared Quantum States](https://arxiv.org/abs/2511.05212)
*Prakash Mudholkar,Chiranjeevi Vanarasa,Indranil Chakrabarty,Srinathan Kannan*

Main category: quant-ph

TL;DR: 提出了一种量子状态共享后的撤销协议，使用四量子比特纠缠资源，让分发者能够撤销已分享的量子态，防止不诚实的参与者重建状态。


<details>
  <summary>Details</summary>
Motivation: 解决量子状态共享后的撤销问题，防止不诚实的参与者未经授权重建量子态，增强分发者对共享状态的控制能力。

Method: 使用四量子比特纠缠态作为资源，分发者持有两个量子比特，每个参与者各持有一个。在撤销阶段，分发者通过测量操作回收量子态。

Result: 确定了协议成功的参数范围，当两个参与者不诚实并合谋时，他们重建状态的成功概率有限。

Conclusion: 该协议为量子状态共享提供了有效的撤销机制，增强了安全性，特别是在参与者可能不诚实的情况下。

Abstract: The problem of revocation of quantum states after sharing is interesting and
we ask: Is it possible for a dealer to revoke the state once shared, before the
reconstruction process? Additional resources like bell states are used to help
the dealer to get back the state. In a three-party scenario, we show an
independent way to revoke, if, for any reason, the dealer is not sure about the
intention of the/any reconstructor. In general, the classical outcomes of the
dealer in sharing phase are needed, to be able to reconstruct the state
perfectly. When both the shareholders are dishonest, and without the dealer's
knowledge, collude to reconstruct, they always have some chance of succeeding.
This is addressed by giving more control to the dealer by making him/her) to
have a quantum share as well. We give a sharing and revocation protocol with a
four-qubit entangled resource shared among three parties (two qubits with the
dealer and one each with the shareholders). We further consider a class of four
qubit pure entangled states as resource and explicitly find the range of
parameters for which the protocol will be successful.

</details>


### [99] [Scaling behavior of dissipative systems with imaginary gap closing](https://arxiv.org/abs/2511.05220)
*Jinghui Pi,Xingli Li,Yangqian Yan*

Main category: quant-ph

TL;DR: 研究点隙拓扑系统在耗散系统中的量子粒子演化，发现平凡和非平凡点隙系统在虚能隙闭合点处表现出不同的动力学标度行为。


<details>
  <summary>Details</summary>
Motivation: 点隙拓扑（由谱缠绕数表征）对非厄米拓扑相至关重要，并显著改变实时动力学。研究耗散系统中虚能隙闭合对量子粒子演化的影响。

Method: 使用鞍点近似方法研究具有虚能隙闭合的耗散系统中量子粒子的演化。

Result: 平凡点隙系统：虚能隙闭合点也是鞍点，导致局域格林函数呈现单一幂律衰减。非平凡点隙系统：虚能隙闭合点通常不与鞍点重合，导致短时区呈指数衰减，长时区呈幂律衰减包络的双标度行为。

Conclusion: 研究推进了对耗散系统中量子动力学的理解，并为未来实验提供了可检验的预测。

Abstract: Point-gap topology, characterized by spectral winding numbers, is crucial to
non-Hermitian topological phases and dramatically alters real-time dynamics. In
this paper, we study the evolution of quantum particles in dissipative systems
with imaginary gap closing, using the saddle-point approximation method. For
trivial point-gap systems, imaginary gap-closing points can also be saddle
points. This leads to a single power-law decay of the local Green's function,
with the asymptotic scaling behavior determined by the order of these saddle
points. In contrast, for nontrivial point-gap systems, imaginary gap-closing
points do not coincide with saddle points in general. This results in a
dynamical behavior characterized by two different scaling laws for distinct
time regimes. In the short-time regime, the local Green's function is governed
by the dominant saddle points and exhibits an asymptotic exponential decay. In
the long-time regime, however, the dynamics is controlled by imaginary
gap-closing points, leading to a power-law decay envelope. Our findings advance
the understanding of quantum dynamics in dissipative systems and provide
predictions testable in future experiments.

</details>


### [100] [Adaptive Entanglement-Aware Routing for Satellite Quantum Networks under Orbital and Atmospheric Variability](https://arxiv.org/abs/2511.05228)
*Dhrumil Bhatt,Vidushi Kumar*

Main category: quant-ph

TL;DR: 提出了一种自适应纠缠感知路由框架，用于卫星量子网络，综合考虑轨道几何、大气衰减和多参数链路评估，显著提升密钥生成率和纠缠保真度。


<details>
  <summary>Details</summary>
Motivation: 传统路由方案无法适应卫星网络的动态轨道和大气条件变化，需要能够维持纠缠连接的自适应路由机制。

Method: 开发了集成保真度、信任度和密钥率权重的路由度量，通过蒙特卡洛模拟在不同轨道密度和环境条件下进行测试。

Result: 相比现有自适应方法，密钥生成率提升275%，有效纠缠保真度提高15%，路径长度随网络规模呈次线性增长。

Conclusion: 该框架在强衰落条件下保持稳健，为未来全球量子星座网络展示了强大潜力。

Abstract: The expansion of satellite-based quantum networks requires adaptive routing
mechanisms that can sustain entanglement under dynamic orbital and atmospheric
conditions. Conventional schemes, often tailored to static or idealised
topologies, fail to capture the combined effects of orbital motion, fading, and
trust variability in inter-satellite links. This work proposes an
\textit{adaptive entanglement-aware routing framework} that jointly accounts
for orbital geometry, atmospheric attenuation, and multi-parameter link
evaluation. The routing metric integrates fidelity, trust, and key-rate weights
to maintain connectivity and mitigate loss from turbulence and fading. Monte
Carlo simulations across multiple orbital densities ($\rho =
10^{-6}$~km$^{-3}$) and environmental regimes, standard atmosphere, strong
turbulence, and clear-sky LEO show up to a 275\% improvement in key generation
rate and a 15\% increase in effective entanglement fidelity over existing
adaptive methods. The framework achieves sub-linear path-length scaling with
network size and remains robust for fading variances up to
$\sigma_{\mathrm{fade}}=0.1$, demonstrating strong potential for future global
quantum constellations.

</details>


### [101] [A Triple-Hybrid Quantum Support Vector Machine Using Classical, Quantum Gate-based and Quantum Annealing-based Computing](https://arxiv.org/abs/2511.05237)
*Juan C. Boschero,Ward van der Schoot,Niels M. P. Neumann*

Main category: quant-ph

TL;DR: 本文提出了一种三重混合量子支持向量机，结合了门基量子计算、量子退火和经典计算三种计算范式，在复杂量子数据分类任务中实现了比纯量子或经典方法更高的精度和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算机规模有限，不同计算范式各有优劣，需要将算法适配底层计算架构并优化任务分配，以充分发挥量子机器学习的潜力。

Method: 使用门基量子模型实现量子核和复杂特征映射，在量子退火硬件上求解二次无约束优化问题，在经典硬件上评估损失并重新配置模型参数。

Result: 在复杂量子数据上，三重混合量子支持向量机比其他支持向量机（包括量子版和经典版）精度更高，收敛更快，所需电路评估次数更少；在简单经典数据上性能表现不一。

Conclusion: 结合不同计算范式的混合方法在复杂量子数据分类任务中具有优势，能够实现更高的精度和效率。

Abstract: Quantum machine learning is one of the fields where quantum computers are
expected to bring advantages over classical methods. However, the limited size
of current computers restricts the exploitation of the full potential of
quantum machine learning methods. Additionally, different computing paradigms,
both quantum and classical, each have their own strengths and weaknesses.
Obtaining optimal results with algorithms thus requires algorithms to be
tweaked to the underlying computational paradigm, and the tasks to be optimally
distributed over the available computational resources. In this work, we
explore the potential gains from combining different computing paradigms to
solve the complex task of data classification for three different datasets. We
use a gate-based quantum model to implement a quantum kernel and implement a
complex feature map. Next, we formulate a quadratic unconstrained optimisation
problem to be solved on quantum annealing hardware. We then evaluate the losses
on classical hardware and reconfigure the model parameters accordingly. We
tested this so-called triple-hybrid quantum support vector machine on various
data sets, and find that it achieves higher precision than other support vector
machines (both quantum and classical) on complex quantum data, whereas it
achieves varying performance on simple classical data using limited training.
For the complex data sets, the triple-hybrid version converges faster,
requiring fewer circuit evaluations.

</details>


### [102] [A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization](https://arxiv.org/abs/2511.05254)
*Leandro C. Souza,Laurent E. Dardenne,Renato Portugal*

Main category: quant-ph

TL;DR: 提出了一种基于量子门的量子遗传算法(QGA)，用于实值全局优化。该算法将个体表示为量子电路，通过二进制离散化将测量结果解码为实值向量，进化算子直接在电路结构上操作，并展示了叠加和纠缠都能增强量子进化算法的搜索性能。


<details>
  <summary>Details</summary>
Motivation: 探索量子资源（如叠加和纠缠）在进化算法中的优势，建立基于量子门的量子遗传算法框架，实现量子增强的全局优化。

Method: 使用量子电路表示个体，通过测量结果解码为实值向量；在电路结构上直接进行变异和交叉操作；引入固定深度和可变深度变体；通过量子采样评估适应度；比较有无Hadamard门的门集效果；引入个体间纠缠。

Result: 叠加持续改善收敛性和鲁棒性；个体间纠缠加速早期收敛；量子相关性为优化提供额外优势；在Rastrigin函数等基准测试中表现良好。

Conclusion: 叠加和纠缠都能增强量子进化算法的搜索动态，基于量子门的QGA是量子增强全局优化的有前景框架。

Abstract: We propose a gate-based Quantum Genetic Algorithm (QGA) for real-valued
global optimization. In this model, individuals are represented by quantum
circuits whose measurement outcomes are decoded into real-valued vectors
through binary discretization. Evolutionary operators act directly on circuit
structures, allowing mutation and crossover to explore the space of gate-based
encodings. Both fixed-depth and variable-depth variants are introduced,
enabling either uniform circuit complexity or adaptive structural evolution.
Fitness is evaluated through quantum sampling, using the mean decoded output of
measurement outcomes as the argument of the objective function. To isolate the
impact of quantum resources, we compare gate sets with and without the Hadamard
gate, showing that superposition consistently improves convergence and
robustness across benchmark functions such as the Rastrigin function.
Furthermore, we demonstrate that introducing pairwise inter-individual
entanglement in the population accelerates early convergence, revealing that
quantum correlations among individuals provide an additional optimization
advantage. Together, these results show that both superposition and
entanglement enhance the search dynamics of evolutionary quantum algorithms,
establishing gate-based QGAs as a promising framework for quantum-enhanced
global optimization.

</details>


### [103] [Generating functions for quantum metric, Berry curvature, and quantum Fisher information matrix](https://arxiv.org/abs/2511.05260)
*Wei Chen*

Main category: quant-ph

TL;DR: 保真度作为生成函数，可导出量子Fisher信息矩阵和Christoffel符号。纯态时保真度和相位分别生成量子度量和Berry曲率，实波函数系统还原到经典Fisher信息矩阵，建立了量子到信息几何的层次结构。


<details>
  <summary>Details</summary>
Motivation: 探索保真度作为生成函数的几何意义，建立量子几何与信息几何的统一框架，揭示不同层次几何结构的内在联系。

Method: 通过保真度对参数的导数推导量子Fisher信息矩阵和Christoffel符号，分析纯态和实波函数系统的特殊情况，并用Bloch表示和SSH模型验证。

Result: 证明了保真度是量子几何量的生成函数，纯态时保真度和相位分别对应量子度量和Berry曲率，实波函数系统退化为经典Fisher信息矩阵。

Conclusion: 保真度作为生成函数统一了量子几何和信息几何，建立了从量子到经典的几何层次结构，有限温度下量子几何效应会减弱。

Abstract: We elaborate that the fidelity between two density matrices is a generating
function, through which the quantum Fisher information matrix and Christoffel
symbol of the first kind in the parameter space can be obtained through
derivatives with respect to the parameters. For pure states, the fidelity and
phase of the product between two quantum states are shown to be the generating
functions of the quantum metric and Berry curvature, respectively. Further
limiting to systems described by real wave functions, our formalism recovers
the well-known result that the fidelity between two probability mass functions
is the generating function of the classical Fisher information matrix,
indicating a hierarchy of quantum to information geometry. The Bloch
representation of the generating functions is given explicitly for $2\times 2$
density matrices, and the application to canonical ensemble of
Su-Schrieffer-Heeger model suggests the mitigation of quantum geometry at
finite temperature.

</details>


### [104] [Effects of boundary conditions on quantum nanoresonators: decoherence-free subspaces](https://arxiv.org/abs/2511.05264)
*Humberto C. F. Lemos,Thiago Cordeiro,Adelcio C. Oliveira*

Main category: quant-ph

TL;DR: 该论文研究了欧拉-伯努利梁模型的半经典量子化，发现了类似卡西米尔效应的现象，并分析了不同边界条件下简并态形成的退相干自由子空间。


<details>
  <summary>Details</summary>
Motivation: 研究欧拉-伯努利梁模型的半经典量子化，探索其与电磁场量子化的相似性，以及由此产生的类卡西米尔效应和简并态对退相干的影响。

Method: 采用半经典量子化方法，类似于电磁场的量子化过程，分析不同边界条件（特别是铰支-铰支边界条件）下梁模型的量子行为。

Result: 发现了类似光子卡西米尔效应的现象，卡西米尔力与梁体积成反比；铰支-铰支边界条件下存在简并态，这些简并对形成对色散热库的退相干自由子空间；其他边界条件下也存在准简并态形成的低退相干率子空间。

Conclusion: 欧拉-伯努利梁模型的半经典量子化揭示了类卡西米尔效应，不同边界条件下的简并态可以形成退相干自由子空间，这对于量子信息处理具有重要意义。

Abstract: The Euler-Bernoulli beam model has been studied classically and
semi-classically. The semi-classical quantization is done in an analogous way
to the quantization of the electromagnetic field, and we found an effect that
is similar to the Casimir effect, which is the photonic Casimir effect. The
Casimir force, by unit area, is proportional to the first mode energy divided
by the volume of the beam. For the hinged-hinged boundary condition, degenerate
states were found. These degenerate pairs form decoherence-free subspaces for
dispersive thermal reservoirs. For other boundary conditions, there are also
subspaces with lower decoherence rates, which occur for quasi-degenerate
states.

</details>


### [105] [Shallow IQP circuit and graph generation](https://arxiv.org/abs/2511.05267)
*Oriol Balló-Gimbernat,Marcos Arroyo-Sánchez,Paula García-Molina,Adan Garriga,Fernando Vilariño*

Main category: quant-ph

TL;DR: 该论文提出使用浅层瞬时量子多项式时间电路作为生成图模型，通过边-量子比特编码将图映射到量子态上。研究在无噪声模拟和真实量子硬件上验证了该模型学习图结构特征的能力。


<details>
  <summary>Details</summary>
Motivation: 探索在NISQ时代量子硬件上使用浅层量子电路进行图生成建模的可行性，为量子生成模型建立实际性能基准。

Method: 使用边-量子比特编码将图映射到量子态，构建浅层IQP电路作为生成模型。在无噪声模拟中测试28量子比特系统，在IBM Aachen QPU上扩展到153量子比特进行大规模实验。

Result: 无噪声模拟显示模型能学习边密度和二分划分等关键结构特征。真实硬件实验中，局部统计量（如度分布）在28-153量子比特范围内保持准确，全局性质（如严格二分性）在最大系统规模下退化，但谱二分性相对稳健。

Conclusion: 即使没有误差缓解，浅层IQP电路也能在现有量子硬件上学习并重现图数据中有意义的结构模式，为NISQ时代及以后的量子生成建模发展提供指导。

Abstract: We introduce shallow instantaneous quantum polynomial-time (IQP) circuits as
generative graph models, using an edge-qubit encoding to map graphs onto
quantum states. Focusing on bipartite and Erd\H{o}s-R\'enyi distributions, we
study their expressivity and robustness through simulations and large-scale
experiments. Noiseless simulations of $28$ qubits ($8$-node graphs) reveal that
shallow IQP models can learn key structural features, such as the edge density
and bipartite partitioning. On IBM's Aachen QPU, we scale experiments from $28$
to $153$ qubits ($8$-$18$ nodes) in order to characterize performance on real
quantum hardware. Local statistics, such as the degree distributions, remain
accurate across scales with total variation distances ranging from $0.04$ to
$0.20$, while global properties like strict bipartiteness degrade at the
largest system sizes ($91$ and $153$ qubits). Notably, spectral bipartivity, a
relaxation of strict bipartiteness, remains comparatively robust at higher
qubit counts. These results establish practical baselines for the performance
of shallow IQP circuits on current quantum hardware and demonstrate that, even
without error mitigation, such circuits can learn and reproduce meaningful
structural patterns in graph data, guiding future developments in quantum
generative modeling for the NISQ era and beyond.

</details>


### [106] [Variational noise mitigation in quantum circuits: the case of Quantum Fourier Transform](https://arxiv.org/abs/2511.05274)
*Rafael Gómez-Lurbe,Alexander Bernal,Armando Pérez,Bryan Zaldívar,J. Alberto Casas*

Main category: quant-ph

TL;DR: 使用变分量子算法在噪声环境下模拟量子傅里叶变换，通过引入相互无偏基优化，在相干噪声主导的场景中实现了比理论电路更高的保真度。


<details>
  <summary>Details</summary>
Motivation: 在真实噪声条件下超越理论电路的保真度，为中小规模量子系统提供有效的错误缓解策略，特别是在相干噪声严重影响性能的场景中。

Method: 采用变分量子算法模拟量子傅里叶变换，在相干和非相干噪声下进行数值模拟，并引入相互无偏基来增强泛化能力。

Result: 变分电路在相干噪声主导的场景中能够以更高保真度重现量子傅里叶变换。

Conclusion: 该方法展示了作为错误缓解策略的潜力，能够适应特定设备的噪声特性，为近期量子硬件中量子算法的可靠性提供实用路径。

Abstract: We propose using variational quantum algorithms (VQAs) to simulate
established quantum algorithms under realistic noise conditions, aiming to
surpass the fidelity of theoretical circuits in noisy environments. Focusing on
the Quantum Fourier Transform (QFT), we perform numerical simulations for two
qubits under both coherent and incoherent noise. To enhance generalization, we
further introduce the use of Mutually Unbiased Bases (MUBs) during the
optimization. Our results show that the variational circuit can reproduce the
QFT with higher fidelity in scenarios dominated by coherent noise. This
demonstrates the potential of the approach as an effective error-mitigation
strategy for small- to medium-scale quantum systems, particularly in settings
where coherent noise strongly impacts performance. Beyond mitigating noise and
improving fidelity, the method can be adapted to the noise profile of a
specific device, providing a versatile and practical route to enhance the
reliability of quantum algorithms in near-term quantum hardware.

</details>


### [107] [Open quantum-classical systems: A hybrid MASH master equation](https://arxiv.org/abs/2511.05282)
*Kasra Asnaashari,Jeremy O. Richardson*

Main category: quant-ph

TL;DR: 提出了一种将量子-经典映射表面跳跃方法与Lindblad主方程的耗散量子动力学相结合的方法，用于模拟同时耦合到马尔可夫量子浴和非马尔可夫经典自由度的开放量子系统。


<details>
  <summary>Details</summary>
Motivation: 传统表面跳跃方法主要处理封闭量子系统，无法有效处理同时耦合到量子浴和经典自由度的开放量子系统动力学问题。

Method: 结合MASH表面跳跃和Lindblad主方程，使用经典轨迹耦合量子子系统，但用量子轨迹代替薛定谔方程演化，基于secular Redfield理论推导随机量子轨迹。

Result: 在自旋-玻色子模型和腔增强荧光分子系统中，与完全量子力学基准结果表现出极好的一致性。

Conclusion: 该方法能够有效模拟同时耦合到马尔可夫量子浴和非马尔可夫经典自由度的复杂开放量子系统动力学。

Abstract: We propose a method which combines the quantum-classical mapping approach to
surface hopping (MASH) with the dissipative quantum dynamics of the Lindblad
master equation. Like conventional surface-hopping methods, our approach is
based on classical trajectories coupled to the dynamics of a quantum subsystem.
However, instead of evolving the subsystem wavefunction according to the
time-dependent Schr\"odinger equation, we use stochastic quantum trajectories
derived from secular Redfield theory. This enables the simulation of open
quantum systems coupled simultaneously to Markovian quantum baths and
anharmonic non-Markovian classical degrees of freedom. Applications to the
spin-boson model and to the cavity-enhanced fluorescence of an electronically
nonadiabatic molecule show excellent agreement with fully quantum-mechanical
benchmarks.

</details>


### [108] [Quantum non-Markovian Hatano-Nelson model](https://arxiv.org/abs/2511.05328)
*Sumit Kumar Jana,Ryo Hanai,Tan Van Vu,Hisao Hayakawa,Archak Purkayastha*

Main category: quant-ph

TL;DR: 该论文研究了频率相关耗散导致的非马尔可夫非厄米系统，通过非平衡格林函数方法构建了Hatano-Nelson模型的非马尔可夫推广，发现了仅存在于非马尔可夫体系中的单向频率阻塞和非平衡耗散量子相变等独特现象。


<details>
  <summary>Details</summary>
Motivation: 传统非厄米哈密顿量通常假设频率无关的耗散，但实验中的耗散往往是频率相关的，这会导致非马尔可夫行为。本文旨在研究频率相关耗散如何从微观上产生非马尔可夫的非互易系统。

Method: 使用非平衡格林函数方法，在准一维耗散晶格中构建非马尔可夫Hatano-Nelson模型，无需弱系统-浴耦合或时间尺度分离等近似。

Result: 得到的有效系统表现出频率相关的非互易跳跃和均匀耗散。在玻色子体系中发现了单向频率阻塞，在费米子体系中发现了非平衡耗散量子相变，这些现象在马尔可夫理论中无法捕捉，且在互易系统中没有对应物。

Conclusion: 研究结果为描述和设计非马尔可夫非互易量子晶格奠定了基础，揭示了仅存在于非马尔可夫体系中的独特量子现象。

Abstract: While considering non-Hermitian Hamiltonians arising in the presence of
dissipation, in most cases, the dissipation is taken to be frequency
independent. However, this idealization may not always be applicable in
experimental settings, where dissipation can be frequency-dependent. Such
frequency-dependent dissipation leads to non-Markovian behavior. In this work,
we demonstrate how a non-Markovian generalization of the Hatano-Nelson model, a
paradigmatic non-Hermitian system with nonreciprocal hopping, arises
microscopically in a quasi-one-dimensional dissipative lattice. This is
achieved using non-equilibrium Green's functions without requiring any
approximation like weak system-bath coupling or a time-scale separation, which
would have been necessary for a Markovian treatment. The resulting effective
system exhibits nonreciprocal hopping, as well as uniform dissipation, both of
which are frequency-dependent. This holds for both bosonic and fermionic
settings. We find solely non-Markovian nonreciprocal features like
unidirectional frequency blocking in bosonic setting, and a non-equilibrium
dissipative quantum phase transition in fermionic setting, that cannot be
captured in a Markovian theory, nor have any analog in reciprocal systems. Our
results lay the groundwork for describing and engineering non-Markovian
nonreciprocal quantum lattices.

</details>


### [109] [Mapping the positions of Two-Level-Systems on the surface of a superconducting transmon qubit](https://arxiv.org/abs/2511.05365)
*Jürgen Lisenfeld,Alexander K. Händel,Etienne Daum,Benedikt Berlitz,Alexander Bilmes,Alexey V. Ustinov*

Main category: quant-ph

TL;DR: 提出了一种确定transmon量子比特表面TLS位置的方法，通过片上栅极电极产生局部电场来调谐TLS共振频率，发现大多数表面TLS位于约瑟夫森结的引线上。


<details>
  <summary>Details</summary>
Motivation: 超导量子计算机的相干性受到材料缺陷产生的寄生两能级系统(TLS)严重限制，但缺乏对TLS形成位置及其对量子比特电路影响的理解。

Method: 使用片上栅极电极产生局部DC电场调谐TLS共振频率，通过TLS与不同电极的耦合强度结合电场模拟推断TLS位置。

Result: 发现大多数可检测的表面TLS位于约瑟夫森结的引线上，尽管共面电容器对电场能量和表面积贡献更大，表明阴影蒸发电极附近的TLS密度显著增加。

Conclusion: 该方法可用于识别TLS对退相干贡献最大的关键电路区域，指导量子比特设计和制造方法的改进。

Abstract: The coherence of superconducting quantum computers is severely limited by
material defects that create parasitic two-level-systems (TLS). Progress is
complicated by lacking understanding how TLS are created and in which parts of
a qubit circuit they are most detrimental. Here, we present a method to
determine the individual positions of TLS at the surface of a transmon qubit.
We employ a set of on-chip gate electrodes near the qubit to generate local DC
electric fields that are used to tune the TLS' resonance frequencies. The TLS
position is inferred from the strengths at which TLS couple to different
electrodes and comparing them to electric field simulations. We found that the
majority of detectable surface-TLS was residing on the leads of the qubit's
Josephson junction, despite the dominant contribution of its coplanar capacitor
to electric field energy and surface area. This indicates that the TLS density
is significantly enhanced near shadow-evaporated electrodes fabricated by
lift-off techniques. Our method is useful to identify critical circuit regions
where TLS contribute most to decoherence, and can guide improvements in qubit
design and fabrication methods.

</details>


### [110] [Spectroscopy and Coherence of an Excited-State Transition in $\text{Tm}^{3+}:\text{YAlO}_{3}$ at Telecommunication Wavelength](https://arxiv.org/abs/2511.05370)
*Luozhen Li,Akshay Babu Karyath,Mohsen Falamarzi Askarani,Maria Gieysztor,Hridya Meppully Sasidharan,Joshua A. Slater,Sara Marzban,Nir Alfasi,Patrick Remy,Wolfgang Tittel*

Main category: quant-ph

TL;DR: 本文首次在稀土晶体中证明了激发态跃迁的相干性，在2T磁场下测得最大光学相干时间为1.1μs，表明这类激发态跃迁在量子技术中具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究铥掺杂钇铝钙钛矿晶体中1451.37 nm激发态零声子线的光谱和相干特性，探索稀土晶体激发态跃迁在量子技术中的应用可能性。

Method: 在约1.5K温度下测量吸收光谱、非均匀展宽、激发态寿命，通过不同磁场下的光谱烧孔研究超精细和超超精细相互作用，使用光谱烧孔和光学自由感应衰减评估光学相干时间。

Result: 测得3F4-3H4激发态ZPL的非均匀展宽，在2T磁场下获得最大光学相干时间1.1μs，这是首次在稀土晶体中证明激发态跃迁的相干性。

Conclusion: 铥掺杂YAlO3晶体中的激发态零声子线表现出良好的相干特性，为利用这类激发态跃迁开发量子技术提供了可能性。

Abstract: We characterize the spectroscopic and coherence properties of the 1451.37 nm
excited-state zero-phonon line (ZPL) between the $^{3}F_{4}$ and the
$^{3}H_{4}$ manifolds of a thulium-doped yttrium aluminum perovskite
($\text{Tm}^{3+}:\text{YAlO}_{3}$) crystal at temperatures around 1.5 K. We
measure the absorption spectrum between the $^{3}H_{6}$ - $^{3}F_{4}$ and
$^{3}F_{4}$ - $^{3}H_{4}$ manifolds, the inhomogeneous broadening of the
$^{3}F_{4}$ - $^{3}H_{4}$ (excited-state) ZPL, and the lifetimes of the
higher-lying and lower-lying excited states. We also investigate spectral
hole-burning spectra with varying magnetic fields, which provides insight into
hyperfine and superhyperfine interactions. Using again spectral holes but also
optical free induction decays (FIDs), we assess optical coherence times,
finding a maximum of 1.1 $\mu s$ when a 2T magnetic field is applied. Our
results -- the first to demonstrate coherence of an excited-state transition in
a rare-earth crystal -- suggest the possibility of exploiting such transitions
for quantum technology.

</details>


### [111] [Adaptive quantum phase estimation can be better than non-adaptive](https://arxiv.org/abs/2511.05372)
*Noah Linden,Ronald de Wolf*

Main category: quant-ph

TL;DR: 本文证明在特定约束条件下，自适应量子相位估计算法比非自适应算法在U_ϕ使用次数上具有近2倍的优势，并给出了自适应算法的最大优势上界。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计是量子算法中的重要工具，虽然已知在任意或均匀随机相位情况下自适应算法没有优势，但在特定约束条件下探索自适应方法的潜在优势。

Method: 研究具有特定约束条件的相位估计问题，比较自适应和非自适应算法在U_ϕ使用次数上的性能差异。

Result: 在特定约束条件下，自适应算法比非自适应算法在U_ϕ使用次数上具有近2倍的优势，并确定了自适应算法的最大优势上界。

Conclusion: 自适应量子相位估计算法在特定约束条件下确实具有显著优势，这为量子算法设计提供了新的思路。

Abstract: Quantum phase estimation is one of the most important tools in quantum
algorithms. It can be made non-adaptive (meaning all applications of the
unitary $U_\phi$ happen simultaneously) without using more applications of
$U_\phi$, albeit at the expense of using many more qubits. It is also known
that there is no advantage for adaptive algorithms in the case where the phase
that needs to be estimated is arbitrary or is uniformly random. Here we give
examples of a special case of phase estimation, with a promise on the values
that the unknown phase can take, where adaptive methods are provably better
than non-adaptive methods by a factor of nearly 2 in the number of uses of
$U_\phi$. We also prove some upper bounds on the maximum advantage that
adaptive algorithms for phase estimation can achieve over non-adaptive ones.

</details>


### [112] [Strain-engineered nanoscale spin polarization reversal in diamond nitrogen-vacancy centers](https://arxiv.org/abs/2511.05373)
*Zhixian Liu,Jiahao Sun,Ganyu Xu,Bo Yang,Yuhang Guo,Yu Wang,Cunliang Xin,Hongfang Zuo,Mengqi Wang,Ya Wang*

Main category: quant-ph

TL;DR: 本文展示了各向异性晶格应变作为操控固态量子发射器自旋动力学的强大工具，通过高压产生巨大剪切应变梯度，实现了本征自旋极化的完全反转。


<details>
  <summary>Details</summary>
Motivation: 传统腔控制方法对关键非辐射过程访问有限，需要开发新方法来操控固态量子发射器的自旋相关光动力学性能。

Method: 结合光磁光谱学和理论模型，量化了应变诱导的NV中心激发态混合和系间窜越的显著改变，分离了对称性保持和对称性破坏的应变贡献。

Result: 在高压下，巨大剪切应变梯度触发了本征自旋极化的完全反转，将基态布居从$|0\rangle$重定向到$|\pm 1\rangle$流形，并实现了低于120纳米的亚衍射极限空间控制。

Conclusion: 应变工程成为定制量子发射器特性的强大工具，为可编程量子光源、高密度自旋存储和混合量子光子器件开辟了新途径。

Abstract: The ability to control solid-state quantum emitters is fundamental to
advancing quantum technologies. The performance of these systems is
fundamentally governed by their spin-dependent photodynamics, yet conventional
control methods using cavities offer limited access to key non-radiative
processes. Here we demonstrate that anisotropic lattice strain serves as a
powerful tool for manipulating spin dynamics in solid-state systems. Under high
pressure, giant shear strain gradients trigger a complete reversal of the
intrinsic spin polarization, redirecting ground-state population from
$|0\rangle$ to $|\pm 1\rangle$ manifold. We show that this reprogramming arises
from strain-induced mixing of the NV center's excited states and dramatic
alteration of intersystem crossing, which we quantify through a combination of
opto-magnetic spectroscopy and a theoretical model that disentangles
symmetry-preserving and symmetry-breaking strain contributions. Furthermore,
the polarization reversal is spatially mapped with a transition region below
120 nm, illustrating sub-diffraction-limit control. Our work establishes strain
engineering as a powerful tool for tailoring quantum emitter properties,
opening avenues for programmable quantum light sources, high-density spin-based
memory, and hybrid quantum photonic devices.

</details>


### [113] [Quantum advantage from effective $200$-qubit holographic random circuit sampling](https://arxiv.org/abs/2511.05433)
*Bingzhi Zhang,Quntao Zhuang*

Main category: quant-ph

TL;DR: 提出了一种全息随机电路采样算法，通过重复交互和中电路测量显著增加采样复杂度，在仅20个物理量子比特上实现了200个量子比特的有效采样。


<details>
  <summary>Details</summary>
Motivation: 量子计算机有望在某些问题上超越经典计算机，但现有实现往往未充分利用电路深度，限制了可实现的量子优势。随机电路采样是展示量子优势的主要候选方案。

Method: 引入全息随机电路采样算法，利用重复交互和中电路测量来扩展有效采样维度，使采样复杂度随电路深度呈指数增长。

Result: 在IBM量子设备上仅使用20个物理量子比特，实验证明了高达200个量子比特的有效采样，交叉熵基准保真度为0.0593。

Conclusion: 通过结合空间和时间量子资源，为可扩展量子优势开辟了新途径。

Abstract: Quantum computers hold the promise of outperforming classical computers in
solving certain problems. While large-scale quantum algorithms will require
fault-tolerant devices, near-term demonstrations of quantum advantage on
existing devices can provide important milestones. Random circuit sampling has
emerged as a leading candidate for such demonstrations. However, existing
implementations often underutilize circuit depth, limiting the achievable
advantage. We introduce a holographic random circuit sampling algorithm that
substantially increases the sampling complexity by leveraging repeated
interactions and mid-circuit measurements. This approach scales the effective
sampling dimension with the circuit depth, ultimately leading to an exponential
growth in sampling complexity. With merely 20 physical qubits on IBM quantum
devices, we experimentally demonstrate the effective sampling of up to 200
qubits, with a cross-entropy benchmark fidelity of $0.0593$, establishing a new
route to scalable quantum advantage through the combined use of spatial and
temporal quantum resources.

</details>


### [114] [Realization of Thread Level Parallelism on Quantum Devices](https://arxiv.org/abs/2511.05436)
*Keren Li,Zidong Lin,Zheng An,Guanru Feng,Zipeng Wu,Shiyao Hou,Jingen Xiang*

Main category: quant-ph

TL;DR: 提出了一种通过经典链路连接多个独立量子处理单元(QPU)的模块化量子架构，实现了线程级并行化，可在现有硬件上扩展量子计算的逻辑规模。


<details>
  <summary>Details</summary>
Motivation: 解决量子设备规模化挑战，传统方法依赖大规模单芯片或高损耗互连，需要更实用的模块化扩展方案。

Method: 使用经典链路方案将多个独立QPU合并为单一逻辑设备，支持线程级并行；理论证明具有乘积态输入和低秩纠缠层的量子程序可重表达为高效并行形式；在最多16个NMR量子节点集群上实验验证。

Result: 成功将4量子比特GHZ态分区为并行2量子比特子电路，保真度达93.8%；非厄米演化通过截断柯西积分精确再现可观测量；证明经典链路足以扩展量子计算逻辑规模。

Conclusion: 经典链路方案为软件定义、集群化量子加速器提供了一条实验可行的路径，可在现有硬件上实现通用非幺正通道和量子计算规模扩展。

Abstract: Scaling up quantum devices is a central challenge for realizing practical
quantum computation. Modular quantum architectures promise scalability, yet
experiments to date have relied on either $\sim\!10^{3}$-qubit monolithic chips
or fragile interconnects with high loss. Here, we introduce a classical linkage
scheme that merges multiple independent quantum processing units (QPUs) into a
single logical device, enabling thread-level parallelism (TLP). Theoretically,
we show that quantum routines with product-state inputs and low-rank entangling
layers can be re-expressed in an efficient parallelizable form. Experimentally,
we validate this architecture on clusters comprising up to sixteen benchtop
nuclear magnetic resonance (NMR) quantum nodes. A four-qubit
Greenberger-Horne-Zeilinger (GHZ) state is partitioned into parallel two-qubit
subcircuits, achieving a fidelity of $93.8\,\%$ with respect to the ideal
state. A non-Hermitian evolution, implemented via a truncated Cauchy integral
on Hermitian Hamiltonians, reproduces exact observables with high accuracy. Our
results demonstrate that classical links suffice to scale up the logical size
of quantum computations and realize general, non-unitary channels on today's
hardware, opening an experimentally accessible route toward software-defined,
clustered quantum accelerators.

</details>


### [115] [Trade-off between complexity and energy in quantum phase estimation](https://arxiv.org/abs/2511.05458)
*Yukuan Tao,Madalin Guta,Gerardo Adesso*

Main category: quant-ph

TL;DR: 提出了一个分析量子程序复杂性与能耗之间权衡关系的框架，研究量子相位估计协议中信道实现能量与应用次数之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 推动量子技术向更可持续的方向发展，分析量子程序复杂性与能耗之间的相互作用。

Method: 采用顺序量子相位估计协议，通过重复应用量子信道到探测态上，测量结果来估计相位，建立信道实现能量与应用次数之间的权衡关系。

Result: 建立了在达到所需估计精度时，信道实现能量与应用次数之间的权衡关系。

Conclusion: 该分析原理可适用于优化其他量子协议和设备的能耗。

Abstract: Driven by the desire to make quantum technologies more sustainable, in this
work we introduce a framework for analysing the interplay between complexity
and energy cost of quantum procedures. In particular, we study a sequential
quantum phase estimation protocol, where a phase of physical significance is
encoded in a quantum channel. The channel is applied to a probe state
repetitively until the probe is measured and the outcome leads to an estimate
on the phase. We establish a trade-off relation between the implementation
energy of the channel and the number of times it is applied (complexity), while
reaching a desired estimation precision. The principles of our analysis can be
adapted to optimise the energy consumption in other quantum protocols and
devices.

</details>


### [116] [Helios: A 98-qubit trapped-ion quantum computer](https://arxiv.org/abs/2511.05465)
*Anthony Ransford,M. S. Allman,Jake Arkinstall,J. P. Campora III,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Alex Hall,Ali A. Husain,Akhil Isanaka,Colin J. Kennedy,Nikhil Kotibhaskar,Ivaylo S. Madjarov,Karl Mayer,Alistair R. Milne,Annie J. Park,Adam P. Reed,Riley Ancona,Molly P. Andersen,Pablo Andres-Martinez,Will Angenent,Liz Argueta,Benjamin Arkin,Leonardo Ascarrunz,William Baker,Corey Barnes,John Bartolotta,Jordan Berg,Ryan Besand,Bryce Bjork,Matt Blain,Paul Blanchard,Robin Blume-Kohout,Matt Bohn,Agustin Borgna,Daniel Y. Botamanenko,Robert Boutelle,Natalie Brown,Grant T. Buckingham,Nathaniel Q. Burdick,William Cody Burton,Varis Carey,Christopher J. Carron,Joe Chambers,John Children,Victor E. Colussi,Steven Crepinsek,Andrew Cureton,Joe Davies,Daniel Davis,Matthew DeCross,David Deen,Conor Delaney,Davide DelVento,B. J. DeSalvo,Jason Dominy,Ross Duncan,Vanya Eccles,Alec Edgington,Neal Erickson,Stephen Erickson,Christopher T. Ertsgaard,Bruce Evans,Tyler Evans,Maya I. Fabrikant,Andrew Fischer,Cameron Foltz,Michael Foss-Feig,David Francois,Brad Freyberg,Charles Gao,Robert Garay,Jane Garvin,David M. Gaudiosi,Christopher N. Gilbreth,Josh Giles,Erin Glynn,Jeff Graves,Azure Hansen,David Hayes,Lukas Heidemann,Bob Higashi,Tyler Hilbun,Jordan Hines,Ariana Hlavaty,Kyle Hoffman,Ian M. Hoffman,Craig Holliman,Isobel Hooper,Bob Horning,James Hostetter,Daniel Hothem,Jack Houlton,Jared Hout,Ross Hutson,Ryan T. Jacobs,Trent Jacobs,Melf Johannsen,Jacob Johansen,Loren Jones,Sydney Julian,Ryan Jung,Aidan Keay,Todd Klein,Mark Koch,Ryo Kondo,Chang Kong,Asa Kosto,Alan Lawrence,David Liefer,Michelle Lollie,Dominic Lucchetti,Nathan K. Lysne,Christian Lytle,Callum MacPherson,Andrew Malm,Spencer Mather,Brian Mathewson,Daniel Maxwell,Lauren McCaffrey,Hannah McDougall,Robin Mendoza,Michael Mills,Richard Morrison,Louis Narmour,Nhung Nguyen,Lora Nugent,Scott Olson,Daniel Ouellette,Jeremy Parks,Zach Peters,Jessie Petricka,Juan M. Pino,Frank Polito,Matthias Preidl,Gabriel Price,Timothy Proctor,McKinley Pugh,Noah Ratcliff,Daisy Raymondson,Peter Rhodes,Conrad Roman,Craig Roy,Ciaran Ryan-Anderson,Fernando Betanzo Sanchez,George Sangiolo,Tatiana Sawadski,Andrew Schaffer,Peter Schow,Jon Sedlacek,Henry Semenenko,Peter Shevchuk,Susan Shore,Peter Siegfried,Kartik Singhal,Seyon Sivarajah,Thomas Skripka,Lucas Sletten,Ben Spaun,R. Tucker Sprenkle,Paul Stoufer,Mariel Tader,Stephen F. Taylor,Travis H. Thompson,Raanan Tobey,Anh Tran,Tam Tran,Grahame Vittorini,Curtis Volin,Jim Walker,Sam White,Douglas Wilson,Quinn Wolf,Chester Wringe,Kevin Young,Jian Zheng,Kristen Zuraski,Charles H. Baldwin,Alex Chernoguzov,John P. Gaebler,Steven J. Sanders,Brian Neyenhuis,Russell Stutz,Justin G. Bohnet*

Main category: quant-ph

TL;DR: Quantinuum Helios是一款基于QCCD架构的98量子比特离子阱量子处理器，具有全连接性、并行操作和实时编译软件栈，在单量子比特门、双量子比特门以及状态准备和测量方面实现了高保真度，超越了经典模拟能力。


<details>
  <summary>Details</summary>
Motivation: 开发高性能量子处理器以超越经典模拟能力，推动量子计算向实用化发展。

Method: 采用量子电荷耦合器件架构，使用钡-137离子作为超精细量子比特，通过可旋转离子存储环实现全连接性，并行化操作提升速度，配备实时编译动态程序的软件栈。

Result: 单量子比特门平均保真度2.5×10^-5，双量子比特门7.9×10^-4，状态准备和测量4.8×10^-4，在随机Clifford电路和随机电路采样中表现出色，超越了经典模拟能力。

Conclusion: Helios处理器在保真度和复杂度方面建立了新的前沿，展示了量子计算超越经典模拟的潜力。

Abstract: We report on Quantinuum Helios, a 98-qubit trapped-ion quantum processor
based on the quantum charge-coupled device (QCCD) architecture. Helios features
$^{137}$Ba$^{+}$ hyperfine qubits, all-to-all connectivity enabled by a
rotatable ion storage ring connecting two quantum operation regions by a
junction, speed improvements from parallelized operations, and a new software
stack with real-time compilation of dynamic programs. Averaged over all
operational zones in the system, we achieve average infidelities of
$2.5(1)\times10^{-5}$ for single-qubit gates, $7.9(2)\times10^{-4}$ for
two-qubit gates, and $4.8(6)\times10^{-4}$ for state preparation and
measurement, none of which are fundamentally limited and likely able to be
improved. These component infidelities are predictive of system-level
performance in both random Clifford circuits and random circuit sampling, the
latter demonstrating that Helios operates well beyond the reach of classical
simulation and establishes a new frontier of fidelity and complexity for
quantum computers.

</details>


### [117] [Further improvements to stabilizer simulation theory: classical rewriting of CSS-preserving stabilizer circuits, quadratic form expansions of stabilizer operations, and framed hidden variable models](https://arxiv.org/abs/2511.05478)
*Vsevolod I. Yashin,Evgeniy O. Kiktenko,Vladimir V. Yatsulevich,Aleksey K. Fedorov*

Main category: quant-ph

TL;DR: 本文提出了一种新的方法来模拟CSS保持稳定器电路，通过将其重写为经典概率电路来避免计算开销，并建立了参考框架理论来解释非CSS保持电路的计算开销来源。


<details>
  <summary>Details</summary>
Motivation: 尽管稳定器电路的模拟已有优化算法，但作者认为可以从稳定器操作的理论结构本身获得进一步改进，特别是针对CSS保持稳定器操作这一在容错计算中自然出现的子类。

Method: 使用基本电路变换技术将CSS保持稳定器电路精确重写为经典概率电路；引入标准二次型表示来描述一般稳定器操作；建立多量子比特系统的参考框架理论。

Result: CSS保持稳定器电路可以无计算开销地重写为经典概率电路，而非CSS保持电路需要动态修改参考框架，这体现了上下文性资源并导致计算开销。

Conclusion: 该框架为在动态演化的准概率模型中模拟稳定器和近稳定器电路提供了新视角，揭示了CSS保持操作的特殊简化性质及其与非CSS保持操作的根本区别。

Abstract: Simulation of stabilizer circuits is a well-studied problem in quantum
information processing, with a number of highly optimized algorithms available.
Yet, we argue that further improvements can arise from the theoretical
structure of stabilizer operations themselves. We focus on the subclass of
stabilizer circuits composed of Calderbank-Shor-Steane (CSS)-preserving
stabilizer operations, which naturally appear in fault-tolerant computations
over CSS stabilizer codes. Using elementary circuit-transformation techniques,
we show that such circuits can be exactly rewritten as classical probabilistic
circuits that reproduce measurement statistics. This rewriting introduces no
computational overhead, in contrast to the general case of stabilizer circuits.
To clarify the origin of this simplification, we introduce the standard
quadratic-form representation of general stabilizer operations (Clifford
channels). It provides an efficient way to describe compositions of stabilizer
operations and thus to simulate stabilizer circuits. CSS-preserving operations
correspond to purely linear forms, which under a Walsh-Hadamard-Fourier
transform yield a noncontextual hidden variable model, providing an alternative
proof of the introduced rewriting. Finally, we develop a theory of reference
frames for multiqubit systems, where frames are encoded by quadratic forms.
This allows us to express stabilizer operations as probabilistic maps for
proper reference frames. Non-CSS-preserving stabilizer circuits require
dynamical modifications of reference frames, embodying a contextuality resource
that leads to the computational overhead. This framework provides a new
perspective on simulating stabilizer and near-stabilizer circuits within
dynamically evolving quasiprobability models.

</details>


### [118] [Quantum Tensor Representation via Circuit Partitioning and Reintegration](https://arxiv.org/abs/2511.05492)
*Ziqing Guo,Jan Balewski,Kewen Xiao,Ziwen Pan*

Main category: quant-ph

TL;DR: 提出了shardQ方法，结合SparseCut算法、矩阵乘积状态编译和全局编织技术，用于优化量子电路切割和重组，在计算时间和错误率之间找到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 当前量子电路切割和重组技术主要关注模拟框架，但支持算法和非全连接硬件拓扑的协议开发不足，特别是对于紧凑受控酉门切割和硬件拓扑的复杂特性。

Method: 使用SparseCut算法结合矩阵乘积状态编译和全局编织技术，通过理论证明和IBM Marrakesh超导量子处理器的消融分析来验证方法。

Result: 阐明了量子编码中计算时间和错误率之间的最优权衡，并展示了应用准备度的结果。

Conclusion: shardQ方法在量子电路切割和重组方面提供了有效的解决方案，能够适应当前噪声量子处理器的限制。

Abstract: Quantum computing enables faster computations than clas-sical algorithms
through superposition and entanglement. Circuit cutting and knitting are
effective techniques for ame-liorating current noisy quantum processing unit
(QPUs) er-rors via a divide-and-conquer approach that splits quantum circuits
into subcircuits and recombines them using classical post-processing. The
development of circuit partitioning and recomposing has focused on tailoring
the simulation frame-work by replacing generic non-local gates with
probabilistic local gates and measuring the classical communication
com-plexity. Designing a protocol that supports algorithms and non-all-to-all
qubit-connected physical hardware remains underdeveloped owing to the
convoluted properties of cut-ting compact controlled unitary gates and hardware
topology. In this study, we introduce shardQ, a method that leverages the
SparseCut algorithm with matrix product state (MPS) compilation and a global
knitting technique. This method elucidates the optimal trade-off between the
computational time and error rate for quantum encoding with a theoretical
proof, evidenced by an ablation analysis using an IBM Mar-rakesh
superconducting-type QPU. This study also presents the results regarding
application readiness.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [119] [Accelerating metamaterial topology optimization using deep super-resolution networks](https://arxiv.org/abs/2511.04795)
*Ajendra Singh,Shubham Saurabh,Abhinav Gupta,Rajib Chowdhury*

Main category: physics.comp-ph

TL;DR: 提出了一种基于增强深度超分辨率(EDSR)的深度学习框架，用于超材料拓扑优化，能够从低分辨率拓扑预测高分辨率拓扑，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化在大参数空间中寻找最优设计参数需要大量计算资源，需要一种更高效的方法。

Method: 使用EDSR网络学习低分辨率和高分辨率超材料拓扑之间的映射关系，训练数据集通过SIMP拓扑优化生成。

Result: 框架能够从48×48低分辨率拓扑预测192×192高分辨率拓扑，计算成本仅为传统方法的5-7%，且能生成适合3D打印的平滑高分辨率拓扑。

Conclusion: 该方法为多学科超材料设计提供了可扩展且高效的解决方案。

Abstract: Designing metamaterials for extreme mechanical behavior involves the optimal
selection of design parameters. However, identifying these optimal parameters
through topology optimization (TO) across a large parametric space requires
extensive computational resources. To address this challenge, we propose a
novel deep learning framework for metamaterial topology optimization using an
enhanced deep super-resolution (EDSR) approach. Generating low-resolution
topologies significantly reduces computational cost compared to high-resolution
designs. Therefore, an EDSR network is trained to learn the mapping between
low- and high-resolution metamaterial topologies. The training dataset is
generated using solid isotropic material with penalization (SIMP)-based TO. We
demonstrate the proposed approach for the design of mechanical metamaterials
targeting objectives such as maximization of bulk modulus, shear modulus, and
elastic modulus, and minimization of Poisson's ratio. Quantitative assessments
-including (i) pixel value error, (ii) objective function error, (iii)
intersection over union, and (iv) volume fraction error -validate the accuracy
of the EDSR-based TO. Our framework predicts high-resolution topologies of size
$192 \times 192$ from optimized low-resolution topologies of size $48 \times
48$. Once trained, the proposed network predicts these high-resolution
topologies with only $5-7\%$ of the computational cost required by conventional
SIMP-based TO at the same resolution. Moreover, by adding upscale blocks, the
framework can generate smoother, higher-resolution topologies suitable for 3D
printing. This approach offers a scalable and efficient solution with strong
potential for multidisciplinary metamaterial design applications.

</details>


### [120] [Structure Matters: A Scale-Resolved Numerical Operando Approach for Lithium-Sulfur Batteries](https://arxiv.org/abs/2511.05233)
*Max Okraschevski,Torben Prill,Paul Maidl,Arnulf Latz,Timo Danner*

Main category: physics.comp-ph

TL;DR: 提出了一种基于高性能计算的尺度解析模拟方法，用于研究锂硫电池多孔阴极结构对倍率性能的影响。


<details>
  <summary>Details</summary>
Motivation: 锂硫电池具有高能量密度但在航空航天应用中受限于倍率性能差和功率输出低的问题，特别是多孔阴极结构对放电倍率性能的影响需要深入研究。

Method: 采用粗粒度连续介质模型，通过间断伽辽金方法进行空间离散，结合自适应控制器进行时间推进的高性能计算模拟方法。

Result: 开发了一个能够提供实验难以获取的电化学电池行为结构洞察的数值原位模拟工具箱。

Conclusion: 该工作流程展示了改进锂硫电池性能的能力，为理解多孔阴极结构与倍率性能关系提供了新工具。

Abstract: Lithium-Sulfur batteries (LSBs) are believed to have a high potential for
aerospace applications due to their high gravimetric energy density. However,
despite decades of research and advances, they still suffer from poor rate
capability and low power output, eventually preventing their practical
implementation. One particular aspect we want to shed light on is the influence
of the porous cathode structure on the rate performance during discharge.
Therefore, we present a scale-resolved simulation methodology that aims to
provide structural insights into the electrochemical cell behavior that are
experimentally hardly accessible even for modern operando methods. Our
numerical operando approach employs high-performance computing (HPC) and is
based on a coarse-grained continuum model. The latter is spatially discretized
with a Discontinuous Galerkin (DG) method and advanced in time by an adaptive
controller. The models and methods as well as HPC aspects of our toolbox will
be critically discussed, finally showcasing the capabilities of our workflow to
improve LSBs.

</details>


### [121] [Impact of higher-order exchange on the lifetime of skyrmions and antiskyrmions](https://arxiv.org/abs/2511.05278)
*Hendrik Schrautzer,Moritz A. Goerzen,Bjarne Beyer,Soumyajyoti Haldar,Pavel F. Bessarab,Stefan Heinze*

Main category: physics.comp-ph

TL;DR: 通过包含四阶交换项的原子自旋模型计算斯格明子和反斯格明子的寿命，发现高阶交换能显著增强其热稳定性，甚至在没有DMI的情况下也能保持稳定。


<details>
  <summary>Details</summary>
Motivation: 实现斯格明子器件的关键在于可靠控制其寿命，但高阶交换在斯格明子稳定化中的作用尚未充分探索。

Method: 基于包含所有四阶交换项的原子自旋模型，采用谐波过渡态理论评估能量和熵贡献。

Result: 高阶交换显著增强寿命，四自旋四位置相互作用提高能垒并降低能量景观曲率，使预指数因子增加。斯格明子和反斯格明子即使没有DMI也能保持热稳定。

Conclusion: 高阶交换是稳定拓扑磁纹理的有前景途径，特别是在缺乏DMI的系统中，并能调控其热激活衰变。

Abstract: Reliable control of skyrmion lifetime is essential for realizing spintronic
devices, yet the role of higher-order exchange - which can lead to skyrmion
stabilization - remains largely unexplored. Here we calculate lifetimes of
isolated skyrmions and antiskyrmions at transition-metal interfaces based on an
atomistic spin model that includes all fourth-order exchange terms. Within
harmonic transition-state theory, we evaluate both energetic and entropic
contributions and find substantially enhanced lifetimes when higher-order
exchange is included. The four-spin four-site interaction raises the energy
barrier and lowers the curvature of the energy landscape at the collapse saddle
point, increasing the pre-exponential factor. We show that skyrmions and
antiskyrmions can remain thermally stable even without Dzyaloshinskii-Moriya
interaction (DMI), and that tuning the four-spin term by a small amount
modulates the prefactor over orders of magnitude. Our results identify
higher-order exchange as a promising route to stabilize topological magnetic
textures - in particular in systems lacking DMI - and to engineer their
thermally activated decay.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [122] [Non-Interacting New Agegraphic Dark Energy Model in $f(Q)$ Gravity](https://arxiv.org/abs/2511.04717)
*M. Sharif,Madiha Ajmal*

Main category: gr-qc

TL;DR: 在平坦FRW时空中通过f(Q)引力框架重建新的年龄图暗能量模型，其中Q表示非度量性。假设尺度因子遵循幂律，分析该模型如何与宇宙膨胀一致。


<details>
  <summary>Details</summary>
Motivation: 探索在f(Q)引力框架下重建新的年龄图暗能量模型，研究其与宇宙膨胀的对应关系，解决宇宙巧合问题。

Method: 假设尺度因子为幂律形式，在f(Q)引力框架下开发新的年龄图暗能量模型，分析状态方程参数、(ωD-ω′D)平面和(r-s)平面的图形行为，评估平方声速来检查非相互作用模型的稳定性。

Result: 状态方程参数表明存在加速膨胀的quintessence时期，(ωD-ω′D)平面识别冻结区域，(r-s)平面表示Chaplygin气体模型。非相互作用的新年龄图暗能量模型有效解决了宇宙巧合问题。

Conclusion: 在f(Q)引力框架下构建的新年龄图暗能量模型能够很好地描述宇宙演化，成功解决了宇宙巧合问题，模型表现出稳定的物理特性。

Abstract: In this study, we explore the reconstruction of a new agegraphic dark energy
model in a flat Friedmann-Robertson-Walker spacetime by $f(Q)$ gravity
framework, where $Q$ represents non-metricity. We assume that the scale factor
follows a power-law and explore how this model aligns with the expanding
universe. In this perspective, we develop a new agegraphic $f(Q)$ model and
analyze the graphical behavior for cosmic evolution. We analyze physical
characteristics of the model using the equation of state parameter,
$(\omega_{D}-\omega^{\prime}_{D})$ and the $(r-s)$ planes. The equation of
state parameter indicates a quintessence era characterized by accelerated
expansion. The $(\omega_{D}-\omega^{\prime}_{D})$-plane identifies the freezing
region and the Chaplygin gas model is represented in the $(r-s)$-plane.
Finally, we examine the stability of the non-interacting model by evaluating
the squared speed of sound. Our findings show that the non-interacting new
agegraphic dark energy model effectively resolves the cosmic coincidence
problem.

</details>


### [123] [A-BHPT-toolkit: Analytic Black Hole Perturbation Theory Package for Gravitational Scattering Amplitudes](https://arxiv.org/abs/2511.04765)
*Jovan Markovic,Mikhail M. Ivanov*

Main category: gr-qc

TL;DR: 开发了首个公开软件包，用于在MST框架下计算黑洞微扰理论中的引力散射振幅，支持低频率极限下的解析计算和任意频率的精确数值计算。


<details>
  <summary>Details</summary>
Motivation: 有效场论和散射振幅在引力问题中的应用需要与广义相对论精确表达式进行比较，但这些表达式难以获得，因为需要复杂的Teukolsky主方程求解技术。

Method: 基于Mano-Suzuki-Takasugi (MST)方法开发软件包，支持后Minkowskian (PM)阶次的解析计算和任意频率的精确数值计算。

Result: 计算了质量为零的自旋0、1、2场在旋转Kerr黑洞散射中的相移和非弹性参数，并与精确数值解进行了比较。

Conclusion: 该软件包为引力散射振幅计算提供了首个公开工具，填补了黑洞微扰理论计算工具的空缺。

Abstract: Applications of effective field theory (EFT) and scattering amplitudes to
gravitational problems have recently produced many unique results that advanced
our understanding of the dynamics of compact binaries. Many of these results
were made possible by comparing gravitational scattering amplitudes in EFT with
exact expressions from general relativity. However, the latter expressions are
not easily available as they require intricate solution techniques for the
Teukolsky master equation, such as the Mano-Suzuki-Takasugi (MST) method. In
this paper, we develop and present the first public package that enables
computations of gravitational scattering amplitudes in black hole perturbation
theory within the MST framework. Our package supports both analytic
computations to a given post-Minkowskian (PM) order in the low-frequency limit
and exact numerical computations for an arbitrary frequency of the perturbing
field. As an application, we compute scattering phase shifts and inelasticity
parameters for massless spin - 0, 1, and 2 fields resulting from scattering off
a rotating Kerr black hole through the third PM order and compare these results
with the exact numerical solutions.

</details>


### [124] [A novel class of rotating black holes with non-aligned electromagnetic field](https://arxiv.org/abs/2511.04840)
*Hryhorii Ovcharenko,Jiri Podolsky*

Main category: gr-qc

TL;DR: 提出了爱因斯坦-麦克斯韦方程的一类新型膨胀扭曲解，其中法拉第张量的零特征方向不与外尔张量的主零方向对齐。该解包含六个物理参数，涵盖质量、扭曲、电荷、加速度等，并能退化到已知特例。


<details>
  <summary>Details</summary>
Motivation: 寻找爱因斯坦-麦克斯韦方程的新解，特别是那些法拉第张量零特征方向与外尔张量主零方向不对齐的情况，以扩展已知解的类型。

Method: 推导了代数类型D的爱因斯坦-麦克斯韦方程的新解，探索了不同的度规形式和参数化方法，使用六个物理参数来描述解的特性。

Result: 成功获得了一类新的膨胀扭曲解，该解能退化到Kerr-Newman黑洞等已知特例，并在静态极限下还原为先前已知的情况。

Conclusion: 提出的新解丰富了爱因斯坦-麦克斯韦方程的解空间，提供了更一般的参数化框架，有助于深入理解带电旋转黑洞等物理系统的性质。

Abstract: We present a new class of expanding and twisting solutions to the
Einstein-Maxwell equations of algebraic type D, where the null eigendirections
of the Faraday tensor are not aligned with PNDs of the Weyl tensor. After
deriving this novel solution, we explore its various metric forms and
parameterizations. In suitable coordinates, the solution depends on six
physical parameters, namely mass $m$, Kerr and NUT twist parameters $a$ and
$l$, complex charge $c$, acceleration $\alpha$, and parameter $\beta$ that
governs the interplay between electric and magnetic charges in the aligned part
of the Faraday tensor. This parameterization, as the Griffiths-Podolsk\'{y}
form of the Pleba\'{n}ski-Demia\'{n}ski solution, facilitates explicit special
subcases, such as Kerr-Newman black holes, and a deeper physical
interpretation. Additionally, in the static limit, our solution reduces to
previously known cases.

</details>


### [125] [Novel Solar System Probes for Primordial Black Holes](https://arxiv.org/abs/2511.04895)
*Oem Trivedi,Abraham Loeb*

Main category: gr-qc

TL;DR: 提出了两种新颖的太阳系尺度搜索方法，用于探测原始黑洞：通过脉冲星计时阵列检测小行星到矮行星质量PBH的偶极时序特征，以及通过KBO相互作用检测行星质量PBH的ADAF吸积耀斑。


<details>
  <summary>Details</summary>
Motivation: 原始黑洞是解决暗物质问题的有趣途径，位于宇宙学和量子引力的交叉点。目前缺乏对某些质量范围的PBH约束，而太阳系尺度观测具有独特的精度和覆盖范围优势。

Method: 1. 利用脉冲星计时阵列检测小行星到矮行星质量PBH产生的偶极时序信号；2. 通过Kuiper Belt天体与行星质量PBH相互作用产生的ADAF吸积耀斑进行探测。

Result: 这两种互补方法能够探测到传统宇宙学方法无法约束的质量范围内的PBH，为PBH探测开辟了新的观测前沿。

Conclusion: 太阳系尺度的观测方法为探测原始黑洞提供了新的途径，能够填补现有探测方法在特定质量范围内的空白。

Abstract: Primordial Black Holes (PBHs) represent one of the more interesting ways to
address dark matter, at the interface of both cosmology and quantum gravity. It
is no surprise then that testing PBHs is a venue of active interest, with
several cosmological and astrophysical probes constraining different mass
ranges. In this work, we propose novel Solar System scale searches for PBHs,
motivated by the unique precision and coverage of local observables. We show
that asteroid to dwarf planet mass PBHs can induce measurable dipolar timing
signatures in pulsar timing arrays, while planetary mass PBHs can generate
detectable ADAF accretion flares through interactions with Kuiper Belt bodies.
Together, these complementary approaches open a new observational frontier for
probing PBHs across mass ranges that remain unconstrained by conventional
cosmological methods.

</details>


### [126] [The thermal view of singularity-free scalar-tensor spacetimes](https://arxiv.org/abs/2511.04941)
*Valerio Faraoni,Nikki Veilleux*

Main category: gr-qc

TL;DR: 分析Brans-Dicke理论中的Pimentel解，探索广义相对论作为标量-张量引力零温度状态的新热力学观点，揭示了新的物理现象和广义相对论的反常极限。


<details>
  <summary>Details</summary>
Motivation: 研究标量-张量引力理论的热力学解释，特别是将广义相对论视为零温度平衡状态的新观点，探索Pimentel解中未发现的物理现象。

Method: 分析Brans-Dicke理论中的两参数非均匀时变Pimentel解，研究参数变化时的物理行为，讨论其向广义相对论的极限过程。

Result: 发现了以前在其他精确解中未观察到的物理现象，揭示了Pimentel几何向广义相对论的反常极限，并表明Mars解是其爱因斯坦框架版本。

Conclusion: Pimentel解展现了标量-张量引力理论中丰富的新物理现象，支持了广义相对论作为零温度状态的热力学观点，为理解引力理论提供了新视角。

Abstract: The two-parameter inhomogeneous and time-dependent Pimentel solution of
Brans-Dicke theory is analyzed to probe the new thermal view in which General
Relativity is the zero-temperature (equilibrium) state of scalar-tensor
gravity. As the parameters vary, we uncover phenomenology not found before with
other exact solutions, nor contemplated thus far in the general theory. In the
process, we also discuss the anomalous limit to General Relativity of the
Pimentel geometry and show how the Mars solution of the Einstein equations is
its Einstein frame version.

</details>


### [127] [Inflation and de Sitter conjectures in 8-dimensional $R+γR^n$ Gravity](https://arxiv.org/abs/2511.05138)
*Hai Dang Nguyen,Hoang Nam Cao*

Main category: gr-qc

TL;DR: 研究8维修正引力(R+γR^n)中的单场和双场势能，计算暴胀观测参数并与实验数据比较，验证模型正确性，同时用德西特猜想检验理论是否属于量子引力景观。


<details>
  <summary>Details</summary>
Motivation: 验证修正引力理论在8维空间中的暴胀模型是否符合观测数据，并探讨这些理论是否属于量子引力景观的可行候选者。

Method: 从8维修正引力(R+γR^n)推导单场和双场势能，计算标张比、谱指数、跑动指数和标量振幅四个暴胀观测参数，与实验数据对比验证。

Result: 通过计算暴胀观测参数并与实验数据比较，验证了模型的正确性，同时用德西特猜想检验了理论在量子引力景观中的可能性。

Conclusion: 8维修正引力中的单场和双场势能模型能够产生符合观测的暴胀参数，且可能属于量子引力景观的可行理论。

Abstract: In this work, we study two potentials, the single-field and the two-field,
from the modified ($R+\gamma R^n$) gravity in D=8 dimensions. From those
potentials, we calculate four observable quantities in inflation, including
scalar-to-tensor ratio, spectral index, running index and scalar amplitude.
Then, we compare them to the experimental data to verify the righteousness of
the models. Last but not least, de Sitter conjectures are brought up with these
two potentials to investigate that it is possible or not the theory lay in the
Landscape of quantum gravity.

</details>


### [128] [The tidal response of a relativistic star](https://arxiv.org/abs/2511.05139)
*Nils Andersson,Rhys Counsell,Fabian Gittins,Suprovo Ghosh*

Main category: gr-qc

TL;DR: 开发了一种完全相对论的方法来确定致密恒星的频率相关潮汐响应，通过匹配恒星内部线性化流体动力学解与近区时空扰动，识别潮汐驱动和恒星响应。


<details>
  <summary>Details</summary>
Motivation: 解决相对论潮汐模型发展中的障碍，特别是在不涉及恒星准正则模式求和的情况下准确识别潮汐响应。

Method: 将恒星内部线性化流体动力学解与近区时空扰动匹配，识别潮汐驱动和恒星响应，并在牛顿引力下精确验证，在相对论情况下提供强有力证据。

Result: 为BSk家族的现实物质状态方程提供了原理性数值结果，包括导致低频重力模式存在的成分分层。

Conclusion: 该方法绕过了恒星准正态模式求和的障碍，为相对论潮汐模型的发展提供了可行途径，并与场论启发的方法建立了联系。

Abstract: We develop a fully relativistic approach for determining the
frequency-dependent tidal response of a compact star. The strategy involves
matching the solution for the linearised fluid dynamics in the star's interior
to the spacetime perturbations in the near-zone surrounding the body, along
with an identification of the tidal driving and the star's response. Notably,
this identification is exact in Newtonian gravity and we provide strong
evidence that it remains robust also in the relativistic case. The argument
does not involve a sum over the star's quasinormal modes and hence circumvents
one of the obstacles that have held up the development of models for
relativistic tides. Numerical results are provided, at the proof-of-principle
level, for a realistic matter equation of state from the BSk family, including
composition stratification leading to the presence of low-frequency gravity
modes. We also sketch the connection with the field-theory inspired approach to
the problem, in which the tidal response is expressed in terms of asymptotic
scattering amplitudes.

</details>


### [129] [Cosmological perturbations in Energy-Momentum Squared Gravity](https://arxiv.org/abs/2511.05166)
*Peter K. S. Dunsby,Maria-Alexia Caldis,Eduardo Bittencourt*

Main category: gr-qc

TL;DR: 对能量-动量平方引力中的线性宇宙学扰动进行完全协变和规范不变分析，推导了FLRW背景上标量、矢量和张量模式的传播方程，发现与广义相对论相比，密度对比度可能增强或减弱，并识别了可观测的引力理论特征。


<details>
  <summary>Details</summary>
Motivation: 研究能量-动量平方引力理论中的宇宙学扰动，探索该理论相对于广义相对论在早期宇宙演化中的差异，为通过CMB和大尺度结构观测约束这类引力理论提供理论基础。

Method: 采用1+3形式体系，在FLRW背景下推导标量、矢量和张量模式的精确传播方程，分析辐射和尘埃情况下的两个代表性子类，其中非线性通过O(ηρ²)修正或状态方程参数和声速的修改引入。

Result: 标量扰动的密度对比度相对于广义相对论可能增强或减弱，取决于耦合参数和波长区域；矢量模式允许早期存在非平凡涡度；张量模式以阻尼波形式传播，具有缓慢变化的有效质量；所有模式在η→0时连续回归到广义相对论极限。

Conclusion: 该框架识别了稳健的特征信号——早期标量倾斜、张量阻尼偏移和改变的涡度衰减，这些特征可通过CMB和大尺度结构观测来约束能量-动量平方引力理论。

Abstract: We present a fully covariant and gauge-invariant analysis of linear
cosmological perturbations in Energy-Momentum Squared Gravity. Working within
the 1+3 formalism, we derive the exact propagation equations for scalar,
vector, and tensor modes on FLRW backgrounds, in the case of radiation and
dust. Two representative subclasses are examined in detail, in which
non-linearity enters through $\mathcal{O}(\eta\rho^2)$ corrections or
modifications in the equation-of-state parameter and the sound speed. For
scalar perturbations, the density contrast can be enhanced or reduced relative
to General Relativity, depending on the coupling parameter and the wavelength
regime. A similar behaviour occurs for vector modes, allowing for a non-trivial
vorticity at early-times. Tensor modes, described by the magnetic part of the
Weyl tensor and the shear tensor propagate as damped waves with slowly varying
effective masses. All sectors reduce continuously to their GR limits as
$\eta\!\to\!0$. The framework isolates robust signatures - early-time scalar
tilts, tensor damping shifts, and altered vorticity decay - that can be
confronted with CMB and large-scale-structure observations to constrain these
theories of gravity.

</details>


### [130] [Poissonian Analysis of Glitches Observed in the LIGO Gravitational Wave Interferometers](https://arxiv.org/abs/2511.05244)
*Giovanna Souza Rodrigues Costa,Julio Cesar Martins,Odylio Denys Aguiar*

Main category: gr-qc

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This work investigates the temporal distribution of glitches detected by
LIGO, focusing on the morphological classification provided by the Gravity Spy
project. Starting from the hypothesis that these events follow a Poisson
process, we developed a statistical methodology to evaluate the agreement
between the empirical distribution of glitches and an ideal Poisson model,
using the coefficient of determination ($R^2$) as the main metric. The analysis
was applied to real data from the LIGO detectors in Livingston and Hanford
throughout the O3 run, as well as to synthetic datasets generated from pure
Poisson distributions. The results show that while several morphologies exhibit
good agreement with the proposed model, classes such as 1400Ripples, Fast
Scattering, and Power Line display significant deviations ($R^2 \leq 0.6$),
suggesting that their origins do not strictly follow Poissonian statistics. In
some cases, a dependence on the detector or the observing run was also
observed. This analysis provides a quantitative basis for distinguishing glitch
classes based on their degree of "Poissonness", potentially supporting the
development of more effective glitch mitigation strategies in gravitational
wave detector data.

</details>


### [131] [Born-Infeld Electrogravity and Dyonic Black Holes](https://arxiv.org/abs/2511.05273)
*Guadalupe Ahumada Acuña,Cecilia Bejarano,Rafael Ferraro*

Main category: gr-qc

TL;DR: Born-Infeld电引力理论将引力和电磁学耦合在单一行列式结构中，通过Palatini形式推导场方程。引力部分简化为爱因斯坦方程，电动力学部分有两种等效解释。球对称双荷解分析显示该理论软化但不消除曲率发散，测地线不完备性仍然存在。


<details>
  <summary>Details</summary>
Motivation: 研究Born-Infeld电引力理论，将引力和电磁学统一在单一行列式结构中，探索这种耦合对时空几何和场方程的影响。

Method: 使用Palatini形式主义，独立变分度量、联络和矢量势，推导场方程。分析球对称双荷解的视界结构和极值条件。

Result: 引力部分简化为爱因斯坦方程，电动力学有两种等效解释。与Reissner-Nordström几何比较显示，Born-Infeld电引力软化了曲率发散但不消除，测地线不完备性仍然存在。

Conclusion: Born-Infeld电引力理论虽然软化了曲率奇异性，但未能完全解决时空奇点问题，测地线不完备性仍然存在。

Abstract: Born-Infeld electrogravity is defined through a Lagrangian that couples
gravity and electromagnetism within a single determinantal structure. The field
equations are derived in Palatini's formalism, where the metric, connection,
and vector potential are varied independently in the action. As a result, the
gravitational sector reduces to Einstein's equations with a torsion-free,
metric-compatible connection. The electrodynamic sector, in turn, admits two
equivalent interpretations or $pictures$: it can be seen either as a standard
Born-Infeld electrodynamics in an effective background geometry, or as an
$anomalous$ Born-Infeld electrodynamics in the physical metric. We illustrate
the dynamics by analyzing the horizon structure and extremality conditions of
spherically symmetric dyonic solutions. A comparison with the
Reissner-Nordstr\"{o}m geometry shows that Born-Infeld electrogravity softens
but does not eliminate curvature divergences, and geodesic incompleteness
persists.

</details>


### [132] [The $\boldsymbol{r^{-3}}$ Curvature Decay and the Infrared Structure of Linearized Gravity](https://arxiv.org/abs/2511.05345)
*Michael Wilson*

Main category: gr-qc

TL;DR: 该论文发现曲率衰减率 |Riem| ~ r^{-3} 是渐近平坦流形上线性化引力的尖锐谱阈值，区分了辐射模式和红外行为。


<details>
  <summary>Details</summary>
Motivation: 研究渐近平坦流形上线性化引力的谱特性，特别是曲率衰减率如何影响引力场的辐射和束缚行为。

Method: 分析空间Lichnerowicz算子的谱特性，并通过径向模型 L_p = -d²/dr² + ℓ(ℓ+1)/r² + C/r^p 进行数值研究。

Result: 当 p > 3 时，谱是纯连续的 [0,∞)，对应自由辐射模式；当 p = 3 时，零能量进入本质谱，产生有限能量的静态模式；当 p < 3 时，束缚态增强。

Conclusion: r^{-3} 衰减率是引力场红外结构的关键阈值，与规范场中的临界阈值平行，揭示了引力和规范场红外行为的共同标度规律。

Abstract: We identify curvature decay $|\mathrm{Riem}| \sim r^{-3}$ as a sharp spectral
threshold in linearized gravity on asymptotically flat manifolds. For faster
decay, the spatial Lichnerowicz operator possesses a purely continuous spectrum
$\sigma_{\mathrm{ess}}(L) = [0,\infty)$, corresponding to freely radiating
tensor modes. At the inverse-cube rate, compactness fails and zero energy
enters $\sigma_{\mathrm{ess}}(L)$, yielding marginally bound, finite-energy
configurations that remain spatially extended. These static modes constitute
the linear precursors of gravitational memory and soft-graviton phenomena,
delineating the geometric boundary between dispersive and infrared behavior. A
complementary numerical study of the radial model \[ L_p = -\frac{d^2}{dr^2} +
\frac{\ell(\ell+1)}{r^2} + \frac{C}{r^p} \] confirms the analytic scaling law,
locating the same transition at $p = 3$. The eigenvalue trends approach the
flat-space limit continuously for $p > 3$ and strengthen progressively for $p <
3$, demonstrating a smooth yet sharp spectral transition rather than a discrete
confinement regime. The result parallels the critical threshold of the
non-Abelian covariant Laplacian~[18], indicating a common $r^{-3}$ scaling that
governs the infrared structure of gauge and gravitational fields.

</details>
